CNNModel CHEMBL3231 RMSprop 0.0005 30 128 0 0.6 False True
Number of active compounds :	514
Number of inactive compounds :	514
---------------------------------
Run id: CNNModel_CHEMBL3231_RMSprop_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3231_RMSprop_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 653
Validation samples: 205
--
Training Step: 1  | time: 1.049s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/653
[A[ATraining Step: 2  | total loss: [1m[32m0.62402[0m[0m | time: 1.960s
[2K
| RMSProp | epoch: 001 | loss: 0.62402 - acc: 0.3937 -- iter: 064/653
[A[ATraining Step: 3  | total loss: [1m[32m0.68044[0m[0m | time: 2.794s
[2K
| RMSProp | epoch: 001 | loss: 0.68044 - acc: 0.5830 -- iter: 096/653
[A[ATraining Step: 4  | total loss: [1m[32m0.69004[0m[0m | time: 3.672s
[2K
| RMSProp | epoch: 001 | loss: 0.69004 - acc: 0.4973 -- iter: 128/653
[A[ATraining Step: 5  | total loss: [1m[32m0.69225[0m[0m | time: 4.575s
[2K
| RMSProp | epoch: 001 | loss: 0.69225 - acc: 0.4775 -- iter: 160/653
[A[ATraining Step: 6  | total loss: [1m[32m0.69275[0m[0m | time: 5.535s
[2K
| RMSProp | epoch: 001 | loss: 0.69275 - acc: 0.5121 -- iter: 192/653
[A[ATraining Step: 7  | total loss: [1m[32m0.69290[0m[0m | time: 6.494s
[2K
| RMSProp | epoch: 001 | loss: 0.69290 - acc: 0.5798 -- iter: 224/653
[A[ATraining Step: 8  | total loss: [1m[32m0.69320[0m[0m | time: 7.386s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4646 -- iter: 256/653
[A[ATraining Step: 9  | total loss: [1m[32m0.69323[0m[0m | time: 8.414s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4172 -- iter: 288/653
[A[ATraining Step: 10  | total loss: [1m[32m0.69307[0m[0m | time: 9.457s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.4898 -- iter: 320/653
[A[ATraining Step: 11  | total loss: [1m[32m0.69316[0m[0m | time: 10.624s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4502 -- iter: 352/653
[A[ATraining Step: 12  | total loss: [1m[32m0.69316[0m[0m | time: 11.411s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4586 -- iter: 384/653
[A[ATraining Step: 13  | total loss: [1m[32m0.69313[0m[0m | time: 12.249s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5031 -- iter: 416/653
[A[ATraining Step: 14  | total loss: [1m[32m0.69310[0m[0m | time: 13.129s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5274 -- iter: 448/653
[A[ATraining Step: 15  | total loss: [1m[32m0.69316[0m[0m | time: 14.056s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4800 -- iter: 480/653
[A[ATraining Step: 16  | total loss: [1m[32m0.69320[0m[0m | time: 14.940s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4641 -- iter: 512/653
[A[ATraining Step: 17  | total loss: [1m[32m0.69314[0m[0m | time: 15.912s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.4995 -- iter: 544/653
[A[ATraining Step: 18  | total loss: [1m[32m0.69304[0m[0m | time: 16.932s
[2K
| RMSProp | epoch: 001 | loss: 0.69304 - acc: 0.5429 -- iter: 576/653
[A[ATraining Step: 19  | total loss: [1m[32m0.69316[0m[0m | time: 17.833s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.5286 -- iter: 608/653
[A[ATraining Step: 20  | total loss: [1m[32m0.69322[0m[0m | time: 18.761s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.5094 -- iter: 640/653
[A[ATraining Step: 21  | total loss: [1m[32m0.69318[0m[0m | time: 20.510s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.5065 | val_loss: 0.69313 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 22  | total loss: [1m[32m0.69318[0m[0m | time: 0.493s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4930 -- iter: 032/653
[A[ATraining Step: 23  | total loss: [1m[32m0.69315[0m[0m | time: 1.556s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5509 -- iter: 064/653
[A[ATraining Step: 24  | total loss: [1m[32m0.69320[0m[0m | time: 2.507s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.5190 -- iter: 096/653
[A[ATraining Step: 25  | total loss: [1m[32m0.69321[0m[0m | time: 3.648s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4627 -- iter: 128/653
[A[ATraining Step: 26  | total loss: [1m[32m0.69316[0m[0m | time: 4.964s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.4643 -- iter: 160/653
[A[ATraining Step: 27  | total loss: [1m[32m0.69306[0m[0m | time: 6.232s
[2K
| RMSProp | epoch: 002 | loss: 0.69306 - acc: 0.5377 -- iter: 192/653
[A[ATraining Step: 28  | total loss: [1m[32m0.69313[0m[0m | time: 7.542s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5127 -- iter: 224/653
[A[ATraining Step: 29  | total loss: [1m[32m0.69306[0m[0m | time: 8.758s
[2K
| RMSProp | epoch: 002 | loss: 0.69306 - acc: 0.5248 -- iter: 256/653
[A[ATraining Step: 30  | total loss: [1m[32m0.69305[0m[0m | time: 9.958s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5263 -- iter: 288/653
[A[ATraining Step: 31  | total loss: [1m[32m0.69309[0m[0m | time: 11.226s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5203 -- iter: 320/653
[A[ATraining Step: 32  | total loss: [1m[32m0.69310[0m[0m | time: 13.141s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5438 -- iter: 352/653
[A[ATraining Step: 33  | total loss: [1m[32m0.69306[0m[0m | time: 15.399s
[2K
| RMSProp | epoch: 002 | loss: 0.69306 - acc: 0.5616 -- iter: 384/653
[A[ATraining Step: 34  | total loss: [1m[32m0.69306[0m[0m | time: 16.413s
[2K
| RMSProp | epoch: 002 | loss: 0.69306 - acc: 0.5618 -- iter: 416/653
[A[ATraining Step: 35  | total loss: [1m[32m0.69317[0m[0m | time: 17.658s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.5358 -- iter: 448/653
[A[ATraining Step: 36  | total loss: [1m[32m0.69317[0m[0m | time: 18.937s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.5349 -- iter: 480/653
[A[ATraining Step: 37  | total loss: [1m[32m0.69310[0m[0m | time: 20.124s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5404 -- iter: 512/653
[A[ATraining Step: 38  | total loss: [1m[32m0.69287[0m[0m | time: 21.184s
[2K
| RMSProp | epoch: 002 | loss: 0.69287 - acc: 0.5753 -- iter: 544/653
[A[ATraining Step: 39  | total loss: [1m[32m0.69290[0m[0m | time: 22.539s
[2K
| RMSProp | epoch: 002 | loss: 0.69290 - acc: 0.5609 -- iter: 576/653
[A[ATraining Step: 40  | total loss: [1m[32m0.69303[0m[0m | time: 23.825s
[2K
| RMSProp | epoch: 002 | loss: 0.69303 - acc: 0.5319 -- iter: 608/653
[A[ATraining Step: 41  | total loss: [1m[32m0.69331[0m[0m | time: 25.240s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4801 -- iter: 640/653
[A[ATraining Step: 42  | total loss: [1m[32m0.69321[0m[0m | time: 27.834s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4949 | val_loss: 0.69312 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 43  | total loss: [1m[32m0.69314[0m[0m | time: 0.619s
[2K
| RMSProp | epoch: 003 | loss: 0.69314 - acc: 0.5013 -- iter: 032/653
[A[ATraining Step: 44  | total loss: [1m[32m0.69312[0m[0m | time: 1.223s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5078 -- iter: 064/653
[A[ATraining Step: 45  | total loss: [1m[32m0.69305[0m[0m | time: 2.503s
[2K
| RMSProp | epoch: 003 | loss: 0.69305 - acc: 0.5130 -- iter: 096/653
[A[ATraining Step: 46  | total loss: [1m[32m0.69289[0m[0m | time: 3.778s
[2K
| RMSProp | epoch: 003 | loss: 0.69289 - acc: 0.5421 -- iter: 128/653
[A[ATraining Step: 47  | total loss: [1m[32m0.69292[0m[0m | time: 5.149s
[2K
| RMSProp | epoch: 003 | loss: 0.69292 - acc: 0.5352 -- iter: 160/653
[A[ATraining Step: 48  | total loss: [1m[32m0.69278[0m[0m | time: 6.487s
[2K
| RMSProp | epoch: 003 | loss: 0.69278 - acc: 0.5546 -- iter: 192/653
[A[ATraining Step: 49  | total loss: [1m[32m0.69274[0m[0m | time: 7.695s
[2K
| RMSProp | epoch: 003 | loss: 0.69274 - acc: 0.5559 -- iter: 224/653
[A[ATraining Step: 50  | total loss: [1m[32m0.69279[0m[0m | time: 9.027s
[2K
| RMSProp | epoch: 003 | loss: 0.69279 - acc: 0.5521 -- iter: 256/653
[A[ATraining Step: 51  | total loss: [1m[32m0.69291[0m[0m | time: 10.348s
[2K
| RMSProp | epoch: 003 | loss: 0.69291 - acc: 0.5394 -- iter: 288/653
[A[ATraining Step: 52  | total loss: [1m[32m0.69290[0m[0m | time: 11.747s
[2K
| RMSProp | epoch: 003 | loss: 0.69290 - acc: 0.5381 -- iter: 320/653
[A[ATraining Step: 53  | total loss: [1m[32m0.69299[0m[0m | time: 13.007s
[2K
| RMSProp | epoch: 003 | loss: 0.69299 - acc: 0.5279 -- iter: 352/653
[A[ATraining Step: 54  | total loss: [1m[32m0.69286[0m[0m | time: 14.141s
[2K
| RMSProp | epoch: 003 | loss: 0.69286 - acc: 0.5420 -- iter: 384/653
[A[ATraining Step: 55  | total loss: [1m[32m0.69295[0m[0m | time: 15.353s
[2K
| RMSProp | epoch: 003 | loss: 0.69295 - acc: 0.5315 -- iter: 416/653
[A[ATraining Step: 56  | total loss: [1m[32m0.69302[0m[0m | time: 16.693s
[2K
| RMSProp | epoch: 003 | loss: 0.69302 - acc: 0.5227 -- iter: 448/653
[A[ATraining Step: 57  | total loss: [1m[32m0.69313[0m[0m | time: 17.979s
[2K
| RMSProp | epoch: 003 | loss: 0.69313 - acc: 0.5109 -- iter: 480/653
[A[ATraining Step: 58  | total loss: [1m[32m0.69302[0m[0m | time: 19.206s
[2K
| RMSProp | epoch: 003 | loss: 0.69302 - acc: 0.5222 -- iter: 512/653
[A[ATraining Step: 59  | total loss: [1m[32m0.69287[0m[0m | time: 20.671s
[2K
| RMSProp | epoch: 003 | loss: 0.69287 - acc: 0.5360 -- iter: 544/653
[A[ATraining Step: 60  | total loss: [1m[32m0.69290[0m[0m | time: 22.029s
[2K
| RMSProp | epoch: 003 | loss: 0.69290 - acc: 0.5312 -- iter: 576/653
[A[ATraining Step: 61  | total loss: [1m[32m0.69289[0m[0m | time: 23.240s
[2K
| RMSProp | epoch: 003 | loss: 0.69289 - acc: 0.5312 -- iter: 608/653
[A[ATraining Step: 62  | total loss: [1m[32m0.69285[0m[0m | time: 24.641s
[2K
| RMSProp | epoch: 003 | loss: 0.69285 - acc: 0.5353 -- iter: 640/653
[A[ATraining Step: 63  | total loss: [1m[32m0.69274[0m[0m | time: 27.408s
[2K
| RMSProp | epoch: 003 | loss: 0.69274 - acc: 0.5427 | val_loss: 0.69306 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 64  | total loss: [1m[32m0.69265[0m[0m | time: 1.011s
[2K
| RMSProp | epoch: 004 | loss: 0.69265 - acc: 0.5491 -- iter: 032/653
[A[ATraining Step: 65  | total loss: [1m[32m0.69266[0m[0m | time: 1.445s
[2K
| RMSProp | epoch: 004 | loss: 0.69266 - acc: 0.5469 -- iter: 064/653
[A[ATraining Step: 66  | total loss: [1m[32m0.69203[0m[0m | time: 1.869s
[2K
| RMSProp | epoch: 004 | loss: 0.69203 - acc: 0.5833 -- iter: 096/653
[A[ATraining Step: 67  | total loss: [1m[32m0.69129[0m[0m | time: 2.922s
[2K
| RMSProp | epoch: 004 | loss: 0.69129 - acc: 0.6148 -- iter: 128/653
[A[ATraining Step: 68  | total loss: [1m[32m0.69181[0m[0m | time: 3.928s
[2K
| RMSProp | epoch: 004 | loss: 0.69181 - acc: 0.5901 -- iter: 160/653
[A[ATraining Step: 69  | total loss: [1m[32m0.69194[0m[0m | time: 4.759s
[2K
| RMSProp | epoch: 004 | loss: 0.69194 - acc: 0.5832 -- iter: 192/653
[A[ATraining Step: 70  | total loss: [1m[32m0.69208[0m[0m | time: 5.880s
[2K
| RMSProp | epoch: 004 | loss: 0.69208 - acc: 0.5736 -- iter: 224/653
[A[ATraining Step: 71  | total loss: [1m[32m0.69222[0m[0m | time: 7.078s
[2K
| RMSProp | epoch: 004 | loss: 0.69222 - acc: 0.5652 -- iter: 256/653
[A[ATraining Step: 72  | total loss: [1m[32m0.69223[0m[0m | time: 8.149s
[2K
| RMSProp | epoch: 004 | loss: 0.69223 - acc: 0.5614 -- iter: 288/653
[A[ATraining Step: 73  | total loss: [1m[32m0.69240[0m[0m | time: 8.934s
[2K
| RMSProp | epoch: 004 | loss: 0.69240 - acc: 0.5511 -- iter: 320/653
[A[ATraining Step: 74  | total loss: [1m[32m0.69242[0m[0m | time: 9.893s
[2K
| RMSProp | epoch: 004 | loss: 0.69242 - acc: 0.5489 -- iter: 352/653
[A[ATraining Step: 75  | total loss: [1m[32m0.69250[0m[0m | time: 10.873s
[2K
| RMSProp | epoch: 004 | loss: 0.69250 - acc: 0.5436 -- iter: 384/653
[A[ATraining Step: 76  | total loss: [1m[32m0.69247[0m[0m | time: 11.760s
[2K
| RMSProp | epoch: 004 | loss: 0.69247 - acc: 0.5423 -- iter: 416/653
[A[ATraining Step: 77  | total loss: [1m[32m0.69262[0m[0m | time: 12.719s
[2K
| RMSProp | epoch: 004 | loss: 0.69262 - acc: 0.5345 -- iter: 448/653
[A[ATraining Step: 78  | total loss: [1m[32m0.69247[0m[0m | time: 13.730s
[2K
| RMSProp | epoch: 004 | loss: 0.69247 - acc: 0.5407 -- iter: 480/653
[A[ATraining Step: 79  | total loss: [1m[32m0.69232[0m[0m | time: 14.677s
[2K
| RMSProp | epoch: 004 | loss: 0.69232 - acc: 0.5462 -- iter: 512/653
[A[ATraining Step: 80  | total loss: [1m[32m0.69269[0m[0m | time: 15.560s
[2K
| RMSProp | epoch: 004 | loss: 0.69269 - acc: 0.5319 -- iter: 544/653
[A[ATraining Step: 81  | total loss: [1m[32m0.69265[0m[0m | time: 16.532s
[2K
| RMSProp | epoch: 004 | loss: 0.69265 - acc: 0.5318 -- iter: 576/653
[A[ATraining Step: 82  | total loss: [1m[32m0.69288[0m[0m | time: 17.548s
[2K
| RMSProp | epoch: 004 | loss: 0.69288 - acc: 0.5224 -- iter: 608/653
[A[ATraining Step: 83  | total loss: [1m[32m0.69277[0m[0m | time: 18.629s
[2K
| RMSProp | epoch: 004 | loss: 0.69277 - acc: 0.5264 -- iter: 640/653
[A[ATraining Step: 84  | total loss: [1m[32m0.69282[0m[0m | time: 20.405s
[2K
| RMSProp | epoch: 004 | loss: 0.69282 - acc: 0.5238 | val_loss: 0.69304 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 85  | total loss: [1m[32m0.69262[0m[0m | time: 1.041s
[2K
| RMSProp | epoch: 005 | loss: 0.69262 - acc: 0.5308 -- iter: 032/653
[A[ATraining Step: 86  | total loss: [1m[32m0.69225[0m[0m | time: 2.256s
[2K
| RMSProp | epoch: 005 | loss: 0.69225 - acc: 0.5433 -- iter: 064/653
[A[ATraining Step: 87  | total loss: [1m[32m0.69195[0m[0m | time: 2.683s
[2K
| RMSProp | epoch: 005 | loss: 0.69195 - acc: 0.5515 -- iter: 096/653
[A[ATraining Step: 88  | total loss: [1m[32m0.69115[0m[0m | time: 3.046s
[2K
| RMSProp | epoch: 005 | loss: 0.69115 - acc: 0.5733 -- iter: 128/653
[A[ATraining Step: 89  | total loss: [1m[32m0.69026[0m[0m | time: 3.921s
[2K
| RMSProp | epoch: 005 | loss: 0.69026 - acc: 0.5929 -- iter: 160/653
[A[ATraining Step: 90  | total loss: [1m[32m0.69002[0m[0m | time: 4.833s
[2K
| RMSProp | epoch: 005 | loss: 0.69002 - acc: 0.5961 -- iter: 192/653
[A[ATraining Step: 91  | total loss: [1m[32m0.68958[0m[0m | time: 5.731s
[2K
| RMSProp | epoch: 005 | loss: 0.68958 - acc: 0.6021 -- iter: 224/653
[A[ATraining Step: 92  | total loss: [1m[32m0.69046[0m[0m | time: 6.728s
[2K
| RMSProp | epoch: 005 | loss: 0.69046 - acc: 0.5825 -- iter: 256/653
[A[ATraining Step: 93  | total loss: [1m[32m0.69075[0m[0m | time: 7.726s
[2K
| RMSProp | epoch: 005 | loss: 0.69075 - acc: 0.5743 -- iter: 288/653
[A[ATraining Step: 94  | total loss: [1m[32m0.69161[0m[0m | time: 8.662s
[2K
| RMSProp | epoch: 005 | loss: 0.69161 - acc: 0.5543 -- iter: 320/653
[A[ATraining Step: 95  | total loss: [1m[32m0.69211[0m[0m | time: 9.533s
[2K
| RMSProp | epoch: 005 | loss: 0.69211 - acc: 0.5426 -- iter: 352/653
[A[ATraining Step: 96  | total loss: [1m[32m0.69293[0m[0m | time: 10.619s
[2K
| RMSProp | epoch: 005 | loss: 0.69293 - acc: 0.5228 -- iter: 384/653
[A[ATraining Step: 97  | total loss: [1m[32m0.69273[0m[0m | time: 11.650s
[2K
| RMSProp | epoch: 005 | loss: 0.69273 - acc: 0.5267 -- iter: 416/653
[A[ATraining Step: 98  | total loss: [1m[32m0.69229[0m[0m | time: 12.689s
[2K
| RMSProp | epoch: 005 | loss: 0.69229 - acc: 0.5366 -- iter: 448/653
[A[ATraining Step: 99  | total loss: [1m[32m0.69283[0m[0m | time: 13.502s
[2K
| RMSProp | epoch: 005 | loss: 0.69283 - acc: 0.5235 -- iter: 480/653
[A[ATraining Step: 100  | total loss: [1m[32m0.69340[0m[0m | time: 14.383s
[2K
| RMSProp | epoch: 005 | loss: 0.69340 - acc: 0.5087 -- iter: 512/653
[A[ATraining Step: 101  | total loss: [1m[32m0.69309[0m[0m | time: 15.262s
[2K
| RMSProp | epoch: 005 | loss: 0.69309 - acc: 0.5172 -- iter: 544/653
[A[ATraining Step: 102  | total loss: [1m[32m0.69286[0m[0m | time: 16.411s
[2K
| RMSProp | epoch: 005 | loss: 0.69286 - acc: 0.5217 -- iter: 576/653
[A[ATraining Step: 103  | total loss: [1m[32m0.69275[0m[0m | time: 17.280s
[2K
| RMSProp | epoch: 005 | loss: 0.69275 - acc: 0.5227 -- iter: 608/653
[A[ATraining Step: 104  | total loss: [1m[32m0.69322[0m[0m | time: 18.243s
[2K
| RMSProp | epoch: 005 | loss: 0.69322 - acc: 0.5110 -- iter: 640/653
[A[ATraining Step: 105  | total loss: [1m[32m0.69312[0m[0m | time: 20.236s
[2K
| RMSProp | epoch: 005 | loss: 0.69312 - acc: 0.5130 | val_loss: 0.69304 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 106  | total loss: [1m[32m0.69328[0m[0m | time: 1.138s
[2K
| RMSProp | epoch: 006 | loss: 0.69328 - acc: 0.5086 -- iter: 032/653
[A[ATraining Step: 107  | total loss: [1m[32m0.69311[0m[0m | time: 10.770s
[2K
| RMSProp | epoch: 006 | loss: 0.69311 - acc: 0.5109 -- iter: 064/653
[A[ATraining Step: 108  | total loss: [1m[32m0.69280[0m[0m | time: 19.853s
[2K
| RMSProp | epoch: 006 | loss: 0.69280 - acc: 0.5192 -- iter: 096/653
[A[ATraining Step: 109  | total loss: [1m[32m0.69233[0m[0m | time: 20.393s
[2K
| RMSProp | epoch: 006 | loss: 0.69233 - acc: 0.5298 -- iter: 128/653
[A[ATraining Step: 110  | total loss: [1m[32m0.69330[0m[0m | time: 20.909s
[2K
| RMSProp | epoch: 006 | loss: 0.69330 - acc: 0.5075 -- iter: 160/653
[A[ATraining Step: 111  | total loss: [1m[32m0.69404[0m[0m | time: 28.070s
[2K
| RMSProp | epoch: 006 | loss: 0.69404 - acc: 0.4876 -- iter: 192/653
[A[ATraining Step: 112  | total loss: [1m[32m0.69359[0m[0m | time: 47.395s
[2K
| RMSProp | epoch: 006 | loss: 0.69359 - acc: 0.5013 -- iter: 224/653
[A[ATraining Step: 113  | total loss: [1m[32m0.69348[0m[0m | time: 50.344s
[2K
| RMSProp | epoch: 006 | loss: 0.69348 - acc: 0.5043 -- iter: 256/653
[A[ATraining Step: 114  | total loss: [1m[32m0.69326[0m[0m | time: 51.510s
[2K
| RMSProp | epoch: 006 | loss: 0.69326 - acc: 0.5101 -- iter: 288/653
[A[ATraining Step: 115  | total loss: [1m[32m0.69327[0m[0m | time: 52.698s
[2K
| RMSProp | epoch: 006 | loss: 0.69327 - acc: 0.5091 -- iter: 320/653
[A[ATraining Step: 116  | total loss: [1m[32m0.69280[0m[0m | time: 53.928s
[2K
| RMSProp | epoch: 006 | loss: 0.69280 - acc: 0.5207 -- iter: 352/653
[A[ATraining Step: 117  | total loss: [1m[32m0.69284[0m[0m | time: 55.171s
[2K
| RMSProp | epoch: 006 | loss: 0.69284 - acc: 0.5186 -- iter: 384/653
[A[ATraining Step: 118  | total loss: [1m[32m0.69262[0m[0m | time: 56.263s
[2K
| RMSProp | epoch: 006 | loss: 0.69262 - acc: 0.5230 -- iter: 416/653
[A[ATraining Step: 119  | total loss: [1m[32m0.69227[0m[0m | time: 57.633s
[2K
| RMSProp | epoch: 006 | loss: 0.69227 - acc: 0.5301 -- iter: 448/653
[A[ATraining Step: 120  | total loss: [1m[32m0.69304[0m[0m | time: 59.162s
[2K
| RMSProp | epoch: 006 | loss: 0.69304 - acc: 0.5146 -- iter: 480/653
[A[ATraining Step: 121  | total loss: [1m[32m0.69293[0m[0m | time: 60.700s
[2K
| RMSProp | epoch: 006 | loss: 0.69293 - acc: 0.5162 -- iter: 512/653
[A[ATraining Step: 122  | total loss: [1m[32m0.69266[0m[0m | time: 61.755s
[2K
| RMSProp | epoch: 006 | loss: 0.69266 - acc: 0.5209 -- iter: 544/653
[A[ATraining Step: 123  | total loss: [1m[32m0.69287[0m[0m | time: 62.727s
[2K
| RMSProp | epoch: 006 | loss: 0.69287 - acc: 0.5157 -- iter: 576/653
[A[ATraining Step: 124  | total loss: [1m[32m0.69262[0m[0m | time: 63.677s
[2K
| RMSProp | epoch: 006 | loss: 0.69262 - acc: 0.5203 -- iter: 608/653
[A[ATraining Step: 125  | total loss: [1m[32m0.69195[0m[0m | time: 64.744s
[2K
| RMSProp | epoch: 006 | loss: 0.69195 - acc: 0.5339 -- iter: 640/653
[A[ATraining Step: 126  | total loss: [1m[32m0.69229[0m[0m | time: 66.985s
[2K
| RMSProp | epoch: 006 | loss: 0.69229 - acc: 0.5274 | val_loss: 0.69309 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 127  | total loss: [1m[32m0.69278[0m[0m | time: 1.623s
[2K
| RMSProp | epoch: 007 | loss: 0.69278 - acc: 0.5184 -- iter: 032/653
[A[ATraining Step: 128  | total loss: [1m[32m0.69300[0m[0m | time: 9.243s
[2K
| RMSProp | epoch: 007 | loss: 0.69300 - acc: 0.5135 -- iter: 064/653
[A[ATraining Step: 129  | total loss: [1m[32m0.69263[0m[0m | time: 11.061s
[2K
| RMSProp | epoch: 007 | loss: 0.69263 - acc: 0.5215 -- iter: 096/653
[A[ATraining Step: 130  | total loss: [1m[32m0.69252[0m[0m | time: 12.253s
[2K
| RMSProp | epoch: 007 | loss: 0.69252 - acc: 0.5225 -- iter: 128/653
[A[ATraining Step: 131  | total loss: [1m[32m0.69212[0m[0m | time: 12.800s
[2K
| RMSProp | epoch: 007 | loss: 0.69212 - acc: 0.5296 -- iter: 160/653
[A[ATraining Step: 132  | total loss: [1m[32m0.69248[0m[0m | time: 14.258s
[2K
| RMSProp | epoch: 007 | loss: 0.69248 - acc: 0.5228 -- iter: 192/653
[A[ATraining Step: 133  | total loss: [1m[32m0.69273[0m[0m | time: 22.805s
[2K
| RMSProp | epoch: 007 | loss: 0.69273 - acc: 0.5167 -- iter: 224/653
[A[ATraining Step: 134  | total loss: [1m[32m0.69281[0m[0m | time: 23.847s
[2K
| RMSProp | epoch: 007 | loss: 0.69281 - acc: 0.5150 -- iter: 256/653
[A[ATraining Step: 135  | total loss: [1m[32m0.69271[0m[0m | time: 25.076s
[2K
| RMSProp | epoch: 007 | loss: 0.69271 - acc: 0.5166 -- iter: 288/653
[A[ATraining Step: 136  | total loss: [1m[32m0.69216[0m[0m | time: 26.303s
[2K
| RMSProp | epoch: 007 | loss: 0.69216 - acc: 0.5275 -- iter: 320/653
[A[ATraining Step: 137  | total loss: [1m[32m0.69315[0m[0m | time: 27.600s
[2K
| RMSProp | epoch: 007 | loss: 0.69315 - acc: 0.5122 -- iter: 352/653
[A[ATraining Step: 138  | total loss: [1m[32m0.69345[0m[0m | time: 28.779s
[2K
| RMSProp | epoch: 007 | loss: 0.69345 - acc: 0.5047 -- iter: 384/653
[A[ATraining Step: 139  | total loss: [1m[32m0.69330[0m[0m | time: 30.198s
[2K
| RMSProp | epoch: 007 | loss: 0.69330 - acc: 0.5074 -- iter: 416/653
[A[ATraining Step: 140  | total loss: [1m[32m0.69302[0m[0m | time: 31.519s
[2K
| RMSProp | epoch: 007 | loss: 0.69302 - acc: 0.5129 -- iter: 448/653
[A[ATraining Step: 141  | total loss: [1m[32m0.69229[0m[0m | time: 32.892s
[2K
| RMSProp | epoch: 007 | loss: 0.69229 - acc: 0.5272 -- iter: 480/653
[A[ATraining Step: 142  | total loss: [1m[32m0.69242[0m[0m | time: 34.238s
[2K
| RMSProp | epoch: 007 | loss: 0.69242 - acc: 0.5245 -- iter: 512/653
[A[ATraining Step: 143  | total loss: [1m[32m0.69252[0m[0m | time: 35.462s
[2K
| RMSProp | epoch: 007 | loss: 0.69252 - acc: 0.5221 -- iter: 544/653
[A[ATraining Step: 144  | total loss: [1m[32m0.69205[0m[0m | time: 36.731s
[2K
| RMSProp | epoch: 007 | loss: 0.69205 - acc: 0.5292 -- iter: 576/653
[A[ATraining Step: 145  | total loss: [1m[32m0.69228[0m[0m | time: 38.743s
[2K
| RMSProp | epoch: 007 | loss: 0.69228 - acc: 0.5263 -- iter: 608/653
[A[ATraining Step: 146  | total loss: [1m[32m0.69270[0m[0m | time: 42.525s
[2K
| RMSProp | epoch: 007 | loss: 0.69270 - acc: 0.5206 -- iter: 640/653
[A[ATraining Step: 147  | total loss: [1m[32m0.69262[0m[0m | time: 44.944s
[2K
| RMSProp | epoch: 007 | loss: 0.69262 - acc: 0.5216 | val_loss: 0.69320 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 148  | total loss: [1m[32m0.69252[0m[0m | time: 1.156s
[2K
| RMSProp | epoch: 008 | loss: 0.69252 - acc: 0.5226 -- iter: 032/653
[A[ATraining Step: 149  | total loss: [1m[32m0.69187[0m[0m | time: 2.451s
[2K
| RMSProp | epoch: 008 | loss: 0.69187 - acc: 0.5328 -- iter: 064/653
[A[ATraining Step: 150  | total loss: [1m[32m0.69259[0m[0m | time: 3.878s
[2K
| RMSProp | epoch: 008 | loss: 0.69259 - acc: 0.5233 -- iter: 096/653
[A[ATraining Step: 151  | total loss: [1m[32m0.69229[0m[0m | time: 5.332s
[2K
| RMSProp | epoch: 008 | loss: 0.69229 - acc: 0.5272 -- iter: 128/653
[A[ATraining Step: 152  | total loss: [1m[32m0.69310[0m[0m | time: 6.403s
[2K
| RMSProp | epoch: 008 | loss: 0.69310 - acc: 0.5151 -- iter: 160/653
[A[ATraining Step: 153  | total loss: [1m[32m0.69328[0m[0m | time: 7.032s
[2K
| RMSProp | epoch: 008 | loss: 0.69328 - acc: 0.5105 -- iter: 192/653
[A[ATraining Step: 154  | total loss: [1m[32m0.69241[0m[0m | time: 7.587s
[2K
| RMSProp | epoch: 008 | loss: 0.69241 - acc: 0.5287 -- iter: 224/653
[A[ATraining Step: 155  | total loss: [1m[32m0.69120[0m[0m | time: 8.949s
[2K
| RMSProp | epoch: 008 | loss: 0.69120 - acc: 0.5450 -- iter: 256/653
[A[ATraining Step: 156  | total loss: [1m[32m0.69086[0m[0m | time: 10.366s
[2K
| RMSProp | epoch: 008 | loss: 0.69086 - acc: 0.5468 -- iter: 288/653
[A[ATraining Step: 157  | total loss: [1m[32m0.68941[0m[0m | time: 14.113s
[2K
| RMSProp | epoch: 008 | loss: 0.68941 - acc: 0.5577 -- iter: 320/653
[A[ATraining Step: 158  | total loss: [1m[32m0.69209[0m[0m | time: 15.445s
[2K
| RMSProp | epoch: 008 | loss: 0.69209 - acc: 0.5457 -- iter: 352/653
[A[ATraining Step: 159  | total loss: [1m[32m0.69060[0m[0m | time: 16.898s
[2K
| RMSProp | epoch: 008 | loss: 0.69060 - acc: 0.5599 -- iter: 384/653
[A[ATraining Step: 160  | total loss: [1m[32m0.69142[0m[0m | time: 17.940s
[2K
| RMSProp | epoch: 008 | loss: 0.69142 - acc: 0.5508 -- iter: 416/653
[A[ATraining Step: 161  | total loss: [1m[32m0.69044[0m[0m | time: 19.305s
[2K
| RMSProp | epoch: 008 | loss: 0.69044 - acc: 0.5582 -- iter: 448/653
[A[ATraining Step: 162  | total loss: [1m[32m0.69174[0m[0m | time: 20.583s
[2K
| RMSProp | epoch: 008 | loss: 0.69174 - acc: 0.5461 -- iter: 480/653
[A[ATraining Step: 163  | total loss: [1m[32m0.69235[0m[0m | time: 22.012s
[2K
| RMSProp | epoch: 008 | loss: 0.69235 - acc: 0.5384 -- iter: 512/653
[A[ATraining Step: 164  | total loss: [1m[32m0.69247[0m[0m | time: 23.285s
[2K
| RMSProp | epoch: 008 | loss: 0.69247 - acc: 0.5345 -- iter: 544/653
[A[ATraining Step: 165  | total loss: [1m[32m0.69265[0m[0m | time: 24.454s
[2K
| RMSProp | epoch: 008 | loss: 0.69265 - acc: 0.5311 -- iter: 576/653
[A[ATraining Step: 166  | total loss: [1m[32m0.69304[0m[0m | time: 25.645s
[2K
| RMSProp | epoch: 008 | loss: 0.69304 - acc: 0.5249 -- iter: 608/653
[A[ATraining Step: 167  | total loss: [1m[32m0.69328[0m[0m | time: 26.889s
[2K
| RMSProp | epoch: 008 | loss: 0.69328 - acc: 0.5192 -- iter: 640/653
[A[ATraining Step: 168  | total loss: [1m[32m0.69329[0m[0m | time: 30.136s
[2K
| RMSProp | epoch: 008 | loss: 0.69329 - acc: 0.5173 | val_loss: 0.69330 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 169  | total loss: [1m[32m0.69281[0m[0m | time: 1.333s
[2K
| RMSProp | epoch: 009 | loss: 0.69281 - acc: 0.5250 -- iter: 032/653
[A[ATraining Step: 170  | total loss: [1m[32m0.69139[0m[0m | time: 2.596s
[2K
| RMSProp | epoch: 009 | loss: 0.69139 - acc: 0.5412 -- iter: 064/653
[A[ATraining Step: 171  | total loss: [1m[32m0.69100[0m[0m | time: 3.958s
[2K
| RMSProp | epoch: 009 | loss: 0.69100 - acc: 0.5433 -- iter: 096/653
[A[ATraining Step: 172  | total loss: [1m[32m0.69011[0m[0m | time: 5.219s
[2K
| RMSProp | epoch: 009 | loss: 0.69011 - acc: 0.5484 -- iter: 128/653
[A[ATraining Step: 173  | total loss: [1m[32m0.69184[0m[0m | time: 6.344s
[2K
| RMSProp | epoch: 009 | loss: 0.69184 - acc: 0.5404 -- iter: 160/653
[A[ATraining Step: 174  | total loss: [1m[32m0.69302[0m[0m | time: 7.320s
[2K
| RMSProp | epoch: 009 | loss: 0.69302 - acc: 0.5270 -- iter: 192/653
[A[ATraining Step: 175  | total loss: [1m[32m0.69329[0m[0m | time: 7.748s
[2K
| RMSProp | epoch: 009 | loss: 0.69329 - acc: 0.5212 -- iter: 224/653
[A[ATraining Step: 176  | total loss: [1m[32m0.69310[0m[0m | time: 8.088s
[2K
| RMSProp | epoch: 009 | loss: 0.69310 - acc: 0.5229 -- iter: 256/653
[A[ATraining Step: 177  | total loss: [1m[32m0.69289[0m[0m | time: 9.068s
[2K
| RMSProp | epoch: 009 | loss: 0.69289 - acc: 0.5245 -- iter: 288/653
[A[ATraining Step: 178  | total loss: [1m[32m0.69365[0m[0m | time: 10.154s
[2K
| RMSProp | epoch: 009 | loss: 0.69365 - acc: 0.5126 -- iter: 320/653
[A[ATraining Step: 179  | total loss: [1m[32m0.69378[0m[0m | time: 11.393s
[2K
| RMSProp | epoch: 009 | loss: 0.69378 - acc: 0.5083 -- iter: 352/653
[A[ATraining Step: 180  | total loss: [1m[32m0.69406[0m[0m | time: 12.277s
[2K
| RMSProp | epoch: 009 | loss: 0.69406 - acc: 0.5012 -- iter: 384/653
[A[ATraining Step: 181  | total loss: [1m[32m0.69314[0m[0m | time: 13.173s
[2K
| RMSProp | epoch: 009 | loss: 0.69314 - acc: 0.5229 -- iter: 416/653
[A[ATraining Step: 182  | total loss: [1m[32m0.69279[0m[0m | time: 14.187s
[2K
| RMSProp | epoch: 009 | loss: 0.69279 - acc: 0.5269 -- iter: 448/653
[A[ATraining Step: 183  | total loss: [1m[32m0.69131[0m[0m | time: 15.080s
[2K
| RMSProp | epoch: 009 | loss: 0.69131 - acc: 0.5461 -- iter: 480/653
[A[ATraining Step: 184  | total loss: [1m[32m0.69171[0m[0m | time: 16.065s
[2K
| RMSProp | epoch: 009 | loss: 0.69171 - acc: 0.5415 -- iter: 512/653
[A[ATraining Step: 185  | total loss: [1m[32m0.69191[0m[0m | time: 17.136s
[2K
| RMSProp | epoch: 009 | loss: 0.69191 - acc: 0.5373 -- iter: 544/653
[A[ATraining Step: 186  | total loss: [1m[32m0.69187[0m[0m | time: 18.023s
[2K
| RMSProp | epoch: 009 | loss: 0.69187 - acc: 0.5367 -- iter: 576/653
[A[ATraining Step: 187  | total loss: [1m[32m0.69236[0m[0m | time: 18.904s
[2K
| RMSProp | epoch: 009 | loss: 0.69236 - acc: 0.5299 -- iter: 608/653
[A[ATraining Step: 188  | total loss: [1m[32m0.69173[0m[0m | time: 19.952s
[2K
| RMSProp | epoch: 009 | loss: 0.69173 - acc: 0.5363 -- iter: 640/653
[A[ATraining Step: 189  | total loss: [1m[32m0.69223[0m[0m | time: 22.104s
[2K
| RMSProp | epoch: 009 | loss: 0.69223 - acc: 0.5295 | val_loss: 0.69343 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 190  | total loss: [1m[32m0.69210[0m[0m | time: 0.903s
[2K
| RMSProp | epoch: 010 | loss: 0.69210 - acc: 0.5297 -- iter: 032/653
[A[ATraining Step: 191  | total loss: [1m[32m0.69176[0m[0m | time: 1.895s
[2K
| RMSProp | epoch: 010 | loss: 0.69176 - acc: 0.5330 -- iter: 064/653
[A[ATraining Step: 192  | total loss: [1m[32m0.69135[0m[0m | time: 2.986s
[2K
| RMSProp | epoch: 010 | loss: 0.69135 - acc: 0.5359 -- iter: 096/653
[A[ATraining Step: 193  | total loss: [1m[32m0.69094[0m[0m | time: 3.926s
[2K
| RMSProp | epoch: 010 | loss: 0.69094 - acc: 0.5386 -- iter: 128/653
[A[ATraining Step: 194  | total loss: [1m[32m0.68997[0m[0m | time: 4.994s
[2K
| RMSProp | epoch: 010 | loss: 0.68997 - acc: 0.5441 -- iter: 160/653
[A[ATraining Step: 195  | total loss: [1m[32m0.68772[0m[0m | time: 6.108s
[2K
| RMSProp | epoch: 010 | loss: 0.68772 - acc: 0.5522 -- iter: 192/653
[A[ATraining Step: 196  | total loss: [1m[32m0.69343[0m[0m | time: 7.271s
[2K
| RMSProp | epoch: 010 | loss: 0.69343 - acc: 0.5501 -- iter: 224/653
[A[ATraining Step: 197  | total loss: [1m[32m0.69694[0m[0m | time: 7.615s
[2K
| RMSProp | epoch: 010 | loss: 0.69694 - acc: 0.5232 -- iter: 256/653
[A[ATraining Step: 198  | total loss: [1m[32m0.69575[0m[0m | time: 8.133s
[2K
| RMSProp | epoch: 010 | loss: 0.69575 - acc: 0.5324 -- iter: 288/653
[A[ATraining Step: 199  | total loss: [1m[32m0.69443[0m[0m | time: 9.557s
[2K
| RMSProp | epoch: 010 | loss: 0.69443 - acc: 0.5407 -- iter: 320/653
[A[ATraining Step: 200  | total loss: [1m[32m0.69294[0m[0m | time: 14.921s
[2K
| RMSProp | epoch: 010 | loss: 0.69294 - acc: 0.5492 | val_loss: 0.70713 - val_acc: 0.5073 -- iter: 352/653
--
Training Step: 201  | total loss: [1m[32m0.68989[0m[0m | time: 16.242s
[2K
| RMSProp | epoch: 010 | loss: 0.68989 - acc: 0.5630 -- iter: 384/653
[A[ATraining Step: 202  | total loss: [1m[32m0.69304[0m[0m | time: 17.605s
[2K
| RMSProp | epoch: 010 | loss: 0.69304 - acc: 0.5536 -- iter: 416/653
[A[ATraining Step: 203  | total loss: [1m[32m0.69332[0m[0m | time: 18.948s
[2K
| RMSProp | epoch: 010 | loss: 0.69332 - acc: 0.5482 -- iter: 448/653
[A[ATraining Step: 204  | total loss: [1m[32m0.69483[0m[0m | time: 20.268s
[2K
| RMSProp | epoch: 010 | loss: 0.69483 - acc: 0.5340 -- iter: 480/653
[A[ATraining Step: 205  | total loss: [1m[32m0.69477[0m[0m | time: 21.690s
[2K
| RMSProp | epoch: 010 | loss: 0.69477 - acc: 0.5306 -- iter: 512/653
[A[ATraining Step: 206  | total loss: [1m[32m0.69472[0m[0m | time: 23.123s
[2K
| RMSProp | epoch: 010 | loss: 0.69472 - acc: 0.5276 -- iter: 544/653
[A[ATraining Step: 207  | total loss: [1m[32m0.69440[0m[0m | time: 24.176s
[2K
| RMSProp | epoch: 010 | loss: 0.69440 - acc: 0.5279 -- iter: 576/653
[A[ATraining Step: 208  | total loss: [1m[32m0.69458[0m[0m | time: 25.622s
[2K
| RMSProp | epoch: 010 | loss: 0.69458 - acc: 0.5220 -- iter: 608/653
[A[ATraining Step: 209  | total loss: [1m[32m0.69449[0m[0m | time: 27.109s
[2K
| RMSProp | epoch: 010 | loss: 0.69449 - acc: 0.5198 -- iter: 640/653
[A[ATraining Step: 210  | total loss: [1m[32m0.69422[0m[0m | time: 35.219s
[2K
| RMSProp | epoch: 010 | loss: 0.69422 - acc: 0.5209 | val_loss: 0.69339 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 211  | total loss: [1m[32m0.69353[0m[0m | time: 1.110s
[2K
| RMSProp | epoch: 011 | loss: 0.69353 - acc: 0.5282 -- iter: 032/653
[A[ATraining Step: 212  | total loss: [1m[32m0.69465[0m[0m | time: 2.454s
[2K
| RMSProp | epoch: 011 | loss: 0.69465 - acc: 0.5129 -- iter: 064/653
[A[ATraining Step: 213  | total loss: [1m[32m0.69476[0m[0m | time: 3.771s
[2K
| RMSProp | epoch: 011 | loss: 0.69476 - acc: 0.5085 -- iter: 096/653
[A[ATraining Step: 214  | total loss: [1m[32m0.69460[0m[0m | time: 5.261s
[2K
| RMSProp | epoch: 011 | loss: 0.69460 - acc: 0.5076 -- iter: 128/653
[A[ATraining Step: 215  | total loss: [1m[32m0.69462[0m[0m | time: 6.352s
[2K
| RMSProp | epoch: 011 | loss: 0.69462 - acc: 0.5038 -- iter: 160/653
[A[ATraining Step: 216  | total loss: [1m[32m0.69397[0m[0m | time: 7.423s
[2K
| RMSProp | epoch: 011 | loss: 0.69397 - acc: 0.5159 -- iter: 192/653
[A[ATraining Step: 217  | total loss: [1m[32m0.69391[0m[0m | time: 8.456s
[2K
| RMSProp | epoch: 011 | loss: 0.69391 - acc: 0.5143 -- iter: 224/653
[A[ATraining Step: 218  | total loss: [1m[32m0.69453[0m[0m | time: 9.563s
[2K
| RMSProp | epoch: 011 | loss: 0.69453 - acc: 0.5004 -- iter: 256/653
[A[ATraining Step: 219  | total loss: [1m[32m0.69441[0m[0m | time: 10.069s
[2K
| RMSProp | epoch: 011 | loss: 0.69441 - acc: 0.5003 -- iter: 288/653
[A[ATraining Step: 220  | total loss: [1m[32m0.69387[0m[0m | time: 10.616s
[2K
| RMSProp | epoch: 011 | loss: 0.69387 - acc: 0.5118 -- iter: 320/653
[A[ATraining Step: 221  | total loss: [1m[32m0.69323[0m[0m | time: 11.713s
[2K
| RMSProp | epoch: 011 | loss: 0.69323 - acc: 0.5222 -- iter: 352/653
[A[ATraining Step: 222  | total loss: [1m[32m0.69268[0m[0m | time: 12.744s
[2K
| RMSProp | epoch: 011 | loss: 0.69268 - acc: 0.5293 -- iter: 384/653
[A[ATraining Step: 223  | total loss: [1m[32m0.69362[0m[0m | time: 13.982s
[2K
| RMSProp | epoch: 011 | loss: 0.69362 - acc: 0.5170 -- iter: 416/653
[A[ATraining Step: 224  | total loss: [1m[32m0.69325[0m[0m | time: 15.254s
[2K
| RMSProp | epoch: 011 | loss: 0.69325 - acc: 0.5216 -- iter: 448/653
[A[ATraining Step: 225  | total loss: [1m[32m0.69164[0m[0m | time: 16.777s
[2K
| RMSProp | epoch: 011 | loss: 0.69164 - acc: 0.5444 -- iter: 480/653
[A[ATraining Step: 226  | total loss: [1m[32m0.69349[0m[0m | time: 18.597s
[2K
| RMSProp | epoch: 011 | loss: 0.69349 - acc: 0.5244 -- iter: 512/653
[A[ATraining Step: 227  | total loss: [1m[32m0.69243[0m[0m | time: 23.589s
[2K
| RMSProp | epoch: 011 | loss: 0.69243 - acc: 0.5375 -- iter: 544/653
[A[ATraining Step: 228  | total loss: [1m[32m0.69155[0m[0m | time: 51.041s
[2K
| RMSProp | epoch: 011 | loss: 0.69155 - acc: 0.5463 -- iter: 576/653
[A[ATraining Step: 229  | total loss: [1m[32m0.69209[0m[0m | time: 52.089s
[2K
| RMSProp | epoch: 011 | loss: 0.69209 - acc: 0.5385 -- iter: 608/653
[A[ATraining Step: 230  | total loss: [1m[32m0.69119[0m[0m | time: 53.242s
[2K
| RMSProp | epoch: 011 | loss: 0.69119 - acc: 0.5472 -- iter: 640/653
[A[ATraining Step: 231  | total loss: [1m[32m0.69116[0m[0m | time: 56.018s
[2K
| RMSProp | epoch: 011 | loss: 0.69116 - acc: 0.5456 | val_loss: 0.69400 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 232  | total loss: [1m[32m0.69078[0m[0m | time: 1.331s
[2K
| RMSProp | epoch: 012 | loss: 0.69078 - acc: 0.5473 -- iter: 032/653
[A[ATraining Step: 233  | total loss: [1m[32m0.68965[0m[0m | time: 2.629s
[2K
| RMSProp | epoch: 012 | loss: 0.68965 - acc: 0.5551 -- iter: 064/653
[A[ATraining Step: 234  | total loss: [1m[32m0.69155[0m[0m | time: 3.834s
[2K
| RMSProp | epoch: 012 | loss: 0.69155 - acc: 0.5433 -- iter: 096/653
[A[ATraining Step: 235  | total loss: [1m[32m0.69114[0m[0m | time: 5.196s
[2K
| RMSProp | epoch: 012 | loss: 0.69114 - acc: 0.5452 -- iter: 128/653
[A[ATraining Step: 236  | total loss: [1m[32m0.69115[0m[0m | time: 6.493s
[2K
| RMSProp | epoch: 012 | loss: 0.69115 - acc: 0.5438 -- iter: 160/653
[A[ATraining Step: 237  | total loss: [1m[32m0.69252[0m[0m | time: 23.751s
[2K
| RMSProp | epoch: 012 | loss: 0.69252 - acc: 0.5301 -- iter: 192/653
[A[ATraining Step: 238  | total loss: [1m[32m0.69163[0m[0m | time: 80.187s
[2K
| RMSProp | epoch: 012 | loss: 0.69163 - acc: 0.5396 -- iter: 224/653
[A[ATraining Step: 239  | total loss: [1m[32m0.69252[0m[0m | time: 82.110s
[2K
| RMSProp | epoch: 012 | loss: 0.69252 - acc: 0.5294 -- iter: 256/653
[A[ATraining Step: 240  | total loss: [1m[32m0.69187[0m[0m | time: 83.850s
[2K
| RMSProp | epoch: 012 | loss: 0.69187 - acc: 0.5358 -- iter: 288/653
[A[ATraining Step: 241  | total loss: [1m[32m0.69208[0m[0m | time: 84.589s
[2K
| RMSProp | epoch: 012 | loss: 0.69208 - acc: 0.5322 -- iter: 320/653
[A[ATraining Step: 242  | total loss: [1m[32m0.69196[0m[0m | time: 85.694s
[2K
| RMSProp | epoch: 012 | loss: 0.69196 - acc: 0.5328 -- iter: 352/653
[A[ATraining Step: 243  | total loss: [1m[32m0.69187[0m[0m | time: 87.105s
[2K
| RMSProp | epoch: 012 | loss: 0.69187 - acc: 0.5334 -- iter: 384/653
[A[ATraining Step: 244  | total loss: [1m[32m0.69204[0m[0m | time: 88.427s
[2K
| RMSProp | epoch: 012 | loss: 0.69204 - acc: 0.5301 -- iter: 416/653
[A[ATraining Step: 245  | total loss: [1m[32m0.69190[0m[0m | time: 89.850s
[2K
| RMSProp | epoch: 012 | loss: 0.69190 - acc: 0.5302 -- iter: 448/653
[A[ATraining Step: 246  | total loss: [1m[32m0.69187[0m[0m | time: 91.336s
[2K
| RMSProp | epoch: 012 | loss: 0.69187 - acc: 0.5303 -- iter: 480/653
[A[ATraining Step: 247  | total loss: [1m[32m0.69119[0m[0m | time: 92.947s
[2K
| RMSProp | epoch: 012 | loss: 0.69119 - acc: 0.5366 -- iter: 512/653
[A[ATraining Step: 248  | total loss: [1m[32m0.69258[0m[0m | time: 94.334s
[2K
| RMSProp | epoch: 012 | loss: 0.69258 - acc: 0.5236 -- iter: 544/653
[A[ATraining Step: 249  | total loss: [1m[32m0.69318[0m[0m | time: 95.958s
[2K
| RMSProp | epoch: 012 | loss: 0.69318 - acc: 0.5150 -- iter: 576/653
[A[ATraining Step: 250  | total loss: [1m[32m0.69341[0m[0m | time: 97.445s
[2K
| RMSProp | epoch: 012 | loss: 0.69341 - acc: 0.5104 -- iter: 608/653
[A[ATraining Step: 251  | total loss: [1m[32m0.69241[0m[0m | time: 99.183s
[2K
| RMSProp | epoch: 012 | loss: 0.69241 - acc: 0.5249 -- iter: 640/653
[A[ATraining Step: 252  | total loss: [1m[32m0.69178[0m[0m | time: 102.729s
[2K
| RMSProp | epoch: 012 | loss: 0.69178 - acc: 0.5318 | val_loss: 0.69357 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 253  | total loss: [1m[32m0.69171[0m[0m | time: 1.600s
[2K
| RMSProp | epoch: 013 | loss: 0.69171 - acc: 0.5318 -- iter: 032/653
[A[ATraining Step: 254  | total loss: [1m[32m0.69123[0m[0m | time: 4.875s
[2K
| RMSProp | epoch: 013 | loss: 0.69123 - acc: 0.5348 -- iter: 064/653
[A[ATraining Step: 255  | total loss: [1m[32m0.69036[0m[0m | time: 12.374s
[2K
| RMSProp | epoch: 013 | loss: 0.69036 - acc: 0.5407 -- iter: 096/653
[A[ATraining Step: 256  | total loss: [1m[32m0.69246[0m[0m | time: 13.775s
[2K
| RMSProp | epoch: 013 | loss: 0.69246 - acc: 0.5304 -- iter: 128/653
[A[ATraining Step: 257  | total loss: [1m[32m0.69320[0m[0m | time: 15.141s
[2K
| RMSProp | epoch: 013 | loss: 0.69320 - acc: 0.5211 -- iter: 160/653
[A[ATraining Step: 258  | total loss: [1m[32m0.69301[0m[0m | time: 16.618s
[2K
| RMSProp | epoch: 013 | loss: 0.69301 - acc: 0.5221 -- iter: 192/653
[A[ATraining Step: 259  | total loss: [1m[32m0.69308[0m[0m | time: 18.215s
[2K
| RMSProp | epoch: 013 | loss: 0.69308 - acc: 0.5199 -- iter: 224/653
[A[ATraining Step: 260  | total loss: [1m[32m0.69360[0m[0m | time: 19.662s
[2K
| RMSProp | epoch: 013 | loss: 0.69360 - acc: 0.5117 -- iter: 256/653
[A[ATraining Step: 261  | total loss: [1m[32m0.69341[0m[0m | time: 21.239s
[2K
| RMSProp | epoch: 013 | loss: 0.69341 - acc: 0.5136 -- iter: 288/653
[A[ATraining Step: 262  | total loss: [1m[32m0.69231[0m[0m | time: 22.669s
[2K
| RMSProp | epoch: 013 | loss: 0.69231 - acc: 0.5310 -- iter: 320/653
[A[ATraining Step: 263  | total loss: [1m[32m0.69306[0m[0m | time: 23.362s
[2K
| RMSProp | epoch: 013 | loss: 0.69306 - acc: 0.5217 -- iter: 352/653
[A[ATraining Step: 264  | total loss: [1m[32m0.69229[0m[0m | time: 24.159s
[2K
| RMSProp | epoch: 013 | loss: 0.69229 - acc: 0.5310 -- iter: 384/653
[A[ATraining Step: 265  | total loss: [1m[32m0.69152[0m[0m | time: 25.731s
[2K
| RMSProp | epoch: 013 | loss: 0.69152 - acc: 0.5395 -- iter: 416/653
[A[ATraining Step: 266  | total loss: [1m[32m0.69178[0m[0m | time: 26.993s
[2K
| RMSProp | epoch: 013 | loss: 0.69178 - acc: 0.5355 -- iter: 448/653
[A[ATraining Step: 267  | total loss: [1m[32m0.69144[0m[0m | time: 28.325s
[2K
| RMSProp | epoch: 013 | loss: 0.69144 - acc: 0.5382 -- iter: 480/653
[A[ATraining Step: 268  | total loss: [1m[32m0.69017[0m[0m | time: 29.546s
[2K
| RMSProp | epoch: 013 | loss: 0.69017 - acc: 0.5500 -- iter: 512/653
[A[ATraining Step: 269  | total loss: [1m[32m0.68942[0m[0m | time: 30.525s
[2K
| RMSProp | epoch: 013 | loss: 0.68942 - acc: 0.5544 -- iter: 544/653
[A[ATraining Step: 270  | total loss: [1m[32m0.69313[0m[0m | time: 31.645s
[2K
| RMSProp | epoch: 013 | loss: 0.69313 - acc: 0.5365 -- iter: 576/653
[A[ATraining Step: 271  | total loss: [1m[32m0.69291[0m[0m | time: 32.824s
[2K
| RMSProp | epoch: 013 | loss: 0.69291 - acc: 0.5359 -- iter: 608/653
[A[ATraining Step: 272  | total loss: [1m[32m0.69239[0m[0m | time: 33.945s
[2K
| RMSProp | epoch: 013 | loss: 0.69239 - acc: 0.5386 -- iter: 640/653
[A[ATraining Step: 273  | total loss: [1m[32m0.69259[0m[0m | time: 36.720s
[2K
| RMSProp | epoch: 013 | loss: 0.69259 - acc: 0.5347 | val_loss: 0.69359 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 274  | total loss: [1m[32m0.69278[0m[0m | time: 1.120s
[2K
| RMSProp | epoch: 014 | loss: 0.69278 - acc: 0.5313 -- iter: 032/653
[A[ATraining Step: 275  | total loss: [1m[32m0.69163[0m[0m | time: 2.426s
[2K
| RMSProp | epoch: 014 | loss: 0.69163 - acc: 0.5406 -- iter: 064/653
[A[ATraining Step: 276  | total loss: [1m[32m0.69196[0m[0m | time: 3.674s
[2K
| RMSProp | epoch: 014 | loss: 0.69196 - acc: 0.5366 -- iter: 096/653
[A[ATraining Step: 277  | total loss: [1m[32m0.69112[0m[0m | time: 4.971s
[2K
| RMSProp | epoch: 014 | loss: 0.69112 - acc: 0.5423 -- iter: 128/653
[A[ATraining Step: 278  | total loss: [1m[32m0.69035[0m[0m | time: 5.985s
[2K
| RMSProp | epoch: 014 | loss: 0.69035 - acc: 0.5474 -- iter: 160/653
[A[ATraining Step: 279  | total loss: [1m[32m0.68838[0m[0m | time: 7.259s
[2K
| RMSProp | epoch: 014 | loss: 0.68838 - acc: 0.5583 -- iter: 192/653
[A[ATraining Step: 280  | total loss: [1m[32m0.68876[0m[0m | time: 8.386s
[2K
| RMSProp | epoch: 014 | loss: 0.68876 - acc: 0.5556 -- iter: 224/653
[A[ATraining Step: 281  | total loss: [1m[32m0.69152[0m[0m | time: 9.484s
[2K
| RMSProp | epoch: 014 | loss: 0.69152 - acc: 0.5407 -- iter: 256/653
[A[ATraining Step: 282  | total loss: [1m[32m0.69216[0m[0m | time: 10.528s
[2K
| RMSProp | epoch: 014 | loss: 0.69216 - acc: 0.5335 -- iter: 288/653
[A[ATraining Step: 283  | total loss: [1m[32m0.69273[0m[0m | time: 11.759s
[2K
| RMSProp | epoch: 014 | loss: 0.69273 - acc: 0.5270 -- iter: 320/653
[A[ATraining Step: 284  | total loss: [1m[32m0.69229[0m[0m | time: 12.843s
[2K
| RMSProp | epoch: 014 | loss: 0.69229 - acc: 0.5306 -- iter: 352/653
[A[ATraining Step: 285  | total loss: [1m[32m0.69151[0m[0m | time: 13.437s
[2K
| RMSProp | epoch: 014 | loss: 0.69151 - acc: 0.5369 -- iter: 384/653
[A[ATraining Step: 286  | total loss: [1m[32m0.69320[0m[0m | time: 13.893s
[2K
| RMSProp | epoch: 014 | loss: 0.69320 - acc: 0.5217 -- iter: 416/653
[A[ATraining Step: 287  | total loss: [1m[32m0.69427[0m[0m | time: 15.087s
[2K
| RMSProp | epoch: 014 | loss: 0.69427 - acc: 0.5079 -- iter: 448/653
[A[ATraining Step: 288  | total loss: [1m[32m0.69467[0m[0m | time: 16.365s
[2K
| RMSProp | epoch: 014 | loss: 0.69467 - acc: 0.5009 -- iter: 480/653
[A[ATraining Step: 289  | total loss: [1m[32m0.69341[0m[0m | time: 17.704s
[2K
| RMSProp | epoch: 014 | loss: 0.69341 - acc: 0.5164 -- iter: 512/653
[A[ATraining Step: 290  | total loss: [1m[32m0.69313[0m[0m | time: 18.812s
[2K
| RMSProp | epoch: 014 | loss: 0.69313 - acc: 0.5179 -- iter: 544/653
[A[ATraining Step: 291  | total loss: [1m[32m0.69255[0m[0m | time: 19.856s
[2K
| RMSProp | epoch: 014 | loss: 0.69255 - acc: 0.5224 -- iter: 576/653
[A[ATraining Step: 292  | total loss: [1m[32m0.69201[0m[0m | time: 20.905s
[2K
| RMSProp | epoch: 014 | loss: 0.69201 - acc: 0.5264 -- iter: 608/653
[A[ATraining Step: 293  | total loss: [1m[32m0.69219[0m[0m | time: 21.985s
[2K
| RMSProp | epoch: 014 | loss: 0.69219 - acc: 0.5238 -- iter: 640/653
[A[ATraining Step: 294  | total loss: [1m[32m0.69405[0m[0m | time: 24.496s
[2K
| RMSProp | epoch: 014 | loss: 0.69405 - acc: 0.5058 | val_loss: 0.69299 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 295  | total loss: [1m[32m0.69442[0m[0m | time: 1.760s
[2K
| RMSProp | epoch: 015 | loss: 0.69442 - acc: 0.4989 -- iter: 032/653
[A[ATraining Step: 296  | total loss: [1m[32m0.69337[0m[0m | time: 3.273s
[2K
| RMSProp | epoch: 015 | loss: 0.69337 - acc: 0.5147 -- iter: 064/653
[A[ATraining Step: 297  | total loss: [1m[32m0.69313[0m[0m | time: 4.671s
[2K
| RMSProp | epoch: 015 | loss: 0.69313 - acc: 0.5163 -- iter: 096/653
[A[ATraining Step: 298  | total loss: [1m[32m0.69265[0m[0m | time: 6.312s
[2K
| RMSProp | epoch: 015 | loss: 0.69265 - acc: 0.5209 -- iter: 128/653
[A[ATraining Step: 299  | total loss: [1m[32m0.69220[0m[0m | time: 7.903s
[2K
| RMSProp | epoch: 015 | loss: 0.69220 - acc: 0.5251 -- iter: 160/653
[A[ATraining Step: 300  | total loss: [1m[32m0.69171[0m[0m | time: 9.547s
[2K
| RMSProp | epoch: 015 | loss: 0.69171 - acc: 0.5288 -- iter: 192/653
[A[ATraining Step: 301  | total loss: [1m[32m0.69399[0m[0m | time: 11.041s
[2K
| RMSProp | epoch: 015 | loss: 0.69399 - acc: 0.5072 -- iter: 224/653
[A[ATraining Step: 302  | total loss: [1m[32m0.69394[0m[0m | time: 12.257s
[2K
| RMSProp | epoch: 015 | loss: 0.69394 - acc: 0.5065 -- iter: 256/653
[A[ATraining Step: 303  | total loss: [1m[32m0.69418[0m[0m | time: 13.532s
[2K
| RMSProp | epoch: 015 | loss: 0.69418 - acc: 0.5027 -- iter: 288/653
[A[ATraining Step: 304  | total loss: [1m[32m0.69279[0m[0m | time: 14.637s
[2K
| RMSProp | epoch: 015 | loss: 0.69279 - acc: 0.5243 -- iter: 320/653
[A[ATraining Step: 305  | total loss: [1m[32m0.69184[0m[0m | time: 15.639s
[2K
| RMSProp | epoch: 015 | loss: 0.69184 - acc: 0.5344 -- iter: 352/653
[A[ATraining Step: 306  | total loss: [1m[32m0.69204[0m[0m | time: 16.729s
[2K
| RMSProp | epoch: 015 | loss: 0.69204 - acc: 0.5309 -- iter: 384/653
[A[ATraining Step: 307  | total loss: [1m[32m0.69330[0m[0m | time: 17.260s
[2K
| RMSProp | epoch: 015 | loss: 0.69330 - acc: 0.5153 -- iter: 416/653
[A[ATraining Step: 308  | total loss: [1m[32m0.69470[0m[0m | time: 17.789s
[2K
| RMSProp | epoch: 015 | loss: 0.69470 - acc: 0.4946 -- iter: 448/653
[A[ATraining Step: 309  | total loss: [1m[32m0.69569[0m[0m | time: 18.934s
[2K
| RMSProp | epoch: 015 | loss: 0.69569 - acc: 0.4759 -- iter: 480/653
[A[ATraining Step: 310  | total loss: [1m[32m0.69485[0m[0m | time: 20.075s
[2K
| RMSProp | epoch: 015 | loss: 0.69485 - acc: 0.4908 -- iter: 512/653
[A[ATraining Step: 311  | total loss: [1m[32m0.69505[0m[0m | time: 21.365s
[2K
| RMSProp | epoch: 015 | loss: 0.69505 - acc: 0.4855 -- iter: 544/653
[A[ATraining Step: 312  | total loss: [1m[32m0.69458[0m[0m | time: 22.601s
[2K
| RMSProp | epoch: 015 | loss: 0.69458 - acc: 0.4901 -- iter: 576/653
[A[ATraining Step: 313  | total loss: [1m[32m0.69275[0m[0m | time: 23.534s
[2K
| RMSProp | epoch: 015 | loss: 0.69275 - acc: 0.5129 -- iter: 608/653
[A[ATraining Step: 314  | total loss: [1m[32m0.69343[0m[0m | time: 24.498s
[2K
| RMSProp | epoch: 015 | loss: 0.69343 - acc: 0.5054 -- iter: 640/653
[A[ATraining Step: 315  | total loss: [1m[32m0.69262[0m[0m | time: 26.906s
[2K
| RMSProp | epoch: 015 | loss: 0.69262 - acc: 0.5111 | val_loss: 0.69126 - val_acc: 0.5073 -- iter: 653/653
--
Training Step: 316  | total loss: [1m[32m0.69379[0m[0m | time: 1.037s
[2K
| RMSProp | epoch: 016 | loss: 0.69379 - acc: 0.5006 -- iter: 032/653
[A[ATraining Step: 317  | total loss: [1m[32m0.69264[0m[0m | time: 2.276s
[2K
| RMSProp | epoch: 016 | loss: 0.69264 - acc: 0.5162 -- iter: 064/653
[A[ATraining Step: 318  | total loss: [1m[32m0.69264[0m[0m | time: 3.616s
[2K
| RMSProp | epoch: 016 | loss: 0.69264 - acc: 0.5114 -- iter: 096/653
[A[ATraining Step: 319  | total loss: [1m[32m0.69175[0m[0m | time: 4.724s
[2K
| RMSProp | epoch: 016 | loss: 0.69175 - acc: 0.5197 -- iter: 128/653
[A[ATraining Step: 320  | total loss: [1m[32m0.69184[0m[0m | time: 6.012s
[2K
| RMSProp | epoch: 016 | loss: 0.69184 - acc: 0.5177 -- iter: 160/653
[A[ATraining Step: 321  | total loss: [1m[32m0.69154[0m[0m | time: 7.295s
[2K
| RMSProp | epoch: 016 | loss: 0.69154 - acc: 0.5191 -- iter: 192/653
[A[ATraining Step: 322  | total loss: [1m[32m0.69151[0m[0m | time: 8.339s
[2K
| RMSProp | epoch: 016 | loss: 0.69151 - acc: 0.5203 -- iter: 224/653
[A[ATraining Step: 323  | total loss: [1m[32m0.69110[0m[0m | time: 9.414s
[2K
| RMSProp | epoch: 016 | loss: 0.69110 - acc: 0.5214 -- iter: 256/653
[A[ATraining Step: 324  | total loss: [1m[32m0.69020[0m[0m | time: 10.510s
[2K
| RMSProp | epoch: 016 | loss: 0.69020 - acc: 0.5224 -- iter: 288/653
[A[ATraining Step: 325  | total loss: [1m[32m0.69005[0m[0m | time: 11.502s
[2K
| RMSProp | epoch: 016 | loss: 0.69005 - acc: 0.5170 -- iter: 320/653
[A[ATraining Step: 326  | total loss: [1m[32m0.68959[0m[0m | time: 12.659s
[2K
| RMSProp | epoch: 016 | loss: 0.68959 - acc: 0.5184 -- iter: 352/653
[A[ATraining Step: 327  | total loss: [1m[32m0.68413[0m[0m | time: 13.699s
[2K
| RMSProp | epoch: 016 | loss: 0.68413 - acc: 0.5353 -- iter: 384/653
[A[ATraining Step: 328  | total loss: [1m[32m0.68093[0m[0m | time: 14.945s
[2K
| RMSProp | epoch: 016 | loss: 0.68093 - acc: 0.5412 -- iter: 416/653
[A[ATraining Step: 329  | total loss: [1m[32m0.68029[0m[0m | time: 15.491s
[2K
| RMSProp | epoch: 016 | loss: 0.68029 - acc: 0.5433 -- iter: 448/653
[A[ATraining Step: 330  | total loss: [1m[32m0.67765[0m[0m | time: 16.063s
[2K
| RMSProp | epoch: 016 | loss: 0.67765 - acc: 0.5505 -- iter: 480/653
[A[ATraining Step: 331  | total loss: [1m[32m0.67373[0m[0m | time: 17.136s
[2K
| RMSProp | epoch: 016 | loss: 0.67373 - acc: 0.5570 -- iter: 512/653
[A[ATraining Step: 332  | total loss: [1m[32m0.68128[0m[0m | time: 18.479s
[2K
| RMSProp | epoch: 016 | loss: 0.68128 - acc: 0.5419 -- iter: 544/653
[A[ATraining Step: 333  | total loss: [1m[32m0.68204[0m[0m | time: 19.679s
[2K
| RMSProp | epoch: 016 | loss: 0.68204 - acc: 0.5315 -- iter: 576/653
[A[ATraining Step: 334  | total loss: [1m[32m0.67956[0m[0m | time: 20.795s
[2K
| RMSProp | epoch: 016 | loss: 0.67956 - acc: 0.5471 -- iter: 608/653
[A[ATraining Step: 335  | total loss: [1m[32m0.67466[0m[0m | time: 21.741s
[2K
| RMSProp | epoch: 016 | loss: 0.67466 - acc: 0.5580 -- iter: 640/653
[A[ATraining Step: 336  | total loss: [1m[32m0.67297[0m[0m | time: 24.422s
[2K
| RMSProp | epoch: 016 | loss: 0.67297 - acc: 0.5553 | val_loss: 0.66942 - val_acc: 0.5463 -- iter: 653/653
--
Training Step: 337  | total loss: [1m[32m0.67310[0m[0m | time: 1.067s
[2K
| RMSProp | epoch: 017 | loss: 0.67310 - acc: 0.5498 -- iter: 032/653
[A[ATraining Step: 338  | total loss: [1m[32m0.67390[0m[0m | time: 2.317s
[2K
| RMSProp | epoch: 017 | loss: 0.67390 - acc: 0.5511 -- iter: 064/653
[A[ATraining Step: 339  | total loss: [1m[32m0.67103[0m[0m | time: 3.505s
[2K
| RMSProp | epoch: 017 | loss: 0.67103 - acc: 0.5710 -- iter: 096/653
[A[ATraining Step: 340  | total loss: [1m[32m0.67741[0m[0m | time: 4.620s
[2K
| RMSProp | epoch: 017 | loss: 0.67741 - acc: 0.5545 -- iter: 128/653
[A[ATraining Step: 341  | total loss: [1m[32m0.67713[0m[0m | time: 5.860s
[2K
| RMSProp | epoch: 017 | loss: 0.67713 - acc: 0.5678 -- iter: 160/653
[A[ATraining Step: 342  | total loss: [1m[32m0.67597[0m[0m | time: 7.124s
[2K
| RMSProp | epoch: 017 | loss: 0.67597 - acc: 0.5798 -- iter: 192/653
[A[ATraining Step: 343  | total loss: [1m[32m0.67188[0m[0m | time: 8.160s
[2K
| RMSProp | epoch: 017 | loss: 0.67188 - acc: 0.5874 -- iter: 224/653
[A[ATraining Step: 344  | total loss: [1m[32m0.67126[0m[0m | time: 9.272s
[2K
| RMSProp | epoch: 017 | loss: 0.67126 - acc: 0.5912 -- iter: 256/653
[A[ATraining Step: 345  | total loss: [1m[32m0.66667[0m[0m | time: 10.340s
[2K
| RMSProp | epoch: 017 | loss: 0.66667 - acc: 0.5946 -- iter: 288/653
[A[ATraining Step: 346  | total loss: [1m[32m0.66913[0m[0m | time: 11.382s
[2K
| RMSProp | epoch: 017 | loss: 0.66913 - acc: 0.5851 -- iter: 320/653
[A[ATraining Step: 347  | total loss: [1m[32m0.66984[0m[0m | time: 12.578s
[2K
| RMSProp | epoch: 017 | loss: 0.66984 - acc: 0.5797 -- iter: 352/653
[A[ATraining Step: 348  | total loss: [1m[32m0.66506[0m[0m | time: 13.566s
[2K
| RMSProp | epoch: 017 | loss: 0.66506 - acc: 0.5905 -- iter: 384/653
[A[ATraining Step: 349  | total loss: [1m[32m0.66926[0m[0m | time: 14.730s
[2K
| RMSProp | epoch: 017 | loss: 0.66926 - acc: 0.5814 -- iter: 416/653
[A[ATraining Step: 350  | total loss: [1m[32m0.67116[0m[0m | time: 15.862s
[2K
| RMSProp | epoch: 017 | loss: 0.67116 - acc: 0.5827 -- iter: 448/653
[A[ATraining Step: 351  | total loss: [1m[32m0.66653[0m[0m | time: 16.375s
[2K
| RMSProp | epoch: 017 | loss: 0.66653 - acc: 0.5994 -- iter: 480/653
[A[ATraining Step: 352  | total loss: [1m[32m0.66917[0m[0m | time: 16.959s
[2K
| RMSProp | epoch: 017 | loss: 0.66917 - acc: 0.6010 -- iter: 512/653
[A[ATraining Step: 353  | total loss: [1m[32m0.66299[0m[0m | time: 18.344s
[2K
| RMSProp | epoch: 017 | loss: 0.66299 - acc: 0.6332 -- iter: 544/653
[A[ATraining Step: 354  | total loss: [1m[32m0.66209[0m[0m | time: 19.598s
[2K
| RMSProp | epoch: 017 | loss: 0.66209 - acc: 0.6355 -- iter: 576/653
[A[ATraining Step: 355  | total loss: [1m[32m0.65010[0m[0m | time: 20.548s
[2K
| RMSProp | epoch: 017 | loss: 0.65010 - acc: 0.6563 -- iter: 608/653
[A[ATraining Step: 356  | total loss: [1m[32m0.64472[0m[0m | time: 21.584s
[2K
| RMSProp | epoch: 017 | loss: 0.64472 - acc: 0.6563 -- iter: 640/653
[A[ATraining Step: 357  | total loss: [1m[32m0.64119[0m[0m | time: 24.125s
[2K
| RMSProp | epoch: 017 | loss: 0.64119 - acc: 0.6626 | val_loss: 0.65696 - val_acc: 0.5805 -- iter: 653/653
--
Training Step: 358  | total loss: [1m[32m0.65502[0m[0m | time: 1.078s
[2K
| RMSProp | epoch: 018 | loss: 0.65502 - acc: 0.6463 -- iter: 032/653
[A[ATraining Step: 359  | total loss: [1m[32m0.64237[0m[0m | time: 2.279s
[2K
| RMSProp | epoch: 018 | loss: 0.64237 - acc: 0.6661 -- iter: 064/653
[A[ATraining Step: 360  | total loss: [1m[32m0.64728[0m[0m | time: 3.309s
[2K
| RMSProp | epoch: 018 | loss: 0.64728 - acc: 0.6432 -- iter: 096/653
[A[ATraining Step: 361  | total loss: [1m[32m0.64122[0m[0m | time: 4.469s
[2K
| RMSProp | epoch: 018 | loss: 0.64122 - acc: 0.6476 -- iter: 128/653
[A[ATraining Step: 362  | total loss: [1m[32m0.64047[0m[0m | time: 5.779s
[2K
| RMSProp | epoch: 018 | loss: 0.64047 - acc: 0.6485 -- iter: 160/653
[A[ATraining Step: 363  | total loss: [1m[32m0.63635[0m[0m | time: 7.139s
[2K
| RMSProp | epoch: 018 | loss: 0.63635 - acc: 0.6555 -- iter: 192/653
[A[ATraining Step: 364  | total loss: [1m[32m0.64028[0m[0m | time: 8.162s
[2K
| RMSProp | epoch: 018 | loss: 0.64028 - acc: 0.6493 -- iter: 224/653
[A[ATraining Step: 365  | total loss: [1m[32m0.63704[0m[0m | time: 9.345s
[2K
| RMSProp | epoch: 018 | loss: 0.63704 - acc: 0.6563 -- iter: 256/653
[A[ATraining Step: 366  | total loss: [1m[32m0.61836[0m[0m | time: 10.500s
[2K
| RMSProp | epoch: 018 | loss: 0.61836 - acc: 0.6688 -- iter: 288/653
[A[ATraining Step: 367  | total loss: [1m[32m0.62029[0m[0m | time: 11.488s
[2K
| RMSProp | epoch: 018 | loss: 0.62029 - acc: 0.6707 -- iter: 320/653
[A[ATraining Step: 368  | total loss: [1m[32m0.62497[0m[0m | time: 12.592s
[2K
| RMSProp | epoch: 018 | loss: 0.62497 - acc: 0.6661 -- iter: 352/653
[A[ATraining Step: 369  | total loss: [1m[32m0.62022[0m[0m | time: 13.935s
[2K
| RMSProp | epoch: 018 | loss: 0.62022 - acc: 0.6682 -- iter: 384/653
[A[ATraining Step: 370  | total loss: [1m[32m0.61882[0m[0m | time: 15.092s
[2K
| RMSProp | epoch: 018 | loss: 0.61882 - acc: 0.6702 -- iter: 416/653
[A[ATraining Step: 371  | total loss: [1m[32m0.62103[0m[0m | time: 16.148s
[2K
| RMSProp | epoch: 018 | loss: 0.62103 - acc: 0.6656 -- iter: 448/653
[A[ATraining Step: 372  | total loss: [1m[32m0.61821[0m[0m | time: 17.406s
[2K
| RMSProp | epoch: 018 | loss: 0.61821 - acc: 0.6710 -- iter: 480/653
[A[ATraining Step: 373  | total loss: [1m[32m0.62157[0m[0m | time: 18.063s
[2K
| RMSProp | epoch: 018 | loss: 0.62157 - acc: 0.6632 -- iter: 512/653
[A[ATraining Step: 374  | total loss: [1m[32m0.61864[0m[0m | time: 18.586s
[2K
| RMSProp | epoch: 018 | loss: 0.61864 - acc: 0.6661 -- iter: 544/653
[A[ATraining Step: 375  | total loss: [1m[32m0.59418[0m[0m | time: 19.943s
[2K
| RMSProp | epoch: 018 | loss: 0.59418 - acc: 0.6918 -- iter: 576/653
[A[ATraining Step: 376  | total loss: [1m[32m0.59156[0m[0m | time: 21.010s
[2K
| RMSProp | epoch: 018 | loss: 0.59156 - acc: 0.6914 -- iter: 608/653
[A[ATraining Step: 377  | total loss: [1m[32m0.59656[0m[0m | time: 22.120s
[2K
| RMSProp | epoch: 018 | loss: 0.59656 - acc: 0.6816 -- iter: 640/653
[A[ATraining Step: 378  | total loss: [1m[32m0.59336[0m[0m | time: 24.489s
[2K
| RMSProp | epoch: 018 | loss: 0.59336 - acc: 0.6916 | val_loss: 0.66268 - val_acc: 0.6439 -- iter: 653/653
--
Training Step: 379  | total loss: [1m[32m0.58673[0m[0m | time: 1.106s
[2K
| RMSProp | epoch: 019 | loss: 0.58673 - acc: 0.7068 -- iter: 032/653
[A[ATraining Step: 380  | total loss: [1m[32m0.60074[0m[0m | time: 2.375s
[2K
| RMSProp | epoch: 019 | loss: 0.60074 - acc: 0.6924 -- iter: 064/653
[A[ATraining Step: 381  | total loss: [1m[32m0.60051[0m[0m | time: 3.450s
[2K
| RMSProp | epoch: 019 | loss: 0.60051 - acc: 0.6919 -- iter: 096/653
[A[ATraining Step: 382  | total loss: [1m[32m0.60072[0m[0m | time: 4.843s
[2K
| RMSProp | epoch: 019 | loss: 0.60072 - acc: 0.6883 -- iter: 128/653
[A[ATraining Step: 383  | total loss: [1m[32m0.59875[0m[0m | time: 6.165s
[2K
| RMSProp | epoch: 019 | loss: 0.59875 - acc: 0.6882 -- iter: 160/653
[A[ATraining Step: 384  | total loss: [1m[32m0.60213[0m[0m | time: 7.187s
[2K
| RMSProp | epoch: 019 | loss: 0.60213 - acc: 0.6913 -- iter: 192/653
[A[ATraining Step: 385  | total loss: [1m[32m0.59601[0m[0m | time: 8.269s
[2K
| RMSProp | epoch: 019 | loss: 0.59601 - acc: 0.7034 -- iter: 224/653
[A[ATraining Step: 386  | total loss: [1m[32m0.59120[0m[0m | time: 9.423s
[2K
| RMSProp | epoch: 019 | loss: 0.59120 - acc: 0.7018 -- iter: 256/653
[A[ATraining Step: 387  | total loss: [1m[32m0.58805[0m[0m | time: 10.627s
[2K
| RMSProp | epoch: 019 | loss: 0.58805 - acc: 0.7066 -- iter: 288/653
[A[ATraining Step: 388  | total loss: [1m[32m0.59148[0m[0m | time: 11.886s
[2K
| RMSProp | epoch: 019 | loss: 0.59148 - acc: 0.7079 -- iter: 320/653
[A[ATraining Step: 389  | total loss: [1m[32m0.58993[0m[0m | time: 13.049s
[2K
| RMSProp | epoch: 019 | loss: 0.58993 - acc: 0.7058 -- iter: 352/653
[A[ATraining Step: 390  | total loss: [1m[32m0.58571[0m[0m | time: 14.354s
[2K
| RMSProp | epoch: 019 | loss: 0.58571 - acc: 0.7071 -- iter: 384/653
[A[ATraining Step: 391  | total loss: [1m[32m0.59038[0m[0m | time: 15.348s
[2K
| RMSProp | epoch: 019 | loss: 0.59038 - acc: 0.7051 -- iter: 416/653
[A[ATraining Step: 392  | total loss: [1m[32m0.59433[0m[0m | time: 16.623s
[2K
| RMSProp | epoch: 019 | loss: 0.59433 - acc: 0.6971 -- iter: 448/653
[A[ATraining Step: 393  | total loss: [1m[32m0.58228[0m[0m | time: 17.965s
[2K
| RMSProp | epoch: 019 | loss: 0.58228 - acc: 0.7024 -- iter: 480/653
[A[ATraining Step: 394  | total loss: [1m[32m0.58173[0m[0m | time: 19.116s
[2K
| RMSProp | epoch: 019 | loss: 0.58173 - acc: 0.7041 -- iter: 512/653
[A[ATraining Step: 395  | total loss: [1m[32m0.56944[0m[0m | time: 19.537s
[2K
| RMSProp | epoch: 019 | loss: 0.56944 - acc: 0.7149 -- iter: 544/653
[A[ATraining Step: 396  | total loss: [1m[32m0.56219[0m[0m | time: 19.990s
[2K
| RMSProp | epoch: 019 | loss: 0.56219 - acc: 0.7203 -- iter: 576/653
[A[ATraining Step: 397  | total loss: [1m[32m0.54742[0m[0m | time: 21.121s
[2K
| RMSProp | epoch: 019 | loss: 0.54742 - acc: 0.7329 -- iter: 608/653
[A[ATraining Step: 398  | total loss: [1m[32m0.54298[0m[0m | time: 22.238s
[2K
| RMSProp | epoch: 019 | loss: 0.54298 - acc: 0.7346 -- iter: 640/653
[A[ATraining Step: 399  | total loss: [1m[32m0.56682[0m[0m | time: 24.843s
[2K
| RMSProp | epoch: 019 | loss: 0.56682 - acc: 0.7237 | val_loss: 0.61049 - val_acc: 0.6683 -- iter: 653/653
--
Training Step: 400  | total loss: [1m[32m0.56228[0m[0m | time: 2.261s
[2K
| RMSProp | epoch: 020 | loss: 0.56228 - acc: 0.7325 | val_loss: 0.59971 - val_acc: 0.6585 -- iter: 032/653
--
Training Step: 401  | total loss: [1m[32m0.57253[0m[0m | time: 3.585s
[2K
| RMSProp | epoch: 020 | loss: 0.57253 - acc: 0.7249 -- iter: 064/653
[A[ATraining Step: 402  | total loss: [1m[32m0.56736[0m[0m | time: 4.697s
[2K
| RMSProp | epoch: 020 | loss: 0.56736 - acc: 0.7305 -- iter: 096/653
[A[ATraining Step: 403  | total loss: [1m[32m0.57484[0m[0m | time: 5.834s
[2K
| RMSProp | epoch: 020 | loss: 0.57484 - acc: 0.7200 -- iter: 128/653
[A[ATraining Step: 404  | total loss: [1m[32m0.57652[0m[0m | time: 6.648s
[2K
| RMSProp | epoch: 020 | loss: 0.57652 - acc: 0.7167 -- iter: 160/653
[A[ATraining Step: 405  | total loss: [1m[32m0.56223[0m[0m | time: 7.609s
[2K
| RMSProp | epoch: 020 | loss: 0.56223 - acc: 0.7294 -- iter: 192/653
[A[ATraining Step: 406  | total loss: [1m[32m0.56199[0m[0m | time: 8.506s
[2K
| RMSProp | epoch: 020 | loss: 0.56199 - acc: 0.7221 -- iter: 224/653
[A[ATraining Step: 407  | total loss: [1m[32m0.56199[0m[0m | time: 9.459s
[2K
| RMSProp | epoch: 020 | loss: 0.56199 - acc: 0.7187 -- iter: 256/653
[A[ATraining Step: 408  | total loss: [1m[32m0.56706[0m[0m | time: 10.530s
[2K
| RMSProp | epoch: 020 | loss: 0.56706 - acc: 0.7124 -- iter: 288/653
[A[ATraining Step: 409  | total loss: [1m[32m0.56777[0m[0m | time: 11.512s
[2K
| RMSProp | epoch: 020 | loss: 0.56777 - acc: 0.7068 -- iter: 320/653
[A[ATraining Step: 410  | total loss: [1m[32m0.56779[0m[0m | time: 12.553s
[2K
| RMSProp | epoch: 020 | loss: 0.56779 - acc: 0.7049 -- iter: 352/653
[A[ATraining Step: 411  | total loss: [1m[32m0.55961[0m[0m | time: 13.587s
[2K
| RMSProp | epoch: 020 | loss: 0.55961 - acc: 0.7156 -- iter: 384/653
[A[ATraining Step: 412  | total loss: [1m[32m0.54635[0m[0m | time: 14.700s
[2K
| RMSProp | epoch: 020 | loss: 0.54635 - acc: 0.7253 -- iter: 416/653
[A[ATraining Step: 413  | total loss: [1m[32m0.54171[0m[0m | time: 15.751s
[2K
| RMSProp | epoch: 020 | loss: 0.54171 - acc: 0.7278 -- iter: 448/653
[A[ATraining Step: 414  | total loss: [1m[32m0.54496[0m[0m | time: 16.553s
[2K
| RMSProp | epoch: 020 | loss: 0.54496 - acc: 0.7238 -- iter: 480/653
[A[ATraining Step: 415  | total loss: [1m[32m0.54635[0m[0m | time: 17.498s
[2K
| RMSProp | epoch: 020 | loss: 0.54635 - acc: 0.7233 -- iter: 512/653
[A[ATraining Step: 416  | total loss: [1m[32m0.52791[0m[0m | time: 18.422s
[2K
| RMSProp | epoch: 020 | loss: 0.52791 - acc: 0.7416 -- iter: 544/653
[A[ATraining Step: 417  | total loss: [1m[32m0.51940[0m[0m | time: 18.833s
[2K
| RMSProp | epoch: 020 | loss: 0.51940 - acc: 0.7487 -- iter: 576/653
[A[ATraining Step: 418  | total loss: [1m[32m0.51874[0m[0m | time: 19.238s
[2K
| RMSProp | epoch: 020 | loss: 0.51874 - acc: 0.7507 -- iter: 608/653
[A[ATraining Step: 419  | total loss: [1m[32m0.50217[0m[0m | time: 20.121s
[2K
| RMSProp | epoch: 020 | loss: 0.50217 - acc: 0.7679 -- iter: 640/653
[A[ATraining Step: 420  | total loss: [1m[32m0.51197[0m[0m | time: 22.430s
[2K
| RMSProp | epoch: 020 | loss: 0.51197 - acc: 0.7630 | val_loss: 0.77530 - val_acc: 0.6098 -- iter: 653/653
--
Training Step: 421  | total loss: [1m[32m0.51606[0m[0m | time: 1.058s
[2K
| RMSProp | epoch: 021 | loss: 0.51606 - acc: 0.7586 -- iter: 032/653
[A[ATraining Step: 422  | total loss: [1m[32m0.57295[0m[0m | time: 2.070s
[2K
| RMSProp | epoch: 021 | loss: 0.57295 - acc: 0.7265 -- iter: 064/653
[A[ATraining Step: 423  | total loss: [1m[32m0.57501[0m[0m | time: 3.201s
[2K
| RMSProp | epoch: 021 | loss: 0.57501 - acc: 0.7195 -- iter: 096/653
[A[ATraining Step: 424  | total loss: [1m[32m0.56251[0m[0m | time: 4.312s
[2K
| RMSProp | epoch: 021 | loss: 0.56251 - acc: 0.7319 -- iter: 128/653
[A[ATraining Step: 425  | total loss: [1m[32m0.55974[0m[0m | time: 5.347s
[2K
| RMSProp | epoch: 021 | loss: 0.55974 - acc: 0.7275 -- iter: 160/653
[A[ATraining Step: 426  | total loss: [1m[32m0.54831[0m[0m | time: 6.417s
[2K
| RMSProp | epoch: 021 | loss: 0.54831 - acc: 0.7453 -- iter: 192/653
[A[ATraining Step: 427  | total loss: [1m[32m0.53570[0m[0m | time: 7.499s
[2K
| RMSProp | epoch: 021 | loss: 0.53570 - acc: 0.7552 -- iter: 224/653
[A[ATraining Step: 428  | total loss: [1m[32m0.53281[0m[0m | time: 8.520s
[2K
| RMSProp | epoch: 021 | loss: 0.53281 - acc: 0.7578 -- iter: 256/653
[A[ATraining Step: 429  | total loss: [1m[32m0.53824[0m[0m | time: 9.516s
[2K
| RMSProp | epoch: 021 | loss: 0.53824 - acc: 0.7476 -- iter: 288/653
[A[ATraining Step: 430  | total loss: [1m[32m0.54255[0m[0m | time: 10.573s
[2K
| RMSProp | epoch: 021 | loss: 0.54255 - acc: 0.7416 -- iter: 320/653
[A[ATraining Step: 431  | total loss: [1m[32m0.53143[0m[0m | time: 11.658s
[2K
| RMSProp | epoch: 021 | loss: 0.53143 - acc: 0.7456 -- iter: 352/653
[A[ATraining Step: 432  | total loss: [1m[32m0.52892[0m[0m | time: 12.755s
[2K
| RMSProp | epoch: 021 | loss: 0.52892 - acc: 0.7491 -- iter: 384/653
[A[ATraining Step: 433  | total loss: [1m[32m0.52279[0m[0m | time: 13.770s
[2K
| RMSProp | epoch: 021 | loss: 0.52279 - acc: 0.7524 -- iter: 416/653
[A[ATraining Step: 434  | total loss: [1m[32m0.51286[0m[0m | time: 14.836s
[2K
| RMSProp | epoch: 021 | loss: 0.51286 - acc: 0.7584 -- iter: 448/653
[A[ATraining Step: 435  | total loss: [1m[32m0.51567[0m[0m | time: 15.831s
[2K
| RMSProp | epoch: 021 | loss: 0.51567 - acc: 0.7607 -- iter: 480/653
[A[ATraining Step: 436  | total loss: [1m[32m0.50743[0m[0m | time: 16.816s
[2K
| RMSProp | epoch: 021 | loss: 0.50743 - acc: 0.7721 -- iter: 512/653
[A[ATraining Step: 437  | total loss: [1m[32m0.49805[0m[0m | time: 17.817s
[2K
| RMSProp | epoch: 021 | loss: 0.49805 - acc: 0.7761 -- iter: 544/653
[A[ATraining Step: 438  | total loss: [1m[32m0.49572[0m[0m | time: 18.506s
[2K
| RMSProp | epoch: 021 | loss: 0.49572 - acc: 0.7798 -- iter: 576/653
[A[ATraining Step: 439  | total loss: [1m[32m0.50413[0m[0m | time: 18.797s
[2K
| RMSProp | epoch: 021 | loss: 0.50413 - acc: 0.7674 -- iter: 608/653
[A[ATraining Step: 440  | total loss: [1m[32m0.49916[0m[0m | time: 19.077s
[2K
| RMSProp | epoch: 021 | loss: 0.49916 - acc: 0.7599 -- iter: 640/653
[A[ATraining Step: 441  | total loss: [1m[32m0.47746[0m[0m | time: 20.739s
[2K
| RMSProp | epoch: 021 | loss: 0.47746 - acc: 0.7839 | val_loss: 0.54392 - val_acc: 0.7317 -- iter: 653/653
--
Training Step: 442  | total loss: [1m[32m0.48891[0m[0m | time: 0.624s
[2K
| RMSProp | epoch: 022 | loss: 0.48891 - acc: 0.7712 -- iter: 032/653
[A[ATraining Step: 443  | total loss: [1m[32m0.48672[0m[0m | time: 1.288s
[2K
| RMSProp | epoch: 022 | loss: 0.48672 - acc: 0.7722 -- iter: 064/653
[A[ATraining Step: 444  | total loss: [1m[32m0.48245[0m[0m | time: 1.957s
[2K
| RMSProp | epoch: 022 | loss: 0.48245 - acc: 0.7762 -- iter: 096/653
[A[ATraining Step: 445  | total loss: [1m[32m0.49064[0m[0m | time: 2.579s
[2K
| RMSProp | epoch: 022 | loss: 0.49064 - acc: 0.7673 -- iter: 128/653
[A[ATraining Step: 446  | total loss: [1m[32m0.48869[0m[0m | time: 3.230s
[2K
| RMSProp | epoch: 022 | loss: 0.48869 - acc: 0.7718 -- iter: 160/653
[A[ATraining Step: 447  | total loss: [1m[32m0.47693[0m[0m | time: 3.906s
[2K
| RMSProp | epoch: 022 | loss: 0.47693 - acc: 0.7759 -- iter: 192/653
[A[ATraining Step: 448  | total loss: [1m[32m0.47184[0m[0m | time: 4.574s
[2K
| RMSProp | epoch: 022 | loss: 0.47184 - acc: 0.7827 -- iter: 224/653
[A[ATraining Step: 449  | total loss: [1m[32m0.46671[0m[0m | time: 5.248s
[2K
| RMSProp | epoch: 022 | loss: 0.46671 - acc: 0.7857 -- iter: 256/653
[A[ATraining Step: 450  | total loss: [1m[32m0.45641[0m[0m | time: 5.903s
[2K
| RMSProp | epoch: 022 | loss: 0.45641 - acc: 0.7915 -- iter: 288/653
[A[ATraining Step: 451  | total loss: [1m[32m0.43422[0m[0m | time: 6.581s
[2K
| RMSProp | epoch: 022 | loss: 0.43422 - acc: 0.8061 -- iter: 320/653
[A[ATraining Step: 452  | total loss: [1m[32m0.44791[0m[0m | time: 7.230s
[2K
| RMSProp | epoch: 022 | loss: 0.44791 - acc: 0.8036 -- iter: 352/653
[A[ATraining Step: 453  | total loss: [1m[32m0.44448[0m[0m | time: 7.867s
[2K
| RMSProp | epoch: 022 | loss: 0.44448 - acc: 0.8045 -- iter: 384/653
[A[ATraining Step: 454  | total loss: [1m[32m0.45248[0m[0m | time: 8.517s
[2K
| RMSProp | epoch: 022 | loss: 0.45248 - acc: 0.8022 -- iter: 416/653
[A[ATraining Step: 455  | total loss: [1m[32m0.45906[0m[0m | time: 9.133s
[2K
| RMSProp | epoch: 022 | loss: 0.45906 - acc: 0.7907 -- iter: 448/653
[A[ATraining Step: 456  | total loss: [1m[32m0.46047[0m[0m | time: 9.789s
[2K
| RMSProp | epoch: 022 | loss: 0.46047 - acc: 0.7866 -- iter: 480/653
[A[ATraining Step: 457  | total loss: [1m[32m0.45127[0m[0m | time: 10.446s
[2K
| RMSProp | epoch: 022 | loss: 0.45127 - acc: 0.8017 -- iter: 512/653
[A[ATraining Step: 458  | total loss: [1m[32m0.44949[0m[0m | time: 11.076s
[2K
| RMSProp | epoch: 022 | loss: 0.44949 - acc: 0.7997 -- iter: 544/653
[A[ATraining Step: 459  | total loss: [1m[32m0.43877[0m[0m | time: 11.728s
[2K
| RMSProp | epoch: 022 | loss: 0.43877 - acc: 0.8072 -- iter: 576/653
[A[ATraining Step: 460  | total loss: [1m[32m0.45116[0m[0m | time: 12.396s
[2K
| RMSProp | epoch: 022 | loss: 0.45116 - acc: 0.8015 -- iter: 608/653
[A[ATraining Step: 461  | total loss: [1m[32m0.44731[0m[0m | time: 12.699s
[2K
| RMSProp | epoch: 022 | loss: 0.44731 - acc: 0.7995 -- iter: 640/653
[A[ATraining Step: 462  | total loss: [1m[32m0.43891[0m[0m | time: 14.474s
[2K
| RMSProp | epoch: 022 | loss: 0.43891 - acc: 0.8041 | val_loss: 0.58571 - val_acc: 0.7171 -- iter: 653/653
--
Training Step: 463  | total loss: [1m[32m0.42333[0m[0m | time: 0.979s
[2K
| RMSProp | epoch: 023 | loss: 0.42333 - acc: 0.8160 -- iter: 032/653
[A[ATraining Step: 464  | total loss: [1m[32m0.43667[0m[0m | time: 1.908s
[2K
| RMSProp | epoch: 023 | loss: 0.43667 - acc: 0.8094 -- iter: 064/653
[A[ATraining Step: 465  | total loss: [1m[32m0.44656[0m[0m | time: 2.948s
[2K
| RMSProp | epoch: 023 | loss: 0.44656 - acc: 0.8035 -- iter: 096/653
[A[ATraining Step: 466  | total loss: [1m[32m0.44114[0m[0m | time: 3.863s
[2K
| RMSProp | epoch: 023 | loss: 0.44114 - acc: 0.8044 -- iter: 128/653
[A[ATraining Step: 467  | total loss: [1m[32m0.43200[0m[0m | time: 4.785s
[2K
| RMSProp | epoch: 023 | loss: 0.43200 - acc: 0.8052 -- iter: 160/653
[A[ATraining Step: 468  | total loss: [1m[32m0.44240[0m[0m | time: 5.844s
[2K
| RMSProp | epoch: 023 | loss: 0.44240 - acc: 0.8059 -- iter: 192/653
[A[ATraining Step: 469  | total loss: [1m[32m0.46823[0m[0m | time: 6.900s
[2K
| RMSProp | epoch: 023 | loss: 0.46823 - acc: 0.7910 -- iter: 224/653
[A[ATraining Step: 470  | total loss: [1m[32m0.45751[0m[0m | time: 7.846s
[2K
| RMSProp | epoch: 023 | loss: 0.45751 - acc: 0.8025 -- iter: 256/653
[A[ATraining Step: 471  | total loss: [1m[32m0.44302[0m[0m | time: 8.904s
[2K
| RMSProp | epoch: 023 | loss: 0.44302 - acc: 0.8129 -- iter: 288/653
[A[ATraining Step: 472  | total loss: [1m[32m0.42589[0m[0m | time: 9.992s
[2K
| RMSProp | epoch: 023 | loss: 0.42589 - acc: 0.8191 -- iter: 320/653
[A[ATraining Step: 473  | total loss: [1m[32m0.40603[0m[0m | time: 11.050s
[2K
| RMSProp | epoch: 023 | loss: 0.40603 - acc: 0.8278 -- iter: 352/653
[A[ATraining Step: 474  | total loss: [1m[32m0.40092[0m[0m | time: 11.942s
[2K
| RMSProp | epoch: 023 | loss: 0.40092 - acc: 0.8263 -- iter: 384/653
[A[ATraining Step: 475  | total loss: [1m[32m0.40025[0m[0m | time: 12.826s
[2K
| RMSProp | epoch: 023 | loss: 0.40025 - acc: 0.8280 -- iter: 416/653
[A[ATraining Step: 476  | total loss: [1m[32m0.40719[0m[0m | time: 13.746s
[2K
| RMSProp | epoch: 023 | loss: 0.40719 - acc: 0.8171 -- iter: 448/653
[A[ATraining Step: 477  | total loss: [1m[32m0.41263[0m[0m | time: 14.679s
[2K
| RMSProp | epoch: 023 | loss: 0.41263 - acc: 0.8166 -- iter: 480/653
[A[ATraining Step: 478  | total loss: [1m[32m0.39841[0m[0m | time: 15.537s
[2K
| RMSProp | epoch: 023 | loss: 0.39841 - acc: 0.8225 -- iter: 512/653
[A[ATraining Step: 479  | total loss: [1m[32m0.39621[0m[0m | time: 16.560s
[2K
| RMSProp | epoch: 023 | loss: 0.39621 - acc: 0.8277 -- iter: 544/653
[A[ATraining Step: 480  | total loss: [1m[32m0.38618[0m[0m | time: 17.591s
[2K
| RMSProp | epoch: 023 | loss: 0.38618 - acc: 0.8324 -- iter: 576/653
[A[ATraining Step: 481  | total loss: [1m[32m0.37661[0m[0m | time: 18.537s
[2K
| RMSProp | epoch: 023 | loss: 0.37661 - acc: 0.8430 -- iter: 608/653
[A[ATraining Step: 482  | total loss: [1m[32m0.39506[0m[0m | time: 19.720s
[2K
| RMSProp | epoch: 023 | loss: 0.39506 - acc: 0.8337 -- iter: 640/653
[A[ATraining Step: 483  | total loss: [1m[32m0.39607[0m[0m | time: 21.530s
[2K
| RMSProp | epoch: 023 | loss: 0.39607 - acc: 0.8315 | val_loss: 0.51620 - val_acc: 0.7659 -- iter: 653/653
--
Training Step: 484  | total loss: [1m[32m0.38971[0m[0m | time: 0.500s
[2K
| RMSProp | epoch: 024 | loss: 0.38971 - acc: 0.8330 -- iter: 032/653
[A[ATraining Step: 485  | total loss: [1m[32m0.36833[0m[0m | time: 1.541s
[2K
| RMSProp | epoch: 024 | loss: 0.36833 - acc: 0.8497 -- iter: 064/653
[A[ATraining Step: 486  | total loss: [1m[32m0.38175[0m[0m | time: 2.511s
[2K
| RMSProp | epoch: 024 | loss: 0.38175 - acc: 0.8366 -- iter: 096/653
[A[ATraining Step: 487  | total loss: [1m[32m0.37595[0m[0m | time: 3.510s
[2K
| RMSProp | epoch: 024 | loss: 0.37595 - acc: 0.8373 -- iter: 128/653
[A[ATraining Step: 488  | total loss: [1m[32m0.38383[0m[0m | time: 4.507s
[2K
| RMSProp | epoch: 024 | loss: 0.38383 - acc: 0.8348 -- iter: 160/653
[A[ATraining Step: 489  | total loss: [1m[32m0.36494[0m[0m | time: 5.485s
[2K
| RMSProp | epoch: 024 | loss: 0.36494 - acc: 0.8482 -- iter: 192/653
[A[ATraining Step: 490  | total loss: [1m[32m0.36863[0m[0m | time: 6.399s
[2K
| RMSProp | epoch: 024 | loss: 0.36863 - acc: 0.8509 -- iter: 224/653
[A[ATraining Step: 491  | total loss: [1m[32m0.37984[0m[0m | time: 7.496s
[2K
| RMSProp | epoch: 024 | loss: 0.37984 - acc: 0.8502 -- iter: 256/653
[A[ATraining Step: 492  | total loss: [1m[32m0.37061[0m[0m | time: 8.715s
[2K
| RMSProp | epoch: 024 | loss: 0.37061 - acc: 0.8558 -- iter: 288/653
[A[ATraining Step: 493  | total loss: [1m[32m0.36126[0m[0m | time: 9.676s
[2K
| RMSProp | epoch: 024 | loss: 0.36126 - acc: 0.8546 -- iter: 320/653
[A[ATraining Step: 494  | total loss: [1m[32m0.36680[0m[0m | time: 10.649s
[2K
| RMSProp | epoch: 024 | loss: 0.36680 - acc: 0.8504 -- iter: 352/653
[A[ATraining Step: 495  | total loss: [1m[32m0.39267[0m[0m | time: 11.650s
[2K
| RMSProp | epoch: 024 | loss: 0.39267 - acc: 0.8341 -- iter: 384/653
[A[ATraining Step: 496  | total loss: [1m[32m0.39914[0m[0m | time: 12.666s
[2K
| RMSProp | epoch: 024 | loss: 0.39914 - acc: 0.8382 -- iter: 416/653
[A[ATraining Step: 497  | total loss: [1m[32m0.37802[0m[0m | time: 13.717s
[2K
| RMSProp | epoch: 024 | loss: 0.37802 - acc: 0.8512 -- iter: 448/653
[A[ATraining Step: 498  | total loss: [1m[32m0.36515[0m[0m | time: 14.783s
[2K
| RMSProp | epoch: 024 | loss: 0.36515 - acc: 0.8599 -- iter: 480/653
[A[ATraining Step: 499  | total loss: [1m[32m0.35257[0m[0m | time: 15.803s
[2K
| RMSProp | epoch: 024 | loss: 0.35257 - acc: 0.8645 -- iter: 512/653
[A[ATraining Step: 500  | total loss: [1m[32m0.35979[0m[0m | time: 16.796s
[2K
| RMSProp | epoch: 024 | loss: 0.35979 - acc: 0.8562 -- iter: 544/653
[A[ATraining Step: 501  | total loss: [1m[32m0.35684[0m[0m | time: 17.988s
[2K
| RMSProp | epoch: 024 | loss: 0.35684 - acc: 0.8518 -- iter: 576/653
[A[ATraining Step: 502  | total loss: [1m[32m0.35408[0m[0m | time: 19.111s
[2K
| RMSProp | epoch: 024 | loss: 0.35408 - acc: 0.8541 -- iter: 608/653
[A[ATraining Step: 503  | total loss: [1m[32m0.33460[0m[0m | time: 19.913s
[2K
| RMSProp | epoch: 024 | loss: 0.33460 - acc: 0.8687 -- iter: 640/653
[A[ATraining Step: 504  | total loss: [1m[32m0.32269[0m[0m | time: 22.156s
[2K
| RMSProp | epoch: 024 | loss: 0.32269 - acc: 0.8756 | val_loss: 0.69416 - val_acc: 0.7415 -- iter: 653/653
--
Training Step: 505  | total loss: [1m[32m0.31075[0m[0m | time: 0.469s
[2K
| RMSProp | epoch: 025 | loss: 0.31075 - acc: 0.8849 -- iter: 032/653
[A[ATraining Step: 506  | total loss: [1m[32m0.32539[0m[0m | time: 0.868s
[2K
| RMSProp | epoch: 025 | loss: 0.32539 - acc: 0.8657 -- iter: 064/653
[A[ATraining Step: 507  | total loss: [1m[32m0.31104[0m[0m | time: 1.949s
[2K
| RMSProp | epoch: 025 | loss: 0.31104 - acc: 0.8791 -- iter: 096/653
[A[ATraining Step: 508  | total loss: [1m[32m0.29450[0m[0m | time: 3.008s
[2K
| RMSProp | epoch: 025 | loss: 0.29450 - acc: 0.8849 -- iter: 128/653
[A[ATraining Step: 509  | total loss: [1m[32m0.32631[0m[0m | time: 3.933s
[2K
| RMSProp | epoch: 025 | loss: 0.32631 - acc: 0.8777 -- iter: 160/653
[A[ATraining Step: 510  | total loss: [1m[32m0.39121[0m[0m | time: 5.101s
[2K
| RMSProp | epoch: 025 | loss: 0.39121 - acc: 0.8430 -- iter: 192/653
[A[ATraining Step: 511  | total loss: [1m[32m0.39908[0m[0m | time: 6.274s
[2K
| RMSProp | epoch: 025 | loss: 0.39908 - acc: 0.8337 -- iter: 224/653
[A[ATraining Step: 512  | total loss: [1m[32m0.39210[0m[0m | time: 7.166s
[2K
| RMSProp | epoch: 025 | loss: 0.39210 - acc: 0.8379 -- iter: 256/653
[A[ATraining Step: 513  | total loss: [1m[32m0.38812[0m[0m | time: 8.083s
[2K
| RMSProp | epoch: 025 | loss: 0.38812 - acc: 0.8385 -- iter: 288/653
[A[ATraining Step: 514  | total loss: [1m[32m0.37275[0m[0m | time: 9.125s
[2K
| RMSProp | epoch: 025 | loss: 0.37275 - acc: 0.8515 -- iter: 320/653
[A[ATraining Step: 515  | total loss: [1m[32m0.36478[0m[0m | time: 10.132s
[2K
| RMSProp | epoch: 025 | loss: 0.36478 - acc: 0.8538 -- iter: 352/653
[A[ATraining Step: 516  | total loss: [1m[32m0.36077[0m[0m | time: 11.071s
[2K
| RMSProp | epoch: 025 | loss: 0.36077 - acc: 0.8560 -- iter: 384/653
[A[ATraining Step: 517  | total loss: [1m[32m0.35072[0m[0m | time: 12.032s
[2K
| RMSProp | epoch: 025 | loss: 0.35072 - acc: 0.8579 -- iter: 416/653
[A[ATraining Step: 518  | total loss: [1m[32m0.33941[0m[0m | time: 13.105s
[2K
| RMSProp | epoch: 025 | loss: 0.33941 - acc: 0.8627 -- iter: 448/653
[A[ATraining Step: 519  | total loss: [1m[32m0.32357[0m[0m | time: 14.075s
[2K
| RMSProp | epoch: 025 | loss: 0.32357 - acc: 0.8733 -- iter: 480/653
[A[ATraining Step: 520  | total loss: [1m[32m0.33220[0m[0m | time: 15.261s
[2K
| RMSProp | epoch: 025 | loss: 0.33220 - acc: 0.8641 -- iter: 512/653
[A[ATraining Step: 521  | total loss: [1m[32m0.33025[0m[0m | time: 16.455s
[2K
| RMSProp | epoch: 025 | loss: 0.33025 - acc: 0.8683 -- iter: 544/653
[A[ATraining Step: 522  | total loss: [1m[32m0.31457[0m[0m | time: 17.306s
[2K
| RMSProp | epoch: 025 | loss: 0.31457 - acc: 0.8721 -- iter: 576/653
[A[ATraining Step: 523  | total loss: [1m[32m0.30586[0m[0m | time: 18.275s
[2K
| RMSProp | epoch: 025 | loss: 0.30586 - acc: 0.8786 -- iter: 608/653
[A[ATraining Step: 524  | total loss: [1m[32m0.30585[0m[0m | time: 19.274s
[2K
| RMSProp | epoch: 025 | loss: 0.30585 - acc: 0.8814 -- iter: 640/653
[A[ATraining Step: 525  | total loss: [1m[32m0.30395[0m[0m | time: 21.471s
[2K
| RMSProp | epoch: 025 | loss: 0.30395 - acc: 0.8776 | val_loss: 0.49161 - val_acc: 0.8000 -- iter: 653/653
--
Training Step: 526  | total loss: [1m[32m0.31130[0m[0m | time: 1.011s
[2K
| RMSProp | epoch: 026 | loss: 0.31130 - acc: 0.8743 -- iter: 032/653
[A[ATraining Step: 527  | total loss: [1m[32m0.29704[0m[0m | time: 1.362s
[2K
| RMSProp | epoch: 026 | loss: 0.29704 - acc: 0.8837 -- iter: 064/653
[A[ATraining Step: 528  | total loss: [1m[32m0.29057[0m[0m | time: 1.819s
[2K
| RMSProp | epoch: 026 | loss: 0.29057 - acc: 0.8876 -- iter: 096/653
[A[ATraining Step: 529  | total loss: [1m[32m0.29266[0m[0m | time: 2.943s
[2K
| RMSProp | epoch: 026 | loss: 0.29266 - acc: 0.8835 -- iter: 128/653
[A[ATraining Step: 530  | total loss: [1m[32m0.28672[0m[0m | time: 4.081s
[2K
| RMSProp | epoch: 026 | loss: 0.28672 - acc: 0.8826 -- iter: 160/653
[A[ATraining Step: 531  | total loss: [1m[32m0.27134[0m[0m | time: 4.956s
[2K
| RMSProp | epoch: 026 | loss: 0.27134 - acc: 0.8944 -- iter: 192/653
[A[ATraining Step: 532  | total loss: [1m[32m0.26987[0m[0m | time: 5.883s
[2K
| RMSProp | epoch: 026 | loss: 0.26987 - acc: 0.8924 -- iter: 224/653
[A[ATraining Step: 533  | total loss: [1m[32m0.29044[0m[0m | time: 6.792s
[2K
| RMSProp | epoch: 026 | loss: 0.29044 - acc: 0.8751 -- iter: 256/653
[A[ATraining Step: 534  | total loss: [1m[32m0.28580[0m[0m | time: 7.761s
[2K
| RMSProp | epoch: 026 | loss: 0.28580 - acc: 0.8688 -- iter: 288/653
[A[ATraining Step: 535  | total loss: [1m[32m0.27806[0m[0m | time: 8.761s
[2K
| RMSProp | epoch: 026 | loss: 0.27806 - acc: 0.8726 -- iter: 320/653
[A[ATraining Step: 536  | total loss: [1m[32m0.26578[0m[0m | time: 9.657s
[2K
| RMSProp | epoch: 026 | loss: 0.26578 - acc: 0.8791 -- iter: 352/653
[A[ATraining Step: 537  | total loss: [1m[32m0.27986[0m[0m | time: 10.667s
[2K
| RMSProp | epoch: 026 | loss: 0.27986 - acc: 0.8661 -- iter: 384/653
[A[ATraining Step: 538  | total loss: [1m[32m0.28532[0m[0m | time: 11.678s
[2K
| RMSProp | epoch: 026 | loss: 0.28532 - acc: 0.8639 -- iter: 416/653
[A[ATraining Step: 539  | total loss: [1m[32m0.29348[0m[0m | time: 12.756s
[2K
| RMSProp | epoch: 026 | loss: 0.29348 - acc: 0.8650 -- iter: 448/653
[A[ATraining Step: 540  | total loss: [1m[32m0.30407[0m[0m | time: 13.922s
[2K
| RMSProp | epoch: 026 | loss: 0.30407 - acc: 0.8566 -- iter: 480/653
[A[ATraining Step: 541  | total loss: [1m[32m0.31074[0m[0m | time: 14.889s
[2K
| RMSProp | epoch: 026 | loss: 0.31074 - acc: 0.8522 -- iter: 512/653
[A[ATraining Step: 542  | total loss: [1m[32m0.29977[0m[0m | time: 15.707s
[2K
| RMSProp | epoch: 026 | loss: 0.29977 - acc: 0.8608 -- iter: 544/653
[A[ATraining Step: 543  | total loss: [1m[32m0.28931[0m[0m | time: 16.591s
[2K
| RMSProp | epoch: 026 | loss: 0.28931 - acc: 0.8653 -- iter: 576/653
[A[ATraining Step: 544  | total loss: [1m[32m0.29329[0m[0m | time: 17.543s
[2K
| RMSProp | epoch: 026 | loss: 0.29329 - acc: 0.8663 -- iter: 608/653
[A[ATraining Step: 545  | total loss: [1m[32m0.29319[0m[0m | time: 18.371s
[2K
| RMSProp | epoch: 026 | loss: 0.29319 - acc: 0.8671 -- iter: 640/653
[A[ATraining Step: 546  | total loss: [1m[32m0.28669[0m[0m | time: 20.399s
[2K
| RMSProp | epoch: 026 | loss: 0.28669 - acc: 0.8742 | val_loss: 0.56389 - val_acc: 0.7512 -- iter: 653/653
--
Training Step: 547  | total loss: [1m[32m0.27553[0m[0m | time: 0.964s
[2K
| RMSProp | epoch: 027 | loss: 0.27553 - acc: 0.8836 -- iter: 032/653
[A[ATraining Step: 548  | total loss: [1m[32m0.27274[0m[0m | time: 1.917s
[2K
| RMSProp | epoch: 027 | loss: 0.27274 - acc: 0.8859 -- iter: 064/653
[A[ATraining Step: 549  | total loss: [1m[32m0.25637[0m[0m | time: 2.397s
[2K
| RMSProp | epoch: 027 | loss: 0.25637 - acc: 0.8942 -- iter: 096/653
[A[ATraining Step: 550  | total loss: [1m[32m0.25148[0m[0m | time: 2.936s
[2K
| RMSProp | epoch: 027 | loss: 0.25148 - acc: 0.8971 -- iter: 128/653
[A[ATraining Step: 551  | total loss: [1m[32m0.23116[0m[0m | time: 4.137s
[2K
| RMSProp | epoch: 027 | loss: 0.23116 - acc: 0.9074 -- iter: 160/653
[A[ATraining Step: 552  | total loss: [1m[32m0.22783[0m[0m | time: 4.976s
[2K
| RMSProp | epoch: 027 | loss: 0.22783 - acc: 0.9073 -- iter: 192/653
[A[ATraining Step: 553  | total loss: [1m[32m0.24601[0m[0m | time: 5.900s
[2K
| RMSProp | epoch: 027 | loss: 0.24601 - acc: 0.9040 -- iter: 224/653
[A[ATraining Step: 554  | total loss: [1m[32m0.26709[0m[0m | time: 6.867s
[2K
| RMSProp | epoch: 027 | loss: 0.26709 - acc: 0.8918 -- iter: 256/653
[A[ATraining Step: 555  | total loss: [1m[32m0.26686[0m[0m | time: 7.850s
[2K
| RMSProp | epoch: 027 | loss: 0.26686 - acc: 0.8932 -- iter: 288/653
[A[ATraining Step: 556  | total loss: [1m[32m0.27392[0m[0m | time: 8.822s
[2K
| RMSProp | epoch: 027 | loss: 0.27392 - acc: 0.8820 -- iter: 320/653
[A[ATraining Step: 557  | total loss: [1m[32m0.28288[0m[0m | time: 9.877s
[2K
| RMSProp | epoch: 027 | loss: 0.28288 - acc: 0.8813 -- iter: 352/653
[A[ATraining Step: 558  | total loss: [1m[32m0.27218[0m[0m | time: 10.869s
[2K
| RMSProp | epoch: 027 | loss: 0.27218 - acc: 0.8932 -- iter: 384/653
[A[ATraining Step: 559  | total loss: [1m[32m0.26315[0m[0m | time: 11.933s
[2K
| RMSProp | epoch: 027 | loss: 0.26315 - acc: 0.8945 -- iter: 416/653
[A[ATraining Step: 560  | total loss: [1m[32m0.25484[0m[0m | time: 13.049s
[2K
| RMSProp | epoch: 027 | loss: 0.25484 - acc: 0.8957 -- iter: 448/653
[A[ATraining Step: 561  | total loss: [1m[32m0.24621[0m[0m | time: 14.093s
[2K
| RMSProp | epoch: 027 | loss: 0.24621 - acc: 0.8967 -- iter: 480/653
[A[ATraining Step: 562  | total loss: [1m[32m0.23289[0m[0m | time: 14.938s
[2K
| RMSProp | epoch: 027 | loss: 0.23289 - acc: 0.9070 -- iter: 512/653
[A[ATraining Step: 563  | total loss: [1m[32m0.22867[0m[0m | time: 15.867s
[2K
| RMSProp | epoch: 027 | loss: 0.22867 - acc: 0.9007 -- iter: 544/653
[A[ATraining Step: 564  | total loss: [1m[32m0.21732[0m[0m | time: 16.856s
[2K
| RMSProp | epoch: 027 | loss: 0.21732 - acc: 0.9075 -- iter: 576/653
[A[ATraining Step: 565  | total loss: [1m[32m0.21331[0m[0m | time: 17.746s
[2K
| RMSProp | epoch: 027 | loss: 0.21331 - acc: 0.9136 -- iter: 608/653
[A[ATraining Step: 566  | total loss: [1m[32m0.20077[0m[0m | time: 18.789s
[2K
| RMSProp | epoch: 027 | loss: 0.20077 - acc: 0.9223 -- iter: 640/653
[A[ATraining Step: 567  | total loss: [1m[32m0.19476[0m[0m | time: 21.051s
[2K
| RMSProp | epoch: 027 | loss: 0.19476 - acc: 0.9238 | val_loss: 0.72428 - val_acc: 0.7366 -- iter: 653/653
--
Training Step: 568  | total loss: [1m[32m0.21383[0m[0m | time: 1.131s
[2K
| RMSProp | epoch: 028 | loss: 0.21383 - acc: 0.9095 -- iter: 032/653
[A[ATraining Step: 569  | total loss: [1m[32m0.22469[0m[0m | time: 2.337s
[2K
| RMSProp | epoch: 028 | loss: 0.22469 - acc: 0.8998 -- iter: 064/653
[A[ATraining Step: 570  | total loss: [1m[32m0.22277[0m[0m | time: 3.390s
[2K
| RMSProp | epoch: 028 | loss: 0.22277 - acc: 0.9067 -- iter: 096/653
[A[ATraining Step: 571  | total loss: [1m[32m0.21888[0m[0m | time: 3.799s
[2K
| RMSProp | epoch: 028 | loss: 0.21888 - acc: 0.9098 -- iter: 128/653
[A[ATraining Step: 572  | total loss: [1m[32m0.23593[0m[0m | time: 4.231s
[2K
| RMSProp | epoch: 028 | loss: 0.23593 - acc: 0.9111 -- iter: 160/653
[A[ATraining Step: 573  | total loss: [1m[32m0.21784[0m[0m | time: 5.151s
[2K
| RMSProp | epoch: 028 | loss: 0.21784 - acc: 0.9200 -- iter: 192/653
[A[ATraining Step: 574  | total loss: [1m[32m0.21552[0m[0m | time: 6.163s
[2K
| RMSProp | epoch: 028 | loss: 0.21552 - acc: 0.9249 -- iter: 224/653
[A[ATraining Step: 575  | total loss: [1m[32m0.20658[0m[0m | time: 7.162s
[2K
| RMSProp | epoch: 028 | loss: 0.20658 - acc: 0.9293 -- iter: 256/653
[A[ATraining Step: 576  | total loss: [1m[32m0.19772[0m[0m | time: 8.211s
[2K
| RMSProp | epoch: 028 | loss: 0.19772 - acc: 0.9332 -- iter: 288/653
[A[ATraining Step: 577  | total loss: [1m[32m0.19023[0m[0m | time: 9.153s
[2K
| RMSProp | epoch: 028 | loss: 0.19023 - acc: 0.9368 -- iter: 320/653
[A[ATraining Step: 578  | total loss: [1m[32m0.18257[0m[0m | time: 10.080s
[2K
| RMSProp | epoch: 028 | loss: 0.18257 - acc: 0.9337 -- iter: 352/653
[A[ATraining Step: 579  | total loss: [1m[32m0.19162[0m[0m | time: 11.098s
[2K
| RMSProp | epoch: 028 | loss: 0.19162 - acc: 0.9310 -- iter: 384/653
[A[ATraining Step: 580  | total loss: [1m[32m0.18839[0m[0m | time: 12.205s
[2K
| RMSProp | epoch: 028 | loss: 0.18839 - acc: 0.9316 -- iter: 416/653
[A[ATraining Step: 581  | total loss: [1m[32m0.17795[0m[0m | time: 13.184s
[2K
| RMSProp | epoch: 028 | loss: 0.17795 - acc: 0.9385 -- iter: 448/653
[A[ATraining Step: 582  | total loss: [1m[32m0.17539[0m[0m | time: 14.117s
[2K
| RMSProp | epoch: 028 | loss: 0.17539 - acc: 0.9415 -- iter: 480/653
[A[ATraining Step: 583  | total loss: [1m[32m0.16316[0m[0m | time: 15.035s
[2K
| RMSProp | epoch: 028 | loss: 0.16316 - acc: 0.9473 -- iter: 512/653
[A[ATraining Step: 584  | total loss: [1m[32m0.17056[0m[0m | time: 15.936s
[2K
| RMSProp | epoch: 028 | loss: 0.17056 - acc: 0.9495 -- iter: 544/653
[A[ATraining Step: 585  | total loss: [1m[32m0.18400[0m[0m | time: 16.871s
[2K
| RMSProp | epoch: 028 | loss: 0.18400 - acc: 0.9420 -- iter: 576/653
[A[ATraining Step: 586  | total loss: [1m[32m0.18473[0m[0m | time: 17.940s
[2K
| RMSProp | epoch: 028 | loss: 0.18473 - acc: 0.9385 -- iter: 608/653
[A[ATraining Step: 587  | total loss: [1m[32m0.18099[0m[0m | time: 19.008s
[2K
| RMSProp | epoch: 028 | loss: 0.18099 - acc: 0.9415 -- iter: 640/653
[A[ATraining Step: 588  | total loss: [1m[32m0.17657[0m[0m | time: 21.019s
[2K
| RMSProp | epoch: 028 | loss: 0.17657 - acc: 0.9442 | val_loss: 0.80819 - val_acc: 0.6976 -- iter: 653/653
--
Training Step: 589  | total loss: [1m[32m0.17886[0m[0m | time: 0.979s
[2K
| RMSProp | epoch: 029 | loss: 0.17886 - acc: 0.9404 -- iter: 032/653
[A[ATraining Step: 590  | total loss: [1m[32m0.19922[0m[0m | time: 1.993s
[2K
| RMSProp | epoch: 029 | loss: 0.19922 - acc: 0.9308 -- iter: 064/653
[A[ATraining Step: 591  | total loss: [1m[32m0.19675[0m[0m | time: 2.905s
[2K
| RMSProp | epoch: 029 | loss: 0.19675 - acc: 0.9346 -- iter: 096/653
[A[ATraining Step: 592  | total loss: [1m[32m0.18320[0m[0m | time: 3.907s
[2K
| RMSProp | epoch: 029 | loss: 0.18320 - acc: 0.9411 -- iter: 128/653
[A[ATraining Step: 593  | total loss: [1m[32m0.17128[0m[0m | time: 4.392s
[2K
| RMSProp | epoch: 029 | loss: 0.17128 - acc: 0.9470 -- iter: 160/653
[A[ATraining Step: 594  | total loss: [1m[32m0.16813[0m[0m | time: 4.920s
[2K
| RMSProp | epoch: 029 | loss: 0.16813 - acc: 0.9446 -- iter: 192/653
[A[ATraining Step: 595  | total loss: [1m[32m0.16603[0m[0m | time: 5.911s
[2K
| RMSProp | epoch: 029 | loss: 0.16603 - acc: 0.9424 -- iter: 224/653
[A[ATraining Step: 596  | total loss: [1m[32m0.15343[0m[0m | time: 6.903s
[2K
| RMSProp | epoch: 029 | loss: 0.15343 - acc: 0.9482 -- iter: 256/653
[A[ATraining Step: 597  | total loss: [1m[32m0.14504[0m[0m | time: 8.090s
[2K
| RMSProp | epoch: 029 | loss: 0.14504 - acc: 0.9534 -- iter: 288/653
[A[ATraining Step: 598  | total loss: [1m[32m0.14529[0m[0m | time: 9.101s
[2K
| RMSProp | epoch: 029 | loss: 0.14529 - acc: 0.9549 -- iter: 320/653
[A[ATraining Step: 599  | total loss: [1m[32m0.16115[0m[0m | time: 10.019s
[2K
| RMSProp | epoch: 029 | loss: 0.16115 - acc: 0.9438 -- iter: 352/653
[A[ATraining Step: 600  | total loss: [1m[32m0.18498[0m[0m | time: 11.987s
[2K
| RMSProp | epoch: 029 | loss: 0.18498 - acc: 0.9338 | val_loss: 0.61771 - val_acc: 0.7415 -- iter: 384/653
--
Training Step: 601  | total loss: [1m[32m0.18752[0m[0m | time: 12.987s
[2K
| RMSProp | epoch: 029 | loss: 0.18752 - acc: 0.9279 -- iter: 416/653
[A[ATraining Step: 602  | total loss: [1m[32m0.18869[0m[0m | time: 14.032s
[2K
| RMSProp | epoch: 029 | loss: 0.18869 - acc: 0.9289 -- iter: 448/653
[A[ATraining Step: 603  | total loss: [1m[32m0.18663[0m[0m | time: 14.900s
[2K
| RMSProp | epoch: 029 | loss: 0.18663 - acc: 0.9329 -- iter: 480/653
[A[ATraining Step: 604  | total loss: [1m[32m0.17793[0m[0m | time: 16.020s
[2K
| RMSProp | epoch: 029 | loss: 0.17793 - acc: 0.9365 -- iter: 512/653
[A[ATraining Step: 605  | total loss: [1m[32m0.17851[0m[0m | time: 17.088s
[2K
| RMSProp | epoch: 029 | loss: 0.17851 - acc: 0.9366 -- iter: 544/653
[A[ATraining Step: 606  | total loss: [1m[32m0.18657[0m[0m | time: 17.985s
[2K
| RMSProp | epoch: 029 | loss: 0.18657 - acc: 0.9335 -- iter: 576/653
[A[ATraining Step: 607  | total loss: [1m[32m0.18878[0m[0m | time: 18.886s
[2K
| RMSProp | epoch: 029 | loss: 0.18878 - acc: 0.9308 -- iter: 608/653
[A[ATraining Step: 608  | total loss: [1m[32m0.18465[0m[0m | time: 19.841s
[2K
| RMSProp | epoch: 029 | loss: 0.18465 - acc: 0.9346 -- iter: 640/653
[A[ATraining Step: 609  | total loss: [1m[32m0.17006[0m[0m | time: 21.809s
[2K
| RMSProp | epoch: 029 | loss: 0.17006 - acc: 0.9411 | val_loss: 0.61973 - val_acc: 0.7756 -- iter: 653/653
--
Training Step: 610  | total loss: [1m[32m0.16461[0m[0m | time: 1.156s
[2K
| RMSProp | epoch: 030 | loss: 0.16461 - acc: 0.9439 -- iter: 032/653
[A[ATraining Step: 611  | total loss: [1m[32m0.16598[0m[0m | time: 2.121s
[2K
| RMSProp | epoch: 030 | loss: 0.16598 - acc: 0.9401 -- iter: 064/653
[A[ATraining Step: 612  | total loss: [1m[32m0.16177[0m[0m | time: 3.038s
[2K
| RMSProp | epoch: 030 | loss: 0.16177 - acc: 0.9430 -- iter: 096/653
[A[ATraining Step: 613  | total loss: [1m[32m0.15063[0m[0m | time: 4.044s
[2K
| RMSProp | epoch: 030 | loss: 0.15063 - acc: 0.9487 -- iter: 128/653
[A[ATraining Step: 614  | total loss: [1m[32m0.13949[0m[0m | time: 4.959s
[2K
| RMSProp | epoch: 030 | loss: 0.13949 - acc: 0.9538 -- iter: 160/653
[A[ATraining Step: 615  | total loss: [1m[32m0.13020[0m[0m | time: 5.405s
[2K
| RMSProp | epoch: 030 | loss: 0.13020 - acc: 0.9584 -- iter: 192/653
[A[ATraining Step: 616  | total loss: [1m[32m0.12052[0m[0m | time: 5.834s
[2K
| RMSProp | epoch: 030 | loss: 0.12052 - acc: 0.9626 -- iter: 224/653
[A[ATraining Step: 617  | total loss: [1m[32m0.10957[0m[0m | time: 6.921s
[2K
| RMSProp | epoch: 030 | loss: 0.10957 - acc: 0.9663 -- iter: 256/653
[A[ATraining Step: 618  | total loss: [1m[32m0.10361[0m[0m | time: 7.908s
[2K
| RMSProp | epoch: 030 | loss: 0.10361 - acc: 0.9697 -- iter: 288/653
[A[ATraining Step: 619  | total loss: [1m[32m0.12656[0m[0m | time: 8.925s
[2K
| RMSProp | epoch: 030 | loss: 0.12656 - acc: 0.9634 -- iter: 320/653
[A[ATraining Step: 620  | total loss: [1m[32m0.16962[0m[0m | time: 10.098s
[2K
| RMSProp | epoch: 030 | loss: 0.16962 - acc: 0.9420 -- iter: 352/653
[A[ATraining Step: 621  | total loss: [1m[32m0.16339[0m[0m | time: 11.305s
[2K
| RMSProp | epoch: 030 | loss: 0.16339 - acc: 0.9447 -- iter: 384/653
[A[ATraining Step: 622  | total loss: [1m[32m0.15098[0m[0m | time: 12.249s
[2K
| RMSProp | epoch: 030 | loss: 0.15098 - acc: 0.9502 -- iter: 416/653
[A[ATraining Step: 623  | total loss: [1m[32m0.14123[0m[0m | time: 13.192s
[2K
| RMSProp | epoch: 030 | loss: 0.14123 - acc: 0.9552 -- iter: 448/653
[A[ATraining Step: 624  | total loss: [1m[32m0.12889[0m[0m | time: 14.161s
[2K
| RMSProp | epoch: 030 | loss: 0.12889 - acc: 0.9597 -- iter: 480/653
[A[ATraining Step: 625  | total loss: [1m[32m0.11773[0m[0m | time: 15.100s
[2K
| RMSProp | epoch: 030 | loss: 0.11773 - acc: 0.9637 -- iter: 512/653
[A[ATraining Step: 626  | total loss: [1m[32m0.11871[0m[0m | time: 16.092s
[2K
| RMSProp | epoch: 030 | loss: 0.11871 - acc: 0.9611 -- iter: 544/653
[A[ATraining Step: 627  | total loss: [1m[32m0.12480[0m[0m | time: 17.162s
[2K
| RMSProp | epoch: 030 | loss: 0.12480 - acc: 0.9587 -- iter: 576/653
[A[ATraining Step: 628  | total loss: [1m[32m0.16362[0m[0m | time: 18.225s
[2K
| RMSProp | epoch: 030 | loss: 0.16362 - acc: 0.9441 -- iter: 608/653
[A[ATraining Step: 629  | total loss: [1m[32m0.16378[0m[0m | time: 19.185s
[2K
| RMSProp | epoch: 030 | loss: 0.16378 - acc: 0.9466 -- iter: 640/653
[A[ATraining Step: 630  | total loss: [1m[32m0.16224[0m[0m | time: 21.703s
[2K
| RMSProp | epoch: 030 | loss: 0.16224 - acc: 0.9457 | val_loss: 0.63522 - val_acc: 0.7854 -- iter: 653/653
--
Validation AUC:0.8575780654988575
Validation AUPRC:0.8651263096089508
Test AUC:0.9174320891147156
Test AUPRC:0.9108501025625273
BestTestF1Score	0.84	0.74	0.87	0.91	0.78	67	7	112	19	0.72
BestTestMCCScore	0.84	0.74	0.87	0.91	0.78	67	7	112	19	0.72
BestTestAccuracyScore	0.84	0.74	0.87	0.91	0.78	67	7	112	19	0.72
BestValidationF1Score	0.8	0.64	0.81	0.88	0.73	76	10	91	28	0.72
BestValidationMCC	0.8	0.64	0.81	0.88	0.73	76	10	91	28	0.72
BestValidationAccuracy	0.8	0.64	0.81	0.88	0.73	76	10	91	28	0.72
TestPredictions (Threshold:0.72)
CHEMBL604060,TP,ACT,1.0	CHEMBL2333898,TP,ACT,0.9700000286102295	CHEMBL2333884,TP,ACT,0.9300000071525574	CHEMBL2332059,TP,ACT,0.9800000190734863	CHEMBL317398,TN,INACT,0.019999999552965164	CHEMBL550856,TN,INACT,0.019999999552965164	CHEMBL1784649,TN,INACT,0.4399999976158142	CHEMBL430902,TN,INACT,0.2800000011920929	CHEMBL2392388,TN,INACT,0.009999999776482582	CHEMBL1923166,TP,ACT,1.0	CHEMBL384073,TP,ACT,0.9700000286102295	CHEMBL2333906,TP,ACT,0.9900000095367432	CHEMBL513336,TN,INACT,0.25999999046325684	CHEMBL1933801,TN,INACT,0.0	CHEMBL1089405,TN,INACT,0.03999999910593033	CHEMBL2070439,FP,INACT,0.8999999761581421	CHEMBL3238165,FN,ACT,0.009999999776482582	CHEMBL1667968,TP,ACT,1.0	CHEMBL598963,FN,ACT,0.6000000238418579	CHEMBL1448,TN,INACT,0.009999999776482582	CHEMBL2420909,TN,INACT,0.009999999776482582	CHEMBL3810107,TP,ACT,1.0	CHEMBL304284,TN,INACT,0.0	CHEMBL1258663,FP,INACT,0.9300000071525574	CHEMBL1929238,TN,INACT,0.029999999329447746	CHEMBL3672514,TN,INACT,0.009999999776482582	CHEMBL23507,TN,INACT,0.019999999552965164	CHEMBL271138,TN,INACT,0.019999999552965164	CHEMBL2334288,TP,ACT,0.9900000095367432	CHEMBL3689079,TN,INACT,0.009999999776482582	CHEMBL395665,TN,INACT,0.009999999776482582	CHEMBL3809796,FN,ACT,0.029999999329447746	CHEMBL3680484,TN,INACT,0.550000011920929	CHEMBL570116,FN,ACT,0.05999999865889549	CHEMBL1877245,TN,INACT,0.009999999776482582	CHEMBL2348176,TN,INACT,0.009999999776482582	CHEMBL279003,TN,INACT,0.0	CHEMBL484274,TN,INACT,0.0	CHEMBL1084892,TP,ACT,0.9800000190734863	CHEMBL3661092,TN,INACT,0.009999999776482582	CHEMBL3808565,TP,ACT,1.0	CHEMBL522892,FN,ACT,0.46000000834465027	CHEMBL29197,TN,INACT,0.019999999552965164	CHEMBL128000,TN,INACT,0.009999999776482582	CHEMBL100811,TN,INACT,0.0	CHEMBL2022282,TN,INACT,0.07000000029802322	CHEMBL487737,TN,INACT,0.6600000262260437	CHEMBL1235213,TN,INACT,0.009999999776482582	CHEMBL2348180,TN,INACT,0.029999999329447746	CHEMBL279193,TN,INACT,0.05999999865889549	CHEMBL2164696,TN,INACT,0.07000000029802322	CHEMBL3680461,TN,INACT,0.019999999552965164	CHEMBL3356117,TN,INACT,0.009999999776482582	CHEMBL86795,TN,INACT,0.05999999865889549	CHEMBL493269,TP,ACT,0.949999988079071	CHEMBL571948,FN,ACT,0.07000000029802322	CHEMBL3680394,TN,INACT,0.4099999964237213	CHEMBL1923161,TP,ACT,0.9900000095367432	CHEMBL132399,TN,INACT,0.009999999776482582	CHEMBL469776,TN,INACT,0.019999999552965164	CHEMBL3218288,TP,ACT,1.0	CHEMBL74799,TN,INACT,0.009999999776482582	CHEMBL99779,TN,INACT,0.5	CHEMBL2392246,TN,INACT,0.009999999776482582	CHEMBL491064,TN,INACT,0.3499999940395355	CHEMBL335938,TN,INACT,0.17000000178813934	CHEMBL506669,TN,INACT,0.009999999776482582	CHEMBL2029515,TN,INACT,0.029999999329447746	CHEMBL3218009,TP,ACT,1.0	CHEMBL550855,TN,INACT,0.5400000214576721	CHEMBL460472,TN,INACT,0.019999999552965164	CHEMBL2147538,TP,ACT,0.9800000190734863	CHEMBL2177670,TN,INACT,0.009999999776482582	CHEMBL3218006,TP,ACT,0.9700000286102295	CHEMBL601834,FN,ACT,0.5600000023841858	CHEMBL522760,TN,INACT,0.05000000074505806	CHEMBL3809604,TP,ACT,0.8700000047683716	CHEMBL3581140,TP,ACT,1.0	CHEMBL1436125,TN,INACT,0.0	CHEMBL3238164,FN,ACT,0.009999999776482582	CHEMBL1643359,FN,ACT,0.6899999976158142	CHEMBL2332069,TP,ACT,0.8500000238418579	CHEMBL485611,TP,ACT,1.0	CHEMBL381932,TN,INACT,0.0	CHEMBL1910602,TN,INACT,0.1899999976158142	CHEMBL2163610,TN,INACT,0.009999999776482582	CHEMBL3581116,TP,ACT,0.9700000286102295	CHEMBL1667976,FN,ACT,0.25	CHEMBL228114,TN,INACT,0.07999999821186066	CHEMBL220241,FN,ACT,0.20999999344348907	CHEMBL575340,TP,ACT,0.9900000095367432	CHEMBL1910758,TN,INACT,0.07999999821186066	CHEMBL602471,FP,INACT,0.9599999785423279	CHEMBL328034,FP,INACT,0.9399999976158142	CHEMBL1765739,TP,ACT,0.7699999809265137	CHEMBL489246,TN,INACT,0.029999999329447746	CHEMBL131098,TN,INACT,0.009999999776482582	CHEMBL3665663,TN,INACT,0.20999999344348907	CHEMBL493911,TP,ACT,1.0	CHEMBL2332065,TP,ACT,0.9399999976158142	CHEMBL483535,TN,INACT,0.07000000029802322	CHEMBL1083966,TP,ACT,0.8199999928474426	CHEMBL259850,TN,INACT,0.009999999776482582	CHEMBL563674,FP,INACT,0.9900000095367432	CHEMBL2333905,TP,ACT,0.9900000095367432	CHEMBL485502,TN,INACT,0.0	CHEMBL328623,TN,INACT,0.009999999776482582	CHEMBL1086322,FN,ACT,0.5699999928474426	CHEMBL562342,TN,INACT,0.10000000149011612	CHEMBL2029516,TN,INACT,0.05999999865889549	CHEMBL1910757,TN,INACT,0.05000000074505806	CHEMBL1994526,TP,ACT,0.8999999761581421	CHEMBL101052,TN,INACT,0.0	CHEMBL1790815,TN,INACT,0.17000000178813934	CHEMBL1643367,TP,ACT,0.9800000190734863	CHEMBL1767294,TN,INACT,0.009999999776482582	CHEMBL384304,FN,ACT,0.019999999552965164	CHEMBL485585,TP,ACT,1.0	CHEMBL2029519,TN,INACT,0.019999999552965164	CHEMBL483574,TP,ACT,0.9900000095367432	CHEMBL521347,TP,ACT,0.8299999833106995	CHEMBL521734,TN,INACT,0.019999999552965164	CHEMBL3665668,TN,INACT,0.07999999821186066	CHEMBL2177830,TN,INACT,0.5199999809265137	CHEMBL1642269,TN,INACT,0.0	CHEMBL3665654,TN,INACT,0.009999999776482582	CHEMBL3691604,FP,INACT,0.9599999785423279	CHEMBL488646,TN,INACT,0.019999999552965164	CHEMBL38380,TP,ACT,0.8199999928474426	CHEMBL1923170,TP,ACT,0.9800000190734863	CHEMBL1079208,TP,ACT,0.9800000190734863	CHEMBL3218005,FN,ACT,0.6499999761581421	CHEMBL3218021,TP,ACT,1.0	CHEMBL1287945,TN,INACT,0.23000000417232513	CHEMBL575562,TP,ACT,0.949999988079071	CHEMBL2332063,TP,ACT,0.9900000095367432	CHEMBL3218013,TP,ACT,0.9800000190734863	CHEMBL1079293,TP,ACT,0.9100000262260437	CHEMBL1922042,TP,ACT,1.0	CHEMBL3665669,TN,INACT,0.05000000074505806	CHEMBL132948,TN,INACT,0.6000000238418579	CHEMBL1809197,TN,INACT,0.0	CHEMBL3218024,TP,ACT,1.0	CHEMBL484968,TP,ACT,0.8600000143051147	CHEMBL1738705,TN,INACT,0.07000000029802322	CHEMBL264666,TN,INACT,0.019999999552965164	CHEMBL3581121,TP,ACT,1.0	CHEMBL436817,TN,INACT,0.0	CHEMBL1083965,FN,ACT,0.029999999329447746	CHEMBL1084863,TN,INACT,0.6399999856948853	CHEMBL2392236,TN,INACT,0.0	CHEMBL230761,TN,INACT,0.49000000953674316	CHEMBL1922026,TP,ACT,1.0	CHEMBL2419278,FN,ACT,0.6100000143051147	CHEMBL1331525,TN,INACT,0.05000000074505806	CHEMBL3609567,TN,INACT,0.0	CHEMBL1643361,TP,ACT,0.9900000095367432	CHEMBL100079,TN,INACT,0.3799999952316284	CHEMBL374453,TP,ACT,0.9700000286102295	CHEMBL1171329,TN,INACT,0.2199999988079071	CHEMBL494088,TP,ACT,0.949999988079071	CHEMBL1762116,TN,INACT,0.2199999988079071	CHEMBL2023147,TN,INACT,0.09000000357627869	CHEMBL99699,TN,INACT,0.009999999776482582	CHEMBL1922032,TP,ACT,1.0	CHEMBL1614774,TP,ACT,1.0	CHEMBL3218285,TP,ACT,0.9800000190734863	CHEMBL2312654,TN,INACT,0.10999999940395355	CHEMBL3665664,TN,INACT,0.6600000262260437	CHEMBL3659983,TN,INACT,0.3499999940395355	CHEMBL453510,FN,ACT,0.019999999552965164	CHEMBL3218019,FN,ACT,0.6600000262260437	CHEMBL2348181,TN,INACT,0.019999999552965164	CHEMBL2312649,TN,INACT,0.019999999552965164	CHEMBL469346,TN,INACT,0.14000000059604645	CHEMBL557237,TN,INACT,0.029999999329447746	CHEMBL101558,TN,INACT,0.0	CHEMBL1688204,TN,INACT,0.09000000357627869	CHEMBL1078426,TP,ACT,0.9399999976158142	CHEMBL282575,FP,INACT,0.9700000286102295	CHEMBL454973,TN,INACT,0.0	CHEMBL197538,TN,INACT,0.009999999776482582	CHEMBL1652453,TN,INACT,0.0	CHEMBL485440,TP,ACT,0.8399999737739563	CHEMBL3335362,TN,INACT,0.6700000166893005	CHEMBL2348175,TN,INACT,0.009999999776482582	CHEMBL1922030,TP,ACT,1.0	CHEMBL2023158,TP,ACT,1.0	CHEMBL1922129,TP,ACT,1.0	CHEMBL1688209,TN,INACT,0.11999999731779099	CHEMBL584291,TP,ACT,0.9900000095367432	CHEMBL2163611,TN,INACT,0.23999999463558197	CHEMBL578643,TP,ACT,0.9800000190734863	CHEMBL591285,TP,ACT,0.9399999976158142	CHEMBL3581124,TP,ACT,0.9900000095367432	CHEMBL575940,TP,ACT,0.9599999785423279	CHEMBL483401,TP,ACT,0.9800000190734863	CHEMBL1097190,TN,INACT,0.12999999523162842	CHEMBL1667964,FN,ACT,0.05000000074505806	CHEMBL2163608,TN,INACT,0.009999999776482582	CHEMBL1287914,TN,INACT,0.009999999776482582	CHEMBL598336,TP,ACT,0.9800000190734863	CHEMBL201307,TN,INACT,0.6899999976158142	CHEMBL1922034,TP,ACT,1.0	CHEMBL523695,TP,ACT,0.9900000095367432	

