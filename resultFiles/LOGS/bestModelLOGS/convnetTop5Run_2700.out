ImageNetInceptionV2 CHEMBL4898 adam 0.001 30 0 0 0.6 False True
Number of active compounds :	159
Number of inactive compounds :	159
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4898_adam_0.001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4898_adam_0.001_30_0.6/
---------------------------------
Training samples: 202
Validation samples: 64
--
Training Step: 1  | time: 425.385s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/202
[A[ATraining Step: 2  | total loss: [1m[32m0.65654[0m[0m | time: 962.121s
[2K
| Adam | epoch: 001 | loss: 0.65654 - acc: 0.4219 -- iter: 064/202
[A[ATraining Step: 3  | total loss: [1m[32m0.66286[0m[0m | time: 1407.464s
[2K
| Adam | epoch: 001 | loss: 0.66286 - acc: 0.5625 -- iter: 096/202
[A[ATraining Step: 4  | total loss: [1m[32m0.61820[0m[0m | time: 1950.281s
[2K
| Adam | epoch: 001 | loss: 0.61820 - acc: 0.6562 -- iter: 128/202
[A[ATraining Step: 5  | total loss: [1m[32m0.78879[0m[0m | time: 2374.792s
[2K
| Adam | epoch: 001 | loss: 0.78879 - acc: 0.5481 -- iter: 160/202
[A[ATraining Step: 6  | total loss: [1m[32m0.66213[0m[0m | time: 2581.230s
[2K
| Adam | epoch: 001 | loss: 0.66213 - acc: 0.6578 -- iter: 192/202
[A[ATraining Step: 7  | total loss: [1m[32m0.61855[0m[0m | time: 2727.993s
[2K
| Adam | epoch: 001 | loss: 0.61855 - acc: 0.7319 | val_loss: 0.74801 - val_acc: 0.5469 -- iter: 202/202
--
Training Step: 8  | total loss: [1m[32m0.51365[0m[0m | time: 88.166s
[2K
| Adam | epoch: 002 | loss: 0.51365 - acc: 0.7702 -- iter: 032/202
[A[ATraining Step: 9  | total loss: [1m[32m0.30351[0m[0m | time: 244.960s
[2K
| Adam | epoch: 002 | loss: 0.30351 - acc: 0.8919 -- iter: 064/202
[A[ATraining Step: 10  | total loss: [1m[32m0.39384[0m[0m | time: 316.650s
[2K
| Adam | epoch: 002 | loss: 0.39384 - acc: 0.8522 -- iter: 096/202
[A[ATraining Step: 11  | total loss: [1m[32m0.37938[0m[0m | time: 456.293s
[2K
| Adam | epoch: 002 | loss: 0.37938 - acc: 0.8334 -- iter: 128/202
[A[ATraining Step: 12  | total loss: [1m[32m0.34471[0m[0m | time: 575.646s
[2K
| Adam | epoch: 002 | loss: 0.34471 - acc: 0.8662 -- iter: 160/202
[A[ATraining Step: 13  | total loss: [1m[32m0.35368[0m[0m | time: 637.415s
[2K
| Adam | epoch: 002 | loss: 0.35368 - acc: 0.8700 -- iter: 192/202
[A[ATraining Step: 14  | total loss: [1m[32m0.34376[0m[0m | time: 789.122s
[2K
| Adam | epoch: 002 | loss: 0.34376 - acc: 0.8592 | val_loss: 1.17655 - val_acc: 0.4531 -- iter: 202/202
--
Training Step: 15  | total loss: [1m[32m0.38788[0m[0m | time: 16.800s
[2K
| Adam | epoch: 003 | loss: 0.38788 - acc: 0.8409 -- iter: 032/202
[A[ATraining Step: 16  | total loss: [1m[32m0.62618[0m[0m | time: 54.952s
[2K
| Adam | epoch: 003 | loss: 0.62618 - acc: 0.7881 -- iter: 064/202
[A[ATraining Step: 17  | total loss: [1m[32m0.54031[0m[0m | time: 219.146s
[2K
| Adam | epoch: 003 | loss: 0.54031 - acc: 0.8284 -- iter: 096/202
[A[ATraining Step: 18  | total loss: [1m[32m0.47115[0m[0m | time: 351.769s
[2K
| Adam | epoch: 003 | loss: 0.47115 - acc: 0.8229 -- iter: 128/202
[A[ATraining Step: 19  | total loss: [1m[32m0.42386[0m[0m | time: 411.100s
[2K
| Adam | epoch: 003 | loss: 0.42386 - acc: 0.8403 -- iter: 160/202
[A[ATraining Step: 20  | total loss: [1m[32m0.42094[0m[0m | time: 528.647s
[2K
| Adam | epoch: 003 | loss: 0.42094 - acc: 0.8112 -- iter: 192/202
[A[ATraining Step: 21  | total loss: [1m[32m0.38112[0m[0m | time: 592.775s
[2K
| Adam | epoch: 003 | loss: 0.38112 - acc: 0.8407 | val_loss: 1.14297 - val_acc: 0.5469 -- iter: 202/202
--
Training Step: 22  | total loss: [1m[32m0.31851[0m[0m | time: 67.695s
[2K
| Adam | epoch: 004 | loss: 0.31851 - acc: 0.8698 -- iter: 032/202
[A[ATraining Step: 23  | total loss: [1m[32m0.32945[0m[0m | time: 75.363s
[2K
| Adam | epoch: 004 | loss: 0.32945 - acc: 0.8713 -- iter: 064/202
[A[ATraining Step: 24  | total loss: [1m[32m0.27144[0m[0m | time: 82.252s
[2K
| Adam | epoch: 004 | loss: 0.27144 - acc: 0.9075 -- iter: 096/202
[A[ATraining Step: 25  | total loss: [1m[32m0.20913[0m[0m | time: 101.285s
[2K
| Adam | epoch: 004 | loss: 0.20913 - acc: 0.9327 -- iter: 128/202
[A[ATraining Step: 26  | total loss: [1m[32m0.17254[0m[0m | time: 188.711s
[2K
| Adam | epoch: 004 | loss: 0.17254 - acc: 0.9505 -- iter: 160/202
[A[ATraining Step: 27  | total loss: [1m[32m0.17050[0m[0m | time: 222.965s
[2K
| Adam | epoch: 004 | loss: 0.17050 - acc: 0.9391 -- iter: 192/202
[A[ATraining Step: 28  | total loss: [1m[32m0.17608[0m[0m | time: 268.068s
[2K
| Adam | epoch: 004 | loss: 0.17608 - acc: 0.9387 | val_loss: 1.59013 - val_acc: 0.5469 -- iter: 202/202
--
Training Step: 29  | total loss: [1m[32m0.14577[0m[0m | time: 115.573s
[2K
| Adam | epoch: 005 | loss: 0.14577 - acc: 0.9536 -- iter: 032/202
[A[ATraining Step: 30  | total loss: [1m[32m0.12008[0m[0m | time: 144.807s
[2K
| Adam | epoch: 005 | loss: 0.12008 - acc: 0.9646 -- iter: 064/202
[A[ATraining Step: 31  | total loss: [1m[32m0.09962[0m[0m | time: 152.311s
[2K
| Adam | epoch: 005 | loss: 0.09962 - acc: 0.9728 -- iter: 096/202
[A[ATraining Step: 32  | total loss: [1m[32m0.10363[0m[0m | time: 159.390s
[2K
| Adam | epoch: 005 | loss: 0.10363 - acc: 0.9789 -- iter: 128/202
[A[ATraining Step: 33  | total loss: [1m[32m0.09225[0m[0m | time: 196.163s
[2K
| Adam | epoch: 005 | loss: 0.09225 - acc: 0.9835 -- iter: 160/202
[A[ATraining Step: 34  | total loss: [1m[32m0.10322[0m[0m | time: 216.998s
[2K
| Adam | epoch: 005 | loss: 0.10322 - acc: 0.9737 -- iter: 192/202
[A[ATraining Step: 35  | total loss: [1m[32m0.09530[0m[0m | time: 295.187s
[2K
| Adam | epoch: 005 | loss: 0.09530 - acc: 0.9726 | val_loss: 1.19237 - val_acc: 0.5469 -- iter: 202/202
--
Training Step: 36  | total loss: [1m[32m0.08118[0m[0m | time: 23.353s
[2K
| Adam | epoch: 006 | loss: 0.08118 - acc: 0.9782 -- iter: 032/202
[A[ATraining Step: 37  | total loss: [1m[32m0.08798[0m[0m | time: 111.723s
[2K
| Adam | epoch: 006 | loss: 0.08798 - acc: 0.9763 -- iter: 064/202
[A[ATraining Step: 38  | total loss: [1m[32m0.12620[0m[0m | time: 129.846s
[2K
| Adam | epoch: 006 | loss: 0.12620 - acc: 0.9626 -- iter: 096/202
[A[ATraining Step: 39  | total loss: [1m[32m0.10700[0m[0m | time: 137.274s
[2K
| Adam | epoch: 006 | loss: 0.10700 - acc: 0.9698 -- iter: 128/202
[A[ATraining Step: 40  | total loss: [1m[32m0.11681[0m[0m | time: 145.007s
[2K
| Adam | epoch: 006 | loss: 0.11681 - acc: 0.9567 -- iter: 160/202
[A[ATraining Step: 41  | total loss: [1m[32m0.13976[0m[0m | time: 166.929s
[2K
| Adam | epoch: 006 | loss: 0.13976 - acc: 0.9463 -- iter: 192/202
[A[ATraining Step: 42  | total loss: [1m[32m0.16672[0m[0m | time: 192.205s
[2K
| Adam | epoch: 006 | loss: 0.16672 - acc: 0.9391 | val_loss: 0.63277 - val_acc: 0.5469 -- iter: 202/202
--
Training Step: 43  | total loss: [1m[32m0.17535[0m[0m | time: 20.506s
[2K
| Adam | epoch: 007 | loss: 0.17535 - acc: 0.9388 -- iter: 032/202
[A[ATraining Step: 44  | total loss: [1m[32m0.21773[0m[0m | time: 80.666s
[2K
| Adam | epoch: 007 | loss: 0.21773 - acc: 0.9278 -- iter: 064/202
[A[ATraining Step: 45  | total loss: [1m[32m0.19318[0m[0m | time: 105.105s
[2K
| Adam | epoch: 007 | loss: 0.19318 - acc: 0.9347 -- iter: 096/202
[A[ATraining Step: 46  | total loss: [1m[32m0.17991[0m[0m | time: 164.284s
[2K
| Adam | epoch: 007 | loss: 0.17991 - acc: 0.9352 -- iter: 128/202
[A[ATraining Step: 47  | total loss: [1m[32m0.19160[0m[0m | time: 171.842s
[2K
| Adam | epoch: 007 | loss: 0.19160 - acc: 0.9304 -- iter: 160/202
[A[ATraining Step: 48  | total loss: [1m[32m0.19892[0m[0m | time: 178.670s
[2K
| Adam | epoch: 007 | loss: 0.19892 - acc: 0.9256 -- iter: 192/202
[A[ATraining Step: 49  | total loss: [1m[32m0.17488[0m[0m | time: 208.973s
[2K
| Adam | epoch: 007 | loss: 0.17488 - acc: 0.9373 | val_loss: 0.69095 - val_acc: 0.7031 -- iter: 202/202
--
Training Step: 50  | total loss: [1m[32m0.16757[0m[0m | time: 42.100s
[2K
| Adam | epoch: 008 | loss: 0.16757 - acc: 0.9422 -- iter: 032/202
[A[ATraining Step: 51  | total loss: [1m[32m0.16411[0m[0m | time: 60.299s
[2K
| Adam | epoch: 008 | loss: 0.16411 - acc: 0.9415 -- iter: 064/202
[A[ATraining Step: 52  | total loss: [1m[32m0.16550[0m[0m | time: 115.254s
[2K
| Adam | epoch: 008 | loss: 0.16550 - acc: 0.9409 -- iter: 096/202
[A[ATraining Step: 53  | total loss: [1m[32m0.15796[0m[0m | time: 133.550s
[2K
| Adam | epoch: 008 | loss: 0.15796 - acc: 0.9450 -- iter: 128/202
[A[ATraining Step: 54  | total loss: [1m[32m0.18143[0m[0m | time: 153.100s
[2K
| Adam | epoch: 008 | loss: 0.18143 - acc: 0.9303 -- iter: 160/202
[A[ATraining Step: 55  | total loss: [1m[32m0.16368[0m[0m | time: 160.993s
[2K
| Adam | epoch: 008 | loss: 0.16368 - acc: 0.9403 -- iter: 192/202
[A[ATraining Step: 56  | total loss: [1m[32m0.14370[0m[0m | time: 175.668s
[2K
| Adam | epoch: 008 | loss: 0.14370 - acc: 0.9487 | val_loss: 1.62345 - val_acc: 0.6719 -- iter: 202/202
--
Training Step: 57  | total loss: [1m[32m0.12620[0m[0m | time: 18.871s
[2K
| Adam | epoch: 009 | loss: 0.12620 - acc: 0.9558 -- iter: 032/202
[A[ATraining Step: 58  | total loss: [1m[32m0.11917[0m[0m | time: 37.137s
[2K
| Adam | epoch: 009 | loss: 0.11917 - acc: 0.9618 -- iter: 064/202
[A[ATraining Step: 59  | total loss: [1m[32m0.10937[0m[0m | time: 70.993s
[2K
| Adam | epoch: 009 | loss: 0.10937 - acc: 0.9627 -- iter: 096/202
[A[ATraining Step: 60  | total loss: [1m[32m0.11132[0m[0m | time: 139.965s
[2K
| Adam | epoch: 009 | loss: 0.11132 - acc: 0.9635 -- iter: 128/202
[A[ATraining Step: 61  | total loss: [1m[32m0.11535[0m[0m | time: 196.130s
[2K
| Adam | epoch: 009 | loss: 0.11535 - acc: 0.9601 -- iter: 160/202
[A[ATraining Step: 62  | total loss: [1m[32m0.11116[0m[0m | time: 227.040s
[2K
| Adam | epoch: 009 | loss: 0.11116 - acc: 0.9653 -- iter: 192/202
[A[ATraining Step: 63  | total loss: [1m[32m0.10939[0m[0m | time: 248.310s
[2K
| Adam | epoch: 009 | loss: 0.10939 - acc: 0.9657 | val_loss: 0.92692 - val_acc: 0.7344 -- iter: 202/202
--
Training Step: 64  | total loss: [1m[32m0.61856[0m[0m | time: 12.532s
[2K
| Adam | epoch: 010 | loss: 0.61856 - acc: 0.8950 -- iter: 032/202
[A[ATraining Step: 65  | total loss: [1m[32m0.57255[0m[0m | time: 57.012s
[2K
| Adam | epoch: 010 | loss: 0.57255 - acc: 0.8833 -- iter: 064/202
[A[ATraining Step: 66  | total loss: [1m[32m0.51116[0m[0m | time: 90.865s
[2K
| Adam | epoch: 010 | loss: 0.51116 - acc: 0.8937 -- iter: 096/202
[A[ATraining Step: 67  | total loss: [1m[32m0.46234[0m[0m | time: 120.497s
[2K
| Adam | epoch: 010 | loss: 0.46234 - acc: 0.8989 -- iter: 128/202
[A[ATraining Step: 68  | total loss: [1m[32m0.47267[0m[0m | time: 141.763s
[2K
| Adam | epoch: 010 | loss: 0.47267 - acc: 0.8887 -- iter: 160/202
[A[ATraining Step: 69  | total loss: [1m[32m0.43893[0m[0m | time: 183.382s
[2K
| Adam | epoch: 010 | loss: 0.43893 - acc: 0.8907 -- iter: 192/202
[A[ATraining Step: 70  | total loss: [1m[32m0.41320[0m[0m | time: 215.425s
[2K
| Adam | epoch: 010 | loss: 0.41320 - acc: 0.8925 | val_loss: 2.84573 - val_acc: 0.4844 -- iter: 202/202
--
Training Step: 71  | total loss: [1m[32m0.38021[0m[0m | time: 16.395s
[2K
| Adam | epoch: 011 | loss: 0.38021 - acc: 0.9012 -- iter: 032/202
[A[ATraining Step: 72  | total loss: [1m[32m0.44987[0m[0m | time: 23.541s
[2K
| Adam | epoch: 011 | loss: 0.44987 - acc: 0.8898 -- iter: 064/202
[A[ATraining Step: 73  | total loss: [1m[32m0.43076[0m[0m | time: 41.442s
[2K
| Adam | epoch: 011 | loss: 0.43076 - acc: 0.8910 -- iter: 096/202
[A[ATraining Step: 74  | total loss: [1m[32m0.41095[0m[0m | time: 67.079s
[2K
| Adam | epoch: 011 | loss: 0.41095 - acc: 0.8892 -- iter: 128/202
[A[ATraining Step: 75  | total loss: [1m[32m0.37899[0m[0m | time: 113.936s
[2K
| Adam | epoch: 011 | loss: 0.37899 - acc: 0.8944 -- iter: 160/202
[A[ATraining Step: 76  | total loss: [1m[32m0.37275[0m[0m | time: 134.254s
[2K
| Adam | epoch: 011 | loss: 0.37275 - acc: 0.8957 -- iter: 192/202
[A[ATraining Step: 77  | total loss: [1m[32m0.35383[0m[0m | time: 203.086s
[2K
| Adam | epoch: 011 | loss: 0.35383 - acc: 0.8935 | val_loss: 4.72909 - val_acc: 0.4531 -- iter: 202/202
--
Training Step: 78  | total loss: [1m[32m0.32594[0m[0m | time: 33.097s
[2K
| Adam | epoch: 012 | loss: 0.32594 - acc: 0.9014 -- iter: 032/202
[A[ATraining Step: 79  | total loss: [1m[32m0.29794[0m[0m | time: 40.357s
[2K
| Adam | epoch: 012 | loss: 0.29794 - acc: 0.9116 -- iter: 064/202
[A[ATraining Step: 80  | total loss: [1m[32m0.26944[0m[0m | time: 50.367s
[2K
| Adam | epoch: 012 | loss: 0.26944 - acc: 0.9206 -- iter: 096/202
[A[ATraining Step: 81  | total loss: [1m[32m0.24402[0m[0m | time: 73.671s
[2K
| Adam | epoch: 012 | loss: 0.24402 - acc: 0.9287 -- iter: 128/202
[A[ATraining Step: 82  | total loss: [1m[32m0.22331[0m[0m | time: 111.258s
[2K
| Adam | epoch: 012 | loss: 0.22331 - acc: 0.9358 -- iter: 160/202
[A[ATraining Step: 83  | total loss: [1m[32m0.20376[0m[0m | time: 157.286s
[2K
| Adam | epoch: 012 | loss: 0.20376 - acc: 0.9422 -- iter: 192/202
[A[ATraining Step: 84  | total loss: [1m[32m0.18653[0m[0m | time: 185.703s
[2K
| Adam | epoch: 012 | loss: 0.18653 - acc: 0.9480 | val_loss: 0.48156 - val_acc: 0.8438 -- iter: 202/202
--
Training Step: 85  | total loss: [1m[32m0.17013[0m[0m | time: 51.656s
[2K
| Adam | epoch: 013 | loss: 0.17013 - acc: 0.9532 -- iter: 032/202
[A[ATraining Step: 86  | total loss: [1m[32m0.15451[0m[0m | time: 100.159s
[2K
| Adam | epoch: 013 | loss: 0.15451 - acc: 0.9579 -- iter: 064/202
[A[ATraining Step: 87  | total loss: [1m[32m0.14605[0m[0m | time: 112.342s
[2K
| Adam | epoch: 013 | loss: 0.14605 - acc: 0.9590 -- iter: 096/202
[A[ATraining Step: 88  | total loss: [1m[32m0.18927[0m[0m | time: 119.605s
[2K
| Adam | epoch: 013 | loss: 0.18927 - acc: 0.9531 -- iter: 128/202
[A[ATraining Step: 89  | total loss: [1m[32m0.17213[0m[0m | time: 138.660s
[2K
| Adam | epoch: 013 | loss: 0.17213 - acc: 0.9578 -- iter: 160/202
[A[ATraining Step: 90  | total loss: [1m[32m0.15638[0m[0m | time: 159.550s
[2K
| Adam | epoch: 013 | loss: 0.15638 - acc: 0.9620 -- iter: 192/202
[A[ATraining Step: 91  | total loss: [1m[32m0.14385[0m[0m | time: 214.106s
[2K
| Adam | epoch: 013 | loss: 0.14385 - acc: 0.9658 | val_loss: 0.26518 - val_acc: 0.9219 -- iter: 202/202
--
Training Step: 92  | total loss: [1m[32m0.13463[0m[0m | time: 18.998s
[2K
| Adam | epoch: 014 | loss: 0.13463 - acc: 0.9661 -- iter: 032/202
[A[ATraining Step: 93  | total loss: [1m[32m0.12509[0m[0m | time: 38.901s
[2K
| Adam | epoch: 014 | loss: 0.12509 - acc: 0.9695 -- iter: 064/202
[A[ATraining Step: 94  | total loss: [1m[32m0.12963[0m[0m | time: 58.790s
[2K
| Adam | epoch: 014 | loss: 0.12963 - acc: 0.9663 -- iter: 096/202
[A[ATraining Step: 95  | total loss: [1m[32m0.11857[0m[0m | time: 68.308s
[2K
| Adam | epoch: 014 | loss: 0.11857 - acc: 0.9696 -- iter: 128/202
[A[ATraining Step: 96  | total loss: [1m[32m0.10685[0m[0m | time: 76.134s
[2K
| Adam | epoch: 014 | loss: 0.10685 - acc: 0.9727 -- iter: 160/202
[A[ATraining Step: 97  | total loss: [1m[32m0.11000[0m[0m | time: 93.517s
[2K
| Adam | epoch: 014 | loss: 0.11000 - acc: 0.9754 -- iter: 192/202
[A[ATraining Step: 98  | total loss: [1m[32m0.10294[0m[0m | time: 130.360s
[2K
| Adam | epoch: 014 | loss: 0.10294 - acc: 0.9747 | val_loss: 1.58735 - val_acc: 0.5781 -- iter: 202/202
--
Training Step: 99  | total loss: [1m[32m0.09402[0m[0m | time: 36.130s
[2K
| Adam | epoch: 015 | loss: 0.09402 - acc: 0.9773 -- iter: 032/202
[A[ATraining Step: 100  | total loss: [1m[32m0.08610[0m[0m | time: 67.082s
[2K
| Adam | epoch: 015 | loss: 0.08610 - acc: 0.9795 -- iter: 064/202
[A[ATraining Step: 101  | total loss: [1m[32m0.07967[0m[0m | time: 91.550s
[2K
| Adam | epoch: 015 | loss: 0.07967 - acc: 0.9816 -- iter: 096/202
[A[ATraining Step: 102  | total loss: [1m[32m0.08221[0m[0m | time: 124.286s
[2K
| Adam | epoch: 015 | loss: 0.08221 - acc: 0.9803 -- iter: 128/202
[A[ATraining Step: 103  | total loss: [1m[32m0.07744[0m[0m | time: 131.552s
[2K
| Adam | epoch: 015 | loss: 0.07744 - acc: 0.9823 -- iter: 160/202
[A[ATraining Step: 104  | total loss: [1m[32m0.07239[0m[0m | time: 140.088s
[2K
| Adam | epoch: 015 | loss: 0.07239 - acc: 0.9840 -- iter: 192/202
[A[ATraining Step: 105  | total loss: [1m[32m0.06788[0m[0m | time: 167.616s
[2K
| Adam | epoch: 015 | loss: 0.06788 - acc: 0.9856 | val_loss: 0.42523 - val_acc: 0.8281 -- iter: 202/202
--
Training Step: 106  | total loss: [1m[32m0.06264[0m[0m | time: 62.595s
[2K
| Adam | epoch: 016 | loss: 0.06264 - acc: 0.9871 -- iter: 032/202
[A[ATraining Step: 107  | total loss: [1m[32m0.05832[0m[0m | time: 86.166s
[2K
| Adam | epoch: 016 | loss: 0.05832 - acc: 0.9884 -- iter: 064/202
[A[ATraining Step: 108  | total loss: [1m[32m0.06227[0m[0m | time: 107.137s
[2K
| Adam | epoch: 016 | loss: 0.06227 - acc: 0.9864 -- iter: 096/202
[A[ATraining Step: 109  | total loss: [1m[32m0.05669[0m[0m | time: 126.276s
[2K
| Adam | epoch: 016 | loss: 0.05669 - acc: 0.9878 -- iter: 128/202
[A[ATraining Step: 110  | total loss: [1m[32m0.05340[0m[0m | time: 144.696s
[2K
| Adam | epoch: 016 | loss: 0.05340 - acc: 0.9890 -- iter: 160/202
[A[ATraining Step: 111  | total loss: [1m[32m0.05156[0m[0m | time: 152.314s
[2K
| Adam | epoch: 016 | loss: 0.05156 - acc: 0.9901 -- iter: 192/202
[A[ATraining Step: 112  | total loss: [1m[32m0.14079[0m[0m | time: 179.535s
[2K
| Adam | epoch: 016 | loss: 0.14079 - acc: 0.9811 | val_loss: 0.27792 - val_acc: 0.8750 -- iter: 202/202
--
Training Step: 113  | total loss: [1m[32m0.12763[0m[0m | time: 64.153s
[2K
| Adam | epoch: 017 | loss: 0.12763 - acc: 0.9830 -- iter: 032/202
[A[ATraining Step: 114  | total loss: [1m[32m0.11968[0m[0m | time: 149.751s
[2K
| Adam | epoch: 017 | loss: 0.11968 - acc: 0.9847 -- iter: 064/202
[A[ATraining Step: 115  | total loss: [1m[32m0.10982[0m[0m | time: 187.189s
[2K
| Adam | epoch: 017 | loss: 0.10982 - acc: 0.9862 -- iter: 096/202
[A[ATraining Step: 116  | total loss: [1m[32m0.10523[0m[0m | time: 237.635s
[2K
| Adam | epoch: 017 | loss: 0.10523 - acc: 0.9876 -- iter: 128/202
[A[ATraining Step: 117  | total loss: [1m[32m0.09525[0m[0m | time: 262.456s
[2K
| Adam | epoch: 017 | loss: 0.09525 - acc: 0.9888 -- iter: 160/202
[A[ATraining Step: 118  | total loss: [1m[32m0.08633[0m[0m | time: 322.971s
[2K
| Adam | epoch: 017 | loss: 0.08633 - acc: 0.9899 -- iter: 192/202
[A[ATraining Step: 119  | total loss: [1m[32m0.07924[0m[0m | time: 358.772s
[2K
| Adam | epoch: 017 | loss: 0.07924 - acc: 0.9910 | val_loss: 0.32620 - val_acc: 0.8438 -- iter: 202/202
--
Training Step: 120  | total loss: [1m[32m0.13844[0m[0m | time: 9.139s
[2K
| Adam | epoch: 018 | loss: 0.13844 - acc: 0.9819 -- iter: 032/202
[A[ATraining Step: 121  | total loss: [1m[32m0.12664[0m[0m | time: 48.817s
[2K
| Adam | epoch: 018 | loss: 0.12664 - acc: 0.9837 -- iter: 064/202
[A[ATraining Step: 122  | total loss: [1m[32m0.12437[0m[0m | time: 95.786s
[2K
| Adam | epoch: 018 | loss: 0.12437 - acc: 0.9822 -- iter: 096/202
[A[ATraining Step: 123  | total loss: [1m[32m0.12308[0m[0m | time: 110.253s
[2K
| Adam | epoch: 018 | loss: 0.12308 - acc: 0.9777 -- iter: 128/202
[A[ATraining Step: 124  | total loss: [1m[32m0.11262[0m[0m | time: 118.926s
[2K
| Adam | epoch: 018 | loss: 0.11262 - acc: 0.9799 -- iter: 160/202
[A[ATraining Step: 125  | total loss: [1m[32m0.11007[0m[0m | time: 128.731s
[2K
| Adam | epoch: 018 | loss: 0.11007 - acc: 0.9788 -- iter: 192/202
[A[ATraining Step: 126  | total loss: [1m[32m0.10057[0m[0m | time: 159.385s
[2K
| Adam | epoch: 018 | loss: 0.10057 - acc: 0.9809 | val_loss: 1.22953 - val_acc: 0.7031 -- iter: 202/202
--
Training Step: 127  | total loss: [1m[32m0.09254[0m[0m | time: 7.691s
[2K
| Adam | epoch: 019 | loss: 0.09254 - acc: 0.9828 -- iter: 032/202
[A[ATraining Step: 128  | total loss: [1m[32m0.43370[0m[0m | time: 15.240s
[2K
| Adam | epoch: 019 | loss: 0.43370 - acc: 0.9446 -- iter: 064/202
[A[ATraining Step: 129  | total loss: [1m[32m0.39114[0m[0m | time: 56.740s
[2K
| Adam | epoch: 019 | loss: 0.39114 - acc: 0.9501 -- iter: 096/202
[A[ATraining Step: 130  | total loss: [1m[32m0.36297[0m[0m | time: 92.394s
[2K
| Adam | epoch: 019 | loss: 0.36297 - acc: 0.9488 -- iter: 128/202
[A[ATraining Step: 131  | total loss: [1m[32m0.33121[0m[0m | time: 111.571s
[2K
| Adam | epoch: 019 | loss: 0.33121 - acc: 0.9540 -- iter: 160/202
[A[ATraining Step: 132  | total loss: [1m[32m0.30729[0m[0m | time: 157.519s
[2K
| Adam | epoch: 019 | loss: 0.30729 - acc: 0.9554 -- iter: 192/202
[A[ATraining Step: 133  | total loss: [1m[32m0.28051[0m[0m | time: 244.739s
[2K
| Adam | epoch: 019 | loss: 0.28051 - acc: 0.9568 | val_loss: 0.24562 - val_acc: 0.9062 -- iter: 202/202
--
Training Step: 134  | total loss: [1m[32m0.25554[0m[0m | time: 27.807s
[2K
| Adam | epoch: 020 | loss: 0.25554 - acc: 0.9611 -- iter: 032/202
[A[ATraining Step: 135  | total loss: [1m[32m0.23220[0m[0m | time: 35.704s
[2K
| Adam | epoch: 020 | loss: 0.23220 - acc: 0.9650 -- iter: 064/202
[A[ATraining Step: 136  | total loss: [1m[32m0.21009[0m[0m | time: 46.925s
[2K
| Adam | epoch: 020 | loss: 0.21009 - acc: 0.9685 -- iter: 096/202
[A[ATraining Step: 137  | total loss: [1m[32m0.19017[0m[0m | time: 89.860s
[2K
| Adam | epoch: 020 | loss: 0.19017 - acc: 0.9716 -- iter: 128/202
[A[ATraining Step: 138  | total loss: [1m[32m0.17365[0m[0m | time: 144.293s
[2K
| Adam | epoch: 020 | loss: 0.17365 - acc: 0.9745 -- iter: 160/202
[A[ATraining Step: 139  | total loss: [1m[32m0.15813[0m[0m | time: 162.808s
[2K
| Adam | epoch: 020 | loss: 0.15813 - acc: 0.9770 -- iter: 192/202
[A[ATraining Step: 140  | total loss: [1m[32m0.14944[0m[0m | time: 244.695s
[2K
| Adam | epoch: 020 | loss: 0.14944 - acc: 0.9762 | val_loss: 0.21045 - val_acc: 0.9375 -- iter: 202/202
--
Training Step: 141  | total loss: [1m[32m0.13625[0m[0m | time: 37.343s
[2K
| Adam | epoch: 021 | loss: 0.13625 - acc: 0.9786 -- iter: 032/202
[A[ATraining Step: 142  | total loss: [1m[32m0.13232[0m[0m | time: 59.621s
[2K
| Adam | epoch: 021 | loss: 0.13232 - acc: 0.9776 -- iter: 064/202
[A[ATraining Step: 143  | total loss: [1m[32m0.12016[0m[0m | time: 67.165s
[2K
| Adam | epoch: 021 | loss: 0.12016 - acc: 0.9798 -- iter: 096/202
[A[ATraining Step: 144  | total loss: [1m[32m0.21842[0m[0m | time: 74.377s
[2K
| Adam | epoch: 021 | loss: 0.21842 - acc: 0.9719 -- iter: 128/202
[A[ATraining Step: 145  | total loss: [1m[32m0.19826[0m[0m | time: 100.104s
[2K
| Adam | epoch: 021 | loss: 0.19826 - acc: 0.9747 -- iter: 160/202
[A[ATraining Step: 146  | total loss: [1m[32m0.18117[0m[0m | time: 126.901s
[2K
| Adam | epoch: 021 | loss: 0.18117 - acc: 0.9772 -- iter: 192/202
[A[ATraining Step: 147  | total loss: [1m[32m0.16863[0m[0m | time: 233.862s
[2K
| Adam | epoch: 021 | loss: 0.16863 - acc: 0.9764 | val_loss: 0.38527 - val_acc: 0.8594 -- iter: 202/202
--
Training Step: 148  | total loss: [1m[32m0.15310[0m[0m | time: 42.089s
[2K
| Adam | epoch: 022 | loss: 0.15310 - acc: 0.9787 -- iter: 032/202
[A[ATraining Step: 149  | total loss: [1m[32m0.14576[0m[0m | time: 86.218s
[2K
| Adam | epoch: 022 | loss: 0.14576 - acc: 0.9777 -- iter: 064/202
[A[ATraining Step: 150  | total loss: [1m[32m0.13350[0m[0m | time: 112.836s
[2K
| Adam | epoch: 022 | loss: 0.13350 - acc: 0.9800 -- iter: 096/202
[A[ATraining Step: 151  | total loss: [1m[32m0.12317[0m[0m | time: 121.153s
[2K
| Adam | epoch: 022 | loss: 0.12317 - acc: 0.9820 -- iter: 128/202
[A[ATraining Step: 152  | total loss: [1m[32m0.28796[0m[0m | time: 128.325s
[2K
| Adam | epoch: 022 | loss: 0.28796 - acc: 0.9538 -- iter: 160/202
[A[ATraining Step: 153  | total loss: [1m[32m0.26889[0m[0m | time: 146.243s
[2K
| Adam | epoch: 022 | loss: 0.26889 - acc: 0.9584 -- iter: 192/202
[A[ATraining Step: 154  | total loss: [1m[32m0.24432[0m[0m | time: 190.417s
[2K
| Adam | epoch: 022 | loss: 0.24432 - acc: 0.9625 | val_loss: 0.34298 - val_acc: 0.8281 -- iter: 202/202
--
Training Step: 155  | total loss: [1m[32m0.22329[0m[0m | time: 42.502s
[2K
| Adam | epoch: 023 | loss: 0.22329 - acc: 0.9663 -- iter: 032/202
[A[ATraining Step: 156  | total loss: [1m[32m0.21471[0m[0m | time: 65.060s
[2K
| Adam | epoch: 023 | loss: 0.21471 - acc: 0.9634 -- iter: 064/202
[A[ATraining Step: 157  | total loss: [1m[32m0.20035[0m[0m | time: 102.125s
[2K
| Adam | epoch: 023 | loss: 0.20035 - acc: 0.9671 -- iter: 096/202
[A[ATraining Step: 158  | total loss: [1m[32m0.19430[0m[0m | time: 135.406s
[2K
| Adam | epoch: 023 | loss: 0.19430 - acc: 0.9672 -- iter: 128/202
[A[ATraining Step: 159  | total loss: [1m[32m0.18070[0m[0m | time: 142.304s
[2K
| Adam | epoch: 023 | loss: 0.18070 - acc: 0.9705 -- iter: 160/202
[A[ATraining Step: 160  | total loss: [1m[32m0.16486[0m[0m | time: 149.994s
[2K
| Adam | epoch: 023 | loss: 0.16486 - acc: 0.9735 -- iter: 192/202
[A[ATraining Step: 161  | total loss: [1m[32m0.15063[0m[0m | time: 184.281s
[2K
| Adam | epoch: 023 | loss: 0.15063 - acc: 0.9761 | val_loss: 0.88700 - val_acc: 0.6875 -- iter: 202/202
--
Training Step: 162  | total loss: [1m[32m0.13991[0m[0m | time: 25.891s
[2K
| Adam | epoch: 024 | loss: 0.13991 - acc: 0.9785 -- iter: 032/202
[A[ATraining Step: 163  | total loss: [1m[32m0.12929[0m[0m | time: 44.410s
[2K
| Adam | epoch: 024 | loss: 0.12929 - acc: 0.9807 -- iter: 064/202
[A[ATraining Step: 164  | total loss: [1m[32m0.12400[0m[0m | time: 68.641s
[2K
| Adam | epoch: 024 | loss: 0.12400 - acc: 0.9795 -- iter: 096/202
[A[ATraining Step: 165  | total loss: [1m[32m0.11347[0m[0m | time: 110.405s
[2K
| Adam | epoch: 024 | loss: 0.11347 - acc: 0.9815 -- iter: 128/202
[A[ATraining Step: 166  | total loss: [1m[32m0.10739[0m[0m | time: 168.107s
[2K
| Adam | epoch: 024 | loss: 0.10739 - acc: 0.9834 -- iter: 160/202
[A[ATraining Step: 167  | total loss: [1m[32m0.09832[0m[0m | time: 182.453s
[2K
| Adam | epoch: 024 | loss: 0.09832 - acc: 0.9850 -- iter: 192/202
[A[ATraining Step: 168  | total loss: [1m[32m0.33055[0m[0m | time: 246.104s
[2K
| Adam | epoch: 024 | loss: 0.33055 - acc: 0.9465 | val_loss: 0.35181 - val_acc: 0.8438 -- iter: 202/202
--
Training Step: 169  | total loss: [1m[32m0.29856[0m[0m | time: 30.616s
[2K
| Adam | epoch: 025 | loss: 0.29856 - acc: 0.9519 -- iter: 032/202
[A[ATraining Step: 170  | total loss: [1m[32m0.27383[0m[0m | time: 70.998s
[2K
| Adam | epoch: 025 | loss: 0.27383 - acc: 0.9536 -- iter: 064/202
[A[ATraining Step: 171  | total loss: [1m[32m0.26016[0m[0m | time: 92.546s
[2K
| Adam | epoch: 025 | loss: 0.26016 - acc: 0.9520 -- iter: 096/202
[A[ATraining Step: 172  | total loss: [1m[32m0.23487[0m[0m | time: 128.533s
[2K
| Adam | epoch: 025 | loss: 0.23487 - acc: 0.9568 -- iter: 128/202
[A[ATraining Step: 173  | total loss: [1m[32m0.21394[0m[0m | time: 161.350s
[2K
| Adam | epoch: 025 | loss: 0.21394 - acc: 0.9611 -- iter: 160/202
[A[ATraining Step: 174  | total loss: [1m[32m0.19384[0m[0m | time: 195.220s
[2K
| Adam | epoch: 025 | loss: 0.19384 - acc: 0.9650 -- iter: 192/202
[A[ATraining Step: 175  | total loss: [1m[32m0.17745[0m[0m | time: 221.620s
[2K
| Adam | epoch: 025 | loss: 0.17745 - acc: 0.9685 | val_loss: 1.61054 - val_acc: 0.5938 -- iter: 202/202
--
Training Step: 176  | total loss: [1m[32m0.22491[0m[0m | time: 8.043s
[2K
| Adam | epoch: 026 | loss: 0.22491 - acc: 0.9616 -- iter: 032/202
[A[ATraining Step: 177  | total loss: [1m[32m0.20481[0m[0m | time: 32.864s
[2K
| Adam | epoch: 026 | loss: 0.20481 - acc: 0.9655 -- iter: 064/202
[A[ATraining Step: 178  | total loss: [1m[32m0.18822[0m[0m | time: 68.506s
[2K
| Adam | epoch: 026 | loss: 0.18822 - acc: 0.9689 -- iter: 096/202
[A[ATraining Step: 179  | total loss: [1m[32m0.17358[0m[0m | time: 94.154s
[2K
| Adam | epoch: 026 | loss: 0.17358 - acc: 0.9720 -- iter: 128/202
[A[ATraining Step: 180  | total loss: [1m[32m0.16974[0m[0m | time: 141.359s
[2K
| Adam | epoch: 026 | loss: 0.16974 - acc: 0.9686 -- iter: 160/202
[A[ATraining Step: 181  | total loss: [1m[32m0.17364[0m[0m | time: 166.733s
[2K
| Adam | epoch: 026 | loss: 0.17364 - acc: 0.9655 -- iter: 192/202
[A[ATraining Step: 182  | total loss: [1m[32m0.16256[0m[0m | time: 272.029s
[2K
| Adam | epoch: 026 | loss: 0.16256 - acc: 0.9689 | val_loss: 2.36444 - val_acc: 0.5312 -- iter: 202/202
--
Training Step: 183  | total loss: [1m[32m0.14988[0m[0m | time: 8.222s
[2K
| Adam | epoch: 027 | loss: 0.14988 - acc: 0.9720 -- iter: 032/202
[A[ATraining Step: 184  | total loss: [1m[32m0.17646[0m[0m | time: 20.625s
[2K
| Adam | epoch: 027 | loss: 0.17646 - acc: 0.9648 -- iter: 064/202
[A[ATraining Step: 185  | total loss: [1m[32m0.15926[0m[0m | time: 54.957s
[2K
| Adam | epoch: 027 | loss: 0.15926 - acc: 0.9683 -- iter: 096/202
[A[ATraining Step: 186  | total loss: [1m[32m0.14497[0m[0m | time: 104.649s
[2K
| Adam | epoch: 027 | loss: 0.14497 - acc: 0.9715 -- iter: 128/202
[A[ATraining Step: 187  | total loss: [1m[32m0.13380[0m[0m | time: 156.437s
[2K
| Adam | epoch: 027 | loss: 0.13380 - acc: 0.9744 -- iter: 160/202
[A[ATraining Step: 188  | total loss: [1m[32m0.12308[0m[0m | time: 210.116s
[2K
| Adam | epoch: 027 | loss: 0.12308 - acc: 0.9769 -- iter: 192/202
[A[ATraining Step: 189  | total loss: [1m[32m0.11619[0m[0m | time: 295.547s
[2K
| Adam | epoch: 027 | loss: 0.11619 - acc: 0.9761 | val_loss: 0.59293 - val_acc: 0.7969 -- iter: 202/202
--
Training Step: 190  | total loss: [1m[32m0.11153[0m[0m | time: 26.334s
[2K
| Adam | epoch: 028 | loss: 0.11153 - acc: 0.9754 -- iter: 032/202
[A[ATraining Step: 191  | total loss: [1m[32m0.10472[0m[0m | time: 33.458s
[2K
| Adam | epoch: 028 | loss: 0.10472 - acc: 0.9778 -- iter: 064/202
[A[ATraining Step: 192  | total loss: [1m[32m0.09543[0m[0m | time: 40.908s
[2K
| Adam | epoch: 028 | loss: 0.09543 - acc: 0.9800 -- iter: 096/202
[A[ATraining Step: 193  | total loss: [1m[32m0.09069[0m[0m | time: 59.146s
[2K
| Adam | epoch: 028 | loss: 0.09069 - acc: 0.9820 -- iter: 128/202
[A[ATraining Step: 194  | total loss: [1m[32m0.08497[0m[0m | time: 77.520s
[2K
| Adam | epoch: 028 | loss: 0.08497 - acc: 0.9838 -- iter: 160/202
[A[ATraining Step: 195  | total loss: [1m[32m0.07941[0m[0m | time: 97.466s
[2K
| Adam | epoch: 028 | loss: 0.07941 - acc: 0.9855 -- iter: 192/202
[A[ATraining Step: 196  | total loss: [1m[32m0.07393[0m[0m | time: 122.398s
[2K
| Adam | epoch: 028 | loss: 0.07393 - acc: 0.9869 | val_loss: 2.63031 - val_acc: 0.5469 -- iter: 202/202
--
Training Step: 197  | total loss: [1m[32m0.06755[0m[0m | time: 18.937s
[2K
| Adam | epoch: 029 | loss: 0.06755 - acc: 0.9882 -- iter: 032/202
[A[ATraining Step: 198  | total loss: [1m[32m0.06201[0m[0m | time: 37.478s
[2K
| Adam | epoch: 029 | loss: 0.06201 - acc: 0.9894 -- iter: 064/202
[A[ATraining Step: 199  | total loss: [1m[32m0.06798[0m[0m | time: 44.592s
[2K
| Adam | epoch: 029 | loss: 0.06798 - acc: 0.9873 -- iter: 096/202
[A[ATraining Step: 200  | total loss: [1m[32m0.13044[0m[0m | time: 58.021s
[2K
| Adam | epoch: 029 | loss: 0.13044 - acc: 0.9786 | val_loss: 2.39866 - val_acc: 0.5469 -- iter: 128/202
--
Training Step: 201  | total loss: [1m[32m0.11802[0m[0m | time: 76.488s
[2K
| Adam | epoch: 029 | loss: 0.11802 - acc: 0.9807 -- iter: 160/202
[A[ATraining Step: 202  | total loss: [1m[32m0.10924[0m[0m | time: 94.747s
[2K
| Adam | epoch: 029 | loss: 0.10924 - acc: 0.9827 -- iter: 192/202
[A[ATraining Step: 203  | total loss: [1m[32m0.09920[0m[0m | time: 121.373s
[2K
| Adam | epoch: 029 | loss: 0.09920 - acc: 0.9844 | val_loss: 1.64707 - val_acc: 0.5625 -- iter: 202/202
--
Training Step: 204  | total loss: [1m[32m0.09110[0m[0m | time: 20.964s
[2K
| Adam | epoch: 030 | loss: 0.09110 - acc: 0.9860 -- iter: 032/202
[A[ATraining Step: 205  | total loss: [1m[32m0.08321[0m[0m | time: 63.062s
[2K
| Adam | epoch: 030 | loss: 0.08321 - acc: 0.9874 -- iter: 064/202
[A[ATraining Step: 206  | total loss: [1m[32m0.07819[0m[0m | time: 81.931s
[2K
| Adam | epoch: 030 | loss: 0.07819 - acc: 0.9855 -- iter: 096/202
[A[ATraining Step: 207  | total loss: [1m[32m0.07141[0m[0m | time: 89.658s
[2K
| Adam | epoch: 030 | loss: 0.07141 - acc: 0.9870 -- iter: 128/202
[A[ATraining Step: 208  | total loss: [1m[32m0.35071[0m[0m | time: 96.052s
[2K
| Adam | epoch: 030 | loss: 0.35071 - acc: 0.9483 -- iter: 160/202
[A[ATraining Step: 209  | total loss: [1m[32m0.31670[0m[0m | time: 114.480s
[2K
| Adam | epoch: 030 | loss: 0.31670 - acc: 0.9534 -- iter: 192/202
[A[ATraining Step: 210  | total loss: [1m[32m0.28919[0m[0m | time: 140.317s
[2K
| Adam | epoch: 030 | loss: 0.28919 - acc: 0.9581 | val_loss: 0.45789 - val_acc: 0.8281 -- iter: 202/202
--
Validation AUC:0.9655172413793104
Validation AUPRC:0.9653801981899415
Test AUC:0.9226190476190476
Test AUPRC:0.9200078935679729
BestTestF1Score	0.84	0.71	0.84	0.96	0.75	27	1	27	9	0.15
BestTestMCCScore	0.84	0.71	0.84	0.96	0.75	27	1	27	9	0.15
BestTestAccuracyScore	0.84	0.71	0.84	0.96	0.75	27	1	27	9	0.15
BestValidationF1Score	0.89	0.82	0.91	0.96	0.83	24	1	34	5	0.15
BestValidationMCC	0.89	0.82	0.91	0.96	0.83	24	1	34	5	0.15
BestValidationAccuracy	0.89	0.82	0.91	0.96	0.83	24	1	34	5	0.15
TestPredictions (Threshold:0.15)
CHEMBL3673456,TP,ACT,0.9100000262260437	CHEMBL102136,TN,INACT,0.0	CHEMBL3673436,TP,ACT,0.8399999737739563	CHEMBL3582438,TP,ACT,0.5299999713897705	CHEMBL3678300,TP,ACT,0.9700000286102295	CHEMBL525538,TN,INACT,0.009999999776482582	CHEMBL3678287,TP,ACT,0.8199999928474426	CHEMBL1436125,TN,INACT,0.009999999776482582	CHEMBL388978,TP,ACT,0.5400000214576721	CHEMBL486487,TN,INACT,0.009999999776482582	CHEMBL3673467,TP,ACT,0.6800000071525574	CHEMBL562198,TN,INACT,0.009999999776482582	CHEMBL3678286,TP,ACT,0.9800000190734863	CHEMBL525921,TN,INACT,0.0	CHEMBL1784649,TN,INACT,0.009999999776482582	CHEMBL1910761,TN,INACT,0.03999999910593033	CHEMBL498130,TN,INACT,0.019999999552965164	CHEMBL2010872,FN,ACT,0.009999999776482582	CHEMBL3673448,TP,ACT,0.9900000095367432	CHEMBL2037211,TP,ACT,1.0	CHEMBL457191,TN,INACT,0.0	CHEMBL2164716,TN,INACT,0.0	CHEMBL457179,TN,INACT,0.0	CHEMBL1908397,FN,ACT,0.029999999329447746	CHEMBL1910756,TN,INACT,0.029999999329447746	CHEMBL3673465,TP,ACT,0.75	CHEMBL3128069,FN,ACT,0.14000000059604645	CHEMBL1230609,TP,ACT,0.7699999809265137	CHEMBL559683,TN,INACT,0.0	CHEMBL1929238,FN,ACT,0.019999999552965164	CHEMBL3673468,TP,ACT,1.0	CHEMBL58905,FN,ACT,0.009999999776482582	CHEMBL456759,TN,INACT,0.009999999776482582	CHEMBL3673483,TP,ACT,0.5	CHEMBL558849,TN,INACT,0.009999999776482582	CHEMBL2037226,FN,ACT,0.009999999776482582	CHEMBL318485,TN,INACT,0.009999999776482582	CHEMBL1933802,TN,INACT,0.12999999523162842	CHEMBL3408947,TP,ACT,0.15000000596046448	CHEMBL3678305,TP,ACT,0.6499999761581421	CHEMBL318188,TN,INACT,0.0	CHEMBL3673486,TP,ACT,0.7400000095367432	CHEMBL557525,TN,INACT,0.009999999776482582	CHEMBL3678285,TP,ACT,0.9900000095367432	CHEMBL1081198,FP,INACT,0.9800000190734863	CHEMBL3673476,TP,ACT,0.8500000238418579	CHEMBL2392355,TN,INACT,0.0	CHEMBL3673461,TP,ACT,0.17000000178813934	CHEMBL502835,TP,ACT,0.4099999964237213	CHEMBL490053,TN,INACT,0.009999999776482582	CHEMBL2392233,TN,INACT,0.009999999776482582	CHEMBL522892,FN,ACT,0.019999999552965164	CHEMBL3673459,TP,ACT,0.9800000190734863	CHEMBL572878,FN,ACT,0.029999999329447746	CHEMBL230761,TN,INACT,0.05999999865889549	CHEMBL3678298,TP,ACT,0.8100000023841858	CHEMBL3678293,TP,ACT,1.0	CHEMBL3582432,TP,ACT,0.5199999809265137	CHEMBL497854,FN,ACT,0.009999999776482582	CHEMBL603469,TP,ACT,0.4300000071525574	CHEMBL576982,TP,ACT,0.15000000596046448	CHEMBL2392236,TN,INACT,0.009999999776482582	CHEMBL509435,TN,INACT,0.009999999776482582	CHEMBL552136,TN,INACT,0.0	

