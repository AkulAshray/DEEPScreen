ImageNetInceptionV2 CHEMBL5113 RMSprop 0.0005 15 0 0 0.6 False True
Number of active compounds :	1564
Number of inactive compounds :	1564
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5113_RMSprop_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5113_RMSprop_0.0005_15_0.6/
---------------------------------
Training samples: 1998
Validation samples: 625
--
Training Step: 1  | time: 77.160s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1998
[A[ATraining Step: 2  | total loss: [1m[32m0.58719[0m[0m | time: 103.366s
[2K
| RMSProp | epoch: 001 | loss: 0.58719 - acc: 0.5625 -- iter: 0064/1998
[A[ATraining Step: 3  | total loss: [1m[32m0.66756[0m[0m | time: 134.160s
[2K
| RMSProp | epoch: 001 | loss: 0.66756 - acc: 0.5881 -- iter: 0096/1998
[A[ATraining Step: 4  | total loss: [1m[32m0.68668[0m[0m | time: 155.455s
[2K
| RMSProp | epoch: 001 | loss: 0.68668 - acc: 0.5923 -- iter: 0128/1998
[A[ATraining Step: 5  | total loss: [1m[32m0.75602[0m[0m | time: 173.887s
[2K
| RMSProp | epoch: 001 | loss: 0.75602 - acc: 0.3770 -- iter: 0160/1998
[A[ATraining Step: 6  | total loss: [1m[32m0.71825[0m[0m | time: 192.504s
[2K
| RMSProp | epoch: 001 | loss: 0.71825 - acc: 0.4561 -- iter: 0192/1998
[A[ATraining Step: 7  | total loss: [1m[32m0.74937[0m[0m | time: 208.120s
[2K
| RMSProp | epoch: 001 | loss: 0.74937 - acc: 0.3699 -- iter: 0224/1998
[A[ATraining Step: 8  | total loss: [1m[32m0.71395[0m[0m | time: 223.577s
[2K
| RMSProp | epoch: 001 | loss: 0.71395 - acc: 0.4958 -- iter: 0256/1998
[A[ATraining Step: 9  | total loss: [1m[32m0.67085[0m[0m | time: 239.343s
[2K
| RMSProp | epoch: 001 | loss: 0.67085 - acc: 0.5973 -- iter: 0288/1998
[A[ATraining Step: 10  | total loss: [1m[32m0.68756[0m[0m | time: 248.173s
[2K
| RMSProp | epoch: 001 | loss: 0.68756 - acc: 0.5643 -- iter: 0320/1998
[A[ATraining Step: 11  | total loss: [1m[32m0.70504[0m[0m | time: 257.145s
[2K
| RMSProp | epoch: 001 | loss: 0.70504 - acc: 0.5486 -- iter: 0352/1998
[A[ATraining Step: 12  | total loss: [1m[32m0.74018[0m[0m | time: 270.665s
[2K
| RMSProp | epoch: 001 | loss: 0.74018 - acc: 0.4142 -- iter: 0384/1998
[A[ATraining Step: 13  | total loss: [1m[32m0.73308[0m[0m | time: 287.309s
[2K
| RMSProp | epoch: 001 | loss: 0.73308 - acc: 0.4510 -- iter: 0416/1998
[A[ATraining Step: 14  | total loss: [1m[32m0.75246[0m[0m | time: 301.461s
[2K
| RMSProp | epoch: 001 | loss: 0.75246 - acc: 0.3943 -- iter: 0448/1998
[A[ATraining Step: 15  | total loss: [1m[32m0.74148[0m[0m | time: 317.922s
[2K
| RMSProp | epoch: 001 | loss: 0.74148 - acc: 0.4601 -- iter: 0480/1998
[A[ATraining Step: 16  | total loss: [1m[32m0.71714[0m[0m | time: 336.385s
[2K
| RMSProp | epoch: 001 | loss: 0.71714 - acc: 0.5102 -- iter: 0512/1998
[A[ATraining Step: 17  | total loss: [1m[32m0.73868[0m[0m | time: 351.083s
[2K
| RMSProp | epoch: 001 | loss: 0.73868 - acc: 0.4616 -- iter: 0544/1998
[A[ATraining Step: 18  | total loss: [1m[32m0.73043[0m[0m | time: 365.604s
[2K
| RMSProp | epoch: 001 | loss: 0.73043 - acc: 0.4965 -- iter: 0576/1998
[A[ATraining Step: 19  | total loss: [1m[32m0.71835[0m[0m | time: 381.833s
[2K
| RMSProp | epoch: 001 | loss: 0.71835 - acc: 0.5081 -- iter: 0608/1998
[A[ATraining Step: 20  | total loss: [1m[32m0.72151[0m[0m | time: 397.801s
[2K
| RMSProp | epoch: 001 | loss: 0.72151 - acc: 0.4954 -- iter: 0640/1998
[A[ATraining Step: 21  | total loss: [1m[32m0.71987[0m[0m | time: 406.588s
[2K
| RMSProp | epoch: 001 | loss: 0.71987 - acc: 0.4678 -- iter: 0672/1998
[A[ATraining Step: 22  | total loss: [1m[32m0.73473[0m[0m | time: 415.608s
[2K
| RMSProp | epoch: 001 | loss: 0.73473 - acc: 0.4493 -- iter: 0704/1998
[A[ATraining Step: 23  | total loss: [1m[32m0.74251[0m[0m | time: 430.411s
[2K
| RMSProp | epoch: 001 | loss: 0.74251 - acc: 0.4731 -- iter: 0736/1998
[A[ATraining Step: 24  | total loss: [1m[32m0.73819[0m[0m | time: 444.453s
[2K
| RMSProp | epoch: 001 | loss: 0.73819 - acc: 0.4631 -- iter: 0768/1998
[A[ATraining Step: 25  | total loss: [1m[32m0.72517[0m[0m | time: 458.413s
[2K
| RMSProp | epoch: 001 | loss: 0.72517 - acc: 0.4817 -- iter: 0800/1998
[A[ATraining Step: 26  | total loss: [1m[32m0.70775[0m[0m | time: 471.689s
[2K
| RMSProp | epoch: 001 | loss: 0.70775 - acc: 0.5279 -- iter: 0832/1998
[A[ATraining Step: 27  | total loss: [1m[32m0.70805[0m[0m | time: 489.627s
[2K
| RMSProp | epoch: 001 | loss: 0.70805 - acc: 0.5207 -- iter: 0864/1998
[A[ATraining Step: 28  | total loss: [1m[32m0.68789[0m[0m | time: 505.565s
[2K
| RMSProp | epoch: 001 | loss: 0.68789 - acc: 0.5702 -- iter: 0896/1998
[A[ATraining Step: 29  | total loss: [1m[32m0.70748[0m[0m | time: 520.664s
[2K
| RMSProp | epoch: 001 | loss: 0.70748 - acc: 0.5455 -- iter: 0928/1998
[A[ATraining Step: 30  | total loss: [1m[32m0.71410[0m[0m | time: 536.950s
[2K
| RMSProp | epoch: 001 | loss: 0.71410 - acc: 0.5126 -- iter: 0960/1998
[A[ATraining Step: 31  | total loss: [1m[32m0.70651[0m[0m | time: 552.334s
[2K
| RMSProp | epoch: 001 | loss: 0.70651 - acc: 0.5313 -- iter: 0992/1998
[A[ATraining Step: 32  | total loss: [1m[32m0.71778[0m[0m | time: 561.296s
[2K
| RMSProp | epoch: 001 | loss: 0.71778 - acc: 0.5172 -- iter: 1024/1998
[A[ATraining Step: 33  | total loss: [1m[32m0.72906[0m[0m | time: 570.238s
[2K
| RMSProp | epoch: 001 | loss: 0.72906 - acc: 0.4791 -- iter: 1056/1998
[A[ATraining Step: 34  | total loss: [1m[32m0.72740[0m[0m | time: 579.031s
[2K
| RMSProp | epoch: 001 | loss: 0.72740 - acc: 0.4903 -- iter: 1088/1998
[A[ATraining Step: 35  | total loss: [1m[32m0.71627[0m[0m | time: 612.140s
[2K
| RMSProp | epoch: 001 | loss: 0.71627 - acc: 0.5054 -- iter: 1120/1998
[A[ATraining Step: 36  | total loss: [1m[32m0.72108[0m[0m | time: 643.087s
[2K
| RMSProp | epoch: 001 | loss: 0.72108 - acc: 0.5107 -- iter: 1152/1998
[A[ATraining Step: 37  | total loss: [1m[32m0.71098[0m[0m | time: 683.686s
[2K
| RMSProp | epoch: 001 | loss: 0.71098 - acc: 0.5148 -- iter: 1184/1998
[A[ATraining Step: 38  | total loss: [1m[32m0.70369[0m[0m | time: 715.474s
[2K
| RMSProp | epoch: 001 | loss: 0.70369 - acc: 0.5241 -- iter: 1216/1998
[A[ATraining Step: 39  | total loss: [1m[32m0.70671[0m[0m | time: 729.492s
[2K
| RMSProp | epoch: 001 | loss: 0.70671 - acc: 0.5016 -- iter: 1248/1998
[A[ATraining Step: 40  | total loss: [1m[32m0.70603[0m[0m | time: 742.480s
[2K
| RMSProp | epoch: 001 | loss: 0.70603 - acc: 0.4954 -- iter: 1280/1998
[A[ATraining Step: 41  | total loss: [1m[32m0.70480[0m[0m | time: 755.760s
[2K
| RMSProp | epoch: 001 | loss: 0.70480 - acc: 0.4905 -- iter: 1312/1998
[A[ATraining Step: 42  | total loss: [1m[32m0.70563[0m[0m | time: 769.133s
[2K
| RMSProp | epoch: 001 | loss: 0.70563 - acc: 0.4978 -- iter: 1344/1998
[A[ATraining Step: 43  | total loss: [1m[32m0.70783[0m[0m | time: 782.938s
[2K
| RMSProp | epoch: 001 | loss: 0.70783 - acc: 0.5037 -- iter: 1376/1998
[A[ATraining Step: 44  | total loss: [1m[32m0.69923[0m[0m | time: 791.926s
[2K
| RMSProp | epoch: 001 | loss: 0.69923 - acc: 0.5139 -- iter: 1408/1998
[A[ATraining Step: 45  | total loss: [1m[32m0.70669[0m[0m | time: 800.784s
[2K
| RMSProp | epoch: 001 | loss: 0.70669 - acc: 0.5062 -- iter: 1440/1998
[A[ATraining Step: 46  | total loss: [1m[32m0.69914[0m[0m | time: 809.785s
[2K
| RMSProp | epoch: 001 | loss: 0.69914 - acc: 0.5104 -- iter: 1472/1998
[A[ATraining Step: 47  | total loss: [1m[32m0.69957[0m[0m | time: 818.849s
[2K
| RMSProp | epoch: 001 | loss: 0.69957 - acc: 0.5087 -- iter: 1504/1998
[A[ATraining Step: 48  | total loss: [1m[32m0.69295[0m[0m | time: 851.414s
[2K
| RMSProp | epoch: 001 | loss: 0.69295 - acc: 0.5274 -- iter: 1536/1998
[A[ATraining Step: 49  | total loss: [1m[32m0.68583[0m[0m | time: 880.406s
[2K
| RMSProp | epoch: 001 | loss: 0.68583 - acc: 0.5379 -- iter: 1568/1998
[A[ATraining Step: 50  | total loss: [1m[32m0.67915[0m[0m | time: 900.957s
[2K
| RMSProp | epoch: 001 | loss: 0.67915 - acc: 0.5417 -- iter: 1600/1998
[A[ATraining Step: 51  | total loss: [1m[32m0.68558[0m[0m | time: 919.904s
[2K
| RMSProp | epoch: 001 | loss: 0.68558 - acc: 0.5449 -- iter: 1632/1998
[A[ATraining Step: 52  | total loss: [1m[32m0.69404[0m[0m | time: 932.831s
[2K
| RMSProp | epoch: 001 | loss: 0.69404 - acc: 0.5335 -- iter: 1664/1998
[A[ATraining Step: 53  | total loss: [1m[32m0.68900[0m[0m | time: 945.679s
[2K
| RMSProp | epoch: 001 | loss: 0.68900 - acc: 0.5423 -- iter: 1696/1998
[A[ATraining Step: 54  | total loss: [1m[32m0.68442[0m[0m | time: 959.262s
[2K
| RMSProp | epoch: 001 | loss: 0.68442 - acc: 0.5407 -- iter: 1728/1998
[A[ATraining Step: 55  | total loss: [1m[32m0.68249[0m[0m | time: 972.476s
[2K
| RMSProp | epoch: 001 | loss: 0.68249 - acc: 0.5438 -- iter: 1760/1998
[A[ATraining Step: 56  | total loss: [1m[32m0.67918[0m[0m | time: 986.378s
[2K
| RMSProp | epoch: 001 | loss: 0.67918 - acc: 0.5640 -- iter: 1792/1998
[A[ATraining Step: 57  | total loss: [1m[32m0.67159[0m[0m | time: 995.361s
[2K
| RMSProp | epoch: 001 | loss: 0.67159 - acc: 0.5725 -- iter: 1824/1998
[A[ATraining Step: 58  | total loss: [1m[32m0.66721[0m[0m | time: 1004.259s
[2K
| RMSProp | epoch: 001 | loss: 0.66721 - acc: 0.5882 -- iter: 1856/1998
[A[ATraining Step: 59  | total loss: [1m[32m0.66778[0m[0m | time: 1015.073s
[2K
| RMSProp | epoch: 001 | loss: 0.66778 - acc: 0.5889 -- iter: 1888/1998
[A[ATraining Step: 60  | total loss: [1m[32m0.66773[0m[0m | time: 1028.496s
[2K
| RMSProp | epoch: 001 | loss: 0.66773 - acc: 0.5772 -- iter: 1920/1998
[A[ATraining Step: 61  | total loss: [1m[32m0.68122[0m[0m | time: 1041.418s
[2K
| RMSProp | epoch: 001 | loss: 0.68122 - acc: 0.5630 -- iter: 1952/1998
[A[ATraining Step: 62  | total loss: [1m[32m0.67055[0m[0m | time: 1054.895s
[2K
| RMSProp | epoch: 001 | loss: 0.67055 - acc: 0.5790 -- iter: 1984/1998
[A[ATraining Step: 63  | total loss: [1m[32m0.67746[0m[0m | time: 1120.506s
[2K
| RMSProp | epoch: 001 | loss: 0.67746 - acc: 0.5730 | val_loss: 0.66210 - val_acc: 0.5488 -- iter: 1998/1998
--
Training Step: 64  | total loss: [1m[32m0.68315[0m[0m | time: 4.506s
[2K
| RMSProp | epoch: 002 | loss: 0.68315 - acc: 0.5638 -- iter: 0032/1998
[A[ATraining Step: 65  | total loss: [1m[32m0.66201[0m[0m | time: 35.145s
[2K
| RMSProp | epoch: 002 | loss: 0.66201 - acc: 0.5912 -- iter: 0064/1998
[A[ATraining Step: 66  | total loss: [1m[32m0.66548[0m[0m | time: 67.534s
[2K
| RMSProp | epoch: 002 | loss: 0.66548 - acc: 0.5915 -- iter: 0096/1998
[A[ATraining Step: 67  | total loss: [1m[32m0.67344[0m[0m | time: 100.897s
[2K
| RMSProp | epoch: 002 | loss: 0.67344 - acc: 0.5918 -- iter: 0128/1998
[A[ATraining Step: 68  | total loss: [1m[32m0.67017[0m[0m | time: 114.533s
[2K
| RMSProp | epoch: 002 | loss: 0.67017 - acc: 0.5920 -- iter: 0160/1998
[A[ATraining Step: 69  | total loss: [1m[32m0.66721[0m[0m | time: 136.310s
[2K
| RMSProp | epoch: 002 | loss: 0.66721 - acc: 0.6032 -- iter: 0192/1998
[A[ATraining Step: 70  | total loss: [1m[32m0.67192[0m[0m | time: 149.777s
[2K
| RMSProp | epoch: 002 | loss: 0.67192 - acc: 0.5913 -- iter: 0224/1998
[A[ATraining Step: 71  | total loss: [1m[32m0.66603[0m[0m | time: 171.067s
[2K
| RMSProp | epoch: 002 | loss: 0.66603 - acc: 0.5987 -- iter: 0256/1998
[A[ATraining Step: 72  | total loss: [1m[32m0.66403[0m[0m | time: 183.936s
[2K
| RMSProp | epoch: 002 | loss: 0.66403 - acc: 0.6016 -- iter: 0288/1998
[A[ATraining Step: 73  | total loss: [1m[32m0.65754[0m[0m | time: 198.319s
[2K
| RMSProp | epoch: 002 | loss: 0.65754 - acc: 0.6112 -- iter: 0320/1998
[A[ATraining Step: 74  | total loss: [1m[32m0.65788[0m[0m | time: 207.128s
[2K
| RMSProp | epoch: 002 | loss: 0.65788 - acc: 0.6196 -- iter: 0352/1998
[A[ATraining Step: 75  | total loss: [1m[32m0.65064[0m[0m | time: 215.925s
[2K
| RMSProp | epoch: 002 | loss: 0.65064 - acc: 0.6371 -- iter: 0384/1998
[A[ATraining Step: 76  | total loss: [1m[32m0.64295[0m[0m | time: 226.777s
[2K
| RMSProp | epoch: 002 | loss: 0.64295 - acc: 0.6458 -- iter: 0416/1998
[A[ATraining Step: 77  | total loss: [1m[32m0.63617[0m[0m | time: 240.003s
[2K
| RMSProp | epoch: 002 | loss: 0.63617 - acc: 0.6635 -- iter: 0448/1998
[A[ATraining Step: 78  | total loss: [1m[32m0.63949[0m[0m | time: 253.521s
[2K
| RMSProp | epoch: 002 | loss: 0.63949 - acc: 0.6660 -- iter: 0480/1998
[A[ATraining Step: 79  | total loss: [1m[32m0.64203[0m[0m | time: 267.171s
[2K
| RMSProp | epoch: 002 | loss: 0.64203 - acc: 0.6715 -- iter: 0512/1998
[A[ATraining Step: 80  | total loss: [1m[32m0.62996[0m[0m | time: 280.454s
[2K
| RMSProp | epoch: 002 | loss: 0.62996 - acc: 0.6795 -- iter: 0544/1998
[A[ATraining Step: 81  | total loss: [1m[32m0.63677[0m[0m | time: 294.976s
[2K
| RMSProp | epoch: 002 | loss: 0.63677 - acc: 0.6613 -- iter: 0576/1998
[A[ATraining Step: 82  | total loss: [1m[32m0.61842[0m[0m | time: 312.056s
[2K
| RMSProp | epoch: 002 | loss: 0.61842 - acc: 0.6796 -- iter: 0608/1998
[A[ATraining Step: 83  | total loss: [1m[32m0.62812[0m[0m | time: 325.830s
[2K
| RMSProp | epoch: 002 | loss: 0.62812 - acc: 0.6741 -- iter: 0640/1998
[A[ATraining Step: 84  | total loss: [1m[32m0.62648[0m[0m | time: 340.485s
[2K
| RMSProp | epoch: 002 | loss: 0.62648 - acc: 0.6723 -- iter: 0672/1998
[A[ATraining Step: 85  | total loss: [1m[32m0.61315[0m[0m | time: 350.842s
[2K
| RMSProp | epoch: 002 | loss: 0.61315 - acc: 0.6832 -- iter: 0704/1998
[A[ATraining Step: 86  | total loss: [1m[32m0.62035[0m[0m | time: 359.977s
[2K
| RMSProp | epoch: 002 | loss: 0.62035 - acc: 0.6837 -- iter: 0736/1998
[A[ATraining Step: 87  | total loss: [1m[32m0.61014[0m[0m | time: 369.824s
[2K
| RMSProp | epoch: 002 | loss: 0.61014 - acc: 0.6997 -- iter: 0768/1998
[A[ATraining Step: 88  | total loss: [1m[32m0.61129[0m[0m | time: 384.195s
[2K
| RMSProp | epoch: 002 | loss: 0.61129 - acc: 0.6984 -- iter: 0800/1998
[A[ATraining Step: 89  | total loss: [1m[32m0.61421[0m[0m | time: 398.715s
[2K
| RMSProp | epoch: 002 | loss: 0.61421 - acc: 0.6911 -- iter: 0832/1998
[A[ATraining Step: 90  | total loss: [1m[32m0.60726[0m[0m | time: 412.240s
[2K
| RMSProp | epoch: 002 | loss: 0.60726 - acc: 0.6970 -- iter: 0864/1998
[A[ATraining Step: 91  | total loss: [1m[32m0.59772[0m[0m | time: 426.812s
[2K
| RMSProp | epoch: 002 | loss: 0.59772 - acc: 0.6960 -- iter: 0896/1998
[A[ATraining Step: 92  | total loss: [1m[32m0.60711[0m[0m | time: 440.490s
[2K
| RMSProp | epoch: 002 | loss: 0.60711 - acc: 0.6921 -- iter: 0928/1998
[A[ATraining Step: 93  | total loss: [1m[32m0.60690[0m[0m | time: 454.259s
[2K
| RMSProp | epoch: 002 | loss: 0.60690 - acc: 0.6885 -- iter: 0960/1998
[A[ATraining Step: 94  | total loss: [1m[32m0.61467[0m[0m | time: 467.919s
[2K
| RMSProp | epoch: 002 | loss: 0.61467 - acc: 0.6915 -- iter: 0992/1998
[A[ATraining Step: 95  | total loss: [1m[32m0.61157[0m[0m | time: 485.180s
[2K
| RMSProp | epoch: 002 | loss: 0.61157 - acc: 0.6974 -- iter: 1024/1998
[A[ATraining Step: 96  | total loss: [1m[32m0.61571[0m[0m | time: 499.327s
[2K
| RMSProp | epoch: 002 | loss: 0.61571 - acc: 0.6964 -- iter: 1056/1998
[A[ATraining Step: 97  | total loss: [1m[32m0.61022[0m[0m | time: 509.130s
[2K
| RMSProp | epoch: 002 | loss: 0.61022 - acc: 0.7080 -- iter: 1088/1998
[A[ATraining Step: 98  | total loss: [1m[32m0.60968[0m[0m | time: 518.402s
[2K
| RMSProp | epoch: 002 | loss: 0.60968 - acc: 0.6997 -- iter: 1120/1998
[A[ATraining Step: 99  | total loss: [1m[32m0.59592[0m[0m | time: 529.192s
[2K
| RMSProp | epoch: 002 | loss: 0.59592 - acc: 0.7078 -- iter: 1152/1998
[A[ATraining Step: 100  | total loss: [1m[32m0.57959[0m[0m | time: 543.252s
[2K
| RMSProp | epoch: 002 | loss: 0.57959 - acc: 0.7183 -- iter: 1184/1998
[A[ATraining Step: 101  | total loss: [1m[32m0.57778[0m[0m | time: 557.780s
[2K
| RMSProp | epoch: 002 | loss: 0.57778 - acc: 0.7152 -- iter: 1216/1998
[A[ATraining Step: 102  | total loss: [1m[32m0.56755[0m[0m | time: 574.966s
[2K
| RMSProp | epoch: 002 | loss: 0.56755 - acc: 0.7218 -- iter: 1248/1998
[A[ATraining Step: 103  | total loss: [1m[32m0.55816[0m[0m | time: 588.546s
[2K
| RMSProp | epoch: 002 | loss: 0.55816 - acc: 0.7340 -- iter: 1280/1998
[A[ATraining Step: 104  | total loss: [1m[32m0.54913[0m[0m | time: 604.866s
[2K
| RMSProp | epoch: 002 | loss: 0.54913 - acc: 0.7450 -- iter: 1312/1998
[A[ATraining Step: 105  | total loss: [1m[32m0.54769[0m[0m | time: 618.660s
[2K
| RMSProp | epoch: 002 | loss: 0.54769 - acc: 0.7455 -- iter: 1344/1998
[A[ATraining Step: 106  | total loss: [1m[32m0.55878[0m[0m | time: 632.281s
[2K
| RMSProp | epoch: 002 | loss: 0.55878 - acc: 0.7334 -- iter: 1376/1998
[A[ATraining Step: 107  | total loss: [1m[32m0.54173[0m[0m | time: 645.521s
[2K
| RMSProp | epoch: 002 | loss: 0.54173 - acc: 0.7382 -- iter: 1408/1998
[A[ATraining Step: 108  | total loss: [1m[32m0.55662[0m[0m | time: 660.454s
[2K
| RMSProp | epoch: 002 | loss: 0.55662 - acc: 0.7363 -- iter: 1440/1998
[A[ATraining Step: 109  | total loss: [1m[32m0.55215[0m[0m | time: 669.654s
[2K
| RMSProp | epoch: 002 | loss: 0.55215 - acc: 0.7439 -- iter: 1472/1998
[A[ATraining Step: 110  | total loss: [1m[32m0.57034[0m[0m | time: 678.677s
[2K
| RMSProp | epoch: 002 | loss: 0.57034 - acc: 0.7383 -- iter: 1504/1998
[A[ATraining Step: 111  | total loss: [1m[32m0.57079[0m[0m | time: 688.894s
[2K
| RMSProp | epoch: 002 | loss: 0.57079 - acc: 0.7394 -- iter: 1536/1998
[A[ATraining Step: 112  | total loss: [1m[32m0.56750[0m[0m | time: 708.099s
[2K
| RMSProp | epoch: 002 | loss: 0.56750 - acc: 0.7405 -- iter: 1568/1998
[A[ATraining Step: 113  | total loss: [1m[32m0.57350[0m[0m | time: 723.651s
[2K
| RMSProp | epoch: 002 | loss: 0.57350 - acc: 0.7321 -- iter: 1600/1998
[A[ATraining Step: 114  | total loss: [1m[32m0.57888[0m[0m | time: 753.299s
[2K
| RMSProp | epoch: 002 | loss: 0.57888 - acc: 0.7276 -- iter: 1632/1998
[A[ATraining Step: 115  | total loss: [1m[32m0.58797[0m[0m | time: 779.600s
[2K
| RMSProp | epoch: 002 | loss: 0.58797 - acc: 0.7142 -- iter: 1664/1998
[A[ATraining Step: 116  | total loss: [1m[32m0.58216[0m[0m | time: 793.239s
[2K
| RMSProp | epoch: 002 | loss: 0.58216 - acc: 0.7209 -- iter: 1696/1998
[A[ATraining Step: 117  | total loss: [1m[32m0.58802[0m[0m | time: 807.260s
[2K
| RMSProp | epoch: 002 | loss: 0.58802 - acc: 0.7113 -- iter: 1728/1998
[A[ATraining Step: 118  | total loss: [1m[32m0.58603[0m[0m | time: 820.672s
[2K
| RMSProp | epoch: 002 | loss: 0.58603 - acc: 0.7183 -- iter: 1760/1998
[A[ATraining Step: 119  | total loss: [1m[32m0.57773[0m[0m | time: 834.284s
[2K
| RMSProp | epoch: 002 | loss: 0.57773 - acc: 0.7215 -- iter: 1792/1998
[A[ATraining Step: 120  | total loss: [1m[32m0.56109[0m[0m | time: 844.297s
[2K
| RMSProp | epoch: 002 | loss: 0.56109 - acc: 0.7337 -- iter: 1824/1998
[A[ATraining Step: 121  | total loss: [1m[32m0.57082[0m[0m | time: 853.217s
[2K
| RMSProp | epoch: 002 | loss: 0.57082 - acc: 0.7291 -- iter: 1856/1998
[A[ATraining Step: 122  | total loss: [1m[32m0.56068[0m[0m | time: 864.159s
[2K
| RMSProp | epoch: 002 | loss: 0.56068 - acc: 0.7406 -- iter: 1888/1998
[A[ATraining Step: 123  | total loss: [1m[32m0.55737[0m[0m | time: 877.450s
[2K
| RMSProp | epoch: 002 | loss: 0.55737 - acc: 0.7321 -- iter: 1920/1998
[A[ATraining Step: 124  | total loss: [1m[32m0.54633[0m[0m | time: 894.885s
[2K
| RMSProp | epoch: 002 | loss: 0.54633 - acc: 0.7339 -- iter: 1952/1998
[A[ATraining Step: 125  | total loss: [1m[32m0.53415[0m[0m | time: 908.215s
[2K
| RMSProp | epoch: 002 | loss: 0.53415 - acc: 0.7449 -- iter: 1984/1998
[A[ATraining Step: 126  | total loss: [1m[32m0.53721[0m[0m | time: 968.620s
[2K
| RMSProp | epoch: 002 | loss: 0.53721 - acc: 0.7454 | val_loss: 4.77082 - val_acc: 0.4800 -- iter: 1998/1998
--
Training Step: 127  | total loss: [1m[32m0.54654[0m[0m | time: 4.472s
[2K
| RMSProp | epoch: 003 | loss: 0.54654 - acc: 0.7334 -- iter: 0032/1998
[A[ATraining Step: 128  | total loss: [1m[32m0.53227[0m[0m | time: 8.824s
[2K
| RMSProp | epoch: 003 | loss: 0.53227 - acc: 0.7386 -- iter: 0064/1998
[A[ATraining Step: 129  | total loss: [1m[32m0.49104[0m[0m | time: 21.238s
[2K
| RMSProp | epoch: 003 | loss: 0.49104 - acc: 0.7647 -- iter: 0096/1998
[A[ATraining Step: 130  | total loss: [1m[32m0.50151[0m[0m | time: 35.347s
[2K
| RMSProp | epoch: 003 | loss: 0.50151 - acc: 0.7633 -- iter: 0128/1998
[A[ATraining Step: 131  | total loss: [1m[32m0.50329[0m[0m | time: 48.320s
[2K
| RMSProp | epoch: 003 | loss: 0.50329 - acc: 0.7588 -- iter: 0160/1998
[A[ATraining Step: 132  | total loss: [1m[32m0.51311[0m[0m | time: 62.453s
[2K
| RMSProp | epoch: 003 | loss: 0.51311 - acc: 0.7517 -- iter: 0192/1998
[A[ATraining Step: 133  | total loss: [1m[32m0.50008[0m[0m | time: 76.254s
[2K
| RMSProp | epoch: 003 | loss: 0.50008 - acc: 0.7578 -- iter: 0224/1998
[A[ATraining Step: 134  | total loss: [1m[32m0.50959[0m[0m | time: 92.646s
[2K
| RMSProp | epoch: 003 | loss: 0.50959 - acc: 0.7414 -- iter: 0256/1998
[A[ATraining Step: 135  | total loss: [1m[32m0.51996[0m[0m | time: 106.314s
[2K
| RMSProp | epoch: 003 | loss: 0.51996 - acc: 0.7391 -- iter: 0288/1998
[A[ATraining Step: 136  | total loss: [1m[32m0.52700[0m[0m | time: 121.532s
[2K
| RMSProp | epoch: 003 | loss: 0.52700 - acc: 0.7371 -- iter: 0320/1998
[A[ATraining Step: 137  | total loss: [1m[32m0.52283[0m[0m | time: 140.104s
[2K
| RMSProp | epoch: 003 | loss: 0.52283 - acc: 0.7384 -- iter: 0352/1998
[A[ATraining Step: 138  | total loss: [1m[32m0.52049[0m[0m | time: 149.159s
[2K
| RMSProp | epoch: 003 | loss: 0.52049 - acc: 0.7395 -- iter: 0384/1998
[A[ATraining Step: 139  | total loss: [1m[32m0.52694[0m[0m | time: 157.984s
[2K
| RMSProp | epoch: 003 | loss: 0.52694 - acc: 0.7406 -- iter: 0416/1998
[A[ATraining Step: 140  | total loss: [1m[32m0.52273[0m[0m | time: 166.779s
[2K
| RMSProp | epoch: 003 | loss: 0.52273 - acc: 0.7415 -- iter: 0448/1998
[A[ATraining Step: 141  | total loss: [1m[32m0.52684[0m[0m | time: 176.197s
[2K
| RMSProp | epoch: 003 | loss: 0.52684 - acc: 0.7361 -- iter: 0480/1998
[A[ATraining Step: 142  | total loss: [1m[32m0.53818[0m[0m | time: 205.884s
[2K
| RMSProp | epoch: 003 | loss: 0.53818 - acc: 0.7313 -- iter: 0512/1998
[A[ATraining Step: 143  | total loss: [1m[32m0.54547[0m[0m | time: 230.825s
[2K
| RMSProp | epoch: 003 | loss: 0.54547 - acc: 0.7300 -- iter: 0544/1998
[A[ATraining Step: 144  | total loss: [1m[32m0.53880[0m[0m | time: 272.671s
[2K
| RMSProp | epoch: 003 | loss: 0.53880 - acc: 0.7351 -- iter: 0576/1998
[A[ATraining Step: 145  | total loss: [1m[32m0.53269[0m[0m | time: 296.370s
[2K
| RMSProp | epoch: 003 | loss: 0.53269 - acc: 0.7304 -- iter: 0608/1998
[A[ATraining Step: 146  | total loss: [1m[32m0.49798[0m[0m | time: 310.211s
[2K
| RMSProp | epoch: 003 | loss: 0.49798 - acc: 0.7573 -- iter: 0640/1998
[A[ATraining Step: 147  | total loss: [1m[32m0.49713[0m[0m | time: 323.742s
[2K
| RMSProp | epoch: 003 | loss: 0.49713 - acc: 0.7628 -- iter: 0672/1998
[A[ATraining Step: 148  | total loss: [1m[32m0.49058[0m[0m | time: 337.136s
[2K
| RMSProp | epoch: 003 | loss: 0.49058 - acc: 0.7709 -- iter: 0704/1998
[A[ATraining Step: 149  | total loss: [1m[32m0.48447[0m[0m | time: 350.381s
[2K
| RMSProp | epoch: 003 | loss: 0.48447 - acc: 0.7720 -- iter: 0736/1998
[A[ATraining Step: 150  | total loss: [1m[32m0.48100[0m[0m | time: 363.537s
[2K
| RMSProp | epoch: 003 | loss: 0.48100 - acc: 0.7760 -- iter: 0768/1998
[A[ATraining Step: 151  | total loss: [1m[32m0.47528[0m[0m | time: 372.415s
[2K
| RMSProp | epoch: 003 | loss: 0.47528 - acc: 0.7797 -- iter: 0800/1998
[A[ATraining Step: 152  | total loss: [1m[32m0.47915[0m[0m | time: 381.052s
[2K
| RMSProp | epoch: 003 | loss: 0.47915 - acc: 0.7767 -- iter: 0832/1998
[A[ATraining Step: 153  | total loss: [1m[32m0.49032[0m[0m | time: 392.039s
[2K
| RMSProp | epoch: 003 | loss: 0.49032 - acc: 0.7678 -- iter: 0864/1998
[A[ATraining Step: 154  | total loss: [1m[32m0.48103[0m[0m | time: 405.273s
[2K
| RMSProp | epoch: 003 | loss: 0.48103 - acc: 0.7754 -- iter: 0896/1998
[A[ATraining Step: 155  | total loss: [1m[32m0.48438[0m[0m | time: 418.986s
[2K
| RMSProp | epoch: 003 | loss: 0.48438 - acc: 0.7760 -- iter: 0928/1998
[A[ATraining Step: 156  | total loss: [1m[32m0.47390[0m[0m | time: 432.586s
[2K
| RMSProp | epoch: 003 | loss: 0.47390 - acc: 0.7827 -- iter: 0960/1998
[A[ATraining Step: 157  | total loss: [1m[32m0.46822[0m[0m | time: 445.831s
[2K
| RMSProp | epoch: 003 | loss: 0.46822 - acc: 0.7826 -- iter: 0992/1998
[A[ATraining Step: 158  | total loss: [1m[32m0.45126[0m[0m | time: 459.876s
[2K
| RMSProp | epoch: 003 | loss: 0.45126 - acc: 0.7887 -- iter: 1024/1998
[A[ATraining Step: 159  | total loss: [1m[32m0.43996[0m[0m | time: 475.429s
[2K
| RMSProp | epoch: 003 | loss: 0.43996 - acc: 0.7973 -- iter: 1056/1998
[A[ATraining Step: 160  | total loss: [1m[32m0.43074[0m[0m | time: 488.949s
[2K
| RMSProp | epoch: 003 | loss: 0.43074 - acc: 0.8051 -- iter: 1088/1998
[A[ATraining Step: 161  | total loss: [1m[32m0.45271[0m[0m | time: 503.411s
[2K
| RMSProp | epoch: 003 | loss: 0.45271 - acc: 0.7933 -- iter: 1120/1998
[A[ATraining Step: 162  | total loss: [1m[32m0.44011[0m[0m | time: 513.283s
[2K
| RMSProp | epoch: 003 | loss: 0.44011 - acc: 0.8078 -- iter: 1152/1998
[A[ATraining Step: 163  | total loss: [1m[32m0.43093[0m[0m | time: 522.257s
[2K
| RMSProp | epoch: 003 | loss: 0.43093 - acc: 0.8114 -- iter: 1184/1998
[A[ATraining Step: 164  | total loss: [1m[32m0.48955[0m[0m | time: 533.656s
[2K
| RMSProp | epoch: 003 | loss: 0.48955 - acc: 0.7865 -- iter: 1216/1998
[A[ATraining Step: 165  | total loss: [1m[32m0.48826[0m[0m | time: 547.874s
[2K
| RMSProp | epoch: 003 | loss: 0.48826 - acc: 0.7828 -- iter: 1248/1998
[A[ATraining Step: 166  | total loss: [1m[32m0.48424[0m[0m | time: 561.685s
[2K
| RMSProp | epoch: 003 | loss: 0.48424 - acc: 0.7827 -- iter: 1280/1998
[A[ATraining Step: 167  | total loss: [1m[32m0.48237[0m[0m | time: 575.086s
[2K
| RMSProp | epoch: 003 | loss: 0.48237 - acc: 0.7825 -- iter: 1312/1998
[A[ATraining Step: 168  | total loss: [1m[32m0.47435[0m[0m | time: 590.901s
[2K
| RMSProp | epoch: 003 | loss: 0.47435 - acc: 0.7855 -- iter: 1344/1998
[A[ATraining Step: 169  | total loss: [1m[32m0.48190[0m[0m | time: 604.310s
[2K
| RMSProp | epoch: 003 | loss: 0.48190 - acc: 0.7726 -- iter: 1376/1998
[A[ATraining Step: 170  | total loss: [1m[32m0.48263[0m[0m | time: 618.392s
[2K
| RMSProp | epoch: 003 | loss: 0.48263 - acc: 0.7735 -- iter: 1408/1998
[A[ATraining Step: 171  | total loss: [1m[32m0.47204[0m[0m | time: 631.662s
[2K
| RMSProp | epoch: 003 | loss: 0.47204 - acc: 0.7805 -- iter: 1440/1998
[A[ATraining Step: 172  | total loss: [1m[32m0.46108[0m[0m | time: 645.571s
[2K
| RMSProp | epoch: 003 | loss: 0.46108 - acc: 0.7931 -- iter: 1472/1998
[A[ATraining Step: 173  | total loss: [1m[32m0.47518[0m[0m | time: 655.253s
[2K
| RMSProp | epoch: 003 | loss: 0.47518 - acc: 0.7825 -- iter: 1504/1998
[A[ATraining Step: 174  | total loss: [1m[32m0.45760[0m[0m | time: 664.205s
[2K
| RMSProp | epoch: 003 | loss: 0.45760 - acc: 0.7918 -- iter: 1536/1998
[A[ATraining Step: 175  | total loss: [1m[32m0.45591[0m[0m | time: 674.605s
[2K
| RMSProp | epoch: 003 | loss: 0.45591 - acc: 0.7876 -- iter: 1568/1998
[A[ATraining Step: 176  | total loss: [1m[32m0.44134[0m[0m | time: 688.081s
[2K
| RMSProp | epoch: 003 | loss: 0.44134 - acc: 0.7994 -- iter: 1600/1998
[A[ATraining Step: 177  | total loss: [1m[32m0.43453[0m[0m | time: 701.233s
[2K
| RMSProp | epoch: 003 | loss: 0.43453 - acc: 0.8070 -- iter: 1632/1998
[A[ATraining Step: 178  | total loss: [1m[32m0.43771[0m[0m | time: 714.746s
[2K
| RMSProp | epoch: 003 | loss: 0.43771 - acc: 0.7982 -- iter: 1664/1998
[A[ATraining Step: 179  | total loss: [1m[32m0.43052[0m[0m | time: 728.085s
[2K
| RMSProp | epoch: 003 | loss: 0.43052 - acc: 0.7996 -- iter: 1696/1998
[A[ATraining Step: 180  | total loss: [1m[32m0.42623[0m[0m | time: 741.739s
[2K
| RMSProp | epoch: 003 | loss: 0.42623 - acc: 0.8072 -- iter: 1728/1998
[A[ATraining Step: 181  | total loss: [1m[32m0.42597[0m[0m | time: 754.730s
[2K
| RMSProp | epoch: 003 | loss: 0.42597 - acc: 0.8108 -- iter: 1760/1998
[A[ATraining Step: 182  | total loss: [1m[32m0.49333[0m[0m | time: 770.592s
[2K
| RMSProp | epoch: 003 | loss: 0.49333 - acc: 0.7735 -- iter: 1792/1998
[A[ATraining Step: 183  | total loss: [1m[32m0.48045[0m[0m | time: 787.612s
[2K
| RMSProp | epoch: 003 | loss: 0.48045 - acc: 0.7774 -- iter: 1824/1998
[A[ATraining Step: 184  | total loss: [1m[32m0.47945[0m[0m | time: 796.515s
[2K
| RMSProp | epoch: 003 | loss: 0.47945 - acc: 0.7746 -- iter: 1856/1998
[A[ATraining Step: 185  | total loss: [1m[32m0.47406[0m[0m | time: 805.422s
[2K
| RMSProp | epoch: 003 | loss: 0.47406 - acc: 0.7847 -- iter: 1888/1998
[A[ATraining Step: 186  | total loss: [1m[32m0.47830[0m[0m | time: 814.044s
[2K
| RMSProp | epoch: 003 | loss: 0.47830 - acc: 0.7875 -- iter: 1920/1998
[A[ATraining Step: 187  | total loss: [1m[32m0.46329[0m[0m | time: 822.894s
[2K
| RMSProp | epoch: 003 | loss: 0.46329 - acc: 0.7962 -- iter: 1952/1998
[A[ATraining Step: 188  | total loss: [1m[32m0.46961[0m[0m | time: 855.653s
[2K
| RMSProp | epoch: 003 | loss: 0.46961 - acc: 0.8010 -- iter: 1984/1998
[A[ATraining Step: 189  | total loss: [1m[32m0.47512[0m[0m | time: 938.599s
[2K
| RMSProp | epoch: 003 | loss: 0.47512 - acc: 0.7959 | val_loss: 0.65629 - val_acc: 0.6704 -- iter: 1998/1998
--
Training Step: 190  | total loss: [1m[32m0.47687[0m[0m | time: 9.576s
[2K
| RMSProp | epoch: 004 | loss: 0.47687 - acc: 0.7913 -- iter: 0032/1998
[A[ATraining Step: 191  | total loss: [1m[32m0.45642[0m[0m | time: 14.110s
[2K
| RMSProp | epoch: 004 | loss: 0.45642 - acc: 0.8059 -- iter: 0064/1998
[A[ATraining Step: 192  | total loss: [1m[32m0.42104[0m[0m | time: 18.577s
[2K
| RMSProp | epoch: 004 | loss: 0.42104 - acc: 0.8182 -- iter: 0096/1998
[A[ATraining Step: 193  | total loss: [1m[32m0.38847[0m[0m | time: 36.455s
[2K
| RMSProp | epoch: 004 | loss: 0.38847 - acc: 0.8364 -- iter: 0128/1998
[A[ATraining Step: 194  | total loss: [1m[32m0.38623[0m[0m | time: 51.768s
[2K
| RMSProp | epoch: 004 | loss: 0.38623 - acc: 0.8371 -- iter: 0160/1998
[A[ATraining Step: 195  | total loss: [1m[32m0.40884[0m[0m | time: 71.522s
[2K
| RMSProp | epoch: 004 | loss: 0.40884 - acc: 0.8190 -- iter: 0192/1998
[A[ATraining Step: 196  | total loss: [1m[32m0.41145[0m[0m | time: 85.153s
[2K
| RMSProp | epoch: 004 | loss: 0.41145 - acc: 0.8152 -- iter: 0224/1998
[A[ATraining Step: 197  | total loss: [1m[32m0.39063[0m[0m | time: 98.243s
[2K
| RMSProp | epoch: 004 | loss: 0.39063 - acc: 0.8243 -- iter: 0256/1998
[A[ATraining Step: 198  | total loss: [1m[32m0.39083[0m[0m | time: 111.726s
[2K
| RMSProp | epoch: 004 | loss: 0.39083 - acc: 0.8232 -- iter: 0288/1998
[A[ATraining Step: 199  | total loss: [1m[32m0.40001[0m[0m | time: 124.970s
[2K
| RMSProp | epoch: 004 | loss: 0.40001 - acc: 0.8158 -- iter: 0320/1998
[A[ATraining Step: 200  | total loss: [1m[32m0.39284[0m[0m | time: 175.124s
[2K
| RMSProp | epoch: 004 | loss: 0.39284 - acc: 0.8218 | val_loss: 0.56590 - val_acc: 0.7552 -- iter: 0352/1998
--
Training Step: 201  | total loss: [1m[32m0.38779[0m[0m | time: 188.839s
[2K
| RMSProp | epoch: 004 | loss: 0.38779 - acc: 0.8240 -- iter: 0384/1998
[A[ATraining Step: 202  | total loss: [1m[32m0.37387[0m[0m | time: 202.956s
[2K
| RMSProp | epoch: 004 | loss: 0.37387 - acc: 0.8353 -- iter: 0416/1998
[A[ATraining Step: 203  | total loss: [1m[32m0.38785[0m[0m | time: 216.402s
[2K
| RMSProp | epoch: 004 | loss: 0.38785 - acc: 0.8237 -- iter: 0448/1998
[A[ATraining Step: 204  | total loss: [1m[32m0.43987[0m[0m | time: 230.182s
[2K
| RMSProp | epoch: 004 | loss: 0.43987 - acc: 0.8069 -- iter: 0480/1998
[A[ATraining Step: 205  | total loss: [1m[32m0.43469[0m[0m | time: 245.217s
[2K
| RMSProp | epoch: 004 | loss: 0.43469 - acc: 0.8168 -- iter: 0512/1998
[A[ATraining Step: 206  | total loss: [1m[32m0.41920[0m[0m | time: 261.654s
[2K
| RMSProp | epoch: 004 | loss: 0.41920 - acc: 0.8227 -- iter: 0544/1998
[A[ATraining Step: 207  | total loss: [1m[32m0.42407[0m[0m | time: 274.842s
[2K
| RMSProp | epoch: 004 | loss: 0.42407 - acc: 0.8216 -- iter: 0576/1998
[A[ATraining Step: 208  | total loss: [1m[32m0.41600[0m[0m | time: 288.731s
[2K
| RMSProp | epoch: 004 | loss: 0.41600 - acc: 0.8207 -- iter: 0608/1998
[A[ATraining Step: 209  | total loss: [1m[32m0.39596[0m[0m | time: 297.598s
[2K
| RMSProp | epoch: 004 | loss: 0.39596 - acc: 0.8293 -- iter: 0640/1998
[A[ATraining Step: 210  | total loss: [1m[32m0.39353[0m[0m | time: 306.763s
[2K
| RMSProp | epoch: 004 | loss: 0.39353 - acc: 0.8276 -- iter: 0672/1998
[A[ATraining Step: 211  | total loss: [1m[32m0.39810[0m[0m | time: 318.961s
[2K
| RMSProp | epoch: 004 | loss: 0.39810 - acc: 0.8230 -- iter: 0704/1998
[A[ATraining Step: 212  | total loss: [1m[32m0.41321[0m[0m | time: 332.381s
[2K
| RMSProp | epoch: 004 | loss: 0.41321 - acc: 0.8125 -- iter: 0736/1998
[A[ATraining Step: 213  | total loss: [1m[32m0.41356[0m[0m | time: 345.871s
[2K
| RMSProp | epoch: 004 | loss: 0.41356 - acc: 0.8157 -- iter: 0768/1998
[A[ATraining Step: 214  | total loss: [1m[32m0.42551[0m[0m | time: 359.000s
[2K
| RMSProp | epoch: 004 | loss: 0.42551 - acc: 0.8060 -- iter: 0800/1998
[A[ATraining Step: 215  | total loss: [1m[32m0.41212[0m[0m | time: 374.361s
[2K
| RMSProp | epoch: 004 | loss: 0.41212 - acc: 0.8098 -- iter: 0832/1998
[A[ATraining Step: 216  | total loss: [1m[32m0.41232[0m[0m | time: 389.338s
[2K
| RMSProp | epoch: 004 | loss: 0.41232 - acc: 0.8163 -- iter: 0864/1998
[A[ATraining Step: 217  | total loss: [1m[32m0.41505[0m[0m | time: 403.096s
[2K
| RMSProp | epoch: 004 | loss: 0.41505 - acc: 0.8159 -- iter: 0896/1998
[A[ATraining Step: 218  | total loss: [1m[32m0.39953[0m[0m | time: 416.374s
[2K
| RMSProp | epoch: 004 | loss: 0.39953 - acc: 0.8156 -- iter: 0928/1998
[A[ATraining Step: 219  | total loss: [1m[32m0.40716[0m[0m | time: 429.656s
[2K
| RMSProp | epoch: 004 | loss: 0.40716 - acc: 0.8028 -- iter: 0960/1998
[A[ATraining Step: 220  | total loss: [1m[32m0.40326[0m[0m | time: 443.508s
[2K
| RMSProp | epoch: 004 | loss: 0.40326 - acc: 0.8069 -- iter: 0992/1998
[A[ATraining Step: 221  | total loss: [1m[32m0.41081[0m[0m | time: 453.185s
[2K
| RMSProp | epoch: 004 | loss: 0.41081 - acc: 0.8074 -- iter: 1024/1998
[A[ATraining Step: 222  | total loss: [1m[32m0.39496[0m[0m | time: 462.375s
[2K
| RMSProp | epoch: 004 | loss: 0.39496 - acc: 0.8173 -- iter: 1056/1998
[A[ATraining Step: 223  | total loss: [1m[32m0.39790[0m[0m | time: 473.318s
[2K
| RMSProp | epoch: 004 | loss: 0.39790 - acc: 0.8168 -- iter: 1088/1998
[A[ATraining Step: 224  | total loss: [1m[32m0.37628[0m[0m | time: 486.647s
[2K
| RMSProp | epoch: 004 | loss: 0.37628 - acc: 0.8258 -- iter: 1120/1998
[A[ATraining Step: 225  | total loss: [1m[32m0.36964[0m[0m | time: 500.055s
[2K
| RMSProp | epoch: 004 | loss: 0.36964 - acc: 0.8276 -- iter: 1152/1998
[A[ATraining Step: 226  | total loss: [1m[32m0.39167[0m[0m | time: 516.290s
[2K
| RMSProp | epoch: 004 | loss: 0.39167 - acc: 0.8292 -- iter: 1184/1998
[A[ATraining Step: 227  | total loss: [1m[32m0.38024[0m[0m | time: 529.766s
[2K
| RMSProp | epoch: 004 | loss: 0.38024 - acc: 0.8369 -- iter: 1216/1998
[A[ATraining Step: 228  | total loss: [1m[32m0.37035[0m[0m | time: 543.100s
[2K
| RMSProp | epoch: 004 | loss: 0.37035 - acc: 0.8376 -- iter: 1248/1998
[A[ATraining Step: 229  | total loss: [1m[32m0.36698[0m[0m | time: 556.676s
[2K
| RMSProp | epoch: 004 | loss: 0.36698 - acc: 0.8382 -- iter: 1280/1998
[A[ATraining Step: 230  | total loss: [1m[32m0.34437[0m[0m | time: 571.122s
[2K
| RMSProp | epoch: 004 | loss: 0.34437 - acc: 0.8512 -- iter: 1312/1998
[A[ATraining Step: 231  | total loss: [1m[32m0.32894[0m[0m | time: 584.962s
[2K
| RMSProp | epoch: 004 | loss: 0.32894 - acc: 0.8599 -- iter: 1344/1998
[A[ATraining Step: 232  | total loss: [1m[32m0.32798[0m[0m | time: 593.709s
[2K
| RMSProp | epoch: 004 | loss: 0.32798 - acc: 0.8614 -- iter: 1376/1998
[A[ATraining Step: 233  | total loss: [1m[32m0.33501[0m[0m | time: 602.553s
[2K
| RMSProp | epoch: 004 | loss: 0.33501 - acc: 0.8565 -- iter: 1408/1998
[A[ATraining Step: 234  | total loss: [1m[32m0.32004[0m[0m | time: 611.705s
[2K
| RMSProp | epoch: 004 | loss: 0.32004 - acc: 0.8615 -- iter: 1440/1998
[A[ATraining Step: 235  | total loss: [1m[32m0.30444[0m[0m | time: 643.262s
[2K
| RMSProp | epoch: 004 | loss: 0.30444 - acc: 0.8691 -- iter: 1472/1998
[A[ATraining Step: 236  | total loss: [1m[32m0.29468[0m[0m | time: 657.950s
[2K
| RMSProp | epoch: 004 | loss: 0.29468 - acc: 0.8728 -- iter: 1504/1998
[A[ATraining Step: 237  | total loss: [1m[32m0.29138[0m[0m | time: 671.395s
[2K
| RMSProp | epoch: 004 | loss: 0.29138 - acc: 0.8730 -- iter: 1536/1998
[A[ATraining Step: 238  | total loss: [1m[32m0.28406[0m[0m | time: 684.864s
[2K
| RMSProp | epoch: 004 | loss: 0.28406 - acc: 0.8732 -- iter: 1568/1998
[A[ATraining Step: 239  | total loss: [1m[32m0.28458[0m[0m | time: 698.012s
[2K
| RMSProp | epoch: 004 | loss: 0.28458 - acc: 0.8734 -- iter: 1600/1998
[A[ATraining Step: 240  | total loss: [1m[32m0.29878[0m[0m | time: 711.435s
[2K
| RMSProp | epoch: 004 | loss: 0.29878 - acc: 0.8673 -- iter: 1632/1998
[A[ATraining Step: 241  | total loss: [1m[32m0.29267[0m[0m | time: 725.054s
[2K
| RMSProp | epoch: 004 | loss: 0.29267 - acc: 0.8712 -- iter: 1664/1998
[A[ATraining Step: 242  | total loss: [1m[32m0.27108[0m[0m | time: 738.050s
[2K
| RMSProp | epoch: 004 | loss: 0.27108 - acc: 0.8841 -- iter: 1696/1998
[A[ATraining Step: 243  | total loss: [1m[32m0.26574[0m[0m | time: 751.526s
[2K
| RMSProp | epoch: 004 | loss: 0.26574 - acc: 0.8832 -- iter: 1728/1998
[A[ATraining Step: 244  | total loss: [1m[32m0.28622[0m[0m | time: 760.467s
[2K
| RMSProp | epoch: 004 | loss: 0.28622 - acc: 0.8699 -- iter: 1760/1998
[A[ATraining Step: 245  | total loss: [1m[32m0.28239[0m[0m | time: 769.388s
[2K
| RMSProp | epoch: 004 | loss: 0.28239 - acc: 0.8704 -- iter: 1792/1998
[A[ATraining Step: 246  | total loss: [1m[32m0.28670[0m[0m | time: 795.971s
[2K
| RMSProp | epoch: 004 | loss: 0.28670 - acc: 0.8677 -- iter: 1824/1998
[A[ATraining Step: 247  | total loss: [1m[32m0.30567[0m[0m | time: 837.443s
[2K
| RMSProp | epoch: 004 | loss: 0.30567 - acc: 0.8528 -- iter: 1856/1998
[A[ATraining Step: 248  | total loss: [1m[32m0.31955[0m[0m | time: 849.979s
[2K
| RMSProp | epoch: 004 | loss: 0.31955 - acc: 0.8457 -- iter: 1888/1998
[A[ATraining Step: 249  | total loss: [1m[32m0.31631[0m[0m | time: 863.415s
[2K
| RMSProp | epoch: 004 | loss: 0.31631 - acc: 0.8455 -- iter: 1920/1998
[A[ATraining Step: 250  | total loss: [1m[32m0.30208[0m[0m | time: 876.786s
[2K
| RMSProp | epoch: 004 | loss: 0.30208 - acc: 0.8515 -- iter: 1952/1998
[A[ATraining Step: 251  | total loss: [1m[32m0.34344[0m[0m | time: 890.211s
[2K
| RMSProp | epoch: 004 | loss: 0.34344 - acc: 0.8476 -- iter: 1984/1998
[A[ATraining Step: 252  | total loss: [1m[32m0.34969[0m[0m | time: 943.993s
[2K
| RMSProp | epoch: 004 | loss: 0.34969 - acc: 0.8566 | val_loss: 0.80655 - val_acc: 0.6608 -- iter: 1998/1998
--
Training Step: 253  | total loss: [1m[32m0.34363[0m[0m | time: 19.914s
[2K
| RMSProp | epoch: 005 | loss: 0.34363 - acc: 0.8616 -- iter: 0032/1998
[A[ATraining Step: 254  | total loss: [1m[32m0.35875[0m[0m | time: 32.724s
[2K
| RMSProp | epoch: 005 | loss: 0.35875 - acc: 0.8629 -- iter: 0064/1998
[A[ATraining Step: 255  | total loss: [1m[32m0.35440[0m[0m | time: 39.790s
[2K
| RMSProp | epoch: 005 | loss: 0.35440 - acc: 0.8610 -- iter: 0096/1998
[A[ATraining Step: 256  | total loss: [1m[32m0.33496[0m[0m | time: 46.248s
[2K
| RMSProp | epoch: 005 | loss: 0.33496 - acc: 0.8678 -- iter: 0128/1998
[A[ATraining Step: 257  | total loss: [1m[32m0.30672[0m[0m | time: 59.347s
[2K
| RMSProp | epoch: 005 | loss: 0.30672 - acc: 0.8810 -- iter: 0160/1998
[A[ATraining Step: 258  | total loss: [1m[32m0.29820[0m[0m | time: 72.521s
[2K
| RMSProp | epoch: 005 | loss: 0.29820 - acc: 0.8835 -- iter: 0192/1998
[A[ATraining Step: 259  | total loss: [1m[32m0.31069[0m[0m | time: 85.696s
[2K
| RMSProp | epoch: 005 | loss: 0.31069 - acc: 0.8889 -- iter: 0224/1998
[A[ATraining Step: 260  | total loss: [1m[32m0.31686[0m[0m | time: 98.790s
[2K
| RMSProp | epoch: 005 | loss: 0.31686 - acc: 0.8781 -- iter: 0256/1998
[A[ATraining Step: 261  | total loss: [1m[32m0.32994[0m[0m | time: 107.819s
[2K
| RMSProp | epoch: 005 | loss: 0.32994 - acc: 0.8685 -- iter: 0288/1998
[A[ATraining Step: 262  | total loss: [1m[32m0.33584[0m[0m | time: 116.644s
[2K
| RMSProp | epoch: 005 | loss: 0.33584 - acc: 0.8660 -- iter: 0320/1998
[A[ATraining Step: 263  | total loss: [1m[32m0.33723[0m[0m | time: 129.418s
[2K
| RMSProp | epoch: 005 | loss: 0.33723 - acc: 0.8575 -- iter: 0352/1998
[A[ATraining Step: 264  | total loss: [1m[32m0.33249[0m[0m | time: 143.335s
[2K
| RMSProp | epoch: 005 | loss: 0.33249 - acc: 0.8593 -- iter: 0384/1998
[A[ATraining Step: 265  | total loss: [1m[32m0.33434[0m[0m | time: 158.164s
[2K
| RMSProp | epoch: 005 | loss: 0.33434 - acc: 0.8608 -- iter: 0416/1998
[A[ATraining Step: 266  | total loss: [1m[32m0.31669[0m[0m | time: 171.448s
[2K
| RMSProp | epoch: 005 | loss: 0.31669 - acc: 0.8748 -- iter: 0448/1998
[A[ATraining Step: 267  | total loss: [1m[32m0.30709[0m[0m | time: 184.199s
[2K
| RMSProp | epoch: 005 | loss: 0.30709 - acc: 0.8779 -- iter: 0480/1998
[A[ATraining Step: 268  | total loss: [1m[32m0.29440[0m[0m | time: 197.340s
[2K
| RMSProp | epoch: 005 | loss: 0.29440 - acc: 0.8807 -- iter: 0512/1998
[A[ATraining Step: 269  | total loss: [1m[32m0.30108[0m[0m | time: 210.309s
[2K
| RMSProp | epoch: 005 | loss: 0.30108 - acc: 0.8770 -- iter: 0544/1998
[A[ATraining Step: 270  | total loss: [1m[32m0.30659[0m[0m | time: 225.144s
[2K
| RMSProp | epoch: 005 | loss: 0.30659 - acc: 0.8768 -- iter: 0576/1998
[A[ATraining Step: 271  | total loss: [1m[32m0.30399[0m[0m | time: 239.596s
[2K
| RMSProp | epoch: 005 | loss: 0.30399 - acc: 0.8798 -- iter: 0608/1998
[A[ATraining Step: 272  | total loss: [1m[32m0.31034[0m[0m | time: 249.634s
[2K
| RMSProp | epoch: 005 | loss: 0.31034 - acc: 0.8699 -- iter: 0640/1998
[A[ATraining Step: 273  | total loss: [1m[32m0.30069[0m[0m | time: 258.476s
[2K
| RMSProp | epoch: 005 | loss: 0.30069 - acc: 0.8767 -- iter: 0672/1998
[A[ATraining Step: 274  | total loss: [1m[32m0.31910[0m[0m | time: 269.059s
[2K
| RMSProp | epoch: 005 | loss: 0.31910 - acc: 0.8734 -- iter: 0704/1998
[A[ATraining Step: 275  | total loss: [1m[32m0.31021[0m[0m | time: 281.871s
[2K
| RMSProp | epoch: 005 | loss: 0.31021 - acc: 0.8798 -- iter: 0736/1998
[A[ATraining Step: 276  | total loss: [1m[32m0.30609[0m[0m | time: 296.786s
[2K
| RMSProp | epoch: 005 | loss: 0.30609 - acc: 0.8824 -- iter: 0768/1998
[A[ATraining Step: 277  | total loss: [1m[32m0.30286[0m[0m | time: 309.791s
[2K
| RMSProp | epoch: 005 | loss: 0.30286 - acc: 0.8848 -- iter: 0800/1998
[A[ATraining Step: 278  | total loss: [1m[32m0.28161[0m[0m | time: 323.359s
[2K
| RMSProp | epoch: 005 | loss: 0.28161 - acc: 0.8932 -- iter: 0832/1998
[A[ATraining Step: 279  | total loss: [1m[32m0.27748[0m[0m | time: 336.602s
[2K
| RMSProp | epoch: 005 | loss: 0.27748 - acc: 0.8945 -- iter: 0864/1998
[A[ATraining Step: 280  | total loss: [1m[32m0.27605[0m[0m | time: 352.208s
[2K
| RMSProp | epoch: 005 | loss: 0.27605 - acc: 0.8957 -- iter: 0896/1998
[A[ATraining Step: 281  | total loss: [1m[32m0.28348[0m[0m | time: 365.911s
[2K
| RMSProp | epoch: 005 | loss: 0.28348 - acc: 0.8874 -- iter: 0928/1998
[A[ATraining Step: 282  | total loss: [1m[32m0.27879[0m[0m | time: 382.143s
[2K
| RMSProp | epoch: 005 | loss: 0.27879 - acc: 0.8861 -- iter: 0960/1998
[A[ATraining Step: 283  | total loss: [1m[32m0.26104[0m[0m | time: 391.310s
[2K
| RMSProp | epoch: 005 | loss: 0.26104 - acc: 0.8944 -- iter: 0992/1998
[A[ATraining Step: 284  | total loss: [1m[32m0.24729[0m[0m | time: 400.118s
[2K
| RMSProp | epoch: 005 | loss: 0.24729 - acc: 0.9018 -- iter: 1024/1998
[A[ATraining Step: 285  | total loss: [1m[32m0.23847[0m[0m | time: 408.987s
[2K
| RMSProp | epoch: 005 | loss: 0.23847 - acc: 0.9054 -- iter: 1056/1998
[A[ATraining Step: 286  | total loss: [1m[32m0.22705[0m[0m | time: 423.482s
[2K
| RMSProp | epoch: 005 | loss: 0.22705 - acc: 0.9086 -- iter: 1088/1998
[A[ATraining Step: 287  | total loss: [1m[32m0.21360[0m[0m | time: 432.446s
[2K
| RMSProp | epoch: 005 | loss: 0.21360 - acc: 0.9146 -- iter: 1120/1998
[A[ATraining Step: 288  | total loss: [1m[32m0.23238[0m[0m | time: 441.133s
[2K
| RMSProp | epoch: 005 | loss: 0.23238 - acc: 0.9075 -- iter: 1152/1998
[A[ATraining Step: 289  | total loss: [1m[32m0.25595[0m[0m | time: 450.110s
[2K
| RMSProp | epoch: 005 | loss: 0.25595 - acc: 0.8949 -- iter: 1184/1998
[A[ATraining Step: 290  | total loss: [1m[32m0.25100[0m[0m | time: 458.878s
[2K
| RMSProp | epoch: 005 | loss: 0.25100 - acc: 0.8960 -- iter: 1216/1998
[A[ATraining Step: 291  | total loss: [1m[32m0.24805[0m[0m | time: 467.625s
[2K
| RMSProp | epoch: 005 | loss: 0.24805 - acc: 0.8939 -- iter: 1248/1998
[A[ATraining Step: 292  | total loss: [1m[32m0.26882[0m[0m | time: 476.454s
[2K
| RMSProp | epoch: 005 | loss: 0.26882 - acc: 0.8920 -- iter: 1280/1998
[A[ATraining Step: 293  | total loss: [1m[32m0.25335[0m[0m | time: 485.164s
[2K
| RMSProp | epoch: 005 | loss: 0.25335 - acc: 0.8997 -- iter: 1312/1998
[A[ATraining Step: 294  | total loss: [1m[32m0.25926[0m[0m | time: 493.781s
[2K
| RMSProp | epoch: 005 | loss: 0.25926 - acc: 0.8941 -- iter: 1344/1998
[A[ATraining Step: 295  | total loss: [1m[32m0.25084[0m[0m | time: 502.609s
[2K
| RMSProp | epoch: 005 | loss: 0.25084 - acc: 0.8985 -- iter: 1376/1998
[A[ATraining Step: 296  | total loss: [1m[32m0.24189[0m[0m | time: 511.576s
[2K
| RMSProp | epoch: 005 | loss: 0.24189 - acc: 0.9024 -- iter: 1408/1998
[A[ATraining Step: 297  | total loss: [1m[32m0.24342[0m[0m | time: 520.421s
[2K
| RMSProp | epoch: 005 | loss: 0.24342 - acc: 0.8996 -- iter: 1440/1998
[A[ATraining Step: 298  | total loss: [1m[32m0.24490[0m[0m | time: 529.396s
[2K
| RMSProp | epoch: 005 | loss: 0.24490 - acc: 0.8972 -- iter: 1472/1998
[A[ATraining Step: 299  | total loss: [1m[32m0.23775[0m[0m | time: 538.341s
[2K
| RMSProp | epoch: 005 | loss: 0.23775 - acc: 0.9012 -- iter: 1504/1998
[A[ATraining Step: 300  | total loss: [1m[32m0.22553[0m[0m | time: 547.228s
[2K
| RMSProp | epoch: 005 | loss: 0.22553 - acc: 0.9080 -- iter: 1536/1998
[A[ATraining Step: 301  | total loss: [1m[32m0.22636[0m[0m | time: 556.351s
[2K
| RMSProp | epoch: 005 | loss: 0.22636 - acc: 0.9078 -- iter: 1568/1998
[A[ATraining Step: 302  | total loss: [1m[32m0.21328[0m[0m | time: 565.235s
[2K
| RMSProp | epoch: 005 | loss: 0.21328 - acc: 0.9108 -- iter: 1600/1998
[A[ATraining Step: 303  | total loss: [1m[32m0.22167[0m[0m | time: 574.190s
[2K
| RMSProp | epoch: 005 | loss: 0.22167 - acc: 0.9041 -- iter: 1632/1998
[A[ATraining Step: 304  | total loss: [1m[32m0.22084[0m[0m | time: 583.114s
[2K
| RMSProp | epoch: 005 | loss: 0.22084 - acc: 0.8980 -- iter: 1664/1998
[A[ATraining Step: 305  | total loss: [1m[32m0.23264[0m[0m | time: 592.124s
[2K
| RMSProp | epoch: 005 | loss: 0.23264 - acc: 0.8957 -- iter: 1696/1998
[A[ATraining Step: 306  | total loss: [1m[32m0.22502[0m[0m | time: 601.037s
[2K
| RMSProp | epoch: 005 | loss: 0.22502 - acc: 0.8999 -- iter: 1728/1998
[A[ATraining Step: 307  | total loss: [1m[32m0.24971[0m[0m | time: 610.094s
[2K
| RMSProp | epoch: 005 | loss: 0.24971 - acc: 0.8943 -- iter: 1760/1998
[A[ATraining Step: 308  | total loss: [1m[32m0.23616[0m[0m | time: 619.029s
[2K
| RMSProp | epoch: 005 | loss: 0.23616 - acc: 0.9017 -- iter: 1792/1998
[A[ATraining Step: 309  | total loss: [1m[32m0.25008[0m[0m | time: 627.907s
[2K
| RMSProp | epoch: 005 | loss: 0.25008 - acc: 0.8959 -- iter: 1824/1998
[A[ATraining Step: 310  | total loss: [1m[32m0.24924[0m[0m | time: 637.234s
[2K
| RMSProp | epoch: 005 | loss: 0.24924 - acc: 0.8938 -- iter: 1856/1998
[A[ATraining Step: 311  | total loss: [1m[32m0.24115[0m[0m | time: 646.494s
[2K
| RMSProp | epoch: 005 | loss: 0.24115 - acc: 0.8982 -- iter: 1888/1998
[A[ATraining Step: 312  | total loss: [1m[32m0.25403[0m[0m | time: 655.769s
[2K
| RMSProp | epoch: 005 | loss: 0.25403 - acc: 0.8990 -- iter: 1920/1998
[A[ATraining Step: 313  | total loss: [1m[32m0.26552[0m[0m | time: 664.851s
[2K
| RMSProp | epoch: 005 | loss: 0.26552 - acc: 0.8872 -- iter: 1952/1998
[A[ATraining Step: 314  | total loss: [1m[32m0.27274[0m[0m | time: 674.031s
[2K
| RMSProp | epoch: 005 | loss: 0.27274 - acc: 0.8798 -- iter: 1984/1998
[A[ATraining Step: 315  | total loss: [1m[32m0.25669[0m[0m | time: 714.872s
[2K
| RMSProp | epoch: 005 | loss: 0.25669 - acc: 0.8887 | val_loss: 0.26556 - val_acc: 0.9024 -- iter: 1998/1998
--
Training Step: 316  | total loss: [1m[32m0.25977[0m[0m | time: 8.961s
[2K
| RMSProp | epoch: 006 | loss: 0.25977 - acc: 0.8873 -- iter: 0032/1998
[A[ATraining Step: 317  | total loss: [1m[32m0.28894[0m[0m | time: 17.991s
[2K
| RMSProp | epoch: 006 | loss: 0.28894 - acc: 0.8736 -- iter: 0064/1998
[A[ATraining Step: 318  | total loss: [1m[32m0.27078[0m[0m | time: 27.081s
[2K
| RMSProp | epoch: 006 | loss: 0.27078 - acc: 0.8831 -- iter: 0096/1998
[A[ATraining Step: 319  | total loss: [1m[32m0.28755[0m[0m | time: 31.600s
[2K
| RMSProp | epoch: 006 | loss: 0.28755 - acc: 0.8791 -- iter: 0128/1998
[A[ATraining Step: 320  | total loss: [1m[32m0.31278[0m[0m | time: 36.192s
[2K
| RMSProp | epoch: 006 | loss: 0.31278 - acc: 0.8627 -- iter: 0160/1998
[A[ATraining Step: 321  | total loss: [1m[32m0.28900[0m[0m | time: 45.198s
[2K
| RMSProp | epoch: 006 | loss: 0.28900 - acc: 0.8764 -- iter: 0192/1998
[A[ATraining Step: 322  | total loss: [1m[32m0.30165[0m[0m | time: 54.123s
[2K
| RMSProp | epoch: 006 | loss: 0.30165 - acc: 0.8700 -- iter: 0224/1998
[A[ATraining Step: 323  | total loss: [1m[32m0.29184[0m[0m | time: 62.917s
[2K
| RMSProp | epoch: 006 | loss: 0.29184 - acc: 0.8768 -- iter: 0256/1998
[A[ATraining Step: 324  | total loss: [1m[32m0.28675[0m[0m | time: 71.900s
[2K
| RMSProp | epoch: 006 | loss: 0.28675 - acc: 0.8766 -- iter: 0288/1998
[A[ATraining Step: 325  | total loss: [1m[32m0.28639[0m[0m | time: 80.416s
[2K
| RMSProp | epoch: 006 | loss: 0.28639 - acc: 0.8764 -- iter: 0320/1998
[A[ATraining Step: 326  | total loss: [1m[32m0.26949[0m[0m | time: 89.290s
[2K
| RMSProp | epoch: 006 | loss: 0.26949 - acc: 0.8825 -- iter: 0352/1998
[A[ATraining Step: 327  | total loss: [1m[32m0.26766[0m[0m | time: 98.011s
[2K
| RMSProp | epoch: 006 | loss: 0.26766 - acc: 0.8849 -- iter: 0384/1998
[A[ATraining Step: 328  | total loss: [1m[32m0.25846[0m[0m | time: 106.960s
[2K
| RMSProp | epoch: 006 | loss: 0.25846 - acc: 0.8870 -- iter: 0416/1998
[A[ATraining Step: 329  | total loss: [1m[32m0.24710[0m[0m | time: 115.719s
[2K
| RMSProp | epoch: 006 | loss: 0.24710 - acc: 0.8921 -- iter: 0448/1998
[A[ATraining Step: 330  | total loss: [1m[32m0.23013[0m[0m | time: 124.596s
[2K
| RMSProp | epoch: 006 | loss: 0.23013 - acc: 0.8997 -- iter: 0480/1998
[A[ATraining Step: 331  | total loss: [1m[32m0.21533[0m[0m | time: 133.349s
[2K
| RMSProp | epoch: 006 | loss: 0.21533 - acc: 0.9035 -- iter: 0512/1998
[A[ATraining Step: 332  | total loss: [1m[32m0.20280[0m[0m | time: 142.300s
[2K
| RMSProp | epoch: 006 | loss: 0.20280 - acc: 0.9100 -- iter: 0544/1998
[A[ATraining Step: 333  | total loss: [1m[32m0.21256[0m[0m | time: 151.163s
[2K
| RMSProp | epoch: 006 | loss: 0.21256 - acc: 0.9065 -- iter: 0576/1998
[A[ATraining Step: 334  | total loss: [1m[32m0.21279[0m[0m | time: 160.419s
[2K
| RMSProp | epoch: 006 | loss: 0.21279 - acc: 0.9065 -- iter: 0608/1998
[A[ATraining Step: 335  | total loss: [1m[32m0.21464[0m[0m | time: 169.164s
[2K
| RMSProp | epoch: 006 | loss: 0.21464 - acc: 0.9096 -- iter: 0640/1998
[A[ATraining Step: 336  | total loss: [1m[32m0.23374[0m[0m | time: 178.483s
[2K
| RMSProp | epoch: 006 | loss: 0.23374 - acc: 0.8999 -- iter: 0672/1998
[A[ATraining Step: 337  | total loss: [1m[32m0.26627[0m[0m | time: 187.630s
[2K
| RMSProp | epoch: 006 | loss: 0.26627 - acc: 0.8787 -- iter: 0704/1998
[A[ATraining Step: 338  | total loss: [1m[32m0.24889[0m[0m | time: 196.552s
[2K
| RMSProp | epoch: 006 | loss: 0.24889 - acc: 0.8877 -- iter: 0736/1998
[A[ATraining Step: 339  | total loss: [1m[32m0.23190[0m[0m | time: 205.737s
[2K
| RMSProp | epoch: 006 | loss: 0.23190 - acc: 0.8958 -- iter: 0768/1998
[A[ATraining Step: 340  | total loss: [1m[32m0.22166[0m[0m | time: 214.865s
[2K
| RMSProp | epoch: 006 | loss: 0.22166 - acc: 0.8999 -- iter: 0800/1998
[A[ATraining Step: 341  | total loss: [1m[32m0.21301[0m[0m | time: 223.877s
[2K
| RMSProp | epoch: 006 | loss: 0.21301 - acc: 0.9006 -- iter: 0832/1998
[A[ATraining Step: 342  | total loss: [1m[32m0.20098[0m[0m | time: 232.875s
[2K
| RMSProp | epoch: 006 | loss: 0.20098 - acc: 0.9074 -- iter: 0864/1998
[A[ATraining Step: 343  | total loss: [1m[32m0.18512[0m[0m | time: 242.065s
[2K
| RMSProp | epoch: 006 | loss: 0.18512 - acc: 0.9167 -- iter: 0896/1998
[A[ATraining Step: 344  | total loss: [1m[32m0.17487[0m[0m | time: 250.982s
[2K
| RMSProp | epoch: 006 | loss: 0.17487 - acc: 0.9219 -- iter: 0928/1998
[A[ATraining Step: 345  | total loss: [1m[32m0.16686[0m[0m | time: 259.971s
[2K
| RMSProp | epoch: 006 | loss: 0.16686 - acc: 0.9234 -- iter: 0960/1998
[A[ATraining Step: 346  | total loss: [1m[32m0.16237[0m[0m | time: 268.771s
[2K
| RMSProp | epoch: 006 | loss: 0.16237 - acc: 0.9248 -- iter: 0992/1998
[A[ATraining Step: 347  | total loss: [1m[32m0.21440[0m[0m | time: 277.994s
[2K
| RMSProp | epoch: 006 | loss: 0.21440 - acc: 0.9074 -- iter: 1024/1998
[A[ATraining Step: 348  | total loss: [1m[32m0.21182[0m[0m | time: 286.904s
[2K
| RMSProp | epoch: 006 | loss: 0.21182 - acc: 0.9104 -- iter: 1056/1998
[A[ATraining Step: 349  | total loss: [1m[32m0.19182[0m[0m | time: 296.111s
[2K
| RMSProp | epoch: 006 | loss: 0.19182 - acc: 0.9193 -- iter: 1088/1998
[A[ATraining Step: 350  | total loss: [1m[32m0.18801[0m[0m | time: 304.903s
[2K
| RMSProp | epoch: 006 | loss: 0.18801 - acc: 0.9243 -- iter: 1120/1998
[A[ATraining Step: 351  | total loss: [1m[32m0.18687[0m[0m | time: 313.812s
[2K
| RMSProp | epoch: 006 | loss: 0.18687 - acc: 0.9256 -- iter: 1152/1998
[A[ATraining Step: 352  | total loss: [1m[32m0.21075[0m[0m | time: 322.854s
[2K
| RMSProp | epoch: 006 | loss: 0.21075 - acc: 0.9174 -- iter: 1184/1998
[A[ATraining Step: 353  | total loss: [1m[32m0.22045[0m[0m | time: 331.691s
[2K
| RMSProp | epoch: 006 | loss: 0.22045 - acc: 0.9163 -- iter: 1216/1998
[A[ATraining Step: 354  | total loss: [1m[32m0.21983[0m[0m | time: 340.531s
[2K
| RMSProp | epoch: 006 | loss: 0.21983 - acc: 0.9153 -- iter: 1248/1998
[A[ATraining Step: 355  | total loss: [1m[32m0.20732[0m[0m | time: 349.667s
[2K
| RMSProp | epoch: 006 | loss: 0.20732 - acc: 0.9206 -- iter: 1280/1998
[A[ATraining Step: 356  | total loss: [1m[32m0.20602[0m[0m | time: 358.742s
[2K
| RMSProp | epoch: 006 | loss: 0.20602 - acc: 0.9192 -- iter: 1312/1998
[A[ATraining Step: 357  | total loss: [1m[32m0.19403[0m[0m | time: 367.891s
[2K
| RMSProp | epoch: 006 | loss: 0.19403 - acc: 0.9242 -- iter: 1344/1998
[A[ATraining Step: 358  | total loss: [1m[32m0.18492[0m[0m | time: 376.865s
[2K
| RMSProp | epoch: 006 | loss: 0.18492 - acc: 0.9286 -- iter: 1376/1998
[A[ATraining Step: 359  | total loss: [1m[32m0.18284[0m[0m | time: 386.139s
[2K
| RMSProp | epoch: 006 | loss: 0.18284 - acc: 0.9295 -- iter: 1408/1998
[A[ATraining Step: 360  | total loss: [1m[32m0.16913[0m[0m | time: 395.014s
[2K
| RMSProp | epoch: 006 | loss: 0.16913 - acc: 0.9366 -- iter: 1440/1998
[A[ATraining Step: 361  | total loss: [1m[32m0.15514[0m[0m | time: 404.119s
[2K
| RMSProp | epoch: 006 | loss: 0.15514 - acc: 0.9429 -- iter: 1472/1998
[A[ATraining Step: 362  | total loss: [1m[32m0.14266[0m[0m | time: 413.438s
[2K
| RMSProp | epoch: 006 | loss: 0.14266 - acc: 0.9486 -- iter: 1504/1998
[A[ATraining Step: 363  | total loss: [1m[32m0.14936[0m[0m | time: 422.327s
[2K
| RMSProp | epoch: 006 | loss: 0.14936 - acc: 0.9444 -- iter: 1536/1998
[A[ATraining Step: 364  | total loss: [1m[32m0.13835[0m[0m | time: 431.367s
[2K
| RMSProp | epoch: 006 | loss: 0.13835 - acc: 0.9499 -- iter: 1568/1998
[A[ATraining Step: 365  | total loss: [1m[32m0.12802[0m[0m | time: 440.488s
[2K
| RMSProp | epoch: 006 | loss: 0.12802 - acc: 0.9549 -- iter: 1600/1998
[A[ATraining Step: 366  | total loss: [1m[32m0.12482[0m[0m | time: 449.547s
[2K
| RMSProp | epoch: 006 | loss: 0.12482 - acc: 0.9532 -- iter: 1632/1998
[A[ATraining Step: 367  | total loss: [1m[32m0.13135[0m[0m | time: 458.549s
[2K
| RMSProp | epoch: 006 | loss: 0.13135 - acc: 0.9516 -- iter: 1664/1998
[A[ATraining Step: 368  | total loss: [1m[32m0.13495[0m[0m | time: 467.569s
[2K
| RMSProp | epoch: 006 | loss: 0.13495 - acc: 0.9502 -- iter: 1696/1998
[A[ATraining Step: 369  | total loss: [1m[32m0.13335[0m[0m | time: 476.536s
[2K
| RMSProp | epoch: 006 | loss: 0.13335 - acc: 0.9489 -- iter: 1728/1998
[A[ATraining Step: 370  | total loss: [1m[32m0.14219[0m[0m | time: 485.212s
[2K
| RMSProp | epoch: 006 | loss: 0.14219 - acc: 0.9415 -- iter: 1760/1998
[A[ATraining Step: 371  | total loss: [1m[32m0.17951[0m[0m | time: 494.234s
[2K
| RMSProp | epoch: 006 | loss: 0.17951 - acc: 0.9318 -- iter: 1792/1998
[A[ATraining Step: 372  | total loss: [1m[32m0.19286[0m[0m | time: 503.313s
[2K
| RMSProp | epoch: 006 | loss: 0.19286 - acc: 0.9323 -- iter: 1824/1998
[A[ATraining Step: 373  | total loss: [1m[32m0.18245[0m[0m | time: 512.649s
[2K
| RMSProp | epoch: 006 | loss: 0.18245 - acc: 0.9360 -- iter: 1856/1998
[A[ATraining Step: 374  | total loss: [1m[32m0.22160[0m[0m | time: 521.691s
[2K
| RMSProp | epoch: 006 | loss: 0.22160 - acc: 0.9205 -- iter: 1888/1998
[A[ATraining Step: 375  | total loss: [1m[32m0.21960[0m[0m | time: 533.335s
[2K
| RMSProp | epoch: 006 | loss: 0.21960 - acc: 0.9222 -- iter: 1920/1998
[A[ATraining Step: 376  | total loss: [1m[32m0.21610[0m[0m | time: 553.028s
[2K
| RMSProp | epoch: 006 | loss: 0.21610 - acc: 0.9237 -- iter: 1952/1998
[A[ATraining Step: 377  | total loss: [1m[32m0.20003[0m[0m | time: 564.909s
[2K
| RMSProp | epoch: 006 | loss: 0.20003 - acc: 0.9314 -- iter: 1984/1998
[A[ATraining Step: 378  | total loss: [1m[32m0.19133[0m[0m | time: 608.257s
[2K
| RMSProp | epoch: 006 | loss: 0.19133 - acc: 0.9351 | val_loss: 0.36283 - val_acc: 0.8672 -- iter: 1998/1998
--
Training Step: 379  | total loss: [1m[32m0.18669[0m[0m | time: 21.056s
[2K
| RMSProp | epoch: 007 | loss: 0.18669 - acc: 0.9322 -- iter: 0032/1998
[A[ATraining Step: 380  | total loss: [1m[32m0.18108[0m[0m | time: 34.196s
[2K
| RMSProp | epoch: 007 | loss: 0.18108 - acc: 0.9296 -- iter: 0064/1998
[A[ATraining Step: 381  | total loss: [1m[32m0.16647[0m[0m | time: 52.728s
[2K
| RMSProp | epoch: 007 | loss: 0.16647 - acc: 0.9367 -- iter: 0096/1998
[A[ATraining Step: 382  | total loss: [1m[32m0.16017[0m[0m | time: 62.529s
[2K
| RMSProp | epoch: 007 | loss: 0.16017 - acc: 0.9367 -- iter: 0128/1998
[A[ATraining Step: 383  | total loss: [1m[32m0.20113[0m[0m | time: 67.297s
[2K
| RMSProp | epoch: 007 | loss: 0.20113 - acc: 0.9243 -- iter: 0160/1998
[A[ATraining Step: 384  | total loss: [1m[32m0.23606[0m[0m | time: 72.157s
[2K
| RMSProp | epoch: 007 | loss: 0.23606 - acc: 0.9176 -- iter: 0192/1998
[A[ATraining Step: 385  | total loss: [1m[32m0.22812[0m[0m | time: 131.331s
[2K
| RMSProp | epoch: 007 | loss: 0.22812 - acc: 0.9187 -- iter: 0224/1998
[A[ATraining Step: 386  | total loss: [1m[32m0.21030[0m[0m | time: 167.195s
[2K
| RMSProp | epoch: 007 | loss: 0.21030 - acc: 0.9268 -- iter: 0256/1998
[A[ATraining Step: 387  | total loss: [1m[32m0.21274[0m[0m | time: 202.988s
[2K
| RMSProp | epoch: 007 | loss: 0.21274 - acc: 0.9216 -- iter: 0288/1998
[A[ATraining Step: 388  | total loss: [1m[32m0.19739[0m[0m | time: 212.668s
[2K
| RMSProp | epoch: 007 | loss: 0.19739 - acc: 0.9295 -- iter: 0320/1998
[A[ATraining Step: 389  | total loss: [1m[32m0.18647[0m[0m | time: 246.340s
[2K
| RMSProp | epoch: 007 | loss: 0.18647 - acc: 0.9334 -- iter: 0352/1998
[A[ATraining Step: 390  | total loss: [1m[32m0.17962[0m[0m | time: 396.933s
[2K
| RMSProp | epoch: 007 | loss: 0.17962 - acc: 0.9338 -- iter: 0384/1998
[A[ATraining Step: 391  | total loss: [1m[32m0.17812[0m[0m | time: 582.363s
[2K
| RMSProp | epoch: 007 | loss: 0.17812 - acc: 0.9342 -- iter: 0416/1998
[A[ATraining Step: 392  | total loss: [1m[32m0.16403[0m[0m | time: 814.652s
[2K
| RMSProp | epoch: 007 | loss: 0.16403 - acc: 0.9408 -- iter: 0448/1998
[A[ATraining Step: 393  | total loss: [1m[32m0.15725[0m[0m | time: 895.023s
[2K
| RMSProp | epoch: 007 | loss: 0.15725 - acc: 0.9404 -- iter: 0480/1998
[A[ATraining Step: 394  | total loss: [1m[32m0.15202[0m[0m | time: 1140.414s
[2K
| RMSProp | epoch: 007 | loss: 0.15202 - acc: 0.9433 -- iter: 0512/1998
[A[ATraining Step: 395  | total loss: [1m[32m0.17187[0m[0m | time: 1586.187s
[2K
| RMSProp | epoch: 007 | loss: 0.17187 - acc: 0.9427 -- iter: 0544/1998
[A[ATraining Step: 396  | total loss: [1m[32m0.16846[0m[0m | time: 1943.665s
[2K
| RMSProp | epoch: 007 | loss: 0.16846 - acc: 0.9453 -- iter: 0576/1998
[A[ATraining Step: 397  | total loss: [1m[32m0.16328[0m[0m | time: 2278.968s
[2K
| RMSProp | epoch: 007 | loss: 0.16328 - acc: 0.9476 -- iter: 0608/1998
[A[ATraining Step: 398  | total loss: [1m[32m0.15111[0m[0m | time: 3101.399s
[2K
| RMSProp | epoch: 007 | loss: 0.15111 - acc: 0.9529 -- iter: 0640/1998
[A[ATraining Step: 399  | total loss: [1m[32m0.15229[0m[0m | time: 3695.936s
[2K
| RMSProp | epoch: 007 | loss: 0.15229 - acc: 0.9545 -- iter: 0672/1998
[A[ATraining Step: 400  | total loss: [1m[32m0.14450[0m[0m | time: 4745.682s
[2K
| RMSProp | epoch: 007 | loss: 0.14450 - acc: 0.9559 | val_loss: 0.82981 - val_acc: 0.7360 -- iter: 0704/1998
--
Training Step: 401  | total loss: [1m[32m0.17590[0m[0m | time: 4773.872s
[2K
| RMSProp | epoch: 007 | loss: 0.17590 - acc: 0.9416 -- iter: 0736/1998
[A[ATraining Step: 402  | total loss: [1m[32m0.16767[0m[0m | time: 4828.444s
[2K
| RMSProp | epoch: 007 | loss: 0.16767 - acc: 0.9443 -- iter: 0768/1998
[A[ATraining Step: 403  | total loss: [1m[32m0.15418[0m[0m | time: 4866.251s
[2K
| RMSProp | epoch: 007 | loss: 0.15418 - acc: 0.9498 -- iter: 0800/1998
[A[ATraining Step: 404  | total loss: [1m[32m0.15636[0m[0m | time: 5038.300s
[2K
| RMSProp | epoch: 007 | loss: 0.15636 - acc: 0.9486 -- iter: 0832/1998
[A[ATraining Step: 405  | total loss: [1m[32m0.15437[0m[0m | time: 5080.647s
[2K
| RMSProp | epoch: 007 | loss: 0.15437 - acc: 0.9506 -- iter: 0864/1998
[A[ATraining Step: 406  | total loss: [1m[32m0.14478[0m[0m | time: 5328.614s
[2K
| RMSProp | epoch: 007 | loss: 0.14478 - acc: 0.9556 -- iter: 0896/1998
[A[ATraining Step: 407  | total loss: [1m[32m0.14000[0m[0m | time: 5352.332s
[2K
| RMSProp | epoch: 007 | loss: 0.14000 - acc: 0.9538 -- iter: 0928/1998
[A[ATraining Step: 408  | total loss: [1m[32m0.13820[0m[0m | time: 5518.582s
[2K
| RMSProp | epoch: 007 | loss: 0.13820 - acc: 0.9521 -- iter: 0960/1998
[A[ATraining Step: 409  | total loss: [1m[32m0.13334[0m[0m | time: 5640.938s
[2K
| RMSProp | epoch: 007 | loss: 0.13334 - acc: 0.9507 -- iter: 0992/1998
[A[ATraining Step: 410  | total loss: [1m[32m0.12455[0m[0m | time: 5744.528s
[2K
| RMSProp | epoch: 007 | loss: 0.12455 - acc: 0.9556 -- iter: 1024/1998
[A[ATraining Step: 411  | total loss: [1m[32m0.12216[0m[0m | time: 5873.468s
[2K
| RMSProp | epoch: 007 | loss: 0.12216 - acc: 0.9569 -- iter: 1056/1998
[A[ATraining Step: 412  | total loss: [1m[32m0.14249[0m[0m | time: 6008.706s
[2K
| RMSProp | epoch: 007 | loss: 0.14249 - acc: 0.9518 -- iter: 1088/1998
[A[ATraining Step: 413  | total loss: [1m[32m0.14396[0m[0m | time: 6040.197s
[2K
| RMSProp | epoch: 007 | loss: 0.14396 - acc: 0.9473 -- iter: 1120/1998
[A[ATraining Step: 414  | total loss: [1m[32m0.15583[0m[0m | time: 6279.245s
[2K
| RMSProp | epoch: 007 | loss: 0.15583 - acc: 0.9401 -- iter: 1152/1998
[A[ATraining Step: 415  | total loss: [1m[32m0.14745[0m[0m | time: 6338.013s
[2K
| RMSProp | epoch: 007 | loss: 0.14745 - acc: 0.9429 -- iter: 1184/1998
[A[ATraining Step: 416  | total loss: [1m[32m0.18779[0m[0m | time: 6454.596s
[2K
| RMSProp | epoch: 007 | loss: 0.18779 - acc: 0.9361 -- iter: 1216/1998
[A[ATraining Step: 417  | total loss: [1m[32m0.19692[0m[0m | time: 6581.829s
[2K
| RMSProp | epoch: 007 | loss: 0.19692 - acc: 0.9300 -- iter: 1248/1998
[A[ATraining Step: 418  | total loss: [1m[32m0.19200[0m[0m | time: 6667.894s
[2K
| RMSProp | epoch: 007 | loss: 0.19200 - acc: 0.9308 -- iter: 1280/1998
[A[ATraining Step: 419  | total loss: [1m[32m0.19134[0m[0m | time: 6740.766s
[2K
| RMSProp | epoch: 007 | loss: 0.19134 - acc: 0.9252 -- iter: 1312/1998
[A[ATraining Step: 420  | total loss: [1m[32m0.18373[0m[0m | time: 6795.335s
[2K
| RMSProp | epoch: 007 | loss: 0.18373 - acc: 0.9264 -- iter: 1344/1998
[A[ATraining Step: 421  | total loss: [1m[32m0.17690[0m[0m | time: 6894.198s
[2K
| RMSProp | epoch: 007 | loss: 0.17690 - acc: 0.9275 -- iter: 1376/1998
[A[ATraining Step: 422  | total loss: [1m[32m0.16799[0m[0m | time: 6913.576s
[2K
| RMSProp | epoch: 007 | loss: 0.16799 - acc: 0.9317 -- iter: 1408/1998
[A[ATraining Step: 423  | total loss: [1m[32m0.15288[0m[0m | time: 7096.078s
[2K
| RMSProp | epoch: 007 | loss: 0.15288 - acc: 0.9385 -- iter: 1440/1998
[A[ATraining Step: 424  | total loss: [1m[32m0.14588[0m[0m | time: 7229.793s
[2K
| RMSProp | epoch: 007 | loss: 0.14588 - acc: 0.9415 -- iter: 1472/1998
[A[ATraining Step: 425  | total loss: [1m[32m0.15515[0m[0m | time: 7304.914s
[2K
| RMSProp | epoch: 007 | loss: 0.15515 - acc: 0.9411 -- iter: 1504/1998
[A[ATraining Step: 426  | total loss: [1m[32m0.14519[0m[0m | time: 7353.743s
[2K
| RMSProp | epoch: 007 | loss: 0.14519 - acc: 0.9439 -- iter: 1536/1998
[A[ATraining Step: 427  | total loss: [1m[32m0.15854[0m[0m | time: 7515.413s
[2K
| RMSProp | epoch: 007 | loss: 0.15854 - acc: 0.9401 -- iter: 1568/1998
[A[ATraining Step: 428  | total loss: [1m[32m0.14520[0m[0m | time: 7566.398s
[2K
| RMSProp | epoch: 007 | loss: 0.14520 - acc: 0.9461 -- iter: 1600/1998
[A[ATraining Step: 429  | total loss: [1m[32m0.13439[0m[0m | time: 7580.797s
[2K
| RMSProp | epoch: 007 | loss: 0.13439 - acc: 0.9515 -- iter: 1632/1998
[A[ATraining Step: 430  | total loss: [1m[32m0.12832[0m[0m | time: 7594.749s
[2K
| RMSProp | epoch: 007 | loss: 0.12832 - acc: 0.9532 -- iter: 1664/1998
[A[ATraining Step: 431  | total loss: [1m[32m0.12011[0m[0m | time: 7611.105s
[2K
| RMSProp | epoch: 007 | loss: 0.12011 - acc: 0.9548 -- iter: 1696/1998
[A[ATraining Step: 432  | total loss: [1m[32m0.11803[0m[0m | time: 7629.877s
[2K
| RMSProp | epoch: 007 | loss: 0.11803 - acc: 0.9593 -- iter: 1728/1998
[A[ATraining Step: 433  | total loss: [1m[32m0.10928[0m[0m | time: 7697.958s
[2K
| RMSProp | epoch: 007 | loss: 0.10928 - acc: 0.9602 -- iter: 1760/1998
[A[ATraining Step: 434  | total loss: [1m[32m0.11105[0m[0m | time: 7711.489s
[2K
| RMSProp | epoch: 007 | loss: 0.11105 - acc: 0.9642 -- iter: 1792/1998
[A[ATraining Step: 435  | total loss: [1m[32m0.10168[0m[0m | time: 7724.932s
[2K
| RMSProp | epoch: 007 | loss: 0.10168 - acc: 0.9678 -- iter: 1824/1998
[A[ATraining Step: 436  | total loss: [1m[32m0.10233[0m[0m | time: 7738.537s
[2K
| RMSProp | epoch: 007 | loss: 0.10233 - acc: 0.9679 -- iter: 1856/1998
[A[ATraining Step: 437  | total loss: [1m[32m0.09351[0m[0m | time: 7751.992s
[2K
| RMSProp | epoch: 007 | loss: 0.09351 - acc: 0.9711 -- iter: 1888/1998
[A[ATraining Step: 438  | total loss: [1m[32m0.09261[0m[0m | time: 7773.532s
[2K
| RMSProp | epoch: 007 | loss: 0.09261 - acc: 0.9709 -- iter: 1920/1998
[A[ATraining Step: 439  | total loss: [1m[32m0.08502[0m[0m | time: 7867.846s
[2K
| RMSProp | epoch: 007 | loss: 0.08502 - acc: 0.9738 -- iter: 1952/1998
[A[ATraining Step: 440  | total loss: [1m[32m0.07742[0m[0m | time: 7980.319s
[2K
| RMSProp | epoch: 007 | loss: 0.07742 - acc: 0.9764 -- iter: 1984/1998
[A[ATraining Step: 441  | total loss: [1m[32m0.07203[0m[0m | time: 8045.347s
[2K
| RMSProp | epoch: 007 | loss: 0.07203 - acc: 0.9788 | val_loss: 3.45272 - val_acc: 0.5712 -- iter: 1998/1998
--
Training Step: 442  | total loss: [1m[32m0.07506[0m[0m | time: 20.786s
[2K
| RMSProp | epoch: 008 | loss: 0.07506 - acc: 0.9715 -- iter: 0032/1998
[A[ATraining Step: 443  | total loss: [1m[32m0.07907[0m[0m | time: 85.287s
[2K
| RMSProp | epoch: 008 | loss: 0.07907 - acc: 0.9712 -- iter: 0064/1998
[A[ATraining Step: 444  | total loss: [1m[32m0.08616[0m[0m | time: 98.773s
[2K
| RMSProp | epoch: 008 | loss: 0.08616 - acc: 0.9679 -- iter: 0096/1998
[A[ATraining Step: 445  | total loss: [1m[32m0.07950[0m[0m | time: 112.159s
[2K
| RMSProp | epoch: 008 | loss: 0.07950 - acc: 0.9711 -- iter: 0128/1998
[A[ATraining Step: 446  | total loss: [1m[32m0.10630[0m[0m | time: 125.625s
[2K
| RMSProp | epoch: 008 | loss: 0.10630 - acc: 0.9615 -- iter: 0160/1998
[A[ATraining Step: 447  | total loss: [1m[32m0.10395[0m[0m | time: 132.340s
[2K
| RMSProp | epoch: 008 | loss: 0.10395 - acc: 0.9591 -- iter: 0192/1998
[A[ATraining Step: 448  | total loss: [1m[32m0.12638[0m[0m | time: 139.470s
[2K
| RMSProp | epoch: 008 | loss: 0.12638 - acc: 0.9560 -- iter: 0224/1998
[A[ATraining Step: 449  | total loss: [1m[32m0.11750[0m[0m | time: 153.231s
[2K
| RMSProp | epoch: 008 | loss: 0.11750 - acc: 0.9604 -- iter: 0256/1998
[A[ATraining Step: 450  | total loss: [1m[32m0.11067[0m[0m | time: 167.215s
[2K
| RMSProp | epoch: 008 | loss: 0.11067 - acc: 0.9644 -- iter: 0288/1998
[A[ATraining Step: 451  | total loss: [1m[32m0.11001[0m[0m | time: 180.655s
[2K
| RMSProp | epoch: 008 | loss: 0.11001 - acc: 0.9617 -- iter: 0320/1998
[A[ATraining Step: 452  | total loss: [1m[32m0.11380[0m[0m | time: 194.594s
[2K
| RMSProp | epoch: 008 | loss: 0.11380 - acc: 0.9593 -- iter: 0352/1998
[A[ATraining Step: 453  | total loss: [1m[32m0.10786[0m[0m | time: 212.677s
[2K
| RMSProp | epoch: 008 | loss: 0.10786 - acc: 0.9633 -- iter: 0384/1998
[A[ATraining Step: 454  | total loss: [1m[32m0.10765[0m[0m | time: 273.258s
[2K
| RMSProp | epoch: 008 | loss: 0.10765 - acc: 0.9608 -- iter: 0416/1998
[A[ATraining Step: 455  | total loss: [1m[32m0.10616[0m[0m | time: 286.834s
[2K
| RMSProp | epoch: 008 | loss: 0.10616 - acc: 0.9616 -- iter: 0448/1998
[A[ATraining Step: 456  | total loss: [1m[32m0.10715[0m[0m | time: 301.757s
[2K
| RMSProp | epoch: 008 | loss: 0.10715 - acc: 0.9592 -- iter: 0480/1998
[A[ATraining Step: 457  | total loss: [1m[32m0.10190[0m[0m | time: 317.154s
[2K
| RMSProp | epoch: 008 | loss: 0.10190 - acc: 0.9601 -- iter: 0512/1998
[A[ATraining Step: 458  | total loss: [1m[32m0.09991[0m[0m | time: 333.128s
[2K
| RMSProp | epoch: 008 | loss: 0.09991 - acc: 0.9579 -- iter: 0544/1998
[A[ATraining Step: 459  | total loss: [1m[32m0.09304[0m[0m | time: 363.557s
[2K
| RMSProp | epoch: 008 | loss: 0.09304 - acc: 0.9621 -- iter: 0576/1998
[A[ATraining Step: 460  | total loss: [1m[32m0.08696[0m[0m | time: 377.115s
[2K
| RMSProp | epoch: 008 | loss: 0.08696 - acc: 0.9659 -- iter: 0608/1998
[A[ATraining Step: 461  | total loss: [1m[32m0.07969[0m[0m | time: 391.526s
[2K
| RMSProp | epoch: 008 | loss: 0.07969 - acc: 0.9693 -- iter: 0640/1998
[A[ATraining Step: 462  | total loss: [1m[32m0.07659[0m[0m | time: 425.168s
[2K
| RMSProp | epoch: 008 | loss: 0.07659 - acc: 0.9692 -- iter: 0672/1998
[A[ATraining Step: 463  | total loss: [1m[32m0.07004[0m[0m | time: 494.501s
[2K
| RMSProp | epoch: 008 | loss: 0.07004 - acc: 0.9723 -- iter: 0704/1998
[A[ATraining Step: 464  | total loss: [1m[32m0.06859[0m[0m | time: 508.037s
[2K
| RMSProp | epoch: 008 | loss: 0.06859 - acc: 0.9688 -- iter: 0736/1998
[A[ATraining Step: 465  | total loss: [1m[32m0.06629[0m[0m | time: 521.524s
[2K
| RMSProp | epoch: 008 | loss: 0.06629 - acc: 0.9719 -- iter: 0768/1998
[A[ATraining Step: 466  | total loss: [1m[32m0.06602[0m[0m | time: 535.294s
[2K
| RMSProp | epoch: 008 | loss: 0.06602 - acc: 0.9716 -- iter: 0800/1998
[A[ATraining Step: 467  | total loss: [1m[32m0.07264[0m[0m | time: 549.041s
[2K
| RMSProp | epoch: 008 | loss: 0.07264 - acc: 0.9682 -- iter: 0832/1998
[A[ATraining Step: 468  | total loss: [1m[32m0.07069[0m[0m | time: 562.446s
[2K
| RMSProp | epoch: 008 | loss: 0.07069 - acc: 0.9714 -- iter: 0864/1998
[A[ATraining Step: 469  | total loss: [1m[32m0.06674[0m[0m | time: 580.709s
[2K
| RMSProp | epoch: 008 | loss: 0.06674 - acc: 0.9742 -- iter: 0896/1998
[A[ATraining Step: 470  | total loss: [1m[32m0.07498[0m[0m | time: 636.993s
[2K
| RMSProp | epoch: 008 | loss: 0.07498 - acc: 0.9737 -- iter: 0928/1998
[A[ATraining Step: 471  | total loss: [1m[32m0.07259[0m[0m | time: 650.133s
[2K
| RMSProp | epoch: 008 | loss: 0.07259 - acc: 0.9732 -- iter: 0960/1998
[A[ATraining Step: 472  | total loss: [1m[32m0.06694[0m[0m | time: 663.351s
[2K
| RMSProp | epoch: 008 | loss: 0.06694 - acc: 0.9759 -- iter: 0992/1998
[A[ATraining Step: 473  | total loss: [1m[32m0.06573[0m[0m | time: 677.589s
[2K
| RMSProp | epoch: 008 | loss: 0.06573 - acc: 0.9752 -- iter: 1024/1998
[A[ATraining Step: 474  | total loss: [1m[32m0.06174[0m[0m | time: 700.383s
[2K
| RMSProp | epoch: 008 | loss: 0.06174 - acc: 0.9777 -- iter: 1056/1998
[A[ATraining Step: 475  | total loss: [1m[32m0.05788[0m[0m | time: 713.787s
[2K
| RMSProp | epoch: 008 | loss: 0.05788 - acc: 0.9799 -- iter: 1088/1998
[A[ATraining Step: 476  | total loss: [1m[32m0.05423[0m[0m | time: 727.054s
[2K
| RMSProp | epoch: 008 | loss: 0.05423 - acc: 0.9819 -- iter: 1120/1998
[A[ATraining Step: 477  | total loss: [1m[32m0.04949[0m[0m | time: 740.461s
[2K
| RMSProp | epoch: 008 | loss: 0.04949 - acc: 0.9837 -- iter: 1152/1998
[A[ATraining Step: 478  | total loss: [1m[32m0.04512[0m[0m | time: 753.871s
[2K
| RMSProp | epoch: 008 | loss: 0.04512 - acc: 0.9853 -- iter: 1184/1998
[A[ATraining Step: 479  | total loss: [1m[32m0.05694[0m[0m | time: 767.796s
[2K
| RMSProp | epoch: 008 | loss: 0.05694 - acc: 0.9806 -- iter: 1216/1998
[A[ATraining Step: 480  | total loss: [1m[32m0.11525[0m[0m | time: 787.755s
[2K
| RMSProp | epoch: 008 | loss: 0.11525 - acc: 0.9700 -- iter: 1248/1998
[A[ATraining Step: 481  | total loss: [1m[32m0.11709[0m[0m | time: 829.150s
[2K
| RMSProp | epoch: 008 | loss: 0.11709 - acc: 0.9699 -- iter: 1280/1998
[A[ATraining Step: 482  | total loss: [1m[32m0.10959[0m[0m | time: 842.259s
[2K
| RMSProp | epoch: 008 | loss: 0.10959 - acc: 0.9698 -- iter: 1312/1998
[A[ATraining Step: 483  | total loss: [1m[32m0.09955[0m[0m | time: 856.153s
[2K
| RMSProp | epoch: 008 | loss: 0.09955 - acc: 0.9728 -- iter: 1344/1998
[A[ATraining Step: 484  | total loss: [1m[32m0.09039[0m[0m | time: 877.863s
[2K
| RMSProp | epoch: 008 | loss: 0.09039 - acc: 0.9755 -- iter: 1376/1998
[A[ATraining Step: 485  | total loss: [1m[32m0.08182[0m[0m | time: 904.964s
[2K
| RMSProp | epoch: 008 | loss: 0.08182 - acc: 0.9780 -- iter: 1408/1998
[A[ATraining Step: 486  | total loss: [1m[32m0.08087[0m[0m | time: 919.789s
[2K
| RMSProp | epoch: 008 | loss: 0.08087 - acc: 0.9770 -- iter: 1440/1998
[A[ATraining Step: 487  | total loss: [1m[32m0.08129[0m[0m | time: 980.520s
[2K
| RMSProp | epoch: 008 | loss: 0.08129 - acc: 0.9731 -- iter: 1472/1998
[A[ATraining Step: 488  | total loss: [1m[32m0.07954[0m[0m | time: 994.196s
[2K
| RMSProp | epoch: 008 | loss: 0.07954 - acc: 0.9726 -- iter: 1504/1998
[A[ATraining Step: 489  | total loss: [1m[32m0.08559[0m[0m | time: 1007.478s
[2K
| RMSProp | epoch: 008 | loss: 0.08559 - acc: 0.9691 -- iter: 1536/1998
[A[ATraining Step: 490  | total loss: [1m[32m0.10104[0m[0m | time: 1022.077s
[2K
| RMSProp | epoch: 008 | loss: 0.10104 - acc: 0.9628 -- iter: 1568/1998
[A[ATraining Step: 491  | total loss: [1m[32m0.15170[0m[0m | time: 1105.070s
[2K
| RMSProp | epoch: 008 | loss: 0.15170 - acc: 0.9509 -- iter: 1600/1998
[A[ATraining Step: 492  | total loss: [1m[32m0.16354[0m[0m | time: 1187.136s
[2K
| RMSProp | epoch: 008 | loss: 0.16354 - acc: 0.9496 -- iter: 1632/1998
[A[ATraining Step: 493  | total loss: [1m[32m0.14872[0m[0m | time: 1274.950s
[2K
| RMSProp | epoch: 008 | loss: 0.14872 - acc: 0.9546 -- iter: 1664/1998
[A[ATraining Step: 494  | total loss: [1m[32m0.14172[0m[0m | time: 1288.923s
[2K
| RMSProp | epoch: 008 | loss: 0.14172 - acc: 0.9560 -- iter: 1696/1998
[A[ATraining Step: 495  | total loss: [1m[32m0.14097[0m[0m | time: 1328.753s
[2K
| RMSProp | epoch: 008 | loss: 0.14097 - acc: 0.9511 -- iter: 1728/1998
[A[ATraining Step: 496  | total loss: [1m[32m0.12806[0m[0m | time: 1366.498s
[2K
| RMSProp | epoch: 008 | loss: 0.12806 - acc: 0.9560 -- iter: 1760/1998
[A[ATraining Step: 497  | total loss: [1m[32m0.12063[0m[0m | time: 1463.292s
[2K
| RMSProp | epoch: 008 | loss: 0.12063 - acc: 0.9572 -- iter: 1792/1998
[A[ATraining Step: 498  | total loss: [1m[32m0.11951[0m[0m | time: 1593.736s
[2K
| RMSProp | epoch: 008 | loss: 0.11951 - acc: 0.9553 -- iter: 1824/1998
[A[ATraining Step: 499  | total loss: [1m[32m0.11955[0m[0m | time: 1799.990s
[2K
| RMSProp | epoch: 008 | loss: 0.11955 - acc: 0.9535 -- iter: 1856/1998
[A[ATraining Step: 500  | total loss: [1m[32m0.12450[0m[0m | time: 1852.787s
[2K
| RMSProp | epoch: 008 | loss: 0.12450 - acc: 0.9519 -- iter: 1888/1998
[A[ATraining Step: 501  | total loss: [1m[32m0.15826[0m[0m | time: 2012.332s
[2K
| RMSProp | epoch: 008 | loss: 0.15826 - acc: 0.9379 -- iter: 1920/1998
[A[ATraining Step: 502  | total loss: [1m[32m0.16818[0m[0m | time: 2072.974s
[2K
| RMSProp | epoch: 008 | loss: 0.16818 - acc: 0.9348 -- iter: 1952/1998
[A[ATraining Step: 503  | total loss: [1m[32m0.17777[0m[0m | time: 2086.339s
[2K
| RMSProp | epoch: 008 | loss: 0.17777 - acc: 0.9288 -- iter: 1984/1998
[A[ATraining Step: 504  | total loss: [1m[32m0.17327[0m[0m | time: 2156.898s
[2K
| RMSProp | epoch: 008 | loss: 0.17327 - acc: 0.9265 | val_loss: 0.28372 - val_acc: 0.9024 -- iter: 1998/1998
--
Training Step: 505  | total loss: [1m[32m0.16154[0m[0m | time: 13.344s
[2K
| RMSProp | epoch: 009 | loss: 0.16154 - acc: 0.9339 -- iter: 0032/1998
[A[ATraining Step: 506  | total loss: [1m[32m0.16596[0m[0m | time: 26.901s
[2K
| RMSProp | epoch: 009 | loss: 0.16596 - acc: 0.9343 -- iter: 0064/1998
[A[ATraining Step: 507  | total loss: [1m[32m0.15886[0m[0m | time: 40.332s
[2K
| RMSProp | epoch: 009 | loss: 0.15886 - acc: 0.9377 -- iter: 0096/1998
[A[ATraining Step: 508  | total loss: [1m[32m0.14515[0m[0m | time: 53.507s
[2K
| RMSProp | epoch: 009 | loss: 0.14515 - acc: 0.9439 -- iter: 0128/1998
[A[ATraining Step: 509  | total loss: [1m[32m0.14142[0m[0m | time: 67.308s
[2K
| RMSProp | epoch: 009 | loss: 0.14142 - acc: 0.9464 -- iter: 0160/1998
[A[ATraining Step: 510  | total loss: [1m[32m0.12801[0m[0m | time: 80.506s
[2K
| RMSProp | epoch: 009 | loss: 0.12801 - acc: 0.9518 -- iter: 0192/1998
[A[ATraining Step: 511  | total loss: [1m[32m0.12251[0m[0m | time: 87.381s
[2K
| RMSProp | epoch: 009 | loss: 0.12251 - acc: 0.9535 -- iter: 0224/1998
[A[ATraining Step: 512  | total loss: [1m[32m0.12160[0m[0m | time: 96.262s
[2K
| RMSProp | epoch: 009 | loss: 0.12160 - acc: 0.9510 -- iter: 0256/1998
[A[ATraining Step: 513  | total loss: [1m[32m0.11592[0m[0m | time: 133.170s
[2K
| RMSProp | epoch: 009 | loss: 0.11592 - acc: 0.9559 -- iter: 0288/1998
[A[ATraining Step: 514  | total loss: [1m[32m0.14262[0m[0m | time: 146.520s
[2K
| RMSProp | epoch: 009 | loss: 0.14262 - acc: 0.9509 -- iter: 0320/1998
[A[ATraining Step: 515  | total loss: [1m[32m0.14645[0m[0m | time: 159.965s
[2K
| RMSProp | epoch: 009 | loss: 0.14645 - acc: 0.9496 -- iter: 0352/1998
[A[ATraining Step: 516  | total loss: [1m[32m0.15359[0m[0m | time: 181.627s
[2K
| RMSProp | epoch: 009 | loss: 0.15359 - acc: 0.9515 -- iter: 0384/1998
[A[ATraining Step: 517  | total loss: [1m[32m0.15665[0m[0m | time: 194.858s
[2K
| RMSProp | epoch: 009 | loss: 0.15665 - acc: 0.9501 -- iter: 0416/1998
[A[ATraining Step: 518  | total loss: [1m[32m0.14500[0m[0m | time: 208.488s
[2K
| RMSProp | epoch: 009 | loss: 0.14500 - acc: 0.9551 -- iter: 0448/1998
[A[ATraining Step: 519  | total loss: [1m[32m0.13288[0m[0m | time: 221.896s
[2K
| RMSProp | epoch: 009 | loss: 0.13288 - acc: 0.9596 -- iter: 0480/1998
[A[ATraining Step: 520  | total loss: [1m[32m0.12342[0m[0m | time: 234.993s
[2K
| RMSProp | epoch: 009 | loss: 0.12342 - acc: 0.9605 -- iter: 0512/1998
[A[ATraining Step: 521  | total loss: [1m[32m0.12185[0m[0m | time: 248.130s
[2K
| RMSProp | epoch: 009 | loss: 0.12185 - acc: 0.9613 -- iter: 0544/1998
[A[ATraining Step: 522  | total loss: [1m[32m0.13332[0m[0m | time: 261.671s
[2K
| RMSProp | epoch: 009 | loss: 0.13332 - acc: 0.9589 -- iter: 0576/1998
[A[ATraining Step: 523  | total loss: [1m[32m0.12499[0m[0m | time: 275.110s
[2K
| RMSProp | epoch: 009 | loss: 0.12499 - acc: 0.9630 -- iter: 0608/1998
[A[ATraining Step: 524  | total loss: [1m[32m0.12068[0m[0m | time: 289.198s
[2K
| RMSProp | epoch: 009 | loss: 0.12068 - acc: 0.9636 -- iter: 0640/1998
[A[ATraining Step: 525  | total loss: [1m[32m0.11427[0m[0m | time: 302.661s
[2K
| RMSProp | epoch: 009 | loss: 0.11427 - acc: 0.9641 -- iter: 0672/1998
[A[ATraining Step: 526  | total loss: [1m[32m0.10564[0m[0m | time: 316.198s
[2K
| RMSProp | epoch: 009 | loss: 0.10564 - acc: 0.9677 -- iter: 0704/1998
[A[ATraining Step: 527  | total loss: [1m[32m0.09739[0m[0m | time: 334.184s
[2K
| RMSProp | epoch: 009 | loss: 0.09739 - acc: 0.9709 -- iter: 0736/1998
[A[ATraining Step: 528  | total loss: [1m[32m0.09641[0m[0m | time: 377.308s
[2K
| RMSProp | epoch: 009 | loss: 0.09641 - acc: 0.9707 -- iter: 0768/1998
[A[ATraining Step: 529  | total loss: [1m[32m0.09443[0m[0m | time: 390.846s
[2K
| RMSProp | epoch: 009 | loss: 0.09443 - acc: 0.9705 -- iter: 0800/1998
[A[ATraining Step: 530  | total loss: [1m[32m0.08848[0m[0m | time: 415.332s
[2K
| RMSProp | epoch: 009 | loss: 0.08848 - acc: 0.9703 -- iter: 0832/1998
[A[ATraining Step: 531  | total loss: [1m[32m0.08340[0m[0m | time: 490.589s
[2K
| RMSProp | epoch: 009 | loss: 0.08340 - acc: 0.9702 -- iter: 0864/1998
[A[ATraining Step: 532  | total loss: [1m[32m0.07894[0m[0m | time: 503.887s
[2K
| RMSProp | epoch: 009 | loss: 0.07894 - acc: 0.9700 -- iter: 0896/1998
[A[ATraining Step: 533  | total loss: [1m[32m0.07669[0m[0m | time: 517.163s
[2K
| RMSProp | epoch: 009 | loss: 0.07669 - acc: 0.9699 -- iter: 0928/1998
[A[ATraining Step: 534  | total loss: [1m[32m0.07159[0m[0m | time: 530.136s
[2K
| RMSProp | epoch: 009 | loss: 0.07159 - acc: 0.9729 -- iter: 0960/1998
[A[ATraining Step: 535  | total loss: [1m[32m0.07191[0m[0m | time: 543.512s
[2K
| RMSProp | epoch: 009 | loss: 0.07191 - acc: 0.9725 -- iter: 0992/1998
[A[ATraining Step: 536  | total loss: [1m[32m0.07001[0m[0m | time: 556.786s
[2K
| RMSProp | epoch: 009 | loss: 0.07001 - acc: 0.9721 -- iter: 1024/1998
[A[ATraining Step: 537  | total loss: [1m[32m0.08178[0m[0m | time: 569.960s
[2K
| RMSProp | epoch: 009 | loss: 0.08178 - acc: 0.9624 -- iter: 1056/1998
[A[ATraining Step: 538  | total loss: [1m[32m0.08453[0m[0m | time: 583.046s
[2K
| RMSProp | epoch: 009 | loss: 0.08453 - acc: 0.9631 -- iter: 1088/1998
[A[ATraining Step: 539  | total loss: [1m[32m0.07874[0m[0m | time: 596.066s
[2K
| RMSProp | epoch: 009 | loss: 0.07874 - acc: 0.9667 -- iter: 1120/1998
[A[ATraining Step: 540  | total loss: [1m[32m0.07966[0m[0m | time: 608.800s
[2K
| RMSProp | epoch: 009 | loss: 0.07966 - acc: 0.9669 -- iter: 1152/1998
[A[ATraining Step: 541  | total loss: [1m[32m0.08981[0m[0m | time: 622.054s
[2K
| RMSProp | epoch: 009 | loss: 0.08981 - acc: 0.9609 -- iter: 1184/1998
[A[ATraining Step: 542  | total loss: [1m[32m0.08964[0m[0m | time: 636.245s
[2K
| RMSProp | epoch: 009 | loss: 0.08964 - acc: 0.9617 -- iter: 1216/1998
[A[ATraining Step: 543  | total loss: [1m[32m0.08474[0m[0m | time: 672.045s
[2K
| RMSProp | epoch: 009 | loss: 0.08474 - acc: 0.9624 -- iter: 1248/1998
[A[ATraining Step: 544  | total loss: [1m[32m0.11580[0m[0m | time: 685.050s
[2K
| RMSProp | epoch: 009 | loss: 0.11580 - acc: 0.9630 -- iter: 1280/1998
[A[ATraining Step: 545  | total loss: [1m[32m0.11361[0m[0m | time: 698.227s
[2K
| RMSProp | epoch: 009 | loss: 0.11361 - acc: 0.9636 -- iter: 1312/1998
[A[ATraining Step: 546  | total loss: [1m[32m0.11237[0m[0m | time: 711.311s
[2K
| RMSProp | epoch: 009 | loss: 0.11237 - acc: 0.9641 -- iter: 1344/1998
[A[ATraining Step: 547  | total loss: [1m[32m0.10409[0m[0m | time: 724.880s
[2K
| RMSProp | epoch: 009 | loss: 0.10409 - acc: 0.9677 -- iter: 1376/1998
[A[ATraining Step: 548  | total loss: [1m[32m0.10151[0m[0m | time: 738.050s
[2K
| RMSProp | epoch: 009 | loss: 0.10151 - acc: 0.9678 -- iter: 1408/1998
[A[ATraining Step: 549  | total loss: [1m[32m0.12682[0m[0m | time: 751.230s
[2K
| RMSProp | epoch: 009 | loss: 0.12682 - acc: 0.9523 -- iter: 1440/1998
[A[ATraining Step: 550  | total loss: [1m[32m0.12573[0m[0m | time: 764.608s
[2K
| RMSProp | epoch: 009 | loss: 0.12573 - acc: 0.9508 -- iter: 1472/1998
[A[ATraining Step: 551  | total loss: [1m[32m0.12014[0m[0m | time: 777.835s
[2K
| RMSProp | epoch: 009 | loss: 0.12014 - acc: 0.9526 -- iter: 1504/1998
[A[ATraining Step: 552  | total loss: [1m[32m0.10960[0m[0m | time: 791.093s
[2K
| RMSProp | epoch: 009 | loss: 0.10960 - acc: 0.9573 -- iter: 1536/1998
[A[ATraining Step: 553  | total loss: [1m[32m0.10776[0m[0m | time: 804.756s
[2K
| RMSProp | epoch: 009 | loss: 0.10776 - acc: 0.9585 -- iter: 1568/1998
[A[ATraining Step: 554  | total loss: [1m[32m0.09725[0m[0m | time: 817.820s
[2K
| RMSProp | epoch: 009 | loss: 0.09725 - acc: 0.9626 -- iter: 1600/1998
[A[ATraining Step: 555  | total loss: [1m[32m0.09615[0m[0m | time: 831.175s
[2K
| RMSProp | epoch: 009 | loss: 0.09615 - acc: 0.9601 -- iter: 1632/1998
[A[ATraining Step: 556  | total loss: [1m[32m0.09971[0m[0m | time: 844.801s
[2K
| RMSProp | epoch: 009 | loss: 0.09971 - acc: 0.9610 -- iter: 1664/1998
[A[ATraining Step: 557  | total loss: [1m[32m0.09147[0m[0m | time: 857.972s
[2K
| RMSProp | epoch: 009 | loss: 0.09147 - acc: 0.9649 -- iter: 1696/1998
[A[ATraining Step: 558  | total loss: [1m[32m0.08261[0m[0m | time: 871.405s
[2K
| RMSProp | epoch: 009 | loss: 0.08261 - acc: 0.9684 -- iter: 1728/1998
[A[ATraining Step: 559  | total loss: [1m[32m0.07787[0m[0m | time: 884.634s
[2K
| RMSProp | epoch: 009 | loss: 0.07787 - acc: 0.9684 -- iter: 1760/1998
[A[ATraining Step: 560  | total loss: [1m[32m0.07794[0m[0m | time: 897.673s
[2K
| RMSProp | epoch: 009 | loss: 0.07794 - acc: 0.9653 -- iter: 1792/1998
[A[ATraining Step: 561  | total loss: [1m[32m0.07273[0m[0m | time: 911.266s
[2K
| RMSProp | epoch: 009 | loss: 0.07273 - acc: 0.9688 -- iter: 1824/1998
[A[ATraining Step: 562  | total loss: [1m[32m0.07174[0m[0m | time: 924.485s
[2K
| RMSProp | epoch: 009 | loss: 0.07174 - acc: 0.9688 -- iter: 1856/1998
[A[ATraining Step: 563  | total loss: [1m[32m0.06541[0m[0m | time: 937.272s
[2K
| RMSProp | epoch: 009 | loss: 0.06541 - acc: 0.9719 -- iter: 1888/1998
[A[ATraining Step: 564  | total loss: [1m[32m0.07090[0m[0m | time: 949.973s
[2K
| RMSProp | epoch: 009 | loss: 0.07090 - acc: 0.9685 -- iter: 1920/1998
[A[ATraining Step: 565  | total loss: [1m[32m0.10065[0m[0m | time: 963.714s
[2K
| RMSProp | epoch: 009 | loss: 0.10065 - acc: 0.9498 -- iter: 1952/1998
[A[ATraining Step: 566  | total loss: [1m[32m0.09655[0m[0m | time: 977.203s
[2K
| RMSProp | epoch: 009 | loss: 0.09655 - acc: 0.9517 -- iter: 1984/1998
[A[ATraining Step: 567  | total loss: [1m[32m0.08975[0m[0m | time: 1037.374s
[2K
| RMSProp | epoch: 009 | loss: 0.08975 - acc: 0.9534 | val_loss: 1.03693 - val_acc: 0.7744 -- iter: 1998/1998
--
Training Step: 568  | total loss: [1m[32m0.08436[0m[0m | time: 14.737s
[2K
| RMSProp | epoch: 010 | loss: 0.08436 - acc: 0.9580 -- iter: 0032/1998
[A[ATraining Step: 569  | total loss: [1m[32m0.08068[0m[0m | time: 29.915s
[2K
| RMSProp | epoch: 010 | loss: 0.08068 - acc: 0.9622 -- iter: 0064/1998
[A[ATraining Step: 570  | total loss: [1m[32m0.07340[0m[0m | time: 44.591s
[2K
| RMSProp | epoch: 010 | loss: 0.07340 - acc: 0.9660 -- iter: 0096/1998
[A[ATraining Step: 571  | total loss: [1m[32m0.06744[0m[0m | time: 58.866s
[2K
| RMSProp | epoch: 010 | loss: 0.06744 - acc: 0.9694 -- iter: 0128/1998
[A[ATraining Step: 572  | total loss: [1m[32m0.06256[0m[0m | time: 73.745s
[2K
| RMSProp | epoch: 010 | loss: 0.06256 - acc: 0.9725 -- iter: 0160/1998
[A[ATraining Step: 573  | total loss: [1m[32m0.05689[0m[0m | time: 88.537s
[2K
| RMSProp | epoch: 010 | loss: 0.05689 - acc: 0.9752 -- iter: 0192/1998
[A[ATraining Step: 574  | total loss: [1m[32m0.05263[0m[0m | time: 103.058s
[2K
| RMSProp | epoch: 010 | loss: 0.05263 - acc: 0.9777 -- iter: 0224/1998
[A[ATraining Step: 575  | total loss: [1m[32m0.04761[0m[0m | time: 110.028s
[2K
| RMSProp | epoch: 010 | loss: 0.04761 - acc: 0.9799 -- iter: 0256/1998
[A[ATraining Step: 576  | total loss: [1m[32m0.04297[0m[0m | time: 114.493s
[2K
| RMSProp | epoch: 010 | loss: 0.04297 - acc: 0.9819 -- iter: 0288/1998
[A[ATraining Step: 577  | total loss: [1m[32m0.03871[0m[0m | time: 123.345s
[2K
| RMSProp | epoch: 010 | loss: 0.03871 - acc: 0.9837 -- iter: 0320/1998
[A[ATraining Step: 578  | total loss: [1m[32m0.03524[0m[0m | time: 132.372s
[2K
| RMSProp | epoch: 010 | loss: 0.03524 - acc: 0.9854 -- iter: 0352/1998
[A[ATraining Step: 579  | total loss: [1m[32m0.03612[0m[0m | time: 141.317s
[2K
| RMSProp | epoch: 010 | loss: 0.03612 - acc: 0.9837 -- iter: 0384/1998
[A[ATraining Step: 580  | total loss: [1m[32m0.04269[0m[0m | time: 152.364s
[2K
| RMSProp | epoch: 010 | loss: 0.04269 - acc: 0.9791 -- iter: 0416/1998
[A[ATraining Step: 581  | total loss: [1m[32m0.07193[0m[0m | time: 165.739s
[2K
| RMSProp | epoch: 010 | loss: 0.07193 - acc: 0.9718 -- iter: 0448/1998
[A[ATraining Step: 582  | total loss: [1m[32m0.06721[0m[0m | time: 178.964s
[2K
| RMSProp | epoch: 010 | loss: 0.06721 - acc: 0.9746 -- iter: 0480/1998
[A[ATraining Step: 583  | total loss: [1m[32m0.07821[0m[0m | time: 192.624s
[2K
| RMSProp | epoch: 010 | loss: 0.07821 - acc: 0.9740 -- iter: 0512/1998
[A[ATraining Step: 584  | total loss: [1m[32m0.08451[0m[0m | time: 208.829s
[2K
| RMSProp | epoch: 010 | loss: 0.08451 - acc: 0.9735 -- iter: 0544/1998
[A[ATraining Step: 585  | total loss: [1m[32m0.07801[0m[0m | time: 221.875s
[2K
| RMSProp | epoch: 010 | loss: 0.07801 - acc: 0.9762 -- iter: 0576/1998
[A[ATraining Step: 586  | total loss: [1m[32m0.09406[0m[0m | time: 235.289s
[2K
| RMSProp | epoch: 010 | loss: 0.09406 - acc: 0.9692 -- iter: 0608/1998
[A[ATraining Step: 587  | total loss: [1m[32m0.08646[0m[0m | time: 248.118s
[2K
| RMSProp | epoch: 010 | loss: 0.08646 - acc: 0.9722 -- iter: 0640/1998
[A[ATraining Step: 588  | total loss: [1m[32m0.09398[0m[0m | time: 261.539s
[2K
| RMSProp | epoch: 010 | loss: 0.09398 - acc: 0.9656 -- iter: 0672/1998
[A[ATraining Step: 589  | total loss: [1m[32m0.08672[0m[0m | time: 277.403s
[2K
| RMSProp | epoch: 010 | loss: 0.08672 - acc: 0.9691 -- iter: 0704/1998
[A[ATraining Step: 590  | total loss: [1m[32m0.07912[0m[0m | time: 294.601s
[2K
| RMSProp | epoch: 010 | loss: 0.07912 - acc: 0.9722 -- iter: 0736/1998
[A[ATraining Step: 591  | total loss: [1m[32m0.08591[0m[0m | time: 307.987s
[2K
| RMSProp | epoch: 010 | loss: 0.08591 - acc: 0.9718 -- iter: 0768/1998
[A[ATraining Step: 592  | total loss: [1m[32m0.07774[0m[0m | time: 321.419s
[2K
| RMSProp | epoch: 010 | loss: 0.07774 - acc: 0.9746 -- iter: 0800/1998
[A[ATraining Step: 593  | total loss: [1m[32m0.07644[0m[0m | time: 334.626s
[2K
| RMSProp | epoch: 010 | loss: 0.07644 - acc: 0.9741 -- iter: 0832/1998
[A[ATraining Step: 594  | total loss: [1m[32m0.07230[0m[0m | time: 348.330s
[2K
| RMSProp | epoch: 010 | loss: 0.07230 - acc: 0.9767 -- iter: 0864/1998
[A[ATraining Step: 595  | total loss: [1m[32m0.06618[0m[0m | time: 361.816s
[2K
| RMSProp | epoch: 010 | loss: 0.06618 - acc: 0.9790 -- iter: 0896/1998
[A[ATraining Step: 596  | total loss: [1m[32m0.06055[0m[0m | time: 375.938s
[2K
| RMSProp | epoch: 010 | loss: 0.06055 - acc: 0.9811 -- iter: 0928/1998
[A[ATraining Step: 597  | total loss: [1m[32m0.05651[0m[0m | time: 390.720s
[2K
| RMSProp | epoch: 010 | loss: 0.05651 - acc: 0.9830 -- iter: 0960/1998
[A[ATraining Step: 598  | total loss: [1m[32m0.06131[0m[0m | time: 412.110s
[2K
| RMSProp | epoch: 010 | loss: 0.06131 - acc: 0.9816 -- iter: 0992/1998
[A[ATraining Step: 599  | total loss: [1m[32m0.07143[0m[0m | time: 425.341s
[2K
| RMSProp | epoch: 010 | loss: 0.07143 - acc: 0.9740 -- iter: 1024/1998
[A[ATraining Step: 600  | total loss: [1m[32m0.06508[0m[0m | time: 490.715s
[2K
| RMSProp | epoch: 010 | loss: 0.06508 - acc: 0.9766 | val_loss: 1.05509 - val_acc: 0.7168 -- iter: 1056/1998
--
Training Step: 601  | total loss: [1m[32m0.05917[0m[0m | time: 504.477s
[2K
| RMSProp | epoch: 010 | loss: 0.05917 - acc: 0.9790 -- iter: 1088/1998
[A[ATraining Step: 602  | total loss: [1m[32m0.06551[0m[0m | time: 528.455s
[2K
| RMSProp | epoch: 010 | loss: 0.06551 - acc: 0.9779 -- iter: 1120/1998
[A[ATraining Step: 603  | total loss: [1m[32m0.06265[0m[0m | time: 561.925s
[2K
| RMSProp | epoch: 010 | loss: 0.06265 - acc: 0.9801 -- iter: 1152/1998
[A[ATraining Step: 604  | total loss: [1m[32m0.06014[0m[0m | time: 575.093s
[2K
| RMSProp | epoch: 010 | loss: 0.06014 - acc: 0.9821 -- iter: 1184/1998
[A[ATraining Step: 605  | total loss: [1m[32m0.06718[0m[0m | time: 588.264s
[2K
| RMSProp | epoch: 010 | loss: 0.06718 - acc: 0.9808 -- iter: 1216/1998
[A[ATraining Step: 606  | total loss: [1m[32m0.06812[0m[0m | time: 601.266s
[2K
| RMSProp | epoch: 010 | loss: 0.06812 - acc: 0.9765 -- iter: 1248/1998
[A[ATraining Step: 607  | total loss: [1m[32m0.07779[0m[0m | time: 614.379s
[2K
| RMSProp | epoch: 010 | loss: 0.07779 - acc: 0.9694 -- iter: 1280/1998
[A[ATraining Step: 608  | total loss: [1m[32m0.13539[0m[0m | time: 627.962s
[2K
| RMSProp | epoch: 010 | loss: 0.13539 - acc: 0.9600 -- iter: 1312/1998
[A[ATraining Step: 609  | total loss: [1m[32m0.13663[0m[0m | time: 642.765s
[2K
| RMSProp | epoch: 010 | loss: 0.13663 - acc: 0.9577 -- iter: 1344/1998
[A[ATraining Step: 610  | total loss: [1m[32m0.14808[0m[0m | time: 657.155s
[2K
| RMSProp | epoch: 010 | loss: 0.14808 - acc: 0.9557 -- iter: 1376/1998
[A[ATraining Step: 611  | total loss: [1m[32m0.13652[0m[0m | time: 672.051s
[2K
| RMSProp | epoch: 010 | loss: 0.13652 - acc: 0.9602 -- iter: 1408/1998
[A[ATraining Step: 612  | total loss: [1m[32m0.12472[0m[0m | time: 686.690s
[2K
| RMSProp | epoch: 010 | loss: 0.12472 - acc: 0.9641 -- iter: 1440/1998
[A[ATraining Step: 613  | total loss: [1m[32m0.11519[0m[0m | time: 701.428s
[2K
| RMSProp | epoch: 010 | loss: 0.11519 - acc: 0.9677 -- iter: 1472/1998
[A[ATraining Step: 614  | total loss: [1m[32m0.10499[0m[0m | time: 716.338s
[2K
| RMSProp | epoch: 010 | loss: 0.10499 - acc: 0.9710 -- iter: 1504/1998
[A[ATraining Step: 615  | total loss: [1m[32m0.12454[0m[0m | time: 731.459s
[2K
| RMSProp | epoch: 010 | loss: 0.12454 - acc: 0.9614 -- iter: 1536/1998
[A[ATraining Step: 616  | total loss: [1m[32m0.12009[0m[0m | time: 745.765s
[2K
| RMSProp | epoch: 010 | loss: 0.12009 - acc: 0.9621 -- iter: 1568/1998
[A[ATraining Step: 617  | total loss: [1m[32m0.12496[0m[0m | time: 756.316s
[2K
| RMSProp | epoch: 010 | loss: 0.12496 - acc: 0.9596 -- iter: 1600/1998
[A[ATraining Step: 618  | total loss: [1m[32m0.11351[0m[0m | time: 767.280s
[2K
| RMSProp | epoch: 010 | loss: 0.11351 - acc: 0.9637 -- iter: 1632/1998
[A[ATraining Step: 619  | total loss: [1m[32m0.10698[0m[0m | time: 780.961s
[2K
| RMSProp | epoch: 010 | loss: 0.10698 - acc: 0.9642 -- iter: 1664/1998
[A[ATraining Step: 620  | total loss: [1m[32m0.09769[0m[0m | time: 794.674s
[2K
| RMSProp | epoch: 010 | loss: 0.09769 - acc: 0.9678 -- iter: 1696/1998
[A[ATraining Step: 621  | total loss: [1m[32m0.09635[0m[0m | time: 808.233s
[2K
| RMSProp | epoch: 010 | loss: 0.09635 - acc: 0.9647 -- iter: 1728/1998
[A[ATraining Step: 622  | total loss: [1m[32m0.09894[0m[0m | time: 821.626s
[2K
| RMSProp | epoch: 010 | loss: 0.09894 - acc: 0.9620 -- iter: 1760/1998
[A[ATraining Step: 623  | total loss: [1m[32m0.10579[0m[0m | time: 835.411s
[2K
| RMSProp | epoch: 010 | loss: 0.10579 - acc: 0.9564 -- iter: 1792/1998
[A[ATraining Step: 624  | total loss: [1m[32m0.09782[0m[0m | time: 848.780s
[2K
| RMSProp | epoch: 010 | loss: 0.09782 - acc: 0.9608 -- iter: 1824/1998
[A[ATraining Step: 625  | total loss: [1m[32m0.09238[0m[0m | time: 862.234s
[2K
| RMSProp | epoch: 010 | loss: 0.09238 - acc: 0.9647 -- iter: 1856/1998
[A[ATraining Step: 626  | total loss: [1m[32m0.08404[0m[0m | time: 876.003s
[2K
| RMSProp | epoch: 010 | loss: 0.08404 - acc: 0.9682 -- iter: 1888/1998
[A[ATraining Step: 627  | total loss: [1m[32m0.08538[0m[0m | time: 889.293s
[2K
| RMSProp | epoch: 010 | loss: 0.08538 - acc: 0.9683 -- iter: 1920/1998
[A[ATraining Step: 628  | total loss: [1m[32m0.08996[0m[0m | time: 902.806s
[2K
| RMSProp | epoch: 010 | loss: 0.08996 - acc: 0.9621 -- iter: 1952/1998
[A[ATraining Step: 629  | total loss: [1m[32m0.08652[0m[0m | time: 916.016s
[2K
| RMSProp | epoch: 010 | loss: 0.08652 - acc: 0.9628 -- iter: 1984/1998
[A[ATraining Step: 630  | total loss: [1m[32m0.07818[0m[0m | time: 978.627s
[2K
| RMSProp | epoch: 010 | loss: 0.07818 - acc: 0.9665 | val_loss: 0.56980 - val_acc: 0.8192 -- iter: 1998/1998
--
Training Step: 631  | total loss: [1m[32m0.10562[0m[0m | time: 13.577s
[2K
| RMSProp | epoch: 011 | loss: 0.10562 - acc: 0.9542 -- iter: 0032/1998
[A[ATraining Step: 632  | total loss: [1m[32m0.10590[0m[0m | time: 27.112s
[2K
| RMSProp | epoch: 011 | loss: 0.10590 - acc: 0.9525 -- iter: 0064/1998
[A[ATraining Step: 633  | total loss: [1m[32m0.09646[0m[0m | time: 40.789s
[2K
| RMSProp | epoch: 011 | loss: 0.09646 - acc: 0.9573 -- iter: 0096/1998
[A[ATraining Step: 634  | total loss: [1m[32m0.10525[0m[0m | time: 54.316s
[2K
| RMSProp | epoch: 011 | loss: 0.10525 - acc: 0.9553 -- iter: 0128/1998
[A[ATraining Step: 635  | total loss: [1m[32m0.09580[0m[0m | time: 68.048s
[2K
| RMSProp | epoch: 011 | loss: 0.09580 - acc: 0.9598 -- iter: 0160/1998
[A[ATraining Step: 636  | total loss: [1m[32m0.08996[0m[0m | time: 81.618s
[2K
| RMSProp | epoch: 011 | loss: 0.08996 - acc: 0.9607 -- iter: 0192/1998
[A[ATraining Step: 637  | total loss: [1m[32m0.08305[0m[0m | time: 94.996s
[2K
| RMSProp | epoch: 011 | loss: 0.08305 - acc: 0.9646 -- iter: 0224/1998
[A[ATraining Step: 638  | total loss: [1m[32m0.07512[0m[0m | time: 107.813s
[2K
| RMSProp | epoch: 011 | loss: 0.07512 - acc: 0.9681 -- iter: 0256/1998
[A[ATraining Step: 639  | total loss: [1m[32m0.07176[0m[0m | time: 114.244s
[2K
| RMSProp | epoch: 011 | loss: 0.07176 - acc: 0.9713 -- iter: 0288/1998
[A[ATraining Step: 640  | total loss: [1m[32m0.10302[0m[0m | time: 121.278s
[2K
| RMSProp | epoch: 011 | loss: 0.10302 - acc: 0.9528 -- iter: 0320/1998
[A[ATraining Step: 641  | total loss: [1m[32m0.09791[0m[0m | time: 134.679s
[2K
| RMSProp | epoch: 011 | loss: 0.09791 - acc: 0.9575 -- iter: 0352/1998
[A[ATraining Step: 642  | total loss: [1m[32m0.10181[0m[0m | time: 147.856s
[2K
| RMSProp | epoch: 011 | loss: 0.10181 - acc: 0.9586 -- iter: 0384/1998
[A[ATraining Step: 643  | total loss: [1m[32m0.09551[0m[0m | time: 161.250s
[2K
| RMSProp | epoch: 011 | loss: 0.09551 - acc: 0.9628 -- iter: 0416/1998
[A[ATraining Step: 644  | total loss: [1m[32m0.08727[0m[0m | time: 174.747s
[2K
| RMSProp | epoch: 011 | loss: 0.08727 - acc: 0.9665 -- iter: 0448/1998
[A[ATraining Step: 645  | total loss: [1m[32m0.08600[0m[0m | time: 188.217s
[2K
| RMSProp | epoch: 011 | loss: 0.08600 - acc: 0.9667 -- iter: 0480/1998
[A[ATraining Step: 646  | total loss: [1m[32m0.07972[0m[0m | time: 201.499s
[2K
| RMSProp | epoch: 011 | loss: 0.07972 - acc: 0.9700 -- iter: 0512/1998
[A[ATraining Step: 647  | total loss: [1m[32m0.07438[0m[0m | time: 214.936s
[2K
| RMSProp | epoch: 011 | loss: 0.07438 - acc: 0.9730 -- iter: 0544/1998
[A[ATraining Step: 648  | total loss: [1m[32m0.07065[0m[0m | time: 228.475s
[2K
| RMSProp | epoch: 011 | loss: 0.07065 - acc: 0.9726 -- iter: 0576/1998
[A[ATraining Step: 649  | total loss: [1m[32m0.06800[0m[0m | time: 241.764s
[2K
| RMSProp | epoch: 011 | loss: 0.06800 - acc: 0.9722 -- iter: 0608/1998
[A[ATraining Step: 650  | total loss: [1m[32m0.06372[0m[0m | time: 255.265s
[2K
| RMSProp | epoch: 011 | loss: 0.06372 - acc: 0.9750 -- iter: 0640/1998
[A[ATraining Step: 651  | total loss: [1m[32m0.05803[0m[0m | time: 268.178s
[2K
| RMSProp | epoch: 011 | loss: 0.05803 - acc: 0.9775 -- iter: 0672/1998
[A[ATraining Step: 652  | total loss: [1m[32m0.06332[0m[0m | time: 281.610s
[2K
| RMSProp | epoch: 011 | loss: 0.06332 - acc: 0.9735 -- iter: 0704/1998
[A[ATraining Step: 653  | total loss: [1m[32m0.05779[0m[0m | time: 295.129s
[2K
| RMSProp | epoch: 011 | loss: 0.05779 - acc: 0.9761 -- iter: 0736/1998
[A[ATraining Step: 654  | total loss: [1m[32m0.05581[0m[0m | time: 308.620s
[2K
| RMSProp | epoch: 011 | loss: 0.05581 - acc: 0.9785 -- iter: 0768/1998
[A[ATraining Step: 655  | total loss: [1m[32m0.06179[0m[0m | time: 322.086s
[2K
| RMSProp | epoch: 011 | loss: 0.06179 - acc: 0.9776 -- iter: 0800/1998
[A[ATraining Step: 656  | total loss: [1m[32m0.08572[0m[0m | time: 335.306s
[2K
| RMSProp | epoch: 011 | loss: 0.08572 - acc: 0.9704 -- iter: 0832/1998
[A[ATraining Step: 657  | total loss: [1m[32m0.08711[0m[0m | time: 349.112s
[2K
| RMSProp | epoch: 011 | loss: 0.08711 - acc: 0.9703 -- iter: 0864/1998
[A[ATraining Step: 658  | total loss: [1m[32m0.08012[0m[0m | time: 362.274s
[2K
| RMSProp | epoch: 011 | loss: 0.08012 - acc: 0.9732 -- iter: 0896/1998
[A[ATraining Step: 659  | total loss: [1m[32m0.07388[0m[0m | time: 375.601s
[2K
| RMSProp | epoch: 011 | loss: 0.07388 - acc: 0.9759 -- iter: 0928/1998
[A[ATraining Step: 660  | total loss: [1m[32m0.06834[0m[0m | time: 389.137s
[2K
| RMSProp | epoch: 011 | loss: 0.06834 - acc: 0.9783 -- iter: 0960/1998
[A[ATraining Step: 661  | total loss: [1m[32m0.06204[0m[0m | time: 402.327s
[2K
| RMSProp | epoch: 011 | loss: 0.06204 - acc: 0.9805 -- iter: 0992/1998
[A[ATraining Step: 662  | total loss: [1m[32m0.06014[0m[0m | time: 415.945s
[2K
| RMSProp | epoch: 011 | loss: 0.06014 - acc: 0.9793 -- iter: 1024/1998
[A[ATraining Step: 663  | total loss: [1m[32m0.05669[0m[0m | time: 429.512s
[2K
| RMSProp | epoch: 011 | loss: 0.05669 - acc: 0.9814 -- iter: 1056/1998
[A[ATraining Step: 664  | total loss: [1m[32m0.05792[0m[0m | time: 443.159s
[2K
| RMSProp | epoch: 011 | loss: 0.05792 - acc: 0.9801 -- iter: 1088/1998
[A[ATraining Step: 665  | total loss: [1m[32m0.05434[0m[0m | time: 456.511s
[2K
| RMSProp | epoch: 011 | loss: 0.05434 - acc: 0.9821 -- iter: 1120/1998
[A[ATraining Step: 666  | total loss: [1m[32m0.04946[0m[0m | time: 469.781s
[2K
| RMSProp | epoch: 011 | loss: 0.04946 - acc: 0.9839 -- iter: 1152/1998
[A[ATraining Step: 667  | total loss: [1m[32m0.04531[0m[0m | time: 483.036s
[2K
| RMSProp | epoch: 011 | loss: 0.04531 - acc: 0.9855 -- iter: 1184/1998
[A[ATraining Step: 668  | total loss: [1m[32m0.04225[0m[0m | time: 496.566s
[2K
| RMSProp | epoch: 011 | loss: 0.04225 - acc: 0.9870 -- iter: 1216/1998
[A[ATraining Step: 669  | total loss: [1m[32m0.03874[0m[0m | time: 510.005s
[2K
| RMSProp | epoch: 011 | loss: 0.03874 - acc: 0.9883 -- iter: 1248/1998
[A[ATraining Step: 670  | total loss: [1m[32m0.03520[0m[0m | time: 523.657s
[2K
| RMSProp | epoch: 011 | loss: 0.03520 - acc: 0.9894 -- iter: 1280/1998
[A[ATraining Step: 671  | total loss: [1m[32m0.03868[0m[0m | time: 537.122s
[2K
| RMSProp | epoch: 011 | loss: 0.03868 - acc: 0.9874 -- iter: 1312/1998
[A[ATraining Step: 672  | total loss: [1m[32m0.13950[0m[0m | time: 550.383s
[2K
| RMSProp | epoch: 011 | loss: 0.13950 - acc: 0.9793 -- iter: 1344/1998
[A[ATraining Step: 673  | total loss: [1m[32m0.13867[0m[0m | time: 563.443s
[2K
| RMSProp | epoch: 011 | loss: 0.13867 - acc: 0.9751 -- iter: 1376/1998
[A[ATraining Step: 674  | total loss: [1m[32m0.14506[0m[0m | time: 576.036s
[2K
| RMSProp | epoch: 011 | loss: 0.14506 - acc: 0.9682 -- iter: 1408/1998
[A[ATraining Step: 675  | total loss: [1m[32m0.13459[0m[0m | time: 589.441s
[2K
| RMSProp | epoch: 011 | loss: 0.13459 - acc: 0.9683 -- iter: 1440/1998
[A[ATraining Step: 676  | total loss: [1m[32m0.12214[0m[0m | time: 602.842s
[2K
| RMSProp | epoch: 011 | loss: 0.12214 - acc: 0.9714 -- iter: 1472/1998
[A[ATraining Step: 677  | total loss: [1m[32m0.11532[0m[0m | time: 616.223s
[2K
| RMSProp | epoch: 011 | loss: 0.11532 - acc: 0.9712 -- iter: 1504/1998
[A[ATraining Step: 678  | total loss: [1m[32m0.11129[0m[0m | time: 629.670s
[2K
| RMSProp | epoch: 011 | loss: 0.11129 - acc: 0.9709 -- iter: 1536/1998
[A[ATraining Step: 679  | total loss: [1m[32m0.10226[0m[0m | time: 643.363s
[2K
| RMSProp | epoch: 011 | loss: 0.10226 - acc: 0.9738 -- iter: 1568/1998
[A[ATraining Step: 680  | total loss: [1m[32m0.12239[0m[0m | time: 656.482s
[2K
| RMSProp | epoch: 011 | loss: 0.12239 - acc: 0.9671 -- iter: 1600/1998
[A[ATraining Step: 681  | total loss: [1m[32m0.11410[0m[0m | time: 669.772s
[2K
| RMSProp | epoch: 011 | loss: 0.11410 - acc: 0.9672 -- iter: 1632/1998
[A[ATraining Step: 682  | total loss: [1m[32m0.10409[0m[0m | time: 682.974s
[2K
| RMSProp | epoch: 011 | loss: 0.10409 - acc: 0.9705 -- iter: 1664/1998
[A[ATraining Step: 683  | total loss: [1m[32m0.09923[0m[0m | time: 695.857s
[2K
| RMSProp | epoch: 011 | loss: 0.09923 - acc: 0.9735 -- iter: 1696/1998
[A[ATraining Step: 684  | total loss: [1m[32m0.09045[0m[0m | time: 709.148s
[2K
| RMSProp | epoch: 011 | loss: 0.09045 - acc: 0.9761 -- iter: 1728/1998
[A[ATraining Step: 685  | total loss: [1m[32m0.08538[0m[0m | time: 722.338s
[2K
| RMSProp | epoch: 011 | loss: 0.08538 - acc: 0.9785 -- iter: 1760/1998
[A[ATraining Step: 686  | total loss: [1m[32m0.07831[0m[0m | time: 735.050s
[2K
| RMSProp | epoch: 011 | loss: 0.07831 - acc: 0.9807 -- iter: 1792/1998
[A[ATraining Step: 687  | total loss: [1m[32m0.07143[0m[0m | time: 748.402s
[2K
| RMSProp | epoch: 011 | loss: 0.07143 - acc: 0.9826 -- iter: 1824/1998
[A[ATraining Step: 688  | total loss: [1m[32m0.06645[0m[0m | time: 761.668s
[2K
| RMSProp | epoch: 011 | loss: 0.06645 - acc: 0.9843 -- iter: 1856/1998
[A[ATraining Step: 689  | total loss: [1m[32m0.06726[0m[0m | time: 774.633s
[2K
| RMSProp | epoch: 011 | loss: 0.06726 - acc: 0.9828 -- iter: 1888/1998
[A[ATraining Step: 690  | total loss: [1m[32m0.06239[0m[0m | time: 787.643s
[2K
| RMSProp | epoch: 011 | loss: 0.06239 - acc: 0.9845 -- iter: 1920/1998
[A[ATraining Step: 691  | total loss: [1m[32m0.05760[0m[0m | time: 801.070s
[2K
| RMSProp | epoch: 011 | loss: 0.05760 - acc: 0.9860 -- iter: 1952/1998
[A[ATraining Step: 692  | total loss: [1m[32m0.05504[0m[0m | time: 814.149s
[2K
| RMSProp | epoch: 011 | loss: 0.05504 - acc: 0.9874 -- iter: 1984/1998
[A[ATraining Step: 693  | total loss: [1m[32m0.05181[0m[0m | time: 873.438s
[2K
| RMSProp | epoch: 011 | loss: 0.05181 - acc: 0.9887 | val_loss: 0.24505 - val_acc: 0.9344 -- iter: 1998/1998
--
Training Step: 694  | total loss: [1m[32m0.04700[0m[0m | time: 14.234s
[2K
| RMSProp | epoch: 012 | loss: 0.04700 - acc: 0.9898 -- iter: 0032/1998
[A[ATraining Step: 695  | total loss: [1m[32m0.04322[0m[0m | time: 27.824s
[2K
| RMSProp | epoch: 012 | loss: 0.04322 - acc: 0.9908 -- iter: 0064/1998
[A[ATraining Step: 696  | total loss: [1m[32m0.04079[0m[0m | time: 41.454s
[2K
| RMSProp | epoch: 012 | loss: 0.04079 - acc: 0.9918 -- iter: 0096/1998
[A[ATraining Step: 697  | total loss: [1m[32m0.03706[0m[0m | time: 54.633s
[2K
| RMSProp | epoch: 012 | loss: 0.03706 - acc: 0.9926 -- iter: 0128/1998
[A[ATraining Step: 698  | total loss: [1m[32m0.03357[0m[0m | time: 68.017s
[2K
| RMSProp | epoch: 012 | loss: 0.03357 - acc: 0.9933 -- iter: 0160/1998
[A[ATraining Step: 699  | total loss: [1m[32m0.03074[0m[0m | time: 81.054s
[2K
| RMSProp | epoch: 012 | loss: 0.03074 - acc: 0.9940 -- iter: 0192/1998
[A[ATraining Step: 700  | total loss: [1m[32m0.03238[0m[0m | time: 94.153s
[2K
| RMSProp | epoch: 012 | loss: 0.03238 - acc: 0.9946 -- iter: 0224/1998
[A[ATraining Step: 701  | total loss: [1m[32m0.03062[0m[0m | time: 107.294s
[2K
| RMSProp | epoch: 012 | loss: 0.03062 - acc: 0.9951 -- iter: 0256/1998
[A[ATraining Step: 702  | total loss: [1m[32m0.03182[0m[0m | time: 120.736s
[2K
| RMSProp | epoch: 012 | loss: 0.03182 - acc: 0.9925 -- iter: 0288/1998
[A[ATraining Step: 703  | total loss: [1m[32m0.03766[0m[0m | time: 127.145s
[2K
| RMSProp | epoch: 012 | loss: 0.03766 - acc: 0.9901 -- iter: 0320/1998
[A[ATraining Step: 704  | total loss: [1m[32m0.03493[0m[0m | time: 134.093s
[2K
| RMSProp | epoch: 012 | loss: 0.03493 - acc: 0.9911 -- iter: 0352/1998
[A[ATraining Step: 705  | total loss: [1m[32m0.03154[0m[0m | time: 147.323s
[2K
| RMSProp | epoch: 012 | loss: 0.03154 - acc: 0.9920 -- iter: 0384/1998
[A[ATraining Step: 706  | total loss: [1m[32m0.03742[0m[0m | time: 160.747s
[2K
| RMSProp | epoch: 012 | loss: 0.03742 - acc: 0.9865 -- iter: 0416/1998
[A[ATraining Step: 707  | total loss: [1m[32m0.06391[0m[0m | time: 174.226s
[2K
| RMSProp | epoch: 012 | loss: 0.06391 - acc: 0.9723 -- iter: 0448/1998
[A[ATraining Step: 708  | total loss: [1m[32m0.05784[0m[0m | time: 187.988s
[2K
| RMSProp | epoch: 012 | loss: 0.05784 - acc: 0.9750 -- iter: 0480/1998
[A[ATraining Step: 709  | total loss: [1m[32m0.05501[0m[0m | time: 201.143s
[2K
| RMSProp | epoch: 012 | loss: 0.05501 - acc: 0.9775 -- iter: 0512/1998
[A[ATraining Step: 710  | total loss: [1m[32m0.05598[0m[0m | time: 214.384s
[2K
| RMSProp | epoch: 012 | loss: 0.05598 - acc: 0.9767 -- iter: 0544/1998
[A[ATraining Step: 711  | total loss: [1m[32m0.05052[0m[0m | time: 227.767s
[2K
| RMSProp | epoch: 012 | loss: 0.05052 - acc: 0.9790 -- iter: 0576/1998
[A[ATraining Step: 712  | total loss: [1m[32m0.04638[0m[0m | time: 241.245s
[2K
| RMSProp | epoch: 012 | loss: 0.04638 - acc: 0.9811 -- iter: 0608/1998
[A[ATraining Step: 713  | total loss: [1m[32m0.06431[0m[0m | time: 255.028s
[2K
| RMSProp | epoch: 012 | loss: 0.06431 - acc: 0.9799 -- iter: 0640/1998
[A[ATraining Step: 714  | total loss: [1m[32m0.06307[0m[0m | time: 268.624s
[2K
| RMSProp | epoch: 012 | loss: 0.06307 - acc: 0.9819 -- iter: 0672/1998
[A[ATraining Step: 715  | total loss: [1m[32m0.05883[0m[0m | time: 281.944s
[2K
| RMSProp | epoch: 012 | loss: 0.05883 - acc: 0.9837 -- iter: 0704/1998
[A[ATraining Step: 716  | total loss: [1m[32m0.05473[0m[0m | time: 295.184s
[2K
| RMSProp | epoch: 012 | loss: 0.05473 - acc: 0.9853 -- iter: 0736/1998
[A[ATraining Step: 717  | total loss: [1m[32m0.05100[0m[0m | time: 308.506s
[2K
| RMSProp | epoch: 012 | loss: 0.05100 - acc: 0.9868 -- iter: 0768/1998
[A[ATraining Step: 718  | total loss: [1m[32m0.04727[0m[0m | time: 322.168s
[2K
| RMSProp | epoch: 012 | loss: 0.04727 - acc: 0.9881 -- iter: 0800/1998
[A[ATraining Step: 719  | total loss: [1m[32m0.04335[0m[0m | time: 335.477s
[2K
| RMSProp | epoch: 012 | loss: 0.04335 - acc: 0.9893 -- iter: 0832/1998
[A[ATraining Step: 720  | total loss: [1m[32m0.04954[0m[0m | time: 348.848s
[2K
| RMSProp | epoch: 012 | loss: 0.04954 - acc: 0.9872 -- iter: 0864/1998
[A[ATraining Step: 721  | total loss: [1m[32m0.04538[0m[0m | time: 362.874s
[2K
| RMSProp | epoch: 012 | loss: 0.04538 - acc: 0.9885 -- iter: 0896/1998
[A[ATraining Step: 722  | total loss: [1m[32m0.04632[0m[0m | time: 376.031s
[2K
| RMSProp | epoch: 012 | loss: 0.04632 - acc: 0.9834 -- iter: 0928/1998
[A[ATraining Step: 723  | total loss: [1m[32m0.04448[0m[0m | time: 389.508s
[2K
| RMSProp | epoch: 012 | loss: 0.04448 - acc: 0.9851 -- iter: 0960/1998
[A[ATraining Step: 724  | total loss: [1m[32m0.04370[0m[0m | time: 403.060s
[2K
| RMSProp | epoch: 012 | loss: 0.04370 - acc: 0.9834 -- iter: 0992/1998
[A[ATraining Step: 725  | total loss: [1m[32m0.04412[0m[0m | time: 416.442s
[2K
| RMSProp | epoch: 012 | loss: 0.04412 - acc: 0.9820 -- iter: 1024/1998
[A[ATraining Step: 726  | total loss: [1m[32m0.04139[0m[0m | time: 429.599s
[2K
| RMSProp | epoch: 012 | loss: 0.04139 - acc: 0.9838 -- iter: 1056/1998
[A[ATraining Step: 727  | total loss: [1m[32m0.03920[0m[0m | time: 443.208s
[2K
| RMSProp | epoch: 012 | loss: 0.03920 - acc: 0.9854 -- iter: 1088/1998
[A[ATraining Step: 728  | total loss: [1m[32m0.03594[0m[0m | time: 456.550s
[2K
| RMSProp | epoch: 012 | loss: 0.03594 - acc: 0.9869 -- iter: 1120/1998
[A[ATraining Step: 729  | total loss: [1m[32m0.03831[0m[0m | time: 470.156s
[2K
| RMSProp | epoch: 012 | loss: 0.03831 - acc: 0.9850 -- iter: 1152/1998
[A[ATraining Step: 730  | total loss: [1m[32m0.04223[0m[0m | time: 483.747s
[2K
| RMSProp | epoch: 012 | loss: 0.04223 - acc: 0.9834 -- iter: 1184/1998
[A[ATraining Step: 731  | total loss: [1m[32m0.04785[0m[0m | time: 497.467s
[2K
| RMSProp | epoch: 012 | loss: 0.04785 - acc: 0.9820 -- iter: 1216/1998
[A[ATraining Step: 732  | total loss: [1m[32m0.06597[0m[0m | time: 511.036s
[2K
| RMSProp | epoch: 012 | loss: 0.06597 - acc: 0.9806 -- iter: 1248/1998
[A[ATraining Step: 733  | total loss: [1m[32m0.06060[0m[0m | time: 523.869s
[2K
| RMSProp | epoch: 012 | loss: 0.06060 - acc: 0.9826 -- iter: 1280/1998
[A[ATraining Step: 734  | total loss: [1m[32m0.07083[0m[0m | time: 537.184s
[2K
| RMSProp | epoch: 012 | loss: 0.07083 - acc: 0.9812 -- iter: 1312/1998
[A[ATraining Step: 735  | total loss: [1m[32m0.06485[0m[0m | time: 550.589s
[2K
| RMSProp | epoch: 012 | loss: 0.06485 - acc: 0.9831 -- iter: 1344/1998
[A[ATraining Step: 736  | total loss: [1m[32m0.13158[0m[0m | time: 564.180s
[2K
| RMSProp | epoch: 012 | loss: 0.13158 - acc: 0.9723 -- iter: 1376/1998
[A[ATraining Step: 737  | total loss: [1m[32m0.12335[0m[0m | time: 577.375s
[2K
| RMSProp | epoch: 012 | loss: 0.12335 - acc: 0.9719 -- iter: 1408/1998
[A[ATraining Step: 738  | total loss: [1m[32m0.12168[0m[0m | time: 590.843s
[2K
| RMSProp | epoch: 012 | loss: 0.12168 - acc: 0.9716 -- iter: 1440/1998
[A[ATraining Step: 739  | total loss: [1m[32m0.14061[0m[0m | time: 604.007s
[2K
| RMSProp | epoch: 012 | loss: 0.14061 - acc: 0.9682 -- iter: 1472/1998
[A[ATraining Step: 740  | total loss: [1m[32m0.12971[0m[0m | time: 617.438s
[2K
| RMSProp | epoch: 012 | loss: 0.12971 - acc: 0.9714 -- iter: 1504/1998
[A[ATraining Step: 741  | total loss: [1m[32m0.11771[0m[0m | time: 632.323s
[2K
| RMSProp | epoch: 012 | loss: 0.11771 - acc: 0.9742 -- iter: 1536/1998
[A[ATraining Step: 742  | total loss: [1m[32m0.10991[0m[0m | time: 647.316s
[2K
| RMSProp | epoch: 012 | loss: 0.10991 - acc: 0.9768 -- iter: 1568/1998
[A[ATraining Step: 743  | total loss: [1m[32m0.09967[0m[0m | time: 662.054s
[2K
| RMSProp | epoch: 012 | loss: 0.09967 - acc: 0.9791 -- iter: 1600/1998
[A[ATraining Step: 744  | total loss: [1m[32m0.09093[0m[0m | time: 676.735s
[2K
| RMSProp | epoch: 012 | loss: 0.09093 - acc: 0.9812 -- iter: 1632/1998
[A[ATraining Step: 745  | total loss: [1m[32m0.08321[0m[0m | time: 691.381s
[2K
| RMSProp | epoch: 012 | loss: 0.08321 - acc: 0.9831 -- iter: 1664/1998
[A[ATraining Step: 746  | total loss: [1m[32m0.07696[0m[0m | time: 706.259s
[2K
| RMSProp | epoch: 012 | loss: 0.07696 - acc: 0.9848 -- iter: 1696/1998
[A[ATraining Step: 747  | total loss: [1m[32m0.08979[0m[0m | time: 721.233s
[2K
| RMSProp | epoch: 012 | loss: 0.08979 - acc: 0.9832 -- iter: 1728/1998
[A[ATraining Step: 748  | total loss: [1m[32m0.08243[0m[0m | time: 736.051s
[2K
| RMSProp | epoch: 012 | loss: 0.08243 - acc: 0.9849 -- iter: 1760/1998
[A[ATraining Step: 749  | total loss: [1m[32m0.07664[0m[0m | time: 746.317s
[2K
| RMSProp | epoch: 012 | loss: 0.07664 - acc: 0.9864 -- iter: 1792/1998
[A[ATraining Step: 750  | total loss: [1m[32m0.06933[0m[0m | time: 755.360s
[2K
| RMSProp | epoch: 012 | loss: 0.06933 - acc: 0.9877 -- iter: 1824/1998
[A[ATraining Step: 751  | total loss: [1m[32m0.06469[0m[0m | time: 764.354s
[2K
| RMSProp | epoch: 012 | loss: 0.06469 - acc: 0.9890 -- iter: 1856/1998
[A[ATraining Step: 752  | total loss: [1m[32m0.05953[0m[0m | time: 774.300s
[2K
| RMSProp | epoch: 012 | loss: 0.05953 - acc: 0.9901 -- iter: 1888/1998
[A[ATraining Step: 753  | total loss: [1m[32m0.06361[0m[0m | time: 787.222s
[2K
| RMSProp | epoch: 012 | loss: 0.06361 - acc: 0.9879 -- iter: 1920/1998
[A[ATraining Step: 754  | total loss: [1m[32m0.06333[0m[0m | time: 800.455s
[2K
| RMSProp | epoch: 012 | loss: 0.06333 - acc: 0.9860 -- iter: 1952/1998
[A[ATraining Step: 755  | total loss: [1m[32m0.06083[0m[0m | time: 813.394s
[2K
| RMSProp | epoch: 012 | loss: 0.06083 - acc: 0.9874 -- iter: 1984/1998
[A[ATraining Step: 756  | total loss: [1m[32m0.05794[0m[0m | time: 873.245s
[2K
| RMSProp | epoch: 012 | loss: 0.05794 - acc: 0.9887 | val_loss: 0.23936 - val_acc: 0.9280 -- iter: 1998/1998
--
Training Step: 757  | total loss: [1m[32m0.05320[0m[0m | time: 13.513s
[2K
| RMSProp | epoch: 013 | loss: 0.05320 - acc: 0.9898 -- iter: 0032/1998
[A[ATraining Step: 758  | total loss: [1m[32m0.05452[0m[0m | time: 27.230s
[2K
| RMSProp | epoch: 013 | loss: 0.05452 - acc: 0.9877 -- iter: 0064/1998
[A[ATraining Step: 759  | total loss: [1m[32m0.05396[0m[0m | time: 40.451s
[2K
| RMSProp | epoch: 013 | loss: 0.05396 - acc: 0.9858 -- iter: 0096/1998
[A[ATraining Step: 760  | total loss: [1m[32m0.04869[0m[0m | time: 53.642s
[2K
| RMSProp | epoch: 013 | loss: 0.04869 - acc: 0.9872 -- iter: 0128/1998
[A[ATraining Step: 761  | total loss: [1m[32m0.04505[0m[0m | time: 66.989s
[2K
| RMSProp | epoch: 013 | loss: 0.04505 - acc: 0.9885 -- iter: 0160/1998
[A[ATraining Step: 762  | total loss: [1m[32m0.04077[0m[0m | time: 80.113s
[2K
| RMSProp | epoch: 013 | loss: 0.04077 - acc: 0.9897 -- iter: 0192/1998
[A[ATraining Step: 763  | total loss: [1m[32m0.03701[0m[0m | time: 93.814s
[2K
| RMSProp | epoch: 013 | loss: 0.03701 - acc: 0.9907 -- iter: 0224/1998
[A[ATraining Step: 764  | total loss: [1m[32m0.03356[0m[0m | time: 107.139s
[2K
| RMSProp | epoch: 013 | loss: 0.03356 - acc: 0.9916 -- iter: 0256/1998
[A[ATraining Step: 765  | total loss: [1m[32m0.03068[0m[0m | time: 120.192s
[2K
| RMSProp | epoch: 013 | loss: 0.03068 - acc: 0.9925 -- iter: 0288/1998
[A[ATraining Step: 766  | total loss: [1m[32m0.02769[0m[0m | time: 133.383s
[2K
| RMSProp | epoch: 013 | loss: 0.02769 - acc: 0.9932 -- iter: 0320/1998
[A[ATraining Step: 767  | total loss: [1m[32m0.02535[0m[0m | time: 140.381s
[2K
| RMSProp | epoch: 013 | loss: 0.02535 - acc: 0.9939 -- iter: 0352/1998
[A[ATraining Step: 768  | total loss: [1m[32m0.02283[0m[0m | time: 146.929s
[2K
| RMSProp | epoch: 013 | loss: 0.02283 - acc: 0.9945 -- iter: 0384/1998
[A[ATraining Step: 769  | total loss: [1m[32m0.02057[0m[0m | time: 160.085s
[2K
| RMSProp | epoch: 013 | loss: 0.02057 - acc: 0.9951 -- iter: 0416/1998
[A[ATraining Step: 770  | total loss: [1m[32m0.02019[0m[0m | time: 173.200s
[2K
| RMSProp | epoch: 013 | loss: 0.02019 - acc: 0.9955 -- iter: 0448/1998
[A[ATraining Step: 771  | total loss: [1m[32m0.01873[0m[0m | time: 186.284s
[2K
| RMSProp | epoch: 013 | loss: 0.01873 - acc: 0.9960 -- iter: 0480/1998
[A[ATraining Step: 772  | total loss: [1m[32m0.01696[0m[0m | time: 199.601s
[2K
| RMSProp | epoch: 013 | loss: 0.01696 - acc: 0.9964 -- iter: 0512/1998
[A[ATraining Step: 773  | total loss: [1m[32m0.01635[0m[0m | time: 213.076s
[2K
| RMSProp | epoch: 013 | loss: 0.01635 - acc: 0.9968 -- iter: 0544/1998
[A[ATraining Step: 774  | total loss: [1m[32m0.01588[0m[0m | time: 226.393s
[2K
| RMSProp | epoch: 013 | loss: 0.01588 - acc: 0.9971 -- iter: 0576/1998
[A[ATraining Step: 775  | total loss: [1m[32m0.01480[0m[0m | time: 239.758s
[2K
| RMSProp | epoch: 013 | loss: 0.01480 - acc: 0.9974 -- iter: 0608/1998
[A[ATraining Step: 776  | total loss: [1m[32m0.01419[0m[0m | time: 254.078s
[2K
| RMSProp | epoch: 013 | loss: 0.01419 - acc: 0.9976 -- iter: 0640/1998
[A[ATraining Step: 777  | total loss: [1m[32m0.01292[0m[0m | time: 266.753s
[2K
| RMSProp | epoch: 013 | loss: 0.01292 - acc: 0.9979 -- iter: 0672/1998
[A[ATraining Step: 778  | total loss: [1m[32m0.01275[0m[0m | time: 280.393s
[2K
| RMSProp | epoch: 013 | loss: 0.01275 - acc: 0.9981 -- iter: 0704/1998
[A[ATraining Step: 779  | total loss: [1m[32m0.01161[0m[0m | time: 293.600s
[2K
| RMSProp | epoch: 013 | loss: 0.01161 - acc: 0.9983 -- iter: 0736/1998
[A[ATraining Step: 780  | total loss: [1m[32m0.01070[0m[0m | time: 306.667s
[2K
| RMSProp | epoch: 013 | loss: 0.01070 - acc: 0.9984 -- iter: 0768/1998
[A[ATraining Step: 781  | total loss: [1m[32m0.01118[0m[0m | time: 320.475s
[2K
| RMSProp | epoch: 013 | loss: 0.01118 - acc: 0.9986 -- iter: 0800/1998
[A[ATraining Step: 782  | total loss: [1m[32m0.01194[0m[0m | time: 333.904s
[2K
| RMSProp | epoch: 013 | loss: 0.01194 - acc: 0.9987 -- iter: 0832/1998
[A[ATraining Step: 783  | total loss: [1m[32m0.01466[0m[0m | time: 347.186s
[2K
| RMSProp | epoch: 013 | loss: 0.01466 - acc: 0.9957 -- iter: 0864/1998
[A[ATraining Step: 784  | total loss: [1m[32m0.03185[0m[0m | time: 360.520s
[2K
| RMSProp | epoch: 013 | loss: 0.03185 - acc: 0.9868 -- iter: 0896/1998
[A[ATraining Step: 785  | total loss: [1m[32m0.08232[0m[0m | time: 374.012s
[2K
| RMSProp | epoch: 013 | loss: 0.08232 - acc: 0.9756 -- iter: 0928/1998
[A[ATraining Step: 786  | total loss: [1m[32m0.08097[0m[0m | time: 386.802s
[2K
| RMSProp | epoch: 013 | loss: 0.08097 - acc: 0.9718 -- iter: 0960/1998
[A[ATraining Step: 787  | total loss: [1m[32m0.07571[0m[0m | time: 399.717s
[2K
| RMSProp | epoch: 013 | loss: 0.07571 - acc: 0.9715 -- iter: 0992/1998
[A[ATraining Step: 788  | total loss: [1m[32m0.07278[0m[0m | time: 413.316s
[2K
| RMSProp | epoch: 013 | loss: 0.07278 - acc: 0.9712 -- iter: 1024/1998
[A[ATraining Step: 789  | total loss: [1m[32m0.06851[0m[0m | time: 426.361s
[2K
| RMSProp | epoch: 013 | loss: 0.06851 - acc: 0.9741 -- iter: 1056/1998
[A[ATraining Step: 790  | total loss: [1m[32m0.09330[0m[0m | time: 439.621s
[2K
| RMSProp | epoch: 013 | loss: 0.09330 - acc: 0.9673 -- iter: 1088/1998
[A[ATraining Step: 791  | total loss: [1m[32m0.09207[0m[0m | time: 452.588s
[2K
| RMSProp | epoch: 013 | loss: 0.09207 - acc: 0.9643 -- iter: 1120/1998
[A[ATraining Step: 792  | total loss: [1m[32m0.12248[0m[0m | time: 466.212s
[2K
| RMSProp | epoch: 013 | loss: 0.12248 - acc: 0.9554 -- iter: 1152/1998
[A[ATraining Step: 793  | total loss: [1m[32m0.12488[0m[0m | time: 479.633s
[2K
| RMSProp | epoch: 013 | loss: 0.12488 - acc: 0.9567 -- iter: 1184/1998
[A[ATraining Step: 794  | total loss: [1m[32m0.12021[0m[0m | time: 492.775s
[2K
| RMSProp | epoch: 013 | loss: 0.12021 - acc: 0.9579 -- iter: 1216/1998
[A[ATraining Step: 795  | total loss: [1m[32m0.10854[0m[0m | time: 506.040s
[2K
| RMSProp | epoch: 013 | loss: 0.10854 - acc: 0.9621 -- iter: 1248/1998
[A[ATraining Step: 796  | total loss: [1m[32m0.09867[0m[0m | time: 519.116s
[2K
| RMSProp | epoch: 013 | loss: 0.09867 - acc: 0.9659 -- iter: 1280/1998
[A[ATraining Step: 797  | total loss: [1m[32m0.08990[0m[0m | time: 532.666s
[2K
| RMSProp | epoch: 013 | loss: 0.08990 - acc: 0.9693 -- iter: 1312/1998
[A[ATraining Step: 798  | total loss: [1m[32m0.08263[0m[0m | time: 545.881s
[2K
| RMSProp | epoch: 013 | loss: 0.08263 - acc: 0.9724 -- iter: 1344/1998
[A[ATraining Step: 799  | total loss: [1m[32m0.07747[0m[0m | time: 559.171s
[2K
| RMSProp | epoch: 013 | loss: 0.07747 - acc: 0.9752 -- iter: 1376/1998
[A[ATraining Step: 800  | total loss: [1m[32m0.13189[0m[0m | time: 619.427s
[2K
| RMSProp | epoch: 013 | loss: 0.13189 - acc: 0.9683 | val_loss: 0.49381 - val_acc: 0.8432 -- iter: 1408/1998
--
Training Step: 801  | total loss: [1m[32m0.12352[0m[0m | time: 632.801s
[2K
| RMSProp | epoch: 013 | loss: 0.12352 - acc: 0.9714 -- iter: 1440/1998
[A[ATraining Step: 802  | total loss: [1m[32m0.11279[0m[0m | time: 646.264s
[2K
| RMSProp | epoch: 013 | loss: 0.11279 - acc: 0.9743 -- iter: 1472/1998
[A[ATraining Step: 803  | total loss: [1m[32m0.12211[0m[0m | time: 659.217s
[2K
| RMSProp | epoch: 013 | loss: 0.12211 - acc: 0.9644 -- iter: 1504/1998
[A[ATraining Step: 804  | total loss: [1m[32m0.12587[0m[0m | time: 672.645s
[2K
| RMSProp | epoch: 013 | loss: 0.12587 - acc: 0.9648 -- iter: 1536/1998
[A[ATraining Step: 805  | total loss: [1m[32m0.11831[0m[0m | time: 685.949s
[2K
| RMSProp | epoch: 013 | loss: 0.11831 - acc: 0.9683 -- iter: 1568/1998
[A[ATraining Step: 806  | total loss: [1m[32m0.11587[0m[0m | time: 700.823s
[2K
| RMSProp | epoch: 013 | loss: 0.11587 - acc: 0.9652 -- iter: 1600/1998
[A[ATraining Step: 807  | total loss: [1m[32m0.10663[0m[0m | time: 715.073s
[2K
| RMSProp | epoch: 013 | loss: 0.10663 - acc: 0.9687 -- iter: 1632/1998
[A[ATraining Step: 808  | total loss: [1m[32m0.09727[0m[0m | time: 730.143s
[2K
| RMSProp | epoch: 013 | loss: 0.09727 - acc: 0.9718 -- iter: 1664/1998
[A[ATraining Step: 809  | total loss: [1m[32m0.09049[0m[0m | time: 744.412s
[2K
| RMSProp | epoch: 013 | loss: 0.09049 - acc: 0.9715 -- iter: 1696/1998
[A[ATraining Step: 810  | total loss: [1m[32m0.08250[0m[0m | time: 758.875s
[2K
| RMSProp | epoch: 013 | loss: 0.08250 - acc: 0.9744 -- iter: 1728/1998
[A[ATraining Step: 811  | total loss: [1m[32m0.07438[0m[0m | time: 774.051s
[2K
| RMSProp | epoch: 013 | loss: 0.07438 - acc: 0.9769 -- iter: 1760/1998
[A[ATraining Step: 812  | total loss: [1m[32m0.06706[0m[0m | time: 789.368s
[2K
| RMSProp | epoch: 013 | loss: 0.06706 - acc: 0.9793 -- iter: 1792/1998
[A[ATraining Step: 813  | total loss: [1m[32m0.08003[0m[0m | time: 804.636s
[2K
| RMSProp | epoch: 013 | loss: 0.08003 - acc: 0.9782 -- iter: 1824/1998
[A[ATraining Step: 814  | total loss: [1m[32m0.07378[0m[0m | time: 815.825s
[2K
| RMSProp | epoch: 013 | loss: 0.07378 - acc: 0.9804 -- iter: 1856/1998
[A[ATraining Step: 815  | total loss: [1m[32m0.06691[0m[0m | time: 826.848s
[2K
| RMSProp | epoch: 013 | loss: 0.06691 - acc: 0.9823 -- iter: 1888/1998
[A[ATraining Step: 816  | total loss: [1m[32m0.06121[0m[0m | time: 840.502s
[2K
| RMSProp | epoch: 013 | loss: 0.06121 - acc: 0.9841 -- iter: 1920/1998
[A[ATraining Step: 817  | total loss: [1m[32m0.05837[0m[0m | time: 853.965s
[2K
| RMSProp | epoch: 013 | loss: 0.05837 - acc: 0.9857 -- iter: 1952/1998
[A[ATraining Step: 818  | total loss: [1m[32m0.06402[0m[0m | time: 867.443s
[2K
| RMSProp | epoch: 013 | loss: 0.06402 - acc: 0.9840 -- iter: 1984/1998
[A[ATraining Step: 819  | total loss: [1m[32m0.05875[0m[0m | time: 927.621s
[2K
| RMSProp | epoch: 013 | loss: 0.05875 - acc: 0.9856 | val_loss: 0.32899 - val_acc: 0.9168 -- iter: 1998/1998
--
Training Step: 820  | total loss: [1m[32m0.05404[0m[0m | time: 13.529s
[2K
| RMSProp | epoch: 014 | loss: 0.05404 - acc: 0.9870 -- iter: 0032/1998
[A[ATraining Step: 821  | total loss: [1m[32m0.04930[0m[0m | time: 26.714s
[2K
| RMSProp | epoch: 014 | loss: 0.04930 - acc: 0.9883 -- iter: 0064/1998
[A[ATraining Step: 822  | total loss: [1m[32m0.04866[0m[0m | time: 40.375s
[2K
| RMSProp | epoch: 014 | loss: 0.04866 - acc: 0.9864 -- iter: 0096/1998
[A[ATraining Step: 823  | total loss: [1m[32m0.04429[0m[0m | time: 53.598s
[2K
| RMSProp | epoch: 014 | loss: 0.04429 - acc: 0.9877 -- iter: 0128/1998
[A[ATraining Step: 824  | total loss: [1m[32m0.04206[0m[0m | time: 67.316s
[2K
| RMSProp | epoch: 014 | loss: 0.04206 - acc: 0.9890 -- iter: 0160/1998
[A[ATraining Step: 825  | total loss: [1m[32m0.03906[0m[0m | time: 80.566s
[2K
| RMSProp | epoch: 014 | loss: 0.03906 - acc: 0.9901 -- iter: 0192/1998
[A[ATraining Step: 826  | total loss: [1m[32m0.03635[0m[0m | time: 93.979s
[2K
| RMSProp | epoch: 014 | loss: 0.03635 - acc: 0.9911 -- iter: 0224/1998
[A[ATraining Step: 827  | total loss: [1m[32m0.03333[0m[0m | time: 107.397s
[2K
| RMSProp | epoch: 014 | loss: 0.03333 - acc: 0.9920 -- iter: 0256/1998
[A[ATraining Step: 828  | total loss: [1m[32m0.03120[0m[0m | time: 120.153s
[2K
| RMSProp | epoch: 014 | loss: 0.03120 - acc: 0.9928 -- iter: 0288/1998
[A[ATraining Step: 829  | total loss: [1m[32m0.02822[0m[0m | time: 133.461s
[2K
| RMSProp | epoch: 014 | loss: 0.02822 - acc: 0.9935 -- iter: 0320/1998
[A[ATraining Step: 830  | total loss: [1m[32m0.02581[0m[0m | time: 146.382s
[2K
| RMSProp | epoch: 014 | loss: 0.02581 - acc: 0.9941 -- iter: 0352/1998
[A[ATraining Step: 831  | total loss: [1m[32m0.02372[0m[0m | time: 153.587s
[2K
| RMSProp | epoch: 014 | loss: 0.02372 - acc: 0.9947 -- iter: 0384/1998
[A[ATraining Step: 832  | total loss: [1m[32m0.02200[0m[0m | time: 159.995s
[2K
| RMSProp | epoch: 014 | loss: 0.02200 - acc: 0.9953 -- iter: 0416/1998
[A[ATraining Step: 833  | total loss: [1m[32m0.01987[0m[0m | time: 173.655s
[2K
| RMSProp | epoch: 014 | loss: 0.01987 - acc: 0.9957 -- iter: 0448/1998
[A[ATraining Step: 834  | total loss: [1m[32m0.02183[0m[0m | time: 187.190s
[2K
| RMSProp | epoch: 014 | loss: 0.02183 - acc: 0.9930 -- iter: 0480/1998
[A[ATraining Step: 835  | total loss: [1m[32m0.02195[0m[0m | time: 200.879s
[2K
| RMSProp | epoch: 014 | loss: 0.02195 - acc: 0.9937 -- iter: 0512/1998
[A[ATraining Step: 836  | total loss: [1m[32m0.08202[0m[0m | time: 214.333s
[2K
| RMSProp | epoch: 014 | loss: 0.08202 - acc: 0.9819 -- iter: 0544/1998
[A[ATraining Step: 837  | total loss: [1m[32m0.07766[0m[0m | time: 228.209s
[2K
| RMSProp | epoch: 014 | loss: 0.07766 - acc: 0.9805 -- iter: 0576/1998
[A[ATraining Step: 838  | total loss: [1m[32m0.07024[0m[0m | time: 241.802s
[2K
| RMSProp | epoch: 014 | loss: 0.07024 - acc: 0.9825 -- iter: 0608/1998
[A[ATraining Step: 839  | total loss: [1m[32m0.07387[0m[0m | time: 255.551s
[2K
| RMSProp | epoch: 014 | loss: 0.07387 - acc: 0.9749 -- iter: 0640/1998
[A[ATraining Step: 840  | total loss: [1m[32m0.07107[0m[0m | time: 269.095s
[2K
| RMSProp | epoch: 014 | loss: 0.07107 - acc: 0.9743 -- iter: 0672/1998
[A[ATraining Step: 841  | total loss: [1m[32m0.06591[0m[0m | time: 282.234s
[2K
| RMSProp | epoch: 014 | loss: 0.06591 - acc: 0.9768 -- iter: 0704/1998
[A[ATraining Step: 842  | total loss: [1m[32m0.06078[0m[0m | time: 295.198s
[2K
| RMSProp | epoch: 014 | loss: 0.06078 - acc: 0.9791 -- iter: 0736/1998
[A[ATraining Step: 843  | total loss: [1m[32m0.05615[0m[0m | time: 308.857s
[2K
| RMSProp | epoch: 014 | loss: 0.05615 - acc: 0.9812 -- iter: 0768/1998
[A[ATraining Step: 844  | total loss: [1m[32m0.05127[0m[0m | time: 321.880s
[2K
| RMSProp | epoch: 014 | loss: 0.05127 - acc: 0.9831 -- iter: 0800/1998
[A[ATraining Step: 845  | total loss: [1m[32m0.04683[0m[0m | time: 335.744s
[2K
| RMSProp | epoch: 014 | loss: 0.04683 - acc: 0.9848 -- iter: 0832/1998
[A[ATraining Step: 846  | total loss: [1m[32m0.04319[0m[0m | time: 349.282s
[2K
| RMSProp | epoch: 014 | loss: 0.04319 - acc: 0.9863 -- iter: 0864/1998
[A[ATraining Step: 847  | total loss: [1m[32m0.03942[0m[0m | time: 362.100s
[2K
| RMSProp | epoch: 014 | loss: 0.03942 - acc: 0.9877 -- iter: 0896/1998
[A[ATraining Step: 848  | total loss: [1m[32m0.04666[0m[0m | time: 375.617s
[2K
| RMSProp | epoch: 014 | loss: 0.04666 - acc: 0.9827 -- iter: 0928/1998
[A[ATraining Step: 849  | total loss: [1m[32m0.04219[0m[0m | time: 388.647s
[2K
| RMSProp | epoch: 014 | loss: 0.04219 - acc: 0.9844 -- iter: 0960/1998
[A[ATraining Step: 850  | total loss: [1m[32m0.04528[0m[0m | time: 402.056s
[2K
| RMSProp | epoch: 014 | loss: 0.04528 - acc: 0.9828 -- iter: 0992/1998
[A[ATraining Step: 851  | total loss: [1m[32m0.04988[0m[0m | time: 415.450s
[2K
| RMSProp | epoch: 014 | loss: 0.04988 - acc: 0.9783 -- iter: 1024/1998
[A[ATraining Step: 852  | total loss: [1m[32m0.04674[0m[0m | time: 428.605s
[2K
| RMSProp | epoch: 014 | loss: 0.04674 - acc: 0.9805 -- iter: 1056/1998
[A[ATraining Step: 853  | total loss: [1m[32m0.04814[0m[0m | time: 442.165s
[2K
| RMSProp | epoch: 014 | loss: 0.04814 - acc: 0.9793 -- iter: 1088/1998
[A[ATraining Step: 854  | total loss: [1m[32m0.04551[0m[0m | time: 455.413s
[2K
| RMSProp | epoch: 014 | loss: 0.04551 - acc: 0.9814 -- iter: 1120/1998
[A[ATraining Step: 855  | total loss: [1m[32m0.04183[0m[0m | time: 468.988s
[2K
| RMSProp | epoch: 014 | loss: 0.04183 - acc: 0.9832 -- iter: 1152/1998
[A[ATraining Step: 856  | total loss: [1m[32m0.03867[0m[0m | time: 482.401s
[2K
| RMSProp | epoch: 014 | loss: 0.03867 - acc: 0.9849 -- iter: 1184/1998
[A[ATraining Step: 857  | total loss: [1m[32m0.03550[0m[0m | time: 495.768s
[2K
| RMSProp | epoch: 014 | loss: 0.03550 - acc: 0.9864 -- iter: 1216/1998
[A[ATraining Step: 858  | total loss: [1m[32m0.04128[0m[0m | time: 509.128s
[2K
| RMSProp | epoch: 014 | loss: 0.04128 - acc: 0.9847 -- iter: 1248/1998
[A[ATraining Step: 859  | total loss: [1m[32m0.04150[0m[0m | time: 522.167s
[2K
| RMSProp | epoch: 014 | loss: 0.04150 - acc: 0.9862 -- iter: 1280/1998
[A[ATraining Step: 860  | total loss: [1m[32m0.03798[0m[0m | time: 535.395s
[2K
| RMSProp | epoch: 014 | loss: 0.03798 - acc: 0.9876 -- iter: 1312/1998
[A[ATraining Step: 861  | total loss: [1m[32m0.04945[0m[0m | time: 548.646s
[2K
| RMSProp | epoch: 014 | loss: 0.04945 - acc: 0.9826 -- iter: 1344/1998
[A[ATraining Step: 862  | total loss: [1m[32m0.04504[0m[0m | time: 561.924s
[2K
| RMSProp | epoch: 014 | loss: 0.04504 - acc: 0.9843 -- iter: 1376/1998
[A[ATraining Step: 863  | total loss: [1m[32m0.04141[0m[0m | time: 575.384s
[2K
| RMSProp | epoch: 014 | loss: 0.04141 - acc: 0.9859 -- iter: 1408/1998
[A[ATraining Step: 864  | total loss: [1m[32m0.07279[0m[0m | time: 588.912s
[2K
| RMSProp | epoch: 014 | loss: 0.07279 - acc: 0.9842 -- iter: 1440/1998
[A[ATraining Step: 865  | total loss: [1m[32m0.06652[0m[0m | time: 602.316s
[2K
| RMSProp | epoch: 014 | loss: 0.06652 - acc: 0.9857 -- iter: 1472/1998
[A[ATraining Step: 866  | total loss: [1m[32m0.06786[0m[0m | time: 615.924s
[2K
| RMSProp | epoch: 014 | loss: 0.06786 - acc: 0.9840 -- iter: 1504/1998
[A[ATraining Step: 867  | total loss: [1m[32m0.06168[0m[0m | time: 629.421s
[2K
| RMSProp | epoch: 014 | loss: 0.06168 - acc: 0.9856 -- iter: 1536/1998
[A[ATraining Step: 868  | total loss: [1m[32m0.05619[0m[0m | time: 642.484s
[2K
| RMSProp | epoch: 014 | loss: 0.05619 - acc: 0.9871 -- iter: 1568/1998
[A[ATraining Step: 869  | total loss: [1m[32m0.05127[0m[0m | time: 655.937s
[2K
| RMSProp | epoch: 014 | loss: 0.05127 - acc: 0.9884 -- iter: 1600/1998
[A[ATraining Step: 870  | total loss: [1m[32m0.04727[0m[0m | time: 669.721s
[2K
| RMSProp | epoch: 014 | loss: 0.04727 - acc: 0.9895 -- iter: 1632/1998
[A[ATraining Step: 871  | total loss: [1m[32m0.04402[0m[0m | time: 682.898s
[2K
| RMSProp | epoch: 014 | loss: 0.04402 - acc: 0.9906 -- iter: 1664/1998
[A[ATraining Step: 872  | total loss: [1m[32m0.03972[0m[0m | time: 696.133s
[2K
| RMSProp | epoch: 014 | loss: 0.03972 - acc: 0.9915 -- iter: 1696/1998
[A[ATraining Step: 873  | total loss: [1m[32m0.03669[0m[0m | time: 708.959s
[2K
| RMSProp | epoch: 014 | loss: 0.03669 - acc: 0.9924 -- iter: 1728/1998
[A[ATraining Step: 874  | total loss: [1m[32m0.03776[0m[0m | time: 722.690s
[2K
| RMSProp | epoch: 014 | loss: 0.03776 - acc: 0.9931 -- iter: 1760/1998
[A[ATraining Step: 875  | total loss: [1m[32m0.03408[0m[0m | time: 736.117s
[2K
| RMSProp | epoch: 014 | loss: 0.03408 - acc: 0.9938 -- iter: 1792/1998
[A[ATraining Step: 876  | total loss: [1m[32m0.03404[0m[0m | time: 749.738s
[2K
| RMSProp | epoch: 014 | loss: 0.03404 - acc: 0.9944 -- iter: 1824/1998
[A[ATraining Step: 877  | total loss: [1m[32m0.03086[0m[0m | time: 762.633s
[2K
| RMSProp | epoch: 014 | loss: 0.03086 - acc: 0.9950 -- iter: 1856/1998
[A[ATraining Step: 878  | total loss: [1m[32m0.02808[0m[0m | time: 776.139s
[2K
| RMSProp | epoch: 014 | loss: 0.02808 - acc: 0.9955 -- iter: 1888/1998
[A[ATraining Step: 879  | total loss: [1m[32m0.02653[0m[0m | time: 789.641s
[2K
| RMSProp | epoch: 014 | loss: 0.02653 - acc: 0.9959 -- iter: 1920/1998
[A[ATraining Step: 880  | total loss: [1m[32m0.03302[0m[0m | time: 802.910s
[2K
| RMSProp | epoch: 014 | loss: 0.03302 - acc: 0.9932 -- iter: 1952/1998
[A[ATraining Step: 881  | total loss: [1m[32m0.03229[0m[0m | time: 816.296s
[2K
| RMSProp | epoch: 014 | loss: 0.03229 - acc: 0.9939 -- iter: 1984/1998
[A[ATraining Step: 882  | total loss: [1m[32m0.02958[0m[0m | time: 877.634s
[2K
| RMSProp | epoch: 014 | loss: 0.02958 - acc: 0.9945 | val_loss: 2.36138 - val_acc: 0.6272 -- iter: 1998/1998
--
Training Step: 883  | total loss: [1m[32m0.02746[0m[0m | time: 13.746s
[2K
| RMSProp | epoch: 015 | loss: 0.02746 - acc: 0.9951 -- iter: 0032/1998
[A[ATraining Step: 884  | total loss: [1m[32m0.02488[0m[0m | time: 27.083s
[2K
| RMSProp | epoch: 015 | loss: 0.02488 - acc: 0.9956 -- iter: 0064/1998
[A[ATraining Step: 885  | total loss: [1m[32m0.02275[0m[0m | time: 40.229s
[2K
| RMSProp | epoch: 015 | loss: 0.02275 - acc: 0.9960 -- iter: 0096/1998
[A[ATraining Step: 886  | total loss: [1m[32m0.03155[0m[0m | time: 53.138s
[2K
| RMSProp | epoch: 015 | loss: 0.03155 - acc: 0.9901 -- iter: 0128/1998
[A[ATraining Step: 887  | total loss: [1m[32m0.02966[0m[0m | time: 66.388s
[2K
| RMSProp | epoch: 015 | loss: 0.02966 - acc: 0.9911 -- iter: 0160/1998
[A[ATraining Step: 888  | total loss: [1m[32m0.03655[0m[0m | time: 79.820s
[2K
| RMSProp | epoch: 015 | loss: 0.03655 - acc: 0.9858 -- iter: 0192/1998
[A[ATraining Step: 889  | total loss: [1m[32m0.04982[0m[0m | time: 93.458s
[2K
| RMSProp | epoch: 015 | loss: 0.04982 - acc: 0.9809 -- iter: 0224/1998
[A[ATraining Step: 890  | total loss: [1m[32m0.04834[0m[0m | time: 106.509s
[2K
| RMSProp | epoch: 015 | loss: 0.04834 - acc: 0.9797 -- iter: 0256/1998
[A[ATraining Step: 891  | total loss: [1m[32m0.04969[0m[0m | time: 119.932s
[2K
| RMSProp | epoch: 015 | loss: 0.04969 - acc: 0.9755 -- iter: 0288/1998
[A[ATraining Step: 892  | total loss: [1m[32m0.06029[0m[0m | time: 133.307s
[2K
| RMSProp | epoch: 015 | loss: 0.06029 - acc: 0.9717 -- iter: 0320/1998
[A[ATraining Step: 893  | total loss: [1m[32m0.06820[0m[0m | time: 147.094s
[2K
| RMSProp | epoch: 015 | loss: 0.06820 - acc: 0.9620 -- iter: 0352/1998
[A[ATraining Step: 894  | total loss: [1m[32m0.06183[0m[0m | time: 160.263s
[2K
| RMSProp | epoch: 015 | loss: 0.06183 - acc: 0.9658 -- iter: 0384/1998
[A[ATraining Step: 895  | total loss: [1m[32m0.06828[0m[0m | time: 167.368s
[2K
| RMSProp | epoch: 015 | loss: 0.06828 - acc: 0.9630 -- iter: 0416/1998
[A[ATraining Step: 896  | total loss: [1m[32m0.06215[0m[0m | time: 173.819s
[2K
| RMSProp | epoch: 015 | loss: 0.06215 - acc: 0.9667 -- iter: 0448/1998
[A[ATraining Step: 897  | total loss: [1m[32m0.05598[0m[0m | time: 187.397s
[2K
| RMSProp | epoch: 015 | loss: 0.05598 - acc: 0.9700 -- iter: 0480/1998
[A[ATraining Step: 898  | total loss: [1m[32m0.05068[0m[0m | time: 200.775s
[2K
| RMSProp | epoch: 015 | loss: 0.05068 - acc: 0.9730 -- iter: 0512/1998
[A[ATraining Step: 899  | total loss: [1m[32m0.04697[0m[0m | time: 214.515s
[2K
| RMSProp | epoch: 015 | loss: 0.04697 - acc: 0.9757 -- iter: 0544/1998
[A[ATraining Step: 900  | total loss: [1m[32m0.04351[0m[0m | time: 227.566s
[2K
| RMSProp | epoch: 015 | loss: 0.04351 - acc: 0.9781 -- iter: 0576/1998
[A[ATraining Step: 901  | total loss: [1m[32m0.04137[0m[0m | time: 241.318s
[2K
| RMSProp | epoch: 015 | loss: 0.04137 - acc: 0.9803 -- iter: 0608/1998
[A[ATraining Step: 902  | total loss: [1m[32m0.03966[0m[0m | time: 255.111s
[2K
| RMSProp | epoch: 015 | loss: 0.03966 - acc: 0.9823 -- iter: 0640/1998
[A[ATraining Step: 903  | total loss: [1m[32m0.03583[0m[0m | time: 269.031s
[2K
| RMSProp | epoch: 015 | loss: 0.03583 - acc: 0.9841 -- iter: 0672/1998
[A[ATraining Step: 904  | total loss: [1m[32m0.03537[0m[0m | time: 282.464s
[2K
| RMSProp | epoch: 015 | loss: 0.03537 - acc: 0.9857 -- iter: 0704/1998
[A[ATraining Step: 905  | total loss: [1m[32m0.03526[0m[0m | time: 295.901s
[2K
| RMSProp | epoch: 015 | loss: 0.03526 - acc: 0.9840 -- iter: 0736/1998
[A[ATraining Step: 906  | total loss: [1m[32m0.03189[0m[0m | time: 309.151s
[2K
| RMSProp | epoch: 015 | loss: 0.03189 - acc: 0.9856 -- iter: 0768/1998
[A[ATraining Step: 907  | total loss: [1m[32m0.02883[0m[0m | time: 322.487s
[2K
| RMSProp | epoch: 015 | loss: 0.02883 - acc: 0.9870 -- iter: 0800/1998
[A[ATraining Step: 908  | total loss: [1m[32m0.03433[0m[0m | time: 337.064s
[2K
| RMSProp | epoch: 015 | loss: 0.03433 - acc: 0.9852 -- iter: 0832/1998
[A[ATraining Step: 909  | total loss: [1m[32m0.03589[0m[0m | time: 351.534s
[2K
| RMSProp | epoch: 015 | loss: 0.03589 - acc: 0.9835 -- iter: 0864/1998
[A[ATraining Step: 910  | total loss: [1m[32m0.04041[0m[0m | time: 366.516s
[2K
| RMSProp | epoch: 015 | loss: 0.04041 - acc: 0.9821 -- iter: 0896/1998
[A[ATraining Step: 911  | total loss: [1m[32m0.03657[0m[0m | time: 381.309s
[2K
| RMSProp | epoch: 015 | loss: 0.03657 - acc: 0.9839 -- iter: 0928/1998
[A[ATraining Step: 912  | total loss: [1m[32m0.03319[0m[0m | time: 396.309s
[2K
| RMSProp | epoch: 015 | loss: 0.03319 - acc: 0.9855 -- iter: 0960/1998
[A[ATraining Step: 913  | total loss: [1m[32m0.03078[0m[0m | time: 410.882s
[2K
| RMSProp | epoch: 015 | loss: 0.03078 - acc: 0.9869 -- iter: 0992/1998
[A[ATraining Step: 914  | total loss: [1m[32m0.02801[0m[0m | time: 425.280s
[2K
| RMSProp | epoch: 015 | loss: 0.02801 - acc: 0.9882 -- iter: 1024/1998
[A[ATraining Step: 915  | total loss: [1m[32m0.02818[0m[0m | time: 439.865s
[2K
| RMSProp | epoch: 015 | loss: 0.02818 - acc: 0.9863 -- iter: 1056/1998
[A[ATraining Step: 916  | total loss: [1m[32m0.02543[0m[0m | time: 451.505s
[2K
| RMSProp | epoch: 015 | loss: 0.02543 - acc: 0.9877 -- iter: 1088/1998
[A[ATraining Step: 917  | total loss: [1m[32m0.02420[0m[0m | time: 460.481s
[2K
| RMSProp | epoch: 015 | loss: 0.02420 - acc: 0.9889 -- iter: 1120/1998
[A[ATraining Step: 918  | total loss: [1m[32m0.02698[0m[0m | time: 470.344s
[2K
| RMSProp | epoch: 015 | loss: 0.02698 - acc: 0.9869 -- iter: 1152/1998
[A[ATraining Step: 919  | total loss: [1m[32m0.04636[0m[0m | time: 483.599s
[2K
| RMSProp | epoch: 015 | loss: 0.04636 - acc: 0.9788 -- iter: 1184/1998
[A[ATraining Step: 920  | total loss: [1m[32m0.04645[0m[0m | time: 497.008s
[2K
| RMSProp | epoch: 015 | loss: 0.04645 - acc: 0.9778 -- iter: 1216/1998
[A[ATraining Step: 921  | total loss: [1m[32m0.04596[0m[0m | time: 510.192s
[2K
| RMSProp | epoch: 015 | loss: 0.04596 - acc: 0.9800 -- iter: 1248/1998
[A[ATraining Step: 922  | total loss: [1m[32m0.04448[0m[0m | time: 523.688s
[2K
| RMSProp | epoch: 015 | loss: 0.04448 - acc: 0.9789 -- iter: 1280/1998
[A[ATraining Step: 923  | total loss: [1m[32m0.06388[0m[0m | time: 537.088s
[2K
| RMSProp | epoch: 015 | loss: 0.06388 - acc: 0.9779 -- iter: 1312/1998
[A[ATraining Step: 924  | total loss: [1m[32m0.05761[0m[0m | time: 550.882s
[2K
| RMSProp | epoch: 015 | loss: 0.05761 - acc: 0.9801 -- iter: 1344/1998
[A[ATraining Step: 925  | total loss: [1m[32m0.08193[0m[0m | time: 564.342s
[2K
| RMSProp | epoch: 015 | loss: 0.08193 - acc: 0.9790 -- iter: 1376/1998
[A[ATraining Step: 926  | total loss: [1m[32m0.07646[0m[0m | time: 578.317s
[2K
| RMSProp | epoch: 015 | loss: 0.07646 - acc: 0.9811 -- iter: 1408/1998
[A[ATraining Step: 927  | total loss: [1m[32m0.06983[0m[0m | time: 592.317s
[2K
| RMSProp | epoch: 015 | loss: 0.06983 - acc: 0.9830 -- iter: 1440/1998
[A[ATraining Step: 928  | total loss: [1m[32m0.12739[0m[0m | time: 606.293s
[2K
| RMSProp | epoch: 015 | loss: 0.12739 - acc: 0.9784 -- iter: 1472/1998
[A[ATraining Step: 929  | total loss: [1m[32m0.11538[0m[0m | time: 619.950s
[2K
| RMSProp | epoch: 015 | loss: 0.11538 - acc: 0.9806 -- iter: 1504/1998
[A[ATraining Step: 930  | total loss: [1m[32m0.10755[0m[0m | time: 633.467s
[2K
| RMSProp | epoch: 015 | loss: 0.10755 - acc: 0.9825 -- iter: 1536/1998
[A[ATraining Step: 931  | total loss: [1m[32m0.09939[0m[0m | time: 647.269s
[2K
| RMSProp | epoch: 015 | loss: 0.09939 - acc: 0.9843 -- iter: 1568/1998
[A[ATraining Step: 932  | total loss: [1m[32m0.09016[0m[0m | time: 661.076s
[2K
| RMSProp | epoch: 015 | loss: 0.09016 - acc: 0.9858 -- iter: 1600/1998
[A[ATraining Step: 933  | total loss: [1m[32m0.08279[0m[0m | time: 674.667s
[2K
| RMSProp | epoch: 015 | loss: 0.08279 - acc: 0.9873 -- iter: 1632/1998
[A[ATraining Step: 934  | total loss: [1m[32m0.07541[0m[0m | time: 688.168s
[2K
| RMSProp | epoch: 015 | loss: 0.07541 - acc: 0.9885 -- iter: 1664/1998
[A[ATraining Step: 935  | total loss: [1m[32m0.06916[0m[0m | time: 701.968s
[2K
| RMSProp | epoch: 015 | loss: 0.06916 - acc: 0.9897 -- iter: 1696/1998
[A[ATraining Step: 936  | total loss: [1m[32m0.06725[0m[0m | time: 715.487s
[2K
| RMSProp | epoch: 015 | loss: 0.06725 - acc: 0.9876 -- iter: 1728/1998
[A[ATraining Step: 937  | total loss: [1m[32m0.06105[0m[0m | time: 729.274s
[2K
| RMSProp | epoch: 015 | loss: 0.06105 - acc: 0.9888 -- iter: 1760/1998
[A[ATraining Step: 938  | total loss: [1m[32m0.05523[0m[0m | time: 742.754s
[2K
| RMSProp | epoch: 015 | loss: 0.05523 - acc: 0.9899 -- iter: 1792/1998
[A[ATraining Step: 939  | total loss: [1m[32m0.06291[0m[0m | time: 756.630s
[2K
| RMSProp | epoch: 015 | loss: 0.06291 - acc: 0.9847 -- iter: 1824/1998
[A[ATraining Step: 940  | total loss: [1m[32m0.05877[0m[0m | time: 770.194s
[2K
| RMSProp | epoch: 015 | loss: 0.05877 - acc: 0.9862 -- iter: 1856/1998
[A[ATraining Step: 941  | total loss: [1m[32m0.05316[0m[0m | time: 783.856s
[2K
| RMSProp | epoch: 015 | loss: 0.05316 - acc: 0.9876 -- iter: 1888/1998
[A[ATraining Step: 942  | total loss: [1m[32m0.05544[0m[0m | time: 797.442s
[2K
| RMSProp | epoch: 015 | loss: 0.05544 - acc: 0.9857 -- iter: 1920/1998
[A[ATraining Step: 943  | total loss: [1m[32m0.05541[0m[0m | time: 811.093s
[2K
| RMSProp | epoch: 015 | loss: 0.05541 - acc: 0.9840 -- iter: 1952/1998
[A[ATraining Step: 944  | total loss: [1m[32m0.05099[0m[0m | time: 824.703s
[2K
| RMSProp | epoch: 015 | loss: 0.05099 - acc: 0.9856 -- iter: 1984/1998
[A[ATraining Step: 945  | total loss: [1m[32m0.05536[0m[0m | time: 886.954s
[2K
| RMSProp | epoch: 015 | loss: 0.05536 - acc: 0.9839 | val_loss: 0.36236 - val_acc: 0.8720 -- iter: 1998/1998
--
Validation AUC:0.9810153846153846
Validation AUPRC:0.9838721594445289
Test AUC:0.9714737858889779
Test AUPRC:0.9693205985430353
BestTestF1Score	0.91	0.82	0.91	0.92	0.89	262	23	308	32	0.99
BestTestMCCScore	0.91	0.82	0.91	0.92	0.89	262	23	308	32	0.99
BestTestAccuracyScore	0.91	0.82	0.91	0.92	0.89	262	23	308	32	0.99
BestValidationF1Score	0.93	0.87	0.93	0.96	0.91	295	12	288	30	0.99
BestValidationMCC	0.93	0.87	0.93	0.96	0.91	295	12	288	30	0.99
BestValidationAccuracy	0.93	0.87	0.93	0.96	0.91	295	12	288	30	0.99
TestPredictions (Threshold:0.99)
CHEMBL3704963,TP,ACT,1.0	CHEMBL185382,TP,ACT,1.0	CHEMBL368133,TN,INACT,0.15000000596046448	CHEMBL284969,TN,INACT,0.0	CHEMBL486688,TN,INACT,0.07999999821186066	CHEMBL327626,TN,INACT,0.019999999552965164	CHEMBL2042401,TN,INACT,0.0	CHEMBL12344,TN,INACT,0.0	CHEMBL241099,TN,INACT,0.800000011920929	CHEMBL3327375,TN,INACT,0.009999999776482582	CHEMBL3314917,TN,INACT,0.009999999776482582	CHEMBL284965,TN,INACT,0.019999999552965164	CHEMBL75200,TN,INACT,0.9700000286102295	CHEMBL3646184,TP,ACT,1.0	CHEMBL3665652,TP,ACT,1.0	CHEMBL3665706,TP,ACT,1.0	CHEMBL2111825,TN,INACT,0.0	CHEMBL106259,TN,INACT,0.9399999976158142	CHEMBL25976,TN,INACT,0.6000000238418579	CHEMBL415879,TN,INACT,0.019999999552965164	CHEMBL26138,TN,INACT,0.7599999904632568	CHEMBL422411,TN,INACT,0.38999998569488525	CHEMBL3665708,TP,ACT,1.0	CHEMBL3589940,TN,INACT,0.0	CHEMBL3665634,TP,ACT,1.0	CHEMBL98014,TN,INACT,0.0	CHEMBL3670566,TP,ACT,1.0	CHEMBL3642144,TP,ACT,1.0	CHEMBL11629,TN,INACT,0.0	CHEMBL3649066,TP,ACT,1.0	CHEMBL123785,TN,INACT,0.0	CHEMBL413040,TN,INACT,0.46000000834465027	CHEMBL3665737,TP,ACT,1.0	CHEMBL302150,TN,INACT,0.05999999865889549	CHEMBL71726,TN,INACT,0.25999999046325684	CHEMBL3670523,TP,ACT,1.0	CHEMBL3663575,TP,ACT,1.0	CHEMBL3669520,TP,ACT,1.0	CHEMBL3663442,TP,ACT,1.0	CHEMBL76128,TN,INACT,0.5699999928474426	CHEMBL3623075,TP,ACT,1.0	CHEMBL319387,TN,INACT,0.009999999776482582	CHEMBL368629,TN,INACT,0.23999999463558197	CHEMBL100513,FP,INACT,1.0	CHEMBL3665443,TN,INACT,0.5400000214576721	CHEMBL314959,TN,INACT,0.0	CHEMBL3663436,TP,ACT,1.0	CHEMBL341339,TN,INACT,0.8899999856948853	CHEMBL3704935,TP,ACT,1.0	CHEMBL3649203,TP,ACT,1.0	CHEMBL3338849,FN,ACT,0.25999999046325684	CHEMBL3099894,FN,ACT,0.9599999785423279	CHEMBL95589,TN,INACT,0.0	CHEMBL2347476,FN,ACT,0.9399999976158142	CHEMBL3669568,TP,ACT,1.0	CHEMBL3586422,TP,ACT,1.0	CHEMBL129198,TN,INACT,0.17000000178813934	CHEMBL584,FP,INACT,1.0	CHEMBL283320,TN,INACT,0.009999999776482582	CHEMBL1224608,TN,INACT,0.6899999976158142	CHEMBL296927,TN,INACT,0.09000000357627869	CHEMBL140620,TN,INACT,0.17000000178813934	CHEMBL2435394,TP,ACT,1.0	CHEMBL63937,TN,INACT,0.3400000035762787	CHEMBL3649062,TP,ACT,1.0	CHEMBL106359,TN,INACT,0.0	CHEMBL319924,TN,INACT,0.8299999833106995	CHEMBL3652437,TP,ACT,1.0	CHEMBL320124,TN,INACT,0.11999999731779099	CHEMBL316648,TN,INACT,0.9800000190734863	CHEMBL436451,TN,INACT,0.5899999737739563	CHEMBL1093044,TN,INACT,0.03999999910593033	CHEMBL312567,TN,INACT,0.6899999976158142	CHEMBL44134,TN,INACT,0.0	CHEMBL2347609,FN,ACT,0.4300000071525574	CHEMBL321579,TN,INACT,0.019999999552965164	CHEMBL2115123,TN,INACT,0.15000000596046448	CHEMBL609247,TN,INACT,0.009999999776482582	CHEMBL169553,TN,INACT,0.019999999552965164	CHEMBL3649089,TP,ACT,1.0	CHEMBL50456,TN,INACT,0.8199999928474426	CHEMBL3670596,TP,ACT,1.0	CHEMBL80504,TN,INACT,0.0	CHEMBL297599,TN,INACT,0.009999999776482582	CHEMBL279898,TN,INACT,0.0	CHEMBL373654,FP,INACT,1.0	CHEMBL3665701,TP,ACT,1.0	CHEMBL330674,TN,INACT,0.2800000011920929	CHEMBL3663441,TP,ACT,1.0	CHEMBL169459,TN,INACT,0.949999988079071	CHEMBL418658,TN,INACT,0.0	CHEMBL337309,TN,INACT,0.0	CHEMBL3335536,TN,INACT,0.0	CHEMBL48448,TN,INACT,0.3700000047683716	CHEMBL3642118,TP,ACT,1.0	CHEMBL453,TN,INACT,0.0	CHEMBL3670595,TP,ACT,1.0	CHEMBL357983,FP,INACT,0.9900000095367432	CHEMBL3665633,TP,ACT,1.0	CHEMBL3663404,TP,ACT,1.0	CHEMBL3667594,TP,ACT,1.0	CHEMBL3691821,TP,ACT,1.0	CHEMBL458465,TN,INACT,0.0	CHEMBL3652436,TP,ACT,1.0	CHEMBL491468,TP,ACT,1.0	CHEMBL95590,TN,INACT,0.0	CHEMBL3343260,TP,ACT,1.0	CHEMBL21509,TN,INACT,0.30000001192092896	CHEMBL410531,TN,INACT,0.5199999809265137	CHEMBL3585949,TP,ACT,1.0	CHEMBL1082036,TN,INACT,0.9399999976158142	CHEMBL75126,TN,INACT,0.0	CHEMBL3649125,TP,ACT,1.0	CHEMBL240895,TN,INACT,0.07000000029802322	CHEMBL71626,FP,INACT,1.0	CHEMBL3691852,TP,ACT,1.0	CHEMBL240021,FP,INACT,0.9900000095367432	CHEMBL3597970,TP,ACT,1.0	CHEMBL3669525,TP,ACT,1.0	CHEMBL416019,TN,INACT,0.0	CHEMBL305313,TN,INACT,0.0	CHEMBL125925,TN,INACT,0.25999999046325684	CHEMBL417712,TN,INACT,0.18000000715255737	CHEMBL3646153,TP,ACT,1.0	CHEMBL3691847,TP,ACT,1.0	CHEMBL3639580,TP,ACT,1.0	CHEMBL363743,TP,ACT,0.9900000095367432	CHEMBL3670511,TP,ACT,1.0	CHEMBL3338859,TN,INACT,0.9300000071525574	CHEMBL3691830,TP,ACT,1.0	CHEMBL3646173,TP,ACT,1.0	CHEMBL3780248,TN,INACT,0.8799999952316284	CHEMBL3634024,TP,ACT,1.0	CHEMBL303538,TN,INACT,0.05999999865889549	CHEMBL298649,TN,INACT,0.14000000059604645	CHEMBL105672,TN,INACT,0.05999999865889549	CHEMBL3669519,TP,ACT,1.0	CHEMBL104198,TN,INACT,0.03999999910593033	CHEMBL3741584,TP,ACT,1.0	CHEMBL288967,TN,INACT,0.9599999785423279	CHEMBL3649023,TP,ACT,1.0	CHEMBL3669566,TP,ACT,1.0	CHEMBL3623079,FN,ACT,0.8999999761581421	CHEMBL3652443,TP,ACT,1.0	CHEMBL101554,TN,INACT,0.0	CHEMBL392401,TN,INACT,0.0	CHEMBL182473,TP,ACT,0.9900000095367432	CHEMBL3670630,TP,ACT,1.0	CHEMBL468633,TN,INACT,0.9399999976158142	CHEMBL3665673,TP,ACT,1.0	CHEMBL3670535,TP,ACT,1.0	CHEMBL3633665,TN,INACT,0.0	CHEMBL3652458,TP,ACT,1.0	CHEMBL3669516,TP,ACT,1.0	CHEMBL3704945,TP,ACT,1.0	CHEMBL299538,TN,INACT,0.9399999976158142	CHEMBL3649136,TP,ACT,1.0	CHEMBL1080153,TN,INACT,0.0	CHEMBL3663564,TP,ACT,1.0	CHEMBL3670536,TP,ACT,1.0	CHEMBL434674,TN,INACT,0.07000000029802322	CHEMBL42065,TN,INACT,0.1899999976158142	CHEMBL1258999,TN,INACT,0.019999999552965164	CHEMBL336033,FP,INACT,1.0	CHEMBL245319,FP,INACT,0.9900000095367432	CHEMBL462650,TN,INACT,0.9700000286102295	CHEMBL3665628,TP,ACT,1.0	CHEMBL1258371,TN,INACT,0.0	CHEMBL3663536,TP,ACT,1.0	CHEMBL3627863,TN,INACT,0.5299999713897705	CHEMBL143304,TN,INACT,0.25999999046325684	CHEMBL3403332,TN,INACT,0.7099999785423279	CHEMBL3659182,TP,ACT,1.0	CHEMBL1346,TN,INACT,0.20999999344348907	CHEMBL3771050,TP,ACT,1.0	CHEMBL103497,TN,INACT,0.009999999776482582	CHEMBL3663476,TP,ACT,1.0	CHEMBL110601,TN,INACT,0.10999999940395355	CHEMBL3669473,TP,ACT,1.0	CHEMBL210931,TN,INACT,0.009999999776482582	CHEMBL2347486,TP,ACT,0.9900000095367432	CHEMBL3218120,TN,INACT,0.6399999856948853	CHEMBL174463,TN,INACT,0.029999999329447746	CHEMBL79915,TN,INACT,0.009999999776482582	CHEMBL3634011,TP,ACT,1.0	CHEMBL2062849,TN,INACT,0.05000000074505806	CHEMBL3665616,TP,ACT,1.0	CHEMBL83747,TN,INACT,0.07000000029802322	CHEMBL9746,TN,INACT,0.0	CHEMBL20844,TN,INACT,0.07000000029802322	CHEMBL140693,TN,INACT,0.05000000074505806	CHEMBL233535,TN,INACT,0.0	CHEMBL444128,TN,INACT,0.0	CHEMBL3663557,TP,ACT,1.0	CHEMBL3691816,TP,ACT,1.0	CHEMBL323175,TN,INACT,0.07999999821186066	CHEMBL1090509,TN,INACT,0.05000000074505806	CHEMBL2413368,FN,ACT,0.7599999904632568	CHEMBL320779,TN,INACT,0.6600000262260437	CHEMBL52867,TN,INACT,0.009999999776482582	CHEMBL140006,TN,INACT,0.1599999964237213	CHEMBL3426152,FN,ACT,0.7099999785423279	CHEMBL3338848,FN,ACT,0.3499999940395355	CHEMBL3646158,TP,ACT,1.0	CHEMBL2425787,TP,ACT,1.0	CHEMBL593443,TN,INACT,0.0	CHEMBL392116,FP,INACT,1.0	CHEMBL449329,TN,INACT,0.019999999552965164	CHEMBL3670551,TP,ACT,1.0	CHEMBL3742301,TP,ACT,0.9900000095367432	CHEMBL600610,TN,INACT,0.07000000029802322	CHEMBL445161,TP,ACT,0.9900000095367432	CHEMBL3663498,TP,ACT,1.0	CHEMBL575027,TN,INACT,0.7599999904632568	CHEMBL294349,TN,INACT,0.0	CHEMBL3669469,TP,ACT,1.0	CHEMBL320763,TN,INACT,0.1899999976158142	CHEMBL3649096,TP,ACT,1.0	CHEMBL3667565,TP,ACT,1.0	CHEMBL2153622,FP,INACT,0.9900000095367432	CHEMBL440864,TN,INACT,0.0	CHEMBL1791403,TN,INACT,0.07999999821186066	CHEMBL109894,FP,INACT,1.0	CHEMBL3691846,TP,ACT,1.0	CHEMBL272873,TN,INACT,0.0	CHEMBL3649084,TP,ACT,1.0	CHEMBL3669537,TP,ACT,1.0	CHEMBL2107822,TP,ACT,1.0	CHEMBL3426143,TP,ACT,1.0	CHEMBL1922023,TN,INACT,0.20000000298023224	CHEMBL557997,TN,INACT,0.0	CHEMBL3649058,TP,ACT,1.0	CHEMBL3114144,TN,INACT,0.009999999776482582	CHEMBL3642141,FN,ACT,0.8600000143051147	CHEMBL1076554,TN,INACT,0.009999999776482582	CHEMBL3663437,TP,ACT,1.0	CHEMBL29541,TN,INACT,0.0	CHEMBL258906,TN,INACT,0.07999999821186066	CHEMBL3691806,TP,ACT,1.0	CHEMBL367024,TN,INACT,0.019999999552965164	CHEMBL171310,TN,INACT,0.029999999329447746	CHEMBL3670534,TP,ACT,1.0	CHEMBL3649073,TP,ACT,1.0	CHEMBL3669475,TP,ACT,1.0	CHEMBL3426149,TP,ACT,1.0	CHEMBL118,FP,INACT,1.0	CHEMBL3672934,TP,ACT,1.0	CHEMBL3663438,TP,ACT,1.0	CHEMBL2413514,TP,ACT,1.0	CHEMBL185136,TP,ACT,1.0	CHEMBL3639623,TP,ACT,1.0	CHEMBL542877,TN,INACT,0.0	CHEMBL3394827,TP,ACT,1.0	CHEMBL78601,TN,INACT,0.0	CHEMBL2062848,TN,INACT,0.10000000149011612	CHEMBL3649201,TP,ACT,1.0	CHEMBL3235253,TP,ACT,1.0	CHEMBL561262,TN,INACT,0.44999998807907104	CHEMBL3099893,FN,ACT,0.9599999785423279	CHEMBL3665630,FN,ACT,0.9800000190734863	CHEMBL2413509,TP,ACT,1.0	CHEMBL2051956,TN,INACT,0.07000000029802322	CHEMBL64559,TN,INACT,0.8100000023841858	CHEMBL3649088,TP,ACT,1.0	CHEMBL2435414,TP,ACT,1.0	CHEMBL215040,TN,INACT,0.5	CHEMBL3667589,TP,ACT,1.0	CHEMBL3739510,FN,ACT,0.9700000286102295	CHEMBL59859,TN,INACT,0.07000000029802322	CHEMBL3652490,TP,ACT,1.0	CHEMBL3649065,TP,ACT,1.0	CHEMBL2113685,TN,INACT,0.009999999776482582	CHEMBL312374,TN,INACT,0.10999999940395355	CHEMBL328476,TN,INACT,0.12999999523162842	CHEMBL89494,TN,INACT,0.2199999988079071	CHEMBL3649219,TP,ACT,1.0	CHEMBL72172,TN,INACT,0.3199999928474426	CHEMBL128360,TN,INACT,0.0	CHEMBL3670555,TP,ACT,1.0	CHEMBL417654,TN,INACT,0.0	CHEMBL304551,TN,INACT,0.0	CHEMBL73096,TN,INACT,0.019999999552965164	CHEMBL75514,TN,INACT,0.019999999552965164	CHEMBL3669506,TP,ACT,1.0	CHEMBL3597951,TP,ACT,1.0	CHEMBL3665674,TP,ACT,1.0	CHEMBL3667585,TP,ACT,1.0	CHEMBL3649115,TP,ACT,1.0	CHEMBL364814,TP,ACT,0.9900000095367432	CHEMBL556506,TN,INACT,0.019999999552965164	CHEMBL3597963,TP,ACT,1.0	CHEMBL320804,TN,INACT,0.6700000166893005	CHEMBL2413367,FN,ACT,0.949999988079071	CHEMBL1775009,TN,INACT,0.0	CHEMBL312372,TN,INACT,0.07999999821186066	CHEMBL489288,TP,ACT,1.0	CHEMBL59733,TN,INACT,0.0	CHEMBL3670616,TP,ACT,1.0	CHEMBL3649208,TP,ACT,1.0	CHEMBL3669047,TP,ACT,1.0	CHEMBL3659186,TP,ACT,1.0	CHEMBL2413373,TP,ACT,0.9900000095367432	CHEMBL43330,TN,INACT,0.8799999952316284	CHEMBL3665640,TP,ACT,1.0	CHEMBL3667582,TP,ACT,1.0	CHEMBL38704,TN,INACT,0.0	CHEMBL3670598,TP,ACT,1.0	CHEMBL2435400,TP,ACT,1.0	CHEMBL279105,TN,INACT,0.09000000357627869	CHEMBL302038,FP,INACT,1.0	CHEMBL65461,TN,INACT,0.009999999776482582	CHEMBL240888,TN,INACT,0.550000011920929	CHEMBL68738,TN,INACT,0.7599999904632568	CHEMBL2373213,FP,INACT,1.0	CHEMBL477665,TN,INACT,0.949999988079071	CHEMBL185088,TP,ACT,1.0	CHEMBL524139,TP,ACT,1.0	CHEMBL30026,TN,INACT,0.09000000357627869	CHEMBL440961,TN,INACT,0.9599999785423279	CHEMBL3338865,FN,ACT,0.9700000286102295	CHEMBL308924,TN,INACT,0.05000000074505806	CHEMBL3597967,TP,ACT,1.0	CHEMBL1201353,TN,INACT,0.05000000074505806	CHEMBL3403733,TN,INACT,0.4399999976158142	CHEMBL3665635,TP,ACT,1.0	CHEMBL522786,TP,ACT,1.0	CHEMBL307326,TN,INACT,0.0	CHEMBL3585952,TP,ACT,1.0	CHEMBL334813,TN,INACT,0.36000001430511475	CHEMBL3663511,TP,ACT,1.0	CHEMBL3649110,TP,ACT,1.0	CHEMBL112777,TN,INACT,0.550000011920929	CHEMBL2381764,TN,INACT,0.029999999329447746	CHEMBL316792,TN,INACT,0.9700000286102295	CHEMBL110749,TN,INACT,0.8700000047683716	CHEMBL85678,TN,INACT,0.0	CHEMBL60620,TN,INACT,0.0	CHEMBL89457,TN,INACT,0.10999999940395355	CHEMBL3670522,TP,ACT,1.0	CHEMBL3669022,TP,ACT,1.0	CHEMBL95091,TN,INACT,0.0	CHEMBL62808,TN,INACT,0.0	CHEMBL2347477,TP,ACT,0.9900000095367432	CHEMBL62601,FP,INACT,0.9900000095367432	CHEMBL3704965,TP,ACT,1.0	CHEMBL3597961,TP,ACT,1.0	CHEMBL325043,TN,INACT,0.009999999776482582	CHEMBL3622422,FN,ACT,0.029999999329447746	CHEMBL165387,TN,INACT,0.0	CHEMBL3667574,TP,ACT,1.0	CHEMBL297473,TN,INACT,0.0	CHEMBL2331793,TN,INACT,0.0	CHEMBL3672936,TP,ACT,1.0	CHEMBL3740042,TN,INACT,0.5	CHEMBL3669477,TP,ACT,1.0	CHEMBL20168,TN,INACT,0.019999999552965164	CHEMBL147340,TN,INACT,0.0	CHEMBL3652456,TP,ACT,1.0	CHEMBL67060,TN,INACT,0.0	CHEMBL2347602,FN,ACT,0.8399999737739563	CHEMBL303792,TN,INACT,0.9300000071525574	CHEMBL3585944,TP,ACT,1.0	CHEMBL3649169,TP,ACT,1.0	CHEMBL59085,TN,INACT,0.019999999552965164	CHEMBL156851,TN,INACT,0.9700000286102295	CHEMBL297173,TN,INACT,0.019999999552965164	CHEMBL3669550,TP,ACT,1.0	CHEMBL322547,TN,INACT,0.1899999976158142	CHEMBL610372,TN,INACT,0.9300000071525574	CHEMBL3663477,TP,ACT,1.0	CHEMBL197159,TN,INACT,0.0	CHEMBL3642121,TP,ACT,1.0	CHEMBL515170,TN,INACT,0.05999999865889549	CHEMBL3665726,TP,ACT,1.0	CHEMBL255845,TP,ACT,1.0	CHEMBL1790738,TN,INACT,0.3799999952316284	CHEMBL185080,TP,ACT,1.0	CHEMBL291293,TN,INACT,0.15000000596046448	CHEMBL211696,TN,INACT,0.9399999976158142	CHEMBL3670625,TP,ACT,1.0	CHEMBL3663547,TP,ACT,1.0	CHEMBL2425785,TP,ACT,1.0	CHEMBL2370511,TN,INACT,0.009999999776482582	CHEMBL3704930,TP,ACT,1.0	CHEMBL407818,TN,INACT,0.0	CHEMBL145584,TN,INACT,0.0	CHEMBL1223346,TN,INACT,0.0	CHEMBL64406,TN,INACT,0.0	CHEMBL89688,TN,INACT,0.12999999523162842	CHEMBL17857,TN,INACT,0.14000000059604645	CHEMBL275433,TN,INACT,0.0	CHEMBL3649033,TP,ACT,1.0	CHEMBL408492,FP,INACT,0.9900000095367432	CHEMBL319910,TN,INACT,0.6899999976158142	CHEMBL147238,TN,INACT,0.019999999552965164	CHEMBL490,TN,INACT,0.0	CHEMBL90491,TN,INACT,0.6499999761581421	CHEMBL262404,TN,INACT,0.09000000357627869	CHEMBL3669564,TP,ACT,1.0	CHEMBL3423400,TN,INACT,0.1899999976158142	CHEMBL3667570,TP,ACT,1.0	CHEMBL3704946,TP,ACT,1.0	CHEMBL63289,TN,INACT,0.5	CHEMBL424214,TN,INACT,0.029999999329447746	CHEMBL109478,TN,INACT,0.7099999785423279	CHEMBL2347482,TP,ACT,1.0	CHEMBL3672931,TP,ACT,1.0	CHEMBL113,TN,INACT,0.20999999344348907	CHEMBL3338853,FN,ACT,0.9800000190734863	CHEMBL72295,FP,INACT,1.0	CHEMBL3314929,FP,INACT,0.9900000095367432	CHEMBL339707,TN,INACT,0.019999999552965164	CHEMBL3665691,TP,ACT,1.0	CHEMBL3741194,FN,ACT,0.9200000166893005	CHEMBL3634025,TP,ACT,1.0	CHEMBL3634017,FN,ACT,0.9100000262260437	CHEMBL3665730,TP,ACT,0.9900000095367432	CHEMBL174448,TN,INACT,0.9800000190734863	CHEMBL1093725,TP,ACT,1.0	CHEMBL421349,TN,INACT,0.2199999988079071	CHEMBL3665731,FN,ACT,0.5799999833106995	CHEMBL3597965,TP,ACT,1.0	CHEMBL61120,TN,INACT,0.0	CHEMBL302027,TN,INACT,0.0	CHEMBL381917,TN,INACT,0.47999998927116394	CHEMBL3649083,TP,ACT,1.0	CHEMBL3545367,TP,ACT,1.0	CHEMBL19808,TN,INACT,0.0	CHEMBL102613,TN,INACT,0.0	CHEMBL184384,FN,ACT,0.1599999964237213	CHEMBL1158,TN,INACT,0.28999999165534973	CHEMBL3115577,TN,INACT,0.009999999776482582	CHEMBL42359,TN,INACT,0.0	CHEMBL3741125,TP,ACT,1.0	CHEMBL3646200,TP,ACT,1.0	CHEMBL7441,TN,INACT,0.0	CHEMBL305512,TN,INACT,0.15000000596046448	CHEMBL3667556,TP,ACT,1.0	CHEMBL3739613,FN,ACT,0.9700000286102295	CHEMBL1093724,TP,ACT,1.0	CHEMBL435810,TN,INACT,0.009999999776482582	CHEMBL610095,TN,INACT,0.0	CHEMBL185424,FN,ACT,0.8500000238418579	CHEMBL3394829,TP,ACT,1.0	CHEMBL3669577,TP,ACT,1.0	CHEMBL3649022,TP,ACT,1.0	CHEMBL3649187,TP,ACT,1.0	CHEMBL3649039,TP,ACT,1.0	CHEMBL2062850,TN,INACT,0.15000000596046448	CHEMBL3670517,TP,ACT,1.0	CHEMBL423666,TN,INACT,0.0	CHEMBL3649227,TP,ACT,1.0	CHEMBL3667571,TP,ACT,1.0	CHEMBL3338857,FN,ACT,0.7900000214576721	CHEMBL3652464,TP,ACT,1.0	CHEMBL240657,TN,INACT,0.20999999344348907	CHEMBL3426134,TP,ACT,1.0	CHEMBL3403741,FP,INACT,0.9900000095367432	CHEMBL3669455,TP,ACT,1.0	CHEMBL100810,TN,INACT,0.0	CHEMBL78929,TN,INACT,0.0	CHEMBL1223275,TN,INACT,0.0	CHEMBL3235254,TP,ACT,1.0	CHEMBL3669518,TP,ACT,1.0	CHEMBL3672933,TP,ACT,1.0	CHEMBL437,TN,INACT,0.18000000715255737	CHEMBL3667554,TP,ACT,1.0	CHEMBL3663549,TP,ACT,1.0	CHEMBL3665642,TP,ACT,1.0	CHEMBL399203,TN,INACT,0.8799999952316284	CHEMBL1907856,TN,INACT,0.3100000023841858	CHEMBL3659176,TP,ACT,1.0	CHEMBL441305,TN,INACT,0.009999999776482582	CHEMBL1916708,TN,INACT,0.8399999737739563	CHEMBL2164434,TN,INACT,0.0	CHEMBL272853,FP,INACT,1.0	CHEMBL43788,TN,INACT,0.5899999737739563	CHEMBL3659226,TP,ACT,1.0	CHEMBL2370509,TN,INACT,0.03999999910593033	CHEMBL3585945,TP,ACT,1.0	CHEMBL3323005,TN,INACT,0.009999999776482582	CHEMBL3652499,TP,ACT,1.0	CHEMBL3649173,TP,ACT,1.0	CHEMBL3740976,FN,ACT,0.2800000011920929	CHEMBL3663492,TP,ACT,1.0	CHEMBL160396,TN,INACT,0.07000000029802322	CHEMBL17875,TN,INACT,0.0	CHEMBL3691831,TP,ACT,1.0	CHEMBL416505,TN,INACT,0.009999999776482582	CHEMBL3734955,TN,INACT,0.8299999833106995	CHEMBL3670584,TP,ACT,1.0	CHEMBL271232,FN,ACT,0.9599999785423279	CHEMBL275481,TN,INACT,0.15000000596046448	CHEMBL3218121,TN,INACT,0.23000000417232513	CHEMBL330885,TN,INACT,0.0	CHEMBL15689,FP,INACT,1.0	CHEMBL3704954,TP,ACT,1.0	CHEMBL3114145,TN,INACT,0.3499999940395355	CHEMBL127167,TN,INACT,0.0	CHEMBL3659194,TP,ACT,0.9900000095367432	CHEMBL308756,TN,INACT,0.0	CHEMBL3663546,TP,ACT,1.0	CHEMBL241080,TN,INACT,0.9399999976158142	CHEMBL452150,TN,INACT,0.0	CHEMBL3691813,TP,ACT,1.0	CHEMBL62840,TN,INACT,0.0	CHEMBL380054,TN,INACT,0.1899999976158142	CHEMBL309194,TN,INACT,0.029999999329447746	CHEMBL3649030,TP,ACT,1.0	CHEMBL3670612,TP,ACT,1.0	CHEMBL142243,TN,INACT,0.8999999761581421	CHEMBL88584,TN,INACT,0.27000001072883606	CHEMBL3659192,TP,ACT,1.0	CHEMBL3646163,TP,ACT,1.0	CHEMBL2163568,TN,INACT,0.6899999976158142	CHEMBL3670606,TP,ACT,1.0	CHEMBL3099888,TP,ACT,0.9900000095367432	CHEMBL3669024,TP,ACT,1.0	CHEMBL101162,TN,INACT,0.019999999552965164	CHEMBL3665671,TP,ACT,1.0	CHEMBL404053,FN,ACT,0.9200000166893005	CHEMBL3649053,TP,ACT,1.0	CHEMBL3665709,TP,ACT,1.0	CHEMBL3649153,TP,ACT,1.0	CHEMBL60401,TN,INACT,0.0	CHEMBL3665685,TP,ACT,1.0	CHEMBL3642145,FN,ACT,0.9599999785423279	CHEMBL3409876,FN,ACT,0.4000000059604645	CHEMBL3343244,TP,ACT,1.0	CHEMBL455493,TN,INACT,0.0	CHEMBL3704941,TP,ACT,1.0	CHEMBL3410297,TN,INACT,0.029999999329447746	CHEMBL404397,TP,ACT,0.9900000095367432	CHEMBL461709,TN,INACT,0.10999999940395355	CHEMBL3665725,TP,ACT,1.0	CHEMBL3669460,TP,ACT,0.9900000095367432	CHEMBL105594,TN,INACT,0.0	CHEMBL60837,TN,INACT,0.0	CHEMBL62948,TN,INACT,0.0	CHEMBL328422,TN,INACT,0.05000000074505806	CHEMBL105764,TN,INACT,0.9100000262260437	CHEMBL3099889,FN,ACT,0.7900000214576721	CHEMBL307307,TN,INACT,0.029999999329447746	CHEMBL281232,TN,INACT,0.0	CHEMBL100071,TN,INACT,0.5699999928474426	CHEMBL119385,TN,INACT,0.949999988079071	CHEMBL3670519,TP,ACT,1.0	CHEMBL3667552,TP,ACT,0.9900000095367432	CHEMBL279520,TN,INACT,0.009999999776482582	CHEMBL3649186,TP,ACT,1.0	CHEMBL3704956,TP,ACT,1.0	CHEMBL104947,TN,INACT,0.0	CHEMBL1788235,TN,INACT,0.9200000166893005	CHEMBL3338846,FN,ACT,0.41999998688697815	CHEMBL3735036,FP,INACT,1.0	CHEMBL3663528,TP,ACT,1.0	CHEMBL291992,TN,INACT,0.0	CHEMBL167032,TN,INACT,0.25999999046325684	CHEMBL3586413,TP,ACT,1.0	CHEMBL2442640,TN,INACT,0.0	CHEMBL3735151,TN,INACT,0.46000000834465027	CHEMBL3667598,TP,ACT,1.0	CHEMBL2385133,TP,ACT,1.0	CHEMBL3652516,TP,ACT,1.0	CHEMBL3649054,TP,ACT,1.0	CHEMBL3649234,TP,ACT,1.0	CHEMBL349689,TN,INACT,0.0	CHEMBL3652482,TP,ACT,1.0	CHEMBL3670615,TP,ACT,1.0	CHEMBL3659234,TP,ACT,1.0	CHEMBL169178,TN,INACT,0.8299999833106995	CHEMBL115556,TN,INACT,0.0	CHEMBL516024,TN,INACT,0.3799999952316284	CHEMBL3669051,TP,ACT,1.0	CHEMBL3665645,TP,ACT,1.0	CHEMBL3649105,TP,ACT,1.0	CHEMBL323074,TN,INACT,0.4300000071525574	CHEMBL3327373,TN,INACT,0.0	CHEMBL1907839,TN,INACT,0.8799999952316284	CHEMBL132179,FP,INACT,1.0	CHEMBL323723,TN,INACT,0.10999999940395355	CHEMBL3670558,TP,ACT,1.0	CHEMBL3646190,TP,ACT,1.0	CHEMBL76860,TN,INACT,0.0	CHEMBL63905,TN,INACT,0.9300000071525574	CHEMBL321644,TN,INACT,0.9399999976158142	CHEMBL3669476,TP,ACT,1.0	CHEMBL343158,TN,INACT,0.14000000059604645	CHEMBL1275791,TN,INACT,0.12999999523162842	CHEMBL3652493,TP,ACT,1.0	CHEMBL3649171,TP,ACT,1.0	CHEMBL3646169,TP,ACT,1.0	CHEMBL3649021,TP,ACT,1.0	CHEMBL3585953,TP,ACT,1.0	CHEMBL33224,TN,INACT,0.05999999865889549	CHEMBL220334,TN,INACT,0.009999999776482582	CHEMBL3669528,TP,ACT,1.0	CHEMBL3663493,TP,ACT,1.0	CHEMBL390842,TN,INACT,0.009999999776482582	CHEMBL3652474,TP,ACT,1.0	CHEMBL3585948,TP,ACT,1.0	CHEMBL143761,TN,INACT,0.20999999344348907	CHEMBL3667577,TP,ACT,1.0	CHEMBL3669447,TP,ACT,1.0	CHEMBL275469,TN,INACT,0.0	CHEMBL177546,TN,INACT,0.25	CHEMBL64124,TN,INACT,0.0	CHEMBL3659217,TP,ACT,1.0	CHEMBL557576,TN,INACT,0.0	CHEMBL322332,TN,INACT,0.05000000074505806	CHEMBL3780633,TN,INACT,0.6000000238418579	CHEMBL3652503,TP,ACT,1.0	CHEMBL3665710,TP,ACT,1.0	CHEMBL142641,TN,INACT,0.019999999552965164	CHEMBL3646207,TP,ACT,1.0	CHEMBL429848,TP,ACT,0.9900000095367432	CHEMBL3649086,TP,ACT,1.0	CHEMBL3741003,TP,ACT,0.9900000095367432	CHEMBL390667,TN,INACT,0.7099999785423279	CHEMBL3649226,TP,ACT,1.0	CHEMBL3646167,TP,ACT,1.0	CHEMBL2112665,TN,INACT,0.10000000149011612	CHEMBL2347601,FN,ACT,0.9700000286102295	CHEMBL45305,TN,INACT,0.05000000074505806	CHEMBL156814,TN,INACT,0.0	

