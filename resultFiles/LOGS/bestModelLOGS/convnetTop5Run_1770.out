CNNModel CHEMBL230 adam 0.0001 30 32 0 0.8 False True
Number of active compounds :	1857
Number of inactive compounds :	1238
---------------------------------
Run id: CNNModel_CHEMBL230_adam_0.0001_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL230_adam_0.0001_30_32_0.8_True/
---------------------------------
Training samples: 1980
Validation samples: 619
--
Training Step: 1  | time: 0.780s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1980
[A[ATraining Step: 2  | total loss: [1m[32m0.62369[0m[0m | time: 1.396s
[2K
| Adam | epoch: 001 | loss: 0.62369 - acc: 0.4781 -- iter: 0064/1980
[A[ATraining Step: 3  | total loss: [1m[32m0.67992[0m[0m | time: 2.026s
[2K
| Adam | epoch: 001 | loss: 0.67992 - acc: 0.5727 -- iter: 0096/1980
[A[ATraining Step: 4  | total loss: [1m[32m0.68878[0m[0m | time: 2.643s
[2K
| Adam | epoch: 001 | loss: 0.68878 - acc: 0.5885 -- iter: 0128/1980
[A[ATraining Step: 5  | total loss: [1m[32m0.69044[0m[0m | time: 3.269s
[2K
| Adam | epoch: 001 | loss: 0.69044 - acc: 0.5921 -- iter: 0160/1980
[A[ATraining Step: 6  | total loss: [1m[32m0.68992[0m[0m | time: 3.896s
[2K
| Adam | epoch: 001 | loss: 0.68992 - acc: 0.6133 -- iter: 0192/1980
[A[ATraining Step: 7  | total loss: [1m[32m0.69025[0m[0m | time: 4.524s
[2K
| Adam | epoch: 001 | loss: 0.69025 - acc: 0.5828 -- iter: 0224/1980
[A[ATraining Step: 8  | total loss: [1m[32m0.69026[0m[0m | time: 5.150s
[2K
| Adam | epoch: 001 | loss: 0.69026 - acc: 0.5714 -- iter: 0256/1980
[A[ATraining Step: 9  | total loss: [1m[32m0.69225[0m[0m | time: 5.767s
[2K
| Adam | epoch: 001 | loss: 0.69225 - acc: 0.5336 -- iter: 0288/1980
[A[ATraining Step: 10  | total loss: [1m[32m0.69483[0m[0m | time: 6.397s
[2K
| Adam | epoch: 001 | loss: 0.69483 - acc: 0.5012 -- iter: 0320/1980
[A[ATraining Step: 11  | total loss: [1m[32m0.69015[0m[0m | time: 7.045s
[2K
| Adam | epoch: 001 | loss: 0.69015 - acc: 0.5598 -- iter: 0352/1980
[A[ATraining Step: 12  | total loss: [1m[32m0.69660[0m[0m | time: 7.659s
[2K
| Adam | epoch: 001 | loss: 0.69660 - acc: 0.4767 -- iter: 0384/1980
[A[ATraining Step: 13  | total loss: [1m[32m0.69079[0m[0m | time: 8.280s
[2K
| Adam | epoch: 001 | loss: 0.69079 - acc: 0.5402 -- iter: 0416/1980
[A[ATraining Step: 14  | total loss: [1m[32m0.68722[0m[0m | time: 8.911s
[2K
| Adam | epoch: 001 | loss: 0.68722 - acc: 0.5749 -- iter: 0448/1980
[A[ATraining Step: 15  | total loss: [1m[32m0.69185[0m[0m | time: 9.539s
[2K
| Adam | epoch: 001 | loss: 0.69185 - acc: 0.5334 -- iter: 0480/1980
[A[ATraining Step: 16  | total loss: [1m[32m0.69503[0m[0m | time: 10.174s
[2K
| Adam | epoch: 001 | loss: 0.69503 - acc: 0.4974 -- iter: 0512/1980
[A[ATraining Step: 17  | total loss: [1m[32m0.69074[0m[0m | time: 10.831s
[2K
| Adam | epoch: 001 | loss: 0.69074 - acc: 0.5321 -- iter: 0544/1980
[A[ATraining Step: 18  | total loss: [1m[32m0.68837[0m[0m | time: 11.480s
[2K
| Adam | epoch: 001 | loss: 0.68837 - acc: 0.5534 -- iter: 0576/1980
[A[ATraining Step: 19  | total loss: [1m[32m0.69056[0m[0m | time: 12.116s
[2K
| Adam | epoch: 001 | loss: 0.69056 - acc: 0.5356 -- iter: 0608/1980
[A[ATraining Step: 20  | total loss: [1m[32m0.68495[0m[0m | time: 12.766s
[2K
| Adam | epoch: 001 | loss: 0.68495 - acc: 0.5844 -- iter: 0640/1980
[A[ATraining Step: 21  | total loss: [1m[32m0.68579[0m[0m | time: 13.442s
[2K
| Adam | epoch: 001 | loss: 0.68579 - acc: 0.5776 -- iter: 0672/1980
[A[ATraining Step: 22  | total loss: [1m[32m0.68072[0m[0m | time: 14.139s
[2K
| Adam | epoch: 001 | loss: 0.68072 - acc: 0.6106 -- iter: 0704/1980
[A[ATraining Step: 23  | total loss: [1m[32m0.68241[0m[0m | time: 14.801s
[2K
| Adam | epoch: 001 | loss: 0.68241 - acc: 0.5966 -- iter: 0736/1980
[A[ATraining Step: 24  | total loss: [1m[32m0.67697[0m[0m | time: 15.465s
[2K
| Adam | epoch: 001 | loss: 0.67697 - acc: 0.6222 -- iter: 0768/1980
[A[ATraining Step: 25  | total loss: [1m[32m0.67750[0m[0m | time: 16.140s
[2K
| Adam | epoch: 001 | loss: 0.67750 - acc: 0.6144 -- iter: 0800/1980
[A[ATraining Step: 26  | total loss: [1m[32m0.67771[0m[0m | time: 16.795s
[2K
| Adam | epoch: 001 | loss: 0.67771 - acc: 0.6090 -- iter: 0832/1980
[A[ATraining Step: 27  | total loss: [1m[32m0.67292[0m[0m | time: 17.458s
[2K
| Adam | epoch: 001 | loss: 0.67292 - acc: 0.6211 -- iter: 0864/1980
[A[ATraining Step: 28  | total loss: [1m[32m0.66402[0m[0m | time: 18.118s
[2K
| Adam | epoch: 001 | loss: 0.66402 - acc: 0.6455 -- iter: 0896/1980
[A[ATraining Step: 29  | total loss: [1m[32m0.66958[0m[0m | time: 18.799s
[2K
| Adam | epoch: 001 | loss: 0.66958 - acc: 0.6253 -- iter: 0928/1980
[A[ATraining Step: 30  | total loss: [1m[32m0.67977[0m[0m | time: 19.456s
[2K
| Adam | epoch: 001 | loss: 0.67977 - acc: 0.5956 -- iter: 0960/1980
[A[ATraining Step: 31  | total loss: [1m[32m0.67011[0m[0m | time: 20.132s
[2K
| Adam | epoch: 001 | loss: 0.67011 - acc: 0.6168 -- iter: 0992/1980
[A[ATraining Step: 32  | total loss: [1m[32m0.65787[0m[0m | time: 20.818s
[2K
| Adam | epoch: 001 | loss: 0.65787 - acc: 0.6398 -- iter: 1024/1980
[A[ATraining Step: 33  | total loss: [1m[32m0.65866[0m[0m | time: 21.482s
[2K
| Adam | epoch: 001 | loss: 0.65866 - acc: 0.6365 -- iter: 1056/1980
[A[ATraining Step: 34  | total loss: [1m[32m0.65571[0m[0m | time: 22.142s
[2K
| Adam | epoch: 001 | loss: 0.65571 - acc: 0.6408 -- iter: 1088/1980
[A[ATraining Step: 35  | total loss: [1m[32m0.65717[0m[0m | time: 22.809s
[2K
| Adam | epoch: 001 | loss: 0.65717 - acc: 0.6375 -- iter: 1120/1980
[A[ATraining Step: 36  | total loss: [1m[32m0.65284[0m[0m | time: 23.493s
[2K
| Adam | epoch: 001 | loss: 0.65284 - acc: 0.6413 -- iter: 1152/1980
[A[ATraining Step: 37  | total loss: [1m[32m0.67203[0m[0m | time: 24.165s
[2K
| Adam | epoch: 001 | loss: 0.67203 - acc: 0.6130 -- iter: 1184/1980
[A[ATraining Step: 38  | total loss: [1m[32m0.67886[0m[0m | time: 24.822s
[2K
| Adam | epoch: 001 | loss: 0.67886 - acc: 0.6032 -- iter: 1216/1980
[A[ATraining Step: 39  | total loss: [1m[32m0.68832[0m[0m | time: 25.486s
[2K
| Adam | epoch: 001 | loss: 0.68832 - acc: 0.5894 -- iter: 1248/1980
[A[ATraining Step: 40  | total loss: [1m[32m0.69799[0m[0m | time: 26.158s
[2K
| Adam | epoch: 001 | loss: 0.69799 - acc: 0.5726 -- iter: 1280/1980
[A[ATraining Step: 41  | total loss: [1m[32m0.69690[0m[0m | time: 26.829s
[2K
| Adam | epoch: 001 | loss: 0.69690 - acc: 0.5708 -- iter: 1312/1980
[A[ATraining Step: 42  | total loss: [1m[32m0.68775[0m[0m | time: 27.506s
[2K
| Adam | epoch: 001 | loss: 0.68775 - acc: 0.5862 -- iter: 1344/1980
[A[ATraining Step: 43  | total loss: [1m[32m0.67651[0m[0m | time: 28.171s
[2K
| Adam | epoch: 001 | loss: 0.67651 - acc: 0.6096 -- iter: 1376/1980
[A[ATraining Step: 44  | total loss: [1m[32m0.66922[0m[0m | time: 28.853s
[2K
| Adam | epoch: 001 | loss: 0.66922 - acc: 0.6230 -- iter: 1408/1980
[A[ATraining Step: 45  | total loss: [1m[32m0.66177[0m[0m | time: 29.528s
[2K
| Adam | epoch: 001 | loss: 0.66177 - acc: 0.6393 -- iter: 1440/1980
[A[ATraining Step: 46  | total loss: [1m[32m0.66809[0m[0m | time: 30.210s
[2K
| Adam | epoch: 001 | loss: 0.66809 - acc: 0.6213 -- iter: 1472/1980
[A[ATraining Step: 47  | total loss: [1m[32m0.66905[0m[0m | time: 30.880s
[2K
| Adam | epoch: 001 | loss: 0.66905 - acc: 0.6168 -- iter: 1504/1980
[A[ATraining Step: 48  | total loss: [1m[32m0.65890[0m[0m | time: 31.536s
[2K
| Adam | epoch: 001 | loss: 0.65890 - acc: 0.6432 -- iter: 1536/1980
[A[ATraining Step: 49  | total loss: [1m[32m0.66185[0m[0m | time: 32.199s
[2K
| Adam | epoch: 001 | loss: 0.66185 - acc: 0.6354 -- iter: 1568/1980
[A[ATraining Step: 50  | total loss: [1m[32m0.66520[0m[0m | time: 32.894s
[2K
| Adam | epoch: 001 | loss: 0.66520 - acc: 0.6241 -- iter: 1600/1980
[A[ATraining Step: 51  | total loss: [1m[32m0.66758[0m[0m | time: 33.546s
[2K
| Adam | epoch: 001 | loss: 0.66758 - acc: 0.6195 -- iter: 1632/1980
[A[ATraining Step: 52  | total loss: [1m[32m0.67568[0m[0m | time: 34.212s
[2K
| Adam | epoch: 001 | loss: 0.67568 - acc: 0.5969 -- iter: 1664/1980
[A[ATraining Step: 53  | total loss: [1m[32m0.67661[0m[0m | time: 34.888s
[2K
| Adam | epoch: 001 | loss: 0.67661 - acc: 0.5918 -- iter: 1696/1980
[A[ATraining Step: 54  | total loss: [1m[32m0.67146[0m[0m | time: 35.556s
[2K
| Adam | epoch: 001 | loss: 0.67146 - acc: 0.6057 -- iter: 1728/1980
[A[ATraining Step: 55  | total loss: [1m[32m0.67525[0m[0m | time: 36.227s
[2K
| Adam | epoch: 001 | loss: 0.67525 - acc: 0.5950 -- iter: 1760/1980
[A[ATraining Step: 56  | total loss: [1m[32m0.66852[0m[0m | time: 36.894s
[2K
| Adam | epoch: 001 | loss: 0.66852 - acc: 0.6124 -- iter: 1792/1980
[A[ATraining Step: 57  | total loss: [1m[32m0.67255[0m[0m | time: 37.560s
[2K
| Adam | epoch: 001 | loss: 0.67255 - acc: 0.6012 -- iter: 1824/1980
[A[ATraining Step: 58  | total loss: [1m[32m0.67657[0m[0m | time: 38.213s
[2K
| Adam | epoch: 001 | loss: 0.67657 - acc: 0.5917 -- iter: 1856/1980
[A[ATraining Step: 59  | total loss: [1m[32m0.67315[0m[0m | time: 38.897s
[2K
| Adam | epoch: 001 | loss: 0.67315 - acc: 0.6003 -- iter: 1888/1980
[A[ATraining Step: 60  | total loss: [1m[32m0.67527[0m[0m | time: 39.596s
[2K
| Adam | epoch: 001 | loss: 0.67527 - acc: 0.5953 -- iter: 1920/1980
[A[ATraining Step: 61  | total loss: [1m[32m0.68023[0m[0m | time: 40.273s
[2K
| Adam | epoch: 001 | loss: 0.68023 - acc: 0.5829 -- iter: 1952/1980
[A[ATraining Step: 62  | total loss: [1m[32m0.67799[0m[0m | time: 43.353s
[2K
| Adam | epoch: 001 | loss: 0.67799 - acc: 0.5883 | val_loss: 0.65929 - val_acc: 0.6381 -- iter: 1980/1980
--
Training Step: 63  | total loss: [1m[32m0.67551[0m[0m | time: 0.603s
[2K
| Adam | epoch: 002 | loss: 0.67551 - acc: 0.5952 -- iter: 0032/1980
[A[ATraining Step: 64  | total loss: [1m[32m0.67330[0m[0m | time: 1.265s
[2K
| Adam | epoch: 002 | loss: 0.67330 - acc: 0.6012 -- iter: 0064/1980
[A[ATraining Step: 65  | total loss: [1m[32m0.68010[0m[0m | time: 1.915s
[2K
| Adam | epoch: 002 | loss: 0.68010 - acc: 0.5810 -- iter: 0096/1980
[A[ATraining Step: 66  | total loss: [1m[32m0.68360[0m[0m | time: 2.594s
[2K
| Adam | epoch: 002 | loss: 0.68360 - acc: 0.5711 -- iter: 0128/1980
[A[ATraining Step: 67  | total loss: [1m[32m0.69259[0m[0m | time: 3.267s
[2K
| Adam | epoch: 002 | loss: 0.69259 - acc: 0.5439 -- iter: 0160/1980
[A[ATraining Step: 68  | total loss: [1m[32m0.69158[0m[0m | time: 3.930s
[2K
| Adam | epoch: 002 | loss: 0.69158 - acc: 0.5461 -- iter: 0192/1980
[A[ATraining Step: 69  | total loss: [1m[32m0.69477[0m[0m | time: 4.621s
[2K
| Adam | epoch: 002 | loss: 0.69477 - acc: 0.5334 -- iter: 0224/1980
[A[ATraining Step: 70  | total loss: [1m[32m0.69733[0m[0m | time: 5.293s
[2K
| Adam | epoch: 002 | loss: 0.69733 - acc: 0.5223 -- iter: 0256/1980
[A[ATraining Step: 71  | total loss: [1m[32m0.69185[0m[0m | time: 5.959s
[2K
| Adam | epoch: 002 | loss: 0.69185 - acc: 0.5447 -- iter: 0288/1980
[A[ATraining Step: 72  | total loss: [1m[32m0.69125[0m[0m | time: 6.637s
[2K
| Adam | epoch: 002 | loss: 0.69125 - acc: 0.5467 -- iter: 0320/1980
[A[ATraining Step: 73  | total loss: [1m[32m0.68860[0m[0m | time: 7.289s
[2K
| Adam | epoch: 002 | loss: 0.68860 - acc: 0.5554 -- iter: 0352/1980
[A[ATraining Step: 74  | total loss: [1m[32m0.68879[0m[0m | time: 7.974s
[2K
| Adam | epoch: 002 | loss: 0.68879 - acc: 0.5527 -- iter: 0384/1980
[A[ATraining Step: 75  | total loss: [1m[32m0.68787[0m[0m | time: 8.631s
[2K
| Adam | epoch: 002 | loss: 0.68787 - acc: 0.5572 -- iter: 0416/1980
[A[ATraining Step: 76  | total loss: [1m[32m0.68648[0m[0m | time: 9.281s
[2K
| Adam | epoch: 002 | loss: 0.68648 - acc: 0.5645 -- iter: 0448/1980
[A[ATraining Step: 77  | total loss: [1m[32m0.68451[0m[0m | time: 9.960s
[2K
| Adam | epoch: 002 | loss: 0.68451 - acc: 0.5742 -- iter: 0480/1980
[A[ATraining Step: 78  | total loss: [1m[32m0.68433[0m[0m | time: 10.625s
[2K
| Adam | epoch: 002 | loss: 0.68433 - acc: 0.5730 -- iter: 0512/1980
[A[ATraining Step: 79  | total loss: [1m[32m0.68320[0m[0m | time: 11.286s
[2K
| Adam | epoch: 002 | loss: 0.68320 - acc: 0.5783 -- iter: 0544/1980
[A[ATraining Step: 80  | total loss: [1m[32m0.68268[0m[0m | time: 11.949s
[2K
| Adam | epoch: 002 | loss: 0.68268 - acc: 0.5799 -- iter: 0576/1980
[A[ATraining Step: 81  | total loss: [1m[32m0.68368[0m[0m | time: 12.616s
[2K
| Adam | epoch: 002 | loss: 0.68368 - acc: 0.5750 -- iter: 0608/1980
[A[ATraining Step: 82  | total loss: [1m[32m0.68441[0m[0m | time: 13.310s
[2K
| Adam | epoch: 002 | loss: 0.68441 - acc: 0.5706 -- iter: 0640/1980
[A[ATraining Step: 83  | total loss: [1m[32m0.68662[0m[0m | time: 13.985s
[2K
| Adam | epoch: 002 | loss: 0.68662 - acc: 0.5604 -- iter: 0672/1980
[A[ATraining Step: 84  | total loss: [1m[32m0.68383[0m[0m | time: 14.644s
[2K
| Adam | epoch: 002 | loss: 0.68383 - acc: 0.5731 -- iter: 0704/1980
[A[ATraining Step: 85  | total loss: [1m[32m0.68186[0m[0m | time: 15.331s
[2K
| Adam | epoch: 002 | loss: 0.68186 - acc: 0.5815 -- iter: 0736/1980
[A[ATraining Step: 86  | total loss: [1m[32m0.68395[0m[0m | time: 15.996s
[2K
| Adam | epoch: 002 | loss: 0.68395 - acc: 0.5702 -- iter: 0768/1980
[A[ATraining Step: 87  | total loss: [1m[32m0.68467[0m[0m | time: 16.658s
[2K
| Adam | epoch: 002 | loss: 0.68467 - acc: 0.5663 -- iter: 0800/1980
[A[ATraining Step: 88  | total loss: [1m[32m0.68321[0m[0m | time: 17.315s
[2K
| Adam | epoch: 002 | loss: 0.68321 - acc: 0.5722 -- iter: 0832/1980
[A[ATraining Step: 89  | total loss: [1m[32m0.68072[0m[0m | time: 17.981s
[2K
| Adam | epoch: 002 | loss: 0.68072 - acc: 0.5837 -- iter: 0864/1980
[A[ATraining Step: 90  | total loss: [1m[32m0.68103[0m[0m | time: 18.639s
[2K
| Adam | epoch: 002 | loss: 0.68103 - acc: 0.5816 -- iter: 0896/1980
[A[ATraining Step: 91  | total loss: [1m[32m0.68123[0m[0m | time: 19.333s
[2K
| Adam | epoch: 002 | loss: 0.68123 - acc: 0.5797 -- iter: 0928/1980
[A[ATraining Step: 92  | total loss: [1m[32m0.68070[0m[0m | time: 19.998s
[2K
| Adam | epoch: 002 | loss: 0.68070 - acc: 0.5811 -- iter: 0960/1980
[A[ATraining Step: 93  | total loss: [1m[32m0.68129[0m[0m | time: 20.687s
[2K
| Adam | epoch: 002 | loss: 0.68129 - acc: 0.5792 -- iter: 0992/1980
[A[ATraining Step: 94  | total loss: [1m[32m0.67666[0m[0m | time: 21.345s
[2K
| Adam | epoch: 002 | loss: 0.67666 - acc: 0.5963 -- iter: 1024/1980
[A[ATraining Step: 95  | total loss: [1m[32m0.67568[0m[0m | time: 22.033s
[2K
| Adam | epoch: 002 | loss: 0.67568 - acc: 0.5992 -- iter: 1056/1980
[A[ATraining Step: 96  | total loss: [1m[32m0.67649[0m[0m | time: 22.699s
[2K
| Adam | epoch: 002 | loss: 0.67649 - acc: 0.5955 -- iter: 1088/1980
[A[ATraining Step: 97  | total loss: [1m[32m0.67952[0m[0m | time: 23.402s
[2K
| Adam | epoch: 002 | loss: 0.67952 - acc: 0.5859 -- iter: 1120/1980
[A[ATraining Step: 98  | total loss: [1m[32m0.67534[0m[0m | time: 24.085s
[2K
| Adam | epoch: 002 | loss: 0.67534 - acc: 0.5992 -- iter: 1152/1980
[A[ATraining Step: 99  | total loss: [1m[32m0.67121[0m[0m | time: 24.786s
[2K
| Adam | epoch: 002 | loss: 0.67121 - acc: 0.6112 -- iter: 1184/1980
[A[ATraining Step: 100  | total loss: [1m[32m0.66826[0m[0m | time: 25.438s
[2K
| Adam | epoch: 002 | loss: 0.66826 - acc: 0.6188 -- iter: 1216/1980
[A[ATraining Step: 101  | total loss: [1m[32m0.66894[0m[0m | time: 26.090s
[2K
| Adam | epoch: 002 | loss: 0.66894 - acc: 0.6163 -- iter: 1248/1980
[A[ATraining Step: 102  | total loss: [1m[32m0.66693[0m[0m | time: 26.770s
[2K
| Adam | epoch: 002 | loss: 0.66693 - acc: 0.6203 -- iter: 1280/1980
[A[ATraining Step: 103  | total loss: [1m[32m0.66812[0m[0m | time: 27.425s
[2K
| Adam | epoch: 002 | loss: 0.66812 - acc: 0.6176 -- iter: 1312/1980
[A[ATraining Step: 104  | total loss: [1m[32m0.66706[0m[0m | time: 28.059s
[2K
| Adam | epoch: 002 | loss: 0.66706 - acc: 0.6184 -- iter: 1344/1980
[A[ATraining Step: 105  | total loss: [1m[32m0.67320[0m[0m | time: 28.693s
[2K
| Adam | epoch: 002 | loss: 0.67320 - acc: 0.6065 -- iter: 1376/1980
[A[ATraining Step: 106  | total loss: [1m[32m0.67515[0m[0m | time: 29.392s
[2K
| Adam | epoch: 002 | loss: 0.67515 - acc: 0.6021 -- iter: 1408/1980
[A[ATraining Step: 107  | total loss: [1m[32m0.67222[0m[0m | time: 30.070s
[2K
| Adam | epoch: 002 | loss: 0.67222 - acc: 0.6076 -- iter: 1440/1980
[A[ATraining Step: 108  | total loss: [1m[32m0.67600[0m[0m | time: 30.706s
[2K
| Adam | epoch: 002 | loss: 0.67600 - acc: 0.5999 -- iter: 1472/1980
[A[ATraining Step: 109  | total loss: [1m[32m0.67792[0m[0m | time: 31.378s
[2K
| Adam | epoch: 002 | loss: 0.67792 - acc: 0.5962 -- iter: 1504/1980
[A[ATraining Step: 110  | total loss: [1m[32m0.67507[0m[0m | time: 32.024s
[2K
| Adam | epoch: 002 | loss: 0.67507 - acc: 0.6022 -- iter: 1536/1980
[A[ATraining Step: 111  | total loss: [1m[32m0.67673[0m[0m | time: 32.684s
[2K
| Adam | epoch: 002 | loss: 0.67673 - acc: 0.5982 -- iter: 1568/1980
[A[ATraining Step: 112  | total loss: [1m[32m0.67664[0m[0m | time: 33.325s
[2K
| Adam | epoch: 002 | loss: 0.67664 - acc: 0.5978 -- iter: 1600/1980
[A[ATraining Step: 113  | total loss: [1m[32m0.67795[0m[0m | time: 33.977s
[2K
| Adam | epoch: 002 | loss: 0.67795 - acc: 0.5942 -- iter: 1632/1980
[A[ATraining Step: 114  | total loss: [1m[32m0.68038[0m[0m | time: 34.674s
[2K
| Adam | epoch: 002 | loss: 0.68038 - acc: 0.5879 -- iter: 1664/1980
[A[ATraining Step: 115  | total loss: [1m[32m0.68631[0m[0m | time: 35.355s
[2K
| Adam | epoch: 002 | loss: 0.68631 - acc: 0.5729 -- iter: 1696/1980
[A[ATraining Step: 116  | total loss: [1m[32m0.68641[0m[0m | time: 36.030s
[2K
| Adam | epoch: 002 | loss: 0.68641 - acc: 0.5719 -- iter: 1728/1980
[A[ATraining Step: 117  | total loss: [1m[32m0.69197[0m[0m | time: 36.662s
[2K
| Adam | epoch: 002 | loss: 0.69197 - acc: 0.5553 -- iter: 1760/1980
[A[ATraining Step: 118  | total loss: [1m[32m0.69244[0m[0m | time: 37.304s
[2K
| Adam | epoch: 002 | loss: 0.69244 - acc: 0.5529 -- iter: 1792/1980
[A[ATraining Step: 119  | total loss: [1m[32m0.69005[0m[0m | time: 37.945s
[2K
| Adam | epoch: 002 | loss: 0.69005 - acc: 0.5601 -- iter: 1824/1980
[A[ATraining Step: 120  | total loss: [1m[32m0.68627[0m[0m | time: 38.573s
[2K
| Adam | epoch: 002 | loss: 0.68627 - acc: 0.5728 -- iter: 1856/1980
[A[ATraining Step: 121  | total loss: [1m[32m0.68459[0m[0m | time: 39.191s
[2K
| Adam | epoch: 002 | loss: 0.68459 - acc: 0.5781 -- iter: 1888/1980
[A[ATraining Step: 122  | total loss: [1m[32m0.68313[0m[0m | time: 39.803s
[2K
| Adam | epoch: 002 | loss: 0.68313 - acc: 0.5828 -- iter: 1920/1980
[A[ATraining Step: 123  | total loss: [1m[32m0.68402[0m[0m | time: 40.420s
[2K
| Adam | epoch: 002 | loss: 0.68402 - acc: 0.5776 -- iter: 1952/1980
[A[ATraining Step: 124  | total loss: [1m[32m0.68279[0m[0m | time: 43.290s
[2K
| Adam | epoch: 002 | loss: 0.68279 - acc: 0.5823 | val_loss: 0.66836 - val_acc: 0.6381 -- iter: 1980/1980
--
Training Step: 125  | total loss: [1m[32m0.67956[0m[0m | time: 0.593s
[2K
| Adam | epoch: 003 | loss: 0.67956 - acc: 0.5960 -- iter: 0032/1980
[A[ATraining Step: 126  | total loss: [1m[32m0.67896[0m[0m | time: 1.172s
[2K
| Adam | epoch: 003 | loss: 0.67896 - acc: 0.5971 -- iter: 0064/1980
[A[ATraining Step: 127  | total loss: [1m[32m0.67842[0m[0m | time: 1.818s
[2K
| Adam | epoch: 003 | loss: 0.67842 - acc: 0.5981 -- iter: 0096/1980
[A[ATraining Step: 128  | total loss: [1m[32m0.68188[0m[0m | time: 2.478s
[2K
| Adam | epoch: 003 | loss: 0.68188 - acc: 0.5820 -- iter: 0128/1980
[A[ATraining Step: 129  | total loss: [1m[32m0.67845[0m[0m | time: 3.128s
[2K
| Adam | epoch: 003 | loss: 0.67845 - acc: 0.5957 -- iter: 0160/1980
[A[ATraining Step: 130  | total loss: [1m[32m0.67965[0m[0m | time: 3.809s
[2K
| Adam | epoch: 003 | loss: 0.67965 - acc: 0.5893 -- iter: 0192/1980
[A[ATraining Step: 131  | total loss: [1m[32m0.68294[0m[0m | time: 4.453s
[2K
| Adam | epoch: 003 | loss: 0.68294 - acc: 0.5741 -- iter: 0224/1980
[A[ATraining Step: 132  | total loss: [1m[32m0.68220[0m[0m | time: 5.119s
[2K
| Adam | epoch: 003 | loss: 0.68220 - acc: 0.5761 -- iter: 0256/1980
[A[ATraining Step: 133  | total loss: [1m[32m0.68182[0m[0m | time: 5.746s
[2K
| Adam | epoch: 003 | loss: 0.68182 - acc: 0.5778 -- iter: 0288/1980
[A[ATraining Step: 134  | total loss: [1m[32m0.68288[0m[0m | time: 6.423s
[2K
| Adam | epoch: 003 | loss: 0.68288 - acc: 0.5732 -- iter: 0320/1980
[A[ATraining Step: 135  | total loss: [1m[32m0.68547[0m[0m | time: 7.057s
[2K
| Adam | epoch: 003 | loss: 0.68547 - acc: 0.5627 -- iter: 0352/1980
[A[ATraining Step: 136  | total loss: [1m[32m0.68250[0m[0m | time: 7.695s
[2K
| Adam | epoch: 003 | loss: 0.68250 - acc: 0.5752 -- iter: 0384/1980
[A[ATraining Step: 137  | total loss: [1m[32m0.67818[0m[0m | time: 8.324s
[2K
| Adam | epoch: 003 | loss: 0.67818 - acc: 0.5927 -- iter: 0416/1980
[A[ATraining Step: 138  | total loss: [1m[32m0.67909[0m[0m | time: 8.963s
[2K
| Adam | epoch: 003 | loss: 0.67909 - acc: 0.5897 -- iter: 0448/1980
[A[ATraining Step: 139  | total loss: [1m[32m0.67966[0m[0m | time: 9.612s
[2K
| Adam | epoch: 003 | loss: 0.67966 - acc: 0.5869 -- iter: 0480/1980
[A[ATraining Step: 140  | total loss: [1m[32m0.67857[0m[0m | time: 10.278s
[2K
| Adam | epoch: 003 | loss: 0.67857 - acc: 0.5908 -- iter: 0512/1980
[A[ATraining Step: 141  | total loss: [1m[32m0.67830[0m[0m | time: 10.951s
[2K
| Adam | epoch: 003 | loss: 0.67830 - acc: 0.5911 -- iter: 0544/1980
[A[ATraining Step: 142  | total loss: [1m[32m0.68086[0m[0m | time: 11.611s
[2K
| Adam | epoch: 003 | loss: 0.68086 - acc: 0.5819 -- iter: 0576/1980
[A[ATraining Step: 143  | total loss: [1m[32m0.68025[0m[0m | time: 12.284s
[2K
| Adam | epoch: 003 | loss: 0.68025 - acc: 0.5831 -- iter: 0608/1980
[A[ATraining Step: 144  | total loss: [1m[32m0.68152[0m[0m | time: 12.977s
[2K
| Adam | epoch: 003 | loss: 0.68152 - acc: 0.5779 -- iter: 0640/1980
[A[ATraining Step: 145  | total loss: [1m[32m0.68084[0m[0m | time: 13.627s
[2K
| Adam | epoch: 003 | loss: 0.68084 - acc: 0.5795 -- iter: 0672/1980
[A[ATraining Step: 146  | total loss: [1m[32m0.67917[0m[0m | time: 14.278s
[2K
| Adam | epoch: 003 | loss: 0.67917 - acc: 0.5841 -- iter: 0704/1980
[A[ATraining Step: 147  | total loss: [1m[32m0.68047[0m[0m | time: 14.936s
[2K
| Adam | epoch: 003 | loss: 0.68047 - acc: 0.5788 -- iter: 0736/1980
[A[ATraining Step: 148  | total loss: [1m[32m0.68120[0m[0m | time: 15.613s
[2K
| Adam | epoch: 003 | loss: 0.68120 - acc: 0.5772 -- iter: 0768/1980
[A[ATraining Step: 149  | total loss: [1m[32m0.68460[0m[0m | time: 16.279s
[2K
| Adam | epoch: 003 | loss: 0.68460 - acc: 0.5663 -- iter: 0800/1980
[A[ATraining Step: 150  | total loss: [1m[32m0.67859[0m[0m | time: 16.960s
[2K
| Adam | epoch: 003 | loss: 0.67859 - acc: 0.5847 -- iter: 0832/1980
[A[ATraining Step: 151  | total loss: [1m[32m0.68265[0m[0m | time: 17.638s
[2K
| Adam | epoch: 003 | loss: 0.68265 - acc: 0.5731 -- iter: 0864/1980
[A[ATraining Step: 152  | total loss: [1m[32m0.68477[0m[0m | time: 18.323s
[2K
| Adam | epoch: 003 | loss: 0.68477 - acc: 0.5658 -- iter: 0896/1980
[A[ATraining Step: 153  | total loss: [1m[32m0.68192[0m[0m | time: 18.981s
[2K
| Adam | epoch: 003 | loss: 0.68192 - acc: 0.5748 -- iter: 0928/1980
[A[ATraining Step: 154  | total loss: [1m[32m0.68242[0m[0m | time: 19.667s
[2K
| Adam | epoch: 003 | loss: 0.68242 - acc: 0.5736 -- iter: 0960/1980
[A[ATraining Step: 155  | total loss: [1m[32m0.68148[0m[0m | time: 20.335s
[2K
| Adam | epoch: 003 | loss: 0.68148 - acc: 0.5756 -- iter: 0992/1980
[A[ATraining Step: 156  | total loss: [1m[32m0.68093[0m[0m | time: 20.991s
[2K
| Adam | epoch: 003 | loss: 0.68093 - acc: 0.5774 -- iter: 1024/1980
[A[ATraining Step: 157  | total loss: [1m[32m0.67539[0m[0m | time: 21.662s
[2K
| Adam | epoch: 003 | loss: 0.67539 - acc: 0.5947 -- iter: 1056/1980
[A[ATraining Step: 158  | total loss: [1m[32m0.67809[0m[0m | time: 22.320s
[2K
| Adam | epoch: 003 | loss: 0.67809 - acc: 0.5852 -- iter: 1088/1980
[A[ATraining Step: 159  | total loss: [1m[32m0.68088[0m[0m | time: 22.995s
[2K
| Adam | epoch: 003 | loss: 0.68088 - acc: 0.5767 -- iter: 1120/1980
[A[ATraining Step: 160  | total loss: [1m[32m0.68216[0m[0m | time: 23.647s
[2K
| Adam | epoch: 003 | loss: 0.68216 - acc: 0.5721 -- iter: 1152/1980
[A[ATraining Step: 161  | total loss: [1m[32m0.67717[0m[0m | time: 24.305s
[2K
| Adam | epoch: 003 | loss: 0.67717 - acc: 0.5868 -- iter: 1184/1980
[A[ATraining Step: 162  | total loss: [1m[32m0.67474[0m[0m | time: 25.001s
[2K
| Adam | epoch: 003 | loss: 0.67474 - acc: 0.5938 -- iter: 1216/1980
[A[ATraining Step: 163  | total loss: [1m[32m0.67459[0m[0m | time: 25.641s
[2K
| Adam | epoch: 003 | loss: 0.67459 - acc: 0.5938 -- iter: 1248/1980
[A[ATraining Step: 164  | total loss: [1m[32m0.67537[0m[0m | time: 26.317s
[2K
| Adam | epoch: 003 | loss: 0.67537 - acc: 0.5906 -- iter: 1280/1980
[A[ATraining Step: 165  | total loss: [1m[32m0.67528[0m[0m | time: 26.983s
[2K
| Adam | epoch: 003 | loss: 0.67528 - acc: 0.5909 -- iter: 1312/1980
[A[ATraining Step: 166  | total loss: [1m[32m0.67419[0m[0m | time: 27.643s
[2K
| Adam | epoch: 003 | loss: 0.67419 - acc: 0.5943 -- iter: 1344/1980
[A[ATraining Step: 167  | total loss: [1m[32m0.66819[0m[0m | time: 28.294s
[2K
| Adam | epoch: 003 | loss: 0.66819 - acc: 0.6099 -- iter: 1376/1980
[A[ATraining Step: 168  | total loss: [1m[32m0.66894[0m[0m | time: 28.977s
[2K
| Adam | epoch: 003 | loss: 0.66894 - acc: 0.6083 -- iter: 1408/1980
[A[ATraining Step: 169  | total loss: [1m[32m0.67209[0m[0m | time: 29.630s
[2K
| Adam | epoch: 003 | loss: 0.67209 - acc: 0.6006 -- iter: 1440/1980
[A[ATraining Step: 170  | total loss: [1m[32m0.67924[0m[0m | time: 30.266s
[2K
| Adam | epoch: 003 | loss: 0.67924 - acc: 0.5843 -- iter: 1472/1980
[A[ATraining Step: 171  | total loss: [1m[32m0.67332[0m[0m | time: 30.923s
[2K
| Adam | epoch: 003 | loss: 0.67332 - acc: 0.5977 -- iter: 1504/1980
[A[ATraining Step: 172  | total loss: [1m[32m0.66915[0m[0m | time: 31.570s
[2K
| Adam | epoch: 003 | loss: 0.66915 - acc: 0.6067 -- iter: 1536/1980
[A[ATraining Step: 173  | total loss: [1m[32m0.66833[0m[0m | time: 32.212s
[2K
| Adam | epoch: 003 | loss: 0.66833 - acc: 0.6085 -- iter: 1568/1980
[A[ATraining Step: 174  | total loss: [1m[32m0.67229[0m[0m | time: 32.876s
[2K
| Adam | epoch: 003 | loss: 0.67229 - acc: 0.6008 -- iter: 1600/1980
[A[ATraining Step: 175  | total loss: [1m[32m0.67206[0m[0m | time: 33.530s
[2K
| Adam | epoch: 003 | loss: 0.67206 - acc: 0.6001 -- iter: 1632/1980
[A[ATraining Step: 176  | total loss: [1m[32m0.67354[0m[0m | time: 34.196s
[2K
| Adam | epoch: 003 | loss: 0.67354 - acc: 0.5963 -- iter: 1664/1980
[A[ATraining Step: 177  | total loss: [1m[32m0.66966[0m[0m | time: 34.879s
[2K
| Adam | epoch: 003 | loss: 0.66966 - acc: 0.6055 -- iter: 1696/1980
[A[ATraining Step: 178  | total loss: [1m[32m0.67315[0m[0m | time: 35.548s
[2K
| Adam | epoch: 003 | loss: 0.67315 - acc: 0.5980 -- iter: 1728/1980
[A[ATraining Step: 179  | total loss: [1m[32m0.66892[0m[0m | time: 36.216s
[2K
| Adam | epoch: 003 | loss: 0.66892 - acc: 0.6070 -- iter: 1760/1980
[A[ATraining Step: 180  | total loss: [1m[32m0.66340[0m[0m | time: 36.879s
[2K
| Adam | epoch: 003 | loss: 0.66340 - acc: 0.6182 -- iter: 1792/1980
[A[ATraining Step: 181  | total loss: [1m[32m0.66616[0m[0m | time: 37.520s
[2K
| Adam | epoch: 003 | loss: 0.66616 - acc: 0.6126 -- iter: 1824/1980
[A[ATraining Step: 182  | total loss: [1m[32m0.66813[0m[0m | time: 38.169s
[2K
| Adam | epoch: 003 | loss: 0.66813 - acc: 0.6076 -- iter: 1856/1980
[A[ATraining Step: 183  | total loss: [1m[32m0.66258[0m[0m | time: 38.825s
[2K
| Adam | epoch: 003 | loss: 0.66258 - acc: 0.6187 -- iter: 1888/1980
[A[ATraining Step: 184  | total loss: [1m[32m0.66914[0m[0m | time: 39.496s
[2K
| Adam | epoch: 003 | loss: 0.66914 - acc: 0.6068 -- iter: 1920/1980
[A[ATraining Step: 185  | total loss: [1m[32m0.67408[0m[0m | time: 40.134s
[2K
| Adam | epoch: 003 | loss: 0.67408 - acc: 0.5961 -- iter: 1952/1980
[A[ATraining Step: 186  | total loss: [1m[32m0.66343[0m[0m | time: 43.157s
[2K
| Adam | epoch: 003 | loss: 0.66343 - acc: 0.6178 | val_loss: 0.65370 - val_acc: 0.6381 -- iter: 1980/1980
--
Training Step: 187  | total loss: [1m[32m0.66903[0m[0m | time: 0.671s
[2K
| Adam | epoch: 004 | loss: 0.66903 - acc: 0.6060 -- iter: 0032/1980
[A[ATraining Step: 188  | total loss: [1m[32m0.67230[0m[0m | time: 1.229s
[2K
| Adam | epoch: 004 | loss: 0.67230 - acc: 0.5985 -- iter: 0064/1980
[A[ATraining Step: 189  | total loss: [1m[32m0.67054[0m[0m | time: 1.822s
[2K
| Adam | epoch: 004 | loss: 0.67054 - acc: 0.6030 -- iter: 0096/1980
[A[ATraining Step: 190  | total loss: [1m[32m0.66899[0m[0m | time: 2.453s
[2K
| Adam | epoch: 004 | loss: 0.66899 - acc: 0.6070 -- iter: 0128/1980
[A[ATraining Step: 191  | total loss: [1m[32m0.66619[0m[0m | time: 3.141s
[2K
| Adam | epoch: 004 | loss: 0.66619 - acc: 0.6119 -- iter: 0160/1980
[A[ATraining Step: 192  | total loss: [1m[32m0.67119[0m[0m | time: 3.801s
[2K
| Adam | epoch: 004 | loss: 0.67119 - acc: 0.6007 -- iter: 0192/1980
[A[ATraining Step: 193  | total loss: [1m[32m0.66735[0m[0m | time: 4.476s
[2K
| Adam | epoch: 004 | loss: 0.66735 - acc: 0.6094 -- iter: 0224/1980
[A[ATraining Step: 194  | total loss: [1m[32m0.67378[0m[0m | time: 5.137s
[2K
| Adam | epoch: 004 | loss: 0.67378 - acc: 0.5953 -- iter: 0256/1980
[A[ATraining Step: 195  | total loss: [1m[32m0.67758[0m[0m | time: 5.814s
[2K
| Adam | epoch: 004 | loss: 0.67758 - acc: 0.5858 -- iter: 0288/1980
[A[ATraining Step: 196  | total loss: [1m[32m0.67868[0m[0m | time: 6.515s
[2K
| Adam | epoch: 004 | loss: 0.67868 - acc: 0.5835 -- iter: 0320/1980
[A[ATraining Step: 197  | total loss: [1m[32m0.67817[0m[0m | time: 7.173s
[2K
| Adam | epoch: 004 | loss: 0.67817 - acc: 0.5845 -- iter: 0352/1980
[A[ATraining Step: 198  | total loss: [1m[32m0.67455[0m[0m | time: 7.816s
[2K
| Adam | epoch: 004 | loss: 0.67455 - acc: 0.5948 -- iter: 0384/1980
[A[ATraining Step: 199  | total loss: [1m[32m0.67779[0m[0m | time: 8.478s
[2K
| Adam | epoch: 004 | loss: 0.67779 - acc: 0.5853 -- iter: 0416/1980
[A[ATraining Step: 200  | total loss: [1m[32m0.67829[0m[0m | time: 11.554s
[2K
| Adam | epoch: 004 | loss: 0.67829 - acc: 0.5830 | val_loss: 0.66027 - val_acc: 0.6381 -- iter: 0448/1980
--
Training Step: 201  | total loss: [1m[32m0.67553[0m[0m | time: 12.185s
[2K
| Adam | epoch: 004 | loss: 0.67553 - acc: 0.5903 -- iter: 0480/1980
[A[ATraining Step: 202  | total loss: [1m[32m0.67628[0m[0m | time: 12.818s
[2K
| Adam | epoch: 004 | loss: 0.67628 - acc: 0.5876 -- iter: 0512/1980
[A[ATraining Step: 203  | total loss: [1m[32m0.68311[0m[0m | time: 13.443s
[2K
| Adam | epoch: 004 | loss: 0.68311 - acc: 0.5663 -- iter: 0544/1980
[A[ATraining Step: 204  | total loss: [1m[32m0.68483[0m[0m | time: 14.066s
[2K
| Adam | epoch: 004 | loss: 0.68483 - acc: 0.5597 -- iter: 0576/1980
[A[ATraining Step: 205  | total loss: [1m[32m0.68402[0m[0m | time: 14.711s
[2K
| Adam | epoch: 004 | loss: 0.68402 - acc: 0.5631 -- iter: 0608/1980
[A[ATraining Step: 206  | total loss: [1m[32m0.68164[0m[0m | time: 15.344s
[2K
| Adam | epoch: 004 | loss: 0.68164 - acc: 0.5724 -- iter: 0640/1980
[A[ATraining Step: 207  | total loss: [1m[32m0.68291[0m[0m | time: 16.001s
[2K
| Adam | epoch: 004 | loss: 0.68291 - acc: 0.5683 -- iter: 0672/1980
[A[ATraining Step: 208  | total loss: [1m[32m0.68799[0m[0m | time: 16.703s
[2K
| Adam | epoch: 004 | loss: 0.68799 - acc: 0.5458 -- iter: 0704/1980
[A[ATraining Step: 209  | total loss: [1m[32m0.68684[0m[0m | time: 17.381s
[2K
| Adam | epoch: 004 | loss: 0.68684 - acc: 0.5506 -- iter: 0736/1980
[A[ATraining Step: 210  | total loss: [1m[32m0.68512[0m[0m | time: 18.061s
[2K
| Adam | epoch: 004 | loss: 0.68512 - acc: 0.5581 -- iter: 0768/1980
[A[ATraining Step: 211  | total loss: [1m[32m0.68361[0m[0m | time: 18.730s
[2K
| Adam | epoch: 004 | loss: 0.68361 - acc: 0.5648 -- iter: 0800/1980
[A[ATraining Step: 212  | total loss: [1m[32m0.68122[0m[0m | time: 19.390s
[2K
| Adam | epoch: 004 | loss: 0.68122 - acc: 0.5770 -- iter: 0832/1980
[A[ATraining Step: 213  | total loss: [1m[32m0.68178[0m[0m | time: 20.044s
[2K
| Adam | epoch: 004 | loss: 0.68178 - acc: 0.5756 -- iter: 0864/1980
[A[ATraining Step: 214  | total loss: [1m[32m0.68218[0m[0m | time: 20.712s
[2K
| Adam | epoch: 004 | loss: 0.68218 - acc: 0.5743 -- iter: 0896/1980
[A[ATraining Step: 215  | total loss: [1m[32m0.68280[0m[0m | time: 21.413s
[2K
| Adam | epoch: 004 | loss: 0.68280 - acc: 0.5700 -- iter: 0928/1980
[A[ATraining Step: 216  | total loss: [1m[32m0.68241[0m[0m | time: 22.080s
[2K
| Adam | epoch: 004 | loss: 0.68241 - acc: 0.5723 -- iter: 0960/1980
[A[ATraining Step: 217  | total loss: [1m[32m0.68594[0m[0m | time: 22.765s
[2K
| Adam | epoch: 004 | loss: 0.68594 - acc: 0.5557 -- iter: 0992/1980
[A[ATraining Step: 218  | total loss: [1m[32m0.68700[0m[0m | time: 23.463s
[2K
| Adam | epoch: 004 | loss: 0.68700 - acc: 0.5502 -- iter: 1024/1980
[A[ATraining Step: 219  | total loss: [1m[32m0.68319[0m[0m | time: 24.124s
[2K
| Adam | epoch: 004 | loss: 0.68319 - acc: 0.5670 -- iter: 1056/1980
[A[ATraining Step: 220  | total loss: [1m[32m0.68470[0m[0m | time: 24.790s
[2K
| Adam | epoch: 004 | loss: 0.68470 - acc: 0.5603 -- iter: 1088/1980
[A[ATraining Step: 221  | total loss: [1m[32m0.68332[0m[0m | time: 25.491s
[2K
| Adam | epoch: 004 | loss: 0.68332 - acc: 0.5668 -- iter: 1120/1980
[A[ATraining Step: 222  | total loss: [1m[32m0.68313[0m[0m | time: 26.160s
[2K
| Adam | epoch: 004 | loss: 0.68313 - acc: 0.5664 -- iter: 1152/1980
[A[ATraining Step: 223  | total loss: [1m[32m0.68736[0m[0m | time: 26.853s
[2K
| Adam | epoch: 004 | loss: 0.68736 - acc: 0.5472 -- iter: 1184/1980
[A[ATraining Step: 224  | total loss: [1m[32m0.68443[0m[0m | time: 27.518s
[2K
| Adam | epoch: 004 | loss: 0.68443 - acc: 0.5613 -- iter: 1216/1980
[A[ATraining Step: 225  | total loss: [1m[32m0.68498[0m[0m | time: 28.214s
[2K
| Adam | epoch: 004 | loss: 0.68498 - acc: 0.5583 -- iter: 1248/1980
[A[ATraining Step: 226  | total loss: [1m[32m0.68337[0m[0m | time: 28.907s
[2K
| Adam | epoch: 004 | loss: 0.68337 - acc: 0.5649 -- iter: 1280/1980
[A[ATraining Step: 227  | total loss: [1m[32m0.68215[0m[0m | time: 29.572s
[2K
| Adam | epoch: 004 | loss: 0.68215 - acc: 0.5709 -- iter: 1312/1980
[A[ATraining Step: 228  | total loss: [1m[32m0.67882[0m[0m | time: 30.232s
[2K
| Adam | epoch: 004 | loss: 0.67882 - acc: 0.5857 -- iter: 1344/1980
[A[ATraining Step: 229  | total loss: [1m[32m0.67849[0m[0m | time: 30.903s
[2K
| Adam | epoch: 004 | loss: 0.67849 - acc: 0.5865 -- iter: 1376/1980
[A[ATraining Step: 230  | total loss: [1m[32m0.67746[0m[0m | time: 31.527s
[2K
| Adam | epoch: 004 | loss: 0.67746 - acc: 0.5904 -- iter: 1408/1980
[A[ATraining Step: 231  | total loss: [1m[32m0.67469[0m[0m | time: 32.149s
[2K
| Adam | epoch: 004 | loss: 0.67469 - acc: 0.6001 -- iter: 1440/1980
[A[ATraining Step: 232  | total loss: [1m[32m0.67566[0m[0m | time: 32.772s
[2K
| Adam | epoch: 004 | loss: 0.67566 - acc: 0.5963 -- iter: 1472/1980
[A[ATraining Step: 233  | total loss: [1m[32m0.67445[0m[0m | time: 33.460s
[2K
| Adam | epoch: 004 | loss: 0.67445 - acc: 0.5992 -- iter: 1504/1980
[A[ATraining Step: 234  | total loss: [1m[32m0.67729[0m[0m | time: 54.289s
[2K
| Adam | epoch: 004 | loss: 0.67729 - acc: 0.5893 -- iter: 1536/1980
[A[ATraining Step: 235  | total loss: [1m[32m0.67163[0m[0m | time: 62.537s
[2K
| Adam | epoch: 004 | loss: 0.67163 - acc: 0.6053 -- iter: 1568/1980
[A[ATraining Step: 236  | total loss: [1m[32m0.67419[0m[0m | time: 77.564s
[2K
| Adam | epoch: 004 | loss: 0.67419 - acc: 0.5979 -- iter: 1600/1980
[A[ATraining Step: 237  | total loss: [1m[32m0.67313[0m[0m | time: 90.491s
[2K
| Adam | epoch: 004 | loss: 0.67313 - acc: 0.6006 -- iter: 1632/1980
[A[ATraining Step: 238  | total loss: [1m[32m0.66812[0m[0m | time: 97.826s
[2K
| Adam | epoch: 004 | loss: 0.66812 - acc: 0.6125 -- iter: 1664/1980
[A[ATraining Step: 239  | total loss: [1m[32m0.66964[0m[0m | time: 115.249s
[2K
| Adam | epoch: 004 | loss: 0.66964 - acc: 0.6075 -- iter: 1696/1980
[A[ATraining Step: 240  | total loss: [1m[32m0.67272[0m[0m | time: 117.123s
[2K
| Adam | epoch: 004 | loss: 0.67272 - acc: 0.5998 -- iter: 1728/1980
[A[ATraining Step: 241  | total loss: [1m[32m0.67314[0m[0m | time: 117.777s
[2K
| Adam | epoch: 004 | loss: 0.67314 - acc: 0.5992 -- iter: 1760/1980
[A[ATraining Step: 242  | total loss: [1m[32m0.66684[0m[0m | time: 118.511s
[2K
| Adam | epoch: 004 | loss: 0.66684 - acc: 0.6112 -- iter: 1792/1980
[A[ATraining Step: 243  | total loss: [1m[32m0.67257[0m[0m | time: 119.218s
[2K
| Adam | epoch: 004 | loss: 0.67257 - acc: 0.6001 -- iter: 1824/1980
[A[ATraining Step: 244  | total loss: [1m[32m0.67418[0m[0m | time: 127.147s
[2K
| Adam | epoch: 004 | loss: 0.67418 - acc: 0.5963 -- iter: 1856/1980
[A[ATraining Step: 245  | total loss: [1m[32m0.67135[0m[0m | time: 145.759s
[2K
| Adam | epoch: 004 | loss: 0.67135 - acc: 0.6023 -- iter: 1888/1980
[A[ATraining Step: 246  | total loss: [1m[32m0.68250[0m[0m | time: 170.335s
[2K
| Adam | epoch: 004 | loss: 0.68250 - acc: 0.5796 -- iter: 1920/1980
[A[ATraining Step: 247  | total loss: [1m[32m0.68411[0m[0m | time: 178.132s
[2K
| Adam | epoch: 004 | loss: 0.68411 - acc: 0.5747 -- iter: 1952/1980
[A[ATraining Step: 248  | total loss: [1m[32m0.68413[0m[0m | time: 181.183s
[2K
| Adam | epoch: 004 | loss: 0.68413 - acc: 0.5735 | val_loss: 0.65507 - val_acc: 0.6381 -- iter: 1980/1980
--
Training Step: 249  | total loss: [1m[32m0.68409[0m[0m | time: 0.714s
[2K
| Adam | epoch: 005 | loss: 0.68409 - acc: 0.5724 -- iter: 0032/1980
[A[ATraining Step: 250  | total loss: [1m[32m0.67804[0m[0m | time: 1.417s
[2K
| Adam | epoch: 005 | loss: 0.67804 - acc: 0.5870 -- iter: 0064/1980
[A[ATraining Step: 251  | total loss: [1m[32m0.67417[0m[0m | time: 2.050s
[2K
| Adam | epoch: 005 | loss: 0.67417 - acc: 0.5971 -- iter: 0096/1980
[A[ATraining Step: 252  | total loss: [1m[32m0.67593[0m[0m | time: 2.610s
[2K
| Adam | epoch: 005 | loss: 0.67593 - acc: 0.5910 -- iter: 0128/1980
[A[ATraining Step: 253  | total loss: [1m[32m0.67712[0m[0m | time: 3.241s
[2K
| Adam | epoch: 005 | loss: 0.67712 - acc: 0.5854 -- iter: 0160/1980
[A[ATraining Step: 254  | total loss: [1m[32m0.67609[0m[0m | time: 3.877s
[2K
| Adam | epoch: 005 | loss: 0.67609 - acc: 0.5894 -- iter: 0192/1980
[A[ATraining Step: 255  | total loss: [1m[32m0.67188[0m[0m | time: 4.502s
[2K
| Adam | epoch: 005 | loss: 0.67188 - acc: 0.5992 -- iter: 0224/1980
[A[ATraining Step: 256  | total loss: [1m[32m0.66895[0m[0m | time: 5.166s
[2K
| Adam | epoch: 005 | loss: 0.66895 - acc: 0.6080 -- iter: 0256/1980
[A[ATraining Step: 257  | total loss: [1m[32m0.66959[0m[0m | time: 5.846s
[2K
| Adam | epoch: 005 | loss: 0.66959 - acc: 0.6035 -- iter: 0288/1980
[A[ATraining Step: 258  | total loss: [1m[32m0.67212[0m[0m | time: 6.541s
[2K
| Adam | epoch: 005 | loss: 0.67212 - acc: 0.5963 -- iter: 0320/1980
[A[ATraining Step: 259  | total loss: [1m[32m0.67690[0m[0m | time: 7.189s
[2K
| Adam | epoch: 005 | loss: 0.67690 - acc: 0.5835 -- iter: 0352/1980
[A[ATraining Step: 260  | total loss: [1m[32m0.67451[0m[0m | time: 7.903s
[2K
| Adam | epoch: 005 | loss: 0.67451 - acc: 0.5908 -- iter: 0384/1980
[A[ATraining Step: 261  | total loss: [1m[32m0.67301[0m[0m | time: 8.613s
[2K
| Adam | epoch: 005 | loss: 0.67301 - acc: 0.5942 -- iter: 0416/1980
[A[ATraining Step: 262  | total loss: [1m[32m0.66875[0m[0m | time: 9.308s
[2K
| Adam | epoch: 005 | loss: 0.66875 - acc: 0.6067 -- iter: 0448/1980
[A[ATraining Step: 263  | total loss: [1m[32m0.66972[0m[0m | time: 9.967s
[2K
| Adam | epoch: 005 | loss: 0.66972 - acc: 0.6022 -- iter: 0480/1980
[A[ATraining Step: 264  | total loss: [1m[32m0.67442[0m[0m | time: 10.602s
[2K
| Adam | epoch: 005 | loss: 0.67442 - acc: 0.5889 -- iter: 0512/1980
[A[ATraining Step: 265  | total loss: [1m[32m0.67393[0m[0m | time: 11.291s
[2K
| Adam | epoch: 005 | loss: 0.67393 - acc: 0.5894 -- iter: 0544/1980
[A[ATraining Step: 266  | total loss: [1m[32m0.67275[0m[0m | time: 11.970s
[2K
| Adam | epoch: 005 | loss: 0.67275 - acc: 0.5929 -- iter: 0576/1980
[A[ATraining Step: 267  | total loss: [1m[32m0.67932[0m[0m | time: 12.595s
[2K
| Adam | epoch: 005 | loss: 0.67932 - acc: 0.5743 -- iter: 0608/1980
[A[ATraining Step: 268  | total loss: [1m[32m0.67791[0m[0m | time: 13.233s
[2K
| Adam | epoch: 005 | loss: 0.67791 - acc: 0.5793 -- iter: 0640/1980
[A[ATraining Step: 269  | total loss: [1m[32m0.67974[0m[0m | time: 13.865s
[2K
| Adam | epoch: 005 | loss: 0.67974 - acc: 0.5745 -- iter: 0672/1980
[A[ATraining Step: 270  | total loss: [1m[32m0.68210[0m[0m | time: 14.490s
[2K
| Adam | epoch: 005 | loss: 0.68210 - acc: 0.5671 -- iter: 0704/1980
[A[ATraining Step: 271  | total loss: [1m[32m0.68020[0m[0m | time: 15.135s
[2K
| Adam | epoch: 005 | loss: 0.68020 - acc: 0.5697 -- iter: 0736/1980
[A[ATraining Step: 272  | total loss: [1m[32m0.67546[0m[0m | time: 15.807s
[2K
| Adam | epoch: 005 | loss: 0.67546 - acc: 0.5846 -- iter: 0768/1980
[A[ATraining Step: 273  | total loss: [1m[32m0.67472[0m[0m | time: 16.484s
[2K
| Adam | epoch: 005 | loss: 0.67472 - acc: 0.5856 -- iter: 0800/1980
[A[ATraining Step: 274  | total loss: [1m[32m0.68112[0m[0m | time: 17.115s
[2K
| Adam | epoch: 005 | loss: 0.68112 - acc: 0.5614 -- iter: 0832/1980
[A[ATraining Step: 275  | total loss: [1m[32m0.68148[0m[0m | time: 17.790s
[2K
| Adam | epoch: 005 | loss: 0.68148 - acc: 0.5584 -- iter: 0864/1980
[A[ATraining Step: 276  | total loss: [1m[32m0.67766[0m[0m | time: 18.453s
[2K
| Adam | epoch: 005 | loss: 0.67766 - acc: 0.5713 -- iter: 0896/1980
[A[ATraining Step: 277  | total loss: [1m[32m0.68060[0m[0m | time: 19.077s
[2K
| Adam | epoch: 005 | loss: 0.68060 - acc: 0.5610 -- iter: 0928/1980
[A[ATraining Step: 278  | total loss: [1m[32m0.67877[0m[0m | time: 19.819s
[2K
| Adam | epoch: 005 | loss: 0.67877 - acc: 0.5674 -- iter: 0960/1980
[A[ATraining Step: 279  | total loss: [1m[32m0.67837[0m[0m | time: 20.513s
[2K
| Adam | epoch: 005 | loss: 0.67837 - acc: 0.5701 -- iter: 0992/1980
[A[ATraining Step: 280  | total loss: [1m[32m0.67498[0m[0m | time: 21.175s
[2K
| Adam | epoch: 005 | loss: 0.67498 - acc: 0.5818 -- iter: 1024/1980
[A[ATraining Step: 281  | total loss: [1m[32m0.67380[0m[0m | time: 21.847s
[2K
| Adam | epoch: 005 | loss: 0.67380 - acc: 0.5830 -- iter: 1056/1980
[A[ATraining Step: 282  | total loss: [1m[32m0.67712[0m[0m | time: 22.501s
[2K
| Adam | epoch: 005 | loss: 0.67712 - acc: 0.5716 -- iter: 1088/1980
[A[ATraining Step: 283  | total loss: [1m[32m0.67718[0m[0m | time: 23.158s
[2K
| Adam | epoch: 005 | loss: 0.67718 - acc: 0.5707 -- iter: 1120/1980
[A[ATraining Step: 284  | total loss: [1m[32m0.67354[0m[0m | time: 23.821s
[2K
| Adam | epoch: 005 | loss: 0.67354 - acc: 0.5823 -- iter: 1152/1980
[A[ATraining Step: 285  | total loss: [1m[32m0.66796[0m[0m | time: 24.470s
[2K
| Adam | epoch: 005 | loss: 0.66796 - acc: 0.6022 -- iter: 1184/1980
[A[ATraining Step: 286  | total loss: [1m[32m0.66762[0m[0m | time: 25.133s
[2K
| Adam | epoch: 005 | loss: 0.66762 - acc: 0.6014 -- iter: 1216/1980
[A[ATraining Step: 287  | total loss: [1m[32m0.67410[0m[0m | time: 25.823s
[2K
| Adam | epoch: 005 | loss: 0.67410 - acc: 0.5819 -- iter: 1248/1980
[A[ATraining Step: 288  | total loss: [1m[32m0.67236[0m[0m | time: 26.535s
[2K
| Adam | epoch: 005 | loss: 0.67236 - acc: 0.5862 -- iter: 1280/1980
[A[ATraining Step: 289  | total loss: [1m[32m0.67114[0m[0m | time: 27.192s
[2K
| Adam | epoch: 005 | loss: 0.67114 - acc: 0.5901 -- iter: 1312/1980
[A[ATraining Step: 290  | total loss: [1m[32m0.67516[0m[0m | time: 27.864s
[2K
| Adam | epoch: 005 | loss: 0.67516 - acc: 0.5811 -- iter: 1344/1980
[A[ATraining Step: 291  | total loss: [1m[32m0.67344[0m[0m | time: 28.568s
[2K
| Adam | epoch: 005 | loss: 0.67344 - acc: 0.5823 -- iter: 1376/1980
[A[ATraining Step: 292  | total loss: [1m[32m0.67109[0m[0m | time: 29.247s
[2K
| Adam | epoch: 005 | loss: 0.67109 - acc: 0.5866 -- iter: 1408/1980
[A[ATraining Step: 293  | total loss: [1m[32m0.67303[0m[0m | time: 29.929s
[2K
| Adam | epoch: 005 | loss: 0.67303 - acc: 0.5811 -- iter: 1440/1980
[A[ATraining Step: 294  | total loss: [1m[32m0.66989[0m[0m | time: 30.585s
[2K
| Adam | epoch: 005 | loss: 0.66989 - acc: 0.5855 -- iter: 1472/1980
[A[ATraining Step: 295  | total loss: [1m[32m0.66630[0m[0m | time: 31.208s
[2K
| Adam | epoch: 005 | loss: 0.66630 - acc: 0.5957 -- iter: 1504/1980
[A[ATraining Step: 296  | total loss: [1m[32m0.66654[0m[0m | time: 31.870s
[2K
| Adam | epoch: 005 | loss: 0.66654 - acc: 0.5892 -- iter: 1536/1980
[A[ATraining Step: 297  | total loss: [1m[32m0.67071[0m[0m | time: 32.547s
[2K
| Adam | epoch: 005 | loss: 0.67071 - acc: 0.5772 -- iter: 1568/1980
[A[ATraining Step: 298  | total loss: [1m[32m0.66996[0m[0m | time: 33.196s
[2K
| Adam | epoch: 005 | loss: 0.66996 - acc: 0.5820 -- iter: 1600/1980
[A[ATraining Step: 299  | total loss: [1m[32m0.67200[0m[0m | time: 33.884s
[2K
| Adam | epoch: 005 | loss: 0.67200 - acc: 0.5769 -- iter: 1632/1980
[A[ATraining Step: 300  | total loss: [1m[32m0.66886[0m[0m | time: 34.545s
[2K
| Adam | epoch: 005 | loss: 0.66886 - acc: 0.5817 -- iter: 1664/1980
[A[ATraining Step: 301  | total loss: [1m[32m0.66559[0m[0m | time: 35.220s
[2K
| Adam | epoch: 005 | loss: 0.66559 - acc: 0.5892 -- iter: 1696/1980
[A[ATraining Step: 302  | total loss: [1m[32m0.66509[0m[0m | time: 35.903s
[2K
| Adam | epoch: 005 | loss: 0.66509 - acc: 0.5896 -- iter: 1728/1980
[A[ATraining Step: 303  | total loss: [1m[32m0.66693[0m[0m | time: 36.598s
[2K
| Adam | epoch: 005 | loss: 0.66693 - acc: 0.5869 -- iter: 1760/1980
[A[ATraining Step: 304  | total loss: [1m[32m0.66370[0m[0m | time: 37.279s
[2K
| Adam | epoch: 005 | loss: 0.66370 - acc: 0.5938 -- iter: 1792/1980
[A[ATraining Step: 305  | total loss: [1m[32m0.65943[0m[0m | time: 37.953s
[2K
| Adam | epoch: 005 | loss: 0.65943 - acc: 0.6032 -- iter: 1824/1980
[A[ATraining Step: 306  | total loss: [1m[32m0.65948[0m[0m | time: 38.609s
[2K
| Adam | epoch: 005 | loss: 0.65948 - acc: 0.5991 -- iter: 1856/1980
[A[ATraining Step: 307  | total loss: [1m[32m0.65536[0m[0m | time: 39.300s
[2K
| Adam | epoch: 005 | loss: 0.65536 - acc: 0.6048 -- iter: 1888/1980
[A[ATraining Step: 308  | total loss: [1m[32m0.64964[0m[0m | time: 39.959s
[2K
| Adam | epoch: 005 | loss: 0.64964 - acc: 0.6162 -- iter: 1920/1980
[A[ATraining Step: 309  | total loss: [1m[32m0.65392[0m[0m | time: 40.656s
[2K
| Adam | epoch: 005 | loss: 0.65392 - acc: 0.6077 -- iter: 1952/1980
[A[ATraining Step: 310  | total loss: [1m[32m0.66352[0m[0m | time: 43.650s
[2K
| Adam | epoch: 005 | loss: 0.66352 - acc: 0.5907 | val_loss: 0.63410 - val_acc: 0.6381 -- iter: 1980/1980
--
Training Step: 311  | total loss: [1m[32m0.66460[0m[0m | time: 0.648s
[2K
| Adam | epoch: 006 | loss: 0.66460 - acc: 0.5910 -- iter: 0032/1980
[A[ATraining Step: 312  | total loss: [1m[32m0.67026[0m[0m | time: 1.290s
[2K
| Adam | epoch: 006 | loss: 0.67026 - acc: 0.5819 -- iter: 0064/1980
[A[ATraining Step: 313  | total loss: [1m[32m0.66686[0m[0m | time: 1.958s
[2K
| Adam | epoch: 006 | loss: 0.66686 - acc: 0.5831 -- iter: 0096/1980
[A[ATraining Step: 314  | total loss: [1m[32m0.66161[0m[0m | time: 2.563s
[2K
| Adam | epoch: 006 | loss: 0.66161 - acc: 0.5904 -- iter: 0128/1980
[A[ATraining Step: 315  | total loss: [1m[32m0.66035[0m[0m | time: 3.134s
[2K
| Adam | epoch: 006 | loss: 0.66035 - acc: 0.5921 -- iter: 0160/1980
[A[ATraining Step: 316  | total loss: [1m[32m0.65908[0m[0m | time: 3.820s
[2K
| Adam | epoch: 006 | loss: 0.65908 - acc: 0.5936 -- iter: 0192/1980
[A[ATraining Step: 317  | total loss: [1m[32m0.66188[0m[0m | time: 4.490s
[2K
| Adam | epoch: 006 | loss: 0.66188 - acc: 0.5874 -- iter: 0224/1980
[A[ATraining Step: 318  | total loss: [1m[32m0.66311[0m[0m | time: 5.157s
[2K
| Adam | epoch: 006 | loss: 0.66311 - acc: 0.5817 -- iter: 0256/1980
[A[ATraining Step: 319  | total loss: [1m[32m0.66347[0m[0m | time: 5.897s
[2K
| Adam | epoch: 006 | loss: 0.66347 - acc: 0.5767 -- iter: 0288/1980
[A[ATraining Step: 320  | total loss: [1m[32m0.66411[0m[0m | time: 6.572s
[2K
| Adam | epoch: 006 | loss: 0.66411 - acc: 0.5722 -- iter: 0320/1980
[A[ATraining Step: 321  | total loss: [1m[32m0.66644[0m[0m | time: 7.276s
[2K
| Adam | epoch: 006 | loss: 0.66644 - acc: 0.5712 -- iter: 0352/1980
[A[ATraining Step: 322  | total loss: [1m[32m0.66827[0m[0m | time: 7.911s
[2K
| Adam | epoch: 006 | loss: 0.66827 - acc: 0.5703 -- iter: 0384/1980
[A[ATraining Step: 323  | total loss: [1m[32m0.66894[0m[0m | time: 8.633s
[2K
| Adam | epoch: 006 | loss: 0.66894 - acc: 0.5727 -- iter: 0416/1980
[A[ATraining Step: 324  | total loss: [1m[32m0.66347[0m[0m | time: 9.300s
[2K
| Adam | epoch: 006 | loss: 0.66347 - acc: 0.6060 -- iter: 0448/1980
[A[ATraining Step: 325  | total loss: [1m[32m0.66494[0m[0m | time: 10.016s
[2K
| Adam | epoch: 006 | loss: 0.66494 - acc: 0.6048 -- iter: 0480/1980
[A[ATraining Step: 326  | total loss: [1m[32m0.66537[0m[0m | time: 10.687s
[2K
| Adam | epoch: 006 | loss: 0.66537 - acc: 0.6037 -- iter: 0512/1980
[A[ATraining Step: 327  | total loss: [1m[32m0.66406[0m[0m | time: 11.372s
[2K
| Adam | epoch: 006 | loss: 0.66406 - acc: 0.6089 -- iter: 0544/1980
[A[ATraining Step: 328  | total loss: [1m[32m0.66004[0m[0m | time: 12.021s
[2K
| Adam | epoch: 006 | loss: 0.66004 - acc: 0.6137 -- iter: 0576/1980
[A[ATraining Step: 329  | total loss: [1m[32m0.65737[0m[0m | time: 12.732s
[2K
| Adam | epoch: 006 | loss: 0.65737 - acc: 0.6273 -- iter: 0608/1980
[A[ATraining Step: 330  | total loss: [1m[32m0.65742[0m[0m | time: 13.350s
[2K
| Adam | epoch: 006 | loss: 0.65742 - acc: 0.6302 -- iter: 0640/1980
[A[ATraining Step: 331  | total loss: [1m[32m0.66667[0m[0m | time: 14.011s
[2K
| Adam | epoch: 006 | loss: 0.66667 - acc: 0.6109 -- iter: 0672/1980
[A[ATraining Step: 332  | total loss: [1m[32m0.66822[0m[0m | time: 14.727s
[2K
| Adam | epoch: 006 | loss: 0.66822 - acc: 0.6061 -- iter: 0704/1980
[A[ATraining Step: 333  | total loss: [1m[32m0.65701[0m[0m | time: 15.369s
[2K
| Adam | epoch: 006 | loss: 0.65701 - acc: 0.6205 -- iter: 0736/1980
[A[ATraining Step: 334  | total loss: [1m[32m0.65494[0m[0m | time: 16.083s
[2K
| Adam | epoch: 006 | loss: 0.65494 - acc: 0.6147 -- iter: 0768/1980
[A[ATraining Step: 335  | total loss: [1m[32m0.64939[0m[0m | time: 16.744s
[2K
| Adam | epoch: 006 | loss: 0.64939 - acc: 0.6220 -- iter: 0800/1980
[A[ATraining Step: 336  | total loss: [1m[32m0.64486[0m[0m | time: 17.435s
[2K
| Adam | epoch: 006 | loss: 0.64486 - acc: 0.6254 -- iter: 0832/1980
[A[ATraining Step: 337  | total loss: [1m[32m0.64830[0m[0m | time: 18.092s
[2K
| Adam | epoch: 006 | loss: 0.64830 - acc: 0.6254 -- iter: 0864/1980
[A[ATraining Step: 338  | total loss: [1m[32m0.65216[0m[0m | time: 18.784s
[2K
| Adam | epoch: 006 | loss: 0.65216 - acc: 0.6191 -- iter: 0896/1980
[A[ATraining Step: 339  | total loss: [1m[32m0.65129[0m[0m | time: 19.455s
[2K
| Adam | epoch: 006 | loss: 0.65129 - acc: 0.6197 -- iter: 0928/1980
[A[ATraining Step: 340  | total loss: [1m[32m0.64984[0m[0m | time: 20.114s
[2K
| Adam | epoch: 006 | loss: 0.64984 - acc: 0.6202 -- iter: 0960/1980
[A[ATraining Step: 341  | total loss: [1m[32m0.63922[0m[0m | time: 20.794s
[2K
| Adam | epoch: 006 | loss: 0.63922 - acc: 0.6363 -- iter: 0992/1980
[A[ATraining Step: 342  | total loss: [1m[32m0.64029[0m[0m | time: 21.508s
[2K
| Adam | epoch: 006 | loss: 0.64029 - acc: 0.6445 -- iter: 1024/1980
[A[ATraining Step: 343  | total loss: [1m[32m0.63923[0m[0m | time: 22.203s
[2K
| Adam | epoch: 006 | loss: 0.63923 - acc: 0.6520 -- iter: 1056/1980
[A[ATraining Step: 344  | total loss: [1m[32m0.64257[0m[0m | time: 22.876s
[2K
| Adam | epoch: 006 | loss: 0.64257 - acc: 0.6461 -- iter: 1088/1980
[A[ATraining Step: 345  | total loss: [1m[32m0.63980[0m[0m | time: 23.590s
[2K
| Adam | epoch: 006 | loss: 0.63980 - acc: 0.6472 -- iter: 1120/1980
[A[ATraining Step: 346  | total loss: [1m[32m0.63747[0m[0m | time: 24.263s
[2K
| Adam | epoch: 006 | loss: 0.63747 - acc: 0.6543 -- iter: 1152/1980
[A[ATraining Step: 347  | total loss: [1m[32m0.63966[0m[0m | time: 24.919s
[2K
| Adam | epoch: 006 | loss: 0.63966 - acc: 0.6483 -- iter: 1184/1980
[A[ATraining Step: 348  | total loss: [1m[32m0.63641[0m[0m | time: 25.575s
[2K
| Adam | epoch: 006 | loss: 0.63641 - acc: 0.6553 -- iter: 1216/1980
[A[ATraining Step: 349  | total loss: [1m[32m0.63698[0m[0m | time: 26.238s
[2K
| Adam | epoch: 006 | loss: 0.63698 - acc: 0.6492 -- iter: 1248/1980
[A[ATraining Step: 350  | total loss: [1m[32m0.63381[0m[0m | time: 26.955s
[2K
| Adam | epoch: 006 | loss: 0.63381 - acc: 0.6530 -- iter: 1280/1980
[A[ATraining Step: 351  | total loss: [1m[32m0.63816[0m[0m | time: 27.629s
[2K
| Adam | epoch: 006 | loss: 0.63816 - acc: 0.6502 -- iter: 1312/1980
[A[ATraining Step: 352  | total loss: [1m[32m0.63528[0m[0m | time: 28.296s
[2K
| Adam | epoch: 006 | loss: 0.63528 - acc: 0.6508 -- iter: 1344/1980
[A[ATraining Step: 353  | total loss: [1m[32m0.65038[0m[0m | time: 28.967s
[2K
| Adam | epoch: 006 | loss: 0.65038 - acc: 0.6201 -- iter: 1376/1980
[A[ATraining Step: 354  | total loss: [1m[32m0.65546[0m[0m | time: 29.677s
[2K
| Adam | epoch: 006 | loss: 0.65546 - acc: 0.6206 -- iter: 1408/1980
[A[ATraining Step: 355  | total loss: [1m[32m0.64971[0m[0m | time: 30.344s
[2K
| Adam | epoch: 006 | loss: 0.64971 - acc: 0.6304 -- iter: 1440/1980
[A[ATraining Step: 356  | total loss: [1m[32m0.64436[0m[0m | time: 31.020s
[2K
| Adam | epoch: 006 | loss: 0.64436 - acc: 0.6424 -- iter: 1472/1980
[A[ATraining Step: 357  | total loss: [1m[32m0.64992[0m[0m | time: 31.712s
[2K
| Adam | epoch: 006 | loss: 0.64992 - acc: 0.6281 -- iter: 1504/1980
[A[ATraining Step: 358  | total loss: [1m[32m0.63095[0m[0m | time: 32.388s
[2K
| Adam | epoch: 006 | loss: 0.63095 - acc: 0.6528 -- iter: 1536/1980
[A[ATraining Step: 359  | total loss: [1m[32m0.62498[0m[0m | time: 33.031s
[2K
| Adam | epoch: 006 | loss: 0.62498 - acc: 0.6563 -- iter: 1568/1980
[A[ATraining Step: 360  | total loss: [1m[32m0.63585[0m[0m | time: 33.693s
[2K
| Adam | epoch: 006 | loss: 0.63585 - acc: 0.6407 -- iter: 1600/1980
[A[ATraining Step: 361  | total loss: [1m[32m0.63472[0m[0m | time: 34.370s
[2K
| Adam | epoch: 006 | loss: 0.63472 - acc: 0.6453 -- iter: 1632/1980
[A[ATraining Step: 362  | total loss: [1m[32m0.62426[0m[0m | time: 35.052s
[2K
| Adam | epoch: 006 | loss: 0.62426 - acc: 0.6527 -- iter: 1664/1980
[A[ATraining Step: 363  | total loss: [1m[32m0.61485[0m[0m | time: 35.716s
[2K
| Adam | epoch: 006 | loss: 0.61485 - acc: 0.6624 -- iter: 1696/1980
[A[ATraining Step: 364  | total loss: [1m[32m0.61833[0m[0m | time: 36.375s
[2K
| Adam | epoch: 006 | loss: 0.61833 - acc: 0.6618 -- iter: 1728/1980
[A[ATraining Step: 365  | total loss: [1m[32m0.61670[0m[0m | time: 37.022s
[2K
| Adam | epoch: 006 | loss: 0.61670 - acc: 0.6675 -- iter: 1760/1980
[A[ATraining Step: 366  | total loss: [1m[32m0.61288[0m[0m | time: 37.670s
[2K
| Adam | epoch: 006 | loss: 0.61288 - acc: 0.6789 -- iter: 1792/1980
[A[ATraining Step: 367  | total loss: [1m[32m0.60983[0m[0m | time: 38.321s
[2K
| Adam | epoch: 006 | loss: 0.60983 - acc: 0.6860 -- iter: 1824/1980
[A[ATraining Step: 368  | total loss: [1m[32m0.60882[0m[0m | time: 38.970s
[2K
| Adam | epoch: 006 | loss: 0.60882 - acc: 0.6799 -- iter: 1856/1980
[A[ATraining Step: 369  | total loss: [1m[32m0.59421[0m[0m | time: 39.624s
[2K
| Adam | epoch: 006 | loss: 0.59421 - acc: 0.6900 -- iter: 1888/1980
[A[ATraining Step: 370  | total loss: [1m[32m0.61701[0m[0m | time: 40.272s
[2K
| Adam | epoch: 006 | loss: 0.61701 - acc: 0.6648 -- iter: 1920/1980
[A[ATraining Step: 371  | total loss: [1m[32m0.61819[0m[0m | time: 40.948s
[2K
| Adam | epoch: 006 | loss: 0.61819 - acc: 0.6608 -- iter: 1952/1980
[A[ATraining Step: 372  | total loss: [1m[32m0.63772[0m[0m | time: 43.920s
[2K
| Adam | epoch: 006 | loss: 0.63772 - acc: 0.6478 | val_loss: 0.61520 - val_acc: 0.6575 -- iter: 1980/1980
--
Training Step: 373  | total loss: [1m[32m0.63577[0m[0m | time: 0.672s
[2K
| Adam | epoch: 007 | loss: 0.63577 - acc: 0.6518 -- iter: 0032/1980
[A[ATraining Step: 374  | total loss: [1m[32m0.63542[0m[0m | time: 1.347s
[2K
| Adam | epoch: 007 | loss: 0.63542 - acc: 0.6522 -- iter: 0064/1980
[A[ATraining Step: 375  | total loss: [1m[32m0.62596[0m[0m | time: 2.041s
[2K
| Adam | epoch: 007 | loss: 0.62596 - acc: 0.6620 -- iter: 0096/1980
[A[ATraining Step: 376  | total loss: [1m[32m0.62290[0m[0m | time: 2.720s
[2K
| Adam | epoch: 007 | loss: 0.62290 - acc: 0.6677 -- iter: 0128/1980
[A[ATraining Step: 377  | total loss: [1m[32m0.62530[0m[0m | time: 3.341s
[2K
| Adam | epoch: 007 | loss: 0.62530 - acc: 0.6603 -- iter: 0160/1980
[A[ATraining Step: 378  | total loss: [1m[32m0.63866[0m[0m | time: 3.937s
[2K
| Adam | epoch: 007 | loss: 0.63866 - acc: 0.6407 -- iter: 0192/1980
[A[ATraining Step: 379  | total loss: [1m[32m0.64722[0m[0m | time: 4.574s
[2K
| Adam | epoch: 007 | loss: 0.64722 - acc: 0.6195 -- iter: 0224/1980
[A[ATraining Step: 380  | total loss: [1m[32m0.64961[0m[0m | time: 5.221s
[2K
| Adam | epoch: 007 | loss: 0.64961 - acc: 0.6107 -- iter: 0256/1980
[A[ATraining Step: 381  | total loss: [1m[32m0.64340[0m[0m | time: 5.902s
[2K
| Adam | epoch: 007 | loss: 0.64340 - acc: 0.6152 -- iter: 0288/1980
[A[ATraining Step: 382  | total loss: [1m[32m0.64202[0m[0m | time: 6.525s
[2K
| Adam | epoch: 007 | loss: 0.64202 - acc: 0.6256 -- iter: 0320/1980
[A[ATraining Step: 383  | total loss: [1m[32m0.64276[0m[0m | time: 7.146s
[2K
| Adam | epoch: 007 | loss: 0.64276 - acc: 0.6349 -- iter: 0352/1980
[A[ATraining Step: 384  | total loss: [1m[32m0.64643[0m[0m | time: 7.789s
[2K
| Adam | epoch: 007 | loss: 0.64643 - acc: 0.6339 -- iter: 0384/1980
[A[ATraining Step: 385  | total loss: [1m[32m0.64908[0m[0m | time: 8.490s
[2K
| Adam | epoch: 007 | loss: 0.64908 - acc: 0.6299 -- iter: 0416/1980
[A[ATraining Step: 386  | total loss: [1m[32m0.64471[0m[0m | time: 9.199s
[2K
| Adam | epoch: 007 | loss: 0.64471 - acc: 0.6356 -- iter: 0448/1980
[A[ATraining Step: 387  | total loss: [1m[32m0.63804[0m[0m | time: 9.838s
[2K
| Adam | epoch: 007 | loss: 0.63804 - acc: 0.6471 -- iter: 0480/1980
[A[ATraining Step: 388  | total loss: [1m[32m0.63995[0m[0m | time: 10.563s
[2K
| Adam | epoch: 007 | loss: 0.63995 - acc: 0.6480 -- iter: 0512/1980
[A[ATraining Step: 389  | total loss: [1m[32m0.63829[0m[0m | time: 11.218s
[2K
| Adam | epoch: 007 | loss: 0.63829 - acc: 0.6520 -- iter: 0544/1980
[A[ATraining Step: 390  | total loss: [1m[32m0.64733[0m[0m | time: 11.877s
[2K
| Adam | epoch: 007 | loss: 0.64733 - acc: 0.6336 -- iter: 0576/1980
[A[ATraining Step: 391  | total loss: [1m[32m0.64026[0m[0m | time: 12.510s
[2K
| Adam | epoch: 007 | loss: 0.64026 - acc: 0.6515 -- iter: 0608/1980
[A[ATraining Step: 392  | total loss: [1m[32m0.62948[0m[0m | time: 13.207s
[2K
| Adam | epoch: 007 | loss: 0.62948 - acc: 0.6645 -- iter: 0640/1980
[A[ATraining Step: 393  | total loss: [1m[32m0.62374[0m[0m | time: 13.850s
[2K
| Adam | epoch: 007 | loss: 0.62374 - acc: 0.6762 -- iter: 0672/1980
[A[ATraining Step: 394  | total loss: [1m[32m0.62072[0m[0m | time: 14.548s
[2K
| Adam | epoch: 007 | loss: 0.62072 - acc: 0.6804 -- iter: 0704/1980
[A[ATraining Step: 395  | total loss: [1m[32m0.62239[0m[0m | time: 15.195s
[2K
| Adam | epoch: 007 | loss: 0.62239 - acc: 0.6718 -- iter: 0736/1980
[A[ATraining Step: 396  | total loss: [1m[32m0.63131[0m[0m | time: 15.853s
[2K
| Adam | epoch: 007 | loss: 0.63131 - acc: 0.6577 -- iter: 0768/1980
[A[ATraining Step: 397  | total loss: [1m[32m0.64084[0m[0m | time: 16.551s
[2K
| Adam | epoch: 007 | loss: 0.64084 - acc: 0.6482 -- iter: 0800/1980
[A[ATraining Step: 398  | total loss: [1m[32m0.63584[0m[0m | time: 17.205s
[2K
| Adam | epoch: 007 | loss: 0.63584 - acc: 0.6521 -- iter: 0832/1980
[A[ATraining Step: 399  | total loss: [1m[32m0.62075[0m[0m | time: 17.896s
[2K
| Adam | epoch: 007 | loss: 0.62075 - acc: 0.6650 -- iter: 0864/1980
[A[ATraining Step: 400  | total loss: [1m[32m0.62804[0m[0m | time: 20.958s
[2K
| Adam | epoch: 007 | loss: 0.62804 - acc: 0.6548 | val_loss: 0.59954 - val_acc: 0.7011 -- iter: 0896/1980
--
Training Step: 401  | total loss: [1m[32m0.62251[0m[0m | time: 21.605s
[2K
| Adam | epoch: 007 | loss: 0.62251 - acc: 0.6643 -- iter: 0928/1980
[A[ATraining Step: 402  | total loss: [1m[32m0.62637[0m[0m | time: 22.315s
[2K
| Adam | epoch: 007 | loss: 0.62637 - acc: 0.6635 -- iter: 0960/1980
[A[ATraining Step: 403  | total loss: [1m[32m0.63160[0m[0m | time: 22.968s
[2K
| Adam | epoch: 007 | loss: 0.63160 - acc: 0.6534 -- iter: 0992/1980
[A[ATraining Step: 404  | total loss: [1m[32m0.63512[0m[0m | time: 23.583s
[2K
| Adam | epoch: 007 | loss: 0.63512 - acc: 0.6474 -- iter: 1024/1980
[A[ATraining Step: 405  | total loss: [1m[32m0.62973[0m[0m | time: 24.241s
[2K
| Adam | epoch: 007 | loss: 0.62973 - acc: 0.6577 -- iter: 1056/1980
[A[ATraining Step: 406  | total loss: [1m[32m0.63818[0m[0m | time: 24.944s
[2K
| Adam | epoch: 007 | loss: 0.63818 - acc: 0.6482 -- iter: 1088/1980
[A[ATraining Step: 407  | total loss: [1m[32m0.64403[0m[0m | time: 25.583s
[2K
| Adam | epoch: 007 | loss: 0.64403 - acc: 0.6396 -- iter: 1120/1980
[A[ATraining Step: 408  | total loss: [1m[32m0.64357[0m[0m | time: 26.237s
[2K
| Adam | epoch: 007 | loss: 0.64357 - acc: 0.6381 -- iter: 1152/1980
[A[ATraining Step: 409  | total loss: [1m[32m0.64589[0m[0m | time: 26.860s
[2K
| Adam | epoch: 007 | loss: 0.64589 - acc: 0.6306 -- iter: 1184/1980
[A[ATraining Step: 410  | total loss: [1m[32m0.64879[0m[0m | time: 27.502s
[2K
| Adam | epoch: 007 | loss: 0.64879 - acc: 0.6300 -- iter: 1216/1980
[A[ATraining Step: 411  | total loss: [1m[32m0.64222[0m[0m | time: 28.135s
[2K
| Adam | epoch: 007 | loss: 0.64222 - acc: 0.6389 -- iter: 1248/1980
[A[ATraining Step: 412  | total loss: [1m[32m0.63041[0m[0m | time: 28.869s
[2K
| Adam | epoch: 007 | loss: 0.63041 - acc: 0.6594 -- iter: 1280/1980
[A[ATraining Step: 413  | total loss: [1m[32m0.62225[0m[0m | time: 29.482s
[2K
| Adam | epoch: 007 | loss: 0.62225 - acc: 0.6716 -- iter: 1312/1980
[A[ATraining Step: 414  | total loss: [1m[32m0.61307[0m[0m | time: 30.106s
[2K
| Adam | epoch: 007 | loss: 0.61307 - acc: 0.6857 -- iter: 1344/1980
[A[ATraining Step: 415  | total loss: [1m[32m0.61537[0m[0m | time: 30.821s
[2K
| Adam | epoch: 007 | loss: 0.61537 - acc: 0.6858 -- iter: 1376/1980
[A[ATraining Step: 416  | total loss: [1m[32m0.61694[0m[0m | time: 31.511s
[2K
| Adam | epoch: 007 | loss: 0.61694 - acc: 0.6891 -- iter: 1408/1980
[A[ATraining Step: 417  | total loss: [1m[32m0.61323[0m[0m | time: 32.170s
[2K
| Adam | epoch: 007 | loss: 0.61323 - acc: 0.6921 -- iter: 1440/1980
[A[ATraining Step: 418  | total loss: [1m[32m0.61798[0m[0m | time: 32.846s
[2K
| Adam | epoch: 007 | loss: 0.61798 - acc: 0.6823 -- iter: 1472/1980
[A[ATraining Step: 419  | total loss: [1m[32m0.63145[0m[0m | time: 33.499s
[2K
| Adam | epoch: 007 | loss: 0.63145 - acc: 0.6609 -- iter: 1504/1980
[A[ATraining Step: 420  | total loss: [1m[32m0.63384[0m[0m | time: 34.151s
[2K
| Adam | epoch: 007 | loss: 0.63384 - acc: 0.6573 -- iter: 1536/1980
[A[ATraining Step: 421  | total loss: [1m[32m0.63061[0m[0m | time: 34.801s
[2K
| Adam | epoch: 007 | loss: 0.63061 - acc: 0.6603 -- iter: 1568/1980
[A[ATraining Step: 422  | total loss: [1m[32m0.62830[0m[0m | time: 35.468s
[2K
| Adam | epoch: 007 | loss: 0.62830 - acc: 0.6599 -- iter: 1600/1980
[A[ATraining Step: 423  | total loss: [1m[32m0.62502[0m[0m | time: 36.150s
[2K
| Adam | epoch: 007 | loss: 0.62502 - acc: 0.6627 -- iter: 1632/1980
[A[ATraining Step: 424  | total loss: [1m[32m0.63698[0m[0m | time: 36.827s
[2K
| Adam | epoch: 007 | loss: 0.63698 - acc: 0.6495 -- iter: 1664/1980
[A[ATraining Step: 425  | total loss: [1m[32m0.62848[0m[0m | time: 37.500s
[2K
| Adam | epoch: 007 | loss: 0.62848 - acc: 0.6627 -- iter: 1696/1980
[A[ATraining Step: 426  | total loss: [1m[32m0.62722[0m[0m | time: 38.185s
[2K
| Adam | epoch: 007 | loss: 0.62722 - acc: 0.6652 -- iter: 1728/1980
[A[ATraining Step: 427  | total loss: [1m[32m0.61945[0m[0m | time: 38.886s
[2K
| Adam | epoch: 007 | loss: 0.61945 - acc: 0.6768 -- iter: 1760/1980
[A[ATraining Step: 428  | total loss: [1m[32m0.62107[0m[0m | time: 39.515s
[2K
| Adam | epoch: 007 | loss: 0.62107 - acc: 0.6716 -- iter: 1792/1980
[A[ATraining Step: 429  | total loss: [1m[32m0.62414[0m[0m | time: 40.172s
[2K
| Adam | epoch: 007 | loss: 0.62414 - acc: 0.6732 -- iter: 1824/1980
[A[ATraining Step: 430  | total loss: [1m[32m0.62044[0m[0m | time: 40.800s
[2K
| Adam | epoch: 007 | loss: 0.62044 - acc: 0.6778 -- iter: 1856/1980
[A[ATraining Step: 431  | total loss: [1m[32m0.61931[0m[0m | time: 41.478s
[2K
| Adam | epoch: 007 | loss: 0.61931 - acc: 0.6787 -- iter: 1888/1980
[A[ATraining Step: 432  | total loss: [1m[32m0.61773[0m[0m | time: 42.107s
[2K
| Adam | epoch: 007 | loss: 0.61773 - acc: 0.6734 -- iter: 1920/1980
[A[ATraining Step: 433  | total loss: [1m[32m0.61515[0m[0m | time: 42.748s
[2K
| Adam | epoch: 007 | loss: 0.61515 - acc: 0.6748 -- iter: 1952/1980
[A[ATraining Step: 434  | total loss: [1m[32m0.61347[0m[0m | time: 45.621s
[2K
| Adam | epoch: 007 | loss: 0.61347 - acc: 0.6792 | val_loss: 0.60615 - val_acc: 0.6931 -- iter: 1980/1980
--
Training Step: 435  | total loss: [1m[32m0.60746[0m[0m | time: 0.676s
[2K
| Adam | epoch: 008 | loss: 0.60746 - acc: 0.6863 -- iter: 0032/1980
[A[ATraining Step: 436  | total loss: [1m[32m0.60522[0m[0m | time: 1.353s
[2K
| Adam | epoch: 008 | loss: 0.60522 - acc: 0.6895 -- iter: 0064/1980
[A[ATraining Step: 437  | total loss: [1m[32m0.60263[0m[0m | time: 1.994s
[2K
| Adam | epoch: 008 | loss: 0.60263 - acc: 0.6862 -- iter: 0096/1980
[A[ATraining Step: 438  | total loss: [1m[32m0.59768[0m[0m | time: 2.675s
[2K
| Adam | epoch: 008 | loss: 0.59768 - acc: 0.6863 -- iter: 0128/1980
[A[ATraining Step: 439  | total loss: [1m[32m0.59550[0m[0m | time: 3.334s
[2K
| Adam | epoch: 008 | loss: 0.59550 - acc: 0.6802 -- iter: 0160/1980
[A[ATraining Step: 440  | total loss: [1m[32m0.59648[0m[0m | time: 3.897s
[2K
| Adam | epoch: 008 | loss: 0.59648 - acc: 0.6747 -- iter: 0192/1980
[A[ATraining Step: 441  | total loss: [1m[32m0.59885[0m[0m | time: 4.437s
[2K
| Adam | epoch: 008 | loss: 0.59885 - acc: 0.6786 -- iter: 0224/1980
[A[ATraining Step: 442  | total loss: [1m[32m0.60038[0m[0m | time: 5.063s
[2K
| Adam | epoch: 008 | loss: 0.60038 - acc: 0.6822 -- iter: 0256/1980
[A[ATraining Step: 443  | total loss: [1m[32m0.59715[0m[0m | time: 5.750s
[2K
| Adam | epoch: 008 | loss: 0.59715 - acc: 0.6921 -- iter: 0288/1980
[A[ATraining Step: 444  | total loss: [1m[32m0.59251[0m[0m | time: 6.428s
[2K
| Adam | epoch: 008 | loss: 0.59251 - acc: 0.6948 -- iter: 0320/1980
[A[ATraining Step: 445  | total loss: [1m[32m0.58616[0m[0m | time: 7.056s
[2K
| Adam | epoch: 008 | loss: 0.58616 - acc: 0.6972 -- iter: 0352/1980
[A[ATraining Step: 446  | total loss: [1m[32m0.59711[0m[0m | time: 7.719s
[2K
| Adam | epoch: 008 | loss: 0.59711 - acc: 0.6931 -- iter: 0384/1980
[A[ATraining Step: 447  | total loss: [1m[32m0.58552[0m[0m | time: 8.383s
[2K
| Adam | epoch: 008 | loss: 0.58552 - acc: 0.7019 -- iter: 0416/1980
[A[ATraining Step: 448  | total loss: [1m[32m0.59781[0m[0m | time: 9.038s
[2K
| Adam | epoch: 008 | loss: 0.59781 - acc: 0.6879 -- iter: 0448/1980
[A[ATraining Step: 449  | total loss: [1m[32m0.60745[0m[0m | time: 9.662s
[2K
| Adam | epoch: 008 | loss: 0.60745 - acc: 0.6879 -- iter: 0480/1980
[A[ATraining Step: 450  | total loss: [1m[32m0.60608[0m[0m | time: 10.277s
[2K
| Adam | epoch: 008 | loss: 0.60608 - acc: 0.6816 -- iter: 0512/1980
[A[ATraining Step: 451  | total loss: [1m[32m0.59741[0m[0m | time: 10.946s
[2K
| Adam | epoch: 008 | loss: 0.59741 - acc: 0.6853 -- iter: 0544/1980
[A[ATraining Step: 452  | total loss: [1m[32m0.60310[0m[0m | time: 11.649s
[2K
| Adam | epoch: 008 | loss: 0.60310 - acc: 0.6824 -- iter: 0576/1980
[A[ATraining Step: 453  | total loss: [1m[32m0.60040[0m[0m | time: 12.299s
[2K
| Adam | epoch: 008 | loss: 0.60040 - acc: 0.6892 -- iter: 0608/1980
[A[ATraining Step: 454  | total loss: [1m[32m0.59991[0m[0m | time: 13.017s
[2K
| Adam | epoch: 008 | loss: 0.59991 - acc: 0.6796 -- iter: 0640/1980
[A[ATraining Step: 455  | total loss: [1m[32m0.60220[0m[0m | time: 13.632s
[2K
| Adam | epoch: 008 | loss: 0.60220 - acc: 0.6804 -- iter: 0672/1980
[A[ATraining Step: 456  | total loss: [1m[32m0.61259[0m[0m | time: 14.306s
[2K
| Adam | epoch: 008 | loss: 0.61259 - acc: 0.6718 -- iter: 0704/1980
[A[ATraining Step: 457  | total loss: [1m[32m0.61098[0m[0m | time: 14.965s
[2K
| Adam | epoch: 008 | loss: 0.61098 - acc: 0.6733 -- iter: 0736/1980
[A[ATraining Step: 458  | total loss: [1m[32m0.60226[0m[0m | time: 15.644s
[2K
| Adam | epoch: 008 | loss: 0.60226 - acc: 0.6779 -- iter: 0768/1980
[A[ATraining Step: 459  | total loss: [1m[32m0.61041[0m[0m | time: 16.294s
[2K
| Adam | epoch: 008 | loss: 0.61041 - acc: 0.6695 -- iter: 0800/1980
[A[ATraining Step: 460  | total loss: [1m[32m0.62592[0m[0m | time: 16.957s
[2K
| Adam | epoch: 008 | loss: 0.62592 - acc: 0.6556 -- iter: 0832/1980
[A[ATraining Step: 461  | total loss: [1m[32m0.62172[0m[0m | time: 17.694s
[2K
| Adam | epoch: 008 | loss: 0.62172 - acc: 0.6619 -- iter: 0864/1980
[A[ATraining Step: 462  | total loss: [1m[32m0.61372[0m[0m | time: 18.372s
[2K
| Adam | epoch: 008 | loss: 0.61372 - acc: 0.6739 -- iter: 0896/1980
[A[ATraining Step: 463  | total loss: [1m[32m0.61426[0m[0m | time: 19.044s
[2K
| Adam | epoch: 008 | loss: 0.61426 - acc: 0.6690 -- iter: 0928/1980
[A[ATraining Step: 464  | total loss: [1m[32m0.60665[0m[0m | time: 19.712s
[2K
| Adam | epoch: 008 | loss: 0.60665 - acc: 0.6740 -- iter: 0960/1980
[A[ATraining Step: 465  | total loss: [1m[32m0.59753[0m[0m | time: 20.369s
[2K
| Adam | epoch: 008 | loss: 0.59753 - acc: 0.6878 -- iter: 0992/1980
[A[ATraining Step: 466  | total loss: [1m[32m0.59009[0m[0m | time: 21.042s
[2K
| Adam | epoch: 008 | loss: 0.59009 - acc: 0.6940 -- iter: 1024/1980
[A[ATraining Step: 467  | total loss: [1m[32m0.58874[0m[0m | time: 21.705s
[2K
| Adam | epoch: 008 | loss: 0.58874 - acc: 0.6934 -- iter: 1056/1980
[A[ATraining Step: 468  | total loss: [1m[32m0.58426[0m[0m | time: 22.374s
[2K
| Adam | epoch: 008 | loss: 0.58426 - acc: 0.6990 -- iter: 1088/1980
[A[ATraining Step: 469  | total loss: [1m[32m0.58302[0m[0m | time: 23.091s
[2K
| Adam | epoch: 008 | loss: 0.58302 - acc: 0.7041 -- iter: 1120/1980
[A[ATraining Step: 470  | total loss: [1m[32m0.59258[0m[0m | time: 23.721s
[2K
| Adam | epoch: 008 | loss: 0.59258 - acc: 0.7025 -- iter: 1152/1980
[A[ATraining Step: 471  | total loss: [1m[32m0.59403[0m[0m | time: 24.368s
[2K
| Adam | epoch: 008 | loss: 0.59403 - acc: 0.6979 -- iter: 1184/1980
[A[ATraining Step: 472  | total loss: [1m[32m0.59517[0m[0m | time: 25.005s
[2K
| Adam | epoch: 008 | loss: 0.59517 - acc: 0.6906 -- iter: 1216/1980
[A[ATraining Step: 473  | total loss: [1m[32m0.59156[0m[0m | time: 25.708s
[2K
| Adam | epoch: 008 | loss: 0.59156 - acc: 0.6903 -- iter: 1248/1980
[A[ATraining Step: 474  | total loss: [1m[32m0.59070[0m[0m | time: 26.341s
[2K
| Adam | epoch: 008 | loss: 0.59070 - acc: 0.6962 -- iter: 1280/1980
[A[ATraining Step: 475  | total loss: [1m[32m0.59601[0m[0m | time: 27.038s
[2K
| Adam | epoch: 008 | loss: 0.59601 - acc: 0.6922 -- iter: 1312/1980
[A[ATraining Step: 476  | total loss: [1m[32m0.59085[0m[0m | time: 27.712s
[2K
| Adam | epoch: 008 | loss: 0.59085 - acc: 0.6980 -- iter: 1344/1980
[A[ATraining Step: 477  | total loss: [1m[32m0.59034[0m[0m | time: 28.383s
[2K
| Adam | epoch: 008 | loss: 0.59034 - acc: 0.7001 -- iter: 1376/1980
[A[ATraining Step: 478  | total loss: [1m[32m0.58619[0m[0m | time: 29.044s
[2K
| Adam | epoch: 008 | loss: 0.58619 - acc: 0.6988 -- iter: 1408/1980
[A[ATraining Step: 479  | total loss: [1m[32m0.58306[0m[0m | time: 29.669s
[2K
| Adam | epoch: 008 | loss: 0.58306 - acc: 0.6977 -- iter: 1440/1980
[A[ATraining Step: 480  | total loss: [1m[32m0.58656[0m[0m | time: 30.334s
[2K
| Adam | epoch: 008 | loss: 0.58656 - acc: 0.6811 -- iter: 1472/1980
[A[ATraining Step: 481  | total loss: [1m[32m0.57777[0m[0m | time: 31.026s
[2K
| Adam | epoch: 008 | loss: 0.57777 - acc: 0.6942 -- iter: 1504/1980
[A[ATraining Step: 482  | total loss: [1m[32m0.56933[0m[0m | time: 31.678s
[2K
| Adam | epoch: 008 | loss: 0.56933 - acc: 0.7029 -- iter: 1536/1980
[A[ATraining Step: 483  | total loss: [1m[32m0.58206[0m[0m | time: 32.395s
[2K
| Adam | epoch: 008 | loss: 0.58206 - acc: 0.6982 -- iter: 1568/1980
[A[ATraining Step: 484  | total loss: [1m[32m0.58059[0m[0m | time: 33.084s
[2K
| Adam | epoch: 008 | loss: 0.58059 - acc: 0.6972 -- iter: 1600/1980
[A[ATraining Step: 485  | total loss: [1m[32m0.58662[0m[0m | time: 33.742s
[2K
| Adam | epoch: 008 | loss: 0.58662 - acc: 0.6837 -- iter: 1632/1980
[A[ATraining Step: 486  | total loss: [1m[32m0.59102[0m[0m | time: 34.429s
[2K
| Adam | epoch: 008 | loss: 0.59102 - acc: 0.6747 -- iter: 1664/1980
[A[ATraining Step: 487  | total loss: [1m[32m0.58717[0m[0m | time: 35.092s
[2K
| Adam | epoch: 008 | loss: 0.58717 - acc: 0.6791 -- iter: 1696/1980
[A[ATraining Step: 488  | total loss: [1m[32m0.58435[0m[0m | time: 35.724s
[2K
| Adam | epoch: 008 | loss: 0.58435 - acc: 0.6862 -- iter: 1728/1980
[A[ATraining Step: 489  | total loss: [1m[32m0.59749[0m[0m | time: 36.371s
[2K
| Adam | epoch: 008 | loss: 0.59749 - acc: 0.6707 -- iter: 1760/1980
[A[ATraining Step: 490  | total loss: [1m[32m0.58490[0m[0m | time: 37.010s
[2K
| Adam | epoch: 008 | loss: 0.58490 - acc: 0.6786 -- iter: 1792/1980
[A[ATraining Step: 491  | total loss: [1m[32m0.58089[0m[0m | time: 37.618s
[2K
| Adam | epoch: 008 | loss: 0.58089 - acc: 0.6858 -- iter: 1824/1980
[A[ATraining Step: 492  | total loss: [1m[32m0.57259[0m[0m | time: 38.255s
[2K
| Adam | epoch: 008 | loss: 0.57259 - acc: 0.6984 -- iter: 1856/1980
[A[ATraining Step: 493  | total loss: [1m[32m0.56623[0m[0m | time: 38.909s
[2K
| Adam | epoch: 008 | loss: 0.56623 - acc: 0.7098 -- iter: 1888/1980
[A[ATraining Step: 494  | total loss: [1m[32m0.56970[0m[0m | time: 39.541s
[2K
| Adam | epoch: 008 | loss: 0.56970 - acc: 0.7076 -- iter: 1920/1980
[A[ATraining Step: 495  | total loss: [1m[32m0.58329[0m[0m | time: 40.175s
[2K
| Adam | epoch: 008 | loss: 0.58329 - acc: 0.6931 -- iter: 1952/1980
[A[ATraining Step: 496  | total loss: [1m[32m0.58323[0m[0m | time: 43.049s
[2K
| Adam | epoch: 008 | loss: 0.58323 - acc: 0.6957 | val_loss: 0.57724 - val_acc: 0.7060 -- iter: 1980/1980
--
Training Step: 497  | total loss: [1m[32m0.59303[0m[0m | time: 0.652s
[2K
| Adam | epoch: 009 | loss: 0.59303 - acc: 0.6855 -- iter: 0032/1980
[A[ATraining Step: 498  | total loss: [1m[32m0.58550[0m[0m | time: 1.302s
[2K
| Adam | epoch: 009 | loss: 0.58550 - acc: 0.6888 -- iter: 0064/1980
[A[ATraining Step: 499  | total loss: [1m[32m0.58010[0m[0m | time: 2.017s
[2K
| Adam | epoch: 009 | loss: 0.58010 - acc: 0.6980 -- iter: 0096/1980
[A[ATraining Step: 500  | total loss: [1m[32m0.59050[0m[0m | time: 2.645s
[2K
| Adam | epoch: 009 | loss: 0.59050 - acc: 0.6907 -- iter: 0128/1980
[A[ATraining Step: 501  | total loss: [1m[32m0.58436[0m[0m | time: 3.293s
[2K
| Adam | epoch: 009 | loss: 0.58436 - acc: 0.6967 -- iter: 0160/1980
[A[ATraining Step: 502  | total loss: [1m[32m0.57671[0m[0m | time: 3.951s
[2K
| Adam | epoch: 009 | loss: 0.57671 - acc: 0.7051 -- iter: 0192/1980
[A[ATraining Step: 503  | total loss: [1m[32m0.57718[0m[0m | time: 4.548s
[2K
| Adam | epoch: 009 | loss: 0.57718 - acc: 0.7034 -- iter: 0224/1980
[A[ATraining Step: 504  | total loss: [1m[32m0.58269[0m[0m | time: 5.121s
[2K
| Adam | epoch: 009 | loss: 0.58269 - acc: 0.6973 -- iter: 0256/1980
[A[ATraining Step: 505  | total loss: [1m[32m0.58828[0m[0m | time: 5.773s
[2K
| Adam | epoch: 009 | loss: 0.58828 - acc: 0.6954 -- iter: 0288/1980
[A[ATraining Step: 506  | total loss: [1m[32m0.58143[0m[0m | time: 6.450s
[2K
| Adam | epoch: 009 | loss: 0.58143 - acc: 0.7009 -- iter: 0320/1980
[A[ATraining Step: 507  | total loss: [1m[32m0.58645[0m[0m | time: 7.141s
[2K
| Adam | epoch: 009 | loss: 0.58645 - acc: 0.6996 -- iter: 0352/1980
[A[ATraining Step: 508  | total loss: [1m[32m0.58531[0m[0m | time: 7.818s
[2K
| Adam | epoch: 009 | loss: 0.58531 - acc: 0.6952 -- iter: 0384/1980
[A[ATraining Step: 509  | total loss: [1m[32m0.58097[0m[0m | time: 8.489s
[2K
| Adam | epoch: 009 | loss: 0.58097 - acc: 0.7007 -- iter: 0416/1980
[A[ATraining Step: 510  | total loss: [1m[32m0.59060[0m[0m | time: 9.119s
[2K
| Adam | epoch: 009 | loss: 0.59060 - acc: 0.6900 -- iter: 0448/1980
[A[ATraining Step: 511  | total loss: [1m[32m0.58611[0m[0m | time: 9.795s
[2K
| Adam | epoch: 009 | loss: 0.58611 - acc: 0.6991 -- iter: 0480/1980
[A[ATraining Step: 512  | total loss: [1m[32m0.59164[0m[0m | time: 10.478s
[2K
| Adam | epoch: 009 | loss: 0.59164 - acc: 0.6948 -- iter: 0512/1980
[A[ATraining Step: 513  | total loss: [1m[32m0.60041[0m[0m | time: 11.130s
[2K
| Adam | epoch: 009 | loss: 0.60041 - acc: 0.6879 -- iter: 0544/1980
[A[ATraining Step: 514  | total loss: [1m[32m0.60034[0m[0m | time: 11.758s
[2K
| Adam | epoch: 009 | loss: 0.60034 - acc: 0.6847 -- iter: 0576/1980
[A[ATraining Step: 515  | total loss: [1m[32m0.60299[0m[0m | time: 12.423s
[2K
| Adam | epoch: 009 | loss: 0.60299 - acc: 0.6819 -- iter: 0608/1980
[A[ATraining Step: 516  | total loss: [1m[32m0.60183[0m[0m | time: 13.089s
[2K
| Adam | epoch: 009 | loss: 0.60183 - acc: 0.6887 -- iter: 0640/1980
[A[ATraining Step: 517  | total loss: [1m[32m0.60387[0m[0m | time: 13.722s
[2K
| Adam | epoch: 009 | loss: 0.60387 - acc: 0.6854 -- iter: 0672/1980
[A[ATraining Step: 518  | total loss: [1m[32m0.59104[0m[0m | time: 14.362s
[2K
| Adam | epoch: 009 | loss: 0.59104 - acc: 0.7013 -- iter: 0704/1980
[A[ATraining Step: 519  | total loss: [1m[32m0.59097[0m[0m | time: 14.988s
[2K
| Adam | epoch: 009 | loss: 0.59097 - acc: 0.7030 -- iter: 0736/1980
[A[ATraining Step: 520  | total loss: [1m[32m0.58884[0m[0m | time: 15.669s
[2K
| Adam | epoch: 009 | loss: 0.58884 - acc: 0.7046 -- iter: 0768/1980
[A[ATraining Step: 521  | total loss: [1m[32m0.58461[0m[0m | time: 16.323s
[2K
| Adam | epoch: 009 | loss: 0.58461 - acc: 0.7122 -- iter: 0800/1980
[A[ATraining Step: 522  | total loss: [1m[32m0.58954[0m[0m | time: 16.957s
[2K
| Adam | epoch: 009 | loss: 0.58954 - acc: 0.7066 -- iter: 0832/1980
[A[ATraining Step: 523  | total loss: [1m[32m0.58774[0m[0m | time: 17.596s
[2K
| Adam | epoch: 009 | loss: 0.58774 - acc: 0.7141 -- iter: 0864/1980
[A[ATraining Step: 524  | total loss: [1m[32m0.58480[0m[0m | time: 18.216s
[2K
| Adam | epoch: 009 | loss: 0.58480 - acc: 0.7208 -- iter: 0896/1980
[A[ATraining Step: 525  | total loss: [1m[32m0.59126[0m[0m | time: 18.844s
[2K
| Adam | epoch: 009 | loss: 0.59126 - acc: 0.7144 -- iter: 0928/1980
[A[ATraining Step: 526  | total loss: [1m[32m0.59193[0m[0m | time: 19.527s
[2K
| Adam | epoch: 009 | loss: 0.59193 - acc: 0.7086 -- iter: 0960/1980
[A[ATraining Step: 527  | total loss: [1m[32m0.60532[0m[0m | time: 20.216s
[2K
| Adam | epoch: 009 | loss: 0.60532 - acc: 0.7002 -- iter: 0992/1980
[A[ATraining Step: 528  | total loss: [1m[32m0.61354[0m[0m | time: 20.846s
[2K
| Adam | epoch: 009 | loss: 0.61354 - acc: 0.6896 -- iter: 1024/1980
[A[ATraining Step: 529  | total loss: [1m[32m0.60898[0m[0m | time: 21.504s
[2K
| Adam | epoch: 009 | loss: 0.60898 - acc: 0.6987 -- iter: 1056/1980
[A[ATraining Step: 530  | total loss: [1m[32m0.61394[0m[0m | time: 22.157s
[2K
| Adam | epoch: 009 | loss: 0.61394 - acc: 0.6882 -- iter: 1088/1980
[A[ATraining Step: 531  | total loss: [1m[32m0.60651[0m[0m | time: 22.839s
[2K
| Adam | epoch: 009 | loss: 0.60651 - acc: 0.6944 -- iter: 1120/1980
[A[ATraining Step: 532  | total loss: [1m[32m0.61482[0m[0m | time: 23.466s
[2K
| Adam | epoch: 009 | loss: 0.61482 - acc: 0.6843 -- iter: 1152/1980
[A[ATraining Step: 533  | total loss: [1m[32m0.59833[0m[0m | time: 24.126s
[2K
| Adam | epoch: 009 | loss: 0.59833 - acc: 0.6940 -- iter: 1184/1980
[A[ATraining Step: 534  | total loss: [1m[32m0.59121[0m[0m | time: 24.771s
[2K
| Adam | epoch: 009 | loss: 0.59121 - acc: 0.7028 -- iter: 1216/1980
[A[ATraining Step: 535  | total loss: [1m[32m0.57486[0m[0m | time: 25.384s
[2K
| Adam | epoch: 009 | loss: 0.57486 - acc: 0.7200 -- iter: 1248/1980
[A[ATraining Step: 536  | total loss: [1m[32m0.57974[0m[0m | time: 26.043s
[2K
| Adam | epoch: 009 | loss: 0.57974 - acc: 0.7199 -- iter: 1280/1980
[A[ATraining Step: 537  | total loss: [1m[32m0.57481[0m[0m | time: 26.656s
[2K
| Adam | epoch: 009 | loss: 0.57481 - acc: 0.7229 -- iter: 1312/1980
[A[ATraining Step: 538  | total loss: [1m[32m0.58119[0m[0m | time: 27.290s
[2K
| Adam | epoch: 009 | loss: 0.58119 - acc: 0.7131 -- iter: 1344/1980
[A[ATraining Step: 539  | total loss: [1m[32m0.58242[0m[0m | time: 27.909s
[2K
| Adam | epoch: 009 | loss: 0.58242 - acc: 0.7074 -- iter: 1376/1980
[A[ATraining Step: 540  | total loss: [1m[32m0.59711[0m[0m | time: 28.524s
[2K
| Adam | epoch: 009 | loss: 0.59711 - acc: 0.6929 -- iter: 1408/1980
[A[ATraining Step: 541  | total loss: [1m[32m0.59645[0m[0m | time: 29.208s
[2K
| Adam | epoch: 009 | loss: 0.59645 - acc: 0.6892 -- iter: 1440/1980
[A[ATraining Step: 542  | total loss: [1m[32m0.58985[0m[0m | time: 29.880s
[2K
| Adam | epoch: 009 | loss: 0.58985 - acc: 0.6891 -- iter: 1472/1980
[A[ATraining Step: 543  | total loss: [1m[32m0.59061[0m[0m | time: 30.544s
[2K
| Adam | epoch: 009 | loss: 0.59061 - acc: 0.6920 -- iter: 1504/1980
[A[ATraining Step: 544  | total loss: [1m[32m0.57137[0m[0m | time: 31.202s
[2K
| Adam | epoch: 009 | loss: 0.57137 - acc: 0.7103 -- iter: 1536/1980
[A[ATraining Step: 545  | total loss: [1m[32m0.57397[0m[0m | time: 31.821s
[2K
| Adam | epoch: 009 | loss: 0.57397 - acc: 0.7018 -- iter: 1568/1980
[A[ATraining Step: 546  | total loss: [1m[32m0.57895[0m[0m | time: 32.437s
[2K
| Adam | epoch: 009 | loss: 0.57895 - acc: 0.7004 -- iter: 1600/1980
[A[ATraining Step: 547  | total loss: [1m[32m0.58582[0m[0m | time: 33.093s
[2K
| Adam | epoch: 009 | loss: 0.58582 - acc: 0.6960 -- iter: 1632/1980
[A[ATraining Step: 548  | total loss: [1m[32m0.58035[0m[0m | time: 33.736s
[2K
| Adam | epoch: 009 | loss: 0.58035 - acc: 0.7045 -- iter: 1664/1980
[A[ATraining Step: 549  | total loss: [1m[32m0.57798[0m[0m | time: 34.457s
[2K
| Adam | epoch: 009 | loss: 0.57798 - acc: 0.6997 -- iter: 1696/1980
[A[ATraining Step: 550  | total loss: [1m[32m0.60948[0m[0m | time: 35.118s
[2K
| Adam | epoch: 009 | loss: 0.60948 - acc: 0.6734 -- iter: 1728/1980
[A[ATraining Step: 551  | total loss: [1m[32m0.60425[0m[0m | time: 35.765s
[2K
| Adam | epoch: 009 | loss: 0.60425 - acc: 0.6811 -- iter: 1760/1980
[A[ATraining Step: 552  | total loss: [1m[32m0.61109[0m[0m | time: 36.421s
[2K
| Adam | epoch: 009 | loss: 0.61109 - acc: 0.6755 -- iter: 1792/1980
[A[ATraining Step: 553  | total loss: [1m[32m0.62401[0m[0m | time: 37.100s
[2K
| Adam | epoch: 009 | loss: 0.62401 - acc: 0.6673 -- iter: 1824/1980
[A[ATraining Step: 554  | total loss: [1m[32m0.63137[0m[0m | time: 37.736s
[2K
| Adam | epoch: 009 | loss: 0.63137 - acc: 0.6600 -- iter: 1856/1980
[A[ATraining Step: 555  | total loss: [1m[32m0.62224[0m[0m | time: 38.434s
[2K
| Adam | epoch: 009 | loss: 0.62224 - acc: 0.6690 -- iter: 1888/1980
[A[ATraining Step: 556  | total loss: [1m[32m0.62518[0m[0m | time: 39.111s
[2K
| Adam | epoch: 009 | loss: 0.62518 - acc: 0.6614 -- iter: 1920/1980
[A[ATraining Step: 557  | total loss: [1m[32m0.62181[0m[0m | time: 39.794s
[2K
| Adam | epoch: 009 | loss: 0.62181 - acc: 0.6609 -- iter: 1952/1980
[A[ATraining Step: 558  | total loss: [1m[32m0.62321[0m[0m | time: 42.680s
[2K
| Adam | epoch: 009 | loss: 0.62321 - acc: 0.6667 | val_loss: 0.58764 - val_acc: 0.7076 -- iter: 1980/1980
--
Training Step: 559  | total loss: [1m[32m0.61489[0m[0m | time: 0.705s
[2K
| Adam | epoch: 010 | loss: 0.61489 - acc: 0.6688 -- iter: 0032/1980
[A[ATraining Step: 560  | total loss: [1m[32m0.60710[0m[0m | time: 1.361s
[2K
| Adam | epoch: 010 | loss: 0.60710 - acc: 0.6769 -- iter: 0064/1980
[A[ATraining Step: 561  | total loss: [1m[32m0.60569[0m[0m | time: 1.997s
[2K
| Adam | epoch: 010 | loss: 0.60569 - acc: 0.6748 -- iter: 0096/1980
[A[ATraining Step: 562  | total loss: [1m[32m0.59726[0m[0m | time: 2.684s
[2K
| Adam | epoch: 010 | loss: 0.59726 - acc: 0.6824 -- iter: 0128/1980
[A[ATraining Step: 563  | total loss: [1m[32m0.59487[0m[0m | time: 3.352s
[2K
| Adam | epoch: 010 | loss: 0.59487 - acc: 0.6829 -- iter: 0160/1980
[A[ATraining Step: 564  | total loss: [1m[32m0.57825[0m[0m | time: 4.004s
[2K
| Adam | epoch: 010 | loss: 0.57825 - acc: 0.7021 -- iter: 0192/1980
[A[ATraining Step: 565  | total loss: [1m[32m0.57238[0m[0m | time: 4.666s
[2K
| Adam | epoch: 010 | loss: 0.57238 - acc: 0.7131 -- iter: 0224/1980
[A[ATraining Step: 566  | total loss: [1m[32m0.58242[0m[0m | time: 5.257s
[2K
| Adam | epoch: 010 | loss: 0.58242 - acc: 0.6949 -- iter: 0256/1980
[A[ATraining Step: 567  | total loss: [1m[32m0.58194[0m[0m | time: 5.863s
[2K
| Adam | epoch: 010 | loss: 0.58194 - acc: 0.7004 -- iter: 0288/1980
[A[ATraining Step: 568  | total loss: [1m[32m0.58151[0m[0m | time: 6.555s
[2K
| Adam | epoch: 010 | loss: 0.58151 - acc: 0.7054 -- iter: 0320/1980
[A[ATraining Step: 569  | total loss: [1m[32m0.57644[0m[0m | time: 7.230s
[2K
| Adam | epoch: 010 | loss: 0.57644 - acc: 0.7130 -- iter: 0352/1980
[A[ATraining Step: 570  | total loss: [1m[32m0.56888[0m[0m | time: 7.853s
[2K
| Adam | epoch: 010 | loss: 0.56888 - acc: 0.7198 -- iter: 0384/1980
[A[ATraining Step: 571  | total loss: [1m[32m0.56924[0m[0m | time: 8.507s
[2K
| Adam | epoch: 010 | loss: 0.56924 - acc: 0.7072 -- iter: 0416/1980
[A[ATraining Step: 572  | total loss: [1m[32m0.55525[0m[0m | time: 9.225s
[2K
| Adam | epoch: 010 | loss: 0.55525 - acc: 0.7177 -- iter: 0448/1980
[A[ATraining Step: 573  | total loss: [1m[32m0.55967[0m[0m | time: 9.882s
[2K
| Adam | epoch: 010 | loss: 0.55967 - acc: 0.7147 -- iter: 0480/1980
[A[ATraining Step: 574  | total loss: [1m[32m0.57305[0m[0m | time: 10.555s
[2K
| Adam | epoch: 010 | loss: 0.57305 - acc: 0.7057 -- iter: 0512/1980
[A[ATraining Step: 575  | total loss: [1m[32m0.56945[0m[0m | time: 11.240s
[2K
| Adam | epoch: 010 | loss: 0.56945 - acc: 0.7039 -- iter: 0544/1980
[A[ATraining Step: 576  | total loss: [1m[32m0.56836[0m[0m | time: 11.898s
[2K
| Adam | epoch: 010 | loss: 0.56836 - acc: 0.7116 -- iter: 0576/1980
[A[ATraining Step: 577  | total loss: [1m[32m0.57519[0m[0m | time: 12.527s
[2K
| Adam | epoch: 010 | loss: 0.57519 - acc: 0.7061 -- iter: 0608/1980
[A[ATraining Step: 578  | total loss: [1m[32m0.57800[0m[0m | time: 13.206s
[2K
| Adam | epoch: 010 | loss: 0.57800 - acc: 0.7042 -- iter: 0640/1980
[A[ATraining Step: 579  | total loss: [1m[32m0.58586[0m[0m | time: 13.881s
[2K
| Adam | epoch: 010 | loss: 0.58586 - acc: 0.6994 -- iter: 0672/1980
[A[ATraining Step: 580  | total loss: [1m[32m0.58358[0m[0m | time: 14.561s
[2K
| Adam | epoch: 010 | loss: 0.58358 - acc: 0.7045 -- iter: 0704/1980
[A[ATraining Step: 581  | total loss: [1m[32m0.57954[0m[0m | time: 15.215s
[2K
| Adam | epoch: 010 | loss: 0.57954 - acc: 0.7059 -- iter: 0736/1980
[A[ATraining Step: 582  | total loss: [1m[32m0.57174[0m[0m | time: 15.874s
[2K
| Adam | epoch: 010 | loss: 0.57174 - acc: 0.7197 -- iter: 0768/1980
[A[ATraining Step: 583  | total loss: [1m[32m0.57147[0m[0m | time: 16.494s
[2K
| Adam | epoch: 010 | loss: 0.57147 - acc: 0.7290 -- iter: 0800/1980
[A[ATraining Step: 584  | total loss: [1m[32m0.57026[0m[0m | time: 17.132s
[2K
| Adam | epoch: 010 | loss: 0.57026 - acc: 0.7248 -- iter: 0832/1980
[A[ATraining Step: 585  | total loss: [1m[32m0.56600[0m[0m | time: 17.794s
[2K
| Adam | epoch: 010 | loss: 0.56600 - acc: 0.7274 -- iter: 0864/1980
[A[ATraining Step: 586  | total loss: [1m[32m0.55614[0m[0m | time: 18.431s
[2K
| Adam | epoch: 010 | loss: 0.55614 - acc: 0.7327 -- iter: 0896/1980
[A[ATraining Step: 587  | total loss: [1m[32m0.54473[0m[0m | time: 19.110s
[2K
| Adam | epoch: 010 | loss: 0.54473 - acc: 0.7438 -- iter: 0928/1980
[A[ATraining Step: 588  | total loss: [1m[32m0.53728[0m[0m | time: 19.763s
[2K
| Adam | epoch: 010 | loss: 0.53728 - acc: 0.7507 -- iter: 0960/1980
[A[ATraining Step: 589  | total loss: [1m[32m0.54880[0m[0m | time: 20.438s
[2K
| Adam | epoch: 010 | loss: 0.54880 - acc: 0.7413 -- iter: 0992/1980
[A[ATraining Step: 590  | total loss: [1m[32m0.54494[0m[0m | time: 21.098s
[2K
| Adam | epoch: 010 | loss: 0.54494 - acc: 0.7453 -- iter: 1024/1980
[A[ATraining Step: 591  | total loss: [1m[32m0.54299[0m[0m | time: 21.751s
[2K
| Adam | epoch: 010 | loss: 0.54299 - acc: 0.7426 -- iter: 1056/1980
[A[ATraining Step: 592  | total loss: [1m[32m0.53730[0m[0m | time: 22.420s
[2K
| Adam | epoch: 010 | loss: 0.53730 - acc: 0.7527 -- iter: 1088/1980
[A[ATraining Step: 593  | total loss: [1m[32m0.55512[0m[0m | time: 23.055s
[2K
| Adam | epoch: 010 | loss: 0.55512 - acc: 0.7400 -- iter: 1120/1980
[A[ATraining Step: 594  | total loss: [1m[32m0.55313[0m[0m | time: 23.698s
[2K
| Adam | epoch: 010 | loss: 0.55313 - acc: 0.7410 -- iter: 1152/1980
[A[ATraining Step: 595  | total loss: [1m[32m0.56033[0m[0m | time: 24.416s
[2K
| Adam | epoch: 010 | loss: 0.56033 - acc: 0.7387 -- iter: 1184/1980
[A[ATraining Step: 596  | total loss: [1m[32m0.54623[0m[0m | time: 25.062s
[2K
| Adam | epoch: 010 | loss: 0.54623 - acc: 0.7399 -- iter: 1216/1980
[A[ATraining Step: 597  | total loss: [1m[32m0.56830[0m[0m | time: 25.691s
[2K
| Adam | epoch: 010 | loss: 0.56830 - acc: 0.7253 -- iter: 1248/1980
[A[ATraining Step: 598  | total loss: [1m[32m0.55485[0m[0m | time: 26.365s
[2K
| Adam | epoch: 010 | loss: 0.55485 - acc: 0.7371 -- iter: 1280/1980
[A[ATraining Step: 599  | total loss: [1m[32m0.55172[0m[0m | time: 26.986s
[2K
| Adam | epoch: 010 | loss: 0.55172 - acc: 0.7384 -- iter: 1312/1980
[A[ATraining Step: 600  | total loss: [1m[32m0.53842[0m[0m | time: 29.869s
[2K
| Adam | epoch: 010 | loss: 0.53842 - acc: 0.7489 | val_loss: 0.59105 - val_acc: 0.6850 -- iter: 1344/1980
--
Training Step: 601  | total loss: [1m[32m0.55369[0m[0m | time: 30.513s
[2K
| Adam | epoch: 010 | loss: 0.55369 - acc: 0.7334 -- iter: 1376/1980
[A[ATraining Step: 602  | total loss: [1m[32m0.54348[0m[0m | time: 31.170s
[2K
| Adam | epoch: 010 | loss: 0.54348 - acc: 0.7413 -- iter: 1408/1980
[A[ATraining Step: 603  | total loss: [1m[32m0.54927[0m[0m | time: 31.833s
[2K
| Adam | epoch: 010 | loss: 0.54927 - acc: 0.7391 -- iter: 1440/1980
[A[ATraining Step: 604  | total loss: [1m[32m0.55327[0m[0m | time: 32.507s
[2K
| Adam | epoch: 010 | loss: 0.55327 - acc: 0.7339 -- iter: 1472/1980
[A[ATraining Step: 605  | total loss: [1m[32m0.56569[0m[0m | time: 33.189s
[2K
| Adam | epoch: 010 | loss: 0.56569 - acc: 0.7199 -- iter: 1504/1980
[A[ATraining Step: 606  | total loss: [1m[32m0.56619[0m[0m | time: 33.828s
[2K
| Adam | epoch: 010 | loss: 0.56619 - acc: 0.7167 -- iter: 1536/1980
[A[ATraining Step: 607  | total loss: [1m[32m0.58215[0m[0m | time: 34.474s
[2K
| Adam | epoch: 010 | loss: 0.58215 - acc: 0.7044 -- iter: 1568/1980
[A[ATraining Step: 608  | total loss: [1m[32m0.56454[0m[0m | time: 35.124s
[2K
| Adam | epoch: 010 | loss: 0.56454 - acc: 0.7183 -- iter: 1600/1980
[A[ATraining Step: 609  | total loss: [1m[32m0.55555[0m[0m | time: 35.789s
[2K
| Adam | epoch: 010 | loss: 0.55555 - acc: 0.7183 -- iter: 1632/1980
[A[ATraining Step: 610  | total loss: [1m[32m0.58287[0m[0m | time: 36.419s
[2K
| Adam | epoch: 010 | loss: 0.58287 - acc: 0.6965 -- iter: 1664/1980
[A[ATraining Step: 611  | total loss: [1m[32m0.57465[0m[0m | time: 37.037s
[2K
| Adam | epoch: 010 | loss: 0.57465 - acc: 0.7019 -- iter: 1696/1980
[A[ATraining Step: 612  | total loss: [1m[32m0.55705[0m[0m | time: 37.713s
[2K
| Adam | epoch: 010 | loss: 0.55705 - acc: 0.7223 -- iter: 1728/1980
[A[ATraining Step: 613  | total loss: [1m[32m0.54998[0m[0m | time: 38.370s
[2K
| Adam | epoch: 010 | loss: 0.54998 - acc: 0.7282 -- iter: 1760/1980
[A[ATraining Step: 614  | total loss: [1m[32m0.55261[0m[0m | time: 39.050s
[2K
| Adam | epoch: 010 | loss: 0.55261 - acc: 0.7241 -- iter: 1792/1980
[A[ATraining Step: 615  | total loss: [1m[32m0.55190[0m[0m | time: 39.694s
[2K
| Adam | epoch: 010 | loss: 0.55190 - acc: 0.7330 -- iter: 1824/1980
[A[ATraining Step: 616  | total loss: [1m[32m0.55091[0m[0m | time: 40.303s
[2K
| Adam | epoch: 010 | loss: 0.55091 - acc: 0.7347 -- iter: 1856/1980
[A[ATraining Step: 617  | total loss: [1m[32m0.55393[0m[0m | time: 40.990s
[2K
| Adam | epoch: 010 | loss: 0.55393 - acc: 0.7331 -- iter: 1888/1980
[A[ATraining Step: 618  | total loss: [1m[32m0.56479[0m[0m | time: 41.639s
[2K
| Adam | epoch: 010 | loss: 0.56479 - acc: 0.7223 -- iter: 1920/1980
[A[ATraining Step: 619  | total loss: [1m[32m0.57332[0m[0m | time: 42.259s
[2K
| Adam | epoch: 010 | loss: 0.57332 - acc: 0.7188 -- iter: 1952/1980
[A[ATraining Step: 620  | total loss: [1m[32m0.57085[0m[0m | time: 45.220s
[2K
| Adam | epoch: 010 | loss: 0.57085 - acc: 0.7219 | val_loss: 0.59116 - val_acc: 0.6882 -- iter: 1980/1980
--
Training Step: 621  | total loss: [1m[32m0.57646[0m[0m | time: 0.665s
[2K
| Adam | epoch: 011 | loss: 0.57646 - acc: 0.7185 -- iter: 0032/1980
[A[ATraining Step: 622  | total loss: [1m[32m0.57950[0m[0m | time: 1.341s
[2K
| Adam | epoch: 011 | loss: 0.57950 - acc: 0.7060 -- iter: 0064/1980
[A[ATraining Step: 623  | total loss: [1m[32m0.57155[0m[0m | time: 1.963s
[2K
| Adam | epoch: 011 | loss: 0.57155 - acc: 0.7166 -- iter: 0096/1980
[A[ATraining Step: 624  | total loss: [1m[32m0.56615[0m[0m | time: 2.620s
[2K
| Adam | epoch: 011 | loss: 0.56615 - acc: 0.7169 -- iter: 0128/1980
[A[ATraining Step: 625  | total loss: [1m[32m0.55041[0m[0m | time: 3.262s
[2K
| Adam | epoch: 011 | loss: 0.55041 - acc: 0.7295 -- iter: 0160/1980
[A[ATraining Step: 626  | total loss: [1m[32m0.54835[0m[0m | time: 3.892s
[2K
| Adam | epoch: 011 | loss: 0.54835 - acc: 0.7285 -- iter: 0192/1980
[A[ATraining Step: 627  | total loss: [1m[32m0.54619[0m[0m | time: 4.565s
[2K
| Adam | epoch: 011 | loss: 0.54619 - acc: 0.7337 -- iter: 0224/1980
[A[ATraining Step: 628  | total loss: [1m[32m0.53460[0m[0m | time: 5.252s
[2K
| Adam | epoch: 011 | loss: 0.53460 - acc: 0.7447 -- iter: 0256/1980
[A[ATraining Step: 629  | total loss: [1m[32m0.54305[0m[0m | time: 5.792s
[2K
| Adam | epoch: 011 | loss: 0.54305 - acc: 0.7328 -- iter: 0288/1980
[A[ATraining Step: 630  | total loss: [1m[32m0.54397[0m[0m | time: 6.365s
[2K
| Adam | epoch: 011 | loss: 0.54397 - acc: 0.7345 -- iter: 0320/1980
[A[ATraining Step: 631  | total loss: [1m[32m0.54410[0m[0m | time: 7.047s
[2K
| Adam | epoch: 011 | loss: 0.54410 - acc: 0.7360 -- iter: 0352/1980
[A[ATraining Step: 632  | total loss: [1m[32m0.55847[0m[0m | time: 7.710s
[2K
| Adam | epoch: 011 | loss: 0.55847 - acc: 0.7218 -- iter: 0384/1980
[A[ATraining Step: 633  | total loss: [1m[32m0.55932[0m[0m | time: 8.411s
[2K
| Adam | epoch: 011 | loss: 0.55932 - acc: 0.7278 -- iter: 0416/1980
[A[ATraining Step: 634  | total loss: [1m[32m0.57044[0m[0m | time: 9.102s
[2K
| Adam | epoch: 011 | loss: 0.57044 - acc: 0.7175 -- iter: 0448/1980
[A[ATraining Step: 635  | total loss: [1m[32m0.56979[0m[0m | time: 9.735s
[2K
| Adam | epoch: 011 | loss: 0.56979 - acc: 0.7145 -- iter: 0480/1980
[A[ATraining Step: 636  | total loss: [1m[32m0.57198[0m[0m | time: 10.384s
[2K
| Adam | epoch: 011 | loss: 0.57198 - acc: 0.7118 -- iter: 0512/1980
[A[ATraining Step: 637  | total loss: [1m[32m0.57798[0m[0m | time: 11.035s
[2K
| Adam | epoch: 011 | loss: 0.57798 - acc: 0.7031 -- iter: 0544/1980
[A[ATraining Step: 638  | total loss: [1m[32m0.57625[0m[0m | time: 11.695s
[2K
| Adam | epoch: 011 | loss: 0.57625 - acc: 0.7015 -- iter: 0576/1980
[A[ATraining Step: 639  | total loss: [1m[32m0.57033[0m[0m | time: 12.406s
[2K
| Adam | epoch: 011 | loss: 0.57033 - acc: 0.7095 -- iter: 0608/1980
[A[ATraining Step: 640  | total loss: [1m[32m0.56052[0m[0m | time: 13.096s
[2K
| Adam | epoch: 011 | loss: 0.56052 - acc: 0.7167 -- iter: 0640/1980
[A[ATraining Step: 641  | total loss: [1m[32m0.56076[0m[0m | time: 13.811s
[2K
| Adam | epoch: 011 | loss: 0.56076 - acc: 0.7200 -- iter: 0672/1980
[A[ATraining Step: 642  | total loss: [1m[32m0.56266[0m[0m | time: 14.496s
[2K
| Adam | epoch: 011 | loss: 0.56266 - acc: 0.7199 -- iter: 0704/1980
[A[ATraining Step: 643  | total loss: [1m[32m0.55945[0m[0m | time: 15.184s
[2K
| Adam | epoch: 011 | loss: 0.55945 - acc: 0.7229 -- iter: 0736/1980
[A[ATraining Step: 644  | total loss: [1m[32m0.57939[0m[0m | time: 15.816s
[2K
| Adam | epoch: 011 | loss: 0.57939 - acc: 0.7069 -- iter: 0768/1980
[A[ATraining Step: 645  | total loss: [1m[32m0.57287[0m[0m | time: 16.478s
[2K
| Adam | epoch: 011 | loss: 0.57287 - acc: 0.7174 -- iter: 0800/1980
[A[ATraining Step: 646  | total loss: [1m[32m0.56763[0m[0m | time: 17.196s
[2K
| Adam | epoch: 011 | loss: 0.56763 - acc: 0.7269 -- iter: 0832/1980
[A[ATraining Step: 647  | total loss: [1m[32m0.56516[0m[0m | time: 17.861s
[2K
| Adam | epoch: 011 | loss: 0.56516 - acc: 0.7292 -- iter: 0864/1980
[A[ATraining Step: 648  | total loss: [1m[32m0.55762[0m[0m | time: 18.526s
[2K
| Adam | epoch: 011 | loss: 0.55762 - acc: 0.7376 -- iter: 0896/1980
[A[ATraining Step: 649  | total loss: [1m[32m0.55334[0m[0m | time: 19.175s
[2K
| Adam | epoch: 011 | loss: 0.55334 - acc: 0.7388 -- iter: 0928/1980
[A[ATraining Step: 650  | total loss: [1m[32m0.56442[0m[0m | time: 19.828s
[2K
| Adam | epoch: 011 | loss: 0.56442 - acc: 0.7274 -- iter: 0960/1980
[A[ATraining Step: 651  | total loss: [1m[32m0.55671[0m[0m | time: 20.450s
[2K
| Adam | epoch: 011 | loss: 0.55671 - acc: 0.7203 -- iter: 0992/1980
[A[ATraining Step: 652  | total loss: [1m[32m0.55587[0m[0m | time: 21.119s
[2K
| Adam | epoch: 011 | loss: 0.55587 - acc: 0.7108 -- iter: 1024/1980
[A[ATraining Step: 653  | total loss: [1m[32m0.55257[0m[0m | time: 21.792s
[2K
| Adam | epoch: 011 | loss: 0.55257 - acc: 0.7178 -- iter: 1056/1980
[A[ATraining Step: 654  | total loss: [1m[32m0.55698[0m[0m | time: 22.475s
[2K
| Adam | epoch: 011 | loss: 0.55698 - acc: 0.7054 -- iter: 1088/1980
[A[ATraining Step: 655  | total loss: [1m[32m0.54333[0m[0m | time: 23.139s
[2K
| Adam | epoch: 011 | loss: 0.54333 - acc: 0.7193 -- iter: 1120/1980
[A[ATraining Step: 656  | total loss: [1m[32m0.54897[0m[0m | time: 23.821s
[2K
| Adam | epoch: 011 | loss: 0.54897 - acc: 0.7098 -- iter: 1152/1980
[A[ATraining Step: 657  | total loss: [1m[32m0.55254[0m[0m | time: 24.535s
[2K
| Adam | epoch: 011 | loss: 0.55254 - acc: 0.7013 -- iter: 1184/1980
[A[ATraining Step: 658  | total loss: [1m[32m0.55804[0m[0m | time: 25.195s
[2K
| Adam | epoch: 011 | loss: 0.55804 - acc: 0.6937 -- iter: 1216/1980
[A[ATraining Step: 659  | total loss: [1m[32m0.54468[0m[0m | time: 25.900s
[2K
| Adam | epoch: 011 | loss: 0.54468 - acc: 0.7087 -- iter: 1248/1980
[A[ATraining Step: 660  | total loss: [1m[32m0.53672[0m[0m | time: 26.550s
[2K
| Adam | epoch: 011 | loss: 0.53672 - acc: 0.7253 -- iter: 1280/1980
[A[ATraining Step: 661  | total loss: [1m[32m0.53468[0m[0m | time: 27.232s
[2K
| Adam | epoch: 011 | loss: 0.53468 - acc: 0.7247 -- iter: 1312/1980
[A[ATraining Step: 662  | total loss: [1m[32m0.53147[0m[0m | time: 27.920s
[2K
| Adam | epoch: 011 | loss: 0.53147 - acc: 0.7335 -- iter: 1344/1980
[A[ATraining Step: 663  | total loss: [1m[32m0.52828[0m[0m | time: 28.570s
[2K
| Adam | epoch: 011 | loss: 0.52828 - acc: 0.7320 -- iter: 1376/1980
[A[ATraining Step: 664  | total loss: [1m[32m0.53882[0m[0m | time: 29.205s
[2K
| Adam | epoch: 011 | loss: 0.53882 - acc: 0.7182 -- iter: 1408/1980
[A[ATraining Step: 665  | total loss: [1m[32m0.54705[0m[0m | time: 29.836s
[2K
| Adam | epoch: 011 | loss: 0.54705 - acc: 0.7089 -- iter: 1440/1980
[A[ATraining Step: 666  | total loss: [1m[32m0.54462[0m[0m | time: 30.484s
[2K
| Adam | epoch: 011 | loss: 0.54462 - acc: 0.7098 -- iter: 1472/1980
[A[ATraining Step: 667  | total loss: [1m[32m0.54551[0m[0m | time: 31.127s
[2K
| Adam | epoch: 011 | loss: 0.54551 - acc: 0.7139 -- iter: 1504/1980
[A[ATraining Step: 668  | total loss: [1m[32m0.53455[0m[0m | time: 31.765s
[2K
| Adam | epoch: 011 | loss: 0.53455 - acc: 0.7300 -- iter: 1536/1980
[A[ATraining Step: 669  | total loss: [1m[32m0.52622[0m[0m | time: 32.449s
[2K
| Adam | epoch: 011 | loss: 0.52622 - acc: 0.7320 -- iter: 1568/1980
[A[ATraining Step: 670  | total loss: [1m[32m0.53234[0m[0m | time: 33.093s
[2K
| Adam | epoch: 011 | loss: 0.53234 - acc: 0.7338 -- iter: 1600/1980
[A[ATraining Step: 671  | total loss: [1m[32m0.53852[0m[0m | time: 33.731s
[2K
| Adam | epoch: 011 | loss: 0.53852 - acc: 0.7291 -- iter: 1632/1980
[A[ATraining Step: 672  | total loss: [1m[32m0.53990[0m[0m | time: 34.391s
[2K
| Adam | epoch: 011 | loss: 0.53990 - acc: 0.7312 -- iter: 1664/1980
[A[ATraining Step: 673  | total loss: [1m[32m0.54418[0m[0m | time: 35.060s
[2K
| Adam | epoch: 011 | loss: 0.54418 - acc: 0.7237 -- iter: 1696/1980
[A[ATraining Step: 674  | total loss: [1m[32m0.54196[0m[0m | time: 35.681s
[2K
| Adam | epoch: 011 | loss: 0.54196 - acc: 0.7201 -- iter: 1728/1980
[A[ATraining Step: 675  | total loss: [1m[32m0.54296[0m[0m | time: 36.327s
[2K
| Adam | epoch: 011 | loss: 0.54296 - acc: 0.7200 -- iter: 1760/1980
[A[ATraining Step: 676  | total loss: [1m[32m0.53543[0m[0m | time: 37.047s
[2K
| Adam | epoch: 011 | loss: 0.53543 - acc: 0.7230 -- iter: 1792/1980
[A[ATraining Step: 677  | total loss: [1m[32m0.55287[0m[0m | time: 37.737s
[2K
| Adam | epoch: 011 | loss: 0.55287 - acc: 0.7069 -- iter: 1824/1980
[A[ATraining Step: 678  | total loss: [1m[32m0.56687[0m[0m | time: 38.402s
[2K
| Adam | epoch: 011 | loss: 0.56687 - acc: 0.6956 -- iter: 1856/1980
[A[ATraining Step: 679  | total loss: [1m[32m0.55245[0m[0m | time: 39.069s
[2K
| Adam | epoch: 011 | loss: 0.55245 - acc: 0.7136 -- iter: 1888/1980
[A[ATraining Step: 680  | total loss: [1m[32m0.54433[0m[0m | time: 39.720s
[2K
| Adam | epoch: 011 | loss: 0.54433 - acc: 0.7141 -- iter: 1920/1980
[A[ATraining Step: 681  | total loss: [1m[32m0.54162[0m[0m | time: 40.387s
[2K
| Adam | epoch: 011 | loss: 0.54162 - acc: 0.7177 -- iter: 1952/1980
[A[ATraining Step: 682  | total loss: [1m[32m0.54286[0m[0m | time: 43.286s
[2K
| Adam | epoch: 011 | loss: 0.54286 - acc: 0.7209 | val_loss: 0.55266 - val_acc: 0.7334 -- iter: 1980/1980
--
Training Step: 683  | total loss: [1m[32m0.54551[0m[0m | time: 0.686s
[2K
| Adam | epoch: 012 | loss: 0.54551 - acc: 0.7238 -- iter: 0032/1980
[A[ATraining Step: 684  | total loss: [1m[32m0.55398[0m[0m | time: 1.326s
[2K
| Adam | epoch: 012 | loss: 0.55398 - acc: 0.7202 -- iter: 0064/1980
[A[ATraining Step: 685  | total loss: [1m[32m0.54722[0m[0m | time: 1.959s
[2K
| Adam | epoch: 012 | loss: 0.54722 - acc: 0.7263 -- iter: 0096/1980
[A[ATraining Step: 686  | total loss: [1m[32m0.53035[0m[0m | time: 2.636s
[2K
| Adam | epoch: 012 | loss: 0.53035 - acc: 0.7380 -- iter: 0128/1980
[A[ATraining Step: 687  | total loss: [1m[32m0.52653[0m[0m | time: 3.301s
[2K
| Adam | epoch: 012 | loss: 0.52653 - acc: 0.7424 -- iter: 0160/1980
[A[ATraining Step: 688  | total loss: [1m[32m0.53064[0m[0m | time: 4.000s
[2K
| Adam | epoch: 012 | loss: 0.53064 - acc: 0.7369 -- iter: 0192/1980
[A[ATraining Step: 689  | total loss: [1m[32m0.53811[0m[0m | time: 4.632s
[2K
| Adam | epoch: 012 | loss: 0.53811 - acc: 0.7351 -- iter: 0224/1980
[A[ATraining Step: 690  | total loss: [1m[32m0.54904[0m[0m | time: 5.356s
[2K
| Adam | epoch: 012 | loss: 0.54904 - acc: 0.7272 -- iter: 0256/1980
[A[ATraining Step: 691  | total loss: [1m[32m0.53751[0m[0m | time: 6.069s
[2K
| Adam | epoch: 012 | loss: 0.53751 - acc: 0.7388 -- iter: 0288/1980
[A[ATraining Step: 692  | total loss: [1m[32m0.52821[0m[0m | time: 6.649s
[2K
| Adam | epoch: 012 | loss: 0.52821 - acc: 0.7462 -- iter: 0320/1980
[A[ATraining Step: 693  | total loss: [1m[32m0.53542[0m[0m | time: 7.215s
[2K
| Adam | epoch: 012 | loss: 0.53542 - acc: 0.7466 -- iter: 0352/1980
[A[ATraining Step: 694  | total loss: [1m[32m0.54138[0m[0m | time: 7.894s
[2K
| Adam | epoch: 012 | loss: 0.54138 - acc: 0.7434 -- iter: 0384/1980
[A[ATraining Step: 695  | total loss: [1m[32m0.54572[0m[0m | time: 8.567s
[2K
| Adam | epoch: 012 | loss: 0.54572 - acc: 0.7409 -- iter: 0416/1980
[A[ATraining Step: 696  | total loss: [1m[32m0.54273[0m[0m | time: 9.280s
[2K
| Adam | epoch: 012 | loss: 0.54273 - acc: 0.7387 -- iter: 0448/1980
[A[ATraining Step: 697  | total loss: [1m[32m0.53668[0m[0m | time: 9.950s
[2K
| Adam | epoch: 012 | loss: 0.53668 - acc: 0.7429 -- iter: 0480/1980
[A[ATraining Step: 698  | total loss: [1m[32m0.52175[0m[0m | time: 10.632s
[2K
| Adam | epoch: 012 | loss: 0.52175 - acc: 0.7561 -- iter: 0512/1980
[A[ATraining Step: 699  | total loss: [1m[32m0.50969[0m[0m | time: 11.306s
[2K
| Adam | epoch: 012 | loss: 0.50969 - acc: 0.7680 -- iter: 0544/1980
[A[ATraining Step: 700  | total loss: [1m[32m0.51428[0m[0m | time: 11.991s
[2K
| Adam | epoch: 012 | loss: 0.51428 - acc: 0.7631 -- iter: 0576/1980
[A[ATraining Step: 701  | total loss: [1m[32m0.51692[0m[0m | time: 12.643s
[2K
| Adam | epoch: 012 | loss: 0.51692 - acc: 0.7587 -- iter: 0608/1980
[A[ATraining Step: 702  | total loss: [1m[32m0.52295[0m[0m | time: 13.321s
[2K
| Adam | epoch: 012 | loss: 0.52295 - acc: 0.7547 -- iter: 0640/1980
[A[ATraining Step: 703  | total loss: [1m[32m0.51750[0m[0m | time: 14.066s
[2K
| Adam | epoch: 012 | loss: 0.51750 - acc: 0.7573 -- iter: 0672/1980
[A[ATraining Step: 704  | total loss: [1m[32m0.50940[0m[0m | time: 14.731s
[2K
| Adam | epoch: 012 | loss: 0.50940 - acc: 0.7566 -- iter: 0704/1980
[A[ATraining Step: 705  | total loss: [1m[32m0.52632[0m[0m | time: 15.357s
[2K
| Adam | epoch: 012 | loss: 0.52632 - acc: 0.7341 -- iter: 0736/1980
[A[ATraining Step: 706  | total loss: [1m[32m0.55109[0m[0m | time: 15.997s
[2K
| Adam | epoch: 012 | loss: 0.55109 - acc: 0.7232 -- iter: 0768/1980
[A[ATraining Step: 707  | total loss: [1m[32m0.55688[0m[0m | time: 16.662s
[2K
| Adam | epoch: 012 | loss: 0.55688 - acc: 0.7196 -- iter: 0800/1980
[A[ATraining Step: 708  | total loss: [1m[32m0.55175[0m[0m | time: 17.286s
[2K
| Adam | epoch: 012 | loss: 0.55175 - acc: 0.7226 -- iter: 0832/1980
[A[ATraining Step: 709  | total loss: [1m[32m0.55693[0m[0m | time: 17.957s
[2K
| Adam | epoch: 012 | loss: 0.55693 - acc: 0.7222 -- iter: 0864/1980
[A[ATraining Step: 710  | total loss: [1m[32m0.56237[0m[0m | time: 18.613s
[2K
| Adam | epoch: 012 | loss: 0.56237 - acc: 0.7125 -- iter: 0896/1980
[A[ATraining Step: 711  | total loss: [1m[32m0.57790[0m[0m | time: 19.290s
[2K
| Adam | epoch: 012 | loss: 0.57790 - acc: 0.7038 -- iter: 0928/1980
[A[ATraining Step: 712  | total loss: [1m[32m0.56045[0m[0m | time: 19.942s
[2K
| Adam | epoch: 012 | loss: 0.56045 - acc: 0.7146 -- iter: 0960/1980
[A[ATraining Step: 713  | total loss: [1m[32m0.55883[0m[0m | time: 20.640s
[2K
| Adam | epoch: 012 | loss: 0.55883 - acc: 0.7213 -- iter: 0992/1980
[A[ATraining Step: 714  | total loss: [1m[32m0.56739[0m[0m | time: 21.279s
[2K
| Adam | epoch: 012 | loss: 0.56739 - acc: 0.7148 -- iter: 1024/1980
[A[ATraining Step: 715  | total loss: [1m[32m0.58101[0m[0m | time: 21.927s
[2K
| Adam | epoch: 012 | loss: 0.58101 - acc: 0.6996 -- iter: 1056/1980
[A[ATraining Step: 716  | total loss: [1m[32m0.56823[0m[0m | time: 22.556s
[2K
| Adam | epoch: 012 | loss: 0.56823 - acc: 0.7202 -- iter: 1088/1980
[A[ATraining Step: 717  | total loss: [1m[32m0.55347[0m[0m | time: 23.210s
[2K
| Adam | epoch: 012 | loss: 0.55347 - acc: 0.7357 -- iter: 1120/1980
[A[ATraining Step: 718  | total loss: [1m[32m0.54012[0m[0m | time: 23.905s
[2K
| Adam | epoch: 012 | loss: 0.54012 - acc: 0.7403 -- iter: 1152/1980
[A[ATraining Step: 719  | total loss: [1m[32m0.53818[0m[0m | time: 24.535s
[2K
| Adam | epoch: 012 | loss: 0.53818 - acc: 0.7381 -- iter: 1184/1980
[A[ATraining Step: 720  | total loss: [1m[32m0.53446[0m[0m | time: 25.187s
[2K
| Adam | epoch: 012 | loss: 0.53446 - acc: 0.7393 -- iter: 1216/1980
[A[ATraining Step: 721  | total loss: [1m[32m0.53702[0m[0m | time: 25.826s
[2K
| Adam | epoch: 012 | loss: 0.53702 - acc: 0.7310 -- iter: 1248/1980
[A[ATraining Step: 722  | total loss: [1m[32m0.53536[0m[0m | time: 26.483s
[2K
| Adam | epoch: 012 | loss: 0.53536 - acc: 0.7266 -- iter: 1280/1980
[A[ATraining Step: 723  | total loss: [1m[32m0.53021[0m[0m | time: 27.163s
[2K
| Adam | epoch: 012 | loss: 0.53021 - acc: 0.7321 -- iter: 1312/1980
[A[ATraining Step: 724  | total loss: [1m[32m0.52433[0m[0m | time: 27.816s
[2K
| Adam | epoch: 012 | loss: 0.52433 - acc: 0.7370 -- iter: 1344/1980
[A[ATraining Step: 725  | total loss: [1m[32m0.51230[0m[0m | time: 28.504s
[2K
| Adam | epoch: 012 | loss: 0.51230 - acc: 0.7508 -- iter: 1376/1980
[A[ATraining Step: 726  | total loss: [1m[32m0.51430[0m[0m | time: 29.182s
[2K
| Adam | epoch: 012 | loss: 0.51430 - acc: 0.7476 -- iter: 1408/1980
[A[ATraining Step: 727  | total loss: [1m[32m0.52106[0m[0m | time: 29.871s
[2K
| Adam | epoch: 012 | loss: 0.52106 - acc: 0.7510 -- iter: 1440/1980
[A[ATraining Step: 728  | total loss: [1m[32m0.51670[0m[0m | time: 30.543s
[2K
| Adam | epoch: 012 | loss: 0.51670 - acc: 0.7603 -- iter: 1472/1980
[A[ATraining Step: 729  | total loss: [1m[32m0.51890[0m[0m | time: 31.194s
[2K
| Adam | epoch: 012 | loss: 0.51890 - acc: 0.7624 -- iter: 1504/1980
[A[ATraining Step: 730  | total loss: [1m[32m0.52145[0m[0m | time: 31.862s
[2K
| Adam | epoch: 012 | loss: 0.52145 - acc: 0.7611 -- iter: 1536/1980
[A[ATraining Step: 731  | total loss: [1m[32m0.52914[0m[0m | time: 32.521s
[2K
| Adam | epoch: 012 | loss: 0.52914 - acc: 0.7506 -- iter: 1568/1980
[A[ATraining Step: 732  | total loss: [1m[32m0.52902[0m[0m | time: 33.232s
[2K
| Adam | epoch: 012 | loss: 0.52902 - acc: 0.7506 -- iter: 1600/1980
[A[ATraining Step: 733  | total loss: [1m[32m0.52279[0m[0m | time: 33.900s
[2K
| Adam | epoch: 012 | loss: 0.52279 - acc: 0.7536 -- iter: 1632/1980
[A[ATraining Step: 734  | total loss: [1m[32m0.51371[0m[0m | time: 34.530s
[2K
| Adam | epoch: 012 | loss: 0.51371 - acc: 0.7626 -- iter: 1664/1980
[A[ATraining Step: 735  | total loss: [1m[32m0.51790[0m[0m | time: 35.183s
[2K
| Adam | epoch: 012 | loss: 0.51790 - acc: 0.7583 -- iter: 1696/1980
[A[ATraining Step: 736  | total loss: [1m[32m0.51135[0m[0m | time: 35.832s
[2K
| Adam | epoch: 012 | loss: 0.51135 - acc: 0.7668 -- iter: 1728/1980
[A[ATraining Step: 737  | total loss: [1m[32m0.52270[0m[0m | time: 36.525s
[2K
| Adam | epoch: 012 | loss: 0.52270 - acc: 0.7495 -- iter: 1760/1980
[A[ATraining Step: 738  | total loss: [1m[32m0.52987[0m[0m | time: 37.171s
[2K
| Adam | epoch: 012 | loss: 0.52987 - acc: 0.7402 -- iter: 1792/1980
[A[ATraining Step: 739  | total loss: [1m[32m0.52943[0m[0m | time: 37.832s
[2K
| Adam | epoch: 012 | loss: 0.52943 - acc: 0.7349 -- iter: 1824/1980
[A[ATraining Step: 740  | total loss: [1m[32m0.53767[0m[0m | time: 38.502s
[2K
| Adam | epoch: 012 | loss: 0.53767 - acc: 0.7302 -- iter: 1856/1980
[A[ATraining Step: 741  | total loss: [1m[32m0.52042[0m[0m | time: 39.171s
[2K
| Adam | epoch: 012 | loss: 0.52042 - acc: 0.7415 -- iter: 1888/1980
[A[ATraining Step: 742  | total loss: [1m[32m0.53744[0m[0m | time: 39.859s
[2K
| Adam | epoch: 012 | loss: 0.53744 - acc: 0.7205 -- iter: 1920/1980
[A[ATraining Step: 743  | total loss: [1m[32m0.54110[0m[0m | time: 40.551s
[2K
| Adam | epoch: 012 | loss: 0.54110 - acc: 0.7234 -- iter: 1952/1980
[A[ATraining Step: 744  | total loss: [1m[32m0.53482[0m[0m | time: 43.433s
[2K
| Adam | epoch: 012 | loss: 0.53482 - acc: 0.7230 | val_loss: 0.56401 - val_acc: 0.7157 -- iter: 1980/1980
--
Training Step: 745  | total loss: [1m[32m0.54419[0m[0m | time: 0.721s
[2K
| Adam | epoch: 013 | loss: 0.54419 - acc: 0.7132 -- iter: 0032/1980
[A[ATraining Step: 746  | total loss: [1m[32m0.54401[0m[0m | time: 1.406s
[2K
| Adam | epoch: 013 | loss: 0.54401 - acc: 0.7075 -- iter: 0064/1980
[A[ATraining Step: 747  | total loss: [1m[32m0.52940[0m[0m | time: 2.070s
[2K
| Adam | epoch: 013 | loss: 0.52940 - acc: 0.7211 -- iter: 0096/1980
[A[ATraining Step: 748  | total loss: [1m[32m0.53583[0m[0m | time: 2.751s
[2K
| Adam | epoch: 013 | loss: 0.53583 - acc: 0.7178 -- iter: 0128/1980
[A[ATraining Step: 749  | total loss: [1m[32m0.53805[0m[0m | time: 3.421s
[2K
| Adam | epoch: 013 | loss: 0.53805 - acc: 0.7241 -- iter: 0160/1980
[A[ATraining Step: 750  | total loss: [1m[32m0.53992[0m[0m | time: 4.071s
[2K
| Adam | epoch: 013 | loss: 0.53992 - acc: 0.7298 -- iter: 0192/1980
[A[ATraining Step: 751  | total loss: [1m[32m0.53577[0m[0m | time: 4.694s
[2K
| Adam | epoch: 013 | loss: 0.53577 - acc: 0.7381 -- iter: 0224/1980
[A[ATraining Step: 752  | total loss: [1m[32m0.53751[0m[0m | time: 5.362s
[2K
| Adam | epoch: 013 | loss: 0.53751 - acc: 0.7393 -- iter: 0256/1980
[A[ATraining Step: 753  | total loss: [1m[32m0.53975[0m[0m | time: 6.039s
[2K
| Adam | epoch: 013 | loss: 0.53975 - acc: 0.7310 -- iter: 0288/1980
[A[ATraining Step: 754  | total loss: [1m[32m0.53491[0m[0m | time: 6.745s
[2K
| Adam | epoch: 013 | loss: 0.53491 - acc: 0.7391 -- iter: 0320/1980
[A[ATraining Step: 755  | total loss: [1m[32m0.53211[0m[0m | time: 7.365s
[2K
| Adam | epoch: 013 | loss: 0.53211 - acc: 0.7402 -- iter: 0352/1980
[A[ATraining Step: 756  | total loss: [1m[32m0.53919[0m[0m | time: 7.940s
[2K
| Adam | epoch: 013 | loss: 0.53919 - acc: 0.7305 -- iter: 0384/1980
[A[ATraining Step: 757  | total loss: [1m[32m0.54438[0m[0m | time: 8.607s
[2K
| Adam | epoch: 013 | loss: 0.54438 - acc: 0.7181 -- iter: 0416/1980
[A[ATraining Step: 758  | total loss: [1m[32m0.53664[0m[0m | time: 9.295s
[2K
| Adam | epoch: 013 | loss: 0.53664 - acc: 0.7182 -- iter: 0448/1980
[A[ATraining Step: 759  | total loss: [1m[32m0.53125[0m[0m | time: 9.980s
[2K
| Adam | epoch: 013 | loss: 0.53125 - acc: 0.7245 -- iter: 0480/1980
[A[ATraining Step: 760  | total loss: [1m[32m0.54942[0m[0m | time: 10.657s
[2K
| Adam | epoch: 013 | loss: 0.54942 - acc: 0.7083 -- iter: 0512/1980
[A[ATraining Step: 761  | total loss: [1m[32m0.53776[0m[0m | time: 11.347s
[2K
| Adam | epoch: 013 | loss: 0.53776 - acc: 0.7187 -- iter: 0544/1980
[A[ATraining Step: 762  | total loss: [1m[32m0.52525[0m[0m | time: 11.978s
[2K
| Adam | epoch: 013 | loss: 0.52525 - acc: 0.7281 -- iter: 0576/1980
[A[ATraining Step: 763  | total loss: [1m[32m0.52145[0m[0m | time: 12.648s
[2K
| Adam | epoch: 013 | loss: 0.52145 - acc: 0.7303 -- iter: 0608/1980
[A[ATraining Step: 764  | total loss: [1m[32m0.52948[0m[0m | time: 13.293s
[2K
| Adam | epoch: 013 | loss: 0.52948 - acc: 0.7198 -- iter: 0640/1980
[A[ATraining Step: 765  | total loss: [1m[32m0.52549[0m[0m | time: 13.915s
[2K
| Adam | epoch: 013 | loss: 0.52549 - acc: 0.7290 -- iter: 0672/1980
[A[ATraining Step: 766  | total loss: [1m[32m0.52931[0m[0m | time: 14.594s
[2K
| Adam | epoch: 013 | loss: 0.52931 - acc: 0.7311 -- iter: 0704/1980
[A[ATraining Step: 767  | total loss: [1m[32m0.53027[0m[0m | time: 15.303s
[2K
| Adam | epoch: 013 | loss: 0.53027 - acc: 0.7299 -- iter: 0736/1980
[A[ATraining Step: 768  | total loss: [1m[32m0.52656[0m[0m | time: 15.963s
[2K
| Adam | epoch: 013 | loss: 0.52656 - acc: 0.7382 -- iter: 0768/1980
[A[ATraining Step: 769  | total loss: [1m[32m0.51697[0m[0m | time: 16.615s
[2K
| Adam | epoch: 013 | loss: 0.51697 - acc: 0.7518 -- iter: 0800/1980
[A[ATraining Step: 770  | total loss: [1m[32m0.51829[0m[0m | time: 17.265s
[2K
| Adam | epoch: 013 | loss: 0.51829 - acc: 0.7579 -- iter: 0832/1980
[A[ATraining Step: 771  | total loss: [1m[32m0.52240[0m[0m | time: 17.883s
[2K
| Adam | epoch: 013 | loss: 0.52240 - acc: 0.7602 -- iter: 0864/1980
[A[ATraining Step: 772  | total loss: [1m[32m0.52948[0m[0m | time: 18.540s
[2K
| Adam | epoch: 013 | loss: 0.52948 - acc: 0.7592 -- iter: 0896/1980
[A[ATraining Step: 773  | total loss: [1m[32m0.53765[0m[0m | time: 19.233s
[2K
| Adam | epoch: 013 | loss: 0.53765 - acc: 0.7427 -- iter: 0928/1980
[A[ATraining Step: 774  | total loss: [1m[32m0.54148[0m[0m | time: 19.899s
[2K
| Adam | epoch: 013 | loss: 0.54148 - acc: 0.7403 -- iter: 0960/1980
[A[ATraining Step: 775  | total loss: [1m[32m0.52609[0m[0m | time: 20.551s
[2K
| Adam | epoch: 013 | loss: 0.52609 - acc: 0.7538 -- iter: 0992/1980
[A[ATraining Step: 776  | total loss: [1m[32m0.51694[0m[0m | time: 21.247s
[2K
| Adam | epoch: 013 | loss: 0.51694 - acc: 0.7565 -- iter: 1024/1980
[A[ATraining Step: 777  | total loss: [1m[32m0.52688[0m[0m | time: 21.899s
[2K
| Adam | epoch: 013 | loss: 0.52688 - acc: 0.7559 -- iter: 1056/1980
[A[ATraining Step: 778  | total loss: [1m[32m0.52480[0m[0m | time: 22.521s
[2K
| Adam | epoch: 013 | loss: 0.52480 - acc: 0.7584 -- iter: 1088/1980
[A[ATraining Step: 779  | total loss: [1m[32m0.52842[0m[0m | time: 23.214s
[2K
| Adam | epoch: 013 | loss: 0.52842 - acc: 0.7544 -- iter: 1120/1980
[A[ATraining Step: 780  | total loss: [1m[32m0.54125[0m[0m | time: 23.834s
[2K
| Adam | epoch: 013 | loss: 0.54125 - acc: 0.7446 -- iter: 1152/1980
[A[ATraining Step: 781  | total loss: [1m[32m0.53916[0m[0m | time: 24.491s
[2K
| Adam | epoch: 013 | loss: 0.53916 - acc: 0.7451 -- iter: 1184/1980
[A[ATraining Step: 782  | total loss: [1m[32m0.53360[0m[0m | time: 25.112s
[2K
| Adam | epoch: 013 | loss: 0.53360 - acc: 0.7456 -- iter: 1216/1980
[A[ATraining Step: 783  | total loss: [1m[32m0.52381[0m[0m | time: 25.765s
[2K
| Adam | epoch: 013 | loss: 0.52381 - acc: 0.7492 -- iter: 1248/1980
[A[ATraining Step: 784  | total loss: [1m[32m0.53194[0m[0m | time: 26.402s
[2K
| Adam | epoch: 013 | loss: 0.53194 - acc: 0.7430 -- iter: 1280/1980
[A[ATraining Step: 785  | total loss: [1m[32m0.53768[0m[0m | time: 27.100s
[2K
| Adam | epoch: 013 | loss: 0.53768 - acc: 0.7406 -- iter: 1312/1980
[A[ATraining Step: 786  | total loss: [1m[32m0.52959[0m[0m | time: 27.736s
[2K
| Adam | epoch: 013 | loss: 0.52959 - acc: 0.7509 -- iter: 1344/1980
[A[ATraining Step: 787  | total loss: [1m[32m0.53178[0m[0m | time: 28.398s
[2K
| Adam | epoch: 013 | loss: 0.53178 - acc: 0.7508 -- iter: 1376/1980
[A[ATraining Step: 788  | total loss: [1m[32m0.51849[0m[0m | time: 29.023s
[2K
| Adam | epoch: 013 | loss: 0.51849 - acc: 0.7632 -- iter: 1408/1980
[A[ATraining Step: 789  | total loss: [1m[32m0.51757[0m[0m | time: 29.675s
[2K
| Adam | epoch: 013 | loss: 0.51757 - acc: 0.7682 -- iter: 1440/1980
[A[ATraining Step: 790  | total loss: [1m[32m0.51148[0m[0m | time: 30.324s
[2K
| Adam | epoch: 013 | loss: 0.51148 - acc: 0.7695 -- iter: 1472/1980
[A[ATraining Step: 791  | total loss: [1m[32m0.51738[0m[0m | time: 30.983s
[2K
| Adam | epoch: 013 | loss: 0.51738 - acc: 0.7675 -- iter: 1504/1980
[A[ATraining Step: 792  | total loss: [1m[32m0.51163[0m[0m | time: 31.615s
[2K
| Adam | epoch: 013 | loss: 0.51163 - acc: 0.7658 -- iter: 1536/1980
[A[ATraining Step: 793  | total loss: [1m[32m0.50869[0m[0m | time: 32.264s
[2K
| Adam | epoch: 013 | loss: 0.50869 - acc: 0.7611 -- iter: 1568/1980
[A[ATraining Step: 794  | total loss: [1m[32m0.51881[0m[0m | time: 32.920s
[2K
| Adam | epoch: 013 | loss: 0.51881 - acc: 0.7506 -- iter: 1600/1980
[A[ATraining Step: 795  | total loss: [1m[32m0.51375[0m[0m | time: 33.561s
[2K
| Adam | epoch: 013 | loss: 0.51375 - acc: 0.7599 -- iter: 1632/1980
[A[ATraining Step: 796  | total loss: [1m[32m0.52229[0m[0m | time: 34.216s
[2K
| Adam | epoch: 013 | loss: 0.52229 - acc: 0.7558 -- iter: 1664/1980
[A[ATraining Step: 797  | total loss: [1m[32m0.51683[0m[0m | time: 34.882s
[2K
| Adam | epoch: 013 | loss: 0.51683 - acc: 0.7583 -- iter: 1696/1980
[A[ATraining Step: 798  | total loss: [1m[32m0.53028[0m[0m | time: 35.547s
[2K
| Adam | epoch: 013 | loss: 0.53028 - acc: 0.7481 -- iter: 1728/1980
[A[ATraining Step: 799  | total loss: [1m[32m0.52991[0m[0m | time: 36.188s
[2K
| Adam | epoch: 013 | loss: 0.52991 - acc: 0.7421 -- iter: 1760/1980
[A[ATraining Step: 800  | total loss: [1m[32m0.53329[0m[0m | time: 39.167s
[2K
| Adam | epoch: 013 | loss: 0.53329 - acc: 0.7397 | val_loss: 0.58154 - val_acc: 0.6947 -- iter: 1792/1980
--
Training Step: 801  | total loss: [1m[32m0.52711[0m[0m | time: 39.819s
[2K
| Adam | epoch: 013 | loss: 0.52711 - acc: 0.7376 -- iter: 1824/1980
[A[ATraining Step: 802  | total loss: [1m[32m0.53239[0m[0m | time: 40.518s
[2K
| Adam | epoch: 013 | loss: 0.53239 - acc: 0.7295 -- iter: 1856/1980
[A[ATraining Step: 803  | total loss: [1m[32m0.52380[0m[0m | time: 41.217s
[2K
| Adam | epoch: 013 | loss: 0.52380 - acc: 0.7440 -- iter: 1888/1980
[A[ATraining Step: 804  | total loss: [1m[32m0.52113[0m[0m | time: 41.914s
[2K
| Adam | epoch: 013 | loss: 0.52113 - acc: 0.7446 -- iter: 1920/1980
[A[ATraining Step: 805  | total loss: [1m[32m0.52717[0m[0m | time: 42.567s
[2K
| Adam | epoch: 013 | loss: 0.52717 - acc: 0.7421 -- iter: 1952/1980
[A[ATraining Step: 806  | total loss: [1m[32m0.52451[0m[0m | time: 45.366s
[2K
| Adam | epoch: 013 | loss: 0.52451 - acc: 0.7460 | val_loss: 0.53996 - val_acc: 0.7383 -- iter: 1980/1980
--
Training Step: 807  | total loss: [1m[32m0.51109[0m[0m | time: 0.660s
[2K
| Adam | epoch: 014 | loss: 0.51109 - acc: 0.7589 -- iter: 0032/1980
[A[ATraining Step: 808  | total loss: [1m[32m0.52278[0m[0m | time: 1.286s
[2K
| Adam | epoch: 014 | loss: 0.52278 - acc: 0.7455 -- iter: 0064/1980
[A[ATraining Step: 809  | total loss: [1m[32m0.52782[0m[0m | time: 1.954s
[2K
| Adam | epoch: 014 | loss: 0.52782 - acc: 0.7397 -- iter: 0096/1980
[A[ATraining Step: 810  | total loss: [1m[32m0.52191[0m[0m | time: 2.631s
[2K
| Adam | epoch: 014 | loss: 0.52191 - acc: 0.7407 -- iter: 0128/1980
[A[ATraining Step: 811  | total loss: [1m[32m0.51734[0m[0m | time: 3.285s
[2K
| Adam | epoch: 014 | loss: 0.51734 - acc: 0.7448 -- iter: 0160/1980
[A[ATraining Step: 812  | total loss: [1m[32m0.52372[0m[0m | time: 3.902s
[2K
| Adam | epoch: 014 | loss: 0.52372 - acc: 0.7390 -- iter: 0192/1980
[A[ATraining Step: 813  | total loss: [1m[32m0.54058[0m[0m | time: 4.556s
[2K
| Adam | epoch: 014 | loss: 0.54058 - acc: 0.7308 -- iter: 0224/1980
[A[ATraining Step: 814  | total loss: [1m[32m0.56233[0m[0m | time: 5.197s
[2K
| Adam | epoch: 014 | loss: 0.56233 - acc: 0.7171 -- iter: 0256/1980
[A[ATraining Step: 815  | total loss: [1m[32m0.54779[0m[0m | time: 5.818s
[2K
| Adam | epoch: 014 | loss: 0.54779 - acc: 0.7329 -- iter: 0288/1980
[A[ATraining Step: 816  | total loss: [1m[32m0.54292[0m[0m | time: 6.444s
[2K
| Adam | epoch: 014 | loss: 0.54292 - acc: 0.7346 -- iter: 0320/1980
[A[ATraining Step: 817  | total loss: [1m[32m0.54685[0m[0m | time: 7.097s
[2K
| Adam | epoch: 014 | loss: 0.54685 - acc: 0.7267 -- iter: 0352/1980
[A[ATraining Step: 818  | total loss: [1m[32m0.54603[0m[0m | time: 7.686s
[2K
| Adam | epoch: 014 | loss: 0.54603 - acc: 0.7291 -- iter: 0384/1980
[A[ATraining Step: 819  | total loss: [1m[32m0.53971[0m[0m | time: 8.305s
[2K
| Adam | epoch: 014 | loss: 0.53971 - acc: 0.7383 -- iter: 0416/1980
[A[ATraining Step: 820  | total loss: [1m[32m0.53410[0m[0m | time: 8.917s
[2K
| Adam | epoch: 014 | loss: 0.53410 - acc: 0.7466 -- iter: 0448/1980
[A[ATraining Step: 821  | total loss: [1m[32m0.52267[0m[0m | time: 9.583s
[2K
| Adam | epoch: 014 | loss: 0.52267 - acc: 0.7532 -- iter: 0480/1980
[A[ATraining Step: 822  | total loss: [1m[32m0.51714[0m[0m | time: 10.244s
[2K
| Adam | epoch: 014 | loss: 0.51714 - acc: 0.7623 -- iter: 0512/1980
[A[ATraining Step: 823  | total loss: [1m[32m0.51513[0m[0m | time: 10.907s
[2K
| Adam | epoch: 014 | loss: 0.51513 - acc: 0.7642 -- iter: 0544/1980
[A[ATraining Step: 824  | total loss: [1m[32m0.51282[0m[0m | time: 11.577s
[2K
| Adam | epoch: 014 | loss: 0.51282 - acc: 0.7690 -- iter: 0576/1980
[A[ATraining Step: 825  | total loss: [1m[32m0.51346[0m[0m | time: 12.192s
[2K
| Adam | epoch: 014 | loss: 0.51346 - acc: 0.7640 -- iter: 0608/1980
[A[ATraining Step: 826  | total loss: [1m[32m0.51044[0m[0m | time: 12.813s
[2K
| Adam | epoch: 014 | loss: 0.51044 - acc: 0.7688 -- iter: 0640/1980
[A[ATraining Step: 827  | total loss: [1m[32m0.51805[0m[0m | time: 13.470s
[2K
| Adam | epoch: 014 | loss: 0.51805 - acc: 0.7607 -- iter: 0672/1980
[A[ATraining Step: 828  | total loss: [1m[32m0.53230[0m[0m | time: 14.127s
[2K
| Adam | epoch: 014 | loss: 0.53230 - acc: 0.7502 -- iter: 0704/1980
[A[ATraining Step: 829  | total loss: [1m[32m0.52770[0m[0m | time: 14.749s
[2K
| Adam | epoch: 014 | loss: 0.52770 - acc: 0.7502 -- iter: 0736/1980
[A[ATraining Step: 830  | total loss: [1m[32m0.51736[0m[0m | time: 15.448s
[2K
| Adam | epoch: 014 | loss: 0.51736 - acc: 0.7627 -- iter: 0768/1980
[A[ATraining Step: 831  | total loss: [1m[32m0.51046[0m[0m | time: 16.149s
[2K
| Adam | epoch: 014 | loss: 0.51046 - acc: 0.7677 -- iter: 0800/1980
[A[ATraining Step: 832  | total loss: [1m[32m0.50318[0m[0m | time: 16.786s
[2K
| Adam | epoch: 014 | loss: 0.50318 - acc: 0.7722 -- iter: 0832/1980
[A[ATraining Step: 833  | total loss: [1m[32m0.49143[0m[0m | time: 17.500s
[2K
| Adam | epoch: 014 | loss: 0.49143 - acc: 0.7824 -- iter: 0864/1980
[A[ATraining Step: 834  | total loss: [1m[32m0.47948[0m[0m | time: 18.179s
[2K
| Adam | epoch: 014 | loss: 0.47948 - acc: 0.7855 -- iter: 0896/1980
[A[ATraining Step: 835  | total loss: [1m[32m0.46740[0m[0m | time: 18.808s
[2K
| Adam | epoch: 014 | loss: 0.46740 - acc: 0.7975 -- iter: 0928/1980
[A[ATraining Step: 836  | total loss: [1m[32m0.47529[0m[0m | time: 19.452s
[2K
| Adam | epoch: 014 | loss: 0.47529 - acc: 0.7834 -- iter: 0960/1980
[A[ATraining Step: 837  | total loss: [1m[32m0.48063[0m[0m | time: 20.108s
[2K
| Adam | epoch: 014 | loss: 0.48063 - acc: 0.7738 -- iter: 0992/1980
[A[ATraining Step: 838  | total loss: [1m[32m0.48992[0m[0m | time: 20.775s
[2K
| Adam | epoch: 014 | loss: 0.48992 - acc: 0.7652 -- iter: 1024/1980
[A[ATraining Step: 839  | total loss: [1m[32m0.50758[0m[0m | time: 21.399s
[2K
| Adam | epoch: 014 | loss: 0.50758 - acc: 0.7574 -- iter: 1056/1980
[A[ATraining Step: 840  | total loss: [1m[32m0.49827[0m[0m | time: 22.002s
[2K
| Adam | epoch: 014 | loss: 0.49827 - acc: 0.7660 -- iter: 1088/1980
[A[ATraining Step: 841  | total loss: [1m[32m0.49406[0m[0m | time: 22.666s
[2K
| Adam | epoch: 014 | loss: 0.49406 - acc: 0.7676 -- iter: 1120/1980
[A[ATraining Step: 842  | total loss: [1m[32m0.49013[0m[0m | time: 23.309s
[2K
| Adam | epoch: 014 | loss: 0.49013 - acc: 0.7721 -- iter: 1152/1980
[A[ATraining Step: 843  | total loss: [1m[32m0.49146[0m[0m | time: 23.981s
[2K
| Adam | epoch: 014 | loss: 0.49146 - acc: 0.7792 -- iter: 1184/1980
[A[ATraining Step: 844  | total loss: [1m[32m0.50437[0m[0m | time: 24.687s
[2K
| Adam | epoch: 014 | loss: 0.50437 - acc: 0.7763 -- iter: 1216/1980
[A[ATraining Step: 845  | total loss: [1m[32m0.49645[0m[0m | time: 25.396s
[2K
| Adam | epoch: 014 | loss: 0.49645 - acc: 0.7862 -- iter: 1248/1980
[A[ATraining Step: 846  | total loss: [1m[32m0.49264[0m[0m | time: 26.027s
[2K
| Adam | epoch: 014 | loss: 0.49264 - acc: 0.7857 -- iter: 1280/1980
[A[ATraining Step: 847  | total loss: [1m[32m0.49000[0m[0m | time: 26.656s
[2K
| Adam | epoch: 014 | loss: 0.49000 - acc: 0.7852 -- iter: 1312/1980
[A[ATraining Step: 848  | total loss: [1m[32m0.50096[0m[0m | time: 27.270s
[2K
| Adam | epoch: 014 | loss: 0.50096 - acc: 0.7817 -- iter: 1344/1980
[A[ATraining Step: 849  | total loss: [1m[32m0.51510[0m[0m | time: 27.890s
[2K
| Adam | epoch: 014 | loss: 0.51510 - acc: 0.7723 -- iter: 1376/1980
[A[ATraining Step: 850  | total loss: [1m[32m0.50773[0m[0m | time: 28.534s
[2K
| Adam | epoch: 014 | loss: 0.50773 - acc: 0.7732 -- iter: 1408/1980
[A[ATraining Step: 851  | total loss: [1m[32m0.51496[0m[0m | time: 29.229s
[2K
| Adam | epoch: 014 | loss: 0.51496 - acc: 0.7646 -- iter: 1440/1980
[A[ATraining Step: 852  | total loss: [1m[32m0.51789[0m[0m | time: 29.857s
[2K
| Adam | epoch: 014 | loss: 0.51789 - acc: 0.7663 -- iter: 1472/1980
[A[ATraining Step: 853  | total loss: [1m[32m0.51502[0m[0m | time: 30.490s
[2K
| Adam | epoch: 014 | loss: 0.51502 - acc: 0.7709 -- iter: 1504/1980
[A[ATraining Step: 854  | total loss: [1m[32m0.52166[0m[0m | time: 31.167s
[2K
| Adam | epoch: 014 | loss: 0.52166 - acc: 0.7657 -- iter: 1536/1980
[A[ATraining Step: 855  | total loss: [1m[32m0.52671[0m[0m | time: 31.833s
[2K
| Adam | epoch: 014 | loss: 0.52671 - acc: 0.7610 -- iter: 1568/1980
[A[ATraining Step: 856  | total loss: [1m[32m0.52573[0m[0m | time: 32.496s
[2K
| Adam | epoch: 014 | loss: 0.52573 - acc: 0.7568 -- iter: 1600/1980
[A[ATraining Step: 857  | total loss: [1m[32m0.52720[0m[0m | time: 33.147s
[2K
| Adam | epoch: 014 | loss: 0.52720 - acc: 0.7498 -- iter: 1632/1980
[A[ATraining Step: 858  | total loss: [1m[32m0.51747[0m[0m | time: 33.849s
[2K
| Adam | epoch: 014 | loss: 0.51747 - acc: 0.7499 -- iter: 1664/1980
[A[ATraining Step: 859  | total loss: [1m[32m0.51132[0m[0m | time: 34.496s
[2K
| Adam | epoch: 014 | loss: 0.51132 - acc: 0.7499 -- iter: 1696/1980
[A[ATraining Step: 860  | total loss: [1m[32m0.51044[0m[0m | time: 35.196s
[2K
| Adam | epoch: 014 | loss: 0.51044 - acc: 0.7468 -- iter: 1728/1980
[A[ATraining Step: 861  | total loss: [1m[32m0.49048[0m[0m | time: 35.873s
[2K
| Adam | epoch: 014 | loss: 0.49048 - acc: 0.7627 -- iter: 1760/1980
[A[ATraining Step: 862  | total loss: [1m[32m0.49450[0m[0m | time: 36.583s
[2K
| Adam | epoch: 014 | loss: 0.49450 - acc: 0.7521 -- iter: 1792/1980
[A[ATraining Step: 863  | total loss: [1m[32m0.49784[0m[0m | time: 37.256s
[2K
| Adam | epoch: 014 | loss: 0.49784 - acc: 0.7550 -- iter: 1824/1980
[A[ATraining Step: 864  | total loss: [1m[32m0.50367[0m[0m | time: 37.931s
[2K
| Adam | epoch: 014 | loss: 0.50367 - acc: 0.7514 -- iter: 1856/1980
[A[ATraining Step: 865  | total loss: [1m[32m0.49003[0m[0m | time: 38.578s
[2K
| Adam | epoch: 014 | loss: 0.49003 - acc: 0.7606 -- iter: 1888/1980
[A[ATraining Step: 866  | total loss: [1m[32m0.51148[0m[0m | time: 39.272s
[2K
| Adam | epoch: 014 | loss: 0.51148 - acc: 0.7408 -- iter: 1920/1980
[A[ATraining Step: 867  | total loss: [1m[32m0.51576[0m[0m | time: 39.954s
[2K
| Adam | epoch: 014 | loss: 0.51576 - acc: 0.7386 -- iter: 1952/1980
[A[ATraining Step: 868  | total loss: [1m[32m0.52566[0m[0m | time: 43.179s
[2K
| Adam | epoch: 014 | loss: 0.52566 - acc: 0.7335 | val_loss: 0.53181 - val_acc: 0.7464 -- iter: 1980/1980
--
Training Step: 869  | total loss: [1m[32m0.51699[0m[0m | time: 0.661s
[2K
| Adam | epoch: 015 | loss: 0.51699 - acc: 0.7414 -- iter: 0032/1980
[A[ATraining Step: 870  | total loss: [1m[32m0.52088[0m[0m | time: 1.344s
[2K
| Adam | epoch: 015 | loss: 0.52088 - acc: 0.7422 -- iter: 0064/1980
[A[ATraining Step: 871  | total loss: [1m[32m0.51655[0m[0m | time: 2.017s
[2K
| Adam | epoch: 015 | loss: 0.51655 - acc: 0.7430 -- iter: 0096/1980
[A[ATraining Step: 872  | total loss: [1m[32m0.51556[0m[0m | time: 2.701s
[2K
| Adam | epoch: 015 | loss: 0.51556 - acc: 0.7437 -- iter: 0128/1980
[A[ATraining Step: 873  | total loss: [1m[32m0.50721[0m[0m | time: 3.403s
[2K
| Adam | epoch: 015 | loss: 0.50721 - acc: 0.7568 -- iter: 0160/1980
[A[ATraining Step: 874  | total loss: [1m[32m0.50532[0m[0m | time: 4.097s
[2K
| Adam | epoch: 015 | loss: 0.50532 - acc: 0.7655 -- iter: 0192/1980
[A[ATraining Step: 875  | total loss: [1m[32m0.51757[0m[0m | time: 4.789s
[2K
| Adam | epoch: 015 | loss: 0.51757 - acc: 0.7484 -- iter: 0224/1980
[A[ATraining Step: 876  | total loss: [1m[32m0.51263[0m[0m | time: 5.481s
[2K
| Adam | epoch: 015 | loss: 0.51263 - acc: 0.7548 -- iter: 0256/1980
[A[ATraining Step: 877  | total loss: [1m[32m0.51516[0m[0m | time: 6.184s
[2K
| Adam | epoch: 015 | loss: 0.51516 - acc: 0.7512 -- iter: 0288/1980
[A[ATraining Step: 878  | total loss: [1m[32m0.50978[0m[0m | time: 6.889s
[2K
| Adam | epoch: 015 | loss: 0.50978 - acc: 0.7573 -- iter: 0320/1980
[A[ATraining Step: 879  | total loss: [1m[32m0.51263[0m[0m | time: 7.571s
[2K
| Adam | epoch: 015 | loss: 0.51263 - acc: 0.7503 -- iter: 0352/1980
[A[ATraining Step: 880  | total loss: [1m[32m0.51749[0m[0m | time: 8.233s
[2K
| Adam | epoch: 015 | loss: 0.51749 - acc: 0.7472 -- iter: 0384/1980
[A[ATraining Step: 881  | total loss: [1m[32m0.51375[0m[0m | time: 8.804s
[2K
| Adam | epoch: 015 | loss: 0.51375 - acc: 0.7537 -- iter: 0416/1980
[A[ATraining Step: 882  | total loss: [1m[32m0.51068[0m[0m | time: 9.393s
[2K
| Adam | epoch: 015 | loss: 0.51068 - acc: 0.7640 -- iter: 0448/1980
[A[ATraining Step: 883  | total loss: [1m[32m0.50776[0m[0m | time: 10.077s
[2K
| Adam | epoch: 015 | loss: 0.50776 - acc: 0.7734 -- iter: 0480/1980
[A[ATraining Step: 884  | total loss: [1m[32m0.51521[0m[0m | time: 10.732s
[2K
| Adam | epoch: 015 | loss: 0.51521 - acc: 0.7679 -- iter: 0512/1980
[A[ATraining Step: 885  | total loss: [1m[32m0.50081[0m[0m | time: 11.402s
[2K
| Adam | epoch: 015 | loss: 0.50081 - acc: 0.7786 -- iter: 0544/1980
[A[ATraining Step: 886  | total loss: [1m[32m0.50733[0m[0m | time: 12.068s
[2K
| Adam | epoch: 015 | loss: 0.50733 - acc: 0.7695 -- iter: 0576/1980
[A[ATraining Step: 887  | total loss: [1m[32m0.51056[0m[0m | time: 12.733s
[2K
| Adam | epoch: 015 | loss: 0.51056 - acc: 0.7644 -- iter: 0608/1980
[A[ATraining Step: 888  | total loss: [1m[32m0.51543[0m[0m | time: 13.416s
[2K
| Adam | epoch: 015 | loss: 0.51543 - acc: 0.7599 -- iter: 0640/1980
[A[ATraining Step: 889  | total loss: [1m[32m0.51599[0m[0m | time: 14.080s
[2K
| Adam | epoch: 015 | loss: 0.51599 - acc: 0.7495 -- iter: 0672/1980
[A[ATraining Step: 890  | total loss: [1m[32m0.50937[0m[0m | time: 14.719s
[2K
| Adam | epoch: 015 | loss: 0.50937 - acc: 0.7589 -- iter: 0704/1980
[A[ATraining Step: 891  | total loss: [1m[32m0.51075[0m[0m | time: 15.420s
[2K
| Adam | epoch: 015 | loss: 0.51075 - acc: 0.7580 -- iter: 0736/1980
[A[ATraining Step: 892  | total loss: [1m[32m0.50346[0m[0m | time: 16.090s
[2K
| Adam | epoch: 015 | loss: 0.50346 - acc: 0.7572 -- iter: 0768/1980
[A[ATraining Step: 893  | total loss: [1m[32m0.49503[0m[0m | time: 16.763s
[2K
| Adam | epoch: 015 | loss: 0.49503 - acc: 0.7628 -- iter: 0800/1980
[A[ATraining Step: 894  | total loss: [1m[32m0.49856[0m[0m | time: 17.422s
[2K
| Adam | epoch: 015 | loss: 0.49856 - acc: 0.7615 -- iter: 0832/1980
[A[ATraining Step: 895  | total loss: [1m[32m0.50782[0m[0m | time: 18.058s
[2K
| Adam | epoch: 015 | loss: 0.50782 - acc: 0.7510 -- iter: 0864/1980
[A[ATraining Step: 896  | total loss: [1m[32m0.50587[0m[0m | time: 18.724s
[2K
| Adam | epoch: 015 | loss: 0.50587 - acc: 0.7571 -- iter: 0896/1980
[A[ATraining Step: 897  | total loss: [1m[32m0.49832[0m[0m | time: 19.403s
[2K
| Adam | epoch: 015 | loss: 0.49832 - acc: 0.7626 -- iter: 0928/1980
[A[ATraining Step: 898  | total loss: [1m[32m0.48923[0m[0m | time: 20.073s
[2K
| Adam | epoch: 015 | loss: 0.48923 - acc: 0.7645 -- iter: 0960/1980
[A[ATraining Step: 899  | total loss: [1m[32m0.48148[0m[0m | time: 20.770s
[2K
| Adam | epoch: 015 | loss: 0.48148 - acc: 0.7756 -- iter: 0992/1980
[A[ATraining Step: 900  | total loss: [1m[32m0.46875[0m[0m | time: 21.476s
[2K
| Adam | epoch: 015 | loss: 0.46875 - acc: 0.7824 -- iter: 1024/1980
[A[ATraining Step: 901  | total loss: [1m[32m0.48771[0m[0m | time: 22.161s
[2K
| Adam | epoch: 015 | loss: 0.48771 - acc: 0.7729 -- iter: 1056/1980
[A[ATraining Step: 902  | total loss: [1m[32m0.48312[0m[0m | time: 22.821s
[2K
| Adam | epoch: 015 | loss: 0.48312 - acc: 0.7737 -- iter: 1088/1980
[A[ATraining Step: 903  | total loss: [1m[32m0.47673[0m[0m | time: 23.481s
[2K
| Adam | epoch: 015 | loss: 0.47673 - acc: 0.7807 -- iter: 1120/1980
[A[ATraining Step: 904  | total loss: [1m[32m0.48229[0m[0m | time: 24.171s
[2K
| Adam | epoch: 015 | loss: 0.48229 - acc: 0.7808 -- iter: 1152/1980
[A[ATraining Step: 905  | total loss: [1m[32m0.49052[0m[0m | time: 24.885s
[2K
| Adam | epoch: 015 | loss: 0.49052 - acc: 0.7840 -- iter: 1184/1980
[A[ATraining Step: 906  | total loss: [1m[32m0.48445[0m[0m | time: 25.619s
[2K
| Adam | epoch: 015 | loss: 0.48445 - acc: 0.7837 -- iter: 1216/1980
[A[ATraining Step: 907  | total loss: [1m[32m0.47201[0m[0m | time: 26.292s
[2K
| Adam | epoch: 015 | loss: 0.47201 - acc: 0.7928 -- iter: 1248/1980
[A[ATraining Step: 908  | total loss: [1m[32m0.46270[0m[0m | time: 26.983s
[2K
| Adam | epoch: 015 | loss: 0.46270 - acc: 0.7979 -- iter: 1280/1980
[A[ATraining Step: 909  | total loss: [1m[32m0.46192[0m[0m | time: 27.705s
[2K
| Adam | epoch: 015 | loss: 0.46192 - acc: 0.7994 -- iter: 1312/1980
[A[ATraining Step: 910  | total loss: [1m[32m0.45895[0m[0m | time: 28.373s
[2K
| Adam | epoch: 015 | loss: 0.45895 - acc: 0.8007 -- iter: 1344/1980
[A[ATraining Step: 911  | total loss: [1m[32m0.44151[0m[0m | time: 29.035s
[2K
| Adam | epoch: 015 | loss: 0.44151 - acc: 0.8144 -- iter: 1376/1980
[A[ATraining Step: 912  | total loss: [1m[32m0.45984[0m[0m | time: 29.721s
[2K
| Adam | epoch: 015 | loss: 0.45984 - acc: 0.8048 -- iter: 1408/1980
[A[ATraining Step: 913  | total loss: [1m[32m0.45797[0m[0m | time: 30.425s
[2K
| Adam | epoch: 015 | loss: 0.45797 - acc: 0.7993 -- iter: 1440/1980
[A[ATraining Step: 914  | total loss: [1m[32m0.47292[0m[0m | time: 31.140s
[2K
| Adam | epoch: 015 | loss: 0.47292 - acc: 0.7881 -- iter: 1472/1980
[A[ATraining Step: 915  | total loss: [1m[32m0.47164[0m[0m | time: 31.819s
[2K
| Adam | epoch: 015 | loss: 0.47164 - acc: 0.7937 -- iter: 1504/1980
[A[ATraining Step: 916  | total loss: [1m[32m0.46691[0m[0m | time: 32.493s
[2K
| Adam | epoch: 015 | loss: 0.46691 - acc: 0.7987 -- iter: 1536/1980
[A[ATraining Step: 917  | total loss: [1m[32m0.47493[0m[0m | time: 33.150s
[2K
| Adam | epoch: 015 | loss: 0.47493 - acc: 0.7970 -- iter: 1568/1980
[A[ATraining Step: 918  | total loss: [1m[32m0.47419[0m[0m | time: 33.783s
[2K
| Adam | epoch: 015 | loss: 0.47419 - acc: 0.7923 -- iter: 1600/1980
[A[ATraining Step: 919  | total loss: [1m[32m0.46854[0m[0m | time: 34.478s
[2K
| Adam | epoch: 015 | loss: 0.46854 - acc: 0.7943 -- iter: 1632/1980
[A[ATraining Step: 920  | total loss: [1m[32m0.47169[0m[0m | time: 35.114s
[2K
| Adam | epoch: 015 | loss: 0.47169 - acc: 0.7836 -- iter: 1664/1980
[A[ATraining Step: 921  | total loss: [1m[32m0.47148[0m[0m | time: 35.730s
[2K
| Adam | epoch: 015 | loss: 0.47148 - acc: 0.7865 -- iter: 1696/1980
[A[ATraining Step: 922  | total loss: [1m[32m0.47215[0m[0m | time: 36.390s
[2K
| Adam | epoch: 015 | loss: 0.47215 - acc: 0.7860 -- iter: 1728/1980
[A[ATraining Step: 923  | total loss: [1m[32m0.46571[0m[0m | time: 37.045s
[2K
| Adam | epoch: 015 | loss: 0.46571 - acc: 0.7918 -- iter: 1760/1980
[A[ATraining Step: 924  | total loss: [1m[32m0.46379[0m[0m | time: 37.737s
[2K
| Adam | epoch: 015 | loss: 0.46379 - acc: 0.7907 -- iter: 1792/1980
[A[ATraining Step: 925  | total loss: [1m[32m0.47498[0m[0m | time: 38.391s
[2K
| Adam | epoch: 015 | loss: 0.47498 - acc: 0.7866 -- iter: 1824/1980
[A[ATraining Step: 926  | total loss: [1m[32m0.47544[0m[0m | time: 39.049s
[2K
| Adam | epoch: 015 | loss: 0.47544 - acc: 0.7798 -- iter: 1856/1980
[A[ATraining Step: 927  | total loss: [1m[32m0.47370[0m[0m | time: 39.714s
[2K
| Adam | epoch: 015 | loss: 0.47370 - acc: 0.7769 -- iter: 1888/1980
[A[ATraining Step: 928  | total loss: [1m[32m0.47248[0m[0m | time: 40.367s
[2K
| Adam | epoch: 015 | loss: 0.47248 - acc: 0.7835 -- iter: 1920/1980
[A[ATraining Step: 929  | total loss: [1m[32m0.46976[0m[0m | time: 41.027s
[2K
| Adam | epoch: 015 | loss: 0.46976 - acc: 0.7864 -- iter: 1952/1980
[A[ATraining Step: 930  | total loss: [1m[32m0.47223[0m[0m | time: 43.986s
[2K
| Adam | epoch: 015 | loss: 0.47223 - acc: 0.7890 | val_loss: 0.53574 - val_acc: 0.7512 -- iter: 1980/1980
--
Training Step: 931  | total loss: [1m[32m0.46734[0m[0m | time: 0.665s
[2K
| Adam | epoch: 016 | loss: 0.46734 - acc: 0.7914 -- iter: 0032/1980
[A[ATraining Step: 932  | total loss: [1m[32m0.49283[0m[0m | time: 1.303s
[2K
| Adam | epoch: 016 | loss: 0.49283 - acc: 0.7748 -- iter: 0064/1980
[A[ATraining Step: 933  | total loss: [1m[32m0.48654[0m[0m | time: 1.949s
[2K
| Adam | epoch: 016 | loss: 0.48654 - acc: 0.7785 -- iter: 0096/1980
[A[ATraining Step: 934  | total loss: [1m[32m0.48487[0m[0m | time: 2.608s
[2K
| Adam | epoch: 016 | loss: 0.48487 - acc: 0.7788 -- iter: 0128/1980
[A[ATraining Step: 935  | total loss: [1m[32m0.47793[0m[0m | time: 3.263s
[2K
| Adam | epoch: 016 | loss: 0.47793 - acc: 0.7853 -- iter: 0160/1980
[A[ATraining Step: 936  | total loss: [1m[32m0.46925[0m[0m | time: 3.933s
[2K
| Adam | epoch: 016 | loss: 0.46925 - acc: 0.7880 -- iter: 0192/1980
[A[ATraining Step: 937  | total loss: [1m[32m0.47586[0m[0m | time: 4.586s
[2K
| Adam | epoch: 016 | loss: 0.47586 - acc: 0.7811 -- iter: 0224/1980
[A[ATraining Step: 938  | total loss: [1m[32m0.47752[0m[0m | time: 5.218s
[2K
| Adam | epoch: 016 | loss: 0.47752 - acc: 0.7842 -- iter: 0256/1980
[A[ATraining Step: 939  | total loss: [1m[32m0.48463[0m[0m | time: 5.848s
[2K
| Adam | epoch: 016 | loss: 0.48463 - acc: 0.7746 -- iter: 0288/1980
[A[ATraining Step: 940  | total loss: [1m[32m0.47452[0m[0m | time: 6.485s
[2K
| Adam | epoch: 016 | loss: 0.47452 - acc: 0.7815 -- iter: 0320/1980
[A[ATraining Step: 941  | total loss: [1m[32m0.49296[0m[0m | time: 7.141s
[2K
| Adam | epoch: 016 | loss: 0.49296 - acc: 0.7627 -- iter: 0352/1980
[A[ATraining Step: 942  | total loss: [1m[32m0.50238[0m[0m | time: 7.859s
[2K
| Adam | epoch: 016 | loss: 0.50238 - acc: 0.7521 -- iter: 0384/1980
[A[ATraining Step: 943  | total loss: [1m[32m0.49511[0m[0m | time: 8.501s
[2K
| Adam | epoch: 016 | loss: 0.49511 - acc: 0.7612 -- iter: 0416/1980
[A[ATraining Step: 944  | total loss: [1m[32m0.49324[0m[0m | time: 9.094s
[2K
| Adam | epoch: 016 | loss: 0.49324 - acc: 0.7664 -- iter: 0448/1980
[A[ATraining Step: 945  | total loss: [1m[32m0.48872[0m[0m | time: 9.723s
[2K
| Adam | epoch: 016 | loss: 0.48872 - acc: 0.7647 -- iter: 0480/1980
[A[ATraining Step: 946  | total loss: [1m[32m0.48706[0m[0m | time: 10.371s
[2K
| Adam | epoch: 016 | loss: 0.48706 - acc: 0.7632 -- iter: 0512/1980
[A[ATraining Step: 947  | total loss: [1m[32m0.49094[0m[0m | time: 11.022s
[2K
| Adam | epoch: 016 | loss: 0.49094 - acc: 0.7650 -- iter: 0544/1980
[A[ATraining Step: 948  | total loss: [1m[32m0.48292[0m[0m | time: 11.654s
[2K
| Adam | epoch: 016 | loss: 0.48292 - acc: 0.7729 -- iter: 0576/1980
[A[ATraining Step: 949  | total loss: [1m[32m0.47662[0m[0m | time: 12.305s
[2K
| Adam | epoch: 016 | loss: 0.47662 - acc: 0.7738 -- iter: 0608/1980
[A[ATraining Step: 950  | total loss: [1m[32m0.48231[0m[0m | time: 12.977s
[2K
| Adam | epoch: 016 | loss: 0.48231 - acc: 0.7714 -- iter: 0640/1980
[A[ATraining Step: 951  | total loss: [1m[32m0.46531[0m[0m | time: 13.639s
[2K
| Adam | epoch: 016 | loss: 0.46531 - acc: 0.7849 -- iter: 0672/1980
[A[ATraining Step: 952  | total loss: [1m[32m0.46671[0m[0m | time: 14.315s
[2K
| Adam | epoch: 016 | loss: 0.46671 - acc: 0.7845 -- iter: 0704/1980
[A[ATraining Step: 953  | total loss: [1m[32m0.46217[0m[0m | time: 15.004s
[2K
| Adam | epoch: 016 | loss: 0.46217 - acc: 0.7873 -- iter: 0736/1980
[A[ATraining Step: 954  | total loss: [1m[32m0.47885[0m[0m | time: 15.664s
[2K
| Adam | epoch: 016 | loss: 0.47885 - acc: 0.7804 -- iter: 0768/1980
[A[ATraining Step: 955  | total loss: [1m[32m0.47916[0m[0m | time: 16.329s
[2K
| Adam | epoch: 016 | loss: 0.47916 - acc: 0.7680 -- iter: 0800/1980
[A[ATraining Step: 956  | total loss: [1m[32m0.49899[0m[0m | time: 16.997s
[2K
| Adam | epoch: 016 | loss: 0.49899 - acc: 0.7568 -- iter: 0832/1980
[A[ATraining Step: 957  | total loss: [1m[32m0.49751[0m[0m | time: 17.681s
[2K
| Adam | epoch: 016 | loss: 0.49751 - acc: 0.7593 -- iter: 0864/1980
[A[ATraining Step: 958  | total loss: [1m[32m0.47991[0m[0m | time: 18.381s
[2K
| Adam | epoch: 016 | loss: 0.47991 - acc: 0.7740 -- iter: 0896/1980
[A[ATraining Step: 959  | total loss: [1m[32m0.47438[0m[0m | time: 19.038s
[2K
| Adam | epoch: 016 | loss: 0.47438 - acc: 0.7810 -- iter: 0928/1980
[A[ATraining Step: 960  | total loss: [1m[32m0.48073[0m[0m | time: 19.696s
[2K
| Adam | epoch: 016 | loss: 0.48073 - acc: 0.7747 -- iter: 0960/1980
[A[ATraining Step: 961  | total loss: [1m[32m0.48020[0m[0m | time: 20.354s
[2K
| Adam | epoch: 016 | loss: 0.48020 - acc: 0.7754 -- iter: 0992/1980
[A[ATraining Step: 962  | total loss: [1m[32m0.48345[0m[0m | time: 21.010s
[2K
| Adam | epoch: 016 | loss: 0.48345 - acc: 0.7697 -- iter: 1024/1980
[A[ATraining Step: 963  | total loss: [1m[32m0.47501[0m[0m | time: 21.649s
[2K
| Adam | epoch: 016 | loss: 0.47501 - acc: 0.7709 -- iter: 1056/1980
[A[ATraining Step: 964  | total loss: [1m[32m0.47757[0m[0m | time: 22.326s
[2K
| Adam | epoch: 016 | loss: 0.47757 - acc: 0.7719 -- iter: 1088/1980
[A[ATraining Step: 965  | total loss: [1m[32m0.48660[0m[0m | time: 22.989s
[2K
| Adam | epoch: 016 | loss: 0.48660 - acc: 0.7729 -- iter: 1120/1980
[A[ATraining Step: 966  | total loss: [1m[32m0.47903[0m[0m | time: 23.645s
[2K
| Adam | epoch: 016 | loss: 0.47903 - acc: 0.7768 -- iter: 1152/1980
[A[ATraining Step: 967  | total loss: [1m[32m0.48018[0m[0m | time: 24.317s
[2K
| Adam | epoch: 016 | loss: 0.48018 - acc: 0.7773 -- iter: 1184/1980
[A[ATraining Step: 968  | total loss: [1m[32m0.48163[0m[0m | time: 24.991s
[2K
| Adam | epoch: 016 | loss: 0.48163 - acc: 0.7745 -- iter: 1216/1980
[A[ATraining Step: 969  | total loss: [1m[32m0.48288[0m[0m | time: 25.695s
[2K
| Adam | epoch: 016 | loss: 0.48288 - acc: 0.7721 -- iter: 1248/1980
[A[ATraining Step: 970  | total loss: [1m[32m0.49718[0m[0m | time: 26.396s
[2K
| Adam | epoch: 016 | loss: 0.49718 - acc: 0.7699 -- iter: 1280/1980
[A[ATraining Step: 971  | total loss: [1m[32m0.48175[0m[0m | time: 27.089s
[2K
| Adam | epoch: 016 | loss: 0.48175 - acc: 0.7804 -- iter: 1312/1980
[A[ATraining Step: 972  | total loss: [1m[32m0.48347[0m[0m | time: 27.791s
[2K
| Adam | epoch: 016 | loss: 0.48347 - acc: 0.7805 -- iter: 1344/1980
[A[ATraining Step: 973  | total loss: [1m[32m0.48347[0m[0m | time: 28.473s
[2K
| Adam | epoch: 016 | loss: 0.48347 - acc: 0.7774 -- iter: 1376/1980
[A[ATraining Step: 974  | total loss: [1m[32m0.46717[0m[0m | time: 29.201s
[2K
| Adam | epoch: 016 | loss: 0.46717 - acc: 0.7841 -- iter: 1408/1980
[A[ATraining Step: 975  | total loss: [1m[32m0.47101[0m[0m | time: 29.881s
[2K
| Adam | epoch: 016 | loss: 0.47101 - acc: 0.7713 -- iter: 1440/1980
[A[ATraining Step: 976  | total loss: [1m[32m0.47232[0m[0m | time: 30.547s
[2K
| Adam | epoch: 016 | loss: 0.47232 - acc: 0.7723 -- iter: 1472/1980
[A[ATraining Step: 977  | total loss: [1m[32m0.46226[0m[0m | time: 31.253s
[2K
| Adam | epoch: 016 | loss: 0.46226 - acc: 0.7794 -- iter: 1504/1980
[A[ATraining Step: 978  | total loss: [1m[32m0.47001[0m[0m | time: 31.943s
[2K
| Adam | epoch: 016 | loss: 0.47001 - acc: 0.7702 -- iter: 1536/1980
[A[ATraining Step: 979  | total loss: [1m[32m0.47341[0m[0m | time: 32.621s
[2K
| Adam | epoch: 016 | loss: 0.47341 - acc: 0.7651 -- iter: 1568/1980
[A[ATraining Step: 980  | total loss: [1m[32m0.48386[0m[0m | time: 33.340s
[2K
| Adam | epoch: 016 | loss: 0.48386 - acc: 0.7573 -- iter: 1600/1980
[A[ATraining Step: 981  | total loss: [1m[32m0.47610[0m[0m | time: 34.056s
[2K
| Adam | epoch: 016 | loss: 0.47610 - acc: 0.7628 -- iter: 1632/1980
[A[ATraining Step: 982  | total loss: [1m[32m0.46715[0m[0m | time: 34.717s
[2K
| Adam | epoch: 016 | loss: 0.46715 - acc: 0.7741 -- iter: 1664/1980
[A[ATraining Step: 983  | total loss: [1m[32m0.46407[0m[0m | time: 35.387s
[2K
| Adam | epoch: 016 | loss: 0.46407 - acc: 0.7717 -- iter: 1696/1980
[A[ATraining Step: 984  | total loss: [1m[32m0.46986[0m[0m | time: 36.107s
[2K
| Adam | epoch: 016 | loss: 0.46986 - acc: 0.7695 -- iter: 1728/1980
[A[ATraining Step: 985  | total loss: [1m[32m0.46689[0m[0m | time: 36.819s
[2K
| Adam | epoch: 016 | loss: 0.46689 - acc: 0.7675 -- iter: 1760/1980
[A[ATraining Step: 986  | total loss: [1m[32m0.45336[0m[0m | time: 37.508s
[2K
| Adam | epoch: 016 | loss: 0.45336 - acc: 0.7783 -- iter: 1792/1980
[A[ATraining Step: 987  | total loss: [1m[32m0.45552[0m[0m | time: 38.261s
[2K
| Adam | epoch: 016 | loss: 0.45552 - acc: 0.7786 -- iter: 1824/1980
[A[ATraining Step: 988  | total loss: [1m[32m0.46741[0m[0m | time: 38.983s
[2K
| Adam | epoch: 016 | loss: 0.46741 - acc: 0.7757 -- iter: 1856/1980
[A[ATraining Step: 989  | total loss: [1m[32m0.47314[0m[0m | time: 39.680s
[2K
| Adam | epoch: 016 | loss: 0.47314 - acc: 0.7700 -- iter: 1888/1980
[A[ATraining Step: 990  | total loss: [1m[32m0.46414[0m[0m | time: 40.360s
[2K
| Adam | epoch: 016 | loss: 0.46414 - acc: 0.7805 -- iter: 1920/1980
[A[ATraining Step: 991  | total loss: [1m[32m0.45798[0m[0m | time: 41.052s
[2K
| Adam | epoch: 016 | loss: 0.45798 - acc: 0.7900 -- iter: 1952/1980
[A[ATraining Step: 992  | total loss: [1m[32m0.46644[0m[0m | time: 44.413s
[2K
| Adam | epoch: 016 | loss: 0.46644 - acc: 0.7828 | val_loss: 0.52374 - val_acc: 0.7544 -- iter: 1980/1980
--
Training Step: 993  | total loss: [1m[32m0.46320[0m[0m | time: 0.698s
[2K
| Adam | epoch: 017 | loss: 0.46320 - acc: 0.7889 -- iter: 0032/1980
[A[ATraining Step: 994  | total loss: [1m[32m0.45974[0m[0m | time: 1.373s
[2K
| Adam | epoch: 017 | loss: 0.45974 - acc: 0.7882 -- iter: 0064/1980
[A[ATraining Step: 995  | total loss: [1m[32m0.44355[0m[0m | time: 2.043s
[2K
| Adam | epoch: 017 | loss: 0.44355 - acc: 0.8031 -- iter: 0096/1980
[A[ATraining Step: 996  | total loss: [1m[32m0.45296[0m[0m | time: 2.745s
[2K
| Adam | epoch: 017 | loss: 0.45296 - acc: 0.7978 -- iter: 0128/1980
[A[ATraining Step: 997  | total loss: [1m[32m0.45125[0m[0m | time: 3.448s
[2K
| Adam | epoch: 017 | loss: 0.45125 - acc: 0.7930 -- iter: 0160/1980
[A[ATraining Step: 998  | total loss: [1m[32m0.46734[0m[0m | time: 4.126s
[2K
| Adam | epoch: 017 | loss: 0.46734 - acc: 0.7887 -- iter: 0192/1980
[A[ATraining Step: 999  | total loss: [1m[32m0.46243[0m[0m | time: 4.816s
[2K
| Adam | epoch: 017 | loss: 0.46243 - acc: 0.7880 -- iter: 0224/1980
[A[ATraining Step: 1000  | total loss: [1m[32m0.47726[0m[0m | time: 8.147s
[2K
| Adam | epoch: 017 | loss: 0.47726 - acc: 0.7748 | val_loss: 0.57545 - val_acc: 0.7237 -- iter: 0256/1980
--
Training Step: 1001  | total loss: [1m[32m0.46781[0m[0m | time: 8.850s
[2K
| Adam | epoch: 017 | loss: 0.46781 - acc: 0.7848 -- iter: 0288/1980
[A[ATraining Step: 1002  | total loss: [1m[32m0.49326[0m[0m | time: 9.535s
[2K
| Adam | epoch: 017 | loss: 0.49326 - acc: 0.7720 -- iter: 0320/1980
[A[ATraining Step: 1003  | total loss: [1m[32m0.49599[0m[0m | time: 10.264s
[2K
| Adam | epoch: 017 | loss: 0.49599 - acc: 0.7698 -- iter: 0352/1980
[A[ATraining Step: 1004  | total loss: [1m[32m0.49068[0m[0m | time: 10.959s
[2K
| Adam | epoch: 017 | loss: 0.49068 - acc: 0.7740 -- iter: 0384/1980
[A[ATraining Step: 1005  | total loss: [1m[32m0.47602[0m[0m | time: 11.676s
[2K
| Adam | epoch: 017 | loss: 0.47602 - acc: 0.7904 -- iter: 0416/1980
[A[ATraining Step: 1006  | total loss: [1m[32m0.46580[0m[0m | time: 12.418s
[2K
| Adam | epoch: 017 | loss: 0.46580 - acc: 0.7988 -- iter: 0448/1980
[A[ATraining Step: 1007  | total loss: [1m[32m0.45689[0m[0m | time: 13.027s
[2K
| Adam | epoch: 017 | loss: 0.45689 - acc: 0.8033 -- iter: 0480/1980
[A[ATraining Step: 1008  | total loss: [1m[32m0.46366[0m[0m | time: 13.652s
[2K
| Adam | epoch: 017 | loss: 0.46366 - acc: 0.7944 -- iter: 0512/1980
[A[ATraining Step: 1009  | total loss: [1m[32m0.47132[0m[0m | time: 14.356s
[2K
| Adam | epoch: 017 | loss: 0.47132 - acc: 0.7936 -- iter: 0544/1980
[A[ATraining Step: 1010  | total loss: [1m[32m0.49962[0m[0m | time: 15.061s
[2K
| Adam | epoch: 017 | loss: 0.49962 - acc: 0.7767 -- iter: 0576/1980
[A[ATraining Step: 1011  | total loss: [1m[32m0.50292[0m[0m | time: 15.793s
[2K
| Adam | epoch: 017 | loss: 0.50292 - acc: 0.7740 -- iter: 0608/1980
[A[ATraining Step: 1012  | total loss: [1m[32m0.50312[0m[0m | time: 16.513s
[2K
| Adam | epoch: 017 | loss: 0.50312 - acc: 0.7779 -- iter: 0640/1980
[A[ATraining Step: 1013  | total loss: [1m[32m0.48407[0m[0m | time: 17.196s
[2K
| Adam | epoch: 017 | loss: 0.48407 - acc: 0.7907 -- iter: 0672/1980
[A[ATraining Step: 1014  | total loss: [1m[32m0.48080[0m[0m | time: 17.899s
[2K
| Adam | epoch: 017 | loss: 0.48080 - acc: 0.7929 -- iter: 0704/1980
[A[ATraining Step: 1015  | total loss: [1m[32m0.49711[0m[0m | time: 18.594s
[2K
| Adam | epoch: 017 | loss: 0.49711 - acc: 0.7792 -- iter: 0736/1980
[A[ATraining Step: 1016  | total loss: [1m[32m0.50382[0m[0m | time: 19.325s
[2K
| Adam | epoch: 017 | loss: 0.50382 - acc: 0.7701 -- iter: 0768/1980
[A[ATraining Step: 1017  | total loss: [1m[32m0.50386[0m[0m | time: 20.049s
[2K
| Adam | epoch: 017 | loss: 0.50386 - acc: 0.7743 -- iter: 0800/1980
[A[ATraining Step: 1018  | total loss: [1m[32m0.51066[0m[0m | time: 20.790s
[2K
| Adam | epoch: 017 | loss: 0.51066 - acc: 0.7656 -- iter: 0832/1980
[A[ATraining Step: 1019  | total loss: [1m[32m0.49624[0m[0m | time: 22.125s
[2K
| Adam | epoch: 017 | loss: 0.49624 - acc: 0.7797 -- iter: 0864/1980
[A[ATraining Step: 1020  | total loss: [1m[32m0.49083[0m[0m | time: 26.409s
[2K
| Adam | epoch: 017 | loss: 0.49083 - acc: 0.7798 -- iter: 0896/1980
[A[ATraining Step: 1021  | total loss: [1m[32m0.48843[0m[0m | time: 31.679s
[2K
| Adam | epoch: 017 | loss: 0.48843 - acc: 0.7800 -- iter: 0928/1980
[A[ATraining Step: 1022  | total loss: [1m[32m0.47666[0m[0m | time: 50.756s
[2K
| Adam | epoch: 017 | loss: 0.47666 - acc: 0.7864 -- iter: 0960/1980
[A[ATraining Step: 1023  | total loss: [1m[32m0.46370[0m[0m | time: 61.869s
[2K
| Adam | epoch: 017 | loss: 0.46370 - acc: 0.7921 -- iter: 0992/1980
[A[ATraining Step: 1024  | total loss: [1m[32m0.46470[0m[0m | time: 62.567s
[2K
| Adam | epoch: 017 | loss: 0.46470 - acc: 0.7973 -- iter: 1024/1980
[A[ATraining Step: 1025  | total loss: [1m[32m0.46037[0m[0m | time: 63.255s
[2K
| Adam | epoch: 017 | loss: 0.46037 - acc: 0.8019 -- iter: 1056/1980
[A[ATraining Step: 1026  | total loss: [1m[32m0.45053[0m[0m | time: 64.640s
[2K
| Adam | epoch: 017 | loss: 0.45053 - acc: 0.8030 -- iter: 1088/1980
[A[ATraining Step: 1027  | total loss: [1m[32m0.45829[0m[0m | time: 65.434s
[2K
| Adam | epoch: 017 | loss: 0.45829 - acc: 0.7914 -- iter: 1120/1980
[A[ATraining Step: 1028  | total loss: [1m[32m0.45856[0m[0m | time: 72.035s
[2K
| Adam | epoch: 017 | loss: 0.45856 - acc: 0.7935 -- iter: 1152/1980
[A[ATraining Step: 1029  | total loss: [1m[32m0.45199[0m[0m | time: 74.768s
[2K
| Adam | epoch: 017 | loss: 0.45199 - acc: 0.7986 -- iter: 1184/1980
[A[ATraining Step: 1030  | total loss: [1m[32m0.44693[0m[0m | time: 80.958s
[2K
| Adam | epoch: 017 | loss: 0.44693 - acc: 0.7999 -- iter: 1216/1980
[A[ATraining Step: 1031  | total loss: [1m[32m0.46400[0m[0m | time: 81.651s
[2K
| Adam | epoch: 017 | loss: 0.46400 - acc: 0.7856 -- iter: 1248/1980
[A[ATraining Step: 1032  | total loss: [1m[32m0.46007[0m[0m | time: 88.386s
[2K
| Adam | epoch: 017 | loss: 0.46007 - acc: 0.7914 -- iter: 1280/1980
[A[ATraining Step: 1033  | total loss: [1m[32m0.45941[0m[0m | time: 89.063s
[2K
| Adam | epoch: 017 | loss: 0.45941 - acc: 0.7904 -- iter: 1312/1980
[A[ATraining Step: 1034  | total loss: [1m[32m0.45494[0m[0m | time: 89.747s
[2K
| Adam | epoch: 017 | loss: 0.45494 - acc: 0.7926 -- iter: 1344/1980
[A[ATraining Step: 1035  | total loss: [1m[32m0.47115[0m[0m | time: 90.423s
[2K
| Adam | epoch: 017 | loss: 0.47115 - acc: 0.7852 -- iter: 1376/1980
[A[ATraining Step: 1036  | total loss: [1m[32m0.48571[0m[0m | time: 91.274s
[2K
| Adam | epoch: 017 | loss: 0.48571 - acc: 0.7754 -- iter: 1408/1980
[A[ATraining Step: 1037  | total loss: [1m[32m0.47010[0m[0m | time: 91.971s
[2K
| Adam | epoch: 017 | loss: 0.47010 - acc: 0.7823 -- iter: 1440/1980
[A[ATraining Step: 1038  | total loss: [1m[32m0.47591[0m[0m | time: 97.956s
[2K
| Adam | epoch: 017 | loss: 0.47591 - acc: 0.7853 -- iter: 1472/1980
[A[ATraining Step: 1039  | total loss: [1m[32m0.48162[0m[0m | time: 98.635s
[2K
| Adam | epoch: 017 | loss: 0.48162 - acc: 0.7755 -- iter: 1504/1980
[A[ATraining Step: 1040  | total loss: [1m[32m0.47652[0m[0m | time: 102.272s
[2K
| Adam | epoch: 017 | loss: 0.47652 - acc: 0.7823 -- iter: 1536/1980
[A[ATraining Step: 1041  | total loss: [1m[32m0.47837[0m[0m | time: 103.029s
[2K
| Adam | epoch: 017 | loss: 0.47837 - acc: 0.7822 -- iter: 1568/1980
[A[ATraining Step: 1042  | total loss: [1m[32m0.48132[0m[0m | time: 103.752s
[2K
| Adam | epoch: 017 | loss: 0.48132 - acc: 0.7728 -- iter: 1600/1980
[A[ATraining Step: 1043  | total loss: [1m[32m0.47203[0m[0m | time: 104.475s
[2K
| Adam | epoch: 017 | loss: 0.47203 - acc: 0.7799 -- iter: 1632/1980
[A[ATraining Step: 1044  | total loss: [1m[32m0.46255[0m[0m | time: 110.242s
[2K
| Adam | epoch: 017 | loss: 0.46255 - acc: 0.7831 -- iter: 1664/1980
[A[ATraining Step: 1045  | total loss: [1m[32m0.45319[0m[0m | time: 110.937s
[2K
| Adam | epoch: 017 | loss: 0.45319 - acc: 0.7892 -- iter: 1696/1980
[A[ATraining Step: 1046  | total loss: [1m[32m0.46100[0m[0m | time: 112.131s
[2K
| Adam | epoch: 017 | loss: 0.46100 - acc: 0.7790 -- iter: 1728/1980
[A[ATraining Step: 1047  | total loss: [1m[32m0.46884[0m[0m | time: 112.845s
[2K
| Adam | epoch: 017 | loss: 0.46884 - acc: 0.7667 -- iter: 1760/1980
[A[ATraining Step: 1048  | total loss: [1m[32m0.46049[0m[0m | time: 113.541s
[2K
| Adam | epoch: 017 | loss: 0.46049 - acc: 0.7776 -- iter: 1792/1980
[A[ATraining Step: 1049  | total loss: [1m[32m0.46831[0m[0m | time: 114.232s
[2K
| Adam | epoch: 017 | loss: 0.46831 - acc: 0.7686 -- iter: 1824/1980
[A[ATraining Step: 1050  | total loss: [1m[32m0.45530[0m[0m | time: 114.897s
[2K
| Adam | epoch: 017 | loss: 0.45530 - acc: 0.7792 -- iter: 1856/1980
[A[ATraining Step: 1051  | total loss: [1m[32m0.44166[0m[0m | time: 119.824s
[2K
| Adam | epoch: 017 | loss: 0.44166 - acc: 0.7950 -- iter: 1888/1980
[A[ATraining Step: 1052  | total loss: [1m[32m0.43503[0m[0m | time: 120.505s
[2K
| Adam | epoch: 017 | loss: 0.43503 - acc: 0.7999 -- iter: 1920/1980
[A[ATraining Step: 1053  | total loss: [1m[32m0.43592[0m[0m | time: 121.183s
[2K
| Adam | epoch: 017 | loss: 0.43592 - acc: 0.7980 -- iter: 1952/1980
[A[ATraining Step: 1054  | total loss: [1m[32m0.42492[0m[0m | time: 185.273s
[2K
| Adam | epoch: 017 | loss: 0.42492 - acc: 0.8057 | val_loss: 0.51448 - val_acc: 0.7593 -- iter: 1980/1980
--
Training Step: 1055  | total loss: [1m[32m0.42450[0m[0m | time: 0.686s
[2K
| Adam | epoch: 018 | loss: 0.42450 - acc: 0.8033 -- iter: 0032/1980
[A[ATraining Step: 1056  | total loss: [1m[32m0.42984[0m[0m | time: 1.389s
[2K
| Adam | epoch: 018 | loss: 0.42984 - acc: 0.7948 -- iter: 0064/1980
[A[ATraining Step: 1057  | total loss: [1m[32m0.44378[0m[0m | time: 2.109s
[2K
| Adam | epoch: 018 | loss: 0.44378 - acc: 0.7903 -- iter: 0096/1980
[A[ATraining Step: 1058  | total loss: [1m[32m0.43691[0m[0m | time: 3.064s
[2K
| Adam | epoch: 018 | loss: 0.43691 - acc: 0.7988 -- iter: 0128/1980
[A[ATraining Step: 1059  | total loss: [1m[32m0.43290[0m[0m | time: 8.598s
[2K
| Adam | epoch: 018 | loss: 0.43290 - acc: 0.8033 -- iter: 0160/1980
[A[ATraining Step: 1060  | total loss: [1m[32m0.43545[0m[0m | time: 10.805s
[2K
| Adam | epoch: 018 | loss: 0.43545 - acc: 0.8011 -- iter: 0192/1980
[A[ATraining Step: 1061  | total loss: [1m[32m0.42757[0m[0m | time: 11.510s
[2K
| Adam | epoch: 018 | loss: 0.42757 - acc: 0.8116 -- iter: 0224/1980
[A[ATraining Step: 1062  | total loss: [1m[32m0.41934[0m[0m | time: 12.287s
[2K
| Adam | epoch: 018 | loss: 0.41934 - acc: 0.8180 -- iter: 0256/1980
[A[ATraining Step: 1063  | total loss: [1m[32m0.42305[0m[0m | time: 12.994s
[2K
| Adam | epoch: 018 | loss: 0.42305 - acc: 0.8143 -- iter: 0288/1980
[A[ATraining Step: 1064  | total loss: [1m[32m0.42109[0m[0m | time: 13.690s
[2K
| Adam | epoch: 018 | loss: 0.42109 - acc: 0.8172 -- iter: 0320/1980
[A[ATraining Step: 1065  | total loss: [1m[32m0.41429[0m[0m | time: 14.668s
[2K
| Adam | epoch: 018 | loss: 0.41429 - acc: 0.8199 -- iter: 0352/1980
[A[ATraining Step: 1066  | total loss: [1m[32m0.43789[0m[0m | time: 16.747s
[2K
| Adam | epoch: 018 | loss: 0.43789 - acc: 0.8066 -- iter: 0384/1980
[A[ATraining Step: 1067  | total loss: [1m[32m0.43323[0m[0m | time: 17.448s
[2K
| Adam | epoch: 018 | loss: 0.43323 - acc: 0.8072 -- iter: 0416/1980
[A[ATraining Step: 1068  | total loss: [1m[32m0.43044[0m[0m | time: 18.158s
[2K
| Adam | epoch: 018 | loss: 0.43044 - acc: 0.8140 -- iter: 0448/1980
[A[ATraining Step: 1069  | total loss: [1m[32m0.42798[0m[0m | time: 19.368s
[2K
| Adam | epoch: 018 | loss: 0.42798 - acc: 0.8139 -- iter: 0480/1980
[A[ATraining Step: 1070  | total loss: [1m[32m0.43033[0m[0m | time: 19.987s
[2K
| Adam | epoch: 018 | loss: 0.43033 - acc: 0.8168 -- iter: 0512/1980
[A[ATraining Step: 1071  | total loss: [1m[32m0.42827[0m[0m | time: 21.228s
[2K
| Adam | epoch: 018 | loss: 0.42827 - acc: 0.8173 -- iter: 0544/1980
[A[ATraining Step: 1072  | total loss: [1m[32m0.42938[0m[0m | time: 21.956s
[2K
| Adam | epoch: 018 | loss: 0.42938 - acc: 0.8177 -- iter: 0576/1980
[A[ATraining Step: 1073  | total loss: [1m[32m0.44524[0m[0m | time: 22.674s
[2K
| Adam | epoch: 018 | loss: 0.44524 - acc: 0.8016 -- iter: 0608/1980
[A[ATraining Step: 1074  | total loss: [1m[32m0.44695[0m[0m | time: 28.664s
[2K
| Adam | epoch: 018 | loss: 0.44695 - acc: 0.7995 -- iter: 0640/1980
[A[ATraining Step: 1075  | total loss: [1m[32m0.45048[0m[0m | time: 31.216s
[2K
| Adam | epoch: 018 | loss: 0.45048 - acc: 0.7977 -- iter: 0672/1980
[A[ATraining Step: 1076  | total loss: [1m[32m0.43420[0m[0m | time: 31.915s
[2K
| Adam | epoch: 018 | loss: 0.43420 - acc: 0.8117 -- iter: 0704/1980
[A[ATraining Step: 1077  | total loss: [1m[32m0.43654[0m[0m | time: 32.951s
[2K
| Adam | epoch: 018 | loss: 0.43654 - acc: 0.8055 -- iter: 0736/1980
[A[ATraining Step: 1078  | total loss: [1m[32m0.42673[0m[0m | time: 41.147s
[2K
| Adam | epoch: 018 | loss: 0.42673 - acc: 0.8062 -- iter: 0768/1980
[A[ATraining Step: 1079  | total loss: [1m[32m0.41832[0m[0m | time: 41.866s
[2K
| Adam | epoch: 018 | loss: 0.41832 - acc: 0.8100 -- iter: 0800/1980
[A[ATraining Step: 1080  | total loss: [1m[32m0.42409[0m[0m | time: 45.153s
[2K
| Adam | epoch: 018 | loss: 0.42409 - acc: 0.8071 -- iter: 0832/1980
[A[ATraining Step: 1081  | total loss: [1m[32m0.42808[0m[0m | time: 50.171s
[2K
| Adam | epoch: 018 | loss: 0.42808 - acc: 0.8014 -- iter: 0864/1980
[A[ATraining Step: 1082  | total loss: [1m[32m0.42518[0m[0m | time: 50.869s
[2K
| Adam | epoch: 018 | loss: 0.42518 - acc: 0.8025 -- iter: 0896/1980
[A[ATraining Step: 1083  | total loss: [1m[32m0.40321[0m[0m | time: 54.558s
[2K
| Adam | epoch: 018 | loss: 0.40321 - acc: 0.8191 -- iter: 0928/1980
[A[ATraining Step: 1084  | total loss: [1m[32m0.40925[0m[0m | time: 55.312s
[2K
| Adam | epoch: 018 | loss: 0.40925 - acc: 0.8153 -- iter: 0960/1980
[A[ATraining Step: 1085  | total loss: [1m[32m0.41714[0m[0m | time: 60.395s
[2K
| Adam | epoch: 018 | loss: 0.41714 - acc: 0.8088 -- iter: 0992/1980
[A[ATraining Step: 1086  | total loss: [1m[32m0.42101[0m[0m | time: 61.121s
[2K
| Adam | epoch: 018 | loss: 0.42101 - acc: 0.8092 -- iter: 1024/1980
[A[ATraining Step: 1087  | total loss: [1m[32m0.42476[0m[0m | time: 73.734s
[2K
| Adam | epoch: 018 | loss: 0.42476 - acc: 0.8158 -- iter: 1056/1980
[A[ATraining Step: 1088  | total loss: [1m[32m0.43785[0m[0m | time: 79.692s
[2K
| Adam | epoch: 018 | loss: 0.43785 - acc: 0.8061 -- iter: 1088/1980
[A[ATraining Step: 1089  | total loss: [1m[32m0.44173[0m[0m | time: 81.551s
[2K
| Adam | epoch: 018 | loss: 0.44173 - acc: 0.8036 -- iter: 1120/1980
[A[ATraining Step: 1090  | total loss: [1m[32m0.45031[0m[0m | time: 88.014s
[2K
| Adam | epoch: 018 | loss: 0.45031 - acc: 0.7982 -- iter: 1152/1980
[A[ATraining Step: 1091  | total loss: [1m[32m0.45055[0m[0m | time: 93.368s
[2K
| Adam | epoch: 018 | loss: 0.45055 - acc: 0.8028 -- iter: 1184/1980
[A[ATraining Step: 1092  | total loss: [1m[32m0.45306[0m[0m | time: 94.883s
[2K
| Adam | epoch: 018 | loss: 0.45306 - acc: 0.8037 -- iter: 1216/1980
[A[ATraining Step: 1093  | total loss: [1m[32m0.45344[0m[0m | time: 100.552s
[2K
| Adam | epoch: 018 | loss: 0.45344 - acc: 0.7952 -- iter: 1248/1980
[A[ATraining Step: 1094  | total loss: [1m[32m0.46533[0m[0m | time: 102.642s
[2K
| Adam | epoch: 018 | loss: 0.46533 - acc: 0.7938 -- iter: 1280/1980
[A[ATraining Step: 1095  | total loss: [1m[32m0.47171[0m[0m | time: 103.840s
[2K
| Adam | epoch: 018 | loss: 0.47171 - acc: 0.7895 -- iter: 1312/1980
[A[ATraining Step: 1096  | total loss: [1m[32m0.47022[0m[0m | time: 106.440s
[2K
| Adam | epoch: 018 | loss: 0.47022 - acc: 0.7886 -- iter: 1344/1980
[A[ATraining Step: 1097  | total loss: [1m[32m0.45758[0m[0m | time: 108.544s
[2K
| Adam | epoch: 018 | loss: 0.45758 - acc: 0.8035 -- iter: 1376/1980
[A[ATraining Step: 1098  | total loss: [1m[32m0.44573[0m[0m | time: 112.044s
[2K
| Adam | epoch: 018 | loss: 0.44573 - acc: 0.8138 -- iter: 1408/1980
[A[ATraining Step: 1099  | total loss: [1m[32m0.43153[0m[0m | time: 114.454s
[2K
| Adam | epoch: 018 | loss: 0.43153 - acc: 0.8262 -- iter: 1440/1980
[A[ATraining Step: 1100  | total loss: [1m[32m0.44330[0m[0m | time: 118.978s
[2K
| Adam | epoch: 018 | loss: 0.44330 - acc: 0.8154 -- iter: 1472/1980
[A[ATraining Step: 1101  | total loss: [1m[32m0.44072[0m[0m | time: 120.106s
[2K
| Adam | epoch: 018 | loss: 0.44072 - acc: 0.8058 -- iter: 1504/1980
[A[ATraining Step: 1102  | total loss: [1m[32m0.44934[0m[0m | time: 121.292s
[2K
| Adam | epoch: 018 | loss: 0.44934 - acc: 0.8064 -- iter: 1536/1980
[A[ATraining Step: 1103  | total loss: [1m[32m0.44957[0m[0m | time: 122.742s
[2K
| Adam | epoch: 018 | loss: 0.44957 - acc: 0.8039 -- iter: 1568/1980
[A[ATraining Step: 1104  | total loss: [1m[32m0.43356[0m[0m | time: 123.749s
[2K
| Adam | epoch: 018 | loss: 0.43356 - acc: 0.8173 -- iter: 1600/1980
[A[ATraining Step: 1105  | total loss: [1m[32m0.43986[0m[0m | time: 129.412s
[2K
| Adam | epoch: 018 | loss: 0.43986 - acc: 0.8168 -- iter: 1632/1980
[A[ATraining Step: 1106  | total loss: [1m[32m0.43882[0m[0m | time: 130.238s
[2K
| Adam | epoch: 018 | loss: 0.43882 - acc: 0.8164 -- iter: 1664/1980
[A[ATraining Step: 1107  | total loss: [1m[32m0.44542[0m[0m | time: 130.984s
[2K
| Adam | epoch: 018 | loss: 0.44542 - acc: 0.8066 -- iter: 1696/1980
[A[ATraining Step: 1108  | total loss: [1m[32m0.44405[0m[0m | time: 135.270s
[2K
| Adam | epoch: 018 | loss: 0.44405 - acc: 0.8072 -- iter: 1728/1980
[A[ATraining Step: 1109  | total loss: [1m[32m0.44101[0m[0m | time: 137.417s
[2K
| Adam | epoch: 018 | loss: 0.44101 - acc: 0.8015 -- iter: 1760/1980
[A[ATraining Step: 1110  | total loss: [1m[32m0.42827[0m[0m | time: 140.534s
[2K
| Adam | epoch: 018 | loss: 0.42827 - acc: 0.8088 -- iter: 1792/1980
[A[ATraining Step: 1111  | total loss: [1m[32m0.42626[0m[0m | time: 145.069s
[2K
| Adam | epoch: 018 | loss: 0.42626 - acc: 0.8092 -- iter: 1824/1980
[A[ATraining Step: 1112  | total loss: [1m[32m0.42179[0m[0m | time: 151.090s
[2K
| Adam | epoch: 018 | loss: 0.42179 - acc: 0.8095 -- iter: 1856/1980
[A[ATraining Step: 1113  | total loss: [1m[32m0.42921[0m[0m | time: 155.146s
[2K
| Adam | epoch: 018 | loss: 0.42921 - acc: 0.8129 -- iter: 1888/1980
[A[ATraining Step: 1114  | total loss: [1m[32m0.41779[0m[0m | time: 162.920s
[2K
| Adam | epoch: 018 | loss: 0.41779 - acc: 0.8192 -- iter: 1920/1980
[A[ATraining Step: 1115  | total loss: [1m[32m0.41348[0m[0m | time: 166.863s
[2K
| Adam | epoch: 018 | loss: 0.41348 - acc: 0.8247 -- iter: 1952/1980
[A[ATraining Step: 1116  | total loss: [1m[32m0.41649[0m[0m | time: 285.642s
[2K
| Adam | epoch: 018 | loss: 0.41649 - acc: 0.8173 | val_loss: 0.51823 - val_acc: 0.7561 -- iter: 1980/1980
--
Training Step: 1117  | total loss: [1m[32m0.41856[0m[0m | time: 4.378s
[2K
| Adam | epoch: 019 | loss: 0.41856 - acc: 0.8168 -- iter: 0032/1980
[A[ATraining Step: 1118  | total loss: [1m[32m0.40586[0m[0m | time: 6.547s
[2K
| Adam | epoch: 019 | loss: 0.40586 - acc: 0.8257 -- iter: 0064/1980
[A[ATraining Step: 1119  | total loss: [1m[32m0.39033[0m[0m | time: 14.731s
[2K
| Adam | epoch: 019 | loss: 0.39033 - acc: 0.8307 -- iter: 0096/1980
[A[ATraining Step: 1120  | total loss: [1m[32m0.39644[0m[0m | time: 27.455s
[2K
| Adam | epoch: 019 | loss: 0.39644 - acc: 0.8226 -- iter: 0128/1980
[A[ATraining Step: 1121  | total loss: [1m[32m0.38671[0m[0m | time: 56.366s
[2K
| Adam | epoch: 019 | loss: 0.38671 - acc: 0.8278 -- iter: 0160/1980
[A[ATraining Step: 1122  | total loss: [1m[32m0.38256[0m[0m | time: 72.833s
[2K
| Adam | epoch: 019 | loss: 0.38256 - acc: 0.8294 -- iter: 0192/1980
[A[ATraining Step: 1123  | total loss: [1m[32m0.39317[0m[0m | time: 80.615s
[2K
| Adam | epoch: 019 | loss: 0.39317 - acc: 0.8309 -- iter: 0224/1980
[A[ATraining Step: 1124  | total loss: [1m[32m0.41410[0m[0m | time: 96.116s
[2K
| Adam | epoch: 019 | loss: 0.41410 - acc: 0.8134 -- iter: 0256/1980
[A[ATraining Step: 1125  | total loss: [1m[32m0.40679[0m[0m | time: 106.154s
[2K
| Adam | epoch: 019 | loss: 0.40679 - acc: 0.8164 -- iter: 0288/1980
[A[ATraining Step: 1126  | total loss: [1m[32m0.40580[0m[0m | time: 126.718s
[2K
| Adam | epoch: 019 | loss: 0.40580 - acc: 0.8254 -- iter: 0320/1980
[A[ATraining Step: 1127  | total loss: [1m[32m0.44209[0m[0m | time: 133.595s
[2K
| Adam | epoch: 019 | loss: 0.44209 - acc: 0.8054 -- iter: 0352/1980
[A[ATraining Step: 1128  | total loss: [1m[32m0.43770[0m[0m | time: 140.802s
[2K
| Adam | epoch: 019 | loss: 0.43770 - acc: 0.8061 -- iter: 0384/1980
[A[ATraining Step: 1129  | total loss: [1m[32m0.43720[0m[0m | time: 149.674s
[2K
| Adam | epoch: 019 | loss: 0.43720 - acc: 0.8036 -- iter: 0416/1980
[A[ATraining Step: 1130  | total loss: [1m[32m0.45011[0m[0m | time: 157.371s
[2K
| Adam | epoch: 019 | loss: 0.45011 - acc: 0.7920 -- iter: 0448/1980
[A[ATraining Step: 1131  | total loss: [1m[32m0.42767[0m[0m | time: 163.393s
[2K
| Adam | epoch: 019 | loss: 0.42767 - acc: 0.8128 -- iter: 0480/1980
[A[ATraining Step: 1132  | total loss: [1m[32m0.42102[0m[0m | time: 167.427s
[2K
| Adam | epoch: 019 | loss: 0.42102 - acc: 0.8159 -- iter: 0512/1980
[A[ATraining Step: 1133  | total loss: [1m[32m0.43305[0m[0m | time: 168.542s
[2K
| Adam | epoch: 019 | loss: 0.43305 - acc: 0.8124 -- iter: 0544/1980
[A[ATraining Step: 1134  | total loss: [1m[32m0.43608[0m[0m | time: 169.581s
[2K
| Adam | epoch: 019 | loss: 0.43608 - acc: 0.8062 -- iter: 0576/1980
[A[ATraining Step: 1135  | total loss: [1m[32m0.43707[0m[0m | time: 174.482s
[2K
| Adam | epoch: 019 | loss: 0.43707 - acc: 0.8006 -- iter: 0608/1980
[A[ATraining Step: 1136  | total loss: [1m[32m0.43776[0m[0m | time: 181.288s
[2K
| Adam | epoch: 019 | loss: 0.43776 - acc: 0.8049 -- iter: 0640/1980
[A[ATraining Step: 1137  | total loss: [1m[32m0.42693[0m[0m | time: 182.860s
[2K
| Adam | epoch: 019 | loss: 0.42693 - acc: 0.8119 -- iter: 0672/1980
[A[ATraining Step: 1138  | total loss: [1m[32m0.41558[0m[0m | time: 188.213s
[2K
| Adam | epoch: 019 | loss: 0.41558 - acc: 0.8151 -- iter: 0704/1980
[A[ATraining Step: 1139  | total loss: [1m[32m0.41474[0m[0m | time: 204.253s
[2K
| Adam | epoch: 019 | loss: 0.41474 - acc: 0.8148 -- iter: 0736/1980
[A[ATraining Step: 1140  | total loss: [1m[32m0.39835[0m[0m | time: 224.270s
[2K
| Adam | epoch: 019 | loss: 0.39835 - acc: 0.8240 -- iter: 0768/1980
[A[ATraining Step: 1141  | total loss: [1m[32m0.41411[0m[0m | time: 234.914s
[2K
| Adam | epoch: 019 | loss: 0.41411 - acc: 0.8072 -- iter: 0800/1980
[A[ATraining Step: 1142  | total loss: [1m[32m0.41172[0m[0m | time: 240.312s
[2K
| Adam | epoch: 019 | loss: 0.41172 - acc: 0.8108 -- iter: 0832/1980
[A[ATraining Step: 1143  | total loss: [1m[32m0.42215[0m[0m | time: 241.169s
[2K
| Adam | epoch: 019 | loss: 0.42215 - acc: 0.8141 -- iter: 0864/1980
[A[ATraining Step: 1144  | total loss: [1m[32m0.42974[0m[0m | time: 266.219s
[2K
| Adam | epoch: 019 | loss: 0.42974 - acc: 0.8015 -- iter: 0896/1980
[A[ATraining Step: 1145  | total loss: [1m[32m0.41992[0m[0m | time: 294.879s
[2K
| Adam | epoch: 019 | loss: 0.41992 - acc: 0.7995 -- iter: 0928/1980
[A[ATraining Step: 1146  | total loss: [1m[32m0.41267[0m[0m | time: 327.912s
[2K
| Adam | epoch: 019 | loss: 0.41267 - acc: 0.8133 -- iter: 0960/1980
[A[ATraining Step: 1147  | total loss: [1m[32m0.40034[0m[0m | time: 378.479s
[2K
| Adam | epoch: 019 | loss: 0.40034 - acc: 0.8288 -- iter: 0992/1980
[A[ATraining Step: 1148  | total loss: [1m[32m0.40623[0m[0m | time: 414.982s
[2K
| Adam | epoch: 019 | loss: 0.40623 - acc: 0.8178 -- iter: 1024/1980
[A[ATraining Step: 1149  | total loss: [1m[32m0.41001[0m[0m | time: 432.618s
[2K
| Adam | epoch: 019 | loss: 0.41001 - acc: 0.8173 -- iter: 1056/1980
[A[ATraining Step: 1150  | total loss: [1m[32m0.40565[0m[0m | time: 440.792s
[2K
| Adam | epoch: 019 | loss: 0.40565 - acc: 0.8137 -- iter: 1088/1980
[A[ATraining Step: 1151  | total loss: [1m[32m0.39384[0m[0m | time: 447.766s
[2K
| Adam | epoch: 019 | loss: 0.39384 - acc: 0.8261 -- iter: 1120/1980
[A[ATraining Step: 1152  | total loss: [1m[32m0.39771[0m[0m | time: 453.659s
[2K
| Adam | epoch: 019 | loss: 0.39771 - acc: 0.8278 -- iter: 1152/1980
[A[ATraining Step: 1153  | total loss: [1m[32m0.40110[0m[0m | time: 475.589s
[2K
| Adam | epoch: 019 | loss: 0.40110 - acc: 0.8263 -- iter: 1184/1980
[A[ATraining Step: 1154  | total loss: [1m[32m0.41205[0m[0m | time: 490.334s
[2K
| Adam | epoch: 019 | loss: 0.41205 - acc: 0.8155 -- iter: 1216/1980
[A[ATraining Step: 1155  | total loss: [1m[32m0.42357[0m[0m | time: 493.924s
[2K
| Adam | epoch: 019 | loss: 0.42357 - acc: 0.8059 -- iter: 1248/1980
[A[ATraining Step: 1156  | total loss: [1m[32m0.42512[0m[0m | time: 498.772s
[2K
| Adam | epoch: 019 | loss: 0.42512 - acc: 0.8034 -- iter: 1280/1980
[A[ATraining Step: 1157  | total loss: [1m[32m0.41425[0m[0m | time: 502.291s
[2K
| Adam | epoch: 019 | loss: 0.41425 - acc: 0.8168 -- iter: 1312/1980
[A[ATraining Step: 1158  | total loss: [1m[32m0.43217[0m[0m | time: 515.541s
[2K
| Adam | epoch: 019 | loss: 0.43217 - acc: 0.8101 -- iter: 1344/1980
[A[ATraining Step: 1159  | total loss: [1m[32m0.42709[0m[0m | time: 528.019s
[2K
| Adam | epoch: 019 | loss: 0.42709 - acc: 0.8135 -- iter: 1376/1980
[A[ATraining Step: 1160  | total loss: [1m[32m0.42469[0m[0m | time: 534.238s
[2K
| Adam | epoch: 019 | loss: 0.42469 - acc: 0.8134 -- iter: 1408/1980
[A[ATraining Step: 1161  | total loss: [1m[32m0.43420[0m[0m | time: 549.409s
[2K
| Adam | epoch: 019 | loss: 0.43420 - acc: 0.8008 -- iter: 1440/1980
[A[ATraining Step: 1162  | total loss: [1m[32m0.43549[0m[0m | time: 558.992s
[2K
| Adam | epoch: 019 | loss: 0.43549 - acc: 0.8020 -- iter: 1472/1980
[A[ATraining Step: 1163  | total loss: [1m[32m0.42057[0m[0m | time: 574.396s
[2K
| Adam | epoch: 019 | loss: 0.42057 - acc: 0.8093 -- iter: 1504/1980
[A[ATraining Step: 1164  | total loss: [1m[32m0.40694[0m[0m | time: 590.620s
[2K
| Adam | epoch: 019 | loss: 0.40694 - acc: 0.8221 -- iter: 1536/1980
[A[ATraining Step: 1165  | total loss: [1m[32m0.40534[0m[0m | time: 601.457s
[2K
| Adam | epoch: 019 | loss: 0.40534 - acc: 0.8243 -- iter: 1568/1980
[A[ATraining Step: 1166  | total loss: [1m[32m0.39480[0m[0m | time: 622.819s
[2K
| Adam | epoch: 019 | loss: 0.39480 - acc: 0.8356 -- iter: 1600/1980
[A[ATraining Step: 1167  | total loss: [1m[32m0.39437[0m[0m | time: 636.353s
[2K
| Adam | epoch: 019 | loss: 0.39437 - acc: 0.8364 -- iter: 1632/1980
[A[ATraining Step: 1168  | total loss: [1m[32m0.38742[0m[0m | time: 645.263s
[2K
| Adam | epoch: 019 | loss: 0.38742 - acc: 0.8434 -- iter: 1664/1980
[A[ATraining Step: 1169  | total loss: [1m[32m0.39563[0m[0m | time: 653.498s
[2K
| Adam | epoch: 019 | loss: 0.39563 - acc: 0.8309 -- iter: 1696/1980
[A[ATraining Step: 1170  | total loss: [1m[32m0.39305[0m[0m | time: 667.479s
[2K
| Adam | epoch: 019 | loss: 0.39305 - acc: 0.8322 -- iter: 1728/1980
[A[ATraining Step: 1171  | total loss: [1m[32m0.39088[0m[0m | time: 670.813s
[2K
| Adam | epoch: 019 | loss: 0.39088 - acc: 0.8334 -- iter: 1760/1980
[A[ATraining Step: 1172  | total loss: [1m[32m0.37704[0m[0m | time: 673.290s
[2K
| Adam | epoch: 019 | loss: 0.37704 - acc: 0.8406 -- iter: 1792/1980
[A[ATraining Step: 1173  | total loss: [1m[32m0.37567[0m[0m | time: 681.931s
[2K
| Adam | epoch: 019 | loss: 0.37567 - acc: 0.8441 -- iter: 1824/1980
[A[ATraining Step: 1174  | total loss: [1m[32m0.38267[0m[0m | time: 710.919s
[2K
| Adam | epoch: 019 | loss: 0.38267 - acc: 0.8409 -- iter: 1856/1980
[A[ATraining Step: 1175  | total loss: [1m[32m0.37620[0m[0m | time: 735.349s
[2K
| Adam | epoch: 019 | loss: 0.37620 - acc: 0.8475 -- iter: 1888/1980
[A[ATraining Step: 1176  | total loss: [1m[32m0.36861[0m[0m | time: 744.264s
[2K
| Adam | epoch: 019 | loss: 0.36861 - acc: 0.8502 -- iter: 1920/1980
[A[ATraining Step: 1177  | total loss: [1m[32m0.36616[0m[0m | time: 746.616s
[2K
| Adam | epoch: 019 | loss: 0.36616 - acc: 0.8496 -- iter: 1952/1980
[A[ATraining Step: 1178  | total loss: [1m[32m0.36317[0m[0m | time: 1072.245s
[2K
| Adam | epoch: 019 | loss: 0.36317 - acc: 0.8552 | val_loss: 0.52334 - val_acc: 0.7674 -- iter: 1980/1980
--
Training Step: 1179  | total loss: [1m[32m0.35988[0m[0m | time: 15.468s
[2K
| Adam | epoch: 020 | loss: 0.35988 - acc: 0.8541 -- iter: 0032/1980
[A[ATraining Step: 1180  | total loss: [1m[32m0.35276[0m[0m | time: 40.838s
[2K
| Adam | epoch: 020 | loss: 0.35276 - acc: 0.8624 -- iter: 0064/1980
[A[ATraining Step: 1181  | total loss: [1m[32m0.36170[0m[0m | time: 73.125s
[2K
| Adam | epoch: 020 | loss: 0.36170 - acc: 0.8606 -- iter: 0096/1980
[A[ATraining Step: 1182  | total loss: [1m[32m0.36780[0m[0m | time: 116.355s
[2K
| Adam | epoch: 020 | loss: 0.36780 - acc: 0.8589 -- iter: 0128/1980
[A[ATraining Step: 1183  | total loss: [1m[32m0.35591[0m[0m | time: 143.484s
[2K
| Adam | epoch: 020 | loss: 0.35591 - acc: 0.8636 -- iter: 0160/1980
[A[ATraining Step: 1184  | total loss: [1m[32m0.34691[0m[0m | time: 155.925s
[2K
| Adam | epoch: 020 | loss: 0.34691 - acc: 0.8679 -- iter: 0192/1980
[A[ATraining Step: 1185  | total loss: [1m[32m0.33658[0m[0m | time: 175.559s
[2K
| Adam | epoch: 020 | loss: 0.33658 - acc: 0.8748 -- iter: 0224/1980
[A[ATraining Step: 1186  | total loss: [1m[32m0.35224[0m[0m | time: 216.888s
[2K
| Adam | epoch: 020 | loss: 0.35224 - acc: 0.8624 -- iter: 0256/1980
[A[ATraining Step: 1187  | total loss: [1m[32m0.35901[0m[0m | time: 246.736s
[2K
| Adam | epoch: 020 | loss: 0.35901 - acc: 0.8574 -- iter: 0288/1980
[A[ATraining Step: 1188  | total loss: [1m[32m0.36012[0m[0m | time: 277.359s
[2K
| Adam | epoch: 020 | loss: 0.36012 - acc: 0.8498 -- iter: 0320/1980
[A[ATraining Step: 1189  | total loss: [1m[32m0.37179[0m[0m | time: 295.927s
[2K
| Adam | epoch: 020 | loss: 0.37179 - acc: 0.8398 -- iter: 0352/1980
[A[ATraining Step: 1190  | total loss: [1m[32m0.35723[0m[0m | time: 307.877s
[2K
| Adam | epoch: 020 | loss: 0.35723 - acc: 0.8464 -- iter: 0384/1980
[A[ATraining Step: 1191  | total loss: [1m[32m0.39450[0m[0m | time: 316.830s
[2K
| Adam | epoch: 020 | loss: 0.39450 - acc: 0.8274 -- iter: 0416/1980
[A[ATraining Step: 1192  | total loss: [1m[32m0.40970[0m[0m | time: 322.334s
[2K
| Adam | epoch: 020 | loss: 0.40970 - acc: 0.8165 -- iter: 0448/1980
[A[ATraining Step: 1193  | total loss: [1m[32m0.42223[0m[0m | time: 332.534s
[2K
| Adam | epoch: 020 | loss: 0.42223 - acc: 0.8130 -- iter: 0480/1980
[A[ATraining Step: 1194  | total loss: [1m[32m0.41960[0m[0m | time: 349.144s
[2K
| Adam | epoch: 020 | loss: 0.41960 - acc: 0.8098 -- iter: 0512/1980
[A[ATraining Step: 1195  | total loss: [1m[32m0.39412[0m[0m | time: 374.076s
[2K
| Adam | epoch: 020 | loss: 0.39412 - acc: 0.8289 -- iter: 0544/1980
[A[ATraining Step: 1196  | total loss: [1m[32m0.39597[0m[0m | time: 403.726s
[2K
| Adam | epoch: 020 | loss: 0.39597 - acc: 0.8272 -- iter: 0576/1980
[A[ATraining Step: 1197  | total loss: [1m[32m0.38924[0m[0m | time: 412.847s
[2K
| Adam | epoch: 020 | loss: 0.38924 - acc: 0.8338 -- iter: 0608/1980
[A[ATraining Step: 1198  | total loss: [1m[32m0.38248[0m[0m | time: 431.446s
[2K
| Adam | epoch: 020 | loss: 0.38248 - acc: 0.8397 -- iter: 0640/1980
[A[ATraining Step: 1199  | total loss: [1m[32m0.38099[0m[0m | time: 458.624s
[2K
| Adam | epoch: 020 | loss: 0.38099 - acc: 0.8370 -- iter: 0672/1980
[A[ATraining Step: 1200  | total loss: [1m[32m0.38158[0m[0m | time: 562.266s
[2K
| Adam | epoch: 020 | loss: 0.38158 - acc: 0.8283 | val_loss: 0.51245 - val_acc: 0.7674 -- iter: 0704/1980
--
Training Step: 1201  | total loss: [1m[32m0.37552[0m[0m | time: 563.356s
[2K
| Adam | epoch: 020 | loss: 0.37552 - acc: 0.8267 -- iter: 0736/1980
[A[ATraining Step: 1202  | total loss: [1m[32m0.37645[0m[0m | time: 564.538s
[2K
| Adam | epoch: 020 | loss: 0.37645 - acc: 0.8284 -- iter: 0768/1980
[A[ATraining Step: 1203  | total loss: [1m[32m0.36883[0m[0m | time: 565.739s
[2K
| Adam | epoch: 020 | loss: 0.36883 - acc: 0.8393 -- iter: 0800/1980
[A[ATraining Step: 1204  | total loss: [1m[32m0.39512[0m[0m | time: 577.756s
[2K
| Adam | epoch: 020 | loss: 0.39512 - acc: 0.8335 -- iter: 0832/1980
[A[ATraining Step: 1205  | total loss: [1m[32m0.40589[0m[0m | time: 578.927s
[2K
| Adam | epoch: 020 | loss: 0.40589 - acc: 0.8252 -- iter: 0864/1980
[A[ATraining Step: 1206  | total loss: [1m[32m0.40495[0m[0m | time: 592.280s
[2K
| Adam | epoch: 020 | loss: 0.40495 - acc: 0.8239 -- iter: 0896/1980
[A[ATraining Step: 1207  | total loss: [1m[32m0.39497[0m[0m | time: 593.447s
[2K
| Adam | epoch: 020 | loss: 0.39497 - acc: 0.8321 -- iter: 0928/1980
[A[ATraining Step: 1208  | total loss: [1m[32m0.40081[0m[0m | time: 594.541s
[2K
| Adam | epoch: 020 | loss: 0.40081 - acc: 0.8270 -- iter: 0960/1980
[A[ATraining Step: 1209  | total loss: [1m[32m0.41101[0m[0m | time: 595.993s
[2K
| Adam | epoch: 020 | loss: 0.41101 - acc: 0.8131 -- iter: 0992/1980
[A[ATraining Step: 1210  | total loss: [1m[32m0.40394[0m[0m | time: 599.287s
[2K
| Adam | epoch: 020 | loss: 0.40394 - acc: 0.8130 -- iter: 1024/1980
[A[ATraining Step: 1211  | total loss: [1m[32m0.39710[0m[0m | time: 621.209s
[2K
| Adam | epoch: 020 | loss: 0.39710 - acc: 0.8223 -- iter: 1056/1980
[A[ATraining Step: 1212  | total loss: [1m[32m0.38808[0m[0m | time: 646.915s
[2K
| Adam | epoch: 020 | loss: 0.38808 - acc: 0.8307 -- iter: 1088/1980
[A[ATraining Step: 1213  | total loss: [1m[32m0.38839[0m[0m | time: 660.713s
[2K
| Adam | epoch: 020 | loss: 0.38839 - acc: 0.8320 -- iter: 1120/1980
[A[ATraining Step: 1214  | total loss: [1m[32m0.39508[0m[0m | time: 690.656s
[2K
| Adam | epoch: 020 | loss: 0.39508 - acc: 0.8145 -- iter: 1152/1980
[A[ATraining Step: 1215  | total loss: [1m[32m0.39124[0m[0m | time: 712.048s
[2K
| Adam | epoch: 020 | loss: 0.39124 - acc: 0.8205 -- iter: 1184/1980
[A[ATraining Step: 1216  | total loss: [1m[32m0.39602[0m[0m | time: 727.744s
[2K
| Adam | epoch: 020 | loss: 0.39602 - acc: 0.8166 -- iter: 1216/1980
[A[ATraining Step: 1217  | total loss: [1m[32m0.40954[0m[0m | time: 753.975s
[2K
| Adam | epoch: 020 | loss: 0.40954 - acc: 0.8068 -- iter: 1248/1980
[A[ATraining Step: 1218  | total loss: [1m[32m0.40887[0m[0m | time: 773.099s
[2K
| Adam | epoch: 020 | loss: 0.40887 - acc: 0.8105 -- iter: 1280/1980
[A[ATraining Step: 1219  | total loss: [1m[32m0.39436[0m[0m | time: 820.905s
[2K
| Adam | epoch: 020 | loss: 0.39436 - acc: 0.8232 -- iter: 1312/1980
[A[ATraining Step: 1220  | total loss: [1m[32m0.39483[0m[0m | time: 845.963s
[2K
| Adam | epoch: 020 | loss: 0.39483 - acc: 0.8315 -- iter: 1344/1980
[A[ATraining Step: 1221  | total loss: [1m[32m0.39895[0m[0m | time: 848.941s
[2K
| Adam | epoch: 020 | loss: 0.39895 - acc: 0.8296 -- iter: 1376/1980
[A[ATraining Step: 1222  | total loss: [1m[32m0.38324[0m[0m | time: 875.780s
[2K
| Adam | epoch: 020 | loss: 0.38324 - acc: 0.8341 -- iter: 1408/1980
[A[ATraining Step: 1223  | total loss: [1m[32m0.37386[0m[0m | time: 895.320s
[2K
| Adam | epoch: 020 | loss: 0.37386 - acc: 0.8382 -- iter: 1440/1980
[A[ATraining Step: 1224  | total loss: [1m[32m0.38474[0m[0m | time: 905.505s
[2K
| Adam | epoch: 020 | loss: 0.38474 - acc: 0.8294 -- iter: 1472/1980
[A[ATraining Step: 1225  | total loss: [1m[32m0.39037[0m[0m | time: 938.944s
[2K
| Adam | epoch: 020 | loss: 0.39037 - acc: 0.8246 -- iter: 1504/1980
[A[ATraining Step: 1226  | total loss: [1m[32m0.39233[0m[0m | time: 972.154s
[2K
| Adam | epoch: 020 | loss: 0.39233 - acc: 0.8140 -- iter: 1536/1980
[A[ATraining Step: 1227  | total loss: [1m[32m0.38234[0m[0m | time: 1001.238s
[2K
| Adam | epoch: 020 | loss: 0.38234 - acc: 0.8232 -- iter: 1568/1980
[A[ATraining Step: 1228  | total loss: [1m[32m0.38757[0m[0m | time: 1024.027s
[2K
| Adam | epoch: 020 | loss: 0.38757 - acc: 0.8253 -- iter: 1600/1980
[A[ATraining Step: 1229  | total loss: [1m[32m0.37660[0m[0m | time: 1039.105s
[2K
| Adam | epoch: 020 | loss: 0.37660 - acc: 0.8334 -- iter: 1632/1980
[A[ATraining Step: 1230  | total loss: [1m[32m0.38781[0m[0m | time: 1060.667s
[2K
| Adam | epoch: 020 | loss: 0.38781 - acc: 0.8250 -- iter: 1664/1980
[A[ATraining Step: 1231  | total loss: [1m[32m0.37293[0m[0m | time: 1062.762s
[2K
| Adam | epoch: 020 | loss: 0.37293 - acc: 0.8332 -- iter: 1696/1980
[A[ATraining Step: 1232  | total loss: [1m[32m0.36604[0m[0m | time: 1064.976s
[2K
| Adam | epoch: 020 | loss: 0.36604 - acc: 0.8373 -- iter: 1728/1980
[A[ATraining Step: 1233  | total loss: [1m[32m0.36555[0m[0m | time: 1067.071s
[2K
| Adam | epoch: 020 | loss: 0.36555 - acc: 0.8380 -- iter: 1760/1980
[A[ATraining Step: 1234  | total loss: [1m[32m0.35496[0m[0m | time: 1068.556s
[2K
| Adam | epoch: 020 | loss: 0.35496 - acc: 0.8448 -- iter: 1792/1980
[A[ATraining Step: 1235  | total loss: [1m[32m0.35115[0m[0m | time: 1070.391s
[2K
| Adam | epoch: 020 | loss: 0.35115 - acc: 0.8478 -- iter: 1824/1980
[A[ATraining Step: 1236  | total loss: [1m[32m0.35387[0m[0m | time: 1071.514s
[2K
| Adam | epoch: 020 | loss: 0.35387 - acc: 0.8568 -- iter: 1856/1980
[A[ATraining Step: 1237  | total loss: [1m[32m0.34434[0m[0m | time: 1073.458s
[2K
| Adam | epoch: 020 | loss: 0.34434 - acc: 0.8649 -- iter: 1888/1980
[A[ATraining Step: 1238  | total loss: [1m[32m0.34352[0m[0m | time: 1086.907s
[2K
| Adam | epoch: 020 | loss: 0.34352 - acc: 0.8596 -- iter: 1920/1980
[A[ATraining Step: 1239  | total loss: [1m[32m0.35433[0m[0m | time: 1099.393s
[2K
| Adam | epoch: 020 | loss: 0.35433 - acc: 0.8455 -- iter: 1952/1980
[A[ATraining Step: 1240  | total loss: [1m[32m0.34937[0m[0m | time: 1280.391s
[2K
| Adam | epoch: 020 | loss: 0.34937 - acc: 0.8516 | val_loss: 0.52527 - val_acc: 0.7674 -- iter: 1980/1980
--
Training Step: 1241  | total loss: [1m[32m0.33933[0m[0m | time: 28.064s
[2K
| Adam | epoch: 021 | loss: 0.33933 - acc: 0.8665 -- iter: 0032/1980
[A[ATraining Step: 1242  | total loss: [1m[32m0.32942[0m[0m | time: 39.005s
[2K
| Adam | epoch: 021 | loss: 0.32942 - acc: 0.8673 -- iter: 0064/1980
[A[ATraining Step: 1243  | total loss: [1m[32m0.33055[0m[0m | time: 64.359s
[2K
| Adam | epoch: 021 | loss: 0.33055 - acc: 0.8650 -- iter: 0096/1980
[A[ATraining Step: 1244  | total loss: [1m[32m0.32618[0m[0m | time: 100.467s
[2K
| Adam | epoch: 021 | loss: 0.32618 - acc: 0.8660 -- iter: 0128/1980
[A[ATraining Step: 1245  | total loss: [1m[32m0.32940[0m[0m | time: 156.686s
[2K
| Adam | epoch: 021 | loss: 0.32940 - acc: 0.8637 -- iter: 0160/1980
[A[ATraining Step: 1246  | total loss: [1m[32m0.33659[0m[0m | time: 243.702s
[2K
| Adam | epoch: 021 | loss: 0.33659 - acc: 0.8586 -- iter: 0192/1980
[A[ATraining Step: 1247  | total loss: [1m[32m0.32502[0m[0m | time: 276.129s
[2K
| Adam | epoch: 021 | loss: 0.32502 - acc: 0.8634 -- iter: 0224/1980
[A[ATraining Step: 1248  | total loss: [1m[32m0.30934[0m[0m | time: 330.537s
[2K
| Adam | epoch: 021 | loss: 0.30934 - acc: 0.8770 -- iter: 0256/1980
[A[ATraining Step: 1249  | total loss: [1m[32m0.31278[0m[0m | time: 368.128s
[2K
| Adam | epoch: 021 | loss: 0.31278 - acc: 0.8737 -- iter: 0288/1980
[A[ATraining Step: 1250  | total loss: [1m[32m0.30944[0m[0m | time: 398.029s
[2K
| Adam | epoch: 021 | loss: 0.30944 - acc: 0.8738 -- iter: 0320/1980
[A[ATraining Step: 1251  | total loss: [1m[32m0.30103[0m[0m | time: 431.197s
[2K
| Adam | epoch: 021 | loss: 0.30103 - acc: 0.8802 -- iter: 0352/1980
[A[ATraining Step: 1252  | total loss: [1m[32m0.29692[0m[0m | time: 445.829s
[2K
| Adam | epoch: 021 | loss: 0.29692 - acc: 0.8766 -- iter: 0384/1980
[A[ATraining Step: 1253  | total loss: [1m[32m0.31139[0m[0m | time: 501.117s
[2K
| Adam | epoch: 021 | loss: 0.31139 - acc: 0.8733 -- iter: 0416/1980
[A[ATraining Step: 1254  | total loss: [1m[32m0.31549[0m[0m | time: 546.542s
[2K
| Adam | epoch: 021 | loss: 0.31549 - acc: 0.8672 -- iter: 0448/1980
[A[ATraining Step: 1255  | total loss: [1m[32m0.30627[0m[0m | time: 592.378s
[2K
| Adam | epoch: 021 | loss: 0.30627 - acc: 0.8742 -- iter: 0480/1980
[A[ATraining Step: 1256  | total loss: [1m[32m0.30302[0m[0m | time: 617.667s
[2K
| Adam | epoch: 021 | loss: 0.30302 - acc: 0.8681 -- iter: 0512/1980
[A[ATraining Step: 1257  | total loss: [1m[32m0.32335[0m[0m | time: 658.502s
[2K
| Adam | epoch: 021 | loss: 0.32335 - acc: 0.8563 -- iter: 0544/1980
[A[ATraining Step: 1258  | total loss: [1m[32m0.32141[0m[0m | time: 683.511s
[2K
| Adam | epoch: 021 | loss: 0.32141 - acc: 0.8581 -- iter: 0576/1980
[A[ATraining Step: 1259  | total loss: [1m[32m0.31834[0m[0m | time: 727.297s
[2K
| Adam | epoch: 021 | loss: 0.31834 - acc: 0.8567 -- iter: 0608/1980
[A[ATraining Step: 1260  | total loss: [1m[32m0.30838[0m[0m | time: 743.724s
[2K
| Adam | epoch: 021 | loss: 0.30838 - acc: 0.8639 -- iter: 0640/1980
[A[ATraining Step: 1261  | total loss: [1m[32m0.29716[0m[0m | time: 774.134s
[2K
| Adam | epoch: 021 | loss: 0.29716 - acc: 0.8703 -- iter: 0672/1980
[A[ATraining Step: 1262  | total loss: [1m[32m0.32784[0m[0m | time: 822.360s
[2K
| Adam | epoch: 021 | loss: 0.32784 - acc: 0.8583 -- iter: 0704/1980
[A[ATraining Step: 1263  | total loss: [1m[32m0.34412[0m[0m | time: 863.122s
[2K
| Adam | epoch: 021 | loss: 0.34412 - acc: 0.8475 -- iter: 0736/1980
[A[ATraining Step: 1264  | total loss: [1m[32m0.34579[0m[0m | time: 885.799s
[2K
| Adam | epoch: 021 | loss: 0.34579 - acc: 0.8471 -- iter: 0768/1980
[A[ATraining Step: 1265  | total loss: [1m[32m0.33504[0m[0m | time: 912.215s
[2K
| Adam | epoch: 021 | loss: 0.33504 - acc: 0.8530 -- iter: 0800/1980
[A[ATraining Step: 1266  | total loss: [1m[32m0.32934[0m[0m | time: 913.127s
[2K
| Adam | epoch: 021 | loss: 0.32934 - acc: 0.8583 -- iter: 0832/1980
[A[ATraining Step: 1267  | total loss: [1m[32m0.32166[0m[0m | time: 914.253s
[2K
| Adam | epoch: 021 | loss: 0.32166 - acc: 0.8569 -- iter: 0864/1980
[A[ATraining Step: 1268  | total loss: [1m[32m0.32110[0m[0m | time: 915.383s
[2K
| Adam | epoch: 021 | loss: 0.32110 - acc: 0.8618 -- iter: 0896/1980
[A[ATraining Step: 1269  | total loss: [1m[32m0.32274[0m[0m | time: 916.488s
[2K
| Adam | epoch: 021 | loss: 0.32274 - acc: 0.8600 -- iter: 0928/1980
[A[ATraining Step: 1270  | total loss: [1m[32m0.33857[0m[0m | time: 917.663s
[2K
| Adam | epoch: 021 | loss: 0.33857 - acc: 0.8553 -- iter: 0960/1980
[A[ATraining Step: 1271  | total loss: [1m[32m0.34693[0m[0m | time: 918.817s
[2K
| Adam | epoch: 021 | loss: 0.34693 - acc: 0.8479 -- iter: 0992/1980
[A[ATraining Step: 1272  | total loss: [1m[32m0.34437[0m[0m | time: 919.939s
[2K
| Adam | epoch: 021 | loss: 0.34437 - acc: 0.8443 -- iter: 1024/1980
[A[ATraining Step: 1273  | total loss: [1m[32m0.33724[0m[0m | time: 921.142s
[2K
| Adam | epoch: 021 | loss: 0.33724 - acc: 0.8411 -- iter: 1056/1980
[A[ATraining Step: 1274  | total loss: [1m[32m0.35899[0m[0m | time: 922.388s
[2K
| Adam | epoch: 021 | loss: 0.35899 - acc: 0.8320 -- iter: 1088/1980
[A[ATraining Step: 1275  | total loss: [1m[32m0.37110[0m[0m | time: 923.684s
[2K
| Adam | epoch: 021 | loss: 0.37110 - acc: 0.8332 -- iter: 1120/1980
[A[ATraining Step: 1276  | total loss: [1m[32m0.36899[0m[0m | time: 954.181s
[2K
| Adam | epoch: 021 | loss: 0.36899 - acc: 0.8405 -- iter: 1152/1980
[A[ATraining Step: 1277  | total loss: [1m[32m0.36952[0m[0m | time: 967.321s
[2K
| Adam | epoch: 021 | loss: 0.36952 - acc: 0.8408 -- iter: 1184/1980
[A[ATraining Step: 1278  | total loss: [1m[32m0.37796[0m[0m | time: 990.453s
[2K
| Adam | epoch: 021 | loss: 0.37796 - acc: 0.8349 -- iter: 1216/1980
[A[ATraining Step: 1279  | total loss: [1m[32m0.36591[0m[0m | time: 1003.489s
[2K
| Adam | epoch: 021 | loss: 0.36591 - acc: 0.8420 -- iter: 1248/1980
[A[ATraining Step: 1280  | total loss: [1m[32m0.37485[0m[0m | time: 1028.918s
[2K
| Adam | epoch: 021 | loss: 0.37485 - acc: 0.8266 -- iter: 1280/1980
[A[ATraining Step: 1281  | total loss: [1m[32m0.37157[0m[0m | time: 1052.468s
[2K
| Adam | epoch: 021 | loss: 0.37157 - acc: 0.8314 -- iter: 1312/1980
[A[ATraining Step: 1282  | total loss: [1m[32m0.36654[0m[0m | time: 1088.370s
[2K
| Adam | epoch: 021 | loss: 0.36654 - acc: 0.8326 -- iter: 1344/1980
[A[ATraining Step: 1283  | total loss: [1m[32m0.38345[0m[0m | time: 1095.610s
[2K
| Adam | epoch: 021 | loss: 0.38345 - acc: 0.8212 -- iter: 1376/1980
[A[ATraining Step: 1284  | total loss: [1m[32m0.39525[0m[0m | time: 1108.514s
[2K
| Adam | epoch: 021 | loss: 0.39525 - acc: 0.8141 -- iter: 1408/1980
[A[ATraining Step: 1285  | total loss: [1m[32m0.39085[0m[0m | time: 1126.613s
[2K
| Adam | epoch: 021 | loss: 0.39085 - acc: 0.8202 -- iter: 1440/1980
[A[ATraining Step: 1286  | total loss: [1m[32m0.38275[0m[0m | time: 1152.568s
[2K
| Adam | epoch: 021 | loss: 0.38275 - acc: 0.8288 -- iter: 1472/1980
[A[ATraining Step: 1287  | total loss: [1m[32m0.36971[0m[0m | time: 1183.267s
[2K
| Adam | epoch: 021 | loss: 0.36971 - acc: 0.8366 -- iter: 1504/1980
[A[ATraining Step: 1288  | total loss: [1m[32m0.36065[0m[0m | time: 1202.661s
[2K
| Adam | epoch: 021 | loss: 0.36065 - acc: 0.8435 -- iter: 1536/1980
[A[ATraining Step: 1289  | total loss: [1m[32m0.37189[0m[0m | time: 1215.470s
[2K
| Adam | epoch: 021 | loss: 0.37189 - acc: 0.8373 -- iter: 1568/1980
[A[ATraining Step: 1290  | total loss: [1m[32m0.36542[0m[0m | time: 1230.313s
[2K
| Adam | epoch: 021 | loss: 0.36542 - acc: 0.8379 -- iter: 1600/1980
[A[ATraining Step: 1291  | total loss: [1m[32m0.36180[0m[0m | time: 1247.119s
[2K
| Adam | epoch: 021 | loss: 0.36180 - acc: 0.8417 -- iter: 1632/1980
[A[ATraining Step: 1292  | total loss: [1m[32m0.35617[0m[0m | time: 1254.080s
[2K
| Adam | epoch: 021 | loss: 0.35617 - acc: 0.8450 -- iter: 1664/1980
[A[ATraining Step: 1293  | total loss: [1m[32m0.35378[0m[0m | time: 1265.253s
[2K
| Adam | epoch: 021 | loss: 0.35378 - acc: 0.8511 -- iter: 1696/1980
[A[ATraining Step: 1294  | total loss: [1m[32m0.35300[0m[0m | time: 1279.076s
[2K
| Adam | epoch: 021 | loss: 0.35300 - acc: 0.8473 -- iter: 1728/1980
[A[ATraining Step: 1295  | total loss: [1m[32m0.35298[0m[0m | time: 1293.854s
[2K
| Adam | epoch: 021 | loss: 0.35298 - acc: 0.8438 -- iter: 1760/1980
[A[ATraining Step: 1296  | total loss: [1m[32m0.35710[0m[0m | time: 1310.843s
[2K
| Adam | epoch: 021 | loss: 0.35710 - acc: 0.8375 -- iter: 1792/1980
[A[ATraining Step: 1297  | total loss: [1m[32m0.34310[0m[0m | time: 1332.508s
[2K
| Adam | epoch: 021 | loss: 0.34310 - acc: 0.8475 -- iter: 1824/1980
[A[ATraining Step: 1298  | total loss: [1m[32m0.33329[0m[0m | time: 1340.751s
[2K
| Adam | epoch: 021 | loss: 0.33329 - acc: 0.8503 -- iter: 1856/1980
[A[ATraining Step: 1299  | total loss: [1m[32m0.33113[0m[0m | time: 1341.935s
[2K
| Adam | epoch: 021 | loss: 0.33113 - acc: 0.8496 -- iter: 1888/1980
[A[ATraining Step: 1300  | total loss: [1m[32m0.32132[0m[0m | time: 1343.028s
[2K
| Adam | epoch: 021 | loss: 0.32132 - acc: 0.8584 -- iter: 1920/1980
[A[ATraining Step: 1301  | total loss: [1m[32m0.31522[0m[0m | time: 1344.084s
[2K
| Adam | epoch: 021 | loss: 0.31522 - acc: 0.8601 -- iter: 1952/1980
[A[ATraining Step: 1302  | total loss: [1m[32m0.30821[0m[0m | time: 1434.918s
[2K
| Adam | epoch: 021 | loss: 0.30821 - acc: 0.8678 | val_loss: 0.52330 - val_acc: 0.7674 -- iter: 1980/1980
--
Training Step: 1303  | total loss: [1m[32m0.30279[0m[0m | time: 1.635s
[2K
| Adam | epoch: 022 | loss: 0.30279 - acc: 0.8717 -- iter: 0032/1980
[A[ATraining Step: 1304  | total loss: [1m[32m0.30014[0m[0m | time: 10.589s
[2K
| Adam | epoch: 022 | loss: 0.30014 - acc: 0.8657 -- iter: 0064/1980
[A[ATraining Step: 1305  | total loss: [1m[32m0.29212[0m[0m | time: 31.370s
[2K
| Adam | epoch: 022 | loss: 0.29212 - acc: 0.8729 -- iter: 0096/1980
[A[ATraining Step: 1306  | total loss: [1m[32m0.30218[0m[0m | time: 52.498s
[2K
| Adam | epoch: 022 | loss: 0.30218 - acc: 0.8637 -- iter: 0128/1980
[A[ATraining Step: 1307  | total loss: [1m[32m0.31254[0m[0m | time: 63.742s
[2K
| Adam | epoch: 022 | loss: 0.31254 - acc: 0.8586 -- iter: 0160/1980
[A[ATraining Step: 1308  | total loss: [1m[32m0.29627[0m[0m | time: 81.594s
[2K
| Adam | epoch: 022 | loss: 0.29627 - acc: 0.8728 -- iter: 0192/1980
[A[ATraining Step: 1309  | total loss: [1m[32m0.28884[0m[0m | time: 102.453s
[2K
| Adam | epoch: 022 | loss: 0.28884 - acc: 0.8792 -- iter: 0224/1980
[A[ATraining Step: 1310  | total loss: [1m[32m0.29180[0m[0m | time: 116.412s
[2K
| Adam | epoch: 022 | loss: 0.29180 - acc: 0.8788 -- iter: 0256/1980
[A[ATraining Step: 1311  | total loss: [1m[32m0.28462[0m[0m | time: 161.944s
[2K
| Adam | epoch: 022 | loss: 0.28462 - acc: 0.8784 -- iter: 0288/1980
[A[ATraining Step: 1312  | total loss: [1m[32m0.28345[0m[0m | time: 193.978s
[2K
| Adam | epoch: 022 | loss: 0.28345 - acc: 0.8750 -- iter: 0320/1980
[A[ATraining Step: 1313  | total loss: [1m[32m0.29054[0m[0m | time: 213.030s
[2K
| Adam | epoch: 022 | loss: 0.29054 - acc: 0.8687 -- iter: 0352/1980
[A[ATraining Step: 1314  | total loss: [1m[32m0.28515[0m[0m | time: 226.723s
[2K
| Adam | epoch: 022 | loss: 0.28515 - acc: 0.8725 -- iter: 0384/1980
[A[ATraining Step: 1315  | total loss: [1m[32m0.30996[0m[0m | time: 249.950s
[2K
| Adam | epoch: 022 | loss: 0.30996 - acc: 0.8665 -- iter: 0416/1980
[A[ATraining Step: 1316  | total loss: [1m[32m0.29994[0m[0m | time: 276.648s
[2K
| Adam | epoch: 022 | loss: 0.29994 - acc: 0.8704 -- iter: 0448/1980
[A[ATraining Step: 1317  | total loss: [1m[32m0.29233[0m[0m | time: 279.882s
[2K
| Adam | epoch: 022 | loss: 0.29233 - acc: 0.8772 -- iter: 0480/1980
[A[ATraining Step: 1318  | total loss: [1m[32m0.30085[0m[0m | time: 284.444s
[2K
| Adam | epoch: 022 | loss: 0.30085 - acc: 0.8676 -- iter: 0512/1980
[A[ATraining Step: 1319  | total loss: [1m[32m0.30850[0m[0m | time: 292.495s
[2K
| Adam | epoch: 022 | loss: 0.30850 - acc: 0.8589 -- iter: 0544/1980
[A[ATraining Step: 1320  | total loss: [1m[32m0.29836[0m[0m | time: 301.555s
[2K
| Adam | epoch: 022 | loss: 0.29836 - acc: 0.8668 -- iter: 0576/1980
[A[ATraining Step: 1321  | total loss: [1m[32m0.28303[0m[0m | time: 305.636s
[2K
| Adam | epoch: 022 | loss: 0.28303 - acc: 0.8739 -- iter: 0608/1980
[A[ATraining Step: 1322  | total loss: [1m[32m0.29190[0m[0m | time: 313.397s
[2K
| Adam | epoch: 022 | loss: 0.29190 - acc: 0.8615 -- iter: 0640/1980
[A[ATraining Step: 1323  | total loss: [1m[32m0.29422[0m[0m | time: 322.314s
[2K
| Adam | epoch: 022 | loss: 0.29422 - acc: 0.8610 -- iter: 0672/1980
[A[ATraining Step: 1324  | total loss: [1m[32m0.29552[0m[0m | time: 337.346s
[2K
| Adam | epoch: 022 | loss: 0.29552 - acc: 0.8607 -- iter: 0704/1980
[A[ATraining Step: 1325  | total loss: [1m[32m0.29374[0m[0m | time: 347.916s
[2K
| Adam | epoch: 022 | loss: 0.29374 - acc: 0.8590 -- iter: 0736/1980
[A[ATraining Step: 1326  | total loss: [1m[32m0.29134[0m[0m | time: 353.520s
[2K
| Adam | epoch: 022 | loss: 0.29134 - acc: 0.8637 -- iter: 0768/1980
[A[ATraining Step: 1327  | total loss: [1m[32m0.30378[0m[0m | time: 363.307s
[2K
| Adam | epoch: 022 | loss: 0.30378 - acc: 0.8617 -- iter: 0800/1980
[A[ATraining Step: 1328  | total loss: [1m[32m0.30534[0m[0m | time: 371.744s
[2K
| Adam | epoch: 022 | loss: 0.30534 - acc: 0.8630 -- iter: 0832/1980
[A[ATraining Step: 1329  | total loss: [1m[32m0.30314[0m[0m | time: 379.155s
[2K
| Adam | epoch: 022 | loss: 0.30314 - acc: 0.8611 -- iter: 0864/1980
[A[ATraining Step: 1330  | total loss: [1m[32m0.32925[0m[0m | time: 380.058s
[2K
| Adam | epoch: 022 | loss: 0.32925 - acc: 0.8500 -- iter: 0896/1980
[A[ATraining Step: 1331  | total loss: [1m[32m0.33162[0m[0m | time: 381.115s
[2K
| Adam | epoch: 022 | loss: 0.33162 - acc: 0.8525 -- iter: 0928/1980
[A[ATraining Step: 1332  | total loss: [1m[32m0.32396[0m[0m | time: 382.269s
[2K
| Adam | epoch: 022 | loss: 0.32396 - acc: 0.8547 -- iter: 0960/1980
[A[ATraining Step: 1333  | total loss: [1m[32m0.31647[0m[0m | time: 383.352s
[2K
| Adam | epoch: 022 | loss: 0.31647 - acc: 0.8568 -- iter: 0992/1980
[A[ATraining Step: 1334  | total loss: [1m[32m0.31008[0m[0m | time: 384.538s
[2K
| Adam | epoch: 022 | loss: 0.31008 - acc: 0.8586 -- iter: 1024/1980
[A[ATraining Step: 1335  | total loss: [1m[32m0.32037[0m[0m | time: 385.585s
[2K
| Adam | epoch: 022 | loss: 0.32037 - acc: 0.8634 -- iter: 1056/1980
[A[ATraining Step: 1336  | total loss: [1m[32m0.32202[0m[0m | time: 386.835s
[2K
| Adam | epoch: 022 | loss: 0.32202 - acc: 0.8676 -- iter: 1088/1980
[A[ATraining Step: 1337  | total loss: [1m[32m0.31839[0m[0m | time: 388.046s
[2K
| Adam | epoch: 022 | loss: 0.31839 - acc: 0.8653 -- iter: 1120/1980
[A[ATraining Step: 1338  | total loss: [1m[32m0.30941[0m[0m | time: 389.161s
[2K
| Adam | epoch: 022 | loss: 0.30941 - acc: 0.8662 -- iter: 1152/1980
[A[ATraining Step: 1339  | total loss: [1m[32m0.31939[0m[0m | time: 390.325s
[2K
| Adam | epoch: 022 | loss: 0.31939 - acc: 0.8640 -- iter: 1184/1980
[A[ATraining Step: 1340  | total loss: [1m[32m0.31755[0m[0m | time: 391.491s
[2K
| Adam | epoch: 022 | loss: 0.31755 - acc: 0.8651 -- iter: 1216/1980
[A[ATraining Step: 1341  | total loss: [1m[32m0.31653[0m[0m | time: 395.368s
[2K
| Adam | epoch: 022 | loss: 0.31653 - acc: 0.8598 -- iter: 1248/1980
[A[ATraining Step: 1342  | total loss: [1m[32m0.30634[0m[0m | time: 413.131s
[2K
| Adam | epoch: 022 | loss: 0.30634 - acc: 0.8676 -- iter: 1280/1980
[A[ATraining Step: 1343  | total loss: [1m[32m0.31091[0m[0m | time: 423.932s
[2K
| Adam | epoch: 022 | loss: 0.31091 - acc: 0.8652 -- iter: 1312/1980
[A[ATraining Step: 1344  | total loss: [1m[32m0.31398[0m[0m | time: 436.254s
[2K
| Adam | epoch: 022 | loss: 0.31398 - acc: 0.8631 -- iter: 1344/1980
[A[ATraining Step: 1345  | total loss: [1m[32m0.31495[0m[0m | time: 452.167s
[2K
| Adam | epoch: 022 | loss: 0.31495 - acc: 0.8611 -- iter: 1376/1980
[A[ATraining Step: 1346  | total loss: [1m[32m0.32622[0m[0m | time: 460.992s
[2K
| Adam | epoch: 022 | loss: 0.32622 - acc: 0.8531 -- iter: 1408/1980
[A[ATraining Step: 1347  | total loss: [1m[32m0.32793[0m[0m | time: 466.136s
[2K
| Adam | epoch: 022 | loss: 0.32793 - acc: 0.8522 -- iter: 1440/1980
[A[ATraining Step: 1348  | total loss: [1m[32m0.34032[0m[0m | time: 467.234s
[2K
| Adam | epoch: 022 | loss: 0.34032 - acc: 0.8451 -- iter: 1472/1980
[A[ATraining Step: 1349  | total loss: [1m[32m0.32710[0m[0m | time: 468.387s
[2K
| Adam | epoch: 022 | loss: 0.32710 - acc: 0.8575 -- iter: 1504/1980
[A[ATraining Step: 1350  | total loss: [1m[32m0.32293[0m[0m | time: 469.485s
[2K
| Adam | epoch: 022 | loss: 0.32293 - acc: 0.8592 -- iter: 1536/1980
[A[ATraining Step: 1351  | total loss: [1m[32m0.32285[0m[0m | time: 470.597s
[2K
| Adam | epoch: 022 | loss: 0.32285 - acc: 0.8577 -- iter: 1568/1980
[A[ATraining Step: 1352  | total loss: [1m[32m0.31747[0m[0m | time: 471.681s
[2K
| Adam | epoch: 022 | loss: 0.31747 - acc: 0.8594 -- iter: 1600/1980
[A[ATraining Step: 1353  | total loss: [1m[32m0.30465[0m[0m | time: 472.846s
[2K
| Adam | epoch: 022 | loss: 0.30465 - acc: 0.8641 -- iter: 1632/1980
[A[ATraining Step: 1354  | total loss: [1m[32m0.30255[0m[0m | time: 473.997s
[2K
| Adam | epoch: 022 | loss: 0.30255 - acc: 0.8683 -- iter: 1664/1980
[A[ATraining Step: 1355  | total loss: [1m[32m0.30268[0m[0m | time: 475.142s
[2K
| Adam | epoch: 022 | loss: 0.30268 - acc: 0.8721 -- iter: 1696/1980
[A[ATraining Step: 1356  | total loss: [1m[32m0.29513[0m[0m | time: 476.271s
[2K
| Adam | epoch: 022 | loss: 0.29513 - acc: 0.8755 -- iter: 1728/1980
[A[ATraining Step: 1357  | total loss: [1m[32m0.28961[0m[0m | time: 477.594s
[2K
| Adam | epoch: 022 | loss: 0.28961 - acc: 0.8817 -- iter: 1760/1980
[A[ATraining Step: 1358  | total loss: [1m[32m0.29147[0m[0m | time: 480.815s
[2K
| Adam | epoch: 022 | loss: 0.29147 - acc: 0.8810 -- iter: 1792/1980
[A[ATraining Step: 1359  | total loss: [1m[32m0.28895[0m[0m | time: 486.797s
[2K
| Adam | epoch: 022 | loss: 0.28895 - acc: 0.8804 -- iter: 1824/1980
[A[ATraining Step: 1360  | total loss: [1m[32m0.28866[0m[0m | time: 493.340s
[2K
| Adam | epoch: 022 | loss: 0.28866 - acc: 0.8799 -- iter: 1856/1980
[A[ATraining Step: 1361  | total loss: [1m[32m0.27803[0m[0m | time: 499.774s
[2K
| Adam | epoch: 022 | loss: 0.27803 - acc: 0.8825 -- iter: 1888/1980
[A[ATraining Step: 1362  | total loss: [1m[32m0.26892[0m[0m | time: 505.999s
[2K
| Adam | epoch: 022 | loss: 0.26892 - acc: 0.8849 -- iter: 1920/1980
[A[ATraining Step: 1363  | total loss: [1m[32m0.26104[0m[0m | time: 510.513s
[2K
| Adam | epoch: 022 | loss: 0.26104 - acc: 0.8902 -- iter: 1952/1980
[A[ATraining Step: 1364  | total loss: [1m[32m0.26186[0m[0m | time: 693.960s
[2K
| Adam | epoch: 022 | loss: 0.26186 - acc: 0.8886 | val_loss: 0.55215 - val_acc: 0.7690 -- iter: 1980/1980
--
Training Step: 1365  | total loss: [1m[32m0.29434[0m[0m | time: 8.910s
[2K
| Adam | epoch: 023 | loss: 0.29434 - acc: 0.8873 -- iter: 0032/1980
[A[ATraining Step: 1366  | total loss: [1m[32m0.28890[0m[0m | time: 21.314s
[2K
| Adam | epoch: 023 | loss: 0.28890 - acc: 0.8829 -- iter: 0064/1980
[A[ATraining Step: 1367  | total loss: [1m[32m0.28291[0m[0m | time: 29.561s
[2K
| Adam | epoch: 023 | loss: 0.28291 - acc: 0.8853 -- iter: 0096/1980
[A[ATraining Step: 1368  | total loss: [1m[32m0.28855[0m[0m | time: 36.369s
[2K
| Adam | epoch: 023 | loss: 0.28855 - acc: 0.8842 -- iter: 0128/1980
[A[ATraining Step: 1369  | total loss: [1m[32m0.28046[0m[0m | time: 42.290s
[2K
| Adam | epoch: 023 | loss: 0.28046 - acc: 0.8896 -- iter: 0160/1980
[A[ATraining Step: 1370  | total loss: [1m[32m0.26797[0m[0m | time: 46.897s
[2K
| Adam | epoch: 023 | loss: 0.26797 - acc: 0.8944 -- iter: 0192/1980
[A[ATraining Step: 1371  | total loss: [1m[32m0.27249[0m[0m | time: 53.439s
[2K
| Adam | epoch: 023 | loss: 0.27249 - acc: 0.8924 -- iter: 0224/1980
[A[ATraining Step: 1372  | total loss: [1m[32m0.26538[0m[0m | time: 69.176s
[2K
| Adam | epoch: 023 | loss: 0.26538 - acc: 0.8938 -- iter: 0256/1980
[A[ATraining Step: 1373  | total loss: [1m[32m0.26310[0m[0m | time: 76.241s
[2K
| Adam | epoch: 023 | loss: 0.26310 - acc: 0.8950 -- iter: 0288/1980
[A[ATraining Step: 1374  | total loss: [1m[32m0.25979[0m[0m | time: 85.095s
[2K
| Adam | epoch: 023 | loss: 0.25979 - acc: 0.8930 -- iter: 0320/1980
[A[ATraining Step: 1375  | total loss: [1m[32m0.24936[0m[0m | time: 86.116s
[2K
| Adam | epoch: 023 | loss: 0.24936 - acc: 0.9006 -- iter: 0352/1980
[A[ATraining Step: 1376  | total loss: [1m[32m0.24758[0m[0m | time: 87.234s
[2K
| Adam | epoch: 023 | loss: 0.24758 - acc: 0.9074 -- iter: 0384/1980
[A[ATraining Step: 1377  | total loss: [1m[32m0.25731[0m[0m | time: 88.348s
[2K
| Adam | epoch: 023 | loss: 0.25731 - acc: 0.9011 -- iter: 0416/1980
[A[ATraining Step: 1378  | total loss: [1m[32m0.26722[0m[0m | time: 89.482s
[2K
| Adam | epoch: 023 | loss: 0.26722 - acc: 0.8953 -- iter: 0448/1980
[A[ATraining Step: 1379  | total loss: [1m[32m0.27152[0m[0m | time: 90.654s
[2K
| Adam | epoch: 023 | loss: 0.27152 - acc: 0.8933 -- iter: 0480/1980
[A[ATraining Step: 1380  | total loss: [1m[32m0.26171[0m[0m | time: 91.977s
[2K
| Adam | epoch: 023 | loss: 0.26171 - acc: 0.9008 -- iter: 0512/1980
[A[ATraining Step: 1381  | total loss: [1m[32m0.25692[0m[0m | time: 93.232s
[2K
| Adam | epoch: 023 | loss: 0.25692 - acc: 0.9045 -- iter: 0544/1980
[A[ATraining Step: 1382  | total loss: [1m[32m0.26371[0m[0m | time: 94.650s
[2K
| Adam | epoch: 023 | loss: 0.26371 - acc: 0.9016 -- iter: 0576/1980
[A[ATraining Step: 1383  | total loss: [1m[32m0.26819[0m[0m | time: 95.837s
[2K
| Adam | epoch: 023 | loss: 0.26819 - acc: 0.8958 -- iter: 0608/1980
[A[ATraining Step: 1384  | total loss: [1m[32m0.27310[0m[0m | time: 97.068s
[2K
| Adam | epoch: 023 | loss: 0.27310 - acc: 0.8968 -- iter: 0640/1980
[A[ATraining Step: 1385  | total loss: [1m[32m0.26167[0m[0m | time: 98.408s
[2K
| Adam | epoch: 023 | loss: 0.26167 - acc: 0.9040 -- iter: 0672/1980
[A[ATraining Step: 1386  | total loss: [1m[32m0.27065[0m[0m | time: 102.218s
[2K
| Adam | epoch: 023 | loss: 0.27065 - acc: 0.8993 -- iter: 0704/1980
[A[ATraining Step: 1387  | total loss: [1m[32m0.27360[0m[0m | time: 106.621s
[2K
| Adam | epoch: 023 | loss: 0.27360 - acc: 0.9023 -- iter: 0736/1980
[A[ATraining Step: 1388  | total loss: [1m[32m0.28441[0m[0m | time: 115.542s
[2K
| Adam | epoch: 023 | loss: 0.28441 - acc: 0.8964 -- iter: 0768/1980
[A[ATraining Step: 1389  | total loss: [1m[32m0.30655[0m[0m | time: 127.150s
[2K
| Adam | epoch: 023 | loss: 0.30655 - acc: 0.8724 -- iter: 0800/1980
[A[ATraining Step: 1390  | total loss: [1m[32m0.36894[0m[0m | time: 144.912s
[2K
| Adam | epoch: 023 | loss: 0.36894 - acc: 0.8476 -- iter: 0832/1980
[A[ATraining Step: 1391  | total loss: [1m[32m0.37322[0m[0m | time: 152.520s
[2K
| Adam | epoch: 023 | loss: 0.37322 - acc: 0.8441 -- iter: 0864/1980
[A[ATraining Step: 1392  | total loss: [1m[32m0.36433[0m[0m | time: 164.176s
[2K
| Adam | epoch: 023 | loss: 0.36433 - acc: 0.8503 -- iter: 0896/1980
[A[ATraining Step: 1393  | total loss: [1m[32m0.34986[0m[0m | time: 175.655s
[2K
| Adam | epoch: 023 | loss: 0.34986 - acc: 0.8559 -- iter: 0928/1980
[A[ATraining Step: 1394  | total loss: [1m[32m0.34162[0m[0m | time: 188.926s
[2K
| Adam | epoch: 023 | loss: 0.34162 - acc: 0.8578 -- iter: 0960/1980
[A[ATraining Step: 1395  | total loss: [1m[32m0.33715[0m[0m | time: 202.724s
[2K
| Adam | epoch: 023 | loss: 0.33715 - acc: 0.8564 -- iter: 0992/1980
[A[ATraining Step: 1396  | total loss: [1m[32m0.33032[0m[0m | time: 210.660s
[2K
| Adam | epoch: 023 | loss: 0.33032 - acc: 0.8614 -- iter: 1024/1980
[A[ATraining Step: 1397  | total loss: [1m[32m0.35964[0m[0m | time: 211.825s
[2K
| Adam | epoch: 023 | loss: 0.35964 - acc: 0.8471 -- iter: 1056/1980
[A[ATraining Step: 1398  | total loss: [1m[32m0.34964[0m[0m | time: 212.964s
[2K
| Adam | epoch: 023 | loss: 0.34964 - acc: 0.8499 -- iter: 1088/1980
[A[ATraining Step: 1399  | total loss: [1m[32m0.35318[0m[0m | time: 214.199s
[2K
| Adam | epoch: 023 | loss: 0.35318 - acc: 0.8524 -- iter: 1120/1980
[A[ATraining Step: 1400  | total loss: [1m[32m0.36505[0m[0m | time: 219.783s
[2K
| Adam | epoch: 023 | loss: 0.36505 - acc: 0.8453 | val_loss: 0.60667 - val_acc: 0.7593 -- iter: 1152/1980
--
Training Step: 1401  | total loss: [1m[32m0.35748[0m[0m | time: 221.004s
[2K
| Adam | epoch: 023 | loss: 0.35748 - acc: 0.8483 -- iter: 1184/1980
[A[ATraining Step: 1402  | total loss: [1m[32m0.34306[0m[0m | time: 221.981s
[2K
| Adam | epoch: 023 | loss: 0.34306 - acc: 0.8541 -- iter: 1216/1980
[A[ATraining Step: 1403  | total loss: [1m[32m0.33913[0m[0m | time: 228.389s
[2K
| Adam | epoch: 023 | loss: 0.33913 - acc: 0.8468 -- iter: 1248/1980
[A[ATraining Step: 1404  | total loss: [1m[32m0.33025[0m[0m | time: 236.383s
[2K
| Adam | epoch: 023 | loss: 0.33025 - acc: 0.8527 -- iter: 1280/1980
[A[ATraining Step: 1405  | total loss: [1m[32m0.31570[0m[0m | time: 241.942s
[2K
| Adam | epoch: 023 | loss: 0.31570 - acc: 0.8612 -- iter: 1312/1980
[A[ATraining Step: 1406  | total loss: [1m[32m0.30890[0m[0m | time: 251.860s
[2K
| Adam | epoch: 023 | loss: 0.30890 - acc: 0.8626 -- iter: 1344/1980
[A[ATraining Step: 1407  | total loss: [1m[32m0.29991[0m[0m | time: 254.274s
[2K
| Adam | epoch: 023 | loss: 0.29991 - acc: 0.8670 -- iter: 1376/1980
[A[ATraining Step: 1408  | total loss: [1m[32m0.29817[0m[0m | time: 264.305s
[2K
| Adam | epoch: 023 | loss: 0.29817 - acc: 0.8678 -- iter: 1408/1980
[A[ATraining Step: 1409  | total loss: [1m[32m0.29974[0m[0m | time: 272.080s
[2K
| Adam | epoch: 023 | loss: 0.29974 - acc: 0.8622 -- iter: 1440/1980
[A[ATraining Step: 1410  | total loss: [1m[32m0.29778[0m[0m | time: 281.799s
[2K
| Adam | epoch: 023 | loss: 0.29778 - acc: 0.8666 -- iter: 1472/1980
[A[ATraining Step: 1411  | total loss: [1m[32m0.30338[0m[0m | time: 289.785s
[2K
| Adam | epoch: 023 | loss: 0.30338 - acc: 0.8644 -- iter: 1504/1980
[A[ATraining Step: 1412  | total loss: [1m[32m0.30592[0m[0m | time: 300.595s
[2K
| Adam | epoch: 023 | loss: 0.30592 - acc: 0.8623 -- iter: 1536/1980
[A[ATraining Step: 1413  | total loss: [1m[32m0.29509[0m[0m | time: 306.261s
[2K
| Adam | epoch: 023 | loss: 0.29509 - acc: 0.8636 -- iter: 1568/1980
[A[ATraining Step: 1414  | total loss: [1m[32m0.28232[0m[0m | time: 313.427s
[2K
| Adam | epoch: 023 | loss: 0.28232 - acc: 0.8741 -- iter: 1600/1980
[A[ATraining Step: 1415  | total loss: [1m[32m0.28156[0m[0m | time: 316.795s
[2K
| Adam | epoch: 023 | loss: 0.28156 - acc: 0.8835 -- iter: 1632/1980
[A[ATraining Step: 1416  | total loss: [1m[32m0.29377[0m[0m | time: 317.967s
[2K
| Adam | epoch: 023 | loss: 0.29377 - acc: 0.8702 -- iter: 1664/1980
[A[ATraining Step: 1417  | total loss: [1m[32m0.38193[0m[0m | time: 319.065s
[2K
| Adam | epoch: 023 | loss: 0.38193 - acc: 0.8394 -- iter: 1696/1980
[A[ATraining Step: 1418  | total loss: [1m[32m0.35882[0m[0m | time: 320.230s
[2K
| Adam | epoch: 023 | loss: 0.35882 - acc: 0.8524 -- iter: 1728/1980
[A[ATraining Step: 1419  | total loss: [1m[32m0.33681[0m[0m | time: 321.346s
[2K
| Adam | epoch: 023 | loss: 0.33681 - acc: 0.8640 -- iter: 1760/1980
[A[ATraining Step: 1420  | total loss: [1m[32m0.33735[0m[0m | time: 322.511s
[2K
| Adam | epoch: 023 | loss: 0.33735 - acc: 0.8620 -- iter: 1792/1980
[A[ATraining Step: 1421  | total loss: [1m[32m0.33326[0m[0m | time: 323.666s
[2K
| Adam | epoch: 023 | loss: 0.33326 - acc: 0.8664 -- iter: 1824/1980
[A[ATraining Step: 1422  | total loss: [1m[32m0.31616[0m[0m | time: 324.831s
[2K
| Adam | epoch: 023 | loss: 0.31616 - acc: 0.8704 -- iter: 1856/1980
[A[ATraining Step: 1423  | total loss: [1m[32m0.32438[0m[0m | time: 325.730s
[2K
| Adam | epoch: 023 | loss: 0.32438 - acc: 0.8646 -- iter: 1888/1980
[A[ATraining Step: 1424  | total loss: [1m[32m0.32225[0m[0m | time: 327.211s
[2K
| Adam | epoch: 023 | loss: 0.32225 - acc: 0.8594 -- iter: 1920/1980
[A[ATraining Step: 1425  | total loss: [1m[32m0.30978[0m[0m | time: 328.609s
[2K
| Adam | epoch: 023 | loss: 0.30978 - acc: 0.8672 -- iter: 1952/1980
[A[ATraining Step: 1426  | total loss: [1m[32m0.31508[0m[0m | time: 466.879s
[2K
| Adam | epoch: 023 | loss: 0.31508 - acc: 0.8649 | val_loss: 0.57053 - val_acc: 0.7625 -- iter: 1980/1980
--
Training Step: 1427  | total loss: [1m[32m0.30522[0m[0m | time: 1.261s
[2K
| Adam | epoch: 024 | loss: 0.30522 - acc: 0.8690 -- iter: 0032/1980
[A[ATraining Step: 1428  | total loss: [1m[32m0.29955[0m[0m | time: 2.547s
[2K
| Adam | epoch: 024 | loss: 0.29955 - acc: 0.8758 -- iter: 0064/1980
[A[ATraining Step: 1429  | total loss: [1m[32m0.28417[0m[0m | time: 3.814s
[2K
| Adam | epoch: 024 | loss: 0.28417 - acc: 0.8851 -- iter: 0096/1980
[A[ATraining Step: 1430  | total loss: [1m[32m0.27539[0m[0m | time: 4.987s
[2K
| Adam | epoch: 024 | loss: 0.27539 - acc: 0.8904 -- iter: 0128/1980
[A[ATraining Step: 1431  | total loss: [1m[32m0.28827[0m[0m | time: 6.015s
[2K
| Adam | epoch: 024 | loss: 0.28827 - acc: 0.8826 -- iter: 0160/1980
[A[ATraining Step: 1432  | total loss: [1m[32m0.28887[0m[0m | time: 7.297s
[2K
| Adam | epoch: 024 | loss: 0.28887 - acc: 0.8850 -- iter: 0192/1980
[A[ATraining Step: 1433  | total loss: [1m[32m0.28512[0m[0m | time: 8.523s
[2K
| Adam | epoch: 024 | loss: 0.28512 - acc: 0.8840 -- iter: 0224/1980
[A[ATraining Step: 1434  | total loss: [1m[32m0.28536[0m[0m | time: 9.721s
[2K
| Adam | epoch: 024 | loss: 0.28536 - acc: 0.8768 -- iter: 0256/1980
[A[ATraining Step: 1435  | total loss: [1m[32m0.27871[0m[0m | time: 11.152s
[2K
| Adam | epoch: 024 | loss: 0.27871 - acc: 0.8829 -- iter: 0288/1980
[A[ATraining Step: 1436  | total loss: [1m[32m0.27339[0m[0m | time: 15.743s
[2K
| Adam | epoch: 024 | loss: 0.27339 - acc: 0.8852 -- iter: 0320/1980
[A[ATraining Step: 1437  | total loss: [1m[32m0.26356[0m[0m | time: 17.745s
[2K
| Adam | epoch: 024 | loss: 0.26356 - acc: 0.8904 -- iter: 0352/1980
[A[ATraining Step: 1438  | total loss: [1m[32m0.25767[0m[0m | time: 19.925s
[2K
| Adam | epoch: 024 | loss: 0.25767 - acc: 0.8920 -- iter: 0384/1980
[A[ATraining Step: 1439  | total loss: [1m[32m0.25225[0m[0m | time: 22.408s
[2K
| Adam | epoch: 024 | loss: 0.25225 - acc: 0.8934 -- iter: 0416/1980
[A[ATraining Step: 1440  | total loss: [1m[32m0.26143[0m[0m | time: 31.431s
[2K
| Adam | epoch: 024 | loss: 0.26143 - acc: 0.8854 -- iter: 0448/1980
[A[ATraining Step: 1441  | total loss: [1m[32m0.25667[0m[0m | time: 39.649s
[2K
| Adam | epoch: 024 | loss: 0.25667 - acc: 0.8906 -- iter: 0480/1980
[A[ATraining Step: 1442  | total loss: [1m[32m0.26610[0m[0m | time: 42.956s
[2K
| Adam | epoch: 024 | loss: 0.26610 - acc: 0.8859 -- iter: 0512/1980
[A[ATraining Step: 1443  | total loss: [1m[32m0.26445[0m[0m | time: 47.276s
[2K
| Adam | epoch: 024 | loss: 0.26445 - acc: 0.8910 -- iter: 0544/1980
[A[ATraining Step: 1444  | total loss: [1m[32m0.26825[0m[0m | time: 54.825s
[2K
| Adam | epoch: 024 | loss: 0.26825 - acc: 0.8863 -- iter: 0576/1980
[A[ATraining Step: 1445  | total loss: [1m[32m0.27726[0m[0m | time: 69.834s
[2K
| Adam | epoch: 024 | loss: 0.27726 - acc: 0.8821 -- iter: 0608/1980
[A[ATraining Step: 1446  | total loss: [1m[32m0.28662[0m[0m | time: 75.107s
[2K
| Adam | epoch: 024 | loss: 0.28662 - acc: 0.8782 -- iter: 0640/1980
[A[ATraining Step: 1447  | total loss: [1m[32m0.28132[0m[0m | time: 88.666s
[2K
| Adam | epoch: 024 | loss: 0.28132 - acc: 0.8810 -- iter: 0672/1980
[A[ATraining Step: 1448  | total loss: [1m[32m0.26937[0m[0m | time: 92.929s
[2K
| Adam | epoch: 024 | loss: 0.26937 - acc: 0.8836 -- iter: 0704/1980
[A[ATraining Step: 1449  | total loss: [1m[32m0.25684[0m[0m | time: 98.391s
[2K
| Adam | epoch: 024 | loss: 0.25684 - acc: 0.8916 -- iter: 0736/1980
[A[ATraining Step: 1450  | total loss: [1m[32m0.24240[0m[0m | time: 115.867s
[2K
| Adam | epoch: 024 | loss: 0.24240 - acc: 0.8989 -- iter: 0768/1980
[A[ATraining Step: 1451  | total loss: [1m[32m0.23849[0m[0m | time: 124.790s
[2K
| Adam | epoch: 024 | loss: 0.23849 - acc: 0.9059 -- iter: 0800/1980
[A[ATraining Step: 1452  | total loss: [1m[32m0.24470[0m[0m | time: 136.411s
[2K
| Adam | epoch: 024 | loss: 0.24470 - acc: 0.8997 -- iter: 0832/1980
[A[ATraining Step: 1453  | total loss: [1m[32m0.23148[0m[0m | time: 142.548s
[2K
| Adam | epoch: 024 | loss: 0.23148 - acc: 0.9066 -- iter: 0864/1980
[A[ATraining Step: 1454  | total loss: [1m[32m0.23818[0m[0m | time: 147.789s
[2K
| Adam | epoch: 024 | loss: 0.23818 - acc: 0.9034 -- iter: 0896/1980
[A[ATraining Step: 1455  | total loss: [1m[32m0.23057[0m[0m | time: 155.975s
[2K
| Adam | epoch: 024 | loss: 0.23057 - acc: 0.9099 -- iter: 0928/1980
[A[ATraining Step: 1456  | total loss: [1m[32m0.23395[0m[0m | time: 166.187s
[2K
| Adam | epoch: 024 | loss: 0.23395 - acc: 0.9033 -- iter: 0960/1980
[A[ATraining Step: 1457  | total loss: [1m[32m0.22610[0m[0m | time: 171.374s
[2K
| Adam | epoch: 024 | loss: 0.22610 - acc: 0.9099 -- iter: 0992/1980
[A[ATraining Step: 1458  | total loss: [1m[32m0.21780[0m[0m | time: 179.122s
[2K
| Adam | epoch: 024 | loss: 0.21780 - acc: 0.9158 -- iter: 1024/1980
[A[ATraining Step: 1459  | total loss: [1m[32m0.21524[0m[0m | time: 186.587s
[2K
| Adam | epoch: 024 | loss: 0.21524 - acc: 0.9148 -- iter: 1056/1980
[A[ATraining Step: 1460  | total loss: [1m[32m0.21921[0m[0m | time: 193.345s
[2K
| Adam | epoch: 024 | loss: 0.21921 - acc: 0.9140 -- iter: 1088/1980
[A[ATraining Step: 1461  | total loss: [1m[32m0.23093[0m[0m | time: 196.134s
[2K
| Adam | epoch: 024 | loss: 0.23093 - acc: 0.9132 -- iter: 1120/1980
[A[ATraining Step: 1462  | total loss: [1m[32m0.23530[0m[0m | time: 197.160s
[2K
| Adam | epoch: 024 | loss: 0.23530 - acc: 0.9094 -- iter: 1152/1980
[A[ATraining Step: 1463  | total loss: [1m[32m0.24064[0m[0m | time: 198.259s
[2K
| Adam | epoch: 024 | loss: 0.24064 - acc: 0.9059 -- iter: 1184/1980
[A[ATraining Step: 1464  | total loss: [1m[32m0.23859[0m[0m | time: 199.387s
[2K
| Adam | epoch: 024 | loss: 0.23859 - acc: 0.9060 -- iter: 1216/1980
[A[ATraining Step: 1465  | total loss: [1m[32m0.23383[0m[0m | time: 200.415s
[2K
| Adam | epoch: 024 | loss: 0.23383 - acc: 0.9060 -- iter: 1248/1980
[A[ATraining Step: 1466  | total loss: [1m[32m0.23076[0m[0m | time: 201.485s
[2K
| Adam | epoch: 024 | loss: 0.23076 - acc: 0.9123 -- iter: 1280/1980
[A[ATraining Step: 1467  | total loss: [1m[32m0.22735[0m[0m | time: 202.631s
[2K
| Adam | epoch: 024 | loss: 0.22735 - acc: 0.9148 -- iter: 1312/1980
[A[ATraining Step: 1468  | total loss: [1m[32m0.23071[0m[0m | time: 203.770s
[2K
| Adam | epoch: 024 | loss: 0.23071 - acc: 0.9108 -- iter: 1344/1980
[A[ATraining Step: 1469  | total loss: [1m[32m0.22574[0m[0m | time: 204.883s
[2K
| Adam | epoch: 024 | loss: 0.22574 - acc: 0.9104 -- iter: 1376/1980
[A[ATraining Step: 1470  | total loss: [1m[32m0.24267[0m[0m | time: 205.978s
[2K
| Adam | epoch: 024 | loss: 0.24267 - acc: 0.9037 -- iter: 1408/1980
[A[ATraining Step: 1471  | total loss: [1m[32m0.23310[0m[0m | time: 207.234s
[2K
| Adam | epoch: 024 | loss: 0.23310 - acc: 0.9102 -- iter: 1440/1980
[A[ATraining Step: 1472  | total loss: [1m[32m0.23261[0m[0m | time: 208.442s
[2K
| Adam | epoch: 024 | loss: 0.23261 - acc: 0.9067 -- iter: 1472/1980
[A[ATraining Step: 1473  | total loss: [1m[32m0.23828[0m[0m | time: 209.361s
[2K
| Adam | epoch: 024 | loss: 0.23828 - acc: 0.9066 -- iter: 1504/1980
[A[ATraining Step: 1474  | total loss: [1m[32m0.24536[0m[0m | time: 210.373s
[2K
| Adam | epoch: 024 | loss: 0.24536 - acc: 0.9035 -- iter: 1536/1980
[A[ATraining Step: 1475  | total loss: [1m[32m0.24631[0m[0m | time: 211.403s
[2K
| Adam | epoch: 024 | loss: 0.24631 - acc: 0.9006 -- iter: 1568/1980
[A[ATraining Step: 1476  | total loss: [1m[32m0.24815[0m[0m | time: 212.409s
[2K
| Adam | epoch: 024 | loss: 0.24815 - acc: 0.9012 -- iter: 1600/1980
[A[ATraining Step: 1477  | total loss: [1m[32m0.24192[0m[0m | time: 213.496s
[2K
| Adam | epoch: 024 | loss: 0.24192 - acc: 0.9048 -- iter: 1632/1980
[A[ATraining Step: 1478  | total loss: [1m[32m0.24322[0m[0m | time: 214.645s
[2K
| Adam | epoch: 024 | loss: 0.24322 - acc: 0.9050 -- iter: 1664/1980
[A[ATraining Step: 1479  | total loss: [1m[32m0.23937[0m[0m | time: 215.797s
[2K
| Adam | epoch: 024 | loss: 0.23937 - acc: 0.9113 -- iter: 1696/1980
[A[ATraining Step: 1480  | total loss: [1m[32m0.25228[0m[0m | time: 216.944s
[2K
| Adam | epoch: 024 | loss: 0.25228 - acc: 0.9077 -- iter: 1728/1980
[A[ATraining Step: 1481  | total loss: [1m[32m0.25353[0m[0m | time: 218.006s
[2K
| Adam | epoch: 024 | loss: 0.25353 - acc: 0.9044 -- iter: 1760/1980
[A[ATraining Step: 1482  | total loss: [1m[32m0.25928[0m[0m | time: 219.114s
[2K
| Adam | epoch: 024 | loss: 0.25928 - acc: 0.9015 -- iter: 1792/1980
[A[ATraining Step: 1483  | total loss: [1m[32m0.25642[0m[0m | time: 220.404s
[2K
| Adam | epoch: 024 | loss: 0.25642 - acc: 0.9020 -- iter: 1824/1980
[A[ATraining Step: 1484  | total loss: [1m[32m0.24101[0m[0m | time: 221.337s
[2K
| Adam | epoch: 024 | loss: 0.24101 - acc: 0.9118 -- iter: 1856/1980
[A[ATraining Step: 1485  | total loss: [1m[32m0.24788[0m[0m | time: 226.513s
[2K
| Adam | epoch: 024 | loss: 0.24788 - acc: 0.9081 -- iter: 1888/1980
[A[ATraining Step: 1486  | total loss: [1m[32m0.25549[0m[0m | time: 231.507s
[2K
| Adam | epoch: 024 | loss: 0.25549 - acc: 0.9079 -- iter: 1920/1980
[A[ATraining Step: 1487  | total loss: [1m[32m0.24949[0m[0m | time: 238.260s
[2K
| Adam | epoch: 024 | loss: 0.24949 - acc: 0.9077 -- iter: 1952/1980
[A[ATraining Step: 1488  | total loss: [1m[32m0.24884[0m[0m | time: 340.990s
[2K
| Adam | epoch: 024 | loss: 0.24884 - acc: 0.9076 | val_loss: 0.55480 - val_acc: 0.7738 -- iter: 1980/1980
--
Training Step: 1489  | total loss: [1m[32m0.25726[0m[0m | time: 1.107s
[2K
| Adam | epoch: 025 | loss: 0.25726 - acc: 0.9075 -- iter: 0032/1980
[A[ATraining Step: 1490  | total loss: [1m[32m0.25008[0m[0m | time: 2.231s
[2K
| Adam | epoch: 025 | loss: 0.25008 - acc: 0.9042 -- iter: 0064/1980
[A[ATraining Step: 1491  | total loss: [1m[32m0.25067[0m[0m | time: 3.409s
[2K
| Adam | epoch: 025 | loss: 0.25067 - acc: 0.9044 -- iter: 0096/1980
[A[ATraining Step: 1492  | total loss: [1m[32m0.24880[0m[0m | time: 4.576s
[2K
| Adam | epoch: 025 | loss: 0.24880 - acc: 0.9015 -- iter: 0128/1980
[A[ATraining Step: 1493  | total loss: [1m[32m0.23793[0m[0m | time: 5.734s
[2K
| Adam | epoch: 025 | loss: 0.23793 - acc: 0.9082 -- iter: 0160/1980
[A[ATraining Step: 1494  | total loss: [1m[32m0.24218[0m[0m | time: 6.788s
[2K
| Adam | epoch: 025 | loss: 0.24218 - acc: 0.9080 -- iter: 0192/1980
[A[ATraining Step: 1495  | total loss: [1m[32m0.22897[0m[0m | time: 7.832s
[2K
| Adam | epoch: 025 | loss: 0.22897 - acc: 0.9141 -- iter: 0224/1980
[A[ATraining Step: 1496  | total loss: [1m[32m0.23365[0m[0m | time: 9.218s
[2K
| Adam | epoch: 025 | loss: 0.23365 - acc: 0.9102 -- iter: 0256/1980
[A[ATraining Step: 1497  | total loss: [1m[32m0.23625[0m[0m | time: 10.704s
[2K
| Adam | epoch: 025 | loss: 0.23625 - acc: 0.9067 -- iter: 0288/1980
[A[ATraining Step: 1498  | total loss: [1m[32m0.24735[0m[0m | time: 20.253s
[2K
| Adam | epoch: 025 | loss: 0.24735 - acc: 0.8972 -- iter: 0320/1980
[A[ATraining Step: 1499  | total loss: [1m[32m0.23333[0m[0m | time: 23.647s
[2K
| Adam | epoch: 025 | loss: 0.23333 - acc: 0.9044 -- iter: 0352/1980
[A[ATraining Step: 1500  | total loss: [1m[32m0.22338[0m[0m | time: 28.897s
[2K
| Adam | epoch: 025 | loss: 0.22338 - acc: 0.9077 -- iter: 0384/1980
[A[ATraining Step: 1501  | total loss: [1m[32m0.21919[0m[0m | time: 39.204s
[2K
| Adam | epoch: 025 | loss: 0.21919 - acc: 0.9107 -- iter: 0416/1980
[A[ATraining Step: 1502  | total loss: [1m[32m0.21788[0m[0m | time: 45.756s
[2K
| Adam | epoch: 025 | loss: 0.21788 - acc: 0.9134 -- iter: 0448/1980
[A[ATraining Step: 1503  | total loss: [1m[32m0.21725[0m[0m | time: 52.753s
[2K
| Adam | epoch: 025 | loss: 0.21725 - acc: 0.9095 -- iter: 0480/1980
[A[ATraining Step: 1504  | total loss: [1m[32m0.21412[0m[0m | time: 64.344s
[2K
| Adam | epoch: 025 | loss: 0.21412 - acc: 0.9092 -- iter: 0512/1980
[A[ATraining Step: 1505  | total loss: [1m[32m0.20749[0m[0m | time: 69.185s
[2K
| Adam | epoch: 025 | loss: 0.20749 - acc: 0.9089 -- iter: 0544/1980
[A[ATraining Step: 1506  | total loss: [1m[32m0.22252[0m[0m | time: 75.805s
[2K
| Adam | epoch: 025 | loss: 0.22252 - acc: 0.9055 -- iter: 0576/1980
[A[ATraining Step: 1507  | total loss: [1m[32m0.21491[0m[0m | time: 80.126s
[2K
| Adam | epoch: 025 | loss: 0.21491 - acc: 0.9087 -- iter: 0608/1980
[A[ATraining Step: 1508  | total loss: [1m[32m0.21143[0m[0m | time: 81.222s
[2K
| Adam | epoch: 025 | loss: 0.21143 - acc: 0.9147 -- iter: 0640/1980
[A[ATraining Step: 1509  | total loss: [1m[32m0.22004[0m[0m | time: 82.402s
[2K
| Adam | epoch: 025 | loss: 0.22004 - acc: 0.9170 -- iter: 0672/1980
[A[ATraining Step: 1510  | total loss: [1m[32m0.21502[0m[0m | time: 83.450s
[2K
| Adam | epoch: 025 | loss: 0.21502 - acc: 0.9190 -- iter: 0704/1980
[A[ATraining Step: 1511  | total loss: [1m[32m0.22473[0m[0m | time: 84.447s
[2K
| Adam | epoch: 025 | loss: 0.22473 - acc: 0.9084 -- iter: 0736/1980
[A[ATraining Step: 1512  | total loss: [1m[32m0.22646[0m[0m | time: 85.468s
[2K
| Adam | epoch: 025 | loss: 0.22646 - acc: 0.9140 -- iter: 0768/1980
[A[ATraining Step: 1513  | total loss: [1m[32m0.22537[0m[0m | time: 86.700s
[2K
| Adam | epoch: 025 | loss: 0.22537 - acc: 0.9154 -- iter: 0800/1980
[A[ATraining Step: 1514  | total loss: [1m[32m0.22116[0m[0m | time: 87.908s
[2K
| Adam | epoch: 025 | loss: 0.22116 - acc: 0.9176 -- iter: 0832/1980
[A[ATraining Step: 1515  | total loss: [1m[32m0.21175[0m[0m | time: 89.024s
[2K
| Adam | epoch: 025 | loss: 0.21175 - acc: 0.9228 -- iter: 0864/1980
[A[ATraining Step: 1516  | total loss: [1m[32m0.20559[0m[0m | time: 90.363s
[2K
| Adam | epoch: 025 | loss: 0.20559 - acc: 0.9274 -- iter: 0896/1980
[A[ATraining Step: 1517  | total loss: [1m[32m0.20274[0m[0m | time: 91.710s
[2K
| Adam | epoch: 025 | loss: 0.20274 - acc: 0.9252 -- iter: 0928/1980
[A[ATraining Step: 1518  | total loss: [1m[32m0.19524[0m[0m | time: 92.773s
[2K
| Adam | epoch: 025 | loss: 0.19524 - acc: 0.9327 -- iter: 0960/1980
[A[ATraining Step: 1519  | total loss: [1m[32m0.19812[0m[0m | time: 93.816s
[2K
| Adam | epoch: 025 | loss: 0.19812 - acc: 0.9332 -- iter: 0992/1980
[A[ATraining Step: 1520  | total loss: [1m[32m0.20481[0m[0m | time: 94.977s
[2K
| Adam | epoch: 025 | loss: 0.20481 - acc: 0.9305 -- iter: 1024/1980
[A[ATraining Step: 1521  | total loss: [1m[32m0.20511[0m[0m | time: 96.130s
[2K
| Adam | epoch: 025 | loss: 0.20511 - acc: 0.9312 -- iter: 1056/1980
[A[ATraining Step: 1522  | total loss: [1m[32m0.20117[0m[0m | time: 97.230s
[2K
| Adam | epoch: 025 | loss: 0.20117 - acc: 0.9350 -- iter: 1088/1980
[A[ATraining Step: 1523  | total loss: [1m[32m0.19822[0m[0m | time: 98.355s
[2K
| Adam | epoch: 025 | loss: 0.19822 - acc: 0.9321 -- iter: 1120/1980
[A[ATraining Step: 1524  | total loss: [1m[32m0.19137[0m[0m | time: 99.453s
[2K
| Adam | epoch: 025 | loss: 0.19137 - acc: 0.9358 -- iter: 1152/1980
[A[ATraining Step: 1525  | total loss: [1m[32m0.19651[0m[0m | time: 100.598s
[2K
| Adam | epoch: 025 | loss: 0.19651 - acc: 0.9297 -- iter: 1184/1980
[A[ATraining Step: 1526  | total loss: [1m[32m0.19428[0m[0m | time: 101.690s
[2K
| Adam | epoch: 025 | loss: 0.19428 - acc: 0.9305 -- iter: 1216/1980
[A[ATraining Step: 1527  | total loss: [1m[32m0.18956[0m[0m | time: 102.743s
[2K
| Adam | epoch: 025 | loss: 0.18956 - acc: 0.9312 -- iter: 1248/1980
[A[ATraining Step: 1528  | total loss: [1m[32m0.20004[0m[0m | time: 103.998s
[2K
| Adam | epoch: 025 | loss: 0.20004 - acc: 0.9224 -- iter: 1280/1980
[A[ATraining Step: 1529  | total loss: [1m[32m0.19489[0m[0m | time: 105.240s
[2K
| Adam | epoch: 025 | loss: 0.19489 - acc: 0.9239 -- iter: 1312/1980
[A[ATraining Step: 1530  | total loss: [1m[32m0.19836[0m[0m | time: 116.678s
[2K
| Adam | epoch: 025 | loss: 0.19836 - acc: 0.9222 -- iter: 1344/1980
[A[ATraining Step: 1531  | total loss: [1m[32m0.20005[0m[0m | time: 124.030s
[2K
| Adam | epoch: 025 | loss: 0.20005 - acc: 0.9174 -- iter: 1376/1980
[A[ATraining Step: 1532  | total loss: [1m[32m0.19635[0m[0m | time: 130.291s
[2K
| Adam | epoch: 025 | loss: 0.19635 - acc: 0.9195 -- iter: 1408/1980
[A[ATraining Step: 1533  | total loss: [1m[32m0.20522[0m[0m | time: 135.084s
[2K
| Adam | epoch: 025 | loss: 0.20522 - acc: 0.9150 -- iter: 1440/1980
[A[ATraining Step: 1534  | total loss: [1m[32m0.20733[0m[0m | time: 140.735s
[2K
| Adam | epoch: 025 | loss: 0.20733 - acc: 0.9173 -- iter: 1472/1980
[A[ATraining Step: 1535  | total loss: [1m[32m0.21085[0m[0m | time: 149.615s
[2K
| Adam | epoch: 025 | loss: 0.21085 - acc: 0.9130 -- iter: 1504/1980
[A[ATraining Step: 1536  | total loss: [1m[32m0.20286[0m[0m | time: 150.731s
[2K
| Adam | epoch: 025 | loss: 0.20286 - acc: 0.9155 -- iter: 1536/1980
[A[ATraining Step: 1537  | total loss: [1m[32m0.20317[0m[0m | time: 151.882s
[2K
| Adam | epoch: 025 | loss: 0.20317 - acc: 0.9177 -- iter: 1568/1980
[A[ATraining Step: 1538  | total loss: [1m[32m0.21107[0m[0m | time: 153.078s
[2K
| Adam | epoch: 025 | loss: 0.21107 - acc: 0.9103 -- iter: 1600/1980
[A[ATraining Step: 1539  | total loss: [1m[32m0.20091[0m[0m | time: 154.165s
[2K
| Adam | epoch: 025 | loss: 0.20091 - acc: 0.9193 -- iter: 1632/1980
[A[ATraining Step: 1540  | total loss: [1m[32m0.20246[0m[0m | time: 155.376s
[2K
| Adam | epoch: 025 | loss: 0.20246 - acc: 0.9180 -- iter: 1664/1980
[A[ATraining Step: 1541  | total loss: [1m[32m0.19821[0m[0m | time: 156.529s
[2K
| Adam | epoch: 025 | loss: 0.19821 - acc: 0.9137 -- iter: 1696/1980
[A[ATraining Step: 1542  | total loss: [1m[32m0.19337[0m[0m | time: 157.673s
[2K
| Adam | epoch: 025 | loss: 0.19337 - acc: 0.9160 -- iter: 1728/1980
[A[ATraining Step: 1543  | total loss: [1m[32m0.18374[0m[0m | time: 158.822s
[2K
| Adam | epoch: 025 | loss: 0.18374 - acc: 0.9213 -- iter: 1760/1980
[A[ATraining Step: 1544  | total loss: [1m[32m0.18436[0m[0m | time: 160.255s
[2K
| Adam | epoch: 025 | loss: 0.18436 - acc: 0.9198 -- iter: 1792/1980
[A[ATraining Step: 1545  | total loss: [1m[32m0.17562[0m[0m | time: 161.630s
[2K
| Adam | epoch: 025 | loss: 0.17562 - acc: 0.9278 -- iter: 1824/1980
[A[ATraining Step: 1546  | total loss: [1m[32m0.17220[0m[0m | time: 166.843s
[2K
| Adam | epoch: 025 | loss: 0.17220 - acc: 0.9288 -- iter: 1856/1980
[A[ATraining Step: 1547  | total loss: [1m[32m0.18644[0m[0m | time: 174.532s
[2K
| Adam | epoch: 025 | loss: 0.18644 - acc: 0.9203 -- iter: 1888/1980
[A[ATraining Step: 1548  | total loss: [1m[32m0.18622[0m[0m | time: 178.057s
[2K
| Adam | epoch: 025 | loss: 0.18622 - acc: 0.9189 -- iter: 1920/1980
[A[ATraining Step: 1549  | total loss: [1m[32m0.20402[0m[0m | time: 184.091s
[2K
| Adam | epoch: 025 | loss: 0.20402 - acc: 0.9145 -- iter: 1952/1980
[A[ATraining Step: 1550  | total loss: [1m[32m0.24493[0m[0m | time: 190.066s
[2K
| Adam | epoch: 025 | loss: 0.24493 - acc: 0.9012 | val_loss: 0.61374 - val_acc: 0.7738 -- iter: 1980/1980
--
Training Step: 1551  | total loss: [1m[32m0.23832[0m[0m | time: 1.190s
[2K
| Adam | epoch: 026 | loss: 0.23832 - acc: 0.8986 -- iter: 0032/1980
[A[ATraining Step: 1552  | total loss: [1m[32m0.23130[0m[0m | time: 2.321s
[2K
| Adam | epoch: 026 | loss: 0.23130 - acc: 0.9025 -- iter: 0064/1980
[A[ATraining Step: 1553  | total loss: [1m[32m0.22141[0m[0m | time: 3.533s
[2K
| Adam | epoch: 026 | loss: 0.22141 - acc: 0.9060 -- iter: 0096/1980
[A[ATraining Step: 1554  | total loss: [1m[32m0.22646[0m[0m | time: 4.679s
[2K
| Adam | epoch: 026 | loss: 0.22646 - acc: 0.9060 -- iter: 0128/1980
[A[ATraining Step: 1555  | total loss: [1m[32m0.22920[0m[0m | time: 5.992s
[2K
| Adam | epoch: 026 | loss: 0.22920 - acc: 0.9060 -- iter: 0160/1980
[A[ATraining Step: 1556  | total loss: [1m[32m0.22581[0m[0m | time: 7.276s
[2K
| Adam | epoch: 026 | loss: 0.22581 - acc: 0.9060 -- iter: 0192/1980
[A[ATraining Step: 1557  | total loss: [1m[32m0.22547[0m[0m | time: 8.291s
[2K
| Adam | epoch: 026 | loss: 0.22547 - acc: 0.9092 -- iter: 0224/1980
[A[ATraining Step: 1558  | total loss: [1m[32m0.21091[0m[0m | time: 9.304s
[2K
| Adam | epoch: 026 | loss: 0.21091 - acc: 0.9183 -- iter: 0256/1980
[A[ATraining Step: 1559  | total loss: [1m[32m0.20777[0m[0m | time: 10.460s
[2K
| Adam | epoch: 026 | loss: 0.20777 - acc: 0.9171 -- iter: 0288/1980
[A[ATraining Step: 1560  | total loss: [1m[32m0.19395[0m[0m | time: 11.584s
[2K
| Adam | epoch: 026 | loss: 0.19395 - acc: 0.9254 -- iter: 0320/1980
[A[ATraining Step: 1561  | total loss: [1m[32m0.18381[0m[0m | time: 12.666s
[2K
| Adam | epoch: 026 | loss: 0.18381 - acc: 0.9328 -- iter: 0352/1980
[A[ATraining Step: 1562  | total loss: [1m[32m0.18364[0m[0m | time: 13.796s
[2K
| Adam | epoch: 026 | loss: 0.18364 - acc: 0.9333 -- iter: 0384/1980
[A[ATraining Step: 1563  | total loss: [1m[32m0.18333[0m[0m | time: 14.929s
[2K
| Adam | epoch: 026 | loss: 0.18333 - acc: 0.9337 -- iter: 0416/1980
[A[ATraining Step: 1564  | total loss: [1m[32m0.18954[0m[0m | time: 16.064s
[2K
| Adam | epoch: 026 | loss: 0.18954 - acc: 0.9372 -- iter: 0448/1980
[A[ATraining Step: 1565  | total loss: [1m[32m0.18790[0m[0m | time: 17.129s
[2K
| Adam | epoch: 026 | loss: 0.18790 - acc: 0.9404 -- iter: 0480/1980
[A[ATraining Step: 1566  | total loss: [1m[32m0.19252[0m[0m | time: 18.379s
[2K
| Adam | epoch: 026 | loss: 0.19252 - acc: 0.9338 -- iter: 0512/1980
[A[ATraining Step: 1567  | total loss: [1m[32m0.18496[0m[0m | time: 19.690s
[2K
| Adam | epoch: 026 | loss: 0.18496 - acc: 0.9373 -- iter: 0544/1980
[A[ATraining Step: 1568  | total loss: [1m[32m0.18920[0m[0m | time: 20.695s
[2K
| Adam | epoch: 026 | loss: 0.18920 - acc: 0.9373 -- iter: 0576/1980
[A[ATraining Step: 1569  | total loss: [1m[32m0.18300[0m[0m | time: 21.633s
[2K
| Adam | epoch: 026 | loss: 0.18300 - acc: 0.9405 -- iter: 0608/1980
[A[ATraining Step: 1570  | total loss: [1m[32m0.17056[0m[0m | time: 22.764s
[2K
| Adam | epoch: 026 | loss: 0.17056 - acc: 0.9433 -- iter: 0640/1980
[A[ATraining Step: 1571  | total loss: [1m[32m0.18421[0m[0m | time: 23.896s
[2K
| Adam | epoch: 026 | loss: 0.18421 - acc: 0.9334 -- iter: 0672/1980
[A[ATraining Step: 1572  | total loss: [1m[32m0.18328[0m[0m | time: 25.071s
[2K
| Adam | epoch: 026 | loss: 0.18328 - acc: 0.9306 -- iter: 0704/1980
[A[ATraining Step: 1573  | total loss: [1m[32m0.17735[0m[0m | time: 26.127s
[2K
| Adam | epoch: 026 | loss: 0.17735 - acc: 0.9345 -- iter: 0736/1980
[A[ATraining Step: 1574  | total loss: [1m[32m0.17215[0m[0m | time: 27.121s
[2K
| Adam | epoch: 026 | loss: 0.17215 - acc: 0.9410 -- iter: 0768/1980
[A[ATraining Step: 1575  | total loss: [1m[32m0.18551[0m[0m | time: 28.153s
[2K
| Adam | epoch: 026 | loss: 0.18551 - acc: 0.9326 -- iter: 0800/1980
[A[ATraining Step: 1576  | total loss: [1m[32m0.19328[0m[0m | time: 29.400s
[2K
| Adam | epoch: 026 | loss: 0.19328 - acc: 0.9251 -- iter: 0832/1980
[A[ATraining Step: 1577  | total loss: [1m[32m0.19234[0m[0m | time: 30.487s
[2K
| Adam | epoch: 026 | loss: 0.19234 - acc: 0.9263 -- iter: 0864/1980
[A[ATraining Step: 1578  | total loss: [1m[32m0.18666[0m[0m | time: 31.829s
[2K
| Adam | epoch: 026 | loss: 0.18666 - acc: 0.9274 -- iter: 0896/1980
[A[ATraining Step: 1579  | total loss: [1m[32m0.18682[0m[0m | time: 33.156s
[2K
| Adam | epoch: 026 | loss: 0.18682 - acc: 0.9253 -- iter: 0928/1980
[A[ATraining Step: 1580  | total loss: [1m[32m0.18528[0m[0m | time: 34.075s
[2K
| Adam | epoch: 026 | loss: 0.18528 - acc: 0.9234 -- iter: 0960/1980
[A[ATraining Step: 1581  | total loss: [1m[32m0.19259[0m[0m | time: 35.160s
[2K
| Adam | epoch: 026 | loss: 0.19259 - acc: 0.9154 -- iter: 0992/1980
[A[ATraining Step: 1582  | total loss: [1m[32m0.20408[0m[0m | time: 36.334s
[2K
| Adam | epoch: 026 | loss: 0.20408 - acc: 0.9051 -- iter: 1024/1980
[A[ATraining Step: 1583  | total loss: [1m[32m0.20206[0m[0m | time: 37.417s
[2K
| Adam | epoch: 026 | loss: 0.20206 - acc: 0.9053 -- iter: 1056/1980
[A[ATraining Step: 1584  | total loss: [1m[32m0.18733[0m[0m | time: 38.501s
[2K
| Adam | epoch: 026 | loss: 0.18733 - acc: 0.9147 -- iter: 1088/1980
[A[ATraining Step: 1585  | total loss: [1m[32m0.19278[0m[0m | time: 39.532s
[2K
| Adam | epoch: 026 | loss: 0.19278 - acc: 0.9108 -- iter: 1120/1980
[A[ATraining Step: 1586  | total loss: [1m[32m0.19418[0m[0m | time: 40.838s
[2K
| Adam | epoch: 026 | loss: 0.19418 - acc: 0.9072 -- iter: 1152/1980
[A[ATraining Step: 1587  | total loss: [1m[32m0.18787[0m[0m | time: 42.214s
[2K
| Adam | epoch: 026 | loss: 0.18787 - acc: 0.9165 -- iter: 1184/1980
[A[ATraining Step: 1588  | total loss: [1m[32m0.19499[0m[0m | time: 43.557s
[2K
| Adam | epoch: 026 | loss: 0.19499 - acc: 0.9154 -- iter: 1216/1980
[A[ATraining Step: 1589  | total loss: [1m[32m0.19687[0m[0m | time: 44.922s
[2K
| Adam | epoch: 026 | loss: 0.19687 - acc: 0.9145 -- iter: 1248/1980
[A[ATraining Step: 1590  | total loss: [1m[32m0.19217[0m[0m | time: 46.280s
[2K
| Adam | epoch: 026 | loss: 0.19217 - acc: 0.9168 -- iter: 1280/1980
[A[ATraining Step: 1591  | total loss: [1m[32m0.21427[0m[0m | time: 47.702s
[2K
| Adam | epoch: 026 | loss: 0.21427 - acc: 0.9095 -- iter: 1312/1980
[A[ATraining Step: 1592  | total loss: [1m[32m0.20838[0m[0m | time: 48.632s
[2K
| Adam | epoch: 026 | loss: 0.20838 - acc: 0.9123 -- iter: 1344/1980
[A[ATraining Step: 1593  | total loss: [1m[32m0.19754[0m[0m | time: 49.736s
[2K
| Adam | epoch: 026 | loss: 0.19754 - acc: 0.9211 -- iter: 1376/1980
[A[ATraining Step: 1594  | total loss: [1m[32m0.18641[0m[0m | time: 50.913s
[2K
| Adam | epoch: 026 | loss: 0.18641 - acc: 0.9290 -- iter: 1408/1980
[A[ATraining Step: 1595  | total loss: [1m[32m0.18433[0m[0m | time: 52.007s
[2K
| Adam | epoch: 026 | loss: 0.18433 - acc: 0.9330 -- iter: 1440/1980
[A[ATraining Step: 1596  | total loss: [1m[32m0.19561[0m[0m | time: 53.109s
[2K
| Adam | epoch: 026 | loss: 0.19561 - acc: 0.9240 -- iter: 1472/1980
[A[ATraining Step: 1597  | total loss: [1m[32m0.19658[0m[0m | time: 54.284s
[2K
| Adam | epoch: 026 | loss: 0.19658 - acc: 0.9160 -- iter: 1504/1980
[A[ATraining Step: 1598  | total loss: [1m[32m0.20498[0m[0m | time: 55.498s
[2K
| Adam | epoch: 026 | loss: 0.20498 - acc: 0.9150 -- iter: 1536/1980
[A[ATraining Step: 1599  | total loss: [1m[32m0.19403[0m[0m | time: 56.609s
[2K
| Adam | epoch: 026 | loss: 0.19403 - acc: 0.9204 -- iter: 1568/1980
[A[ATraining Step: 1600  | total loss: [1m[32m0.18283[0m[0m | time: 61.781s
[2K
| Adam | epoch: 026 | loss: 0.18283 - acc: 0.9252 | val_loss: 0.73076 - val_acc: 0.7577 -- iter: 1600/1980
--
Training Step: 1601  | total loss: [1m[32m0.20392[0m[0m | time: 62.803s
[2K
| Adam | epoch: 026 | loss: 0.20392 - acc: 0.9202 -- iter: 1632/1980
[A[ATraining Step: 1602  | total loss: [1m[32m0.20047[0m[0m | time: 63.906s
[2K
| Adam | epoch: 026 | loss: 0.20047 - acc: 0.9219 -- iter: 1664/1980
[A[ATraining Step: 1603  | total loss: [1m[32m0.22523[0m[0m | time: 64.948s
[2K
| Adam | epoch: 026 | loss: 0.22523 - acc: 0.9079 -- iter: 1696/1980
[A[ATraining Step: 1604  | total loss: [1m[32m0.24402[0m[0m | time: 66.045s
[2K
| Adam | epoch: 026 | loss: 0.24402 - acc: 0.9015 -- iter: 1728/1980
[A[ATraining Step: 1605  | total loss: [1m[32m0.27046[0m[0m | time: 67.211s
[2K
| Adam | epoch: 026 | loss: 0.27046 - acc: 0.8894 -- iter: 1760/1980
[A[ATraining Step: 1606  | total loss: [1m[32m0.28155[0m[0m | time: 68.341s
[2K
| Adam | epoch: 026 | loss: 0.28155 - acc: 0.8880 -- iter: 1792/1980
[A[ATraining Step: 1607  | total loss: [1m[32m0.26873[0m[0m | time: 69.453s
[2K
| Adam | epoch: 026 | loss: 0.26873 - acc: 0.8929 -- iter: 1824/1980
[A[ATraining Step: 1608  | total loss: [1m[32m0.25396[0m[0m | time: 70.557s
[2K
| Adam | epoch: 026 | loss: 0.25396 - acc: 0.8974 -- iter: 1856/1980
[A[ATraining Step: 1609  | total loss: [1m[32m0.26583[0m[0m | time: 71.756s
[2K
| Adam | epoch: 026 | loss: 0.26583 - acc: 0.8889 -- iter: 1888/1980
[A[ATraining Step: 1610  | total loss: [1m[32m0.26651[0m[0m | time: 72.994s
[2K
| Adam | epoch: 026 | loss: 0.26651 - acc: 0.8844 -- iter: 1920/1980
[A[ATraining Step: 1611  | total loss: [1m[32m0.24881[0m[0m | time: 74.105s
[2K
| Adam | epoch: 026 | loss: 0.24881 - acc: 0.8960 -- iter: 1952/1980
[A[ATraining Step: 1612  | total loss: [1m[32m0.24289[0m[0m | time: 79.172s
[2K
| Adam | epoch: 026 | loss: 0.24289 - acc: 0.9001 | val_loss: 0.63601 - val_acc: 0.7835 -- iter: 1980/1980
--
Training Step: 1613  | total loss: [1m[32m0.23478[0m[0m | time: 1.140s
[2K
| Adam | epoch: 027 | loss: 0.23478 - acc: 0.9070 -- iter: 0032/1980
[A[ATraining Step: 1614  | total loss: [1m[32m0.23039[0m[0m | time: 2.263s
[2K
| Adam | epoch: 027 | loss: 0.23039 - acc: 0.9132 -- iter: 0064/1980
[A[ATraining Step: 1615  | total loss: [1m[32m0.22690[0m[0m | time: 3.456s
[2K
| Adam | epoch: 027 | loss: 0.22690 - acc: 0.9093 -- iter: 0096/1980
[A[ATraining Step: 1616  | total loss: [1m[32m0.23653[0m[0m | time: 4.465s
[2K
| Adam | epoch: 027 | loss: 0.23653 - acc: 0.9090 -- iter: 0128/1980
[A[ATraining Step: 1617  | total loss: [1m[32m0.23624[0m[0m | time: 5.775s
[2K
| Adam | epoch: 027 | loss: 0.23624 - acc: 0.9119 -- iter: 0160/1980
[A[ATraining Step: 1618  | total loss: [1m[32m0.22023[0m[0m | time: 7.027s
[2K
| Adam | epoch: 027 | loss: 0.22023 - acc: 0.9207 -- iter: 0192/1980
[A[ATraining Step: 1619  | total loss: [1m[32m0.20926[0m[0m | time: 8.008s
[2K
| Adam | epoch: 027 | loss: 0.20926 - acc: 0.9224 -- iter: 0224/1980
[A[ATraining Step: 1620  | total loss: [1m[32m0.20192[0m[0m | time: 9.064s
[2K
| Adam | epoch: 027 | loss: 0.20192 - acc: 0.9301 -- iter: 0256/1980
[A[ATraining Step: 1621  | total loss: [1m[32m0.21397[0m[0m | time: 10.300s
[2K
| Adam | epoch: 027 | loss: 0.21397 - acc: 0.9309 -- iter: 0288/1980
[A[ATraining Step: 1622  | total loss: [1m[32m0.19842[0m[0m | time: 11.547s
[2K
| Adam | epoch: 027 | loss: 0.19842 - acc: 0.9378 -- iter: 0320/1980
[A[ATraining Step: 1623  | total loss: [1m[32m0.19112[0m[0m | time: 12.660s
[2K
| Adam | epoch: 027 | loss: 0.19112 - acc: 0.9409 -- iter: 0352/1980
[A[ATraining Step: 1624  | total loss: [1m[32m0.17948[0m[0m | time: 13.845s
[2K
| Adam | epoch: 027 | loss: 0.17948 - acc: 0.9437 -- iter: 0384/1980
[A[ATraining Step: 1625  | total loss: [1m[32m0.18523[0m[0m | time: 15.043s
[2K
| Adam | epoch: 027 | loss: 0.18523 - acc: 0.9399 -- iter: 0416/1980
[A[ATraining Step: 1626  | total loss: [1m[32m0.17733[0m[0m | time: 16.131s
[2K
| Adam | epoch: 027 | loss: 0.17733 - acc: 0.9397 -- iter: 0448/1980
[A[ATraining Step: 1627  | total loss: [1m[32m0.17356[0m[0m | time: 17.215s
[2K
| Adam | epoch: 027 | loss: 0.17356 - acc: 0.9426 -- iter: 0480/1980
[A[ATraining Step: 1628  | total loss: [1m[32m0.17689[0m[0m | time: 18.423s
[2K
| Adam | epoch: 027 | loss: 0.17689 - acc: 0.9390 -- iter: 0512/1980
[A[ATraining Step: 1629  | total loss: [1m[32m0.17765[0m[0m | time: 19.634s
[2K
| Adam | epoch: 027 | loss: 0.17765 - acc: 0.9419 -- iter: 0544/1980
[A[ATraining Step: 1630  | total loss: [1m[32m0.17762[0m[0m | time: 20.827s
[2K
| Adam | epoch: 027 | loss: 0.17762 - acc: 0.9384 -- iter: 0576/1980
[A[ATraining Step: 1631  | total loss: [1m[32m0.16786[0m[0m | time: 21.814s
[2K
| Adam | epoch: 027 | loss: 0.16786 - acc: 0.9445 -- iter: 0608/1980
[A[ATraining Step: 1632  | total loss: [1m[32m0.16858[0m[0m | time: 22.948s
[2K
| Adam | epoch: 027 | loss: 0.16858 - acc: 0.9438 -- iter: 0640/1980
[A[ATraining Step: 1633  | total loss: [1m[32m0.18158[0m[0m | time: 24.162s
[2K
| Adam | epoch: 027 | loss: 0.18158 - acc: 0.9338 -- iter: 0672/1980
[A[ATraining Step: 1634  | total loss: [1m[32m0.19193[0m[0m | time: 25.409s
[2K
| Adam | epoch: 027 | loss: 0.19193 - acc: 0.9279 -- iter: 0704/1980
[A[ATraining Step: 1635  | total loss: [1m[32m0.18925[0m[0m | time: 26.583s
[2K
| Adam | epoch: 027 | loss: 0.18925 - acc: 0.9258 -- iter: 0736/1980
[A[ATraining Step: 1636  | total loss: [1m[32m0.18273[0m[0m | time: 27.726s
[2K
| Adam | epoch: 027 | loss: 0.18273 - acc: 0.9301 -- iter: 0768/1980
[A[ATraining Step: 1637  | total loss: [1m[32m0.17717[0m[0m | time: 28.728s
[2K
| Adam | epoch: 027 | loss: 0.17717 - acc: 0.9339 -- iter: 0800/1980
[A[ATraining Step: 1638  | total loss: [1m[32m0.18580[0m[0m | time: 29.742s
[2K
| Adam | epoch: 027 | loss: 0.18580 - acc: 0.9298 -- iter: 0832/1980
[A[ATraining Step: 1639  | total loss: [1m[32m0.19116[0m[0m | time: 30.967s
[2K
| Adam | epoch: 027 | loss: 0.19116 - acc: 0.9261 -- iter: 0864/1980
[A[ATraining Step: 1640  | total loss: [1m[32m0.18833[0m[0m | time: 32.281s
[2K
| Adam | epoch: 027 | loss: 0.18833 - acc: 0.9304 -- iter: 0896/1980
[A[ATraining Step: 1641  | total loss: [1m[32m0.19363[0m[0m | time: 33.501s
[2K
| Adam | epoch: 027 | loss: 0.19363 - acc: 0.9249 -- iter: 0928/1980
[A[ATraining Step: 1642  | total loss: [1m[32m0.19022[0m[0m | time: 34.432s
[2K
| Adam | epoch: 027 | loss: 0.19022 - acc: 0.9230 -- iter: 0960/1980
[A[ATraining Step: 1643  | total loss: [1m[32m0.17712[0m[0m | time: 35.460s
[2K
| Adam | epoch: 027 | loss: 0.17712 - acc: 0.9307 -- iter: 0992/1980
[A[ATraining Step: 1644  | total loss: [1m[32m0.17953[0m[0m | time: 36.541s
[2K
| Adam | epoch: 027 | loss: 0.17953 - acc: 0.9282 -- iter: 1024/1980
[A[ATraining Step: 1645  | total loss: [1m[32m0.18129[0m[0m | time: 37.642s
[2K
| Adam | epoch: 027 | loss: 0.18129 - acc: 0.9260 -- iter: 1056/1980
[A[ATraining Step: 1646  | total loss: [1m[32m0.17937[0m[0m | time: 38.714s
[2K
| Adam | epoch: 027 | loss: 0.17937 - acc: 0.9241 -- iter: 1088/1980
[A[ATraining Step: 1647  | total loss: [1m[32m0.17860[0m[0m | time: 39.814s
[2K
| Adam | epoch: 027 | loss: 0.17860 - acc: 0.9254 -- iter: 1120/1980
[A[ATraining Step: 1648  | total loss: [1m[32m0.17499[0m[0m | time: 40.977s
[2K
| Adam | epoch: 027 | loss: 0.17499 - acc: 0.9266 -- iter: 1152/1980
[A[ATraining Step: 1649  | total loss: [1m[32m0.17718[0m[0m | time: 42.157s
[2K
| Adam | epoch: 027 | loss: 0.17718 - acc: 0.9277 -- iter: 1184/1980
[A[ATraining Step: 1650  | total loss: [1m[32m0.18052[0m[0m | time: 43.259s
[2K
| Adam | epoch: 027 | loss: 0.18052 - acc: 0.9224 -- iter: 1216/1980
[A[ATraining Step: 1651  | total loss: [1m[32m0.16959[0m[0m | time: 44.488s
[2K
| Adam | epoch: 027 | loss: 0.16959 - acc: 0.9302 -- iter: 1248/1980
[A[ATraining Step: 1652  | total loss: [1m[32m0.16746[0m[0m | time: 45.761s
[2K
| Adam | epoch: 027 | loss: 0.16746 - acc: 0.9309 -- iter: 1280/1980
[A[ATraining Step: 1653  | total loss: [1m[32m0.16432[0m[0m | time: 46.891s
[2K
| Adam | epoch: 027 | loss: 0.16432 - acc: 0.9347 -- iter: 1312/1980
[A[ATraining Step: 1654  | total loss: [1m[32m0.16570[0m[0m | time: 47.849s
[2K
| Adam | epoch: 027 | loss: 0.16570 - acc: 0.9319 -- iter: 1344/1980
[A[ATraining Step: 1655  | total loss: [1m[32m0.17384[0m[0m | time: 48.966s
[2K
| Adam | epoch: 027 | loss: 0.17384 - acc: 0.9293 -- iter: 1376/1980
[A[ATraining Step: 1656  | total loss: [1m[32m0.19116[0m[0m | time: 50.070s
[2K
| Adam | epoch: 027 | loss: 0.19116 - acc: 0.9145 -- iter: 1408/1980
[A[ATraining Step: 1657  | total loss: [1m[32m0.19653[0m[0m | time: 51.123s
[2K
| Adam | epoch: 027 | loss: 0.19653 - acc: 0.9074 -- iter: 1440/1980
[A[ATraining Step: 1658  | total loss: [1m[32m0.22069[0m[0m | time: 52.261s
[2K
| Adam | epoch: 027 | loss: 0.22069 - acc: 0.8979 -- iter: 1472/1980
[A[ATraining Step: 1659  | total loss: [1m[32m0.23038[0m[0m | time: 53.386s
[2K
| Adam | epoch: 027 | loss: 0.23038 - acc: 0.8925 -- iter: 1504/1980
[A[ATraining Step: 1660  | total loss: [1m[32m0.23408[0m[0m | time: 54.481s
[2K
| Adam | epoch: 027 | loss: 0.23408 - acc: 0.8939 -- iter: 1536/1980
[A[ATraining Step: 1661  | total loss: [1m[32m0.22297[0m[0m | time: 55.617s
[2K
| Adam | epoch: 027 | loss: 0.22297 - acc: 0.9014 -- iter: 1568/1980
[A[ATraining Step: 1662  | total loss: [1m[32m0.21470[0m[0m | time: 56.700s
[2K
| Adam | epoch: 027 | loss: 0.21470 - acc: 0.9050 -- iter: 1600/1980
[A[ATraining Step: 1663  | total loss: [1m[32m0.21876[0m[0m | time: 57.960s
[2K
| Adam | epoch: 027 | loss: 0.21876 - acc: 0.9051 -- iter: 1632/1980
[A[ATraining Step: 1664  | total loss: [1m[32m0.23788[0m[0m | time: 59.123s
[2K
| Adam | epoch: 027 | loss: 0.23788 - acc: 0.8958 -- iter: 1664/1980
[A[ATraining Step: 1665  | total loss: [1m[32m0.24336[0m[0m | time: 60.077s
[2K
| Adam | epoch: 027 | loss: 0.24336 - acc: 0.8906 -- iter: 1696/1980
[A[ATraining Step: 1666  | total loss: [1m[32m0.23272[0m[0m | time: 61.137s
[2K
| Adam | epoch: 027 | loss: 0.23272 - acc: 0.8985 -- iter: 1728/1980
[A[ATraining Step: 1667  | total loss: [1m[32m0.22270[0m[0m | time: 62.226s
[2K
| Adam | epoch: 027 | loss: 0.22270 - acc: 0.9055 -- iter: 1760/1980
[A[ATraining Step: 1668  | total loss: [1m[32m0.21223[0m[0m | time: 63.283s
[2K
| Adam | epoch: 027 | loss: 0.21223 - acc: 0.9087 -- iter: 1792/1980
[A[ATraining Step: 1669  | total loss: [1m[32m0.23357[0m[0m | time: 64.355s
[2K
| Adam | epoch: 027 | loss: 0.23357 - acc: 0.9084 -- iter: 1824/1980
[A[ATraining Step: 1670  | total loss: [1m[32m0.21657[0m[0m | time: 65.592s
[2K
| Adam | epoch: 027 | loss: 0.21657 - acc: 0.9176 -- iter: 1856/1980
[A[ATraining Step: 1671  | total loss: [1m[32m0.20875[0m[0m | time: 66.777s
[2K
| Adam | epoch: 027 | loss: 0.20875 - acc: 0.9196 -- iter: 1888/1980
[A[ATraining Step: 1672  | total loss: [1m[32m0.20127[0m[0m | time: 68.152s
[2K
| Adam | epoch: 027 | loss: 0.20127 - acc: 0.9245 -- iter: 1920/1980
[A[ATraining Step: 1673  | total loss: [1m[32m0.20260[0m[0m | time: 69.526s
[2K
| Adam | epoch: 027 | loss: 0.20260 - acc: 0.9289 -- iter: 1952/1980
[A[ATraining Step: 1674  | total loss: [1m[32m0.19093[0m[0m | time: 75.543s
[2K
| Adam | epoch: 027 | loss: 0.19093 - acc: 0.9329 | val_loss: 0.61285 - val_acc: 0.7884 -- iter: 1980/1980
--
Training Step: 1675  | total loss: [1m[32m0.18345[0m[0m | time: 1.148s
[2K
| Adam | epoch: 028 | loss: 0.18345 - acc: 0.9334 -- iter: 0032/1980
[A[ATraining Step: 1676  | total loss: [1m[32m0.17641[0m[0m | time: 2.290s
[2K
| Adam | epoch: 028 | loss: 0.17641 - acc: 0.9400 -- iter: 0064/1980
[A[ATraining Step: 1677  | total loss: [1m[32m0.16544[0m[0m | time: 3.417s
[2K
| Adam | epoch: 028 | loss: 0.16544 - acc: 0.9460 -- iter: 0096/1980
[A[ATraining Step: 1678  | total loss: [1m[32m0.15895[0m[0m | time: 4.660s
[2K
| Adam | epoch: 028 | loss: 0.15895 - acc: 0.9483 -- iter: 0128/1980
[A[ATraining Step: 1679  | total loss: [1m[32m0.15938[0m[0m | time: 5.855s
[2K
| Adam | epoch: 028 | loss: 0.15938 - acc: 0.9472 -- iter: 0160/1980
[A[ATraining Step: 1680  | total loss: [1m[32m0.15296[0m[0m | time: 7.029s
[2K
| Adam | epoch: 028 | loss: 0.15296 - acc: 0.9494 -- iter: 0192/1980
[A[ATraining Step: 1681  | total loss: [1m[32m0.14998[0m[0m | time: 8.229s
[2K
| Adam | epoch: 028 | loss: 0.14998 - acc: 0.9513 -- iter: 0224/1980
[A[ATraining Step: 1682  | total loss: [1m[32m0.14330[0m[0m | time: 9.405s
[2K
| Adam | epoch: 028 | loss: 0.14330 - acc: 0.9562 -- iter: 0256/1980
[A[ATraining Step: 1683  | total loss: [1m[32m0.14637[0m[0m | time: 10.681s
[2K
| Adam | epoch: 028 | loss: 0.14637 - acc: 0.9512 -- iter: 0288/1980
[A[ATraining Step: 1684  | total loss: [1m[32m0.14840[0m[0m | time: 11.735s
[2K
| Adam | epoch: 028 | loss: 0.14840 - acc: 0.9467 -- iter: 0320/1980
[A[ATraining Step: 1685  | total loss: [1m[32m0.14686[0m[0m | time: 12.687s
[2K
| Adam | epoch: 028 | loss: 0.14686 - acc: 0.9489 -- iter: 0352/1980
[A[ATraining Step: 1686  | total loss: [1m[32m0.13725[0m[0m | time: 13.742s
[2K
| Adam | epoch: 028 | loss: 0.13725 - acc: 0.9540 -- iter: 0384/1980
[A[ATraining Step: 1687  | total loss: [1m[32m0.13956[0m[0m | time: 14.938s
[2K
| Adam | epoch: 028 | loss: 0.13956 - acc: 0.9524 -- iter: 0416/1980
[A[ATraining Step: 1688  | total loss: [1m[32m0.14339[0m[0m | time: 15.990s
[2K
| Adam | epoch: 028 | loss: 0.14339 - acc: 0.9540 -- iter: 0448/1980
[A[ATraining Step: 1689  | total loss: [1m[32m0.13963[0m[0m | time: 17.134s
[2K
| Adam | epoch: 028 | loss: 0.13963 - acc: 0.9555 -- iter: 0480/1980
[A[ATraining Step: 1690  | total loss: [1m[32m0.18180[0m[0m | time: 18.291s
[2K
| Adam | epoch: 028 | loss: 0.18180 - acc: 0.9443 -- iter: 0512/1980
[A[ATraining Step: 1691  | total loss: [1m[32m0.19912[0m[0m | time: 19.435s
[2K
| Adam | epoch: 028 | loss: 0.19912 - acc: 0.9342 -- iter: 0544/1980
[A[ATraining Step: 1692  | total loss: [1m[32m0.19179[0m[0m | time: 20.655s
[2K
| Adam | epoch: 028 | loss: 0.19179 - acc: 0.9377 -- iter: 0576/1980
[A[ATraining Step: 1693  | total loss: [1m[32m0.19007[0m[0m | time: 21.758s
[2K
| Adam | epoch: 028 | loss: 0.19007 - acc: 0.9408 -- iter: 0608/1980
[A[ATraining Step: 1694  | total loss: [1m[32m0.18233[0m[0m | time: 22.976s
[2K
| Adam | epoch: 028 | loss: 0.18233 - acc: 0.9436 -- iter: 0640/1980
[A[ATraining Step: 1695  | total loss: [1m[32m0.19268[0m[0m | time: 24.203s
[2K
| Adam | epoch: 028 | loss: 0.19268 - acc: 0.9336 -- iter: 0672/1980
[A[ATraining Step: 1696  | total loss: [1m[32m0.20511[0m[0m | time: 25.141s
[2K
| Adam | epoch: 028 | loss: 0.20511 - acc: 0.9246 -- iter: 0704/1980
[A[ATraining Step: 1697  | total loss: [1m[32m0.19824[0m[0m | time: 26.196s
[2K
| Adam | epoch: 028 | loss: 0.19824 - acc: 0.9259 -- iter: 0736/1980
[A[ATraining Step: 1698  | total loss: [1m[32m0.21024[0m[0m | time: 27.398s
[2K
| Adam | epoch: 028 | loss: 0.21024 - acc: 0.9208 -- iter: 0768/1980
[A[ATraining Step: 1699  | total loss: [1m[32m0.19933[0m[0m | time: 28.482s
[2K
| Adam | epoch: 028 | loss: 0.19933 - acc: 0.9256 -- iter: 0800/1980
[A[ATraining Step: 1700  | total loss: [1m[32m0.19048[0m[0m | time: 29.471s
[2K
| Adam | epoch: 028 | loss: 0.19048 - acc: 0.9268 -- iter: 0832/1980
[A[ATraining Step: 1701  | total loss: [1m[32m0.18478[0m[0m | time: 30.454s
[2K
| Adam | epoch: 028 | loss: 0.18478 - acc: 0.9306 -- iter: 0864/1980
[A[ATraining Step: 1702  | total loss: [1m[32m0.18142[0m[0m | time: 31.704s
[2K
| Adam | epoch: 028 | loss: 0.18142 - acc: 0.9304 -- iter: 0896/1980
[A[ATraining Step: 1703  | total loss: [1m[32m0.20106[0m[0m | time: 32.890s
[2K
| Adam | epoch: 028 | loss: 0.20106 - acc: 0.9248 -- iter: 0928/1980
[A[ATraining Step: 1704  | total loss: [1m[32m0.19419[0m[0m | time: 33.984s
[2K
| Adam | epoch: 028 | loss: 0.19419 - acc: 0.9261 -- iter: 0960/1980
[A[ATraining Step: 1705  | total loss: [1m[32m0.18809[0m[0m | time: 35.287s
[2K
| Adam | epoch: 028 | loss: 0.18809 - acc: 0.9304 -- iter: 0992/1980
[A[ATraining Step: 1706  | total loss: [1m[32m0.17963[0m[0m | time: 36.535s
[2K
| Adam | epoch: 028 | loss: 0.17963 - acc: 0.9342 -- iter: 1024/1980
[A[ATraining Step: 1707  | total loss: [1m[32m0.18737[0m[0m | time: 37.579s
[2K
| Adam | epoch: 028 | loss: 0.18737 - acc: 0.9283 -- iter: 1056/1980
[A[ATraining Step: 1708  | total loss: [1m[32m0.18013[0m[0m | time: 38.598s
[2K
| Adam | epoch: 028 | loss: 0.18013 - acc: 0.9292 -- iter: 1088/1980
[A[ATraining Step: 1709  | total loss: [1m[32m0.17997[0m[0m | time: 39.654s
[2K
| Adam | epoch: 028 | loss: 0.17997 - acc: 0.9269 -- iter: 1120/1980
[A[ATraining Step: 1710  | total loss: [1m[32m0.16874[0m[0m | time: 40.740s
[2K
| Adam | epoch: 028 | loss: 0.16874 - acc: 0.9342 -- iter: 1152/1980
[A[ATraining Step: 1711  | total loss: [1m[32m0.17627[0m[0m | time: 41.836s
[2K
| Adam | epoch: 028 | loss: 0.17627 - acc: 0.9314 -- iter: 1184/1980
[A[ATraining Step: 1712  | total loss: [1m[32m0.16905[0m[0m | time: 42.943s
[2K
| Adam | epoch: 028 | loss: 0.16905 - acc: 0.9351 -- iter: 1216/1980
[A[ATraining Step: 1713  | total loss: [1m[32m0.17601[0m[0m | time: 44.103s
[2K
| Adam | epoch: 028 | loss: 0.17601 - acc: 0.9291 -- iter: 1248/1980
[A[ATraining Step: 1714  | total loss: [1m[32m0.18573[0m[0m | time: 45.235s
[2K
| Adam | epoch: 028 | loss: 0.18573 - acc: 0.9237 -- iter: 1280/1980
[A[ATraining Step: 1715  | total loss: [1m[32m0.17683[0m[0m | time: 46.348s
[2K
| Adam | epoch: 028 | loss: 0.17683 - acc: 0.9251 -- iter: 1312/1980
[A[ATraining Step: 1716  | total loss: [1m[32m0.18028[0m[0m | time: 47.470s
[2K
| Adam | epoch: 028 | loss: 0.18028 - acc: 0.9232 -- iter: 1344/1980
[A[ATraining Step: 1717  | total loss: [1m[32m0.18414[0m[0m | time: 48.722s
[2K
| Adam | epoch: 028 | loss: 0.18414 - acc: 0.9215 -- iter: 1376/1980
[A[ATraining Step: 1718  | total loss: [1m[32m0.18667[0m[0m | time: 49.896s
[2K
| Adam | epoch: 028 | loss: 0.18667 - acc: 0.9200 -- iter: 1408/1980
[A[ATraining Step: 1719  | total loss: [1m[32m0.18102[0m[0m | time: 50.829s
[2K
| Adam | epoch: 028 | loss: 0.18102 - acc: 0.9249 -- iter: 1440/1980
[A[ATraining Step: 1720  | total loss: [1m[32m0.17862[0m[0m | time: 51.852s
[2K
| Adam | epoch: 028 | loss: 0.17862 - acc: 0.9293 -- iter: 1472/1980
[A[ATraining Step: 1721  | total loss: [1m[32m0.17172[0m[0m | time: 52.938s
[2K
| Adam | epoch: 028 | loss: 0.17172 - acc: 0.9332 -- iter: 1504/1980
[A[ATraining Step: 1722  | total loss: [1m[32m0.18074[0m[0m | time: 54.107s
[2K
| Adam | epoch: 028 | loss: 0.18074 - acc: 0.9274 -- iter: 1536/1980
[A[ATraining Step: 1723  | total loss: [1m[32m0.17275[0m[0m | time: 55.123s
[2K
| Adam | epoch: 028 | loss: 0.17275 - acc: 0.9284 -- iter: 1568/1980
[A[ATraining Step: 1724  | total loss: [1m[32m0.16547[0m[0m | time: 56.260s
[2K
| Adam | epoch: 028 | loss: 0.16547 - acc: 0.9324 -- iter: 1600/1980
[A[ATraining Step: 1725  | total loss: [1m[32m0.17477[0m[0m | time: 57.550s
[2K
| Adam | epoch: 028 | loss: 0.17477 - acc: 0.9298 -- iter: 1632/1980
[A[ATraining Step: 1726  | total loss: [1m[32m0.17686[0m[0m | time: 58.721s
[2K
| Adam | epoch: 028 | loss: 0.17686 - acc: 0.9243 -- iter: 1664/1980
[A[ATraining Step: 1727  | total loss: [1m[32m0.16901[0m[0m | time: 59.879s
[2K
| Adam | epoch: 028 | loss: 0.16901 - acc: 0.9288 -- iter: 1696/1980
[A[ATraining Step: 1728  | total loss: [1m[32m0.17516[0m[0m | time: 61.108s
[2K
| Adam | epoch: 028 | loss: 0.17516 - acc: 0.9265 -- iter: 1728/1980
[A[ATraining Step: 1729  | total loss: [1m[32m0.18760[0m[0m | time: 62.297s
[2K
| Adam | epoch: 028 | loss: 0.18760 - acc: 0.9245 -- iter: 1760/1980
[A[ATraining Step: 1730  | total loss: [1m[32m0.17779[0m[0m | time: 63.265s
[2K
| Adam | epoch: 028 | loss: 0.17779 - acc: 0.9258 -- iter: 1792/1980
[A[ATraining Step: 1731  | total loss: [1m[32m0.18360[0m[0m | time: 64.332s
[2K
| Adam | epoch: 028 | loss: 0.18360 - acc: 0.9238 -- iter: 1824/1980
[A[ATraining Step: 1732  | total loss: [1m[32m0.20088[0m[0m | time: 65.412s
[2K
| Adam | epoch: 028 | loss: 0.20088 - acc: 0.9221 -- iter: 1856/1980
[A[ATraining Step: 1733  | total loss: [1m[32m0.20700[0m[0m | time: 66.529s
[2K
| Adam | epoch: 028 | loss: 0.20700 - acc: 0.9142 -- iter: 1888/1980
[A[ATraining Step: 1734  | total loss: [1m[32m0.20481[0m[0m | time: 67.609s
[2K
| Adam | epoch: 028 | loss: 0.20481 - acc: 0.9166 -- iter: 1920/1980
[A[ATraining Step: 1735  | total loss: [1m[32m0.20430[0m[0m | time: 68.726s
[2K
| Adam | epoch: 028 | loss: 0.20430 - acc: 0.9155 -- iter: 1952/1980
[A[ATraining Step: 1736  | total loss: [1m[32m0.19445[0m[0m | time: 74.480s
[2K
| Adam | epoch: 028 | loss: 0.19445 - acc: 0.9209 | val_loss: 0.84078 - val_acc: 0.7076 -- iter: 1980/1980
--
Training Step: 1737  | total loss: [1m[32m0.20969[0m[0m | time: 1.289s
[2K
| Adam | epoch: 029 | loss: 0.20969 - acc: 0.9163 -- iter: 0032/1980
[A[ATraining Step: 1738  | total loss: [1m[32m0.22740[0m[0m | time: 2.227s
[2K
| Adam | epoch: 029 | loss: 0.22740 - acc: 0.9090 -- iter: 0064/1980
[A[ATraining Step: 1739  | total loss: [1m[32m0.21737[0m[0m | time: 3.264s
[2K
| Adam | epoch: 029 | loss: 0.21737 - acc: 0.9150 -- iter: 0096/1980
[A[ATraining Step: 1740  | total loss: [1m[32m0.22438[0m[0m | time: 4.336s
[2K
| Adam | epoch: 029 | loss: 0.22438 - acc: 0.9141 -- iter: 0128/1980
[A[ATraining Step: 1741  | total loss: [1m[32m0.20995[0m[0m | time: 5.481s
[2K
| Adam | epoch: 029 | loss: 0.20995 - acc: 0.9227 -- iter: 0160/1980
[A[ATraining Step: 1742  | total loss: [1m[32m0.19847[0m[0m | time: 6.629s
[2K
| Adam | epoch: 029 | loss: 0.19847 - acc: 0.9273 -- iter: 0192/1980
[A[ATraining Step: 1743  | total loss: [1m[32m0.19138[0m[0m | time: 7.792s
[2K
| Adam | epoch: 029 | loss: 0.19138 - acc: 0.9283 -- iter: 0224/1980
[A[ATraining Step: 1744  | total loss: [1m[32m0.20116[0m[0m | time: 9.031s
[2K
| Adam | epoch: 029 | loss: 0.20116 - acc: 0.9261 -- iter: 0256/1980
[A[ATraining Step: 1745  | total loss: [1m[32m0.19181[0m[0m | time: 10.227s
[2K
| Adam | epoch: 029 | loss: 0.19181 - acc: 0.9304 -- iter: 0288/1980
[A[ATraining Step: 1746  | total loss: [1m[32m0.20965[0m[0m | time: 11.302s
[2K
| Adam | epoch: 029 | loss: 0.20965 - acc: 0.9186 -- iter: 0320/1980
[A[ATraining Step: 1747  | total loss: [1m[32m0.19858[0m[0m | time: 12.558s
[2K
| Adam | epoch: 029 | loss: 0.19858 - acc: 0.9205 -- iter: 0352/1980
[A[ATraining Step: 1748  | total loss: [1m[32m0.19791[0m[0m | time: 13.731s
[2K
| Adam | epoch: 029 | loss: 0.19791 - acc: 0.9222 -- iter: 0384/1980
[A[ATraining Step: 1749  | total loss: [1m[32m0.19302[0m[0m | time: 14.751s
[2K
| Adam | epoch: 029 | loss: 0.19302 - acc: 0.9237 -- iter: 0416/1980
[A[ATraining Step: 1750  | total loss: [1m[32m0.17997[0m[0m | time: 15.789s
[2K
| Adam | epoch: 029 | loss: 0.17997 - acc: 0.9313 -- iter: 0448/1980
[A[ATraining Step: 1751  | total loss: [1m[32m0.18376[0m[0m | time: 16.967s
[2K
| Adam | epoch: 029 | loss: 0.18376 - acc: 0.9320 -- iter: 0480/1980
[A[ATraining Step: 1752  | total loss: [1m[32m0.17362[0m[0m | time: 18.171s
[2K
| Adam | epoch: 029 | loss: 0.17362 - acc: 0.9356 -- iter: 0512/1980
[A[ATraining Step: 1753  | total loss: [1m[32m0.16394[0m[0m | time: 19.284s
[2K
| Adam | epoch: 029 | loss: 0.16394 - acc: 0.9421 -- iter: 0544/1980
[A[ATraining Step: 1754  | total loss: [1m[32m0.18880[0m[0m | time: 20.506s
[2K
| Adam | epoch: 029 | loss: 0.18880 - acc: 0.9354 -- iter: 0576/1980
[A[ATraining Step: 1755  | total loss: [1m[32m0.18143[0m[0m | time: 21.755s
[2K
| Adam | epoch: 029 | loss: 0.18143 - acc: 0.9387 -- iter: 0608/1980
[A[ATraining Step: 1756  | total loss: [1m[32m0.17201[0m[0m | time: 22.934s
[2K
| Adam | epoch: 029 | loss: 0.17201 - acc: 0.9417 -- iter: 0640/1980
[A[ATraining Step: 1757  | total loss: [1m[32m0.16416[0m[0m | time: 24.088s
[2K
| Adam | epoch: 029 | loss: 0.16416 - acc: 0.9444 -- iter: 0672/1980
[A[ATraining Step: 1758  | total loss: [1m[32m0.15525[0m[0m | time: 25.349s
[2K
| Adam | epoch: 029 | loss: 0.15525 - acc: 0.9500 -- iter: 0704/1980
[A[ATraining Step: 1759  | total loss: [1m[32m0.15873[0m[0m | time: 26.607s
[2K
| Adam | epoch: 029 | loss: 0.15873 - acc: 0.9456 -- iter: 0736/1980
[A[ATraining Step: 1760  | total loss: [1m[32m0.14639[0m[0m | time: 27.584s
[2K
| Adam | epoch: 029 | loss: 0.14639 - acc: 0.9510 -- iter: 0768/1980
[A[ATraining Step: 1761  | total loss: [1m[32m0.14824[0m[0m | time: 28.654s
[2K
| Adam | epoch: 029 | loss: 0.14824 - acc: 0.9466 -- iter: 0800/1980
[A[ATraining Step: 1762  | total loss: [1m[32m0.14420[0m[0m | time: 29.768s
[2K
| Adam | epoch: 029 | loss: 0.14420 - acc: 0.9457 -- iter: 0832/1980
[A[ATraining Step: 1763  | total loss: [1m[32m0.14061[0m[0m | time: 30.801s
[2K
| Adam | epoch: 029 | loss: 0.14061 - acc: 0.9448 -- iter: 0864/1980
[A[ATraining Step: 1764  | total loss: [1m[32m0.14011[0m[0m | time: 31.738s
[2K
| Adam | epoch: 029 | loss: 0.14011 - acc: 0.9432 -- iter: 0896/1980
[A[ATraining Step: 1765  | total loss: [1m[32m0.13773[0m[0m | time: 32.926s
[2K
| Adam | epoch: 029 | loss: 0.13773 - acc: 0.9489 -- iter: 0928/1980
[A[ATraining Step: 1766  | total loss: [1m[32m0.14147[0m[0m | time: 34.017s
[2K
| Adam | epoch: 029 | loss: 0.14147 - acc: 0.9446 -- iter: 0960/1980
[A[ATraining Step: 1767  | total loss: [1m[32m0.13308[0m[0m | time: 35.139s
[2K
| Adam | epoch: 029 | loss: 0.13308 - acc: 0.9502 -- iter: 0992/1980
[A[ATraining Step: 1768  | total loss: [1m[32m0.14112[0m[0m | time: 36.232s
[2K
| Adam | epoch: 029 | loss: 0.14112 - acc: 0.9489 -- iter: 1024/1980
[A[ATraining Step: 1769  | total loss: [1m[32m0.13170[0m[0m | time: 37.293s
[2K
| Adam | epoch: 029 | loss: 0.13170 - acc: 0.9540 -- iter: 1056/1980
[A[ATraining Step: 1770  | total loss: [1m[32m0.12426[0m[0m | time: 38.536s
[2K
| Adam | epoch: 029 | loss: 0.12426 - acc: 0.9586 -- iter: 1088/1980
[A[ATraining Step: 1771  | total loss: [1m[32m0.12757[0m[0m | time: 39.729s
[2K
| Adam | epoch: 029 | loss: 0.12757 - acc: 0.9565 -- iter: 1120/1980
[A[ATraining Step: 1772  | total loss: [1m[32m0.14041[0m[0m | time: 40.651s
[2K
| Adam | epoch: 029 | loss: 0.14041 - acc: 0.9515 -- iter: 1152/1980
[A[ATraining Step: 1773  | total loss: [1m[32m0.14269[0m[0m | time: 41.662s
[2K
| Adam | epoch: 029 | loss: 0.14269 - acc: 0.9470 -- iter: 1184/1980
[A[ATraining Step: 1774  | total loss: [1m[32m0.13441[0m[0m | time: 42.753s
[2K
| Adam | epoch: 029 | loss: 0.13441 - acc: 0.9523 -- iter: 1216/1980
[A[ATraining Step: 1775  | total loss: [1m[32m0.12808[0m[0m | time: 43.818s
[2K
| Adam | epoch: 029 | loss: 0.12808 - acc: 0.9570 -- iter: 1248/1980
[A[ATraining Step: 1776  | total loss: [1m[32m0.12007[0m[0m | time: 44.916s
[2K
| Adam | epoch: 029 | loss: 0.12007 - acc: 0.9613 -- iter: 1280/1980
[A[ATraining Step: 1777  | total loss: [1m[32m0.12925[0m[0m | time: 46.050s
[2K
| Adam | epoch: 029 | loss: 0.12925 - acc: 0.9558 -- iter: 1312/1980
[A[ATraining Step: 1778  | total loss: [1m[32m0.14140[0m[0m | time: 47.294s
[2K
| Adam | epoch: 029 | loss: 0.14140 - acc: 0.9477 -- iter: 1344/1980
[A[ATraining Step: 1779  | total loss: [1m[32m0.15049[0m[0m | time: 48.438s
[2K
| Adam | epoch: 029 | loss: 0.15049 - acc: 0.9467 -- iter: 1376/1980
[A[ATraining Step: 1780  | total loss: [1m[32m0.18248[0m[0m | time: 49.499s
[2K
| Adam | epoch: 029 | loss: 0.18248 - acc: 0.9333 -- iter: 1408/1980
[A[ATraining Step: 1781  | total loss: [1m[32m0.18640[0m[0m | time: 50.616s
[2K
| Adam | epoch: 029 | loss: 0.18640 - acc: 0.9275 -- iter: 1440/1980
[A[ATraining Step: 1782  | total loss: [1m[32m0.18467[0m[0m | time: 51.841s
[2K
| Adam | epoch: 029 | loss: 0.18467 - acc: 0.9253 -- iter: 1472/1980
[A[ATraining Step: 1783  | total loss: [1m[32m0.16930[0m[0m | time: 52.974s
[2K
| Adam | epoch: 029 | loss: 0.16930 - acc: 0.9328 -- iter: 1504/1980
[A[ATraining Step: 1784  | total loss: [1m[32m0.16897[0m[0m | time: 54.075s
[2K
| Adam | epoch: 029 | loss: 0.16897 - acc: 0.9333 -- iter: 1536/1980
[A[ATraining Step: 1785  | total loss: [1m[32m0.18234[0m[0m | time: 55.280s
[2K
| Adam | epoch: 029 | loss: 0.18234 - acc: 0.9337 -- iter: 1568/1980
[A[ATraining Step: 1786  | total loss: [1m[32m0.18434[0m[0m | time: 56.586s
[2K
| Adam | epoch: 029 | loss: 0.18434 - acc: 0.9216 -- iter: 1600/1980
[A[ATraining Step: 1787  | total loss: [1m[32m0.18558[0m[0m | time: 57.838s
[2K
| Adam | epoch: 029 | loss: 0.18558 - acc: 0.9169 -- iter: 1632/1980
[A[ATraining Step: 1788  | total loss: [1m[32m0.17472[0m[0m | time: 59.088s
[2K
| Adam | epoch: 029 | loss: 0.17472 - acc: 0.9221 -- iter: 1664/1980
[A[ATraining Step: 1789  | total loss: [1m[32m0.17254[0m[0m | time: 60.403s
[2K
| Adam | epoch: 029 | loss: 0.17254 - acc: 0.9268 -- iter: 1696/1980
[A[ATraining Step: 1790  | total loss: [1m[32m0.16391[0m[0m | time: 61.697s
[2K
| Adam | epoch: 029 | loss: 0.16391 - acc: 0.9310 -- iter: 1728/1980
[A[ATraining Step: 1791  | total loss: [1m[32m0.15788[0m[0m | time: 62.900s
[2K
| Adam | epoch: 029 | loss: 0.15788 - acc: 0.9316 -- iter: 1760/1980
[A[ATraining Step: 1792  | total loss: [1m[32m0.16069[0m[0m | time: 63.994s
[2K
| Adam | epoch: 029 | loss: 0.16069 - acc: 0.9291 -- iter: 1792/1980
[A[ATraining Step: 1793  | total loss: [1m[32m0.16250[0m[0m | time: 65.070s
[2K
| Adam | epoch: 029 | loss: 0.16250 - acc: 0.9299 -- iter: 1824/1980
[A[ATraining Step: 1794  | total loss: [1m[32m0.15796[0m[0m | time: 66.364s
[2K
| Adam | epoch: 029 | loss: 0.15796 - acc: 0.9338 -- iter: 1856/1980
[A[ATraining Step: 1795  | total loss: [1m[32m0.17143[0m[0m | time: 67.633s
[2K
| Adam | epoch: 029 | loss: 0.17143 - acc: 0.9342 -- iter: 1888/1980
[A[ATraining Step: 1796  | total loss: [1m[32m0.16533[0m[0m | time: 68.923s
[2K
| Adam | epoch: 029 | loss: 0.16533 - acc: 0.9345 -- iter: 1920/1980
[A[ATraining Step: 1797  | total loss: [1m[32m0.15996[0m[0m | time: 70.095s
[2K
| Adam | epoch: 029 | loss: 0.15996 - acc: 0.9379 -- iter: 1952/1980
[A[ATraining Step: 1798  | total loss: [1m[32m0.14799[0m[0m | time: 76.098s
[2K
| Adam | epoch: 029 | loss: 0.14799 - acc: 0.9441 | val_loss: 0.66951 - val_acc: 0.7997 -- iter: 1980/1980
--
Training Step: 1799  | total loss: [1m[32m0.14860[0m[0m | time: 1.152s
[2K
| Adam | epoch: 030 | loss: 0.14860 - acc: 0.9435 -- iter: 0032/1980
[A[ATraining Step: 1800  | total loss: [1m[32m0.14326[0m[0m | time: 6.685s
[2K
| Adam | epoch: 030 | loss: 0.14326 - acc: 0.9429 | val_loss: 0.74274 - val_acc: 0.7496 -- iter: 0064/1980
--
Training Step: 1801  | total loss: [1m[32m0.13171[0m[0m | time: 7.599s
[2K
| Adam | epoch: 030 | loss: 0.13171 - acc: 0.9486 -- iter: 0096/1980
[A[ATraining Step: 1802  | total loss: [1m[32m0.14369[0m[0m | time: 8.758s
[2K
| Adam | epoch: 030 | loss: 0.14369 - acc: 0.9506 -- iter: 0128/1980
[A[ATraining Step: 1803  | total loss: [1m[32m0.14343[0m[0m | time: 9.837s
[2K
| Adam | epoch: 030 | loss: 0.14343 - acc: 0.9493 -- iter: 0160/1980
[A[ATraining Step: 1804  | total loss: [1m[32m0.13233[0m[0m | time: 11.015s
[2K
| Adam | epoch: 030 | loss: 0.13233 - acc: 0.9544 -- iter: 0192/1980
[A[ATraining Step: 1805  | total loss: [1m[32m0.13252[0m[0m | time: 12.108s
[2K
| Adam | epoch: 030 | loss: 0.13252 - acc: 0.9527 -- iter: 0224/1980
[A[ATraining Step: 1806  | total loss: [1m[32m0.12224[0m[0m | time: 13.313s
[2K
| Adam | epoch: 030 | loss: 0.12224 - acc: 0.9574 -- iter: 0256/1980
[A[ATraining Step: 1807  | total loss: [1m[32m0.11831[0m[0m | time: 14.432s
[2K
| Adam | epoch: 030 | loss: 0.11831 - acc: 0.9617 -- iter: 0288/1980
[A[ATraining Step: 1808  | total loss: [1m[32m0.11211[0m[0m | time: 15.505s
[2K
| Adam | epoch: 030 | loss: 0.11211 - acc: 0.9655 -- iter: 0320/1980
[A[ATraining Step: 1809  | total loss: [1m[32m0.10717[0m[0m | time: 16.584s
[2K
| Adam | epoch: 030 | loss: 0.10717 - acc: 0.9658 -- iter: 0352/1980
[A[ATraining Step: 1810  | total loss: [1m[32m0.10550[0m[0m | time: 17.831s
[2K
| Adam | epoch: 030 | loss: 0.10550 - acc: 0.9661 -- iter: 0384/1980
[A[ATraining Step: 1811  | total loss: [1m[32m0.10555[0m[0m | time: 19.025s
[2K
| Adam | epoch: 030 | loss: 0.10555 - acc: 0.9664 -- iter: 0416/1980
[A[ATraining Step: 1812  | total loss: [1m[32m0.10845[0m[0m | time: 19.947s
[2K
| Adam | epoch: 030 | loss: 0.10845 - acc: 0.9635 -- iter: 0448/1980
[A[ATraining Step: 1813  | total loss: [1m[32m0.11864[0m[0m | time: 20.954s
[2K
| Adam | epoch: 030 | loss: 0.11864 - acc: 0.9609 -- iter: 0480/1980
[A[ATraining Step: 1814  | total loss: [1m[32m0.12664[0m[0m | time: 22.145s
[2K
| Adam | epoch: 030 | loss: 0.12664 - acc: 0.9554 -- iter: 0512/1980
[A[ATraining Step: 1815  | total loss: [1m[32m0.12439[0m[0m | time: 23.228s
[2K
| Adam | epoch: 030 | loss: 0.12439 - acc: 0.9568 -- iter: 0544/1980
[A[ATraining Step: 1816  | total loss: [1m[32m0.12631[0m[0m | time: 24.399s
[2K
| Adam | epoch: 030 | loss: 0.12631 - acc: 0.9517 -- iter: 0576/1980
[A[ATraining Step: 1817  | total loss: [1m[32m0.12937[0m[0m | time: 25.686s
[2K
| Adam | epoch: 030 | loss: 0.12937 - acc: 0.9534 -- iter: 0608/1980
[A[ATraining Step: 1818  | total loss: [1m[32m0.13902[0m[0m | time: 26.875s
[2K
| Adam | epoch: 030 | loss: 0.13902 - acc: 0.9456 -- iter: 0640/1980
[A[ATraining Step: 1819  | total loss: [1m[32m0.13718[0m[0m | time: 28.013s
[2K
| Adam | epoch: 030 | loss: 0.13718 - acc: 0.9448 -- iter: 0672/1980
[A[ATraining Step: 1820  | total loss: [1m[32m0.13135[0m[0m | time: 29.181s
[2K
| Adam | epoch: 030 | loss: 0.13135 - acc: 0.9472 -- iter: 0704/1980
[A[ATraining Step: 1821  | total loss: [1m[32m0.13306[0m[0m | time: 30.439s
[2K
| Adam | epoch: 030 | loss: 0.13306 - acc: 0.9462 -- iter: 0736/1980
[A[ATraining Step: 1822  | total loss: [1m[32m0.12695[0m[0m | time: 31.672s
[2K
| Adam | epoch: 030 | loss: 0.12695 - acc: 0.9516 -- iter: 0768/1980
[A[ATraining Step: 1823  | total loss: [1m[32m0.12496[0m[0m | time: 32.555s
[2K
| Adam | epoch: 030 | loss: 0.12496 - acc: 0.9533 -- iter: 0800/1980
[A[ATraining Step: 1824  | total loss: [1m[32m0.11919[0m[0m | time: 33.573s
[2K
| Adam | epoch: 030 | loss: 0.11919 - acc: 0.9580 -- iter: 0832/1980
[A[ATraining Step: 1825  | total loss: [1m[32m0.11562[0m[0m | time: 34.707s
[2K
| Adam | epoch: 030 | loss: 0.11562 - acc: 0.9559 -- iter: 0864/1980
[A[ATraining Step: 1826  | total loss: [1m[32m0.11576[0m[0m | time: 35.699s
[2K
| Adam | epoch: 030 | loss: 0.11576 - acc: 0.9572 -- iter: 0896/1980
[A[ATraining Step: 1827  | total loss: [1m[32m0.12888[0m[0m | time: 36.703s
[2K
| Adam | epoch: 030 | loss: 0.12888 - acc: 0.9508 -- iter: 0928/1980
[A[ATraining Step: 1828  | total loss: [1m[32m0.14002[0m[0m | time: 37.795s
[2K
| Adam | epoch: 030 | loss: 0.14002 - acc: 0.9485 -- iter: 0960/1980
[A[ATraining Step: 1829  | total loss: [1m[32m0.13425[0m[0m | time: 38.971s
[2K
| Adam | epoch: 030 | loss: 0.13425 - acc: 0.9506 -- iter: 0992/1980
[A[ATraining Step: 1830  | total loss: [1m[32m0.13511[0m[0m | time: 40.087s
[2K
| Adam | epoch: 030 | loss: 0.13511 - acc: 0.9493 -- iter: 1024/1980
[A[ATraining Step: 1831  | total loss: [1m[32m0.14262[0m[0m | time: 41.162s
[2K
| Adam | epoch: 030 | loss: 0.14262 - acc: 0.9481 -- iter: 1056/1980
[A[ATraining Step: 1832  | total loss: [1m[32m0.14505[0m[0m | time: 42.270s
[2K
| Adam | epoch: 030 | loss: 0.14505 - acc: 0.9470 -- iter: 1088/1980
[A[ATraining Step: 1833  | total loss: [1m[32m0.14130[0m[0m | time: 43.467s
[2K
| Adam | epoch: 030 | loss: 0.14130 - acc: 0.9461 -- iter: 1120/1980
[A[ATraining Step: 1834  | total loss: [1m[32m0.14725[0m[0m | time: 44.596s
[2K
| Adam | epoch: 030 | loss: 0.14725 - acc: 0.9390 -- iter: 1152/1980
[A[ATraining Step: 1835  | total loss: [1m[32m0.14530[0m[0m | time: 45.460s
[2K
| Adam | epoch: 030 | loss: 0.14530 - acc: 0.9419 -- iter: 1184/1980
[A[ATraining Step: 1836  | total loss: [1m[32m0.13815[0m[0m | time: 46.514s
[2K
| Adam | epoch: 030 | loss: 0.13815 - acc: 0.9446 -- iter: 1216/1980
[A[ATraining Step: 1837  | total loss: [1m[32m0.13679[0m[0m | time: 47.650s
[2K
| Adam | epoch: 030 | loss: 0.13679 - acc: 0.9470 -- iter: 1248/1980
[A[ATraining Step: 1838  | total loss: [1m[32m0.14143[0m[0m | time: 48.742s
[2K
| Adam | epoch: 030 | loss: 0.14143 - acc: 0.9461 -- iter: 1280/1980
[A[ATraining Step: 1839  | total loss: [1m[32m0.15003[0m[0m | time: 49.864s
[2K
| Adam | epoch: 030 | loss: 0.15003 - acc: 0.9359 -- iter: 1312/1980
[A[ATraining Step: 1840  | total loss: [1m[32m0.14529[0m[0m | time: 51.012s
[2K
| Adam | epoch: 030 | loss: 0.14529 - acc: 0.9391 -- iter: 1344/1980
[A[ATraining Step: 1841  | total loss: [1m[32m0.14048[0m[0m | time: 52.141s
[2K
| Adam | epoch: 030 | loss: 0.14048 - acc: 0.9452 -- iter: 1376/1980
[A[ATraining Step: 1842  | total loss: [1m[32m0.14253[0m[0m | time: 53.306s
[2K
| Adam | epoch: 030 | loss: 0.14253 - acc: 0.9445 -- iter: 1408/1980
[A[ATraining Step: 1843  | total loss: [1m[32m0.13281[0m[0m | time: 54.446s
[2K
| Adam | epoch: 030 | loss: 0.13281 - acc: 0.9500 -- iter: 1440/1980
[A[ATraining Step: 1844  | total loss: [1m[32m0.12507[0m[0m | time: 55.561s
[2K
| Adam | epoch: 030 | loss: 0.12507 - acc: 0.9550 -- iter: 1472/1980
[A[ATraining Step: 1845  | total loss: [1m[32m0.11919[0m[0m | time: 56.816s
[2K
| Adam | epoch: 030 | loss: 0.11919 - acc: 0.9564 -- iter: 1504/1980
[A[ATraining Step: 1846  | total loss: [1m[32m0.12204[0m[0m | time: 58.023s
[2K
| Adam | epoch: 030 | loss: 0.12204 - acc: 0.9545 -- iter: 1536/1980
[A[ATraining Step: 1847  | total loss: [1m[32m0.12126[0m[0m | time: 58.953s
[2K
| Adam | epoch: 030 | loss: 0.12126 - acc: 0.9559 -- iter: 1568/1980
[A[ATraining Step: 1848  | total loss: [1m[32m0.12394[0m[0m | time: 60.044s
[2K
| Adam | epoch: 030 | loss: 0.12394 - acc: 0.9510 -- iter: 1600/1980
[A[ATraining Step: 1849  | total loss: [1m[32m0.11652[0m[0m | time: 61.159s
[2K
| Adam | epoch: 030 | loss: 0.11652 - acc: 0.9559 -- iter: 1632/1980
[A[ATraining Step: 1850  | total loss: [1m[32m0.11552[0m[0m | time: 62.239s
[2K
| Adam | epoch: 030 | loss: 0.11552 - acc: 0.9540 -- iter: 1664/1980
[A[ATraining Step: 1851  | total loss: [1m[32m0.11101[0m[0m | time: 63.345s
[2K
| Adam | epoch: 030 | loss: 0.11101 - acc: 0.9555 -- iter: 1696/1980
[A[ATraining Step: 1852  | total loss: [1m[32m0.11523[0m[0m | time: 64.438s
[2K
| Adam | epoch: 030 | loss: 0.11523 - acc: 0.9537 -- iter: 1728/1980
[A[ATraining Step: 1853  | total loss: [1m[32m0.11046[0m[0m | time: 65.609s
[2K
| Adam | epoch: 030 | loss: 0.11046 - acc: 0.9552 -- iter: 1760/1980
[A[ATraining Step: 1854  | total loss: [1m[32m0.11124[0m[0m | time: 66.716s
[2K
| Adam | epoch: 030 | loss: 0.11124 - acc: 0.9534 -- iter: 1792/1980
[A[ATraining Step: 1855  | total loss: [1m[32m0.13327[0m[0m | time: 67.737s
[2K
| Adam | epoch: 030 | loss: 0.13327 - acc: 0.9425 -- iter: 1824/1980
[A[ATraining Step: 1856  | total loss: [1m[32m0.12918[0m[0m | time: 69.028s
[2K
| Adam | epoch: 030 | loss: 0.12918 - acc: 0.9451 -- iter: 1856/1980
[A[ATraining Step: 1857  | total loss: [1m[32m0.15547[0m[0m | time: 70.275s
[2K
| Adam | epoch: 030 | loss: 0.15547 - acc: 0.9381 -- iter: 1888/1980
[A[ATraining Step: 1858  | total loss: [1m[32m0.14507[0m[0m | time: 71.330s
[2K
| Adam | epoch: 030 | loss: 0.14507 - acc: 0.9411 -- iter: 1920/1980
[A[ATraining Step: 1859  | total loss: [1m[32m0.13882[0m[0m | time: 72.392s
[2K
| Adam | epoch: 030 | loss: 0.13882 - acc: 0.9439 -- iter: 1952/1980
[A[ATraining Step: 1860  | total loss: [1m[32m0.13873[0m[0m | time: 77.583s
[2K
| Adam | epoch: 030 | loss: 0.13873 - acc: 0.9401 | val_loss: 0.70283 - val_acc: 0.7787 -- iter: 1980/1980
--
Validation AUC:0.8323010849909585
Validation AUPRC:0.8870328052093694
Test AUC:0.8694181770422906
Test AUPRC:0.9082286125889706
BestTestF1Score	0.84	0.57	0.8	0.82	0.86	325	73	170	51	0.27
BestTestMCCScore	0.84	0.59	0.81	0.84	0.84	314	58	185	62	0.4
BestTestAccuracyScore	0.84	0.59	0.81	0.84	0.84	314	58	185	62	0.4
BestValidationF1Score	0.84	0.54	0.79	0.82	0.87	344	77	147	51	0.27
BestValidationMCC	0.84	0.55	0.79	0.83	0.85	335	67	157	60	0.4
BestValidationAccuracy	0.84	0.55	0.79	0.83	0.85	335	67	157	60	0.4
TestPredictions (Threshold:0.4)
CHEMBL282360,TP,ACT,0.9900000095367432	CHEMBL3576983,TP,ACT,0.8799999952316284	CHEMBL1643002,FP,INACT,0.9900000095367432	CHEMBL419268,TP,ACT,0.9800000190734863	CHEMBL447655,TN,INACT,0.10999999940395355	CHEMBL1171258,TP,ACT,0.6600000262260437	CHEMBL418859,TP,ACT,1.0	CHEMBL1172842,FP,INACT,0.41999998688697815	CHEMBL1684152,TN,INACT,0.009999999776482582	CHEMBL523865,FP,INACT,0.46000000834465027	CHEMBL12532,TP,ACT,1.0	CHEMBL275843,TP,ACT,1.0	CHEMBL41876,TN,INACT,0.0	CHEMBL2159926,FN,ACT,0.029999999329447746	CHEMBL270886,FN,ACT,0.09000000357627869	CHEMBL257483,TP,ACT,0.8899999856948853	CHEMBL1907778,TN,INACT,0.029999999329447746	CHEMBL405417,FP,INACT,0.6200000047683716	CHEMBL358222,TN,INACT,0.36000001430511475	CHEMBL185820,TN,INACT,0.33000001311302185	CHEMBL158148,TP,ACT,0.9900000095367432	CHEMBL2315853,FN,ACT,0.2199999988079071	CHEMBL605161,TP,ACT,0.44999998807907104	CHEMBL1916950,TP,ACT,0.9599999785423279	CHEMBL280226,TP,ACT,0.9200000166893005	CHEMBL307606,FP,INACT,0.9800000190734863	CHEMBL271932,TP,ACT,1.0	CHEMBL18373,FN,ACT,0.07000000029802322	CHEMBL3289927,TN,INACT,0.019999999552965164	CHEMBL512578,TN,INACT,0.03999999910593033	CHEMBL1689431,TP,ACT,0.8500000238418579	CHEMBL456619,TP,ACT,0.8100000023841858	CHEMBL1165011,TN,INACT,0.009999999776482582	CHEMBL3735601,TP,ACT,0.9399999976158142	CHEMBL497858,FN,ACT,0.20999999344348907	CHEMBL190083,FP,INACT,0.9300000071525574	CHEMBL300597,TP,ACT,1.0	CHEMBL16996,TP,ACT,0.8100000023841858	CHEMBL2011190,FP,INACT,0.5600000023841858	CHEMBL363767,TP,ACT,1.0	CHEMBL589087,TN,INACT,0.009999999776482582	CHEMBL324923,TP,ACT,1.0	CHEMBL3127309,TP,ACT,0.9100000262260437	CHEMBL444805,TP,ACT,0.949999988079071	CHEMBL91577,TN,INACT,0.009999999776482582	CHEMBL2158359,TN,INACT,0.18000000715255737	CHEMBL117763,TN,INACT,0.0	CHEMBL403099,TP,ACT,1.0	CHEMBL3596288,TP,ACT,0.9900000095367432	CHEMBL327254,TN,INACT,0.20000000298023224	CHEMBL225092,TP,ACT,0.949999988079071	CHEMBL433287,TN,INACT,0.25999999046325684	CHEMBL3113231,TP,ACT,0.9399999976158142	CHEMBL3262712,TN,INACT,0.009999999776482582	CHEMBL259972,TP,ACT,0.8899999856948853	CHEMBL3408773,TN,INACT,0.009999999776482582	CHEMBL461417,TN,INACT,0.03999999910593033	CHEMBL175436,TN,INACT,0.009999999776482582	CHEMBL51860,TP,ACT,1.0	CHEMBL215872,FP,INACT,0.5199999809265137	CHEMBL521,TP,ACT,0.8999999761581421	CHEMBL110574,FN,ACT,0.3100000023841858	CHEMBL257677,TP,ACT,0.9900000095367432	CHEMBL290945,TP,ACT,0.9700000286102295	CHEMBL2283171,TP,ACT,0.9200000166893005	CHEMBL122357,TP,ACT,0.8700000047683716	CHEMBL434673,TP,ACT,0.9399999976158142	CHEMBL118962,TP,ACT,0.8100000023841858	CHEMBL1275972,FN,ACT,0.14000000059604645	CHEMBL88899,TP,ACT,1.0	CHEMBL271549,FN,ACT,0.1599999964237213	CHEMBL115410,TP,ACT,1.0	CHEMBL3309825,TN,INACT,0.009999999776482582	CHEMBL1956388,TP,ACT,0.9599999785423279	CHEMBL3810258,FN,ACT,0.17000000178813934	CHEMBL3309954,TN,INACT,0.009999999776482582	CHEMBL3265345,FP,INACT,0.5699999928474426	CHEMBL187468,TP,ACT,0.9900000095367432	CHEMBL16981,TP,ACT,0.9900000095367432	CHEMBL3338719,TN,INACT,0.3700000047683716	CHEMBL324472,TP,ACT,0.9700000286102295	CHEMBL320961,TP,ACT,1.0	CHEMBL2323507,TN,INACT,0.009999999776482582	CHEMBL559056,FN,ACT,0.36000001430511475	CHEMBL378875,TN,INACT,0.33000001311302185	CHEMBL282924,TP,ACT,1.0	CHEMBL3264519,FP,INACT,0.7900000214576721	CHEMBL320111,TP,ACT,0.6399999856948853	CHEMBL255378,TP,ACT,1.0	CHEMBL168444,TN,INACT,0.019999999552965164	CHEMBL622,FN,ACT,0.009999999776482582	CHEMBL13623,TP,ACT,1.0	CHEMBL2333751,TP,ACT,0.8799999952316284	CHEMBL125460,TP,ACT,1.0	CHEMBL391916,TN,INACT,0.2800000011920929	CHEMBL44466,FN,ACT,0.3199999928474426	CHEMBL270087,TP,ACT,0.9900000095367432	CHEMBL1089510,TN,INACT,0.20000000298023224	CHEMBL2398536,TN,INACT,0.05999999865889549	CHEMBL275120,TP,ACT,0.9900000095367432	CHEMBL210300,TP,ACT,0.8199999928474426	CHEMBL1240924,TN,INACT,0.3100000023841858	CHEMBL39782,TN,INACT,0.009999999776482582	CHEMBL96011,TP,ACT,1.0	CHEMBL29562,TP,ACT,0.9800000190734863	CHEMBL3322409,TP,ACT,1.0	CHEMBL7976,TN,INACT,0.15000000596046448	CHEMBL38368,TP,ACT,1.0	CHEMBL2334135,FP,INACT,0.8899999856948853	CHEMBL3400659,TP,ACT,0.8700000047683716	CHEMBL3736406,TN,INACT,0.2199999988079071	CHEMBL100615,FP,INACT,0.949999988079071	CHEMBL490292,FN,ACT,0.019999999552965164	CHEMBL129861,FP,INACT,0.9399999976158142	CHEMBL1950012,TP,ACT,0.7099999785423279	CHEMBL80047,FN,ACT,0.03999999910593033	CHEMBL189133,TN,INACT,0.029999999329447746	CHEMBL116328,TN,INACT,0.0	CHEMBL1088301,FP,INACT,0.6100000143051147	CHEMBL331749,TP,ACT,0.9800000190734863	CHEMBL32375,TN,INACT,0.0	CHEMBL1290564,TP,ACT,0.9900000095367432	CHEMBL1290683,TP,ACT,0.9900000095367432	CHEMBL35978,TN,INACT,0.15000000596046448	CHEMBL315421,TN,INACT,0.0	CHEMBL108512,TP,ACT,0.9900000095367432	CHEMBL431843,TN,INACT,0.09000000357627869	CHEMBL3233602,TP,ACT,1.0	CHEMBL2347672,TP,ACT,1.0	CHEMBL66552,TN,INACT,0.009999999776482582	CHEMBL469785,FN,ACT,0.11999999731779099	CHEMBL3264523,FN,ACT,0.1599999964237213	CHEMBL3289929,TN,INACT,0.019999999552965164	CHEMBL344351,TP,ACT,1.0	CHEMBL1632396,FP,INACT,0.949999988079071	CHEMBL54326,TP,ACT,1.0	CHEMBL82981,FP,INACT,0.5899999737739563	CHEMBL293892,TN,INACT,0.0	CHEMBL283497,TP,ACT,0.9900000095367432	CHEMBL347198,TP,ACT,0.8600000143051147	CHEMBL2391200,TN,INACT,0.009999999776482582	CHEMBL3402440,TN,INACT,0.0	CHEMBL2315738,TN,INACT,0.009999999776482582	CHEMBL122065,TP,ACT,0.9599999785423279	CHEMBL2283165,TP,ACT,0.8799999952316284	CHEMBL108857,TP,ACT,0.9300000071525574	CHEMBL522267,TN,INACT,0.0	CHEMBL9126,TN,INACT,0.009999999776482582	CHEMBL156399,TP,ACT,0.949999988079071	CHEMBL111356,TP,ACT,0.6800000071525574	CHEMBL1957877,TN,INACT,0.1599999964237213	CHEMBL143339,TP,ACT,1.0	CHEMBL149597,TP,ACT,0.5899999737739563	CHEMBL321217,TP,ACT,0.9800000190734863	CHEMBL408788,TP,ACT,1.0	CHEMBL178687,FP,INACT,0.7799999713897705	CHEMBL363741,FN,ACT,0.0	CHEMBL277385,TP,ACT,1.0	CHEMBL66445,TP,ACT,0.9700000286102295	CHEMBL417452,TN,INACT,0.009999999776482582	CHEMBL3309823,TP,ACT,0.9700000286102295	CHEMBL314225,TP,ACT,1.0	CHEMBL99374,TP,ACT,0.47999998927116394	CHEMBL117650,TP,ACT,1.0	CHEMBL330314,TP,ACT,1.0	CHEMBL3402334,TN,INACT,0.0	CHEMBL1917103,FN,ACT,0.23999999463558197	CHEMBL407109,TP,ACT,0.8700000047683716	CHEMBL3823735,TP,ACT,0.9300000071525574	CHEMBL3576981,TP,ACT,0.7599999904632568	CHEMBL311400,TN,INACT,0.0	CHEMBL411894,TP,ACT,1.0	CHEMBL1275971,TN,INACT,0.07999999821186066	CHEMBL2283148,FN,ACT,0.05000000074505806	CHEMBL458707,TN,INACT,0.019999999552965164	CHEMBL552145,TP,ACT,0.7099999785423279	CHEMBL117,TN,INACT,0.05000000074505806	CHEMBL126418,TN,INACT,0.10000000149011612	CHEMBL391344,FP,INACT,0.9800000190734863	CHEMBL49775,TP,ACT,0.9900000095367432	CHEMBL408442,TP,ACT,0.949999988079071	CHEMBL314297,TP,ACT,1.0	CHEMBL43842,TP,ACT,1.0	CHEMBL3735721,TP,ACT,0.9700000286102295	CHEMBL298084,TP,ACT,1.0	CHEMBL89578,TP,ACT,1.0	CHEMBL3309953,TN,INACT,0.009999999776482582	CHEMBL262744,TP,ACT,1.0	CHEMBL3099218,TP,ACT,0.9900000095367432	CHEMBL3103780,TN,INACT,0.11999999731779099	CHEMBL110514,TP,ACT,0.8999999761581421	CHEMBL3264694,TP,ACT,0.9800000190734863	CHEMBL298296,TP,ACT,1.0	CHEMBL1204023,TP,ACT,0.9900000095367432	CHEMBL426110,TN,INACT,0.0	CHEMBL111057,TP,ACT,0.9399999976158142	CHEMBL298208,TP,ACT,1.0	CHEMBL1165711,TN,INACT,0.05999999865889549	CHEMBL493094,TN,INACT,0.0	CHEMBL259386,TN,INACT,0.009999999776482582	CHEMBL465879,TN,INACT,0.14000000059604645	CHEMBL1630226,TP,ACT,0.9300000071525574	CHEMBL320998,TP,ACT,1.0	CHEMBL45192,TP,ACT,0.800000011920929	CHEMBL451311,FP,INACT,0.9800000190734863	CHEMBL282839,TP,ACT,0.9599999785423279	CHEMBL3338727,TN,INACT,0.0	CHEMBL2087940,TN,INACT,0.0	CHEMBL1082691,TN,INACT,0.009999999776482582	CHEMBL1288695,FN,ACT,0.12999999523162842	CHEMBL1775097,TN,INACT,0.05999999865889549	CHEMBL228985,TN,INACT,0.12999999523162842	CHEMBL2398534,FN,ACT,0.07000000029802322	CHEMBL1915161,TN,INACT,0.0	CHEMBL71372,TP,ACT,1.0	CHEMBL1288642,TP,ACT,0.9900000095367432	CHEMBL3113227,TN,INACT,0.019999999552965164	CHEMBL185547,TP,ACT,1.0	CHEMBL45387,TP,ACT,1.0	CHEMBL98489,TP,ACT,1.0	CHEMBL2105528,FN,ACT,0.05999999865889549	CHEMBL86153,TN,INACT,0.18000000715255737	CHEMBL320006,FP,INACT,0.9900000095367432	CHEMBL95921,TP,ACT,1.0	CHEMBL2391202,TN,INACT,0.07999999821186066	CHEMBL16855,FP,INACT,0.8399999737739563	CHEMBL326254,TP,ACT,0.8999999761581421	CHEMBL1630257,TP,ACT,0.9800000190734863	CHEMBL350549,FN,ACT,0.3499999940395355	CHEMBL327113,TN,INACT,0.0	CHEMBL459525,TN,INACT,0.009999999776482582	CHEMBL116343,TP,ACT,1.0	CHEMBL2158363,FN,ACT,0.009999999776482582	CHEMBL2441025,TN,INACT,0.07999999821186066	CHEMBL491088,TP,ACT,0.46000000834465027	CHEMBL345533,TN,INACT,0.009999999776482582	CHEMBL3746878,TP,ACT,0.7300000190734863	CHEMBL268470,TN,INACT,0.019999999552965164	CHEMBL3596282,TP,ACT,1.0	CHEMBL2391038,TN,INACT,0.009999999776482582	CHEMBL313527,TP,ACT,1.0	CHEMBL2018667,FN,ACT,0.3799999952316284	CHEMBL2106551,FN,ACT,0.07999999821186066	CHEMBL320318,FP,INACT,1.0	CHEMBL1766285,TP,ACT,0.9900000095367432	CHEMBL3309956,TN,INACT,0.0	CHEMBL323197,TN,INACT,0.029999999329447746	CHEMBL3410362,TP,ACT,0.6100000143051147	CHEMBL3309443,TP,ACT,1.0	CHEMBL3774538,TP,ACT,0.9900000095367432	CHEMBL491272,TN,INACT,0.0	CHEMBL2011176,FP,INACT,0.5199999809265137	CHEMBL23378,TP,ACT,0.9300000071525574	CHEMBL2160148,TP,ACT,0.9900000095367432	CHEMBL29533,TP,ACT,0.8899999856948853	CHEMBL463125,TN,INACT,0.12999999523162842	CHEMBL2347667,FN,ACT,0.20999999344348907	CHEMBL513339,TN,INACT,0.019999999552965164	CHEMBL466585,TN,INACT,0.3100000023841858	CHEMBL291834,TN,INACT,0.0	CHEMBL2441062,TN,INACT,0.03999999910593033	CHEMBL1775089,TN,INACT,0.009999999776482582	CHEMBL8145,TN,INACT,0.20000000298023224	CHEMBL2431525,TN,INACT,0.0	CHEMBL3823238,TP,ACT,0.9800000190734863	CHEMBL350475,TN,INACT,0.009999999776482582	CHEMBL3322397,TP,ACT,0.8999999761581421	CHEMBL3608346,TN,INACT,0.009999999776482582	CHEMBL1669033,TP,ACT,0.8899999856948853	CHEMBL155587,TP,ACT,0.9900000095367432	CHEMBL159303,TN,INACT,0.3700000047683716	CHEMBL605820,TP,ACT,0.6899999976158142	CHEMBL1289129,TP,ACT,0.9900000095367432	CHEMBL17276,TP,ACT,1.0	CHEMBL3410339,TP,ACT,1.0	CHEMBL2391194,TN,INACT,0.019999999552965164	CHEMBL550473,TP,ACT,0.9900000095367432	CHEMBL3408770,TN,INACT,0.019999999552965164	CHEMBL2115305,TP,ACT,1.0	CHEMBL147016,FP,INACT,0.8799999952316284	CHEMBL1766299,TP,ACT,0.9900000095367432	CHEMBL1957882,TP,ACT,0.9200000166893005	CHEMBL54039,TP,ACT,1.0	CHEMBL499349,TP,ACT,1.0	CHEMBL3355606,TP,ACT,0.949999988079071	CHEMBL513096,TP,ACT,0.6399999856948853	CHEMBL55072,TP,ACT,1.0	CHEMBL153732,TN,INACT,0.12999999523162842	CHEMBL2441064,FP,INACT,0.6000000238418579	CHEMBL99199,TP,ACT,0.9900000095367432	CHEMBL319148,TP,ACT,1.0	CHEMBL148691,FP,INACT,0.9900000095367432	CHEMBL456807,FN,ACT,0.0	CHEMBL124230,TN,INACT,0.07000000029802322	CHEMBL29257,TP,ACT,0.9599999785423279	CHEMBL438647,FP,INACT,0.4099999964237213	CHEMBL158325,TN,INACT,0.3400000035762787	CHEMBL28599,TP,ACT,0.9300000071525574	CHEMBL324312,TP,ACT,0.9900000095367432	CHEMBL366121,FN,ACT,0.0	CHEMBL1147,TP,ACT,0.5	CHEMBL111597,TP,ACT,1.0	CHEMBL465001,TN,INACT,0.009999999776482582	CHEMBL2112309,TN,INACT,0.0	CHEMBL146465,TP,ACT,1.0	CHEMBL70158,TP,ACT,0.9900000095367432	CHEMBL316786,FP,INACT,1.0	CHEMBL3115903,TN,INACT,0.05000000074505806	CHEMBL1950019,FN,ACT,0.019999999552965164	CHEMBL100250,TP,ACT,0.550000011920929	CHEMBL3355608,TP,ACT,1.0	CHEMBL361494,TP,ACT,0.7799999713897705	CHEMBL3103783,FP,INACT,1.0	CHEMBL109546,TN,INACT,0.25	CHEMBL2018668,FN,ACT,0.3799999952316284	CHEMBL173283,TN,INACT,0.27000001072883606	CHEMBL308600,TN,INACT,0.019999999552965164	CHEMBL3265355,TP,ACT,0.5799999833106995	CHEMBL1957886,TP,ACT,0.9100000262260437	CHEMBL317271,TN,INACT,0.23000000417232513	CHEMBL1669035,FN,ACT,0.05000000074505806	CHEMBL3105519,TN,INACT,0.0	CHEMBL2235864,FN,ACT,0.3700000047683716	CHEMBL309490,TN,INACT,0.009999999776482582	CHEMBL368409,TP,ACT,0.8600000143051147	CHEMBL23241,TP,ACT,0.949999988079071	CHEMBL17218,TP,ACT,0.9800000190734863	CHEMBL327751,TP,ACT,1.0	CHEMBL260943,TN,INACT,0.1599999964237213	CHEMBL153495,TN,INACT,0.05999999865889549	CHEMBL104,TN,INACT,0.0	CHEMBL2171266,FP,INACT,0.9800000190734863	CHEMBL1957880,FN,ACT,0.27000001072883606	CHEMBL1775091,TN,INACT,0.12999999523162842	CHEMBL2315856,FN,ACT,0.2199999988079071	CHEMBL89625,TP,ACT,0.75	CHEMBL2040965,TN,INACT,0.0	CHEMBL49606,TP,ACT,1.0	CHEMBL375497,FP,INACT,0.6499999761581421	CHEMBL457145,FN,ACT,0.0	CHEMBL2283172,TP,ACT,1.0	CHEMBL54619,TP,ACT,1.0	CHEMBL16881,TP,ACT,1.0	CHEMBL526720,TP,ACT,1.0	CHEMBL3338726,TN,INACT,0.009999999776482582	CHEMBL18089,TP,ACT,0.8999999761581421	CHEMBL154373,FN,ACT,0.07000000029802322	CHEMBL54370,TP,ACT,1.0	CHEMBL1775104,FN,ACT,0.05000000074505806	CHEMBL512917,TP,ACT,0.7300000190734863	CHEMBL8079,TN,INACT,0.05999999865889549	CHEMBL131876,TN,INACT,0.009999999776482582	CHEMBL184686,TN,INACT,0.03999999910593033	CHEMBL29500,TP,ACT,0.9599999785423279	CHEMBL2333736,TP,ACT,0.8600000143051147	CHEMBL49056,TP,ACT,0.4300000071525574	CHEMBL2283150,TP,ACT,1.0	CHEMBL3315157,TN,INACT,0.14000000059604645	CHEMBL1689434,FN,ACT,0.11999999731779099	CHEMBL2391041,TN,INACT,0.0	CHEMBL1630230,TP,ACT,0.8199999928474426	CHEMBL3127458,TP,ACT,0.47999998927116394	CHEMBL2234964,FP,INACT,1.0	CHEMBL296384,TP,ACT,1.0	CHEMBL427356,FP,INACT,0.7599999904632568	CHEMBL470129,FP,INACT,0.5600000023841858	CHEMBL3359453,TP,ACT,0.47999998927116394	CHEMBL154253,TP,ACT,1.0	CHEMBL109486,TP,ACT,0.9599999785423279	CHEMBL3823208,TP,ACT,0.9800000190734863	CHEMBL254465,FP,INACT,0.7599999904632568	CHEMBL1316,FN,ACT,0.38999998569488525	CHEMBL441769,TP,ACT,1.0	CHEMBL2096829,TP,ACT,0.9700000286102295	CHEMBL338746,TN,INACT,0.009999999776482582	CHEMBL3309820,TP,ACT,1.0	CHEMBL224400,TP,ACT,0.9900000095367432	CHEMBL43664,TP,ACT,0.800000011920929	CHEMBL328837,TP,ACT,1.0	CHEMBL1243065,FP,INACT,0.4300000071525574	CHEMBL153497,TN,INACT,0.1599999964237213	CHEMBL284761,TP,ACT,1.0	CHEMBL387518,TN,INACT,0.009999999776482582	CHEMBL350424,FP,INACT,0.8999999761581421	CHEMBL43737,TP,ACT,0.9900000095367432	CHEMBL283660,TP,ACT,1.0	CHEMBL2299194,FP,INACT,0.6700000166893005	CHEMBL1288640,TP,ACT,0.9900000095367432	CHEMBL1766284,TP,ACT,0.9300000071525574	CHEMBL337251,TN,INACT,0.05999999865889549	CHEMBL563322,TP,ACT,0.9900000095367432	CHEMBL346288,TP,ACT,1.0	CHEMBL303688,FN,ACT,0.25999999046325684	CHEMBL1276001,FN,ACT,0.17000000178813934	CHEMBL3113232,TN,INACT,0.10999999940395355	CHEMBL460026,TN,INACT,0.029999999329447746	CHEMBL272862,TP,ACT,1.0	CHEMBL1240964,TN,INACT,0.09000000357627869	CHEMBL3265349,TN,INACT,0.11999999731779099	CHEMBL312822,TP,ACT,1.0	CHEMBL189387,FP,INACT,0.5600000023841858	CHEMBL3735874,TN,INACT,0.0	CHEMBL1643018,TN,INACT,0.03999999910593033	CHEMBL29766,TP,ACT,0.6100000143051147	CHEMBL433585,TP,ACT,0.8399999737739563	CHEMBL480462,TN,INACT,0.009999999776482582	CHEMBL325461,FP,INACT,0.5	CHEMBL322136,TP,ACT,1.0	CHEMBL3290201,TP,ACT,0.9900000095367432	CHEMBL173724,TP,ACT,0.9599999785423279	CHEMBL549393,TP,ACT,0.9300000071525574	CHEMBL570406,TN,INACT,0.09000000357627869	CHEMBL1770585,TN,INACT,0.029999999329447746	CHEMBL325787,TP,ACT,0.9700000286102295	CHEMBL416146,TP,ACT,0.9599999785423279	CHEMBL3290200,TP,ACT,0.9700000286102295	CHEMBL164985,TN,INACT,0.0	CHEMBL42709,TP,ACT,1.0	CHEMBL90988,TP,ACT,0.8500000238418579	CHEMBL3084325,TP,ACT,1.0	CHEMBL1770592,TN,INACT,0.05999999865889549	CHEMBL14735,TP,ACT,0.7599999904632568	CHEMBL1684392,TN,INACT,0.019999999552965164	CHEMBL97562,TP,ACT,0.7699999809265137	CHEMBL270060,FN,ACT,0.0	CHEMBL3265358,FN,ACT,0.009999999776482582	CHEMBL276739,FP,INACT,1.0	CHEMBL319244,FP,INACT,0.8100000023841858	CHEMBL1916967,TP,ACT,0.9900000095367432	CHEMBL3287567,TP,ACT,0.9700000286102295	CHEMBL2112399,TP,ACT,1.0	CHEMBL146005,FP,INACT,0.9800000190734863	CHEMBL2441046,TN,INACT,0.27000001072883606	CHEMBL15770,TP,ACT,1.0	CHEMBL3754046,TN,INACT,0.029999999329447746	CHEMBL175,TP,ACT,0.8999999761581421	CHEMBL3127459,FP,INACT,0.9900000095367432	CHEMBL3309824,FN,ACT,0.009999999776482582	CHEMBL106445,TP,ACT,0.7799999713897705	CHEMBL275838,FP,INACT,0.6000000238418579	CHEMBL285335,TP,ACT,1.0	CHEMBL414005,TP,ACT,0.9900000095367432	CHEMBL24415,TP,ACT,0.9900000095367432	CHEMBL49918,TP,ACT,0.9900000095367432	CHEMBL70588,TP,ACT,1.0	CHEMBL3822899,TP,ACT,0.9900000095367432	CHEMBL3823400,FP,INACT,0.9900000095367432	CHEMBL76084,TP,ACT,0.9800000190734863	CHEMBL210771,TN,INACT,0.009999999776482582	CHEMBL149791,TN,INACT,0.029999999329447746	CHEMBL321597,TP,ACT,0.9599999785423279	CHEMBL271962,TP,ACT,0.9100000262260437	CHEMBL3596289,TP,ACT,0.8799999952316284	CHEMBL2234962,FP,INACT,1.0	CHEMBL2333741,TP,ACT,0.8199999928474426	CHEMBL3809958,FN,ACT,0.1599999964237213	CHEMBL184389,TP,ACT,1.0	CHEMBL277116,TP,ACT,0.9900000095367432	CHEMBL279752,TP,ACT,1.0	CHEMBL491079,FN,ACT,0.18000000715255737	CHEMBL365473,TP,ACT,0.949999988079071	CHEMBL377499,FP,INACT,0.7599999904632568	CHEMBL1644912,TN,INACT,0.009999999776482582	CHEMBL124188,FN,ACT,0.07999999821186066	CHEMBL165,TP,ACT,0.4699999988079071	CHEMBL3824071,TP,ACT,0.9800000190734863	CHEMBL108975,TP,ACT,1.0	CHEMBL3322415,TP,ACT,0.9800000190734863	CHEMBL161481,TN,INACT,0.10999999940395355	CHEMBL104192,TN,INACT,0.0	CHEMBL494513,TN,INACT,0.0	CHEMBL41862,TN,INACT,0.009999999776482582	CHEMBL155675,TP,ACT,0.9700000286102295	CHEMBL358246,TP,ACT,0.9900000095367432	CHEMBL440798,TN,INACT,0.019999999552965164	CHEMBL2160141,FN,ACT,0.15000000596046448	CHEMBL257054,TP,ACT,1.0	CHEMBL3736140,TP,ACT,1.0	CHEMBL589812,FN,ACT,0.15000000596046448	CHEMBL281379,TP,ACT,1.0	CHEMBL338347,TP,ACT,1.0	CHEMBL323732,TP,ACT,0.9900000095367432	CHEMBL414437,TP,ACT,0.7699999809265137	CHEMBL351052,TN,INACT,0.019999999552965164	CHEMBL274457,TP,ACT,1.0	CHEMBL86023,TN,INACT,0.09000000357627869	CHEMBL323849,TN,INACT,0.009999999776482582	CHEMBL599,FN,ACT,0.03999999910593033	CHEMBL279268,TP,ACT,1.0	CHEMBL345018,TP,ACT,0.9900000095367432	CHEMBL213180,TN,INACT,0.23999999463558197	CHEMBL518935,TP,ACT,0.8700000047683716	CHEMBL196041,FN,ACT,0.05999999865889549	CHEMBL443791,TP,ACT,0.9800000190734863	CHEMBL3264520,FP,INACT,0.9200000166893005	CHEMBL237021,TP,ACT,0.9900000095367432	CHEMBL294067,TN,INACT,0.0	CHEMBL458187,FP,INACT,0.8799999952316284	CHEMBL2158360,TN,INACT,0.17000000178813934	CHEMBL204293,FP,INACT,0.6000000238418579	CHEMBL422147,FP,INACT,0.550000011920929	CHEMBL292607,FP,INACT,0.9900000095367432	CHEMBL139474,TN,INACT,0.0	CHEMBL2347675,TP,ACT,1.0	CHEMBL259842,TP,ACT,0.800000011920929	CHEMBL2417910,TN,INACT,0.0	CHEMBL416542,TN,INACT,0.14000000059604645	CHEMBL1667876,TP,ACT,0.9100000262260437	CHEMBL148100,TP,ACT,1.0	CHEMBL214814,TN,INACT,0.009999999776482582	CHEMBL127190,TP,ACT,0.9800000190734863	CHEMBL1242095,TP,ACT,0.46000000834465027	CHEMBL2334136,TP,ACT,0.9800000190734863	CHEMBL120842,TN,INACT,0.0	CHEMBL237208,TP,ACT,0.9700000286102295	CHEMBL3402600,TP,ACT,1.0	CHEMBL331278,FN,ACT,0.009999999776482582	CHEMBL497507,TP,ACT,0.9900000095367432	CHEMBL80405,FN,ACT,0.3400000035762787	CHEMBL158326,TN,INACT,0.3100000023841858	CHEMBL1163221,TN,INACT,0.17000000178813934	CHEMBL2087938,TN,INACT,0.0	CHEMBL1080407,TP,ACT,0.49000000953674316	CHEMBL315520,TP,ACT,1.0	CHEMBL140167,TP,ACT,1.0	CHEMBL1078683,FP,INACT,0.8700000047683716	CHEMBL117852,TP,ACT,1.0	CHEMBL1630227,FN,ACT,0.15000000596046448	CHEMBL519521,TN,INACT,0.029999999329447746	CHEMBL326362,TP,ACT,0.9700000286102295	CHEMBL84837,TN,INACT,0.0	CHEMBL224624,TP,ACT,0.8500000238418579	CHEMBL95380,FN,ACT,0.33000001311302185	CHEMBL172364,TN,INACT,0.10000000149011612	CHEMBL463453,TN,INACT,0.05000000074505806	CHEMBL324048,TP,ACT,1.0	CHEMBL3736221,TN,INACT,0.0	CHEMBL1630254,TP,ACT,0.9900000095367432	CHEMBL3736077,TN,INACT,0.009999999776482582	CHEMBL188071,TP,ACT,0.9800000190734863	CHEMBL1290433,FN,ACT,0.2199999988079071	CHEMBL1290459,TP,ACT,0.9200000166893005	CHEMBL365883,TP,ACT,1.0	CHEMBL1242275,TP,ACT,0.5199999809265137	CHEMBL3309957,TN,INACT,0.0	CHEMBL2408966,TN,INACT,0.07999999821186066	CHEMBL347720,TP,ACT,1.0	CHEMBL174990,TP,ACT,0.9800000190734863	CHEMBL276800,TP,ACT,0.9900000095367432	CHEMBL42011,TP,ACT,0.9599999785423279	CHEMBL3113239,TP,ACT,0.9900000095367432	CHEMBL469529,TN,INACT,0.029999999329447746	CHEMBL340573,TP,ACT,0.9900000095367432	CHEMBL153334,TN,INACT,0.0	CHEMBL160076,TN,INACT,0.029999999329447746	CHEMBL3331466,FN,ACT,0.019999999552965164	CHEMBL2391196,TN,INACT,0.009999999776482582	CHEMBL29620,TP,ACT,1.0	CHEMBL3264691,TP,ACT,0.9900000095367432	CHEMBL2315018,TP,ACT,0.9900000095367432	CHEMBL405071,TP,ACT,1.0	CHEMBL386249,TN,INACT,0.0	CHEMBL43553,TP,ACT,0.9900000095367432	CHEMBL229790,FP,INACT,0.8899999856948853	CHEMBL3601280,TN,INACT,0.0	CHEMBL3357954,TN,INACT,0.0	CHEMBL18020,TP,ACT,0.47999998927116394	CHEMBL470938,FN,ACT,0.05000000074505806	CHEMBL3810231,TN,INACT,0.029999999329447746	CHEMBL2391054,FN,ACT,0.0	CHEMBL2334134,TP,ACT,0.6600000262260437	CHEMBL2023862,TP,ACT,0.9599999785423279	CHEMBL398087,TP,ACT,0.8299999833106995	CHEMBL307233,TP,ACT,0.949999988079071	CHEMBL2315017,TP,ACT,0.6000000238418579	CHEMBL14767,TP,ACT,1.0	CHEMBL275835,TN,INACT,0.07000000029802322	CHEMBL3408783,FP,INACT,0.9399999976158142	CHEMBL2299201,TN,INACT,0.3700000047683716	CHEMBL70921,TP,ACT,1.0	CHEMBL47147,TP,ACT,0.9800000190734863	CHEMBL126244,TP,ACT,0.8600000143051147	CHEMBL2347669,TP,ACT,0.49000000953674316	CHEMBL43317,TP,ACT,1.0	CHEMBL26065,TN,INACT,0.009999999776482582	CHEMBL2333753,TP,ACT,0.9399999976158142	CHEMBL389184,TN,INACT,0.0	CHEMBL16733,TP,ACT,0.9399999976158142	CHEMBL157720,TP,ACT,1.0	CHEMBL416363,TP,ACT,1.0	CHEMBL3734826,TN,INACT,0.0	CHEMBL271104,TP,ACT,1.0	CHEMBL127203,TN,INACT,0.019999999552965164	CHEMBL2380876,TN,INACT,0.07999999821186066	CHEMBL2011171,TN,INACT,0.0	CHEMBL317332,TP,ACT,1.0	CHEMBL2235865,TP,ACT,0.7799999713897705	CHEMBL1084,TP,ACT,1.0	CHEMBL270723,TP,ACT,1.0	CHEMBL502286,TP,ACT,1.0	CHEMBL270351,TP,ACT,0.4000000059604645	CHEMBL865,TP,ACT,0.8500000238418579	CHEMBL2096835,TP,ACT,1.0	CHEMBL3234235,FN,ACT,0.07000000029802322	CHEMBL419777,FP,INACT,1.0	CHEMBL2160139,TP,ACT,0.9700000286102295	CHEMBL558728,TP,ACT,0.7300000190734863	CHEMBL186634,TP,ACT,0.6800000071525574	CHEMBL2023858,FN,ACT,0.14000000059604645	CHEMBL101893,TN,INACT,0.019999999552965164	CHEMBL3809154,TP,ACT,0.8799999952316284	CHEMBL3785696,TN,INACT,0.18000000715255737	CHEMBL1669028,TN,INACT,0.3700000047683716	CHEMBL2040989,TN,INACT,0.07999999821186066	CHEMBL1086611,TN,INACT,0.30000001192092896	CHEMBL1956390,FP,INACT,0.5600000023841858	CHEMBL215295,TN,INACT,0.009999999776482582	CHEMBL406527,TP,ACT,1.0	CHEMBL502285,TP,ACT,1.0	

