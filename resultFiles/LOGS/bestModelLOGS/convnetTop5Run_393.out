ImageNetInceptionV2 CHEMBL1741186 adam 0.001 5 0 0 0.8 False True
Number of active compounds :	571
Number of inactive compounds :	571
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1741186_adam_0.001_5_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1741186_adam_0.001_5_0.8/
---------------------------------
Training samples: 658
Validation samples: 206
--
Training Step: 1  | time: 135.237s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/658
[A[ATraining Step: 2  | total loss: [1m[32m0.64839[0m[0m | time: 226.398s
[2K
| Adam | epoch: 001 | loss: 0.64839 - acc: 0.4781 -- iter: 064/658
[A[ATraining Step: 3  | total loss: [1m[32m0.65630[0m[0m | time: 253.533s
[2K
| Adam | epoch: 001 | loss: 0.65630 - acc: 0.6239 -- iter: 096/658
[A[ATraining Step: 4  | total loss: [1m[32m0.79004[0m[0m | time: 277.142s
[2K
| Adam | epoch: 001 | loss: 0.79004 - acc: 0.5778 -- iter: 128/658
[A[ATraining Step: 5  | total loss: [1m[32m0.74843[0m[0m | time: 295.458s
[2K
| Adam | epoch: 001 | loss: 0.74843 - acc: 0.6321 -- iter: 160/658
[A[ATraining Step: 6  | total loss: [1m[32m0.60458[0m[0m | time: 402.576s
[2K
| Adam | epoch: 001 | loss: 0.60458 - acc: 0.6878 -- iter: 192/658
[A[ATraining Step: 7  | total loss: [1m[32m0.74123[0m[0m | time: 511.699s
[2K
| Adam | epoch: 001 | loss: 0.74123 - acc: 0.5939 -- iter: 224/658
[A[ATraining Step: 8  | total loss: [1m[32m0.63279[0m[0m | time: 572.956s
[2K
| Adam | epoch: 001 | loss: 0.63279 - acc: 0.6465 -- iter: 256/658
[A[ATraining Step: 9  | total loss: [1m[32m0.60557[0m[0m | time: 648.323s
[2K
| Adam | epoch: 001 | loss: 0.60557 - acc: 0.7179 -- iter: 288/658
[A[ATraining Step: 10  | total loss: [1m[32m0.62597[0m[0m | time: 718.642s
[2K
| Adam | epoch: 001 | loss: 0.62597 - acc: 0.6558 -- iter: 320/658
[A[ATraining Step: 11  | total loss: [1m[32m0.64749[0m[0m | time: 731.526s
[2K
| Adam | epoch: 001 | loss: 0.64749 - acc: 0.5968 -- iter: 352/658
[A[ATraining Step: 12  | total loss: [1m[32m0.56293[0m[0m | time: 742.415s
[2K
| Adam | epoch: 001 | loss: 0.56293 - acc: 0.6939 -- iter: 384/658
[A[ATraining Step: 13  | total loss: [1m[32m0.58635[0m[0m | time: 755.262s
[2K
| Adam | epoch: 001 | loss: 0.58635 - acc: 0.7045 -- iter: 416/658
[A[ATraining Step: 14  | total loss: [1m[32m0.62449[0m[0m | time: 776.421s
[2K
| Adam | epoch: 001 | loss: 0.62449 - acc: 0.6720 -- iter: 448/658
[A[ATraining Step: 15  | total loss: [1m[32m0.58037[0m[0m | time: 797.691s
[2K
| Adam | epoch: 001 | loss: 0.58037 - acc: 0.7270 -- iter: 480/658
[A[ATraining Step: 16  | total loss: [1m[32m0.58335[0m[0m | time: 812.992s
[2K
| Adam | epoch: 001 | loss: 0.58335 - acc: 0.7122 -- iter: 512/658
[A[ATraining Step: 17  | total loss: [1m[32m0.58447[0m[0m | time: 829.229s
[2K
| Adam | epoch: 001 | loss: 0.58447 - acc: 0.7258 -- iter: 544/658
[A[ATraining Step: 18  | total loss: [1m[32m0.56429[0m[0m | time: 843.939s
[2K
| Adam | epoch: 001 | loss: 0.56429 - acc: 0.7017 -- iter: 576/658
[A[ATraining Step: 19  | total loss: [1m[32m0.60413[0m[0m | time: 854.431s
[2K
| Adam | epoch: 001 | loss: 0.60413 - acc: 0.6657 -- iter: 608/658
[A[ATraining Step: 20  | total loss: [1m[32m0.56416[0m[0m | time: 879.014s
[2K
| Adam | epoch: 001 | loss: 0.56416 - acc: 0.7129 -- iter: 640/658
[A[ATraining Step: 21  | total loss: [1m[32m0.53079[0m[0m | time: 919.821s
[2K
| Adam | epoch: 001 | loss: 0.53079 - acc: 0.7244 | val_loss: 2.83108 - val_acc: 0.5243 -- iter: 658/658
--
Training Step: 22  | total loss: [1m[32m0.48170[0m[0m | time: 8.379s
[2K
| Adam | epoch: 002 | loss: 0.48170 - acc: 0.7904 -- iter: 032/658
[A[ATraining Step: 23  | total loss: [1m[32m0.42015[0m[0m | time: 30.048s
[2K
| Adam | epoch: 002 | loss: 0.42015 - acc: 0.8351 -- iter: 064/658
[A[ATraining Step: 24  | total loss: [1m[32m0.45175[0m[0m | time: 45.844s
[2K
| Adam | epoch: 002 | loss: 0.45175 - acc: 0.7936 -- iter: 096/658
[A[ATraining Step: 25  | total loss: [1m[32m0.50762[0m[0m | time: 66.027s
[2K
| Adam | epoch: 002 | loss: 0.50762 - acc: 0.7476 -- iter: 128/658
[A[ATraining Step: 26  | total loss: [1m[32m0.51883[0m[0m | time: 87.119s
[2K
| Adam | epoch: 002 | loss: 0.51883 - acc: 0.7565 -- iter: 160/658
[A[ATraining Step: 27  | total loss: [1m[32m0.51120[0m[0m | time: 109.447s
[2K
| Adam | epoch: 002 | loss: 0.51120 - acc: 0.7468 -- iter: 192/658
[A[ATraining Step: 28  | total loss: [1m[32m0.53238[0m[0m | time: 120.348s
[2K
| Adam | epoch: 002 | loss: 0.53238 - acc: 0.7320 -- iter: 224/658
[A[ATraining Step: 29  | total loss: [1m[32m0.54176[0m[0m | time: 132.280s
[2K
| Adam | epoch: 002 | loss: 0.54176 - acc: 0.7060 -- iter: 256/658
[A[ATraining Step: 30  | total loss: [1m[32m0.51098[0m[0m | time: 151.992s
[2K
| Adam | epoch: 002 | loss: 0.51098 - acc: 0.7312 -- iter: 288/658
[A[ATraining Step: 31  | total loss: [1m[32m0.50269[0m[0m | time: 164.495s
[2K
| Adam | epoch: 002 | loss: 0.50269 - acc: 0.7283 -- iter: 320/658
[A[ATraining Step: 32  | total loss: [1m[32m0.51058[0m[0m | time: 177.188s
[2K
| Adam | epoch: 002 | loss: 0.51058 - acc: 0.7332 -- iter: 352/658
[A[ATraining Step: 33  | total loss: [1m[32m0.48671[0m[0m | time: 190.061s
[2K
| Adam | epoch: 002 | loss: 0.48671 - acc: 0.7437 -- iter: 384/658
[A[ATraining Step: 34  | total loss: [1m[32m0.46564[0m[0m | time: 204.676s
[2K
| Adam | epoch: 002 | loss: 0.46564 - acc: 0.7652 -- iter: 416/658
[A[ATraining Step: 35  | total loss: [1m[32m0.42235[0m[0m | time: 213.234s
[2K
| Adam | epoch: 002 | loss: 0.42235 - acc: 0.8012 -- iter: 448/658
[A[ATraining Step: 36  | total loss: [1m[32m0.39898[0m[0m | time: 221.690s
[2K
| Adam | epoch: 002 | loss: 0.39898 - acc: 0.8035 -- iter: 480/658
[A[ATraining Step: 37  | total loss: [1m[32m0.37094[0m[0m | time: 232.791s
[2K
| Adam | epoch: 002 | loss: 0.37094 - acc: 0.8178 -- iter: 512/658
[A[ATraining Step: 38  | total loss: [1m[32m0.39306[0m[0m | time: 245.815s
[2K
| Adam | epoch: 002 | loss: 0.39306 - acc: 0.8107 -- iter: 544/658
[A[ATraining Step: 39  | total loss: [1m[32m0.39685[0m[0m | time: 258.349s
[2K
| Adam | epoch: 002 | loss: 0.39685 - acc: 0.7991 -- iter: 576/658
[A[ATraining Step: 40  | total loss: [1m[32m0.35412[0m[0m | time: 285.122s
[2K
| Adam | epoch: 002 | loss: 0.35412 - acc: 0.8250 -- iter: 608/658
[A[ATraining Step: 41  | total loss: [1m[32m0.37016[0m[0m | time: 298.549s
[2K
| Adam | epoch: 002 | loss: 0.37016 - acc: 0.8285 -- iter: 640/658
[A[ATraining Step: 42  | total loss: [1m[32m0.35912[0m[0m | time: 319.388s
[2K
| Adam | epoch: 002 | loss: 0.35912 - acc: 0.8425 | val_loss: 3.26159 - val_acc: 0.5243 -- iter: 658/658
--
Training Step: 43  | total loss: [1m[32m0.39931[0m[0m | time: 8.090s
[2K
| Adam | epoch: 003 | loss: 0.39931 - acc: 0.8372 -- iter: 032/658
[A[ATraining Step: 44  | total loss: [1m[32m0.40745[0m[0m | time: 15.969s
[2K
| Adam | epoch: 003 | loss: 0.40745 - acc: 0.8461 -- iter: 064/658
[A[ATraining Step: 45  | total loss: [1m[32m0.36754[0m[0m | time: 37.091s
[2K
| Adam | epoch: 003 | loss: 0.36754 - acc: 0.8628 -- iter: 096/658
[A[ATraining Step: 46  | total loss: [1m[32m0.35757[0m[0m | time: 46.994s
[2K
| Adam | epoch: 003 | loss: 0.35757 - acc: 0.8596 -- iter: 128/658
[A[ATraining Step: 47  | total loss: [1m[32m0.37214[0m[0m | time: 55.559s
[2K
| Adam | epoch: 003 | loss: 0.37214 - acc: 0.8570 -- iter: 160/658
[A[ATraining Step: 48  | total loss: [1m[32m0.38851[0m[0m | time: 64.075s
[2K
| Adam | epoch: 003 | loss: 0.38851 - acc: 0.8449 -- iter: 192/658
[A[ATraining Step: 49  | total loss: [1m[32m0.37784[0m[0m | time: 108.046s
[2K
| Adam | epoch: 003 | loss: 0.37784 - acc: 0.8496 -- iter: 224/658
[A[ATraining Step: 50  | total loss: [1m[32m0.40831[0m[0m | time: 132.801s
[2K
| Adam | epoch: 003 | loss: 0.40831 - acc: 0.8245 -- iter: 256/658
[A[ATraining Step: 51  | total loss: [1m[32m0.41118[0m[0m | time: 146.068s
[2K
| Adam | epoch: 003 | loss: 0.41118 - acc: 0.8226 -- iter: 288/658
[A[ATraining Step: 52  | total loss: [1m[32m0.43085[0m[0m | time: 158.554s
[2K
| Adam | epoch: 003 | loss: 0.43085 - acc: 0.8071 -- iter: 320/658
[A[ATraining Step: 53  | total loss: [1m[32m0.40690[0m[0m | time: 172.829s
[2K
| Adam | epoch: 003 | loss: 0.40690 - acc: 0.8263 -- iter: 352/658
[A[ATraining Step: 54  | total loss: [1m[32m0.41555[0m[0m | time: 182.061s
[2K
| Adam | epoch: 003 | loss: 0.41555 - acc: 0.8198 -- iter: 384/658
[A[ATraining Step: 55  | total loss: [1m[32m0.40567[0m[0m | time: 190.903s
[2K
| Adam | epoch: 003 | loss: 0.40567 - acc: 0.8232 -- iter: 416/658
[A[ATraining Step: 56  | total loss: [1m[32m0.41878[0m[0m | time: 199.280s
[2K
| Adam | epoch: 003 | loss: 0.41878 - acc: 0.8261 -- iter: 448/658
[A[ATraining Step: 57  | total loss: [1m[32m0.39953[0m[0m | time: 207.885s
[2K
| Adam | epoch: 003 | loss: 0.39953 - acc: 0.8329 -- iter: 480/658
[A[ATraining Step: 58  | total loss: [1m[32m0.38704[0m[0m | time: 219.619s
[2K
| Adam | epoch: 003 | loss: 0.38704 - acc: 0.8343 -- iter: 512/658
[A[ATraining Step: 59  | total loss: [1m[32m0.36917[0m[0m | time: 227.873s
[2K
| Adam | epoch: 003 | loss: 0.36917 - acc: 0.8398 -- iter: 544/658
[A[ATraining Step: 60  | total loss: [1m[32m0.38477[0m[0m | time: 236.103s
[2K
| Adam | epoch: 003 | loss: 0.38477 - acc: 0.8321 -- iter: 576/658
[A[ATraining Step: 61  | total loss: [1m[32m0.37411[0m[0m | time: 244.290s
[2K
| Adam | epoch: 003 | loss: 0.37411 - acc: 0.8377 -- iter: 608/658
[A[ATraining Step: 62  | total loss: [1m[32m0.36407[0m[0m | time: 252.630s
[2K
| Adam | epoch: 003 | loss: 0.36407 - acc: 0.8384 -- iter: 640/658
[A[ATraining Step: 63  | total loss: [1m[32m0.36638[0m[0m | time: 270.411s
[2K
| Adam | epoch: 003 | loss: 0.36638 - acc: 0.8351 | val_loss: 3.13887 - val_acc: 0.6214 -- iter: 658/658
--
Training Step: 64  | total loss: [1m[32m0.35239[0m[0m | time: 7.997s
[2K
| Adam | epoch: 004 | loss: 0.35239 - acc: 0.8440 -- iter: 032/658
[A[ATraining Step: 65  | total loss: [1m[32m0.41197[0m[0m | time: 13.109s
[2K
| Adam | epoch: 004 | loss: 0.41197 - acc: 0.8286 -- iter: 064/658
[A[ATraining Step: 66  | total loss: [1m[32m0.42636[0m[0m | time: 18.350s
[2K
| Adam | epoch: 004 | loss: 0.42636 - acc: 0.8089 -- iter: 096/658
[A[ATraining Step: 67  | total loss: [1m[32m0.42073[0m[0m | time: 26.276s
[2K
| Adam | epoch: 004 | loss: 0.42073 - acc: 0.8118 -- iter: 128/658
[A[ATraining Step: 68  | total loss: [1m[32m0.40398[0m[0m | time: 34.556s
[2K
| Adam | epoch: 004 | loss: 0.40398 - acc: 0.8156 -- iter: 160/658
[A[ATraining Step: 69  | total loss: [1m[32m0.41787[0m[0m | time: 42.588s
[2K
| Adam | epoch: 004 | loss: 0.41787 - acc: 0.8189 -- iter: 192/658
[A[ATraining Step: 70  | total loss: [1m[32m0.39886[0m[0m | time: 50.624s
[2K
| Adam | epoch: 004 | loss: 0.39886 - acc: 0.8290 -- iter: 224/658
[A[ATraining Step: 71  | total loss: [1m[32m0.39081[0m[0m | time: 58.764s
[2K
| Adam | epoch: 004 | loss: 0.39081 - acc: 0.8307 -- iter: 256/658
[A[ATraining Step: 72  | total loss: [1m[32m0.37913[0m[0m | time: 67.114s
[2K
| Adam | epoch: 004 | loss: 0.37913 - acc: 0.8356 -- iter: 288/658
[A[ATraining Step: 73  | total loss: [1m[32m0.39891[0m[0m | time: 75.116s
[2K
| Adam | epoch: 004 | loss: 0.39891 - acc: 0.8331 -- iter: 320/658
[A[ATraining Step: 74  | total loss: [1m[32m0.43345[0m[0m | time: 83.260s
[2K
| Adam | epoch: 004 | loss: 0.43345 - acc: 0.8308 -- iter: 352/658
[A[ATraining Step: 75  | total loss: [1m[32m0.44406[0m[0m | time: 91.553s
[2K
| Adam | epoch: 004 | loss: 0.44406 - acc: 0.8221 -- iter: 384/658
[A[ATraining Step: 76  | total loss: [1m[32m0.43948[0m[0m | time: 99.607s
[2K
| Adam | epoch: 004 | loss: 0.43948 - acc: 0.8143 -- iter: 416/658
[A[ATraining Step: 77  | total loss: [1m[32m0.43239[0m[0m | time: 107.781s
[2K
| Adam | epoch: 004 | loss: 0.43239 - acc: 0.8174 -- iter: 448/658
[A[ATraining Step: 78  | total loss: [1m[32m0.43435[0m[0m | time: 115.708s
[2K
| Adam | epoch: 004 | loss: 0.43435 - acc: 0.8104 -- iter: 480/658
[A[ATraining Step: 79  | total loss: [1m[32m0.43533[0m[0m | time: 123.830s
[2K
| Adam | epoch: 004 | loss: 0.43533 - acc: 0.8138 -- iter: 512/658
[A[ATraining Step: 80  | total loss: [1m[32m0.42972[0m[0m | time: 131.931s
[2K
| Adam | epoch: 004 | loss: 0.42972 - acc: 0.8201 -- iter: 544/658
[A[ATraining Step: 81  | total loss: [1m[32m0.41353[0m[0m | time: 140.125s
[2K
| Adam | epoch: 004 | loss: 0.41353 - acc: 0.8288 -- iter: 576/658
[A[ATraining Step: 82  | total loss: [1m[32m0.41068[0m[0m | time: 148.299s
[2K
| Adam | epoch: 004 | loss: 0.41068 - acc: 0.8272 -- iter: 608/658
[A[ATraining Step: 83  | total loss: [1m[32m0.39956[0m[0m | time: 156.583s
[2K
| Adam | epoch: 004 | loss: 0.39956 - acc: 0.8320 -- iter: 640/658
[A[ATraining Step: 84  | total loss: [1m[32m0.38274[0m[0m | time: 174.245s
[2K
| Adam | epoch: 004 | loss: 0.38274 - acc: 0.8394 | val_loss: 1.32864 - val_acc: 0.5243 -- iter: 658/658
--
Training Step: 85  | total loss: [1m[32m0.37719[0m[0m | time: 8.017s
[2K
| Adam | epoch: 005 | loss: 0.37719 - acc: 0.8398 -- iter: 032/658
[A[ATraining Step: 86  | total loss: [1m[32m0.36969[0m[0m | time: 16.069s
[2K
| Adam | epoch: 005 | loss: 0.36969 - acc: 0.8402 -- iter: 064/658
[A[ATraining Step: 87  | total loss: [1m[32m0.36894[0m[0m | time: 21.123s
[2K
| Adam | epoch: 005 | loss: 0.36894 - acc: 0.8406 -- iter: 096/658
[A[ATraining Step: 88  | total loss: [1m[32m0.34734[0m[0m | time: 26.188s
[2K
| Adam | epoch: 005 | loss: 0.34734 - acc: 0.8565 -- iter: 128/658
[A[ATraining Step: 89  | total loss: [1m[32m0.32585[0m[0m | time: 34.132s
[2K
| Adam | epoch: 005 | loss: 0.32585 - acc: 0.8709 -- iter: 160/658
[A[ATraining Step: 90  | total loss: [1m[32m0.31990[0m[0m | time: 42.099s
[2K
| Adam | epoch: 005 | loss: 0.31990 - acc: 0.8713 -- iter: 192/658
[A[ATraining Step: 91  | total loss: [1m[32m0.31383[0m[0m | time: 50.086s
[2K
| Adam | epoch: 005 | loss: 0.31383 - acc: 0.8716 -- iter: 224/658
[A[ATraining Step: 92  | total loss: [1m[32m0.30658[0m[0m | time: 58.170s
[2K
| Adam | epoch: 005 | loss: 0.30658 - acc: 0.8751 -- iter: 256/658
[A[ATraining Step: 93  | total loss: [1m[32m0.29738[0m[0m | time: 66.317s
[2K
| Adam | epoch: 005 | loss: 0.29738 - acc: 0.8782 -- iter: 288/658
[A[ATraining Step: 94  | total loss: [1m[32m0.31555[0m[0m | time: 74.427s
[2K
| Adam | epoch: 005 | loss: 0.31555 - acc: 0.8654 -- iter: 320/658
[A[ATraining Step: 95  | total loss: [1m[32m0.31073[0m[0m | time: 82.523s
[2K
| Adam | epoch: 005 | loss: 0.31073 - acc: 0.8664 -- iter: 352/658
[A[ATraining Step: 96  | total loss: [1m[32m0.28912[0m[0m | time: 90.554s
[2K
| Adam | epoch: 005 | loss: 0.28912 - acc: 0.8797 -- iter: 384/658
[A[ATraining Step: 97  | total loss: [1m[32m0.29461[0m[0m | time: 98.589s
[2K
| Adam | epoch: 005 | loss: 0.29461 - acc: 0.8824 -- iter: 416/658
[A[ATraining Step: 98  | total loss: [1m[32m0.29603[0m[0m | time: 106.717s
[2K
| Adam | epoch: 005 | loss: 0.29603 - acc: 0.8754 -- iter: 448/658
[A[ATraining Step: 99  | total loss: [1m[32m0.29414[0m[0m | time: 114.704s
[2K
| Adam | epoch: 005 | loss: 0.29414 - acc: 0.8722 -- iter: 480/658
[A[ATraining Step: 100  | total loss: [1m[32m0.28426[0m[0m | time: 122.706s
[2K
| Adam | epoch: 005 | loss: 0.28426 - acc: 0.8788 -- iter: 512/658
[A[ATraining Step: 101  | total loss: [1m[32m0.27036[0m[0m | time: 130.879s
[2K
| Adam | epoch: 005 | loss: 0.27036 - acc: 0.8878 -- iter: 544/658
[A[ATraining Step: 102  | total loss: [1m[32m0.26222[0m[0m | time: 139.064s
[2K
| Adam | epoch: 005 | loss: 0.26222 - acc: 0.8927 -- iter: 576/658
[A[ATraining Step: 103  | total loss: [1m[32m0.25927[0m[0m | time: 147.227s
[2K
| Adam | epoch: 005 | loss: 0.25927 - acc: 0.9003 -- iter: 608/658
[A[ATraining Step: 104  | total loss: [1m[32m0.26339[0m[0m | time: 155.436s
[2K
| Adam | epoch: 005 | loss: 0.26339 - acc: 0.8978 -- iter: 640/658
[A[ATraining Step: 105  | total loss: [1m[32m0.24723[0m[0m | time: 173.035s
[2K
| Adam | epoch: 005 | loss: 0.24723 - acc: 0.9080 | val_loss: 0.43669 - val_acc: 0.8447 -- iter: 658/658
--
Validation AUC:0.9143990929705215
Validation AUPRC:0.9025768271332368
Test AUC:0.9178213091256571
Test AUPRC:0.8877630977875061
BestTestF1Score	0.84	0.71	0.85	0.78	0.91	83	23	92	8	0.17
BestTestMCCScore	0.84	0.71	0.85	0.78	0.91	83	23	92	8	0.17
BestTestAccuracyScore	0.84	0.71	0.85	0.78	0.91	83	23	92	8	0.17
BestValidationF1Score	0.88	0.77	0.88	0.89	0.87	85	11	97	13	0.17
BestValidationMCC	0.88	0.77	0.88	0.89	0.87	85	11	97	13	0.17
BestValidationAccuracy	0.88	0.77	0.88	0.89	0.87	85	11	97	13	0.17
TestPredictions (Threshold:0.17)
CHEMBL2381196,FP,INACT,0.2199999988079071	CHEMBL1304227,TN,INACT,0.05000000074505806	CHEMBL3189499,TN,INACT,0.009999999776482582	CHEMBL590586,FP,INACT,0.36000001430511475	CHEMBL2204687,TN,INACT,0.029999999329447746	CHEMBL2381204,TN,INACT,0.05000000074505806	CHEMBL3105801,TP,ACT,0.8399999737739563	CHEMBL237822,TN,INACT,0.0	CHEMBL3793822,TP,ACT,1.0	CHEMBL1465490,FP,INACT,0.5799999833106995	CHEMBL1536177,TN,INACT,0.03999999910593033	CHEMBL3105812,FN,ACT,0.019999999552965164	CHEMBL1613213,TN,INACT,0.05000000074505806	CHEMBL3617358,FP,INACT,0.2199999988079071	CHEMBL562250,TN,INACT,0.0	CHEMBL1393976,TN,INACT,0.009999999776482582	CHEMBL2070852,TN,INACT,0.05999999865889549	CHEMBL3218918,FN,ACT,0.0	CHEMBL3581535,TP,ACT,0.9300000071525574	CHEMBL39176,TN,INACT,0.009999999776482582	CHEMBL3598062,TP,ACT,0.7900000214576721	CHEMBL1560367,FP,INACT,0.3799999952316284	CHEMBL3799613,TP,ACT,0.6700000166893005	CHEMBL2381198,FP,INACT,0.20999999344348907	CHEMBL3317843,TP,ACT,0.4099999964237213	CHEMBL3361044,TP,ACT,0.9700000286102295	CHEMBL3581531,TP,ACT,0.8899999856948853	CHEMBL1489063,TN,INACT,0.09000000357627869	CHEMBL194805,TN,INACT,0.0	CHEMBL3317839,TP,ACT,0.4300000071525574	CHEMBL3105800,TP,ACT,0.7699999809265137	CHEMBL3596614,TP,ACT,0.9399999976158142	CHEMBL3259995,TP,ACT,0.1899999976158142	CHEMBL2326703,FN,ACT,0.12999999523162842	CHEMBL3623111,TN,INACT,0.09000000357627869	CHEMBL3094370,TP,ACT,0.9900000095367432	CHEMBL9352,TN,INACT,0.009999999776482582	CHEMBL3361054,TP,ACT,0.9200000166893005	CHEMBL1467399,TN,INACT,0.019999999552965164	CHEMBL3598049,TP,ACT,0.9800000190734863	CHEMBL3598070,TP,ACT,0.949999988079071	CHEMBL3317824,TP,ACT,0.699999988079071	CHEMBL3596627,TP,ACT,0.800000011920929	CHEMBL325172,FP,INACT,1.0	CHEMBL3218921,FN,ACT,0.14000000059604645	CHEMBL3781062,FP,INACT,0.9399999976158142	CHEMBL3105686,TP,ACT,0.9900000095367432	CHEMBL2070862,TN,INACT,0.05000000074505806	CHEMBL1390963,TN,INACT,0.019999999552965164	CHEMBL3094384,TP,ACT,0.9300000071525574	CHEMBL3208784,FP,INACT,0.3799999952316284	CHEMBL3609393,TP,ACT,0.9599999785423279	CHEMBL119869,TN,INACT,0.07000000029802322	CHEMBL3094367,TP,ACT,1.0	CHEMBL1392188,FP,INACT,0.23999999463558197	CHEMBL379252,TN,INACT,0.009999999776482582	CHEMBL2204695,TN,INACT,0.0	CHEMBL3759448,TN,INACT,0.009999999776482582	CHEMBL2441819,TN,INACT,0.1599999964237213	CHEMBL3617304,TP,ACT,0.44999998807907104	CHEMBL1751,TP,ACT,0.550000011920929	CHEMBL1410824,TN,INACT,0.009999999776482582	CHEMBL3581540,TP,ACT,0.8700000047683716	CHEMBL3313932,TP,ACT,0.9800000190734863	CHEMBL418971,FP,INACT,0.5199999809265137	CHEMBL2070870,TN,INACT,0.05999999865889549	CHEMBL3798862,TP,ACT,0.7699999809265137	CHEMBL3609415,TP,ACT,1.0	CHEMBL1453259,TN,INACT,0.029999999329447746	CHEMBL3314023,TP,ACT,0.5699999928474426	CHEMBL3581542,TP,ACT,0.949999988079071	CHEMBL1526851,TN,INACT,0.009999999776482582	CHEMBL3234274,TN,INACT,0.0	CHEMBL3325742,TP,ACT,0.17000000178813934	CHEMBL3598079,TP,ACT,0.9900000095367432	CHEMBL3263244,TN,INACT,0.10000000149011612	CHEMBL3361043,TP,ACT,0.9900000095367432	CHEMBL382698,TN,INACT,0.009999999776482582	CHEMBL1572403,TN,INACT,0.019999999552965164	CHEMBL3596633,TP,ACT,0.8199999928474426	CHEMBL1439181,TN,INACT,0.05000000074505806	CHEMBL3596612,TP,ACT,0.9900000095367432	CHEMBL3234242,TP,ACT,0.8100000023841858	CHEMBL1329271,TN,INACT,0.009999999776482582	CHEMBL3402135,TP,ACT,0.9900000095367432	CHEMBL3105669,TP,ACT,1.0	CHEMBL2381202,TN,INACT,0.09000000357627869	CHEMBL1308226,TN,INACT,0.029999999329447746	CHEMBL150924,TN,INACT,0.009999999776482582	CHEMBL236495,TN,INACT,0.009999999776482582	CHEMBL1429596,TN,INACT,0.11999999731779099	CHEMBL1299357,TN,INACT,0.05999999865889549	CHEMBL1086742,TN,INACT,0.07000000029802322	CHEMBL3598077,TP,ACT,0.9700000286102295	CHEMBL3745944,FP,INACT,0.949999988079071	CHEMBL3105799,TP,ACT,0.75	CHEMBL3634609,TP,ACT,0.4000000059604645	CHEMBL3775807,TP,ACT,0.1899999976158142	CHEMBL2070860,TN,INACT,0.019999999552965164	CHEMBL1765175,TP,ACT,0.9399999976158142	CHEMBL218591,TN,INACT,0.07999999821186066	CHEMBL3402134,TP,ACT,0.6299999952316284	CHEMBL1271259,FP,INACT,0.20999999344348907	CHEMBL3775781,FN,ACT,0.10000000149011612	CHEMBL2348886,TN,INACT,0.09000000357627869	CHEMBL1533166,TN,INACT,0.019999999552965164	CHEMBL2070838,TN,INACT,0.009999999776482582	CHEMBL237455,TN,INACT,0.0	CHEMBL3609403,TP,ACT,0.9900000095367432	CHEMBL487611,TN,INACT,0.009999999776482582	CHEMBL3746619,FP,INACT,0.2199999988079071	CHEMBL3105806,TP,ACT,0.9300000071525574	CHEMBL3317826,FN,ACT,0.09000000357627869	CHEMBL3094380,TP,ACT,0.9900000095367432	CHEMBL3361039,TP,ACT,0.9900000095367432	CHEMBL491820,TN,INACT,0.009999999776482582	CHEMBL237611,TN,INACT,0.0	CHEMBL3208992,TN,INACT,0.009999999776482582	CHEMBL981,TN,INACT,0.009999999776482582	CHEMBL6,TN,INACT,0.029999999329447746	CHEMBL1424468,TN,INACT,0.019999999552965164	CHEMBL3827152,TN,INACT,0.05999999865889549	CHEMBL3623100,TN,INACT,0.09000000357627869	CHEMBL3263703,TP,ACT,0.44999998807907104	CHEMBL3617311,TP,ACT,0.4300000071525574	CHEMBL2326411,TP,ACT,0.17000000178813934	CHEMBL3609414,TP,ACT,1.0	CHEMBL2325060,TN,INACT,0.03999999910593033	CHEMBL1326803,TN,INACT,0.019999999552965164	CHEMBL434063,FP,INACT,0.2800000011920929	CHEMBL3775607,TP,ACT,0.1899999976158142	CHEMBL1173381,TN,INACT,0.0	CHEMBL52,TN,INACT,0.019999999552965164	CHEMBL1466928,FP,INACT,0.2199999988079071	CHEMBL3313985,TP,ACT,0.9599999785423279	CHEMBL1254991,TN,INACT,0.029999999329447746	CHEMBL3797861,FP,INACT,0.6800000071525574	CHEMBL3314016,TP,ACT,1.0	CHEMBL3598047,TP,ACT,0.9399999976158142	CHEMBL205137,TN,INACT,0.019999999552965164	CHEMBL2337126,TN,INACT,0.009999999776482582	CHEMBL1528124,TN,INACT,0.10000000149011612	CHEMBL3581553,TP,ACT,0.9300000071525574	CHEMBL1349347,TN,INACT,0.009999999776482582	CHEMBL1642349,FP,INACT,0.2800000011920929	CHEMBL108766,TN,INACT,0.0	CHEMBL1462377,TN,INACT,0.029999999329447746	CHEMBL1350069,TN,INACT,0.11999999731779099	CHEMBL584,FP,INACT,0.25999999046325684	CHEMBL3632715,TP,ACT,0.699999988079071	CHEMBL2381195,TN,INACT,0.09000000357627869	CHEMBL478726,TN,INACT,0.019999999552965164	CHEMBL3198515,TN,INACT,0.019999999552965164	CHEMBL2403501,TN,INACT,0.05000000074505806	CHEMBL3234275,FP,INACT,0.7900000214576721	CHEMBL3234263,TP,ACT,0.8700000047683716	CHEMBL1578278,TN,INACT,0.019999999552965164	CHEMBL3109233,FN,ACT,0.029999999329447746	CHEMBL3605079,TP,ACT,0.8500000238418579	CHEMBL3598056,TP,ACT,0.9599999785423279	CHEMBL3598072,TP,ACT,0.8100000023841858	CHEMBL3263697,TP,ACT,0.8999999761581421	CHEMBL497834,TP,ACT,0.25	CHEMBL1390729,TN,INACT,0.029999999329447746	CHEMBL1334930,TN,INACT,0.05000000074505806	CHEMBL3596631,TP,ACT,0.8399999737739563	CHEMBL488991,TN,INACT,0.009999999776482582	CHEMBL3234262,TP,ACT,0.9900000095367432	CHEMBL3361052,TP,ACT,0.7099999785423279	CHEMBL3105673,TP,ACT,0.9900000095367432	CHEMBL1543264,TN,INACT,0.10999999940395355	CHEMBL3827193,TN,INACT,0.03999999910593033	CHEMBL3234251,TP,ACT,0.7400000095367432	CHEMBL3313988,TP,ACT,0.5099999904632568	CHEMBL3325743,TP,ACT,0.949999988079071	CHEMBL3314020,TP,ACT,0.7900000214576721	CHEMBL3596634,TP,ACT,0.9800000190734863	CHEMBL2403509,TN,INACT,0.009999999776482582	CHEMBL3109607,TN,INACT,0.11999999731779099	CHEMBL3094373,TP,ACT,0.9300000071525574	CHEMBL3105805,TP,ACT,0.9800000190734863	CHEMBL3138046,TN,INACT,0.07999999821186066	CHEMBL1466913,TN,INACT,0.12999999523162842	CHEMBL3314010,TP,ACT,0.17000000178813934	CHEMBL460174,TN,INACT,0.0	CHEMBL1359893,TN,INACT,0.009999999776482582	CHEMBL3317847,TP,ACT,0.5299999713897705	CHEMBL3105814,TP,ACT,0.7699999809265137	CHEMBL3799245,TN,INACT,0.11999999731779099	CHEMBL3657602,TP,ACT,0.4699999988079071	CHEMBL583378,TN,INACT,0.009999999776482582	CHEMBL464453,TN,INACT,0.07000000029802322	CHEMBL473801,FP,INACT,0.30000001192092896	CHEMBL1430316,TN,INACT,0.029999999329447746	CHEMBL398012,FP,INACT,0.6000000238418579	CHEMBL3335625,FP,INACT,0.5699999928474426	CHEMBL1465370,TN,INACT,0.009999999776482582	CHEMBL1361641,TN,INACT,0.07999999821186066	CHEMBL3314036,TP,ACT,0.7799999713897705	CHEMBL15766,TN,INACT,0.009999999776482582	CHEMBL3775765,TP,ACT,0.4000000059604645	CHEMBL484264,TN,INACT,0.029999999329447746	CHEMBL3361047,TP,ACT,0.9900000095367432	CHEMBL1445192,TN,INACT,0.12999999523162842	CHEMBL3581551,TP,ACT,0.9399999976158142	CHEMBL38,FN,ACT,0.0	

