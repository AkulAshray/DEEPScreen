CNNModel CHEMBL3501 RMSprop 0.001 30 32 0 0.8 False True
Number of active compounds :	547
Number of inactive compounds :	547
---------------------------------
Run id: CNNModel_CHEMBL3501_RMSprop_0.001_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3501_RMSprop_0.001_30_32_0.8_True/
---------------------------------
Training samples: 685
Validation samples: 215
--
Training Step: 1  | time: 0.780s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/685
[A[ATraining Step: 2  | total loss: [1m[32m0.62366[0m[0m | time: 1.383s
[2K
| RMSProp | epoch: 001 | loss: 0.62366 - acc: 0.5906 -- iter: 064/685
[A[ATraining Step: 3  | total loss: [1m[32m0.68067[0m[0m | time: 1.978s
[2K
| RMSProp | epoch: 001 | loss: 0.68067 - acc: 0.4398 -- iter: 096/685
[A[ATraining Step: 4  | total loss: [1m[32m0.68989[0m[0m | time: 2.577s
[2K
| RMSProp | epoch: 001 | loss: 0.68989 - acc: 0.5787 -- iter: 128/685
[A[ATraining Step: 5  | total loss: [1m[32m0.69189[0m[0m | time: 3.181s
[2K
| RMSProp | epoch: 001 | loss: 0.69189 - acc: 0.5891 -- iter: 160/685
[A[ATraining Step: 6  | total loss: [1m[32m0.69280[0m[0m | time: 3.788s
[2K
| RMSProp | epoch: 001 | loss: 0.69280 - acc: 0.5117 -- iter: 192/685
[A[ATraining Step: 7  | total loss: [1m[32m0.69288[0m[0m | time: 4.398s
[2K
| RMSProp | epoch: 001 | loss: 0.69288 - acc: 0.5234 -- iter: 224/685
[A[ATraining Step: 8  | total loss: [1m[32m0.69309[0m[0m | time: 5.009s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.4399 -- iter: 256/685
[A[ATraining Step: 9  | total loss: [1m[32m0.69306[0m[0m | time: 5.624s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.4883 -- iter: 288/685
[A[ATraining Step: 10  | total loss: [1m[32m0.69321[0m[0m | time: 6.261s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4629 -- iter: 320/685
[A[ATraining Step: 11  | total loss: [1m[32m0.69314[0m[0m | time: 6.863s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.4805 -- iter: 352/685
[A[ATraining Step: 12  | total loss: [1m[32m0.69310[0m[0m | time: 7.501s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.4893 -- iter: 384/685
[A[ATraining Step: 13  | total loss: [1m[32m0.69313[0m[0m | time: 8.103s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4537 -- iter: 416/685
[A[ATraining Step: 14  | total loss: [1m[32m0.69311[0m[0m | time: 8.724s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.4726 -- iter: 448/685
[A[ATraining Step: 15  | total loss: [1m[32m0.69319[0m[0m | time: 9.342s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4589 -- iter: 480/685
[A[ATraining Step: 16  | total loss: [1m[32m0.69322[0m[0m | time: 9.954s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4743 -- iter: 512/685
[A[ATraining Step: 17  | total loss: [1m[32m0.69321[0m[0m | time: 10.567s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4498 -- iter: 544/685
[A[ATraining Step: 18  | total loss: [1m[32m0.69313[0m[0m | time: 11.193s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5104 -- iter: 576/685
[A[ATraining Step: 19  | total loss: [1m[32m0.69304[0m[0m | time: 11.799s
[2K
| RMSProp | epoch: 001 | loss: 0.69304 - acc: 0.5382 -- iter: 608/685
[A[ATraining Step: 20  | total loss: [1m[32m0.69318[0m[0m | time: 12.392s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.5058 -- iter: 640/685
[A[ATraining Step: 21  | total loss: [1m[32m0.69310[0m[0m | time: 13.010s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5040 -- iter: 672/685
[A[ATraining Step: 22  | total loss: [1m[32m0.69311[0m[0m | time: 14.304s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5216 | val_loss: 0.69328 - val_acc: 0.4372 -- iter: 685/685
--
Training Step: 23  | total loss: [1m[32m0.69316[0m[0m | time: 0.285s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.5041 -- iter: 032/685
[A[ATraining Step: 24  | total loss: [1m[32m0.69314[0m[0m | time: 0.893s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4922 -- iter: 064/685
[A[ATraining Step: 25  | total loss: [1m[32m0.69315[0m[0m | time: 1.493s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4943 -- iter: 096/685
[A[ATraining Step: 26  | total loss: [1m[32m0.69302[0m[0m | time: 2.125s
[2K
| RMSProp | epoch: 002 | loss: 0.69302 - acc: 0.5537 -- iter: 128/685
[A[ATraining Step: 27  | total loss: [1m[32m0.69296[0m[0m | time: 2.727s
[2K
| RMSProp | epoch: 002 | loss: 0.69296 - acc: 0.5640 -- iter: 160/685
[A[ATraining Step: 28  | total loss: [1m[32m0.69314[0m[0m | time: 3.334s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.5168 -- iter: 192/685
[A[ATraining Step: 29  | total loss: [1m[32m0.69313[0m[0m | time: 3.932s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5127 -- iter: 224/685
[A[ATraining Step: 30  | total loss: [1m[32m0.69314[0m[0m | time: 4.533s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.5097 -- iter: 256/685
[A[ATraining Step: 31  | total loss: [1m[32m0.69312[0m[0m | time: 5.131s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5291 -- iter: 288/685
[A[ATraining Step: 32  | total loss: [1m[32m0.69321[0m[0m | time: 5.734s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.5014 -- iter: 320/685
[A[ATraining Step: 33  | total loss: [1m[32m0.69318[0m[0m | time: 6.351s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.5217 -- iter: 352/685
[A[ATraining Step: 34  | total loss: [1m[32m0.69313[0m[0m | time: 6.980s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5238 -- iter: 384/685
[A[ATraining Step: 35  | total loss: [1m[32m0.69309[0m[0m | time: 7.573s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5253 -- iter: 416/685
[A[ATraining Step: 36  | total loss: [1m[32m0.69322[0m[0m | time: 8.185s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4818 -- iter: 448/685
[A[ATraining Step: 37  | total loss: [1m[32m0.69319[0m[0m | time: 8.796s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4854 -- iter: 480/685
[A[ATraining Step: 38  | total loss: [1m[32m0.69316[0m[0m | time: 9.399s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.5066 -- iter: 512/685
[A[ATraining Step: 39  | total loss: [1m[32m0.69317[0m[0m | time: 10.011s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4994 -- iter: 544/685
[A[ATraining Step: 40  | total loss: [1m[32m0.69314[0m[0m | time: 10.608s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.5053 -- iter: 576/685
[A[ATraining Step: 41  | total loss: [1m[32m0.69310[0m[0m | time: 11.211s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5158 -- iter: 608/685
[A[ATraining Step: 42  | total loss: [1m[32m0.69314[0m[0m | time: 11.819s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.5017 -- iter: 640/685
[A[ATraining Step: 43  | total loss: [1m[32m0.69315[0m[0m | time: 12.415s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5014 -- iter: 672/685
[A[ATraining Step: 44  | total loss: [1m[32m0.69312[0m[0m | time: 14.018s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5066 | val_loss: 0.69344 - val_acc: 0.4372 -- iter: 685/685
--
Training Step: 45  | total loss: [1m[32m0.69307[0m[0m | time: 0.281s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5161 -- iter: 032/685
[A[ATraining Step: 46  | total loss: [1m[32m0.69292[0m[0m | time: 0.555s
[2K
| RMSProp | epoch: 003 | loss: 0.69292 - acc: 0.5455 -- iter: 064/685
[A[ATraining Step: 47  | total loss: [1m[32m0.69269[0m[0m | time: 1.182s
[2K
| RMSProp | epoch: 003 | loss: 0.69269 - acc: 0.5695 -- iter: 096/685
[A[ATraining Step: 48  | total loss: [1m[32m0.69273[0m[0m | time: 1.780s
[2K
| RMSProp | epoch: 003 | loss: 0.69273 - acc: 0.5633 -- iter: 128/685
[A[ATraining Step: 49  | total loss: [1m[32m0.69252[0m[0m | time: 2.395s
[2K
| RMSProp | epoch: 003 | loss: 0.69252 - acc: 0.5731 -- iter: 160/685
[A[ATraining Step: 50  | total loss: [1m[32m0.69279[0m[0m | time: 3.000s
[2K
| RMSProp | epoch: 003 | loss: 0.69279 - acc: 0.5520 -- iter: 192/685
[A[ATraining Step: 51  | total loss: [1m[32m0.69277[0m[0m | time: 3.598s
[2K
| RMSProp | epoch: 003 | loss: 0.69277 - acc: 0.5489 -- iter: 224/685
[A[ATraining Step: 52  | total loss: [1m[32m0.69282[0m[0m | time: 4.194s
[2K
| RMSProp | epoch: 003 | loss: 0.69282 - acc: 0.5415 -- iter: 256/685
[A[ATraining Step: 53  | total loss: [1m[32m0.69308[0m[0m | time: 4.794s
[2K
| RMSProp | epoch: 003 | loss: 0.69308 - acc: 0.5216 -- iter: 288/685
[A[ATraining Step: 54  | total loss: [1m[32m0.69312[0m[0m | time: 5.402s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5139 -- iter: 320/685
[A[ATraining Step: 55  | total loss: [1m[32m0.69327[0m[0m | time: 6.013s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.4985 -- iter: 352/685
[A[ATraining Step: 56  | total loss: [1m[32m0.69328[0m[0m | time: 6.614s
[2K
| RMSProp | epoch: 003 | loss: 0.69328 - acc: 0.4943 -- iter: 384/685
[A[ATraining Step: 57  | total loss: [1m[32m0.69313[0m[0m | time: 7.241s
[2K
| RMSProp | epoch: 003 | loss: 0.69313 - acc: 0.5081 -- iter: 416/685
[A[ATraining Step: 58  | total loss: [1m[32m0.69307[0m[0m | time: 7.835s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5113 -- iter: 448/685
[A[ATraining Step: 59  | total loss: [1m[32m0.69313[0m[0m | time: 8.427s
[2K
| RMSProp | epoch: 003 | loss: 0.69313 - acc: 0.5056 -- iter: 480/685
[A[ATraining Step: 60  | total loss: [1m[32m0.69319[0m[0m | time: 9.035s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5007 -- iter: 512/685
[A[ATraining Step: 61  | total loss: [1m[32m0.69307[0m[0m | time: 9.632s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5128 -- iter: 544/685
[A[ATraining Step: 62  | total loss: [1m[32m0.69317[0m[0m | time: 10.235s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.5031 -- iter: 576/685
[A[ATraining Step: 63  | total loss: [1m[32m0.69312[0m[0m | time: 10.864s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5067 -- iter: 608/685
[A[ATraining Step: 64  | total loss: [1m[32m0.69307[0m[0m | time: 11.473s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5098 -- iter: 640/685
[A[ATraining Step: 65  | total loss: [1m[32m0.69263[0m[0m | time: 12.084s
[2K
| RMSProp | epoch: 003 | loss: 0.69263 - acc: 0.5394 -- iter: 672/685
[A[ATraining Step: 66  | total loss: [1m[32m0.69277[0m[0m | time: 13.694s
[2K
| RMSProp | epoch: 003 | loss: 0.69277 - acc: 0.5308 | val_loss: 0.69411 - val_acc: 0.4372 -- iter: 685/685
--
Training Step: 67  | total loss: [1m[32m0.69303[0m[0m | time: 0.617s
[2K
| RMSProp | epoch: 004 | loss: 0.69303 - acc: 0.5158 -- iter: 032/685
[A[ATraining Step: 68  | total loss: [1m[32m0.69303[0m[0m | time: 0.889s
[2K
| RMSProp | epoch: 004 | loss: 0.69303 - acc: 0.5140 -- iter: 064/685
[A[ATraining Step: 69  | total loss: [1m[32m0.69312[0m[0m | time: 1.166s
[2K
| RMSProp | epoch: 004 | loss: 0.69312 - acc: 0.5078 -- iter: 096/685
[A[ATraining Step: 70  | total loss: [1m[32m0.69319[0m[0m | time: 1.795s
[2K
| RMSProp | epoch: 004 | loss: 0.69319 - acc: 0.5025 -- iter: 128/685
[A[ATraining Step: 71  | total loss: [1m[32m0.69319[0m[0m | time: 2.390s
[2K
| RMSProp | epoch: 004 | loss: 0.69319 - acc: 0.5022 -- iter: 160/685
[A[ATraining Step: 72  | total loss: [1m[32m0.69322[0m[0m | time: 2.996s
[2K
| RMSProp | epoch: 004 | loss: 0.69322 - acc: 0.4985 -- iter: 192/685
[A[ATraining Step: 73  | total loss: [1m[32m0.69321[0m[0m | time: 3.613s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.4986 -- iter: 224/685
[A[ATraining Step: 74  | total loss: [1m[32m0.69326[0m[0m | time: 4.210s
[2K
| RMSProp | epoch: 004 | loss: 0.69326 - acc: 0.4919 -- iter: 256/685
[A[ATraining Step: 75  | total loss: [1m[32m0.69327[0m[0m | time: 4.811s
[2K
| RMSProp | epoch: 004 | loss: 0.69327 - acc: 0.4894 -- iter: 288/685
[A[ATraining Step: 76  | total loss: [1m[32m0.69325[0m[0m | time: 5.413s
[2K
| RMSProp | epoch: 004 | loss: 0.69325 - acc: 0.4905 -- iter: 320/685
[A[ATraining Step: 77  | total loss: [1m[32m0.69323[0m[0m | time: 6.037s
[2K
| RMSProp | epoch: 004 | loss: 0.69323 - acc: 0.4948 -- iter: 352/685
[A[ATraining Step: 78  | total loss: [1m[32m0.69313[0m[0m | time: 6.646s
[2K
| RMSProp | epoch: 004 | loss: 0.69313 - acc: 0.5052 -- iter: 384/685
[A[ATraining Step: 79  | total loss: [1m[32m0.69317[0m[0m | time: 7.252s
[2K
| RMSProp | epoch: 004 | loss: 0.69317 - acc: 0.5014 -- iter: 416/685
[A[ATraining Step: 80  | total loss: [1m[32m0.69306[0m[0m | time: 7.853s
[2K
| RMSProp | epoch: 004 | loss: 0.69306 - acc: 0.5109 -- iter: 448/685
[A[ATraining Step: 81  | total loss: [1m[32m0.69311[0m[0m | time: 8.460s
[2K
| RMSProp | epoch: 004 | loss: 0.69311 - acc: 0.5066 -- iter: 480/685
[A[ATraining Step: 82  | total loss: [1m[32m0.69306[0m[0m | time: 9.059s
[2K
| RMSProp | epoch: 004 | loss: 0.69306 - acc: 0.5091 -- iter: 512/685
[A[ATraining Step: 83  | total loss: [1m[32m0.69296[0m[0m | time: 9.653s
[2K
| RMSProp | epoch: 004 | loss: 0.69296 - acc: 0.5144 -- iter: 544/685
[A[ATraining Step: 84  | total loss: [1m[32m0.69310[0m[0m | time: 10.248s
[2K
| RMSProp | epoch: 004 | loss: 0.69310 - acc: 0.5067 -- iter: 576/685
[A[ATraining Step: 85  | total loss: [1m[32m0.69319[0m[0m | time: 10.840s
[2K
| RMSProp | epoch: 004 | loss: 0.69319 - acc: 0.4998 -- iter: 608/685
[A[ATraining Step: 86  | total loss: [1m[32m0.69315[0m[0m | time: 11.441s
[2K
| RMSProp | epoch: 004 | loss: 0.69315 - acc: 0.5029 -- iter: 640/685
[A[ATraining Step: 87  | total loss: [1m[32m0.69315[0m[0m | time: 12.046s
[2K
| RMSProp | epoch: 004 | loss: 0.69315 - acc: 0.5027 -- iter: 672/685
[A[ATraining Step: 88  | total loss: [1m[32m0.69310[0m[0m | time: 13.650s
[2K
| RMSProp | epoch: 004 | loss: 0.69310 - acc: 0.5055 | val_loss: 0.69351 - val_acc: 0.4372 -- iter: 685/685
--
Training Step: 89  | total loss: [1m[32m0.69326[0m[0m | time: 0.608s
[2K
| RMSProp | epoch: 005 | loss: 0.69326 - acc: 0.4956 -- iter: 032/685
[A[ATraining Step: 90  | total loss: [1m[32m0.69326[0m[0m | time: 1.207s
[2K
| RMSProp | epoch: 005 | loss: 0.69326 - acc: 0.4960 -- iter: 064/685
[A[ATraining Step: 91  | total loss: [1m[32m0.69325[0m[0m | time: 1.487s
[2K
| RMSProp | epoch: 005 | loss: 0.69325 - acc: 0.4933 -- iter: 096/685
[A[ATraining Step: 92  | total loss: [1m[32m0.69320[0m[0m | time: 1.762s
[2K
| RMSProp | epoch: 005 | loss: 0.69320 - acc: 0.4978 -- iter: 128/685
[A[ATraining Step: 93  | total loss: [1m[32m0.69315[0m[0m | time: 2.378s
[2K
| RMSProp | epoch: 005 | loss: 0.69315 - acc: 0.5019 -- iter: 160/685
[A[ATraining Step: 94  | total loss: [1m[32m0.69310[0m[0m | time: 3.007s
[2K
| RMSProp | epoch: 005 | loss: 0.69310 - acc: 0.5048 -- iter: 192/685
[A[ATraining Step: 95  | total loss: [1m[32m0.69304[0m[0m | time: 3.621s
[2K
| RMSProp | epoch: 005 | loss: 0.69304 - acc: 0.5075 -- iter: 224/685
[A[ATraining Step: 96  | total loss: [1m[32m0.69316[0m[0m | time: 4.221s
[2K
| RMSProp | epoch: 005 | loss: 0.69316 - acc: 0.5005 -- iter: 256/685
[A[ATraining Step: 97  | total loss: [1m[32m0.69308[0m[0m | time: 4.810s
[2K
| RMSProp | epoch: 005 | loss: 0.69308 - acc: 0.5067 -- iter: 288/685
[A[ATraining Step: 98  | total loss: [1m[32m0.69278[0m[0m | time: 5.413s
[2K
| RMSProp | epoch: 005 | loss: 0.69278 - acc: 0.5216 -- iter: 320/685
[A[ATraining Step: 99  | total loss: [1m[32m0.69281[0m[0m | time: 6.016s
[2K
| RMSProp | epoch: 005 | loss: 0.69281 - acc: 0.5195 -- iter: 352/685
[A[ATraining Step: 100  | total loss: [1m[32m0.69343[0m[0m | time: 6.627s
[2K
| RMSProp | epoch: 005 | loss: 0.69343 - acc: 0.4988 -- iter: 384/685
[A[ATraining Step: 101  | total loss: [1m[32m0.69329[0m[0m | time: 7.255s
[2K
| RMSProp | epoch: 005 | loss: 0.69329 - acc: 0.5051 -- iter: 416/685
[A[ATraining Step: 102  | total loss: [1m[32m0.69325[0m[0m | time: 7.857s
[2K
| RMSProp | epoch: 005 | loss: 0.69325 - acc: 0.5046 -- iter: 448/685
[A[ATraining Step: 103  | total loss: [1m[32m0.69310[0m[0m | time: 8.463s
[2K
| RMSProp | epoch: 005 | loss: 0.69310 - acc: 0.5104 -- iter: 480/685
[A[ATraining Step: 104  | total loss: [1m[32m0.69267[0m[0m | time: 9.051s
[2K
| RMSProp | epoch: 005 | loss: 0.69267 - acc: 0.5250 -- iter: 512/685
[A[ATraining Step: 105  | total loss: [1m[32m0.69257[0m[0m | time: 9.650s
[2K
| RMSProp | epoch: 005 | loss: 0.69257 - acc: 0.5256 -- iter: 544/685
[A[ATraining Step: 106  | total loss: [1m[32m0.69280[0m[0m | time: 10.242s
[2K
| RMSProp | epoch: 005 | loss: 0.69280 - acc: 0.5199 -- iter: 576/685
[A[ATraining Step: 107  | total loss: [1m[32m0.69222[0m[0m | time: 10.837s
[2K
| RMSProp | epoch: 005 | loss: 0.69222 - acc: 0.5336 -- iter: 608/685
[A[ATraining Step: 108  | total loss: [1m[32m0.69321[0m[0m | time: 11.456s
[2K
| RMSProp | epoch: 005 | loss: 0.69321 - acc: 0.5146 -- iter: 640/685
[A[ATraining Step: 109  | total loss: [1m[32m0.69321[0m[0m | time: 12.045s
[2K
| RMSProp | epoch: 005 | loss: 0.69321 - acc: 0.5131 -- iter: 672/685
[A[ATraining Step: 110  | total loss: [1m[32m0.69277[0m[0m | time: 13.649s
[2K
| RMSProp | epoch: 005 | loss: 0.69277 - acc: 0.5243 | val_loss: 0.69501 - val_acc: 0.4372 -- iter: 685/685
--
Training Step: 111  | total loss: [1m[32m0.69346[0m[0m | time: 0.616s
[2K
| RMSProp | epoch: 006 | loss: 0.69346 - acc: 0.5094 -- iter: 032/685
[A[ATraining Step: 112  | total loss: [1m[32m0.69342[0m[0m | time: 1.209s
[2K
| RMSProp | epoch: 006 | loss: 0.69342 - acc: 0.5084 -- iter: 064/685
[A[ATraining Step: 113  | total loss: [1m[32m0.69348[0m[0m | time: 1.820s
[2K
| RMSProp | epoch: 006 | loss: 0.69348 - acc: 0.5045 -- iter: 096/685
[A[ATraining Step: 114  | total loss: [1m[32m0.69338[0m[0m | time: 2.102s
[2K
| RMSProp | epoch: 006 | loss: 0.69338 - acc: 0.5072 -- iter: 128/685
[A[ATraining Step: 115  | total loss: [1m[32m0.69231[0m[0m | time: 2.374s
[2K
| RMSProp | epoch: 006 | loss: 0.69231 - acc: 0.5411 -- iter: 160/685
[A[ATraining Step: 116  | total loss: [1m[32m0.68998[0m[0m | time: 2.972s
[2K
| RMSProp | epoch: 006 | loss: 0.68998 - acc: 0.5716 -- iter: 192/685
[A[ATraining Step: 117  | total loss: [1m[32m0.68971[0m[0m | time: 3.563s
[2K
| RMSProp | epoch: 006 | loss: 0.68971 - acc: 0.5707 -- iter: 224/685
[A[ATraining Step: 118  | total loss: [1m[32m0.68981[0m[0m | time: 4.168s
[2K
| RMSProp | epoch: 006 | loss: 0.68981 - acc: 0.5667 -- iter: 256/685
[A[ATraining Step: 119  | total loss: [1m[32m0.69215[0m[0m | time: 4.755s
[2K
| RMSProp | epoch: 006 | loss: 0.69215 - acc: 0.5475 -- iter: 288/685
[A[ATraining Step: 120  | total loss: [1m[32m0.69252[0m[0m | time: 5.360s
[2K
| RMSProp | epoch: 006 | loss: 0.69252 - acc: 0.5397 -- iter: 320/685
[A[ATraining Step: 121  | total loss: [1m[32m0.69237[0m[0m | time: 5.968s
[2K
| RMSProp | epoch: 006 | loss: 0.69237 - acc: 0.5388 -- iter: 352/685
[A[ATraining Step: 122  | total loss: [1m[32m0.69246[0m[0m | time: 6.576s
[2K
| RMSProp | epoch: 006 | loss: 0.69246 - acc: 0.5349 -- iter: 384/685
[A[ATraining Step: 123  | total loss: [1m[32m0.69255[0m[0m | time: 7.190s
[2K
| RMSProp | epoch: 006 | loss: 0.69255 - acc: 0.5314 -- iter: 416/685
[A[ATraining Step: 124  | total loss: [1m[32m0.69239[0m[0m | time: 7.792s
[2K
| RMSProp | epoch: 006 | loss: 0.69239 - acc: 0.5314 -- iter: 448/685
[A[ATraining Step: 125  | total loss: [1m[32m0.69245[0m[0m | time: 8.389s
[2K
| RMSProp | epoch: 006 | loss: 0.69245 - acc: 0.5283 -- iter: 480/685
[A[ATraining Step: 126  | total loss: [1m[32m0.69233[0m[0m | time: 8.991s
[2K
| RMSProp | epoch: 006 | loss: 0.69233 - acc: 0.5286 -- iter: 512/685
[A[ATraining Step: 127  | total loss: [1m[32m0.69213[0m[0m | time: 9.593s
[2K
| RMSProp | epoch: 006 | loss: 0.69213 - acc: 0.5288 -- iter: 544/685
[A[ATraining Step: 128  | total loss: [1m[32m0.69166[0m[0m | time: 10.212s
[2K
| RMSProp | epoch: 006 | loss: 0.69166 - acc: 0.5322 -- iter: 576/685
[A[ATraining Step: 129  | total loss: [1m[32m0.69123[0m[0m | time: 10.819s
[2K
| RMSProp | epoch: 006 | loss: 0.69123 - acc: 0.5352 -- iter: 608/685
[A[ATraining Step: 130  | total loss: [1m[32m0.69145[0m[0m | time: 11.425s
[2K
| RMSProp | epoch: 006 | loss: 0.69145 - acc: 0.5317 -- iter: 640/685
[A[ATraining Step: 131  | total loss: [1m[32m0.69166[0m[0m | time: 12.026s
[2K
| RMSProp | epoch: 006 | loss: 0.69166 - acc: 0.5285 -- iter: 672/685
[A[ATraining Step: 132  | total loss: [1m[32m0.69158[0m[0m | time: 13.634s
[2K
| RMSProp | epoch: 006 | loss: 0.69158 - acc: 0.5288 | val_loss: 0.70154 - val_acc: 0.4372 -- iter: 685/685
--
Training Step: 133  | total loss: [1m[32m0.69140[0m[0m | time: 0.602s
[2K
| RMSProp | epoch: 007 | loss: 0.69140 - acc: 0.5291 -- iter: 032/685
[A[ATraining Step: 134  | total loss: [1m[32m0.69353[0m[0m | time: 1.202s
[2K
| RMSProp | epoch: 007 | loss: 0.69353 - acc: 0.5105 -- iter: 064/685
[A[ATraining Step: 135  | total loss: [1m[32m0.69310[0m[0m | time: 1.807s
[2K
| RMSProp | epoch: 007 | loss: 0.69310 - acc: 0.5220 -- iter: 096/685
[A[ATraining Step: 136  | total loss: [1m[32m0.69313[0m[0m | time: 2.410s
[2K
| RMSProp | epoch: 007 | loss: 0.69313 - acc: 0.5198 -- iter: 128/685
[A[ATraining Step: 137  | total loss: [1m[32m0.69348[0m[0m | time: 2.680s
[2K
| RMSProp | epoch: 007 | loss: 0.69348 - acc: 0.5116 -- iter: 160/685
[A[ATraining Step: 138  | total loss: [1m[32m0.69331[0m[0m | time: 2.960s
[2K
| RMSProp | epoch: 007 | loss: 0.69331 - acc: 0.5142 -- iter: 192/685
[A[ATraining Step: 139  | total loss: [1m[32m0.69315[0m[0m | time: 3.583s
[2K
| RMSProp | epoch: 007 | loss: 0.69315 - acc: 0.5167 -- iter: 224/685
[A[ATraining Step: 140  | total loss: [1m[32m0.69299[0m[0m | time: 4.215s
[2K
| RMSProp | epoch: 007 | loss: 0.69299 - acc: 0.5181 -- iter: 256/685
[A[ATraining Step: 141  | total loss: [1m[32m0.69285[0m[0m | time: 4.819s
[2K
| RMSProp | epoch: 007 | loss: 0.69285 - acc: 0.5194 -- iter: 288/685
[A[ATraining Step: 142  | total loss: [1m[32m0.69239[0m[0m | time: 5.447s
[2K
| RMSProp | epoch: 007 | loss: 0.69239 - acc: 0.5269 -- iter: 320/685
[A[ATraining Step: 143  | total loss: [1m[32m0.69224[0m[0m | time: 6.063s
[2K
| RMSProp | epoch: 007 | loss: 0.69224 - acc: 0.5273 -- iter: 352/685
[A[ATraining Step: 144  | total loss: [1m[32m0.69295[0m[0m | time: 6.662s
[2K
| RMSProp | epoch: 007 | loss: 0.69295 - acc: 0.5183 -- iter: 384/685
[A[ATraining Step: 145  | total loss: [1m[32m0.69214[0m[0m | time: 7.272s
[2K
| RMSProp | epoch: 007 | loss: 0.69214 - acc: 0.5321 -- iter: 416/685
[A[ATraining Step: 146  | total loss: [1m[32m0.69261[0m[0m | time: 7.876s
[2K
| RMSProp | epoch: 007 | loss: 0.69261 - acc: 0.5258 -- iter: 448/685
[A[ATraining Step: 147  | total loss: [1m[32m0.69200[0m[0m | time: 8.484s
[2K
| RMSProp | epoch: 007 | loss: 0.69200 - acc: 0.5326 -- iter: 480/685
[A[ATraining Step: 148  | total loss: [1m[32m0.69281[0m[0m | time: 9.092s
[2K
| RMSProp | epoch: 007 | loss: 0.69281 - acc: 0.5231 -- iter: 512/685
[A[ATraining Step: 149  | total loss: [1m[32m0.69382[0m[0m | time: 9.718s
[2K
| RMSProp | epoch: 007 | loss: 0.69382 - acc: 0.5051 -- iter: 544/685
[A[ATraining Step: 150  | total loss: [1m[32m0.69356[0m[0m | time: 10.310s
[2K
| RMSProp | epoch: 007 | loss: 0.69356 - acc: 0.5109 -- iter: 576/685
[A[ATraining Step: 151  | total loss: [1m[32m0.69353[0m[0m | time: 10.939s
[2K
| RMSProp | epoch: 007 | loss: 0.69353 - acc: 0.5098 -- iter: 608/685
[A[ATraining Step: 152  | total loss: [1m[32m0.69323[0m[0m | time: 11.545s
[2K
| RMSProp | epoch: 007 | loss: 0.69323 - acc: 0.5151 -- iter: 640/685
[A[ATraining Step: 153  | total loss: [1m[32m0.69290[0m[0m | time: 12.168s
[2K
| RMSProp | epoch: 007 | loss: 0.69290 - acc: 0.5198 -- iter: 672/685
[A[ATraining Step: 154  | total loss: [1m[32m0.69315[0m[0m | time: 13.776s
[2K
| RMSProp | epoch: 007 | loss: 0.69315 - acc: 0.5147 | val_loss: 0.69637 - val_acc: 0.4372 -- iter: 685/685
--
Training Step: 155  | total loss: [1m[32m0.69312[0m[0m | time: 0.663s
[2K
| RMSProp | epoch: 008 | loss: 0.69312 - acc: 0.5132 -- iter: 032/685
[A[ATraining Step: 156  | total loss: [1m[32m0.69310[0m[0m | time: 1.261s
[2K
| RMSProp | epoch: 008 | loss: 0.69310 - acc: 0.5119 -- iter: 064/685
[A[ATraining Step: 157  | total loss: [1m[32m0.69296[0m[0m | time: 1.849s
[2K
| RMSProp | epoch: 008 | loss: 0.69296 - acc: 0.5138 -- iter: 096/685
[A[ATraining Step: 158  | total loss: [1m[32m0.69318[0m[0m | time: 2.448s
[2K
| RMSProp | epoch: 008 | loss: 0.69318 - acc: 0.5093 -- iter: 128/685
[A[ATraining Step: 159  | total loss: [1m[32m0.69256[0m[0m | time: 3.051s
[2K
| RMSProp | epoch: 008 | loss: 0.69256 - acc: 0.5240 -- iter: 160/685
[A[ATraining Step: 160  | total loss: [1m[32m0.69199[0m[0m | time: 3.317s
[2K
| RMSProp | epoch: 008 | loss: 0.69199 - acc: 0.5279 -- iter: 192/685
[A[ATraining Step: 161  | total loss: [1m[32m0.69125[0m[0m | time: 3.589s
[2K
| RMSProp | epoch: 008 | loss: 0.69125 - acc: 0.5289 -- iter: 224/685
[A[ATraining Step: 162  | total loss: [1m[32m0.69046[0m[0m | time: 4.186s
[2K
| RMSProp | epoch: 008 | loss: 0.69046 - acc: 0.5299 -- iter: 256/685
[A[ATraining Step: 163  | total loss: [1m[32m0.69237[0m[0m | time: 4.793s
[2K
| RMSProp | epoch: 008 | loss: 0.69237 - acc: 0.5175 -- iter: 288/685
[A[ATraining Step: 164  | total loss: [1m[32m0.69222[0m[0m | time: 5.392s
[2K
| RMSProp | epoch: 008 | loss: 0.69222 - acc: 0.5220 -- iter: 320/685
[A[ATraining Step: 165  | total loss: [1m[32m0.69183[0m[0m | time: 5.992s
[2K
| RMSProp | epoch: 008 | loss: 0.69183 - acc: 0.5292 -- iter: 352/685
[A[ATraining Step: 166  | total loss: [1m[32m0.69224[0m[0m | time: 6.592s
[2K
| RMSProp | epoch: 008 | loss: 0.69224 - acc: 0.5231 -- iter: 384/685
[A[ATraining Step: 167  | total loss: [1m[32m0.69234[0m[0m | time: 7.180s
[2K
| RMSProp | epoch: 008 | loss: 0.69234 - acc: 0.5208 -- iter: 416/685
[A[ATraining Step: 168  | total loss: [1m[32m0.69241[0m[0m | time: 7.787s
[2K
| RMSProp | epoch: 008 | loss: 0.69241 - acc: 0.5187 -- iter: 448/685
[A[ATraining Step: 169  | total loss: [1m[32m0.69268[0m[0m | time: 8.396s
[2K
| RMSProp | epoch: 008 | loss: 0.69268 - acc: 0.5137 -- iter: 480/685
[A[ATraining Step: 170  | total loss: [1m[32m0.69342[0m[0m | time: 8.994s
[2K
| RMSProp | epoch: 008 | loss: 0.69342 - acc: 0.4967 -- iter: 512/685
[A[ATraining Step: 171  | total loss: [1m[32m0.69362[0m[0m | time: 9.598s
[2K
| RMSProp | epoch: 008 | loss: 0.69362 - acc: 0.4846 -- iter: 544/685
[A[ATraining Step: 172  | total loss: [1m[32m0.69355[0m[0m | time: 10.201s
[2K
| RMSProp | epoch: 008 | loss: 0.69355 - acc: 0.4986 -- iter: 576/685
[A[ATraining Step: 173  | total loss: [1m[32m0.69339[0m[0m | time: 10.795s
[2K
| RMSProp | epoch: 008 | loss: 0.69339 - acc: 0.5081 -- iter: 608/685
[A[ATraining Step: 174  | total loss: [1m[32m0.69337[0m[0m | time: 11.424s
[2K
| RMSProp | epoch: 008 | loss: 0.69337 - acc: 0.5073 -- iter: 640/685
[A[ATraining Step: 175  | total loss: [1m[32m0.69309[0m[0m | time: 12.022s
[2K
| RMSProp | epoch: 008 | loss: 0.69309 - acc: 0.5160 -- iter: 672/685
[A[ATraining Step: 176  | total loss: [1m[32m0.69395[0m[0m | time: 13.628s
[2K
| RMSProp | epoch: 008 | loss: 0.69395 - acc: 0.4987 | val_loss: 0.69363 - val_acc: 0.4372 -- iter: 685/685
--
Training Step: 177  | total loss: [1m[32m0.69397[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 009 | loss: 0.69397 - acc: 0.4926 -- iter: 032/685
[A[ATraining Step: 178  | total loss: [1m[32m0.69381[0m[0m | time: 1.213s
[2K
| RMSProp | epoch: 009 | loss: 0.69381 - acc: 0.5027 -- iter: 064/685
[A[ATraining Step: 179  | total loss: [1m[32m0.69381[0m[0m | time: 1.809s
[2K
| RMSProp | epoch: 009 | loss: 0.69381 - acc: 0.4993 -- iter: 096/685
[A[ATraining Step: 180  | total loss: [1m[32m0.69380[0m[0m | time: 2.403s
[2K
| RMSProp | epoch: 009 | loss: 0.69380 - acc: 0.4963 -- iter: 128/685
[A[ATraining Step: 181  | total loss: [1m[32m0.69361[0m[0m | time: 2.999s
[2K
| RMSProp | epoch: 009 | loss: 0.69361 - acc: 0.5091 -- iter: 160/685
[A[ATraining Step: 182  | total loss: [1m[32m0.69365[0m[0m | time: 3.608s
[2K
| RMSProp | epoch: 009 | loss: 0.69365 - acc: 0.5051 -- iter: 192/685
[A[ATraining Step: 183  | total loss: [1m[32m0.69362[0m[0m | time: 3.879s
[2K
| RMSProp | epoch: 009 | loss: 0.69362 - acc: 0.5046 -- iter: 224/685
[A[ATraining Step: 184  | total loss: [1m[32m0.69379[0m[0m | time: 4.148s
[2K
| RMSProp | epoch: 009 | loss: 0.69379 - acc: 0.4926 -- iter: 256/685
[A[ATraining Step: 185  | total loss: [1m[32m0.69376[0m[0m | time: 4.751s
[2K
| RMSProp | epoch: 009 | loss: 0.69376 - acc: 0.4818 -- iter: 288/685
[A[ATraining Step: 186  | total loss: [1m[32m0.69363[0m[0m | time: 5.348s
[2K
| RMSProp | epoch: 009 | loss: 0.69363 - acc: 0.4899 -- iter: 320/685
[A[ATraining Step: 187  | total loss: [1m[32m0.69343[0m[0m | time: 5.952s
[2K
| RMSProp | epoch: 009 | loss: 0.69343 - acc: 0.5034 -- iter: 352/685
[A[ATraining Step: 188  | total loss: [1m[32m0.69369[0m[0m | time: 6.589s
[2K
| RMSProp | epoch: 009 | loss: 0.69369 - acc: 0.4937 -- iter: 384/685
[A[ATraining Step: 189  | total loss: [1m[32m0.69361[0m[0m | time: 7.198s
[2K
| RMSProp | epoch: 009 | loss: 0.69361 - acc: 0.4943 -- iter: 416/685
[A[ATraining Step: 190  | total loss: [1m[32m0.69349[0m[0m | time: 7.802s
[2K
| RMSProp | epoch: 009 | loss: 0.69349 - acc: 0.5136 -- iter: 448/685
[A[ATraining Step: 191  | total loss: [1m[32m0.69306[0m[0m | time: 8.416s
[2K
| RMSProp | epoch: 009 | loss: 0.69306 - acc: 0.5154 -- iter: 480/685
[A[ATraining Step: 192  | total loss: [1m[32m0.69436[0m[0m | time: 9.019s
[2K
| RMSProp | epoch: 009 | loss: 0.69436 - acc: 0.5045 -- iter: 512/685
[A[ATraining Step: 193  | total loss: [1m[32m0.69424[0m[0m | time: 9.642s
[2K
| RMSProp | epoch: 009 | loss: 0.69424 - acc: 0.5040 -- iter: 544/685
[A[ATraining Step: 194  | total loss: [1m[32m0.69467[0m[0m | time: 10.236s
[2K
| RMSProp | epoch: 009 | loss: 0.69467 - acc: 0.4755 -- iter: 576/685
[A[ATraining Step: 195  | total loss: [1m[32m0.69447[0m[0m | time: 10.841s
[2K
| RMSProp | epoch: 009 | loss: 0.69447 - acc: 0.4779 -- iter: 608/685
[A[ATraining Step: 196  | total loss: [1m[32m0.69424[0m[0m | time: 11.428s
[2K
| RMSProp | epoch: 009 | loss: 0.69424 - acc: 0.4802 -- iter: 640/685
[A[ATraining Step: 197  | total loss: [1m[32m0.69350[0m[0m | time: 12.020s
[2K
| RMSProp | epoch: 009 | loss: 0.69350 - acc: 0.4946 -- iter: 672/685
[A[ATraining Step: 198  | total loss: [1m[32m0.68685[0m[0m | time: 13.618s
[2K
| RMSProp | epoch: 009 | loss: 0.68685 - acc: 0.5139 | val_loss: 0.71270 - val_acc: 0.4372 -- iter: 685/685
--
Training Step: 199  | total loss: [1m[32m0.83495[0m[0m | time: 0.600s
[2K
| RMSProp | epoch: 010 | loss: 0.83495 - acc: 0.5188 -- iter: 032/685
[A[ATraining Step: 200  | total loss: [1m[32m0.81936[0m[0m | time: 2.200s
[2K
| RMSProp | epoch: 010 | loss: 0.81936 - acc: 0.5232 | val_loss: 0.72785 - val_acc: 0.4372 -- iter: 064/685
--
Training Step: 201  | total loss: [1m[32m0.80344[0m[0m | time: 2.811s
[2K
| RMSProp | epoch: 010 | loss: 0.80344 - acc: 0.5333 -- iter: 096/685
[A[ATraining Step: 202  | total loss: [1m[32m0.79134[0m[0m | time: 3.393s
[2K
| RMSProp | epoch: 010 | loss: 0.79134 - acc: 0.5363 -- iter: 128/685
[A[ATraining Step: 203  | total loss: [1m[32m0.78647[0m[0m | time: 3.984s
[2K
| RMSProp | epoch: 010 | loss: 0.78647 - acc: 0.5201 -- iter: 160/685
[A[ATraining Step: 204  | total loss: [1m[32m0.77746[0m[0m | time: 4.590s
[2K
| RMSProp | epoch: 010 | loss: 0.77746 - acc: 0.5119 -- iter: 192/685
[A[ATraining Step: 205  | total loss: [1m[32m0.76848[0m[0m | time: 5.229s
[2K
| RMSProp | epoch: 010 | loss: 0.76848 - acc: 0.5138 -- iter: 224/685
[A[ATraining Step: 206  | total loss: [1m[32m0.76160[0m[0m | time: 5.495s
[2K
| RMSProp | epoch: 010 | loss: 0.76160 - acc: 0.4999 -- iter: 256/685
[A[ATraining Step: 207  | total loss: [1m[32m0.75498[0m[0m | time: 5.768s
[2K
| RMSProp | epoch: 010 | loss: 0.75498 - acc: 0.4884 -- iter: 288/685
[A[ATraining Step: 208  | total loss: [1m[32m0.74847[0m[0m | time: 6.373s
[2K
| RMSProp | epoch: 010 | loss: 0.74847 - acc: 0.5011 -- iter: 320/685
[A[ATraining Step: 209  | total loss: [1m[32m0.74259[0m[0m | time: 6.971s
[2K
| RMSProp | epoch: 010 | loss: 0.74259 - acc: 0.5041 -- iter: 352/685
[A[ATraining Step: 210  | total loss: [1m[32m0.73688[0m[0m | time: 7.558s
[2K
| RMSProp | epoch: 010 | loss: 0.73688 - acc: 0.5099 -- iter: 384/685
[A[ATraining Step: 211  | total loss: [1m[32m0.73680[0m[0m | time: 8.157s
[2K
| RMSProp | epoch: 010 | loss: 0.73680 - acc: 0.4965 -- iter: 416/685
[A[ATraining Step: 212  | total loss: [1m[32m0.73234[0m[0m | time: 8.761s
[2K
| RMSProp | epoch: 010 | loss: 0.73234 - acc: 0.4968 -- iter: 448/685
[A[ATraining Step: 213  | total loss: [1m[32m0.72807[0m[0m | time: 9.363s
[2K
| RMSProp | epoch: 010 | loss: 0.72807 - acc: 0.5128 -- iter: 480/685
[A[ATraining Step: 214  | total loss: [1m[32m0.72391[0m[0m | time: 9.988s
[2K
| RMSProp | epoch: 010 | loss: 0.72391 - acc: 0.5209 -- iter: 512/685
[A[ATraining Step: 215  | total loss: [1m[32m0.71938[0m[0m | time: 10.596s
[2K
| RMSProp | epoch: 010 | loss: 0.71938 - acc: 0.5281 -- iter: 544/685
[A[ATraining Step: 216  | total loss: [1m[32m0.71795[0m[0m | time: 11.198s
[2K
| RMSProp | epoch: 010 | loss: 0.71795 - acc: 0.5191 -- iter: 576/685
[A[ATraining Step: 217  | total loss: [1m[32m0.71513[0m[0m | time: 11.813s
[2K
| RMSProp | epoch: 010 | loss: 0.71513 - acc: 0.5172 -- iter: 608/685
[A[ATraining Step: 218  | total loss: [1m[32m0.71372[0m[0m | time: 12.411s
[2K
| RMSProp | epoch: 010 | loss: 0.71372 - acc: 0.4998 -- iter: 640/685
[A[ATraining Step: 219  | total loss: [1m[32m0.71151[0m[0m | time: 13.007s
[2K
| RMSProp | epoch: 010 | loss: 0.71151 - acc: 0.5092 -- iter: 672/685
[A[ATraining Step: 220  | total loss: [1m[32m0.70999[0m[0m | time: 14.604s
[2K
| RMSProp | epoch: 010 | loss: 0.70999 - acc: 0.4895 | val_loss: 0.68888 - val_acc: 0.7209 -- iter: 685/685
--
Training Step: 221  | total loss: [1m[32m0.70816[0m[0m | time: 0.609s
[2K
| RMSProp | epoch: 011 | loss: 0.70816 - acc: 0.5000 -- iter: 032/685
[A[ATraining Step: 222  | total loss: [1m[32m0.70610[0m[0m | time: 1.215s
[2K
| RMSProp | epoch: 011 | loss: 0.70610 - acc: 0.5343 -- iter: 064/685
[A[ATraining Step: 223  | total loss: [1m[32m0.70428[0m[0m | time: 1.816s
[2K
| RMSProp | epoch: 011 | loss: 0.70428 - acc: 0.5403 -- iter: 096/685
[A[ATraining Step: 224  | total loss: [1m[32m0.70306[0m[0m | time: 2.416s
[2K
| RMSProp | epoch: 011 | loss: 0.70306 - acc: 0.5363 -- iter: 128/685
[A[ATraining Step: 225  | total loss: [1m[32m0.70048[0m[0m | time: 3.013s
[2K
| RMSProp | epoch: 011 | loss: 0.70048 - acc: 0.5389 -- iter: 160/685
[A[ATraining Step: 226  | total loss: [1m[32m0.69820[0m[0m | time: 3.616s
[2K
| RMSProp | epoch: 011 | loss: 0.69820 - acc: 0.5350 -- iter: 192/685
[A[ATraining Step: 227  | total loss: [1m[32m0.69862[0m[0m | time: 4.216s
[2K
| RMSProp | epoch: 011 | loss: 0.69862 - acc: 0.5221 -- iter: 224/685
[A[ATraining Step: 228  | total loss: [1m[32m0.69736[0m[0m | time: 4.812s
[2K
| RMSProp | epoch: 011 | loss: 0.69736 - acc: 0.5418 -- iter: 256/685
[A[ATraining Step: 229  | total loss: [1m[32m0.69515[0m[0m | time: 5.091s
[2K
| RMSProp | epoch: 011 | loss: 0.69515 - acc: 0.5470 -- iter: 288/685
[A[ATraining Step: 230  | total loss: [1m[32m0.69326[0m[0m | time: 5.365s
[2K
| RMSProp | epoch: 011 | loss: 0.69326 - acc: 0.5384 -- iter: 320/685
[A[ATraining Step: 231  | total loss: [1m[32m0.69005[0m[0m | time: 5.969s
[2K
| RMSProp | epoch: 011 | loss: 0.69005 - acc: 0.5461 -- iter: 352/685
[A[ATraining Step: 232  | total loss: [1m[32m0.68833[0m[0m | time: 6.608s
[2K
| RMSProp | epoch: 011 | loss: 0.68833 - acc: 0.5353 -- iter: 384/685
[A[ATraining Step: 233  | total loss: [1m[32m0.68936[0m[0m | time: 7.215s
[2K
| RMSProp | epoch: 011 | loss: 0.68936 - acc: 0.5255 -- iter: 416/685
[A[ATraining Step: 234  | total loss: [1m[32m0.68938[0m[0m | time: 7.864s
[2K
| RMSProp | epoch: 011 | loss: 0.68938 - acc: 0.5292 -- iter: 448/685
[A[ATraining Step: 235  | total loss: [1m[32m0.69092[0m[0m | time: 8.449s
[2K
| RMSProp | epoch: 011 | loss: 0.69092 - acc: 0.5106 -- iter: 480/685
[A[ATraining Step: 236  | total loss: [1m[32m0.69098[0m[0m | time: 9.094s
[2K
| RMSProp | epoch: 011 | loss: 0.69098 - acc: 0.5127 -- iter: 512/685
[A[ATraining Step: 237  | total loss: [1m[32m0.69143[0m[0m | time: 9.693s
[2K
| RMSProp | epoch: 011 | loss: 0.69143 - acc: 0.5052 -- iter: 544/685
[A[ATraining Step: 238  | total loss: [1m[32m0.69120[0m[0m | time: 10.288s
[2K
| RMSProp | epoch: 011 | loss: 0.69120 - acc: 0.5328 -- iter: 576/685
[A[ATraining Step: 239  | total loss: [1m[32m0.69357[0m[0m | time: 10.908s
[2K
| RMSProp | epoch: 011 | loss: 0.69357 - acc: 0.5264 -- iter: 608/685
[A[ATraining Step: 240  | total loss: [1m[32m0.69323[0m[0m | time: 11.504s
[2K
| RMSProp | epoch: 011 | loss: 0.69323 - acc: 0.5175 -- iter: 640/685
[A[ATraining Step: 241  | total loss: [1m[32m0.69265[0m[0m | time: 12.121s
[2K
| RMSProp | epoch: 011 | loss: 0.69265 - acc: 0.5345 -- iter: 672/685
[A[ATraining Step: 242  | total loss: [1m[32m0.69174[0m[0m | time: 13.738s
[2K
| RMSProp | epoch: 011 | loss: 0.69174 - acc: 0.5342 | val_loss: 0.67196 - val_acc: 0.4791 -- iter: 685/685
--
Training Step: 243  | total loss: [1m[32m0.69089[0m[0m | time: 0.608s
[2K
| RMSProp | epoch: 012 | loss: 0.69089 - acc: 0.5276 -- iter: 032/685
[A[ATraining Step: 244  | total loss: [1m[32m0.68760[0m[0m | time: 1.203s
[2K
| RMSProp | epoch: 012 | loss: 0.68760 - acc: 0.5280 -- iter: 064/685
[A[ATraining Step: 245  | total loss: [1m[32m0.69567[0m[0m | time: 1.803s
[2K
| RMSProp | epoch: 012 | loss: 0.69567 - acc: 0.5283 -- iter: 096/685
[A[ATraining Step: 246  | total loss: [1m[32m0.69608[0m[0m | time: 2.393s
[2K
| RMSProp | epoch: 012 | loss: 0.69608 - acc: 0.5130 -- iter: 128/685
[A[ATraining Step: 247  | total loss: [1m[32m0.69563[0m[0m | time: 3.004s
[2K
| RMSProp | epoch: 012 | loss: 0.69563 - acc: 0.5117 -- iter: 160/685
[A[ATraining Step: 248  | total loss: [1m[32m0.69523[0m[0m | time: 3.606s
[2K
| RMSProp | epoch: 012 | loss: 0.69523 - acc: 0.5105 -- iter: 192/685
[A[ATraining Step: 249  | total loss: [1m[32m0.69391[0m[0m | time: 4.231s
[2K
| RMSProp | epoch: 012 | loss: 0.69391 - acc: 0.5095 -- iter: 224/685
[A[ATraining Step: 250  | total loss: [1m[32m0.69331[0m[0m | time: 4.836s
[2K
| RMSProp | epoch: 012 | loss: 0.69331 - acc: 0.4960 -- iter: 256/685
[A[ATraining Step: 251  | total loss: [1m[32m0.69157[0m[0m | time: 5.452s
[2K
| RMSProp | epoch: 012 | loss: 0.69157 - acc: 0.5339 -- iter: 288/685
[A[ATraining Step: 252  | total loss: [1m[32m0.68902[0m[0m | time: 5.725s
[2K
| RMSProp | epoch: 012 | loss: 0.68902 - acc: 0.5587 -- iter: 320/685
[A[ATraining Step: 253  | total loss: [1m[32m0.69075[0m[0m | time: 6.008s
[2K
| RMSProp | epoch: 012 | loss: 0.69075 - acc: 0.5412 -- iter: 352/685
[A[ATraining Step: 254  | total loss: [1m[32m0.68877[0m[0m | time: 6.620s
[2K
| RMSProp | epoch: 012 | loss: 0.68877 - acc: 0.5640 -- iter: 384/685
[A[ATraining Step: 255  | total loss: [1m[32m0.68768[0m[0m | time: 7.217s
[2K
| RMSProp | epoch: 012 | loss: 0.68768 - acc: 0.5701 -- iter: 416/685
[A[ATraining Step: 256  | total loss: [1m[32m0.68307[0m[0m | time: 7.824s
[2K
| RMSProp | epoch: 012 | loss: 0.68307 - acc: 0.5944 -- iter: 448/685
[A[ATraining Step: 257  | total loss: [1m[32m0.68242[0m[0m | time: 8.421s
[2K
| RMSProp | epoch: 012 | loss: 0.68242 - acc: 0.5849 -- iter: 480/685
[A[ATraining Step: 258  | total loss: [1m[32m0.67872[0m[0m | time: 9.022s
[2K
| RMSProp | epoch: 012 | loss: 0.67872 - acc: 0.6046 -- iter: 512/685
[A[ATraining Step: 259  | total loss: [1m[32m0.67314[0m[0m | time: 9.628s
[2K
| RMSProp | epoch: 012 | loss: 0.67314 - acc: 0.6004 -- iter: 544/685
[A[ATraining Step: 260  | total loss: [1m[32m0.66479[0m[0m | time: 10.242s
[2K
| RMSProp | epoch: 012 | loss: 0.66479 - acc: 0.6185 -- iter: 576/685
[A[ATraining Step: 261  | total loss: [1m[32m0.66239[0m[0m | time: 10.836s
[2K
| RMSProp | epoch: 012 | loss: 0.66239 - acc: 0.6129 -- iter: 608/685
[A[ATraining Step: 262  | total loss: [1m[32m0.66249[0m[0m | time: 11.458s
[2K
| RMSProp | epoch: 012 | loss: 0.66249 - acc: 0.6234 -- iter: 640/685
[A[ATraining Step: 263  | total loss: [1m[32m0.66051[0m[0m | time: 12.048s
[2K
| RMSProp | epoch: 012 | loss: 0.66051 - acc: 0.6205 -- iter: 672/685
[A[ATraining Step: 264  | total loss: [1m[32m0.65475[0m[0m | time: 13.662s
[2K
| RMSProp | epoch: 012 | loss: 0.65475 - acc: 0.6303 | val_loss: 0.53261 - val_acc: 0.7628 -- iter: 685/685
--
Training Step: 265  | total loss: [1m[32m0.64291[0m[0m | time: 0.607s
[2K
| RMSProp | epoch: 013 | loss: 0.64291 - acc: 0.6516 -- iter: 032/685
[A[ATraining Step: 266  | total loss: [1m[32m0.63296[0m[0m | time: 1.208s
[2K
| RMSProp | epoch: 013 | loss: 0.63296 - acc: 0.6521 -- iter: 064/685
[A[ATraining Step: 267  | total loss: [1m[32m0.68714[0m[0m | time: 1.816s
[2K
| RMSProp | epoch: 013 | loss: 0.68714 - acc: 0.6369 -- iter: 096/685
[A[ATraining Step: 268  | total loss: [1m[32m0.67658[0m[0m | time: 2.422s
[2K
| RMSProp | epoch: 013 | loss: 0.67658 - acc: 0.6701 -- iter: 128/685
[A[ATraining Step: 269  | total loss: [1m[32m0.67173[0m[0m | time: 3.043s
[2K
| RMSProp | epoch: 013 | loss: 0.67173 - acc: 0.6687 -- iter: 160/685
[A[ATraining Step: 270  | total loss: [1m[32m0.65720[0m[0m | time: 3.647s
[2K
| RMSProp | epoch: 013 | loss: 0.65720 - acc: 0.6925 -- iter: 192/685
[A[ATraining Step: 271  | total loss: [1m[32m0.64095[0m[0m | time: 4.243s
[2K
| RMSProp | epoch: 013 | loss: 0.64095 - acc: 0.7045 -- iter: 224/685
[A[ATraining Step: 272  | total loss: [1m[32m0.63190[0m[0m | time: 4.850s
[2K
| RMSProp | epoch: 013 | loss: 0.63190 - acc: 0.7059 -- iter: 256/685
[A[ATraining Step: 273  | total loss: [1m[32m0.62390[0m[0m | time: 5.444s
[2K
| RMSProp | epoch: 013 | loss: 0.62390 - acc: 0.7134 -- iter: 288/685
[A[ATraining Step: 274  | total loss: [1m[32m0.61898[0m[0m | time: 6.033s
[2K
| RMSProp | epoch: 013 | loss: 0.61898 - acc: 0.7108 -- iter: 320/685
[A[ATraining Step: 275  | total loss: [1m[32m0.60925[0m[0m | time: 6.301s
[2K
| RMSProp | epoch: 013 | loss: 0.60925 - acc: 0.7272 -- iter: 352/685
[A[ATraining Step: 276  | total loss: [1m[32m0.60216[0m[0m | time: 6.592s
[2K
| RMSProp | epoch: 013 | loss: 0.60216 - acc: 0.7238 -- iter: 384/685
[A[ATraining Step: 277  | total loss: [1m[32m0.58578[0m[0m | time: 7.204s
[2K
| RMSProp | epoch: 013 | loss: 0.58578 - acc: 0.7437 -- iter: 416/685
[A[ATraining Step: 278  | total loss: [1m[32m0.57269[0m[0m | time: 7.813s
[2K
| RMSProp | epoch: 013 | loss: 0.57269 - acc: 0.7443 -- iter: 448/685
[A[ATraining Step: 279  | total loss: [1m[32m0.56052[0m[0m | time: 8.426s
[2K
| RMSProp | epoch: 013 | loss: 0.56052 - acc: 0.7543 -- iter: 480/685
[A[ATraining Step: 280  | total loss: [1m[32m0.60278[0m[0m | time: 9.034s
[2K
| RMSProp | epoch: 013 | loss: 0.60278 - acc: 0.7226 -- iter: 512/685
[A[ATraining Step: 281  | total loss: [1m[32m0.60004[0m[0m | time: 9.637s
[2K
| RMSProp | epoch: 013 | loss: 0.60004 - acc: 0.7222 -- iter: 544/685
[A[ATraining Step: 282  | total loss: [1m[32m0.59263[0m[0m | time: 10.264s
[2K
| RMSProp | epoch: 013 | loss: 0.59263 - acc: 0.7281 -- iter: 576/685
[A[ATraining Step: 283  | total loss: [1m[32m0.58154[0m[0m | time: 10.875s
[2K
| RMSProp | epoch: 013 | loss: 0.58154 - acc: 0.7334 -- iter: 608/685
[A[ATraining Step: 284  | total loss: [1m[32m0.57017[0m[0m | time: 11.473s
[2K
| RMSProp | epoch: 013 | loss: 0.57017 - acc: 0.7351 -- iter: 640/685
[A[ATraining Step: 285  | total loss: [1m[32m0.54560[0m[0m | time: 12.094s
[2K
| RMSProp | epoch: 013 | loss: 0.54560 - acc: 0.7522 -- iter: 672/685
[A[ATraining Step: 286  | total loss: [1m[32m0.53677[0m[0m | time: 13.685s
[2K
| RMSProp | epoch: 013 | loss: 0.53677 - acc: 0.7520 | val_loss: 0.61568 - val_acc: 0.6930 -- iter: 685/685
--
Training Step: 287  | total loss: [1m[32m0.51669[0m[0m | time: 0.603s
[2K
| RMSProp | epoch: 014 | loss: 0.51669 - acc: 0.7643 -- iter: 032/685
[A[ATraining Step: 288  | total loss: [1m[32m0.53543[0m[0m | time: 1.200s
[2K
| RMSProp | epoch: 014 | loss: 0.53543 - acc: 0.7535 -- iter: 064/685
[A[ATraining Step: 289  | total loss: [1m[32m0.53993[0m[0m | time: 1.805s
[2K
| RMSProp | epoch: 014 | loss: 0.53993 - acc: 0.7563 -- iter: 096/685
[A[ATraining Step: 290  | total loss: [1m[32m0.53082[0m[0m | time: 2.409s
[2K
| RMSProp | epoch: 014 | loss: 0.53082 - acc: 0.7556 -- iter: 128/685
[A[ATraining Step: 291  | total loss: [1m[32m0.51696[0m[0m | time: 3.001s
[2K
| RMSProp | epoch: 014 | loss: 0.51696 - acc: 0.7676 -- iter: 160/685
[A[ATraining Step: 292  | total loss: [1m[32m0.49714[0m[0m | time: 3.596s
[2K
| RMSProp | epoch: 014 | loss: 0.49714 - acc: 0.7783 -- iter: 192/685
[A[ATraining Step: 293  | total loss: [1m[32m0.48316[0m[0m | time: 4.209s
[2K
| RMSProp | epoch: 014 | loss: 0.48316 - acc: 0.7849 -- iter: 224/685
[A[ATraining Step: 294  | total loss: [1m[32m0.46452[0m[0m | time: 4.814s
[2K
| RMSProp | epoch: 014 | loss: 0.46452 - acc: 0.7907 -- iter: 256/685
[A[ATraining Step: 295  | total loss: [1m[32m0.49396[0m[0m | time: 5.407s
[2K
| RMSProp | epoch: 014 | loss: 0.49396 - acc: 0.7773 -- iter: 288/685
[A[ATraining Step: 296  | total loss: [1m[32m0.48223[0m[0m | time: 6.002s
[2K
| RMSProp | epoch: 014 | loss: 0.48223 - acc: 0.7777 -- iter: 320/685
[A[ATraining Step: 297  | total loss: [1m[32m0.47816[0m[0m | time: 6.593s
[2K
| RMSProp | epoch: 014 | loss: 0.47816 - acc: 0.7749 -- iter: 352/685
[A[ATraining Step: 298  | total loss: [1m[32m0.47615[0m[0m | time: 6.863s
[2K
| RMSProp | epoch: 014 | loss: 0.47615 - acc: 0.7787 -- iter: 384/685
[A[ATraining Step: 299  | total loss: [1m[32m0.46997[0m[0m | time: 7.137s
[2K
| RMSProp | epoch: 014 | loss: 0.46997 - acc: 0.7777 -- iter: 416/685
[A[ATraining Step: 300  | total loss: [1m[32m0.45430[0m[0m | time: 7.735s
[2K
| RMSProp | epoch: 014 | loss: 0.45430 - acc: 0.7923 -- iter: 448/685
[A[ATraining Step: 301  | total loss: [1m[32m0.45007[0m[0m | time: 8.350s
[2K
| RMSProp | epoch: 014 | loss: 0.45007 - acc: 0.7912 -- iter: 480/685
[A[ATraining Step: 302  | total loss: [1m[32m0.45987[0m[0m | time: 8.947s
[2K
| RMSProp | epoch: 014 | loss: 0.45987 - acc: 0.7839 -- iter: 512/685
[A[ATraining Step: 303  | total loss: [1m[32m0.50771[0m[0m | time: 9.549s
[2K
| RMSProp | epoch: 014 | loss: 0.50771 - acc: 0.7524 -- iter: 544/685
[A[ATraining Step: 304  | total loss: [1m[32m0.49590[0m[0m | time: 10.141s
[2K
| RMSProp | epoch: 014 | loss: 0.49590 - acc: 0.7709 -- iter: 576/685
[A[ATraining Step: 305  | total loss: [1m[32m0.48451[0m[0m | time: 10.753s
[2K
| RMSProp | epoch: 014 | loss: 0.48451 - acc: 0.7813 -- iter: 608/685
[A[ATraining Step: 306  | total loss: [1m[32m0.46213[0m[0m | time: 11.347s
[2K
| RMSProp | epoch: 014 | loss: 0.46213 - acc: 0.7969 -- iter: 640/685
[A[ATraining Step: 307  | total loss: [1m[32m0.44517[0m[0m | time: 11.945s
[2K
| RMSProp | epoch: 014 | loss: 0.44517 - acc: 0.8079 -- iter: 672/685
[A[ATraining Step: 308  | total loss: [1m[32m0.43401[0m[0m | time: 13.633s
[2K
| RMSProp | epoch: 014 | loss: 0.43401 - acc: 0.8115 | val_loss: 1.02087 - val_acc: 0.5767 -- iter: 685/685
--
Training Step: 309  | total loss: [1m[32m0.43022[0m[0m | time: 0.610s
[2K
| RMSProp | epoch: 015 | loss: 0.43022 - acc: 0.8116 -- iter: 032/685
[A[ATraining Step: 310  | total loss: [1m[32m0.51632[0m[0m | time: 1.206s
[2K
| RMSProp | epoch: 015 | loss: 0.51632 - acc: 0.7835 -- iter: 064/685
[A[ATraining Step: 311  | total loss: [1m[32m0.50196[0m[0m | time: 1.829s
[2K
| RMSProp | epoch: 015 | loss: 0.50196 - acc: 0.7989 -- iter: 096/685
[A[ATraining Step: 312  | total loss: [1m[32m0.48200[0m[0m | time: 2.432s
[2K
| RMSProp | epoch: 015 | loss: 0.48200 - acc: 0.8097 -- iter: 128/685
[A[ATraining Step: 313  | total loss: [1m[32m0.46575[0m[0m | time: 3.074s
[2K
| RMSProp | epoch: 015 | loss: 0.46575 - acc: 0.8193 -- iter: 160/685
[A[ATraining Step: 314  | total loss: [1m[32m0.45008[0m[0m | time: 3.677s
[2K
| RMSProp | epoch: 015 | loss: 0.45008 - acc: 0.8280 -- iter: 192/685
[A[ATraining Step: 315  | total loss: [1m[32m0.49920[0m[0m | time: 4.282s
[2K
| RMSProp | epoch: 015 | loss: 0.49920 - acc: 0.8077 -- iter: 224/685
[A[ATraining Step: 316  | total loss: [1m[32m0.50442[0m[0m | time: 4.882s
[2K
| RMSProp | epoch: 015 | loss: 0.50442 - acc: 0.7926 -- iter: 256/685
[A[ATraining Step: 317  | total loss: [1m[32m0.49769[0m[0m | time: 5.482s
[2K
| RMSProp | epoch: 015 | loss: 0.49769 - acc: 0.8008 -- iter: 288/685
[A[ATraining Step: 318  | total loss: [1m[32m0.47152[0m[0m | time: 6.095s
[2K
| RMSProp | epoch: 015 | loss: 0.47152 - acc: 0.8176 -- iter: 320/685
[A[ATraining Step: 319  | total loss: [1m[32m0.45055[0m[0m | time: 6.695s
[2K
| RMSProp | epoch: 015 | loss: 0.45055 - acc: 0.8296 -- iter: 352/685
[A[ATraining Step: 320  | total loss: [1m[32m0.44257[0m[0m | time: 7.297s
[2K
| RMSProp | epoch: 015 | loss: 0.44257 - acc: 0.8310 -- iter: 384/685
[A[ATraining Step: 321  | total loss: [1m[32m0.44188[0m[0m | time: 7.589s
[2K
| RMSProp | epoch: 015 | loss: 0.44188 - acc: 0.8323 -- iter: 416/685
[A[ATraining Step: 322  | total loss: [1m[32m0.41276[0m[0m | time: 7.858s
[2K
| RMSProp | epoch: 015 | loss: 0.41276 - acc: 0.8414 -- iter: 448/685
[A[ATraining Step: 323  | total loss: [1m[32m0.37781[0m[0m | time: 8.477s
[2K
| RMSProp | epoch: 015 | loss: 0.37781 - acc: 0.8572 -- iter: 480/685
[A[ATraining Step: 324  | total loss: [1m[32m0.36814[0m[0m | time: 9.081s
[2K
| RMSProp | epoch: 015 | loss: 0.36814 - acc: 0.8590 -- iter: 512/685
[A[ATraining Step: 325  | total loss: [1m[32m0.36690[0m[0m | time: 9.680s
[2K
| RMSProp | epoch: 015 | loss: 0.36690 - acc: 0.8637 -- iter: 544/685
[A[ATraining Step: 326  | total loss: [1m[32m0.36791[0m[0m | time: 10.279s
[2K
| RMSProp | epoch: 015 | loss: 0.36791 - acc: 0.8555 -- iter: 576/685
[A[ATraining Step: 327  | total loss: [1m[32m0.37241[0m[0m | time: 10.871s
[2K
| RMSProp | epoch: 015 | loss: 0.37241 - acc: 0.8481 -- iter: 608/685
[A[ATraining Step: 328  | total loss: [1m[32m0.37648[0m[0m | time: 11.474s
[2K
| RMSProp | epoch: 015 | loss: 0.37648 - acc: 0.8476 -- iter: 640/685
[A[ATraining Step: 329  | total loss: [1m[32m0.37523[0m[0m | time: 12.096s
[2K
| RMSProp | epoch: 015 | loss: 0.37523 - acc: 0.8535 -- iter: 672/685
[A[ATraining Step: 330  | total loss: [1m[32m0.36046[0m[0m | time: 13.694s
[2K
| RMSProp | epoch: 015 | loss: 0.36046 - acc: 0.8588 | val_loss: 0.47086 - val_acc: 0.8000 -- iter: 685/685
--
Training Step: 331  | total loss: [1m[32m0.34289[0m[0m | time: 0.603s
[2K
| RMSProp | epoch: 016 | loss: 0.34289 - acc: 0.8666 -- iter: 032/685
[A[ATraining Step: 332  | total loss: [1m[32m0.36905[0m[0m | time: 1.203s
[2K
| RMSProp | epoch: 016 | loss: 0.36905 - acc: 0.8487 -- iter: 064/685
[A[ATraining Step: 333  | total loss: [1m[32m0.39489[0m[0m | time: 1.814s
[2K
| RMSProp | epoch: 016 | loss: 0.39489 - acc: 0.8389 -- iter: 096/685
[A[ATraining Step: 334  | total loss: [1m[32m0.38217[0m[0m | time: 2.405s
[2K
| RMSProp | epoch: 016 | loss: 0.38217 - acc: 0.8456 -- iter: 128/685
[A[ATraining Step: 335  | total loss: [1m[32m0.37534[0m[0m | time: 3.003s
[2K
| RMSProp | epoch: 016 | loss: 0.37534 - acc: 0.8517 -- iter: 160/685
[A[ATraining Step: 336  | total loss: [1m[32m0.38900[0m[0m | time: 3.603s
[2K
| RMSProp | epoch: 016 | loss: 0.38900 - acc: 0.8415 -- iter: 192/685
[A[ATraining Step: 337  | total loss: [1m[32m0.37177[0m[0m | time: 4.204s
[2K
| RMSProp | epoch: 016 | loss: 0.37177 - acc: 0.8542 -- iter: 224/685
[A[ATraining Step: 338  | total loss: [1m[32m0.37674[0m[0m | time: 4.819s
[2K
| RMSProp | epoch: 016 | loss: 0.37674 - acc: 0.8438 -- iter: 256/685
[A[ATraining Step: 339  | total loss: [1m[32m0.36758[0m[0m | time: 5.446s
[2K
| RMSProp | epoch: 016 | loss: 0.36758 - acc: 0.8469 -- iter: 288/685
[A[ATraining Step: 340  | total loss: [1m[32m0.36468[0m[0m | time: 6.069s
[2K
| RMSProp | epoch: 016 | loss: 0.36468 - acc: 0.8435 -- iter: 320/685
[A[ATraining Step: 341  | total loss: [1m[32m0.37757[0m[0m | time: 6.668s
[2K
| RMSProp | epoch: 016 | loss: 0.37757 - acc: 0.8310 -- iter: 352/685
[A[ATraining Step: 342  | total loss: [1m[32m0.37817[0m[0m | time: 7.274s
[2K
| RMSProp | epoch: 016 | loss: 0.37817 - acc: 0.8323 -- iter: 384/685
[A[ATraining Step: 343  | total loss: [1m[32m0.37913[0m[0m | time: 7.883s
[2K
| RMSProp | epoch: 016 | loss: 0.37913 - acc: 0.8272 -- iter: 416/685
[A[ATraining Step: 344  | total loss: [1m[32m0.38670[0m[0m | time: 8.160s
[2K
| RMSProp | epoch: 016 | loss: 0.38670 - acc: 0.8288 -- iter: 448/685
[A[ATraining Step: 345  | total loss: [1m[32m0.36825[0m[0m | time: 8.437s
[2K
| RMSProp | epoch: 016 | loss: 0.36825 - acc: 0.8383 -- iter: 480/685
[A[ATraining Step: 346  | total loss: [1m[32m0.34099[0m[0m | time: 9.036s
[2K
| RMSProp | epoch: 016 | loss: 0.34099 - acc: 0.8544 -- iter: 512/685
[A[ATraining Step: 347  | total loss: [1m[32m0.33280[0m[0m | time: 9.641s
[2K
| RMSProp | epoch: 016 | loss: 0.33280 - acc: 0.8534 -- iter: 544/685
[A[ATraining Step: 348  | total loss: [1m[32m0.30909[0m[0m | time: 10.243s
[2K
| RMSProp | epoch: 016 | loss: 0.30909 - acc: 0.8649 -- iter: 576/685
[A[ATraining Step: 349  | total loss: [1m[32m0.29789[0m[0m | time: 10.835s
[2K
| RMSProp | epoch: 016 | loss: 0.29789 - acc: 0.8690 -- iter: 608/685
[A[ATraining Step: 350  | total loss: [1m[32m0.32410[0m[0m | time: 11.432s
[2K
| RMSProp | epoch: 016 | loss: 0.32410 - acc: 0.8571 -- iter: 640/685
[A[ATraining Step: 351  | total loss: [1m[32m0.33064[0m[0m | time: 12.012s
[2K
| RMSProp | epoch: 016 | loss: 0.33064 - acc: 0.8558 -- iter: 672/685
[A[ATraining Step: 352  | total loss: [1m[32m0.33183[0m[0m | time: 13.621s
[2K
| RMSProp | epoch: 016 | loss: 0.33183 - acc: 0.8483 | val_loss: 0.43783 - val_acc: 0.7860 -- iter: 685/685
--
Training Step: 353  | total loss: [1m[32m0.32991[0m[0m | time: 0.623s
[2K
| RMSProp | epoch: 017 | loss: 0.32991 - acc: 0.8510 -- iter: 032/685
[A[ATraining Step: 354  | total loss: [1m[32m0.33018[0m[0m | time: 1.238s
[2K
| RMSProp | epoch: 017 | loss: 0.33018 - acc: 0.8472 -- iter: 064/685
[A[ATraining Step: 355  | total loss: [1m[32m0.32807[0m[0m | time: 1.842s
[2K
| RMSProp | epoch: 017 | loss: 0.32807 - acc: 0.8531 -- iter: 096/685
[A[ATraining Step: 356  | total loss: [1m[32m0.32401[0m[0m | time: 2.435s
[2K
| RMSProp | epoch: 017 | loss: 0.32401 - acc: 0.8553 -- iter: 128/685
[A[ATraining Step: 357  | total loss: [1m[32m0.31663[0m[0m | time: 3.038s
[2K
| RMSProp | epoch: 017 | loss: 0.31663 - acc: 0.8541 -- iter: 160/685
[A[ATraining Step: 358  | total loss: [1m[32m0.30471[0m[0m | time: 3.653s
[2K
| RMSProp | epoch: 017 | loss: 0.30471 - acc: 0.8593 -- iter: 192/685
[A[ATraining Step: 359  | total loss: [1m[32m0.31534[0m[0m | time: 4.249s
[2K
| RMSProp | epoch: 017 | loss: 0.31534 - acc: 0.8515 -- iter: 224/685
[A[ATraining Step: 360  | total loss: [1m[32m0.33586[0m[0m | time: 4.860s
[2K
| RMSProp | epoch: 017 | loss: 0.33586 - acc: 0.8476 -- iter: 256/685
[A[ATraining Step: 361  | total loss: [1m[32m0.33553[0m[0m | time: 5.461s
[2K
| RMSProp | epoch: 017 | loss: 0.33553 - acc: 0.8441 -- iter: 288/685
[A[ATraining Step: 362  | total loss: [1m[32m0.33915[0m[0m | time: 6.065s
[2K
| RMSProp | epoch: 017 | loss: 0.33915 - acc: 0.8409 -- iter: 320/685
[A[ATraining Step: 363  | total loss: [1m[32m0.31791[0m[0m | time: 6.667s
[2K
| RMSProp | epoch: 017 | loss: 0.31791 - acc: 0.8568 -- iter: 352/685
[A[ATraining Step: 364  | total loss: [1m[32m0.32104[0m[0m | time: 7.263s
[2K
| RMSProp | epoch: 017 | loss: 0.32104 - acc: 0.8587 -- iter: 384/685
[A[ATraining Step: 365  | total loss: [1m[32m0.31779[0m[0m | time: 7.855s
[2K
| RMSProp | epoch: 017 | loss: 0.31779 - acc: 0.8665 -- iter: 416/685
[A[ATraining Step: 366  | total loss: [1m[32m0.31158[0m[0m | time: 8.457s
[2K
| RMSProp | epoch: 017 | loss: 0.31158 - acc: 0.8674 -- iter: 448/685
[A[ATraining Step: 367  | total loss: [1m[32m0.30495[0m[0m | time: 8.729s
[2K
| RMSProp | epoch: 017 | loss: 0.30495 - acc: 0.8744 -- iter: 480/685
[A[ATraining Step: 368  | total loss: [1m[32m0.30417[0m[0m | time: 8.997s
[2K
| RMSProp | epoch: 017 | loss: 0.30417 - acc: 0.8793 -- iter: 512/685
[A[ATraining Step: 369  | total loss: [1m[32m0.28932[0m[0m | time: 9.634s
[2K
| RMSProp | epoch: 017 | loss: 0.28932 - acc: 0.8837 -- iter: 544/685
[A[ATraining Step: 370  | total loss: [1m[32m0.27896[0m[0m | time: 10.236s
[2K
| RMSProp | epoch: 017 | loss: 0.27896 - acc: 0.8922 -- iter: 576/685
[A[ATraining Step: 371  | total loss: [1m[32m0.27254[0m[0m | time: 10.831s
[2K
| RMSProp | epoch: 017 | loss: 0.27254 - acc: 0.8904 -- iter: 608/685
[A[ATraining Step: 372  | total loss: [1m[32m0.27318[0m[0m | time: 11.445s
[2K
| RMSProp | epoch: 017 | loss: 0.27318 - acc: 0.8889 -- iter: 640/685
[A[ATraining Step: 373  | total loss: [1m[32m0.30714[0m[0m | time: 12.042s
[2K
| RMSProp | epoch: 017 | loss: 0.30714 - acc: 0.8781 -- iter: 672/685
[A[ATraining Step: 374  | total loss: [1m[32m0.30106[0m[0m | time: 13.640s
[2K
| RMSProp | epoch: 017 | loss: 0.30106 - acc: 0.8747 | val_loss: 0.44944 - val_acc: 0.8326 -- iter: 685/685
--
Training Step: 375  | total loss: [1m[32m0.30089[0m[0m | time: 0.609s
[2K
| RMSProp | epoch: 018 | loss: 0.30089 - acc: 0.8779 -- iter: 032/685
[A[ATraining Step: 376  | total loss: [1m[32m0.28580[0m[0m | time: 1.215s
[2K
| RMSProp | epoch: 018 | loss: 0.28580 - acc: 0.8869 -- iter: 064/685
[A[ATraining Step: 377  | total loss: [1m[32m0.27333[0m[0m | time: 1.842s
[2K
| RMSProp | epoch: 018 | loss: 0.27333 - acc: 0.8920 -- iter: 096/685
[A[ATraining Step: 378  | total loss: [1m[32m0.26003[0m[0m | time: 2.452s
[2K
| RMSProp | epoch: 018 | loss: 0.26003 - acc: 0.8965 -- iter: 128/685
[A[ATraining Step: 379  | total loss: [1m[32m0.26041[0m[0m | time: 3.046s
[2K
| RMSProp | epoch: 018 | loss: 0.26041 - acc: 0.8975 -- iter: 160/685
[A[ATraining Step: 380  | total loss: [1m[32m0.25962[0m[0m | time: 3.646s
[2K
| RMSProp | epoch: 018 | loss: 0.25962 - acc: 0.8921 -- iter: 192/685
[A[ATraining Step: 381  | total loss: [1m[32m0.26464[0m[0m | time: 4.243s
[2K
| RMSProp | epoch: 018 | loss: 0.26464 - acc: 0.8904 -- iter: 224/685
[A[ATraining Step: 382  | total loss: [1m[32m0.35432[0m[0m | time: 4.843s
[2K
| RMSProp | epoch: 018 | loss: 0.35432 - acc: 0.8639 -- iter: 256/685
[A[ATraining Step: 383  | total loss: [1m[32m0.35034[0m[0m | time: 5.441s
[2K
| RMSProp | epoch: 018 | loss: 0.35034 - acc: 0.8619 -- iter: 288/685
[A[ATraining Step: 384  | total loss: [1m[32m0.33071[0m[0m | time: 6.040s
[2K
| RMSProp | epoch: 018 | loss: 0.33071 - acc: 0.8726 -- iter: 320/685
[A[ATraining Step: 385  | total loss: [1m[32m0.30474[0m[0m | time: 6.666s
[2K
| RMSProp | epoch: 018 | loss: 0.30474 - acc: 0.8853 -- iter: 352/685
[A[ATraining Step: 386  | total loss: [1m[32m0.29963[0m[0m | time: 7.298s
[2K
| RMSProp | epoch: 018 | loss: 0.29963 - acc: 0.8843 -- iter: 384/685
[A[ATraining Step: 387  | total loss: [1m[32m0.35960[0m[0m | time: 7.903s
[2K
| RMSProp | epoch: 018 | loss: 0.35960 - acc: 0.8771 -- iter: 416/685
[A[ATraining Step: 388  | total loss: [1m[32m0.34465[0m[0m | time: 8.519s
[2K
| RMSProp | epoch: 018 | loss: 0.34465 - acc: 0.8894 -- iter: 448/685
[A[ATraining Step: 389  | total loss: [1m[32m0.32708[0m[0m | time: 9.143s
[2K
| RMSProp | epoch: 018 | loss: 0.32708 - acc: 0.8942 -- iter: 480/685
[A[ATraining Step: 390  | total loss: [1m[32m0.32551[0m[0m | time: 9.412s
[2K
| RMSProp | epoch: 018 | loss: 0.32551 - acc: 0.8923 -- iter: 512/685
[A[ATraining Step: 391  | total loss: [1m[32m0.32397[0m[0m | time: 9.679s
[2K
| RMSProp | epoch: 018 | loss: 0.32397 - acc: 0.8877 -- iter: 544/685
[A[ATraining Step: 392  | total loss: [1m[32m0.31140[0m[0m | time: 10.279s
[2K
| RMSProp | epoch: 018 | loss: 0.31140 - acc: 0.8912 -- iter: 576/685
[A[ATraining Step: 393  | total loss: [1m[32m0.30249[0m[0m | time: 10.882s
[2K
| RMSProp | epoch: 018 | loss: 0.30249 - acc: 0.8927 -- iter: 608/685
[A[ATraining Step: 394  | total loss: [1m[32m0.30250[0m[0m | time: 11.491s
[2K
| RMSProp | epoch: 018 | loss: 0.30250 - acc: 0.8847 -- iter: 640/685
[A[ATraining Step: 395  | total loss: [1m[32m0.29491[0m[0m | time: 12.121s
[2K
| RMSProp | epoch: 018 | loss: 0.29491 - acc: 0.8900 -- iter: 672/685
[A[ATraining Step: 396  | total loss: [1m[32m0.27361[0m[0m | time: 13.731s
[2K
| RMSProp | epoch: 018 | loss: 0.27361 - acc: 0.9010 | val_loss: 0.30759 - val_acc: 0.8930 -- iter: 685/685
--
Training Step: 397  | total loss: [1m[32m0.25568[0m[0m | time: 0.620s
[2K
| RMSProp | epoch: 019 | loss: 0.25568 - acc: 0.9078 -- iter: 032/685
[A[ATraining Step: 398  | total loss: [1m[32m0.23331[0m[0m | time: 1.213s
[2K
| RMSProp | epoch: 019 | loss: 0.23331 - acc: 0.9170 -- iter: 064/685
[A[ATraining Step: 399  | total loss: [1m[32m0.23779[0m[0m | time: 1.822s
[2K
| RMSProp | epoch: 019 | loss: 0.23779 - acc: 0.9159 -- iter: 096/685
[A[ATraining Step: 400  | total loss: [1m[32m0.23097[0m[0m | time: 3.424s
[2K
| RMSProp | epoch: 019 | loss: 0.23097 - acc: 0.9181 | val_loss: 0.81352 - val_acc: 0.6837 -- iter: 128/685
--
Training Step: 401  | total loss: [1m[32m0.23717[0m[0m | time: 4.024s
[2K
| RMSProp | epoch: 019 | loss: 0.23717 - acc: 0.9106 -- iter: 160/685
[A[ATraining Step: 402  | total loss: [1m[32m0.28116[0m[0m | time: 4.654s
[2K
| RMSProp | epoch: 019 | loss: 0.28116 - acc: 0.8883 -- iter: 192/685
[A[ATraining Step: 403  | total loss: [1m[32m0.28721[0m[0m | time: 5.270s
[2K
| RMSProp | epoch: 019 | loss: 0.28721 - acc: 0.8745 -- iter: 224/685
[A[ATraining Step: 404  | total loss: [1m[32m0.27586[0m[0m | time: 5.885s
[2K
| RMSProp | epoch: 019 | loss: 0.27586 - acc: 0.8808 -- iter: 256/685
[A[ATraining Step: 405  | total loss: [1m[32m0.27054[0m[0m | time: 6.479s
[2K
| RMSProp | epoch: 019 | loss: 0.27054 - acc: 0.8833 -- iter: 288/685
[A[ATraining Step: 406  | total loss: [1m[32m0.26274[0m[0m | time: 7.075s
[2K
| RMSProp | epoch: 019 | loss: 0.26274 - acc: 0.8888 -- iter: 320/685
[A[ATraining Step: 407  | total loss: [1m[32m0.25628[0m[0m | time: 7.665s
[2K
| RMSProp | epoch: 019 | loss: 0.25628 - acc: 0.8936 -- iter: 352/685
[A[ATraining Step: 408  | total loss: [1m[32m0.23777[0m[0m | time: 8.260s
[2K
| RMSProp | epoch: 019 | loss: 0.23777 - acc: 0.9043 -- iter: 384/685
[A[ATraining Step: 409  | total loss: [1m[32m0.22183[0m[0m | time: 8.831s
[2K
| RMSProp | epoch: 019 | loss: 0.22183 - acc: 0.9107 -- iter: 416/685
[A[ATraining Step: 410  | total loss: [1m[32m0.22944[0m[0m | time: 9.436s
[2K
| RMSProp | epoch: 019 | loss: 0.22944 - acc: 0.9103 -- iter: 448/685
[A[ATraining Step: 411  | total loss: [1m[32m0.26143[0m[0m | time: 10.034s
[2K
| RMSProp | epoch: 019 | loss: 0.26143 - acc: 0.8942 -- iter: 480/685
[A[ATraining Step: 412  | total loss: [1m[32m0.27416[0m[0m | time: 10.634s
[2K
| RMSProp | epoch: 019 | loss: 0.27416 - acc: 0.8861 -- iter: 512/685
[A[ATraining Step: 413  | total loss: [1m[32m0.25874[0m[0m | time: 10.905s
[2K
| RMSProp | epoch: 019 | loss: 0.25874 - acc: 0.8975 -- iter: 544/685
[A[ATraining Step: 414  | total loss: [1m[32m0.25348[0m[0m | time: 11.185s
[2K
| RMSProp | epoch: 019 | loss: 0.25348 - acc: 0.9000 -- iter: 576/685
[A[ATraining Step: 415  | total loss: [1m[32m0.25880[0m[0m | time: 11.792s
[2K
| RMSProp | epoch: 019 | loss: 0.25880 - acc: 0.9023 -- iter: 608/685
[A[ATraining Step: 416  | total loss: [1m[32m0.24946[0m[0m | time: 12.410s
[2K
| RMSProp | epoch: 019 | loss: 0.24946 - acc: 0.9058 -- iter: 640/685
[A[ATraining Step: 417  | total loss: [1m[32m0.24366[0m[0m | time: 13.017s
[2K
| RMSProp | epoch: 019 | loss: 0.24366 - acc: 0.9090 -- iter: 672/685
[A[ATraining Step: 418  | total loss: [1m[32m0.23407[0m[0m | time: 14.636s
[2K
| RMSProp | epoch: 019 | loss: 0.23407 - acc: 0.9119 | val_loss: 1.23298 - val_acc: 0.6558 -- iter: 685/685
--
Training Step: 419  | total loss: [1m[32m0.24584[0m[0m | time: 0.601s
[2K
| RMSProp | epoch: 020 | loss: 0.24584 - acc: 0.9019 -- iter: 032/685
[A[ATraining Step: 420  | total loss: [1m[32m0.28787[0m[0m | time: 1.217s
[2K
| RMSProp | epoch: 020 | loss: 0.28787 - acc: 0.8867 -- iter: 064/685
[A[ATraining Step: 421  | total loss: [1m[32m0.28134[0m[0m | time: 1.830s
[2K
| RMSProp | epoch: 020 | loss: 0.28134 - acc: 0.8887 -- iter: 096/685
[A[ATraining Step: 422  | total loss: [1m[32m0.26800[0m[0m | time: 2.430s
[2K
| RMSProp | epoch: 020 | loss: 0.26800 - acc: 0.8936 -- iter: 128/685
[A[ATraining Step: 423  | total loss: [1m[32m0.25697[0m[0m | time: 3.036s
[2K
| RMSProp | epoch: 020 | loss: 0.25697 - acc: 0.8917 -- iter: 160/685
[A[ATraining Step: 424  | total loss: [1m[32m0.23952[0m[0m | time: 3.633s
[2K
| RMSProp | epoch: 020 | loss: 0.23952 - acc: 0.8994 -- iter: 192/685
[A[ATraining Step: 425  | total loss: [1m[32m0.23824[0m[0m | time: 4.229s
[2K
| RMSProp | epoch: 020 | loss: 0.23824 - acc: 0.8970 -- iter: 224/685
[A[ATraining Step: 426  | total loss: [1m[32m0.26382[0m[0m | time: 4.828s
[2K
| RMSProp | epoch: 020 | loss: 0.26382 - acc: 0.8823 -- iter: 256/685
[A[ATraining Step: 427  | total loss: [1m[32m0.25292[0m[0m | time: 5.458s
[2K
| RMSProp | epoch: 020 | loss: 0.25292 - acc: 0.8878 -- iter: 288/685
[A[ATraining Step: 428  | total loss: [1m[32m0.25399[0m[0m | time: 6.168s
[2K
| RMSProp | epoch: 020 | loss: 0.25399 - acc: 0.8928 -- iter: 320/685
[A[ATraining Step: 429  | total loss: [1m[32m0.25315[0m[0m | time: 6.904s
[2K
| RMSProp | epoch: 020 | loss: 0.25315 - acc: 0.8910 -- iter: 352/685
[A[ATraining Step: 430  | total loss: [1m[32m0.24284[0m[0m | time: 7.622s
[2K
| RMSProp | epoch: 020 | loss: 0.24284 - acc: 0.8956 -- iter: 384/685
[A[ATraining Step: 431  | total loss: [1m[32m0.22863[0m[0m | time: 8.405s
[2K
| RMSProp | epoch: 020 | loss: 0.22863 - acc: 0.9061 -- iter: 416/685
[A[ATraining Step: 432  | total loss: [1m[32m0.21821[0m[0m | time: 9.125s
[2K
| RMSProp | epoch: 020 | loss: 0.21821 - acc: 0.9092 -- iter: 448/685
[A[ATraining Step: 433  | total loss: [1m[32m0.21272[0m[0m | time: 9.843s
[2K
| RMSProp | epoch: 020 | loss: 0.21272 - acc: 0.9152 -- iter: 480/685
[A[ATraining Step: 434  | total loss: [1m[32m0.20416[0m[0m | time: 10.529s
[2K
| RMSProp | epoch: 020 | loss: 0.20416 - acc: 0.9205 -- iter: 512/685
[A[ATraining Step: 435  | total loss: [1m[32m0.19144[0m[0m | time: 11.271s
[2K
| RMSProp | epoch: 020 | loss: 0.19144 - acc: 0.9285 -- iter: 544/685
[A[ATraining Step: 436  | total loss: [1m[32m0.18059[0m[0m | time: 11.548s
[2K
| RMSProp | epoch: 020 | loss: 0.18059 - acc: 0.9325 -- iter: 576/685
[A[ATraining Step: 437  | total loss: [1m[32m0.27131[0m[0m | time: 11.817s
[2K
| RMSProp | epoch: 020 | loss: 0.27131 - acc: 0.9162 -- iter: 608/685
[A[ATraining Step: 438  | total loss: [1m[32m0.25821[0m[0m | time: 12.412s
[2K
| RMSProp | epoch: 020 | loss: 0.25821 - acc: 0.9169 -- iter: 640/685
[A[ATraining Step: 439  | total loss: [1m[32m0.24861[0m[0m | time: 13.031s
[2K
| RMSProp | epoch: 020 | loss: 0.24861 - acc: 0.9221 -- iter: 672/685
[A[ATraining Step: 440  | total loss: [1m[32m0.24466[0m[0m | time: 14.660s
[2K
| RMSProp | epoch: 020 | loss: 0.24466 - acc: 0.9173 | val_loss: 0.38486 - val_acc: 0.8512 -- iter: 685/685
--
Training Step: 441  | total loss: [1m[32m0.24060[0m[0m | time: 0.612s
[2K
| RMSProp | epoch: 021 | loss: 0.24060 - acc: 0.9162 -- iter: 032/685
[A[ATraining Step: 442  | total loss: [1m[32m0.23828[0m[0m | time: 1.213s
[2K
| RMSProp | epoch: 021 | loss: 0.23828 - acc: 0.9152 -- iter: 064/685
[A[ATraining Step: 443  | total loss: [1m[32m0.22593[0m[0m | time: 1.815s
[2K
| RMSProp | epoch: 021 | loss: 0.22593 - acc: 0.9237 -- iter: 096/685
[A[ATraining Step: 444  | total loss: [1m[32m0.22878[0m[0m | time: 2.419s
[2K
| RMSProp | epoch: 021 | loss: 0.22878 - acc: 0.9220 -- iter: 128/685
[A[ATraining Step: 445  | total loss: [1m[32m0.23285[0m[0m | time: 3.012s
[2K
| RMSProp | epoch: 021 | loss: 0.23285 - acc: 0.9173 -- iter: 160/685
[A[ATraining Step: 446  | total loss: [1m[32m0.22048[0m[0m | time: 3.691s
[2K
| RMSProp | epoch: 021 | loss: 0.22048 - acc: 0.9224 -- iter: 192/685
[A[ATraining Step: 447  | total loss: [1m[32m0.21318[0m[0m | time: 4.381s
[2K
| RMSProp | epoch: 021 | loss: 0.21318 - acc: 0.9239 -- iter: 224/685
[A[ATraining Step: 448  | total loss: [1m[32m0.19647[0m[0m | time: 5.233s
[2K
| RMSProp | epoch: 021 | loss: 0.19647 - acc: 0.9315 -- iter: 256/685
[A[ATraining Step: 449  | total loss: [1m[32m0.19822[0m[0m | time: 6.035s
[2K
| RMSProp | epoch: 021 | loss: 0.19822 - acc: 0.9353 -- iter: 288/685
[A[ATraining Step: 450  | total loss: [1m[32m0.18332[0m[0m | time: 6.775s
[2K
| RMSProp | epoch: 021 | loss: 0.18332 - acc: 0.9417 -- iter: 320/685
[A[ATraining Step: 451  | total loss: [1m[32m0.17882[0m[0m | time: 7.504s
[2K
| RMSProp | epoch: 021 | loss: 0.17882 - acc: 0.9413 -- iter: 352/685
[A[ATraining Step: 452  | total loss: [1m[32m0.17106[0m[0m | time: 8.277s
[2K
| RMSProp | epoch: 021 | loss: 0.17106 - acc: 0.9441 -- iter: 384/685
[A[ATraining Step: 453  | total loss: [1m[32m0.15942[0m[0m | time: 8.919s
[2K
| RMSProp | epoch: 021 | loss: 0.15942 - acc: 0.9496 -- iter: 416/685
[A[ATraining Step: 454  | total loss: [1m[32m0.18642[0m[0m | time: 9.523s
[2K
| RMSProp | epoch: 021 | loss: 0.18642 - acc: 0.9359 -- iter: 448/685
[A[ATraining Step: 455  | total loss: [1m[32m0.19149[0m[0m | time: 10.135s
[2K
| RMSProp | epoch: 021 | loss: 0.19149 - acc: 0.9361 -- iter: 480/685
[A[ATraining Step: 456  | total loss: [1m[32m0.18301[0m[0m | time: 10.730s
[2K
| RMSProp | epoch: 021 | loss: 0.18301 - acc: 0.9362 -- iter: 512/685
[A[ATraining Step: 457  | total loss: [1m[32m0.16788[0m[0m | time: 11.327s
[2K
| RMSProp | epoch: 021 | loss: 0.16788 - acc: 0.9426 -- iter: 544/685
[A[ATraining Step: 458  | total loss: [1m[32m0.15692[0m[0m | time: 11.941s
[2K
| RMSProp | epoch: 021 | loss: 0.15692 - acc: 0.9452 -- iter: 576/685
[A[ATraining Step: 459  | total loss: [1m[32m0.15563[0m[0m | time: 12.285s
[2K
| RMSProp | epoch: 021 | loss: 0.15563 - acc: 0.9444 -- iter: 608/685
[A[ATraining Step: 460  | total loss: [1m[32m0.17160[0m[0m | time: 12.609s
[2K
| RMSProp | epoch: 021 | loss: 0.17160 - acc: 0.9269 -- iter: 640/685
[A[ATraining Step: 461  | total loss: [1m[32m0.16814[0m[0m | time: 13.308s
[2K
| RMSProp | epoch: 021 | loss: 0.16814 - acc: 0.9342 -- iter: 672/685
[A[ATraining Step: 462  | total loss: [1m[32m0.16063[0m[0m | time: 15.103s
[2K
| RMSProp | epoch: 021 | loss: 0.16063 - acc: 0.9377 | val_loss: 0.37292 - val_acc: 0.8977 -- iter: 685/685
--
Training Step: 463  | total loss: [1m[32m0.15512[0m[0m | time: 0.617s
[2K
| RMSProp | epoch: 022 | loss: 0.15512 - acc: 0.9408 -- iter: 032/685
[A[ATraining Step: 464  | total loss: [1m[32m0.15521[0m[0m | time: 1.280s
[2K
| RMSProp | epoch: 022 | loss: 0.15521 - acc: 0.9405 -- iter: 064/685
[A[ATraining Step: 465  | total loss: [1m[32m0.14976[0m[0m | time: 2.041s
[2K
| RMSProp | epoch: 022 | loss: 0.14976 - acc: 0.9433 -- iter: 096/685
[A[ATraining Step: 466  | total loss: [1m[32m0.15337[0m[0m | time: 2.818s
[2K
| RMSProp | epoch: 022 | loss: 0.15337 - acc: 0.9396 -- iter: 128/685
[A[ATraining Step: 467  | total loss: [1m[32m0.15657[0m[0m | time: 3.587s
[2K
| RMSProp | epoch: 022 | loss: 0.15657 - acc: 0.9425 -- iter: 160/685
[A[ATraining Step: 468  | total loss: [1m[32m0.18875[0m[0m | time: 4.334s
[2K
| RMSProp | epoch: 022 | loss: 0.18875 - acc: 0.9295 -- iter: 192/685
[A[ATraining Step: 469  | total loss: [1m[32m0.18958[0m[0m | time: 5.044s
[2K
| RMSProp | epoch: 022 | loss: 0.18958 - acc: 0.9303 -- iter: 224/685
[A[ATraining Step: 470  | total loss: [1m[32m0.17863[0m[0m | time: 5.791s
[2K
| RMSProp | epoch: 022 | loss: 0.17863 - acc: 0.9373 -- iter: 256/685
[A[ATraining Step: 471  | total loss: [1m[32m0.16914[0m[0m | time: 6.499s
[2K
| RMSProp | epoch: 022 | loss: 0.16914 - acc: 0.9404 -- iter: 288/685
[A[ATraining Step: 472  | total loss: [1m[32m0.15700[0m[0m | time: 7.113s
[2K
| RMSProp | epoch: 022 | loss: 0.15700 - acc: 0.9464 -- iter: 320/685
[A[ATraining Step: 473  | total loss: [1m[32m0.14483[0m[0m | time: 7.718s
[2K
| RMSProp | epoch: 022 | loss: 0.14483 - acc: 0.9517 -- iter: 352/685
[A[ATraining Step: 474  | total loss: [1m[32m0.14194[0m[0m | time: 8.329s
[2K
| RMSProp | epoch: 022 | loss: 0.14194 - acc: 0.9503 -- iter: 384/685
[A[ATraining Step: 475  | total loss: [1m[32m0.14487[0m[0m | time: 8.932s
[2K
| RMSProp | epoch: 022 | loss: 0.14487 - acc: 0.9490 -- iter: 416/685
[A[ATraining Step: 476  | total loss: [1m[32m0.13658[0m[0m | time: 9.551s
[2K
| RMSProp | epoch: 022 | loss: 0.13658 - acc: 0.9479 -- iter: 448/685
[A[ATraining Step: 477  | total loss: [1m[32m0.13234[0m[0m | time: 10.295s
[2K
| RMSProp | epoch: 022 | loss: 0.13234 - acc: 0.9500 -- iter: 480/685
[A[ATraining Step: 478  | total loss: [1m[32m0.12594[0m[0m | time: 11.021s
[2K
| RMSProp | epoch: 022 | loss: 0.12594 - acc: 0.9518 -- iter: 512/685
[A[ATraining Step: 479  | total loss: [1m[32m0.12099[0m[0m | time: 11.771s
[2K
| RMSProp | epoch: 022 | loss: 0.12099 - acc: 0.9504 -- iter: 544/685
[A[ATraining Step: 480  | total loss: [1m[32m0.13120[0m[0m | time: 12.473s
[2K
| RMSProp | epoch: 022 | loss: 0.13120 - acc: 0.9460 -- iter: 576/685
[A[ATraining Step: 481  | total loss: [1m[32m0.13139[0m[0m | time: 13.199s
[2K
| RMSProp | epoch: 022 | loss: 0.13139 - acc: 0.9483 -- iter: 608/685
[A[ATraining Step: 482  | total loss: [1m[32m0.13806[0m[0m | time: 13.496s
[2K
| RMSProp | epoch: 022 | loss: 0.13806 - acc: 0.9441 -- iter: 640/685
[A[ATraining Step: 483  | total loss: [1m[32m0.12544[0m[0m | time: 13.881s
[2K
| RMSProp | epoch: 022 | loss: 0.12544 - acc: 0.9497 -- iter: 672/685
[A[ATraining Step: 484  | total loss: [1m[32m0.11352[0m[0m | time: 15.617s
[2K
| RMSProp | epoch: 022 | loss: 0.11352 - acc: 0.9547 | val_loss: 0.53714 - val_acc: 0.8140 -- iter: 685/685
--
Training Step: 485  | total loss: [1m[32m0.12700[0m[0m | time: 0.845s
[2K
| RMSProp | epoch: 023 | loss: 0.12700 - acc: 0.9499 -- iter: 032/685
[A[ATraining Step: 486  | total loss: [1m[32m0.14177[0m[0m | time: 1.613s
[2K
| RMSProp | epoch: 023 | loss: 0.14177 - acc: 0.9455 -- iter: 064/685
[A[ATraining Step: 487  | total loss: [1m[32m0.13305[0m[0m | time: 2.399s
[2K
| RMSProp | epoch: 023 | loss: 0.13305 - acc: 0.9509 -- iter: 096/685
[A[ATraining Step: 488  | total loss: [1m[32m0.14856[0m[0m | time: 3.153s
[2K
| RMSProp | epoch: 023 | loss: 0.14856 - acc: 0.9402 -- iter: 128/685
[A[ATraining Step: 489  | total loss: [1m[32m0.14760[0m[0m | time: 3.871s
[2K
| RMSProp | epoch: 023 | loss: 0.14760 - acc: 0.9431 -- iter: 160/685
[A[ATraining Step: 490  | total loss: [1m[32m0.13863[0m[0m | time: 4.613s
[2K
| RMSProp | epoch: 023 | loss: 0.13863 - acc: 0.9488 -- iter: 192/685
[A[ATraining Step: 491  | total loss: [1m[32m0.13630[0m[0m | time: 5.369s
[2K
| RMSProp | epoch: 023 | loss: 0.13630 - acc: 0.9508 -- iter: 224/685
[A[ATraining Step: 492  | total loss: [1m[32m0.13198[0m[0m | time: 5.971s
[2K
| RMSProp | epoch: 023 | loss: 0.13198 - acc: 0.9526 -- iter: 256/685
[A[ATraining Step: 493  | total loss: [1m[32m0.12762[0m[0m | time: 6.582s
[2K
| RMSProp | epoch: 023 | loss: 0.12762 - acc: 0.9542 -- iter: 288/685
[A[ATraining Step: 494  | total loss: [1m[32m0.11614[0m[0m | time: 7.187s
[2K
| RMSProp | epoch: 023 | loss: 0.11614 - acc: 0.9588 -- iter: 320/685
[A[ATraining Step: 495  | total loss: [1m[32m0.11682[0m[0m | time: 7.785s
[2K
| RMSProp | epoch: 023 | loss: 0.11682 - acc: 0.9566 -- iter: 352/685
[A[ATraining Step: 496  | total loss: [1m[32m0.11324[0m[0m | time: 8.398s
[2K
| RMSProp | epoch: 023 | loss: 0.11324 - acc: 0.9578 -- iter: 384/685
[A[ATraining Step: 497  | total loss: [1m[32m0.13341[0m[0m | time: 8.996s
[2K
| RMSProp | epoch: 023 | loss: 0.13341 - acc: 0.9558 -- iter: 416/685
[A[ATraining Step: 498  | total loss: [1m[32m0.13436[0m[0m | time: 9.761s
[2K
| RMSProp | epoch: 023 | loss: 0.13436 - acc: 0.9571 -- iter: 448/685
[A[ATraining Step: 499  | total loss: [1m[32m0.12615[0m[0m | time: 10.523s
[2K
| RMSProp | epoch: 023 | loss: 0.12615 - acc: 0.9614 -- iter: 480/685
[A[ATraining Step: 500  | total loss: [1m[32m0.11458[0m[0m | time: 11.289s
[2K
| RMSProp | epoch: 023 | loss: 0.11458 - acc: 0.9653 -- iter: 512/685
[A[ATraining Step: 501  | total loss: [1m[32m0.10580[0m[0m | time: 12.021s
[2K
| RMSProp | epoch: 023 | loss: 0.10580 - acc: 0.9687 -- iter: 544/685
[A[ATraining Step: 502  | total loss: [1m[32m0.09946[0m[0m | time: 12.774s
[2K
| RMSProp | epoch: 023 | loss: 0.09946 - acc: 0.9719 -- iter: 576/685
[A[ATraining Step: 503  | total loss: [1m[32m0.09811[0m[0m | time: 13.492s
[2K
| RMSProp | epoch: 023 | loss: 0.09811 - acc: 0.9715 -- iter: 608/685
[A[ATraining Step: 504  | total loss: [1m[32m0.10293[0m[0m | time: 14.225s
[2K
| RMSProp | epoch: 023 | loss: 0.10293 - acc: 0.9713 -- iter: 640/685
[A[ATraining Step: 505  | total loss: [1m[32m0.10181[0m[0m | time: 14.516s
[2K
| RMSProp | epoch: 023 | loss: 0.10181 - acc: 0.9679 -- iter: 672/685
[A[ATraining Step: 506  | total loss: [1m[32m0.09829[0m[0m | time: 15.792s
[2K
| RMSProp | epoch: 023 | loss: 0.09829 - acc: 0.9711 | val_loss: 0.35751 - val_acc: 0.8930 -- iter: 685/685
--
Training Step: 507  | total loss: [1m[32m0.09193[0m[0m | time: 0.636s
[2K
| RMSProp | epoch: 024 | loss: 0.09193 - acc: 0.9740 -- iter: 032/685
[A[ATraining Step: 508  | total loss: [1m[32m0.09031[0m[0m | time: 1.297s
[2K
| RMSProp | epoch: 024 | loss: 0.09031 - acc: 0.9735 -- iter: 064/685
[A[ATraining Step: 509  | total loss: [1m[32m0.08439[0m[0m | time: 2.018s
[2K
| RMSProp | epoch: 024 | loss: 0.08439 - acc: 0.9761 -- iter: 096/685
[A[ATraining Step: 510  | total loss: [1m[32m0.07616[0m[0m | time: 2.806s
[2K
| RMSProp | epoch: 024 | loss: 0.07616 - acc: 0.9785 -- iter: 128/685
[A[ATraining Step: 511  | total loss: [1m[32m0.07756[0m[0m | time: 3.532s
[2K
| RMSProp | epoch: 024 | loss: 0.07756 - acc: 0.9775 -- iter: 160/685
[A[ATraining Step: 512  | total loss: [1m[32m0.09667[0m[0m | time: 4.282s
[2K
| RMSProp | epoch: 024 | loss: 0.09667 - acc: 0.9704 -- iter: 192/685
[A[ATraining Step: 513  | total loss: [1m[32m0.13710[0m[0m | time: 4.986s
[2K
| RMSProp | epoch: 024 | loss: 0.13710 - acc: 0.9546 -- iter: 224/685
[A[ATraining Step: 514  | total loss: [1m[32m0.12701[0m[0m | time: 5.734s
[2K
| RMSProp | epoch: 024 | loss: 0.12701 - acc: 0.9592 -- iter: 256/685
[A[ATraining Step: 515  | total loss: [1m[32m0.11605[0m[0m | time: 6.510s
[2K
| RMSProp | epoch: 024 | loss: 0.11605 - acc: 0.9632 -- iter: 288/685
[A[ATraining Step: 516  | total loss: [1m[32m0.11345[0m[0m | time: 7.113s
[2K
| RMSProp | epoch: 024 | loss: 0.11345 - acc: 0.9607 -- iter: 320/685
[A[ATraining Step: 517  | total loss: [1m[32m0.11701[0m[0m | time: 7.708s
[2K
| RMSProp | epoch: 024 | loss: 0.11701 - acc: 0.9615 -- iter: 352/685
[A[ATraining Step: 518  | total loss: [1m[32m0.10864[0m[0m | time: 8.304s
[2K
| RMSProp | epoch: 024 | loss: 0.10864 - acc: 0.9653 -- iter: 384/685
[A[ATraining Step: 519  | total loss: [1m[32m0.09978[0m[0m | time: 8.889s
[2K
| RMSProp | epoch: 024 | loss: 0.09978 - acc: 0.9688 -- iter: 416/685
[A[ATraining Step: 520  | total loss: [1m[32m0.12344[0m[0m | time: 9.488s
[2K
| RMSProp | epoch: 024 | loss: 0.12344 - acc: 0.9657 -- iter: 448/685
[A[ATraining Step: 521  | total loss: [1m[32m0.11470[0m[0m | time: 10.091s
[2K
| RMSProp | epoch: 024 | loss: 0.11470 - acc: 0.9691 -- iter: 480/685
[A[ATraining Step: 522  | total loss: [1m[32m0.10461[0m[0m | time: 10.697s
[2K
| RMSProp | epoch: 024 | loss: 0.10461 - acc: 0.9722 -- iter: 512/685
[A[ATraining Step: 523  | total loss: [1m[32m0.09683[0m[0m | time: 11.296s
[2K
| RMSProp | epoch: 024 | loss: 0.09683 - acc: 0.9750 -- iter: 544/685
[A[ATraining Step: 524  | total loss: [1m[32m0.08940[0m[0m | time: 11.924s
[2K
| RMSProp | epoch: 024 | loss: 0.08940 - acc: 0.9775 -- iter: 576/685
[A[ATraining Step: 525  | total loss: [1m[32m0.08093[0m[0m | time: 12.522s
[2K
| RMSProp | epoch: 024 | loss: 0.08093 - acc: 0.9797 -- iter: 608/685
[A[ATraining Step: 526  | total loss: [1m[32m0.07631[0m[0m | time: 13.152s
[2K
| RMSProp | epoch: 024 | loss: 0.07631 - acc: 0.9818 -- iter: 640/685
[A[ATraining Step: 527  | total loss: [1m[32m0.08190[0m[0m | time: 13.944s
[2K
| RMSProp | epoch: 024 | loss: 0.08190 - acc: 0.9805 -- iter: 672/685
[A[ATraining Step: 528  | total loss: [1m[32m0.07903[0m[0m | time: 15.235s
[2K
| RMSProp | epoch: 024 | loss: 0.07903 - acc: 0.9793 | val_loss: 0.64612 - val_acc: 0.8512 -- iter: 685/685
--
Training Step: 529  | total loss: [1m[32m0.13673[0m[0m | time: 0.271s
[2K
| RMSProp | epoch: 025 | loss: 0.13673 - acc: 0.9583 -- iter: 032/685
[A[ATraining Step: 530  | total loss: [1m[32m0.12429[0m[0m | time: 0.887s
[2K
| RMSProp | epoch: 025 | loss: 0.12429 - acc: 0.9624 -- iter: 064/685
[A[ATraining Step: 531  | total loss: [1m[32m0.13272[0m[0m | time: 1.492s
[2K
| RMSProp | epoch: 025 | loss: 0.13272 - acc: 0.9568 -- iter: 096/685
[A[ATraining Step: 532  | total loss: [1m[32m0.13652[0m[0m | time: 2.094s
[2K
| RMSProp | epoch: 025 | loss: 0.13652 - acc: 0.9580 -- iter: 128/685
[A[ATraining Step: 533  | total loss: [1m[32m0.13459[0m[0m | time: 2.682s
[2K
| RMSProp | epoch: 025 | loss: 0.13459 - acc: 0.9591 -- iter: 160/685
[A[ATraining Step: 534  | total loss: [1m[32m0.13122[0m[0m | time: 3.321s
[2K
| RMSProp | epoch: 025 | loss: 0.13122 - acc: 0.9632 -- iter: 192/685
[A[ATraining Step: 535  | total loss: [1m[32m0.11976[0m[0m | time: 3.939s
[2K
| RMSProp | epoch: 025 | loss: 0.11976 - acc: 0.9669 -- iter: 224/685
[A[ATraining Step: 536  | total loss: [1m[32m0.10830[0m[0m | time: 4.547s
[2K
| RMSProp | epoch: 025 | loss: 0.10830 - acc: 0.9702 -- iter: 256/685
[A[ATraining Step: 537  | total loss: [1m[32m0.09869[0m[0m | time: 5.282s
[2K
| RMSProp | epoch: 025 | loss: 0.09869 - acc: 0.9732 -- iter: 288/685
[A[ATraining Step: 538  | total loss: [1m[32m0.08894[0m[0m | time: 6.017s
[2K
| RMSProp | epoch: 025 | loss: 0.08894 - acc: 0.9758 -- iter: 320/685
[A[ATraining Step: 539  | total loss: [1m[32m0.08078[0m[0m | time: 6.741s
[2K
| RMSProp | epoch: 025 | loss: 0.08078 - acc: 0.9783 -- iter: 352/685
[A[ATraining Step: 540  | total loss: [1m[32m0.07348[0m[0m | time: 7.463s
[2K
| RMSProp | epoch: 025 | loss: 0.07348 - acc: 0.9804 -- iter: 384/685
[A[ATraining Step: 541  | total loss: [1m[32m0.07216[0m[0m | time: 8.182s
[2K
| RMSProp | epoch: 025 | loss: 0.07216 - acc: 0.9793 -- iter: 416/685
[A[ATraining Step: 542  | total loss: [1m[32m0.06604[0m[0m | time: 8.896s
[2K
| RMSProp | epoch: 025 | loss: 0.06604 - acc: 0.9813 -- iter: 448/685
[A[ATraining Step: 543  | total loss: [1m[32m0.07077[0m[0m | time: 9.632s
[2K
| RMSProp | epoch: 025 | loss: 0.07077 - acc: 0.9801 -- iter: 480/685
[A[ATraining Step: 544  | total loss: [1m[32m0.06661[0m[0m | time: 10.229s
[2K
| RMSProp | epoch: 025 | loss: 0.06661 - acc: 0.9821 -- iter: 512/685
[A[ATraining Step: 545  | total loss: [1m[32m0.06052[0m[0m | time: 10.825s
[2K
| RMSProp | epoch: 025 | loss: 0.06052 - acc: 0.9839 -- iter: 544/685
[A[ATraining Step: 546  | total loss: [1m[32m0.05488[0m[0m | time: 11.449s
[2K
| RMSProp | epoch: 025 | loss: 0.05488 - acc: 0.9855 -- iter: 576/685
[A[ATraining Step: 547  | total loss: [1m[32m0.04964[0m[0m | time: 12.047s
[2K
| RMSProp | epoch: 025 | loss: 0.04964 - acc: 0.9869 -- iter: 608/685
[A[ATraining Step: 548  | total loss: [1m[32m0.04483[0m[0m | time: 12.697s
[2K
| RMSProp | epoch: 025 | loss: 0.04483 - acc: 0.9882 -- iter: 640/685
[A[ATraining Step: 549  | total loss: [1m[32m0.05023[0m[0m | time: 13.464s
[2K
| RMSProp | epoch: 025 | loss: 0.05023 - acc: 0.9863 -- iter: 672/685
[A[ATraining Step: 550  | total loss: [1m[32m0.09218[0m[0m | time: 15.191s
[2K
| RMSProp | epoch: 025 | loss: 0.09218 - acc: 0.9720 | val_loss: 0.40009 - val_acc: 0.8884 -- iter: 685/685
--
Training Step: 551  | total loss: [1m[32m0.12043[0m[0m | time: 0.273s
[2K
| RMSProp | epoch: 026 | loss: 0.12043 - acc: 0.9561 -- iter: 032/685
[A[ATraining Step: 552  | total loss: [1m[32m0.11380[0m[0m | time: 0.543s
[2K
| RMSProp | epoch: 026 | loss: 0.11380 - acc: 0.9605 -- iter: 064/685
[A[ATraining Step: 553  | total loss: [1m[32m0.10281[0m[0m | time: 1.143s
[2K
| RMSProp | epoch: 026 | loss: 0.10281 - acc: 0.9644 -- iter: 096/685
[A[ATraining Step: 554  | total loss: [1m[32m0.09930[0m[0m | time: 1.745s
[2K
| RMSProp | epoch: 026 | loss: 0.09930 - acc: 0.9649 -- iter: 128/685
[A[ATraining Step: 555  | total loss: [1m[32m0.09262[0m[0m | time: 2.357s
[2K
| RMSProp | epoch: 026 | loss: 0.09262 - acc: 0.9652 -- iter: 160/685
[A[ATraining Step: 556  | total loss: [1m[32m0.08423[0m[0m | time: 2.973s
[2K
| RMSProp | epoch: 026 | loss: 0.08423 - acc: 0.9687 -- iter: 192/685
[A[ATraining Step: 557  | total loss: [1m[32m0.08417[0m[0m | time: 3.582s
[2K
| RMSProp | epoch: 026 | loss: 0.08417 - acc: 0.9656 -- iter: 224/685
[A[ATraining Step: 558  | total loss: [1m[32m0.13529[0m[0m | time: 4.364s
[2K
| RMSProp | epoch: 026 | loss: 0.13529 - acc: 0.9503 -- iter: 256/685
[A[ATraining Step: 559  | total loss: [1m[32m0.13494[0m[0m | time: 5.124s
[2K
| RMSProp | epoch: 026 | loss: 0.13494 - acc: 0.9490 -- iter: 288/685
[A[ATraining Step: 560  | total loss: [1m[32m0.12828[0m[0m | time: 5.893s
[2K
| RMSProp | epoch: 026 | loss: 0.12828 - acc: 0.9510 -- iter: 320/685
[A[ATraining Step: 561  | total loss: [1m[32m0.11699[0m[0m | time: 6.615s
[2K
| RMSProp | epoch: 026 | loss: 0.11699 - acc: 0.9559 -- iter: 352/685
[A[ATraining Step: 562  | total loss: [1m[32m0.10566[0m[0m | time: 7.333s
[2K
| RMSProp | epoch: 026 | loss: 0.10566 - acc: 0.9603 -- iter: 384/685
[A[ATraining Step: 563  | total loss: [1m[32m0.10515[0m[0m | time: 8.098s
[2K
| RMSProp | epoch: 026 | loss: 0.10515 - acc: 0.9549 -- iter: 416/685
[A[ATraining Step: 564  | total loss: [1m[32m0.18865[0m[0m | time: 8.815s
[2K
| RMSProp | epoch: 026 | loss: 0.18865 - acc: 0.9250 -- iter: 448/685
[A[ATraining Step: 565  | total loss: [1m[32m0.18442[0m[0m | time: 9.430s
[2K
| RMSProp | epoch: 026 | loss: 0.18442 - acc: 0.9294 -- iter: 480/685
[A[ATraining Step: 566  | total loss: [1m[32m0.16956[0m[0m | time: 10.036s
[2K
| RMSProp | epoch: 026 | loss: 0.16956 - acc: 0.9365 -- iter: 512/685
[A[ATraining Step: 567  | total loss: [1m[32m0.15367[0m[0m | time: 10.659s
[2K
| RMSProp | epoch: 026 | loss: 0.15367 - acc: 0.9428 -- iter: 544/685
[A[ATraining Step: 568  | total loss: [1m[32m0.13894[0m[0m | time: 11.380s
[2K
| RMSProp | epoch: 026 | loss: 0.13894 - acc: 0.9485 -- iter: 576/685
[A[ATraining Step: 569  | total loss: [1m[32m0.12806[0m[0m | time: 12.103s
[2K
| RMSProp | epoch: 026 | loss: 0.12806 - acc: 0.9506 -- iter: 608/685
[A[ATraining Step: 570  | total loss: [1m[32m0.11828[0m[0m | time: 12.836s
[2K
| RMSProp | epoch: 026 | loss: 0.11828 - acc: 0.9555 -- iter: 640/685
[A[ATraining Step: 571  | total loss: [1m[32m0.11886[0m[0m | time: 13.552s
[2K
| RMSProp | epoch: 026 | loss: 0.11886 - acc: 0.9568 -- iter: 672/685
[A[ATraining Step: 572  | total loss: [1m[32m0.12367[0m[0m | time: 15.307s
[2K
| RMSProp | epoch: 026 | loss: 0.12367 - acc: 0.9549 | val_loss: 0.35178 - val_acc: 0.8930 -- iter: 685/685
--
Training Step: 573  | total loss: [1m[32m0.11307[0m[0m | time: 0.622s
[2K
| RMSProp | epoch: 027 | loss: 0.11307 - acc: 0.9594 -- iter: 032/685
[A[ATraining Step: 574  | total loss: [1m[32m0.11314[0m[0m | time: 0.899s
[2K
| RMSProp | epoch: 027 | loss: 0.11314 - acc: 0.9572 -- iter: 064/685
[A[ATraining Step: 575  | total loss: [1m[32m0.10356[0m[0m | time: 1.239s
[2K
| RMSProp | epoch: 027 | loss: 0.10356 - acc: 0.9615 -- iter: 096/685
[A[ATraining Step: 576  | total loss: [1m[32m0.09404[0m[0m | time: 2.010s
[2K
| RMSProp | epoch: 027 | loss: 0.09404 - acc: 0.9653 -- iter: 128/685
[A[ATraining Step: 577  | total loss: [1m[32m0.08632[0m[0m | time: 2.726s
[2K
| RMSProp | epoch: 027 | loss: 0.08632 - acc: 0.9688 -- iter: 160/685
[A[ATraining Step: 578  | total loss: [1m[32m0.08003[0m[0m | time: 3.470s
[2K
| RMSProp | epoch: 027 | loss: 0.08003 - acc: 0.9719 -- iter: 192/685
[A[ATraining Step: 579  | total loss: [1m[32m0.07366[0m[0m | time: 4.224s
[2K
| RMSProp | epoch: 027 | loss: 0.07366 - acc: 0.9747 -- iter: 224/685
[A[ATraining Step: 580  | total loss: [1m[32m0.06795[0m[0m | time: 4.929s
[2K
| RMSProp | epoch: 027 | loss: 0.06795 - acc: 0.9773 -- iter: 256/685
[A[ATraining Step: 581  | total loss: [1m[32m0.06832[0m[0m | time: 5.648s
[2K
| RMSProp | epoch: 027 | loss: 0.06832 - acc: 0.9733 -- iter: 288/685
[A[ATraining Step: 582  | total loss: [1m[32m0.07126[0m[0m | time: 6.396s
[2K
| RMSProp | epoch: 027 | loss: 0.07126 - acc: 0.9697 -- iter: 320/685
[A[ATraining Step: 583  | total loss: [1m[32m0.06459[0m[0m | time: 7.000s
[2K
| RMSProp | epoch: 027 | loss: 0.06459 - acc: 0.9727 -- iter: 352/685
[A[ATraining Step: 584  | total loss: [1m[32m0.05856[0m[0m | time: 7.599s
[2K
| RMSProp | epoch: 027 | loss: 0.05856 - acc: 0.9755 -- iter: 384/685
[A[ATraining Step: 585  | total loss: [1m[32m0.05664[0m[0m | time: 8.210s
[2K
| RMSProp | epoch: 027 | loss: 0.05664 - acc: 0.9748 -- iter: 416/685
[A[ATraining Step: 586  | total loss: [1m[32m0.05407[0m[0m | time: 8.812s
[2K
| RMSProp | epoch: 027 | loss: 0.05407 - acc: 0.9773 -- iter: 448/685
[A[ATraining Step: 587  | total loss: [1m[32m0.04915[0m[0m | time: 9.705s
[2K
| RMSProp | epoch: 027 | loss: 0.04915 - acc: 0.9796 -- iter: 480/685
[A[ATraining Step: 588  | total loss: [1m[32m0.04481[0m[0m | time: 10.318s
[2K
| RMSProp | epoch: 027 | loss: 0.04481 - acc: 0.9816 -- iter: 512/685
[A[ATraining Step: 589  | total loss: [1m[32m0.10384[0m[0m | time: 10.948s
[2K
| RMSProp | epoch: 027 | loss: 0.10384 - acc: 0.9772 -- iter: 544/685
[A[ATraining Step: 590  | total loss: [1m[32m0.10307[0m[0m | time: 11.541s
[2K
| RMSProp | epoch: 027 | loss: 0.10307 - acc: 0.9764 -- iter: 576/685
[A[ATraining Step: 591  | total loss: [1m[32m0.09330[0m[0m | time: 12.132s
[2K
| RMSProp | epoch: 027 | loss: 0.09330 - acc: 0.9787 -- iter: 608/685
[A[ATraining Step: 592  | total loss: [1m[32m0.08559[0m[0m | time: 12.803s
[2K
| RMSProp | epoch: 027 | loss: 0.08559 - acc: 0.9809 -- iter: 640/685
[A[ATraining Step: 593  | total loss: [1m[32m0.07801[0m[0m | time: 13.409s
[2K
| RMSProp | epoch: 027 | loss: 0.07801 - acc: 0.9828 -- iter: 672/685
[A[ATraining Step: 594  | total loss: [1m[32m0.07069[0m[0m | time: 15.073s
[2K
| RMSProp | epoch: 027 | loss: 0.07069 - acc: 0.9845 | val_loss: 0.46030 - val_acc: 0.9116 -- iter: 685/685
--
Training Step: 595  | total loss: [1m[32m0.06948[0m[0m | time: 0.617s
[2K
| RMSProp | epoch: 028 | loss: 0.06948 - acc: 0.9829 -- iter: 032/685
[A[ATraining Step: 596  | total loss: [1m[32m0.06706[0m[0m | time: 1.230s
[2K
| RMSProp | epoch: 028 | loss: 0.06706 - acc: 0.9815 -- iter: 064/685
[A[ATraining Step: 597  | total loss: [1m[32m0.06243[0m[0m | time: 1.501s
[2K
| RMSProp | epoch: 028 | loss: 0.06243 - acc: 0.9834 -- iter: 096/685
[A[ATraining Step: 598  | total loss: [1m[32m0.05655[0m[0m | time: 1.777s
[2K
| RMSProp | epoch: 028 | loss: 0.05655 - acc: 0.9850 -- iter: 128/685
[A[ATraining Step: 599  | total loss: [1m[32m0.05109[0m[0m | time: 2.394s
[2K
| RMSProp | epoch: 028 | loss: 0.05109 - acc: 0.9865 -- iter: 160/685
[A[ATraining Step: 600  | total loss: [1m[32m0.04621[0m[0m | time: 3.997s
[2K
| RMSProp | epoch: 028 | loss: 0.04621 - acc: 0.9879 | val_loss: 0.38387 - val_acc: 0.8884 -- iter: 192/685
--
Training Step: 601  | total loss: [1m[32m0.04169[0m[0m | time: 4.611s
[2K
| RMSProp | epoch: 028 | loss: 0.04169 - acc: 0.9891 -- iter: 224/685
[A[ATraining Step: 602  | total loss: [1m[32m0.03878[0m[0m | time: 5.214s
[2K
| RMSProp | epoch: 028 | loss: 0.03878 - acc: 0.9902 -- iter: 256/685
[A[ATraining Step: 603  | total loss: [1m[32m0.04660[0m[0m | time: 5.832s
[2K
| RMSProp | epoch: 028 | loss: 0.04660 - acc: 0.9880 -- iter: 288/685
[A[ATraining Step: 604  | total loss: [1m[32m0.04731[0m[0m | time: 6.433s
[2K
| RMSProp | epoch: 028 | loss: 0.04731 - acc: 0.9861 -- iter: 320/685
[A[ATraining Step: 605  | total loss: [1m[32m0.05865[0m[0m | time: 7.041s
[2K
| RMSProp | epoch: 028 | loss: 0.05865 - acc: 0.9781 -- iter: 352/685
[A[ATraining Step: 606  | total loss: [1m[32m0.09046[0m[0m | time: 7.641s
[2K
| RMSProp | epoch: 028 | loss: 0.09046 - acc: 0.9709 -- iter: 384/685
[A[ATraining Step: 607  | total loss: [1m[32m0.08992[0m[0m | time: 8.233s
[2K
| RMSProp | epoch: 028 | loss: 0.08992 - acc: 0.9707 -- iter: 416/685
[A[ATraining Step: 608  | total loss: [1m[32m0.09493[0m[0m | time: 8.839s
[2K
| RMSProp | epoch: 028 | loss: 0.09493 - acc: 0.9643 -- iter: 448/685
[A[ATraining Step: 609  | total loss: [1m[32m0.08687[0m[0m | time: 9.449s
[2K
| RMSProp | epoch: 028 | loss: 0.08687 - acc: 0.9678 -- iter: 480/685
[A[ATraining Step: 610  | total loss: [1m[32m0.08897[0m[0m | time: 10.062s
[2K
| RMSProp | epoch: 028 | loss: 0.08897 - acc: 0.9648 -- iter: 512/685
[A[ATraining Step: 611  | total loss: [1m[32m0.08944[0m[0m | time: 10.667s
[2K
| RMSProp | epoch: 028 | loss: 0.08944 - acc: 0.9652 -- iter: 544/685
[A[ATraining Step: 612  | total loss: [1m[32m0.11353[0m[0m | time: 11.292s
[2K
| RMSProp | epoch: 028 | loss: 0.11353 - acc: 0.9656 -- iter: 576/685
[A[ATraining Step: 613  | total loss: [1m[32m0.10907[0m[0m | time: 11.888s
[2K
| RMSProp | epoch: 028 | loss: 0.10907 - acc: 0.9659 -- iter: 608/685
[A[ATraining Step: 614  | total loss: [1m[32m0.10002[0m[0m | time: 12.509s
[2K
| RMSProp | epoch: 028 | loss: 0.10002 - acc: 0.9693 -- iter: 640/685
[A[ATraining Step: 615  | total loss: [1m[32m0.09982[0m[0m | time: 13.135s
[2K
| RMSProp | epoch: 028 | loss: 0.09982 - acc: 0.9692 -- iter: 672/685
[A[ATraining Step: 616  | total loss: [1m[32m0.09151[0m[0m | time: 14.778s
[2K
| RMSProp | epoch: 028 | loss: 0.09151 - acc: 0.9723 | val_loss: 0.32103 - val_acc: 0.8930 -- iter: 685/685
--
Training Step: 617  | total loss: [1m[32m0.08306[0m[0m | time: 0.604s
[2K
| RMSProp | epoch: 029 | loss: 0.08306 - acc: 0.9751 -- iter: 032/685
[A[ATraining Step: 618  | total loss: [1m[32m0.08268[0m[0m | time: 1.207s
[2K
| RMSProp | epoch: 029 | loss: 0.08268 - acc: 0.9744 -- iter: 064/685
[A[ATraining Step: 619  | total loss: [1m[32m0.07558[0m[0m | time: 1.807s
[2K
| RMSProp | epoch: 029 | loss: 0.07558 - acc: 0.9770 -- iter: 096/685
[A[ATraining Step: 620  | total loss: [1m[32m0.06943[0m[0m | time: 2.075s
[2K
| RMSProp | epoch: 029 | loss: 0.06943 - acc: 0.9793 -- iter: 128/685
[A[ATraining Step: 621  | total loss: [1m[32m0.06280[0m[0m | time: 2.361s
[2K
| RMSProp | epoch: 029 | loss: 0.06280 - acc: 0.9814 -- iter: 160/685
[A[ATraining Step: 622  | total loss: [1m[32m0.05670[0m[0m | time: 2.981s
[2K
| RMSProp | epoch: 029 | loss: 0.05670 - acc: 0.9832 -- iter: 192/685
[A[ATraining Step: 623  | total loss: [1m[32m0.05132[0m[0m | time: 3.582s
[2K
| RMSProp | epoch: 029 | loss: 0.05132 - acc: 0.9849 -- iter: 224/685
[A[ATraining Step: 624  | total loss: [1m[32m0.04640[0m[0m | time: 4.178s
[2K
| RMSProp | epoch: 029 | loss: 0.04640 - acc: 0.9864 -- iter: 256/685
[A[ATraining Step: 625  | total loss: [1m[32m0.04192[0m[0m | time: 4.771s
[2K
| RMSProp | epoch: 029 | loss: 0.04192 - acc: 0.9878 -- iter: 288/685
[A[ATraining Step: 626  | total loss: [1m[32m0.03812[0m[0m | time: 5.403s
[2K
| RMSProp | epoch: 029 | loss: 0.03812 - acc: 0.9890 -- iter: 320/685
[A[ATraining Step: 627  | total loss: [1m[32m0.03459[0m[0m | time: 6.014s
[2K
| RMSProp | epoch: 029 | loss: 0.03459 - acc: 0.9901 -- iter: 352/685
[A[ATraining Step: 628  | total loss: [1m[32m0.03170[0m[0m | time: 6.616s
[2K
| RMSProp | epoch: 029 | loss: 0.03170 - acc: 0.9911 -- iter: 384/685
[A[ATraining Step: 629  | total loss: [1m[32m0.02862[0m[0m | time: 7.239s
[2K
| RMSProp | epoch: 029 | loss: 0.02862 - acc: 0.9920 -- iter: 416/685
[A[ATraining Step: 630  | total loss: [1m[32m0.02577[0m[0m | time: 7.848s
[2K
| RMSProp | epoch: 029 | loss: 0.02577 - acc: 0.9928 -- iter: 448/685
[A[ATraining Step: 631  | total loss: [1m[32m0.02323[0m[0m | time: 8.446s
[2K
| RMSProp | epoch: 029 | loss: 0.02323 - acc: 0.9935 -- iter: 480/685
[A[ATraining Step: 632  | total loss: [1m[32m0.02185[0m[0m | time: 9.044s
[2K
| RMSProp | epoch: 029 | loss: 0.02185 - acc: 0.9942 -- iter: 512/685
[A[ATraining Step: 633  | total loss: [1m[32m0.07958[0m[0m | time: 9.664s
[2K
| RMSProp | epoch: 029 | loss: 0.07958 - acc: 0.9854 -- iter: 544/685
[A[ATraining Step: 634  | total loss: [1m[32m0.11185[0m[0m | time: 10.273s
[2K
| RMSProp | epoch: 029 | loss: 0.11185 - acc: 0.9775 -- iter: 576/685
[A[ATraining Step: 635  | total loss: [1m[32m0.16057[0m[0m | time: 10.872s
[2K
| RMSProp | epoch: 029 | loss: 0.16057 - acc: 0.9516 -- iter: 608/685
[A[ATraining Step: 636  | total loss: [1m[32m0.15333[0m[0m | time: 11.471s
[2K
| RMSProp | epoch: 029 | loss: 0.15333 - acc: 0.9533 -- iter: 640/685
[A[ATraining Step: 637  | total loss: [1m[32m0.14145[0m[0m | time: 12.070s
[2K
| RMSProp | epoch: 029 | loss: 0.14145 - acc: 0.9580 -- iter: 672/685
[A[ATraining Step: 638  | total loss: [1m[32m0.12832[0m[0m | time: 13.695s
[2K
| RMSProp | epoch: 029 | loss: 0.12832 - acc: 0.9622 | val_loss: 0.34572 - val_acc: 0.8977 -- iter: 685/685
--
Training Step: 639  | total loss: [1m[32m0.11706[0m[0m | time: 0.605s
[2K
| RMSProp | epoch: 030 | loss: 0.11706 - acc: 0.9660 -- iter: 032/685
[A[ATraining Step: 640  | total loss: [1m[32m0.10568[0m[0m | time: 1.214s
[2K
| RMSProp | epoch: 030 | loss: 0.10568 - acc: 0.9694 -- iter: 064/685
[A[ATraining Step: 641  | total loss: [1m[32m0.09531[0m[0m | time: 1.803s
[2K
| RMSProp | epoch: 030 | loss: 0.09531 - acc: 0.9724 -- iter: 096/685
[A[ATraining Step: 642  | total loss: [1m[32m0.08621[0m[0m | time: 2.427s
[2K
| RMSProp | epoch: 030 | loss: 0.08621 - acc: 0.9752 -- iter: 128/685
[A[ATraining Step: 643  | total loss: [1m[32m0.07791[0m[0m | time: 2.697s
[2K
| RMSProp | epoch: 030 | loss: 0.07791 - acc: 0.9777 -- iter: 160/685
[A[ATraining Step: 644  | total loss: [1m[32m0.07018[0m[0m | time: 2.968s
[2K
| RMSProp | epoch: 030 | loss: 0.07018 - acc: 0.9799 -- iter: 192/685
[A[ATraining Step: 645  | total loss: [1m[32m0.06321[0m[0m | time: 3.551s
[2K
| RMSProp | epoch: 030 | loss: 0.06321 - acc: 0.9819 -- iter: 224/685
[A[ATraining Step: 646  | total loss: [1m[32m0.05713[0m[0m | time: 4.143s
[2K
| RMSProp | epoch: 030 | loss: 0.05713 - acc: 0.9837 -- iter: 256/685
[A[ATraining Step: 647  | total loss: [1m[32m0.05182[0m[0m | time: 4.743s
[2K
| RMSProp | epoch: 030 | loss: 0.05182 - acc: 0.9853 -- iter: 288/685
[A[ATraining Step: 648  | total loss: [1m[32m0.04667[0m[0m | time: 5.341s
[2K
| RMSProp | epoch: 030 | loss: 0.04667 - acc: 0.9868 -- iter: 320/685
[A[ATraining Step: 649  | total loss: [1m[32m0.04204[0m[0m | time: 5.938s
[2K
| RMSProp | epoch: 030 | loss: 0.04204 - acc: 0.9881 -- iter: 352/685
[A[ATraining Step: 650  | total loss: [1m[32m0.03790[0m[0m | time: 6.575s
[2K
| RMSProp | epoch: 030 | loss: 0.03790 - acc: 0.9893 -- iter: 384/685
[A[ATraining Step: 651  | total loss: [1m[32m0.03415[0m[0m | time: 7.171s
[2K
| RMSProp | epoch: 030 | loss: 0.03415 - acc: 0.9904 -- iter: 416/685
[A[ATraining Step: 652  | total loss: [1m[32m0.03082[0m[0m | time: 7.778s
[2K
| RMSProp | epoch: 030 | loss: 0.03082 - acc: 0.9913 -- iter: 448/685
[A[ATraining Step: 653  | total loss: [1m[32m0.02783[0m[0m | time: 8.405s
[2K
| RMSProp | epoch: 030 | loss: 0.02783 - acc: 0.9922 -- iter: 480/685
[A[ATraining Step: 654  | total loss: [1m[32m0.02513[0m[0m | time: 9.000s
[2K
| RMSProp | epoch: 030 | loss: 0.02513 - acc: 0.9930 -- iter: 512/685
[A[ATraining Step: 655  | total loss: [1m[32m0.03679[0m[0m | time: 9.604s
[2K
| RMSProp | epoch: 030 | loss: 0.03679 - acc: 0.9906 -- iter: 544/685
[A[ATraining Step: 656  | total loss: [1m[32m0.04686[0m[0m | time: 10.201s
[2K
| RMSProp | epoch: 030 | loss: 0.04686 - acc: 0.9821 -- iter: 576/685
[A[ATraining Step: 657  | total loss: [1m[32m0.13298[0m[0m | time: 10.805s
[2K
| RMSProp | epoch: 030 | loss: 0.13298 - acc: 0.9558 -- iter: 608/685
[A[ATraining Step: 658  | total loss: [1m[32m0.12328[0m[0m | time: 11.395s
[2K
| RMSProp | epoch: 030 | loss: 0.12328 - acc: 0.9602 -- iter: 640/685
[A[ATraining Step: 659  | total loss: [1m[32m0.12586[0m[0m | time: 12.001s
[2K
| RMSProp | epoch: 030 | loss: 0.12586 - acc: 0.9579 -- iter: 672/685
[A[ATraining Step: 660  | total loss: [1m[32m0.12254[0m[0m | time: 13.608s
[2K
| RMSProp | epoch: 030 | loss: 0.12254 - acc: 0.9590 | val_loss: 0.27082 - val_acc: 0.9209 -- iter: 685/685
--
Validation AUC:0.9608756813785827
Validation AUPRC:0.937859049275357
Test AUC:0.9828761139262624
Test AUPRC:0.9761967187330697
BestTestF1Score	0.94	0.89	0.94	0.92	0.96	93	8	110	4	0.3
BestTestMCCScore	0.94	0.89	0.94	0.92	0.96	93	8	110	4	0.3
BestTestAccuracyScore	0.94	0.89	0.94	0.92	0.96	93	8	110	4	0.34
BestValidationF1Score	0.92	0.86	0.93	0.89	0.96	90	11	110	4	0.3
BestValidationMCC	0.92	0.86	0.93	0.89	0.96	90	11	110	4	0.3
BestValidationAccuracy	0.92	0.86	0.93	0.91	0.94	88	9	112	6	0.34
TestPredictions (Threshold:0.3)
CHEMBL537834,TN,INACT,0.009999999776482582	CHEMBL39310,TP,ACT,1.0	CHEMBL125253,TP,ACT,0.8799999952316284	CHEMBL169567,TP,ACT,1.0	CHEMBL78830,TN,INACT,0.009999999776482582	CHEMBL60401,TN,INACT,0.009999999776482582	CHEMBL298203,TN,INACT,0.009999999776482582	CHEMBL2067948,TP,ACT,0.9300000071525574	CHEMBL2111882,TP,ACT,0.949999988079071	CHEMBL296927,TN,INACT,0.009999999776482582	CHEMBL156415,TN,INACT,0.029999999329447746	CHEMBL405468,TP,ACT,0.4699999988079071	CHEMBL2067947,TP,ACT,0.800000011920929	CHEMBL412238,TP,ACT,0.9399999976158142	CHEMBL115093,TP,ACT,0.8600000143051147	CHEMBL2371225,FN,ACT,0.05000000074505806	CHEMBL436209,TP,ACT,1.0	CHEMBL3142689,TP,ACT,1.0	CHEMBL112417,TN,INACT,0.0	CHEMBL3142682,TP,ACT,1.0	CHEMBL319085,TP,ACT,0.7799999713897705	CHEMBL2042400,TN,INACT,0.009999999776482582	CHEMBL297335,TN,INACT,0.05999999865889549	CHEMBL428103,TP,ACT,1.0	CHEMBL291033,TP,ACT,0.9800000190734863	CHEMBL3142681,TP,ACT,1.0	CHEMBL148967,TN,INACT,0.019999999552965164	CHEMBL269016,TP,ACT,1.0	CHEMBL2062854,TN,INACT,0.009999999776482582	CHEMBL48448,TN,INACT,0.009999999776482582	CHEMBL300926,TN,INACT,0.019999999552965164	CHEMBL1478530,TN,INACT,0.019999999552965164	CHEMBL411271,TP,ACT,0.7699999809265137	CHEMBL137525,TP,ACT,0.9900000095367432	CHEMBL461088,TN,INACT,0.009999999776482582	CHEMBL423405,TN,INACT,0.009999999776482582	CHEMBL433407,TP,ACT,0.9800000190734863	CHEMBL295651,TN,INACT,0.009999999776482582	CHEMBL103457,FN,ACT,0.029999999329447746	CHEMBL141354,TN,INACT,0.0	CHEMBL322678,TN,INACT,0.0	CHEMBL3218123,FP,INACT,0.9700000286102295	CHEMBL107680,TN,INACT,0.03999999910593033	CHEMBL344154,TN,INACT,0.0	CHEMBL2042551,TN,INACT,0.009999999776482582	CHEMBL593685,TN,INACT,0.0	CHEMBL345951,TN,INACT,0.009999999776482582	CHEMBL63290,TN,INACT,0.009999999776482582	CHEMBL160932,TN,INACT,0.0	CHEMBL114926,TP,ACT,1.0	CHEMBL310427,TN,INACT,0.019999999552965164	CHEMBL3142904,TP,ACT,1.0	CHEMBL91073,TN,INACT,0.009999999776482582	CHEMBL3589940,TN,INACT,0.029999999329447746	CHEMBL368629,FP,INACT,0.7799999713897705	CHEMBL303203,TN,INACT,0.009999999776482582	CHEMBL92318,TN,INACT,0.019999999552965164	CHEMBL370882,TP,ACT,0.9800000190734863	CHEMBL554692,TN,INACT,0.019999999552965164	CHEMBL42065,TN,INACT,0.019999999552965164	CHEMBL95209,TP,ACT,0.8899999856948853	CHEMBL196133,TP,ACT,0.9300000071525574	CHEMBL2111881,TP,ACT,0.949999988079071	CHEMBL104172,TN,INACT,0.009999999776482582	CHEMBL413768,TP,ACT,1.0	CHEMBL53237,TP,ACT,0.800000011920929	CHEMBL45305,TN,INACT,0.0	CHEMBL1259071,TN,INACT,0.0	CHEMBL115269,TP,ACT,0.8399999737739563	CHEMBL240021,TN,INACT,0.0	CHEMBL135344,TP,ACT,1.0	CHEMBL78669,TN,INACT,0.009999999776482582	CHEMBL3144539,TP,ACT,1.0	CHEMBL422873,TP,ACT,0.4099999964237213	CHEMBL283320,TN,INACT,0.05000000074505806	CHEMBL102703,TP,ACT,0.9900000095367432	CHEMBL40796,TN,INACT,0.009999999776482582	CHEMBL91362,TN,INACT,0.0	CHEMBL195007,TP,ACT,0.9700000286102295	CHEMBL3350720,TP,ACT,1.0	CHEMBL317477,TP,ACT,1.0	CHEMBL177799,TP,ACT,0.699999988079071	CHEMBL267329,TP,ACT,0.9800000190734863	CHEMBL2112592,TN,INACT,0.019999999552965164	CHEMBL3351055,TP,ACT,0.949999988079071	CHEMBL297480,TP,ACT,0.9399999976158142	CHEMBL282426,TN,INACT,0.0	CHEMBL107574,TN,INACT,0.009999999776482582	CHEMBL373168,TP,ACT,0.9300000071525574	CHEMBL389311,TP,ACT,0.800000011920929	CHEMBL2067955,TP,ACT,0.8999999761581421	CHEMBL101752,FN,ACT,0.17000000178813934	CHEMBL26522,TN,INACT,0.0	CHEMBL417358,TN,INACT,0.0	CHEMBL3144531,TP,ACT,1.0	CHEMBL3142685,TP,ACT,1.0	CHEMBL3144554,TP,ACT,1.0	CHEMBL98468,TP,ACT,1.0	CHEMBL19808,TN,INACT,0.009999999776482582	CHEMBL1916635,FP,INACT,0.7799999713897705	CHEMBL110695,TN,INACT,0.0	CHEMBL241100,TN,INACT,0.019999999552965164	CHEMBL437661,TP,ACT,1.0	CHEMBL262767,TP,ACT,1.0	CHEMBL76860,TN,INACT,0.009999999776482582	CHEMBL316619,TP,ACT,0.8700000047683716	CHEMBL59865,TP,ACT,0.9700000286102295	CHEMBL44134,TN,INACT,0.12999999523162842	CHEMBL412917,TP,ACT,1.0	CHEMBL118553,TN,INACT,0.009999999776482582	CHEMBL137308,TP,ACT,0.9900000095367432	CHEMBL312551,TN,INACT,0.009999999776482582	CHEMBL329735,TP,ACT,0.8500000238418579	CHEMBL408392,TP,ACT,1.0	CHEMBL169553,TN,INACT,0.019999999552965164	CHEMBL252232,TN,INACT,0.0	CHEMBL496066,TN,INACT,0.029999999329447746	CHEMBL89688,TN,INACT,0.019999999552965164	CHEMBL175698,FP,INACT,0.7400000095367432	CHEMBL80317,TN,INACT,0.009999999776482582	CHEMBL320399,TP,ACT,0.7300000190734863	CHEMBL199186,TN,INACT,0.009999999776482582	CHEMBL3633663,TN,INACT,0.029999999329447746	CHEMBL252231,TN,INACT,0.0	CHEMBL111023,TN,INACT,0.0	CHEMBL74066,TN,INACT,0.0	CHEMBL319913,TP,ACT,1.0	CHEMBL41157,FN,ACT,0.11999999731779099	CHEMBL353862,TP,ACT,0.9300000071525574	CHEMBL59759,TP,ACT,1.0	CHEMBL1161390,TP,ACT,1.0	CHEMBL423260,TN,INACT,0.019999999552965164	CHEMBL391191,TN,INACT,0.0	CHEMBL2310856,TP,ACT,0.9900000095367432	CHEMBL321811,TP,ACT,0.9700000286102295	CHEMBL3780633,TN,INACT,0.03999999910593033	CHEMBL602474,TN,INACT,0.0	CHEMBL114980,TP,ACT,0.800000011920929	CHEMBL306645,FP,INACT,0.6800000071525574	CHEMBL3144534,TP,ACT,1.0	CHEMBL112222,TP,ACT,0.6499999761581421	CHEMBL343367,TP,ACT,0.9900000095367432	CHEMBL294087,TN,INACT,0.0	CHEMBL354126,TN,INACT,0.0	CHEMBL439591,TP,ACT,1.0	CHEMBL197716,TP,ACT,0.9700000286102295	CHEMBL359141,TN,INACT,0.019999999552965164	CHEMBL80945,TN,INACT,0.0	CHEMBL295207,TN,INACT,0.029999999329447746	CHEMBL283040,TP,ACT,0.4399999976158142	CHEMBL105527,TP,ACT,0.9599999785423279	CHEMBL453,TN,INACT,0.0	CHEMBL125863,TP,ACT,0.9800000190734863	CHEMBL167032,TN,INACT,0.009999999776482582	CHEMBL319569,TP,ACT,0.9300000071525574	CHEMBL324022,TP,ACT,0.9800000190734863	CHEMBL351531,TN,INACT,0.019999999552965164	CHEMBL369359,TN,INACT,0.03999999910593033	CHEMBL78624,TN,INACT,0.019999999552965164	CHEMBL1093044,TN,INACT,0.019999999552965164	CHEMBL303994,TP,ACT,1.0	CHEMBL3142691,TP,ACT,1.0	CHEMBL324760,TP,ACT,0.8899999856948853	CHEMBL288373,TP,ACT,1.0	CHEMBL436175,TP,ACT,0.9200000166893005	CHEMBL61792,TN,INACT,0.0	CHEMBL430937,TP,ACT,1.0	CHEMBL1907736,TN,INACT,0.019999999552965164	CHEMBL515170,TN,INACT,0.019999999552965164	CHEMBL11131,TN,INACT,0.019999999552965164	CHEMBL44463,TN,INACT,0.0	CHEMBL157722,TP,ACT,0.5799999833106995	CHEMBL323951,TN,INACT,0.0	CHEMBL88629,TN,INACT,0.1599999964237213	CHEMBL279520,TN,INACT,0.05000000074505806	CHEMBL352779,TN,INACT,0.019999999552965164	CHEMBL2067957,TP,ACT,0.8999999761581421	CHEMBL45456,TN,INACT,0.009999999776482582	CHEMBL109478,TN,INACT,0.0	CHEMBL96970,TP,ACT,0.9399999976158142	CHEMBL77962,TN,INACT,0.009999999776482582	CHEMBL11629,TN,INACT,0.0	CHEMBL3142702,TP,ACT,1.0	CHEMBL62660,TN,INACT,0.0	CHEMBL135658,TP,ACT,0.8500000238418579	CHEMBL78601,TN,INACT,0.0	CHEMBL594802,TN,INACT,0.009999999776482582	CHEMBL281232,TN,INACT,0.009999999776482582	CHEMBL444128,FP,INACT,0.5199999809265137	CHEMBL2092748,TN,INACT,0.009999999776482582	CHEMBL325935,TN,INACT,0.0	CHEMBL58617,FP,INACT,0.9800000190734863	CHEMBL346784,TP,ACT,0.8999999761581421	CHEMBL423918,TN,INACT,0.019999999552965164	CHEMBL38716,TP,ACT,1.0	CHEMBL165012,TN,INACT,0.009999999776482582	CHEMBL434674,TP,ACT,1.0	CHEMBL164968,TN,INACT,0.029999999329447746	CHEMBL3351059,TP,ACT,0.800000011920929	CHEMBL320901,TP,ACT,0.8299999833106995	CHEMBL64043,TN,INACT,0.0	CHEMBL545363,TN,INACT,0.0	CHEMBL2443002,TN,INACT,0.0	CHEMBL98446,TP,ACT,1.0	CHEMBL81593,TN,INACT,0.0	CHEMBL3144563,TP,ACT,1.0	CHEMBL429063,TN,INACT,0.019999999552965164	CHEMBL333671,TP,ACT,0.9100000262260437	CHEMBL80807,TN,INACT,0.009999999776482582	CHEMBL354171,TP,ACT,1.0	CHEMBL289284,FP,INACT,0.9200000166893005	CHEMBL593861,TN,INACT,0.009999999776482582	CHEMBL62804,TN,INACT,0.0	CHEMBL10808,TN,INACT,0.009999999776482582	CHEMBL328925,TN,INACT,0.0	

