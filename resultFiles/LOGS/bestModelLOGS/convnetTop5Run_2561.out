ImageNetInceptionV2 CHEMBL2318 adam 0.001 30 0 0 0.8 False True
Number of active compounds :	172
Number of inactive compounds :	115
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2318_adam_0.001_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2318_adam_0.001_30_0.8/
---------------------------------
Training samples: 182
Validation samples: 58
--
Training Step: 1  | time: 36.226s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/182
[A[ATraining Step: 2  | total loss: [1m[32m0.73172[0m[0m | time: 44.460s
[2K
| Adam | epoch: 001 | loss: 0.73172 - acc: 0.3094 -- iter: 064/182
[A[ATraining Step: 3  | total loss: [1m[32m0.77677[0m[0m | time: 52.732s
[2K
| Adam | epoch: 001 | loss: 0.77677 - acc: 0.5676 -- iter: 096/182
[A[ATraining Step: 4  | total loss: [1m[32m0.83318[0m[0m | time: 61.084s
[2K
| Adam | epoch: 001 | loss: 0.83318 - acc: 0.6341 -- iter: 128/182
[A[ATraining Step: 5  | total loss: [1m[32m0.81406[0m[0m | time: 69.361s
[2K
| Adam | epoch: 001 | loss: 0.81406 - acc: 0.6062 -- iter: 160/182
[A[ATraining Step: 6  | total loss: [1m[32m0.71979[0m[0m | time: 83.545s
[2K
| Adam | epoch: 001 | loss: 0.71979 - acc: 0.5781 | val_loss: 0.62034 - val_acc: 0.6897 -- iter: 182/182
--
Training Step: 7  | total loss: [1m[32m0.47176[0m[0m | time: 6.095s
[2K
| Adam | epoch: 002 | loss: 0.47176 - acc: 0.8040 -- iter: 032/182
[A[ATraining Step: 8  | total loss: [1m[32m0.27031[0m[0m | time: 14.243s
[2K
| Adam | epoch: 002 | loss: 0.27031 - acc: 0.9142 -- iter: 064/182
[A[ATraining Step: 9  | total loss: [1m[32m0.83577[0m[0m | time: 22.546s
[2K
| Adam | epoch: 002 | loss: 0.83577 - acc: 0.6949 -- iter: 096/182
[A[ATraining Step: 10  | total loss: [1m[32m0.85641[0m[0m | time: 30.846s
[2K
| Adam | epoch: 002 | loss: 0.85641 - acc: 0.6600 -- iter: 128/182
[A[ATraining Step: 11  | total loss: [1m[32m0.71514[0m[0m | time: 39.256s
[2K
| Adam | epoch: 002 | loss: 0.71514 - acc: 0.7026 -- iter: 160/182
[A[ATraining Step: 12  | total loss: [1m[32m0.68979[0m[0m | time: 49.983s
[2K
| Adam | epoch: 002 | loss: 0.68979 - acc: 0.6677 | val_loss: 1.13430 - val_acc: 0.6897 -- iter: 182/182
--
Training Step: 13  | total loss: [1m[32m0.56198[0m[0m | time: 6.159s
[2K
| Adam | epoch: 003 | loss: 0.56198 - acc: 0.7431 -- iter: 032/182
[A[ATraining Step: 14  | total loss: [1m[32m0.52537[0m[0m | time: 12.193s
[2K
| Adam | epoch: 003 | loss: 0.52537 - acc: 0.7552 -- iter: 064/182
[A[ATraining Step: 15  | total loss: [1m[32m0.43643[0m[0m | time: 20.535s
[2K
| Adam | epoch: 003 | loss: 0.43643 - acc: 0.8154 -- iter: 096/182
[A[ATraining Step: 16  | total loss: [1m[32m0.40992[0m[0m | time: 28.870s
[2K
| Adam | epoch: 003 | loss: 0.40992 - acc: 0.8495 -- iter: 128/182
[A[ATraining Step: 17  | total loss: [1m[32m0.53386[0m[0m | time: 37.346s
[2K
| Adam | epoch: 003 | loss: 0.53386 - acc: 0.7912 -- iter: 160/182
[A[ATraining Step: 18  | total loss: [1m[32m0.41091[0m[0m | time: 48.295s
[2K
| Adam | epoch: 003 | loss: 0.41091 - acc: 0.8526 | val_loss: 1.74349 - val_acc: 0.6897 -- iter: 182/182
--
Training Step: 19  | total loss: [1m[32m0.36177[0m[0m | time: 8.533s
[2K
| Adam | epoch: 004 | loss: 0.36177 - acc: 0.8809 -- iter: 032/182
[A[ATraining Step: 20  | total loss: [1m[32m0.36545[0m[0m | time: 14.651s
[2K
| Adam | epoch: 004 | loss: 0.36545 - acc: 0.8589 -- iter: 064/182
[A[ATraining Step: 21  | total loss: [1m[32m0.40423[0m[0m | time: 20.606s
[2K
| Adam | epoch: 004 | loss: 0.40423 - acc: 0.8181 -- iter: 096/182
[A[ATraining Step: 22  | total loss: [1m[32m0.36780[0m[0m | time: 28.896s
[2K
| Adam | epoch: 004 | loss: 0.36780 - acc: 0.8317 -- iter: 128/182
[A[ATraining Step: 23  | total loss: [1m[32m0.45847[0m[0m | time: 37.218s
[2K
| Adam | epoch: 004 | loss: 0.45847 - acc: 0.7899 -- iter: 160/182
[A[ATraining Step: 24  | total loss: [1m[32m0.40524[0m[0m | time: 48.147s
[2K
| Adam | epoch: 004 | loss: 0.40524 - acc: 0.8050 | val_loss: 1.03381 - val_acc: 0.6897 -- iter: 182/182
--
Training Step: 25  | total loss: [1m[32m0.36345[0m[0m | time: 8.340s
[2K
| Adam | epoch: 005 | loss: 0.36345 - acc: 0.8326 -- iter: 032/182
[A[ATraining Step: 26  | total loss: [1m[32m0.30967[0m[0m | time: 16.573s
[2K
| Adam | epoch: 005 | loss: 0.30967 - acc: 0.8604 -- iter: 064/182
[A[ATraining Step: 27  | total loss: [1m[32m0.32944[0m[0m | time: 22.648s
[2K
| Adam | epoch: 005 | loss: 0.32944 - acc: 0.8561 -- iter: 096/182
[A[ATraining Step: 28  | total loss: [1m[32m0.40747[0m[0m | time: 28.725s
[2K
| Adam | epoch: 005 | loss: 0.40747 - acc: 0.8353 -- iter: 128/182
[A[ATraining Step: 29  | total loss: [1m[32m0.37918[0m[0m | time: 37.042s
[2K
| Adam | epoch: 005 | loss: 0.37918 - acc: 0.8532 -- iter: 160/182
[A[ATraining Step: 30  | total loss: [1m[32m0.37280[0m[0m | time: 48.064s
[2K
| Adam | epoch: 005 | loss: 0.37280 - acc: 0.8510 | val_loss: 0.60953 - val_acc: 0.6897 -- iter: 182/182
--
Training Step: 31  | total loss: [1m[32m0.35141[0m[0m | time: 8.739s
[2K
| Adam | epoch: 006 | loss: 0.35141 - acc: 0.8565 -- iter: 032/182
[A[ATraining Step: 32  | total loss: [1m[32m0.35717[0m[0m | time: 17.067s
[2K
| Adam | epoch: 006 | loss: 0.35717 - acc: 0.8466 -- iter: 064/182
[A[ATraining Step: 33  | total loss: [1m[32m0.35089[0m[0m | time: 25.461s
[2K
| Adam | epoch: 006 | loss: 0.35089 - acc: 0.8460 -- iter: 096/182
[A[ATraining Step: 34  | total loss: [1m[32m0.31445[0m[0m | time: 31.582s
[2K
| Adam | epoch: 006 | loss: 0.31445 - acc: 0.8589 -- iter: 128/182
[A[ATraining Step: 35  | total loss: [1m[32m0.30741[0m[0m | time: 37.518s
[2K
| Adam | epoch: 006 | loss: 0.30741 - acc: 0.8599 -- iter: 160/182
[A[ATraining Step: 36  | total loss: [1m[32m0.28702[0m[0m | time: 48.487s
[2K
| Adam | epoch: 006 | loss: 0.28702 - acc: 0.8700 | val_loss: 0.58457 - val_acc: 0.6897 -- iter: 182/182
--
Training Step: 37  | total loss: [1m[32m0.28753[0m[0m | time: 8.464s
[2K
| Adam | epoch: 007 | loss: 0.28753 - acc: 0.8710 -- iter: 032/182
[A[ATraining Step: 38  | total loss: [1m[32m0.25472[0m[0m | time: 17.000s
[2K
| Adam | epoch: 007 | loss: 0.25472 - acc: 0.8962 -- iter: 064/182
[A[ATraining Step: 39  | total loss: [1m[32m0.22631[0m[0m | time: 25.449s
[2K
| Adam | epoch: 007 | loss: 0.22631 - acc: 0.9101 -- iter: 096/182
[A[ATraining Step: 40  | total loss: [1m[32m0.19793[0m[0m | time: 34.051s
[2K
| Adam | epoch: 007 | loss: 0.19793 - acc: 0.9270 -- iter: 128/182
[A[ATraining Step: 41  | total loss: [1m[32m0.18791[0m[0m | time: 40.131s
[2K
| Adam | epoch: 007 | loss: 0.18791 - acc: 0.9346 -- iter: 160/182
[A[ATraining Step: 42  | total loss: [1m[32m0.16117[0m[0m | time: 48.753s
[2K
| Adam | epoch: 007 | loss: 0.16117 - acc: 0.9464 | val_loss: 0.94967 - val_acc: 0.3793 -- iter: 182/182
--
Training Step: 43  | total loss: [1m[32m0.13612[0m[0m | time: 8.238s
[2K
| Adam | epoch: 008 | loss: 0.13612 - acc: 0.9559 -- iter: 032/182
[A[ATraining Step: 44  | total loss: [1m[32m0.12312[0m[0m | time: 16.525s
[2K
| Adam | epoch: 008 | loss: 0.12312 - acc: 0.9635 -- iter: 064/182
[A[ATraining Step: 45  | total loss: [1m[32m0.21191[0m[0m | time: 24.868s
[2K
| Adam | epoch: 008 | loss: 0.21191 - acc: 0.9538 -- iter: 096/182
[A[ATraining Step: 46  | total loss: [1m[32m0.18250[0m[0m | time: 33.173s
[2K
| Adam | epoch: 008 | loss: 0.18250 - acc: 0.9615 -- iter: 128/182
[A[ATraining Step: 47  | total loss: [1m[32m0.16621[0m[0m | time: 41.658s
[2K
| Adam | epoch: 008 | loss: 0.16621 - acc: 0.9576 -- iter: 160/182
[A[ATraining Step: 48  | total loss: [1m[32m0.14934[0m[0m | time: 50.338s
[2K
| Adam | epoch: 008 | loss: 0.14934 - acc: 0.9644 | val_loss: 2.89041 - val_acc: 0.3103 -- iter: 182/182
--
Training Step: 49  | total loss: [1m[32m0.13152[0m[0m | time: 6.192s
[2K
| Adam | epoch: 009 | loss: 0.13152 - acc: 0.9700 -- iter: 032/182
[A[ATraining Step: 50  | total loss: [1m[32m0.11556[0m[0m | time: 14.613s
[2K
| Adam | epoch: 009 | loss: 0.11556 - acc: 0.9747 -- iter: 064/182
[A[ATraining Step: 51  | total loss: [1m[32m0.12680[0m[0m | time: 23.094s
[2K
| Adam | epoch: 009 | loss: 0.12680 - acc: 0.9642 -- iter: 096/182
[A[ATraining Step: 52  | total loss: [1m[32m0.11018[0m[0m | time: 31.510s
[2K
| Adam | epoch: 009 | loss: 0.11018 - acc: 0.9696 -- iter: 128/182
[A[ATraining Step: 53  | total loss: [1m[32m0.10762[0m[0m | time: 39.981s
[2K
| Adam | epoch: 009 | loss: 0.10762 - acc: 0.9695 -- iter: 160/182
[A[ATraining Step: 54  | total loss: [1m[32m0.09825[0m[0m | time: 50.860s
[2K
| Adam | epoch: 009 | loss: 0.09825 - acc: 0.9694 | val_loss: 0.96861 - val_acc: 0.8103 -- iter: 182/182
--
Training Step: 55  | total loss: [1m[32m0.08791[0m[0m | time: 6.276s
[2K
| Adam | epoch: 010 | loss: 0.08791 - acc: 0.9737 -- iter: 032/182
[A[ATraining Step: 56  | total loss: [1m[32m0.12419[0m[0m | time: 12.419s
[2K
| Adam | epoch: 010 | loss: 0.12419 - acc: 0.9519 -- iter: 064/182
[A[ATraining Step: 57  | total loss: [1m[32m0.11551[0m[0m | time: 20.771s
[2K
| Adam | epoch: 010 | loss: 0.11551 - acc: 0.9585 -- iter: 096/182
[A[ATraining Step: 58  | total loss: [1m[32m0.10353[0m[0m | time: 29.202s
[2K
| Adam | epoch: 010 | loss: 0.10353 - acc: 0.9642 -- iter: 128/182
[A[ATraining Step: 59  | total loss: [1m[32m0.13853[0m[0m | time: 37.568s
[2K
| Adam | epoch: 010 | loss: 0.13853 - acc: 0.9648 -- iter: 160/182
[A[ATraining Step: 60  | total loss: [1m[32m0.12908[0m[0m | time: 48.567s
[2K
| Adam | epoch: 010 | loss: 0.12908 - acc: 0.9653 | val_loss: 1.91646 - val_acc: 0.7069 -- iter: 182/182
--
Training Step: 61  | total loss: [1m[32m0.11796[0m[0m | time: 8.495s
[2K
| Adam | epoch: 011 | loss: 0.11796 - acc: 0.9698 -- iter: 032/182
[A[ATraining Step: 62  | total loss: [1m[32m0.10414[0m[0m | time: 14.678s
[2K
| Adam | epoch: 011 | loss: 0.10414 - acc: 0.9737 -- iter: 064/182
[A[ATraining Step: 63  | total loss: [1m[32m0.09523[0m[0m | time: 20.833s
[2K
| Adam | epoch: 011 | loss: 0.09523 - acc: 0.9771 -- iter: 096/182
[A[ATraining Step: 64  | total loss: [1m[32m0.08768[0m[0m | time: 29.279s
[2K
| Adam | epoch: 011 | loss: 0.08768 - acc: 0.9799 -- iter: 128/182
[A[ATraining Step: 65  | total loss: [1m[32m0.12405[0m[0m | time: 37.791s
[2K
| Adam | epoch: 011 | loss: 0.12405 - acc: 0.9708 -- iter: 160/182
[A[ATraining Step: 66  | total loss: [1m[32m0.13941[0m[0m | time: 48.732s
[2K
| Adam | epoch: 011 | loss: 0.13941 - acc: 0.9706 | val_loss: 0.59290 - val_acc: 0.8103 -- iter: 182/182
--
Training Step: 67  | total loss: [1m[32m0.12621[0m[0m | time: 10.298s
[2K
| Adam | epoch: 012 | loss: 0.12621 - acc: 0.9741 -- iter: 032/182
[A[ATraining Step: 68  | total loss: [1m[32m0.11889[0m[0m | time: 23.969s
[2K
| Adam | epoch: 012 | loss: 0.11889 - acc: 0.9698 -- iter: 064/182
[A[ATraining Step: 69  | total loss: [1m[32m0.11473[0m[0m | time: 34.963s
[2K
| Adam | epoch: 012 | loss: 0.11473 - acc: 0.9733 -- iter: 096/182
[A[ATraining Step: 70  | total loss: [1m[32m0.10504[0m[0m | time: 47.160s
[2K
| Adam | epoch: 012 | loss: 0.10504 - acc: 0.9764 -- iter: 128/182
[A[ATraining Step: 71  | total loss: [1m[32m0.09473[0m[0m | time: 64.511s
[2K
| Adam | epoch: 012 | loss: 0.09473 - acc: 0.9791 -- iter: 160/182
[A[ATraining Step: 72  | total loss: [1m[32m0.08601[0m[0m | time: 87.196s
[2K
| Adam | epoch: 012 | loss: 0.08601 - acc: 0.9814 | val_loss: 2.59102 - val_acc: 0.3621 -- iter: 182/182
--
Training Step: 73  | total loss: [1m[32m0.12608[0m[0m | time: 18.746s
[2K
| Adam | epoch: 013 | loss: 0.12608 - acc: 0.9766 -- iter: 032/182
[A[ATraining Step: 74  | total loss: [1m[32m0.11680[0m[0m | time: 37.349s
[2K
| Adam | epoch: 013 | loss: 0.11680 - acc: 0.9791 -- iter: 064/182
[A[ATraining Step: 75  | total loss: [1m[32m0.10853[0m[0m | time: 56.998s
[2K
| Adam | epoch: 013 | loss: 0.10853 - acc: 0.9814 -- iter: 096/182
[A[ATraining Step: 76  | total loss: [1m[32m0.10107[0m[0m | time: 69.804s
[2K
| Adam | epoch: 013 | loss: 0.10107 - acc: 0.9834 -- iter: 128/182
[A[ATraining Step: 77  | total loss: [1m[32m0.10536[0m[0m | time: 82.803s
[2K
| Adam | epoch: 013 | loss: 0.10536 - acc: 0.9803 -- iter: 160/182
[A[ATraining Step: 78  | total loss: [1m[32m0.09713[0m[0m | time: 104.405s
[2K
| Adam | epoch: 013 | loss: 0.09713 - acc: 0.9824 | val_loss: 1.19311 - val_acc: 0.6552 -- iter: 182/182
--
Training Step: 79  | total loss: [1m[32m0.09575[0m[0m | time: 10.799s
[2K
| Adam | epoch: 014 | loss: 0.09575 - acc: 0.9777 -- iter: 032/182
[A[ATraining Step: 80  | total loss: [1m[32m0.08803[0m[0m | time: 21.131s
[2K
| Adam | epoch: 014 | loss: 0.08803 - acc: 0.9800 -- iter: 064/182
[A[ATraining Step: 81  | total loss: [1m[32m0.08115[0m[0m | time: 31.969s
[2K
| Adam | epoch: 014 | loss: 0.08115 - acc: 0.9820 -- iter: 096/182
[A[ATraining Step: 82  | total loss: [1m[32m0.07454[0m[0m | time: 48.153s
[2K
| Adam | epoch: 014 | loss: 0.07454 - acc: 0.9838 -- iter: 128/182
[A[ATraining Step: 83  | total loss: [1m[32m0.07006[0m[0m | time: 61.437s
[2K
| Adam | epoch: 014 | loss: 0.07006 - acc: 0.9855 -- iter: 160/182
[A[ATraining Step: 84  | total loss: [1m[32m0.06768[0m[0m | time: 80.238s
[2K
| Adam | epoch: 014 | loss: 0.06768 - acc: 0.9869 | val_loss: 3.13766 - val_acc: 0.3103 -- iter: 182/182
--
Training Step: 85  | total loss: [1m[32m0.06266[0m[0m | time: 21.164s
[2K
| Adam | epoch: 015 | loss: 0.06266 - acc: 0.9882 -- iter: 032/182
[A[ATraining Step: 86  | total loss: [1m[32m0.06260[0m[0m | time: 43.528s
[2K
| Adam | epoch: 015 | loss: 0.06260 - acc: 0.9863 -- iter: 064/182
[A[ATraining Step: 87  | total loss: [1m[32m0.07008[0m[0m | time: 59.593s
[2K
| Adam | epoch: 015 | loss: 0.07008 - acc: 0.9845 -- iter: 096/182
[A[ATraining Step: 88  | total loss: [1m[32m0.06497[0m[0m | time: 90.887s
[2K
| Adam | epoch: 015 | loss: 0.06497 - acc: 0.9861 -- iter: 128/182
[A[ATraining Step: 89  | total loss: [1m[32m0.07866[0m[0m | time: 107.555s
[2K
| Adam | epoch: 015 | loss: 0.07866 - acc: 0.9781 -- iter: 160/182
[A[ATraining Step: 90  | total loss: [1m[32m0.09041[0m[0m | time: 125.933s
[2K
| Adam | epoch: 015 | loss: 0.09041 - acc: 0.9740 | val_loss: 5.55184 - val_acc: 0.3103 -- iter: 182/182
--
Training Step: 91  | total loss: [1m[32m0.08213[0m[0m | time: 7.920s
[2K
| Adam | epoch: 016 | loss: 0.08213 - acc: 0.9766 -- iter: 032/182
[A[ATraining Step: 92  | total loss: [1m[32m0.07435[0m[0m | time: 18.399s
[2K
| Adam | epoch: 016 | loss: 0.07435 - acc: 0.9790 -- iter: 064/182
[A[ATraining Step: 93  | total loss: [1m[32m0.07084[0m[0m | time: 29.515s
[2K
| Adam | epoch: 016 | loss: 0.07084 - acc: 0.9779 -- iter: 096/182
[A[ATraining Step: 94  | total loss: [1m[32m0.10212[0m[0m | time: 52.585s
[2K
| Adam | epoch: 016 | loss: 0.10212 - acc: 0.9739 -- iter: 128/182
[A[ATraining Step: 95  | total loss: [1m[32m0.09681[0m[0m | time: 80.187s
[2K
| Adam | epoch: 016 | loss: 0.09681 - acc: 0.9734 -- iter: 160/182
[A[ATraining Step: 96  | total loss: [1m[32m0.09521[0m[0m | time: 102.370s
[2K
| Adam | epoch: 016 | loss: 0.09521 - acc: 0.9698 | val_loss: 3.68599 - val_acc: 0.3103 -- iter: 182/182
--
Training Step: 97  | total loss: [1m[32m0.12482[0m[0m | time: 13.445s
[2K
| Adam | epoch: 017 | loss: 0.12482 - acc: 0.9572 -- iter: 032/182
[A[ATraining Step: 98  | total loss: [1m[32m0.13623[0m[0m | time: 26.285s
[2K
| Adam | epoch: 017 | loss: 0.13623 - acc: 0.9569 -- iter: 064/182
[A[ATraining Step: 99  | total loss: [1m[32m0.12713[0m[0m | time: 43.519s
[2K
| Adam | epoch: 017 | loss: 0.12713 - acc: 0.9567 -- iter: 096/182
[A[ATraining Step: 100  | total loss: [1m[32m0.14295[0m[0m | time: 60.507s
[2K
| Adam | epoch: 017 | loss: 0.14295 - acc: 0.9454 -- iter: 128/182
[A[ATraining Step: 101  | total loss: [1m[32m0.16037[0m[0m | time: 89.835s
[2K
| Adam | epoch: 017 | loss: 0.16037 - acc: 0.9415 -- iter: 160/182
[A[ATraining Step: 102  | total loss: [1m[32m0.16719[0m[0m | time: 111.567s
[2K
| Adam | epoch: 017 | loss: 0.16719 - acc: 0.9380 | val_loss: 2.08252 - val_acc: 0.7414 -- iter: 182/182
--
Training Step: 103  | total loss: [1m[32m0.15775[0m[0m | time: 12.379s
[2K
| Adam | epoch: 018 | loss: 0.15775 - acc: 0.9410 -- iter: 032/182
[A[ATraining Step: 104  | total loss: [1m[32m0.15174[0m[0m | time: 20.788s
[2K
| Adam | epoch: 018 | loss: 0.15174 - acc: 0.9407 -- iter: 064/182
[A[ATraining Step: 105  | total loss: [1m[32m0.14616[0m[0m | time: 30.881s
[2K
| Adam | epoch: 018 | loss: 0.14616 - acc: 0.9421 -- iter: 096/182
[A[ATraining Step: 106  | total loss: [1m[32m0.13603[0m[0m | time: 44.791s
[2K
| Adam | epoch: 018 | loss: 0.13603 - acc: 0.9479 -- iter: 128/182
[A[ATraining Step: 107  | total loss: [1m[32m0.12841[0m[0m | time: 58.694s
[2K
| Adam | epoch: 018 | loss: 0.12841 - acc: 0.9500 -- iter: 160/182
[A[ATraining Step: 108  | total loss: [1m[32m0.14361[0m[0m | time: 76.731s
[2K
| Adam | epoch: 018 | loss: 0.14361 - acc: 0.9518 | val_loss: 2.23268 - val_acc: 0.7241 -- iter: 182/182
--
Training Step: 109  | total loss: [1m[32m0.13786[0m[0m | time: 13.844s
[2K
| Adam | epoch: 019 | loss: 0.13786 - acc: 0.9504 -- iter: 032/182
[A[ATraining Step: 110  | total loss: [1m[32m0.12718[0m[0m | time: 27.792s
[2K
| Adam | epoch: 019 | loss: 0.12718 - acc: 0.9554 -- iter: 064/182
[A[ATraining Step: 111  | total loss: [1m[32m0.11945[0m[0m | time: 37.655s
[2K
| Adam | epoch: 019 | loss: 0.11945 - acc: 0.9598 -- iter: 096/182
[A[ATraining Step: 112  | total loss: [1m[32m0.10994[0m[0m | time: 46.480s
[2K
| Adam | epoch: 019 | loss: 0.10994 - acc: 0.9638 -- iter: 128/182
[A[ATraining Step: 113  | total loss: [1m[32m0.10034[0m[0m | time: 54.882s
[2K
| Adam | epoch: 019 | loss: 0.10034 - acc: 0.9675 -- iter: 160/182
[A[ATraining Step: 114  | total loss: [1m[32m0.12701[0m[0m | time: 65.730s
[2K
| Adam | epoch: 019 | loss: 0.12701 - acc: 0.9551 | val_loss: 0.70829 - val_acc: 0.7931 -- iter: 182/182
--
Training Step: 115  | total loss: [1m[32m0.11767[0m[0m | time: 13.219s
[2K
| Adam | epoch: 020 | loss: 0.11767 - acc: 0.9596 -- iter: 032/182
[A[ATraining Step: 116  | total loss: [1m[32m0.10722[0m[0m | time: 25.470s
[2K
| Adam | epoch: 020 | loss: 0.10722 - acc: 0.9636 -- iter: 064/182
[A[ATraining Step: 117  | total loss: [1m[32m0.09739[0m[0m | time: 39.193s
[2K
| Adam | epoch: 020 | loss: 0.09739 - acc: 0.9673 -- iter: 096/182
[A[ATraining Step: 118  | total loss: [1m[32m0.09093[0m[0m | time: 49.399s
[2K
| Adam | epoch: 020 | loss: 0.09093 - acc: 0.9705 -- iter: 128/182
[A[ATraining Step: 119  | total loss: [1m[32m0.10657[0m[0m | time: 59.466s
[2K
| Adam | epoch: 020 | loss: 0.10657 - acc: 0.9598 -- iter: 160/182
[A[ATraining Step: 120  | total loss: [1m[32m0.10569[0m[0m | time: 77.438s
[2K
| Adam | epoch: 020 | loss: 0.10569 - acc: 0.9593 | val_loss: 1.37221 - val_acc: 0.5345 -- iter: 182/182
--
Training Step: 121  | total loss: [1m[32m0.10032[0m[0m | time: 13.377s
[2K
| Adam | epoch: 021 | loss: 0.10032 - acc: 0.9603 -- iter: 032/182
[A[ATraining Step: 122  | total loss: [1m[32m0.24597[0m[0m | time: 25.485s
[2K
| Adam | epoch: 021 | loss: 0.24597 - acc: 0.9330 -- iter: 064/182
[A[ATraining Step: 123  | total loss: [1m[32m0.23098[0m[0m | time: 34.003s
[2K
| Adam | epoch: 021 | loss: 0.23098 - acc: 0.9366 -- iter: 096/182
[A[ATraining Step: 124  | total loss: [1m[32m0.22040[0m[0m | time: 42.622s
[2K
| Adam | epoch: 021 | loss: 0.22040 - acc: 0.9367 -- iter: 128/182
[A[ATraining Step: 125  | total loss: [1m[32m0.20431[0m[0m | time: 48.717s
[2K
| Adam | epoch: 021 | loss: 0.20431 - acc: 0.9430 -- iter: 160/182
[A[ATraining Step: 126  | total loss: [1m[32m0.19109[0m[0m | time: 62.455s
[2K
| Adam | epoch: 021 | loss: 0.19109 - acc: 0.9487 | val_loss: 0.76061 - val_acc: 0.7414 -- iter: 182/182
--
Training Step: 127  | total loss: [1m[32m0.17649[0m[0m | time: 13.714s
[2K
| Adam | epoch: 022 | loss: 0.17649 - acc: 0.9538 -- iter: 032/182
[A[ATraining Step: 128  | total loss: [1m[32m0.16727[0m[0m | time: 27.514s
[2K
| Adam | epoch: 022 | loss: 0.16727 - acc: 0.9522 -- iter: 064/182
[A[ATraining Step: 129  | total loss: [1m[32m0.16328[0m[0m | time: 41.313s
[2K
| Adam | epoch: 022 | loss: 0.16328 - acc: 0.9538 -- iter: 096/182
[A[ATraining Step: 130  | total loss: [1m[32m0.16804[0m[0m | time: 54.974s
[2K
| Adam | epoch: 022 | loss: 0.16804 - acc: 0.9491 -- iter: 128/182
[A[ATraining Step: 131  | total loss: [1m[32m0.15422[0m[0m | time: 68.733s
[2K
| Adam | epoch: 022 | loss: 0.15422 - acc: 0.9542 -- iter: 160/182
[A[ATraining Step: 132  | total loss: [1m[32m0.13986[0m[0m | time: 83.289s
[2K
| Adam | epoch: 022 | loss: 0.13986 - acc: 0.9588 | val_loss: 4.21683 - val_acc: 0.3103 -- iter: 182/182
--
Training Step: 133  | total loss: [1m[32m0.14514[0m[0m | time: 6.334s
[2K
| Adam | epoch: 023 | loss: 0.14514 - acc: 0.9583 -- iter: 032/182
[A[ATraining Step: 134  | total loss: [1m[32m0.13302[0m[0m | time: 15.350s
[2K
| Adam | epoch: 023 | loss: 0.13302 - acc: 0.9625 -- iter: 064/182
[A[ATraining Step: 135  | total loss: [1m[32m0.12655[0m[0m | time: 28.466s
[2K
| Adam | epoch: 023 | loss: 0.12655 - acc: 0.9663 -- iter: 096/182
[A[ATraining Step: 136  | total loss: [1m[32m0.20039[0m[0m | time: 42.922s
[2K
| Adam | epoch: 023 | loss: 0.20039 - acc: 0.9571 -- iter: 128/182
[A[ATraining Step: 137  | total loss: [1m[32m0.18492[0m[0m | time: 56.219s
[2K
| Adam | epoch: 023 | loss: 0.18492 - acc: 0.9614 -- iter: 160/182
[A[ATraining Step: 138  | total loss: [1m[32m0.17019[0m[0m | time: 73.569s
[2K
| Adam | epoch: 023 | loss: 0.17019 - acc: 0.9653 | val_loss: 1.56454 - val_acc: 0.5000 -- iter: 182/182
--
Training Step: 139  | total loss: [1m[32m0.17046[0m[0m | time: 9.545s
[2K
| Adam | epoch: 024 | loss: 0.17046 - acc: 0.9594 -- iter: 032/182
[A[ATraining Step: 140  | total loss: [1m[32m0.16243[0m[0m | time: 19.878s
[2K
| Adam | epoch: 024 | loss: 0.16243 - acc: 0.9589 -- iter: 064/182
[A[ATraining Step: 141  | total loss: [1m[32m0.14927[0m[0m | time: 33.105s
[2K
| Adam | epoch: 024 | loss: 0.14927 - acc: 0.9630 -- iter: 096/182
[A[ATraining Step: 142  | total loss: [1m[32m0.13766[0m[0m | time: 46.754s
[2K
| Adam | epoch: 024 | loss: 0.13766 - acc: 0.9667 -- iter: 128/182
[A[ATraining Step: 143  | total loss: [1m[32m0.16439[0m[0m | time: 59.560s
[2K
| Adam | epoch: 024 | loss: 0.16439 - acc: 0.9607 -- iter: 160/182
[A[ATraining Step: 144  | total loss: [1m[32m0.15543[0m[0m | time: 70.536s
[2K
| Adam | epoch: 024 | loss: 0.15543 - acc: 0.9615 | val_loss: 0.67651 - val_acc: 0.7586 -- iter: 182/182
--
Training Step: 145  | total loss: [1m[32m0.14174[0m[0m | time: 13.789s
[2K
| Adam | epoch: 025 | loss: 0.14174 - acc: 0.9653 -- iter: 032/182
[A[ATraining Step: 146  | total loss: [1m[32m0.13008[0m[0m | time: 23.471s
[2K
| Adam | epoch: 025 | loss: 0.13008 - acc: 0.9688 -- iter: 064/182
[A[ATraining Step: 147  | total loss: [1m[32m0.12610[0m[0m | time: 33.887s
[2K
| Adam | epoch: 025 | loss: 0.12610 - acc: 0.9719 -- iter: 096/182
[A[ATraining Step: 148  | total loss: [1m[32m0.11868[0m[0m | time: 45.434s
[2K
| Adam | epoch: 025 | loss: 0.11868 - acc: 0.9747 -- iter: 128/182
[A[ATraining Step: 149  | total loss: [1m[32m0.12358[0m[0m | time: 58.989s
[2K
| Adam | epoch: 025 | loss: 0.12358 - acc: 0.9710 -- iter: 160/182
[A[ATraining Step: 150  | total loss: [1m[32m0.12100[0m[0m | time: 76.180s
[2K
| Adam | epoch: 025 | loss: 0.12100 - acc: 0.9708 | val_loss: 2.34534 - val_acc: 0.3966 -- iter: 182/182
--
Training Step: 151  | total loss: [1m[32m0.11323[0m[0m | time: 12.244s
[2K
| Adam | epoch: 026 | loss: 0.11323 - acc: 0.9706 -- iter: 032/182
[A[ATraining Step: 152  | total loss: [1m[32m0.10516[0m[0m | time: 20.756s
[2K
| Adam | epoch: 026 | loss: 0.10516 - acc: 0.9735 -- iter: 064/182
[A[ATraining Step: 153  | total loss: [1m[32m0.09634[0m[0m | time: 26.705s
[2K
| Adam | epoch: 026 | loss: 0.09634 - acc: 0.9762 -- iter: 096/182
[A[ATraining Step: 154  | total loss: [1m[32m0.08879[0m[0m | time: 32.982s
[2K
| Adam | epoch: 026 | loss: 0.08879 - acc: 0.9785 -- iter: 128/182
[A[ATraining Step: 155  | total loss: [1m[32m0.08125[0m[0m | time: 44.068s
[2K
| Adam | epoch: 026 | loss: 0.08125 - acc: 0.9807 -- iter: 160/182
[A[ATraining Step: 156  | total loss: [1m[32m0.07466[0m[0m | time: 61.670s
[2K
| Adam | epoch: 026 | loss: 0.07466 - acc: 0.9826 | val_loss: 0.69862 - val_acc: 0.7931 -- iter: 182/182
--
Training Step: 157  | total loss: [1m[32m0.07261[0m[0m | time: 16.024s
[2K
| Adam | epoch: 027 | loss: 0.07261 - acc: 0.9812 -- iter: 032/182
[A[ATraining Step: 158  | total loss: [1m[32m0.06681[0m[0m | time: 30.652s
[2K
| Adam | epoch: 027 | loss: 0.06681 - acc: 0.9831 -- iter: 064/182
[A[ATraining Step: 159  | total loss: [1m[32m0.06207[0m[0m | time: 47.192s
[2K
| Adam | epoch: 027 | loss: 0.06207 - acc: 0.9848 -- iter: 096/182
[A[ATraining Step: 160  | total loss: [1m[32m0.06071[0m[0m | time: 60.035s
[2K
| Adam | epoch: 027 | loss: 0.06071 - acc: 0.9832 -- iter: 128/182
[A[ATraining Step: 161  | total loss: [1m[32m0.05527[0m[0m | time: 72.268s
[2K
| Adam | epoch: 027 | loss: 0.05527 - acc: 0.9849 -- iter: 160/182
[A[ATraining Step: 162  | total loss: [1m[32m0.05052[0m[0m | time: 94.080s
[2K
| Adam | epoch: 027 | loss: 0.05052 - acc: 0.9864 | val_loss: 1.05633 - val_acc: 0.7241 -- iter: 182/182
--
Training Step: 163  | total loss: [1m[32m0.05200[0m[0m | time: 10.644s
[2K
| Adam | epoch: 028 | loss: 0.05200 - acc: 0.9846 -- iter: 032/182
[A[ATraining Step: 164  | total loss: [1m[32m0.17109[0m[0m | time: 39.121s
[2K
| Adam | epoch: 028 | loss: 0.17109 - acc: 0.9705 -- iter: 064/182
[A[ATraining Step: 165  | total loss: [1m[32m0.15429[0m[0m | time: 58.264s
[2K
| Adam | epoch: 028 | loss: 0.15429 - acc: 0.9735 -- iter: 096/182
[A[ATraining Step: 166  | total loss: [1m[32m0.13947[0m[0m | time: 74.175s
[2K
| Adam | epoch: 028 | loss: 0.13947 - acc: 0.9761 -- iter: 128/182
[A[ATraining Step: 167  | total loss: [1m[32m0.12577[0m[0m | time: 85.381s
[2K
| Adam | epoch: 028 | loss: 0.12577 - acc: 0.9785 -- iter: 160/182
[A[ATraining Step: 168  | total loss: [1m[32m0.11767[0m[0m | time: 103.453s
[2K
| Adam | epoch: 028 | loss: 0.11767 - acc: 0.9761 | val_loss: 0.72722 - val_acc: 0.7931 -- iter: 182/182
--
Training Step: 169  | total loss: [1m[32m0.10903[0m[0m | time: 16.032s
[2K
| Adam | epoch: 029 | loss: 0.10903 - acc: 0.9785 -- iter: 032/182
[A[ATraining Step: 170  | total loss: [1m[32m0.10315[0m[0m | time: 31.997s
[2K
| Adam | epoch: 029 | loss: 0.10315 - acc: 0.9775 -- iter: 064/182
[A[ATraining Step: 171  | total loss: [1m[32m0.09483[0m[0m | time: 48.250s
[2K
| Adam | epoch: 029 | loss: 0.09483 - acc: 0.9798 -- iter: 096/182
[A[ATraining Step: 172  | total loss: [1m[32m0.08692[0m[0m | time: 64.116s
[2K
| Adam | epoch: 029 | loss: 0.08692 - acc: 0.9818 -- iter: 128/182
[A[ATraining Step: 173  | total loss: [1m[32m0.08175[0m[0m | time: 78.025s
[2K
| Adam | epoch: 029 | loss: 0.08175 - acc: 0.9836 -- iter: 160/182
[A[ATraining Step: 174  | total loss: [1m[32m0.07833[0m[0m | time: 88.313s
[2K
| Adam | epoch: 029 | loss: 0.07833 - acc: 0.9821 | val_loss: 0.95606 - val_acc: 0.7414 -- iter: 182/182
--
Training Step: 175  | total loss: [1m[32m0.07151[0m[0m | time: 12.841s
[2K
| Adam | epoch: 030 | loss: 0.07151 - acc: 0.9839 -- iter: 032/182
[A[ATraining Step: 176  | total loss: [1m[32m0.06518[0m[0m | time: 28.892s
[2K
| Adam | epoch: 030 | loss: 0.06518 - acc: 0.9855 -- iter: 064/182
[A[ATraining Step: 177  | total loss: [1m[32m0.05922[0m[0m | time: 45.088s
[2K
| Adam | epoch: 030 | loss: 0.05922 - acc: 0.9870 -- iter: 096/182
[A[ATraining Step: 178  | total loss: [1m[32m0.05412[0m[0m | time: 60.524s
[2K
| Adam | epoch: 030 | loss: 0.05412 - acc: 0.9883 -- iter: 128/182
[A[ATraining Step: 179  | total loss: [1m[32m0.04940[0m[0m | time: 76.703s
[2K
| Adam | epoch: 030 | loss: 0.04940 - acc: 0.9895 -- iter: 160/182
[A[ATraining Step: 180  | total loss: [1m[32m0.04494[0m[0m | time: 97.333s
[2K
| Adam | epoch: 030 | loss: 0.04494 - acc: 0.9905 | val_loss: 0.72082 - val_acc: 0.7931 -- iter: 182/182
--
Validation AUC:0.8166666666666667
Validation AUPRC:0.8812783450959913
Test AUC:0.9187574671445639
Test AUPRC:0.9213756532665356
BestTestF1Score	0.91	0.8	0.9	0.86	0.97	30	5	22	1	0.21
BestTestMCCScore	0.9	0.79	0.9	0.93	0.87	27	2	25	4	0.75
BestTestAccuracyScore	0.9	0.79	0.9	0.93	0.87	27	2	25	4	0.75
BestValidationF1Score	0.86	0.49	0.79	0.82	0.9	36	8	10	4	0.21
BestValidationMCC	0.85	0.62	0.81	0.94	0.78	31	2	16	9	0.75
BestValidationAccuracy	0.85	0.62	0.81	0.94	0.78	31	2	16	9	0.75
TestPredictions (Threshold:0.75)
CHEMBL1767014,TP,ACT,0.9900000095367432	CHEMBL3622502,TP,ACT,0.9700000286102295	CHEMBL2337690,FN,ACT,0.550000011920929	CHEMBL2437160,TP,ACT,0.9900000095367432	CHEMBL373058,TN,INACT,0.029999999329447746	CHEMBL1939844,TN,INACT,0.03999999910593033	CHEMBL1683464,TP,ACT,1.0	CHEMBL1910463,TN,INACT,0.6499999761581421	CHEMBL3622505,TP,ACT,0.9900000095367432	CHEMBL1910446,FP,INACT,1.0	CHEMBL1784347,TP,ACT,1.0	CHEMBL397906,TN,INACT,0.05000000074505806	CHEMBL1784350,TP,ACT,0.9800000190734863	CHEMBL1683455,TP,ACT,1.0	CHEMBL3622500,TP,ACT,0.9900000095367432	CHEMBL219234,TN,INACT,0.009999999776482582	CHEMBL369234,TN,INACT,0.029999999329447746	CHEMBL16433,TN,INACT,0.009999999776482582	CHEMBL70273,TN,INACT,0.07000000029802322	CHEMBL1910460,TP,ACT,0.9800000190734863	CHEMBL1683462,TP,ACT,1.0	CHEMBL47606,TN,INACT,0.0	CHEMBL298653,TN,INACT,0.0	CHEMBL567341,TN,INACT,0.0	CHEMBL3622485,TP,ACT,0.9900000095367432	CHEMBL501414,TP,ACT,0.9900000095367432	CHEMBL1683458,TP,ACT,1.0	CHEMBL16016,TN,INACT,0.0	CHEMBL2374449,TN,INACT,0.20000000298023224	CHEMBL1910465,FN,ACT,0.7300000190734863	CHEMBL200221,TP,ACT,1.0	CHEMBL412073,TN,INACT,0.009999999776482582	CHEMBL1270274,TN,INACT,0.0	CHEMBL3622492,TP,ACT,0.7699999809265137	CHEMBL241897,TN,INACT,0.07999999821186066	CHEMBL360704,FN,ACT,0.699999988079071	CHEMBL573714,TN,INACT,0.0	CHEMBL1910444,TN,INACT,0.019999999552965164	CHEMBL1683447,TP,ACT,1.0	CHEMBL466881,TP,ACT,1.0	CHEMBL243190,TN,INACT,0.019999999552965164	CHEMBL75703,TN,INACT,0.0	CHEMBL1270466,TN,INACT,0.0	CHEMBL418568,TN,INACT,0.0	CHEMBL404644,FP,INACT,1.0	CHEMBL1784338,TP,ACT,0.9900000095367432	CHEMBL3358153,FN,ACT,0.0	CHEMBL1683452,TP,ACT,1.0	CHEMBL2437188,TN,INACT,0.6700000166893005	CHEMBL562003,TP,ACT,0.8799999952316284	CHEMBL1784358,TP,ACT,0.949999988079071	CHEMBL425792,TN,INACT,0.07000000029802322	CHEMBL1683448,TP,ACT,1.0	CHEMBL183935,TP,ACT,0.7699999809265137	CHEMBL1784360,TP,ACT,0.7799999713897705	CHEMBL1910464,TN,INACT,0.5799999833106995	CHEMBL1784337,TP,ACT,0.9700000286102295	CHEMBL466016,TP,ACT,0.9900000095367432	

