CNNModel CHEMBL4051 adam 0.0005 30 128 0 0.6 False True
Number of active compounds :	172
Number of inactive compounds :	172
---------------------------------
Run id: CNNModel_CHEMBL4051_adam_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4051_adam_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 191
Validation samples: 60
--
Training Step: 1  | time: 0.791s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/191
[A[ATraining Step: 2  | total loss: [1m[32m0.62393[0m[0m | time: 1.613s
[2K
| Adam | epoch: 001 | loss: 0.62393 - acc: 0.4219 -- iter: 064/191
[A[ATraining Step: 3  | total loss: [1m[32m0.68035[0m[0m | time: 2.359s
[2K
| Adam | epoch: 001 | loss: 0.68035 - acc: 0.5369 -- iter: 096/191
[A[ATraining Step: 4  | total loss: [1m[32m0.68927[0m[0m | time: 3.122s
[2K
| Adam | epoch: 001 | loss: 0.68927 - acc: 0.5561 -- iter: 128/191
[A[ATraining Step: 5  | total loss: [1m[32m0.68937[0m[0m | time: 3.846s
[2K
| Adam | epoch: 001 | loss: 0.68937 - acc: 0.6038 -- iter: 160/191
[A[ATraining Step: 6  | total loss: [1m[32m0.69462[0m[0m | time: 5.577s
[2K
| Adam | epoch: 001 | loss: 0.69462 - acc: 0.4969 | val_loss: 0.69260 - val_acc: 0.5167 -- iter: 191/191
--
Training Step: 7  | total loss: [1m[32m0.69097[0m[0m | time: 0.801s
[2K
| Adam | epoch: 002 | loss: 0.69097 - acc: 0.5471 -- iter: 032/191
[A[ATraining Step: 8  | total loss: [1m[32m0.68848[0m[0m | time: 1.547s
[2K
| Adam | epoch: 002 | loss: 0.68848 - acc: 0.5660 -- iter: 064/191
[A[ATraining Step: 9  | total loss: [1m[32m0.68814[0m[0m | time: 2.291s
[2K
| Adam | epoch: 002 | loss: 0.68814 - acc: 0.5641 -- iter: 096/191
[A[ATraining Step: 10  | total loss: [1m[32m0.68699[0m[0m | time: 3.004s
[2K
| Adam | epoch: 002 | loss: 0.68699 - acc: 0.5633 -- iter: 128/191
[A[ATraining Step: 11  | total loss: [1m[32m0.68905[0m[0m | time: 3.636s
[2K
| Adam | epoch: 002 | loss: 0.68905 - acc: 0.5481 -- iter: 160/191
[A[ATraining Step: 12  | total loss: [1m[32m0.68441[0m[0m | time: 5.266s
[2K
| Adam | epoch: 002 | loss: 0.68441 - acc: 0.5687 | val_loss: 0.69973 - val_acc: 0.5167 -- iter: 191/191
--
Training Step: 13  | total loss: [1m[32m0.68986[0m[0m | time: 0.813s
[2K
| Adam | epoch: 003 | loss: 0.68986 - acc: 0.5526 -- iter: 032/191
[A[ATraining Step: 14  | total loss: [1m[32m0.68614[0m[0m | time: 1.566s
[2K
| Adam | epoch: 003 | loss: 0.68614 - acc: 0.5641 -- iter: 064/191
[A[ATraining Step: 15  | total loss: [1m[32m0.68423[0m[0m | time: 2.345s
[2K
| Adam | epoch: 003 | loss: 0.68423 - acc: 0.5706 -- iter: 096/191
[A[ATraining Step: 16  | total loss: [1m[32m0.68675[0m[0m | time: 3.095s
[2K
| Adam | epoch: 003 | loss: 0.68675 - acc: 0.5558 -- iter: 128/191
[A[ATraining Step: 17  | total loss: [1m[32m0.68582[0m[0m | time: 3.760s
[2K
| Adam | epoch: 003 | loss: 0.68582 - acc: 0.5582 -- iter: 160/191
[A[ATraining Step: 18  | total loss: [1m[32m0.69067[0m[0m | time: 5.377s
[2K
| Adam | epoch: 003 | loss: 0.69067 - acc: 0.5381 | val_loss: 0.69240 - val_acc: 0.5167 -- iter: 191/191
--
Training Step: 19  | total loss: [1m[32m0.69054[0m[0m | time: 0.745s
[2K
| Adam | epoch: 004 | loss: 0.69054 - acc: 0.5358 -- iter: 032/191
[A[ATraining Step: 20  | total loss: [1m[32m0.68969[0m[0m | time: 1.430s
[2K
| Adam | epoch: 004 | loss: 0.68969 - acc: 0.5343 -- iter: 064/191
[A[ATraining Step: 21  | total loss: [1m[32m0.68786[0m[0m | time: 2.033s
[2K
| Adam | epoch: 004 | loss: 0.68786 - acc: 0.5487 -- iter: 096/191
[A[ATraining Step: 22  | total loss: [1m[32m0.68695[0m[0m | time: 2.632s
[2K
| Adam | epoch: 004 | loss: 0.68695 - acc: 0.5583 -- iter: 128/191
[A[ATraining Step: 23  | total loss: [1m[32m0.68421[0m[0m | time: 3.242s
[2K
| Adam | epoch: 004 | loss: 0.68421 - acc: 0.5777 -- iter: 160/191
[A[ATraining Step: 24  | total loss: [1m[32m0.68455[0m[0m | time: 4.873s
[2K
| Adam | epoch: 004 | loss: 0.68455 - acc: 0.5734 | val_loss: 0.69242 - val_acc: 0.5167 -- iter: 191/191
--
Training Step: 25  | total loss: [1m[32m0.68512[0m[0m | time: 0.703s
[2K
| Adam | epoch: 005 | loss: 0.68512 - acc: 0.5704 -- iter: 032/191
[A[ATraining Step: 26  | total loss: [1m[32m0.68493[0m[0m | time: 1.314s
[2K
| Adam | epoch: 005 | loss: 0.68493 - acc: 0.5683 -- iter: 064/191
[A[ATraining Step: 27  | total loss: [1m[32m0.68426[0m[0m | time: 1.913s
[2K
| Adam | epoch: 005 | loss: 0.68426 - acc: 0.5668 -- iter: 096/191
[A[ATraining Step: 28  | total loss: [1m[32m0.68483[0m[0m | time: 2.498s
[2K
| Adam | epoch: 005 | loss: 0.68483 - acc: 0.5622 -- iter: 128/191
[A[ATraining Step: 29  | total loss: [1m[32m0.68517[0m[0m | time: 3.120s
[2K
| Adam | epoch: 005 | loss: 0.68517 - acc: 0.5589 -- iter: 160/191
[A[ATraining Step: 30  | total loss: [1m[32m0.68627[0m[0m | time: 4.737s
[2K
| Adam | epoch: 005 | loss: 0.68627 - acc: 0.5523 | val_loss: 0.69310 - val_acc: 0.5167 -- iter: 191/191
--
Training Step: 31  | total loss: [1m[32m0.68500[0m[0m | time: 0.609s
[2K
| Adam | epoch: 006 | loss: 0.68500 - acc: 0.5547 -- iter: 032/191
[A[ATraining Step: 32  | total loss: [1m[32m0.69176[0m[0m | time: 1.263s
[2K
| Adam | epoch: 006 | loss: 0.69176 - acc: 0.5283 -- iter: 064/191
[A[ATraining Step: 33  | total loss: [1m[32m0.69058[0m[0m | time: 1.873s
[2K
| Adam | epoch: 006 | loss: 0.69058 - acc: 0.5290 -- iter: 096/191
[A[ATraining Step: 34  | total loss: [1m[32m0.68783[0m[0m | time: 2.473s
[2K
| Adam | epoch: 006 | loss: 0.68783 - acc: 0.5361 -- iter: 128/191
[A[ATraining Step: 35  | total loss: [1m[32m0.68334[0m[0m | time: 3.144s
[2K
| Adam | epoch: 006 | loss: 0.68334 - acc: 0.5657 -- iter: 160/191
[A[ATraining Step: 36  | total loss: [1m[32m0.67930[0m[0m | time: 4.910s
[2K
| Adam | epoch: 006 | loss: 0.67930 - acc: 0.5886 | val_loss: 0.68727 - val_acc: 0.5167 -- iter: 191/191
--
Training Step: 37  | total loss: [1m[32m0.67948[0m[0m | time: 0.599s
[2K
| Adam | epoch: 007 | loss: 0.67948 - acc: 0.5833 -- iter: 032/191
[A[ATraining Step: 38  | total loss: [1m[32m0.68349[0m[0m | time: 1.241s
[2K
| Adam | epoch: 007 | loss: 0.68349 - acc: 0.5609 -- iter: 064/191
[A[ATraining Step: 39  | total loss: [1m[32m0.68475[0m[0m | time: 1.848s
[2K
| Adam | epoch: 007 | loss: 0.68475 - acc: 0.5493 -- iter: 096/191
[A[ATraining Step: 40  | total loss: [1m[32m0.67394[0m[0m | time: 2.580s
[2K
| Adam | epoch: 007 | loss: 0.67394 - acc: 0.5869 -- iter: 128/191
[A[ATraining Step: 41  | total loss: [1m[32m0.67213[0m[0m | time: 3.320s
[2K
| Adam | epoch: 007 | loss: 0.67213 - acc: 0.5882 -- iter: 160/191
[A[ATraining Step: 42  | total loss: [1m[32m0.67794[0m[0m | time: 5.089s
[2K
| Adam | epoch: 007 | loss: 0.67794 - acc: 0.5694 | val_loss: 0.68322 - val_acc: 0.5167 -- iter: 191/191
--
Training Step: 43  | total loss: [1m[32m0.68269[0m[0m | time: 0.775s
[2K
| Adam | epoch: 008 | loss: 0.68269 - acc: 0.5543 -- iter: 032/191
[A[ATraining Step: 44  | total loss: [1m[32m0.68265[0m[0m | time: 1.387s
[2K
| Adam | epoch: 008 | loss: 0.68265 - acc: 0.5503 -- iter: 064/191
[A[ATraining Step: 45  | total loss: [1m[32m0.67466[0m[0m | time: 1.998s
[2K
| Adam | epoch: 008 | loss: 0.67466 - acc: 0.5736 -- iter: 096/191
[A[ATraining Step: 46  | total loss: [1m[32m0.67368[0m[0m | time: 2.604s
[2K
| Adam | epoch: 008 | loss: 0.67368 - acc: 0.5665 -- iter: 128/191
[A[ATraining Step: 47  | total loss: [1m[32m0.67134[0m[0m | time: 3.206s
[2K
| Adam | epoch: 008 | loss: 0.67134 - acc: 0.5608 -- iter: 160/191
[A[ATraining Step: 48  | total loss: [1m[32m0.67053[0m[0m | time: 4.806s
[2K
| Adam | epoch: 008 | loss: 0.67053 - acc: 0.5610 | val_loss: 0.66009 - val_acc: 0.5167 -- iter: 191/191
--
Training Step: 49  | total loss: [1m[32m0.67133[0m[0m | time: 0.604s
[2K
| Adam | epoch: 009 | loss: 0.67133 - acc: 0.5489 -- iter: 032/191
[A[ATraining Step: 50  | total loss: [1m[32m0.67125[0m[0m | time: 1.220s
[2K
| Adam | epoch: 009 | loss: 0.67125 - acc: 0.5388 -- iter: 064/191
[A[ATraining Step: 51  | total loss: [1m[32m0.66680[0m[0m | time: 1.842s
[2K
| Adam | epoch: 009 | loss: 0.66680 - acc: 0.5376 -- iter: 096/191
[A[ATraining Step: 52  | total loss: [1m[32m0.66421[0m[0m | time: 2.454s
[2K
| Adam | epoch: 009 | loss: 0.66421 - acc: 0.5414 -- iter: 128/191
[A[ATraining Step: 53  | total loss: [1m[32m0.66027[0m[0m | time: 3.085s
[2K
| Adam | epoch: 009 | loss: 0.66027 - acc: 0.5353 -- iter: 160/191
[A[ATraining Step: 54  | total loss: [1m[32m0.65645[0m[0m | time: 4.721s
[2K
| Adam | epoch: 009 | loss: 0.65645 - acc: 0.5301 | val_loss: 0.62523 - val_acc: 0.6167 -- iter: 191/191
--
Training Step: 55  | total loss: [1m[32m0.64457[0m[0m | time: 0.594s
[2K
| Adam | epoch: 010 | loss: 0.64457 - acc: 0.5482 -- iter: 032/191
[A[ATraining Step: 56  | total loss: [1m[32m0.64140[0m[0m | time: 1.207s
[2K
| Adam | epoch: 010 | loss: 0.64140 - acc: 0.5527 -- iter: 064/191
[A[ATraining Step: 57  | total loss: [1m[32m0.63654[0m[0m | time: 1.815s
[2K
| Adam | epoch: 010 | loss: 0.63654 - acc: 0.5566 -- iter: 096/191
[A[ATraining Step: 58  | total loss: [1m[32m0.62479[0m[0m | time: 2.434s
[2K
| Adam | epoch: 010 | loss: 0.62479 - acc: 0.5957 -- iter: 128/191
[A[ATraining Step: 59  | total loss: [1m[32m0.61188[0m[0m | time: 3.048s
[2K
| Adam | epoch: 010 | loss: 0.61188 - acc: 0.6123 -- iter: 160/191
[A[ATraining Step: 60  | total loss: [1m[32m0.59991[0m[0m | time: 4.636s
[2K
| Adam | epoch: 010 | loss: 0.59991 - acc: 0.6388 | val_loss: 0.53429 - val_acc: 0.8167 -- iter: 191/191
--
Training Step: 61  | total loss: [1m[32m0.59876[0m[0m | time: 0.634s
[2K
| Adam | epoch: 011 | loss: 0.59876 - acc: 0.6492 -- iter: 032/191
[A[ATraining Step: 62  | total loss: [1m[32m0.59237[0m[0m | time: 1.232s
[2K
| Adam | epoch: 011 | loss: 0.59237 - acc: 0.6662 -- iter: 064/191
[A[ATraining Step: 63  | total loss: [1m[32m0.58746[0m[0m | time: 1.837s
[2K
| Adam | epoch: 011 | loss: 0.58746 - acc: 0.6840 -- iter: 096/191
[A[ATraining Step: 64  | total loss: [1m[32m0.56701[0m[0m | time: 2.473s
[2K
| Adam | epoch: 011 | loss: 0.56701 - acc: 0.7073 -- iter: 128/191
[A[ATraining Step: 65  | total loss: [1m[32m0.55713[0m[0m | time: 3.097s
[2K
| Adam | epoch: 011 | loss: 0.55713 - acc: 0.7126 -- iter: 160/191
[A[ATraining Step: 66  | total loss: [1m[32m0.52926[0m[0m | time: 4.707s
[2K
| Adam | epoch: 011 | loss: 0.52926 - acc: 0.7323 | val_loss: 0.52229 - val_acc: 0.7833 -- iter: 191/191
--
Training Step: 67  | total loss: [1m[32m0.51650[0m[0m | time: 0.633s
[2K
| Adam | epoch: 012 | loss: 0.51650 - acc: 0.7457 -- iter: 032/191
[A[ATraining Step: 68  | total loss: [1m[32m0.51624[0m[0m | time: 1.250s
[2K
| Adam | epoch: 012 | loss: 0.51624 - acc: 0.7425 -- iter: 064/191
[A[ATraining Step: 69  | total loss: [1m[32m0.52168[0m[0m | time: 1.871s
[2K
| Adam | epoch: 012 | loss: 0.52168 - acc: 0.7361 -- iter: 096/191
[A[ATraining Step: 70  | total loss: [1m[32m0.50564[0m[0m | time: 2.455s
[2K
| Adam | epoch: 012 | loss: 0.50564 - acc: 0.7554 -- iter: 128/191
[A[ATraining Step: 71  | total loss: [1m[32m0.50433[0m[0m | time: 3.098s
[2K
| Adam | epoch: 012 | loss: 0.50433 - acc: 0.7612 -- iter: 160/191
[A[ATraining Step: 72  | total loss: [1m[32m0.47893[0m[0m | time: 4.744s
[2K
| Adam | epoch: 012 | loss: 0.47893 - acc: 0.7740 | val_loss: 0.39261 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 73  | total loss: [1m[32m0.46693[0m[0m | time: 0.647s
[2K
| Adam | epoch: 013 | loss: 0.46693 - acc: 0.7887 -- iter: 032/191
[A[ATraining Step: 74  | total loss: [1m[32m0.45867[0m[0m | time: 1.274s
[2K
| Adam | epoch: 013 | loss: 0.45867 - acc: 0.7913 -- iter: 064/191
[A[ATraining Step: 75  | total loss: [1m[32m0.44382[0m[0m | time: 1.879s
[2K
| Adam | epoch: 013 | loss: 0.44382 - acc: 0.8038 -- iter: 096/191
[A[ATraining Step: 76  | total loss: [1m[32m0.42661[0m[0m | time: 2.479s
[2K
| Adam | epoch: 013 | loss: 0.42661 - acc: 0.8147 -- iter: 128/191
[A[ATraining Step: 77  | total loss: [1m[32m0.43973[0m[0m | time: 3.074s
[2K
| Adam | epoch: 013 | loss: 0.43973 - acc: 0.8139 -- iter: 160/191
[A[ATraining Step: 78  | total loss: [1m[32m0.45996[0m[0m | time: 4.695s
[2K
| Adam | epoch: 013 | loss: 0.45996 - acc: 0.8063 | val_loss: 0.35349 - val_acc: 0.8667 -- iter: 191/191
--
Training Step: 79  | total loss: [1m[32m0.45973[0m[0m | time: 0.616s
[2K
| Adam | epoch: 014 | loss: 0.45973 - acc: 0.8102 -- iter: 032/191
[A[ATraining Step: 80  | total loss: [1m[32m0.45297[0m[0m | time: 1.204s
[2K
| Adam | epoch: 014 | loss: 0.45297 - acc: 0.8104 -- iter: 064/191
[A[ATraining Step: 81  | total loss: [1m[32m0.43844[0m[0m | time: 1.820s
[2K
| Adam | epoch: 014 | loss: 0.43844 - acc: 0.8170 -- iter: 096/191
[A[ATraining Step: 82  | total loss: [1m[32m0.41682[0m[0m | time: 2.428s
[2K
| Adam | epoch: 014 | loss: 0.41682 - acc: 0.8259 -- iter: 128/191
[A[ATraining Step: 83  | total loss: [1m[32m0.41155[0m[0m | time: 3.020s
[2K
| Adam | epoch: 014 | loss: 0.41155 - acc: 0.8277 -- iter: 160/191
[A[ATraining Step: 84  | total loss: [1m[32m0.40921[0m[0m | time: 4.616s
[2K
| Adam | epoch: 014 | loss: 0.40921 - acc: 0.8352 | val_loss: 0.33224 - val_acc: 0.8833 -- iter: 191/191
--
Training Step: 85  | total loss: [1m[32m0.40329[0m[0m | time: 0.721s
[2K
| Adam | epoch: 015 | loss: 0.40329 - acc: 0.8420 -- iter: 032/191
[A[ATraining Step: 86  | total loss: [1m[32m0.37928[0m[0m | time: 1.324s
[2K
| Adam | epoch: 015 | loss: 0.37928 - acc: 0.8578 -- iter: 064/191
[A[ATraining Step: 87  | total loss: [1m[32m0.39076[0m[0m | time: 1.931s
[2K
| Adam | epoch: 015 | loss: 0.39076 - acc: 0.8502 -- iter: 096/191
[A[ATraining Step: 88  | total loss: [1m[32m0.37566[0m[0m | time: 2.529s
[2K
| Adam | epoch: 015 | loss: 0.37566 - acc: 0.8558 -- iter: 128/191
[A[ATraining Step: 89  | total loss: [1m[32m0.36564[0m[0m | time: 3.129s
[2K
| Adam | epoch: 015 | loss: 0.36564 - acc: 0.8577 -- iter: 160/191
[A[ATraining Step: 90  | total loss: [1m[32m0.34843[0m[0m | time: 4.741s
[2K
| Adam | epoch: 015 | loss: 0.34843 - acc: 0.8719 | val_loss: 0.36971 - val_acc: 0.8167 -- iter: 191/191
--
Training Step: 91  | total loss: [1m[32m0.33894[0m[0m | time: 0.598s
[2K
| Adam | epoch: 016 | loss: 0.33894 - acc: 0.8751 -- iter: 032/191
[A[ATraining Step: 92  | total loss: [1m[32m0.32115[0m[0m | time: 1.201s
[2K
| Adam | epoch: 016 | loss: 0.32115 - acc: 0.8843 -- iter: 064/191
[A[ATraining Step: 93  | total loss: [1m[32m0.33306[0m[0m | time: 1.832s
[2K
| Adam | epoch: 016 | loss: 0.33306 - acc: 0.8771 -- iter: 096/191
[A[ATraining Step: 94  | total loss: [1m[32m0.36595[0m[0m | time: 2.432s
[2K
| Adam | epoch: 016 | loss: 0.36595 - acc: 0.8519 -- iter: 128/191
[A[ATraining Step: 95  | total loss: [1m[32m0.36117[0m[0m | time: 3.051s
[2K
| Adam | epoch: 016 | loss: 0.36117 - acc: 0.8511 -- iter: 160/191
[A[ATraining Step: 96  | total loss: [1m[32m0.34397[0m[0m | time: 4.688s
[2K
| Adam | epoch: 016 | loss: 0.34397 - acc: 0.8598 | val_loss: 0.46362 - val_acc: 0.8000 -- iter: 191/191
--
Training Step: 97  | total loss: [1m[32m0.33026[0m[0m | time: 0.601s
[2K
| Adam | epoch: 017 | loss: 0.33026 - acc: 0.8675 -- iter: 032/191
[A[ATraining Step: 98  | total loss: [1m[32m0.30867[0m[0m | time: 1.194s
[2K
| Adam | epoch: 017 | loss: 0.30867 - acc: 0.8775 -- iter: 064/191
[A[ATraining Step: 99  | total loss: [1m[32m0.28450[0m[0m | time: 1.830s
[2K
| Adam | epoch: 017 | loss: 0.28450 - acc: 0.8898 -- iter: 096/191
[A[ATraining Step: 100  | total loss: [1m[32m0.27846[0m[0m | time: 2.440s
[2K
| Adam | epoch: 017 | loss: 0.27846 - acc: 0.8914 -- iter: 128/191
[A[ATraining Step: 101  | total loss: [1m[32m0.27509[0m[0m | time: 3.049s
[2K
| Adam | epoch: 017 | loss: 0.27509 - acc: 0.8960 -- iter: 160/191
[A[ATraining Step: 102  | total loss: [1m[32m0.25452[0m[0m | time: 4.655s
[2K
| Adam | epoch: 017 | loss: 0.25452 - acc: 0.9064 | val_loss: 0.31122 - val_acc: 0.8500 -- iter: 191/191
--
Training Step: 103  | total loss: [1m[32m0.23818[0m[0m | time: 0.610s
[2K
| Adam | epoch: 018 | loss: 0.23818 - acc: 0.9127 -- iter: 032/191
[A[ATraining Step: 104  | total loss: [1m[32m0.22581[0m[0m | time: 1.207s
[2K
| Adam | epoch: 018 | loss: 0.22581 - acc: 0.9183 -- iter: 064/191
[A[ATraining Step: 105  | total loss: [1m[32m0.21234[0m[0m | time: 1.826s
[2K
| Adam | epoch: 018 | loss: 0.21234 - acc: 0.9232 -- iter: 096/191
[A[ATraining Step: 106  | total loss: [1m[32m0.19828[0m[0m | time: 2.433s
[2K
| Adam | epoch: 018 | loss: 0.19828 - acc: 0.9309 -- iter: 128/191
[A[ATraining Step: 107  | total loss: [1m[32m0.18863[0m[0m | time: 3.041s
[2K
| Adam | epoch: 018 | loss: 0.18863 - acc: 0.9347 -- iter: 160/191
[A[ATraining Step: 108  | total loss: [1m[32m0.21115[0m[0m | time: 4.655s
[2K
| Adam | epoch: 018 | loss: 0.21115 - acc: 0.9350 | val_loss: 0.33586 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 109  | total loss: [1m[32m0.20582[0m[0m | time: 0.644s
[2K
| Adam | epoch: 019 | loss: 0.20582 - acc: 0.9383 -- iter: 032/191
[A[ATraining Step: 110  | total loss: [1m[32m0.19404[0m[0m | time: 1.254s
[2K
| Adam | epoch: 019 | loss: 0.19404 - acc: 0.9414 -- iter: 064/191
[A[ATraining Step: 111  | total loss: [1m[32m0.19278[0m[0m | time: 1.842s
[2K
| Adam | epoch: 019 | loss: 0.19278 - acc: 0.9410 -- iter: 096/191
[A[ATraining Step: 112  | total loss: [1m[32m0.18013[0m[0m | time: 2.459s
[2K
| Adam | epoch: 019 | loss: 0.18013 - acc: 0.9469 -- iter: 128/191
[A[ATraining Step: 113  | total loss: [1m[32m0.16598[0m[0m | time: 3.073s
[2K
| Adam | epoch: 019 | loss: 0.16598 - acc: 0.9522 -- iter: 160/191
[A[ATraining Step: 114  | total loss: [1m[32m0.15335[0m[0m | time: 4.690s
[2K
| Adam | epoch: 019 | loss: 0.15335 - acc: 0.9570 | val_loss: 0.36101 - val_acc: 0.8500 -- iter: 191/191
--
Training Step: 115  | total loss: [1m[32m0.14391[0m[0m | time: 0.637s
[2K
| Adam | epoch: 020 | loss: 0.14391 - acc: 0.9613 -- iter: 032/191
[A[ATraining Step: 116  | total loss: [1m[32m0.13178[0m[0m | time: 1.266s
[2K
| Adam | epoch: 020 | loss: 0.13178 - acc: 0.9652 -- iter: 064/191
[A[ATraining Step: 117  | total loss: [1m[32m0.12150[0m[0m | time: 1.893s
[2K
| Adam | epoch: 020 | loss: 0.12150 - acc: 0.9686 -- iter: 096/191
[A[ATraining Step: 118  | total loss: [1m[32m0.11378[0m[0m | time: 2.495s
[2K
| Adam | epoch: 020 | loss: 0.11378 - acc: 0.9718 -- iter: 128/191
[A[ATraining Step: 119  | total loss: [1m[32m0.10539[0m[0m | time: 3.107s
[2K
| Adam | epoch: 020 | loss: 0.10539 - acc: 0.9746 -- iter: 160/191
[A[ATraining Step: 120  | total loss: [1m[32m0.09795[0m[0m | time: 4.720s
[2K
| Adam | epoch: 020 | loss: 0.09795 - acc: 0.9771 | val_loss: 0.42924 - val_acc: 0.7833 -- iter: 191/191
--
Training Step: 121  | total loss: [1m[32m0.10558[0m[0m | time: 0.605s
[2K
| Adam | epoch: 021 | loss: 0.10558 - acc: 0.9763 -- iter: 032/191
[A[ATraining Step: 122  | total loss: [1m[32m0.12386[0m[0m | time: 1.209s
[2K
| Adam | epoch: 021 | loss: 0.12386 - acc: 0.9755 -- iter: 064/191
[A[ATraining Step: 123  | total loss: [1m[32m0.11544[0m[0m | time: 1.843s
[2K
| Adam | epoch: 021 | loss: 0.11544 - acc: 0.9780 -- iter: 096/191
[A[ATraining Step: 124  | total loss: [1m[32m0.10588[0m[0m | time: 2.469s
[2K
| Adam | epoch: 021 | loss: 0.10588 - acc: 0.9802 -- iter: 128/191
[A[ATraining Step: 125  | total loss: [1m[32m0.11074[0m[0m | time: 3.098s
[2K
| Adam | epoch: 021 | loss: 0.11074 - acc: 0.9790 -- iter: 160/191
[A[ATraining Step: 126  | total loss: [1m[32m0.10083[0m[0m | time: 4.706s
[2K
| Adam | epoch: 021 | loss: 0.10083 - acc: 0.9811 | val_loss: 0.42048 - val_acc: 0.8000 -- iter: 191/191
--
Training Step: 127  | total loss: [1m[32m0.09199[0m[0m | time: 0.616s
[2K
| Adam | epoch: 022 | loss: 0.09199 - acc: 0.9830 -- iter: 032/191
[A[ATraining Step: 128  | total loss: [1m[32m0.08441[0m[0m | time: 1.221s
[2K
| Adam | epoch: 022 | loss: 0.08441 - acc: 0.9847 -- iter: 064/191
[A[ATraining Step: 129  | total loss: [1m[32m0.09205[0m[0m | time: 1.824s
[2K
| Adam | epoch: 022 | loss: 0.09205 - acc: 0.9831 -- iter: 096/191
[A[ATraining Step: 130  | total loss: [1m[32m0.08397[0m[0m | time: 2.428s
[2K
| Adam | epoch: 022 | loss: 0.08397 - acc: 0.9848 -- iter: 128/191
[A[ATraining Step: 131  | total loss: [1m[32m0.07781[0m[0m | time: 3.052s
[2K
| Adam | epoch: 022 | loss: 0.07781 - acc: 0.9863 -- iter: 160/191
[A[ATraining Step: 132  | total loss: [1m[32m0.07120[0m[0m | time: 4.645s
[2K
| Adam | epoch: 022 | loss: 0.07120 - acc: 0.9877 | val_loss: 0.41068 - val_acc: 0.8000 -- iter: 191/191
--
Training Step: 133  | total loss: [1m[32m0.07793[0m[0m | time: 0.603s
[2K
| Adam | epoch: 023 | loss: 0.07793 - acc: 0.9857 -- iter: 032/191
[A[ATraining Step: 134  | total loss: [1m[32m0.08189[0m[0m | time: 1.236s
[2K
| Adam | epoch: 023 | loss: 0.08189 - acc: 0.9839 -- iter: 064/191
[A[ATraining Step: 135  | total loss: [1m[32m0.07536[0m[0m | time: 1.860s
[2K
| Adam | epoch: 023 | loss: 0.07536 - acc: 0.9855 -- iter: 096/191
[A[ATraining Step: 136  | total loss: [1m[32m0.09642[0m[0m | time: 2.491s
[2K
| Adam | epoch: 023 | loss: 0.09642 - acc: 0.9838 -- iter: 128/191
[A[ATraining Step: 137  | total loss: [1m[32m0.08868[0m[0m | time: 3.115s
[2K
| Adam | epoch: 023 | loss: 0.08868 - acc: 0.9855 -- iter: 160/191
[A[ATraining Step: 138  | total loss: [1m[32m0.08348[0m[0m | time: 4.716s
[2K
| Adam | epoch: 023 | loss: 0.08348 - acc: 0.9869 | val_loss: 0.37510 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 139  | total loss: [1m[32m0.07670[0m[0m | time: 0.602s
[2K
| Adam | epoch: 024 | loss: 0.07670 - acc: 0.9882 -- iter: 032/191
[A[ATraining Step: 140  | total loss: [1m[32m0.07206[0m[0m | time: 1.194s
[2K
| Adam | epoch: 024 | loss: 0.07206 - acc: 0.9894 -- iter: 064/191
[A[ATraining Step: 141  | total loss: [1m[32m0.06677[0m[0m | time: 1.789s
[2K
| Adam | epoch: 024 | loss: 0.06677 - acc: 0.9905 -- iter: 096/191
[A[ATraining Step: 142  | total loss: [1m[32m0.06586[0m[0m | time: 2.383s
[2K
| Adam | epoch: 024 | loss: 0.06586 - acc: 0.9914 -- iter: 128/191
[A[ATraining Step: 143  | total loss: [1m[32m0.07507[0m[0m | time: 2.992s
[2K
| Adam | epoch: 024 | loss: 0.07507 - acc: 0.9891 -- iter: 160/191
[A[ATraining Step: 144  | total loss: [1m[32m0.06907[0m[0m | time: 4.616s
[2K
| Adam | epoch: 024 | loss: 0.06907 - acc: 0.9902 | val_loss: 0.40355 - val_acc: 0.8167 -- iter: 191/191
--
Training Step: 145  | total loss: [1m[32m0.06522[0m[0m | time: 0.619s
[2K
| Adam | epoch: 025 | loss: 0.06522 - acc: 0.9912 -- iter: 032/191
[A[ATraining Step: 146  | total loss: [1m[32m0.06031[0m[0m | time: 1.217s
[2K
| Adam | epoch: 025 | loss: 0.06031 - acc: 0.9921 -- iter: 064/191
[A[ATraining Step: 147  | total loss: [1m[32m0.05531[0m[0m | time: 1.833s
[2K
| Adam | epoch: 025 | loss: 0.05531 - acc: 0.9929 -- iter: 096/191
[A[ATraining Step: 148  | total loss: [1m[32m0.05079[0m[0m | time: 2.471s
[2K
| Adam | epoch: 025 | loss: 0.05079 - acc: 0.9936 -- iter: 128/191
[A[ATraining Step: 149  | total loss: [1m[32m0.04674[0m[0m | time: 3.075s
[2K
| Adam | epoch: 025 | loss: 0.04674 - acc: 0.9942 -- iter: 160/191
[A[ATraining Step: 150  | total loss: [1m[32m0.04360[0m[0m | time: 4.705s
[2K
| Adam | epoch: 025 | loss: 0.04360 - acc: 0.9948 | val_loss: 0.35336 - val_acc: 0.8500 -- iter: 191/191
--
Training Step: 151  | total loss: [1m[32m0.04181[0m[0m | time: 0.642s
[2K
| Adam | epoch: 026 | loss: 0.04181 - acc: 0.9953 -- iter: 032/191
[A[ATraining Step: 152  | total loss: [1m[32m0.03899[0m[0m | time: 1.251s
[2K
| Adam | epoch: 026 | loss: 0.03899 - acc: 0.9958 -- iter: 064/191
[A[ATraining Step: 153  | total loss: [1m[32m0.03581[0m[0m | time: 1.861s
[2K
| Adam | epoch: 026 | loss: 0.03581 - acc: 0.9962 -- iter: 096/191
[A[ATraining Step: 154  | total loss: [1m[32m0.03401[0m[0m | time: 2.455s
[2K
| Adam | epoch: 026 | loss: 0.03401 - acc: 0.9966 -- iter: 128/191
[A[ATraining Step: 155  | total loss: [1m[32m0.03174[0m[0m | time: 3.063s
[2K
| Adam | epoch: 026 | loss: 0.03174 - acc: 0.9969 -- iter: 160/191
[A[ATraining Step: 156  | total loss: [1m[32m0.02904[0m[0m | time: 4.696s
[2K
| Adam | epoch: 026 | loss: 0.02904 - acc: 0.9972 | val_loss: 0.38994 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 157  | total loss: [1m[32m0.04439[0m[0m | time: 0.623s
[2K
| Adam | epoch: 027 | loss: 0.04439 - acc: 0.9944 -- iter: 032/191
[A[ATraining Step: 158  | total loss: [1m[32m0.04030[0m[0m | time: 1.248s
[2K
| Adam | epoch: 027 | loss: 0.04030 - acc: 0.9950 -- iter: 064/191
[A[ATraining Step: 159  | total loss: [1m[32m0.03696[0m[0m | time: 1.857s
[2K
| Adam | epoch: 027 | loss: 0.03696 - acc: 0.9955 -- iter: 096/191
[A[ATraining Step: 160  | total loss: [1m[32m0.03417[0m[0m | time: 2.452s
[2K
| Adam | epoch: 027 | loss: 0.03417 - acc: 0.9959 -- iter: 128/191
[A[ATraining Step: 161  | total loss: [1m[32m0.03209[0m[0m | time: 3.061s
[2K
| Adam | epoch: 027 | loss: 0.03209 - acc: 0.9963 -- iter: 160/191
[A[ATraining Step: 162  | total loss: [1m[32m0.02940[0m[0m | time: 4.680s
[2K
| Adam | epoch: 027 | loss: 0.02940 - acc: 0.9967 | val_loss: 0.43014 - val_acc: 0.8500 -- iter: 191/191
--
Training Step: 163  | total loss: [1m[32m0.02710[0m[0m | time: 0.605s
[2K
| Adam | epoch: 028 | loss: 0.02710 - acc: 0.9970 -- iter: 032/191
[A[ATraining Step: 164  | total loss: [1m[32m0.02508[0m[0m | time: 1.223s
[2K
| Adam | epoch: 028 | loss: 0.02508 - acc: 0.9973 -- iter: 064/191
[A[ATraining Step: 165  | total loss: [1m[32m0.02455[0m[0m | time: 1.835s
[2K
| Adam | epoch: 028 | loss: 0.02455 - acc: 0.9976 -- iter: 096/191
[A[ATraining Step: 166  | total loss: [1m[32m0.02243[0m[0m | time: 2.446s
[2K
| Adam | epoch: 028 | loss: 0.02243 - acc: 0.9978 -- iter: 128/191
[A[ATraining Step: 167  | total loss: [1m[32m0.02036[0m[0m | time: 3.058s
[2K
| Adam | epoch: 028 | loss: 0.02036 - acc: 0.9980 -- iter: 160/191
[A[ATraining Step: 168  | total loss: [1m[32m0.01855[0m[0m | time: 4.674s
[2K
| Adam | epoch: 028 | loss: 0.01855 - acc: 0.9982 | val_loss: 0.51286 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 169  | total loss: [1m[32m0.01692[0m[0m | time: 0.624s
[2K
| Adam | epoch: 029 | loss: 0.01692 - acc: 0.9984 -- iter: 032/191
[A[ATraining Step: 170  | total loss: [1m[32m0.01571[0m[0m | time: 1.225s
[2K
| Adam | epoch: 029 | loss: 0.01571 - acc: 0.9986 -- iter: 064/191
[A[ATraining Step: 171  | total loss: [1m[32m0.01426[0m[0m | time: 1.863s
[2K
| Adam | epoch: 029 | loss: 0.01426 - acc: 0.9987 -- iter: 096/191
[A[ATraining Step: 172  | total loss: [1m[32m0.01343[0m[0m | time: 2.474s
[2K
| Adam | epoch: 029 | loss: 0.01343 - acc: 0.9988 -- iter: 128/191
[A[ATraining Step: 173  | total loss: [1m[32m0.01230[0m[0m | time: 3.085s
[2K
| Adam | epoch: 029 | loss: 0.01230 - acc: 0.9990 -- iter: 160/191
[A[ATraining Step: 174  | total loss: [1m[32m0.01146[0m[0m | time: 4.677s
[2K
| Adam | epoch: 029 | loss: 0.01146 - acc: 0.9991 | val_loss: 0.48003 - val_acc: 0.8333 -- iter: 191/191
--
Training Step: 175  | total loss: [1m[32m0.01046[0m[0m | time: 0.615s
[2K
| Adam | epoch: 030 | loss: 0.01046 - acc: 0.9992 -- iter: 032/191
[A[ATraining Step: 176  | total loss: [1m[32m0.00956[0m[0m | time: 1.244s
[2K
| Adam | epoch: 030 | loss: 0.00956 - acc: 0.9992 -- iter: 064/191
[A[ATraining Step: 177  | total loss: [1m[32m0.00882[0m[0m | time: 1.879s
[2K
| Adam | epoch: 030 | loss: 0.00882 - acc: 0.9993 -- iter: 096/191
[A[ATraining Step: 178  | total loss: [1m[32m0.03134[0m[0m | time: 2.498s
[2K
| Adam | epoch: 030 | loss: 0.03134 - acc: 0.9963 -- iter: 128/191
[A[ATraining Step: 179  | total loss: [1m[32m0.02868[0m[0m | time: 3.171s
[2K
| Adam | epoch: 030 | loss: 0.02868 - acc: 0.9966 -- iter: 160/191
[A[ATraining Step: 180  | total loss: [1m[32m0.03823[0m[0m | time: 4.808s
[2K
| Adam | epoch: 030 | loss: 0.03823 - acc: 0.9938 | val_loss: 0.50487 - val_acc: 0.8167 -- iter: 191/191
--
Validation AUC:0.9276974416017798
Validation AUPRC:0.9353463984996742
Test AUC:0.8487208008898776
Test AUPRC:0.8992746707076786
BestTestF1Score	0.79	0.57	0.78	0.78	0.81	25	7	22	6	0.23
BestTestMCCScore	0.73	0.63	0.78	1.0	0.58	18	0	29	13	0.97
BestTestAccuracyScore	0.73	0.63	0.78	1.0	0.58	18	0	29	13	0.97
BestValidationF1Score	0.85	0.69	0.83	0.76	0.97	28	9	22	1	0.23
BestValidationMCC	0.82	0.72	0.85	0.95	0.72	21	1	30	8	0.97
BestValidationAccuracy	0.82	0.72	0.85	0.95	0.72	21	1	30	8	0.97
TestPredictions (Threshold:0.97)
CHEMBL1945511,TN,INACT,0.009999999776482582	CHEMBL1946136,TN,INACT,0.0	CHEMBL1163,TN,INACT,0.4699999988079071	CHEMBL363325,TN,INACT,0.0	CHEMBL1222338,TP,ACT,1.0	CHEMBL3357136,TP,ACT,1.0	CHEMBL3809206,TN,INACT,0.0	CHEMBL3298812,TP,ACT,1.0	CHEMBL487654,FN,ACT,0.0	CHEMBL3765052,TN,INACT,0.0	CHEMBL3597886,TN,INACT,0.9599999785423279	CHEMBL3356632,TP,ACT,1.0	CHEMBL2018574,FN,ACT,0.9599999785423279	CHEMBL3323417,TP,ACT,1.0	CHEMBL3357125,FN,ACT,0.9599999785423279	CHEMBL2449318,TN,INACT,0.0	CHEMBL3747654,FN,ACT,0.8999999761581421	CHEMBL2449531,TN,INACT,0.12999999523162842	CHEMBL1098779,TP,ACT,0.9900000095367432	CHEMBL1831059,TP,ACT,1.0	CHEMBL2018583,FN,ACT,0.75	CHEMBL3323400,TP,ACT,1.0	CHEMBL561227,TN,INACT,0.0	CHEMBL541689,TN,INACT,0.0	CHEMBL1779949,FN,ACT,0.18000000715255737	CHEMBL521207,TN,INACT,0.9599999785423279	CHEMBL1096523,TP,ACT,0.9800000190734863	CHEMBL84391,TN,INACT,0.0	CHEMBL226968,TN,INACT,0.7400000095367432	CHEMBL3323407,TP,ACT,1.0	CHEMBL1685067,TN,INACT,0.0	CHEMBL1779950,FN,ACT,0.0	CHEMBL3597843,TN,INACT,0.10999999940395355	CHEMBL461575,FN,ACT,0.6100000143051147	CHEMBL1946134,TN,INACT,0.009999999776482582	CHEMBL2069572,FN,ACT,0.0	CHEMBL261802,TN,INACT,0.019999999552965164	CHEMBL3352989,TN,INACT,0.03999999910593033	CHEMBL384538,TN,INACT,0.0	CHEMBL6,TN,INACT,0.33000001311302185	CHEMBL486633,TN,INACT,0.5400000214576721	CHEMBL3323408,TP,ACT,0.9900000095367432	CHEMBL461939,TP,ACT,1.0	CHEMBL3237962,TN,INACT,0.0	CHEMBL3356631,TP,ACT,1.0	CHEMBL3358692,FN,ACT,0.0	CHEMBL3357129,TP,ACT,1.0	CHEMBL1831064,TP,ACT,1.0	CHEMBL502,TN,INACT,0.0	CHEMBL1831058,TP,ACT,1.0	CHEMBL3357128,TP,ACT,1.0	CHEMBL472190,FN,ACT,0.23999999463558197	CHEMBL75680,FN,ACT,0.49000000953674316	CHEMBL461576,TP,ACT,1.0	CHEMBL1945977,TN,INACT,0.0	CHEMBL1945980,TN,INACT,0.0	CHEMBL3317938,TN,INACT,0.0	CHEMBL3747159,FN,ACT,0.0	CHEMBL2449536,TN,INACT,0.7599999904632568	CHEMBL74898,TN,INACT,0.0	

