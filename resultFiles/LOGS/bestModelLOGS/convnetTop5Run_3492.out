ImageNetInceptionV2 CHEMBL1918 adam 0.0001 30 0 0 0.6 False True
Number of active compounds :	150
Number of inactive compounds :	150
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1918_adam_0.0001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1918_adam_0.0001_30_0.6/
---------------------------------
Training samples: 183
Validation samples: 58
--
Training Step: 1  | time: 104.808s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/183
[A[ATraining Step: 2  | total loss: [1m[32m0.61919[0m[0m | time: 193.022s
[2K
| Adam | epoch: 001 | loss: 0.61919 - acc: 0.5062 -- iter: 064/183
[A[ATraining Step: 3  | total loss: [1m[32m0.65225[0m[0m | time: 281.120s
[2K
| Adam | epoch: 001 | loss: 0.65225 - acc: 0.5778 -- iter: 096/183
[A[ATraining Step: 4  | total loss: [1m[32m0.69306[0m[0m | time: 324.404s
[2K
| Adam | epoch: 001 | loss: 0.69306 - acc: 0.5195 -- iter: 128/183
[A[ATraining Step: 5  | total loss: [1m[32m0.62957[0m[0m | time: 395.393s
[2K
| Adam | epoch: 001 | loss: 0.62957 - acc: 0.5709 -- iter: 160/183
[A[ATraining Step: 6  | total loss: [1m[32m0.63325[0m[0m | time: 459.814s
[2K
| Adam | epoch: 001 | loss: 0.63325 - acc: 0.6258 | val_loss: 0.67118 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 7  | total loss: [1m[32m0.59444[0m[0m | time: 9.752s
[2K
| Adam | epoch: 002 | loss: 0.59444 - acc: 0.7460 -- iter: 032/183
[A[ATraining Step: 8  | total loss: [1m[32m0.50400[0m[0m | time: 69.296s
[2K
| Adam | epoch: 002 | loss: 0.50400 - acc: 0.8155 -- iter: 064/183
[A[ATraining Step: 9  | total loss: [1m[32m0.56495[0m[0m | time: 201.643s
[2K
| Adam | epoch: 002 | loss: 0.56495 - acc: 0.7808 -- iter: 096/183
[A[ATraining Step: 10  | total loss: [1m[32m0.47046[0m[0m | time: 313.787s
[2K
| Adam | epoch: 002 | loss: 0.47046 - acc: 0.8435 -- iter: 128/183
[A[ATraining Step: 11  | total loss: [1m[32m0.41762[0m[0m | time: 474.724s
[2K
| Adam | epoch: 002 | loss: 0.41762 - acc: 0.8880 -- iter: 160/183
[A[ATraining Step: 12  | total loss: [1m[32m0.37004[0m[0m | time: 611.488s
[2K
| Adam | epoch: 002 | loss: 0.37004 - acc: 0.9103 | val_loss: 0.68977 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 13  | total loss: [1m[32m0.37931[0m[0m | time: 58.051s
[2K
| Adam | epoch: 003 | loss: 0.37931 - acc: 0.9086 -- iter: 032/183
[A[ATraining Step: 14  | total loss: [1m[32m0.36756[0m[0m | time: 99.919s
[2K
| Adam | epoch: 003 | loss: 0.36756 - acc: 0.9104 -- iter: 064/183
[A[ATraining Step: 15  | total loss: [1m[32m0.33653[0m[0m | time: 161.490s
[2K
| Adam | epoch: 003 | loss: 0.33653 - acc: 0.9284 -- iter: 096/183
[A[ATraining Step: 16  | total loss: [1m[32m0.35629[0m[0m | time: 199.985s
[2K
| Adam | epoch: 003 | loss: 0.35629 - acc: 0.9084 -- iter: 128/183
[A[ATraining Step: 17  | total loss: [1m[32m0.54578[0m[0m | time: 244.227s
[2K
| Adam | epoch: 003 | loss: 0.54578 - acc: 0.8289 -- iter: 160/183
[A[ATraining Step: 18  | total loss: [1m[32m0.42238[0m[0m | time: 348.659s
[2K
| Adam | epoch: 003 | loss: 0.42238 - acc: 0.8881 | val_loss: 0.71796 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 19  | total loss: [1m[32m0.34260[0m[0m | time: 63.111s
[2K
| Adam | epoch: 004 | loss: 0.34260 - acc: 0.9150 -- iter: 032/183
[A[ATraining Step: 20  | total loss: [1m[32m0.30904[0m[0m | time: 134.473s
[2K
| Adam | epoch: 004 | loss: 0.30904 - acc: 0.9323 -- iter: 064/183
[A[ATraining Step: 21  | total loss: [1m[32m0.27352[0m[0m | time: 201.569s
[2K
| Adam | epoch: 004 | loss: 0.27352 - acc: 0.9398 -- iter: 096/183
[A[ATraining Step: 22  | total loss: [1m[32m0.22913[0m[0m | time: 231.366s
[2K
| Adam | epoch: 004 | loss: 0.22913 - acc: 0.9579 -- iter: 128/183
[A[ATraining Step: 23  | total loss: [1m[32m0.20116[0m[0m | time: 248.249s
[2K
| Adam | epoch: 004 | loss: 0.20116 - acc: 0.9610 -- iter: 160/183
[A[ATraining Step: 24  | total loss: [1m[32m0.45850[0m[0m | time: 291.426s
[2K
| Adam | epoch: 004 | loss: 0.45850 - acc: 0.8577 | val_loss: 0.66938 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 25  | total loss: [1m[32m0.35526[0m[0m | time: 22.275s
[2K
| Adam | epoch: 005 | loss: 0.35526 - acc: 0.8965 -- iter: 032/183
[A[ATraining Step: 26  | total loss: [1m[32m0.28941[0m[0m | time: 42.642s
[2K
| Adam | epoch: 005 | loss: 0.28941 - acc: 0.9239 -- iter: 064/183
[A[ATraining Step: 27  | total loss: [1m[32m0.23218[0m[0m | time: 61.326s
[2K
| Adam | epoch: 005 | loss: 0.23218 - acc: 0.9354 -- iter: 096/183
[A[ATraining Step: 28  | total loss: [1m[32m0.22289[0m[0m | time: 101.851s
[2K
| Adam | epoch: 005 | loss: 0.22289 - acc: 0.9298 -- iter: 128/183
[A[ATraining Step: 29  | total loss: [1m[32m0.19511[0m[0m | time: 171.177s
[2K
| Adam | epoch: 005 | loss: 0.19511 - acc: 0.9363 -- iter: 160/183
[A[ATraining Step: 30  | total loss: [1m[32m0.16540[0m[0m | time: 221.064s
[2K
| Adam | epoch: 005 | loss: 0.16540 - acc: 0.9514 | val_loss: 1.03685 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 31  | total loss: [1m[32m0.31743[0m[0m | time: 18.920s
[2K
| Adam | epoch: 006 | loss: 0.31743 - acc: 0.9049 -- iter: 032/183
[A[ATraining Step: 32  | total loss: [1m[32m0.27585[0m[0m | time: 44.034s
[2K
| Adam | epoch: 006 | loss: 0.27585 - acc: 0.9193 -- iter: 064/183
[A[ATraining Step: 33  | total loss: [1m[32m0.22646[0m[0m | time: 74.770s
[2K
| Adam | epoch: 006 | loss: 0.22646 - acc: 0.9370 -- iter: 096/183
[A[ATraining Step: 34  | total loss: [1m[32m0.18656[0m[0m | time: 89.651s
[2K
| Adam | epoch: 006 | loss: 0.18656 - acc: 0.9505 -- iter: 128/183
[A[ATraining Step: 35  | total loss: [1m[32m0.15448[0m[0m | time: 182.496s
[2K
| Adam | epoch: 006 | loss: 0.15448 - acc: 0.9609 -- iter: 160/183
[A[ATraining Step: 36  | total loss: [1m[32m0.12901[0m[0m | time: 213.427s
[2K
| Adam | epoch: 006 | loss: 0.12901 - acc: 0.9689 | val_loss: 1.20663 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 37  | total loss: [1m[32m0.11040[0m[0m | time: 19.470s
[2K
| Adam | epoch: 007 | loss: 0.11040 - acc: 0.9751 -- iter: 032/183
[A[ATraining Step: 38  | total loss: [1m[32m0.11792[0m[0m | time: 33.953s
[2K
| Adam | epoch: 007 | loss: 0.11792 - acc: 0.9739 -- iter: 064/183
[A[ATraining Step: 39  | total loss: [1m[32m0.13715[0m[0m | time: 48.439s
[2K
| Adam | epoch: 007 | loss: 0.13715 - acc: 0.9609 -- iter: 096/183
[A[ATraining Step: 40  | total loss: [1m[32m0.11379[0m[0m | time: 68.815s
[2K
| Adam | epoch: 007 | loss: 0.11379 - acc: 0.9682 -- iter: 128/183
[A[ATraining Step: 41  | total loss: [1m[32m0.10220[0m[0m | time: 87.790s
[2K
| Adam | epoch: 007 | loss: 0.10220 - acc: 0.9683 -- iter: 160/183
[A[ATraining Step: 42  | total loss: [1m[32m0.09649[0m[0m | time: 156.151s
[2K
| Adam | epoch: 007 | loss: 0.09649 - acc: 0.9662 | val_loss: 1.01336 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 43  | total loss: [1m[32m0.08797[0m[0m | time: 25.479s
[2K
| Adam | epoch: 008 | loss: 0.08797 - acc: 0.9722 -- iter: 032/183
[A[ATraining Step: 44  | total loss: [1m[32m0.07496[0m[0m | time: 49.050s
[2K
| Adam | epoch: 008 | loss: 0.07496 - acc: 0.9770 -- iter: 064/183
[A[ATraining Step: 45  | total loss: [1m[32m0.09422[0m[0m | time: 73.098s
[2K
| Adam | epoch: 008 | loss: 0.09422 - acc: 0.9756 -- iter: 096/183
[A[ATraining Step: 46  | total loss: [1m[32m0.08013[0m[0m | time: 90.803s
[2K
| Adam | epoch: 008 | loss: 0.08013 - acc: 0.9797 -- iter: 128/183
[A[ATraining Step: 47  | total loss: [1m[32m0.07225[0m[0m | time: 111.210s
[2K
| Adam | epoch: 008 | loss: 0.07225 - acc: 0.9779 -- iter: 160/183
[A[ATraining Step: 48  | total loss: [1m[32m0.08273[0m[0m | time: 143.657s
[2K
| Adam | epoch: 008 | loss: 0.08273 - acc: 0.9714 | val_loss: 0.77972 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 49  | total loss: [1m[32m0.07250[0m[0m | time: 22.086s
[2K
| Adam | epoch: 009 | loss: 0.07250 - acc: 0.9759 -- iter: 032/183
[A[ATraining Step: 50  | total loss: [1m[32m0.06255[0m[0m | time: 75.952s
[2K
| Adam | epoch: 009 | loss: 0.06255 - acc: 0.9796 -- iter: 064/183
[A[ATraining Step: 51  | total loss: [1m[32m0.05425[0m[0m | time: 93.276s
[2K
| Adam | epoch: 009 | loss: 0.05425 - acc: 0.9827 -- iter: 096/183
[A[ATraining Step: 52  | total loss: [1m[32m0.33274[0m[0m | time: 106.533s
[2K
| Adam | epoch: 009 | loss: 0.33274 - acc: 0.9338 -- iter: 128/183
[A[ATraining Step: 53  | total loss: [1m[32m0.28536[0m[0m | time: 121.822s
[2K
| Adam | epoch: 009 | loss: 0.28536 - acc: 0.9435 -- iter: 160/183
[A[ATraining Step: 54  | total loss: [1m[32m0.24633[0m[0m | time: 153.782s
[2K
| Adam | epoch: 009 | loss: 0.24633 - acc: 0.9517 | val_loss: 0.49894 - val_acc: 0.7414 -- iter: 183/183
--
Training Step: 55  | total loss: [1m[32m0.21532[0m[0m | time: 14.209s
[2K
| Adam | epoch: 010 | loss: 0.21532 - acc: 0.9586 -- iter: 032/183
[A[ATraining Step: 56  | total loss: [1m[32m0.18877[0m[0m | time: 27.537s
[2K
| Adam | epoch: 010 | loss: 0.18877 - acc: 0.9645 -- iter: 064/183
[A[ATraining Step: 57  | total loss: [1m[32m0.16547[0m[0m | time: 56.924s
[2K
| Adam | epoch: 010 | loss: 0.16547 - acc: 0.9694 -- iter: 096/183
[A[ATraining Step: 58  | total loss: [1m[32m0.14674[0m[0m | time: 76.632s
[2K
| Adam | epoch: 010 | loss: 0.14674 - acc: 0.9735 -- iter: 128/183
[A[ATraining Step: 59  | total loss: [1m[32m0.14372[0m[0m | time: 99.536s
[2K
| Adam | epoch: 010 | loss: 0.14372 - acc: 0.9729 -- iter: 160/183
[A[ATraining Step: 60  | total loss: [1m[32m0.12593[0m[0m | time: 140.112s
[2K
| Adam | epoch: 010 | loss: 0.12593 - acc: 0.9765 | val_loss: 0.43005 - val_acc: 0.8276 -- iter: 183/183
--
Training Step: 61  | total loss: [1m[32m0.11236[0m[0m | time: 29.582s
[2K
| Adam | epoch: 011 | loss: 0.11236 - acc: 0.9796 -- iter: 032/183
[A[ATraining Step: 62  | total loss: [1m[32m0.10246[0m[0m | time: 41.737s
[2K
| Adam | epoch: 011 | loss: 0.10246 - acc: 0.9822 -- iter: 064/183
[A[ATraining Step: 63  | total loss: [1m[32m0.09281[0m[0m | time: 51.371s
[2K
| Adam | epoch: 011 | loss: 0.09281 - acc: 0.9844 -- iter: 096/183
[A[ATraining Step: 64  | total loss: [1m[32m0.08266[0m[0m | time: 60.010s
[2K
| Adam | epoch: 011 | loss: 0.08266 - acc: 0.9864 -- iter: 128/183
[A[ATraining Step: 65  | total loss: [1m[32m0.07533[0m[0m | time: 69.418s
[2K
| Adam | epoch: 011 | loss: 0.07533 - acc: 0.9881 -- iter: 160/183
[A[ATraining Step: 66  | total loss: [1m[32m0.08638[0m[0m | time: 87.096s
[2K
| Adam | epoch: 011 | loss: 0.08638 - acc: 0.9857 | val_loss: 0.44385 - val_acc: 0.7931 -- iter: 183/183
--
Training Step: 67  | total loss: [1m[32m0.07711[0m[0m | time: 13.816s
[2K
| Adam | epoch: 012 | loss: 0.07711 - acc: 0.9874 -- iter: 032/183
[A[ATraining Step: 68  | total loss: [1m[32m0.07363[0m[0m | time: 31.186s
[2K
| Adam | epoch: 012 | loss: 0.07363 - acc: 0.9889 -- iter: 064/183
[A[ATraining Step: 69  | total loss: [1m[32m0.06818[0m[0m | time: 41.525s
[2K
| Adam | epoch: 012 | loss: 0.06818 - acc: 0.9902 -- iter: 096/183
[A[ATraining Step: 70  | total loss: [1m[32m0.06106[0m[0m | time: 51.491s
[2K
| Adam | epoch: 012 | loss: 0.06106 - acc: 0.9913 -- iter: 128/183
[A[ATraining Step: 71  | total loss: [1m[32m0.05484[0m[0m | time: 64.569s
[2K
| Adam | epoch: 012 | loss: 0.05484 - acc: 0.9923 -- iter: 160/183
[A[ATraining Step: 72  | total loss: [1m[32m0.05162[0m[0m | time: 82.451s
[2K
| Adam | epoch: 012 | loss: 0.05162 - acc: 0.9932 | val_loss: 1.27793 - val_acc: 0.5345 -- iter: 183/183
--
Training Step: 73  | total loss: [1m[32m0.07795[0m[0m | time: 13.139s
[2K
| Adam | epoch: 013 | loss: 0.07795 - acc: 0.9870 -- iter: 032/183
[A[ATraining Step: 74  | total loss: [1m[32m0.07095[0m[0m | time: 27.112s
[2K
| Adam | epoch: 013 | loss: 0.07095 - acc: 0.9884 -- iter: 064/183
[A[ATraining Step: 75  | total loss: [1m[32m0.06491[0m[0m | time: 35.597s
[2K
| Adam | epoch: 013 | loss: 0.06491 - acc: 0.9897 -- iter: 096/183
[A[ATraining Step: 76  | total loss: [1m[32m0.05940[0m[0m | time: 42.177s
[2K
| Adam | epoch: 013 | loss: 0.05940 - acc: 0.9908 -- iter: 128/183
[A[ATraining Step: 77  | total loss: [1m[32m0.05381[0m[0m | time: 48.559s
[2K
| Adam | epoch: 013 | loss: 0.05381 - acc: 0.9918 -- iter: 160/183
[A[ATraining Step: 78  | total loss: [1m[32m0.04886[0m[0m | time: 62.399s
[2K
| Adam | epoch: 013 | loss: 0.04886 - acc: 0.9926 | val_loss: 0.97479 - val_acc: 0.6724 -- iter: 183/183
--
Training Step: 79  | total loss: [1m[32m0.04625[0m[0m | time: 13.415s
[2K
| Adam | epoch: 014 | loss: 0.04625 - acc: 0.9934 -- iter: 032/183
[A[ATraining Step: 80  | total loss: [1m[32m0.06110[0m[0m | time: 26.688s
[2K
| Adam | epoch: 014 | loss: 0.06110 - acc: 0.9909 -- iter: 064/183
[A[ATraining Step: 81  | total loss: [1m[32m0.06685[0m[0m | time: 39.779s
[2K
| Adam | epoch: 014 | loss: 0.06685 - acc: 0.9886 -- iter: 096/183
[A[ATraining Step: 82  | total loss: [1m[32m0.06057[0m[0m | time: 55.171s
[2K
| Adam | epoch: 014 | loss: 0.06057 - acc: 0.9898 -- iter: 128/183
[A[ATraining Step: 83  | total loss: [1m[32m0.05535[0m[0m | time: 65.142s
[2K
| Adam | epoch: 014 | loss: 0.05535 - acc: 0.9908 -- iter: 160/183
[A[ATraining Step: 84  | total loss: [1m[32m0.05973[0m[0m | time: 79.355s
[2K
| Adam | epoch: 014 | loss: 0.05973 - acc: 0.9874 | val_loss: 0.73333 - val_acc: 0.7414 -- iter: 183/183
--
Training Step: 85  | total loss: [1m[32m0.05500[0m[0m | time: 14.358s
[2K
| Adam | epoch: 015 | loss: 0.05500 - acc: 0.9886 -- iter: 032/183
[A[ATraining Step: 86  | total loss: [1m[32m0.07274[0m[0m | time: 27.960s
[2K
| Adam | epoch: 015 | loss: 0.07274 - acc: 0.9835 -- iter: 064/183
[A[ATraining Step: 87  | total loss: [1m[32m0.11105[0m[0m | time: 41.572s
[2K
| Adam | epoch: 015 | loss: 0.11105 - acc: 0.9758 -- iter: 096/183
[A[ATraining Step: 88  | total loss: [1m[32m0.10194[0m[0m | time: 53.752s
[2K
| Adam | epoch: 015 | loss: 0.10194 - acc: 0.9782 -- iter: 128/183
[A[ATraining Step: 89  | total loss: [1m[32m0.09382[0m[0m | time: 62.529s
[2K
| Adam | epoch: 015 | loss: 0.09382 - acc: 0.9804 -- iter: 160/183
[A[ATraining Step: 90  | total loss: [1m[32m0.08617[0m[0m | time: 73.536s
[2K
| Adam | epoch: 015 | loss: 0.08617 - acc: 0.9824 | val_loss: 0.48938 - val_acc: 0.8276 -- iter: 183/183
--
Training Step: 91  | total loss: [1m[32m0.07908[0m[0m | time: 9.891s
[2K
| Adam | epoch: 016 | loss: 0.07908 - acc: 0.9841 -- iter: 032/183
[A[ATraining Step: 92  | total loss: [1m[32m0.07237[0m[0m | time: 22.870s
[2K
| Adam | epoch: 016 | loss: 0.07237 - acc: 0.9857 -- iter: 064/183
[A[ATraining Step: 93  | total loss: [1m[32m0.07265[0m[0m | time: 35.804s
[2K
| Adam | epoch: 016 | loss: 0.07265 - acc: 0.9840 -- iter: 096/183
[A[ATraining Step: 94  | total loss: [1m[32m0.08442[0m[0m | time: 49.362s
[2K
| Adam | epoch: 016 | loss: 0.08442 - acc: 0.9825 -- iter: 128/183
[A[ATraining Step: 95  | total loss: [1m[32m0.07704[0m[0m | time: 63.489s
[2K
| Adam | epoch: 016 | loss: 0.07704 - acc: 0.9842 -- iter: 160/183
[A[ATraining Step: 96  | total loss: [1m[32m0.07920[0m[0m | time: 81.327s
[2K
| Adam | epoch: 016 | loss: 0.07920 - acc: 0.9796 | val_loss: 0.65391 - val_acc: 0.7069 -- iter: 183/183
--
Training Step: 97  | total loss: [1m[32m0.07290[0m[0m | time: 9.608s
[2K
| Adam | epoch: 017 | loss: 0.07290 - acc: 0.9816 -- iter: 032/183
[A[ATraining Step: 98  | total loss: [1m[32m0.06663[0m[0m | time: 19.589s
[2K
| Adam | epoch: 017 | loss: 0.06663 - acc: 0.9834 -- iter: 064/183
[A[ATraining Step: 99  | total loss: [1m[32m0.06076[0m[0m | time: 33.528s
[2K
| Adam | epoch: 017 | loss: 0.06076 - acc: 0.9851 -- iter: 096/183
[A[ATraining Step: 100  | total loss: [1m[32m0.05566[0m[0m | time: 42.439s
[2K
| Adam | epoch: 017 | loss: 0.05566 - acc: 0.9866 -- iter: 128/183
[A[ATraining Step: 101  | total loss: [1m[32m0.09692[0m[0m | time: 51.258s
[2K
| Adam | epoch: 017 | loss: 0.09692 - acc: 0.9817 -- iter: 160/183
[A[ATraining Step: 102  | total loss: [1m[32m0.09134[0m[0m | time: 65.942s
[2K
| Adam | epoch: 017 | loss: 0.09134 - acc: 0.9835 | val_loss: 0.86194 - val_acc: 0.6552 -- iter: 183/183
--
Training Step: 103  | total loss: [1m[32m0.08325[0m[0m | time: 13.265s
[2K
| Adam | epoch: 018 | loss: 0.08325 - acc: 0.9852 -- iter: 032/183
[A[ATraining Step: 104  | total loss: [1m[32m0.07694[0m[0m | time: 23.125s
[2K
| Adam | epoch: 018 | loss: 0.07694 - acc: 0.9866 -- iter: 064/183
[A[ATraining Step: 105  | total loss: [1m[32m0.07394[0m[0m | time: 32.790s
[2K
| Adam | epoch: 018 | loss: 0.07394 - acc: 0.9880 -- iter: 096/183
[A[ATraining Step: 106  | total loss: [1m[32m0.06870[0m[0m | time: 46.109s
[2K
| Adam | epoch: 018 | loss: 0.06870 - acc: 0.9892 -- iter: 128/183
[A[ATraining Step: 107  | total loss: [1m[32m0.06392[0m[0m | time: 59.720s
[2K
| Adam | epoch: 018 | loss: 0.06392 - acc: 0.9903 -- iter: 160/183
[A[ATraining Step: 108  | total loss: [1m[32m0.07074[0m[0m | time: 77.119s
[2K
| Adam | epoch: 018 | loss: 0.07074 - acc: 0.9881 | val_loss: 0.50313 - val_acc: 0.8103 -- iter: 183/183
--
Training Step: 109  | total loss: [1m[32m0.06470[0m[0m | time: 13.180s
[2K
| Adam | epoch: 019 | loss: 0.06470 - acc: 0.9893 -- iter: 032/183
[A[ATraining Step: 110  | total loss: [1m[32m0.05930[0m[0m | time: 26.693s
[2K
| Adam | epoch: 019 | loss: 0.05930 - acc: 0.9904 -- iter: 064/183
[A[ATraining Step: 111  | total loss: [1m[32m0.05440[0m[0m | time: 36.503s
[2K
| Adam | epoch: 019 | loss: 0.05440 - acc: 0.9913 -- iter: 096/183
[A[ATraining Step: 112  | total loss: [1m[32m0.04968[0m[0m | time: 43.281s
[2K
| Adam | epoch: 019 | loss: 0.04968 - acc: 0.9922 -- iter: 128/183
[A[ATraining Step: 113  | total loss: [1m[32m0.04537[0m[0m | time: 52.239s
[2K
| Adam | epoch: 019 | loss: 0.04537 - acc: 0.9930 -- iter: 160/183
[A[ATraining Step: 114  | total loss: [1m[32m0.04203[0m[0m | time: 67.848s
[2K
| Adam | epoch: 019 | loss: 0.04203 - acc: 0.9937 | val_loss: 0.60982 - val_acc: 0.8103 -- iter: 183/183
--
Training Step: 115  | total loss: [1m[32m0.05407[0m[0m | time: 13.657s
[2K
| Adam | epoch: 020 | loss: 0.05407 - acc: 0.9912 -- iter: 032/183
[A[ATraining Step: 116  | total loss: [1m[32m0.05032[0m[0m | time: 26.229s
[2K
| Adam | epoch: 020 | loss: 0.05032 - acc: 0.9921 -- iter: 064/183
[A[ATraining Step: 117  | total loss: [1m[32m0.04586[0m[0m | time: 39.103s
[2K
| Adam | epoch: 020 | loss: 0.04586 - acc: 0.9929 -- iter: 096/183
[A[ATraining Step: 118  | total loss: [1m[32m0.04242[0m[0m | time: 48.689s
[2K
| Adam | epoch: 020 | loss: 0.04242 - acc: 0.9936 -- iter: 128/183
[A[ATraining Step: 119  | total loss: [1m[32m0.03917[0m[0m | time: 58.070s
[2K
| Adam | epoch: 020 | loss: 0.03917 - acc: 0.9942 -- iter: 160/183
[A[ATraining Step: 120  | total loss: [1m[32m0.03605[0m[0m | time: 75.984s
[2K
| Adam | epoch: 020 | loss: 0.03605 - acc: 0.9948 | val_loss: 0.76419 - val_acc: 0.7069 -- iter: 183/183
--
Training Step: 121  | total loss: [1m[32m0.03307[0m[0m | time: 13.418s
[2K
| Adam | epoch: 021 | loss: 0.03307 - acc: 0.9953 -- iter: 032/183
[A[ATraining Step: 122  | total loss: [1m[32m0.04215[0m[0m | time: 26.940s
[2K
| Adam | epoch: 021 | loss: 0.04215 - acc: 0.9927 -- iter: 064/183
[A[ATraining Step: 123  | total loss: [1m[32m0.03907[0m[0m | time: 41.310s
[2K
| Adam | epoch: 021 | loss: 0.03907 - acc: 0.9934 -- iter: 096/183
[A[ATraining Step: 124  | total loss: [1m[32m0.03732[0m[0m | time: 50.265s
[2K
| Adam | epoch: 021 | loss: 0.03732 - acc: 0.9941 -- iter: 128/183
[A[ATraining Step: 125  | total loss: [1m[32m0.05988[0m[0m | time: 56.901s
[2K
| Adam | epoch: 021 | loss: 0.05988 - acc: 0.9915 -- iter: 160/183
[A[ATraining Step: 126  | total loss: [1m[32m0.05754[0m[0m | time: 68.707s
[2K
| Adam | epoch: 021 | loss: 0.05754 - acc: 0.9924 | val_loss: 0.89044 - val_acc: 0.6897 -- iter: 183/183
--
Training Step: 127  | total loss: [1m[32m0.05324[0m[0m | time: 13.426s
[2K
| Adam | epoch: 022 | loss: 0.05324 - acc: 0.9931 -- iter: 032/183
[A[ATraining Step: 128  | total loss: [1m[32m0.04868[0m[0m | time: 26.314s
[2K
| Adam | epoch: 022 | loss: 0.04868 - acc: 0.9938 -- iter: 064/183
[A[ATraining Step: 129  | total loss: [1m[32m0.04455[0m[0m | time: 40.029s
[2K
| Adam | epoch: 022 | loss: 0.04455 - acc: 0.9944 -- iter: 096/183
[A[ATraining Step: 130  | total loss: [1m[32m0.04254[0m[0m | time: 53.929s
[2K
| Adam | epoch: 022 | loss: 0.04254 - acc: 0.9950 -- iter: 128/183
[A[ATraining Step: 131  | total loss: [1m[32m0.03893[0m[0m | time: 67.600s
[2K
| Adam | epoch: 022 | loss: 0.03893 - acc: 0.9955 -- iter: 160/183
[A[ATraining Step: 132  | total loss: [1m[32m0.03594[0m[0m | time: 81.268s
[2K
| Adam | epoch: 022 | loss: 0.03594 - acc: 0.9959 | val_loss: 0.74535 - val_acc: 0.7241 -- iter: 183/183
--
Training Step: 133  | total loss: [1m[32m0.03322[0m[0m | time: 10.219s
[2K
| Adam | epoch: 023 | loss: 0.03322 - acc: 0.9964 -- iter: 032/183
[A[ATraining Step: 134  | total loss: [1m[32m0.03053[0m[0m | time: 23.335s
[2K
| Adam | epoch: 023 | loss: 0.03053 - acc: 0.9967 -- iter: 064/183
[A[ATraining Step: 135  | total loss: [1m[32m0.06442[0m[0m | time: 37.221s
[2K
| Adam | epoch: 023 | loss: 0.06442 - acc: 0.9908 -- iter: 096/183
[A[ATraining Step: 136  | total loss: [1m[32m0.05849[0m[0m | time: 46.317s
[2K
| Adam | epoch: 023 | loss: 0.05849 - acc: 0.9917 -- iter: 128/183
[A[ATraining Step: 137  | total loss: [1m[32m0.07495[0m[0m | time: 55.166s
[2K
| Adam | epoch: 023 | loss: 0.07495 - acc: 0.9894 -- iter: 160/183
[A[ATraining Step: 138  | total loss: [1m[32m0.06829[0m[0m | time: 72.615s
[2K
| Adam | epoch: 023 | loss: 0.06829 - acc: 0.9905 | val_loss: 0.78978 - val_acc: 0.6897 -- iter: 183/183
--
Training Step: 139  | total loss: [1m[32m0.06228[0m[0m | time: 10.081s
[2K
| Adam | epoch: 024 | loss: 0.06228 - acc: 0.9914 -- iter: 032/183
[A[ATraining Step: 140  | total loss: [1m[32m0.05652[0m[0m | time: 20.253s
[2K
| Adam | epoch: 024 | loss: 0.05652 - acc: 0.9923 -- iter: 064/183
[A[ATraining Step: 141  | total loss: [1m[32m0.05147[0m[0m | time: 33.545s
[2K
| Adam | epoch: 024 | loss: 0.05147 - acc: 0.9931 -- iter: 096/183
[A[ATraining Step: 142  | total loss: [1m[32m0.04746[0m[0m | time: 46.747s
[2K
| Adam | epoch: 024 | loss: 0.04746 - acc: 0.9938 -- iter: 128/183
[A[ATraining Step: 143  | total loss: [1m[32m0.06126[0m[0m | time: 60.107s
[2K
| Adam | epoch: 024 | loss: 0.06126 - acc: 0.9913 -- iter: 160/183
[A[ATraining Step: 144  | total loss: [1m[32m0.05576[0m[0m | time: 76.746s
[2K
| Adam | epoch: 024 | loss: 0.05576 - acc: 0.9921 | val_loss: 1.98450 - val_acc: 0.4310 -- iter: 183/183
--
Training Step: 145  | total loss: [1m[32m0.05165[0m[0m | time: 13.135s
[2K
| Adam | epoch: 025 | loss: 0.05165 - acc: 0.9929 -- iter: 032/183
[A[ATraining Step: 146  | total loss: [1m[32m0.04763[0m[0m | time: 23.310s
[2K
| Adam | epoch: 025 | loss: 0.04763 - acc: 0.9936 -- iter: 064/183
[A[ATraining Step: 147  | total loss: [1m[32m0.04363[0m[0m | time: 34.092s
[2K
| Adam | epoch: 025 | loss: 0.04363 - acc: 0.9943 -- iter: 096/183
[A[ATraining Step: 148  | total loss: [1m[32m0.03985[0m[0m | time: 43.994s
[2K
| Adam | epoch: 025 | loss: 0.03985 - acc: 0.9948 -- iter: 128/183
[A[ATraining Step: 149  | total loss: [1m[32m0.03762[0m[0m | time: 52.915s
[2K
| Adam | epoch: 025 | loss: 0.03762 - acc: 0.9954 -- iter: 160/183
[A[ATraining Step: 150  | total loss: [1m[32m0.05771[0m[0m | time: 69.050s
[2K
| Adam | epoch: 025 | loss: 0.05771 - acc: 0.9927 | val_loss: 0.82813 - val_acc: 0.6724 -- iter: 183/183
--
Training Step: 151  | total loss: [1m[32m0.05270[0m[0m | time: 30.100s
[2K
| Adam | epoch: 026 | loss: 0.05270 - acc: 0.9934 -- iter: 032/183
[A[ATraining Step: 152  | total loss: [1m[32m0.08118[0m[0m | time: 42.763s
[2K
| Adam | epoch: 026 | loss: 0.08118 - acc: 0.9910 -- iter: 064/183
[A[ATraining Step: 153  | total loss: [1m[32m0.07462[0m[0m | time: 53.053s
[2K
| Adam | epoch: 026 | loss: 0.07462 - acc: 0.9919 -- iter: 096/183
[A[ATraining Step: 154  | total loss: [1m[32m0.09016[0m[0m | time: 63.196s
[2K
| Adam | epoch: 026 | loss: 0.09016 - acc: 0.9883 -- iter: 128/183
[A[ATraining Step: 155  | total loss: [1m[32m0.09071[0m[0m | time: 76.245s
[2K
| Adam | epoch: 026 | loss: 0.09071 - acc: 0.9851 -- iter: 160/183
[A[ATraining Step: 156  | total loss: [1m[32m0.08266[0m[0m | time: 94.057s
[2K
| Adam | epoch: 026 | loss: 0.08266 - acc: 0.9866 | val_loss: 0.50283 - val_acc: 0.7931 -- iter: 183/183
--
Training Step: 157  | total loss: [1m[32m0.07589[0m[0m | time: 13.671s
[2K
| Adam | epoch: 027 | loss: 0.07589 - acc: 0.9880 -- iter: 032/183
[A[ATraining Step: 158  | total loss: [1m[32m0.06955[0m[0m | time: 26.924s
[2K
| Adam | epoch: 027 | loss: 0.06955 - acc: 0.9892 -- iter: 064/183
[A[ATraining Step: 159  | total loss: [1m[32m0.06345[0m[0m | time: 40.860s
[2K
| Adam | epoch: 027 | loss: 0.06345 - acc: 0.9903 -- iter: 096/183
[A[ATraining Step: 160  | total loss: [1m[32m0.06105[0m[0m | time: 47.282s
[2K
| Adam | epoch: 027 | loss: 0.06105 - acc: 0.9881 -- iter: 128/183
[A[ATraining Step: 161  | total loss: [1m[32m0.05776[0m[0m | time: 54.163s
[2K
| Adam | epoch: 027 | loss: 0.05776 - acc: 0.9893 -- iter: 160/183
[A[ATraining Step: 162  | total loss: [1m[32m0.05378[0m[0m | time: 66.202s
[2K
| Adam | epoch: 027 | loss: 0.05378 - acc: 0.9904 | val_loss: 0.82646 - val_acc: 0.6552 -- iter: 183/183
--
Training Step: 163  | total loss: [1m[32m0.04979[0m[0m | time: 13.565s
[2K
| Adam | epoch: 028 | loss: 0.04979 - acc: 0.9913 -- iter: 032/183
[A[ATraining Step: 164  | total loss: [1m[32m0.09234[0m[0m | time: 27.036s
[2K
| Adam | epoch: 028 | loss: 0.09234 - acc: 0.9828 -- iter: 064/183
[A[ATraining Step: 165  | total loss: [1m[32m0.08660[0m[0m | time: 40.422s
[2K
| Adam | epoch: 028 | loss: 0.08660 - acc: 0.9845 -- iter: 096/183
[A[ATraining Step: 166  | total loss: [1m[32m0.07974[0m[0m | time: 53.826s
[2K
| Adam | epoch: 028 | loss: 0.07974 - acc: 0.9861 -- iter: 128/183
[A[ATraining Step: 167  | total loss: [1m[32m0.07735[0m[0m | time: 63.578s
[2K
| Adam | epoch: 028 | loss: 0.07735 - acc: 0.9844 -- iter: 160/183
[A[ATraining Step: 168  | total loss: [1m[32m0.07076[0m[0m | time: 77.923s
[2K
| Adam | epoch: 028 | loss: 0.07076 - acc: 0.9859 | val_loss: 0.50024 - val_acc: 0.8103 -- iter: 183/183
--
Training Step: 169  | total loss: [1m[32m0.06479[0m[0m | time: 12.672s
[2K
| Adam | epoch: 029 | loss: 0.06479 - acc: 0.9873 -- iter: 032/183
[A[ATraining Step: 170  | total loss: [1m[32m0.07443[0m[0m | time: 25.823s
[2K
| Adam | epoch: 029 | loss: 0.07443 - acc: 0.9855 -- iter: 064/183
[A[ATraining Step: 171  | total loss: [1m[32m0.06762[0m[0m | time: 39.191s
[2K
| Adam | epoch: 029 | loss: 0.06762 - acc: 0.9869 -- iter: 096/183
[A[ATraining Step: 172  | total loss: [1m[32m0.06194[0m[0m | time: 52.930s
[2K
| Adam | epoch: 029 | loss: 0.06194 - acc: 0.9882 -- iter: 128/183
[A[ATraining Step: 173  | total loss: [1m[32m0.05798[0m[0m | time: 64.205s
[2K
| Adam | epoch: 029 | loss: 0.05798 - acc: 0.9894 -- iter: 160/183
[A[ATraining Step: 174  | total loss: [1m[32m0.06168[0m[0m | time: 73.739s
[2K
| Adam | epoch: 029 | loss: 0.06168 - acc: 0.9873 | val_loss: 0.49198 - val_acc: 0.8276 -- iter: 183/183
--
Training Step: 175  | total loss: [1m[32m0.05602[0m[0m | time: 10.201s
[2K
| Adam | epoch: 030 | loss: 0.05602 - acc: 0.9886 -- iter: 032/183
[A[ATraining Step: 176  | total loss: [1m[32m0.05108[0m[0m | time: 23.374s
[2K
| Adam | epoch: 030 | loss: 0.05108 - acc: 0.9897 -- iter: 064/183
[A[ATraining Step: 177  | total loss: [1m[32m0.04716[0m[0m | time: 36.724s
[2K
| Adam | epoch: 030 | loss: 0.04716 - acc: 0.9908 -- iter: 096/183
[A[ATraining Step: 178  | total loss: [1m[32m0.06502[0m[0m | time: 49.974s
[2K
| Adam | epoch: 030 | loss: 0.06502 - acc: 0.9886 -- iter: 128/183
[A[ATraining Step: 179  | total loss: [1m[32m0.05913[0m[0m | time: 63.492s
[2K
| Adam | epoch: 030 | loss: 0.05913 - acc: 0.9897 -- iter: 160/183
[A[ATraining Step: 180  | total loss: [1m[32m0.05597[0m[0m | time: 81.319s
[2K
| Adam | epoch: 030 | loss: 0.05597 - acc: 0.9907 | val_loss: 0.57484 - val_acc: 0.7931 -- iter: 183/183
--
Validation AUC:0.8623737373737373
Validation AUPRC:0.8627666526934473
Test AUC:0.9464285714285715
Test AUPRC:0.9629071650788916
BestTestF1Score	0.94	0.86	0.93	0.91	0.97	29	3	25	1	0.25
BestTestMCCScore	0.94	0.86	0.93	0.91	0.97	29	3	25	1	0.25
BestTestAccuracyScore	0.94	0.86	0.93	0.91	0.97	29	3	25	1	0.25
BestValidationF1Score	0.9	0.71	0.86	0.83	0.97	35	7	15	1	0.25
BestValidationMCC	0.9	0.71	0.86	0.83	0.97	35	7	15	1	0.25
BestValidationAccuracy	0.9	0.71	0.86	0.83	0.97	35	7	15	1	0.25
TestPredictions (Threshold:0.25)
CHEMBL3088070,TP,ACT,0.7799999713897705	CHEMBL303415,TP,ACT,0.7300000190734863	CHEMBL44926,TN,INACT,0.0	CHEMBL471104,TN,INACT,0.0	CHEMBL2160145,TN,INACT,0.009999999776482582	CHEMBL2440693,TP,ACT,0.46000000834465027	CHEMBL372643,TP,ACT,0.25	CHEMBL184613,TN,INACT,0.009999999776482582	CHEMBL3088056,TP,ACT,0.5299999713897705	CHEMBL193087,TN,INACT,0.09000000357627869	CHEMBL1814722,TN,INACT,0.0	CHEMBL2111523,TP,ACT,1.0	CHEMBL2440684,TP,ACT,1.0	CHEMBL399878,TN,INACT,0.17000000178813934	CHEMBL1916954,TN,INACT,0.019999999552965164	CHEMBL189721,TP,ACT,0.9599999785423279	CHEMBL3088063,TP,ACT,0.7099999785423279	CHEMBL396990,FP,INACT,0.33000001311302185	CHEMBL297919,TP,ACT,0.9800000190734863	CHEMBL58718,TP,ACT,0.9399999976158142	CHEMBL18251,TN,INACT,0.05000000074505806	CHEMBL2440687,FN,ACT,0.0	CHEMBL2159921,TN,INACT,0.009999999776482582	CHEMBL275040,TP,ACT,0.9800000190734863	CHEMBL59284,TP,ACT,0.9900000095367432	CHEMBL463453,TN,INACT,0.009999999776482582	CHEMBL13378,TP,ACT,1.0	CHEMBL3088054,TP,ACT,1.0	CHEMBL299180,TP,ACT,0.4300000071525574	CHEMBL399879,TN,INACT,0.23000000417232513	CHEMBL2160143,TN,INACT,0.009999999776482582	CHEMBL156768,FP,INACT,0.949999988079071	CHEMBL346339,TP,ACT,1.0	CHEMBL2333739,TN,INACT,0.0	CHEMBL304434,TP,ACT,0.9800000190734863	CHEMBL430783,TN,INACT,0.019999999552965164	CHEMBL398724,TN,INACT,0.18000000715255737	CHEMBL60114,TP,ACT,0.9900000095367432	CHEMBL1684142,TN,INACT,0.05999999865889549	CHEMBL358246,TN,INACT,0.009999999776482582	CHEMBL155101,TP,ACT,1.0	CHEMBL517675,TN,INACT,0.12999999523162842	CHEMBL154290,TN,INACT,0.07999999821186066	CHEMBL209461,TN,INACT,0.029999999329447746	CHEMBL156717,TP,ACT,0.4300000071525574	CHEMBL51054,TP,ACT,0.9800000190734863	CHEMBL59286,TP,ACT,0.9900000095367432	CHEMBL174625,TN,INACT,0.009999999776482582	CHEMBL54238,TP,ACT,0.9900000095367432	CHEMBL367027,FP,INACT,0.5600000023841858	CHEMBL292745,TP,ACT,1.0	CHEMBL155535,TP,ACT,0.9599999785423279	CHEMBL2323507,TN,INACT,0.009999999776482582	CHEMBL14935,TP,ACT,1.0	CHEMBL59297,TP,ACT,0.9900000095367432	CHEMBL3088069,TP,ACT,0.4099999964237213	CHEMBL210661,TN,INACT,0.05000000074505806	CHEMBL3410356,TN,INACT,0.0	

