CNNModel CHEMBL4017 RMSprop 0.0005 30 32 0 0.6 False True
Number of active compounds :	265
Number of inactive compounds :	265
---------------------------------
Run id: CNNModel_CHEMBL4017_RMSprop_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4017_RMSprop_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 339
Validation samples: 106
--
Training Step: 1  | time: 0.743s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/339
[A[ATraining Step: 2  | total loss: [1m[32m0.62394[0m[0m | time: 1.381s
[2K
| RMSProp | epoch: 001 | loss: 0.62394 - acc: 0.3937 -- iter: 064/339
[A[ATraining Step: 3  | total loss: [1m[32m0.68052[0m[0m | time: 1.987s
[2K
| RMSProp | epoch: 001 | loss: 0.68052 - acc: 0.5830 -- iter: 096/339
[A[ATraining Step: 4  | total loss: [1m[32m0.68997[0m[0m | time: 2.568s
[2K
| RMSProp | epoch: 001 | loss: 0.68997 - acc: 0.5676 -- iter: 128/339
[A[ATraining Step: 5  | total loss: [1m[32m0.69214[0m[0m | time: 3.211s
[2K
| RMSProp | epoch: 001 | loss: 0.69214 - acc: 0.5208 -- iter: 160/339
[A[ATraining Step: 6  | total loss: [1m[32m0.69273[0m[0m | time: 3.821s
[2K
| RMSProp | epoch: 001 | loss: 0.69273 - acc: 0.4873 -- iter: 192/339
[A[ATraining Step: 7  | total loss: [1m[32m0.69301[0m[0m | time: 4.436s
[2K
| RMSProp | epoch: 001 | loss: 0.69301 - acc: 0.4574 -- iter: 224/339
[A[ATraining Step: 8  | total loss: [1m[32m0.69316[0m[0m | time: 5.059s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4111 -- iter: 256/339
[A[ATraining Step: 9  | total loss: [1m[32m0.69315[0m[0m | time: 5.668s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.4416 -- iter: 288/339
[A[ATraining Step: 10  | total loss: [1m[32m0.69309[0m[0m | time: 6.273s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5333 -- iter: 320/339
[A[ATraining Step: 11  | total loss: [1m[32m0.69311[0m[0m | time: 7.689s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5027 | val_loss: 0.69313 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 12  | total loss: [1m[32m0.69308[0m[0m | time: 0.387s
[2K
| RMSProp | epoch: 002 | loss: 0.69308 - acc: 0.4897 -- iter: 032/339
[A[ATraining Step: 13  | total loss: [1m[32m0.69315[0m[0m | time: 1.006s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4377 -- iter: 064/339
[A[ATraining Step: 14  | total loss: [1m[32m0.69319[0m[0m | time: 1.644s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4376 -- iter: 096/339
[A[ATraining Step: 15  | total loss: [1m[32m0.69320[0m[0m | time: 2.285s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4376 -- iter: 128/339
[A[ATraining Step: 16  | total loss: [1m[32m0.69322[0m[0m | time: 2.906s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4141 -- iter: 160/339
[A[ATraining Step: 17  | total loss: [1m[32m0.69321[0m[0m | time: 3.522s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4563 -- iter: 192/339
[A[ATraining Step: 18  | total loss: [1m[32m0.69321[0m[0m | time: 4.139s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4498 -- iter: 224/339
[A[ATraining Step: 19  | total loss: [1m[32m0.69318[0m[0m | time: 4.769s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4769 -- iter: 256/339
[A[ATraining Step: 20  | total loss: [1m[32m0.69319[0m[0m | time: 5.393s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4542 -- iter: 288/339
[A[ATraining Step: 21  | total loss: [1m[32m0.69323[0m[0m | time: 6.040s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4393 -- iter: 320/339
[A[ATraining Step: 22  | total loss: [1m[32m0.69319[0m[0m | time: 7.682s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4575 | val_loss: 0.69315 - val_acc: 0.4811 -- iter: 339/339
--
Training Step: 23  | total loss: [1m[32m0.69317[0m[0m | time: 0.416s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.4517 -- iter: 032/339
[A[ATraining Step: 24  | total loss: [1m[32m0.69319[0m[0m | time: 0.820s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.4579 -- iter: 064/339
[A[ATraining Step: 25  | total loss: [1m[32m0.69321[0m[0m | time: 1.434s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4478 -- iter: 096/339
[A[ATraining Step: 26  | total loss: [1m[32m0.69318[0m[0m | time: 2.035s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.4534 -- iter: 128/339
[A[ATraining Step: 27  | total loss: [1m[32m0.69317[0m[0m | time: 2.662s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.4413 -- iter: 160/339
[A[ATraining Step: 28  | total loss: [1m[32m0.69316[0m[0m | time: 3.267s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.4638 -- iter: 192/339
[A[ATraining Step: 29  | total loss: [1m[32m0.69319[0m[0m | time: 3.870s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.4422 -- iter: 224/339
[A[ATraining Step: 30  | total loss: [1m[32m0.69318[0m[0m | time: 4.505s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.4485 -- iter: 256/339
[A[ATraining Step: 31  | total loss: [1m[32m0.69317[0m[0m | time: 5.120s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.4459 -- iter: 288/339
[A[ATraining Step: 32  | total loss: [1m[32m0.69317[0m[0m | time: 5.732s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.4792 -- iter: 320/339
[A[ATraining Step: 33  | total loss: [1m[32m0.69316[0m[0m | time: 7.348s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.4769 | val_loss: 0.69311 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 34  | total loss: [1m[32m0.69311[0m[0m | time: 0.625s
[2K
| RMSProp | epoch: 004 | loss: 0.69311 - acc: 0.5086 -- iter: 032/339
[A[ATraining Step: 35  | total loss: [1m[32m0.69311[0m[0m | time: 1.004s
[2K
| RMSProp | epoch: 004 | loss: 0.69311 - acc: 0.5003 -- iter: 064/339
[A[ATraining Step: 36  | total loss: [1m[32m0.69308[0m[0m | time: 1.385s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5379 -- iter: 096/339
[A[ATraining Step: 37  | total loss: [1m[32m0.69299[0m[0m | time: 2.003s
[2K
| RMSProp | epoch: 004 | loss: 0.69299 - acc: 0.5672 -- iter: 128/339
[A[ATraining Step: 38  | total loss: [1m[32m0.69314[0m[0m | time: 2.607s
[2K
| RMSProp | epoch: 004 | loss: 0.69314 - acc: 0.5173 -- iter: 160/339
[A[ATraining Step: 39  | total loss: [1m[32m0.69311[0m[0m | time: 3.210s
[2K
| RMSProp | epoch: 004 | loss: 0.69311 - acc: 0.5260 -- iter: 192/339
[A[ATraining Step: 40  | total loss: [1m[32m0.69308[0m[0m | time: 3.815s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5328 -- iter: 224/339
[A[ATraining Step: 41  | total loss: [1m[32m0.69308[0m[0m | time: 4.420s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5325 -- iter: 256/339
[A[ATraining Step: 42  | total loss: [1m[32m0.69309[0m[0m | time: 5.028s
[2K
| RMSProp | epoch: 004 | loss: 0.69309 - acc: 0.5323 -- iter: 288/339
[A[ATraining Step: 43  | total loss: [1m[32m0.69306[0m[0m | time: 5.641s
[2K
| RMSProp | epoch: 004 | loss: 0.69306 - acc: 0.5432 -- iter: 320/339
[A[ATraining Step: 44  | total loss: [1m[32m0.69297[0m[0m | time: 7.286s
[2K
| RMSProp | epoch: 004 | loss: 0.69297 - acc: 0.5573 | val_loss: 0.69304 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 45  | total loss: [1m[32m0.69306[0m[0m | time: 0.605s
[2K
| RMSProp | epoch: 005 | loss: 0.69306 - acc: 0.5370 -- iter: 032/339
[A[ATraining Step: 46  | total loss: [1m[32m0.69314[0m[0m | time: 1.196s
[2K
| RMSProp | epoch: 005 | loss: 0.69314 - acc: 0.5152 -- iter: 064/339
[A[ATraining Step: 47  | total loss: [1m[32m0.69326[0m[0m | time: 1.569s
[2K
| RMSProp | epoch: 005 | loss: 0.69326 - acc: 0.4871 -- iter: 096/339
[A[ATraining Step: 48  | total loss: [1m[32m0.69318[0m[0m | time: 1.949s
[2K
| RMSProp | epoch: 005 | loss: 0.69318 - acc: 0.5188 -- iter: 128/339
[A[ATraining Step: 49  | total loss: [1m[32m0.69306[0m[0m | time: 2.552s
[2K
| RMSProp | epoch: 005 | loss: 0.69306 - acc: 0.5449 -- iter: 160/339
[A[ATraining Step: 50  | total loss: [1m[32m0.69307[0m[0m | time: 3.170s
[2K
| RMSProp | epoch: 005 | loss: 0.69307 - acc: 0.5380 -- iter: 192/339
[A[ATraining Step: 51  | total loss: [1m[32m0.69318[0m[0m | time: 3.771s
[2K
| RMSProp | epoch: 005 | loss: 0.69318 - acc: 0.5131 -- iter: 224/339
[A[ATraining Step: 52  | total loss: [1m[32m0.69314[0m[0m | time: 4.379s
[2K
| RMSProp | epoch: 005 | loss: 0.69314 - acc: 0.5205 -- iter: 256/339
[A[ATraining Step: 53  | total loss: [1m[32m0.69316[0m[0m | time: 5.021s
[2K
| RMSProp | epoch: 005 | loss: 0.69316 - acc: 0.5129 -- iter: 288/339
[A[ATraining Step: 54  | total loss: [1m[32m0.69310[0m[0m | time: 5.621s
[2K
| RMSProp | epoch: 005 | loss: 0.69310 - acc: 0.5246 -- iter: 320/339
[A[ATraining Step: 55  | total loss: [1m[32m0.69318[0m[0m | time: 7.234s
[2K
| RMSProp | epoch: 005 | loss: 0.69318 - acc: 0.5077 | val_loss: 0.69302 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 56  | total loss: [1m[32m0.69312[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 006 | loss: 0.69312 - acc: 0.5242 -- iter: 032/339
[A[ATraining Step: 57  | total loss: [1m[32m0.69321[0m[0m | time: 1.254s
[2K
| RMSProp | epoch: 006 | loss: 0.69321 - acc: 0.5079 -- iter: 064/339
[A[ATraining Step: 58  | total loss: [1m[32m0.69319[0m[0m | time: 1.893s
[2K
| RMSProp | epoch: 006 | loss: 0.69319 - acc: 0.5068 -- iter: 096/339
[A[ATraining Step: 59  | total loss: [1m[32m0.69323[0m[0m | time: 2.279s
[2K
| RMSProp | epoch: 006 | loss: 0.69323 - acc: 0.4975 -- iter: 128/339
[A[ATraining Step: 60  | total loss: [1m[32m0.69320[0m[0m | time: 2.661s
[2K
| RMSProp | epoch: 006 | loss: 0.69320 - acc: 0.5083 -- iter: 160/339
[A[ATraining Step: 61  | total loss: [1m[32m0.69316[0m[0m | time: 3.271s
[2K
| RMSProp | epoch: 006 | loss: 0.69316 - acc: 0.5175 -- iter: 192/339
[A[ATraining Step: 62  | total loss: [1m[32m0.69314[0m[0m | time: 3.893s
[2K
| RMSProp | epoch: 006 | loss: 0.69314 - acc: 0.5152 -- iter: 224/339
[A[ATraining Step: 63  | total loss: [1m[32m0.69316[0m[0m | time: 4.524s
[2K
| RMSProp | epoch: 006 | loss: 0.69316 - acc: 0.5093 -- iter: 256/339
[A[ATraining Step: 64  | total loss: [1m[32m0.69320[0m[0m | time: 5.137s
[2K
| RMSProp | epoch: 006 | loss: 0.69320 - acc: 0.5004 -- iter: 288/339
[A[ATraining Step: 65  | total loss: [1m[32m0.69320[0m[0m | time: 5.772s
[2K
| RMSProp | epoch: 006 | loss: 0.69320 - acc: 0.4965 -- iter: 320/339
[A[ATraining Step: 66  | total loss: [1m[32m0.69324[0m[0m | time: 7.390s
[2K
| RMSProp | epoch: 006 | loss: 0.69324 - acc: 0.4855 | val_loss: 0.69307 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 67  | total loss: [1m[32m0.69322[0m[0m | time: 0.623s
[2K
| RMSProp | epoch: 007 | loss: 0.69322 - acc: 0.4910 -- iter: 032/339
[A[ATraining Step: 68  | total loss: [1m[32m0.69319[0m[0m | time: 1.225s
[2K
| RMSProp | epoch: 007 | loss: 0.69319 - acc: 0.4921 -- iter: 064/339
[A[ATraining Step: 69  | total loss: [1m[32m0.69317[0m[0m | time: 1.854s
[2K
| RMSProp | epoch: 007 | loss: 0.69317 - acc: 0.5039 -- iter: 096/339
[A[ATraining Step: 70  | total loss: [1m[32m0.69311[0m[0m | time: 2.486s
[2K
| RMSProp | epoch: 007 | loss: 0.69311 - acc: 0.5179 -- iter: 128/339
[A[ATraining Step: 71  | total loss: [1m[32m0.69324[0m[0m | time: 2.858s
[2K
| RMSProp | epoch: 007 | loss: 0.69324 - acc: 0.4981 -- iter: 160/339
[A[ATraining Step: 72  | total loss: [1m[32m0.69315[0m[0m | time: 3.252s
[2K
| RMSProp | epoch: 007 | loss: 0.69315 - acc: 0.5190 -- iter: 192/339
[A[ATraining Step: 73  | total loss: [1m[32m0.69300[0m[0m | time: 3.858s
[2K
| RMSProp | epoch: 007 | loss: 0.69300 - acc: 0.5374 -- iter: 224/339
[A[ATraining Step: 74  | total loss: [1m[32m0.69312[0m[0m | time: 4.503s
[2K
| RMSProp | epoch: 007 | loss: 0.69312 - acc: 0.5230 -- iter: 256/339
[A[ATraining Step: 75  | total loss: [1m[32m0.69303[0m[0m | time: 5.132s
[2K
| RMSProp | epoch: 007 | loss: 0.69303 - acc: 0.5306 -- iter: 288/339
[A[ATraining Step: 76  | total loss: [1m[32m0.69305[0m[0m | time: 5.733s
[2K
| RMSProp | epoch: 007 | loss: 0.69305 - acc: 0.5274 -- iter: 320/339
[A[ATraining Step: 77  | total loss: [1m[32m0.69319[0m[0m | time: 7.334s
[2K
| RMSProp | epoch: 007 | loss: 0.69319 - acc: 0.5112 | val_loss: 0.69298 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 78  | total loss: [1m[32m0.69320[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 008 | loss: 0.69320 - acc: 0.5101 -- iter: 032/339
[A[ATraining Step: 79  | total loss: [1m[32m0.69315[0m[0m | time: 1.247s
[2K
| RMSProp | epoch: 008 | loss: 0.69315 - acc: 0.5122 -- iter: 064/339
[A[ATraining Step: 80  | total loss: [1m[32m0.69310[0m[0m | time: 1.862s
[2K
| RMSProp | epoch: 008 | loss: 0.69310 - acc: 0.5142 -- iter: 096/339
[A[ATraining Step: 81  | total loss: [1m[32m0.69326[0m[0m | time: 2.467s
[2K
| RMSProp | epoch: 008 | loss: 0.69326 - acc: 0.4970 -- iter: 128/339
[A[ATraining Step: 82  | total loss: [1m[32m0.69319[0m[0m | time: 3.095s
[2K
| RMSProp | epoch: 008 | loss: 0.69319 - acc: 0.5066 -- iter: 160/339
[A[ATraining Step: 83  | total loss: [1m[32m0.69321[0m[0m | time: 3.478s
[2K
| RMSProp | epoch: 008 | loss: 0.69321 - acc: 0.5028 -- iter: 192/339
[A[ATraining Step: 84  | total loss: [1m[32m0.69317[0m[0m | time: 3.856s
[2K
| RMSProp | epoch: 008 | loss: 0.69317 - acc: 0.5052 -- iter: 224/339
[A[ATraining Step: 85  | total loss: [1m[32m0.69315[0m[0m | time: 4.486s
[2K
| RMSProp | epoch: 008 | loss: 0.69315 - acc: 0.5073 -- iter: 256/339
[A[ATraining Step: 86  | total loss: [1m[32m0.69311[0m[0m | time: 5.093s
[2K
| RMSProp | epoch: 008 | loss: 0.69311 - acc: 0.5097 -- iter: 288/339
[A[ATraining Step: 87  | total loss: [1m[32m0.69300[0m[0m | time: 5.700s
[2K
| RMSProp | epoch: 008 | loss: 0.69300 - acc: 0.5212 -- iter: 320/339
[A[ATraining Step: 88  | total loss: [1m[32m0.69322[0m[0m | time: 7.308s
[2K
| RMSProp | epoch: 008 | loss: 0.69322 - acc: 0.5035 | val_loss: 0.69291 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 89  | total loss: [1m[32m0.69310[0m[0m | time: 0.599s
[2K
| RMSProp | epoch: 009 | loss: 0.69310 - acc: 0.5156 -- iter: 032/339
[A[ATraining Step: 90  | total loss: [1m[32m0.69300[0m[0m | time: 1.199s
[2K
| RMSProp | epoch: 009 | loss: 0.69300 - acc: 0.5234 -- iter: 064/339
[A[ATraining Step: 91  | total loss: [1m[32m0.69296[0m[0m | time: 1.793s
[2K
| RMSProp | epoch: 009 | loss: 0.69296 - acc: 0.5242 -- iter: 096/339
[A[ATraining Step: 92  | total loss: [1m[32m0.69303[0m[0m | time: 2.424s
[2K
| RMSProp | epoch: 009 | loss: 0.69303 - acc: 0.5187 -- iter: 128/339
[A[ATraining Step: 93  | total loss: [1m[32m0.69299[0m[0m | time: 3.024s
[2K
| RMSProp | epoch: 009 | loss: 0.69299 - acc: 0.5199 -- iter: 160/339
[A[ATraining Step: 94  | total loss: [1m[32m0.69310[0m[0m | time: 3.627s
[2K
| RMSProp | epoch: 009 | loss: 0.69310 - acc: 0.5117 -- iter: 192/339
[A[ATraining Step: 95  | total loss: [1m[32m0.69318[0m[0m | time: 3.998s
[2K
| RMSProp | epoch: 009 | loss: 0.69318 - acc: 0.5043 -- iter: 224/339
[A[ATraining Step: 96  | total loss: [1m[32m0.69319[0m[0m | time: 4.367s
[2K
| RMSProp | epoch: 009 | loss: 0.69319 - acc: 0.5012 -- iter: 256/339
[A[ATraining Step: 97  | total loss: [1m[32m0.69320[0m[0m | time: 4.969s
[2K
| RMSProp | epoch: 009 | loss: 0.69320 - acc: 0.4985 -- iter: 288/339
[A[ATraining Step: 98  | total loss: [1m[32m0.69312[0m[0m | time: 5.581s
[2K
| RMSProp | epoch: 009 | loss: 0.69312 - acc: 0.5049 -- iter: 320/339
[A[ATraining Step: 99  | total loss: [1m[32m0.69311[0m[0m | time: 7.196s
[2K
| RMSProp | epoch: 009 | loss: 0.69311 - acc: 0.5044 | val_loss: 0.69287 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 100  | total loss: [1m[32m0.69305[0m[0m | time: 0.633s
[2K
| RMSProp | epoch: 010 | loss: 0.69305 - acc: 0.5102 -- iter: 032/339
[A[ATraining Step: 101  | total loss: [1m[32m0.69293[0m[0m | time: 1.243s
[2K
| RMSProp | epoch: 010 | loss: 0.69293 - acc: 0.5185 -- iter: 064/339
[A[ATraining Step: 102  | total loss: [1m[32m0.69311[0m[0m | time: 1.853s
[2K
| RMSProp | epoch: 010 | loss: 0.69311 - acc: 0.5073 -- iter: 096/339
[A[ATraining Step: 103  | total loss: [1m[32m0.69311[0m[0m | time: 2.467s
[2K
| RMSProp | epoch: 010 | loss: 0.69311 - acc: 0.5066 -- iter: 128/339
[A[ATraining Step: 104  | total loss: [1m[32m0.69315[0m[0m | time: 3.101s
[2K
| RMSProp | epoch: 010 | loss: 0.69315 - acc: 0.5028 -- iter: 160/339
[A[ATraining Step: 105  | total loss: [1m[32m0.69309[0m[0m | time: 3.722s
[2K
| RMSProp | epoch: 010 | loss: 0.69309 - acc: 0.5088 -- iter: 192/339
[A[ATraining Step: 106  | total loss: [1m[32m0.69321[0m[0m | time: 4.337s
[2K
| RMSProp | epoch: 010 | loss: 0.69321 - acc: 0.4985 -- iter: 224/339
[A[ATraining Step: 107  | total loss: [1m[32m0.69323[0m[0m | time: 4.713s
[2K
| RMSProp | epoch: 010 | loss: 0.69323 - acc: 0.4955 -- iter: 256/339
[A[ATraining Step: 108  | total loss: [1m[32m0.69330[0m[0m | time: 5.120s
[2K
| RMSProp | epoch: 010 | loss: 0.69330 - acc: 0.4828 -- iter: 288/339
[A[ATraining Step: 109  | total loss: [1m[32m0.69329[0m[0m | time: 5.735s
[2K
| RMSProp | epoch: 010 | loss: 0.69329 - acc: 0.4714 -- iter: 320/339
[A[ATraining Step: 110  | total loss: [1m[32m0.69332[0m[0m | time: 7.355s
[2K
| RMSProp | epoch: 010 | loss: 0.69332 - acc: 0.4649 | val_loss: 0.69306 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 111  | total loss: [1m[32m0.69331[0m[0m | time: 0.635s
[2K
| RMSProp | epoch: 011 | loss: 0.69331 - acc: 0.4684 -- iter: 032/339
[A[ATraining Step: 112  | total loss: [1m[32m0.69328[0m[0m | time: 1.280s
[2K
| RMSProp | epoch: 011 | loss: 0.69328 - acc: 0.4684 -- iter: 064/339
[A[ATraining Step: 113  | total loss: [1m[32m0.69323[0m[0m | time: 1.872s
[2K
| RMSProp | epoch: 011 | loss: 0.69323 - acc: 0.4778 -- iter: 096/339
[A[ATraining Step: 114  | total loss: [1m[32m0.69320[0m[0m | time: 2.494s
[2K
| RMSProp | epoch: 011 | loss: 0.69320 - acc: 0.4832 -- iter: 128/339
[A[ATraining Step: 115  | total loss: [1m[32m0.69324[0m[0m | time: 3.109s
[2K
| RMSProp | epoch: 011 | loss: 0.69324 - acc: 0.4786 -- iter: 160/339
[A[ATraining Step: 116  | total loss: [1m[32m0.69321[0m[0m | time: 3.729s
[2K
| RMSProp | epoch: 011 | loss: 0.69321 - acc: 0.4870 -- iter: 192/339
[A[ATraining Step: 117  | total loss: [1m[32m0.69313[0m[0m | time: 4.349s
[2K
| RMSProp | epoch: 011 | loss: 0.69313 - acc: 0.4945 -- iter: 224/339
[A[ATraining Step: 118  | total loss: [1m[32m0.69323[0m[0m | time: 4.971s
[2K
| RMSProp | epoch: 011 | loss: 0.69323 - acc: 0.4857 -- iter: 256/339
[A[ATraining Step: 119  | total loss: [1m[32m0.69320[0m[0m | time: 5.354s
[2K
| RMSProp | epoch: 011 | loss: 0.69320 - acc: 0.4903 -- iter: 288/339
[A[ATraining Step: 120  | total loss: [1m[32m0.69325[0m[0m | time: 5.744s
[2K
| RMSProp | epoch: 011 | loss: 0.69325 - acc: 0.4833 -- iter: 320/339
[A[ATraining Step: 121  | total loss: [1m[32m0.69326[0m[0m | time: 7.363s
[2K
| RMSProp | epoch: 011 | loss: 0.69326 - acc: 0.4771 | val_loss: 0.69313 - val_acc: 0.4811 -- iter: 339/339
--
Training Step: 122  | total loss: [1m[32m0.69322[0m[0m | time: 0.622s
[2K
| RMSProp | epoch: 012 | loss: 0.69322 - acc: 0.4825 -- iter: 032/339
[A[ATraining Step: 123  | total loss: [1m[32m0.69315[0m[0m | time: 1.229s
[2K
| RMSProp | epoch: 012 | loss: 0.69315 - acc: 0.4905 -- iter: 064/339
[A[ATraining Step: 124  | total loss: [1m[32m0.69309[0m[0m | time: 1.837s
[2K
| RMSProp | epoch: 012 | loss: 0.69309 - acc: 0.4946 -- iter: 096/339
[A[ATraining Step: 125  | total loss: [1m[32m0.69318[0m[0m | time: 2.485s
[2K
| RMSProp | epoch: 012 | loss: 0.69318 - acc: 0.4858 -- iter: 128/339
[A[ATraining Step: 126  | total loss: [1m[32m0.69314[0m[0m | time: 3.129s
[2K
| RMSProp | epoch: 012 | loss: 0.69314 - acc: 0.5028 -- iter: 160/339
[A[ATraining Step: 127  | total loss: [1m[32m0.69308[0m[0m | time: 3.737s
[2K
| RMSProp | epoch: 012 | loss: 0.69308 - acc: 0.5057 -- iter: 192/339
[A[ATraining Step: 128  | total loss: [1m[32m0.69325[0m[0m | time: 4.346s
[2K
| RMSProp | epoch: 012 | loss: 0.69325 - acc: 0.4926 -- iter: 224/339
[A[ATraining Step: 129  | total loss: [1m[32m0.69323[0m[0m | time: 4.972s
[2K
| RMSProp | epoch: 012 | loss: 0.69323 - acc: 0.4871 -- iter: 256/339
[A[ATraining Step: 130  | total loss: [1m[32m0.69320[0m[0m | time: 5.584s
[2K
| RMSProp | epoch: 012 | loss: 0.69320 - acc: 0.5071 -- iter: 288/339
[A[ATraining Step: 131  | total loss: [1m[32m0.69318[0m[0m | time: 5.959s
[2K
| RMSProp | epoch: 012 | loss: 0.69318 - acc: 0.5127 -- iter: 320/339
[A[ATraining Step: 132  | total loss: [1m[32m0.69319[0m[0m | time: 7.341s
[2K
| RMSProp | epoch: 012 | loss: 0.69319 - acc: 0.4982 | val_loss: 0.69267 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 133  | total loss: [1m[32m0.69304[0m[0m | time: 0.636s
[2K
| RMSProp | epoch: 013 | loss: 0.69304 - acc: 0.5116 -- iter: 032/339
[A[ATraining Step: 134  | total loss: [1m[32m0.69314[0m[0m | time: 1.252s
[2K
| RMSProp | epoch: 013 | loss: 0.69314 - acc: 0.5042 -- iter: 064/339
[A[ATraining Step: 135  | total loss: [1m[32m0.69315[0m[0m | time: 1.849s
[2K
| RMSProp | epoch: 013 | loss: 0.69315 - acc: 0.5006 -- iter: 096/339
[A[ATraining Step: 136  | total loss: [1m[32m0.69310[0m[0m | time: 2.457s
[2K
| RMSProp | epoch: 013 | loss: 0.69310 - acc: 0.5068 -- iter: 128/339
[A[ATraining Step: 137  | total loss: [1m[32m0.69315[0m[0m | time: 3.060s
[2K
| RMSProp | epoch: 013 | loss: 0.69315 - acc: 0.4968 -- iter: 160/339
[A[ATraining Step: 138  | total loss: [1m[32m0.69310[0m[0m | time: 3.683s
[2K
| RMSProp | epoch: 013 | loss: 0.69310 - acc: 0.5065 -- iter: 192/339
[A[ATraining Step: 139  | total loss: [1m[32m0.69313[0m[0m | time: 4.287s
[2K
| RMSProp | epoch: 013 | loss: 0.69313 - acc: 0.4996 -- iter: 224/339
[A[ATraining Step: 140  | total loss: [1m[32m0.69309[0m[0m | time: 4.888s
[2K
| RMSProp | epoch: 013 | loss: 0.69309 - acc: 0.5059 -- iter: 256/339
[A[ATraining Step: 141  | total loss: [1m[32m0.69305[0m[0m | time: 5.487s
[2K
| RMSProp | epoch: 013 | loss: 0.69305 - acc: 0.5146 -- iter: 288/339
[A[ATraining Step: 142  | total loss: [1m[32m0.69304[0m[0m | time: 6.098s
[2K
| RMSProp | epoch: 013 | loss: 0.69304 - acc: 0.5101 -- iter: 320/339
[A[ATraining Step: 143  | total loss: [1m[32m0.69304[0m[0m | time: 7.513s
[2K
| RMSProp | epoch: 013 | loss: 0.69304 - acc: 0.5090 | val_loss: 0.69274 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 144  | total loss: [1m[32m0.69285[0m[0m | time: 0.411s
[2K
| RMSProp | epoch: 014 | loss: 0.69285 - acc: 0.5266 -- iter: 032/339
[A[ATraining Step: 145  | total loss: [1m[32m0.69240[0m[0m | time: 1.010s
[2K
| RMSProp | epoch: 014 | loss: 0.69240 - acc: 0.5423 -- iter: 064/339
[A[ATraining Step: 146  | total loss: [1m[32m0.69221[0m[0m | time: 1.621s
[2K
| RMSProp | epoch: 014 | loss: 0.69221 - acc: 0.5443 -- iter: 096/339
[A[ATraining Step: 147  | total loss: [1m[32m0.69295[0m[0m | time: 2.223s
[2K
| RMSProp | epoch: 014 | loss: 0.69295 - acc: 0.5274 -- iter: 128/339
[A[ATraining Step: 148  | total loss: [1m[32m0.69265[0m[0m | time: 2.839s
[2K
| RMSProp | epoch: 014 | loss: 0.69265 - acc: 0.5340 -- iter: 160/339
[A[ATraining Step: 149  | total loss: [1m[32m0.69228[0m[0m | time: 3.446s
[2K
| RMSProp | epoch: 014 | loss: 0.69228 - acc: 0.5400 -- iter: 192/339
[A[ATraining Step: 150  | total loss: [1m[32m0.69204[0m[0m | time: 4.101s
[2K
| RMSProp | epoch: 014 | loss: 0.69204 - acc: 0.5423 -- iter: 224/339
[A[ATraining Step: 151  | total loss: [1m[32m0.69230[0m[0m | time: 4.719s
[2K
| RMSProp | epoch: 014 | loss: 0.69230 - acc: 0.5349 -- iter: 256/339
[A[ATraining Step: 152  | total loss: [1m[32m0.69298[0m[0m | time: 5.329s
[2K
| RMSProp | epoch: 014 | loss: 0.69298 - acc: 0.5127 -- iter: 288/339
[A[ATraining Step: 153  | total loss: [1m[32m0.69304[0m[0m | time: 5.939s
[2K
| RMSProp | epoch: 014 | loss: 0.69304 - acc: 0.5083 -- iter: 320/339
[A[ATraining Step: 154  | total loss: [1m[32m0.69307[0m[0m | time: 7.555s
[2K
| RMSProp | epoch: 014 | loss: 0.69307 - acc: 0.5012 | val_loss: 0.69271 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 155  | total loss: [1m[32m0.69315[0m[0m | time: 0.397s
[2K
| RMSProp | epoch: 015 | loss: 0.69315 - acc: 0.4980 -- iter: 032/339
[A[ATraining Step: 156  | total loss: [1m[32m0.69308[0m[0m | time: 0.787s
[2K
| RMSProp | epoch: 015 | loss: 0.69308 - acc: 0.5061 -- iter: 064/339
[A[ATraining Step: 157  | total loss: [1m[32m0.69289[0m[0m | time: 1.406s
[2K
| RMSProp | epoch: 015 | loss: 0.69289 - acc: 0.5133 -- iter: 096/339
[A[ATraining Step: 158  | total loss: [1m[32m0.69383[0m[0m | time: 2.011s
[2K
| RMSProp | epoch: 015 | loss: 0.69383 - acc: 0.4870 -- iter: 128/339
[A[ATraining Step: 159  | total loss: [1m[32m0.69370[0m[0m | time: 2.617s
[2K
| RMSProp | epoch: 015 | loss: 0.69370 - acc: 0.4977 -- iter: 160/339
[A[ATraining Step: 160  | total loss: [1m[32m0.69381[0m[0m | time: 3.221s
[2K
| RMSProp | epoch: 015 | loss: 0.69381 - acc: 0.4854 -- iter: 192/339
[A[ATraining Step: 161  | total loss: [1m[32m0.69370[0m[0m | time: 3.818s
[2K
| RMSProp | epoch: 015 | loss: 0.69370 - acc: 0.5087 -- iter: 224/339
[A[ATraining Step: 162  | total loss: [1m[32m0.69356[0m[0m | time: 4.426s
[2K
| RMSProp | epoch: 015 | loss: 0.69356 - acc: 0.5141 -- iter: 256/339
[A[ATraining Step: 163  | total loss: [1m[32m0.69348[0m[0m | time: 5.040s
[2K
| RMSProp | epoch: 015 | loss: 0.69348 - acc: 0.5127 -- iter: 288/339
[A[ATraining Step: 164  | total loss: [1m[32m0.69317[0m[0m | time: 5.657s
[2K
| RMSProp | epoch: 015 | loss: 0.69317 - acc: 0.5239 -- iter: 320/339
[A[ATraining Step: 165  | total loss: [1m[32m0.69362[0m[0m | time: 7.306s
[2K
| RMSProp | epoch: 015 | loss: 0.69362 - acc: 0.5090 | val_loss: 0.69221 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 166  | total loss: [1m[32m0.69345[0m[0m | time: 0.620s
[2K
| RMSProp | epoch: 016 | loss: 0.69345 - acc: 0.5113 -- iter: 032/339
[A[ATraining Step: 167  | total loss: [1m[32m0.69337[0m[0m | time: 0.994s
[2K
| RMSProp | epoch: 016 | loss: 0.69337 - acc: 0.5101 -- iter: 064/339
[A[ATraining Step: 168  | total loss: [1m[32m0.69346[0m[0m | time: 1.372s
[2K
| RMSProp | epoch: 016 | loss: 0.69346 - acc: 0.5012 -- iter: 096/339
[A[ATraining Step: 169  | total loss: [1m[32m0.69343[0m[0m | time: 1.997s
[2K
| RMSProp | epoch: 016 | loss: 0.69343 - acc: 0.4880 -- iter: 128/339
[A[ATraining Step: 170  | total loss: [1m[32m0.69330[0m[0m | time: 2.609s
[2K
| RMSProp | epoch: 016 | loss: 0.69330 - acc: 0.4985 -- iter: 160/339
[A[ATraining Step: 171  | total loss: [1m[32m0.69318[0m[0m | time: 3.215s
[2K
| RMSProp | epoch: 016 | loss: 0.69318 - acc: 0.4987 -- iter: 192/339
[A[ATraining Step: 172  | total loss: [1m[32m0.69297[0m[0m | time: 3.814s
[2K
| RMSProp | epoch: 016 | loss: 0.69297 - acc: 0.5238 -- iter: 224/339
[A[ATraining Step: 173  | total loss: [1m[32m0.69359[0m[0m | time: 4.423s
[2K
| RMSProp | epoch: 016 | loss: 0.69359 - acc: 0.5121 -- iter: 256/339
[A[ATraining Step: 174  | total loss: [1m[32m0.69341[0m[0m | time: 5.027s
[2K
| RMSProp | epoch: 016 | loss: 0.69341 - acc: 0.5233 -- iter: 288/339
[A[ATraining Step: 175  | total loss: [1m[32m0.69326[0m[0m | time: 5.646s
[2K
| RMSProp | epoch: 016 | loss: 0.69326 - acc: 0.5210 -- iter: 320/339
[A[ATraining Step: 176  | total loss: [1m[32m0.69315[0m[0m | time: 7.269s
[2K
| RMSProp | epoch: 016 | loss: 0.69315 - acc: 0.5158 | val_loss: 0.69173 - val_acc: 0.4811 -- iter: 339/339
--
Training Step: 177  | total loss: [1m[32m0.69282[0m[0m | time: 0.622s
[2K
| RMSProp | epoch: 017 | loss: 0.69282 - acc: 0.5392 -- iter: 032/339
[A[ATraining Step: 178  | total loss: [1m[32m0.69291[0m[0m | time: 1.226s
[2K
| RMSProp | epoch: 017 | loss: 0.69291 - acc: 0.5290 -- iter: 064/339
[A[ATraining Step: 179  | total loss: [1m[32m0.69265[0m[0m | time: 1.602s
[2K
| RMSProp | epoch: 017 | loss: 0.69265 - acc: 0.5355 -- iter: 096/339
[A[ATraining Step: 180  | total loss: [1m[32m0.69219[0m[0m | time: 1.978s
[2K
| RMSProp | epoch: 017 | loss: 0.69219 - acc: 0.5556 -- iter: 128/339
[A[ATraining Step: 181  | total loss: [1m[32m0.69131[0m[0m | time: 2.591s
[2K
| RMSProp | epoch: 017 | loss: 0.69131 - acc: 0.5632 -- iter: 160/339
[A[ATraining Step: 182  | total loss: [1m[32m0.69168[0m[0m | time: 3.191s
[2K
| RMSProp | epoch: 017 | loss: 0.69168 - acc: 0.5569 -- iter: 192/339
[A[ATraining Step: 183  | total loss: [1m[32m0.69224[0m[0m | time: 3.786s
[2K
| RMSProp | epoch: 017 | loss: 0.69224 - acc: 0.5450 -- iter: 224/339
[A[ATraining Step: 184  | total loss: [1m[32m0.69193[0m[0m | time: 4.416s
[2K
| RMSProp | epoch: 017 | loss: 0.69193 - acc: 0.5498 -- iter: 256/339
[A[ATraining Step: 185  | total loss: [1m[32m0.69126[0m[0m | time: 5.031s
[2K
| RMSProp | epoch: 017 | loss: 0.69126 - acc: 0.5511 -- iter: 288/339
[A[ATraining Step: 186  | total loss: [1m[32m0.69065[0m[0m | time: 5.648s
[2K
| RMSProp | epoch: 017 | loss: 0.69065 - acc: 0.5429 -- iter: 320/339
[A[ATraining Step: 187  | total loss: [1m[32m0.68940[0m[0m | time: 7.268s
[2K
| RMSProp | epoch: 017 | loss: 0.68940 - acc: 0.5605 | val_loss: 0.71405 - val_acc: 0.5189 -- iter: 339/339
--
Training Step: 188  | total loss: [1m[32m0.68631[0m[0m | time: 0.618s
[2K
| RMSProp | epoch: 018 | loss: 0.68631 - acc: 0.5825 -- iter: 032/339
[A[ATraining Step: 189  | total loss: [1m[32m0.69846[0m[0m | time: 1.222s
[2K
| RMSProp | epoch: 018 | loss: 0.69846 - acc: 0.5587 -- iter: 064/339
[A[ATraining Step: 190  | total loss: [1m[32m0.69789[0m[0m | time: 1.808s
[2K
| RMSProp | epoch: 018 | loss: 0.69789 - acc: 0.5528 -- iter: 096/339
[A[ATraining Step: 191  | total loss: [1m[32m0.69647[0m[0m | time: 2.197s
[2K
| RMSProp | epoch: 018 | loss: 0.69647 - acc: 0.5475 -- iter: 128/339
[A[ATraining Step: 192  | total loss: [1m[32m0.69448[0m[0m | time: 2.593s
[2K
| RMSProp | epoch: 018 | loss: 0.69448 - acc: 0.5612 -- iter: 160/339
[A[ATraining Step: 193  | total loss: [1m[32m0.69137[0m[0m | time: 3.194s
[2K
| RMSProp | epoch: 018 | loss: 0.69137 - acc: 0.5735 -- iter: 192/339
[A[ATraining Step: 194  | total loss: [1m[32m0.68742[0m[0m | time: 3.807s
[2K
| RMSProp | epoch: 018 | loss: 0.68742 - acc: 0.5724 -- iter: 224/339
[A[ATraining Step: 195  | total loss: [1m[32m0.68450[0m[0m | time: 4.416s
[2K
| RMSProp | epoch: 018 | loss: 0.68450 - acc: 0.5839 -- iter: 256/339
[A[ATraining Step: 196  | total loss: [1m[32m0.67769[0m[0m | time: 5.022s
[2K
| RMSProp | epoch: 018 | loss: 0.67769 - acc: 0.5818 -- iter: 288/339
[A[ATraining Step: 197  | total loss: [1m[32m0.67844[0m[0m | time: 5.643s
[2K
| RMSProp | epoch: 018 | loss: 0.67844 - acc: 0.5736 -- iter: 320/339
[A[ATraining Step: 198  | total loss: [1m[32m0.67850[0m[0m | time: 7.249s
[2K
| RMSProp | epoch: 018 | loss: 0.67850 - acc: 0.5631 | val_loss: 0.60627 - val_acc: 0.7453 -- iter: 339/339
--
Training Step: 199  | total loss: [1m[32m0.67525[0m[0m | time: 0.610s
[2K
| RMSProp | epoch: 019 | loss: 0.67525 - acc: 0.5787 -- iter: 032/339
[A[ATraining Step: 200  | total loss: [1m[32m0.66488[0m[0m | time: 2.253s
[2K
| RMSProp | epoch: 019 | loss: 0.66488 - acc: 0.5958 | val_loss: 0.60239 - val_acc: 0.7264 -- iter: 064/339
--
Training Step: 201  | total loss: [1m[32m0.65886[0m[0m | time: 2.875s
[2K
| RMSProp | epoch: 019 | loss: 0.65886 - acc: 0.5956 -- iter: 096/339
[A[ATraining Step: 202  | total loss: [1m[32m0.65317[0m[0m | time: 3.479s
[2K
| RMSProp | epoch: 019 | loss: 0.65317 - acc: 0.6110 -- iter: 128/339
[A[ATraining Step: 203  | total loss: [1m[32m0.63516[0m[0m | time: 3.863s
[2K
| RMSProp | epoch: 019 | loss: 0.63516 - acc: 0.6249 -- iter: 160/339
[A[ATraining Step: 204  | total loss: [1m[32m0.62359[0m[0m | time: 4.256s
[2K
| RMSProp | epoch: 019 | loss: 0.62359 - acc: 0.6414 -- iter: 192/339
[A[ATraining Step: 205  | total loss: [1m[32m0.61685[0m[0m | time: 4.883s
[2K
| RMSProp | epoch: 019 | loss: 0.61685 - acc: 0.6509 -- iter: 224/339
[A[ATraining Step: 206  | total loss: [1m[32m0.61974[0m[0m | time: 5.484s
[2K
| RMSProp | epoch: 019 | loss: 0.61974 - acc: 0.6483 -- iter: 256/339
[A[ATraining Step: 207  | total loss: [1m[32m0.61795[0m[0m | time: 6.095s
[2K
| RMSProp | epoch: 019 | loss: 0.61795 - acc: 0.6460 -- iter: 288/339
[A[ATraining Step: 208  | total loss: [1m[32m0.60641[0m[0m | time: 6.710s
[2K
| RMSProp | epoch: 019 | loss: 0.60641 - acc: 0.6627 -- iter: 320/339
[A[ATraining Step: 209  | total loss: [1m[32m0.59070[0m[0m | time: 8.322s
[2K
| RMSProp | epoch: 019 | loss: 0.59070 - acc: 0.6745 | val_loss: 0.73060 - val_acc: 0.5472 -- iter: 339/339
--
Training Step: 210  | total loss: [1m[32m0.61736[0m[0m | time: 0.632s
[2K
| RMSProp | epoch: 020 | loss: 0.61736 - acc: 0.6508 -- iter: 032/339
[A[ATraining Step: 211  | total loss: [1m[32m0.62012[0m[0m | time: 1.248s
[2K
| RMSProp | epoch: 020 | loss: 0.62012 - acc: 0.6451 -- iter: 064/339
[A[ATraining Step: 212  | total loss: [1m[32m0.60736[0m[0m | time: 1.847s
[2K
| RMSProp | epoch: 020 | loss: 0.60736 - acc: 0.6587 -- iter: 096/339
[A[ATraining Step: 213  | total loss: [1m[32m0.59659[0m[0m | time: 2.455s
[2K
| RMSProp | epoch: 020 | loss: 0.59659 - acc: 0.6741 -- iter: 128/339
[A[ATraining Step: 214  | total loss: [1m[32m0.57154[0m[0m | time: 3.067s
[2K
| RMSProp | epoch: 020 | loss: 0.57154 - acc: 0.6911 -- iter: 160/339
[A[ATraining Step: 215  | total loss: [1m[32m0.54988[0m[0m | time: 3.443s
[2K
| RMSProp | epoch: 020 | loss: 0.54988 - acc: 0.7095 -- iter: 192/339
[A[ATraining Step: 216  | total loss: [1m[32m0.54640[0m[0m | time: 3.825s
[2K
| RMSProp | epoch: 020 | loss: 0.54640 - acc: 0.7069 -- iter: 224/339
[A[ATraining Step: 217  | total loss: [1m[32m0.53814[0m[0m | time: 4.454s
[2K
| RMSProp | epoch: 020 | loss: 0.53814 - acc: 0.7152 -- iter: 256/339
[A[ATraining Step: 218  | total loss: [1m[32m0.52034[0m[0m | time: 5.054s
[2K
| RMSProp | epoch: 020 | loss: 0.52034 - acc: 0.7312 -- iter: 288/339
[A[ATraining Step: 219  | total loss: [1m[32m0.50676[0m[0m | time: 5.664s
[2K
| RMSProp | epoch: 020 | loss: 0.50676 - acc: 0.7456 -- iter: 320/339
[A[ATraining Step: 220  | total loss: [1m[32m0.49727[0m[0m | time: 7.295s
[2K
| RMSProp | epoch: 020 | loss: 0.49727 - acc: 0.7554 | val_loss: 0.56577 - val_acc: 0.7170 -- iter: 339/339
--
Training Step: 221  | total loss: [1m[32m0.47846[0m[0m | time: 0.619s
[2K
| RMSProp | epoch: 021 | loss: 0.47846 - acc: 0.7767 -- iter: 032/339
[A[ATraining Step: 222  | total loss: [1m[32m0.48047[0m[0m | time: 1.226s
[2K
| RMSProp | epoch: 021 | loss: 0.48047 - acc: 0.7772 -- iter: 064/339
[A[ATraining Step: 223  | total loss: [1m[32m0.47465[0m[0m | time: 1.832s
[2K
| RMSProp | epoch: 021 | loss: 0.47465 - acc: 0.7776 -- iter: 096/339
[A[ATraining Step: 224  | total loss: [1m[32m0.46645[0m[0m | time: 2.453s
[2K
| RMSProp | epoch: 021 | loss: 0.46645 - acc: 0.7811 -- iter: 128/339
[A[ATraining Step: 225  | total loss: [1m[32m0.45814[0m[0m | time: 3.065s
[2K
| RMSProp | epoch: 021 | loss: 0.45814 - acc: 0.7811 -- iter: 160/339
[A[ATraining Step: 226  | total loss: [1m[32m0.43312[0m[0m | time: 3.673s
[2K
| RMSProp | epoch: 021 | loss: 0.43312 - acc: 0.8030 -- iter: 192/339
[A[ATraining Step: 227  | total loss: [1m[32m0.41079[0m[0m | time: 4.084s
[2K
| RMSProp | epoch: 021 | loss: 0.41079 - acc: 0.8164 -- iter: 224/339
[A[ATraining Step: 228  | total loss: [1m[32m0.39590[0m[0m | time: 4.456s
[2K
| RMSProp | epoch: 021 | loss: 0.39590 - acc: 0.8190 -- iter: 256/339
[A[ATraining Step: 229  | total loss: [1m[32m0.40281[0m[0m | time: 5.083s
[2K
| RMSProp | epoch: 021 | loss: 0.40281 - acc: 0.8108 -- iter: 288/339
[A[ATraining Step: 230  | total loss: [1m[32m0.40556[0m[0m | time: 5.683s
[2K
| RMSProp | epoch: 021 | loss: 0.40556 - acc: 0.8110 -- iter: 320/339
[A[ATraining Step: 231  | total loss: [1m[32m0.38993[0m[0m | time: 7.298s
[2K
| RMSProp | epoch: 021 | loss: 0.38993 - acc: 0.8205 | val_loss: 0.27128 - val_acc: 0.8774 -- iter: 339/339
--
Training Step: 232  | total loss: [1m[32m0.38603[0m[0m | time: 0.609s
[2K
| RMSProp | epoch: 022 | loss: 0.38603 - acc: 0.8228 -- iter: 032/339
[A[ATraining Step: 233  | total loss: [1m[32m0.37281[0m[0m | time: 1.217s
[2K
| RMSProp | epoch: 022 | loss: 0.37281 - acc: 0.8343 -- iter: 064/339
[A[ATraining Step: 234  | total loss: [1m[32m0.35277[0m[0m | time: 1.823s
[2K
| RMSProp | epoch: 022 | loss: 0.35277 - acc: 0.8477 -- iter: 096/339
[A[ATraining Step: 235  | total loss: [1m[32m0.34231[0m[0m | time: 2.428s
[2K
| RMSProp | epoch: 022 | loss: 0.34231 - acc: 0.8567 -- iter: 128/339
[A[ATraining Step: 236  | total loss: [1m[32m0.33719[0m[0m | time: 3.056s
[2K
| RMSProp | epoch: 022 | loss: 0.33719 - acc: 0.8585 -- iter: 160/339
[A[ATraining Step: 237  | total loss: [1m[32m0.35443[0m[0m | time: 3.663s
[2K
| RMSProp | epoch: 022 | loss: 0.35443 - acc: 0.8508 -- iter: 192/339
[A[ATraining Step: 238  | total loss: [1m[32m0.33619[0m[0m | time: 4.273s
[2K
| RMSProp | epoch: 022 | loss: 0.33619 - acc: 0.8595 -- iter: 224/339
[A[ATraining Step: 239  | total loss: [1m[32m0.32291[0m[0m | time: 4.656s
[2K
| RMSProp | epoch: 022 | loss: 0.32291 - acc: 0.8704 -- iter: 256/339
[A[ATraining Step: 240  | total loss: [1m[32m0.33124[0m[0m | time: 5.061s
[2K
| RMSProp | epoch: 022 | loss: 0.33124 - acc: 0.8570 -- iter: 288/339
[A[ATraining Step: 241  | total loss: [1m[32m0.33231[0m[0m | time: 5.680s
[2K
| RMSProp | epoch: 022 | loss: 0.33231 - acc: 0.8503 -- iter: 320/339
[A[ATraining Step: 242  | total loss: [1m[32m0.31591[0m[0m | time: 7.288s
[2K
| RMSProp | epoch: 022 | loss: 0.31591 - acc: 0.8621 | val_loss: 0.21868 - val_acc: 0.9245 -- iter: 339/339
--
Training Step: 243  | total loss: [1m[32m0.31227[0m[0m | time: 0.635s
[2K
| RMSProp | epoch: 023 | loss: 0.31227 - acc: 0.8697 -- iter: 032/339
[A[ATraining Step: 244  | total loss: [1m[32m0.29786[0m[0m | time: 1.234s
[2K
| RMSProp | epoch: 023 | loss: 0.29786 - acc: 0.8765 -- iter: 064/339
[A[ATraining Step: 245  | total loss: [1m[32m0.28931[0m[0m | time: 1.858s
[2K
| RMSProp | epoch: 023 | loss: 0.28931 - acc: 0.8794 -- iter: 096/339
[A[ATraining Step: 246  | total loss: [1m[32m0.29361[0m[0m | time: 2.469s
[2K
| RMSProp | epoch: 023 | loss: 0.29361 - acc: 0.8759 -- iter: 128/339
[A[ATraining Step: 247  | total loss: [1m[32m0.28261[0m[0m | time: 3.084s
[2K
| RMSProp | epoch: 023 | loss: 0.28261 - acc: 0.8852 -- iter: 160/339
[A[ATraining Step: 248  | total loss: [1m[32m0.28254[0m[0m | time: 3.680s
[2K
| RMSProp | epoch: 023 | loss: 0.28254 - acc: 0.8873 -- iter: 192/339
[A[ATraining Step: 249  | total loss: [1m[32m0.28038[0m[0m | time: 4.286s
[2K
| RMSProp | epoch: 023 | loss: 0.28038 - acc: 0.8923 -- iter: 224/339
[A[ATraining Step: 250  | total loss: [1m[32m0.27186[0m[0m | time: 4.883s
[2K
| RMSProp | epoch: 023 | loss: 0.27186 - acc: 0.8968 -- iter: 256/339
[A[ATraining Step: 251  | total loss: [1m[32m0.25620[0m[0m | time: 5.255s
[2K
| RMSProp | epoch: 023 | loss: 0.25620 - acc: 0.9071 -- iter: 288/339
[A[ATraining Step: 252  | total loss: [1m[32m0.25988[0m[0m | time: 5.631s
[2K
| RMSProp | epoch: 023 | loss: 0.25988 - acc: 0.9112 -- iter: 320/339
[A[ATraining Step: 253  | total loss: [1m[32m0.24947[0m[0m | time: 7.229s
[2K
| RMSProp | epoch: 023 | loss: 0.24947 - acc: 0.9148 | val_loss: 0.18880 - val_acc: 0.9151 -- iter: 339/339
--
Training Step: 254  | total loss: [1m[32m0.24667[0m[0m | time: 0.658s
[2K
| RMSProp | epoch: 024 | loss: 0.24667 - acc: 0.9139 -- iter: 032/339
[A[ATraining Step: 255  | total loss: [1m[32m0.23474[0m[0m | time: 1.299s
[2K
| RMSProp | epoch: 024 | loss: 0.23474 - acc: 0.9225 -- iter: 064/339
[A[ATraining Step: 256  | total loss: [1m[32m0.22785[0m[0m | time: 1.901s
[2K
| RMSProp | epoch: 024 | loss: 0.22785 - acc: 0.9272 -- iter: 096/339
[A[ATraining Step: 257  | total loss: [1m[32m0.21045[0m[0m | time: 2.527s
[2K
| RMSProp | epoch: 024 | loss: 0.21045 - acc: 0.9344 -- iter: 128/339
[A[ATraining Step: 258  | total loss: [1m[32m0.20155[0m[0m | time: 3.134s
[2K
| RMSProp | epoch: 024 | loss: 0.20155 - acc: 0.9410 -- iter: 160/339
[A[ATraining Step: 259  | total loss: [1m[32m0.20450[0m[0m | time: 3.719s
[2K
| RMSProp | epoch: 024 | loss: 0.20450 - acc: 0.9375 -- iter: 192/339
[A[ATraining Step: 260  | total loss: [1m[32m0.20703[0m[0m | time: 4.298s
[2K
| RMSProp | epoch: 024 | loss: 0.20703 - acc: 0.9344 -- iter: 224/339
[A[ATraining Step: 261  | total loss: [1m[32m0.22422[0m[0m | time: 4.914s
[2K
| RMSProp | epoch: 024 | loss: 0.22422 - acc: 0.9222 -- iter: 256/339
[A[ATraining Step: 262  | total loss: [1m[32m0.22236[0m[0m | time: 5.520s
[2K
| RMSProp | epoch: 024 | loss: 0.22236 - acc: 0.9237 -- iter: 288/339
[A[ATraining Step: 263  | total loss: [1m[32m0.21622[0m[0m | time: 5.896s
[2K
| RMSProp | epoch: 024 | loss: 0.21622 - acc: 0.9282 -- iter: 320/339
[A[ATraining Step: 264  | total loss: [1m[32m0.20593[0m[0m | time: 7.276s
[2K
| RMSProp | epoch: 024 | loss: 0.20593 - acc: 0.9301 | val_loss: 0.19607 - val_acc: 0.9151 -- iter: 339/339
--
Training Step: 265  | total loss: [1m[32m0.19289[0m[0m | time: 0.610s
[2K
| RMSProp | epoch: 025 | loss: 0.19289 - acc: 0.9319 -- iter: 032/339
[A[ATraining Step: 266  | total loss: [1m[32m0.17931[0m[0m | time: 1.209s
[2K
| RMSProp | epoch: 025 | loss: 0.17931 - acc: 0.9387 -- iter: 064/339
[A[ATraining Step: 267  | total loss: [1m[32m0.17166[0m[0m | time: 1.816s
[2K
| RMSProp | epoch: 025 | loss: 0.17166 - acc: 0.9417 -- iter: 096/339
[A[ATraining Step: 268  | total loss: [1m[32m0.16036[0m[0m | time: 2.454s
[2K
| RMSProp | epoch: 025 | loss: 0.16036 - acc: 0.9475 -- iter: 128/339
[A[ATraining Step: 269  | total loss: [1m[32m0.15699[0m[0m | time: 3.065s
[2K
| RMSProp | epoch: 025 | loss: 0.15699 - acc: 0.9465 -- iter: 160/339
[A[ATraining Step: 270  | total loss: [1m[32m0.15350[0m[0m | time: 3.672s
[2K
| RMSProp | epoch: 025 | loss: 0.15350 - acc: 0.9425 -- iter: 192/339
[A[ATraining Step: 271  | total loss: [1m[32m0.14319[0m[0m | time: 4.282s
[2K
| RMSProp | epoch: 025 | loss: 0.14319 - acc: 0.9482 -- iter: 224/339
[A[ATraining Step: 272  | total loss: [1m[32m0.13222[0m[0m | time: 4.875s
[2K
| RMSProp | epoch: 025 | loss: 0.13222 - acc: 0.9534 -- iter: 256/339
[A[ATraining Step: 273  | total loss: [1m[32m0.13071[0m[0m | time: 5.479s
[2K
| RMSProp | epoch: 025 | loss: 0.13071 - acc: 0.9550 -- iter: 288/339
[A[ATraining Step: 274  | total loss: [1m[32m0.12715[0m[0m | time: 6.077s
[2K
| RMSProp | epoch: 025 | loss: 0.12715 - acc: 0.9563 -- iter: 320/339
[A[ATraining Step: 275  | total loss: [1m[32m0.15603[0m[0m | time: 7.454s
[2K
| RMSProp | epoch: 025 | loss: 0.15603 - acc: 0.9451 | val_loss: 0.27003 - val_acc: 0.9057 -- iter: 339/339
--
Training Step: 276  | total loss: [1m[32m0.15882[0m[0m | time: 0.457s
[2K
| RMSProp | epoch: 026 | loss: 0.15882 - acc: 0.9400 -- iter: 032/339
[A[ATraining Step: 277  | total loss: [1m[32m0.14688[0m[0m | time: 1.070s
[2K
| RMSProp | epoch: 026 | loss: 0.14688 - acc: 0.9460 -- iter: 064/339
[A[ATraining Step: 278  | total loss: [1m[32m0.15337[0m[0m | time: 1.677s
[2K
| RMSProp | epoch: 026 | loss: 0.15337 - acc: 0.9452 -- iter: 096/339
[A[ATraining Step: 279  | total loss: [1m[32m0.15331[0m[0m | time: 2.275s
[2K
| RMSProp | epoch: 026 | loss: 0.15331 - acc: 0.9444 -- iter: 128/339
[A[ATraining Step: 280  | total loss: [1m[32m0.15628[0m[0m | time: 2.887s
[2K
| RMSProp | epoch: 026 | loss: 0.15628 - acc: 0.9437 -- iter: 160/339
[A[ATraining Step: 281  | total loss: [1m[32m0.15464[0m[0m | time: 3.500s
[2K
| RMSProp | epoch: 026 | loss: 0.15464 - acc: 0.9462 -- iter: 192/339
[A[ATraining Step: 282  | total loss: [1m[32m0.14463[0m[0m | time: 4.110s
[2K
| RMSProp | epoch: 026 | loss: 0.14463 - acc: 0.9485 -- iter: 224/339
[A[ATraining Step: 283  | total loss: [1m[32m0.13353[0m[0m | time: 4.716s
[2K
| RMSProp | epoch: 026 | loss: 0.13353 - acc: 0.9536 -- iter: 256/339
[A[ATraining Step: 284  | total loss: [1m[32m0.12855[0m[0m | time: 5.366s
[2K
| RMSProp | epoch: 026 | loss: 0.12855 - acc: 0.9551 -- iter: 288/339
[A[ATraining Step: 285  | total loss: [1m[32m0.14744[0m[0m | time: 6.000s
[2K
| RMSProp | epoch: 026 | loss: 0.14744 - acc: 0.9440 -- iter: 320/339
[A[ATraining Step: 286  | total loss: [1m[32m0.20529[0m[0m | time: 7.632s
[2K
| RMSProp | epoch: 026 | loss: 0.20529 - acc: 0.9246 | val_loss: 0.16465 - val_acc: 0.9151 -- iter: 339/339
--
Training Step: 287  | total loss: [1m[32m0.19926[0m[0m | time: 0.378s
[2K
| RMSProp | epoch: 027 | loss: 0.19926 - acc: 0.9290 -- iter: 032/339
[A[ATraining Step: 288  | total loss: [1m[32m0.18516[0m[0m | time: 0.754s
[2K
| RMSProp | epoch: 027 | loss: 0.18516 - acc: 0.9361 -- iter: 064/339
[A[ATraining Step: 289  | total loss: [1m[32m0.16971[0m[0m | time: 1.367s
[2K
| RMSProp | epoch: 027 | loss: 0.16971 - acc: 0.9425 -- iter: 096/339
[A[ATraining Step: 290  | total loss: [1m[32m0.16219[0m[0m | time: 1.982s
[2K
| RMSProp | epoch: 027 | loss: 0.16219 - acc: 0.9451 -- iter: 128/339
[A[ATraining Step: 291  | total loss: [1m[32m0.15193[0m[0m | time: 2.601s
[2K
| RMSProp | epoch: 027 | loss: 0.15193 - acc: 0.9475 -- iter: 160/339
[A[ATraining Step: 292  | total loss: [1m[32m0.16125[0m[0m | time: 3.211s
[2K
| RMSProp | epoch: 027 | loss: 0.16125 - acc: 0.9465 -- iter: 192/339
[A[ATraining Step: 293  | total loss: [1m[32m0.14855[0m[0m | time: 3.817s
[2K
| RMSProp | epoch: 027 | loss: 0.14855 - acc: 0.9518 -- iter: 224/339
[A[ATraining Step: 294  | total loss: [1m[32m0.14644[0m[0m | time: 4.429s
[2K
| RMSProp | epoch: 027 | loss: 0.14644 - acc: 0.9535 -- iter: 256/339
[A[ATraining Step: 295  | total loss: [1m[32m0.14337[0m[0m | time: 5.049s
[2K
| RMSProp | epoch: 027 | loss: 0.14337 - acc: 0.9551 -- iter: 288/339
[A[ATraining Step: 296  | total loss: [1m[32m0.14622[0m[0m | time: 5.658s
[2K
| RMSProp | epoch: 027 | loss: 0.14622 - acc: 0.9533 -- iter: 320/339
[A[ATraining Step: 297  | total loss: [1m[32m0.14024[0m[0m | time: 7.274s
[2K
| RMSProp | epoch: 027 | loss: 0.14024 - acc: 0.9548 | val_loss: 0.16438 - val_acc: 0.9151 -- iter: 339/339
--
Training Step: 298  | total loss: [1m[32m0.13927[0m[0m | time: 0.623s
[2K
| RMSProp | epoch: 028 | loss: 0.13927 - acc: 0.9562 -- iter: 032/339
[A[ATraining Step: 299  | total loss: [1m[32m0.15498[0m[0m | time: 1.009s
[2K
| RMSProp | epoch: 028 | loss: 0.15498 - acc: 0.9512 -- iter: 064/339
[A[ATraining Step: 300  | total loss: [1m[32m0.14707[0m[0m | time: 1.393s
[2K
| RMSProp | epoch: 028 | loss: 0.14707 - acc: 0.9561 -- iter: 096/339
[A[ATraining Step: 301  | total loss: [1m[32m0.13537[0m[0m | time: 2.001s
[2K
| RMSProp | epoch: 028 | loss: 0.13537 - acc: 0.9605 -- iter: 128/339
[A[ATraining Step: 302  | total loss: [1m[32m0.12369[0m[0m | time: 2.631s
[2K
| RMSProp | epoch: 028 | loss: 0.12369 - acc: 0.9645 -- iter: 160/339
[A[ATraining Step: 303  | total loss: [1m[32m0.11312[0m[0m | time: 3.236s
[2K
| RMSProp | epoch: 028 | loss: 0.11312 - acc: 0.9680 -- iter: 192/339
[A[ATraining Step: 304  | total loss: [1m[32m0.12029[0m[0m | time: 3.832s
[2K
| RMSProp | epoch: 028 | loss: 0.12029 - acc: 0.9681 -- iter: 224/339
[A[ATraining Step: 305  | total loss: [1m[32m0.11741[0m[0m | time: 4.442s
[2K
| RMSProp | epoch: 028 | loss: 0.11741 - acc: 0.9650 -- iter: 256/339
[A[ATraining Step: 306  | total loss: [1m[32m0.10895[0m[0m | time: 5.054s
[2K
| RMSProp | epoch: 028 | loss: 0.10895 - acc: 0.9685 -- iter: 288/339
[A[ATraining Step: 307  | total loss: [1m[32m0.10122[0m[0m | time: 5.658s
[2K
| RMSProp | epoch: 028 | loss: 0.10122 - acc: 0.9717 -- iter: 320/339
[A[ATraining Step: 308  | total loss: [1m[32m0.10299[0m[0m | time: 7.256s
[2K
| RMSProp | epoch: 028 | loss: 0.10299 - acc: 0.9714 | val_loss: 0.19081 - val_acc: 0.9245 -- iter: 339/339
--
Training Step: 309  | total loss: [1m[32m0.09989[0m[0m | time: 0.627s
[2K
| RMSProp | epoch: 029 | loss: 0.09989 - acc: 0.9711 -- iter: 032/339
[A[ATraining Step: 310  | total loss: [1m[32m0.09503[0m[0m | time: 1.231s
[2K
| RMSProp | epoch: 029 | loss: 0.09503 - acc: 0.9709 -- iter: 064/339
[A[ATraining Step: 311  | total loss: [1m[32m0.08731[0m[0m | time: 1.605s
[2K
| RMSProp | epoch: 029 | loss: 0.08731 - acc: 0.9738 -- iter: 096/339
[A[ATraining Step: 312  | total loss: [1m[32m0.08321[0m[0m | time: 1.982s
[2K
| RMSProp | epoch: 029 | loss: 0.08321 - acc: 0.9764 -- iter: 128/339
[A[ATraining Step: 313  | total loss: [1m[32m0.08664[0m[0m | time: 2.579s
[2K
| RMSProp | epoch: 029 | loss: 0.08664 - acc: 0.9735 -- iter: 160/339
[A[ATraining Step: 314  | total loss: [1m[32m0.11735[0m[0m | time: 3.184s
[2K
| RMSProp | epoch: 029 | loss: 0.11735 - acc: 0.9605 -- iter: 192/339
[A[ATraining Step: 315  | total loss: [1m[32m0.14112[0m[0m | time: 3.784s
[2K
| RMSProp | epoch: 029 | loss: 0.14112 - acc: 0.9520 -- iter: 224/339
[A[ATraining Step: 316  | total loss: [1m[32m0.13329[0m[0m | time: 4.387s
[2K
| RMSProp | epoch: 029 | loss: 0.13329 - acc: 0.9568 -- iter: 256/339
[A[ATraining Step: 317  | total loss: [1m[32m0.12297[0m[0m | time: 5.000s
[2K
| RMSProp | epoch: 029 | loss: 0.12297 - acc: 0.9611 -- iter: 288/339
[A[ATraining Step: 318  | total loss: [1m[32m0.12731[0m[0m | time: 5.609s
[2K
| RMSProp | epoch: 029 | loss: 0.12731 - acc: 0.9619 -- iter: 320/339
[A[ATraining Step: 319  | total loss: [1m[32m0.11710[0m[0m | time: 7.228s
[2K
| RMSProp | epoch: 029 | loss: 0.11710 - acc: 0.9657 | val_loss: 0.16386 - val_acc: 0.9245 -- iter: 339/339
--
Training Step: 320  | total loss: [1m[32m0.10733[0m[0m | time: 0.617s
[2K
| RMSProp | epoch: 030 | loss: 0.10733 - acc: 0.9691 -- iter: 032/339
[A[ATraining Step: 321  | total loss: [1m[32m0.09815[0m[0m | time: 1.266s
[2K
| RMSProp | epoch: 030 | loss: 0.09815 - acc: 0.9722 -- iter: 064/339
[A[ATraining Step: 322  | total loss: [1m[32m0.08934[0m[0m | time: 1.854s
[2K
| RMSProp | epoch: 030 | loss: 0.08934 - acc: 0.9750 -- iter: 096/339
[A[ATraining Step: 323  | total loss: [1m[32m0.08162[0m[0m | time: 2.241s
[2K
| RMSProp | epoch: 030 | loss: 0.08162 - acc: 0.9775 -- iter: 128/339
[A[ATraining Step: 324  | total loss: [1m[32m0.09684[0m[0m | time: 2.634s
[2K
| RMSProp | epoch: 030 | loss: 0.09684 - acc: 0.9745 -- iter: 160/339
[A[ATraining Step: 325  | total loss: [1m[32m0.09235[0m[0m | time: 3.234s
[2K
| RMSProp | epoch: 030 | loss: 0.09235 - acc: 0.9770 -- iter: 192/339
[A[ATraining Step: 326  | total loss: [1m[32m0.10061[0m[0m | time: 3.841s
[2K
| RMSProp | epoch: 030 | loss: 0.10061 - acc: 0.9731 -- iter: 224/339
[A[ATraining Step: 327  | total loss: [1m[32m0.10399[0m[0m | time: 4.444s
[2K
| RMSProp | epoch: 030 | loss: 0.10399 - acc: 0.9726 -- iter: 256/339
[A[ATraining Step: 328  | total loss: [1m[32m0.12986[0m[0m | time: 5.043s
[2K
| RMSProp | epoch: 030 | loss: 0.12986 - acc: 0.9691 -- iter: 288/339
[A[ATraining Step: 329  | total loss: [1m[32m0.12751[0m[0m | time: 5.637s
[2K
| RMSProp | epoch: 030 | loss: 0.12751 - acc: 0.9722 -- iter: 320/339
[A[ATraining Step: 330  | total loss: [1m[32m0.11964[0m[0m | time: 7.260s
[2K
| RMSProp | epoch: 030 | loss: 0.11964 - acc: 0.9750 | val_loss: 0.14559 - val_acc: 0.9340 -- iter: 339/339
--
Validation AUC:0.9910873440285205
Validation AUPRC:0.9906754274419256
Test AUC:0.9960488505747126
Test AUPRC:0.9967902287893492
BestTestF1Score	0.97	0.94	0.97	0.97	0.98	57	2	46	1	0.21
BestTestMCCScore	0.97	0.94	0.97	0.97	0.98	57	2	46	1	0.21
BestTestAccuracyScore	0.97	0.94	0.97	0.97	0.98	57	2	46	1	0.21
BestValidationF1Score	0.95	0.91	0.95	0.91	1.0	51	5	50	0	0.21
BestValidationMCC	0.95	0.91	0.95	0.91	1.0	51	5	50	0	0.21
BestValidationAccuracy	0.95	0.91	0.95	0.91	1.0	51	5	50	0	0.21
TestPredictions (Threshold:0.21)
CHEMBL3697638,TP,ACT,1.0	CHEMBL1269990,TP,ACT,0.9800000190734863	CHEMBL3678222,TP,ACT,1.0	CHEMBL486495,FN,ACT,0.18000000715255737	CHEMBL3678183,TP,ACT,1.0	CHEMBL3085878,TN,INACT,0.009999999776482582	CHEMBL134495,TN,INACT,0.07000000029802322	CHEMBL1278044,TP,ACT,1.0	CHEMBL1777855,TN,INACT,0.019999999552965164	CHEMBL3085879,TN,INACT,0.009999999776482582	CHEMBL3697680,TP,ACT,1.0	CHEMBL1277958,TP,ACT,0.9700000286102295	CHEMBL3697664,TP,ACT,1.0	CHEMBL3085868,TN,INACT,0.009999999776482582	CHEMBL3697685,TP,ACT,0.9300000071525574	CHEMBL177000,TN,INACT,0.009999999776482582	CHEMBL3678245,TP,ACT,0.9900000095367432	CHEMBL3697681,TP,ACT,1.0	CHEMBL3678264,TP,ACT,1.0	CHEMBL3697629,TP,ACT,0.9900000095367432	CHEMBL3678256,TP,ACT,1.0	CHEMBL3126835,FP,INACT,0.7200000286102295	CHEMBL80950,TN,INACT,0.019999999552965164	CHEMBL2324977,TN,INACT,0.009999999776482582	CHEMBL3697689,TP,ACT,0.9900000095367432	CHEMBL3697665,TP,ACT,1.0	CHEMBL2381013,TN,INACT,0.0	CHEMBL3683083,TP,ACT,1.0	CHEMBL3697674,TP,ACT,1.0	CHEMBL2380899,TN,INACT,0.0	CHEMBL3678185,TP,ACT,1.0	CHEMBL3697637,TP,ACT,1.0	CHEMBL3697642,TP,ACT,1.0	CHEMBL114552,TN,INACT,0.029999999329447746	CHEMBL3697631,TP,ACT,1.0	CHEMBL3678190,TP,ACT,1.0	CHEMBL3678267,TP,ACT,0.9900000095367432	CHEMBL3683093,TP,ACT,1.0	CHEMBL3113256,TN,INACT,0.009999999776482582	CHEMBL1277700,TP,ACT,0.9800000190734863	CHEMBL3697695,TP,ACT,0.9800000190734863	CHEMBL2381034,TN,INACT,0.20000000298023224	CHEMBL3678275,TP,ACT,0.8999999761581421	CHEMBL3683099,TP,ACT,0.7200000286102295	CHEMBL522211,TN,INACT,0.009999999776482582	CHEMBL484996,TN,INACT,0.0	CHEMBL3697679,TP,ACT,0.9900000095367432	CHEMBL2381043,TN,INACT,0.019999999552965164	CHEMBL3678177,TP,ACT,1.0	CHEMBL2409401,TN,INACT,0.14000000059604645	CHEMBL3799790,TN,INACT,0.009999999776482582	CHEMBL3678274,TP,ACT,1.0	CHEMBL3353580,TN,INACT,0.03999999910593033	CHEMBL212864,TN,INACT,0.0	CHEMBL3678253,TP,ACT,1.0	CHEMBL3678205,TP,ACT,1.0	CHEMBL1202591,TN,INACT,0.009999999776482582	CHEMBL2381035,TN,INACT,0.019999999552965164	CHEMBL3697691,TP,ACT,1.0	CHEMBL3589904,TN,INACT,0.009999999776482582	CHEMBL3683090,TP,ACT,0.6299999952316284	CHEMBL3678281,TP,ACT,0.9200000166893005	CHEMBL3634329,TN,INACT,0.009999999776482582	CHEMBL34069,TN,INACT,0.18000000715255737	CHEMBL2325265,TN,INACT,0.009999999776482582	CHEMBL3683068,TP,ACT,0.9399999976158142	CHEMBL3697683,TP,ACT,0.6399999856948853	CHEMBL2380903,TN,INACT,0.009999999776482582	CHEMBL477740,TN,INACT,0.019999999552965164	CHEMBL3683064,TP,ACT,0.9800000190734863	CHEMBL3634323,TN,INACT,0.0	CHEMBL2324983,TN,INACT,0.009999999776482582	CHEMBL163568,TN,INACT,0.029999999329447746	CHEMBL2398403,TN,INACT,0.17000000178813934	CHEMBL3678234,TP,ACT,0.9900000095367432	CHEMBL3113250,TN,INACT,0.009999999776482582	CHEMBL2409407,TN,INACT,0.019999999552965164	CHEMBL3697697,TP,ACT,0.9900000095367432	CHEMBL3113255,TN,INACT,0.009999999776482582	CHEMBL3678203,TP,ACT,1.0	CHEMBL2111852,TN,INACT,0.009999999776482582	CHEMBL2380915,TN,INACT,0.0	CHEMBL398545,TN,INACT,0.029999999329447746	CHEMBL3697678,TP,ACT,0.9900000095367432	CHEMBL2448079,TN,INACT,0.009999999776482582	CHEMBL3687593,TN,INACT,0.09000000357627869	CHEMBL3678219,TP,ACT,1.0	CHEMBL3678198,TP,ACT,1.0	CHEMBL23,FP,INACT,0.800000011920929	CHEMBL3697696,TP,ACT,0.9900000095367432	CHEMBL1276881,TP,ACT,0.9800000190734863	CHEMBL3113246,TN,INACT,0.009999999776482582	CHEMBL3678180,TP,ACT,0.9900000095367432	CHEMBL1269883,TP,ACT,0.9800000190734863	CHEMBL3678263,TP,ACT,1.0	CHEMBL3678257,TP,ACT,1.0	CHEMBL3677857,TN,INACT,0.029999999329447746	CHEMBL3697666,TP,ACT,0.9900000095367432	CHEMBL448040,TN,INACT,0.03999999910593033	CHEMBL3678227,TP,ACT,1.0	CHEMBL466517,TN,INACT,0.009999999776482582	CHEMBL3697644,TP,ACT,1.0	CHEMBL3697669,TP,ACT,1.0	CHEMBL2018453,TN,INACT,0.029999999329447746	CHEMBL2298877,TN,INACT,0.009999999776482582	CHEMBL1277512,TP,ACT,0.7699999809265137	

