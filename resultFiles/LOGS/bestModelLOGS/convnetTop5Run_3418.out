ImageNetInceptionV2 CHEMBL5414 adam 0.0005 30 0 0 0.6 False True
Number of active compounds :	203
Number of inactive compounds :	203
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5414_adam_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5414_adam_0.0005_30_0.6/
---------------------------------
Training samples: 256
Validation samples: 81
--
Training Step: 1  | time: 91.586s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/256
[A[ATraining Step: 2  | total loss: [1m[32m0.68461[0m[0m | time: 153.905s
[2K
| Adam | epoch: 001 | loss: 0.68461 - acc: 0.3656 -- iter: 064/256
[A[ATraining Step: 3  | total loss: [1m[32m0.86710[0m[0m | time: 218.078s
[2K
| Adam | epoch: 001 | loss: 0.86710 - acc: 0.5011 -- iter: 096/256
[A[ATraining Step: 4  | total loss: [1m[32m0.52800[0m[0m | time: 237.593s
[2K
| Adam | epoch: 001 | loss: 0.52800 - acc: 0.6878 -- iter: 128/256
[A[ATraining Step: 5  | total loss: [1m[32m0.61492[0m[0m | time: 299.831s
[2K
| Adam | epoch: 001 | loss: 0.61492 - acc: 0.5578 -- iter: 160/256
[A[ATraining Step: 6  | total loss: [1m[32m0.47898[0m[0m | time: 355.616s
[2K
| Adam | epoch: 001 | loss: 0.47898 - acc: 0.7215 -- iter: 192/256
[A[ATraining Step: 7  | total loss: [1m[32m0.46783[0m[0m | time: 401.006s
[2K
| Adam | epoch: 001 | loss: 0.46783 - acc: 0.7761 -- iter: 224/256
[A[ATraining Step: 8  | total loss: [1m[32m0.69659[0m[0m | time: 487.546s
[2K
| Adam | epoch: 001 | loss: 0.69659 - acc: 0.6384 | val_loss: 1.61577 - val_acc: 0.5556 -- iter: 256/256
--
Training Step: 9  | total loss: [1m[32m0.64820[0m[0m | time: 46.906s
[2K
| Adam | epoch: 002 | loss: 0.64820 - acc: 0.6478 -- iter: 032/256
[A[ATraining Step: 10  | total loss: [1m[32m0.53836[0m[0m | time: 148.109s
[2K
| Adam | epoch: 002 | loss: 0.53836 - acc: 0.7145 -- iter: 064/256
[A[ATraining Step: 11  | total loss: [1m[32m0.60740[0m[0m | time: 201.803s
[2K
| Adam | epoch: 002 | loss: 0.60740 - acc: 0.6869 -- iter: 096/256
[A[ATraining Step: 12  | total loss: [1m[32m0.51301[0m[0m | time: 317.995s
[2K
| Adam | epoch: 002 | loss: 0.51301 - acc: 0.7575 -- iter: 128/256
[A[ATraining Step: 13  | total loss: [1m[32m0.51133[0m[0m | time: 390.451s
[2K
| Adam | epoch: 002 | loss: 0.51133 - acc: 0.7811 -- iter: 160/256
[A[ATraining Step: 14  | total loss: [1m[32m0.48389[0m[0m | time: 463.019s
[2K
| Adam | epoch: 002 | loss: 0.48389 - acc: 0.7939 -- iter: 192/256
[A[ATraining Step: 15  | total loss: [1m[32m0.44548[0m[0m | time: 543.253s
[2K
| Adam | epoch: 002 | loss: 0.44548 - acc: 0.8012 -- iter: 224/256
[A[ATraining Step: 16  | total loss: [1m[32m0.44181[0m[0m | time: 628.767s
[2K
| Adam | epoch: 002 | loss: 0.44181 - acc: 0.7820 | val_loss: 1.79575 - val_acc: 0.5556 -- iter: 256/256
--
Training Step: 17  | total loss: [1m[32m0.39120[0m[0m | time: 51.776s
[2K
| Adam | epoch: 003 | loss: 0.39120 - acc: 0.8267 -- iter: 032/256
[A[ATraining Step: 18  | total loss: [1m[32m0.38689[0m[0m | time: 77.472s
[2K
| Adam | epoch: 003 | loss: 0.38689 - acc: 0.8326 -- iter: 064/256
[A[ATraining Step: 19  | total loss: [1m[32m0.30253[0m[0m | time: 125.111s
[2K
| Adam | epoch: 003 | loss: 0.30253 - acc: 0.8884 -- iter: 096/256
[A[ATraining Step: 20  | total loss: [1m[32m0.33447[0m[0m | time: 183.542s
[2K
| Adam | epoch: 003 | loss: 0.33447 - acc: 0.8439 -- iter: 128/256
[A[ATraining Step: 21  | total loss: [1m[32m0.33674[0m[0m | time: 240.509s
[2K
| Adam | epoch: 003 | loss: 0.33674 - acc: 0.8439 -- iter: 160/256
[A[ATraining Step: 22  | total loss: [1m[32m0.29304[0m[0m | time: 267.185s
[2K
| Adam | epoch: 003 | loss: 0.29304 - acc: 0.8626 -- iter: 192/256
[A[ATraining Step: 23  | total loss: [1m[32m0.24822[0m[0m | time: 307.125s
[2K
| Adam | epoch: 003 | loss: 0.24822 - acc: 0.8843 -- iter: 224/256
[A[ATraining Step: 24  | total loss: [1m[32m0.20289[0m[0m | time: 377.687s
[2K
| Adam | epoch: 003 | loss: 0.20289 - acc: 0.9169 | val_loss: 1.09751 - val_acc: 0.5556 -- iter: 256/256
--
Training Step: 25  | total loss: [1m[32m0.19170[0m[0m | time: 19.968s
[2K
| Adam | epoch: 004 | loss: 0.19170 - acc: 0.9310 -- iter: 032/256
[A[ATraining Step: 26  | total loss: [1m[32m0.16588[0m[0m | time: 54.152s
[2K
| Adam | epoch: 004 | loss: 0.16588 - acc: 0.9410 -- iter: 064/256
[A[ATraining Step: 27  | total loss: [1m[32m0.15617[0m[0m | time: 78.063s
[2K
| Adam | epoch: 004 | loss: 0.15617 - acc: 0.9481 -- iter: 096/256
[A[ATraining Step: 28  | total loss: [1m[32m0.12631[0m[0m | time: 97.355s
[2K
| Adam | epoch: 004 | loss: 0.12631 - acc: 0.9611 -- iter: 128/256
[A[ATraining Step: 29  | total loss: [1m[32m0.14539[0m[0m | time: 167.210s
[2K
| Adam | epoch: 004 | loss: 0.14539 - acc: 0.9554 -- iter: 160/256
[A[ATraining Step: 30  | total loss: [1m[32m0.15683[0m[0m | time: 186.200s
[2K
| Adam | epoch: 004 | loss: 0.15683 - acc: 0.9511 -- iter: 192/256
[A[ATraining Step: 31  | total loss: [1m[32m0.16120[0m[0m | time: 206.975s
[2K
| Adam | epoch: 004 | loss: 0.16120 - acc: 0.9552 -- iter: 224/256
[A[ATraining Step: 32  | total loss: [1m[32m0.15014[0m[0m | time: 264.142s
[2K
| Adam | epoch: 004 | loss: 0.15014 - acc: 0.9582 | val_loss: 2.10963 - val_acc: 0.5556 -- iter: 256/256
--
Training Step: 33  | total loss: [1m[32m0.14450[0m[0m | time: 44.101s
[2K
| Adam | epoch: 005 | loss: 0.14450 - acc: 0.9537 -- iter: 032/256
[A[ATraining Step: 34  | total loss: [1m[32m0.14294[0m[0m | time: 58.843s
[2K
| Adam | epoch: 005 | loss: 0.14294 - acc: 0.9569 -- iter: 064/256
[A[ATraining Step: 35  | total loss: [1m[32m0.12590[0m[0m | time: 75.882s
[2K
| Adam | epoch: 005 | loss: 0.12590 - acc: 0.9594 -- iter: 096/256
[A[ATraining Step: 36  | total loss: [1m[32m0.13856[0m[0m | time: 94.347s
[2K
| Adam | epoch: 005 | loss: 0.13856 - acc: 0.9549 -- iter: 128/256
[A[ATraining Step: 37  | total loss: [1m[32m0.12026[0m[0m | time: 111.218s
[2K
| Adam | epoch: 005 | loss: 0.12026 - acc: 0.9639 -- iter: 160/256
[A[ATraining Step: 38  | total loss: [1m[32m0.15695[0m[0m | time: 139.785s
[2K
| Adam | epoch: 005 | loss: 0.15695 - acc: 0.9649 -- iter: 192/256
[A[ATraining Step: 39  | total loss: [1m[32m0.17247[0m[0m | time: 155.320s
[2K
| Adam | epoch: 005 | loss: 0.17247 - acc: 0.9656 -- iter: 224/256
[A[ATraining Step: 40  | total loss: [1m[32m0.18235[0m[0m | time: 194.135s
[2K
| Adam | epoch: 005 | loss: 0.18235 - acc: 0.9486 | val_loss: 3.12792 - val_acc: 0.5556 -- iter: 256/256
--
Training Step: 41  | total loss: [1m[32m0.15526[0m[0m | time: 34.518s
[2K
| Adam | epoch: 006 | loss: 0.15526 - acc: 0.9581 -- iter: 032/256
[A[ATraining Step: 42  | total loss: [1m[32m0.15451[0m[0m | time: 60.230s
[2K
| Adam | epoch: 006 | loss: 0.15451 - acc: 0.9600 -- iter: 064/256
[A[ATraining Step: 43  | total loss: [1m[32m0.13093[0m[0m | time: 95.508s
[2K
| Adam | epoch: 006 | loss: 0.13093 - acc: 0.9670 -- iter: 096/256
[A[ATraining Step: 44  | total loss: [1m[32m0.16183[0m[0m | time: 151.974s
[2K
| Adam | epoch: 006 | loss: 0.16183 - acc: 0.9619 -- iter: 128/256
[A[ATraining Step: 45  | total loss: [1m[32m0.14053[0m[0m | time: 181.742s
[2K
| Adam | epoch: 006 | loss: 0.14053 - acc: 0.9684 -- iter: 160/256
[A[ATraining Step: 46  | total loss: [1m[32m0.12300[0m[0m | time: 200.058s
[2K
| Adam | epoch: 006 | loss: 0.12300 - acc: 0.9737 -- iter: 192/256
[A[ATraining Step: 47  | total loss: [1m[32m0.15189[0m[0m | time: 214.966s
[2K
| Adam | epoch: 006 | loss: 0.15189 - acc: 0.9524 -- iter: 224/256
[A[ATraining Step: 48  | total loss: [1m[32m0.17972[0m[0m | time: 230.787s
[2K
| Adam | epoch: 006 | loss: 0.17972 - acc: 0.9349 | val_loss: 2.92438 - val_acc: 0.5556 -- iter: 256/256
--
Training Step: 49  | total loss: [1m[32m0.16049[0m[0m | time: 15.525s
[2K
| Adam | epoch: 007 | loss: 0.16049 - acc: 0.9403 -- iter: 032/256
[A[ATraining Step: 50  | total loss: [1m[32m0.15801[0m[0m | time: 52.043s
[2K
| Adam | epoch: 007 | loss: 0.15801 - acc: 0.9350 -- iter: 064/256
[A[ATraining Step: 51  | total loss: [1m[32m0.15767[0m[0m | time: 66.627s
[2K
| Adam | epoch: 007 | loss: 0.15767 - acc: 0.9258 -- iter: 096/256
[A[ATraining Step: 52  | total loss: [1m[32m0.15056[0m[0m | time: 85.624s
[2K
| Adam | epoch: 007 | loss: 0.15056 - acc: 0.9323 -- iter: 128/256
[A[ATraining Step: 53  | total loss: [1m[32m0.14214[0m[0m | time: 110.637s
[2K
| Adam | epoch: 007 | loss: 0.14214 - acc: 0.9377 -- iter: 160/256
[A[ATraining Step: 54  | total loss: [1m[32m0.13603[0m[0m | time: 127.195s
[2K
| Adam | epoch: 007 | loss: 0.13603 - acc: 0.9422 -- iter: 192/256
[A[ATraining Step: 55  | total loss: [1m[32m0.11981[0m[0m | time: 142.682s
[2K
| Adam | epoch: 007 | loss: 0.11981 - acc: 0.9504 -- iter: 224/256
[A[ATraining Step: 56  | total loss: [1m[32m0.12557[0m[0m | time: 162.364s
[2K
| Adam | epoch: 007 | loss: 0.12557 - acc: 0.9442 | val_loss: 3.57148 - val_acc: 0.5556 -- iter: 256/256
--
Training Step: 57  | total loss: [1m[32m0.11491[0m[0m | time: 16.525s
[2K
| Adam | epoch: 008 | loss: 0.11491 - acc: 0.9519 -- iter: 032/256
[A[ATraining Step: 58  | total loss: [1m[32m0.12489[0m[0m | time: 40.719s
[2K
| Adam | epoch: 008 | loss: 0.12489 - acc: 0.9542 -- iter: 064/256
[A[ATraining Step: 59  | total loss: [1m[32m0.14303[0m[0m | time: 55.454s
[2K
| Adam | epoch: 008 | loss: 0.14303 - acc: 0.9520 -- iter: 096/256
[A[ATraining Step: 60  | total loss: [1m[32m0.12802[0m[0m | time: 79.345s
[2K
| Adam | epoch: 008 | loss: 0.12802 - acc: 0.9583 -- iter: 128/256
[A[ATraining Step: 61  | total loss: [1m[32m0.11682[0m[0m | time: 98.933s
[2K
| Adam | epoch: 008 | loss: 0.11682 - acc: 0.9597 -- iter: 160/256
[A[ATraining Step: 62  | total loss: [1m[32m0.12324[0m[0m | time: 117.513s
[2K
| Adam | epoch: 008 | loss: 0.12324 - acc: 0.9609 -- iter: 192/256
[A[ATraining Step: 63  | total loss: [1m[32m0.11256[0m[0m | time: 133.439s
[2K
| Adam | epoch: 008 | loss: 0.11256 - acc: 0.9658 -- iter: 224/256
[A[ATraining Step: 64  | total loss: [1m[32m0.10146[0m[0m | time: 150.436s
[2K
| Adam | epoch: 008 | loss: 0.10146 - acc: 0.9701 | val_loss: 0.86269 - val_acc: 0.8148 -- iter: 256/256
--
Training Step: 65  | total loss: [1m[32m0.11634[0m[0m | time: 37.464s
[2K
| Adam | epoch: 009 | loss: 0.11634 - acc: 0.9699 -- iter: 032/256
[A[ATraining Step: 66  | total loss: [1m[32m0.10603[0m[0m | time: 54.803s
[2K
| Adam | epoch: 009 | loss: 0.10603 - acc: 0.9736 -- iter: 064/256
[A[ATraining Step: 67  | total loss: [1m[32m0.09506[0m[0m | time: 69.880s
[2K
| Adam | epoch: 009 | loss: 0.09506 - acc: 0.9768 -- iter: 096/256
[A[ATraining Step: 68  | total loss: [1m[32m0.08554[0m[0m | time: 86.857s
[2K
| Adam | epoch: 009 | loss: 0.08554 - acc: 0.9795 -- iter: 128/256
[A[ATraining Step: 69  | total loss: [1m[32m0.07800[0m[0m | time: 110.905s
[2K
| Adam | epoch: 009 | loss: 0.07800 - acc: 0.9819 -- iter: 160/256
[A[ATraining Step: 70  | total loss: [1m[32m0.07723[0m[0m | time: 132.586s
[2K
| Adam | epoch: 009 | loss: 0.07723 - acc: 0.9804 -- iter: 192/256
[A[ATraining Step: 71  | total loss: [1m[32m0.08610[0m[0m | time: 150.712s
[2K
| Adam | epoch: 009 | loss: 0.08610 - acc: 0.9791 -- iter: 224/256
[A[ATraining Step: 72  | total loss: [1m[32m0.07745[0m[0m | time: 167.249s
[2K
| Adam | epoch: 009 | loss: 0.07745 - acc: 0.9814 | val_loss: 0.85070 - val_acc: 0.7160 -- iter: 256/256
--
Training Step: 73  | total loss: [1m[32m0.06967[0m[0m | time: 15.464s
[2K
| Adam | epoch: 010 | loss: 0.06967 - acc: 0.9835 -- iter: 032/256
[A[ATraining Step: 74  | total loss: [1m[32m0.06320[0m[0m | time: 31.199s
[2K
| Adam | epoch: 010 | loss: 0.06320 - acc: 0.9853 -- iter: 064/256
[A[ATraining Step: 75  | total loss: [1m[32m0.05986[0m[0m | time: 48.287s
[2K
| Adam | epoch: 010 | loss: 0.05986 - acc: 0.9869 -- iter: 096/256
[A[ATraining Step: 76  | total loss: [1m[32m0.09287[0m[0m | time: 74.520s
[2K
| Adam | epoch: 010 | loss: 0.09287 - acc: 0.9816 -- iter: 128/256
[A[ATraining Step: 77  | total loss: [1m[32m0.08404[0m[0m | time: 93.902s
[2K
| Adam | epoch: 010 | loss: 0.08404 - acc: 0.9835 -- iter: 160/256
[A[ATraining Step: 78  | total loss: [1m[32m0.08647[0m[0m | time: 110.777s
[2K
| Adam | epoch: 010 | loss: 0.08647 - acc: 0.9820 -- iter: 192/256
[A[ATraining Step: 79  | total loss: [1m[32m0.08677[0m[0m | time: 150.037s
[2K
| Adam | epoch: 010 | loss: 0.08677 - acc: 0.9806 -- iter: 224/256
[A[ATraining Step: 80  | total loss: [1m[32m0.07982[0m[0m | time: 187.682s
[2K
| Adam | epoch: 010 | loss: 0.07982 - acc: 0.9826 | val_loss: 0.42446 - val_acc: 0.8642 -- iter: 256/256
--
Training Step: 81  | total loss: [1m[32m0.07431[0m[0m | time: 26.944s
[2K
| Adam | epoch: 011 | loss: 0.07431 - acc: 0.9844 -- iter: 032/256
[A[ATraining Step: 82  | total loss: [1m[32m0.06797[0m[0m | time: 51.714s
[2K
| Adam | epoch: 011 | loss: 0.06797 - acc: 0.9859 -- iter: 064/256
[A[ATraining Step: 83  | total loss: [1m[32m0.08228[0m[0m | time: 65.892s
[2K
| Adam | epoch: 011 | loss: 0.08228 - acc: 0.9842 -- iter: 096/256
[A[ATraining Step: 84  | total loss: [1m[32m0.08150[0m[0m | time: 76.978s
[2K
| Adam | epoch: 011 | loss: 0.08150 - acc: 0.9827 -- iter: 128/256
[A[ATraining Step: 85  | total loss: [1m[32m0.12749[0m[0m | time: 88.505s
[2K
| Adam | epoch: 011 | loss: 0.12749 - acc: 0.9750 -- iter: 160/256
[A[ATraining Step: 86  | total loss: [1m[32m0.11952[0m[0m | time: 109.993s
[2K
| Adam | epoch: 011 | loss: 0.11952 - acc: 0.9744 -- iter: 192/256
[A[ATraining Step: 87  | total loss: [1m[32m0.11554[0m[0m | time: 126.629s
[2K
| Adam | epoch: 011 | loss: 0.11554 - acc: 0.9738 -- iter: 224/256
[A[ATraining Step: 88  | total loss: [1m[32m0.11047[0m[0m | time: 154.288s
[2K
| Adam | epoch: 011 | loss: 0.11047 - acc: 0.9764 | val_loss: 4.36232 - val_acc: 0.4938 -- iter: 256/256
--
Training Step: 89  | total loss: [1m[32m0.11232[0m[0m | time: 15.347s
[2K
| Adam | epoch: 012 | loss: 0.11232 - acc: 0.9757 -- iter: 032/256
[A[ATraining Step: 90  | total loss: [1m[32m0.11323[0m[0m | time: 38.485s
[2K
| Adam | epoch: 012 | loss: 0.11323 - acc: 0.9719 -- iter: 064/256
[A[ATraining Step: 91  | total loss: [1m[32m0.10551[0m[0m | time: 53.595s
[2K
| Adam | epoch: 012 | loss: 0.10551 - acc: 0.9747 -- iter: 096/256
[A[ATraining Step: 92  | total loss: [1m[32m0.11246[0m[0m | time: 70.005s
[2K
| Adam | epoch: 012 | loss: 0.11246 - acc: 0.9741 -- iter: 128/256
[A[ATraining Step: 93  | total loss: [1m[32m0.10500[0m[0m | time: 82.759s
[2K
| Adam | epoch: 012 | loss: 0.10500 - acc: 0.9767 -- iter: 160/256
[A[ATraining Step: 94  | total loss: [1m[32m0.14662[0m[0m | time: 99.081s
[2K
| Adam | epoch: 012 | loss: 0.14662 - acc: 0.9696 -- iter: 192/256
[A[ATraining Step: 95  | total loss: [1m[32m0.13398[0m[0m | time: 120.856s
[2K
| Adam | epoch: 012 | loss: 0.13398 - acc: 0.9727 -- iter: 224/256
[A[ATraining Step: 96  | total loss: [1m[32m0.12278[0m[0m | time: 145.213s
[2K
| Adam | epoch: 012 | loss: 0.12278 - acc: 0.9754 | val_loss: 0.61894 - val_acc: 0.7901 -- iter: 256/256
--
Training Step: 97  | total loss: [1m[32m0.11806[0m[0m | time: 15.646s
[2K
| Adam | epoch: 013 | loss: 0.11806 - acc: 0.9747 -- iter: 032/256
[A[ATraining Step: 98  | total loss: [1m[32m0.12629[0m[0m | time: 35.349s
[2K
| Adam | epoch: 013 | loss: 0.12629 - acc: 0.9741 -- iter: 064/256
[A[ATraining Step: 99  | total loss: [1m[32m0.12658[0m[0m | time: 50.304s
[2K
| Adam | epoch: 013 | loss: 0.12658 - acc: 0.9736 -- iter: 096/256
[A[ATraining Step: 100  | total loss: [1m[32m0.12159[0m[0m | time: 67.015s
[2K
| Adam | epoch: 013 | loss: 0.12159 - acc: 0.9762 -- iter: 128/256
[A[ATraining Step: 101  | total loss: [1m[32m0.14341[0m[0m | time: 81.155s
[2K
| Adam | epoch: 013 | loss: 0.14341 - acc: 0.9724 -- iter: 160/256
[A[ATraining Step: 102  | total loss: [1m[32m0.13373[0m[0m | time: 94.187s
[2K
| Adam | epoch: 013 | loss: 0.13373 - acc: 0.9720 -- iter: 192/256
[A[ATraining Step: 103  | total loss: [1m[32m0.32097[0m[0m | time: 109.001s
[2K
| Adam | epoch: 013 | loss: 0.32097 - acc: 0.9373 -- iter: 224/256
[A[ATraining Step: 104  | total loss: [1m[32m0.29189[0m[0m | time: 134.500s
[2K
| Adam | epoch: 013 | loss: 0.29189 - acc: 0.9436 | val_loss: 1.43429 - val_acc: 0.5679 -- iter: 256/256
--
Training Step: 105  | total loss: [1m[32m0.27663[0m[0m | time: 15.666s
[2K
| Adam | epoch: 014 | loss: 0.27663 - acc: 0.9461 -- iter: 032/256
[A[ATraining Step: 106  | total loss: [1m[32m0.26109[0m[0m | time: 38.634s
[2K
| Adam | epoch: 014 | loss: 0.26109 - acc: 0.9484 -- iter: 064/256
[A[ATraining Step: 107  | total loss: [1m[32m0.24461[0m[0m | time: 54.143s
[2K
| Adam | epoch: 014 | loss: 0.24461 - acc: 0.9504 -- iter: 096/256
[A[ATraining Step: 108  | total loss: [1m[32m0.22798[0m[0m | time: 66.215s
[2K
| Adam | epoch: 014 | loss: 0.22798 - acc: 0.9554 -- iter: 128/256
[A[ATraining Step: 109  | total loss: [1m[32m0.21157[0m[0m | time: 78.431s
[2K
| Adam | epoch: 014 | loss: 0.21157 - acc: 0.9598 -- iter: 160/256
[A[ATraining Step: 110  | total loss: [1m[32m0.19782[0m[0m | time: 94.002s
[2K
| Adam | epoch: 014 | loss: 0.19782 - acc: 0.9607 -- iter: 192/256
[A[ATraining Step: 111  | total loss: [1m[32m0.18399[0m[0m | time: 107.402s
[2K
| Adam | epoch: 014 | loss: 0.18399 - acc: 0.9646 -- iter: 224/256
[A[ATraining Step: 112  | total loss: [1m[32m0.16920[0m[0m | time: 130.939s
[2K
| Adam | epoch: 014 | loss: 0.16920 - acc: 0.9682 | val_loss: 2.31588 - val_acc: 0.5556 -- iter: 256/256
--
Training Step: 113  | total loss: [1m[32m0.15462[0m[0m | time: 19.779s
[2K
| Adam | epoch: 015 | loss: 0.15462 - acc: 0.9714 -- iter: 032/256
[A[ATraining Step: 114  | total loss: [1m[32m0.14499[0m[0m | time: 35.375s
[2K
| Adam | epoch: 015 | loss: 0.14499 - acc: 0.9711 -- iter: 064/256
[A[ATraining Step: 115  | total loss: [1m[32m0.14333[0m[0m | time: 52.465s
[2K
| Adam | epoch: 015 | loss: 0.14333 - acc: 0.9677 -- iter: 096/256
[A[ATraining Step: 116  | total loss: [1m[32m0.13048[0m[0m | time: 63.427s
[2K
| Adam | epoch: 015 | loss: 0.13048 - acc: 0.9710 -- iter: 128/256
[A[ATraining Step: 117  | total loss: [1m[32m0.12360[0m[0m | time: 74.117s
[2K
| Adam | epoch: 015 | loss: 0.12360 - acc: 0.9707 -- iter: 160/256
[A[ATraining Step: 118  | total loss: [1m[32m0.11581[0m[0m | time: 89.442s
[2K
| Adam | epoch: 015 | loss: 0.11581 - acc: 0.9737 -- iter: 192/256
[A[ATraining Step: 119  | total loss: [1m[32m0.10920[0m[0m | time: 105.202s
[2K
| Adam | epoch: 015 | loss: 0.10920 - acc: 0.9763 -- iter: 224/256
[A[ATraining Step: 120  | total loss: [1m[32m0.10026[0m[0m | time: 126.540s
[2K
| Adam | epoch: 015 | loss: 0.10026 - acc: 0.9787 | val_loss: 0.45434 - val_acc: 0.8395 -- iter: 256/256
--
Training Step: 121  | total loss: [1m[32m0.09337[0m[0m | time: 25.205s
[2K
| Adam | epoch: 016 | loss: 0.09337 - acc: 0.9808 -- iter: 032/256
[A[ATraining Step: 122  | total loss: [1m[32m0.08594[0m[0m | time: 41.580s
[2K
| Adam | epoch: 016 | loss: 0.08594 - acc: 0.9827 -- iter: 064/256
[A[ATraining Step: 123  | total loss: [1m[32m0.07767[0m[0m | time: 55.855s
[2K
| Adam | epoch: 016 | loss: 0.07767 - acc: 0.9845 -- iter: 096/256
[A[ATraining Step: 124  | total loss: [1m[32m0.07041[0m[0m | time: 66.595s
[2K
| Adam | epoch: 016 | loss: 0.07041 - acc: 0.9860 -- iter: 128/256
[A[ATraining Step: 125  | total loss: [1m[32m0.06805[0m[0m | time: 79.479s
[2K
| Adam | epoch: 016 | loss: 0.06805 - acc: 0.9874 -- iter: 160/256
[A[ATraining Step: 126  | total loss: [1m[32m0.06254[0m[0m | time: 95.018s
[2K
| Adam | epoch: 016 | loss: 0.06254 - acc: 0.9887 -- iter: 192/256
[A[ATraining Step: 127  | total loss: [1m[32m0.05722[0m[0m | time: 109.961s
[2K
| Adam | epoch: 016 | loss: 0.05722 - acc: 0.9898 -- iter: 224/256
[A[ATraining Step: 128  | total loss: [1m[32m0.06633[0m[0m | time: 132.390s
[2K
| Adam | epoch: 016 | loss: 0.06633 - acc: 0.9877 | val_loss: 2.03128 - val_acc: 0.5802 -- iter: 256/256
--
Training Step: 129  | total loss: [1m[32m0.07531[0m[0m | time: 23.767s
[2K
| Adam | epoch: 017 | loss: 0.07531 - acc: 0.9858 -- iter: 032/256
[A[ATraining Step: 130  | total loss: [1m[32m0.06844[0m[0m | time: 41.751s
[2K
| Adam | epoch: 017 | loss: 0.06844 - acc: 0.9872 -- iter: 064/256
[A[ATraining Step: 131  | total loss: [1m[32m0.06237[0m[0m | time: 54.349s
[2K
| Adam | epoch: 017 | loss: 0.06237 - acc: 0.9885 -- iter: 096/256
[A[ATraining Step: 132  | total loss: [1m[32m0.05720[0m[0m | time: 65.511s
[2K
| Adam | epoch: 017 | loss: 0.05720 - acc: 0.9896 -- iter: 128/256
[A[ATraining Step: 133  | total loss: [1m[32m0.05518[0m[0m | time: 79.117s
[2K
| Adam | epoch: 017 | loss: 0.05518 - acc: 0.9907 -- iter: 160/256
[A[ATraining Step: 134  | total loss: [1m[32m0.05105[0m[0m | time: 94.273s
[2K
| Adam | epoch: 017 | loss: 0.05105 - acc: 0.9916 -- iter: 192/256
[A[ATraining Step: 135  | total loss: [1m[32m0.04932[0m[0m | time: 110.722s
[2K
| Adam | epoch: 017 | loss: 0.04932 - acc: 0.9893 -- iter: 224/256
[A[ATraining Step: 136  | total loss: [1m[32m0.04469[0m[0m | time: 134.342s
[2K
| Adam | epoch: 017 | loss: 0.04469 - acc: 0.9904 | val_loss: 1.05774 - val_acc: 0.7160 -- iter: 256/256
--
Training Step: 137  | total loss: [1m[32m0.07032[0m[0m | time: 20.672s
[2K
| Adam | epoch: 018 | loss: 0.07032 - acc: 0.9820 -- iter: 032/256
[A[ATraining Step: 138  | total loss: [1m[32m0.06387[0m[0m | time: 35.645s
[2K
| Adam | epoch: 018 | loss: 0.06387 - acc: 0.9838 -- iter: 064/256
[A[ATraining Step: 139  | total loss: [1m[32m0.06330[0m[0m | time: 46.577s
[2K
| Adam | epoch: 018 | loss: 0.06330 - acc: 0.9823 -- iter: 096/256
[A[ATraining Step: 140  | total loss: [1m[32m0.05846[0m[0m | time: 59.330s
[2K
| Adam | epoch: 018 | loss: 0.05846 - acc: 0.9841 -- iter: 128/256
[A[ATraining Step: 141  | total loss: [1m[32m0.05314[0m[0m | time: 74.423s
[2K
| Adam | epoch: 018 | loss: 0.05314 - acc: 0.9856 -- iter: 160/256
[A[ATraining Step: 142  | total loss: [1m[32m0.04877[0m[0m | time: 90.010s
[2K
| Adam | epoch: 018 | loss: 0.04877 - acc: 0.9871 -- iter: 192/256
[A[ATraining Step: 143  | total loss: [1m[32m0.04500[0m[0m | time: 111.149s
[2K
| Adam | epoch: 018 | loss: 0.04500 - acc: 0.9884 -- iter: 224/256
[A[ATraining Step: 144  | total loss: [1m[32m0.04678[0m[0m | time: 134.519s
[2K
| Adam | epoch: 018 | loss: 0.04678 - acc: 0.9864 | val_loss: 0.79612 - val_acc: 0.7901 -- iter: 256/256
--
Training Step: 145  | total loss: [1m[32m0.04360[0m[0m | time: 16.036s
[2K
| Adam | epoch: 019 | loss: 0.04360 - acc: 0.9878 -- iter: 032/256
[A[ATraining Step: 146  | total loss: [1m[32m0.05135[0m[0m | time: 26.642s
[2K
| Adam | epoch: 019 | loss: 0.05135 - acc: 0.9859 -- iter: 064/256
[A[ATraining Step: 147  | total loss: [1m[32m0.04706[0m[0m | time: 38.093s
[2K
| Adam | epoch: 019 | loss: 0.04706 - acc: 0.9873 -- iter: 096/256
[A[ATraining Step: 148  | total loss: [1m[32m0.04293[0m[0m | time: 53.525s
[2K
| Adam | epoch: 019 | loss: 0.04293 - acc: 0.9886 -- iter: 128/256
[A[ATraining Step: 149  | total loss: [1m[32m0.05053[0m[0m | time: 69.900s
[2K
| Adam | epoch: 019 | loss: 0.05053 - acc: 0.9866 -- iter: 160/256
[A[ATraining Step: 150  | total loss: [1m[32m0.04600[0m[0m | time: 86.671s
[2K
| Adam | epoch: 019 | loss: 0.04600 - acc: 0.9879 -- iter: 192/256
[A[ATraining Step: 151  | total loss: [1m[32m0.04280[0m[0m | time: 101.760s
[2K
| Adam | epoch: 019 | loss: 0.04280 - acc: 0.9891 -- iter: 224/256
[A[ATraining Step: 152  | total loss: [1m[32m0.04508[0m[0m | time: 125.558s
[2K
| Adam | epoch: 019 | loss: 0.04508 - acc: 0.9871 | val_loss: 3.23038 - val_acc: 0.5432 -- iter: 256/256
--
Training Step: 153  | total loss: [1m[32m0.04102[0m[0m | time: 15.099s
[2K
| Adam | epoch: 020 | loss: 0.04102 - acc: 0.9884 -- iter: 032/256
[A[ATraining Step: 154  | total loss: [1m[32m0.03720[0m[0m | time: 25.880s
[2K
| Adam | epoch: 020 | loss: 0.03720 - acc: 0.9895 -- iter: 064/256
[A[ATraining Step: 155  | total loss: [1m[32m0.03458[0m[0m | time: 38.635s
[2K
| Adam | epoch: 020 | loss: 0.03458 - acc: 0.9906 -- iter: 096/256
[A[ATraining Step: 156  | total loss: [1m[32m0.03238[0m[0m | time: 56.050s
[2K
| Adam | epoch: 020 | loss: 0.03238 - acc: 0.9915 -- iter: 128/256
[A[ATraining Step: 157  | total loss: [1m[32m0.05839[0m[0m | time: 70.825s
[2K
| Adam | epoch: 020 | loss: 0.05839 - acc: 0.9861 -- iter: 160/256
[A[ATraining Step: 158  | total loss: [1m[32m0.05299[0m[0m | time: 85.792s
[2K
| Adam | epoch: 020 | loss: 0.05299 - acc: 0.9875 -- iter: 192/256
[A[ATraining Step: 159  | total loss: [1m[32m0.06075[0m[0m | time: 104.074s
[2K
| Adam | epoch: 020 | loss: 0.06075 - acc: 0.9856 -- iter: 224/256
[A[ATraining Step: 160  | total loss: [1m[32m0.06837[0m[0m | time: 127.207s
[2K
| Adam | epoch: 020 | loss: 0.06837 - acc: 0.9839 | val_loss: 2.37334 - val_acc: 0.5802 -- iter: 256/256
--
Training Step: 161  | total loss: [1m[32m0.06603[0m[0m | time: 12.805s
[2K
| Adam | epoch: 021 | loss: 0.06603 - acc: 0.9856 -- iter: 032/256
[A[ATraining Step: 162  | total loss: [1m[32m0.06061[0m[0m | time: 24.862s
[2K
| Adam | epoch: 021 | loss: 0.06061 - acc: 0.9870 -- iter: 064/256
[A[ATraining Step: 163  | total loss: [1m[32m0.05536[0m[0m | time: 37.776s
[2K
| Adam | epoch: 021 | loss: 0.05536 - acc: 0.9883 -- iter: 096/256
[A[ATraining Step: 164  | total loss: [1m[32m0.05066[0m[0m | time: 56.142s
[2K
| Adam | epoch: 021 | loss: 0.05066 - acc: 0.9895 -- iter: 128/256
[A[ATraining Step: 165  | total loss: [1m[32m0.04703[0m[0m | time: 66.776s
[2K
| Adam | epoch: 021 | loss: 0.04703 - acc: 0.9905 -- iter: 160/256
[A[ATraining Step: 166  | total loss: [1m[32m0.07135[0m[0m | time: 77.547s
[2K
| Adam | epoch: 021 | loss: 0.07135 - acc: 0.9852 -- iter: 192/256
[A[ATraining Step: 167  | total loss: [1m[32m0.06870[0m[0m | time: 88.214s
[2K
| Adam | epoch: 021 | loss: 0.06870 - acc: 0.9836 -- iter: 224/256
[A[ATraining Step: 168  | total loss: [1m[32m0.06265[0m[0m | time: 103.581s
[2K
| Adam | epoch: 021 | loss: 0.06265 - acc: 0.9852 | val_loss: 0.59689 - val_acc: 0.8025 -- iter: 256/256
--
Training Step: 169  | total loss: [1m[32m0.05729[0m[0m | time: 11.957s
[2K
| Adam | epoch: 022 | loss: 0.05729 - acc: 0.9867 -- iter: 032/256
[A[ATraining Step: 170  | total loss: [1m[32m0.05248[0m[0m | time: 23.047s
[2K
| Adam | epoch: 022 | loss: 0.05248 - acc: 0.9880 -- iter: 064/256
[A[ATraining Step: 171  | total loss: [1m[32m0.06103[0m[0m | time: 33.590s
[2K
| Adam | epoch: 022 | loss: 0.06103 - acc: 0.9861 -- iter: 096/256
[A[ATraining Step: 172  | total loss: [1m[32m0.06628[0m[0m | time: 44.376s
[2K
| Adam | epoch: 022 | loss: 0.06628 - acc: 0.9844 -- iter: 128/256
[A[ATraining Step: 173  | total loss: [1m[32m0.06580[0m[0m | time: 54.869s
[2K
| Adam | epoch: 022 | loss: 0.06580 - acc: 0.9828 -- iter: 160/256
[A[ATraining Step: 174  | total loss: [1m[32m0.06001[0m[0m | time: 65.362s
[2K
| Adam | epoch: 022 | loss: 0.06001 - acc: 0.9845 -- iter: 192/256
[A[ATraining Step: 175  | total loss: [1m[32m0.08572[0m[0m | time: 76.257s
[2K
| Adam | epoch: 022 | loss: 0.08572 - acc: 0.9829 -- iter: 224/256
[A[ATraining Step: 176  | total loss: [1m[32m0.07884[0m[0m | time: 91.591s
[2K
| Adam | epoch: 022 | loss: 0.07884 - acc: 0.9846 | val_loss: 0.59654 - val_acc: 0.7778 -- iter: 256/256
--
Training Step: 177  | total loss: [1m[32m0.07918[0m[0m | time: 11.137s
[2K
| Adam | epoch: 023 | loss: 0.07918 - acc: 0.9831 -- iter: 032/256
[A[ATraining Step: 178  | total loss: [1m[32m0.07548[0m[0m | time: 22.035s
[2K
| Adam | epoch: 023 | loss: 0.07548 - acc: 0.9816 -- iter: 064/256
[A[ATraining Step: 179  | total loss: [1m[32m0.06889[0m[0m | time: 32.426s
[2K
| Adam | epoch: 023 | loss: 0.06889 - acc: 0.9835 -- iter: 096/256
[A[ATraining Step: 180  | total loss: [1m[32m0.06685[0m[0m | time: 43.237s
[2K
| Adam | epoch: 023 | loss: 0.06685 - acc: 0.9851 -- iter: 128/256
[A[ATraining Step: 181  | total loss: [1m[32m0.06287[0m[0m | time: 54.175s
[2K
| Adam | epoch: 023 | loss: 0.06287 - acc: 0.9866 -- iter: 160/256
[A[ATraining Step: 182  | total loss: [1m[32m0.06007[0m[0m | time: 65.144s
[2K
| Adam | epoch: 023 | loss: 0.06007 - acc: 0.9879 -- iter: 192/256
[A[ATraining Step: 183  | total loss: [1m[32m0.07521[0m[0m | time: 76.100s
[2K
| Adam | epoch: 023 | loss: 0.07521 - acc: 0.9860 -- iter: 224/256
[A[ATraining Step: 184  | total loss: [1m[32m0.08402[0m[0m | time: 91.767s
[2K
| Adam | epoch: 023 | loss: 0.08402 - acc: 0.9843 | val_loss: 0.61321 - val_acc: 0.8272 -- iter: 256/256
--
Training Step: 185  | total loss: [1m[32m0.07809[0m[0m | time: 10.439s
[2K
| Adam | epoch: 024 | loss: 0.07809 - acc: 0.9859 -- iter: 032/256
[A[ATraining Step: 186  | total loss: [1m[32m0.08782[0m[0m | time: 21.368s
[2K
| Adam | epoch: 024 | loss: 0.08782 - acc: 0.9842 -- iter: 064/256
[A[ATraining Step: 187  | total loss: [1m[32m0.08595[0m[0m | time: 31.995s
[2K
| Adam | epoch: 024 | loss: 0.08595 - acc: 0.9826 -- iter: 096/256
[A[ATraining Step: 188  | total loss: [1m[32m0.09131[0m[0m | time: 42.302s
[2K
| Adam | epoch: 024 | loss: 0.09131 - acc: 0.9812 -- iter: 128/256
[A[ATraining Step: 189  | total loss: [1m[32m0.08421[0m[0m | time: 52.782s
[2K
| Adam | epoch: 024 | loss: 0.08421 - acc: 0.9831 -- iter: 160/256
[A[ATraining Step: 190  | total loss: [1m[32m0.07746[0m[0m | time: 63.112s
[2K
| Adam | epoch: 024 | loss: 0.07746 - acc: 0.9848 -- iter: 192/256
[A[ATraining Step: 191  | total loss: [1m[32m0.07353[0m[0m | time: 74.987s
[2K
| Adam | epoch: 024 | loss: 0.07353 - acc: 0.9863 -- iter: 224/256
[A[ATraining Step: 192  | total loss: [1m[32m0.06738[0m[0m | time: 90.649s
[2K
| Adam | epoch: 024 | loss: 0.06738 - acc: 0.9877 | val_loss: 0.50921 - val_acc: 0.8148 -- iter: 256/256
--
Training Step: 193  | total loss: [1m[32m0.06146[0m[0m | time: 10.596s
[2K
| Adam | epoch: 025 | loss: 0.06146 - acc: 0.9889 -- iter: 032/256
[A[ATraining Step: 194  | total loss: [1m[32m0.05616[0m[0m | time: 21.289s
[2K
| Adam | epoch: 025 | loss: 0.05616 - acc: 0.9900 -- iter: 064/256
[A[ATraining Step: 195  | total loss: [1m[32m0.05092[0m[0m | time: 32.199s
[2K
| Adam | epoch: 025 | loss: 0.05092 - acc: 0.9910 -- iter: 096/256
[A[ATraining Step: 196  | total loss: [1m[32m0.04636[0m[0m | time: 42.746s
[2K
| Adam | epoch: 025 | loss: 0.04636 - acc: 0.9919 -- iter: 128/256
[A[ATraining Step: 197  | total loss: [1m[32m0.04211[0m[0m | time: 53.405s
[2K
| Adam | epoch: 025 | loss: 0.04211 - acc: 0.9927 -- iter: 160/256
[A[ATraining Step: 198  | total loss: [1m[32m0.04461[0m[0m | time: 64.928s
[2K
| Adam | epoch: 025 | loss: 0.04461 - acc: 0.9903 -- iter: 192/256
[A[ATraining Step: 199  | total loss: [1m[32m0.04299[0m[0m | time: 102.924s
[2K
| Adam | epoch: 025 | loss: 0.04299 - acc: 0.9882 -- iter: 224/256
[A[ATraining Step: 200  | total loss: [1m[32m0.03912[0m[0m | time: 115.444s
[2K
| Adam | epoch: 025 | loss: 0.03912 - acc: 0.9894 | val_loss: 0.54839 - val_acc: 0.8519 -- iter: 256/256
--
Training Step: 201  | total loss: [1m[32m0.03564[0m[0m | time: 8.570s
[2K
| Adam | epoch: 026 | loss: 0.03564 - acc: 0.9904 -- iter: 032/256
[A[ATraining Step: 202  | total loss: [1m[32m0.06620[0m[0m | time: 17.224s
[2K
| Adam | epoch: 026 | loss: 0.06620 - acc: 0.9851 -- iter: 064/256
[A[ATraining Step: 203  | total loss: [1m[32m0.06027[0m[0m | time: 26.018s
[2K
| Adam | epoch: 026 | loss: 0.06027 - acc: 0.9866 -- iter: 096/256
[A[ATraining Step: 204  | total loss: [1m[32m0.05574[0m[0m | time: 34.831s
[2K
| Adam | epoch: 026 | loss: 0.05574 - acc: 0.9880 -- iter: 128/256
[A[ATraining Step: 205  | total loss: [1m[32m0.05091[0m[0m | time: 43.295s
[2K
| Adam | epoch: 026 | loss: 0.05091 - acc: 0.9892 -- iter: 160/256
[A[ATraining Step: 206  | total loss: [1m[32m0.06673[0m[0m | time: 51.765s
[2K
| Adam | epoch: 026 | loss: 0.06673 - acc: 0.9871 -- iter: 192/256
[A[ATraining Step: 207  | total loss: [1m[32m0.06046[0m[0m | time: 60.316s
[2K
| Adam | epoch: 026 | loss: 0.06046 - acc: 0.9884 -- iter: 224/256
[A[ATraining Step: 208  | total loss: [1m[32m0.05481[0m[0m | time: 72.855s
[2K
| Adam | epoch: 026 | loss: 0.05481 - acc: 0.9896 | val_loss: 0.62489 - val_acc: 0.8148 -- iter: 256/256
--
Training Step: 209  | total loss: [1m[32m0.05349[0m[0m | time: 8.707s
[2K
| Adam | epoch: 027 | loss: 0.05349 - acc: 0.9906 -- iter: 032/256
[A[ATraining Step: 210  | total loss: [1m[32m0.04898[0m[0m | time: 17.138s
[2K
| Adam | epoch: 027 | loss: 0.04898 - acc: 0.9915 -- iter: 064/256
[A[ATraining Step: 211  | total loss: [1m[32m0.26095[0m[0m | time: 25.831s
[2K
| Adam | epoch: 027 | loss: 0.26095 - acc: 0.9580 -- iter: 096/256
[A[ATraining Step: 212  | total loss: [1m[32m0.24022[0m[0m | time: 34.344s
[2K
| Adam | epoch: 027 | loss: 0.24022 - acc: 0.9622 -- iter: 128/256
[A[ATraining Step: 213  | total loss: [1m[32m0.21885[0m[0m | time: 43.016s
[2K
| Adam | epoch: 027 | loss: 0.21885 - acc: 0.9660 -- iter: 160/256
[A[ATraining Step: 214  | total loss: [1m[32m0.20141[0m[0m | time: 51.590s
[2K
| Adam | epoch: 027 | loss: 0.20141 - acc: 0.9663 -- iter: 192/256
[A[ATraining Step: 215  | total loss: [1m[32m0.19536[0m[0m | time: 60.205s
[2K
| Adam | epoch: 027 | loss: 0.19536 - acc: 0.9665 -- iter: 224/256
[A[ATraining Step: 216  | total loss: [1m[32m0.18171[0m[0m | time: 72.791s
[2K
| Adam | epoch: 027 | loss: 0.18171 - acc: 0.9667 | val_loss: 0.35622 - val_acc: 0.8272 -- iter: 256/256
--
Training Step: 217  | total loss: [1m[32m0.16688[0m[0m | time: 8.828s
[2K
| Adam | epoch: 028 | loss: 0.16688 - acc: 0.9701 -- iter: 032/256
[A[ATraining Step: 218  | total loss: [1m[32m0.16346[0m[0m | time: 17.625s
[2K
| Adam | epoch: 028 | loss: 0.16346 - acc: 0.9699 -- iter: 064/256
[A[ATraining Step: 219  | total loss: [1m[32m0.15022[0m[0m | time: 26.025s
[2K
| Adam | epoch: 028 | loss: 0.15022 - acc: 0.9729 -- iter: 096/256
[A[ATraining Step: 220  | total loss: [1m[32m0.14625[0m[0m | time: 34.814s
[2K
| Adam | epoch: 028 | loss: 0.14625 - acc: 0.9725 -- iter: 128/256
[A[ATraining Step: 221  | total loss: [1m[32m0.13314[0m[0m | time: 43.490s
[2K
| Adam | epoch: 028 | loss: 0.13314 - acc: 0.9753 -- iter: 160/256
[A[ATraining Step: 222  | total loss: [1m[32m0.12303[0m[0m | time: 52.062s
[2K
| Adam | epoch: 028 | loss: 0.12303 - acc: 0.9777 -- iter: 192/256
[A[ATraining Step: 223  | total loss: [1m[32m0.11415[0m[0m | time: 60.642s
[2K
| Adam | epoch: 028 | loss: 0.11415 - acc: 0.9800 -- iter: 224/256
[A[ATraining Step: 224  | total loss: [1m[32m0.10750[0m[0m | time: 72.882s
[2K
| Adam | epoch: 028 | loss: 0.10750 - acc: 0.9788 | val_loss: 0.34224 - val_acc: 0.8519 -- iter: 256/256
--
Training Step: 225  | total loss: [1m[32m0.09896[0m[0m | time: 8.463s
[2K
| Adam | epoch: 029 | loss: 0.09896 - acc: 0.9810 -- iter: 032/256
[A[ATraining Step: 226  | total loss: [1m[32m0.09111[0m[0m | time: 16.975s
[2K
| Adam | epoch: 029 | loss: 0.09111 - acc: 0.9829 -- iter: 064/256
[A[ATraining Step: 227  | total loss: [1m[32m0.08328[0m[0m | time: 25.387s
[2K
| Adam | epoch: 029 | loss: 0.08328 - acc: 0.9846 -- iter: 096/256
[A[ATraining Step: 228  | total loss: [1m[32m0.08287[0m[0m | time: 34.030s
[2K
| Adam | epoch: 029 | loss: 0.08287 - acc: 0.9830 -- iter: 128/256
[A[ATraining Step: 229  | total loss: [1m[32m0.07555[0m[0m | time: 42.330s
[2K
| Adam | epoch: 029 | loss: 0.07555 - acc: 0.9847 -- iter: 160/256
[A[ATraining Step: 230  | total loss: [1m[32m0.07207[0m[0m | time: 50.901s
[2K
| Adam | epoch: 029 | loss: 0.07207 - acc: 0.9862 -- iter: 192/256
[A[ATraining Step: 231  | total loss: [1m[32m0.08218[0m[0m | time: 59.466s
[2K
| Adam | epoch: 029 | loss: 0.08218 - acc: 0.9845 -- iter: 224/256
[A[ATraining Step: 232  | total loss: [1m[32m0.07467[0m[0m | time: 71.723s
[2K
| Adam | epoch: 029 | loss: 0.07467 - acc: 0.9860 | val_loss: 0.29279 - val_acc: 0.8642 -- iter: 256/256
--
Training Step: 233  | total loss: [1m[32m0.06884[0m[0m | time: 8.463s
[2K
| Adam | epoch: 030 | loss: 0.06884 - acc: 0.9874 -- iter: 032/256
[A[ATraining Step: 234  | total loss: [1m[32m0.06242[0m[0m | time: 17.044s
[2K
| Adam | epoch: 030 | loss: 0.06242 - acc: 0.9887 -- iter: 064/256
[A[ATraining Step: 235  | total loss: [1m[32m0.05662[0m[0m | time: 25.687s
[2K
| Adam | epoch: 030 | loss: 0.05662 - acc: 0.9898 -- iter: 096/256
[A[ATraining Step: 236  | total loss: [1m[32m0.05250[0m[0m | time: 34.154s
[2K
| Adam | epoch: 030 | loss: 0.05250 - acc: 0.9908 -- iter: 128/256
[A[ATraining Step: 237  | total loss: [1m[32m0.04777[0m[0m | time: 42.747s
[2K
| Adam | epoch: 030 | loss: 0.04777 - acc: 0.9918 -- iter: 160/256
[A[ATraining Step: 238  | total loss: [1m[32m0.04394[0m[0m | time: 51.626s
[2K
| Adam | epoch: 030 | loss: 0.04394 - acc: 0.9926 -- iter: 192/256
[A[ATraining Step: 239  | total loss: [1m[32m0.04014[0m[0m | time: 60.343s
[2K
| Adam | epoch: 030 | loss: 0.04014 - acc: 0.9933 -- iter: 224/256
[A[ATraining Step: 240  | total loss: [1m[32m0.03688[0m[0m | time: 72.762s
[2K
| Adam | epoch: 030 | loss: 0.03688 - acc: 0.9940 | val_loss: 0.49831 - val_acc: 0.8025 -- iter: 256/256
--
Validation AUC:0.9506172839506173
Validation AUPRC:0.9651101611972022
Test AUC:0.9512345679012345
Test AUPRC:0.9488340816265384
BestTestF1Score	0.86	0.75	0.88	0.86	0.86	31	5	40	5	0.94
BestTestMCCScore	0.86	0.75	0.88	0.86	0.86	31	5	40	5	0.94
BestTestAccuracyScore	0.86	0.75	0.88	0.86	0.86	31	5	40	5	0.94
BestValidationF1Score	0.89	0.75	0.88	0.89	0.89	40	5	31	5	0.94
BestValidationMCC	0.89	0.75	0.88	0.89	0.89	40	5	31	5	0.94
BestValidationAccuracy	0.89	0.75	0.88	0.89	0.89	40	5	31	5	0.94
TestPredictions (Threshold:0.94)
CHEMBL2335415,TP,ACT,0.949999988079071	CHEMBL24045,TP,ACT,1.0	CHEMBL175698,TN,INACT,0.0	CHEMBL2335413,FN,ACT,0.9399999976158142	CHEMBL173629,TN,INACT,0.0	CHEMBL327091,TP,ACT,1.0	CHEMBL31025,TP,ACT,0.9900000095367432	CHEMBL44134,TN,INACT,0.3100000023841858	CHEMBL2322893,TN,INACT,0.5600000023841858	CHEMBL173424,TP,ACT,1.0	CHEMBL76949,TN,INACT,0.7900000214576721	CHEMBL172788,TN,INACT,0.6399999856948853	CHEMBL294649,TN,INACT,0.009999999776482582	CHEMBL311781,TN,INACT,0.46000000834465027	CHEMBL11414,TN,INACT,0.9399999976158142	CHEMBL416069,TN,INACT,0.029999999329447746	CHEMBL26224,TP,ACT,1.0	CHEMBL31529,FN,ACT,0.9100000262260437	CHEMBL281967,TP,ACT,1.0	CHEMBL269219,TP,ACT,1.0	CHEMBL45305,FP,INACT,0.9800000190734863	CHEMBL416150,TP,ACT,0.9900000095367432	CHEMBL1258999,TN,INACT,0.05000000074505806	CHEMBL6995,TP,ACT,1.0	CHEMBL48120,TN,INACT,0.1599999964237213	CHEMBL434,TP,ACT,1.0	CHEMBL31021,TP,ACT,1.0	CHEMBL11224,TP,ACT,1.0	CHEMBL336081,TN,INACT,0.14000000059604645	CHEMBL1983100,TN,INACT,0.1599999964237213	CHEMBL3392321,FN,ACT,0.2199999988079071	CHEMBL453,TN,INACT,0.07999999821186066	CHEMBL227378,TN,INACT,0.30000001192092896	CHEMBL40317,TN,INACT,0.07000000029802322	CHEMBL293232,TN,INACT,0.4000000059604645	CHEMBL118553,TN,INACT,0.4300000071525574	CHEMBL3323663,FN,ACT,0.8299999833106995	CHEMBL555637,TP,ACT,0.9800000190734863	CHEMBL416151,TN,INACT,0.11999999731779099	CHEMBL417712,TN,INACT,0.009999999776482582	CHEMBL30292,TP,ACT,0.9800000190734863	CHEMBL2042401,TN,INACT,0.9399999976158142	CHEMBL283535,TN,INACT,0.15000000596046448	CHEMBL3633656,TN,INACT,0.6899999976158142	CHEMBL11406,TP,ACT,0.9599999785423279	CHEMBL1788251,TP,ACT,1.0	CHEMBL1256786,TP,ACT,0.9900000095367432	CHEMBL162095,TN,INACT,0.7699999809265137	CHEMBL541088,FN,ACT,0.75	CHEMBL42065,FP,INACT,0.949999988079071	CHEMBL513389,TP,ACT,0.9800000190734863	CHEMBL302038,TN,INACT,0.1899999976158142	CHEMBL552615,TN,INACT,0.23999999463558197	CHEMBL3323653,TP,ACT,1.0	CHEMBL31411,TP,ACT,0.9900000095367432	CHEMBL39879,TN,INACT,0.6000000238418579	CHEMBL2335414,TP,ACT,0.9900000095367432	CHEMBL355100,TP,ACT,1.0	CHEMBL39873,TP,ACT,1.0	CHEMBL11131,TN,INACT,0.019999999552965164	CHEMBL1221681,TP,ACT,0.949999988079071	CHEMBL3309718,TN,INACT,0.7099999785423279	CHEMBL594802,TN,INACT,0.7799999713897705	CHEMBL2096751,TN,INACT,0.0	CHEMBL352779,TN,INACT,0.15000000596046448	CHEMBL2042551,TN,INACT,0.029999999329447746	CHEMBL358648,TP,ACT,1.0	CHEMBL2391356,FP,INACT,0.9800000190734863	CHEMBL2335409,TP,ACT,0.9599999785423279	CHEMBL423,TP,ACT,1.0	CHEMBL233552,TN,INACT,0.8100000023841858	CHEMBL6568,TN,INACT,0.8399999737739563	CHEMBL323176,FP,INACT,0.9900000095367432	CHEMBL10801,TN,INACT,0.009999999776482582	CHEMBL2042403,FP,INACT,0.9599999785423279	CHEMBL9746,TN,INACT,0.10999999940395355	CHEMBL279520,TN,INACT,0.03999999910593033	CHEMBL341654,TP,ACT,1.0	CHEMBL298203,TN,INACT,0.8100000023841858	CHEMBL31568,TP,ACT,0.9900000095367432	CHEMBL416030,TP,ACT,0.9900000095367432	

