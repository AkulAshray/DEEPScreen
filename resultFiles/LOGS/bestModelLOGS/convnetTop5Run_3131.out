ImageNetInceptionV2 CHEMBL4106 adam 0.0005 30 0 0 0.6 False True
Number of active compounds :	187
Number of inactive compounds :	187
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4106_adam_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4106_adam_0.0005_30_0.6/
---------------------------------
Training samples: 239
Validation samples: 75
--
Training Step: 1  | time: 95.517s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/239
[A[ATraining Step: 2  | total loss: [1m[32m0.70712[0m[0m | time: 164.284s
[2K
| Adam | epoch: 001 | loss: 0.70712 - acc: 0.3094 -- iter: 064/239
[A[ATraining Step: 3  | total loss: [1m[32m0.58531[0m[0m | time: 212.800s
[2K
| Adam | epoch: 001 | loss: 0.58531 - acc: 0.6443 -- iter: 096/239
[A[ATraining Step: 4  | total loss: [1m[32m0.66021[0m[0m | time: 251.832s
[2K
| Adam | epoch: 001 | loss: 0.66021 - acc: 0.7001 -- iter: 128/239
[A[ATraining Step: 5  | total loss: [1m[32m0.52327[0m[0m | time: 319.405s
[2K
| Adam | epoch: 001 | loss: 0.52327 - acc: 0.7563 -- iter: 160/239
[A[ATraining Step: 6  | total loss: [1m[32m0.47803[0m[0m | time: 372.465s
[2K
| Adam | epoch: 001 | loss: 0.47803 - acc: 0.7924 -- iter: 192/239
[A[ATraining Step: 7  | total loss: [1m[32m0.49462[0m[0m | time: 412.720s
[2K
| Adam | epoch: 001 | loss: 0.49462 - acc: 0.7857 -- iter: 224/239
[A[ATraining Step: 8  | total loss: [1m[32m0.42817[0m[0m | time: 434.797s
[2K
| Adam | epoch: 001 | loss: 0.42817 - acc: 0.8359 | val_loss: 0.75669 - val_acc: 0.5333 -- iter: 239/239
--
Training Step: 9  | total loss: [1m[32m0.37145[0m[0m | time: 4.727s
[2K
| Adam | epoch: 002 | loss: 0.37145 - acc: 0.8169 -- iter: 032/239
[A[ATraining Step: 10  | total loss: [1m[32m0.22197[0m[0m | time: 13.100s
[2K
| Adam | epoch: 002 | loss: 0.22197 - acc: 0.9085 -- iter: 064/239
[A[ATraining Step: 11  | total loss: [1m[32m0.33132[0m[0m | time: 86.021s
[2K
| Adam | epoch: 002 | loss: 0.33132 - acc: 0.8778 -- iter: 096/239
[A[ATraining Step: 12  | total loss: [1m[32m0.36526[0m[0m | time: 143.635s
[2K
| Adam | epoch: 002 | loss: 0.36526 - acc: 0.8906 -- iter: 128/239
[A[ATraining Step: 13  | total loss: [1m[32m0.42609[0m[0m | time: 185.731s
[2K
| Adam | epoch: 002 | loss: 0.42609 - acc: 0.8705 -- iter: 160/239
[A[ATraining Step: 14  | total loss: [1m[32m0.35278[0m[0m | time: 260.438s
[2K
| Adam | epoch: 002 | loss: 0.35278 - acc: 0.8851 -- iter: 192/239
[A[ATraining Step: 15  | total loss: [1m[32m0.28574[0m[0m | time: 273.181s
[2K
| Adam | epoch: 002 | loss: 0.28574 - acc: 0.9056 -- iter: 224/239
[A[ATraining Step: 16  | total loss: [1m[32m0.29139[0m[0m | time: 296.847s
[2K
| Adam | epoch: 002 | loss: 0.29139 - acc: 0.8824 | val_loss: 1.28626 - val_acc: 0.5333 -- iter: 239/239
--
Training Step: 17  | total loss: [1m[32m0.27945[0m[0m | time: 7.177s
[2K
| Adam | epoch: 003 | loss: 0.27945 - acc: 0.9023 -- iter: 032/239
[A[ATraining Step: 18  | total loss: [1m[32m0.29863[0m[0m | time: 14.169s
[2K
| Adam | epoch: 003 | loss: 0.29863 - acc: 0.8899 -- iter: 064/239
[A[ATraining Step: 19  | total loss: [1m[32m0.23601[0m[0m | time: 38.353s
[2K
| Adam | epoch: 003 | loss: 0.23601 - acc: 0.9044 -- iter: 096/239
[A[ATraining Step: 20  | total loss: [1m[32m0.19956[0m[0m | time: 75.270s
[2K
| Adam | epoch: 003 | loss: 0.19956 - acc: 0.9351 -- iter: 128/239
[A[ATraining Step: 21  | total loss: [1m[32m0.19551[0m[0m | time: 89.079s
[2K
| Adam | epoch: 003 | loss: 0.19551 - acc: 0.9262 -- iter: 160/239
[A[ATraining Step: 22  | total loss: [1m[32m0.17778[0m[0m | time: 131.274s
[2K
| Adam | epoch: 003 | loss: 0.17778 - acc: 0.9389 -- iter: 192/239
[A[ATraining Step: 23  | total loss: [1m[32m0.17933[0m[0m | time: 182.274s
[2K
| Adam | epoch: 003 | loss: 0.17933 - acc: 0.9385 -- iter: 224/239
[A[ATraining Step: 24  | total loss: [1m[32m0.18854[0m[0m | time: 232.785s
[2K
| Adam | epoch: 003 | loss: 0.18854 - acc: 0.9294 | val_loss: 0.68535 - val_acc: 0.5333 -- iter: 239/239
--
Training Step: 25  | total loss: [1m[32m0.17534[0m[0m | time: 13.630s
[2K
| Adam | epoch: 004 | loss: 0.17534 - acc: 0.9402 -- iter: 032/239
[A[ATraining Step: 26  | total loss: [1m[32m0.14254[0m[0m | time: 18.347s
[2K
| Adam | epoch: 004 | loss: 0.14254 - acc: 0.9560 -- iter: 064/239
[A[ATraining Step: 27  | total loss: [1m[32m0.22753[0m[0m | time: 22.985s
[2K
| Adam | epoch: 004 | loss: 0.22753 - acc: 0.9502 -- iter: 096/239
[A[ATraining Step: 28  | total loss: [1m[32m0.23399[0m[0m | time: 36.982s
[2K
| Adam | epoch: 004 | loss: 0.23399 - acc: 0.9460 -- iter: 128/239
[A[ATraining Step: 29  | total loss: [1m[32m0.19633[0m[0m | time: 49.555s
[2K
| Adam | epoch: 004 | loss: 0.19633 - acc: 0.9591 -- iter: 160/239
[A[ATraining Step: 30  | total loss: [1m[32m0.19873[0m[0m | time: 75.251s
[2K
| Adam | epoch: 004 | loss: 0.19873 - acc: 0.9392 -- iter: 192/239
[A[ATraining Step: 31  | total loss: [1m[32m0.18521[0m[0m | time: 88.240s
[2K
| Adam | epoch: 004 | loss: 0.18521 - acc: 0.9388 -- iter: 224/239
[A[ATraining Step: 32  | total loss: [1m[32m0.15759[0m[0m | time: 115.064s
[2K
| Adam | epoch: 004 | loss: 0.15759 - acc: 0.9526 | val_loss: 0.75622 - val_acc: 0.4667 -- iter: 239/239
--
Training Step: 33  | total loss: [1m[32m0.14516[0m[0m | time: 19.974s
[2K
| Adam | epoch: 005 | loss: 0.14516 - acc: 0.9561 -- iter: 032/239
[A[ATraining Step: 34  | total loss: [1m[32m0.12633[0m[0m | time: 74.022s
[2K
| Adam | epoch: 005 | loss: 0.12633 - acc: 0.9655 -- iter: 064/239
[A[ATraining Step: 35  | total loss: [1m[32m0.10983[0m[0m | time: 78.629s
[2K
| Adam | epoch: 005 | loss: 0.10983 - acc: 0.9727 -- iter: 096/239
[A[ATraining Step: 36  | total loss: [1m[32m0.09186[0m[0m | time: 83.443s
[2K
| Adam | epoch: 005 | loss: 0.09186 - acc: 0.9783 -- iter: 128/239
[A[ATraining Step: 37  | total loss: [1m[32m0.07625[0m[0m | time: 129.519s
[2K
| Adam | epoch: 005 | loss: 0.07625 - acc: 0.9827 -- iter: 160/239
[A[ATraining Step: 38  | total loss: [1m[32m0.07459[0m[0m | time: 143.421s
[2K
| Adam | epoch: 005 | loss: 0.07459 - acc: 0.9799 -- iter: 192/239
[A[ATraining Step: 39  | total loss: [1m[32m0.07266[0m[0m | time: 156.318s
[2K
| Adam | epoch: 005 | loss: 0.07266 - acc: 0.9778 -- iter: 224/239
[A[ATraining Step: 40  | total loss: [1m[32m0.07026[0m[0m | time: 175.921s
[2K
| Adam | epoch: 005 | loss: 0.07026 - acc: 0.9820 | val_loss: 1.28900 - val_acc: 0.5333 -- iter: 239/239
--
Training Step: 41  | total loss: [1m[32m0.06868[0m[0m | time: 37.903s
[2K
| Adam | epoch: 006 | loss: 0.06868 - acc: 0.9795 -- iter: 032/239
[A[ATraining Step: 42  | total loss: [1m[32m0.05708[0m[0m | time: 51.123s
[2K
| Adam | epoch: 006 | loss: 0.05708 - acc: 0.9832 -- iter: 064/239
[A[ATraining Step: 43  | total loss: [1m[32m0.05567[0m[0m | time: 64.797s
[2K
| Adam | epoch: 006 | loss: 0.05567 - acc: 0.9807 -- iter: 096/239
[A[ATraining Step: 44  | total loss: [1m[32m0.04656[0m[0m | time: 72.306s
[2K
| Adam | epoch: 006 | loss: 0.04656 - acc: 0.9840 -- iter: 128/239
[A[ATraining Step: 45  | total loss: [1m[32m0.04188[0m[0m | time: 79.657s
[2K
| Adam | epoch: 006 | loss: 0.04188 - acc: 0.9867 -- iter: 160/239
[A[ATraining Step: 46  | total loss: [1m[32m0.03587[0m[0m | time: 92.758s
[2K
| Adam | epoch: 006 | loss: 0.03587 - acc: 0.9889 -- iter: 192/239
[A[ATraining Step: 47  | total loss: [1m[32m0.03311[0m[0m | time: 115.943s
[2K
| Adam | epoch: 006 | loss: 0.03311 - acc: 0.9907 -- iter: 224/239
[A[ATraining Step: 48  | total loss: [1m[32m0.04843[0m[0m | time: 148.980s
[2K
| Adam | epoch: 006 | loss: 0.04843 - acc: 0.9822 | val_loss: 0.41125 - val_acc: 0.8667 -- iter: 239/239
--
Training Step: 49  | total loss: [1m[32m0.09414[0m[0m | time: 8.920s
[2K
| Adam | epoch: 007 | loss: 0.09414 - acc: 0.9751 -- iter: 032/239
[A[ATraining Step: 50  | total loss: [1m[32m0.09149[0m[0m | time: 17.282s
[2K
| Adam | epoch: 007 | loss: 0.09149 - acc: 0.9741 -- iter: 064/239
[A[ATraining Step: 51  | total loss: [1m[32m0.07861[0m[0m | time: 26.007s
[2K
| Adam | epoch: 007 | loss: 0.07861 - acc: 0.9781 -- iter: 096/239
[A[ATraining Step: 52  | total loss: [1m[32m0.06992[0m[0m | time: 34.294s
[2K
| Adam | epoch: 007 | loss: 0.06992 - acc: 0.9814 -- iter: 128/239
[A[ATraining Step: 53  | total loss: [1m[32m0.07157[0m[0m | time: 38.909s
[2K
| Adam | epoch: 007 | loss: 0.07157 - acc: 0.9795 -- iter: 160/239
[A[ATraining Step: 54  | total loss: [1m[32m0.06272[0m[0m | time: 43.563s
[2K
| Adam | epoch: 007 | loss: 0.06272 - acc: 0.9825 -- iter: 192/239
[A[ATraining Step: 55  | total loss: [1m[32m0.05431[0m[0m | time: 51.833s
[2K
| Adam | epoch: 007 | loss: 0.05431 - acc: 0.9850 -- iter: 224/239
[A[ATraining Step: 56  | total loss: [1m[32m0.05574[0m[0m | time: 64.176s
[2K
| Adam | epoch: 007 | loss: 0.05574 - acc: 0.9827 | val_loss: 0.13737 - val_acc: 0.9600 -- iter: 239/239
--
Training Step: 57  | total loss: [1m[32m0.09767[0m[0m | time: 8.411s
[2K
| Adam | epoch: 008 | loss: 0.09767 - acc: 0.9764 -- iter: 032/239
[A[ATraining Step: 58  | total loss: [1m[32m0.09037[0m[0m | time: 16.786s
[2K
| Adam | epoch: 008 | loss: 0.09037 - acc: 0.9797 -- iter: 064/239
[A[ATraining Step: 59  | total loss: [1m[32m0.08116[0m[0m | time: 25.373s
[2K
| Adam | epoch: 008 | loss: 0.08116 - acc: 0.9824 -- iter: 096/239
[A[ATraining Step: 60  | total loss: [1m[32m0.08044[0m[0m | time: 33.993s
[2K
| Adam | epoch: 008 | loss: 0.08044 - acc: 0.9764 -- iter: 128/239
[A[ATraining Step: 61  | total loss: [1m[32m0.07238[0m[0m | time: 42.561s
[2K
| Adam | epoch: 008 | loss: 0.07238 - acc: 0.9795 -- iter: 160/239
[A[ATraining Step: 62  | total loss: [1m[32m0.06422[0m[0m | time: 47.187s
[2K
| Adam | epoch: 008 | loss: 0.06422 - acc: 0.9822 -- iter: 192/239
[A[ATraining Step: 63  | total loss: [1m[32m0.05696[0m[0m | time: 51.937s
[2K
| Adam | epoch: 008 | loss: 0.05696 - acc: 0.9844 -- iter: 224/239
[A[ATraining Step: 64  | total loss: [1m[32m0.05088[0m[0m | time: 64.166s
[2K
| Adam | epoch: 008 | loss: 0.05088 - acc: 0.9864 | val_loss: 0.19835 - val_acc: 0.9467 -- iter: 239/239
--
Training Step: 65  | total loss: [1m[32m0.04833[0m[0m | time: 8.545s
[2K
| Adam | epoch: 009 | loss: 0.04833 - acc: 0.9880 -- iter: 032/239
[A[ATraining Step: 66  | total loss: [1m[32m0.06522[0m[0m | time: 17.121s
[2K
| Adam | epoch: 009 | loss: 0.06522 - acc: 0.9819 -- iter: 064/239
[A[ATraining Step: 67  | total loss: [1m[32m0.12231[0m[0m | time: 25.797s
[2K
| Adam | epoch: 009 | loss: 0.12231 - acc: 0.9616 -- iter: 096/239
[A[ATraining Step: 68  | total loss: [1m[32m0.11303[0m[0m | time: 34.531s
[2K
| Adam | epoch: 009 | loss: 0.11303 - acc: 0.9624 -- iter: 128/239
[A[ATraining Step: 69  | total loss: [1m[32m0.10324[0m[0m | time: 42.965s
[2K
| Adam | epoch: 009 | loss: 0.10324 - acc: 0.9668 -- iter: 160/239
[A[ATraining Step: 70  | total loss: [1m[32m0.09313[0m[0m | time: 51.474s
[2K
| Adam | epoch: 009 | loss: 0.09313 - acc: 0.9706 -- iter: 192/239
[A[ATraining Step: 71  | total loss: [1m[32m0.10222[0m[0m | time: 56.157s
[2K
| Adam | epoch: 009 | loss: 0.10222 - acc: 0.9633 -- iter: 224/239
[A[ATraining Step: 72  | total loss: [1m[32m0.10962[0m[0m | time: 64.493s
[2K
| Adam | epoch: 009 | loss: 0.10962 - acc: 0.9524 | val_loss: 1.46953 - val_acc: 0.5867 -- iter: 239/239
--
Training Step: 73  | total loss: [1m[32m0.10007[0m[0m | time: 8.823s
[2K
| Adam | epoch: 010 | loss: 0.10007 - acc: 0.9577 -- iter: 032/239
[A[ATraining Step: 74  | total loss: [1m[32m0.09022[0m[0m | time: 17.342s
[2K
| Adam | epoch: 010 | loss: 0.09022 - acc: 0.9624 -- iter: 064/239
[A[ATraining Step: 75  | total loss: [1m[32m0.08408[0m[0m | time: 25.759s
[2K
| Adam | epoch: 010 | loss: 0.08408 - acc: 0.9631 -- iter: 096/239
[A[ATraining Step: 76  | total loss: [1m[32m0.09911[0m[0m | time: 34.274s
[2K
| Adam | epoch: 010 | loss: 0.09911 - acc: 0.9637 -- iter: 128/239
[A[ATraining Step: 77  | total loss: [1m[32m0.08929[0m[0m | time: 42.657s
[2K
| Adam | epoch: 010 | loss: 0.08929 - acc: 0.9675 -- iter: 160/239
[A[ATraining Step: 78  | total loss: [1m[32m0.08063[0m[0m | time: 51.010s
[2K
| Adam | epoch: 010 | loss: 0.08063 - acc: 0.9709 -- iter: 192/239
[A[ATraining Step: 79  | total loss: [1m[32m0.07282[0m[0m | time: 59.441s
[2K
| Adam | epoch: 010 | loss: 0.07282 - acc: 0.9739 -- iter: 224/239
[A[ATraining Step: 80  | total loss: [1m[32m0.07085[0m[0m | time: 67.760s
[2K
| Adam | epoch: 010 | loss: 0.07085 - acc: 0.9734 | val_loss: 2.82795 - val_acc: 0.5333 -- iter: 239/239
--
Training Step: 81  | total loss: [1m[32m0.06522[0m[0m | time: 4.650s
[2K
| Adam | epoch: 011 | loss: 0.06522 - acc: 0.9761 -- iter: 032/239
[A[ATraining Step: 82  | total loss: [1m[32m0.05979[0m[0m | time: 13.004s
[2K
| Adam | epoch: 011 | loss: 0.05979 - acc: 0.9785 -- iter: 064/239
[A[ATraining Step: 83  | total loss: [1m[32m0.05555[0m[0m | time: 21.458s
[2K
| Adam | epoch: 011 | loss: 0.05555 - acc: 0.9806 -- iter: 096/239
[A[ATraining Step: 84  | total loss: [1m[32m0.05680[0m[0m | time: 29.823s
[2K
| Adam | epoch: 011 | loss: 0.05680 - acc: 0.9794 -- iter: 128/239
[A[ATraining Step: 85  | total loss: [1m[32m0.07218[0m[0m | time: 38.180s
[2K
| Adam | epoch: 011 | loss: 0.07218 - acc: 0.9784 -- iter: 160/239
[A[ATraining Step: 86  | total loss: [1m[32m0.06819[0m[0m | time: 46.762s
[2K
| Adam | epoch: 011 | loss: 0.06819 - acc: 0.9805 -- iter: 192/239
[A[ATraining Step: 87  | total loss: [1m[32m0.06323[0m[0m | time: 55.461s
[2K
| Adam | epoch: 011 | loss: 0.06323 - acc: 0.9825 -- iter: 224/239
[A[ATraining Step: 88  | total loss: [1m[32m0.05823[0m[0m | time: 67.843s
[2K
| Adam | epoch: 011 | loss: 0.05823 - acc: 0.9842 | val_loss: 0.18089 - val_acc: 0.9200 -- iter: 239/239
--
Training Step: 89  | total loss: [1m[32m0.05303[0m[0m | time: 4.610s
[2K
| Adam | epoch: 012 | loss: 0.05303 - acc: 0.9858 -- iter: 032/239
[A[ATraining Step: 90  | total loss: [1m[32m0.04946[0m[0m | time: 9.236s
[2K
| Adam | epoch: 012 | loss: 0.04946 - acc: 0.9872 -- iter: 064/239
[A[ATraining Step: 91  | total loss: [1m[32m0.04511[0m[0m | time: 17.587s
[2K
| Adam | epoch: 012 | loss: 0.04511 - acc: 0.9885 -- iter: 096/239
[A[ATraining Step: 92  | total loss: [1m[32m0.04268[0m[0m | time: 25.911s
[2K
| Adam | epoch: 012 | loss: 0.04268 - acc: 0.9897 -- iter: 128/239
[A[ATraining Step: 93  | total loss: [1m[32m0.04603[0m[0m | time: 34.260s
[2K
| Adam | epoch: 012 | loss: 0.04603 - acc: 0.9876 -- iter: 160/239
[A[ATraining Step: 94  | total loss: [1m[32m0.04501[0m[0m | time: 42.519s
[2K
| Adam | epoch: 012 | loss: 0.04501 - acc: 0.9857 -- iter: 192/239
[A[ATraining Step: 95  | total loss: [1m[32m0.04112[0m[0m | time: 50.847s
[2K
| Adam | epoch: 012 | loss: 0.04112 - acc: 0.9871 -- iter: 224/239
[A[ATraining Step: 96  | total loss: [1m[32m0.03824[0m[0m | time: 62.804s
[2K
| Adam | epoch: 012 | loss: 0.03824 - acc: 0.9884 | val_loss: 0.38446 - val_acc: 0.8667 -- iter: 239/239
--
Training Step: 97  | total loss: [1m[32m0.03789[0m[0m | time: 8.397s
[2K
| Adam | epoch: 013 | loss: 0.03789 - acc: 0.9864 -- iter: 032/239
[A[ATraining Step: 98  | total loss: [1m[32m0.04724[0m[0m | time: 12.918s
[2K
| Adam | epoch: 013 | loss: 0.04724 - acc: 0.9847 -- iter: 064/239
[A[ATraining Step: 99  | total loss: [1m[32m0.06563[0m[0m | time: 17.489s
[2K
| Adam | epoch: 013 | loss: 0.06563 - acc: 0.9795 -- iter: 096/239
[A[ATraining Step: 100  | total loss: [1m[32m0.06145[0m[0m | time: 25.998s
[2K
| Adam | epoch: 013 | loss: 0.06145 - acc: 0.9816 -- iter: 128/239
[A[ATraining Step: 101  | total loss: [1m[32m0.05640[0m[0m | time: 35.347s
[2K
| Adam | epoch: 013 | loss: 0.05640 - acc: 0.9834 -- iter: 160/239
[A[ATraining Step: 102  | total loss: [1m[32m0.05209[0m[0m | time: 45.464s
[2K
| Adam | epoch: 013 | loss: 0.05209 - acc: 0.9851 -- iter: 192/239
[A[ATraining Step: 103  | total loss: [1m[32m0.06218[0m[0m | time: 55.215s
[2K
| Adam | epoch: 013 | loss: 0.06218 - acc: 0.9834 -- iter: 224/239
[A[ATraining Step: 104  | total loss: [1m[32m0.05809[0m[0m | time: 69.302s
[2K
| Adam | epoch: 013 | loss: 0.05809 - acc: 0.9851 | val_loss: 0.25918 - val_acc: 0.9467 -- iter: 239/239
--
Training Step: 105  | total loss: [1m[32m0.05377[0m[0m | time: 9.984s
[2K
| Adam | epoch: 014 | loss: 0.05377 - acc: 0.9866 -- iter: 032/239
[A[ATraining Step: 106  | total loss: [1m[32m0.05133[0m[0m | time: 19.833s
[2K
| Adam | epoch: 014 | loss: 0.05133 - acc: 0.9879 -- iter: 064/239
[A[ATraining Step: 107  | total loss: [1m[32m0.04698[0m[0m | time: 25.356s
[2K
| Adam | epoch: 014 | loss: 0.04698 - acc: 0.9891 -- iter: 096/239
[A[ATraining Step: 108  | total loss: [1m[32m0.04297[0m[0m | time: 30.643s
[2K
| Adam | epoch: 014 | loss: 0.04297 - acc: 0.9902 -- iter: 128/239
[A[ATraining Step: 109  | total loss: [1m[32m0.03937[0m[0m | time: 40.201s
[2K
| Adam | epoch: 014 | loss: 0.03937 - acc: 0.9912 -- iter: 160/239
[A[ATraining Step: 110  | total loss: [1m[32m0.06279[0m[0m | time: 49.953s
[2K
| Adam | epoch: 014 | loss: 0.06279 - acc: 0.9858 -- iter: 192/239
[A[ATraining Step: 111  | total loss: [1m[32m0.07713[0m[0m | time: 60.027s
[2K
| Adam | epoch: 014 | loss: 0.07713 - acc: 0.9841 -- iter: 224/239
[A[ATraining Step: 112  | total loss: [1m[32m0.07041[0m[0m | time: 75.050s
[2K
| Adam | epoch: 014 | loss: 0.07041 - acc: 0.9857 | val_loss: 2.41721 - val_acc: 0.6400 -- iter: 239/239
--
Training Step: 113  | total loss: [1m[32m0.06768[0m[0m | time: 10.924s
[2K
| Adam | epoch: 015 | loss: 0.06768 - acc: 0.9840 -- iter: 032/239
[A[ATraining Step: 114  | total loss: [1m[32m0.07216[0m[0m | time: 28.962s
[2K
| Adam | epoch: 015 | loss: 0.07216 - acc: 0.9825 -- iter: 064/239
[A[ATraining Step: 115  | total loss: [1m[32m0.06680[0m[0m | time: 108.560s
[2K
| Adam | epoch: 015 | loss: 0.06680 - acc: 0.9842 -- iter: 096/239
[A[ATraining Step: 116  | total loss: [1m[32m0.06366[0m[0m | time: 150.583s
[2K
| Adam | epoch: 015 | loss: 0.06366 - acc: 0.9858 -- iter: 128/239
[A[ATraining Step: 117  | total loss: [1m[32m0.07368[0m[0m | time: 161.101s
[2K
| Adam | epoch: 015 | loss: 0.07368 - acc: 0.9739 -- iter: 160/239
[A[ATraining Step: 118  | total loss: [1m[32m0.06989[0m[0m | time: 199.088s
[2K
| Adam | epoch: 015 | loss: 0.06989 - acc: 0.9765 -- iter: 192/239
[A[ATraining Step: 119  | total loss: [1m[32m0.06710[0m[0m | time: 219.763s
[2K
| Adam | epoch: 015 | loss: 0.06710 - acc: 0.9757 -- iter: 224/239
[A[ATraining Step: 120  | total loss: [1m[32m0.06150[0m[0m | time: 273.496s
[2K
| Adam | epoch: 015 | loss: 0.06150 - acc: 0.9782 | val_loss: 0.18674 - val_acc: 0.9600 -- iter: 239/239
--
Training Step: 121  | total loss: [1m[32m0.07323[0m[0m | time: 49.890s
[2K
| Adam | epoch: 016 | loss: 0.07323 - acc: 0.9772 -- iter: 032/239
[A[ATraining Step: 122  | total loss: [1m[32m0.06695[0m[0m | time: 125.301s
[2K
| Adam | epoch: 016 | loss: 0.06695 - acc: 0.9795 -- iter: 064/239
[A[ATraining Step: 123  | total loss: [1m[32m0.06155[0m[0m | time: 164.603s
[2K
| Adam | epoch: 016 | loss: 0.06155 - acc: 0.9815 -- iter: 096/239
[A[ATraining Step: 124  | total loss: [1m[32m0.05609[0m[0m | time: 208.284s
[2K
| Adam | epoch: 016 | loss: 0.05609 - acc: 0.9834 -- iter: 128/239
[A[ATraining Step: 125  | total loss: [1m[32m0.05191[0m[0m | time: 229.588s
[2K
| Adam | epoch: 016 | loss: 0.05191 - acc: 0.9851 -- iter: 160/239
[A[ATraining Step: 126  | total loss: [1m[32m0.04847[0m[0m | time: 237.576s
[2K
| Adam | epoch: 016 | loss: 0.04847 - acc: 0.9865 -- iter: 192/239
[A[ATraining Step: 127  | total loss: [1m[32m0.04394[0m[0m | time: 286.167s
[2K
| Adam | epoch: 016 | loss: 0.04394 - acc: 0.9879 -- iter: 224/239
[A[ATraining Step: 128  | total loss: [1m[32m0.04016[0m[0m | time: 343.933s
[2K
| Adam | epoch: 016 | loss: 0.04016 - acc: 0.9891 | val_loss: 0.15934 - val_acc: 0.9600 -- iter: 239/239
--
Training Step: 129  | total loss: [1m[32m0.03829[0m[0m | time: 53.929s
[2K
| Adam | epoch: 017 | loss: 0.03829 - acc: 0.9902 -- iter: 032/239
[A[ATraining Step: 130  | total loss: [1m[32m0.04671[0m[0m | time: 67.325s
[2K
| Adam | epoch: 017 | loss: 0.04671 - acc: 0.9880 -- iter: 064/239
[A[ATraining Step: 131  | total loss: [1m[32m0.04288[0m[0m | time: 99.262s
[2K
| Adam | epoch: 017 | loss: 0.04288 - acc: 0.9892 -- iter: 096/239
[A[ATraining Step: 132  | total loss: [1m[32m0.03995[0m[0m | time: 148.631s
[2K
| Adam | epoch: 017 | loss: 0.03995 - acc: 0.9903 -- iter: 128/239
[A[ATraining Step: 133  | total loss: [1m[32m0.04957[0m[0m | time: 166.998s
[2K
| Adam | epoch: 017 | loss: 0.04957 - acc: 0.9882 -- iter: 160/239
[A[ATraining Step: 134  | total loss: [1m[32m0.04543[0m[0m | time: 180.354s
[2K
| Adam | epoch: 017 | loss: 0.04543 - acc: 0.9893 -- iter: 192/239
[A[ATraining Step: 135  | total loss: [1m[32m0.06025[0m[0m | time: 188.084s
[2K
| Adam | epoch: 017 | loss: 0.06025 - acc: 0.9837 -- iter: 224/239
[A[ATraining Step: 136  | total loss: [1m[32m0.05675[0m[0m | time: 210.594s
[2K
| Adam | epoch: 017 | loss: 0.05675 - acc: 0.9854 | val_loss: 0.28981 - val_acc: 0.9467 -- iter: 239/239
--
Training Step: 137  | total loss: [1m[32m0.05135[0m[0m | time: 24.921s
[2K
| Adam | epoch: 018 | loss: 0.05135 - acc: 0.9868 -- iter: 032/239
[A[ATraining Step: 138  | total loss: [1m[32m0.04927[0m[0m | time: 60.838s
[2K
| Adam | epoch: 018 | loss: 0.04927 - acc: 0.9850 -- iter: 064/239
[A[ATraining Step: 139  | total loss: [1m[32m0.06119[0m[0m | time: 75.816s
[2K
| Adam | epoch: 018 | loss: 0.06119 - acc: 0.9834 -- iter: 096/239
[A[ATraining Step: 140  | total loss: [1m[32m0.05613[0m[0m | time: 92.366s
[2K
| Adam | epoch: 018 | loss: 0.05613 - acc: 0.9851 -- iter: 128/239
[A[ATraining Step: 141  | total loss: [1m[32m0.05103[0m[0m | time: 136.811s
[2K
| Adam | epoch: 018 | loss: 0.05103 - acc: 0.9866 -- iter: 160/239
[A[ATraining Step: 142  | total loss: [1m[32m0.05427[0m[0m | time: 167.307s
[2K
| Adam | epoch: 018 | loss: 0.05427 - acc: 0.9848 -- iter: 192/239
[A[ATraining Step: 143  | total loss: [1m[32m0.04969[0m[0m | time: 188.856s
[2K
| Adam | epoch: 018 | loss: 0.04969 - acc: 0.9863 -- iter: 224/239
[A[ATraining Step: 144  | total loss: [1m[32m0.04663[0m[0m | time: 202.712s
[2K
| Adam | epoch: 018 | loss: 0.04663 - acc: 0.9877 | val_loss: 0.49715 - val_acc: 0.8667 -- iter: 239/239
--
Training Step: 145  | total loss: [1m[32m0.04273[0m[0m | time: 17.605s
[2K
| Adam | epoch: 019 | loss: 0.04273 - acc: 0.9889 -- iter: 032/239
[A[ATraining Step: 146  | total loss: [1m[32m0.05837[0m[0m | time: 33.363s
[2K
| Adam | epoch: 019 | loss: 0.05837 - acc: 0.9806 -- iter: 064/239
[A[ATraining Step: 147  | total loss: [1m[32m0.06699[0m[0m | time: 96.563s
[2K
| Adam | epoch: 019 | loss: 0.06699 - acc: 0.9794 -- iter: 096/239
[A[ATraining Step: 148  | total loss: [1m[32m0.10497[0m[0m | time: 119.455s
[2K
| Adam | epoch: 019 | loss: 0.10497 - acc: 0.9784 -- iter: 128/239
[A[ATraining Step: 149  | total loss: [1m[32m0.09633[0m[0m | time: 133.328s
[2K
| Adam | epoch: 019 | loss: 0.09633 - acc: 0.9805 -- iter: 160/239
[A[ATraining Step: 150  | total loss: [1m[32m0.08827[0m[0m | time: 159.791s
[2K
| Adam | epoch: 019 | loss: 0.08827 - acc: 0.9825 -- iter: 192/239
[A[ATraining Step: 151  | total loss: [1m[32m0.08069[0m[0m | time: 173.138s
[2K
| Adam | epoch: 019 | loss: 0.08069 - acc: 0.9842 -- iter: 224/239
[A[ATraining Step: 152  | total loss: [1m[32m0.07450[0m[0m | time: 186.549s
[2K
| Adam | epoch: 019 | loss: 0.07450 - acc: 0.9858 | val_loss: 0.12545 - val_acc: 0.9467 -- iter: 239/239
--
Training Step: 153  | total loss: [1m[32m0.07493[0m[0m | time: 7.854s
[2K
| Adam | epoch: 020 | loss: 0.07493 - acc: 0.9806 -- iter: 032/239
[A[ATraining Step: 154  | total loss: [1m[32m0.06939[0m[0m | time: 22.054s
[2K
| Adam | epoch: 020 | loss: 0.06939 - acc: 0.9825 -- iter: 064/239
[A[ATraining Step: 155  | total loss: [1m[32m0.06385[0m[0m | time: 53.072s
[2K
| Adam | epoch: 020 | loss: 0.06385 - acc: 0.9843 -- iter: 096/239
[A[ATraining Step: 156  | total loss: [1m[32m0.07372[0m[0m | time: 66.800s
[2K
| Adam | epoch: 020 | loss: 0.07372 - acc: 0.9733 -- iter: 128/239
[A[ATraining Step: 157  | total loss: [1m[32m0.11191[0m[0m | time: 80.657s
[2K
| Adam | epoch: 020 | loss: 0.11191 - acc: 0.9666 -- iter: 160/239
[A[ATraining Step: 158  | total loss: [1m[32m0.10774[0m[0m | time: 94.793s
[2K
| Adam | epoch: 020 | loss: 0.10774 - acc: 0.9668 -- iter: 192/239
[A[ATraining Step: 159  | total loss: [1m[32m0.10312[0m[0m | time: 108.600s
[2K
| Adam | epoch: 020 | loss: 0.10312 - acc: 0.9670 -- iter: 224/239
[A[ATraining Step: 160  | total loss: [1m[32m0.10557[0m[0m | time: 129.675s
[2K
| Adam | epoch: 020 | loss: 0.10557 - acc: 0.9641 | val_loss: 0.22585 - val_acc: 0.9333 -- iter: 239/239
--
Training Step: 161  | total loss: [1m[32m0.10534[0m[0m | time: 8.599s
[2K
| Adam | epoch: 021 | loss: 0.10534 - acc: 0.9677 -- iter: 032/239
[A[ATraining Step: 162  | total loss: [1m[32m0.09801[0m[0m | time: 17.373s
[2K
| Adam | epoch: 021 | loss: 0.09801 - acc: 0.9709 -- iter: 064/239
[A[ATraining Step: 163  | total loss: [1m[32m0.09023[0m[0m | time: 30.537s
[2K
| Adam | epoch: 021 | loss: 0.09023 - acc: 0.9738 -- iter: 096/239
[A[ATraining Step: 164  | total loss: [1m[32m0.08501[0m[0m | time: 39.377s
[2K
| Adam | epoch: 021 | loss: 0.08501 - acc: 0.9764 -- iter: 128/239
[A[ATraining Step: 165  | total loss: [1m[32m0.07919[0m[0m | time: 48.271s
[2K
| Adam | epoch: 021 | loss: 0.07919 - acc: 0.9788 -- iter: 160/239
[A[ATraining Step: 166  | total loss: [1m[32m0.09919[0m[0m | time: 57.065s
[2K
| Adam | epoch: 021 | loss: 0.09919 - acc: 0.9778 -- iter: 192/239
[A[ATraining Step: 167  | total loss: [1m[32m0.09003[0m[0m | time: 66.924s
[2K
| Adam | epoch: 021 | loss: 0.09003 - acc: 0.9800 -- iter: 224/239
[A[ATraining Step: 168  | total loss: [1m[32m0.08276[0m[0m | time: 91.060s
[2K
| Adam | epoch: 021 | loss: 0.08276 - acc: 0.9820 | val_loss: 0.66007 - val_acc: 0.6400 -- iter: 239/239
--
Training Step: 169  | total loss: [1m[32m0.07570[0m[0m | time: 14.619s
[2K
| Adam | epoch: 022 | loss: 0.07570 - acc: 0.9838 -- iter: 032/239
[A[ATraining Step: 170  | total loss: [1m[32m0.06989[0m[0m | time: 22.156s
[2K
| Adam | epoch: 022 | loss: 0.06989 - acc: 0.9854 -- iter: 064/239
[A[ATraining Step: 171  | total loss: [1m[32m0.06339[0m[0m | time: 29.742s
[2K
| Adam | epoch: 022 | loss: 0.06339 - acc: 0.9869 -- iter: 096/239
[A[ATraining Step: 172  | total loss: [1m[32m0.05741[0m[0m | time: 43.098s
[2K
| Adam | epoch: 022 | loss: 0.05741 - acc: 0.9882 -- iter: 128/239
[A[ATraining Step: 173  | total loss: [1m[32m0.05454[0m[0m | time: 60.755s
[2K
| Adam | epoch: 022 | loss: 0.05454 - acc: 0.9862 -- iter: 160/239
[A[ATraining Step: 174  | total loss: [1m[32m0.04990[0m[0m | time: 74.334s
[2K
| Adam | epoch: 022 | loss: 0.04990 - acc: 0.9876 -- iter: 192/239
[A[ATraining Step: 175  | total loss: [1m[32m0.06345[0m[0m | time: 89.364s
[2K
| Adam | epoch: 022 | loss: 0.06345 - acc: 0.9857 -- iter: 224/239
[A[ATraining Step: 176  | total loss: [1m[32m0.05806[0m[0m | time: 121.460s
[2K
| Adam | epoch: 022 | loss: 0.05806 - acc: 0.9872 | val_loss: 0.10720 - val_acc: 0.9600 -- iter: 239/239
--
Training Step: 177  | total loss: [1m[32m0.05302[0m[0m | time: 14.300s
[2K
| Adam | epoch: 023 | loss: 0.05302 - acc: 0.9884 -- iter: 032/239
[A[ATraining Step: 178  | total loss: [1m[32m0.04823[0m[0m | time: 28.132s
[2K
| Adam | epoch: 023 | loss: 0.04823 - acc: 0.9896 -- iter: 064/239
[A[ATraining Step: 179  | total loss: [1m[32m0.04861[0m[0m | time: 40.870s
[2K
| Adam | epoch: 023 | loss: 0.04861 - acc: 0.9875 -- iter: 096/239
[A[ATraining Step: 180  | total loss: [1m[32m0.04449[0m[0m | time: 52.279s
[2K
| Adam | epoch: 023 | loss: 0.04449 - acc: 0.9888 -- iter: 128/239
[A[ATraining Step: 181  | total loss: [1m[32m0.04051[0m[0m | time: 68.775s
[2K
| Adam | epoch: 023 | loss: 0.04051 - acc: 0.9899 -- iter: 160/239
[A[ATraining Step: 182  | total loss: [1m[32m0.03690[0m[0m | time: 83.907s
[2K
| Adam | epoch: 023 | loss: 0.03690 - acc: 0.9909 -- iter: 192/239
[A[ATraining Step: 183  | total loss: [1m[32m0.03381[0m[0m | time: 103.282s
[2K
| Adam | epoch: 023 | loss: 0.03381 - acc: 0.9918 -- iter: 224/239
[A[ATraining Step: 184  | total loss: [1m[32m0.08257[0m[0m | time: 154.913s
[2K
| Adam | epoch: 023 | loss: 0.08257 - acc: 0.9864 | val_loss: 0.15163 - val_acc: 0.9733 -- iter: 239/239
--
Training Step: 185  | total loss: [1m[32m0.07487[0m[0m | time: 19.498s
[2K
| Adam | epoch: 024 | loss: 0.07487 - acc: 0.9877 -- iter: 032/239
[A[ATraining Step: 186  | total loss: [1m[32m0.06880[0m[0m | time: 33.241s
[2K
| Adam | epoch: 024 | loss: 0.06880 - acc: 0.9890 -- iter: 064/239
[A[ATraining Step: 187  | total loss: [1m[32m0.06742[0m[0m | time: 50.675s
[2K
| Adam | epoch: 024 | loss: 0.06742 - acc: 0.9901 -- iter: 096/239
[A[ATraining Step: 188  | total loss: [1m[32m0.06112[0m[0m | time: 58.109s
[2K
| Adam | epoch: 024 | loss: 0.06112 - acc: 0.9911 -- iter: 128/239
[A[ATraining Step: 189  | total loss: [1m[32m0.05637[0m[0m | time: 65.728s
[2K
| Adam | epoch: 024 | loss: 0.05637 - acc: 0.9920 -- iter: 160/239
[A[ATraining Step: 190  | total loss: [1m[32m0.05179[0m[0m | time: 87.209s
[2K
| Adam | epoch: 024 | loss: 0.05179 - acc: 0.9928 -- iter: 192/239
[A[ATraining Step: 191  | total loss: [1m[32m0.04876[0m[0m | time: 110.528s
[2K
| Adam | epoch: 024 | loss: 0.04876 - acc: 0.9935 -- iter: 224/239
[A[ATraining Step: 192  | total loss: [1m[32m0.05082[0m[0m | time: 139.595s
[2K
| Adam | epoch: 024 | loss: 0.05082 - acc: 0.9941 | val_loss: 0.14012 - val_acc: 0.9733 -- iter: 239/239
--
Training Step: 193  | total loss: [1m[32m0.06786[0m[0m | time: 13.877s
[2K
| Adam | epoch: 025 | loss: 0.06786 - acc: 0.9916 -- iter: 032/239
[A[ATraining Step: 194  | total loss: [1m[32m0.06628[0m[0m | time: 30.859s
[2K
| Adam | epoch: 025 | loss: 0.06628 - acc: 0.9893 -- iter: 064/239
[A[ATraining Step: 195  | total loss: [1m[32m0.06055[0m[0m | time: 44.568s
[2K
| Adam | epoch: 025 | loss: 0.06055 - acc: 0.9904 -- iter: 096/239
[A[ATraining Step: 196  | total loss: [1m[32m0.05587[0m[0m | time: 58.411s
[2K
| Adam | epoch: 025 | loss: 0.05587 - acc: 0.9913 -- iter: 128/239
[A[ATraining Step: 197  | total loss: [1m[32m0.05060[0m[0m | time: 65.870s
[2K
| Adam | epoch: 025 | loss: 0.05060 - acc: 0.9922 -- iter: 160/239
[A[ATraining Step: 198  | total loss: [1m[32m0.04843[0m[0m | time: 73.668s
[2K
| Adam | epoch: 025 | loss: 0.04843 - acc: 0.9930 -- iter: 192/239
[A[ATraining Step: 199  | total loss: [1m[32m0.04510[0m[0m | time: 99.799s
[2K
| Adam | epoch: 025 | loss: 0.04510 - acc: 0.9937 -- iter: 224/239
[A[ATraining Step: 200  | total loss: [1m[32m0.04599[0m[0m | time: 142.728s
[2K
| Adam | epoch: 025 | loss: 0.04599 - acc: 0.9912 | val_loss: 0.28228 - val_acc: 0.9067 -- iter: 239/239
--
Training Step: 201  | total loss: [1m[32m0.04240[0m[0m | time: 19.202s
[2K
| Adam | epoch: 026 | loss: 0.04240 - acc: 0.9921 -- iter: 032/239
[A[ATraining Step: 202  | total loss: [1m[32m0.03863[0m[0m | time: 37.625s
[2K
| Adam | epoch: 026 | loss: 0.03863 - acc: 0.9929 -- iter: 064/239
[A[ATraining Step: 203  | total loss: [1m[32m0.03513[0m[0m | time: 61.013s
[2K
| Adam | epoch: 026 | loss: 0.03513 - acc: 0.9936 -- iter: 096/239
[A[ATraining Step: 204  | total loss: [1m[32m0.03232[0m[0m | time: 94.218s
[2K
| Adam | epoch: 026 | loss: 0.03232 - acc: 0.9942 -- iter: 128/239
[A[ATraining Step: 205  | total loss: [1m[32m0.03033[0m[0m | time: 141.187s
[2K
| Adam | epoch: 026 | loss: 0.03033 - acc: 0.9948 -- iter: 160/239
[A[ATraining Step: 206  | total loss: [1m[32m0.02754[0m[0m | time: 157.306s
[2K
| Adam | epoch: 026 | loss: 0.02754 - acc: 0.9953 -- iter: 192/239
[A[ATraining Step: 207  | total loss: [1m[32m0.02490[0m[0m | time: 166.721s
[2K
| Adam | epoch: 026 | loss: 0.02490 - acc: 0.9958 -- iter: 224/239
[A[ATraining Step: 208  | total loss: [1m[32m0.02253[0m[0m | time: 211.869s
[2K
| Adam | epoch: 026 | loss: 0.02253 - acc: 0.9962 | val_loss: 0.52277 - val_acc: 0.7733 -- iter: 239/239
--
Training Step: 209  | total loss: [1m[32m0.02047[0m[0m | time: 17.183s
[2K
| Adam | epoch: 027 | loss: 0.02047 - acc: 0.9966 -- iter: 032/239
[A[ATraining Step: 210  | total loss: [1m[32m0.01858[0m[0m | time: 50.714s
[2K
| Adam | epoch: 027 | loss: 0.01858 - acc: 0.9969 -- iter: 064/239
[A[ATraining Step: 211  | total loss: [1m[32m0.03148[0m[0m | time: 67.950s
[2K
| Adam | epoch: 027 | loss: 0.03148 - acc: 0.9941 -- iter: 096/239
[A[ATraining Step: 212  | total loss: [1m[32m0.02876[0m[0m | time: 81.800s
[2K
| Adam | epoch: 027 | loss: 0.02876 - acc: 0.9947 -- iter: 128/239
[A[ATraining Step: 213  | total loss: [1m[32m0.02598[0m[0m | time: 92.872s
[2K
| Adam | epoch: 027 | loss: 0.02598 - acc: 0.9952 -- iter: 160/239
[A[ATraining Step: 214  | total loss: [1m[32m0.03237[0m[0m | time: 104.526s
[2K
| Adam | epoch: 027 | loss: 0.03237 - acc: 0.9926 -- iter: 192/239
[A[ATraining Step: 215  | total loss: [1m[32m0.03256[0m[0m | time: 118.103s
[2K
| Adam | epoch: 027 | loss: 0.03256 - acc: 0.9933 -- iter: 224/239
[A[ATraining Step: 216  | total loss: [1m[32m0.02936[0m[0m | time: 163.382s
[2K
| Adam | epoch: 027 | loss: 0.02936 - acc: 0.9940 | val_loss: 0.11428 - val_acc: 0.9733 -- iter: 239/239
--
Training Step: 217  | total loss: [1m[32m0.02651[0m[0m | time: 20.417s
[2K
| Adam | epoch: 028 | loss: 0.02651 - acc: 0.9946 -- iter: 032/239
[A[ATraining Step: 218  | total loss: [1m[32m0.02432[0m[0m | time: 37.670s
[2K
| Adam | epoch: 028 | loss: 0.02432 - acc: 0.9951 -- iter: 064/239
[A[ATraining Step: 219  | total loss: [1m[32m0.02207[0m[0m | time: 70.987s
[2K
| Adam | epoch: 028 | loss: 0.02207 - acc: 0.9956 -- iter: 096/239
[A[ATraining Step: 220  | total loss: [1m[32m0.03954[0m[0m | time: 135.603s
[2K
| Adam | epoch: 028 | loss: 0.03954 - acc: 0.9929 -- iter: 128/239
[A[ATraining Step: 221  | total loss: [1m[32m0.03577[0m[0m | time: 173.722s
[2K
| Adam | epoch: 028 | loss: 0.03577 - acc: 0.9936 -- iter: 160/239
[A[ATraining Step: 222  | total loss: [1m[32m0.03230[0m[0m | time: 226.736s
[2K
| Adam | epoch: 028 | loss: 0.03230 - acc: 0.9943 -- iter: 192/239
[A[ATraining Step: 223  | total loss: [1m[32m0.02940[0m[0m | time: 278.263s
[2K
| Adam | epoch: 028 | loss: 0.02940 - acc: 0.9948 -- iter: 224/239
[A[ATraining Step: 224  | total loss: [1m[32m0.02679[0m[0m | time: 296.789s
[2K
| Adam | epoch: 028 | loss: 0.02679 - acc: 0.9954 | val_loss: 0.15218 - val_acc: 0.9333 -- iter: 239/239
--
Training Step: 225  | total loss: [1m[32m0.03109[0m[0m | time: 13.175s
[2K
| Adam | epoch: 029 | loss: 0.03109 - acc: 0.9892 -- iter: 032/239
[A[ATraining Step: 226  | total loss: [1m[32m0.02835[0m[0m | time: 37.810s
[2K
| Adam | epoch: 029 | loss: 0.02835 - acc: 0.9902 -- iter: 064/239
[A[ATraining Step: 227  | total loss: [1m[32m0.02570[0m[0m | time: 55.378s
[2K
| Adam | epoch: 029 | loss: 0.02570 - acc: 0.9912 -- iter: 096/239
[A[ATraining Step: 228  | total loss: [1m[32m0.02397[0m[0m | time: 79.713s
[2K
| Adam | epoch: 029 | loss: 0.02397 - acc: 0.9921 -- iter: 128/239
[A[ATraining Step: 229  | total loss: [1m[32m0.02190[0m[0m | time: 97.802s
[2K
| Adam | epoch: 029 | loss: 0.02190 - acc: 0.9929 -- iter: 160/239
[A[ATraining Step: 230  | total loss: [1m[32m0.02171[0m[0m | time: 126.219s
[2K
| Adam | epoch: 029 | loss: 0.02171 - acc: 0.9936 -- iter: 192/239
[A[ATraining Step: 231  | total loss: [1m[32m0.02055[0m[0m | time: 143.066s
[2K
| Adam | epoch: 029 | loss: 0.02055 - acc: 0.9942 -- iter: 224/239
[A[ATraining Step: 232  | total loss: [1m[32m0.01940[0m[0m | time: 177.467s
[2K
| Adam | epoch: 029 | loss: 0.01940 - acc: 0.9948 | val_loss: 0.19341 - val_acc: 0.9200 -- iter: 239/239
--
Training Step: 233  | total loss: [1m[32m0.01920[0m[0m | time: 10.819s
[2K
| Adam | epoch: 030 | loss: 0.01920 - acc: 0.9953 -- iter: 032/239
[A[ATraining Step: 234  | total loss: [1m[32m0.01946[0m[0m | time: 19.699s
[2K
| Adam | epoch: 030 | loss: 0.01946 - acc: 0.9958 -- iter: 064/239
[A[ATraining Step: 235  | total loss: [1m[32m0.01852[0m[0m | time: 62.393s
[2K
| Adam | epoch: 030 | loss: 0.01852 - acc: 0.9962 -- iter: 096/239
[A[ATraining Step: 236  | total loss: [1m[32m0.02675[0m[0m | time: 84.680s
[2K
| Adam | epoch: 030 | loss: 0.02675 - acc: 0.9935 -- iter: 128/239
[A[ATraining Step: 237  | total loss: [1m[32m0.02526[0m[0m | time: 121.403s
[2K
| Adam | epoch: 030 | loss: 0.02526 - acc: 0.9941 -- iter: 160/239
[A[ATraining Step: 238  | total loss: [1m[32m0.21921[0m[0m | time: 160.101s
[2K
| Adam | epoch: 030 | loss: 0.21921 - acc: 0.9666 -- iter: 192/239
[A[ATraining Step: 239  | total loss: [1m[32m0.19766[0m[0m | time: 218.858s
[2K
| Adam | epoch: 030 | loss: 0.19766 - acc: 0.9699 -- iter: 224/239
[A[ATraining Step: 240  | total loss: [1m[32m0.17866[0m[0m | time: 285.985s
[2K
| Adam | epoch: 030 | loss: 0.17866 - acc: 0.9729 | val_loss: 0.11837 - val_acc: 0.9600 -- iter: 239/239
--
Validation AUC:0.9914285714285713
Validation AUPRC:0.9890035058480741
Test AUC:0.9519368723098995
Test AUPRC:0.884394813104147
BestTestF1Score	0.92	0.85	0.92	0.87	0.97	33	5	36	1	0.12
BestTestMCCScore	0.92	0.85	0.92	0.87	0.97	33	5	36	1	0.12
BestTestAccuracyScore	0.93	0.87	0.93	0.91	0.94	32	3	38	2	0.62
BestValidationF1Score	0.97	0.95	0.97	0.95	1.0	35	2	38	0	0.12
BestValidationMCC	0.97	0.95	0.97	0.95	1.0	35	2	38	0	0.12
BestValidationAccuracy	0.97	0.95	0.97	0.97	0.97	34	1	39	1	0.62
TestPredictions (Threshold:0.12)
CHEMBL3127099,TN,INACT,0.0	CHEMBL165448,TP,ACT,0.949999988079071	CHEMBL109380,TP,ACT,1.0	CHEMBL299252,TP,ACT,0.9800000190734863	CHEMBL1791099,TP,ACT,0.9599999785423279	CHEMBL31550,TP,ACT,0.9599999785423279	CHEMBL29103,TP,ACT,0.8799999952316284	CHEMBL3688762,TN,INACT,0.0	CHEMBL164716,TP,ACT,0.9700000286102295	CHEMBL566415,TN,INACT,0.0	CHEMBL399656,TN,INACT,0.0	CHEMBL3763900,TN,INACT,0.0	CHEMBL500555,TN,INACT,0.019999999552965164	CHEMBL2177322,TN,INACT,0.0	CHEMBL1824352,TN,INACT,0.0	CHEMBL3354251,FP,INACT,0.17000000178813934	CHEMBL23793,TP,ACT,0.8899999856948853	CHEMBL143902,TP,ACT,0.5699999928474426	CHEMBL562554,TN,INACT,0.0	CHEMBL3688803,TN,INACT,0.009999999776482582	CHEMBL3688649,TN,INACT,0.03999999910593033	CHEMBL43185,TN,INACT,0.009999999776482582	CHEMBL111515,TP,ACT,1.0	CHEMBL3764744,TN,INACT,0.009999999776482582	CHEMBL1824134,TN,INACT,0.0	CHEMBL3688802,TN,INACT,0.009999999776482582	CHEMBL582044,TN,INACT,0.0	CHEMBL3422235,TN,INACT,0.0	CHEMBL31268,TP,ACT,0.9399999976158142	CHEMBL2112265,TP,ACT,0.9800000190734863	CHEMBL2112256,TP,ACT,0.9399999976158142	CHEMBL81652,TP,ACT,0.9800000190734863	CHEMBL1941005,TN,INACT,0.0	CHEMBL584509,TN,INACT,0.0	CHEMBL1092227,TN,INACT,0.0	CHEMBL405227,FN,ACT,0.05000000074505806	CHEMBL1271451,TN,INACT,0.0	CHEMBL2177314,TN,INACT,0.0	CHEMBL3124962,TN,INACT,0.0	CHEMBL441325,TP,ACT,0.8600000143051147	CHEMBL598876,TN,INACT,0.0	CHEMBL1824137,TN,INACT,0.009999999776482582	CHEMBL287423,TP,ACT,1.0	CHEMBL324213,TP,ACT,1.0	CHEMBL3353636,TN,INACT,0.019999999552965164	CHEMBL32239,TP,ACT,0.9599999785423279	CHEMBL141337,TP,ACT,1.0	CHEMBL2177332,TN,INACT,0.0	CHEMBL427798,FP,INACT,1.0	CHEMBL276553,TP,ACT,0.9900000095367432	CHEMBL2112257,TP,ACT,1.0	CHEMBL597277,TN,INACT,0.009999999776482582	CHEMBL3586132,TN,INACT,0.0	CHEMBL362209,TP,ACT,1.0	CHEMBL3344272,FP,INACT,0.7400000095367432	CHEMBL2112268,TP,ACT,0.949999988079071	CHEMBL3354262,TN,INACT,0.009999999776482582	CHEMBL315380,FP,INACT,1.0	CHEMBL382977,TP,ACT,0.9800000190734863	CHEMBL262137,TP,ACT,0.9900000095367432	CHEMBL58153,TP,ACT,0.9900000095367432	CHEMBL29041,TP,ACT,0.949999988079071	CHEMBL343681,TP,ACT,0.6299999952316284	CHEMBL3142506,TP,ACT,0.9700000286102295	CHEMBL2349610,TN,INACT,0.0	CHEMBL1824349,TN,INACT,0.0	CHEMBL2112266,TP,ACT,0.8299999833106995	CHEMBL2112252,TP,ACT,1.0	CHEMBL1210334,TN,INACT,0.0	CHEMBL1092475,TN,INACT,0.0	CHEMBL252861,TN,INACT,0.0	CHEMBL314065,FP,INACT,0.5799999833106995	CHEMBL1941015,TN,INACT,0.0	CHEMBL3392091,TP,ACT,0.75	CHEMBL3142505,TP,ACT,0.9900000095367432	

