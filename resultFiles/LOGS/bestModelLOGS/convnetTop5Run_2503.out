CNNModel CHEMBL5652 adam 0.0005 15 128 0 0.6 False True
Number of active compounds :	318
Number of inactive compounds :	318
---------------------------------
Run id: CNNModel_CHEMBL5652_adam_0.0005_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5652_adam_0.0005_15_128_0.6_True/
---------------------------------
Training samples: 399
Validation samples: 125
--
Training Step: 1  | time: 0.973s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/399
[A[ATraining Step: 2  | total loss: [1m[32m0.62387[0m[0m | time: 1.716s
[2K
| Adam | epoch: 001 | loss: 0.62387 - acc: 0.4219 -- iter: 064/399
[A[ATraining Step: 3  | total loss: [1m[32m0.68160[0m[0m | time: 2.412s
[2K
| Adam | epoch: 001 | loss: 0.68160 - acc: 0.4347 -- iter: 096/399
[A[ATraining Step: 4  | total loss: [1m[32m0.69029[0m[0m | time: 3.028s
[2K
| Adam | epoch: 001 | loss: 0.69029 - acc: 0.5071 -- iter: 128/399
[A[ATraining Step: 5  | total loss: [1m[32m0.69207[0m[0m | time: 3.659s
[2K
| Adam | epoch: 001 | loss: 0.69207 - acc: 0.5238 -- iter: 160/399
[A[ATraining Step: 6  | total loss: [1m[32m0.69336[0m[0m | time: 4.277s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4683 -- iter: 192/399
[A[ATraining Step: 7  | total loss: [1m[32m0.69253[0m[0m | time: 4.889s
[2K
| Adam | epoch: 001 | loss: 0.69253 - acc: 0.5436 -- iter: 224/399
[A[ATraining Step: 8  | total loss: [1m[32m0.69370[0m[0m | time: 5.505s
[2K
| Adam | epoch: 001 | loss: 0.69370 - acc: 0.4663 -- iter: 256/399
[A[ATraining Step: 9  | total loss: [1m[32m0.69365[0m[0m | time: 6.119s
[2K
| Adam | epoch: 001 | loss: 0.69365 - acc: 0.4676 -- iter: 288/399
[A[ATraining Step: 10  | total loss: [1m[32m0.69317[0m[0m | time: 6.835s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.4994 -- iter: 320/399
[A[ATraining Step: 11  | total loss: [1m[32m0.69287[0m[0m | time: 7.602s
[2K
| Adam | epoch: 001 | loss: 0.69287 - acc: 0.5293 -- iter: 352/399
[A[ATraining Step: 12  | total loss: [1m[32m0.69322[0m[0m | time: 8.356s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.4880 -- iter: 384/399
[A[ATraining Step: 13  | total loss: [1m[32m0.69332[0m[0m | time: 9.829s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.4797 | val_loss: 0.69314 - val_acc: 0.5040 -- iter: 399/399
--
Training Step: 14  | total loss: [1m[32m0.69392[0m[0m | time: 0.391s
[2K
| Adam | epoch: 002 | loss: 0.69392 - acc: 0.4198 -- iter: 032/399
[A[ATraining Step: 15  | total loss: [1m[32m0.69367[0m[0m | time: 1.142s
[2K
| Adam | epoch: 002 | loss: 0.69367 - acc: 0.4643 -- iter: 064/399
[A[ATraining Step: 16  | total loss: [1m[32m0.69343[0m[0m | time: 1.931s
[2K
| Adam | epoch: 002 | loss: 0.69343 - acc: 0.5011 -- iter: 096/399
[A[ATraining Step: 17  | total loss: [1m[32m0.69294[0m[0m | time: 2.671s
[2K
| Adam | epoch: 002 | loss: 0.69294 - acc: 0.5570 -- iter: 128/399
[A[ATraining Step: 18  | total loss: [1m[32m0.69300[0m[0m | time: 3.427s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5372 -- iter: 160/399
[A[ATraining Step: 19  | total loss: [1m[32m0.69288[0m[0m | time: 4.129s
[2K
| Adam | epoch: 002 | loss: 0.69288 - acc: 0.5352 -- iter: 192/399
[A[ATraining Step: 20  | total loss: [1m[32m0.69203[0m[0m | time: 4.750s
[2K
| Adam | epoch: 002 | loss: 0.69203 - acc: 0.5641 -- iter: 224/399
[A[ATraining Step: 21  | total loss: [1m[32m0.69333[0m[0m | time: 5.356s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.5151 -- iter: 256/399
[A[ATraining Step: 22  | total loss: [1m[32m0.69298[0m[0m | time: 5.976s
[2K
| Adam | epoch: 002 | loss: 0.69298 - acc: 0.5200 -- iter: 288/399
[A[ATraining Step: 23  | total loss: [1m[32m0.69579[0m[0m | time: 6.580s
[2K
| Adam | epoch: 002 | loss: 0.69579 - acc: 0.4507 -- iter: 320/399
[A[ATraining Step: 24  | total loss: [1m[32m0.69476[0m[0m | time: 7.195s
[2K
| Adam | epoch: 002 | loss: 0.69476 - acc: 0.4733 -- iter: 352/399
[A[ATraining Step: 25  | total loss: [1m[32m0.69456[0m[0m | time: 7.812s
[2K
| Adam | epoch: 002 | loss: 0.69456 - acc: 0.4721 -- iter: 384/399
[A[ATraining Step: 26  | total loss: [1m[32m0.69302[0m[0m | time: 9.524s
[2K
| Adam | epoch: 002 | loss: 0.69302 - acc: 0.5208 | val_loss: 0.69335 - val_acc: 0.4960 -- iter: 399/399
--
Training Step: 27  | total loss: [1m[32m0.69333[0m[0m | time: 0.305s
[2K
| Adam | epoch: 003 | loss: 0.69333 - acc: 0.5074 -- iter: 032/399
[A[ATraining Step: 28  | total loss: [1m[32m0.69395[0m[0m | time: 0.616s
[2K
| Adam | epoch: 003 | loss: 0.69395 - acc: 0.4806 -- iter: 064/399
[A[ATraining Step: 29  | total loss: [1m[32m0.69445[0m[0m | time: 1.229s
[2K
| Adam | epoch: 003 | loss: 0.69445 - acc: 0.4610 -- iter: 096/399
[A[ATraining Step: 30  | total loss: [1m[32m0.69447[0m[0m | time: 1.832s
[2K
| Adam | epoch: 003 | loss: 0.69447 - acc: 0.4554 -- iter: 128/399
[A[ATraining Step: 31  | total loss: [1m[32m0.69451[0m[0m | time: 2.440s
[2K
| Adam | epoch: 003 | loss: 0.69451 - acc: 0.4441 -- iter: 160/399
[A[ATraining Step: 32  | total loss: [1m[32m0.69397[0m[0m | time: 3.047s
[2K
| Adam | epoch: 003 | loss: 0.69397 - acc: 0.4777 -- iter: 192/399
[A[ATraining Step: 33  | total loss: [1m[32m0.69391[0m[0m | time: 3.670s
[2K
| Adam | epoch: 003 | loss: 0.69391 - acc: 0.4689 -- iter: 224/399
[A[ATraining Step: 34  | total loss: [1m[32m0.69379[0m[0m | time: 4.378s
[2K
| Adam | epoch: 003 | loss: 0.69379 - acc: 0.4689 -- iter: 256/399
[A[ATraining Step: 35  | total loss: [1m[32m0.69356[0m[0m | time: 5.130s
[2K
| Adam | epoch: 003 | loss: 0.69356 - acc: 0.4950 -- iter: 288/399
[A[ATraining Step: 36  | total loss: [1m[32m0.69333[0m[0m | time: 5.872s
[2K
| Adam | epoch: 003 | loss: 0.69333 - acc: 0.5216 -- iter: 320/399
[A[ATraining Step: 37  | total loss: [1m[32m0.69325[0m[0m | time: 6.581s
[2K
| Adam | epoch: 003 | loss: 0.69325 - acc: 0.5173 -- iter: 352/399
[A[ATraining Step: 38  | total loss: [1m[32m0.69337[0m[0m | time: 7.312s
[2K
| Adam | epoch: 003 | loss: 0.69337 - acc: 0.4956 -- iter: 384/399
[A[ATraining Step: 39  | total loss: [1m[32m0.69328[0m[0m | time: 8.967s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.5024 | val_loss: 0.69318 - val_acc: 0.4960 -- iter: 399/399
--
Training Step: 40  | total loss: [1m[32m0.69330[0m[0m | time: 0.696s
[2K
| Adam | epoch: 004 | loss: 0.69330 - acc: 0.4961 -- iter: 032/399
[A[ATraining Step: 41  | total loss: [1m[32m0.69326[0m[0m | time: 1.106s
[2K
| Adam | epoch: 004 | loss: 0.69326 - acc: 0.4968 -- iter: 064/399
[A[ATraining Step: 42  | total loss: [1m[32m0.69316[0m[0m | time: 1.420s
[2K
| Adam | epoch: 004 | loss: 0.69316 - acc: 0.5034 -- iter: 096/399
[A[ATraining Step: 43  | total loss: [1m[32m0.69310[0m[0m | time: 2.021s
[2K
| Adam | epoch: 004 | loss: 0.69310 - acc: 0.5087 -- iter: 128/399
[A[ATraining Step: 44  | total loss: [1m[32m0.69293[0m[0m | time: 2.615s
[2K
| Adam | epoch: 004 | loss: 0.69293 - acc: 0.5288 -- iter: 160/399
[A[ATraining Step: 45  | total loss: [1m[32m0.69308[0m[0m | time: 3.227s
[2K
| Adam | epoch: 004 | loss: 0.69308 - acc: 0.5133 -- iter: 192/399
[A[ATraining Step: 46  | total loss: [1m[32m0.69310[0m[0m | time: 3.868s
[2K
| Adam | epoch: 004 | loss: 0.69310 - acc: 0.5111 -- iter: 224/399
[A[ATraining Step: 47  | total loss: [1m[32m0.69317[0m[0m | time: 4.494s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5042 -- iter: 256/399
[A[ATraining Step: 48  | total loss: [1m[32m0.69276[0m[0m | time: 5.202s
[2K
| Adam | epoch: 004 | loss: 0.69276 - acc: 0.5386 -- iter: 288/399
[A[ATraining Step: 49  | total loss: [1m[32m0.69282[0m[0m | time: 5.979s
[2K
| Adam | epoch: 004 | loss: 0.69282 - acc: 0.5325 -- iter: 320/399
[A[ATraining Step: 50  | total loss: [1m[32m0.69281[0m[0m | time: 6.752s
[2K
| Adam | epoch: 004 | loss: 0.69281 - acc: 0.5323 -- iter: 352/399
[A[ATraining Step: 51  | total loss: [1m[32m0.69306[0m[0m | time: 7.509s
[2K
| Adam | epoch: 004 | loss: 0.69306 - acc: 0.5179 -- iter: 384/399
[A[ATraining Step: 52  | total loss: [1m[32m0.69284[0m[0m | time: 9.272s
[2K
| Adam | epoch: 004 | loss: 0.69284 - acc: 0.5293 | val_loss: 0.69327 - val_acc: 0.4960 -- iter: 399/399
--
Training Step: 53  | total loss: [1m[32m0.69346[0m[0m | time: 0.800s
[2K
| Adam | epoch: 005 | loss: 0.69346 - acc: 0.4973 -- iter: 032/399
[A[ATraining Step: 54  | total loss: [1m[32m0.69323[0m[0m | time: 1.552s
[2K
| Adam | epoch: 005 | loss: 0.69323 - acc: 0.5067 -- iter: 064/399
[A[ATraining Step: 55  | total loss: [1m[32m0.69304[0m[0m | time: 2.027s
[2K
| Adam | epoch: 005 | loss: 0.69304 - acc: 0.5147 -- iter: 096/399
[A[ATraining Step: 56  | total loss: [1m[32m0.69296[0m[0m | time: 2.409s
[2K
| Adam | epoch: 005 | loss: 0.69296 - acc: 0.5173 -- iter: 128/399
[A[ATraining Step: 57  | total loss: [1m[32m0.69287[0m[0m | time: 3.187s
[2K
| Adam | epoch: 005 | loss: 0.69287 - acc: 0.5195 -- iter: 160/399
[A[ATraining Step: 58  | total loss: [1m[32m0.69262[0m[0m | time: 3.918s
[2K
| Adam | epoch: 005 | loss: 0.69262 - acc: 0.5297 -- iter: 192/399
[A[ATraining Step: 59  | total loss: [1m[32m0.69293[0m[0m | time: 4.519s
[2K
| Adam | epoch: 005 | loss: 0.69293 - acc: 0.5173 -- iter: 224/399
[A[ATraining Step: 60  | total loss: [1m[32m0.69285[0m[0m | time: 5.155s
[2K
| Adam | epoch: 005 | loss: 0.69285 - acc: 0.5191 -- iter: 256/399
[A[ATraining Step: 61  | total loss: [1m[32m0.69267[0m[0m | time: 5.753s
[2K
| Adam | epoch: 005 | loss: 0.69267 - acc: 0.5248 -- iter: 288/399
[A[ATraining Step: 62  | total loss: [1m[32m0.69250[0m[0m | time: 6.360s
[2K
| Adam | epoch: 005 | loss: 0.69250 - acc: 0.5296 -- iter: 320/399
[A[ATraining Step: 63  | total loss: [1m[32m0.69245[0m[0m | time: 6.959s
[2K
| Adam | epoch: 005 | loss: 0.69245 - acc: 0.5298 -- iter: 352/399
[A[ATraining Step: 64  | total loss: [1m[32m0.69285[0m[0m | time: 7.564s
[2K
| Adam | epoch: 005 | loss: 0.69285 - acc: 0.5183 -- iter: 384/399
[A[ATraining Step: 65  | total loss: [1m[32m0.69321[0m[0m | time: 9.319s
[2K
| Adam | epoch: 005 | loss: 0.69321 - acc: 0.5083 | val_loss: 0.69339 - val_acc: 0.4960 -- iter: 399/399
--
Training Step: 66  | total loss: [1m[32m0.69296[0m[0m | time: 0.621s
[2K
| Adam | epoch: 006 | loss: 0.69296 - acc: 0.5149 -- iter: 032/399
[A[ATraining Step: 67  | total loss: [1m[32m0.69257[0m[0m | time: 1.226s
[2K
| Adam | epoch: 006 | loss: 0.69257 - acc: 0.5244 -- iter: 064/399
[A[ATraining Step: 68  | total loss: [1m[32m0.69253[0m[0m | time: 1.834s
[2K
| Adam | epoch: 006 | loss: 0.69253 - acc: 0.5252 -- iter: 096/399
[A[ATraining Step: 69  | total loss: [1m[32m0.69169[0m[0m | time: 2.139s
[2K
| Adam | epoch: 006 | loss: 0.69169 - acc: 0.5442 -- iter: 128/399
[A[ATraining Step: 70  | total loss: [1m[32m0.69091[0m[0m | time: 2.441s
[2K
| Adam | epoch: 006 | loss: 0.69091 - acc: 0.5583 -- iter: 160/399
[A[ATraining Step: 71  | total loss: [1m[32m0.69002[0m[0m | time: 3.043s
[2K
| Adam | epoch: 006 | loss: 0.69002 - acc: 0.5706 -- iter: 192/399
[A[ATraining Step: 72  | total loss: [1m[32m0.69267[0m[0m | time: 3.652s
[2K
| Adam | epoch: 006 | loss: 0.69267 - acc: 0.5381 -- iter: 224/399
[A[ATraining Step: 73  | total loss: [1m[32m0.69133[0m[0m | time: 4.265s
[2K
| Adam | epoch: 006 | loss: 0.69133 - acc: 0.5512 -- iter: 256/399
[A[ATraining Step: 74  | total loss: [1m[32m0.69285[0m[0m | time: 4.874s
[2K
| Adam | epoch: 006 | loss: 0.69285 - acc: 0.5319 -- iter: 288/399
[A[ATraining Step: 75  | total loss: [1m[32m0.69204[0m[0m | time: 5.495s
[2K
| Adam | epoch: 006 | loss: 0.69204 - acc: 0.5386 -- iter: 320/399
[A[ATraining Step: 76  | total loss: [1m[32m0.69253[0m[0m | time: 6.113s
[2K
| Adam | epoch: 006 | loss: 0.69253 - acc: 0.5311 -- iter: 352/399
[A[ATraining Step: 77  | total loss: [1m[32m0.69244[0m[0m | time: 6.720s
[2K
| Adam | epoch: 006 | loss: 0.69244 - acc: 0.5311 -- iter: 384/399
[A[ATraining Step: 78  | total loss: [1m[32m0.69404[0m[0m | time: 8.339s
[2K
| Adam | epoch: 006 | loss: 0.69404 - acc: 0.5115 | val_loss: 0.69383 - val_acc: 0.4960 -- iter: 399/399
--
Training Step: 79  | total loss: [1m[32m0.69452[0m[0m | time: 0.613s
[2K
| Adam | epoch: 007 | loss: 0.69452 - acc: 0.5039 -- iter: 032/399
[A[ATraining Step: 80  | total loss: [1m[32m0.69375[0m[0m | time: 1.218s
[2K
| Adam | epoch: 007 | loss: 0.69375 - acc: 0.5130 -- iter: 064/399
[A[ATraining Step: 81  | total loss: [1m[32m0.69331[0m[0m | time: 1.817s
[2K
| Adam | epoch: 007 | loss: 0.69331 - acc: 0.5180 -- iter: 096/399
[A[ATraining Step: 82  | total loss: [1m[32m0.69332[0m[0m | time: 2.415s
[2K
| Adam | epoch: 007 | loss: 0.69332 - acc: 0.5162 -- iter: 128/399
[A[ATraining Step: 83  | total loss: [1m[32m0.69463[0m[0m | time: 2.721s
[2K
| Adam | epoch: 007 | loss: 0.69463 - acc: 0.4927 -- iter: 160/399
[A[ATraining Step: 84  | total loss: [1m[32m0.69363[0m[0m | time: 3.038s
[2K
| Adam | epoch: 007 | loss: 0.69363 - acc: 0.5101 -- iter: 192/399
[A[ATraining Step: 85  | total loss: [1m[32m0.69274[0m[0m | time: 3.670s
[2K
| Adam | epoch: 007 | loss: 0.69274 - acc: 0.5258 -- iter: 224/399
[A[ATraining Step: 86  | total loss: [1m[32m0.69262[0m[0m | time: 4.272s
[2K
| Adam | epoch: 007 | loss: 0.69262 - acc: 0.5263 -- iter: 256/399
[A[ATraining Step: 87  | total loss: [1m[32m0.69252[0m[0m | time: 4.868s
[2K
| Adam | epoch: 007 | loss: 0.69252 - acc: 0.5268 -- iter: 288/399
[A[ATraining Step: 88  | total loss: [1m[32m0.69274[0m[0m | time: 5.476s
[2K
| Adam | epoch: 007 | loss: 0.69274 - acc: 0.5210 -- iter: 320/399
[A[ATraining Step: 89  | total loss: [1m[32m0.69259[0m[0m | time: 6.078s
[2K
| Adam | epoch: 007 | loss: 0.69259 - acc: 0.5220 -- iter: 352/399
[A[ATraining Step: 90  | total loss: [1m[32m0.69246[0m[0m | time: 6.716s
[2K
| Adam | epoch: 007 | loss: 0.69246 - acc: 0.5230 -- iter: 384/399
[A[ATraining Step: 91  | total loss: [1m[32m0.69301[0m[0m | time: 8.341s
[2K
| Adam | epoch: 007 | loss: 0.69301 - acc: 0.5113 | val_loss: 0.69329 - val_acc: 0.4960 -- iter: 399/399
--
Training Step: 92  | total loss: [1m[32m0.69304[0m[0m | time: 0.611s
[2K
| Adam | epoch: 008 | loss: 0.69304 - acc: 0.5102 -- iter: 032/399
[A[ATraining Step: 93  | total loss: [1m[32m0.69238[0m[0m | time: 1.204s
[2K
| Adam | epoch: 008 | loss: 0.69238 - acc: 0.5216 -- iter: 064/399
[A[ATraining Step: 94  | total loss: [1m[32m0.69223[0m[0m | time: 1.822s
[2K
| Adam | epoch: 008 | loss: 0.69223 - acc: 0.5226 -- iter: 096/399
[A[ATraining Step: 95  | total loss: [1m[32m0.69216[0m[0m | time: 2.425s
[2K
| Adam | epoch: 008 | loss: 0.69216 - acc: 0.5235 -- iter: 128/399
[A[ATraining Step: 96  | total loss: [1m[32m0.69217[0m[0m | time: 3.023s
[2K
| Adam | epoch: 008 | loss: 0.69217 - acc: 0.5211 -- iter: 160/399
[A[ATraining Step: 97  | total loss: [1m[32m0.69223[0m[0m | time: 3.329s
[2K
| Adam | epoch: 008 | loss: 0.69223 - acc: 0.5190 -- iter: 192/399
[A[ATraining Step: 98  | total loss: [1m[32m0.69199[0m[0m | time: 3.631s
[2K
| Adam | epoch: 008 | loss: 0.69199 - acc: 0.5204 -- iter: 224/399
[A[ATraining Step: 99  | total loss: [1m[32m0.69173[0m[0m | time: 4.239s
[2K
| Adam | epoch: 008 | loss: 0.69173 - acc: 0.5217 -- iter: 256/399
[A[ATraining Step: 100  | total loss: [1m[32m0.69175[0m[0m | time: 4.840s
[2K
| Adam | epoch: 008 | loss: 0.69175 - acc: 0.5196 -- iter: 288/399
[A[ATraining Step: 101  | total loss: [1m[32m0.69221[0m[0m | time: 5.455s
[2K
| Adam | epoch: 008 | loss: 0.69221 - acc: 0.5114 -- iter: 320/399
[A[ATraining Step: 102  | total loss: [1m[32m0.69169[0m[0m | time: 6.077s
[2K
| Adam | epoch: 008 | loss: 0.69169 - acc: 0.5165 -- iter: 352/399
[A[ATraining Step: 103  | total loss: [1m[32m0.69083[0m[0m | time: 6.702s
[2K
| Adam | epoch: 008 | loss: 0.69083 - acc: 0.5242 -- iter: 384/399
[A[ATraining Step: 104  | total loss: [1m[32m0.69052[0m[0m | time: 8.304s
[2K
| Adam | epoch: 008 | loss: 0.69052 - acc: 0.5249 | val_loss: 0.69150 - val_acc: 0.4960 -- iter: 399/399
--
Training Step: 105  | total loss: [1m[32m0.68999[0m[0m | time: 0.602s
[2K
| Adam | epoch: 009 | loss: 0.68999 - acc: 0.5287 -- iter: 032/399
[A[ATraining Step: 106  | total loss: [1m[32m0.68971[0m[0m | time: 1.210s
[2K
| Adam | epoch: 009 | loss: 0.68971 - acc: 0.5258 -- iter: 064/399
[A[ATraining Step: 107  | total loss: [1m[32m0.69089[0m[0m | time: 1.827s
[2K
| Adam | epoch: 009 | loss: 0.69089 - acc: 0.5107 -- iter: 096/399
[A[ATraining Step: 108  | total loss: [1m[32m0.69001[0m[0m | time: 2.437s
[2K
| Adam | epoch: 009 | loss: 0.69001 - acc: 0.5128 -- iter: 128/399
[A[ATraining Step: 109  | total loss: [1m[32m0.69014[0m[0m | time: 3.054s
[2K
| Adam | epoch: 009 | loss: 0.69014 - acc: 0.5115 -- iter: 160/399
[A[ATraining Step: 110  | total loss: [1m[32m0.68849[0m[0m | time: 3.654s
[2K
| Adam | epoch: 009 | loss: 0.68849 - acc: 0.5385 -- iter: 192/399
[A[ATraining Step: 111  | total loss: [1m[32m0.68743[0m[0m | time: 3.960s
[2K
| Adam | epoch: 009 | loss: 0.68743 - acc: 0.5346 -- iter: 224/399
[A[ATraining Step: 112  | total loss: [1m[32m0.68359[0m[0m | time: 4.260s
[2K
| Adam | epoch: 009 | loss: 0.68359 - acc: 0.5478 -- iter: 256/399
[A[ATraining Step: 113  | total loss: [1m[32m0.67902[0m[0m | time: 4.864s
[2K
| Adam | epoch: 009 | loss: 0.67902 - acc: 0.5530 -- iter: 288/399
[A[ATraining Step: 114  | total loss: [1m[32m0.68204[0m[0m | time: 5.461s
[2K
| Adam | epoch: 009 | loss: 0.68204 - acc: 0.5477 -- iter: 320/399
[A[ATraining Step: 115  | total loss: [1m[32m0.67602[0m[0m | time: 6.062s
[2K
| Adam | epoch: 009 | loss: 0.67602 - acc: 0.5586 -- iter: 352/399
[A[ATraining Step: 116  | total loss: [1m[32m0.66973[0m[0m | time: 6.661s
[2K
| Adam | epoch: 009 | loss: 0.66973 - acc: 0.5840 -- iter: 384/399
[A[ATraining Step: 117  | total loss: [1m[32m0.66415[0m[0m | time: 8.270s
[2K
| Adam | epoch: 009 | loss: 0.66415 - acc: 0.6006 | val_loss: 0.66179 - val_acc: 0.6320 -- iter: 399/399
--
Training Step: 118  | total loss: [1m[32m0.67463[0m[0m | time: 0.627s
[2K
| Adam | epoch: 010 | loss: 0.67463 - acc: 0.5811 -- iter: 032/399
[A[ATraining Step: 119  | total loss: [1m[32m0.67034[0m[0m | time: 1.251s
[2K
| Adam | epoch: 010 | loss: 0.67034 - acc: 0.5949 -- iter: 064/399
[A[ATraining Step: 120  | total loss: [1m[32m0.66579[0m[0m | time: 1.850s
[2K
| Adam | epoch: 010 | loss: 0.66579 - acc: 0.5979 -- iter: 096/399
[A[ATraining Step: 121  | total loss: [1m[32m0.67295[0m[0m | time: 2.450s
[2K
| Adam | epoch: 010 | loss: 0.67295 - acc: 0.5850 -- iter: 128/399
[A[ATraining Step: 122  | total loss: [1m[32m0.66824[0m[0m | time: 3.046s
[2K
| Adam | epoch: 010 | loss: 0.66824 - acc: 0.5953 -- iter: 160/399
[A[ATraining Step: 123  | total loss: [1m[32m0.66385[0m[0m | time: 3.650s
[2K
| Adam | epoch: 010 | loss: 0.66385 - acc: 0.6045 -- iter: 192/399
[A[ATraining Step: 124  | total loss: [1m[32m0.65963[0m[0m | time: 4.277s
[2K
| Adam | epoch: 010 | loss: 0.65963 - acc: 0.6159 -- iter: 224/399
[A[ATraining Step: 125  | total loss: [1m[32m0.65985[0m[0m | time: 4.622s
[2K
| Adam | epoch: 010 | loss: 0.65985 - acc: 0.6137 -- iter: 256/399
[A[ATraining Step: 126  | total loss: [1m[32m0.65793[0m[0m | time: 4.929s
[2K
| Adam | epoch: 010 | loss: 0.65793 - acc: 0.6257 -- iter: 288/399
[A[ATraining Step: 127  | total loss: [1m[32m0.65426[0m[0m | time: 5.540s
[2K
| Adam | epoch: 010 | loss: 0.65426 - acc: 0.6364 -- iter: 320/399
[A[ATraining Step: 128  | total loss: [1m[32m0.65046[0m[0m | time: 6.156s
[2K
| Adam | epoch: 010 | loss: 0.65046 - acc: 0.6384 -- iter: 352/399
[A[ATraining Step: 129  | total loss: [1m[32m0.64664[0m[0m | time: 6.757s
[2K
| Adam | epoch: 010 | loss: 0.64664 - acc: 0.6433 -- iter: 384/399
[A[ATraining Step: 130  | total loss: [1m[32m0.65275[0m[0m | time: 8.403s
[2K
| Adam | epoch: 010 | loss: 0.65275 - acc: 0.6321 | val_loss: 0.66426 - val_acc: 0.6160 -- iter: 399/399
--
Training Step: 131  | total loss: [1m[32m0.64592[0m[0m | time: 0.643s
[2K
| Adam | epoch: 011 | loss: 0.64592 - acc: 0.6345 -- iter: 032/399
[A[ATraining Step: 132  | total loss: [1m[32m0.63754[0m[0m | time: 1.278s
[2K
| Adam | epoch: 011 | loss: 0.63754 - acc: 0.6429 -- iter: 064/399
[A[ATraining Step: 133  | total loss: [1m[32m0.62326[0m[0m | time: 1.877s
[2K
| Adam | epoch: 011 | loss: 0.62326 - acc: 0.6599 -- iter: 096/399
[A[ATraining Step: 134  | total loss: [1m[32m0.63762[0m[0m | time: 2.489s
[2K
| Adam | epoch: 011 | loss: 0.63762 - acc: 0.6502 -- iter: 128/399
[A[ATraining Step: 135  | total loss: [1m[32m0.62753[0m[0m | time: 3.077s
[2K
| Adam | epoch: 011 | loss: 0.62753 - acc: 0.6664 -- iter: 160/399
[A[ATraining Step: 136  | total loss: [1m[32m0.61432[0m[0m | time: 3.682s
[2K
| Adam | epoch: 011 | loss: 0.61432 - acc: 0.6841 -- iter: 192/399
[A[ATraining Step: 137  | total loss: [1m[32m0.61689[0m[0m | time: 4.279s
[2K
| Adam | epoch: 011 | loss: 0.61689 - acc: 0.6782 -- iter: 224/399
[A[ATraining Step: 138  | total loss: [1m[32m0.61230[0m[0m | time: 4.871s
[2K
| Adam | epoch: 011 | loss: 0.61230 - acc: 0.6823 -- iter: 256/399
[A[ATraining Step: 139  | total loss: [1m[32m0.60874[0m[0m | time: 5.177s
[2K
| Adam | epoch: 011 | loss: 0.60874 - acc: 0.6890 -- iter: 288/399
[A[ATraining Step: 140  | total loss: [1m[32m0.60849[0m[0m | time: 5.503s
[2K
| Adam | epoch: 011 | loss: 0.60849 - acc: 0.6868 -- iter: 320/399
[A[ATraining Step: 141  | total loss: [1m[32m0.60581[0m[0m | time: 6.134s
[2K
| Adam | epoch: 011 | loss: 0.60581 - acc: 0.6848 -- iter: 352/399
[A[ATraining Step: 142  | total loss: [1m[32m0.58915[0m[0m | time: 6.743s
[2K
| Adam | epoch: 011 | loss: 0.58915 - acc: 0.7038 -- iter: 384/399
[A[ATraining Step: 143  | total loss: [1m[32m0.57725[0m[0m | time: 8.368s
[2K
| Adam | epoch: 011 | loss: 0.57725 - acc: 0.7147 | val_loss: 0.57355 - val_acc: 0.7840 -- iter: 399/399
--
Training Step: 144  | total loss: [1m[32m0.55802[0m[0m | time: 0.610s
[2K
| Adam | epoch: 012 | loss: 0.55802 - acc: 0.7338 -- iter: 032/399
[A[ATraining Step: 145  | total loss: [1m[32m0.55220[0m[0m | time: 1.214s
[2K
| Adam | epoch: 012 | loss: 0.55220 - acc: 0.7417 -- iter: 064/399
[A[ATraining Step: 146  | total loss: [1m[32m0.53970[0m[0m | time: 1.816s
[2K
| Adam | epoch: 012 | loss: 0.53970 - acc: 0.7488 -- iter: 096/399
[A[ATraining Step: 147  | total loss: [1m[32m0.53304[0m[0m | time: 2.419s
[2K
| Adam | epoch: 012 | loss: 0.53304 - acc: 0.7489 -- iter: 128/399
[A[ATraining Step: 148  | total loss: [1m[32m0.53857[0m[0m | time: 3.028s
[2K
| Adam | epoch: 012 | loss: 0.53857 - acc: 0.7459 -- iter: 160/399
[A[ATraining Step: 149  | total loss: [1m[32m0.54030[0m[0m | time: 3.633s
[2K
| Adam | epoch: 012 | loss: 0.54030 - acc: 0.7401 -- iter: 192/399
[A[ATraining Step: 150  | total loss: [1m[32m0.53144[0m[0m | time: 4.237s
[2K
| Adam | epoch: 012 | loss: 0.53144 - acc: 0.7442 -- iter: 224/399
[A[ATraining Step: 151  | total loss: [1m[32m0.53736[0m[0m | time: 4.845s
[2K
| Adam | epoch: 012 | loss: 0.53736 - acc: 0.7354 -- iter: 256/399
[A[ATraining Step: 152  | total loss: [1m[32m0.52126[0m[0m | time: 5.450s
[2K
| Adam | epoch: 012 | loss: 0.52126 - acc: 0.7493 -- iter: 288/399
[A[ATraining Step: 153  | total loss: [1m[32m0.51620[0m[0m | time: 5.772s
[2K
| Adam | epoch: 012 | loss: 0.51620 - acc: 0.7557 -- iter: 320/399
[A[ATraining Step: 154  | total loss: [1m[32m0.49749[0m[0m | time: 6.068s
[2K
| Adam | epoch: 012 | loss: 0.49749 - acc: 0.7668 -- iter: 352/399
[A[ATraining Step: 155  | total loss: [1m[32m0.47923[0m[0m | time: 6.680s
[2K
| Adam | epoch: 012 | loss: 0.47923 - acc: 0.7767 -- iter: 384/399
[A[ATraining Step: 156  | total loss: [1m[32m0.47109[0m[0m | time: 8.284s
[2K
| Adam | epoch: 012 | loss: 0.47109 - acc: 0.7834 | val_loss: 0.48490 - val_acc: 0.8160 -- iter: 399/399
--
Training Step: 157  | total loss: [1m[32m0.46633[0m[0m | time: 0.604s
[2K
| Adam | epoch: 013 | loss: 0.46633 - acc: 0.7864 -- iter: 032/399
[A[ATraining Step: 158  | total loss: [1m[32m0.45615[0m[0m | time: 1.194s
[2K
| Adam | epoch: 013 | loss: 0.45615 - acc: 0.8015 -- iter: 064/399
[A[ATraining Step: 159  | total loss: [1m[32m0.44975[0m[0m | time: 1.804s
[2K
| Adam | epoch: 013 | loss: 0.44975 - acc: 0.8088 -- iter: 096/399
[A[ATraining Step: 160  | total loss: [1m[32m0.43077[0m[0m | time: 2.407s
[2K
| Adam | epoch: 013 | loss: 0.43077 - acc: 0.8186 -- iter: 128/399
[A[ATraining Step: 161  | total loss: [1m[32m0.42875[0m[0m | time: 3.018s
[2K
| Adam | epoch: 013 | loss: 0.42875 - acc: 0.8086 -- iter: 160/399
[A[ATraining Step: 162  | total loss: [1m[32m0.43477[0m[0m | time: 3.623s
[2K
| Adam | epoch: 013 | loss: 0.43477 - acc: 0.7996 -- iter: 192/399
[A[ATraining Step: 163  | total loss: [1m[32m0.42885[0m[0m | time: 4.221s
[2K
| Adam | epoch: 013 | loss: 0.42885 - acc: 0.8009 -- iter: 224/399
[A[ATraining Step: 164  | total loss: [1m[32m0.43004[0m[0m | time: 4.845s
[2K
| Adam | epoch: 013 | loss: 0.43004 - acc: 0.7958 -- iter: 256/399
[A[ATraining Step: 165  | total loss: [1m[32m0.41470[0m[0m | time: 5.445s
[2K
| Adam | epoch: 013 | loss: 0.41470 - acc: 0.8131 -- iter: 288/399
[A[ATraining Step: 166  | total loss: [1m[32m0.39883[0m[0m | time: 6.060s
[2K
| Adam | epoch: 013 | loss: 0.39883 - acc: 0.8255 -- iter: 320/399
[A[ATraining Step: 167  | total loss: [1m[32m0.38671[0m[0m | time: 6.367s
[2K
| Adam | epoch: 013 | loss: 0.38671 - acc: 0.8305 -- iter: 352/399
[A[ATraining Step: 168  | total loss: [1m[32m0.39255[0m[0m | time: 6.688s
[2K
| Adam | epoch: 013 | loss: 0.39255 - acc: 0.8274 -- iter: 384/399
[A[ATraining Step: 169  | total loss: [1m[32m0.39193[0m[0m | time: 8.294s
[2K
| Adam | epoch: 013 | loss: 0.39193 - acc: 0.8314 | val_loss: 0.44966 - val_acc: 0.7600 -- iter: 399/399
--
Training Step: 170  | total loss: [1m[32m0.38566[0m[0m | time: 0.611s
[2K
| Adam | epoch: 014 | loss: 0.38566 - acc: 0.8326 -- iter: 032/399
[A[ATraining Step: 171  | total loss: [1m[32m0.39795[0m[0m | time: 1.201s
[2K
| Adam | epoch: 014 | loss: 0.39795 - acc: 0.8243 -- iter: 064/399
[A[ATraining Step: 172  | total loss: [1m[32m0.40047[0m[0m | time: 1.795s
[2K
| Adam | epoch: 014 | loss: 0.40047 - acc: 0.8232 -- iter: 096/399
[A[ATraining Step: 173  | total loss: [1m[32m0.37907[0m[0m | time: 2.400s
[2K
| Adam | epoch: 014 | loss: 0.37907 - acc: 0.8346 -- iter: 128/399
[A[ATraining Step: 174  | total loss: [1m[32m0.37024[0m[0m | time: 3.014s
[2K
| Adam | epoch: 014 | loss: 0.37024 - acc: 0.8355 -- iter: 160/399
[A[ATraining Step: 175  | total loss: [1m[32m0.34898[0m[0m | time: 3.629s
[2K
| Adam | epoch: 014 | loss: 0.34898 - acc: 0.8488 -- iter: 192/399
[A[ATraining Step: 176  | total loss: [1m[32m0.36813[0m[0m | time: 4.223s
[2K
| Adam | epoch: 014 | loss: 0.36813 - acc: 0.8327 -- iter: 224/399
[A[ATraining Step: 177  | total loss: [1m[32m0.37509[0m[0m | time: 4.833s
[2K
| Adam | epoch: 014 | loss: 0.37509 - acc: 0.8276 -- iter: 256/399
[A[ATraining Step: 178  | total loss: [1m[32m0.35033[0m[0m | time: 5.493s
[2K
| Adam | epoch: 014 | loss: 0.35033 - acc: 0.8417 -- iter: 288/399
[A[ATraining Step: 179  | total loss: [1m[32m0.32396[0m[0m | time: 6.109s
[2K
| Adam | epoch: 014 | loss: 0.32396 - acc: 0.8544 -- iter: 320/399
[A[ATraining Step: 180  | total loss: [1m[32m0.32027[0m[0m | time: 6.733s
[2K
| Adam | epoch: 014 | loss: 0.32027 - acc: 0.8596 -- iter: 352/399
[A[ATraining Step: 181  | total loss: [1m[32m0.31466[0m[0m | time: 7.036s
[2K
| Adam | epoch: 014 | loss: 0.31466 - acc: 0.8580 -- iter: 384/399
[A[ATraining Step: 182  | total loss: [1m[32m0.32980[0m[0m | time: 8.339s
[2K
| Adam | epoch: 014 | loss: 0.32980 - acc: 0.8522 | val_loss: 0.40442 - val_acc: 0.8320 -- iter: 399/399
--
Training Step: 183  | total loss: [1m[32m0.34285[0m[0m | time: 0.630s
[2K
| Adam | epoch: 015 | loss: 0.34285 - acc: 0.8470 -- iter: 032/399
[A[ATraining Step: 184  | total loss: [1m[32m0.33692[0m[0m | time: 1.219s
[2K
| Adam | epoch: 015 | loss: 0.33692 - acc: 0.8529 -- iter: 064/399
[A[ATraining Step: 185  | total loss: [1m[32m0.32955[0m[0m | time: 1.826s
[2K
| Adam | epoch: 015 | loss: 0.32955 - acc: 0.8614 -- iter: 096/399
[A[ATraining Step: 186  | total loss: [1m[32m0.31380[0m[0m | time: 2.448s
[2K
| Adam | epoch: 015 | loss: 0.31380 - acc: 0.8721 -- iter: 128/399
[A[ATraining Step: 187  | total loss: [1m[32m0.31621[0m[0m | time: 3.033s
[2K
| Adam | epoch: 015 | loss: 0.31621 - acc: 0.8755 -- iter: 160/399
[A[ATraining Step: 188  | total loss: [1m[32m0.31145[0m[0m | time: 3.653s
[2K
| Adam | epoch: 015 | loss: 0.31145 - acc: 0.8755 -- iter: 192/399
[A[ATraining Step: 189  | total loss: [1m[32m0.31369[0m[0m | time: 4.247s
[2K
| Adam | epoch: 015 | loss: 0.31369 - acc: 0.8785 -- iter: 224/399
[A[ATraining Step: 190  | total loss: [1m[32m0.31172[0m[0m | time: 4.849s
[2K
| Adam | epoch: 015 | loss: 0.31172 - acc: 0.8813 -- iter: 256/399
[A[ATraining Step: 191  | total loss: [1m[32m0.30275[0m[0m | time: 5.443s
[2K
| Adam | epoch: 015 | loss: 0.30275 - acc: 0.8838 -- iter: 288/399
[A[ATraining Step: 192  | total loss: [1m[32m0.29134[0m[0m | time: 6.051s
[2K
| Adam | epoch: 015 | loss: 0.29134 - acc: 0.8892 -- iter: 320/399
[A[ATraining Step: 193  | total loss: [1m[32m0.29773[0m[0m | time: 6.648s
[2K
| Adam | epoch: 015 | loss: 0.29773 - acc: 0.8878 -- iter: 352/399
[A[ATraining Step: 194  | total loss: [1m[32m0.28636[0m[0m | time: 7.248s
[2K
| Adam | epoch: 015 | loss: 0.28636 - acc: 0.8896 -- iter: 384/399
[A[ATraining Step: 195  | total loss: [1m[32m0.27704[0m[0m | time: 8.563s
[2K
| Adam | epoch: 015 | loss: 0.27704 - acc: 0.8975 | val_loss: 0.36406 - val_acc: 0.8480 -- iter: 399/399
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9201228878648234
Validation AUPRC:0.9237223986286301
Test AUC:0.9648717948717949
Test AUPRC:0.9658760203992962
BestTestF1Score	0.95	0.89	0.94	0.93	0.97	63	5	55	2	0.41
BestTestMCCScore	0.95	0.89	0.94	0.93	0.97	63	5	55	2	0.41
BestTestAccuracyScore	0.9	0.81	0.9	0.93	0.88	57	4	56	8	0.56
BestValidationF1Score	0.86	0.71	0.86	0.83	0.89	55	11	52	7	0.41
BestValidationMCC	0.86	0.71	0.86	0.83	0.89	55	11	52	7	0.41
BestValidationAccuracy	0.85	0.71	0.86	0.88	0.82	51	7	56	11	0.56
TestPredictions (Threshold:0.41)
CHEMBL3260541,TP,ACT,0.9800000190734863	CHEMBL595022,TN,INACT,0.019999999552965164	CHEMBL3238444,TN,INACT,0.05000000074505806	CHEMBL3321834,TP,ACT,0.949999988079071	CHEMBL2391353,TN,INACT,0.009999999776482582	CHEMBL241100,TN,INACT,0.15000000596046448	CHEMBL3598103,TP,ACT,0.4399999976158142	CHEMBL2062854,TN,INACT,0.029999999329447746	CHEMBL3326666,TP,ACT,0.8899999856948853	CHEMBL2311545,TP,ACT,0.9399999976158142	CHEMBL3260531,TP,ACT,0.9800000190734863	CHEMBL3321826,TP,ACT,0.9700000286102295	CHEMBL294349,TN,INACT,0.10999999940395355	CHEMBL3598098,TP,ACT,0.8799999952316284	CHEMBL419617,TN,INACT,0.03999999910593033	CHEMBL3326685,TP,ACT,0.8100000023841858	CHEMBL75358,TN,INACT,0.03999999910593033	CHEMBL3823398,TP,ACT,0.9800000190734863	CHEMBL1983100,TN,INACT,0.009999999776482582	CHEMBL2323593,TP,ACT,0.8999999761581421	CHEMBL3577344,TN,INACT,0.10000000149011612	CHEMBL2312161,TP,ACT,0.949999988079071	CHEMBL594802,TN,INACT,0.019999999552965164	CHEMBL3338167,TP,ACT,0.8299999833106995	CHEMBL145584,TN,INACT,0.009999999776482582	CHEMBL166736,TN,INACT,0.029999999329447746	CHEMBL3354804,TP,ACT,0.9599999785423279	CHEMBL3326686,TP,ACT,0.9100000262260437	CHEMBL196866,TN,INACT,0.3199999928474426	CHEMBL3633650,TN,INACT,0.0	CHEMBL2086650,TP,ACT,0.8299999833106995	CHEMBL3338164,TP,ACT,0.8299999833106995	CHEMBL3260539,TP,ACT,0.7799999713897705	CHEMBL62804,TN,INACT,0.07000000029802322	CHEMBL3622176,TP,ACT,0.9300000071525574	CHEMBL2382409,TP,ACT,0.8399999737739563	CHEMBL3354786,TP,ACT,0.9800000190734863	CHEMBL2312510,TP,ACT,0.7099999785423279	CHEMBL2312509,TP,ACT,0.7300000190734863	CHEMBL3338179,TP,ACT,0.8500000238418579	CHEMBL104994,TN,INACT,0.07999999821186066	CHEMBL3824019,TP,ACT,0.9800000190734863	CHEMBL2312508,TP,ACT,0.8899999856948853	CHEMBL3321828,TP,ACT,0.9300000071525574	CHEMBL129198,FP,INACT,0.9200000166893005	CHEMBL2312527,FN,ACT,0.38999998569488525	CHEMBL304888,TN,INACT,0.05000000074505806	CHEMBL3354783,TP,ACT,0.8199999928474426	CHEMBL9746,TN,INACT,0.009999999776482582	CHEMBL3260504,TP,ACT,0.9200000166893005	CHEMBL3354789,TP,ACT,0.9900000095367432	CHEMBL99331,TN,INACT,0.3100000023841858	CHEMBL301826,TN,INACT,0.10000000149011612	CHEMBL2312501,TP,ACT,0.44999998807907104	CHEMBL3622172,TP,ACT,0.9700000286102295	CHEMBL254500,TN,INACT,0.28999999165534973	CHEMBL6568,TN,INACT,0.23999999463558197	CHEMBL2312376,TN,INACT,0.009999999776482582	CHEMBL2335158,TN,INACT,0.0	CHEMBL3354794,TP,ACT,0.9300000071525574	CHEMBL593443,TN,INACT,0.019999999552965164	CHEMBL3598092,TP,ACT,0.8299999833106995	CHEMBL558766,TN,INACT,0.009999999776482582	CHEMBL72060,TN,INACT,0.11999999731779099	CHEMBL3590085,TN,INACT,0.3400000035762787	CHEMBL3338173,TP,ACT,0.800000011920929	CHEMBL241279,TN,INACT,0.05999999865889549	CHEMBL307326,TN,INACT,0.029999999329447746	CHEMBL2312517,TP,ACT,0.9800000190734863	CHEMBL1091790,TN,INACT,0.029999999329447746	CHEMBL1091778,TN,INACT,0.019999999552965164	CHEMBL284969,TN,INACT,0.05000000074505806	CHEMBL3598088,TP,ACT,0.9700000286102295	CHEMBL3338168,TP,ACT,0.5099999904632568	CHEMBL2204986,TP,ACT,0.5099999904632568	CHEMBL2323595,TP,ACT,0.8899999856948853	CHEMBL62716,TN,INACT,0.05000000074505806	CHEMBL59597,TN,INACT,0.029999999329447746	CHEMBL2086690,TP,ACT,0.5	CHEMBL516334,TN,INACT,0.03999999910593033	CHEMBL3335537,TN,INACT,0.029999999329447746	CHEMBL7441,TN,INACT,0.09000000357627869	CHEMBL456675,TN,INACT,0.019999999552965164	CHEMBL3629484,TP,ACT,0.9700000286102295	CHEMBL3410301,TN,INACT,0.019999999552965164	CHEMBL114478,TN,INACT,0.14000000059604645	CHEMBL3260508,TP,ACT,0.9700000286102295	CHEMBL60401,TN,INACT,0.03999999910593033	CHEMBL2312505,TP,ACT,0.75	CHEMBL2312160,TP,ACT,0.9300000071525574	CHEMBL3260511,TP,ACT,0.9700000286102295	CHEMBL197159,TN,INACT,0.009999999776482582	CHEMBL3629482,TP,ACT,0.9200000166893005	CHEMBL3338193,TP,ACT,0.9300000071525574	CHEMBL3260517,TP,ACT,0.9800000190734863	CHEMBL3326683,TP,ACT,0.9599999785423279	CHEMBL25373,TN,INACT,0.25999999046325684	CHEMBL3629480,TP,ACT,0.9599999785423279	CHEMBL461709,TN,INACT,0.029999999329447746	CHEMBL291821,TN,INACT,0.07999999821186066	CHEMBL279520,TN,INACT,0.019999999552965164	CHEMBL162095,TN,INACT,0.3199999928474426	CHEMBL62660,TN,INACT,0.1899999976158142	CHEMBL132179,TN,INACT,0.019999999552965164	CHEMBL557840,TN,INACT,0.009999999776482582	CHEMBL3326673,TP,ACT,0.9599999785423279	CHEMBL2204985,TP,ACT,0.7200000286102295	CHEMBL3321837,TP,ACT,0.9599999785423279	CHEMBL3764306,FP,INACT,0.47999998927116394	CHEMBL3622164,TP,ACT,0.6600000262260437	CHEMBL3354796,TP,ACT,0.9700000286102295	CHEMBL3338169,TP,ACT,0.9599999785423279	CHEMBL308924,FP,INACT,0.6800000071525574	CHEMBL3326675,TP,ACT,0.9399999976158142	CHEMBL461502,TN,INACT,0.009999999776482582	CHEMBL3354797,TP,ACT,0.8999999761581421	CHEMBL140006,FP,INACT,0.9200000166893005	CHEMBL100624,TN,INACT,0.30000001192092896	CHEMBL553082,TN,INACT,0.28999999165534973	CHEMBL272853,FP,INACT,0.8299999833106995	CHEMBL3822759,TP,ACT,0.9900000095367432	CHEMBL2382416,TP,ACT,0.47999998927116394	CHEMBL2312162,FN,ACT,0.019999999552965164	CHEMBL3629478,TP,ACT,0.8399999737739563	CHEMBL2086684,TP,ACT,0.7400000095367432	

