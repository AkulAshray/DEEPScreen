ImageNetInceptionV2 CHEMBL1824 adam 0.0005 5 0 0 0.6 False True
Number of active compounds :	1228
Number of inactive compounds :	1228
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1824_adam_0.0005_5_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1824_adam_0.0005_5_0.6/
---------------------------------
Training samples: 1559
Validation samples: 488
--
Training Step: 1  | time: 53.507s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1559
[A[ATraining Step: 2  | total loss: [1m[32m0.67889[0m[0m | time: 67.117s
[2K
| Adam | epoch: 001 | loss: 0.67889 - acc: 0.3656 -- iter: 0064/1559
[A[ATraining Step: 3  | total loss: [1m[32m0.73021[0m[0m | time: 81.170s
[2K
| Adam | epoch: 001 | loss: 0.73021 - acc: 0.5011 -- iter: 0096/1559
[A[ATraining Step: 4  | total loss: [1m[32m0.74660[0m[0m | time: 96.598s
[2K
| Adam | epoch: 001 | loss: 0.74660 - acc: 0.5940 -- iter: 0128/1559
[A[ATraining Step: 5  | total loss: [1m[32m0.67955[0m[0m | time: 115.325s
[2K
| Adam | epoch: 001 | loss: 0.67955 - acc: 0.6371 -- iter: 0160/1559
[A[ATraining Step: 6  | total loss: [1m[32m0.69072[0m[0m | time: 132.012s
[2K
| Adam | epoch: 001 | loss: 0.69072 - acc: 0.5289 -- iter: 0192/1559
[A[ATraining Step: 7  | total loss: [1m[32m0.70707[0m[0m | time: 149.743s
[2K
| Adam | epoch: 001 | loss: 0.70707 - acc: 0.5678 -- iter: 0224/1559
[A[ATraining Step: 8  | total loss: [1m[32m0.70854[0m[0m | time: 160.038s
[2K
| Adam | epoch: 001 | loss: 0.70854 - acc: 0.6176 -- iter: 0256/1559
[A[ATraining Step: 9  | total loss: [1m[32m0.65076[0m[0m | time: 168.524s
[2K
| Adam | epoch: 001 | loss: 0.65076 - acc: 0.6380 -- iter: 0288/1559
[A[ATraining Step: 10  | total loss: [1m[32m0.63632[0m[0m | time: 177.036s
[2K
| Adam | epoch: 001 | loss: 0.63632 - acc: 0.6159 -- iter: 0320/1559
[A[ATraining Step: 11  | total loss: [1m[32m0.63873[0m[0m | time: 187.156s
[2K
| Adam | epoch: 001 | loss: 0.63873 - acc: 0.6646 -- iter: 0352/1559
[A[ATraining Step: 12  | total loss: [1m[32m0.61103[0m[0m | time: 201.063s
[2K
| Adam | epoch: 001 | loss: 0.61103 - acc: 0.7171 -- iter: 0384/1559
[A[ATraining Step: 13  | total loss: [1m[32m0.60790[0m[0m | time: 215.920s
[2K
| Adam | epoch: 001 | loss: 0.60790 - acc: 0.6910 -- iter: 0416/1559
[A[ATraining Step: 14  | total loss: [1m[32m0.57877[0m[0m | time: 230.210s
[2K
| Adam | epoch: 001 | loss: 0.57877 - acc: 0.7279 -- iter: 0448/1559
[A[ATraining Step: 15  | total loss: [1m[32m0.56607[0m[0m | time: 245.514s
[2K
| Adam | epoch: 001 | loss: 0.56607 - acc: 0.7488 -- iter: 0480/1559
[A[ATraining Step: 16  | total loss: [1m[32m0.55114[0m[0m | time: 258.729s
[2K
| Adam | epoch: 001 | loss: 0.55114 - acc: 0.7610 -- iter: 0512/1559
[A[ATraining Step: 17  | total loss: [1m[32m0.62517[0m[0m | time: 270.010s
[2K
| Adam | epoch: 001 | loss: 0.62517 - acc: 0.6895 -- iter: 0544/1559
[A[ATraining Step: 18  | total loss: [1m[32m0.55286[0m[0m | time: 281.838s
[2K
| Adam | epoch: 001 | loss: 0.55286 - acc: 0.7321 -- iter: 0576/1559
[A[ATraining Step: 19  | total loss: [1m[32m0.58151[0m[0m | time: 294.588s
[2K
| Adam | epoch: 001 | loss: 0.58151 - acc: 0.7276 -- iter: 0608/1559
[A[ATraining Step: 20  | total loss: [1m[32m0.64161[0m[0m | time: 307.155s
[2K
| Adam | epoch: 001 | loss: 0.64161 - acc: 0.6846 -- iter: 0640/1559
[A[ATraining Step: 21  | total loss: [1m[32m0.61346[0m[0m | time: 321.490s
[2K
| Adam | epoch: 001 | loss: 0.61346 - acc: 0.6661 -- iter: 0672/1559
[A[ATraining Step: 22  | total loss: [1m[32m0.55980[0m[0m | time: 334.385s
[2K
| Adam | epoch: 001 | loss: 0.55980 - acc: 0.7100 -- iter: 0704/1559
[A[ATraining Step: 23  | total loss: [1m[32m0.57009[0m[0m | time: 344.987s
[2K
| Adam | epoch: 001 | loss: 0.57009 - acc: 0.6944 -- iter: 0736/1559
[A[ATraining Step: 24  | total loss: [1m[32m0.59847[0m[0m | time: 353.623s
[2K
| Adam | epoch: 001 | loss: 0.59847 - acc: 0.6573 -- iter: 0768/1559
[A[ATraining Step: 25  | total loss: [1m[32m0.60213[0m[0m | time: 362.095s
[2K
| Adam | epoch: 001 | loss: 0.60213 - acc: 0.6229 -- iter: 0800/1559
[A[ATraining Step: 26  | total loss: [1m[32m0.64083[0m[0m | time: 372.724s
[2K
| Adam | epoch: 001 | loss: 0.64083 - acc: 0.6318 -- iter: 0832/1559
[A[ATraining Step: 27  | total loss: [1m[32m0.62082[0m[0m | time: 385.657s
[2K
| Adam | epoch: 001 | loss: 0.62082 - acc: 0.6220 -- iter: 0864/1559
[A[ATraining Step: 28  | total loss: [1m[32m0.60355[0m[0m | time: 398.088s
[2K
| Adam | epoch: 001 | loss: 0.60355 - acc: 0.6384 -- iter: 0896/1559
[A[ATraining Step: 29  | total loss: [1m[32m0.58237[0m[0m | time: 412.792s
[2K
| Adam | epoch: 001 | loss: 0.58237 - acc: 0.6503 -- iter: 0928/1559
[A[ATraining Step: 30  | total loss: [1m[32m0.58506[0m[0m | time: 425.335s
[2K
| Adam | epoch: 001 | loss: 0.58506 - acc: 0.6665 -- iter: 0960/1559
[A[ATraining Step: 31  | total loss: [1m[32m0.57224[0m[0m | time: 437.060s
[2K
| Adam | epoch: 001 | loss: 0.57224 - acc: 0.6930 -- iter: 0992/1559
[A[ATraining Step: 32  | total loss: [1m[32m0.58739[0m[0m | time: 460.785s
[2K
| Adam | epoch: 001 | loss: 0.58739 - acc: 0.6847 -- iter: 1024/1559
[A[ATraining Step: 33  | total loss: [1m[32m0.55881[0m[0m | time: 473.463s
[2K
| Adam | epoch: 001 | loss: 0.55881 - acc: 0.7128 -- iter: 1056/1559
[A[ATraining Step: 34  | total loss: [1m[32m0.58437[0m[0m | time: 485.334s
[2K
| Adam | epoch: 001 | loss: 0.58437 - acc: 0.7074 -- iter: 1088/1559
[A[ATraining Step: 35  | total loss: [1m[32m0.58337[0m[0m | time: 497.940s
[2K
| Adam | epoch: 001 | loss: 0.58337 - acc: 0.7032 -- iter: 1120/1559
[A[ATraining Step: 36  | total loss: [1m[32m0.58137[0m[0m | time: 510.177s
[2K
| Adam | epoch: 001 | loss: 0.58137 - acc: 0.7000 -- iter: 1152/1559
[A[ATraining Step: 37  | total loss: [1m[32m0.55033[0m[0m | time: 521.851s
[2K
| Adam | epoch: 001 | loss: 0.55033 - acc: 0.7225 -- iter: 1184/1559
[A[ATraining Step: 38  | total loss: [1m[32m0.54689[0m[0m | time: 533.090s
[2K
| Adam | epoch: 001 | loss: 0.54689 - acc: 0.7340 -- iter: 1216/1559
[A[ATraining Step: 39  | total loss: [1m[32m0.53069[0m[0m | time: 541.306s
[2K
| Adam | epoch: 001 | loss: 0.53069 - acc: 0.7490 -- iter: 1248/1559
[A[ATraining Step: 40  | total loss: [1m[32m0.49537[0m[0m | time: 549.295s
[2K
| Adam | epoch: 001 | loss: 0.49537 - acc: 0.7726 -- iter: 1280/1559
[A[ATraining Step: 41  | total loss: [1m[32m0.54357[0m[0m | time: 560.572s
[2K
| Adam | epoch: 001 | loss: 0.54357 - acc: 0.7455 -- iter: 1312/1559
[A[ATraining Step: 42  | total loss: [1m[32m0.54681[0m[0m | time: 573.201s
[2K
| Adam | epoch: 001 | loss: 0.54681 - acc: 0.7463 -- iter: 1344/1559
[A[ATraining Step: 43  | total loss: [1m[32m0.53737[0m[0m | time: 585.541s
[2K
| Adam | epoch: 001 | loss: 0.53737 - acc: 0.7525 -- iter: 1376/1559
[A[ATraining Step: 44  | total loss: [1m[32m0.53645[0m[0m | time: 597.982s
[2K
| Adam | epoch: 001 | loss: 0.53645 - acc: 0.7575 -- iter: 1408/1559
[A[ATraining Step: 45  | total loss: [1m[32m0.54417[0m[0m | time: 610.643s
[2K
| Adam | epoch: 001 | loss: 0.54417 - acc: 0.7403 -- iter: 1440/1559
[A[ATraining Step: 46  | total loss: [1m[32m0.52781[0m[0m | time: 623.438s
[2K
| Adam | epoch: 001 | loss: 0.52781 - acc: 0.7471 -- iter: 1472/1559
[A[ATraining Step: 47  | total loss: [1m[32m0.53993[0m[0m | time: 635.763s
[2K
| Adam | epoch: 001 | loss: 0.53993 - acc: 0.7476 -- iter: 1504/1559
[A[ATraining Step: 48  | total loss: [1m[32m0.54529[0m[0m | time: 647.757s
[2K
| Adam | epoch: 001 | loss: 0.54529 - acc: 0.7480 -- iter: 1536/1559
[A[ATraining Step: 49  | total loss: [1m[32m0.58734[0m[0m | time: 699.225s
[2K
| Adam | epoch: 001 | loss: 0.58734 - acc: 0.7236 | val_loss: 0.59323 - val_acc: 0.6742 -- iter: 1559/1559
--
Training Step: 50  | total loss: [1m[32m0.56606[0m[0m | time: 9.769s
[2K
| Adam | epoch: 002 | loss: 0.56606 - acc: 0.7463 -- iter: 0032/1559
[A[ATraining Step: 51  | total loss: [1m[32m0.53874[0m[0m | time: 21.931s
[2K
| Adam | epoch: 002 | loss: 0.53874 - acc: 0.7651 -- iter: 0064/1559
[A[ATraining Step: 52  | total loss: [1m[32m0.53121[0m[0m | time: 51.042s
[2K
| Adam | epoch: 002 | loss: 0.53121 - acc: 0.7722 -- iter: 0096/1559
[A[ATraining Step: 53  | total loss: [1m[32m0.53318[0m[0m | time: 63.351s
[2K
| Adam | epoch: 002 | loss: 0.53318 - acc: 0.7597 -- iter: 0128/1559
[A[ATraining Step: 54  | total loss: [1m[32m0.53566[0m[0m | time: 75.771s
[2K
| Adam | epoch: 002 | loss: 0.53566 - acc: 0.7538 -- iter: 0160/1559
[A[ATraining Step: 55  | total loss: [1m[32m0.51343[0m[0m | time: 88.110s
[2K
| Adam | epoch: 002 | loss: 0.51343 - acc: 0.7621 -- iter: 0192/1559
[A[ATraining Step: 56  | total loss: [1m[32m0.50461[0m[0m | time: 99.838s
[2K
| Adam | epoch: 002 | loss: 0.50461 - acc: 0.7648 -- iter: 0224/1559
[A[ATraining Step: 57  | total loss: [1m[32m0.50779[0m[0m | time: 111.290s
[2K
| Adam | epoch: 002 | loss: 0.50779 - acc: 0.7671 -- iter: 0256/1559
[A[ATraining Step: 58  | total loss: [1m[32m0.52798[0m[0m | time: 123.917s
[2K
| Adam | epoch: 002 | loss: 0.52798 - acc: 0.7477 -- iter: 0288/1559
[A[ATraining Step: 59  | total loss: [1m[32m0.52332[0m[0m | time: 136.667s
[2K
| Adam | epoch: 002 | loss: 0.52332 - acc: 0.7438 -- iter: 0320/1559
[A[ATraining Step: 60  | total loss: [1m[32m0.52690[0m[0m | time: 145.167s
[2K
| Adam | epoch: 002 | loss: 0.52690 - acc: 0.7446 -- iter: 0352/1559
[A[ATraining Step: 61  | total loss: [1m[32m0.52204[0m[0m | time: 153.737s
[2K
| Adam | epoch: 002 | loss: 0.52204 - acc: 0.7535 -- iter: 0384/1559
[A[ATraining Step: 62  | total loss: [1m[32m0.51347[0m[0m | time: 162.149s
[2K
| Adam | epoch: 002 | loss: 0.51347 - acc: 0.7530 -- iter: 0416/1559
[A[ATraining Step: 63  | total loss: [1m[32m0.51531[0m[0m | time: 170.485s
[2K
| Adam | epoch: 002 | loss: 0.51531 - acc: 0.7527 -- iter: 0448/1559
[A[ATraining Step: 64  | total loss: [1m[32m0.51864[0m[0m | time: 181.975s
[2K
| Adam | epoch: 002 | loss: 0.51864 - acc: 0.7523 -- iter: 0480/1559
[A[ATraining Step: 65  | total loss: [1m[32m0.52291[0m[0m | time: 195.004s
[2K
| Adam | epoch: 002 | loss: 0.52291 - acc: 0.7482 -- iter: 0512/1559
[A[ATraining Step: 66  | total loss: [1m[32m0.53034[0m[0m | time: 207.603s
[2K
| Adam | epoch: 002 | loss: 0.53034 - acc: 0.7408 -- iter: 0544/1559
[A[ATraining Step: 67  | total loss: [1m[32m0.55222[0m[0m | time: 220.407s
[2K
| Adam | epoch: 002 | loss: 0.55222 - acc: 0.7269 -- iter: 0576/1559
[A[ATraining Step: 68  | total loss: [1m[32m0.53784[0m[0m | time: 232.577s
[2K
| Adam | epoch: 002 | loss: 0.53784 - acc: 0.7407 -- iter: 0608/1559
[A[ATraining Step: 69  | total loss: [1m[32m0.51950[0m[0m | time: 245.439s
[2K
| Adam | epoch: 002 | loss: 0.51950 - acc: 0.7564 -- iter: 0640/1559
[A[ATraining Step: 70  | total loss: [1m[32m0.49444[0m[0m | time: 260.023s
[2K
| Adam | epoch: 002 | loss: 0.49444 - acc: 0.7737 -- iter: 0672/1559
[A[ATraining Step: 71  | total loss: [1m[32m0.49056[0m[0m | time: 298.766s
[2K
| Adam | epoch: 002 | loss: 0.49056 - acc: 0.7746 -- iter: 0704/1559
[A[ATraining Step: 72  | total loss: [1m[32m0.47939[0m[0m | time: 311.243s
[2K
| Adam | epoch: 002 | loss: 0.47939 - acc: 0.7753 -- iter: 0736/1559
[A[ATraining Step: 73  | total loss: [1m[32m0.45680[0m[0m | time: 323.851s
[2K
| Adam | epoch: 002 | loss: 0.45680 - acc: 0.7899 -- iter: 0768/1559
[A[ATraining Step: 74  | total loss: [1m[32m0.44244[0m[0m | time: 335.815s
[2K
| Adam | epoch: 002 | loss: 0.44244 - acc: 0.7958 -- iter: 0800/1559
[A[ATraining Step: 75  | total loss: [1m[32m0.43078[0m[0m | time: 347.635s
[2K
| Adam | epoch: 002 | loss: 0.43078 - acc: 0.8044 -- iter: 0832/1559
[A[ATraining Step: 76  | total loss: [1m[32m0.44132[0m[0m | time: 358.921s
[2K
| Adam | epoch: 002 | loss: 0.44132 - acc: 0.7986 -- iter: 0864/1559
[A[ATraining Step: 77  | total loss: [1m[32m0.42418[0m[0m | time: 367.221s
[2K
| Adam | epoch: 002 | loss: 0.42418 - acc: 0.8100 -- iter: 0896/1559
[A[ATraining Step: 78  | total loss: [1m[32m0.43676[0m[0m | time: 375.804s
[2K
| Adam | epoch: 002 | loss: 0.43676 - acc: 0.8070 -- iter: 0928/1559
[A[ATraining Step: 79  | total loss: [1m[32m0.43351[0m[0m | time: 384.445s
[2K
| Adam | epoch: 002 | loss: 0.43351 - acc: 0.8108 -- iter: 0960/1559
[A[ATraining Step: 80  | total loss: [1m[32m0.42403[0m[0m | time: 404.621s
[2K
| Adam | epoch: 002 | loss: 0.42403 - acc: 0.8141 -- iter: 0992/1559
[A[ATraining Step: 81  | total loss: [1m[32m0.42802[0m[0m | time: 426.691s
[2K
| Adam | epoch: 002 | loss: 0.42802 - acc: 0.8140 -- iter: 1024/1559
[A[ATraining Step: 82  | total loss: [1m[32m0.43626[0m[0m | time: 439.117s
[2K
| Adam | epoch: 002 | loss: 0.43626 - acc: 0.8044 -- iter: 1056/1559
[A[ATraining Step: 83  | total loss: [1m[32m0.41274[0m[0m | time: 451.530s
[2K
| Adam | epoch: 002 | loss: 0.41274 - acc: 0.8178 -- iter: 1088/1559
[A[ATraining Step: 84  | total loss: [1m[32m0.42814[0m[0m | time: 464.032s
[2K
| Adam | epoch: 002 | loss: 0.42814 - acc: 0.8141 -- iter: 1120/1559
[A[ATraining Step: 85  | total loss: [1m[32m0.45457[0m[0m | time: 476.718s
[2K
| Adam | epoch: 002 | loss: 0.45457 - acc: 0.8046 -- iter: 1152/1559
[A[ATraining Step: 86  | total loss: [1m[32m0.44333[0m[0m | time: 489.418s
[2K
| Adam | epoch: 002 | loss: 0.44333 - acc: 0.8054 -- iter: 1184/1559
[A[ATraining Step: 87  | total loss: [1m[32m0.44924[0m[0m | time: 502.383s
[2K
| Adam | epoch: 002 | loss: 0.44924 - acc: 0.8029 -- iter: 1216/1559
[A[ATraining Step: 88  | total loss: [1m[32m0.45049[0m[0m | time: 514.713s
[2K
| Adam | epoch: 002 | loss: 0.45049 - acc: 0.7945 -- iter: 1248/1559
[A[ATraining Step: 89  | total loss: [1m[32m0.44926[0m[0m | time: 526.924s
[2K
| Adam | epoch: 002 | loss: 0.44926 - acc: 0.7963 -- iter: 1280/1559
[A[ATraining Step: 90  | total loss: [1m[32m0.45700[0m[0m | time: 553.562s
[2K
| Adam | epoch: 002 | loss: 0.45700 - acc: 0.7948 -- iter: 1312/1559
[A[ATraining Step: 91  | total loss: [1m[32m0.45753[0m[0m | time: 565.404s
[2K
| Adam | epoch: 002 | loss: 0.45753 - acc: 0.7903 -- iter: 1344/1559
[A[ATraining Step: 92  | total loss: [1m[32m0.45606[0m[0m | time: 576.488s
[2K
| Adam | epoch: 002 | loss: 0.45606 - acc: 0.7894 -- iter: 1376/1559
[A[ATraining Step: 93  | total loss: [1m[32m0.44689[0m[0m | time: 585.016s
[2K
| Adam | epoch: 002 | loss: 0.44689 - acc: 0.8011 -- iter: 1408/1559
[A[ATraining Step: 94  | total loss: [1m[32m0.44005[0m[0m | time: 593.262s
[2K
| Adam | epoch: 002 | loss: 0.44005 - acc: 0.8022 -- iter: 1440/1559
[A[ATraining Step: 95  | total loss: [1m[32m0.42877[0m[0m | time: 603.553s
[2K
| Adam | epoch: 002 | loss: 0.42877 - acc: 0.8095 -- iter: 1472/1559
[A[ATraining Step: 96  | total loss: [1m[32m0.43825[0m[0m | time: 615.799s
[2K
| Adam | epoch: 002 | loss: 0.43825 - acc: 0.8004 -- iter: 1504/1559
[A[ATraining Step: 97  | total loss: [1m[32m0.47873[0m[0m | time: 628.243s
[2K
| Adam | epoch: 002 | loss: 0.47873 - acc: 0.7767 -- iter: 1536/1559
[A[ATraining Step: 98  | total loss: [1m[32m0.47845[0m[0m | time: 674.741s
[2K
| Adam | epoch: 002 | loss: 0.47845 - acc: 0.7865 | val_loss: 0.51763 - val_acc: 0.7705 -- iter: 1559/1559
--
Training Step: 99  | total loss: [1m[32m0.47036[0m[0m | time: 11.979s
[2K
| Adam | epoch: 003 | loss: 0.47036 - acc: 0.7891 -- iter: 0032/1559
[A[ATraining Step: 100  | total loss: [1m[32m0.45236[0m[0m | time: 21.539s
[2K
| Adam | epoch: 003 | loss: 0.45236 - acc: 0.7971 -- iter: 0064/1559
[A[ATraining Step: 101  | total loss: [1m[32m0.43556[0m[0m | time: 30.343s
[2K
| Adam | epoch: 003 | loss: 0.43556 - acc: 0.8044 -- iter: 0096/1559
[A[ATraining Step: 102  | total loss: [1m[32m0.43167[0m[0m | time: 38.662s
[2K
| Adam | epoch: 003 | loss: 0.43167 - acc: 0.8052 -- iter: 0128/1559
[A[ATraining Step: 103  | total loss: [1m[32m0.44195[0m[0m | time: 46.911s
[2K
| Adam | epoch: 003 | loss: 0.44195 - acc: 0.7965 -- iter: 0160/1559
[A[ATraining Step: 104  | total loss: [1m[32m0.44398[0m[0m | time: 58.323s
[2K
| Adam | epoch: 003 | loss: 0.44398 - acc: 0.7888 -- iter: 0192/1559
[A[ATraining Step: 105  | total loss: [1m[32m0.44844[0m[0m | time: 70.259s
[2K
| Adam | epoch: 003 | loss: 0.44844 - acc: 0.7880 -- iter: 0224/1559
[A[ATraining Step: 106  | total loss: [1m[32m0.42478[0m[0m | time: 82.946s
[2K
| Adam | epoch: 003 | loss: 0.42478 - acc: 0.8061 -- iter: 0256/1559
[A[ATraining Step: 107  | total loss: [1m[32m0.42414[0m[0m | time: 95.103s
[2K
| Adam | epoch: 003 | loss: 0.42414 - acc: 0.8005 -- iter: 0288/1559
[A[ATraining Step: 108  | total loss: [1m[32m0.41045[0m[0m | time: 117.068s
[2K
| Adam | epoch: 003 | loss: 0.41045 - acc: 0.8111 -- iter: 0320/1559
[A[ATraining Step: 109  | total loss: [1m[32m0.41470[0m[0m | time: 136.009s
[2K
| Adam | epoch: 003 | loss: 0.41470 - acc: 0.8081 -- iter: 0352/1559
[A[ATraining Step: 110  | total loss: [1m[32m0.40084[0m[0m | time: 148.196s
[2K
| Adam | epoch: 003 | loss: 0.40084 - acc: 0.8148 -- iter: 0384/1559
[A[ATraining Step: 111  | total loss: [1m[32m0.41051[0m[0m | time: 160.596s
[2K
| Adam | epoch: 003 | loss: 0.41051 - acc: 0.8083 -- iter: 0416/1559
[A[ATraining Step: 112  | total loss: [1m[32m0.39859[0m[0m | time: 173.144s
[2K
| Adam | epoch: 003 | loss: 0.39859 - acc: 0.8181 -- iter: 0448/1559
[A[ATraining Step: 113  | total loss: [1m[32m0.39620[0m[0m | time: 185.631s
[2K
| Adam | epoch: 003 | loss: 0.39620 - acc: 0.8207 -- iter: 0480/1559
[A[ATraining Step: 114  | total loss: [1m[32m0.40955[0m[0m | time: 198.100s
[2K
| Adam | epoch: 003 | loss: 0.40955 - acc: 0.8167 -- iter: 0512/1559
[A[ATraining Step: 115  | total loss: [1m[32m0.41423[0m[0m | time: 210.338s
[2K
| Adam | epoch: 003 | loss: 0.41423 - acc: 0.8132 -- iter: 0544/1559
[A[ATraining Step: 116  | total loss: [1m[32m0.45983[0m[0m | time: 220.568s
[2K
| Adam | epoch: 003 | loss: 0.45983 - acc: 0.7912 -- iter: 0576/1559
[A[ATraining Step: 117  | total loss: [1m[32m0.45637[0m[0m | time: 228.942s
[2K
| Adam | epoch: 003 | loss: 0.45637 - acc: 0.7902 -- iter: 0608/1559
[A[ATraining Step: 118  | total loss: [1m[32m0.45992[0m[0m | time: 237.311s
[2K
| Adam | epoch: 003 | loss: 0.45992 - acc: 0.7862 -- iter: 0640/1559
[A[ATraining Step: 119  | total loss: [1m[32m0.44389[0m[0m | time: 245.820s
[2K
| Adam | epoch: 003 | loss: 0.44389 - acc: 0.7951 -- iter: 0672/1559
[A[ATraining Step: 120  | total loss: [1m[32m0.44288[0m[0m | time: 255.038s
[2K
| Adam | epoch: 003 | loss: 0.44288 - acc: 0.7968 -- iter: 0704/1559
[A[ATraining Step: 121  | total loss: [1m[32m0.42328[0m[0m | time: 268.848s
[2K
| Adam | epoch: 003 | loss: 0.42328 - acc: 0.8109 -- iter: 0736/1559
[A[ATraining Step: 122  | total loss: [1m[32m0.41615[0m[0m | time: 277.452s
[2K
| Adam | epoch: 003 | loss: 0.41615 - acc: 0.8204 -- iter: 0768/1559
[A[ATraining Step: 123  | total loss: [1m[32m0.41389[0m[0m | time: 285.288s
[2K
| Adam | epoch: 003 | loss: 0.41389 - acc: 0.8134 -- iter: 0800/1559
[A[ATraining Step: 124  | total loss: [1m[32m0.39996[0m[0m | time: 293.147s
[2K
| Adam | epoch: 003 | loss: 0.39996 - acc: 0.8195 -- iter: 0832/1559
[A[ATraining Step: 125  | total loss: [1m[32m0.39925[0m[0m | time: 300.991s
[2K
| Adam | epoch: 003 | loss: 0.39925 - acc: 0.8188 -- iter: 0864/1559
[A[ATraining Step: 126  | total loss: [1m[32m0.38253[0m[0m | time: 308.805s
[2K
| Adam | epoch: 003 | loss: 0.38253 - acc: 0.8276 -- iter: 0896/1559
[A[ATraining Step: 127  | total loss: [1m[32m0.38493[0m[0m | time: 316.870s
[2K
| Adam | epoch: 003 | loss: 0.38493 - acc: 0.8261 -- iter: 0928/1559
[A[ATraining Step: 128  | total loss: [1m[32m0.36942[0m[0m | time: 324.863s
[2K
| Adam | epoch: 003 | loss: 0.36942 - acc: 0.8341 -- iter: 0960/1559
[A[ATraining Step: 129  | total loss: [1m[32m0.36679[0m[0m | time: 332.694s
[2K
| Adam | epoch: 003 | loss: 0.36679 - acc: 0.8319 -- iter: 0992/1559
[A[ATraining Step: 130  | total loss: [1m[32m0.35083[0m[0m | time: 340.535s
[2K
| Adam | epoch: 003 | loss: 0.35083 - acc: 0.8425 -- iter: 1024/1559
[A[ATraining Step: 131  | total loss: [1m[32m0.36654[0m[0m | time: 348.551s
[2K
| Adam | epoch: 003 | loss: 0.36654 - acc: 0.8332 -- iter: 1056/1559
[A[ATraining Step: 132  | total loss: [1m[32m0.37182[0m[0m | time: 356.276s
[2K
| Adam | epoch: 003 | loss: 0.37182 - acc: 0.8343 -- iter: 1088/1559
[A[ATraining Step: 133  | total loss: [1m[32m0.35888[0m[0m | time: 364.243s
[2K
| Adam | epoch: 003 | loss: 0.35888 - acc: 0.8477 -- iter: 1120/1559
[A[ATraining Step: 134  | total loss: [1m[32m0.36196[0m[0m | time: 372.007s
[2K
| Adam | epoch: 003 | loss: 0.36196 - acc: 0.8411 -- iter: 1152/1559
[A[ATraining Step: 135  | total loss: [1m[32m0.34353[0m[0m | time: 379.854s
[2K
| Adam | epoch: 003 | loss: 0.34353 - acc: 0.8507 -- iter: 1184/1559
[A[ATraining Step: 136  | total loss: [1m[32m0.34081[0m[0m | time: 387.692s
[2K
| Adam | epoch: 003 | loss: 0.34081 - acc: 0.8469 -- iter: 1216/1559
[A[ATraining Step: 137  | total loss: [1m[32m0.32207[0m[0m | time: 395.539s
[2K
| Adam | epoch: 003 | loss: 0.32207 - acc: 0.8560 -- iter: 1248/1559
[A[ATraining Step: 138  | total loss: [1m[32m0.32251[0m[0m | time: 403.423s
[2K
| Adam | epoch: 003 | loss: 0.32251 - acc: 0.8516 -- iter: 1280/1559
[A[ATraining Step: 139  | total loss: [1m[32m0.33139[0m[0m | time: 411.399s
[2K
| Adam | epoch: 003 | loss: 0.33139 - acc: 0.8540 -- iter: 1312/1559
[A[ATraining Step: 140  | total loss: [1m[32m0.32347[0m[0m | time: 419.246s
[2K
| Adam | epoch: 003 | loss: 0.32347 - acc: 0.8592 -- iter: 1344/1559
[A[ATraining Step: 141  | total loss: [1m[32m0.31445[0m[0m | time: 427.256s
[2K
| Adam | epoch: 003 | loss: 0.31445 - acc: 0.8639 -- iter: 1376/1559
[A[ATraining Step: 142  | total loss: [1m[32m0.31586[0m[0m | time: 435.141s
[2K
| Adam | epoch: 003 | loss: 0.31586 - acc: 0.8650 -- iter: 1408/1559
[A[ATraining Step: 143  | total loss: [1m[32m0.30970[0m[0m | time: 442.940s
[2K
| Adam | epoch: 003 | loss: 0.30970 - acc: 0.8629 -- iter: 1440/1559
[A[ATraining Step: 144  | total loss: [1m[32m0.30559[0m[0m | time: 450.718s
[2K
| Adam | epoch: 003 | loss: 0.30559 - acc: 0.8610 -- iter: 1472/1559
[A[ATraining Step: 145  | total loss: [1m[32m0.31273[0m[0m | time: 458.523s
[2K
| Adam | epoch: 003 | loss: 0.31273 - acc: 0.8655 -- iter: 1504/1559
[A[ATraining Step: 146  | total loss: [1m[32m0.30903[0m[0m | time: 466.480s
[2K
| Adam | epoch: 003 | loss: 0.30903 - acc: 0.8633 -- iter: 1536/1559
[A[ATraining Step: 147  | total loss: [1m[32m0.29303[0m[0m | time: 495.755s
[2K
| Adam | epoch: 003 | loss: 0.29303 - acc: 0.8707 | val_loss: 2.63621 - val_acc: 0.5389 -- iter: 1559/1559
--
Training Step: 148  | total loss: [1m[32m0.30756[0m[0m | time: 7.768s
[2K
| Adam | epoch: 004 | loss: 0.30756 - acc: 0.8649 -- iter: 0032/1559
[A[ATraining Step: 149  | total loss: [1m[32m0.30720[0m[0m | time: 13.828s
[2K
| Adam | epoch: 004 | loss: 0.30720 - acc: 0.8628 -- iter: 0064/1559
[A[ATraining Step: 150  | total loss: [1m[32m0.30352[0m[0m | time: 19.813s
[2K
| Adam | epoch: 004 | loss: 0.30352 - acc: 0.8635 -- iter: 0096/1559
[A[ATraining Step: 151  | total loss: [1m[32m0.28839[0m[0m | time: 27.511s
[2K
| Adam | epoch: 004 | loss: 0.28839 - acc: 0.8771 -- iter: 0128/1559
[A[ATraining Step: 152  | total loss: [1m[32m0.30630[0m[0m | time: 35.291s
[2K
| Adam | epoch: 004 | loss: 0.30630 - acc: 0.8769 -- iter: 0160/1559
[A[ATraining Step: 153  | total loss: [1m[32m0.32345[0m[0m | time: 43.097s
[2K
| Adam | epoch: 004 | loss: 0.32345 - acc: 0.8673 -- iter: 0192/1559
[A[ATraining Step: 154  | total loss: [1m[32m0.31243[0m[0m | time: 51.070s
[2K
| Adam | epoch: 004 | loss: 0.31243 - acc: 0.8712 -- iter: 0224/1559
[A[ATraining Step: 155  | total loss: [1m[32m0.30791[0m[0m | time: 58.851s
[2K
| Adam | epoch: 004 | loss: 0.30791 - acc: 0.8779 -- iter: 0256/1559
[A[ATraining Step: 156  | total loss: [1m[32m0.31481[0m[0m | time: 66.866s
[2K
| Adam | epoch: 004 | loss: 0.31481 - acc: 0.8745 -- iter: 0288/1559
[A[ATraining Step: 157  | total loss: [1m[32m0.33967[0m[0m | time: 74.852s
[2K
| Adam | epoch: 004 | loss: 0.33967 - acc: 0.8620 -- iter: 0320/1559
[A[ATraining Step: 158  | total loss: [1m[32m0.35543[0m[0m | time: 82.794s
[2K
| Adam | epoch: 004 | loss: 0.35543 - acc: 0.8539 -- iter: 0352/1559
[A[ATraining Step: 159  | total loss: [1m[32m0.36792[0m[0m | time: 90.787s
[2K
| Adam | epoch: 004 | loss: 0.36792 - acc: 0.8498 -- iter: 0384/1559
[A[ATraining Step: 160  | total loss: [1m[32m0.35887[0m[0m | time: 98.546s
[2K
| Adam | epoch: 004 | loss: 0.35887 - acc: 0.8554 -- iter: 0416/1559
[A[ATraining Step: 161  | total loss: [1m[32m0.35230[0m[0m | time: 106.375s
[2K
| Adam | epoch: 004 | loss: 0.35230 - acc: 0.8574 -- iter: 0448/1559
[A[ATraining Step: 162  | total loss: [1m[32m0.35390[0m[0m | time: 114.204s
[2K
| Adam | epoch: 004 | loss: 0.35390 - acc: 0.8560 -- iter: 0480/1559
[A[ATraining Step: 163  | total loss: [1m[32m0.34753[0m[0m | time: 122.001s
[2K
| Adam | epoch: 004 | loss: 0.34753 - acc: 0.8579 -- iter: 0512/1559
[A[ATraining Step: 164  | total loss: [1m[32m0.34749[0m[0m | time: 129.868s
[2K
| Adam | epoch: 004 | loss: 0.34749 - acc: 0.8565 -- iter: 0544/1559
[A[ATraining Step: 165  | total loss: [1m[32m0.35227[0m[0m | time: 137.686s
[2K
| Adam | epoch: 004 | loss: 0.35227 - acc: 0.8552 -- iter: 0576/1559
[A[ATraining Step: 166  | total loss: [1m[32m0.34221[0m[0m | time: 145.495s
[2K
| Adam | epoch: 004 | loss: 0.34221 - acc: 0.8572 -- iter: 0608/1559
[A[ATraining Step: 167  | total loss: [1m[32m0.35071[0m[0m | time: 153.385s
[2K
| Adam | epoch: 004 | loss: 0.35071 - acc: 0.8527 -- iter: 0640/1559
[A[ATraining Step: 168  | total loss: [1m[32m0.35655[0m[0m | time: 161.078s
[2K
| Adam | epoch: 004 | loss: 0.35655 - acc: 0.8581 -- iter: 0672/1559
[A[ATraining Step: 169  | total loss: [1m[32m0.35131[0m[0m | time: 168.878s
[2K
| Adam | epoch: 004 | loss: 0.35131 - acc: 0.8598 -- iter: 0704/1559
[A[ATraining Step: 170  | total loss: [1m[32m0.33209[0m[0m | time: 176.909s
[2K
| Adam | epoch: 004 | loss: 0.33209 - acc: 0.8707 -- iter: 0736/1559
[A[ATraining Step: 171  | total loss: [1m[32m0.33633[0m[0m | time: 184.618s
[2K
| Adam | epoch: 004 | loss: 0.33633 - acc: 0.8617 -- iter: 0768/1559
[A[ATraining Step: 172  | total loss: [1m[32m0.33911[0m[0m | time: 192.610s
[2K
| Adam | epoch: 004 | loss: 0.33911 - acc: 0.8599 -- iter: 0800/1559
[A[ATraining Step: 173  | total loss: [1m[32m0.34064[0m[0m | time: 200.384s
[2K
| Adam | epoch: 004 | loss: 0.34064 - acc: 0.8677 -- iter: 0832/1559
[A[ATraining Step: 174  | total loss: [1m[32m0.33247[0m[0m | time: 208.167s
[2K
| Adam | epoch: 004 | loss: 0.33247 - acc: 0.8747 -- iter: 0864/1559
[A[ATraining Step: 175  | total loss: [1m[32m0.33401[0m[0m | time: 215.957s
[2K
| Adam | epoch: 004 | loss: 0.33401 - acc: 0.8716 -- iter: 0896/1559
[A[ATraining Step: 176  | total loss: [1m[32m0.33193[0m[0m | time: 223.806s
[2K
| Adam | epoch: 004 | loss: 0.33193 - acc: 0.8719 -- iter: 0928/1559
[A[ATraining Step: 177  | total loss: [1m[32m0.32673[0m[0m | time: 231.601s
[2K
| Adam | epoch: 004 | loss: 0.32673 - acc: 0.8691 -- iter: 0960/1559
[A[ATraining Step: 178  | total loss: [1m[32m0.32877[0m[0m | time: 239.466s
[2K
| Adam | epoch: 004 | loss: 0.32877 - acc: 0.8634 -- iter: 0992/1559
[A[ATraining Step: 179  | total loss: [1m[32m0.31387[0m[0m | time: 247.378s
[2K
| Adam | epoch: 004 | loss: 0.31387 - acc: 0.8709 -- iter: 1024/1559
[A[ATraining Step: 180  | total loss: [1m[32m0.32500[0m[0m | time: 255.305s
[2K
| Adam | epoch: 004 | loss: 0.32500 - acc: 0.8681 -- iter: 1056/1559
[A[ATraining Step: 181  | total loss: [1m[32m0.32981[0m[0m | time: 263.407s
[2K
| Adam | epoch: 004 | loss: 0.32981 - acc: 0.8720 -- iter: 1088/1559
[A[ATraining Step: 182  | total loss: [1m[32m0.32819[0m[0m | time: 271.154s
[2K
| Adam | epoch: 004 | loss: 0.32819 - acc: 0.8723 -- iter: 1120/1559
[A[ATraining Step: 183  | total loss: [1m[32m0.32749[0m[0m | time: 278.905s
[2K
| Adam | epoch: 004 | loss: 0.32749 - acc: 0.8757 -- iter: 1152/1559
[A[ATraining Step: 184  | total loss: [1m[32m0.30349[0m[0m | time: 286.932s
[2K
| Adam | epoch: 004 | loss: 0.30349 - acc: 0.8881 -- iter: 1184/1559
[A[ATraining Step: 185  | total loss: [1m[32m0.28826[0m[0m | time: 294.585s
[2K
| Adam | epoch: 004 | loss: 0.28826 - acc: 0.8962 -- iter: 1216/1559
[A[ATraining Step: 186  | total loss: [1m[32m0.27388[0m[0m | time: 302.398s
[2K
| Adam | epoch: 004 | loss: 0.27388 - acc: 0.9034 -- iter: 1248/1559
[A[ATraining Step: 187  | total loss: [1m[32m0.26855[0m[0m | time: 310.324s
[2K
| Adam | epoch: 004 | loss: 0.26855 - acc: 0.9037 -- iter: 1280/1559
[A[ATraining Step: 188  | total loss: [1m[32m0.27239[0m[0m | time: 318.251s
[2K
| Adam | epoch: 004 | loss: 0.27239 - acc: 0.8977 -- iter: 1312/1559
[A[ATraining Step: 189  | total loss: [1m[32m0.26927[0m[0m | time: 326.067s
[2K
| Adam | epoch: 004 | loss: 0.26927 - acc: 0.8954 -- iter: 1344/1559
[A[ATraining Step: 190  | total loss: [1m[32m0.26887[0m[0m | time: 333.923s
[2K
| Adam | epoch: 004 | loss: 0.26887 - acc: 0.8965 -- iter: 1376/1559
[A[ATraining Step: 191  | total loss: [1m[32m0.27849[0m[0m | time: 341.846s
[2K
| Adam | epoch: 004 | loss: 0.27849 - acc: 0.8912 -- iter: 1408/1559
[A[ATraining Step: 192  | total loss: [1m[32m0.29171[0m[0m | time: 349.785s
[2K
| Adam | epoch: 004 | loss: 0.29171 - acc: 0.8927 -- iter: 1440/1559
[A[ATraining Step: 193  | total loss: [1m[32m0.28512[0m[0m | time: 357.652s
[2K
| Adam | epoch: 004 | loss: 0.28512 - acc: 0.8910 -- iter: 1472/1559
[A[ATraining Step: 194  | total loss: [1m[32m0.27851[0m[0m | time: 365.750s
[2K
| Adam | epoch: 004 | loss: 0.27851 - acc: 0.8925 -- iter: 1504/1559
[A[ATraining Step: 195  | total loss: [1m[32m0.26897[0m[0m | time: 373.817s
[2K
| Adam | epoch: 004 | loss: 0.26897 - acc: 0.8970 -- iter: 1536/1559
[A[ATraining Step: 196  | total loss: [1m[32m0.26226[0m[0m | time: 403.077s
[2K
| Adam | epoch: 004 | loss: 0.26226 - acc: 0.8979 | val_loss: 0.95389 - val_acc: 0.6660 -- iter: 1559/1559
--
Training Step: 197  | total loss: [1m[32m0.27007[0m[0m | time: 7.769s
[2K
| Adam | epoch: 005 | loss: 0.27007 - acc: 0.8894 -- iter: 0032/1559
[A[ATraining Step: 198  | total loss: [1m[32m0.29308[0m[0m | time: 15.528s
[2K
| Adam | epoch: 005 | loss: 0.29308 - acc: 0.8879 -- iter: 0064/1559
[A[ATraining Step: 199  | total loss: [1m[32m0.29514[0m[0m | time: 21.604s
[2K
| Adam | epoch: 005 | loss: 0.29514 - acc: 0.8898 -- iter: 0096/1559
[A[ATraining Step: 200  | total loss: [1m[32m0.28975[0m[0m | time: 48.842s
[2K
| Adam | epoch: 005 | loss: 0.28975 - acc: 0.8921 | val_loss: 2.82965 - val_acc: 0.5389 -- iter: 0128/1559
--
Training Step: 201  | total loss: [1m[32m0.26745[0m[0m | time: 56.932s
[2K
| Adam | epoch: 005 | loss: 0.26745 - acc: 0.9029 -- iter: 0160/1559
[A[ATraining Step: 202  | total loss: [1m[32m0.25758[0m[0m | time: 64.938s
[2K
| Adam | epoch: 005 | loss: 0.25758 - acc: 0.9063 -- iter: 0192/1559
[A[ATraining Step: 203  | total loss: [1m[32m0.25505[0m[0m | time: 72.815s
[2K
| Adam | epoch: 005 | loss: 0.25505 - acc: 0.9063 -- iter: 0224/1559
[A[ATraining Step: 204  | total loss: [1m[32m0.24752[0m[0m | time: 80.881s
[2K
| Adam | epoch: 005 | loss: 0.24752 - acc: 0.9063 -- iter: 0256/1559
[A[ATraining Step: 205  | total loss: [1m[32m0.26299[0m[0m | time: 88.793s
[2K
| Adam | epoch: 005 | loss: 0.26299 - acc: 0.9001 -- iter: 0288/1559
[A[ATraining Step: 206  | total loss: [1m[32m0.26613[0m[0m | time: 96.692s
[2K
| Adam | epoch: 005 | loss: 0.26613 - acc: 0.8944 -- iter: 0320/1559
[A[ATraining Step: 207  | total loss: [1m[32m0.27028[0m[0m | time: 104.460s
[2K
| Adam | epoch: 005 | loss: 0.27028 - acc: 0.8894 -- iter: 0352/1559
[A[ATraining Step: 208  | total loss: [1m[32m0.25094[0m[0m | time: 112.384s
[2K
| Adam | epoch: 005 | loss: 0.25094 - acc: 0.8973 -- iter: 0384/1559
[A[ATraining Step: 209  | total loss: [1m[32m0.23928[0m[0m | time: 123.796s
[2K
| Adam | epoch: 005 | loss: 0.23928 - acc: 0.9013 -- iter: 0416/1559
[A[ATraining Step: 210  | total loss: [1m[32m0.26373[0m[0m | time: 136.637s
[2K
| Adam | epoch: 005 | loss: 0.26373 - acc: 0.8956 -- iter: 0448/1559
[A[ATraining Step: 211  | total loss: [1m[32m0.26430[0m[0m | time: 150.503s
[2K
| Adam | epoch: 005 | loss: 0.26430 - acc: 0.8841 -- iter: 0480/1559
[A[ATraining Step: 212  | total loss: [1m[32m0.27910[0m[0m | time: 165.344s
[2K
| Adam | epoch: 005 | loss: 0.27910 - acc: 0.8801 -- iter: 0512/1559
[A[ATraining Step: 213  | total loss: [1m[32m0.28122[0m[0m | time: 179.539s
[2K
| Adam | epoch: 005 | loss: 0.28122 - acc: 0.8733 -- iter: 0544/1559
[A[ATraining Step: 214  | total loss: [1m[32m0.31550[0m[0m | time: 193.770s
[2K
| Adam | epoch: 005 | loss: 0.31550 - acc: 0.8641 -- iter: 0576/1559
[A[ATraining Step: 215  | total loss: [1m[32m0.32493[0m[0m | time: 207.555s
[2K
| Adam | epoch: 005 | loss: 0.32493 - acc: 0.8558 -- iter: 0608/1559
[A[ATraining Step: 216  | total loss: [1m[32m0.34115[0m[0m | time: 222.410s
[2K
| Adam | epoch: 005 | loss: 0.34115 - acc: 0.8609 -- iter: 0640/1559
[A[ATraining Step: 217  | total loss: [1m[32m0.33239[0m[0m | time: 240.722s
[2K
| Adam | epoch: 005 | loss: 0.33239 - acc: 0.8623 -- iter: 0672/1559
[A[ATraining Step: 218  | total loss: [1m[32m0.31657[0m[0m | time: 255.612s
[2K
| Adam | epoch: 005 | loss: 0.31657 - acc: 0.8698 -- iter: 0704/1559
[A[ATraining Step: 219  | total loss: [1m[32m0.31288[0m[0m | time: 272.673s
[2K
| Adam | epoch: 005 | loss: 0.31288 - acc: 0.8735 -- iter: 0736/1559
[A[ATraining Step: 220  | total loss: [1m[32m0.32026[0m[0m | time: 327.881s
[2K
| Adam | epoch: 005 | loss: 0.32026 - acc: 0.8705 -- iter: 0768/1559
[A[ATraining Step: 221  | total loss: [1m[32m0.31522[0m[0m | time: 358.366s
[2K
| Adam | epoch: 005 | loss: 0.31522 - acc: 0.8678 -- iter: 0800/1559
[A[ATraining Step: 222  | total loss: [1m[32m0.32263[0m[0m | time: 375.349s
[2K
| Adam | epoch: 005 | loss: 0.32263 - acc: 0.8654 -- iter: 0832/1559
[A[ATraining Step: 223  | total loss: [1m[32m0.30723[0m[0m | time: 394.108s
[2K
| Adam | epoch: 005 | loss: 0.30723 - acc: 0.8726 -- iter: 0864/1559
[A[ATraining Step: 224  | total loss: [1m[32m0.33931[0m[0m | time: 409.553s
[2K
| Adam | epoch: 005 | loss: 0.33931 - acc: 0.8635 -- iter: 0896/1559
[A[ATraining Step: 225  | total loss: [1m[32m0.32361[0m[0m | time: 423.654s
[2K
| Adam | epoch: 005 | loss: 0.32361 - acc: 0.8646 -- iter: 0928/1559
[A[ATraining Step: 226  | total loss: [1m[32m0.30460[0m[0m | time: 432.287s
[2K
| Adam | epoch: 005 | loss: 0.30460 - acc: 0.8750 -- iter: 0960/1559
[A[ATraining Step: 227  | total loss: [1m[32m0.31129[0m[0m | time: 445.063s
[2K
| Adam | epoch: 005 | loss: 0.31129 - acc: 0.8625 -- iter: 0992/1559
[A[ATraining Step: 228  | total loss: [1m[32m0.29446[0m[0m | time: 458.539s
[2K
| Adam | epoch: 005 | loss: 0.29446 - acc: 0.8732 -- iter: 1024/1559
[A[ATraining Step: 229  | total loss: [1m[32m0.27600[0m[0m | time: 475.394s
[2K
| Adam | epoch: 005 | loss: 0.27600 - acc: 0.8827 -- iter: 1056/1559
[A[ATraining Step: 230  | total loss: [1m[32m0.27635[0m[0m | time: 522.760s
[2K
| Adam | epoch: 005 | loss: 0.27635 - acc: 0.8819 -- iter: 1088/1559
[A[ATraining Step: 231  | total loss: [1m[32m0.26219[0m[0m | time: 565.607s
[2K
| Adam | epoch: 005 | loss: 0.26219 - acc: 0.8906 -- iter: 1120/1559
[A[ATraining Step: 232  | total loss: [1m[32m0.27168[0m[0m | time: 590.373s
[2K
| Adam | epoch: 005 | loss: 0.27168 - acc: 0.8797 -- iter: 1152/1559
[A[ATraining Step: 233  | total loss: [1m[32m0.27407[0m[0m | time: 625.212s
[2K
| Adam | epoch: 005 | loss: 0.27407 - acc: 0.8855 -- iter: 1184/1559
[A[ATraining Step: 234  | total loss: [1m[32m0.25836[0m[0m | time: 647.658s
[2K
| Adam | epoch: 005 | loss: 0.25836 - acc: 0.8907 -- iter: 1216/1559
[A[ATraining Step: 235  | total loss: [1m[32m0.25948[0m[0m | time: 676.050s
[2K
| Adam | epoch: 005 | loss: 0.25948 - acc: 0.8922 -- iter: 1248/1559
[A[ATraining Step: 236  | total loss: [1m[32m0.25937[0m[0m | time: 690.129s
[2K
| Adam | epoch: 005 | loss: 0.25937 - acc: 0.8905 -- iter: 1280/1559
[A[ATraining Step: 237  | total loss: [1m[32m0.25674[0m[0m | time: 703.622s
[2K
| Adam | epoch: 005 | loss: 0.25674 - acc: 0.8890 -- iter: 1312/1559
[A[ATraining Step: 238  | total loss: [1m[32m0.24474[0m[0m | time: 771.146s
[2K
| Adam | epoch: 005 | loss: 0.24474 - acc: 0.8969 -- iter: 1344/1559
[A[ATraining Step: 239  | total loss: [1m[32m0.25557[0m[0m | time: 798.430s
[2K
| Adam | epoch: 005 | loss: 0.25557 - acc: 0.8916 -- iter: 1376/1559
[A[ATraining Step: 240  | total loss: [1m[32m0.25314[0m[0m | time: 820.622s
[2K
| Adam | epoch: 005 | loss: 0.25314 - acc: 0.8993 -- iter: 1408/1559
[A[ATraining Step: 241  | total loss: [1m[32m0.24447[0m[0m | time: 837.030s
[2K
| Adam | epoch: 005 | loss: 0.24447 - acc: 0.9000 -- iter: 1440/1559
[A[ATraining Step: 242  | total loss: [1m[32m0.26498[0m[0m | time: 852.006s
[2K
| Adam | epoch: 005 | loss: 0.26498 - acc: 0.9006 -- iter: 1472/1559
[A[ATraining Step: 243  | total loss: [1m[32m0.25828[0m[0m | time: 873.154s
[2K
| Adam | epoch: 005 | loss: 0.25828 - acc: 0.9043 -- iter: 1504/1559
[A[ATraining Step: 244  | total loss: [1m[32m0.27137[0m[0m | time: 886.545s
[2K
| Adam | epoch: 005 | loss: 0.27137 - acc: 0.8983 -- iter: 1536/1559
[A[ATraining Step: 245  | total loss: [1m[32m0.26820[0m[0m | time: 1004.633s
[2K
| Adam | epoch: 005 | loss: 0.26820 - acc: 0.8959 | val_loss: 0.58018 - val_acc: 0.7541 -- iter: 1559/1559
--
Validation AUC:0.8891592733417828
Validation AUPRC:0.8917468652271396
Test AUC:0.9123235887096774
Test AUPRC:0.9244988141564437
BestTestF1Score	0.83	0.65	0.82	0.83	0.82	204	42	198	44	0.85
BestTestMCCScore	0.83	0.65	0.83	0.84	0.81	202	39	201	46	0.87
BestTestAccuracyScore	0.83	0.65	0.83	0.84	0.81	202	39	201	46	0.87
BestValidationF1Score	0.8	0.63	0.82	0.82	0.77	173	37	226	52	0.85
BestValidationMCC	0.79	0.64	0.82	0.85	0.74	167	30	233	58	0.87
BestValidationAccuracy	0.79	0.64	0.82	0.85	0.74	167	30	233	58	0.87
TestPredictions (Threshold:0.87)
CHEMBL504034,TP,ACT,1.0	CHEMBL411799,TP,ACT,0.9800000190734863	CHEMBL55994,TN,INACT,0.36000001430511475	CHEMBL1277990,TN,INACT,0.4000000059604645	CHEMBL157084,TP,ACT,1.0	CHEMBL475779,TN,INACT,0.5899999737739563	CHEMBL453398,TP,ACT,1.0	CHEMBL501050,TP,ACT,1.0	CHEMBL359934,TN,INACT,0.20999999344348907	CHEMBL589413,TN,INACT,0.09000000357627869	CHEMBL378175,FP,INACT,0.8700000047683716	CHEMBL1241682,TN,INACT,0.23000000417232513	CHEMBL2408210,TP,ACT,0.9100000262260437	CHEMBL607581,TN,INACT,0.10999999940395355	CHEMBL194958,TP,ACT,1.0	CHEMBL1172418,TN,INACT,0.47999998927116394	CHEMBL269620,TP,ACT,1.0	CHEMBL160846,TP,ACT,1.0	CHEMBL110065,TN,INACT,0.6700000166893005	CHEMBL1821888,TN,INACT,0.2199999988079071	CHEMBL3133826,FP,INACT,0.9800000190734863	CHEMBL452980,TP,ACT,1.0	CHEMBL592707,TP,ACT,0.9900000095367432	CHEMBL220444,FP,INACT,1.0	CHEMBL3633940,FN,ACT,0.75	CHEMBL497803,TP,ACT,1.0	CHEMBL598377,TP,ACT,1.0	CHEMBL589259,TN,INACT,0.7099999785423279	CHEMBL539433,TN,INACT,0.029999999329447746	CHEMBL3344218,TP,ACT,1.0	CHEMBL1958212,FN,ACT,0.5699999928474426	CHEMBL106379,TN,INACT,0.3799999952316284	CHEMBL2011296,TN,INACT,0.8299999833106995	CHEMBL510730,TP,ACT,0.9200000166893005	CHEMBL247512,TP,ACT,1.0	CHEMBL499534,TP,ACT,1.0	CHEMBL456936,TN,INACT,0.4099999964237213	CHEMBL1630578,FP,INACT,0.8999999761581421	CHEMBL204625,TP,ACT,1.0	CHEMBL273789,TP,ACT,1.0	CHEMBL2325092,TP,ACT,0.8899999856948853	CHEMBL1793843,TN,INACT,0.38999998569488525	CHEMBL3104853,TN,INACT,0.20000000298023224	CHEMBL417950,FP,INACT,0.9100000262260437	CHEMBL77067,TN,INACT,0.029999999329447746	CHEMBL430571,TP,ACT,1.0	CHEMBL3680394,TN,INACT,0.029999999329447746	CHEMBL3436360,TP,ACT,1.0	CHEMBL1240683,TN,INACT,0.25	CHEMBL566350,TP,ACT,1.0	CHEMBL246687,TP,ACT,1.0	CHEMBL217090,FP,INACT,0.9900000095367432	CHEMBL1382642,FP,INACT,0.9700000286102295	CHEMBL296407,FN,ACT,0.3199999928474426	CHEMBL2148044,TP,ACT,1.0	CHEMBL85021,FN,ACT,0.3799999952316284	CHEMBL114728,TP,ACT,0.9700000286102295	CHEMBL414960,FN,ACT,0.4099999964237213	CHEMBL3344219,TP,ACT,0.9800000190734863	CHEMBL460731,TP,ACT,1.0	CHEMBL3342105,TN,INACT,0.30000001192092896	CHEMBL2437301,TN,INACT,0.4300000071525574	CHEMBL307179,TN,INACT,0.05999999865889549	CHEMBL3261190,TN,INACT,0.4000000059604645	CHEMBL2409594,TN,INACT,0.05000000074505806	CHEMBL1559959,TN,INACT,0.4099999964237213	CHEMBL335628,TN,INACT,0.07000000029802322	CHEMBL1916951,TN,INACT,0.029999999329447746	CHEMBL3623847,TN,INACT,0.8299999833106995	CHEMBL45149,TN,INACT,0.11999999731779099	CHEMBL2205026,FN,ACT,0.4399999976158142	CHEMBL427671,TP,ACT,0.9900000095367432	CHEMBL521734,TN,INACT,0.6899999976158142	CHEMBL1241948,TN,INACT,0.23000000417232513	CHEMBL3098326,TN,INACT,0.36000001430511475	CHEMBL381604,TP,ACT,1.0	CHEMBL197538,FP,INACT,1.0	CHEMBL3586444,TN,INACT,0.07000000029802322	CHEMBL131256,TN,INACT,0.8199999928474426	CHEMBL1256430,TP,ACT,1.0	CHEMBL1241390,TN,INACT,0.05999999865889549	CHEMBL1254363,TN,INACT,0.12999999523162842	CHEMBL215716,TP,ACT,1.0	CHEMBL591051,FP,INACT,0.9200000166893005	CHEMBL134030,TN,INACT,0.12999999523162842	CHEMBL155607,TN,INACT,0.4300000071525574	CHEMBL585299,TP,ACT,1.0	CHEMBL1958021,TP,ACT,1.0	CHEMBL565084,TN,INACT,0.800000011920929	CHEMBL3325471,FN,ACT,0.4099999964237213	CHEMBL116211,TN,INACT,0.09000000357627869	CHEMBL3143230,TN,INACT,0.6399999856948853	CHEMBL1910756,TN,INACT,0.1599999964237213	CHEMBL416444,FP,INACT,0.8700000047683716	CHEMBL1612732,TN,INACT,0.5699999928474426	CHEMBL372692,TP,ACT,1.0	CHEMBL149603,TN,INACT,0.18000000715255737	CHEMBL369967,TP,ACT,0.9900000095367432	CHEMBL3357635,TP,ACT,0.9800000190734863	CHEMBL2335172,FN,ACT,0.05999999865889549	CHEMBL205059,TP,ACT,1.0	CHEMBL1923022,TP,ACT,1.0	CHEMBL1171688,TN,INACT,0.46000000834465027	CHEMBL941,TN,INACT,0.5199999809265137	CHEMBL1093815,TP,ACT,0.9599999785423279	CHEMBL309937,TN,INACT,0.10000000149011612	CHEMBL3344209,TP,ACT,1.0	CHEMBL519891,TN,INACT,0.7799999713897705	CHEMBL1933737,TN,INACT,0.30000001192092896	CHEMBL154969,TN,INACT,0.009999999776482582	CHEMBL55993,TN,INACT,0.6600000262260437	CHEMBL2336582,TN,INACT,0.28999999165534973	CHEMBL206003,TP,ACT,1.0	CHEMBL523059,FP,INACT,0.9200000166893005	CHEMBL1688213,TN,INACT,0.019999999552965164	CHEMBL22978,TN,INACT,0.3499999940395355	CHEMBL160303,TP,ACT,1.0	CHEMBL1077107,TN,INACT,0.0	CHEMBL808,FP,INACT,0.9399999976158142	CHEMBL592141,TN,INACT,0.8500000238418579	CHEMBL466614,TP,ACT,1.0	CHEMBL258818,FP,INACT,0.9800000190734863	CHEMBL3133820,FN,ACT,0.3799999952316284	CHEMBL205572,TN,INACT,0.8100000023841858	CHEMBL939,TP,ACT,0.9399999976158142	CHEMBL2036727,TN,INACT,0.4000000059604645	CHEMBL435831,TN,INACT,0.029999999329447746	CHEMBL3633936,TP,ACT,1.0	CHEMBL55360,TN,INACT,0.33000001311302185	CHEMBL428777,TP,ACT,1.0	CHEMBL132399,TN,INACT,0.15000000596046448	CHEMBL2333164,TP,ACT,0.9599999785423279	CHEMBL1078965,TN,INACT,0.20999999344348907	CHEMBL392774,TP,ACT,1.0	CHEMBL443523,FN,ACT,0.4399999976158142	CHEMBL598163,TP,ACT,0.9900000095367432	CHEMBL1090361,FN,ACT,0.07000000029802322	CHEMBL66127,FP,INACT,0.8999999761581421	CHEMBL255291,FN,ACT,0.550000011920929	CHEMBL3436357,TP,ACT,0.9900000095367432	CHEMBL245868,TP,ACT,1.0	CHEMBL3216211,TN,INACT,0.4300000071525574	CHEMBL2179826,TN,INACT,0.6100000143051147	CHEMBL1641996,TN,INACT,0.10000000149011612	CHEMBL2029520,TN,INACT,0.03999999910593033	CHEMBL230786,TP,ACT,1.0	CHEMBL76642,TN,INACT,0.11999999731779099	CHEMBL1242033,FP,INACT,0.9300000071525574	CHEMBL1958034,TP,ACT,1.0	CHEMBL246072,TP,ACT,1.0	CHEMBL143212,FN,ACT,0.7699999809265137	CHEMBL230574,TP,ACT,1.0	CHEMBL2071602,TP,ACT,1.0	CHEMBL33175,TN,INACT,0.10999999940395355	CHEMBL501705,TP,ACT,1.0	CHEMBL2408045,TP,ACT,0.9599999785423279	CHEMBL65376,FN,ACT,0.6100000143051147	CHEMBL94123,TP,ACT,1.0	CHEMBL490570,TN,INACT,0.23999999463558197	CHEMBL207247,TP,ACT,0.9900000095367432	CHEMBL77338,TN,INACT,0.5600000023841858	CHEMBL507714,TP,ACT,0.9900000095367432	CHEMBL194349,TP,ACT,0.9900000095367432	CHEMBL556746,TN,INACT,0.2800000011920929	CHEMBL70360,TN,INACT,0.0	CHEMBL2325097,TP,ACT,1.0	CHEMBL1087054,TN,INACT,0.17000000178813934	CHEMBL488811,FP,INACT,0.8999999761581421	CHEMBL2425111,TN,INACT,0.09000000357627869	CHEMBL68534,TN,INACT,0.550000011920929	CHEMBL2408211,TP,ACT,1.0	CHEMBL434827,TP,ACT,0.9900000095367432	CHEMBL402113,TP,ACT,0.9900000095367432	CHEMBL309016,TN,INACT,0.17000000178813934	CHEMBL2047248,TN,INACT,0.23999999463558197	CHEMBL405059,TN,INACT,0.7699999809265137	CHEMBL246356,FP,INACT,0.8999999761581421	CHEMBL400858,TP,ACT,0.8999999761581421	CHEMBL604893,TP,ACT,1.0	CHEMBL1630114,TP,ACT,0.9900000095367432	CHEMBL3680532,TN,INACT,0.11999999731779099	CHEMBL421047,FN,ACT,0.8399999737739563	CHEMBL1922902,FN,ACT,0.6499999761581421	CHEMBL258282,TP,ACT,1.0	CHEMBL248108,TP,ACT,1.0	CHEMBL1080221,TN,INACT,0.07999999821186066	CHEMBL305660,FN,ACT,0.09000000357627869	CHEMBL510845,TP,ACT,1.0	CHEMBL2348415,TP,ACT,1.0	CHEMBL3661096,FP,INACT,0.9300000071525574	CHEMBL181742,TP,ACT,0.9599999785423279	CHEMBL209511,TN,INACT,0.009999999776482582	CHEMBL601828,TP,ACT,0.9900000095367432	CHEMBL3401291,FP,INACT,0.9900000095367432	CHEMBL1645469,FN,ACT,0.8399999737739563	CHEMBL3133818,TP,ACT,0.8700000047683716	CHEMBL1807520,TN,INACT,0.05999999865889549	CHEMBL501709,TN,INACT,0.8600000143051147	CHEMBL148630,TN,INACT,0.03999999910593033	CHEMBL1170459,TP,ACT,0.949999988079071	CHEMBL3657215,TN,INACT,0.5099999904632568	CHEMBL311119,TN,INACT,0.10999999940395355	CHEMBL281300,FN,ACT,0.25999999046325684	CHEMBL92882,TP,ACT,1.0	CHEMBL201307,FP,INACT,0.9900000095367432	CHEMBL434312,TN,INACT,0.27000001072883606	CHEMBL248321,TP,ACT,1.0	CHEMBL438610,TN,INACT,0.11999999731779099	CHEMBL483321,TP,ACT,1.0	CHEMBL597752,TP,ACT,0.9399999976158142	CHEMBL519757,TP,ACT,1.0	CHEMBL514938,TP,ACT,1.0	CHEMBL333454,FN,ACT,0.6700000166893005	CHEMBL1077069,TN,INACT,0.3700000047683716	CHEMBL215171,TP,ACT,1.0	CHEMBL1688206,TN,INACT,0.28999999165534973	CHEMBL475768,TP,ACT,1.0	CHEMBL435054,TN,INACT,0.05999999865889549	CHEMBL1163521,FP,INACT,0.9900000095367432	CHEMBL498249,TN,INACT,0.14000000059604645	CHEMBL1958210,TP,ACT,1.0	CHEMBL2048911,TP,ACT,0.9599999785423279	CHEMBL1090362,TP,ACT,0.9800000190734863	CHEMBL30432,FN,ACT,0.5799999833106995	CHEMBL1933074,TN,INACT,0.029999999329447746	CHEMBL3233785,TP,ACT,0.9800000190734863	CHEMBL203645,TP,ACT,0.949999988079071	CHEMBL3357642,TP,ACT,0.9900000095367432	CHEMBL1081754,FP,INACT,0.9700000286102295	CHEMBL1095445,TN,INACT,0.2199999988079071	CHEMBL334891,TN,INACT,0.10999999940395355	CHEMBL116595,FN,ACT,0.7799999713897705	CHEMBL363607,TN,INACT,0.2199999988079071	CHEMBL1934627,TP,ACT,1.0	CHEMBL293251,TN,INACT,0.10999999940395355	CHEMBL207869,TP,ACT,1.0	CHEMBL1928944,TP,ACT,0.8899999856948853	CHEMBL270556,FP,INACT,0.9300000071525574	CHEMBL267213,FP,INACT,0.949999988079071	CHEMBL3115321,TN,INACT,0.4300000071525574	CHEMBL3115324,TN,INACT,0.30000001192092896	CHEMBL56964,TN,INACT,0.029999999329447746	CHEMBL446250,TP,ACT,0.9599999785423279	CHEMBL1241684,TN,INACT,0.6100000143051147	CHEMBL1830257,TN,INACT,0.46000000834465027	CHEMBL2408054,TP,ACT,0.9900000095367432	CHEMBL25186,TN,INACT,0.009999999776482582	CHEMBL511451,TN,INACT,0.15000000596046448	CHEMBL115519,TN,INACT,0.5	CHEMBL233338,FP,INACT,0.9700000286102295	CHEMBL3693949,TN,INACT,0.5600000023841858	CHEMBL79808,TN,INACT,0.23999999463558197	CHEMBL189584,TN,INACT,0.8199999928474426	CHEMBL1173023,FP,INACT,0.9800000190734863	CHEMBL599192,TN,INACT,0.05999999865889549	CHEMBL75969,FP,INACT,0.9900000095367432	CHEMBL28418,TP,ACT,0.9399999976158142	CHEMBL439425,TP,ACT,0.9900000095367432	CHEMBL497222,FN,ACT,0.7599999904632568	CHEMBL496629,TP,ACT,0.9700000286102295	CHEMBL495979,TP,ACT,1.0	CHEMBL3344213,TP,ACT,1.0	CHEMBL14627,TP,ACT,1.0	CHEMBL246073,TP,ACT,1.0	CHEMBL138940,TP,ACT,1.0	CHEMBL3261191,TN,INACT,0.6800000071525574	CHEMBL301018,TP,ACT,0.8999999761581421	CHEMBL1688209,TN,INACT,0.019999999552965164	CHEMBL1242665,TN,INACT,0.6299999952316284	CHEMBL566233,TP,ACT,1.0	CHEMBL438805,TP,ACT,0.9900000095367432	CHEMBL324718,FN,ACT,0.4000000059604645	CHEMBL341946,TN,INACT,0.5099999904632568	CHEMBL2064400,TN,INACT,0.5400000214576721	CHEMBL3290148,TP,ACT,0.9900000095367432	CHEMBL1241492,TN,INACT,0.550000011920929	CHEMBL247914,TP,ACT,1.0	CHEMBL3237851,TN,INACT,0.4000000059604645	CHEMBL3133832,FN,ACT,0.8399999737739563	CHEMBL203661,TP,ACT,1.0	CHEMBL422347,TP,ACT,1.0	CHEMBL3092308,TP,ACT,0.9700000286102295	CHEMBL378144,FN,ACT,0.7099999785423279	CHEMBL2348418,TP,ACT,1.0	CHEMBL2322993,FP,INACT,0.9200000166893005	CHEMBL1830259,TN,INACT,0.4000000059604645	CHEMBL1958039,TP,ACT,1.0	CHEMBL77085,TN,INACT,0.17000000178813934	CHEMBL500115,TP,ACT,1.0	CHEMBL583218,TP,ACT,1.0	CHEMBL1242118,TN,INACT,0.07000000029802322	CHEMBL3586175,FP,INACT,0.9599999785423279	CHEMBL315546,FP,INACT,0.8999999761581421	CHEMBL2409588,TN,INACT,0.38999998569488525	CHEMBL279481,TN,INACT,0.20000000298023224	CHEMBL2437475,TN,INACT,0.44999998807907104	CHEMBL314146,TN,INACT,0.30000001192092896	CHEMBL2316785,FN,ACT,0.23999999463558197	CHEMBL411284,TN,INACT,0.5099999904632568	CHEMBL2029515,TN,INACT,0.5400000214576721	CHEMBL327838,TP,ACT,1.0	CHEMBL2048797,TP,ACT,0.9900000095367432	CHEMBL3813728,TP,ACT,1.0	CHEMBL77261,FP,INACT,0.9900000095367432	CHEMBL3665663,TN,INACT,0.7300000190734863	CHEMBL507821,TP,ACT,1.0	CHEMBL1683974,TP,ACT,0.9800000190734863	CHEMBL1256423,TP,ACT,1.0	CHEMBL450929,TN,INACT,0.009999999776482582	CHEMBL3596523,TN,INACT,0.3100000023841858	CHEMBL1683968,TP,ACT,1.0	CHEMBL3633929,TP,ACT,1.0	CHEMBL197689,TP,ACT,1.0	CHEMBL521201,TN,INACT,0.03999999910593033	CHEMBL3745929,FP,INACT,0.9300000071525574	CHEMBL245667,TP,ACT,1.0	CHEMBL402149,FN,ACT,0.7300000190734863	CHEMBL3680375,TP,ACT,1.0	CHEMBL403594,TP,ACT,1.0	CHEMBL245867,TP,ACT,1.0	CHEMBL517123,TP,ACT,1.0	CHEMBL1242471,TN,INACT,0.17000000178813934	CHEMBL2337362,TN,INACT,0.3100000023841858	CHEMBL3344215,TP,ACT,1.0	CHEMBL2437226,TP,ACT,1.0	CHEMBL1922903,TP,ACT,1.0	CHEMBL1828882,TN,INACT,0.09000000357627869	CHEMBL1922224,TN,INACT,0.3199999928474426	CHEMBL380042,TN,INACT,0.05999999865889549	CHEMBL1923009,TP,ACT,1.0	CHEMBL2437227,TP,ACT,0.9900000095367432	CHEMBL3814021,TP,ACT,1.0	CHEMBL299763,TN,INACT,0.6399999856948853	CHEMBL130871,TN,INACT,0.03999999910593033	CHEMBL1796180,TN,INACT,0.05000000074505806	CHEMBL427961,TP,ACT,0.8799999952316284	CHEMBL1090359,FN,ACT,0.699999988079071	CHEMBL302113,TN,INACT,0.6399999856948853	CHEMBL93537,TP,ACT,1.0	CHEMBL597773,TP,ACT,0.9800000190734863	CHEMBL54091,TP,ACT,0.949999988079071	CHEMBL592427,TP,ACT,0.9700000286102295	CHEMBL395665,TN,INACT,0.20000000298023224	CHEMBL3237858,TN,INACT,0.5099999904632568	CHEMBL3657211,TN,INACT,0.4399999976158142	CHEMBL590877,FP,INACT,0.9200000166893005	CHEMBL589561,TP,ACT,0.9800000190734863	CHEMBL214487,TP,ACT,1.0	CHEMBL291313,TN,INACT,0.03999999910593033	CHEMBL73625,TN,INACT,0.36000001430511475	CHEMBL2011293,FP,INACT,0.8899999856948853	CHEMBL64459,TN,INACT,0.11999999731779099	CHEMBL2148046,TP,ACT,1.0	CHEMBL54088,TP,ACT,0.9900000095367432	CHEMBL137829,TN,INACT,0.25999999046325684	CHEMBL1256436,TP,ACT,1.0	CHEMBL252246,FN,ACT,0.550000011920929	CHEMBL202621,TP,ACT,1.0	CHEMBL451513,TP,ACT,1.0	CHEMBL1241675,TN,INACT,0.1599999964237213	CHEMBL231099,FN,ACT,0.8500000238418579	CHEMBL339077,TN,INACT,0.10000000149011612	CHEMBL488101,FP,INACT,0.9700000286102295	CHEMBL202425,FN,ACT,0.6899999976158142	CHEMBL15346,TP,ACT,1.0	CHEMBL589120,TN,INACT,0.46000000834465027	CHEMBL1928958,TP,ACT,0.9100000262260437	CHEMBL3436356,TP,ACT,1.0	CHEMBL106840,TN,INACT,0.17000000178813934	CHEMBL2029698,TN,INACT,0.30000001192092896	CHEMBL1688211,TN,INACT,0.46000000834465027	CHEMBL473437,TP,ACT,1.0	CHEMBL132007,TN,INACT,0.11999999731779099	CHEMBL179363,FN,ACT,0.7799999713897705	CHEMBL55592,TN,INACT,0.2199999988079071	CHEMBL601871,TN,INACT,0.49000000953674316	CHEMBL114073,TN,INACT,0.5	CHEMBL78444,TN,INACT,0.3499999940395355	CHEMBL593987,TP,ACT,1.0	CHEMBL3675452,TN,INACT,0.3100000023841858	CHEMBL111443,TN,INACT,0.6299999952316284	CHEMBL2325098,TP,ACT,1.0	CHEMBL539942,TN,INACT,0.20999999344348907	CHEMBL1172802,FN,ACT,0.550000011920929	CHEMBL403435,TP,ACT,1.0	CHEMBL62843,TN,INACT,0.029999999329447746	CHEMBL523573,TP,ACT,1.0	CHEMBL1921813,TP,ACT,0.9900000095367432	CHEMBL1828865,FN,ACT,0.14000000059604645	CHEMBL3814812,TP,ACT,1.0	CHEMBL1958031,FN,ACT,0.5400000214576721	CHEMBL2382017,TN,INACT,0.029999999329447746	CHEMBL426622,TN,INACT,0.10000000149011612	CHEMBL246167,TN,INACT,0.5	CHEMBL1173667,TP,ACT,0.9900000095367432	CHEMBL304442,FN,ACT,0.3199999928474426	CHEMBL367440,TN,INACT,0.7799999713897705	CHEMBL2031311,FN,ACT,0.75	CHEMBL311449,TN,INACT,0.05999999865889549	CHEMBL372112,TP,ACT,0.8700000047683716	CHEMBL3680484,TN,INACT,0.4099999964237213	CHEMBL1829275,TN,INACT,0.17000000178813934	CHEMBL293986,TN,INACT,0.05000000074505806	CHEMBL1683972,TP,ACT,1.0	CHEMBL417478,TP,ACT,0.949999988079071	CHEMBL461113,TP,ACT,1.0	CHEMBL508760,TP,ACT,1.0	CHEMBL2408046,TP,ACT,0.9800000190734863	CHEMBL227103,TP,ACT,0.9599999785423279	CHEMBL1172147,TN,INACT,0.23000000417232513	CHEMBL1933756,TN,INACT,0.25	CHEMBL390156,FP,INACT,0.9900000095367432	CHEMBL3633933,TP,ACT,1.0	CHEMBL1242030,TN,INACT,0.5299999713897705	CHEMBL156797,TN,INACT,0.03999999910593033	CHEMBL366327,TN,INACT,0.17000000178813934	CHEMBL93464,TN,INACT,0.8500000238418579	CHEMBL19996,TN,INACT,0.05999999865889549	CHEMBL1928957,FN,ACT,0.75	CHEMBL1242286,TN,INACT,0.6299999952316284	CHEMBL246489,TP,ACT,1.0	CHEMBL3189172,TN,INACT,0.09000000357627869	CHEMBL2325107,TP,ACT,0.9300000071525574	CHEMBL193681,TP,ACT,0.8700000047683716	CHEMBL1016,FN,ACT,0.47999998927116394	CHEMBL56731,TN,INACT,0.4000000059604645	CHEMBL102765,TN,INACT,0.8299999833106995	CHEMBL604785,FN,ACT,0.4399999976158142	CHEMBL1821883,TN,INACT,0.27000001072883606	CHEMBL216646,TN,INACT,0.09000000357627869	CHEMBL1242846,TN,INACT,0.33000001311302185	CHEMBL1170550,TN,INACT,0.6100000143051147	CHEMBL2048795,TP,ACT,0.9800000190734863	CHEMBL3218000,TP,ACT,0.9900000095367432	CHEMBL590714,TP,ACT,1.0	CHEMBL3344208,TP,ACT,1.0	CHEMBL257861,TP,ACT,1.0	CHEMBL206029,TP,ACT,0.9100000262260437	CHEMBL214689,TP,ACT,1.0	CHEMBL228926,TP,ACT,0.9800000190734863	CHEMBL122522,FN,ACT,0.5400000214576721	CHEMBL1922904,TP,ACT,0.949999988079071	CHEMBL231302,TP,ACT,0.9900000095367432	CHEMBL334801,TP,ACT,0.9800000190734863	CHEMBL3680377,TP,ACT,0.9800000190734863	CHEMBL372293,TP,ACT,1.0	CHEMBL432396,TN,INACT,0.3400000035762787	CHEMBL593306,TP,ACT,0.9900000095367432	CHEMBL1078726,FP,INACT,0.9100000262260437	CHEMBL511172,TN,INACT,0.4000000059604645	CHEMBL513602,TN,INACT,0.33000001311302185	CHEMBL592457,TP,ACT,0.9900000095367432	CHEMBL394465,FN,ACT,0.6600000262260437	CHEMBL284326,TP,ACT,0.9200000166893005	CHEMBL488350,TP,ACT,1.0	CHEMBL344319,TN,INACT,0.15000000596046448	CHEMBL91748,FP,INACT,1.0	CHEMBL311135,TN,INACT,0.029999999329447746	CHEMBL457250,TP,ACT,1.0	CHEMBL150,TN,INACT,0.4699999988079071	CHEMBL150504,TN,INACT,0.3400000035762787	CHEMBL1910268,TN,INACT,0.6499999761581421	CHEMBL1910602,TN,INACT,0.23999999463558197	CHEMBL231205,TP,ACT,1.0	CHEMBL155761,TP,ACT,1.0	CHEMBL1828883,TN,INACT,0.09000000357627869	CHEMBL2315560,TN,INACT,0.20999999344348907	CHEMBL2393372,TN,INACT,0.25	CHEMBL1258118,TP,ACT,1.0	CHEMBL116853,FN,ACT,0.8500000238418579	CHEMBL541445,TN,INACT,0.1599999964237213	CHEMBL346200,FP,INACT,0.9200000166893005	CHEMBL395883,TP,ACT,1.0	CHEMBL3397287,TN,INACT,0.4300000071525574	CHEMBL202360,FN,ACT,0.7300000190734863	CHEMBL201162,TP,ACT,0.8899999856948853	CHEMBL257859,TP,ACT,0.9800000190734863	CHEMBL92356,TP,ACT,0.9700000286102295	CHEMBL86771,TN,INACT,0.009999999776482582	CHEMBL3353409,TN,INACT,0.23999999463558197	CHEMBL381521,TP,ACT,0.9800000190734863	CHEMBL3661094,TN,INACT,0.7300000190734863	CHEMBL392664,TP,ACT,0.9599999785423279	CHEMBL247104,TP,ACT,1.0	CHEMBL1923014,TP,ACT,1.0	CHEMBL1080506,TP,ACT,1.0	CHEMBL572045,FN,ACT,0.3100000023841858	CHEMBL512076,TP,ACT,1.0	

