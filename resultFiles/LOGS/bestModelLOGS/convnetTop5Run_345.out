ImageNetInceptionV2 CHEMBL4477 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	198
Number of inactive compounds :	198
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4477_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4477_adam_0.001_15_0.8/
---------------------------------
Training samples: 250
Validation samples: 79
--
Training Step: 1  | time: 39.521s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/250
[A[ATraining Step: 2  | total loss: [1m[32m0.55298[0m[0m | time: 54.929s
[2K
| Adam | epoch: 001 | loss: 0.55298 - acc: 0.5906 -- iter: 064/250
[A[ATraining Step: 3  | total loss: [1m[32m0.69063[0m[0m | time: 71.209s
[2K
| Adam | epoch: 001 | loss: 0.69063 - acc: 0.5165 -- iter: 096/250
[A[ATraining Step: 4  | total loss: [1m[32m0.58243[0m[0m | time: 84.057s
[2K
| Adam | epoch: 001 | loss: 0.58243 - acc: 0.7151 -- iter: 128/250
[A[ATraining Step: 5  | total loss: [1m[32m0.77063[0m[0m | time: 101.804s
[2K
| Adam | epoch: 001 | loss: 0.77063 - acc: 0.6311 -- iter: 160/250
[A[ATraining Step: 6  | total loss: [1m[32m0.76068[0m[0m | time: 127.736s
[2K
| Adam | epoch: 001 | loss: 0.76068 - acc: 0.6272 -- iter: 192/250
[A[ATraining Step: 7  | total loss: [1m[32m0.64941[0m[0m | time: 150.254s
[2K
| Adam | epoch: 001 | loss: 0.64941 - acc: 0.7009 -- iter: 224/250
[A[ATraining Step: 8  | total loss: [1m[32m0.68451[0m[0m | time: 167.280s
[2K
| Adam | epoch: 001 | loss: 0.68451 - acc: 0.6230 | val_loss: 0.93982 - val_acc: 0.5063 -- iter: 250/250
--
Training Step: 9  | total loss: [1m[32m0.61831[0m[0m | time: 571.414s
[2K
| Adam | epoch: 002 | loss: 0.61831 - acc: 0.6801 -- iter: 032/250
[A[ATraining Step: 10  | total loss: [1m[32m0.51522[0m[0m | time: 855.453s
[2K
| Adam | epoch: 002 | loss: 0.51522 - acc: 0.7631 -- iter: 064/250
[A[ATraining Step: 11  | total loss: [1m[32m0.54985[0m[0m | time: 906.388s
[2K
| Adam | epoch: 002 | loss: 0.54985 - acc: 0.7717 -- iter: 096/250
[A[ATraining Step: 12  | total loss: [1m[32m0.41026[0m[0m | time: 955.313s
[2K
| Adam | epoch: 002 | loss: 0.41026 - acc: 0.8463 -- iter: 128/250
[A[ATraining Step: 13  | total loss: [1m[32m0.37221[0m[0m | time: 973.754s
[2K
| Adam | epoch: 002 | loss: 0.37221 - acc: 0.8318 -- iter: 160/250
[A[ATraining Step: 14  | total loss: [1m[32m0.32208[0m[0m | time: 989.365s
[2K
| Adam | epoch: 002 | loss: 0.32208 - acc: 0.8495 -- iter: 192/250
[A[ATraining Step: 15  | total loss: [1m[32m0.33571[0m[0m | time: 1004.528s
[2K
| Adam | epoch: 002 | loss: 0.33571 - acc: 0.8595 -- iter: 224/250
[A[ATraining Step: 16  | total loss: [1m[32m0.41652[0m[0m | time: 1020.986s
[2K
| Adam | epoch: 002 | loss: 0.41652 - acc: 0.8301 | val_loss: 1.67078 - val_acc: 0.4937 -- iter: 250/250
--
Training Step: 17  | total loss: [1m[32m0.46558[0m[0m | time: 8.336s
[2K
| Adam | epoch: 003 | loss: 0.46558 - acc: 0.7900 -- iter: 032/250
[A[ATraining Step: 18  | total loss: [1m[32m0.40669[0m[0m | time: 16.433s
[2K
| Adam | epoch: 003 | loss: 0.40669 - acc: 0.8228 -- iter: 064/250
[A[ATraining Step: 19  | total loss: [1m[32m0.33431[0m[0m | time: 29.160s
[2K
| Adam | epoch: 003 | loss: 0.33431 - acc: 0.8819 -- iter: 096/250
[A[ATraining Step: 20  | total loss: [1m[32m0.31740[0m[0m | time: 42.610s
[2K
| Adam | epoch: 003 | loss: 0.31740 - acc: 0.8796 -- iter: 128/250
[A[ATraining Step: 21  | total loss: [1m[32m0.28596[0m[0m | time: 55.805s
[2K
| Adam | epoch: 003 | loss: 0.28596 - acc: 0.8879 -- iter: 160/250
[A[ATraining Step: 22  | total loss: [1m[32m0.30762[0m[0m | time: 69.034s
[2K
| Adam | epoch: 003 | loss: 0.30762 - acc: 0.8934 -- iter: 192/250
[A[ATraining Step: 23  | total loss: [1m[32m0.27774[0m[0m | time: 81.776s
[2K
| Adam | epoch: 003 | loss: 0.27774 - acc: 0.9062 -- iter: 224/250
[A[ATraining Step: 24  | total loss: [1m[32m0.21520[0m[0m | time: 100.776s
[2K
| Adam | epoch: 003 | loss: 0.21520 - acc: 0.9326 | val_loss: 0.72088 - val_acc: 0.4937 -- iter: 250/250
--
Training Step: 25  | total loss: [1m[32m0.17178[0m[0m | time: 8.378s
[2K
| Adam | epoch: 004 | loss: 0.17178 - acc: 0.9510 -- iter: 032/250
[A[ATraining Step: 26  | total loss: [1m[32m0.15062[0m[0m | time: 18.631s
[2K
| Adam | epoch: 004 | loss: 0.15062 - acc: 0.9557 -- iter: 064/250
[A[ATraining Step: 27  | total loss: [1m[32m0.12956[0m[0m | time: 29.149s
[2K
| Adam | epoch: 004 | loss: 0.12956 - acc: 0.9572 -- iter: 096/250
[A[ATraining Step: 28  | total loss: [1m[32m0.10589[0m[0m | time: 41.752s
[2K
| Adam | epoch: 004 | loss: 0.10589 - acc: 0.9679 -- iter: 128/250
[A[ATraining Step: 29  | total loss: [1m[32m0.17323[0m[0m | time: 53.973s
[2K
| Adam | epoch: 004 | loss: 0.17323 - acc: 0.9377 -- iter: 160/250
[A[ATraining Step: 30  | total loss: [1m[32m0.16376[0m[0m | time: 66.604s
[2K
| Adam | epoch: 004 | loss: 0.16376 - acc: 0.9450 -- iter: 192/250
[A[ATraining Step: 31  | total loss: [1m[32m0.12912[0m[0m | time: 79.676s
[2K
| Adam | epoch: 004 | loss: 0.12912 - acc: 0.9577 -- iter: 224/250
[A[ATraining Step: 32  | total loss: [1m[32m0.11229[0m[0m | time: 98.310s
[2K
| Adam | epoch: 004 | loss: 0.11229 - acc: 0.9602 | val_loss: 3.76226 - val_acc: 0.5063 -- iter: 250/250
--
Training Step: 33  | total loss: [1m[32m0.12041[0m[0m | time: 10.319s
[2K
| Adam | epoch: 005 | loss: 0.12041 - acc: 0.9621 -- iter: 032/250
[A[ATraining Step: 34  | total loss: [1m[32m0.15663[0m[0m | time: 22.142s
[2K
| Adam | epoch: 005 | loss: 0.15663 - acc: 0.9300 -- iter: 064/250
[A[ATraining Step: 35  | total loss: [1m[32m0.14531[0m[0m | time: 32.701s
[2K
| Adam | epoch: 005 | loss: 0.14531 - acc: 0.9316 -- iter: 096/250
[A[ATraining Step: 36  | total loss: [1m[32m0.14327[0m[0m | time: 43.312s
[2K
| Adam | epoch: 005 | loss: 0.14327 - acc: 0.9377 -- iter: 128/250
[A[ATraining Step: 37  | total loss: [1m[32m0.12013[0m[0m | time: 55.900s
[2K
| Adam | epoch: 005 | loss: 0.12013 - acc: 0.9502 -- iter: 160/250
[A[ATraining Step: 38  | total loss: [1m[32m0.19946[0m[0m | time: 68.469s
[2K
| Adam | epoch: 005 | loss: 0.19946 - acc: 0.9294 -- iter: 192/250
[A[ATraining Step: 39  | total loss: [1m[32m0.22495[0m[0m | time: 80.475s
[2K
| Adam | epoch: 005 | loss: 0.22495 - acc: 0.9249 -- iter: 224/250
[A[ATraining Step: 40  | total loss: [1m[32m0.18677[0m[0m | time: 96.006s
[2K
| Adam | epoch: 005 | loss: 0.18677 - acc: 0.9390 | val_loss: 6.44683 - val_acc: 0.5063 -- iter: 250/250
--
Training Step: 41  | total loss: [1m[32m0.16065[0m[0m | time: 12.506s
[2K
| Adam | epoch: 006 | loss: 0.16065 - acc: 0.9445 -- iter: 032/250
[A[ATraining Step: 42  | total loss: [1m[32m0.13876[0m[0m | time: 24.877s
[2K
| Adam | epoch: 006 | loss: 0.13876 - acc: 0.9545 -- iter: 064/250
[A[ATraining Step: 43  | total loss: [1m[32m0.16072[0m[0m | time: 36.975s
[2K
| Adam | epoch: 006 | loss: 0.16072 - acc: 0.9515 -- iter: 096/250
[A[ATraining Step: 44  | total loss: [1m[32m0.27890[0m[0m | time: 47.307s
[2K
| Adam | epoch: 006 | loss: 0.27890 - acc: 0.9058 -- iter: 128/250
[A[ATraining Step: 45  | total loss: [1m[32m0.26767[0m[0m | time: 57.906s
[2K
| Adam | epoch: 006 | loss: 0.26767 - acc: 0.9153 -- iter: 160/250
[A[ATraining Step: 46  | total loss: [1m[32m0.23347[0m[0m | time: 70.470s
[2K
| Adam | epoch: 006 | loss: 0.23347 - acc: 0.9230 -- iter: 192/250
[A[ATraining Step: 47  | total loss: [1m[32m0.25803[0m[0m | time: 82.940s
[2K
| Adam | epoch: 006 | loss: 0.25803 - acc: 0.9151 -- iter: 224/250
[A[ATraining Step: 48  | total loss: [1m[32m0.25620[0m[0m | time: 94.640s
[2K
| Adam | epoch: 006 | loss: 0.25620 - acc: 0.9087 | val_loss: 3.35098 - val_acc: 0.5063 -- iter: 250/250
--
Training Step: 49  | total loss: [1m[32m0.36499[0m[0m | time: 12.087s
[2K
| Adam | epoch: 007 | loss: 0.36499 - acc: 0.8984 -- iter: 032/250
[A[ATraining Step: 50  | total loss: [1m[32m0.32190[0m[0m | time: 24.642s
[2K
| Adam | epoch: 007 | loss: 0.32190 - acc: 0.9093 -- iter: 064/250
[A[ATraining Step: 51  | total loss: [1m[32m0.28363[0m[0m | time: 36.758s
[2K
| Adam | epoch: 007 | loss: 0.28363 - acc: 0.9232 -- iter: 096/250
[A[ATraining Step: 52  | total loss: [1m[32m0.31252[0m[0m | time: 48.742s
[2K
| Adam | epoch: 007 | loss: 0.31252 - acc: 0.8972 -- iter: 128/250
[A[ATraining Step: 53  | total loss: [1m[32m0.29190[0m[0m | time: 59.672s
[2K
| Adam | epoch: 007 | loss: 0.29190 - acc: 0.9124 -- iter: 160/250
[A[ATraining Step: 54  | total loss: [1m[32m0.30248[0m[0m | time: 69.731s
[2K
| Adam | epoch: 007 | loss: 0.30248 - acc: 0.8916 -- iter: 192/250
[A[ATraining Step: 55  | total loss: [1m[32m0.30535[0m[0m | time: 79.237s
[2K
| Adam | epoch: 007 | loss: 0.30535 - acc: 0.8686 -- iter: 224/250
[A[ATraining Step: 56  | total loss: [1m[32m0.28546[0m[0m | time: 90.918s
[2K
| Adam | epoch: 007 | loss: 0.28546 - acc: 0.8739 | val_loss: 0.81098 - val_acc: 0.6962 -- iter: 250/250
--
Training Step: 57  | total loss: [1m[32m0.27492[0m[0m | time: 15.186s
[2K
| Adam | epoch: 008 | loss: 0.27492 - acc: 0.8827 -- iter: 032/250
[A[ATraining Step: 58  | total loss: [1m[32m0.25996[0m[0m | time: 30.271s
[2K
| Adam | epoch: 008 | loss: 0.25996 - acc: 0.8944 -- iter: 064/250
[A[ATraining Step: 59  | total loss: [1m[32m0.23079[0m[0m | time: 55.195s
[2K
| Adam | epoch: 008 | loss: 0.23079 - acc: 0.9086 -- iter: 096/250
[A[ATraining Step: 60  | total loss: [1m[32m0.21721[0m[0m | time: 67.611s
[2K
| Adam | epoch: 008 | loss: 0.21721 - acc: 0.9166 -- iter: 128/250
[A[ATraining Step: 61  | total loss: [1m[32m0.19431[0m[0m | time: 77.405s
[2K
| Adam | epoch: 008 | loss: 0.19431 - acc: 0.9275 -- iter: 160/250
[A[ATraining Step: 62  | total loss: [1m[32m0.17492[0m[0m | time: 85.707s
[2K
| Adam | epoch: 008 | loss: 0.17492 - acc: 0.9368 -- iter: 192/250
[A[ATraining Step: 63  | total loss: [1m[32m0.15909[0m[0m | time: 93.871s
[2K
| Adam | epoch: 008 | loss: 0.15909 - acc: 0.9448 -- iter: 224/250
[A[ATraining Step: 64  | total loss: [1m[32m0.14163[0m[0m | time: 115.813s
[2K
| Adam | epoch: 008 | loss: 0.14163 - acc: 0.9517 | val_loss: 1.79770 - val_acc: 0.5696 -- iter: 250/250
--
Training Step: 65  | total loss: [1m[32m0.13852[0m[0m | time: 16.763s
[2K
| Adam | epoch: 009 | loss: 0.13852 - acc: 0.9538 -- iter: 032/250
[A[ATraining Step: 66  | total loss: [1m[32m0.12676[0m[0m | time: 31.840s
[2K
| Adam | epoch: 009 | loss: 0.12676 - acc: 0.9556 -- iter: 064/250
[A[ATraining Step: 67  | total loss: [1m[32m0.15260[0m[0m | time: 46.834s
[2K
| Adam | epoch: 009 | loss: 0.15260 - acc: 0.9534 -- iter: 096/250
[A[ATraining Step: 68  | total loss: [1m[32m0.14357[0m[0m | time: 58.843s
[2K
| Adam | epoch: 009 | loss: 0.14357 - acc: 0.9553 -- iter: 128/250
[A[ATraining Step: 69  | total loss: [1m[32m0.12983[0m[0m | time: 68.707s
[2K
| Adam | epoch: 009 | loss: 0.12983 - acc: 0.9605 -- iter: 160/250
[A[ATraining Step: 70  | total loss: [1m[32m0.11691[0m[0m | time: 79.504s
[2K
| Adam | epoch: 009 | loss: 0.11691 - acc: 0.9650 -- iter: 192/250
[A[ATraining Step: 71  | total loss: [1m[32m0.10731[0m[0m | time: 92.184s
[2K
| Adam | epoch: 009 | loss: 0.10731 - acc: 0.9690 -- iter: 224/250
[A[ATraining Step: 72  | total loss: [1m[32m0.09656[0m[0m | time: 112.964s
[2K
| Adam | epoch: 009 | loss: 0.09656 - acc: 0.9725 | val_loss: 0.46702 - val_acc: 0.8228 -- iter: 250/250
--
Training Step: 73  | total loss: [1m[32m0.08682[0m[0m | time: 14.506s
[2K
| Adam | epoch: 010 | loss: 0.08682 - acc: 0.9756 -- iter: 032/250
[A[ATraining Step: 74  | total loss: [1m[32m0.07902[0m[0m | time: 24.138s
[2K
| Adam | epoch: 010 | loss: 0.07902 - acc: 0.9782 -- iter: 064/250
[A[ATraining Step: 75  | total loss: [1m[32m0.07282[0m[0m | time: 34.342s
[2K
| Adam | epoch: 010 | loss: 0.07282 - acc: 0.9806 -- iter: 096/250
[A[ATraining Step: 76  | total loss: [1m[32m0.10970[0m[0m | time: 44.072s
[2K
| Adam | epoch: 010 | loss: 0.10970 - acc: 0.9760 -- iter: 128/250
[A[ATraining Step: 77  | total loss: [1m[32m0.10220[0m[0m | time: 56.292s
[2K
| Adam | epoch: 010 | loss: 0.10220 - acc: 0.9752 -- iter: 160/250
[A[ATraining Step: 78  | total loss: [1m[32m0.09460[0m[0m | time: 71.130s
[2K
| Adam | epoch: 010 | loss: 0.09460 - acc: 0.9778 -- iter: 192/250
[A[ATraining Step: 79  | total loss: [1m[32m0.08555[0m[0m | time: 86.472s
[2K
| Adam | epoch: 010 | loss: 0.08555 - acc: 0.9801 -- iter: 224/250
[A[ATraining Step: 80  | total loss: [1m[32m0.08361[0m[0m | time: 106.251s
[2K
| Adam | epoch: 010 | loss: 0.08361 - acc: 0.9789 | val_loss: 1.30258 - val_acc: 0.6582 -- iter: 250/250
--
Training Step: 81  | total loss: [1m[32m0.08159[0m[0m | time: 13.336s
[2K
| Adam | epoch: 011 | loss: 0.08159 - acc: 0.9772 -- iter: 032/250
[A[ATraining Step: 82  | total loss: [1m[32m0.07535[0m[0m | time: 23.006s
[2K
| Adam | epoch: 011 | loss: 0.07535 - acc: 0.9795 -- iter: 064/250
[A[ATraining Step: 83  | total loss: [1m[32m0.09864[0m[0m | time: 32.962s
[2K
| Adam | epoch: 011 | loss: 0.09864 - acc: 0.9721 -- iter: 096/250
[A[ATraining Step: 84  | total loss: [1m[32m0.09360[0m[0m | time: 47.068s
[2K
| Adam | epoch: 011 | loss: 0.09360 - acc: 0.9718 -- iter: 128/250
[A[ATraining Step: 85  | total loss: [1m[32m0.08549[0m[0m | time: 61.485s
[2K
| Adam | epoch: 011 | loss: 0.08549 - acc: 0.9746 -- iter: 160/250
[A[ATraining Step: 86  | total loss: [1m[32m0.07760[0m[0m | time: 76.636s
[2K
| Adam | epoch: 011 | loss: 0.07760 - acc: 0.9772 -- iter: 192/250
[A[ATraining Step: 87  | total loss: [1m[32m0.07649[0m[0m | time: 91.861s
[2K
| Adam | epoch: 011 | loss: 0.07649 - acc: 0.9763 -- iter: 224/250
[A[ATraining Step: 88  | total loss: [1m[32m0.07084[0m[0m | time: 113.804s
[2K
| Adam | epoch: 011 | loss: 0.07084 - acc: 0.9787 | val_loss: 0.51479 - val_acc: 0.8228 -- iter: 250/250
--
Training Step: 89  | total loss: [1m[32m0.06889[0m[0m | time: 8.297s
[2K
| Adam | epoch: 012 | loss: 0.06889 - acc: 0.9808 -- iter: 032/250
[A[ATraining Step: 90  | total loss: [1m[32m0.06470[0m[0m | time: 20.210s
[2K
| Adam | epoch: 012 | loss: 0.06470 - acc: 0.9827 -- iter: 064/250
[A[ATraining Step: 91  | total loss: [1m[32m0.06002[0m[0m | time: 34.849s
[2K
| Adam | epoch: 012 | loss: 0.06002 - acc: 0.9845 -- iter: 096/250
[A[ATraining Step: 92  | total loss: [1m[32m0.05615[0m[0m | time: 49.264s
[2K
| Adam | epoch: 012 | loss: 0.05615 - acc: 0.9860 -- iter: 128/250
[A[ATraining Step: 93  | total loss: [1m[32m0.05321[0m[0m | time: 64.554s
[2K
| Adam | epoch: 012 | loss: 0.05321 - acc: 0.9874 -- iter: 160/250
[A[ATraining Step: 94  | total loss: [1m[32m0.04851[0m[0m | time: 79.240s
[2K
| Adam | epoch: 012 | loss: 0.04851 - acc: 0.9887 -- iter: 192/250
[A[ATraining Step: 95  | total loss: [1m[32m0.04422[0m[0m | time: 94.453s
[2K
| Adam | epoch: 012 | loss: 0.04422 - acc: 0.9898 -- iter: 224/250
[A[ATraining Step: 96  | total loss: [1m[32m0.04138[0m[0m | time: 116.911s
[2K
| Adam | epoch: 012 | loss: 0.04138 - acc: 0.9908 | val_loss: 0.41137 - val_acc: 0.8608 -- iter: 250/250
--
Training Step: 97  | total loss: [1m[32m0.03800[0m[0m | time: 14.689s
[2K
| Adam | epoch: 013 | loss: 0.03800 - acc: 0.9917 -- iter: 032/250
[A[ATraining Step: 98  | total loss: [1m[32m0.03510[0m[0m | time: 27.669s
[2K
| Adam | epoch: 013 | loss: 0.03510 - acc: 0.9926 -- iter: 064/250
[A[ATraining Step: 99  | total loss: [1m[32m0.03607[0m[0m | time: 39.998s
[2K
| Adam | epoch: 013 | loss: 0.03607 - acc: 0.9933 -- iter: 096/250
[A[ATraining Step: 100  | total loss: [1m[32m0.03281[0m[0m | time: 54.651s
[2K
| Adam | epoch: 013 | loss: 0.03281 - acc: 0.9940 -- iter: 128/250
[A[ATraining Step: 101  | total loss: [1m[32m0.02980[0m[0m | time: 69.942s
[2K
| Adam | epoch: 013 | loss: 0.02980 - acc: 0.9946 -- iter: 160/250
[A[ATraining Step: 102  | total loss: [1m[32m0.02766[0m[0m | time: 84.494s
[2K
| Adam | epoch: 013 | loss: 0.02766 - acc: 0.9951 -- iter: 192/250
[A[ATraining Step: 103  | total loss: [1m[32m0.06325[0m[0m | time: 95.647s
[2K
| Adam | epoch: 013 | loss: 0.06325 - acc: 0.9925 -- iter: 224/250
[A[ATraining Step: 104  | total loss: [1m[32m0.06206[0m[0m | time: 109.952s
[2K
| Adam | epoch: 013 | loss: 0.06206 - acc: 0.9932 | val_loss: 2.72197 - val_acc: 0.5696 -- iter: 250/250
--
Training Step: 105  | total loss: [1m[32m0.05605[0m[0m | time: 14.749s
[2K
| Adam | epoch: 014 | loss: 0.05605 - acc: 0.9939 -- iter: 032/250
[A[ATraining Step: 106  | total loss: [1m[32m0.05133[0m[0m | time: 29.268s
[2K
| Adam | epoch: 014 | loss: 0.05133 - acc: 0.9945 -- iter: 064/250
[A[ATraining Step: 107  | total loss: [1m[32m0.05344[0m[0m | time: 41.242s
[2K
| Adam | epoch: 014 | loss: 0.05344 - acc: 0.9919 -- iter: 096/250
[A[ATraining Step: 108  | total loss: [1m[32m0.07097[0m[0m | time: 54.034s
[2K
| Adam | epoch: 014 | loss: 0.07097 - acc: 0.9851 -- iter: 128/250
[A[ATraining Step: 109  | total loss: [1m[32m0.06896[0m[0m | time: 68.861s
[2K
| Adam | epoch: 014 | loss: 0.06896 - acc: 0.9827 -- iter: 160/250
[A[ATraining Step: 110  | total loss: [1m[32m0.06934[0m[0m | time: 81.815s
[2K
| Adam | epoch: 014 | loss: 0.06934 - acc: 0.9813 -- iter: 192/250
[A[ATraining Step: 111  | total loss: [1m[32m0.06488[0m[0m | time: 91.687s
[2K
| Adam | epoch: 014 | loss: 0.06488 - acc: 0.9832 -- iter: 224/250
[A[ATraining Step: 112  | total loss: [1m[32m0.08502[0m[0m | time: 107.698s
[2K
| Adam | epoch: 014 | loss: 0.08502 - acc: 0.9786 | val_loss: 0.60199 - val_acc: 0.8608 -- iter: 250/250
--
Training Step: 113  | total loss: [1m[32m0.08031[0m[0m | time: 14.643s
[2K
| Adam | epoch: 015 | loss: 0.08031 - acc: 0.9776 -- iter: 032/250
[A[ATraining Step: 114  | total loss: [1m[32m0.08021[0m[0m | time: 29.278s
[2K
| Adam | epoch: 015 | loss: 0.08021 - acc: 0.9767 -- iter: 064/250
[A[ATraining Step: 115  | total loss: [1m[32m0.07277[0m[0m | time: 44.048s
[2K
| Adam | epoch: 015 | loss: 0.07277 - acc: 0.9791 -- iter: 096/250
[A[ATraining Step: 116  | total loss: [1m[32m0.06725[0m[0m | time: 56.317s
[2K
| Adam | epoch: 015 | loss: 0.06725 - acc: 0.9812 -- iter: 128/250
[A[ATraining Step: 117  | total loss: [1m[32m0.07161[0m[0m | time: 67.950s
[2K
| Adam | epoch: 015 | loss: 0.07161 - acc: 0.9754 -- iter: 160/250
[A[ATraining Step: 118  | total loss: [1m[32m0.06572[0m[0m | time: 77.655s
[2K
| Adam | epoch: 015 | loss: 0.06572 - acc: 0.9778 -- iter: 192/250
[A[ATraining Step: 119  | total loss: [1m[32m0.08493[0m[0m | time: 88.346s
[2K
| Adam | epoch: 015 | loss: 0.08493 - acc: 0.9738 -- iter: 224/250
[A[ATraining Step: 120  | total loss: [1m[32m0.07811[0m[0m | time: 107.627s
[2K
| Adam | epoch: 015 | loss: 0.07811 - acc: 0.9764 | val_loss: 0.49797 - val_acc: 0.8608 -- iter: 250/250
--
Validation AUC:0.9416666666666667
Validation AUPRC:0.9427300251387927
Test AUC:0.8758043758043759
Test AUPRC:0.831734576246806
BestTestF1Score	0.85	0.72	0.86	0.86	0.84	31	5	37	6	0.74
BestTestMCCScore	0.85	0.72	0.86	0.86	0.84	31	5	37	6	0.87
BestTestAccuracyScore	0.85	0.72	0.86	0.86	0.84	31	5	37	6	0.87
BestValidationF1Score	0.9	0.8	0.9	0.9	0.9	35	4	36	4	0.74
BestValidationMCC	0.89	0.8	0.9	0.92	0.87	34	3	37	5	0.87
BestValidationAccuracy	0.89	0.8	0.9	0.92	0.87	34	3	37	5	0.87
TestPredictions (Threshold:0.87)
CHEMBL29726,TN,INACT,0.0	CHEMBL386935,TP,ACT,0.9900000095367432	CHEMBL175463,TP,ACT,1.0	CHEMBL334667,TN,INACT,0.0	CHEMBL392420,TN,INACT,0.0	CHEMBL61550,TN,INACT,0.0	CHEMBL486278,TN,INACT,0.03999999910593033	CHEMBL3785675,TP,ACT,1.0	CHEMBL315484,TN,INACT,0.0	CHEMBL346524,TN,INACT,0.009999999776482582	CHEMBL69869,FP,INACT,0.9900000095367432	CHEMBL157100,TN,INACT,0.0	CHEMBL260328,TN,INACT,0.0	CHEMBL96281,TN,INACT,0.10999999940395355	CHEMBL230951,TN,INACT,0.0	CHEMBL76232,FN,ACT,0.029999999329447746	CHEMBL223868,TP,ACT,1.0	CHEMBL334842,TN,INACT,0.0	CHEMBL178741,TP,ACT,1.0	CHEMBL433392,TN,INACT,0.36000001430511475	CHEMBL299180,TN,INACT,0.0	CHEMBL330790,FP,INACT,1.0	CHEMBL154678,TN,INACT,0.0	CHEMBL66794,FN,ACT,0.0	CHEMBL39221,FN,ACT,0.0	CHEMBL572128,TP,ACT,1.0	CHEMBL2112963,TP,ACT,1.0	CHEMBL236177,TP,ACT,1.0	CHEMBL291278,TN,INACT,0.0	CHEMBL386565,TP,ACT,1.0	CHEMBL3597602,TP,ACT,0.8999999761581421	CHEMBL67197,TP,ACT,0.9900000095367432	CHEMBL63161,FN,ACT,0.03999999910593033	CHEMBL377136,TN,INACT,0.05000000074505806	CHEMBL154535,TN,INACT,0.0	CHEMBL550523,FP,INACT,1.0	CHEMBL3787247,TP,ACT,1.0	CHEMBL30853,TN,INACT,0.0	CHEMBL94717,TN,INACT,0.0	CHEMBL422505,TN,INACT,0.0	CHEMBL211442,TN,INACT,0.5	CHEMBL554700,TP,ACT,1.0	CHEMBL375439,TP,ACT,1.0	CHEMBL67472,TP,ACT,1.0	CHEMBL327764,TN,INACT,0.14000000059604645	CHEMBL225201,TP,ACT,1.0	CHEMBL441269,TN,INACT,0.019999999552965164	CHEMBL235767,TP,ACT,1.0	CHEMBL2111523,TN,INACT,0.0	CHEMBL90625,FP,INACT,1.0	CHEMBL238263,TP,ACT,1.0	CHEMBL2181519,TP,ACT,0.9900000095367432	CHEMBL175699,TP,ACT,1.0	CHEMBL252531,FP,INACT,1.0	CHEMBL241327,TP,ACT,1.0	CHEMBL302781,FN,ACT,0.019999999552965164	CHEMBL399071,TN,INACT,0.009999999776482582	CHEMBL29830,TN,INACT,0.0	CHEMBL93076,TN,INACT,0.05999999865889549	CHEMBL368858,TN,INACT,0.0	CHEMBL3786063,TP,ACT,1.0	CHEMBL224615,TP,ACT,1.0	CHEMBL59286,TN,INACT,0.0	CHEMBL64417,TN,INACT,0.0	CHEMBL107768,TN,INACT,0.0	CHEMBL72366,TN,INACT,0.0	CHEMBL392164,TP,ACT,1.0	CHEMBL235975,TP,ACT,1.0	CHEMBL347828,TN,INACT,0.0	CHEMBL388827,TP,ACT,1.0	CHEMBL236180,TP,ACT,1.0	CHEMBL3786560,TP,ACT,1.0	CHEMBL294550,FN,ACT,0.0	CHEMBL66693,TN,INACT,0.0	CHEMBL63539,TP,ACT,0.8799999952316284	CHEMBL43412,TN,INACT,0.5	CHEMBL175700,TP,ACT,0.9900000095367432	CHEMBL299291,TN,INACT,0.0	CHEMBL224672,TP,ACT,1.0	

