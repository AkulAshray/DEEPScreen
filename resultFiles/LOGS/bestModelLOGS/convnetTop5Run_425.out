CNNModel CHEMBL5299 adam 0.0005 15 32 0 0.6 False True
Number of active compounds :	141
Number of inactive compounds :	141
---------------------------------
Run id: CNNModel_CHEMBL5299_adam_0.0005_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5299_adam_0.0005_15_32_0.6_True/
---------------------------------
Training samples: 169
Validation samples: 53
--
Training Step: 1  | time: 0.770s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/169
[A[ATraining Step: 2  | total loss: [1m[32m0.62367[0m[0m | time: 1.374s
[2K
| Adam | epoch: 001 | loss: 0.62367 - acc: 0.5062 -- iter: 064/169
[A[ATraining Step: 3  | total loss: [1m[32m0.67928[0m[0m | time: 1.982s
[2K
| Adam | epoch: 001 | loss: 0.67928 - acc: 0.5523 -- iter: 096/169
[A[ATraining Step: 4  | total loss: [1m[32m0.68511[0m[0m | time: 2.593s
[2K
| Adam | epoch: 001 | loss: 0.68511 - acc: 0.6068 -- iter: 128/169
[A[ATraining Step: 5  | total loss: [1m[32m0.70184[0m[0m | time: 3.207s
[2K
| Adam | epoch: 001 | loss: 0.70184 - acc: 0.4463 -- iter: 160/169
[A[ATraining Step: 6  | total loss: [1m[32m0.68517[0m[0m | time: 4.455s
[2K
| Adam | epoch: 001 | loss: 0.68517 - acc: 0.6014 | val_loss: 0.69660 - val_acc: 0.4528 -- iter: 169/169
--
Training Step: 7  | total loss: [1m[32m0.70198[0m[0m | time: 0.269s
[2K
| Adam | epoch: 002 | loss: 0.70198 - acc: 0.4405 -- iter: 032/169
[A[ATraining Step: 8  | total loss: [1m[32m0.70496[0m[0m | time: 0.881s
[2K
| Adam | epoch: 002 | loss: 0.70496 - acc: 0.3802 -- iter: 064/169
[A[ATraining Step: 9  | total loss: [1m[32m0.69156[0m[0m | time: 1.477s
[2K
| Adam | epoch: 002 | loss: 0.69156 - acc: 0.5595 -- iter: 096/169
[A[ATraining Step: 10  | total loss: [1m[32m0.68752[0m[0m | time: 2.091s
[2K
| Adam | epoch: 002 | loss: 0.68752 - acc: 0.6079 -- iter: 128/169
[A[ATraining Step: 11  | total loss: [1m[32m0.68472[0m[0m | time: 2.712s
[2K
| Adam | epoch: 002 | loss: 0.68472 - acc: 0.6308 -- iter: 160/169
[A[ATraining Step: 12  | total loss: [1m[32m0.68666[0m[0m | time: 4.339s
[2K
| Adam | epoch: 002 | loss: 0.68666 - acc: 0.5860 | val_loss: 0.69658 - val_acc: 0.4528 -- iter: 169/169
--
Training Step: 13  | total loss: [1m[32m0.68615[0m[0m | time: 0.236s
[2K
| Adam | epoch: 003 | loss: 0.68615 - acc: 0.5759 -- iter: 032/169
[A[ATraining Step: 14  | total loss: [1m[32m0.68528[0m[0m | time: 0.445s
[2K
| Adam | epoch: 003 | loss: 0.68528 - acc: 0.5676 -- iter: 064/169
[A[ATraining Step: 15  | total loss: [1m[32m0.68468[0m[0m | time: 1.053s
[2K
| Adam | epoch: 003 | loss: 0.68468 - acc: 0.5629 -- iter: 096/169
[A[ATraining Step: 16  | total loss: [1m[32m0.68788[0m[0m | time: 1.673s
[2K
| Adam | epoch: 003 | loss: 0.68788 - acc: 0.5393 -- iter: 128/169
[A[ATraining Step: 17  | total loss: [1m[32m0.68594[0m[0m | time: 2.282s
[2K
| Adam | epoch: 003 | loss: 0.68594 - acc: 0.5364 -- iter: 160/169
[A[ATraining Step: 18  | total loss: [1m[32m0.68721[0m[0m | time: 3.893s
[2K
| Adam | epoch: 003 | loss: 0.68721 - acc: 0.5238 | val_loss: 0.69894 - val_acc: 0.4528 -- iter: 169/169
--
Training Step: 19  | total loss: [1m[32m0.67556[0m[0m | time: 0.643s
[2K
| Adam | epoch: 004 | loss: 0.67556 - acc: 0.5680 -- iter: 032/169
[A[ATraining Step: 20  | total loss: [1m[32m0.68101[0m[0m | time: 0.845s
[2K
| Adam | epoch: 004 | loss: 0.68101 - acc: 0.5361 -- iter: 064/169
[A[ATraining Step: 21  | total loss: [1m[32m0.68354[0m[0m | time: 1.071s
[2K
| Adam | epoch: 004 | loss: 0.68354 - acc: 0.5076 -- iter: 096/169
[A[ATraining Step: 22  | total loss: [1m[32m0.68287[0m[0m | time: 1.693s
[2K
| Adam | epoch: 004 | loss: 0.68287 - acc: 0.4887 -- iter: 128/169
[A[ATraining Step: 23  | total loss: [1m[32m0.66819[0m[0m | time: 2.305s
[2K
| Adam | epoch: 004 | loss: 0.66819 - acc: 0.5736 -- iter: 160/169
[A[ATraining Step: 24  | total loss: [1m[32m0.66551[0m[0m | time: 3.910s
[2K
| Adam | epoch: 004 | loss: 0.66551 - acc: 0.5617 | val_loss: 0.69909 - val_acc: 0.4528 -- iter: 169/169
--
Training Step: 25  | total loss: [1m[32m0.64790[0m[0m | time: 0.614s
[2K
| Adam | epoch: 005 | loss: 0.64790 - acc: 0.5960 -- iter: 032/169
[A[ATraining Step: 26  | total loss: [1m[32m0.64526[0m[0m | time: 1.231s
[2K
| Adam | epoch: 005 | loss: 0.64526 - acc: 0.5871 -- iter: 064/169
[A[ATraining Step: 27  | total loss: [1m[32m0.63512[0m[0m | time: 1.441s
[2K
| Adam | epoch: 005 | loss: 0.63512 - acc: 0.5969 -- iter: 096/169
[A[ATraining Step: 28  | total loss: [1m[32m0.62356[0m[0m | time: 1.645s
[2K
| Adam | epoch: 005 | loss: 0.62356 - acc: 0.6143 -- iter: 128/169
[A[ATraining Step: 29  | total loss: [1m[32m0.60746[0m[0m | time: 2.312s
[2K
| Adam | epoch: 005 | loss: 0.60746 - acc: 0.6271 -- iter: 160/169
[A[ATraining Step: 30  | total loss: [1m[32m0.61325[0m[0m | time: 3.939s
[2K
| Adam | epoch: 005 | loss: 0.61325 - acc: 0.5896 | val_loss: 0.61553 - val_acc: 0.8868 -- iter: 169/169
--
Training Step: 31  | total loss: [1m[32m0.61578[0m[0m | time: 0.643s
[2K
| Adam | epoch: 006 | loss: 0.61578 - acc: 0.5689 -- iter: 032/169
[A[ATraining Step: 32  | total loss: [1m[32m0.60460[0m[0m | time: 1.282s
[2K
| Adam | epoch: 006 | loss: 0.60460 - acc: 0.6448 -- iter: 064/169
[A[ATraining Step: 33  | total loss: [1m[32m0.58372[0m[0m | time: 1.918s
[2K
| Adam | epoch: 006 | loss: 0.58372 - acc: 0.6816 -- iter: 096/169
[A[ATraining Step: 34  | total loss: [1m[32m0.57443[0m[0m | time: 2.127s
[2K
| Adam | epoch: 006 | loss: 0.57443 - acc: 0.6561 -- iter: 128/169
[A[ATraining Step: 35  | total loss: [1m[32m0.53343[0m[0m | time: 2.336s
[2K
| Adam | epoch: 006 | loss: 0.53343 - acc: 0.6583 -- iter: 160/169
[A[ATraining Step: 36  | total loss: [1m[32m0.49274[0m[0m | time: 3.949s
[2K
| Adam | epoch: 006 | loss: 0.49274 - acc: 0.6600 | val_loss: 0.45917 - val_acc: 0.9057 -- iter: 169/169
--
Training Step: 37  | total loss: [1m[32m0.49424[0m[0m | time: 0.619s
[2K
| Adam | epoch: 007 | loss: 0.49424 - acc: 0.7030 -- iter: 032/169
[A[ATraining Step: 38  | total loss: [1m[32m0.46907[0m[0m | time: 1.230s
[2K
| Adam | epoch: 007 | loss: 0.46907 - acc: 0.7367 -- iter: 064/169
[A[ATraining Step: 39  | total loss: [1m[32m0.45683[0m[0m | time: 1.837s
[2K
| Adam | epoch: 007 | loss: 0.45683 - acc: 0.7691 -- iter: 096/169
[A[ATraining Step: 40  | total loss: [1m[32m0.43415[0m[0m | time: 2.467s
[2K
| Adam | epoch: 007 | loss: 0.43415 - acc: 0.7890 -- iter: 128/169
[A[ATraining Step: 41  | total loss: [1m[32m0.42724[0m[0m | time: 2.682s
[2K
| Adam | epoch: 007 | loss: 0.42724 - acc: 0.7876 -- iter: 160/169
[A[ATraining Step: 42  | total loss: [1m[32m0.38680[0m[0m | time: 3.919s
[2K
| Adam | epoch: 007 | loss: 0.38680 - acc: 0.8058 | val_loss: 0.28812 - val_acc: 0.9057 -- iter: 169/169
--
Training Step: 43  | total loss: [1m[32m0.35776[0m[0m | time: 0.612s
[2K
| Adam | epoch: 008 | loss: 0.35776 - acc: 0.8205 -- iter: 032/169
[A[ATraining Step: 44  | total loss: [1m[32m0.35551[0m[0m | time: 1.213s
[2K
| Adam | epoch: 008 | loss: 0.35551 - acc: 0.8245 -- iter: 064/169
[A[ATraining Step: 45  | total loss: [1m[32m0.37056[0m[0m | time: 1.836s
[2K
| Adam | epoch: 008 | loss: 0.37056 - acc: 0.8278 -- iter: 096/169
[A[ATraining Step: 46  | total loss: [1m[32m0.35400[0m[0m | time: 2.468s
[2K
| Adam | epoch: 008 | loss: 0.35400 - acc: 0.8304 -- iter: 128/169
[A[ATraining Step: 47  | total loss: [1m[32m0.32278[0m[0m | time: 3.082s
[2K
| Adam | epoch: 008 | loss: 0.32278 - acc: 0.8479 -- iter: 160/169
[A[ATraining Step: 48  | total loss: [1m[32m0.32150[0m[0m | time: 4.295s
[2K
| Adam | epoch: 008 | loss: 0.32150 - acc: 0.8473 | val_loss: 0.28566 - val_acc: 0.8491 -- iter: 169/169
--
Training Step: 49  | total loss: [1m[32m0.30577[0m[0m | time: 0.237s
[2K
| Adam | epoch: 009 | loss: 0.30577 - acc: 0.8538 -- iter: 032/169
[A[ATraining Step: 50  | total loss: [1m[32m0.29415[0m[0m | time: 0.862s
[2K
| Adam | epoch: 009 | loss: 0.29415 - acc: 0.8593 -- iter: 064/169
[A[ATraining Step: 51  | total loss: [1m[32m0.28492[0m[0m | time: 1.477s
[2K
| Adam | epoch: 009 | loss: 0.28492 - acc: 0.8664 -- iter: 096/169
[A[ATraining Step: 52  | total loss: [1m[32m0.30121[0m[0m | time: 2.084s
[2K
| Adam | epoch: 009 | loss: 0.30121 - acc: 0.8537 -- iter: 128/169
[A[ATraining Step: 53  | total loss: [1m[32m0.34746[0m[0m | time: 2.695s
[2K
| Adam | epoch: 009 | loss: 0.34746 - acc: 0.8292 -- iter: 160/169
[A[ATraining Step: 54  | total loss: [1m[32m0.31611[0m[0m | time: 4.349s
[2K
| Adam | epoch: 009 | loss: 0.31611 - acc: 0.8449 | val_loss: 0.22338 - val_acc: 0.8679 -- iter: 169/169
--
Training Step: 55  | total loss: [1m[32m0.29743[0m[0m | time: 0.245s
[2K
| Adam | epoch: 010 | loss: 0.29743 - acc: 0.8536 -- iter: 032/169
[A[ATraining Step: 56  | total loss: [1m[32m0.26183[0m[0m | time: 0.464s
[2K
| Adam | epoch: 010 | loss: 0.26183 - acc: 0.8742 -- iter: 064/169
[A[ATraining Step: 57  | total loss: [1m[32m0.22962[0m[0m | time: 1.082s
[2K
| Adam | epoch: 010 | loss: 0.22962 - acc: 0.8916 -- iter: 096/169
[A[ATraining Step: 58  | total loss: [1m[32m0.21562[0m[0m | time: 1.699s
[2K
| Adam | epoch: 010 | loss: 0.21562 - acc: 0.8979 -- iter: 128/169
[A[ATraining Step: 59  | total loss: [1m[32m0.20218[0m[0m | time: 2.313s
[2K
| Adam | epoch: 010 | loss: 0.20218 - acc: 0.9032 -- iter: 160/169
[A[ATraining Step: 60  | total loss: [1m[32m0.18736[0m[0m | time: 3.930s
[2K
| Adam | epoch: 010 | loss: 0.18736 - acc: 0.9119 | val_loss: 0.23822 - val_acc: 0.9057 -- iter: 169/169
--
Training Step: 61  | total loss: [1m[32m0.18891[0m[0m | time: 0.615s
[2K
| Adam | epoch: 011 | loss: 0.18891 - acc: 0.9112 -- iter: 032/169
[A[ATraining Step: 62  | total loss: [1m[32m0.17426[0m[0m | time: 0.842s
[2K
| Adam | epoch: 011 | loss: 0.17426 - acc: 0.9186 -- iter: 064/169
[A[ATraining Step: 63  | total loss: [1m[32m0.16027[0m[0m | time: 1.071s
[2K
| Adam | epoch: 011 | loss: 0.16027 - acc: 0.9289 -- iter: 096/169
[A[ATraining Step: 64  | total loss: [1m[32m0.14908[0m[0m | time: 1.683s
[2K
| Adam | epoch: 011 | loss: 0.14908 - acc: 0.9378 -- iter: 128/169
[A[ATraining Step: 65  | total loss: [1m[32m0.16109[0m[0m | time: 2.289s
[2K
| Adam | epoch: 011 | loss: 0.16109 - acc: 0.9262 -- iter: 160/169
[A[ATraining Step: 66  | total loss: [1m[32m0.17518[0m[0m | time: 3.899s
[2K
| Adam | epoch: 011 | loss: 0.17518 - acc: 0.9200 | val_loss: 0.16188 - val_acc: 0.9245 -- iter: 169/169
--
Training Step: 67  | total loss: [1m[32m0.16462[0m[0m | time: 0.626s
[2K
| Adam | epoch: 012 | loss: 0.16462 - acc: 0.9258 -- iter: 032/169
[A[ATraining Step: 68  | total loss: [1m[32m0.15329[0m[0m | time: 1.267s
[2K
| Adam | epoch: 012 | loss: 0.15329 - acc: 0.9309 -- iter: 064/169
[A[ATraining Step: 69  | total loss: [1m[32m0.15061[0m[0m | time: 1.490s
[2K
| Adam | epoch: 012 | loss: 0.15061 - acc: 0.9317 -- iter: 096/169
[A[ATraining Step: 70  | total loss: [1m[32m0.13609[0m[0m | time: 1.694s
[2K
| Adam | epoch: 012 | loss: 0.13609 - acc: 0.9396 -- iter: 128/169
[A[ATraining Step: 71  | total loss: [1m[32m0.12385[0m[0m | time: 2.303s
[2K
| Adam | epoch: 012 | loss: 0.12385 - acc: 0.9464 -- iter: 160/169
[A[ATraining Step: 72  | total loss: [1m[32m0.12522[0m[0m | time: 3.931s
[2K
| Adam | epoch: 012 | loss: 0.12522 - acc: 0.9454 | val_loss: 0.26811 - val_acc: 0.9057 -- iter: 169/169
--
Training Step: 73  | total loss: [1m[32m0.18566[0m[0m | time: 0.613s
[2K
| Adam | epoch: 013 | loss: 0.18566 - acc: 0.9376 -- iter: 032/169
[A[ATraining Step: 74  | total loss: [1m[32m0.17589[0m[0m | time: 1.226s
[2K
| Adam | epoch: 013 | loss: 0.17589 - acc: 0.9376 -- iter: 064/169
[A[ATraining Step: 75  | total loss: [1m[32m0.16508[0m[0m | time: 1.826s
[2K
| Adam | epoch: 013 | loss: 0.16508 - acc: 0.9444 -- iter: 096/169
[A[ATraining Step: 76  | total loss: [1m[32m0.17044[0m[0m | time: 2.026s
[2K
| Adam | epoch: 013 | loss: 0.17044 - acc: 0.9403 -- iter: 128/169
[A[ATraining Step: 77  | total loss: [1m[32m0.16758[0m[0m | time: 2.235s
[2K
| Adam | epoch: 013 | loss: 0.16758 - acc: 0.9348 -- iter: 160/169
[A[ATraining Step: 78  | total loss: [1m[32m0.15725[0m[0m | time: 3.879s
[2K
| Adam | epoch: 013 | loss: 0.15725 - acc: 0.9417 | val_loss: 0.31607 - val_acc: 0.8868 -- iter: 169/169
--
Training Step: 79  | total loss: [1m[32m0.16494[0m[0m | time: 0.645s
[2K
| Adam | epoch: 014 | loss: 0.16494 - acc: 0.9412 -- iter: 032/169
[A[ATraining Step: 80  | total loss: [1m[32m0.17980[0m[0m | time: 1.259s
[2K
| Adam | epoch: 014 | loss: 0.17980 - acc: 0.9345 -- iter: 064/169
[A[ATraining Step: 81  | total loss: [1m[32m0.19333[0m[0m | time: 1.905s
[2K
| Adam | epoch: 014 | loss: 0.19333 - acc: 0.9316 -- iter: 096/169
[A[ATraining Step: 82  | total loss: [1m[32m0.18770[0m[0m | time: 2.510s
[2K
| Adam | epoch: 014 | loss: 0.18770 - acc: 0.9291 -- iter: 128/169
[A[ATraining Step: 83  | total loss: [1m[32m0.18696[0m[0m | time: 2.731s
[2K
| Adam | epoch: 014 | loss: 0.18696 - acc: 0.9299 -- iter: 160/169
[A[ATraining Step: 84  | total loss: [1m[32m0.17667[0m[0m | time: 3.937s
[2K
| Adam | epoch: 014 | loss: 0.17667 - acc: 0.9369 | val_loss: 0.58190 - val_acc: 0.8113 -- iter: 169/169
--
Training Step: 85  | total loss: [1m[32m0.17668[0m[0m | time: 0.624s
[2K
| Adam | epoch: 015 | loss: 0.17668 - acc: 0.9321 -- iter: 032/169
[A[ATraining Step: 86  | total loss: [1m[32m0.20867[0m[0m | time: 1.254s
[2K
| Adam | epoch: 015 | loss: 0.20867 - acc: 0.9170 -- iter: 064/169
[A[ATraining Step: 87  | total loss: [1m[32m0.26752[0m[0m | time: 1.892s
[2K
| Adam | epoch: 015 | loss: 0.26752 - acc: 0.8972 -- iter: 096/169
[A[ATraining Step: 88  | total loss: [1m[32m0.26513[0m[0m | time: 2.495s
[2K
| Adam | epoch: 015 | loss: 0.26513 - acc: 0.8981 -- iter: 128/169
[A[ATraining Step: 89  | total loss: [1m[32m0.26953[0m[0m | time: 3.096s
[2K
| Adam | epoch: 015 | loss: 0.26953 - acc: 0.8989 -- iter: 160/169
[A[ATraining Step: 90  | total loss: [1m[32m0.24870[0m[0m | time: 4.302s
[2K
| Adam | epoch: 015 | loss: 0.24870 - acc: 0.9090 | val_loss: 0.43676 - val_acc: 0.8679 -- iter: 169/169
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9885057471264368
Validation AUPRC:0.9915099268547544
Test AUC:0.9772727272727273
Test AUPRC:0.9880950265114488
BestTestF1Score	0.94	0.86	0.92	1.0	0.88	29	0	20	4	0.14
BestTestMCCScore	0.94	0.86	0.92	1.0	0.88	29	0	20	4	0.14
BestTestAccuracyScore	0.94	0.86	0.92	1.0	0.88	29	0	20	4	0.14
BestValidationF1Score	0.96	0.93	0.96	1.0	0.93	27	0	24	2	0.14
BestValidationMCC	0.96	0.93	0.96	1.0	0.93	27	0	24	2	0.14
BestValidationAccuracy	0.96	0.93	0.96	1.0	0.93	27	0	24	2	0.14
TestPredictions (Threshold:0.14)
CHEMBL594802,TN,INACT,0.0	CHEMBL2387313,TP,ACT,0.6100000143051147	CHEMBL228144,TN,INACT,0.0	CHEMBL2441642,TP,ACT,0.8100000023841858	CHEMBL336081,TN,INACT,0.0	CHEMBL21509,TN,INACT,0.0	CHEMBL3680091,TP,ACT,0.20999999344348907	CHEMBL3680069,TP,ACT,0.25	CHEMBL2042403,TN,INACT,0.0	CHEMBL3680048,TP,ACT,0.8600000143051147	CHEMBL294649,TN,INACT,0.0	CHEMBL407818,TN,INACT,0.03999999910593033	CHEMBL2387311,TP,ACT,0.6000000238418579	CHEMBL297335,TN,INACT,0.0	CHEMBL42065,TN,INACT,0.0	CHEMBL3680058,TP,ACT,0.8700000047683716	CHEMBL3087360,TP,ACT,0.6800000071525574	CHEMBL40317,TN,INACT,0.0	CHEMBL3680115,TP,ACT,0.1899999976158142	CHEMBL2387310,TP,ACT,0.41999998688697815	CHEMBL128360,TN,INACT,0.0	CHEMBL2387283,TP,ACT,0.7300000190734863	CHEMBL40986,TN,INACT,0.0	CHEMBL44262,TN,INACT,0.0	CHEMBL3680100,TP,ACT,0.7900000214576721	CHEMBL3680081,TP,ACT,0.27000001072883606	CHEMBL3680102,TP,ACT,0.6000000238418579	CHEMBL476323,FN,ACT,0.0	CHEMBL245319,TN,INACT,0.009999999776482582	CHEMBL2441648,FN,ACT,0.029999999329447746	CHEMBL3680065,TP,ACT,0.7200000286102295	CHEMBL3087357,TP,ACT,0.6899999976158142	CHEMBL3680101,TP,ACT,0.5699999928474426	CHEMBL3680051,TP,ACT,0.8600000143051147	CHEMBL2387286,TP,ACT,0.7699999809265137	CHEMBL602269,TN,INACT,0.019999999552965164	CHEMBL107680,TN,INACT,0.0	CHEMBL89445,TN,INACT,0.0	CHEMBL450463,TN,INACT,0.0	CHEMBL3633650,TN,INACT,0.0	CHEMBL218790,FN,ACT,0.0	CHEMBL2441652,TP,ACT,0.7300000190734863	CHEMBL3680113,TP,ACT,0.7599999904632568	CHEMBL3680108,TP,ACT,0.550000011920929	CHEMBL2387312,TP,ACT,0.6600000262260437	CHEMBL3680068,TP,ACT,0.14000000059604645	CHEMBL42799,TN,INACT,0.0	CHEMBL2441647,TP,ACT,0.5	CHEMBL3680052,TP,ACT,0.7900000214576721	CHEMBL3680104,TP,ACT,0.6499999761581421	CHEMBL2387292,TP,ACT,0.5	CHEMBL3680092,FN,ACT,0.009999999776482582	CHEMBL3680050,TP,ACT,0.8600000143051147	

