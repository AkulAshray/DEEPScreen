ImageNetInceptionV2 CHEMBL3067 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	152
Number of inactive compounds :	152
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3067_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3067_adam_0.0001_15_0.6/
---------------------------------
Training samples: 175
Validation samples: 55
--
Training Step: 1  | time: 833.232s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/175
[A[ATraining Step: 2  | total loss: [1m[32m0.70706[0m[0m | time: 2418.153s
[2K
| Adam | epoch: 001 | loss: 0.70706 - acc: 0.3656 -- iter: 064/175
[A[ATraining Step: 3  | total loss: [1m[32m0.61778[0m[0m | time: 3284.568s
[2K
| Adam | epoch: 001 | loss: 0.61778 - acc: 0.6034 -- iter: 096/175
[A[ATraining Step: 4  | total loss: [1m[32m0.54067[0m[0m | time: 3624.967s
[2K
| Adam | epoch: 001 | loss: 0.54067 - acc: 0.7368 -- iter: 128/175
[A[ATraining Step: 5  | total loss: [1m[32m0.53073[0m[0m | time: 3731.278s
[2K
| Adam | epoch: 001 | loss: 0.53073 - acc: 0.7027 -- iter: 160/175
[A[ATraining Step: 6  | total loss: [1m[32m0.47270[0m[0m | time: 3756.320s
[2K
| Adam | epoch: 001 | loss: 0.47270 - acc: 0.7733 | val_loss: 0.91239 - val_acc: 0.5273 -- iter: 175/175
--
Training Step: 7  | total loss: [1m[32m0.47938[0m[0m | time: 9.117s
[2K
| Adam | epoch: 002 | loss: 0.47938 - acc: 0.7493 -- iter: 032/175
[A[ATraining Step: 8  | total loss: [1m[32m0.43503[0m[0m | time: 25.083s
[2K
| Adam | epoch: 002 | loss: 0.43503 - acc: 0.7778 -- iter: 064/175
[A[ATraining Step: 9  | total loss: [1m[32m0.45661[0m[0m | time: 38.934s
[2K
| Adam | epoch: 002 | loss: 0.45661 - acc: 0.7962 -- iter: 096/175
[A[ATraining Step: 10  | total loss: [1m[32m0.42021[0m[0m | time: 50.377s
[2K
| Adam | epoch: 002 | loss: 0.42021 - acc: 0.8043 -- iter: 128/175
[A[ATraining Step: 11  | total loss: [1m[32m0.37627[0m[0m | time: 62.794s
[2K
| Adam | epoch: 002 | loss: 0.37627 - acc: 0.8674 -- iter: 160/175
[A[ATraining Step: 12  | total loss: [1m[32m0.28678[0m[0m | time: 75.727s
[2K
| Adam | epoch: 002 | loss: 0.28678 - acc: 0.9271 | val_loss: 2.31622 - val_acc: 0.5273 -- iter: 175/175
--
Training Step: 13  | total loss: [1m[32m0.26722[0m[0m | time: 8.485s
[2K
| Adam | epoch: 003 | loss: 0.26722 - acc: 0.9449 -- iter: 032/175
[A[ATraining Step: 14  | total loss: [1m[32m0.26576[0m[0m | time: 17.070s
[2K
| Adam | epoch: 003 | loss: 0.26576 - acc: 0.9675 -- iter: 064/175
[A[ATraining Step: 15  | total loss: [1m[32m0.23331[0m[0m | time: 32.529s
[2K
| Adam | epoch: 003 | loss: 0.23331 - acc: 0.9802 -- iter: 096/175
[A[ATraining Step: 16  | total loss: [1m[32m0.20761[0m[0m | time: 47.517s
[2K
| Adam | epoch: 003 | loss: 0.20761 - acc: 0.9642 -- iter: 128/175
[A[ATraining Step: 17  | total loss: [1m[32m0.19150[0m[0m | time: 62.848s
[2K
| Adam | epoch: 003 | loss: 0.19150 - acc: 0.9546 -- iter: 160/175
[A[ATraining Step: 18  | total loss: [1m[32m0.15597[0m[0m | time: 83.269s
[2K
| Adam | epoch: 003 | loss: 0.15597 - acc: 0.9703 | val_loss: 3.05913 - val_acc: 0.5273 -- iter: 175/175
--
Training Step: 19  | total loss: [1m[32m0.13814[0m[0m | time: 16.038s
[2K
| Adam | epoch: 004 | loss: 0.13814 - acc: 0.9802 -- iter: 032/175
[A[ATraining Step: 20  | total loss: [1m[32m0.11347[0m[0m | time: 24.809s
[2K
| Adam | epoch: 004 | loss: 0.11347 - acc: 0.9866 -- iter: 064/175
[A[ATraining Step: 21  | total loss: [1m[32m0.09863[0m[0m | time: 33.620s
[2K
| Adam | epoch: 004 | loss: 0.09863 - acc: 0.9907 -- iter: 096/175
[A[ATraining Step: 22  | total loss: [1m[32m0.07859[0m[0m | time: 49.902s
[2K
| Adam | epoch: 004 | loss: 0.07859 - acc: 0.9935 -- iter: 128/175
[A[ATraining Step: 23  | total loss: [1m[32m0.07616[0m[0m | time: 60.245s
[2K
| Adam | epoch: 004 | loss: 0.07616 - acc: 0.9954 -- iter: 160/175
[A[ATraining Step: 24  | total loss: [1m[32m0.09459[0m[0m | time: 73.629s
[2K
| Adam | epoch: 004 | loss: 0.09459 - acc: 0.9879 | val_loss: 2.97523 - val_acc: 0.5273 -- iter: 175/175
--
Training Step: 25  | total loss: [1m[32m0.07794[0m[0m | time: 12.970s
[2K
| Adam | epoch: 005 | loss: 0.07794 - acc: 0.9912 -- iter: 032/175
[A[ATraining Step: 26  | total loss: [1m[32m0.06326[0m[0m | time: 25.662s
[2K
| Adam | epoch: 005 | loss: 0.06326 - acc: 0.9935 -- iter: 064/175
[A[ATraining Step: 27  | total loss: [1m[32m0.07115[0m[0m | time: 32.786s
[2K
| Adam | epoch: 005 | loss: 0.07115 - acc: 0.9872 -- iter: 096/175
[A[ATraining Step: 28  | total loss: [1m[32m0.06423[0m[0m | time: 39.978s
[2K
| Adam | epoch: 005 | loss: 0.06423 - acc: 0.9904 -- iter: 128/175
[A[ATraining Step: 29  | total loss: [1m[32m0.05294[0m[0m | time: 52.929s
[2K
| Adam | epoch: 005 | loss: 0.05294 - acc: 0.9927 -- iter: 160/175
[A[ATraining Step: 30  | total loss: [1m[32m0.04242[0m[0m | time: 69.396s
[2K
| Adam | epoch: 005 | loss: 0.04242 - acc: 0.9944 | val_loss: 1.85940 - val_acc: 0.5273 -- iter: 175/175
--
Training Step: 31  | total loss: [1m[32m0.07692[0m[0m | time: 9.398s
[2K
| Adam | epoch: 006 | loss: 0.07692 - acc: 0.9885 -- iter: 032/175
[A[ATraining Step: 32  | total loss: [1m[32m0.06093[0m[0m | time: 17.566s
[2K
| Adam | epoch: 006 | loss: 0.06093 - acc: 0.9911 -- iter: 064/175
[A[ATraining Step: 33  | total loss: [1m[32m0.06312[0m[0m | time: 26.556s
[2K
| Adam | epoch: 006 | loss: 0.06312 - acc: 0.9862 -- iter: 096/175
[A[ATraining Step: 34  | total loss: [1m[32m0.05158[0m[0m | time: 33.257s
[2K
| Adam | epoch: 006 | loss: 0.05158 - acc: 0.9891 -- iter: 128/175
[A[ATraining Step: 35  | total loss: [1m[32m0.05886[0m[0m | time: 39.445s
[2K
| Adam | epoch: 006 | loss: 0.05886 - acc: 0.9775 -- iter: 160/175
[A[ATraining Step: 36  | total loss: [1m[32m0.05330[0m[0m | time: 55.447s
[2K
| Adam | epoch: 006 | loss: 0.05330 - acc: 0.9821 | val_loss: 0.70964 - val_acc: 0.5818 -- iter: 175/175
--
Training Step: 37  | total loss: [1m[32m0.04599[0m[0m | time: 13.249s
[2K
| Adam | epoch: 007 | loss: 0.04599 - acc: 0.9857 -- iter: 032/175
[A[ATraining Step: 38  | total loss: [1m[32m0.03911[0m[0m | time: 26.044s
[2K
| Adam | epoch: 007 | loss: 0.03911 - acc: 0.9885 -- iter: 064/175
[A[ATraining Step: 39  | total loss: [1m[32m0.03301[0m[0m | time: 38.986s
[2K
| Adam | epoch: 007 | loss: 0.03301 - acc: 0.9907 -- iter: 096/175
[A[ATraining Step: 40  | total loss: [1m[32m0.02961[0m[0m | time: 52.197s
[2K
| Adam | epoch: 007 | loss: 0.02961 - acc: 0.9924 -- iter: 128/175
[A[ATraining Step: 41  | total loss: [1m[32m0.02580[0m[0m | time: 59.706s
[2K
| Adam | epoch: 007 | loss: 0.02580 - acc: 0.9938 -- iter: 160/175
[A[ATraining Step: 42  | total loss: [1m[32m0.03641[0m[0m | time: 66.597s
[2K
| Adam | epoch: 007 | loss: 0.03641 - acc: 0.9829 | val_loss: 0.49220 - val_acc: 0.8364 -- iter: 175/175
--
Training Step: 43  | total loss: [1m[32m0.03556[0m[0m | time: 11.318s
[2K
| Adam | epoch: 008 | loss: 0.03556 - acc: 0.9859 -- iter: 032/175
[A[ATraining Step: 44  | total loss: [1m[32m0.03074[0m[0m | time: 23.876s
[2K
| Adam | epoch: 008 | loss: 0.03074 - acc: 0.9884 -- iter: 064/175
[A[ATraining Step: 45  | total loss: [1m[32m0.02727[0m[0m | time: 37.000s
[2K
| Adam | epoch: 008 | loss: 0.02727 - acc: 0.9903 -- iter: 096/175
[A[ATraining Step: 46  | total loss: [1m[32m0.02343[0m[0m | time: 49.346s
[2K
| Adam | epoch: 008 | loss: 0.02343 - acc: 0.9920 -- iter: 128/175
[A[ATraining Step: 47  | total loss: [1m[32m0.02072[0m[0m | time: 62.190s
[2K
| Adam | epoch: 008 | loss: 0.02072 - acc: 0.9933 -- iter: 160/175
[A[ATraining Step: 48  | total loss: [1m[32m0.01821[0m[0m | time: 73.254s
[2K
| Adam | epoch: 008 | loss: 0.01821 - acc: 0.9944 | val_loss: 0.40321 - val_acc: 0.8545 -- iter: 175/175
--
Training Step: 49  | total loss: [1m[32m0.01655[0m[0m | time: 4.551s
[2K
| Adam | epoch: 009 | loss: 0.01655 - acc: 0.9952 -- iter: 032/175
[A[ATraining Step: 50  | total loss: [1m[32m0.01493[0m[0m | time: 12.725s
[2K
| Adam | epoch: 009 | loss: 0.01493 - acc: 0.9960 -- iter: 064/175
[A[ATraining Step: 51  | total loss: [1m[32m0.01358[0m[0m | time: 24.994s
[2K
| Adam | epoch: 009 | loss: 0.01358 - acc: 0.9966 -- iter: 096/175
[A[ATraining Step: 52  | total loss: [1m[32m0.04380[0m[0m | time: 38.456s
[2K
| Adam | epoch: 009 | loss: 0.04380 - acc: 0.9924 -- iter: 128/175
[A[ATraining Step: 53  | total loss: [1m[32m0.03816[0m[0m | time: 51.054s
[2K
| Adam | epoch: 009 | loss: 0.03816 - acc: 0.9935 -- iter: 160/175
[A[ATraining Step: 54  | total loss: [1m[32m0.03360[0m[0m | time: 66.401s
[2K
| Adam | epoch: 009 | loss: 0.03360 - acc: 0.9945 | val_loss: 0.26072 - val_acc: 0.9091 -- iter: 175/175
--
Training Step: 55  | total loss: [1m[32m0.03257[0m[0m | time: 7.115s
[2K
| Adam | epoch: 010 | loss: 0.03257 - acc: 0.9953 -- iter: 032/175
[A[ATraining Step: 56  | total loss: [1m[32m0.03060[0m[0m | time: 14.180s
[2K
| Adam | epoch: 010 | loss: 0.03060 - acc: 0.9959 -- iter: 064/175
[A[ATraining Step: 57  | total loss: [1m[32m0.02751[0m[0m | time: 27.370s
[2K
| Adam | epoch: 010 | loss: 0.02751 - acc: 0.9965 -- iter: 096/175
[A[ATraining Step: 58  | total loss: [1m[32m0.02471[0m[0m | time: 39.756s
[2K
| Adam | epoch: 010 | loss: 0.02471 - acc: 0.9970 -- iter: 128/175
[A[ATraining Step: 59  | total loss: [1m[32m0.25988[0m[0m | time: 48.189s
[2K
| Adam | epoch: 010 | loss: 0.25988 - acc: 0.9554 -- iter: 160/175
[A[ATraining Step: 60  | total loss: [1m[32m0.22661[0m[0m | time: 59.111s
[2K
| Adam | epoch: 010 | loss: 0.22661 - acc: 0.9613 | val_loss: 0.39434 - val_acc: 0.8909 -- iter: 175/175
--
Training Step: 61  | total loss: [1m[32m0.21563[0m[0m | time: 13.154s
[2K
| Adam | epoch: 011 | loss: 0.21563 - acc: 0.9623 -- iter: 032/175
[A[ATraining Step: 62  | total loss: [1m[32m0.18912[0m[0m | time: 20.006s
[2K
| Adam | epoch: 011 | loss: 0.18912 - acc: 0.9671 -- iter: 064/175
[A[ATraining Step: 63  | total loss: [1m[32m0.16600[0m[0m | time: 26.275s
[2K
| Adam | epoch: 011 | loss: 0.16600 - acc: 0.9713 -- iter: 096/175
[A[ATraining Step: 64  | total loss: [1m[32m0.14589[0m[0m | time: 39.689s
[2K
| Adam | epoch: 011 | loss: 0.14589 - acc: 0.9749 -- iter: 128/175
[A[ATraining Step: 65  | total loss: [1m[32m0.13714[0m[0m | time: 52.468s
[2K
| Adam | epoch: 011 | loss: 0.13714 - acc: 0.9741 -- iter: 160/175
[A[ATraining Step: 66  | total loss: [1m[32m0.16517[0m[0m | time: 69.743s
[2K
| Adam | epoch: 011 | loss: 0.16517 - acc: 0.9697 | val_loss: 0.81428 - val_acc: 0.7091 -- iter: 175/175
--
Training Step: 67  | total loss: [1m[32m0.15599[0m[0m | time: 9.061s
[2K
| Adam | epoch: 012 | loss: 0.15599 - acc: 0.9696 -- iter: 032/175
[A[ATraining Step: 68  | total loss: [1m[32m0.13943[0m[0m | time: 17.125s
[2K
| Adam | epoch: 012 | loss: 0.13943 - acc: 0.9732 -- iter: 064/175
[A[ATraining Step: 69  | total loss: [1m[32m0.12571[0m[0m | time: 21.746s
[2K
| Adam | epoch: 012 | loss: 0.12571 - acc: 0.9763 -- iter: 096/175
[A[ATraining Step: 70  | total loss: [1m[32m0.11244[0m[0m | time: 27.845s
[2K
| Adam | epoch: 012 | loss: 0.11244 - acc: 0.9790 -- iter: 128/175
[A[ATraining Step: 71  | total loss: [1m[32m0.10070[0m[0m | time: 40.461s
[2K
| Adam | epoch: 012 | loss: 0.10070 - acc: 0.9814 -- iter: 160/175
[A[ATraining Step: 72  | total loss: [1m[32m0.11917[0m[0m | time: 57.259s
[2K
| Adam | epoch: 012 | loss: 0.11917 - acc: 0.9765 | val_loss: 0.33152 - val_acc: 0.9091 -- iter: 175/175
--
Training Step: 73  | total loss: [1m[32m0.11407[0m[0m | time: 12.249s
[2K
| Adam | epoch: 013 | loss: 0.11407 - acc: 0.9756 -- iter: 032/175
[A[ATraining Step: 74  | total loss: [1m[32m0.10265[0m[0m | time: 24.999s
[2K
| Adam | epoch: 013 | loss: 0.10265 - acc: 0.9783 -- iter: 064/175
[A[ATraining Step: 75  | total loss: [1m[32m0.09323[0m[0m | time: 37.779s
[2K
| Adam | epoch: 013 | loss: 0.09323 - acc: 0.9807 -- iter: 096/175
[A[ATraining Step: 76  | total loss: [1m[32m0.09276[0m[0m | time: 45.082s
[2K
| Adam | epoch: 013 | loss: 0.09276 - acc: 0.9794 -- iter: 128/175
[A[ATraining Step: 77  | total loss: [1m[32m0.08606[0m[0m | time: 51.964s
[2K
| Adam | epoch: 013 | loss: 0.08606 - acc: 0.9816 -- iter: 160/175
[A[ATraining Step: 78  | total loss: [1m[32m0.07912[0m[0m | time: 68.519s
[2K
| Adam | epoch: 013 | loss: 0.07912 - acc: 0.9835 | val_loss: 0.84714 - val_acc: 0.6727 -- iter: 175/175
--
Training Step: 79  | total loss: [1m[32m0.07265[0m[0m | time: 8.261s
[2K
| Adam | epoch: 014 | loss: 0.07265 - acc: 0.9852 -- iter: 032/175
[A[ATraining Step: 80  | total loss: [1m[32m0.08139[0m[0m | time: 20.608s
[2K
| Adam | epoch: 014 | loss: 0.08139 - acc: 0.9835 -- iter: 064/175
[A[ATraining Step: 81  | total loss: [1m[32m0.07407[0m[0m | time: 33.483s
[2K
| Adam | epoch: 014 | loss: 0.07407 - acc: 0.9852 -- iter: 096/175
[A[ATraining Step: 82  | total loss: [1m[32m0.07534[0m[0m | time: 45.832s
[2K
| Adam | epoch: 014 | loss: 0.07534 - acc: 0.9835 -- iter: 128/175
[A[ATraining Step: 83  | total loss: [1m[32m0.06947[0m[0m | time: 52.825s
[2K
| Adam | epoch: 014 | loss: 0.06947 - acc: 0.9852 -- iter: 160/175
[A[ATraining Step: 84  | total loss: [1m[32m0.06322[0m[0m | time: 64.135s
[2K
| Adam | epoch: 014 | loss: 0.06322 - acc: 0.9867 | val_loss: 0.14518 - val_acc: 0.9273 -- iter: 175/175
--
Training Step: 85  | total loss: [1m[32m0.05748[0m[0m | time: 13.109s
[2K
| Adam | epoch: 015 | loss: 0.05748 - acc: 0.9880 -- iter: 032/175
[A[ATraining Step: 86  | total loss: [1m[32m0.05419[0m[0m | time: 25.462s
[2K
| Adam | epoch: 015 | loss: 0.05419 - acc: 0.9892 -- iter: 064/175
[A[ATraining Step: 87  | total loss: [1m[32m0.06719[0m[0m | time: 35.404s
[2K
| Adam | epoch: 015 | loss: 0.06719 - acc: 0.9872 -- iter: 096/175
[A[ATraining Step: 88  | total loss: [1m[32m0.06102[0m[0m | time: 43.526s
[2K
| Adam | epoch: 015 | loss: 0.06102 - acc: 0.9884 -- iter: 128/175
[A[ATraining Step: 89  | total loss: [1m[32m0.05527[0m[0m | time: 52.435s
[2K
| Adam | epoch: 015 | loss: 0.05527 - acc: 0.9896 -- iter: 160/175
[A[ATraining Step: 90  | total loss: [1m[32m0.05302[0m[0m | time: 63.744s
[2K
| Adam | epoch: 015 | loss: 0.05302 - acc: 0.9875 | val_loss: 0.29720 - val_acc: 0.9091 -- iter: 175/175
--
Validation AUC:0.980106100795756
Validation AUPRC:0.9875839946907059
Test AUC:0.9957983193277311
Test AUPRC:0.9931869717584005
BestTestF1Score	0.93	0.89	0.95	0.88	1.0	21	3	31	0	0.05
BestTestMCCScore	0.95	0.92	0.96	0.95	0.95	20	1	33	1	0.17
BestTestAccuracyScore	0.95	0.92	0.96	0.95	0.95	20	1	33	1	0.17
BestValidationF1Score	0.97	0.93	0.96	0.97	0.97	28	1	25	1	0.05
BestValidationMCC	0.96	0.93	0.96	1.0	0.93	27	0	26	2	0.17
BestValidationAccuracy	0.96	0.93	0.96	1.0	0.93	27	0	26	2	0.17
TestPredictions (Threshold:0.17)
CHEMBL3617650,TP,ACT,1.0	CHEMBL2385888,TP,ACT,0.9599999785423279	CHEMBL3617505,TP,ACT,1.0	CHEMBL267929,TN,INACT,0.0	CHEMBL328935,TN,INACT,0.0	CHEMBL3287719,TP,ACT,0.9300000071525574	CHEMBL310435,TN,INACT,0.0	CHEMBL32976,TN,INACT,0.0	CHEMBL154960,TN,INACT,0.0	CHEMBL3617655,TP,ACT,0.9900000095367432	CHEMBL3617504,TP,ACT,0.9800000190734863	CHEMBL610746,TN,INACT,0.019999999552965164	CHEMBL297283,TN,INACT,0.0	CHEMBL504772,TN,INACT,0.0	CHEMBL1098104,TN,INACT,0.0	CHEMBL2385889,TP,ACT,0.9300000071525574	CHEMBL210512,TN,INACT,0.0	CHEMBL3288660,FN,ACT,0.12999999523162842	CHEMBL123259,TN,INACT,0.0	CHEMBL575060,TP,ACT,0.4000000059604645	CHEMBL29830,TN,INACT,0.0	CHEMBL334014,TP,ACT,0.17000000178813934	CHEMBL3287724,TP,ACT,0.9100000262260437	CHEMBL3358461,TN,INACT,0.0	CHEMBL3617656,TP,ACT,1.0	CHEMBL209461,TN,INACT,0.0	CHEMBL260122,TN,INACT,0.0	CHEMBL347828,TN,INACT,0.07000000029802322	CHEMBL59299,TN,INACT,0.029999999329447746	CHEMBL54291,TN,INACT,0.0	CHEMBL3617524,TP,ACT,0.9800000190734863	CHEMBL69869,TN,INACT,0.0	CHEMBL61434,TN,INACT,0.07999999821186066	CHEMBL3337650,TN,INACT,0.03999999910593033	CHEMBL3617512,TP,ACT,0.8399999737739563	CHEMBL58027,TN,INACT,0.009999999776482582	CHEMBL77362,TN,INACT,0.0	CHEMBL368858,TN,INACT,0.0	CHEMBL199626,TN,INACT,0.019999999552965164	CHEMBL244584,TN,INACT,0.029999999329447746	CHEMBL66693,TN,INACT,0.0	CHEMBL90484,TN,INACT,0.0	CHEMBL2021372,FP,INACT,0.44999998807907104	CHEMBL174625,TN,INACT,0.0	CHEMBL3617617,TP,ACT,1.0	CHEMBL334842,TN,INACT,0.0	CHEMBL2204439,TP,ACT,0.9800000190734863	CHEMBL3617519,TP,ACT,0.9800000190734863	CHEMBL1209591,TN,INACT,0.0	CHEMBL2346778,TN,INACT,0.009999999776482582	CHEMBL3617649,TP,ACT,0.9800000190734863	CHEMBL3617521,TP,ACT,1.0	CHEMBL157100,TN,INACT,0.0	CHEMBL3287683,TP,ACT,0.9700000286102295	CHEMBL3287709,TP,ACT,0.9800000190734863	

