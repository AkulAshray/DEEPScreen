ImageNetInceptionV2 CHEMBL1968 adam 0.001 30 0 0 0.8 False True
Number of active compounds :	154
Number of inactive compounds :	103
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1968_adam_0.001_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1968_adam_0.001_30_0.8/
---------------------------------
Training samples: 164
Validation samples: 52
--
Training Step: 1  | time: 38.398s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/164
[A[ATraining Step: 2  | total loss: [1m[32m0.78859[0m[0m | time: 46.823s
[2K
| Adam | epoch: 001 | loss: 0.78859 - acc: 0.2531 -- iter: 064/164
[A[ATraining Step: 3  | total loss: [1m[32m1.33029[0m[0m | time: 55.370s
[2K
| Adam | epoch: 001 | loss: 1.33029 - acc: 0.5318 -- iter: 096/164
[A[ATraining Step: 4  | total loss: [1m[32m0.77087[0m[0m | time: 64.249s
[2K
| Adam | epoch: 001 | loss: 0.77087 - acc: 0.7423 -- iter: 128/164
[A[ATraining Step: 5  | total loss: [1m[32m0.79518[0m[0m | time: 73.112s
[2K
| Adam | epoch: 001 | loss: 0.79518 - acc: 0.6178 -- iter: 160/164
[A[ATraining Step: 6  | total loss: [1m[32m0.73483[0m[0m | time: 83.170s
[2K
| Adam | epoch: 001 | loss: 0.73483 - acc: 0.6425 | val_loss: 1.42623 - val_acc: 0.5385 -- iter: 164/164
--
Training Step: 7  | total loss: [1m[32m0.68362[0m[0m | time: 1.829s
[2K
| Adam | epoch: 002 | loss: 0.68362 - acc: 0.7070 -- iter: 032/164
[A[ATraining Step: 8  | total loss: [1m[32m0.47951[0m[0m | time: 10.399s
[2K
| Adam | epoch: 002 | loss: 0.47951 - acc: 0.7312 -- iter: 064/164
[A[ATraining Step: 9  | total loss: [1m[32m0.59508[0m[0m | time: 18.981s
[2K
| Adam | epoch: 002 | loss: 0.59508 - acc: 0.6419 -- iter: 096/164
[A[ATraining Step: 10  | total loss: [1m[32m0.66972[0m[0m | time: 28.118s
[2K
| Adam | epoch: 002 | loss: 0.66972 - acc: 0.5866 -- iter: 128/164
[A[ATraining Step: 11  | total loss: [1m[32m0.69213[0m[0m | time: 36.508s
[2K
| Adam | epoch: 002 | loss: 0.69213 - acc: 0.5308 -- iter: 160/164
[A[ATraining Step: 12  | total loss: [1m[32m0.61110[0m[0m | time: 48.264s
[2K
| Adam | epoch: 002 | loss: 0.61110 - acc: 0.6154 | val_loss: 2.18522 - val_acc: 0.5385 -- iter: 164/164
--
Training Step: 13  | total loss: [1m[32m0.58026[0m[0m | time: 1.861s
[2K
| Adam | epoch: 003 | loss: 0.58026 - acc: 0.6865 -- iter: 032/164
[A[ATraining Step: 14  | total loss: [1m[32m0.78403[0m[0m | time: 3.711s
[2K
| Adam | epoch: 003 | loss: 0.78403 - acc: 0.5079 -- iter: 064/164
[A[ATraining Step: 15  | total loss: [1m[32m0.66744[0m[0m | time: 12.086s
[2K
| Adam | epoch: 003 | loss: 0.66744 - acc: 0.6026 -- iter: 096/164
[A[ATraining Step: 16  | total loss: [1m[32m0.66893[0m[0m | time: 20.472s
[2K
| Adam | epoch: 003 | loss: 0.66893 - acc: 0.5993 -- iter: 128/164
[A[ATraining Step: 17  | total loss: [1m[32m0.59374[0m[0m | time: 28.716s
[2K
| Adam | epoch: 003 | loss: 0.59374 - acc: 0.6423 -- iter: 160/164
[A[ATraining Step: 18  | total loss: [1m[32m0.60371[0m[0m | time: 39.356s
[2K
| Adam | epoch: 003 | loss: 0.60371 - acc: 0.6471 | val_loss: 2.54215 - val_acc: 0.5385 -- iter: 164/164
--
Training Step: 19  | total loss: [1m[32m0.58637[0m[0m | time: 8.258s
[2K
| Adam | epoch: 004 | loss: 0.58637 - acc: 0.6710 -- iter: 032/164
[A[ATraining Step: 20  | total loss: [1m[32m0.56447[0m[0m | time: 10.100s
[2K
| Adam | epoch: 004 | loss: 0.56447 - acc: 0.6763 -- iter: 064/164
[A[ATraining Step: 21  | total loss: [1m[32m0.70947[0m[0m | time: 11.937s
[2K
| Adam | epoch: 004 | loss: 0.70947 - acc: 0.5440 -- iter: 096/164
[A[ATraining Step: 22  | total loss: [1m[32m0.63622[0m[0m | time: 20.162s
[2K
| Adam | epoch: 004 | loss: 0.63622 - acc: 0.6808 -- iter: 128/164
[A[ATraining Step: 23  | total loss: [1m[32m0.59740[0m[0m | time: 28.361s
[2K
| Adam | epoch: 004 | loss: 0.59740 - acc: 0.7009 -- iter: 160/164
[A[ATraining Step: 24  | total loss: [1m[32m0.59059[0m[0m | time: 39.022s
[2K
| Adam | epoch: 004 | loss: 0.59059 - acc: 0.6795 | val_loss: 2.72251 - val_acc: 0.5385 -- iter: 164/164
--
Training Step: 25  | total loss: [1m[32m0.58170[0m[0m | time: 8.166s
[2K
| Adam | epoch: 005 | loss: 0.58170 - acc: 0.6817 -- iter: 032/164
[A[ATraining Step: 26  | total loss: [1m[32m0.55667[0m[0m | time: 16.375s
[2K
| Adam | epoch: 005 | loss: 0.55667 - acc: 0.6750 -- iter: 064/164
[A[ATraining Step: 27  | total loss: [1m[32m0.50255[0m[0m | time: 18.175s
[2K
| Adam | epoch: 005 | loss: 0.50255 - acc: 0.7103 -- iter: 096/164
[A[ATraining Step: 28  | total loss: [1m[32m0.48846[0m[0m | time: 19.963s
[2K
| Adam | epoch: 005 | loss: 0.48846 - acc: 0.7203 -- iter: 128/164
[A[ATraining Step: 29  | total loss: [1m[32m0.44889[0m[0m | time: 28.204s
[2K
| Adam | epoch: 005 | loss: 0.44889 - acc: 0.7883 -- iter: 160/164
[A[ATraining Step: 30  | total loss: [1m[32m0.50172[0m[0m | time: 39.004s
[2K
| Adam | epoch: 005 | loss: 0.50172 - acc: 0.7644 | val_loss: 3.01446 - val_acc: 0.5385 -- iter: 164/164
--
Training Step: 31  | total loss: [1m[32m0.61274[0m[0m | time: 8.217s
[2K
| Adam | epoch: 006 | loss: 0.61274 - acc: 0.7178 -- iter: 032/164
[A[ATraining Step: 32  | total loss: [1m[32m0.57167[0m[0m | time: 17.214s
[2K
| Adam | epoch: 006 | loss: 0.57167 - acc: 0.7391 -- iter: 064/164
[A[ATraining Step: 33  | total loss: [1m[32m0.54565[0m[0m | time: 25.600s
[2K
| Adam | epoch: 006 | loss: 0.54565 - acc: 0.7484 -- iter: 096/164
[A[ATraining Step: 34  | total loss: [1m[32m0.49906[0m[0m | time: 27.372s
[2K
| Adam | epoch: 006 | loss: 0.49906 - acc: 0.7755 -- iter: 128/164
[A[ATraining Step: 35  | total loss: [1m[32m0.47435[0m[0m | time: 29.149s
[2K
| Adam | epoch: 006 | loss: 0.47435 - acc: 0.7702 -- iter: 160/164
[A[ATraining Step: 36  | total loss: [1m[32m0.39230[0m[0m | time: 39.802s
[2K
| Adam | epoch: 006 | loss: 0.39230 - acc: 0.8172 | val_loss: 1.90865 - val_acc: 0.5385 -- iter: 164/164
--
Training Step: 37  | total loss: [1m[32m0.39990[0m[0m | time: 8.190s
[2K
| Adam | epoch: 007 | loss: 0.39990 - acc: 0.8037 -- iter: 032/164
[A[ATraining Step: 38  | total loss: [1m[32m0.38004[0m[0m | time: 16.451s
[2K
| Adam | epoch: 007 | loss: 0.38004 - acc: 0.8238 -- iter: 064/164
[A[ATraining Step: 39  | total loss: [1m[32m0.37446[0m[0m | time: 24.639s
[2K
| Adam | epoch: 007 | loss: 0.37446 - acc: 0.8336 -- iter: 096/164
[A[ATraining Step: 40  | total loss: [1m[32m0.38857[0m[0m | time: 32.792s
[2K
| Adam | epoch: 007 | loss: 0.38857 - acc: 0.8355 -- iter: 128/164
[A[ATraining Step: 41  | total loss: [1m[32m0.38316[0m[0m | time: 34.640s
[2K
| Adam | epoch: 007 | loss: 0.38316 - acc: 0.8255 -- iter: 160/164
[A[ATraining Step: 42  | total loss: [1m[32m0.46660[0m[0m | time: 38.791s
[2K
| Adam | epoch: 007 | loss: 0.46660 - acc: 0.7669 | val_loss: 0.77001 - val_acc: 0.6346 -- iter: 164/164
--
Training Step: 43  | total loss: [1m[32m0.56367[0m[0m | time: 8.391s
[2K
| Adam | epoch: 008 | loss: 0.56367 - acc: 0.7640 -- iter: 032/164
[A[ATraining Step: 44  | total loss: [1m[32m0.54343[0m[0m | time: 16.789s
[2K
| Adam | epoch: 008 | loss: 0.54343 - acc: 0.7669 -- iter: 064/164
[A[ATraining Step: 45  | total loss: [1m[32m0.49693[0m[0m | time: 25.051s
[2K
| Adam | epoch: 008 | loss: 0.49693 - acc: 0.7906 -- iter: 096/164
[A[ATraining Step: 46  | total loss: [1m[32m0.49086[0m[0m | time: 33.262s
[2K
| Adam | epoch: 008 | loss: 0.49086 - acc: 0.7838 -- iter: 128/164
[A[ATraining Step: 47  | total loss: [1m[32m0.49216[0m[0m | time: 41.522s
[2K
| Adam | epoch: 008 | loss: 0.49216 - acc: 0.7732 -- iter: 160/164
[A[ATraining Step: 48  | total loss: [1m[32m0.47062[0m[0m | time: 45.693s
[2K
| Adam | epoch: 008 | loss: 0.47062 - acc: 0.7895 | val_loss: 1.25059 - val_acc: 0.4808 -- iter: 164/164
--
Training Step: 49  | total loss: [1m[32m0.44304[0m[0m | time: 1.776s
[2K
| Adam | epoch: 009 | loss: 0.44304 - acc: 0.8228 -- iter: 032/164
[A[ATraining Step: 50  | total loss: [1m[32m0.39436[0m[0m | time: 9.764s
[2K
| Adam | epoch: 009 | loss: 0.39436 - acc: 0.8503 -- iter: 064/164
[A[ATraining Step: 51  | total loss: [1m[32m0.40706[0m[0m | time: 18.030s
[2K
| Adam | epoch: 009 | loss: 0.40706 - acc: 0.8445 -- iter: 096/164
[A[ATraining Step: 52  | total loss: [1m[32m0.40978[0m[0m | time: 26.296s
[2K
| Adam | epoch: 009 | loss: 0.40978 - acc: 0.8397 -- iter: 128/164
[A[ATraining Step: 53  | total loss: [1m[32m0.37851[0m[0m | time: 34.486s
[2K
| Adam | epoch: 009 | loss: 0.37851 - acc: 0.8541 -- iter: 160/164
[A[ATraining Step: 54  | total loss: [1m[32m0.36178[0m[0m | time: 45.170s
[2K
| Adam | epoch: 009 | loss: 0.36178 - acc: 0.8572 | val_loss: 0.89829 - val_acc: 0.6154 -- iter: 164/164
--
Training Step: 55  | total loss: [1m[32m0.40762[0m[0m | time: 1.790s
[2K
| Adam | epoch: 010 | loss: 0.40762 - acc: 0.8419 -- iter: 032/164
[A[ATraining Step: 56  | total loss: [1m[32m0.36242[0m[0m | time: 3.541s
[2K
| Adam | epoch: 010 | loss: 0.36242 - acc: 0.8641 -- iter: 064/164
[A[ATraining Step: 57  | total loss: [1m[32m0.31669[0m[0m | time: 12.453s
[2K
| Adam | epoch: 010 | loss: 0.31669 - acc: 0.8829 -- iter: 096/164
[A[ATraining Step: 58  | total loss: [1m[32m0.29331[0m[0m | time: 20.727s
[2K
| Adam | epoch: 010 | loss: 0.29331 - acc: 0.8946 -- iter: 128/164
[A[ATraining Step: 59  | total loss: [1m[32m0.29798[0m[0m | time: 29.210s
[2K
| Adam | epoch: 010 | loss: 0.29798 - acc: 0.8920 -- iter: 160/164
[A[ATraining Step: 60  | total loss: [1m[32m0.27746[0m[0m | time: 39.957s
[2K
| Adam | epoch: 010 | loss: 0.27746 - acc: 0.8980 | val_loss: 0.95643 - val_acc: 0.7115 -- iter: 164/164
--
Training Step: 61  | total loss: [1m[32m0.26388[0m[0m | time: 8.145s
[2K
| Adam | epoch: 011 | loss: 0.26388 - acc: 0.9032 -- iter: 032/164
[A[ATraining Step: 62  | total loss: [1m[32m0.26611[0m[0m | time: 9.880s
[2K
| Adam | epoch: 011 | loss: 0.26611 - acc: 0.9036 -- iter: 064/164
[A[ATraining Step: 63  | total loss: [1m[32m0.23516[0m[0m | time: 11.676s
[2K
| Adam | epoch: 011 | loss: 0.23516 - acc: 0.9158 -- iter: 096/164
[A[ATraining Step: 64  | total loss: [1m[32m0.20923[0m[0m | time: 19.812s
[2K
| Adam | epoch: 011 | loss: 0.20923 - acc: 0.9263 -- iter: 128/164
[A[ATraining Step: 65  | total loss: [1m[32m0.21313[0m[0m | time: 27.998s
[2K
| Adam | epoch: 011 | loss: 0.21313 - acc: 0.9238 -- iter: 160/164
[A[ATraining Step: 66  | total loss: [1m[32m0.22369[0m[0m | time: 38.636s
[2K
| Adam | epoch: 011 | loss: 0.22369 - acc: 0.9141 | val_loss: 1.52613 - val_acc: 0.5769 -- iter: 164/164
--
Training Step: 67  | total loss: [1m[32m0.22753[0m[0m | time: 8.124s
[2K
| Adam | epoch: 012 | loss: 0.22753 - acc: 0.9132 -- iter: 032/164
[A[ATraining Step: 68  | total loss: [1m[32m0.21978[0m[0m | time: 16.277s
[2K
| Adam | epoch: 012 | loss: 0.21978 - acc: 0.9123 -- iter: 064/164
[A[ATraining Step: 69  | total loss: [1m[32m0.21630[0m[0m | time: 18.034s
[2K
| Adam | epoch: 012 | loss: 0.21630 - acc: 0.9153 -- iter: 096/164
[A[ATraining Step: 70  | total loss: [1m[32m0.22956[0m[0m | time: 19.845s
[2K
| Adam | epoch: 012 | loss: 0.22956 - acc: 0.8962 -- iter: 128/164
[A[ATraining Step: 71  | total loss: [1m[32m0.20515[0m[0m | time: 27.738s
[2K
| Adam | epoch: 012 | loss: 0.20515 - acc: 0.9080 -- iter: 160/164
[A[ATraining Step: 72  | total loss: [1m[32m0.20163[0m[0m | time: 38.057s
[2K
| Adam | epoch: 012 | loss: 0.20163 - acc: 0.9149 | val_loss: 0.85607 - val_acc: 0.6538 -- iter: 164/164
--
Training Step: 73  | total loss: [1m[32m0.21463[0m[0m | time: 8.148s
[2K
| Adam | epoch: 013 | loss: 0.21463 - acc: 0.9070 -- iter: 032/164
[A[ATraining Step: 74  | total loss: [1m[32m0.20278[0m[0m | time: 16.056s
[2K
| Adam | epoch: 013 | loss: 0.20278 - acc: 0.9172 -- iter: 064/164
[A[ATraining Step: 75  | total loss: [1m[32m0.20462[0m[0m | time: 24.109s
[2K
| Adam | epoch: 013 | loss: 0.20462 - acc: 0.9194 -- iter: 096/164
[A[ATraining Step: 76  | total loss: [1m[32m0.19439[0m[0m | time: 25.896s
[2K
| Adam | epoch: 013 | loss: 0.19439 - acc: 0.9247 -- iter: 128/164
[A[ATraining Step: 77  | total loss: [1m[32m0.24627[0m[0m | time: 27.631s
[2K
| Adam | epoch: 013 | loss: 0.24627 - acc: 0.9062 -- iter: 160/164
[A[ATraining Step: 78  | total loss: [1m[32m0.23831[0m[0m | time: 38.012s
[2K
| Adam | epoch: 013 | loss: 0.23831 - acc: 0.9160 | val_loss: 1.32873 - val_acc: 0.6731 -- iter: 164/164
--
Training Step: 79  | total loss: [1m[32m0.23956[0m[0m | time: 7.883s
[2K
| Adam | epoch: 014 | loss: 0.23956 - acc: 0.9150 -- iter: 032/164
[A[ATraining Step: 80  | total loss: [1m[32m0.26720[0m[0m | time: 15.853s
[2K
| Adam | epoch: 014 | loss: 0.26720 - acc: 0.9077 -- iter: 064/164
[A[ATraining Step: 81  | total loss: [1m[32m0.28098[0m[0m | time: 23.721s
[2K
| Adam | epoch: 014 | loss: 0.28098 - acc: 0.9107 -- iter: 096/164
[A[ATraining Step: 82  | total loss: [1m[32m0.26970[0m[0m | time: 31.796s
[2K
| Adam | epoch: 014 | loss: 0.26970 - acc: 0.9103 -- iter: 128/164
[A[ATraining Step: 83  | total loss: [1m[32m0.25985[0m[0m | time: 33.544s
[2K
| Adam | epoch: 014 | loss: 0.25985 - acc: 0.9161 -- iter: 160/164
[A[ATraining Step: 84  | total loss: [1m[32m0.45309[0m[0m | time: 37.681s
[2K
| Adam | epoch: 014 | loss: 0.45309 - acc: 0.8745 | val_loss: 11.16657 - val_acc: 0.4615 -- iter: 164/164
--
Training Step: 85  | total loss: [1m[32m0.57809[0m[0m | time: 8.171s
[2K
| Adam | epoch: 015 | loss: 0.57809 - acc: 0.8371 -- iter: 032/164
[A[ATraining Step: 86  | total loss: [1m[32m0.53541[0m[0m | time: 16.297s
[2K
| Adam | epoch: 015 | loss: 0.53541 - acc: 0.8502 -- iter: 064/164
[A[ATraining Step: 87  | total loss: [1m[32m0.50252[0m[0m | time: 24.141s
[2K
| Adam | epoch: 015 | loss: 0.50252 - acc: 0.8558 -- iter: 096/164
[A[ATraining Step: 88  | total loss: [1m[32m0.47718[0m[0m | time: 32.147s
[2K
| Adam | epoch: 015 | loss: 0.47718 - acc: 0.8609 -- iter: 128/164
[A[ATraining Step: 89  | total loss: [1m[32m0.45077[0m[0m | time: 40.014s
[2K
| Adam | epoch: 015 | loss: 0.45077 - acc: 0.8623 -- iter: 160/164
[A[ATraining Step: 90  | total loss: [1m[32m0.41242[0m[0m | time: 44.125s
[2K
| Adam | epoch: 015 | loss: 0.41242 - acc: 0.8761 | val_loss: 0.75121 - val_acc: 0.7308 -- iter: 164/164
--
Training Step: 91  | total loss: [1m[32m0.42123[0m[0m | time: 1.767s
[2K
| Adam | epoch: 016 | loss: 0.42123 - acc: 0.8634 -- iter: 032/164
[A[ATraining Step: 92  | total loss: [1m[32m0.41305[0m[0m | time: 9.712s
[2K
| Adam | epoch: 016 | loss: 0.41305 - acc: 0.8771 -- iter: 064/164
[A[ATraining Step: 93  | total loss: [1m[32m0.40258[0m[0m | time: 17.777s
[2K
| Adam | epoch: 016 | loss: 0.40258 - acc: 0.8706 -- iter: 096/164
[A[ATraining Step: 94  | total loss: [1m[32m0.38255[0m[0m | time: 25.732s
[2K
| Adam | epoch: 016 | loss: 0.38255 - acc: 0.8773 -- iter: 128/164
[A[ATraining Step: 95  | total loss: [1m[32m0.35948[0m[0m | time: 33.740s
[2K
| Adam | epoch: 016 | loss: 0.35948 - acc: 0.8865 -- iter: 160/164
[A[ATraining Step: 96  | total loss: [1m[32m0.33656[0m[0m | time: 43.945s
[2K
| Adam | epoch: 016 | loss: 0.33656 - acc: 0.8884 | val_loss: 0.75622 - val_acc: 0.7885 -- iter: 164/164
--
Training Step: 97  | total loss: [1m[32m0.31354[0m[0m | time: 1.747s
[2K
| Adam | epoch: 017 | loss: 0.31354 - acc: 0.8996 -- iter: 032/164
[A[ATraining Step: 98  | total loss: [1m[32m0.28631[0m[0m | time: 3.458s
[2K
| Adam | epoch: 017 | loss: 0.28631 - acc: 0.9096 -- iter: 064/164
[A[ATraining Step: 99  | total loss: [1m[32m0.26058[0m[0m | time: 11.377s
[2K
| Adam | epoch: 017 | loss: 0.26058 - acc: 0.9187 -- iter: 096/164
[A[ATraining Step: 100  | total loss: [1m[32m0.26284[0m[0m | time: 19.403s
[2K
| Adam | epoch: 017 | loss: 0.26284 - acc: 0.9112 -- iter: 128/164
[A[ATraining Step: 101  | total loss: [1m[32m0.25039[0m[0m | time: 27.561s
[2K
| Adam | epoch: 017 | loss: 0.25039 - acc: 0.9169 -- iter: 160/164
[A[ATraining Step: 102  | total loss: [1m[32m0.23348[0m[0m | time: 37.993s
[2K
| Adam | epoch: 017 | loss: 0.23348 - acc: 0.9252 | val_loss: 1.48717 - val_acc: 0.6346 -- iter: 164/164
--
Training Step: 103  | total loss: [1m[32m0.22514[0m[0m | time: 8.469s
[2K
| Adam | epoch: 018 | loss: 0.22514 - acc: 0.9265 -- iter: 032/164
[A[ATraining Step: 104  | total loss: [1m[32m0.23831[0m[0m | time: 10.188s
[2K
| Adam | epoch: 018 | loss: 0.23831 - acc: 0.9276 -- iter: 064/164
[A[ATraining Step: 105  | total loss: [1m[32m0.41466[0m[0m | time: 11.896s
[2K
| Adam | epoch: 018 | loss: 0.41466 - acc: 0.9098 -- iter: 096/164
[A[ATraining Step: 106  | total loss: [1m[32m0.41442[0m[0m | time: 19.800s
[2K
| Adam | epoch: 018 | loss: 0.41442 - acc: 0.8938 -- iter: 128/164
[A[ATraining Step: 107  | total loss: [1m[32m0.38100[0m[0m | time: 27.379s
[2K
| Adam | epoch: 018 | loss: 0.38100 - acc: 0.9045 -- iter: 160/164
[A[ATraining Step: 108  | total loss: [1m[32m0.34455[0m[0m | time: 37.630s
[2K
| Adam | epoch: 018 | loss: 0.34455 - acc: 0.9140 | val_loss: 3.29755 - val_acc: 0.4808 -- iter: 164/164
--
Training Step: 109  | total loss: [1m[32m0.32891[0m[0m | time: 7.921s
[2K
| Adam | epoch: 019 | loss: 0.32891 - acc: 0.9164 -- iter: 032/164
[A[ATraining Step: 110  | total loss: [1m[32m0.31122[0m[0m | time: 15.927s
[2K
| Adam | epoch: 019 | loss: 0.31122 - acc: 0.9185 -- iter: 064/164
[A[ATraining Step: 111  | total loss: [1m[32m0.31580[0m[0m | time: 17.632s
[2K
| Adam | epoch: 019 | loss: 0.31580 - acc: 0.9141 -- iter: 096/164
[A[ATraining Step: 112  | total loss: [1m[32m0.31927[0m[0m | time: 19.346s
[2K
| Adam | epoch: 019 | loss: 0.31927 - acc: 0.8977 -- iter: 128/164
[A[ATraining Step: 113  | total loss: [1m[32m0.30914[0m[0m | time: 27.244s
[2K
| Adam | epoch: 019 | loss: 0.30914 - acc: 0.8829 -- iter: 160/164
[A[ATraining Step: 114  | total loss: [1m[32m0.30203[0m[0m | time: 37.426s
[2K
| Adam | epoch: 019 | loss: 0.30203 - acc: 0.8821 | val_loss: 1.07883 - val_acc: 0.6538 -- iter: 164/164
--
Training Step: 115  | total loss: [1m[32m0.28116[0m[0m | time: 7.863s
[2K
| Adam | epoch: 020 | loss: 0.28116 - acc: 0.8908 -- iter: 032/164
[A[ATraining Step: 116  | total loss: [1m[32m0.26357[0m[0m | time: 15.779s
[2K
| Adam | epoch: 020 | loss: 0.26357 - acc: 0.8986 -- iter: 064/164
[A[ATraining Step: 117  | total loss: [1m[32m0.24020[0m[0m | time: 23.725s
[2K
| Adam | epoch: 020 | loss: 0.24020 - acc: 0.9087 -- iter: 096/164
[A[ATraining Step: 118  | total loss: [1m[32m0.22949[0m[0m | time: 25.502s
[2K
| Adam | epoch: 020 | loss: 0.22949 - acc: 0.9116 -- iter: 128/164
[A[ATraining Step: 119  | total loss: [1m[32m0.28917[0m[0m | time: 27.262s
[2K
| Adam | epoch: 020 | loss: 0.28917 - acc: 0.8955 -- iter: 160/164
[A[ATraining Step: 120  | total loss: [1m[32m0.32141[0m[0m | time: 37.519s
[2K
| Adam | epoch: 020 | loss: 0.32141 - acc: 0.8559 | val_loss: 0.72113 - val_acc: 0.7500 -- iter: 164/164
--
Training Step: 121  | total loss: [1m[32m0.29648[0m[0m | time: 7.945s
[2K
| Adam | epoch: 021 | loss: 0.29648 - acc: 0.8672 -- iter: 032/164
[A[ATraining Step: 122  | total loss: [1m[32m0.28190[0m[0m | time: 15.803s
[2K
| Adam | epoch: 021 | loss: 0.28190 - acc: 0.8773 -- iter: 064/164
[A[ATraining Step: 123  | total loss: [1m[32m0.25846[0m[0m | time: 23.768s
[2K
| Adam | epoch: 021 | loss: 0.25846 - acc: 0.8865 -- iter: 096/164
[A[ATraining Step: 124  | total loss: [1m[32m0.24213[0m[0m | time: 31.535s
[2K
| Adam | epoch: 021 | loss: 0.24213 - acc: 0.8947 -- iter: 128/164
[A[ATraining Step: 125  | total loss: [1m[32m0.22195[0m[0m | time: 33.297s
[2K
| Adam | epoch: 021 | loss: 0.22195 - acc: 0.9052 -- iter: 160/164
[A[ATraining Step: 126  | total loss: [1m[32m0.22072[0m[0m | time: 37.348s
[2K
| Adam | epoch: 021 | loss: 0.22072 - acc: 0.9147 | val_loss: 0.98910 - val_acc: 0.6731 -- iter: 164/164
--
Training Step: 127  | total loss: [1m[32m0.20629[0m[0m | time: 7.875s
[2K
| Adam | epoch: 022 | loss: 0.20629 - acc: 0.9232 -- iter: 032/164
[A[ATraining Step: 128  | total loss: [1m[32m0.20114[0m[0m | time: 15.672s
[2K
| Adam | epoch: 022 | loss: 0.20114 - acc: 0.9247 -- iter: 064/164
[A[ATraining Step: 129  | total loss: [1m[32m0.18652[0m[0m | time: 23.609s
[2K
| Adam | epoch: 022 | loss: 0.18652 - acc: 0.9322 -- iter: 096/164
[A[ATraining Step: 130  | total loss: [1m[32m0.17311[0m[0m | time: 31.419s
[2K
| Adam | epoch: 022 | loss: 0.17311 - acc: 0.9359 -- iter: 128/164
[A[ATraining Step: 131  | total loss: [1m[32m0.16005[0m[0m | time: 40.232s
[2K
| Adam | epoch: 022 | loss: 0.16005 - acc: 0.9423 -- iter: 160/164
[A[ATraining Step: 132  | total loss: [1m[32m0.15190[0m[0m | time: 44.260s
[2K
| Adam | epoch: 022 | loss: 0.15190 - acc: 0.9449 | val_loss: 2.19624 - val_acc: 0.6154 -- iter: 164/164
--
Training Step: 133  | total loss: [1m[32m0.13699[0m[0m | time: 1.728s
[2K
| Adam | epoch: 023 | loss: 0.13699 - acc: 0.9504 -- iter: 032/164
[A[ATraining Step: 134  | total loss: [1m[32m0.12354[0m[0m | time: 9.663s
[2K
| Adam | epoch: 023 | loss: 0.12354 - acc: 0.9554 -- iter: 064/164
[A[ATraining Step: 135  | total loss: [1m[32m0.12000[0m[0m | time: 17.499s
[2K
| Adam | epoch: 023 | loss: 0.12000 - acc: 0.9536 -- iter: 096/164
[A[ATraining Step: 136  | total loss: [1m[32m0.12610[0m[0m | time: 25.302s
[2K
| Adam | epoch: 023 | loss: 0.12610 - acc: 0.9457 -- iter: 128/164
[A[ATraining Step: 137  | total loss: [1m[32m0.11976[0m[0m | time: 33.148s
[2K
| Adam | epoch: 023 | loss: 0.11976 - acc: 0.9480 -- iter: 160/164
[A[ATraining Step: 138  | total loss: [1m[32m0.13322[0m[0m | time: 43.395s
[2K
| Adam | epoch: 023 | loss: 0.13322 - acc: 0.9470 | val_loss: 2.18162 - val_acc: 0.6346 -- iter: 164/164
--
Training Step: 139  | total loss: [1m[32m0.13802[0m[0m | time: 1.780s
[2K
| Adam | epoch: 024 | loss: 0.13802 - acc: 0.9492 -- iter: 032/164
[A[ATraining Step: 140  | total loss: [1m[32m0.24635[0m[0m | time: 3.511s
[2K
| Adam | epoch: 024 | loss: 0.24635 - acc: 0.9042 -- iter: 064/164
[A[ATraining Step: 141  | total loss: [1m[32m0.26701[0m[0m | time: 11.479s
[2K
| Adam | epoch: 024 | loss: 0.26701 - acc: 0.8888 -- iter: 096/164
[A[ATraining Step: 142  | total loss: [1m[32m0.24796[0m[0m | time: 19.542s
[2K
| Adam | epoch: 024 | loss: 0.24796 - acc: 0.8937 -- iter: 128/164
[A[ATraining Step: 143  | total loss: [1m[32m0.26655[0m[0m | time: 27.583s
[2K
| Adam | epoch: 024 | loss: 0.26655 - acc: 0.8887 -- iter: 160/164
[A[ATraining Step: 144  | total loss: [1m[32m0.24303[0m[0m | time: 37.692s
[2K
| Adam | epoch: 024 | loss: 0.24303 - acc: 0.8998 | val_loss: 1.34432 - val_acc: 0.7692 -- iter: 164/164
--
Training Step: 145  | total loss: [1m[32m0.24504[0m[0m | time: 8.024s
[2K
| Adam | epoch: 025 | loss: 0.24504 - acc: 0.9067 -- iter: 032/164
[A[ATraining Step: 146  | total loss: [1m[32m0.22729[0m[0m | time: 9.831s
[2K
| Adam | epoch: 025 | loss: 0.22729 - acc: 0.9129 -- iter: 064/164
[A[ATraining Step: 147  | total loss: [1m[32m0.20493[0m[0m | time: 11.568s
[2K
| Adam | epoch: 025 | loss: 0.20493 - acc: 0.9216 -- iter: 096/164
[A[ATraining Step: 148  | total loss: [1m[32m0.18493[0m[0m | time: 19.428s
[2K
| Adam | epoch: 025 | loss: 0.18493 - acc: 0.9295 -- iter: 128/164
[A[ATraining Step: 149  | total loss: [1m[32m0.17890[0m[0m | time: 27.366s
[2K
| Adam | epoch: 025 | loss: 0.17890 - acc: 0.9303 -- iter: 160/164
[A[ATraining Step: 150  | total loss: [1m[32m0.16265[0m[0m | time: 37.725s
[2K
| Adam | epoch: 025 | loss: 0.16265 - acc: 0.9372 | val_loss: 1.95228 - val_acc: 0.6346 -- iter: 164/164
--
Training Step: 151  | total loss: [1m[32m0.16363[0m[0m | time: 7.980s
[2K
| Adam | epoch: 026 | loss: 0.16363 - acc: 0.9404 -- iter: 032/164
[A[ATraining Step: 152  | total loss: [1m[32m0.14917[0m[0m | time: 15.851s
[2K
| Adam | epoch: 026 | loss: 0.14917 - acc: 0.9464 -- iter: 064/164
[A[ATraining Step: 153  | total loss: [1m[32m0.15662[0m[0m | time: 17.640s
[2K
| Adam | epoch: 026 | loss: 0.15662 - acc: 0.9455 -- iter: 096/164
[A[ATraining Step: 154  | total loss: [1m[32m0.33903[0m[0m | time: 19.382s
[2K
| Adam | epoch: 026 | loss: 0.33903 - acc: 0.9009 -- iter: 128/164
[A[ATraining Step: 155  | total loss: [1m[32m0.46629[0m[0m | time: 27.077s
[2K
| Adam | epoch: 026 | loss: 0.46629 - acc: 0.8108 -- iter: 160/164
[A[ATraining Step: 156  | total loss: [1m[32m0.42261[0m[0m | time: 37.483s
[2K
| Adam | epoch: 026 | loss: 0.42261 - acc: 0.8266 | val_loss: 1.66388 - val_acc: 0.6538 -- iter: 164/164
--
Training Step: 157  | total loss: [1m[32m0.38616[0m[0m | time: 7.894s
[2K
| Adam | epoch: 027 | loss: 0.38616 - acc: 0.8408 -- iter: 032/164
[A[ATraining Step: 158  | total loss: [1m[32m0.37023[0m[0m | time: 15.757s
[2K
| Adam | epoch: 027 | loss: 0.37023 - acc: 0.8505 -- iter: 064/164
[A[ATraining Step: 159  | total loss: [1m[32m0.34191[0m[0m | time: 23.557s
[2K
| Adam | epoch: 027 | loss: 0.34191 - acc: 0.8623 -- iter: 096/164
[A[ATraining Step: 160  | total loss: [1m[32m0.33069[0m[0m | time: 25.303s
[2K
| Adam | epoch: 027 | loss: 0.33069 - acc: 0.8730 -- iter: 128/164
[A[ATraining Step: 161  | total loss: [1m[32m0.38665[0m[0m | time: 26.991s
[2K
| Adam | epoch: 027 | loss: 0.38665 - acc: 0.8607 -- iter: 160/164
[A[ATraining Step: 162  | total loss: [1m[32m0.35749[0m[0m | time: 37.161s
[2K
| Adam | epoch: 027 | loss: 0.35749 - acc: 0.8746 | val_loss: 3.51041 - val_acc: 0.5385 -- iter: 164/164
--
Training Step: 163  | total loss: [1m[32m0.32323[0m[0m | time: 7.740s
[2K
| Adam | epoch: 028 | loss: 0.32323 - acc: 0.8871 -- iter: 032/164
[A[ATraining Step: 164  | total loss: [1m[32m0.35385[0m[0m | time: 15.689s
[2K
| Adam | epoch: 028 | loss: 0.35385 - acc: 0.8828 -- iter: 064/164
[A[ATraining Step: 165  | total loss: [1m[32m0.34533[0m[0m | time: 23.645s
[2K
| Adam | epoch: 028 | loss: 0.34533 - acc: 0.8851 -- iter: 096/164
[A[ATraining Step: 166  | total loss: [1m[32m0.35151[0m[0m | time: 31.468s
[2K
| Adam | epoch: 028 | loss: 0.35151 - acc: 0.8810 -- iter: 128/164
[A[ATraining Step: 167  | total loss: [1m[32m0.34089[0m[0m | time: 33.204s
[2K
| Adam | epoch: 028 | loss: 0.34089 - acc: 0.8804 -- iter: 160/164
[A[ATraining Step: 168  | total loss: [1m[32m0.31698[0m[0m | time: 37.249s
[2K
| Adam | epoch: 028 | loss: 0.31698 - acc: 0.8924 | val_loss: 0.97963 - val_acc: 0.7115 -- iter: 164/164
--
Training Step: 169  | total loss: [1m[32m0.29128[0m[0m | time: 7.937s
[2K
| Adam | epoch: 029 | loss: 0.29128 - acc: 0.9031 -- iter: 032/164
[A[ATraining Step: 170  | total loss: [1m[32m0.29204[0m[0m | time: 15.962s
[2K
| Adam | epoch: 029 | loss: 0.29204 - acc: 0.9003 -- iter: 064/164
[A[ATraining Step: 171  | total loss: [1m[32m0.31049[0m[0m | time: 23.736s
[2K
| Adam | epoch: 029 | loss: 0.31049 - acc: 0.9009 -- iter: 096/164
[A[ATraining Step: 172  | total loss: [1m[32m0.28244[0m[0m | time: 31.700s
[2K
| Adam | epoch: 029 | loss: 0.28244 - acc: 0.9108 -- iter: 128/164
[A[ATraining Step: 173  | total loss: [1m[32m0.26948[0m[0m | time: 39.540s
[2K
| Adam | epoch: 029 | loss: 0.26948 - acc: 0.9135 -- iter: 160/164
[A[ATraining Step: 174  | total loss: [1m[32m0.25217[0m[0m | time: 43.763s
[2K
| Adam | epoch: 029 | loss: 0.25217 - acc: 0.9190 | val_loss: 1.76355 - val_acc: 0.6154 -- iter: 164/164
--
Training Step: 175  | total loss: [1m[32m0.23167[0m[0m | time: 1.725s
[2K
| Adam | epoch: 030 | loss: 0.23167 - acc: 0.9271 -- iter: 032/164
[A[ATraining Step: 176  | total loss: [1m[32m0.21019[0m[0m | time: 9.606s
[2K
| Adam | epoch: 030 | loss: 0.21019 - acc: 0.9344 -- iter: 064/164
[A[ATraining Step: 177  | total loss: [1m[32m0.19671[0m[0m | time: 17.512s
[2K
| Adam | epoch: 030 | loss: 0.19671 - acc: 0.9410 -- iter: 096/164
[A[ATraining Step: 178  | total loss: [1m[32m0.18664[0m[0m | time: 25.607s
[2K
| Adam | epoch: 030 | loss: 0.18664 - acc: 0.9469 -- iter: 128/164
[A[ATraining Step: 179  | total loss: [1m[32m0.17573[0m[0m | time: 33.581s
[2K
| Adam | epoch: 030 | loss: 0.17573 - acc: 0.9491 -- iter: 160/164
[A[ATraining Step: 180  | total loss: [1m[32m0.18323[0m[0m | time: 43.880s
[2K
| Adam | epoch: 030 | loss: 0.18323 - acc: 0.9448 | val_loss: 1.03921 - val_acc: 0.6538 -- iter: 164/164
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7455357142857142
Validation AUPRC:0.6921185731890456
Test AUC:0.8310291858678955
Test AUPRC:0.8544235640378477
BestTestF1Score	0.82	0.48	0.75	0.72	0.94	29	11	10	2	0.01
BestTestMCCScore	0.82	0.48	0.75	0.72	0.94	29	11	10	2	0.01
BestTestAccuracyScore	0.82	0.48	0.75	0.72	0.94	29	11	10	2	0.01
BestValidationF1Score	0.79	0.48	0.73	0.68	0.93	26	12	12	2	0.01
BestValidationMCC	0.79	0.48	0.73	0.68	0.93	26	12	12	2	0.01
BestValidationAccuracy	0.79	0.48	0.73	0.68	0.93	26	12	12	2	0.01
TestPredictions (Threshold:0.01)
CHEMBL10835,TP,ACT,0.44999998807907104	CHEMBL3661398,TP,ACT,0.15000000596046448	CHEMBL3661328,TP,ACT,0.9800000190734863	CHEMBL426881,TN,INACT,0.0	CHEMBL3824249,FP,INACT,0.05999999865889549	CHEMBL3661350,TP,ACT,1.0	CHEMBL3661342,TP,ACT,0.9900000095367432	CHEMBL3661391,TP,ACT,0.5899999737739563	CHEMBL3642231,FP,INACT,0.4000000059604645	CHEMBL3661327,TP,ACT,0.9900000095367432	CHEMBL3661364,TP,ACT,0.07000000029802322	CHEMBL219695,FP,INACT,0.9800000190734863	CHEMBL3099592,TN,INACT,0.0	CHEMBL3661417,TP,ACT,0.800000011920929	CHEMBL3642244,TP,ACT,0.7400000095367432	CHEMBL217942,FP,INACT,0.09000000357627869	CHEMBL214127,TP,ACT,0.5799999833106995	CHEMBL444191,TN,INACT,0.0	CHEMBL1458,TP,ACT,0.46000000834465027	CHEMBL2094355,FP,INACT,0.03999999910593033	CHEMBL2031932,TP,ACT,0.49000000953674316	CHEMBL3657190,FN,ACT,0.009999999776482582	CHEMBL3661381,TP,ACT,0.07999999821186066	CHEMBL376856,FP,INACT,0.09000000357627869	CHEMBL3661357,TP,ACT,0.9900000095367432	CHEMBL482845,FP,INACT,0.029999999329447746	CHEMBL386164,TN,INACT,0.0	CHEMBL384280,FN,ACT,0.009999999776482582	CHEMBL215820,TP,ACT,0.8899999856948853	CHEMBL1257759,TP,ACT,0.11999999731779099	CHEMBL1632453,TN,INACT,0.0	CHEMBL3402236,TN,INACT,0.009999999776482582	CHEMBL213611,TP,ACT,0.949999988079071	CHEMBL251254,TN,INACT,0.0	CHEMBL374864,TN,INACT,0.0	CHEMBL3661378,TP,ACT,0.14000000059604645	CHEMBL3402234,FP,INACT,0.9100000262260437	CHEMBL3661377,TP,ACT,0.9599999785423279	CHEMBL3402235,FP,INACT,0.05999999865889549	CHEMBL67158,TP,ACT,0.9900000095367432	CHEMBL2236327,TP,ACT,0.25	CHEMBL2236326,TP,ACT,0.2199999988079071	CHEMBL3233606,TN,INACT,0.0	CHEMBL3661355,TP,ACT,0.9700000286102295	CHEMBL11524,TP,ACT,0.9100000262260437	CHEMBL2236339,TP,ACT,0.12999999523162842	CHEMBL3222125,FP,INACT,0.6499999761581421	CHEMBL3661400,TP,ACT,0.9100000262260437	CHEMBL365939,TP,ACT,0.15000000596046448	CHEMBL511524,TN,INACT,0.009999999776482582	CHEMBL215025,TP,ACT,0.5099999904632568	CHEMBL3661408,FP,INACT,0.7400000095367432	

