ImageNetInceptionV2 CHEMBL2714 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	122
Number of inactive compounds :	122
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2714_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2714_adam_0.001_15_0.6/
---------------------------------
Training samples: 156
Validation samples: 49
--
Training Step: 1  | time: 100.799s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/156
[A[ATraining Step: 2  | total loss: [1m[32m0.62417[0m[0m | time: 121.894s
[2K
| Adam | epoch: 001 | loss: 0.62417 - acc: 0.5062 -- iter: 064/156
[A[ATraining Step: 3  | total loss: [1m[32m0.48185[0m[0m | time: 148.132s
[2K
| Adam | epoch: 001 | loss: 0.48185 - acc: 0.7057 -- iter: 096/156
[A[ATraining Step: 4  | total loss: [1m[32m0.54348[0m[0m | time: 170.346s
[2K
| Adam | epoch: 001 | loss: 0.54348 - acc: 0.7858 -- iter: 128/156
[A[ATraining Step: 5  | total loss: [1m[32m0.47212[0m[0m | time: 210.999s
[2K
| Adam | epoch: 001 | loss: 0.47212 - acc: 0.8259 | val_loss: 1.97233 - val_acc: 0.5510 -- iter: 156/156
--
Training Step: 6  | total loss: [1m[32m0.41037[0m[0m | time: 20.909s
[2K
| Adam | epoch: 002 | loss: 0.41037 - acc: 0.8460 -- iter: 032/156
[A[ATraining Step: 7  | total loss: [1m[32m0.22438[0m[0m | time: 36.786s
[2K
| Adam | epoch: 002 | loss: 0.22438 - acc: 0.9384 -- iter: 064/156
[A[ATraining Step: 8  | total loss: [1m[32m0.35730[0m[0m | time: 148.805s
[2K
| Adam | epoch: 002 | loss: 0.35730 - acc: 0.8852 -- iter: 096/156
[A[ATraining Step: 9  | total loss: [1m[32m0.44600[0m[0m | time: 269.838s
[2K
| Adam | epoch: 002 | loss: 0.44600 - acc: 0.8301 -- iter: 128/156
[A[ATraining Step: 10  | total loss: [1m[32m0.34291[0m[0m | time: 295.130s
[2K
| Adam | epoch: 002 | loss: 0.34291 - acc: 0.8682 | val_loss: 3.21049 - val_acc: 0.5510 -- iter: 156/156
--
Training Step: 11  | total loss: [1m[32m0.23751[0m[0m | time: 61.069s
[2K
| Adam | epoch: 003 | loss: 0.23751 - acc: 0.9158 -- iter: 032/156
[A[ATraining Step: 12  | total loss: [1m[32m0.19688[0m[0m | time: 101.605s
[2K
| Adam | epoch: 003 | loss: 0.19688 - acc: 0.9055 -- iter: 064/156
[A[ATraining Step: 13  | total loss: [1m[32m0.14873[0m[0m | time: 127.164s
[2K
| Adam | epoch: 003 | loss: 0.14873 - acc: 0.9460 -- iter: 096/156
[A[ATraining Step: 14  | total loss: [1m[32m0.13426[0m[0m | time: 146.019s
[2K
| Adam | epoch: 003 | loss: 0.13426 - acc: 0.9425 -- iter: 128/156
[A[ATraining Step: 15  | total loss: [1m[32m0.16755[0m[0m | time: 171.699s
[2K
| Adam | epoch: 003 | loss: 0.16755 - acc: 0.9283 | val_loss: 2.48226 - val_acc: 0.5510 -- iter: 156/156
--
Training Step: 16  | total loss: [1m[32m0.19252[0m[0m | time: 27.227s
[2K
| Adam | epoch: 004 | loss: 0.19252 - acc: 0.9318 -- iter: 032/156
[A[ATraining Step: 17  | total loss: [1m[32m0.15973[0m[0m | time: 46.851s
[2K
| Adam | epoch: 004 | loss: 0.15973 - acc: 0.9451 -- iter: 064/156
[A[ATraining Step: 18  | total loss: [1m[32m0.16942[0m[0m | time: 63.858s
[2K
| Adam | epoch: 004 | loss: 0.16942 - acc: 0.9270 -- iter: 096/156
[A[ATraining Step: 19  | total loss: [1m[32m0.12634[0m[0m | time: 80.091s
[2K
| Adam | epoch: 004 | loss: 0.12634 - acc: 0.9513 -- iter: 128/156
[A[ATraining Step: 20  | total loss: [1m[32m0.09732[0m[0m | time: 94.989s
[2K
| Adam | epoch: 004 | loss: 0.09732 - acc: 0.9670 | val_loss: 2.60062 - val_acc: 0.5510 -- iter: 156/156
--
Training Step: 21  | total loss: [1m[32m0.11509[0m[0m | time: 22.994s
[2K
| Adam | epoch: 005 | loss: 0.11509 - acc: 0.9578 -- iter: 032/156
[A[ATraining Step: 22  | total loss: [1m[32m0.62559[0m[0m | time: 44.650s
[2K
| Adam | epoch: 005 | loss: 0.62559 - acc: 0.8767 -- iter: 064/156
[A[ATraining Step: 23  | total loss: [1m[32m0.53032[0m[0m | time: 67.399s
[2K
| Adam | epoch: 005 | loss: 0.53032 - acc: 0.8581 -- iter: 096/156
[A[ATraining Step: 24  | total loss: [1m[32m0.42390[0m[0m | time: 85.682s
[2K
| Adam | epoch: 005 | loss: 0.42390 - acc: 0.8779 -- iter: 128/156
[A[ATraining Step: 25  | total loss: [1m[32m0.31760[0m[0m | time: 118.942s
[2K
| Adam | epoch: 005 | loss: 0.31760 - acc: 0.9112 | val_loss: 1.15428 - val_acc: 0.5510 -- iter: 156/156
--
Training Step: 26  | total loss: [1m[32m0.25744[0m[0m | time: 22.463s
[2K
| Adam | epoch: 006 | loss: 0.25744 - acc: 0.9182 -- iter: 032/156
[A[ATraining Step: 27  | total loss: [1m[32m0.22867[0m[0m | time: 46.630s
[2K
| Adam | epoch: 006 | loss: 0.22867 - acc: 0.9231 -- iter: 064/156
[A[ATraining Step: 28  | total loss: [1m[32m0.20726[0m[0m | time: 79.744s
[2K
| Adam | epoch: 006 | loss: 0.20726 - acc: 0.9345 -- iter: 096/156
[A[ATraining Step: 29  | total loss: [1m[32m0.16757[0m[0m | time: 101.779s
[2K
| Adam | epoch: 006 | loss: 0.16757 - acc: 0.9505 -- iter: 128/156
[A[ATraining Step: 30  | total loss: [1m[32m0.15217[0m[0m | time: 133.003s
[2K
| Adam | epoch: 006 | loss: 0.15217 - acc: 0.9537 | val_loss: 1.19321 - val_acc: 0.5510 -- iter: 156/156
--
Training Step: 31  | total loss: [1m[32m0.12884[0m[0m | time: 50.949s
[2K
| Adam | epoch: 007 | loss: 0.12884 - acc: 0.9644 -- iter: 032/156
[A[ATraining Step: 32  | total loss: [1m[32m0.12987[0m[0m | time: 104.184s
[2K
| Adam | epoch: 007 | loss: 0.12987 - acc: 0.9584 -- iter: 064/156
[A[ATraining Step: 33  | total loss: [1m[32m0.12514[0m[0m | time: 125.561s
[2K
| Adam | epoch: 007 | loss: 0.12514 - acc: 0.9606 -- iter: 096/156
[A[ATraining Step: 34  | total loss: [1m[32m0.12100[0m[0m | time: 141.278s
[2K
| Adam | epoch: 007 | loss: 0.12100 - acc: 0.9624 -- iter: 128/156
[A[ATraining Step: 35  | total loss: [1m[32m0.09944[0m[0m | time: 162.915s
[2K
| Adam | epoch: 007 | loss: 0.09944 - acc: 0.9703 | val_loss: 2.41499 - val_acc: 0.5510 -- iter: 156/156
--
Training Step: 36  | total loss: [1m[32m0.08460[0m[0m | time: 39.171s
[2K
| Adam | epoch: 008 | loss: 0.08460 - acc: 0.9763 -- iter: 032/156
[A[ATraining Step: 37  | total loss: [1m[32m0.07096[0m[0m | time: 58.670s
[2K
| Adam | epoch: 008 | loss: 0.07096 - acc: 0.9811 -- iter: 064/156
[A[ATraining Step: 38  | total loss: [1m[32m0.07989[0m[0m | time: 81.417s
[2K
| Adam | epoch: 008 | loss: 0.07989 - acc: 0.9725 -- iter: 096/156
[A[ATraining Step: 39  | total loss: [1m[32m0.07739[0m[0m | time: 107.214s
[2K
| Adam | epoch: 008 | loss: 0.07739 - acc: 0.9718 -- iter: 128/156
[A[ATraining Step: 40  | total loss: [1m[32m0.07791[0m[0m | time: 146.530s
[2K
| Adam | epoch: 008 | loss: 0.07791 - acc: 0.9712 | val_loss: 1.25693 - val_acc: 0.4286 -- iter: 156/156
--
Training Step: 41  | total loss: [1m[32m0.07333[0m[0m | time: 18.946s
[2K
| Adam | epoch: 009 | loss: 0.07333 - acc: 0.9708 -- iter: 032/156
[A[ATraining Step: 42  | total loss: [1m[32m0.06401[0m[0m | time: 39.109s
[2K
| Adam | epoch: 009 | loss: 0.06401 - acc: 0.9760 -- iter: 064/156
[A[ATraining Step: 43  | total loss: [1m[32m0.05430[0m[0m | time: 76.667s
[2K
| Adam | epoch: 009 | loss: 0.05430 - acc: 0.9803 -- iter: 096/156
[A[ATraining Step: 44  | total loss: [1m[32m0.04685[0m[0m | time: 137.495s
[2K
| Adam | epoch: 009 | loss: 0.04685 - acc: 0.9837 -- iter: 128/156
[A[ATraining Step: 45  | total loss: [1m[32m0.05632[0m[0m | time: 192.230s
[2K
| Adam | epoch: 009 | loss: 0.05632 - acc: 0.9811 | val_loss: 2.03823 - val_acc: 0.3878 -- iter: 156/156
--
Training Step: 46  | total loss: [1m[32m0.10922[0m[0m | time: 21.901s
[2K
| Adam | epoch: 010 | loss: 0.10922 - acc: 0.9739 -- iter: 032/156
[A[ATraining Step: 47  | total loss: [1m[32m0.09476[0m[0m | time: 36.702s
[2K
| Adam | epoch: 010 | loss: 0.09476 - acc: 0.9781 -- iter: 064/156
[A[ATraining Step: 48  | total loss: [1m[32m0.08313[0m[0m | time: 50.445s
[2K
| Adam | epoch: 010 | loss: 0.08313 - acc: 0.9817 -- iter: 096/156
[A[ATraining Step: 49  | total loss: [1m[32m0.07289[0m[0m | time: 70.999s
[2K
| Adam | epoch: 010 | loss: 0.07289 - acc: 0.9846 -- iter: 128/156
[A[ATraining Step: 50  | total loss: [1m[32m0.07283[0m[0m | time: 98.709s
[2K
| Adam | epoch: 010 | loss: 0.07283 - acc: 0.9821 | val_loss: 2.71800 - val_acc: 0.4082 -- iter: 156/156
--
Training Step: 51  | total loss: [1m[32m0.08501[0m[0m | time: 18.508s
[2K
| Adam | epoch: 011 | loss: 0.08501 - acc: 0.9801 -- iter: 032/156
[A[ATraining Step: 52  | total loss: [1m[32m0.34167[0m[0m | time: 41.025s
[2K
| Adam | epoch: 011 | loss: 0.34167 - acc: 0.9409 -- iter: 064/156
[A[ATraining Step: 53  | total loss: [1m[32m0.29279[0m[0m | time: 57.658s
[2K
| Adam | epoch: 011 | loss: 0.29279 - acc: 0.9496 -- iter: 096/156
[A[ATraining Step: 54  | total loss: [1m[32m0.27198[0m[0m | time: 73.821s
[2K
| Adam | epoch: 011 | loss: 0.27198 - acc: 0.9465 -- iter: 128/156
[A[ATraining Step: 55  | total loss: [1m[32m0.24606[0m[0m | time: 93.835s
[2K
| Adam | epoch: 011 | loss: 0.24606 - acc: 0.9491 | val_loss: 1.04447 - val_acc: 0.6939 -- iter: 156/156
--
Training Step: 56  | total loss: [1m[32m0.22243[0m[0m | time: 21.869s
[2K
| Adam | epoch: 012 | loss: 0.22243 - acc: 0.9562 -- iter: 032/156
[A[ATraining Step: 57  | total loss: [1m[32m0.21207[0m[0m | time: 45.719s
[2K
| Adam | epoch: 012 | loss: 0.21207 - acc: 0.9493 -- iter: 064/156
[A[ATraining Step: 58  | total loss: [1m[32m0.23387[0m[0m | time: 72.003s
[2K
| Adam | epoch: 012 | loss: 0.23387 - acc: 0.9392 -- iter: 096/156
[A[ATraining Step: 59  | total loss: [1m[32m0.20887[0m[0m | time: 87.644s
[2K
| Adam | epoch: 012 | loss: 0.20887 - acc: 0.9474 -- iter: 128/156
[A[ATraining Step: 60  | total loss: [1m[32m0.19260[0m[0m | time: 109.204s
[2K
| Adam | epoch: 012 | loss: 0.19260 - acc: 0.9543 | val_loss: 0.20534 - val_acc: 0.9184 -- iter: 156/156
--
Training Step: 61  | total loss: [1m[32m0.17820[0m[0m | time: 17.596s
[2K
| Adam | epoch: 013 | loss: 0.17820 - acc: 0.9603 -- iter: 032/156
[A[ATraining Step: 62  | total loss: [1m[32m0.16095[0m[0m | time: 35.176s
[2K
| Adam | epoch: 013 | loss: 0.16095 - acc: 0.9654 -- iter: 064/156
[A[ATraining Step: 63  | total loss: [1m[32m0.15095[0m[0m | time: 52.765s
[2K
| Adam | epoch: 013 | loss: 0.15095 - acc: 0.9658 -- iter: 096/156
[A[ATraining Step: 64  | total loss: [1m[32m0.30111[0m[0m | time: 70.009s
[2K
| Adam | epoch: 013 | loss: 0.30111 - acc: 0.9388 -- iter: 128/156
[A[ATraining Step: 65  | total loss: [1m[32m0.26742[0m[0m | time: 84.769s
[2K
| Adam | epoch: 013 | loss: 0.26742 - acc: 0.9464 | val_loss: 0.26042 - val_acc: 0.9184 -- iter: 156/156
--
Training Step: 66  | total loss: [1m[32m0.23935[0m[0m | time: 15.221s
[2K
| Adam | epoch: 014 | loss: 0.23935 - acc: 0.9529 -- iter: 032/156
[A[ATraining Step: 67  | total loss: [1m[32m0.21567[0m[0m | time: 32.785s
[2K
| Adam | epoch: 014 | loss: 0.21567 - acc: 0.9586 -- iter: 064/156
[A[ATraining Step: 68  | total loss: [1m[32m0.19987[0m[0m | time: 50.735s
[2K
| Adam | epoch: 014 | loss: 0.19987 - acc: 0.9635 -- iter: 096/156
[A[ATraining Step: 69  | total loss: [1m[32m0.19631[0m[0m | time: 68.947s
[2K
| Adam | epoch: 014 | loss: 0.19631 - acc: 0.9604 -- iter: 128/156
[A[ATraining Step: 70  | total loss: [1m[32m0.19320[0m[0m | time: 91.911s
[2K
| Adam | epoch: 014 | loss: 0.19320 - acc: 0.9614 | val_loss: 0.23943 - val_acc: 0.9184 -- iter: 156/156
--
Training Step: 71  | total loss: [1m[32m0.18093[0m[0m | time: 15.924s
[2K
| Adam | epoch: 015 | loss: 0.18093 - acc: 0.9658 -- iter: 032/156
[A[ATraining Step: 72  | total loss: [1m[32m0.16858[0m[0m | time: 28.069s
[2K
| Adam | epoch: 015 | loss: 0.16858 - acc: 0.9656 -- iter: 064/156
[A[ATraining Step: 73  | total loss: [1m[32m0.15451[0m[0m | time: 40.992s
[2K
| Adam | epoch: 015 | loss: 0.15451 - acc: 0.9694 -- iter: 096/156
[A[ATraining Step: 74  | total loss: [1m[32m0.14004[0m[0m | time: 56.177s
[2K
| Adam | epoch: 015 | loss: 0.14004 - acc: 0.9728 -- iter: 128/156
[A[ATraining Step: 75  | total loss: [1m[32m0.12581[0m[0m | time: 78.813s
[2K
| Adam | epoch: 015 | loss: 0.12581 - acc: 0.9757 | val_loss: 0.51407 - val_acc: 0.8980 -- iter: 156/156
--
Validation AUC:0.9562289562289562
Validation AUPRC:0.9403173841363858
Test AUC:0.979933110367893
Test AUPRC:0.9707501087155292
BestTestF1Score	0.98	0.96	0.98	0.96	1.0	23	1	25	0	0.93
BestTestMCCScore	0.98	0.96	0.98	0.96	1.0	23	1	25	0	0.93
BestTestAccuracyScore	0.98	0.96	0.98	0.96	1.0	23	1	25	0	0.93
BestValidationF1Score	0.92	0.85	0.92	0.85	1.0	22	4	23	0	0.93
BestValidationMCC	0.92	0.85	0.92	0.85	1.0	22	4	23	0	0.93
BestValidationAccuracy	0.92	0.85	0.92	0.85	1.0	22	4	23	0	0.93
TestPredictions (Threshold:0.93)
CHEMBL124945,TP,ACT,1.0	CHEMBL3688805,TN,INACT,0.0	CHEMBL432824,TP,ACT,1.0	CHEMBL333564,TP,ACT,0.9700000286102295	CHEMBL90912,TP,ACT,1.0	CHEMBL500555,TN,INACT,0.23999999463558197	CHEMBL398418,TN,INACT,0.0	CHEMBL262137,TP,ACT,1.0	CHEMBL2349471,TN,INACT,0.0	CHEMBL534410,TN,INACT,0.0	CHEMBL3344263,FP,INACT,1.0	CHEMBL583887,TN,INACT,0.0	CHEMBL166175,TP,ACT,1.0	CHEMBL2311113,TP,ACT,0.9800000190734863	CHEMBL562290,TN,INACT,0.0	CHEMBL272714,TN,INACT,0.3100000023841858	CHEMBL400530,TN,INACT,0.009999999776482582	CHEMBL3142509,TP,ACT,0.9900000095367432	CHEMBL172581,TP,ACT,0.9700000286102295	CHEMBL3683914,TN,INACT,0.27000001072883606	CHEMBL94122,TP,ACT,1.0	CHEMBL3688799,TN,INACT,0.14000000059604645	CHEMBL126807,TP,ACT,1.0	CHEMBL1091441,TN,INACT,0.0	CHEMBL94125,TP,ACT,1.0	CHEMBL3349397,TP,ACT,1.0	CHEMBL258277,TN,INACT,0.0	CHEMBL123741,TP,ACT,0.9900000095367432	CHEMBL174197,TP,ACT,1.0	CHEMBL1092227,TN,INACT,0.009999999776482582	CHEMBL3127078,TN,INACT,0.0	CHEMBL172638,TP,ACT,1.0	CHEMBL3127095,TN,INACT,0.0	CHEMBL3349396,TP,ACT,1.0	CHEMBL3142507,TP,ACT,0.9900000095367432	CHEMBL333332,TP,ACT,0.9900000095367432	CHEMBL125900,TP,ACT,1.0	CHEMBL598876,TN,INACT,0.0	CHEMBL3353630,TN,INACT,0.05999999865889549	CHEMBL402120,TN,INACT,0.9200000166893005	CHEMBL91089,TP,ACT,1.0	CHEMBL493807,TN,INACT,0.009999999776482582	CHEMBL339356,TP,ACT,1.0	CHEMBL217068,TN,INACT,0.0	CHEMBL2322538,TN,INACT,0.15000000596046448	CHEMBL72555,TP,ACT,1.0	CHEMBL566969,TN,INACT,0.0	CHEMBL3688766,TN,INACT,0.0	CHEMBL1210337,TN,INACT,0.0	

