ImageNetInceptionV2 CHEMBL2889 adam 0.0005 30 0 0 0.6 False True
Number of active compounds :	116
Number of inactive compounds :	116
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2889_adam_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2889_adam_0.0005_30_0.6/
---------------------------------
Training samples: 146
Validation samples: 46
--
Training Step: 1  | time: 68.446s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/146
[A[ATraining Step: 2  | total loss: [1m[32m0.63382[0m[0m | time: 86.192s
[2K
| Adam | epoch: 001 | loss: 0.63382 - acc: 0.4219 -- iter: 064/146
[A[ATraining Step: 3  | total loss: [1m[32m0.78236[0m[0m | time: 108.647s
[2K
| Adam | epoch: 001 | loss: 0.78236 - acc: 0.3835 -- iter: 096/146
[A[ATraining Step: 4  | total loss: [1m[32m0.65803[0m[0m | time: 128.472s
[2K
| Adam | epoch: 001 | loss: 0.65803 - acc: 0.5881 -- iter: 128/146
[A[ATraining Step: 5  | total loss: [1m[32m0.59465[0m[0m | time: 152.039s
[2K
| Adam | epoch: 001 | loss: 0.59465 - acc: 0.6569 | val_loss: 0.76758 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 6  | total loss: [1m[32m0.64327[0m[0m | time: 8.494s
[2K
| Adam | epoch: 002 | loss: 0.64327 - acc: 0.6275 -- iter: 032/146
[A[ATraining Step: 7  | total loss: [1m[32m0.41458[0m[0m | time: 50.507s
[2K
| Adam | epoch: 002 | loss: 0.41458 - acc: 0.8510 -- iter: 064/146
[A[ATraining Step: 8  | total loss: [1m[32m0.40781[0m[0m | time: 76.552s
[2K
| Adam | epoch: 002 | loss: 0.40781 - acc: 0.8118 -- iter: 096/146
[A[ATraining Step: 9  | total loss: [1m[32m0.62134[0m[0m | time: 90.201s
[2K
| Adam | epoch: 002 | loss: 0.62134 - acc: 0.7460 -- iter: 128/146
[A[ATraining Step: 10  | total loss: [1m[32m0.57037[0m[0m | time: 107.683s
[2K
| Adam | epoch: 002 | loss: 0.57037 - acc: 0.7792 | val_loss: 0.70391 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 11  | total loss: [1m[32m0.46529[0m[0m | time: 9.182s
[2K
| Adam | epoch: 003 | loss: 0.46529 - acc: 0.8246 -- iter: 032/146
[A[ATraining Step: 12  | total loss: [1m[32m0.38278[0m[0m | time: 17.979s
[2K
| Adam | epoch: 003 | loss: 0.38278 - acc: 0.8535 -- iter: 064/146
[A[ATraining Step: 13  | total loss: [1m[32m0.26382[0m[0m | time: 30.958s
[2K
| Adam | epoch: 003 | loss: 0.26382 - acc: 0.8925 -- iter: 096/146
[A[ATraining Step: 14  | total loss: [1m[32m0.36306[0m[0m | time: 47.232s
[2K
| Adam | epoch: 003 | loss: 0.36306 - acc: 0.8726 -- iter: 128/146
[A[ATraining Step: 15  | total loss: [1m[32m0.35162[0m[0m | time: 69.137s
[2K
| Adam | epoch: 003 | loss: 0.35162 - acc: 0.8735 | val_loss: 0.96434 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 16  | total loss: [1m[32m0.37775[0m[0m | time: 11.083s
[2K
| Adam | epoch: 004 | loss: 0.37775 - acc: 0.8858 -- iter: 032/146
[A[ATraining Step: 17  | total loss: [1m[32m0.30078[0m[0m | time: 16.724s
[2K
| Adam | epoch: 004 | loss: 0.30078 - acc: 0.9044 -- iter: 064/146
[A[ATraining Step: 18  | total loss: [1m[32m0.23565[0m[0m | time: 22.424s
[2K
| Adam | epoch: 004 | loss: 0.23565 - acc: 0.9375 -- iter: 096/146
[A[ATraining Step: 19  | total loss: [1m[32m0.17040[0m[0m | time: 31.629s
[2K
| Adam | epoch: 004 | loss: 0.17040 - acc: 0.9583 -- iter: 128/146
[A[ATraining Step: 20  | total loss: [1m[32m0.15947[0m[0m | time: 60.910s
[2K
| Adam | epoch: 004 | loss: 0.15947 - acc: 0.9516 | val_loss: 1.63585 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 21  | total loss: [1m[32m0.15925[0m[0m | time: 13.398s
[2K
| Adam | epoch: 005 | loss: 0.15925 - acc: 0.9472 -- iter: 032/146
[A[ATraining Step: 22  | total loss: [1m[32m0.14907[0m[0m | time: 28.792s
[2K
| Adam | epoch: 005 | loss: 0.14907 - acc: 0.9537 -- iter: 064/146
[A[ATraining Step: 23  | total loss: [1m[32m0.13158[0m[0m | time: 40.079s
[2K
| Adam | epoch: 005 | loss: 0.13158 - acc: 0.9490 -- iter: 096/146
[A[ATraining Step: 24  | total loss: [1m[32m0.11124[0m[0m | time: 51.649s
[2K
| Adam | epoch: 005 | loss: 0.11124 - acc: 0.9633 -- iter: 128/146
[A[ATraining Step: 25  | total loss: [1m[32m0.09008[0m[0m | time: 73.447s
[2K
| Adam | epoch: 005 | loss: 0.09008 - acc: 0.9733 | val_loss: 2.85928 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 26  | total loss: [1m[32m0.07192[0m[0m | time: 53.452s
[2K
| Adam | epoch: 006 | loss: 0.07192 - acc: 0.9804 -- iter: 032/146
[A[ATraining Step: 27  | total loss: [1m[32m0.10936[0m[0m | time: 100.870s
[2K
| Adam | epoch: 006 | loss: 0.10936 - acc: 0.9533 -- iter: 064/146
[A[ATraining Step: 28  | total loss: [1m[32m0.14279[0m[0m | time: 153.137s
[2K
| Adam | epoch: 006 | loss: 0.14279 - acc: 0.9572 -- iter: 096/146
[A[ATraining Step: 29  | total loss: [1m[32m0.11532[0m[0m | time: 164.692s
[2K
| Adam | epoch: 006 | loss: 0.11532 - acc: 0.9676 -- iter: 128/146
[A[ATraining Step: 30  | total loss: [1m[32m0.09990[0m[0m | time: 180.454s
[2K
| Adam | epoch: 006 | loss: 0.09990 - acc: 0.9753 | val_loss: 0.96551 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 31  | total loss: [1m[32m0.08150[0m[0m | time: 27.925s
[2K
| Adam | epoch: 007 | loss: 0.08150 - acc: 0.9810 -- iter: 032/146
[A[ATraining Step: 32  | total loss: [1m[32m0.08661[0m[0m | time: 45.000s
[2K
| Adam | epoch: 007 | loss: 0.08661 - acc: 0.9782 -- iter: 064/146
[A[ATraining Step: 33  | total loss: [1m[32m0.10220[0m[0m | time: 62.200s
[2K
| Adam | epoch: 007 | loss: 0.10220 - acc: 0.9761 -- iter: 096/146
[A[ATraining Step: 34  | total loss: [1m[32m0.12840[0m[0m | time: 79.374s
[2K
| Adam | epoch: 007 | loss: 0.12840 - acc: 0.9679 -- iter: 128/146
[A[ATraining Step: 35  | total loss: [1m[32m0.11244[0m[0m | time: 95.692s
[2K
| Adam | epoch: 007 | loss: 0.11244 - acc: 0.9680 | val_loss: 2.13180 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 36  | total loss: [1m[32m0.09396[0m[0m | time: 11.405s
[2K
| Adam | epoch: 008 | loss: 0.09396 - acc: 0.9746 -- iter: 032/146
[A[ATraining Step: 37  | total loss: [1m[32m0.07797[0m[0m | time: 27.855s
[2K
| Adam | epoch: 008 | loss: 0.07797 - acc: 0.9797 -- iter: 064/146
[A[ATraining Step: 38  | total loss: [1m[32m0.08586[0m[0m | time: 45.155s
[2K
| Adam | epoch: 008 | loss: 0.08586 - acc: 0.9714 -- iter: 096/146
[A[ATraining Step: 39  | total loss: [1m[32m0.15697[0m[0m | time: 62.461s
[2K
| Adam | epoch: 008 | loss: 0.15697 - acc: 0.9589 -- iter: 128/146
[A[ATraining Step: 40  | total loss: [1m[32m0.14114[0m[0m | time: 84.364s
[2K
| Adam | epoch: 008 | loss: 0.14114 - acc: 0.9608 | val_loss: 1.52025 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 41  | total loss: [1m[32m0.13124[0m[0m | time: 11.879s
[2K
| Adam | epoch: 009 | loss: 0.13124 - acc: 0.9565 -- iter: 032/146
[A[ATraining Step: 42  | total loss: [1m[32m0.12985[0m[0m | time: 22.753s
[2K
| Adam | epoch: 009 | loss: 0.12985 - acc: 0.9543 -- iter: 064/146
[A[ATraining Step: 43  | total loss: [1m[32m0.11283[0m[0m | time: 36.253s
[2K
| Adam | epoch: 009 | loss: 0.11283 - acc: 0.9624 -- iter: 096/146
[A[ATraining Step: 44  | total loss: [1m[32m0.10271[0m[0m | time: 47.371s
[2K
| Adam | epoch: 009 | loss: 0.10271 - acc: 0.9635 -- iter: 128/146
[A[ATraining Step: 45  | total loss: [1m[32m0.12757[0m[0m | time: 63.733s
[2K
| Adam | epoch: 009 | loss: 0.12757 - acc: 0.9644 | val_loss: 1.00991 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 46  | total loss: [1m[32m0.11259[0m[0m | time: 19.652s
[2K
| Adam | epoch: 010 | loss: 0.11259 - acc: 0.9703 -- iter: 032/146
[A[ATraining Step: 47  | total loss: [1m[32m0.11786[0m[0m | time: 30.716s
[2K
| Adam | epoch: 010 | loss: 0.11786 - acc: 0.9701 -- iter: 064/146
[A[ATraining Step: 48  | total loss: [1m[32m0.10706[0m[0m | time: 41.299s
[2K
| Adam | epoch: 010 | loss: 0.10706 - acc: 0.9749 -- iter: 096/146
[A[ATraining Step: 49  | total loss: [1m[32m0.09517[0m[0m | time: 54.029s
[2K
| Adam | epoch: 010 | loss: 0.09517 - acc: 0.9788 -- iter: 128/146
[A[ATraining Step: 50  | total loss: [1m[32m0.08799[0m[0m | time: 70.906s
[2K
| Adam | epoch: 010 | loss: 0.08799 - acc: 0.9821 | val_loss: 1.55197 - val_acc: 0.3696 -- iter: 146/146
--
Training Step: 51  | total loss: [1m[32m0.09112[0m[0m | time: 13.633s
[2K
| Adam | epoch: 011 | loss: 0.09112 - acc: 0.9753 -- iter: 032/146
[A[ATraining Step: 52  | total loss: [1m[32m0.09105[0m[0m | time: 27.133s
[2K
| Adam | epoch: 011 | loss: 0.09105 - acc: 0.9696 -- iter: 064/146
[A[ATraining Step: 53  | total loss: [1m[32m0.08227[0m[0m | time: 35.905s
[2K
| Adam | epoch: 011 | loss: 0.08227 - acc: 0.9741 -- iter: 096/146
[A[ATraining Step: 54  | total loss: [1m[32m0.07603[0m[0m | time: 46.800s
[2K
| Adam | epoch: 011 | loss: 0.07603 - acc: 0.9779 -- iter: 128/146
[A[ATraining Step: 55  | total loss: [1m[32m0.06940[0m[0m | time: 67.260s
[2K
| Adam | epoch: 011 | loss: 0.06940 - acc: 0.9810 | val_loss: 2.68768 - val_acc: 0.3913 -- iter: 146/146
--
Training Step: 56  | total loss: [1m[32m0.06354[0m[0m | time: 19.929s
[2K
| Adam | epoch: 012 | loss: 0.06354 - acc: 0.9837 -- iter: 032/146
[A[ATraining Step: 57  | total loss: [1m[32m0.05717[0m[0m | time: 62.704s
[2K
| Adam | epoch: 012 | loss: 0.05717 - acc: 0.9860 -- iter: 064/146
[A[ATraining Step: 58  | total loss: [1m[32m0.07186[0m[0m | time: 87.020s
[2K
| Adam | epoch: 012 | loss: 0.07186 - acc: 0.9836 -- iter: 096/146
[A[ATraining Step: 59  | total loss: [1m[32m0.06971[0m[0m | time: 97.329s
[2K
| Adam | epoch: 012 | loss: 0.06971 - acc: 0.9816 -- iter: 128/146
[A[ATraining Step: 60  | total loss: [1m[32m0.06093[0m[0m | time: 112.313s
[2K
| Adam | epoch: 012 | loss: 0.06093 - acc: 0.9841 | val_loss: 4.27322 - val_acc: 0.3913 -- iter: 146/146
--
Training Step: 61  | total loss: [1m[32m0.05364[0m[0m | time: 16.903s
[2K
| Adam | epoch: 013 | loss: 0.05364 - acc: 0.9861 -- iter: 032/146
[A[ATraining Step: 62  | total loss: [1m[32m0.04942[0m[0m | time: 30.723s
[2K
| Adam | epoch: 013 | loss: 0.04942 - acc: 0.9879 -- iter: 064/146
[A[ATraining Step: 63  | total loss: [1m[32m0.07668[0m[0m | time: 44.391s
[2K
| Adam | epoch: 013 | loss: 0.07668 - acc: 0.9855 -- iter: 096/146
[A[ATraining Step: 64  | total loss: [1m[32m0.28422[0m[0m | time: 57.747s
[2K
| Adam | epoch: 013 | loss: 0.28422 - acc: 0.9560 -- iter: 128/146
[A[ATraining Step: 65  | total loss: [1m[32m0.25903[0m[0m | time: 69.988s
[2K
| Adam | epoch: 013 | loss: 0.25903 - acc: 0.9576 | val_loss: 2.41961 - val_acc: 0.4348 -- iter: 146/146
--
Training Step: 66  | total loss: [1m[32m0.23293[0m[0m | time: 8.532s
[2K
| Adam | epoch: 014 | loss: 0.23293 - acc: 0.9628 -- iter: 032/146
[A[ATraining Step: 67  | total loss: [1m[32m0.20724[0m[0m | time: 21.715s
[2K
| Adam | epoch: 014 | loss: 0.20724 - acc: 0.9672 -- iter: 064/146
[A[ATraining Step: 68  | total loss: [1m[32m0.21308[0m[0m | time: 35.284s
[2K
| Adam | epoch: 014 | loss: 0.21308 - acc: 0.9526 -- iter: 096/146
[A[ATraining Step: 69  | total loss: [1m[32m0.19301[0m[0m | time: 43.892s
[2K
| Adam | epoch: 014 | loss: 0.19301 - acc: 0.9545 -- iter: 128/146
[A[ATraining Step: 70  | total loss: [1m[32m0.22152[0m[0m | time: 54.721s
[2K
| Adam | epoch: 014 | loss: 0.22152 - acc: 0.9381 | val_loss: 2.71116 - val_acc: 0.6304 -- iter: 146/146
--
Training Step: 71  | total loss: [1m[32m0.21032[0m[0m | time: 8.974s
[2K
| Adam | epoch: 015 | loss: 0.21032 - acc: 0.9380 -- iter: 032/146
[A[ATraining Step: 72  | total loss: [1m[32m0.19567[0m[0m | time: 17.178s
[2K
| Adam | epoch: 015 | loss: 0.19567 - acc: 0.9388 -- iter: 064/146
[A[ATraining Step: 73  | total loss: [1m[32m0.17554[0m[0m | time: 30.259s
[2K
| Adam | epoch: 015 | loss: 0.17554 - acc: 0.9456 -- iter: 096/146
[A[ATraining Step: 74  | total loss: [1m[32m0.17421[0m[0m | time: 43.445s
[2K
| Adam | epoch: 015 | loss: 0.17421 - acc: 0.9447 -- iter: 128/146
[A[ATraining Step: 75  | total loss: [1m[32m0.19330[0m[0m | time: 60.310s
[2K
| Adam | epoch: 015 | loss: 0.19330 - acc: 0.9304 | val_loss: 1.61635 - val_acc: 0.6522 -- iter: 146/146
--
Training Step: 76  | total loss: [1m[32m0.20546[0m[0m | time: 13.248s
[2K
| Adam | epoch: 016 | loss: 0.20546 - acc: 0.9311 -- iter: 032/146
[A[ATraining Step: 77  | total loss: [1m[32m0.18468[0m[0m | time: 21.598s
[2K
| Adam | epoch: 016 | loss: 0.18468 - acc: 0.9384 -- iter: 064/146
[A[ATraining Step: 78  | total loss: [1m[32m0.21424[0m[0m | time: 30.330s
[2K
| Adam | epoch: 016 | loss: 0.21424 - acc: 0.9274 -- iter: 096/146
[A[ATraining Step: 79  | total loss: [1m[32m0.21053[0m[0m | time: 43.639s
[2K
| Adam | epoch: 016 | loss: 0.21053 - acc: 0.9292 -- iter: 128/146
[A[ATraining Step: 80  | total loss: [1m[32m0.20207[0m[0m | time: 60.148s
[2K
| Adam | epoch: 016 | loss: 0.20207 - acc: 0.9332 | val_loss: 2.64266 - val_acc: 0.4130 -- iter: 146/146
--
Training Step: 81  | total loss: [1m[32m0.18815[0m[0m | time: 13.353s
[2K
| Adam | epoch: 017 | loss: 0.18815 - acc: 0.9400 -- iter: 032/146
[A[ATraining Step: 82  | total loss: [1m[32m0.18141[0m[0m | time: 25.852s
[2K
| Adam | epoch: 017 | loss: 0.18141 - acc: 0.9397 -- iter: 064/146
[A[ATraining Step: 83  | total loss: [1m[32m0.17531[0m[0m | time: 34.353s
[2K
| Adam | epoch: 017 | loss: 0.17531 - acc: 0.9395 -- iter: 096/146
[A[ATraining Step: 84  | total loss: [1m[32m0.16298[0m[0m | time: 43.404s
[2K
| Adam | epoch: 017 | loss: 0.16298 - acc: 0.9456 -- iter: 128/146
[A[ATraining Step: 85  | total loss: [1m[32m0.15096[0m[0m | time: 60.237s
[2K
| Adam | epoch: 017 | loss: 0.15096 - acc: 0.9510 | val_loss: 3.78207 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 86  | total loss: [1m[32m0.14494[0m[0m | time: 13.116s
[2K
| Adam | epoch: 018 | loss: 0.14494 - acc: 0.9528 -- iter: 032/146
[A[ATraining Step: 87  | total loss: [1m[32m0.13739[0m[0m | time: 26.704s
[2K
| Adam | epoch: 018 | loss: 0.13739 - acc: 0.9544 -- iter: 064/146
[A[ATraining Step: 88  | total loss: [1m[32m0.31835[0m[0m | time: 40.232s
[2K
| Adam | epoch: 018 | loss: 0.31835 - acc: 0.9183 -- iter: 096/146
[A[ATraining Step: 89  | total loss: [1m[32m0.30000[0m[0m | time: 48.622s
[2K
| Adam | epoch: 018 | loss: 0.30000 - acc: 0.9234 -- iter: 128/146
[A[ATraining Step: 90  | total loss: [1m[32m0.27182[0m[0m | time: 60.489s
[2K
| Adam | epoch: 018 | loss: 0.27182 - acc: 0.9310 | val_loss: 5.81872 - val_acc: 0.5870 -- iter: 146/146
--
Training Step: 91  | total loss: [1m[32m0.24655[0m[0m | time: 9.072s
[2K
| Adam | epoch: 019 | loss: 0.24655 - acc: 0.9379 -- iter: 032/146
[A[ATraining Step: 92  | total loss: [1m[32m0.22533[0m[0m | time: 18.185s
[2K
| Adam | epoch: 019 | loss: 0.22533 - acc: 0.9441 -- iter: 064/146
[A[ATraining Step: 93  | total loss: [1m[32m0.21286[0m[0m | time: 28.461s
[2K
| Adam | epoch: 019 | loss: 0.21286 - acc: 0.9435 -- iter: 096/146
[A[ATraining Step: 94  | total loss: [1m[32m0.21923[0m[0m | time: 41.655s
[2K
| Adam | epoch: 019 | loss: 0.21923 - acc: 0.9460 -- iter: 128/146
[A[ATraining Step: 95  | total loss: [1m[32m0.19937[0m[0m | time: 53.513s
[2K
| Adam | epoch: 019 | loss: 0.19937 - acc: 0.9514 | val_loss: 4.46867 - val_acc: 0.6087 -- iter: 146/146
--
Training Step: 96  | total loss: [1m[32m0.18160[0m[0m | time: 8.626s
[2K
| Adam | epoch: 020 | loss: 0.18160 - acc: 0.9563 -- iter: 032/146
[A[ATraining Step: 97  | total loss: [1m[32m0.16502[0m[0m | time: 22.296s
[2K
| Adam | epoch: 020 | loss: 0.16502 - acc: 0.9606 -- iter: 064/146
[A[ATraining Step: 98  | total loss: [1m[32m0.16080[0m[0m | time: 35.827s
[2K
| Adam | epoch: 020 | loss: 0.16080 - acc: 0.9583 -- iter: 096/146
[A[ATraining Step: 99  | total loss: [1m[32m0.14724[0m[0m | time: 49.199s
[2K
| Adam | epoch: 020 | loss: 0.14724 - acc: 0.9625 -- iter: 128/146
[A[ATraining Step: 100  | total loss: [1m[32m0.18878[0m[0m | time: 66.174s
[2K
| Adam | epoch: 020 | loss: 0.18878 - acc: 0.9569 | val_loss: 1.34603 - val_acc: 0.6304 -- iter: 146/146
--
Training Step: 101  | total loss: [1m[32m0.17358[0m[0m | time: 8.686s
[2K
| Adam | epoch: 021 | loss: 0.17358 - acc: 0.9612 -- iter: 032/146
[A[ATraining Step: 102  | total loss: [1m[32m0.15876[0m[0m | time: 17.437s
[2K
| Adam | epoch: 021 | loss: 0.15876 - acc: 0.9651 -- iter: 064/146
[A[ATraining Step: 103  | total loss: [1m[32m0.14584[0m[0m | time: 31.059s
[2K
| Adam | epoch: 021 | loss: 0.14584 - acc: 0.9686 -- iter: 096/146
[A[ATraining Step: 104  | total loss: [1m[32m0.13362[0m[0m | time: 44.625s
[2K
| Adam | epoch: 021 | loss: 0.13362 - acc: 0.9717 -- iter: 128/146
[A[ATraining Step: 105  | total loss: [1m[32m0.12194[0m[0m | time: 61.700s
[2K
| Adam | epoch: 021 | loss: 0.12194 - acc: 0.9745 | val_loss: 0.76144 - val_acc: 0.7174 -- iter: 146/146
--
Training Step: 106  | total loss: [1m[32m0.19827[0m[0m | time: 13.394s
[2K
| Adam | epoch: 022 | loss: 0.19827 - acc: 0.9614 -- iter: 032/146
[A[ATraining Step: 107  | total loss: [1m[32m0.17978[0m[0m | time: 22.191s
[2K
| Adam | epoch: 022 | loss: 0.17978 - acc: 0.9653 -- iter: 064/146
[A[ATraining Step: 108  | total loss: [1m[32m0.16670[0m[0m | time: 30.539s
[2K
| Adam | epoch: 022 | loss: 0.16670 - acc: 0.9688 -- iter: 096/146
[A[ATraining Step: 109  | total loss: [1m[32m0.15297[0m[0m | time: 43.693s
[2K
| Adam | epoch: 022 | loss: 0.15297 - acc: 0.9719 -- iter: 128/146
[A[ATraining Step: 110  | total loss: [1m[32m0.14057[0m[0m | time: 60.537s
[2K
| Adam | epoch: 022 | loss: 0.14057 - acc: 0.9747 | val_loss: 1.31755 - val_acc: 0.6522 -- iter: 146/146
--
Training Step: 111  | total loss: [1m[32m0.12920[0m[0m | time: 13.302s
[2K
| Adam | epoch: 023 | loss: 0.12920 - acc: 0.9772 -- iter: 032/146
[A[ATraining Step: 112  | total loss: [1m[32m0.14879[0m[0m | time: 26.524s
[2K
| Adam | epoch: 023 | loss: 0.14879 - acc: 0.9733 -- iter: 064/146
[A[ATraining Step: 113  | total loss: [1m[32m0.13703[0m[0m | time: 35.783s
[2K
| Adam | epoch: 023 | loss: 0.13703 - acc: 0.9728 -- iter: 096/146
[A[ATraining Step: 114  | total loss: [1m[32m0.13451[0m[0m | time: 44.069s
[2K
| Adam | epoch: 023 | loss: 0.13451 - acc: 0.9700 -- iter: 128/146
[A[ATraining Step: 115  | total loss: [1m[32m0.12582[0m[0m | time: 61.745s
[2K
| Adam | epoch: 023 | loss: 0.12582 - acc: 0.9730 | val_loss: 1.74974 - val_acc: 0.6304 -- iter: 146/146
--
Training Step: 116  | total loss: [1m[32m0.11546[0m[0m | time: 13.311s
[2K
| Adam | epoch: 024 | loss: 0.11546 - acc: 0.9757 -- iter: 032/146
[A[ATraining Step: 117  | total loss: [1m[32m0.10610[0m[0m | time: 26.368s
[2K
| Adam | epoch: 024 | loss: 0.10610 - acc: 0.9781 -- iter: 064/146
[A[ATraining Step: 118  | total loss: [1m[32m0.13962[0m[0m | time: 35.212s
[2K
| Adam | epoch: 024 | loss: 0.13962 - acc: 0.9741 -- iter: 096/146
[A[ATraining Step: 119  | total loss: [1m[32m0.12876[0m[0m | time: 40.985s
[2K
| Adam | epoch: 024 | loss: 0.12876 - acc: 0.9766 -- iter: 128/146
[A[ATraining Step: 120  | total loss: [1m[32m0.11883[0m[0m | time: 48.927s
[2K
| Adam | epoch: 024 | loss: 0.11883 - acc: 0.9790 | val_loss: 1.11537 - val_acc: 0.6522 -- iter: 146/146
--
Training Step: 121  | total loss: [1m[32m0.10887[0m[0m | time: 13.211s
[2K
| Adam | epoch: 025 | loss: 0.10887 - acc: 0.9811 -- iter: 032/146
[A[ATraining Step: 122  | total loss: [1m[32m0.11452[0m[0m | time: 26.391s
[2K
| Adam | epoch: 025 | loss: 0.11452 - acc: 0.9798 -- iter: 064/146
[A[ATraining Step: 123  | total loss: [1m[32m0.10455[0m[0m | time: 39.532s
[2K
| Adam | epoch: 025 | loss: 0.10455 - acc: 0.9819 -- iter: 096/146
[A[ATraining Step: 124  | total loss: [1m[32m0.09590[0m[0m | time: 52.838s
[2K
| Adam | epoch: 025 | loss: 0.09590 - acc: 0.9837 -- iter: 128/146
[A[ATraining Step: 125  | total loss: [1m[32m0.08752[0m[0m | time: 65.159s
[2K
| Adam | epoch: 025 | loss: 0.08752 - acc: 0.9853 | val_loss: 0.91327 - val_acc: 0.7174 -- iter: 146/146
--
Training Step: 126  | total loss: [1m[32m0.07982[0m[0m | time: 8.806s
[2K
| Adam | epoch: 026 | loss: 0.07982 - acc: 0.9868 -- iter: 032/146
[A[ATraining Step: 127  | total loss: [1m[32m0.07271[0m[0m | time: 21.732s
[2K
| Adam | epoch: 026 | loss: 0.07271 - acc: 0.9881 -- iter: 064/146
[A[ATraining Step: 128  | total loss: [1m[32m0.06655[0m[0m | time: 34.960s
[2K
| Adam | epoch: 026 | loss: 0.06655 - acc: 0.9893 -- iter: 096/146
[A[ATraining Step: 129  | total loss: [1m[32m0.06394[0m[0m | time: 48.405s
[2K
| Adam | epoch: 026 | loss: 0.06394 - acc: 0.9904 -- iter: 128/146
[A[ATraining Step: 130  | total loss: [1m[32m0.08051[0m[0m | time: 65.361s
[2K
| Adam | epoch: 026 | loss: 0.08051 - acc: 0.9882 | val_loss: 1.06605 - val_acc: 0.6739 -- iter: 146/146
--
Training Step: 131  | total loss: [1m[32m0.07333[0m[0m | time: 8.798s
[2K
| Adam | epoch: 027 | loss: 0.07333 - acc: 0.9894 -- iter: 032/146
[A[ATraining Step: 132  | total loss: [1m[32m0.06739[0m[0m | time: 17.115s
[2K
| Adam | epoch: 027 | loss: 0.06739 - acc: 0.9904 -- iter: 064/146
[A[ATraining Step: 133  | total loss: [1m[32m0.06214[0m[0m | time: 29.883s
[2K
| Adam | epoch: 027 | loss: 0.06214 - acc: 0.9914 -- iter: 096/146
[A[ATraining Step: 134  | total loss: [1m[32m0.05634[0m[0m | time: 48.563s
[2K
| Adam | epoch: 027 | loss: 0.05634 - acc: 0.9923 -- iter: 128/146
[A[ATraining Step: 135  | total loss: [1m[32m0.05571[0m[0m | time: 64.981s
[2K
| Adam | epoch: 027 | loss: 0.05571 - acc: 0.9930 | val_loss: 1.81288 - val_acc: 0.6087 -- iter: 146/146
--
Training Step: 136  | total loss: [1m[32m0.07226[0m[0m | time: 13.954s
[2K
| Adam | epoch: 028 | loss: 0.07226 - acc: 0.9844 -- iter: 032/146
[A[ATraining Step: 137  | total loss: [1m[32m0.06831[0m[0m | time: 22.307s
[2K
| Adam | epoch: 028 | loss: 0.06831 - acc: 0.9828 -- iter: 064/146
[A[ATraining Step: 138  | total loss: [1m[32m0.06233[0m[0m | time: 31.099s
[2K
| Adam | epoch: 028 | loss: 0.06233 - acc: 0.9845 -- iter: 096/146
[A[ATraining Step: 139  | total loss: [1m[32m0.05664[0m[0m | time: 44.233s
[2K
| Adam | epoch: 028 | loss: 0.05664 - acc: 0.9861 -- iter: 128/146
[A[ATraining Step: 140  | total loss: [1m[32m0.06979[0m[0m | time: 60.419s
[2K
| Adam | epoch: 028 | loss: 0.06979 - acc: 0.9843 | val_loss: 3.46047 - val_acc: 0.4348 -- iter: 146/146
--
Training Step: 141  | total loss: [1m[32m0.06597[0m[0m | time: 8.762s
[2K
| Adam | epoch: 029 | loss: 0.06597 - acc: 0.9859 -- iter: 032/146
[A[ATraining Step: 142  | total loss: [1m[32m0.15256[0m[0m | time: 17.296s
[2K
| Adam | epoch: 029 | loss: 0.15256 - acc: 0.9748 -- iter: 064/146
[A[ATraining Step: 143  | total loss: [1m[32m0.15123[0m[0m | time: 22.546s
[2K
| Adam | epoch: 029 | loss: 0.15123 - acc: 0.9742 -- iter: 096/146
[A[ATraining Step: 144  | total loss: [1m[32m0.14124[0m[0m | time: 29.107s
[2K
| Adam | epoch: 029 | loss: 0.14124 - acc: 0.9768 -- iter: 128/146
[A[ATraining Step: 145  | total loss: [1m[32m0.13152[0m[0m | time: 45.385s
[2K
| Adam | epoch: 029 | loss: 0.13152 - acc: 0.9791 | val_loss: 2.22614 - val_acc: 0.5217 -- iter: 146/146
--
Training Step: 146  | total loss: [1m[32m0.13187[0m[0m | time: 13.192s
[2K
| Adam | epoch: 030 | loss: 0.13187 - acc: 0.9781 -- iter: 032/146
[A[ATraining Step: 147  | total loss: [1m[32m0.12352[0m[0m | time: 26.004s
[2K
| Adam | epoch: 030 | loss: 0.12352 - acc: 0.9771 -- iter: 064/146
[A[ATraining Step: 148  | total loss: [1m[32m0.14859[0m[0m | time: 38.837s
[2K
| Adam | epoch: 030 | loss: 0.14859 - acc: 0.9700 -- iter: 096/146
[A[ATraining Step: 149  | total loss: [1m[32m0.13465[0m[0m | time: 46.544s
[2K
| Adam | epoch: 030 | loss: 0.13465 - acc: 0.9730 -- iter: 128/146
[A[ATraining Step: 150  | total loss: [1m[32m0.12652[0m[0m | time: 58.782s
[2K
| Adam | epoch: 030 | loss: 0.12652 - acc: 0.9757 | val_loss: 0.98954 - val_acc: 0.6739 -- iter: 146/146
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7719298245614035
Validation AUPRC:0.8288690987380039
Test AUC:0.8346153846153846
Test AUPRC:0.7671001805212333
BestTestF1Score	0.6	0.05	0.46	0.44	0.95	19	24	2	1	0.05
BestTestMCCScore	0.78	0.6	0.8	0.76	0.8	16	5	21	4	0.98
BestTestAccuracyScore	0.78	0.6	0.8	0.76	0.8	16	5	21	4	0.98
BestValidationF1Score	0.77	0.31	0.65	0.63	1.0	27	16	3	0	0.05
BestValidationMCC	0.75	0.5	0.74	0.86	0.67	18	3	16	9	0.98
BestValidationAccuracy	0.75	0.5	0.74	0.86	0.67	18	3	16	9	0.98
TestPredictions (Threshold:0.98)
CHEMBL2159960,TP,ACT,1.0	CHEMBL1438889,TP,ACT,0.9800000190734863	CHEMBL2316905,TP,ACT,1.0	CHEMBL1650888,TP,ACT,1.0	CHEMBL402803,TN,INACT,0.9700000286102295	CHEMBL2159935,FN,ACT,0.029999999329447746	CHEMBL2430648,FP,INACT,1.0	CHEMBL447335,TN,INACT,0.8899999856948853	CHEMBL590043,FP,INACT,1.0	CHEMBL2159937,FP,INACT,1.0	CHEMBL2159945,TN,INACT,0.3499999940395355	CHEMBL3360913,TN,INACT,0.2199999988079071	CHEMBL1650891,TP,ACT,1.0	CHEMBL301982,TN,INACT,0.4000000059604645	CHEMBL527109,TN,INACT,0.20999999344348907	CHEMBL322726,TN,INACT,0.4099999964237213	CHEMBL391533,TN,INACT,0.44999998807907104	CHEMBL1650892,TP,ACT,1.0	CHEMBL107729,TP,ACT,0.9800000190734863	CHEMBL1822606,TN,INACT,0.5699999928474426	CHEMBL228563,FP,INACT,0.9900000095367432	CHEMBL1417070,TN,INACT,0.9300000071525574	CHEMBL2159948,TN,INACT,0.4399999976158142	CHEMBL1795950,TN,INACT,0.28999999165534973	CHEMBL139202,TN,INACT,0.019999999552965164	CHEMBL1713374,FN,ACT,0.9700000286102295	CHEMBL3706920,TN,INACT,0.28999999165534973	CHEMBL1650907,TP,ACT,1.0	CHEMBL1650908,TP,ACT,1.0	CHEMBL502540,TN,INACT,0.3799999952316284	CHEMBL1721448,TN,INACT,0.029999999329447746	CHEMBL169,TN,INACT,0.8299999833106995	CHEMBL1650895,TP,ACT,1.0	CHEMBL2316895,FN,ACT,0.9700000286102295	CHEMBL274087,TN,INACT,0.25	CHEMBL6914,TN,INACT,0.4099999964237213	CHEMBL2396731,TP,ACT,0.9900000095367432	CHEMBL401743,TP,ACT,0.9900000095367432	CHEMBL499329,TN,INACT,0.4300000071525574	CHEMBL1706168,FP,INACT,1.0	CHEMBL1645419,FN,ACT,0.8799999952316284	CHEMBL137620,TN,INACT,0.9599999785423279	CHEMBL1650899,TP,ACT,1.0	CHEMBL2316907,TP,ACT,1.0	CHEMBL1650910,TP,ACT,1.0	CHEMBL1724482,TP,ACT,0.9800000190734863	

