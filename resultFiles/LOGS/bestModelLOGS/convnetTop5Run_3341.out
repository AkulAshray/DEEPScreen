CNNModel CHEMBL242 adam 0.0001 30 128 0 0.6 False True
Number of active compounds :	1083
Number of inactive compounds :	722
---------------------------------
Run id: CNNModel_CHEMBL242_adam_0.0001_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL242_adam_0.0001_30_128_0.6_True/
---------------------------------
Training samples: 1053
Validation samples: 330
--
Training Step: 1  | time: 1.976s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1053
[A[ATraining Step: 2  | total loss: [1m[32m0.62369[0m[0m | time: 3.195s
[2K
| Adam | epoch: 001 | loss: 0.62369 - acc: 0.5344 -- iter: 0064/1053
[A[ATraining Step: 3  | total loss: [1m[32m0.68071[0m[0m | time: 4.572s
[2K
| Adam | epoch: 001 | loss: 0.68071 - acc: 0.5063 -- iter: 0096/1053
[A[ATraining Step: 4  | total loss: [1m[32m0.69009[0m[0m | time: 5.886s
[2K
| Adam | epoch: 001 | loss: 0.69009 - acc: 0.5250 -- iter: 0128/1053
[A[ATraining Step: 5  | total loss: [1m[32m0.69222[0m[0m | time: 7.210s
[2K
| Adam | epoch: 001 | loss: 0.69222 - acc: 0.5077 -- iter: 0160/1053
[A[ATraining Step: 6  | total loss: [1m[32m0.69275[0m[0m | time: 8.801s
[2K
| Adam | epoch: 001 | loss: 0.69275 - acc: 0.5228 -- iter: 0192/1053
[A[ATraining Step: 7  | total loss: [1m[32m0.69242[0m[0m | time: 10.271s
[2K
| Adam | epoch: 001 | loss: 0.69242 - acc: 0.5654 -- iter: 0224/1053
[A[ATraining Step: 8  | total loss: [1m[32m0.69268[0m[0m | time: 11.601s
[2K
| Adam | epoch: 001 | loss: 0.69268 - acc: 0.5286 -- iter: 0256/1053
[A[ATraining Step: 9  | total loss: [1m[32m0.69210[0m[0m | time: 12.833s
[2K
| Adam | epoch: 001 | loss: 0.69210 - acc: 0.5631 -- iter: 0288/1053
[A[ATraining Step: 10  | total loss: [1m[32m0.69207[0m[0m | time: 14.285s
[2K
| Adam | epoch: 001 | loss: 0.69207 - acc: 0.5784 -- iter: 0320/1053
[A[ATraining Step: 11  | total loss: [1m[32m0.69262[0m[0m | time: 15.877s
[2K
| Adam | epoch: 001 | loss: 0.69262 - acc: 0.5265 -- iter: 0352/1053
[A[ATraining Step: 12  | total loss: [1m[32m0.69101[0m[0m | time: 17.545s
[2K
| Adam | epoch: 001 | loss: 0.69101 - acc: 0.5849 -- iter: 0384/1053
[A[ATraining Step: 13  | total loss: [1m[32m0.69227[0m[0m | time: 18.872s
[2K
| Adam | epoch: 001 | loss: 0.69227 - acc: 0.5351 -- iter: 0416/1053
[A[ATraining Step: 14  | total loss: [1m[32m0.69213[0m[0m | time: 20.139s
[2K
| Adam | epoch: 001 | loss: 0.69213 - acc: 0.5335 -- iter: 0448/1053
[A[ATraining Step: 15  | total loss: [1m[32m0.69228[0m[0m | time: 21.347s
[2K
| Adam | epoch: 001 | loss: 0.69228 - acc: 0.5326 -- iter: 0480/1053
[A[ATraining Step: 16  | total loss: [1m[32m0.68950[0m[0m | time: 22.581s
[2K
| Adam | epoch: 001 | loss: 0.68950 - acc: 0.5907 -- iter: 0512/1053
[A[ATraining Step: 17  | total loss: [1m[32m0.68932[0m[0m | time: 23.942s
[2K
| Adam | epoch: 001 | loss: 0.68932 - acc: 0.5806 -- iter: 0544/1053
[A[ATraining Step: 18  | total loss: [1m[32m0.68890[0m[0m | time: 25.481s
[2K
| Adam | epoch: 001 | loss: 0.68890 - acc: 0.5851 -- iter: 0576/1053
[A[ATraining Step: 19  | total loss: [1m[32m0.68717[0m[0m | time: 26.762s
[2K
| Adam | epoch: 001 | loss: 0.68717 - acc: 0.5984 -- iter: 0608/1053
[A[ATraining Step: 20  | total loss: [1m[32m0.69190[0m[0m | time: 28.303s
[2K
| Adam | epoch: 001 | loss: 0.69190 - acc: 0.5366 -- iter: 0640/1053
[A[ATraining Step: 21  | total loss: [1m[32m0.69036[0m[0m | time: 29.564s
[2K
| Adam | epoch: 001 | loss: 0.69036 - acc: 0.5447 -- iter: 0672/1053
[A[ATraining Step: 22  | total loss: [1m[32m0.68736[0m[0m | time: 30.982s
[2K
| Adam | epoch: 001 | loss: 0.68736 - acc: 0.5688 -- iter: 0704/1053
[A[ATraining Step: 23  | total loss: [1m[32m0.69292[0m[0m | time: 32.705s
[2K
| Adam | epoch: 001 | loss: 0.69292 - acc: 0.5216 -- iter: 0736/1053
[A[ATraining Step: 24  | total loss: [1m[32m0.69461[0m[0m | time: 34.444s
[2K
| Adam | epoch: 001 | loss: 0.69461 - acc: 0.5067 -- iter: 0768/1053
[A[ATraining Step: 25  | total loss: [1m[32m0.69378[0m[0m | time: 35.828s
[2K
| Adam | epoch: 001 | loss: 0.69378 - acc: 0.5134 -- iter: 0800/1053
[A[ATraining Step: 26  | total loss: [1m[32m0.69192[0m[0m | time: 37.121s
[2K
| Adam | epoch: 001 | loss: 0.69192 - acc: 0.5264 -- iter: 0832/1053
[A[ATraining Step: 27  | total loss: [1m[32m0.69101[0m[0m | time: 38.465s
[2K
| Adam | epoch: 001 | loss: 0.69101 - acc: 0.5357 -- iter: 0864/1053
[A[ATraining Step: 28  | total loss: [1m[32m0.68927[0m[0m | time: 39.793s
[2K
| Adam | epoch: 001 | loss: 0.68927 - acc: 0.5502 -- iter: 0896/1053
[A[ATraining Step: 29  | total loss: [1m[32m0.69040[0m[0m | time: 41.057s
[2K
| Adam | epoch: 001 | loss: 0.69040 - acc: 0.5456 -- iter: 0928/1053
[A[ATraining Step: 30  | total loss: [1m[32m0.68245[0m[0m | time: 42.507s
[2K
| Adam | epoch: 001 | loss: 0.68245 - acc: 0.5940 -- iter: 0960/1053
[A[ATraining Step: 31  | total loss: [1m[32m0.68942[0m[0m | time: 44.067s
[2K
| Adam | epoch: 001 | loss: 0.68942 - acc: 0.5507 -- iter: 0992/1053
[A[ATraining Step: 32  | total loss: [1m[32m0.68128[0m[0m | time: 45.303s
[2K
| Adam | epoch: 001 | loss: 0.68128 - acc: 0.5955 -- iter: 1024/1053
[A[ATraining Step: 33  | total loss: [1m[32m0.68330[0m[0m | time: 50.110s
[2K
| Adam | epoch: 001 | loss: 0.68330 - acc: 0.5814 | val_loss: 0.67604 - val_acc: 0.6091 -- iter: 1053/1053
--
Training Step: 34  | total loss: [1m[32m0.69253[0m[0m | time: 1.656s
[2K
| Adam | epoch: 002 | loss: 0.69253 - acc: 0.5307 -- iter: 0032/1053
[A[ATraining Step: 35  | total loss: [1m[32m0.70047[0m[0m | time: 2.688s
[2K
| Adam | epoch: 002 | loss: 0.70047 - acc: 0.4918 -- iter: 0064/1053
[A[ATraining Step: 36  | total loss: [1m[32m0.69683[0m[0m | time: 3.680s
[2K
| Adam | epoch: 002 | loss: 0.69683 - acc: 0.5063 -- iter: 0096/1053
[A[ATraining Step: 37  | total loss: [1m[32m0.69111[0m[0m | time: 4.914s
[2K
| Adam | epoch: 002 | loss: 0.69111 - acc: 0.5363 -- iter: 0128/1053
[A[ATraining Step: 38  | total loss: [1m[32m0.69508[0m[0m | time: 6.206s
[2K
| Adam | epoch: 002 | loss: 0.69508 - acc: 0.5108 -- iter: 0160/1053
[A[ATraining Step: 39  | total loss: [1m[32m0.69212[0m[0m | time: 7.480s
[2K
| Adam | epoch: 002 | loss: 0.69212 - acc: 0.5267 -- iter: 0192/1053
[A[ATraining Step: 40  | total loss: [1m[32m0.69099[0m[0m | time: 8.932s
[2K
| Adam | epoch: 002 | loss: 0.69099 - acc: 0.5334 -- iter: 0224/1053
[A[ATraining Step: 41  | total loss: [1m[32m0.69293[0m[0m | time: 10.297s
[2K
| Adam | epoch: 002 | loss: 0.69293 - acc: 0.5215 -- iter: 0256/1053
[A[ATraining Step: 42  | total loss: [1m[32m0.69171[0m[0m | time: 11.562s
[2K
| Adam | epoch: 002 | loss: 0.69171 - acc: 0.5289 -- iter: 0288/1053
[A[ATraining Step: 43  | total loss: [1m[32m0.69450[0m[0m | time: 12.913s
[2K
| Adam | epoch: 002 | loss: 0.69450 - acc: 0.5128 -- iter: 0320/1053
[A[ATraining Step: 44  | total loss: [1m[32m0.69240[0m[0m | time: 14.563s
[2K
| Adam | epoch: 002 | loss: 0.69240 - acc: 0.5268 -- iter: 0352/1053
[A[ATraining Step: 45  | total loss: [1m[32m0.69246[0m[0m | time: 16.303s
[2K
| Adam | epoch: 002 | loss: 0.69246 - acc: 0.5276 -- iter: 0384/1053
[A[ATraining Step: 46  | total loss: [1m[32m0.68892[0m[0m | time: 17.967s
[2K
| Adam | epoch: 002 | loss: 0.68892 - acc: 0.5490 -- iter: 0416/1053
[A[ATraining Step: 47  | total loss: [1m[32m0.68589[0m[0m | time: 19.123s
[2K
| Adam | epoch: 002 | loss: 0.68589 - acc: 0.5717 -- iter: 0448/1053
[A[ATraining Step: 48  | total loss: [1m[32m0.68423[0m[0m | time: 20.462s
[2K
| Adam | epoch: 002 | loss: 0.68423 - acc: 0.5802 -- iter: 0480/1053
[A[ATraining Step: 49  | total loss: [1m[32m0.68527[0m[0m | time: 21.905s
[2K
| Adam | epoch: 002 | loss: 0.68527 - acc: 0.5725 -- iter: 0512/1053
[A[ATraining Step: 50  | total loss: [1m[32m0.68651[0m[0m | time: 23.328s
[2K
| Adam | epoch: 002 | loss: 0.68651 - acc: 0.5661 -- iter: 0544/1053
[A[ATraining Step: 51  | total loss: [1m[32m0.68548[0m[0m | time: 24.824s
[2K
| Adam | epoch: 002 | loss: 0.68548 - acc: 0.5703 -- iter: 0576/1053
[A[ATraining Step: 52  | total loss: [1m[32m0.68537[0m[0m | time: 26.227s
[2K
| Adam | epoch: 002 | loss: 0.68537 - acc: 0.5691 -- iter: 0608/1053
[A[ATraining Step: 53  | total loss: [1m[32m0.68943[0m[0m | time: 27.662s
[2K
| Adam | epoch: 002 | loss: 0.68943 - acc: 0.5451 -- iter: 0640/1053
[A[ATraining Step: 54  | total loss: [1m[32m0.68595[0m[0m | time: 28.900s
[2K
| Adam | epoch: 002 | loss: 0.68595 - acc: 0.5612 -- iter: 0672/1053
[A[ATraining Step: 55  | total loss: [1m[32m0.68965[0m[0m | time: 30.508s
[2K
| Adam | epoch: 002 | loss: 0.68965 - acc: 0.5436 -- iter: 0704/1053
[A[ATraining Step: 56  | total loss: [1m[32m0.68909[0m[0m | time: 32.224s
[2K
| Adam | epoch: 002 | loss: 0.68909 - acc: 0.5462 -- iter: 0736/1053
[A[ATraining Step: 57  | total loss: [1m[32m0.68944[0m[0m | time: 33.871s
[2K
| Adam | epoch: 002 | loss: 0.68944 - acc: 0.5442 -- iter: 0768/1053
[A[ATraining Step: 58  | total loss: [1m[32m0.68515[0m[0m | time: 35.261s
[2K
| Adam | epoch: 002 | loss: 0.68515 - acc: 0.5637 -- iter: 0800/1053
[A[ATraining Step: 59  | total loss: [1m[32m0.68261[0m[0m | time: 36.422s
[2K
| Adam | epoch: 002 | loss: 0.68261 - acc: 0.5761 -- iter: 0832/1053
[A[ATraining Step: 60  | total loss: [1m[32m0.68567[0m[0m | time: 37.648s
[2K
| Adam | epoch: 002 | loss: 0.68567 - acc: 0.5619 -- iter: 0864/1053
[A[ATraining Step: 61  | total loss: [1m[32m0.69187[0m[0m | time: 38.925s
[2K
| Adam | epoch: 002 | loss: 0.69187 - acc: 0.5335 -- iter: 0896/1053
[A[ATraining Step: 62  | total loss: [1m[32m0.69367[0m[0m | time: 40.130s
[2K
| Adam | epoch: 002 | loss: 0.69367 - acc: 0.5251 -- iter: 0928/1053
[A[ATraining Step: 63  | total loss: [1m[32m0.69742[0m[0m | time: 41.408s
[2K
| Adam | epoch: 002 | loss: 0.69742 - acc: 0.5061 -- iter: 0960/1053
[A[ATraining Step: 64  | total loss: [1m[32m0.69805[0m[0m | time: 42.809s
[2K
| Adam | epoch: 002 | loss: 0.69805 - acc: 0.5014 -- iter: 0992/1053
[A[ATraining Step: 65  | total loss: [1m[32m0.69910[0m[0m | time: 44.219s
[2K
| Adam | epoch: 002 | loss: 0.69910 - acc: 0.4936 -- iter: 1024/1053
[A[ATraining Step: 66  | total loss: [1m[32m0.69838[0m[0m | time: 47.562s
[2K
| Adam | epoch: 002 | loss: 0.69838 - acc: 0.4981 | val_loss: 0.68032 - val_acc: 0.6091 -- iter: 1053/1053
--
Training Step: 67  | total loss: [1m[32m0.69486[0m[0m | time: 1.539s
[2K
| Adam | epoch: 003 | loss: 0.69486 - acc: 0.5209 -- iter: 0032/1053
[A[ATraining Step: 68  | total loss: [1m[32m0.69128[0m[0m | time: 2.992s
[2K
| Adam | epoch: 003 | loss: 0.69128 - acc: 0.5449 -- iter: 0064/1053
[A[ATraining Step: 69  | total loss: [1m[32m0.68814[0m[0m | time: 4.225s
[2K
| Adam | epoch: 003 | loss: 0.68814 - acc: 0.5659 -- iter: 0096/1053
[A[ATraining Step: 70  | total loss: [1m[32m0.68908[0m[0m | time: 5.478s
[2K
| Adam | epoch: 003 | loss: 0.68908 - acc: 0.5583 -- iter: 0128/1053
[A[ATraining Step: 71  | total loss: [1m[32m0.69069[0m[0m | time: 6.712s
[2K
| Adam | epoch: 003 | loss: 0.69069 - acc: 0.5445 -- iter: 0160/1053
[A[ATraining Step: 72  | total loss: [1m[32m0.68986[0m[0m | time: 7.970s
[2K
| Adam | epoch: 003 | loss: 0.68986 - acc: 0.5501 -- iter: 0192/1053
[A[ATraining Step: 73  | total loss: [1m[32m0.69017[0m[0m | time: 9.223s
[2K
| Adam | epoch: 003 | loss: 0.69017 - acc: 0.5480 -- iter: 0224/1053
[A[ATraining Step: 74  | total loss: [1m[32m0.69106[0m[0m | time: 10.521s
[2K
| Adam | epoch: 003 | loss: 0.69106 - acc: 0.5393 -- iter: 0256/1053
[A[ATraining Step: 75  | total loss: [1m[32m0.69198[0m[0m | time: 11.988s
[2K
| Adam | epoch: 003 | loss: 0.69198 - acc: 0.5316 -- iter: 0288/1053
[A[ATraining Step: 76  | total loss: [1m[32m0.68999[0m[0m | time: 13.237s
[2K
| Adam | epoch: 003 | loss: 0.68999 - acc: 0.5450 -- iter: 0320/1053
[A[ATraining Step: 77  | total loss: [1m[32m0.69016[0m[0m | time: 14.433s
[2K
| Adam | epoch: 003 | loss: 0.69016 - acc: 0.5435 -- iter: 0352/1053
[A[ATraining Step: 78  | total loss: [1m[32m0.68890[0m[0m | time: 15.894s
[2K
| Adam | epoch: 003 | loss: 0.68890 - acc: 0.5521 -- iter: 0384/1053
[A[ATraining Step: 79  | total loss: [1m[32m0.68833[0m[0m | time: 17.681s
[2K
| Adam | epoch: 003 | loss: 0.68833 - acc: 0.5564 -- iter: 0416/1053
[A[ATraining Step: 80  | total loss: [1m[32m0.68868[0m[0m | time: 19.399s
[2K
| Adam | epoch: 003 | loss: 0.68868 - acc: 0.5538 -- iter: 0448/1053
[A[ATraining Step: 81  | total loss: [1m[32m0.68741[0m[0m | time: 20.794s
[2K
| Adam | epoch: 003 | loss: 0.68741 - acc: 0.5610 -- iter: 0480/1053
[A[ATraining Step: 82  | total loss: [1m[32m0.68866[0m[0m | time: 22.008s
[2K
| Adam | epoch: 003 | loss: 0.68866 - acc: 0.5518 -- iter: 0512/1053
[A[ATraining Step: 83  | total loss: [1m[32m0.68883[0m[0m | time: 23.373s
[2K
| Adam | epoch: 003 | loss: 0.68883 - acc: 0.5497 -- iter: 0544/1053
[A[ATraining Step: 84  | total loss: [1m[32m0.69046[0m[0m | time: 24.877s
[2K
| Adam | epoch: 003 | loss: 0.69046 - acc: 0.5385 -- iter: 0576/1053
[A[ATraining Step: 85  | total loss: [1m[32m0.68872[0m[0m | time: 26.389s
[2K
| Adam | epoch: 003 | loss: 0.68872 - acc: 0.5503 -- iter: 0608/1053
[A[ATraining Step: 86  | total loss: [1m[32m0.68737[0m[0m | time: 27.962s
[2K
| Adam | epoch: 003 | loss: 0.68737 - acc: 0.5577 -- iter: 0640/1053
[A[ATraining Step: 87  | total loss: [1m[32m0.68679[0m[0m | time: 29.429s
[2K
| Adam | epoch: 003 | loss: 0.68679 - acc: 0.5613 -- iter: 0672/1053
[A[ATraining Step: 88  | total loss: [1m[32m0.68731[0m[0m | time: 30.772s
[2K
| Adam | epoch: 003 | loss: 0.68731 - acc: 0.5583 -- iter: 0704/1053
[A[ATraining Step: 89  | total loss: [1m[32m0.68661[0m[0m | time: 32.284s
[2K
| Adam | epoch: 003 | loss: 0.68661 - acc: 0.5619 -- iter: 0736/1053
[A[ATraining Step: 90  | total loss: [1m[32m0.68965[0m[0m | time: 33.920s
[2K
| Adam | epoch: 003 | loss: 0.68965 - acc: 0.5432 -- iter: 0768/1053
[A[ATraining Step: 91  | total loss: [1m[32m0.68953[0m[0m | time: 35.643s
[2K
| Adam | epoch: 003 | loss: 0.68953 - acc: 0.5420 -- iter: 0800/1053
[A[ATraining Step: 92  | total loss: [1m[32m0.68686[0m[0m | time: 37.338s
[2K
| Adam | epoch: 003 | loss: 0.68686 - acc: 0.5565 -- iter: 0832/1053
[A[ATraining Step: 93  | total loss: [1m[32m0.68703[0m[0m | time: 38.593s
[2K
| Adam | epoch: 003 | loss: 0.68703 - acc: 0.5540 -- iter: 0864/1053
[A[ATraining Step: 94  | total loss: [1m[32m0.68888[0m[0m | time: 40.164s
[2K
| Adam | epoch: 003 | loss: 0.68888 - acc: 0.5455 -- iter: 0896/1053
[A[ATraining Step: 95  | total loss: [1m[32m0.69035[0m[0m | time: 41.419s
[2K
| Adam | epoch: 003 | loss: 0.69035 - acc: 0.5378 -- iter: 0928/1053
[A[ATraining Step: 96  | total loss: [1m[32m0.68850[0m[0m | time: 42.917s
[2K
| Adam | epoch: 003 | loss: 0.68850 - acc: 0.5465 -- iter: 0960/1053
[A[ATraining Step: 97  | total loss: [1m[32m0.68932[0m[0m | time: 44.085s
[2K
| Adam | epoch: 003 | loss: 0.68932 - acc: 0.5419 -- iter: 0992/1053
[A[ATraining Step: 98  | total loss: [1m[32m0.68874[0m[0m | time: 45.556s
[2K
| Adam | epoch: 003 | loss: 0.68874 - acc: 0.5439 -- iter: 1024/1053
[A[ATraining Step: 99  | total loss: [1m[32m0.68915[0m[0m | time: 49.040s
[2K
| Adam | epoch: 003 | loss: 0.68915 - acc: 0.5427 | val_loss: 0.67632 - val_acc: 0.6091 -- iter: 1053/1053
--
Training Step: 100  | total loss: [1m[32m0.68999[0m[0m | time: 1.878s
[2K
| Adam | epoch: 004 | loss: 0.68999 - acc: 0.5384 -- iter: 0032/1053
[A[ATraining Step: 101  | total loss: [1m[32m0.68952[0m[0m | time: 3.434s
[2K
| Adam | epoch: 004 | loss: 0.68952 - acc: 0.5408 -- iter: 0064/1053
[A[ATraining Step: 102  | total loss: [1m[32m0.68744[0m[0m | time: 4.692s
[2K
| Adam | epoch: 004 | loss: 0.68744 - acc: 0.5523 -- iter: 0096/1053
[A[ATraining Step: 103  | total loss: [1m[32m0.68542[0m[0m | time: 5.955s
[2K
| Adam | epoch: 004 | loss: 0.68542 - acc: 0.5625 -- iter: 0128/1053
[A[ATraining Step: 104  | total loss: [1m[32m0.68565[0m[0m | time: 7.225s
[2K
| Adam | epoch: 004 | loss: 0.68565 - acc: 0.5625 -- iter: 0160/1053
[A[ATraining Step: 105  | total loss: [1m[32m0.68479[0m[0m | time: 8.525s
[2K
| Adam | epoch: 004 | loss: 0.68479 - acc: 0.5657 -- iter: 0192/1053
[A[ATraining Step: 106  | total loss: [1m[32m0.68261[0m[0m | time: 9.754s
[2K
| Adam | epoch: 004 | loss: 0.68261 - acc: 0.5747 -- iter: 0224/1053
[A[ATraining Step: 107  | total loss: [1m[32m0.68341[0m[0m | time: 11.268s
[2K
| Adam | epoch: 004 | loss: 0.68341 - acc: 0.5704 -- iter: 0256/1053
[A[ATraining Step: 108  | total loss: [1m[32m0.68567[0m[0m | time: 12.699s
[2K
| Adam | epoch: 004 | loss: 0.68567 - acc: 0.5602 -- iter: 0288/1053
[A[ATraining Step: 109  | total loss: [1m[32m0.68544[0m[0m | time: 14.124s
[2K
| Adam | epoch: 004 | loss: 0.68544 - acc: 0.5604 -- iter: 0320/1053
[A[ATraining Step: 110  | total loss: [1m[32m0.68844[0m[0m | time: 15.367s
[2K
| Adam | epoch: 004 | loss: 0.68844 - acc: 0.5481 -- iter: 0352/1053
[A[ATraining Step: 111  | total loss: [1m[32m0.69211[0m[0m | time: 16.931s
[2K
| Adam | epoch: 004 | loss: 0.69211 - acc: 0.5340 -- iter: 0384/1053
[A[ATraining Step: 112  | total loss: [1m[32m0.69297[0m[0m | time: 18.662s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5306 -- iter: 0416/1053
[A[ATraining Step: 113  | total loss: [1m[32m0.69392[0m[0m | time: 20.353s
[2K
| Adam | epoch: 004 | loss: 0.69392 - acc: 0.5244 -- iter: 0448/1053
[A[ATraining Step: 114  | total loss: [1m[32m0.69140[0m[0m | time: 21.625s
[2K
| Adam | epoch: 004 | loss: 0.69140 - acc: 0.5344 -- iter: 0480/1053
[A[ATraining Step: 115  | total loss: [1m[32m0.68829[0m[0m | time: 22.787s
[2K
| Adam | epoch: 004 | loss: 0.68829 - acc: 0.5497 -- iter: 0512/1053
[A[ATraining Step: 116  | total loss: [1m[32m0.68815[0m[0m | time: 23.981s
[2K
| Adam | epoch: 004 | loss: 0.68815 - acc: 0.5510 -- iter: 0544/1053
[A[ATraining Step: 117  | total loss: [1m[32m0.68618[0m[0m | time: 25.367s
[2K
| Adam | epoch: 004 | loss: 0.68618 - acc: 0.5615 -- iter: 0576/1053
[A[ATraining Step: 118  | total loss: [1m[32m0.68474[0m[0m | time: 26.744s
[2K
| Adam | epoch: 004 | loss: 0.68474 - acc: 0.5679 -- iter: 0608/1053
[A[ATraining Step: 119  | total loss: [1m[32m0.68512[0m[0m | time: 28.104s
[2K
| Adam | epoch: 004 | loss: 0.68512 - acc: 0.5642 -- iter: 0640/1053
[A[ATraining Step: 120  | total loss: [1m[32m0.68257[0m[0m | time: 29.519s
[2K
| Adam | epoch: 004 | loss: 0.68257 - acc: 0.5766 -- iter: 0672/1053
[A[ATraining Step: 121  | total loss: [1m[32m0.68047[0m[0m | time: 30.886s
[2K
| Adam | epoch: 004 | loss: 0.68047 - acc: 0.5845 -- iter: 0704/1053
[A[ATraining Step: 122  | total loss: [1m[32m0.68544[0m[0m | time: 32.136s
[2K
| Adam | epoch: 004 | loss: 0.68544 - acc: 0.5636 -- iter: 0736/1053
[A[ATraining Step: 123  | total loss: [1m[32m0.68674[0m[0m | time: 33.541s
[2K
| Adam | epoch: 004 | loss: 0.68674 - acc: 0.5572 -- iter: 0768/1053
[A[ATraining Step: 124  | total loss: [1m[32m0.68724[0m[0m | time: 35.135s
[2K
| Adam | epoch: 004 | loss: 0.68724 - acc: 0.5546 -- iter: 0800/1053
[A[ATraining Step: 125  | total loss: [1m[32m0.69036[0m[0m | time: 36.699s
[2K
| Adam | epoch: 004 | loss: 0.69036 - acc: 0.5398 -- iter: 0832/1053
[A[ATraining Step: 126  | total loss: [1m[32m0.68762[0m[0m | time: 38.334s
[2K
| Adam | epoch: 004 | loss: 0.68762 - acc: 0.5514 -- iter: 0864/1053
[A[ATraining Step: 127  | total loss: [1m[32m0.69354[0m[0m | time: 39.548s
[2K
| Adam | epoch: 004 | loss: 0.69354 - acc: 0.5244 -- iter: 0896/1053
[A[ATraining Step: 128  | total loss: [1m[32m0.69450[0m[0m | time: 40.750s
[2K
| Adam | epoch: 004 | loss: 0.69450 - acc: 0.5188 -- iter: 0928/1053
[A[ATraining Step: 129  | total loss: [1m[32m0.69224[0m[0m | time: 41.963s
[2K
| Adam | epoch: 004 | loss: 0.69224 - acc: 0.5295 -- iter: 0960/1053
[A[ATraining Step: 130  | total loss: [1m[32m0.69332[0m[0m | time: 43.227s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.5234 -- iter: 0992/1053
[A[ATraining Step: 131  | total loss: [1m[32m0.69151[0m[0m | time: 44.547s
[2K
| Adam | epoch: 004 | loss: 0.69151 - acc: 0.5335 -- iter: 1024/1053
[A[ATraining Step: 132  | total loss: [1m[32m0.69095[0m[0m | time: 48.806s
[2K
| Adam | epoch: 004 | loss: 0.69095 - acc: 0.5364 | val_loss: 0.67824 - val_acc: 0.6091 -- iter: 1053/1053
--
Training Step: 133  | total loss: [1m[32m0.68992[0m[0m | time: 1.375s
[2K
| Adam | epoch: 005 | loss: 0.68992 - acc: 0.5422 -- iter: 0032/1053
[A[ATraining Step: 134  | total loss: [1m[32m0.69116[0m[0m | time: 2.975s
[2K
| Adam | epoch: 005 | loss: 0.69116 - acc: 0.5348 -- iter: 0064/1053
[A[ATraining Step: 135  | total loss: [1m[32m0.69103[0m[0m | time: 4.057s
[2K
| Adam | epoch: 005 | loss: 0.69103 - acc: 0.5345 -- iter: 0096/1053
[A[ATraining Step: 136  | total loss: [1m[32m0.68889[0m[0m | time: 5.238s
[2K
| Adam | epoch: 005 | loss: 0.68889 - acc: 0.5500 -- iter: 0128/1053
[A[ATraining Step: 137  | total loss: [1m[32m0.68658[0m[0m | time: 6.475s
[2K
| Adam | epoch: 005 | loss: 0.68658 - acc: 0.5640 -- iter: 0160/1053
[A[ATraining Step: 138  | total loss: [1m[32m0.68642[0m[0m | time: 7.765s
[2K
| Adam | epoch: 005 | loss: 0.68642 - acc: 0.5638 -- iter: 0192/1053
[A[ATraining Step: 139  | total loss: [1m[32m0.68481[0m[0m | time: 9.027s
[2K
| Adam | epoch: 005 | loss: 0.68481 - acc: 0.5731 -- iter: 0224/1053
[A[ATraining Step: 140  | total loss: [1m[32m0.68241[0m[0m | time: 10.328s
[2K
| Adam | epoch: 005 | loss: 0.68241 - acc: 0.5876 -- iter: 0256/1053
[A[ATraining Step: 141  | total loss: [1m[32m0.68435[0m[0m | time: 11.667s
[2K
| Adam | epoch: 005 | loss: 0.68435 - acc: 0.5757 -- iter: 0288/1053
[A[ATraining Step: 142  | total loss: [1m[32m0.68322[0m[0m | time: 13.106s
[2K
| Adam | epoch: 005 | loss: 0.68322 - acc: 0.5807 -- iter: 0320/1053
[A[ATraining Step: 143  | total loss: [1m[32m0.68408[0m[0m | time: 14.218s
[2K
| Adam | epoch: 005 | loss: 0.68408 - acc: 0.5757 -- iter: 0352/1053
[A[ATraining Step: 144  | total loss: [1m[32m0.68399[0m[0m | time: 15.673s
[2K
| Adam | epoch: 005 | loss: 0.68399 - acc: 0.5744 -- iter: 0384/1053
[A[ATraining Step: 145  | total loss: [1m[32m0.68455[0m[0m | time: 17.227s
[2K
| Adam | epoch: 005 | loss: 0.68455 - acc: 0.5732 -- iter: 0416/1053
[A[ATraining Step: 146  | total loss: [1m[32m0.68359[0m[0m | time: 18.950s
[2K
| Adam | epoch: 005 | loss: 0.68359 - acc: 0.5753 -- iter: 0448/1053
[A[ATraining Step: 147  | total loss: [1m[32m0.68386[0m[0m | time: 20.554s
[2K
| Adam | epoch: 005 | loss: 0.68386 - acc: 0.5740 -- iter: 0480/1053
[A[ATraining Step: 148  | total loss: [1m[32m0.68555[0m[0m | time: 21.699s
[2K
| Adam | epoch: 005 | loss: 0.68555 - acc: 0.5666 -- iter: 0512/1053
[A[ATraining Step: 149  | total loss: [1m[32m0.68394[0m[0m | time: 22.861s
[2K
| Adam | epoch: 005 | loss: 0.68394 - acc: 0.5724 -- iter: 0544/1053
[A[ATraining Step: 150  | total loss: [1m[32m0.68318[0m[0m | time: 24.174s
[2K
| Adam | epoch: 005 | loss: 0.68318 - acc: 0.5746 -- iter: 0576/1053
[A[ATraining Step: 151  | total loss: [1m[32m0.68180[0m[0m | time: 25.519s
[2K
| Adam | epoch: 005 | loss: 0.68180 - acc: 0.5796 -- iter: 0608/1053
[A[ATraining Step: 152  | total loss: [1m[32m0.68544[0m[0m | time: 26.975s
[2K
| Adam | epoch: 005 | loss: 0.68544 - acc: 0.5654 -- iter: 0640/1053
[A[ATraining Step: 153  | total loss: [1m[32m0.68931[0m[0m | time: 28.248s
[2K
| Adam | epoch: 005 | loss: 0.68931 - acc: 0.5526 -- iter: 0672/1053
[A[ATraining Step: 154  | total loss: [1m[32m0.69343[0m[0m | time: 29.699s
[2K
| Adam | epoch: 005 | loss: 0.69343 - acc: 0.5380 -- iter: 0704/1053
[A[ATraining Step: 155  | total loss: [1m[32m0.69325[0m[0m | time: 31.078s
[2K
| Adam | epoch: 005 | loss: 0.69325 - acc: 0.5373 -- iter: 0736/1053
[A[ATraining Step: 156  | total loss: [1m[32m0.69704[0m[0m | time: 32.387s
[2K
| Adam | epoch: 005 | loss: 0.69704 - acc: 0.5211 -- iter: 0768/1053
[A[ATraining Step: 157  | total loss: [1m[32m0.69726[0m[0m | time: 34.021s
[2K
| Adam | epoch: 005 | loss: 0.69726 - acc: 0.5190 -- iter: 0800/1053
[A[ATraining Step: 158  | total loss: [1m[32m0.69856[0m[0m | time: 35.637s
[2K
| Adam | epoch: 005 | loss: 0.69856 - acc: 0.5108 -- iter: 0832/1053
[A[ATraining Step: 159  | total loss: [1m[32m0.69853[0m[0m | time: 37.220s
[2K
| Adam | epoch: 005 | loss: 0.69853 - acc: 0.5097 -- iter: 0864/1053
[A[ATraining Step: 160  | total loss: [1m[32m0.69565[0m[0m | time: 38.527s
[2K
| Adam | epoch: 005 | loss: 0.69565 - acc: 0.5244 -- iter: 0896/1053
[A[ATraining Step: 161  | total loss: [1m[32m0.69415[0m[0m | time: 39.872s
[2K
| Adam | epoch: 005 | loss: 0.69415 - acc: 0.5313 -- iter: 0928/1053
[A[ATraining Step: 162  | total loss: [1m[32m0.69214[0m[0m | time: 41.138s
[2K
| Adam | epoch: 005 | loss: 0.69214 - acc: 0.5438 -- iter: 0960/1053
[A[ATraining Step: 163  | total loss: [1m[32m0.69367[0m[0m | time: 42.570s
[2K
| Adam | epoch: 005 | loss: 0.69367 - acc: 0.5301 -- iter: 0992/1053
[A[ATraining Step: 164  | total loss: [1m[32m0.69257[0m[0m | time: 43.921s
[2K
| Adam | epoch: 005 | loss: 0.69257 - acc: 0.5364 -- iter: 1024/1053
[A[ATraining Step: 165  | total loss: [1m[32m0.69061[0m[0m | time: 47.978s
[2K
| Adam | epoch: 005 | loss: 0.69061 - acc: 0.5515 | val_loss: 0.68142 - val_acc: 0.6091 -- iter: 1053/1053
--
Training Step: 166  | total loss: [1m[32m0.68941[0m[0m | time: 1.536s
[2K
| Adam | epoch: 006 | loss: 0.68941 - acc: 0.5589 -- iter: 0032/1053
[A[ATraining Step: 167  | total loss: [1m[32m0.68829[0m[0m | time: 3.142s
[2K
| Adam | epoch: 006 | loss: 0.68829 - acc: 0.5655 -- iter: 0064/1053
[A[ATraining Step: 168  | total loss: [1m[32m0.69056[0m[0m | time: 4.842s
[2K
| Adam | epoch: 006 | loss: 0.69056 - acc: 0.5464 -- iter: 0096/1053
[A[ATraining Step: 169  | total loss: [1m[32m0.69023[0m[0m | time: 6.268s
[2K
| Adam | epoch: 006 | loss: 0.69023 - acc: 0.5480 -- iter: 0128/1053
[A[ATraining Step: 170  | total loss: [1m[32m0.69035[0m[0m | time: 7.162s
[2K
| Adam | epoch: 006 | loss: 0.69035 - acc: 0.5450 -- iter: 0160/1053
[A[ATraining Step: 171  | total loss: [1m[32m0.69036[0m[0m | time: 8.356s
[2K
| Adam | epoch: 006 | loss: 0.69036 - acc: 0.5422 -- iter: 0192/1053
[A[ATraining Step: 172  | total loss: [1m[32m0.68964[0m[0m | time: 9.620s
[2K
| Adam | epoch: 006 | loss: 0.68964 - acc: 0.5474 -- iter: 0224/1053
[A[ATraining Step: 173  | total loss: [1m[32m0.68948[0m[0m | time: 10.948s
[2K
| Adam | epoch: 006 | loss: 0.68948 - acc: 0.5489 -- iter: 0256/1053
[A[ATraining Step: 174  | total loss: [1m[32m0.68899[0m[0m | time: 12.345s
[2K
| Adam | epoch: 006 | loss: 0.68899 - acc: 0.5534 -- iter: 0288/1053
[A[ATraining Step: 175  | total loss: [1m[32m0.69009[0m[0m | time: 13.749s
[2K
| Adam | epoch: 006 | loss: 0.69009 - acc: 0.5449 -- iter: 0320/1053
[A[ATraining Step: 176  | total loss: [1m[32m0.68886[0m[0m | time: 15.121s
[2K
| Adam | epoch: 006 | loss: 0.68886 - acc: 0.5529 -- iter: 0352/1053
[A[ATraining Step: 177  | total loss: [1m[32m0.68958[0m[0m | time: 16.589s
[2K
| Adam | epoch: 006 | loss: 0.68958 - acc: 0.5476 -- iter: 0384/1053
[A[ATraining Step: 178  | total loss: [1m[32m0.68850[0m[0m | time: 18.192s
[2K
| Adam | epoch: 006 | loss: 0.68850 - acc: 0.5554 -- iter: 0416/1053
[A[ATraining Step: 179  | total loss: [1m[32m0.68849[0m[0m | time: 19.781s
[2K
| Adam | epoch: 006 | loss: 0.68849 - acc: 0.5561 -- iter: 0448/1053
[A[ATraining Step: 180  | total loss: [1m[32m0.68875[0m[0m | time: 21.646s
[2K
| Adam | epoch: 006 | loss: 0.68875 - acc: 0.5536 -- iter: 0480/1053
[A[ATraining Step: 181  | total loss: [1m[32m0.68907[0m[0m | time: 23.314s
[2K
| Adam | epoch: 006 | loss: 0.68907 - acc: 0.5514 -- iter: 0512/1053
[A[ATraining Step: 182  | total loss: [1m[32m0.68880[0m[0m | time: 24.306s
[2K
| Adam | epoch: 006 | loss: 0.68880 - acc: 0.5525 -- iter: 0544/1053
[A[ATraining Step: 183  | total loss: [1m[32m0.68753[0m[0m | time: 25.542s
[2K
| Adam | epoch: 006 | loss: 0.68753 - acc: 0.5597 -- iter: 0576/1053
[A[ATraining Step: 184  | total loss: [1m[32m0.68723[0m[0m | time: 26.847s
[2K
| Adam | epoch: 006 | loss: 0.68723 - acc: 0.5600 -- iter: 0608/1053
[A[ATraining Step: 185  | total loss: [1m[32m0.68704[0m[0m | time: 28.151s
[2K
| Adam | epoch: 006 | loss: 0.68704 - acc: 0.5602 -- iter: 0640/1053
[A[ATraining Step: 186  | total loss: [1m[32m0.68774[0m[0m | time: 29.470s
[2K
| Adam | epoch: 006 | loss: 0.68774 - acc: 0.5542 -- iter: 0672/1053
[A[ATraining Step: 187  | total loss: [1m[32m0.68803[0m[0m | time: 31.005s
[2K
| Adam | epoch: 006 | loss: 0.68803 - acc: 0.5519 -- iter: 0704/1053
[A[ATraining Step: 188  | total loss: [1m[32m0.68819[0m[0m | time: 32.345s
[2K
| Adam | epoch: 006 | loss: 0.68819 - acc: 0.5499 -- iter: 0736/1053
[A[ATraining Step: 189  | total loss: [1m[32m0.68731[0m[0m | time: 33.572s
[2K
| Adam | epoch: 006 | loss: 0.68731 - acc: 0.5542 -- iter: 0768/1053
[A[ATraining Step: 190  | total loss: [1m[32m0.68965[0m[0m | time: 35.015s
[2K
| Adam | epoch: 006 | loss: 0.68965 - acc: 0.5394 -- iter: 0800/1053
[A[ATraining Step: 191  | total loss: [1m[32m0.69152[0m[0m | time: 36.551s
[2K
| Adam | epoch: 006 | loss: 0.69152 - acc: 0.5293 -- iter: 0832/1053
[A[ATraining Step: 192  | total loss: [1m[32m0.69202[0m[0m | time: 38.128s
[2K
| Adam | epoch: 006 | loss: 0.69202 - acc: 0.5263 -- iter: 0864/1053
[A[ATraining Step: 193  | total loss: [1m[32m0.69223[0m[0m | time: 39.574s
[2K
| Adam | epoch: 006 | loss: 0.69223 - acc: 0.5237 -- iter: 0896/1053
[A[ATraining Step: 194  | total loss: [1m[32m0.69268[0m[0m | time: 40.836s
[2K
| Adam | epoch: 006 | loss: 0.69268 - acc: 0.5213 -- iter: 0928/1053
[A[ATraining Step: 195  | total loss: [1m[32m0.69278[0m[0m | time: 42.445s
[2K
| Adam | epoch: 006 | loss: 0.69278 - acc: 0.5192 -- iter: 0960/1053
[A[ATraining Step: 196  | total loss: [1m[32m0.69099[0m[0m | time: 43.935s
[2K
| Adam | epoch: 006 | loss: 0.69099 - acc: 0.5298 -- iter: 0992/1053
[A[ATraining Step: 197  | total loss: [1m[32m0.69147[0m[0m | time: 45.023s
[2K
| Adam | epoch: 006 | loss: 0.69147 - acc: 0.5268 -- iter: 1024/1053
[A[ATraining Step: 198  | total loss: [1m[32m0.69142[0m[0m | time: 48.740s
[2K
| Adam | epoch: 006 | loss: 0.69142 - acc: 0.5272 | val_loss: 0.67911 - val_acc: 0.6091 -- iter: 1053/1053
--
Training Step: 199  | total loss: [1m[32m0.69171[0m[0m | time: 1.313s
[2K
| Adam | epoch: 007 | loss: 0.69171 - acc: 0.5245 -- iter: 0032/1053
[A[ATraining Step: 200  | total loss: [1m[32m0.69020[0m[0m | time: 5.642s
[2K
| Adam | epoch: 007 | loss: 0.69020 - acc: 0.5346 | val_loss: 0.67893 - val_acc: 0.6091 -- iter: 0064/1053
--
Training Step: 201  | total loss: [1m[32m0.68853[0m[0m | time: 7.124s
[2K
| Adam | epoch: 007 | loss: 0.68853 - acc: 0.5467 -- iter: 0096/1053
[A[ATraining Step: 202  | total loss: [1m[32m0.68822[0m[0m | time: 8.311s
[2K
| Adam | epoch: 007 | loss: 0.68822 - acc: 0.5483 -- iter: 0128/1053
[A[ATraining Step: 203  | total loss: [1m[32m0.68862[0m[0m | time: 9.481s
[2K
| Adam | epoch: 007 | loss: 0.68862 - acc: 0.5435 -- iter: 0160/1053
[A[ATraining Step: 204  | total loss: [1m[32m0.68783[0m[0m | time: 10.653s
[2K
| Adam | epoch: 007 | loss: 0.68783 - acc: 0.5478 -- iter: 0192/1053
[A[ATraining Step: 205  | total loss: [1m[32m0.68709[0m[0m | time: 12.108s
[2K
| Adam | epoch: 007 | loss: 0.68709 - acc: 0.5516 -- iter: 0224/1053
[A[ATraining Step: 206  | total loss: [1m[32m0.68805[0m[0m | time: 13.290s
[2K
| Adam | epoch: 007 | loss: 0.68805 - acc: 0.5464 -- iter: 0256/1053
[A[ATraining Step: 207  | total loss: [1m[32m0.68570[0m[0m | time: 14.647s
[2K
| Adam | epoch: 007 | loss: 0.68570 - acc: 0.5605 -- iter: 0288/1053
[A[ATraining Step: 208  | total loss: [1m[32m0.68709[0m[0m | time: 16.137s
[2K
| Adam | epoch: 007 | loss: 0.68709 - acc: 0.5514 -- iter: 0320/1053
[A[ATraining Step: 209  | total loss: [1m[32m0.68635[0m[0m | time: 17.344s
[2K
| Adam | epoch: 007 | loss: 0.68635 - acc: 0.5556 -- iter: 0352/1053
[A[ATraining Step: 210  | total loss: [1m[32m0.68441[0m[0m | time: 18.736s
[2K
| Adam | epoch: 007 | loss: 0.68441 - acc: 0.5657 -- iter: 0384/1053
[A[ATraining Step: 211  | total loss: [1m[32m0.68313[0m[0m | time: 20.391s
[2K
| Adam | epoch: 007 | loss: 0.68313 - acc: 0.5716 -- iter: 0416/1053
[A[ATraining Step: 212  | total loss: [1m[32m0.68586[0m[0m | time: 21.984s
[2K
| Adam | epoch: 007 | loss: 0.68586 - acc: 0.5582 -- iter: 0448/1053
[A[ATraining Step: 213  | total loss: [1m[32m0.68564[0m[0m | time: 23.560s
[2K
| Adam | epoch: 007 | loss: 0.68564 - acc: 0.5586 -- iter: 0480/1053
[A[ATraining Step: 214  | total loss: [1m[32m0.68923[0m[0m | time: 24.953s
[2K
| Adam | epoch: 007 | loss: 0.68923 - acc: 0.5434 -- iter: 0512/1053
[A[ATraining Step: 215  | total loss: [1m[32m0.68917[0m[0m | time: 26.252s
[2K
| Adam | epoch: 007 | loss: 0.68917 - acc: 0.5422 -- iter: 0544/1053
[A[ATraining Step: 216  | total loss: [1m[32m0.69072[0m[0m | time: 27.499s
[2K
| Adam | epoch: 007 | loss: 0.69072 - acc: 0.5348 -- iter: 0576/1053
[A[ATraining Step: 217  | total loss: [1m[32m0.69409[0m[0m | time: 28.940s
[2K
| Adam | epoch: 007 | loss: 0.69409 - acc: 0.5188 -- iter: 0608/1053
[A[ATraining Step: 218  | total loss: [1m[32m0.69251[0m[0m | time: 30.264s
[2K
| Adam | epoch: 007 | loss: 0.69251 - acc: 0.5263 -- iter: 0640/1053
[A[ATraining Step: 219  | total loss: [1m[32m0.69305[0m[0m | time: 31.651s
[2K
| Adam | epoch: 007 | loss: 0.69305 - acc: 0.5237 -- iter: 0672/1053
[A[ATraining Step: 220  | total loss: [1m[32m0.69617[0m[0m | time: 33.089s
[2K
| Adam | epoch: 007 | loss: 0.69617 - acc: 0.5057 -- iter: 0704/1053
[A[ATraining Step: 221  | total loss: [1m[32m0.69655[0m[0m | time: 34.445s
[2K
| Adam | epoch: 007 | loss: 0.69655 - acc: 0.5020 -- iter: 0736/1053
[A[ATraining Step: 222  | total loss: [1m[32m0.69400[0m[0m | time: 35.707s
[2K
| Adam | epoch: 007 | loss: 0.69400 - acc: 0.5174 -- iter: 0768/1053
[A[ATraining Step: 223  | total loss: [1m[32m0.69220[0m[0m | time: 37.163s
[2K
| Adam | epoch: 007 | loss: 0.69220 - acc: 0.5282 -- iter: 0800/1053
[A[ATraining Step: 224  | total loss: [1m[32m0.69090[0m[0m | time: 38.949s
[2K
| Adam | epoch: 007 | loss: 0.69090 - acc: 0.5379 -- iter: 0832/1053
[A[ATraining Step: 225  | total loss: [1m[32m0.69001[0m[0m | time: 40.536s
[2K
| Adam | epoch: 007 | loss: 0.69001 - acc: 0.5435 -- iter: 0864/1053
[A[ATraining Step: 226  | total loss: [1m[32m0.69092[0m[0m | time: 42.000s
[2K
| Adam | epoch: 007 | loss: 0.69092 - acc: 0.5360 -- iter: 0896/1053
[A[ATraining Step: 227  | total loss: [1m[32m0.68999[0m[0m | time: 43.508s
[2K
| Adam | epoch: 007 | loss: 0.68999 - acc: 0.5418 -- iter: 0928/1053
[A[ATraining Step: 228  | total loss: [1m[32m0.68870[0m[0m | time: 45.037s
[2K
| Adam | epoch: 007 | loss: 0.68870 - acc: 0.5501 -- iter: 0960/1053
[A[ATraining Step: 229  | total loss: [1m[32m0.68658[0m[0m | time: 46.115s
[2K
| Adam | epoch: 007 | loss: 0.68658 - acc: 0.5638 -- iter: 0992/1053
[A[ATraining Step: 230  | total loss: [1m[32m0.68700[0m[0m | time: 47.270s
[2K
| Adam | epoch: 007 | loss: 0.68700 - acc: 0.5606 -- iter: 1024/1053
[A[ATraining Step: 231  | total loss: [1m[32m0.68646[0m[0m | time: 50.935s
[2K
| Adam | epoch: 007 | loss: 0.68646 - acc: 0.5639 | val_loss: 0.67772 - val_acc: 0.6091 -- iter: 1053/1053
--
Training Step: 232  | total loss: [1m[32m0.68737[0m[0m | time: 1.146s
[2K
| Adam | epoch: 008 | loss: 0.68737 - acc: 0.5575 -- iter: 0032/1053
[A[ATraining Step: 233  | total loss: [1m[32m0.68773[0m[0m | time: 2.401s
[2K
| Adam | epoch: 008 | loss: 0.68773 - acc: 0.5549 -- iter: 0064/1053
[A[ATraining Step: 234  | total loss: [1m[32m0.68882[0m[0m | time: 3.863s
[2K
| Adam | epoch: 008 | loss: 0.68882 - acc: 0.5463 -- iter: 0096/1053
[A[ATraining Step: 235  | total loss: [1m[32m0.68954[0m[0m | time: 5.178s
[2K
| Adam | epoch: 008 | loss: 0.68954 - acc: 0.5416 -- iter: 0128/1053
[A[ATraining Step: 236  | total loss: [1m[32m0.68842[0m[0m | time: 6.187s
[2K
| Adam | epoch: 008 | loss: 0.68842 - acc: 0.5468 -- iter: 0160/1053
[A[ATraining Step: 237  | total loss: [1m[32m0.68957[0m[0m | time: 7.260s
[2K
| Adam | epoch: 008 | loss: 0.68957 - acc: 0.5390 -- iter: 0192/1053
[A[ATraining Step: 238  | total loss: [1m[32m0.68626[0m[0m | time: 8.310s
[2K
| Adam | epoch: 008 | loss: 0.68626 - acc: 0.5575 -- iter: 0224/1053
[A[ATraining Step: 239  | total loss: [1m[32m0.68359[0m[0m | time: 9.429s
[2K
| Adam | epoch: 008 | loss: 0.68359 - acc: 0.5742 -- iter: 0256/1053
[A[ATraining Step: 240  | total loss: [1m[32m0.68491[0m[0m | time: 10.605s
[2K
| Adam | epoch: 008 | loss: 0.68491 - acc: 0.5668 -- iter: 0288/1053
[A[ATraining Step: 241  | total loss: [1m[32m0.68292[0m[0m | time: 11.991s
[2K
| Adam | epoch: 008 | loss: 0.68292 - acc: 0.5757 -- iter: 0320/1053
[A[ATraining Step: 242  | total loss: [1m[32m0.68567[0m[0m | time: 13.094s
[2K
| Adam | epoch: 008 | loss: 0.68567 - acc: 0.5619 -- iter: 0352/1053
[A[ATraining Step: 243  | total loss: [1m[32m0.68420[0m[0m | time: 14.328s
[2K
| Adam | epoch: 008 | loss: 0.68420 - acc: 0.5682 -- iter: 0384/1053
[A[ATraining Step: 244  | total loss: [1m[32m0.68346[0m[0m | time: 15.914s
[2K
| Adam | epoch: 008 | loss: 0.68346 - acc: 0.5708 -- iter: 0416/1053
[A[ATraining Step: 245  | total loss: [1m[32m0.68633[0m[0m | time: 17.570s
[2K
| Adam | epoch: 008 | loss: 0.68633 - acc: 0.5574 -- iter: 0448/1053
[A[ATraining Step: 246  | total loss: [1m[32m0.68675[0m[0m | time: 19.128s
[2K
| Adam | epoch: 008 | loss: 0.68675 - acc: 0.5548 -- iter: 0480/1053
[A[ATraining Step: 247  | total loss: [1m[32m0.68539[0m[0m | time: 20.248s
[2K
| Adam | epoch: 008 | loss: 0.68539 - acc: 0.5587 -- iter: 0512/1053
[A[ATraining Step: 248  | total loss: [1m[32m0.68514[0m[0m | time: 21.504s
[2K
| Adam | epoch: 008 | loss: 0.68514 - acc: 0.5591 -- iter: 0544/1053
[A[ATraining Step: 249  | total loss: [1m[32m0.68345[0m[0m | time: 22.830s
[2K
| Adam | epoch: 008 | loss: 0.68345 - acc: 0.5657 -- iter: 0576/1053
[A[ATraining Step: 250  | total loss: [1m[32m0.68040[0m[0m | time: 24.086s
[2K
| Adam | epoch: 008 | loss: 0.68040 - acc: 0.5779 -- iter: 0608/1053
[A[ATraining Step: 251  | total loss: [1m[32m0.68514[0m[0m | time: 25.353s
[2K
| Adam | epoch: 008 | loss: 0.68514 - acc: 0.5607 -- iter: 0640/1053
[A[ATraining Step: 252  | total loss: [1m[32m0.68472[0m[0m | time: 26.716s
[2K
| Adam | epoch: 008 | loss: 0.68472 - acc: 0.5609 -- iter: 0672/1053
[A[ATraining Step: 253  | total loss: [1m[32m0.68464[0m[0m | time: 28.139s
[2K
| Adam | epoch: 008 | loss: 0.68464 - acc: 0.5610 -- iter: 0704/1053
[A[ATraining Step: 254  | total loss: [1m[32m0.68245[0m[0m | time: 29.322s
[2K
| Adam | epoch: 008 | loss: 0.68245 - acc: 0.5674 -- iter: 0736/1053
[A[ATraining Step: 255  | total loss: [1m[32m0.68145[0m[0m | time: 30.719s
[2K
| Adam | epoch: 008 | loss: 0.68145 - acc: 0.5701 -- iter: 0768/1053
[A[ATraining Step: 256  | total loss: [1m[32m0.68327[0m[0m | time: 32.300s
[2K
| Adam | epoch: 008 | loss: 0.68327 - acc: 0.5631 -- iter: 0800/1053
[A[ATraining Step: 257  | total loss: [1m[32m0.68213[0m[0m | time: 33.925s
[2K
| Adam | epoch: 008 | loss: 0.68213 - acc: 0.5661 -- iter: 0832/1053
[A[ATraining Step: 258  | total loss: [1m[32m0.68369[0m[0m | time: 35.423s
[2K
| Adam | epoch: 008 | loss: 0.68369 - acc: 0.5595 -- iter: 0864/1053
[A[ATraining Step: 259  | total loss: [1m[32m0.68426[0m[0m | time: 36.653s
[2K
| Adam | epoch: 008 | loss: 0.68426 - acc: 0.5567 -- iter: 0896/1053
[A[ATraining Step: 260  | total loss: [1m[32m0.68862[0m[0m | time: 37.833s
[2K
| Adam | epoch: 008 | loss: 0.68862 - acc: 0.5416 -- iter: 0928/1053
[A[ATraining Step: 261  | total loss: [1m[32m0.68837[0m[0m | time: 39.115s
[2K
| Adam | epoch: 008 | loss: 0.68837 - acc: 0.5437 -- iter: 0960/1053
[A[ATraining Step: 262  | total loss: [1m[32m0.68923[0m[0m | time: 40.416s
[2K
| Adam | epoch: 008 | loss: 0.68923 - acc: 0.5394 -- iter: 0992/1053
[A[ATraining Step: 263  | total loss: [1m[32m0.68966[0m[0m | time: 41.782s
[2K
| Adam | epoch: 008 | loss: 0.68966 - acc: 0.5385 -- iter: 1024/1053
[A[ATraining Step: 264  | total loss: [1m[32m0.68971[0m[0m | time: 45.599s
[2K
| Adam | epoch: 008 | loss: 0.68971 - acc: 0.5378 | val_loss: 0.67378 - val_acc: 0.6091 -- iter: 1053/1053
--
Training Step: 265  | total loss: [1m[32m0.69026[0m[0m | time: 1.498s
[2K
| Adam | epoch: 009 | loss: 0.69026 - acc: 0.5340 -- iter: 0032/1053
[A[ATraining Step: 266  | total loss: [1m[32m0.68754[0m[0m | time: 3.031s
[2K
| Adam | epoch: 009 | loss: 0.68754 - acc: 0.5463 -- iter: 0064/1053
[A[ATraining Step: 267  | total loss: [1m[32m0.68838[0m[0m | time: 4.650s
[2K
| Adam | epoch: 009 | loss: 0.68838 - acc: 0.5416 -- iter: 0096/1053
[A[ATraining Step: 268  | total loss: [1m[32m0.68744[0m[0m | time: 5.926s
[2K
| Adam | epoch: 009 | loss: 0.68744 - acc: 0.5468 -- iter: 0128/1053
[A[ATraining Step: 269  | total loss: [1m[32m0.68944[0m[0m | time: 7.198s
[2K
| Adam | epoch: 009 | loss: 0.68944 - acc: 0.5359 -- iter: 0160/1053
[A[ATraining Step: 270  | total loss: [1m[32m0.68832[0m[0m | time: 8.542s
[2K
| Adam | epoch: 009 | loss: 0.68832 - acc: 0.5417 -- iter: 0192/1053
[A[ATraining Step: 271  | total loss: [1m[32m0.68842[0m[0m | time: 9.633s
[2K
| Adam | epoch: 009 | loss: 0.68842 - acc: 0.5406 -- iter: 0224/1053
[A[ATraining Step: 272  | total loss: [1m[32m0.68888[0m[0m | time: 10.768s
[2K
| Adam | epoch: 009 | loss: 0.68888 - acc: 0.5349 -- iter: 0256/1053
[A[ATraining Step: 273  | total loss: [1m[32m0.68893[0m[0m | time: 12.149s
[2K
| Adam | epoch: 009 | loss: 0.68893 - acc: 0.5297 -- iter: 0288/1053
[A[ATraining Step: 274  | total loss: [1m[32m0.68898[0m[0m | time: 13.584s
[2K
| Adam | epoch: 009 | loss: 0.68898 - acc: 0.5298 -- iter: 0320/1053
[A[ATraining Step: 275  | total loss: [1m[32m0.68954[0m[0m | time: 14.854s
[2K
| Adam | epoch: 009 | loss: 0.68954 - acc: 0.5268 -- iter: 0352/1053
[A[ATraining Step: 276  | total loss: [1m[32m0.68990[0m[0m | time: 16.175s
[2K
| Adam | epoch: 009 | loss: 0.68990 - acc: 0.5210 -- iter: 0384/1053
[A[ATraining Step: 277  | total loss: [1m[32m0.69014[0m[0m | time: 17.986s
[2K
| Adam | epoch: 009 | loss: 0.69014 - acc: 0.5189 -- iter: 0416/1053
[A[ATraining Step: 278  | total loss: [1m[32m0.68973[0m[0m | time: 19.825s
[2K
| Adam | epoch: 009 | loss: 0.68973 - acc: 0.5233 -- iter: 0448/1053
[A[ATraining Step: 279  | total loss: [1m[32m0.68940[0m[0m | time: 21.521s
[2K
| Adam | epoch: 009 | loss: 0.68940 - acc: 0.5272 -- iter: 0480/1053
[A[ATraining Step: 280  | total loss: [1m[32m0.68847[0m[0m | time: 23.020s
[2K
| Adam | epoch: 009 | loss: 0.68847 - acc: 0.5370 -- iter: 0512/1053
[A[ATraining Step: 281  | total loss: [1m[32m0.68857[0m[0m | time: 24.229s
[2K
| Adam | epoch: 009 | loss: 0.68857 - acc: 0.5333 -- iter: 0544/1053
[A[ATraining Step: 282  | total loss: [1m[32m0.68846[0m[0m | time: 25.585s
[2K
| Adam | epoch: 009 | loss: 0.68846 - acc: 0.5331 -- iter: 0576/1053
[A[ATraining Step: 283  | total loss: [1m[32m0.68651[0m[0m | time: 26.838s
[2K
| Adam | epoch: 009 | loss: 0.68651 - acc: 0.5485 -- iter: 0608/1053
[A[ATraining Step: 284  | total loss: [1m[32m0.68822[0m[0m | time: 28.195s
[2K
| Adam | epoch: 009 | loss: 0.68822 - acc: 0.5343 -- iter: 0640/1053
[A[ATraining Step: 285  | total loss: [1m[32m0.68645[0m[0m | time: 29.564s
[2K
| Adam | epoch: 009 | loss: 0.68645 - acc: 0.5465 -- iter: 0672/1053
[A[ATraining Step: 286  | total loss: [1m[32m0.68672[0m[0m | time: 31.084s
[2K
| Adam | epoch: 009 | loss: 0.68672 - acc: 0.5450 -- iter: 0704/1053
[A[ATraining Step: 287  | total loss: [1m[32m0.68522[0m[0m | time: 32.748s
[2K
| Adam | epoch: 009 | loss: 0.68522 - acc: 0.5530 -- iter: 0736/1053
[A[ATraining Step: 288  | total loss: [1m[32m0.68762[0m[0m | time: 33.973s
[2K
| Adam | epoch: 009 | loss: 0.68762 - acc: 0.5383 -- iter: 0768/1053
[A[ATraining Step: 289  | total loss: [1m[32m0.68840[0m[0m | time: 35.646s
[2K
| Adam | epoch: 009 | loss: 0.68840 - acc: 0.5313 -- iter: 0800/1053
[A[ATraining Step: 290  | total loss: [1m[32m0.68866[0m[0m | time: 37.382s
[2K
| Adam | epoch: 009 | loss: 0.68866 - acc: 0.5251 -- iter: 0832/1053
[A[ATraining Step: 291  | total loss: [1m[32m0.68936[0m[0m | time: 39.032s
[2K
| Adam | epoch: 009 | loss: 0.68936 - acc: 0.5226 -- iter: 0864/1053
[A[ATraining Step: 292  | total loss: [1m[32m0.68819[0m[0m | time: 40.566s
[2K
| Adam | epoch: 009 | loss: 0.68819 - acc: 0.5297 -- iter: 0896/1053
[A[ATraining Step: 293  | total loss: [1m[32m0.68811[0m[0m | time: 41.786s
[2K
| Adam | epoch: 009 | loss: 0.68811 - acc: 0.5298 -- iter: 0928/1053
[A[ATraining Step: 294  | total loss: [1m[32m0.68751[0m[0m | time: 43.025s
[2K
| Adam | epoch: 009 | loss: 0.68751 - acc: 0.5331 -- iter: 0960/1053
[A[ATraining Step: 295  | total loss: [1m[32m0.68607[0m[0m | time: 44.302s
[2K
| Adam | epoch: 009 | loss: 0.68607 - acc: 0.5486 -- iter: 0992/1053
[A[ATraining Step: 296  | total loss: [1m[32m0.68579[0m[0m | time: 45.554s
[2K
| Adam | epoch: 009 | loss: 0.68579 - acc: 0.5437 -- iter: 1024/1053
[A[ATraining Step: 297  | total loss: [1m[32m0.68510[0m[0m | time: 49.692s
[2K
| Adam | epoch: 009 | loss: 0.68510 - acc: 0.5487 | val_loss: 0.67157 - val_acc: 0.6091 -- iter: 1053/1053
--
Training Step: 298  | total loss: [1m[32m0.68397[0m[0m | time: 1.281s
[2K
| Adam | epoch: 010 | loss: 0.68397 - acc: 0.5563 -- iter: 0032/1053
[A[ATraining Step: 299  | total loss: [1m[32m0.68324[0m[0m | time: 2.898s
[2K
| Adam | epoch: 010 | loss: 0.68324 - acc: 0.5569 -- iter: 0064/1053
[A[ATraining Step: 300  | total loss: [1m[32m0.68191[0m[0m | time: 4.485s
[2K
| Adam | epoch: 010 | loss: 0.68191 - acc: 0.5606 -- iter: 0096/1053
[A[ATraining Step: 301  | total loss: [1m[32m0.68380[0m[0m | time: 6.168s
[2K
| Adam | epoch: 010 | loss: 0.68380 - acc: 0.5514 -- iter: 0128/1053
[A[ATraining Step: 302  | total loss: [1m[32m0.68284[0m[0m | time: 7.455s
[2K
| Adam | epoch: 010 | loss: 0.68284 - acc: 0.5557 -- iter: 0160/1053
[A[ATraining Step: 303  | total loss: [1m[32m0.68501[0m[0m | time: 8.696s
[2K
| Adam | epoch: 010 | loss: 0.68501 - acc: 0.5439 -- iter: 0192/1053
[A[ATraining Step: 304  | total loss: [1m[32m0.68118[0m[0m | time: 9.968s
[2K
| Adam | epoch: 010 | loss: 0.68118 - acc: 0.5582 -- iter: 0224/1053
[A[ATraining Step: 305  | total loss: [1m[32m0.68239[0m[0m | time: 11.156s
[2K
| Adam | epoch: 010 | loss: 0.68239 - acc: 0.5524 -- iter: 0256/1053
[A[ATraining Step: 306  | total loss: [1m[32m0.68314[0m[0m | time: 12.311s
[2K
| Adam | epoch: 010 | loss: 0.68314 - acc: 0.5489 -- iter: 0288/1053
[A[ATraining Step: 307  | total loss: [1m[32m0.68366[0m[0m | time: 13.621s
[2K
| Adam | epoch: 010 | loss: 0.68366 - acc: 0.5457 -- iter: 0320/1053
[A[ATraining Step: 308  | total loss: [1m[32m0.68355[0m[0m | time: 15.207s
[2K
| Adam | epoch: 010 | loss: 0.68355 - acc: 0.5474 -- iter: 0352/1053
[A[ATraining Step: 309  | total loss: [1m[32m0.68362[0m[0m | time: 16.693s
[2K
| Adam | epoch: 010 | loss: 0.68362 - acc: 0.5427 -- iter: 0384/1053
[A[ATraining Step: 310  | total loss: [1m[32m0.68195[0m[0m | time: 17.808s
[2K
| Adam | epoch: 010 | loss: 0.68195 - acc: 0.5478 -- iter: 0416/1053
[A[ATraining Step: 311  | total loss: [1m[32m0.68005[0m[0m | time: 19.358s
[2K
| Adam | epoch: 010 | loss: 0.68005 - acc: 0.5492 -- iter: 0448/1053
[A[ATraining Step: 312  | total loss: [1m[32m0.68117[0m[0m | time: 21.047s
[2K
| Adam | epoch: 010 | loss: 0.68117 - acc: 0.5443 -- iter: 0480/1053
[A[ATraining Step: 313  | total loss: [1m[32m0.68386[0m[0m | time: 22.695s
[2K
| Adam | epoch: 010 | loss: 0.68386 - acc: 0.5274 -- iter: 0512/1053
[A[ATraining Step: 314  | total loss: [1m[32m0.68229[0m[0m | time: 24.191s
[2K
| Adam | epoch: 010 | loss: 0.68229 - acc: 0.5340 -- iter: 0544/1053
[A[ATraining Step: 315  | total loss: [1m[32m0.68163[0m[0m | time: 25.440s
[2K
| Adam | epoch: 010 | loss: 0.68163 - acc: 0.5369 -- iter: 0576/1053
[A[ATraining Step: 316  | total loss: [1m[32m0.68151[0m[0m | time: 26.776s
[2K
| Adam | epoch: 010 | loss: 0.68151 - acc: 0.5363 -- iter: 0608/1053
[A[ATraining Step: 317  | total loss: [1m[32m0.68023[0m[0m | time: 28.022s
[2K
| Adam | epoch: 010 | loss: 0.68023 - acc: 0.5639 -- iter: 0640/1053
[A[ATraining Step: 318  | total loss: [1m[32m0.67912[0m[0m | time: 29.393s
[2K
| Adam | epoch: 010 | loss: 0.67912 - acc: 0.5763 -- iter: 0672/1053
[A[ATraining Step: 319  | total loss: [1m[32m0.67727[0m[0m | time: 30.752s
[2K
| Adam | epoch: 010 | loss: 0.67727 - acc: 0.5812 -- iter: 0704/1053
[A[ATraining Step: 320  | total loss: [1m[32m0.67705[0m[0m | time: 32.301s
[2K
| Adam | epoch: 010 | loss: 0.67705 - acc: 0.5824 -- iter: 0736/1053
[A[ATraining Step: 321  | total loss: [1m[32m0.67494[0m[0m | time: 33.801s
[2K
| Adam | epoch: 010 | loss: 0.67494 - acc: 0.5835 -- iter: 0768/1053
[A[ATraining Step: 322  | total loss: [1m[32m0.68120[0m[0m | time: 35.164s
[2K
| Adam | epoch: 010 | loss: 0.68120 - acc: 0.5627 -- iter: 0800/1053
[A[ATraining Step: 323  | total loss: [1m[32m0.67608[0m[0m | time: 36.819s
[2K
| Adam | epoch: 010 | loss: 0.67608 - acc: 0.5720 -- iter: 0832/1053
[A[ATraining Step: 324  | total loss: [1m[32m0.67450[0m[0m | time: 38.538s
[2K
| Adam | epoch: 010 | loss: 0.67450 - acc: 0.5711 -- iter: 0864/1053
[A[ATraining Step: 325  | total loss: [1m[32m0.67693[0m[0m | time: 40.345s
[2K
| Adam | epoch: 010 | loss: 0.67693 - acc: 0.5609 -- iter: 0896/1053
[A[ATraining Step: 326  | total loss: [1m[32m0.67341[0m[0m | time: 41.903s
[2K
| Adam | epoch: 010 | loss: 0.67341 - acc: 0.5641 -- iter: 0928/1053
[A[ATraining Step: 327  | total loss: [1m[32m0.66846[0m[0m | time: 43.067s
[2K
| Adam | epoch: 010 | loss: 0.66846 - acc: 0.5796 -- iter: 0960/1053
[A[ATraining Step: 328  | total loss: [1m[32m0.67268[0m[0m | time: 45.235s
[2K
| Adam | epoch: 010 | loss: 0.67268 - acc: 0.5654 -- iter: 0992/1053
[A[ATraining Step: 329  | total loss: [1m[32m0.67348[0m[0m | time: 47.515s
[2K
| Adam | epoch: 010 | loss: 0.67348 - acc: 0.5651 -- iter: 1024/1053
[A[ATraining Step: 330  | total loss: [1m[32m0.67084[0m[0m | time: 50.931s
[2K
| Adam | epoch: 010 | loss: 0.67084 - acc: 0.5805 | val_loss: 0.65242 - val_acc: 0.7061 -- iter: 1053/1053
--
Training Step: 331  | total loss: [1m[32m0.66945[0m[0m | time: 1.127s
[2K
| Adam | epoch: 011 | loss: 0.66945 - acc: 0.5849 -- iter: 0032/1053
[A[ATraining Step: 332  | total loss: [1m[32m0.66796[0m[0m | time: 2.279s
[2K
| Adam | epoch: 011 | loss: 0.66796 - acc: 0.5889 -- iter: 0064/1053
[A[ATraining Step: 333  | total loss: [1m[32m0.66932[0m[0m | time: 3.547s
[2K
| Adam | epoch: 011 | loss: 0.66932 - acc: 0.5925 -- iter: 0096/1053
[A[ATraining Step: 334  | total loss: [1m[32m0.66625[0m[0m | time: 5.027s
[2K
| Adam | epoch: 011 | loss: 0.66625 - acc: 0.6052 -- iter: 0128/1053
[A[ATraining Step: 335  | total loss: [1m[32m0.66463[0m[0m | time: 6.315s
[2K
| Adam | epoch: 011 | loss: 0.66463 - acc: 0.6196 -- iter: 0160/1053
[A[ATraining Step: 336  | total loss: [1m[32m0.66548[0m[0m | time: 7.327s
[2K
| Adam | epoch: 011 | loss: 0.66548 - acc: 0.6171 -- iter: 0192/1053
[A[ATraining Step: 337  | total loss: [1m[32m0.66918[0m[0m | time: 8.453s
[2K
| Adam | epoch: 011 | loss: 0.66918 - acc: 0.5960 -- iter: 0224/1053
[A[ATraining Step: 338  | total loss: [1m[32m0.66757[0m[0m | time: 9.529s
[2K
| Adam | epoch: 011 | loss: 0.66757 - acc: 0.5958 -- iter: 0256/1053
[A[ATraining Step: 339  | total loss: [1m[32m0.66626[0m[0m | time: 10.558s
[2K
| Adam | epoch: 011 | loss: 0.66626 - acc: 0.6018 -- iter: 0288/1053
[A[ATraining Step: 340  | total loss: [1m[32m0.66403[0m[0m | time: 11.579s
[2K
| Adam | epoch: 011 | loss: 0.66403 - acc: 0.6106 -- iter: 0320/1053
[A[ATraining Step: 341  | total loss: [1m[32m0.66019[0m[0m | time: 12.884s
[2K
| Adam | epoch: 011 | loss: 0.66019 - acc: 0.6185 -- iter: 0352/1053
[A[ATraining Step: 342  | total loss: [1m[32m0.66175[0m[0m | time: 14.021s
[2K
| Adam | epoch: 011 | loss: 0.66175 - acc: 0.6098 -- iter: 0384/1053
[A[ATraining Step: 343  | total loss: [1m[32m0.66454[0m[0m | time: 15.073s
[2K
| Adam | epoch: 011 | loss: 0.66454 - acc: 0.5988 -- iter: 0416/1053
[A[ATraining Step: 344  | total loss: [1m[32m0.66842[0m[0m | time: 16.332s
[2K
| Adam | epoch: 011 | loss: 0.66842 - acc: 0.5858 -- iter: 0448/1053
[A[ATraining Step: 345  | total loss: [1m[32m0.66143[0m[0m | time: 17.702s
[2K
| Adam | epoch: 011 | loss: 0.66143 - acc: 0.6053 -- iter: 0480/1053
[A[ATraining Step: 346  | total loss: [1m[32m0.65337[0m[0m | time: 19.187s
[2K
| Adam | epoch: 011 | loss: 0.65337 - acc: 0.6198 -- iter: 0512/1053
[A[ATraining Step: 347  | total loss: [1m[32m0.65392[0m[0m | time: 20.261s
[2K
| Adam | epoch: 011 | loss: 0.65392 - acc: 0.6141 -- iter: 0544/1053
[A[ATraining Step: 348  | total loss: [1m[32m0.64757[0m[0m | time: 21.325s
[2K
| Adam | epoch: 011 | loss: 0.64757 - acc: 0.6402 -- iter: 0576/1053
[A[ATraining Step: 349  | total loss: [1m[32m0.64681[0m[0m | time: 22.529s
[2K
| Adam | epoch: 011 | loss: 0.64681 - acc: 0.6324 -- iter: 0608/1053
[A[ATraining Step: 350  | total loss: [1m[32m0.64254[0m[0m | time: 23.687s
[2K
| Adam | epoch: 011 | loss: 0.64254 - acc: 0.6410 -- iter: 0640/1053
[A[ATraining Step: 351  | total loss: [1m[32m0.64491[0m[0m | time: 24.864s
[2K
| Adam | epoch: 011 | loss: 0.64491 - acc: 0.6363 -- iter: 0672/1053
[A[ATraining Step: 352  | total loss: [1m[32m0.63717[0m[0m | time: 26.160s
[2K
| Adam | epoch: 011 | loss: 0.63717 - acc: 0.6633 -- iter: 0704/1053
[A[ATraining Step: 353  | total loss: [1m[32m0.63649[0m[0m | time: 27.317s
[2K
| Adam | epoch: 011 | loss: 0.63649 - acc: 0.6688 -- iter: 0736/1053
[A[ATraining Step: 354  | total loss: [1m[32m0.63762[0m[0m | time: 28.318s
[2K
| Adam | epoch: 011 | loss: 0.63762 - acc: 0.6645 -- iter: 0768/1053
[A[ATraining Step: 355  | total loss: [1m[32m0.63321[0m[0m | time: 29.452s
[2K
| Adam | epoch: 011 | loss: 0.63321 - acc: 0.6761 -- iter: 0800/1053
[A[ATraining Step: 356  | total loss: [1m[32m0.63319[0m[0m | time: 30.659s
[2K
| Adam | epoch: 011 | loss: 0.63319 - acc: 0.6710 -- iter: 0832/1053
[A[ATraining Step: 357  | total loss: [1m[32m0.63311[0m[0m | time: 31.787s
[2K
| Adam | epoch: 011 | loss: 0.63311 - acc: 0.6727 -- iter: 0864/1053
[A[ATraining Step: 358  | total loss: [1m[32m0.62976[0m[0m | time: 33.005s
[2K
| Adam | epoch: 011 | loss: 0.62976 - acc: 0.6648 -- iter: 0896/1053
[A[ATraining Step: 359  | total loss: [1m[32m0.63343[0m[0m | time: 34.258s
[2K
| Adam | epoch: 011 | loss: 0.63343 - acc: 0.6608 -- iter: 0928/1053
[A[ATraining Step: 360  | total loss: [1m[32m0.63078[0m[0m | time: 35.430s
[2K
| Adam | epoch: 011 | loss: 0.63078 - acc: 0.6541 -- iter: 0960/1053
[A[ATraining Step: 361  | total loss: [1m[32m0.62371[0m[0m | time: 36.619s
[2K
| Adam | epoch: 011 | loss: 0.62371 - acc: 0.6637 -- iter: 0992/1053
[A[ATraining Step: 362  | total loss: [1m[32m0.62398[0m[0m | time: 37.864s
[2K
| Adam | epoch: 011 | loss: 0.62398 - acc: 0.6536 -- iter: 1024/1053
[A[ATraining Step: 363  | total loss: [1m[32m0.61579[0m[0m | time: 41.166s
[2K
| Adam | epoch: 011 | loss: 0.61579 - acc: 0.6632 | val_loss: 0.61025 - val_acc: 0.6848 -- iter: 1053/1053
--
Training Step: 364  | total loss: [1m[32m0.61383[0m[0m | time: 1.211s
[2K
| Adam | epoch: 012 | loss: 0.61383 - acc: 0.6750 -- iter: 0032/1053
[A[ATraining Step: 365  | total loss: [1m[32m0.61929[0m[0m | time: 2.325s
[2K
| Adam | epoch: 012 | loss: 0.61929 - acc: 0.6700 -- iter: 0064/1053
[A[ATraining Step: 366  | total loss: [1m[32m0.62615[0m[0m | time: 3.439s
[2K
| Adam | epoch: 012 | loss: 0.62615 - acc: 0.6655 -- iter: 0096/1053
[A[ATraining Step: 367  | total loss: [1m[32m0.62872[0m[0m | time: 4.685s
[2K
| Adam | epoch: 012 | loss: 0.62872 - acc: 0.6615 -- iter: 0128/1053
[A[ATraining Step: 368  | total loss: [1m[32m0.62811[0m[0m | time: 5.849s
[2K
| Adam | epoch: 012 | loss: 0.62811 - acc: 0.6703 -- iter: 0160/1053
[A[ATraining Step: 369  | total loss: [1m[32m0.62574[0m[0m | time: 6.963s
[2K
| Adam | epoch: 012 | loss: 0.62574 - acc: 0.6783 -- iter: 0192/1053
[A[ATraining Step: 370  | total loss: [1m[32m0.61868[0m[0m | time: 8.135s
[2K
| Adam | epoch: 012 | loss: 0.61868 - acc: 0.6823 -- iter: 0224/1053
[A[ATraining Step: 371  | total loss: [1m[32m0.61715[0m[0m | time: 9.639s
[2K
| Adam | epoch: 012 | loss: 0.61715 - acc: 0.6828 -- iter: 0256/1053
[A[ATraining Step: 372  | total loss: [1m[32m0.60916[0m[0m | time: 10.877s
[2K
| Adam | epoch: 012 | loss: 0.60916 - acc: 0.6896 -- iter: 0288/1053
[A[ATraining Step: 373  | total loss: [1m[32m0.60859[0m[0m | time: 12.043s
[2K
| Adam | epoch: 012 | loss: 0.60859 - acc: 0.6956 -- iter: 0320/1053
[A[ATraining Step: 374  | total loss: [1m[32m0.60804[0m[0m | time: 13.175s
[2K
| Adam | epoch: 012 | loss: 0.60804 - acc: 0.6985 -- iter: 0352/1053
[A[ATraining Step: 375  | total loss: [1m[32m0.60434[0m[0m | time: 14.361s
[2K
| Adam | epoch: 012 | loss: 0.60434 - acc: 0.7079 -- iter: 0384/1053
[A[ATraining Step: 376  | total loss: [1m[32m0.60217[0m[0m | time: 15.638s
[2K
| Adam | epoch: 012 | loss: 0.60217 - acc: 0.6965 -- iter: 0416/1053
[A[ATraining Step: 377  | total loss: [1m[32m0.60099[0m[0m | time: 16.803s
[2K
| Adam | epoch: 012 | loss: 0.60099 - acc: 0.7050 -- iter: 0448/1053
[A[ATraining Step: 378  | total loss: [1m[32m0.60240[0m[0m | time: 17.981s
[2K
| Adam | epoch: 012 | loss: 0.60240 - acc: 0.6939 -- iter: 0480/1053
[A[ATraining Step: 379  | total loss: [1m[32m0.59989[0m[0m | time: 19.205s
[2K
| Adam | epoch: 012 | loss: 0.59989 - acc: 0.6963 -- iter: 0512/1053
[A[ATraining Step: 380  | total loss: [1m[32m0.59854[0m[0m | time: 20.459s
[2K
| Adam | epoch: 012 | loss: 0.59854 - acc: 0.6986 -- iter: 0544/1053
[A[ATraining Step: 381  | total loss: [1m[32m0.59113[0m[0m | time: 21.620s
[2K
| Adam | epoch: 012 | loss: 0.59113 - acc: 0.7037 -- iter: 0576/1053
[A[ATraining Step: 382  | total loss: [1m[32m0.58088[0m[0m | time: 22.465s
[2K
| Adam | epoch: 012 | loss: 0.58088 - acc: 0.7146 -- iter: 0608/1053
[A[ATraining Step: 383  | total loss: [1m[32m0.58825[0m[0m | time: 23.238s
[2K
| Adam | epoch: 012 | loss: 0.58825 - acc: 0.7025 -- iter: 0640/1053
[A[ATraining Step: 384  | total loss: [1m[32m0.58844[0m[0m | time: 24.022s
[2K
| Adam | epoch: 012 | loss: 0.58844 - acc: 0.7041 -- iter: 0672/1053
[A[ATraining Step: 385  | total loss: [1m[32m0.58011[0m[0m | time: 24.757s
[2K
| Adam | epoch: 012 | loss: 0.58011 - acc: 0.7181 -- iter: 0704/1053
[A[ATraining Step: 386  | total loss: [1m[32m0.58448[0m[0m | time: 25.497s
[2K
| Adam | epoch: 012 | loss: 0.58448 - acc: 0.7119 -- iter: 0736/1053
[A[ATraining Step: 387  | total loss: [1m[32m0.58332[0m[0m | time: 26.227s
[2K
| Adam | epoch: 012 | loss: 0.58332 - acc: 0.7157 -- iter: 0768/1053
[A[ATraining Step: 388  | total loss: [1m[32m0.59267[0m[0m | time: 26.985s
[2K
| Adam | epoch: 012 | loss: 0.59267 - acc: 0.7067 -- iter: 0800/1053
[A[ATraining Step: 389  | total loss: [1m[32m0.58570[0m[0m | time: 27.717s
[2K
| Adam | epoch: 012 | loss: 0.58570 - acc: 0.7141 -- iter: 0832/1053
[A[ATraining Step: 390  | total loss: [1m[32m0.58318[0m[0m | time: 28.477s
[2K
| Adam | epoch: 012 | loss: 0.58318 - acc: 0.7146 -- iter: 0864/1053
[A[ATraining Step: 391  | total loss: [1m[32m0.58521[0m[0m | time: 29.225s
[2K
| Adam | epoch: 012 | loss: 0.58521 - acc: 0.7056 -- iter: 0896/1053
[A[ATraining Step: 392  | total loss: [1m[32m0.58617[0m[0m | time: 29.971s
[2K
| Adam | epoch: 012 | loss: 0.58617 - acc: 0.7101 -- iter: 0928/1053
[A[ATraining Step: 393  | total loss: [1m[32m0.57909[0m[0m | time: 30.699s
[2K
| Adam | epoch: 012 | loss: 0.57909 - acc: 0.7109 -- iter: 0960/1053
[A[ATraining Step: 394  | total loss: [1m[32m0.56743[0m[0m | time: 31.425s
[2K
| Adam | epoch: 012 | loss: 0.56743 - acc: 0.7211 -- iter: 0992/1053
[A[ATraining Step: 395  | total loss: [1m[32m0.56672[0m[0m | time: 32.200s
[2K
| Adam | epoch: 012 | loss: 0.56672 - acc: 0.7209 -- iter: 1024/1053
[A[ATraining Step: 396  | total loss: [1m[32m0.56960[0m[0m | time: 34.222s
[2K
| Adam | epoch: 012 | loss: 0.56960 - acc: 0.7113 | val_loss: 0.57348 - val_acc: 0.7121 -- iter: 1053/1053
--
Training Step: 397  | total loss: [1m[32m0.57494[0m[0m | time: 0.777s
[2K
| Adam | epoch: 013 | loss: 0.57494 - acc: 0.7026 -- iter: 0032/1053
[A[ATraining Step: 398  | total loss: [1m[32m0.56373[0m[0m | time: 1.550s
[2K
| Adam | epoch: 013 | loss: 0.56373 - acc: 0.7136 -- iter: 0064/1053
[A[ATraining Step: 399  | total loss: [1m[32m0.56671[0m[0m | time: 2.315s
[2K
| Adam | epoch: 013 | loss: 0.56671 - acc: 0.7079 -- iter: 0096/1053
[A[ATraining Step: 400  | total loss: [1m[32m0.56548[0m[0m | time: 4.357s
[2K
| Adam | epoch: 013 | loss: 0.56548 - acc: 0.7058 | val_loss: 0.56197 - val_acc: 0.7121 -- iter: 0128/1053
--
Training Step: 401  | total loss: [1m[32m0.57559[0m[0m | time: 5.205s
[2K
| Adam | epoch: 013 | loss: 0.57559 - acc: 0.6915 -- iter: 0160/1053
[A[ATraining Step: 402  | total loss: [1m[32m0.56748[0m[0m | time: 6.394s
[2K
| Adam | epoch: 013 | loss: 0.56748 - acc: 0.7005 -- iter: 0192/1053
[A[ATraining Step: 403  | total loss: [1m[32m0.58105[0m[0m | time: 7.646s
[2K
| Adam | epoch: 013 | loss: 0.58105 - acc: 0.6867 -- iter: 0224/1053
[A[ATraining Step: 404  | total loss: [1m[32m0.57862[0m[0m | time: 8.966s
[2K
| Adam | epoch: 013 | loss: 0.57862 - acc: 0.6868 -- iter: 0256/1053
[A[ATraining Step: 405  | total loss: [1m[32m0.57946[0m[0m | time: 9.966s
[2K
| Adam | epoch: 013 | loss: 0.57946 - acc: 0.6962 -- iter: 0288/1053
[A[ATraining Step: 406  | total loss: [1m[32m0.58343[0m[0m | time: 10.977s
[2K
| Adam | epoch: 013 | loss: 0.58343 - acc: 0.7016 -- iter: 0320/1053
[A[ATraining Step: 407  | total loss: [1m[32m0.58443[0m[0m | time: 11.968s
[2K
| Adam | epoch: 013 | loss: 0.58443 - acc: 0.7002 -- iter: 0352/1053
[A[ATraining Step: 408  | total loss: [1m[32m0.57374[0m[0m | time: 13.000s
[2K
| Adam | epoch: 013 | loss: 0.57374 - acc: 0.7060 -- iter: 0384/1053
[A[ATraining Step: 409  | total loss: [1m[32m0.55840[0m[0m | time: 14.089s
[2K
| Adam | epoch: 013 | loss: 0.55840 - acc: 0.7251 -- iter: 0416/1053
[A[ATraining Step: 410  | total loss: [1m[32m0.56116[0m[0m | time: 15.242s
[2K
| Adam | epoch: 013 | loss: 0.56116 - acc: 0.7213 -- iter: 0448/1053
[A[ATraining Step: 411  | total loss: [1m[32m0.56217[0m[0m | time: 16.577s
[2K
| Adam | epoch: 013 | loss: 0.56217 - acc: 0.7211 -- iter: 0480/1053
[A[ATraining Step: 412  | total loss: [1m[32m0.56797[0m[0m | time: 17.936s
[2K
| Adam | epoch: 013 | loss: 0.56797 - acc: 0.7177 -- iter: 0512/1053
[A[ATraining Step: 413  | total loss: [1m[32m0.55336[0m[0m | time: 19.135s
[2K
| Adam | epoch: 013 | loss: 0.55336 - acc: 0.7272 -- iter: 0544/1053
[A[ATraining Step: 414  | total loss: [1m[32m0.56173[0m[0m | time: 20.418s
[2K
| Adam | epoch: 013 | loss: 0.56173 - acc: 0.7138 -- iter: 0576/1053
[A[ATraining Step: 415  | total loss: [1m[32m0.55538[0m[0m | time: 21.862s
[2K
| Adam | epoch: 013 | loss: 0.55538 - acc: 0.7143 -- iter: 0608/1053
[A[ATraining Step: 416  | total loss: [1m[32m0.55882[0m[0m | time: 23.105s
[2K
| Adam | epoch: 013 | loss: 0.55882 - acc: 0.7179 -- iter: 0640/1053
[A[ATraining Step: 417  | total loss: [1m[32m0.55700[0m[0m | time: 24.049s
[2K
| Adam | epoch: 013 | loss: 0.55700 - acc: 0.7180 -- iter: 0672/1053
[A[ATraining Step: 418  | total loss: [1m[32m0.55957[0m[0m | time: 25.167s
[2K
| Adam | epoch: 013 | loss: 0.55957 - acc: 0.7118 -- iter: 0704/1053
[A[ATraining Step: 419  | total loss: [1m[32m0.55583[0m[0m | time: 26.220s
[2K
| Adam | epoch: 013 | loss: 0.55583 - acc: 0.7219 -- iter: 0736/1053
[A[ATraining Step: 420  | total loss: [1m[32m0.54440[0m[0m | time: 27.383s
[2K
| Adam | epoch: 013 | loss: 0.54440 - acc: 0.7341 -- iter: 0768/1053
[A[ATraining Step: 421  | total loss: [1m[32m0.55649[0m[0m | time: 28.499s
[2K
| Adam | epoch: 013 | loss: 0.55649 - acc: 0.7232 -- iter: 0800/1053
[A[ATraining Step: 422  | total loss: [1m[32m0.56931[0m[0m | time: 29.709s
[2K
| Adam | epoch: 013 | loss: 0.56931 - acc: 0.7102 -- iter: 0832/1053
[A[ATraining Step: 423  | total loss: [1m[32m0.56522[0m[0m | time: 30.869s
[2K
| Adam | epoch: 013 | loss: 0.56522 - acc: 0.7111 -- iter: 0864/1053
[A[ATraining Step: 424  | total loss: [1m[32m0.57347[0m[0m | time: 31.853s
[2K
| Adam | epoch: 013 | loss: 0.57347 - acc: 0.7087 -- iter: 0896/1053
[A[ATraining Step: 425  | total loss: [1m[32m0.56513[0m[0m | time: 32.951s
[2K
| Adam | epoch: 013 | loss: 0.56513 - acc: 0.7097 -- iter: 0928/1053
[A[ATraining Step: 426  | total loss: [1m[32m0.56548[0m[0m | time: 33.797s
[2K
| Adam | epoch: 013 | loss: 0.56548 - acc: 0.7044 -- iter: 0960/1053
[A[ATraining Step: 427  | total loss: [1m[32m0.56159[0m[0m | time: 34.712s
[2K
| Adam | epoch: 013 | loss: 0.56159 - acc: 0.7089 -- iter: 0992/1053
[A[ATraining Step: 428  | total loss: [1m[32m0.56307[0m[0m | time: 35.678s
[2K
| Adam | epoch: 013 | loss: 0.56307 - acc: 0.7068 -- iter: 1024/1053
[A[ATraining Step: 429  | total loss: [1m[32m0.55758[0m[0m | time: 38.389s
[2K
| Adam | epoch: 013 | loss: 0.55758 - acc: 0.7174 | val_loss: 0.59280 - val_acc: 0.7182 -- iter: 1053/1053
--
Training Step: 430  | total loss: [1m[32m0.56525[0m[0m | time: 1.142s
[2K
| Adam | epoch: 014 | loss: 0.56525 - acc: 0.7050 -- iter: 0032/1053
[A[ATraining Step: 431  | total loss: [1m[32m0.55425[0m[0m | time: 2.422s
[2K
| Adam | epoch: 014 | loss: 0.55425 - acc: 0.7220 -- iter: 0064/1053
[A[ATraining Step: 432  | total loss: [1m[32m0.56316[0m[0m | time: 3.428s
[2K
| Adam | epoch: 014 | loss: 0.56316 - acc: 0.7186 -- iter: 0096/1053
[A[ATraining Step: 433  | total loss: [1m[32m0.56498[0m[0m | time: 4.441s
[2K
| Adam | epoch: 014 | loss: 0.56498 - acc: 0.7217 -- iter: 0128/1053
[A[ATraining Step: 434  | total loss: [1m[32m0.55941[0m[0m | time: 5.648s
[2K
| Adam | epoch: 014 | loss: 0.55941 - acc: 0.7277 -- iter: 0160/1053
[A[ATraining Step: 435  | total loss: [1m[32m0.55632[0m[0m | time: 6.859s
[2K
| Adam | epoch: 014 | loss: 0.55632 - acc: 0.7299 -- iter: 0192/1053
[A[ATraining Step: 436  | total loss: [1m[32m0.55600[0m[0m | time: 8.047s
[2K
| Adam | epoch: 014 | loss: 0.55600 - acc: 0.7256 -- iter: 0224/1053
[A[ATraining Step: 437  | total loss: [1m[32m0.54749[0m[0m | time: 9.294s
[2K
| Adam | epoch: 014 | loss: 0.54749 - acc: 0.7281 -- iter: 0256/1053
[A[ATraining Step: 438  | total loss: [1m[32m0.55525[0m[0m | time: 10.494s
[2K
| Adam | epoch: 014 | loss: 0.55525 - acc: 0.7209 -- iter: 0288/1053
[A[ATraining Step: 439  | total loss: [1m[32m0.55472[0m[0m | time: 11.614s
[2K
| Adam | epoch: 014 | loss: 0.55472 - acc: 0.7269 -- iter: 0320/1053
[A[ATraining Step: 440  | total loss: [1m[32m0.54630[0m[0m | time: 12.868s
[2K
| Adam | epoch: 014 | loss: 0.54630 - acc: 0.7355 -- iter: 0352/1053
[A[ATraining Step: 441  | total loss: [1m[32m0.55561[0m[0m | time: 13.908s
[2K
| Adam | epoch: 014 | loss: 0.55561 - acc: 0.7244 -- iter: 0384/1053
[A[ATraining Step: 442  | total loss: [1m[32m0.55231[0m[0m | time: 14.963s
[2K
| Adam | epoch: 014 | loss: 0.55231 - acc: 0.7313 -- iter: 0416/1053
[A[ATraining Step: 443  | total loss: [1m[32m0.54990[0m[0m | time: 16.094s
[2K
| Adam | epoch: 014 | loss: 0.54990 - acc: 0.7340 -- iter: 0448/1053
[A[ATraining Step: 444  | total loss: [1m[32m0.54374[0m[0m | time: 17.225s
[2K
| Adam | epoch: 014 | loss: 0.54374 - acc: 0.7481 -- iter: 0480/1053
[A[ATraining Step: 445  | total loss: [1m[32m0.54736[0m[0m | time: 18.296s
[2K
| Adam | epoch: 014 | loss: 0.54736 - acc: 0.7421 -- iter: 0512/1053
[A[ATraining Step: 446  | total loss: [1m[32m0.55266[0m[0m | time: 19.546s
[2K
| Adam | epoch: 014 | loss: 0.55266 - acc: 0.7397 -- iter: 0544/1053
[A[ATraining Step: 447  | total loss: [1m[32m0.55693[0m[0m | time: 20.674s
[2K
| Adam | epoch: 014 | loss: 0.55693 - acc: 0.7314 -- iter: 0576/1053
[A[ATraining Step: 448  | total loss: [1m[32m0.55890[0m[0m | time: 21.864s
[2K
| Adam | epoch: 014 | loss: 0.55890 - acc: 0.7301 -- iter: 0608/1053
[A[ATraining Step: 449  | total loss: [1m[32m0.55213[0m[0m | time: 23.090s
[2K
| Adam | epoch: 014 | loss: 0.55213 - acc: 0.7415 -- iter: 0640/1053
[A[ATraining Step: 450  | total loss: [1m[32m0.56468[0m[0m | time: 24.344s
[2K
| Adam | epoch: 014 | loss: 0.56468 - acc: 0.7236 -- iter: 0672/1053
[A[ATraining Step: 451  | total loss: [1m[32m0.57197[0m[0m | time: 25.516s
[2K
| Adam | epoch: 014 | loss: 0.57197 - acc: 0.7169 -- iter: 0704/1053
[A[ATraining Step: 452  | total loss: [1m[32m0.56595[0m[0m | time: 26.650s
[2K
| Adam | epoch: 014 | loss: 0.56595 - acc: 0.7202 -- iter: 0736/1053
[A[ATraining Step: 453  | total loss: [1m[32m0.55056[0m[0m | time: 27.806s
[2K
| Adam | epoch: 014 | loss: 0.55056 - acc: 0.7325 -- iter: 0768/1053
[A[ATraining Step: 454  | total loss: [1m[32m0.55193[0m[0m | time: 29.025s
[2K
| Adam | epoch: 014 | loss: 0.55193 - acc: 0.7312 -- iter: 0800/1053
[A[ATraining Step: 455  | total loss: [1m[32m0.55582[0m[0m | time: 30.257s
[2K
| Adam | epoch: 014 | loss: 0.55582 - acc: 0.7237 -- iter: 0832/1053
[A[ATraining Step: 456  | total loss: [1m[32m0.55510[0m[0m | time: 31.401s
[2K
| Adam | epoch: 014 | loss: 0.55510 - acc: 0.7169 -- iter: 0864/1053
[A[ATraining Step: 457  | total loss: [1m[32m0.54440[0m[0m | time: 32.626s
[2K
| Adam | epoch: 014 | loss: 0.54440 - acc: 0.7234 -- iter: 0896/1053
[A[ATraining Step: 458  | total loss: [1m[32m0.55187[0m[0m | time: 33.956s
[2K
| Adam | epoch: 014 | loss: 0.55187 - acc: 0.7198 -- iter: 0928/1053
[A[ATraining Step: 459  | total loss: [1m[32m0.54874[0m[0m | time: 35.120s
[2K
| Adam | epoch: 014 | loss: 0.54874 - acc: 0.7290 -- iter: 0960/1053
[A[ATraining Step: 460  | total loss: [1m[32m0.54540[0m[0m | time: 36.366s
[2K
| Adam | epoch: 014 | loss: 0.54540 - acc: 0.7311 -- iter: 0992/1053
[A[ATraining Step: 461  | total loss: [1m[32m0.54476[0m[0m | time: 37.622s
[2K
| Adam | epoch: 014 | loss: 0.54476 - acc: 0.7330 -- iter: 1024/1053
[A[ATraining Step: 462  | total loss: [1m[32m0.54519[0m[0m | time: 40.311s
[2K
| Adam | epoch: 014 | loss: 0.54519 - acc: 0.7347 | val_loss: 0.55549 - val_acc: 0.7303 -- iter: 1053/1053
--
Training Step: 463  | total loss: [1m[32m0.54255[0m[0m | time: 0.758s
[2K
| Adam | epoch: 015 | loss: 0.54255 - acc: 0.7394 -- iter: 0032/1053
[A[ATraining Step: 464  | total loss: [1m[32m0.54728[0m[0m | time: 1.473s
[2K
| Adam | epoch: 015 | loss: 0.54728 - acc: 0.7373 -- iter: 0064/1053
[A[ATraining Step: 465  | total loss: [1m[32m0.55523[0m[0m | time: 2.233s
[2K
| Adam | epoch: 015 | loss: 0.55523 - acc: 0.7292 -- iter: 0096/1053
[A[ATraining Step: 466  | total loss: [1m[32m0.55238[0m[0m | time: 2.977s
[2K
| Adam | epoch: 015 | loss: 0.55238 - acc: 0.7282 -- iter: 0128/1053
[A[ATraining Step: 467  | total loss: [1m[32m0.53853[0m[0m | time: 3.710s
[2K
| Adam | epoch: 015 | loss: 0.53853 - acc: 0.7397 -- iter: 0160/1053
[A[ATraining Step: 468  | total loss: [1m[32m0.52653[0m[0m | time: 4.445s
[2K
| Adam | epoch: 015 | loss: 0.52653 - acc: 0.7501 -- iter: 0192/1053
[A[ATraining Step: 469  | total loss: [1m[32m0.51981[0m[0m | time: 5.172s
[2K
| Adam | epoch: 015 | loss: 0.51981 - acc: 0.7532 -- iter: 0224/1053
[A[ATraining Step: 470  | total loss: [1m[32m0.51907[0m[0m | time: 5.897s
[2K
| Adam | epoch: 015 | loss: 0.51907 - acc: 0.7467 -- iter: 0256/1053
[A[ATraining Step: 471  | total loss: [1m[32m0.51157[0m[0m | time: 6.610s
[2K
| Adam | epoch: 015 | loss: 0.51157 - acc: 0.7532 -- iter: 0288/1053
[A[ATraining Step: 472  | total loss: [1m[32m0.51297[0m[0m | time: 7.327s
[2K
| Adam | epoch: 015 | loss: 0.51297 - acc: 0.7467 -- iter: 0320/1053
[A[ATraining Step: 473  | total loss: [1m[32m0.50879[0m[0m | time: 8.075s
[2K
| Adam | epoch: 015 | loss: 0.50879 - acc: 0.7533 -- iter: 0352/1053
[A[ATraining Step: 474  | total loss: [1m[32m0.50810[0m[0m | time: 8.798s
[2K
| Adam | epoch: 015 | loss: 0.50810 - acc: 0.7561 -- iter: 0384/1053
[A[ATraining Step: 475  | total loss: [1m[32m0.50320[0m[0m | time: 9.587s
[2K
| Adam | epoch: 015 | loss: 0.50320 - acc: 0.7554 -- iter: 0416/1053
[A[ATraining Step: 476  | total loss: [1m[32m0.49363[0m[0m | time: 10.685s
[2K
| Adam | epoch: 015 | loss: 0.49363 - acc: 0.7661 -- iter: 0448/1053
[A[ATraining Step: 477  | total loss: [1m[32m0.48448[0m[0m | time: 12.219s
[2K
| Adam | epoch: 015 | loss: 0.48448 - acc: 0.7757 -- iter: 0480/1053
[A[ATraining Step: 478  | total loss: [1m[32m0.50055[0m[0m | time: 13.554s
[2K
| Adam | epoch: 015 | loss: 0.50055 - acc: 0.7638 -- iter: 0512/1053
[A[ATraining Step: 479  | total loss: [1m[32m0.51439[0m[0m | time: 14.533s
[2K
| Adam | epoch: 015 | loss: 0.51439 - acc: 0.7499 -- iter: 0544/1053
[A[ATraining Step: 480  | total loss: [1m[32m0.51005[0m[0m | time: 15.555s
[2K
| Adam | epoch: 015 | loss: 0.51005 - acc: 0.7561 -- iter: 0576/1053
[A[ATraining Step: 481  | total loss: [1m[32m0.51002[0m[0m | time: 16.679s
[2K
| Adam | epoch: 015 | loss: 0.51002 - acc: 0.7555 -- iter: 0608/1053
[A[ATraining Step: 482  | total loss: [1m[32m0.51918[0m[0m | time: 17.733s
[2K
| Adam | epoch: 015 | loss: 0.51918 - acc: 0.7519 -- iter: 0640/1053
[A[ATraining Step: 483  | total loss: [1m[32m0.52040[0m[0m | time: 18.844s
[2K
| Adam | epoch: 015 | loss: 0.52040 - acc: 0.7548 -- iter: 0672/1053
[A[ATraining Step: 484  | total loss: [1m[32m0.50895[0m[0m | time: 20.055s
[2K
| Adam | epoch: 015 | loss: 0.50895 - acc: 0.7606 -- iter: 0704/1053
[A[ATraining Step: 485  | total loss: [1m[32m0.50868[0m[0m | time: 21.278s
[2K
| Adam | epoch: 015 | loss: 0.50868 - acc: 0.7658 -- iter: 0736/1053
[A[ATraining Step: 486  | total loss: [1m[32m0.49568[0m[0m | time: 22.288s
[2K
| Adam | epoch: 015 | loss: 0.49568 - acc: 0.7642 -- iter: 0768/1053
[A[ATraining Step: 487  | total loss: [1m[32m0.50366[0m[0m | time: 23.335s
[2K
| Adam | epoch: 015 | loss: 0.50366 - acc: 0.7503 -- iter: 0800/1053
[A[ATraining Step: 488  | total loss: [1m[32m0.50642[0m[0m | time: 24.666s
[2K
| Adam | epoch: 015 | loss: 0.50642 - acc: 0.7471 -- iter: 0832/1053
[A[ATraining Step: 489  | total loss: [1m[32m0.49585[0m[0m | time: 26.132s
[2K
| Adam | epoch: 015 | loss: 0.49585 - acc: 0.7568 -- iter: 0864/1053
[A[ATraining Step: 490  | total loss: [1m[32m0.49476[0m[0m | time: 27.379s
[2K
| Adam | epoch: 015 | loss: 0.49476 - acc: 0.7592 -- iter: 0896/1053
[A[ATraining Step: 491  | total loss: [1m[32m0.49347[0m[0m | time: 28.356s
[2K
| Adam | epoch: 015 | loss: 0.49347 - acc: 0.7583 -- iter: 0928/1053
[A[ATraining Step: 492  | total loss: [1m[32m0.49193[0m[0m | time: 29.434s
[2K
| Adam | epoch: 015 | loss: 0.49193 - acc: 0.7637 -- iter: 0960/1053
[A[ATraining Step: 493  | total loss: [1m[32m0.47702[0m[0m | time: 30.488s
[2K
| Adam | epoch: 015 | loss: 0.47702 - acc: 0.7811 -- iter: 0992/1053
[A[ATraining Step: 494  | total loss: [1m[32m0.46412[0m[0m | time: 31.553s
[2K
| Adam | epoch: 015 | loss: 0.46412 - acc: 0.7936 -- iter: 1024/1053
[A[ATraining Step: 495  | total loss: [1m[32m0.46782[0m[0m | time: 34.806s
[2K
| Adam | epoch: 015 | loss: 0.46782 - acc: 0.7955 | val_loss: 0.55575 - val_acc: 0.7364 -- iter: 1053/1053
--
Training Step: 496  | total loss: [1m[32m0.47960[0m[0m | time: 1.168s
[2K
| Adam | epoch: 016 | loss: 0.47960 - acc: 0.7816 -- iter: 0032/1053
[A[ATraining Step: 497  | total loss: [1m[32m0.48288[0m[0m | time: 2.472s
[2K
| Adam | epoch: 016 | loss: 0.48288 - acc: 0.7784 -- iter: 0064/1053
[A[ATraining Step: 498  | total loss: [1m[32m0.48174[0m[0m | time: 3.976s
[2K
| Adam | epoch: 016 | loss: 0.48174 - acc: 0.7787 -- iter: 0096/1053
[A[ATraining Step: 499  | total loss: [1m[32m0.49631[0m[0m | time: 5.396s
[2K
| Adam | epoch: 016 | loss: 0.49631 - acc: 0.7602 -- iter: 0128/1053
[A[ATraining Step: 500  | total loss: [1m[32m0.49639[0m[0m | time: 6.456s
[2K
| Adam | epoch: 016 | loss: 0.49639 - acc: 0.7561 -- iter: 0160/1053
[A[ATraining Step: 501  | total loss: [1m[32m0.48906[0m[0m | time: 7.461s
[2K
| Adam | epoch: 016 | loss: 0.48906 - acc: 0.7648 -- iter: 0192/1053
[A[ATraining Step: 502  | total loss: [1m[32m0.48534[0m[0m | time: 8.601s
[2K
| Adam | epoch: 016 | loss: 0.48534 - acc: 0.7696 -- iter: 0224/1053
[A[ATraining Step: 503  | total loss: [1m[32m0.49604[0m[0m | time: 9.617s
[2K
| Adam | epoch: 016 | loss: 0.49604 - acc: 0.7614 -- iter: 0256/1053
[A[ATraining Step: 504  | total loss: [1m[32m0.50558[0m[0m | time: 10.862s
[2K
| Adam | epoch: 016 | loss: 0.50558 - acc: 0.7540 -- iter: 0288/1053
[A[ATraining Step: 505  | total loss: [1m[32m0.51364[0m[0m | time: 12.128s
[2K
| Adam | epoch: 016 | loss: 0.51364 - acc: 0.7505 -- iter: 0320/1053
[A[ATraining Step: 506  | total loss: [1m[32m0.50110[0m[0m | time: 13.174s
[2K
| Adam | epoch: 016 | loss: 0.50110 - acc: 0.7629 -- iter: 0352/1053
[A[ATraining Step: 507  | total loss: [1m[32m0.50039[0m[0m | time: 14.283s
[2K
| Adam | epoch: 016 | loss: 0.50039 - acc: 0.7679 -- iter: 0384/1053
[A[ATraining Step: 508  | total loss: [1m[32m0.50231[0m[0m | time: 15.579s
[2K
| Adam | epoch: 016 | loss: 0.50231 - acc: 0.7661 -- iter: 0416/1053
[A[ATraining Step: 509  | total loss: [1m[32m0.49193[0m[0m | time: 16.824s
[2K
| Adam | epoch: 016 | loss: 0.49193 - acc: 0.7707 -- iter: 0448/1053
[A[ATraining Step: 510  | total loss: [1m[32m0.49714[0m[0m | time: 18.065s
[2K
| Adam | epoch: 016 | loss: 0.49714 - acc: 0.7626 -- iter: 0480/1053
[A[ATraining Step: 511  | total loss: [1m[32m0.50205[0m[0m | time: 19.037s
[2K
| Adam | epoch: 016 | loss: 0.50205 - acc: 0.7588 -- iter: 0512/1053
[A[ATraining Step: 512  | total loss: [1m[32m0.50292[0m[0m | time: 20.101s
[2K
| Adam | epoch: 016 | loss: 0.50292 - acc: 0.7548 -- iter: 0544/1053
[A[ATraining Step: 513  | total loss: [1m[32m0.49422[0m[0m | time: 21.219s
[2K
| Adam | epoch: 016 | loss: 0.49422 - acc: 0.7605 -- iter: 0576/1053
[A[ATraining Step: 514  | total loss: [1m[32m0.48939[0m[0m | time: 22.286s
[2K
| Adam | epoch: 016 | loss: 0.48939 - acc: 0.7626 -- iter: 0608/1053
[A[ATraining Step: 515  | total loss: [1m[32m0.48773[0m[0m | time: 23.422s
[2K
| Adam | epoch: 016 | loss: 0.48773 - acc: 0.7614 -- iter: 0640/1053
[A[ATraining Step: 516  | total loss: [1m[32m0.48399[0m[0m | time: 24.589s
[2K
| Adam | epoch: 016 | loss: 0.48399 - acc: 0.7602 -- iter: 0672/1053
[A[ATraining Step: 517  | total loss: [1m[32m0.48387[0m[0m | time: 25.716s
[2K
| Adam | epoch: 016 | loss: 0.48387 - acc: 0.7623 -- iter: 0704/1053
[A[ATraining Step: 518  | total loss: [1m[32m0.48414[0m[0m | time: 26.705s
[2K
| Adam | epoch: 016 | loss: 0.48414 - acc: 0.7611 -- iter: 0736/1053
[A[ATraining Step: 519  | total loss: [1m[32m0.48569[0m[0m | time: 27.828s
[2K
| Adam | epoch: 016 | loss: 0.48569 - acc: 0.7537 -- iter: 0768/1053
[A[ATraining Step: 520  | total loss: [1m[32m0.48253[0m[0m | time: 29.179s
[2K
| Adam | epoch: 016 | loss: 0.48253 - acc: 0.7565 -- iter: 0800/1053
[A[ATraining Step: 521  | total loss: [1m[32m0.47285[0m[0m | time: 30.622s
[2K
| Adam | epoch: 016 | loss: 0.47285 - acc: 0.7652 -- iter: 0832/1053
[A[ATraining Step: 522  | total loss: [1m[32m0.46848[0m[0m | time: 31.702s
[2K
| Adam | epoch: 016 | loss: 0.46848 - acc: 0.7699 -- iter: 0864/1053
[A[ATraining Step: 523  | total loss: [1m[32m0.47905[0m[0m | time: 32.728s
[2K
| Adam | epoch: 016 | loss: 0.47905 - acc: 0.7586 -- iter: 0896/1053
[A[ATraining Step: 524  | total loss: [1m[32m0.48061[0m[0m | time: 33.751s
[2K
| Adam | epoch: 016 | loss: 0.48061 - acc: 0.7577 -- iter: 0928/1053
[A[ATraining Step: 525  | total loss: [1m[32m0.48355[0m[0m | time: 34.880s
[2K
| Adam | epoch: 016 | loss: 0.48355 - acc: 0.7601 -- iter: 0960/1053
[A[ATraining Step: 526  | total loss: [1m[32m0.48686[0m[0m | time: 35.977s
[2K
| Adam | epoch: 016 | loss: 0.48686 - acc: 0.7653 -- iter: 0992/1053
[A[ATraining Step: 527  | total loss: [1m[32m0.48763[0m[0m | time: 37.169s
[2K
| Adam | epoch: 016 | loss: 0.48763 - acc: 0.7638 -- iter: 1024/1053
[A[ATraining Step: 528  | total loss: [1m[32m0.49178[0m[0m | time: 39.994s
[2K
| Adam | epoch: 016 | loss: 0.49178 - acc: 0.7624 | val_loss: 0.61952 - val_acc: 0.6848 -- iter: 1053/1053
--
Training Step: 529  | total loss: [1m[32m0.49829[0m[0m | time: 1.325s
[2K
| Adam | epoch: 017 | loss: 0.49829 - acc: 0.7643 -- iter: 0032/1053
[A[ATraining Step: 530  | total loss: [1m[32m0.49875[0m[0m | time: 2.794s
[2K
| Adam | epoch: 017 | loss: 0.49875 - acc: 0.7597 -- iter: 0064/1053
[A[ATraining Step: 531  | total loss: [1m[32m0.49316[0m[0m | time: 4.083s
[2K
| Adam | epoch: 017 | loss: 0.49316 - acc: 0.7713 -- iter: 0096/1053
[A[ATraining Step: 532  | total loss: [1m[32m0.48361[0m[0m | time: 5.094s
[2K
| Adam | epoch: 017 | loss: 0.48361 - acc: 0.7848 -- iter: 0128/1053
[A[ATraining Step: 533  | total loss: [1m[32m0.47360[0m[0m | time: 6.186s
[2K
| Adam | epoch: 017 | loss: 0.47360 - acc: 0.7938 -- iter: 0160/1053
[A[ATraining Step: 534  | total loss: [1m[32m0.49278[0m[0m | time: 7.268s
[2K
| Adam | epoch: 017 | loss: 0.49278 - acc: 0.7832 -- iter: 0192/1053
[A[ATraining Step: 535  | total loss: [1m[32m0.50020[0m[0m | time: 8.301s
[2K
| Adam | epoch: 017 | loss: 0.50020 - acc: 0.7736 -- iter: 0224/1053
[A[ATraining Step: 536  | total loss: [1m[32m0.48351[0m[0m | time: 9.545s
[2K
| Adam | epoch: 017 | loss: 0.48351 - acc: 0.7806 -- iter: 0256/1053
[A[ATraining Step: 537  | total loss: [1m[32m0.48514[0m[0m | time: 10.754s
[2K
| Adam | epoch: 017 | loss: 0.48514 - acc: 0.7807 -- iter: 0288/1053
[A[ATraining Step: 538  | total loss: [1m[32m0.47435[0m[0m | time: 11.810s
[2K
| Adam | epoch: 017 | loss: 0.47435 - acc: 0.7901 -- iter: 0320/1053
[A[ATraining Step: 539  | total loss: [1m[32m0.48004[0m[0m | time: 12.774s
[2K
| Adam | epoch: 017 | loss: 0.48004 - acc: 0.7892 -- iter: 0352/1053
[A[ATraining Step: 540  | total loss: [1m[32m0.48848[0m[0m | time: 13.944s
[2K
| Adam | epoch: 017 | loss: 0.48848 - acc: 0.7759 -- iter: 0384/1053
[A[ATraining Step: 541  | total loss: [1m[32m0.49848[0m[0m | time: 15.313s
[2K
| Adam | epoch: 017 | loss: 0.49848 - acc: 0.7733 -- iter: 0416/1053
[A[ATraining Step: 542  | total loss: [1m[32m0.50138[0m[0m | time: 16.718s
[2K
| Adam | epoch: 017 | loss: 0.50138 - acc: 0.7679 -- iter: 0448/1053
[A[ATraining Step: 543  | total loss: [1m[32m0.49462[0m[0m | time: 17.730s
[2K
| Adam | epoch: 017 | loss: 0.49462 - acc: 0.7786 -- iter: 0480/1053
[A[ATraining Step: 544  | total loss: [1m[32m0.48801[0m[0m | time: 18.945s
[2K
| Adam | epoch: 017 | loss: 0.48801 - acc: 0.7869 -- iter: 0512/1053
[A[ATraining Step: 545  | total loss: [1m[32m0.47983[0m[0m | time: 20.137s
[2K
| Adam | epoch: 017 | loss: 0.47983 - acc: 0.7944 -- iter: 0544/1053
[A[ATraining Step: 546  | total loss: [1m[32m0.49698[0m[0m | time: 21.151s
[2K
| Adam | epoch: 017 | loss: 0.49698 - acc: 0.7806 -- iter: 0576/1053
[A[ATraining Step: 547  | total loss: [1m[32m0.49630[0m[0m | time: 22.291s
[2K
| Adam | epoch: 017 | loss: 0.49630 - acc: 0.7744 -- iter: 0608/1053
[A[ATraining Step: 548  | total loss: [1m[32m0.50695[0m[0m | time: 23.601s
[2K
| Adam | epoch: 017 | loss: 0.50695 - acc: 0.7657 -- iter: 0640/1053
[A[ATraining Step: 549  | total loss: [1m[32m0.49041[0m[0m | time: 24.782s
[2K
| Adam | epoch: 017 | loss: 0.49041 - acc: 0.7798 -- iter: 0672/1053
[A[ATraining Step: 550  | total loss: [1m[32m0.48586[0m[0m | time: 25.786s
[2K
| Adam | epoch: 017 | loss: 0.48586 - acc: 0.7768 -- iter: 0704/1053
[A[ATraining Step: 551  | total loss: [1m[32m0.49068[0m[0m | time: 26.875s
[2K
| Adam | epoch: 017 | loss: 0.49068 - acc: 0.7679 -- iter: 0736/1053
[A[ATraining Step: 552  | total loss: [1m[32m0.49000[0m[0m | time: 28.264s
[2K
| Adam | epoch: 017 | loss: 0.49000 - acc: 0.7786 -- iter: 0768/1053
[A[ATraining Step: 553  | total loss: [1m[32m0.49682[0m[0m | time: 29.655s
[2K
| Adam | epoch: 017 | loss: 0.49682 - acc: 0.7757 -- iter: 0800/1053
[A[ATraining Step: 554  | total loss: [1m[32m0.50104[0m[0m | time: 30.711s
[2K
| Adam | epoch: 017 | loss: 0.50104 - acc: 0.7700 -- iter: 0832/1053
[A[ATraining Step: 555  | total loss: [1m[32m0.49587[0m[0m | time: 31.711s
[2K
| Adam | epoch: 017 | loss: 0.49587 - acc: 0.7649 -- iter: 0864/1053
[A[ATraining Step: 556  | total loss: [1m[32m0.49132[0m[0m | time: 32.802s
[2K
| Adam | epoch: 017 | loss: 0.49132 - acc: 0.7697 -- iter: 0896/1053
[A[ATraining Step: 557  | total loss: [1m[32m0.48470[0m[0m | time: 33.886s
[2K
| Adam | epoch: 017 | loss: 0.48470 - acc: 0.7708 -- iter: 0928/1053
[A[ATraining Step: 558  | total loss: [1m[32m0.47561[0m[0m | time: 35.038s
[2K
| Adam | epoch: 017 | loss: 0.47561 - acc: 0.7750 -- iter: 0960/1053
[A[ATraining Step: 559  | total loss: [1m[32m0.48128[0m[0m | time: 36.154s
[2K
| Adam | epoch: 017 | loss: 0.48128 - acc: 0.7725 -- iter: 0992/1053
[A[ATraining Step: 560  | total loss: [1m[32m0.47365[0m[0m | time: 37.342s
[2K
| Adam | epoch: 017 | loss: 0.47365 - acc: 0.7702 -- iter: 1024/1053
[A[ATraining Step: 561  | total loss: [1m[32m0.49303[0m[0m | time: 40.134s
[2K
| Adam | epoch: 017 | loss: 0.49303 - acc: 0.7620 | val_loss: 0.53848 - val_acc: 0.7091 -- iter: 1053/1053
--
Training Step: 562  | total loss: [1m[32m0.49162[0m[0m | time: 1.434s
[2K
| Adam | epoch: 018 | loss: 0.49162 - acc: 0.7670 -- iter: 0032/1053
[A[ATraining Step: 563  | total loss: [1m[32m0.47963[0m[0m | time: 2.858s
[2K
| Adam | epoch: 018 | loss: 0.47963 - acc: 0.7684 -- iter: 0064/1053
[A[ATraining Step: 564  | total loss: [1m[32m0.49338[0m[0m | time: 3.822s
[2K
| Adam | epoch: 018 | loss: 0.49338 - acc: 0.7604 -- iter: 0096/1053
[A[ATraining Step: 565  | total loss: [1m[32m0.48672[0m[0m | time: 4.933s
[2K
| Adam | epoch: 018 | loss: 0.48672 - acc: 0.7624 -- iter: 0128/1053
[A[ATraining Step: 566  | total loss: [1m[32m0.47472[0m[0m | time: 6.013s
[2K
| Adam | epoch: 018 | loss: 0.47472 - acc: 0.7674 -- iter: 0160/1053
[A[ATraining Step: 567  | total loss: [1m[32m0.46082[0m[0m | time: 7.106s
[2K
| Adam | epoch: 018 | loss: 0.46082 - acc: 0.7813 -- iter: 0192/1053
[A[ATraining Step: 568  | total loss: [1m[32m0.45782[0m[0m | time: 8.211s
[2K
| Adam | epoch: 018 | loss: 0.45782 - acc: 0.7876 -- iter: 0224/1053
[A[ATraining Step: 569  | total loss: [1m[32m0.45456[0m[0m | time: 9.490s
[2K
| Adam | epoch: 018 | loss: 0.45456 - acc: 0.7901 -- iter: 0256/1053
[A[ATraining Step: 570  | total loss: [1m[32m0.45597[0m[0m | time: 10.723s
[2K
| Adam | epoch: 018 | loss: 0.45597 - acc: 0.7892 -- iter: 0288/1053
[A[ATraining Step: 571  | total loss: [1m[32m0.46548[0m[0m | time: 11.779s
[2K
| Adam | epoch: 018 | loss: 0.46548 - acc: 0.7821 -- iter: 0320/1053
[A[ATraining Step: 572  | total loss: [1m[32m0.46187[0m[0m | time: 13.053s
[2K
| Adam | epoch: 018 | loss: 0.46187 - acc: 0.7883 -- iter: 0352/1053
[A[ATraining Step: 573  | total loss: [1m[32m0.46768[0m[0m | time: 14.522s
[2K
| Adam | epoch: 018 | loss: 0.46768 - acc: 0.7876 -- iter: 0384/1053
[A[ATraining Step: 574  | total loss: [1m[32m0.45855[0m[0m | time: 15.927s
[2K
| Adam | epoch: 018 | loss: 0.45855 - acc: 0.7932 -- iter: 0416/1053
[A[ATraining Step: 575  | total loss: [1m[32m0.43900[0m[0m | time: 16.895s
[2K
| Adam | epoch: 018 | loss: 0.43900 - acc: 0.8076 -- iter: 0448/1053
[A[ATraining Step: 576  | total loss: [1m[32m0.42672[0m[0m | time: 18.043s
[2K
| Adam | epoch: 018 | loss: 0.42672 - acc: 0.8113 -- iter: 0480/1053
[A[ATraining Step: 577  | total loss: [1m[32m0.44642[0m[0m | time: 19.133s
[2K
| Adam | epoch: 018 | loss: 0.44642 - acc: 0.7926 -- iter: 0512/1053
[A[ATraining Step: 578  | total loss: [1m[32m0.44263[0m[0m | time: 20.154s
[2K
| Adam | epoch: 018 | loss: 0.44263 - acc: 0.7927 -- iter: 0544/1053
[A[ATraining Step: 579  | total loss: [1m[32m0.43853[0m[0m | time: 21.269s
[2K
| Adam | epoch: 018 | loss: 0.43853 - acc: 0.7927 -- iter: 0576/1053
[A[ATraining Step: 580  | total loss: [1m[32m0.43765[0m[0m | time: 22.457s
[2K
| Adam | epoch: 018 | loss: 0.43765 - acc: 0.7947 -- iter: 0608/1053
[A[ATraining Step: 581  | total loss: [1m[32m0.41722[0m[0m | time: 23.647s
[2K
| Adam | epoch: 018 | loss: 0.41722 - acc: 0.8027 -- iter: 0640/1053
[A[ATraining Step: 582  | total loss: [1m[32m0.41028[0m[0m | time: 24.654s
[2K
| Adam | epoch: 018 | loss: 0.41028 - acc: 0.8131 -- iter: 0672/1053
[A[ATraining Step: 583  | total loss: [1m[32m0.41581[0m[0m | time: 25.836s
[2K
| Adam | epoch: 018 | loss: 0.41581 - acc: 0.8130 -- iter: 0704/1053
[A[ATraining Step: 584  | total loss: [1m[32m0.41441[0m[0m | time: 27.194s
[2K
| Adam | epoch: 018 | loss: 0.41441 - acc: 0.8161 -- iter: 0736/1053
[A[ATraining Step: 585  | total loss: [1m[32m0.41812[0m[0m | time: 28.650s
[2K
| Adam | epoch: 018 | loss: 0.41812 - acc: 0.8157 -- iter: 0768/1053
[A[ATraining Step: 586  | total loss: [1m[32m0.42337[0m[0m | time: 29.720s
[2K
| Adam | epoch: 018 | loss: 0.42337 - acc: 0.8092 -- iter: 0800/1053
[A[ATraining Step: 587  | total loss: [1m[32m0.43387[0m[0m | time: 30.736s
[2K
| Adam | epoch: 018 | loss: 0.43387 - acc: 0.8001 -- iter: 0832/1053
[A[ATraining Step: 588  | total loss: [1m[32m0.43387[0m[0m | time: 31.694s
[2K
| Adam | epoch: 018 | loss: 0.43387 - acc: 0.8014 -- iter: 0864/1053
[A[ATraining Step: 589  | total loss: [1m[32m0.43273[0m[0m | time: 33.096s
[2K
| Adam | epoch: 018 | loss: 0.43273 - acc: 0.8056 -- iter: 0896/1053
[A[ATraining Step: 590  | total loss: [1m[32m0.44255[0m[0m | time: 34.329s
[2K
| Adam | epoch: 018 | loss: 0.44255 - acc: 0.7938 -- iter: 0928/1053
[A[ATraining Step: 591  | total loss: [1m[32m0.43079[0m[0m | time: 35.566s
[2K
| Adam | epoch: 018 | loss: 0.43079 - acc: 0.7988 -- iter: 0960/1053
[A[ATraining Step: 592  | total loss: [1m[32m0.42895[0m[0m | time: 36.758s
[2K
| Adam | epoch: 018 | loss: 0.42895 - acc: 0.8064 -- iter: 0992/1053
[A[ATraining Step: 593  | total loss: [1m[32m0.41525[0m[0m | time: 37.850s
[2K
| Adam | epoch: 018 | loss: 0.41525 - acc: 0.8133 -- iter: 1024/1053
[A[ATraining Step: 594  | total loss: [1m[32m0.42657[0m[0m | time: 41.076s
[2K
| Adam | epoch: 018 | loss: 0.42657 - acc: 0.8069 | val_loss: 0.58355 - val_acc: 0.7182 -- iter: 1053/1053
--
Training Step: 595  | total loss: [1m[32m0.43186[0m[0m | time: 1.299s
[2K
| Adam | epoch: 019 | loss: 0.43186 - acc: 0.8044 -- iter: 0032/1053
[A[ATraining Step: 596  | total loss: [1m[32m0.42746[0m[0m | time: 2.295s
[2K
| Adam | epoch: 019 | loss: 0.42746 - acc: 0.8114 -- iter: 0064/1053
[A[ATraining Step: 597  | total loss: [1m[32m0.42723[0m[0m | time: 3.292s
[2K
| Adam | epoch: 019 | loss: 0.42723 - acc: 0.8084 -- iter: 0096/1053
[A[ATraining Step: 598  | total loss: [1m[32m0.43396[0m[0m | time: 4.314s
[2K
| Adam | epoch: 019 | loss: 0.43396 - acc: 0.8057 -- iter: 0128/1053
[A[ATraining Step: 599  | total loss: [1m[32m0.43252[0m[0m | time: 5.404s
[2K
| Adam | epoch: 019 | loss: 0.43252 - acc: 0.8033 -- iter: 0160/1053
[A[ATraining Step: 600  | total loss: [1m[32m0.43098[0m[0m | time: 8.577s
[2K
| Adam | epoch: 019 | loss: 0.43098 - acc: 0.8011 | val_loss: 0.51477 - val_acc: 0.7364 -- iter: 0192/1053
--
Training Step: 601  | total loss: [1m[32m0.43747[0m[0m | time: 9.691s
[2K
| Adam | epoch: 019 | loss: 0.43747 - acc: 0.8022 -- iter: 0224/1053
[A[ATraining Step: 602  | total loss: [1m[32m0.43623[0m[0m | time: 10.950s
[2K
| Adam | epoch: 019 | loss: 0.43623 - acc: 0.7970 -- iter: 0256/1053
[A[ATraining Step: 603  | total loss: [1m[32m0.43179[0m[0m | time: 12.342s
[2K
| Adam | epoch: 019 | loss: 0.43179 - acc: 0.7954 -- iter: 0288/1053
[A[ATraining Step: 604  | total loss: [1m[32m0.43404[0m[0m | time: 13.808s
[2K
| Adam | epoch: 019 | loss: 0.43404 - acc: 0.7909 -- iter: 0320/1053
[A[ATraining Step: 605  | total loss: [1m[32m0.43759[0m[0m | time: 14.802s
[2K
| Adam | epoch: 019 | loss: 0.43759 - acc: 0.7837 -- iter: 0352/1053
[A[ATraining Step: 606  | total loss: [1m[32m0.43177[0m[0m | time: 15.832s
[2K
| Adam | epoch: 019 | loss: 0.43177 - acc: 0.7865 -- iter: 0384/1053
[A[ATraining Step: 607  | total loss: [1m[32m0.43532[0m[0m | time: 16.929s
[2K
| Adam | epoch: 019 | loss: 0.43532 - acc: 0.7891 -- iter: 0416/1053
[A[ATraining Step: 608  | total loss: [1m[32m0.43700[0m[0m | time: 18.039s
[2K
| Adam | epoch: 019 | loss: 0.43700 - acc: 0.7915 -- iter: 0448/1053
[A[ATraining Step: 609  | total loss: [1m[32m0.43175[0m[0m | time: 19.302s
[2K
| Adam | epoch: 019 | loss: 0.43175 - acc: 0.7998 -- iter: 0480/1053
[A[ATraining Step: 610  | total loss: [1m[32m0.42979[0m[0m | time: 20.632s
[2K
| Adam | epoch: 019 | loss: 0.42979 - acc: 0.7980 -- iter: 0512/1053
[A[ATraining Step: 611  | total loss: [1m[32m0.43249[0m[0m | time: 21.642s
[2K
| Adam | epoch: 019 | loss: 0.43249 - acc: 0.7994 -- iter: 0544/1053
[A[ATraining Step: 612  | total loss: [1m[32m0.43489[0m[0m | time: 22.579s
[2K
| Adam | epoch: 019 | loss: 0.43489 - acc: 0.7988 -- iter: 0576/1053
[A[ATraining Step: 613  | total loss: [1m[32m0.43642[0m[0m | time: 23.761s
[2K
| Adam | epoch: 019 | loss: 0.43642 - acc: 0.7982 -- iter: 0608/1053
[A[ATraining Step: 614  | total loss: [1m[32m0.45513[0m[0m | time: 25.198s
[2K
| Adam | epoch: 019 | loss: 0.45513 - acc: 0.7871 -- iter: 0640/1053
[A[ATraining Step: 615  | total loss: [1m[32m0.43800[0m[0m | time: 26.593s
[2K
| Adam | epoch: 019 | loss: 0.43800 - acc: 0.8022 -- iter: 0672/1053
[A[ATraining Step: 616  | total loss: [1m[32m0.44523[0m[0m | time: 27.494s
[2K
| Adam | epoch: 019 | loss: 0.44523 - acc: 0.8032 -- iter: 0704/1053
[A[ATraining Step: 617  | total loss: [1m[32m0.43918[0m[0m | time: 28.651s
[2K
| Adam | epoch: 019 | loss: 0.43918 - acc: 0.8041 -- iter: 0736/1053
[A[ATraining Step: 618  | total loss: [1m[32m0.43838[0m[0m | time: 29.786s
[2K
| Adam | epoch: 019 | loss: 0.43838 - acc: 0.8081 -- iter: 0768/1053
[A[ATraining Step: 619  | total loss: [1m[32m0.45430[0m[0m | time: 30.904s
[2K
| Adam | epoch: 019 | loss: 0.45430 - acc: 0.7992 -- iter: 0800/1053
[A[ATraining Step: 620  | total loss: [1m[32m0.44203[0m[0m | time: 31.981s
[2K
| Adam | epoch: 019 | loss: 0.44203 - acc: 0.8036 -- iter: 0832/1053
[A[ATraining Step: 621  | total loss: [1m[32m0.43632[0m[0m | time: 33.222s
[2K
| Adam | epoch: 019 | loss: 0.43632 - acc: 0.8076 -- iter: 0864/1053
[A[ATraining Step: 622  | total loss: [1m[32m0.42629[0m[0m | time: 34.356s
[2K
| Adam | epoch: 019 | loss: 0.42629 - acc: 0.8081 -- iter: 0896/1053
[A[ATraining Step: 623  | total loss: [1m[32m0.41851[0m[0m | time: 35.349s
[2K
| Adam | epoch: 019 | loss: 0.41851 - acc: 0.8148 -- iter: 0928/1053
[A[ATraining Step: 624  | total loss: [1m[32m0.40108[0m[0m | time: 36.554s
[2K
| Adam | epoch: 019 | loss: 0.40108 - acc: 0.8240 -- iter: 0960/1053
[A[ATraining Step: 625  | total loss: [1m[32m0.40026[0m[0m | time: 38.217s
[2K
| Adam | epoch: 019 | loss: 0.40026 - acc: 0.8228 -- iter: 0992/1053
[A[ATraining Step: 626  | total loss: [1m[32m0.40474[0m[0m | time: 39.751s
[2K
| Adam | epoch: 019 | loss: 0.40474 - acc: 0.8249 -- iter: 1024/1053
[A[ATraining Step: 627  | total loss: [1m[32m0.40570[0m[0m | time: 42.580s
[2K
| Adam | epoch: 019 | loss: 0.40570 - acc: 0.8237 | val_loss: 0.51535 - val_acc: 0.7606 -- iter: 1053/1053
--
Training Step: 628  | total loss: [1m[32m0.40749[0m[0m | time: 1.172s
[2K
| Adam | epoch: 020 | loss: 0.40749 - acc: 0.8163 -- iter: 0032/1053
[A[ATraining Step: 629  | total loss: [1m[32m0.41169[0m[0m | time: 2.292s
[2K
| Adam | epoch: 020 | loss: 0.41169 - acc: 0.8128 -- iter: 0064/1053
[A[ATraining Step: 630  | total loss: [1m[32m0.40768[0m[0m | time: 3.813s
[2K
| Adam | epoch: 020 | loss: 0.40768 - acc: 0.8128 -- iter: 0096/1053
[A[ATraining Step: 631  | total loss: [1m[32m0.41537[0m[0m | time: 5.280s
[2K
| Adam | epoch: 020 | loss: 0.41537 - acc: 0.8127 -- iter: 0128/1053
[A[ATraining Step: 632  | total loss: [1m[32m0.42207[0m[0m | time: 6.257s
[2K
| Adam | epoch: 020 | loss: 0.42207 - acc: 0.8127 -- iter: 0160/1053
[A[ATraining Step: 633  | total loss: [1m[32m0.43032[0m[0m | time: 7.448s
[2K
| Adam | epoch: 020 | loss: 0.43032 - acc: 0.8033 -- iter: 0192/1053
[A[ATraining Step: 634  | total loss: [1m[32m0.42552[0m[0m | time: 8.782s
[2K
| Adam | epoch: 020 | loss: 0.42552 - acc: 0.8074 -- iter: 0224/1053
[A[ATraining Step: 635  | total loss: [1m[32m0.41736[0m[0m | time: 10.287s
[2K
| Adam | epoch: 020 | loss: 0.41736 - acc: 0.8235 -- iter: 0256/1053
[A[ATraining Step: 636  | total loss: [1m[32m0.41082[0m[0m | time: 11.341s
[2K
| Adam | epoch: 020 | loss: 0.41082 - acc: 0.8255 -- iter: 0288/1053
[A[ATraining Step: 637  | total loss: [1m[32m0.40756[0m[0m | time: 12.363s
[2K
| Adam | epoch: 020 | loss: 0.40756 - acc: 0.8305 -- iter: 0320/1053
[A[ATraining Step: 638  | total loss: [1m[32m0.39842[0m[0m | time: 13.460s
[2K
| Adam | epoch: 020 | loss: 0.39842 - acc: 0.8349 -- iter: 0352/1053
[A[ATraining Step: 639  | total loss: [1m[32m0.40709[0m[0m | time: 14.518s
[2K
| Adam | epoch: 020 | loss: 0.40709 - acc: 0.8327 -- iter: 0384/1053
[A[ATraining Step: 640  | total loss: [1m[32m0.39620[0m[0m | time: 15.691s
[2K
| Adam | epoch: 020 | loss: 0.39620 - acc: 0.8338 -- iter: 0416/1053
[A[ATraining Step: 641  | total loss: [1m[32m0.40308[0m[0m | time: 16.846s
[2K
| Adam | epoch: 020 | loss: 0.40308 - acc: 0.8285 -- iter: 0448/1053
[A[ATraining Step: 642  | total loss: [1m[32m0.38752[0m[0m | time: 18.043s
[2K
| Adam | epoch: 020 | loss: 0.38752 - acc: 0.8363 -- iter: 0480/1053
[A[ATraining Step: 643  | total loss: [1m[32m0.38104[0m[0m | time: 19.067s
[2K
| Adam | epoch: 020 | loss: 0.38104 - acc: 0.8371 -- iter: 0512/1053
[A[ATraining Step: 644  | total loss: [1m[32m0.39792[0m[0m | time: 20.366s
[2K
| Adam | epoch: 020 | loss: 0.39792 - acc: 0.8221 -- iter: 0544/1053
[A[ATraining Step: 645  | total loss: [1m[32m0.38361[0m[0m | time: 21.703s
[2K
| Adam | epoch: 020 | loss: 0.38361 - acc: 0.8305 -- iter: 0576/1053
[A[ATraining Step: 646  | total loss: [1m[32m0.37340[0m[0m | time: 23.050s
[2K
| Adam | epoch: 020 | loss: 0.37340 - acc: 0.8371 -- iter: 0608/1053
[A[ATraining Step: 647  | total loss: [1m[32m0.36379[0m[0m | time: 24.138s
[2K
| Adam | epoch: 020 | loss: 0.36379 - acc: 0.8396 -- iter: 0640/1053
[A[ATraining Step: 648  | total loss: [1m[32m0.41797[0m[0m | time: 25.154s
[2K
| Adam | epoch: 020 | loss: 0.41797 - acc: 0.8119 -- iter: 0672/1053
[A[ATraining Step: 649  | total loss: [1m[32m0.42566[0m[0m | time: 26.178s
[2K
| Adam | epoch: 020 | loss: 0.42566 - acc: 0.8120 -- iter: 0704/1053
[A[ATraining Step: 650  | total loss: [1m[32m0.41320[0m[0m | time: 27.230s
[2K
| Adam | epoch: 020 | loss: 0.41320 - acc: 0.8214 -- iter: 0736/1053
[A[ATraining Step: 651  | total loss: [1m[32m0.42561[0m[0m | time: 28.328s
[2K
| Adam | epoch: 020 | loss: 0.42561 - acc: 0.8142 -- iter: 0768/1053
[A[ATraining Step: 652  | total loss: [1m[32m0.42309[0m[0m | time: 29.447s
[2K
| Adam | epoch: 020 | loss: 0.42309 - acc: 0.8109 -- iter: 0800/1053
[A[ATraining Step: 653  | total loss: [1m[32m0.42906[0m[0m | time: 30.701s
[2K
| Adam | epoch: 020 | loss: 0.42906 - acc: 0.8080 -- iter: 0832/1053
[A[ATraining Step: 654  | total loss: [1m[32m0.42202[0m[0m | time: 31.752s
[2K
| Adam | epoch: 020 | loss: 0.42202 - acc: 0.8116 -- iter: 0864/1053
[A[ATraining Step: 655  | total loss: [1m[32m0.41258[0m[0m | time: 32.854s
[2K
| Adam | epoch: 020 | loss: 0.41258 - acc: 0.8148 -- iter: 0896/1053
[A[ATraining Step: 656  | total loss: [1m[32m0.40590[0m[0m | time: 34.192s
[2K
| Adam | epoch: 020 | loss: 0.40590 - acc: 0.8177 -- iter: 0928/1053
[A[ATraining Step: 657  | total loss: [1m[32m0.39175[0m[0m | time: 35.698s
[2K
| Adam | epoch: 020 | loss: 0.39175 - acc: 0.8265 -- iter: 0960/1053
[A[ATraining Step: 658  | total loss: [1m[32m0.38306[0m[0m | time: 36.879s
[2K
| Adam | epoch: 020 | loss: 0.38306 - acc: 0.8376 -- iter: 0992/1053
[A[ATraining Step: 659  | total loss: [1m[32m0.37818[0m[0m | time: 37.849s
[2K
| Adam | epoch: 020 | loss: 0.37818 - acc: 0.8414 -- iter: 1024/1053
[A[ATraining Step: 660  | total loss: [1m[32m0.38079[0m[0m | time: 40.872s
[2K
| Adam | epoch: 020 | loss: 0.38079 - acc: 0.8416 | val_loss: 0.54181 - val_acc: 0.7515 -- iter: 1053/1053
--
Training Step: 661  | total loss: [1m[32m0.38346[0m[0m | time: 1.281s
[2K
| Adam | epoch: 021 | loss: 0.38346 - acc: 0.8356 -- iter: 0032/1053
[A[ATraining Step: 662  | total loss: [1m[32m0.39705[0m[0m | time: 2.451s
[2K
| Adam | epoch: 021 | loss: 0.39705 - acc: 0.8270 -- iter: 0064/1053
[A[ATraining Step: 663  | total loss: [1m[32m0.38963[0m[0m | time: 3.533s
[2K
| Adam | epoch: 021 | loss: 0.38963 - acc: 0.8287 -- iter: 0096/1053
[A[ATraining Step: 664  | total loss: [1m[32m0.37879[0m[0m | time: 4.624s
[2K
| Adam | epoch: 021 | loss: 0.37879 - acc: 0.8364 -- iter: 0128/1053
[A[ATraining Step: 665  | total loss: [1m[32m0.38668[0m[0m | time: 5.845s
[2K
| Adam | epoch: 021 | loss: 0.38668 - acc: 0.8340 -- iter: 0160/1053
[A[ATraining Step: 666  | total loss: [1m[32m0.37659[0m[0m | time: 7.291s
[2K
| Adam | epoch: 021 | loss: 0.37659 - acc: 0.8413 -- iter: 0192/1053
[A[ATraining Step: 667  | total loss: [1m[32m0.38924[0m[0m | time: 8.569s
[2K
| Adam | epoch: 021 | loss: 0.38924 - acc: 0.8353 -- iter: 0224/1053
[A[ATraining Step: 668  | total loss: [1m[32m0.40297[0m[0m | time: 9.565s
[2K
| Adam | epoch: 021 | loss: 0.40297 - acc: 0.8330 -- iter: 0256/1053
[A[ATraining Step: 669  | total loss: [1m[32m0.38870[0m[0m | time: 10.606s
[2K
| Adam | epoch: 021 | loss: 0.38870 - acc: 0.8372 -- iter: 0288/1053
[A[ATraining Step: 670  | total loss: [1m[32m0.38990[0m[0m | time: 11.683s
[2K
| Adam | epoch: 021 | loss: 0.38990 - acc: 0.8347 -- iter: 0320/1053
[A[ATraining Step: 671  | total loss: [1m[32m0.38398[0m[0m | time: 12.746s
[2K
| Adam | epoch: 021 | loss: 0.38398 - acc: 0.8387 -- iter: 0352/1053
[A[ATraining Step: 672  | total loss: [1m[32m0.37146[0m[0m | time: 13.831s
[2K
| Adam | epoch: 021 | loss: 0.37146 - acc: 0.8486 -- iter: 0384/1053
[A[ATraining Step: 673  | total loss: [1m[32m0.36175[0m[0m | time: 15.075s
[2K
| Adam | epoch: 021 | loss: 0.36175 - acc: 0.8606 -- iter: 0416/1053
[A[ATraining Step: 674  | total loss: [1m[32m0.37433[0m[0m | time: 16.285s
[2K
| Adam | epoch: 021 | loss: 0.37433 - acc: 0.8496 -- iter: 0448/1053
[A[ATraining Step: 675  | total loss: [1m[32m0.35689[0m[0m | time: 17.540s
[2K
| Adam | epoch: 021 | loss: 0.35689 - acc: 0.8615 -- iter: 0480/1053
[A[ATraining Step: 676  | total loss: [1m[32m0.34510[0m[0m | time: 18.756s
[2K
| Adam | epoch: 021 | loss: 0.34510 - acc: 0.8660 -- iter: 0512/1053
[A[ATraining Step: 677  | total loss: [1m[32m0.34024[0m[0m | time: 20.150s
[2K
| Adam | epoch: 021 | loss: 0.34024 - acc: 0.8700 -- iter: 0544/1053
[A[ATraining Step: 678  | total loss: [1m[32m0.33702[0m[0m | time: 21.666s
[2K
| Adam | epoch: 021 | loss: 0.33702 - acc: 0.8705 -- iter: 0576/1053
[A[ATraining Step: 679  | total loss: [1m[32m0.35107[0m[0m | time: 22.618s
[2K
| Adam | epoch: 021 | loss: 0.35107 - acc: 0.8584 -- iter: 0608/1053
[A[ATraining Step: 680  | total loss: [1m[32m0.35531[0m[0m | time: 23.597s
[2K
| Adam | epoch: 021 | loss: 0.35531 - acc: 0.8588 -- iter: 0640/1053
[A[ATraining Step: 681  | total loss: [1m[32m0.35728[0m[0m | time: 24.730s
[2K
| Adam | epoch: 021 | loss: 0.35728 - acc: 0.8591 -- iter: 0672/1053
[A[ATraining Step: 682  | total loss: [1m[32m0.40623[0m[0m | time: 25.895s
[2K
| Adam | epoch: 021 | loss: 0.40623 - acc: 0.8357 -- iter: 0704/1053
[A[ATraining Step: 683  | total loss: [1m[32m0.39314[0m[0m | time: 27.048s
[2K
| Adam | epoch: 021 | loss: 0.39314 - acc: 0.8428 -- iter: 0736/1053
[A[ATraining Step: 684  | total loss: [1m[32m0.38598[0m[0m | time: 28.370s
[2K
| Adam | epoch: 021 | loss: 0.38598 - acc: 0.8429 -- iter: 0768/1053
[A[ATraining Step: 685  | total loss: [1m[32m0.39977[0m[0m | time: 29.606s
[2K
| Adam | epoch: 021 | loss: 0.39977 - acc: 0.8336 -- iter: 0800/1053
[A[ATraining Step: 686  | total loss: [1m[32m0.39983[0m[0m | time: 30.592s
[2K
| Adam | epoch: 021 | loss: 0.39983 - acc: 0.8284 -- iter: 0832/1053
[A[ATraining Step: 687  | total loss: [1m[32m0.38551[0m[0m | time: 31.823s
[2K
| Adam | epoch: 021 | loss: 0.38551 - acc: 0.8393 -- iter: 0864/1053
[A[ATraining Step: 688  | total loss: [1m[32m0.38006[0m[0m | time: 33.228s
[2K
| Adam | epoch: 021 | loss: 0.38006 - acc: 0.8428 -- iter: 0896/1053
[A[ATraining Step: 689  | total loss: [1m[32m0.38741[0m[0m | time: 34.642s
[2K
| Adam | epoch: 021 | loss: 0.38741 - acc: 0.8398 -- iter: 0928/1053
[A[ATraining Step: 690  | total loss: [1m[32m0.37480[0m[0m | time: 35.665s
[2K
| Adam | epoch: 021 | loss: 0.37480 - acc: 0.8464 -- iter: 0960/1053
[A[ATraining Step: 691  | total loss: [1m[32m0.36040[0m[0m | time: 36.651s
[2K
| Adam | epoch: 021 | loss: 0.36040 - acc: 0.8524 -- iter: 0992/1053
[A[ATraining Step: 692  | total loss: [1m[32m0.36074[0m[0m | time: 37.724s
[2K
| Adam | epoch: 021 | loss: 0.36074 - acc: 0.8484 -- iter: 1024/1053
[A[ATraining Step: 693  | total loss: [1m[32m0.35662[0m[0m | time: 40.627s
[2K
| Adam | epoch: 021 | loss: 0.35662 - acc: 0.8511 | val_loss: 0.50636 - val_acc: 0.7515 -- iter: 1053/1053
--
Training Step: 694  | total loss: [1m[32m0.35438[0m[0m | time: 1.222s
[2K
| Adam | epoch: 022 | loss: 0.35438 - acc: 0.8566 -- iter: 0032/1053
[A[ATraining Step: 695  | total loss: [1m[32m0.35059[0m[0m | time: 2.354s
[2K
| Adam | epoch: 022 | loss: 0.35059 - acc: 0.8584 -- iter: 0064/1053
[A[ATraining Step: 696  | total loss: [1m[32m0.34901[0m[0m | time: 3.434s
[2K
| Adam | epoch: 022 | loss: 0.34901 - acc: 0.8601 -- iter: 0096/1053
[A[ATraining Step: 697  | total loss: [1m[32m0.35205[0m[0m | time: 4.734s
[2K
| Adam | epoch: 022 | loss: 0.35205 - acc: 0.8616 -- iter: 0128/1053
[A[ATraining Step: 698  | total loss: [1m[32m0.33985[0m[0m | time: 6.186s
[2K
| Adam | epoch: 022 | loss: 0.33985 - acc: 0.8661 -- iter: 0160/1053
[A[ATraining Step: 699  | total loss: [1m[32m0.33945[0m[0m | time: 7.635s
[2K
| Adam | epoch: 022 | loss: 0.33945 - acc: 0.8701 -- iter: 0192/1053
[A[ATraining Step: 700  | total loss: [1m[32m0.35143[0m[0m | time: 8.537s
[2K
| Adam | epoch: 022 | loss: 0.35143 - acc: 0.8643 -- iter: 0224/1053
[A[ATraining Step: 701  | total loss: [1m[32m0.35176[0m[0m | time: 9.568s
[2K
| Adam | epoch: 022 | loss: 0.35176 - acc: 0.8654 -- iter: 0256/1053
[A[ATraining Step: 702  | total loss: [1m[32m0.35031[0m[0m | time: 10.636s
[2K
| Adam | epoch: 022 | loss: 0.35031 - acc: 0.8695 -- iter: 0288/1053
[A[ATraining Step: 703  | total loss: [1m[32m0.35340[0m[0m | time: 11.740s
[2K
| Adam | epoch: 022 | loss: 0.35340 - acc: 0.8607 -- iter: 0320/1053
[A[ATraining Step: 704  | total loss: [1m[32m0.35491[0m[0m | time: 12.798s
[2K
| Adam | epoch: 022 | loss: 0.35491 - acc: 0.8496 -- iter: 0352/1053
[A[ATraining Step: 705  | total loss: [1m[32m0.36099[0m[0m | time: 13.963s
[2K
| Adam | epoch: 022 | loss: 0.36099 - acc: 0.8490 -- iter: 0384/1053
[A[ATraining Step: 706  | total loss: [1m[32m0.36735[0m[0m | time: 15.086s
[2K
| Adam | epoch: 022 | loss: 0.36735 - acc: 0.8422 -- iter: 0416/1053
[A[ATraining Step: 707  | total loss: [1m[32m0.35559[0m[0m | time: 16.172s
[2K
| Adam | epoch: 022 | loss: 0.35559 - acc: 0.8518 -- iter: 0448/1053
[A[ATraining Step: 708  | total loss: [1m[32m0.35453[0m[0m | time: 17.161s
[2K
| Adam | epoch: 022 | loss: 0.35453 - acc: 0.8510 -- iter: 0480/1053
[A[ATraining Step: 709  | total loss: [1m[32m0.35522[0m[0m | time: 18.400s
[2K
| Adam | epoch: 022 | loss: 0.35522 - acc: 0.8502 -- iter: 0512/1053
[A[ATraining Step: 710  | total loss: [1m[32m0.35238[0m[0m | time: 19.698s
[2K
| Adam | epoch: 022 | loss: 0.35238 - acc: 0.8496 -- iter: 0544/1053
[A[ATraining Step: 711  | total loss: [1m[32m0.35534[0m[0m | time: 21.141s
[2K
| Adam | epoch: 022 | loss: 0.35534 - acc: 0.8490 -- iter: 0576/1053
[A[ATraining Step: 712  | total loss: [1m[32m0.34963[0m[0m | time: 22.152s
[2K
| Adam | epoch: 022 | loss: 0.34963 - acc: 0.8547 -- iter: 0608/1053
[A[ATraining Step: 713  | total loss: [1m[32m0.33468[0m[0m | time: 23.093s
[2K
| Adam | epoch: 022 | loss: 0.33468 - acc: 0.8630 -- iter: 0640/1053
[A[ATraining Step: 714  | total loss: [1m[32m0.33403[0m[0m | time: 24.147s
[2K
| Adam | epoch: 022 | loss: 0.33403 - acc: 0.8629 -- iter: 0672/1053
[A[ATraining Step: 715  | total loss: [1m[32m0.33307[0m[0m | time: 25.232s
[2K
| Adam | epoch: 022 | loss: 0.33307 - acc: 0.8594 -- iter: 0704/1053
[A[ATraining Step: 716  | total loss: [1m[32m0.33423[0m[0m | time: 26.337s
[2K
| Adam | epoch: 022 | loss: 0.33423 - acc: 0.8609 -- iter: 0736/1053
[A[ATraining Step: 717  | total loss: [1m[32m0.33251[0m[0m | time: 27.555s
[2K
| Adam | epoch: 022 | loss: 0.33251 - acc: 0.8655 -- iter: 0768/1053
[A[ATraining Step: 718  | total loss: [1m[32m0.32642[0m[0m | time: 28.720s
[2K
| Adam | epoch: 022 | loss: 0.32642 - acc: 0.8695 -- iter: 0800/1053
[A[ATraining Step: 719  | total loss: [1m[32m0.32855[0m[0m | time: 30.158s
[2K
| Adam | epoch: 022 | loss: 0.32855 - acc: 0.8576 -- iter: 0832/1053
[A[ATraining Step: 720  | total loss: [1m[32m0.32384[0m[0m | time: 31.399s
[2K
| Adam | epoch: 022 | loss: 0.32384 - acc: 0.8625 -- iter: 0864/1053
[A[ATraining Step: 721  | total loss: [1m[32m0.32453[0m[0m | time: 32.790s
[2K
| Adam | epoch: 022 | loss: 0.32453 - acc: 0.8606 -- iter: 0896/1053
[A[ATraining Step: 722  | total loss: [1m[32m0.31873[0m[0m | time: 34.234s
[2K
| Adam | epoch: 022 | loss: 0.31873 - acc: 0.8652 -- iter: 0928/1053
[A[ATraining Step: 723  | total loss: [1m[32m0.30910[0m[0m | time: 35.402s
[2K
| Adam | epoch: 022 | loss: 0.30910 - acc: 0.8724 -- iter: 0960/1053
[A[ATraining Step: 724  | total loss: [1m[32m0.32199[0m[0m | time: 36.322s
[2K
| Adam | epoch: 022 | loss: 0.32199 - acc: 0.8664 -- iter: 0992/1053
[A[ATraining Step: 725  | total loss: [1m[32m0.32121[0m[0m | time: 37.425s
[2K
| Adam | epoch: 022 | loss: 0.32121 - acc: 0.8673 -- iter: 1024/1053
[A[ATraining Step: 726  | total loss: [1m[32m0.31317[0m[0m | time: 40.223s
[2K
| Adam | epoch: 022 | loss: 0.31317 - acc: 0.8743 | val_loss: 0.49333 - val_acc: 0.7727 -- iter: 1053/1053
--
Training Step: 727  | total loss: [1m[32m0.31174[0m[0m | time: 1.249s
[2K
| Adam | epoch: 023 | loss: 0.31174 - acc: 0.8744 -- iter: 0032/1053
[A[ATraining Step: 728  | total loss: [1m[32m0.31512[0m[0m | time: 2.218s
[2K
| Adam | epoch: 023 | loss: 0.31512 - acc: 0.8744 -- iter: 0064/1053
[A[ATraining Step: 729  | total loss: [1m[32m0.30754[0m[0m | time: 3.405s
[2K
| Adam | epoch: 023 | loss: 0.30754 - acc: 0.8776 -- iter: 0096/1053
[A[ATraining Step: 730  | total loss: [1m[32m0.31691[0m[0m | time: 4.724s
[2K
| Adam | epoch: 023 | loss: 0.31691 - acc: 0.8773 -- iter: 0128/1053
[A[ATraining Step: 731  | total loss: [1m[32m0.32179[0m[0m | time: 6.085s
[2K
| Adam | epoch: 023 | loss: 0.32179 - acc: 0.8740 -- iter: 0160/1053
[A[ATraining Step: 732  | total loss: [1m[32m0.34855[0m[0m | time: 7.202s
[2K
| Adam | epoch: 023 | loss: 0.34855 - acc: 0.8553 -- iter: 0192/1053
[A[ATraining Step: 733  | total loss: [1m[32m0.34449[0m[0m | time: 8.279s
[2K
| Adam | epoch: 023 | loss: 0.34449 - acc: 0.8573 -- iter: 0224/1053
[A[ATraining Step: 734  | total loss: [1m[32m0.33818[0m[0m | time: 9.378s
[2K
| Adam | epoch: 023 | loss: 0.33818 - acc: 0.8653 -- iter: 0256/1053
[A[ATraining Step: 735  | total loss: [1m[32m0.34185[0m[0m | time: 10.486s
[2K
| Adam | epoch: 023 | loss: 0.34185 - acc: 0.8569 -- iter: 0288/1053
[A[ATraining Step: 736  | total loss: [1m[32m0.34109[0m[0m | time: 11.616s
[2K
| Adam | epoch: 023 | loss: 0.34109 - acc: 0.8525 -- iter: 0320/1053
[A[ATraining Step: 737  | total loss: [1m[32m0.33021[0m[0m | time: 12.829s
[2K
| Adam | epoch: 023 | loss: 0.33021 - acc: 0.8547 -- iter: 0352/1053
[A[ATraining Step: 738  | total loss: [1m[32m0.33500[0m[0m | time: 14.053s
[2K
| Adam | epoch: 023 | loss: 0.33500 - acc: 0.8505 -- iter: 0384/1053
[A[ATraining Step: 739  | total loss: [1m[32m0.32663[0m[0m | time: 15.058s
[2K
| Adam | epoch: 023 | loss: 0.32663 - acc: 0.8561 -- iter: 0416/1053
[A[ATraining Step: 740  | total loss: [1m[32m0.33361[0m[0m | time: 16.164s
[2K
| Adam | epoch: 023 | loss: 0.33361 - acc: 0.8517 -- iter: 0448/1053
[A[ATraining Step: 741  | total loss: [1m[32m0.33762[0m[0m | time: 17.617s
[2K
| Adam | epoch: 023 | loss: 0.33762 - acc: 0.8509 -- iter: 0480/1053
[A[ATraining Step: 742  | total loss: [1m[32m0.33091[0m[0m | time: 18.955s
[2K
| Adam | epoch: 023 | loss: 0.33091 - acc: 0.8565 -- iter: 0512/1053
[A[ATraining Step: 743  | total loss: [1m[32m0.32871[0m[0m | time: 20.296s
[2K
| Adam | epoch: 023 | loss: 0.32871 - acc: 0.8552 -- iter: 0544/1053
[A[ATraining Step: 744  | total loss: [1m[32m0.32722[0m[0m | time: 21.275s
[2K
| Adam | epoch: 023 | loss: 0.32722 - acc: 0.8603 -- iter: 0576/1053
[A[ATraining Step: 745  | total loss: [1m[32m0.32209[0m[0m | time: 22.350s
[2K
| Adam | epoch: 023 | loss: 0.32209 - acc: 0.8618 -- iter: 0608/1053
[A[ATraining Step: 746  | total loss: [1m[32m0.31929[0m[0m | time: 23.413s
[2K
| Adam | epoch: 023 | loss: 0.31929 - acc: 0.8631 -- iter: 0640/1053
[A[ATraining Step: 747  | total loss: [1m[32m0.32187[0m[0m | time: 24.364s
[2K
| Adam | epoch: 023 | loss: 0.32187 - acc: 0.8612 -- iter: 0672/1053
[A[ATraining Step: 748  | total loss: [1m[32m0.32056[0m[0m | time: 25.453s
[2K
| Adam | epoch: 023 | loss: 0.32056 - acc: 0.8612 -- iter: 0704/1053
[A[ATraining Step: 749  | total loss: [1m[32m0.31766[0m[0m | time: 26.718s
[2K
| Adam | epoch: 023 | loss: 0.31766 - acc: 0.8613 -- iter: 0736/1053
[A[ATraining Step: 750  | total loss: [1m[32m0.30896[0m[0m | time: 27.848s
[2K
| Adam | epoch: 023 | loss: 0.30896 - acc: 0.8658 -- iter: 0768/1053
[A[ATraining Step: 751  | total loss: [1m[32m0.30449[0m[0m | time: 28.805s
[2K
| Adam | epoch: 023 | loss: 0.30449 - acc: 0.8730 -- iter: 0800/1053
[A[ATraining Step: 752  | total loss: [1m[32m0.30209[0m[0m | time: 30.020s
[2K
| Adam | epoch: 023 | loss: 0.30209 - acc: 0.8763 -- iter: 0832/1053
[A[ATraining Step: 753  | total loss: [1m[32m0.29811[0m[0m | time: 31.562s
[2K
| Adam | epoch: 023 | loss: 0.29811 - acc: 0.8824 -- iter: 0864/1053
[A[ATraining Step: 754  | total loss: [1m[32m0.31631[0m[0m | time: 32.990s
[2K
| Adam | epoch: 023 | loss: 0.31631 - acc: 0.8754 -- iter: 0896/1053
[A[ATraining Step: 755  | total loss: [1m[32m0.30557[0m[0m | time: 34.026s
[2K
| Adam | epoch: 023 | loss: 0.30557 - acc: 0.8785 -- iter: 0928/1053
[A[ATraining Step: 756  | total loss: [1m[32m0.30994[0m[0m | time: 34.999s
[2K
| Adam | epoch: 023 | loss: 0.30994 - acc: 0.8750 -- iter: 0960/1053
[A[ATraining Step: 757  | total loss: [1m[32m0.30753[0m[0m | time: 36.077s
[2K
| Adam | epoch: 023 | loss: 0.30753 - acc: 0.8750 -- iter: 0992/1053
[A[ATraining Step: 758  | total loss: [1m[32m0.30404[0m[0m | time: 37.143s
[2K
| Adam | epoch: 023 | loss: 0.30404 - acc: 0.8750 -- iter: 1024/1053
[A[ATraining Step: 759  | total loss: [1m[32m0.30842[0m[0m | time: 40.259s
[2K
| Adam | epoch: 023 | loss: 0.30842 - acc: 0.8750 | val_loss: 0.49342 - val_acc: 0.7727 -- iter: 1053/1053
--
Training Step: 760  | total loss: [1m[32m0.29982[0m[0m | time: 1.194s
[2K
| Adam | epoch: 024 | loss: 0.29982 - acc: 0.8813 -- iter: 0032/1053
[A[ATraining Step: 761  | total loss: [1m[32m0.28661[0m[0m | time: 2.414s
[2K
| Adam | epoch: 024 | loss: 0.28661 - acc: 0.8869 -- iter: 0064/1053
[A[ATraining Step: 762  | total loss: [1m[32m0.29894[0m[0m | time: 3.715s
[2K
| Adam | epoch: 024 | loss: 0.29894 - acc: 0.8857 -- iter: 0096/1053
[A[ATraining Step: 763  | total loss: [1m[32m0.30008[0m[0m | time: 5.082s
[2K
| Adam | epoch: 024 | loss: 0.30008 - acc: 0.8878 -- iter: 0128/1053
[A[ATraining Step: 764  | total loss: [1m[32m0.32124[0m[0m | time: 6.575s
[2K
| Adam | epoch: 024 | loss: 0.32124 - acc: 0.8709 -- iter: 0160/1053
[A[ATraining Step: 765  | total loss: [1m[32m0.30464[0m[0m | time: 7.446s
[2K
| Adam | epoch: 024 | loss: 0.30464 - acc: 0.8807 -- iter: 0192/1053
[A[ATraining Step: 766  | total loss: [1m[32m0.31492[0m[0m | time: 8.479s
[2K
| Adam | epoch: 024 | loss: 0.31492 - acc: 0.8770 -- iter: 0224/1053
[A[ATraining Step: 767  | total loss: [1m[32m0.31895[0m[0m | time: 9.543s
[2K
| Adam | epoch: 024 | loss: 0.31895 - acc: 0.8768 -- iter: 0256/1053
[A[ATraining Step: 768  | total loss: [1m[32m0.31154[0m[0m | time: 10.636s
[2K
| Adam | epoch: 024 | loss: 0.31154 - acc: 0.8766 -- iter: 0288/1053
[A[ATraining Step: 769  | total loss: [1m[32m0.31033[0m[0m | time: 11.777s
[2K
| Adam | epoch: 024 | loss: 0.31033 - acc: 0.8764 -- iter: 0320/1053
[A[ATraining Step: 770  | total loss: [1m[32m0.30290[0m[0m | time: 13.019s
[2K
| Adam | epoch: 024 | loss: 0.30290 - acc: 0.8794 -- iter: 0352/1053
[A[ATraining Step: 771  | total loss: [1m[32m0.30244[0m[0m | time: 14.237s
[2K
| Adam | epoch: 024 | loss: 0.30244 - acc: 0.8790 -- iter: 0384/1053
[A[ATraining Step: 772  | total loss: [1m[32m0.30245[0m[0m | time: 15.214s
[2K
| Adam | epoch: 024 | loss: 0.30245 - acc: 0.8817 -- iter: 0416/1053
[A[ATraining Step: 773  | total loss: [1m[32m0.29452[0m[0m | time: 16.302s
[2K
| Adam | epoch: 024 | loss: 0.29452 - acc: 0.8904 -- iter: 0448/1053
[A[ATraining Step: 774  | total loss: [1m[32m0.29502[0m[0m | time: 17.889s
[2K
| Adam | epoch: 024 | loss: 0.29502 - acc: 0.8920 -- iter: 0480/1053
[A[ATraining Step: 775  | total loss: [1m[32m0.29048[0m[0m | time: 19.449s
[2K
| Adam | epoch: 024 | loss: 0.29048 - acc: 0.8934 -- iter: 0512/1053
[A[ATraining Step: 776  | total loss: [1m[32m0.28285[0m[0m | time: 20.486s
[2K
| Adam | epoch: 024 | loss: 0.28285 - acc: 0.8947 -- iter: 0544/1053
[A[ATraining Step: 777  | total loss: [1m[32m0.27334[0m[0m | time: 21.623s
[2K
| Adam | epoch: 024 | loss: 0.27334 - acc: 0.9021 -- iter: 0576/1053
[A[ATraining Step: 778  | total loss: [1m[32m0.27589[0m[0m | time: 22.785s
[2K
| Adam | epoch: 024 | loss: 0.27589 - acc: 0.9025 -- iter: 0608/1053
[A[ATraining Step: 779  | total loss: [1m[32m0.28900[0m[0m | time: 23.861s
[2K
| Adam | epoch: 024 | loss: 0.28900 - acc: 0.8966 -- iter: 0640/1053
[A[ATraining Step: 780  | total loss: [1m[32m0.28160[0m[0m | time: 25.116s
[2K
| Adam | epoch: 024 | loss: 0.28160 - acc: 0.9007 -- iter: 0672/1053
[A[ATraining Step: 781  | total loss: [1m[32m0.27790[0m[0m | time: 26.293s
[2K
| Adam | epoch: 024 | loss: 0.27790 - acc: 0.8982 -- iter: 0704/1053
[A[ATraining Step: 782  | total loss: [1m[32m0.27254[0m[0m | time: 27.400s
[2K
| Adam | epoch: 024 | loss: 0.27254 - acc: 0.8980 -- iter: 0736/1053
[A[ATraining Step: 783  | total loss: [1m[32m0.26293[0m[0m | time: 28.536s
[2K
| Adam | epoch: 024 | loss: 0.26293 - acc: 0.9013 -- iter: 0768/1053
[A[ATraining Step: 784  | total loss: [1m[32m0.25625[0m[0m | time: 29.946s
[2K
| Adam | epoch: 024 | loss: 0.25625 - acc: 0.9049 -- iter: 0800/1053
[A[ATraining Step: 785  | total loss: [1m[32m0.27119[0m[0m | time: 31.294s
[2K
| Adam | epoch: 024 | loss: 0.27119 - acc: 0.8957 -- iter: 0832/1053
[A[ATraining Step: 786  | total loss: [1m[32m0.29826[0m[0m | time: 32.579s
[2K
| Adam | epoch: 024 | loss: 0.29826 - acc: 0.8905 -- iter: 0864/1053
[A[ATraining Step: 787  | total loss: [1m[32m0.29018[0m[0m | time: 33.632s
[2K
| Adam | epoch: 024 | loss: 0.29018 - acc: 0.8921 -- iter: 0896/1053
[A[ATraining Step: 788  | total loss: [1m[32m0.29528[0m[0m | time: 34.804s
[2K
| Adam | epoch: 024 | loss: 0.29528 - acc: 0.8872 -- iter: 0928/1053
[A[ATraining Step: 789  | total loss: [1m[32m0.30591[0m[0m | time: 35.957s
[2K
| Adam | epoch: 024 | loss: 0.30591 - acc: 0.8798 -- iter: 0960/1053
[A[ATraining Step: 790  | total loss: [1m[32m0.29865[0m[0m | time: 37.021s
[2K
| Adam | epoch: 024 | loss: 0.29865 - acc: 0.8824 -- iter: 0992/1053
[A[ATraining Step: 791  | total loss: [1m[32m0.29595[0m[0m | time: 38.152s
[2K
| Adam | epoch: 024 | loss: 0.29595 - acc: 0.8848 -- iter: 1024/1053
[A[ATraining Step: 792  | total loss: [1m[32m0.29161[0m[0m | time: 41.288s
[2K
| Adam | epoch: 024 | loss: 0.29161 - acc: 0.8901 | val_loss: 0.49500 - val_acc: 0.7758 -- iter: 1053/1053
--
Training Step: 793  | total loss: [1m[32m0.28836[0m[0m | time: 1.419s
[2K
| Adam | epoch: 025 | loss: 0.28836 - acc: 0.8917 -- iter: 0032/1053
[A[ATraining Step: 794  | total loss: [1m[32m0.27997[0m[0m | time: 2.828s
[2K
| Adam | epoch: 025 | loss: 0.27997 - acc: 0.8931 -- iter: 0064/1053
[A[ATraining Step: 795  | total loss: [1m[32m0.27313[0m[0m | time: 3.803s
[2K
| Adam | epoch: 025 | loss: 0.27313 - acc: 0.9007 -- iter: 0096/1053
[A[ATraining Step: 796  | total loss: [1m[32m0.25946[0m[0m | time: 4.836s
[2K
| Adam | epoch: 025 | loss: 0.25946 - acc: 0.9075 -- iter: 0128/1053
[A[ATraining Step: 797  | total loss: [1m[32m0.25618[0m[0m | time: 5.931s
[2K
| Adam | epoch: 025 | loss: 0.25618 - acc: 0.9074 -- iter: 0160/1053
[A[ATraining Step: 798  | total loss: [1m[32m0.26087[0m[0m | time: 7.041s
[2K
| Adam | epoch: 025 | loss: 0.26087 - acc: 0.9041 -- iter: 0192/1053
[A[ATraining Step: 799  | total loss: [1m[32m0.26147[0m[0m | time: 8.152s
[2K
| Adam | epoch: 025 | loss: 0.26147 - acc: 0.8950 -- iter: 0224/1053
[A[ATraining Step: 800  | total loss: [1m[32m0.27553[0m[0m | time: 11.324s
[2K
| Adam | epoch: 025 | loss: 0.27553 - acc: 0.8899 | val_loss: 0.52230 - val_acc: 0.7727 -- iter: 0256/1053
--
Training Step: 801  | total loss: [1m[32m0.27674[0m[0m | time: 12.403s
[2K
| Adam | epoch: 025 | loss: 0.27674 - acc: 0.8915 -- iter: 0288/1053
[A[ATraining Step: 802  | total loss: [1m[32m0.28691[0m[0m | time: 13.716s
[2K
| Adam | epoch: 025 | loss: 0.28691 - acc: 0.8773 -- iter: 0320/1053
[A[ATraining Step: 803  | total loss: [1m[32m0.28361[0m[0m | time: 15.294s
[2K
| Adam | epoch: 025 | loss: 0.28361 - acc: 0.8802 -- iter: 0352/1053
[A[ATraining Step: 804  | total loss: [1m[32m0.27852[0m[0m | time: 16.804s
[2K
| Adam | epoch: 025 | loss: 0.27852 - acc: 0.8860 -- iter: 0384/1053
[A[ATraining Step: 805  | total loss: [1m[32m0.28047[0m[0m | time: 17.754s
[2K
| Adam | epoch: 025 | loss: 0.28047 - acc: 0.8786 -- iter: 0416/1053
[A[ATraining Step: 806  | total loss: [1m[32m0.27117[0m[0m | time: 18.793s
[2K
| Adam | epoch: 025 | loss: 0.27117 - acc: 0.8908 -- iter: 0448/1053
[A[ATraining Step: 807  | total loss: [1m[32m0.25927[0m[0m | time: 19.975s
[2K
| Adam | epoch: 025 | loss: 0.25927 - acc: 0.9017 -- iter: 0480/1053
[A[ATraining Step: 808  | total loss: [1m[32m0.26054[0m[0m | time: 21.082s
[2K
| Adam | epoch: 025 | loss: 0.26054 - acc: 0.9021 -- iter: 0512/1053
[A[ATraining Step: 809  | total loss: [1m[32m0.29722[0m[0m | time: 22.128s
[2K
| Adam | epoch: 025 | loss: 0.29722 - acc: 0.8932 -- iter: 0544/1053
[A[ATraining Step: 810  | total loss: [1m[32m0.30325[0m[0m | time: 23.346s
[2K
| Adam | epoch: 025 | loss: 0.30325 - acc: 0.8851 -- iter: 0576/1053
[A[ATraining Step: 811  | total loss: [1m[32m0.31059[0m[0m | time: 24.531s
[2K
| Adam | epoch: 025 | loss: 0.31059 - acc: 0.8810 -- iter: 0608/1053
[A[ATraining Step: 812  | total loss: [1m[32m0.29261[0m[0m | time: 25.582s
[2K
| Adam | epoch: 025 | loss: 0.29261 - acc: 0.8897 -- iter: 0640/1053
[A[ATraining Step: 813  | total loss: [1m[32m0.29250[0m[0m | time: 26.963s
[2K
| Adam | epoch: 025 | loss: 0.29250 - acc: 0.8883 -- iter: 0672/1053
[A[ATraining Step: 814  | total loss: [1m[32m0.30418[0m[0m | time: 28.321s
[2K
| Adam | epoch: 025 | loss: 0.30418 - acc: 0.8838 -- iter: 0704/1053
[A[ATraining Step: 815  | total loss: [1m[32m0.31675[0m[0m | time: 29.776s
[2K
| Adam | epoch: 025 | loss: 0.31675 - acc: 0.8736 -- iter: 0736/1053
[A[ATraining Step: 816  | total loss: [1m[32m0.35151[0m[0m | time: 30.703s
[2K
| Adam | epoch: 025 | loss: 0.35151 - acc: 0.8586 -- iter: 0768/1053
[A[ATraining Step: 817  | total loss: [1m[32m0.37826[0m[0m | time: 31.717s
[2K
| Adam | epoch: 025 | loss: 0.37826 - acc: 0.8452 -- iter: 0800/1053
[A[ATraining Step: 818  | total loss: [1m[32m0.36894[0m[0m | time: 32.771s
[2K
| Adam | epoch: 025 | loss: 0.36894 - acc: 0.8419 -- iter: 0832/1053
[A[ATraining Step: 819  | total loss: [1m[32m0.35615[0m[0m | time: 34.155s
[2K
| Adam | epoch: 025 | loss: 0.35615 - acc: 0.8452 -- iter: 0864/1053
[A[ATraining Step: 820  | total loss: [1m[32m0.34085[0m[0m | time: 35.496s
[2K
| Adam | epoch: 025 | loss: 0.34085 - acc: 0.8576 -- iter: 0896/1053
[A[ATraining Step: 821  | total loss: [1m[32m0.33462[0m[0m | time: 36.695s
[2K
| Adam | epoch: 025 | loss: 0.33462 - acc: 0.8624 -- iter: 0928/1053
[A[ATraining Step: 822  | total loss: [1m[32m0.34336[0m[0m | time: 38.048s
[2K
| Adam | epoch: 025 | loss: 0.34336 - acc: 0.8606 -- iter: 0960/1053
[A[ATraining Step: 823  | total loss: [1m[32m0.36168[0m[0m | time: 39.099s
[2K
| Adam | epoch: 025 | loss: 0.36168 - acc: 0.8526 -- iter: 0992/1053
[A[ATraining Step: 824  | total loss: [1m[32m0.35273[0m[0m | time: 40.245s
[2K
| Adam | epoch: 025 | loss: 0.35273 - acc: 0.8611 -- iter: 1024/1053
[A[ATraining Step: 825  | total loss: [1m[32m0.34474[0m[0m | time: 44.167s
[2K
| Adam | epoch: 025 | loss: 0.34474 - acc: 0.8656 | val_loss: 0.52110 - val_acc: 0.7667 -- iter: 1053/1053
--
Training Step: 826  | total loss: [1m[32m0.34290[0m[0m | time: 1.094s
[2K
| Adam | epoch: 026 | loss: 0.34290 - acc: 0.8666 -- iter: 0032/1053
[A[ATraining Step: 827  | total loss: [1m[32m0.35278[0m[0m | time: 2.171s
[2K
| Adam | epoch: 026 | loss: 0.35278 - acc: 0.8580 -- iter: 0064/1053
[A[ATraining Step: 828  | total loss: [1m[32m0.35397[0m[0m | time: 3.270s
[2K
| Adam | epoch: 026 | loss: 0.35397 - acc: 0.8566 -- iter: 0096/1053
[A[ATraining Step: 829  | total loss: [1m[32m0.36336[0m[0m | time: 4.367s
[2K
| Adam | epoch: 026 | loss: 0.36336 - acc: 0.8553 -- iter: 0128/1053
[A[ATraining Step: 830  | total loss: [1m[32m0.34590[0m[0m | time: 5.528s
[2K
| Adam | epoch: 026 | loss: 0.34590 - acc: 0.8667 -- iter: 0160/1053
[A[ATraining Step: 831  | total loss: [1m[32m0.33549[0m[0m | time: 6.757s
[2K
| Adam | epoch: 026 | loss: 0.33549 - acc: 0.8769 -- iter: 0192/1053
[A[ATraining Step: 832  | total loss: [1m[32m0.31890[0m[0m | time: 7.758s
[2K
| Adam | epoch: 026 | loss: 0.31890 - acc: 0.8861 -- iter: 0224/1053
[A[ATraining Step: 833  | total loss: [1m[32m0.30649[0m[0m | time: 8.938s
[2K
| Adam | epoch: 026 | loss: 0.30649 - acc: 0.8943 -- iter: 0256/1053
[A[ATraining Step: 834  | total loss: [1m[32m0.30292[0m[0m | time: 10.272s
[2K
| Adam | epoch: 026 | loss: 0.30292 - acc: 0.8924 -- iter: 0288/1053
[A[ATraining Step: 835  | total loss: [1m[32m0.31613[0m[0m | time: 11.756s
[2K
| Adam | epoch: 026 | loss: 0.31613 - acc: 0.8844 -- iter: 0320/1053
[A[ATraining Step: 836  | total loss: [1m[32m0.30833[0m[0m | time: 12.943s
[2K
| Adam | epoch: 026 | loss: 0.30833 - acc: 0.8866 -- iter: 0352/1053
[A[ATraining Step: 837  | total loss: [1m[32m0.31055[0m[0m | time: 13.895s
[2K
| Adam | epoch: 026 | loss: 0.31055 - acc: 0.8823 -- iter: 0384/1053
[A[ATraining Step: 838  | total loss: [1m[32m0.29954[0m[0m | time: 14.959s
[2K
| Adam | epoch: 026 | loss: 0.29954 - acc: 0.8878 -- iter: 0416/1053
[A[ATraining Step: 839  | total loss: [1m[32m0.30047[0m[0m | time: 16.057s
[2K
| Adam | epoch: 026 | loss: 0.30047 - acc: 0.8865 -- iter: 0448/1053
[A[ATraining Step: 840  | total loss: [1m[32m0.30919[0m[0m | time: 17.132s
[2K
| Adam | epoch: 026 | loss: 0.30919 - acc: 0.8760 -- iter: 0480/1053
[A[ATraining Step: 841  | total loss: [1m[32m0.31961[0m[0m | time: 18.348s
[2K
| Adam | epoch: 026 | loss: 0.31961 - acc: 0.8759 -- iter: 0512/1053
[A[ATraining Step: 842  | total loss: [1m[32m0.31796[0m[0m | time: 19.580s
[2K
| Adam | epoch: 026 | loss: 0.31796 - acc: 0.8821 -- iter: 0544/1053
[A[ATraining Step: 843  | total loss: [1m[32m0.30718[0m[0m | time: 20.726s
[2K
| Adam | epoch: 026 | loss: 0.30718 - acc: 0.8876 -- iter: 0576/1053
[A[ATraining Step: 844  | total loss: [1m[32m0.29422[0m[0m | time: 21.851s
[2K
| Adam | epoch: 026 | loss: 0.29422 - acc: 0.8989 -- iter: 0608/1053
[A[ATraining Step: 845  | total loss: [1m[32m0.28880[0m[0m | time: 23.174s
[2K
| Adam | epoch: 026 | loss: 0.28880 - acc: 0.9027 -- iter: 0640/1053
[A[ATraining Step: 846  | total loss: [1m[32m0.28295[0m[0m | time: 24.689s
[2K
| Adam | epoch: 026 | loss: 0.28295 - acc: 0.9062 -- iter: 0672/1053
[A[ATraining Step: 847  | total loss: [1m[32m0.27935[0m[0m | time: 25.856s
[2K
| Adam | epoch: 026 | loss: 0.27935 - acc: 0.9031 -- iter: 0704/1053
[A[ATraining Step: 848  | total loss: [1m[32m0.26533[0m[0m | time: 27.012s
[2K
| Adam | epoch: 026 | loss: 0.26533 - acc: 0.9065 -- iter: 0736/1053
[A[ATraining Step: 849  | total loss: [1m[32m0.26269[0m[0m | time: 28.389s
[2K
| Adam | epoch: 026 | loss: 0.26269 - acc: 0.9065 -- iter: 0768/1053
[A[ATraining Step: 850  | total loss: [1m[32m0.25381[0m[0m | time: 29.338s
[2K
| Adam | epoch: 026 | loss: 0.25381 - acc: 0.9124 -- iter: 0800/1053
[A[ATraining Step: 851  | total loss: [1m[32m0.24594[0m[0m | time: 30.461s
[2K
| Adam | epoch: 026 | loss: 0.24594 - acc: 0.9177 -- iter: 0832/1053
[A[ATraining Step: 852  | total loss: [1m[32m0.26365[0m[0m | time: 31.618s
[2K
| Adam | epoch: 026 | loss: 0.26365 - acc: 0.9072 -- iter: 0864/1053
[A[ATraining Step: 853  | total loss: [1m[32m0.26108[0m[0m | time: 32.883s
[2K
| Adam | epoch: 026 | loss: 0.26108 - acc: 0.9071 -- iter: 0896/1053
[A[ATraining Step: 854  | total loss: [1m[32m0.25255[0m[0m | time: 34.077s
[2K
| Adam | epoch: 026 | loss: 0.25255 - acc: 0.9101 -- iter: 0928/1053
[A[ATraining Step: 855  | total loss: [1m[32m0.26938[0m[0m | time: 35.056s
[2K
| Adam | epoch: 026 | loss: 0.26938 - acc: 0.9035 -- iter: 0960/1053
[A[ATraining Step: 856  | total loss: [1m[32m0.26462[0m[0m | time: 36.309s
[2K
| Adam | epoch: 026 | loss: 0.26462 - acc: 0.9038 -- iter: 0992/1053
[A[ATraining Step: 857  | total loss: [1m[32m0.26182[0m[0m | time: 37.713s
[2K
| Adam | epoch: 026 | loss: 0.26182 - acc: 0.9040 -- iter: 1024/1053
[A[ATraining Step: 858  | total loss: [1m[32m0.26967[0m[0m | time: 40.846s
[2K
| Adam | epoch: 026 | loss: 0.26967 - acc: 0.9011 | val_loss: 0.52774 - val_acc: 0.7727 -- iter: 1053/1053
--
Training Step: 859  | total loss: [1m[32m0.25882[0m[0m | time: 1.149s
[2K
| Adam | epoch: 027 | loss: 0.25882 - acc: 0.9048 -- iter: 0032/1053
[A[ATraining Step: 860  | total loss: [1m[32m0.26186[0m[0m | time: 2.165s
[2K
| Adam | epoch: 027 | loss: 0.26186 - acc: 0.8987 -- iter: 0064/1053
[A[ATraining Step: 861  | total loss: [1m[32m0.24118[0m[0m | time: 3.335s
[2K
| Adam | epoch: 027 | loss: 0.24118 - acc: 0.9088 -- iter: 0096/1053
[A[ATraining Step: 862  | total loss: [1m[32m0.24218[0m[0m | time: 4.495s
[2K
| Adam | epoch: 027 | loss: 0.24218 - acc: 0.9023 -- iter: 0128/1053
[A[ATraining Step: 863  | total loss: [1m[32m0.24613[0m[0m | time: 5.685s
[2K
| Adam | epoch: 027 | loss: 0.24613 - acc: 0.9058 -- iter: 0160/1053
[A[ATraining Step: 864  | total loss: [1m[32m0.24411[0m[0m | time: 6.631s
[2K
| Adam | epoch: 027 | loss: 0.24411 - acc: 0.9059 -- iter: 0192/1053
[A[ATraining Step: 865  | total loss: [1m[32m0.24366[0m[0m | time: 7.879s
[2K
| Adam | epoch: 027 | loss: 0.24366 - acc: 0.9059 -- iter: 0224/1053
[A[ATraining Step: 866  | total loss: [1m[32m0.23944[0m[0m | time: 9.195s
[2K
| Adam | epoch: 027 | loss: 0.23944 - acc: 0.9122 -- iter: 0256/1053
[A[ATraining Step: 867  | total loss: [1m[32m0.23438[0m[0m | time: 10.571s
[2K
| Adam | epoch: 027 | loss: 0.23438 - acc: 0.9116 -- iter: 0288/1053
[A[ATraining Step: 868  | total loss: [1m[32m0.24219[0m[0m | time: 11.678s
[2K
| Adam | epoch: 027 | loss: 0.24219 - acc: 0.9079 -- iter: 0320/1053
[A[ATraining Step: 869  | total loss: [1m[32m0.22965[0m[0m | time: 12.665s
[2K
| Adam | epoch: 027 | loss: 0.22965 - acc: 0.9171 -- iter: 0352/1053
[A[ATraining Step: 870  | total loss: [1m[32m0.23962[0m[0m | time: 13.722s
[2K
| Adam | epoch: 027 | loss: 0.23962 - acc: 0.9129 -- iter: 0384/1053
[A[ATraining Step: 871  | total loss: [1m[32m0.24285[0m[0m | time: 14.809s
[2K
| Adam | epoch: 027 | loss: 0.24285 - acc: 0.9091 -- iter: 0416/1053
[A[ATraining Step: 872  | total loss: [1m[32m0.24326[0m[0m | time: 15.882s
[2K
| Adam | epoch: 027 | loss: 0.24326 - acc: 0.9120 -- iter: 0448/1053
[A[ATraining Step: 873  | total loss: [1m[32m0.23756[0m[0m | time: 17.134s
[2K
| Adam | epoch: 027 | loss: 0.23756 - acc: 0.9176 -- iter: 0480/1053
[A[ATraining Step: 874  | total loss: [1m[32m0.22776[0m[0m | time: 18.383s
[2K
| Adam | epoch: 027 | loss: 0.22776 - acc: 0.9228 -- iter: 0512/1053
[A[ATraining Step: 875  | total loss: [1m[32m0.22356[0m[0m | time: 19.394s
[2K
| Adam | epoch: 027 | loss: 0.22356 - acc: 0.9242 -- iter: 0544/1053
[A[ATraining Step: 876  | total loss: [1m[32m0.21421[0m[0m | time: 20.512s
[2K
| Adam | epoch: 027 | loss: 0.21421 - acc: 0.9318 -- iter: 0576/1053
[A[ATraining Step: 877  | total loss: [1m[32m0.22454[0m[0m | time: 21.770s
[2K
| Adam | epoch: 027 | loss: 0.22454 - acc: 0.9293 -- iter: 0608/1053
[A[ATraining Step: 878  | total loss: [1m[32m0.22143[0m[0m | time: 23.193s
[2K
| Adam | epoch: 027 | loss: 0.22143 - acc: 0.9270 -- iter: 0640/1053
[A[ATraining Step: 879  | total loss: [1m[32m0.22142[0m[0m | time: 24.372s
[2K
| Adam | epoch: 027 | loss: 0.22142 - acc: 0.9280 -- iter: 0672/1053
[A[ATraining Step: 880  | total loss: [1m[32m0.21884[0m[0m | time: 25.416s
[2K
| Adam | epoch: 027 | loss: 0.21884 - acc: 0.9258 -- iter: 0704/1053
[A[ATraining Step: 881  | total loss: [1m[32m0.22459[0m[0m | time: 26.464s
[2K
| Adam | epoch: 027 | loss: 0.22459 - acc: 0.9207 -- iter: 0736/1053
[A[ATraining Step: 882  | total loss: [1m[32m0.22806[0m[0m | time: 27.478s
[2K
| Adam | epoch: 027 | loss: 0.22806 - acc: 0.9224 -- iter: 0768/1053
[A[ATraining Step: 883  | total loss: [1m[32m0.23678[0m[0m | time: 28.465s
[2K
| Adam | epoch: 027 | loss: 0.23678 - acc: 0.9208 -- iter: 0800/1053
[A[ATraining Step: 884  | total loss: [1m[32m0.23214[0m[0m | time: 29.544s
[2K
| Adam | epoch: 027 | loss: 0.23214 - acc: 0.9253 -- iter: 0832/1053
[A[ATraining Step: 885  | total loss: [1m[32m0.22603[0m[0m | time: 30.679s
[2K
| Adam | epoch: 027 | loss: 0.22603 - acc: 0.9293 -- iter: 0864/1053
[A[ATraining Step: 886  | total loss: [1m[32m0.26715[0m[0m | time: 31.852s
[2K
| Adam | epoch: 027 | loss: 0.26715 - acc: 0.9114 -- iter: 0896/1053
[A[ATraining Step: 887  | total loss: [1m[32m0.25600[0m[0m | time: 32.815s
[2K
| Adam | epoch: 027 | loss: 0.25600 - acc: 0.9171 -- iter: 0928/1053
[A[ATraining Step: 888  | total loss: [1m[32m0.24503[0m[0m | time: 33.928s
[2K
| Adam | epoch: 027 | loss: 0.24503 - acc: 0.9223 -- iter: 0960/1053
[A[ATraining Step: 889  | total loss: [1m[32m0.23909[0m[0m | time: 35.229s
[2K
| Adam | epoch: 027 | loss: 0.23909 - acc: 0.9238 -- iter: 0992/1053
[A[ATraining Step: 890  | total loss: [1m[32m0.23630[0m[0m | time: 36.719s
[2K
| Adam | epoch: 027 | loss: 0.23630 - acc: 0.9189 -- iter: 1024/1053
[A[ATraining Step: 891  | total loss: [1m[32m0.22721[0m[0m | time: 39.835s
[2K
| Adam | epoch: 027 | loss: 0.22721 - acc: 0.9239 | val_loss: 0.69289 - val_acc: 0.7091 -- iter: 1053/1053
--
Training Step: 892  | total loss: [1m[32m0.24703[0m[0m | time: 1.037s
[2K
| Adam | epoch: 028 | loss: 0.24703 - acc: 0.9190 -- iter: 0032/1053
[A[ATraining Step: 893  | total loss: [1m[32m0.25097[0m[0m | time: 2.064s
[2K
| Adam | epoch: 028 | loss: 0.25097 - acc: 0.9177 -- iter: 0064/1053
[A[ATraining Step: 894  | total loss: [1m[32m0.25237[0m[0m | time: 3.226s
[2K
| Adam | epoch: 028 | loss: 0.25237 - acc: 0.9197 -- iter: 0096/1053
[A[ATraining Step: 895  | total loss: [1m[32m0.25421[0m[0m | time: 4.420s
[2K
| Adam | epoch: 028 | loss: 0.25421 - acc: 0.9090 -- iter: 0128/1053
[A[ATraining Step: 896  | total loss: [1m[32m0.24982[0m[0m | time: 5.440s
[2K
| Adam | epoch: 028 | loss: 0.24982 - acc: 0.9087 -- iter: 0160/1053
[A[ATraining Step: 897  | total loss: [1m[32m0.25050[0m[0m | time: 6.572s
[2K
| Adam | epoch: 028 | loss: 0.25050 - acc: 0.9053 -- iter: 0192/1053
[A[ATraining Step: 898  | total loss: [1m[32m0.24477[0m[0m | time: 7.757s
[2K
| Adam | epoch: 028 | loss: 0.24477 - acc: 0.9054 -- iter: 0224/1053
[A[ATraining Step: 899  | total loss: [1m[32m0.23119[0m[0m | time: 9.138s
[2K
| Adam | epoch: 028 | loss: 0.23119 - acc: 0.9149 -- iter: 0256/1053
[A[ATraining Step: 900  | total loss: [1m[32m0.24964[0m[0m | time: 10.398s
[2K
| Adam | epoch: 028 | loss: 0.24964 - acc: 0.9047 -- iter: 0288/1053
[A[ATraining Step: 901  | total loss: [1m[32m0.25655[0m[0m | time: 11.445s
[2K
| Adam | epoch: 028 | loss: 0.25655 - acc: 0.9017 -- iter: 0320/1053
[A[ATraining Step: 902  | total loss: [1m[32m0.25647[0m[0m | time: 12.480s
[2K
| Adam | epoch: 028 | loss: 0.25647 - acc: 0.8990 -- iter: 0352/1053
[A[ATraining Step: 903  | total loss: [1m[32m0.24869[0m[0m | time: 13.494s
[2K
| Adam | epoch: 028 | loss: 0.24869 - acc: 0.8997 -- iter: 0384/1053
[A[ATraining Step: 904  | total loss: [1m[32m0.24505[0m[0m | time: 14.471s
[2K
| Adam | epoch: 028 | loss: 0.24505 - acc: 0.9035 -- iter: 0416/1053
[A[ATraining Step: 905  | total loss: [1m[32m0.26241[0m[0m | time: 15.580s
[2K
| Adam | epoch: 028 | loss: 0.26241 - acc: 0.8975 -- iter: 0448/1053
[A[ATraining Step: 906  | total loss: [1m[32m0.26295[0m[0m | time: 16.646s
[2K
| Adam | epoch: 028 | loss: 0.26295 - acc: 0.8984 -- iter: 0480/1053
[A[ATraining Step: 907  | total loss: [1m[32m0.25054[0m[0m | time: 17.823s
[2K
| Adam | epoch: 028 | loss: 0.25054 - acc: 0.9054 -- iter: 0512/1053
[A[ATraining Step: 908  | total loss: [1m[32m0.26775[0m[0m | time: 18.878s
[2K
| Adam | epoch: 028 | loss: 0.26775 - acc: 0.8962 -- iter: 0544/1053
[A[ATraining Step: 909  | total loss: [1m[32m0.25223[0m[0m | time: 20.165s
[2K
| Adam | epoch: 028 | loss: 0.25223 - acc: 0.9065 -- iter: 0576/1053
[A[ATraining Step: 910  | total loss: [1m[32m0.25247[0m[0m | time: 21.475s
[2K
| Adam | epoch: 028 | loss: 0.25247 - acc: 0.9034 -- iter: 0608/1053
[A[ATraining Step: 911  | total loss: [1m[32m0.25074[0m[0m | time: 22.933s
[2K
| Adam | epoch: 028 | loss: 0.25074 - acc: 0.9037 -- iter: 0640/1053
[A[ATraining Step: 912  | total loss: [1m[32m0.25845[0m[0m | time: 23.967s
[2K
| Adam | epoch: 028 | loss: 0.25845 - acc: 0.8914 -- iter: 0672/1053
[A[ATraining Step: 913  | total loss: [1m[32m0.25839[0m[0m | time: 25.079s
[2K
| Adam | epoch: 028 | loss: 0.25839 - acc: 0.8867 -- iter: 0704/1053
[A[ATraining Step: 914  | total loss: [1m[32m0.26677[0m[0m | time: 26.138s
[2K
| Adam | epoch: 028 | loss: 0.26677 - acc: 0.8824 -- iter: 0736/1053
[A[ATraining Step: 915  | total loss: [1m[32m0.26346[0m[0m | time: 27.252s
[2K
| Adam | epoch: 028 | loss: 0.26346 - acc: 0.8879 -- iter: 0768/1053
[A[ATraining Step: 916  | total loss: [1m[32m0.26474[0m[0m | time: 28.389s
[2K
| Adam | epoch: 028 | loss: 0.26474 - acc: 0.8866 -- iter: 0800/1053
[A[ATraining Step: 917  | total loss: [1m[32m0.26161[0m[0m | time: 29.602s
[2K
| Adam | epoch: 028 | loss: 0.26161 - acc: 0.8886 -- iter: 0832/1053
[A[ATraining Step: 918  | total loss: [1m[32m0.27200[0m[0m | time: 30.724s
[2K
| Adam | epoch: 028 | loss: 0.27200 - acc: 0.8790 -- iter: 0864/1053
[A[ATraining Step: 919  | total loss: [1m[32m0.27708[0m[0m | time: 31.735s
[2K
| Adam | epoch: 028 | loss: 0.27708 - acc: 0.8739 -- iter: 0896/1053
[A[ATraining Step: 920  | total loss: [1m[32m0.34381[0m[0m | time: 32.967s
[2K
| Adam | epoch: 028 | loss: 0.34381 - acc: 0.8459 -- iter: 0928/1053
[A[ATraining Step: 921  | total loss: [1m[32m0.33408[0m[0m | time: 34.282s
[2K
| Adam | epoch: 028 | loss: 0.33408 - acc: 0.8519 -- iter: 0960/1053
[A[ATraining Step: 922  | total loss: [1m[32m0.33432[0m[0m | time: 35.645s
[2K
| Adam | epoch: 028 | loss: 0.33432 - acc: 0.8542 -- iter: 0992/1053
[A[ATraining Step: 923  | total loss: [1m[32m0.31154[0m[0m | time: 36.655s
[2K
| Adam | epoch: 028 | loss: 0.31154 - acc: 0.8657 -- iter: 1024/1053
[A[ATraining Step: 924  | total loss: [1m[32m0.30052[0m[0m | time: 39.433s
[2K
| Adam | epoch: 028 | loss: 0.30052 - acc: 0.8697 | val_loss: 0.48564 - val_acc: 0.7606 -- iter: 1053/1053
--
Training Step: 925  | total loss: [1m[32m0.29126[0m[0m | time: 1.084s
[2K
| Adam | epoch: 029 | loss: 0.29126 - acc: 0.8796 -- iter: 0032/1053
[A[ATraining Step: 926  | total loss: [1m[32m0.29346[0m[0m | time: 2.306s
[2K
| Adam | epoch: 029 | loss: 0.29346 - acc: 0.8729 -- iter: 0064/1053
[A[ATraining Step: 927  | total loss: [1m[32m0.28901[0m[0m | time: 3.507s
[2K
| Adam | epoch: 029 | loss: 0.28901 - acc: 0.8762 -- iter: 0096/1053
[A[ATraining Step: 928  | total loss: [1m[32m0.28191[0m[0m | time: 4.514s
[2K
| Adam | epoch: 029 | loss: 0.28191 - acc: 0.8855 -- iter: 0128/1053
[A[ATraining Step: 929  | total loss: [1m[32m0.28121[0m[0m | time: 5.642s
[2K
| Adam | epoch: 029 | loss: 0.28121 - acc: 0.8844 -- iter: 0160/1053
[A[ATraining Step: 930  | total loss: [1m[32m0.27421[0m[0m | time: 6.816s
[2K
| Adam | epoch: 029 | loss: 0.27421 - acc: 0.8898 -- iter: 0192/1053
[A[ATraining Step: 931  | total loss: [1m[32m0.28194[0m[0m | time: 8.190s
[2K
| Adam | epoch: 029 | loss: 0.28194 - acc: 0.8883 -- iter: 0224/1053
[A[ATraining Step: 932  | total loss: [1m[32m0.27460[0m[0m | time: 9.436s
[2K
| Adam | epoch: 029 | loss: 0.27460 - acc: 0.8932 -- iter: 0256/1053
[A[ATraining Step: 933  | total loss: [1m[32m0.26630[0m[0m | time: 10.333s
[2K
| Adam | epoch: 029 | loss: 0.26630 - acc: 0.8976 -- iter: 0288/1053
[A[ATraining Step: 934  | total loss: [1m[32m0.25526[0m[0m | time: 11.360s
[2K
| Adam | epoch: 029 | loss: 0.25526 - acc: 0.9047 -- iter: 0320/1053
[A[ATraining Step: 935  | total loss: [1m[32m0.25057[0m[0m | time: 12.503s
[2K
| Adam | epoch: 029 | loss: 0.25057 - acc: 0.9049 -- iter: 0352/1053
[A[ATraining Step: 936  | total loss: [1m[32m0.24144[0m[0m | time: 13.890s
[2K
| Adam | epoch: 029 | loss: 0.24144 - acc: 0.9113 -- iter: 0384/1053
[A[ATraining Step: 937  | total loss: [1m[32m0.22997[0m[0m | time: 14.979s
[2K
| Adam | epoch: 029 | loss: 0.22997 - acc: 0.9170 -- iter: 0416/1053
[A[ATraining Step: 938  | total loss: [1m[32m0.21707[0m[0m | time: 16.171s
[2K
| Adam | epoch: 029 | loss: 0.21707 - acc: 0.9253 -- iter: 0448/1053
[A[ATraining Step: 939  | total loss: [1m[32m0.22732[0m[0m | time: 17.488s
[2K
| Adam | epoch: 029 | loss: 0.22732 - acc: 0.9203 -- iter: 0480/1053
[A[ATraining Step: 940  | total loss: [1m[32m0.21411[0m[0m | time: 18.487s
[2K
| Adam | epoch: 029 | loss: 0.21411 - acc: 0.9283 -- iter: 0512/1053
[A[ATraining Step: 941  | total loss: [1m[32m0.21271[0m[0m | time: 19.643s
[2K
| Adam | epoch: 029 | loss: 0.21271 - acc: 0.9229 -- iter: 0544/1053
[A[ATraining Step: 942  | total loss: [1m[32m0.21842[0m[0m | time: 20.951s
[2K
| Adam | epoch: 029 | loss: 0.21842 - acc: 0.9213 -- iter: 0576/1053
[A[ATraining Step: 943  | total loss: [1m[32m0.20925[0m[0m | time: 22.486s
[2K
| Adam | epoch: 029 | loss: 0.20925 - acc: 0.9260 -- iter: 0608/1053
[A[ATraining Step: 944  | total loss: [1m[32m0.19932[0m[0m | time: 23.647s
[2K
| Adam | epoch: 029 | loss: 0.19932 - acc: 0.9303 -- iter: 0640/1053
[A[ATraining Step: 945  | total loss: [1m[32m0.19211[0m[0m | time: 24.718s
[2K
| Adam | epoch: 029 | loss: 0.19211 - acc: 0.9341 -- iter: 0672/1053
[A[ATraining Step: 946  | total loss: [1m[32m0.18699[0m[0m | time: 25.932s
[2K
| Adam | epoch: 029 | loss: 0.18699 - acc: 0.9376 -- iter: 0704/1053
[A[ATraining Step: 947  | total loss: [1m[32m0.17923[0m[0m | time: 27.080s
[2K
| Adam | epoch: 029 | loss: 0.17923 - acc: 0.9407 -- iter: 0736/1053
[A[ATraining Step: 948  | total loss: [1m[32m0.17955[0m[0m | time: 28.271s
[2K
| Adam | epoch: 029 | loss: 0.17955 - acc: 0.9373 -- iter: 0768/1053
[A[ATraining Step: 949  | total loss: [1m[32m0.19178[0m[0m | time: 29.509s
[2K
| Adam | epoch: 029 | loss: 0.19178 - acc: 0.9310 -- iter: 0800/1053
[A[ATraining Step: 950  | total loss: [1m[32m0.18723[0m[0m | time: 30.624s
[2K
| Adam | epoch: 029 | loss: 0.18723 - acc: 0.9317 -- iter: 0832/1053
[A[ATraining Step: 951  | total loss: [1m[32m0.18612[0m[0m | time: 31.639s
[2K
| Adam | epoch: 029 | loss: 0.18612 - acc: 0.9291 -- iter: 0864/1053
[A[ATraining Step: 952  | total loss: [1m[32m0.19647[0m[0m | time: 32.724s
[2K
| Adam | epoch: 029 | loss: 0.19647 - acc: 0.9293 -- iter: 0896/1053
[A[ATraining Step: 953  | total loss: [1m[32m0.20387[0m[0m | time: 33.904s
[2K
| Adam | epoch: 029 | loss: 0.20387 - acc: 0.9261 -- iter: 0928/1053
[A[ATraining Step: 954  | total loss: [1m[32m0.20272[0m[0m | time: 35.066s
[2K
| Adam | epoch: 029 | loss: 0.20272 - acc: 0.9272 -- iter: 0960/1053
[A[ATraining Step: 955  | total loss: [1m[32m0.20972[0m[0m | time: 36.258s
[2K
| Adam | epoch: 029 | loss: 0.20972 - acc: 0.9282 -- iter: 0992/1053
[A[ATraining Step: 956  | total loss: [1m[32m0.19487[0m[0m | time: 37.398s
[2K
| Adam | epoch: 029 | loss: 0.19487 - acc: 0.9323 -- iter: 1024/1053
[A[ATraining Step: 957  | total loss: [1m[32m0.20014[0m[0m | time: 40.590s
[2K
| Adam | epoch: 029 | loss: 0.20014 - acc: 0.9328 | val_loss: 0.58625 - val_acc: 0.7879 -- iter: 1053/1053
--
Training Step: 958  | total loss: [1m[32m0.20147[0m[0m | time: 1.175s
[2K
| Adam | epoch: 030 | loss: 0.20147 - acc: 0.9301 -- iter: 0032/1053
[A[ATraining Step: 959  | total loss: [1m[32m0.19078[0m[0m | time: 2.339s
[2K
| Adam | epoch: 030 | loss: 0.19078 - acc: 0.9371 -- iter: 0064/1053
[A[ATraining Step: 960  | total loss: [1m[32m0.19230[0m[0m | time: 3.506s
[2K
| Adam | epoch: 030 | loss: 0.19230 - acc: 0.9372 -- iter: 0096/1053
[A[ATraining Step: 961  | total loss: [1m[32m0.18091[0m[0m | time: 4.638s
[2K
| Adam | epoch: 030 | loss: 0.18091 - acc: 0.9435 -- iter: 0128/1053
[A[ATraining Step: 962  | total loss: [1m[32m0.18627[0m[0m | time: 5.766s
[2K
| Adam | epoch: 030 | loss: 0.18627 - acc: 0.9397 -- iter: 0160/1053
[A[ATraining Step: 963  | total loss: [1m[32m0.17742[0m[0m | time: 6.847s
[2K
| Adam | epoch: 030 | loss: 0.17742 - acc: 0.9458 -- iter: 0192/1053
[A[ATraining Step: 964  | total loss: [1m[32m0.17168[0m[0m | time: 7.982s
[2K
| Adam | epoch: 030 | loss: 0.17168 - acc: 0.9481 -- iter: 0224/1053
[A[ATraining Step: 965  | total loss: [1m[32m0.16961[0m[0m | time: 9.230s
[2K
| Adam | epoch: 030 | loss: 0.16961 - acc: 0.9470 -- iter: 0256/1053
[A[ATraining Step: 966  | total loss: [1m[32m0.17295[0m[0m | time: 10.403s
[2K
| Adam | epoch: 030 | loss: 0.17295 - acc: 0.9429 -- iter: 0288/1053
[A[ATraining Step: 967  | total loss: [1m[32m0.18622[0m[0m | time: 11.459s
[2K
| Adam | epoch: 030 | loss: 0.18622 - acc: 0.9393 -- iter: 0320/1053
[A[ATraining Step: 968  | total loss: [1m[32m0.18009[0m[0m | time: 12.614s
[2K
| Adam | epoch: 030 | loss: 0.18009 - acc: 0.9391 -- iter: 0352/1053
[A[ATraining Step: 969  | total loss: [1m[32m0.17063[0m[0m | time: 13.805s
[2K
| Adam | epoch: 030 | loss: 0.17063 - acc: 0.9452 -- iter: 0384/1053
[A[ATraining Step: 970  | total loss: [1m[32m0.16614[0m[0m | time: 14.969s
[2K
| Adam | epoch: 030 | loss: 0.16614 - acc: 0.9444 -- iter: 0416/1053
[A[ATraining Step: 971  | total loss: [1m[32m0.18036[0m[0m | time: 16.044s
[2K
| Adam | epoch: 030 | loss: 0.18036 - acc: 0.9375 -- iter: 0448/1053
[A[ATraining Step: 972  | total loss: [1m[32m0.17174[0m[0m | time: 17.203s
[2K
| Adam | epoch: 030 | loss: 0.17174 - acc: 0.9437 -- iter: 0480/1053
[A[ATraining Step: 973  | total loss: [1m[32m0.16530[0m[0m | time: 18.337s
[2K
| Adam | epoch: 030 | loss: 0.16530 - acc: 0.9493 -- iter: 0512/1053
[A[ATraining Step: 974  | total loss: [1m[32m0.17514[0m[0m | time: 19.407s
[2K
| Adam | epoch: 030 | loss: 0.17514 - acc: 0.9482 -- iter: 0544/1053
[A[ATraining Step: 975  | total loss: [1m[32m0.17079[0m[0m | time: 20.532s
[2K
| Adam | epoch: 030 | loss: 0.17079 - acc: 0.9533 -- iter: 0576/1053
[A[ATraining Step: 976  | total loss: [1m[32m0.17999[0m[0m | time: 21.715s
[2K
| Adam | epoch: 030 | loss: 0.17999 - acc: 0.9486 -- iter: 0608/1053
[A[ATraining Step: 977  | total loss: [1m[32m0.17998[0m[0m | time: 22.899s
[2K
| Adam | epoch: 030 | loss: 0.17998 - acc: 0.9444 -- iter: 0640/1053
[A[ATraining Step: 978  | total loss: [1m[32m0.18583[0m[0m | time: 24.033s
[2K
| Adam | epoch: 030 | loss: 0.18583 - acc: 0.9437 -- iter: 0672/1053
[A[ATraining Step: 979  | total loss: [1m[32m0.18733[0m[0m | time: 25.265s
[2K
| Adam | epoch: 030 | loss: 0.18733 - acc: 0.9368 -- iter: 0704/1053
[A[ATraining Step: 980  | total loss: [1m[32m0.19131[0m[0m | time: 25.943s
[2K
| Adam | epoch: 030 | loss: 0.19131 - acc: 0.9338 -- iter: 0736/1053
[A[ATraining Step: 981  | total loss: [1m[32m0.19177[0m[0m | time: 26.566s
[2K
| Adam | epoch: 030 | loss: 0.19177 - acc: 0.9310 -- iter: 0768/1053
[A[ATraining Step: 982  | total loss: [1m[32m0.18859[0m[0m | time: 27.313s
[2K
| Adam | epoch: 030 | loss: 0.18859 - acc: 0.9348 -- iter: 0800/1053
[A[ATraining Step: 983  | total loss: [1m[32m0.18578[0m[0m | time: 28.078s
[2K
| Adam | epoch: 030 | loss: 0.18578 - acc: 0.9319 -- iter: 0832/1053
[A[ATraining Step: 984  | total loss: [1m[32m0.19968[0m[0m | time: 28.810s
[2K
| Adam | epoch: 030 | loss: 0.19968 - acc: 0.9200 -- iter: 0864/1053
[A[ATraining Step: 985  | total loss: [1m[32m0.21123[0m[0m | time: 29.523s
[2K
| Adam | epoch: 030 | loss: 0.21123 - acc: 0.9124 -- iter: 0896/1053
[A[ATraining Step: 986  | total loss: [1m[32m0.23109[0m[0m | time: 30.196s
[2K
| Adam | epoch: 030 | loss: 0.23109 - acc: 0.9004 -- iter: 0928/1053
[A[ATraining Step: 987  | total loss: [1m[32m0.23866[0m[0m | time: 30.936s
[2K
| Adam | epoch: 030 | loss: 0.23866 - acc: 0.8966 -- iter: 0960/1053
[A[ATraining Step: 988  | total loss: [1m[32m0.23004[0m[0m | time: 31.649s
[2K
| Adam | epoch: 030 | loss: 0.23004 - acc: 0.9007 -- iter: 0992/1053
[A[ATraining Step: 989  | total loss: [1m[32m0.23048[0m[0m | time: 32.445s
[2K
| Adam | epoch: 030 | loss: 0.23048 - acc: 0.9044 -- iter: 1024/1053
[A[ATraining Step: 990  | total loss: [1m[32m0.21648[0m[0m | time: 34.434s
[2K
| Adam | epoch: 030 | loss: 0.21648 - acc: 0.9108 | val_loss: 0.58988 - val_acc: 0.7818 -- iter: 1053/1053
--
Validation AUC:0.8484708241737051
Validation AUPRC:0.9096621254478082
Test AUC:0.8980074299223235
Test AUPRC:0.9305353195263095
BestTestF1Score	0.85	0.69	0.84	0.91	0.81	153	16	125	36	0.28
BestTestMCCScore	0.82	0.66	0.82	0.93	0.74	139	10	131	50	0.5
BestTestAccuracyScore	0.85	0.69	0.84	0.91	0.81	153	16	125	36	0.28
BestValidationF1Score	0.82	0.58	0.79	0.86	0.79	158	25	104	43	0.28
BestValidationMCC	0.8	0.6	0.78	0.92	0.7	141	12	117	60	0.5
BestValidationAccuracy	0.82	0.58	0.79	0.86	0.79	158	25	104	43	0.28
TestPredictions (Threshold:0.5)
CHEMBL2437300,TN,INACT,0.2199999988079071	CHEMBL1559853,TN,INACT,0.03999999910593033	CHEMBL1518838,FN,ACT,0.05000000074505806	CHEMBL491499,TN,INACT,0.029999999329447746	CHEMBL237241,TN,INACT,0.03999999910593033	CHEMBL2382121,TN,INACT,0.029999999329447746	CHEMBL1383746,TP,ACT,0.5699999928474426	CHEMBL1545787,TN,INACT,0.03999999910593033	CHEMBL205119,TP,ACT,0.9900000095367432	CHEMBL1587920,TN,INACT,0.25	CHEMBL3753560,TN,INACT,0.11999999731779099	CHEMBL2011538,TN,INACT,0.029999999329447746	CHEMBL3145073,TN,INACT,0.1899999976158142	CHEMBL3234635,TP,ACT,0.9599999785423279	CHEMBL2403349,TP,ACT,0.9900000095367432	CHEMBL2348882,TN,INACT,0.029999999329447746	CHEMBL1300534,FN,ACT,0.10999999940395355	CHEMBL2403499,TN,INACT,0.029999999329447746	CHEMBL3589349,TP,ACT,0.7099999785423279	CHEMBL77851,TP,ACT,0.9200000166893005	CHEMBL1087041,TP,ACT,0.5299999713897705	CHEMBL1361641,TN,INACT,0.009999999776482582	CHEMBL251515,TP,ACT,0.8100000023841858	CHEMBL482593,TN,INACT,0.07999999821186066	CHEMBL3334825,TN,INACT,0.03999999910593033	CHEMBL219577,FN,ACT,0.2199999988079071	CHEMBL1300662,TN,INACT,0.029999999329447746	CHEMBL3827152,FP,INACT,0.75	CHEMBL59146,TP,ACT,0.8600000143051147	CHEMBL215802,TP,ACT,0.9700000286102295	CHEMBL3354989,TN,INACT,0.03999999910593033	CHEMBL193146,TP,ACT,0.9900000095367432	CHEMBL539220,TP,ACT,1.0	CHEMBL192876,TP,ACT,1.0	CHEMBL1342063,FN,ACT,0.07000000029802322	CHEMBL3099431,FN,ACT,0.07999999821186066	CHEMBL3645269,TP,ACT,0.9100000262260437	CHEMBL182402,TP,ACT,0.9100000262260437	CHEMBL377342,TP,ACT,0.9900000095367432	CHEMBL3763659,TN,INACT,0.11999999731779099	CHEMBL48352,TP,ACT,0.9700000286102295	CHEMBL379543,TP,ACT,0.9700000286102295	CHEMBL2403509,TN,INACT,0.05000000074505806	CHEMBL3422045,TP,ACT,0.949999988079071	CHEMBL1606490,TN,INACT,0.09000000357627869	CHEMBL458899,TN,INACT,0.07999999821186066	CHEMBL1270644,TN,INACT,0.029999999329447746	CHEMBL1577184,FN,ACT,0.019999999552965164	CHEMBL192586,TP,ACT,0.9399999976158142	CHEMBL1505049,TN,INACT,0.03999999910593033	CHEMBL205614,TP,ACT,0.5299999713897705	CHEMBL1559291,TN,INACT,0.05000000074505806	CHEMBL346401,TP,ACT,0.5099999904632568	CHEMBL2070863,TN,INACT,0.019999999552965164	CHEMBL1956361,TN,INACT,0.009999999776482582	CHEMBL361601,TP,ACT,0.9599999785423279	CHEMBL1087040,TP,ACT,0.5299999713897705	CHEMBL360315,TP,ACT,0.9700000286102295	CHEMBL370037,TP,ACT,0.9300000071525574	CHEMBL1613213,TN,INACT,0.019999999552965164	CHEMBL2348890,TN,INACT,0.03999999910593033	CHEMBL328716,TP,ACT,1.0	CHEMBL187311,TP,ACT,0.8999999761581421	CHEMBL1448466,FN,ACT,0.029999999329447746	CHEMBL1360564,TN,INACT,0.03999999910593033	CHEMBL99308,FP,INACT,0.8500000238418579	CHEMBL2332574,FN,ACT,0.3799999952316284	CHEMBL1502852,FN,ACT,0.07000000029802322	CHEMBL196530,TP,ACT,0.9800000190734863	CHEMBL1950809,TP,ACT,0.9700000286102295	CHEMBL364419,TP,ACT,0.5400000214576721	CHEMBL489584,FN,ACT,0.2800000011920929	CHEMBL1088344,TP,ACT,1.0	CHEMBL203351,TP,ACT,0.5299999713897705	CHEMBL361871,TP,ACT,0.9800000190734863	CHEMBL118617,TN,INACT,0.029999999329447746	CHEMBL183333,TP,ACT,0.9900000095367432	CHEMBL3797260,TN,INACT,0.029999999329447746	CHEMBL197757,TP,ACT,0.9900000095367432	CHEMBL188189,TP,ACT,1.0	CHEMBL3645264,FN,ACT,0.23999999463558197	CHEMBL1353907,TN,INACT,0.09000000357627869	CHEMBL3645265,FN,ACT,0.3499999940395355	CHEMBL1578407,FP,INACT,0.550000011920929	CHEMBL2325057,TN,INACT,0.019999999552965164	CHEMBL477940,TN,INACT,0.12999999523162842	CHEMBL482642,TN,INACT,0.20999999344348907	CHEMBL1507788,TN,INACT,0.009999999776482582	CHEMBL440757,TP,ACT,1.0	CHEMBL264862,FN,ACT,0.12999999523162842	CHEMBL332625,FN,ACT,0.4000000059604645	CHEMBL243999,TP,ACT,0.9900000095367432	CHEMBL1597481,FN,ACT,0.10000000149011612	CHEMBL1528123,TN,INACT,0.029999999329447746	CHEMBL181368,TP,ACT,1.0	CHEMBL2011539,TN,INACT,0.029999999329447746	CHEMBL1087884,TN,INACT,0.05999999865889549	CHEMBL489597,TN,INACT,0.05000000074505806	CHEMBL203724,TP,ACT,0.9200000166893005	CHEMBL135236,TP,ACT,0.9100000262260437	CHEMBL1377510,TN,INACT,0.019999999552965164	CHEMBL391479,TN,INACT,0.029999999329447746	CHEMBL56198,TP,ACT,0.9300000071525574	CHEMBL365999,TP,ACT,0.7400000095367432	CHEMBL3234629,TP,ACT,0.9599999785423279	CHEMBL3422032,TP,ACT,0.9399999976158142	CHEMBL335412,TP,ACT,0.5699999928474426	CHEMBL1084746,TN,INACT,0.27000001072883606	CHEMBL90794,TP,ACT,1.0	CHEMBL153407,TP,ACT,0.9200000166893005	CHEMBL1097284,FN,ACT,0.25	CHEMBL307205,TP,ACT,0.949999988079071	CHEMBL316292,TP,ACT,0.9700000286102295	CHEMBL123,TN,INACT,0.019999999552965164	CHEMBL377083,TP,ACT,0.8399999737739563	CHEMBL250520,TN,INACT,0.029999999329447746	CHEMBL39176,TN,INACT,0.05000000074505806	CHEMBL471626,TP,ACT,0.9100000262260437	CHEMBL1463175,TN,INACT,0.03999999910593033	CHEMBL3235686,TP,ACT,0.9300000071525574	CHEMBL235491,TN,INACT,0.05000000074505806	CHEMBL538148,FN,ACT,0.07000000029802322	CHEMBL234639,TP,ACT,0.5299999713897705	CHEMBL490197,FN,ACT,0.09000000357627869	CHEMBL203370,TP,ACT,0.75	CHEMBL235113,TN,INACT,0.05000000074505806	CHEMBL556650,TP,ACT,0.5899999737739563	CHEMBL31127,TP,ACT,0.5400000214576721	CHEMBL2011543,TN,INACT,0.03999999910593033	CHEMBL384709,TP,ACT,0.8299999833106995	CHEMBL347063,FN,ACT,0.019999999552965164	CHEMBL150704,TP,ACT,0.5600000023841858	CHEMBL85322,TN,INACT,0.009999999776482582	CHEMBL380359,TP,ACT,0.5799999833106995	CHEMBL182850,TP,ACT,0.7900000214576721	CHEMBL267385,TP,ACT,0.9599999785423279	CHEMBL396947,TP,ACT,0.9599999785423279	CHEMBL1542128,FN,ACT,0.14000000059604645	CHEMBL195693,TN,INACT,0.05000000074505806	CHEMBL204317,TP,ACT,0.9599999785423279	CHEMBL464453,TN,INACT,0.4000000059604645	CHEMBL194265,TP,ACT,0.9200000166893005	CHEMBL2386485,TN,INACT,0.03999999910593033	CHEMBL2348917,TN,INACT,0.029999999329447746	CHEMBL650,FP,INACT,0.6899999976158142	CHEMBL237600,TN,INACT,0.03999999910593033	CHEMBL220072,TP,ACT,0.8500000238418579	CHEMBL121,TN,INACT,0.07000000029802322	CHEMBL410683,TN,INACT,0.11999999731779099	CHEMBL1359893,FN,ACT,0.019999999552965164	CHEMBL1370794,FN,ACT,0.03999999910593033	CHEMBL2348872,TN,INACT,0.05000000074505806	CHEMBL199766,TP,ACT,0.8399999737739563	CHEMBL2204684,TN,INACT,0.4300000071525574	CHEMBL1538325,TN,INACT,0.029999999329447746	CHEMBL574787,TN,INACT,0.25	CHEMBL1784260,TN,INACT,0.03999999910593033	CHEMBL19954,TN,INACT,0.029999999329447746	CHEMBL185918,TP,ACT,0.949999988079071	CHEMBL188528,TP,ACT,0.9100000262260437	CHEMBL310972,FN,ACT,0.4099999964237213	CHEMBL584,TN,INACT,0.019999999552965164	CHEMBL356874,FN,ACT,0.009999999776482582	CHEMBL190487,TP,ACT,0.9300000071525574	CHEMBL57150,TP,ACT,0.9900000095367432	CHEMBL1408395,TP,ACT,0.8100000023841858	CHEMBL195118,TP,ACT,0.8199999928474426	CHEMBL364492,TP,ACT,0.7099999785423279	CHEMBL600336,FN,ACT,0.05000000074505806	CHEMBL1096975,FN,ACT,0.12999999523162842	CHEMBL1480843,TN,INACT,0.019999999552965164	CHEMBL2031540,TP,ACT,0.9100000262260437	CHEMBL2403359,FN,ACT,0.33000001311302185	CHEMBL3623110,TN,INACT,0.03999999910593033	CHEMBL3208465,FN,ACT,0.05000000074505806	CHEMBL3798394,FP,INACT,0.8199999928474426	CHEMBL93826,FN,ACT,0.009999999776482582	CHEMBL3827633,FP,INACT,0.5400000214576721	CHEMBL1627354,TP,ACT,0.7400000095367432	CHEMBL33808,TP,ACT,0.9300000071525574	CHEMBL236086,FN,ACT,0.11999999731779099	CHEMBL187115,TP,ACT,0.8299999833106995	CHEMBL1525824,TN,INACT,0.12999999523162842	CHEMBL418971,TP,ACT,0.9700000286102295	CHEMBL3134124,FN,ACT,0.33000001311302185	CHEMBL196836,TP,ACT,0.9800000190734863	CHEMBL363017,TP,ACT,0.949999988079071	CHEMBL1087919,TP,ACT,0.6800000071525574	CHEMBL489,TP,ACT,0.9399999976158142	CHEMBL107789,TN,INACT,0.029999999329447746	CHEMBL1608989,TN,INACT,0.019999999552965164	CHEMBL135649,TP,ACT,0.5199999809265137	CHEMBL371305,TP,ACT,0.9900000095367432	CHEMBL94116,TP,ACT,1.0	CHEMBL1498999,TN,INACT,0.019999999552965164	CHEMBL1349382,TN,INACT,0.1899999976158142	CHEMBL1464837,TN,INACT,0.029999999329447746	CHEMBL550568,TN,INACT,0.019999999552965164	CHEMBL33053,FN,ACT,0.4000000059604645	CHEMBL1822155,TN,INACT,0.07000000029802322	CHEMBL2381198,TN,INACT,0.029999999329447746	CHEMBL143192,FP,INACT,0.6399999856948853	CHEMBL3667040,TN,INACT,0.07999999821186066	CHEMBL203072,TP,ACT,0.9900000095367432	CHEMBL1574512,TN,INACT,0.019999999552965164	CHEMBL379821,TP,ACT,1.0	CHEMBL1528124,TN,INACT,0.10999999940395355	CHEMBL385279,FN,ACT,0.3799999952316284	CHEMBL195280,TP,ACT,1.0	CHEMBL213529,TP,ACT,0.9900000095367432	CHEMBL1429596,TN,INACT,0.10999999940395355	CHEMBL2348879,TN,INACT,0.029999999329447746	CHEMBL380032,TP,ACT,0.949999988079071	CHEMBL192706,FN,ACT,0.4699999988079071	CHEMBL3317827,FP,INACT,0.9900000095367432	CHEMBL142889,TN,INACT,0.2199999988079071	CHEMBL1549732,FN,ACT,0.019999999552965164	CHEMBL402063,TN,INACT,0.05999999865889549	CHEMBL209803,TP,ACT,0.8999999761581421	CHEMBL1087682,TP,ACT,0.9800000190734863	CHEMBL191238,TP,ACT,0.9900000095367432	CHEMBL236339,TN,INACT,0.05000000074505806	CHEMBL398012,TN,INACT,0.03999999910593033	CHEMBL1443554,FN,ACT,0.12999999523162842	CHEMBL219467,TP,ACT,0.9800000190734863	CHEMBL380358,FN,ACT,0.05000000074505806	CHEMBL1577661,FN,ACT,0.03999999910593033	CHEMBL1485842,TN,INACT,0.05000000074505806	CHEMBL1533166,TN,INACT,0.05999999865889549	CHEMBL328475,FN,ACT,0.11999999731779099	CHEMBL237822,TN,INACT,0.05999999865889549	CHEMBL2011540,TN,INACT,0.029999999329447746	CHEMBL1412087,TN,INACT,0.019999999552965164	CHEMBL1384353,TN,INACT,0.019999999552965164	CHEMBL1088343,TP,ACT,1.0	CHEMBL1501342,TN,INACT,0.029999999329447746	CHEMBL2348886,TN,INACT,0.019999999552965164	CHEMBL372304,TP,ACT,0.9599999785423279	CHEMBL182690,TP,ACT,0.9200000166893005	CHEMBL387094,TN,INACT,0.07999999821186066	CHEMBL1087298,TP,ACT,0.9900000095367432	CHEMBL200799,TP,ACT,0.75	CHEMBL1310309,TN,INACT,0.11999999731779099	CHEMBL370236,TP,ACT,0.9700000286102295	CHEMBL189200,TP,ACT,0.9100000262260437	CHEMBL2096708,FN,ACT,0.03999999910593033	CHEMBL363955,FN,ACT,0.3799999952316284	CHEMBL683,TN,INACT,0.23000000417232513	CHEMBL330307,FN,ACT,0.4000000059604645	CHEMBL1532234,TN,INACT,0.05999999865889549	CHEMBL261781,TP,ACT,0.5600000023841858	CHEMBL360978,TP,ACT,0.8899999856948853	CHEMBL183371,TP,ACT,1.0	CHEMBL3578286,TP,ACT,0.6299999952316284	CHEMBL2070851,TN,INACT,0.009999999776482582	CHEMBL2316569,TN,INACT,0.05999999865889549	CHEMBL153706,TP,ACT,0.8899999856948853	CHEMBL3335625,TN,INACT,0.019999999552965164	CHEMBL361272,TP,ACT,0.9599999785423279	CHEMBL3589700,FN,ACT,0.11999999731779099	CHEMBL1489063,TN,INACT,0.03999999910593033	CHEMBL206137,TP,ACT,0.949999988079071	CHEMBL377847,TP,ACT,0.9800000190734863	CHEMBL3623106,TN,INACT,0.019999999552965164	CHEMBL372783,TP,ACT,1.0	CHEMBL3195986,TN,INACT,0.05999999865889549	CHEMBL438443,TP,ACT,0.7400000095367432	CHEMBL2113027,TP,ACT,0.9900000095367432	CHEMBL3189499,TN,INACT,0.029999999329447746	CHEMBL560648,TN,INACT,0.019999999552965164	CHEMBL101382,TP,ACT,0.9900000095367432	CHEMBL93207,FN,ACT,0.2199999988079071	CHEMBL1323006,FN,ACT,0.36000001430511475	CHEMBL1334930,TN,INACT,0.30000001192092896	CHEMBL1257895,TN,INACT,0.09000000357627869	CHEMBL2111532,TP,ACT,1.0	CHEMBL28626,TP,ACT,0.7699999809265137	CHEMBL363630,FN,ACT,0.1599999964237213	CHEMBL390021,TP,ACT,0.9900000095367432	CHEMBL260419,TN,INACT,0.05000000074505806	CHEMBL1539865,TN,INACT,0.2199999988079071	CHEMBL361063,TP,ACT,0.5400000214576721	CHEMBL186945,TP,ACT,0.9200000166893005	CHEMBL2204685,TN,INACT,0.46000000834465027	CHEMBL3827286,TN,INACT,0.12999999523162842	CHEMBL328810,TP,ACT,0.8700000047683716	CHEMBL379827,TP,ACT,0.9800000190734863	CHEMBL195165,TP,ACT,0.8799999952316284	CHEMBL195466,TP,ACT,0.8600000143051147	CHEMBL1535728,TN,INACT,0.3700000047683716	CHEMBL1466928,TN,INACT,0.03999999910593033	CHEMBL1582403,TN,INACT,0.1599999964237213	CHEMBL380452,FN,ACT,0.029999999329447746	CHEMBL313941,TP,ACT,0.8199999928474426	CHEMBL197667,TP,ACT,1.0	CHEMBL3234612,TP,ACT,0.949999988079071	CHEMBL193108,TP,ACT,0.949999988079071	CHEMBL3827193,FP,INACT,0.7599999904632568	CHEMBL198445,TP,ACT,1.0	CHEMBL3193600,TN,INACT,0.05000000074505806	CHEMBL366928,TP,ACT,0.8700000047683716	CHEMBL135597,TP,ACT,0.8899999856948853	CHEMBL180873,TP,ACT,0.550000011920929	CHEMBL1447311,TN,INACT,0.019999999552965164	CHEMBL150356,FN,ACT,0.10999999940395355	CHEMBL1627757,TN,INACT,0.05000000074505806	CHEMBL198680,TP,ACT,0.9900000095367432	CHEMBL1550490,TN,INACT,0.03999999910593033	CHEMBL2070867,TN,INACT,0.009999999776482582	CHEMBL1288322,FP,INACT,0.6700000166893005	CHEMBL333890,TN,INACT,0.15000000596046448	CHEMBL1390795,TN,INACT,0.029999999329447746	CHEMBL1525853,TN,INACT,0.03999999910593033	CHEMBL319211,TP,ACT,0.949999988079071	CHEMBL1416591,TN,INACT,0.05000000074505806	CHEMBL1981243,FN,ACT,0.07999999821186066	CHEMBL108766,TN,INACT,0.09000000357627869	CHEMBL1381098,TN,INACT,0.09000000357627869	CHEMBL509360,TP,ACT,0.8399999737739563	CHEMBL370750,FN,ACT,0.33000001311302185	CHEMBL3360848,TN,INACT,0.029999999329447746	CHEMBL3764886,TN,INACT,0.4399999976158142	CHEMBL365290,TP,ACT,0.7400000095367432	CHEMBL73989,TP,ACT,0.7300000190734863	CHEMBL30707,TP,ACT,0.9599999785423279	CHEMBL516827,TN,INACT,0.11999999731779099	CHEMBL3752362,TN,INACT,0.029999999329447746	CHEMBL1504315,TN,INACT,0.07000000029802322	CHEMBL1428161,TN,INACT,0.05999999865889549	CHEMBL1084128,TP,ACT,0.9700000286102295	

