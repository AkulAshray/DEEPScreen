CNNModel CHEMBL2409 adam 0.001 30 256 0 0.8 False True
Number of active compounds :	163
Number of inactive compounds :	109
---------------------------------
Run id: CNNModel_CHEMBL2409_adam_0.001_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2409_adam_0.001_30_256_0.8_True/
---------------------------------
Training samples: 172
Validation samples: 54
--
Training Step: 1  | time: 0.749s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/172
[A[ATraining Step: 2  | total loss: [1m[32m0.62375[0m[0m | time: 1.348s
[2K
| Adam | epoch: 001 | loss: 0.62375 - acc: 0.4500 -- iter: 064/172
[A[ATraining Step: 3  | total loss: [1m[32m0.68020[0m[0m | time: 1.962s
[2K
| Adam | epoch: 001 | loss: 0.68020 - acc: 0.4909 -- iter: 096/172
[A[ATraining Step: 4  | total loss: [1m[32m0.67846[0m[0m | time: 2.563s
[2K
| Adam | epoch: 001 | loss: 0.67846 - acc: 0.6852 -- iter: 128/172
[A[ATraining Step: 5  | total loss: [1m[32m0.66314[0m[0m | time: 3.172s
[2K
| Adam | epoch: 001 | loss: 0.66314 - acc: 0.6868 -- iter: 160/172
[A[ATraining Step: 6  | total loss: [1m[32m0.70898[0m[0m | time: 4.459s
[2K
| Adam | epoch: 001 | loss: 0.70898 - acc: 0.5868 | val_loss: 0.69219 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 7  | total loss: [1m[32m0.72079[0m[0m | time: 0.261s
[2K
| Adam | epoch: 002 | loss: 0.72079 - acc: 0.5347 -- iter: 032/172
[A[ATraining Step: 8  | total loss: [1m[32m0.71276[0m[0m | time: 0.861s
[2K
| Adam | epoch: 002 | loss: 0.71276 - acc: 0.5152 -- iter: 064/172
[A[ATraining Step: 9  | total loss: [1m[32m0.69696[0m[0m | time: 1.472s
[2K
| Adam | epoch: 002 | loss: 0.69696 - acc: 0.5568 -- iter: 096/172
[A[ATraining Step: 10  | total loss: [1m[32m0.69264[0m[0m | time: 2.074s
[2K
| Adam | epoch: 002 | loss: 0.69264 - acc: 0.5596 -- iter: 128/172
[A[ATraining Step: 11  | total loss: [1m[32m0.68971[0m[0m | time: 2.680s
[2K
| Adam | epoch: 002 | loss: 0.68971 - acc: 0.5758 -- iter: 160/172
[A[ATraining Step: 12  | total loss: [1m[32m0.68977[0m[0m | time: 4.284s
[2K
| Adam | epoch: 002 | loss: 0.68977 - acc: 0.5698 | val_loss: 0.69144 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 13  | total loss: [1m[32m0.68900[0m[0m | time: 0.256s
[2K
| Adam | epoch: 003 | loss: 0.68900 - acc: 0.5801 -- iter: 032/172
[A[ATraining Step: 14  | total loss: [1m[32m0.68877[0m[0m | time: 0.519s
[2K
| Adam | epoch: 003 | loss: 0.68877 - acc: 0.5814 -- iter: 064/172
[A[ATraining Step: 15  | total loss: [1m[32m0.68882[0m[0m | time: 1.139s
[2K
| Adam | epoch: 003 | loss: 0.68882 - acc: 0.5822 -- iter: 096/172
[A[ATraining Step: 16  | total loss: [1m[32m0.68561[0m[0m | time: 1.748s
[2K
| Adam | epoch: 003 | loss: 0.68561 - acc: 0.6334 -- iter: 128/172
[A[ATraining Step: 17  | total loss: [1m[32m0.68540[0m[0m | time: 2.358s
[2K
| Adam | epoch: 003 | loss: 0.68540 - acc: 0.6304 -- iter: 160/172
[A[ATraining Step: 18  | total loss: [1m[32m0.68595[0m[0m | time: 3.992s
[2K
| Adam | epoch: 003 | loss: 0.68595 - acc: 0.6177 | val_loss: 0.69075 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 19  | total loss: [1m[32m0.68596[0m[0m | time: 0.604s
[2K
| Adam | epoch: 004 | loss: 0.68596 - acc: 0.6097 -- iter: 032/172
[A[ATraining Step: 20  | total loss: [1m[32m0.68651[0m[0m | time: 0.868s
[2K
| Adam | epoch: 004 | loss: 0.68651 - acc: 0.5945 -- iter: 064/172
[A[ATraining Step: 21  | total loss: [1m[32m0.68086[0m[0m | time: 1.117s
[2K
| Adam | epoch: 004 | loss: 0.68086 - acc: 0.6428 -- iter: 096/172
[A[ATraining Step: 22  | total loss: [1m[32m0.67580[0m[0m | time: 1.754s
[2K
| Adam | epoch: 004 | loss: 0.67580 - acc: 0.6749 -- iter: 128/172
[A[ATraining Step: 23  | total loss: [1m[32m0.67781[0m[0m | time: 2.358s
[2K
| Adam | epoch: 004 | loss: 0.67781 - acc: 0.6514 -- iter: 160/172
[A[ATraining Step: 24  | total loss: [1m[32m0.67707[0m[0m | time: 3.970s
[2K
| Adam | epoch: 004 | loss: 0.67707 - acc: 0.6440 | val_loss: 0.69225 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 25  | total loss: [1m[32m0.67583[0m[0m | time: 0.599s
[2K
| Adam | epoch: 005 | loss: 0.67583 - acc: 0.6388 -- iter: 032/172
[A[ATraining Step: 26  | total loss: [1m[32m0.67589[0m[0m | time: 1.220s
[2K
| Adam | epoch: 005 | loss: 0.67589 - acc: 0.6269 -- iter: 064/172
[A[ATraining Step: 27  | total loss: [1m[32m0.67573[0m[0m | time: 1.467s
[2K
| Adam | epoch: 005 | loss: 0.67573 - acc: 0.6183 -- iter: 096/172
[A[ATraining Step: 28  | total loss: [1m[32m0.70435[0m[0m | time: 1.713s
[2K
| Adam | epoch: 005 | loss: 0.70435 - acc: 0.5471 -- iter: 128/172
[A[ATraining Step: 29  | total loss: [1m[32m0.72090[0m[0m | time: 2.307s
[2K
| Adam | epoch: 005 | loss: 0.72090 - acc: 0.4951 -- iter: 160/172
[A[ATraining Step: 30  | total loss: [1m[32m0.71453[0m[0m | time: 3.899s
[2K
| Adam | epoch: 005 | loss: 0.71453 - acc: 0.5037 | val_loss: 0.69102 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 31  | total loss: [1m[32m0.70258[0m[0m | time: 0.602s
[2K
| Adam | epoch: 006 | loss: 0.70258 - acc: 0.5389 -- iter: 032/172
[A[ATraining Step: 32  | total loss: [1m[32m0.69554[0m[0m | time: 1.171s
[2K
| Adam | epoch: 006 | loss: 0.69554 - acc: 0.5583 -- iter: 064/172
[A[ATraining Step: 33  | total loss: [1m[32m0.69180[0m[0m | time: 1.764s
[2K
| Adam | epoch: 006 | loss: 0.69180 - acc: 0.5660 -- iter: 096/172
[A[ATraining Step: 34  | total loss: [1m[32m0.69180[0m[0m | time: 2.013s
[2K
| Adam | epoch: 006 | loss: 0.69180 - acc: 0.5586 -- iter: 128/172
[A[ATraining Step: 35  | total loss: [1m[32m0.68960[0m[0m | time: 2.266s
[2K
| Adam | epoch: 006 | loss: 0.68960 - acc: 0.5638 -- iter: 160/172
[A[ATraining Step: 36  | total loss: [1m[32m0.68795[0m[0m | time: 3.872s
[2K
| Adam | epoch: 006 | loss: 0.68795 - acc: 0.5678 | val_loss: 0.69043 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 37  | total loss: [1m[32m0.68535[0m[0m | time: 0.622s
[2K
| Adam | epoch: 007 | loss: 0.68535 - acc: 0.5792 -- iter: 032/172
[A[ATraining Step: 38  | total loss: [1m[32m0.68454[0m[0m | time: 1.212s
[2K
| Adam | epoch: 007 | loss: 0.68454 - acc: 0.5821 -- iter: 064/172
[A[ATraining Step: 39  | total loss: [1m[32m0.68288[0m[0m | time: 1.822s
[2K
| Adam | epoch: 007 | loss: 0.68288 - acc: 0.5903 -- iter: 096/172
[A[ATraining Step: 40  | total loss: [1m[32m0.68148[0m[0m | time: 2.426s
[2K
| Adam | epoch: 007 | loss: 0.68148 - acc: 0.5968 -- iter: 128/172
[A[ATraining Step: 41  | total loss: [1m[32m0.68038[0m[0m | time: 2.667s
[2K
| Adam | epoch: 007 | loss: 0.68038 - acc: 0.6020 -- iter: 160/172
[A[ATraining Step: 42  | total loss: [1m[32m0.67813[0m[0m | time: 3.920s
[2K
| Adam | epoch: 007 | loss: 0.67813 - acc: 0.6136 | val_loss: 0.69062 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 43  | total loss: [1m[32m0.67600[0m[0m | time: 0.598s
[2K
| Adam | epoch: 008 | loss: 0.67600 - acc: 0.6230 -- iter: 032/172
[A[ATraining Step: 44  | total loss: [1m[32m0.67874[0m[0m | time: 1.203s
[2K
| Adam | epoch: 008 | loss: 0.67874 - acc: 0.6071 -- iter: 064/172
[A[ATraining Step: 45  | total loss: [1m[32m0.67973[0m[0m | time: 1.832s
[2K
| Adam | epoch: 008 | loss: 0.67973 - acc: 0.5995 -- iter: 096/172
[A[ATraining Step: 46  | total loss: [1m[32m0.68485[0m[0m | time: 2.441s
[2K
| Adam | epoch: 008 | loss: 0.68485 - acc: 0.5725 -- iter: 128/172
[A[ATraining Step: 47  | total loss: [1m[32m0.68282[0m[0m | time: 3.034s
[2K
| Adam | epoch: 008 | loss: 0.68282 - acc: 0.5811 -- iter: 160/172
[A[ATraining Step: 48  | total loss: [1m[32m0.68109[0m[0m | time: 4.294s
[2K
| Adam | epoch: 008 | loss: 0.68109 - acc: 0.5882 | val_loss: 0.69125 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 49  | total loss: [1m[32m0.67270[0m[0m | time: 0.240s
[2K
| Adam | epoch: 009 | loss: 0.67270 - acc: 0.6269 -- iter: 032/172
[A[ATraining Step: 50  | total loss: [1m[32m0.66507[0m[0m | time: 0.831s
[2K
| Adam | epoch: 009 | loss: 0.66507 - acc: 0.6589 -- iter: 064/172
[A[ATraining Step: 51  | total loss: [1m[32m0.66334[0m[0m | time: 1.441s
[2K
| Adam | epoch: 009 | loss: 0.66334 - acc: 0.6633 -- iter: 096/172
[A[ATraining Step: 52  | total loss: [1m[32m0.66408[0m[0m | time: 2.042s
[2K
| Adam | epoch: 009 | loss: 0.66408 - acc: 0.6575 -- iter: 128/172
[A[ATraining Step: 53  | total loss: [1m[32m0.66844[0m[0m | time: 2.655s
[2K
| Adam | epoch: 009 | loss: 0.66844 - acc: 0.6389 -- iter: 160/172
[A[ATraining Step: 54  | total loss: [1m[32m0.66813[0m[0m | time: 4.261s
[2K
| Adam | epoch: 009 | loss: 0.66813 - acc: 0.6369 | val_loss: 0.69520 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 55  | total loss: [1m[32m0.67067[0m[0m | time: 0.246s
[2K
| Adam | epoch: 010 | loss: 0.67067 - acc: 0.6263 -- iter: 032/172
[A[ATraining Step: 56  | total loss: [1m[32m0.67180[0m[0m | time: 0.488s
[2K
| Adam | epoch: 010 | loss: 0.67180 - acc: 0.6202 -- iter: 064/172
[A[ATraining Step: 57  | total loss: [1m[32m0.67318[0m[0m | time: 1.081s
[2K
| Adam | epoch: 010 | loss: 0.67318 - acc: 0.6151 -- iter: 096/172
[A[ATraining Step: 58  | total loss: [1m[32m0.66866[0m[0m | time: 1.685s
[2K
| Adam | epoch: 010 | loss: 0.66866 - acc: 0.6250 -- iter: 128/172
[A[ATraining Step: 59  | total loss: [1m[32m0.66626[0m[0m | time: 2.281s
[2K
| Adam | epoch: 010 | loss: 0.66626 - acc: 0.6292 -- iter: 160/172
[A[ATraining Step: 60  | total loss: [1m[32m0.66383[0m[0m | time: 3.877s
[2K
| Adam | epoch: 010 | loss: 0.66383 - acc: 0.6328 | val_loss: 0.70488 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 61  | total loss: [1m[32m0.66151[0m[0m | time: 0.611s
[2K
| Adam | epoch: 011 | loss: 0.66151 - acc: 0.6358 -- iter: 032/172
[A[ATraining Step: 62  | total loss: [1m[32m0.66351[0m[0m | time: 0.853s
[2K
| Adam | epoch: 011 | loss: 0.66351 - acc: 0.6304 -- iter: 064/172
[A[ATraining Step: 63  | total loss: [1m[32m0.66071[0m[0m | time: 1.119s
[2K
| Adam | epoch: 011 | loss: 0.66071 - acc: 0.6350 -- iter: 096/172
[A[ATraining Step: 64  | total loss: [1m[32m0.65782[0m[0m | time: 1.710s
[2K
| Adam | epoch: 011 | loss: 0.65782 - acc: 0.6390 -- iter: 128/172
[A[ATraining Step: 65  | total loss: [1m[32m0.67251[0m[0m | time: 2.303s
[2K
| Adam | epoch: 011 | loss: 0.67251 - acc: 0.6141 -- iter: 160/172
[A[ATraining Step: 66  | total loss: [1m[32m0.67530[0m[0m | time: 3.930s
[2K
| Adam | epoch: 011 | loss: 0.67530 - acc: 0.6079 | val_loss: 0.70650 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 67  | total loss: [1m[32m0.67592[0m[0m | time: 0.607s
[2K
| Adam | epoch: 012 | loss: 0.67592 - acc: 0.6062 -- iter: 032/172
[A[ATraining Step: 68  | total loss: [1m[32m0.67604[0m[0m | time: 1.235s
[2K
| Adam | epoch: 012 | loss: 0.67604 - acc: 0.6047 -- iter: 064/172
[A[ATraining Step: 69  | total loss: [1m[32m0.67442[0m[0m | time: 1.477s
[2K
| Adam | epoch: 012 | loss: 0.67442 - acc: 0.6071 -- iter: 096/172
[A[ATraining Step: 70  | total loss: [1m[32m0.67052[0m[0m | time: 1.726s
[2K
| Adam | epoch: 012 | loss: 0.67052 - acc: 0.6139 -- iter: 128/172
[A[ATraining Step: 71  | total loss: [1m[32m0.66746[0m[0m | time: 2.316s
[2K
| Adam | epoch: 012 | loss: 0.66746 - acc: 0.6199 -- iter: 160/172
[A[ATraining Step: 72  | total loss: [1m[32m0.66702[0m[0m | time: 3.913s
[2K
| Adam | epoch: 012 | loss: 0.66702 - acc: 0.6205 | val_loss: 0.70012 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 73  | total loss: [1m[32m0.66213[0m[0m | time: 0.598s
[2K
| Adam | epoch: 013 | loss: 0.66213 - acc: 0.6314 -- iter: 032/172
[A[ATraining Step: 74  | total loss: [1m[32m0.66663[0m[0m | time: 1.211s
[2K
| Adam | epoch: 013 | loss: 0.66663 - acc: 0.6204 -- iter: 064/172
[A[ATraining Step: 75  | total loss: [1m[32m0.66618[0m[0m | time: 1.807s
[2K
| Adam | epoch: 013 | loss: 0.66618 - acc: 0.6209 -- iter: 096/172
[A[ATraining Step: 76  | total loss: [1m[32m0.66731[0m[0m | time: 2.052s
[2K
| Adam | epoch: 013 | loss: 0.66731 - acc: 0.6180 -- iter: 128/172
[A[ATraining Step: 77  | total loss: [1m[32m0.66138[0m[0m | time: 2.312s
[2K
| Adam | epoch: 013 | loss: 0.66138 - acc: 0.6320 -- iter: 160/172
[A[ATraining Step: 78  | total loss: [1m[32m0.65580[0m[0m | time: 3.918s
[2K
| Adam | epoch: 013 | loss: 0.65580 - acc: 0.6443 | val_loss: 0.70251 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 79  | total loss: [1m[32m0.66247[0m[0m | time: 0.611s
[2K
| Adam | epoch: 014 | loss: 0.66247 - acc: 0.6294 -- iter: 032/172
[A[ATraining Step: 80  | total loss: [1m[32m0.66688[0m[0m | time: 1.215s
[2K
| Adam | epoch: 014 | loss: 0.66688 - acc: 0.6194 -- iter: 064/172
[A[ATraining Step: 81  | total loss: [1m[32m0.66178[0m[0m | time: 1.817s
[2K
| Adam | epoch: 014 | loss: 0.66178 - acc: 0.6294 -- iter: 096/172
[A[ATraining Step: 82  | total loss: [1m[32m0.66620[0m[0m | time: 2.405s
[2K
| Adam | epoch: 014 | loss: 0.66620 - acc: 0.6196 -- iter: 128/172
[A[ATraining Step: 83  | total loss: [1m[32m0.66856[0m[0m | time: 2.649s
[2K
| Adam | epoch: 014 | loss: 0.66856 - acc: 0.6139 -- iter: 160/172
[A[ATraining Step: 84  | total loss: [1m[32m0.66186[0m[0m | time: 3.902s
[2K
| Adam | epoch: 014 | loss: 0.66186 - acc: 0.6275 | val_loss: 0.70451 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 85  | total loss: [1m[32m0.65548[0m[0m | time: 0.613s
[2K
| Adam | epoch: 015 | loss: 0.65548 - acc: 0.6398 -- iter: 032/172
[A[ATraining Step: 86  | total loss: [1m[32m0.65597[0m[0m | time: 1.222s
[2K
| Adam | epoch: 015 | loss: 0.65597 - acc: 0.6383 -- iter: 064/172
[A[ATraining Step: 87  | total loss: [1m[32m0.65973[0m[0m | time: 1.827s
[2K
| Adam | epoch: 015 | loss: 0.65973 - acc: 0.6307 -- iter: 096/172
[A[ATraining Step: 88  | total loss: [1m[32m0.65826[0m[0m | time: 2.425s
[2K
| Adam | epoch: 015 | loss: 0.65826 - acc: 0.6333 -- iter: 128/172
[A[ATraining Step: 89  | total loss: [1m[32m0.66190[0m[0m | time: 3.028s
[2K
| Adam | epoch: 015 | loss: 0.66190 - acc: 0.6262 -- iter: 160/172
[A[ATraining Step: 90  | total loss: [1m[32m0.66322[0m[0m | time: 4.277s
[2K
| Adam | epoch: 015 | loss: 0.66322 - acc: 0.6229 | val_loss: 0.70435 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 91  | total loss: [1m[32m0.66579[0m[0m | time: 0.262s
[2K
| Adam | epoch: 016 | loss: 0.66579 - acc: 0.6190 -- iter: 032/172
[A[ATraining Step: 92  | total loss: [1m[32m0.66714[0m[0m | time: 0.877s
[2K
| Adam | epoch: 016 | loss: 0.66714 - acc: 0.6154 -- iter: 064/172
[A[ATraining Step: 93  | total loss: [1m[32m0.66475[0m[0m | time: 1.485s
[2K
| Adam | epoch: 016 | loss: 0.66475 - acc: 0.6195 -- iter: 096/172
[A[ATraining Step: 94  | total loss: [1m[32m0.66580[0m[0m | time: 2.093s
[2K
| Adam | epoch: 016 | loss: 0.66580 - acc: 0.6169 -- iter: 128/172
[A[ATraining Step: 95  | total loss: [1m[32m0.66666[0m[0m | time: 2.694s
[2K
| Adam | epoch: 016 | loss: 0.66666 - acc: 0.6146 -- iter: 160/172
[A[ATraining Step: 96  | total loss: [1m[32m0.66026[0m[0m | time: 4.322s
[2K
| Adam | epoch: 016 | loss: 0.66026 - acc: 0.6281 | val_loss: 0.69966 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 97  | total loss: [1m[32m0.66606[0m[0m | time: 0.247s
[2K
| Adam | epoch: 017 | loss: 0.66606 - acc: 0.6153 -- iter: 032/172
[A[ATraining Step: 98  | total loss: [1m[32m0.65838[0m[0m | time: 0.487s
[2K
| Adam | epoch: 017 | loss: 0.65838 - acc: 0.6288 -- iter: 064/172
[A[ATraining Step: 99  | total loss: [1m[32m0.65119[0m[0m | time: 1.096s
[2K
| Adam | epoch: 017 | loss: 0.65119 - acc: 0.6409 -- iter: 096/172
[A[ATraining Step: 100  | total loss: [1m[32m0.65661[0m[0m | time: 1.687s
[2K
| Adam | epoch: 017 | loss: 0.65661 - acc: 0.6300 -- iter: 128/172
[A[ATraining Step: 101  | total loss: [1m[32m0.65776[0m[0m | time: 2.291s
[2K
| Adam | epoch: 017 | loss: 0.65776 - acc: 0.6263 -- iter: 160/172
[A[ATraining Step: 102  | total loss: [1m[32m0.66422[0m[0m | time: 3.907s
[2K
| Adam | epoch: 017 | loss: 0.66422 - acc: 0.6137 | val_loss: 0.69933 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 103  | total loss: [1m[32m0.65951[0m[0m | time: 0.587s
[2K
| Adam | epoch: 018 | loss: 0.65951 - acc: 0.6211 -- iter: 032/172
[A[ATraining Step: 104  | total loss: [1m[32m0.65966[0m[0m | time: 0.822s
[2K
| Adam | epoch: 018 | loss: 0.65966 - acc: 0.6183 -- iter: 064/172
[A[ATraining Step: 105  | total loss: [1m[32m0.65692[0m[0m | time: 1.065s
[2K
| Adam | epoch: 018 | loss: 0.65692 - acc: 0.6232 -- iter: 096/172
[A[ATraining Step: 106  | total loss: [1m[32m0.65346[0m[0m | time: 1.678s
[2K
| Adam | epoch: 018 | loss: 0.65346 - acc: 0.6275 -- iter: 128/172
[A[ATraining Step: 107  | total loss: [1m[32m0.65385[0m[0m | time: 2.283s
[2K
| Adam | epoch: 018 | loss: 0.65385 - acc: 0.6273 -- iter: 160/172
[A[ATraining Step: 108  | total loss: [1m[32m0.65130[0m[0m | time: 3.870s
[2K
| Adam | epoch: 018 | loss: 0.65130 - acc: 0.6302 | val_loss: 0.70081 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 109  | total loss: [1m[32m0.65899[0m[0m | time: 0.594s
[2K
| Adam | epoch: 019 | loss: 0.65899 - acc: 0.6172 -- iter: 032/172
[A[ATraining Step: 110  | total loss: [1m[32m0.65394[0m[0m | time: 1.199s
[2K
| Adam | epoch: 019 | loss: 0.65394 - acc: 0.6211 -- iter: 064/172
[A[ATraining Step: 111  | total loss: [1m[32m0.65290[0m[0m | time: 1.442s
[2K
| Adam | epoch: 019 | loss: 0.65290 - acc: 0.6215 -- iter: 096/172
[A[ATraining Step: 112  | total loss: [1m[32m0.65259[0m[0m | time: 1.683s
[2K
| Adam | epoch: 019 | loss: 0.65259 - acc: 0.6260 -- iter: 128/172
[A[ATraining Step: 113  | total loss: [1m[32m0.65146[0m[0m | time: 2.298s
[2K
| Adam | epoch: 019 | loss: 0.65146 - acc: 0.6300 -- iter: 160/172
[A[ATraining Step: 114  | total loss: [1m[32m0.65030[0m[0m | time: 3.896s
[2K
| Adam | epoch: 019 | loss: 0.65030 - acc: 0.6233 | val_loss: 0.70102 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 115  | total loss: [1m[32m0.65015[0m[0m | time: 0.595s
[2K
| Adam | epoch: 020 | loss: 0.65015 - acc: 0.6235 -- iter: 032/172
[A[ATraining Step: 116  | total loss: [1m[32m0.64310[0m[0m | time: 1.196s
[2K
| Adam | epoch: 020 | loss: 0.64310 - acc: 0.6267 -- iter: 064/172
[A[ATraining Step: 117  | total loss: [1m[32m0.64100[0m[0m | time: 1.800s
[2K
| Adam | epoch: 020 | loss: 0.64100 - acc: 0.6234 -- iter: 096/172
[A[ATraining Step: 118  | total loss: [1m[32m0.63909[0m[0m | time: 2.058s
[2K
| Adam | epoch: 020 | loss: 0.63909 - acc: 0.6173 -- iter: 128/172
[A[ATraining Step: 119  | total loss: [1m[32m0.64232[0m[0m | time: 2.304s
[2K
| Adam | epoch: 020 | loss: 0.64232 - acc: 0.6139 -- iter: 160/172
[A[ATraining Step: 120  | total loss: [1m[32m0.64270[0m[0m | time: 3.913s
[2K
| Adam | epoch: 020 | loss: 0.64270 - acc: 0.6192 | val_loss: 0.64732 - val_acc: 0.5741 -- iter: 172/172
--
Training Step: 121  | total loss: [1m[32m0.65020[0m[0m | time: 0.602s
[2K
| Adam | epoch: 021 | loss: 0.65020 - acc: 0.5948 -- iter: 032/172
[A[ATraining Step: 122  | total loss: [1m[32m0.64483[0m[0m | time: 1.200s
[2K
| Adam | epoch: 021 | loss: 0.64483 - acc: 0.6166 -- iter: 064/172
[A[ATraining Step: 123  | total loss: [1m[32m0.64465[0m[0m | time: 1.812s
[2K
| Adam | epoch: 021 | loss: 0.64465 - acc: 0.6205 -- iter: 096/172
[A[ATraining Step: 124  | total loss: [1m[32m0.63663[0m[0m | time: 2.431s
[2K
| Adam | epoch: 021 | loss: 0.63663 - acc: 0.6335 -- iter: 128/172
[A[ATraining Step: 125  | total loss: [1m[32m0.62285[0m[0m | time: 2.685s
[2K
| Adam | epoch: 021 | loss: 0.62285 - acc: 0.6545 -- iter: 160/172
[A[ATraining Step: 126  | total loss: [1m[32m0.61720[0m[0m | time: 3.945s
[2K
| Adam | epoch: 021 | loss: 0.61720 - acc: 0.6641 | val_loss: 0.93366 - val_acc: 0.6481 -- iter: 172/172
--
Training Step: 127  | total loss: [1m[32m0.60283[0m[0m | time: 0.597s
[2K
| Adam | epoch: 022 | loss: 0.60283 - acc: 0.6727 -- iter: 032/172
[A[ATraining Step: 128  | total loss: [1m[32m0.62152[0m[0m | time: 1.193s
[2K
| Adam | epoch: 022 | loss: 0.62152 - acc: 0.6616 -- iter: 064/172
[A[ATraining Step: 129  | total loss: [1m[32m0.59470[0m[0m | time: 1.798s
[2K
| Adam | epoch: 022 | loss: 0.59470 - acc: 0.6767 -- iter: 096/172
[A[ATraining Step: 130  | total loss: [1m[32m0.61349[0m[0m | time: 2.427s
[2K
| Adam | epoch: 022 | loss: 0.61349 - acc: 0.6622 -- iter: 128/172
[A[ATraining Step: 131  | total loss: [1m[32m0.60634[0m[0m | time: 3.013s
[2K
| Adam | epoch: 022 | loss: 0.60634 - acc: 0.6710 -- iter: 160/172
[A[ATraining Step: 132  | total loss: [1m[32m0.61047[0m[0m | time: 4.262s
[2K
| Adam | epoch: 022 | loss: 0.61047 - acc: 0.6695 | val_loss: 0.66671 - val_acc: 0.6852 -- iter: 172/172
--
Training Step: 133  | total loss: [1m[32m0.61525[0m[0m | time: 0.241s
[2K
| Adam | epoch: 023 | loss: 0.61525 - acc: 0.6775 -- iter: 032/172
[A[ATraining Step: 134  | total loss: [1m[32m0.62108[0m[0m | time: 0.836s
[2K
| Adam | epoch: 023 | loss: 0.62108 - acc: 0.6681 -- iter: 064/172
[A[ATraining Step: 135  | total loss: [1m[32m0.62670[0m[0m | time: 1.440s
[2K
| Adam | epoch: 023 | loss: 0.62670 - acc: 0.6576 -- iter: 096/172
[A[ATraining Step: 136  | total loss: [1m[32m0.63015[0m[0m | time: 2.046s
[2K
| Adam | epoch: 023 | loss: 0.63015 - acc: 0.6606 -- iter: 128/172
[A[ATraining Step: 137  | total loss: [1m[32m0.62876[0m[0m | time: 2.643s
[2K
| Adam | epoch: 023 | loss: 0.62876 - acc: 0.6789 -- iter: 160/172
[A[ATraining Step: 138  | total loss: [1m[32m0.62676[0m[0m | time: 4.236s
[2K
| Adam | epoch: 023 | loss: 0.62676 - acc: 0.6891 | val_loss: 0.65262 - val_acc: 0.6481 -- iter: 172/172
--
Training Step: 139  | total loss: [1m[32m0.61924[0m[0m | time: 0.247s
[2K
| Adam | epoch: 024 | loss: 0.61924 - acc: 0.7046 -- iter: 032/172
[A[ATraining Step: 140  | total loss: [1m[32m0.61200[0m[0m | time: 0.492s
[2K
| Adam | epoch: 024 | loss: 0.61200 - acc: 0.7174 -- iter: 064/172
[A[ATraining Step: 141  | total loss: [1m[32m0.60327[0m[0m | time: 1.082s
[2K
| Adam | epoch: 024 | loss: 0.60327 - acc: 0.7290 -- iter: 096/172
[A[ATraining Step: 142  | total loss: [1m[32m0.61731[0m[0m | time: 1.667s
[2K
| Adam | epoch: 024 | loss: 0.61731 - acc: 0.7061 -- iter: 128/172
[A[ATraining Step: 143  | total loss: [1m[32m0.60691[0m[0m | time: 2.255s
[2K
| Adam | epoch: 024 | loss: 0.60691 - acc: 0.7168 -- iter: 160/172
[A[ATraining Step: 144  | total loss: [1m[32m0.60369[0m[0m | time: 3.858s
[2K
| Adam | epoch: 024 | loss: 0.60369 - acc: 0.7170 | val_loss: 0.62989 - val_acc: 0.6481 -- iter: 172/172
--
Training Step: 145  | total loss: [1m[32m0.60066[0m[0m | time: 0.599s
[2K
| Adam | epoch: 025 | loss: 0.60066 - acc: 0.7171 -- iter: 032/172
[A[ATraining Step: 146  | total loss: [1m[32m0.59651[0m[0m | time: 0.853s
[2K
| Adam | epoch: 025 | loss: 0.59651 - acc: 0.7173 -- iter: 064/172
[A[ATraining Step: 147  | total loss: [1m[32m0.59653[0m[0m | time: 1.089s
[2K
| Adam | epoch: 025 | loss: 0.59653 - acc: 0.7122 -- iter: 096/172
[A[ATraining Step: 148  | total loss: [1m[32m0.59492[0m[0m | time: 1.675s
[2K
| Adam | epoch: 025 | loss: 0.59492 - acc: 0.7077 -- iter: 128/172
[A[ATraining Step: 149  | total loss: [1m[32m0.59503[0m[0m | time: 2.277s
[2K
| Adam | epoch: 025 | loss: 0.59503 - acc: 0.7119 -- iter: 160/172
[A[ATraining Step: 150  | total loss: [1m[32m0.59335[0m[0m | time: 3.880s
[2K
| Adam | epoch: 025 | loss: 0.59335 - acc: 0.7126 | val_loss: 0.73271 - val_acc: 0.6481 -- iter: 172/172
--
Training Step: 151  | total loss: [1m[32m0.57730[0m[0m | time: 0.592s
[2K
| Adam | epoch: 026 | loss: 0.57730 - acc: 0.7226 -- iter: 032/172
[A[ATraining Step: 152  | total loss: [1m[32m0.57894[0m[0m | time: 1.193s
[2K
| Adam | epoch: 026 | loss: 0.57894 - acc: 0.7222 -- iter: 064/172
[A[ATraining Step: 153  | total loss: [1m[32m0.56934[0m[0m | time: 1.434s
[2K
| Adam | epoch: 026 | loss: 0.56934 - acc: 0.7281 -- iter: 096/172
[A[ATraining Step: 154  | total loss: [1m[32m0.56565[0m[0m | time: 1.679s
[2K
| Adam | epoch: 026 | loss: 0.56565 - acc: 0.7303 -- iter: 128/172
[A[ATraining Step: 155  | total loss: [1m[32m0.55519[0m[0m | time: 2.247s
[2K
| Adam | epoch: 026 | loss: 0.55519 - acc: 0.7323 -- iter: 160/172
[A[ATraining Step: 156  | total loss: [1m[32m0.54662[0m[0m | time: 3.840s
[2K
| Adam | epoch: 026 | loss: 0.54662 - acc: 0.7403 | val_loss: 0.56040 - val_acc: 0.7037 -- iter: 172/172
--
Training Step: 157  | total loss: [1m[32m0.53220[0m[0m | time: 0.598s
[2K
| Adam | epoch: 027 | loss: 0.53220 - acc: 0.7538 -- iter: 032/172
[A[ATraining Step: 158  | total loss: [1m[32m0.51801[0m[0m | time: 1.206s
[2K
| Adam | epoch: 027 | loss: 0.51801 - acc: 0.7628 -- iter: 064/172
[A[ATraining Step: 159  | total loss: [1m[32m0.50872[0m[0m | time: 1.799s
[2K
| Adam | epoch: 027 | loss: 0.50872 - acc: 0.7677 -- iter: 096/172
[A[ATraining Step: 160  | total loss: [1m[32m0.50538[0m[0m | time: 2.052s
[2K
| Adam | epoch: 027 | loss: 0.50538 - acc: 0.7660 -- iter: 128/172
[A[ATraining Step: 161  | total loss: [1m[32m0.48023[0m[0m | time: 2.292s
[2K
| Adam | epoch: 027 | loss: 0.48023 - acc: 0.7810 -- iter: 160/172
[A[ATraining Step: 162  | total loss: [1m[32m0.45523[0m[0m | time: 3.887s
[2K
| Adam | epoch: 027 | loss: 0.45523 - acc: 0.8029 | val_loss: 0.62091 - val_acc: 0.7037 -- iter: 172/172
--
Training Step: 163  | total loss: [1m[32m0.45062[0m[0m | time: 0.621s
[2K
| Adam | epoch: 028 | loss: 0.45062 - acc: 0.8039 -- iter: 032/172
[A[ATraining Step: 164  | total loss: [1m[32m0.47539[0m[0m | time: 1.217s
[2K
| Adam | epoch: 028 | loss: 0.47539 - acc: 0.7891 -- iter: 064/172
[A[ATraining Step: 165  | total loss: [1m[32m0.46155[0m[0m | time: 1.833s
[2K
| Adam | epoch: 028 | loss: 0.46155 - acc: 0.7977 -- iter: 096/172
[A[ATraining Step: 166  | total loss: [1m[32m0.44147[0m[0m | time: 2.424s
[2K
| Adam | epoch: 028 | loss: 0.44147 - acc: 0.8086 -- iter: 128/172
[A[ATraining Step: 167  | total loss: [1m[32m0.43722[0m[0m | time: 2.668s
[2K
| Adam | epoch: 028 | loss: 0.43722 - acc: 0.8121 -- iter: 160/172
[A[ATraining Step: 168  | total loss: [1m[32m0.40808[0m[0m | time: 3.929s
[2K
| Adam | epoch: 028 | loss: 0.40808 - acc: 0.8225 | val_loss: 0.54198 - val_acc: 0.7593 -- iter: 172/172
--
Training Step: 169  | total loss: [1m[32m0.37656[0m[0m | time: 0.612s
[2K
| Adam | epoch: 029 | loss: 0.37656 - acc: 0.8403 -- iter: 032/172
[A[ATraining Step: 170  | total loss: [1m[32m0.35473[0m[0m | time: 1.206s
[2K
| Adam | epoch: 029 | loss: 0.35473 - acc: 0.8531 -- iter: 064/172
[A[ATraining Step: 171  | total loss: [1m[32m0.33547[0m[0m | time: 1.810s
[2K
| Adam | epoch: 029 | loss: 0.33547 - acc: 0.8647 -- iter: 096/172
[A[ATraining Step: 172  | total loss: [1m[32m0.32328[0m[0m | time: 2.410s
[2K
| Adam | epoch: 029 | loss: 0.32328 - acc: 0.8689 -- iter: 128/172
[A[ATraining Step: 173  | total loss: [1m[32m0.30461[0m[0m | time: 2.983s
[2K
| Adam | epoch: 029 | loss: 0.30461 - acc: 0.8788 -- iter: 160/172
[A[ATraining Step: 174  | total loss: [1m[32m0.28859[0m[0m | time: 4.229s
[2K
| Adam | epoch: 029 | loss: 0.28859 - acc: 0.8878 | val_loss: 0.76166 - val_acc: 0.7963 -- iter: 172/172
--
Training Step: 175  | total loss: [1m[32m0.27312[0m[0m | time: 0.261s
[2K
| Adam | epoch: 030 | loss: 0.27312 - acc: 0.8907 -- iter: 032/172
[A[ATraining Step: 176  | total loss: [1m[32m0.25224[0m[0m | time: 0.866s
[2K
| Adam | epoch: 030 | loss: 0.25224 - acc: 0.9016 -- iter: 064/172
[A[ATraining Step: 177  | total loss: [1m[32m0.24738[0m[0m | time: 1.477s
[2K
| Adam | epoch: 030 | loss: 0.24738 - acc: 0.9021 -- iter: 096/172
[A[ATraining Step: 178  | total loss: [1m[32m0.24402[0m[0m | time: 2.086s
[2K
| Adam | epoch: 030 | loss: 0.24402 - acc: 0.9025 -- iter: 128/172
[A[ATraining Step: 179  | total loss: [1m[32m0.23422[0m[0m | time: 2.667s
[2K
| Adam | epoch: 030 | loss: 0.23422 - acc: 0.9060 -- iter: 160/172
[A[ATraining Step: 180  | total loss: [1m[32m0.22074[0m[0m | time: 4.280s
[2K
| Adam | epoch: 030 | loss: 0.22074 - acc: 0.9123 | val_loss: 0.71871 - val_acc: 0.7593 -- iter: 172/172
--
Validation AUC:0.8537931034482759
Validation AUPRC:0.8807735367264357
Test AUC:0.8235294117647058
Test AUPRC:0.8752720478324016
BestTestF1Score	0.83	0.51	0.78	0.79	0.88	30	8	12	4	0.3
BestTestMCCScore	0.83	0.51	0.78	0.79	0.88	30	8	12	4	0.3
BestTestAccuracyScore	0.71	0.48	0.7	0.91	0.59	20	2	18	14	0.89
BestValidationF1Score	0.82	0.57	0.78	0.73	0.93	27	10	15	2	0.3
BestValidationMCC	0.82	0.57	0.78	0.73	0.93	27	10	15	2	0.3
BestValidationAccuracy	0.79	0.55	0.78	0.79	0.79	23	6	19	6	0.89
TestPredictions (Threshold:0.3)
CHEMBL426881,TN,INACT,0.009999999776482582	CHEMBL434374,TN,INACT,0.029999999329447746	CHEMBL2313186,TP,ACT,0.8199999928474426	CHEMBL69495,FP,INACT,0.5799999833106995	CHEMBL1079256,FN,ACT,0.25	CHEMBL3661407,FP,INACT,0.8899999856948853	CHEMBL438867,TP,ACT,0.9900000095367432	CHEMBL1256164,TP,ACT,0.9399999976158142	CHEMBL3099591,TN,INACT,0.0	CHEMBL3764795,TP,ACT,0.6399999856948853	CHEMBL218061,TN,INACT,0.03999999910593033	CHEMBL1087722,TP,ACT,0.9599999785423279	CHEMBL3661401,TN,INACT,0.20999999344348907	CHEMBL3661404,TN,INACT,0.20000000298023224	CHEMBL1360431,TP,ACT,0.9599999785423279	CHEMBL551517,TP,ACT,0.9800000190734863	CHEMBL390796,TP,ACT,1.0	CHEMBL1375713,TP,ACT,0.3199999928474426	CHEMBL270302,FP,INACT,0.9900000095367432	CHEMBL204484,TN,INACT,0.20000000298023224	CHEMBL1563200,FN,ACT,0.029999999329447746	CHEMBL2436592,TP,ACT,0.9700000286102295	CHEMBL2392756,TP,ACT,0.7599999904632568	CHEMBL3661346,FP,INACT,0.3400000035762787	CHEMBL476614,TP,ACT,0.9900000095367432	CHEMBL1668416,TN,INACT,0.0	CHEMBL1088688,TP,ACT,0.7599999904632568	CHEMBL3236510,TN,INACT,0.0	CHEMBL3327071,TP,ACT,0.7799999713897705	CHEMBL2031930,TP,ACT,1.0	CHEMBL1258105,TP,ACT,0.9900000095367432	CHEMBL3037907,TN,INACT,0.10999999940395355	CHEMBL245067,TN,INACT,0.07000000029802322	CHEMBL376597,FN,ACT,0.1599999964237213	CHEMBL3222116,TP,ACT,0.4099999964237213	CHEMBL1766284,FN,ACT,0.05000000074505806	CHEMBL3628774,TP,ACT,0.9599999785423279	CHEMBL3402236,FP,INACT,0.5299999713897705	CHEMBL1933516,TP,ACT,0.9900000095367432	CHEMBL519149,TP,ACT,0.9900000095367432	CHEMBL425436,TP,ACT,0.5899999737739563	CHEMBL589374,TP,ACT,1.0	CHEMBL1257879,TP,ACT,0.8399999737739563	CHEMBL3677979,TP,ACT,1.0	CHEMBL3661408,FP,INACT,0.9900000095367432	CHEMBL219695,TN,INACT,0.009999999776482582	CHEMBL1933674,TP,ACT,0.9900000095367432	CHEMBL3628779,TP,ACT,0.9200000166893005	CHEMBL3125288,FP,INACT,0.7099999785423279	CHEMBL1087977,TP,ACT,0.9900000095367432	CHEMBL1818412,TP,ACT,1.0	CHEMBL3818875,TP,ACT,0.8500000238418579	CHEMBL1258785,TP,ACT,0.9900000095367432	CHEMBL3661405,FP,INACT,0.8700000047683716	

