CNNModel CHEMBL4376 adam 0.0005 30 256 0 0.8 False True
Number of active compounds :	107
Number of inactive compounds :	107
---------------------------------
Run id: CNNModel_CHEMBL4376_adam_0.0005_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4376_adam_0.0005_30_256_0.8_True/
---------------------------------
Training samples: 136
Validation samples: 43
--
Training Step: 1  | time: 17.974s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/136
[A[ATraining Step: 2  | total loss: [1m[32m0.62384[0m[0m | time: 80.704s
[2K
| Adam | epoch: 001 | loss: 0.62384 - acc: 0.4219 -- iter: 064/136
[A[ATraining Step: 3  | total loss: [1m[32m0.68058[0m[0m | time: 139.327s
[2K
| Adam | epoch: 001 | loss: 0.68058 - acc: 0.5114 -- iter: 096/136
[A[ATraining Step: 4  | total loss: [1m[32m0.68964[0m[0m | time: 160.558s
[2K
| Adam | epoch: 001 | loss: 0.68964 - acc: 0.5263 -- iter: 128/136
[A[ATraining Step: 5  | total loss: [1m[32m0.69275[0m[0m | time: 175.260s
[2K
| Adam | epoch: 001 | loss: 0.69275 - acc: 0.4865 | val_loss: 0.70172 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 6  | total loss: [1m[32m0.68983[0m[0m | time: 13.879s
[2K
| Adam | epoch: 002 | loss: 0.68983 - acc: 0.5755 -- iter: 032/136
[A[ATraining Step: 7  | total loss: [1m[32m0.68840[0m[0m | time: 41.145s
[2K
| Adam | epoch: 002 | loss: 0.68840 - acc: 0.6052 -- iter: 064/136
[A[ATraining Step: 8  | total loss: [1m[32m0.69178[0m[0m | time: 83.720s
[2K
| Adam | epoch: 002 | loss: 0.69178 - acc: 0.5460 -- iter: 096/136
[A[ATraining Step: 9  | total loss: [1m[32m0.68954[0m[0m | time: 119.423s
[2K
| Adam | epoch: 002 | loss: 0.68954 - acc: 0.5547 -- iter: 128/136
[A[ATraining Step: 10  | total loss: [1m[32m0.69644[0m[0m | time: 170.555s
[2K
| Adam | epoch: 002 | loss: 0.69644 - acc: 0.5117 | val_loss: 0.71701 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 11  | total loss: [1m[32m0.69461[0m[0m | time: 15.821s
[2K
| Adam | epoch: 003 | loss: 0.69461 - acc: 0.5210 -- iter: 032/136
[A[ATraining Step: 12  | total loss: [1m[32m0.67770[0m[0m | time: 22.348s
[2K
| Adam | epoch: 003 | loss: 0.67770 - acc: 0.6240 -- iter: 064/136
[A[ATraining Step: 13  | total loss: [1m[32m0.66546[0m[0m | time: 53.061s
[2K
| Adam | epoch: 003 | loss: 0.66546 - acc: 0.6780 -- iter: 096/136
[A[ATraining Step: 14  | total loss: [1m[32m0.67975[0m[0m | time: 75.842s
[2K
| Adam | epoch: 003 | loss: 0.67975 - acc: 0.6052 -- iter: 128/136
[A[ATraining Step: 15  | total loss: [1m[32m0.68662[0m[0m | time: 139.771s
[2K
| Adam | epoch: 003 | loss: 0.68662 - acc: 0.5763 | val_loss: 0.75886 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 16  | total loss: [1m[32m0.69735[0m[0m | time: 18.083s
[2K
| Adam | epoch: 004 | loss: 0.69735 - acc: 0.5477 -- iter: 032/136
[A[ATraining Step: 17  | total loss: [1m[32m0.69326[0m[0m | time: 21.028s
[2K
| Adam | epoch: 004 | loss: 0.69326 - acc: 0.5530 -- iter: 064/136
[A[ATraining Step: 18  | total loss: [1m[32m0.68268[0m[0m | time: 21.257s
[2K
| Adam | epoch: 004 | loss: 0.68268 - acc: 0.5779 -- iter: 096/136
[A[ATraining Step: 19  | total loss: [1m[32m0.67595[0m[0m | time: 55.893s
[2K
| Adam | epoch: 004 | loss: 0.67595 - acc: 0.5936 -- iter: 128/136
[A[ATraining Step: 20  | total loss: [1m[32m0.68188[0m[0m | time: 126.376s
[2K
| Adam | epoch: 004 | loss: 0.68188 - acc: 0.5736 | val_loss: 0.73740 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 21  | total loss: [1m[32m0.69082[0m[0m | time: 14.381s
[2K
| Adam | epoch: 005 | loss: 0.69082 - acc: 0.5410 -- iter: 032/136
[A[ATraining Step: 22  | total loss: [1m[32m0.68352[0m[0m | time: 22.449s
[2K
| Adam | epoch: 005 | loss: 0.68352 - acc: 0.5662 -- iter: 064/136
[A[ATraining Step: 23  | total loss: [1m[32m0.69036[0m[0m | time: 40.409s
[2K
| Adam | epoch: 005 | loss: 0.69036 - acc: 0.5379 -- iter: 096/136
[A[ATraining Step: 24  | total loss: [1m[32m0.66858[0m[0m | time: 49.427s
[2K
| Adam | epoch: 005 | loss: 0.66858 - acc: 0.6327 -- iter: 128/136
[A[ATraining Step: 25  | total loss: [1m[32m0.65003[0m[0m | time: 98.998s
[2K
| Adam | epoch: 005 | loss: 0.65003 - acc: 0.6988 | val_loss: 0.76691 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 26  | total loss: [1m[32m0.66614[0m[0m | time: 34.867s
[2K
| Adam | epoch: 006 | loss: 0.66614 - acc: 0.6379 -- iter: 032/136
[A[ATraining Step: 27  | total loss: [1m[32m0.68342[0m[0m | time: 56.867s
[2K
| Adam | epoch: 006 | loss: 0.68342 - acc: 0.5864 -- iter: 064/136
[A[ATraining Step: 28  | total loss: [1m[32m0.68416[0m[0m | time: 79.704s
[2K
| Adam | epoch: 006 | loss: 0.68416 - acc: 0.5804 -- iter: 096/136
[A[ATraining Step: 29  | total loss: [1m[32m0.68051[0m[0m | time: 80.183s
[2K
| Adam | epoch: 006 | loss: 0.68051 - acc: 0.5837 -- iter: 128/136
[A[ATraining Step: 30  | total loss: [1m[32m0.68651[0m[0m | time: 107.656s
[2K
| Adam | epoch: 006 | loss: 0.68651 - acc: 0.5638 | val_loss: 0.74348 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 31  | total loss: [1m[32m0.68775[0m[0m | time: 18.646s
[2K
| Adam | epoch: 007 | loss: 0.68775 - acc: 0.5491 -- iter: 032/136
[A[ATraining Step: 32  | total loss: [1m[32m0.69688[0m[0m | time: 37.610s
[2K
| Adam | epoch: 007 | loss: 0.69688 - acc: 0.5170 -- iter: 064/136
[A[ATraining Step: 33  | total loss: [1m[32m0.69469[0m[0m | time: 68.253s
[2K
| Adam | epoch: 007 | loss: 0.69469 - acc: 0.5201 -- iter: 096/136
[A[ATraining Step: 34  | total loss: [1m[32m0.69533[0m[0m | time: 107.823s
[2K
| Adam | epoch: 007 | loss: 0.69533 - acc: 0.5091 -- iter: 128/136
[A[ATraining Step: 35  | total loss: [1m[32m0.69360[0m[0m | time: 140.950s
[2K
| Adam | epoch: 007 | loss: 0.69360 - acc: 0.5137 | val_loss: 0.70381 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 36  | total loss: [1m[32m0.69062[0m[0m | time: 0.337s
[2K
| Adam | epoch: 008 | loss: 0.69062 - acc: 0.5365 -- iter: 032/136
[A[ATraining Step: 37  | total loss: [1m[32m0.68833[0m[0m | time: 9.106s
[2K
| Adam | epoch: 008 | loss: 0.68833 - acc: 0.5542 -- iter: 064/136
[A[ATraining Step: 38  | total loss: [1m[32m0.68849[0m[0m | time: 27.586s
[2K
| Adam | epoch: 008 | loss: 0.68849 - acc: 0.5436 -- iter: 096/136
[A[ATraining Step: 39  | total loss: [1m[32m0.68732[0m[0m | time: 48.824s
[2K
| Adam | epoch: 008 | loss: 0.68732 - acc: 0.5472 -- iter: 128/136
[A[ATraining Step: 40  | total loss: [1m[32m0.68713[0m[0m | time: 72.944s
[2K
| Adam | epoch: 008 | loss: 0.68713 - acc: 0.5442 | val_loss: 0.69883 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 41  | total loss: [1m[32m0.68788[0m[0m | time: 9.806s
[2K
| Adam | epoch: 009 | loss: 0.68788 - acc: 0.5304 -- iter: 032/136
[A[ATraining Step: 42  | total loss: [1m[32m0.68571[0m[0m | time: 20.729s
[2K
| Adam | epoch: 009 | loss: 0.68571 - acc: 0.5474 -- iter: 064/136
[A[ATraining Step: 43  | total loss: [1m[32m0.68358[0m[0m | time: 58.365s
[2K
| Adam | epoch: 009 | loss: 0.68358 - acc: 0.5611 -- iter: 096/136
[A[ATraining Step: 44  | total loss: [1m[32m0.68468[0m[0m | time: 81.479s
[2K
| Adam | epoch: 009 | loss: 0.68468 - acc: 0.5505 -- iter: 128/136
[A[ATraining Step: 45  | total loss: [1m[32m0.68362[0m[0m | time: 128.432s
[2K
| Adam | epoch: 009 | loss: 0.68362 - acc: 0.5526 | val_loss: 0.69623 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 46  | total loss: [1m[32m0.68647[0m[0m | time: 1.240s
[2K
| Adam | epoch: 010 | loss: 0.68647 - acc: 0.5230 -- iter: 032/136
[A[ATraining Step: 47  | total loss: [1m[32m0.68594[0m[0m | time: 3.676s
[2K
| Adam | epoch: 010 | loss: 0.68594 - acc: 0.5192 -- iter: 064/136
[A[ATraining Step: 48  | total loss: [1m[32m0.67916[0m[0m | time: 12.432s
[2K
| Adam | epoch: 010 | loss: 0.67916 - acc: 0.5563 -- iter: 096/136
[A[ATraining Step: 49  | total loss: [1m[32m0.67159[0m[0m | time: 41.756s
[2K
| Adam | epoch: 010 | loss: 0.67159 - acc: 0.5869 -- iter: 128/136
[A[ATraining Step: 50  | total loss: [1m[32m0.66993[0m[0m | time: 83.623s
[2K
| Adam | epoch: 010 | loss: 0.66993 - acc: 0.5879 | val_loss: 0.73499 - val_acc: 0.3488 -- iter: 136/136
--
Training Step: 51  | total loss: [1m[32m0.67023[0m[0m | time: 20.974s
[2K
| Adam | epoch: 011 | loss: 0.67023 - acc: 0.5841 -- iter: 032/136
[A[ATraining Step: 52  | total loss: [1m[32m0.66886[0m[0m | time: 28.729s
[2K
| Adam | epoch: 011 | loss: 0.66886 - acc: 0.5761 -- iter: 064/136
[A[ATraining Step: 53  | total loss: [1m[32m0.67019[0m[0m | time: 37.818s
[2K
| Adam | epoch: 011 | loss: 0.67019 - acc: 0.5649 -- iter: 096/136
[A[ATraining Step: 54  | total loss: [1m[32m0.67552[0m[0m | time: 38.116s
[2K
| Adam | epoch: 011 | loss: 0.67552 - acc: 0.5373 -- iter: 128/136
[A[ATraining Step: 55  | total loss: [1m[32m0.67520[0m[0m | time: 82.401s
[2K
| Adam | epoch: 011 | loss: 0.67520 - acc: 0.5141 | val_loss: 0.66011 - val_acc: 0.8372 -- iter: 136/136
--
Training Step: 56  | total loss: [1m[32m0.67291[0m[0m | time: 12.753s
[2K
| Adam | epoch: 012 | loss: 0.67291 - acc: 0.5297 -- iter: 032/136
[A[ATraining Step: 57  | total loss: [1m[32m0.67426[0m[0m | time: 42.373s
[2K
| Adam | epoch: 012 | loss: 0.67426 - acc: 0.5299 -- iter: 064/136
[A[ATraining Step: 58  | total loss: [1m[32m0.67164[0m[0m | time: 60.821s
[2K
| Adam | epoch: 012 | loss: 0.67164 - acc: 0.5472 -- iter: 096/136
[A[ATraining Step: 59  | total loss: [1m[32m0.67156[0m[0m | time: 79.257s
[2K
| Adam | epoch: 012 | loss: 0.67156 - acc: 0.5618 -- iter: 128/136
[A[ATraining Step: 60  | total loss: [1m[32m0.67155[0m[0m | time: 129.974s
[2K
| Adam | epoch: 012 | loss: 0.67155 - acc: 0.5867 | val_loss: 0.62117 - val_acc: 0.7907 -- iter: 136/136
--
Training Step: 61  | total loss: [1m[32m0.67009[0m[0m | time: 47.722s
[2K
| Adam | epoch: 013 | loss: 0.67009 - acc: 0.6080 -- iter: 032/136
[A[ATraining Step: 62  | total loss: [1m[32m0.66736[0m[0m | time: 109.468s
[2K
| Adam | epoch: 013 | loss: 0.66736 - acc: 0.6142 -- iter: 064/136
[A[ATraining Step: 63  | total loss: [1m[32m0.66276[0m[0m | time: 142.320s
[2K
| Adam | epoch: 013 | loss: 0.66276 - acc: 0.6196 -- iter: 096/136
[A[ATraining Step: 64  | total loss: [1m[32m0.65428[0m[0m | time: 177.488s
[2K
| Adam | epoch: 013 | loss: 0.65428 - acc: 0.6320 -- iter: 128/136
[A[ATraining Step: 65  | total loss: [1m[32m0.64865[0m[0m | time: 202.731s
[2K
| Adam | epoch: 013 | loss: 0.64865 - acc: 0.6388 | val_loss: 0.56114 - val_acc: 0.8140 -- iter: 136/136
--
Training Step: 66  | total loss: [1m[32m0.64797[0m[0m | time: 7.607s
[2K
| Adam | epoch: 014 | loss: 0.64797 - acc: 0.6219 -- iter: 032/136
[A[ATraining Step: 67  | total loss: [1m[32m0.64402[0m[0m | time: 36.358s
[2K
| Adam | epoch: 014 | loss: 0.64402 - acc: 0.6073 -- iter: 064/136
[A[ATraining Step: 68  | total loss: [1m[32m0.63368[0m[0m | time: 50.194s
[2K
| Adam | epoch: 014 | loss: 0.63368 - acc: 0.6168 -- iter: 096/136
[A[ATraining Step: 69  | total loss: [1m[32m0.62102[0m[0m | time: 82.657s
[2K
| Adam | epoch: 014 | loss: 0.62102 - acc: 0.6251 -- iter: 128/136
[A[ATraining Step: 70  | total loss: [1m[32m0.60641[0m[0m | time: 171.550s
[2K
| Adam | epoch: 014 | loss: 0.60641 - acc: 0.6503 | val_loss: 0.44610 - val_acc: 0.7907 -- iter: 136/136
--
Training Step: 71  | total loss: [1m[32m0.59405[0m[0m | time: 14.267s
[2K
| Adam | epoch: 015 | loss: 0.59405 - acc: 0.6616 -- iter: 032/136
[A[ATraining Step: 72  | total loss: [1m[32m0.58673[0m[0m | time: 18.584s
[2K
| Adam | epoch: 015 | loss: 0.58673 - acc: 0.6716 -- iter: 064/136
[A[ATraining Step: 73  | total loss: [1m[32m0.57898[0m[0m | time: 34.299s
[2K
| Adam | epoch: 015 | loss: 0.57898 - acc: 0.6803 -- iter: 096/136
[A[ATraining Step: 74  | total loss: [1m[32m0.57530[0m[0m | time: 54.152s
[2K
| Adam | epoch: 015 | loss: 0.57530 - acc: 0.6811 -- iter: 128/136
[A[ATraining Step: 75  | total loss: [1m[32m0.58013[0m[0m | time: 113.067s
[2K
| Adam | epoch: 015 | loss: 0.58013 - acc: 0.6818 | val_loss: 0.85860 - val_acc: 0.4651 -- iter: 136/136
--
Training Step: 76  | total loss: [1m[32m0.60964[0m[0m | time: 27.359s
[2K
| Adam | epoch: 016 | loss: 0.60964 - acc: 0.6590 -- iter: 032/136
[A[ATraining Step: 77  | total loss: [1m[32m0.64328[0m[0m | time: 28.557s
[2K
| Adam | epoch: 016 | loss: 0.64328 - acc: 0.6388 -- iter: 064/136
[A[ATraining Step: 78  | total loss: [1m[32m0.60898[0m[0m | time: 41.574s
[2K
| Adam | epoch: 016 | loss: 0.60898 - acc: 0.6635 -- iter: 096/136
[A[ATraining Step: 79  | total loss: [1m[32m0.57792[0m[0m | time: 57.718s
[2K
| Adam | epoch: 016 | loss: 0.57792 - acc: 0.6983 -- iter: 128/136
[A[ATraining Step: 80  | total loss: [1m[32m0.58345[0m[0m | time: 63.227s
[2K
| Adam | epoch: 016 | loss: 0.58345 - acc: 0.6908 | val_loss: 0.49292 - val_acc: 0.7907 -- iter: 136/136
--
Training Step: 81  | total loss: [1m[32m0.58529[0m[0m | time: 11.905s
[2K
| Adam | epoch: 017 | loss: 0.58529 - acc: 0.6842 -- iter: 032/136
[A[ATraining Step: 82  | total loss: [1m[32m0.58420[0m[0m | time: 60.936s
[2K
| Adam | epoch: 017 | loss: 0.58420 - acc: 0.6814 -- iter: 064/136
[A[ATraining Step: 83  | total loss: [1m[32m0.56838[0m[0m | time: 76.315s
[2K
| Adam | epoch: 017 | loss: 0.56838 - acc: 0.6976 -- iter: 096/136
[A[ATraining Step: 84  | total loss: [1m[32m0.56014[0m[0m | time: 85.607s
[2K
| Adam | epoch: 017 | loss: 0.56014 - acc: 0.7154 -- iter: 128/136
[A[ATraining Step: 85  | total loss: [1m[32m0.55143[0m[0m | time: 112.921s
[2K
| Adam | epoch: 017 | loss: 0.55143 - acc: 0.7313 | val_loss: 0.51403 - val_acc: 0.8372 -- iter: 136/136
--
Training Step: 86  | total loss: [1m[32m0.54551[0m[0m | time: 10.563s
[2K
| Adam | epoch: 018 | loss: 0.54551 - acc: 0.7426 -- iter: 032/136
[A[ATraining Step: 87  | total loss: [1m[32m0.54666[0m[0m | time: 22.036s
[2K
| Adam | epoch: 018 | loss: 0.54666 - acc: 0.7339 -- iter: 064/136
[A[ATraining Step: 88  | total loss: [1m[32m0.53196[0m[0m | time: 34.720s
[2K
| Adam | epoch: 018 | loss: 0.53196 - acc: 0.7449 -- iter: 096/136
[A[ATraining Step: 89  | total loss: [1m[32m0.53452[0m[0m | time: 45.004s
[2K
| Adam | epoch: 018 | loss: 0.53452 - acc: 0.7329 -- iter: 128/136
[A[ATraining Step: 90  | total loss: [1m[32m0.51669[0m[0m | time: 70.008s
[2K
| Adam | epoch: 018 | loss: 0.51669 - acc: 0.7471 | val_loss: 0.50601 - val_acc: 0.8372 -- iter: 136/136
--
Training Step: 91  | total loss: [1m[32m0.49691[0m[0m | time: 8.356s
[2K
| Adam | epoch: 019 | loss: 0.49691 - acc: 0.7724 -- iter: 032/136
[A[ATraining Step: 92  | total loss: [1m[32m0.48866[0m[0m | time: 21.385s
[2K
| Adam | epoch: 019 | loss: 0.48866 - acc: 0.7764 -- iter: 064/136
[A[ATraining Step: 93  | total loss: [1m[32m0.48396[0m[0m | time: 40.659s
[2K
| Adam | epoch: 019 | loss: 0.48396 - acc: 0.7769 -- iter: 096/136
[A[ATraining Step: 94  | total loss: [1m[32m0.47221[0m[0m | time: 57.283s
[2K
| Adam | epoch: 019 | loss: 0.47221 - acc: 0.7836 -- iter: 128/136
[A[ATraining Step: 95  | total loss: [1m[32m0.47059[0m[0m | time: 80.802s
[2K
| Adam | epoch: 019 | loss: 0.47059 - acc: 0.7865 | val_loss: 0.42629 - val_acc: 0.7907 -- iter: 136/136
--
Training Step: 96  | total loss: [1m[32m0.44424[0m[0m | time: 6.370s
[2K
| Adam | epoch: 020 | loss: 0.44424 - acc: 0.8078 -- iter: 032/136
[A[ATraining Step: 97  | total loss: [1m[32m0.41552[0m[0m | time: 16.438s
[2K
| Adam | epoch: 020 | loss: 0.41552 - acc: 0.8271 -- iter: 064/136
[A[ATraining Step: 98  | total loss: [1m[32m0.42803[0m[0m | time: 23.332s
[2K
| Adam | epoch: 020 | loss: 0.42803 - acc: 0.8193 -- iter: 096/136
[A[ATraining Step: 99  | total loss: [1m[32m0.44123[0m[0m | time: 53.474s
[2K
| Adam | epoch: 020 | loss: 0.44123 - acc: 0.8155 -- iter: 128/136
[A[ATraining Step: 100  | total loss: [1m[32m0.45087[0m[0m | time: 101.276s
[2K
| Adam | epoch: 020 | loss: 0.45087 - acc: 0.8121 | val_loss: 0.64437 - val_acc: 0.8140 -- iter: 136/136
--
Training Step: 101  | total loss: [1m[32m0.45937[0m[0m | time: 11.925s
[2K
| Adam | epoch: 021 | loss: 0.45937 - acc: 0.8090 -- iter: 032/136
[A[ATraining Step: 102  | total loss: [1m[32m0.45153[0m[0m | time: 13.149s
[2K
| Adam | epoch: 021 | loss: 0.45153 - acc: 0.8031 -- iter: 064/136
[A[ATraining Step: 103  | total loss: [1m[32m0.44163[0m[0m | time: 24.323s
[2K
| Adam | epoch: 021 | loss: 0.44163 - acc: 0.8103 -- iter: 096/136
[A[ATraining Step: 104  | total loss: [1m[32m0.44754[0m[0m | time: 39.543s
[2K
| Adam | epoch: 021 | loss: 0.44754 - acc: 0.8012 -- iter: 128/136
[A[ATraining Step: 105  | total loss: [1m[32m0.44869[0m[0m | time: 80.296s
[2K
| Adam | epoch: 021 | loss: 0.44869 - acc: 0.7929 | val_loss: 0.46378 - val_acc: 0.7907 -- iter: 136/136
--
Training Step: 106  | total loss: [1m[32m0.44883[0m[0m | time: 4.160s
[2K
| Adam | epoch: 022 | loss: 0.44883 - acc: 0.7917 -- iter: 032/136
[A[ATraining Step: 107  | total loss: [1m[32m0.44423[0m[0m | time: 11.820s
[2K
| Adam | epoch: 022 | loss: 0.44423 - acc: 0.7938 -- iter: 064/136
[A[ATraining Step: 108  | total loss: [1m[32m0.45310[0m[0m | time: 12.875s
[2K
| Adam | epoch: 022 | loss: 0.45310 - acc: 0.7894 -- iter: 096/136
[A[ATraining Step: 109  | total loss: [1m[32m0.45101[0m[0m | time: 28.494s
[2K
| Adam | epoch: 022 | loss: 0.45101 - acc: 0.7855 -- iter: 128/136
[A[ATraining Step: 110  | total loss: [1m[32m0.44228[0m[0m | time: 46.868s
[2K
| Adam | epoch: 022 | loss: 0.44228 - acc: 0.7851 | val_loss: 0.70272 - val_acc: 0.6977 -- iter: 136/136
--
Training Step: 111  | total loss: [1m[32m0.43730[0m[0m | time: 17.642s
[2K
| Adam | epoch: 023 | loss: 0.43730 - acc: 0.7909 -- iter: 032/136
[A[ATraining Step: 112  | total loss: [1m[32m0.49216[0m[0m | time: 52.031s
[2K
| Adam | epoch: 023 | loss: 0.49216 - acc: 0.7618 -- iter: 064/136
[A[ATraining Step: 113  | total loss: [1m[32m0.48041[0m[0m | time: 64.951s
[2K
| Adam | epoch: 023 | loss: 0.48041 - acc: 0.7669 -- iter: 096/136
[A[ATraining Step: 114  | total loss: [1m[32m0.46041[0m[0m | time: 83.174s
[2K
| Adam | epoch: 023 | loss: 0.46041 - acc: 0.7777 -- iter: 128/136
[A[ATraining Step: 115  | total loss: [1m[32m0.43606[0m[0m | time: 147.571s
[2K
| Adam | epoch: 023 | loss: 0.43606 - acc: 0.7999 | val_loss: 0.45479 - val_acc: 0.8372 -- iter: 136/136
--
Training Step: 116  | total loss: [1m[32m0.42800[0m[0m | time: 7.326s
[2K
| Adam | epoch: 024 | loss: 0.42800 - acc: 0.8106 -- iter: 032/136
[A[ATraining Step: 117  | total loss: [1m[32m0.42236[0m[0m | time: 26.335s
[2K
| Adam | epoch: 024 | loss: 0.42236 - acc: 0.8170 -- iter: 064/136
[A[ATraining Step: 118  | total loss: [1m[32m0.42679[0m[0m | time: 46.301s
[2K
| Adam | epoch: 024 | loss: 0.42679 - acc: 0.8134 -- iter: 096/136
[A[ATraining Step: 119  | total loss: [1m[32m0.41658[0m[0m | time: 50.857s
[2K
| Adam | epoch: 024 | loss: 0.41658 - acc: 0.8227 -- iter: 128/136
[A[ATraining Step: 120  | total loss: [1m[32m0.40582[0m[0m | time: 89.011s
[2K
| Adam | epoch: 024 | loss: 0.40582 - acc: 0.8280 | val_loss: 0.47288 - val_acc: 0.8140 -- iter: 136/136
--
Training Step: 121  | total loss: [1m[32m0.39078[0m[0m | time: 25.023s
[2K
| Adam | epoch: 025 | loss: 0.39078 - acc: 0.8327 -- iter: 032/136
[A[ATraining Step: 122  | total loss: [1m[32m0.38109[0m[0m | time: 52.538s
[2K
| Adam | epoch: 025 | loss: 0.38109 - acc: 0.8431 -- iter: 064/136
[A[ATraining Step: 123  | total loss: [1m[32m0.37440[0m[0m | time: 58.686s
[2K
| Adam | epoch: 025 | loss: 0.37440 - acc: 0.8495 -- iter: 096/136
[A[ATraining Step: 124  | total loss: [1m[32m0.36760[0m[0m | time: 66.037s
[2K
| Adam | epoch: 025 | loss: 0.36760 - acc: 0.8489 -- iter: 128/136
[A[ATraining Step: 125  | total loss: [1m[32m0.36783[0m[0m | time: 83.113s
[2K
| Adam | epoch: 025 | loss: 0.36783 - acc: 0.8421 | val_loss: 0.51308 - val_acc: 0.8140 -- iter: 136/136
--
Training Step: 126  | total loss: [1m[32m0.35130[0m[0m | time: 3.432s
[2K
| Adam | epoch: 026 | loss: 0.35130 - acc: 0.8579 -- iter: 032/136
[A[ATraining Step: 127  | total loss: [1m[32m0.32526[0m[0m | time: 6.600s
[2K
| Adam | epoch: 026 | loss: 0.32526 - acc: 0.8721 -- iter: 064/136
[A[ATraining Step: 128  | total loss: [1m[32m0.32263[0m[0m | time: 19.984s
[2K
| Adam | epoch: 026 | loss: 0.32263 - acc: 0.8755 -- iter: 096/136
[A[ATraining Step: 129  | total loss: [1m[32m0.32772[0m[0m | time: 34.704s
[2K
| Adam | epoch: 026 | loss: 0.32772 - acc: 0.8724 -- iter: 128/136
[A[ATraining Step: 130  | total loss: [1m[32m0.35408[0m[0m | time: 55.880s
[2K
| Adam | epoch: 026 | loss: 0.35408 - acc: 0.8632 | val_loss: 0.48399 - val_acc: 0.7907 -- iter: 136/136
--
Training Step: 131  | total loss: [1m[32m0.35168[0m[0m | time: 3.166s
[2K
| Adam | epoch: 027 | loss: 0.35168 - acc: 0.8644 -- iter: 032/136
[A[ATraining Step: 132  | total loss: [1m[32m0.33070[0m[0m | time: 6.618s
[2K
| Adam | epoch: 027 | loss: 0.33070 - acc: 0.8655 -- iter: 064/136
[A[ATraining Step: 133  | total loss: [1m[32m0.31374[0m[0m | time: 12.627s
[2K
| Adam | epoch: 027 | loss: 0.31374 - acc: 0.8664 -- iter: 096/136
[A[ATraining Step: 134  | total loss: [1m[32m0.29855[0m[0m | time: 22.135s
[2K
| Adam | epoch: 027 | loss: 0.29855 - acc: 0.8767 -- iter: 128/136
[A[ATraining Step: 135  | total loss: [1m[32m0.28549[0m[0m | time: 39.755s
[2K
| Adam | epoch: 027 | loss: 0.28549 - acc: 0.8859 | val_loss: 0.51703 - val_acc: 0.8372 -- iter: 136/136
--
Training Step: 136  | total loss: [1m[32m0.28108[0m[0m | time: 8.611s
[2K
| Adam | epoch: 028 | loss: 0.28108 - acc: 0.8879 -- iter: 032/136
[A[ATraining Step: 137  | total loss: [1m[32m0.26587[0m[0m | time: 10.070s
[2K
| Adam | epoch: 028 | loss: 0.26587 - acc: 0.8960 -- iter: 064/136
[A[ATraining Step: 138  | total loss: [1m[32m0.24514[0m[0m | time: 15.434s
[2K
| Adam | epoch: 028 | loss: 0.24514 - acc: 0.9064 -- iter: 096/136
[A[ATraining Step: 139  | total loss: [1m[32m0.22524[0m[0m | time: 27.419s
[2K
| Adam | epoch: 028 | loss: 0.22524 - acc: 0.9158 -- iter: 128/136
[A[ATraining Step: 140  | total loss: [1m[32m0.23179[0m[0m | time: 45.206s
[2K
| Adam | epoch: 028 | loss: 0.23179 - acc: 0.9086 | val_loss: 0.54888 - val_acc: 0.8372 -- iter: 136/136
--
Training Step: 141  | total loss: [1m[32m0.22264[0m[0m | time: 6.196s
[2K
| Adam | epoch: 029 | loss: 0.22264 - acc: 0.9146 -- iter: 032/136
[A[ATraining Step: 142  | total loss: [1m[32m0.23506[0m[0m | time: 12.976s
[2K
| Adam | epoch: 029 | loss: 0.23506 - acc: 0.9106 -- iter: 064/136
[A[ATraining Step: 143  | total loss: [1m[32m0.23312[0m[0m | time: 14.536s
[2K
| Adam | epoch: 029 | loss: 0.23312 - acc: 0.9102 -- iter: 096/136
[A[ATraining Step: 144  | total loss: [1m[32m0.21547[0m[0m | time: 16.220s
[2K
| Adam | epoch: 029 | loss: 0.21547 - acc: 0.9192 -- iter: 128/136
[A[ATraining Step: 145  | total loss: [1m[32m0.20087[0m[0m | time: 45.085s
[2K
| Adam | epoch: 029 | loss: 0.20087 - acc: 0.9272 | val_loss: 0.56984 - val_acc: 0.7907 -- iter: 136/136
--
Training Step: 146  | total loss: [1m[32m0.19573[0m[0m | time: 14.445s
[2K
| Adam | epoch: 030 | loss: 0.19573 - acc: 0.9283 -- iter: 032/136
[A[ATraining Step: 147  | total loss: [1m[32m0.18287[0m[0m | time: 20.067s
[2K
| Adam | epoch: 030 | loss: 0.18287 - acc: 0.9354 -- iter: 064/136
[A[ATraining Step: 148  | total loss: [1m[32m0.18392[0m[0m | time: 24.948s
[2K
| Adam | epoch: 030 | loss: 0.18392 - acc: 0.9325 -- iter: 096/136
[A[ATraining Step: 149  | total loss: [1m[32m0.17214[0m[0m | time: 25.358s
[2K
| Adam | epoch: 030 | loss: 0.17214 - acc: 0.9393 -- iter: 128/136
[A[ATraining Step: 150  | total loss: [1m[32m0.17060[0m[0m | time: 36.627s
[2K
| Adam | epoch: 030 | loss: 0.17060 - acc: 0.9328 | val_loss: 0.66890 - val_acc: 0.8140 -- iter: 136/136
--
Validation AUC:0.8595238095238096
Validation AUPRC:0.7700240954918787
Test AUC:0.9057017543859649
Test AUPRC:0.9182031086160363
BestTestF1Score	0.8	0.59	0.79	0.86	0.75	18	3	16	6	0.28
BestTestMCCScore	0.8	0.59	0.79	0.86	0.75	18	3	16	6	0.28
BestTestAccuracyScore	0.57	0.41	0.65	0.91	0.42	10	1	18	14	0.98
BestValidationF1Score	0.75	0.61	0.81	0.71	0.8	12	5	23	3	0.28
BestValidationMCC	0.75	0.61	0.81	0.71	0.8	12	5	23	3	0.28
BestValidationAccuracy	0.67	0.58	0.81	0.89	0.53	8	1	27	7	0.98
TestPredictions (Threshold:0.28)
CHEMBL3775393,TP,ACT,1.0	CHEMBL388978,TP,ACT,0.9300000071525574	CHEMBL3774696,FN,ACT,0.18000000715255737	CHEMBL1803071,TP,ACT,1.0	CHEMBL551936,TN,INACT,0.009999999776482582	CHEMBL2392355,TN,INACT,0.11999999731779099	CHEMBL1767294,TN,INACT,0.07000000029802322	CHEMBL1922121,TN,INACT,0.019999999552965164	CHEMBL525538,TN,INACT,0.03999999910593033	CHEMBL1803082,TP,ACT,1.0	CHEMBL1803085,TP,ACT,1.0	CHEMBL2321959,TP,ACT,0.949999988079071	CHEMBL3775111,TP,ACT,1.0	CHEMBL515051,TN,INACT,0.009999999776482582	CHEMBL1767126,TN,INACT,0.009999999776482582	CHEMBL1802852,TP,ACT,1.0	CHEMBL2392237,TN,INACT,0.009999999776482582	CHEMBL1241674,FN,ACT,0.23999999463558197	CHEMBL3589672,TP,ACT,1.0	CHEMBL318485,TN,INACT,0.009999999776482582	CHEMBL475251,TP,ACT,0.699999988079071	CHEMBL1802846,TP,ACT,1.0	CHEMBL457180,TN,INACT,0.0	CHEMBL1908397,FN,ACT,0.1599999964237213	CHEMBL265470,FN,ACT,0.03999999910593033	CHEMBL2321968,TP,ACT,0.7099999785423279	CHEMBL3092863,FN,ACT,0.07000000029802322	CHEMBL560278,TN,INACT,0.0	CHEMBL521851,TP,ACT,0.3799999952316284	CHEMBL3297832,TP,ACT,0.8500000238418579	CHEMBL1803073,TP,ACT,0.7099999785423279	CHEMBL1922120,TN,INACT,0.029999999329447746	CHEMBL1922122,FP,INACT,0.49000000953674316	CHEMBL1802854,TP,ACT,1.0	CHEMBL487526,FP,INACT,0.3100000023841858	CHEMBL1767292,TN,INACT,0.029999999329447746	CHEMBL463384,TN,INACT,0.05000000074505806	CHEMBL456759,TN,INACT,0.0	CHEMBL558601,TN,INACT,0.009999999776482582	CHEMBL2420584,FP,INACT,1.0	CHEMBL1802857,TP,ACT,0.9300000071525574	CHEMBL485053,TP,ACT,0.9900000095367432	CHEMBL249697,FN,ACT,0.009999999776482582	

