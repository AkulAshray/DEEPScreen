CNNModel CHEMBL338 adam 0.0005 15 256 0 0.6 False True
Number of active compounds :	714
Number of inactive compounds :	476
---------------------------------
Run id: CNNModel_CHEMBL338_adam_0.0005_15_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL338_adam_0.0005_15_256_0.6_True/
---------------------------------
Training samples: 649
Validation samples: 204
--
Training Step: 1  | time: 1.307s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/649
[A[ATraining Step: 2  | total loss: [1m[32m0.62388[0m[0m | time: 2.273s
[2K
| Adam | epoch: 001 | loss: 0.62388 - acc: 0.3656 -- iter: 064/649
[A[ATraining Step: 3  | total loss: [1m[32m0.68092[0m[0m | time: 3.197s
[2K
| Adam | epoch: 001 | loss: 0.68092 - acc: 0.4500 -- iter: 096/649
[A[ATraining Step: 4  | total loss: [1m[32m0.68917[0m[0m | time: 4.292s
[2K
| Adam | epoch: 001 | loss: 0.68917 - acc: 0.5578 -- iter: 128/649
[A[ATraining Step: 5  | total loss: [1m[32m0.69209[0m[0m | time: 5.278s
[2K
| Adam | epoch: 001 | loss: 0.69209 - acc: 0.4962 -- iter: 160/649
[A[ATraining Step: 6  | total loss: [1m[32m0.68933[0m[0m | time: 6.226s
[2K
| Adam | epoch: 001 | loss: 0.68933 - acc: 0.5991 -- iter: 192/649
[A[ATraining Step: 7  | total loss: [1m[32m0.68826[0m[0m | time: 7.309s
[2K
| Adam | epoch: 001 | loss: 0.68826 - acc: 0.5959 -- iter: 224/649
[A[ATraining Step: 8  | total loss: [1m[32m0.69090[0m[0m | time: 8.129s
[2K
| Adam | epoch: 001 | loss: 0.69090 - acc: 0.5419 -- iter: 256/649
[A[ATraining Step: 9  | total loss: [1m[32m0.68782[0m[0m | time: 8.750s
[2K
| Adam | epoch: 001 | loss: 0.68782 - acc: 0.5528 -- iter: 288/649
[A[ATraining Step: 10  | total loss: [1m[32m0.68249[0m[0m | time: 9.371s
[2K
| Adam | epoch: 001 | loss: 0.68249 - acc: 0.5733 -- iter: 320/649
[A[ATraining Step: 11  | total loss: [1m[32m0.71633[0m[0m | time: 9.989s
[2K
| Adam | epoch: 001 | loss: 0.71633 - acc: 0.4942 -- iter: 352/649
[A[ATraining Step: 12  | total loss: [1m[32m0.69236[0m[0m | time: 10.607s
[2K
| Adam | epoch: 001 | loss: 0.69236 - acc: 0.5530 -- iter: 384/649
[A[ATraining Step: 13  | total loss: [1m[32m0.68649[0m[0m | time: 11.231s
[2K
| Adam | epoch: 001 | loss: 0.68649 - acc: 0.5705 -- iter: 416/649
[A[ATraining Step: 14  | total loss: [1m[32m0.70011[0m[0m | time: 11.841s
[2K
| Adam | epoch: 001 | loss: 0.70011 - acc: 0.5033 -- iter: 448/649
[A[ATraining Step: 15  | total loss: [1m[32m0.69401[0m[0m | time: 12.447s
[2K
| Adam | epoch: 001 | loss: 0.69401 - acc: 0.5265 -- iter: 480/649
[A[ATraining Step: 16  | total loss: [1m[32m0.68235[0m[0m | time: 13.073s
[2K
| Adam | epoch: 001 | loss: 0.68235 - acc: 0.5986 -- iter: 512/649
[A[ATraining Step: 17  | total loss: [1m[32m0.67856[0m[0m | time: 13.683s
[2K
| Adam | epoch: 001 | loss: 0.67856 - acc: 0.6193 -- iter: 544/649
[A[ATraining Step: 18  | total loss: [1m[32m0.68688[0m[0m | time: 14.297s
[2K
| Adam | epoch: 001 | loss: 0.68688 - acc: 0.5564 -- iter: 576/649
[A[ATraining Step: 19  | total loss: [1m[32m0.68945[0m[0m | time: 14.921s
[2K
| Adam | epoch: 001 | loss: 0.68945 - acc: 0.5376 -- iter: 608/649
[A[ATraining Step: 20  | total loss: [1m[32m0.68704[0m[0m | time: 15.548s
[2K
| Adam | epoch: 001 | loss: 0.68704 - acc: 0.5556 -- iter: 640/649
[A[ATraining Step: 21  | total loss: [1m[32m0.69103[0m[0m | time: 16.813s
[2K
| Adam | epoch: 001 | loss: 0.69103 - acc: 0.5287 | val_loss: 0.68883 - val_acc: 0.5490 -- iter: 649/649
--
Training Step: 22  | total loss: [1m[32m0.70364[0m[0m | time: 0.207s
[2K
| Adam | epoch: 002 | loss: 0.70364 - acc: 0.4367 -- iter: 032/649
[A[ATraining Step: 23  | total loss: [1m[32m0.70965[0m[0m | time: 0.833s
[2K
| Adam | epoch: 002 | loss: 0.70965 - acc: 0.3745 -- iter: 064/649
[A[ATraining Step: 24  | total loss: [1m[32m0.70386[0m[0m | time: 1.451s
[2K
| Adam | epoch: 002 | loss: 0.70386 - acc: 0.4273 -- iter: 096/649
[A[ATraining Step: 25  | total loss: [1m[32m0.69966[0m[0m | time: 2.071s
[2K
| Adam | epoch: 002 | loss: 0.69966 - acc: 0.4727 -- iter: 128/649
[A[ATraining Step: 26  | total loss: [1m[32m0.69726[0m[0m | time: 2.690s
[2K
| Adam | epoch: 002 | loss: 0.69726 - acc: 0.4965 -- iter: 160/649
[A[ATraining Step: 27  | total loss: [1m[32m0.69583[0m[0m | time: 3.306s
[2K
| Adam | epoch: 002 | loss: 0.69583 - acc: 0.5054 -- iter: 192/649
[A[ATraining Step: 28  | total loss: [1m[32m0.69615[0m[0m | time: 3.910s
[2K
| Adam | epoch: 002 | loss: 0.69615 - acc: 0.4728 -- iter: 224/649
[A[ATraining Step: 29  | total loss: [1m[32m0.69565[0m[0m | time: 4.517s
[2K
| Adam | epoch: 002 | loss: 0.69565 - acc: 0.4718 -- iter: 256/649
[A[ATraining Step: 30  | total loss: [1m[32m0.69435[0m[0m | time: 5.151s
[2K
| Adam | epoch: 002 | loss: 0.69435 - acc: 0.5155 -- iter: 288/649
[A[ATraining Step: 31  | total loss: [1m[32m0.69439[0m[0m | time: 5.765s
[2K
| Adam | epoch: 002 | loss: 0.69439 - acc: 0.4903 -- iter: 320/649
[A[ATraining Step: 32  | total loss: [1m[32m0.69372[0m[0m | time: 6.370s
[2K
| Adam | epoch: 002 | loss: 0.69372 - acc: 0.5206 -- iter: 352/649
[A[ATraining Step: 33  | total loss: [1m[32m0.69356[0m[0m | time: 7.005s
[2K
| Adam | epoch: 002 | loss: 0.69356 - acc: 0.5161 -- iter: 384/649
[A[ATraining Step: 34  | total loss: [1m[32m0.69340[0m[0m | time: 7.633s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.5193 -- iter: 416/649
[A[ATraining Step: 35  | total loss: [1m[32m0.69340[0m[0m | time: 8.378s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.5087 -- iter: 448/649
[A[ATraining Step: 36  | total loss: [1m[32m0.69321[0m[0m | time: 9.492s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5197 -- iter: 480/649
[A[ATraining Step: 37  | total loss: [1m[32m0.69334[0m[0m | time: 10.552s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.5033 -- iter: 512/649
[A[ATraining Step: 38  | total loss: [1m[32m0.69319[0m[0m | time: 11.586s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5210 -- iter: 544/649
[A[ATraining Step: 39  | total loss: [1m[32m0.69312[0m[0m | time: 13.695s
[2K
| Adam | epoch: 002 | loss: 0.69312 - acc: 0.5230 -- iter: 576/649
[A[ATraining Step: 40  | total loss: [1m[32m0.69296[0m[0m | time: 14.444s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5362 -- iter: 608/649
[A[ATraining Step: 41  | total loss: [1m[32m0.69270[0m[0m | time: 15.480s
[2K
| Adam | epoch: 002 | loss: 0.69270 - acc: 0.5525 -- iter: 640/649
[A[ATraining Step: 42  | total loss: [1m[32m0.69269[0m[0m | time: 17.515s
[2K
| Adam | epoch: 002 | loss: 0.69269 - acc: 0.5487 | val_loss: 0.69233 - val_acc: 0.5490 -- iter: 649/649
--
Training Step: 43  | total loss: [1m[32m0.69283[0m[0m | time: 0.743s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5346 -- iter: 032/649
[A[ATraining Step: 44  | total loss: [1m[32m0.69205[0m[0m | time: 2.832s
[2K
| Adam | epoch: 003 | loss: 0.69205 - acc: 0.5767 -- iter: 064/649
[A[ATraining Step: 45  | total loss: [1m[32m0.69132[0m[0m | time: 9.517s
[2K
| Adam | epoch: 003 | loss: 0.69132 - acc: 0.6108 -- iter: 096/649
[A[ATraining Step: 46  | total loss: [1m[32m0.69118[0m[0m | time: 18.525s
[2K
| Adam | epoch: 003 | loss: 0.69118 - acc: 0.6132 -- iter: 128/649
[A[ATraining Step: 47  | total loss: [1m[32m0.69134[0m[0m | time: 31.626s
[2K
| Adam | epoch: 003 | loss: 0.69134 - acc: 0.5998 -- iter: 160/649
[A[ATraining Step: 48  | total loss: [1m[32m0.69230[0m[0m | time: 46.663s
[2K
| Adam | epoch: 003 | loss: 0.69230 - acc: 0.5637 -- iter: 192/649
[A[ATraining Step: 49  | total loss: [1m[32m0.69193[0m[0m | time: 47.642s
[2K
| Adam | epoch: 003 | loss: 0.69193 - acc: 0.5684 -- iter: 224/649
[A[ATraining Step: 50  | total loss: [1m[32m0.69157[0m[0m | time: 48.719s
[2K
| Adam | epoch: 003 | loss: 0.69157 - acc: 0.5723 -- iter: 256/649
[A[ATraining Step: 51  | total loss: [1m[32m0.69137[0m[0m | time: 49.696s
[2K
| Adam | epoch: 003 | loss: 0.69137 - acc: 0.5708 -- iter: 288/649
[A[ATraining Step: 52  | total loss: [1m[32m0.69210[0m[0m | time: 50.924s
[2K
| Adam | epoch: 003 | loss: 0.69210 - acc: 0.5508 -- iter: 320/649
[A[ATraining Step: 53  | total loss: [1m[32m0.69159[0m[0m | time: 52.044s
[2K
| Adam | epoch: 003 | loss: 0.69159 - acc: 0.5572 -- iter: 352/649
[A[ATraining Step: 54  | total loss: [1m[32m0.69137[0m[0m | time: 52.916s
[2K
| Adam | epoch: 003 | loss: 0.69137 - acc: 0.5579 -- iter: 384/649
[A[ATraining Step: 55  | total loss: [1m[32m0.69192[0m[0m | time: 54.050s
[2K
| Adam | epoch: 003 | loss: 0.69192 - acc: 0.5452 -- iter: 416/649
[A[ATraining Step: 56  | total loss: [1m[32m0.69249[0m[0m | time: 55.101s
[2K
| Adam | epoch: 003 | loss: 0.69249 - acc: 0.5345 -- iter: 448/649
[A[ATraining Step: 57  | total loss: [1m[32m0.69266[0m[0m | time: 56.161s
[2K
| Adam | epoch: 003 | loss: 0.69266 - acc: 0.5297 -- iter: 480/649
[A[ATraining Step: 58  | total loss: [1m[32m0.69244[0m[0m | time: 59.599s
[2K
| Adam | epoch: 003 | loss: 0.69244 - acc: 0.5299 -- iter: 512/649
[A[ATraining Step: 59  | total loss: [1m[32m0.69257[0m[0m | time: 62.859s
[2K
| Adam | epoch: 003 | loss: 0.69257 - acc: 0.5259 -- iter: 544/649
[A[ATraining Step: 60  | total loss: [1m[32m0.69132[0m[0m | time: 74.650s
[2K
| Adam | epoch: 003 | loss: 0.69132 - acc: 0.5431 -- iter: 576/649
[A[ATraining Step: 61  | total loss: [1m[32m0.69016[0m[0m | time: 75.559s
[2K
| Adam | epoch: 003 | loss: 0.69016 - acc: 0.5579 -- iter: 608/649
[A[ATraining Step: 62  | total loss: [1m[32m0.69168[0m[0m | time: 76.629s
[2K
| Adam | epoch: 003 | loss: 0.69168 - acc: 0.5384 -- iter: 640/649
[A[ATraining Step: 63  | total loss: [1m[32m0.68975[0m[0m | time: 78.872s
[2K
| Adam | epoch: 003 | loss: 0.68975 - acc: 0.5573 | val_loss: 0.68901 - val_acc: 0.5490 -- iter: 649/649
--
Training Step: 64  | total loss: [1m[32m0.69064[0m[0m | time: 21.624s
[2K
| Adam | epoch: 004 | loss: 0.69064 - acc: 0.5462 -- iter: 032/649
[A[ATraining Step: 65  | total loss: [1m[32m0.68984[0m[0m | time: 32.174s
[2K
| Adam | epoch: 004 | loss: 0.68984 - acc: 0.5521 -- iter: 064/649
[A[ATraining Step: 66  | total loss: [1m[32m0.68977[0m[0m | time: 41.658s
[2K
| Adam | epoch: 004 | loss: 0.68977 - acc: 0.5525 -- iter: 096/649
[A[ATraining Step: 67  | total loss: [1m[32m0.68952[0m[0m | time: 56.483s
[2K
| Adam | epoch: 004 | loss: 0.68952 - acc: 0.5529 -- iter: 128/649
[A[ATraining Step: 68  | total loss: [1m[32m0.68969[0m[0m | time: 65.003s
[2K
| Adam | epoch: 004 | loss: 0.68969 - acc: 0.5503 -- iter: 160/649
[A[ATraining Step: 69  | total loss: [1m[32m0.69043[0m[0m | time: 84.269s
[2K
| Adam | epoch: 004 | loss: 0.69043 - acc: 0.5444 -- iter: 192/649
[A[ATraining Step: 70  | total loss: [1m[32m0.69228[0m[0m | time: 85.238s
[2K
| Adam | epoch: 004 | loss: 0.69228 - acc: 0.5321 -- iter: 224/649
[A[ATraining Step: 71  | total loss: [1m[32m0.69159[0m[0m | time: 86.283s
[2K
| Adam | epoch: 004 | loss: 0.69159 - acc: 0.5356 -- iter: 256/649
[A[ATraining Step: 72  | total loss: [1m[32m0.69159[0m[0m | time: 87.371s
[2K
| Adam | epoch: 004 | loss: 0.69159 - acc: 0.5351 -- iter: 288/649
[A[ATraining Step: 73  | total loss: [1m[32m0.69144[0m[0m | time: 88.504s
[2K
| Adam | epoch: 004 | loss: 0.69144 - acc: 0.5346 -- iter: 320/649
[A[ATraining Step: 74  | total loss: [1m[32m0.69079[0m[0m | time: 89.547s
[2K
| Adam | epoch: 004 | loss: 0.69079 - acc: 0.5377 -- iter: 352/649
[A[ATraining Step: 75  | total loss: [1m[32m0.69136[0m[0m | time: 90.555s
[2K
| Adam | epoch: 004 | loss: 0.69136 - acc: 0.5336 -- iter: 384/649
[A[ATraining Step: 76  | total loss: [1m[32m0.69011[0m[0m | time: 91.672s
[2K
| Adam | epoch: 004 | loss: 0.69011 - acc: 0.5401 -- iter: 416/649
[A[ATraining Step: 77  | total loss: [1m[32m0.69008[0m[0m | time: 92.677s
[2K
| Adam | epoch: 004 | loss: 0.69008 - acc: 0.5391 -- iter: 448/649
[A[ATraining Step: 78  | total loss: [1m[32m0.68863[0m[0m | time: 93.298s
[2K
| Adam | epoch: 004 | loss: 0.68863 - acc: 0.5481 -- iter: 480/649
[A[ATraining Step: 79  | total loss: [1m[32m0.68929[0m[0m | time: 93.946s
[2K
| Adam | epoch: 004 | loss: 0.68929 - acc: 0.5431 -- iter: 512/649
[A[ATraining Step: 80  | total loss: [1m[32m0.68896[0m[0m | time: 94.617s
[2K
| Adam | epoch: 004 | loss: 0.68896 - acc: 0.5451 -- iter: 544/649
[A[ATraining Step: 81  | total loss: [1m[32m0.68903[0m[0m | time: 95.278s
[2K
| Adam | epoch: 004 | loss: 0.68903 - acc: 0.5437 -- iter: 576/649
[A[ATraining Step: 82  | total loss: [1m[32m0.68857[0m[0m | time: 95.934s
[2K
| Adam | epoch: 004 | loss: 0.68857 - acc: 0.5456 -- iter: 608/649
[A[ATraining Step: 83  | total loss: [1m[32m0.68602[0m[0m | time: 96.564s
[2K
| Adam | epoch: 004 | loss: 0.68602 - acc: 0.5567 -- iter: 640/649
[A[ATraining Step: 84  | total loss: [1m[32m0.68816[0m[0m | time: 98.214s
[2K
| Adam | epoch: 004 | loss: 0.68816 - acc: 0.5479 | val_loss: 0.68660 - val_acc: 0.5490 -- iter: 649/649
--
Training Step: 85  | total loss: [1m[32m0.68999[0m[0m | time: 0.638s
[2K
| Adam | epoch: 005 | loss: 0.68999 - acc: 0.5400 -- iter: 032/649
[A[ATraining Step: 86  | total loss: [1m[32m0.68998[0m[0m | time: 1.308s
[2K
| Adam | epoch: 005 | loss: 0.68998 - acc: 0.5391 -- iter: 064/649
[A[ATraining Step: 87  | total loss: [1m[32m0.68989[0m[0m | time: 1.533s
[2K
| Adam | epoch: 005 | loss: 0.68989 - acc: 0.5383 -- iter: 096/649
[A[ATraining Step: 88  | total loss: [1m[32m0.68975[0m[0m | time: 1.772s
[2K
| Adam | epoch: 005 | loss: 0.68975 - acc: 0.5400 -- iter: 128/649
[A[ATraining Step: 89  | total loss: [1m[32m0.68931[0m[0m | time: 2.430s
[2K
| Adam | epoch: 005 | loss: 0.68931 - acc: 0.5416 -- iter: 160/649
[A[ATraining Step: 90  | total loss: [1m[32m0.68800[0m[0m | time: 3.075s
[2K
| Adam | epoch: 005 | loss: 0.68800 - acc: 0.5468 -- iter: 192/649
[A[ATraining Step: 91  | total loss: [1m[32m0.68937[0m[0m | time: 3.674s
[2K
| Adam | epoch: 005 | loss: 0.68937 - acc: 0.5390 -- iter: 224/649
[A[ATraining Step: 92  | total loss: [1m[32m0.68933[0m[0m | time: 4.327s
[2K
| Adam | epoch: 005 | loss: 0.68933 - acc: 0.5382 -- iter: 256/649
[A[ATraining Step: 93  | total loss: [1m[32m0.69217[0m[0m | time: 4.938s
[2K
| Adam | epoch: 005 | loss: 0.69217 - acc: 0.5219 -- iter: 288/649
[A[ATraining Step: 94  | total loss: [1m[32m0.69365[0m[0m | time: 5.569s
[2K
| Adam | epoch: 005 | loss: 0.69365 - acc: 0.5103 -- iter: 320/649
[A[ATraining Step: 95  | total loss: [1m[32m0.69097[0m[0m | time: 6.186s
[2K
| Adam | epoch: 005 | loss: 0.69097 - acc: 0.5312 -- iter: 352/649
[A[ATraining Step: 96  | total loss: [1m[32m0.69125[0m[0m | time: 6.813s
[2K
| Adam | epoch: 005 | loss: 0.69125 - acc: 0.5281 -- iter: 384/649
[A[ATraining Step: 97  | total loss: [1m[32m0.69043[0m[0m | time: 7.458s
[2K
| Adam | epoch: 005 | loss: 0.69043 - acc: 0.5346 -- iter: 416/649
[A[ATraining Step: 98  | total loss: [1m[32m0.69028[0m[0m | time: 8.068s
[2K
| Adam | epoch: 005 | loss: 0.69028 - acc: 0.5343 -- iter: 448/649
[A[ATraining Step: 99  | total loss: [1m[32m0.68951[0m[0m | time: 8.716s
[2K
| Adam | epoch: 005 | loss: 0.68951 - acc: 0.5402 -- iter: 480/649
[A[ATraining Step: 100  | total loss: [1m[32m0.68925[0m[0m | time: 9.431s
[2K
| Adam | epoch: 005 | loss: 0.68925 - acc: 0.5425 -- iter: 512/649
[A[ATraining Step: 101  | total loss: [1m[32m0.69067[0m[0m | time: 10.068s
[2K
| Adam | epoch: 005 | loss: 0.69067 - acc: 0.5288 -- iter: 544/649
[A[ATraining Step: 102  | total loss: [1m[32m0.69112[0m[0m | time: 11.263s
[2K
| Adam | epoch: 005 | loss: 0.69112 - acc: 0.5228 -- iter: 576/649
[A[ATraining Step: 103  | total loss: [1m[32m0.69182[0m[0m | time: 12.520s
[2K
| Adam | epoch: 005 | loss: 0.69182 - acc: 0.5174 -- iter: 608/649
[A[ATraining Step: 104  | total loss: [1m[32m0.69176[0m[0m | time: 13.555s
[2K
| Adam | epoch: 005 | loss: 0.69176 - acc: 0.5157 -- iter: 640/649
[A[ATraining Step: 105  | total loss: [1m[32m0.69181[0m[0m | time: 49.625s
[2K
| Adam | epoch: 005 | loss: 0.69181 - acc: 0.5141 | val_loss: 0.68732 - val_acc: 0.5490 -- iter: 649/649
--
Training Step: 106  | total loss: [1m[32m0.69015[0m[0m | time: 1.158s
[2K
| Adam | epoch: 006 | loss: 0.69015 - acc: 0.5315 -- iter: 032/649
[A[ATraining Step: 107  | total loss: [1m[32m0.69113[0m[0m | time: 2.462s
[2K
| Adam | epoch: 006 | loss: 0.69113 - acc: 0.5189 -- iter: 064/649
[A[ATraining Step: 108  | total loss: [1m[32m0.69024[0m[0m | time: 6.961s
[2K
| Adam | epoch: 006 | loss: 0.69024 - acc: 0.5264 -- iter: 096/649
[A[ATraining Step: 109  | total loss: [1m[32m0.68764[0m[0m | time: 9.419s
[2K
| Adam | epoch: 006 | loss: 0.68764 - acc: 0.5488 -- iter: 128/649
[A[ATraining Step: 110  | total loss: [1m[32m0.68598[0m[0m | time: 15.934s
[2K
| Adam | epoch: 006 | loss: 0.68598 - acc: 0.5606 -- iter: 160/649
[A[ATraining Step: 111  | total loss: [1m[32m0.68408[0m[0m | time: 24.636s
[2K
| Adam | epoch: 006 | loss: 0.68408 - acc: 0.5712 -- iter: 192/649
[A[ATraining Step: 112  | total loss: [1m[32m0.68565[0m[0m | time: 25.667s
[2K
| Adam | epoch: 006 | loss: 0.68565 - acc: 0.5641 -- iter: 224/649
[A[ATraining Step: 113  | total loss: [1m[32m0.68664[0m[0m | time: 26.655s
[2K
| Adam | epoch: 006 | loss: 0.68664 - acc: 0.5576 -- iter: 256/649
[A[ATraining Step: 114  | total loss: [1m[32m0.68815[0m[0m | time: 27.715s
[2K
| Adam | epoch: 006 | loss: 0.68815 - acc: 0.5519 -- iter: 288/649
[A[ATraining Step: 115  | total loss: [1m[32m0.68698[0m[0m | time: 28.988s
[2K
| Adam | epoch: 006 | loss: 0.68698 - acc: 0.5529 -- iter: 320/649
[A[ATraining Step: 116  | total loss: [1m[32m0.68636[0m[0m | time: 30.086s
[2K
| Adam | epoch: 006 | loss: 0.68636 - acc: 0.5539 -- iter: 352/649
[A[ATraining Step: 117  | total loss: [1m[32m0.68767[0m[0m | time: 31.044s
[2K
| Adam | epoch: 006 | loss: 0.68767 - acc: 0.5485 -- iter: 384/649
[A[ATraining Step: 118  | total loss: [1m[32m0.68473[0m[0m | time: 32.288s
[2K
| Adam | epoch: 006 | loss: 0.68473 - acc: 0.5562 -- iter: 416/649
[A[ATraining Step: 119  | total loss: [1m[32m0.68651[0m[0m | time: 33.437s
[2K
| Adam | epoch: 006 | loss: 0.68651 - acc: 0.5474 -- iter: 448/649
[A[ATraining Step: 120  | total loss: [1m[32m0.68597[0m[0m | time: 35.681s
[2K
| Adam | epoch: 006 | loss: 0.68597 - acc: 0.5458 -- iter: 480/649
[A[ATraining Step: 121  | total loss: [1m[32m0.68343[0m[0m | time: 41.620s
[2K
| Adam | epoch: 006 | loss: 0.68343 - acc: 0.5537 -- iter: 512/649
[A[ATraining Step: 122  | total loss: [1m[32m0.68479[0m[0m | time: 43.056s
[2K
| Adam | epoch: 006 | loss: 0.68479 - acc: 0.5483 -- iter: 544/649
[A[ATraining Step: 123  | total loss: [1m[32m0.68527[0m[0m | time: 48.773s
[2K
| Adam | epoch: 006 | loss: 0.68527 - acc: 0.5435 -- iter: 576/649
[A[ATraining Step: 124  | total loss: [1m[32m0.68723[0m[0m | time: 49.841s
[2K
| Adam | epoch: 006 | loss: 0.68723 - acc: 0.5329 -- iter: 608/649
[A[ATraining Step: 125  | total loss: [1m[32m0.68735[0m[0m | time: 50.808s
[2K
| Adam | epoch: 006 | loss: 0.68735 - acc: 0.5327 -- iter: 640/649
[A[ATraining Step: 126  | total loss: [1m[32m0.68584[0m[0m | time: 53.270s
[2K
| Adam | epoch: 006 | loss: 0.68584 - acc: 0.5388 | val_loss: 0.68055 - val_acc: 0.5490 -- iter: 649/649
--
Training Step: 127  | total loss: [1m[32m0.68532[0m[0m | time: 18.261s
[2K
| Adam | epoch: 007 | loss: 0.68532 - acc: 0.5350 -- iter: 032/649
[A[ATraining Step: 128  | total loss: [1m[32m0.68246[0m[0m | time: 27.161s
[2K
| Adam | epoch: 007 | loss: 0.68246 - acc: 0.5502 -- iter: 064/649
[A[ATraining Step: 129  | total loss: [1m[32m0.68128[0m[0m | time: 43.996s
[2K
| Adam | epoch: 007 | loss: 0.68128 - acc: 0.5577 -- iter: 096/649
[A[ATraining Step: 130  | total loss: [1m[32m0.68251[0m[0m | time: 44.915s
[2K
| Adam | epoch: 007 | loss: 0.68251 - acc: 0.5457 -- iter: 128/649
[A[ATraining Step: 131  | total loss: [1m[32m0.68107[0m[0m | time: 45.282s
[2K
| Adam | epoch: 007 | loss: 0.68107 - acc: 0.5474 -- iter: 160/649
[A[ATraining Step: 132  | total loss: [1m[32m0.68484[0m[0m | time: 45.648s
[2K
| Adam | epoch: 007 | loss: 0.68484 - acc: 0.5371 -- iter: 192/649
[A[ATraining Step: 133  | total loss: [1m[32m0.68700[0m[0m | time: 46.729s
[2K
| Adam | epoch: 007 | loss: 0.68700 - acc: 0.5278 -- iter: 224/649
[A[ATraining Step: 134  | total loss: [1m[32m0.68587[0m[0m | time: 47.772s
[2K
| Adam | epoch: 007 | loss: 0.68587 - acc: 0.5281 -- iter: 256/649
[A[ATraining Step: 135  | total loss: [1m[32m0.68445[0m[0m | time: 48.900s
[2K
| Adam | epoch: 007 | loss: 0.68445 - acc: 0.5316 -- iter: 288/649
[A[ATraining Step: 136  | total loss: [1m[32m0.68522[0m[0m | time: 49.812s
[2K
| Adam | epoch: 007 | loss: 0.68522 - acc: 0.5253 -- iter: 320/649
[A[ATraining Step: 137  | total loss: [1m[32m0.68607[0m[0m | time: 50.862s
[2K
| Adam | epoch: 007 | loss: 0.68607 - acc: 0.5103 -- iter: 352/649
[A[ATraining Step: 138  | total loss: [1m[32m0.68511[0m[0m | time: 52.016s
[2K
| Adam | epoch: 007 | loss: 0.68511 - acc: 0.5186 -- iter: 384/649
[A[ATraining Step: 139  | total loss: [1m[32m0.68238[0m[0m | time: 52.865s
[2K
| Adam | epoch: 007 | loss: 0.68238 - acc: 0.5293 -- iter: 416/649
[A[ATraining Step: 140  | total loss: [1m[32m0.68084[0m[0m | time: 53.588s
[2K
| Adam | epoch: 007 | loss: 0.68084 - acc: 0.5326 -- iter: 448/649
[A[ATraining Step: 141  | total loss: [1m[32m0.67986[0m[0m | time: 54.221s
[2K
| Adam | epoch: 007 | loss: 0.67986 - acc: 0.5324 -- iter: 480/649
[A[ATraining Step: 142  | total loss: [1m[32m0.67344[0m[0m | time: 54.903s
[2K
| Adam | epoch: 007 | loss: 0.67344 - acc: 0.5480 -- iter: 512/649
[A[ATraining Step: 143  | total loss: [1m[32m0.67571[0m[0m | time: 55.610s
[2K
| Adam | epoch: 007 | loss: 0.67571 - acc: 0.5400 -- iter: 544/649
[A[ATraining Step: 144  | total loss: [1m[32m0.68096[0m[0m | time: 56.244s
[2K
| Adam | epoch: 007 | loss: 0.68096 - acc: 0.5298 -- iter: 576/649
[A[ATraining Step: 145  | total loss: [1m[32m0.68013[0m[0m | time: 56.902s
[2K
| Adam | epoch: 007 | loss: 0.68013 - acc: 0.5331 -- iter: 608/649
[A[ATraining Step: 146  | total loss: [1m[32m0.67991[0m[0m | time: 57.551s
[2K
| Adam | epoch: 007 | loss: 0.67991 - acc: 0.5329 -- iter: 640/649
[A[ATraining Step: 147  | total loss: [1m[32m0.67760[0m[0m | time: 59.257s
[2K
| Adam | epoch: 007 | loss: 0.67760 - acc: 0.5421 | val_loss: 0.66809 - val_acc: 0.6275 -- iter: 649/649
--
Training Step: 148  | total loss: [1m[32m0.67760[0m[0m | time: 0.698s
[2K
| Adam | epoch: 008 | loss: 0.67760 - acc: 0.5348 -- iter: 032/649
[A[ATraining Step: 149  | total loss: [1m[32m0.67488[0m[0m | time: 1.392s
[2K
| Adam | epoch: 008 | loss: 0.67488 - acc: 0.5375 -- iter: 064/649
[A[ATraining Step: 150  | total loss: [1m[32m0.67481[0m[0m | time: 2.062s
[2K
| Adam | epoch: 008 | loss: 0.67481 - acc: 0.5463 -- iter: 096/649
[A[ATraining Step: 151  | total loss: [1m[32m0.67247[0m[0m | time: 2.770s
[2K
| Adam | epoch: 008 | loss: 0.67247 - acc: 0.5416 -- iter: 128/649
[A[ATraining Step: 152  | total loss: [1m[32m0.67154[0m[0m | time: 3.455s
[2K
| Adam | epoch: 008 | loss: 0.67154 - acc: 0.5469 -- iter: 160/649
[A[ATraining Step: 153  | total loss: [1m[32m0.66707[0m[0m | time: 3.683s
[2K
| Adam | epoch: 008 | loss: 0.66707 - acc: 0.5703 -- iter: 192/649
[A[ATraining Step: 154  | total loss: [1m[32m0.66438[0m[0m | time: 3.900s
[2K
| Adam | epoch: 008 | loss: 0.66438 - acc: 0.5799 -- iter: 224/649
[A[ATraining Step: 155  | total loss: [1m[32m0.66175[0m[0m | time: 4.553s
[2K
| Adam | epoch: 008 | loss: 0.66175 - acc: 0.5775 -- iter: 256/649
[A[ATraining Step: 156  | total loss: [1m[32m0.65561[0m[0m | time: 5.247s
[2K
| Adam | epoch: 008 | loss: 0.65561 - acc: 0.5760 -- iter: 288/649
[A[ATraining Step: 157  | total loss: [1m[32m0.64784[0m[0m | time: 5.896s
[2K
| Adam | epoch: 008 | loss: 0.64784 - acc: 0.5871 -- iter: 320/649
[A[ATraining Step: 158  | total loss: [1m[32m0.63854[0m[0m | time: 6.577s
[2K
| Adam | epoch: 008 | loss: 0.63854 - acc: 0.6066 -- iter: 352/649
[A[ATraining Step: 159  | total loss: [1m[32m0.64424[0m[0m | time: 7.252s
[2K
| Adam | epoch: 008 | loss: 0.64424 - acc: 0.6053 -- iter: 384/649
[A[ATraining Step: 160  | total loss: [1m[32m0.64202[0m[0m | time: 8.240s
[2K
| Adam | epoch: 008 | loss: 0.64202 - acc: 0.6010 -- iter: 416/649
[A[ATraining Step: 161  | total loss: [1m[32m0.64034[0m[0m | time: 9.460s
[2K
| Adam | epoch: 008 | loss: 0.64034 - acc: 0.6034 -- iter: 448/649
[A[ATraining Step: 162  | total loss: [1m[32m0.64641[0m[0m | time: 10.562s
[2K
| Adam | epoch: 008 | loss: 0.64641 - acc: 0.5993 -- iter: 480/649
[A[ATraining Step: 163  | total loss: [1m[32m0.63911[0m[0m | time: 11.528s
[2K
| Adam | epoch: 008 | loss: 0.63911 - acc: 0.6144 -- iter: 512/649
[A[ATraining Step: 164  | total loss: [1m[32m0.63907[0m[0m | time: 14.857s
[2K
| Adam | epoch: 008 | loss: 0.63907 - acc: 0.6123 -- iter: 544/649
[A[ATraining Step: 165  | total loss: [1m[32m0.62682[0m[0m | time: 23.736s
[2K
| Adam | epoch: 008 | loss: 0.62682 - acc: 0.6167 -- iter: 576/649
[A[ATraining Step: 166  | total loss: [1m[32m0.62443[0m[0m | time: 24.979s
[2K
| Adam | epoch: 008 | loss: 0.62443 - acc: 0.6144 -- iter: 608/649
[A[ATraining Step: 167  | total loss: [1m[32m0.62181[0m[0m | time: 25.947s
[2K
| Adam | epoch: 008 | loss: 0.62181 - acc: 0.6248 -- iter: 640/649
[A[ATraining Step: 168  | total loss: [1m[32m0.61634[0m[0m | time: 28.263s
[2K
| Adam | epoch: 008 | loss: 0.61634 - acc: 0.6436 | val_loss: 0.74043 - val_acc: 0.5049 -- iter: 649/649
--
Training Step: 169  | total loss: [1m[32m0.62125[0m[0m | time: 1.051s
[2K
| Adam | epoch: 009 | loss: 0.62125 - acc: 0.6386 -- iter: 032/649
[A[ATraining Step: 170  | total loss: [1m[32m0.62712[0m[0m | time: 6.454s
[2K
| Adam | epoch: 009 | loss: 0.62712 - acc: 0.6310 -- iter: 064/649
[A[ATraining Step: 171  | total loss: [1m[32m0.63824[0m[0m | time: 7.519s
[2K
| Adam | epoch: 009 | loss: 0.63824 - acc: 0.6117 -- iter: 096/649
[A[ATraining Step: 172  | total loss: [1m[32m0.63445[0m[0m | time: 8.632s
[2K
| Adam | epoch: 009 | loss: 0.63445 - acc: 0.6161 -- iter: 128/649
[A[ATraining Step: 173  | total loss: [1m[32m0.62213[0m[0m | time: 9.757s
[2K
| Adam | epoch: 009 | loss: 0.62213 - acc: 0.6326 -- iter: 160/649
[A[ATraining Step: 174  | total loss: [1m[32m0.61476[0m[0m | time: 10.924s
[2K
| Adam | epoch: 009 | loss: 0.61476 - acc: 0.6256 -- iter: 192/649
[A[ATraining Step: 175  | total loss: [1m[32m0.60159[0m[0m | time: 11.306s
[2K
| Adam | epoch: 009 | loss: 0.60159 - acc: 0.6349 -- iter: 224/649
[A[ATraining Step: 176  | total loss: [1m[32m0.59625[0m[0m | time: 11.660s
[2K
| Adam | epoch: 009 | loss: 0.59625 - acc: 0.6492 -- iter: 256/649
[A[ATraining Step: 177  | total loss: [1m[32m0.58650[0m[0m | time: 12.519s
[2K
| Adam | epoch: 009 | loss: 0.58650 - acc: 0.6732 -- iter: 288/649
[A[ATraining Step: 178  | total loss: [1m[32m0.58045[0m[0m | time: 13.641s
[2K
| Adam | epoch: 009 | loss: 0.58045 - acc: 0.6809 -- iter: 320/649
[A[ATraining Step: 179  | total loss: [1m[32m0.56708[0m[0m | time: 15.087s
[2K
| Adam | epoch: 009 | loss: 0.56708 - acc: 0.7003 -- iter: 352/649
[A[ATraining Step: 180  | total loss: [1m[32m0.56704[0m[0m | time: 16.993s
[2K
| Adam | epoch: 009 | loss: 0.56704 - acc: 0.6990 -- iter: 384/649
[A[ATraining Step: 181  | total loss: [1m[32m0.56430[0m[0m | time: 20.316s
[2K
| Adam | epoch: 009 | loss: 0.56430 - acc: 0.7010 -- iter: 416/649
[A[ATraining Step: 182  | total loss: [1m[32m0.55443[0m[0m | time: 28.066s
[2K
| Adam | epoch: 009 | loss: 0.55443 - acc: 0.7059 -- iter: 448/649
[A[ATraining Step: 183  | total loss: [1m[32m0.55070[0m[0m | time: 29.035s
[2K
| Adam | epoch: 009 | loss: 0.55070 - acc: 0.6947 -- iter: 480/649
[A[ATraining Step: 184  | total loss: [1m[32m0.54131[0m[0m | time: 30.151s
[2K
| Adam | epoch: 009 | loss: 0.54131 - acc: 0.7033 -- iter: 512/649
[A[ATraining Step: 185  | total loss: [1m[32m0.54003[0m[0m | time: 31.121s
[2K
| Adam | epoch: 009 | loss: 0.54003 - acc: 0.7080 -- iter: 544/649
[A[ATraining Step: 186  | total loss: [1m[32m0.53069[0m[0m | time: 32.174s
[2K
| Adam | epoch: 009 | loss: 0.53069 - acc: 0.7122 -- iter: 576/649
[A[ATraining Step: 187  | total loss: [1m[32m0.54192[0m[0m | time: 33.239s
[2K
| Adam | epoch: 009 | loss: 0.54192 - acc: 0.7097 -- iter: 608/649
[A[ATraining Step: 188  | total loss: [1m[32m0.52462[0m[0m | time: 34.173s
[2K
| Adam | epoch: 009 | loss: 0.52462 - acc: 0.7231 -- iter: 640/649
[A[ATraining Step: 189  | total loss: [1m[32m0.52454[0m[0m | time: 36.976s
[2K
| Adam | epoch: 009 | loss: 0.52454 - acc: 0.7289 | val_loss: 0.62488 - val_acc: 0.6667 -- iter: 649/649
--
Training Step: 190  | total loss: [1m[32m0.51694[0m[0m | time: 11.201s
[2K
| Adam | epoch: 010 | loss: 0.51694 - acc: 0.7310 -- iter: 032/649
[A[ATraining Step: 191  | total loss: [1m[32m0.50886[0m[0m | time: 22.780s
[2K
| Adam | epoch: 010 | loss: 0.50886 - acc: 0.7361 -- iter: 064/649
[A[ATraining Step: 192  | total loss: [1m[32m0.50426[0m[0m | time: 23.727s
[2K
| Adam | epoch: 010 | loss: 0.50426 - acc: 0.7437 -- iter: 096/649
[A[ATraining Step: 193  | total loss: [1m[32m0.50839[0m[0m | time: 24.834s
[2K
| Adam | epoch: 010 | loss: 0.50839 - acc: 0.7475 -- iter: 128/649
[A[ATraining Step: 194  | total loss: [1m[32m0.52064[0m[0m | time: 25.929s
[2K
| Adam | epoch: 010 | loss: 0.52064 - acc: 0.7383 -- iter: 160/649
[A[ATraining Step: 195  | total loss: [1m[32m0.53111[0m[0m | time: 27.124s
[2K
| Adam | epoch: 010 | loss: 0.53111 - acc: 0.7301 -- iter: 192/649
[A[ATraining Step: 196  | total loss: [1m[32m0.52672[0m[0m | time: 28.154s
[2K
| Adam | epoch: 010 | loss: 0.52672 - acc: 0.7290 -- iter: 224/649
[A[ATraining Step: 197  | total loss: [1m[32m0.52096[0m[0m | time: 28.462s
[2K
| Adam | epoch: 010 | loss: 0.52096 - acc: 0.7373 -- iter: 256/649
[A[ATraining Step: 198  | total loss: [1m[32m0.49075[0m[0m | time: 28.790s
[2K
| Adam | epoch: 010 | loss: 0.49075 - acc: 0.7636 -- iter: 288/649
[A[ATraining Step: 199  | total loss: [1m[32m0.46198[0m[0m | time: 30.005s
[2K
| Adam | epoch: 010 | loss: 0.46198 - acc: 0.7872 -- iter: 320/649
[A[ATraining Step: 200  | total loss: [1m[32m0.48482[0m[0m | time: 32.113s
[2K
| Adam | epoch: 010 | loss: 0.48482 - acc: 0.7679 | val_loss: 0.53481 - val_acc: 0.7353 -- iter: 352/649
--
Training Step: 201  | total loss: [1m[32m0.49755[0m[0m | time: 32.799s
[2K
| Adam | epoch: 010 | loss: 0.49755 - acc: 0.7567 -- iter: 384/649
[A[ATraining Step: 202  | total loss: [1m[32m0.49022[0m[0m | time: 33.479s
[2K
| Adam | epoch: 010 | loss: 0.49022 - acc: 0.7592 -- iter: 416/649
[A[ATraining Step: 203  | total loss: [1m[32m0.48540[0m[0m | time: 34.220s
[2K
| Adam | epoch: 010 | loss: 0.48540 - acc: 0.7676 -- iter: 448/649
[A[ATraining Step: 204  | total loss: [1m[32m0.49442[0m[0m | time: 34.906s
[2K
| Adam | epoch: 010 | loss: 0.49442 - acc: 0.7659 -- iter: 480/649
[A[ATraining Step: 205  | total loss: [1m[32m0.48773[0m[0m | time: 35.594s
[2K
| Adam | epoch: 010 | loss: 0.48773 - acc: 0.7643 -- iter: 512/649
[A[ATraining Step: 206  | total loss: [1m[32m0.47410[0m[0m | time: 36.323s
[2K
| Adam | epoch: 010 | loss: 0.47410 - acc: 0.7785 -- iter: 544/649
[A[ATraining Step: 207  | total loss: [1m[32m0.47615[0m[0m | time: 37.006s
[2K
| Adam | epoch: 010 | loss: 0.47615 - acc: 0.7819 -- iter: 576/649
[A[ATraining Step: 208  | total loss: [1m[32m0.46777[0m[0m | time: 37.695s
[2K
| Adam | epoch: 010 | loss: 0.46777 - acc: 0.7849 -- iter: 608/649
[A[ATraining Step: 209  | total loss: [1m[32m0.45547[0m[0m | time: 38.354s
[2K
| Adam | epoch: 010 | loss: 0.45547 - acc: 0.7940 -- iter: 640/649
[A[ATraining Step: 210  | total loss: [1m[32m0.45130[0m[0m | time: 40.039s
[2K
| Adam | epoch: 010 | loss: 0.45130 - acc: 0.8021 | val_loss: 0.52419 - val_acc: 0.7598 -- iter: 649/649
--
Training Step: 211  | total loss: [1m[32m0.45149[0m[0m | time: 0.714s
[2K
| Adam | epoch: 011 | loss: 0.45149 - acc: 0.7937 -- iter: 032/649
[A[ATraining Step: 212  | total loss: [1m[32m0.43143[0m[0m | time: 1.887s
[2K
| Adam | epoch: 011 | loss: 0.43143 - acc: 0.8050 -- iter: 064/649
[A[ATraining Step: 213  | total loss: [1m[32m0.41259[0m[0m | time: 3.219s
[2K
| Adam | epoch: 011 | loss: 0.41259 - acc: 0.8182 -- iter: 096/649
[A[ATraining Step: 214  | total loss: [1m[32m0.39946[0m[0m | time: 4.243s
[2K
| Adam | epoch: 011 | loss: 0.39946 - acc: 0.8270 -- iter: 128/649
[A[ATraining Step: 215  | total loss: [1m[32m0.39000[0m[0m | time: 11.661s
[2K
| Adam | epoch: 011 | loss: 0.39000 - acc: 0.8350 -- iter: 160/649
[A[ATraining Step: 216  | total loss: [1m[32m0.39526[0m[0m | time: 17.013s
[2K
| Adam | epoch: 011 | loss: 0.39526 - acc: 0.8358 -- iter: 192/649
[A[ATraining Step: 217  | total loss: [1m[32m0.38062[0m[0m | time: 18.032s
[2K
| Adam | epoch: 011 | loss: 0.38062 - acc: 0.8429 -- iter: 224/649
[A[ATraining Step: 218  | total loss: [1m[32m0.37867[0m[0m | time: 19.027s
[2K
| Adam | epoch: 011 | loss: 0.37867 - acc: 0.8461 -- iter: 256/649
[A[ATraining Step: 219  | total loss: [1m[32m0.36212[0m[0m | time: 19.424s
[2K
| Adam | epoch: 011 | loss: 0.36212 - acc: 0.8521 -- iter: 288/649
[A[ATraining Step: 220  | total loss: [1m[32m0.37924[0m[0m | time: 19.814s
[2K
| Adam | epoch: 011 | loss: 0.37924 - acc: 0.8336 -- iter: 320/649
[A[ATraining Step: 221  | total loss: [1m[32m0.37126[0m[0m | time: 20.932s
[2K
| Adam | epoch: 011 | loss: 0.37126 - acc: 0.8391 -- iter: 352/649
[A[ATraining Step: 222  | total loss: [1m[32m0.35557[0m[0m | time: 22.057s
[2K
| Adam | epoch: 011 | loss: 0.35557 - acc: 0.8521 -- iter: 384/649
[A[ATraining Step: 223  | total loss: [1m[32m0.35305[0m[0m | time: 22.990s
[2K
| Adam | epoch: 011 | loss: 0.35305 - acc: 0.8544 -- iter: 416/649
[A[ATraining Step: 224  | total loss: [1m[32m0.36009[0m[0m | time: 24.210s
[2K
| Adam | epoch: 011 | loss: 0.36009 - acc: 0.8533 -- iter: 448/649
[A[ATraining Step: 225  | total loss: [1m[32m0.36535[0m[0m | time: 25.376s
[2K
| Adam | epoch: 011 | loss: 0.36535 - acc: 0.8461 -- iter: 480/649
[A[ATraining Step: 226  | total loss: [1m[32m0.35350[0m[0m | time: 26.532s
[2K
| Adam | epoch: 011 | loss: 0.35350 - acc: 0.8490 -- iter: 512/649
[A[ATraining Step: 227  | total loss: [1m[32m0.36366[0m[0m | time: 27.549s
[2K
| Adam | epoch: 011 | loss: 0.36366 - acc: 0.8422 -- iter: 544/649
[A[ATraining Step: 228  | total loss: [1m[32m0.36927[0m[0m | time: 28.564s
[2K
| Adam | epoch: 011 | loss: 0.36927 - acc: 0.8455 -- iter: 576/649
[A[ATraining Step: 229  | total loss: [1m[32m0.36033[0m[0m | time: 29.670s
[2K
| Adam | epoch: 011 | loss: 0.36033 - acc: 0.8484 -- iter: 608/649
[A[ATraining Step: 230  | total loss: [1m[32m0.36061[0m[0m | time: 30.762s
[2K
| Adam | epoch: 011 | loss: 0.36061 - acc: 0.8480 -- iter: 640/649
[A[ATraining Step: 231  | total loss: [1m[32m0.34494[0m[0m | time: 33.104s
[2K
| Adam | epoch: 011 | loss: 0.34494 - acc: 0.8569 | val_loss: 0.59266 - val_acc: 0.7157 -- iter: 649/649
--
Training Step: 232  | total loss: [1m[32m0.32583[0m[0m | time: 1.099s
[2K
| Adam | epoch: 012 | loss: 0.32583 - acc: 0.8712 -- iter: 032/649
[A[ATraining Step: 233  | total loss: [1m[32m0.33415[0m[0m | time: 2.261s
[2K
| Adam | epoch: 012 | loss: 0.33415 - acc: 0.8622 -- iter: 064/649
[A[ATraining Step: 234  | total loss: [1m[32m0.32013[0m[0m | time: 3.228s
[2K
| Adam | epoch: 012 | loss: 0.32013 - acc: 0.8698 -- iter: 096/649
[A[ATraining Step: 235  | total loss: [1m[32m0.30452[0m[0m | time: 4.466s
[2K
| Adam | epoch: 012 | loss: 0.30452 - acc: 0.8765 -- iter: 128/649
[A[ATraining Step: 236  | total loss: [1m[32m0.30642[0m[0m | time: 5.721s
[2K
| Adam | epoch: 012 | loss: 0.30642 - acc: 0.8701 -- iter: 160/649
[A[ATraining Step: 237  | total loss: [1m[32m0.29407[0m[0m | time: 6.668s
[2K
| Adam | epoch: 012 | loss: 0.29407 - acc: 0.8769 -- iter: 192/649
[A[ATraining Step: 238  | total loss: [1m[32m0.29344[0m[0m | time: 7.897s
[2K
| Adam | epoch: 012 | loss: 0.29344 - acc: 0.8798 -- iter: 224/649
[A[ATraining Step: 239  | total loss: [1m[32m0.28653[0m[0m | time: 10.608s
[2K
| Adam | epoch: 012 | loss: 0.28653 - acc: 0.8824 -- iter: 256/649
[A[ATraining Step: 240  | total loss: [1m[32m0.29651[0m[0m | time: 11.682s
[2K
| Adam | epoch: 012 | loss: 0.29651 - acc: 0.8755 -- iter: 288/649
[A[ATraining Step: 241  | total loss: [1m[32m0.28800[0m[0m | time: 12.014s
[2K
| Adam | epoch: 012 | loss: 0.28800 - acc: 0.8785 -- iter: 320/649
[A[ATraining Step: 242  | total loss: [1m[32m0.26617[0m[0m | time: 12.397s
[2K
| Adam | epoch: 012 | loss: 0.26617 - acc: 0.8907 -- iter: 352/649
[A[ATraining Step: 243  | total loss: [1m[32m0.24644[0m[0m | time: 13.466s
[2K
| Adam | epoch: 012 | loss: 0.24644 - acc: 0.9016 -- iter: 384/649
[A[ATraining Step: 244  | total loss: [1m[32m0.24703[0m[0m | time: 14.582s
[2K
| Adam | epoch: 012 | loss: 0.24703 - acc: 0.9021 -- iter: 416/649
[A[ATraining Step: 245  | total loss: [1m[32m0.25106[0m[0m | time: 15.683s
[2K
| Adam | epoch: 012 | loss: 0.25106 - acc: 0.8994 -- iter: 448/649
[A[ATraining Step: 246  | total loss: [1m[32m0.24135[0m[0m | time: 16.571s
[2K
| Adam | epoch: 012 | loss: 0.24135 - acc: 0.9032 -- iter: 480/649
[A[ATraining Step: 247  | total loss: [1m[32m0.24213[0m[0m | time: 17.735s
[2K
| Adam | epoch: 012 | loss: 0.24213 - acc: 0.9035 -- iter: 512/649
[A[ATraining Step: 248  | total loss: [1m[32m0.24688[0m[0m | time: 18.817s
[2K
| Adam | epoch: 012 | loss: 0.24688 - acc: 0.9069 -- iter: 544/649
[A[ATraining Step: 249  | total loss: [1m[32m0.23405[0m[0m | time: 19.535s
[2K
| Adam | epoch: 012 | loss: 0.23405 - acc: 0.9162 -- iter: 576/649
[A[ATraining Step: 250  | total loss: [1m[32m0.22533[0m[0m | time: 20.224s
[2K
| Adam | epoch: 012 | loss: 0.22533 - acc: 0.9183 -- iter: 608/649
[A[ATraining Step: 251  | total loss: [1m[32m0.21417[0m[0m | time: 20.925s
[2K
| Adam | epoch: 012 | loss: 0.21417 - acc: 0.9234 -- iter: 640/649
[A[ATraining Step: 252  | total loss: [1m[32m0.20924[0m[0m | time: 22.628s
[2K
| Adam | epoch: 012 | loss: 0.20924 - acc: 0.9248 | val_loss: 0.60888 - val_acc: 0.7696 -- iter: 649/649
--
Training Step: 253  | total loss: [1m[32m0.20355[0m[0m | time: 0.713s
[2K
| Adam | epoch: 013 | loss: 0.20355 - acc: 0.9229 -- iter: 032/649
[A[ATraining Step: 254  | total loss: [1m[32m0.36199[0m[0m | time: 1.428s
[2K
| Adam | epoch: 013 | loss: 0.36199 - acc: 0.8869 -- iter: 064/649
[A[ATraining Step: 255  | total loss: [1m[32m0.34187[0m[0m | time: 2.124s
[2K
| Adam | epoch: 013 | loss: 0.34187 - acc: 0.8951 -- iter: 096/649
[A[ATraining Step: 256  | total loss: [1m[32m0.31403[0m[0m | time: 2.842s
[2K
| Adam | epoch: 013 | loss: 0.31403 - acc: 0.9056 -- iter: 128/649
[A[ATraining Step: 257  | total loss: [1m[32m0.29655[0m[0m | time: 3.524s
[2K
| Adam | epoch: 013 | loss: 0.29655 - acc: 0.9088 -- iter: 160/649
[A[ATraining Step: 258  | total loss: [1m[32m0.28586[0m[0m | time: 4.217s
[2K
| Adam | epoch: 013 | loss: 0.28586 - acc: 0.9148 -- iter: 192/649
[A[ATraining Step: 259  | total loss: [1m[32m0.27954[0m[0m | time: 4.923s
[2K
| Adam | epoch: 013 | loss: 0.27954 - acc: 0.9202 -- iter: 224/649
[A[ATraining Step: 260  | total loss: [1m[32m0.26222[0m[0m | time: 5.578s
[2K
| Adam | epoch: 013 | loss: 0.26222 - acc: 0.9281 -- iter: 256/649
[A[ATraining Step: 261  | total loss: [1m[32m0.25812[0m[0m | time: 6.222s
[2K
| Adam | epoch: 013 | loss: 0.25812 - acc: 0.9291 -- iter: 288/649
[A[ATraining Step: 262  | total loss: [1m[32m0.25095[0m[0m | time: 6.921s
[2K
| Adam | epoch: 013 | loss: 0.25095 - acc: 0.9268 -- iter: 320/649
[A[ATraining Step: 263  | total loss: [1m[32m0.24450[0m[0m | time: 7.161s
[2K
| Adam | epoch: 013 | loss: 0.24450 - acc: 0.9279 -- iter: 352/649
[A[ATraining Step: 264  | total loss: [1m[32m0.22427[0m[0m | time: 7.395s
[2K
| Adam | epoch: 013 | loss: 0.22427 - acc: 0.9351 -- iter: 384/649
[A[ATraining Step: 265  | total loss: [1m[32m0.20699[0m[0m | time: 8.072s
[2K
| Adam | epoch: 013 | loss: 0.20699 - acc: 0.9416 -- iter: 416/649
[A[ATraining Step: 266  | total loss: [1m[32m0.20429[0m[0m | time: 8.738s
[2K
| Adam | epoch: 013 | loss: 0.20429 - acc: 0.9380 -- iter: 448/649
[A[ATraining Step: 267  | total loss: [1m[32m0.20325[0m[0m | time: 9.419s
[2K
| Adam | epoch: 013 | loss: 0.20325 - acc: 0.9317 -- iter: 480/649
[A[ATraining Step: 268  | total loss: [1m[32m0.19221[0m[0m | time: 10.477s
[2K
| Adam | epoch: 013 | loss: 0.19221 - acc: 0.9354 -- iter: 512/649
[A[ATraining Step: 269  | total loss: [1m[32m0.20023[0m[0m | time: 11.595s
[2K
| Adam | epoch: 013 | loss: 0.20023 - acc: 0.9325 -- iter: 544/649
[A[ATraining Step: 270  | total loss: [1m[32m0.18899[0m[0m | time: 12.866s
[2K
| Adam | epoch: 013 | loss: 0.18899 - acc: 0.9361 -- iter: 576/649
[A[ATraining Step: 271  | total loss: [1m[32m0.17662[0m[0m | time: 13.757s
[2K
| Adam | epoch: 013 | loss: 0.17662 - acc: 0.9425 -- iter: 608/649
[A[ATraining Step: 272  | total loss: [1m[32m0.17689[0m[0m | time: 14.829s
[2K
| Adam | epoch: 013 | loss: 0.17689 - acc: 0.9420 -- iter: 640/649
[A[ATraining Step: 273  | total loss: [1m[32m0.18196[0m[0m | time: 17.234s
[2K
| Adam | epoch: 013 | loss: 0.18196 - acc: 0.9353 | val_loss: 0.69305 - val_acc: 0.7598 -- iter: 649/649
--
Training Step: 274  | total loss: [1m[32m0.18017[0m[0m | time: 1.267s
[2K
| Adam | epoch: 014 | loss: 0.18017 - acc: 0.9355 -- iter: 032/649
[A[ATraining Step: 275  | total loss: [1m[32m0.16981[0m[0m | time: 2.169s
[2K
| Adam | epoch: 014 | loss: 0.16981 - acc: 0.9389 -- iter: 064/649
[A[ATraining Step: 276  | total loss: [1m[32m0.16036[0m[0m | time: 3.220s
[2K
| Adam | epoch: 014 | loss: 0.16036 - acc: 0.9418 -- iter: 096/649
[A[ATraining Step: 277  | total loss: [1m[32m0.15317[0m[0m | time: 4.321s
[2K
| Adam | epoch: 014 | loss: 0.15317 - acc: 0.9445 -- iter: 128/649
[A[ATraining Step: 278  | total loss: [1m[32m0.14281[0m[0m | time: 5.456s
[2K
| Adam | epoch: 014 | loss: 0.14281 - acc: 0.9501 -- iter: 160/649
[A[ATraining Step: 279  | total loss: [1m[32m0.13827[0m[0m | time: 6.565s
[2K
| Adam | epoch: 014 | loss: 0.13827 - acc: 0.9488 -- iter: 192/649
[A[ATraining Step: 280  | total loss: [1m[32m0.12896[0m[0m | time: 7.577s
[2K
| Adam | epoch: 014 | loss: 0.12896 - acc: 0.9539 -- iter: 224/649
[A[ATraining Step: 281  | total loss: [1m[32m0.13384[0m[0m | time: 8.707s
[2K
| Adam | epoch: 014 | loss: 0.13384 - acc: 0.9554 -- iter: 256/649
[A[ATraining Step: 282  | total loss: [1m[32m0.12254[0m[0m | time: 9.876s
[2K
| Adam | epoch: 014 | loss: 0.12254 - acc: 0.9599 -- iter: 288/649
[A[ATraining Step: 283  | total loss: [1m[32m0.11442[0m[0m | time: 11.061s
[2K
| Adam | epoch: 014 | loss: 0.11442 - acc: 0.9639 -- iter: 320/649
[A[ATraining Step: 284  | total loss: [1m[32m0.10845[0m[0m | time: 12.034s
[2K
| Adam | epoch: 014 | loss: 0.10845 - acc: 0.9644 -- iter: 352/649
[A[ATraining Step: 285  | total loss: [1m[32m0.10179[0m[0m | time: 12.410s
[2K
| Adam | epoch: 014 | loss: 0.10179 - acc: 0.9679 -- iter: 384/649
[A[ATraining Step: 286  | total loss: [1m[32m0.10768[0m[0m | time: 12.786s
[2K
| Adam | epoch: 014 | loss: 0.10768 - acc: 0.9600 -- iter: 416/649
[A[ATraining Step: 287  | total loss: [1m[32m0.09964[0m[0m | time: 13.909s
[2K
| Adam | epoch: 014 | loss: 0.09964 - acc: 0.9640 -- iter: 448/649
[A[ATraining Step: 288  | total loss: [1m[32m0.10060[0m[0m | time: 14.944s
[2K
| Adam | epoch: 014 | loss: 0.10060 - acc: 0.9614 -- iter: 480/649
[A[ATraining Step: 289  | total loss: [1m[32m0.09257[0m[0m | time: 16.142s
[2K
| Adam | epoch: 014 | loss: 0.09257 - acc: 0.9652 -- iter: 512/649
[A[ATraining Step: 290  | total loss: [1m[32m0.09115[0m[0m | time: 17.139s
[2K
| Adam | epoch: 014 | loss: 0.09115 - acc: 0.9656 -- iter: 544/649
[A[ATraining Step: 291  | total loss: [1m[32m0.09431[0m[0m | time: 18.028s
[2K
| Adam | epoch: 014 | loss: 0.09431 - acc: 0.9659 -- iter: 576/649
[A[ATraining Step: 292  | total loss: [1m[32m0.08705[0m[0m | time: 19.289s
[2K
| Adam | epoch: 014 | loss: 0.08705 - acc: 0.9693 -- iter: 608/649
[A[ATraining Step: 293  | total loss: [1m[32m0.08733[0m[0m | time: 20.810s
[2K
| Adam | epoch: 014 | loss: 0.08733 - acc: 0.9693 -- iter: 640/649
[A[ATraining Step: 294  | total loss: [1m[32m0.08490[0m[0m | time: 38.908s
[2K
| Adam | epoch: 014 | loss: 0.08490 - acc: 0.9692 | val_loss: 0.79321 - val_acc: 0.7402 -- iter: 649/649
--
Training Step: 295  | total loss: [1m[32m0.09535[0m[0m | time: 1.020s
[2K
| Adam | epoch: 015 | loss: 0.09535 - acc: 0.9629 -- iter: 032/649
[A[ATraining Step: 296  | total loss: [1m[32m0.14594[0m[0m | time: 1.821s
[2K
| Adam | epoch: 015 | loss: 0.14594 - acc: 0.9447 -- iter: 064/649
[A[ATraining Step: 297  | total loss: [1m[32m0.14840[0m[0m | time: 2.537s
[2K
| Adam | epoch: 015 | loss: 0.14840 - acc: 0.9471 -- iter: 096/649
[A[ATraining Step: 298  | total loss: [1m[32m0.17265[0m[0m | time: 3.236s
[2K
| Adam | epoch: 015 | loss: 0.17265 - acc: 0.9431 -- iter: 128/649
[A[ATraining Step: 299  | total loss: [1m[32m0.17009[0m[0m | time: 3.938s
[2K
| Adam | epoch: 015 | loss: 0.17009 - acc: 0.9363 -- iter: 160/649
[A[ATraining Step: 300  | total loss: [1m[32m0.17078[0m[0m | time: 4.581s
[2K
| Adam | epoch: 015 | loss: 0.17078 - acc: 0.9364 -- iter: 192/649
[A[ATraining Step: 301  | total loss: [1m[32m0.15772[0m[0m | time: 5.274s
[2K
| Adam | epoch: 015 | loss: 0.15772 - acc: 0.9427 -- iter: 224/649
[A[ATraining Step: 302  | total loss: [1m[32m0.14330[0m[0m | time: 5.915s
[2K
| Adam | epoch: 015 | loss: 0.14330 - acc: 0.9485 -- iter: 256/649
[A[ATraining Step: 303  | total loss: [1m[32m0.14510[0m[0m | time: 6.527s
[2K
| Adam | epoch: 015 | loss: 0.14510 - acc: 0.9474 -- iter: 288/649
[A[ATraining Step: 304  | total loss: [1m[32m0.15067[0m[0m | time: 7.211s
[2K
| Adam | epoch: 015 | loss: 0.15067 - acc: 0.9464 -- iter: 320/649
[A[ATraining Step: 305  | total loss: [1m[32m0.14229[0m[0m | time: 7.899s
[2K
| Adam | epoch: 015 | loss: 0.14229 - acc: 0.9486 -- iter: 352/649
[A[ATraining Step: 306  | total loss: [1m[32m0.13296[0m[0m | time: 8.601s
[2K
| Adam | epoch: 015 | loss: 0.13296 - acc: 0.9506 -- iter: 384/649
[A[ATraining Step: 307  | total loss: [1m[32m0.13733[0m[0m | time: 8.844s
[2K
| Adam | epoch: 015 | loss: 0.13733 - acc: 0.9493 -- iter: 416/649
[A[ATraining Step: 308  | total loss: [1m[32m0.12846[0m[0m | time: 9.095s
[2K
| Adam | epoch: 015 | loss: 0.12846 - acc: 0.9544 -- iter: 448/649
[A[ATraining Step: 309  | total loss: [1m[32m0.11824[0m[0m | time: 9.746s
[2K
| Adam | epoch: 015 | loss: 0.11824 - acc: 0.9589 -- iter: 480/649
[A[ATraining Step: 310  | total loss: [1m[32m0.12442[0m[0m | time: 10.401s
[2K
| Adam | epoch: 015 | loss: 0.12442 - acc: 0.9568 -- iter: 512/649
[A[ATraining Step: 311  | total loss: [1m[32m0.11455[0m[0m | time: 11.070s
[2K
| Adam | epoch: 015 | loss: 0.11455 - acc: 0.9611 -- iter: 544/649
[A[ATraining Step: 312  | total loss: [1m[32m0.10624[0m[0m | time: 11.759s
[2K
| Adam | epoch: 015 | loss: 0.10624 - acc: 0.9650 -- iter: 576/649
[A[ATraining Step: 313  | total loss: [1m[32m0.10010[0m[0m | time: 12.441s
[2K
| Adam | epoch: 015 | loss: 0.10010 - acc: 0.9685 -- iter: 608/649
[A[ATraining Step: 314  | total loss: [1m[32m0.09622[0m[0m | time: 13.131s
[2K
| Adam | epoch: 015 | loss: 0.09622 - acc: 0.9717 -- iter: 640/649
[A[ATraining Step: 315  | total loss: [1m[32m0.09562[0m[0m | time: 14.838s
[2K
| Adam | epoch: 015 | loss: 0.09562 - acc: 0.9714 | val_loss: 0.69012 - val_acc: 0.7696 -- iter: 649/649
--
Validation AUC:0.8393827639751553
Validation AUPRC:0.8299910926010463
Test AUC:0.8578044934962554
Test AUPRC:0.8614821756972858
BestTestF1Score	0.85	0.61	0.81	0.79	0.92	108	29	57	10	0.33
BestTestMCCScore	0.85	0.61	0.81	0.79	0.92	108	29	57	10	0.33
BestTestAccuracyScore	0.85	0.61	0.81	0.79	0.92	108	29	57	10	0.33
BestValidationF1Score	0.84	0.61	0.8	0.77	0.92	103	31	61	9	0.33
BestValidationMCC	0.84	0.61	0.8	0.77	0.92	103	31	61	9	0.33
BestValidationAccuracy	0.84	0.61	0.8	0.77	0.92	103	31	61	9	0.33
TestPredictions (Threshold:0.33)
CHEMBL243204,TN,INACT,0.05999999865889549	CHEMBL2403791,TN,INACT,0.25	CHEMBL145942,TP,ACT,0.9800000190734863	CHEMBL3289567,TN,INACT,0.009999999776482582	CHEMBL3099486,TP,ACT,0.5899999737739563	CHEMBL258370,TN,INACT,0.14000000059604645	CHEMBL2096874,FP,INACT,1.0	CHEMBL32181,TP,ACT,0.8100000023841858	CHEMBL37736,TN,INACT,0.03999999910593033	CHEMBL432737,TN,INACT,0.0	CHEMBL142642,TP,ACT,0.8999999761581421	CHEMBL249807,FP,INACT,0.9700000286102295	CHEMBL1201192,TP,ACT,1.0	CHEMBL1202020,TP,ACT,0.9800000190734863	CHEMBL3126724,FP,INACT,0.7400000095367432	CHEMBL249329,TN,INACT,0.10000000149011612	CHEMBL540360,TN,INACT,0.10000000149011612	CHEMBL290662,TP,ACT,0.3799999952316284	CHEMBL1253698,TP,ACT,0.9700000286102295	CHEMBL3085024,TP,ACT,1.0	CHEMBL366993,TP,ACT,0.9900000095367432	CHEMBL2326029,FP,INACT,0.4399999976158142	CHEMBL78166,TN,INACT,0.009999999776482582	CHEMBL2387677,TN,INACT,0.05999999865889549	CHEMBL773,FP,INACT,0.8799999952316284	CHEMBL472577,TN,INACT,0.0	CHEMBL3397797,TP,ACT,0.5799999833106995	CHEMBL245637,TP,ACT,0.44999998807907104	CHEMBL3289291,TN,INACT,0.009999999776482582	CHEMBL436295,TN,INACT,0.009999999776482582	CHEMBL250008,FP,INACT,0.9399999976158142	CHEMBL2375176,TP,ACT,0.9900000095367432	CHEMBL1214843,FN,ACT,0.019999999552965164	CHEMBL144348,TP,ACT,0.9800000190734863	CHEMBL471211,TP,ACT,0.4000000059604645	CHEMBL603863,TN,INACT,0.009999999776482582	CHEMBL480988,TN,INACT,0.05000000074505806	CHEMBL3357048,TN,INACT,0.009999999776482582	CHEMBL473310,TN,INACT,0.03999999910593033	CHEMBL179498,TP,ACT,0.9900000095367432	CHEMBL294365,TP,ACT,0.6700000166893005	CHEMBL31361,TP,ACT,1.0	CHEMBL12619,TP,ACT,1.0	CHEMBL399429,FP,INACT,0.9599999785423279	CHEMBL606826,TP,ACT,0.9800000190734863	CHEMBL104567,TP,ACT,1.0	CHEMBL3403588,FP,INACT,1.0	CHEMBL3099489,TP,ACT,0.8100000023841858	CHEMBL18025,TP,ACT,0.47999998927116394	CHEMBL327432,TP,ACT,1.0	CHEMBL2414182,TN,INACT,0.019999999552965164	CHEMBL21115,FN,ACT,0.1599999964237213	CHEMBL455633,FP,INACT,0.9300000071525574	CHEMBL2112763,TP,ACT,1.0	CHEMBL249214,FP,INACT,0.8100000023841858	CHEMBL3398494,TN,INACT,0.009999999776482582	CHEMBL287389,TP,ACT,0.5600000023841858	CHEMBL471001,FP,INACT,0.9599999785423279	CHEMBL579221,TP,ACT,0.9900000095367432	CHEMBL1159820,TN,INACT,0.009999999776482582	CHEMBL327963,TN,INACT,0.029999999329447746	CHEMBL136499,TP,ACT,0.9800000190734863	CHEMBL537654,TP,ACT,1.0	CHEMBL372709,TP,ACT,0.9599999785423279	CHEMBL1178924,TP,ACT,0.9900000095367432	CHEMBL1253839,TP,ACT,0.9700000286102295	CHEMBL2414186,TN,INACT,0.009999999776482582	CHEMBL51771,TP,ACT,1.0	CHEMBL383572,TP,ACT,0.9900000095367432	CHEMBL554446,TP,ACT,0.9399999976158142	CHEMBL293527,TN,INACT,0.009999999776482582	CHEMBL28867,TP,ACT,0.9800000190734863	CHEMBL544633,TP,ACT,0.5799999833106995	CHEMBL336413,TP,ACT,0.9599999785423279	CHEMBL1253378,TP,ACT,1.0	CHEMBL543736,TP,ACT,1.0	CHEMBL23974,TP,ACT,0.9900000095367432	CHEMBL1672376,FP,INACT,0.9900000095367432	CHEMBL217627,TP,ACT,1.0	CHEMBL116374,TP,ACT,0.9900000095367432	CHEMBL1077884,TN,INACT,0.12999999523162842	CHEMBL279461,TP,ACT,0.9900000095367432	CHEMBL83296,TP,ACT,1.0	CHEMBL3403559,TN,INACT,0.009999999776482582	CHEMBL217160,TP,ACT,0.8799999952316284	CHEMBL1171650,TN,INACT,0.019999999552965164	CHEMBL3695490,FN,ACT,0.3199999928474426	CHEMBL200344,TP,ACT,0.9399999976158142	CHEMBL332097,TN,INACT,0.019999999552965164	CHEMBL3289296,TN,INACT,0.009999999776482582	CHEMBL102327,TP,ACT,0.46000000834465027	CHEMBL284367,FN,ACT,0.009999999776482582	CHEMBL3126742,FP,INACT,0.6200000047683716	CHEMBL2326023,TN,INACT,0.009999999776482582	CHEMBL257745,TP,ACT,0.4699999988079071	CHEMBL50901,FP,INACT,0.9900000095367432	CHEMBL541898,FN,ACT,0.029999999329447746	CHEMBL158111,TN,INACT,0.019999999552965164	CHEMBL434361,TP,ACT,1.0	CHEMBL217022,TP,ACT,1.0	CHEMBL473118,FP,INACT,0.9900000095367432	CHEMBL476568,TN,INACT,0.019999999552965164	CHEMBL2114393,TP,ACT,0.9900000095367432	CHEMBL28149,TP,ACT,1.0	CHEMBL284394,TP,ACT,0.5899999737739563	CHEMBL541825,TP,ACT,0.9900000095367432	CHEMBL2414174,TN,INACT,0.0	CHEMBL60614,FP,INACT,0.6000000238418579	CHEMBL493384,TN,INACT,0.05000000074505806	CHEMBL362395,TP,ACT,0.949999988079071	CHEMBL82807,TP,ACT,1.0	CHEMBL337020,FN,ACT,0.05999999865889549	CHEMBL3403571,TN,INACT,0.029999999329447746	CHEMBL1203373,TP,ACT,1.0	CHEMBL61335,TP,ACT,1.0	CHEMBL430561,TP,ACT,1.0	CHEMBL64102,FP,INACT,0.47999998927116394	CHEMBL318755,TP,ACT,1.0	CHEMBL388759,TP,ACT,1.0	CHEMBL3397808,TP,ACT,0.6600000262260437	CHEMBL3403570,TN,INACT,0.0	CHEMBL105218,TN,INACT,0.05999999865889549	CHEMBL3084883,TP,ACT,1.0	CHEMBL3289290,TN,INACT,0.0	CHEMBL1253212,TP,ACT,0.9900000095367432	CHEMBL514198,FP,INACT,1.0	CHEMBL3085022,FN,ACT,0.07999999821186066	CHEMBL38653,TP,ACT,0.9900000095367432	CHEMBL421862,TP,ACT,0.6299999952316284	CHEMBL538322,FP,INACT,0.46000000834465027	CHEMBL20724,TN,INACT,0.009999999776482582	CHEMBL293438,TP,ACT,0.9900000095367432	CHEMBL2310878,TP,ACT,0.9700000286102295	CHEMBL119385,TN,INACT,0.019999999552965164	CHEMBL1237344,FN,ACT,0.23999999463558197	CHEMBL537429,TP,ACT,0.9700000286102295	CHEMBL308528,TN,INACT,0.019999999552965164	CHEMBL189989,TP,ACT,1.0	CHEMBL544145,TN,INACT,0.2199999988079071	CHEMBL112280,TP,ACT,0.9900000095367432	CHEMBL431299,TP,ACT,0.9800000190734863	CHEMBL135858,TP,ACT,0.7099999785423279	CHEMBL290799,TP,ACT,0.9900000095367432	CHEMBL261737,TP,ACT,0.5299999713897705	CHEMBL129962,FN,ACT,0.2800000011920929	CHEMBL2236987,FP,INACT,0.5600000023841858	CHEMBL1077897,TN,INACT,0.009999999776482582	CHEMBL321940,TP,ACT,0.9599999785423279	CHEMBL2310882,FN,ACT,0.03999999910593033	CHEMBL1289973,TP,ACT,0.9900000095367432	CHEMBL33903,TP,ACT,0.8100000023841858	CHEMBL157757,TP,ACT,0.949999988079071	CHEMBL1215762,TP,ACT,0.9800000190734863	CHEMBL171007,FP,INACT,0.9900000095367432	CHEMBL396082,FP,INACT,0.6000000238418579	CHEMBL372975,TP,ACT,0.9800000190734863	CHEMBL378330,TN,INACT,0.3100000023841858	CHEMBL402924,FP,INACT,0.9900000095367432	CHEMBL159423,TP,ACT,1.0	CHEMBL3775704,TN,INACT,0.019999999552965164	CHEMBL3403607,TN,INACT,0.009999999776482582	CHEMBL1253310,TP,ACT,0.949999988079071	CHEMBL65346,TP,ACT,1.0	CHEMBL390743,TP,ACT,1.0	CHEMBL3698963,TP,ACT,0.949999988079071	CHEMBL34990,TP,ACT,0.9900000095367432	CHEMBL269445,TP,ACT,0.9900000095367432	CHEMBL544721,TP,ACT,1.0	CHEMBL369693,TP,ACT,0.9900000095367432	CHEMBL1762478,FP,INACT,0.9800000190734863	CHEMBL186918,TP,ACT,0.8500000238418579	CHEMBL434080,TP,ACT,1.0	CHEMBL3115211,TN,INACT,0.009999999776482582	CHEMBL3698970,TP,ACT,0.9800000190734863	CHEMBL125678,TP,ACT,0.9700000286102295	CHEMBL264262,FP,INACT,0.6499999761581421	CHEMBL65917,TP,ACT,0.9800000190734863	CHEMBL10971,TN,INACT,0.11999999731779099	CHEMBL149437,TP,ACT,0.9900000095367432	CHEMBL1078920,TN,INACT,0.009999999776482582	CHEMBL335901,TP,ACT,0.5899999737739563	CHEMBL456222,TN,INACT,0.029999999329447746	CHEMBL3403567,TN,INACT,0.009999999776482582	CHEMBL434959,FP,INACT,0.6600000262260437	CHEMBL202910,FP,INACT,0.8999999761581421	CHEMBL329553,TP,ACT,0.9900000095367432	CHEMBL1917040,TN,INACT,0.019999999552965164	CHEMBL2414178,TN,INACT,0.019999999552965164	CHEMBL1078836,TN,INACT,0.009999999776482582	CHEMBL149801,TP,ACT,0.9800000190734863	CHEMBL495916,TN,INACT,0.009999999776482582	CHEMBL1196025,TN,INACT,0.029999999329447746	CHEMBL298285,FP,INACT,0.44999998807907104	CHEMBL93011,TP,ACT,0.9900000095367432	CHEMBL38666,TP,ACT,0.8299999833106995	CHEMBL2326022,TN,INACT,0.009999999776482582	CHEMBL96,TN,INACT,0.1899999976158142	CHEMBL97887,TP,ACT,0.9800000190734863	CHEMBL159657,TP,ACT,0.9800000190734863	CHEMBL512665,FP,INACT,0.8700000047683716	CHEMBL1947052,TP,ACT,0.46000000834465027	CHEMBL327055,TP,ACT,1.0	CHEMBL23034,TP,ACT,0.9700000286102295	CHEMBL61529,TP,ACT,1.0	

