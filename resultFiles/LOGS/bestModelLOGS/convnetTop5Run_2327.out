CNNModel CHEMBL3464 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	300
Number of inactive compounds :	300
---------------------------------
Run id: CNNModel_CHEMBL3464_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3464_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 342
Validation samples: 108
--
Training Step: 1  | time: 1.346s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/342
[A[ATraining Step: 2  | total loss: [1m[32m0.62374[0m[0m | time: 2.329s
[2K
| Adam | epoch: 001 | loss: 0.62374 - acc: 0.3937 -- iter: 064/342
[A[ATraining Step: 3  | total loss: [1m[32m0.68018[0m[0m | time: 3.389s
[2K
| Adam | epoch: 001 | loss: 0.68018 - acc: 0.5063 -- iter: 096/342
[A[ATraining Step: 4  | total loss: [1m[32m0.68776[0m[0m | time: 4.292s
[2K
| Adam | epoch: 001 | loss: 0.68776 - acc: 0.5484 -- iter: 128/342
[A[ATraining Step: 5  | total loss: [1m[32m0.69190[0m[0m | time: 5.412s
[2K
| Adam | epoch: 001 | loss: 0.69190 - acc: 0.5149 -- iter: 160/342
[A[ATraining Step: 6  | total loss: [1m[32m0.69377[0m[0m | time: 6.555s
[2K
| Adam | epoch: 001 | loss: 0.69377 - acc: 0.5053 -- iter: 192/342
[A[ATraining Step: 7  | total loss: [1m[32m0.69856[0m[0m | time: 7.700s
[2K
| Adam | epoch: 001 | loss: 0.69856 - acc: 0.4646 -- iter: 224/342
[A[ATraining Step: 8  | total loss: [1m[32m0.69605[0m[0m | time: 8.565s
[2K
| Adam | epoch: 001 | loss: 0.69605 - acc: 0.4669 -- iter: 256/342
[A[ATraining Step: 9  | total loss: [1m[32m0.69270[0m[0m | time: 9.512s
[2K
| Adam | epoch: 001 | loss: 0.69270 - acc: 0.5341 -- iter: 288/342
[A[ATraining Step: 10  | total loss: [1m[32m0.69316[0m[0m | time: 10.527s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5170 -- iter: 320/342
[A[ATraining Step: 11  | total loss: [1m[32m0.69385[0m[0m | time: 12.385s
[2K
| Adam | epoch: 001 | loss: 0.69385 - acc: 0.4794 | val_loss: 0.69254 - val_acc: 0.5741 -- iter: 342/342
--
Training Step: 12  | total loss: [1m[32m0.69403[0m[0m | time: 0.778s
[2K
| Adam | epoch: 002 | loss: 0.69403 - acc: 0.4477 -- iter: 032/342
[A[ATraining Step: 13  | total loss: [1m[32m0.69385[0m[0m | time: 1.820s
[2K
| Adam | epoch: 002 | loss: 0.69385 - acc: 0.4312 -- iter: 064/342
[A[ATraining Step: 14  | total loss: [1m[32m0.69359[0m[0m | time: 3.266s
[2K
| Adam | epoch: 002 | loss: 0.69359 - acc: 0.4338 -- iter: 096/342
[A[ATraining Step: 15  | total loss: [1m[32m0.69325[0m[0m | time: 3.959s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4964 -- iter: 128/342
[A[ATraining Step: 16  | total loss: [1m[32m0.69338[0m[0m | time: 4.779s
[2K
| Adam | epoch: 002 | loss: 0.69338 - acc: 0.4977 -- iter: 160/342
[A[ATraining Step: 17  | total loss: [1m[32m0.69292[0m[0m | time: 5.656s
[2K
| Adam | epoch: 002 | loss: 0.69292 - acc: 0.5210 -- iter: 192/342
[A[ATraining Step: 18  | total loss: [1m[32m0.69341[0m[0m | time: 6.493s
[2K
| Adam | epoch: 002 | loss: 0.69341 - acc: 0.4921 -- iter: 224/342
[A[ATraining Step: 19  | total loss: [1m[32m0.69449[0m[0m | time: 7.342s
[2K
| Adam | epoch: 002 | loss: 0.69449 - acc: 0.4531 -- iter: 256/342
[A[ATraining Step: 20  | total loss: [1m[32m0.69363[0m[0m | time: 8.207s
[2K
| Adam | epoch: 002 | loss: 0.69363 - acc: 0.4883 -- iter: 288/342
[A[ATraining Step: 21  | total loss: [1m[32m0.69151[0m[0m | time: 9.072s
[2K
| Adam | epoch: 002 | loss: 0.69151 - acc: 0.5792 -- iter: 320/342
[A[ATraining Step: 22  | total loss: [1m[32m0.69245[0m[0m | time: 11.012s
[2K
| Adam | epoch: 002 | loss: 0.69245 - acc: 0.5367 | val_loss: 0.69630 - val_acc: 0.4259 -- iter: 342/342
--
Training Step: 23  | total loss: [1m[32m0.69214[0m[0m | time: 0.512s
[2K
| Adam | epoch: 003 | loss: 0.69214 - acc: 0.5442 -- iter: 032/342
[A[ATraining Step: 24  | total loss: [1m[32m0.69497[0m[0m | time: 1.057s
[2K
| Adam | epoch: 003 | loss: 0.69497 - acc: 0.4678 -- iter: 064/342
[A[ATraining Step: 25  | total loss: [1m[32m0.69674[0m[0m | time: 1.885s
[2K
| Adam | epoch: 003 | loss: 0.69674 - acc: 0.4146 -- iter: 096/342
[A[ATraining Step: 26  | total loss: [1m[32m0.69538[0m[0m | time: 2.737s
[2K
| Adam | epoch: 003 | loss: 0.69538 - acc: 0.4538 -- iter: 128/342
[A[ATraining Step: 27  | total loss: [1m[32m0.69482[0m[0m | time: 3.582s
[2K
| Adam | epoch: 003 | loss: 0.69482 - acc: 0.4657 -- iter: 160/342
[A[ATraining Step: 28  | total loss: [1m[32m0.69448[0m[0m | time: 4.436s
[2K
| Adam | epoch: 003 | loss: 0.69448 - acc: 0.4742 -- iter: 192/342
[A[ATraining Step: 29  | total loss: [1m[32m0.69454[0m[0m | time: 5.310s
[2K
| Adam | epoch: 003 | loss: 0.69454 - acc: 0.4577 -- iter: 224/342
[A[ATraining Step: 30  | total loss: [1m[32m0.69381[0m[0m | time: 6.170s
[2K
| Adam | epoch: 003 | loss: 0.69381 - acc: 0.4973 -- iter: 256/342
[A[ATraining Step: 31  | total loss: [1m[32m0.69377[0m[0m | time: 7.038s
[2K
| Adam | epoch: 003 | loss: 0.69377 - acc: 0.4907 -- iter: 288/342
[A[ATraining Step: 32  | total loss: [1m[32m0.69352[0m[0m | time: 7.859s
[2K
| Adam | epoch: 003 | loss: 0.69352 - acc: 0.4998 -- iter: 320/342
[A[ATraining Step: 33  | total loss: [1m[32m0.69347[0m[0m | time: 9.895s
[2K
| Adam | epoch: 003 | loss: 0.69347 - acc: 0.4999 | val_loss: 0.69379 - val_acc: 0.4259 -- iter: 342/342
--
Training Step: 34  | total loss: [1m[32m0.69342[0m[0m | time: 0.896s
[2K
| Adam | epoch: 004 | loss: 0.69342 - acc: 0.4999 -- iter: 032/342
[A[ATraining Step: 35  | total loss: [1m[32m0.69340[0m[0m | time: 1.507s
[2K
| Adam | epoch: 004 | loss: 0.69340 - acc: 0.4934 -- iter: 064/342
[A[ATraining Step: 36  | total loss: [1m[32m0.69297[0m[0m | time: 2.147s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5412 -- iter: 096/342
[A[ATraining Step: 37  | total loss: [1m[32m0.69258[0m[0m | time: 3.033s
[2K
| Adam | epoch: 004 | loss: 0.69258 - acc: 0.5784 -- iter: 128/342
[A[ATraining Step: 38  | total loss: [1m[32m0.69305[0m[0m | time: 3.793s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5325 -- iter: 160/342
[A[ATraining Step: 39  | total loss: [1m[32m0.69277[0m[0m | time: 4.778s
[2K
| Adam | epoch: 004 | loss: 0.69277 - acc: 0.5502 -- iter: 192/342
[A[ATraining Step: 40  | total loss: [1m[32m0.69302[0m[0m | time: 5.772s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5291 -- iter: 224/342
[A[ATraining Step: 41  | total loss: [1m[32m0.69299[0m[0m | time: 6.617s
[2K
| Adam | epoch: 004 | loss: 0.69299 - acc: 0.5295 -- iter: 256/342
[A[ATraining Step: 42  | total loss: [1m[32m0.69304[0m[0m | time: 7.334s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5242 -- iter: 288/342
[A[ATraining Step: 43  | total loss: [1m[32m0.69271[0m[0m | time: 8.219s
[2K
| Adam | epoch: 004 | loss: 0.69271 - acc: 0.5420 -- iter: 320/342
[A[ATraining Step: 44  | total loss: [1m[32m0.69287[0m[0m | time: 10.099s
[2K
| Adam | epoch: 004 | loss: 0.69287 - acc: 0.5293 | val_loss: 0.69472 - val_acc: 0.4259 -- iter: 342/342
--
Training Step: 45  | total loss: [1m[32m0.69276[0m[0m | time: 0.834s
[2K
| Adam | epoch: 005 | loss: 0.69276 - acc: 0.5349 -- iter: 032/342
[A[ATraining Step: 46  | total loss: [1m[32m0.69282[0m[0m | time: 1.794s
[2K
| Adam | epoch: 005 | loss: 0.69282 - acc: 0.5291 -- iter: 064/342
[A[ATraining Step: 47  | total loss: [1m[32m0.69299[0m[0m | time: 2.515s
[2K
| Adam | epoch: 005 | loss: 0.69299 - acc: 0.5192 -- iter: 096/342
[A[ATraining Step: 48  | total loss: [1m[32m0.69287[0m[0m | time: 3.164s
[2K
| Adam | epoch: 005 | loss: 0.69287 - acc: 0.5234 -- iter: 128/342
[A[ATraining Step: 49  | total loss: [1m[32m0.69270[0m[0m | time: 3.871s
[2K
| Adam | epoch: 005 | loss: 0.69270 - acc: 0.5269 -- iter: 160/342
[A[ATraining Step: 50  | total loss: [1m[32m0.69304[0m[0m | time: 4.659s
[2K
| Adam | epoch: 005 | loss: 0.69304 - acc: 0.5130 -- iter: 192/342
[A[ATraining Step: 51  | total loss: [1m[32m0.69285[0m[0m | time: 5.482s
[2K
| Adam | epoch: 005 | loss: 0.69285 - acc: 0.5206 -- iter: 224/342
[A[ATraining Step: 52  | total loss: [1m[32m0.69304[0m[0m | time: 6.360s
[2K
| Adam | epoch: 005 | loss: 0.69304 - acc: 0.5128 -- iter: 256/342
[A[ATraining Step: 53  | total loss: [1m[32m0.69358[0m[0m | time: 7.221s
[2K
| Adam | epoch: 005 | loss: 0.69358 - acc: 0.4925 -- iter: 288/342
[A[ATraining Step: 54  | total loss: [1m[32m0.69318[0m[0m | time: 8.085s
[2K
| Adam | epoch: 005 | loss: 0.69318 - acc: 0.5072 -- iter: 320/342
[A[ATraining Step: 55  | total loss: [1m[32m0.69309[0m[0m | time: 9.963s
[2K
| Adam | epoch: 005 | loss: 0.69309 - acc: 0.5106 | val_loss: 0.69511 - val_acc: 0.4259 -- iter: 342/342
--
Training Step: 56  | total loss: [1m[32m0.69343[0m[0m | time: 0.832s
[2K
| Adam | epoch: 006 | loss: 0.69343 - acc: 0.4959 -- iter: 032/342
[A[ATraining Step: 57  | total loss: [1m[32m0.69342[0m[0m | time: 1.711s
[2K
| Adam | epoch: 006 | loss: 0.69342 - acc: 0.4965 -- iter: 064/342
[A[ATraining Step: 58  | total loss: [1m[32m0.69328[0m[0m | time: 2.651s
[2K
| Adam | epoch: 006 | loss: 0.69328 - acc: 0.5012 -- iter: 096/342
[A[ATraining Step: 59  | total loss: [1m[32m0.69246[0m[0m | time: 3.282s
[2K
| Adam | epoch: 006 | loss: 0.69246 - acc: 0.5347 -- iter: 128/342
[A[ATraining Step: 60  | total loss: [1m[32m0.69273[0m[0m | time: 3.885s
[2K
| Adam | epoch: 006 | loss: 0.69273 - acc: 0.5241 -- iter: 160/342
[A[ATraining Step: 61  | total loss: [1m[32m0.69293[0m[0m | time: 4.796s
[2K
| Adam | epoch: 006 | loss: 0.69293 - acc: 0.5150 -- iter: 192/342
[A[ATraining Step: 62  | total loss: [1m[32m0.69295[0m[0m | time: 5.679s
[2K
| Adam | epoch: 006 | loss: 0.69295 - acc: 0.5131 -- iter: 224/342
[A[ATraining Step: 63  | total loss: [1m[32m0.69301[0m[0m | time: 6.518s
[2K
| Adam | epoch: 006 | loss: 0.69301 - acc: 0.5114 -- iter: 256/342
[A[ATraining Step: 64  | total loss: [1m[32m0.69235[0m[0m | time: 7.475s
[2K
| Adam | epoch: 006 | loss: 0.69235 - acc: 0.5334 -- iter: 288/342
[A[ATraining Step: 65  | total loss: [1m[32m0.69256[0m[0m | time: 8.488s
[2K
| Adam | epoch: 006 | loss: 0.69256 - acc: 0.5254 -- iter: 320/342
[A[ATraining Step: 66  | total loss: [1m[32m0.69201[0m[0m | time: 10.425s
[2K
| Adam | epoch: 006 | loss: 0.69201 - acc: 0.5414 | val_loss: 0.69600 - val_acc: 0.4259 -- iter: 342/342
--
Training Step: 67  | total loss: [1m[32m0.69255[0m[0m | time: 0.903s
[2K
| Adam | epoch: 007 | loss: 0.69255 - acc: 0.5251 -- iter: 032/342
[A[ATraining Step: 68  | total loss: [1m[32m0.69305[0m[0m | time: 1.762s
[2K
| Adam | epoch: 007 | loss: 0.69305 - acc: 0.5111 -- iter: 064/342
[A[ATraining Step: 69  | total loss: [1m[32m0.69307[0m[0m | time: 2.654s
[2K
| Adam | epoch: 007 | loss: 0.69307 - acc: 0.5098 -- iter: 096/342
[A[ATraining Step: 70  | total loss: [1m[32m0.69309[0m[0m | time: 3.465s
[2K
| Adam | epoch: 007 | loss: 0.69309 - acc: 0.5086 -- iter: 128/342
[A[ATraining Step: 71  | total loss: [1m[32m0.69309[0m[0m | time: 4.161s
[2K
| Adam | epoch: 007 | loss: 0.69309 - acc: 0.5077 -- iter: 160/342
[A[ATraining Step: 72  | total loss: [1m[32m0.69329[0m[0m | time: 4.885s
[2K
| Adam | epoch: 007 | loss: 0.69329 - acc: 0.5017 -- iter: 192/342
[A[ATraining Step: 73  | total loss: [1m[32m0.69347[0m[0m | time: 5.912s
[2K
| Adam | epoch: 007 | loss: 0.69347 - acc: 0.4964 -- iter: 224/342
[A[ATraining Step: 74  | total loss: [1m[32m0.69346[0m[0m | time: 6.640s
[2K
| Adam | epoch: 007 | loss: 0.69346 - acc: 0.4968 -- iter: 256/342
[A[ATraining Step: 75  | total loss: [1m[32m0.69334[0m[0m | time: 7.479s
[2K
| Adam | epoch: 007 | loss: 0.69334 - acc: 0.5006 -- iter: 288/342
[A[ATraining Step: 76  | total loss: [1m[32m0.69292[0m[0m | time: 8.323s
[2K
| Adam | epoch: 007 | loss: 0.69292 - acc: 0.5139 -- iter: 320/342
[A[ATraining Step: 77  | total loss: [1m[32m0.69252[0m[0m | time: 10.175s
[2K
| Adam | epoch: 007 | loss: 0.69252 - acc: 0.5257 | val_loss: 0.69570 - val_acc: 0.4259 -- iter: 342/342
--
Training Step: 78  | total loss: [1m[32m0.69277[0m[0m | time: 0.814s
[2K
| Adam | epoch: 008 | loss: 0.69277 - acc: 0.5164 -- iter: 032/342
[A[ATraining Step: 79  | total loss: [1m[32m0.69313[0m[0m | time: 1.722s
[2K
| Adam | epoch: 008 | loss: 0.69313 - acc: 0.5050 -- iter: 064/342
[A[ATraining Step: 80  | total loss: [1m[32m0.69270[0m[0m | time: 2.701s
[2K
| Adam | epoch: 008 | loss: 0.69270 - acc: 0.5173 -- iter: 096/342
[A[ATraining Step: 81  | total loss: [1m[32m0.69263[0m[0m | time: 3.630s
[2K
| Adam | epoch: 008 | loss: 0.69263 - acc: 0.5187 -- iter: 128/342
[A[ATraining Step: 82  | total loss: [1m[32m0.69290[0m[0m | time: 4.368s
[2K
| Adam | epoch: 008 | loss: 0.69290 - acc: 0.5106 -- iter: 160/342
[A[ATraining Step: 83  | total loss: [1m[32m0.69291[0m[0m | time: 4.978s
[2K
| Adam | epoch: 008 | loss: 0.69291 - acc: 0.5095 -- iter: 192/342
[A[ATraining Step: 84  | total loss: [1m[32m0.69274[0m[0m | time: 5.584s
[2K
| Adam | epoch: 008 | loss: 0.69274 - acc: 0.5131 -- iter: 224/342
[A[ATraining Step: 85  | total loss: [1m[32m0.69260[0m[0m | time: 6.558s
[2K
| Adam | epoch: 008 | loss: 0.69260 - acc: 0.5164 -- iter: 256/342
[A[ATraining Step: 86  | total loss: [1m[32m0.69277[0m[0m | time: 7.519s
[2K
| Adam | epoch: 008 | loss: 0.69277 - acc: 0.5116 -- iter: 288/342
[A[ATraining Step: 87  | total loss: [1m[32m0.69305[0m[0m | time: 8.474s
[2K
| Adam | epoch: 008 | loss: 0.69305 - acc: 0.5042 -- iter: 320/342
[A[ATraining Step: 88  | total loss: [1m[32m0.69319[0m[0m | time: 10.594s
[2K
| Adam | epoch: 008 | loss: 0.69319 - acc: 0.4975 | val_loss: 0.69526 - val_acc: 0.4259 -- iter: 342/342
--
Training Step: 89  | total loss: [1m[32m0.69314[0m[0m | time: 0.901s
[2K
| Adam | epoch: 009 | loss: 0.69314 - acc: 0.4978 -- iter: 032/342
[A[ATraining Step: 90  | total loss: [1m[32m0.69306[0m[0m | time: 2.053s
[2K
| Adam | epoch: 009 | loss: 0.69306 - acc: 0.4980 -- iter: 064/342
[A[ATraining Step: 91  | total loss: [1m[32m0.69327[0m[0m | time: 3.227s
[2K
| Adam | epoch: 009 | loss: 0.69327 - acc: 0.4919 -- iter: 096/342
[A[ATraining Step: 92  | total loss: [1m[32m0.69291[0m[0m | time: 4.101s
[2K
| Adam | epoch: 009 | loss: 0.69291 - acc: 0.5021 -- iter: 128/342
[A[ATraining Step: 93  | total loss: [1m[32m0.69262[0m[0m | time: 4.916s
[2K
| Adam | epoch: 009 | loss: 0.69262 - acc: 0.5082 -- iter: 160/342
[A[ATraining Step: 94  | total loss: [1m[32m0.69242[0m[0m | time: 5.867s
[2K
| Adam | epoch: 009 | loss: 0.69242 - acc: 0.5136 -- iter: 192/342
[A[ATraining Step: 95  | total loss: [1m[32m0.69240[0m[0m | time: 6.528s
[2K
| Adam | epoch: 009 | loss: 0.69240 - acc: 0.5122 -- iter: 224/342
[A[ATraining Step: 96  | total loss: [1m[32m0.69232[0m[0m | time: 7.231s
[2K
| Adam | epoch: 009 | loss: 0.69232 - acc: 0.5110 -- iter: 256/342
[A[ATraining Step: 97  | total loss: [1m[32m0.69223[0m[0m | time: 8.216s
[2K
| Adam | epoch: 009 | loss: 0.69223 - acc: 0.5099 -- iter: 288/342
[A[ATraining Step: 98  | total loss: [1m[32m0.69165[0m[0m | time: 9.235s
[2K
| Adam | epoch: 009 | loss: 0.69165 - acc: 0.5183 -- iter: 320/342
[A[ATraining Step: 99  | total loss: [1m[32m0.69188[0m[0m | time: 11.297s
[2K
| Adam | epoch: 009 | loss: 0.69188 - acc: 0.5102 | val_loss: 0.69545 - val_acc: 0.4259 -- iter: 342/342
--
Training Step: 100  | total loss: [1m[32m0.69149[0m[0m | time: 1.002s
[2K
| Adam | epoch: 010 | loss: 0.69149 - acc: 0.5217 -- iter: 032/342
[A[ATraining Step: 101  | total loss: [1m[32m0.69088[0m[0m | time: 2.063s
[2K
| Adam | epoch: 010 | loss: 0.69088 - acc: 0.5289 -- iter: 064/342
[A[ATraining Step: 102  | total loss: [1m[32m0.69131[0m[0m | time: 3.249s
[2K
| Adam | epoch: 010 | loss: 0.69131 - acc: 0.5198 -- iter: 096/342
[A[ATraining Step: 103  | total loss: [1m[32m0.68990[0m[0m | time: 4.198s
[2K
| Adam | epoch: 010 | loss: 0.68990 - acc: 0.5272 -- iter: 128/342
[A[ATraining Step: 104  | total loss: [1m[32m0.69014[0m[0m | time: 5.067s
[2K
| Adam | epoch: 010 | loss: 0.69014 - acc: 0.5213 -- iter: 160/342
[A[ATraining Step: 105  | total loss: [1m[32m0.68939[0m[0m | time: 6.047s
[2K
| Adam | epoch: 010 | loss: 0.68939 - acc: 0.5192 -- iter: 192/342
[A[ATraining Step: 106  | total loss: [1m[32m0.68913[0m[0m | time: 6.976s
[2K
| Adam | epoch: 010 | loss: 0.68913 - acc: 0.5173 -- iter: 224/342
[A[ATraining Step: 107  | total loss: [1m[32m0.68890[0m[0m | time: 7.652s
[2K
| Adam | epoch: 010 | loss: 0.68890 - acc: 0.5312 -- iter: 256/342
[A[ATraining Step: 108  | total loss: [1m[32m0.68801[0m[0m | time: 8.356s
[2K
| Adam | epoch: 010 | loss: 0.68801 - acc: 0.5417 -- iter: 288/342
[A[ATraining Step: 109  | total loss: [1m[32m0.68634[0m[0m | time: 9.449s
[2K
| Adam | epoch: 010 | loss: 0.68634 - acc: 0.5557 -- iter: 320/342
[A[ATraining Step: 110  | total loss: [1m[32m0.68437[0m[0m | time: 11.508s
[2K
| Adam | epoch: 010 | loss: 0.68437 - acc: 0.5564 | val_loss: 0.69596 - val_acc: 0.5093 -- iter: 342/342
--
Training Step: 111  | total loss: [1m[32m0.68526[0m[0m | time: 1.234s
[2K
| Adam | epoch: 011 | loss: 0.68526 - acc: 0.5445 -- iter: 032/342
[A[ATraining Step: 112  | total loss: [1m[32m0.68179[0m[0m | time: 2.376s
[2K
| Adam | epoch: 011 | loss: 0.68179 - acc: 0.5557 -- iter: 064/342
[A[ATraining Step: 113  | total loss: [1m[32m0.67606[0m[0m | time: 3.351s
[2K
| Adam | epoch: 011 | loss: 0.67606 - acc: 0.5720 -- iter: 096/342
[A[ATraining Step: 114  | total loss: [1m[32m0.66837[0m[0m | time: 4.222s
[2K
| Adam | epoch: 011 | loss: 0.66837 - acc: 0.5929 -- iter: 128/342
[A[ATraining Step: 115  | total loss: [1m[32m0.67041[0m[0m | time: 5.188s
[2K
| Adam | epoch: 011 | loss: 0.67041 - acc: 0.5867 -- iter: 160/342
[A[ATraining Step: 116  | total loss: [1m[32m0.67447[0m[0m | time: 6.175s
[2K
| Adam | epoch: 011 | loss: 0.67447 - acc: 0.5812 -- iter: 192/342
[A[ATraining Step: 117  | total loss: [1m[32m0.67555[0m[0m | time: 7.012s
[2K
| Adam | epoch: 011 | loss: 0.67555 - acc: 0.5731 -- iter: 224/342
[A[ATraining Step: 118  | total loss: [1m[32m0.67380[0m[0m | time: 7.863s
[2K
| Adam | epoch: 011 | loss: 0.67380 - acc: 0.5751 -- iter: 256/342
[A[ATraining Step: 119  | total loss: [1m[32m0.66888[0m[0m | time: 8.457s
[2K
| Adam | epoch: 011 | loss: 0.66888 - acc: 0.5895 -- iter: 288/342
[A[ATraining Step: 120  | total loss: [1m[32m0.67333[0m[0m | time: 9.331s
[2K
| Adam | epoch: 011 | loss: 0.67333 - acc: 0.5896 -- iter: 320/342
[A[ATraining Step: 121  | total loss: [1m[32m0.67207[0m[0m | time: 11.370s
[2K
| Adam | epoch: 011 | loss: 0.67207 - acc: 0.5989 | val_loss: 0.67030 - val_acc: 0.5926 -- iter: 342/342
--
Training Step: 122  | total loss: [1m[32m0.66571[0m[0m | time: 0.972s
[2K
| Adam | epoch: 012 | loss: 0.66571 - acc: 0.6108 -- iter: 032/342
[A[ATraining Step: 123  | total loss: [1m[32m0.67112[0m[0m | time: 1.931s
[2K
| Adam | epoch: 012 | loss: 0.67112 - acc: 0.5998 -- iter: 064/342
[A[ATraining Step: 124  | total loss: [1m[32m0.66429[0m[0m | time: 2.800s
[2K
| Adam | epoch: 012 | loss: 0.66429 - acc: 0.6117 -- iter: 096/342
[A[ATraining Step: 125  | total loss: [1m[32m0.65969[0m[0m | time: 3.683s
[2K
| Adam | epoch: 012 | loss: 0.65969 - acc: 0.6130 -- iter: 128/342
[A[ATraining Step: 126  | total loss: [1m[32m0.65984[0m[0m | time: 4.632s
[2K
| Adam | epoch: 012 | loss: 0.65984 - acc: 0.6142 -- iter: 160/342
[A[ATraining Step: 127  | total loss: [1m[32m0.65976[0m[0m | time: 5.707s
[2K
| Adam | epoch: 012 | loss: 0.65976 - acc: 0.6153 -- iter: 192/342
[A[ATraining Step: 128  | total loss: [1m[32m0.65890[0m[0m | time: 6.809s
[2K
| Adam | epoch: 012 | loss: 0.65890 - acc: 0.6194 -- iter: 224/342
[A[ATraining Step: 129  | total loss: [1m[32m0.65868[0m[0m | time: 7.850s
[2K
| Adam | epoch: 012 | loss: 0.65868 - acc: 0.6231 -- iter: 256/342
[A[ATraining Step: 130  | total loss: [1m[32m0.65579[0m[0m | time: 8.890s
[2K
| Adam | epoch: 012 | loss: 0.65579 - acc: 0.6201 -- iter: 288/342
[A[ATraining Step: 131  | total loss: [1m[32m0.65113[0m[0m | time: 9.467s
[2K
| Adam | epoch: 012 | loss: 0.65113 - acc: 0.6362 -- iter: 320/342
[A[ATraining Step: 132  | total loss: [1m[32m0.64837[0m[0m | time: 11.272s
[2K
| Adam | epoch: 012 | loss: 0.64837 - acc: 0.6408 | val_loss: 0.66302 - val_acc: 0.6204 -- iter: 342/342
--
Training Step: 133  | total loss: [1m[32m0.64314[0m[0m | time: 0.990s
[2K
| Adam | epoch: 013 | loss: 0.64314 - acc: 0.6494 -- iter: 032/342
[A[ATraining Step: 134  | total loss: [1m[32m0.64030[0m[0m | time: 1.949s
[2K
| Adam | epoch: 013 | loss: 0.64030 - acc: 0.6533 -- iter: 064/342
[A[ATraining Step: 135  | total loss: [1m[32m0.62976[0m[0m | time: 2.953s
[2K
| Adam | epoch: 013 | loss: 0.62976 - acc: 0.6629 -- iter: 096/342
[A[ATraining Step: 136  | total loss: [1m[32m0.63934[0m[0m | time: 3.973s
[2K
| Adam | epoch: 013 | loss: 0.63934 - acc: 0.6560 -- iter: 128/342
[A[ATraining Step: 137  | total loss: [1m[32m0.63497[0m[0m | time: 5.030s
[2K
| Adam | epoch: 013 | loss: 0.63497 - acc: 0.6467 -- iter: 160/342
[A[ATraining Step: 138  | total loss: [1m[32m0.64022[0m[0m | time: 6.103s
[2K
| Adam | epoch: 013 | loss: 0.64022 - acc: 0.6382 -- iter: 192/342
[A[ATraining Step: 139  | total loss: [1m[32m0.63465[0m[0m | time: 7.105s
[2K
| Adam | epoch: 013 | loss: 0.63465 - acc: 0.6432 -- iter: 224/342
[A[ATraining Step: 140  | total loss: [1m[32m0.62122[0m[0m | time: 8.235s
[2K
| Adam | epoch: 013 | loss: 0.62122 - acc: 0.6695 -- iter: 256/342
[A[ATraining Step: 141  | total loss: [1m[32m0.61550[0m[0m | time: 9.399s
[2K
| Adam | epoch: 013 | loss: 0.61550 - acc: 0.6807 -- iter: 288/342
[A[ATraining Step: 142  | total loss: [1m[32m0.63233[0m[0m | time: 10.164s
[2K
| Adam | epoch: 013 | loss: 0.63233 - acc: 0.6532 -- iter: 320/342
[A[ATraining Step: 143  | total loss: [1m[32m0.62684[0m[0m | time: 11.749s
[2K
| Adam | epoch: 013 | loss: 0.62684 - acc: 0.6629 | val_loss: 0.63671 - val_acc: 0.6296 -- iter: 342/342
--
Training Step: 144  | total loss: [1m[32m0.63497[0m[0m | time: 0.714s
[2K
| Adam | epoch: 014 | loss: 0.63497 - acc: 0.6466 -- iter: 032/342
[A[ATraining Step: 145  | total loss: [1m[32m0.63679[0m[0m | time: 1.814s
[2K
| Adam | epoch: 014 | loss: 0.63679 - acc: 0.6410 -- iter: 064/342
[A[ATraining Step: 146  | total loss: [1m[32m0.63302[0m[0m | time: 2.985s
[2K
| Adam | epoch: 014 | loss: 0.63302 - acc: 0.6519 -- iter: 096/342
[A[ATraining Step: 147  | total loss: [1m[32m0.63395[0m[0m | time: 4.062s
[2K
| Adam | epoch: 014 | loss: 0.63395 - acc: 0.6492 -- iter: 128/342
[A[ATraining Step: 148  | total loss: [1m[32m0.62878[0m[0m | time: 5.034s
[2K
| Adam | epoch: 014 | loss: 0.62878 - acc: 0.6531 -- iter: 160/342
[A[ATraining Step: 149  | total loss: [1m[32m0.62935[0m[0m | time: 6.070s
[2K
| Adam | epoch: 014 | loss: 0.62935 - acc: 0.6534 -- iter: 192/342
[A[ATraining Step: 150  | total loss: [1m[32m0.62131[0m[0m | time: 7.062s
[2K
| Adam | epoch: 014 | loss: 0.62131 - acc: 0.6599 -- iter: 224/342
[A[ATraining Step: 151  | total loss: [1m[32m0.61489[0m[0m | time: 8.048s
[2K
| Adam | epoch: 014 | loss: 0.61489 - acc: 0.6689 -- iter: 256/342
[A[ATraining Step: 152  | total loss: [1m[32m0.61108[0m[0m | time: 8.772s
[2K
| Adam | epoch: 014 | loss: 0.61108 - acc: 0.6770 -- iter: 288/342
[A[ATraining Step: 153  | total loss: [1m[32m0.60995[0m[0m | time: 9.751s
[2K
| Adam | epoch: 014 | loss: 0.60995 - acc: 0.6781 -- iter: 320/342
[A[ATraining Step: 154  | total loss: [1m[32m0.61099[0m[0m | time: 11.798s
[2K
| Adam | epoch: 014 | loss: 0.61099 - acc: 0.6759 | val_loss: 0.62412 - val_acc: 0.6296 -- iter: 342/342
--
Training Step: 155  | total loss: [1m[32m0.60376[0m[0m | time: 0.768s
[2K
| Adam | epoch: 015 | loss: 0.60376 - acc: 0.6802 -- iter: 032/342
[A[ATraining Step: 156  | total loss: [1m[32m0.59560[0m[0m | time: 1.444s
[2K
| Adam | epoch: 015 | loss: 0.59560 - acc: 0.6803 -- iter: 064/342
[A[ATraining Step: 157  | total loss: [1m[32m0.58396[0m[0m | time: 2.519s
[2K
| Adam | epoch: 015 | loss: 0.58396 - acc: 0.6941 -- iter: 096/342
[A[ATraining Step: 158  | total loss: [1m[32m0.57533[0m[0m | time: 3.474s
[2K
| Adam | epoch: 015 | loss: 0.57533 - acc: 0.7060 -- iter: 128/342
[A[ATraining Step: 159  | total loss: [1m[32m0.55955[0m[0m | time: 4.451s
[2K
| Adam | epoch: 015 | loss: 0.55955 - acc: 0.7104 -- iter: 160/342
[A[ATraining Step: 160  | total loss: [1m[32m0.54034[0m[0m | time: 5.490s
[2K
| Adam | epoch: 015 | loss: 0.54034 - acc: 0.7300 -- iter: 192/342
[A[ATraining Step: 161  | total loss: [1m[32m0.52885[0m[0m | time: 6.385s
[2K
| Adam | epoch: 015 | loss: 0.52885 - acc: 0.7413 -- iter: 224/342
[A[ATraining Step: 162  | total loss: [1m[32m0.54080[0m[0m | time: 7.237s
[2K
| Adam | epoch: 015 | loss: 0.54080 - acc: 0.7297 -- iter: 256/342
[A[ATraining Step: 163  | total loss: [1m[32m0.54000[0m[0m | time: 8.141s
[2K
| Adam | epoch: 015 | loss: 0.54000 - acc: 0.7317 -- iter: 288/342
[A[ATraining Step: 164  | total loss: [1m[32m0.53227[0m[0m | time: 9.126s
[2K
| Adam | epoch: 015 | loss: 0.53227 - acc: 0.7304 -- iter: 320/342
[A[ATraining Step: 165  | total loss: [1m[32m0.52691[0m[0m | time: 11.130s
[2K
| Adam | epoch: 015 | loss: 0.52691 - acc: 0.7355 | val_loss: 0.86459 - val_acc: 0.5926 -- iter: 342/342
--
Training Step: 166  | total loss: [1m[32m0.51034[0m[0m | time: 0.890s
[2K
| Adam | epoch: 016 | loss: 0.51034 - acc: 0.7432 -- iter: 032/342
[A[ATraining Step: 167  | total loss: [1m[32m0.51057[0m[0m | time: 1.670s
[2K
| Adam | epoch: 016 | loss: 0.51057 - acc: 0.7470 -- iter: 064/342
[A[ATraining Step: 168  | total loss: [1m[32m0.50642[0m[0m | time: 2.279s
[2K
| Adam | epoch: 016 | loss: 0.50642 - acc: 0.7405 -- iter: 096/342
[A[ATraining Step: 169  | total loss: [1m[32m0.48982[0m[0m | time: 3.260s
[2K
| Adam | epoch: 016 | loss: 0.48982 - acc: 0.7528 -- iter: 128/342
[A[ATraining Step: 170  | total loss: [1m[32m0.50284[0m[0m | time: 4.213s
[2K
| Adam | epoch: 016 | loss: 0.50284 - acc: 0.7494 -- iter: 160/342
[A[ATraining Step: 171  | total loss: [1m[32m0.51204[0m[0m | time: 5.323s
[2K
| Adam | epoch: 016 | loss: 0.51204 - acc: 0.7401 -- iter: 192/342
[A[ATraining Step: 172  | total loss: [1m[32m0.49382[0m[0m | time: 6.150s
[2K
| Adam | epoch: 016 | loss: 0.49382 - acc: 0.7567 -- iter: 224/342
[A[ATraining Step: 173  | total loss: [1m[32m0.48701[0m[0m | time: 7.103s
[2K
| Adam | epoch: 016 | loss: 0.48701 - acc: 0.7654 -- iter: 256/342
[A[ATraining Step: 174  | total loss: [1m[32m0.46825[0m[0m | time: 8.121s
[2K
| Adam | epoch: 016 | loss: 0.46825 - acc: 0.7826 -- iter: 288/342
[A[ATraining Step: 175  | total loss: [1m[32m0.47741[0m[0m | time: 9.072s
[2K
| Adam | epoch: 016 | loss: 0.47741 - acc: 0.7731 -- iter: 320/342
[A[ATraining Step: 176  | total loss: [1m[32m0.48421[0m[0m | time: 11.035s
[2K
| Adam | epoch: 016 | loss: 0.48421 - acc: 0.7708 | val_loss: 0.58361 - val_acc: 0.6852 -- iter: 342/342
--
Training Step: 177  | total loss: [1m[32m0.48060[0m[0m | time: 0.839s
[2K
| Adam | epoch: 017 | loss: 0.48060 - acc: 0.7718 -- iter: 032/342
[A[ATraining Step: 178  | total loss: [1m[32m0.45503[0m[0m | time: 1.873s
[2K
| Adam | epoch: 017 | loss: 0.45503 - acc: 0.7947 -- iter: 064/342
[A[ATraining Step: 179  | total loss: [1m[32m0.46799[0m[0m | time: 2.642s
[2K
| Adam | epoch: 017 | loss: 0.46799 - acc: 0.7808 -- iter: 096/342
[A[ATraining Step: 180  | total loss: [1m[32m0.46502[0m[0m | time: 3.529s
[2K
| Adam | epoch: 017 | loss: 0.46502 - acc: 0.7800 -- iter: 128/342
[A[ATraining Step: 181  | total loss: [1m[32m0.44755[0m[0m | time: 4.328s
[2K
| Adam | epoch: 017 | loss: 0.44755 - acc: 0.7975 -- iter: 160/342
[A[ATraining Step: 182  | total loss: [1m[32m0.44130[0m[0m | time: 5.222s
[2K
| Adam | epoch: 017 | loss: 0.44130 - acc: 0.8021 -- iter: 192/342
[A[ATraining Step: 183  | total loss: [1m[32m0.44520[0m[0m | time: 6.229s
[2K
| Adam | epoch: 017 | loss: 0.44520 - acc: 0.7938 -- iter: 224/342
[A[ATraining Step: 184  | total loss: [1m[32m0.45318[0m[0m | time: 7.179s
[2K
| Adam | epoch: 017 | loss: 0.45318 - acc: 0.7894 -- iter: 256/342
[A[ATraining Step: 185  | total loss: [1m[32m0.44200[0m[0m | time: 8.102s
[2K
| Adam | epoch: 017 | loss: 0.44200 - acc: 0.7979 -- iter: 288/342
[A[ATraining Step: 186  | total loss: [1m[32m0.43221[0m[0m | time: 9.129s
[2K
| Adam | epoch: 017 | loss: 0.43221 - acc: 0.8025 -- iter: 320/342
[A[ATraining Step: 187  | total loss: [1m[32m0.41424[0m[0m | time: 11.137s
[2K
| Adam | epoch: 017 | loss: 0.41424 - acc: 0.8160 | val_loss: 0.61237 - val_acc: 0.6574 -- iter: 342/342
--
Training Step: 188  | total loss: [1m[32m0.40221[0m[0m | time: 1.108s
[2K
| Adam | epoch: 018 | loss: 0.40221 - acc: 0.8250 -- iter: 032/342
[A[ATraining Step: 189  | total loss: [1m[32m0.39135[0m[0m | time: 2.139s
[2K
| Adam | epoch: 018 | loss: 0.39135 - acc: 0.8300 -- iter: 064/342
[A[ATraining Step: 190  | total loss: [1m[32m0.37783[0m[0m | time: 3.088s
[2K
| Adam | epoch: 018 | loss: 0.37783 - acc: 0.8408 -- iter: 096/342
[A[ATraining Step: 191  | total loss: [1m[32m0.37203[0m[0m | time: 3.795s
[2K
| Adam | epoch: 018 | loss: 0.37203 - acc: 0.8442 -- iter: 128/342
[A[ATraining Step: 192  | total loss: [1m[32m0.36480[0m[0m | time: 4.527s
[2K
| Adam | epoch: 018 | loss: 0.36480 - acc: 0.8462 -- iter: 160/342
[A[ATraining Step: 193  | total loss: [1m[32m0.36082[0m[0m | time: 5.563s
[2K
| Adam | epoch: 018 | loss: 0.36082 - acc: 0.8434 -- iter: 192/342
[A[ATraining Step: 194  | total loss: [1m[32m0.35438[0m[0m | time: 6.583s
[2K
| Adam | epoch: 018 | loss: 0.35438 - acc: 0.8434 -- iter: 224/342
[A[ATraining Step: 195  | total loss: [1m[32m0.33554[0m[0m | time: 7.553s
[2K
| Adam | epoch: 018 | loss: 0.33554 - acc: 0.8559 -- iter: 256/342
[A[ATraining Step: 196  | total loss: [1m[32m0.34474[0m[0m | time: 8.558s
[2K
| Adam | epoch: 018 | loss: 0.34474 - acc: 0.8578 -- iter: 288/342
[A[ATraining Step: 197  | total loss: [1m[32m0.33806[0m[0m | time: 9.494s
[2K
| Adam | epoch: 018 | loss: 0.33806 - acc: 0.8627 -- iter: 320/342
[A[ATraining Step: 198  | total loss: [1m[32m0.31614[0m[0m | time: 11.407s
[2K
| Adam | epoch: 018 | loss: 0.31614 - acc: 0.8764 | val_loss: 0.81940 - val_acc: 0.6667 -- iter: 342/342
--
Training Step: 199  | total loss: [1m[32m0.30843[0m[0m | time: 0.921s
[2K
| Adam | epoch: 019 | loss: 0.30843 - acc: 0.8794 -- iter: 032/342
[A[ATraining Step: 200  | total loss: [1m[32m0.30042[0m[0m | time: 2.864s
[2K
| Adam | epoch: 019 | loss: 0.30042 - acc: 0.8852 | val_loss: 0.63271 - val_acc: 0.6852 -- iter: 064/342
--
Training Step: 201  | total loss: [1m[32m0.30077[0m[0m | time: 3.893s
[2K
| Adam | epoch: 019 | loss: 0.30077 - acc: 0.8842 -- iter: 096/342
[A[ATraining Step: 202  | total loss: [1m[32m0.29737[0m[0m | time: 4.762s
[2K
| Adam | epoch: 019 | loss: 0.29737 - acc: 0.8833 -- iter: 128/342
[A[ATraining Step: 203  | total loss: [1m[32m0.29339[0m[0m | time: 5.391s
[2K
| Adam | epoch: 019 | loss: 0.29339 - acc: 0.8824 -- iter: 160/342
[A[ATraining Step: 204  | total loss: [1m[32m0.30368[0m[0m | time: 6.125s
[2K
| Adam | epoch: 019 | loss: 0.30368 - acc: 0.8806 -- iter: 192/342
[A[ATraining Step: 205  | total loss: [1m[32m0.30188[0m[0m | time: 7.124s
[2K
| Adam | epoch: 019 | loss: 0.30188 - acc: 0.8880 -- iter: 224/342
[A[ATraining Step: 206  | total loss: [1m[32m0.28985[0m[0m | time: 7.998s
[2K
| Adam | epoch: 019 | loss: 0.28985 - acc: 0.8929 -- iter: 256/342
[A[ATraining Step: 207  | total loss: [1m[32m0.28650[0m[0m | time: 9.154s
[2K
| Adam | epoch: 019 | loss: 0.28650 - acc: 0.8942 -- iter: 288/342
[A[ATraining Step: 208  | total loss: [1m[32m0.28428[0m[0m | time: 10.311s
[2K
| Adam | epoch: 019 | loss: 0.28428 - acc: 0.8986 -- iter: 320/342
[A[ATraining Step: 209  | total loss: [1m[32m0.27443[0m[0m | time: 12.491s
[2K
| Adam | epoch: 019 | loss: 0.27443 - acc: 0.9025 | val_loss: 0.64159 - val_acc: 0.6852 -- iter: 342/342
--
Training Step: 210  | total loss: [1m[32m0.26465[0m[0m | time: 0.849s
[2K
| Adam | epoch: 020 | loss: 0.26465 - acc: 0.9091 -- iter: 032/342
[A[ATraining Step: 211  | total loss: [1m[32m0.24759[0m[0m | time: 1.722s
[2K
| Adam | epoch: 020 | loss: 0.24759 - acc: 0.9182 -- iter: 064/342
[A[ATraining Step: 212  | total loss: [1m[32m0.24030[0m[0m | time: 2.633s
[2K
| Adam | epoch: 020 | loss: 0.24030 - acc: 0.9201 -- iter: 096/342
[A[ATraining Step: 213  | total loss: [1m[32m0.22349[0m[0m | time: 3.641s
[2K
| Adam | epoch: 020 | loss: 0.22349 - acc: 0.9281 -- iter: 128/342
[A[ATraining Step: 214  | total loss: [1m[32m0.21184[0m[0m | time: 4.650s
[2K
| Adam | epoch: 020 | loss: 0.21184 - acc: 0.9290 -- iter: 160/342
[A[ATraining Step: 215  | total loss: [1m[32m0.20283[0m[0m | time: 5.355s
[2K
| Adam | epoch: 020 | loss: 0.20283 - acc: 0.9361 -- iter: 192/342
[A[ATraining Step: 216  | total loss: [1m[32m0.19388[0m[0m | time: 6.155s
[2K
| Adam | epoch: 020 | loss: 0.19388 - acc: 0.9380 -- iter: 224/342
[A[ATraining Step: 217  | total loss: [1m[32m0.18244[0m[0m | time: 7.169s
[2K
| Adam | epoch: 020 | loss: 0.18244 - acc: 0.9442 -- iter: 256/342
[A[ATraining Step: 218  | total loss: [1m[32m0.19144[0m[0m | time: 8.282s
[2K
| Adam | epoch: 020 | loss: 0.19144 - acc: 0.9404 -- iter: 288/342
[A[ATraining Step: 219  | total loss: [1m[32m0.21553[0m[0m | time: 9.547s
[2K
| Adam | epoch: 020 | loss: 0.21553 - acc: 0.9307 -- iter: 320/342
[A[ATraining Step: 220  | total loss: [1m[32m0.21219[0m[0m | time: 11.657s
[2K
| Adam | epoch: 020 | loss: 0.21219 - acc: 0.9345 | val_loss: 0.95662 - val_acc: 0.6852 -- iter: 342/342
--
Training Step: 221  | total loss: [1m[32m0.19677[0m[0m | time: 0.877s
[2K
| Adam | epoch: 021 | loss: 0.19677 - acc: 0.9411 -- iter: 032/342
[A[ATraining Step: 222  | total loss: [1m[32m0.19496[0m[0m | time: 1.932s
[2K
| Adam | epoch: 021 | loss: 0.19496 - acc: 0.9407 -- iter: 064/342
[A[ATraining Step: 223  | total loss: [1m[32m0.18271[0m[0m | time: 3.099s
[2K
| Adam | epoch: 021 | loss: 0.18271 - acc: 0.9435 -- iter: 096/342
[A[ATraining Step: 224  | total loss: [1m[32m0.17288[0m[0m | time: 4.150s
[2K
| Adam | epoch: 021 | loss: 0.17288 - acc: 0.9460 -- iter: 128/342
[A[ATraining Step: 225  | total loss: [1m[32m0.17044[0m[0m | time: 5.099s
[2K
| Adam | epoch: 021 | loss: 0.17044 - acc: 0.9483 -- iter: 160/342
[A[ATraining Step: 226  | total loss: [1m[32m0.16175[0m[0m | time: 6.207s
[2K
| Adam | epoch: 021 | loss: 0.16175 - acc: 0.9504 -- iter: 192/342
[A[ATraining Step: 227  | total loss: [1m[32m0.15925[0m[0m | time: 6.998s
[2K
| Adam | epoch: 021 | loss: 0.15925 - acc: 0.9522 -- iter: 224/342
[A[ATraining Step: 228  | total loss: [1m[32m0.15341[0m[0m | time: 7.789s
[2K
| Adam | epoch: 021 | loss: 0.15341 - acc: 0.9524 -- iter: 256/342
[A[ATraining Step: 229  | total loss: [1m[32m0.14304[0m[0m | time: 8.802s
[2K
| Adam | epoch: 021 | loss: 0.14304 - acc: 0.9572 -- iter: 288/342
[A[ATraining Step: 230  | total loss: [1m[32m0.16670[0m[0m | time: 9.659s
[2K
| Adam | epoch: 021 | loss: 0.16670 - acc: 0.9458 -- iter: 320/342
[A[ATraining Step: 231  | total loss: [1m[32m0.19981[0m[0m | time: 11.511s
[2K
| Adam | epoch: 021 | loss: 0.19981 - acc: 0.9325 | val_loss: 0.79539 - val_acc: 0.7315 -- iter: 342/342
--
Training Step: 232  | total loss: [1m[32m0.18898[0m[0m | time: 1.065s
[2K
| Adam | epoch: 022 | loss: 0.18898 - acc: 0.9393 -- iter: 032/342
[A[ATraining Step: 233  | total loss: [1m[32m0.18424[0m[0m | time: 2.109s
[2K
| Adam | epoch: 022 | loss: 0.18424 - acc: 0.9391 -- iter: 064/342
[A[ATraining Step: 234  | total loss: [1m[32m0.16869[0m[0m | time: 3.112s
[2K
| Adam | epoch: 022 | loss: 0.16869 - acc: 0.9452 -- iter: 096/342
[A[ATraining Step: 235  | total loss: [1m[32m0.17336[0m[0m | time: 4.057s
[2K
| Adam | epoch: 022 | loss: 0.17336 - acc: 0.9413 -- iter: 128/342
[A[ATraining Step: 236  | total loss: [1m[32m0.17476[0m[0m | time: 5.159s
[2K
| Adam | epoch: 022 | loss: 0.17476 - acc: 0.9409 -- iter: 160/342
[A[ATraining Step: 237  | total loss: [1m[32m0.18571[0m[0m | time: 6.219s
[2K
| Adam | epoch: 022 | loss: 0.18571 - acc: 0.9406 -- iter: 192/342
[A[ATraining Step: 238  | total loss: [1m[32m0.17461[0m[0m | time: 7.037s
[2K
| Adam | epoch: 022 | loss: 0.17461 - acc: 0.9434 -- iter: 224/342
[A[ATraining Step: 239  | total loss: [1m[32m0.16360[0m[0m | time: 7.690s
[2K
| Adam | epoch: 022 | loss: 0.16360 - acc: 0.9490 -- iter: 256/342
[A[ATraining Step: 240  | total loss: [1m[32m0.16467[0m[0m | time: 8.376s
[2K
| Adam | epoch: 022 | loss: 0.16467 - acc: 0.9450 -- iter: 288/342
[A[ATraining Step: 241  | total loss: [1m[32m0.16069[0m[0m | time: 9.382s
[2K
| Adam | epoch: 022 | loss: 0.16069 - acc: 0.9415 -- iter: 320/342
[A[ATraining Step: 242  | total loss: [1m[32m0.16541[0m[0m | time: 11.424s
[2K
| Adam | epoch: 022 | loss: 0.16541 - acc: 0.9379 | val_loss: 0.77826 - val_acc: 0.7222 -- iter: 342/342
--
Training Step: 243  | total loss: [1m[32m0.15412[0m[0m | time: 0.982s
[2K
| Adam | epoch: 023 | loss: 0.15412 - acc: 0.9441 -- iter: 032/342
[A[ATraining Step: 244  | total loss: [1m[32m0.15057[0m[0m | time: 2.017s
[2K
| Adam | epoch: 023 | loss: 0.15057 - acc: 0.9466 -- iter: 064/342
[A[ATraining Step: 245  | total loss: [1m[32m0.15232[0m[0m | time: 3.041s
[2K
| Adam | epoch: 023 | loss: 0.15232 - acc: 0.9457 -- iter: 096/342
[A[ATraining Step: 246  | total loss: [1m[32m0.15865[0m[0m | time: 3.872s
[2K
| Adam | epoch: 023 | loss: 0.15865 - acc: 0.9417 -- iter: 128/342
[A[ATraining Step: 247  | total loss: [1m[32m0.14889[0m[0m | time: 4.801s
[2K
| Adam | epoch: 023 | loss: 0.14889 - acc: 0.9444 -- iter: 160/342
[A[ATraining Step: 248  | total loss: [1m[32m0.13636[0m[0m | time: 5.805s
[2K
| Adam | epoch: 023 | loss: 0.13636 - acc: 0.9500 -- iter: 192/342
[A[ATraining Step: 249  | total loss: [1m[32m0.12641[0m[0m | time: 6.730s
[2K
| Adam | epoch: 023 | loss: 0.12641 - acc: 0.9550 -- iter: 224/342
[A[ATraining Step: 250  | total loss: [1m[32m0.13948[0m[0m | time: 7.531s
[2K
| Adam | epoch: 023 | loss: 0.13948 - acc: 0.9470 -- iter: 256/342
[A[ATraining Step: 251  | total loss: [1m[32m0.14243[0m[0m | time: 8.177s
[2K
| Adam | epoch: 023 | loss: 0.14243 - acc: 0.9461 -- iter: 288/342
[A[ATraining Step: 252  | total loss: [1m[32m0.15684[0m[0m | time: 8.912s
[2K
| Adam | epoch: 023 | loss: 0.15684 - acc: 0.9424 -- iter: 320/342
[A[ATraining Step: 253  | total loss: [1m[32m0.16102[0m[0m | time: 10.945s
[2K
| Adam | epoch: 023 | loss: 0.16102 - acc: 0.9390 | val_loss: 0.86782 - val_acc: 0.6759 -- iter: 342/342
--
Training Step: 254  | total loss: [1m[32m0.15616[0m[0m | time: 1.056s
[2K
| Adam | epoch: 024 | loss: 0.15616 - acc: 0.9420 -- iter: 032/342
[A[ATraining Step: 255  | total loss: [1m[32m0.14617[0m[0m | time: 1.903s
[2K
| Adam | epoch: 024 | loss: 0.14617 - acc: 0.9478 -- iter: 064/342
[A[ATraining Step: 256  | total loss: [1m[32m0.14845[0m[0m | time: 2.941s
[2K
| Adam | epoch: 024 | loss: 0.14845 - acc: 0.9468 -- iter: 096/342
[A[ATraining Step: 257  | total loss: [1m[32m0.16781[0m[0m | time: 3.822s
[2K
| Adam | epoch: 024 | loss: 0.16781 - acc: 0.9396 -- iter: 128/342
[A[ATraining Step: 258  | total loss: [1m[32m0.15599[0m[0m | time: 4.852s
[2K
| Adam | epoch: 024 | loss: 0.15599 - acc: 0.9456 -- iter: 160/342
[A[ATraining Step: 259  | total loss: [1m[32m0.14616[0m[0m | time: 5.912s
[2K
| Adam | epoch: 024 | loss: 0.14616 - acc: 0.9511 -- iter: 192/342
[A[ATraining Step: 260  | total loss: [1m[32m0.14236[0m[0m | time: 6.877s
[2K
| Adam | epoch: 024 | loss: 0.14236 - acc: 0.9497 -- iter: 224/342
[A[ATraining Step: 261  | total loss: [1m[32m0.13183[0m[0m | time: 7.755s
[2K
| Adam | epoch: 024 | loss: 0.13183 - acc: 0.9547 -- iter: 256/342
[A[ATraining Step: 262  | total loss: [1m[32m0.12770[0m[0m | time: 8.776s
[2K
| Adam | epoch: 024 | loss: 0.12770 - acc: 0.9561 -- iter: 288/342
[A[ATraining Step: 263  | total loss: [1m[32m0.11840[0m[0m | time: 9.461s
[2K
| Adam | epoch: 024 | loss: 0.11840 - acc: 0.9605 -- iter: 320/342
[A[ATraining Step: 264  | total loss: [1m[32m0.11823[0m[0m | time: 11.217s
[2K
| Adam | epoch: 024 | loss: 0.11823 - acc: 0.9599 | val_loss: 0.78394 - val_acc: 0.7037 -- iter: 342/342
--
Training Step: 265  | total loss: [1m[32m0.11379[0m[0m | time: 0.814s
[2K
| Adam | epoch: 025 | loss: 0.11379 - acc: 0.9594 -- iter: 032/342
[A[ATraining Step: 266  | total loss: [1m[32m0.11378[0m[0m | time: 1.660s
[2K
| Adam | epoch: 025 | loss: 0.11378 - acc: 0.9603 -- iter: 064/342
[A[ATraining Step: 267  | total loss: [1m[32m0.12446[0m[0m | time: 2.779s
[2K
| Adam | epoch: 025 | loss: 0.12446 - acc: 0.9580 -- iter: 096/342
[A[ATraining Step: 268  | total loss: [1m[32m0.14040[0m[0m | time: 3.932s
[2K
| Adam | epoch: 025 | loss: 0.14040 - acc: 0.9529 -- iter: 128/342
[A[ATraining Step: 269  | total loss: [1m[32m0.12794[0m[0m | time: 4.898s
[2K
| Adam | epoch: 025 | loss: 0.12794 - acc: 0.9576 -- iter: 160/342
[A[ATraining Step: 270  | total loss: [1m[32m0.11770[0m[0m | time: 5.867s
[2K
| Adam | epoch: 025 | loss: 0.11770 - acc: 0.9618 -- iter: 192/342
[A[ATraining Step: 271  | total loss: [1m[32m0.11384[0m[0m | time: 6.854s
[2K
| Adam | epoch: 025 | loss: 0.11384 - acc: 0.9625 -- iter: 224/342
[A[ATraining Step: 272  | total loss: [1m[32m0.11798[0m[0m | time: 7.830s
[2K
| Adam | epoch: 025 | loss: 0.11798 - acc: 0.9569 -- iter: 256/342
[A[ATraining Step: 273  | total loss: [1m[32m0.11384[0m[0m | time: 8.802s
[2K
| Adam | epoch: 025 | loss: 0.11384 - acc: 0.9581 -- iter: 288/342
[A[ATraining Step: 274  | total loss: [1m[32m0.12488[0m[0m | time: 9.783s
[2K
| Adam | epoch: 025 | loss: 0.12488 - acc: 0.9560 -- iter: 320/342
[A[ATraining Step: 275  | total loss: [1m[32m0.12517[0m[0m | time: 11.469s
[2K
| Adam | epoch: 025 | loss: 0.12517 - acc: 0.9573 | val_loss: 1.05220 - val_acc: 0.6667 -- iter: 342/342
--
Training Step: 276  | total loss: [1m[32m0.11734[0m[0m | time: 0.820s
[2K
| Adam | epoch: 026 | loss: 0.11734 - acc: 0.9570 -- iter: 032/342
[A[ATraining Step: 277  | total loss: [1m[32m0.10857[0m[0m | time: 1.876s
[2K
| Adam | epoch: 026 | loss: 0.10857 - acc: 0.9613 -- iter: 064/342
[A[ATraining Step: 278  | total loss: [1m[32m0.10468[0m[0m | time: 2.958s
[2K
| Adam | epoch: 026 | loss: 0.10468 - acc: 0.9652 -- iter: 096/342
[A[ATraining Step: 279  | total loss: [1m[32m0.10699[0m[0m | time: 3.679s
[2K
| Adam | epoch: 026 | loss: 0.10699 - acc: 0.9624 -- iter: 128/342
[A[ATraining Step: 280  | total loss: [1m[32m0.10046[0m[0m | time: 4.642s
[2K
| Adam | epoch: 026 | loss: 0.10046 - acc: 0.9662 -- iter: 160/342
[A[ATraining Step: 281  | total loss: [1m[32m0.09988[0m[0m | time: 5.599s
[2K
| Adam | epoch: 026 | loss: 0.09988 - acc: 0.9664 -- iter: 192/342
[A[ATraining Step: 282  | total loss: [1m[32m0.09315[0m[0m | time: 6.637s
[2K
| Adam | epoch: 026 | loss: 0.09315 - acc: 0.9698 -- iter: 224/342
[A[ATraining Step: 283  | total loss: [1m[32m0.10323[0m[0m | time: 7.618s
[2K
| Adam | epoch: 026 | loss: 0.10323 - acc: 0.9666 -- iter: 256/342
[A[ATraining Step: 284  | total loss: [1m[32m0.10057[0m[0m | time: 8.567s
[2K
| Adam | epoch: 026 | loss: 0.10057 - acc: 0.9637 -- iter: 288/342
[A[ATraining Step: 285  | total loss: [1m[32m0.09798[0m[0m | time: 9.604s
[2K
| Adam | epoch: 026 | loss: 0.09798 - acc: 0.9610 -- iter: 320/342
[A[ATraining Step: 286  | total loss: [1m[32m0.09094[0m[0m | time: 11.664s
[2K
| Adam | epoch: 026 | loss: 0.09094 - acc: 0.9649 | val_loss: 0.96007 - val_acc: 0.7037 -- iter: 342/342
--
Training Step: 287  | total loss: [1m[32m0.08373[0m[0m | time: 0.706s
[2K
| Adam | epoch: 027 | loss: 0.08373 - acc: 0.9684 -- iter: 032/342
[A[ATraining Step: 288  | total loss: [1m[32m0.08306[0m[0m | time: 1.478s
[2K
| Adam | epoch: 027 | loss: 0.08306 - acc: 0.9671 -- iter: 064/342
[A[ATraining Step: 289  | total loss: [1m[32m0.07976[0m[0m | time: 2.317s
[2K
| Adam | epoch: 027 | loss: 0.07976 - acc: 0.9658 -- iter: 096/342
[A[ATraining Step: 290  | total loss: [1m[32m0.08101[0m[0m | time: 3.246s
[2K
| Adam | epoch: 027 | loss: 0.08101 - acc: 0.9661 -- iter: 128/342
[A[ATraining Step: 291  | total loss: [1m[32m0.08987[0m[0m | time: 4.246s
[2K
| Adam | epoch: 027 | loss: 0.08987 - acc: 0.9664 -- iter: 160/342
[A[ATraining Step: 292  | total loss: [1m[32m0.08417[0m[0m | time: 5.290s
[2K
| Adam | epoch: 027 | loss: 0.08417 - acc: 0.9697 -- iter: 192/342
[A[ATraining Step: 293  | total loss: [1m[32m0.08159[0m[0m | time: 6.264s
[2K
| Adam | epoch: 027 | loss: 0.08159 - acc: 0.9728 -- iter: 224/342
[A[ATraining Step: 294  | total loss: [1m[32m0.07485[0m[0m | time: 7.368s
[2K
| Adam | epoch: 027 | loss: 0.07485 - acc: 0.9755 -- iter: 256/342
[A[ATraining Step: 295  | total loss: [1m[32m0.07380[0m[0m | time: 8.424s
[2K
| Adam | epoch: 027 | loss: 0.07380 - acc: 0.9748 -- iter: 288/342
[A[ATraining Step: 296  | total loss: [1m[32m0.06701[0m[0m | time: 9.402s
[2K
| Adam | epoch: 027 | loss: 0.06701 - acc: 0.9773 -- iter: 320/342
[A[ATraining Step: 297  | total loss: [1m[32m0.06604[0m[0m | time: 11.256s
[2K
| Adam | epoch: 027 | loss: 0.06604 - acc: 0.9765 | val_loss: 1.14803 - val_acc: 0.6852 -- iter: 342/342
--
Training Step: 298  | total loss: [1m[32m0.07753[0m[0m | time: 1.171s
[2K
| Adam | epoch: 028 | loss: 0.07753 - acc: 0.9726 -- iter: 032/342
[A[ATraining Step: 299  | total loss: [1m[32m0.07213[0m[0m | time: 1.805s
[2K
| Adam | epoch: 028 | loss: 0.07213 - acc: 0.9753 -- iter: 064/342
[A[ATraining Step: 300  | total loss: [1m[32m0.06620[0m[0m | time: 2.513s
[2K
| Adam | epoch: 028 | loss: 0.06620 - acc: 0.9778 -- iter: 096/342
[A[ATraining Step: 301  | total loss: [1m[32m0.06145[0m[0m | time: 3.474s
[2K
| Adam | epoch: 028 | loss: 0.06145 - acc: 0.9800 -- iter: 128/342
[A[ATraining Step: 302  | total loss: [1m[32m0.05856[0m[0m | time: 4.438s
[2K
| Adam | epoch: 028 | loss: 0.05856 - acc: 0.9820 -- iter: 160/342
[A[ATraining Step: 303  | total loss: [1m[32m0.05833[0m[0m | time: 5.465s
[2K
| Adam | epoch: 028 | loss: 0.05833 - acc: 0.9807 -- iter: 192/342
[A[ATraining Step: 304  | total loss: [1m[32m0.06750[0m[0m | time: 6.306s
[2K
| Adam | epoch: 028 | loss: 0.06750 - acc: 0.9795 -- iter: 224/342
[A[ATraining Step: 305  | total loss: [1m[32m0.06517[0m[0m | time: 7.162s
[2K
| Adam | epoch: 028 | loss: 0.06517 - acc: 0.9784 -- iter: 256/342
[A[ATraining Step: 306  | total loss: [1m[32m0.06592[0m[0m | time: 8.100s
[2K
| Adam | epoch: 028 | loss: 0.06592 - acc: 0.9774 -- iter: 288/342
[A[ATraining Step: 307  | total loss: [1m[32m0.06797[0m[0m | time: 9.136s
[2K
| Adam | epoch: 028 | loss: 0.06797 - acc: 0.9735 -- iter: 320/342
[A[ATraining Step: 308  | total loss: [1m[32m0.07769[0m[0m | time: 11.073s
[2K
| Adam | epoch: 028 | loss: 0.07769 - acc: 0.9699 | val_loss: 1.00318 - val_acc: 0.7037 -- iter: 342/342
--
Training Step: 309  | total loss: [1m[32m0.08118[0m[0m | time: 0.941s
[2K
| Adam | epoch: 029 | loss: 0.08118 - acc: 0.9697 -- iter: 032/342
[A[ATraining Step: 310  | total loss: [1m[32m0.08188[0m[0m | time: 1.925s
[2K
| Adam | epoch: 029 | loss: 0.08188 - acc: 0.9696 -- iter: 064/342
[A[ATraining Step: 311  | total loss: [1m[32m0.08201[0m[0m | time: 2.748s
[2K
| Adam | epoch: 029 | loss: 0.08201 - acc: 0.9696 -- iter: 096/342
[A[ATraining Step: 312  | total loss: [1m[32m0.07470[0m[0m | time: 3.497s
[2K
| Adam | epoch: 029 | loss: 0.07470 - acc: 0.9726 -- iter: 128/342
[A[ATraining Step: 313  | total loss: [1m[32m0.06824[0m[0m | time: 4.414s
[2K
| Adam | epoch: 029 | loss: 0.06824 - acc: 0.9753 -- iter: 160/342
[A[ATraining Step: 314  | total loss: [1m[32m0.06400[0m[0m | time: 5.346s
[2K
| Adam | epoch: 029 | loss: 0.06400 - acc: 0.9778 -- iter: 192/342
[A[ATraining Step: 315  | total loss: [1m[32m0.05867[0m[0m | time: 6.392s
[2K
| Adam | epoch: 029 | loss: 0.05867 - acc: 0.9800 -- iter: 224/342
[A[ATraining Step: 316  | total loss: [1m[32m0.05377[0m[0m | time: 7.585s
[2K
| Adam | epoch: 029 | loss: 0.05377 - acc: 0.9820 -- iter: 256/342
[A[ATraining Step: 317  | total loss: [1m[32m0.05113[0m[0m | time: 8.584s
[2K
| Adam | epoch: 029 | loss: 0.05113 - acc: 0.9838 -- iter: 288/342
[A[ATraining Step: 318  | total loss: [1m[32m0.05161[0m[0m | time: 9.641s
[2K
| Adam | epoch: 029 | loss: 0.05161 - acc: 0.9823 -- iter: 320/342
[A[ATraining Step: 319  | total loss: [1m[32m0.04750[0m[0m | time: 11.890s
[2K
| Adam | epoch: 029 | loss: 0.04750 - acc: 0.9841 | val_loss: 0.85528 - val_acc: 0.7407 -- iter: 342/342
--
Training Step: 320  | total loss: [1m[32m0.04364[0m[0m | time: 0.840s
[2K
| Adam | epoch: 030 | loss: 0.04364 - acc: 0.9857 -- iter: 032/342
[A[ATraining Step: 321  | total loss: [1m[32m0.06145[0m[0m | time: 1.751s
[2K
| Adam | epoch: 030 | loss: 0.06145 - acc: 0.9777 -- iter: 064/342
[A[ATraining Step: 322  | total loss: [1m[32m0.06570[0m[0m | time: 2.759s
[2K
| Adam | epoch: 030 | loss: 0.06570 - acc: 0.9737 -- iter: 096/342
[A[ATraining Step: 323  | total loss: [1m[32m0.05972[0m[0m | time: 3.423s
[2K
| Adam | epoch: 030 | loss: 0.05972 - acc: 0.9763 -- iter: 128/342
[A[ATraining Step: 324  | total loss: [1m[32m0.05634[0m[0m | time: 4.191s
[2K
| Adam | epoch: 030 | loss: 0.05634 - acc: 0.9787 -- iter: 160/342
[A[ATraining Step: 325  | total loss: [1m[32m0.05399[0m[0m | time: 5.137s
[2K
| Adam | epoch: 030 | loss: 0.05399 - acc: 0.9808 -- iter: 192/342
[A[ATraining Step: 326  | total loss: [1m[32m0.05709[0m[0m | time: 6.154s
[2K
| Adam | epoch: 030 | loss: 0.05709 - acc: 0.9796 -- iter: 224/342
[A[ATraining Step: 327  | total loss: [1m[32m0.06950[0m[0m | time: 7.169s
[2K
| Adam | epoch: 030 | loss: 0.06950 - acc: 0.9754 -- iter: 256/342
[A[ATraining Step: 328  | total loss: [1m[32m0.08340[0m[0m | time: 8.113s
[2K
| Adam | epoch: 030 | loss: 0.08340 - acc: 0.9716 -- iter: 288/342
[A[ATraining Step: 329  | total loss: [1m[32m0.07757[0m[0m | time: 9.243s
[2K
| Adam | epoch: 030 | loss: 0.07757 - acc: 0.9745 -- iter: 320/342
[A[ATraining Step: 330  | total loss: [1m[32m0.08580[0m[0m | time: 11.446s
[2K
| Adam | epoch: 030 | loss: 0.08580 - acc: 0.9739 | val_loss: 0.86680 - val_acc: 0.7315 -- iter: 342/342
--
Validation AUC:0.7801542776998597
Validation AUPRC:0.8319881616571367
Test AUC:0.8174957118353344
Test AUPRC:0.854822391277316
BestTestF1Score	0.73	0.39	0.69	0.64	0.85	47	26	27	8	0.38
BestTestMCCScore	0.66	0.53	0.73	0.93	0.51	28	2	51	27	0.99
BestTestAccuracyScore	0.73	0.39	0.69	0.64	0.85	47	26	27	8	0.38
BestValidationF1Score	0.79	0.48	0.75	0.75	0.84	52	17	29	10	0.38
BestValidationMCC	0.65	0.49	0.69	0.94	0.5	31	2	44	31	0.99
BestValidationAccuracy	0.79	0.48	0.75	0.75	0.84	52	17	29	10	0.38
TestPredictions (Threshold:0.99)
CHEMBL3217256,TN,INACT,0.2800000011920929	CHEMBL3597263,TP,ACT,1.0	CHEMBL2203598,TP,ACT,1.0	CHEMBL1766631,FN,ACT,0.7799999713897705	CHEMBL3597261,TP,ACT,1.0	CHEMBL412797,TN,INACT,0.019999999552965164	CHEMBL553271,FN,ACT,0.10999999940395355	CHEMBL553992,FN,ACT,0.9599999785423279	CHEMBL2414435,TP,ACT,1.0	CHEMBL1162881,FP,INACT,1.0	CHEMBL1813769,FN,ACT,0.5799999833106995	CHEMBL2430150,TP,ACT,1.0	CHEMBL3577136,FN,ACT,0.7900000214576721	CHEMBL314801,TN,INACT,0.7400000095367432	CHEMBL553287,TN,INACT,0.8700000047683716	CHEMBL227744,FN,ACT,0.3199999928474426	CHEMBL296805,TN,INACT,0.550000011920929	CHEMBL3262025,TP,ACT,1.0	CHEMBL459907,TN,INACT,0.3499999940395355	CHEMBL3109186,TP,ACT,1.0	CHEMBL2414847,TN,INACT,0.019999999552965164	CHEMBL3407813,TP,ACT,1.0	CHEMBL2414840,TN,INACT,0.4699999988079071	CHEMBL1277143,TN,INACT,0.0	CHEMBL3325612,FN,ACT,0.9800000190734863	CHEMBL3323314,FN,ACT,0.23999999463558197	CHEMBL3216853,FN,ACT,0.5799999833106995	CHEMBL127739,TN,INACT,0.03999999910593033	CHEMBL1801060,FN,ACT,0.9800000190734863	CHEMBL1946204,TN,INACT,0.8799999952316284	CHEMBL1946353,TN,INACT,0.7799999713897705	CHEMBL100932,TN,INACT,0.5400000214576721	CHEMBL1800346,FN,ACT,0.9800000190734863	CHEMBL3327298,TP,ACT,1.0	CHEMBL519772,FN,ACT,0.6200000047683716	CHEMBL1277693,TP,ACT,1.0	CHEMBL3589092,TP,ACT,1.0	CHEMBL516064,TN,INACT,0.8899999856948853	CHEMBL2326356,TN,INACT,0.8299999833106995	CHEMBL101405,TN,INACT,0.8500000238418579	CHEMBL481465,FN,ACT,0.36000001430511475	CHEMBL1222677,TN,INACT,0.05999999865889549	CHEMBL1945915,TN,INACT,0.41999998688697815	CHEMBL486371,TN,INACT,0.18000000715255737	CHEMBL491922,TP,ACT,1.0	CHEMBL536512,TN,INACT,0.0	CHEMBL481413,TN,INACT,0.5299999713897705	CHEMBL481032,FN,ACT,0.7900000214576721	CHEMBL554018,FN,ACT,0.800000011920929	CHEMBL1915179,TN,INACT,0.1899999976158142	CHEMBL1928924,FN,ACT,0.029999999329447746	CHEMBL2414851,TN,INACT,0.9200000166893005	CHEMBL2430147,TN,INACT,0.9800000190734863	CHEMBL1615292,TP,ACT,1.0	CHEMBL44833,TN,INACT,0.36000001430511475	CHEMBL1644793,TP,ACT,1.0	CHEMBL472782,TN,INACT,0.75	CHEMBL233857,TN,INACT,0.6499999761581421	CHEMBL320547,TP,ACT,0.9900000095367432	CHEMBL41060,TN,INACT,0.8600000143051147	CHEMBL3597256,TP,ACT,0.9900000095367432	CHEMBL3407812,TP,ACT,1.0	CHEMBL536313,FN,ACT,0.2199999988079071	CHEMBL1821991,TN,INACT,0.949999988079071	CHEMBL3407806,FN,ACT,0.9800000190734863	CHEMBL3597247,TP,ACT,0.9900000095367432	CHEMBL3128240,TN,INACT,0.7099999785423279	CHEMBL1269104,TN,INACT,0.9599999785423279	CHEMBL1614782,TN,INACT,0.009999999776482582	CHEMBL1744478,TN,INACT,0.8100000023841858	CHEMBL226390,TN,INACT,0.029999999329447746	CHEMBL1928923,FN,ACT,0.20000000298023224	CHEMBL227937,TN,INACT,0.009999999776482582	CHEMBL3109188,TP,ACT,0.9900000095367432	CHEMBL2414436,FN,ACT,0.5	CHEMBL1915391,TN,INACT,0.20999999344348907	CHEMBL2414451,TN,INACT,0.019999999552965164	CHEMBL472975,TN,INACT,0.09000000357627869	CHEMBL2414426,FN,ACT,0.5299999713897705	CHEMBL1915401,TN,INACT,0.10000000149011612	CHEMBL1956741,TN,INACT,0.3799999952316284	CHEMBL479268,TN,INACT,0.0	CHEMBL233652,TN,INACT,0.009999999776482582	CHEMBL1202110,TN,INACT,0.009999999776482582	CHEMBL1269105,FP,INACT,0.9900000095367432	CHEMBL535641,TN,INACT,0.07999999821186066	CHEMBL1915155,TN,INACT,0.09000000357627869	CHEMBL512136,TP,ACT,0.9900000095367432	CHEMBL1278132,FN,ACT,0.019999999552965164	CHEMBL535863,FN,ACT,0.9700000286102295	CHEMBL563369,TN,INACT,0.05999999865889549	CHEMBL3586662,TP,ACT,1.0	CHEMBL3577125,TP,ACT,0.9900000095367432	CHEMBL461230,FN,ACT,0.5799999833106995	CHEMBL229169,TP,ACT,0.9900000095367432	CHEMBL1801487,TP,ACT,1.0	CHEMBL3597265,TP,ACT,0.9900000095367432	CHEMBL3407823,TP,ACT,1.0	CHEMBL1946354,TN,INACT,0.0	CHEMBL2013188,FN,ACT,0.699999988079071	CHEMBL475163,TN,INACT,0.6399999856948853	CHEMBL501199,TN,INACT,0.6399999856948853	CHEMBL1928926,TP,ACT,1.0	CHEMBL469987,FN,ACT,0.9800000190734863	CHEMBL1926708,TN,INACT,0.9399999976158142	CHEMBL1813926,TP,ACT,1.0	CHEMBL1945914,TN,INACT,0.20000000298023224	CHEMBL1202118,FN,ACT,0.38999998569488525	

