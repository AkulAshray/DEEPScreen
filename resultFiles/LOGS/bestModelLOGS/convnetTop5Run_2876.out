ImageNetInceptionV2 CHEMBL248 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	1259
Number of inactive compounds :	1259
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL248_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL248_adam_0.001_15_0.6/
---------------------------------
Training samples: 1608
Validation samples: 503
--
Training Step: 1  | time: 70.585s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1608
[A[ATraining Step: 2  | total loss: [1m[32m0.72188[0m[0m | time: 83.145s
[2K
| Adam | epoch: 001 | loss: 0.72188 - acc: 0.3937 -- iter: 0064/1608
[A[ATraining Step: 3  | total loss: [1m[32m0.79446[0m[0m | time: 95.981s
[2K
| Adam | epoch: 001 | loss: 0.79446 - acc: 0.5318 -- iter: 0096/1608
[A[ATraining Step: 4  | total loss: [1m[32m0.80625[0m[0m | time: 108.616s
[2K
| Adam | epoch: 001 | loss: 0.80625 - acc: 0.5783 -- iter: 0128/1608
[A[ATraining Step: 5  | total loss: [1m[32m0.72406[0m[0m | time: 127.460s
[2K
| Adam | epoch: 001 | loss: 0.72406 - acc: 0.5890 -- iter: 0160/1608
[A[ATraining Step: 6  | total loss: [1m[32m0.78496[0m[0m | time: 141.746s
[2K
| Adam | epoch: 001 | loss: 0.78496 - acc: 0.5720 -- iter: 0192/1608
[A[ATraining Step: 7  | total loss: [1m[32m0.75020[0m[0m | time: 156.478s
[2K
| Adam | epoch: 001 | loss: 0.75020 - acc: 0.5475 -- iter: 0224/1608
[A[ATraining Step: 8  | total loss: [1m[32m0.72508[0m[0m | time: 174.271s
[2K
| Adam | epoch: 001 | loss: 0.72508 - acc: 0.5560 -- iter: 0256/1608
[A[ATraining Step: 9  | total loss: [1m[32m0.76115[0m[0m | time: 189.503s
[2K
| Adam | epoch: 001 | loss: 0.76115 - acc: 0.5263 -- iter: 0288/1608
[A[ATraining Step: 10  | total loss: [1m[32m0.74300[0m[0m | time: 206.417s
[2K
| Adam | epoch: 001 | loss: 0.74300 - acc: 0.5757 -- iter: 0320/1608
[A[ATraining Step: 11  | total loss: [1m[32m0.69747[0m[0m | time: 224.069s
[2K
| Adam | epoch: 001 | loss: 0.69747 - acc: 0.5842 -- iter: 0352/1608
[A[ATraining Step: 12  | total loss: [1m[32m0.68833[0m[0m | time: 241.215s
[2K
| Adam | epoch: 001 | loss: 0.68833 - acc: 0.5604 -- iter: 0384/1608
[A[ATraining Step: 13  | total loss: [1m[32m0.67309[0m[0m | time: 253.391s
[2K
| Adam | epoch: 001 | loss: 0.67309 - acc: 0.5881 -- iter: 0416/1608
[A[ATraining Step: 14  | total loss: [1m[32m0.65354[0m[0m | time: 265.485s
[2K
| Adam | epoch: 001 | loss: 0.65354 - acc: 0.5904 -- iter: 0448/1608
[A[ATraining Step: 15  | total loss: [1m[32m0.64534[0m[0m | time: 281.150s
[2K
| Adam | epoch: 001 | loss: 0.64534 - acc: 0.6162 -- iter: 0480/1608
[A[ATraining Step: 16  | total loss: [1m[32m0.64111[0m[0m | time: 298.180s
[2K
| Adam | epoch: 001 | loss: 0.64111 - acc: 0.6429 -- iter: 0512/1608
[A[ATraining Step: 17  | total loss: [1m[32m0.66225[0m[0m | time: 314.803s
[2K
| Adam | epoch: 001 | loss: 0.66225 - acc: 0.6140 -- iter: 0544/1608
[A[ATraining Step: 18  | total loss: [1m[32m0.66476[0m[0m | time: 332.699s
[2K
| Adam | epoch: 001 | loss: 0.66476 - acc: 0.6070 -- iter: 0576/1608
[A[ATraining Step: 19  | total loss: [1m[32m0.65570[0m[0m | time: 347.428s
[2K
| Adam | epoch: 001 | loss: 0.65570 - acc: 0.6546 -- iter: 0608/1608
[A[ATraining Step: 20  | total loss: [1m[32m0.67788[0m[0m | time: 359.022s
[2K
| Adam | epoch: 001 | loss: 0.67788 - acc: 0.6351 -- iter: 0640/1608
[A[ATraining Step: 21  | total loss: [1m[32m0.64830[0m[0m | time: 368.524s
[2K
| Adam | epoch: 001 | loss: 0.64830 - acc: 0.6222 -- iter: 0672/1608
[A[ATraining Step: 22  | total loss: [1m[32m0.66450[0m[0m | time: 380.905s
[2K
| Adam | epoch: 001 | loss: 0.66450 - acc: 0.6137 -- iter: 0704/1608
[A[ATraining Step: 23  | total loss: [1m[32m0.67501[0m[0m | time: 393.044s
[2K
| Adam | epoch: 001 | loss: 0.67501 - acc: 0.5988 -- iter: 0736/1608
[A[ATraining Step: 24  | total loss: [1m[32m0.66581[0m[0m | time: 416.335s
[2K
| Adam | epoch: 001 | loss: 0.66581 - acc: 0.5886 -- iter: 0768/1608
[A[ATraining Step: 25  | total loss: [1m[32m0.67286[0m[0m | time: 438.080s
[2K
| Adam | epoch: 001 | loss: 0.67286 - acc: 0.5900 -- iter: 0800/1608
[A[ATraining Step: 26  | total loss: [1m[32m0.69315[0m[0m | time: 455.137s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.5993 -- iter: 0832/1608
[A[ATraining Step: 27  | total loss: [1m[32m0.68209[0m[0m | time: 471.118s
[2K
| Adam | epoch: 001 | loss: 0.68209 - acc: 0.6300 -- iter: 0864/1608
[A[ATraining Step: 28  | total loss: [1m[32m0.67066[0m[0m | time: 488.343s
[2K
| Adam | epoch: 001 | loss: 0.67066 - acc: 0.6209 -- iter: 0896/1608
[A[ATraining Step: 29  | total loss: [1m[32m0.66744[0m[0m | time: 503.281s
[2K
| Adam | epoch: 001 | loss: 0.66744 - acc: 0.6219 -- iter: 0928/1608
[A[ATraining Step: 30  | total loss: [1m[32m0.65958[0m[0m | time: 515.481s
[2K
| Adam | epoch: 001 | loss: 0.65958 - acc: 0.6153 -- iter: 0960/1608
[A[ATraining Step: 31  | total loss: [1m[32m0.67495[0m[0m | time: 529.304s
[2K
| Adam | epoch: 001 | loss: 0.67495 - acc: 0.5959 -- iter: 0992/1608
[A[ATraining Step: 32  | total loss: [1m[32m0.67086[0m[0m | time: 546.102s
[2K
| Adam | epoch: 001 | loss: 0.67086 - acc: 0.6095 -- iter: 1024/1608
[A[ATraining Step: 33  | total loss: [1m[32m0.72239[0m[0m | time: 562.712s
[2K
| Adam | epoch: 001 | loss: 0.72239 - acc: 0.5854 -- iter: 1056/1608
[A[ATraining Step: 34  | total loss: [1m[32m0.71030[0m[0m | time: 579.214s
[2K
| Adam | epoch: 001 | loss: 0.71030 - acc: 0.5805 -- iter: 1088/1608
[A[ATraining Step: 35  | total loss: [1m[32m0.70123[0m[0m | time: 595.303s
[2K
| Adam | epoch: 001 | loss: 0.70123 - acc: 0.5702 -- iter: 1120/1608
[A[ATraining Step: 36  | total loss: [1m[32m0.68649[0m[0m | time: 607.235s
[2K
| Adam | epoch: 001 | loss: 0.68649 - acc: 0.5878 -- iter: 1152/1608
[A[ATraining Step: 37  | total loss: [1m[32m0.69003[0m[0m | time: 616.604s
[2K
| Adam | epoch: 001 | loss: 0.69003 - acc: 0.5765 -- iter: 1184/1608
[A[ATraining Step: 38  | total loss: [1m[32m0.67398[0m[0m | time: 627.858s
[2K
| Adam | epoch: 001 | loss: 0.67398 - acc: 0.5982 -- iter: 1216/1608
[A[ATraining Step: 39  | total loss: [1m[32m0.66087[0m[0m | time: 639.500s
[2K
| Adam | epoch: 001 | loss: 0.66087 - acc: 0.6093 -- iter: 1248/1608
[A[ATraining Step: 40  | total loss: [1m[32m0.65040[0m[0m | time: 651.757s
[2K
| Adam | epoch: 001 | loss: 0.65040 - acc: 0.6181 -- iter: 1280/1608
[A[ATraining Step: 41  | total loss: [1m[32m0.64553[0m[0m | time: 668.365s
[2K
| Adam | epoch: 001 | loss: 0.64553 - acc: 0.6194 -- iter: 1312/1608
[A[ATraining Step: 42  | total loss: [1m[32m0.66244[0m[0m | time: 685.343s
[2K
| Adam | epoch: 001 | loss: 0.66244 - acc: 0.5979 -- iter: 1344/1608
[A[ATraining Step: 43  | total loss: [1m[32m0.63567[0m[0m | time: 702.499s
[2K
| Adam | epoch: 001 | loss: 0.63567 - acc: 0.6303 -- iter: 1376/1608
[A[ATraining Step: 44  | total loss: [1m[32m0.60794[0m[0m | time: 718.489s
[2K
| Adam | epoch: 001 | loss: 0.60794 - acc: 0.6780 -- iter: 1408/1608
[A[ATraining Step: 45  | total loss: [1m[32m0.61407[0m[0m | time: 733.982s
[2K
| Adam | epoch: 001 | loss: 0.61407 - acc: 0.6531 -- iter: 1440/1608
[A[ATraining Step: 46  | total loss: [1m[32m0.61088[0m[0m | time: 748.917s
[2K
| Adam | epoch: 001 | loss: 0.61088 - acc: 0.6484 -- iter: 1472/1608
[A[ATraining Step: 47  | total loss: [1m[32m0.61529[0m[0m | time: 761.359s
[2K
| Adam | epoch: 001 | loss: 0.61529 - acc: 0.6497 -- iter: 1504/1608
[A[ATraining Step: 48  | total loss: [1m[32m0.60886[0m[0m | time: 774.013s
[2K
| Adam | epoch: 001 | loss: 0.60886 - acc: 0.6508 -- iter: 1536/1608
[A[ATraining Step: 49  | total loss: [1m[32m0.61195[0m[0m | time: 790.790s
[2K
| Adam | epoch: 001 | loss: 0.61195 - acc: 0.6418 -- iter: 1568/1608
[A[ATraining Step: 50  | total loss: [1m[32m0.63177[0m[0m | time: 812.742s
[2K
| Adam | epoch: 001 | loss: 0.63177 - acc: 0.6343 -- iter: 1600/1608
[A[ATraining Step: 51  | total loss: [1m[32m0.61499[0m[0m | time: 867.808s
[2K
| Adam | epoch: 001 | loss: 0.61499 - acc: 0.6424 | val_loss: 0.57907 - val_acc: 0.7356 -- iter: 1608/1608
--
Training Step: 52  | total loss: [1m[32m0.62015[0m[0m | time: 6.256s
[2K
| Adam | epoch: 002 | loss: 0.62015 - acc: 0.6398 -- iter: 0032/1608
[A[ATraining Step: 53  | total loss: [1m[32m0.60294[0m[0m | time: 23.751s
[2K
| Adam | epoch: 002 | loss: 0.60294 - acc: 0.6745 -- iter: 0064/1608
[A[ATraining Step: 54  | total loss: [1m[32m0.59968[0m[0m | time: 40.571s
[2K
| Adam | epoch: 002 | loss: 0.59968 - acc: 0.6764 -- iter: 0096/1608
[A[ATraining Step: 55  | total loss: [1m[32m0.62629[0m[0m | time: 56.413s
[2K
| Adam | epoch: 002 | loss: 0.62629 - acc: 0.6467 -- iter: 0128/1608
[A[ATraining Step: 56  | total loss: [1m[32m0.62045[0m[0m | time: 67.782s
[2K
| Adam | epoch: 002 | loss: 0.62045 - acc: 0.6393 -- iter: 0160/1608
[A[ATraining Step: 57  | total loss: [1m[32m0.60044[0m[0m | time: 80.393s
[2K
| Adam | epoch: 002 | loss: 0.60044 - acc: 0.6633 -- iter: 0192/1608
[A[ATraining Step: 58  | total loss: [1m[32m0.58481[0m[0m | time: 97.389s
[2K
| Adam | epoch: 002 | loss: 0.58481 - acc: 0.6751 -- iter: 0224/1608
[A[ATraining Step: 59  | total loss: [1m[32m0.59140[0m[0m | time: 114.779s
[2K
| Adam | epoch: 002 | loss: 0.59140 - acc: 0.6726 -- iter: 0256/1608
[A[ATraining Step: 60  | total loss: [1m[32m0.59369[0m[0m | time: 132.468s
[2K
| Adam | epoch: 002 | loss: 0.59369 - acc: 0.6745 -- iter: 0288/1608
[A[ATraining Step: 61  | total loss: [1m[32m0.59963[0m[0m | time: 150.667s
[2K
| Adam | epoch: 002 | loss: 0.59963 - acc: 0.6803 -- iter: 0320/1608
[A[ATraining Step: 62  | total loss: [1m[32m0.60974[0m[0m | time: 165.129s
[2K
| Adam | epoch: 002 | loss: 0.60974 - acc: 0.6893 -- iter: 0352/1608
[A[ATraining Step: 63  | total loss: [1m[32m0.60857[0m[0m | time: 175.563s
[2K
| Adam | epoch: 002 | loss: 0.60857 - acc: 0.6890 -- iter: 0384/1608
[A[ATraining Step: 64  | total loss: [1m[32m0.61366[0m[0m | time: 183.519s
[2K
| Adam | epoch: 002 | loss: 0.61366 - acc: 0.6928 -- iter: 0416/1608
[A[ATraining Step: 65  | total loss: [1m[32m0.61000[0m[0m | time: 193.836s
[2K
| Adam | epoch: 002 | loss: 0.61000 - acc: 0.6960 -- iter: 0448/1608
[A[ATraining Step: 66  | total loss: [1m[32m0.58825[0m[0m | time: 205.995s
[2K
| Adam | epoch: 002 | loss: 0.58825 - acc: 0.7101 -- iter: 0480/1608
[A[ATraining Step: 67  | total loss: [1m[32m0.57566[0m[0m | time: 221.324s
[2K
| Adam | epoch: 002 | loss: 0.57566 - acc: 0.7112 -- iter: 0512/1608
[A[ATraining Step: 68  | total loss: [1m[32m0.58558[0m[0m | time: 233.277s
[2K
| Adam | epoch: 002 | loss: 0.58558 - acc: 0.7121 -- iter: 0544/1608
[A[ATraining Step: 69  | total loss: [1m[32m0.57477[0m[0m | time: 244.758s
[2K
| Adam | epoch: 002 | loss: 0.57477 - acc: 0.7092 -- iter: 0576/1608
[A[ATraining Step: 70  | total loss: [1m[32m0.58678[0m[0m | time: 256.446s
[2K
| Adam | epoch: 002 | loss: 0.58678 - acc: 0.6959 -- iter: 0608/1608
[A[ATraining Step: 71  | total loss: [1m[32m0.57173[0m[0m | time: 268.370s
[2K
| Adam | epoch: 002 | loss: 0.57173 - acc: 0.7056 -- iter: 0640/1608
[A[ATraining Step: 72  | total loss: [1m[32m0.57467[0m[0m | time: 280.539s
[2K
| Adam | epoch: 002 | loss: 0.57467 - acc: 0.7000 -- iter: 0672/1608
[A[ATraining Step: 73  | total loss: [1m[32m0.56833[0m[0m | time: 292.524s
[2K
| Adam | epoch: 002 | loss: 0.56833 - acc: 0.6987 -- iter: 0704/1608
[A[ATraining Step: 74  | total loss: [1m[32m0.54698[0m[0m | time: 302.666s
[2K
| Adam | epoch: 002 | loss: 0.54698 - acc: 0.7077 -- iter: 0736/1608
[A[ATraining Step: 75  | total loss: [1m[32m0.55740[0m[0m | time: 314.282s
[2K
| Adam | epoch: 002 | loss: 0.55740 - acc: 0.6987 -- iter: 0768/1608
[A[ATraining Step: 76  | total loss: [1m[32m0.55091[0m[0m | time: 325.889s
[2K
| Adam | epoch: 002 | loss: 0.55091 - acc: 0.7109 -- iter: 0800/1608
[A[ATraining Step: 77  | total loss: [1m[32m0.54096[0m[0m | time: 337.784s
[2K
| Adam | epoch: 002 | loss: 0.54096 - acc: 0.7217 -- iter: 0832/1608
[A[ATraining Step: 78  | total loss: [1m[32m0.53224[0m[0m | time: 349.652s
[2K
| Adam | epoch: 002 | loss: 0.53224 - acc: 0.7279 -- iter: 0864/1608
[A[ATraining Step: 79  | total loss: [1m[32m0.52233[0m[0m | time: 361.910s
[2K
| Adam | epoch: 002 | loss: 0.52233 - acc: 0.7367 -- iter: 0896/1608
[A[ATraining Step: 80  | total loss: [1m[32m0.55837[0m[0m | time: 371.621s
[2K
| Adam | epoch: 002 | loss: 0.55837 - acc: 0.7348 -- iter: 0928/1608
[A[ATraining Step: 81  | total loss: [1m[32m0.56934[0m[0m | time: 379.696s
[2K
| Adam | epoch: 002 | loss: 0.56934 - acc: 0.7364 -- iter: 0960/1608
[A[ATraining Step: 82  | total loss: [1m[32m0.55798[0m[0m | time: 387.703s
[2K
| Adam | epoch: 002 | loss: 0.55798 - acc: 0.7471 -- iter: 0992/1608
[A[ATraining Step: 83  | total loss: [1m[32m0.55628[0m[0m | time: 398.184s
[2K
| Adam | epoch: 002 | loss: 0.55628 - acc: 0.7443 -- iter: 1024/1608
[A[ATraining Step: 84  | total loss: [1m[32m0.54351[0m[0m | time: 410.192s
[2K
| Adam | epoch: 002 | loss: 0.54351 - acc: 0.7542 -- iter: 1056/1608
[A[ATraining Step: 85  | total loss: [1m[32m0.56576[0m[0m | time: 421.817s
[2K
| Adam | epoch: 002 | loss: 0.56576 - acc: 0.7413 -- iter: 1088/1608
[A[ATraining Step: 86  | total loss: [1m[32m0.55608[0m[0m | time: 433.709s
[2K
| Adam | epoch: 002 | loss: 0.55608 - acc: 0.7422 -- iter: 1120/1608
[A[ATraining Step: 87  | total loss: [1m[32m0.55236[0m[0m | time: 446.030s
[2K
| Adam | epoch: 002 | loss: 0.55236 - acc: 0.7430 -- iter: 1152/1608
[A[ATraining Step: 88  | total loss: [1m[32m0.55085[0m[0m | time: 457.907s
[2K
| Adam | epoch: 002 | loss: 0.55085 - acc: 0.7468 -- iter: 1184/1608
[A[ATraining Step: 89  | total loss: [1m[32m0.54887[0m[0m | time: 469.342s
[2K
| Adam | epoch: 002 | loss: 0.54887 - acc: 0.7440 -- iter: 1216/1608
[A[ATraining Step: 90  | total loss: [1m[32m0.54091[0m[0m | time: 481.223s
[2K
| Adam | epoch: 002 | loss: 0.54091 - acc: 0.7477 -- iter: 1248/1608
[A[ATraining Step: 91  | total loss: [1m[32m0.53099[0m[0m | time: 493.013s
[2K
| Adam | epoch: 002 | loss: 0.53099 - acc: 0.7511 -- iter: 1280/1608
[A[ATraining Step: 92  | total loss: [1m[32m0.52169[0m[0m | time: 505.138s
[2K
| Adam | epoch: 002 | loss: 0.52169 - acc: 0.7572 -- iter: 1312/1608
[A[ATraining Step: 93  | total loss: [1m[32m0.53165[0m[0m | time: 515.351s
[2K
| Adam | epoch: 002 | loss: 0.53165 - acc: 0.7440 -- iter: 1344/1608
[A[ATraining Step: 94  | total loss: [1m[32m0.54914[0m[0m | time: 527.130s
[2K
| Adam | epoch: 002 | loss: 0.54914 - acc: 0.7321 -- iter: 1376/1608
[A[ATraining Step: 95  | total loss: [1m[32m0.55056[0m[0m | time: 539.010s
[2K
| Adam | epoch: 002 | loss: 0.55056 - acc: 0.7276 -- iter: 1408/1608
[A[ATraining Step: 96  | total loss: [1m[32m0.54414[0m[0m | time: 550.808s
[2K
| Adam | epoch: 002 | loss: 0.54414 - acc: 0.7299 -- iter: 1440/1608
[A[ATraining Step: 97  | total loss: [1m[32m0.53812[0m[0m | time: 563.254s
[2K
| Adam | epoch: 002 | loss: 0.53812 - acc: 0.7381 -- iter: 1472/1608
[A[ATraining Step: 98  | total loss: [1m[32m0.54288[0m[0m | time: 571.765s
[2K
| Adam | epoch: 002 | loss: 0.54288 - acc: 0.7393 -- iter: 1504/1608
[A[ATraining Step: 99  | total loss: [1m[32m0.52703[0m[0m | time: 579.647s
[2K
| Adam | epoch: 002 | loss: 0.52703 - acc: 0.7498 -- iter: 1536/1608
[A[ATraining Step: 100  | total loss: [1m[32m0.52697[0m[0m | time: 589.428s
[2K
| Adam | epoch: 002 | loss: 0.52697 - acc: 0.7498 -- iter: 1568/1608
[A[ATraining Step: 101  | total loss: [1m[32m0.50765[0m[0m | time: 603.506s
[2K
| Adam | epoch: 002 | loss: 0.50765 - acc: 0.7654 -- iter: 1600/1608
[A[ATraining Step: 102  | total loss: [1m[32m0.49006[0m[0m | time: 661.454s
[2K
| Adam | epoch: 002 | loss: 0.49006 - acc: 0.7701 | val_loss: 0.85664 - val_acc: 0.6163 -- iter: 1608/1608
--
Training Step: 103  | total loss: [1m[32m0.50735[0m[0m | time: 6.445s
[2K
| Adam | epoch: 003 | loss: 0.50735 - acc: 0.7619 -- iter: 0032/1608
[A[ATraining Step: 104  | total loss: [1m[32m0.52156[0m[0m | time: 12.270s
[2K
| Adam | epoch: 003 | loss: 0.52156 - acc: 0.7357 -- iter: 0064/1608
[A[ATraining Step: 105  | total loss: [1m[32m0.50792[0m[0m | time: 26.668s
[2K
| Adam | epoch: 003 | loss: 0.50792 - acc: 0.7371 -- iter: 0096/1608
[A[ATraining Step: 106  | total loss: [1m[32m0.51809[0m[0m | time: 41.591s
[2K
| Adam | epoch: 003 | loss: 0.51809 - acc: 0.7384 -- iter: 0128/1608
[A[ATraining Step: 107  | total loss: [1m[32m0.55701[0m[0m | time: 55.376s
[2K
| Adam | epoch: 003 | loss: 0.55701 - acc: 0.7208 -- iter: 0160/1608
[A[ATraining Step: 108  | total loss: [1m[32m0.58794[0m[0m | time: 68.682s
[2K
| Adam | epoch: 003 | loss: 0.58794 - acc: 0.7112 -- iter: 0192/1608
[A[ATraining Step: 109  | total loss: [1m[32m0.58987[0m[0m | time: 83.044s
[2K
| Adam | epoch: 003 | loss: 0.58987 - acc: 0.7151 -- iter: 0224/1608
[A[ATraining Step: 110  | total loss: [1m[32m0.59598[0m[0m | time: 98.130s
[2K
| Adam | epoch: 003 | loss: 0.59598 - acc: 0.7155 -- iter: 0256/1608
[A[ATraining Step: 111  | total loss: [1m[32m0.57661[0m[0m | time: 110.468s
[2K
| Adam | epoch: 003 | loss: 0.57661 - acc: 0.7283 -- iter: 0288/1608
[A[ATraining Step: 112  | total loss: [1m[32m0.56786[0m[0m | time: 121.929s
[2K
| Adam | epoch: 003 | loss: 0.56786 - acc: 0.7336 -- iter: 0320/1608
[A[ATraining Step: 113  | total loss: [1m[32m0.54857[0m[0m | time: 133.627s
[2K
| Adam | epoch: 003 | loss: 0.54857 - acc: 0.7446 -- iter: 0352/1608
[A[ATraining Step: 114  | total loss: [1m[32m0.55073[0m[0m | time: 149.855s
[2K
| Adam | epoch: 003 | loss: 0.55073 - acc: 0.7483 -- iter: 0384/1608
[A[ATraining Step: 115  | total loss: [1m[32m0.54013[0m[0m | time: 164.412s
[2K
| Adam | epoch: 003 | loss: 0.54013 - acc: 0.7484 -- iter: 0416/1608
[A[ATraining Step: 116  | total loss: [1m[32m0.54997[0m[0m | time: 178.453s
[2K
| Adam | epoch: 003 | loss: 0.54997 - acc: 0.7424 -- iter: 0448/1608
[A[ATraining Step: 117  | total loss: [1m[32m0.56363[0m[0m | time: 192.757s
[2K
| Adam | epoch: 003 | loss: 0.56363 - acc: 0.7337 -- iter: 0480/1608
[A[ATraining Step: 118  | total loss: [1m[32m0.56434[0m[0m | time: 207.538s
[2K
| Adam | epoch: 003 | loss: 0.56434 - acc: 0.7229 -- iter: 0512/1608
[A[ATraining Step: 119  | total loss: [1m[32m0.56820[0m[0m | time: 222.130s
[2K
| Adam | epoch: 003 | loss: 0.56820 - acc: 0.7131 -- iter: 0544/1608
[A[ATraining Step: 120  | total loss: [1m[32m0.56708[0m[0m | time: 237.879s
[2K
| Adam | epoch: 003 | loss: 0.56708 - acc: 0.7136 -- iter: 0576/1608
[A[ATraining Step: 121  | total loss: [1m[32m0.56238[0m[0m | time: 252.883s
[2K
| Adam | epoch: 003 | loss: 0.56238 - acc: 0.7173 -- iter: 0608/1608
[A[ATraining Step: 122  | total loss: [1m[32m0.54474[0m[0m | time: 266.863s
[2K
| Adam | epoch: 003 | loss: 0.54474 - acc: 0.7299 -- iter: 0640/1608
[A[ATraining Step: 123  | total loss: [1m[32m0.52955[0m[0m | time: 281.397s
[2K
| Adam | epoch: 003 | loss: 0.52955 - acc: 0.7413 -- iter: 0672/1608
[A[ATraining Step: 124  | total loss: [1m[32m0.53907[0m[0m | time: 295.835s
[2K
| Adam | epoch: 003 | loss: 0.53907 - acc: 0.7391 -- iter: 0704/1608
[A[ATraining Step: 125  | total loss: [1m[32m0.52715[0m[0m | time: 308.598s
[2K
| Adam | epoch: 003 | loss: 0.52715 - acc: 0.7402 -- iter: 0736/1608
[A[ATraining Step: 126  | total loss: [1m[32m0.51901[0m[0m | time: 322.560s
[2K
| Adam | epoch: 003 | loss: 0.51901 - acc: 0.7443 -- iter: 0768/1608
[A[ATraining Step: 127  | total loss: [1m[32m0.53273[0m[0m | time: 337.634s
[2K
| Adam | epoch: 003 | loss: 0.53273 - acc: 0.7323 -- iter: 0800/1608
[A[ATraining Step: 128  | total loss: [1m[32m0.53544[0m[0m | time: 348.267s
[2K
| Adam | epoch: 003 | loss: 0.53544 - acc: 0.7310 -- iter: 0832/1608
[A[ATraining Step: 129  | total loss: [1m[32m0.54134[0m[0m | time: 359.802s
[2K
| Adam | epoch: 003 | loss: 0.54134 - acc: 0.7266 -- iter: 0864/1608
[A[ATraining Step: 130  | total loss: [1m[32m0.52816[0m[0m | time: 372.359s
[2K
| Adam | epoch: 003 | loss: 0.52816 - acc: 0.7383 -- iter: 0896/1608
[A[ATraining Step: 131  | total loss: [1m[32m0.52656[0m[0m | time: 386.799s
[2K
| Adam | epoch: 003 | loss: 0.52656 - acc: 0.7333 -- iter: 0928/1608
[A[ATraining Step: 132  | total loss: [1m[32m0.51778[0m[0m | time: 402.518s
[2K
| Adam | epoch: 003 | loss: 0.51778 - acc: 0.7474 -- iter: 0960/1608
[A[ATraining Step: 133  | total loss: [1m[32m0.51724[0m[0m | time: 416.986s
[2K
| Adam | epoch: 003 | loss: 0.51724 - acc: 0.7539 -- iter: 0992/1608
[A[ATraining Step: 134  | total loss: [1m[32m0.51338[0m[0m | time: 431.819s
[2K
| Adam | epoch: 003 | loss: 0.51338 - acc: 0.7535 -- iter: 1024/1608
[A[ATraining Step: 135  | total loss: [1m[32m0.50391[0m[0m | time: 444.218s
[2K
| Adam | epoch: 003 | loss: 0.50391 - acc: 0.7594 -- iter: 1056/1608
[A[ATraining Step: 136  | total loss: [1m[32m0.49642[0m[0m | time: 453.885s
[2K
| Adam | epoch: 003 | loss: 0.49642 - acc: 0.7647 -- iter: 1088/1608
[A[ATraining Step: 137  | total loss: [1m[32m0.48748[0m[0m | time: 463.465s
[2K
| Adam | epoch: 003 | loss: 0.48748 - acc: 0.7726 -- iter: 1120/1608
[A[ATraining Step: 138  | total loss: [1m[32m0.47972[0m[0m | time: 478.713s
[2K
| Adam | epoch: 003 | loss: 0.47972 - acc: 0.7829 -- iter: 1152/1608
[A[ATraining Step: 139  | total loss: [1m[32m0.48011[0m[0m | time: 493.191s
[2K
| Adam | epoch: 003 | loss: 0.48011 - acc: 0.7858 -- iter: 1184/1608
[A[ATraining Step: 140  | total loss: [1m[32m0.48158[0m[0m | time: 508.033s
[2K
| Adam | epoch: 003 | loss: 0.48158 - acc: 0.7823 -- iter: 1216/1608
[A[ATraining Step: 141  | total loss: [1m[32m0.46868[0m[0m | time: 521.917s
[2K
| Adam | epoch: 003 | loss: 0.46868 - acc: 0.7915 -- iter: 1248/1608
[A[ATraining Step: 142  | total loss: [1m[32m0.46517[0m[0m | time: 536.486s
[2K
| Adam | epoch: 003 | loss: 0.46517 - acc: 0.7936 -- iter: 1280/1608
[A[ATraining Step: 143  | total loss: [1m[32m0.46714[0m[0m | time: 551.155s
[2K
| Adam | epoch: 003 | loss: 0.46714 - acc: 0.7893 -- iter: 1312/1608
[A[ATraining Step: 144  | total loss: [1m[32m0.46942[0m[0m | time: 565.746s
[2K
| Adam | epoch: 003 | loss: 0.46942 - acc: 0.7822 -- iter: 1344/1608
[A[ATraining Step: 145  | total loss: [1m[32m0.46626[0m[0m | time: 580.092s
[2K
| Adam | epoch: 003 | loss: 0.46626 - acc: 0.7915 -- iter: 1376/1608
[A[ATraining Step: 146  | total loss: [1m[32m0.46522[0m[0m | time: 595.368s
[2K
| Adam | epoch: 003 | loss: 0.46522 - acc: 0.7905 -- iter: 1408/1608
[A[ATraining Step: 147  | total loss: [1m[32m0.47742[0m[0m | time: 610.250s
[2K
| Adam | epoch: 003 | loss: 0.47742 - acc: 0.7864 -- iter: 1440/1608
[A[ATraining Step: 148  | total loss: [1m[32m0.46528[0m[0m | time: 620.871s
[2K
| Adam | epoch: 003 | loss: 0.46528 - acc: 0.7922 -- iter: 1472/1608
[A[ATraining Step: 149  | total loss: [1m[32m0.46265[0m[0m | time: 630.756s
[2K
| Adam | epoch: 003 | loss: 0.46265 - acc: 0.7942 -- iter: 1504/1608
[A[ATraining Step: 150  | total loss: [1m[32m0.46944[0m[0m | time: 642.073s
[2K
| Adam | epoch: 003 | loss: 0.46944 - acc: 0.7929 -- iter: 1536/1608
[A[ATraining Step: 151  | total loss: [1m[32m0.45617[0m[0m | time: 656.818s
[2K
| Adam | epoch: 003 | loss: 0.45617 - acc: 0.7980 -- iter: 1568/1608
[A[ATraining Step: 152  | total loss: [1m[32m0.43984[0m[0m | time: 670.916s
[2K
| Adam | epoch: 003 | loss: 0.43984 - acc: 0.8088 -- iter: 1600/1608
[A[ATraining Step: 153  | total loss: [1m[32m0.45079[0m[0m | time: 710.271s
[2K
| Adam | epoch: 003 | loss: 0.45079 - acc: 0.8029 | val_loss: 0.71387 - val_acc: 0.7018 -- iter: 1608/1608
--
Training Step: 154  | total loss: [1m[32m0.44422[0m[0m | time: 9.771s
[2K
| Adam | epoch: 004 | loss: 0.44422 - acc: 0.8101 -- iter: 0032/1608
[A[ATraining Step: 155  | total loss: [1m[32m0.45561[0m[0m | time: 13.126s
[2K
| Adam | epoch: 004 | loss: 0.45561 - acc: 0.8010 -- iter: 0064/1608
[A[ATraining Step: 156  | total loss: [1m[32m0.42672[0m[0m | time: 16.419s
[2K
| Adam | epoch: 004 | loss: 0.42672 - acc: 0.8209 -- iter: 0096/1608
[A[ATraining Step: 157  | total loss: [1m[32m0.40257[0m[0m | time: 26.189s
[2K
| Adam | epoch: 004 | loss: 0.40257 - acc: 0.8388 -- iter: 0128/1608
[A[ATraining Step: 158  | total loss: [1m[32m0.38745[0m[0m | time: 35.736s
[2K
| Adam | epoch: 004 | loss: 0.38745 - acc: 0.8456 -- iter: 0160/1608
[A[ATraining Step: 159  | total loss: [1m[32m0.39598[0m[0m | time: 46.097s
[2K
| Adam | epoch: 004 | loss: 0.39598 - acc: 0.8360 -- iter: 0192/1608
[A[ATraining Step: 160  | total loss: [1m[32m0.40814[0m[0m | time: 56.558s
[2K
| Adam | epoch: 004 | loss: 0.40814 - acc: 0.8243 -- iter: 0224/1608
[A[ATraining Step: 161  | total loss: [1m[32m0.38900[0m[0m | time: 66.596s
[2K
| Adam | epoch: 004 | loss: 0.38900 - acc: 0.8387 -- iter: 0256/1608
[A[ATraining Step: 162  | total loss: [1m[32m0.39239[0m[0m | time: 76.182s
[2K
| Adam | epoch: 004 | loss: 0.39239 - acc: 0.8330 -- iter: 0288/1608
[A[ATraining Step: 163  | total loss: [1m[32m0.41229[0m[0m | time: 86.176s
[2K
| Adam | epoch: 004 | loss: 0.41229 - acc: 0.8247 -- iter: 0320/1608
[A[ATraining Step: 164  | total loss: [1m[32m0.39856[0m[0m | time: 96.007s
[2K
| Adam | epoch: 004 | loss: 0.39856 - acc: 0.8297 -- iter: 0352/1608
[A[ATraining Step: 165  | total loss: [1m[32m0.39467[0m[0m | time: 106.012s
[2K
| Adam | epoch: 004 | loss: 0.39467 - acc: 0.8374 -- iter: 0384/1608
[A[ATraining Step: 166  | total loss: [1m[32m0.38464[0m[0m | time: 116.912s
[2K
| Adam | epoch: 004 | loss: 0.38464 - acc: 0.8380 -- iter: 0416/1608
[A[ATraining Step: 167  | total loss: [1m[32m0.38010[0m[0m | time: 126.569s
[2K
| Adam | epoch: 004 | loss: 0.38010 - acc: 0.8480 -- iter: 0448/1608
[A[ATraining Step: 168  | total loss: [1m[32m0.38050[0m[0m | time: 136.450s
[2K
| Adam | epoch: 004 | loss: 0.38050 - acc: 0.8444 -- iter: 0480/1608
[A[ATraining Step: 169  | total loss: [1m[32m0.39788[0m[0m | time: 147.201s
[2K
| Adam | epoch: 004 | loss: 0.39788 - acc: 0.8318 -- iter: 0512/1608
[A[ATraining Step: 170  | total loss: [1m[32m0.39780[0m[0m | time: 156.954s
[2K
| Adam | epoch: 004 | loss: 0.39780 - acc: 0.8299 -- iter: 0544/1608
[A[ATraining Step: 171  | total loss: [1m[32m0.42463[0m[0m | time: 166.593s
[2K
| Adam | epoch: 004 | loss: 0.42463 - acc: 0.8250 -- iter: 0576/1608
[A[ATraining Step: 172  | total loss: [1m[32m0.43073[0m[0m | time: 176.664s
[2K
| Adam | epoch: 004 | loss: 0.43073 - acc: 0.8238 -- iter: 0608/1608
[A[ATraining Step: 173  | total loss: [1m[32m0.41476[0m[0m | time: 186.046s
[2K
| Adam | epoch: 004 | loss: 0.41476 - acc: 0.8289 -- iter: 0640/1608
[A[ATraining Step: 174  | total loss: [1m[32m0.42077[0m[0m | time: 195.575s
[2K
| Adam | epoch: 004 | loss: 0.42077 - acc: 0.8304 -- iter: 0672/1608
[A[ATraining Step: 175  | total loss: [1m[32m0.41237[0m[0m | time: 205.038s
[2K
| Adam | epoch: 004 | loss: 0.41237 - acc: 0.8349 -- iter: 0704/1608
[A[ATraining Step: 176  | total loss: [1m[32m0.41526[0m[0m | time: 214.709s
[2K
| Adam | epoch: 004 | loss: 0.41526 - acc: 0.8326 -- iter: 0736/1608
[A[ATraining Step: 177  | total loss: [1m[32m0.41282[0m[0m | time: 224.474s
[2K
| Adam | epoch: 004 | loss: 0.41282 - acc: 0.8337 -- iter: 0768/1608
[A[ATraining Step: 178  | total loss: [1m[32m0.40085[0m[0m | time: 235.356s
[2K
| Adam | epoch: 004 | loss: 0.40085 - acc: 0.8410 -- iter: 0800/1608
[A[ATraining Step: 179  | total loss: [1m[32m0.39606[0m[0m | time: 245.653s
[2K
| Adam | epoch: 004 | loss: 0.39606 - acc: 0.8413 -- iter: 0832/1608
[A[ATraining Step: 180  | total loss: [1m[32m0.39278[0m[0m | time: 255.347s
[2K
| Adam | epoch: 004 | loss: 0.39278 - acc: 0.8446 -- iter: 0864/1608
[A[ATraining Step: 181  | total loss: [1m[32m0.38921[0m[0m | time: 265.455s
[2K
| Adam | epoch: 004 | loss: 0.38921 - acc: 0.8445 -- iter: 0896/1608
[A[ATraining Step: 182  | total loss: [1m[32m0.39241[0m[0m | time: 275.115s
[2K
| Adam | epoch: 004 | loss: 0.39241 - acc: 0.8476 -- iter: 0928/1608
[A[ATraining Step: 183  | total loss: [1m[32m0.38784[0m[0m | time: 284.884s
[2K
| Adam | epoch: 004 | loss: 0.38784 - acc: 0.8535 -- iter: 0960/1608
[A[ATraining Step: 184  | total loss: [1m[32m0.37537[0m[0m | time: 294.483s
[2K
| Adam | epoch: 004 | loss: 0.37537 - acc: 0.8650 -- iter: 0992/1608
[A[ATraining Step: 185  | total loss: [1m[32m0.38039[0m[0m | time: 304.249s
[2K
| Adam | epoch: 004 | loss: 0.38039 - acc: 0.8535 -- iter: 1024/1608
[A[ATraining Step: 186  | total loss: [1m[32m0.37604[0m[0m | time: 314.930s
[2K
| Adam | epoch: 004 | loss: 0.37604 - acc: 0.8556 -- iter: 1056/1608
[A[ATraining Step: 187  | total loss: [1m[32m0.37961[0m[0m | time: 325.271s
[2K
| Adam | epoch: 004 | loss: 0.37961 - acc: 0.8451 -- iter: 1088/1608
[A[ATraining Step: 188  | total loss: [1m[32m0.38494[0m[0m | time: 336.285s
[2K
| Adam | epoch: 004 | loss: 0.38494 - acc: 0.8387 -- iter: 1120/1608
[A[ATraining Step: 189  | total loss: [1m[32m0.37765[0m[0m | time: 345.692s
[2K
| Adam | epoch: 004 | loss: 0.37765 - acc: 0.8361 -- iter: 1152/1608
[A[ATraining Step: 190  | total loss: [1m[32m0.38819[0m[0m | time: 355.367s
[2K
| Adam | epoch: 004 | loss: 0.38819 - acc: 0.8275 -- iter: 1184/1608
[A[ATraining Step: 191  | total loss: [1m[32m0.39130[0m[0m | time: 364.983s
[2K
| Adam | epoch: 004 | loss: 0.39130 - acc: 0.8322 -- iter: 1216/1608
[A[ATraining Step: 192  | total loss: [1m[32m0.38910[0m[0m | time: 374.494s
[2K
| Adam | epoch: 004 | loss: 0.38910 - acc: 0.8271 -- iter: 1248/1608
[A[ATraining Step: 193  | total loss: [1m[32m0.38563[0m[0m | time: 384.297s
[2K
| Adam | epoch: 004 | loss: 0.38563 - acc: 0.8288 -- iter: 1280/1608
[A[ATraining Step: 194  | total loss: [1m[32m0.38626[0m[0m | time: 394.251s
[2K
| Adam | epoch: 004 | loss: 0.38626 - acc: 0.8272 -- iter: 1312/1608
[A[ATraining Step: 195  | total loss: [1m[32m0.36916[0m[0m | time: 404.270s
[2K
| Adam | epoch: 004 | loss: 0.36916 - acc: 0.8413 -- iter: 1344/1608
[A[ATraining Step: 196  | total loss: [1m[32m0.36808[0m[0m | time: 414.011s
[2K
| Adam | epoch: 004 | loss: 0.36808 - acc: 0.8384 -- iter: 1376/1608
[A[ATraining Step: 197  | total loss: [1m[32m0.37462[0m[0m | time: 425.483s
[2K
| Adam | epoch: 004 | loss: 0.37462 - acc: 0.8390 -- iter: 1408/1608
[A[ATraining Step: 198  | total loss: [1m[32m0.36671[0m[0m | time: 435.231s
[2K
| Adam | epoch: 004 | loss: 0.36671 - acc: 0.8457 -- iter: 1440/1608
[A[ATraining Step: 199  | total loss: [1m[32m0.35965[0m[0m | time: 445.265s
[2K
| Adam | epoch: 004 | loss: 0.35965 - acc: 0.8455 -- iter: 1472/1608
[A[ATraining Step: 200  | total loss: [1m[32m0.37989[0m[0m | time: 482.828s
[2K
| Adam | epoch: 004 | loss: 0.37989 - acc: 0.8359 | val_loss: 0.64234 - val_acc: 0.7435 -- iter: 1504/1608
--
Training Step: 201  | total loss: [1m[32m0.37099[0m[0m | time: 494.841s
[2K
| Adam | epoch: 004 | loss: 0.37099 - acc: 0.8399 -- iter: 1536/1608
[A[ATraining Step: 202  | total loss: [1m[32m0.38083[0m[0m | time: 505.534s
[2K
| Adam | epoch: 004 | loss: 0.38083 - acc: 0.8340 -- iter: 1568/1608
[A[ATraining Step: 203  | total loss: [1m[32m0.37053[0m[0m | time: 515.357s
[2K
| Adam | epoch: 004 | loss: 0.37053 - acc: 0.8443 -- iter: 1600/1608
[A[ATraining Step: 204  | total loss: [1m[32m0.36183[0m[0m | time: 553.025s
[2K
| Adam | epoch: 004 | loss: 0.36183 - acc: 0.8443 | val_loss: 0.70056 - val_acc: 0.7296 -- iter: 1608/1608
--
Training Step: 205  | total loss: [1m[32m0.34905[0m[0m | time: 10.774s
[2K
| Adam | epoch: 005 | loss: 0.34905 - acc: 0.8505 -- iter: 0032/1608
[A[ATraining Step: 206  | total loss: [1m[32m0.34035[0m[0m | time: 20.671s
[2K
| Adam | epoch: 005 | loss: 0.34035 - acc: 0.8561 -- iter: 0064/1608
[A[ATraining Step: 207  | total loss: [1m[32m0.36240[0m[0m | time: 24.044s
[2K
| Adam | epoch: 005 | loss: 0.36240 - acc: 0.8517 -- iter: 0096/1608
[A[ATraining Step: 208  | total loss: [1m[32m0.36880[0m[0m | time: 27.480s
[2K
| Adam | epoch: 005 | loss: 0.36880 - acc: 0.8415 -- iter: 0128/1608
[A[ATraining Step: 209  | total loss: [1m[32m0.34991[0m[0m | time: 37.745s
[2K
| Adam | epoch: 005 | loss: 0.34991 - acc: 0.8574 -- iter: 0160/1608
[A[ATraining Step: 210  | total loss: [1m[32m0.37124[0m[0m | time: 47.321s
[2K
| Adam | epoch: 005 | loss: 0.37124 - acc: 0.8435 -- iter: 0192/1608
[A[ATraining Step: 211  | total loss: [1m[32m0.36732[0m[0m | time: 57.209s
[2K
| Adam | epoch: 005 | loss: 0.36732 - acc: 0.8467 -- iter: 0224/1608
[A[ATraining Step: 212  | total loss: [1m[32m0.36948[0m[0m | time: 67.160s
[2K
| Adam | epoch: 005 | loss: 0.36948 - acc: 0.8370 -- iter: 0256/1608
[A[ATraining Step: 213  | total loss: [1m[32m0.37329[0m[0m | time: 76.910s
[2K
| Adam | epoch: 005 | loss: 0.37329 - acc: 0.8345 -- iter: 0288/1608
[A[ATraining Step: 214  | total loss: [1m[32m0.36414[0m[0m | time: 86.775s
[2K
| Adam | epoch: 005 | loss: 0.36414 - acc: 0.8417 -- iter: 0320/1608
[A[ATraining Step: 215  | total loss: [1m[32m0.35412[0m[0m | time: 98.157s
[2K
| Adam | epoch: 005 | loss: 0.35412 - acc: 0.8450 -- iter: 0352/1608
[A[ATraining Step: 216  | total loss: [1m[32m0.34009[0m[0m | time: 107.693s
[2K
| Adam | epoch: 005 | loss: 0.34009 - acc: 0.8543 -- iter: 0384/1608
[A[ATraining Step: 217  | total loss: [1m[32m0.35800[0m[0m | time: 118.954s
[2K
| Adam | epoch: 005 | loss: 0.35800 - acc: 0.8439 -- iter: 0416/1608
[A[ATraining Step: 218  | total loss: [1m[32m0.39085[0m[0m | time: 128.717s
[2K
| Adam | epoch: 005 | loss: 0.39085 - acc: 0.8345 -- iter: 0448/1608
[A[ATraining Step: 219  | total loss: [1m[32m0.39835[0m[0m | time: 138.598s
[2K
| Adam | epoch: 005 | loss: 0.39835 - acc: 0.8260 -- iter: 0480/1608
[A[ATraining Step: 220  | total loss: [1m[32m0.41591[0m[0m | time: 148.215s
[2K
| Adam | epoch: 005 | loss: 0.41591 - acc: 0.8153 -- iter: 0512/1608
[A[ATraining Step: 221  | total loss: [1m[32m0.40828[0m[0m | time: 158.132s
[2K
| Adam | epoch: 005 | loss: 0.40828 - acc: 0.8150 -- iter: 0544/1608
[A[ATraining Step: 222  | total loss: [1m[32m0.41804[0m[0m | time: 167.608s
[2K
| Adam | epoch: 005 | loss: 0.41804 - acc: 0.8085 -- iter: 0576/1608
[A[ATraining Step: 223  | total loss: [1m[32m0.41327[0m[0m | time: 177.354s
[2K
| Adam | epoch: 005 | loss: 0.41327 - acc: 0.8089 -- iter: 0608/1608
[A[ATraining Step: 224  | total loss: [1m[32m0.42963[0m[0m | time: 188.730s
[2K
| Adam | epoch: 005 | loss: 0.42963 - acc: 0.7937 -- iter: 0640/1608
[A[ATraining Step: 225  | total loss: [1m[32m0.40772[0m[0m | time: 198.439s
[2K
| Adam | epoch: 005 | loss: 0.40772 - acc: 0.8049 -- iter: 0672/1608
[A[ATraining Step: 226  | total loss: [1m[32m0.40925[0m[0m | time: 208.097s
[2K
| Adam | epoch: 005 | loss: 0.40925 - acc: 0.8057 -- iter: 0704/1608
[A[ATraining Step: 227  | total loss: [1m[32m0.40684[0m[0m | time: 218.025s
[2K
| Adam | epoch: 005 | loss: 0.40684 - acc: 0.8095 -- iter: 0736/1608
[A[ATraining Step: 228  | total loss: [1m[32m0.41950[0m[0m | time: 227.620s
[2K
| Adam | epoch: 005 | loss: 0.41950 - acc: 0.7942 -- iter: 0768/1608
[A[ATraining Step: 229  | total loss: [1m[32m0.43132[0m[0m | time: 237.549s
[2K
| Adam | epoch: 005 | loss: 0.43132 - acc: 0.7929 -- iter: 0800/1608
[A[ATraining Step: 230  | total loss: [1m[32m0.41973[0m[0m | time: 247.489s
[2K
| Adam | epoch: 005 | loss: 0.41973 - acc: 0.8042 -- iter: 0832/1608
[A[ATraining Step: 231  | total loss: [1m[32m0.40322[0m[0m | time: 257.482s
[2K
| Adam | epoch: 005 | loss: 0.40322 - acc: 0.8175 -- iter: 0864/1608
[A[ATraining Step: 232  | total loss: [1m[32m0.39040[0m[0m | time: 267.382s
[2K
| Adam | epoch: 005 | loss: 0.39040 - acc: 0.8327 -- iter: 0896/1608
[A[ATraining Step: 233  | total loss: [1m[32m0.38870[0m[0m | time: 278.733s
[2K
| Adam | epoch: 005 | loss: 0.38870 - acc: 0.8338 -- iter: 0928/1608
[A[ATraining Step: 234  | total loss: [1m[32m0.38385[0m[0m | time: 288.766s
[2K
| Adam | epoch: 005 | loss: 0.38385 - acc: 0.8379 -- iter: 0960/1608
[A[ATraining Step: 235  | total loss: [1m[32m0.37850[0m[0m | time: 298.290s
[2K
| Adam | epoch: 005 | loss: 0.37850 - acc: 0.8353 -- iter: 0992/1608
[A[ATraining Step: 236  | total loss: [1m[32m0.39632[0m[0m | time: 308.303s
[2K
| Adam | epoch: 005 | loss: 0.39632 - acc: 0.8237 -- iter: 1024/1608
[A[ATraining Step: 237  | total loss: [1m[32m0.39758[0m[0m | time: 319.331s
[2K
| Adam | epoch: 005 | loss: 0.39758 - acc: 0.8226 -- iter: 1056/1608
[A[ATraining Step: 238  | total loss: [1m[32m0.39612[0m[0m | time: 329.457s
[2K
| Adam | epoch: 005 | loss: 0.39612 - acc: 0.8153 -- iter: 1088/1608
[A[ATraining Step: 239  | total loss: [1m[32m0.39655[0m[0m | time: 339.407s
[2K
| Adam | epoch: 005 | loss: 0.39655 - acc: 0.8182 -- iter: 1120/1608
[A[ATraining Step: 240  | total loss: [1m[32m0.38677[0m[0m | time: 349.000s
[2K
| Adam | epoch: 005 | loss: 0.38677 - acc: 0.8301 -- iter: 1152/1608
[A[ATraining Step: 241  | total loss: [1m[32m0.38728[0m[0m | time: 358.508s
[2K
| Adam | epoch: 005 | loss: 0.38728 - acc: 0.8283 -- iter: 1184/1608
[A[ATraining Step: 242  | total loss: [1m[32m0.37019[0m[0m | time: 368.303s
[2K
| Adam | epoch: 005 | loss: 0.37019 - acc: 0.8392 -- iter: 1216/1608
[A[ATraining Step: 243  | total loss: [1m[32m0.36028[0m[0m | time: 379.505s
[2K
| Adam | epoch: 005 | loss: 0.36028 - acc: 0.8428 -- iter: 1248/1608
[A[ATraining Step: 244  | total loss: [1m[32m0.35401[0m[0m | time: 389.192s
[2K
| Adam | epoch: 005 | loss: 0.35401 - acc: 0.8398 -- iter: 1280/1608
[A[ATraining Step: 245  | total loss: [1m[32m0.34440[0m[0m | time: 399.008s
[2K
| Adam | epoch: 005 | loss: 0.34440 - acc: 0.8464 -- iter: 1312/1608
[A[ATraining Step: 246  | total loss: [1m[32m0.34805[0m[0m | time: 408.642s
[2K
| Adam | epoch: 005 | loss: 0.34805 - acc: 0.8493 -- iter: 1344/1608
[A[ATraining Step: 247  | total loss: [1m[32m0.34787[0m[0m | time: 418.248s
[2K
| Adam | epoch: 005 | loss: 0.34787 - acc: 0.8519 -- iter: 1376/1608
[A[ATraining Step: 248  | total loss: [1m[32m0.33544[0m[0m | time: 428.386s
[2K
| Adam | epoch: 005 | loss: 0.33544 - acc: 0.8604 -- iter: 1408/1608
[A[ATraining Step: 249  | total loss: [1m[32m0.33382[0m[0m | time: 438.388s
[2K
| Adam | epoch: 005 | loss: 0.33382 - acc: 0.8588 -- iter: 1440/1608
[A[ATraining Step: 250  | total loss: [1m[32m0.32097[0m[0m | time: 447.968s
[2K
| Adam | epoch: 005 | loss: 0.32097 - acc: 0.8666 -- iter: 1472/1608
[A[ATraining Step: 251  | total loss: [1m[32m0.31158[0m[0m | time: 457.775s
[2K
| Adam | epoch: 005 | loss: 0.31158 - acc: 0.8737 -- iter: 1504/1608
[A[ATraining Step: 252  | total loss: [1m[32m0.32776[0m[0m | time: 469.158s
[2K
| Adam | epoch: 005 | loss: 0.32776 - acc: 0.8676 -- iter: 1536/1608
[A[ATraining Step: 253  | total loss: [1m[32m0.33826[0m[0m | time: 478.608s
[2K
| Adam | epoch: 005 | loss: 0.33826 - acc: 0.8621 -- iter: 1568/1608
[A[ATraining Step: 254  | total loss: [1m[32m0.34655[0m[0m | time: 488.464s
[2K
| Adam | epoch: 005 | loss: 0.34655 - acc: 0.8540 -- iter: 1600/1608
[A[ATraining Step: 255  | total loss: [1m[32m0.34613[0m[0m | time: 527.873s
[2K
| Adam | epoch: 005 | loss: 0.34613 - acc: 0.8467 | val_loss: 0.64320 - val_acc: 0.6839 -- iter: 1608/1608
--
Training Step: 256  | total loss: [1m[32m0.35170[0m[0m | time: 11.388s
[2K
| Adam | epoch: 006 | loss: 0.35170 - acc: 0.8496 -- iter: 0032/1608
[A[ATraining Step: 257  | total loss: [1m[32m0.35168[0m[0m | time: 21.123s
[2K
| Adam | epoch: 006 | loss: 0.35168 - acc: 0.8521 -- iter: 0064/1608
[A[ATraining Step: 258  | total loss: [1m[32m0.34280[0m[0m | time: 30.681s
[2K
| Adam | epoch: 006 | loss: 0.34280 - acc: 0.8513 -- iter: 0096/1608
[A[ATraining Step: 259  | total loss: [1m[32m0.34320[0m[0m | time: 34.224s
[2K
| Adam | epoch: 006 | loss: 0.34320 - acc: 0.8568 -- iter: 0128/1608
[A[ATraining Step: 260  | total loss: [1m[32m0.35723[0m[0m | time: 37.648s
[2K
| Adam | epoch: 006 | loss: 0.35723 - acc: 0.8461 -- iter: 0160/1608
[A[ATraining Step: 261  | total loss: [1m[32m0.34667[0m[0m | time: 47.192s
[2K
| Adam | epoch: 006 | loss: 0.34667 - acc: 0.8490 -- iter: 0192/1608
[A[ATraining Step: 262  | total loss: [1m[32m0.34534[0m[0m | time: 56.684s
[2K
| Adam | epoch: 006 | loss: 0.34534 - acc: 0.8453 -- iter: 0224/1608
[A[ATraining Step: 263  | total loss: [1m[32m0.34653[0m[0m | time: 66.312s
[2K
| Adam | epoch: 006 | loss: 0.34653 - acc: 0.8420 -- iter: 0256/1608
[A[ATraining Step: 264  | total loss: [1m[32m0.34282[0m[0m | time: 76.187s
[2K
| Adam | epoch: 006 | loss: 0.34282 - acc: 0.8422 -- iter: 0288/1608
[A[ATraining Step: 265  | total loss: [1m[32m0.34926[0m[0m | time: 85.982s
[2K
| Adam | epoch: 006 | loss: 0.34926 - acc: 0.8330 -- iter: 0320/1608
[A[ATraining Step: 266  | total loss: [1m[32m0.34778[0m[0m | time: 96.826s
[2K
| Adam | epoch: 006 | loss: 0.34778 - acc: 0.8309 -- iter: 0352/1608
[A[ATraining Step: 267  | total loss: [1m[32m0.35814[0m[0m | time: 106.876s
[2K
| Adam | epoch: 006 | loss: 0.35814 - acc: 0.8291 -- iter: 0384/1608
[A[ATraining Step: 268  | total loss: [1m[32m0.36750[0m[0m | time: 116.584s
[2K
| Adam | epoch: 006 | loss: 0.36750 - acc: 0.8243 -- iter: 0416/1608
[A[ATraining Step: 269  | total loss: [1m[32m0.36904[0m[0m | time: 126.616s
[2K
| Adam | epoch: 006 | loss: 0.36904 - acc: 0.8169 -- iter: 0448/1608
[A[ATraining Step: 270  | total loss: [1m[32m0.36815[0m[0m | time: 136.376s
[2K
| Adam | epoch: 006 | loss: 0.36815 - acc: 0.8164 -- iter: 0480/1608
[A[ATraining Step: 271  | total loss: [1m[32m0.36561[0m[0m | time: 146.043s
[2K
| Adam | epoch: 006 | loss: 0.36561 - acc: 0.8223 -- iter: 0512/1608
[A[ATraining Step: 272  | total loss: [1m[32m0.35363[0m[0m | time: 155.943s
[2K
| Adam | epoch: 006 | loss: 0.35363 - acc: 0.8244 -- iter: 0544/1608
[A[ATraining Step: 273  | total loss: [1m[32m0.35291[0m[0m | time: 167.479s
[2K
| Adam | epoch: 006 | loss: 0.35291 - acc: 0.8295 -- iter: 0576/1608
[A[ATraining Step: 274  | total loss: [1m[32m0.35922[0m[0m | time: 177.464s
[2K
| Adam | epoch: 006 | loss: 0.35922 - acc: 0.8309 -- iter: 0608/1608
[A[ATraining Step: 275  | total loss: [1m[32m0.34911[0m[0m | time: 187.934s
[2K
| Adam | epoch: 006 | loss: 0.34911 - acc: 0.8447 -- iter: 0640/1608
[A[ATraining Step: 276  | total loss: [1m[32m0.34848[0m[0m | time: 198.557s
[2K
| Adam | epoch: 006 | loss: 0.34848 - acc: 0.8446 -- iter: 0672/1608
[A[ATraining Step: 277  | total loss: [1m[32m0.37864[0m[0m | time: 208.335s
[2K
| Adam | epoch: 006 | loss: 0.37864 - acc: 0.8320 -- iter: 0704/1608
[A[ATraining Step: 278  | total loss: [1m[32m0.37675[0m[0m | time: 217.978s
[2K
| Adam | epoch: 006 | loss: 0.37675 - acc: 0.8394 -- iter: 0736/1608
[A[ATraining Step: 279  | total loss: [1m[32m0.36740[0m[0m | time: 227.731s
[2K
| Adam | epoch: 006 | loss: 0.36740 - acc: 0.8461 -- iter: 0768/1608
[A[ATraining Step: 280  | total loss: [1m[32m0.37296[0m[0m | time: 237.559s
[2K
| Adam | epoch: 006 | loss: 0.37296 - acc: 0.8459 -- iter: 0800/1608
[A[ATraining Step: 281  | total loss: [1m[32m0.35799[0m[0m | time: 247.451s
[2K
| Adam | epoch: 006 | loss: 0.35799 - acc: 0.8519 -- iter: 0832/1608
[A[ATraining Step: 282  | total loss: [1m[32m0.35380[0m[0m | time: 257.108s
[2K
| Adam | epoch: 006 | loss: 0.35380 - acc: 0.8480 -- iter: 0864/1608
[A[ATraining Step: 283  | total loss: [1m[32m0.33647[0m[0m | time: 266.897s
[2K
| Adam | epoch: 006 | loss: 0.33647 - acc: 0.8569 -- iter: 0896/1608
[A[ATraining Step: 284  | total loss: [1m[32m0.32901[0m[0m | time: 276.874s
[2K
| Adam | epoch: 006 | loss: 0.32901 - acc: 0.8556 -- iter: 0928/1608
[A[ATraining Step: 285  | total loss: [1m[32m0.34988[0m[0m | time: 287.808s
[2K
| Adam | epoch: 006 | loss: 0.34988 - acc: 0.8482 -- iter: 0960/1608
[A[ATraining Step: 286  | total loss: [1m[32m0.38817[0m[0m | time: 297.389s
[2K
| Adam | epoch: 006 | loss: 0.38817 - acc: 0.8321 -- iter: 0992/1608
[A[ATraining Step: 287  | total loss: [1m[32m0.37256[0m[0m | time: 307.089s
[2K
| Adam | epoch: 006 | loss: 0.37256 - acc: 0.8427 -- iter: 1024/1608
[A[ATraining Step: 288  | total loss: [1m[32m0.37323[0m[0m | time: 316.806s
[2K
| Adam | epoch: 006 | loss: 0.37323 - acc: 0.8334 -- iter: 1056/1608
[A[ATraining Step: 289  | total loss: [1m[32m0.36566[0m[0m | time: 326.885s
[2K
| Adam | epoch: 006 | loss: 0.36566 - acc: 0.8282 -- iter: 1088/1608
[A[ATraining Step: 290  | total loss: [1m[32m0.36804[0m[0m | time: 336.491s
[2K
| Adam | epoch: 006 | loss: 0.36804 - acc: 0.8266 -- iter: 1120/1608
[A[ATraining Step: 291  | total loss: [1m[32m0.34814[0m[0m | time: 346.436s
[2K
| Adam | epoch: 006 | loss: 0.34814 - acc: 0.8377 -- iter: 1152/1608
[A[ATraining Step: 292  | total loss: [1m[32m0.33487[0m[0m | time: 356.185s
[2K
| Adam | epoch: 006 | loss: 0.33487 - acc: 0.8477 -- iter: 1184/1608
[A[ATraining Step: 293  | total loss: [1m[32m0.32467[0m[0m | time: 367.488s
[2K
| Adam | epoch: 006 | loss: 0.32467 - acc: 0.8504 -- iter: 1216/1608
[A[ATraining Step: 294  | total loss: [1m[32m0.33251[0m[0m | time: 378.535s
[2K
| Adam | epoch: 006 | loss: 0.33251 - acc: 0.8466 -- iter: 1248/1608
[A[ATraining Step: 295  | total loss: [1m[32m0.36432[0m[0m | time: 388.371s
[2K
| Adam | epoch: 006 | loss: 0.36432 - acc: 0.8307 -- iter: 1280/1608
[A[ATraining Step: 296  | total loss: [1m[32m0.35716[0m[0m | time: 397.983s
[2K
| Adam | epoch: 006 | loss: 0.35716 - acc: 0.8320 -- iter: 1312/1608
[A[ATraining Step: 297  | total loss: [1m[32m0.34474[0m[0m | time: 407.378s
[2K
| Adam | epoch: 006 | loss: 0.34474 - acc: 0.8394 -- iter: 1344/1608
[A[ATraining Step: 298  | total loss: [1m[32m0.33804[0m[0m | time: 416.736s
[2K
| Adam | epoch: 006 | loss: 0.33804 - acc: 0.8430 -- iter: 1376/1608
[A[ATraining Step: 299  | total loss: [1m[32m0.32737[0m[0m | time: 426.237s
[2K
| Adam | epoch: 006 | loss: 0.32737 - acc: 0.8462 -- iter: 1408/1608
[A[ATraining Step: 300  | total loss: [1m[32m0.32896[0m[0m | time: 435.918s
[2K
| Adam | epoch: 006 | loss: 0.32896 - acc: 0.8428 -- iter: 1440/1608
[A[ATraining Step: 301  | total loss: [1m[32m0.31302[0m[0m | time: 445.677s
[2K
| Adam | epoch: 006 | loss: 0.31302 - acc: 0.8554 -- iter: 1472/1608
[A[ATraining Step: 302  | total loss: [1m[32m0.30297[0m[0m | time: 455.059s
[2K
| Adam | epoch: 006 | loss: 0.30297 - acc: 0.8667 -- iter: 1504/1608
[A[ATraining Step: 303  | total loss: [1m[32m0.29941[0m[0m | time: 466.364s
[2K
| Adam | epoch: 006 | loss: 0.29941 - acc: 0.8676 -- iter: 1536/1608
[A[ATraining Step: 304  | total loss: [1m[32m0.30621[0m[0m | time: 476.022s
[2K
| Adam | epoch: 006 | loss: 0.30621 - acc: 0.8621 -- iter: 1568/1608
[A[ATraining Step: 305  | total loss: [1m[32m0.30970[0m[0m | time: 485.688s
[2K
| Adam | epoch: 006 | loss: 0.30970 - acc: 0.8634 -- iter: 1600/1608
[A[ATraining Step: 306  | total loss: [1m[32m0.29258[0m[0m | time: 523.493s
[2K
| Adam | epoch: 006 | loss: 0.29258 - acc: 0.8739 | val_loss: 0.44792 - val_acc: 0.7992 -- iter: 1608/1608
--
Training Step: 307  | total loss: [1m[32m0.29007[0m[0m | time: 11.514s
[2K
| Adam | epoch: 007 | loss: 0.29007 - acc: 0.8771 -- iter: 0032/1608
[A[ATraining Step: 308  | total loss: [1m[32m0.28598[0m[0m | time: 21.160s
[2K
| Adam | epoch: 007 | loss: 0.28598 - acc: 0.8769 -- iter: 0064/1608
[A[ATraining Step: 309  | total loss: [1m[32m0.31670[0m[0m | time: 31.120s
[2K
| Adam | epoch: 007 | loss: 0.31670 - acc: 0.8674 -- iter: 0096/1608
[A[ATraining Step: 310  | total loss: [1m[32m0.30286[0m[0m | time: 40.725s
[2K
| Adam | epoch: 007 | loss: 0.30286 - acc: 0.8712 -- iter: 0128/1608
[A[ATraining Step: 311  | total loss: [1m[32m0.31698[0m[0m | time: 44.300s
[2K
| Adam | epoch: 007 | loss: 0.31698 - acc: 0.8654 -- iter: 0160/1608
[A[ATraining Step: 312  | total loss: [1m[32m0.28870[0m[0m | time: 47.667s
[2K
| Adam | epoch: 007 | loss: 0.28870 - acc: 0.8788 -- iter: 0192/1608
[A[ATraining Step: 313  | total loss: [1m[32m0.26287[0m[0m | time: 57.371s
[2K
| Adam | epoch: 007 | loss: 0.26287 - acc: 0.8909 -- iter: 0224/1608
[A[ATraining Step: 314  | total loss: [1m[32m0.27748[0m[0m | time: 67.418s
[2K
| Adam | epoch: 007 | loss: 0.27748 - acc: 0.8769 -- iter: 0256/1608
[A[ATraining Step: 315  | total loss: [1m[32m0.26664[0m[0m | time: 77.104s
[2K
| Adam | epoch: 007 | loss: 0.26664 - acc: 0.8860 -- iter: 0288/1608
[A[ATraining Step: 316  | total loss: [1m[32m0.28545[0m[0m | time: 88.299s
[2K
| Adam | epoch: 007 | loss: 0.28545 - acc: 0.8787 -- iter: 0320/1608
[A[ATraining Step: 317  | total loss: [1m[32m0.29133[0m[0m | time: 98.148s
[2K
| Adam | epoch: 007 | loss: 0.29133 - acc: 0.8783 -- iter: 0352/1608
[A[ATraining Step: 318  | total loss: [1m[32m0.26959[0m[0m | time: 107.789s
[2K
| Adam | epoch: 007 | loss: 0.26959 - acc: 0.8905 -- iter: 0384/1608
[A[ATraining Step: 319  | total loss: [1m[32m0.27916[0m[0m | time: 117.471s
[2K
| Adam | epoch: 007 | loss: 0.27916 - acc: 0.8827 -- iter: 0416/1608
[A[ATraining Step: 320  | total loss: [1m[32m0.27100[0m[0m | time: 127.449s
[2K
| Adam | epoch: 007 | loss: 0.27100 - acc: 0.8850 -- iter: 0448/1608
[A[ATraining Step: 321  | total loss: [1m[32m0.30152[0m[0m | time: 137.222s
[2K
| Adam | epoch: 007 | loss: 0.30152 - acc: 0.8684 -- iter: 0480/1608
[A[ATraining Step: 322  | total loss: [1m[32m0.28184[0m[0m | time: 146.949s
[2K
| Adam | epoch: 007 | loss: 0.28184 - acc: 0.8784 -- iter: 0512/1608
[A[ATraining Step: 323  | total loss: [1m[32m0.28873[0m[0m | time: 156.759s
[2K
| Adam | epoch: 007 | loss: 0.28873 - acc: 0.8781 -- iter: 0544/1608
[A[ATraining Step: 324  | total loss: [1m[32m0.29487[0m[0m | time: 166.403s
[2K
| Adam | epoch: 007 | loss: 0.29487 - acc: 0.8778 -- iter: 0576/1608
[A[ATraining Step: 325  | total loss: [1m[32m0.29016[0m[0m | time: 177.603s
[2K
| Adam | epoch: 007 | loss: 0.29016 - acc: 0.8806 -- iter: 0608/1608
[A[ATraining Step: 326  | total loss: [1m[32m0.28518[0m[0m | time: 187.356s
[2K
| Adam | epoch: 007 | loss: 0.28518 - acc: 0.8832 -- iter: 0640/1608
[A[ATraining Step: 327  | total loss: [1m[32m0.30363[0m[0m | time: 197.015s
[2K
| Adam | epoch: 007 | loss: 0.30363 - acc: 0.8824 -- iter: 0672/1608
[A[ATraining Step: 328  | total loss: [1m[32m0.29015[0m[0m | time: 208.403s
[2K
| Adam | epoch: 007 | loss: 0.29015 - acc: 0.8848 -- iter: 0704/1608
[A[ATraining Step: 329  | total loss: [1m[32m0.27875[0m[0m | time: 218.200s
[2K
| Adam | epoch: 007 | loss: 0.27875 - acc: 0.8900 -- iter: 0736/1608
[A[ATraining Step: 330  | total loss: [1m[32m0.28794[0m[0m | time: 227.940s
[2K
| Adam | epoch: 007 | loss: 0.28794 - acc: 0.8854 -- iter: 0768/1608
[A[ATraining Step: 331  | total loss: [1m[32m0.28811[0m[0m | time: 237.845s
[2K
| Adam | epoch: 007 | loss: 0.28811 - acc: 0.8844 -- iter: 0800/1608
[A[ATraining Step: 332  | total loss: [1m[32m0.29784[0m[0m | time: 247.534s
[2K
| Adam | epoch: 007 | loss: 0.29784 - acc: 0.8803 -- iter: 0832/1608
[A[ATraining Step: 333  | total loss: [1m[32m0.29896[0m[0m | time: 257.113s
[2K
| Adam | epoch: 007 | loss: 0.29896 - acc: 0.8735 -- iter: 0864/1608
[A[ATraining Step: 334  | total loss: [1m[32m0.29492[0m[0m | time: 266.914s
[2K
| Adam | epoch: 007 | loss: 0.29492 - acc: 0.8737 -- iter: 0896/1608
[A[ATraining Step: 335  | total loss: [1m[32m0.29227[0m[0m | time: 278.088s
[2K
| Adam | epoch: 007 | loss: 0.29227 - acc: 0.8769 -- iter: 0928/1608
[A[ATraining Step: 336  | total loss: [1m[32m0.28775[0m[0m | time: 287.835s
[2K
| Adam | epoch: 007 | loss: 0.28775 - acc: 0.8830 -- iter: 0960/1608
[A[ATraining Step: 337  | total loss: [1m[32m0.28262[0m[0m | time: 297.584s
[2K
| Adam | epoch: 007 | loss: 0.28262 - acc: 0.8853 -- iter: 0992/1608
[A[ATraining Step: 338  | total loss: [1m[32m0.26931[0m[0m | time: 307.472s
[2K
| Adam | epoch: 007 | loss: 0.26931 - acc: 0.8968 -- iter: 1024/1608
[A[ATraining Step: 339  | total loss: [1m[32m0.26051[0m[0m | time: 317.223s
[2K
| Adam | epoch: 007 | loss: 0.26051 - acc: 0.9040 -- iter: 1056/1608
[A[ATraining Step: 340  | total loss: [1m[32m0.26201[0m[0m | time: 327.002s
[2K
| Adam | epoch: 007 | loss: 0.26201 - acc: 0.9042 -- iter: 1088/1608
[A[ATraining Step: 341  | total loss: [1m[32m0.24219[0m[0m | time: 336.705s
[2K
| Adam | epoch: 007 | loss: 0.24219 - acc: 0.9138 -- iter: 1120/1608
[A[ATraining Step: 342  | total loss: [1m[32m0.25727[0m[0m | time: 346.556s
[2K
| Adam | epoch: 007 | loss: 0.25727 - acc: 0.9099 -- iter: 1152/1608
[A[ATraining Step: 343  | total loss: [1m[32m0.25395[0m[0m | time: 356.238s
[2K
| Adam | epoch: 007 | loss: 0.25395 - acc: 0.9127 -- iter: 1184/1608
[A[ATraining Step: 344  | total loss: [1m[32m0.25383[0m[0m | time: 371.076s
[2K
| Adam | epoch: 007 | loss: 0.25383 - acc: 0.9120 -- iter: 1216/1608
[A[ATraining Step: 345  | total loss: [1m[32m0.25296[0m[0m | time: 379.062s
[2K
| Adam | epoch: 007 | loss: 0.25296 - acc: 0.9083 -- iter: 1248/1608
[A[ATraining Step: 346  | total loss: [1m[32m0.24440[0m[0m | time: 386.771s
[2K
| Adam | epoch: 007 | loss: 0.24440 - acc: 0.9144 -- iter: 1280/1608
[A[ATraining Step: 347  | total loss: [1m[32m0.23898[0m[0m | time: 394.529s
[2K
| Adam | epoch: 007 | loss: 0.23898 - acc: 0.9167 -- iter: 1312/1608
[A[ATraining Step: 348  | total loss: [1m[32m0.23668[0m[0m | time: 402.506s
[2K
| Adam | epoch: 007 | loss: 0.23668 - acc: 0.9094 -- iter: 1344/1608
[A[ATraining Step: 349  | total loss: [1m[32m0.23183[0m[0m | time: 410.174s
[2K
| Adam | epoch: 007 | loss: 0.23183 - acc: 0.9122 -- iter: 1376/1608
[A[ATraining Step: 350  | total loss: [1m[32m0.24212[0m[0m | time: 418.007s
[2K
| Adam | epoch: 007 | loss: 0.24212 - acc: 0.9085 -- iter: 1408/1608
[A[ATraining Step: 351  | total loss: [1m[32m0.23553[0m[0m | time: 425.961s
[2K
| Adam | epoch: 007 | loss: 0.23553 - acc: 0.9083 -- iter: 1440/1608
[A[ATraining Step: 352  | total loss: [1m[32m0.23869[0m[0m | time: 433.937s
[2K
| Adam | epoch: 007 | loss: 0.23869 - acc: 0.9049 -- iter: 1472/1608
[A[ATraining Step: 353  | total loss: [1m[32m0.24470[0m[0m | time: 441.827s
[2K
| Adam | epoch: 007 | loss: 0.24470 - acc: 0.9019 -- iter: 1504/1608
[A[ATraining Step: 354  | total loss: [1m[32m0.23653[0m[0m | time: 449.716s
[2K
| Adam | epoch: 007 | loss: 0.23653 - acc: 0.9055 -- iter: 1536/1608
[A[ATraining Step: 355  | total loss: [1m[32m0.23309[0m[0m | time: 457.660s
[2K
| Adam | epoch: 007 | loss: 0.23309 - acc: 0.8993 -- iter: 1568/1608
[A[ATraining Step: 356  | total loss: [1m[32m0.23408[0m[0m | time: 465.472s
[2K
| Adam | epoch: 007 | loss: 0.23408 - acc: 0.8969 -- iter: 1600/1608
[A[ATraining Step: 357  | total loss: [1m[32m0.22551[0m[0m | time: 495.430s
[2K
| Adam | epoch: 007 | loss: 0.22551 - acc: 0.9041 | val_loss: 0.43283 - val_acc: 0.8171 -- iter: 1608/1608
--
Training Step: 358  | total loss: [1m[32m0.21621[0m[0m | time: 7.742s
[2K
| Adam | epoch: 008 | loss: 0.21621 - acc: 0.9043 -- iter: 0032/1608
[A[ATraining Step: 359  | total loss: [1m[32m0.21306[0m[0m | time: 15.566s
[2K
| Adam | epoch: 008 | loss: 0.21306 - acc: 0.9045 -- iter: 0064/1608
[A[ATraining Step: 360  | total loss: [1m[32m0.21628[0m[0m | time: 23.295s
[2K
| Adam | epoch: 008 | loss: 0.21628 - acc: 0.9047 -- iter: 0096/1608
[A[ATraining Step: 361  | total loss: [1m[32m0.22948[0m[0m | time: 31.268s
[2K
| Adam | epoch: 008 | loss: 0.22948 - acc: 0.9079 -- iter: 0128/1608
[A[ATraining Step: 362  | total loss: [1m[32m0.21892[0m[0m | time: 39.068s
[2K
| Adam | epoch: 008 | loss: 0.21892 - acc: 0.9140 -- iter: 0160/1608
[A[ATraining Step: 363  | total loss: [1m[32m0.24705[0m[0m | time: 41.816s
[2K
| Adam | epoch: 008 | loss: 0.24705 - acc: 0.9007 -- iter: 0192/1608
[A[ATraining Step: 364  | total loss: [1m[32m0.27073[0m[0m | time: 44.608s
[2K
| Adam | epoch: 008 | loss: 0.27073 - acc: 0.8857 -- iter: 0224/1608
[A[ATraining Step: 365  | total loss: [1m[32m0.25058[0m[0m | time: 52.495s
[2K
| Adam | epoch: 008 | loss: 0.25058 - acc: 0.8971 -- iter: 0256/1608
[A[ATraining Step: 366  | total loss: [1m[32m0.24506[0m[0m | time: 60.404s
[2K
| Adam | epoch: 008 | loss: 0.24506 - acc: 0.9043 -- iter: 0288/1608
[A[ATraining Step: 367  | total loss: [1m[32m0.24717[0m[0m | time: 68.338s
[2K
| Adam | epoch: 008 | loss: 0.24717 - acc: 0.9045 -- iter: 0320/1608
[A[ATraining Step: 368  | total loss: [1m[32m0.23891[0m[0m | time: 76.212s
[2K
| Adam | epoch: 008 | loss: 0.23891 - acc: 0.9078 -- iter: 0352/1608
[A[ATraining Step: 369  | total loss: [1m[32m0.23225[0m[0m | time: 84.105s
[2K
| Adam | epoch: 008 | loss: 0.23225 - acc: 0.9139 -- iter: 0384/1608
[A[ATraining Step: 370  | total loss: [1m[32m0.24280[0m[0m | time: 92.081s
[2K
| Adam | epoch: 008 | loss: 0.24280 - acc: 0.9069 -- iter: 0416/1608
[A[ATraining Step: 371  | total loss: [1m[32m0.23780[0m[0m | time: 99.889s
[2K
| Adam | epoch: 008 | loss: 0.23780 - acc: 0.9099 -- iter: 0448/1608
[A[ATraining Step: 372  | total loss: [1m[32m0.22841[0m[0m | time: 107.667s
[2K
| Adam | epoch: 008 | loss: 0.22841 - acc: 0.9127 -- iter: 0480/1608
[A[ATraining Step: 373  | total loss: [1m[32m0.22286[0m[0m | time: 115.565s
[2K
| Adam | epoch: 008 | loss: 0.22286 - acc: 0.9152 -- iter: 0512/1608
[A[ATraining Step: 374  | total loss: [1m[32m0.22370[0m[0m | time: 123.428s
[2K
| Adam | epoch: 008 | loss: 0.22370 - acc: 0.9174 -- iter: 0544/1608
[A[ATraining Step: 375  | total loss: [1m[32m0.22129[0m[0m | time: 131.180s
[2K
| Adam | epoch: 008 | loss: 0.22129 - acc: 0.9132 -- iter: 0576/1608
[A[ATraining Step: 376  | total loss: [1m[32m0.23423[0m[0m | time: 139.043s
[2K
| Adam | epoch: 008 | loss: 0.23423 - acc: 0.9093 -- iter: 0608/1608
[A[ATraining Step: 377  | total loss: [1m[32m0.24249[0m[0m | time: 146.854s
[2K
| Adam | epoch: 008 | loss: 0.24249 - acc: 0.9059 -- iter: 0640/1608
[A[ATraining Step: 378  | total loss: [1m[32m0.25278[0m[0m | time: 154.770s
[2K
| Adam | epoch: 008 | loss: 0.25278 - acc: 0.9059 -- iter: 0672/1608
[A[ATraining Step: 379  | total loss: [1m[32m0.25110[0m[0m | time: 162.764s
[2K
| Adam | epoch: 008 | loss: 0.25110 - acc: 0.9060 -- iter: 0704/1608
[A[ATraining Step: 380  | total loss: [1m[32m0.26161[0m[0m | time: 170.648s
[2K
| Adam | epoch: 008 | loss: 0.26161 - acc: 0.9060 -- iter: 0736/1608
[A[ATraining Step: 381  | total loss: [1m[32m0.26240[0m[0m | time: 178.453s
[2K
| Adam | epoch: 008 | loss: 0.26240 - acc: 0.9060 -- iter: 0768/1608
[A[ATraining Step: 382  | total loss: [1m[32m0.28483[0m[0m | time: 186.380s
[2K
| Adam | epoch: 008 | loss: 0.28483 - acc: 0.8998 -- iter: 0800/1608
[A[ATraining Step: 383  | total loss: [1m[32m0.27436[0m[0m | time: 194.423s
[2K
| Adam | epoch: 008 | loss: 0.27436 - acc: 0.9036 -- iter: 0832/1608
[A[ATraining Step: 384  | total loss: [1m[32m0.26173[0m[0m | time: 202.203s
[2K
| Adam | epoch: 008 | loss: 0.26173 - acc: 0.9070 -- iter: 0864/1608
[A[ATraining Step: 385  | total loss: [1m[32m0.26618[0m[0m | time: 210.114s
[2K
| Adam | epoch: 008 | loss: 0.26618 - acc: 0.9038 -- iter: 0896/1608
[A[ATraining Step: 386  | total loss: [1m[32m0.26547[0m[0m | time: 217.988s
[2K
| Adam | epoch: 008 | loss: 0.26547 - acc: 0.8978 -- iter: 0928/1608
[A[ATraining Step: 387  | total loss: [1m[32m0.26806[0m[0m | time: 225.897s
[2K
| Adam | epoch: 008 | loss: 0.26806 - acc: 0.8955 -- iter: 0960/1608
[A[ATraining Step: 388  | total loss: [1m[32m0.26159[0m[0m | time: 233.677s
[2K
| Adam | epoch: 008 | loss: 0.26159 - acc: 0.8934 -- iter: 0992/1608
[A[ATraining Step: 389  | total loss: [1m[32m0.26888[0m[0m | time: 241.294s
[2K
| Adam | epoch: 008 | loss: 0.26888 - acc: 0.8853 -- iter: 1024/1608
[A[ATraining Step: 390  | total loss: [1m[32m0.25780[0m[0m | time: 249.445s
[2K
| Adam | epoch: 008 | loss: 0.25780 - acc: 0.8874 -- iter: 1056/1608
[A[ATraining Step: 391  | total loss: [1m[32m0.25254[0m[0m | time: 257.364s
[2K
| Adam | epoch: 008 | loss: 0.25254 - acc: 0.8893 -- iter: 1088/1608
[A[ATraining Step: 392  | total loss: [1m[32m0.24556[0m[0m | time: 265.401s
[2K
| Adam | epoch: 008 | loss: 0.24556 - acc: 0.8910 -- iter: 1120/1608
[A[ATraining Step: 393  | total loss: [1m[32m0.24991[0m[0m | time: 273.349s
[2K
| Adam | epoch: 008 | loss: 0.24991 - acc: 0.8925 -- iter: 1152/1608
[A[ATraining Step: 394  | total loss: [1m[32m0.23873[0m[0m | time: 281.043s
[2K
| Adam | epoch: 008 | loss: 0.23873 - acc: 0.8970 -- iter: 1184/1608
[A[ATraining Step: 395  | total loss: [1m[32m0.23295[0m[0m | time: 289.000s
[2K
| Adam | epoch: 008 | loss: 0.23295 - acc: 0.9042 -- iter: 1216/1608
[A[ATraining Step: 396  | total loss: [1m[32m0.24017[0m[0m | time: 296.670s
[2K
| Adam | epoch: 008 | loss: 0.24017 - acc: 0.9044 -- iter: 1248/1608
[A[ATraining Step: 397  | total loss: [1m[32m0.23798[0m[0m | time: 304.597s
[2K
| Adam | epoch: 008 | loss: 0.23798 - acc: 0.9046 -- iter: 1280/1608
[A[ATraining Step: 398  | total loss: [1m[32m0.23185[0m[0m | time: 312.315s
[2K
| Adam | epoch: 008 | loss: 0.23185 - acc: 0.9079 -- iter: 1312/1608
[A[ATraining Step: 399  | total loss: [1m[32m0.22261[0m[0m | time: 320.188s
[2K
| Adam | epoch: 008 | loss: 0.22261 - acc: 0.9140 -- iter: 1344/1608
[A[ATraining Step: 400  | total loss: [1m[32m0.21730[0m[0m | time: 350.229s
[2K
| Adam | epoch: 008 | loss: 0.21730 - acc: 0.9132 | val_loss: 0.92170 - val_acc: 0.6938 -- iter: 1376/1608
--
Training Step: 401  | total loss: [1m[32m0.21087[0m[0m | time: 358.139s
[2K
| Adam | epoch: 008 | loss: 0.21087 - acc: 0.9156 -- iter: 1408/1608
[A[ATraining Step: 402  | total loss: [1m[32m0.21195[0m[0m | time: 365.914s
[2K
| Adam | epoch: 008 | loss: 0.21195 - acc: 0.9178 -- iter: 1440/1608
[A[ATraining Step: 403  | total loss: [1m[32m0.22755[0m[0m | time: 373.594s
[2K
| Adam | epoch: 008 | loss: 0.22755 - acc: 0.9073 -- iter: 1472/1608
[A[ATraining Step: 404  | total loss: [1m[32m0.23202[0m[0m | time: 381.546s
[2K
| Adam | epoch: 008 | loss: 0.23202 - acc: 0.9072 -- iter: 1504/1608
[A[ATraining Step: 405  | total loss: [1m[32m0.22266[0m[0m | time: 389.480s
[2K
| Adam | epoch: 008 | loss: 0.22266 - acc: 0.9133 -- iter: 1536/1608
[A[ATraining Step: 406  | total loss: [1m[32m0.22313[0m[0m | time: 397.191s
[2K
| Adam | epoch: 008 | loss: 0.22313 - acc: 0.9158 -- iter: 1568/1608
[A[ATraining Step: 407  | total loss: [1m[32m0.22210[0m[0m | time: 405.197s
[2K
| Adam | epoch: 008 | loss: 0.22210 - acc: 0.9179 -- iter: 1600/1608
[A[ATraining Step: 408  | total loss: [1m[32m0.23864[0m[0m | time: 435.395s
[2K
| Adam | epoch: 008 | loss: 0.23864 - acc: 0.9136 | val_loss: 4.06116 - val_acc: 0.5408 -- iter: 1608/1608
--
Training Step: 409  | total loss: [1m[32m0.23017[0m[0m | time: 7.698s
[2K
| Adam | epoch: 009 | loss: 0.23017 - acc: 0.9160 -- iter: 0032/1608
[A[ATraining Step: 410  | total loss: [1m[32m0.22906[0m[0m | time: 15.591s
[2K
| Adam | epoch: 009 | loss: 0.22906 - acc: 0.9150 -- iter: 0064/1608
[A[ATraining Step: 411  | total loss: [1m[32m0.24714[0m[0m | time: 23.325s
[2K
| Adam | epoch: 009 | loss: 0.24714 - acc: 0.9048 -- iter: 0096/1608
[A[ATraining Step: 412  | total loss: [1m[32m0.24494[0m[0m | time: 31.367s
[2K
| Adam | epoch: 009 | loss: 0.24494 - acc: 0.9081 -- iter: 0128/1608
[A[ATraining Step: 413  | total loss: [1m[32m0.23548[0m[0m | time: 39.194s
[2K
| Adam | epoch: 009 | loss: 0.23548 - acc: 0.9110 -- iter: 0160/1608
[A[ATraining Step: 414  | total loss: [1m[32m0.22527[0m[0m | time: 47.085s
[2K
| Adam | epoch: 009 | loss: 0.22527 - acc: 0.9137 -- iter: 0192/1608
[A[ATraining Step: 415  | total loss: [1m[32m0.21823[0m[0m | time: 49.859s
[2K
| Adam | epoch: 009 | loss: 0.21823 - acc: 0.9129 -- iter: 0224/1608
[A[ATraining Step: 416  | total loss: [1m[32m0.20188[0m[0m | time: 52.571s
[2K
| Adam | epoch: 009 | loss: 0.20188 - acc: 0.9216 -- iter: 0256/1608
[A[ATraining Step: 417  | total loss: [1m[32m0.18437[0m[0m | time: 60.475s
[2K
| Adam | epoch: 009 | loss: 0.18437 - acc: 0.9295 -- iter: 0288/1608
[A[ATraining Step: 418  | total loss: [1m[32m0.20534[0m[0m | time: 68.311s
[2K
| Adam | epoch: 009 | loss: 0.20534 - acc: 0.9178 -- iter: 0320/1608
[A[ATraining Step: 419  | total loss: [1m[32m0.22673[0m[0m | time: 76.066s
[2K
| Adam | epoch: 009 | loss: 0.22673 - acc: 0.9041 -- iter: 0352/1608
[A[ATraining Step: 420  | total loss: [1m[32m0.23341[0m[0m | time: 83.916s
[2K
| Adam | epoch: 009 | loss: 0.23341 - acc: 0.8950 -- iter: 0384/1608
[A[ATraining Step: 421  | total loss: [1m[32m0.21737[0m[0m | time: 91.902s
[2K
| Adam | epoch: 009 | loss: 0.21737 - acc: 0.9023 -- iter: 0416/1608
[A[ATraining Step: 422  | total loss: [1m[32m0.21238[0m[0m | time: 99.916s
[2K
| Adam | epoch: 009 | loss: 0.21238 - acc: 0.9090 -- iter: 0448/1608
[A[ATraining Step: 423  | total loss: [1m[32m0.21845[0m[0m | time: 107.900s
[2K
| Adam | epoch: 009 | loss: 0.21845 - acc: 0.9025 -- iter: 0480/1608
[A[ATraining Step: 424  | total loss: [1m[32m0.21129[0m[0m | time: 115.934s
[2K
| Adam | epoch: 009 | loss: 0.21129 - acc: 0.9060 -- iter: 0512/1608
[A[ATraining Step: 425  | total loss: [1m[32m0.21103[0m[0m | time: 123.766s
[2K
| Adam | epoch: 009 | loss: 0.21103 - acc: 0.9060 -- iter: 0544/1608
[A[ATraining Step: 426  | total loss: [1m[32m0.20232[0m[0m | time: 131.710s
[2K
| Adam | epoch: 009 | loss: 0.20232 - acc: 0.9091 -- iter: 0576/1608
[A[ATraining Step: 427  | total loss: [1m[32m0.20780[0m[0m | time: 139.713s
[2K
| Adam | epoch: 009 | loss: 0.20780 - acc: 0.9120 -- iter: 0608/1608
[A[ATraining Step: 428  | total loss: [1m[32m0.23548[0m[0m | time: 147.698s
[2K
| Adam | epoch: 009 | loss: 0.23548 - acc: 0.9114 -- iter: 0640/1608
[A[ATraining Step: 429  | total loss: [1m[32m0.22793[0m[0m | time: 155.710s
[2K
| Adam | epoch: 009 | loss: 0.22793 - acc: 0.9109 -- iter: 0672/1608
[A[ATraining Step: 430  | total loss: [1m[32m0.23983[0m[0m | time: 163.608s
[2K
| Adam | epoch: 009 | loss: 0.23983 - acc: 0.9042 -- iter: 0704/1608
[A[ATraining Step: 431  | total loss: [1m[32m0.23396[0m[0m | time: 171.480s
[2K
| Adam | epoch: 009 | loss: 0.23396 - acc: 0.9013 -- iter: 0736/1608
[A[ATraining Step: 432  | total loss: [1m[32m0.22733[0m[0m | time: 179.273s
[2K
| Adam | epoch: 009 | loss: 0.22733 - acc: 0.9049 -- iter: 0768/1608
[A[ATraining Step: 433  | total loss: [1m[32m0.22801[0m[0m | time: 187.128s
[2K
| Adam | epoch: 009 | loss: 0.22801 - acc: 0.9081 -- iter: 0800/1608
[A[ATraining Step: 434  | total loss: [1m[32m0.23115[0m[0m | time: 194.890s
[2K
| Adam | epoch: 009 | loss: 0.23115 - acc: 0.9080 -- iter: 0832/1608
[A[ATraining Step: 435  | total loss: [1m[32m0.23121[0m[0m | time: 202.799s
[2K
| Adam | epoch: 009 | loss: 0.23121 - acc: 0.9078 -- iter: 0864/1608
[A[ATraining Step: 436  | total loss: [1m[32m0.23389[0m[0m | time: 210.592s
[2K
| Adam | epoch: 009 | loss: 0.23389 - acc: 0.9076 -- iter: 0896/1608
[A[ATraining Step: 437  | total loss: [1m[32m0.23872[0m[0m | time: 218.523s
[2K
| Adam | epoch: 009 | loss: 0.23872 - acc: 0.9012 -- iter: 0928/1608
[A[ATraining Step: 438  | total loss: [1m[32m0.23630[0m[0m | time: 226.294s
[2K
| Adam | epoch: 009 | loss: 0.23630 - acc: 0.9049 -- iter: 0960/1608
[A[ATraining Step: 439  | total loss: [1m[32m0.22416[0m[0m | time: 234.045s
[2K
| Adam | epoch: 009 | loss: 0.22416 - acc: 0.9113 -- iter: 0992/1608
[A[ATraining Step: 440  | total loss: [1m[32m0.21210[0m[0m | time: 241.873s
[2K
| Adam | epoch: 009 | loss: 0.21210 - acc: 0.9170 -- iter: 1024/1608
[A[ATraining Step: 441  | total loss: [1m[32m0.21811[0m[0m | time: 249.664s
[2K
| Adam | epoch: 009 | loss: 0.21811 - acc: 0.9191 -- iter: 1056/1608
[A[ATraining Step: 442  | total loss: [1m[32m0.22102[0m[0m | time: 257.450s
[2K
| Adam | epoch: 009 | loss: 0.22102 - acc: 0.9115 -- iter: 1088/1608
[A[ATraining Step: 443  | total loss: [1m[32m0.20672[0m[0m | time: 265.123s
[2K
| Adam | epoch: 009 | loss: 0.20672 - acc: 0.9204 -- iter: 1120/1608
[A[ATraining Step: 444  | total loss: [1m[32m0.21298[0m[0m | time: 272.800s
[2K
| Adam | epoch: 009 | loss: 0.21298 - acc: 0.9127 -- iter: 1152/1608
[A[ATraining Step: 445  | total loss: [1m[32m0.22352[0m[0m | time: 280.702s
[2K
| Adam | epoch: 009 | loss: 0.22352 - acc: 0.9089 -- iter: 1184/1608
[A[ATraining Step: 446  | total loss: [1m[32m0.21296[0m[0m | time: 288.645s
[2K
| Adam | epoch: 009 | loss: 0.21296 - acc: 0.9149 -- iter: 1216/1608
[A[ATraining Step: 447  | total loss: [1m[32m0.20415[0m[0m | time: 296.399s
[2K
| Adam | epoch: 009 | loss: 0.20415 - acc: 0.9172 -- iter: 1248/1608
[A[ATraining Step: 448  | total loss: [1m[32m0.20947[0m[0m | time: 304.615s
[2K
| Adam | epoch: 009 | loss: 0.20947 - acc: 0.9130 -- iter: 1280/1608
[A[ATraining Step: 449  | total loss: [1m[32m0.19981[0m[0m | time: 312.432s
[2K
| Adam | epoch: 009 | loss: 0.19981 - acc: 0.9185 -- iter: 1312/1608
[A[ATraining Step: 450  | total loss: [1m[32m0.19282[0m[0m | time: 320.335s
[2K
| Adam | epoch: 009 | loss: 0.19282 - acc: 0.9236 -- iter: 1344/1608
[A[ATraining Step: 451  | total loss: [1m[32m0.19577[0m[0m | time: 328.156s
[2K
| Adam | epoch: 009 | loss: 0.19577 - acc: 0.9218 -- iter: 1376/1608
[A[ATraining Step: 452  | total loss: [1m[32m0.19029[0m[0m | time: 336.018s
[2K
| Adam | epoch: 009 | loss: 0.19029 - acc: 0.9234 -- iter: 1408/1608
[A[ATraining Step: 453  | total loss: [1m[32m0.18485[0m[0m | time: 343.820s
[2K
| Adam | epoch: 009 | loss: 0.18485 - acc: 0.9248 -- iter: 1440/1608
[A[ATraining Step: 454  | total loss: [1m[32m0.18098[0m[0m | time: 351.634s
[2K
| Adam | epoch: 009 | loss: 0.18098 - acc: 0.9292 -- iter: 1472/1608
[A[ATraining Step: 455  | total loss: [1m[32m0.17921[0m[0m | time: 359.348s
[2K
| Adam | epoch: 009 | loss: 0.17921 - acc: 0.9300 -- iter: 1504/1608
[A[ATraining Step: 456  | total loss: [1m[32m0.18208[0m[0m | time: 367.378s
[2K
| Adam | epoch: 009 | loss: 0.18208 - acc: 0.9245 -- iter: 1536/1608
[A[ATraining Step: 457  | total loss: [1m[32m0.19486[0m[0m | time: 375.127s
[2K
| Adam | epoch: 009 | loss: 0.19486 - acc: 0.9133 -- iter: 1568/1608
[A[ATraining Step: 458  | total loss: [1m[32m0.19704[0m[0m | time: 382.872s
[2K
| Adam | epoch: 009 | loss: 0.19704 - acc: 0.9157 -- iter: 1600/1608
[A[ATraining Step: 459  | total loss: [1m[32m0.18086[0m[0m | time: 412.705s
[2K
| Adam | epoch: 009 | loss: 0.18086 - acc: 0.9242 | val_loss: 1.34075 - val_acc: 0.6481 -- iter: 1608/1608
--
Training Step: 460  | total loss: [1m[32m0.16677[0m[0m | time: 7.892s
[2K
| Adam | epoch: 010 | loss: 0.16677 - acc: 0.9318 -- iter: 0032/1608
[A[ATraining Step: 461  | total loss: [1m[32m0.16162[0m[0m | time: 15.707s
[2K
| Adam | epoch: 010 | loss: 0.16162 - acc: 0.9292 -- iter: 0064/1608
[A[ATraining Step: 462  | total loss: [1m[32m0.15383[0m[0m | time: 23.601s
[2K
| Adam | epoch: 010 | loss: 0.15383 - acc: 0.9363 -- iter: 0096/1608
[A[ATraining Step: 463  | total loss: [1m[32m0.15200[0m[0m | time: 31.470s
[2K
| Adam | epoch: 010 | loss: 0.15200 - acc: 0.9395 -- iter: 0128/1608
[A[ATraining Step: 464  | total loss: [1m[32m0.14498[0m[0m | time: 39.346s
[2K
| Adam | epoch: 010 | loss: 0.14498 - acc: 0.9425 -- iter: 0160/1608
[A[ATraining Step: 465  | total loss: [1m[32m0.13968[0m[0m | time: 47.241s
[2K
| Adam | epoch: 010 | loss: 0.13968 - acc: 0.9420 -- iter: 0192/1608
[A[ATraining Step: 466  | total loss: [1m[32m0.15797[0m[0m | time: 55.143s
[2K
| Adam | epoch: 010 | loss: 0.15797 - acc: 0.9384 -- iter: 0224/1608
[A[ATraining Step: 467  | total loss: [1m[32m0.15681[0m[0m | time: 57.929s
[2K
| Adam | epoch: 010 | loss: 0.15681 - acc: 0.9414 -- iter: 0256/1608
[A[ATraining Step: 468  | total loss: [1m[32m0.30435[0m[0m | time: 60.667s
[2K
| Adam | epoch: 010 | loss: 0.30435 - acc: 0.9223 -- iter: 0288/1608
[A[ATraining Step: 469  | total loss: [1m[32m0.31163[0m[0m | time: 68.647s
[2K
| Adam | epoch: 010 | loss: 0.31163 - acc: 0.9051 -- iter: 0320/1608
[A[ATraining Step: 470  | total loss: [1m[32m0.30511[0m[0m | time: 76.612s
[2K
| Adam | epoch: 010 | loss: 0.30511 - acc: 0.9083 -- iter: 0352/1608
[A[ATraining Step: 471  | total loss: [1m[32m0.31494[0m[0m | time: 84.472s
[2K
| Adam | epoch: 010 | loss: 0.31494 - acc: 0.9050 -- iter: 0384/1608
[A[ATraining Step: 472  | total loss: [1m[32m0.32570[0m[0m | time: 92.401s
[2K
| Adam | epoch: 010 | loss: 0.32570 - acc: 0.8988 -- iter: 0416/1608
[A[ATraining Step: 473  | total loss: [1m[32m0.32615[0m[0m | time: 100.365s
[2K
| Adam | epoch: 010 | loss: 0.32615 - acc: 0.8902 -- iter: 0448/1608
[A[ATraining Step: 474  | total loss: [1m[32m0.33105[0m[0m | time: 108.267s
[2K
| Adam | epoch: 010 | loss: 0.33105 - acc: 0.8856 -- iter: 0480/1608
[A[ATraining Step: 475  | total loss: [1m[32m0.32118[0m[0m | time: 116.291s
[2K
| Adam | epoch: 010 | loss: 0.32118 - acc: 0.8908 -- iter: 0512/1608
[A[ATraining Step: 476  | total loss: [1m[32m0.30102[0m[0m | time: 124.201s
[2K
| Adam | epoch: 010 | loss: 0.30102 - acc: 0.8954 -- iter: 0544/1608
[A[ATraining Step: 477  | total loss: [1m[32m0.29014[0m[0m | time: 132.066s
[2K
| Adam | epoch: 010 | loss: 0.29014 - acc: 0.8996 -- iter: 0576/1608
[A[ATraining Step: 478  | total loss: [1m[32m0.27310[0m[0m | time: 139.924s
[2K
| Adam | epoch: 010 | loss: 0.27310 - acc: 0.9034 -- iter: 0608/1608
[A[ATraining Step: 479  | total loss: [1m[32m0.27648[0m[0m | time: 147.795s
[2K
| Adam | epoch: 010 | loss: 0.27648 - acc: 0.8975 -- iter: 0640/1608
[A[ATraining Step: 480  | total loss: [1m[32m0.26797[0m[0m | time: 155.769s
[2K
| Adam | epoch: 010 | loss: 0.26797 - acc: 0.8921 -- iter: 0672/1608
[A[ATraining Step: 481  | total loss: [1m[32m0.25447[0m[0m | time: 163.461s
[2K
| Adam | epoch: 010 | loss: 0.25447 - acc: 0.8966 -- iter: 0704/1608
[A[ATraining Step: 482  | total loss: [1m[32m0.24538[0m[0m | time: 171.433s
[2K
| Adam | epoch: 010 | loss: 0.24538 - acc: 0.9007 -- iter: 0736/1608
[A[ATraining Step: 483  | total loss: [1m[32m0.23672[0m[0m | time: 179.306s
[2K
| Adam | epoch: 010 | loss: 0.23672 - acc: 0.9013 -- iter: 0768/1608
[A[ATraining Step: 484  | total loss: [1m[32m0.25496[0m[0m | time: 187.351s
[2K
| Adam | epoch: 010 | loss: 0.25496 - acc: 0.8893 -- iter: 0800/1608
[A[ATraining Step: 485  | total loss: [1m[32m0.24786[0m[0m | time: 195.247s
[2K
| Adam | epoch: 010 | loss: 0.24786 - acc: 0.8910 -- iter: 0832/1608
[A[ATraining Step: 486  | total loss: [1m[32m0.23922[0m[0m | time: 203.235s
[2K
| Adam | epoch: 010 | loss: 0.23922 - acc: 0.8956 -- iter: 0864/1608
[A[ATraining Step: 487  | total loss: [1m[32m0.23655[0m[0m | time: 211.108s
[2K
| Adam | epoch: 010 | loss: 0.23655 - acc: 0.8998 -- iter: 0896/1608
[A[ATraining Step: 488  | total loss: [1m[32m0.23362[0m[0m | time: 219.010s
[2K
| Adam | epoch: 010 | loss: 0.23362 - acc: 0.8973 -- iter: 0928/1608
[A[ATraining Step: 489  | total loss: [1m[32m0.22633[0m[0m | time: 226.963s
[2K
| Adam | epoch: 010 | loss: 0.22633 - acc: 0.8982 -- iter: 0960/1608
[A[ATraining Step: 490  | total loss: [1m[32m0.22403[0m[0m | time: 234.923s
[2K
| Adam | epoch: 010 | loss: 0.22403 - acc: 0.9021 -- iter: 0992/1608
[A[ATraining Step: 491  | total loss: [1m[32m0.23294[0m[0m | time: 242.794s
[2K
| Adam | epoch: 010 | loss: 0.23294 - acc: 0.8963 -- iter: 1024/1608
[A[ATraining Step: 492  | total loss: [1m[32m0.22858[0m[0m | time: 250.670s
[2K
| Adam | epoch: 010 | loss: 0.22858 - acc: 0.9004 -- iter: 1056/1608
[A[ATraining Step: 493  | total loss: [1m[32m0.22243[0m[0m | time: 258.695s
[2K
| Adam | epoch: 010 | loss: 0.22243 - acc: 0.9010 -- iter: 1088/1608
[A[ATraining Step: 494  | total loss: [1m[32m0.23070[0m[0m | time: 266.427s
[2K
| Adam | epoch: 010 | loss: 0.23070 - acc: 0.8984 -- iter: 1120/1608
[A[ATraining Step: 495  | total loss: [1m[32m0.21844[0m[0m | time: 274.403s
[2K
| Adam | epoch: 010 | loss: 0.21844 - acc: 0.9054 -- iter: 1152/1608
[A[ATraining Step: 496  | total loss: [1m[32m0.20687[0m[0m | time: 282.170s
[2K
| Adam | epoch: 010 | loss: 0.20687 - acc: 0.9149 -- iter: 1184/1608
[A[ATraining Step: 497  | total loss: [1m[32m0.20200[0m[0m | time: 289.899s
[2K
| Adam | epoch: 010 | loss: 0.20200 - acc: 0.9203 -- iter: 1216/1608
[A[ATraining Step: 498  | total loss: [1m[32m0.19419[0m[0m | time: 297.854s
[2K
| Adam | epoch: 010 | loss: 0.19419 - acc: 0.9251 -- iter: 1248/1608
[A[ATraining Step: 499  | total loss: [1m[32m0.18028[0m[0m | time: 305.783s
[2K
| Adam | epoch: 010 | loss: 0.18028 - acc: 0.9326 -- iter: 1280/1608
[A[ATraining Step: 500  | total loss: [1m[32m0.17857[0m[0m | time: 313.720s
[2K
| Adam | epoch: 010 | loss: 0.17857 - acc: 0.9331 -- iter: 1312/1608
[A[ATraining Step: 501  | total loss: [1m[32m0.18051[0m[0m | time: 321.496s
[2K
| Adam | epoch: 010 | loss: 0.18051 - acc: 0.9304 -- iter: 1344/1608
[A[ATraining Step: 502  | total loss: [1m[32m0.17362[0m[0m | time: 329.567s
[2K
| Adam | epoch: 010 | loss: 0.17362 - acc: 0.9343 -- iter: 1376/1608
[A[ATraining Step: 503  | total loss: [1m[32m0.18193[0m[0m | time: 337.321s
[2K
| Adam | epoch: 010 | loss: 0.18193 - acc: 0.9221 -- iter: 1408/1608
[A[ATraining Step: 504  | total loss: [1m[32m0.17875[0m[0m | time: 345.263s
[2K
| Adam | epoch: 010 | loss: 0.17875 - acc: 0.9267 -- iter: 1440/1608
[A[ATraining Step: 505  | total loss: [1m[32m0.17559[0m[0m | time: 353.036s
[2K
| Adam | epoch: 010 | loss: 0.17559 - acc: 0.9309 -- iter: 1472/1608
[A[ATraining Step: 506  | total loss: [1m[32m0.17481[0m[0m | time: 360.975s
[2K
| Adam | epoch: 010 | loss: 0.17481 - acc: 0.9285 -- iter: 1504/1608
[A[ATraining Step: 507  | total loss: [1m[32m0.18259[0m[0m | time: 369.026s
[2K
| Adam | epoch: 010 | loss: 0.18259 - acc: 0.9263 -- iter: 1536/1608
[A[ATraining Step: 508  | total loss: [1m[32m0.16918[0m[0m | time: 377.071s
[2K
| Adam | epoch: 010 | loss: 0.16918 - acc: 0.9336 -- iter: 1568/1608
[A[ATraining Step: 509  | total loss: [1m[32m0.16049[0m[0m | time: 385.038s
[2K
| Adam | epoch: 010 | loss: 0.16049 - acc: 0.9403 -- iter: 1600/1608
[A[ATraining Step: 510  | total loss: [1m[32m0.15470[0m[0m | time: 415.522s
[2K
| Adam | epoch: 010 | loss: 0.15470 - acc: 0.9400 | val_loss: 1.60276 - val_acc: 0.6123 -- iter: 1608/1608
--
Training Step: 511  | total loss: [1m[32m0.14386[0m[0m | time: 7.976s
[2K
| Adam | epoch: 011 | loss: 0.14386 - acc: 0.9429 -- iter: 0032/1608
[A[ATraining Step: 512  | total loss: [1m[32m0.13425[0m[0m | time: 16.053s
[2K
| Adam | epoch: 011 | loss: 0.13425 - acc: 0.9486 -- iter: 0064/1608
[A[ATraining Step: 513  | total loss: [1m[32m0.12947[0m[0m | time: 23.932s
[2K
| Adam | epoch: 011 | loss: 0.12947 - acc: 0.9506 -- iter: 0096/1608
[A[ATraining Step: 514  | total loss: [1m[32m0.13255[0m[0m | time: 31.668s
[2K
| Adam | epoch: 011 | loss: 0.13255 - acc: 0.9493 -- iter: 0128/1608
[A[ATraining Step: 515  | total loss: [1m[32m0.13396[0m[0m | time: 39.467s
[2K
| Adam | epoch: 011 | loss: 0.13396 - acc: 0.9481 -- iter: 0160/1608
[A[ATraining Step: 516  | total loss: [1m[32m0.15494[0m[0m | time: 47.464s
[2K
| Adam | epoch: 011 | loss: 0.15494 - acc: 0.9408 -- iter: 0192/1608
[A[ATraining Step: 517  | total loss: [1m[32m0.14529[0m[0m | time: 55.250s
[2K
| Adam | epoch: 011 | loss: 0.14529 - acc: 0.9467 -- iter: 0224/1608
[A[ATraining Step: 518  | total loss: [1m[32m0.14318[0m[0m | time: 63.191s
[2K
| Adam | epoch: 011 | loss: 0.14318 - acc: 0.9458 -- iter: 0256/1608
[A[ATraining Step: 519  | total loss: [1m[32m0.14048[0m[0m | time: 65.920s
[2K
| Adam | epoch: 011 | loss: 0.14048 - acc: 0.9450 -- iter: 0288/1608
[A[ATraining Step: 520  | total loss: [1m[32m0.13107[0m[0m | time: 68.604s
[2K
| Adam | epoch: 011 | loss: 0.13107 - acc: 0.9505 -- iter: 0320/1608
[A[ATraining Step: 521  | total loss: [1m[32m0.11891[0m[0m | time: 76.382s
[2K
| Adam | epoch: 011 | loss: 0.11891 - acc: 0.9554 -- iter: 0352/1608
[A[ATraining Step: 522  | total loss: [1m[32m0.13284[0m[0m | time: 84.147s
[2K
| Adam | epoch: 011 | loss: 0.13284 - acc: 0.9536 -- iter: 0384/1608
[A[ATraining Step: 523  | total loss: [1m[32m0.12602[0m[0m | time: 92.021s
[2K
| Adam | epoch: 011 | loss: 0.12602 - acc: 0.9551 -- iter: 0416/1608
[A[ATraining Step: 524  | total loss: [1m[32m0.11819[0m[0m | time: 99.903s
[2K
| Adam | epoch: 011 | loss: 0.11819 - acc: 0.9596 -- iter: 0448/1608
[A[ATraining Step: 525  | total loss: [1m[32m0.11793[0m[0m | time: 107.850s
[2K
| Adam | epoch: 011 | loss: 0.11793 - acc: 0.9574 -- iter: 0480/1608
[A[ATraining Step: 526  | total loss: [1m[32m0.16771[0m[0m | time: 115.677s
[2K
| Adam | epoch: 011 | loss: 0.16771 - acc: 0.9429 -- iter: 0512/1608
[A[ATraining Step: 527  | total loss: [1m[32m0.17122[0m[0m | time: 123.488s
[2K
| Adam | epoch: 011 | loss: 0.17122 - acc: 0.9393 -- iter: 0544/1608
[A[ATraining Step: 528  | total loss: [1m[32m0.17597[0m[0m | time: 131.397s
[2K
| Adam | epoch: 011 | loss: 0.17597 - acc: 0.9360 -- iter: 0576/1608
[A[ATraining Step: 529  | total loss: [1m[32m0.19643[0m[0m | time: 139.185s
[2K
| Adam | epoch: 011 | loss: 0.19643 - acc: 0.9299 -- iter: 0608/1608
[A[ATraining Step: 530  | total loss: [1m[32m0.19331[0m[0m | time: 146.934s
[2K
| Adam | epoch: 011 | loss: 0.19331 - acc: 0.9337 -- iter: 0640/1608
[A[ATraining Step: 531  | total loss: [1m[32m0.18939[0m[0m | time: 154.801s
[2K
| Adam | epoch: 011 | loss: 0.18939 - acc: 0.9341 -- iter: 0672/1608
[A[ATraining Step: 532  | total loss: [1m[32m0.18612[0m[0m | time: 162.712s
[2K
| Adam | epoch: 011 | loss: 0.18612 - acc: 0.9345 -- iter: 0704/1608
[A[ATraining Step: 533  | total loss: [1m[32m0.19420[0m[0m | time: 170.632s
[2K
| Adam | epoch: 011 | loss: 0.19420 - acc: 0.9316 -- iter: 0736/1608
[A[ATraining Step: 534  | total loss: [1m[32m0.18363[0m[0m | time: 178.473s
[2K
| Adam | epoch: 011 | loss: 0.18363 - acc: 0.9385 -- iter: 0768/1608
[A[ATraining Step: 535  | total loss: [1m[32m0.20042[0m[0m | time: 186.571s
[2K
| Adam | epoch: 011 | loss: 0.20042 - acc: 0.9259 -- iter: 0800/1608
[A[ATraining Step: 536  | total loss: [1m[32m0.21284[0m[0m | time: 194.486s
[2K
| Adam | epoch: 011 | loss: 0.21284 - acc: 0.9177 -- iter: 0832/1608
[A[ATraining Step: 537  | total loss: [1m[32m0.21381[0m[0m | time: 202.376s
[2K
| Adam | epoch: 011 | loss: 0.21381 - acc: 0.9196 -- iter: 0864/1608
[A[ATraining Step: 538  | total loss: [1m[32m0.21069[0m[0m | time: 210.129s
[2K
| Adam | epoch: 011 | loss: 0.21069 - acc: 0.9152 -- iter: 0896/1608
[A[ATraining Step: 539  | total loss: [1m[32m0.19267[0m[0m | time: 218.032s
[2K
| Adam | epoch: 011 | loss: 0.19267 - acc: 0.9237 -- iter: 0928/1608
[A[ATraining Step: 540  | total loss: [1m[32m0.19980[0m[0m | time: 225.745s
[2K
| Adam | epoch: 011 | loss: 0.19980 - acc: 0.9219 -- iter: 0960/1608
[A[ATraining Step: 541  | total loss: [1m[32m0.21143[0m[0m | time: 233.504s
[2K
| Adam | epoch: 011 | loss: 0.21143 - acc: 0.9141 -- iter: 0992/1608
[A[ATraining Step: 542  | total loss: [1m[32m0.19810[0m[0m | time: 241.452s
[2K
| Adam | epoch: 011 | loss: 0.19810 - acc: 0.9227 -- iter: 1024/1608
[A[ATraining Step: 543  | total loss: [1m[32m0.18712[0m[0m | time: 249.261s
[2K
| Adam | epoch: 011 | loss: 0.18712 - acc: 0.9304 -- iter: 1056/1608
[A[ATraining Step: 544  | total loss: [1m[32m0.18723[0m[0m | time: 257.286s
[2K
| Adam | epoch: 011 | loss: 0.18723 - acc: 0.9249 -- iter: 1088/1608
[A[ATraining Step: 545  | total loss: [1m[32m0.18658[0m[0m | time: 265.300s
[2K
| Adam | epoch: 011 | loss: 0.18658 - acc: 0.9293 -- iter: 1120/1608
[A[ATraining Step: 546  | total loss: [1m[32m0.19071[0m[0m | time: 273.142s
[2K
| Adam | epoch: 011 | loss: 0.19071 - acc: 0.9270 -- iter: 1152/1608
[A[ATraining Step: 547  | total loss: [1m[32m0.18112[0m[0m | time: 280.917s
[2K
| Adam | epoch: 011 | loss: 0.18112 - acc: 0.9311 -- iter: 1184/1608
[A[ATraining Step: 548  | total loss: [1m[32m0.17567[0m[0m | time: 288.779s
[2K
| Adam | epoch: 011 | loss: 0.17567 - acc: 0.9349 -- iter: 1216/1608
[A[ATraining Step: 549  | total loss: [1m[32m0.17088[0m[0m | time: 296.565s
[2K
| Adam | epoch: 011 | loss: 0.17088 - acc: 0.9414 -- iter: 1248/1608
[A[ATraining Step: 550  | total loss: [1m[32m0.16626[0m[0m | time: 304.535s
[2K
| Adam | epoch: 011 | loss: 0.16626 - acc: 0.9410 -- iter: 1280/1608
[A[ATraining Step: 551  | total loss: [1m[32m0.17042[0m[0m | time: 312.350s
[2K
| Adam | epoch: 011 | loss: 0.17042 - acc: 0.9344 -- iter: 1312/1608
[A[ATraining Step: 552  | total loss: [1m[32m0.19260[0m[0m | time: 320.235s
[2K
| Adam | epoch: 011 | loss: 0.19260 - acc: 0.9285 -- iter: 1344/1608
[A[ATraining Step: 553  | total loss: [1m[32m0.19428[0m[0m | time: 328.262s
[2K
| Adam | epoch: 011 | loss: 0.19428 - acc: 0.9294 -- iter: 1376/1608
[A[ATraining Step: 554  | total loss: [1m[32m0.18959[0m[0m | time: 336.183s
[2K
| Adam | epoch: 011 | loss: 0.18959 - acc: 0.9302 -- iter: 1408/1608
[A[ATraining Step: 555  | total loss: [1m[32m0.18992[0m[0m | time: 344.013s
[2K
| Adam | epoch: 011 | loss: 0.18992 - acc: 0.9309 -- iter: 1440/1608
[A[ATraining Step: 556  | total loss: [1m[32m0.19219[0m[0m | time: 351.913s
[2K
| Adam | epoch: 011 | loss: 0.19219 - acc: 0.9253 -- iter: 1472/1608
[A[ATraining Step: 557  | total loss: [1m[32m0.18718[0m[0m | time: 360.095s
[2K
| Adam | epoch: 011 | loss: 0.18718 - acc: 0.9234 -- iter: 1504/1608
[A[ATraining Step: 558  | total loss: [1m[32m0.18718[0m[0m | time: 368.068s
[2K
| Adam | epoch: 011 | loss: 0.18718 - acc: 0.9280 -- iter: 1536/1608
[A[ATraining Step: 559  | total loss: [1m[32m0.17911[0m[0m | time: 376.023s
[2K
| Adam | epoch: 011 | loss: 0.17911 - acc: 0.9289 -- iter: 1568/1608
[A[ATraining Step: 560  | total loss: [1m[32m0.16869[0m[0m | time: 383.965s
[2K
| Adam | epoch: 011 | loss: 0.16869 - acc: 0.9329 -- iter: 1600/1608
[A[ATraining Step: 561  | total loss: [1m[32m0.17833[0m[0m | time: 414.066s
[2K
| Adam | epoch: 011 | loss: 0.17833 - acc: 0.9302 | val_loss: 10.65521 - val_acc: 0.5209 -- iter: 1608/1608
--
Training Step: 562  | total loss: [1m[32m0.16718[0m[0m | time: 7.982s
[2K
| Adam | epoch: 012 | loss: 0.16718 - acc: 0.9372 -- iter: 0032/1608
[A[ATraining Step: 563  | total loss: [1m[32m0.18384[0m[0m | time: 15.813s
[2K
| Adam | epoch: 012 | loss: 0.18384 - acc: 0.9279 -- iter: 0064/1608
[A[ATraining Step: 564  | total loss: [1m[32m0.18040[0m[0m | time: 23.882s
[2K
| Adam | epoch: 012 | loss: 0.18040 - acc: 0.9257 -- iter: 0096/1608
[A[ATraining Step: 565  | total loss: [1m[32m0.16959[0m[0m | time: 31.818s
[2K
| Adam | epoch: 012 | loss: 0.16959 - acc: 0.9331 -- iter: 0128/1608
[A[ATraining Step: 566  | total loss: [1m[32m0.16287[0m[0m | time: 39.725s
[2K
| Adam | epoch: 012 | loss: 0.16287 - acc: 0.9367 -- iter: 0160/1608
[A[ATraining Step: 567  | total loss: [1m[32m0.16045[0m[0m | time: 47.596s
[2K
| Adam | epoch: 012 | loss: 0.16045 - acc: 0.9336 -- iter: 0192/1608
[A[ATraining Step: 568  | total loss: [1m[32m0.17290[0m[0m | time: 55.380s
[2K
| Adam | epoch: 012 | loss: 0.17290 - acc: 0.9340 -- iter: 0224/1608
[A[ATraining Step: 569  | total loss: [1m[32m0.16391[0m[0m | time: 63.325s
[2K
| Adam | epoch: 012 | loss: 0.16391 - acc: 0.9375 -- iter: 0256/1608
[A[ATraining Step: 570  | total loss: [1m[32m0.18621[0m[0m | time: 71.262s
[2K
| Adam | epoch: 012 | loss: 0.18621 - acc: 0.9344 -- iter: 0288/1608
[A[ATraining Step: 571  | total loss: [1m[32m0.21202[0m[0m | time: 73.928s
[2K
| Adam | epoch: 012 | loss: 0.21202 - acc: 0.9253 -- iter: 0320/1608
[A[ATraining Step: 572  | total loss: [1m[32m0.19777[0m[0m | time: 76.657s
[2K
| Adam | epoch: 012 | loss: 0.19777 - acc: 0.9328 -- iter: 0352/1608
[A[ATraining Step: 573  | total loss: [1m[32m0.18295[0m[0m | time: 84.521s
[2K
| Adam | epoch: 012 | loss: 0.18295 - acc: 0.9395 -- iter: 0384/1608
[A[ATraining Step: 574  | total loss: [1m[32m0.17878[0m[0m | time: 92.466s
[2K
| Adam | epoch: 012 | loss: 0.17878 - acc: 0.9393 -- iter: 0416/1608
[A[ATraining Step: 575  | total loss: [1m[32m0.17319[0m[0m | time: 100.350s
[2K
| Adam | epoch: 012 | loss: 0.17319 - acc: 0.9423 -- iter: 0448/1608
[A[ATraining Step: 576  | total loss: [1m[32m0.17974[0m[0m | time: 108.177s
[2K
| Adam | epoch: 012 | loss: 0.17974 - acc: 0.9355 -- iter: 0480/1608
[A[ATraining Step: 577  | total loss: [1m[32m0.19050[0m[0m | time: 115.969s
[2K
| Adam | epoch: 012 | loss: 0.19050 - acc: 0.9295 -- iter: 0512/1608
[A[ATraining Step: 578  | total loss: [1m[32m0.20798[0m[0m | time: 124.022s
[2K
| Adam | epoch: 012 | loss: 0.20798 - acc: 0.9272 -- iter: 0544/1608
[A[ATraining Step: 579  | total loss: [1m[32m0.19743[0m[0m | time: 131.892s
[2K
| Adam | epoch: 012 | loss: 0.19743 - acc: 0.9313 -- iter: 0576/1608
[A[ATraining Step: 580  | total loss: [1m[32m0.18401[0m[0m | time: 139.890s
[2K
| Adam | epoch: 012 | loss: 0.18401 - acc: 0.9382 -- iter: 0608/1608
[A[ATraining Step: 581  | total loss: [1m[32m0.18054[0m[0m | time: 147.622s
[2K
| Adam | epoch: 012 | loss: 0.18054 - acc: 0.9381 -- iter: 0640/1608
[A[ATraining Step: 582  | total loss: [1m[32m0.18863[0m[0m | time: 155.443s
[2K
| Adam | epoch: 012 | loss: 0.18863 - acc: 0.9318 -- iter: 0672/1608
[A[ATraining Step: 583  | total loss: [1m[32m0.18136[0m[0m | time: 163.375s
[2K
| Adam | epoch: 012 | loss: 0.18136 - acc: 0.9355 -- iter: 0704/1608
[A[ATraining Step: 584  | total loss: [1m[32m0.18514[0m[0m | time: 171.235s
[2K
| Adam | epoch: 012 | loss: 0.18514 - acc: 0.9357 -- iter: 0736/1608
[A[ATraining Step: 585  | total loss: [1m[32m0.17992[0m[0m | time: 179.138s
[2K
| Adam | epoch: 012 | loss: 0.17992 - acc: 0.9359 -- iter: 0768/1608
[A[ATraining Step: 586  | total loss: [1m[32m0.18899[0m[0m | time: 187.053s
[2K
| Adam | epoch: 012 | loss: 0.18899 - acc: 0.9298 -- iter: 0800/1608
[A[ATraining Step: 587  | total loss: [1m[32m0.17623[0m[0m | time: 195.046s
[2K
| Adam | epoch: 012 | loss: 0.17623 - acc: 0.9368 -- iter: 0832/1608
[A[ATraining Step: 588  | total loss: [1m[32m0.17042[0m[0m | time: 202.968s
[2K
| Adam | epoch: 012 | loss: 0.17042 - acc: 0.9400 -- iter: 0864/1608
[A[ATraining Step: 589  | total loss: [1m[32m0.17243[0m[0m | time: 210.598s
[2K
| Adam | epoch: 012 | loss: 0.17243 - acc: 0.9398 -- iter: 0896/1608
[A[ATraining Step: 590  | total loss: [1m[32m0.16944[0m[0m | time: 218.536s
[2K
| Adam | epoch: 012 | loss: 0.16944 - acc: 0.9333 -- iter: 0928/1608
[A[ATraining Step: 591  | total loss: [1m[32m0.17856[0m[0m | time: 226.317s
[2K
| Adam | epoch: 012 | loss: 0.17856 - acc: 0.9306 -- iter: 0960/1608
[A[ATraining Step: 592  | total loss: [1m[32m0.17216[0m[0m | time: 234.457s
[2K
| Adam | epoch: 012 | loss: 0.17216 - acc: 0.9313 -- iter: 0992/1608
[A[ATraining Step: 593  | total loss: [1m[32m0.16214[0m[0m | time: 242.262s
[2K
| Adam | epoch: 012 | loss: 0.16214 - acc: 0.9319 -- iter: 1024/1608
[A[ATraining Step: 594  | total loss: [1m[32m0.15026[0m[0m | time: 250.057s
[2K
| Adam | epoch: 012 | loss: 0.15026 - acc: 0.9387 -- iter: 1056/1608
[A[ATraining Step: 595  | total loss: [1m[32m0.14397[0m[0m | time: 257.836s
[2K
| Adam | epoch: 012 | loss: 0.14397 - acc: 0.9386 -- iter: 1088/1608
[A[ATraining Step: 596  | total loss: [1m[32m0.14232[0m[0m | time: 265.658s
[2K
| Adam | epoch: 012 | loss: 0.14232 - acc: 0.9385 -- iter: 1120/1608
[A[ATraining Step: 597  | total loss: [1m[32m0.13383[0m[0m | time: 273.504s
[2K
| Adam | epoch: 012 | loss: 0.13383 - acc: 0.9415 -- iter: 1152/1608
[A[ATraining Step: 598  | total loss: [1m[32m0.12906[0m[0m | time: 281.369s
[2K
| Adam | epoch: 012 | loss: 0.12906 - acc: 0.9411 -- iter: 1184/1608
[A[ATraining Step: 599  | total loss: [1m[32m0.11967[0m[0m | time: 289.188s
[2K
| Adam | epoch: 012 | loss: 0.11967 - acc: 0.9470 -- iter: 1216/1608
[A[ATraining Step: 600  | total loss: [1m[32m0.11685[0m[0m | time: 319.310s
[2K
| Adam | epoch: 012 | loss: 0.11685 - acc: 0.9492 | val_loss: 1.51871 - val_acc: 0.7117 -- iter: 1248/1608
--
Training Step: 601  | total loss: [1m[32m0.12185[0m[0m | time: 327.276s
[2K
| Adam | epoch: 012 | loss: 0.12185 - acc: 0.9480 -- iter: 1280/1608
[A[ATraining Step: 602  | total loss: [1m[32m0.12679[0m[0m | time: 335.343s
[2K
| Adam | epoch: 012 | loss: 0.12679 - acc: 0.9438 -- iter: 1312/1608
[A[ATraining Step: 603  | total loss: [1m[32m0.11931[0m[0m | time: 343.379s
[2K
| Adam | epoch: 012 | loss: 0.11931 - acc: 0.9494 -- iter: 1344/1608
[A[ATraining Step: 604  | total loss: [1m[32m0.10985[0m[0m | time: 351.248s
[2K
| Adam | epoch: 012 | loss: 0.10985 - acc: 0.9545 -- iter: 1376/1608
[A[ATraining Step: 605  | total loss: [1m[32m0.11177[0m[0m | time: 359.167s
[2K
| Adam | epoch: 012 | loss: 0.11177 - acc: 0.9528 -- iter: 1408/1608
[A[ATraining Step: 606  | total loss: [1m[32m0.12092[0m[0m | time: 367.174s
[2K
| Adam | epoch: 012 | loss: 0.12092 - acc: 0.9513 -- iter: 1440/1608
[A[ATraining Step: 607  | total loss: [1m[32m0.11126[0m[0m | time: 375.002s
[2K
| Adam | epoch: 012 | loss: 0.11126 - acc: 0.9561 -- iter: 1472/1608
[A[ATraining Step: 608  | total loss: [1m[32m0.11998[0m[0m | time: 382.863s
[2K
| Adam | epoch: 012 | loss: 0.11998 - acc: 0.9543 -- iter: 1504/1608
[A[ATraining Step: 609  | total loss: [1m[32m0.11270[0m[0m | time: 390.636s
[2K
| Adam | epoch: 012 | loss: 0.11270 - acc: 0.9557 -- iter: 1536/1608
[A[ATraining Step: 610  | total loss: [1m[32m0.10615[0m[0m | time: 398.485s
[2K
| Adam | epoch: 012 | loss: 0.10615 - acc: 0.9570 -- iter: 1568/1608
[A[ATraining Step: 611  | total loss: [1m[32m0.12257[0m[0m | time: 406.385s
[2K
| Adam | epoch: 012 | loss: 0.12257 - acc: 0.9519 -- iter: 1600/1608
[A[ATraining Step: 612  | total loss: [1m[32m0.11720[0m[0m | time: 436.606s
[2K
| Adam | epoch: 012 | loss: 0.11720 - acc: 0.9536 | val_loss: 0.46422 - val_acc: 0.8588 -- iter: 1608/1608
--
Training Step: 613  | total loss: [1m[32m0.11461[0m[0m | time: 8.030s
[2K
| Adam | epoch: 013 | loss: 0.11461 - acc: 0.9551 -- iter: 0032/1608
[A[ATraining Step: 614  | total loss: [1m[32m0.10768[0m[0m | time: 16.100s
[2K
| Adam | epoch: 013 | loss: 0.10768 - acc: 0.9596 -- iter: 0064/1608
[A[ATraining Step: 615  | total loss: [1m[32m0.11698[0m[0m | time: 23.928s
[2K
| Adam | epoch: 013 | loss: 0.11698 - acc: 0.9543 -- iter: 0096/1608
[A[ATraining Step: 616  | total loss: [1m[32m0.12216[0m[0m | time: 31.820s
[2K
| Adam | epoch: 013 | loss: 0.12216 - acc: 0.9526 -- iter: 0128/1608
[A[ATraining Step: 617  | total loss: [1m[32m0.11618[0m[0m | time: 39.778s
[2K
| Adam | epoch: 013 | loss: 0.11618 - acc: 0.9573 -- iter: 0160/1608
[A[ATraining Step: 618  | total loss: [1m[32m0.11025[0m[0m | time: 47.780s
[2K
| Adam | epoch: 013 | loss: 0.11025 - acc: 0.9585 -- iter: 0192/1608
[A[ATraining Step: 619  | total loss: [1m[32m0.11460[0m[0m | time: 55.630s
[2K
| Adam | epoch: 013 | loss: 0.11460 - acc: 0.9595 -- iter: 0224/1608
[A[ATraining Step: 620  | total loss: [1m[32m0.10820[0m[0m | time: 63.326s
[2K
| Adam | epoch: 013 | loss: 0.10820 - acc: 0.9636 -- iter: 0256/1608
[A[ATraining Step: 621  | total loss: [1m[32m0.10255[0m[0m | time: 71.282s
[2K
| Adam | epoch: 013 | loss: 0.10255 - acc: 0.9641 -- iter: 0288/1608
[A[ATraining Step: 622  | total loss: [1m[32m0.09596[0m[0m | time: 79.290s
[2K
| Adam | epoch: 013 | loss: 0.09596 - acc: 0.9677 -- iter: 0320/1608
[A[ATraining Step: 623  | total loss: [1m[32m0.09448[0m[0m | time: 82.041s
[2K
| Adam | epoch: 013 | loss: 0.09448 - acc: 0.9678 -- iter: 0352/1608
[A[ATraining Step: 624  | total loss: [1m[32m0.08882[0m[0m | time: 84.760s
[2K
| Adam | epoch: 013 | loss: 0.08882 - acc: 0.9710 -- iter: 0384/1608
[A[ATraining Step: 625  | total loss: [1m[32m0.08277[0m[0m | time: 92.821s
[2K
| Adam | epoch: 013 | loss: 0.08277 - acc: 0.9739 -- iter: 0416/1608
[A[ATraining Step: 626  | total loss: [1m[32m0.08610[0m[0m | time: 100.669s
[2K
| Adam | epoch: 013 | loss: 0.08610 - acc: 0.9734 -- iter: 0448/1608
[A[ATraining Step: 627  | total loss: [1m[32m0.10524[0m[0m | time: 108.639s
[2K
| Adam | epoch: 013 | loss: 0.10524 - acc: 0.9667 -- iter: 0480/1608
[A[ATraining Step: 628  | total loss: [1m[32m0.09996[0m[0m | time: 116.638s
[2K
| Adam | epoch: 013 | loss: 0.09996 - acc: 0.9669 -- iter: 0512/1608
[A[ATraining Step: 629  | total loss: [1m[32m0.10599[0m[0m | time: 124.651s
[2K
| Adam | epoch: 013 | loss: 0.10599 - acc: 0.9671 -- iter: 0544/1608
[A[ATraining Step: 630  | total loss: [1m[32m0.09660[0m[0m | time: 132.579s
[2K
| Adam | epoch: 013 | loss: 0.09660 - acc: 0.9704 -- iter: 0576/1608
[A[ATraining Step: 631  | total loss: [1m[32m0.09378[0m[0m | time: 140.495s
[2K
| Adam | epoch: 013 | loss: 0.09378 - acc: 0.9702 -- iter: 0608/1608
[A[ATraining Step: 632  | total loss: [1m[32m0.10209[0m[0m | time: 148.656s
[2K
| Adam | epoch: 013 | loss: 0.10209 - acc: 0.9669 -- iter: 0640/1608
[A[ATraining Step: 633  | total loss: [1m[32m0.10114[0m[0m | time: 156.569s
[2K
| Adam | epoch: 013 | loss: 0.10114 - acc: 0.9671 -- iter: 0672/1608
[A[ATraining Step: 634  | total loss: [1m[32m0.10321[0m[0m | time: 164.580s
[2K
| Adam | epoch: 013 | loss: 0.10321 - acc: 0.9642 -- iter: 0704/1608
[A[ATraining Step: 635  | total loss: [1m[32m0.09713[0m[0m | time: 172.358s
[2K
| Adam | epoch: 013 | loss: 0.09713 - acc: 0.9677 -- iter: 0736/1608
[A[ATraining Step: 636  | total loss: [1m[32m0.10009[0m[0m | time: 180.255s
[2K
| Adam | epoch: 013 | loss: 0.10009 - acc: 0.9647 -- iter: 0768/1608
[A[ATraining Step: 637  | total loss: [1m[32m0.10896[0m[0m | time: 188.232s
[2K
| Adam | epoch: 013 | loss: 0.10896 - acc: 0.9589 -- iter: 0800/1608
[A[ATraining Step: 638  | total loss: [1m[32m0.12652[0m[0m | time: 196.171s
[2K
| Adam | epoch: 013 | loss: 0.12652 - acc: 0.9474 -- iter: 0832/1608
[A[ATraining Step: 639  | total loss: [1m[32m0.11884[0m[0m | time: 204.038s
[2K
| Adam | epoch: 013 | loss: 0.11884 - acc: 0.9495 -- iter: 0864/1608
[A[ATraining Step: 640  | total loss: [1m[32m0.11371[0m[0m | time: 211.780s
[2K
| Adam | epoch: 013 | loss: 0.11371 - acc: 0.9545 -- iter: 0896/1608
[A[ATraining Step: 641  | total loss: [1m[32m0.10741[0m[0m | time: 219.528s
[2K
| Adam | epoch: 013 | loss: 0.10741 - acc: 0.9591 -- iter: 0928/1608
[A[ATraining Step: 642  | total loss: [1m[32m0.10554[0m[0m | time: 227.614s
[2K
| Adam | epoch: 013 | loss: 0.10554 - acc: 0.9632 -- iter: 0960/1608
[A[ATraining Step: 643  | total loss: [1m[32m0.10416[0m[0m | time: 235.515s
[2K
| Adam | epoch: 013 | loss: 0.10416 - acc: 0.9637 -- iter: 0992/1608
[A[ATraining Step: 644  | total loss: [1m[32m0.15451[0m[0m | time: 243.291s
[2K
| Adam | epoch: 013 | loss: 0.15451 - acc: 0.9580 -- iter: 1024/1608
[A[ATraining Step: 645  | total loss: [1m[32m0.15258[0m[0m | time: 251.165s
[2K
| Adam | epoch: 013 | loss: 0.15258 - acc: 0.9559 -- iter: 1056/1608
[A[ATraining Step: 646  | total loss: [1m[32m0.14362[0m[0m | time: 259.100s
[2K
| Adam | epoch: 013 | loss: 0.14362 - acc: 0.9572 -- iter: 1088/1608
[A[ATraining Step: 647  | total loss: [1m[32m0.13121[0m[0m | time: 266.935s
[2K
| Adam | epoch: 013 | loss: 0.13121 - acc: 0.9615 -- iter: 1120/1608
[A[ATraining Step: 648  | total loss: [1m[32m0.12412[0m[0m | time: 274.955s
[2K
| Adam | epoch: 013 | loss: 0.12412 - acc: 0.9622 -- iter: 1152/1608
[A[ATraining Step: 649  | total loss: [1m[32m0.12303[0m[0m | time: 282.962s
[2K
| Adam | epoch: 013 | loss: 0.12303 - acc: 0.9629 -- iter: 1184/1608
[A[ATraining Step: 650  | total loss: [1m[32m0.11636[0m[0m | time: 290.744s
[2K
| Adam | epoch: 013 | loss: 0.11636 - acc: 0.9635 -- iter: 1216/1608
[A[ATraining Step: 651  | total loss: [1m[32m0.10680[0m[0m | time: 298.481s
[2K
| Adam | epoch: 013 | loss: 0.10680 - acc: 0.9671 -- iter: 1248/1608
[A[ATraining Step: 652  | total loss: [1m[32m0.10502[0m[0m | time: 306.486s
[2K
| Adam | epoch: 013 | loss: 0.10502 - acc: 0.9642 -- iter: 1280/1608
[A[ATraining Step: 653  | total loss: [1m[32m0.10530[0m[0m | time: 314.635s
[2K
| Adam | epoch: 013 | loss: 0.10530 - acc: 0.9615 -- iter: 1312/1608
[A[ATraining Step: 654  | total loss: [1m[32m0.10302[0m[0m | time: 322.453s
[2K
| Adam | epoch: 013 | loss: 0.10302 - acc: 0.9622 -- iter: 1344/1608
[A[ATraining Step: 655  | total loss: [1m[32m0.10634[0m[0m | time: 330.251s
[2K
| Adam | epoch: 013 | loss: 0.10634 - acc: 0.9597 -- iter: 1376/1608
[A[ATraining Step: 656  | total loss: [1m[32m0.10294[0m[0m | time: 338.237s
[2K
| Adam | epoch: 013 | loss: 0.10294 - acc: 0.9606 -- iter: 1408/1608
[A[ATraining Step: 657  | total loss: [1m[32m0.11057[0m[0m | time: 346.001s
[2K
| Adam | epoch: 013 | loss: 0.11057 - acc: 0.9615 -- iter: 1440/1608
[A[ATraining Step: 658  | total loss: [1m[32m0.10434[0m[0m | time: 353.840s
[2K
| Adam | epoch: 013 | loss: 0.10434 - acc: 0.9653 -- iter: 1472/1608
[A[ATraining Step: 659  | total loss: [1m[32m0.09924[0m[0m | time: 361.780s
[2K
| Adam | epoch: 013 | loss: 0.09924 - acc: 0.9657 -- iter: 1504/1608
[A[ATraining Step: 660  | total loss: [1m[32m0.09124[0m[0m | time: 369.558s
[2K
| Adam | epoch: 013 | loss: 0.09124 - acc: 0.9691 -- iter: 1536/1608
[A[ATraining Step: 661  | total loss: [1m[32m0.08803[0m[0m | time: 377.572s
[2K
| Adam | epoch: 013 | loss: 0.08803 - acc: 0.9722 -- iter: 1568/1608
[A[ATraining Step: 662  | total loss: [1m[32m0.08731[0m[0m | time: 385.702s
[2K
| Adam | epoch: 013 | loss: 0.08731 - acc: 0.9718 -- iter: 1600/1608
[A[ATraining Step: 663  | total loss: [1m[32m0.09264[0m[0m | time: 416.000s
[2K
| Adam | epoch: 013 | loss: 0.09264 - acc: 0.9684 | val_loss: 0.38474 - val_acc: 0.8827 -- iter: 1608/1608
--
Training Step: 664  | total loss: [1m[32m0.08551[0m[0m | time: 7.914s
[2K
| Adam | epoch: 014 | loss: 0.08551 - acc: 0.9716 -- iter: 0032/1608
[A[ATraining Step: 665  | total loss: [1m[32m0.08604[0m[0m | time: 15.750s
[2K
| Adam | epoch: 014 | loss: 0.08604 - acc: 0.9682 -- iter: 0064/1608
[A[ATraining Step: 666  | total loss: [1m[32m0.08543[0m[0m | time: 23.826s
[2K
| Adam | epoch: 014 | loss: 0.08543 - acc: 0.9682 -- iter: 0096/1608
[A[ATraining Step: 667  | total loss: [1m[32m0.08921[0m[0m | time: 31.634s
[2K
| Adam | epoch: 014 | loss: 0.08921 - acc: 0.9651 -- iter: 0128/1608
[A[ATraining Step: 668  | total loss: [1m[32m0.08339[0m[0m | time: 39.627s
[2K
| Adam | epoch: 014 | loss: 0.08339 - acc: 0.9686 -- iter: 0160/1608
[A[ATraining Step: 669  | total loss: [1m[32m0.08288[0m[0m | time: 47.761s
[2K
| Adam | epoch: 014 | loss: 0.08288 - acc: 0.9686 -- iter: 0192/1608
[A[ATraining Step: 670  | total loss: [1m[32m0.08085[0m[0m | time: 55.464s
[2K
| Adam | epoch: 014 | loss: 0.08085 - acc: 0.9718 -- iter: 0224/1608
[A[ATraining Step: 671  | total loss: [1m[32m0.08031[0m[0m | time: 63.429s
[2K
| Adam | epoch: 014 | loss: 0.08031 - acc: 0.9683 -- iter: 0256/1608
[A[ATraining Step: 672  | total loss: [1m[32m0.07413[0m[0m | time: 71.314s
[2K
| Adam | epoch: 014 | loss: 0.07413 - acc: 0.9715 -- iter: 0288/1608
[A[ATraining Step: 673  | total loss: [1m[32m0.07465[0m[0m | time: 79.370s
[2K
| Adam | epoch: 014 | loss: 0.07465 - acc: 0.9712 -- iter: 0320/1608
[A[ATraining Step: 674  | total loss: [1m[32m0.07426[0m[0m | time: 87.258s
[2K
| Adam | epoch: 014 | loss: 0.07426 - acc: 0.9679 -- iter: 0352/1608
[A[ATraining Step: 675  | total loss: [1m[32m0.06971[0m[0m | time: 89.970s
[2K
| Adam | epoch: 014 | loss: 0.06971 - acc: 0.9711 -- iter: 0384/1608
[A[ATraining Step: 676  | total loss: [1m[32m0.06297[0m[0m | time: 92.728s
[2K
| Adam | epoch: 014 | loss: 0.06297 - acc: 0.9740 -- iter: 0416/1608
[A[ATraining Step: 677  | total loss: [1m[32m0.05689[0m[0m | time: 100.689s
[2K
| Adam | epoch: 014 | loss: 0.05689 - acc: 0.9766 -- iter: 0448/1608
[A[ATraining Step: 678  | total loss: [1m[32m0.05879[0m[0m | time: 108.638s
[2K
| Adam | epoch: 014 | loss: 0.05879 - acc: 0.9758 -- iter: 0480/1608
[A[ATraining Step: 679  | total loss: [1m[32m0.05615[0m[0m | time: 116.511s
[2K
| Adam | epoch: 014 | loss: 0.05615 - acc: 0.9782 -- iter: 0512/1608
[A[ATraining Step: 680  | total loss: [1m[32m0.05480[0m[0m | time: 124.420s
[2K
| Adam | epoch: 014 | loss: 0.05480 - acc: 0.9804 -- iter: 0544/1608
[A[ATraining Step: 681  | total loss: [1m[32m0.05382[0m[0m | time: 132.403s
[2K
| Adam | epoch: 014 | loss: 0.05382 - acc: 0.9824 -- iter: 0576/1608
[A[ATraining Step: 682  | total loss: [1m[32m0.05275[0m[0m | time: 140.349s
[2K
| Adam | epoch: 014 | loss: 0.05275 - acc: 0.9841 -- iter: 0608/1608
[A[ATraining Step: 683  | total loss: [1m[32m0.05277[0m[0m | time: 148.231s
[2K
| Adam | epoch: 014 | loss: 0.05277 - acc: 0.9857 -- iter: 0640/1608
[A[ATraining Step: 684  | total loss: [1m[32m0.05763[0m[0m | time: 156.014s
[2K
| Adam | epoch: 014 | loss: 0.05763 - acc: 0.9778 -- iter: 0672/1608
[A[ATraining Step: 685  | total loss: [1m[32m0.06466[0m[0m | time: 163.852s
[2K
| Adam | epoch: 014 | loss: 0.06466 - acc: 0.9737 -- iter: 0704/1608
[A[ATraining Step: 686  | total loss: [1m[32m0.06756[0m[0m | time: 171.578s
[2K
| Adam | epoch: 014 | loss: 0.06756 - acc: 0.9732 -- iter: 0736/1608
[A[ATraining Step: 687  | total loss: [1m[32m0.06156[0m[0m | time: 179.723s
[2K
| Adam | epoch: 014 | loss: 0.06156 - acc: 0.9759 -- iter: 0768/1608
[A[ATraining Step: 688  | total loss: [1m[32m0.10945[0m[0m | time: 187.481s
[2K
| Adam | epoch: 014 | loss: 0.10945 - acc: 0.9658 -- iter: 0800/1608
[A[ATraining Step: 689  | total loss: [1m[32m0.10856[0m[0m | time: 195.474s
[2K
| Adam | epoch: 014 | loss: 0.10856 - acc: 0.9661 -- iter: 0832/1608
[A[ATraining Step: 690  | total loss: [1m[32m0.10051[0m[0m | time: 203.586s
[2K
| Adam | epoch: 014 | loss: 0.10051 - acc: 0.9695 -- iter: 0864/1608
[A[ATraining Step: 691  | total loss: [1m[32m0.09582[0m[0m | time: 211.814s
[2K
| Adam | epoch: 014 | loss: 0.09582 - acc: 0.9694 -- iter: 0896/1608
[A[ATraining Step: 692  | total loss: [1m[32m0.09987[0m[0m | time: 219.594s
[2K
| Adam | epoch: 014 | loss: 0.09987 - acc: 0.9662 -- iter: 0928/1608
[A[ATraining Step: 693  | total loss: [1m[32m0.11567[0m[0m | time: 227.552s
[2K
| Adam | epoch: 014 | loss: 0.11567 - acc: 0.9634 -- iter: 0960/1608
[A[ATraining Step: 694  | total loss: [1m[32m0.11005[0m[0m | time: 235.400s
[2K
| Adam | epoch: 014 | loss: 0.11005 - acc: 0.9639 -- iter: 0992/1608
[A[ATraining Step: 695  | total loss: [1m[32m0.10466[0m[0m | time: 243.349s
[2K
| Adam | epoch: 014 | loss: 0.10466 - acc: 0.9644 -- iter: 1024/1608
[A[ATraining Step: 696  | total loss: [1m[32m0.09509[0m[0m | time: 251.278s
[2K
| Adam | epoch: 014 | loss: 0.09509 - acc: 0.9679 -- iter: 1056/1608
[A[ATraining Step: 697  | total loss: [1m[32m0.09171[0m[0m | time: 259.307s
[2K
| Adam | epoch: 014 | loss: 0.09171 - acc: 0.9680 -- iter: 1088/1608
[A[ATraining Step: 698  | total loss: [1m[32m0.09707[0m[0m | time: 267.125s
[2K
| Adam | epoch: 014 | loss: 0.09707 - acc: 0.9618 -- iter: 1120/1608
[A[ATraining Step: 699  | total loss: [1m[32m0.09491[0m[0m | time: 275.152s
[2K
| Adam | epoch: 014 | loss: 0.09491 - acc: 0.9625 -- iter: 1152/1608
[A[ATraining Step: 700  | total loss: [1m[32m0.09698[0m[0m | time: 282.979s
[2K
| Adam | epoch: 014 | loss: 0.09698 - acc: 0.9600 -- iter: 1184/1608
[A[ATraining Step: 701  | total loss: [1m[32m0.08902[0m[0m | time: 291.194s
[2K
| Adam | epoch: 014 | loss: 0.08902 - acc: 0.9640 -- iter: 1216/1608
[A[ATraining Step: 702  | total loss: [1m[32m0.09003[0m[0m | time: 299.058s
[2K
| Adam | epoch: 014 | loss: 0.09003 - acc: 0.9614 -- iter: 1248/1608
[A[ATraining Step: 703  | total loss: [1m[32m0.08523[0m[0m | time: 307.098s
[2K
| Adam | epoch: 014 | loss: 0.08523 - acc: 0.9652 -- iter: 1280/1608
[A[ATraining Step: 704  | total loss: [1m[32m0.09234[0m[0m | time: 315.054s
[2K
| Adam | epoch: 014 | loss: 0.09234 - acc: 0.9625 -- iter: 1312/1608
[A[ATraining Step: 705  | total loss: [1m[32m0.09002[0m[0m | time: 323.015s
[2K
| Adam | epoch: 014 | loss: 0.09002 - acc: 0.9631 -- iter: 1344/1608
[A[ATraining Step: 706  | total loss: [1m[32m0.08592[0m[0m | time: 331.137s
[2K
| Adam | epoch: 014 | loss: 0.08592 - acc: 0.9637 -- iter: 1376/1608
[A[ATraining Step: 707  | total loss: [1m[32m0.08655[0m[0m | time: 339.129s
[2K
| Adam | epoch: 014 | loss: 0.08655 - acc: 0.9673 -- iter: 1408/1608
[A[ATraining Step: 708  | total loss: [1m[32m0.08435[0m[0m | time: 347.211s
[2K
| Adam | epoch: 014 | loss: 0.08435 - acc: 0.9674 -- iter: 1440/1608
[A[ATraining Step: 709  | total loss: [1m[32m0.08198[0m[0m | time: 355.449s
[2K
| Adam | epoch: 014 | loss: 0.08198 - acc: 0.9676 -- iter: 1472/1608
[A[ATraining Step: 710  | total loss: [1m[32m0.07786[0m[0m | time: 363.329s
[2K
| Adam | epoch: 014 | loss: 0.07786 - acc: 0.9677 -- iter: 1504/1608
[A[ATraining Step: 711  | total loss: [1m[32m0.07933[0m[0m | time: 371.415s
[2K
| Adam | epoch: 014 | loss: 0.07933 - acc: 0.9615 -- iter: 1536/1608
[A[ATraining Step: 712  | total loss: [1m[32m0.07908[0m[0m | time: 379.439s
[2K
| Adam | epoch: 014 | loss: 0.07908 - acc: 0.9591 -- iter: 1568/1608
[A[ATraining Step: 713  | total loss: [1m[32m0.07427[0m[0m | time: 387.649s
[2K
| Adam | epoch: 014 | loss: 0.07427 - acc: 0.9632 -- iter: 1600/1608
[A[ATraining Step: 714  | total loss: [1m[32m0.06989[0m[0m | time: 418.000s
[2K
| Adam | epoch: 014 | loss: 0.06989 - acc: 0.9669 | val_loss: 1.02500 - val_acc: 0.7555 -- iter: 1608/1608
--
Training Step: 715  | total loss: [1m[32m0.06561[0m[0m | time: 7.905s
[2K
| Adam | epoch: 015 | loss: 0.06561 - acc: 0.9702 -- iter: 0032/1608
[A[ATraining Step: 716  | total loss: [1m[32m0.07219[0m[0m | time: 15.728s
[2K
| Adam | epoch: 015 | loss: 0.07219 - acc: 0.9701 -- iter: 0064/1608
[A[ATraining Step: 717  | total loss: [1m[32m0.08682[0m[0m | time: 23.556s
[2K
| Adam | epoch: 015 | loss: 0.08682 - acc: 0.9699 -- iter: 0096/1608
[A[ATraining Step: 718  | total loss: [1m[32m0.09966[0m[0m | time: 31.660s
[2K
| Adam | epoch: 015 | loss: 0.09966 - acc: 0.9636 -- iter: 0128/1608
[A[ATraining Step: 719  | total loss: [1m[32m0.09045[0m[0m | time: 39.701s
[2K
| Adam | epoch: 015 | loss: 0.09045 - acc: 0.9672 -- iter: 0160/1608
[A[ATraining Step: 720  | total loss: [1m[32m0.08409[0m[0m | time: 47.793s
[2K
| Adam | epoch: 015 | loss: 0.08409 - acc: 0.9705 -- iter: 0192/1608
[A[ATraining Step: 721  | total loss: [1m[32m0.07939[0m[0m | time: 55.943s
[2K
| Adam | epoch: 015 | loss: 0.07939 - acc: 0.9734 -- iter: 0224/1608
[A[ATraining Step: 722  | total loss: [1m[32m0.07245[0m[0m | time: 63.848s
[2K
| Adam | epoch: 015 | loss: 0.07245 - acc: 0.9761 -- iter: 0256/1608
[A[ATraining Step: 723  | total loss: [1m[32m0.06864[0m[0m | time: 71.884s
[2K
| Adam | epoch: 015 | loss: 0.06864 - acc: 0.9785 -- iter: 0288/1608
[A[ATraining Step: 724  | total loss: [1m[32m0.07862[0m[0m | time: 79.846s
[2K
| Adam | epoch: 015 | loss: 0.07862 - acc: 0.9775 -- iter: 0320/1608
[A[ATraining Step: 725  | total loss: [1m[32m0.09182[0m[0m | time: 87.969s
[2K
| Adam | epoch: 015 | loss: 0.09182 - acc: 0.9704 -- iter: 0352/1608
[A[ATraining Step: 726  | total loss: [1m[32m0.09259[0m[0m | time: 95.866s
[2K
| Adam | epoch: 015 | loss: 0.09259 - acc: 0.9702 -- iter: 0384/1608
[A[ATraining Step: 727  | total loss: [1m[32m0.09761[0m[0m | time: 98.567s
[2K
| Adam | epoch: 015 | loss: 0.09761 - acc: 0.9670 -- iter: 0416/1608
[A[ATraining Step: 728  | total loss: [1m[32m0.10613[0m[0m | time: 101.301s
[2K
| Adam | epoch: 015 | loss: 0.10613 - acc: 0.9578 -- iter: 0448/1608
[A[ATraining Step: 729  | total loss: [1m[32m0.09776[0m[0m | time: 109.153s
[2K
| Adam | epoch: 015 | loss: 0.09776 - acc: 0.9620 -- iter: 0480/1608
[A[ATraining Step: 730  | total loss: [1m[32m0.12331[0m[0m | time: 117.048s
[2K
| Adam | epoch: 015 | loss: 0.12331 - acc: 0.9564 -- iter: 0512/1608
[A[ATraining Step: 731  | total loss: [1m[32m0.13365[0m[0m | time: 125.047s
[2K
| Adam | epoch: 015 | loss: 0.13365 - acc: 0.9545 -- iter: 0544/1608
[A[ATraining Step: 732  | total loss: [1m[32m0.14760[0m[0m | time: 133.071s
[2K
| Adam | epoch: 015 | loss: 0.14760 - acc: 0.9497 -- iter: 0576/1608
[A[ATraining Step: 733  | total loss: [1m[32m0.15973[0m[0m | time: 141.049s
[2K
| Adam | epoch: 015 | loss: 0.15973 - acc: 0.9516 -- iter: 0608/1608
[A[ATraining Step: 734  | total loss: [1m[32m0.15923[0m[0m | time: 149.262s
[2K
| Adam | epoch: 015 | loss: 0.15923 - acc: 0.9502 -- iter: 0640/1608
[A[ATraining Step: 735  | total loss: [1m[32m0.16167[0m[0m | time: 157.237s
[2K
| Adam | epoch: 015 | loss: 0.16167 - acc: 0.9489 -- iter: 0672/1608
[A[ATraining Step: 736  | total loss: [1m[32m0.15419[0m[0m | time: 165.350s
[2K
| Adam | epoch: 015 | loss: 0.15419 - acc: 0.9478 -- iter: 0704/1608
[A[ATraining Step: 737  | total loss: [1m[32m0.14494[0m[0m | time: 173.434s
[2K
| Adam | epoch: 015 | loss: 0.14494 - acc: 0.9499 -- iter: 0736/1608
[A[ATraining Step: 738  | total loss: [1m[32m0.13713[0m[0m | time: 181.482s
[2K
| Adam | epoch: 015 | loss: 0.13713 - acc: 0.9518 -- iter: 0768/1608
[A[ATraining Step: 739  | total loss: [1m[32m0.12686[0m[0m | time: 189.400s
[2K
| Adam | epoch: 015 | loss: 0.12686 - acc: 0.9566 -- iter: 0800/1608
[A[ATraining Step: 740  | total loss: [1m[32m0.14598[0m[0m | time: 197.413s
[2K
| Adam | epoch: 015 | loss: 0.14598 - acc: 0.9516 -- iter: 0832/1608
[A[ATraining Step: 741  | total loss: [1m[32m0.13540[0m[0m | time: 205.288s
[2K
| Adam | epoch: 015 | loss: 0.13540 - acc: 0.9564 -- iter: 0864/1608
[A[ATraining Step: 742  | total loss: [1m[32m0.15545[0m[0m | time: 213.353s
[2K
| Adam | epoch: 015 | loss: 0.15545 - acc: 0.9420 -- iter: 0896/1608
[A[ATraining Step: 743  | total loss: [1m[32m0.14759[0m[0m | time: 221.173s
[2K
| Adam | epoch: 015 | loss: 0.14759 - acc: 0.9447 -- iter: 0928/1608
[A[ATraining Step: 744  | total loss: [1m[32m0.13740[0m[0m | time: 228.985s
[2K
| Adam | epoch: 015 | loss: 0.13740 - acc: 0.9502 -- iter: 0960/1608
[A[ATraining Step: 745  | total loss: [1m[32m0.14066[0m[0m | time: 236.817s
[2K
| Adam | epoch: 015 | loss: 0.14066 - acc: 0.9489 -- iter: 0992/1608
[A[ATraining Step: 746  | total loss: [1m[32m0.14464[0m[0m | time: 244.875s
[2K
| Adam | epoch: 015 | loss: 0.14464 - acc: 0.9447 -- iter: 1024/1608
[A[ATraining Step: 747  | total loss: [1m[32m0.14653[0m[0m | time: 252.903s
[2K
| Adam | epoch: 015 | loss: 0.14653 - acc: 0.9471 -- iter: 1056/1608
[A[ATraining Step: 748  | total loss: [1m[32m0.13747[0m[0m | time: 260.802s
[2K
| Adam | epoch: 015 | loss: 0.13747 - acc: 0.9524 -- iter: 1088/1608
[A[ATraining Step: 749  | total loss: [1m[32m0.14218[0m[0m | time: 268.764s
[2K
| Adam | epoch: 015 | loss: 0.14218 - acc: 0.9509 -- iter: 1120/1608
[A[ATraining Step: 750  | total loss: [1m[32m0.15200[0m[0m | time: 276.739s
[2K
| Adam | epoch: 015 | loss: 0.15200 - acc: 0.9464 -- iter: 1152/1608
[A[ATraining Step: 751  | total loss: [1m[32m0.15053[0m[0m | time: 284.982s
[2K
| Adam | epoch: 015 | loss: 0.15053 - acc: 0.9455 -- iter: 1184/1608
[A[ATraining Step: 752  | total loss: [1m[32m0.13938[0m[0m | time: 292.999s
[2K
| Adam | epoch: 015 | loss: 0.13938 - acc: 0.9510 -- iter: 1216/1608
[A[ATraining Step: 753  | total loss: [1m[32m0.13555[0m[0m | time: 300.876s
[2K
| Adam | epoch: 015 | loss: 0.13555 - acc: 0.9528 -- iter: 1248/1608
[A[ATraining Step: 754  | total loss: [1m[32m0.13698[0m[0m | time: 308.889s
[2K
| Adam | epoch: 015 | loss: 0.13698 - acc: 0.9512 -- iter: 1280/1608
[A[ATraining Step: 755  | total loss: [1m[32m0.13344[0m[0m | time: 316.896s
[2K
| Adam | epoch: 015 | loss: 0.13344 - acc: 0.9530 -- iter: 1312/1608
[A[ATraining Step: 756  | total loss: [1m[32m0.14922[0m[0m | time: 324.708s
[2K
| Adam | epoch: 015 | loss: 0.14922 - acc: 0.9483 -- iter: 1344/1608
[A[ATraining Step: 757  | total loss: [1m[32m0.15217[0m[0m | time: 332.861s
[2K
| Adam | epoch: 015 | loss: 0.15217 - acc: 0.9441 -- iter: 1376/1608
[A[ATraining Step: 758  | total loss: [1m[32m0.15168[0m[0m | time: 340.854s
[2K
| Adam | epoch: 015 | loss: 0.15168 - acc: 0.9466 -- iter: 1408/1608
[A[ATraining Step: 759  | total loss: [1m[32m0.16286[0m[0m | time: 348.641s
[2K
| Adam | epoch: 015 | loss: 0.16286 - acc: 0.9457 -- iter: 1440/1608
[A[ATraining Step: 760  | total loss: [1m[32m0.16326[0m[0m | time: 356.744s
[2K
| Adam | epoch: 015 | loss: 0.16326 - acc: 0.9448 -- iter: 1472/1608
[A[ATraining Step: 761  | total loss: [1m[32m0.14828[0m[0m | time: 364.692s
[2K
| Adam | epoch: 015 | loss: 0.14828 - acc: 0.9504 -- iter: 1504/1608
[A[ATraining Step: 762  | total loss: [1m[32m0.13888[0m[0m | time: 372.632s
[2K
| Adam | epoch: 015 | loss: 0.13888 - acc: 0.9522 -- iter: 1536/1608
[A[ATraining Step: 763  | total loss: [1m[32m0.13044[0m[0m | time: 380.312s
[2K
| Adam | epoch: 015 | loss: 0.13044 - acc: 0.9539 -- iter: 1568/1608
[A[ATraining Step: 764  | total loss: [1m[32m0.12385[0m[0m | time: 388.263s
[2K
| Adam | epoch: 015 | loss: 0.12385 - acc: 0.9553 -- iter: 1600/1608
[A[ATraining Step: 765  | total loss: [1m[32m0.11880[0m[0m | time: 418.605s
[2K
| Adam | epoch: 015 | loss: 0.11880 - acc: 0.9567 | val_loss: 0.39589 - val_acc: 0.8489 -- iter: 1608/1608
--
Validation AUC:0.93215292515283
Validation AUPRC:0.9277873416095366
Test AUC:0.9384281688356925
Test AUPRC:0.9308915627066585
BestTestF1Score	0.86	0.73	0.86	0.84	0.89	216	42	219	26	0.31
BestTestMCCScore	0.86	0.73	0.86	0.84	0.89	216	42	219	26	0.31
BestTestAccuracyScore	0.86	0.73	0.86	0.84	0.89	216	42	219	26	0.31
BestValidationF1Score	0.87	0.74	0.87	0.85	0.89	214	39	223	27	0.31
BestValidationMCC	0.87	0.74	0.87	0.85	0.89	214	39	223	27	0.31
BestValidationAccuracy	0.87	0.74	0.87	0.85	0.89	214	39	223	27	0.31
TestPredictions (Threshold:0.31)
CHEMBL204084,FP,INACT,0.7300000190734863	CHEMBL354883,TP,ACT,1.0	CHEMBL424111,TP,ACT,0.8600000143051147	CHEMBL320098,TN,INACT,0.0	CHEMBL2313089,TN,INACT,0.03999999910593033	CHEMBL3423008,TN,INACT,0.0	CHEMBL171288,TP,ACT,0.9300000071525574	CHEMBL333835,TP,ACT,1.0	CHEMBL3780208,TN,INACT,0.0	CHEMBL214368,TN,INACT,0.009999999776482582	CHEMBL553237,FP,INACT,0.800000011920929	CHEMBL441468,TN,INACT,0.2800000011920929	CHEMBL315626,FP,INACT,0.9800000190734863	CHEMBL64838,TN,INACT,0.009999999776482582	CHEMBL292300,TN,INACT,0.0	CHEMBL1812021,FP,INACT,0.8799999952316284	CHEMBL1921969,FP,INACT,1.0	CHEMBL2182017,TN,INACT,0.009999999776482582	CHEMBL344451,TP,ACT,1.0	CHEMBL62160,TN,INACT,0.0	CHEMBL2409440,TP,ACT,1.0	CHEMBL40878,TP,ACT,0.6600000262260437	CHEMBL144859,TN,INACT,0.0	CHEMBL3423010,TN,INACT,0.009999999776482582	CHEMBL10975,TP,ACT,1.0	CHEMBL1464645,TN,INACT,0.10000000149011612	CHEMBL2372448,TN,INACT,0.0	CHEMBL147707,TN,INACT,0.0	CHEMBL2326345,TN,INACT,0.03999999910593033	CHEMBL314155,TP,ACT,0.9900000095367432	CHEMBL230879,TN,INACT,0.0	CHEMBL406121,TN,INACT,0.1599999964237213	CHEMBL1366764,TN,INACT,0.14000000059604645	CHEMBL1812011,FP,INACT,0.9900000095367432	CHEMBL543416,FN,ACT,0.09000000357627869	CHEMBL2367637,TP,ACT,0.7799999713897705	CHEMBL354199,TP,ACT,0.9700000286102295	CHEMBL160154,TP,ACT,1.0	CHEMBL3125570,TN,INACT,0.009999999776482582	CHEMBL84205,TP,ACT,0.9800000190734863	CHEMBL1046,TN,INACT,0.009999999776482582	CHEMBL330460,TN,INACT,0.0	CHEMBL85215,TP,ACT,1.0	CHEMBL2159365,TN,INACT,0.0	CHEMBL244726,FN,ACT,0.07000000029802322	CHEMBL3423028,TN,INACT,0.029999999329447746	CHEMBL320750,FP,INACT,0.6800000071525574	CHEMBL92865,TN,INACT,0.0	CHEMBL217744,TP,ACT,0.9300000071525574	CHEMBL278222,TP,ACT,0.9800000190734863	CHEMBL1392593,FP,INACT,0.8399999737739563	CHEMBL118176,TP,ACT,0.5899999737739563	CHEMBL2372759,TN,INACT,0.0	CHEMBL2409433,TP,ACT,1.0	CHEMBL418822,TP,ACT,1.0	CHEMBL302913,TN,INACT,0.0	CHEMBL557472,TN,INACT,0.0	CHEMBL12051,TP,ACT,1.0	CHEMBL3585742,TN,INACT,0.029999999329447746	CHEMBL3617964,TP,ACT,0.9900000095367432	CHEMBL62807,TN,INACT,0.0	CHEMBL276864,TN,INACT,0.009999999776482582	CHEMBL342379,TP,ACT,1.0	CHEMBL542949,TP,ACT,0.949999988079071	CHEMBL26499,TP,ACT,1.0	CHEMBL86037,FN,ACT,0.20999999344348907	CHEMBL1289860,TN,INACT,0.019999999552965164	CHEMBL2338694,TN,INACT,0.0	CHEMBL68311,TP,ACT,0.9900000095367432	CHEMBL273818,TP,ACT,0.9700000286102295	CHEMBL319723,TP,ACT,1.0	CHEMBL335981,FP,INACT,0.8899999856948853	CHEMBL105935,TN,INACT,0.1599999964237213	CHEMBL293558,TP,ACT,1.0	CHEMBL593985,TP,ACT,0.9900000095367432	CHEMBL13740,TP,ACT,0.9700000286102295	CHEMBL2367672,TP,ACT,0.7099999785423279	CHEMBL2304304,TP,ACT,0.9700000286102295	CHEMBL10176,TP,ACT,0.5799999833106995	CHEMBL180850,TN,INACT,0.0	CHEMBL104930,TN,INACT,0.05000000074505806	CHEMBL1688696,TN,INACT,0.0	CHEMBL3287437,FP,INACT,0.41999998688697815	CHEMBL25699,FP,INACT,0.6299999952316284	CHEMBL213180,TN,INACT,0.009999999776482582	CHEMBL308632,TN,INACT,0.0	CHEMBL422299,TN,INACT,0.009999999776482582	CHEMBL2159392,TN,INACT,0.0	CHEMBL563834,TN,INACT,0.0	CHEMBL417289,TP,ACT,0.7599999904632568	CHEMBL84442,FP,INACT,0.8999999761581421	CHEMBL36341,TN,INACT,0.0	CHEMBL3398155,TP,ACT,0.9800000190734863	CHEMBL346117,TN,INACT,0.0	CHEMBL9802,TP,ACT,0.949999988079071	CHEMBL83564,TP,ACT,1.0	CHEMBL117147,TN,INACT,0.0	CHEMBL340818,TP,ACT,1.0	CHEMBL104,TN,INACT,0.0	CHEMBL378916,TN,INACT,0.0	CHEMBL56907,TP,ACT,1.0	CHEMBL269669,TP,ACT,0.9700000286102295	CHEMBL242998,FP,INACT,0.8500000238418579	CHEMBL215295,TN,INACT,0.0	CHEMBL2372359,TP,ACT,1.0	CHEMBL3219678,FP,INACT,0.9800000190734863	CHEMBL311340,FP,INACT,0.6399999856948853	CHEMBL56342,TP,ACT,1.0	CHEMBL49425,TP,ACT,1.0	CHEMBL23952,TP,ACT,0.6800000071525574	CHEMBL558846,TP,ACT,0.9200000166893005	CHEMBL2370192,TP,ACT,0.9599999785423279	CHEMBL2115562,TP,ACT,0.8399999737739563	CHEMBL39078,TN,INACT,0.0	CHEMBL109306,TP,ACT,0.9300000071525574	CHEMBL3398150,FN,ACT,0.09000000357627869	CHEMBL143215,TP,ACT,1.0	CHEMBL280162,TN,INACT,0.0	CHEMBL343478,TP,ACT,0.7300000190734863	CHEMBL3781784,TN,INACT,0.0	CHEMBL284205,TP,ACT,0.5199999809265137	CHEMBL2409445,TP,ACT,0.9800000190734863	CHEMBL610502,TN,INACT,0.019999999552965164	CHEMBL429359,TP,ACT,1.0	CHEMBL417058,TN,INACT,0.0	CHEMBL3084798,TN,INACT,0.0	CHEMBL11758,TP,ACT,1.0	CHEMBL561190,TP,ACT,0.38999998569488525	CHEMBL3423011,TN,INACT,0.0	CHEMBL572250,TN,INACT,0.03999999910593033	CHEMBL3287456,TN,INACT,0.0	CHEMBL40862,TN,INACT,0.0	CHEMBL495465,TN,INACT,0.0	CHEMBL461629,TN,INACT,0.0	CHEMBL40840,TP,ACT,0.7200000286102295	CHEMBL307385,FP,INACT,0.46000000834465027	CHEMBL212723,TN,INACT,0.23000000417232513	CHEMBL3342779,TP,ACT,0.9700000286102295	CHEMBL2372455,TN,INACT,0.10000000149011612	CHEMBL13937,TP,ACT,1.0	CHEMBL3596201,TN,INACT,0.0	CHEMBL350280,TN,INACT,0.23999999463558197	CHEMBL127714,TP,ACT,0.8299999833106995	CHEMBL2372678,TN,INACT,0.25	CHEMBL38674,FP,INACT,0.9700000286102295	CHEMBL60160,TN,INACT,0.10000000149011612	CHEMBL3596559,TN,INACT,0.0	CHEMBL559936,TP,ACT,0.9700000286102295	CHEMBL244908,TP,ACT,0.5	CHEMBL562975,TP,ACT,0.9800000190734863	CHEMBL272394,FP,INACT,0.9900000095367432	CHEMBL419985,TP,ACT,0.9300000071525574	CHEMBL2159294,TN,INACT,0.009999999776482582	CHEMBL110685,TP,ACT,0.9300000071525574	CHEMBL2409572,TP,ACT,0.3400000035762787	CHEMBL564263,TP,ACT,1.0	CHEMBL356487,TN,INACT,0.0	CHEMBL41504,TP,ACT,0.49000000953674316	CHEMBL142240,TN,INACT,0.05999999865889549	CHEMBL306565,TP,ACT,0.949999988079071	CHEMBL433751,TN,INACT,0.029999999329447746	CHEMBL2372684,TN,INACT,0.009999999776482582	CHEMBL343599,TP,ACT,0.9599999785423279	CHEMBL111660,TN,INACT,0.0	CHEMBL3273009,FP,INACT,0.949999988079071	CHEMBL7816,FN,ACT,0.15000000596046448	CHEMBL142100,TP,ACT,0.8600000143051147	CHEMBL90730,TP,ACT,1.0	CHEMBL128685,TN,INACT,0.07000000029802322	CHEMBL295211,FP,INACT,0.5	CHEMBL421272,TN,INACT,0.0	CHEMBL105171,TN,INACT,0.0	CHEMBL13684,TP,ACT,0.3400000035762787	CHEMBL60244,TN,INACT,0.0	CHEMBL227425,TN,INACT,0.009999999776482582	CHEMBL549709,TP,ACT,0.8899999856948853	CHEMBL145550,TP,ACT,0.47999998927116394	CHEMBL85914,FP,INACT,0.9700000286102295	CHEMBL397270,FN,ACT,0.2199999988079071	CHEMBL204086,TN,INACT,0.0	CHEMBL2372975,TP,ACT,1.0	CHEMBL268957,TP,ACT,0.44999998807907104	CHEMBL2409435,TP,ACT,0.800000011920929	CHEMBL16143,TN,INACT,0.0	CHEMBL64495,TN,INACT,0.009999999776482582	CHEMBL387791,FN,ACT,0.1599999964237213	CHEMBL512935,TN,INACT,0.07000000029802322	CHEMBL3262102,FN,ACT,0.1599999964237213	CHEMBL3786896,FP,INACT,0.9599999785423279	CHEMBL131747,TN,INACT,0.019999999552965164	CHEMBL106592,TP,ACT,0.9800000190734863	CHEMBL262956,TP,ACT,0.8600000143051147	CHEMBL426433,TN,INACT,0.0	CHEMBL3262099,TP,ACT,0.7799999713897705	CHEMBL146940,TN,INACT,0.0	CHEMBL84724,TP,ACT,0.9900000095367432	CHEMBL215556,TN,INACT,0.009999999776482582	CHEMBL419567,TP,ACT,0.9800000190734863	CHEMBL493140,TN,INACT,0.0	CHEMBL67393,TN,INACT,0.25	CHEMBL56605,TP,ACT,0.6200000047683716	CHEMBL305643,TN,INACT,0.0	CHEMBL2372685,TN,INACT,0.0	CHEMBL2367638,TP,ACT,0.9900000095367432	CHEMBL1808481,FN,ACT,0.09000000357627869	CHEMBL418117,TP,ACT,1.0	CHEMBL2159391,TN,INACT,0.0	CHEMBL430991,FP,INACT,0.5299999713897705	CHEMBL393591,TN,INACT,0.07000000029802322	CHEMBL11098,TP,ACT,1.0	CHEMBL3287465,TN,INACT,0.0	CHEMBL3398151,TP,ACT,0.7900000214576721	CHEMBL103043,TN,INACT,0.0	CHEMBL23263,TP,ACT,0.9900000095367432	CHEMBL558610,TN,INACT,0.0	CHEMBL176221,TN,INACT,0.0	CHEMBL2409571,TP,ACT,0.9399999976158142	CHEMBL114868,TP,ACT,1.0	CHEMBL2159302,TN,INACT,0.0	CHEMBL210771,TN,INACT,0.0	CHEMBL153687,TP,ACT,0.7599999904632568	CHEMBL9792,TP,ACT,0.8899999856948853	CHEMBL2047998,TN,INACT,0.029999999329447746	CHEMBL43017,TN,INACT,0.0	CHEMBL410994,TN,INACT,0.05000000074505806	CHEMBL269448,TP,ACT,1.0	CHEMBL54894,TN,INACT,0.0	CHEMBL422298,TP,ACT,1.0	CHEMBL1574542,TN,INACT,0.11999999731779099	CHEMBL108873,TP,ACT,1.0	CHEMBL308061,TP,ACT,0.9900000095367432	CHEMBL86173,TP,ACT,0.9100000262260437	CHEMBL160417,TP,ACT,0.9700000286102295	CHEMBL14165,TP,ACT,0.9900000095367432	CHEMBL160256,TP,ACT,1.0	CHEMBL13954,TP,ACT,1.0	CHEMBL293062,TP,ACT,1.0	CHEMBL151,TN,INACT,0.009999999776482582	CHEMBL11391,TP,ACT,0.9900000095367432	CHEMBL212401,TN,INACT,0.019999999552965164	CHEMBL446371,TP,ACT,0.9700000286102295	CHEMBL2159390,TN,INACT,0.0	CHEMBL72575,TP,ACT,0.8799999952316284	CHEMBL113531,TN,INACT,0.029999999329447746	CHEMBL2372702,FP,INACT,0.6200000047683716	CHEMBL3408420,TN,INACT,0.07000000029802322	CHEMBL112119,TP,ACT,1.0	CHEMBL594012,TP,ACT,0.9900000095367432	CHEMBL262516,TP,ACT,1.0	CHEMBL319997,TN,INACT,0.0	CHEMBL502292,TN,INACT,0.009999999776482582	CHEMBL1808521,TP,ACT,0.3700000047683716	CHEMBL3125572,TN,INACT,0.05000000074505806	CHEMBL346534,TP,ACT,1.0	CHEMBL14631,TP,ACT,1.0	CHEMBL127027,TP,ACT,0.7599999904632568	CHEMBL284805,TN,INACT,0.0	CHEMBL85164,TN,INACT,0.05000000074505806	CHEMBL566918,TP,ACT,0.8799999952316284	CHEMBL385140,TN,INACT,0.029999999329447746	CHEMBL274085,TP,ACT,1.0	CHEMBL298959,TP,ACT,0.9599999785423279	CHEMBL398168,TP,ACT,0.9900000095367432	CHEMBL387576,TP,ACT,0.6399999856948853	CHEMBL1422664,TN,INACT,0.05000000074505806	CHEMBL336779,TP,ACT,0.4300000071525574	CHEMBL605210,TN,INACT,0.05999999865889549	CHEMBL443008,TN,INACT,0.029999999329447746	CHEMBL325713,TP,ACT,1.0	CHEMBL302123,TP,ACT,1.0	CHEMBL302961,TP,ACT,1.0	CHEMBL2107493,FN,ACT,0.25999999046325684	CHEMBL10157,TP,ACT,0.9900000095367432	CHEMBL217920,FP,INACT,0.3100000023841858	CHEMBL326616,FN,ACT,0.07000000029802322	CHEMBL65589,FN,ACT,0.15000000596046448	CHEMBL1526632,TN,INACT,0.30000001192092896	CHEMBL504657,TN,INACT,0.0	CHEMBL314189,TN,INACT,0.0	CHEMBL2315243,TN,INACT,0.0	CHEMBL418251,TN,INACT,0.03999999910593033	CHEMBL49955,TP,ACT,1.0	CHEMBL1808477,FP,INACT,0.5299999713897705	CHEMBL111643,TN,INACT,0.05000000074505806	CHEMBL339902,TN,INACT,0.0	CHEMBL228113,FP,INACT,0.4699999988079071	CHEMBL151119,TP,ACT,0.8500000238418579	CHEMBL1808487,FN,ACT,0.28999999165534973	CHEMBL74598,TP,ACT,1.0	CHEMBL2372665,TN,INACT,0.0	CHEMBL172183,TP,ACT,0.9700000286102295	CHEMBL14293,TP,ACT,0.9800000190734863	CHEMBL104937,TN,INACT,0.0	CHEMBL564055,TP,ACT,0.9599999785423279	CHEMBL1232568,TN,INACT,0.03999999910593033	CHEMBL3238375,TN,INACT,0.029999999329447746	CHEMBL314845,TP,ACT,1.0	CHEMBL142579,TP,ACT,1.0	CHEMBL422356,TP,ACT,0.9900000095367432	CHEMBL146219,FN,ACT,0.07999999821186066	CHEMBL291309,TP,ACT,1.0	CHEMBL2372751,TN,INACT,0.009999999776482582	CHEMBL2370416,TN,INACT,0.03999999910593033	CHEMBL283168,TP,ACT,0.6399999856948853	CHEMBL49750,TP,ACT,0.9599999785423279	CHEMBL11032,TP,ACT,1.0	CHEMBL431207,FN,ACT,0.15000000596046448	CHEMBL1809238,TN,INACT,0.23000000417232513	CHEMBL111036,TN,INACT,0.0	CHEMBL279400,TN,INACT,0.0	CHEMBL263927,TP,ACT,0.9599999785423279	CHEMBL415972,TP,ACT,1.0	CHEMBL309645,TP,ACT,1.0	CHEMBL289277,FP,INACT,0.9300000071525574	CHEMBL85563,TP,ACT,1.0	CHEMBL151182,TP,ACT,0.949999988079071	CHEMBL357832,TN,INACT,0.0	CHEMBL385442,TP,ACT,0.9100000262260437	CHEMBL300030,TN,INACT,0.0	CHEMBL76883,TN,INACT,0.009999999776482582	CHEMBL116202,TN,INACT,0.0	CHEMBL3596566,TN,INACT,0.009999999776482582	CHEMBL325873,TP,ACT,1.0	CHEMBL314873,TP,ACT,0.9399999976158142	CHEMBL3398143,FN,ACT,0.05999999865889549	CHEMBL326073,TP,ACT,1.0	CHEMBL147789,TN,INACT,0.019999999552965164	CHEMBL522532,TN,INACT,0.09000000357627869	CHEMBL6845,FP,INACT,0.6499999761581421	CHEMBL432539,TP,ACT,1.0	CHEMBL1910421,TN,INACT,0.0	CHEMBL2370875,TP,ACT,0.9599999785423279	CHEMBL554824,FP,INACT,0.46000000834465027	CHEMBL2409427,TP,ACT,0.47999998927116394	CHEMBL1808485,TP,ACT,0.3199999928474426	CHEMBL3664003,TN,INACT,0.0	CHEMBL140716,TP,ACT,1.0	CHEMBL99558,FN,ACT,0.23000000417232513	CHEMBL50,TN,INACT,0.0	CHEMBL159435,TN,INACT,0.009999999776482582	CHEMBL3109170,TN,INACT,0.07000000029802322	CHEMBL487956,TN,INACT,0.0	CHEMBL2373011,TP,ACT,0.9800000190734863	CHEMBL78475,TN,INACT,0.03999999910593033	CHEMBL328307,TN,INACT,0.0	CHEMBL209022,TN,INACT,0.0	CHEMBL344940,TP,ACT,1.0	CHEMBL75972,TN,INACT,0.05000000074505806	CHEMBL298256,TN,INACT,0.009999999776482582	CHEMBL309710,FP,INACT,0.7300000190734863	CHEMBL268005,TP,ACT,0.9900000095367432	CHEMBL462253,TN,INACT,0.0	CHEMBL342914,TN,INACT,0.0	CHEMBL3663999,TN,INACT,0.0	CHEMBL88975,TP,ACT,1.0	CHEMBL3109060,TN,INACT,0.05000000074505806	CHEMBL304794,TN,INACT,0.0	CHEMBL422675,TP,ACT,0.9900000095367432	CHEMBL1834511,TN,INACT,0.0	CHEMBL3647999,TN,INACT,0.009999999776482582	CHEMBL174548,TP,ACT,0.9800000190734863	CHEMBL2182020,TN,INACT,0.07999999821186066	CHEMBL106107,TP,ACT,0.949999988079071	CHEMBL379315,TN,INACT,0.029999999329447746	CHEMBL40849,FN,ACT,0.09000000357627869	CHEMBL43457,TP,ACT,0.699999988079071	CHEMBL311124,TN,INACT,0.07000000029802322	CHEMBL2409456,TP,ACT,1.0	CHEMBL109411,TP,ACT,1.0	CHEMBL272413,TP,ACT,0.9599999785423279	CHEMBL29304,TN,INACT,0.0	CHEMBL438647,TN,INACT,0.009999999776482582	CHEMBL3398160,FN,ACT,0.20000000298023224	CHEMBL313667,TP,ACT,1.0	CHEMBL2371207,TP,ACT,1.0	CHEMBL109251,TN,INACT,0.009999999776482582	CHEMBL2409451,TP,ACT,0.6600000262260437	CHEMBL113409,TP,ACT,1.0	CHEMBL1744051,FP,INACT,0.3499999940395355	CHEMBL1835010,FN,ACT,0.0	CHEMBL354420,TP,ACT,1.0	CHEMBL306105,TP,ACT,1.0	CHEMBL1631754,TP,ACT,0.6000000238418579	CHEMBL3647982,TN,INACT,0.0	CHEMBL273486,TP,ACT,1.0	CHEMBL150384,TP,ACT,1.0	CHEMBL412582,FP,INACT,0.9800000190734863	CHEMBL14516,TP,ACT,1.0	CHEMBL96428,TN,INACT,0.0	CHEMBL3585734,TN,INACT,0.009999999776482582	CHEMBL3408410,TN,INACT,0.12999999523162842	CHEMBL273668,FN,ACT,0.25999999046325684	CHEMBL26896,TN,INACT,0.0	CHEMBL101559,TN,INACT,0.0	CHEMBL160737,TP,ACT,0.6200000047683716	CHEMBL2409434,TP,ACT,0.9200000166893005	CHEMBL3109162,TN,INACT,0.10000000149011612	CHEMBL43817,TN,INACT,0.009999999776482582	CHEMBL383257,TP,ACT,0.9800000190734863	CHEMBL153392,TP,ACT,0.6100000143051147	CHEMBL276827,TP,ACT,0.3499999940395355	CHEMBL300135,TN,INACT,0.20999999344348907	CHEMBL288700,TP,ACT,1.0	CHEMBL2338689,TN,INACT,0.0	CHEMBL2372696,FP,INACT,0.5	CHEMBL182309,TN,INACT,0.0	CHEMBL2159301,TN,INACT,0.0	CHEMBL522376,TN,INACT,0.05000000074505806	CHEMBL569280,TN,INACT,0.0	CHEMBL49258,FN,ACT,0.03999999910593033	CHEMBL43177,TP,ACT,0.46000000834465027	CHEMBL56713,TP,ACT,1.0	CHEMBL146895,TN,INACT,0.0	CHEMBL347652,TP,ACT,1.0	CHEMBL281765,TP,ACT,0.9900000095367432	CHEMBL544444,TP,ACT,0.9800000190734863	CHEMBL429694,TN,INACT,0.029999999329447746	CHEMBL355937,TP,ACT,1.0	CHEMBL429563,TP,ACT,0.9900000095367432	CHEMBL74648,FP,INACT,0.9900000095367432	CHEMBL2409432,TP,ACT,0.9200000166893005	CHEMBL9895,TP,ACT,0.8299999833106995	CHEMBL344750,TP,ACT,1.0	CHEMBL11335,TP,ACT,1.0	CHEMBL3659903,TP,ACT,0.38999998569488525	CHEMBL436383,TP,ACT,1.0	CHEMBL112880,TP,ACT,1.0	CHEMBL65148,TP,ACT,0.4099999964237213	CHEMBL3125346,FN,ACT,0.0	CHEMBL160365,TP,ACT,1.0	CHEMBL48929,TN,INACT,0.0	CHEMBL3093821,TP,ACT,0.9300000071525574	CHEMBL2159299,FP,INACT,0.5099999904632568	CHEMBL553963,TN,INACT,0.0	CHEMBL92250,TN,INACT,0.0	CHEMBL14064,TP,ACT,1.0	CHEMBL3585746,TN,INACT,0.0	CHEMBL3423000,TN,INACT,0.10999999940395355	CHEMBL137311,TN,INACT,0.05000000074505806	CHEMBL310574,FP,INACT,0.9800000190734863	CHEMBL492334,TN,INACT,0.0	CHEMBL2396792,FP,INACT,0.6800000071525574	CHEMBL2159276,TN,INACT,0.019999999552965164	CHEMBL431864,TP,ACT,0.9200000166893005	CHEMBL2159279,TN,INACT,0.019999999552965164	CHEMBL432961,TP,ACT,0.9900000095367432	CHEMBL322345,TN,INACT,0.07000000029802322	CHEMBL3423009,TN,INACT,0.009999999776482582	CHEMBL2159291,TN,INACT,0.03999999910593033	CHEMBL11334,TP,ACT,1.0	CHEMBL2373045,TN,INACT,0.25	CHEMBL11558,TP,ACT,1.0	CHEMBL356390,FN,ACT,0.23999999463558197	CHEMBL176985,TP,ACT,0.9800000190734863	CHEMBL11383,TP,ACT,1.0	CHEMBL544131,TN,INACT,0.0	CHEMBL84461,TN,INACT,0.07000000029802322	CHEMBL495010,TN,INACT,0.0	CHEMBL3398144,TP,ACT,0.3199999928474426	CHEMBL51173,TN,INACT,0.0	CHEMBL313299,TP,ACT,0.5199999809265137	CHEMBL64654,TN,INACT,0.0	CHEMBL3251188,TN,INACT,0.0	CHEMBL344981,TP,ACT,0.6499999761581421	CHEMBL494632,TN,INACT,0.07000000029802322	CHEMBL1172305,TP,ACT,0.8899999856948853	CHEMBL3109168,TN,INACT,0.2199999988079071	CHEMBL2448389,TN,INACT,0.0	CHEMBL339880,TN,INACT,0.0	CHEMBL131107,TP,ACT,1.0	CHEMBL566475,FN,ACT,0.11999999731779099	CHEMBL554013,TP,ACT,0.5099999904632568	CHEMBL76445,TP,ACT,0.7599999904632568	CHEMBL3799329,TN,INACT,0.009999999776482582	CHEMBL107966,TP,ACT,1.0	CHEMBL96376,TN,INACT,0.05999999865889549	CHEMBL333098,TN,INACT,0.009999999776482582	CHEMBL83205,TN,INACT,0.0	CHEMBL318177,FP,INACT,0.6600000262260437	CHEMBL10342,TP,ACT,0.9900000095367432	CHEMBL10625,TP,ACT,0.7200000286102295	CHEMBL1808479,TN,INACT,0.1599999964237213	CHEMBL277905,TP,ACT,0.7599999904632568	CHEMBL2087345,TN,INACT,0.27000001072883606	CHEMBL324953,TN,INACT,0.03999999910593033	CHEMBL304354,TP,ACT,1.0	CHEMBL385899,TN,INACT,0.10000000149011612	CHEMBL3287842,TN,INACT,0.07000000029802322	CHEMBL59258,TP,ACT,1.0	CHEMBL239536,TN,INACT,0.03999999910593033	CHEMBL109050,TN,INACT,0.0	CHEMBL319035,FP,INACT,0.6000000238418579	CHEMBL295786,FP,INACT,0.9200000166893005	CHEMBL107656,TP,ACT,0.9900000095367432	CHEMBL341909,TN,INACT,0.23999999463558197	CHEMBL544130,TN,INACT,0.0	CHEMBL41525,TN,INACT,0.0	CHEMBL378083,TN,INACT,0.029999999329447746	CHEMBL3084830,FP,INACT,0.36000001430511475	CHEMBL238707,TN,INACT,0.1899999976158142	CHEMBL1808520,FN,ACT,0.1599999964237213	CHEMBL389383,TP,ACT,0.3499999940395355	CHEMBL300557,TP,ACT,1.0	

