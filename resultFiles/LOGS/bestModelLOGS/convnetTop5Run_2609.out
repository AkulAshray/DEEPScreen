CNNModel CHEMBL3181 adam 0.001 30 128 0 0.6 False True
Number of active compounds :	238
Number of inactive compounds :	159
---------------------------------
Run id: CNNModel_CHEMBL3181_adam_0.001_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3181_adam_0.001_30_128_0.6_True/
---------------------------------
Training samples: 253
Validation samples: 80
--
Training Step: 1  | time: 1.341s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/253
[A[ATraining Step: 2  | total loss: [1m[32m0.62412[0m[0m | time: 2.366s
[2K
| Adam | epoch: 001 | loss: 0.62412 - acc: 0.3937 -- iter: 064/253
[A[ATraining Step: 3  | total loss: [1m[32m0.67529[0m[0m | time: 3.485s
[2K
| Adam | epoch: 001 | loss: 0.67529 - acc: 0.5830 -- iter: 096/253
[A[ATraining Step: 4  | total loss: [1m[32m0.66105[0m[0m | time: 4.583s
[2K
| Adam | epoch: 001 | loss: 0.66105 - acc: 0.6379 -- iter: 128/253
[A[ATraining Step: 5  | total loss: [1m[32m0.78977[0m[0m | time: 5.644s
[2K
| Adam | epoch: 001 | loss: 0.78977 - acc: 0.4992 -- iter: 160/253
[A[ATraining Step: 6  | total loss: [1m[32m0.72450[0m[0m | time: 6.866s
[2K
| Adam | epoch: 001 | loss: 0.72450 - acc: 0.5399 -- iter: 192/253
[A[ATraining Step: 7  | total loss: [1m[32m0.69598[0m[0m | time: 8.099s
[2K
| Adam | epoch: 001 | loss: 0.69598 - acc: 0.5722 -- iter: 224/253
[A[ATraining Step: 8  | total loss: [1m[32m0.68163[0m[0m | time: 10.351s
[2K
| Adam | epoch: 001 | loss: 0.68163 - acc: 0.6371 | val_loss: 0.68495 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 9  | total loss: [1m[32m0.68053[0m[0m | time: 0.803s
[2K
| Adam | epoch: 002 | loss: 0.68053 - acc: 0.6466 -- iter: 032/253
[A[ATraining Step: 10  | total loss: [1m[32m0.68103[0m[0m | time: 1.777s
[2K
| Adam | epoch: 002 | loss: 0.68103 - acc: 0.6509 -- iter: 064/253
[A[ATraining Step: 11  | total loss: [1m[32m0.68160[0m[0m | time: 2.752s
[2K
| Adam | epoch: 002 | loss: 0.68160 - acc: 0.6534 -- iter: 096/253
[A[ATraining Step: 12  | total loss: [1m[32m0.68486[0m[0m | time: 3.737s
[2K
| Adam | epoch: 002 | loss: 0.68486 - acc: 0.6125 -- iter: 128/253
[A[ATraining Step: 13  | total loss: [1m[32m0.68454[0m[0m | time: 4.671s
[2K
| Adam | epoch: 002 | loss: 0.68454 - acc: 0.6179 -- iter: 160/253
[A[ATraining Step: 14  | total loss: [1m[32m0.68648[0m[0m | time: 5.700s
[2K
| Adam | epoch: 002 | loss: 0.68648 - acc: 0.5952 -- iter: 192/253
[A[ATraining Step: 15  | total loss: [1m[32m0.68534[0m[0m | time: 6.800s
[2K
| Adam | epoch: 002 | loss: 0.68534 - acc: 0.6069 -- iter: 224/253
[A[ATraining Step: 16  | total loss: [1m[32m0.68498[0m[0m | time: 8.883s
[2K
| Adam | epoch: 002 | loss: 0.68498 - acc: 0.6020 | val_loss: 0.68132 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 17  | total loss: [1m[32m0.68597[0m[0m | time: 1.104s
[2K
| Adam | epoch: 003 | loss: 0.68597 - acc: 0.5877 -- iter: 032/253
[A[ATraining Step: 18  | total loss: [1m[32m0.68556[0m[0m | time: 2.142s
[2K
| Adam | epoch: 003 | loss: 0.68556 - acc: 0.5872 -- iter: 064/253
[A[ATraining Step: 19  | total loss: [1m[32m0.68524[0m[0m | time: 2.955s
[2K
| Adam | epoch: 003 | loss: 0.68524 - acc: 0.5869 -- iter: 096/253
[A[ATraining Step: 20  | total loss: [1m[32m0.68362[0m[0m | time: 3.917s
[2K
| Adam | epoch: 003 | loss: 0.68362 - acc: 0.5891 -- iter: 128/253
[A[ATraining Step: 21  | total loss: [1m[32m0.67865[0m[0m | time: 4.893s
[2K
| Adam | epoch: 003 | loss: 0.67865 - acc: 0.6099 -- iter: 160/253
[A[ATraining Step: 22  | total loss: [1m[32m0.67208[0m[0m | time: 5.939s
[2K
| Adam | epoch: 003 | loss: 0.67208 - acc: 0.6332 -- iter: 192/253
[A[ATraining Step: 23  | total loss: [1m[32m0.66828[0m[0m | time: 7.003s
[2K
| Adam | epoch: 003 | loss: 0.66828 - acc: 0.6399 -- iter: 224/253
[A[ATraining Step: 24  | total loss: [1m[32m0.67799[0m[0m | time: 9.016s
[2K
| Adam | epoch: 003 | loss: 0.67799 - acc: 0.6093 | val_loss: 0.66771 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 25  | total loss: [1m[32m0.67730[0m[0m | time: 1.018s
[2K
| Adam | epoch: 004 | loss: 0.67730 - acc: 0.6051 -- iter: 032/253
[A[ATraining Step: 26  | total loss: [1m[32m0.68516[0m[0m | time: 2.072s
[2K
| Adam | epoch: 004 | loss: 0.68516 - acc: 0.5855 -- iter: 064/253
[A[ATraining Step: 27  | total loss: [1m[32m0.68315[0m[0m | time: 3.211s
[2K
| Adam | epoch: 004 | loss: 0.68315 - acc: 0.5857 -- iter: 096/253
[A[ATraining Step: 28  | total loss: [1m[32m0.68168[0m[0m | time: 4.250s
[2K
| Adam | epoch: 004 | loss: 0.68168 - acc: 0.5858 -- iter: 128/253
[A[ATraining Step: 29  | total loss: [1m[32m0.68517[0m[0m | time: 5.124s
[2K
| Adam | epoch: 004 | loss: 0.68517 - acc: 0.5726 -- iter: 160/253
[A[ATraining Step: 30  | total loss: [1m[32m0.67550[0m[0m | time: 6.071s
[2K
| Adam | epoch: 004 | loss: 0.67550 - acc: 0.5998 -- iter: 192/253
[A[ATraining Step: 31  | total loss: [1m[32m0.67839[0m[0m | time: 7.035s
[2K
| Adam | epoch: 004 | loss: 0.67839 - acc: 0.5912 -- iter: 224/253
[A[ATraining Step: 32  | total loss: [1m[32m0.66906[0m[0m | time: 9.054s
[2K
| Adam | epoch: 004 | loss: 0.66906 - acc: 0.6199 | val_loss: 0.66973 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 33  | total loss: [1m[32m0.68468[0m[0m | time: 1.039s
[2K
| Adam | epoch: 005 | loss: 0.68468 - acc: 0.5730 -- iter: 032/253
[A[ATraining Step: 34  | total loss: [1m[32m0.67040[0m[0m | time: 2.084s
[2K
| Adam | epoch: 005 | loss: 0.67040 - acc: 0.6176 -- iter: 064/253
[A[ATraining Step: 35  | total loss: [1m[32m0.67341[0m[0m | time: 3.047s
[2K
| Adam | epoch: 005 | loss: 0.67341 - acc: 0.6061 -- iter: 096/253
[A[ATraining Step: 36  | total loss: [1m[32m0.66657[0m[0m | time: 4.072s
[2K
| Adam | epoch: 005 | loss: 0.66657 - acc: 0.6232 -- iter: 128/253
[A[ATraining Step: 37  | total loss: [1m[32m0.66036[0m[0m | time: 5.214s
[2K
| Adam | epoch: 005 | loss: 0.66036 - acc: 0.6365 -- iter: 160/253
[A[ATraining Step: 38  | total loss: [1m[32m0.66967[0m[0m | time: 6.330s
[2K
| Adam | epoch: 005 | loss: 0.66967 - acc: 0.6159 -- iter: 192/253
[A[ATraining Step: 39  | total loss: [1m[32m0.67457[0m[0m | time: 7.228s
[2K
| Adam | epoch: 005 | loss: 0.67457 - acc: 0.6057 -- iter: 224/253
[A[ATraining Step: 40  | total loss: [1m[32m0.66402[0m[0m | time: 9.198s
[2K
| Adam | epoch: 005 | loss: 0.66402 - acc: 0.6269 | val_loss: 0.66891 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 41  | total loss: [1m[32m0.66370[0m[0m | time: 1.078s
[2K
| Adam | epoch: 006 | loss: 0.66370 - acc: 0.6265 -- iter: 032/253
[A[ATraining Step: 42  | total loss: [1m[32m0.67581[0m[0m | time: 2.188s
[2K
| Adam | epoch: 006 | loss: 0.67581 - acc: 0.6037 -- iter: 064/253
[A[ATraining Step: 43  | total loss: [1m[32m0.68177[0m[0m | time: 3.251s
[2K
| Adam | epoch: 006 | loss: 0.68177 - acc: 0.5910 -- iter: 096/253
[A[ATraining Step: 44  | total loss: [1m[32m0.68101[0m[0m | time: 4.167s
[2K
| Adam | epoch: 006 | loss: 0.68101 - acc: 0.5914 -- iter: 128/253
[A[ATraining Step: 45  | total loss: [1m[32m0.67594[0m[0m | time: 5.099s
[2K
| Adam | epoch: 006 | loss: 0.67594 - acc: 0.6023 -- iter: 160/253
[A[ATraining Step: 46  | total loss: [1m[32m0.67248[0m[0m | time: 6.244s
[2K
| Adam | epoch: 006 | loss: 0.67248 - acc: 0.6111 -- iter: 192/253
[A[ATraining Step: 47  | total loss: [1m[32m0.67138[0m[0m | time: 7.295s
[2K
| Adam | epoch: 006 | loss: 0.67138 - acc: 0.6134 -- iter: 224/253
[A[ATraining Step: 48  | total loss: [1m[32m0.67376[0m[0m | time: 9.356s
[2K
| Adam | epoch: 006 | loss: 0.67376 - acc: 0.6052 | val_loss: 0.67072 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 49  | total loss: [1m[32m0.68363[0m[0m | time: 1.018s
[2K
| Adam | epoch: 007 | loss: 0.68363 - acc: 0.5738 -- iter: 032/253
[A[ATraining Step: 50  | total loss: [1m[32m0.68385[0m[0m | time: 2.015s
[2K
| Adam | epoch: 007 | loss: 0.68385 - acc: 0.5720 -- iter: 064/253
[A[ATraining Step: 51  | total loss: [1m[32m0.68165[0m[0m | time: 2.969s
[2K
| Adam | epoch: 007 | loss: 0.68165 - acc: 0.5801 -- iter: 096/253
[A[ATraining Step: 52  | total loss: [1m[32m0.67974[0m[0m | time: 3.924s
[2K
| Adam | epoch: 007 | loss: 0.67974 - acc: 0.5868 -- iter: 128/253
[A[ATraining Step: 53  | total loss: [1m[32m0.67846[0m[0m | time: 4.892s
[2K
| Adam | epoch: 007 | loss: 0.67846 - acc: 0.5925 -- iter: 160/253
[A[ATraining Step: 54  | total loss: [1m[32m0.67384[0m[0m | time: 5.916s
[2K
| Adam | epoch: 007 | loss: 0.67384 - acc: 0.6116 -- iter: 192/253
[A[ATraining Step: 55  | total loss: [1m[32m0.66965[0m[0m | time: 6.938s
[2K
| Adam | epoch: 007 | loss: 0.66965 - acc: 0.6277 -- iter: 224/253
[A[ATraining Step: 56  | total loss: [1m[32m0.67051[0m[0m | time: 8.928s
[2K
| Adam | epoch: 007 | loss: 0.67051 - acc: 0.6229 | val_loss: 0.66970 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 57  | total loss: [1m[32m0.66889[0m[0m | time: 0.909s
[2K
| Adam | epoch: 008 | loss: 0.66889 - acc: 0.6275 -- iter: 032/253
[A[ATraining Step: 58  | total loss: [1m[32m0.67108[0m[0m | time: 1.952s
[2K
| Adam | epoch: 008 | loss: 0.67108 - acc: 0.6186 -- iter: 064/253
[A[ATraining Step: 59  | total loss: [1m[32m0.67435[0m[0m | time: 2.982s
[2K
| Adam | epoch: 008 | loss: 0.67435 - acc: 0.6069 -- iter: 096/253
[A[ATraining Step: 60  | total loss: [1m[32m0.66676[0m[0m | time: 3.967s
[2K
| Adam | epoch: 008 | loss: 0.66676 - acc: 0.6258 -- iter: 128/253
[A[ATraining Step: 61  | total loss: [1m[32m0.66934[0m[0m | time: 5.074s
[2K
| Adam | epoch: 008 | loss: 0.66934 - acc: 0.6176 -- iter: 160/253
[A[ATraining Step: 62  | total loss: [1m[32m0.68091[0m[0m | time: 6.031s
[2K
| Adam | epoch: 008 | loss: 0.68091 - acc: 0.5904 -- iter: 192/253
[A[ATraining Step: 63  | total loss: [1m[32m0.67694[0m[0m | time: 6.999s
[2K
| Adam | epoch: 008 | loss: 0.67694 - acc: 0.5986 -- iter: 224/253
[A[ATraining Step: 64  | total loss: [1m[32m0.67330[0m[0m | time: 9.025s
[2K
| Adam | epoch: 008 | loss: 0.67330 - acc: 0.6057 | val_loss: 0.66676 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 65  | total loss: [1m[32m0.67211[0m[0m | time: 1.032s
[2K
| Adam | epoch: 009 | loss: 0.67211 - acc: 0.6081 -- iter: 032/253
[A[ATraining Step: 66  | total loss: [1m[32m0.66571[0m[0m | time: 1.908s
[2K
| Adam | epoch: 009 | loss: 0.66571 - acc: 0.6215 -- iter: 064/253
[A[ATraining Step: 67  | total loss: [1m[32m0.67254[0m[0m | time: 2.885s
[2K
| Adam | epoch: 009 | loss: 0.67254 - acc: 0.6069 -- iter: 096/253
[A[ATraining Step: 68  | total loss: [1m[32m0.67299[0m[0m | time: 3.897s
[2K
| Adam | epoch: 009 | loss: 0.67299 - acc: 0.6054 -- iter: 128/253
[A[ATraining Step: 69  | total loss: [1m[32m0.67350[0m[0m | time: 4.959s
[2K
| Adam | epoch: 009 | loss: 0.67350 - acc: 0.6040 -- iter: 160/253
[A[ATraining Step: 70  | total loss: [1m[32m0.67472[0m[0m | time: 5.956s
[2K
| Adam | epoch: 009 | loss: 0.67472 - acc: 0.5992 -- iter: 192/253
[A[ATraining Step: 71  | total loss: [1m[32m0.66993[0m[0m | time: 6.936s
[2K
| Adam | epoch: 009 | loss: 0.66993 - acc: 0.6093 -- iter: 224/253
[A[ATraining Step: 72  | total loss: [1m[32m0.66563[0m[0m | time: 8.931s
[2K
| Adam | epoch: 009 | loss: 0.66563 - acc: 0.6183 | val_loss: 0.66667 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 73  | total loss: [1m[32m0.66155[0m[0m | time: 1.155s
[2K
| Adam | epoch: 010 | loss: 0.66155 - acc: 0.6263 -- iter: 032/253
[A[ATraining Step: 74  | total loss: [1m[32m0.66842[0m[0m | time: 2.213s
[2K
| Adam | epoch: 010 | loss: 0.66842 - acc: 0.6124 -- iter: 064/253
[A[ATraining Step: 75  | total loss: [1m[32m0.66372[0m[0m | time: 3.422s
[2K
| Adam | epoch: 010 | loss: 0.66372 - acc: 0.6205 -- iter: 096/253
[A[ATraining Step: 76  | total loss: [1m[32m0.66743[0m[0m | time: 4.449s
[2K
| Adam | epoch: 010 | loss: 0.66743 - acc: 0.6143 -- iter: 128/253
[A[ATraining Step: 77  | total loss: [1m[32m0.67168[0m[0m | time: 5.718s
[2K
| Adam | epoch: 010 | loss: 0.67168 - acc: 0.6055 -- iter: 160/253
[A[ATraining Step: 78  | total loss: [1m[32m0.67325[0m[0m | time: 6.891s
[2K
| Adam | epoch: 010 | loss: 0.67325 - acc: 0.6010 -- iter: 192/253
[A[ATraining Step: 79  | total loss: [1m[32m0.66906[0m[0m | time: 8.050s
[2K
| Adam | epoch: 010 | loss: 0.66906 - acc: 0.6100 -- iter: 224/253
[A[ATraining Step: 80  | total loss: [1m[32m0.67204[0m[0m | time: 10.121s
[2K
| Adam | epoch: 010 | loss: 0.67204 - acc: 0.6019 | val_loss: 0.66655 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 81  | total loss: [1m[32m0.66801[0m[0m | time: 0.906s
[2K
| Adam | epoch: 011 | loss: 0.66801 - acc: 0.6108 -- iter: 032/253
[A[ATraining Step: 82  | total loss: [1m[32m0.66451[0m[0m | time: 2.038s
[2K
| Adam | epoch: 011 | loss: 0.66451 - acc: 0.6187 -- iter: 064/253
[A[ATraining Step: 83  | total loss: [1m[32m0.66396[0m[0m | time: 3.159s
[2K
| Adam | epoch: 011 | loss: 0.66396 - acc: 0.6193 -- iter: 096/253
[A[ATraining Step: 84  | total loss: [1m[32m0.66354[0m[0m | time: 4.119s
[2K
| Adam | epoch: 011 | loss: 0.66354 - acc: 0.6199 -- iter: 128/253
[A[ATraining Step: 85  | total loss: [1m[32m0.66444[0m[0m | time: 4.990s
[2K
| Adam | epoch: 011 | loss: 0.66444 - acc: 0.6173 -- iter: 160/253
[A[ATraining Step: 86  | total loss: [1m[32m0.66199[0m[0m | time: 5.972s
[2K
| Adam | epoch: 011 | loss: 0.66199 - acc: 0.6212 -- iter: 192/253
[A[ATraining Step: 87  | total loss: [1m[32m0.66019[0m[0m | time: 6.956s
[2K
| Adam | epoch: 011 | loss: 0.66019 - acc: 0.6247 -- iter: 224/253
[A[ATraining Step: 88  | total loss: [1m[32m0.66536[0m[0m | time: 8.896s
[2K
| Adam | epoch: 011 | loss: 0.66536 - acc: 0.6153 | val_loss: 0.66423 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 89  | total loss: [1m[32m0.67205[0m[0m | time: 1.105s
[2K
| Adam | epoch: 012 | loss: 0.67205 - acc: 0.6038 -- iter: 032/253
[A[ATraining Step: 90  | total loss: [1m[32m0.67086[0m[0m | time: 2.022s
[2K
| Adam | epoch: 012 | loss: 0.67086 - acc: 0.6055 -- iter: 064/253
[A[ATraining Step: 91  | total loss: [1m[32m0.67007[0m[0m | time: 3.130s
[2K
| Adam | epoch: 012 | loss: 0.67007 - acc: 0.6070 -- iter: 096/253
[A[ATraining Step: 92  | total loss: [1m[32m0.66763[0m[0m | time: 4.268s
[2K
| Adam | epoch: 012 | loss: 0.66763 - acc: 0.6119 -- iter: 128/253
[A[ATraining Step: 93  | total loss: [1m[32m0.66810[0m[0m | time: 5.369s
[2K
| Adam | epoch: 012 | loss: 0.66810 - acc: 0.6101 -- iter: 160/253
[A[ATraining Step: 94  | total loss: [1m[32m0.67063[0m[0m | time: 6.320s
[2K
| Adam | epoch: 012 | loss: 0.67063 - acc: 0.6022 -- iter: 192/253
[A[ATraining Step: 95  | total loss: [1m[32m0.66855[0m[0m | time: 7.232s
[2K
| Adam | epoch: 012 | loss: 0.66855 - acc: 0.6076 -- iter: 224/253
[A[ATraining Step: 96  | total loss: [1m[32m0.67274[0m[0m | time: 9.284s
[2K
| Adam | epoch: 012 | loss: 0.67274 - acc: 0.5937 | val_loss: 0.66617 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 97  | total loss: [1m[32m0.67145[0m[0m | time: 1.030s
[2K
| Adam | epoch: 013 | loss: 0.67145 - acc: 0.5969 -- iter: 032/253
[A[ATraining Step: 98  | total loss: [1m[32m0.67137[0m[0m | time: 2.053s
[2K
| Adam | epoch: 013 | loss: 0.67137 - acc: 0.5966 -- iter: 064/253
[A[ATraining Step: 99  | total loss: [1m[32m0.66724[0m[0m | time: 2.999s
[2K
| Adam | epoch: 013 | loss: 0.66724 - acc: 0.6093 -- iter: 096/253
[A[ATraining Step: 100  | total loss: [1m[32m0.66291[0m[0m | time: 3.964s
[2K
| Adam | epoch: 013 | loss: 0.66291 - acc: 0.6208 -- iter: 128/253
[A[ATraining Step: 101  | total loss: [1m[32m0.66448[0m[0m | time: 4.980s
[2K
| Adam | epoch: 013 | loss: 0.66448 - acc: 0.6150 -- iter: 160/253
[A[ATraining Step: 102  | total loss: [1m[32m0.66229[0m[0m | time: 6.054s
[2K
| Adam | epoch: 013 | loss: 0.66229 - acc: 0.6191 -- iter: 192/253
[A[ATraining Step: 103  | total loss: [1m[32m0.66329[0m[0m | time: 7.189s
[2K
| Adam | epoch: 013 | loss: 0.66329 - acc: 0.6166 -- iter: 224/253
[A[ATraining Step: 104  | total loss: [1m[32m0.66240[0m[0m | time: 9.102s
[2K
| Adam | epoch: 013 | loss: 0.66240 - acc: 0.6174 | val_loss: 0.66235 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 105  | total loss: [1m[32m0.66092[0m[0m | time: 0.980s
[2K
| Adam | epoch: 014 | loss: 0.66092 - acc: 0.6182 -- iter: 032/253
[A[ATraining Step: 106  | total loss: [1m[32m0.65624[0m[0m | time: 2.003s
[2K
| Adam | epoch: 014 | loss: 0.65624 - acc: 0.6251 -- iter: 064/253
[A[ATraining Step: 107  | total loss: [1m[32m0.66163[0m[0m | time: 3.063s
[2K
| Adam | epoch: 014 | loss: 0.66163 - acc: 0.6157 -- iter: 096/253
[A[ATraining Step: 108  | total loss: [1m[32m0.66044[0m[0m | time: 4.092s
[2K
| Adam | epoch: 014 | loss: 0.66044 - acc: 0.6162 -- iter: 128/253
[A[ATraining Step: 109  | total loss: [1m[32m0.65919[0m[0m | time: 5.106s
[2K
| Adam | epoch: 014 | loss: 0.65919 - acc: 0.6167 -- iter: 160/253
[A[ATraining Step: 110  | total loss: [1m[32m0.66476[0m[0m | time: 6.084s
[2K
| Adam | epoch: 014 | loss: 0.66476 - acc: 0.6019 -- iter: 192/253
[A[ATraining Step: 111  | total loss: [1m[32m0.66179[0m[0m | time: 7.196s
[2K
| Adam | epoch: 014 | loss: 0.66179 - acc: 0.6073 -- iter: 224/253
[A[ATraining Step: 112  | total loss: [1m[32m0.66525[0m[0m | time: 9.425s
[2K
| Adam | epoch: 014 | loss: 0.66525 - acc: 0.5966 | val_loss: 0.66120 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 113  | total loss: [1m[32m0.66612[0m[0m | time: 0.985s
[2K
| Adam | epoch: 015 | loss: 0.66612 - acc: 0.5932 -- iter: 032/253
[A[ATraining Step: 114  | total loss: [1m[32m0.66792[0m[0m | time: 1.997s
[2K
| Adam | epoch: 015 | loss: 0.66792 - acc: 0.5839 -- iter: 064/253
[A[ATraining Step: 115  | total loss: [1m[32m0.66920[0m[0m | time: 2.997s
[2K
| Adam | epoch: 015 | loss: 0.66920 - acc: 0.5786 -- iter: 096/253
[A[ATraining Step: 116  | total loss: [1m[32m0.66601[0m[0m | time: 3.941s
[2K
| Adam | epoch: 015 | loss: 0.66601 - acc: 0.5926 -- iter: 128/253
[A[ATraining Step: 117  | total loss: [1m[32m0.66178[0m[0m | time: 4.999s
[2K
| Adam | epoch: 015 | loss: 0.66178 - acc: 0.6023 -- iter: 160/253
[A[ATraining Step: 118  | total loss: [1m[32m0.65576[0m[0m | time: 6.010s
[2K
| Adam | epoch: 015 | loss: 0.65576 - acc: 0.6110 -- iter: 192/253
[A[ATraining Step: 119  | total loss: [1m[32m0.64532[0m[0m | time: 7.088s
[2K
| Adam | epoch: 015 | loss: 0.64532 - acc: 0.6249 -- iter: 224/253
[A[ATraining Step: 120  | total loss: [1m[32m0.65220[0m[0m | time: 9.098s
[2K
| Adam | epoch: 015 | loss: 0.65220 - acc: 0.6187 | val_loss: 0.65045 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 121  | total loss: [1m[32m0.65778[0m[0m | time: 1.001s
[2K
| Adam | epoch: 016 | loss: 0.65778 - acc: 0.6162 -- iter: 032/253
[A[ATraining Step: 122  | total loss: [1m[32m0.66072[0m[0m | time: 1.996s
[2K
| Adam | epoch: 016 | loss: 0.66072 - acc: 0.6108 -- iter: 064/253
[A[ATraining Step: 123  | total loss: [1m[32m0.65667[0m[0m | time: 2.985s
[2K
| Adam | epoch: 016 | loss: 0.65667 - acc: 0.6122 -- iter: 096/253
[A[ATraining Step: 124  | total loss: [1m[32m0.65627[0m[0m | time: 4.087s
[2K
| Adam | epoch: 016 | loss: 0.65627 - acc: 0.6073 -- iter: 128/253
[A[ATraining Step: 125  | total loss: [1m[32m0.65687[0m[0m | time: 5.043s
[2K
| Adam | epoch: 016 | loss: 0.65687 - acc: 0.5934 -- iter: 160/253
[A[ATraining Step: 126  | total loss: [1m[32m0.65813[0m[0m | time: 5.965s
[2K
| Adam | epoch: 016 | loss: 0.65813 - acc: 0.6065 -- iter: 192/253
[A[ATraining Step: 127  | total loss: [1m[32m0.65836[0m[0m | time: 7.030s
[2K
| Adam | epoch: 016 | loss: 0.65836 - acc: 0.6217 -- iter: 224/253
[A[ATraining Step: 128  | total loss: [1m[32m0.65623[0m[0m | time: 9.031s
[2K
| Adam | epoch: 016 | loss: 0.65623 - acc: 0.6189 | val_loss: 0.63490 - val_acc: 0.6125 -- iter: 253/253
--
Training Step: 129  | total loss: [1m[32m0.64509[0m[0m | time: 0.940s
[2K
| Adam | epoch: 017 | loss: 0.64509 - acc: 0.6414 -- iter: 032/253
[A[ATraining Step: 130  | total loss: [1m[32m0.65246[0m[0m | time: 1.945s
[2K
| Adam | epoch: 017 | loss: 0.65246 - acc: 0.6241 -- iter: 064/253
[A[ATraining Step: 131  | total loss: [1m[32m0.64282[0m[0m | time: 2.943s
[2K
| Adam | epoch: 017 | loss: 0.64282 - acc: 0.6305 -- iter: 096/253
[A[ATraining Step: 132  | total loss: [1m[32m0.64373[0m[0m | time: 3.960s
[2K
| Adam | epoch: 017 | loss: 0.64373 - acc: 0.6237 -- iter: 128/253
[A[ATraining Step: 133  | total loss: [1m[32m0.63464[0m[0m | time: 5.000s
[2K
| Adam | epoch: 017 | loss: 0.63464 - acc: 0.6301 -- iter: 160/253
[A[ATraining Step: 134  | total loss: [1m[32m0.63467[0m[0m | time: 5.985s
[2K
| Adam | epoch: 017 | loss: 0.63467 - acc: 0.6327 -- iter: 192/253
[A[ATraining Step: 135  | total loss: [1m[32m0.62432[0m[0m | time: 6.986s
[2K
| Adam | epoch: 017 | loss: 0.62432 - acc: 0.6418 -- iter: 224/253
[A[ATraining Step: 136  | total loss: [1m[32m0.61378[0m[0m | time: 9.007s
[2K
| Adam | epoch: 017 | loss: 0.61378 - acc: 0.6535 | val_loss: 0.59307 - val_acc: 0.6500 -- iter: 253/253
--
Training Step: 137  | total loss: [1m[32m0.61340[0m[0m | time: 1.070s
[2K
| Adam | epoch: 018 | loss: 0.61340 - acc: 0.6538 -- iter: 032/253
[A[ATraining Step: 138  | total loss: [1m[32m0.60697[0m[0m | time: 1.910s
[2K
| Adam | epoch: 018 | loss: 0.60697 - acc: 0.6634 -- iter: 064/253
[A[ATraining Step: 139  | total loss: [1m[32m0.61378[0m[0m | time: 2.935s
[2K
| Adam | epoch: 018 | loss: 0.61378 - acc: 0.6564 -- iter: 096/253
[A[ATraining Step: 140  | total loss: [1m[32m0.62730[0m[0m | time: 3.921s
[2K
| Adam | epoch: 018 | loss: 0.62730 - acc: 0.6377 -- iter: 128/253
[A[ATraining Step: 141  | total loss: [1m[32m0.62830[0m[0m | time: 5.008s
[2K
| Adam | epoch: 018 | loss: 0.62830 - acc: 0.6364 -- iter: 160/253
[A[ATraining Step: 142  | total loss: [1m[32m0.62427[0m[0m | time: 6.026s
[2K
| Adam | epoch: 018 | loss: 0.62427 - acc: 0.6353 -- iter: 192/253
[A[ATraining Step: 143  | total loss: [1m[32m0.61765[0m[0m | time: 6.991s
[2K
| Adam | epoch: 018 | loss: 0.61765 - acc: 0.6374 -- iter: 224/253
[A[ATraining Step: 144  | total loss: [1m[32m0.59522[0m[0m | time: 8.955s
[2K
| Adam | epoch: 018 | loss: 0.59522 - acc: 0.6495 | val_loss: 0.60681 - val_acc: 0.6250 -- iter: 253/253
--
Training Step: 145  | total loss: [1m[32m0.57442[0m[0m | time: 1.247s
[2K
| Adam | epoch: 019 | loss: 0.57442 - acc: 0.6604 -- iter: 032/253
[A[ATraining Step: 146  | total loss: [1m[32m0.57159[0m[0m | time: 2.263s
[2K
| Adam | epoch: 019 | loss: 0.57159 - acc: 0.6631 -- iter: 064/253
[A[ATraining Step: 147  | total loss: [1m[32m0.56096[0m[0m | time: 3.095s
[2K
| Adam | epoch: 019 | loss: 0.56096 - acc: 0.6718 -- iter: 096/253
[A[ATraining Step: 148  | total loss: [1m[32m0.55465[0m[0m | time: 4.006s
[2K
| Adam | epoch: 019 | loss: 0.55465 - acc: 0.6859 -- iter: 128/253
[A[ATraining Step: 149  | total loss: [1m[32m0.55198[0m[0m | time: 5.028s
[2K
| Adam | epoch: 019 | loss: 0.55198 - acc: 0.6923 -- iter: 160/253
[A[ATraining Step: 150  | total loss: [1m[32m0.54725[0m[0m | time: 6.029s
[2K
| Adam | epoch: 019 | loss: 0.54725 - acc: 0.6981 -- iter: 192/253
[A[ATraining Step: 151  | total loss: [1m[32m0.54998[0m[0m | time: 7.026s
[2K
| Adam | epoch: 019 | loss: 0.54998 - acc: 0.6970 -- iter: 224/253
[A[ATraining Step: 152  | total loss: [1m[32m0.53345[0m[0m | time: 9.018s
[2K
| Adam | epoch: 019 | loss: 0.53345 - acc: 0.7117 | val_loss: 0.54271 - val_acc: 0.7125 -- iter: 253/253
--
Training Step: 153  | total loss: [1m[32m0.53120[0m[0m | time: 1.001s
[2K
| Adam | epoch: 020 | loss: 0.53120 - acc: 0.7198 -- iter: 032/253
[A[ATraining Step: 154  | total loss: [1m[32m0.51359[0m[0m | time: 2.162s
[2K
| Adam | epoch: 020 | loss: 0.51359 - acc: 0.7340 -- iter: 064/253
[A[ATraining Step: 155  | total loss: [1m[32m0.50968[0m[0m | time: 3.082s
[2K
| Adam | epoch: 020 | loss: 0.50968 - acc: 0.7356 -- iter: 096/253
[A[ATraining Step: 156  | total loss: [1m[32m0.50536[0m[0m | time: 4.025s
[2K
| Adam | epoch: 020 | loss: 0.50536 - acc: 0.7371 -- iter: 128/253
[A[ATraining Step: 157  | total loss: [1m[32m0.51955[0m[0m | time: 5.020s
[2K
| Adam | epoch: 020 | loss: 0.51955 - acc: 0.7384 -- iter: 160/253
[A[ATraining Step: 158  | total loss: [1m[32m0.51999[0m[0m | time: 5.988s
[2K
| Adam | epoch: 020 | loss: 0.51999 - acc: 0.7395 -- iter: 192/253
[A[ATraining Step: 159  | total loss: [1m[32m0.50921[0m[0m | time: 6.963s
[2K
| Adam | epoch: 020 | loss: 0.50921 - acc: 0.7437 -- iter: 224/253
[A[ATraining Step: 160  | total loss: [1m[32m0.50233[0m[0m | time: 8.917s
[2K
| Adam | epoch: 020 | loss: 0.50233 - acc: 0.7537 | val_loss: 0.56438 - val_acc: 0.6500 -- iter: 253/253
--
Training Step: 161  | total loss: [1m[32m0.49533[0m[0m | time: 0.871s
[2K
| Adam | epoch: 021 | loss: 0.49533 - acc: 0.7658 -- iter: 032/253
[A[ATraining Step: 162  | total loss: [1m[32m0.49539[0m[0m | time: 1.956s
[2K
| Adam | epoch: 021 | loss: 0.49539 - acc: 0.7651 -- iter: 064/253
[A[ATraining Step: 163  | total loss: [1m[32m0.48719[0m[0m | time: 3.103s
[2K
| Adam | epoch: 021 | loss: 0.48719 - acc: 0.7714 -- iter: 096/253
[A[ATraining Step: 164  | total loss: [1m[32m0.46827[0m[0m | time: 4.225s
[2K
| Adam | epoch: 021 | loss: 0.46827 - acc: 0.7786 -- iter: 128/253
[A[ATraining Step: 165  | total loss: [1m[32m0.45762[0m[0m | time: 5.126s
[2K
| Adam | epoch: 021 | loss: 0.45762 - acc: 0.7820 -- iter: 160/253
[A[ATraining Step: 166  | total loss: [1m[32m0.50081[0m[0m | time: 6.011s
[2K
| Adam | epoch: 021 | loss: 0.50081 - acc: 0.7757 -- iter: 192/253
[A[ATraining Step: 167  | total loss: [1m[32m0.48070[0m[0m | time: 7.049s
[2K
| Adam | epoch: 021 | loss: 0.48070 - acc: 0.7856 -- iter: 224/253
[A[ATraining Step: 168  | total loss: [1m[32m0.46257[0m[0m | time: 9.034s
[2K
| Adam | epoch: 021 | loss: 0.46257 - acc: 0.7945 | val_loss: 0.54931 - val_acc: 0.7000 -- iter: 253/253
--
Training Step: 169  | total loss: [1m[32m0.45113[0m[0m | time: 1.153s
[2K
| Adam | epoch: 022 | loss: 0.45113 - acc: 0.7963 -- iter: 032/253
[A[ATraining Step: 170  | total loss: [1m[32m0.44496[0m[0m | time: 2.246s
[2K
| Adam | epoch: 022 | loss: 0.44496 - acc: 0.8011 -- iter: 064/253
[A[ATraining Step: 171  | total loss: [1m[32m0.43035[0m[0m | time: 3.294s
[2K
| Adam | epoch: 022 | loss: 0.43035 - acc: 0.8141 -- iter: 096/253
[A[ATraining Step: 172  | total loss: [1m[32m0.41636[0m[0m | time: 4.527s
[2K
| Adam | epoch: 022 | loss: 0.41636 - acc: 0.8223 -- iter: 128/253
[A[ATraining Step: 173  | total loss: [1m[32m0.40585[0m[0m | time: 5.810s
[2K
| Adam | epoch: 022 | loss: 0.40585 - acc: 0.8276 -- iter: 160/253
[A[ATraining Step: 174  | total loss: [1m[32m0.39250[0m[0m | time: 7.120s
[2K
| Adam | epoch: 022 | loss: 0.39250 - acc: 0.8355 -- iter: 192/253
[A[ATraining Step: 175  | total loss: [1m[32m0.37670[0m[0m | time: 7.991s
[2K
| Adam | epoch: 022 | loss: 0.37670 - acc: 0.8457 -- iter: 224/253
[A[ATraining Step: 176  | total loss: [1m[32m0.37118[0m[0m | time: 9.845s
[2K
| Adam | epoch: 022 | loss: 0.37118 - acc: 0.8548 | val_loss: 0.49194 - val_acc: 0.8000 -- iter: 253/253
--
Training Step: 177  | total loss: [1m[32m0.36655[0m[0m | time: 1.036s
[2K
| Adam | epoch: 023 | loss: 0.36655 - acc: 0.8506 -- iter: 032/253
[A[ATraining Step: 178  | total loss: [1m[32m0.34230[0m[0m | time: 2.009s
[2K
| Adam | epoch: 023 | loss: 0.34230 - acc: 0.8624 -- iter: 064/253
[A[ATraining Step: 179  | total loss: [1m[32m0.31410[0m[0m | time: 3.053s
[2K
| Adam | epoch: 023 | loss: 0.31410 - acc: 0.8762 -- iter: 096/253
[A[ATraining Step: 180  | total loss: [1m[32m0.30251[0m[0m | time: 4.047s
[2K
| Adam | epoch: 023 | loss: 0.30251 - acc: 0.8817 -- iter: 128/253
[A[ATraining Step: 181  | total loss: [1m[32m0.28029[0m[0m | time: 5.246s
[2K
| Adam | epoch: 023 | loss: 0.28029 - acc: 0.8935 -- iter: 160/253
[A[ATraining Step: 182  | total loss: [1m[32m0.26571[0m[0m | time: 6.589s
[2K
| Adam | epoch: 023 | loss: 0.26571 - acc: 0.8979 -- iter: 192/253
[A[ATraining Step: 183  | total loss: [1m[32m0.26781[0m[0m | time: 7.671s
[2K
| Adam | epoch: 023 | loss: 0.26781 - acc: 0.8987 -- iter: 224/253
[A[ATraining Step: 184  | total loss: [1m[32m0.27036[0m[0m | time: 9.818s
[2K
| Adam | epoch: 023 | loss: 0.27036 - acc: 0.8964 | val_loss: 0.43481 - val_acc: 0.8375 -- iter: 253/253
--
Training Step: 185  | total loss: [1m[32m0.25001[0m[0m | time: 1.041s
[2K
| Adam | epoch: 024 | loss: 0.25001 - acc: 0.9036 -- iter: 032/253
[A[ATraining Step: 186  | total loss: [1m[32m0.22962[0m[0m | time: 2.098s
[2K
| Adam | epoch: 024 | loss: 0.22962 - acc: 0.9132 -- iter: 064/253
[A[ATraining Step: 187  | total loss: [1m[32m0.23325[0m[0m | time: 3.014s
[2K
| Adam | epoch: 024 | loss: 0.23325 - acc: 0.9125 -- iter: 096/253
[A[ATraining Step: 188  | total loss: [1m[32m0.21897[0m[0m | time: 4.015s
[2K
| Adam | epoch: 024 | loss: 0.21897 - acc: 0.9182 -- iter: 128/253
[A[ATraining Step: 189  | total loss: [1m[32m0.23162[0m[0m | time: 5.121s
[2K
| Adam | epoch: 024 | loss: 0.23162 - acc: 0.9126 -- iter: 160/253
[A[ATraining Step: 190  | total loss: [1m[32m0.21696[0m[0m | time: 6.251s
[2K
| Adam | epoch: 024 | loss: 0.21696 - acc: 0.9178 -- iter: 192/253
[A[ATraining Step: 191  | total loss: [1m[32m0.21227[0m[0m | time: 7.245s
[2K
| Adam | epoch: 024 | loss: 0.21227 - acc: 0.9198 -- iter: 224/253
[A[ATraining Step: 192  | total loss: [1m[32m0.21970[0m[0m | time: 9.299s
[2K
| Adam | epoch: 024 | loss: 0.21970 - acc: 0.9185 | val_loss: 0.52439 - val_acc: 0.7625 -- iter: 253/253
--
Training Step: 193  | total loss: [1m[32m0.20214[0m[0m | time: 0.960s
[2K
| Adam | epoch: 025 | loss: 0.20214 - acc: 0.9266 -- iter: 032/253
[A[ATraining Step: 194  | total loss: [1m[32m0.20687[0m[0m | time: 1.952s
[2K
| Adam | epoch: 025 | loss: 0.20687 - acc: 0.9277 -- iter: 064/253
[A[ATraining Step: 195  | total loss: [1m[32m0.21517[0m[0m | time: 2.951s
[2K
| Adam | epoch: 025 | loss: 0.21517 - acc: 0.9256 -- iter: 096/253
[A[ATraining Step: 196  | total loss: [1m[32m0.19731[0m[0m | time: 4.050s
[2K
| Adam | epoch: 025 | loss: 0.19731 - acc: 0.9330 -- iter: 128/253
[A[ATraining Step: 197  | total loss: [1m[32m0.18444[0m[0m | time: 5.094s
[2K
| Adam | epoch: 025 | loss: 0.18444 - acc: 0.9366 -- iter: 160/253
[A[ATraining Step: 198  | total loss: [1m[32m0.17831[0m[0m | time: 6.044s
[2K
| Adam | epoch: 025 | loss: 0.17831 - acc: 0.9395 -- iter: 192/253
[A[ATraining Step: 199  | total loss: [1m[32m0.16612[0m[0m | time: 7.178s
[2K
| Adam | epoch: 025 | loss: 0.16612 - acc: 0.9421 -- iter: 224/253
[A[ATraining Step: 200  | total loss: [1m[32m0.15193[0m[0m | time: 9.300s
[2K
| Adam | epoch: 025 | loss: 0.15193 - acc: 0.9479 | val_loss: 0.56380 - val_acc: 0.7625 -- iter: 253/253
--
Training Step: 201  | total loss: [1m[32m0.13953[0m[0m | time: 1.022s
[2K
| Adam | epoch: 026 | loss: 0.13953 - acc: 0.9531 -- iter: 032/253
[A[ATraining Step: 202  | total loss: [1m[32m0.13242[0m[0m | time: 2.024s
[2K
| Adam | epoch: 026 | loss: 0.13242 - acc: 0.9578 -- iter: 064/253
[A[ATraining Step: 203  | total loss: [1m[32m0.12861[0m[0m | time: 3.003s
[2K
| Adam | epoch: 026 | loss: 0.12861 - acc: 0.9557 -- iter: 096/253
[A[ATraining Step: 204  | total loss: [1m[32m0.11896[0m[0m | time: 4.133s
[2K
| Adam | epoch: 026 | loss: 0.11896 - acc: 0.9602 -- iter: 128/253
[A[ATraining Step: 205  | total loss: [1m[32m0.13551[0m[0m | time: 5.147s
[2K
| Adam | epoch: 026 | loss: 0.13551 - acc: 0.9517 -- iter: 160/253
[A[ATraining Step: 206  | total loss: [1m[32m0.13677[0m[0m | time: 6.073s
[2K
| Adam | epoch: 026 | loss: 0.13677 - acc: 0.9502 -- iter: 192/253
[A[ATraining Step: 207  | total loss: [1m[32m0.12661[0m[0m | time: 7.166s
[2K
| Adam | epoch: 026 | loss: 0.12661 - acc: 0.9552 -- iter: 224/253
[A[ATraining Step: 208  | total loss: [1m[32m0.12068[0m[0m | time: 9.297s
[2K
| Adam | epoch: 026 | loss: 0.12068 - acc: 0.9597 | val_loss: 0.51524 - val_acc: 0.8500 -- iter: 253/253
--
Training Step: 209  | total loss: [1m[32m0.11008[0m[0m | time: 1.061s
[2K
| Adam | epoch: 027 | loss: 0.11008 - acc: 0.9637 -- iter: 032/253
[A[ATraining Step: 210  | total loss: [1m[32m0.10011[0m[0m | time: 2.023s
[2K
| Adam | epoch: 027 | loss: 0.10011 - acc: 0.9674 -- iter: 064/253
[A[ATraining Step: 211  | total loss: [1m[32m0.11942[0m[0m | time: 3.124s
[2K
| Adam | epoch: 027 | loss: 0.11942 - acc: 0.9644 -- iter: 096/253
[A[ATraining Step: 212  | total loss: [1m[32m0.11445[0m[0m | time: 4.196s
[2K
| Adam | epoch: 027 | loss: 0.11445 - acc: 0.9648 -- iter: 128/253
[A[ATraining Step: 213  | total loss: [1m[32m0.10465[0m[0m | time: 5.151s
[2K
| Adam | epoch: 027 | loss: 0.10465 - acc: 0.9683 -- iter: 160/253
[A[ATraining Step: 214  | total loss: [1m[32m0.09542[0m[0m | time: 6.322s
[2K
| Adam | epoch: 027 | loss: 0.09542 - acc: 0.9715 -- iter: 192/253
[A[ATraining Step: 215  | total loss: [1m[32m0.08842[0m[0m | time: 7.425s
[2K
| Adam | epoch: 027 | loss: 0.08842 - acc: 0.9743 -- iter: 224/253
[A[ATraining Step: 216  | total loss: [1m[32m0.09412[0m[0m | time: 9.534s
[2K
| Adam | epoch: 027 | loss: 0.09412 - acc: 0.9735 | val_loss: 0.88553 - val_acc: 0.7375 -- iter: 253/253
--
Training Step: 217  | total loss: [1m[32m0.08956[0m[0m | time: 1.039s
[2K
| Adam | epoch: 028 | loss: 0.08956 - acc: 0.9727 -- iter: 032/253
[A[ATraining Step: 218  | total loss: [1m[32m0.13777[0m[0m | time: 2.030s
[2K
| Adam | epoch: 028 | loss: 0.13777 - acc: 0.9535 -- iter: 064/253
[A[ATraining Step: 219  | total loss: [1m[32m0.13892[0m[0m | time: 3.052s
[2K
| Adam | epoch: 028 | loss: 0.13892 - acc: 0.9550 -- iter: 096/253
[A[ATraining Step: 220  | total loss: [1m[32m0.14798[0m[0m | time: 4.147s
[2K
| Adam | epoch: 028 | loss: 0.14798 - acc: 0.9564 -- iter: 128/253
[A[ATraining Step: 221  | total loss: [1m[32m0.13366[0m[0m | time: 5.107s
[2K
| Adam | epoch: 028 | loss: 0.13366 - acc: 0.9608 -- iter: 160/253
[A[ATraining Step: 222  | total loss: [1m[32m0.13520[0m[0m | time: 6.248s
[2K
| Adam | epoch: 028 | loss: 0.13520 - acc: 0.9616 -- iter: 192/253
[A[ATraining Step: 223  | total loss: [1m[32m0.14692[0m[0m | time: 7.298s
[2K
| Adam | epoch: 028 | loss: 0.14692 - acc: 0.9560 -- iter: 224/253
[A[ATraining Step: 224  | total loss: [1m[32m0.14089[0m[0m | time: 9.166s
[2K
| Adam | epoch: 028 | loss: 0.14089 - acc: 0.9573 | val_loss: 0.63640 - val_acc: 0.7500 -- iter: 253/253
--
Training Step: 225  | total loss: [1m[32m0.14003[0m[0m | time: 0.965s
[2K
| Adam | epoch: 029 | loss: 0.14003 - acc: 0.9581 -- iter: 032/253
[A[ATraining Step: 226  | total loss: [1m[32m0.14105[0m[0m | time: 2.035s
[2K
| Adam | epoch: 029 | loss: 0.14105 - acc: 0.9589 -- iter: 064/253
[A[ATraining Step: 227  | total loss: [1m[32m0.13530[0m[0m | time: 3.037s
[2K
| Adam | epoch: 029 | loss: 0.13530 - acc: 0.9599 -- iter: 096/253
[A[ATraining Step: 228  | total loss: [1m[32m0.12777[0m[0m | time: 4.080s
[2K
| Adam | epoch: 029 | loss: 0.12777 - acc: 0.9639 -- iter: 128/253
[A[ATraining Step: 229  | total loss: [1m[32m0.12912[0m[0m | time: 5.173s
[2K
| Adam | epoch: 029 | loss: 0.12912 - acc: 0.9644 -- iter: 160/253
[A[ATraining Step: 230  | total loss: [1m[32m0.12456[0m[0m | time: 6.254s
[2K
| Adam | epoch: 029 | loss: 0.12456 - acc: 0.9648 -- iter: 192/253
[A[ATraining Step: 231  | total loss: [1m[32m0.11574[0m[0m | time: 7.276s
[2K
| Adam | epoch: 029 | loss: 0.11574 - acc: 0.9683 -- iter: 224/253
[A[ATraining Step: 232  | total loss: [1m[32m0.10916[0m[0m | time: 9.346s
[2K
| Adam | epoch: 029 | loss: 0.10916 - acc: 0.9715 | val_loss: 0.55349 - val_acc: 0.7625 -- iter: 253/253
--
Training Step: 233  | total loss: [1m[32m0.10269[0m[0m | time: 1.050s
[2K
| Adam | epoch: 030 | loss: 0.10269 - acc: 0.9743 -- iter: 032/253
[A[ATraining Step: 234  | total loss: [1m[32m0.10014[0m[0m | time: 2.030s
[2K
| Adam | epoch: 030 | loss: 0.10014 - acc: 0.9735 -- iter: 064/253
[A[ATraining Step: 235  | total loss: [1m[32m0.09517[0m[0m | time: 3.089s
[2K
| Adam | epoch: 030 | loss: 0.09517 - acc: 0.9761 -- iter: 096/253
[A[ATraining Step: 236  | total loss: [1m[32m0.08750[0m[0m | time: 4.137s
[2K
| Adam | epoch: 030 | loss: 0.08750 - acc: 0.9785 -- iter: 128/253
[A[ATraining Step: 237  | total loss: [1m[32m0.08045[0m[0m | time: 5.195s
[2K
| Adam | epoch: 030 | loss: 0.08045 - acc: 0.9806 -- iter: 160/253
[A[ATraining Step: 238  | total loss: [1m[32m0.09825[0m[0m | time: 6.157s
[2K
| Adam | epoch: 030 | loss: 0.09825 - acc: 0.9763 -- iter: 192/253
[A[ATraining Step: 239  | total loss: [1m[32m0.09966[0m[0m | time: 7.204s
[2K
| Adam | epoch: 030 | loss: 0.09966 - acc: 0.9756 -- iter: 224/253
[A[ATraining Step: 240  | total loss: [1m[32m0.09126[0m[0m | time: 9.282s
[2K
| Adam | epoch: 030 | loss: 0.09126 - acc: 0.9780 | val_loss: 0.50848 - val_acc: 0.8125 -- iter: 253/253
--
Validation AUC:0.9137590520079
Validation AUPRC:0.9482445169837284
Test AUC:0.9462915601023018
Test AUPRC:0.9656590819439956
BestTestF1Score	0.9	0.77	0.89	0.91	0.89	41	4	30	5	0.09
BestTestMCCScore	0.88	0.76	0.88	0.95	0.83	38	2	32	8	0.28
BestTestAccuracyScore	0.88	0.76	0.88	0.95	0.83	38	2	32	8	0.28
BestValidationF1Score	0.89	0.71	0.86	0.85	0.94	46	8	23	3	0.09
BestValidationMCC	0.89	0.71	0.86	0.9	0.88	43	5	26	6	0.28
BestValidationAccuracy	0.89	0.71	0.86	0.9	0.88	43	5	26	6	0.28
TestPredictions (Threshold:0.28)
CHEMBL218569,TN,INACT,0.03999999910593033	CHEMBL240504,TN,INACT,0.009999999776482582	CHEMBL3335359,TP,ACT,0.9900000095367432	CHEMBL1097417,TP,ACT,0.9300000071525574	CHEMBL1915949,FN,ACT,0.1899999976158142	CHEMBL240980,TN,INACT,0.019999999552965164	CHEMBL373383,FN,ACT,0.019999999552965164	CHEMBL241717,TN,INACT,0.0	CHEMBL1800127,TN,INACT,0.07999999821186066	CHEMBL3698479,TN,INACT,0.07000000029802322	CHEMBL436335,TN,INACT,0.0	CHEMBL1277341,FN,ACT,0.14000000059604645	CHEMBL246858,TN,INACT,0.009999999776482582	CHEMBL1627752,TP,ACT,0.9800000190734863	CHEMBL217917,TN,INACT,0.009999999776482582	CHEMBL195217,TP,ACT,0.9900000095367432	CHEMBL1277802,TP,ACT,1.0	CHEMBL1644043,TP,ACT,0.9100000262260437	CHEMBL2324371,TP,ACT,0.7699999809265137	CHEMBL3289865,TP,ACT,0.6899999976158142	CHEMBL1277708,TP,ACT,0.9900000095367432	CHEMBL511530,TP,ACT,1.0	CHEMBL438624,TP,ACT,0.9800000190734863	CHEMBL2163793,TN,INACT,0.05000000074505806	CHEMBL246057,TN,INACT,0.0	CHEMBL583519,TP,ACT,0.9599999785423279	CHEMBL364060,TP,ACT,0.9800000190734863	CHEMBL3765799,TN,INACT,0.009999999776482582	CHEMBL2041362,TP,ACT,0.9800000190734863	CHEMBL3629457,FN,ACT,0.029999999329447746	CHEMBL3646661,TN,INACT,0.10999999940395355	CHEMBL240503,TN,INACT,0.009999999776482582	CHEMBL2436742,FN,ACT,0.009999999776482582	CHEMBL3645218,TP,ACT,0.9300000071525574	CHEMBL2170753,TP,ACT,1.0	CHEMBL365752,TP,ACT,0.9900000095367432	CHEMBL2376866,TN,INACT,0.009999999776482582	CHEMBL2041376,TP,ACT,0.9200000166893005	CHEMBL521,TN,INACT,0.019999999552965164	CHEMBL371948,TP,ACT,0.7300000190734863	CHEMBL210465,TN,INACT,0.019999999552965164	CHEMBL3627738,TP,ACT,0.9900000095367432	CHEMBL375744,TN,INACT,0.0	CHEMBL246676,TN,INACT,0.0	CHEMBL392809,TN,INACT,0.11999999731779099	CHEMBL469227,TP,ACT,0.9800000190734863	CHEMBL1096026,TP,ACT,1.0	CHEMBL3763512,TN,INACT,0.019999999552965164	CHEMBL1915946,FN,ACT,0.009999999776482582	CHEMBL458727,TP,ACT,0.9900000095367432	CHEMBL3629452,TP,ACT,1.0	CHEMBL3645225,FN,ACT,0.1899999976158142	CHEMBL576896,TP,ACT,0.9900000095367432	CHEMBL2041366,TP,ACT,0.9800000190734863	CHEMBL221459,TN,INACT,0.009999999776482582	CHEMBL3298952,TP,ACT,0.9900000095367432	CHEMBL2436738,TP,ACT,0.9900000095367432	CHEMBL384650,FP,INACT,0.5799999833106995	CHEMBL1079608,TP,ACT,0.9800000190734863	CHEMBL1917889,TP,ACT,1.0	CHEMBL469909,TN,INACT,0.009999999776482582	CHEMBL374728,TN,INACT,0.019999999552965164	CHEMBL398087,TN,INACT,0.009999999776482582	CHEMBL75893,TN,INACT,0.009999999776482582	CHEMBL3765140,TN,INACT,0.0	CHEMBL3342507,TP,ACT,0.6399999856948853	CHEMBL241716,TN,INACT,0.0	CHEMBL570595,TP,ACT,0.9900000095367432	CHEMBL1915948,FN,ACT,0.029999999329447746	CHEMBL1277340,TP,ACT,1.0	CHEMBL211039,FP,INACT,0.949999988079071	CHEMBL2402167,TN,INACT,0.05000000074505806	CHEMBL1277616,TP,ACT,1.0	CHEMBL259000,TP,ACT,0.7900000214576721	CHEMBL394252,TN,INACT,0.07000000029802322	CHEMBL3629437,TP,ACT,0.9900000095367432	CHEMBL220414,TN,INACT,0.0	CHEMBL577338,TP,ACT,0.9900000095367432	CHEMBL2436736,TP,ACT,1.0	CHEMBL1163877,TN,INACT,0.05000000074505806	

