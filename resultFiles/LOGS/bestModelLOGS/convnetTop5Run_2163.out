CNNModel CHEMBL2758 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	100
Number of inactive compounds :	100
---------------------------------
Run id: CNNModel_CHEMBL2758_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2758_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 128
Validation samples: 40
--
Training Step: 1  | time: 1.380s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/128
[A[ATraining Step: 2  | total loss: [1m[32m0.62422[0m[0m | time: 2.623s
[2K
| Adam | epoch: 001 | loss: 0.62422 - acc: 0.1969 -- iter: 064/128
[A[ATraining Step: 3  | total loss: [1m[32m0.68049[0m[0m | time: 3.771s
[2K
| Adam | epoch: 001 | loss: 0.68049 - acc: 0.4449 -- iter: 096/128
[A[ATraining Step: 4  | total loss: [1m[32m0.68937[0m[0m | time: 6.065s
[2K
| Adam | epoch: 001 | loss: 0.68937 - acc: 0.5097 | val_loss: 0.69400 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 5  | total loss: [1m[32m0.69099[0m[0m | time: 1.293s
[2K
| Adam | epoch: 002 | loss: 0.69099 - acc: 0.5462 -- iter: 032/128
[A[ATraining Step: 6  | total loss: [1m[32m0.68933[0m[0m | time: 2.501s
[2K
| Adam | epoch: 002 | loss: 0.68933 - acc: 0.5567 -- iter: 064/128
[A[ATraining Step: 7  | total loss: [1m[32m0.69868[0m[0m | time: 3.854s
[2K
| Adam | epoch: 002 | loss: 0.69868 - acc: 0.4852 -- iter: 096/128
[A[ATraining Step: 8  | total loss: [1m[32m0.69806[0m[0m | time: 5.996s
[2K
| Adam | epoch: 002 | loss: 0.69806 - acc: 0.4759 | val_loss: 0.69383 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 9  | total loss: [1m[32m0.69201[0m[0m | time: 1.263s
[2K
| Adam | epoch: 003 | loss: 0.69201 - acc: 0.5383 -- iter: 032/128
[A[ATraining Step: 10  | total loss: [1m[32m0.69525[0m[0m | time: 2.407s
[2K
| Adam | epoch: 003 | loss: 0.69525 - acc: 0.4879 -- iter: 064/128
[A[ATraining Step: 11  | total loss: [1m[32m0.69577[0m[0m | time: 3.437s
[2K
| Adam | epoch: 003 | loss: 0.69577 - acc: 0.4640 -- iter: 096/128
[A[ATraining Step: 12  | total loss: [1m[32m0.69404[0m[0m | time: 5.730s
[2K
| Adam | epoch: 003 | loss: 0.69404 - acc: 0.4943 | val_loss: 0.69321 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 13  | total loss: [1m[32m0.69549[0m[0m | time: 1.195s
[2K
| Adam | epoch: 004 | loss: 0.69549 - acc: 0.4432 -- iter: 032/128
[A[ATraining Step: 14  | total loss: [1m[32m0.69414[0m[0m | time: 2.240s
[2K
| Adam | epoch: 004 | loss: 0.69414 - acc: 0.4792 -- iter: 064/128
[A[ATraining Step: 15  | total loss: [1m[32m0.69304[0m[0m | time: 3.501s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5362 -- iter: 096/128
[A[ATraining Step: 16  | total loss: [1m[32m0.69251[0m[0m | time: 5.695s
[2K
| Adam | epoch: 004 | loss: 0.69251 - acc: 0.5695 | val_loss: 0.69319 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 17  | total loss: [1m[32m0.69278[0m[0m | time: 1.213s
[2K
| Adam | epoch: 005 | loss: 0.69278 - acc: 0.5445 -- iter: 032/128
[A[ATraining Step: 18  | total loss: [1m[32m0.69304[0m[0m | time: 2.332s
[2K
| Adam | epoch: 005 | loss: 0.69304 - acc: 0.5183 -- iter: 064/128
[A[ATraining Step: 19  | total loss: [1m[32m0.69306[0m[0m | time: 3.431s
[2K
| Adam | epoch: 005 | loss: 0.69306 - acc: 0.5122 -- iter: 096/128
[A[ATraining Step: 20  | total loss: [1m[32m0.69310[0m[0m | time: 5.711s
[2K
| Adam | epoch: 005 | loss: 0.69310 - acc: 0.5083 | val_loss: 0.69319 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 21  | total loss: [1m[32m0.69314[0m[0m | time: 1.243s
[2K
| Adam | epoch: 006 | loss: 0.69314 - acc: 0.5057 -- iter: 032/128
[A[ATraining Step: 22  | total loss: [1m[32m0.69273[0m[0m | time: 2.424s
[2K
| Adam | epoch: 006 | loss: 0.69273 - acc: 0.5227 -- iter: 064/128
[A[ATraining Step: 23  | total loss: [1m[32m0.69280[0m[0m | time: 3.688s
[2K
| Adam | epoch: 006 | loss: 0.69280 - acc: 0.5161 -- iter: 096/128
[A[ATraining Step: 24  | total loss: [1m[32m0.69251[0m[0m | time: 5.641s
[2K
| Adam | epoch: 006 | loss: 0.69251 - acc: 0.5292 | val_loss: 0.69323 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 25  | total loss: [1m[32m0.69247[0m[0m | time: 1.098s
[2K
| Adam | epoch: 007 | loss: 0.69247 - acc: 0.5297 -- iter: 032/128
[A[ATraining Step: 26  | total loss: [1m[32m0.69246[0m[0m | time: 2.327s
[2K
| Adam | epoch: 007 | loss: 0.69246 - acc: 0.5301 -- iter: 064/128
[A[ATraining Step: 27  | total loss: [1m[32m0.69312[0m[0m | time: 3.543s
[2K
| Adam | epoch: 007 | loss: 0.69312 - acc: 0.5063 -- iter: 096/128
[A[ATraining Step: 28  | total loss: [1m[32m0.69337[0m[0m | time: 5.569s
[2K
| Adam | epoch: 007 | loss: 0.69337 - acc: 0.4969 | val_loss: 0.69324 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 29  | total loss: [1m[32m0.69373[0m[0m | time: 1.229s
[2K
| Adam | epoch: 008 | loss: 0.69373 - acc: 0.4825 -- iter: 032/128
[A[ATraining Step: 30  | total loss: [1m[32m0.69321[0m[0m | time: 2.296s
[2K
| Adam | epoch: 008 | loss: 0.69321 - acc: 0.5014 -- iter: 064/128
[A[ATraining Step: 31  | total loss: [1m[32m0.69292[0m[0m | time: 3.434s
[2K
| Adam | epoch: 008 | loss: 0.69292 - acc: 0.5155 -- iter: 096/128
[A[ATraining Step: 32  | total loss: [1m[32m0.69264[0m[0m | time: 5.540s
[2K
| Adam | epoch: 008 | loss: 0.69264 - acc: 0.5261 | val_loss: 0.69325 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 33  | total loss: [1m[32m0.69297[0m[0m | time: 1.144s
[2K
| Adam | epoch: 009 | loss: 0.69297 - acc: 0.5135 -- iter: 032/128
[A[ATraining Step: 34  | total loss: [1m[32m0.69300[0m[0m | time: 2.247s
[2K
| Adam | epoch: 009 | loss: 0.69300 - acc: 0.5106 -- iter: 064/128
[A[ATraining Step: 35  | total loss: [1m[32m0.69209[0m[0m | time: 3.459s
[2K
| Adam | epoch: 009 | loss: 0.69209 - acc: 0.5411 -- iter: 096/128
[A[ATraining Step: 36  | total loss: [1m[32m0.69123[0m[0m | time: 5.753s
[2K
| Adam | epoch: 009 | loss: 0.69123 - acc: 0.5646 | val_loss: 0.69339 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 37  | total loss: [1m[32m0.69241[0m[0m | time: 1.193s
[2K
| Adam | epoch: 010 | loss: 0.69241 - acc: 0.5330 -- iter: 032/128
[A[ATraining Step: 38  | total loss: [1m[32m0.69205[0m[0m | time: 2.534s
[2K
| Adam | epoch: 010 | loss: 0.69205 - acc: 0.5387 -- iter: 064/128
[A[ATraining Step: 39  | total loss: [1m[32m0.69197[0m[0m | time: 3.882s
[2K
| Adam | epoch: 010 | loss: 0.69197 - acc: 0.5373 -- iter: 096/128
[A[ATraining Step: 40  | total loss: [1m[32m0.69254[0m[0m | time: 5.995s
[2K
| Adam | epoch: 010 | loss: 0.69254 - acc: 0.5245 | val_loss: 0.69357 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 41  | total loss: [1m[32m0.69311[0m[0m | time: 1.307s
[2K
| Adam | epoch: 011 | loss: 0.69311 - acc: 0.5142 -- iter: 032/128
[A[ATraining Step: 42  | total loss: [1m[32m0.69354[0m[0m | time: 2.593s
[2K
| Adam | epoch: 011 | loss: 0.69354 - acc: 0.5060 -- iter: 064/128
[A[ATraining Step: 43  | total loss: [1m[32m0.69382[0m[0m | time: 4.791s
[2K
| Adam | epoch: 011 | loss: 0.69382 - acc: 0.4995 -- iter: 096/128
[A[ATraining Step: 44  | total loss: [1m[32m0.69393[0m[0m | time: 6.791s
[2K
| Adam | epoch: 011 | loss: 0.69393 - acc: 0.4941 | val_loss: 0.69336 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 45  | total loss: [1m[32m0.69358[0m[0m | time: 1.181s
[2K
| Adam | epoch: 012 | loss: 0.69358 - acc: 0.5004 -- iter: 032/128
[A[ATraining Step: 46  | total loss: [1m[32m0.69336[0m[0m | time: 2.439s
[2K
| Adam | epoch: 012 | loss: 0.69336 - acc: 0.5056 -- iter: 064/128
[A[ATraining Step: 47  | total loss: [1m[32m0.69288[0m[0m | time: 3.449s
[2K
| Adam | epoch: 012 | loss: 0.69288 - acc: 0.5149 -- iter: 096/128
[A[ATraining Step: 48  | total loss: [1m[32m0.69271[0m[0m | time: 5.492s
[2K
| Adam | epoch: 012 | loss: 0.69271 - acc: 0.5175 | val_loss: 0.69334 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 49  | total loss: [1m[32m0.69211[0m[0m | time: 1.217s
[2K
| Adam | epoch: 013 | loss: 0.69211 - acc: 0.5296 -- iter: 032/128
[A[ATraining Step: 50  | total loss: [1m[32m0.69270[0m[0m | time: 2.177s
[2K
| Adam | epoch: 013 | loss: 0.69270 - acc: 0.5153 -- iter: 064/128
[A[ATraining Step: 51  | total loss: [1m[32m0.69321[0m[0m | time: 3.329s
[2K
| Adam | epoch: 013 | loss: 0.69321 - acc: 0.5034 -- iter: 096/128
[A[ATraining Step: 52  | total loss: [1m[32m0.69341[0m[0m | time: 5.396s
[2K
| Adam | epoch: 013 | loss: 0.69341 - acc: 0.4982 | val_loss: 0.69322 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 53  | total loss: [1m[32m0.69335[0m[0m | time: 1.129s
[2K
| Adam | epoch: 014 | loss: 0.69335 - acc: 0.4985 -- iter: 032/128
[A[ATraining Step: 54  | total loss: [1m[32m0.69442[0m[0m | time: 2.229s
[2K
| Adam | epoch: 014 | loss: 0.69442 - acc: 0.4715 -- iter: 064/128
[A[ATraining Step: 55  | total loss: [1m[32m0.69350[0m[0m | time: 3.537s
[2K
| Adam | epoch: 014 | loss: 0.69350 - acc: 0.4979 -- iter: 096/128
[A[ATraining Step: 56  | total loss: [1m[32m0.69273[0m[0m | time: 5.896s
[2K
| Adam | epoch: 014 | loss: 0.69273 - acc: 0.5201 | val_loss: 0.69324 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 57  | total loss: [1m[32m0.69248[0m[0m | time: 1.099s
[2K
| Adam | epoch: 015 | loss: 0.69248 - acc: 0.5260 -- iter: 032/128
[A[ATraining Step: 58  | total loss: [1m[32m0.69247[0m[0m | time: 2.186s
[2K
| Adam | epoch: 015 | loss: 0.69247 - acc: 0.5267 -- iter: 064/128
[A[ATraining Step: 59  | total loss: [1m[32m0.69227[0m[0m | time: 3.335s
[2K
| Adam | epoch: 015 | loss: 0.69227 - acc: 0.5315 -- iter: 096/128
[A[ATraining Step: 60  | total loss: [1m[32m0.69217[0m[0m | time: 5.583s
[2K
| Adam | epoch: 015 | loss: 0.69217 - acc: 0.5315 | val_loss: 0.69336 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 61  | total loss: [1m[32m0.69207[0m[0m | time: 1.131s
[2K
| Adam | epoch: 016 | loss: 0.69207 - acc: 0.5315 -- iter: 032/128
[A[ATraining Step: 62  | total loss: [1m[32m0.69276[0m[0m | time: 2.492s
[2K
| Adam | epoch: 016 | loss: 0.69276 - acc: 0.5154 -- iter: 064/128
[A[ATraining Step: 63  | total loss: [1m[32m0.69260[0m[0m | time: 4.552s
[2K
| Adam | epoch: 016 | loss: 0.69260 - acc: 0.5174 -- iter: 096/128
[A[ATraining Step: 64  | total loss: [1m[32m0.69278[0m[0m | time: 6.533s
[2K
| Adam | epoch: 016 | loss: 0.69278 - acc: 0.5113 | val_loss: 0.69327 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 65  | total loss: [1m[32m0.69211[0m[0m | time: 1.152s
[2K
| Adam | epoch: 017 | loss: 0.69211 - acc: 0.5215 -- iter: 032/128
[A[ATraining Step: 66  | total loss: [1m[32m0.69144[0m[0m | time: 2.329s
[2K
| Adam | epoch: 017 | loss: 0.69144 - acc: 0.5303 -- iter: 064/128
[A[ATraining Step: 67  | total loss: [1m[32m0.69168[0m[0m | time: 3.454s
[2K
| Adam | epoch: 017 | loss: 0.69168 - acc: 0.5266 -- iter: 096/128
[A[ATraining Step: 68  | total loss: [1m[32m0.69171[0m[0m | time: 5.644s
[2K
| Adam | epoch: 017 | loss: 0.69171 - acc: 0.5235 | val_loss: 0.69324 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 69  | total loss: [1m[32m0.69226[0m[0m | time: 1.130s
[2K
| Adam | epoch: 018 | loss: 0.69226 - acc: 0.5134 -- iter: 032/128
[A[ATraining Step: 70  | total loss: [1m[32m0.69254[0m[0m | time: 2.139s
[2K
| Adam | epoch: 018 | loss: 0.69254 - acc: 0.5083 -- iter: 064/128
[A[ATraining Step: 71  | total loss: [1m[32m0.69267[0m[0m | time: 3.170s
[2K
| Adam | epoch: 018 | loss: 0.69267 - acc: 0.5038 -- iter: 096/128
[A[ATraining Step: 72  | total loss: [1m[32m0.69193[0m[0m | time: 5.324s
[2K
| Adam | epoch: 018 | loss: 0.69193 - acc: 0.5174 | val_loss: 0.69296 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 73  | total loss: [1m[32m0.69095[0m[0m | time: 1.105s
[2K
| Adam | epoch: 019 | loss: 0.69095 - acc: 0.5294 -- iter: 032/128
[A[ATraining Step: 74  | total loss: [1m[32m0.69080[0m[0m | time: 2.177s
[2K
| Adam | epoch: 019 | loss: 0.69080 - acc: 0.5261 -- iter: 064/128
[A[ATraining Step: 75  | total loss: [1m[32m0.69216[0m[0m | time: 3.429s
[2K
| Adam | epoch: 019 | loss: 0.69216 - acc: 0.5097 -- iter: 096/128
[A[ATraining Step: 76  | total loss: [1m[32m0.69316[0m[0m | time: 5.752s
[2K
| Adam | epoch: 019 | loss: 0.69316 - acc: 0.4953 | val_loss: 0.69270 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 77  | total loss: [1m[32m0.69242[0m[0m | time: 0.939s
[2K
| Adam | epoch: 020 | loss: 0.69242 - acc: 0.4991 -- iter: 032/128
[A[ATraining Step: 78  | total loss: [1m[32m0.69200[0m[0m | time: 1.909s
[2K
| Adam | epoch: 020 | loss: 0.69200 - acc: 0.5025 -- iter: 064/128
[A[ATraining Step: 79  | total loss: [1m[32m0.69229[0m[0m | time: 2.987s
[2K
| Adam | epoch: 020 | loss: 0.69229 - acc: 0.4893 -- iter: 096/128
[A[ATraining Step: 80  | total loss: [1m[32m0.69143[0m[0m | time: 5.160s
[2K
| Adam | epoch: 020 | loss: 0.69143 - acc: 0.5000 | val_loss: 0.69301 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 81  | total loss: [1m[32m0.68998[0m[0m | time: 1.279s
[2K
| Adam | epoch: 021 | loss: 0.68998 - acc: 0.5095 -- iter: 032/128
[A[ATraining Step: 82  | total loss: [1m[32m0.68917[0m[0m | time: 2.587s
[2K
| Adam | epoch: 021 | loss: 0.68917 - acc: 0.5116 -- iter: 064/128
[A[ATraining Step: 83  | total loss: [1m[32m0.68816[0m[0m | time: 4.010s
[2K
| Adam | epoch: 021 | loss: 0.68816 - acc: 0.5167 -- iter: 096/128
[A[ATraining Step: 84  | total loss: [1m[32m0.68767[0m[0m | time: 7.167s
[2K
| Adam | epoch: 021 | loss: 0.68767 - acc: 0.5151 | val_loss: 0.69707 - val_acc: 0.5250 -- iter: 128/128
--
Training Step: 85  | total loss: [1m[32m0.68809[0m[0m | time: 1.307s
[2K
| Adam | epoch: 022 | loss: 0.68809 - acc: 0.5104 -- iter: 032/128
[A[ATraining Step: 86  | total loss: [1m[32m0.68786[0m[0m | time: 2.437s
[2K
| Adam | epoch: 022 | loss: 0.68786 - acc: 0.5094 -- iter: 064/128
[A[ATraining Step: 87  | total loss: [1m[32m0.68632[0m[0m | time: 3.505s
[2K
| Adam | epoch: 022 | loss: 0.68632 - acc: 0.5116 -- iter: 096/128
[A[ATraining Step: 88  | total loss: [1m[32m0.68603[0m[0m | time: 5.767s
[2K
| Adam | epoch: 022 | loss: 0.68603 - acc: 0.5198 | val_loss: 0.68942 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 89  | total loss: [1m[32m0.68458[0m[0m | time: 1.153s
[2K
| Adam | epoch: 023 | loss: 0.68458 - acc: 0.5397 -- iter: 032/128
[A[ATraining Step: 90  | total loss: [1m[32m0.68318[0m[0m | time: 2.316s
[2K
| Adam | epoch: 023 | loss: 0.68318 - acc: 0.5513 -- iter: 064/128
[A[ATraining Step: 91  | total loss: [1m[32m0.68087[0m[0m | time: 3.407s
[2K
| Adam | epoch: 023 | loss: 0.68087 - acc: 0.5556 -- iter: 096/128
[A[ATraining Step: 92  | total loss: [1m[32m0.67625[0m[0m | time: 5.721s
[2K
| Adam | epoch: 023 | loss: 0.67625 - acc: 0.5656 | val_loss: 0.70907 - val_acc: 0.5250 -- iter: 128/128
--
Training Step: 93  | total loss: [1m[32m0.67601[0m[0m | time: 1.270s
[2K
| Adam | epoch: 024 | loss: 0.67601 - acc: 0.5591 -- iter: 032/128
[A[ATraining Step: 94  | total loss: [1m[32m0.67808[0m[0m | time: 2.571s
[2K
| Adam | epoch: 024 | loss: 0.67808 - acc: 0.5532 -- iter: 064/128
[A[ATraining Step: 95  | total loss: [1m[32m0.67003[0m[0m | time: 3.606s
[2K
| Adam | epoch: 024 | loss: 0.67003 - acc: 0.5854 -- iter: 096/128
[A[ATraining Step: 96  | total loss: [1m[32m0.65941[0m[0m | time: 5.605s
[2K
| Adam | epoch: 024 | loss: 0.65941 - acc: 0.6143 | val_loss: 0.74900 - val_acc: 0.5000 -- iter: 128/128
--
Training Step: 97  | total loss: [1m[32m0.65657[0m[0m | time: 1.177s
[2K
| Adam | epoch: 025 | loss: 0.65657 - acc: 0.6091 -- iter: 032/128
[A[ATraining Step: 98  | total loss: [1m[32m0.66182[0m[0m | time: 2.404s
[2K
| Adam | epoch: 025 | loss: 0.66182 - acc: 0.5982 -- iter: 064/128
[A[ATraining Step: 99  | total loss: [1m[32m0.65627[0m[0m | time: 3.433s
[2K
| Adam | epoch: 025 | loss: 0.65627 - acc: 0.6040 -- iter: 096/128
[A[ATraining Step: 100  | total loss: [1m[32m0.64189[0m[0m | time: 5.544s
[2K
| Adam | epoch: 025 | loss: 0.64189 - acc: 0.6155 | val_loss: 0.71263 - val_acc: 0.5250 -- iter: 128/128
--
Training Step: 101  | total loss: [1m[32m0.62674[0m[0m | time: 1.150s
[2K
| Adam | epoch: 026 | loss: 0.62674 - acc: 0.6446 -- iter: 032/128
[A[ATraining Step: 102  | total loss: [1m[32m0.62353[0m[0m | time: 2.195s
[2K
| Adam | epoch: 026 | loss: 0.62353 - acc: 0.6489 -- iter: 064/128
[A[ATraining Step: 103  | total loss: [1m[32m0.63204[0m[0m | time: 3.237s
[2K
| Adam | epoch: 026 | loss: 0.63204 - acc: 0.6402 -- iter: 096/128
[A[ATraining Step: 104  | total loss: [1m[32m0.62565[0m[0m | time: 5.394s
[2K
| Adam | epoch: 026 | loss: 0.62565 - acc: 0.6512 | val_loss: 0.75241 - val_acc: 0.5750 -- iter: 128/128
--
Training Step: 105  | total loss: [1m[32m0.61670[0m[0m | time: 1.124s
[2K
| Adam | epoch: 027 | loss: 0.61670 - acc: 0.6642 -- iter: 032/128
[A[ATraining Step: 106  | total loss: [1m[32m0.60482[0m[0m | time: 2.455s
[2K
| Adam | epoch: 027 | loss: 0.60482 - acc: 0.6759 -- iter: 064/128
[A[ATraining Step: 107  | total loss: [1m[32m0.59125[0m[0m | time: 3.403s
[2K
| Adam | epoch: 027 | loss: 0.59125 - acc: 0.6833 -- iter: 096/128
[A[ATraining Step: 108  | total loss: [1m[32m0.58025[0m[0m | time: 5.512s
[2K
| Adam | epoch: 027 | loss: 0.58025 - acc: 0.6931 | val_loss: 0.81242 - val_acc: 0.4500 -- iter: 128/128
--
Training Step: 109  | total loss: [1m[32m0.57667[0m[0m | time: 1.206s
[2K
| Adam | epoch: 028 | loss: 0.57667 - acc: 0.6894 -- iter: 032/128
[A[ATraining Step: 110  | total loss: [1m[32m0.58229[0m[0m | time: 2.377s
[2K
| Adam | epoch: 028 | loss: 0.58229 - acc: 0.6861 -- iter: 064/128
[A[ATraining Step: 111  | total loss: [1m[32m0.58556[0m[0m | time: 3.498s
[2K
| Adam | epoch: 028 | loss: 0.58556 - acc: 0.6863 -- iter: 096/128
[A[ATraining Step: 112  | total loss: [1m[32m0.56918[0m[0m | time: 5.722s
[2K
| Adam | epoch: 028 | loss: 0.56918 - acc: 0.7051 | val_loss: 0.96284 - val_acc: 0.5500 -- iter: 128/128
--
Training Step: 113  | total loss: [1m[32m0.55530[0m[0m | time: 1.109s
[2K
| Adam | epoch: 029 | loss: 0.55530 - acc: 0.7065 -- iter: 032/128
[A[ATraining Step: 114  | total loss: [1m[32m0.54790[0m[0m | time: 2.537s
[2K
| Adam | epoch: 029 | loss: 0.54790 - acc: 0.7077 -- iter: 064/128
[A[ATraining Step: 115  | total loss: [1m[32m0.53526[0m[0m | time: 3.978s
[2K
| Adam | epoch: 029 | loss: 0.53526 - acc: 0.7182 -- iter: 096/128
[A[ATraining Step: 116  | total loss: [1m[32m0.51981[0m[0m | time: 6.001s
[2K
| Adam | epoch: 029 | loss: 0.51981 - acc: 0.7370 | val_loss: 0.78741 - val_acc: 0.4500 -- iter: 128/128
--
Training Step: 117  | total loss: [1m[32m0.50806[0m[0m | time: 1.241s
[2K
| Adam | epoch: 030 | loss: 0.50806 - acc: 0.7539 -- iter: 032/128
[A[ATraining Step: 118  | total loss: [1m[32m0.49625[0m[0m | time: 2.530s
[2K
| Adam | epoch: 030 | loss: 0.49625 - acc: 0.7598 -- iter: 064/128
[A[ATraining Step: 119  | total loss: [1m[32m0.49035[0m[0m | time: 3.767s
[2K
| Adam | epoch: 030 | loss: 0.49035 - acc: 0.7651 -- iter: 096/128
[A[ATraining Step: 120  | total loss: [1m[32m0.47903[0m[0m | time: 5.774s
[2K
| Adam | epoch: 030 | loss: 0.47903 - acc: 0.7792 | val_loss: 0.89169 - val_acc: 0.5250 -- iter: 128/128
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.55
Validation AUPRC:0.589413074978616
Test AUC:0.7468671679197995
Test AUPRC:0.8179412524493981
BestTestF1Score	0.7	0.18	0.57	0.56	0.95	20	16	3	1	0.27
BestTestMCCScore	0.25	0.27	0.55	1.0	0.14	3	0	19	18	0.98
BestTestAccuracyScore	0.7	0.4	0.7	0.74	0.67	14	5	14	7	0.62
BestValidationF1Score	0.69	0.23	0.57	0.54	0.95	19	16	4	1	0.27
BestValidationMCC	0.18	0.23	0.55	1.0	0.1	2	0	20	18	0.98
BestValidationAccuracy	0.59	0.15	0.57	0.57	0.6	12	9	11	8	0.62
TestPredictions (Threshold:0.98)
CHEMBL1300410,FN,ACT,0.20000000298023224	CHEMBL1386182,FN,ACT,0.28999999165534973	CHEMBL1437928,TN,INACT,0.17000000178813934	CHEMBL3191714,FN,ACT,0.8299999833106995	CHEMBL1329850,TN,INACT,0.47999998927116394	CHEMBL1699075,TN,INACT,0.6399999856948853	CHEMBL77534,TN,INACT,0.5699999928474426	CHEMBL1553163,FN,ACT,0.9100000262260437	CHEMBL1581158,TN,INACT,0.8199999928474426	CHEMBL1567571,FN,ACT,0.3499999940395355	CHEMBL1400481,FN,ACT,0.47999998927116394	CHEMBL1706897,TP,ACT,0.9900000095367432	CHEMBL1703200,FN,ACT,0.7699999809265137	CHEMBL1731106,TN,INACT,0.699999988079071	CHEMBL1708115,FN,ACT,0.949999988079071	CHEMBL1390710,FN,ACT,0.5799999833106995	CHEMBL1607035,TN,INACT,0.3400000035762787	CHEMBL3193771,TN,INACT,0.8100000023841858	CHEMBL3193639,TN,INACT,0.20999999344348907	CHEMBL1720939,TN,INACT,0.8100000023841858	CHEMBL1523343,TN,INACT,0.44999998807907104	CHEMBL1609871,TN,INACT,0.25	CHEMBL2007180,TN,INACT,0.49000000953674316	CHEMBL1714665,FN,ACT,0.8100000023841858	CHEMBL1536196,TN,INACT,0.3100000023841858	CHEMBL1403738,TN,INACT,0.4300000071525574	CHEMBL1547498,TN,INACT,0.36000001430511475	CHEMBL1374283,FN,ACT,0.46000000834465027	CHEMBL1725120,FN,ACT,0.9599999785423279	CHEMBL1348194,TN,INACT,0.550000011920929	CHEMBL3196976,FN,ACT,0.8799999952316284	CHEMBL1520143,TP,ACT,0.9800000190734863	CHEMBL1453636,FN,ACT,0.6200000047683716	CHEMBL1486827,FN,ACT,0.7599999904632568	CHEMBL1707546,TN,INACT,0.5699999928474426	CHEMBL1993627,FN,ACT,0.6299999952316284	CHEMBL1698123,TP,ACT,0.9800000190734863	CHEMBL3190407,TN,INACT,0.2800000011920929	CHEMBL1715058,FN,ACT,0.3700000047683716	CHEMBL1732623,FN,ACT,0.8799999952316284	

