ImageNetInceptionV2 CHEMBL3254 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	259
Number of inactive compounds :	259
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3254_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3254_adam_0.0005_15_0.6/
---------------------------------
Training samples: 331
Validation samples: 104
--
Training Step: 1  | time: 38.745s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/331
[A[ATraining Step: 2  | total loss: [1m[32m0.68553[0m[0m | time: 47.543s
[2K
| Adam | epoch: 001 | loss: 0.68553 - acc: 0.4500 -- iter: 064/331
[A[ATraining Step: 3  | total loss: [1m[32m0.63906[0m[0m | time: 56.621s
[2K
| Adam | epoch: 001 | loss: 0.63906 - acc: 0.6187 -- iter: 096/331
[A[ATraining Step: 4  | total loss: [1m[32m0.62783[0m[0m | time: 65.322s
[2K
| Adam | epoch: 001 | loss: 0.62783 - acc: 0.6000 -- iter: 128/331
[A[ATraining Step: 5  | total loss: [1m[32m0.66330[0m[0m | time: 73.670s
[2K
| Adam | epoch: 001 | loss: 0.66330 - acc: 0.5308 -- iter: 160/331
[A[ATraining Step: 6  | total loss: [1m[32m0.64444[0m[0m | time: 82.159s
[2K
| Adam | epoch: 001 | loss: 0.64444 - acc: 0.5512 -- iter: 192/331
[A[ATraining Step: 7  | total loss: [1m[32m0.61281[0m[0m | time: 90.555s
[2K
| Adam | epoch: 001 | loss: 0.61281 - acc: 0.6517 -- iter: 224/331
[A[ATraining Step: 8  | total loss: [1m[32m0.64356[0m[0m | time: 98.994s
[2K
| Adam | epoch: 001 | loss: 0.64356 - acc: 0.6367 -- iter: 256/331
[A[ATraining Step: 9  | total loss: [1m[32m0.63500[0m[0m | time: 107.316s
[2K
| Adam | epoch: 001 | loss: 0.63500 - acc: 0.6801 -- iter: 288/331
[A[ATraining Step: 10  | total loss: [1m[32m0.61032[0m[0m | time: 116.518s
[2K
| Adam | epoch: 001 | loss: 0.61032 - acc: 0.6994 -- iter: 320/331
[A[ATraining Step: 11  | total loss: [1m[32m0.60678[0m[0m | time: 130.288s
[2K
| Adam | epoch: 001 | loss: 0.60678 - acc: 0.7234 | val_loss: 1.69579 - val_acc: 0.5000 -- iter: 331/331
--
Training Step: 12  | total loss: [1m[32m0.65763[0m[0m | time: 3.448s
[2K
| Adam | epoch: 002 | loss: 0.65763 - acc: 0.6842 -- iter: 032/331
[A[ATraining Step: 13  | total loss: [1m[32m0.52986[0m[0m | time: 12.185s
[2K
| Adam | epoch: 002 | loss: 0.52986 - acc: 0.7806 -- iter: 064/331
[A[ATraining Step: 14  | total loss: [1m[32m0.63839[0m[0m | time: 20.484s
[2K
| Adam | epoch: 002 | loss: 0.63839 - acc: 0.6786 -- iter: 096/331
[A[ATraining Step: 15  | total loss: [1m[32m0.61165[0m[0m | time: 29.014s
[2K
| Adam | epoch: 002 | loss: 0.61165 - acc: 0.7065 -- iter: 128/331
[A[ATraining Step: 16  | total loss: [1m[32m0.51065[0m[0m | time: 37.309s
[2K
| Adam | epoch: 002 | loss: 0.51065 - acc: 0.7814 -- iter: 160/331
[A[ATraining Step: 17  | total loss: [1m[32m0.42022[0m[0m | time: 45.753s
[2K
| Adam | epoch: 002 | loss: 0.42022 - acc: 0.8151 -- iter: 192/331
[A[ATraining Step: 18  | total loss: [1m[32m0.41358[0m[0m | time: 53.948s
[2K
| Adam | epoch: 002 | loss: 0.41358 - acc: 0.7926 -- iter: 224/331
[A[ATraining Step: 19  | total loss: [1m[32m0.42198[0m[0m | time: 62.139s
[2K
| Adam | epoch: 002 | loss: 0.42198 - acc: 0.7784 -- iter: 256/331
[A[ATraining Step: 20  | total loss: [1m[32m0.55239[0m[0m | time: 70.547s
[2K
| Adam | epoch: 002 | loss: 0.55239 - acc: 0.7291 -- iter: 288/331
[A[ATraining Step: 21  | total loss: [1m[32m0.55733[0m[0m | time: 78.917s
[2K
| Adam | epoch: 002 | loss: 0.55733 - acc: 0.7356 -- iter: 320/331
[A[ATraining Step: 22  | total loss: [1m[32m0.44165[0m[0m | time: 92.044s
[2K
| Adam | epoch: 002 | loss: 0.44165 - acc: 0.7962 | val_loss: 1.52704 - val_acc: 0.5000 -- iter: 331/331
--
Training Step: 23  | total loss: [1m[32m0.41835[0m[0m | time: 3.341s
[2K
| Adam | epoch: 003 | loss: 0.41835 - acc: 0.8100 -- iter: 032/331
[A[ATraining Step: 24  | total loss: [1m[32m0.38381[0m[0m | time: 6.744s
[2K
| Adam | epoch: 003 | loss: 0.38381 - acc: 0.8378 -- iter: 064/331
[A[ATraining Step: 25  | total loss: [1m[32m0.33494[0m[0m | time: 14.881s
[2K
| Adam | epoch: 003 | loss: 0.33494 - acc: 0.8573 -- iter: 096/331
[A[ATraining Step: 26  | total loss: [1m[32m0.32668[0m[0m | time: 23.094s
[2K
| Adam | epoch: 003 | loss: 0.32668 - acc: 0.8454 -- iter: 128/331
[A[ATraining Step: 27  | total loss: [1m[32m0.26887[0m[0m | time: 31.378s
[2K
| Adam | epoch: 003 | loss: 0.26887 - acc: 0.8771 -- iter: 160/331
[A[ATraining Step: 28  | total loss: [1m[32m0.26795[0m[0m | time: 39.540s
[2K
| Adam | epoch: 003 | loss: 0.26795 - acc: 0.8844 -- iter: 192/331
[A[ATraining Step: 29  | total loss: [1m[32m0.22306[0m[0m | time: 47.700s
[2K
| Adam | epoch: 003 | loss: 0.22306 - acc: 0.9125 -- iter: 224/331
[A[ATraining Step: 30  | total loss: [1m[32m0.19787[0m[0m | time: 55.999s
[2K
| Adam | epoch: 003 | loss: 0.19787 - acc: 0.9184 -- iter: 256/331
[A[ATraining Step: 31  | total loss: [1m[32m0.21648[0m[0m | time: 64.105s
[2K
| Adam | epoch: 003 | loss: 0.21648 - acc: 0.9084 -- iter: 288/331
[A[ATraining Step: 32  | total loss: [1m[32m0.19828[0m[0m | time: 72.129s
[2K
| Adam | epoch: 003 | loss: 0.19828 - acc: 0.9009 -- iter: 320/331
[A[ATraining Step: 33  | total loss: [1m[32m0.31608[0m[0m | time: 84.888s
[2K
| Adam | epoch: 003 | loss: 0.31608 - acc: 0.8609 | val_loss: 2.03775 - val_acc: 0.5000 -- iter: 331/331
--
Training Step: 34  | total loss: [1m[32m0.29760[0m[0m | time: 8.096s
[2K
| Adam | epoch: 004 | loss: 0.29760 - acc: 0.8572 -- iter: 032/331
[A[ATraining Step: 35  | total loss: [1m[32m0.35217[0m[0m | time: 11.326s
[2K
| Adam | epoch: 004 | loss: 0.35217 - acc: 0.8479 -- iter: 064/331
[A[ATraining Step: 36  | total loss: [1m[32m0.41807[0m[0m | time: 14.621s
[2K
| Adam | epoch: 004 | loss: 0.41807 - acc: 0.8604 -- iter: 096/331
[A[ATraining Step: 37  | total loss: [1m[32m0.35931[0m[0m | time: 22.669s
[2K
| Adam | epoch: 004 | loss: 0.35931 - acc: 0.8883 -- iter: 128/331
[A[ATraining Step: 38  | total loss: [1m[32m0.33367[0m[0m | time: 30.816s
[2K
| Adam | epoch: 004 | loss: 0.33367 - acc: 0.8857 -- iter: 160/331
[A[ATraining Step: 39  | total loss: [1m[32m0.32951[0m[0m | time: 38.969s
[2K
| Adam | epoch: 004 | loss: 0.32951 - acc: 0.8777 -- iter: 192/331
[A[ATraining Step: 40  | total loss: [1m[32m0.28480[0m[0m | time: 47.310s
[2K
| Adam | epoch: 004 | loss: 0.28480 - acc: 0.9006 -- iter: 224/331
[A[ATraining Step: 41  | total loss: [1m[32m0.24507[0m[0m | time: 55.367s
[2K
| Adam | epoch: 004 | loss: 0.24507 - acc: 0.9189 -- iter: 256/331
[A[ATraining Step: 42  | total loss: [1m[32m0.23798[0m[0m | time: 63.400s
[2K
| Adam | epoch: 004 | loss: 0.23798 - acc: 0.9166 -- iter: 288/331
[A[ATraining Step: 43  | total loss: [1m[32m0.20663[0m[0m | time: 71.557s
[2K
| Adam | epoch: 004 | loss: 0.20663 - acc: 0.9313 -- iter: 320/331
[A[ATraining Step: 44  | total loss: [1m[32m0.21833[0m[0m | time: 84.162s
[2K
| Adam | epoch: 004 | loss: 0.21833 - acc: 0.9270 | val_loss: 1.20247 - val_acc: 0.5000 -- iter: 331/331
--
Training Step: 45  | total loss: [1m[32m0.20193[0m[0m | time: 8.077s
[2K
| Adam | epoch: 005 | loss: 0.20193 - acc: 0.9288 -- iter: 032/331
[A[ATraining Step: 46  | total loss: [1m[32m0.18533[0m[0m | time: 16.197s
[2K
| Adam | epoch: 005 | loss: 0.18533 - acc: 0.9354 -- iter: 064/331
[A[ATraining Step: 47  | total loss: [1m[32m0.19101[0m[0m | time: 19.600s
[2K
| Adam | epoch: 005 | loss: 0.19101 - acc: 0.9307 -- iter: 096/331
[A[ATraining Step: 48  | total loss: [1m[32m0.17239[0m[0m | time: 22.849s
[2K
| Adam | epoch: 005 | loss: 0.17239 - acc: 0.9418 -- iter: 128/331
[A[ATraining Step: 49  | total loss: [1m[32m0.14920[0m[0m | time: 31.037s
[2K
| Adam | epoch: 005 | loss: 0.14920 - acc: 0.9510 -- iter: 160/331
[A[ATraining Step: 50  | total loss: [1m[32m0.18184[0m[0m | time: 39.192s
[2K
| Adam | epoch: 005 | loss: 0.18184 - acc: 0.9440 -- iter: 192/331
[A[ATraining Step: 51  | total loss: [1m[32m0.16432[0m[0m | time: 47.292s
[2K
| Adam | epoch: 005 | loss: 0.16432 - acc: 0.9526 -- iter: 224/331
[A[ATraining Step: 52  | total loss: [1m[32m0.16961[0m[0m | time: 55.500s
[2K
| Adam | epoch: 005 | loss: 0.16961 - acc: 0.9456 -- iter: 256/331
[A[ATraining Step: 53  | total loss: [1m[32m0.16626[0m[0m | time: 63.569s
[2K
| Adam | epoch: 005 | loss: 0.16626 - acc: 0.9398 -- iter: 288/331
[A[ATraining Step: 54  | total loss: [1m[32m0.17912[0m[0m | time: 71.760s
[2K
| Adam | epoch: 005 | loss: 0.17912 - acc: 0.9395 -- iter: 320/331
[A[ATraining Step: 55  | total loss: [1m[32m0.16925[0m[0m | time: 84.410s
[2K
| Adam | epoch: 005 | loss: 0.16925 - acc: 0.9437 | val_loss: 1.01025 - val_acc: 0.5865 -- iter: 331/331
--
Training Step: 56  | total loss: [1m[32m0.15742[0m[0m | time: 8.132s
[2K
| Adam | epoch: 006 | loss: 0.15742 - acc: 0.9472 -- iter: 032/331
[A[ATraining Step: 57  | total loss: [1m[32m0.18777[0m[0m | time: 16.372s
[2K
| Adam | epoch: 006 | loss: 0.18777 - acc: 0.9329 -- iter: 064/331
[A[ATraining Step: 58  | total loss: [1m[32m0.17450[0m[0m | time: 24.533s
[2K
| Adam | epoch: 006 | loss: 0.17450 - acc: 0.9378 -- iter: 096/331
[A[ATraining Step: 59  | total loss: [1m[32m0.19051[0m[0m | time: 27.906s
[2K
| Adam | epoch: 006 | loss: 0.19051 - acc: 0.9377 -- iter: 128/331
[A[ATraining Step: 60  | total loss: [1m[32m0.17261[0m[0m | time: 31.151s
[2K
| Adam | epoch: 006 | loss: 0.17261 - acc: 0.9460 -- iter: 160/331
[A[ATraining Step: 61  | total loss: [1m[32m0.15116[0m[0m | time: 39.287s
[2K
| Adam | epoch: 006 | loss: 0.15116 - acc: 0.9530 -- iter: 192/331
[A[ATraining Step: 62  | total loss: [1m[32m0.13727[0m[0m | time: 47.378s
[2K
| Adam | epoch: 006 | loss: 0.13727 - acc: 0.9591 -- iter: 224/331
[A[ATraining Step: 63  | total loss: [1m[32m0.14296[0m[0m | time: 55.408s
[2K
| Adam | epoch: 006 | loss: 0.14296 - acc: 0.9524 -- iter: 256/331
[A[ATraining Step: 64  | total loss: [1m[32m0.14228[0m[0m | time: 63.465s
[2K
| Adam | epoch: 006 | loss: 0.14228 - acc: 0.9544 -- iter: 288/331
[A[ATraining Step: 65  | total loss: [1m[32m0.12623[0m[0m | time: 71.539s
[2K
| Adam | epoch: 006 | loss: 0.12623 - acc: 0.9600 -- iter: 320/331
[A[ATraining Step: 66  | total loss: [1m[32m0.13644[0m[0m | time: 84.344s
[2K
| Adam | epoch: 006 | loss: 0.13644 - acc: 0.9573 | val_loss: 1.37887 - val_acc: 0.6250 -- iter: 331/331
--
Training Step: 67  | total loss: [1m[32m0.12565[0m[0m | time: 8.103s
[2K
| Adam | epoch: 007 | loss: 0.12565 - acc: 0.9587 -- iter: 032/331
[A[ATraining Step: 68  | total loss: [1m[32m0.11807[0m[0m | time: 16.153s
[2K
| Adam | epoch: 007 | loss: 0.11807 - acc: 0.9599 -- iter: 064/331
[A[ATraining Step: 69  | total loss: [1m[32m0.12885[0m[0m | time: 24.200s
[2K
| Adam | epoch: 007 | loss: 0.12885 - acc: 0.9572 -- iter: 096/331
[A[ATraining Step: 70  | total loss: [1m[32m0.15312[0m[0m | time: 32.309s
[2K
| Adam | epoch: 007 | loss: 0.15312 - acc: 0.9550 -- iter: 128/331
[A[ATraining Step: 71  | total loss: [1m[32m0.13814[0m[0m | time: 35.595s
[2K
| Adam | epoch: 007 | loss: 0.13814 - acc: 0.9601 -- iter: 160/331
[A[ATraining Step: 72  | total loss: [1m[32m0.12599[0m[0m | time: 38.867s
[2K
| Adam | epoch: 007 | loss: 0.12599 - acc: 0.9646 -- iter: 192/331
[A[ATraining Step: 73  | total loss: [1m[32m0.11275[0m[0m | time: 47.015s
[2K
| Adam | epoch: 007 | loss: 0.11275 - acc: 0.9685 -- iter: 224/331
[A[ATraining Step: 74  | total loss: [1m[32m0.10569[0m[0m | time: 55.182s
[2K
| Adam | epoch: 007 | loss: 0.10569 - acc: 0.9720 -- iter: 256/331
[A[ATraining Step: 75  | total loss: [1m[32m0.12813[0m[0m | time: 63.229s
[2K
| Adam | epoch: 007 | loss: 0.12813 - acc: 0.9547 -- iter: 288/331
[A[ATraining Step: 76  | total loss: [1m[32m0.14469[0m[0m | time: 71.280s
[2K
| Adam | epoch: 007 | loss: 0.14469 - acc: 0.9562 -- iter: 320/331
[A[ATraining Step: 77  | total loss: [1m[32m0.13133[0m[0m | time: 83.960s
[2K
| Adam | epoch: 007 | loss: 0.13133 - acc: 0.9608 | val_loss: 0.74438 - val_acc: 0.7115 -- iter: 331/331
--
Training Step: 78  | total loss: [1m[32m0.12285[0m[0m | time: 8.019s
[2K
| Adam | epoch: 008 | loss: 0.12285 - acc: 0.9649 -- iter: 032/331
[A[ATraining Step: 79  | total loss: [1m[32m0.11748[0m[0m | time: 16.319s
[2K
| Adam | epoch: 008 | loss: 0.11748 - acc: 0.9653 -- iter: 064/331
[A[ATraining Step: 80  | total loss: [1m[32m0.11352[0m[0m | time: 24.457s
[2K
| Adam | epoch: 008 | loss: 0.11352 - acc: 0.9689 -- iter: 096/331
[A[ATraining Step: 81  | total loss: [1m[32m0.12586[0m[0m | time: 32.607s
[2K
| Adam | epoch: 008 | loss: 0.12586 - acc: 0.9657 -- iter: 128/331
[A[ATraining Step: 82  | total loss: [1m[32m0.11915[0m[0m | time: 40.773s
[2K
| Adam | epoch: 008 | loss: 0.11915 - acc: 0.9660 -- iter: 160/331
[A[ATraining Step: 83  | total loss: [1m[32m0.11511[0m[0m | time: 44.057s
[2K
| Adam | epoch: 008 | loss: 0.11511 - acc: 0.9663 -- iter: 192/331
[A[ATraining Step: 84  | total loss: [1m[32m0.11935[0m[0m | time: 47.283s
[2K
| Adam | epoch: 008 | loss: 0.11935 - acc: 0.9606 -- iter: 224/331
[A[ATraining Step: 85  | total loss: [1m[32m0.11083[0m[0m | time: 55.256s
[2K
| Adam | epoch: 008 | loss: 0.11083 - acc: 0.9645 -- iter: 256/331
[A[ATraining Step: 86  | total loss: [1m[32m0.10249[0m[0m | time: 63.496s
[2K
| Adam | epoch: 008 | loss: 0.10249 - acc: 0.9681 -- iter: 288/331
[A[ATraining Step: 87  | total loss: [1m[32m0.16067[0m[0m | time: 71.375s
[2K
| Adam | epoch: 008 | loss: 0.16067 - acc: 0.9494 -- iter: 320/331
[A[ATraining Step: 88  | total loss: [1m[32m0.17005[0m[0m | time: 84.070s
[2K
| Adam | epoch: 008 | loss: 0.17005 - acc: 0.9482 | val_loss: 0.65129 - val_acc: 0.7212 -- iter: 331/331
--
Training Step: 89  | total loss: [1m[32m0.15952[0m[0m | time: 8.116s
[2K
| Adam | epoch: 009 | loss: 0.15952 - acc: 0.9502 -- iter: 032/331
[A[ATraining Step: 90  | total loss: [1m[32m0.17001[0m[0m | time: 16.089s
[2K
| Adam | epoch: 009 | loss: 0.17001 - acc: 0.9490 -- iter: 064/331
[A[ATraining Step: 91  | total loss: [1m[32m0.17548[0m[0m | time: 24.215s
[2K
| Adam | epoch: 009 | loss: 0.17548 - acc: 0.9447 -- iter: 096/331
[A[ATraining Step: 92  | total loss: [1m[32m0.16502[0m[0m | time: 32.189s
[2K
| Adam | epoch: 009 | loss: 0.16502 - acc: 0.9502 -- iter: 128/331
[A[ATraining Step: 93  | total loss: [1m[32m0.16094[0m[0m | time: 40.268s
[2K
| Adam | epoch: 009 | loss: 0.16094 - acc: 0.9490 -- iter: 160/331
[A[ATraining Step: 94  | total loss: [1m[32m0.15842[0m[0m | time: 48.159s
[2K
| Adam | epoch: 009 | loss: 0.15842 - acc: 0.9478 -- iter: 192/331
[A[ATraining Step: 95  | total loss: [1m[32m0.14625[0m[0m | time: 51.337s
[2K
| Adam | epoch: 009 | loss: 0.14625 - acc: 0.9530 -- iter: 224/331
[A[ATraining Step: 96  | total loss: [1m[32m0.15884[0m[0m | time: 54.693s
[2K
| Adam | epoch: 009 | loss: 0.15884 - acc: 0.9486 -- iter: 256/331
[A[ATraining Step: 97  | total loss: [1m[32m0.14880[0m[0m | time: 62.815s
[2K
| Adam | epoch: 009 | loss: 0.14880 - acc: 0.9538 -- iter: 288/331
[A[ATraining Step: 98  | total loss: [1m[32m0.14350[0m[0m | time: 70.902s
[2K
| Adam | epoch: 009 | loss: 0.14350 - acc: 0.9584 -- iter: 320/331
[A[ATraining Step: 99  | total loss: [1m[32m0.15422[0m[0m | time: 83.664s
[2K
| Adam | epoch: 009 | loss: 0.15422 - acc: 0.9563 | val_loss: 0.64716 - val_acc: 0.7404 -- iter: 331/331
--
Training Step: 100  | total loss: [1m[32m0.15659[0m[0m | time: 8.048s
[2K
| Adam | epoch: 010 | loss: 0.15659 - acc: 0.9482 -- iter: 032/331
[A[ATraining Step: 101  | total loss: [1m[32m0.15720[0m[0m | time: 15.944s
[2K
| Adam | epoch: 010 | loss: 0.15720 - acc: 0.9471 -- iter: 064/331
[A[ATraining Step: 102  | total loss: [1m[32m0.14629[0m[0m | time: 23.887s
[2K
| Adam | epoch: 010 | loss: 0.14629 - acc: 0.9524 -- iter: 096/331
[A[ATraining Step: 103  | total loss: [1m[32m0.15638[0m[0m | time: 31.958s
[2K
| Adam | epoch: 010 | loss: 0.15638 - acc: 0.9478 -- iter: 128/331
[A[ATraining Step: 104  | total loss: [1m[32m0.14387[0m[0m | time: 39.918s
[2K
| Adam | epoch: 010 | loss: 0.14387 - acc: 0.9530 -- iter: 160/331
[A[ATraining Step: 105  | total loss: [1m[32m0.13256[0m[0m | time: 47.901s
[2K
| Adam | epoch: 010 | loss: 0.13256 - acc: 0.9577 -- iter: 192/331
[A[ATraining Step: 106  | total loss: [1m[32m0.12136[0m[0m | time: 55.988s
[2K
| Adam | epoch: 010 | loss: 0.12136 - acc: 0.9619 -- iter: 224/331
[A[ATraining Step: 107  | total loss: [1m[32m0.11923[0m[0m | time: 59.281s
[2K
| Adam | epoch: 010 | loss: 0.11923 - acc: 0.9626 -- iter: 256/331
[A[ATraining Step: 108  | total loss: [1m[32m0.17865[0m[0m | time: 62.514s
[2K
| Adam | epoch: 010 | loss: 0.17865 - acc: 0.9573 -- iter: 288/331
[A[ATraining Step: 109  | total loss: [1m[32m0.19727[0m[0m | time: 70.651s
[2K
| Adam | epoch: 010 | loss: 0.19727 - acc: 0.9524 -- iter: 320/331
[A[ATraining Step: 110  | total loss: [1m[32m0.19813[0m[0m | time: 83.366s
[2K
| Adam | epoch: 010 | loss: 0.19813 - acc: 0.9510 | val_loss: 2.15025 - val_acc: 0.5481 -- iter: 331/331
--
Training Step: 111  | total loss: [1m[32m0.18641[0m[0m | time: 8.239s
[2K
| Adam | epoch: 011 | loss: 0.18641 - acc: 0.9527 -- iter: 032/331
[A[ATraining Step: 112  | total loss: [1m[32m0.22815[0m[0m | time: 16.177s
[2K
| Adam | epoch: 011 | loss: 0.22815 - acc: 0.9481 -- iter: 064/331
[A[ATraining Step: 113  | total loss: [1m[32m0.21607[0m[0m | time: 24.179s
[2K
| Adam | epoch: 011 | loss: 0.21607 - acc: 0.9501 -- iter: 096/331
[A[ATraining Step: 114  | total loss: [1m[32m0.19757[0m[0m | time: 32.329s
[2K
| Adam | epoch: 011 | loss: 0.19757 - acc: 0.9551 -- iter: 128/331
[A[ATraining Step: 115  | total loss: [1m[32m0.18302[0m[0m | time: 40.469s
[2K
| Adam | epoch: 011 | loss: 0.18302 - acc: 0.9565 -- iter: 160/331
[A[ATraining Step: 116  | total loss: [1m[32m0.17356[0m[0m | time: 48.518s
[2K
| Adam | epoch: 011 | loss: 0.17356 - acc: 0.9577 -- iter: 192/331
[A[ATraining Step: 117  | total loss: [1m[32m0.16281[0m[0m | time: 56.585s
[2K
| Adam | epoch: 011 | loss: 0.16281 - acc: 0.9619 -- iter: 224/331
[A[ATraining Step: 118  | total loss: [1m[32m0.15057[0m[0m | time: 64.664s
[2K
| Adam | epoch: 011 | loss: 0.15057 - acc: 0.9658 -- iter: 256/331
[A[ATraining Step: 119  | total loss: [1m[32m0.13884[0m[0m | time: 67.940s
[2K
| Adam | epoch: 011 | loss: 0.13884 - acc: 0.9692 -- iter: 288/331
[A[ATraining Step: 120  | total loss: [1m[32m0.12687[0m[0m | time: 71.167s
[2K
| Adam | epoch: 011 | loss: 0.12687 - acc: 0.9723 -- iter: 320/331
[A[ATraining Step: 121  | total loss: [1m[32m0.11522[0m[0m | time: 83.947s
[2K
| Adam | epoch: 011 | loss: 0.11522 - acc: 0.9750 | val_loss: 1.99898 - val_acc: 0.5673 -- iter: 331/331
--
Training Step: 122  | total loss: [1m[32m0.11285[0m[0m | time: 8.171s
[2K
| Adam | epoch: 012 | loss: 0.11285 - acc: 0.9744 -- iter: 032/331
[A[ATraining Step: 123  | total loss: [1m[32m0.12260[0m[0m | time: 16.241s
[2K
| Adam | epoch: 012 | loss: 0.12260 - acc: 0.9645 -- iter: 064/331
[A[ATraining Step: 124  | total loss: [1m[32m0.15490[0m[0m | time: 24.241s
[2K
| Adam | epoch: 012 | loss: 0.15490 - acc: 0.9618 -- iter: 096/331
[A[ATraining Step: 125  | total loss: [1m[32m0.14931[0m[0m | time: 32.257s
[2K
| Adam | epoch: 012 | loss: 0.14931 - acc: 0.9625 -- iter: 128/331
[A[ATraining Step: 126  | total loss: [1m[32m0.13609[0m[0m | time: 40.335s
[2K
| Adam | epoch: 012 | loss: 0.13609 - acc: 0.9662 -- iter: 160/331
[A[ATraining Step: 127  | total loss: [1m[32m0.14647[0m[0m | time: 48.337s
[2K
| Adam | epoch: 012 | loss: 0.14647 - acc: 0.9665 -- iter: 192/331
[A[ATraining Step: 128  | total loss: [1m[32m0.13562[0m[0m | time: 56.318s
[2K
| Adam | epoch: 012 | loss: 0.13562 - acc: 0.9698 -- iter: 224/331
[A[ATraining Step: 129  | total loss: [1m[32m0.15062[0m[0m | time: 64.318s
[2K
| Adam | epoch: 012 | loss: 0.15062 - acc: 0.9603 -- iter: 256/331
[A[ATraining Step: 130  | total loss: [1m[32m0.13819[0m[0m | time: 72.295s
[2K
| Adam | epoch: 012 | loss: 0.13819 - acc: 0.9643 -- iter: 288/331
[A[ATraining Step: 131  | total loss: [1m[32m0.12665[0m[0m | time: 75.593s
[2K
| Adam | epoch: 012 | loss: 0.12665 - acc: 0.9679 -- iter: 320/331
[A[ATraining Step: 132  | total loss: [1m[32m0.11599[0m[0m | time: 83.373s
[2K
| Adam | epoch: 012 | loss: 0.11599 - acc: 0.9711 | val_loss: 1.11339 - val_acc: 0.6731 -- iter: 331/331
--
Training Step: 133  | total loss: [1m[32m0.10684[0m[0m | time: 7.966s
[2K
| Adam | epoch: 013 | loss: 0.10684 - acc: 0.9740 -- iter: 032/331
[A[ATraining Step: 134  | total loss: [1m[32m0.10928[0m[0m | time: 16.038s
[2K
| Adam | epoch: 013 | loss: 0.10928 - acc: 0.9735 -- iter: 064/331
[A[ATraining Step: 135  | total loss: [1m[32m0.10938[0m[0m | time: 24.102s
[2K
| Adam | epoch: 013 | loss: 0.10938 - acc: 0.9730 -- iter: 096/331
[A[ATraining Step: 136  | total loss: [1m[32m0.12504[0m[0m | time: 32.093s
[2K
| Adam | epoch: 013 | loss: 0.12504 - acc: 0.9694 -- iter: 128/331
[A[ATraining Step: 137  | total loss: [1m[32m0.11839[0m[0m | time: 40.129s
[2K
| Adam | epoch: 013 | loss: 0.11839 - acc: 0.9694 -- iter: 160/331
[A[ATraining Step: 138  | total loss: [1m[32m0.11615[0m[0m | time: 48.058s
[2K
| Adam | epoch: 013 | loss: 0.11615 - acc: 0.9724 -- iter: 192/331
[A[ATraining Step: 139  | total loss: [1m[32m0.10996[0m[0m | time: 56.230s
[2K
| Adam | epoch: 013 | loss: 0.10996 - acc: 0.9752 -- iter: 224/331
[A[ATraining Step: 140  | total loss: [1m[32m0.11225[0m[0m | time: 64.268s
[2K
| Adam | epoch: 013 | loss: 0.11225 - acc: 0.9714 -- iter: 256/331
[A[ATraining Step: 141  | total loss: [1m[32m0.10420[0m[0m | time: 72.336s
[2K
| Adam | epoch: 013 | loss: 0.10420 - acc: 0.9743 -- iter: 288/331
[A[ATraining Step: 142  | total loss: [1m[32m0.10795[0m[0m | time: 80.441s
[2K
| Adam | epoch: 013 | loss: 0.10795 - acc: 0.9706 -- iter: 320/331
[A[ATraining Step: 143  | total loss: [1m[32m0.11798[0m[0m | time: 88.217s
[2K
| Adam | epoch: 013 | loss: 0.11798 - acc: 0.9673 | val_loss: 0.59375 - val_acc: 0.7788 -- iter: 331/331
--
Training Step: 144  | total loss: [1m[32m0.12933[0m[0m | time: 3.203s
[2K
| Adam | epoch: 014 | loss: 0.12933 - acc: 0.9615 -- iter: 032/331
[A[ATraining Step: 145  | total loss: [1m[32m0.13195[0m[0m | time: 11.218s
[2K
| Adam | epoch: 014 | loss: 0.13195 - acc: 0.9562 -- iter: 064/331
[A[ATraining Step: 146  | total loss: [1m[32m0.12835[0m[0m | time: 19.281s
[2K
| Adam | epoch: 014 | loss: 0.12835 - acc: 0.9575 -- iter: 096/331
[A[ATraining Step: 147  | total loss: [1m[32m0.11648[0m[0m | time: 27.324s
[2K
| Adam | epoch: 014 | loss: 0.11648 - acc: 0.9617 -- iter: 128/331
[A[ATraining Step: 148  | total loss: [1m[32m0.15854[0m[0m | time: 35.316s
[2K
| Adam | epoch: 014 | loss: 0.15854 - acc: 0.9562 -- iter: 160/331
[A[ATraining Step: 149  | total loss: [1m[32m0.14790[0m[0m | time: 43.166s
[2K
| Adam | epoch: 014 | loss: 0.14790 - acc: 0.9574 -- iter: 192/331
[A[ATraining Step: 150  | total loss: [1m[32m0.13581[0m[0m | time: 51.235s
[2K
| Adam | epoch: 014 | loss: 0.13581 - acc: 0.9617 -- iter: 224/331
[A[ATraining Step: 151  | total loss: [1m[32m0.13110[0m[0m | time: 59.176s
[2K
| Adam | epoch: 014 | loss: 0.13110 - acc: 0.9624 -- iter: 256/331
[A[ATraining Step: 152  | total loss: [1m[32m0.12485[0m[0m | time: 67.350s
[2K
| Adam | epoch: 014 | loss: 0.12485 - acc: 0.9630 -- iter: 288/331
[A[ATraining Step: 153  | total loss: [1m[32m0.12682[0m[0m | time: 75.594s
[2K
| Adam | epoch: 014 | loss: 0.12682 - acc: 0.9605 -- iter: 320/331
[A[ATraining Step: 154  | total loss: [1m[32m0.12925[0m[0m | time: 88.163s
[2K
| Adam | epoch: 014 | loss: 0.12925 - acc: 0.9613 | val_loss: 0.50134 - val_acc: 0.8173 -- iter: 331/331
--
Training Step: 155  | total loss: [1m[32m0.12416[0m[0m | time: 3.176s
[2K
| Adam | epoch: 015 | loss: 0.12416 - acc: 0.9652 -- iter: 032/331
[A[ATraining Step: 156  | total loss: [1m[32m0.11364[0m[0m | time: 6.342s
[2K
| Adam | epoch: 015 | loss: 0.11364 - acc: 0.9687 -- iter: 064/331
[A[ATraining Step: 157  | total loss: [1m[32m0.10403[0m[0m | time: 14.513s
[2K
| Adam | epoch: 015 | loss: 0.10403 - acc: 0.9718 -- iter: 096/331
[A[ATraining Step: 158  | total loss: [1m[32m0.10048[0m[0m | time: 22.513s
[2K
| Adam | epoch: 015 | loss: 0.10048 - acc: 0.9715 -- iter: 128/331
[A[ATraining Step: 159  | total loss: [1m[32m0.11756[0m[0m | time: 30.442s
[2K
| Adam | epoch: 015 | loss: 0.11756 - acc: 0.9681 -- iter: 160/331
[A[ATraining Step: 160  | total loss: [1m[32m0.10857[0m[0m | time: 38.454s
[2K
| Adam | epoch: 015 | loss: 0.10857 - acc: 0.9713 -- iter: 192/331
[A[ATraining Step: 161  | total loss: [1m[32m0.10122[0m[0m | time: 46.362s
[2K
| Adam | epoch: 015 | loss: 0.10122 - acc: 0.9742 -- iter: 224/331
[A[ATraining Step: 162  | total loss: [1m[32m0.10526[0m[0m | time: 54.218s
[2K
| Adam | epoch: 015 | loss: 0.10526 - acc: 0.9705 -- iter: 256/331
[A[ATraining Step: 163  | total loss: [1m[32m0.09821[0m[0m | time: 62.384s
[2K
| Adam | epoch: 015 | loss: 0.09821 - acc: 0.9734 -- iter: 288/331
[A[ATraining Step: 164  | total loss: [1m[32m0.09404[0m[0m | time: 70.301s
[2K
| Adam | epoch: 015 | loss: 0.09404 - acc: 0.9730 -- iter: 320/331
[A[ATraining Step: 165  | total loss: [1m[32m0.09003[0m[0m | time: 82.884s
[2K
| Adam | epoch: 015 | loss: 0.09003 - acc: 0.9725 | val_loss: 0.52697 - val_acc: 0.8365 -- iter: 331/331
--
Validation AUC:0.8764792899408284
Validation AUPRC:0.794780090540778
Test AUC:0.9308035714285714
Test AUPRC:0.9218321098362308
BestTestF1Score	0.83	0.66	0.82	0.74	0.94	45	16	40	3	0.2
BestTestMCCScore	0.83	0.66	0.82	0.74	0.94	45	16	40	3	0.2
BestTestAccuracyScore	0.86	0.75	0.88	0.89	0.83	40	5	51	8	0.63
BestValidationF1Score	0.86	0.72	0.85	0.77	0.98	51	15	37	1	0.2
BestValidationMCC	0.86	0.72	0.85	0.77	0.98	51	15	37	1	0.2
BestValidationAccuracy	0.85	0.69	0.85	0.85	0.85	44	8	44	8	0.63
TestPredictions (Threshold:0.2)
CHEMBL2088301,TN,INACT,0.0	CHEMBL3219617,TN,INACT,0.009999999776482582	CHEMBL3741782,TN,INACT,0.019999999552965164	CHEMBL3134338,TN,INACT,0.0	CHEMBL230436,FP,INACT,0.28999999165534973	CHEMBL462054,TP,ACT,0.9300000071525574	CHEMBL474940,TP,ACT,0.9599999785423279	CHEMBL3408924,TP,ACT,1.0	CHEMBL1830830,FP,INACT,0.3400000035762787	CHEMBL462097,TP,ACT,1.0	CHEMBL3415441,FN,ACT,0.05000000074505806	CHEMBL3633204,TN,INACT,0.0	CHEMBL121432,TP,ACT,0.38999998569488525	CHEMBL389940,TP,ACT,0.9300000071525574	CHEMBL464333,TP,ACT,0.9100000262260437	CHEMBL515250,TP,ACT,0.7900000214576721	CHEMBL2088312,TN,INACT,0.0	CHEMBL3408921,TP,ACT,1.0	CHEMBL459962,TP,ACT,0.6399999856948853	CHEMBL526897,TN,INACT,0.10999999940395355	CHEMBL3408927,TP,ACT,0.9200000166893005	CHEMBL1830135,TN,INACT,0.15000000596046448	CHEMBL489084,FP,INACT,0.46000000834465027	CHEMBL3633198,TN,INACT,0.0	CHEMBL515237,TP,ACT,0.36000001430511475	CHEMBL354971,FN,ACT,0.03999999910593033	CHEMBL3415442,FN,ACT,0.009999999776482582	CHEMBL1253762,FP,INACT,0.3199999928474426	CHEMBL3651131,TN,INACT,0.009999999776482582	CHEMBL390050,FP,INACT,0.949999988079071	CHEMBL2088299,TN,INACT,0.0	CHEMBL1939847,TP,ACT,0.9900000095367432	CHEMBL1950703,FP,INACT,0.7400000095367432	CHEMBL220264,TP,ACT,0.8700000047683716	CHEMBL3585822,TP,ACT,0.8999999761581421	CHEMBL469571,TN,INACT,0.009999999776482582	CHEMBL188061,TN,INACT,0.1899999976158142	CHEMBL3655320,TN,INACT,0.05999999865889549	CHEMBL460608,TP,ACT,0.9900000095367432	CHEMBL459543,TP,ACT,0.9700000286102295	CHEMBL3585837,TP,ACT,0.9800000190734863	CHEMBL424956,TN,INACT,0.009999999776482582	CHEMBL126,FP,INACT,0.8700000047683716	CHEMBL224191,TP,ACT,0.9900000095367432	CHEMBL3585813,TP,ACT,0.9800000190734863	CHEMBL3133243,FP,INACT,0.20999999344348907	CHEMBL3585820,TP,ACT,0.9599999785423279	CHEMBL508959,TP,ACT,0.8799999952316284	CHEMBL3771277,TN,INACT,0.009999999776482582	CHEMBL3651112,FP,INACT,0.20000000298023224	CHEMBL489086,TP,ACT,0.8700000047683716	CHEMBL425640,TP,ACT,0.3400000035762787	CHEMBL460610,TP,ACT,0.5199999809265137	CHEMBL2062881,TN,INACT,0.0	CHEMBL450824,TP,ACT,0.9800000190734863	CHEMBL466769,TN,INACT,0.10999999940395355	CHEMBL2088313,TN,INACT,0.0	CHEMBL187265,TN,INACT,0.10999999940395355	CHEMBL3297871,FP,INACT,0.3700000047683716	CHEMBL449889,TP,ACT,0.8100000023841858	CHEMBL186416,TN,INACT,0.0	CHEMBL472716,TP,ACT,0.8799999952316284	CHEMBL3408929,TP,ACT,0.9100000262260437	CHEMBL3124971,TN,INACT,0.0	CHEMBL1830818,TN,INACT,0.0	CHEMBL185895,TN,INACT,0.009999999776482582	CHEMBL199600,TN,INACT,0.019999999552965164	CHEMBL1938411,TP,ACT,0.9900000095367432	CHEMBL3133242,TN,INACT,0.07000000029802322	CHEMBL3651597,TN,INACT,0.0	CHEMBL500683,TN,INACT,0.019999999552965164	CHEMBL3797476,TN,INACT,0.03999999910593033	CHEMBL3770084,TN,INACT,0.009999999776482582	CHEMBL1830834,TN,INACT,0.07000000029802322	CHEMBL498683,TN,INACT,0.009999999776482582	CHEMBL3408909,TP,ACT,1.0	CHEMBL1939857,TP,ACT,0.9900000095367432	CHEMBL387736,TP,ACT,0.9900000095367432	CHEMBL223433,TP,ACT,0.9700000286102295	CHEMBL3261200,TN,INACT,0.029999999329447746	CHEMBL187801,TN,INACT,0.05000000074505806	CHEMBL1642684,FP,INACT,0.699999988079071	CHEMBL222368,TP,ACT,0.8700000047683716	CHEMBL1830129,FP,INACT,0.44999998807907104	CHEMBL17653,TP,ACT,1.0	CHEMBL3585824,TP,ACT,1.0	CHEMBL352538,TP,ACT,0.9900000095367432	CHEMBL511967,TN,INACT,0.0	CHEMBL1243059,TN,INACT,0.0	CHEMBL1388493,FP,INACT,0.9900000095367432	CHEMBL3585830,TP,ACT,0.8899999856948853	CHEMBL1939851,TP,ACT,0.9700000286102295	CHEMBL2177467,TN,INACT,0.07000000029802322	CHEMBL257057,FP,INACT,0.5	CHEMBL3408928,TP,ACT,0.6399999856948853	CHEMBL3655328,TN,INACT,0.03999999910593033	CHEMBL496281,TN,INACT,0.0	CHEMBL375807,TP,ACT,0.9900000095367432	CHEMBL3739683,FP,INACT,0.36000001430511475	CHEMBL3585819,TP,ACT,0.8899999856948853	CHEMBL3134358,TN,INACT,0.009999999776482582	CHEMBL3585825,TP,ACT,0.9800000190734863	CHEMBL1642682,FP,INACT,0.3100000023841858	CHEMBL375966,TP,ACT,0.3100000023841858	

