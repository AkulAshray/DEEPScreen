CNNModel CHEMBL286 adam 0.0005 15 256 0 0.6 False True
Number of active compounds :	1036
Number of inactive compounds :	691
---------------------------------
Run id: CNNModel_CHEMBL286_adam_0.0005_15_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL286_adam_0.0005_15_256_0.6_True/
---------------------------------
Training samples: 1104
Validation samples: 346
--
Training Step: 1  | time: 1.132s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1104
[A[ATraining Step: 2  | total loss: [1m[32m0.62394[0m[0m | time: 2.044s
[2K
| Adam | epoch: 001 | loss: 0.62394 - acc: 0.4219 -- iter: 0064/1104
[A[ATraining Step: 3  | total loss: [1m[32m0.67991[0m[0m | time: 3.025s
[2K
| Adam | epoch: 001 | loss: 0.67991 - acc: 0.5881 -- iter: 0096/1104
[A[ATraining Step: 4  | total loss: [1m[32m0.68868[0m[0m | time: 3.933s
[2K
| Adam | epoch: 001 | loss: 0.68868 - acc: 0.5689 -- iter: 0128/1104
[A[ATraining Step: 5  | total loss: [1m[32m0.69059[0m[0m | time: 4.667s
[2K
| Adam | epoch: 001 | loss: 0.69059 - acc: 0.5428 -- iter: 0160/1104
[A[ATraining Step: 6  | total loss: [1m[32m0.68491[0m[0m | time: 5.505s
[2K
| Adam | epoch: 001 | loss: 0.68491 - acc: 0.5957 -- iter: 0192/1104
[A[ATraining Step: 7  | total loss: [1m[32m0.66588[0m[0m | time: 6.395s
[2K
| Adam | epoch: 001 | loss: 0.66588 - acc: 0.6883 -- iter: 0224/1104
[A[ATraining Step: 8  | total loss: [1m[32m0.68214[0m[0m | time: 7.302s
[2K
| Adam | epoch: 001 | loss: 0.68214 - acc: 0.5999 -- iter: 0256/1104
[A[ATraining Step: 9  | total loss: [1m[32m0.67823[0m[0m | time: 8.181s
[2K
| Adam | epoch: 001 | loss: 0.67823 - acc: 0.5967 -- iter: 0288/1104
[A[ATraining Step: 10  | total loss: [1m[32m0.69601[0m[0m | time: 9.077s
[2K
| Adam | epoch: 001 | loss: 0.69601 - acc: 0.5640 -- iter: 0320/1104
[A[ATraining Step: 11  | total loss: [1m[32m0.65301[0m[0m | time: 9.965s
[2K
| Adam | epoch: 001 | loss: 0.65301 - acc: 0.6521 -- iter: 0352/1104
[A[ATraining Step: 12  | total loss: [1m[32m0.67800[0m[0m | time: 10.855s
[2K
| Adam | epoch: 001 | loss: 0.67800 - acc: 0.5977 -- iter: 0384/1104
[A[ATraining Step: 13  | total loss: [1m[32m0.68467[0m[0m | time: 11.667s
[2K
| Adam | epoch: 001 | loss: 0.68467 - acc: 0.5826 -- iter: 0416/1104
[A[ATraining Step: 14  | total loss: [1m[32m0.67006[0m[0m | time: 12.570s
[2K
| Adam | epoch: 001 | loss: 0.67006 - acc: 0.6127 -- iter: 0448/1104
[A[ATraining Step: 15  | total loss: [1m[32m0.65102[0m[0m | time: 13.594s
[2K
| Adam | epoch: 001 | loss: 0.65102 - acc: 0.6542 -- iter: 0480/1104
[A[ATraining Step: 16  | total loss: [1m[32m0.63866[0m[0m | time: 14.549s
[2K
| Adam | epoch: 001 | loss: 0.63866 - acc: 0.6784 -- iter: 0512/1104
[A[ATraining Step: 17  | total loss: [1m[32m0.65254[0m[0m | time: 15.233s
[2K
| Adam | epoch: 001 | loss: 0.65254 - acc: 0.6479 -- iter: 0544/1104
[A[ATraining Step: 18  | total loss: [1m[32m0.64890[0m[0m | time: 16.043s
[2K
| Adam | epoch: 001 | loss: 0.64890 - acc: 0.6508 -- iter: 0576/1104
[A[ATraining Step: 19  | total loss: [1m[32m0.64669[0m[0m | time: 16.904s
[2K
| Adam | epoch: 001 | loss: 0.64669 - acc: 0.6526 -- iter: 0608/1104
[A[ATraining Step: 20  | total loss: [1m[32m0.65318[0m[0m | time: 17.720s
[2K
| Adam | epoch: 001 | loss: 0.65318 - acc: 0.6437 -- iter: 0640/1104
[A[ATraining Step: 21  | total loss: [1m[32m0.66348[0m[0m | time: 18.545s
[2K
| Adam | epoch: 001 | loss: 0.66348 - acc: 0.6282 -- iter: 0672/1104
[A[ATraining Step: 22  | total loss: [1m[32m0.65577[0m[0m | time: 19.452s
[2K
| Adam | epoch: 001 | loss: 0.65577 - acc: 0.6366 -- iter: 0704/1104
[A[ATraining Step: 23  | total loss: [1m[32m0.68327[0m[0m | time: 20.291s
[2K
| Adam | epoch: 001 | loss: 0.68327 - acc: 0.5879 -- iter: 0736/1104
[A[ATraining Step: 24  | total loss: [1m[32m0.68100[0m[0m | time: 21.154s
[2K
| Adam | epoch: 001 | loss: 0.68100 - acc: 0.5895 -- iter: 0768/1104
[A[ATraining Step: 25  | total loss: [1m[32m0.67376[0m[0m | time: 21.998s
[2K
| Adam | epoch: 001 | loss: 0.67376 - acc: 0.6077 -- iter: 0800/1104
[A[ATraining Step: 26  | total loss: [1m[32m0.68080[0m[0m | time: 22.787s
[2K
| Adam | epoch: 001 | loss: 0.68080 - acc: 0.5792 -- iter: 0832/1104
[A[ATraining Step: 27  | total loss: [1m[32m0.68566[0m[0m | time: 23.694s
[2K
| Adam | epoch: 001 | loss: 0.68566 - acc: 0.5588 -- iter: 0864/1104
[A[ATraining Step: 28  | total loss: [1m[32m0.68680[0m[0m | time: 24.687s
[2K
| Adam | epoch: 001 | loss: 0.68680 - acc: 0.5519 -- iter: 0896/1104
[A[ATraining Step: 29  | total loss: [1m[32m0.68984[0m[0m | time: 25.623s
[2K
| Adam | epoch: 001 | loss: 0.68984 - acc: 0.5317 -- iter: 0928/1104
[A[ATraining Step: 30  | total loss: [1m[32m0.69186[0m[0m | time: 26.290s
[2K
| Adam | epoch: 001 | loss: 0.69186 - acc: 0.5168 -- iter: 0960/1104
[A[ATraining Step: 31  | total loss: [1m[32m0.69155[0m[0m | time: 27.107s
[2K
| Adam | epoch: 001 | loss: 0.69155 - acc: 0.5201 -- iter: 0992/1104
[A[ATraining Step: 32  | total loss: [1m[32m0.68939[0m[0m | time: 27.935s
[2K
| Adam | epoch: 001 | loss: 0.68939 - acc: 0.5508 -- iter: 1024/1104
[A[ATraining Step: 33  | total loss: [1m[32m0.68779[0m[0m | time: 28.813s
[2K
| Adam | epoch: 001 | loss: 0.68779 - acc: 0.5739 -- iter: 1056/1104
[A[ATraining Step: 34  | total loss: [1m[32m0.68629[0m[0m | time: 29.727s
[2K
| Adam | epoch: 001 | loss: 0.68629 - acc: 0.5983 -- iter: 1088/1104
[A[ATraining Step: 35  | total loss: [1m[32m0.68729[0m[0m | time: 31.854s
[2K
| Adam | epoch: 001 | loss: 0.68729 - acc: 0.5842 | val_loss: 0.68520 - val_acc: 0.6127 -- iter: 1104/1104
--
Training Step: 36  | total loss: [1m[32m0.68607[0m[0m | time: 0.491s
[2K
| Adam | epoch: 002 | loss: 0.68607 - acc: 0.6054 -- iter: 0032/1104
[A[ATraining Step: 37  | total loss: [1m[32m0.68476[0m[0m | time: 1.300s
[2K
| Adam | epoch: 002 | loss: 0.68476 - acc: 0.6218 -- iter: 0064/1104
[A[ATraining Step: 38  | total loss: [1m[32m0.68410[0m[0m | time: 2.153s
[2K
| Adam | epoch: 002 | loss: 0.68410 - acc: 0.6285 -- iter: 0096/1104
[A[ATraining Step: 39  | total loss: [1m[32m0.68442[0m[0m | time: 3.202s
[2K
| Adam | epoch: 002 | loss: 0.68442 - acc: 0.6219 -- iter: 0128/1104
[A[ATraining Step: 40  | total loss: [1m[32m0.68451[0m[0m | time: 4.154s
[2K
| Adam | epoch: 002 | loss: 0.68451 - acc: 0.6166 -- iter: 0160/1104
[A[ATraining Step: 41  | total loss: [1m[32m0.68370[0m[0m | time: 4.817s
[2K
| Adam | epoch: 002 | loss: 0.68370 - acc: 0.6181 -- iter: 0192/1104
[A[ATraining Step: 42  | total loss: [1m[32m0.68541[0m[0m | time: 5.622s
[2K
| Adam | epoch: 002 | loss: 0.68541 - acc: 0.5969 -- iter: 0224/1104
[A[ATraining Step: 43  | total loss: [1m[32m0.68622[0m[0m | time: 6.474s
[2K
| Adam | epoch: 002 | loss: 0.68622 - acc: 0.5853 -- iter: 0256/1104
[A[ATraining Step: 44  | total loss: [1m[32m0.68457[0m[0m | time: 7.315s
[2K
| Adam | epoch: 002 | loss: 0.68457 - acc: 0.5922 -- iter: 0288/1104
[A[ATraining Step: 45  | total loss: [1m[32m0.68553[0m[0m | time: 8.160s
[2K
| Adam | epoch: 002 | loss: 0.68553 - acc: 0.5818 -- iter: 0320/1104
[A[ATraining Step: 46  | total loss: [1m[32m0.68311[0m[0m | time: 8.999s
[2K
| Adam | epoch: 002 | loss: 0.68311 - acc: 0.5890 -- iter: 0352/1104
[A[ATraining Step: 47  | total loss: [1m[32m0.67735[0m[0m | time: 9.887s
[2K
| Adam | epoch: 002 | loss: 0.67735 - acc: 0.6102 -- iter: 0384/1104
[A[ATraining Step: 48  | total loss: [1m[32m0.67967[0m[0m | time: 10.772s
[2K
| Adam | epoch: 002 | loss: 0.67967 - acc: 0.5976 -- iter: 0416/1104
[A[ATraining Step: 49  | total loss: [1m[32m0.68269[0m[0m | time: 11.634s
[2K
| Adam | epoch: 002 | loss: 0.68269 - acc: 0.5871 -- iter: 0448/1104
[A[ATraining Step: 50  | total loss: [1m[32m0.68755[0m[0m | time: 12.436s
[2K
| Adam | epoch: 002 | loss: 0.68755 - acc: 0.5687 -- iter: 0480/1104
[A[ATraining Step: 51  | total loss: [1m[32m0.68006[0m[0m | time: 13.447s
[2K
| Adam | epoch: 002 | loss: 0.68006 - acc: 0.5868 -- iter: 0512/1104
[A[ATraining Step: 52  | total loss: [1m[32m0.67565[0m[0m | time: 14.413s
[2K
| Adam | epoch: 002 | loss: 0.67565 - acc: 0.5973 -- iter: 0544/1104
[A[ATraining Step: 53  | total loss: [1m[32m0.66862[0m[0m | time: 15.181s
[2K
| Adam | epoch: 002 | loss: 0.66862 - acc: 0.6106 -- iter: 0576/1104
[A[ATraining Step: 54  | total loss: [1m[32m0.67992[0m[0m | time: 16.011s
[2K
| Adam | epoch: 002 | loss: 0.67992 - acc: 0.5854 -- iter: 0608/1104
[A[ATraining Step: 55  | total loss: [1m[32m0.68815[0m[0m | time: 16.870s
[2K
| Adam | epoch: 002 | loss: 0.68815 - acc: 0.5688 -- iter: 0640/1104
[A[ATraining Step: 56  | total loss: [1m[32m0.68752[0m[0m | time: 17.695s
[2K
| Adam | epoch: 002 | loss: 0.68752 - acc: 0.5679 -- iter: 0672/1104
[A[ATraining Step: 57  | total loss: [1m[32m0.67985[0m[0m | time: 18.615s
[2K
| Adam | epoch: 002 | loss: 0.67985 - acc: 0.5845 -- iter: 0704/1104
[A[ATraining Step: 58  | total loss: [1m[32m0.68175[0m[0m | time: 19.435s
[2K
| Adam | epoch: 002 | loss: 0.68175 - acc: 0.5772 -- iter: 0736/1104
[A[ATraining Step: 59  | total loss: [1m[32m0.67612[0m[0m | time: 20.294s
[2K
| Adam | epoch: 002 | loss: 0.67612 - acc: 0.5920 -- iter: 0768/1104
[A[ATraining Step: 60  | total loss: [1m[32m0.67698[0m[0m | time: 21.122s
[2K
| Adam | epoch: 002 | loss: 0.67698 - acc: 0.5881 -- iter: 0800/1104
[A[ATraining Step: 61  | total loss: [1m[32m0.68305[0m[0m | time: 21.984s
[2K
| Adam | epoch: 002 | loss: 0.68305 - acc: 0.5685 -- iter: 0832/1104
[A[ATraining Step: 62  | total loss: [1m[32m0.68202[0m[0m | time: 22.787s
[2K
| Adam | epoch: 002 | loss: 0.68202 - acc: 0.5717 -- iter: 0864/1104
[A[ATraining Step: 63  | total loss: [1m[32m0.68111[0m[0m | time: 23.672s
[2K
| Adam | epoch: 002 | loss: 0.68111 - acc: 0.5745 -- iter: 0896/1104
[A[ATraining Step: 64  | total loss: [1m[32m0.67789[0m[0m | time: 24.661s
[2K
| Adam | epoch: 002 | loss: 0.67789 - acc: 0.5847 -- iter: 0928/1104
[A[ATraining Step: 65  | total loss: [1m[32m0.67738[0m[0m | time: 25.622s
[2K
| Adam | epoch: 002 | loss: 0.67738 - acc: 0.5858 -- iter: 0960/1104
[A[ATraining Step: 66  | total loss: [1m[32m0.67354[0m[0m | time: 26.289s
[2K
| Adam | epoch: 002 | loss: 0.67354 - acc: 0.5982 -- iter: 0992/1104
[A[ATraining Step: 67  | total loss: [1m[32m0.67222[0m[0m | time: 27.191s
[2K
| Adam | epoch: 002 | loss: 0.67222 - acc: 0.6014 -- iter: 1024/1104
[A[ATraining Step: 68  | total loss: [1m[32m0.67298[0m[0m | time: 28.048s
[2K
| Adam | epoch: 002 | loss: 0.67298 - acc: 0.5968 -- iter: 1056/1104
[A[ATraining Step: 69  | total loss: [1m[32m0.67235[0m[0m | time: 28.872s
[2K
| Adam | epoch: 002 | loss: 0.67235 - acc: 0.5965 -- iter: 1088/1104
[A[ATraining Step: 70  | total loss: [1m[32m0.66876[0m[0m | time: 31.153s
[2K
| Adam | epoch: 002 | loss: 0.66876 - acc: 0.6034 | val_loss: 0.65740 - val_acc: 0.6127 -- iter: 1104/1104
--
Training Step: 71  | total loss: [1m[32m0.66333[0m[0m | time: 0.420s
[2K
| Adam | epoch: 003 | loss: 0.66333 - acc: 0.6129 -- iter: 0032/1104
[A[ATraining Step: 72  | total loss: [1m[32m0.66658[0m[0m | time: 0.876s
[2K
| Adam | epoch: 003 | loss: 0.66658 - acc: 0.6073 -- iter: 0064/1104
[A[ATraining Step: 73  | total loss: [1m[32m0.67098[0m[0m | time: 1.695s
[2K
| Adam | epoch: 003 | loss: 0.67098 - acc: 0.6023 -- iter: 0096/1104
[A[ATraining Step: 74  | total loss: [1m[32m0.66978[0m[0m | time: 2.490s
[2K
| Adam | epoch: 003 | loss: 0.66978 - acc: 0.6048 -- iter: 0128/1104
[A[ATraining Step: 75  | total loss: [1m[32m0.65401[0m[0m | time: 3.371s
[2K
| Adam | epoch: 003 | loss: 0.65401 - acc: 0.6307 -- iter: 0160/1104
[A[ATraining Step: 76  | total loss: [1m[32m0.65121[0m[0m | time: 4.341s
[2K
| Adam | epoch: 003 | loss: 0.65121 - acc: 0.6334 -- iter: 0192/1104
[A[ATraining Step: 77  | total loss: [1m[32m0.65278[0m[0m | time: 5.294s
[2K
| Adam | epoch: 003 | loss: 0.65278 - acc: 0.6292 -- iter: 0224/1104
[A[ATraining Step: 78  | total loss: [1m[32m0.66719[0m[0m | time: 6.012s
[2K
| Adam | epoch: 003 | loss: 0.66719 - acc: 0.6092 -- iter: 0256/1104
[A[ATraining Step: 79  | total loss: [1m[32m0.66944[0m[0m | time: 6.822s
[2K
| Adam | epoch: 003 | loss: 0.66944 - acc: 0.6043 -- iter: 0288/1104
[A[ATraining Step: 80  | total loss: [1m[32m0.66549[0m[0m | time: 7.672s
[2K
| Adam | epoch: 003 | loss: 0.66549 - acc: 0.6096 -- iter: 0320/1104
[A[ATraining Step: 81  | total loss: [1m[32m0.66332[0m[0m | time: 8.546s
[2K
| Adam | epoch: 003 | loss: 0.66332 - acc: 0.6144 -- iter: 0352/1104
[A[ATraining Step: 82  | total loss: [1m[32m0.66342[0m[0m | time: 9.389s
[2K
| Adam | epoch: 003 | loss: 0.66342 - acc: 0.6123 -- iter: 0384/1104
[A[ATraining Step: 83  | total loss: [1m[32m0.66336[0m[0m | time: 10.261s
[2K
| Adam | epoch: 003 | loss: 0.66336 - acc: 0.6104 -- iter: 0416/1104
[A[ATraining Step: 84  | total loss: [1m[32m0.65982[0m[0m | time: 11.082s
[2K
| Adam | epoch: 003 | loss: 0.65982 - acc: 0.6213 -- iter: 0448/1104
[A[ATraining Step: 85  | total loss: [1m[32m0.65664[0m[0m | time: 11.934s
[2K
| Adam | epoch: 003 | loss: 0.65664 - acc: 0.6310 -- iter: 0480/1104
[A[ATraining Step: 86  | total loss: [1m[32m0.65293[0m[0m | time: 12.749s
[2K
| Adam | epoch: 003 | loss: 0.65293 - acc: 0.6398 -- iter: 0512/1104
[A[ATraining Step: 87  | total loss: [1m[32m0.65464[0m[0m | time: 13.533s
[2K
| Adam | epoch: 003 | loss: 0.65464 - acc: 0.6352 -- iter: 0544/1104
[A[ATraining Step: 88  | total loss: [1m[32m0.65407[0m[0m | time: 14.567s
[2K
| Adam | epoch: 003 | loss: 0.65407 - acc: 0.6342 -- iter: 0576/1104
[A[ATraining Step: 89  | total loss: [1m[32m0.64732[0m[0m | time: 15.525s
[2K
| Adam | epoch: 003 | loss: 0.64732 - acc: 0.6458 -- iter: 0608/1104
[A[ATraining Step: 90  | total loss: [1m[32m0.64982[0m[0m | time: 16.347s
[2K
| Adam | epoch: 003 | loss: 0.64982 - acc: 0.6406 -- iter: 0640/1104
[A[ATraining Step: 91  | total loss: [1m[32m0.64986[0m[0m | time: 17.059s
[2K
| Adam | epoch: 003 | loss: 0.64986 - acc: 0.6390 -- iter: 0672/1104
[A[ATraining Step: 92  | total loss: [1m[32m0.66037[0m[0m | time: 17.881s
[2K
| Adam | epoch: 003 | loss: 0.66037 - acc: 0.6220 -- iter: 0704/1104
[A[ATraining Step: 93  | total loss: [1m[32m0.66017[0m[0m | time: 18.745s
[2K
| Adam | epoch: 003 | loss: 0.66017 - acc: 0.6223 -- iter: 0736/1104
[A[ATraining Step: 94  | total loss: [1m[32m0.66473[0m[0m | time: 19.648s
[2K
| Adam | epoch: 003 | loss: 0.66473 - acc: 0.6132 -- iter: 0768/1104
[A[ATraining Step: 95  | total loss: [1m[32m0.66673[0m[0m | time: 20.488s
[2K
| Adam | epoch: 003 | loss: 0.66673 - acc: 0.6050 -- iter: 0800/1104
[A[ATraining Step: 96  | total loss: [1m[32m0.66265[0m[0m | time: 21.334s
[2K
| Adam | epoch: 003 | loss: 0.66265 - acc: 0.6101 -- iter: 0832/1104
[A[ATraining Step: 97  | total loss: [1m[32m0.66047[0m[0m | time: 22.199s
[2K
| Adam | epoch: 003 | loss: 0.66047 - acc: 0.6116 -- iter: 0864/1104
[A[ATraining Step: 98  | total loss: [1m[32m0.65861[0m[0m | time: 23.051s
[2K
| Adam | epoch: 003 | loss: 0.65861 - acc: 0.6129 -- iter: 0896/1104
[A[ATraining Step: 99  | total loss: [1m[32m0.65653[0m[0m | time: 23.848s
[2K
| Adam | epoch: 003 | loss: 0.65653 - acc: 0.6173 -- iter: 0928/1104
[A[ATraining Step: 100  | total loss: [1m[32m0.65637[0m[0m | time: 24.811s
[2K
| Adam | epoch: 003 | loss: 0.65637 - acc: 0.6149 -- iter: 0960/1104
[A[ATraining Step: 101  | total loss: [1m[32m0.65754[0m[0m | time: 25.811s
[2K
| Adam | epoch: 003 | loss: 0.65754 - acc: 0.6066 -- iter: 0992/1104
[A[ATraining Step: 102  | total loss: [1m[32m0.65553[0m[0m | time: 26.726s
[2K
| Adam | epoch: 003 | loss: 0.65553 - acc: 0.6115 -- iter: 1024/1104
[A[ATraining Step: 103  | total loss: [1m[32m0.66168[0m[0m | time: 27.468s
[2K
| Adam | epoch: 003 | loss: 0.66168 - acc: 0.5941 -- iter: 1056/1104
[A[ATraining Step: 104  | total loss: [1m[32m0.66138[0m[0m | time: 28.341s
[2K
| Adam | epoch: 003 | loss: 0.66138 - acc: 0.5910 -- iter: 1088/1104
[A[ATraining Step: 105  | total loss: [1m[32m0.66082[0m[0m | time: 30.655s
[2K
| Adam | epoch: 003 | loss: 0.66082 - acc: 0.5944 | val_loss: 0.63331 - val_acc: 0.6127 -- iter: 1104/1104
--
Training Step: 106  | total loss: [1m[32m0.66072[0m[0m | time: 0.847s
[2K
| Adam | epoch: 004 | loss: 0.66072 - acc: 0.5912 -- iter: 0032/1104
[A[ATraining Step: 107  | total loss: [1m[32m0.66315[0m[0m | time: 1.314s
[2K
| Adam | epoch: 004 | loss: 0.66315 - acc: 0.5852 -- iter: 0064/1104
[A[ATraining Step: 108  | total loss: [1m[32m0.66066[0m[0m | time: 1.760s
[2K
| Adam | epoch: 004 | loss: 0.66066 - acc: 0.5829 -- iter: 0096/1104
[A[ATraining Step: 109  | total loss: [1m[32m0.65817[0m[0m | time: 2.631s
[2K
| Adam | epoch: 004 | loss: 0.65817 - acc: 0.5809 -- iter: 0128/1104
[A[ATraining Step: 110  | total loss: [1m[32m0.65811[0m[0m | time: 3.463s
[2K
| Adam | epoch: 004 | loss: 0.65811 - acc: 0.5759 -- iter: 0160/1104
[A[ATraining Step: 111  | total loss: [1m[32m0.65772[0m[0m | time: 4.421s
[2K
| Adam | epoch: 004 | loss: 0.65772 - acc: 0.5746 -- iter: 0192/1104
[A[ATraining Step: 112  | total loss: [1m[32m0.65526[0m[0m | time: 5.396s
[2K
| Adam | epoch: 004 | loss: 0.65526 - acc: 0.5734 -- iter: 0224/1104
[A[ATraining Step: 113  | total loss: [1m[32m0.64788[0m[0m | time: 6.365s
[2K
| Adam | epoch: 004 | loss: 0.64788 - acc: 0.5817 -- iter: 0256/1104
[A[ATraining Step: 114  | total loss: [1m[32m0.64570[0m[0m | time: 7.106s
[2K
| Adam | epoch: 004 | loss: 0.64570 - acc: 0.5829 -- iter: 0288/1104
[A[ATraining Step: 115  | total loss: [1m[32m0.64473[0m[0m | time: 7.914s
[2K
| Adam | epoch: 004 | loss: 0.64473 - acc: 0.5839 -- iter: 0320/1104
[A[ATraining Step: 116  | total loss: [1m[32m0.64927[0m[0m | time: 8.720s
[2K
| Adam | epoch: 004 | loss: 0.64927 - acc: 0.5724 -- iter: 0352/1104
[A[ATraining Step: 117  | total loss: [1m[32m0.64499[0m[0m | time: 9.611s
[2K
| Adam | epoch: 004 | loss: 0.64499 - acc: 0.5777 -- iter: 0384/1104
[A[ATraining Step: 118  | total loss: [1m[32m0.64821[0m[0m | time: 10.489s
[2K
| Adam | epoch: 004 | loss: 0.64821 - acc: 0.5762 -- iter: 0416/1104
[A[ATraining Step: 119  | total loss: [1m[32m0.64732[0m[0m | time: 11.324s
[2K
| Adam | epoch: 004 | loss: 0.64732 - acc: 0.5967 -- iter: 0448/1104
[A[ATraining Step: 120  | total loss: [1m[32m0.64054[0m[0m | time: 12.181s
[2K
| Adam | epoch: 004 | loss: 0.64054 - acc: 0.6089 -- iter: 0480/1104
[A[ATraining Step: 121  | total loss: [1m[32m0.64192[0m[0m | time: 12.993s
[2K
| Adam | epoch: 004 | loss: 0.64192 - acc: 0.6074 -- iter: 0512/1104
[A[ATraining Step: 122  | total loss: [1m[32m0.63854[0m[0m | time: 13.929s
[2K
| Adam | epoch: 004 | loss: 0.63854 - acc: 0.6091 -- iter: 0544/1104
[A[ATraining Step: 123  | total loss: [1m[32m0.62329[0m[0m | time: 14.761s
[2K
| Adam | epoch: 004 | loss: 0.62329 - acc: 0.6232 -- iter: 0576/1104
[A[ATraining Step: 124  | total loss: [1m[32m0.62359[0m[0m | time: 15.658s
[2K
| Adam | epoch: 004 | loss: 0.62359 - acc: 0.6171 -- iter: 0608/1104
[A[ATraining Step: 125  | total loss: [1m[32m0.61691[0m[0m | time: 16.618s
[2K
| Adam | epoch: 004 | loss: 0.61691 - acc: 0.6304 -- iter: 0640/1104
[A[ATraining Step: 126  | total loss: [1m[32m0.61207[0m[0m | time: 17.603s
[2K
| Adam | epoch: 004 | loss: 0.61207 - acc: 0.6486 -- iter: 0672/1104
[A[ATraining Step: 127  | total loss: [1m[32m0.61023[0m[0m | time: 18.266s
[2K
| Adam | epoch: 004 | loss: 0.61023 - acc: 0.6557 -- iter: 0704/1104
[A[ATraining Step: 128  | total loss: [1m[32m0.59915[0m[0m | time: 19.070s
[2K
| Adam | epoch: 004 | loss: 0.59915 - acc: 0.6713 -- iter: 0736/1104
[A[ATraining Step: 129  | total loss: [1m[32m0.58953[0m[0m | time: 19.968s
[2K
| Adam | epoch: 004 | loss: 0.58953 - acc: 0.6730 -- iter: 0768/1104
[A[ATraining Step: 130  | total loss: [1m[32m0.56395[0m[0m | time: 20.821s
[2K
| Adam | epoch: 004 | loss: 0.56395 - acc: 0.6900 -- iter: 0800/1104
[A[ATraining Step: 131  | total loss: [1m[32m0.54352[0m[0m | time: 21.684s
[2K
| Adam | epoch: 004 | loss: 0.54352 - acc: 0.7054 -- iter: 0832/1104
[A[ATraining Step: 132  | total loss: [1m[32m0.56110[0m[0m | time: 22.516s
[2K
| Adam | epoch: 004 | loss: 0.56110 - acc: 0.6880 -- iter: 0864/1104
[A[ATraining Step: 133  | total loss: [1m[32m0.56657[0m[0m | time: 23.411s
[2K
| Adam | epoch: 004 | loss: 0.56657 - acc: 0.6848 -- iter: 0896/1104
[A[ATraining Step: 134  | total loss: [1m[32m0.57628[0m[0m | time: 24.293s
[2K
| Adam | epoch: 004 | loss: 0.57628 - acc: 0.6788 -- iter: 0928/1104
[A[ATraining Step: 135  | total loss: [1m[32m0.59208[0m[0m | time: 25.177s
[2K
| Adam | epoch: 004 | loss: 0.59208 - acc: 0.6641 -- iter: 0960/1104
[A[ATraining Step: 136  | total loss: [1m[32m0.61644[0m[0m | time: 25.990s
[2K
| Adam | epoch: 004 | loss: 0.61644 - acc: 0.6352 -- iter: 0992/1104
[A[ATraining Step: 137  | total loss: [1m[32m0.63223[0m[0m | time: 26.836s
[2K
| Adam | epoch: 004 | loss: 0.63223 - acc: 0.6123 -- iter: 1024/1104
[A[ATraining Step: 138  | total loss: [1m[32m0.65090[0m[0m | time: 27.805s
[2K
| Adam | epoch: 004 | loss: 0.65090 - acc: 0.5698 -- iter: 1056/1104
[A[ATraining Step: 139  | total loss: [1m[32m0.65100[0m[0m | time: 28.841s
[2K
| Adam | epoch: 004 | loss: 0.65100 - acc: 0.5847 -- iter: 1088/1104
[A[ATraining Step: 140  | total loss: [1m[32m0.65271[0m[0m | time: 30.965s
[2K
| Adam | epoch: 004 | loss: 0.65271 - acc: 0.5918 | val_loss: 0.57664 - val_acc: 0.7861 -- iter: 1104/1104
--
Training Step: 141  | total loss: [1m[32m0.64614[0m[0m | time: 0.822s
[2K
| Adam | epoch: 005 | loss: 0.64614 - acc: 0.6170 -- iter: 0032/1104
[A[ATraining Step: 142  | total loss: [1m[32m0.63487[0m[0m | time: 1.690s
[2K
| Adam | epoch: 005 | loss: 0.63487 - acc: 0.6397 -- iter: 0064/1104
[A[ATraining Step: 143  | total loss: [1m[32m0.64072[0m[0m | time: 2.178s
[2K
| Adam | epoch: 005 | loss: 0.64072 - acc: 0.6257 -- iter: 0096/1104
[A[ATraining Step: 144  | total loss: [1m[32m0.63723[0m[0m | time: 2.655s
[2K
| Adam | epoch: 005 | loss: 0.63723 - acc: 0.6194 -- iter: 0128/1104
[A[ATraining Step: 145  | total loss: [1m[32m0.63397[0m[0m | time: 3.564s
[2K
| Adam | epoch: 005 | loss: 0.63397 - acc: 0.6137 -- iter: 0160/1104
[A[ATraining Step: 146  | total loss: [1m[32m0.62672[0m[0m | time: 4.414s
[2K
| Adam | epoch: 005 | loss: 0.62672 - acc: 0.6149 -- iter: 0192/1104
[A[ATraining Step: 147  | total loss: [1m[32m0.62888[0m[0m | time: 5.326s
[2K
| Adam | epoch: 005 | loss: 0.62888 - acc: 0.6065 -- iter: 0224/1104
[A[ATraining Step: 148  | total loss: [1m[32m0.63462[0m[0m | time: 6.247s
[2K
| Adam | epoch: 005 | loss: 0.63462 - acc: 0.5958 -- iter: 0256/1104
[A[ATraining Step: 149  | total loss: [1m[32m0.62241[0m[0m | time: 7.239s
[2K
| Adam | epoch: 005 | loss: 0.62241 - acc: 0.6019 -- iter: 0288/1104
[A[ATraining Step: 150  | total loss: [1m[32m0.61316[0m[0m | time: 8.206s
[2K
| Adam | epoch: 005 | loss: 0.61316 - acc: 0.6229 -- iter: 0320/1104
[A[ATraining Step: 151  | total loss: [1m[32m0.61118[0m[0m | time: 8.877s
[2K
| Adam | epoch: 005 | loss: 0.61118 - acc: 0.6357 -- iter: 0352/1104
[A[ATraining Step: 152  | total loss: [1m[32m0.60505[0m[0m | time: 9.711s
[2K
| Adam | epoch: 005 | loss: 0.60505 - acc: 0.6502 -- iter: 0384/1104
[A[ATraining Step: 153  | total loss: [1m[32m0.60296[0m[0m | time: 10.572s
[2K
| Adam | epoch: 005 | loss: 0.60296 - acc: 0.6633 -- iter: 0416/1104
[A[ATraining Step: 154  | total loss: [1m[32m0.59305[0m[0m | time: 11.426s
[2K
| Adam | epoch: 005 | loss: 0.59305 - acc: 0.6751 -- iter: 0448/1104
[A[ATraining Step: 155  | total loss: [1m[32m0.59485[0m[0m | time: 12.218s
[2K
| Adam | epoch: 005 | loss: 0.59485 - acc: 0.6763 -- iter: 0480/1104
[A[ATraining Step: 156  | total loss: [1m[32m0.58584[0m[0m | time: 13.095s
[2K
| Adam | epoch: 005 | loss: 0.58584 - acc: 0.6806 -- iter: 0512/1104
[A[ATraining Step: 157  | total loss: [1m[32m0.57033[0m[0m | time: 13.942s
[2K
| Adam | epoch: 005 | loss: 0.57033 - acc: 0.6875 -- iter: 0544/1104
[A[ATraining Step: 158  | total loss: [1m[32m0.56423[0m[0m | time: 14.803s
[2K
| Adam | epoch: 005 | loss: 0.56423 - acc: 0.6938 -- iter: 0576/1104
[A[ATraining Step: 159  | total loss: [1m[32m0.55453[0m[0m | time: 15.644s
[2K
| Adam | epoch: 005 | loss: 0.55453 - acc: 0.7056 -- iter: 0608/1104
[A[ATraining Step: 160  | total loss: [1m[32m0.54445[0m[0m | time: 16.499s
[2K
| Adam | epoch: 005 | loss: 0.54445 - acc: 0.7226 -- iter: 0640/1104
[A[ATraining Step: 161  | total loss: [1m[32m0.53565[0m[0m | time: 17.487s
[2K
| Adam | epoch: 005 | loss: 0.53565 - acc: 0.7347 -- iter: 0672/1104
[A[ATraining Step: 162  | total loss: [1m[32m0.51616[0m[0m | time: 18.515s
[2K
| Adam | epoch: 005 | loss: 0.51616 - acc: 0.7519 -- iter: 0704/1104
[A[ATraining Step: 163  | total loss: [1m[32m0.52332[0m[0m | time: 19.220s
[2K
| Adam | epoch: 005 | loss: 0.52332 - acc: 0.7517 -- iter: 0736/1104
[A[ATraining Step: 164  | total loss: [1m[32m0.51564[0m[0m | time: 20.039s
[2K
| Adam | epoch: 005 | loss: 0.51564 - acc: 0.7515 -- iter: 0768/1104
[A[ATraining Step: 165  | total loss: [1m[32m0.51831[0m[0m | time: 20.892s
[2K
| Adam | epoch: 005 | loss: 0.51831 - acc: 0.7514 -- iter: 0800/1104
[A[ATraining Step: 166  | total loss: [1m[32m0.52263[0m[0m | time: 21.716s
[2K
| Adam | epoch: 005 | loss: 0.52263 - acc: 0.7543 -- iter: 0832/1104
[A[ATraining Step: 167  | total loss: [1m[32m0.53224[0m[0m | time: 22.522s
[2K
| Adam | epoch: 005 | loss: 0.53224 - acc: 0.7477 -- iter: 0864/1104
[A[ATraining Step: 168  | total loss: [1m[32m0.53023[0m[0m | time: 23.371s
[2K
| Adam | epoch: 005 | loss: 0.53023 - acc: 0.7448 -- iter: 0896/1104
[A[ATraining Step: 169  | total loss: [1m[32m0.52029[0m[0m | time: 24.210s
[2K
| Adam | epoch: 005 | loss: 0.52029 - acc: 0.7547 -- iter: 0928/1104
[A[ATraining Step: 170  | total loss: [1m[32m0.51114[0m[0m | time: 25.054s
[2K
| Adam | epoch: 005 | loss: 0.51114 - acc: 0.7636 -- iter: 0960/1104
[A[ATraining Step: 171  | total loss: [1m[32m0.53684[0m[0m | time: 25.926s
[2K
| Adam | epoch: 005 | loss: 0.53684 - acc: 0.7560 -- iter: 0992/1104
[A[ATraining Step: 172  | total loss: [1m[32m0.54745[0m[0m | time: 26.797s
[2K
| Adam | epoch: 005 | loss: 0.54745 - acc: 0.7522 -- iter: 1024/1104
[A[ATraining Step: 173  | total loss: [1m[32m0.54908[0m[0m | time: 27.650s
[2K
| Adam | epoch: 005 | loss: 0.54908 - acc: 0.7520 -- iter: 1056/1104
[A[ATraining Step: 174  | total loss: [1m[32m0.54302[0m[0m | time: 28.617s
[2K
| Adam | epoch: 005 | loss: 0.54302 - acc: 0.7581 -- iter: 1088/1104
[A[ATraining Step: 175  | total loss: [1m[32m0.55377[0m[0m | time: 30.776s
[2K
| Adam | epoch: 005 | loss: 0.55377 - acc: 0.7541 | val_loss: 0.47383 - val_acc: 0.8006 -- iter: 1104/1104
--
Training Step: 176  | total loss: [1m[32m0.54801[0m[0m | time: 0.848s
[2K
| Adam | epoch: 006 | loss: 0.54801 - acc: 0.7600 -- iter: 0032/1104
[A[ATraining Step: 177  | total loss: [1m[32m0.55646[0m[0m | time: 1.657s
[2K
| Adam | epoch: 006 | loss: 0.55646 - acc: 0.7559 -- iter: 0064/1104
[A[ATraining Step: 178  | total loss: [1m[32m0.55803[0m[0m | time: 2.470s
[2K
| Adam | epoch: 006 | loss: 0.55803 - acc: 0.7553 -- iter: 0096/1104
[A[ATraining Step: 179  | total loss: [1m[32m0.55079[0m[0m | time: 2.942s
[2K
| Adam | epoch: 006 | loss: 0.55079 - acc: 0.7610 -- iter: 0128/1104
[A[ATraining Step: 180  | total loss: [1m[32m0.53086[0m[0m | time: 3.398s
[2K
| Adam | epoch: 006 | loss: 0.53086 - acc: 0.7661 -- iter: 0160/1104
[A[ATraining Step: 181  | total loss: [1m[32m0.51107[0m[0m | time: 4.294s
[2K
| Adam | epoch: 006 | loss: 0.51107 - acc: 0.7770 -- iter: 0192/1104
[A[ATraining Step: 182  | total loss: [1m[32m0.49668[0m[0m | time: 5.157s
[2K
| Adam | epoch: 006 | loss: 0.49668 - acc: 0.7868 -- iter: 0224/1104
[A[ATraining Step: 183  | total loss: [1m[32m0.50698[0m[0m | time: 6.049s
[2K
| Adam | epoch: 006 | loss: 0.50698 - acc: 0.7800 -- iter: 0256/1104
[A[ATraining Step: 184  | total loss: [1m[32m0.49234[0m[0m | time: 6.953s
[2K
| Adam | epoch: 006 | loss: 0.49234 - acc: 0.7926 -- iter: 0288/1104
[A[ATraining Step: 185  | total loss: [1m[32m0.48342[0m[0m | time: 7.892s
[2K
| Adam | epoch: 006 | loss: 0.48342 - acc: 0.7946 -- iter: 0320/1104
[A[ATraining Step: 186  | total loss: [1m[32m0.48160[0m[0m | time: 8.910s
[2K
| Adam | epoch: 006 | loss: 0.48160 - acc: 0.7933 -- iter: 0352/1104
[A[ATraining Step: 187  | total loss: [1m[32m0.48252[0m[0m | time: 9.634s
[2K
| Adam | epoch: 006 | loss: 0.48252 - acc: 0.7890 -- iter: 0384/1104
[A[ATraining Step: 188  | total loss: [1m[32m0.48196[0m[0m | time: 10.449s
[2K
| Adam | epoch: 006 | loss: 0.48196 - acc: 0.7851 -- iter: 0416/1104
[A[ATraining Step: 189  | total loss: [1m[32m0.48508[0m[0m | time: 11.268s
[2K
| Adam | epoch: 006 | loss: 0.48508 - acc: 0.7816 -- iter: 0448/1104
[A[ATraining Step: 190  | total loss: [1m[32m0.48448[0m[0m | time: 12.092s
[2K
| Adam | epoch: 006 | loss: 0.48448 - acc: 0.7784 -- iter: 0480/1104
[A[ATraining Step: 191  | total loss: [1m[32m0.47758[0m[0m | time: 12.929s
[2K
| Adam | epoch: 006 | loss: 0.47758 - acc: 0.7787 -- iter: 0512/1104
[A[ATraining Step: 192  | total loss: [1m[32m0.44902[0m[0m | time: 13.763s
[2K
| Adam | epoch: 006 | loss: 0.44902 - acc: 0.8008 -- iter: 0544/1104
[A[ATraining Step: 193  | total loss: [1m[32m0.45209[0m[0m | time: 14.635s
[2K
| Adam | epoch: 006 | loss: 0.45209 - acc: 0.8020 -- iter: 0576/1104
[A[ATraining Step: 194  | total loss: [1m[32m0.47449[0m[0m | time: 15.481s
[2K
| Adam | epoch: 006 | loss: 0.47449 - acc: 0.7905 -- iter: 0608/1104
[A[ATraining Step: 195  | total loss: [1m[32m0.47743[0m[0m | time: 16.392s
[2K
| Adam | epoch: 006 | loss: 0.47743 - acc: 0.7865 -- iter: 0640/1104
[A[ATraining Step: 196  | total loss: [1m[32m0.46330[0m[0m | time: 17.219s
[2K
| Adam | epoch: 006 | loss: 0.46330 - acc: 0.7953 -- iter: 0672/1104
[A[ATraining Step: 197  | total loss: [1m[32m0.44953[0m[0m | time: 18.089s
[2K
| Adam | epoch: 006 | loss: 0.44953 - acc: 0.8064 -- iter: 0704/1104
[A[ATraining Step: 198  | total loss: [1m[32m0.44295[0m[0m | time: 19.071s
[2K
| Adam | epoch: 006 | loss: 0.44295 - acc: 0.8164 -- iter: 0736/1104
[A[ATraining Step: 199  | total loss: [1m[32m0.44972[0m[0m | time: 20.070s
[2K
| Adam | epoch: 006 | loss: 0.44972 - acc: 0.8098 -- iter: 0768/1104
[A[ATraining Step: 200  | total loss: [1m[32m0.44219[0m[0m | time: 22.149s
[2K
| Adam | epoch: 006 | loss: 0.44219 - acc: 0.8163 | val_loss: 0.45608 - val_acc: 0.8121 -- iter: 0800/1104
--
Training Step: 201  | total loss: [1m[32m0.43699[0m[0m | time: 23.014s
[2K
| Adam | epoch: 006 | loss: 0.43699 - acc: 0.8190 -- iter: 0832/1104
[A[ATraining Step: 202  | total loss: [1m[32m0.44229[0m[0m | time: 23.879s
[2K
| Adam | epoch: 006 | loss: 0.44229 - acc: 0.8215 -- iter: 0864/1104
[A[ATraining Step: 203  | total loss: [1m[32m0.43019[0m[0m | time: 24.731s
[2K
| Adam | epoch: 006 | loss: 0.43019 - acc: 0.8237 -- iter: 0896/1104
[A[ATraining Step: 204  | total loss: [1m[32m0.42845[0m[0m | time: 25.572s
[2K
| Adam | epoch: 006 | loss: 0.42845 - acc: 0.8226 -- iter: 0928/1104
[A[ATraining Step: 205  | total loss: [1m[32m0.42243[0m[0m | time: 26.434s
[2K
| Adam | epoch: 006 | loss: 0.42243 - acc: 0.8278 -- iter: 0960/1104
[A[ATraining Step: 206  | total loss: [1m[32m0.42336[0m[0m | time: 27.271s
[2K
| Adam | epoch: 006 | loss: 0.42336 - acc: 0.8263 -- iter: 0992/1104
[A[ATraining Step: 207  | total loss: [1m[32m0.42302[0m[0m | time: 28.028s
[2K
| Adam | epoch: 006 | loss: 0.42302 - acc: 0.8281 -- iter: 1024/1104
[A[ATraining Step: 208  | total loss: [1m[32m0.43876[0m[0m | time: 28.940s
[2K
| Adam | epoch: 006 | loss: 0.43876 - acc: 0.8171 -- iter: 1056/1104
[A[ATraining Step: 209  | total loss: [1m[32m0.43654[0m[0m | time: 29.901s
[2K
| Adam | epoch: 006 | loss: 0.43654 - acc: 0.8167 -- iter: 1088/1104
[A[ATraining Step: 210  | total loss: [1m[32m0.44654[0m[0m | time: 32.037s
[2K
| Adam | epoch: 006 | loss: 0.44654 - acc: 0.8162 | val_loss: 0.52002 - val_acc: 0.7543 -- iter: 1104/1104
--
Training Step: 211  | total loss: [1m[32m0.45120[0m[0m | time: 0.842s
[2K
| Adam | epoch: 007 | loss: 0.45120 - acc: 0.8159 -- iter: 0032/1104
[A[ATraining Step: 212  | total loss: [1m[32m0.46016[0m[0m | time: 1.682s
[2K
| Adam | epoch: 007 | loss: 0.46016 - acc: 0.8062 -- iter: 0064/1104
[A[ATraining Step: 213  | total loss: [1m[32m0.46569[0m[0m | time: 2.531s
[2K
| Adam | epoch: 007 | loss: 0.46569 - acc: 0.8005 -- iter: 0096/1104
[A[ATraining Step: 214  | total loss: [1m[32m0.46173[0m[0m | time: 3.461s
[2K
| Adam | epoch: 007 | loss: 0.46173 - acc: 0.8080 -- iter: 0128/1104
[A[ATraining Step: 215  | total loss: [1m[32m0.45860[0m[0m | time: 3.932s
[2K
| Adam | epoch: 007 | loss: 0.45860 - acc: 0.8084 -- iter: 0160/1104
[A[ATraining Step: 216  | total loss: [1m[32m0.44298[0m[0m | time: 4.364s
[2K
| Adam | epoch: 007 | loss: 0.44298 - acc: 0.8276 -- iter: 0192/1104
[A[ATraining Step: 217  | total loss: [1m[32m0.42973[0m[0m | time: 5.264s
[2K
| Adam | epoch: 007 | loss: 0.42973 - acc: 0.8448 -- iter: 0224/1104
[A[ATraining Step: 218  | total loss: [1m[32m0.43907[0m[0m | time: 6.072s
[2K
| Adam | epoch: 007 | loss: 0.43907 - acc: 0.8322 -- iter: 0256/1104
[A[ATraining Step: 219  | total loss: [1m[32m0.42982[0m[0m | time: 6.993s
[2K
| Adam | epoch: 007 | loss: 0.42982 - acc: 0.8365 -- iter: 0288/1104
[A[ATraining Step: 220  | total loss: [1m[32m0.46837[0m[0m | time: 7.954s
[2K
| Adam | epoch: 007 | loss: 0.46837 - acc: 0.8091 -- iter: 0320/1104
[A[ATraining Step: 221  | total loss: [1m[32m0.45198[0m[0m | time: 8.882s
[2K
| Adam | epoch: 007 | loss: 0.45198 - acc: 0.8188 -- iter: 0352/1104
[A[ATraining Step: 222  | total loss: [1m[32m0.43176[0m[0m | time: 9.554s
[2K
| Adam | epoch: 007 | loss: 0.43176 - acc: 0.8276 -- iter: 0384/1104
[A[ATraining Step: 223  | total loss: [1m[32m0.43029[0m[0m | time: 10.344s
[2K
| Adam | epoch: 007 | loss: 0.43029 - acc: 0.8229 -- iter: 0416/1104
[A[ATraining Step: 224  | total loss: [1m[32m0.41765[0m[0m | time: 11.181s
[2K
| Adam | epoch: 007 | loss: 0.41765 - acc: 0.8313 -- iter: 0448/1104
[A[ATraining Step: 225  | total loss: [1m[32m0.44300[0m[0m | time: 12.042s
[2K
| Adam | epoch: 007 | loss: 0.44300 - acc: 0.8138 -- iter: 0480/1104
[A[ATraining Step: 226  | total loss: [1m[32m0.43189[0m[0m | time: 12.886s
[2K
| Adam | epoch: 007 | loss: 0.43189 - acc: 0.8168 -- iter: 0512/1104
[A[ATraining Step: 227  | total loss: [1m[32m0.41851[0m[0m | time: 13.713s
[2K
| Adam | epoch: 007 | loss: 0.41851 - acc: 0.8226 -- iter: 0544/1104
[A[ATraining Step: 228  | total loss: [1m[32m0.40069[0m[0m | time: 14.527s
[2K
| Adam | epoch: 007 | loss: 0.40069 - acc: 0.8310 -- iter: 0576/1104
[A[ATraining Step: 229  | total loss: [1m[32m0.39795[0m[0m | time: 15.372s
[2K
| Adam | epoch: 007 | loss: 0.39795 - acc: 0.8354 -- iter: 0608/1104
[A[ATraining Step: 230  | total loss: [1m[32m0.38681[0m[0m | time: 16.236s
[2K
| Adam | epoch: 007 | loss: 0.38681 - acc: 0.8424 -- iter: 0640/1104
[A[ATraining Step: 231  | total loss: [1m[32m0.36770[0m[0m | time: 17.086s
[2K
| Adam | epoch: 007 | loss: 0.36770 - acc: 0.8551 -- iter: 0672/1104
[A[ATraining Step: 232  | total loss: [1m[32m0.36774[0m[0m | time: 17.949s
[2K
| Adam | epoch: 007 | loss: 0.36774 - acc: 0.8539 -- iter: 0704/1104
[A[ATraining Step: 233  | total loss: [1m[32m0.35721[0m[0m | time: 18.939s
[2K
| Adam | epoch: 007 | loss: 0.35721 - acc: 0.8623 -- iter: 0736/1104
[A[ATraining Step: 234  | total loss: [1m[32m0.36541[0m[0m | time: 19.902s
[2K
| Adam | epoch: 007 | loss: 0.36541 - acc: 0.8573 -- iter: 0768/1104
[A[ATraining Step: 235  | total loss: [1m[32m0.36518[0m[0m | time: 20.574s
[2K
| Adam | epoch: 007 | loss: 0.36518 - acc: 0.8591 -- iter: 0800/1104
[A[ATraining Step: 236  | total loss: [1m[32m0.38118[0m[0m | time: 21.368s
[2K
| Adam | epoch: 007 | loss: 0.38118 - acc: 0.8419 -- iter: 0832/1104
[A[ATraining Step: 237  | total loss: [1m[32m0.36287[0m[0m | time: 22.185s
[2K
| Adam | epoch: 007 | loss: 0.36287 - acc: 0.8515 -- iter: 0864/1104
[A[ATraining Step: 238  | total loss: [1m[32m0.35611[0m[0m | time: 23.043s
[2K
| Adam | epoch: 007 | loss: 0.35611 - acc: 0.8538 -- iter: 0896/1104
[A[ATraining Step: 239  | total loss: [1m[32m0.35478[0m[0m | time: 23.892s
[2K
| Adam | epoch: 007 | loss: 0.35478 - acc: 0.8560 -- iter: 0928/1104
[A[ATraining Step: 240  | total loss: [1m[32m0.35854[0m[0m | time: 24.737s
[2K
| Adam | epoch: 007 | loss: 0.35854 - acc: 0.8516 -- iter: 0960/1104
[A[ATraining Step: 241  | total loss: [1m[32m0.35174[0m[0m | time: 25.580s
[2K
| Adam | epoch: 007 | loss: 0.35174 - acc: 0.8539 -- iter: 0992/1104
[A[ATraining Step: 242  | total loss: [1m[32m0.35551[0m[0m | time: 26.469s
[2K
| Adam | epoch: 007 | loss: 0.35551 - acc: 0.8529 -- iter: 1024/1104
[A[ATraining Step: 243  | total loss: [1m[32m0.36102[0m[0m | time: 27.364s
[2K
| Adam | epoch: 007 | loss: 0.36102 - acc: 0.8520 -- iter: 1056/1104
[A[ATraining Step: 244  | total loss: [1m[32m0.35647[0m[0m | time: 28.130s
[2K
| Adam | epoch: 007 | loss: 0.35647 - acc: 0.8543 -- iter: 1088/1104
[A[ATraining Step: 245  | total loss: [1m[32m0.36310[0m[0m | time: 30.749s
[2K
| Adam | epoch: 007 | loss: 0.36310 - acc: 0.8501 | val_loss: 0.49092 - val_acc: 0.7832 -- iter: 1104/1104
--
Training Step: 246  | total loss: [1m[32m0.34673[0m[0m | time: 0.729s
[2K
| Adam | epoch: 008 | loss: 0.34673 - acc: 0.8589 -- iter: 0032/1104
[A[ATraining Step: 247  | total loss: [1m[32m0.35544[0m[0m | time: 1.556s
[2K
| Adam | epoch: 008 | loss: 0.35544 - acc: 0.8511 -- iter: 0064/1104
[A[ATraining Step: 248  | total loss: [1m[32m0.35861[0m[0m | time: 2.386s
[2K
| Adam | epoch: 008 | loss: 0.35861 - acc: 0.8472 -- iter: 0096/1104
[A[ATraining Step: 249  | total loss: [1m[32m0.36711[0m[0m | time: 3.211s
[2K
| Adam | epoch: 008 | loss: 0.36711 - acc: 0.8469 -- iter: 0128/1104
[A[ATraining Step: 250  | total loss: [1m[32m0.36689[0m[0m | time: 4.068s
[2K
| Adam | epoch: 008 | loss: 0.36689 - acc: 0.8466 -- iter: 0160/1104
[A[ATraining Step: 251  | total loss: [1m[32m0.36754[0m[0m | time: 4.507s
[2K
| Adam | epoch: 008 | loss: 0.36754 - acc: 0.8494 -- iter: 0192/1104
[A[ATraining Step: 252  | total loss: [1m[32m0.34571[0m[0m | time: 4.993s
[2K
| Adam | epoch: 008 | loss: 0.34571 - acc: 0.8645 -- iter: 0224/1104
[A[ATraining Step: 253  | total loss: [1m[32m0.32280[0m[0m | time: 5.871s
[2K
| Adam | epoch: 008 | loss: 0.32280 - acc: 0.8780 -- iter: 0256/1104
[A[ATraining Step: 254  | total loss: [1m[32m0.32557[0m[0m | time: 6.727s
[2K
| Adam | epoch: 008 | loss: 0.32557 - acc: 0.8715 -- iter: 0288/1104
[A[ATraining Step: 255  | total loss: [1m[32m0.32920[0m[0m | time: 7.530s
[2K
| Adam | epoch: 008 | loss: 0.32920 - acc: 0.8718 -- iter: 0320/1104
[A[ATraining Step: 256  | total loss: [1m[32m0.33862[0m[0m | time: 8.388s
[2K
| Adam | epoch: 008 | loss: 0.33862 - acc: 0.8753 -- iter: 0352/1104
[A[ATraining Step: 257  | total loss: [1m[32m0.33225[0m[0m | time: 9.368s
[2K
| Adam | epoch: 008 | loss: 0.33225 - acc: 0.8815 -- iter: 0384/1104
[A[ATraining Step: 258  | total loss: [1m[32m0.32171[0m[0m | time: 10.402s
[2K
| Adam | epoch: 008 | loss: 0.32171 - acc: 0.8871 -- iter: 0416/1104
[A[ATraining Step: 259  | total loss: [1m[32m0.30462[0m[0m | time: 11.157s
[2K
| Adam | epoch: 008 | loss: 0.30462 - acc: 0.8984 -- iter: 0448/1104
[A[ATraining Step: 260  | total loss: [1m[32m0.30542[0m[0m | time: 11.970s
[2K
| Adam | epoch: 008 | loss: 0.30542 - acc: 0.8929 -- iter: 0480/1104
[A[ATraining Step: 261  | total loss: [1m[32m0.30292[0m[0m | time: 12.853s
[2K
| Adam | epoch: 008 | loss: 0.30292 - acc: 0.8880 -- iter: 0512/1104
[A[ATraining Step: 262  | total loss: [1m[32m0.30233[0m[0m | time: 13.700s
[2K
| Adam | epoch: 008 | loss: 0.30233 - acc: 0.8836 -- iter: 0544/1104
[A[ATraining Step: 263  | total loss: [1m[32m0.29818[0m[0m | time: 14.567s
[2K
| Adam | epoch: 008 | loss: 0.29818 - acc: 0.8858 -- iter: 0576/1104
[A[ATraining Step: 264  | total loss: [1m[32m0.29934[0m[0m | time: 15.405s
[2K
| Adam | epoch: 008 | loss: 0.29934 - acc: 0.8816 -- iter: 0608/1104
[A[ATraining Step: 265  | total loss: [1m[32m0.29612[0m[0m | time: 16.315s
[2K
| Adam | epoch: 008 | loss: 0.29612 - acc: 0.8810 -- iter: 0640/1104
[A[ATraining Step: 266  | total loss: [1m[32m0.30143[0m[0m | time: 17.188s
[2K
| Adam | epoch: 008 | loss: 0.30143 - acc: 0.8741 -- iter: 0672/1104
[A[ATraining Step: 267  | total loss: [1m[32m0.28719[0m[0m | time: 18.028s
[2K
| Adam | epoch: 008 | loss: 0.28719 - acc: 0.8836 -- iter: 0704/1104
[A[ATraining Step: 268  | total loss: [1m[32m0.27419[0m[0m | time: 18.862s
[2K
| Adam | epoch: 008 | loss: 0.27419 - acc: 0.8890 -- iter: 0736/1104
[A[ATraining Step: 269  | total loss: [1m[32m0.27469[0m[0m | time: 19.821s
[2K
| Adam | epoch: 008 | loss: 0.27469 - acc: 0.8907 -- iter: 0768/1104
[A[ATraining Step: 270  | total loss: [1m[32m0.27026[0m[0m | time: 20.813s
[2K
| Adam | epoch: 008 | loss: 0.27026 - acc: 0.8954 -- iter: 0800/1104
[A[ATraining Step: 271  | total loss: [1m[32m0.25800[0m[0m | time: 21.594s
[2K
| Adam | epoch: 008 | loss: 0.25800 - acc: 0.8996 -- iter: 0832/1104
[A[ATraining Step: 272  | total loss: [1m[32m0.25828[0m[0m | time: 22.355s
[2K
| Adam | epoch: 008 | loss: 0.25828 - acc: 0.8940 -- iter: 0864/1104
[A[ATraining Step: 273  | total loss: [1m[32m0.24857[0m[0m | time: 23.247s
[2K
| Adam | epoch: 008 | loss: 0.24857 - acc: 0.9015 -- iter: 0896/1104
[A[ATraining Step: 274  | total loss: [1m[32m0.25288[0m[0m | time: 24.107s
[2K
| Adam | epoch: 008 | loss: 0.25288 - acc: 0.8957 -- iter: 0928/1104
[A[ATraining Step: 275  | total loss: [1m[32m0.24578[0m[0m | time: 24.975s
[2K
| Adam | epoch: 008 | loss: 0.24578 - acc: 0.8936 -- iter: 0960/1104
[A[ATraining Step: 276  | total loss: [1m[32m0.24442[0m[0m | time: 25.832s
[2K
| Adam | epoch: 008 | loss: 0.24442 - acc: 0.8980 -- iter: 0992/1104
[A[ATraining Step: 277  | total loss: [1m[32m0.24317[0m[0m | time: 26.706s
[2K
| Adam | epoch: 008 | loss: 0.24317 - acc: 0.8988 -- iter: 1024/1104
[A[ATraining Step: 278  | total loss: [1m[32m0.27802[0m[0m | time: 27.592s
[2K
| Adam | epoch: 008 | loss: 0.27802 - acc: 0.8902 -- iter: 1056/1104
[A[ATraining Step: 279  | total loss: [1m[32m0.25754[0m[0m | time: 28.432s
[2K
| Adam | epoch: 008 | loss: 0.25754 - acc: 0.9012 -- iter: 1088/1104
[A[ATraining Step: 280  | total loss: [1m[32m0.24476[0m[0m | time: 30.847s
[2K
| Adam | epoch: 008 | loss: 0.24476 - acc: 0.9079 | val_loss: 0.38771 - val_acc: 0.8324 -- iter: 1104/1104
--
Training Step: 281  | total loss: [1m[32m0.25704[0m[0m | time: 0.768s
[2K
| Adam | epoch: 009 | loss: 0.25704 - acc: 0.9047 -- iter: 0032/1104
[A[ATraining Step: 282  | total loss: [1m[32m0.25506[0m[0m | time: 1.522s
[2K
| Adam | epoch: 009 | loss: 0.25506 - acc: 0.9079 -- iter: 0064/1104
[A[ATraining Step: 283  | total loss: [1m[32m0.24270[0m[0m | time: 2.391s
[2K
| Adam | epoch: 009 | loss: 0.24270 - acc: 0.9140 -- iter: 0096/1104
[A[ATraining Step: 284  | total loss: [1m[32m0.25762[0m[0m | time: 3.250s
[2K
| Adam | epoch: 009 | loss: 0.25762 - acc: 0.9070 -- iter: 0128/1104
[A[ATraining Step: 285  | total loss: [1m[32m0.25454[0m[0m | time: 4.081s
[2K
| Adam | epoch: 009 | loss: 0.25454 - acc: 0.9038 -- iter: 0160/1104
[A[ATraining Step: 286  | total loss: [1m[32m0.25983[0m[0m | time: 4.906s
[2K
| Adam | epoch: 009 | loss: 0.25983 - acc: 0.9009 -- iter: 0192/1104
[A[ATraining Step: 287  | total loss: [1m[32m0.24833[0m[0m | time: 5.379s
[2K
| Adam | epoch: 009 | loss: 0.24833 - acc: 0.9077 -- iter: 0224/1104
[A[ATraining Step: 288  | total loss: [1m[32m0.23819[0m[0m | time: 5.889s
[2K
| Adam | epoch: 009 | loss: 0.23819 - acc: 0.9169 -- iter: 0256/1104
[A[ATraining Step: 289  | total loss: [1m[32m0.22448[0m[0m | time: 6.724s
[2K
| Adam | epoch: 009 | loss: 0.22448 - acc: 0.9252 -- iter: 0288/1104
[A[ATraining Step: 290  | total loss: [1m[32m0.23118[0m[0m | time: 7.658s
[2K
| Adam | epoch: 009 | loss: 0.23118 - acc: 0.9233 -- iter: 0320/1104
[A[ATraining Step: 291  | total loss: [1m[32m0.22845[0m[0m | time: 8.511s
[2K
| Adam | epoch: 009 | loss: 0.22845 - acc: 0.9248 -- iter: 0352/1104
[A[ATraining Step: 292  | total loss: [1m[32m0.23746[0m[0m | time: 9.432s
[2K
| Adam | epoch: 009 | loss: 0.23746 - acc: 0.9229 -- iter: 0384/1104
[A[ATraining Step: 293  | total loss: [1m[32m0.22842[0m[0m | time: 10.443s
[2K
| Adam | epoch: 009 | loss: 0.22842 - acc: 0.9275 -- iter: 0416/1104
[A[ATraining Step: 294  | total loss: [1m[32m0.21292[0m[0m | time: 11.303s
[2K
| Adam | epoch: 009 | loss: 0.21292 - acc: 0.9316 -- iter: 0448/1104
[A[ATraining Step: 295  | total loss: [1m[32m0.21372[0m[0m | time: 12.070s
[2K
| Adam | epoch: 009 | loss: 0.21372 - acc: 0.9322 -- iter: 0480/1104
[A[ATraining Step: 296  | total loss: [1m[32m0.22373[0m[0m | time: 12.879s
[2K
| Adam | epoch: 009 | loss: 0.22373 - acc: 0.9234 -- iter: 0512/1104
[A[ATraining Step: 297  | total loss: [1m[32m0.21180[0m[0m | time: 13.754s
[2K
| Adam | epoch: 009 | loss: 0.21180 - acc: 0.9279 -- iter: 0544/1104
[A[ATraining Step: 298  | total loss: [1m[32m0.20075[0m[0m | time: 14.606s
[2K
| Adam | epoch: 009 | loss: 0.20075 - acc: 0.9320 -- iter: 0576/1104
[A[ATraining Step: 299  | total loss: [1m[32m0.20441[0m[0m | time: 15.513s
[2K
| Adam | epoch: 009 | loss: 0.20441 - acc: 0.9294 -- iter: 0608/1104
[A[ATraining Step: 300  | total loss: [1m[32m0.19706[0m[0m | time: 16.365s
[2K
| Adam | epoch: 009 | loss: 0.19706 - acc: 0.9302 -- iter: 0640/1104
[A[ATraining Step: 301  | total loss: [1m[32m0.19413[0m[0m | time: 17.206s
[2K
| Adam | epoch: 009 | loss: 0.19413 - acc: 0.9309 -- iter: 0672/1104
[A[ATraining Step: 302  | total loss: [1m[32m0.18219[0m[0m | time: 18.081s
[2K
| Adam | epoch: 009 | loss: 0.18219 - acc: 0.9379 -- iter: 0704/1104
[A[ATraining Step: 303  | total loss: [1m[32m0.17039[0m[0m | time: 18.991s
[2K
| Adam | epoch: 009 | loss: 0.17039 - acc: 0.9441 -- iter: 0736/1104
[A[ATraining Step: 304  | total loss: [1m[32m0.16278[0m[0m | time: 19.923s
[2K
| Adam | epoch: 009 | loss: 0.16278 - acc: 0.9465 -- iter: 0768/1104
[A[ATraining Step: 305  | total loss: [1m[32m0.15307[0m[0m | time: 20.878s
[2K
| Adam | epoch: 009 | loss: 0.15307 - acc: 0.9488 -- iter: 0800/1104
[A[ATraining Step: 306  | total loss: [1m[32m0.14677[0m[0m | time: 21.837s
[2K
| Adam | epoch: 009 | loss: 0.14677 - acc: 0.9508 -- iter: 0832/1104
[A[ATraining Step: 307  | total loss: [1m[32m0.14048[0m[0m | time: 22.510s
[2K
| Adam | epoch: 009 | loss: 0.14048 - acc: 0.9526 -- iter: 0864/1104
[A[ATraining Step: 308  | total loss: [1m[32m0.13331[0m[0m | time: 23.390s
[2K
| Adam | epoch: 009 | loss: 0.13331 - acc: 0.9573 -- iter: 0896/1104
[A[ATraining Step: 309  | total loss: [1m[32m0.12937[0m[0m | time: 24.226s
[2K
| Adam | epoch: 009 | loss: 0.12937 - acc: 0.9553 -- iter: 0928/1104
[A[ATraining Step: 310  | total loss: [1m[32m0.12731[0m[0m | time: 25.057s
[2K
| Adam | epoch: 009 | loss: 0.12731 - acc: 0.9567 -- iter: 0960/1104
[A[ATraining Step: 311  | total loss: [1m[32m0.13010[0m[0m | time: 25.888s
[2K
| Adam | epoch: 009 | loss: 0.13010 - acc: 0.9547 -- iter: 0992/1104
[A[ATraining Step: 312  | total loss: [1m[32m0.14749[0m[0m | time: 26.749s
[2K
| Adam | epoch: 009 | loss: 0.14749 - acc: 0.9436 -- iter: 1024/1104
[A[ATraining Step: 313  | total loss: [1m[32m0.17386[0m[0m | time: 27.589s
[2K
| Adam | epoch: 009 | loss: 0.17386 - acc: 0.9399 -- iter: 1056/1104
[A[ATraining Step: 314  | total loss: [1m[32m0.15908[0m[0m | time: 28.483s
[2K
| Adam | epoch: 009 | loss: 0.15908 - acc: 0.9459 -- iter: 1088/1104
[A[ATraining Step: 315  | total loss: [1m[32m0.19442[0m[0m | time: 30.691s
[2K
| Adam | epoch: 009 | loss: 0.19442 - acc: 0.9357 | val_loss: 0.42355 - val_acc: 0.8642 -- iter: 1104/1104
--
Training Step: 316  | total loss: [1m[32m0.19667[0m[0m | time: 1.022s
[2K
| Adam | epoch: 010 | loss: 0.19667 - acc: 0.9328 -- iter: 0032/1104
[A[ATraining Step: 317  | total loss: [1m[32m0.20208[0m[0m | time: 1.787s
[2K
| Adam | epoch: 010 | loss: 0.20208 - acc: 0.9270 -- iter: 0064/1104
[A[ATraining Step: 318  | total loss: [1m[32m0.18577[0m[0m | time: 2.586s
[2K
| Adam | epoch: 010 | loss: 0.18577 - acc: 0.9343 -- iter: 0096/1104
[A[ATraining Step: 319  | total loss: [1m[32m0.17318[0m[0m | time: 3.398s
[2K
| Adam | epoch: 010 | loss: 0.17318 - acc: 0.9409 -- iter: 0128/1104
[A[ATraining Step: 320  | total loss: [1m[32m0.16764[0m[0m | time: 4.267s
[2K
| Adam | epoch: 010 | loss: 0.16764 - acc: 0.9405 -- iter: 0160/1104
[A[ATraining Step: 321  | total loss: [1m[32m0.16186[0m[0m | time: 5.170s
[2K
| Adam | epoch: 010 | loss: 0.16186 - acc: 0.9433 -- iter: 0192/1104
[A[ATraining Step: 322  | total loss: [1m[32m0.15131[0m[0m | time: 5.990s
[2K
| Adam | epoch: 010 | loss: 0.15131 - acc: 0.9490 -- iter: 0224/1104
[A[ATraining Step: 323  | total loss: [1m[32m0.14178[0m[0m | time: 6.436s
[2K
| Adam | epoch: 010 | loss: 0.14178 - acc: 0.9541 -- iter: 0256/1104
[A[ATraining Step: 324  | total loss: [1m[32m0.14145[0m[0m | time: 6.884s
[2K
| Adam | epoch: 010 | loss: 0.14145 - acc: 0.9524 -- iter: 0288/1104
[A[ATraining Step: 325  | total loss: [1m[32m0.13185[0m[0m | time: 7.789s
[2K
| Adam | epoch: 010 | loss: 0.13185 - acc: 0.9572 -- iter: 0320/1104
[A[ATraining Step: 326  | total loss: [1m[32m0.13232[0m[0m | time: 8.697s
[2K
| Adam | epoch: 010 | loss: 0.13232 - acc: 0.9552 -- iter: 0352/1104
[A[ATraining Step: 327  | total loss: [1m[32m0.12485[0m[0m | time: 9.488s
[2K
| Adam | epoch: 010 | loss: 0.12485 - acc: 0.9597 -- iter: 0384/1104
[A[ATraining Step: 328  | total loss: [1m[32m0.25212[0m[0m | time: 10.488s
[2K
| Adam | epoch: 010 | loss: 0.25212 - acc: 0.9200 -- iter: 0416/1104
[A[ATraining Step: 329  | total loss: [1m[32m0.23448[0m[0m | time: 11.504s
[2K
| Adam | epoch: 010 | loss: 0.23448 - acc: 0.9249 -- iter: 0448/1104
[A[ATraining Step: 330  | total loss: [1m[32m0.21948[0m[0m | time: 12.323s
[2K
| Adam | epoch: 010 | loss: 0.21948 - acc: 0.9293 -- iter: 0480/1104
[A[ATraining Step: 331  | total loss: [1m[32m0.20436[0m[0m | time: 13.060s
[2K
| Adam | epoch: 010 | loss: 0.20436 - acc: 0.9363 -- iter: 0512/1104
[A[ATraining Step: 332  | total loss: [1m[32m0.19885[0m[0m | time: 13.905s
[2K
| Adam | epoch: 010 | loss: 0.19885 - acc: 0.9364 -- iter: 0544/1104
[A[ATraining Step: 333  | total loss: [1m[32m0.19006[0m[0m | time: 14.760s
[2K
| Adam | epoch: 010 | loss: 0.19006 - acc: 0.9365 -- iter: 0576/1104
[A[ATraining Step: 334  | total loss: [1m[32m0.17495[0m[0m | time: 15.583s
[2K
| Adam | epoch: 010 | loss: 0.17495 - acc: 0.9429 -- iter: 0608/1104
[A[ATraining Step: 335  | total loss: [1m[32m0.16181[0m[0m | time: 16.448s
[2K
| Adam | epoch: 010 | loss: 0.16181 - acc: 0.9486 -- iter: 0640/1104
[A[ATraining Step: 336  | total loss: [1m[32m0.16277[0m[0m | time: 17.315s
[2K
| Adam | epoch: 010 | loss: 0.16277 - acc: 0.9506 -- iter: 0672/1104
[A[ATraining Step: 337  | total loss: [1m[32m0.15536[0m[0m | time: 18.161s
[2K
| Adam | epoch: 010 | loss: 0.15536 - acc: 0.9556 -- iter: 0704/1104
[A[ATraining Step: 338  | total loss: [1m[32m0.14503[0m[0m | time: 19.042s
[2K
| Adam | epoch: 010 | loss: 0.14503 - acc: 0.9600 -- iter: 0736/1104
[A[ATraining Step: 339  | total loss: [1m[32m0.14609[0m[0m | time: 19.864s
[2K
| Adam | epoch: 010 | loss: 0.14609 - acc: 0.9578 -- iter: 0768/1104
[A[ATraining Step: 340  | total loss: [1m[32m0.14368[0m[0m | time: 20.733s
[2K
| Adam | epoch: 010 | loss: 0.14368 - acc: 0.9526 -- iter: 0800/1104
[A[ATraining Step: 341  | total loss: [1m[32m0.14151[0m[0m | time: 21.731s
[2K
| Adam | epoch: 010 | loss: 0.14151 - acc: 0.9511 -- iter: 0832/1104
[A[ATraining Step: 342  | total loss: [1m[32m0.14207[0m[0m | time: 22.721s
[2K
| Adam | epoch: 010 | loss: 0.14207 - acc: 0.9529 -- iter: 0864/1104
[A[ATraining Step: 343  | total loss: [1m[32m0.13759[0m[0m | time: 23.425s
[2K
| Adam | epoch: 010 | loss: 0.13759 - acc: 0.9513 -- iter: 0896/1104
[A[ATraining Step: 344  | total loss: [1m[32m0.12910[0m[0m | time: 24.264s
[2K
| Adam | epoch: 010 | loss: 0.12910 - acc: 0.9562 -- iter: 0928/1104
[A[ATraining Step: 345  | total loss: [1m[32m0.12097[0m[0m | time: 25.123s
[2K
| Adam | epoch: 010 | loss: 0.12097 - acc: 0.9606 -- iter: 0960/1104
[A[ATraining Step: 346  | total loss: [1m[32m0.11435[0m[0m | time: 25.972s
[2K
| Adam | epoch: 010 | loss: 0.11435 - acc: 0.9614 -- iter: 0992/1104
[A[ATraining Step: 347  | total loss: [1m[32m0.10719[0m[0m | time: 26.828s
[2K
| Adam | epoch: 010 | loss: 0.10719 - acc: 0.9621 -- iter: 1024/1104
[A[ATraining Step: 348  | total loss: [1m[32m0.10136[0m[0m | time: 27.719s
[2K
| Adam | epoch: 010 | loss: 0.10136 - acc: 0.9659 -- iter: 1056/1104
[A[ATraining Step: 349  | total loss: [1m[32m0.09476[0m[0m | time: 28.633s
[2K
| Adam | epoch: 010 | loss: 0.09476 - acc: 0.9693 -- iter: 1088/1104
[A[ATraining Step: 350  | total loss: [1m[32m0.09252[0m[0m | time: 30.997s
[2K
| Adam | epoch: 010 | loss: 0.09252 - acc: 0.9693 | val_loss: 0.42786 - val_acc: 0.8699 -- iter: 1104/1104
--
Training Step: 351  | total loss: [1m[32m0.10782[0m[0m | time: 0.972s
[2K
| Adam | epoch: 011 | loss: 0.10782 - acc: 0.9630 -- iter: 0032/1104
[A[ATraining Step: 352  | total loss: [1m[32m0.09906[0m[0m | time: 1.917s
[2K
| Adam | epoch: 011 | loss: 0.09906 - acc: 0.9667 -- iter: 0064/1104
[A[ATraining Step: 353  | total loss: [1m[32m0.09460[0m[0m | time: 2.612s
[2K
| Adam | epoch: 011 | loss: 0.09460 - acc: 0.9669 -- iter: 0096/1104
[A[ATraining Step: 354  | total loss: [1m[32m0.08658[0m[0m | time: 3.422s
[2K
| Adam | epoch: 011 | loss: 0.08658 - acc: 0.9702 -- iter: 0128/1104
[A[ATraining Step: 355  | total loss: [1m[32m0.08236[0m[0m | time: 4.351s
[2K
| Adam | epoch: 011 | loss: 0.08236 - acc: 0.9732 -- iter: 0160/1104
[A[ATraining Step: 356  | total loss: [1m[32m0.07791[0m[0m | time: 5.178s
[2K
| Adam | epoch: 011 | loss: 0.07791 - acc: 0.9759 -- iter: 0192/1104
[A[ATraining Step: 357  | total loss: [1m[32m0.07483[0m[0m | time: 5.981s
[2K
| Adam | epoch: 011 | loss: 0.07483 - acc: 0.9751 -- iter: 0224/1104
[A[ATraining Step: 358  | total loss: [1m[32m0.08003[0m[0m | time: 6.827s
[2K
| Adam | epoch: 011 | loss: 0.08003 - acc: 0.9683 -- iter: 0256/1104
[A[ATraining Step: 359  | total loss: [1m[32m0.08074[0m[0m | time: 7.313s
[2K
| Adam | epoch: 011 | loss: 0.08074 - acc: 0.9683 -- iter: 0288/1104
[A[ATraining Step: 360  | total loss: [1m[32m0.10817[0m[0m | time: 7.780s
[2K
| Adam | epoch: 011 | loss: 0.10817 - acc: 0.9652 -- iter: 0320/1104
[A[ATraining Step: 361  | total loss: [1m[32m0.13028[0m[0m | time: 8.664s
[2K
| Adam | epoch: 011 | loss: 0.13028 - acc: 0.9499 -- iter: 0352/1104
[A[ATraining Step: 362  | total loss: [1m[32m0.19446[0m[0m | time: 9.516s
[2K
| Adam | epoch: 011 | loss: 0.19446 - acc: 0.9237 -- iter: 0384/1104
[A[ATraining Step: 363  | total loss: [1m[32m0.25454[0m[0m | time: 10.418s
[2K
| Adam | epoch: 011 | loss: 0.25454 - acc: 0.9095 -- iter: 0416/1104
[A[ATraining Step: 364  | total loss: [1m[32m0.42886[0m[0m | time: 11.462s
[2K
| Adam | epoch: 011 | loss: 0.42886 - acc: 0.8841 -- iter: 0448/1104
[A[ATraining Step: 365  | total loss: [1m[32m0.39004[0m[0m | time: 12.428s
[2K
| Adam | epoch: 011 | loss: 0.39004 - acc: 0.8957 -- iter: 0480/1104
[A[ATraining Step: 366  | total loss: [1m[32m0.36533[0m[0m | time: 13.146s
[2K
| Adam | epoch: 011 | loss: 0.36533 - acc: 0.8999 -- iter: 0512/1104
[A[ATraining Step: 367  | total loss: [1m[32m0.35274[0m[0m | time: 13.969s
[2K
| Adam | epoch: 011 | loss: 0.35274 - acc: 0.9005 -- iter: 0544/1104
[A[ATraining Step: 368  | total loss: [1m[32m0.33901[0m[0m | time: 14.792s
[2K
| Adam | epoch: 011 | loss: 0.33901 - acc: 0.9042 -- iter: 0576/1104
[A[ATraining Step: 369  | total loss: [1m[32m0.30887[0m[0m | time: 15.607s
[2K
| Adam | epoch: 011 | loss: 0.30887 - acc: 0.9138 -- iter: 0608/1104
[A[ATraining Step: 370  | total loss: [1m[32m0.28658[0m[0m | time: 16.424s
[2K
| Adam | epoch: 011 | loss: 0.28658 - acc: 0.9193 -- iter: 0640/1104
[A[ATraining Step: 371  | total loss: [1m[32m0.27656[0m[0m | time: 17.251s
[2K
| Adam | epoch: 011 | loss: 0.27656 - acc: 0.9242 -- iter: 0672/1104
[A[ATraining Step: 372  | total loss: [1m[32m0.27238[0m[0m | time: 18.092s
[2K
| Adam | epoch: 011 | loss: 0.27238 - acc: 0.9193 -- iter: 0704/1104
[A[ATraining Step: 373  | total loss: [1m[32m0.24984[0m[0m | time: 18.962s
[2K
| Adam | epoch: 011 | loss: 0.24984 - acc: 0.9274 -- iter: 0736/1104
[A[ATraining Step: 374  | total loss: [1m[32m0.24124[0m[0m | time: 19.848s
[2K
| Adam | epoch: 011 | loss: 0.24124 - acc: 0.9315 -- iter: 0768/1104
[A[ATraining Step: 375  | total loss: [1m[32m0.22795[0m[0m | time: 20.658s
[2K
| Adam | epoch: 011 | loss: 0.22795 - acc: 0.9352 -- iter: 0800/1104
[A[ATraining Step: 376  | total loss: [1m[32m0.21001[0m[0m | time: 21.614s
[2K
| Adam | epoch: 011 | loss: 0.21001 - acc: 0.9417 -- iter: 0832/1104
[A[ATraining Step: 377  | total loss: [1m[32m0.19783[0m[0m | time: 22.618s
[2K
| Adam | epoch: 011 | loss: 0.19783 - acc: 0.9444 -- iter: 0864/1104
[A[ATraining Step: 378  | total loss: [1m[32m0.18776[0m[0m | time: 23.563s
[2K
| Adam | epoch: 011 | loss: 0.18776 - acc: 0.9500 -- iter: 0896/1104
[A[ATraining Step: 379  | total loss: [1m[32m0.17382[0m[0m | time: 24.243s
[2K
| Adam | epoch: 011 | loss: 0.17382 - acc: 0.9550 -- iter: 0928/1104
[A[ATraining Step: 380  | total loss: [1m[32m0.16105[0m[0m | time: 25.106s
[2K
| Adam | epoch: 011 | loss: 0.16105 - acc: 0.9595 -- iter: 0960/1104
[A[ATraining Step: 381  | total loss: [1m[32m0.14783[0m[0m | time: 25.972s
[2K
| Adam | epoch: 011 | loss: 0.14783 - acc: 0.9635 -- iter: 0992/1104
[A[ATraining Step: 382  | total loss: [1m[32m0.14080[0m[0m | time: 26.838s
[2K
| Adam | epoch: 011 | loss: 0.14080 - acc: 0.9672 -- iter: 1024/1104
[A[ATraining Step: 383  | total loss: [1m[32m0.13102[0m[0m | time: 27.683s
[2K
| Adam | epoch: 011 | loss: 0.13102 - acc: 0.9673 -- iter: 1056/1104
[A[ATraining Step: 384  | total loss: [1m[32m0.12379[0m[0m | time: 28.565s
[2K
| Adam | epoch: 011 | loss: 0.12379 - acc: 0.9675 -- iter: 1088/1104
[A[ATraining Step: 385  | total loss: [1m[32m0.11310[0m[0m | time: 31.030s
[2K
| Adam | epoch: 011 | loss: 0.11310 - acc: 0.9707 | val_loss: 0.40496 - val_acc: 0.8757 -- iter: 1104/1104
--
Training Step: 386  | total loss: [1m[32m0.10880[0m[0m | time: 0.941s
[2K
| Adam | epoch: 012 | loss: 0.10880 - acc: 0.9705 -- iter: 0032/1104
[A[ATraining Step: 387  | total loss: [1m[32m0.09877[0m[0m | time: 1.919s
[2K
| Adam | epoch: 012 | loss: 0.09877 - acc: 0.9735 -- iter: 0064/1104
[A[ATraining Step: 388  | total loss: [1m[32m0.09072[0m[0m | time: 2.890s
[2K
| Adam | epoch: 012 | loss: 0.09072 - acc: 0.9761 -- iter: 0096/1104
[A[ATraining Step: 389  | total loss: [1m[32m0.08472[0m[0m | time: 3.580s
[2K
| Adam | epoch: 012 | loss: 0.08472 - acc: 0.9785 -- iter: 0128/1104
[A[ATraining Step: 390  | total loss: [1m[32m0.07803[0m[0m | time: 4.409s
[2K
| Adam | epoch: 012 | loss: 0.07803 - acc: 0.9807 -- iter: 0160/1104
[A[ATraining Step: 391  | total loss: [1m[32m0.07965[0m[0m | time: 5.282s
[2K
| Adam | epoch: 012 | loss: 0.07965 - acc: 0.9764 -- iter: 0192/1104
[A[ATraining Step: 392  | total loss: [1m[32m0.07277[0m[0m | time: 6.156s
[2K
| Adam | epoch: 012 | loss: 0.07277 - acc: 0.9787 -- iter: 0224/1104
[A[ATraining Step: 393  | total loss: [1m[32m0.06925[0m[0m | time: 7.047s
[2K
| Adam | epoch: 012 | loss: 0.06925 - acc: 0.9808 -- iter: 0256/1104
[A[ATraining Step: 394  | total loss: [1m[32m0.06346[0m[0m | time: 7.885s
[2K
| Adam | epoch: 012 | loss: 0.06346 - acc: 0.9828 -- iter: 0288/1104
[A[ATraining Step: 395  | total loss: [1m[32m0.08126[0m[0m | time: 8.343s
[2K
| Adam | epoch: 012 | loss: 0.08126 - acc: 0.9782 -- iter: 0320/1104
[A[ATraining Step: 396  | total loss: [1m[32m0.07466[0m[0m | time: 8.773s
[2K
| Adam | epoch: 012 | loss: 0.07466 - acc: 0.9804 -- iter: 0352/1104
[A[ATraining Step: 397  | total loss: [1m[32m0.06829[0m[0m | time: 9.664s
[2K
| Adam | epoch: 012 | loss: 0.06829 - acc: 0.9824 -- iter: 0384/1104
[A[ATraining Step: 398  | total loss: [1m[32m0.08122[0m[0m | time: 10.504s
[2K
| Adam | epoch: 012 | loss: 0.08122 - acc: 0.9748 -- iter: 0416/1104
[A[ATraining Step: 399  | total loss: [1m[32m0.09188[0m[0m | time: 11.344s
[2K
| Adam | epoch: 012 | loss: 0.09188 - acc: 0.9710 -- iter: 0448/1104
[A[ATraining Step: 400  | total loss: [1m[32m0.09966[0m[0m | time: 13.988s
[2K
| Adam | epoch: 012 | loss: 0.09966 - acc: 0.9708 | val_loss: 0.51256 - val_acc: 0.8439 -- iter: 0480/1104
--
Training Step: 401  | total loss: [1m[32m0.09587[0m[0m | time: 14.751s
[2K
| Adam | epoch: 012 | loss: 0.09587 - acc: 0.9706 -- iter: 0512/1104
[A[ATraining Step: 402  | total loss: [1m[32m0.08750[0m[0m | time: 15.573s
[2K
| Adam | epoch: 012 | loss: 0.08750 - acc: 0.9735 -- iter: 0544/1104
[A[ATraining Step: 403  | total loss: [1m[32m0.08024[0m[0m | time: 16.421s
[2K
| Adam | epoch: 012 | loss: 0.08024 - acc: 0.9762 -- iter: 0576/1104
[A[ATraining Step: 404  | total loss: [1m[32m0.07433[0m[0m | time: 17.243s
[2K
| Adam | epoch: 012 | loss: 0.07433 - acc: 0.9786 -- iter: 0608/1104
[A[ATraining Step: 405  | total loss: [1m[32m0.06939[0m[0m | time: 18.096s
[2K
| Adam | epoch: 012 | loss: 0.06939 - acc: 0.9807 -- iter: 0640/1104
[A[ATraining Step: 406  | total loss: [1m[32m0.06480[0m[0m | time: 18.913s
[2K
| Adam | epoch: 012 | loss: 0.06480 - acc: 0.9826 -- iter: 0672/1104
[A[ATraining Step: 407  | total loss: [1m[32m0.05868[0m[0m | time: 19.746s
[2K
| Adam | epoch: 012 | loss: 0.05868 - acc: 0.9844 -- iter: 0704/1104
[A[ATraining Step: 408  | total loss: [1m[32m0.05462[0m[0m | time: 20.614s
[2K
| Adam | epoch: 012 | loss: 0.05462 - acc: 0.9859 -- iter: 0736/1104
[A[ATraining Step: 409  | total loss: [1m[32m0.06408[0m[0m | time: 21.436s
[2K
| Adam | epoch: 012 | loss: 0.06408 - acc: 0.9811 -- iter: 0768/1104
[A[ATraining Step: 410  | total loss: [1m[32m0.05905[0m[0m | time: 22.254s
[2K
| Adam | epoch: 012 | loss: 0.05905 - acc: 0.9830 -- iter: 0800/1104
[A[ATraining Step: 411  | total loss: [1m[32m0.05384[0m[0m | time: 23.239s
[2K
| Adam | epoch: 012 | loss: 0.05384 - acc: 0.9847 -- iter: 0832/1104
[A[ATraining Step: 412  | total loss: [1m[32m0.05163[0m[0m | time: 24.256s
[2K
| Adam | epoch: 012 | loss: 0.05163 - acc: 0.9862 -- iter: 0864/1104
[A[ATraining Step: 413  | total loss: [1m[32m0.04832[0m[0m | time: 24.984s
[2K
| Adam | epoch: 012 | loss: 0.04832 - acc: 0.9876 -- iter: 0896/1104
[A[ATraining Step: 414  | total loss: [1m[32m0.04626[0m[0m | time: 25.798s
[2K
| Adam | epoch: 012 | loss: 0.04626 - acc: 0.9888 -- iter: 0928/1104
[A[ATraining Step: 415  | total loss: [1m[32m0.04378[0m[0m | time: 26.691s
[2K
| Adam | epoch: 012 | loss: 0.04378 - acc: 0.9900 -- iter: 0960/1104
[A[ATraining Step: 416  | total loss: [1m[32m0.04208[0m[0m | time: 27.551s
[2K
| Adam | epoch: 012 | loss: 0.04208 - acc: 0.9910 -- iter: 0992/1104
[A[ATraining Step: 417  | total loss: [1m[32m0.04116[0m[0m | time: 28.349s
[2K
| Adam | epoch: 012 | loss: 0.04116 - acc: 0.9919 -- iter: 1024/1104
[A[ATraining Step: 418  | total loss: [1m[32m0.03801[0m[0m | time: 29.176s
[2K
| Adam | epoch: 012 | loss: 0.03801 - acc: 0.9927 -- iter: 1056/1104
[A[ATraining Step: 419  | total loss: [1m[32m0.03496[0m[0m | time: 30.019s
[2K
| Adam | epoch: 012 | loss: 0.03496 - acc: 0.9934 -- iter: 1088/1104
[A[ATraining Step: 420  | total loss: [1m[32m0.03195[0m[0m | time: 32.351s
[2K
| Adam | epoch: 012 | loss: 0.03195 - acc: 0.9941 | val_loss: 0.48660 - val_acc: 0.8671 -- iter: 1104/1104
--
Training Step: 421  | total loss: [1m[32m0.03039[0m[0m | time: 0.913s
[2K
| Adam | epoch: 013 | loss: 0.03039 - acc: 0.9947 -- iter: 0032/1104
[A[ATraining Step: 422  | total loss: [1m[32m0.02861[0m[0m | time: 1.911s
[2K
| Adam | epoch: 013 | loss: 0.02861 - acc: 0.9952 -- iter: 0064/1104
[A[ATraining Step: 423  | total loss: [1m[32m0.03124[0m[0m | time: 2.820s
[2K
| Adam | epoch: 013 | loss: 0.03124 - acc: 0.9925 -- iter: 0096/1104
[A[ATraining Step: 424  | total loss: [1m[32m0.03115[0m[0m | time: 3.494s
[2K
| Adam | epoch: 013 | loss: 0.03115 - acc: 0.9933 -- iter: 0128/1104
[A[ATraining Step: 425  | total loss: [1m[32m0.02835[0m[0m | time: 4.317s
[2K
| Adam | epoch: 013 | loss: 0.02835 - acc: 0.9940 -- iter: 0160/1104
[A[ATraining Step: 426  | total loss: [1m[32m0.02584[0m[0m | time: 5.140s
[2K
| Adam | epoch: 013 | loss: 0.02584 - acc: 0.9946 -- iter: 0192/1104
[A[ATraining Step: 427  | total loss: [1m[32m0.02370[0m[0m | time: 5.972s
[2K
| Adam | epoch: 013 | loss: 0.02370 - acc: 0.9951 -- iter: 0224/1104
[A[ATraining Step: 428  | total loss: [1m[32m0.03278[0m[0m | time: 6.820s
[2K
| Adam | epoch: 013 | loss: 0.03278 - acc: 0.9925 -- iter: 0256/1104
[A[ATraining Step: 429  | total loss: [1m[32m0.03146[0m[0m | time: 7.691s
[2K
| Adam | epoch: 013 | loss: 0.03146 - acc: 0.9932 -- iter: 0288/1104
[A[ATraining Step: 430  | total loss: [1m[32m0.04579[0m[0m | time: 8.550s
[2K
| Adam | epoch: 013 | loss: 0.04579 - acc: 0.9877 -- iter: 0320/1104
[A[ATraining Step: 431  | total loss: [1m[32m0.04189[0m[0m | time: 9.000s
[2K
| Adam | epoch: 013 | loss: 0.04189 - acc: 0.9889 -- iter: 0352/1104
[A[ATraining Step: 432  | total loss: [1m[32m0.03892[0m[0m | time: 9.511s
[2K
| Adam | epoch: 013 | loss: 0.03892 - acc: 0.9900 -- iter: 0384/1104
[A[ATraining Step: 433  | total loss: [1m[32m0.03710[0m[0m | time: 10.368s
[2K
| Adam | epoch: 013 | loss: 0.03710 - acc: 0.9910 -- iter: 0416/1104
[A[ATraining Step: 434  | total loss: [1m[32m0.03498[0m[0m | time: 11.164s
[2K
| Adam | epoch: 013 | loss: 0.03498 - acc: 0.9919 -- iter: 0448/1104
[A[ATraining Step: 435  | total loss: [1m[32m0.03188[0m[0m | time: 12.139s
[2K
| Adam | epoch: 013 | loss: 0.03188 - acc: 0.9927 -- iter: 0480/1104
[A[ATraining Step: 436  | total loss: [1m[32m0.06324[0m[0m | time: 13.081s
[2K
| Adam | epoch: 013 | loss: 0.06324 - acc: 0.9903 -- iter: 0512/1104
[A[ATraining Step: 437  | total loss: [1m[32m0.08053[0m[0m | time: 13.860s
[2K
| Adam | epoch: 013 | loss: 0.08053 - acc: 0.9882 -- iter: 0544/1104
[A[ATraining Step: 438  | total loss: [1m[32m0.07278[0m[0m | time: 14.694s
[2K
| Adam | epoch: 013 | loss: 0.07278 - acc: 0.9893 -- iter: 0576/1104
[A[ATraining Step: 439  | total loss: [1m[32m0.09244[0m[0m | time: 15.562s
[2K
| Adam | epoch: 013 | loss: 0.09244 - acc: 0.9873 -- iter: 0608/1104
[A[ATraining Step: 440  | total loss: [1m[32m0.08381[0m[0m | time: 16.435s
[2K
| Adam | epoch: 013 | loss: 0.08381 - acc: 0.9886 -- iter: 0640/1104
[A[ATraining Step: 441  | total loss: [1m[32m0.07578[0m[0m | time: 17.325s
[2K
| Adam | epoch: 013 | loss: 0.07578 - acc: 0.9897 -- iter: 0672/1104
[A[ATraining Step: 442  | total loss: [1m[32m0.06907[0m[0m | time: 18.164s
[2K
| Adam | epoch: 013 | loss: 0.06907 - acc: 0.9907 -- iter: 0704/1104
[A[ATraining Step: 443  | total loss: [1m[32m0.06367[0m[0m | time: 19.057s
[2K
| Adam | epoch: 013 | loss: 0.06367 - acc: 0.9917 -- iter: 0736/1104
[A[ATraining Step: 444  | total loss: [1m[32m0.05858[0m[0m | time: 19.961s
[2K
| Adam | epoch: 013 | loss: 0.05858 - acc: 0.9925 -- iter: 0768/1104
[A[ATraining Step: 445  | total loss: [1m[32m0.05313[0m[0m | time: 20.853s
[2K
| Adam | epoch: 013 | loss: 0.05313 - acc: 0.9932 -- iter: 0800/1104
[A[ATraining Step: 446  | total loss: [1m[32m0.04894[0m[0m | time: 21.662s
[2K
| Adam | epoch: 013 | loss: 0.04894 - acc: 0.9939 -- iter: 0832/1104
[A[ATraining Step: 447  | total loss: [1m[32m0.04475[0m[0m | time: 22.654s
[2K
| Adam | epoch: 013 | loss: 0.04475 - acc: 0.9945 -- iter: 0864/1104
[A[ATraining Step: 448  | total loss: [1m[32m0.04140[0m[0m | time: 23.619s
[2K
| Adam | epoch: 013 | loss: 0.04140 - acc: 0.9951 -- iter: 0896/1104
[A[ATraining Step: 449  | total loss: [1m[32m0.03779[0m[0m | time: 24.446s
[2K
| Adam | epoch: 013 | loss: 0.03779 - acc: 0.9956 -- iter: 0928/1104
[A[ATraining Step: 450  | total loss: [1m[32m0.03501[0m[0m | time: 25.233s
[2K
| Adam | epoch: 013 | loss: 0.03501 - acc: 0.9960 -- iter: 0960/1104
[A[ATraining Step: 451  | total loss: [1m[32m0.03213[0m[0m | time: 26.088s
[2K
| Adam | epoch: 013 | loss: 0.03213 - acc: 0.9964 -- iter: 0992/1104
[A[ATraining Step: 452  | total loss: [1m[32m0.02973[0m[0m | time: 26.942s
[2K
| Adam | epoch: 013 | loss: 0.02973 - acc: 0.9968 -- iter: 1024/1104
[A[ATraining Step: 453  | total loss: [1m[32m0.02753[0m[0m | time: 27.795s
[2K
| Adam | epoch: 013 | loss: 0.02753 - acc: 0.9971 -- iter: 1056/1104
[A[ATraining Step: 454  | total loss: [1m[32m0.02522[0m[0m | time: 28.654s
[2K
| Adam | epoch: 013 | loss: 0.02522 - acc: 0.9974 -- iter: 1088/1104
[A[ATraining Step: 455  | total loss: [1m[32m0.02426[0m[0m | time: 31.030s
[2K
| Adam | epoch: 013 | loss: 0.02426 - acc: 0.9976 | val_loss: 0.47820 - val_acc: 0.8815 -- iter: 1104/1104
--
Training Step: 456  | total loss: [1m[32m0.02239[0m[0m | time: 0.825s
[2K
| Adam | epoch: 014 | loss: 0.02239 - acc: 0.9979 -- iter: 0032/1104
[A[ATraining Step: 457  | total loss: [1m[32m0.02887[0m[0m | time: 1.764s
[2K
| Adam | epoch: 014 | loss: 0.02887 - acc: 0.9950 -- iter: 0064/1104
[A[ATraining Step: 458  | total loss: [1m[32m0.02674[0m[0m | time: 2.726s
[2K
| Adam | epoch: 014 | loss: 0.02674 - acc: 0.9955 -- iter: 0096/1104
[A[ATraining Step: 459  | total loss: [1m[32m0.02920[0m[0m | time: 3.543s
[2K
| Adam | epoch: 014 | loss: 0.02920 - acc: 0.9928 -- iter: 0128/1104
[A[ATraining Step: 460  | total loss: [1m[32m0.02721[0m[0m | time: 4.328s
[2K
| Adam | epoch: 014 | loss: 0.02721 - acc: 0.9935 -- iter: 0160/1104
[A[ATraining Step: 461  | total loss: [1m[32m0.02564[0m[0m | time: 5.151s
[2K
| Adam | epoch: 014 | loss: 0.02564 - acc: 0.9942 -- iter: 0192/1104
[A[ATraining Step: 462  | total loss: [1m[32m0.02358[0m[0m | time: 5.982s
[2K
| Adam | epoch: 014 | loss: 0.02358 - acc: 0.9947 -- iter: 0224/1104
[A[ATraining Step: 463  | total loss: [1m[32m0.02194[0m[0m | time: 6.813s
[2K
| Adam | epoch: 014 | loss: 0.02194 - acc: 0.9953 -- iter: 0256/1104
[A[ATraining Step: 464  | total loss: [1m[32m0.02008[0m[0m | time: 7.648s
[2K
| Adam | epoch: 014 | loss: 0.02008 - acc: 0.9957 -- iter: 0288/1104
[A[ATraining Step: 465  | total loss: [1m[32m0.01887[0m[0m | time: 8.486s
[2K
| Adam | epoch: 014 | loss: 0.01887 - acc: 0.9962 -- iter: 0320/1104
[A[ATraining Step: 466  | total loss: [1m[32m0.02395[0m[0m | time: 9.325s
[2K
| Adam | epoch: 014 | loss: 0.02395 - acc: 0.9934 -- iter: 0352/1104
[A[ATraining Step: 467  | total loss: [1m[32m0.02252[0m[0m | time: 9.789s
[2K
| Adam | epoch: 014 | loss: 0.02252 - acc: 0.9941 -- iter: 0384/1104
[A[ATraining Step: 468  | total loss: [1m[32m0.02105[0m[0m | time: 10.261s
[2K
| Adam | epoch: 014 | loss: 0.02105 - acc: 0.9947 -- iter: 0416/1104
[A[ATraining Step: 469  | total loss: [1m[32m0.02001[0m[0m | time: 11.080s
[2K
| Adam | epoch: 014 | loss: 0.02001 - acc: 0.9952 -- iter: 0448/1104
[A[ATraining Step: 470  | total loss: [1m[32m0.01873[0m[0m | time: 11.912s
[2K
| Adam | epoch: 014 | loss: 0.01873 - acc: 0.9957 -- iter: 0480/1104
[A[ATraining Step: 471  | total loss: [1m[32m0.02263[0m[0m | time: 12.903s
[2K
| Adam | epoch: 014 | loss: 0.02263 - acc: 0.9961 -- iter: 0512/1104
[A[ATraining Step: 472  | total loss: [1m[32m0.02973[0m[0m | time: 13.860s
[2K
| Adam | epoch: 014 | loss: 0.02973 - acc: 0.9934 -- iter: 0544/1104
[A[ATraining Step: 473  | total loss: [1m[32m0.02982[0m[0m | time: 14.547s
[2K
| Adam | epoch: 014 | loss: 0.02982 - acc: 0.9940 -- iter: 0576/1104
[A[ATraining Step: 474  | total loss: [1m[32m0.02710[0m[0m | time: 15.390s
[2K
| Adam | epoch: 014 | loss: 0.02710 - acc: 0.9946 -- iter: 0608/1104
[A[ATraining Step: 475  | total loss: [1m[32m0.02509[0m[0m | time: 16.330s
[2K
| Adam | epoch: 014 | loss: 0.02509 - acc: 0.9952 -- iter: 0640/1104
[A[ATraining Step: 476  | total loss: [1m[32m0.03556[0m[0m | time: 17.223s
[2K
| Adam | epoch: 014 | loss: 0.03556 - acc: 0.9894 -- iter: 0672/1104
[A[ATraining Step: 477  | total loss: [1m[32m0.03345[0m[0m | time: 18.185s
[2K
| Adam | epoch: 014 | loss: 0.03345 - acc: 0.9905 -- iter: 0704/1104
[A[ATraining Step: 478  | total loss: [1m[32m0.03263[0m[0m | time: 19.115s
[2K
| Adam | epoch: 014 | loss: 0.03263 - acc: 0.9914 -- iter: 0736/1104
[A[ATraining Step: 479  | total loss: [1m[32m0.03719[0m[0m | time: 19.998s
[2K
| Adam | epoch: 014 | loss: 0.03719 - acc: 0.9892 -- iter: 0768/1104
[A[ATraining Step: 480  | total loss: [1m[32m0.03738[0m[0m | time: 20.879s
[2K
| Adam | epoch: 014 | loss: 0.03738 - acc: 0.9902 -- iter: 0800/1104
[A[ATraining Step: 481  | total loss: [1m[32m0.03420[0m[0m | time: 21.624s
[2K
| Adam | epoch: 014 | loss: 0.03420 - acc: 0.9912 -- iter: 0832/1104
[A[ATraining Step: 482  | total loss: [1m[32m0.03119[0m[0m | time: 22.525s
[2K
| Adam | epoch: 014 | loss: 0.03119 - acc: 0.9921 -- iter: 0864/1104
[A[ATraining Step: 483  | total loss: [1m[32m0.02836[0m[0m | time: 23.499s
[2K
| Adam | epoch: 014 | loss: 0.02836 - acc: 0.9929 -- iter: 0896/1104
[A[ATraining Step: 484  | total loss: [1m[32m0.02985[0m[0m | time: 24.371s
[2K
| Adam | epoch: 014 | loss: 0.02985 - acc: 0.9905 -- iter: 0928/1104
[A[ATraining Step: 485  | total loss: [1m[32m0.02885[0m[0m | time: 25.083s
[2K
| Adam | epoch: 014 | loss: 0.02885 - acc: 0.9914 -- iter: 0960/1104
[A[ATraining Step: 486  | total loss: [1m[32m0.02630[0m[0m | time: 25.907s
[2K
| Adam | epoch: 014 | loss: 0.02630 - acc: 0.9923 -- iter: 0992/1104
[A[ATraining Step: 487  | total loss: [1m[32m0.02392[0m[0m | time: 26.766s
[2K
| Adam | epoch: 014 | loss: 0.02392 - acc: 0.9931 -- iter: 1024/1104
[A[ATraining Step: 488  | total loss: [1m[32m0.02175[0m[0m | time: 27.591s
[2K
| Adam | epoch: 014 | loss: 0.02175 - acc: 0.9937 -- iter: 1056/1104
[A[ATraining Step: 489  | total loss: [1m[32m0.01998[0m[0m | time: 28.450s
[2K
| Adam | epoch: 014 | loss: 0.01998 - acc: 0.9944 -- iter: 1088/1104
[A[ATraining Step: 490  | total loss: [1m[32m0.01837[0m[0m | time: 30.870s
[2K
| Adam | epoch: 014 | loss: 0.01837 - acc: 0.9949 | val_loss: 0.64092 - val_acc: 0.8526 -- iter: 1104/1104
--
Training Step: 491  | total loss: [1m[32m0.03655[0m[0m | time: 0.870s
[2K
| Adam | epoch: 015 | loss: 0.03655 - acc: 0.9923 -- iter: 0032/1104
[A[ATraining Step: 492  | total loss: [1m[32m0.03345[0m[0m | time: 1.756s
[2K
| Adam | epoch: 015 | loss: 0.03345 - acc: 0.9931 -- iter: 0064/1104
[A[ATraining Step: 493  | total loss: [1m[32m0.03064[0m[0m | time: 2.866s
[2K
| Adam | epoch: 015 | loss: 0.03064 - acc: 0.9938 -- iter: 0096/1104
[A[ATraining Step: 494  | total loss: [1m[32m0.02856[0m[0m | time: 3.838s
[2K
| Adam | epoch: 015 | loss: 0.02856 - acc: 0.9944 -- iter: 0128/1104
[A[ATraining Step: 495  | total loss: [1m[32m0.02592[0m[0m | time: 4.559s
[2K
| Adam | epoch: 015 | loss: 0.02592 - acc: 0.9950 -- iter: 0160/1104
[A[ATraining Step: 496  | total loss: [1m[32m0.02374[0m[0m | time: 5.381s
[2K
| Adam | epoch: 015 | loss: 0.02374 - acc: 0.9955 -- iter: 0192/1104
[A[ATraining Step: 497  | total loss: [1m[32m0.02177[0m[0m | time: 6.219s
[2K
| Adam | epoch: 015 | loss: 0.02177 - acc: 0.9959 -- iter: 0224/1104
[A[ATraining Step: 498  | total loss: [1m[32m0.02094[0m[0m | time: 7.082s
[2K
| Adam | epoch: 015 | loss: 0.02094 - acc: 0.9963 -- iter: 0256/1104
[A[ATraining Step: 499  | total loss: [1m[32m0.02271[0m[0m | time: 7.934s
[2K
| Adam | epoch: 015 | loss: 0.02271 - acc: 0.9936 -- iter: 0288/1104
[A[ATraining Step: 500  | total loss: [1m[32m0.02158[0m[0m | time: 8.785s
[2K
| Adam | epoch: 015 | loss: 0.02158 - acc: 0.9942 -- iter: 0320/1104
[A[ATraining Step: 501  | total loss: [1m[32m0.02094[0m[0m | time: 9.645s
[2K
| Adam | epoch: 015 | loss: 0.02094 - acc: 0.9948 -- iter: 0352/1104
[A[ATraining Step: 502  | total loss: [1m[32m0.04067[0m[0m | time: 10.493s
[2K
| Adam | epoch: 015 | loss: 0.04067 - acc: 0.9922 -- iter: 0384/1104
[A[ATraining Step: 503  | total loss: [1m[32m0.03794[0m[0m | time: 10.973s
[2K
| Adam | epoch: 015 | loss: 0.03794 - acc: 0.9930 -- iter: 0416/1104
[A[ATraining Step: 504  | total loss: [1m[32m0.03860[0m[0m | time: 11.400s
[2K
| Adam | epoch: 015 | loss: 0.03860 - acc: 0.9937 -- iter: 0448/1104
[A[ATraining Step: 505  | total loss: [1m[32m0.03527[0m[0m | time: 12.184s
[2K
| Adam | epoch: 015 | loss: 0.03527 - acc: 0.9943 -- iter: 0480/1104
[A[ATraining Step: 506  | total loss: [1m[32m0.04418[0m[0m | time: 13.165s
[2K
| Adam | epoch: 015 | loss: 0.04418 - acc: 0.9855 -- iter: 0512/1104
[A[ATraining Step: 507  | total loss: [1m[32m0.04974[0m[0m | time: 14.161s
[2K
| Adam | epoch: 015 | loss: 0.04974 - acc: 0.9838 -- iter: 0544/1104
[A[ATraining Step: 508  | total loss: [1m[32m0.09166[0m[0m | time: 15.009s
[2K
| Adam | epoch: 015 | loss: 0.09166 - acc: 0.9792 -- iter: 0576/1104
[A[ATraining Step: 509  | total loss: [1m[32m0.08703[0m[0m | time: 15.841s
[2K
| Adam | epoch: 015 | loss: 0.08703 - acc: 0.9781 -- iter: 0608/1104
[A[ATraining Step: 510  | total loss: [1m[32m0.07961[0m[0m | time: 16.685s
[2K
| Adam | epoch: 015 | loss: 0.07961 - acc: 0.9803 -- iter: 0640/1104
[A[ATraining Step: 511  | total loss: [1m[32m0.07655[0m[0m | time: 17.527s
[2K
| Adam | epoch: 015 | loss: 0.07655 - acc: 0.9792 -- iter: 0672/1104
[A[ATraining Step: 512  | total loss: [1m[32m0.09630[0m[0m | time: 18.372s
[2K
| Adam | epoch: 015 | loss: 0.09630 - acc: 0.9750 -- iter: 0704/1104
[A[ATraining Step: 513  | total loss: [1m[32m0.09966[0m[0m | time: 19.282s
[2K
| Adam | epoch: 015 | loss: 0.09966 - acc: 0.9744 -- iter: 0736/1104
[A[ATraining Step: 514  | total loss: [1m[32m0.09064[0m[0m | time: 20.163s
[2K
| Adam | epoch: 015 | loss: 0.09064 - acc: 0.9769 -- iter: 0768/1104
[A[ATraining Step: 515  | total loss: [1m[32m0.08219[0m[0m | time: 21.021s
[2K
| Adam | epoch: 015 | loss: 0.08219 - acc: 0.9792 -- iter: 0800/1104
[A[ATraining Step: 516  | total loss: [1m[32m0.07794[0m[0m | time: 21.963s
[2K
| Adam | epoch: 015 | loss: 0.07794 - acc: 0.9782 -- iter: 0832/1104
[A[ATraining Step: 517  | total loss: [1m[32m0.07457[0m[0m | time: 22.796s
[2K
| Adam | epoch: 015 | loss: 0.07457 - acc: 0.9804 -- iter: 0864/1104
[A[ATraining Step: 518  | total loss: [1m[32m0.07062[0m[0m | time: 23.766s
[2K
| Adam | epoch: 015 | loss: 0.07062 - acc: 0.9823 -- iter: 0896/1104
[A[ATraining Step: 519  | total loss: [1m[32m0.06597[0m[0m | time: 24.791s
[2K
| Adam | epoch: 015 | loss: 0.06597 - acc: 0.9841 -- iter: 0928/1104
[A[ATraining Step: 520  | total loss: [1m[32m0.06174[0m[0m | time: 25.577s
[2K
| Adam | epoch: 015 | loss: 0.06174 - acc: 0.9857 -- iter: 0960/1104
[A[ATraining Step: 521  | total loss: [1m[32m0.06778[0m[0m | time: 26.337s
[2K
| Adam | epoch: 015 | loss: 0.06778 - acc: 0.9840 -- iter: 0992/1104
[A[ATraining Step: 522  | total loss: [1m[32m0.06291[0m[0m | time: 27.286s
[2K
| Adam | epoch: 015 | loss: 0.06291 - acc: 0.9856 -- iter: 1024/1104
[A[ATraining Step: 523  | total loss: [1m[32m0.05946[0m[0m | time: 28.186s
[2K
| Adam | epoch: 015 | loss: 0.05946 - acc: 0.9870 -- iter: 1056/1104
[A[ATraining Step: 524  | total loss: [1m[32m0.05439[0m[0m | time: 29.055s
[2K
| Adam | epoch: 015 | loss: 0.05439 - acc: 0.9883 -- iter: 1088/1104
[A[ATraining Step: 525  | total loss: [1m[32m0.04986[0m[0m | time: 31.482s
[2K
| Adam | epoch: 015 | loss: 0.04986 - acc: 0.9895 | val_loss: 0.43886 - val_acc: 0.8873 -- iter: 1104/1104
--
Validation AUC:0.9292100816671359
Validation AUPRC:0.9495029994581763
Test AUC:0.9207876712328767
Test AUPRC:0.922603182391062
BestTestF1Score	0.89	0.74	0.87	0.86	0.94	187	31	115	13	0.47
BestTestMCCScore	0.89	0.74	0.87	0.86	0.94	187	31	115	13	0.47
BestTestAccuracyScore	0.89	0.74	0.87	0.86	0.94	187	31	115	13	0.47
BestValidationF1Score	0.91	0.77	0.89	0.9	0.93	197	23	111	15	0.47
BestValidationMCC	0.91	0.77	0.89	0.9	0.93	197	23	111	15	0.47
BestValidationAccuracy	0.91	0.77	0.89	0.9	0.93	197	23	111	15	0.47
TestPredictions (Threshold:0.47)
CHEMBL71939,TP,ACT,0.9800000190734863	CHEMBL2177330,TN,INACT,0.009999999776482582	CHEMBL1087431,TN,INACT,0.009999999776482582	CHEMBL536085,TP,ACT,1.0	CHEMBL97631,TN,INACT,0.019999999552965164	CHEMBL534728,TP,ACT,1.0	CHEMBL1821803,TN,INACT,0.009999999776482582	CHEMBL1165279,FP,INACT,0.9100000262260437	CHEMBL1790495,TP,ACT,1.0	CHEMBL536760,TP,ACT,1.0	CHEMBL1824634,FN,ACT,0.14000000059604645	CHEMBL3144409,TP,ACT,1.0	CHEMBL313773,TP,ACT,0.9900000095367432	CHEMBL116247,TP,ACT,0.9900000095367432	CHEMBL94131,TP,ACT,0.6399999856948853	CHEMBL431401,FN,ACT,0.07000000029802322	CHEMBL2048575,TP,ACT,1.0	CHEMBL239745,TP,ACT,0.6000000238418579	CHEMBL146651,TP,ACT,1.0	CHEMBL280744,TP,ACT,1.0	CHEMBL266334,TP,ACT,0.9900000095367432	CHEMBL239320,FN,ACT,0.10999999940395355	CHEMBL1164239,TN,INACT,0.03999999910593033	CHEMBL3344272,FP,INACT,1.0	CHEMBL2115366,TP,ACT,1.0	CHEMBL2322607,FN,ACT,0.05000000074505806	CHEMBL1164332,TN,INACT,0.10000000149011612	CHEMBL1791135,TP,ACT,0.9900000095367432	CHEMBL3142176,TP,ACT,1.0	CHEMBL1165534,FP,INACT,0.8500000238418579	CHEMBL371193,TP,ACT,1.0	CHEMBL3143444,TP,ACT,1.0	CHEMBL2387550,TP,ACT,1.0	CHEMBL3650841,TN,INACT,0.0	CHEMBL286413,TP,ACT,0.9100000262260437	CHEMBL290732,TP,ACT,1.0	CHEMBL1163700,TN,INACT,0.20999999344348907	CHEMBL1215372,TN,INACT,0.0	CHEMBL2169947,TN,INACT,0.0	CHEMBL452191,TP,ACT,0.8600000143051147	CHEMBL1808232,TP,ACT,1.0	CHEMBL265270,TP,ACT,1.0	CHEMBL22411,TP,ACT,1.0	CHEMBL241032,TP,ACT,0.9900000095367432	CHEMBL1269674,TP,ACT,1.0	CHEMBL299834,TP,ACT,1.0	CHEMBL1163299,TN,INACT,0.009999999776482582	CHEMBL68229,TP,ACT,1.0	CHEMBL1164568,FP,INACT,0.9399999976158142	CHEMBL405844,TN,INACT,0.0	CHEMBL3142221,TP,ACT,1.0	CHEMBL3326698,TN,INACT,0.0	CHEMBL344010,TP,ACT,1.0	CHEMBL252459,TN,INACT,0.07999999821186066	CHEMBL289146,TP,ACT,1.0	CHEMBL3353630,TN,INACT,0.07000000029802322	CHEMBL282642,TP,ACT,1.0	CHEMBL350359,FP,INACT,1.0	CHEMBL440650,TP,ACT,1.0	CHEMBL1165489,FP,INACT,1.0	CHEMBL1076454,TP,ACT,0.9700000286102295	CHEMBL220895,TN,INACT,0.009999999776482582	CHEMBL3693238,TN,INACT,0.009999999776482582	CHEMBL3414702,TN,INACT,0.009999999776482582	CHEMBL1165526,TN,INACT,0.05999999865889549	CHEMBL585120,TN,INACT,0.009999999776482582	CHEMBL30869,TP,ACT,1.0	CHEMBL99903,TP,ACT,1.0	CHEMBL1790120,TP,ACT,0.5099999904632568	CHEMBL292726,TP,ACT,0.9700000286102295	CHEMBL3348545,TP,ACT,1.0	CHEMBL1923113,TP,ACT,0.75	CHEMBL288346,TP,ACT,1.0	CHEMBL439616,TP,ACT,1.0	CHEMBL3688649,TN,INACT,0.0	CHEMBL1790063,TP,ACT,0.9399999976158142	CHEMBL3683914,TN,INACT,0.0	CHEMBL3688762,TN,INACT,0.009999999776482582	CHEMBL57121,TP,ACT,1.0	CHEMBL556380,FP,INACT,0.9599999785423279	CHEMBL3688675,TN,INACT,0.0	CHEMBL1230745,TP,ACT,1.0	CHEMBL2169943,TN,INACT,0.009999999776482582	CHEMBL1269699,FN,ACT,0.0	CHEMBL2371847,TP,ACT,1.0	CHEMBL1824932,TP,ACT,0.9800000190734863	CHEMBL1215444,TN,INACT,0.0	CHEMBL431526,TP,ACT,1.0	CHEMBL3703207,TN,INACT,0.20999999344348907	CHEMBL407670,TP,ACT,1.0	CHEMBL2322611,TP,ACT,1.0	CHEMBL1796060,FN,ACT,0.3400000035762787	CHEMBL2169937,TN,INACT,0.009999999776482582	CHEMBL264854,TP,ACT,1.0	CHEMBL31889,TP,ACT,1.0	CHEMBL534729,TP,ACT,1.0	CHEMBL286958,FP,INACT,0.9700000286102295	CHEMBL52174,FP,INACT,0.7799999713897705	CHEMBL2169938,TN,INACT,0.009999999776482582	CHEMBL1215294,TN,INACT,0.0	CHEMBL3633308,TP,ACT,0.9900000095367432	CHEMBL3350020,TP,ACT,1.0	CHEMBL41303,TP,ACT,1.0	CHEMBL575232,TN,INACT,0.0	CHEMBL3703242,TN,INACT,0.0	CHEMBL356842,TP,ACT,0.9900000095367432	CHEMBL1222238,TN,INACT,0.0	CHEMBL49971,TN,INACT,0.009999999776482582	CHEMBL1258233,TN,INACT,0.009999999776482582	CHEMBL291037,FN,ACT,0.3100000023841858	CHEMBL1941010,TN,INACT,0.019999999552965164	CHEMBL76896,FN,ACT,0.07999999821186066	CHEMBL3354242,TN,INACT,0.009999999776482582	CHEMBL398418,TN,INACT,0.019999999552965164	CHEMBL3683822,TN,INACT,0.0	CHEMBL3400449,TP,ACT,1.0	CHEMBL3142772,TP,ACT,1.0	CHEMBL284254,TP,ACT,0.9800000190734863	CHEMBL1160990,TP,ACT,0.9700000286102295	CHEMBL460835,TN,INACT,0.0	CHEMBL397162,TN,INACT,0.009999999776482582	CHEMBL1821809,TN,INACT,0.009999999776482582	CHEMBL2111810,TP,ACT,0.9900000095367432	CHEMBL303699,TP,ACT,1.0	CHEMBL237891,TN,INACT,0.0	CHEMBL545630,TN,INACT,0.10999999940395355	CHEMBL1923115,TP,ACT,0.949999988079071	CHEMBL280816,TP,ACT,1.0	CHEMBL2371853,TP,ACT,1.0	CHEMBL416472,TP,ACT,1.0	CHEMBL319832,TP,ACT,1.0	CHEMBL347185,FP,INACT,1.0	CHEMBL469117,TN,INACT,0.019999999552965164	CHEMBL235820,FP,INACT,0.9900000095367432	CHEMBL222794,TN,INACT,0.3100000023841858	CHEMBL3683900,TN,INACT,0.009999999776482582	CHEMBL3703230,TN,INACT,0.009999999776482582	CHEMBL1546,TN,INACT,0.0	CHEMBL49989,FP,INACT,0.9900000095367432	CHEMBL1910319,TP,ACT,0.9900000095367432	CHEMBL3142335,TP,ACT,1.0	CHEMBL1164331,FP,INACT,0.9100000262260437	CHEMBL1164397,TN,INACT,0.009999999776482582	CHEMBL3143008,TP,ACT,0.9599999785423279	CHEMBL1222032,TN,INACT,0.0	CHEMBL1090025,TN,INACT,0.009999999776482582	CHEMBL1270277,TP,ACT,0.9900000095367432	CHEMBL2437452,TN,INACT,0.019999999552965164	CHEMBL49582,TP,ACT,1.0	CHEMBL53919,FP,INACT,1.0	CHEMBL508648,TN,INACT,0.05000000074505806	CHEMBL288347,TP,ACT,1.0	CHEMBL22504,TP,ACT,1.0	CHEMBL3403983,TP,ACT,1.0	CHEMBL3401349,TP,ACT,0.9800000190734863	CHEMBL319424,TP,ACT,1.0	CHEMBL2048580,TP,ACT,1.0	CHEMBL295332,TP,ACT,0.9900000095367432	CHEMBL324692,TP,ACT,1.0	CHEMBL1221921,TN,INACT,0.009999999776482582	CHEMBL31550,TP,ACT,1.0	CHEMBL1807378,TP,ACT,1.0	CHEMBL2437490,FN,ACT,0.44999998807907104	CHEMBL3633310,TP,ACT,0.9800000190734863	CHEMBL1957797,TP,ACT,0.9800000190734863	CHEMBL3401538,TP,ACT,1.0	CHEMBL2181997,TN,INACT,0.0	CHEMBL2380822,FP,INACT,0.8500000238418579	CHEMBL31420,TP,ACT,0.9900000095367432	CHEMBL2019032,TN,INACT,0.0	CHEMBL88069,TP,ACT,0.9599999785423279	CHEMBL361660,TN,INACT,0.0	CHEMBL235821,TN,INACT,0.0	CHEMBL373264,TP,ACT,1.0	CHEMBL3400434,TP,ACT,1.0	CHEMBL401474,TN,INACT,0.009999999776482582	CHEMBL2204329,TP,ACT,1.0	CHEMBL2059453,TN,INACT,0.0	CHEMBL29103,TP,ACT,1.0	CHEMBL1257228,TP,ACT,1.0	CHEMBL582045,TN,INACT,0.0	CHEMBL1163420,TN,INACT,0.03999999910593033	CHEMBL566415,TN,INACT,0.009999999776482582	CHEMBL1790076,TP,ACT,0.9300000071525574	CHEMBL939,TN,INACT,0.0	CHEMBL52833,TP,ACT,0.9900000095367432	CHEMBL3142328,TP,ACT,1.0	CHEMBL3639827,TN,INACT,0.0	CHEMBL306917,TP,ACT,1.0	CHEMBL1795901,TP,ACT,0.8199999928474426	CHEMBL2181981,TN,INACT,0.009999999776482582	CHEMBL3142251,TN,INACT,0.23000000417232513	CHEMBL493807,TN,INACT,0.029999999329447746	CHEMBL103905,TP,ACT,1.0	CHEMBL154897,TP,ACT,1.0	CHEMBL493637,TN,INACT,0.11999999731779099	CHEMBL3143673,TP,ACT,0.9900000095367432	CHEMBL3683890,TN,INACT,0.0	CHEMBL39538,FN,ACT,0.009999999776482582	CHEMBL46271,TP,ACT,0.949999988079071	CHEMBL265486,TP,ACT,0.9900000095367432	CHEMBL3143481,TP,ACT,0.9700000286102295	CHEMBL87316,TP,ACT,1.0	CHEMBL1091441,TN,INACT,0.009999999776482582	CHEMBL3691380,FP,INACT,0.49000000953674316	CHEMBL291091,TP,ACT,0.949999988079071	CHEMBL281153,TP,ACT,1.0	CHEMBL455047,TP,ACT,1.0	CHEMBL3127101,TN,INACT,0.019999999552965164	CHEMBL3142322,TP,ACT,1.0	CHEMBL3400437,TP,ACT,0.9900000095367432	CHEMBL185917,TN,INACT,0.0	CHEMBL540047,TP,ACT,1.0	CHEMBL48112,TP,ACT,1.0	CHEMBL40053,TP,ACT,1.0	CHEMBL2177321,TN,INACT,0.0	CHEMBL258277,TN,INACT,0.0	CHEMBL96796,TP,ACT,0.8500000238418579	CHEMBL585952,FP,INACT,0.9700000286102295	CHEMBL293320,TP,ACT,0.9900000095367432	CHEMBL3144144,TP,ACT,1.0	CHEMBL1163234,FP,INACT,0.550000011920929	CHEMBL3344263,FP,INACT,1.0	CHEMBL398997,TP,ACT,0.9399999976158142	CHEMBL540885,TP,ACT,1.0	CHEMBL255750,TN,INACT,0.009999999776482582	CHEMBL3403992,FN,ACT,0.009999999776482582	CHEMBL473159,TN,INACT,0.009999999776482582	CHEMBL48201,TP,ACT,0.9900000095367432	CHEMBL1093066,TN,INACT,0.009999999776482582	CHEMBL2381579,TN,INACT,0.0	CHEMBL151836,FP,INACT,0.9800000190734863	CHEMBL1782313,FP,INACT,1.0	CHEMBL422190,FN,ACT,0.07999999821186066	CHEMBL31880,TP,ACT,0.949999988079071	CHEMBL266139,TP,ACT,0.9900000095367432	CHEMBL1257824,TP,ACT,1.0	CHEMBL3350015,TP,ACT,1.0	CHEMBL3703222,TN,INACT,0.05000000074505806	CHEMBL90896,TP,ACT,1.0	CHEMBL442029,TP,ACT,1.0	CHEMBL3142766,TP,ACT,1.0	CHEMBL286316,TP,ACT,1.0	CHEMBL302984,TP,ACT,0.9900000095367432	CHEMBL354767,TP,ACT,1.0	CHEMBL3659641,TN,INACT,0.4699999988079071	CHEMBL3318945,TP,ACT,0.9700000286102295	CHEMBL2011271,TN,INACT,0.0	CHEMBL2169922,TN,INACT,0.009999999776482582	CHEMBL556766,TP,ACT,1.0	CHEMBL1790064,TP,ACT,0.9900000095367432	CHEMBL340907,TP,ACT,0.9900000095367432	CHEMBL327710,TP,ACT,0.9900000095367432	CHEMBL3143458,TP,ACT,1.0	CHEMBL3650158,TN,INACT,0.009999999776482582	CHEMBL3127097,TN,INACT,0.009999999776482582	CHEMBL431217,TP,ACT,0.9900000095367432	CHEMBL3403987,TP,ACT,1.0	CHEMBL2177485,TN,INACT,0.23000000417232513	CHEMBL3688678,TN,INACT,0.019999999552965164	CHEMBL63190,TP,ACT,0.9900000095367432	CHEMBL1222236,TN,INACT,0.0	CHEMBL3354262,FP,INACT,0.8100000023841858	CHEMBL3401343,TP,ACT,0.9800000190734863	CHEMBL94677,TP,ACT,0.9900000095367432	CHEMBL1788375,TN,INACT,0.05000000074505806	CHEMBL1941011,TN,INACT,0.05000000074505806	CHEMBL1164127,TN,INACT,0.10999999940395355	CHEMBL32575,TP,ACT,1.0	CHEMBL1269676,TP,ACT,1.0	CHEMBL582828,FP,INACT,0.9300000071525574	CHEMBL31881,TP,ACT,1.0	CHEMBL48414,TP,ACT,1.0	CHEMBL3633131,TP,ACT,1.0	CHEMBL279917,TP,ACT,1.0	CHEMBL1796067,TP,ACT,0.9700000286102295	CHEMBL1269695,TP,ACT,0.9599999785423279	CHEMBL536294,TP,ACT,1.0	CHEMBL113917,TN,INACT,0.0	CHEMBL127362,TP,ACT,1.0	CHEMBL1760863,TN,INACT,0.009999999776482582	CHEMBL281436,TP,ACT,0.9800000190734863	CHEMBL496827,TP,ACT,0.9900000095367432	CHEMBL1824948,TP,ACT,0.9800000190734863	CHEMBL406089,FP,INACT,0.9700000286102295	CHEMBL290605,TP,ACT,1.0	CHEMBL2272783,FP,INACT,0.9300000071525574	CHEMBL1782318,TN,INACT,0.03999999910593033	CHEMBL254068,TN,INACT,0.0	CHEMBL441371,FP,INACT,0.9900000095367432	CHEMBL118421,TP,ACT,1.0	CHEMBL3604595,FP,INACT,0.9800000190734863	CHEMBL1824633,FN,ACT,0.019999999552965164	CHEMBL325329,TP,ACT,1.0	CHEMBL300468,TP,ACT,0.9800000190734863	CHEMBL3349576,TP,ACT,1.0	CHEMBL1164617,TN,INACT,0.05000000074505806	CHEMBL3401542,TP,ACT,1.0	CHEMBL149356,TN,INACT,0.05000000074505806	CHEMBL3400429,TP,ACT,0.9900000095367432	CHEMBL500811,TP,ACT,1.0	CHEMBL3348551,TP,ACT,0.9300000071525574	CHEMBL1412710,TN,INACT,0.0	CHEMBL1214217,TN,INACT,0.05000000074505806	CHEMBL3349393,TP,ACT,1.0	CHEMBL3703205,TN,INACT,0.029999999329447746	CHEMBL53115,TP,ACT,0.9900000095367432	CHEMBL286147,TP,ACT,0.9100000262260437	CHEMBL1165197,TN,INACT,0.07999999821186066	CHEMBL31259,TP,ACT,0.9900000095367432	CHEMBL2151040,TN,INACT,0.019999999552965164	CHEMBL3348543,TP,ACT,0.9900000095367432	CHEMBL157575,FP,INACT,1.0	CHEMBL599965,FP,INACT,0.9599999785423279	CHEMBL435266,TP,ACT,0.9900000095367432	CHEMBL1941015,TN,INACT,0.10999999940395355	CHEMBL1215371,TN,INACT,0.0	CHEMBL338891,TP,ACT,1.0	CHEMBL1203095,TP,ACT,1.0	CHEMBL3633121,TP,ACT,1.0	CHEMBL571319,TN,INACT,0.009999999776482582	CHEMBL54022,TN,INACT,0.07999999821186066	CHEMBL140721,TP,ACT,0.9900000095367432	CHEMBL562634,TP,ACT,1.0	CHEMBL1163251,TN,INACT,0.0	CHEMBL27307,FP,INACT,0.9599999785423279	CHEMBL3688686,TN,INACT,0.009999999776482582	CHEMBL284701,TP,ACT,0.9900000095367432	CHEMBL117799,TP,ACT,1.0	CHEMBL1269758,TP,ACT,0.47999998927116394	CHEMBL353412,FP,INACT,0.9900000095367432	CHEMBL1761673,TP,ACT,0.9900000095367432	CHEMBL1164493,TN,INACT,0.009999999776482582	CHEMBL2349466,TN,INACT,0.009999999776482582	CHEMBL194658,TP,ACT,1.0	CHEMBL3703223,TN,INACT,0.029999999329447746	CHEMBL3143476,TP,ACT,0.9700000286102295	CHEMBL511390,TN,INACT,0.05000000074505806	CHEMBL295507,TP,ACT,1.0	CHEMBL2322541,TN,INACT,0.0	CHEMBL1923129,TP,ACT,0.9900000095367432	CHEMBL1076444,TP,ACT,1.0	CHEMBL3604596,TN,INACT,0.05000000074505806	CHEMBL327616,TP,ACT,0.9900000095367432	CHEMBL3142183,TP,ACT,1.0	CHEMBL285046,TP,ACT,0.9900000095367432	

