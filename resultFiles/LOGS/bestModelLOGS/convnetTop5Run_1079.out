CNNModel CHEMBL4247 RMSprop 0.0005 30 256 0 0.8 False True
Number of active compounds :	929
Number of inactive compounds :	929
---------------------------------
Run id: CNNModel_CHEMBL4247_RMSprop_0.0005_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4247_RMSprop_0.0005_30_256_0.8_True/
---------------------------------
Training samples: 1162
Validation samples: 364
--
Training Step: 1  | time: 1.702s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1162
[A[ATraining Step: 2  | total loss: [1m[32m0.62392[0m[0m | time: 3.345s
[2K
| RMSProp | epoch: 001 | loss: 0.62392 - acc: 0.4219 -- iter: 0064/1162
[A[ATraining Step: 3  | total loss: [1m[32m0.68064[0m[0m | time: 4.745s
[2K
| RMSProp | epoch: 001 | loss: 0.68064 - acc: 0.4858 -- iter: 0096/1162
[A[ATraining Step: 4  | total loss: [1m[32m0.68959[0m[0m | time: 5.925s
[2K
| RMSProp | epoch: 001 | loss: 0.68959 - acc: 0.5433 -- iter: 0128/1162
[A[ATraining Step: 5  | total loss: [1m[32m0.69212[0m[0m | time: 7.462s
[2K
| RMSProp | epoch: 001 | loss: 0.69212 - acc: 0.5133 -- iter: 0160/1162
[A[ATraining Step: 6  | total loss: [1m[32m0.69365[0m[0m | time: 9.008s
[2K
| RMSProp | epoch: 001 | loss: 0.69365 - acc: 0.4244 -- iter: 0192/1162
[A[ATraining Step: 7  | total loss: [1m[32m0.69421[0m[0m | time: 10.484s
[2K
| RMSProp | epoch: 001 | loss: 0.69421 - acc: 0.3948 -- iter: 0224/1162
[A[ATraining Step: 8  | total loss: [1m[32m0.69267[0m[0m | time: 19.805s
[2K
| RMSProp | epoch: 001 | loss: 0.69267 - acc: 0.5418 -- iter: 0256/1162
[A[ATraining Step: 9  | total loss: [1m[32m0.69307[0m[0m | time: 65.778s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5197 -- iter: 0288/1162
[A[ATraining Step: 10  | total loss: [1m[32m0.69347[0m[0m | time: 94.457s
[2K
| RMSProp | epoch: 001 | loss: 0.69347 - acc: 0.4630 -- iter: 0320/1162
[A[ATraining Step: 11  | total loss: [1m[32m0.69267[0m[0m | time: 134.138s
[2K
| RMSProp | epoch: 001 | loss: 0.69267 - acc: 0.5249 -- iter: 0352/1162
[A[ATraining Step: 12  | total loss: [1m[32m0.69244[0m[0m | time: 172.121s
[2K
| RMSProp | epoch: 001 | loss: 0.69244 - acc: 0.5559 -- iter: 0384/1162
[A[ATraining Step: 13  | total loss: [1m[32m0.69294[0m[0m | time: 193.312s
[2K
| RMSProp | epoch: 001 | loss: 0.69294 - acc: 0.5319 -- iter: 0416/1162
[A[ATraining Step: 14  | total loss: [1m[32m0.69375[0m[0m | time: 194.634s
[2K
| RMSProp | epoch: 001 | loss: 0.69375 - acc: 0.4550 -- iter: 0448/1162
[A[ATraining Step: 15  | total loss: [1m[32m0.69320[0m[0m | time: 195.883s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.5093 -- iter: 0480/1162
[A[ATraining Step: 16  | total loss: [1m[32m0.69309[0m[0m | time: 197.104s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5175 -- iter: 0512/1162
[A[ATraining Step: 17  | total loss: [1m[32m0.69329[0m[0m | time: 198.434s
[2K
| RMSProp | epoch: 001 | loss: 0.69329 - acc: 0.5000 -- iter: 0544/1162
[A[ATraining Step: 18  | total loss: [1m[32m0.69361[0m[0m | time: 200.083s
[2K
| RMSProp | epoch: 001 | loss: 0.69361 - acc: 0.4675 -- iter: 0576/1162
[A[ATraining Step: 19  | total loss: [1m[32m0.69354[0m[0m | time: 201.367s
[2K
| RMSProp | epoch: 001 | loss: 0.69354 - acc: 0.4679 -- iter: 0608/1162
[A[ATraining Step: 20  | total loss: [1m[32m0.69350[0m[0m | time: 202.438s
[2K
| RMSProp | epoch: 001 | loss: 0.69350 - acc: 0.4682 -- iter: 0640/1162
[A[ATraining Step: 21  | total loss: [1m[32m0.69350[0m[0m | time: 203.803s
[2K
| RMSProp | epoch: 001 | loss: 0.69350 - acc: 0.4684 -- iter: 0672/1162
[A[ATraining Step: 22  | total loss: [1m[32m0.69324[0m[0m | time: 205.154s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.5060 -- iter: 0704/1162
[A[ATraining Step: 23  | total loss: [1m[32m0.69344[0m[0m | time: 206.463s
[2K
| RMSProp | epoch: 001 | loss: 0.69344 - acc: 0.4861 -- iter: 0736/1162
[A[ATraining Step: 24  | total loss: [1m[32m0.69290[0m[0m | time: 207.838s
[2K
| RMSProp | epoch: 001 | loss: 0.69290 - acc: 0.5252 -- iter: 0768/1162
[A[ATraining Step: 25  | total loss: [1m[32m0.69287[0m[0m | time: 209.198s
[2K
| RMSProp | epoch: 001 | loss: 0.69287 - acc: 0.5268 -- iter: 0800/1162
[A[ATraining Step: 26  | total loss: [1m[32m0.69323[0m[0m | time: 210.506s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4949 -- iter: 0832/1162
[A[ATraining Step: 27  | total loss: [1m[32m0.69347[0m[0m | time: 211.894s
[2K
| RMSProp | epoch: 001 | loss: 0.69347 - acc: 0.4721 -- iter: 0864/1162
[A[ATraining Step: 28  | total loss: [1m[32m0.69328[0m[0m | time: 213.265s
[2K
| RMSProp | epoch: 001 | loss: 0.69328 - acc: 0.4869 -- iter: 0896/1162
[A[ATraining Step: 29  | total loss: [1m[32m0.69316[0m[0m | time: 214.199s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4977 -- iter: 0928/1162
[A[ATraining Step: 30  | total loss: [1m[32m0.69300[0m[0m | time: 214.982s
[2K
| RMSProp | epoch: 001 | loss: 0.69300 - acc: 0.5130 -- iter: 0960/1162
[A[ATraining Step: 31  | total loss: [1m[32m0.69271[0m[0m | time: 215.771s
[2K
| RMSProp | epoch: 001 | loss: 0.69271 - acc: 0.5461 -- iter: 0992/1162
[A[ATraining Step: 32  | total loss: [1m[32m0.69269[0m[0m | time: 216.646s
[2K
| RMSProp | epoch: 001 | loss: 0.69269 - acc: 0.5427 -- iter: 1024/1162
[A[ATraining Step: 33  | total loss: [1m[32m0.69218[0m[0m | time: 217.530s
[2K
| RMSProp | epoch: 001 | loss: 0.69218 - acc: 0.5814 -- iter: 1056/1162
[A[ATraining Step: 34  | total loss: [1m[32m0.69231[0m[0m | time: 218.328s
[2K
| RMSProp | epoch: 001 | loss: 0.69231 - acc: 0.5706 -- iter: 1088/1162
[A[ATraining Step: 35  | total loss: [1m[32m0.69257[0m[0m | time: 219.113s
[2K
| RMSProp | epoch: 001 | loss: 0.69257 - acc: 0.5493 -- iter: 1120/1162
[A[ATraining Step: 36  | total loss: [1m[32m0.69268[0m[0m | time: 219.901s
[2K
| RMSProp | epoch: 001 | loss: 0.69268 - acc: 0.5392 -- iter: 1152/1162
[A[ATraining Step: 37  | total loss: [1m[32m0.69261[0m[0m | time: 221.772s
[2K
| RMSProp | epoch: 001 | loss: 0.69261 - acc: 0.5439 | val_loss: 0.69321 - val_acc: 0.4945 -- iter: 1162/1162
--
Training Step: 38  | total loss: [1m[32m0.69326[0m[0m | time: 0.253s
[2K
| RMSProp | epoch: 002 | loss: 0.69326 - acc: 0.4962 -- iter: 0032/1162
[A[ATraining Step: 39  | total loss: [1m[32m0.69374[0m[0m | time: 1.059s
[2K
| RMSProp | epoch: 002 | loss: 0.69374 - acc: 0.4586 -- iter: 0064/1162
[A[ATraining Step: 40  | total loss: [1m[32m0.69345[0m[0m | time: 1.877s
[2K
| RMSProp | epoch: 002 | loss: 0.69345 - acc: 0.4839 -- iter: 0096/1162
[A[ATraining Step: 41  | total loss: [1m[32m0.69325[0m[0m | time: 2.813s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4984 -- iter: 0128/1162
[A[ATraining Step: 42  | total loss: [1m[32m0.69350[0m[0m | time: 3.542s
[2K
| RMSProp | epoch: 002 | loss: 0.69350 - acc: 0.4818 -- iter: 0160/1162
[A[ATraining Step: 43  | total loss: [1m[32m0.69354[0m[0m | time: 4.353s
[2K
| RMSProp | epoch: 002 | loss: 0.69354 - acc: 0.4740 -- iter: 0192/1162
[A[ATraining Step: 44  | total loss: [1m[32m0.69353[0m[0m | time: 5.202s
[2K
| RMSProp | epoch: 002 | loss: 0.69353 - acc: 0.4731 -- iter: 0224/1162
[A[ATraining Step: 45  | total loss: [1m[32m0.69333[0m[0m | time: 6.142s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.4936 -- iter: 0256/1162
[A[ATraining Step: 46  | total loss: [1m[32m0.69340[0m[0m | time: 6.908s
[2K
| RMSProp | epoch: 002 | loss: 0.69340 - acc: 0.4842 -- iter: 0288/1162
[A[ATraining Step: 47  | total loss: [1m[32m0.69319[0m[0m | time: 7.767s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.5021 -- iter: 0320/1162
[A[ATraining Step: 48  | total loss: [1m[32m0.69307[0m[0m | time: 8.632s
[2K
| RMSProp | epoch: 002 | loss: 0.69307 - acc: 0.5169 -- iter: 0352/1162
[A[ATraining Step: 49  | total loss: [1m[32m0.69323[0m[0m | time: 9.456s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.5043 -- iter: 0384/1162
[A[ATraining Step: 50  | total loss: [1m[32m0.69310[0m[0m | time: 10.259s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5085 -- iter: 0416/1162
[A[ATraining Step: 51  | total loss: [1m[32m0.69295[0m[0m | time: 11.063s
[2K
| RMSProp | epoch: 002 | loss: 0.69295 - acc: 0.5215 -- iter: 0448/1162
[A[ATraining Step: 52  | total loss: [1m[32m0.69287[0m[0m | time: 11.898s
[2K
| RMSProp | epoch: 002 | loss: 0.69287 - acc: 0.5277 -- iter: 0480/1162
[A[ATraining Step: 53  | total loss: [1m[32m0.69282[0m[0m | time: 12.714s
[2K
| RMSProp | epoch: 002 | loss: 0.69282 - acc: 0.5328 -- iter: 0512/1162
[A[ATraining Step: 54  | total loss: [1m[32m0.69307[0m[0m | time: 13.540s
[2K
| RMSProp | epoch: 002 | loss: 0.69307 - acc: 0.5144 -- iter: 0544/1162
[A[ATraining Step: 55  | total loss: [1m[32m0.69331[0m[0m | time: 14.321s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4945 -- iter: 0576/1162
[A[ATraining Step: 56  | total loss: [1m[32m0.69355[0m[0m | time: 15.894s
[2K
| RMSProp | epoch: 002 | loss: 0.69355 - acc: 0.4733 -- iter: 0608/1162
[A[ATraining Step: 57  | total loss: [1m[32m0.69347[0m[0m | time: 17.370s
[2K
| RMSProp | epoch: 002 | loss: 0.69347 - acc: 0.4813 -- iter: 0640/1162
[A[ATraining Step: 58  | total loss: [1m[32m0.69348[0m[0m | time: 18.743s
[2K
| RMSProp | epoch: 002 | loss: 0.69348 - acc: 0.4754 -- iter: 0672/1162
[A[ATraining Step: 59  | total loss: [1m[32m0.69365[0m[0m | time: 69.949s
[2K
| RMSProp | epoch: 002 | loss: 0.69365 - acc: 0.4577 -- iter: 0704/1162
[A[ATraining Step: 60  | total loss: [1m[32m0.69362[0m[0m | time: 118.601s
[2K
| RMSProp | epoch: 002 | loss: 0.69362 - acc: 0.4550 -- iter: 0736/1162
[A[ATraining Step: 61  | total loss: [1m[32m0.69356[0m[0m | time: 154.101s
[2K
| RMSProp | epoch: 002 | loss: 0.69356 - acc: 0.4609 -- iter: 0768/1162
[A[ATraining Step: 62  | total loss: [1m[32m0.69351[0m[0m | time: 155.493s
[2K
| RMSProp | epoch: 002 | loss: 0.69351 - acc: 0.4619 -- iter: 0800/1162
[A[ATraining Step: 63  | total loss: [1m[32m0.69350[0m[0m | time: 156.811s
[2K
| RMSProp | epoch: 002 | loss: 0.69350 - acc: 0.4588 -- iter: 0832/1162
[A[ATraining Step: 64  | total loss: [1m[32m0.69349[0m[0m | time: 158.406s
[2K
| RMSProp | epoch: 002 | loss: 0.69349 - acc: 0.4639 -- iter: 0864/1162
[A[ATraining Step: 65  | total loss: [1m[32m0.69345[0m[0m | time: 159.807s
[2K
| RMSProp | epoch: 002 | loss: 0.69345 - acc: 0.4684 -- iter: 0896/1162
[A[ATraining Step: 66  | total loss: [1m[32m0.69342[0m[0m | time: 161.504s
[2K
| RMSProp | epoch: 002 | loss: 0.69342 - acc: 0.4684 -- iter: 0928/1162
[A[ATraining Step: 67  | total loss: [1m[32m0.69342[0m[0m | time: 163.207s
[2K
| RMSProp | epoch: 002 | loss: 0.69342 - acc: 0.4610 -- iter: 0960/1162
[A[ATraining Step: 68  | total loss: [1m[32m0.69342[0m[0m | time: 164.726s
[2K
| RMSProp | epoch: 002 | loss: 0.69342 - acc: 0.4582 -- iter: 0992/1162
[A[ATraining Step: 69  | total loss: [1m[32m0.69337[0m[0m | time: 166.269s
[2K
| RMSProp | epoch: 002 | loss: 0.69337 - acc: 0.4704 -- iter: 1024/1162
[A[ATraining Step: 70  | total loss: [1m[32m0.69329[0m[0m | time: 167.929s
[2K
| RMSProp | epoch: 002 | loss: 0.69329 - acc: 0.4810 -- iter: 1056/1162
[A[ATraining Step: 71  | total loss: [1m[32m0.69308[0m[0m | time: 169.700s
[2K
| RMSProp | epoch: 002 | loss: 0.69308 - acc: 0.5117 -- iter: 1088/1162
[A[ATraining Step: 72  | total loss: [1m[32m0.69303[0m[0m | time: 173.642s
[2K
| RMSProp | epoch: 002 | loss: 0.69303 - acc: 0.5174 -- iter: 1120/1162
[A[ATraining Step: 73  | total loss: [1m[32m0.69293[0m[0m | time: 174.852s
[2K
| RMSProp | epoch: 002 | loss: 0.69293 - acc: 0.5259 -- iter: 1152/1162
[A[ATraining Step: 74  | total loss: [1m[32m0.69323[0m[0m | time: 179.237s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.5059 | val_loss: 0.69321 - val_acc: 0.4945 -- iter: 1162/1162
--
Training Step: 75  | total loss: [1m[32m0.69315[0m[0m | time: 0.623s
[2K
| RMSProp | epoch: 003 | loss: 0.69315 - acc: 0.5120 -- iter: 0032/1162
[A[ATraining Step: 76  | total loss: [1m[32m0.69279[0m[0m | time: 1.302s
[2K
| RMSProp | epoch: 003 | loss: 0.69279 - acc: 0.5429 -- iter: 0064/1162
[A[ATraining Step: 77  | total loss: [1m[32m0.69220[0m[0m | time: 2.667s
[2K
| RMSProp | epoch: 003 | loss: 0.69220 - acc: 0.5701 -- iter: 0096/1162
[A[ATraining Step: 78  | total loss: [1m[32m0.69241[0m[0m | time: 3.887s
[2K
| RMSProp | epoch: 003 | loss: 0.69241 - acc: 0.5595 -- iter: 0128/1162
[A[ATraining Step: 79  | total loss: [1m[32m0.69265[0m[0m | time: 5.541s
[2K
| RMSProp | epoch: 003 | loss: 0.69265 - acc: 0.5469 -- iter: 0160/1162
[A[ATraining Step: 80  | total loss: [1m[32m0.69286[0m[0m | time: 7.121s
[2K
| RMSProp | epoch: 003 | loss: 0.69286 - acc: 0.5357 -- iter: 0192/1162
[A[ATraining Step: 81  | total loss: [1m[32m0.69234[0m[0m | time: 8.767s
[2K
| RMSProp | epoch: 003 | loss: 0.69234 - acc: 0.5574 -- iter: 0224/1162
[A[ATraining Step: 82  | total loss: [1m[32m0.69270[0m[0m | time: 11.139s
[2K
| RMSProp | epoch: 003 | loss: 0.69270 - acc: 0.5422 -- iter: 0256/1162
[A[ATraining Step: 83  | total loss: [1m[32m0.69306[0m[0m | time: 12.317s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5255 -- iter: 0288/1162
[A[ATraining Step: 84  | total loss: [1m[32m0.69298[0m[0m | time: 13.838s
[2K
| RMSProp | epoch: 003 | loss: 0.69298 - acc: 0.5261 -- iter: 0320/1162
[A[ATraining Step: 85  | total loss: [1m[32m0.69312[0m[0m | time: 15.375s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5172 -- iter: 0352/1162
[A[ATraining Step: 86  | total loss: [1m[32m0.69309[0m[0m | time: 16.677s
[2K
| RMSProp | epoch: 003 | loss: 0.69309 - acc: 0.5155 -- iter: 0384/1162
[A[ATraining Step: 87  | total loss: [1m[32m0.69309[0m[0m | time: 18.364s
[2K
| RMSProp | epoch: 003 | loss: 0.69309 - acc: 0.5108 -- iter: 0416/1162
[A[ATraining Step: 88  | total loss: [1m[32m0.69315[0m[0m | time: 19.899s
[2K
| RMSProp | epoch: 003 | loss: 0.69315 - acc: 0.5098 -- iter: 0448/1162
[A[ATraining Step: 89  | total loss: [1m[32m0.69306[0m[0m | time: 21.362s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5119 -- iter: 0480/1162
[A[ATraining Step: 90  | total loss: [1m[32m0.69300[0m[0m | time: 23.224s
[2K
| RMSProp | epoch: 003 | loss: 0.69300 - acc: 0.5138 -- iter: 0512/1162
[A[ATraining Step: 91  | total loss: [1m[32m0.69269[0m[0m | time: 25.094s
[2K
| RMSProp | epoch: 003 | loss: 0.69269 - acc: 0.5281 -- iter: 0544/1162
[A[ATraining Step: 92  | total loss: [1m[32m0.69288[0m[0m | time: 26.559s
[2K
| RMSProp | epoch: 003 | loss: 0.69288 - acc: 0.5190 -- iter: 0576/1162
[A[ATraining Step: 93  | total loss: [1m[32m0.69297[0m[0m | time: 38.167s
[2K
| RMSProp | epoch: 003 | loss: 0.69297 - acc: 0.5140 -- iter: 0608/1162
[A[ATraining Step: 94  | total loss: [1m[32m0.69299[0m[0m | time: 50.918s
[2K
| RMSProp | epoch: 003 | loss: 0.69299 - acc: 0.5126 -- iter: 0640/1162
[A[ATraining Step: 95  | total loss: [1m[32m0.69301[0m[0m | time: 67.729s
[2K
| RMSProp | epoch: 003 | loss: 0.69301 - acc: 0.5113 -- iter: 0672/1162
[A[ATraining Step: 96  | total loss: [1m[32m0.69283[0m[0m | time: 88.058s
[2K
| RMSProp | epoch: 003 | loss: 0.69283 - acc: 0.5196 -- iter: 0704/1162
[A[ATraining Step: 97  | total loss: [1m[32m0.69262[0m[0m | time: 109.526s
[2K
| RMSProp | epoch: 003 | loss: 0.69262 - acc: 0.5270 -- iter: 0736/1162
[A[ATraining Step: 98  | total loss: [1m[32m0.69279[0m[0m | time: 110.899s
[2K
| RMSProp | epoch: 003 | loss: 0.69279 - acc: 0.5212 -- iter: 0768/1162
[A[ATraining Step: 99  | total loss: [1m[32m0.69271[0m[0m | time: 112.658s
[2K
| RMSProp | epoch: 003 | loss: 0.69271 - acc: 0.5222 -- iter: 0800/1162
[A[ATraining Step: 100  | total loss: [1m[32m0.69246[0m[0m | time: 114.100s
[2K
| RMSProp | epoch: 003 | loss: 0.69246 - acc: 0.5293 -- iter: 0832/1162
[A[ATraining Step: 101  | total loss: [1m[32m0.69190[0m[0m | time: 115.714s
[2K
| RMSProp | epoch: 003 | loss: 0.69190 - acc: 0.5452 -- iter: 0864/1162
[A[ATraining Step: 102  | total loss: [1m[32m0.69207[0m[0m | time: 117.482s
[2K
| RMSProp | epoch: 003 | loss: 0.69207 - acc: 0.5406 -- iter: 0896/1162
[A[ATraining Step: 103  | total loss: [1m[32m0.69280[0m[0m | time: 119.300s
[2K
| RMSProp | epoch: 003 | loss: 0.69280 - acc: 0.5241 -- iter: 0928/1162
[A[ATraining Step: 104  | total loss: [1m[32m0.69243[0m[0m | time: 120.683s
[2K
| RMSProp | epoch: 003 | loss: 0.69243 - acc: 0.5342 -- iter: 0960/1162
[A[ATraining Step: 105  | total loss: [1m[32m0.69252[0m[0m | time: 122.263s
[2K
| RMSProp | epoch: 003 | loss: 0.69252 - acc: 0.5307 -- iter: 0992/1162
[A[ATraining Step: 106  | total loss: [1m[32m0.69257[0m[0m | time: 123.917s
[2K
| RMSProp | epoch: 003 | loss: 0.69257 - acc: 0.5277 -- iter: 1024/1162
[A[ATraining Step: 107  | total loss: [1m[32m0.69295[0m[0m | time: 125.422s
[2K
| RMSProp | epoch: 003 | loss: 0.69295 - acc: 0.5187 -- iter: 1056/1162
[A[ATraining Step: 108  | total loss: [1m[32m0.69296[0m[0m | time: 144.659s
[2K
| RMSProp | epoch: 003 | loss: 0.69296 - acc: 0.5168 -- iter: 1088/1162
[A[ATraining Step: 109  | total loss: [1m[32m0.69296[0m[0m | time: 171.135s
[2K
| RMSProp | epoch: 003 | loss: 0.69296 - acc: 0.5151 -- iter: 1120/1162
[A[ATraining Step: 110  | total loss: [1m[32m0.69320[0m[0m | time: 187.493s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.5074 -- iter: 1152/1162
[A[ATraining Step: 111  | total loss: [1m[32m0.69319[0m[0m | time: 246.684s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5066 | val_loss: 0.69331 - val_acc: 0.4945 -- iter: 1162/1162
--
Training Step: 112  | total loss: [1m[32m0.69329[0m[0m | time: 1.373s
[2K
| RMSProp | epoch: 004 | loss: 0.69329 - acc: 0.5028 -- iter: 0032/1162
[A[ATraining Step: 113  | total loss: [1m[32m0.69345[0m[0m | time: 1.886s
[2K
| RMSProp | epoch: 004 | loss: 0.69345 - acc: 0.4963 -- iter: 0064/1162
[A[ATraining Step: 114  | total loss: [1m[32m0.69378[0m[0m | time: 2.362s
[2K
| RMSProp | epoch: 004 | loss: 0.69378 - acc: 0.4767 -- iter: 0096/1162
[A[ATraining Step: 115  | total loss: [1m[32m0.69373[0m[0m | time: 3.702s
[2K
| RMSProp | epoch: 004 | loss: 0.69373 - acc: 0.4590 -- iter: 0128/1162
[A[ATraining Step: 116  | total loss: [1m[32m0.69372[0m[0m | time: 5.300s
[2K
| RMSProp | epoch: 004 | loss: 0.69372 - acc: 0.4568 -- iter: 0160/1162
[A[ATraining Step: 117  | total loss: [1m[32m0.69361[0m[0m | time: 6.959s
[2K
| RMSProp | epoch: 004 | loss: 0.69361 - acc: 0.4643 -- iter: 0192/1162
[A[ATraining Step: 118  | total loss: [1m[32m0.69379[0m[0m | time: 8.384s
[2K
| RMSProp | epoch: 004 | loss: 0.69379 - acc: 0.4429 -- iter: 0224/1162
[A[ATraining Step: 119  | total loss: [1m[32m0.69374[0m[0m | time: 9.807s
[2K
| RMSProp | epoch: 004 | loss: 0.69374 - acc: 0.4454 -- iter: 0256/1162
[A[ATraining Step: 120  | total loss: [1m[32m0.69366[0m[0m | time: 11.335s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.4540 -- iter: 0288/1162
[A[ATraining Step: 121  | total loss: [1m[32m0.69359[0m[0m | time: 12.811s
[2K
| RMSProp | epoch: 004 | loss: 0.69359 - acc: 0.4618 -- iter: 0320/1162
[A[ATraining Step: 122  | total loss: [1m[32m0.69350[0m[0m | time: 14.194s
[2K
| RMSProp | epoch: 004 | loss: 0.69350 - acc: 0.4687 -- iter: 0352/1162
[A[ATraining Step: 123  | total loss: [1m[32m0.69351[0m[0m | time: 28.848s
[2K
| RMSProp | epoch: 004 | loss: 0.69351 - acc: 0.4656 -- iter: 0384/1162
[A[ATraining Step: 124  | total loss: [1m[32m0.69353[0m[0m | time: 37.389s
[2K
| RMSProp | epoch: 004 | loss: 0.69353 - acc: 0.4628 -- iter: 0416/1162
[A[ATraining Step: 125  | total loss: [1m[32m0.69349[0m[0m | time: 49.951s
[2K
| RMSProp | epoch: 004 | loss: 0.69349 - acc: 0.4821 -- iter: 0448/1162
[A[ATraining Step: 126  | total loss: [1m[32m0.69336[0m[0m | time: 65.228s
[2K
| RMSProp | epoch: 004 | loss: 0.69336 - acc: 0.4902 -- iter: 0480/1162
[A[ATraining Step: 127  | total loss: [1m[32m0.69310[0m[0m | time: 75.564s
[2K
| RMSProp | epoch: 004 | loss: 0.69310 - acc: 0.5005 -- iter: 0512/1162
[A[ATraining Step: 128  | total loss: [1m[32m0.69289[0m[0m | time: 101.052s
[2K
| RMSProp | epoch: 004 | loss: 0.69289 - acc: 0.5067 -- iter: 0544/1162
[A[ATraining Step: 129  | total loss: [1m[32m0.69341[0m[0m | time: 102.421s
[2K
| RMSProp | epoch: 004 | loss: 0.69341 - acc: 0.4967 -- iter: 0576/1162
[A[ATraining Step: 130  | total loss: [1m[32m0.69320[0m[0m | time: 103.715s
[2K
| RMSProp | epoch: 004 | loss: 0.69320 - acc: 0.5033 -- iter: 0608/1162
[A[ATraining Step: 131  | total loss: [1m[32m0.69301[0m[0m | time: 105.209s
[2K
| RMSProp | epoch: 004 | loss: 0.69301 - acc: 0.5092 -- iter: 0640/1162
[A[ATraining Step: 132  | total loss: [1m[32m0.69382[0m[0m | time: 106.794s
[2K
| RMSProp | epoch: 004 | loss: 0.69382 - acc: 0.4895 -- iter: 0672/1162
[A[ATraining Step: 133  | total loss: [1m[32m0.69378[0m[0m | time: 108.453s
[2K
| RMSProp | epoch: 004 | loss: 0.69378 - acc: 0.4874 -- iter: 0704/1162
[A[ATraining Step: 134  | total loss: [1m[32m0.69383[0m[0m | time: 110.227s
[2K
| RMSProp | epoch: 004 | loss: 0.69383 - acc: 0.4762 -- iter: 0736/1162
[A[ATraining Step: 135  | total loss: [1m[32m0.69376[0m[0m | time: 111.523s
[2K
| RMSProp | epoch: 004 | loss: 0.69376 - acc: 0.4817 -- iter: 0768/1162
[A[ATraining Step: 136  | total loss: [1m[32m0.69371[0m[0m | time: 113.345s
[2K
| RMSProp | epoch: 004 | loss: 0.69371 - acc: 0.4867 -- iter: 0800/1162
[A[ATraining Step: 137  | total loss: [1m[32m0.69364[0m[0m | time: 115.061s
[2K
| RMSProp | epoch: 004 | loss: 0.69364 - acc: 0.4880 -- iter: 0832/1162
[A[ATraining Step: 138  | total loss: [1m[32m0.69368[0m[0m | time: 116.690s
[2K
| RMSProp | epoch: 004 | loss: 0.69368 - acc: 0.4798 -- iter: 0864/1162
[A[ATraining Step: 139  | total loss: [1m[32m0.69363[0m[0m | time: 154.283s
[2K
| RMSProp | epoch: 004 | loss: 0.69363 - acc: 0.4693 -- iter: 0896/1162
[A[ATraining Step: 140  | total loss: [1m[32m0.69357[0m[0m | time: 188.994s
[2K
| RMSProp | epoch: 004 | loss: 0.69357 - acc: 0.4755 -- iter: 0928/1162
[A[ATraining Step: 141  | total loss: [1m[32m0.69343[0m[0m | time: 190.329s
[2K
| RMSProp | epoch: 004 | loss: 0.69343 - acc: 0.4873 -- iter: 0960/1162
[A[ATraining Step: 142  | total loss: [1m[32m0.69314[0m[0m | time: 191.705s
[2K
| RMSProp | epoch: 004 | loss: 0.69314 - acc: 0.5011 -- iter: 0992/1162
[A[ATraining Step: 143  | total loss: [1m[32m0.69320[0m[0m | time: 193.043s
[2K
| RMSProp | epoch: 004 | loss: 0.69320 - acc: 0.5010 -- iter: 1024/1162
[A[ATraining Step: 144  | total loss: [1m[32m0.69343[0m[0m | time: 194.437s
[2K
| RMSProp | epoch: 004 | loss: 0.69343 - acc: 0.4947 -- iter: 1056/1162
[A[ATraining Step: 145  | total loss: [1m[32m0.69351[0m[0m | time: 195.979s
[2K
| RMSProp | epoch: 004 | loss: 0.69351 - acc: 0.4921 -- iter: 1088/1162
[A[ATraining Step: 146  | total loss: [1m[32m0.69338[0m[0m | time: 197.433s
[2K
| RMSProp | epoch: 004 | loss: 0.69338 - acc: 0.4991 -- iter: 1120/1162
[A[ATraining Step: 147  | total loss: [1m[32m0.69321[0m[0m | time: 198.722s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.5054 -- iter: 1152/1162
[A[ATraining Step: 148  | total loss: [1m[32m0.69363[0m[0m | time: 209.872s
[2K
| RMSProp | epoch: 004 | loss: 0.69363 - acc: 0.4924 | val_loss: 0.69317 - val_acc: 0.4945 -- iter: 1162/1162
--
Training Step: 149  | total loss: [1m[32m0.69366[0m[0m | time: 23.503s
[2K
| RMSProp | epoch: 005 | loss: 0.69366 - acc: 0.4869 -- iter: 0032/1162
[A[ATraining Step: 150  | total loss: [1m[32m0.69361[0m[0m | time: 35.241s
[2K
| RMSProp | epoch: 005 | loss: 0.69361 - acc: 0.4820 -- iter: 0064/1162
[A[ATraining Step: 151  | total loss: [1m[32m0.69356[0m[0m | time: 48.918s
[2K
| RMSProp | epoch: 005 | loss: 0.69356 - acc: 0.4900 -- iter: 0096/1162
[A[ATraining Step: 152  | total loss: [1m[32m0.69376[0m[0m | time: 49.306s
[2K
| RMSProp | epoch: 005 | loss: 0.69376 - acc: 0.4510 -- iter: 0128/1162
[A[ATraining Step: 153  | total loss: [1m[32m0.69307[0m[0m | time: 50.466s
[2K
| RMSProp | epoch: 005 | loss: 0.69307 - acc: 0.4959 -- iter: 0160/1162
[A[ATraining Step: 154  | total loss: [1m[32m0.69328[0m[0m | time: 52.006s
[2K
| RMSProp | epoch: 005 | loss: 0.69328 - acc: 0.4932 -- iter: 0192/1162
[A[ATraining Step: 155  | total loss: [1m[32m0.69318[0m[0m | time: 53.319s
[2K
| RMSProp | epoch: 005 | loss: 0.69318 - acc: 0.4970 -- iter: 0224/1162
[A[ATraining Step: 156  | total loss: [1m[32m0.69303[0m[0m | time: 54.806s
[2K
| RMSProp | epoch: 005 | loss: 0.69303 - acc: 0.5004 -- iter: 0256/1162
[A[ATraining Step: 157  | total loss: [1m[32m0.69307[0m[0m | time: 56.196s
[2K
| RMSProp | epoch: 005 | loss: 0.69307 - acc: 0.5004 -- iter: 0288/1162
[A[ATraining Step: 158  | total loss: [1m[32m0.69277[0m[0m | time: 57.733s
[2K
| RMSProp | epoch: 005 | loss: 0.69277 - acc: 0.5066 -- iter: 0320/1162
[A[ATraining Step: 159  | total loss: [1m[32m0.69268[0m[0m | time: 59.167s
[2K
| RMSProp | epoch: 005 | loss: 0.69268 - acc: 0.5091 -- iter: 0352/1162
[A[ATraining Step: 160  | total loss: [1m[32m0.69183[0m[0m | time: 60.618s
[2K
| RMSProp | epoch: 005 | loss: 0.69183 - acc: 0.5207 -- iter: 0384/1162
[A[ATraining Step: 161  | total loss: [1m[32m0.69139[0m[0m | time: 62.363s
[2K
| RMSProp | epoch: 005 | loss: 0.69139 - acc: 0.5248 -- iter: 0416/1162
[A[ATraining Step: 162  | total loss: [1m[32m0.69273[0m[0m | time: 64.066s
[2K
| RMSProp | epoch: 005 | loss: 0.69273 - acc: 0.5192 -- iter: 0448/1162
[A[ATraining Step: 163  | total loss: [1m[32m0.69267[0m[0m | time: 66.032s
[2K
| RMSProp | epoch: 005 | loss: 0.69267 - acc: 0.5204 -- iter: 0480/1162
[A[ATraining Step: 164  | total loss: [1m[32m0.69232[0m[0m | time: 67.831s
[2K
| RMSProp | epoch: 005 | loss: 0.69232 - acc: 0.5246 -- iter: 0512/1162
[A[ATraining Step: 165  | total loss: [1m[32m0.69199[0m[0m | time: 71.972s
[2K
| RMSProp | epoch: 005 | loss: 0.69199 - acc: 0.5284 -- iter: 0544/1162
[A[ATraining Step: 166  | total loss: [1m[32m0.69155[0m[0m | time: 93.119s
[2K
| RMSProp | epoch: 005 | loss: 0.69155 - acc: 0.5318 -- iter: 0576/1162
[A[ATraining Step: 167  | total loss: [1m[32m0.69202[0m[0m | time: 103.241s
[2K
| RMSProp | epoch: 005 | loss: 0.69202 - acc: 0.5287 -- iter: 0608/1162
[A[ATraining Step: 168  | total loss: [1m[32m0.69254[0m[0m | time: 127.403s
[2K
| RMSProp | epoch: 005 | loss: 0.69254 - acc: 0.5227 -- iter: 0640/1162
[A[ATraining Step: 169  | total loss: [1m[32m0.69318[0m[0m | time: 128.821s
[2K
| RMSProp | epoch: 005 | loss: 0.69318 - acc: 0.5110 -- iter: 0672/1162
[A[ATraining Step: 170  | total loss: [1m[32m0.69327[0m[0m | time: 130.265s
[2K
| RMSProp | epoch: 005 | loss: 0.69327 - acc: 0.5068 -- iter: 0704/1162
[A[ATraining Step: 171  | total loss: [1m[32m0.69349[0m[0m | time: 131.777s
[2K
| RMSProp | epoch: 005 | loss: 0.69349 - acc: 0.4936 -- iter: 0736/1162
[A[ATraining Step: 172  | total loss: [1m[32m0.69354[0m[0m | time: 133.275s
[2K
| RMSProp | epoch: 005 | loss: 0.69354 - acc: 0.4818 -- iter: 0768/1162
[A[ATraining Step: 173  | total loss: [1m[32m0.69348[0m[0m | time: 135.068s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.4898 -- iter: 0800/1162
[A[ATraining Step: 174  | total loss: [1m[32m0.69342[0m[0m | time: 136.550s
[2K
| RMSProp | epoch: 005 | loss: 0.69342 - acc: 0.4940 -- iter: 0832/1162
[A[ATraining Step: 175  | total loss: [1m[32m0.69365[0m[0m | time: 138.069s
[2K
| RMSProp | epoch: 005 | loss: 0.69365 - acc: 0.4789 -- iter: 0864/1162
[A[ATraining Step: 176  | total loss: [1m[32m0.69357[0m[0m | time: 140.007s
[2K
| RMSProp | epoch: 005 | loss: 0.69357 - acc: 0.4842 -- iter: 0896/1162
[A[ATraining Step: 177  | total loss: [1m[32m0.69366[0m[0m | time: 141.671s
[2K
| RMSProp | epoch: 005 | loss: 0.69366 - acc: 0.4733 -- iter: 0928/1162
[A[ATraining Step: 178  | total loss: [1m[32m0.69359[0m[0m | time: 143.695s
[2K
| RMSProp | epoch: 005 | loss: 0.69359 - acc: 0.4884 -- iter: 0960/1162
[A[ATraining Step: 179  | total loss: [1m[32m0.69350[0m[0m | time: 168.680s
[2K
| RMSProp | epoch: 005 | loss: 0.69350 - acc: 0.4927 -- iter: 0992/1162
[A[ATraining Step: 180  | total loss: [1m[32m0.69372[0m[0m | time: 174.151s
[2K
| RMSProp | epoch: 005 | loss: 0.69372 - acc: 0.4778 -- iter: 1024/1162
[A[ATraining Step: 181  | total loss: [1m[32m0.69365[0m[0m | time: 190.742s
[2K
| RMSProp | epoch: 005 | loss: 0.69365 - acc: 0.4863 -- iter: 1056/1162
[A[ATraining Step: 182  | total loss: [1m[32m0.69362[0m[0m | time: 191.939s
[2K
| RMSProp | epoch: 005 | loss: 0.69362 - acc: 0.4783 -- iter: 1088/1162
[A[ATraining Step: 183  | total loss: [1m[32m0.69360[0m[0m | time: 193.121s
[2K
| RMSProp | epoch: 005 | loss: 0.69360 - acc: 0.4742 -- iter: 1120/1162
[A[ATraining Step: 184  | total loss: [1m[32m0.69355[0m[0m | time: 194.285s
[2K
| RMSProp | epoch: 005 | loss: 0.69355 - acc: 0.4862 -- iter: 1152/1162
[A[ATraining Step: 185  | total loss: [1m[32m0.69353[0m[0m | time: 198.454s
[2K
| RMSProp | epoch: 005 | loss: 0.69353 - acc: 0.4875 | val_loss: 0.69314 - val_acc: 0.4973 -- iter: 1162/1162
--
Training Step: 186  | total loss: [1m[32m0.69360[0m[0m | time: 1.573s
[2K
| RMSProp | epoch: 006 | loss: 0.69360 - acc: 0.4794 -- iter: 0032/1162
[A[ATraining Step: 187  | total loss: [1m[32m0.69355[0m[0m | time: 3.055s
[2K
| RMSProp | epoch: 006 | loss: 0.69355 - acc: 0.4877 -- iter: 0064/1162
[A[ATraining Step: 188  | total loss: [1m[32m0.69346[0m[0m | time: 4.253s
[2K
| RMSProp | epoch: 006 | loss: 0.69346 - acc: 0.5015 -- iter: 0096/1162
[A[ATraining Step: 189  | total loss: [1m[32m0.69322[0m[0m | time: 4.600s
[2K
| RMSProp | epoch: 006 | loss: 0.69322 - acc: 0.5138 -- iter: 0128/1162
[A[ATraining Step: 190  | total loss: [1m[32m0.69287[0m[0m | time: 5.020s
[2K
| RMSProp | epoch: 006 | loss: 0.69287 - acc: 0.5224 -- iter: 0160/1162
[A[ATraining Step: 191  | total loss: [1m[32m0.69224[0m[0m | time: 6.219s
[2K
| RMSProp | epoch: 006 | loss: 0.69224 - acc: 0.5302 -- iter: 0192/1162
[A[ATraining Step: 192  | total loss: [1m[32m0.69366[0m[0m | time: 7.503s
[2K
| RMSProp | epoch: 006 | loss: 0.69366 - acc: 0.5240 -- iter: 0224/1162
[A[ATraining Step: 193  | total loss: [1m[32m0.69348[0m[0m | time: 8.689s
[2K
| RMSProp | epoch: 006 | loss: 0.69348 - acc: 0.5248 -- iter: 0256/1162
[A[ATraining Step: 194  | total loss: [1m[32m0.69393[0m[0m | time: 9.989s
[2K
| RMSProp | epoch: 006 | loss: 0.69393 - acc: 0.5129 -- iter: 0288/1162
[A[ATraining Step: 195  | total loss: [1m[32m0.69388[0m[0m | time: 11.185s
[2K
| RMSProp | epoch: 006 | loss: 0.69388 - acc: 0.5116 -- iter: 0320/1162
[A[ATraining Step: 196  | total loss: [1m[32m0.69364[0m[0m | time: 12.361s
[2K
| RMSProp | epoch: 006 | loss: 0.69364 - acc: 0.5167 -- iter: 0352/1162
[A[ATraining Step: 197  | total loss: [1m[32m0.69341[0m[0m | time: 13.818s
[2K
| RMSProp | epoch: 006 | loss: 0.69341 - acc: 0.5213 -- iter: 0384/1162
[A[ATraining Step: 198  | total loss: [1m[32m0.69311[0m[0m | time: 15.373s
[2K
| RMSProp | epoch: 006 | loss: 0.69311 - acc: 0.5254 -- iter: 0416/1162
[A[ATraining Step: 199  | total loss: [1m[32m0.69308[0m[0m | time: 16.747s
[2K
| RMSProp | epoch: 006 | loss: 0.69308 - acc: 0.5229 -- iter: 0448/1162
[A[ATraining Step: 200  | total loss: [1m[32m0.69299[0m[0m | time: 20.721s
[2K
| RMSProp | epoch: 006 | loss: 0.69299 - acc: 0.5237 | val_loss: 0.69373 - val_acc: 0.4945 -- iter: 0480/1162
--
Training Step: 201  | total loss: [1m[32m0.69312[0m[0m | time: 21.922s
[2K
| RMSProp | epoch: 006 | loss: 0.69312 - acc: 0.5213 -- iter: 0512/1162
[A[ATraining Step: 202  | total loss: [1m[32m0.69245[0m[0m | time: 23.288s
[2K
| RMSProp | epoch: 006 | loss: 0.69245 - acc: 0.5317 -- iter: 0544/1162
[A[ATraining Step: 203  | total loss: [1m[32m0.69165[0m[0m | time: 24.518s
[2K
| RMSProp | epoch: 006 | loss: 0.69165 - acc: 0.5379 -- iter: 0576/1162
[A[ATraining Step: 204  | total loss: [1m[32m0.68943[0m[0m | time: 25.571s
[2K
| RMSProp | epoch: 006 | loss: 0.68943 - acc: 0.5466 -- iter: 0608/1162
[A[ATraining Step: 205  | total loss: [1m[32m0.69688[0m[0m | time: 27.159s
[2K
| RMSProp | epoch: 006 | loss: 0.69688 - acc: 0.5420 -- iter: 0640/1162
[A[ATraining Step: 206  | total loss: [1m[32m0.69596[0m[0m | time: 28.722s
[2K
| RMSProp | epoch: 006 | loss: 0.69596 - acc: 0.5440 -- iter: 0672/1162
[A[ATraining Step: 207  | total loss: [1m[32m0.69676[0m[0m | time: 30.024s
[2K
| RMSProp | epoch: 006 | loss: 0.69676 - acc: 0.5334 -- iter: 0704/1162
[A[ATraining Step: 208  | total loss: [1m[32m0.69498[0m[0m | time: 31.057s
[2K
| RMSProp | epoch: 006 | loss: 0.69498 - acc: 0.5456 -- iter: 0736/1162
[A[ATraining Step: 209  | total loss: [1m[32m0.69452[0m[0m | time: 32.250s
[2K
| RMSProp | epoch: 006 | loss: 0.69452 - acc: 0.5442 -- iter: 0768/1162
[A[ATraining Step: 210  | total loss: [1m[32m0.69511[0m[0m | time: 33.493s
[2K
| RMSProp | epoch: 006 | loss: 0.69511 - acc: 0.5367 -- iter: 0800/1162
[A[ATraining Step: 211  | total loss: [1m[32m0.69402[0m[0m | time: 34.862s
[2K
| RMSProp | epoch: 006 | loss: 0.69402 - acc: 0.5424 -- iter: 0832/1162
[A[ATraining Step: 212  | total loss: [1m[32m0.69523[0m[0m | time: 36.003s
[2K
| RMSProp | epoch: 006 | loss: 0.69523 - acc: 0.5319 -- iter: 0864/1162
[A[ATraining Step: 213  | total loss: [1m[32m0.69471[0m[0m | time: 37.388s
[2K
| RMSProp | epoch: 006 | loss: 0.69471 - acc: 0.5318 -- iter: 0896/1162
[A[ATraining Step: 214  | total loss: [1m[32m0.69527[0m[0m | time: 38.556s
[2K
| RMSProp | epoch: 006 | loss: 0.69527 - acc: 0.5224 -- iter: 0928/1162
[A[ATraining Step: 215  | total loss: [1m[32m0.69491[0m[0m | time: 40.049s
[2K
| RMSProp | epoch: 006 | loss: 0.69491 - acc: 0.5233 -- iter: 0960/1162
[A[ATraining Step: 216  | total loss: [1m[32m0.69335[0m[0m | time: 41.518s
[2K
| RMSProp | epoch: 006 | loss: 0.69335 - acc: 0.5397 -- iter: 0992/1162
[A[ATraining Step: 217  | total loss: [1m[32m0.69452[0m[0m | time: 42.859s
[2K
| RMSProp | epoch: 006 | loss: 0.69452 - acc: 0.5264 -- iter: 1024/1162
[A[ATraining Step: 218  | total loss: [1m[32m0.69321[0m[0m | time: 43.888s
[2K
| RMSProp | epoch: 006 | loss: 0.69321 - acc: 0.5393 -- iter: 1056/1162
[A[ATraining Step: 219  | total loss: [1m[32m0.69494[0m[0m | time: 45.021s
[2K
| RMSProp | epoch: 006 | loss: 0.69494 - acc: 0.5229 -- iter: 1088/1162
[A[ATraining Step: 220  | total loss: [1m[32m0.69456[0m[0m | time: 46.290s
[2K
| RMSProp | epoch: 006 | loss: 0.69456 - acc: 0.5237 -- iter: 1120/1162
[A[ATraining Step: 221  | total loss: [1m[32m0.69513[0m[0m | time: 47.505s
[2K
| RMSProp | epoch: 006 | loss: 0.69513 - acc: 0.5120 -- iter: 1152/1162
[A[ATraining Step: 222  | total loss: [1m[32m0.69543[0m[0m | time: 51.577s
[2K
| RMSProp | epoch: 006 | loss: 0.69543 - acc: 0.5014 | val_loss: 0.69331 - val_acc: 0.4945 -- iter: 1162/1162
--
Training Step: 223  | total loss: [1m[32m0.69540[0m[0m | time: 1.535s
[2K
| RMSProp | epoch: 007 | loss: 0.69540 - acc: 0.4950 -- iter: 0032/1162
[A[ATraining Step: 224  | total loss: [1m[32m0.69543[0m[0m | time: 3.004s
[2K
| RMSProp | epoch: 007 | loss: 0.69543 - acc: 0.4861 -- iter: 0064/1162
[A[ATraining Step: 225  | total loss: [1m[32m0.69533[0m[0m | time: 4.101s
[2K
| RMSProp | epoch: 007 | loss: 0.69533 - acc: 0.4782 -- iter: 0096/1162
[A[ATraining Step: 226  | total loss: [1m[32m0.69514[0m[0m | time: 5.429s
[2K
| RMSProp | epoch: 007 | loss: 0.69514 - acc: 0.4553 -- iter: 0128/1162
[A[ATraining Step: 227  | total loss: [1m[32m0.69496[0m[0m | time: 5.929s
[2K
| RMSProp | epoch: 007 | loss: 0.69496 - acc: 0.4598 -- iter: 0160/1162
[A[ATraining Step: 228  | total loss: [1m[32m0.69490[0m[0m | time: 6.317s
[2K
| RMSProp | epoch: 007 | loss: 0.69490 - acc: 0.4538 -- iter: 0192/1162
[A[ATraining Step: 229  | total loss: [1m[32m0.69471[0m[0m | time: 7.504s
[2K
| RMSProp | epoch: 007 | loss: 0.69471 - acc: 0.4684 -- iter: 0224/1162
[A[ATraining Step: 230  | total loss: [1m[32m0.69489[0m[0m | time: 8.731s
[2K
| RMSProp | epoch: 007 | loss: 0.69489 - acc: 0.4529 -- iter: 0256/1162
[A[ATraining Step: 231  | total loss: [1m[32m0.69473[0m[0m | time: 10.246s
[2K
| RMSProp | epoch: 007 | loss: 0.69473 - acc: 0.4544 -- iter: 0288/1162
[A[ATraining Step: 232  | total loss: [1m[32m0.69457[0m[0m | time: 11.331s
[2K
| RMSProp | epoch: 007 | loss: 0.69457 - acc: 0.4590 -- iter: 0320/1162
[A[ATraining Step: 233  | total loss: [1m[32m0.69441[0m[0m | time: 12.601s
[2K
| RMSProp | epoch: 007 | loss: 0.69441 - acc: 0.4725 -- iter: 0352/1162
[A[ATraining Step: 234  | total loss: [1m[32m0.69431[0m[0m | time: 13.976s
[2K
| RMSProp | epoch: 007 | loss: 0.69431 - acc: 0.4658 -- iter: 0384/1162
[A[ATraining Step: 235  | total loss: [1m[32m0.69400[0m[0m | time: 15.378s
[2K
| RMSProp | epoch: 007 | loss: 0.69400 - acc: 0.4849 -- iter: 0416/1162
[A[ATraining Step: 236  | total loss: [1m[32m0.69383[0m[0m | time: 16.666s
[2K
| RMSProp | epoch: 007 | loss: 0.69383 - acc: 0.4895 -- iter: 0448/1162
[A[ATraining Step: 237  | total loss: [1m[32m0.69410[0m[0m | time: 17.966s
[2K
| RMSProp | epoch: 007 | loss: 0.69410 - acc: 0.4812 -- iter: 0480/1162
[A[ATraining Step: 238  | total loss: [1m[32m0.69411[0m[0m | time: 19.334s
[2K
| RMSProp | epoch: 007 | loss: 0.69411 - acc: 0.4768 -- iter: 0512/1162
[A[ATraining Step: 239  | total loss: [1m[32m0.69403[0m[0m | time: 20.638s
[2K
| RMSProp | epoch: 007 | loss: 0.69403 - acc: 0.4791 -- iter: 0544/1162
[A[ATraining Step: 240  | total loss: [1m[32m0.69392[0m[0m | time: 21.741s
[2K
| RMSProp | epoch: 007 | loss: 0.69392 - acc: 0.4844 -- iter: 0576/1162
[A[ATraining Step: 241  | total loss: [1m[32m0.69384[0m[0m | time: 22.555s
[2K
| RMSProp | epoch: 007 | loss: 0.69384 - acc: 0.4859 -- iter: 0608/1162
[A[ATraining Step: 242  | total loss: [1m[32m0.69370[0m[0m | time: 23.354s
[2K
| RMSProp | epoch: 007 | loss: 0.69370 - acc: 0.4936 -- iter: 0640/1162
[A[ATraining Step: 243  | total loss: [1m[32m0.69360[0m[0m | time: 24.168s
[2K
| RMSProp | epoch: 007 | loss: 0.69360 - acc: 0.4973 -- iter: 0672/1162
[A[ATraining Step: 244  | total loss: [1m[32m0.69363[0m[0m | time: 25.010s
[2K
| RMSProp | epoch: 007 | loss: 0.69363 - acc: 0.4945 -- iter: 0704/1162
[A[ATraining Step: 245  | total loss: [1m[32m0.69347[0m[0m | time: 25.819s
[2K
| RMSProp | epoch: 007 | loss: 0.69347 - acc: 0.5013 -- iter: 0736/1162
[A[ATraining Step: 246  | total loss: [1m[32m0.69338[0m[0m | time: 26.765s
[2K
| RMSProp | epoch: 007 | loss: 0.69338 - acc: 0.5043 -- iter: 0768/1162
[A[ATraining Step: 247  | total loss: [1m[32m0.69345[0m[0m | time: 27.843s
[2K
| RMSProp | epoch: 007 | loss: 0.69345 - acc: 0.5007 -- iter: 0800/1162
[A[ATraining Step: 248  | total loss: [1m[32m0.69360[0m[0m | time: 28.587s
[2K
| RMSProp | epoch: 007 | loss: 0.69360 - acc: 0.4913 -- iter: 0832/1162
[A[ATraining Step: 249  | total loss: [1m[32m0.69351[0m[0m | time: 29.359s
[2K
| RMSProp | epoch: 007 | loss: 0.69351 - acc: 0.4984 -- iter: 0864/1162
[A[ATraining Step: 250  | total loss: [1m[32m0.69367[0m[0m | time: 30.164s
[2K
| RMSProp | epoch: 007 | loss: 0.69367 - acc: 0.4861 -- iter: 0896/1162
[A[ATraining Step: 251  | total loss: [1m[32m0.69360[0m[0m | time: 30.860s
[2K
| RMSProp | epoch: 007 | loss: 0.69360 - acc: 0.4906 -- iter: 0928/1162
[A[ATraining Step: 252  | total loss: [1m[32m0.69355[0m[0m | time: 31.769s
[2K
| RMSProp | epoch: 007 | loss: 0.69355 - acc: 0.4915 -- iter: 0960/1162
[A[ATraining Step: 253  | total loss: [1m[32m0.69342[0m[0m | time: 32.575s
[2K
| RMSProp | epoch: 007 | loss: 0.69342 - acc: 0.5049 -- iter: 0992/1162
[A[ATraining Step: 254  | total loss: [1m[32m0.69341[0m[0m | time: 33.388s
[2K
| RMSProp | epoch: 007 | loss: 0.69341 - acc: 0.5044 -- iter: 1024/1162
[A[ATraining Step: 255  | total loss: [1m[32m0.69335[0m[0m | time: 34.133s
[2K
| RMSProp | epoch: 007 | loss: 0.69335 - acc: 0.5071 -- iter: 1056/1162
[A[ATraining Step: 256  | total loss: [1m[32m0.69345[0m[0m | time: 34.996s
[2K
| RMSProp | epoch: 007 | loss: 0.69345 - acc: 0.5001 -- iter: 1088/1162
[A[ATraining Step: 257  | total loss: [1m[32m0.69343[0m[0m | time: 35.780s
[2K
| RMSProp | epoch: 007 | loss: 0.69343 - acc: 0.5001 -- iter: 1120/1162
[A[ATraining Step: 258  | total loss: [1m[32m0.69360[0m[0m | time: 36.545s
[2K
| RMSProp | epoch: 007 | loss: 0.69360 - acc: 0.4845 -- iter: 1152/1162
[A[ATraining Step: 259  | total loss: [1m[32m0.69356[0m[0m | time: 39.168s
[2K
| RMSProp | epoch: 007 | loss: 0.69356 - acc: 0.4766 | val_loss: 0.69312 - val_acc: 0.5055 -- iter: 1162/1162
--
Training Step: 260  | total loss: [1m[32m0.69353[0m[0m | time: 1.081s
[2K
| RMSProp | epoch: 008 | loss: 0.69353 - acc: 0.4790 -- iter: 0032/1162
[A[ATraining Step: 261  | total loss: [1m[32m0.69354[0m[0m | time: 1.960s
[2K
| RMSProp | epoch: 008 | loss: 0.69354 - acc: 0.4748 -- iter: 0064/1162
[A[ATraining Step: 262  | total loss: [1m[32m0.69348[0m[0m | time: 2.729s
[2K
| RMSProp | epoch: 008 | loss: 0.69348 - acc: 0.4867 -- iter: 0096/1162
[A[ATraining Step: 263  | total loss: [1m[32m0.69343[0m[0m | time: 3.510s
[2K
| RMSProp | epoch: 008 | loss: 0.69343 - acc: 0.4974 -- iter: 0128/1162
[A[ATraining Step: 264  | total loss: [1m[32m0.69333[0m[0m | time: 4.240s
[2K
| RMSProp | epoch: 008 | loss: 0.69333 - acc: 0.5039 -- iter: 0160/1162
[A[ATraining Step: 265  | total loss: [1m[32m0.69333[0m[0m | time: 4.489s
[2K
| RMSProp | epoch: 008 | loss: 0.69333 - acc: 0.5035 -- iter: 0192/1162
[A[ATraining Step: 266  | total loss: [1m[32m0.69328[0m[0m | time: 4.789s
[2K
| RMSProp | epoch: 008 | loss: 0.69328 - acc: 0.5032 -- iter: 0224/1162
[A[ATraining Step: 267  | total loss: [1m[32m0.69333[0m[0m | time: 5.623s
[2K
| RMSProp | epoch: 008 | loss: 0.69333 - acc: 0.5029 -- iter: 0256/1162
[A[ATraining Step: 268  | total loss: [1m[32m0.69320[0m[0m | time: 6.505s
[2K
| RMSProp | epoch: 008 | loss: 0.69320 - acc: 0.5088 -- iter: 0288/1162
[A[ATraining Step: 269  | total loss: [1m[32m0.69276[0m[0m | time: 7.348s
[2K
| RMSProp | epoch: 008 | loss: 0.69276 - acc: 0.5173 -- iter: 0320/1162
[A[ATraining Step: 270  | total loss: [1m[32m0.69338[0m[0m | time: 8.099s
[2K
| RMSProp | epoch: 008 | loss: 0.69338 - acc: 0.5125 -- iter: 0352/1162
[A[ATraining Step: 271  | total loss: [1m[32m0.69282[0m[0m | time: 8.928s
[2K
| RMSProp | epoch: 008 | loss: 0.69282 - acc: 0.5268 -- iter: 0384/1162
[A[ATraining Step: 272  | total loss: [1m[32m0.69213[0m[0m | time: 9.710s
[2K
| RMSProp | epoch: 008 | loss: 0.69213 - acc: 0.5335 -- iter: 0416/1162
[A[ATraining Step: 273  | total loss: [1m[32m0.69311[0m[0m | time: 10.450s
[2K
| RMSProp | epoch: 008 | loss: 0.69311 - acc: 0.5271 -- iter: 0448/1162
[A[ATraining Step: 274  | total loss: [1m[32m0.69278[0m[0m | time: 11.266s
[2K
| RMSProp | epoch: 008 | loss: 0.69278 - acc: 0.5306 -- iter: 0480/1162
[A[ATraining Step: 275  | total loss: [1m[32m0.69186[0m[0m | time: 12.074s
[2K
| RMSProp | epoch: 008 | loss: 0.69186 - acc: 0.5400 -- iter: 0512/1162
[A[ATraining Step: 276  | total loss: [1m[32m0.69022[0m[0m | time: 13.058s
[2K
| RMSProp | epoch: 008 | loss: 0.69022 - acc: 0.5485 -- iter: 0544/1162
[A[ATraining Step: 277  | total loss: [1m[32m0.69004[0m[0m | time: 14.463s
[2K
| RMSProp | epoch: 008 | loss: 0.69004 - acc: 0.5499 -- iter: 0576/1162
[A[ATraining Step: 278  | total loss: [1m[32m0.68958[0m[0m | time: 15.904s
[2K
| RMSProp | epoch: 008 | loss: 0.68958 - acc: 0.5512 -- iter: 0608/1162
[A[ATraining Step: 279  | total loss: [1m[32m0.68837[0m[0m | time: 17.212s
[2K
| RMSProp | epoch: 008 | loss: 0.68837 - acc: 0.5554 -- iter: 0640/1162
[A[ATraining Step: 280  | total loss: [1m[32m0.69532[0m[0m | time: 18.292s
[2K
| RMSProp | epoch: 008 | loss: 0.69532 - acc: 0.5374 -- iter: 0672/1162
[A[ATraining Step: 281  | total loss: [1m[32m0.69491[0m[0m | time: 19.347s
[2K
| RMSProp | epoch: 008 | loss: 0.69491 - acc: 0.5368 -- iter: 0704/1162
[A[ATraining Step: 282  | total loss: [1m[32m0.69604[0m[0m | time: 20.500s
[2K
| RMSProp | epoch: 008 | loss: 0.69604 - acc: 0.5206 -- iter: 0736/1162
[A[ATraining Step: 283  | total loss: [1m[32m0.69554[0m[0m | time: 21.623s
[2K
| RMSProp | epoch: 008 | loss: 0.69554 - acc: 0.5217 -- iter: 0768/1162
[A[ATraining Step: 284  | total loss: [1m[32m0.69497[0m[0m | time: 22.924s
[2K
| RMSProp | epoch: 008 | loss: 0.69497 - acc: 0.5258 -- iter: 0800/1162
[A[ATraining Step: 285  | total loss: [1m[32m0.69461[0m[0m | time: 24.408s
[2K
| RMSProp | epoch: 008 | loss: 0.69461 - acc: 0.5263 -- iter: 0832/1162
[A[ATraining Step: 286  | total loss: [1m[32m0.69493[0m[0m | time: 25.731s
[2K
| RMSProp | epoch: 008 | loss: 0.69493 - acc: 0.5174 -- iter: 0864/1162
[A[ATraining Step: 287  | total loss: [1m[32m0.69501[0m[0m | time: 27.146s
[2K
| RMSProp | epoch: 008 | loss: 0.69501 - acc: 0.5126 -- iter: 0896/1162
[A[ATraining Step: 288  | total loss: [1m[32m0.69541[0m[0m | time: 28.636s
[2K
| RMSProp | epoch: 008 | loss: 0.69541 - acc: 0.4988 -- iter: 0928/1162
[A[ATraining Step: 289  | total loss: [1m[32m0.69508[0m[0m | time: 30.168s
[2K
| RMSProp | epoch: 008 | loss: 0.69508 - acc: 0.5020 -- iter: 0960/1162
[A[ATraining Step: 290  | total loss: [1m[32m0.69486[0m[0m | time: 31.146s
[2K
| RMSProp | epoch: 008 | loss: 0.69486 - acc: 0.5018 -- iter: 0992/1162
[A[ATraining Step: 291  | total loss: [1m[32m0.69511[0m[0m | time: 32.281s
[2K
| RMSProp | epoch: 008 | loss: 0.69511 - acc: 0.4892 -- iter: 1024/1162
[A[ATraining Step: 292  | total loss: [1m[32m0.69499[0m[0m | time: 33.400s
[2K
| RMSProp | epoch: 008 | loss: 0.69499 - acc: 0.4840 -- iter: 1056/1162
[A[ATraining Step: 293  | total loss: [1m[32m0.69479[0m[0m | time: 34.604s
[2K
| RMSProp | epoch: 008 | loss: 0.69479 - acc: 0.4981 -- iter: 1088/1162
[A[ATraining Step: 294  | total loss: [1m[32m0.69457[0m[0m | time: 35.881s
[2K
| RMSProp | epoch: 008 | loss: 0.69457 - acc: 0.5014 -- iter: 1120/1162
[A[ATraining Step: 295  | total loss: [1m[32m0.69446[0m[0m | time: 37.138s
[2K
| RMSProp | epoch: 008 | loss: 0.69446 - acc: 0.5013 -- iter: 1152/1162
[A[ATraining Step: 296  | total loss: [1m[32m0.69463[0m[0m | time: 41.011s
[2K
| RMSProp | epoch: 008 | loss: 0.69463 - acc: 0.4886 | val_loss: 0.69318 - val_acc: 0.4945 -- iter: 1162/1162
--
Training Step: 297  | total loss: [1m[32m0.69449[0m[0m | time: 1.416s
[2K
| RMSProp | epoch: 009 | loss: 0.69449 - acc: 0.4898 -- iter: 0032/1162
[A[ATraining Step: 298  | total loss: [1m[32m0.69434[0m[0m | time: 2.545s
[2K
| RMSProp | epoch: 009 | loss: 0.69434 - acc: 0.4908 -- iter: 0064/1162
[A[ATraining Step: 299  | total loss: [1m[32m0.69414[0m[0m | time: 3.759s
[2K
| RMSProp | epoch: 009 | loss: 0.69414 - acc: 0.4980 -- iter: 0096/1162
[A[ATraining Step: 300  | total loss: [1m[32m0.69427[0m[0m | time: 4.965s
[2K
| RMSProp | epoch: 009 | loss: 0.69427 - acc: 0.4888 -- iter: 0128/1162
[A[ATraining Step: 301  | total loss: [1m[32m0.69407[0m[0m | time: 6.332s
[2K
| RMSProp | epoch: 009 | loss: 0.69407 - acc: 0.4993 -- iter: 0160/1162
[A[ATraining Step: 302  | total loss: [1m[32m0.69383[0m[0m | time: 7.448s
[2K
| RMSProp | epoch: 009 | loss: 0.69383 - acc: 0.5056 -- iter: 0192/1162
[A[ATraining Step: 303  | total loss: [1m[32m0.69387[0m[0m | time: 7.868s
[2K
| RMSProp | epoch: 009 | loss: 0.69387 - acc: 0.5019 -- iter: 0224/1162
[A[ATraining Step: 304  | total loss: [1m[32m0.69430[0m[0m | time: 8.410s
[2K
| RMSProp | epoch: 009 | loss: 0.69430 - acc: 0.4817 -- iter: 0256/1162
[A[ATraining Step: 305  | total loss: [1m[32m0.69416[0m[0m | time: 9.855s
[2K
| RMSProp | epoch: 009 | loss: 0.69416 - acc: 0.4936 -- iter: 0288/1162
[A[ATraining Step: 306  | total loss: [1m[32m0.69416[0m[0m | time: 11.112s
[2K
| RMSProp | epoch: 009 | loss: 0.69416 - acc: 0.4848 -- iter: 0320/1162
[A[ATraining Step: 307  | total loss: [1m[32m0.69401[0m[0m | time: 12.154s
[2K
| RMSProp | epoch: 009 | loss: 0.69401 - acc: 0.4926 -- iter: 0352/1162
[A[ATraining Step: 308  | total loss: [1m[32m0.69391[0m[0m | time: 13.286s
[2K
| RMSProp | epoch: 009 | loss: 0.69391 - acc: 0.4933 -- iter: 0384/1162
[A[ATraining Step: 309  | total loss: [1m[32m0.69388[0m[0m | time: 14.378s
[2K
| RMSProp | epoch: 009 | loss: 0.69388 - acc: 0.4878 -- iter: 0416/1162
[A[ATraining Step: 310  | total loss: [1m[32m0.69380[0m[0m | time: 15.656s
[2K
| RMSProp | epoch: 009 | loss: 0.69380 - acc: 0.4921 -- iter: 0448/1162
[A[ATraining Step: 311  | total loss: [1m[32m0.69371[0m[0m | time: 16.911s
[2K
| RMSProp | epoch: 009 | loss: 0.69371 - acc: 0.4960 -- iter: 0480/1162
[A[ATraining Step: 312  | total loss: [1m[32m0.69367[0m[0m | time: 17.983s
[2K
| RMSProp | epoch: 009 | loss: 0.69367 - acc: 0.4933 -- iter: 0512/1162
[A[ATraining Step: 313  | total loss: [1m[32m0.69364[0m[0m | time: 19.540s
[2K
| RMSProp | epoch: 009 | loss: 0.69364 - acc: 0.4908 -- iter: 0544/1162
[A[ATraining Step: 314  | total loss: [1m[32m0.69355[0m[0m | time: 20.996s
[2K
| RMSProp | epoch: 009 | loss: 0.69355 - acc: 0.5011 -- iter: 0576/1162
[A[ATraining Step: 315  | total loss: [1m[32m0.69343[0m[0m | time: 22.325s
[2K
| RMSProp | epoch: 009 | loss: 0.69343 - acc: 0.5073 -- iter: 0608/1162
[A[ATraining Step: 316  | total loss: [1m[32m0.69338[0m[0m | time: 23.335s
[2K
| RMSProp | epoch: 009 | loss: 0.69338 - acc: 0.5065 -- iter: 0640/1162
[A[ATraining Step: 317  | total loss: [1m[32m0.69315[0m[0m | time: 24.436s
[2K
| RMSProp | epoch: 009 | loss: 0.69315 - acc: 0.5184 -- iter: 0672/1162
[A[ATraining Step: 318  | total loss: [1m[32m0.69361[0m[0m | time: 25.629s
[2K
| RMSProp | epoch: 009 | loss: 0.69361 - acc: 0.5009 -- iter: 0704/1162
[A[ATraining Step: 319  | total loss: [1m[32m0.69356[0m[0m | time: 26.793s
[2K
| RMSProp | epoch: 009 | loss: 0.69356 - acc: 0.5008 -- iter: 0736/1162
[A[ATraining Step: 320  | total loss: [1m[32m0.69353[0m[0m | time: 27.989s
[2K
| RMSProp | epoch: 009 | loss: 0.69353 - acc: 0.5007 -- iter: 0768/1162
[A[ATraining Step: 321  | total loss: [1m[32m0.69363[0m[0m | time: 29.198s
[2K
| RMSProp | epoch: 009 | loss: 0.69363 - acc: 0.4913 -- iter: 0800/1162
[A[ATraining Step: 322  | total loss: [1m[32m0.69353[0m[0m | time: 30.553s
[2K
| RMSProp | epoch: 009 | loss: 0.69353 - acc: 0.4984 -- iter: 0832/1162
[A[ATraining Step: 323  | total loss: [1m[32m0.69340[0m[0m | time: 31.739s
[2K
| RMSProp | epoch: 009 | loss: 0.69340 - acc: 0.5080 -- iter: 0864/1162
[A[ATraining Step: 324  | total loss: [1m[32m0.69347[0m[0m | time: 33.200s
[2K
| RMSProp | epoch: 009 | loss: 0.69347 - acc: 0.5009 -- iter: 0896/1162
[A[ATraining Step: 325  | total loss: [1m[32m0.69340[0m[0m | time: 34.603s
[2K
| RMSProp | epoch: 009 | loss: 0.69340 - acc: 0.5039 -- iter: 0928/1162
[A[ATraining Step: 326  | total loss: [1m[32m0.69328[0m[0m | time: 35.853s
[2K
| RMSProp | epoch: 009 | loss: 0.69328 - acc: 0.5098 -- iter: 0960/1162
[A[ATraining Step: 327  | total loss: [1m[32m0.69320[0m[0m | time: 36.902s
[2K
| RMSProp | epoch: 009 | loss: 0.69320 - acc: 0.5119 -- iter: 0992/1162
[A[ATraining Step: 328  | total loss: [1m[32m0.69339[0m[0m | time: 38.114s
[2K
| RMSProp | epoch: 009 | loss: 0.69339 - acc: 0.5014 -- iter: 1024/1162
[A[ATraining Step: 329  | total loss: [1m[32m0.69346[0m[0m | time: 39.365s
[2K
| RMSProp | epoch: 009 | loss: 0.69346 - acc: 0.4950 -- iter: 1056/1162
[A[ATraining Step: 330  | total loss: [1m[32m0.69335[0m[0m | time: 40.569s
[2K
| RMSProp | epoch: 009 | loss: 0.69335 - acc: 0.5049 -- iter: 1088/1162
[A[ATraining Step: 331  | total loss: [1m[32m0.69342[0m[0m | time: 41.971s
[2K
| RMSProp | epoch: 009 | loss: 0.69342 - acc: 0.4981 -- iter: 1120/1162
[A[ATraining Step: 332  | total loss: [1m[32m0.69343[0m[0m | time: 43.008s
[2K
| RMSProp | epoch: 009 | loss: 0.69343 - acc: 0.4952 -- iter: 1152/1162
[A[ATraining Step: 333  | total loss: [1m[32m0.69343[0m[0m | time: 47.436s
[2K
| RMSProp | epoch: 009 | loss: 0.69343 - acc: 0.4925 | val_loss: 0.69310 - val_acc: 0.5055 -- iter: 1162/1162
--
Training Step: 334  | total loss: [1m[32m0.69338[0m[0m | time: 1.241s
[2K
| RMSProp | epoch: 010 | loss: 0.69338 - acc: 0.4995 -- iter: 0032/1162
[A[ATraining Step: 335  | total loss: [1m[32m0.69331[0m[0m | time: 2.499s
[2K
| RMSProp | epoch: 010 | loss: 0.69331 - acc: 0.5058 -- iter: 0064/1162
[A[ATraining Step: 336  | total loss: [1m[32m0.69320[0m[0m | time: 3.651s
[2K
| RMSProp | epoch: 010 | loss: 0.69320 - acc: 0.5115 -- iter: 0096/1162
[A[ATraining Step: 337  | total loss: [1m[32m0.69308[0m[0m | time: 4.963s
[2K
| RMSProp | epoch: 010 | loss: 0.69308 - acc: 0.5166 -- iter: 0128/1162
[A[ATraining Step: 338  | total loss: [1m[32m0.69361[0m[0m | time: 6.181s
[2K
| RMSProp | epoch: 010 | loss: 0.69361 - acc: 0.4931 -- iter: 0160/1162
[A[ATraining Step: 339  | total loss: [1m[32m0.69366[0m[0m | time: 7.311s
[2K
| RMSProp | epoch: 010 | loss: 0.69366 - acc: 0.4813 -- iter: 0192/1162
[A[ATraining Step: 340  | total loss: [1m[32m0.69357[0m[0m | time: 8.637s
[2K
| RMSProp | epoch: 010 | loss: 0.69357 - acc: 0.4956 -- iter: 0224/1162
[A[ATraining Step: 341  | total loss: [1m[32m0.69360[0m[0m | time: 9.135s
[2K
| RMSProp | epoch: 010 | loss: 0.69360 - acc: 0.4961 -- iter: 0256/1162
[A[ATraining Step: 342  | total loss: [1m[32m0.69353[0m[0m | time: 9.643s
[2K
| RMSProp | epoch: 010 | loss: 0.69353 - acc: 0.4965 -- iter: 0288/1162
[A[ATraining Step: 343  | total loss: [1m[32m0.69349[0m[0m | time: 11.083s
[2K
| RMSProp | epoch: 010 | loss: 0.69349 - acc: 0.4968 -- iter: 0320/1162
[A[ATraining Step: 344  | total loss: [1m[32m0.69327[0m[0m | time: 12.364s
[2K
| RMSProp | epoch: 010 | loss: 0.69327 - acc: 0.5065 -- iter: 0352/1162
[A[ATraining Step: 345  | total loss: [1m[32m0.69260[0m[0m | time: 13.393s
[2K
| RMSProp | epoch: 010 | loss: 0.69260 - acc: 0.5152 -- iter: 0384/1162
[A[ATraining Step: 346  | total loss: [1m[32m0.69343[0m[0m | time: 14.664s
[2K
| RMSProp | epoch: 010 | loss: 0.69343 - acc: 0.5137 -- iter: 0416/1162
[A[ATraining Step: 347  | total loss: [1m[32m0.69391[0m[0m | time: 15.912s
[2K
| RMSProp | epoch: 010 | loss: 0.69391 - acc: 0.5061 -- iter: 0448/1162
[A[ATraining Step: 348  | total loss: [1m[32m0.69367[0m[0m | time: 17.109s
[2K
| RMSProp | epoch: 010 | loss: 0.69367 - acc: 0.5117 -- iter: 0480/1162
[A[ATraining Step: 349  | total loss: [1m[32m0.69330[0m[0m | time: 18.443s
[2K
| RMSProp | epoch: 010 | loss: 0.69330 - acc: 0.5168 -- iter: 0512/1162
[A[ATraining Step: 350  | total loss: [1m[32m0.69229[0m[0m | time: 19.655s
[2K
| RMSProp | epoch: 010 | loss: 0.69229 - acc: 0.5308 -- iter: 0544/1162
[A[ATraining Step: 351  | total loss: [1m[32m0.69209[0m[0m | time: 20.843s
[2K
| RMSProp | epoch: 010 | loss: 0.69209 - acc: 0.5308 -- iter: 0576/1162
[A[ATraining Step: 352  | total loss: [1m[32m0.69285[0m[0m | time: 22.280s
[2K
| RMSProp | epoch: 010 | loss: 0.69285 - acc: 0.5246 -- iter: 0608/1162
[A[ATraining Step: 353  | total loss: [1m[32m0.69271[0m[0m | time: 23.648s
[2K
| RMSProp | epoch: 010 | loss: 0.69271 - acc: 0.5253 -- iter: 0640/1162
[A[ATraining Step: 354  | total loss: [1m[32m0.69161[0m[0m | time: 24.829s
[2K
| RMSProp | epoch: 010 | loss: 0.69161 - acc: 0.5384 -- iter: 0672/1162
[A[ATraining Step: 355  | total loss: [1m[32m0.68979[0m[0m | time: 25.928s
[2K
| RMSProp | epoch: 010 | loss: 0.68979 - acc: 0.5470 -- iter: 0704/1162
[A[ATraining Step: 356  | total loss: [1m[32m0.69741[0m[0m | time: 27.044s
[2K
| RMSProp | epoch: 010 | loss: 0.69741 - acc: 0.5298 -- iter: 0736/1162
[A[ATraining Step: 357  | total loss: [1m[32m0.69702[0m[0m | time: 28.255s
[2K
| RMSProp | epoch: 010 | loss: 0.69702 - acc: 0.5268 -- iter: 0768/1162
[A[ATraining Step: 358  | total loss: [1m[32m0.69607[0m[0m | time: 29.547s
[2K
| RMSProp | epoch: 010 | loss: 0.69607 - acc: 0.5304 -- iter: 0800/1162
[A[ATraining Step: 359  | total loss: [1m[32m0.69567[0m[0m | time: 30.868s
[2K
| RMSProp | epoch: 010 | loss: 0.69567 - acc: 0.5305 -- iter: 0832/1162
[A[ATraining Step: 360  | total loss: [1m[32m0.69548[0m[0m | time: 32.179s
[2K
| RMSProp | epoch: 010 | loss: 0.69548 - acc: 0.5274 -- iter: 0864/1162
[A[ATraining Step: 361  | total loss: [1m[32m0.69446[0m[0m | time: 33.238s
[2K
| RMSProp | epoch: 010 | loss: 0.69446 - acc: 0.5341 -- iter: 0896/1162
[A[ATraining Step: 362  | total loss: [1m[32m0.69263[0m[0m | time: 34.734s
[2K
| RMSProp | epoch: 010 | loss: 0.69263 - acc: 0.5463 -- iter: 0928/1162
[A[ATraining Step: 363  | total loss: [1m[32m0.69325[0m[0m | time: 36.163s
[2K
| RMSProp | epoch: 010 | loss: 0.69325 - acc: 0.5417 -- iter: 0960/1162
[A[ATraining Step: 364  | total loss: [1m[32m0.69559[0m[0m | time: 37.547s
[2K
| RMSProp | epoch: 010 | loss: 0.69559 - acc: 0.5219 -- iter: 0992/1162
[A[ATraining Step: 365  | total loss: [1m[32m0.69561[0m[0m | time: 38.538s
[2K
| RMSProp | epoch: 010 | loss: 0.69561 - acc: 0.5166 -- iter: 1024/1162
[A[ATraining Step: 366  | total loss: [1m[32m0.69534[0m[0m | time: 39.636s
[2K
| RMSProp | epoch: 010 | loss: 0.69534 - acc: 0.5149 -- iter: 1056/1162
[A[ATraining Step: 367  | total loss: [1m[32m0.69561[0m[0m | time: 40.731s
[2K
| RMSProp | epoch: 010 | loss: 0.69561 - acc: 0.5040 -- iter: 1088/1162
[A[ATraining Step: 368  | total loss: [1m[32m0.69536[0m[0m | time: 41.989s
[2K
| RMSProp | epoch: 010 | loss: 0.69536 - acc: 0.5036 -- iter: 1120/1162
[A[ATraining Step: 369  | total loss: [1m[32m0.69505[0m[0m | time: 43.313s
[2K
| RMSProp | epoch: 010 | loss: 0.69505 - acc: 0.5033 -- iter: 1152/1162
[A[ATraining Step: 370  | total loss: [1m[32m0.69464[0m[0m | time: 47.112s
[2K
| RMSProp | epoch: 010 | loss: 0.69464 - acc: 0.5092 | val_loss: 0.69320 - val_acc: 0.4945 -- iter: 1162/1162
--
Training Step: 371  | total loss: [1m[32m0.69464[0m[0m | time: 1.490s
[2K
| RMSProp | epoch: 011 | loss: 0.69464 - acc: 0.5051 -- iter: 0032/1162
[A[ATraining Step: 372  | total loss: [1m[32m0.69418[0m[0m | time: 2.532s
[2K
| RMSProp | epoch: 011 | loss: 0.69418 - acc: 0.5109 -- iter: 0064/1162
[A[ATraining Step: 373  | total loss: [1m[32m0.69376[0m[0m | time: 3.582s
[2K
| RMSProp | epoch: 011 | loss: 0.69376 - acc: 0.5160 -- iter: 0096/1162
[A[ATraining Step: 374  | total loss: [1m[32m0.69458[0m[0m | time: 4.823s
[2K
| RMSProp | epoch: 011 | loss: 0.69458 - acc: 0.5019 -- iter: 0128/1162
[A[ATraining Step: 375  | total loss: [1m[32m0.69494[0m[0m | time: 6.035s
[2K
| RMSProp | epoch: 011 | loss: 0.69494 - acc: 0.4861 -- iter: 0160/1162
[A[ATraining Step: 376  | total loss: [1m[32m0.69479[0m[0m | time: 7.301s
[2K
| RMSProp | epoch: 011 | loss: 0.69479 - acc: 0.4781 -- iter: 0192/1162
[A[ATraining Step: 377  | total loss: [1m[32m0.69459[0m[0m | time: 8.499s
[2K
| RMSProp | epoch: 011 | loss: 0.69459 - acc: 0.4928 -- iter: 0224/1162
[A[ATraining Step: 378  | total loss: [1m[32m0.69467[0m[0m | time: 9.703s
[2K
| RMSProp | epoch: 011 | loss: 0.69467 - acc: 0.4779 -- iter: 0256/1162
[A[ATraining Step: 379  | total loss: [1m[32m0.69456[0m[0m | time: 10.080s
[2K
| RMSProp | epoch: 011 | loss: 0.69456 - acc: 0.4676 -- iter: 0288/1162
[A[ATraining Step: 380  | total loss: [1m[32m0.69413[0m[0m | time: 10.513s
[2K
| RMSProp | epoch: 011 | loss: 0.69413 - acc: 0.5009 -- iter: 0320/1162
[A[ATraining Step: 381  | total loss: [1m[32m0.69329[0m[0m | time: 12.017s
[2K
| RMSProp | epoch: 011 | loss: 0.69329 - acc: 0.5308 -- iter: 0352/1162
[A[ATraining Step: 382  | total loss: [1m[32m0.69364[0m[0m | time: 13.526s
[2K
| RMSProp | epoch: 011 | loss: 0.69364 - acc: 0.5183 -- iter: 0384/1162
[A[ATraining Step: 383  | total loss: [1m[32m0.69332[0m[0m | time: 14.868s
[2K
| RMSProp | epoch: 011 | loss: 0.69332 - acc: 0.5259 -- iter: 0416/1162
[A[ATraining Step: 384  | total loss: [1m[32m0.69409[0m[0m | time: 15.848s
[2K
| RMSProp | epoch: 011 | loss: 0.69409 - acc: 0.5014 -- iter: 0448/1162
[A[ATraining Step: 385  | total loss: [1m[32m0.69381[0m[0m | time: 16.918s
[2K
| RMSProp | epoch: 011 | loss: 0.69381 - acc: 0.5106 -- iter: 0480/1162
[A[ATraining Step: 386  | total loss: [1m[32m0.69393[0m[0m | time: 18.132s
[2K
| RMSProp | epoch: 011 | loss: 0.69393 - acc: 0.5033 -- iter: 0512/1162
[A[ATraining Step: 387  | total loss: [1m[32m0.69402[0m[0m | time: 19.306s
[2K
| RMSProp | epoch: 011 | loss: 0.69402 - acc: 0.4967 -- iter: 0544/1162
[A[ATraining Step: 388  | total loss: [1m[32m0.69401[0m[0m | time: 20.498s
[2K
| RMSProp | epoch: 011 | loss: 0.69401 - acc: 0.4939 -- iter: 0576/1162
[A[ATraining Step: 389  | total loss: [1m[32m0.69392[0m[0m | time: 21.717s
[2K
| RMSProp | epoch: 011 | loss: 0.69392 - acc: 0.4945 -- iter: 0608/1162
[A[ATraining Step: 390  | total loss: [1m[32m0.69375[0m[0m | time: 22.903s
[2K
| RMSProp | epoch: 011 | loss: 0.69375 - acc: 0.5013 -- iter: 0640/1162
[A[ATraining Step: 391  | total loss: [1m[32m0.69362[0m[0m | time: 23.965s
[2K
| RMSProp | epoch: 011 | loss: 0.69362 - acc: 0.5043 -- iter: 0672/1162
[A[ATraining Step: 392  | total loss: [1m[32m0.69348[0m[0m | time: 25.506s
[2K
| RMSProp | epoch: 011 | loss: 0.69348 - acc: 0.5070 -- iter: 0704/1162
[A[ATraining Step: 393  | total loss: [1m[32m0.69357[0m[0m | time: 26.905s
[2K
| RMSProp | epoch: 011 | loss: 0.69357 - acc: 0.5001 -- iter: 0736/1162
[A[ATraining Step: 394  | total loss: [1m[32m0.69350[0m[0m | time: 28.159s
[2K
| RMSProp | epoch: 011 | loss: 0.69350 - acc: 0.5001 -- iter: 0768/1162
[A[ATraining Step: 395  | total loss: [1m[32m0.69330[0m[0m | time: 29.139s
[2K
| RMSProp | epoch: 011 | loss: 0.69330 - acc: 0.5094 -- iter: 0800/1162
[A[ATraining Step: 396  | total loss: [1m[32m0.69350[0m[0m | time: 30.382s
[2K
| RMSProp | epoch: 011 | loss: 0.69350 - acc: 0.4991 -- iter: 0832/1162
[A[ATraining Step: 397  | total loss: [1m[32m0.69340[0m[0m | time: 31.596s
[2K
| RMSProp | epoch: 011 | loss: 0.69340 - acc: 0.5055 -- iter: 0864/1162
[A[ATraining Step: 398  | total loss: [1m[32m0.69359[0m[0m | time: 32.562s
[2K
| RMSProp | epoch: 011 | loss: 0.69359 - acc: 0.4924 -- iter: 0896/1162
[A[ATraining Step: 399  | total loss: [1m[32m0.69351[0m[0m | time: 33.594s
[2K
| RMSProp | epoch: 011 | loss: 0.69351 - acc: 0.5057 -- iter: 0928/1162
[A[ATraining Step: 400  | total loss: [1m[32m0.69338[0m[0m | time: 37.387s
[2K
| RMSProp | epoch: 011 | loss: 0.69338 - acc: 0.5176 | val_loss: 0.69244 - val_acc: 0.4945 -- iter: 0960/1162
--
Training Step: 401  | total loss: [1m[32m0.69327[0m[0m | time: 38.815s
[2K
| RMSProp | epoch: 011 | loss: 0.69327 - acc: 0.5252 -- iter: 0992/1162
[A[ATraining Step: 402  | total loss: [1m[32m0.69339[0m[0m | time: 40.205s
[2K
| RMSProp | epoch: 011 | loss: 0.69339 - acc: 0.5196 -- iter: 1024/1162
[A[ATraining Step: 403  | total loss: [1m[32m0.69338[0m[0m | time: 41.179s
[2K
| RMSProp | epoch: 011 | loss: 0.69338 - acc: 0.4989 -- iter: 1056/1162
[A[ATraining Step: 404  | total loss: [1m[32m0.69335[0m[0m | time: 42.240s
[2K
| RMSProp | epoch: 011 | loss: 0.69335 - acc: 0.4990 -- iter: 1088/1162
[A[ATraining Step: 405  | total loss: [1m[32m0.69285[0m[0m | time: 43.474s
[2K
| RMSProp | epoch: 011 | loss: 0.69285 - acc: 0.5085 -- iter: 1120/1162
[A[ATraining Step: 406  | total loss: [1m[32m0.69487[0m[0m | time: 44.639s
[2K
| RMSProp | epoch: 011 | loss: 0.69487 - acc: 0.4920 -- iter: 1152/1162
[A[ATraining Step: 407  | total loss: [1m[32m0.69463[0m[0m | time: 48.695s
[2K
| RMSProp | epoch: 011 | loss: 0.69463 - acc: 0.4990 | val_loss: 0.69235 - val_acc: 0.4945 -- iter: 1162/1162
--
Training Step: 408  | total loss: [1m[32m0.69438[0m[0m | time: 1.560s
[2K
| RMSProp | epoch: 012 | loss: 0.69438 - acc: 0.5023 -- iter: 0032/1162
[A[ATraining Step: 409  | total loss: [1m[32m0.69394[0m[0m | time: 2.847s
[2K
| RMSProp | epoch: 012 | loss: 0.69394 - acc: 0.5114 -- iter: 0064/1162
[A[ATraining Step: 410  | total loss: [1m[32m0.69379[0m[0m | time: 3.888s
[2K
| RMSProp | epoch: 012 | loss: 0.69379 - acc: 0.5103 -- iter: 0096/1162
[A[ATraining Step: 411  | total loss: [1m[32m0.69335[0m[0m | time: 5.149s
[2K
| RMSProp | epoch: 012 | loss: 0.69335 - acc: 0.5155 -- iter: 0128/1162
[A[ATraining Step: 412  | total loss: [1m[32m0.69289[0m[0m | time: 6.331s
[2K
| RMSProp | epoch: 012 | loss: 0.69289 - acc: 0.5202 -- iter: 0160/1162
[A[ATraining Step: 413  | total loss: [1m[32m0.69313[0m[0m | time: 7.444s
[2K
| RMSProp | epoch: 012 | loss: 0.69313 - acc: 0.5150 -- iter: 0192/1162
[A[ATraining Step: 414  | total loss: [1m[32m0.69327[0m[0m | time: 8.787s
[2K
| RMSProp | epoch: 012 | loss: 0.69327 - acc: 0.5073 -- iter: 0224/1162
[A[ATraining Step: 415  | total loss: [1m[32m0.69317[0m[0m | time: 10.115s
[2K
| RMSProp | epoch: 012 | loss: 0.69317 - acc: 0.5097 -- iter: 0256/1162
[A[ATraining Step: 416  | total loss: [1m[32m0.69315[0m[0m | time: 11.237s
[2K
| RMSProp | epoch: 012 | loss: 0.69315 - acc: 0.5087 -- iter: 0288/1162
[A[ATraining Step: 417  | total loss: [1m[32m0.69367[0m[0m | time: 11.679s
[2K
| RMSProp | epoch: 012 | loss: 0.69367 - acc: 0.4953 -- iter: 0320/1162
[A[ATraining Step: 418  | total loss: [1m[32m0.69344[0m[0m | time: 12.231s
[2K
| RMSProp | epoch: 012 | loss: 0.69344 - acc: 0.5258 -- iter: 0352/1162
[A[ATraining Step: 419  | total loss: [1m[32m0.69122[0m[0m | time: 13.484s
[2K
| RMSProp | epoch: 012 | loss: 0.69122 - acc: 0.5532 -- iter: 0384/1162
[A[ATraining Step: 420  | total loss: [1m[32m0.69025[0m[0m | time: 14.748s
[2K
| RMSProp | epoch: 012 | loss: 0.69025 - acc: 0.5542 -- iter: 0416/1162
[A[ATraining Step: 421  | total loss: [1m[32m0.69019[0m[0m | time: 15.980s
[2K
| RMSProp | epoch: 012 | loss: 0.69019 - acc: 0.5519 -- iter: 0448/1162
[A[ATraining Step: 422  | total loss: [1m[32m0.69044[0m[0m | time: 17.184s
[2K
| RMSProp | epoch: 012 | loss: 0.69044 - acc: 0.5467 -- iter: 0480/1162
[A[ATraining Step: 423  | total loss: [1m[32m0.69083[0m[0m | time: 18.444s
[2K
| RMSProp | epoch: 012 | loss: 0.69083 - acc: 0.5389 -- iter: 0512/1162
[A[ATraining Step: 424  | total loss: [1m[32m0.69139[0m[0m | time: 19.738s
[2K
| RMSProp | epoch: 012 | loss: 0.69139 - acc: 0.5287 -- iter: 0544/1162
[A[ATraining Step: 425  | total loss: [1m[32m0.69132[0m[0m | time: 20.847s
[2K
| RMSProp | epoch: 012 | loss: 0.69132 - acc: 0.5321 -- iter: 0576/1162
[A[ATraining Step: 426  | total loss: [1m[32m0.69063[0m[0m | time: 21.780s
[2K
| RMSProp | epoch: 012 | loss: 0.69063 - acc: 0.5383 -- iter: 0608/1162
[A[ATraining Step: 427  | total loss: [1m[32m0.69192[0m[0m | time: 22.625s
[2K
| RMSProp | epoch: 012 | loss: 0.69192 - acc: 0.5251 -- iter: 0640/1162
[A[ATraining Step: 428  | total loss: [1m[32m0.69178[0m[0m | time: 23.438s
[2K
| RMSProp | epoch: 012 | loss: 0.69178 - acc: 0.5194 -- iter: 0672/1162
[A[ATraining Step: 429  | total loss: [1m[32m0.69166[0m[0m | time: 24.258s
[2K
| RMSProp | epoch: 012 | loss: 0.69166 - acc: 0.5144 -- iter: 0704/1162
[A[ATraining Step: 430  | total loss: [1m[32m0.69105[0m[0m | time: 25.221s
[2K
| RMSProp | epoch: 012 | loss: 0.69105 - acc: 0.5411 -- iter: 0736/1162
[A[ATraining Step: 431  | total loss: [1m[32m0.69007[0m[0m | time: 26.221s
[2K
| RMSProp | epoch: 012 | loss: 0.69007 - acc: 0.5463 -- iter: 0768/1162
[A[ATraining Step: 432  | total loss: [1m[32m0.68932[0m[0m | time: 26.885s
[2K
| RMSProp | epoch: 012 | loss: 0.68932 - acc: 0.5480 -- iter: 0800/1162
[A[ATraining Step: 433  | total loss: [1m[32m0.69090[0m[0m | time: 27.799s
[2K
| RMSProp | epoch: 012 | loss: 0.69090 - acc: 0.5369 -- iter: 0832/1162
[A[ATraining Step: 434  | total loss: [1m[32m0.69078[0m[0m | time: 28.652s
[2K
| RMSProp | epoch: 012 | loss: 0.69078 - acc: 0.5301 -- iter: 0864/1162
[A[ATraining Step: 435  | total loss: [1m[32m0.69082[0m[0m | time: 29.471s
[2K
| RMSProp | epoch: 012 | loss: 0.69082 - acc: 0.5365 -- iter: 0896/1162
[A[ATraining Step: 436  | total loss: [1m[32m0.69097[0m[0m | time: 30.305s
[2K
| RMSProp | epoch: 012 | loss: 0.69097 - acc: 0.5297 -- iter: 0928/1162
[A[ATraining Step: 437  | total loss: [1m[32m0.69059[0m[0m | time: 31.151s
[2K
| RMSProp | epoch: 012 | loss: 0.69059 - acc: 0.5298 -- iter: 0960/1162
[A[ATraining Step: 438  | total loss: [1m[32m0.69047[0m[0m | time: 31.899s
[2K
| RMSProp | epoch: 012 | loss: 0.69047 - acc: 0.5237 -- iter: 0992/1162
[A[ATraining Step: 439  | total loss: [1m[32m0.69006[0m[0m | time: 32.687s
[2K
| RMSProp | epoch: 012 | loss: 0.69006 - acc: 0.5432 -- iter: 1024/1162
[A[ATraining Step: 440  | total loss: [1m[32m0.68912[0m[0m | time: 33.530s
[2K
| RMSProp | epoch: 012 | loss: 0.68912 - acc: 0.5608 -- iter: 1056/1162
[A[ATraining Step: 441  | total loss: [1m[32m0.68876[0m[0m | time: 34.360s
[2K
| RMSProp | epoch: 012 | loss: 0.68876 - acc: 0.5578 -- iter: 1088/1162
[A[ATraining Step: 442  | total loss: [1m[32m0.68542[0m[0m | time: 35.175s
[2K
| RMSProp | epoch: 012 | loss: 0.68542 - acc: 0.5708 -- iter: 1120/1162
[A[ATraining Step: 443  | total loss: [1m[32m0.69501[0m[0m | time: 35.959s
[2K
| RMSProp | epoch: 012 | loss: 0.69501 - acc: 0.5512 -- iter: 1152/1162
[A[ATraining Step: 444  | total loss: [1m[32m0.69458[0m[0m | time: 38.626s
[2K
| RMSProp | epoch: 012 | loss: 0.69458 - acc: 0.5398 | val_loss: 0.68041 - val_acc: 0.6923 -- iter: 1162/1162
--
Training Step: 445  | total loss: [1m[32m0.69337[0m[0m | time: 0.834s
[2K
| RMSProp | epoch: 013 | loss: 0.69337 - acc: 0.5671 -- iter: 0032/1162
[A[ATraining Step: 446  | total loss: [1m[32m0.69232[0m[0m | time: 1.590s
[2K
| RMSProp | epoch: 013 | loss: 0.69232 - acc: 0.5854 -- iter: 0064/1162
[A[ATraining Step: 447  | total loss: [1m[32m0.69311[0m[0m | time: 2.355s
[2K
| RMSProp | epoch: 013 | loss: 0.69311 - acc: 0.5644 -- iter: 0096/1162
[A[ATraining Step: 448  | total loss: [1m[32m0.69147[0m[0m | time: 3.092s
[2K
| RMSProp | epoch: 013 | loss: 0.69147 - acc: 0.5767 -- iter: 0128/1162
[A[ATraining Step: 449  | total loss: [1m[32m0.68948[0m[0m | time: 3.952s
[2K
| RMSProp | epoch: 013 | loss: 0.68948 - acc: 0.6003 -- iter: 0160/1162
[A[ATraining Step: 450  | total loss: [1m[32m0.68803[0m[0m | time: 4.753s
[2K
| RMSProp | epoch: 013 | loss: 0.68803 - acc: 0.6059 -- iter: 0192/1162
[A[ATraining Step: 451  | total loss: [1m[32m0.68877[0m[0m | time: 5.539s
[2K
| RMSProp | epoch: 013 | loss: 0.68877 - acc: 0.5890 -- iter: 0224/1162
[A[ATraining Step: 452  | total loss: [1m[32m0.68751[0m[0m | time: 6.326s
[2K
| RMSProp | epoch: 013 | loss: 0.68751 - acc: 0.5895 -- iter: 0256/1162
[A[ATraining Step: 453  | total loss: [1m[32m0.68564[0m[0m | time: 7.177s
[2K
| RMSProp | epoch: 013 | loss: 0.68564 - acc: 0.5993 -- iter: 0288/1162
[A[ATraining Step: 454  | total loss: [1m[32m0.68691[0m[0m | time: 7.956s
[2K
| RMSProp | epoch: 013 | loss: 0.68691 - acc: 0.5831 -- iter: 0320/1162
[A[ATraining Step: 455  | total loss: [1m[32m0.68514[0m[0m | time: 8.238s
[2K
| RMSProp | epoch: 013 | loss: 0.68514 - acc: 0.5811 -- iter: 0352/1162
[A[ATraining Step: 456  | total loss: [1m[32m0.68365[0m[0m | time: 8.470s
[2K
| RMSProp | epoch: 013 | loss: 0.68365 - acc: 0.5929 -- iter: 0384/1162
[A[ATraining Step: 457  | total loss: [1m[32m0.68047[0m[0m | time: 9.373s
[2K
| RMSProp | epoch: 013 | loss: 0.68047 - acc: 0.6137 -- iter: 0416/1162
[A[ATraining Step: 458  | total loss: [1m[32m0.67893[0m[0m | time: 10.507s
[2K
| RMSProp | epoch: 013 | loss: 0.67893 - acc: 0.6179 -- iter: 0448/1162
[A[ATraining Step: 459  | total loss: [1m[32m0.67959[0m[0m | time: 11.332s
[2K
| RMSProp | epoch: 013 | loss: 0.67959 - acc: 0.6061 -- iter: 0480/1162
[A[ATraining Step: 460  | total loss: [1m[32m0.67670[0m[0m | time: 12.142s
[2K
| RMSProp | epoch: 013 | loss: 0.67670 - acc: 0.6080 -- iter: 0512/1162
[A[ATraining Step: 461  | total loss: [1m[32m0.67212[0m[0m | time: 13.685s
[2K
| RMSProp | epoch: 013 | loss: 0.67212 - acc: 0.6128 -- iter: 0544/1162
[A[ATraining Step: 462  | total loss: [1m[32m0.67285[0m[0m | time: 15.293s
[2K
| RMSProp | epoch: 013 | loss: 0.67285 - acc: 0.6016 -- iter: 0576/1162
[A[ATraining Step: 463  | total loss: [1m[32m0.67357[0m[0m | time: 16.635s
[2K
| RMSProp | epoch: 013 | loss: 0.67357 - acc: 0.5945 -- iter: 0608/1162
[A[ATraining Step: 464  | total loss: [1m[32m0.67171[0m[0m | time: 17.695s
[2K
| RMSProp | epoch: 013 | loss: 0.67171 - acc: 0.6007 -- iter: 0640/1162
[A[ATraining Step: 465  | total loss: [1m[32m0.66957[0m[0m | time: 18.991s
[2K
| RMSProp | epoch: 013 | loss: 0.66957 - acc: 0.6125 -- iter: 0672/1162
[A[ATraining Step: 466  | total loss: [1m[32m0.66823[0m[0m | time: 20.136s
[2K
| RMSProp | epoch: 013 | loss: 0.66823 - acc: 0.6106 -- iter: 0704/1162
[A[ATraining Step: 467  | total loss: [1m[32m0.66815[0m[0m | time: 21.302s
[2K
| RMSProp | epoch: 013 | loss: 0.66815 - acc: 0.6058 -- iter: 0736/1162
[A[ATraining Step: 468  | total loss: [1m[32m0.66973[0m[0m | time: 22.853s
[2K
| RMSProp | epoch: 013 | loss: 0.66973 - acc: 0.5984 -- iter: 0768/1162
[A[ATraining Step: 469  | total loss: [1m[32m0.66621[0m[0m | time: 24.221s
[2K
| RMSProp | epoch: 013 | loss: 0.66621 - acc: 0.5979 -- iter: 0800/1162
[A[ATraining Step: 470  | total loss: [1m[32m0.66644[0m[0m | time: 25.137s
[2K
| RMSProp | epoch: 013 | loss: 0.66644 - acc: 0.6006 -- iter: 0832/1162
[A[ATraining Step: 471  | total loss: [1m[32m0.66637[0m[0m | time: 26.675s
[2K
| RMSProp | epoch: 013 | loss: 0.66637 - acc: 0.5937 -- iter: 0864/1162
[A[ATraining Step: 472  | total loss: [1m[32m0.66035[0m[0m | time: 28.117s
[2K
| RMSProp | epoch: 013 | loss: 0.66035 - acc: 0.6031 -- iter: 0896/1162
[A[ATraining Step: 473  | total loss: [1m[32m0.65240[0m[0m | time: 29.633s
[2K
| RMSProp | epoch: 013 | loss: 0.65240 - acc: 0.6115 -- iter: 0928/1162
[A[ATraining Step: 474  | total loss: [1m[32m0.65118[0m[0m | time: 30.700s
[2K
| RMSProp | epoch: 013 | loss: 0.65118 - acc: 0.6160 -- iter: 0960/1162
[A[ATraining Step: 475  | total loss: [1m[32m0.67039[0m[0m | time: 31.829s
[2K
| RMSProp | epoch: 013 | loss: 0.67039 - acc: 0.5919 -- iter: 0992/1162
[A[ATraining Step: 476  | total loss: [1m[32m0.66450[0m[0m | time: 33.033s
[2K
| RMSProp | epoch: 013 | loss: 0.66450 - acc: 0.6014 -- iter: 1024/1162
[A[ATraining Step: 477  | total loss: [1m[32m0.65492[0m[0m | time: 34.143s
[2K
| RMSProp | epoch: 013 | loss: 0.65492 - acc: 0.6132 -- iter: 1056/1162
[A[ATraining Step: 478  | total loss: [1m[32m0.64816[0m[0m | time: 35.342s
[2K
| RMSProp | epoch: 013 | loss: 0.64816 - acc: 0.6300 -- iter: 1088/1162
[A[ATraining Step: 479  | total loss: [1m[32m0.64269[0m[0m | time: 36.690s
[2K
| RMSProp | epoch: 013 | loss: 0.64269 - acc: 0.6389 -- iter: 1120/1162
[A[ATraining Step: 480  | total loss: [1m[32m0.63682[0m[0m | time: 37.665s
[2K
| RMSProp | epoch: 013 | loss: 0.63682 - acc: 0.6531 -- iter: 1152/1162
[A[ATraining Step: 481  | total loss: [1m[32m0.62846[0m[0m | time: 42.297s
[2K
| RMSProp | epoch: 013 | loss: 0.62846 - acc: 0.6534 | val_loss: 0.72456 - val_acc: 0.5220 -- iter: 1162/1162
--
Training Step: 482  | total loss: [1m[32m0.63656[0m[0m | time: 1.115s
[2K
| RMSProp | epoch: 014 | loss: 0.63656 - acc: 0.6474 -- iter: 0032/1162
[A[ATraining Step: 483  | total loss: [1m[32m0.64831[0m[0m | time: 2.309s
[2K
| RMSProp | epoch: 014 | loss: 0.64831 - acc: 0.6296 -- iter: 0064/1162
[A[ATraining Step: 484  | total loss: [1m[32m0.64340[0m[0m | time: 3.622s
[2K
| RMSProp | epoch: 014 | loss: 0.64340 - acc: 0.6447 -- iter: 0096/1162
[A[ATraining Step: 485  | total loss: [1m[32m0.63066[0m[0m | time: 4.969s
[2K
| RMSProp | epoch: 014 | loss: 0.63066 - acc: 0.6709 -- iter: 0128/1162
[A[ATraining Step: 486  | total loss: [1m[32m0.61847[0m[0m | time: 6.299s
[2K
| RMSProp | epoch: 014 | loss: 0.61847 - acc: 0.6913 -- iter: 0160/1162
[A[ATraining Step: 487  | total loss: [1m[32m0.61869[0m[0m | time: 7.478s
[2K
| RMSProp | epoch: 014 | loss: 0.61869 - acc: 0.6909 -- iter: 0192/1162
[A[ATraining Step: 488  | total loss: [1m[32m0.61907[0m[0m | time: 8.937s
[2K
| RMSProp | epoch: 014 | loss: 0.61907 - acc: 0.6875 -- iter: 0224/1162
[A[ATraining Step: 489  | total loss: [1m[32m0.63516[0m[0m | time: 10.387s
[2K
| RMSProp | epoch: 014 | loss: 0.63516 - acc: 0.6781 -- iter: 0256/1162
[A[ATraining Step: 490  | total loss: [1m[32m0.63688[0m[0m | time: 11.571s
[2K
| RMSProp | epoch: 014 | loss: 0.63688 - acc: 0.6728 -- iter: 0288/1162
[A[ATraining Step: 491  | total loss: [1m[32m0.64613[0m[0m | time: 12.700s
[2K
| RMSProp | epoch: 014 | loss: 0.64613 - acc: 0.6524 -- iter: 0320/1162
[A[ATraining Step: 492  | total loss: [1m[32m0.63993[0m[0m | time: 13.894s
[2K
| RMSProp | epoch: 014 | loss: 0.63993 - acc: 0.6684 -- iter: 0352/1162
[A[ATraining Step: 493  | total loss: [1m[32m0.63439[0m[0m | time: 14.294s
[2K
| RMSProp | epoch: 014 | loss: 0.63439 - acc: 0.6609 -- iter: 0384/1162
[A[ATraining Step: 494  | total loss: [1m[32m0.64478[0m[0m | time: 14.792s
[2K
| RMSProp | epoch: 014 | loss: 0.64478 - acc: 0.6348 -- iter: 0416/1162
[A[ATraining Step: 495  | total loss: [1m[32m0.62176[0m[0m | time: 16.075s
[2K
| RMSProp | epoch: 014 | loss: 0.62176 - acc: 0.6513 -- iter: 0448/1162
[A[ATraining Step: 496  | total loss: [1m[32m0.63973[0m[0m | time: 17.239s
[2K
| RMSProp | epoch: 014 | loss: 0.63973 - acc: 0.6331 -- iter: 0480/1162
[A[ATraining Step: 497  | total loss: [1m[32m0.63611[0m[0m | time: 18.369s
[2K
| RMSProp | epoch: 014 | loss: 0.63611 - acc: 0.6385 -- iter: 0512/1162
[A[ATraining Step: 498  | total loss: [1m[32m0.62924[0m[0m | time: 19.912s
[2K
| RMSProp | epoch: 014 | loss: 0.62924 - acc: 0.6497 -- iter: 0544/1162
[A[ATraining Step: 499  | total loss: [1m[32m0.62669[0m[0m | time: 21.272s
[2K
| RMSProp | epoch: 014 | loss: 0.62669 - acc: 0.6503 -- iter: 0576/1162
[A[ATraining Step: 500  | total loss: [1m[32m0.61884[0m[0m | time: 22.521s
[2K
| RMSProp | epoch: 014 | loss: 0.61884 - acc: 0.6634 -- iter: 0608/1162
[A[ATraining Step: 501  | total loss: [1m[32m0.62672[0m[0m | time: 23.706s
[2K
| RMSProp | epoch: 014 | loss: 0.62672 - acc: 0.6440 -- iter: 0640/1162
[A[ATraining Step: 502  | total loss: [1m[32m0.62422[0m[0m | time: 24.891s
[2K
| RMSProp | epoch: 014 | loss: 0.62422 - acc: 0.6514 -- iter: 0672/1162
[A[ATraining Step: 503  | total loss: [1m[32m0.61810[0m[0m | time: 26.207s
[2K
| RMSProp | epoch: 014 | loss: 0.61810 - acc: 0.6644 -- iter: 0704/1162
[A[ATraining Step: 504  | total loss: [1m[32m0.61776[0m[0m | time: 27.458s
[2K
| RMSProp | epoch: 014 | loss: 0.61776 - acc: 0.6605 -- iter: 0736/1162
[A[ATraining Step: 505  | total loss: [1m[32m0.61381[0m[0m | time: 28.855s
[2K
| RMSProp | epoch: 014 | loss: 0.61381 - acc: 0.6757 -- iter: 0768/1162
[A[ATraining Step: 506  | total loss: [1m[32m0.60947[0m[0m | time: 30.477s
[2K
| RMSProp | epoch: 014 | loss: 0.60947 - acc: 0.6769 -- iter: 0800/1162
[A[ATraining Step: 507  | total loss: [1m[32m0.60137[0m[0m | time: 31.757s
[2K
| RMSProp | epoch: 014 | loss: 0.60137 - acc: 0.6935 -- iter: 0832/1162
[A[ATraining Step: 508  | total loss: [1m[32m0.60011[0m[0m | time: 32.888s
[2K
| RMSProp | epoch: 014 | loss: 0.60011 - acc: 0.6961 -- iter: 0864/1162
[A[ATraining Step: 509  | total loss: [1m[32m0.58341[0m[0m | time: 33.970s
[2K
| RMSProp | epoch: 014 | loss: 0.58341 - acc: 0.7202 -- iter: 0896/1162
[A[ATraining Step: 510  | total loss: [1m[32m0.57952[0m[0m | time: 35.154s
[2K
| RMSProp | epoch: 014 | loss: 0.57952 - acc: 0.7169 -- iter: 0928/1162
[A[ATraining Step: 511  | total loss: [1m[32m0.58137[0m[0m | time: 36.267s
[2K
| RMSProp | epoch: 014 | loss: 0.58137 - acc: 0.7077 -- iter: 0960/1162
[A[ATraining Step: 512  | total loss: [1m[32m0.57500[0m[0m | time: 37.541s
[2K
| RMSProp | epoch: 014 | loss: 0.57500 - acc: 0.7088 -- iter: 0992/1162
[A[ATraining Step: 513  | total loss: [1m[32m0.57188[0m[0m | time: 38.992s
[2K
| RMSProp | epoch: 014 | loss: 0.57188 - acc: 0.7161 -- iter: 1024/1162
[A[ATraining Step: 514  | total loss: [1m[32m0.57014[0m[0m | time: 40.082s
[2K
| RMSProp | epoch: 014 | loss: 0.57014 - acc: 0.7226 -- iter: 1056/1162
[A[ATraining Step: 515  | total loss: [1m[32m0.56256[0m[0m | time: 41.467s
[2K
| RMSProp | epoch: 014 | loss: 0.56256 - acc: 0.7222 -- iter: 1088/1162
[A[ATraining Step: 516  | total loss: [1m[32m0.56632[0m[0m | time: 42.920s
[2K
| RMSProp | epoch: 014 | loss: 0.56632 - acc: 0.7187 -- iter: 1120/1162
[A[ATraining Step: 517  | total loss: [1m[32m0.59292[0m[0m | time: 44.438s
[2K
| RMSProp | epoch: 014 | loss: 0.59292 - acc: 0.6937 -- iter: 1152/1162
[A[ATraining Step: 518  | total loss: [1m[32m0.59009[0m[0m | time: 48.097s
[2K
| RMSProp | epoch: 014 | loss: 0.59009 - acc: 0.7056 | val_loss: 0.56524 - val_acc: 0.7390 -- iter: 1162/1162
--
Training Step: 519  | total loss: [1m[32m0.59416[0m[0m | time: 1.101s
[2K
| RMSProp | epoch: 015 | loss: 0.59416 - acc: 0.6913 -- iter: 0032/1162
[A[ATraining Step: 520  | total loss: [1m[32m0.59221[0m[0m | time: 2.628s
[2K
| RMSProp | epoch: 015 | loss: 0.59221 - acc: 0.6972 -- iter: 0064/1162
[A[ATraining Step: 521  | total loss: [1m[32m0.58914[0m[0m | time: 4.217s
[2K
| RMSProp | epoch: 015 | loss: 0.58914 - acc: 0.6931 -- iter: 0096/1162
[A[ATraining Step: 522  | total loss: [1m[32m0.58591[0m[0m | time: 5.490s
[2K
| RMSProp | epoch: 015 | loss: 0.58591 - acc: 0.6894 -- iter: 0128/1162
[A[ATraining Step: 523  | total loss: [1m[32m0.58027[0m[0m | time: 6.533s
[2K
| RMSProp | epoch: 015 | loss: 0.58027 - acc: 0.6986 -- iter: 0160/1162
[A[ATraining Step: 524  | total loss: [1m[32m0.57475[0m[0m | time: 7.681s
[2K
| RMSProp | epoch: 015 | loss: 0.57475 - acc: 0.7100 -- iter: 0192/1162
[A[ATraining Step: 525  | total loss: [1m[32m0.56629[0m[0m | time: 8.842s
[2K
| RMSProp | epoch: 015 | loss: 0.56629 - acc: 0.7171 -- iter: 0224/1162
[A[ATraining Step: 526  | total loss: [1m[32m0.56178[0m[0m | time: 10.144s
[2K
| RMSProp | epoch: 015 | loss: 0.56178 - acc: 0.7173 -- iter: 0256/1162
[A[ATraining Step: 527  | total loss: [1m[32m0.56976[0m[0m | time: 11.379s
[2K
| RMSProp | epoch: 015 | loss: 0.56976 - acc: 0.7049 -- iter: 0288/1162
[A[ATraining Step: 528  | total loss: [1m[32m0.57149[0m[0m | time: 12.728s
[2K
| RMSProp | epoch: 015 | loss: 0.57149 - acc: 0.7001 -- iter: 0320/1162
[A[ATraining Step: 529  | total loss: [1m[32m0.56533[0m[0m | time: 13.750s
[2K
| RMSProp | epoch: 015 | loss: 0.56533 - acc: 0.7082 -- iter: 0352/1162
[A[ATraining Step: 530  | total loss: [1m[32m0.55850[0m[0m | time: 15.350s
[2K
| RMSProp | epoch: 015 | loss: 0.55850 - acc: 0.7092 -- iter: 0384/1162
[A[ATraining Step: 531  | total loss: [1m[32m0.55007[0m[0m | time: 15.859s
[2K
| RMSProp | epoch: 015 | loss: 0.55007 - acc: 0.7102 -- iter: 0416/1162
[A[ATraining Step: 532  | total loss: [1m[32m0.55706[0m[0m | time: 16.390s
[2K
| RMSProp | epoch: 015 | loss: 0.55706 - acc: 0.7092 -- iter: 0448/1162
[A[ATraining Step: 533  | total loss: [1m[32m0.55648[0m[0m | time: 17.786s
[2K
| RMSProp | epoch: 015 | loss: 0.55648 - acc: 0.7182 -- iter: 0480/1162
[A[ATraining Step: 534  | total loss: [1m[32m0.55969[0m[0m | time: 18.948s
[2K
| RMSProp | epoch: 015 | loss: 0.55969 - acc: 0.7152 -- iter: 0512/1162
[A[ATraining Step: 535  | total loss: [1m[32m0.56550[0m[0m | time: 20.081s
[2K
| RMSProp | epoch: 015 | loss: 0.56550 - acc: 0.7093 -- iter: 0544/1162
[A[ATraining Step: 536  | total loss: [1m[32m0.57846[0m[0m | time: 21.258s
[2K
| RMSProp | epoch: 015 | loss: 0.57846 - acc: 0.6915 -- iter: 0576/1162
[A[ATraining Step: 537  | total loss: [1m[32m0.56167[0m[0m | time: 22.506s
[2K
| RMSProp | epoch: 015 | loss: 0.56167 - acc: 0.7098 -- iter: 0608/1162
[A[ATraining Step: 538  | total loss: [1m[32m0.57152[0m[0m | time: 23.833s
[2K
| RMSProp | epoch: 015 | loss: 0.57152 - acc: 0.6951 -- iter: 0640/1162
[A[ATraining Step: 539  | total loss: [1m[32m0.56633[0m[0m | time: 25.422s
[2K
| RMSProp | epoch: 015 | loss: 0.56633 - acc: 0.7037 -- iter: 0672/1162
[A[ATraining Step: 540  | total loss: [1m[32m0.55427[0m[0m | time: 26.666s
[2K
| RMSProp | epoch: 015 | loss: 0.55427 - acc: 0.7177 -- iter: 0704/1162
[A[ATraining Step: 541  | total loss: [1m[32m0.54250[0m[0m | time: 27.978s
[2K
| RMSProp | epoch: 015 | loss: 0.54250 - acc: 0.7334 -- iter: 0736/1162
[A[ATraining Step: 542  | total loss: [1m[32m0.55087[0m[0m | time: 29.345s
[2K
| RMSProp | epoch: 015 | loss: 0.55087 - acc: 0.7257 -- iter: 0768/1162
[A[ATraining Step: 543  | total loss: [1m[32m0.54364[0m[0m | time: 30.597s
[2K
| RMSProp | epoch: 015 | loss: 0.54364 - acc: 0.7219 -- iter: 0800/1162
[A[ATraining Step: 544  | total loss: [1m[32m0.54176[0m[0m | time: 31.445s
[2K
| RMSProp | epoch: 015 | loss: 0.54176 - acc: 0.7278 -- iter: 0832/1162
[A[ATraining Step: 545  | total loss: [1m[32m0.53179[0m[0m | time: 32.527s
[2K
| RMSProp | epoch: 015 | loss: 0.53179 - acc: 0.7332 -- iter: 0864/1162
[A[ATraining Step: 546  | total loss: [1m[32m0.52158[0m[0m | time: 33.675s
[2K
| RMSProp | epoch: 015 | loss: 0.52158 - acc: 0.7442 -- iter: 0896/1162
[A[ATraining Step: 547  | total loss: [1m[32m0.50970[0m[0m | time: 34.926s
[2K
| RMSProp | epoch: 015 | loss: 0.50970 - acc: 0.7573 -- iter: 0928/1162
[A[ATraining Step: 548  | total loss: [1m[32m0.51101[0m[0m | time: 36.164s
[2K
| RMSProp | epoch: 015 | loss: 0.51101 - acc: 0.7535 -- iter: 0960/1162
[A[ATraining Step: 549  | total loss: [1m[32m0.50885[0m[0m | time: 37.561s
[2K
| RMSProp | epoch: 015 | loss: 0.50885 - acc: 0.7562 -- iter: 0992/1162
[A[ATraining Step: 550  | total loss: [1m[32m0.50151[0m[0m | time: 38.758s
[2K
| RMSProp | epoch: 015 | loss: 0.50151 - acc: 0.7650 -- iter: 1024/1162
[A[ATraining Step: 551  | total loss: [1m[32m0.49356[0m[0m | time: 40.113s
[2K
| RMSProp | epoch: 015 | loss: 0.49356 - acc: 0.7697 -- iter: 1056/1162
[A[ATraining Step: 552  | total loss: [1m[32m0.48812[0m[0m | time: 41.488s
[2K
| RMSProp | epoch: 015 | loss: 0.48812 - acc: 0.7771 -- iter: 1088/1162
[A[ATraining Step: 553  | total loss: [1m[32m0.49945[0m[0m | time: 42.952s
[2K
| RMSProp | epoch: 015 | loss: 0.49945 - acc: 0.7651 -- iter: 1120/1162
[A[ATraining Step: 554  | total loss: [1m[32m0.51094[0m[0m | time: 44.216s
[2K
| RMSProp | epoch: 015 | loss: 0.51094 - acc: 0.7573 -- iter: 1152/1162
[A[ATraining Step: 555  | total loss: [1m[32m0.51632[0m[0m | time: 47.821s
[2K
| RMSProp | epoch: 015 | loss: 0.51632 - acc: 0.7534 | val_loss: 0.49198 - val_acc: 0.7692 -- iter: 1162/1162
--
Training Step: 556  | total loss: [1m[32m0.51958[0m[0m | time: 1.709s
[2K
| RMSProp | epoch: 016 | loss: 0.51958 - acc: 0.7500 -- iter: 0032/1162
[A[ATraining Step: 557  | total loss: [1m[32m0.51894[0m[0m | time: 2.916s
[2K
| RMSProp | epoch: 016 | loss: 0.51894 - acc: 0.7500 -- iter: 0064/1162
[A[ATraining Step: 558  | total loss: [1m[32m0.52316[0m[0m | time: 4.025s
[2K
| RMSProp | epoch: 016 | loss: 0.52316 - acc: 0.7531 -- iter: 0096/1162
[A[ATraining Step: 559  | total loss: [1m[32m0.51359[0m[0m | time: 5.248s
[2K
| RMSProp | epoch: 016 | loss: 0.51359 - acc: 0.7622 -- iter: 0128/1162
[A[ATraining Step: 560  | total loss: [1m[32m0.51415[0m[0m | time: 6.451s
[2K
| RMSProp | epoch: 016 | loss: 0.51415 - acc: 0.7610 -- iter: 0160/1162
[A[ATraining Step: 561  | total loss: [1m[32m0.50966[0m[0m | time: 7.729s
[2K
| RMSProp | epoch: 016 | loss: 0.50966 - acc: 0.7661 -- iter: 0192/1162
[A[ATraining Step: 562  | total loss: [1m[32m0.50312[0m[0m | time: 9.033s
[2K
| RMSProp | epoch: 016 | loss: 0.50312 - acc: 0.7770 -- iter: 0224/1162
[A[ATraining Step: 563  | total loss: [1m[32m0.49675[0m[0m | time: 10.304s
[2K
| RMSProp | epoch: 016 | loss: 0.49675 - acc: 0.7805 -- iter: 0256/1162
[A[ATraining Step: 564  | total loss: [1m[32m0.48402[0m[0m | time: 11.838s
[2K
| RMSProp | epoch: 016 | loss: 0.48402 - acc: 0.7869 -- iter: 0288/1162
[A[ATraining Step: 565  | total loss: [1m[32m0.47480[0m[0m | time: 13.305s
[2K
| RMSProp | epoch: 016 | loss: 0.47480 - acc: 0.7894 -- iter: 0320/1162
[A[ATraining Step: 566  | total loss: [1m[32m0.45809[0m[0m | time: 14.739s
[2K
| RMSProp | epoch: 016 | loss: 0.45809 - acc: 0.8042 -- iter: 0352/1162
[A[ATraining Step: 567  | total loss: [1m[32m0.45933[0m[0m | time: 15.796s
[2K
| RMSProp | epoch: 016 | loss: 0.45933 - acc: 0.8051 -- iter: 0384/1162
[A[ATraining Step: 568  | total loss: [1m[32m0.47033[0m[0m | time: 16.946s
[2K
| RMSProp | epoch: 016 | loss: 0.47033 - acc: 0.7996 -- iter: 0416/1162
[A[ATraining Step: 569  | total loss: [1m[32m0.47317[0m[0m | time: 17.349s
[2K
| RMSProp | epoch: 016 | loss: 0.47317 - acc: 0.7946 -- iter: 0448/1162
[A[ATraining Step: 570  | total loss: [1m[32m0.47222[0m[0m | time: 17.789s
[2K
| RMSProp | epoch: 016 | loss: 0.47222 - acc: 0.7951 -- iter: 0480/1162
[A[ATraining Step: 571  | total loss: [1m[32m0.45721[0m[0m | time: 18.998s
[2K
| RMSProp | epoch: 016 | loss: 0.45721 - acc: 0.8056 -- iter: 0512/1162
[A[ATraining Step: 572  | total loss: [1m[32m0.47239[0m[0m | time: 20.241s
[2K
| RMSProp | epoch: 016 | loss: 0.47239 - acc: 0.7938 -- iter: 0544/1162
[A[ATraining Step: 573  | total loss: [1m[32m0.50664[0m[0m | time: 21.713s
[2K
| RMSProp | epoch: 016 | loss: 0.50664 - acc: 0.7676 -- iter: 0576/1162
[A[ATraining Step: 574  | total loss: [1m[32m0.49610[0m[0m | time: 22.948s
[2K
| RMSProp | epoch: 016 | loss: 0.49610 - acc: 0.7814 -- iter: 0608/1162
[A[ATraining Step: 575  | total loss: [1m[32m0.47993[0m[0m | time: 24.273s
[2K
| RMSProp | epoch: 016 | loss: 0.47993 - acc: 0.7970 -- iter: 0640/1162
[A[ATraining Step: 576  | total loss: [1m[32m0.49233[0m[0m | time: 25.830s
[2K
| RMSProp | epoch: 016 | loss: 0.49233 - acc: 0.7861 -- iter: 0672/1162
[A[ATraining Step: 577  | total loss: [1m[32m0.49937[0m[0m | time: 27.268s
[2K
| RMSProp | epoch: 016 | loss: 0.49937 - acc: 0.7793 -- iter: 0704/1162
[A[ATraining Step: 578  | total loss: [1m[32m0.48824[0m[0m | time: 28.306s
[2K
| RMSProp | epoch: 016 | loss: 0.48824 - acc: 0.7920 -- iter: 0736/1162
[A[ATraining Step: 579  | total loss: [1m[32m0.47228[0m[0m | time: 29.268s
[2K
| RMSProp | epoch: 016 | loss: 0.47228 - acc: 0.8066 -- iter: 0768/1162
[A[ATraining Step: 580  | total loss: [1m[32m0.45793[0m[0m | time: 30.269s
[2K
| RMSProp | epoch: 016 | loss: 0.45793 - acc: 0.8134 -- iter: 0800/1162
[A[ATraining Step: 581  | total loss: [1m[32m0.45635[0m[0m | time: 31.291s
[2K
| RMSProp | epoch: 016 | loss: 0.45635 - acc: 0.8133 -- iter: 0832/1162
[A[ATraining Step: 582  | total loss: [1m[32m0.46533[0m[0m | time: 32.490s
[2K
| RMSProp | epoch: 016 | loss: 0.46533 - acc: 0.8070 -- iter: 0864/1162
[A[ATraining Step: 583  | total loss: [1m[32m0.46678[0m[0m | time: 33.824s
[2K
| RMSProp | epoch: 016 | loss: 0.46678 - acc: 0.8044 -- iter: 0896/1162
[A[ATraining Step: 584  | total loss: [1m[32m0.45767[0m[0m | time: 34.910s
[2K
| RMSProp | epoch: 016 | loss: 0.45767 - acc: 0.8052 -- iter: 0928/1162
[A[ATraining Step: 585  | total loss: [1m[32m0.46052[0m[0m | time: 36.062s
[2K
| RMSProp | epoch: 016 | loss: 0.46052 - acc: 0.8028 -- iter: 0960/1162
[A[ATraining Step: 586  | total loss: [1m[32m0.45700[0m[0m | time: 37.465s
[2K
| RMSProp | epoch: 016 | loss: 0.45700 - acc: 0.8038 -- iter: 0992/1162
[A[ATraining Step: 587  | total loss: [1m[32m0.45510[0m[0m | time: 38.968s
[2K
| RMSProp | epoch: 016 | loss: 0.45510 - acc: 0.7984 -- iter: 1024/1162
[A[ATraining Step: 588  | total loss: [1m[32m0.44268[0m[0m | time: 40.297s
[2K
| RMSProp | epoch: 016 | loss: 0.44268 - acc: 0.8092 -- iter: 1056/1162
[A[ATraining Step: 589  | total loss: [1m[32m0.42163[0m[0m | time: 41.384s
[2K
| RMSProp | epoch: 016 | loss: 0.42163 - acc: 0.8220 -- iter: 1088/1162
[A[ATraining Step: 590  | total loss: [1m[32m0.41579[0m[0m | time: 42.509s
[2K
| RMSProp | epoch: 016 | loss: 0.41579 - acc: 0.8242 -- iter: 1120/1162
[A[ATraining Step: 591  | total loss: [1m[32m0.43123[0m[0m | time: 43.666s
[2K
| RMSProp | epoch: 016 | loss: 0.43123 - acc: 0.8137 -- iter: 1152/1162
[A[ATraining Step: 592  | total loss: [1m[32m0.48355[0m[0m | time: 47.804s
[2K
| RMSProp | epoch: 016 | loss: 0.48355 - acc: 0.7823 | val_loss: 0.46154 - val_acc: 0.7912 -- iter: 1162/1162
--
Training Step: 593  | total loss: [1m[32m0.46780[0m[0m | time: 1.382s
[2K
| RMSProp | epoch: 017 | loss: 0.46780 - acc: 0.7916 -- iter: 0032/1162
[A[ATraining Step: 594  | total loss: [1m[32m0.46031[0m[0m | time: 2.670s
[2K
| RMSProp | epoch: 017 | loss: 0.46031 - acc: 0.7968 -- iter: 0064/1162
[A[ATraining Step: 595  | total loss: [1m[32m0.46004[0m[0m | time: 3.830s
[2K
| RMSProp | epoch: 017 | loss: 0.46004 - acc: 0.7890 -- iter: 0096/1162
[A[ATraining Step: 596  | total loss: [1m[32m0.47554[0m[0m | time: 5.038s
[2K
| RMSProp | epoch: 017 | loss: 0.47554 - acc: 0.7757 -- iter: 0128/1162
[A[ATraining Step: 597  | total loss: [1m[32m0.46159[0m[0m | time: 6.162s
[2K
| RMSProp | epoch: 017 | loss: 0.46159 - acc: 0.7825 -- iter: 0160/1162
[A[ATraining Step: 598  | total loss: [1m[32m0.46489[0m[0m | time: 6.936s
[2K
| RMSProp | epoch: 017 | loss: 0.46489 - acc: 0.7824 -- iter: 0192/1162
[A[ATraining Step: 599  | total loss: [1m[32m0.44577[0m[0m | time: 7.693s
[2K
| RMSProp | epoch: 017 | loss: 0.44577 - acc: 0.7948 -- iter: 0224/1162
[A[ATraining Step: 600  | total loss: [1m[32m0.44260[0m[0m | time: 10.074s
[2K
| RMSProp | epoch: 017 | loss: 0.44260 - acc: 0.7965 | val_loss: 0.49200 - val_acc: 0.7775 -- iter: 0256/1162
--
Training Step: 601  | total loss: [1m[32m0.44287[0m[0m | time: 10.884s
[2K
| RMSProp | epoch: 017 | loss: 0.44287 - acc: 0.7919 -- iter: 0288/1162
[A[ATraining Step: 602  | total loss: [1m[32m0.44730[0m[0m | time: 11.665s
[2K
| RMSProp | epoch: 017 | loss: 0.44730 - acc: 0.7846 -- iter: 0320/1162
[A[ATraining Step: 603  | total loss: [1m[32m0.45464[0m[0m | time: 12.449s
[2K
| RMSProp | epoch: 017 | loss: 0.45464 - acc: 0.7780 -- iter: 0352/1162
[A[ATraining Step: 604  | total loss: [1m[32m0.45390[0m[0m | time: 13.254s
[2K
| RMSProp | epoch: 017 | loss: 0.45390 - acc: 0.7783 -- iter: 0384/1162
[A[ATraining Step: 605  | total loss: [1m[32m0.46680[0m[0m | time: 14.081s
[2K
| RMSProp | epoch: 017 | loss: 0.46680 - acc: 0.7724 -- iter: 0416/1162
[A[ATraining Step: 606  | total loss: [1m[32m0.46094[0m[0m | time: 14.864s
[2K
| RMSProp | epoch: 017 | loss: 0.46094 - acc: 0.7795 -- iter: 0448/1162
[A[ATraining Step: 607  | total loss: [1m[32m0.46220[0m[0m | time: 15.164s
[2K
| RMSProp | epoch: 017 | loss: 0.46220 - acc: 0.7766 -- iter: 0480/1162
[A[ATraining Step: 608  | total loss: [1m[32m0.49148[0m[0m | time: 15.440s
[2K
| RMSProp | epoch: 017 | loss: 0.49148 - acc: 0.7689 -- iter: 0512/1162
[A[ATraining Step: 609  | total loss: [1m[32m0.48431[0m[0m | time: 16.326s
[2K
| RMSProp | epoch: 017 | loss: 0.48431 - acc: 0.7820 -- iter: 0544/1162
[A[ATraining Step: 610  | total loss: [1m[32m0.46737[0m[0m | time: 17.392s
[2K
| RMSProp | epoch: 017 | loss: 0.46737 - acc: 0.7944 -- iter: 0576/1162
[A[ATraining Step: 611  | total loss: [1m[32m0.44940[0m[0m | time: 18.121s
[2K
| RMSProp | epoch: 017 | loss: 0.44940 - acc: 0.8119 -- iter: 0608/1162
[A[ATraining Step: 612  | total loss: [1m[32m0.44805[0m[0m | time: 18.791s
[2K
| RMSProp | epoch: 017 | loss: 0.44805 - acc: 0.8057 -- iter: 0640/1162
[A[ATraining Step: 613  | total loss: [1m[32m0.44791[0m[0m | time: 20.150s
[2K
| RMSProp | epoch: 017 | loss: 0.44791 - acc: 0.8032 -- iter: 0672/1162
[A[ATraining Step: 614  | total loss: [1m[32m0.44622[0m[0m | time: 21.696s
[2K
| RMSProp | epoch: 017 | loss: 0.44622 - acc: 0.8010 -- iter: 0704/1162
[A[ATraining Step: 615  | total loss: [1m[32m0.44814[0m[0m | time: 22.441s
[2K
| RMSProp | epoch: 017 | loss: 0.44814 - acc: 0.7991 -- iter: 0736/1162
[A[ATraining Step: 616  | total loss: [1m[32m0.43834[0m[0m | time: 23.128s
[2K
| RMSProp | epoch: 017 | loss: 0.43834 - acc: 0.8067 -- iter: 0768/1162
[A[ATraining Step: 617  | total loss: [1m[32m0.42050[0m[0m | time: 23.804s
[2K
| RMSProp | epoch: 017 | loss: 0.42050 - acc: 0.8166 -- iter: 0800/1162
[A[ATraining Step: 618  | total loss: [1m[32m0.40705[0m[0m | time: 24.468s
[2K
| RMSProp | epoch: 017 | loss: 0.40705 - acc: 0.8287 -- iter: 0832/1162
[A[ATraining Step: 619  | total loss: [1m[32m0.39902[0m[0m | time: 25.176s
[2K
| RMSProp | epoch: 017 | loss: 0.39902 - acc: 0.8302 -- iter: 0864/1162
[A[ATraining Step: 620  | total loss: [1m[32m0.38354[0m[0m | time: 25.838s
[2K
| RMSProp | epoch: 017 | loss: 0.38354 - acc: 0.8409 -- iter: 0896/1162
[A[ATraining Step: 621  | total loss: [1m[32m0.38029[0m[0m | time: 26.534s
[2K
| RMSProp | epoch: 017 | loss: 0.38029 - acc: 0.8381 -- iter: 0928/1162
[A[ATraining Step: 622  | total loss: [1m[32m0.37513[0m[0m | time: 27.214s
[2K
| RMSProp | epoch: 017 | loss: 0.37513 - acc: 0.8387 -- iter: 0960/1162
[A[ATraining Step: 623  | total loss: [1m[32m0.36903[0m[0m | time: 27.939s
[2K
| RMSProp | epoch: 017 | loss: 0.36903 - acc: 0.8423 -- iter: 0992/1162
[A[ATraining Step: 624  | total loss: [1m[32m0.40080[0m[0m | time: 28.640s
[2K
| RMSProp | epoch: 017 | loss: 0.40080 - acc: 0.8268 -- iter: 1024/1162
[A[ATraining Step: 625  | total loss: [1m[32m0.40798[0m[0m | time: 30.175s
[2K
| RMSProp | epoch: 017 | loss: 0.40798 - acc: 0.8191 -- iter: 1056/1162
[A[ATraining Step: 626  | total loss: [1m[32m0.42849[0m[0m | time: 31.581s
[2K
| RMSProp | epoch: 017 | loss: 0.42849 - acc: 0.8091 -- iter: 1088/1162
[A[ATraining Step: 627  | total loss: [1m[32m0.42663[0m[0m | time: 32.660s
[2K
| RMSProp | epoch: 017 | loss: 0.42663 - acc: 0.8094 -- iter: 1120/1162
[A[ATraining Step: 628  | total loss: [1m[32m0.41800[0m[0m | time: 33.614s
[2K
| RMSProp | epoch: 017 | loss: 0.41800 - acc: 0.8129 -- iter: 1152/1162
[A[ATraining Step: 629  | total loss: [1m[32m0.42098[0m[0m | time: 36.972s
[2K
| RMSProp | epoch: 017 | loss: 0.42098 - acc: 0.8066 | val_loss: 0.42214 - val_acc: 0.8242 -- iter: 1162/1162
--
Training Step: 630  | total loss: [1m[32m0.41037[0m[0m | time: 1.024s
[2K
| RMSProp | epoch: 018 | loss: 0.41037 - acc: 0.8165 -- iter: 0032/1162
[A[ATraining Step: 631  | total loss: [1m[32m0.41727[0m[0m | time: 2.125s
[2K
| RMSProp | epoch: 018 | loss: 0.41727 - acc: 0.8161 -- iter: 0064/1162
[A[ATraining Step: 632  | total loss: [1m[32m0.43440[0m[0m | time: 3.229s
[2K
| RMSProp | epoch: 018 | loss: 0.43440 - acc: 0.8033 -- iter: 0096/1162
[A[ATraining Step: 633  | total loss: [1m[32m0.42974[0m[0m | time: 4.412s
[2K
| RMSProp | epoch: 018 | loss: 0.42974 - acc: 0.8073 -- iter: 0128/1162
[A[ATraining Step: 634  | total loss: [1m[32m0.43131[0m[0m | time: 5.483s
[2K
| RMSProp | epoch: 018 | loss: 0.43131 - acc: 0.8078 -- iter: 0160/1162
[A[ATraining Step: 635  | total loss: [1m[32m0.42123[0m[0m | time: 6.502s
[2K
| RMSProp | epoch: 018 | loss: 0.42123 - acc: 0.8083 -- iter: 0192/1162
[A[ATraining Step: 636  | total loss: [1m[32m0.40187[0m[0m | time: 7.991s
[2K
| RMSProp | epoch: 018 | loss: 0.40187 - acc: 0.8212 -- iter: 0224/1162
[A[ATraining Step: 637  | total loss: [1m[32m0.39757[0m[0m | time: 9.383s
[2K
| RMSProp | epoch: 018 | loss: 0.39757 - acc: 0.8266 -- iter: 0256/1162
[A[ATraining Step: 638  | total loss: [1m[32m0.39448[0m[0m | time: 10.392s
[2K
| RMSProp | epoch: 018 | loss: 0.39448 - acc: 0.8221 -- iter: 0288/1162
[A[ATraining Step: 639  | total loss: [1m[32m0.40303[0m[0m | time: 11.304s
[2K
| RMSProp | epoch: 018 | loss: 0.40303 - acc: 0.8211 -- iter: 0320/1162
[A[ATraining Step: 640  | total loss: [1m[32m0.39946[0m[0m | time: 12.333s
[2K
| RMSProp | epoch: 018 | loss: 0.39946 - acc: 0.8234 -- iter: 0352/1162
[A[ATraining Step: 641  | total loss: [1m[32m0.39123[0m[0m | time: 13.411s
[2K
| RMSProp | epoch: 018 | loss: 0.39123 - acc: 0.8348 -- iter: 0384/1162
[A[ATraining Step: 642  | total loss: [1m[32m0.38753[0m[0m | time: 14.650s
[2K
| RMSProp | epoch: 018 | loss: 0.38753 - acc: 0.8388 -- iter: 0416/1162
[A[ATraining Step: 643  | total loss: [1m[32m0.38047[0m[0m | time: 15.801s
[2K
| RMSProp | epoch: 018 | loss: 0.38047 - acc: 0.8456 -- iter: 0448/1162
[A[ATraining Step: 644  | total loss: [1m[32m0.37359[0m[0m | time: 16.690s
[2K
| RMSProp | epoch: 018 | loss: 0.37359 - acc: 0.8485 -- iter: 0480/1162
[A[ATraining Step: 645  | total loss: [1m[32m0.37685[0m[0m | time: 17.207s
[2K
| RMSProp | epoch: 018 | loss: 0.37685 - acc: 0.8449 -- iter: 0512/1162
[A[ATraining Step: 646  | total loss: [1m[32m0.39308[0m[0m | time: 17.766s
[2K
| RMSProp | epoch: 018 | loss: 0.39308 - acc: 0.8404 -- iter: 0544/1162
[A[ATraining Step: 647  | total loss: [1m[32m0.39999[0m[0m | time: 19.202s
[2K
| RMSProp | epoch: 018 | loss: 0.39999 - acc: 0.8364 -- iter: 0576/1162
[A[ATraining Step: 648  | total loss: [1m[32m0.40609[0m[0m | time: 20.272s
[2K
| RMSProp | epoch: 018 | loss: 0.40609 - acc: 0.8340 -- iter: 0608/1162
[A[ATraining Step: 649  | total loss: [1m[32m0.40866[0m[0m | time: 21.192s
[2K
| RMSProp | epoch: 018 | loss: 0.40866 - acc: 0.8318 -- iter: 0640/1162
[A[ATraining Step: 650  | total loss: [1m[32m0.38791[0m[0m | time: 22.263s
[2K
| RMSProp | epoch: 018 | loss: 0.38791 - acc: 0.8424 -- iter: 0672/1162
[A[ATraining Step: 651  | total loss: [1m[32m0.38596[0m[0m | time: 23.313s
[2K
| RMSProp | epoch: 018 | loss: 0.38596 - acc: 0.8394 -- iter: 0704/1162
[A[ATraining Step: 652  | total loss: [1m[32m0.39952[0m[0m | time: 24.340s
[2K
| RMSProp | epoch: 018 | loss: 0.39952 - acc: 0.8336 -- iter: 0736/1162
[A[ATraining Step: 653  | total loss: [1m[32m0.38501[0m[0m | time: 25.512s
[2K
| RMSProp | epoch: 018 | loss: 0.38501 - acc: 0.8409 -- iter: 0768/1162
[A[ATraining Step: 654  | total loss: [1m[32m0.39525[0m[0m | time: 26.618s
[2K
| RMSProp | epoch: 018 | loss: 0.39525 - acc: 0.8286 -- iter: 0800/1162
[A[ATraining Step: 655  | total loss: [1m[32m0.43163[0m[0m | time: 28.046s
[2K
| RMSProp | epoch: 018 | loss: 0.43163 - acc: 0.8145 -- iter: 0832/1162
[A[ATraining Step: 656  | total loss: [1m[32m0.41930[0m[0m | time: 29.382s
[2K
| RMSProp | epoch: 018 | loss: 0.41930 - acc: 0.8206 -- iter: 0864/1162
[A[ATraining Step: 657  | total loss: [1m[32m0.40455[0m[0m | time: 30.459s
[2K
| RMSProp | epoch: 018 | loss: 0.40455 - acc: 0.8323 -- iter: 0896/1162
[A[ATraining Step: 658  | total loss: [1m[32m0.39046[0m[0m | time: 31.482s
[2K
| RMSProp | epoch: 018 | loss: 0.39046 - acc: 0.8397 -- iter: 0928/1162
[A[ATraining Step: 659  | total loss: [1m[32m0.36518[0m[0m | time: 32.508s
[2K
| RMSProp | epoch: 018 | loss: 0.36518 - acc: 0.8526 -- iter: 0960/1162
[A[ATraining Step: 660  | total loss: [1m[32m0.35871[0m[0m | time: 33.649s
[2K
| RMSProp | epoch: 018 | loss: 0.35871 - acc: 0.8548 -- iter: 0992/1162
[A[ATraining Step: 661  | total loss: [1m[32m0.35150[0m[0m | time: 34.725s
[2K
| RMSProp | epoch: 018 | loss: 0.35150 - acc: 0.8537 -- iter: 1024/1162
[A[ATraining Step: 662  | total loss: [1m[32m0.34994[0m[0m | time: 35.744s
[2K
| RMSProp | epoch: 018 | loss: 0.34994 - acc: 0.8558 -- iter: 1056/1162
[A[ATraining Step: 663  | total loss: [1m[32m0.34567[0m[0m | time: 37.086s
[2K
| RMSProp | epoch: 018 | loss: 0.34567 - acc: 0.8609 -- iter: 1088/1162
[A[ATraining Step: 664  | total loss: [1m[32m0.32640[0m[0m | time: 38.524s
[2K
| RMSProp | epoch: 018 | loss: 0.32640 - acc: 0.8717 -- iter: 1120/1162
[A[ATraining Step: 665  | total loss: [1m[32m0.32981[0m[0m | time: 39.429s
[2K
| RMSProp | epoch: 018 | loss: 0.32981 - acc: 0.8658 -- iter: 1152/1162
[A[ATraining Step: 666  | total loss: [1m[32m0.39537[0m[0m | time: 42.596s
[2K
| RMSProp | epoch: 018 | loss: 0.39537 - acc: 0.8354 | val_loss: 0.40703 - val_acc: 0.8324 -- iter: 1162/1162
--
Training Step: 667  | total loss: [1m[32m0.37855[0m[0m | time: 0.978s
[2K
| RMSProp | epoch: 019 | loss: 0.37855 - acc: 0.8456 -- iter: 0032/1162
[A[ATraining Step: 668  | total loss: [1m[32m0.36454[0m[0m | time: 2.052s
[2K
| RMSProp | epoch: 019 | loss: 0.36454 - acc: 0.8517 -- iter: 0064/1162
[A[ATraining Step: 669  | total loss: [1m[32m0.36139[0m[0m | time: 3.108s
[2K
| RMSProp | epoch: 019 | loss: 0.36139 - acc: 0.8478 -- iter: 0096/1162
[A[ATraining Step: 670  | total loss: [1m[32m0.37764[0m[0m | time: 4.117s
[2K
| RMSProp | epoch: 019 | loss: 0.37764 - acc: 0.8442 -- iter: 0128/1162
[A[ATraining Step: 671  | total loss: [1m[32m0.37707[0m[0m | time: 5.275s
[2K
| RMSProp | epoch: 019 | loss: 0.37707 - acc: 0.8442 -- iter: 0160/1162
[A[ATraining Step: 672  | total loss: [1m[32m0.36272[0m[0m | time: 6.354s
[2K
| RMSProp | epoch: 019 | loss: 0.36272 - acc: 0.8504 -- iter: 0192/1162
[A[ATraining Step: 673  | total loss: [1m[32m0.36315[0m[0m | time: 7.405s
[2K
| RMSProp | epoch: 019 | loss: 0.36315 - acc: 0.8497 -- iter: 0224/1162
[A[ATraining Step: 674  | total loss: [1m[32m0.40224[0m[0m | time: 8.833s
[2K
| RMSProp | epoch: 019 | loss: 0.40224 - acc: 0.8273 -- iter: 0256/1162
[A[ATraining Step: 675  | total loss: [1m[32m0.39478[0m[0m | time: 10.266s
[2K
| RMSProp | epoch: 019 | loss: 0.39478 - acc: 0.8289 -- iter: 0288/1162
[A[ATraining Step: 676  | total loss: [1m[32m0.38294[0m[0m | time: 11.366s
[2K
| RMSProp | epoch: 019 | loss: 0.38294 - acc: 0.8335 -- iter: 0320/1162
[A[ATraining Step: 677  | total loss: [1m[32m0.38345[0m[0m | time: 12.267s
[2K
| RMSProp | epoch: 019 | loss: 0.38345 - acc: 0.8314 -- iter: 0352/1162
[A[ATraining Step: 678  | total loss: [1m[32m0.37405[0m[0m | time: 13.284s
[2K
| RMSProp | epoch: 019 | loss: 0.37405 - acc: 0.8295 -- iter: 0384/1162
[A[ATraining Step: 679  | total loss: [1m[32m0.36362[0m[0m | time: 14.251s
[2K
| RMSProp | epoch: 019 | loss: 0.36362 - acc: 0.8372 -- iter: 0416/1162
[A[ATraining Step: 680  | total loss: [1m[32m0.36035[0m[0m | time: 15.329s
[2K
| RMSProp | epoch: 019 | loss: 0.36035 - acc: 0.8379 -- iter: 0448/1162
[A[ATraining Step: 681  | total loss: [1m[32m0.40205[0m[0m | time: 16.496s
[2K
| RMSProp | epoch: 019 | loss: 0.40205 - acc: 0.8228 -- iter: 0480/1162
[A[ATraining Step: 682  | total loss: [1m[32m0.39960[0m[0m | time: 17.549s
[2K
| RMSProp | epoch: 019 | loss: 0.39960 - acc: 0.8280 -- iter: 0512/1162
[A[ATraining Step: 683  | total loss: [1m[32m0.37806[0m[0m | time: 17.876s
[2K
| RMSProp | epoch: 019 | loss: 0.37806 - acc: 0.8421 -- iter: 0544/1162
[A[ATraining Step: 684  | total loss: [1m[32m0.35021[0m[0m | time: 18.425s
[2K
| RMSProp | epoch: 019 | loss: 0.35021 - acc: 0.8579 -- iter: 0576/1162
[A[ATraining Step: 685  | total loss: [1m[32m0.32049[0m[0m | time: 19.923s
[2K
| RMSProp | epoch: 019 | loss: 0.32049 - acc: 0.8721 -- iter: 0608/1162
[A[ATraining Step: 686  | total loss: [1m[32m0.32167[0m[0m | time: 21.257s
[2K
| RMSProp | epoch: 019 | loss: 0.32167 - acc: 0.8724 -- iter: 0640/1162
[A[ATraining Step: 687  | total loss: [1m[32m0.33923[0m[0m | time: 22.174s
[2K
| RMSProp | epoch: 019 | loss: 0.33923 - acc: 0.8633 -- iter: 0672/1162
[A[ATraining Step: 688  | total loss: [1m[32m0.35616[0m[0m | time: 23.108s
[2K
| RMSProp | epoch: 019 | loss: 0.35616 - acc: 0.8582 -- iter: 0704/1162
[A[ATraining Step: 689  | total loss: [1m[32m0.35151[0m[0m | time: 24.086s
[2K
| RMSProp | epoch: 019 | loss: 0.35151 - acc: 0.8599 -- iter: 0736/1162
[A[ATraining Step: 690  | total loss: [1m[32m0.34565[0m[0m | time: 25.099s
[2K
| RMSProp | epoch: 019 | loss: 0.34565 - acc: 0.8676 -- iter: 0768/1162
[A[ATraining Step: 691  | total loss: [1m[32m0.33243[0m[0m | time: 26.272s
[2K
| RMSProp | epoch: 019 | loss: 0.33243 - acc: 0.8715 -- iter: 0800/1162
[A[ATraining Step: 692  | total loss: [1m[32m0.31467[0m[0m | time: 27.306s
[2K
| RMSProp | epoch: 019 | loss: 0.31467 - acc: 0.8812 -- iter: 0832/1162
[A[ATraining Step: 693  | total loss: [1m[32m0.32104[0m[0m | time: 28.149s
[2K
| RMSProp | epoch: 019 | loss: 0.32104 - acc: 0.8806 -- iter: 0864/1162
[A[ATraining Step: 694  | total loss: [1m[32m0.32310[0m[0m | time: 29.462s
[2K
| RMSProp | epoch: 019 | loss: 0.32310 - acc: 0.8769 -- iter: 0896/1162
[A[ATraining Step: 695  | total loss: [1m[32m0.33617[0m[0m | time: 30.765s
[2K
| RMSProp | epoch: 019 | loss: 0.33617 - acc: 0.8642 -- iter: 0928/1162
[A[ATraining Step: 696  | total loss: [1m[32m0.32888[0m[0m | time: 32.128s
[2K
| RMSProp | epoch: 019 | loss: 0.32888 - acc: 0.8653 -- iter: 0960/1162
[A[ATraining Step: 697  | total loss: [1m[32m0.32439[0m[0m | time: 33.054s
[2K
| RMSProp | epoch: 019 | loss: 0.32439 - acc: 0.8694 -- iter: 0992/1162
[A[ATraining Step: 698  | total loss: [1m[32m0.33359[0m[0m | time: 34.043s
[2K
| RMSProp | epoch: 019 | loss: 0.33359 - acc: 0.8637 -- iter: 1024/1162
[A[ATraining Step: 699  | total loss: [1m[32m0.33532[0m[0m | time: 35.092s
[2K
| RMSProp | epoch: 019 | loss: 0.33532 - acc: 0.8680 -- iter: 1056/1162
[A[ATraining Step: 700  | total loss: [1m[32m0.32928[0m[0m | time: 36.067s
[2K
| RMSProp | epoch: 019 | loss: 0.32928 - acc: 0.8687 -- iter: 1088/1162
[A[ATraining Step: 701  | total loss: [1m[32m0.32348[0m[0m | time: 37.171s
[2K
| RMSProp | epoch: 019 | loss: 0.32348 - acc: 0.8693 -- iter: 1120/1162
[A[ATraining Step: 702  | total loss: [1m[32m0.30728[0m[0m | time: 38.324s
[2K
| RMSProp | epoch: 019 | loss: 0.30728 - acc: 0.8761 -- iter: 1152/1162
[A[ATraining Step: 703  | total loss: [1m[32m0.31493[0m[0m | time: 41.894s
[2K
| RMSProp | epoch: 019 | loss: 0.31493 - acc: 0.8729 | val_loss: 0.43442 - val_acc: 0.8077 -- iter: 1162/1162
--
Training Step: 704  | total loss: [1m[32m0.29975[0m[0m | time: 1.191s
[2K
| RMSProp | epoch: 020 | loss: 0.29975 - acc: 0.8825 -- iter: 0032/1162
[A[ATraining Step: 705  | total loss: [1m[32m0.30007[0m[0m | time: 2.302s
[2K
| RMSProp | epoch: 020 | loss: 0.30007 - acc: 0.8786 -- iter: 0064/1162
[A[ATraining Step: 706  | total loss: [1m[32m0.30401[0m[0m | time: 3.344s
[2K
| RMSProp | epoch: 020 | loss: 0.30401 - acc: 0.8751 -- iter: 0096/1162
[A[ATraining Step: 707  | total loss: [1m[32m0.33911[0m[0m | time: 4.776s
[2K
| RMSProp | epoch: 020 | loss: 0.33911 - acc: 0.8595 -- iter: 0128/1162
[A[ATraining Step: 708  | total loss: [1m[32m0.33428[0m[0m | time: 6.234s
[2K
| RMSProp | epoch: 020 | loss: 0.33428 - acc: 0.8610 -- iter: 0160/1162
[A[ATraining Step: 709  | total loss: [1m[32m0.32135[0m[0m | time: 7.552s
[2K
| RMSProp | epoch: 020 | loss: 0.32135 - acc: 0.8656 -- iter: 0192/1162
[A[ATraining Step: 710  | total loss: [1m[32m0.29866[0m[0m | time: 8.503s
[2K
| RMSProp | epoch: 020 | loss: 0.29866 - acc: 0.8790 -- iter: 0224/1162
[A[ATraining Step: 711  | total loss: [1m[32m0.30707[0m[0m | time: 9.512s
[2K
| RMSProp | epoch: 020 | loss: 0.30707 - acc: 0.8786 -- iter: 0256/1162
[A[ATraining Step: 712  | total loss: [1m[32m0.29418[0m[0m | time: 10.506s
[2K
| RMSProp | epoch: 020 | loss: 0.29418 - acc: 0.8876 -- iter: 0288/1162
[A[ATraining Step: 713  | total loss: [1m[32m0.29155[0m[0m | time: 11.584s
[2K
| RMSProp | epoch: 020 | loss: 0.29155 - acc: 0.8864 -- iter: 0320/1162
[A[ATraining Step: 714  | total loss: [1m[32m0.30681[0m[0m | time: 12.793s
[2K
| RMSProp | epoch: 020 | loss: 0.30681 - acc: 0.8727 -- iter: 0352/1162
[A[ATraining Step: 715  | total loss: [1m[32m0.30282[0m[0m | time: 13.843s
[2K
| RMSProp | epoch: 020 | loss: 0.30282 - acc: 0.8761 -- iter: 0384/1162
[A[ATraining Step: 716  | total loss: [1m[32m0.29929[0m[0m | time: 15.029s
[2K
| RMSProp | epoch: 020 | loss: 0.29929 - acc: 0.8760 -- iter: 0416/1162
[A[ATraining Step: 717  | total loss: [1m[32m0.31006[0m[0m | time: 16.511s
[2K
| RMSProp | epoch: 020 | loss: 0.31006 - acc: 0.8727 -- iter: 0448/1162
[A[ATraining Step: 718  | total loss: [1m[32m0.31331[0m[0m | time: 17.873s
[2K
| RMSProp | epoch: 020 | loss: 0.31331 - acc: 0.8698 -- iter: 0480/1162
[A[ATraining Step: 719  | total loss: [1m[32m0.32833[0m[0m | time: 18.672s
[2K
| RMSProp | epoch: 020 | loss: 0.32833 - acc: 0.8516 -- iter: 0512/1162
[A[ATraining Step: 720  | total loss: [1m[32m0.32104[0m[0m | time: 19.676s
[2K
| RMSProp | epoch: 020 | loss: 0.32104 - acc: 0.8508 -- iter: 0544/1162
[A[ATraining Step: 721  | total loss: [1m[32m0.31364[0m[0m | time: 20.053s
[2K
| RMSProp | epoch: 020 | loss: 0.31364 - acc: 0.8595 -- iter: 0576/1162
[A[ATraining Step: 722  | total loss: [1m[32m0.31891[0m[0m | time: 20.420s
[2K
| RMSProp | epoch: 020 | loss: 0.31891 - acc: 0.8535 -- iter: 0608/1162
[A[ATraining Step: 723  | total loss: [1m[32m0.30021[0m[0m | time: 21.455s
[2K
| RMSProp | epoch: 020 | loss: 0.30021 - acc: 0.8682 -- iter: 0640/1162
[A[ATraining Step: 724  | total loss: [1m[32m0.28794[0m[0m | time: 22.588s
[2K
| RMSProp | epoch: 020 | loss: 0.28794 - acc: 0.8751 -- iter: 0672/1162
[A[ATraining Step: 725  | total loss: [1m[32m0.27797[0m[0m | time: 23.719s
[2K
| RMSProp | epoch: 020 | loss: 0.27797 - acc: 0.8751 -- iter: 0704/1162
[A[ATraining Step: 726  | total loss: [1m[32m0.25696[0m[0m | time: 24.748s
[2K
| RMSProp | epoch: 020 | loss: 0.25696 - acc: 0.8876 -- iter: 0736/1162
[A[ATraining Step: 727  | total loss: [1m[32m0.26521[0m[0m | time: 26.257s
[2K
| RMSProp | epoch: 020 | loss: 0.26521 - acc: 0.8801 -- iter: 0768/1162
[A[ATraining Step: 728  | total loss: [1m[32m0.28743[0m[0m | time: 27.729s
[2K
| RMSProp | epoch: 020 | loss: 0.28743 - acc: 0.8702 -- iter: 0800/1162
[A[ATraining Step: 729  | total loss: [1m[32m0.28457[0m[0m | time: 28.792s
[2K
| RMSProp | epoch: 020 | loss: 0.28457 - acc: 0.8769 -- iter: 0832/1162
[A[ATraining Step: 730  | total loss: [1m[32m0.26527[0m[0m | time: 29.790s
[2K
| RMSProp | epoch: 020 | loss: 0.26527 - acc: 0.8892 -- iter: 0864/1162
[A[ATraining Step: 731  | total loss: [1m[32m0.26223[0m[0m | time: 30.862s
[2K
| RMSProp | epoch: 020 | loss: 0.26223 - acc: 0.8878 -- iter: 0896/1162
[A[ATraining Step: 732  | total loss: [1m[32m0.26583[0m[0m | time: 31.948s
[2K
| RMSProp | epoch: 020 | loss: 0.26583 - acc: 0.8897 -- iter: 0928/1162
[A[ATraining Step: 733  | total loss: [1m[32m0.25910[0m[0m | time: 33.098s
[2K
| RMSProp | epoch: 020 | loss: 0.25910 - acc: 0.8944 -- iter: 0960/1162
[A[ATraining Step: 734  | total loss: [1m[32m0.25800[0m[0m | time: 34.230s
[2K
| RMSProp | epoch: 020 | loss: 0.25800 - acc: 0.8956 -- iter: 0992/1162
[A[ATraining Step: 735  | total loss: [1m[32m0.27990[0m[0m | time: 35.222s
[2K
| RMSProp | epoch: 020 | loss: 0.27990 - acc: 0.8873 -- iter: 1024/1162
[A[ATraining Step: 736  | total loss: [1m[32m0.27247[0m[0m | time: 36.602s
[2K
| RMSProp | epoch: 020 | loss: 0.27247 - acc: 0.8923 -- iter: 1056/1162
[A[ATraining Step: 737  | total loss: [1m[32m0.26878[0m[0m | time: 38.022s
[2K
| RMSProp | epoch: 020 | loss: 0.26878 - acc: 0.8937 -- iter: 1088/1162
[A[ATraining Step: 738  | total loss: [1m[32m0.27483[0m[0m | time: 39.151s
[2K
| RMSProp | epoch: 020 | loss: 0.27483 - acc: 0.8856 -- iter: 1120/1162
[A[ATraining Step: 739  | total loss: [1m[32m0.30762[0m[0m | time: 40.148s
[2K
| RMSProp | epoch: 020 | loss: 0.30762 - acc: 0.8689 -- iter: 1152/1162
[A[ATraining Step: 740  | total loss: [1m[32m0.29875[0m[0m | time: 43.487s
[2K
| RMSProp | epoch: 020 | loss: 0.29875 - acc: 0.8758 | val_loss: 0.43702 - val_acc: 0.8022 -- iter: 1162/1162
--
Training Step: 741  | total loss: [1m[32m0.30308[0m[0m | time: 1.184s
[2K
| RMSProp | epoch: 021 | loss: 0.30308 - acc: 0.8757 -- iter: 0032/1162
[A[ATraining Step: 742  | total loss: [1m[32m0.29117[0m[0m | time: 2.251s
[2K
| RMSProp | epoch: 021 | loss: 0.29117 - acc: 0.8788 -- iter: 0064/1162
[A[ATraining Step: 743  | total loss: [1m[32m0.28518[0m[0m | time: 3.266s
[2K
| RMSProp | epoch: 021 | loss: 0.28518 - acc: 0.8846 -- iter: 0096/1162
[A[ATraining Step: 744  | total loss: [1m[32m0.27456[0m[0m | time: 4.383s
[2K
| RMSProp | epoch: 021 | loss: 0.27456 - acc: 0.8899 -- iter: 0128/1162
[A[ATraining Step: 745  | total loss: [1m[32m0.27082[0m[0m | time: 5.606s
[2K
| RMSProp | epoch: 021 | loss: 0.27082 - acc: 0.8915 -- iter: 0160/1162
[A[ATraining Step: 746  | total loss: [1m[32m0.28079[0m[0m | time: 6.729s
[2K
| RMSProp | epoch: 021 | loss: 0.28079 - acc: 0.8836 -- iter: 0192/1162
[A[ATraining Step: 747  | total loss: [1m[32m0.26703[0m[0m | time: 7.626s
[2K
| RMSProp | epoch: 021 | loss: 0.26703 - acc: 0.8890 -- iter: 0224/1162
[A[ATraining Step: 748  | total loss: [1m[32m0.26509[0m[0m | time: 8.305s
[2K
| RMSProp | epoch: 021 | loss: 0.26509 - acc: 0.8908 -- iter: 0256/1162
[A[ATraining Step: 749  | total loss: [1m[32m0.27880[0m[0m | time: 9.006s
[2K
| RMSProp | epoch: 021 | loss: 0.27880 - acc: 0.8892 -- iter: 0288/1162
[A[ATraining Step: 750  | total loss: [1m[32m0.27273[0m[0m | time: 9.686s
[2K
| RMSProp | epoch: 021 | loss: 0.27273 - acc: 0.8878 -- iter: 0320/1162
[A[ATraining Step: 751  | total loss: [1m[32m0.27476[0m[0m | time: 10.362s
[2K
| RMSProp | epoch: 021 | loss: 0.27476 - acc: 0.8896 -- iter: 0352/1162
[A[ATraining Step: 752  | total loss: [1m[32m0.27510[0m[0m | time: 10.989s
[2K
| RMSProp | epoch: 021 | loss: 0.27510 - acc: 0.8881 -- iter: 0384/1162
[A[ATraining Step: 753  | total loss: [1m[32m0.26212[0m[0m | time: 11.672s
[2K
| RMSProp | epoch: 021 | loss: 0.26212 - acc: 0.8962 -- iter: 0416/1162
[A[ATraining Step: 754  | total loss: [1m[32m0.25006[0m[0m | time: 12.326s
[2K
| RMSProp | epoch: 021 | loss: 0.25006 - acc: 0.9003 -- iter: 0448/1162
[A[ATraining Step: 755  | total loss: [1m[32m0.26444[0m[0m | time: 13.006s
[2K
| RMSProp | epoch: 021 | loss: 0.26444 - acc: 0.8978 -- iter: 0480/1162
[A[ATraining Step: 756  | total loss: [1m[32m0.26351[0m[0m | time: 13.678s
[2K
| RMSProp | epoch: 021 | loss: 0.26351 - acc: 0.8955 -- iter: 0512/1162
[A[ATraining Step: 757  | total loss: [1m[32m0.26627[0m[0m | time: 14.375s
[2K
| RMSProp | epoch: 021 | loss: 0.26627 - acc: 0.8935 -- iter: 0544/1162
[A[ATraining Step: 758  | total loss: [1m[32m0.25895[0m[0m | time: 15.016s
[2K
| RMSProp | epoch: 021 | loss: 0.25895 - acc: 0.8979 -- iter: 0576/1162
[A[ATraining Step: 759  | total loss: [1m[32m0.25414[0m[0m | time: 15.252s
[2K
| RMSProp | epoch: 021 | loss: 0.25414 - acc: 0.9018 -- iter: 0608/1162
[A[ATraining Step: 760  | total loss: [1m[32m0.24287[0m[0m | time: 15.497s
[2K
| RMSProp | epoch: 021 | loss: 0.24287 - acc: 0.9117 -- iter: 0640/1162
[A[ATraining Step: 761  | total loss: [1m[32m0.22392[0m[0m | time: 16.187s
[2K
| RMSProp | epoch: 021 | loss: 0.22392 - acc: 0.9205 -- iter: 0672/1162
[A[ATraining Step: 762  | total loss: [1m[32m0.21183[0m[0m | time: 16.842s
[2K
| RMSProp | epoch: 021 | loss: 0.21183 - acc: 0.9253 -- iter: 0704/1162
[A[ATraining Step: 763  | total loss: [1m[32m0.20730[0m[0m | time: 17.486s
[2K
| RMSProp | epoch: 021 | loss: 0.20730 - acc: 0.9265 -- iter: 0736/1162
[A[ATraining Step: 764  | total loss: [1m[32m0.20268[0m[0m | time: 18.139s
[2K
| RMSProp | epoch: 021 | loss: 0.20268 - acc: 0.9214 -- iter: 0768/1162
[A[ATraining Step: 765  | total loss: [1m[32m0.19670[0m[0m | time: 18.812s
[2K
| RMSProp | epoch: 021 | loss: 0.19670 - acc: 0.9261 -- iter: 0800/1162
[A[ATraining Step: 766  | total loss: [1m[32m0.20856[0m[0m | time: 19.467s
[2K
| RMSProp | epoch: 021 | loss: 0.20856 - acc: 0.9210 -- iter: 0832/1162
[A[ATraining Step: 767  | total loss: [1m[32m0.23351[0m[0m | time: 20.126s
[2K
| RMSProp | epoch: 021 | loss: 0.23351 - acc: 0.9102 -- iter: 0864/1162
[A[ATraining Step: 768  | total loss: [1m[32m0.22523[0m[0m | time: 20.830s
[2K
| RMSProp | epoch: 021 | loss: 0.22523 - acc: 0.9160 -- iter: 0896/1162
[A[ATraining Step: 769  | total loss: [1m[32m0.21335[0m[0m | time: 21.506s
[2K
| RMSProp | epoch: 021 | loss: 0.21335 - acc: 0.9213 -- iter: 0928/1162
[A[ATraining Step: 770  | total loss: [1m[32m0.21902[0m[0m | time: 22.175s
[2K
| RMSProp | epoch: 021 | loss: 0.21902 - acc: 0.9198 -- iter: 0960/1162
[A[ATraining Step: 771  | total loss: [1m[32m0.21339[0m[0m | time: 22.852s
[2K
| RMSProp | epoch: 021 | loss: 0.21339 - acc: 0.9216 -- iter: 0992/1162
[A[ATraining Step: 772  | total loss: [1m[32m0.21483[0m[0m | time: 23.526s
[2K
| RMSProp | epoch: 021 | loss: 0.21483 - acc: 0.9200 -- iter: 1024/1162
[A[ATraining Step: 773  | total loss: [1m[32m0.21479[0m[0m | time: 24.214s
[2K
| RMSProp | epoch: 021 | loss: 0.21479 - acc: 0.9218 -- iter: 1056/1162
[A[ATraining Step: 774  | total loss: [1m[32m0.20660[0m[0m | time: 24.874s
[2K
| RMSProp | epoch: 021 | loss: 0.20660 - acc: 0.9265 -- iter: 1088/1162
[A[ATraining Step: 775  | total loss: [1m[32m0.19457[0m[0m | time: 25.532s
[2K
| RMSProp | epoch: 021 | loss: 0.19457 - acc: 0.9307 -- iter: 1120/1162
[A[ATraining Step: 776  | total loss: [1m[32m0.20865[0m[0m | time: 26.219s
[2K
| RMSProp | epoch: 021 | loss: 0.20865 - acc: 0.9189 -- iter: 1152/1162
[A[ATraining Step: 777  | total loss: [1m[32m0.24486[0m[0m | time: 28.609s
[2K
| RMSProp | epoch: 021 | loss: 0.24486 - acc: 0.8957 | val_loss: 0.62527 - val_acc: 0.7500 -- iter: 1162/1162
--
Training Step: 778  | total loss: [1m[32m0.23665[0m[0m | time: 0.960s
[2K
| RMSProp | epoch: 022 | loss: 0.23665 - acc: 0.8999 -- iter: 0032/1162
[A[ATraining Step: 779  | total loss: [1m[32m0.23169[0m[0m | time: 2.032s
[2K
| RMSProp | epoch: 022 | loss: 0.23169 - acc: 0.9037 -- iter: 0064/1162
[A[ATraining Step: 780  | total loss: [1m[32m0.21744[0m[0m | time: 3.060s
[2K
| RMSProp | epoch: 022 | loss: 0.21744 - acc: 0.9102 -- iter: 0096/1162
[A[ATraining Step: 781  | total loss: [1m[32m0.21522[0m[0m | time: 4.087s
[2K
| RMSProp | epoch: 022 | loss: 0.21522 - acc: 0.9129 -- iter: 0128/1162
[A[ATraining Step: 782  | total loss: [1m[32m0.22050[0m[0m | time: 5.181s
[2K
| RMSProp | epoch: 022 | loss: 0.22050 - acc: 0.9091 -- iter: 0160/1162
[A[ATraining Step: 783  | total loss: [1m[32m0.25017[0m[0m | time: 6.321s
[2K
| RMSProp | epoch: 022 | loss: 0.25017 - acc: 0.8963 -- iter: 0192/1162
[A[ATraining Step: 784  | total loss: [1m[32m0.24112[0m[0m | time: 7.494s
[2K
| RMSProp | epoch: 022 | loss: 0.24112 - acc: 0.9036 -- iter: 0224/1162
[A[ATraining Step: 785  | total loss: [1m[32m0.22453[0m[0m | time: 8.954s
[2K
| RMSProp | epoch: 022 | loss: 0.22453 - acc: 0.9132 -- iter: 0256/1162
[A[ATraining Step: 786  | total loss: [1m[32m0.21358[0m[0m | time: 10.312s
[2K
| RMSProp | epoch: 022 | loss: 0.21358 - acc: 0.9125 -- iter: 0288/1162
[A[ATraining Step: 787  | total loss: [1m[32m0.20074[0m[0m | time: 11.444s
[2K
| RMSProp | epoch: 022 | loss: 0.20074 - acc: 0.9181 -- iter: 0320/1162
[A[ATraining Step: 788  | total loss: [1m[32m0.18984[0m[0m | time: 12.443s
[2K
| RMSProp | epoch: 022 | loss: 0.18984 - acc: 0.9232 -- iter: 0352/1162
[A[ATraining Step: 789  | total loss: [1m[32m0.19136[0m[0m | time: 13.438s
[2K
| RMSProp | epoch: 022 | loss: 0.19136 - acc: 0.9246 -- iter: 0384/1162
[A[ATraining Step: 790  | total loss: [1m[32m0.26389[0m[0m | time: 14.456s
[2K
| RMSProp | epoch: 022 | loss: 0.26389 - acc: 0.9103 -- iter: 0416/1162
[A[ATraining Step: 791  | total loss: [1m[32m0.27915[0m[0m | time: 15.559s
[2K
| RMSProp | epoch: 022 | loss: 0.27915 - acc: 0.9036 -- iter: 0448/1162
[A[ATraining Step: 792  | total loss: [1m[32m0.27447[0m[0m | time: 16.772s
[2K
| RMSProp | epoch: 022 | loss: 0.27447 - acc: 0.8977 -- iter: 0480/1162
[A[ATraining Step: 793  | total loss: [1m[32m0.28095[0m[0m | time: 17.753s
[2K
| RMSProp | epoch: 022 | loss: 0.28095 - acc: 0.8923 -- iter: 0512/1162
[A[ATraining Step: 794  | total loss: [1m[32m0.27642[0m[0m | time: 19.317s
[2K
| RMSProp | epoch: 022 | loss: 0.27642 - acc: 0.8968 -- iter: 0544/1162
[A[ATraining Step: 795  | total loss: [1m[32m0.26192[0m[0m | time: 20.702s
[2K
| RMSProp | epoch: 022 | loss: 0.26192 - acc: 0.9009 -- iter: 0576/1162
[A[ATraining Step: 796  | total loss: [1m[32m0.26257[0m[0m | time: 21.754s
[2K
| RMSProp | epoch: 022 | loss: 0.26257 - acc: 0.8983 -- iter: 0608/1162
[A[ATraining Step: 797  | total loss: [1m[32m0.25895[0m[0m | time: 22.064s
[2K
| RMSProp | epoch: 022 | loss: 0.25895 - acc: 0.9022 -- iter: 0640/1162
[A[ATraining Step: 798  | total loss: [1m[32m0.24459[0m[0m | time: 22.416s
[2K
| RMSProp | epoch: 022 | loss: 0.24459 - acc: 0.9120 -- iter: 0672/1162
[A[ATraining Step: 799  | total loss: [1m[32m0.22326[0m[0m | time: 23.484s
[2K
| RMSProp | epoch: 022 | loss: 0.22326 - acc: 0.9208 -- iter: 0704/1162
[A[ATraining Step: 800  | total loss: [1m[32m0.22114[0m[0m | time: 26.838s
[2K
| RMSProp | epoch: 022 | loss: 0.22114 - acc: 0.9162 | val_loss: 0.36599 - val_acc: 0.8516 -- iter: 0736/1162
--
Training Step: 801  | total loss: [1m[32m0.26912[0m[0m | time: 27.897s
[2K
| RMSProp | epoch: 022 | loss: 0.26912 - acc: 0.8965 -- iter: 0768/1162
[A[ATraining Step: 802  | total loss: [1m[32m0.25278[0m[0m | time: 28.881s
[2K
| RMSProp | epoch: 022 | loss: 0.25278 - acc: 0.9068 -- iter: 0800/1162
[A[ATraining Step: 803  | total loss: [1m[32m0.24958[0m[0m | time: 29.868s
[2K
| RMSProp | epoch: 022 | loss: 0.24958 - acc: 0.9036 -- iter: 0832/1162
[A[ATraining Step: 804  | total loss: [1m[32m0.30212[0m[0m | time: 30.832s
[2K
| RMSProp | epoch: 022 | loss: 0.30212 - acc: 0.8820 -- iter: 0864/1162
[A[ATraining Step: 805  | total loss: [1m[32m0.28938[0m[0m | time: 31.838s
[2K
| RMSProp | epoch: 022 | loss: 0.28938 - acc: 0.8907 -- iter: 0896/1162
[A[ATraining Step: 806  | total loss: [1m[32m0.27776[0m[0m | time: 33.042s
[2K
| RMSProp | epoch: 022 | loss: 0.27776 - acc: 0.8985 -- iter: 0928/1162
[A[ATraining Step: 807  | total loss: [1m[32m0.26405[0m[0m | time: 33.992s
[2K
| RMSProp | epoch: 022 | loss: 0.26405 - acc: 0.9024 -- iter: 0960/1162
[A[ATraining Step: 808  | total loss: [1m[32m0.24695[0m[0m | time: 35.141s
[2K
| RMSProp | epoch: 022 | loss: 0.24695 - acc: 0.9090 -- iter: 0992/1162
[A[ATraining Step: 809  | total loss: [1m[32m0.23247[0m[0m | time: 36.517s
[2K
| RMSProp | epoch: 022 | loss: 0.23247 - acc: 0.9150 -- iter: 1024/1162
[A[ATraining Step: 810  | total loss: [1m[32m0.22400[0m[0m | time: 37.926s
[2K
| RMSProp | epoch: 022 | loss: 0.22400 - acc: 0.9204 -- iter: 1056/1162
[A[ATraining Step: 811  | total loss: [1m[32m0.22935[0m[0m | time: 38.930s
[2K
| RMSProp | epoch: 022 | loss: 0.22935 - acc: 0.9158 -- iter: 1088/1162
[A[ATraining Step: 812  | total loss: [1m[32m0.23352[0m[0m | time: 39.870s
[2K
| RMSProp | epoch: 022 | loss: 0.23352 - acc: 0.9086 -- iter: 1120/1162
[A[ATraining Step: 813  | total loss: [1m[32m0.24218[0m[0m | time: 40.881s
[2K
| RMSProp | epoch: 022 | loss: 0.24218 - acc: 0.9021 -- iter: 1152/1162
[A[ATraining Step: 814  | total loss: [1m[32m0.23215[0m[0m | time: 44.305s
[2K
| RMSProp | epoch: 022 | loss: 0.23215 - acc: 0.9119 | val_loss: 0.37990 - val_acc: 0.8544 -- iter: 1162/1162
--
Training Step: 815  | total loss: [1m[32m0.22753[0m[0m | time: 1.004s
[2K
| RMSProp | epoch: 023 | loss: 0.22753 - acc: 0.9145 -- iter: 0032/1162
[A[ATraining Step: 816  | total loss: [1m[32m0.21899[0m[0m | time: 1.949s
[2K
| RMSProp | epoch: 023 | loss: 0.21899 - acc: 0.9199 -- iter: 0064/1162
[A[ATraining Step: 817  | total loss: [1m[32m0.21213[0m[0m | time: 2.919s
[2K
| RMSProp | epoch: 023 | loss: 0.21213 - acc: 0.9217 -- iter: 0096/1162
[A[ATraining Step: 818  | total loss: [1m[32m0.21066[0m[0m | time: 4.074s
[2K
| RMSProp | epoch: 023 | loss: 0.21066 - acc: 0.9201 -- iter: 0128/1162
[A[ATraining Step: 819  | total loss: [1m[32m0.21158[0m[0m | time: 4.994s
[2K
| RMSProp | epoch: 023 | loss: 0.21158 - acc: 0.9187 -- iter: 0160/1162
[A[ATraining Step: 820  | total loss: [1m[32m0.20895[0m[0m | time: 6.423s
[2K
| RMSProp | epoch: 023 | loss: 0.20895 - acc: 0.9175 -- iter: 0192/1162
[A[ATraining Step: 821  | total loss: [1m[32m0.20730[0m[0m | time: 7.799s
[2K
| RMSProp | epoch: 023 | loss: 0.20730 - acc: 0.9164 -- iter: 0224/1162
[A[ATraining Step: 822  | total loss: [1m[32m0.20170[0m[0m | time: 8.740s
[2K
| RMSProp | epoch: 023 | loss: 0.20170 - acc: 0.9216 -- iter: 0256/1162
[A[ATraining Step: 823  | total loss: [1m[32m0.18578[0m[0m | time: 9.717s
[2K
| RMSProp | epoch: 023 | loss: 0.18578 - acc: 0.9294 -- iter: 0288/1162
[A[ATraining Step: 824  | total loss: [1m[32m0.18046[0m[0m | time: 10.743s
[2K
| RMSProp | epoch: 023 | loss: 0.18046 - acc: 0.9303 -- iter: 0320/1162
[A[ATraining Step: 825  | total loss: [1m[32m0.20051[0m[0m | time: 11.742s
[2K
| RMSProp | epoch: 023 | loss: 0.20051 - acc: 0.9247 -- iter: 0352/1162
[A[ATraining Step: 826  | total loss: [1m[32m0.20413[0m[0m | time: 12.850s
[2K
| RMSProp | epoch: 023 | loss: 0.20413 - acc: 0.9166 -- iter: 0384/1162
[A[ATraining Step: 827  | total loss: [1m[32m0.19859[0m[0m | time: 13.842s
[2K
| RMSProp | epoch: 023 | loss: 0.19859 - acc: 0.9218 -- iter: 0416/1162
[A[ATraining Step: 828  | total loss: [1m[32m0.18984[0m[0m | time: 15.263s
[2K
| RMSProp | epoch: 023 | loss: 0.18984 - acc: 0.9265 -- iter: 0448/1162
[A[ATraining Step: 829  | total loss: [1m[32m0.19418[0m[0m | time: 16.677s
[2K
| RMSProp | epoch: 023 | loss: 0.19418 - acc: 0.9276 -- iter: 0480/1162
[A[ATraining Step: 830  | total loss: [1m[32m0.19579[0m[0m | time: 17.696s
[2K
| RMSProp | epoch: 023 | loss: 0.19579 - acc: 0.9317 -- iter: 0512/1162
[A[ATraining Step: 831  | total loss: [1m[32m0.19841[0m[0m | time: 18.601s
[2K
| RMSProp | epoch: 023 | loss: 0.19841 - acc: 0.9292 -- iter: 0544/1162
[A[ATraining Step: 832  | total loss: [1m[32m0.18718[0m[0m | time: 19.577s
[2K
| RMSProp | epoch: 023 | loss: 0.18718 - acc: 0.9331 -- iter: 0576/1162
[A[ATraining Step: 833  | total loss: [1m[32m0.18228[0m[0m | time: 20.622s
[2K
| RMSProp | epoch: 023 | loss: 0.18228 - acc: 0.9367 -- iter: 0608/1162
[A[ATraining Step: 834  | total loss: [1m[32m0.16749[0m[0m | time: 21.780s
[2K
| RMSProp | epoch: 023 | loss: 0.16749 - acc: 0.9430 -- iter: 0640/1162
[A[ATraining Step: 835  | total loss: [1m[32m0.15524[0m[0m | time: 22.218s
[2K
| RMSProp | epoch: 023 | loss: 0.15524 - acc: 0.9487 -- iter: 0672/1162
[A[ATraining Step: 836  | total loss: [1m[32m0.14287[0m[0m | time: 22.638s
[2K
| RMSProp | epoch: 023 | loss: 0.14287 - acc: 0.9539 -- iter: 0704/1162
[A[ATraining Step: 837  | total loss: [1m[32m0.12987[0m[0m | time: 23.618s
[2K
| RMSProp | epoch: 023 | loss: 0.12987 - acc: 0.9585 -- iter: 0736/1162
[A[ATraining Step: 838  | total loss: [1m[32m0.14551[0m[0m | time: 24.957s
[2K
| RMSProp | epoch: 023 | loss: 0.14551 - acc: 0.9501 -- iter: 0768/1162
[A[ATraining Step: 839  | total loss: [1m[32m0.16420[0m[0m | time: 26.399s
[2K
| RMSProp | epoch: 023 | loss: 0.16420 - acc: 0.9395 -- iter: 0800/1162
[A[ATraining Step: 840  | total loss: [1m[32m0.15701[0m[0m | time: 27.580s
[2K
| RMSProp | epoch: 023 | loss: 0.15701 - acc: 0.9424 -- iter: 0832/1162
[A[ATraining Step: 841  | total loss: [1m[32m0.15928[0m[0m | time: 28.528s
[2K
| RMSProp | epoch: 023 | loss: 0.15928 - acc: 0.9419 -- iter: 0864/1162
[A[ATraining Step: 842  | total loss: [1m[32m0.15164[0m[0m | time: 29.618s
[2K
| RMSProp | epoch: 023 | loss: 0.15164 - acc: 0.9446 -- iter: 0896/1162
[A[ATraining Step: 843  | total loss: [1m[32m0.14353[0m[0m | time: 30.627s
[2K
| RMSProp | epoch: 023 | loss: 0.14353 - acc: 0.9470 -- iter: 0928/1162
[A[ATraining Step: 844  | total loss: [1m[32m0.13502[0m[0m | time: 31.673s
[2K
| RMSProp | epoch: 023 | loss: 0.13502 - acc: 0.9523 -- iter: 0960/1162
[A[ATraining Step: 845  | total loss: [1m[32m0.12465[0m[0m | time: 32.864s
[2K
| RMSProp | epoch: 023 | loss: 0.12465 - acc: 0.9571 -- iter: 0992/1162
[A[ATraining Step: 846  | total loss: [1m[32m0.12069[0m[0m | time: 33.861s
[2K
| RMSProp | epoch: 023 | loss: 0.12069 - acc: 0.9583 -- iter: 1024/1162
[A[ATraining Step: 847  | total loss: [1m[32m0.12519[0m[0m | time: 34.978s
[2K
| RMSProp | epoch: 023 | loss: 0.12519 - acc: 0.9531 -- iter: 1056/1162
[A[ATraining Step: 848  | total loss: [1m[32m0.12074[0m[0m | time: 36.364s
[2K
| RMSProp | epoch: 023 | loss: 0.12074 - acc: 0.9546 -- iter: 1088/1162
[A[ATraining Step: 849  | total loss: [1m[32m0.12803[0m[0m | time: 37.694s
[2K
| RMSProp | epoch: 023 | loss: 0.12803 - acc: 0.9560 -- iter: 1120/1162
[A[ATraining Step: 850  | total loss: [1m[32m0.12337[0m[0m | time: 38.612s
[2K
| RMSProp | epoch: 023 | loss: 0.12337 - acc: 0.9573 -- iter: 1152/1162
[A[ATraining Step: 851  | total loss: [1m[32m0.15347[0m[0m | time: 41.832s
[2K
| RMSProp | epoch: 023 | loss: 0.15347 - acc: 0.9522 | val_loss: 0.35972 - val_acc: 0.8654 -- iter: 1162/1162
--
Training Step: 852  | total loss: [1m[32m0.15727[0m[0m | time: 1.457s
[2K
| RMSProp | epoch: 024 | loss: 0.15727 - acc: 0.9507 -- iter: 0032/1162
[A[ATraining Step: 853  | total loss: [1m[32m0.14543[0m[0m | time: 2.605s
[2K
| RMSProp | epoch: 024 | loss: 0.14543 - acc: 0.9557 -- iter: 0064/1162
[A[ATraining Step: 854  | total loss: [1m[32m0.13599[0m[0m | time: 3.626s
[2K
| RMSProp | epoch: 024 | loss: 0.13599 - acc: 0.9601 -- iter: 0096/1162
[A[ATraining Step: 855  | total loss: [1m[32m0.13572[0m[0m | time: 4.728s
[2K
| RMSProp | epoch: 024 | loss: 0.13572 - acc: 0.9578 -- iter: 0128/1162
[A[ATraining Step: 856  | total loss: [1m[32m0.14502[0m[0m | time: 5.712s
[2K
| RMSProp | epoch: 024 | loss: 0.14502 - acc: 0.9495 -- iter: 0160/1162
[A[ATraining Step: 857  | total loss: [1m[32m0.14391[0m[0m | time: 6.823s
[2K
| RMSProp | epoch: 024 | loss: 0.14391 - acc: 0.9515 -- iter: 0192/1162
[A[ATraining Step: 858  | total loss: [1m[32m0.13992[0m[0m | time: 7.901s
[2K
| RMSProp | epoch: 024 | loss: 0.13992 - acc: 0.9501 -- iter: 0224/1162
[A[ATraining Step: 859  | total loss: [1m[32m0.14262[0m[0m | time: 8.895s
[2K
| RMSProp | epoch: 024 | loss: 0.14262 - acc: 0.9519 -- iter: 0256/1162
[A[ATraining Step: 860  | total loss: [1m[32m0.13151[0m[0m | time: 10.316s
[2K
| RMSProp | epoch: 024 | loss: 0.13151 - acc: 0.9567 -- iter: 0288/1162
[A[ATraining Step: 861  | total loss: [1m[32m0.12589[0m[0m | time: 11.652s
[2K
| RMSProp | epoch: 024 | loss: 0.12589 - acc: 0.9611 -- iter: 0320/1162
[A[ATraining Step: 862  | total loss: [1m[32m0.11854[0m[0m | time: 13.075s
[2K
| RMSProp | epoch: 024 | loss: 0.11854 - acc: 0.9650 -- iter: 0352/1162
[A[ATraining Step: 863  | total loss: [1m[32m0.12953[0m[0m | time: 14.001s
[2K
| RMSProp | epoch: 024 | loss: 0.12953 - acc: 0.9591 -- iter: 0384/1162
[A[ATraining Step: 864  | total loss: [1m[32m0.13336[0m[0m | time: 15.018s
[2K
| RMSProp | epoch: 024 | loss: 0.13336 - acc: 0.9538 -- iter: 0416/1162
[A[ATraining Step: 865  | total loss: [1m[32m0.13403[0m[0m | time: 16.032s
[2K
| RMSProp | epoch: 024 | loss: 0.13403 - acc: 0.9553 -- iter: 0448/1162
[A[ATraining Step: 866  | total loss: [1m[32m0.12618[0m[0m | time: 16.980s
[2K
| RMSProp | epoch: 024 | loss: 0.12618 - acc: 0.9598 -- iter: 0480/1162
[A[ATraining Step: 867  | total loss: [1m[32m0.13327[0m[0m | time: 18.147s
[2K
| RMSProp | epoch: 024 | loss: 0.13327 - acc: 0.9607 -- iter: 0512/1162
[A[ATraining Step: 868  | total loss: [1m[32m0.13818[0m[0m | time: 19.265s
[2K
| RMSProp | epoch: 024 | loss: 0.13818 - acc: 0.9615 -- iter: 0544/1162
[A[ATraining Step: 869  | total loss: [1m[32m0.15108[0m[0m | time: 20.248s
[2K
| RMSProp | epoch: 024 | loss: 0.15108 - acc: 0.9528 -- iter: 0576/1162
[A[ATraining Step: 870  | total loss: [1m[32m0.14695[0m[0m | time: 21.519s
[2K
| RMSProp | epoch: 024 | loss: 0.14695 - acc: 0.9544 -- iter: 0608/1162
[A[ATraining Step: 871  | total loss: [1m[32m0.15826[0m[0m | time: 22.962s
[2K
| RMSProp | epoch: 024 | loss: 0.15826 - acc: 0.9496 -- iter: 0640/1162
[A[ATraining Step: 872  | total loss: [1m[32m0.15618[0m[0m | time: 24.106s
[2K
| RMSProp | epoch: 024 | loss: 0.15618 - acc: 0.9515 -- iter: 0672/1162
[A[ATraining Step: 873  | total loss: [1m[32m0.16048[0m[0m | time: 24.461s
[2K
| RMSProp | epoch: 024 | loss: 0.16048 - acc: 0.9470 -- iter: 0704/1162
[A[ATraining Step: 874  | total loss: [1m[32m0.14548[0m[0m | time: 24.834s
[2K
| RMSProp | epoch: 024 | loss: 0.14548 - acc: 0.9523 -- iter: 0736/1162
[A[ATraining Step: 875  | total loss: [1m[32m0.13179[0m[0m | time: 25.787s
[2K
| RMSProp | epoch: 024 | loss: 0.13179 - acc: 0.9571 -- iter: 0768/1162
[A[ATraining Step: 876  | total loss: [1m[32m0.13485[0m[0m | time: 26.782s
[2K
| RMSProp | epoch: 024 | loss: 0.13485 - acc: 0.9520 -- iter: 0800/1162
[A[ATraining Step: 877  | total loss: [1m[32m0.12520[0m[0m | time: 27.857s
[2K
| RMSProp | epoch: 024 | loss: 0.12520 - acc: 0.9568 -- iter: 0832/1162
[A[ATraining Step: 878  | total loss: [1m[32m0.11941[0m[0m | time: 29.023s
[2K
| RMSProp | epoch: 024 | loss: 0.11941 - acc: 0.9580 -- iter: 0864/1162
[A[ATraining Step: 879  | total loss: [1m[32m0.11020[0m[0m | time: 30.144s
[2K
| RMSProp | epoch: 024 | loss: 0.11020 - acc: 0.9622 -- iter: 0896/1162
[A[ATraining Step: 880  | total loss: [1m[32m0.10961[0m[0m | time: 31.303s
[2K
| RMSProp | epoch: 024 | loss: 0.10961 - acc: 0.9628 -- iter: 0928/1162
[A[ATraining Step: 881  | total loss: [1m[32m0.10684[0m[0m | time: 32.718s
[2K
| RMSProp | epoch: 024 | loss: 0.10684 - acc: 0.9634 -- iter: 0960/1162
[A[ATraining Step: 882  | total loss: [1m[32m0.10310[0m[0m | time: 34.115s
[2K
| RMSProp | epoch: 024 | loss: 0.10310 - acc: 0.9640 -- iter: 0992/1162
[A[ATraining Step: 883  | total loss: [1m[32m0.10014[0m[0m | time: 35.088s
[2K
| RMSProp | epoch: 024 | loss: 0.10014 - acc: 0.9676 -- iter: 1024/1162
[A[ATraining Step: 884  | total loss: [1m[32m0.09613[0m[0m | time: 36.160s
[2K
| RMSProp | epoch: 024 | loss: 0.09613 - acc: 0.9708 -- iter: 1056/1162
[A[ATraining Step: 885  | total loss: [1m[32m0.08865[0m[0m | time: 37.276s
[2K
| RMSProp | epoch: 024 | loss: 0.08865 - acc: 0.9737 -- iter: 1088/1162
[A[ATraining Step: 886  | total loss: [1m[32m0.08643[0m[0m | time: 38.242s
[2K
| RMSProp | epoch: 024 | loss: 0.08643 - acc: 0.9732 -- iter: 1120/1162
[A[ATraining Step: 887  | total loss: [1m[32m0.10704[0m[0m | time: 39.431s
[2K
| RMSProp | epoch: 024 | loss: 0.10704 - acc: 0.9634 -- iter: 1152/1162
[A[ATraining Step: 888  | total loss: [1m[32m0.12169[0m[0m | time: 42.784s
[2K
| RMSProp | epoch: 024 | loss: 0.12169 - acc: 0.9608 | val_loss: 0.49605 - val_acc: 0.8352 -- iter: 1162/1162
--
Training Step: 889  | total loss: [1m[32m0.12275[0m[0m | time: 1.079s
[2K
| RMSProp | epoch: 025 | loss: 0.12275 - acc: 0.9585 -- iter: 0032/1162
[A[ATraining Step: 890  | total loss: [1m[32m0.13535[0m[0m | time: 2.222s
[2K
| RMSProp | epoch: 025 | loss: 0.13535 - acc: 0.9533 -- iter: 0064/1162
[A[ATraining Step: 891  | total loss: [1m[32m0.13849[0m[0m | time: 3.399s
[2K
| RMSProp | epoch: 025 | loss: 0.13849 - acc: 0.9548 -- iter: 0096/1162
[A[ATraining Step: 892  | total loss: [1m[32m0.12780[0m[0m | time: 4.554s
[2K
| RMSProp | epoch: 025 | loss: 0.12780 - acc: 0.9593 -- iter: 0128/1162
[A[ATraining Step: 893  | total loss: [1m[32m0.11709[0m[0m | time: 5.557s
[2K
| RMSProp | epoch: 025 | loss: 0.11709 - acc: 0.9634 -- iter: 0160/1162
[A[ATraining Step: 894  | total loss: [1m[32m0.11823[0m[0m | time: 6.753s
[2K
| RMSProp | epoch: 025 | loss: 0.11823 - acc: 0.9639 -- iter: 0192/1162
[A[ATraining Step: 895  | total loss: [1m[32m0.10799[0m[0m | time: 7.797s
[2K
| RMSProp | epoch: 025 | loss: 0.10799 - acc: 0.9675 -- iter: 0224/1162
[A[ATraining Step: 896  | total loss: [1m[32m0.10158[0m[0m | time: 8.958s
[2K
| RMSProp | epoch: 025 | loss: 0.10158 - acc: 0.9677 -- iter: 0256/1162
[A[ATraining Step: 897  | total loss: [1m[32m0.10385[0m[0m | time: 10.139s
[2K
| RMSProp | epoch: 025 | loss: 0.10385 - acc: 0.9678 -- iter: 0288/1162
[A[ATraining Step: 898  | total loss: [1m[32m0.09989[0m[0m | time: 11.297s
[2K
| RMSProp | epoch: 025 | loss: 0.09989 - acc: 0.9679 -- iter: 0320/1162
[A[ATraining Step: 899  | total loss: [1m[32m0.10790[0m[0m | time: 12.312s
[2K
| RMSProp | epoch: 025 | loss: 0.10790 - acc: 0.9617 -- iter: 0352/1162
[A[ATraining Step: 900  | total loss: [1m[32m0.10585[0m[0m | time: 13.428s
[2K
| RMSProp | epoch: 025 | loss: 0.10585 - acc: 0.9624 -- iter: 0384/1162
[A[ATraining Step: 901  | total loss: [1m[32m0.09798[0m[0m | time: 14.101s
[2K
| RMSProp | epoch: 025 | loss: 0.09798 - acc: 0.9662 -- iter: 0416/1162
[A[ATraining Step: 902  | total loss: [1m[32m0.09262[0m[0m | time: 14.789s
[2K
| RMSProp | epoch: 025 | loss: 0.09262 - acc: 0.9664 -- iter: 0448/1162
[A[ATraining Step: 903  | total loss: [1m[32m0.09486[0m[0m | time: 15.490s
[2K
| RMSProp | epoch: 025 | loss: 0.09486 - acc: 0.9667 -- iter: 0480/1162
[A[ATraining Step: 904  | total loss: [1m[32m0.11257[0m[0m | time: 16.112s
[2K
| RMSProp | epoch: 025 | loss: 0.11257 - acc: 0.9606 -- iter: 0512/1162
[A[ATraining Step: 905  | total loss: [1m[32m0.11573[0m[0m | time: 16.800s
[2K
| RMSProp | epoch: 025 | loss: 0.11573 - acc: 0.9614 -- iter: 0544/1162
[A[ATraining Step: 906  | total loss: [1m[32m0.13193[0m[0m | time: 17.452s
[2K
| RMSProp | epoch: 025 | loss: 0.13193 - acc: 0.9528 -- iter: 0576/1162
[A[ATraining Step: 907  | total loss: [1m[32m0.13615[0m[0m | time: 18.131s
[2K
| RMSProp | epoch: 025 | loss: 0.13615 - acc: 0.9481 -- iter: 0608/1162
[A[ATraining Step: 908  | total loss: [1m[32m0.14272[0m[0m | time: 18.780s
[2K
| RMSProp | epoch: 025 | loss: 0.14272 - acc: 0.9439 -- iter: 0640/1162
[A[ATraining Step: 909  | total loss: [1m[32m0.16380[0m[0m | time: 19.455s
[2K
| RMSProp | epoch: 025 | loss: 0.16380 - acc: 0.9371 -- iter: 0672/1162
[A[ATraining Step: 910  | total loss: [1m[32m0.16607[0m[0m | time: 20.149s
[2K
| RMSProp | epoch: 025 | loss: 0.16607 - acc: 0.9340 -- iter: 0704/1162
[A[ATraining Step: 911  | total loss: [1m[32m0.15948[0m[0m | time: 20.379s
[2K
| RMSProp | epoch: 025 | loss: 0.15948 - acc: 0.9343 -- iter: 0736/1162
[A[ATraining Step: 912  | total loss: [1m[32m0.15753[0m[0m | time: 20.624s
[2K
| RMSProp | epoch: 025 | loss: 0.15753 - acc: 0.9309 -- iter: 0768/1162
[A[ATraining Step: 913  | total loss: [1m[32m0.14408[0m[0m | time: 21.224s
[2K
| RMSProp | epoch: 025 | loss: 0.14408 - acc: 0.9378 -- iter: 0800/1162
[A[ATraining Step: 914  | total loss: [1m[32m0.13115[0m[0m | time: 21.932s
[2K
| RMSProp | epoch: 025 | loss: 0.13115 - acc: 0.9440 -- iter: 0832/1162
[A[ATraining Step: 915  | total loss: [1m[32m0.12006[0m[0m | time: 22.584s
[2K
| RMSProp | epoch: 025 | loss: 0.12006 - acc: 0.9496 -- iter: 0864/1162
[A[ATraining Step: 916  | total loss: [1m[32m0.11264[0m[0m | time: 23.243s
[2K
| RMSProp | epoch: 025 | loss: 0.11264 - acc: 0.9515 -- iter: 0896/1162
[A[ATraining Step: 917  | total loss: [1m[32m0.10353[0m[0m | time: 23.930s
[2K
| RMSProp | epoch: 025 | loss: 0.10353 - acc: 0.9564 -- iter: 0928/1162
[A[ATraining Step: 918  | total loss: [1m[32m0.12905[0m[0m | time: 24.642s
[2K
| RMSProp | epoch: 025 | loss: 0.12905 - acc: 0.9545 -- iter: 0960/1162
[A[ATraining Step: 919  | total loss: [1m[32m0.13479[0m[0m | time: 25.310s
[2K
| RMSProp | epoch: 025 | loss: 0.13479 - acc: 0.9497 -- iter: 0992/1162
[A[ATraining Step: 920  | total loss: [1m[32m0.12831[0m[0m | time: 25.991s
[2K
| RMSProp | epoch: 025 | loss: 0.12831 - acc: 0.9516 -- iter: 1024/1162
[A[ATraining Step: 921  | total loss: [1m[32m0.12188[0m[0m | time: 26.677s
[2K
| RMSProp | epoch: 025 | loss: 0.12188 - acc: 0.9533 -- iter: 1056/1162
[A[ATraining Step: 922  | total loss: [1m[32m0.11472[0m[0m | time: 27.355s
[2K
| RMSProp | epoch: 025 | loss: 0.11472 - acc: 0.9580 -- iter: 1088/1162
[A[ATraining Step: 923  | total loss: [1m[32m0.10649[0m[0m | time: 28.042s
[2K
| RMSProp | epoch: 025 | loss: 0.10649 - acc: 0.9622 -- iter: 1120/1162
[A[ATraining Step: 924  | total loss: [1m[32m0.09862[0m[0m | time: 28.713s
[2K
| RMSProp | epoch: 025 | loss: 0.09862 - acc: 0.9660 -- iter: 1152/1162
[A[ATraining Step: 925  | total loss: [1m[32m0.09038[0m[0m | time: 30.893s
[2K
| RMSProp | epoch: 025 | loss: 0.09038 - acc: 0.9694 | val_loss: 0.54102 - val_acc: 0.8214 -- iter: 1162/1162
--
Training Step: 926  | total loss: [1m[32m0.08504[0m[0m | time: 0.663s
[2K
| RMSProp | epoch: 026 | loss: 0.08504 - acc: 0.9693 -- iter: 0032/1162
[A[ATraining Step: 927  | total loss: [1m[32m0.07774[0m[0m | time: 1.380s
[2K
| RMSProp | epoch: 026 | loss: 0.07774 - acc: 0.9724 -- iter: 0064/1162
[A[ATraining Step: 928  | total loss: [1m[32m0.07448[0m[0m | time: 2.069s
[2K
| RMSProp | epoch: 026 | loss: 0.07448 - acc: 0.9720 -- iter: 0096/1162
[A[ATraining Step: 929  | total loss: [1m[32m0.08630[0m[0m | time: 2.765s
[2K
| RMSProp | epoch: 026 | loss: 0.08630 - acc: 0.9686 -- iter: 0128/1162
[A[ATraining Step: 930  | total loss: [1m[32m0.13408[0m[0m | time: 3.433s
[2K
| RMSProp | epoch: 026 | loss: 0.13408 - acc: 0.9561 -- iter: 0160/1162
[A[ATraining Step: 931  | total loss: [1m[32m0.12594[0m[0m | time: 4.116s
[2K
| RMSProp | epoch: 026 | loss: 0.12594 - acc: 0.9605 -- iter: 0192/1162
[A[ATraining Step: 932  | total loss: [1m[32m0.12880[0m[0m | time: 4.790s
[2K
| RMSProp | epoch: 026 | loss: 0.12880 - acc: 0.9582 -- iter: 0224/1162
[A[ATraining Step: 933  | total loss: [1m[32m0.13501[0m[0m | time: 5.447s
[2K
| RMSProp | epoch: 026 | loss: 0.13501 - acc: 0.9592 -- iter: 0256/1162
[A[ATraining Step: 934  | total loss: [1m[32m0.14268[0m[0m | time: 6.164s
[2K
| RMSProp | epoch: 026 | loss: 0.14268 - acc: 0.9539 -- iter: 0288/1162
[A[ATraining Step: 935  | total loss: [1m[32m0.15686[0m[0m | time: 6.847s
[2K
| RMSProp | epoch: 026 | loss: 0.15686 - acc: 0.9460 -- iter: 0320/1162
[A[ATraining Step: 936  | total loss: [1m[32m0.14953[0m[0m | time: 7.503s
[2K
| RMSProp | epoch: 026 | loss: 0.14953 - acc: 0.9483 -- iter: 0352/1162
[A[ATraining Step: 937  | total loss: [1m[32m0.14180[0m[0m | time: 8.194s
[2K
| RMSProp | epoch: 026 | loss: 0.14180 - acc: 0.9504 -- iter: 0384/1162
[A[ATraining Step: 938  | total loss: [1m[32m0.13415[0m[0m | time: 8.911s
[2K
| RMSProp | epoch: 026 | loss: 0.13415 - acc: 0.9522 -- iter: 0416/1162
[A[ATraining Step: 939  | total loss: [1m[32m0.13134[0m[0m | time: 10.266s
[2K
| RMSProp | epoch: 026 | loss: 0.13134 - acc: 0.9538 -- iter: 0448/1162
[A[ATraining Step: 940  | total loss: [1m[32m0.12220[0m[0m | time: 11.542s
[2K
| RMSProp | epoch: 026 | loss: 0.12220 - acc: 0.9585 -- iter: 0480/1162
[A[ATraining Step: 941  | total loss: [1m[32m0.11137[0m[0m | time: 12.755s
[2K
| RMSProp | epoch: 026 | loss: 0.11137 - acc: 0.9626 -- iter: 0512/1162
[A[ATraining Step: 942  | total loss: [1m[32m0.10269[0m[0m | time: 13.577s
[2K
| RMSProp | epoch: 026 | loss: 0.10269 - acc: 0.9664 -- iter: 0544/1162
[A[ATraining Step: 943  | total loss: [1m[32m0.09418[0m[0m | time: 14.566s
[2K
| RMSProp | epoch: 026 | loss: 0.09418 - acc: 0.9697 -- iter: 0576/1162
[A[ATraining Step: 944  | total loss: [1m[32m0.10074[0m[0m | time: 15.544s
[2K
| RMSProp | epoch: 026 | loss: 0.10074 - acc: 0.9696 -- iter: 0608/1162
[A[ATraining Step: 945  | total loss: [1m[32m0.09251[0m[0m | time: 16.610s
[2K
| RMSProp | epoch: 026 | loss: 0.09251 - acc: 0.9727 -- iter: 0640/1162
[A[ATraining Step: 946  | total loss: [1m[32m0.08502[0m[0m | time: 17.695s
[2K
| RMSProp | epoch: 026 | loss: 0.08502 - acc: 0.9754 -- iter: 0672/1162
[A[ATraining Step: 947  | total loss: [1m[32m0.07800[0m[0m | time: 18.911s
[2K
| RMSProp | epoch: 026 | loss: 0.07800 - acc: 0.9779 -- iter: 0704/1162
[A[ATraining Step: 948  | total loss: [1m[32m0.07126[0m[0m | time: 19.943s
[2K
| RMSProp | epoch: 026 | loss: 0.07126 - acc: 0.9801 -- iter: 0736/1162
[A[ATraining Step: 949  | total loss: [1m[32m0.06479[0m[0m | time: 20.520s
[2K
| RMSProp | epoch: 026 | loss: 0.06479 - acc: 0.9821 -- iter: 0768/1162
[A[ATraining Step: 950  | total loss: [1m[32m0.06026[0m[0m | time: 21.001s
[2K
| RMSProp | epoch: 026 | loss: 0.06026 - acc: 0.9839 -- iter: 0800/1162
[A[ATraining Step: 951  | total loss: [1m[32m0.05580[0m[0m | time: 22.328s
[2K
| RMSProp | epoch: 026 | loss: 0.05580 - acc: 0.9855 -- iter: 0832/1162
[A[ATraining Step: 952  | total loss: [1m[32m0.05684[0m[0m | time: 23.575s
[2K
| RMSProp | epoch: 026 | loss: 0.05684 - acc: 0.9838 -- iter: 0864/1162
[A[ATraining Step: 953  | total loss: [1m[32m0.06522[0m[0m | time: 24.457s
[2K
| RMSProp | epoch: 026 | loss: 0.06522 - acc: 0.9760 -- iter: 0896/1162
[A[ATraining Step: 954  | total loss: [1m[32m0.10996[0m[0m | time: 25.407s
[2K
| RMSProp | epoch: 026 | loss: 0.10996 - acc: 0.9628 -- iter: 0928/1162
[A[ATraining Step: 955  | total loss: [1m[32m0.10286[0m[0m | time: 26.455s
[2K
| RMSProp | epoch: 026 | loss: 0.10286 - acc: 0.9665 -- iter: 0960/1162
[A[ATraining Step: 956  | total loss: [1m[32m0.11115[0m[0m | time: 27.496s
[2K
| RMSProp | epoch: 026 | loss: 0.11115 - acc: 0.9605 -- iter: 0992/1162
[A[ATraining Step: 957  | total loss: [1m[32m0.11408[0m[0m | time: 28.626s
[2K
| RMSProp | epoch: 026 | loss: 0.11408 - acc: 0.9582 -- iter: 1024/1162
[A[ATraining Step: 958  | total loss: [1m[32m0.10353[0m[0m | time: 29.763s
[2K
| RMSProp | epoch: 026 | loss: 0.10353 - acc: 0.9624 -- iter: 1056/1162
[A[ATraining Step: 959  | total loss: [1m[32m0.10872[0m[0m | time: 30.779s
[2K
| RMSProp | epoch: 026 | loss: 0.10872 - acc: 0.9599 -- iter: 1088/1162
[A[ATraining Step: 960  | total loss: [1m[32m0.10790[0m[0m | time: 32.202s
[2K
| RMSProp | epoch: 026 | loss: 0.10790 - acc: 0.9639 -- iter: 1120/1162
[A[ATraining Step: 961  | total loss: [1m[32m0.09919[0m[0m | time: 33.605s
[2K
| RMSProp | epoch: 026 | loss: 0.09919 - acc: 0.9675 -- iter: 1152/1162
[A[ATraining Step: 962  | total loss: [1m[32m0.10457[0m[0m | time: 36.755s
[2K
| RMSProp | epoch: 026 | loss: 0.10457 - acc: 0.9676 | val_loss: 0.46532 - val_acc: 0.8626 -- iter: 1162/1162
--
Training Step: 963  | total loss: [1m[32m0.09665[0m[0m | time: 1.248s
[2K
| RMSProp | epoch: 027 | loss: 0.09665 - acc: 0.9709 -- iter: 0032/1162
[A[ATraining Step: 964  | total loss: [1m[32m0.09429[0m[0m | time: 2.947s
[2K
| RMSProp | epoch: 027 | loss: 0.09429 - acc: 0.9675 -- iter: 0064/1162
[A[ATraining Step: 965  | total loss: [1m[32m0.10113[0m[0m | time: 4.194s
[2K
| RMSProp | epoch: 027 | loss: 0.10113 - acc: 0.9614 -- iter: 0096/1162
[A[ATraining Step: 966  | total loss: [1m[32m0.09237[0m[0m | time: 5.136s
[2K
| RMSProp | epoch: 027 | loss: 0.09237 - acc: 0.9653 -- iter: 0128/1162
[A[ATraining Step: 967  | total loss: [1m[32m0.08558[0m[0m | time: 6.203s
[2K
| RMSProp | epoch: 027 | loss: 0.08558 - acc: 0.9687 -- iter: 0160/1162
[A[ATraining Step: 968  | total loss: [1m[32m0.07832[0m[0m | time: 7.263s
[2K
| RMSProp | epoch: 027 | loss: 0.07832 - acc: 0.9719 -- iter: 0192/1162
[A[ATraining Step: 969  | total loss: [1m[32m0.08779[0m[0m | time: 8.314s
[2K
| RMSProp | epoch: 027 | loss: 0.08779 - acc: 0.9716 -- iter: 0224/1162
[A[ATraining Step: 970  | total loss: [1m[32m0.10626[0m[0m | time: 9.495s
[2K
| RMSProp | epoch: 027 | loss: 0.10626 - acc: 0.9650 -- iter: 0256/1162
[A[ATraining Step: 971  | total loss: [1m[32m0.09733[0m[0m | time: 10.490s
[2K
| RMSProp | epoch: 027 | loss: 0.09733 - acc: 0.9685 -- iter: 0288/1162
[A[ATraining Step: 972  | total loss: [1m[32m0.09192[0m[0m | time: 11.606s
[2K
| RMSProp | epoch: 027 | loss: 0.09192 - acc: 0.9685 -- iter: 0320/1162
[A[ATraining Step: 973  | total loss: [1m[32m0.09396[0m[0m | time: 12.980s
[2K
| RMSProp | epoch: 027 | loss: 0.09396 - acc: 0.9686 -- iter: 0352/1162
[A[ATraining Step: 974  | total loss: [1m[32m0.10106[0m[0m | time: 14.314s
[2K
| RMSProp | epoch: 027 | loss: 0.10106 - acc: 0.9623 -- iter: 0384/1162
[A[ATraining Step: 975  | total loss: [1m[32m0.09618[0m[0m | time: 15.380s
[2K
| RMSProp | epoch: 027 | loss: 0.09618 - acc: 0.9661 -- iter: 0416/1162
[A[ATraining Step: 976  | total loss: [1m[32m0.10122[0m[0m | time: 16.319s
[2K
| RMSProp | epoch: 027 | loss: 0.10122 - acc: 0.9664 -- iter: 0448/1162
[A[ATraining Step: 977  | total loss: [1m[32m0.10296[0m[0m | time: 17.361s
[2K
| RMSProp | epoch: 027 | loss: 0.10296 - acc: 0.9635 -- iter: 0480/1162
[A[ATraining Step: 978  | total loss: [1m[32m0.10487[0m[0m | time: 18.382s
[2K
| RMSProp | epoch: 027 | loss: 0.10487 - acc: 0.9609 -- iter: 0512/1162
[A[ATraining Step: 979  | total loss: [1m[32m0.10079[0m[0m | time: 19.473s
[2K
| RMSProp | epoch: 027 | loss: 0.10079 - acc: 0.9648 -- iter: 0544/1162
[A[ATraining Step: 980  | total loss: [1m[32m0.09445[0m[0m | time: 20.618s
[2K
| RMSProp | epoch: 027 | loss: 0.09445 - acc: 0.9683 -- iter: 0576/1162
[A[ATraining Step: 981  | total loss: [1m[32m0.09245[0m[0m | time: 21.591s
[2K
| RMSProp | epoch: 027 | loss: 0.09245 - acc: 0.9652 -- iter: 0608/1162
[A[ATraining Step: 982  | total loss: [1m[32m0.10275[0m[0m | time: 22.990s
[2K
| RMSProp | epoch: 027 | loss: 0.10275 - acc: 0.9593 -- iter: 0640/1162
[A[ATraining Step: 983  | total loss: [1m[32m0.09784[0m[0m | time: 24.493s
[2K
| RMSProp | epoch: 027 | loss: 0.09784 - acc: 0.9603 -- iter: 0672/1162
[A[ATraining Step: 984  | total loss: [1m[32m0.09125[0m[0m | time: 25.807s
[2K
| RMSProp | epoch: 027 | loss: 0.09125 - acc: 0.9642 -- iter: 0704/1162
[A[ATraining Step: 985  | total loss: [1m[32m0.08234[0m[0m | time: 26.608s
[2K
| RMSProp | epoch: 027 | loss: 0.08234 - acc: 0.9678 -- iter: 0736/1162
[A[ATraining Step: 986  | total loss: [1m[32m0.07471[0m[0m | time: 27.630s
[2K
| RMSProp | epoch: 027 | loss: 0.07471 - acc: 0.9710 -- iter: 0768/1162
[A[ATraining Step: 987  | total loss: [1m[32m0.06770[0m[0m | time: 28.003s
[2K
| RMSProp | epoch: 027 | loss: 0.06770 - acc: 0.9739 -- iter: 0800/1162
[A[ATraining Step: 988  | total loss: [1m[32m0.07779[0m[0m | time: 28.375s
[2K
| RMSProp | epoch: 027 | loss: 0.07779 - acc: 0.9665 -- iter: 0832/1162
[A[ATraining Step: 989  | total loss: [1m[32m0.07041[0m[0m | time: 29.411s
[2K
| RMSProp | epoch: 027 | loss: 0.07041 - acc: 0.9699 -- iter: 0864/1162
[A[ATraining Step: 990  | total loss: [1m[32m0.08259[0m[0m | time: 30.673s
[2K
| RMSProp | epoch: 027 | loss: 0.08259 - acc: 0.9666 -- iter: 0896/1162
[A[ATraining Step: 991  | total loss: [1m[32m0.07684[0m[0m | time: 31.783s
[2K
| RMSProp | epoch: 027 | loss: 0.07684 - acc: 0.9700 -- iter: 0928/1162
[A[ATraining Step: 992  | total loss: [1m[32m0.07031[0m[0m | time: 32.720s
[2K
| RMSProp | epoch: 027 | loss: 0.07031 - acc: 0.9730 -- iter: 0960/1162
[A[ATraining Step: 993  | total loss: [1m[32m0.06618[0m[0m | time: 34.170s
[2K
| RMSProp | epoch: 027 | loss: 0.06618 - acc: 0.9757 -- iter: 0992/1162
[A[ATraining Step: 994  | total loss: [1m[32m0.09870[0m[0m | time: 35.456s
[2K
| RMSProp | epoch: 027 | loss: 0.09870 - acc: 0.9719 -- iter: 1024/1162
[A[ATraining Step: 995  | total loss: [1m[32m0.09531[0m[0m | time: 36.441s
[2K
| RMSProp | epoch: 027 | loss: 0.09531 - acc: 0.9716 -- iter: 1056/1162
[A[ATraining Step: 996  | total loss: [1m[32m0.11702[0m[0m | time: 37.474s
[2K
| RMSProp | epoch: 027 | loss: 0.11702 - acc: 0.9619 -- iter: 1088/1162
[A[ATraining Step: 997  | total loss: [1m[32m0.11148[0m[0m | time: 38.478s
[2K
| RMSProp | epoch: 027 | loss: 0.11148 - acc: 0.9626 -- iter: 1120/1162
[A[ATraining Step: 998  | total loss: [1m[32m0.10131[0m[0m | time: 39.612s
[2K
| RMSProp | epoch: 027 | loss: 0.10131 - acc: 0.9663 -- iter: 1152/1162
[A[ATraining Step: 999  | total loss: [1m[32m0.09386[0m[0m | time: 43.426s
[2K
| RMSProp | epoch: 027 | loss: 0.09386 - acc: 0.9697 | val_loss: 0.41853 - val_acc: 0.8819 -- iter: 1162/1162
--
Training Step: 1000  | total loss: [1m[32m0.08606[0m[0m | time: 3.870s
[2K
| RMSProp | epoch: 028 | loss: 0.08606 - acc: 0.9727 | val_loss: 0.38116 - val_acc: 0.8654 -- iter: 0032/1162
--
Training Step: 1001  | total loss: [1m[32m0.09150[0m[0m | time: 4.921s
[2K
| RMSProp | epoch: 028 | loss: 0.09150 - acc: 0.9723 -- iter: 0064/1162
[A[ATraining Step: 1002  | total loss: [1m[32m0.08346[0m[0m | time: 5.959s
[2K
| RMSProp | epoch: 028 | loss: 0.08346 - acc: 0.9751 -- iter: 0096/1162
[A[ATraining Step: 1003  | total loss: [1m[32m0.08626[0m[0m | time: 7.088s
[2K
| RMSProp | epoch: 028 | loss: 0.08626 - acc: 0.9745 -- iter: 0128/1162
[A[ATraining Step: 1004  | total loss: [1m[32m0.08515[0m[0m | time: 8.211s
[2K
| RMSProp | epoch: 028 | loss: 0.08515 - acc: 0.9739 -- iter: 0160/1162
[A[ATraining Step: 1005  | total loss: [1m[32m0.09330[0m[0m | time: 9.045s
[2K
| RMSProp | epoch: 028 | loss: 0.09330 - acc: 0.9703 -- iter: 0192/1162
[A[ATraining Step: 1006  | total loss: [1m[32m0.09733[0m[0m | time: 10.459s
[2K
| RMSProp | epoch: 028 | loss: 0.09733 - acc: 0.9701 -- iter: 0224/1162
[A[ATraining Step: 1007  | total loss: [1m[32m0.09591[0m[0m | time: 11.773s
[2K
| RMSProp | epoch: 028 | loss: 0.09591 - acc: 0.9668 -- iter: 0256/1162
[A[ATraining Step: 1008  | total loss: [1m[32m0.10370[0m[0m | time: 12.951s
[2K
| RMSProp | epoch: 028 | loss: 0.10370 - acc: 0.9639 -- iter: 0288/1162
[A[ATraining Step: 1009  | total loss: [1m[32m0.09556[0m[0m | time: 13.788s
[2K
| RMSProp | epoch: 028 | loss: 0.09556 - acc: 0.9675 -- iter: 0320/1162
[A[ATraining Step: 1010  | total loss: [1m[32m0.08845[0m[0m | time: 14.758s
[2K
| RMSProp | epoch: 028 | loss: 0.08845 - acc: 0.9708 -- iter: 0352/1162
[A[ATraining Step: 1011  | total loss: [1m[32m0.08484[0m[0m | time: 15.740s
[2K
| RMSProp | epoch: 028 | loss: 0.08484 - acc: 0.9706 -- iter: 0384/1162
[A[ATraining Step: 1012  | total loss: [1m[32m0.08275[0m[0m | time: 16.749s
[2K
| RMSProp | epoch: 028 | loss: 0.08275 - acc: 0.9704 -- iter: 0416/1162
[A[ATraining Step: 1013  | total loss: [1m[32m0.08516[0m[0m | time: 17.845s
[2K
| RMSProp | epoch: 028 | loss: 0.08516 - acc: 0.9671 -- iter: 0448/1162
[A[ATraining Step: 1014  | total loss: [1m[32m0.07817[0m[0m | time: 19.044s
[2K
| RMSProp | epoch: 028 | loss: 0.07817 - acc: 0.9704 -- iter: 0480/1162
[A[ATraining Step: 1015  | total loss: [1m[32m0.07555[0m[0m | time: 20.054s
[2K
| RMSProp | epoch: 028 | loss: 0.07555 - acc: 0.9702 -- iter: 0512/1162
[A[ATraining Step: 1016  | total loss: [1m[32m0.08501[0m[0m | time: 21.517s
[2K
| RMSProp | epoch: 028 | loss: 0.08501 - acc: 0.9669 -- iter: 0544/1162
[A[ATraining Step: 1017  | total loss: [1m[32m0.07782[0m[0m | time: 22.990s
[2K
| RMSProp | epoch: 028 | loss: 0.07782 - acc: 0.9703 -- iter: 0576/1162
[A[ATraining Step: 1018  | total loss: [1m[32m0.07314[0m[0m | time: 24.115s
[2K
| RMSProp | epoch: 028 | loss: 0.07314 - acc: 0.9701 -- iter: 0608/1162
[A[ATraining Step: 1019  | total loss: [1m[32m0.07218[0m[0m | time: 25.150s
[2K
| RMSProp | epoch: 028 | loss: 0.07218 - acc: 0.9731 -- iter: 0640/1162
[A[ATraining Step: 1020  | total loss: [1m[32m0.07761[0m[0m | time: 26.222s
[2K
| RMSProp | epoch: 028 | loss: 0.07761 - acc: 0.9727 -- iter: 0672/1162
[A[ATraining Step: 1021  | total loss: [1m[32m0.07960[0m[0m | time: 27.263s
[2K
| RMSProp | epoch: 028 | loss: 0.07960 - acc: 0.9691 -- iter: 0704/1162
[A[ATraining Step: 1022  | total loss: [1m[32m0.08899[0m[0m | time: 28.401s
[2K
| RMSProp | epoch: 028 | loss: 0.08899 - acc: 0.9629 -- iter: 0736/1162
[A[ATraining Step: 1023  | total loss: [1m[32m0.09476[0m[0m | time: 29.464s
[2K
| RMSProp | epoch: 028 | loss: 0.09476 - acc: 0.9634 -- iter: 0768/1162
[A[ATraining Step: 1024  | total loss: [1m[32m0.08705[0m[0m | time: 30.431s
[2K
| RMSProp | epoch: 028 | loss: 0.08705 - acc: 0.9671 -- iter: 0800/1162
[A[ATraining Step: 1025  | total loss: [1m[32m0.08005[0m[0m | time: 30.968s
[2K
| RMSProp | epoch: 028 | loss: 0.08005 - acc: 0.9704 -- iter: 0832/1162
[A[ATraining Step: 1026  | total loss: [1m[32m0.07254[0m[0m | time: 31.485s
[2K
| RMSProp | epoch: 028 | loss: 0.07254 - acc: 0.9734 -- iter: 0864/1162
[A[ATraining Step: 1027  | total loss: [1m[32m0.06568[0m[0m | time: 32.830s
[2K
| RMSProp | epoch: 028 | loss: 0.06568 - acc: 0.9760 -- iter: 0896/1162
[A[ATraining Step: 1028  | total loss: [1m[32m0.06145[0m[0m | time: 34.128s
[2K
| RMSProp | epoch: 028 | loss: 0.06145 - acc: 0.9784 -- iter: 0928/1162
[A[ATraining Step: 1029  | total loss: [1m[32m0.06047[0m[0m | time: 35.025s
[2K
| RMSProp | epoch: 028 | loss: 0.06047 - acc: 0.9774 -- iter: 0960/1162
[A[ATraining Step: 1030  | total loss: [1m[32m0.05972[0m[0m | time: 36.052s
[2K
| RMSProp | epoch: 028 | loss: 0.05972 - acc: 0.9766 -- iter: 0992/1162
[A[ATraining Step: 1031  | total loss: [1m[32m0.06201[0m[0m | time: 37.082s
[2K
| RMSProp | epoch: 028 | loss: 0.06201 - acc: 0.9758 -- iter: 1024/1162
[A[ATraining Step: 1032  | total loss: [1m[32m0.08369[0m[0m | time: 38.152s
[2K
| RMSProp | epoch: 028 | loss: 0.08369 - acc: 0.9751 -- iter: 1056/1162
[A[ATraining Step: 1033  | total loss: [1m[32m0.07660[0m[0m | time: 39.352s
[2K
| RMSProp | epoch: 028 | loss: 0.07660 - acc: 0.9776 -- iter: 1088/1162
[A[ATraining Step: 1034  | total loss: [1m[32m0.07003[0m[0m | time: 40.433s
[2K
| RMSProp | epoch: 028 | loss: 0.07003 - acc: 0.9798 -- iter: 1120/1162
[A[ATraining Step: 1035  | total loss: [1m[32m0.06416[0m[0m | time: 41.291s
[2K
| RMSProp | epoch: 028 | loss: 0.06416 - acc: 0.9818 -- iter: 1152/1162
[A[ATraining Step: 1036  | total loss: [1m[32m0.05822[0m[0m | time: 45.578s
[2K
| RMSProp | epoch: 028 | loss: 0.05822 - acc: 0.9837 | val_loss: 0.49698 - val_acc: 0.8626 -- iter: 1162/1162
--
Training Step: 1037  | total loss: [1m[32m0.05280[0m[0m | time: 1.253s
[2K
| RMSProp | epoch: 029 | loss: 0.05280 - acc: 0.9853 -- iter: 0032/1162
[A[ATraining Step: 1038  | total loss: [1m[32m0.04887[0m[0m | time: 2.320s
[2K
| RMSProp | epoch: 029 | loss: 0.04887 - acc: 0.9868 -- iter: 0064/1162
[A[ATraining Step: 1039  | total loss: [1m[32m0.04439[0m[0m | time: 3.613s
[2K
| RMSProp | epoch: 029 | loss: 0.04439 - acc: 0.9881 -- iter: 0096/1162
[A[ATraining Step: 1040  | total loss: [1m[32m0.04135[0m[0m | time: 5.070s
[2K
| RMSProp | epoch: 029 | loss: 0.04135 - acc: 0.9893 -- iter: 0128/1162
[A[ATraining Step: 1041  | total loss: [1m[32m0.03821[0m[0m | time: 6.445s
[2K
| RMSProp | epoch: 029 | loss: 0.03821 - acc: 0.9903 -- iter: 0160/1162
[A[ATraining Step: 1042  | total loss: [1m[32m0.03476[0m[0m | time: 7.389s
[2K
| RMSProp | epoch: 029 | loss: 0.03476 - acc: 0.9913 -- iter: 0192/1162
[A[ATraining Step: 1043  | total loss: [1m[32m0.03149[0m[0m | time: 8.423s
[2K
| RMSProp | epoch: 029 | loss: 0.03149 - acc: 0.9922 -- iter: 0224/1162
[A[ATraining Step: 1044  | total loss: [1m[32m0.02877[0m[0m | time: 9.539s
[2K
| RMSProp | epoch: 029 | loss: 0.02877 - acc: 0.9930 -- iter: 0256/1162
[A[ATraining Step: 1045  | total loss: [1m[32m0.02599[0m[0m | time: 10.599s
[2K
| RMSProp | epoch: 029 | loss: 0.02599 - acc: 0.9937 -- iter: 0288/1162
[A[ATraining Step: 1046  | total loss: [1m[32m0.02394[0m[0m | time: 11.853s
[2K
| RMSProp | epoch: 029 | loss: 0.02394 - acc: 0.9943 -- iter: 0320/1162
[A[ATraining Step: 1047  | total loss: [1m[32m0.02168[0m[0m | time: 12.886s
[2K
| RMSProp | epoch: 029 | loss: 0.02168 - acc: 0.9949 -- iter: 0352/1162
[A[ATraining Step: 1048  | total loss: [1m[32m0.03602[0m[0m | time: 14.106s
[2K
| RMSProp | epoch: 029 | loss: 0.03602 - acc: 0.9923 -- iter: 0384/1162
[A[ATraining Step: 1049  | total loss: [1m[32m0.07103[0m[0m | time: 15.527s
[2K
| RMSProp | epoch: 029 | loss: 0.07103 - acc: 0.9805 -- iter: 0416/1162
[A[ATraining Step: 1050  | total loss: [1m[32m0.07249[0m[0m | time: 16.899s
[2K
| RMSProp | epoch: 029 | loss: 0.07249 - acc: 0.9762 -- iter: 0448/1162
[A[ATraining Step: 1051  | total loss: [1m[32m0.08918[0m[0m | time: 17.770s
[2K
| RMSProp | epoch: 029 | loss: 0.08918 - acc: 0.9692 -- iter: 0480/1162
[A[ATraining Step: 1052  | total loss: [1m[32m0.09162[0m[0m | time: 18.752s
[2K
| RMSProp | epoch: 029 | loss: 0.09162 - acc: 0.9661 -- iter: 0512/1162
[A[ATraining Step: 1053  | total loss: [1m[32m0.08558[0m[0m | time: 19.739s
[2K
| RMSProp | epoch: 029 | loss: 0.08558 - acc: 0.9695 -- iter: 0544/1162
[A[ATraining Step: 1054  | total loss: [1m[32m0.08869[0m[0m | time: 20.796s
[2K
| RMSProp | epoch: 029 | loss: 0.08869 - acc: 0.9694 -- iter: 0576/1162
[A[ATraining Step: 1055  | total loss: [1m[32m0.09088[0m[0m | time: 21.842s
[2K
| RMSProp | epoch: 029 | loss: 0.09088 - acc: 0.9662 -- iter: 0608/1162
[A[ATraining Step: 1056  | total loss: [1m[32m0.08361[0m[0m | time: 23.093s
[2K
| RMSProp | epoch: 029 | loss: 0.08361 - acc: 0.9696 -- iter: 0640/1162
[A[ATraining Step: 1057  | total loss: [1m[32m0.09147[0m[0m | time: 23.990s
[2K
| RMSProp | epoch: 029 | loss: 0.09147 - acc: 0.9695 -- iter: 0672/1162
[A[ATraining Step: 1058  | total loss: [1m[32m0.08363[0m[0m | time: 25.130s
[2K
| RMSProp | epoch: 029 | loss: 0.08363 - acc: 0.9725 -- iter: 0704/1162
[A[ATraining Step: 1059  | total loss: [1m[32m0.07607[0m[0m | time: 26.302s
[2K
| RMSProp | epoch: 029 | loss: 0.07607 - acc: 0.9753 -- iter: 0736/1162
[A[ATraining Step: 1060  | total loss: [1m[32m0.08293[0m[0m | time: 27.407s
[2K
| RMSProp | epoch: 029 | loss: 0.08293 - acc: 0.9746 -- iter: 0768/1162
[A[ATraining Step: 1061  | total loss: [1m[32m0.07719[0m[0m | time: 28.670s
[2K
| RMSProp | epoch: 029 | loss: 0.07719 - acc: 0.9772 -- iter: 0800/1162
[A[ATraining Step: 1062  | total loss: [1m[32m0.07014[0m[0m | time: 29.810s
[2K
| RMSProp | epoch: 029 | loss: 0.07014 - acc: 0.9795 -- iter: 0832/1162
[A[ATraining Step: 1063  | total loss: [1m[32m0.06355[0m[0m | time: 30.235s
[2K
| RMSProp | epoch: 029 | loss: 0.06355 - acc: 0.9815 -- iter: 0864/1162
[A[ATraining Step: 1064  | total loss: [1m[32m0.05754[0m[0m | time: 30.615s
[2K
| RMSProp | epoch: 029 | loss: 0.05754 - acc: 0.9834 -- iter: 0896/1162
[A[ATraining Step: 1065  | total loss: [1m[32m0.05204[0m[0m | time: 31.698s
[2K
| RMSProp | epoch: 029 | loss: 0.05204 - acc: 0.9850 -- iter: 0928/1162
[A[ATraining Step: 1066  | total loss: [1m[32m0.04749[0m[0m | time: 32.413s
[2K
| RMSProp | epoch: 029 | loss: 0.04749 - acc: 0.9865 -- iter: 0960/1162
[A[ATraining Step: 1067  | total loss: [1m[32m0.04340[0m[0m | time: 33.080s
[2K
| RMSProp | epoch: 029 | loss: 0.04340 - acc: 0.9879 -- iter: 0992/1162
[A[ATraining Step: 1068  | total loss: [1m[32m0.06215[0m[0m | time: 33.726s
[2K
| RMSProp | epoch: 029 | loss: 0.06215 - acc: 0.9860 -- iter: 1024/1162
[A[ATraining Step: 1069  | total loss: [1m[32m0.07184[0m[0m | time: 34.376s
[2K
| RMSProp | epoch: 029 | loss: 0.07184 - acc: 0.9842 -- iter: 1056/1162
[A[ATraining Step: 1070  | total loss: [1m[32m0.08178[0m[0m | time: 35.033s
[2K
| RMSProp | epoch: 029 | loss: 0.08178 - acc: 0.9796 -- iter: 1088/1162
[A[ATraining Step: 1071  | total loss: [1m[32m0.07834[0m[0m | time: 35.649s
[2K
| RMSProp | epoch: 029 | loss: 0.07834 - acc: 0.9816 -- iter: 1120/1162
[A[ATraining Step: 1072  | total loss: [1m[32m0.07168[0m[0m | time: 36.263s
[2K
| RMSProp | epoch: 029 | loss: 0.07168 - acc: 0.9834 -- iter: 1152/1162
[A[ATraining Step: 1073  | total loss: [1m[32m0.06505[0m[0m | time: 38.272s
[2K
| RMSProp | epoch: 029 | loss: 0.06505 - acc: 0.9851 | val_loss: 0.44412 - val_acc: 0.8736 -- iter: 1162/1162
--
Training Step: 1074  | total loss: [1m[32m0.05958[0m[0m | time: 0.697s
[2K
| RMSProp | epoch: 030 | loss: 0.05958 - acc: 0.9866 -- iter: 0032/1162
[A[ATraining Step: 1075  | total loss: [1m[32m0.05529[0m[0m | time: 1.362s
[2K
| RMSProp | epoch: 030 | loss: 0.05529 - acc: 0.9879 -- iter: 0064/1162
[A[ATraining Step: 1076  | total loss: [1m[32m0.05004[0m[0m | time: 2.027s
[2K
| RMSProp | epoch: 030 | loss: 0.05004 - acc: 0.9891 -- iter: 0096/1162
[A[ATraining Step: 1077  | total loss: [1m[32m0.04540[0m[0m | time: 2.710s
[2K
| RMSProp | epoch: 030 | loss: 0.04540 - acc: 0.9902 -- iter: 0128/1162
[A[ATraining Step: 1078  | total loss: [1m[32m0.04203[0m[0m | time: 3.343s
[2K
| RMSProp | epoch: 030 | loss: 0.04203 - acc: 0.9912 -- iter: 0160/1162
[A[ATraining Step: 1079  | total loss: [1m[32m0.03880[0m[0m | time: 3.985s
[2K
| RMSProp | epoch: 030 | loss: 0.03880 - acc: 0.9921 -- iter: 0192/1162
[A[ATraining Step: 1080  | total loss: [1m[32m0.03587[0m[0m | time: 4.619s
[2K
| RMSProp | epoch: 030 | loss: 0.03587 - acc: 0.9929 -- iter: 0224/1162
[A[ATraining Step: 1081  | total loss: [1m[32m0.03301[0m[0m | time: 5.329s
[2K
| RMSProp | epoch: 030 | loss: 0.03301 - acc: 0.9936 -- iter: 0256/1162
[A[ATraining Step: 1082  | total loss: [1m[32m0.03016[0m[0m | time: 6.016s
[2K
| RMSProp | epoch: 030 | loss: 0.03016 - acc: 0.9942 -- iter: 0288/1162
[A[ATraining Step: 1083  | total loss: [1m[32m0.02738[0m[0m | time: 6.696s
[2K
| RMSProp | epoch: 030 | loss: 0.02738 - acc: 0.9948 -- iter: 0320/1162
[A[ATraining Step: 1084  | total loss: [1m[32m0.02495[0m[0m | time: 7.386s
[2K
| RMSProp | epoch: 030 | loss: 0.02495 - acc: 0.9953 -- iter: 0352/1162
[A[ATraining Step: 1085  | total loss: [1m[32m0.02294[0m[0m | time: 8.065s
[2K
| RMSProp | epoch: 030 | loss: 0.02294 - acc: 0.9958 -- iter: 0384/1162
[A[ATraining Step: 1086  | total loss: [1m[32m0.02074[0m[0m | time: 8.740s
[2K
| RMSProp | epoch: 030 | loss: 0.02074 - acc: 0.9962 -- iter: 0416/1162
[A[ATraining Step: 1087  | total loss: [1m[32m0.01878[0m[0m | time: 9.354s
[2K
| RMSProp | epoch: 030 | loss: 0.01878 - acc: 0.9966 -- iter: 0448/1162
[A[ATraining Step: 1088  | total loss: [1m[32m0.01699[0m[0m | time: 10.513s
[2K
| RMSProp | epoch: 030 | loss: 0.01699 - acc: 0.9969 -- iter: 0480/1162
[A[ATraining Step: 1089  | total loss: [1m[32m0.01549[0m[0m | time: 11.994s
[2K
| RMSProp | epoch: 030 | loss: 0.01549 - acc: 0.9972 -- iter: 0512/1162
[A[ATraining Step: 1090  | total loss: [1m[32m0.04023[0m[0m | time: 13.340s
[2K
| RMSProp | epoch: 030 | loss: 0.04023 - acc: 0.9913 -- iter: 0544/1162
[A[ATraining Step: 1091  | total loss: [1m[32m0.05050[0m[0m | time: 14.283s
[2K
| RMSProp | epoch: 030 | loss: 0.05050 - acc: 0.9828 -- iter: 0576/1162
[A[ATraining Step: 1092  | total loss: [1m[32m0.18795[0m[0m | time: 15.273s
[2K
| RMSProp | epoch: 030 | loss: 0.18795 - acc: 0.9439 -- iter: 0608/1162
[A[ATraining Step: 1093  | total loss: [1m[32m0.23348[0m[0m | time: 16.370s
[2K
| RMSProp | epoch: 030 | loss: 0.23348 - acc: 0.9307 -- iter: 0640/1162
[A[ATraining Step: 1094  | total loss: [1m[32m0.21219[0m[0m | time: 17.458s
[2K
| RMSProp | epoch: 030 | loss: 0.21219 - acc: 0.9377 -- iter: 0672/1162
[A[ATraining Step: 1095  | total loss: [1m[32m0.19307[0m[0m | time: 18.736s
[2K
| RMSProp | epoch: 030 | loss: 0.19307 - acc: 0.9439 -- iter: 0704/1162
[A[ATraining Step: 1096  | total loss: [1m[32m0.17494[0m[0m | time: 19.798s
[2K
| RMSProp | epoch: 030 | loss: 0.17494 - acc: 0.9495 -- iter: 0736/1162
[A[ATraining Step: 1097  | total loss: [1m[32m0.15958[0m[0m | time: 20.883s
[2K
| RMSProp | epoch: 030 | loss: 0.15958 - acc: 0.9545 -- iter: 0768/1162
[A[ATraining Step: 1098  | total loss: [1m[32m0.15866[0m[0m | time: 22.268s
[2K
| RMSProp | epoch: 030 | loss: 0.15866 - acc: 0.9497 -- iter: 0800/1162
[A[ATraining Step: 1099  | total loss: [1m[32m0.14747[0m[0m | time: 23.574s
[2K
| RMSProp | epoch: 030 | loss: 0.14747 - acc: 0.9547 -- iter: 0832/1162
[A[ATraining Step: 1100  | total loss: [1m[32m0.13354[0m[0m | time: 24.606s
[2K
| RMSProp | epoch: 030 | loss: 0.13354 - acc: 0.9593 -- iter: 0864/1162
[A[ATraining Step: 1101  | total loss: [1m[32m0.12068[0m[0m | time: 24.958s
[2K
| RMSProp | epoch: 030 | loss: 0.12068 - acc: 0.9633 -- iter: 0896/1162
[A[ATraining Step: 1102  | total loss: [1m[32m0.13531[0m[0m | time: 25.355s
[2K
| RMSProp | epoch: 030 | loss: 0.13531 - acc: 0.9570 -- iter: 0928/1162
[A[ATraining Step: 1103  | total loss: [1m[32m0.14146[0m[0m | time: 26.447s
[2K
| RMSProp | epoch: 030 | loss: 0.14146 - acc: 0.9513 -- iter: 0960/1162
[A[ATraining Step: 1104  | total loss: [1m[32m0.14552[0m[0m | time: 27.468s
[2K
| RMSProp | epoch: 030 | loss: 0.14552 - acc: 0.9468 -- iter: 0992/1162
[A[ATraining Step: 1105  | total loss: [1m[32m0.17287[0m[0m | time: 28.506s
[2K
| RMSProp | epoch: 030 | loss: 0.17287 - acc: 0.9334 -- iter: 1024/1162
[A[ATraining Step: 1106  | total loss: [1m[32m0.15737[0m[0m | time: 29.729s
[2K
| RMSProp | epoch: 030 | loss: 0.15737 - acc: 0.9400 -- iter: 1056/1162
[A[ATraining Step: 1107  | total loss: [1m[32m0.14559[0m[0m | time: 30.776s
[2K
| RMSProp | epoch: 030 | loss: 0.14559 - acc: 0.9460 -- iter: 1088/1162
[A[ATraining Step: 1108  | total loss: [1m[32m0.14697[0m[0m | time: 32.170s
[2K
| RMSProp | epoch: 030 | loss: 0.14697 - acc: 0.9483 -- iter: 1120/1162
[A[ATraining Step: 1109  | total loss: [1m[32m0.13375[0m[0m | time: 33.602s
[2K
| RMSProp | epoch: 030 | loss: 0.13375 - acc: 0.9535 -- iter: 1152/1162
[A[ATraining Step: 1110  | total loss: [1m[32m0.12155[0m[0m | time: 36.827s
[2K
| RMSProp | epoch: 030 | loss: 0.12155 - acc: 0.9581 | val_loss: 0.43187 - val_acc: 0.8654 -- iter: 1162/1162
--
Validation AUC:0.9308574879227053
Validation AUPRC:0.9373361122346412
Test AUC:0.9281767955801105
Test AUPRC:0.9390175072516775
BestTestF1Score	0.86	0.71	0.85	0.85	0.86	157	27	154	26	0.36
BestTestMCCScore	0.86	0.72	0.86	0.89	0.83	151	19	162	32	0.55
BestTestAccuracyScore	0.86	0.72	0.86	0.89	0.83	151	19	162	32	0.55
BestValidationF1Score	0.87	0.74	0.87	0.86	0.87	157	25	159	23	0.36
BestValidationMCC	0.86	0.74	0.87	0.9	0.83	150	17	167	30	0.55
BestValidationAccuracy	0.86	0.74	0.87	0.9	0.83	150	17	167	30	0.55
TestPredictions (Threshold:0.55)
CHEMBL1642271,TN,INACT,0.009999999776482582	CHEMBL1791364,TN,INACT,0.0	CHEMBL1242663,TN,INACT,0.03999999910593033	CHEMBL1642260,TP,ACT,1.0	CHEMBL1683298,TN,INACT,0.0	CHEMBL1828876,TN,INACT,0.0	CHEMBL3115494,TN,INACT,0.009999999776482582	CHEMBL498947,TN,INACT,0.009999999776482582	CHEMBL3218002,FP,INACT,0.949999988079071	CHEMBL58142,TN,INACT,0.009999999776482582	CHEMBL1822525,TP,ACT,1.0	CHEMBL3651850,TP,ACT,1.0	CHEMBL3128069,TP,ACT,1.0	CHEMBL3805129,TP,ACT,0.9900000095367432	CHEMBL236384,TN,INACT,0.0	CHEMBL1651521,TP,ACT,0.9800000190734863	CHEMBL76905,TN,INACT,0.009999999776482582	CHEMBL3687206,TP,ACT,1.0	CHEMBL3806112,FN,ACT,0.3499999940395355	CHEMBL1779185,TP,ACT,0.9900000095367432	CHEMBL1642282,TN,INACT,0.0	CHEMBL3786714,TP,ACT,0.9900000095367432	CHEMBL1944928,TN,INACT,0.029999999329447746	CHEMBL3128061,TP,ACT,0.9900000095367432	CHEMBL1779190,TP,ACT,1.0	CHEMBL1241299,TN,INACT,0.03999999910593033	CHEMBL3358991,TN,INACT,0.029999999329447746	CHEMBL477772,FN,ACT,0.0	CHEMBL1762181,TN,INACT,0.019999999552965164	CHEMBL554,FP,INACT,0.9300000071525574	CHEMBL453336,TN,INACT,0.0	CHEMBL1630578,TN,INACT,0.009999999776482582	CHEMBL474863,TN,INACT,0.0	CHEMBL1796242,TP,ACT,0.7099999785423279	CHEMBL2042830,TP,ACT,0.9900000095367432	CHEMBL128000,TN,INACT,0.05999999865889549	CHEMBL608533,FN,ACT,0.38999998569488525	CHEMBL433507,TN,INACT,0.009999999776482582	CHEMBL3604647,TP,ACT,1.0	CHEMBL404939,TN,INACT,0.47999998927116394	CHEMBL466496,TN,INACT,0.009999999776482582	CHEMBL3286815,TP,ACT,0.9900000095367432	CHEMBL3263991,TP,ACT,1.0	CHEMBL2386794,FN,ACT,0.14000000059604645	CHEMBL543600,TN,INACT,0.05999999865889549	CHEMBL19978,TN,INACT,0.0	CHEMBL602645,FP,INACT,0.800000011920929	CHEMBL2172302,TP,ACT,1.0	CHEMBL1796249,TP,ACT,0.9900000095367432	CHEMBL2335019,TN,INACT,0.009999999776482582	CHEMBL520839,TN,INACT,0.0	CHEMBL3286821,TP,ACT,0.9599999785423279	CHEMBL1163505,TP,ACT,0.8500000238418579	CHEMBL941,FP,INACT,0.8899999856948853	CHEMBL2023544,TP,ACT,0.9700000286102295	CHEMBL486437,TN,INACT,0.0	CHEMBL3651877,TP,ACT,1.0	CHEMBL293250,TN,INACT,0.0	CHEMBL299763,TN,INACT,0.07000000029802322	CHEMBL3651836,TP,ACT,1.0	CHEMBL1088348,TN,INACT,0.0	CHEMBL3128058,TP,ACT,1.0	CHEMBL3785304,TP,ACT,0.9599999785423279	CHEMBL603198,TN,INACT,0.009999999776482582	CHEMBL3735650,TP,ACT,1.0	CHEMBL3687213,TP,ACT,1.0	CHEMBL1641996,TN,INACT,0.0	CHEMBL539433,TN,INACT,0.0	CHEMBL422540,TN,INACT,0.3100000023841858	CHEMBL3218846,TP,ACT,0.9800000190734863	CHEMBL1956891,TN,INACT,0.0	CHEMBL304340,TN,INACT,0.25	CHEMBL1287853,FN,ACT,0.20000000298023224	CHEMBL77242,TN,INACT,0.11999999731779099	CHEMBL3687214,TP,ACT,1.0	CHEMBL18797,TN,INACT,0.15000000596046448	CHEMBL340977,TN,INACT,0.0	CHEMBL602890,TN,INACT,0.0	CHEMBL428690,FN,ACT,0.009999999776482582	CHEMBL1822516,TP,ACT,1.0	CHEMBL2112638,TN,INACT,0.0	CHEMBL3263978,FN,ACT,0.15000000596046448	CHEMBL1084863,TN,INACT,0.0	CHEMBL3651841,TP,ACT,0.9900000095367432	CHEMBL3398173,TP,ACT,1.0	CHEMBL2418763,TP,ACT,1.0	CHEMBL3822557,TP,ACT,1.0	CHEMBL50,FN,ACT,0.25	CHEMBL1790809,TN,INACT,0.009999999776482582	CHEMBL1946614,TP,ACT,0.9900000095367432	CHEMBL3823165,TP,ACT,1.0	CHEMBL3604649,TP,ACT,0.9900000095367432	CHEMBL131653,TN,INACT,0.019999999552965164	CHEMBL2403832,TP,ACT,0.7799999713897705	CHEMBL332497,TN,INACT,0.009999999776482582	CHEMBL557491,FN,ACT,0.009999999776482582	CHEMBL515674,TN,INACT,0.0	CHEMBL3286809,TP,ACT,1.0	CHEMBL3608645,TP,ACT,0.9900000095367432	CHEMBL3824304,TP,ACT,1.0	CHEMBL3604651,TP,ACT,1.0	CHEMBL77068,TN,INACT,0.009999999776482582	CHEMBL3263998,FP,INACT,1.0	CHEMBL304271,TN,INACT,0.0	CHEMBL560733,TP,ACT,0.9399999976158142	CHEMBL456797,TN,INACT,0.029999999329447746	CHEMBL602472,TN,INACT,0.28999999165534973	CHEMBL3687203,TP,ACT,1.0	CHEMBL3823235,TP,ACT,0.9900000095367432	CHEMBL19562,TN,INACT,0.0	CHEMBL1095776,TN,INACT,0.03999999910593033	CHEMBL3128063,TP,ACT,1.0	CHEMBL1940176,TP,ACT,1.0	CHEMBL2023556,TP,ACT,0.9900000095367432	CHEMBL2064722,TP,ACT,0.8899999856948853	CHEMBL1644799,TP,ACT,0.9800000190734863	CHEMBL345862,TN,INACT,0.009999999776482582	CHEMBL2172315,TP,ACT,1.0	CHEMBL1940174,TP,ACT,1.0	CHEMBL142648,TN,INACT,0.009999999776482582	CHEMBL2023552,TP,ACT,1.0	CHEMBL1077085,TN,INACT,0.09000000357627869	CHEMBL3330854,TP,ACT,0.949999988079071	CHEMBL3787598,TP,ACT,1.0	CHEMBL102765,TN,INACT,0.009999999776482582	CHEMBL560446,TP,ACT,0.9800000190734863	CHEMBL77261,TN,INACT,0.2800000011920929	CHEMBL102136,TN,INACT,0.05000000074505806	CHEMBL3805009,TP,ACT,1.0	CHEMBL562943,FN,ACT,0.009999999776482582	CHEMBL574738,FN,ACT,0.0	CHEMBL488645,TN,INACT,0.0	CHEMBL3128070,FN,ACT,0.029999999329447746	CHEMBL66278,TN,INACT,0.0	CHEMBL3286826,TP,ACT,0.9900000095367432	CHEMBL1796184,TN,INACT,0.0	CHEMBL3669145,TP,ACT,0.9700000286102295	CHEMBL3706656,FP,INACT,0.9200000166893005	CHEMBL3608641,TP,ACT,0.9800000190734863	CHEMBL1929312,TN,INACT,0.009999999776482582	CHEMBL3735314,TP,ACT,1.0	CHEMBL3330852,TP,ACT,0.949999988079071	CHEMBL49120,TN,INACT,0.3400000035762787	CHEMBL1642257,TP,ACT,1.0	CHEMBL3824308,TP,ACT,0.8500000238418579	CHEMBL322464,TN,INACT,0.0	CHEMBL335284,TN,INACT,0.0	CHEMBL2418746,TP,ACT,0.9800000190734863	CHEMBL2385543,TN,INACT,0.009999999776482582	CHEMBL3669150,FN,ACT,0.019999999552965164	CHEMBL3651857,TP,ACT,1.0	CHEMBL94581,TN,INACT,0.0	CHEMBL3357446,TP,ACT,1.0	CHEMBL359934,TN,INACT,0.0	CHEMBL2386792,TP,ACT,0.9800000190734863	CHEMBL3669134,TP,ACT,1.0	CHEMBL1822524,TP,ACT,1.0	CHEMBL3669135,TP,ACT,1.0	CHEMBL1779201,TP,ACT,1.0	CHEMBL1170563,FP,INACT,0.8799999952316284	CHEMBL514511,TN,INACT,0.3400000035762787	CHEMBL1221415,TN,INACT,0.0	CHEMBL246166,TN,INACT,0.0	CHEMBL1922120,TN,INACT,0.0	CHEMBL130871,TN,INACT,0.4300000071525574	CHEMBL2172312,TP,ACT,1.0	CHEMBL1922973,TP,ACT,1.0	CHEMBL150825,FP,INACT,0.800000011920929	CHEMBL3735531,TP,ACT,1.0	CHEMBL86480,TN,INACT,0.009999999776482582	CHEMBL3115503,FN,ACT,0.009999999776482582	CHEMBL1487936,FN,ACT,0.05000000074505806	CHEMBL3218848,FN,ACT,0.18000000715255737	CHEMBL1738705,FP,INACT,0.8700000047683716	CHEMBL136289,TN,INACT,0.0	CHEMBL3651865,TP,ACT,1.0	CHEMBL3218849,TP,ACT,0.9200000166893005	CHEMBL1684372,TN,INACT,0.019999999552965164	CHEMBL2023993,TP,ACT,1.0	CHEMBL3398174,TP,ACT,1.0	CHEMBL3398167,TP,ACT,0.9900000095367432	CHEMBL3824185,TP,ACT,1.0	CHEMBL515051,TN,INACT,0.0	CHEMBL3806045,TP,ACT,1.0	CHEMBL1778710,FN,ACT,0.009999999776482582	CHEMBL318188,TN,INACT,0.009999999776482582	CHEMBL3805786,TP,ACT,0.800000011920929	CHEMBL26128,TN,INACT,0.009999999776482582	CHEMBL425615,TN,INACT,0.0	CHEMBL521201,TN,INACT,0.009999999776482582	CHEMBL3651883,TP,ACT,1.0	CHEMBL1958316,TN,INACT,0.5299999713897705	CHEMBL2418748,FN,ACT,0.47999998927116394	CHEMBL87325,TN,INACT,0.0	CHEMBL315546,TN,INACT,0.05000000074505806	CHEMBL277667,FP,INACT,0.8700000047683716	CHEMBL3687196,TP,ACT,1.0	CHEMBL2172325,TP,ACT,1.0	CHEMBL3133834,TN,INACT,0.3499999940395355	CHEMBL3651866,TP,ACT,1.0	CHEMBL20926,TN,INACT,0.019999999552965164	CHEMBL3736273,TP,ACT,1.0	CHEMBL498520,TN,INACT,0.0	CHEMBL3397292,FP,INACT,0.9900000095367432	CHEMBL3397285,TP,ACT,0.9800000190734863	CHEMBL2312645,TN,INACT,0.009999999776482582	CHEMBL1828884,TN,INACT,0.0	CHEMBL246356,FP,INACT,0.9800000190734863	CHEMBL346716,TN,INACT,0.0	CHEMBL2158516,TP,ACT,1.0	CHEMBL3237857,TN,INACT,0.0	CHEMBL1828881,TN,INACT,0.0	CHEMBL2426288,FP,INACT,0.7400000095367432	CHEMBL3780985,TN,INACT,0.0	CHEMBL3286830,TP,ACT,0.7699999809265137	CHEMBL3785093,TP,ACT,1.0	CHEMBL421138,TN,INACT,0.009999999776482582	CHEMBL3651856,TP,ACT,1.0	CHEMBL1242471,TN,INACT,0.03999999910593033	CHEMBL451860,TN,INACT,0.009999999776482582	CHEMBL279481,FP,INACT,0.699999988079071	CHEMBL3358966,TN,INACT,0.0	CHEMBL1668419,FP,INACT,1.0	CHEMBL3330874,TP,ACT,0.7900000214576721	CHEMBL155607,TN,INACT,0.009999999776482582	CHEMBL3735401,TP,ACT,1.0	CHEMBL1778707,FN,ACT,0.009999999776482582	CHEMBL79704,TN,INACT,0.0	CHEMBL1796260,TP,ACT,1.0	CHEMBL529663,TN,INACT,0.029999999329447746	CHEMBL3824301,TP,ACT,1.0	CHEMBL1779191,TP,ACT,0.9900000095367432	CHEMBL3608530,FN,ACT,0.0	CHEMBL2403377,TP,ACT,0.9800000190734863	CHEMBL2386796,TP,ACT,0.8999999761581421	CHEMBL559628,TN,INACT,0.0	CHEMBL3651859,TP,ACT,0.9900000095367432	CHEMBL279193,TN,INACT,0.0	CHEMBL3357463,FN,ACT,0.05999999865889549	CHEMBL453593,TN,INACT,0.009999999776482582	CHEMBL3786148,TP,ACT,1.0	CHEMBL3781538,TN,INACT,0.3799999952316284	CHEMBL1241680,TN,INACT,0.019999999552965164	CHEMBL1241583,TN,INACT,0.009999999776482582	CHEMBL2042983,TP,ACT,1.0	CHEMBL3735648,TP,ACT,1.0	CHEMBL1253945,TN,INACT,0.0	CHEMBL187431,TN,INACT,0.029999999329447746	CHEMBL1779193,TP,ACT,1.0	CHEMBL1241301,TN,INACT,0.05000000074505806	CHEMBL2029693,TN,INACT,0.009999999776482582	CHEMBL3800448,TN,INACT,0.0	CHEMBL208433,FP,INACT,0.9100000262260437	CHEMBL3604635,TP,ACT,1.0	CHEMBL3651880,TP,ACT,1.0	CHEMBL1922978,FN,ACT,0.03999999910593033	CHEMBL1796241,TP,ACT,0.7200000286102295	CHEMBL1779197,TP,ACT,0.9900000095367432	CHEMBL1944930,TN,INACT,0.05999999865889549	CHEMBL76985,TN,INACT,0.019999999552965164	CHEMBL122721,TN,INACT,0.07000000029802322	CHEMBL3805749,TP,ACT,1.0	CHEMBL79177,TN,INACT,0.009999999776482582	CHEMBL1830129,TN,INACT,0.0	CHEMBL1241390,TN,INACT,0.05999999865889549	CHEMBL1171960,FN,ACT,0.5199999809265137	CHEMBL509435,TN,INACT,0.029999999329447746	CHEMBL3824290,TP,ACT,1.0	CHEMBL2023998,TP,ACT,1.0	CHEMBL2158586,TP,ACT,1.0	CHEMBL371095,FP,INACT,0.6399999856948853	CHEMBL201865,TN,INACT,0.3799999952316284	CHEMBL2064396,TN,INACT,0.009999999776482582	CHEMBL1823222,TP,ACT,1.0	CHEMBL2335377,TN,INACT,0.0	CHEMBL241750,TN,INACT,0.0	CHEMBL3608522,TP,ACT,1.0	CHEMBL3286831,TP,ACT,1.0	CHEMBL1779752,TN,INACT,0.07999999821186066	CHEMBL3651854,TP,ACT,1.0	CHEMBL14326,TN,INACT,0.0	CHEMBL2403108,TP,ACT,1.0	CHEMBL1173789,TN,INACT,0.0	CHEMBL405008,TN,INACT,0.0	CHEMBL2418747,TP,ACT,0.9900000095367432	CHEMBL141238,TN,INACT,0.029999999329447746	CHEMBL3608646,FN,ACT,0.12999999523162842	CHEMBL1808107,FN,ACT,0.3499999940395355	CHEMBL3805002,TP,ACT,1.0	CHEMBL1796179,TN,INACT,0.0	CHEMBL1940177,TP,ACT,1.0	CHEMBL1683957,TN,INACT,0.009999999776482582	CHEMBL1922983,FN,ACT,0.5400000214576721	CHEMBL1828880,TN,INACT,0.0	CHEMBL1983268,TP,ACT,1.0	CHEMBL1823220,TP,ACT,1.0	CHEMBL2403366,TP,ACT,0.9700000286102295	CHEMBL3115496,TN,INACT,0.0	CHEMBL1922988,TP,ACT,1.0	CHEMBL1821888,TN,INACT,0.0	CHEMBL160566,TN,INACT,0.0	CHEMBL3687200,TP,ACT,1.0	CHEMBL515109,TN,INACT,0.0	CHEMBL3263982,TP,ACT,1.0	CHEMBL513897,TP,ACT,0.9800000190734863	CHEMBL14762,FN,ACT,0.019999999552965164	CHEMBL1823361,TP,ACT,1.0	CHEMBL3128059,TP,ACT,0.7599999904632568	CHEMBL1922985,TP,ACT,1.0	CHEMBL483234,TN,INACT,0.009999999776482582	CHEMBL207297,TN,INACT,0.009999999776482582	CHEMBL2147259,TN,INACT,0.0	CHEMBL511451,TN,INACT,0.009999999776482582	CHEMBL2403840,TP,ACT,1.0	CHEMBL3133912,TN,INACT,0.0	CHEMBL3115492,TN,INACT,0.009999999776482582	CHEMBL3651831,TP,ACT,1.0	CHEMBL366831,TN,INACT,0.0	CHEMBL1642269,TN,INACT,0.0	CHEMBL3787658,TP,ACT,1.0	CHEMBL2023539,TP,ACT,0.9100000262260437	CHEMBL2178352,TP,ACT,1.0	CHEMBL3608533,FN,ACT,0.36000001430511475	CHEMBL1933736,TN,INACT,0.5	CHEMBL1958319,FP,INACT,0.9599999785423279	CHEMBL456112,TN,INACT,0.009999999776482582	CHEMBL281957,TN,INACT,0.17000000178813934	CHEMBL2064400,TN,INACT,0.36000001430511475	CHEMBL2172313,TP,ACT,1.0	CHEMBL456936,TP,ACT,1.0	CHEMBL55360,TN,INACT,0.07000000029802322	CHEMBL3604645,TP,ACT,1.0	CHEMBL3786831,TP,ACT,1.0	CHEMBL330360,TN,INACT,0.009999999776482582	CHEMBL2172309,TP,ACT,1.0	CHEMBL1945444,TN,INACT,0.0	CHEMBL557525,TN,INACT,0.0	CHEMBL1642264,FN,ACT,0.05000000074505806	CHEMBL3360318,FP,INACT,0.9200000166893005	CHEMBL505253,TN,INACT,0.019999999552965164	CHEMBL1829272,TN,INACT,0.0	CHEMBL2064665,TP,ACT,0.8199999928474426	CHEMBL3822973,TP,ACT,0.7300000190734863	CHEMBL1933756,TN,INACT,0.4699999988079071	CHEMBL3357451,TP,ACT,1.0	CHEMBL3651843,TP,ACT,1.0	CHEMBL558849,TN,INACT,0.0	CHEMBL1684800,FN,ACT,0.0	CHEMBL3806013,FN,ACT,0.44999998807907104	CHEMBL1793896,FN,ACT,0.019999999552965164	CHEMBL1922977,TP,ACT,1.0	CHEMBL560245,TN,INACT,0.0	CHEMBL440213,TN,INACT,0.3199999928474426	CHEMBL3286829,TP,ACT,0.9700000286102295	CHEMBL3785928,TP,ACT,1.0	CHEMBL334539,TN,INACT,0.019999999552965164	CHEMBL3098315,TN,INACT,0.009999999776482582	CHEMBL1077107,TN,INACT,0.009999999776482582	CHEMBL521155,TN,INACT,0.009999999776482582	CHEMBL3608524,TP,ACT,1.0	CHEMBL1933734,TN,INACT,0.09000000357627869	CHEMBL132399,TN,INACT,0.009999999776482582	CHEMBL3687199,TP,ACT,0.9900000095367432	CHEMBL2158512,TP,ACT,1.0	

