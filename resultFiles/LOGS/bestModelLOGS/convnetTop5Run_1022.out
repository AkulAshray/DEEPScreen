CNNModel CHEMBL5491 adam 0.0005 15 128 0 0.6 False True
Number of active compounds :	292
Number of inactive compounds :	292
---------------------------------
Run id: CNNModel_CHEMBL5491_adam_0.0005_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5491_adam_0.0005_15_128_0.6_True/
---------------------------------
Training samples: 373
Validation samples: 117
--
Training Step: 1  | time: 0.766s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/373
[A[ATraining Step: 2  | total loss: [1m[32m0.62396[0m[0m | time: 1.394s
[2K
| Adam | epoch: 001 | loss: 0.62396 - acc: 0.4500 -- iter: 064/373
[A[ATraining Step: 3  | total loss: [1m[32m0.68011[0m[0m | time: 2.005s
[2K
| Adam | epoch: 001 | loss: 0.68011 - acc: 0.5165 -- iter: 096/373
[A[ATraining Step: 4  | total loss: [1m[32m0.69592[0m[0m | time: 2.620s
[2K
| Adam | epoch: 001 | loss: 0.69592 - acc: 0.3635 -- iter: 128/373
[A[ATraining Step: 5  | total loss: [1m[32m0.69348[0m[0m | time: 3.239s
[2K
| Adam | epoch: 001 | loss: 0.69348 - acc: 0.5229 -- iter: 160/373
[A[ATraining Step: 6  | total loss: [1m[32m0.69315[0m[0m | time: 3.851s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.4881 -- iter: 192/373
[A[ATraining Step: 7  | total loss: [1m[32m0.69314[0m[0m | time: 4.482s
[2K
| Adam | epoch: 001 | loss: 0.69314 - acc: 0.5140 -- iter: 224/373
[A[ATraining Step: 8  | total loss: [1m[32m0.69325[0m[0m | time: 5.119s
[2K
| Adam | epoch: 001 | loss: 0.69325 - acc: 0.4710 -- iter: 256/373
[A[ATraining Step: 9  | total loss: [1m[32m0.69328[0m[0m | time: 5.751s
[2K
| Adam | epoch: 001 | loss: 0.69328 - acc: 0.4367 -- iter: 288/373
[A[ATraining Step: 10  | total loss: [1m[32m0.69345[0m[0m | time: 6.369s
[2K
| Adam | epoch: 001 | loss: 0.69345 - acc: 0.4059 -- iter: 320/373
[A[ATraining Step: 11  | total loss: [1m[32m0.69324[0m[0m | time: 6.967s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.4356 -- iter: 352/373
[A[ATraining Step: 12  | total loss: [1m[32m0.69408[0m[0m | time: 8.421s
[2K
| Adam | epoch: 001 | loss: 0.69408 - acc: 0.3662 | val_loss: 0.69330 - val_acc: 0.4786 -- iter: 373/373
--
Training Step: 13  | total loss: [1m[32m0.69342[0m[0m | time: 0.421s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4745 -- iter: 032/373
[A[ATraining Step: 14  | total loss: [1m[32m0.69287[0m[0m | time: 1.019s
[2K
| Adam | epoch: 002 | loss: 0.69287 - acc: 0.5337 -- iter: 064/373
[A[ATraining Step: 15  | total loss: [1m[32m0.69316[0m[0m | time: 1.632s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5083 -- iter: 096/373
[A[ATraining Step: 16  | total loss: [1m[32m0.69333[0m[0m | time: 2.271s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4934 -- iter: 128/373
[A[ATraining Step: 17  | total loss: [1m[32m0.69362[0m[0m | time: 2.917s
[2K
| Adam | epoch: 002 | loss: 0.69362 - acc: 0.4733 -- iter: 160/373
[A[ATraining Step: 18  | total loss: [1m[32m0.69333[0m[0m | time: 3.533s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4934 -- iter: 192/373
[A[ATraining Step: 19  | total loss: [1m[32m0.69299[0m[0m | time: 4.140s
[2K
| Adam | epoch: 002 | loss: 0.69299 - acc: 0.5164 -- iter: 224/373
[A[ATraining Step: 20  | total loss: [1m[32m0.69304[0m[0m | time: 4.754s
[2K
| Adam | epoch: 002 | loss: 0.69304 - acc: 0.5111 -- iter: 256/373
[A[ATraining Step: 21  | total loss: [1m[32m0.69321[0m[0m | time: 5.358s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4883 -- iter: 288/373
[A[ATraining Step: 22  | total loss: [1m[32m0.69322[0m[0m | time: 5.960s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4824 -- iter: 320/373
[A[ATraining Step: 23  | total loss: [1m[32m0.69310[0m[0m | time: 6.563s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.4966 -- iter: 352/373
[A[ATraining Step: 24  | total loss: [1m[32m0.69304[0m[0m | time: 8.176s
[2K
| Adam | epoch: 002 | loss: 0.69304 - acc: 0.4976 | val_loss: 0.69331 - val_acc: 0.4786 -- iter: 373/373
--
Training Step: 25  | total loss: [1m[32m0.69283[0m[0m | time: 0.443s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5238 -- iter: 032/373
[A[ATraining Step: 26  | total loss: [1m[32m0.69312[0m[0m | time: 0.872s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.4986 -- iter: 064/373
[A[ATraining Step: 27  | total loss: [1m[32m0.69329[0m[0m | time: 1.508s
[2K
| Adam | epoch: 003 | loss: 0.69329 - acc: 0.4806 -- iter: 096/373
[A[ATraining Step: 28  | total loss: [1m[32m0.69344[0m[0m | time: 2.121s
[2K
| Adam | epoch: 003 | loss: 0.69344 - acc: 0.4620 -- iter: 128/373
[A[ATraining Step: 29  | total loss: [1m[32m0.69321[0m[0m | time: 2.755s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.4788 -- iter: 160/373
[A[ATraining Step: 30  | total loss: [1m[32m0.69306[0m[0m | time: 3.376s
[2K
| Adam | epoch: 003 | loss: 0.69306 - acc: 0.5135 -- iter: 192/373
[A[ATraining Step: 31  | total loss: [1m[32m0.69292[0m[0m | time: 3.987s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5464 -- iter: 224/373
[A[ATraining Step: 32  | total loss: [1m[32m0.69270[0m[0m | time: 4.624s
[2K
| Adam | epoch: 003 | loss: 0.69270 - acc: 0.5571 -- iter: 256/373
[A[ATraining Step: 33  | total loss: [1m[32m0.69275[0m[0m | time: 5.234s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5377 -- iter: 288/373
[A[ATraining Step: 34  | total loss: [1m[32m0.69287[0m[0m | time: 5.860s
[2K
| Adam | epoch: 003 | loss: 0.69287 - acc: 0.5162 -- iter: 320/373
[A[ATraining Step: 35  | total loss: [1m[32m0.69244[0m[0m | time: 6.481s
[2K
| Adam | epoch: 003 | loss: 0.69244 - acc: 0.5324 -- iter: 352/373
[A[ATraining Step: 36  | total loss: [1m[32m0.69229[0m[0m | time: 8.106s
[2K
| Adam | epoch: 003 | loss: 0.69229 - acc: 0.5322 | val_loss: 0.69299 - val_acc: 0.4786 -- iter: 373/373
--
Training Step: 37  | total loss: [1m[32m0.69192[0m[0m | time: 0.637s
[2K
| Adam | epoch: 004 | loss: 0.69192 - acc: 0.5383 -- iter: 032/373
[A[ATraining Step: 38  | total loss: [1m[32m0.69165[0m[0m | time: 1.060s
[2K
| Adam | epoch: 004 | loss: 0.69165 - acc: 0.5369 -- iter: 064/373
[A[ATraining Step: 39  | total loss: [1m[32m0.69245[0m[0m | time: 1.476s
[2K
| Adam | epoch: 004 | loss: 0.69245 - acc: 0.5161 -- iter: 096/373
[A[ATraining Step: 40  | total loss: [1m[32m0.69253[0m[0m | time: 2.083s
[2K
| Adam | epoch: 004 | loss: 0.69253 - acc: 0.4997 -- iter: 128/373
[A[ATraining Step: 41  | total loss: [1m[32m0.69241[0m[0m | time: 2.698s
[2K
| Adam | epoch: 004 | loss: 0.69241 - acc: 0.5342 -- iter: 160/373
[A[ATraining Step: 42  | total loss: [1m[32m0.69242[0m[0m | time: 3.314s
[2K
| Adam | epoch: 004 | loss: 0.69242 - acc: 0.5337 -- iter: 192/373
[A[ATraining Step: 43  | total loss: [1m[32m0.69278[0m[0m | time: 3.919s
[2K
| Adam | epoch: 004 | loss: 0.69278 - acc: 0.5167 -- iter: 224/373
[A[ATraining Step: 44  | total loss: [1m[32m0.69384[0m[0m | time: 4.522s
[2K
| Adam | epoch: 004 | loss: 0.69384 - acc: 0.4814 -- iter: 256/373
[A[ATraining Step: 45  | total loss: [1m[32m0.69286[0m[0m | time: 5.125s
[2K
| Adam | epoch: 004 | loss: 0.69286 - acc: 0.5111 -- iter: 288/373
[A[ATraining Step: 46  | total loss: [1m[32m0.69253[0m[0m | time: 5.727s
[2K
| Adam | epoch: 004 | loss: 0.69253 - acc: 0.5248 -- iter: 320/373
[A[ATraining Step: 47  | total loss: [1m[32m0.69189[0m[0m | time: 6.351s
[2K
| Adam | epoch: 004 | loss: 0.69189 - acc: 0.5770 -- iter: 352/373
[A[ATraining Step: 48  | total loss: [1m[32m0.69213[0m[0m | time: 7.953s
[2K
| Adam | epoch: 004 | loss: 0.69213 - acc: 0.5496 | val_loss: 0.68910 - val_acc: 0.6581 -- iter: 373/373
--
Training Step: 49  | total loss: [1m[32m0.69141[0m[0m | time: 0.619s
[2K
| Adam | epoch: 005 | loss: 0.69141 - acc: 0.5615 -- iter: 032/373
[A[ATraining Step: 50  | total loss: [1m[32m0.69105[0m[0m | time: 1.225s
[2K
| Adam | epoch: 005 | loss: 0.69105 - acc: 0.5762 -- iter: 064/373
[A[ATraining Step: 51  | total loss: [1m[32m0.69038[0m[0m | time: 1.643s
[2K
| Adam | epoch: 005 | loss: 0.69038 - acc: 0.5836 -- iter: 096/373
[A[ATraining Step: 52  | total loss: [1m[32m0.68973[0m[0m | time: 2.057s
[2K
| Adam | epoch: 005 | loss: 0.68973 - acc: 0.5961 -- iter: 128/373
[A[ATraining Step: 53  | total loss: [1m[32m0.68736[0m[0m | time: 2.694s
[2K
| Adam | epoch: 005 | loss: 0.68736 - acc: 0.6416 -- iter: 160/373
[A[ATraining Step: 54  | total loss: [1m[32m0.68681[0m[0m | time: 3.304s
[2K
| Adam | epoch: 005 | loss: 0.68681 - acc: 0.6256 -- iter: 192/373
[A[ATraining Step: 55  | total loss: [1m[32m0.68858[0m[0m | time: 3.910s
[2K
| Adam | epoch: 005 | loss: 0.68858 - acc: 0.5987 -- iter: 224/373
[A[ATraining Step: 56  | total loss: [1m[32m0.68528[0m[0m | time: 4.509s
[2K
| Adam | epoch: 005 | loss: 0.68528 - acc: 0.5980 -- iter: 256/373
[A[ATraining Step: 57  | total loss: [1m[32m0.68779[0m[0m | time: 5.119s
[2K
| Adam | epoch: 005 | loss: 0.68779 - acc: 0.5758 -- iter: 288/373
[A[ATraining Step: 58  | total loss: [1m[32m0.68446[0m[0m | time: 5.721s
[2K
| Adam | epoch: 005 | loss: 0.68446 - acc: 0.5740 -- iter: 320/373
[A[ATraining Step: 59  | total loss: [1m[32m0.68168[0m[0m | time: 6.333s
[2K
| Adam | epoch: 005 | loss: 0.68168 - acc: 0.5808 -- iter: 352/373
[A[ATraining Step: 60  | total loss: [1m[32m0.67772[0m[0m | time: 7.942s
[2K
| Adam | epoch: 005 | loss: 0.67772 - acc: 0.6198 | val_loss: 0.66836 - val_acc: 0.5812 -- iter: 373/373
--
Training Step: 61  | total loss: [1m[32m0.67496[0m[0m | time: 0.647s
[2K
| Adam | epoch: 006 | loss: 0.67496 - acc: 0.6286 -- iter: 032/373
[A[ATraining Step: 62  | total loss: [1m[32m0.67342[0m[0m | time: 1.263s
[2K
| Adam | epoch: 006 | loss: 0.67342 - acc: 0.6201 -- iter: 064/373
[A[ATraining Step: 63  | total loss: [1m[32m0.66642[0m[0m | time: 1.875s
[2K
| Adam | epoch: 006 | loss: 0.66642 - acc: 0.6405 -- iter: 096/373
[A[ATraining Step: 64  | total loss: [1m[32m0.66314[0m[0m | time: 2.321s
[2K
| Adam | epoch: 006 | loss: 0.66314 - acc: 0.6620 -- iter: 128/373
[A[ATraining Step: 65  | total loss: [1m[32m0.64738[0m[0m | time: 2.736s
[2K
| Adam | epoch: 006 | loss: 0.64738 - acc: 0.6861 -- iter: 160/373
[A[ATraining Step: 66  | total loss: [1m[32m0.62901[0m[0m | time: 3.347s
[2K
| Adam | epoch: 006 | loss: 0.62901 - acc: 0.7011 -- iter: 192/373
[A[ATraining Step: 67  | total loss: [1m[32m0.61642[0m[0m | time: 3.953s
[2K
| Adam | epoch: 006 | loss: 0.61642 - acc: 0.7107 -- iter: 224/373
[A[ATraining Step: 68  | total loss: [1m[32m0.61337[0m[0m | time: 4.556s
[2K
| Adam | epoch: 006 | loss: 0.61337 - acc: 0.7080 -- iter: 256/373
[A[ATraining Step: 69  | total loss: [1m[32m0.60937[0m[0m | time: 5.168s
[2K
| Adam | epoch: 006 | loss: 0.60937 - acc: 0.7019 -- iter: 288/373
[A[ATraining Step: 70  | total loss: [1m[32m0.65088[0m[0m | time: 5.771s
[2K
| Adam | epoch: 006 | loss: 0.65088 - acc: 0.6750 -- iter: 320/373
[A[ATraining Step: 71  | total loss: [1m[32m0.70353[0m[0m | time: 6.382s
[2K
| Adam | epoch: 006 | loss: 0.70353 - acc: 0.6515 -- iter: 352/373
[A[ATraining Step: 72  | total loss: [1m[32m0.71754[0m[0m | time: 8.000s
[2K
| Adam | epoch: 006 | loss: 0.71754 - acc: 0.6345 | val_loss: 0.64769 - val_acc: 0.6410 -- iter: 373/373
--
Training Step: 73  | total loss: [1m[32m0.69145[0m[0m | time: 0.610s
[2K
| Adam | epoch: 007 | loss: 0.69145 - acc: 0.6438 -- iter: 032/373
[A[ATraining Step: 74  | total loss: [1m[32m0.68286[0m[0m | time: 1.221s
[2K
| Adam | epoch: 007 | loss: 0.68286 - acc: 0.6521 -- iter: 064/373
[A[ATraining Step: 75  | total loss: [1m[32m0.66676[0m[0m | time: 1.838s
[2K
| Adam | epoch: 007 | loss: 0.66676 - acc: 0.6593 -- iter: 096/373
[A[ATraining Step: 76  | total loss: [1m[32m0.65153[0m[0m | time: 2.457s
[2K
| Adam | epoch: 007 | loss: 0.65153 - acc: 0.6623 -- iter: 128/373
[A[ATraining Step: 77  | total loss: [1m[32m0.64092[0m[0m | time: 2.883s
[2K
| Adam | epoch: 007 | loss: 0.64092 - acc: 0.6749 -- iter: 160/373
[A[ATraining Step: 78  | total loss: [1m[32m0.62361[0m[0m | time: 3.315s
[2K
| Adam | epoch: 007 | loss: 0.62361 - acc: 0.6940 -- iter: 192/373
[A[ATraining Step: 79  | total loss: [1m[32m0.60795[0m[0m | time: 3.920s
[2K
| Adam | epoch: 007 | loss: 0.60795 - acc: 0.7109 -- iter: 224/373
[A[ATraining Step: 80  | total loss: [1m[32m0.59476[0m[0m | time: 4.538s
[2K
| Adam | epoch: 007 | loss: 0.59476 - acc: 0.7213 -- iter: 256/373
[A[ATraining Step: 81  | total loss: [1m[32m0.58015[0m[0m | time: 5.148s
[2K
| Adam | epoch: 007 | loss: 0.58015 - acc: 0.7368 -- iter: 288/373
[A[ATraining Step: 82  | total loss: [1m[32m0.56285[0m[0m | time: 5.768s
[2K
| Adam | epoch: 007 | loss: 0.56285 - acc: 0.7537 -- iter: 320/373
[A[ATraining Step: 83  | total loss: [1m[32m0.55907[0m[0m | time: 6.379s
[2K
| Adam | epoch: 007 | loss: 0.55907 - acc: 0.7596 -- iter: 352/373
[A[ATraining Step: 84  | total loss: [1m[32m0.55153[0m[0m | time: 7.980s
[2K
| Adam | epoch: 007 | loss: 0.55153 - acc: 0.7587 | val_loss: 0.61419 - val_acc: 0.7265 -- iter: 373/373
--
Training Step: 85  | total loss: [1m[32m0.53730[0m[0m | time: 0.618s
[2K
| Adam | epoch: 008 | loss: 0.53730 - acc: 0.7609 -- iter: 032/373
[A[ATraining Step: 86  | total loss: [1m[32m0.54675[0m[0m | time: 1.236s
[2K
| Adam | epoch: 008 | loss: 0.54675 - acc: 0.7598 -- iter: 064/373
[A[ATraining Step: 87  | total loss: [1m[32m0.53131[0m[0m | time: 1.881s
[2K
| Adam | epoch: 008 | loss: 0.53131 - acc: 0.7682 -- iter: 096/373
[A[ATraining Step: 88  | total loss: [1m[32m0.53679[0m[0m | time: 2.490s
[2K
| Adam | epoch: 008 | loss: 0.53679 - acc: 0.7570 -- iter: 128/373
[A[ATraining Step: 89  | total loss: [1m[32m0.52628[0m[0m | time: 3.117s
[2K
| Adam | epoch: 008 | loss: 0.52628 - acc: 0.7657 -- iter: 160/373
[A[ATraining Step: 90  | total loss: [1m[32m0.52165[0m[0m | time: 3.537s
[2K
| Adam | epoch: 008 | loss: 0.52165 - acc: 0.7735 -- iter: 192/373
[A[ATraining Step: 91  | total loss: [1m[32m0.50458[0m[0m | time: 3.960s
[2K
| Adam | epoch: 008 | loss: 0.50458 - acc: 0.7819 -- iter: 224/373
[A[ATraining Step: 92  | total loss: [1m[32m0.49115[0m[0m | time: 4.561s
[2K
| Adam | epoch: 008 | loss: 0.49115 - acc: 0.7894 -- iter: 256/373
[A[ATraining Step: 93  | total loss: [1m[32m0.48295[0m[0m | time: 5.169s
[2K
| Adam | epoch: 008 | loss: 0.48295 - acc: 0.7948 -- iter: 288/373
[A[ATraining Step: 94  | total loss: [1m[32m0.47457[0m[0m | time: 5.785s
[2K
| Adam | epoch: 008 | loss: 0.47457 - acc: 0.7935 -- iter: 320/373
[A[ATraining Step: 95  | total loss: [1m[32m0.46029[0m[0m | time: 6.427s
[2K
| Adam | epoch: 008 | loss: 0.46029 - acc: 0.8016 -- iter: 352/373
[A[ATraining Step: 96  | total loss: [1m[32m0.45185[0m[0m | time: 8.031s
[2K
| Adam | epoch: 008 | loss: 0.45185 - acc: 0.7996 | val_loss: 0.53728 - val_acc: 0.8034 -- iter: 373/373
--
Training Step: 97  | total loss: [1m[32m0.43795[0m[0m | time: 0.621s
[2K
| Adam | epoch: 009 | loss: 0.43795 - acc: 0.8103 -- iter: 032/373
[A[ATraining Step: 98  | total loss: [1m[32m0.42196[0m[0m | time: 1.227s
[2K
| Adam | epoch: 009 | loss: 0.42196 - acc: 0.8199 -- iter: 064/373
[A[ATraining Step: 99  | total loss: [1m[32m0.41687[0m[0m | time: 1.867s
[2K
| Adam | epoch: 009 | loss: 0.41687 - acc: 0.8254 -- iter: 096/373
[A[ATraining Step: 100  | total loss: [1m[32m0.41040[0m[0m | time: 2.492s
[2K
| Adam | epoch: 009 | loss: 0.41040 - acc: 0.8335 -- iter: 128/373
[A[ATraining Step: 101  | total loss: [1m[32m0.40751[0m[0m | time: 3.134s
[2K
| Adam | epoch: 009 | loss: 0.40751 - acc: 0.8376 -- iter: 160/373
[A[ATraining Step: 102  | total loss: [1m[32m0.39669[0m[0m | time: 3.763s
[2K
| Adam | epoch: 009 | loss: 0.39669 - acc: 0.8445 -- iter: 192/373
[A[ATraining Step: 103  | total loss: [1m[32m0.39829[0m[0m | time: 4.173s
[2K
| Adam | epoch: 009 | loss: 0.39829 - acc: 0.8444 -- iter: 224/373
[A[ATraining Step: 104  | total loss: [1m[32m0.38173[0m[0m | time: 4.596s
[2K
| Adam | epoch: 009 | loss: 0.38173 - acc: 0.8600 -- iter: 256/373
[A[ATraining Step: 105  | total loss: [1m[32m0.36224[0m[0m | time: 5.218s
[2K
| Adam | epoch: 009 | loss: 0.36224 - acc: 0.8692 -- iter: 288/373
[A[ATraining Step: 106  | total loss: [1m[32m0.37319[0m[0m | time: 5.835s
[2K
| Adam | epoch: 009 | loss: 0.37319 - acc: 0.8573 -- iter: 320/373
[A[ATraining Step: 107  | total loss: [1m[32m0.35952[0m[0m | time: 6.450s
[2K
| Adam | epoch: 009 | loss: 0.35952 - acc: 0.8622 -- iter: 352/373
[A[ATraining Step: 108  | total loss: [1m[32m0.35792[0m[0m | time: 8.086s
[2K
| Adam | epoch: 009 | loss: 0.35792 - acc: 0.8572 | val_loss: 0.55315 - val_acc: 0.7265 -- iter: 373/373
--
Training Step: 109  | total loss: [1m[32m0.33917[0m[0m | time: 0.622s
[2K
| Adam | epoch: 010 | loss: 0.33917 - acc: 0.8684 -- iter: 032/373
[A[ATraining Step: 110  | total loss: [1m[32m0.33413[0m[0m | time: 1.249s
[2K
| Adam | epoch: 010 | loss: 0.33413 - acc: 0.8722 -- iter: 064/373
[A[ATraining Step: 111  | total loss: [1m[32m0.33991[0m[0m | time: 1.859s
[2K
| Adam | epoch: 010 | loss: 0.33991 - acc: 0.8662 -- iter: 096/373
[A[ATraining Step: 112  | total loss: [1m[32m0.33387[0m[0m | time: 2.466s
[2K
| Adam | epoch: 010 | loss: 0.33387 - acc: 0.8671 -- iter: 128/373
[A[ATraining Step: 113  | total loss: [1m[32m0.31476[0m[0m | time: 3.080s
[2K
| Adam | epoch: 010 | loss: 0.31476 - acc: 0.8772 -- iter: 160/373
[A[ATraining Step: 114  | total loss: [1m[32m0.31927[0m[0m | time: 3.697s
[2K
| Adam | epoch: 010 | loss: 0.31927 - acc: 0.8770 -- iter: 192/373
[A[ATraining Step: 115  | total loss: [1m[32m0.32720[0m[0m | time: 4.304s
[2K
| Adam | epoch: 010 | loss: 0.32720 - acc: 0.8643 -- iter: 224/373
[A[ATraining Step: 116  | total loss: [1m[32m0.31266[0m[0m | time: 4.732s
[2K
| Adam | epoch: 010 | loss: 0.31266 - acc: 0.8716 -- iter: 256/373
[A[ATraining Step: 117  | total loss: [1m[32m0.30211[0m[0m | time: 5.149s
[2K
| Adam | epoch: 010 | loss: 0.30211 - acc: 0.8749 -- iter: 288/373
[A[ATraining Step: 118  | total loss: [1m[32m0.29889[0m[0m | time: 5.766s
[2K
| Adam | epoch: 010 | loss: 0.29889 - acc: 0.8732 -- iter: 320/373
[A[ATraining Step: 119  | total loss: [1m[32m0.31117[0m[0m | time: 6.380s
[2K
| Adam | epoch: 010 | loss: 0.31117 - acc: 0.8640 -- iter: 352/373
[A[ATraining Step: 120  | total loss: [1m[32m0.32157[0m[0m | time: 8.009s
[2K
| Adam | epoch: 010 | loss: 0.32157 - acc: 0.8651 | val_loss: 0.54740 - val_acc: 0.7521 -- iter: 373/373
--
Training Step: 121  | total loss: [1m[32m0.30495[0m[0m | time: 0.612s
[2K
| Adam | epoch: 011 | loss: 0.30495 - acc: 0.8754 -- iter: 032/373
[A[ATraining Step: 122  | total loss: [1m[32m0.30722[0m[0m | time: 1.227s
[2K
| Adam | epoch: 011 | loss: 0.30722 - acc: 0.8723 -- iter: 064/373
[A[ATraining Step: 123  | total loss: [1m[32m0.31820[0m[0m | time: 1.823s
[2K
| Adam | epoch: 011 | loss: 0.31820 - acc: 0.8663 -- iter: 096/373
[A[ATraining Step: 124  | total loss: [1m[32m0.31314[0m[0m | time: 2.463s
[2K
| Adam | epoch: 011 | loss: 0.31314 - acc: 0.8672 -- iter: 128/373
[A[ATraining Step: 125  | total loss: [1m[32m0.29222[0m[0m | time: 3.100s
[2K
| Adam | epoch: 011 | loss: 0.29222 - acc: 0.8804 -- iter: 160/373
[A[ATraining Step: 126  | total loss: [1m[32m0.28165[0m[0m | time: 3.708s
[2K
| Adam | epoch: 011 | loss: 0.28165 - acc: 0.8893 -- iter: 192/373
[A[ATraining Step: 127  | total loss: [1m[32m0.27883[0m[0m | time: 4.306s
[2K
| Adam | epoch: 011 | loss: 0.27883 - acc: 0.8941 -- iter: 224/373
[A[ATraining Step: 128  | total loss: [1m[32m0.26341[0m[0m | time: 4.913s
[2K
| Adam | epoch: 011 | loss: 0.26341 - acc: 0.9016 -- iter: 256/373
[A[ATraining Step: 129  | total loss: [1m[32m0.25945[0m[0m | time: 5.333s
[2K
| Adam | epoch: 011 | loss: 0.25945 - acc: 0.9020 -- iter: 288/373
[A[ATraining Step: 130  | total loss: [1m[32m0.25133[0m[0m | time: 5.757s
[2K
| Adam | epoch: 011 | loss: 0.25133 - acc: 0.9071 -- iter: 320/373
[A[ATraining Step: 131  | total loss: [1m[32m0.24244[0m[0m | time: 6.355s
[2K
| Adam | epoch: 011 | loss: 0.24244 - acc: 0.9116 -- iter: 352/373
[A[ATraining Step: 132  | total loss: [1m[32m0.23662[0m[0m | time: 7.960s
[2K
| Adam | epoch: 011 | loss: 0.23662 - acc: 0.9142 | val_loss: 0.34863 - val_acc: 0.8547 -- iter: 373/373
--
Training Step: 133  | total loss: [1m[32m0.23841[0m[0m | time: 0.624s
[2K
| Adam | epoch: 012 | loss: 0.23841 - acc: 0.9165 -- iter: 032/373
[A[ATraining Step: 134  | total loss: [1m[32m0.22802[0m[0m | time: 1.227s
[2K
| Adam | epoch: 012 | loss: 0.22802 - acc: 0.9186 -- iter: 064/373
[A[ATraining Step: 135  | total loss: [1m[32m0.21574[0m[0m | time: 1.851s
[2K
| Adam | epoch: 012 | loss: 0.21574 - acc: 0.9268 -- iter: 096/373
[A[ATraining Step: 136  | total loss: [1m[32m0.21732[0m[0m | time: 2.466s
[2K
| Adam | epoch: 012 | loss: 0.21732 - acc: 0.9216 -- iter: 128/373
[A[ATraining Step: 137  | total loss: [1m[32m0.21693[0m[0m | time: 3.123s
[2K
| Adam | epoch: 012 | loss: 0.21693 - acc: 0.9232 -- iter: 160/373
[A[ATraining Step: 138  | total loss: [1m[32m0.20100[0m[0m | time: 3.724s
[2K
| Adam | epoch: 012 | loss: 0.20100 - acc: 0.9309 -- iter: 192/373
[A[ATraining Step: 139  | total loss: [1m[32m0.18616[0m[0m | time: 4.361s
[2K
| Adam | epoch: 012 | loss: 0.18616 - acc: 0.9378 -- iter: 224/373
[A[ATraining Step: 140  | total loss: [1m[32m0.18986[0m[0m | time: 4.962s
[2K
| Adam | epoch: 012 | loss: 0.18986 - acc: 0.9377 -- iter: 256/373
[A[ATraining Step: 141  | total loss: [1m[32m0.19070[0m[0m | time: 5.580s
[2K
| Adam | epoch: 012 | loss: 0.19070 - acc: 0.9408 -- iter: 288/373
[A[ATraining Step: 142  | total loss: [1m[32m0.18034[0m[0m | time: 5.998s
[2K
| Adam | epoch: 012 | loss: 0.18034 - acc: 0.9468 -- iter: 320/373
[A[ATraining Step: 143  | total loss: [1m[32m0.16840[0m[0m | time: 6.421s
[2K
| Adam | epoch: 012 | loss: 0.16840 - acc: 0.9521 -- iter: 352/373
[A[ATraining Step: 144  | total loss: [1m[32m0.16008[0m[0m | time: 8.020s
[2K
| Adam | epoch: 012 | loss: 0.16008 - acc: 0.9569 | val_loss: 0.41496 - val_acc: 0.8718 -- iter: 373/373
--
Training Step: 145  | total loss: [1m[32m0.17430[0m[0m | time: 0.615s
[2K
| Adam | epoch: 013 | loss: 0.17430 - acc: 0.9518 -- iter: 032/373
[A[ATraining Step: 146  | total loss: [1m[32m0.17304[0m[0m | time: 1.220s
[2K
| Adam | epoch: 013 | loss: 0.17304 - acc: 0.9504 -- iter: 064/373
[A[ATraining Step: 147  | total loss: [1m[32m0.16700[0m[0m | time: 1.819s
[2K
| Adam | epoch: 013 | loss: 0.16700 - acc: 0.9491 -- iter: 096/373
[A[ATraining Step: 148  | total loss: [1m[32m0.17572[0m[0m | time: 2.435s
[2K
| Adam | epoch: 013 | loss: 0.17572 - acc: 0.9417 -- iter: 128/373
[A[ATraining Step: 149  | total loss: [1m[32m0.16153[0m[0m | time: 3.049s
[2K
| Adam | epoch: 013 | loss: 0.16153 - acc: 0.9475 -- iter: 160/373
[A[ATraining Step: 150  | total loss: [1m[32m0.17680[0m[0m | time: 3.681s
[2K
| Adam | epoch: 013 | loss: 0.17680 - acc: 0.9434 -- iter: 192/373
[A[ATraining Step: 151  | total loss: [1m[32m0.16707[0m[0m | time: 4.269s
[2K
| Adam | epoch: 013 | loss: 0.16707 - acc: 0.9491 -- iter: 224/373
[A[ATraining Step: 152  | total loss: [1m[32m0.15928[0m[0m | time: 4.885s
[2K
| Adam | epoch: 013 | loss: 0.15928 - acc: 0.9479 -- iter: 256/373
[A[ATraining Step: 153  | total loss: [1m[32m0.15827[0m[0m | time: 5.486s
[2K
| Adam | epoch: 013 | loss: 0.15827 - acc: 0.9437 -- iter: 288/373
[A[ATraining Step: 154  | total loss: [1m[32m0.16222[0m[0m | time: 6.102s
[2K
| Adam | epoch: 013 | loss: 0.16222 - acc: 0.9431 -- iter: 320/373
[A[ATraining Step: 155  | total loss: [1m[32m0.15445[0m[0m | time: 6.529s
[2K
| Adam | epoch: 013 | loss: 0.15445 - acc: 0.9457 -- iter: 352/373
[A[ATraining Step: 156  | total loss: [1m[32m0.15148[0m[0m | time: 7.952s
[2K
| Adam | epoch: 013 | loss: 0.15148 - acc: 0.9463 | val_loss: 0.39127 - val_acc: 0.8547 -- iter: 373/373
--
Training Step: 157  | total loss: [1m[32m0.15083[0m[0m | time: 0.620s
[2K
| Adam | epoch: 014 | loss: 0.15083 - acc: 0.9469 -- iter: 032/373
[A[ATraining Step: 158  | total loss: [1m[32m0.14311[0m[0m | time: 1.233s
[2K
| Adam | epoch: 014 | loss: 0.14311 - acc: 0.9491 -- iter: 064/373
[A[ATraining Step: 159  | total loss: [1m[32m0.13178[0m[0m | time: 1.851s
[2K
| Adam | epoch: 014 | loss: 0.13178 - acc: 0.9542 -- iter: 096/373
[A[ATraining Step: 160  | total loss: [1m[32m0.12382[0m[0m | time: 2.485s
[2K
| Adam | epoch: 014 | loss: 0.12382 - acc: 0.9588 -- iter: 128/373
[A[ATraining Step: 161  | total loss: [1m[32m0.11933[0m[0m | time: 3.096s
[2K
| Adam | epoch: 014 | loss: 0.11933 - acc: 0.9598 -- iter: 160/373
[A[ATraining Step: 162  | total loss: [1m[32m0.11778[0m[0m | time: 3.710s
[2K
| Adam | epoch: 014 | loss: 0.11778 - acc: 0.9607 -- iter: 192/373
[A[ATraining Step: 163  | total loss: [1m[32m0.12832[0m[0m | time: 4.349s
[2K
| Adam | epoch: 014 | loss: 0.12832 - acc: 0.9584 -- iter: 224/373
[A[ATraining Step: 164  | total loss: [1m[32m0.12189[0m[0m | time: 4.955s
[2K
| Adam | epoch: 014 | loss: 0.12189 - acc: 0.9625 -- iter: 256/373
[A[ATraining Step: 165  | total loss: [1m[32m0.11321[0m[0m | time: 5.566s
[2K
| Adam | epoch: 014 | loss: 0.11321 - acc: 0.9663 -- iter: 288/373
[A[ATraining Step: 166  | total loss: [1m[32m0.10444[0m[0m | time: 6.211s
[2K
| Adam | epoch: 014 | loss: 0.10444 - acc: 0.9696 -- iter: 320/373
[A[ATraining Step: 167  | total loss: [1m[32m0.09903[0m[0m | time: 6.820s
[2K
| Adam | epoch: 014 | loss: 0.09903 - acc: 0.9696 -- iter: 352/373
[A[ATraining Step: 168  | total loss: [1m[32m0.09665[0m[0m | time: 8.258s
[2K
| Adam | epoch: 014 | loss: 0.09665 - acc: 0.9695 | val_loss: 0.34148 - val_acc: 0.8547 -- iter: 373/373
--
Training Step: 169  | total loss: [1m[32m0.11045[0m[0m | time: 0.439s
[2K
| Adam | epoch: 015 | loss: 0.11045 - acc: 0.9678 -- iter: 032/373
[A[ATraining Step: 170  | total loss: [1m[32m0.12473[0m[0m | time: 1.039s
[2K
| Adam | epoch: 015 | loss: 0.12473 - acc: 0.9662 -- iter: 064/373
[A[ATraining Step: 171  | total loss: [1m[32m0.11630[0m[0m | time: 1.674s
[2K
| Adam | epoch: 015 | loss: 0.11630 - acc: 0.9696 -- iter: 096/373
[A[ATraining Step: 172  | total loss: [1m[32m0.11220[0m[0m | time: 2.292s
[2K
| Adam | epoch: 015 | loss: 0.11220 - acc: 0.9695 -- iter: 128/373
[A[ATraining Step: 173  | total loss: [1m[32m0.10575[0m[0m | time: 2.896s
[2K
| Adam | epoch: 015 | loss: 0.10575 - acc: 0.9694 -- iter: 160/373
[A[ATraining Step: 174  | total loss: [1m[32m0.10272[0m[0m | time: 3.504s
[2K
| Adam | epoch: 015 | loss: 0.10272 - acc: 0.9694 -- iter: 192/373
[A[ATraining Step: 175  | total loss: [1m[32m0.10507[0m[0m | time: 4.108s
[2K
| Adam | epoch: 015 | loss: 0.10507 - acc: 0.9631 -- iter: 224/373
[A[ATraining Step: 176  | total loss: [1m[32m0.09711[0m[0m | time: 4.716s
[2K
| Adam | epoch: 015 | loss: 0.09711 - acc: 0.9668 -- iter: 256/373
[A[ATraining Step: 177  | total loss: [1m[32m0.08970[0m[0m | time: 5.315s
[2K
| Adam | epoch: 015 | loss: 0.08970 - acc: 0.9701 -- iter: 288/373
[A[ATraining Step: 178  | total loss: [1m[32m0.08320[0m[0m | time: 5.930s
[2K
| Adam | epoch: 015 | loss: 0.08320 - acc: 0.9731 -- iter: 320/373
[A[ATraining Step: 179  | total loss: [1m[32m0.07817[0m[0m | time: 6.537s
[2K
| Adam | epoch: 015 | loss: 0.07817 - acc: 0.9758 -- iter: 352/373
[A[ATraining Step: 180  | total loss: [1m[32m0.07997[0m[0m | time: 8.152s
[2K
| Adam | epoch: 015 | loss: 0.07997 - acc: 0.9751 | val_loss: 0.47382 - val_acc: 0.8803 -- iter: 373/373
--
Validation AUC:0.9326697892271663
Validation AUPRC:0.9449406573766608
Test AUC:0.964327485380117
Test AUPRC:0.9644376136373889
BestTestF1Score	0.93	0.85	0.92	0.92	0.93	56	5	52	4	0.31
BestTestMCCScore	0.93	0.85	0.92	0.92	0.93	56	5	52	4	0.31
BestTestAccuracyScore	0.93	0.85	0.92	0.92	0.93	56	5	52	4	0.31
BestValidationF1Score	0.91	0.82	0.91	0.95	0.87	53	3	53	8	0.31
BestValidationMCC	0.91	0.82	0.91	0.95	0.87	53	3	53	8	0.31
BestValidationAccuracy	0.91	0.82	0.91	0.95	0.87	53	3	53	8	0.31
TestPredictions (Threshold:0.31)
CHEMBL369296,TP,ACT,0.9300000071525574	CHEMBL72480,TN,INACT,0.0	CHEMBL183024,TN,INACT,0.09000000357627869	CHEMBL207297,TN,INACT,0.0	CHEMBL1958319,TN,INACT,0.05999999865889549	CHEMBL486101,TP,ACT,0.9900000095367432	CHEMBL180810,TP,ACT,0.41999998688697815	CHEMBL30432,TN,INACT,0.0	CHEMBL562342,TN,INACT,0.0	CHEMBL215815,TP,ACT,0.9900000095367432	CHEMBL452336,TP,ACT,1.0	CHEMBL1783703,TN,INACT,0.0	CHEMBL1829272,TN,INACT,0.0	CHEMBL598449,TN,INACT,0.0	CHEMBL230232,TN,INACT,0.0	CHEMBL519212,TP,ACT,0.9900000095367432	CHEMBL3628992,TN,INACT,0.0	CHEMBL508294,FN,ACT,0.0	CHEMBL401776,TP,ACT,1.0	CHEMBL515940,TN,INACT,0.10000000149011612	CHEMBL2323552,TN,INACT,0.0	CHEMBL199865,TN,INACT,0.0	CHEMBL591051,TN,INACT,0.0	CHEMBL104264,TN,INACT,0.0	CHEMBL3355525,TP,ACT,0.6000000238418579	CHEMBL413579,TP,ACT,0.4300000071525574	CHEMBL520049,TP,ACT,0.7099999785423279	CHEMBL3355522,TP,ACT,0.949999988079071	CHEMBL3263998,TN,INACT,0.0	CHEMBL607707,FN,ACT,0.0	CHEMBL559881,TN,INACT,0.0	CHEMBL180316,TP,ACT,0.9700000286102295	CHEMBL213019,TP,ACT,0.4300000071525574	CHEMBL488811,TN,INACT,0.029999999329447746	CHEMBL181017,TP,ACT,0.8999999761581421	CHEMBL488571,TP,ACT,0.8100000023841858	CHEMBL213313,TP,ACT,0.9300000071525574	CHEMBL472209,TP,ACT,0.9300000071525574	CHEMBL360689,FP,INACT,0.6399999856948853	CHEMBL2163627,FP,INACT,0.8500000238418579	CHEMBL584640,TN,INACT,0.0	CHEMBL56731,TN,INACT,0.0	CHEMBL238617,TN,INACT,0.0	CHEMBL3355524,TP,ACT,0.5899999737739563	CHEMBL230654,TN,INACT,0.0	CHEMBL329642,TN,INACT,0.05000000074505806	CHEMBL1208888,TN,INACT,0.009999999776482582	CHEMBL1208886,TN,INACT,0.0	CHEMBL212495,TP,ACT,0.9900000095367432	CHEMBL1240703,TP,ACT,0.5699999928474426	CHEMBL488054,TP,ACT,1.0	CHEMBL470117,TP,ACT,1.0	CHEMBL460079,TP,ACT,1.0	CHEMBL453347,TP,ACT,0.9900000095367432	CHEMBL471157,TP,ACT,0.9900000095367432	CHEMBL211140,TP,ACT,0.9900000095367432	CHEMBL360278,TN,INACT,0.0	CHEMBL2323553,TN,INACT,0.0	CHEMBL1683957,TN,INACT,0.009999999776482582	CHEMBL488573,TP,ACT,0.9800000190734863	CHEMBL520181,TP,ACT,0.9599999785423279	CHEMBL2322992,TN,INACT,0.0	CHEMBL466700,TN,INACT,0.0	CHEMBL483611,TP,ACT,1.0	CHEMBL272479,TP,ACT,0.9700000286102295	CHEMBL433361,TN,INACT,0.0	CHEMBL3809901,TN,INACT,0.0	CHEMBL520537,TP,ACT,1.0	CHEMBL521200,TP,ACT,0.9900000095367432	CHEMBL3736217,TN,INACT,0.0	CHEMBL379322,TP,ACT,0.9200000166893005	CHEMBL1421,TP,ACT,0.5899999737739563	CHEMBL1270522,TN,INACT,0.009999999776482582	CHEMBL1958321,FP,INACT,0.4699999988079071	CHEMBL211306,TP,ACT,0.9599999785423279	CHEMBL179806,FN,ACT,0.11999999731779099	CHEMBL362692,TP,ACT,0.8899999856948853	CHEMBL1783554,TN,INACT,0.0	CHEMBL563281,TN,INACT,0.0	CHEMBL362402,FN,ACT,0.2800000011920929	CHEMBL213233,FP,INACT,0.550000011920929	CHEMBL514192,TP,ACT,0.75	CHEMBL3355536,TP,ACT,0.9800000190734863	CHEMBL318248,TN,INACT,0.0	CHEMBL2322990,TN,INACT,0.0	CHEMBL3355539,TP,ACT,0.9800000190734863	CHEMBL3736006,TN,INACT,0.0	CHEMBL395132,TN,INACT,0.019999999552965164	CHEMBL3355523,TP,ACT,0.949999988079071	CHEMBL384477,TP,ACT,0.9700000286102295	CHEMBL38380,TN,INACT,0.0	CHEMBL469822,TP,ACT,0.9900000095367432	CHEMBL1783564,TN,INACT,0.0	CHEMBL255416,TP,ACT,0.9800000190734863	CHEMBL248312,TN,INACT,0.0	CHEMBL2063416,TN,INACT,0.0	CHEMBL181733,TP,ACT,0.3799999952316284	CHEMBL299987,TN,INACT,0.0	CHEMBL209786,TP,ACT,0.8299999833106995	CHEMBL2312645,TN,INACT,0.009999999776482582	CHEMBL1209836,TN,INACT,0.0	CHEMBL104,TN,INACT,0.18000000715255737	CHEMBL271071,TP,ACT,0.7799999713897705	CHEMBL386809,TP,ACT,0.9900000095367432	CHEMBL271084,TP,ACT,1.0	CHEMBL377867,FP,INACT,0.9800000190734863	CHEMBL181314,TP,ACT,0.8700000047683716	CHEMBL475325,TP,ACT,0.3199999928474426	CHEMBL486661,TP,ACT,0.9900000095367432	CHEMBL483800,TP,ACT,0.5099999904632568	CHEMBL472208,TP,ACT,0.9900000095367432	CHEMBL215762,TP,ACT,0.9700000286102295	CHEMBL475524,TP,ACT,1.0	CHEMBL1208823,TN,INACT,0.0	CHEMBL435732,TP,ACT,0.8999999761581421	CHEMBL1828876,TN,INACT,0.0	CHEMBL314021,TN,INACT,0.0	

