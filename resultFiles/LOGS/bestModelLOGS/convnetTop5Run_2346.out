ImageNetInceptionV2 CHEMBL3802 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	141
Number of inactive compounds :	141
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3802_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3802_adam_0.001_15_0.6/
---------------------------------
Training samples: 172
Validation samples: 54
--
Training Step: 1  | time: 406.008s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/172
[A[ATraining Step: 2  | total loss: [1m[32m0.65354[0m[0m | time: 530.310s
[2K
| Adam | epoch: 001 | loss: 0.65354 - acc: 0.4500 -- iter: 064/172
[A[ATraining Step: 3  | total loss: [1m[32m0.89978[0m[0m | time: 850.095s
[2K
| Adam | epoch: 001 | loss: 0.89978 - acc: 0.5932 -- iter: 096/172
[A[ATraining Step: 4  | total loss: [1m[32m0.56381[0m[0m | time: 1137.457s
[2K
| Adam | epoch: 001 | loss: 0.56381 - acc: 0.7577 -- iter: 128/172
[A[ATraining Step: 5  | total loss: [1m[32m0.43681[0m[0m | time: 1423.041s
[2K
| Adam | epoch: 001 | loss: 0.43681 - acc: 0.8822 -- iter: 160/172
[A[ATraining Step: 6  | total loss: [1m[32m0.32393[0m[0m | time: 1435.462s
[2K
| Adam | epoch: 001 | loss: 0.32393 - acc: 0.8976 | val_loss: 3.20282 - val_acc: 0.4630 -- iter: 172/172
--
Training Step: 7  | total loss: [1m[32m0.50538[0m[0m | time: 4.175s
[2K
| Adam | epoch: 002 | loss: 0.50538 - acc: 0.8091 -- iter: 032/172
[A[ATraining Step: 8  | total loss: [1m[32m0.27334[0m[0m | time: 101.416s
[2K
| Adam | epoch: 002 | loss: 0.27334 - acc: 0.9165 -- iter: 064/172
[A[ATraining Step: 9  | total loss: [1m[32m0.36917[0m[0m | time: 174.291s
[2K
| Adam | epoch: 002 | loss: 0.36917 - acc: 0.8118 -- iter: 096/172
[A[ATraining Step: 10  | total loss: [1m[32m0.32946[0m[0m | time: 231.861s
[2K
| Adam | epoch: 002 | loss: 0.32946 - acc: 0.8746 -- iter: 128/172
[A[ATraining Step: 11  | total loss: [1m[32m0.25430[0m[0m | time: 296.443s
[2K
| Adam | epoch: 002 | loss: 0.25430 - acc: 0.8896 -- iter: 160/172
[A[ATraining Step: 12  | total loss: [1m[32m0.26165[0m[0m | time: 332.395s
[2K
| Adam | epoch: 002 | loss: 0.26165 - acc: 0.8971 | val_loss: 1.86821 - val_acc: 0.4630 -- iter: 172/172
--
Training Step: 13  | total loss: [1m[32m0.25232[0m[0m | time: 4.584s
[2K
| Adam | epoch: 003 | loss: 0.25232 - acc: 0.9144 -- iter: 032/172
[A[ATraining Step: 14  | total loss: [1m[32m0.40160[0m[0m | time: 8.548s
[2K
| Adam | epoch: 003 | loss: 0.40160 - acc: 0.9153 -- iter: 064/172
[A[ATraining Step: 15  | total loss: [1m[32m0.32514[0m[0m | time: 56.573s
[2K
| Adam | epoch: 003 | loss: 0.32514 - acc: 0.9485 -- iter: 096/172
[A[ATraining Step: 16  | total loss: [1m[32m0.34609[0m[0m | time: 99.648s
[2K
| Adam | epoch: 003 | loss: 0.34609 - acc: 0.9092 -- iter: 128/172
[A[ATraining Step: 17  | total loss: [1m[32m0.36381[0m[0m | time: 118.668s
[2K
| Adam | epoch: 003 | loss: 0.36381 - acc: 0.8631 -- iter: 160/172
[A[ATraining Step: 18  | total loss: [1m[32m0.33334[0m[0m | time: 194.504s
[2K
| Adam | epoch: 003 | loss: 0.33334 - acc: 0.8672 | val_loss: 1.45753 - val_acc: 0.4630 -- iter: 172/172
--
Training Step: 19  | total loss: [1m[32m0.27989[0m[0m | time: 35.063s
[2K
| Adam | epoch: 004 | loss: 0.27989 - acc: 0.8907 -- iter: 032/172
[A[ATraining Step: 20  | total loss: [1m[32m0.22204[0m[0m | time: 39.031s
[2K
| Adam | epoch: 004 | loss: 0.22204 - acc: 0.9057 -- iter: 064/172
[A[ATraining Step: 21  | total loss: [1m[32m0.17436[0m[0m | time: 42.786s
[2K
| Adam | epoch: 004 | loss: 0.17436 - acc: 0.9350 -- iter: 096/172
[A[ATraining Step: 22  | total loss: [1m[32m0.12784[0m[0m | time: 111.207s
[2K
| Adam | epoch: 004 | loss: 0.12784 - acc: 0.9545 -- iter: 128/172
[A[ATraining Step: 23  | total loss: [1m[32m0.14798[0m[0m | time: 122.649s
[2K
| Adam | epoch: 004 | loss: 0.14798 - acc: 0.9405 -- iter: 160/172
[A[ATraining Step: 24  | total loss: [1m[32m0.11007[0m[0m | time: 162.911s
[2K
| Adam | epoch: 004 | loss: 0.11007 - acc: 0.9572 | val_loss: 4.16037 - val_acc: 0.4630 -- iter: 172/172
--
Training Step: 25  | total loss: [1m[32m0.11013[0m[0m | time: 107.505s
[2K
| Adam | epoch: 005 | loss: 0.11013 - acc: 0.9604 -- iter: 032/172
[A[ATraining Step: 26  | total loss: [1m[32m0.08411[0m[0m | time: 143.512s
[2K
| Adam | epoch: 005 | loss: 0.08411 - acc: 0.9709 -- iter: 064/172
[A[ATraining Step: 27  | total loss: [1m[32m0.07431[0m[0m | time: 180.203s
[2K
| Adam | epoch: 005 | loss: 0.07431 - acc: 0.9784 -- iter: 096/172
[A[ATraining Step: 28  | total loss: [1m[32m0.05790[0m[0m | time: 223.572s
[2K
| Adam | epoch: 005 | loss: 0.05790 - acc: 0.9838 -- iter: 128/172
[A[ATraining Step: 29  | total loss: [1m[32m0.04602[0m[0m | time: 281.610s
[2K
| Adam | epoch: 005 | loss: 0.04602 - acc: 0.9877 -- iter: 160/172
[A[ATraining Step: 30  | total loss: [1m[32m0.07908[0m[0m | time: 359.966s
[2K
| Adam | epoch: 005 | loss: 0.07908 - acc: 0.9684 | val_loss: 2.87096 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 31  | total loss: [1m[32m0.07559[0m[0m | time: 50.675s
[2K
| Adam | epoch: 006 | loss: 0.07559 - acc: 0.9613 -- iter: 032/172
[A[ATraining Step: 32  | total loss: [1m[32m0.10118[0m[0m | time: 150.752s
[2K
| Adam | epoch: 006 | loss: 0.10118 - acc: 0.9559 -- iter: 064/172
[A[ATraining Step: 33  | total loss: [1m[32m0.13439[0m[0m | time: 233.045s
[2K
| Adam | epoch: 006 | loss: 0.13439 - acc: 0.9382 -- iter: 096/172
[A[ATraining Step: 34  | total loss: [1m[32m0.12319[0m[0m | time: 258.454s
[2K
| Adam | epoch: 006 | loss: 0.12319 - acc: 0.9447 -- iter: 128/172
[A[ATraining Step: 35  | total loss: [1m[32m0.12945[0m[0m | time: 282.924s
[2K
| Adam | epoch: 006 | loss: 0.12945 - acc: 0.9388 -- iter: 160/172
[A[ATraining Step: 36  | total loss: [1m[32m0.11377[0m[0m | time: 356.284s
[2K
| Adam | epoch: 006 | loss: 0.11377 - acc: 0.9514 | val_loss: 5.60651 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 37  | total loss: [1m[32m0.09675[0m[0m | time: 26.116s
[2K
| Adam | epoch: 007 | loss: 0.09675 - acc: 0.9548 -- iter: 032/172
[A[ATraining Step: 38  | total loss: [1m[32m0.09176[0m[0m | time: 69.689s
[2K
| Adam | epoch: 007 | loss: 0.09176 - acc: 0.9576 -- iter: 064/172
[A[ATraining Step: 39  | total loss: [1m[32m0.07639[0m[0m | time: 118.814s
[2K
| Adam | epoch: 007 | loss: 0.07639 - acc: 0.9657 -- iter: 096/172
[A[ATraining Step: 40  | total loss: [1m[32m0.09224[0m[0m | time: 197.085s
[2K
| Adam | epoch: 007 | loss: 0.09224 - acc: 0.9604 -- iter: 128/172
[A[ATraining Step: 41  | total loss: [1m[32m0.07728[0m[0m | time: 210.281s
[2K
| Adam | epoch: 007 | loss: 0.07728 - acc: 0.9677 -- iter: 160/172
[A[ATraining Step: 42  | total loss: [1m[32m0.07072[0m[0m | time: 234.539s
[2K
| Adam | epoch: 007 | loss: 0.07072 - acc: 0.9735 | val_loss: 3.31520 - val_acc: 0.5370 -- iter: 172/172
--
Training Step: 43  | total loss: [1m[32m0.06180[0m[0m | time: 28.330s
[2K
| Adam | epoch: 008 | loss: 0.06180 - acc: 0.9782 -- iter: 032/172
[A[ATraining Step: 44  | total loss: [1m[32m0.10630[0m[0m | time: 61.259s
[2K
| Adam | epoch: 008 | loss: 0.10630 - acc: 0.9549 -- iter: 064/172
[A[ATraining Step: 45  | total loss: [1m[32m0.08996[0m[0m | time: 106.129s
[2K
| Adam | epoch: 008 | loss: 0.08996 - acc: 0.9626 -- iter: 096/172
[A[ATraining Step: 46  | total loss: [1m[32m0.07799[0m[0m | time: 165.600s
[2K
| Adam | epoch: 008 | loss: 0.07799 - acc: 0.9688 -- iter: 128/172
[A[ATraining Step: 47  | total loss: [1m[32m0.07089[0m[0m | time: 193.508s
[2K
| Adam | epoch: 008 | loss: 0.07089 - acc: 0.9688 -- iter: 160/172
[A[ATraining Step: 48  | total loss: [1m[32m0.06706[0m[0m | time: 228.936s
[2K
| Adam | epoch: 008 | loss: 0.06706 - acc: 0.9738 | val_loss: 0.59601 - val_acc: 0.8148 -- iter: 172/172
--
Training Step: 49  | total loss: [1m[32m0.05865[0m[0m | time: 15.748s
[2K
| Adam | epoch: 009 | loss: 0.05865 - acc: 0.9779 -- iter: 032/172
[A[ATraining Step: 50  | total loss: [1m[32m0.05076[0m[0m | time: 41.933s
[2K
| Adam | epoch: 009 | loss: 0.05076 - acc: 0.9814 -- iter: 064/172
[A[ATraining Step: 51  | total loss: [1m[32m0.05483[0m[0m | time: 61.866s
[2K
| Adam | epoch: 009 | loss: 0.05483 - acc: 0.9794 -- iter: 096/172
[A[ATraining Step: 52  | total loss: [1m[32m0.08203[0m[0m | time: 85.559s
[2K
| Adam | epoch: 009 | loss: 0.08203 - acc: 0.9778 -- iter: 128/172
[A[ATraining Step: 53  | total loss: [1m[32m0.09808[0m[0m | time: 111.397s
[2K
| Adam | epoch: 009 | loss: 0.09808 - acc: 0.9719 -- iter: 160/172
[A[ATraining Step: 54  | total loss: [1m[32m0.08619[0m[0m | time: 136.681s
[2K
| Adam | epoch: 009 | loss: 0.08619 - acc: 0.9760 | val_loss: 0.58914 - val_acc: 0.7963 -- iter: 172/172
--
Training Step: 55  | total loss: [1m[32m0.07750[0m[0m | time: 9.241s
[2K
| Adam | epoch: 010 | loss: 0.07750 - acc: 0.9794 -- iter: 032/172
[A[ATraining Step: 56  | total loss: [1m[32m0.07189[0m[0m | time: 22.950s
[2K
| Adam | epoch: 010 | loss: 0.07189 - acc: 0.9823 -- iter: 064/172
[A[ATraining Step: 57  | total loss: [1m[32m0.06574[0m[0m | time: 52.531s
[2K
| Adam | epoch: 010 | loss: 0.06574 - acc: 0.9847 -- iter: 096/172
[A[ATraining Step: 58  | total loss: [1m[32m0.06299[0m[0m | time: 109.064s
[2K
| Adam | epoch: 010 | loss: 0.06299 - acc: 0.9826 -- iter: 128/172
[A[ATraining Step: 59  | total loss: [1m[32m0.05986[0m[0m | time: 137.950s
[2K
| Adam | epoch: 010 | loss: 0.05986 - acc: 0.9849 -- iter: 160/172
[A[ATraining Step: 60  | total loss: [1m[32m0.06867[0m[0m | time: 297.092s
[2K
| Adam | epoch: 010 | loss: 0.06867 - acc: 0.9828 | val_loss: 0.44335 - val_acc: 0.8333 -- iter: 172/172
--
Training Step: 61  | total loss: [1m[32m0.06316[0m[0m | time: 26.931s
[2K
| Adam | epoch: 011 | loss: 0.06316 - acc: 0.9850 -- iter: 032/172
[A[ATraining Step: 62  | total loss: [1m[32m0.06086[0m[0m | time: 40.364s
[2K
| Adam | epoch: 011 | loss: 0.06086 - acc: 0.9829 -- iter: 064/172
[A[ATraining Step: 63  | total loss: [1m[32m0.05397[0m[0m | time: 48.129s
[2K
| Adam | epoch: 011 | loss: 0.05397 - acc: 0.9851 -- iter: 096/172
[A[ATraining Step: 64  | total loss: [1m[32m0.04792[0m[0m | time: 71.022s
[2K
| Adam | epoch: 011 | loss: 0.04792 - acc: 0.9870 -- iter: 128/172
[A[ATraining Step: 65  | total loss: [1m[32m0.04420[0m[0m | time: 96.135s
[2K
| Adam | epoch: 011 | loss: 0.04420 - acc: 0.9886 -- iter: 160/172
[A[ATraining Step: 66  | total loss: [1m[32m0.11329[0m[0m | time: 127.365s
[2K
| Adam | epoch: 011 | loss: 0.11329 - acc: 0.9862 | val_loss: 0.57171 - val_acc: 0.8519 -- iter: 172/172
--
Training Step: 67  | total loss: [1m[32m0.10015[0m[0m | time: 24.575s
[2K
| Adam | epoch: 012 | loss: 0.10015 - acc: 0.9878 -- iter: 032/172
[A[ATraining Step: 68  | total loss: [1m[32m0.09737[0m[0m | time: 41.655s
[2K
| Adam | epoch: 012 | loss: 0.09737 - acc: 0.9819 -- iter: 064/172
[A[ATraining Step: 69  | total loss: [1m[32m0.08646[0m[0m | time: 52.926s
[2K
| Adam | epoch: 012 | loss: 0.08646 - acc: 0.9840 -- iter: 096/172
[A[ATraining Step: 70  | total loss: [1m[32m0.07701[0m[0m | time: 60.393s
[2K
| Adam | epoch: 012 | loss: 0.07701 - acc: 0.9858 -- iter: 128/172
[A[ATraining Step: 71  | total loss: [1m[32m0.06909[0m[0m | time: 80.047s
[2K
| Adam | epoch: 012 | loss: 0.06909 - acc: 0.9874 -- iter: 160/172
[A[ATraining Step: 72  | total loss: [1m[32m0.06876[0m[0m | time: 111.607s
[2K
| Adam | epoch: 012 | loss: 0.06876 - acc: 0.9853 | val_loss: 2.48499 - val_acc: 0.5741 -- iter: 172/172
--
Training Step: 73  | total loss: [1m[32m0.06627[0m[0m | time: 20.535s
[2K
| Adam | epoch: 013 | loss: 0.06627 - acc: 0.9870 -- iter: 032/172
[A[ATraining Step: 74  | total loss: [1m[32m0.06537[0m[0m | time: 46.438s
[2K
| Adam | epoch: 013 | loss: 0.06537 - acc: 0.9850 -- iter: 064/172
[A[ATraining Step: 75  | total loss: [1m[32m0.06175[0m[0m | time: 83.704s
[2K
| Adam | epoch: 013 | loss: 0.06175 - acc: 0.9866 -- iter: 096/172
[A[ATraining Step: 76  | total loss: [1m[32m0.05621[0m[0m | time: 107.042s
[2K
| Adam | epoch: 013 | loss: 0.05621 - acc: 0.9880 -- iter: 128/172
[A[ATraining Step: 77  | total loss: [1m[32m0.05095[0m[0m | time: 116.628s
[2K
| Adam | epoch: 013 | loss: 0.05095 - acc: 0.9893 -- iter: 160/172
[A[ATraining Step: 78  | total loss: [1m[32m0.04647[0m[0m | time: 166.112s
[2K
| Adam | epoch: 013 | loss: 0.04647 - acc: 0.9904 | val_loss: 0.38894 - val_acc: 0.9074 -- iter: 172/172
--
Training Step: 79  | total loss: [1m[32m0.04248[0m[0m | time: 24.896s
[2K
| Adam | epoch: 014 | loss: 0.04248 - acc: 0.9914 -- iter: 032/172
[A[ATraining Step: 80  | total loss: [1m[32m0.13805[0m[0m | time: 61.429s
[2K
| Adam | epoch: 014 | loss: 0.13805 - acc: 0.9763 -- iter: 064/172
[A[ATraining Step: 81  | total loss: [1m[32m0.12520[0m[0m | time: 87.508s
[2K
| Adam | epoch: 014 | loss: 0.12520 - acc: 0.9787 -- iter: 096/172
[A[ATraining Step: 82  | total loss: [1m[32m0.11737[0m[0m | time: 116.395s
[2K
| Adam | epoch: 014 | loss: 0.11737 - acc: 0.9777 -- iter: 128/172
[A[ATraining Step: 83  | total loss: [1m[32m0.10923[0m[0m | time: 137.890s
[2K
| Adam | epoch: 014 | loss: 0.10923 - acc: 0.9768 -- iter: 160/172
[A[ATraining Step: 84  | total loss: [1m[32m0.11901[0m[0m | time: 160.669s
[2K
| Adam | epoch: 014 | loss: 0.11901 - acc: 0.9708 | val_loss: 0.77300 - val_acc: 0.7037 -- iter: 172/172
--
Training Step: 85  | total loss: [1m[32m0.11590[0m[0m | time: 22.993s
[2K
| Adam | epoch: 015 | loss: 0.11590 - acc: 0.9737 -- iter: 032/172
[A[ATraining Step: 86  | total loss: [1m[32m0.11339[0m[0m | time: 48.135s
[2K
| Adam | epoch: 015 | loss: 0.11339 - acc: 0.9732 -- iter: 064/172
[A[ATraining Step: 87  | total loss: [1m[32m0.12769[0m[0m | time: 86.513s
[2K
| Adam | epoch: 015 | loss: 0.12769 - acc: 0.9696 -- iter: 096/172
[A[ATraining Step: 88  | total loss: [1m[32m0.11803[0m[0m | time: 127.653s
[2K
| Adam | epoch: 015 | loss: 0.11803 - acc: 0.9727 -- iter: 128/172
[A[ATraining Step: 89  | total loss: [1m[32m0.11293[0m[0m | time: 162.439s
[2K
| Adam | epoch: 015 | loss: 0.11293 - acc: 0.9723 -- iter: 160/172
[A[ATraining Step: 90  | total loss: [1m[32m0.11631[0m[0m | time: 174.824s
[2K
| Adam | epoch: 015 | loss: 0.11631 - acc: 0.9719 | val_loss: 0.39431 - val_acc: 0.8519 -- iter: 172/172
--
Validation AUC:0.9903448275862069
Validation AUPRC:0.9894373626373628
Test AUC:0.9928977272727273
Test AUPRC:0.9949491504133381
BestTestF1Score	0.95	0.89	0.94	0.97	0.94	30	1	21	2	0.95
BestTestMCCScore	0.95	0.89	0.94	0.97	0.94	30	1	21	2	0.95
BestTestAccuracyScore	0.95	0.89	0.94	0.97	0.94	30	1	21	2	0.95
BestValidationF1Score	0.94	0.89	0.94	1.0	0.88	22	0	29	3	0.95
BestValidationMCC	0.94	0.89	0.94	1.0	0.88	22	0	29	3	0.95
BestValidationAccuracy	0.94	0.89	0.94	1.0	0.88	22	0	29	3	0.95
TestPredictions (Threshold:0.95)
CHEMBL450729,TN,INACT,0.029999999329447746	CHEMBL429238,TN,INACT,0.0	CHEMBL3646134,TP,ACT,0.9900000095367432	CHEMBL3646127,TP,ACT,0.9599999785423279	CHEMBL3666783,TP,ACT,1.0	CHEMBL3646132,TP,ACT,1.0	CHEMBL359685,TP,ACT,1.0	CHEMBL246585,TN,INACT,0.009999999776482582	CHEMBL3646140,TP,ACT,0.9900000095367432	CHEMBL2159172,TP,ACT,0.9700000286102295	CHEMBL2016681,TP,ACT,0.9700000286102295	CHEMBL2322893,FP,INACT,0.9800000190734863	CHEMBL450463,TN,INACT,0.6600000262260437	CHEMBL3666784,TP,ACT,1.0	CHEMBL165012,TN,INACT,0.33000001311302185	CHEMBL3666802,TP,ACT,1.0	CHEMBL40796,TN,INACT,0.029999999329447746	CHEMBL2070159,TP,ACT,1.0	CHEMBL1259241,TN,INACT,0.9300000071525574	CHEMBL461502,TN,INACT,0.0	CHEMBL296245,TN,INACT,0.20000000298023224	CHEMBL279225,TN,INACT,0.029999999329447746	CHEMBL3666796,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.1599999964237213	CHEMBL162095,TN,INACT,0.8799999952316284	CHEMBL39879,TN,INACT,0.25999999046325684	CHEMBL2069316,TP,ACT,0.9900000095367432	CHEMBL283320,TN,INACT,0.25	CHEMBL2312079,TP,ACT,1.0	CHEMBL2312076,TP,ACT,1.0	CHEMBL3666800,TP,ACT,1.0	CHEMBL2159157,TP,ACT,1.0	CHEMBL308924,TN,INACT,0.1599999964237213	CHEMBL227429,TN,INACT,0.0	CHEMBL3666795,TP,ACT,1.0	CHEMBL3666790,TP,ACT,1.0	CHEMBL2312063,TP,ACT,1.0	CHEMBL2070149,TP,ACT,1.0	CHEMBL414570,TN,INACT,0.0	CHEMBL3666792,TP,ACT,1.0	CHEMBL2312070,TP,ACT,1.0	CHEMBL181250,FN,ACT,0.949999988079071	CHEMBL2159162,TP,ACT,1.0	CHEMBL168632,TN,INACT,0.7400000095367432	CHEMBL2159160,TP,ACT,1.0	CHEMBL2159166,TP,ACT,0.9900000095367432	CHEMBL42359,TN,INACT,0.11999999731779099	CHEMBL3646144,TP,ACT,0.9900000095367432	CHEMBL189810,TP,ACT,1.0	CHEMBL413040,TN,INACT,0.0	CHEMBL3350741,TN,INACT,0.0	CHEMBL362795,FN,ACT,0.9399999976158142	CHEMBL2070144,TP,ACT,1.0	CHEMBL2312075,TP,ACT,1.0	

