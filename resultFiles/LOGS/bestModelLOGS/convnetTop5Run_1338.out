ImageNetInceptionV2 CHEMBL4527 RMSprop 0.0005 30 0 0 0.6 False True
Number of active compounds :	157
Number of inactive compounds :	157
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4527_RMSprop_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4527_RMSprop_0.0005_30_0.6/
---------------------------------
Training samples: 176
Validation samples: 56
--
Training Step: 1  | time: 202.432s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/176
[A[ATraining Step: 2  | total loss: [1m[32m0.59964[0m[0m | time: 421.308s
[2K
| RMSProp | epoch: 001 | loss: 0.59964 - acc: 0.5625 -- iter: 064/176
[A[ATraining Step: 3  | total loss: [1m[32m0.69644[0m[0m | time: 509.107s
[2K
| RMSProp | epoch: 001 | loss: 0.69644 - acc: 0.5114 -- iter: 096/176
[A[ATraining Step: 4  | total loss: [1m[32m0.68552[0m[0m | time: 593.301s
[2K
| RMSProp | epoch: 001 | loss: 0.68552 - acc: 0.5497 -- iter: 128/176
[A[ATraining Step: 5  | total loss: [1m[32m0.65238[0m[0m | time: 845.420s
[2K
| RMSProp | epoch: 001 | loss: 0.65238 - acc: 0.6235 -- iter: 160/176
[A[ATraining Step: 6  | total loss: [1m[32m0.65665[0m[0m | time: 1345.904s
[2K
| RMSProp | epoch: 001 | loss: 0.65665 - acc: 0.5843 | val_loss: 0.67821 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 7  | total loss: [1m[32m0.76162[0m[0m | time: 155.924s
[2K
| RMSProp | epoch: 002 | loss: 0.76162 - acc: 0.4587 -- iter: 032/176
[A[ATraining Step: 8  | total loss: [1m[32m0.76302[0m[0m | time: 491.882s
[2K
| RMSProp | epoch: 002 | loss: 0.76302 - acc: 0.4468 -- iter: 064/176
[A[ATraining Step: 9  | total loss: [1m[32m0.76314[0m[0m | time: 574.890s
[2K
| RMSProp | epoch: 002 | loss: 0.76314 - acc: 0.4419 -- iter: 096/176
[A[ATraining Step: 10  | total loss: [1m[32m0.72239[0m[0m | time: 631.292s
[2K
| RMSProp | epoch: 002 | loss: 0.72239 - acc: 0.4553 -- iter: 128/176
[A[ATraining Step: 11  | total loss: [1m[32m0.69580[0m[0m | time: 739.680s
[2K
| RMSProp | epoch: 002 | loss: 0.69580 - acc: 0.5357 -- iter: 160/176
[A[ATraining Step: 12  | total loss: [1m[32m0.71380[0m[0m | time: 786.144s
[2K
| RMSProp | epoch: 002 | loss: 0.71380 - acc: 0.4774 | val_loss: 0.67609 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 13  | total loss: [1m[32m0.69138[0m[0m | time: 10.333s
[2K
| RMSProp | epoch: 003 | loss: 0.69138 - acc: 0.5809 -- iter: 032/176
[A[ATraining Step: 14  | total loss: [1m[32m0.66555[0m[0m | time: 16.354s
[2K
| RMSProp | epoch: 003 | loss: 0.66555 - acc: 0.6501 -- iter: 064/176
[A[ATraining Step: 15  | total loss: [1m[32m0.65293[0m[0m | time: 24.753s
[2K
| RMSProp | epoch: 003 | loss: 0.65293 - acc: 0.6402 -- iter: 096/176
[A[ATraining Step: 16  | total loss: [1m[32m0.66861[0m[0m | time: 33.063s
[2K
| RMSProp | epoch: 003 | loss: 0.66861 - acc: 0.5994 -- iter: 128/176
[A[ATraining Step: 17  | total loss: [1m[32m0.69959[0m[0m | time: 41.397s
[2K
| RMSProp | epoch: 003 | loss: 0.69959 - acc: 0.5186 -- iter: 160/176
[A[ATraining Step: 18  | total loss: [1m[32m0.68927[0m[0m | time: 53.879s
[2K
| RMSProp | epoch: 003 | loss: 0.68927 - acc: 0.5338 | val_loss: 0.68595 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 19  | total loss: [1m[32m0.70190[0m[0m | time: 45.809s
[2K
| RMSProp | epoch: 004 | loss: 0.70190 - acc: 0.4913 -- iter: 032/176
[A[ATraining Step: 20  | total loss: [1m[32m0.69198[0m[0m | time: 53.232s
[2K
| RMSProp | epoch: 004 | loss: 0.69198 - acc: 0.5443 -- iter: 064/176
[A[ATraining Step: 21  | total loss: [1m[32m0.68586[0m[0m | time: 60.696s
[2K
| RMSProp | epoch: 004 | loss: 0.68586 - acc: 0.5693 -- iter: 096/176
[A[ATraining Step: 22  | total loss: [1m[32m0.67900[0m[0m | time: 73.664s
[2K
| RMSProp | epoch: 004 | loss: 0.67900 - acc: 0.5860 -- iter: 128/176
[A[ATraining Step: 23  | total loss: [1m[32m0.67678[0m[0m | time: 86.525s
[2K
| RMSProp | epoch: 004 | loss: 0.67678 - acc: 0.5792 -- iter: 160/176
[A[ATraining Step: 24  | total loss: [1m[32m0.66354[0m[0m | time: 103.640s
[2K
| RMSProp | epoch: 004 | loss: 0.66354 - acc: 0.6097 | val_loss: 0.67541 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 25  | total loss: [1m[32m0.65224[0m[0m | time: 13.333s
[2K
| RMSProp | epoch: 005 | loss: 0.65224 - acc: 0.6479 -- iter: 032/176
[A[ATraining Step: 26  | total loss: [1m[32m0.67719[0m[0m | time: 22.622s
[2K
| RMSProp | epoch: 005 | loss: 0.67719 - acc: 0.6088 -- iter: 064/176
[A[ATraining Step: 27  | total loss: [1m[32m0.68014[0m[0m | time: 27.306s
[2K
| RMSProp | epoch: 005 | loss: 0.68014 - acc: 0.5888 -- iter: 096/176
[A[ATraining Step: 28  | total loss: [1m[32m0.69455[0m[0m | time: 32.064s
[2K
| RMSProp | epoch: 005 | loss: 0.69455 - acc: 0.5666 -- iter: 128/176
[A[ATraining Step: 29  | total loss: [1m[32m0.67336[0m[0m | time: 41.429s
[2K
| RMSProp | epoch: 005 | loss: 0.67336 - acc: 0.5960 -- iter: 160/176
[A[ATraining Step: 30  | total loss: [1m[32m0.68212[0m[0m | time: 58.434s
[2K
| RMSProp | epoch: 005 | loss: 0.68212 - acc: 0.5659 | val_loss: 0.69299 - val_acc: 0.5179 -- iter: 176/176
--
Training Step: 31  | total loss: [1m[32m0.68005[0m[0m | time: 12.693s
[2K
| RMSProp | epoch: 006 | loss: 0.68005 - acc: 0.5579 -- iter: 032/176
[A[ATraining Step: 32  | total loss: [1m[32m0.67643[0m[0m | time: 25.981s
[2K
| RMSProp | epoch: 006 | loss: 0.67643 - acc: 0.5519 -- iter: 064/176
[A[ATraining Step: 33  | total loss: [1m[32m0.68090[0m[0m | time: 39.071s
[2K
| RMSProp | epoch: 006 | loss: 0.68090 - acc: 0.5268 -- iter: 096/176
[A[ATraining Step: 34  | total loss: [1m[32m0.67741[0m[0m | time: 46.781s
[2K
| RMSProp | epoch: 006 | loss: 0.67741 - acc: 0.5545 -- iter: 128/176
[A[ATraining Step: 35  | total loss: [1m[32m0.67800[0m[0m | time: 54.391s
[2K
| RMSProp | epoch: 006 | loss: 0.67800 - acc: 0.5693 -- iter: 160/176
[A[ATraining Step: 36  | total loss: [1m[32m0.67303[0m[0m | time: 118.441s
[2K
| RMSProp | epoch: 006 | loss: 0.67303 - acc: 0.5679 | val_loss: 0.67343 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 37  | total loss: [1m[32m0.66255[0m[0m | time: 8.330s
[2K
| RMSProp | epoch: 007 | loss: 0.66255 - acc: 0.5856 -- iter: 032/176
[A[ATraining Step: 38  | total loss: [1m[32m0.66240[0m[0m | time: 16.843s
[2K
| RMSProp | epoch: 007 | loss: 0.66240 - acc: 0.5872 -- iter: 064/176
[A[ATraining Step: 39  | total loss: [1m[32m0.66402[0m[0m | time: 25.070s
[2K
| RMSProp | epoch: 007 | loss: 0.66402 - acc: 0.5884 -- iter: 096/176
[A[ATraining Step: 40  | total loss: [1m[32m0.66366[0m[0m | time: 34.920s
[2K
| RMSProp | epoch: 007 | loss: 0.66366 - acc: 0.5836 -- iter: 128/176
[A[ATraining Step: 41  | total loss: [1m[32m0.65971[0m[0m | time: 42.344s
[2K
| RMSProp | epoch: 007 | loss: 0.65971 - acc: 0.5912 -- iter: 160/176
[A[ATraining Step: 42  | total loss: [1m[32m0.64563[0m[0m | time: 54.393s
[2K
| RMSProp | epoch: 007 | loss: 0.64563 - acc: 0.6198 | val_loss: 0.66118 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 43  | total loss: [1m[32m0.62281[0m[0m | time: 13.253s
[2K
| RMSProp | epoch: 008 | loss: 0.62281 - acc: 0.6538 -- iter: 032/176
[A[ATraining Step: 44  | total loss: [1m[32m0.62691[0m[0m | time: 26.108s
[2K
| RMSProp | epoch: 008 | loss: 0.62691 - acc: 0.6380 -- iter: 064/176
[A[ATraining Step: 45  | total loss: [1m[32m0.62150[0m[0m | time: 39.088s
[2K
| RMSProp | epoch: 008 | loss: 0.62150 - acc: 0.6517 -- iter: 096/176
[A[ATraining Step: 46  | total loss: [1m[32m0.61851[0m[0m | time: 54.078s
[2K
| RMSProp | epoch: 008 | loss: 0.61851 - acc: 0.6837 -- iter: 128/176
[A[ATraining Step: 47  | total loss: [1m[32m0.62404[0m[0m | time: 67.698s
[2K
| RMSProp | epoch: 008 | loss: 0.62404 - acc: 0.6792 -- iter: 160/176
[A[ATraining Step: 48  | total loss: [1m[32m0.62235[0m[0m | time: 79.097s
[2K
| RMSProp | epoch: 008 | loss: 0.62235 - acc: 0.6856 | val_loss: 0.67421 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 49  | total loss: [1m[32m0.62982[0m[0m | time: 4.703s
[2K
| RMSProp | epoch: 009 | loss: 0.62982 - acc: 0.6661 -- iter: 032/176
[A[ATraining Step: 50  | total loss: [1m[32m0.63058[0m[0m | time: 13.001s
[2K
| RMSProp | epoch: 009 | loss: 0.63058 - acc: 0.6404 -- iter: 064/176
[A[ATraining Step: 51  | total loss: [1m[32m0.63365[0m[0m | time: 21.200s
[2K
| RMSProp | epoch: 009 | loss: 0.63365 - acc: 0.6285 -- iter: 096/176
[A[ATraining Step: 52  | total loss: [1m[32m0.62914[0m[0m | time: 29.745s
[2K
| RMSProp | epoch: 009 | loss: 0.62914 - acc: 0.6326 -- iter: 128/176
[A[ATraining Step: 53  | total loss: [1m[32m0.62628[0m[0m | time: 43.983s
[2K
| RMSProp | epoch: 009 | loss: 0.62628 - acc: 0.6453 -- iter: 160/176
[A[ATraining Step: 54  | total loss: [1m[32m0.60910[0m[0m | time: 61.725s
[2K
| RMSProp | epoch: 009 | loss: 0.60910 - acc: 0.6787 | val_loss: 0.65293 - val_acc: 0.6786 -- iter: 176/176
--
Training Step: 55  | total loss: [1m[32m0.60870[0m[0m | time: 7.679s
[2K
| RMSProp | epoch: 010 | loss: 0.60870 - acc: 0.6844 -- iter: 032/176
[A[ATraining Step: 56  | total loss: [1m[32m0.60598[0m[0m | time: 14.869s
[2K
| RMSProp | epoch: 010 | loss: 0.60598 - acc: 0.6848 -- iter: 064/176
[A[ATraining Step: 57  | total loss: [1m[32m0.58840[0m[0m | time: 27.602s
[2K
| RMSProp | epoch: 010 | loss: 0.58840 - acc: 0.7025 -- iter: 096/176
[A[ATraining Step: 58  | total loss: [1m[32m0.59215[0m[0m | time: 40.273s
[2K
| RMSProp | epoch: 010 | loss: 0.59215 - acc: 0.6919 -- iter: 128/176
[A[ATraining Step: 59  | total loss: [1m[32m0.59575[0m[0m | time: 53.092s
[2K
| RMSProp | epoch: 010 | loss: 0.59575 - acc: 0.6746 -- iter: 160/176
[A[ATraining Step: 60  | total loss: [1m[32m0.58908[0m[0m | time: 70.051s
[2K
| RMSProp | epoch: 010 | loss: 0.58908 - acc: 0.6887 | val_loss: 0.62692 - val_acc: 0.7143 -- iter: 176/176
--
Training Step: 61  | total loss: [1m[32m0.58177[0m[0m | time: 18.774s
[2K
| RMSProp | epoch: 011 | loss: 0.58177 - acc: 0.6967 -- iter: 032/176
[A[ATraining Step: 62  | total loss: [1m[32m0.57877[0m[0m | time: 26.047s
[2K
| RMSProp | epoch: 011 | loss: 0.57877 - acc: 0.6995 -- iter: 064/176
[A[ATraining Step: 63  | total loss: [1m[32m0.58440[0m[0m | time: 33.725s
[2K
| RMSProp | epoch: 011 | loss: 0.58440 - acc: 0.6821 -- iter: 096/176
[A[ATraining Step: 64  | total loss: [1m[32m0.57218[0m[0m | time: 47.306s
[2K
| RMSProp | epoch: 011 | loss: 0.57218 - acc: 0.6906 -- iter: 128/176
[A[ATraining Step: 65  | total loss: [1m[32m0.57785[0m[0m | time: 60.274s
[2K
| RMSProp | epoch: 011 | loss: 0.57785 - acc: 0.6825 -- iter: 160/176
[A[ATraining Step: 66  | total loss: [1m[32m0.58572[0m[0m | time: 77.509s
[2K
| RMSProp | epoch: 011 | loss: 0.58572 - acc: 0.6869 | val_loss: 0.62788 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 67  | total loss: [1m[32m0.58107[0m[0m | time: 13.196s
[2K
| RMSProp | epoch: 012 | loss: 0.58107 - acc: 0.6945 -- iter: 032/176
[A[ATraining Step: 68  | total loss: [1m[32m0.57439[0m[0m | time: 27.599s
[2K
| RMSProp | epoch: 012 | loss: 0.57439 - acc: 0.6974 -- iter: 064/176
[A[ATraining Step: 69  | total loss: [1m[32m0.57900[0m[0m | time: 35.371s
[2K
| RMSProp | epoch: 012 | loss: 0.57900 - acc: 0.6889 -- iter: 096/176
[A[ATraining Step: 70  | total loss: [1m[32m0.57612[0m[0m | time: 41.993s
[2K
| RMSProp | epoch: 012 | loss: 0.57612 - acc: 0.7104 -- iter: 128/176
[A[ATraining Step: 71  | total loss: [1m[32m0.56808[0m[0m | time: 50.450s
[2K
| RMSProp | epoch: 012 | loss: 0.56808 - acc: 0.7291 -- iter: 160/176
[A[ATraining Step: 72  | total loss: [1m[32m0.56671[0m[0m | time: 61.945s
[2K
| RMSProp | epoch: 012 | loss: 0.56671 - acc: 0.7280 | val_loss: 0.59162 - val_acc: 0.6250 -- iter: 176/176
--
Training Step: 73  | total loss: [1m[32m0.56469[0m[0m | time: 13.783s
[2K
| RMSProp | epoch: 013 | loss: 0.56469 - acc: 0.7339 -- iter: 032/176
[A[ATraining Step: 74  | total loss: [1m[32m0.55986[0m[0m | time: 26.771s
[2K
| RMSProp | epoch: 013 | loss: 0.55986 - acc: 0.7391 -- iter: 064/176
[A[ATraining Step: 75  | total loss: [1m[32m0.55614[0m[0m | time: 40.675s
[2K
| RMSProp | epoch: 013 | loss: 0.55614 - acc: 0.7301 -- iter: 096/176
[A[ATraining Step: 76  | total loss: [1m[32m0.56280[0m[0m | time: 47.905s
[2K
| RMSProp | epoch: 013 | loss: 0.56280 - acc: 0.7322 -- iter: 128/176
[A[ATraining Step: 77  | total loss: [1m[32m0.57665[0m[0m | time: 55.091s
[2K
| RMSProp | epoch: 013 | loss: 0.57665 - acc: 0.7076 -- iter: 160/176
[A[ATraining Step: 78  | total loss: [1m[32m0.55213[0m[0m | time: 72.035s
[2K
| RMSProp | epoch: 013 | loss: 0.55213 - acc: 0.7317 | val_loss: 0.56895 - val_acc: 0.7321 -- iter: 176/176
--
Training Step: 79  | total loss: [1m[32m0.54807[0m[0m | time: 8.406s
[2K
| RMSProp | epoch: 014 | loss: 0.54807 - acc: 0.7498 -- iter: 032/176
[A[ATraining Step: 80  | total loss: [1m[32m0.56044[0m[0m | time: 16.796s
[2K
| RMSProp | epoch: 014 | loss: 0.56044 - acc: 0.7370 -- iter: 064/176
[A[ATraining Step: 81  | total loss: [1m[32m0.55455[0m[0m | time: 32.384s
[2K
| RMSProp | epoch: 014 | loss: 0.55455 - acc: 0.7446 -- iter: 096/176
[A[ATraining Step: 82  | total loss: [1m[32m0.54718[0m[0m | time: 64.705s
[2K
| RMSProp | epoch: 014 | loss: 0.54718 - acc: 0.7577 -- iter: 128/176
[A[ATraining Step: 83  | total loss: [1m[32m0.54273[0m[0m | time: 71.944s
[2K
| RMSProp | epoch: 014 | loss: 0.54273 - acc: 0.7663 -- iter: 160/176
[A[ATraining Step: 84  | total loss: [1m[32m0.54541[0m[0m | time: 83.499s
[2K
| RMSProp | epoch: 014 | loss: 0.54541 - acc: 0.7584 | val_loss: 0.65518 - val_acc: 0.5893 -- iter: 176/176
--
Training Step: 85  | total loss: [1m[32m0.52646[0m[0m | time: 12.913s
[2K
| RMSProp | epoch: 015 | loss: 0.52646 - acc: 0.7826 -- iter: 032/176
[A[ATraining Step: 86  | total loss: [1m[32m0.52815[0m[0m | time: 26.064s
[2K
| RMSProp | epoch: 015 | loss: 0.52815 - acc: 0.7762 -- iter: 064/176
[A[ATraining Step: 87  | total loss: [1m[32m0.52390[0m[0m | time: 39.235s
[2K
| RMSProp | epoch: 015 | loss: 0.52390 - acc: 0.7829 -- iter: 096/176
[A[ATraining Step: 88  | total loss: [1m[32m0.51402[0m[0m | time: 51.761s
[2K
| RMSProp | epoch: 015 | loss: 0.51402 - acc: 0.7953 -- iter: 128/176
[A[ATraining Step: 89  | total loss: [1m[32m0.50685[0m[0m | time: 64.545s
[2K
| RMSProp | epoch: 015 | loss: 0.50685 - acc: 0.7939 -- iter: 160/176
[A[ATraining Step: 90  | total loss: [1m[32m0.50310[0m[0m | time: 76.798s
[2K
| RMSProp | epoch: 015 | loss: 0.50310 - acc: 0.7926 | val_loss: 0.48907 - val_acc: 0.7679 -- iter: 176/176
--
Training Step: 91  | total loss: [1m[32m0.49882[0m[0m | time: 7.626s
[2K
| RMSProp | epoch: 016 | loss: 0.49882 - acc: 0.7946 -- iter: 032/176
[A[ATraining Step: 92  | total loss: [1m[32m0.47602[0m[0m | time: 20.278s
[2K
| RMSProp | epoch: 016 | loss: 0.47602 - acc: 0.8089 -- iter: 064/176
[A[ATraining Step: 93  | total loss: [1m[32m0.48611[0m[0m | time: 34.568s
[2K
| RMSProp | epoch: 016 | loss: 0.48611 - acc: 0.8030 -- iter: 096/176
[A[ATraining Step: 94  | total loss: [1m[32m0.47600[0m[0m | time: 48.457s
[2K
| RMSProp | epoch: 016 | loss: 0.47600 - acc: 0.8133 -- iter: 128/176
[A[ATraining Step: 95  | total loss: [1m[32m0.45917[0m[0m | time: 61.308s
[2K
| RMSProp | epoch: 016 | loss: 0.45917 - acc: 0.8257 -- iter: 160/176
[A[ATraining Step: 96  | total loss: [1m[32m0.44332[0m[0m | time: 78.200s
[2K
| RMSProp | epoch: 016 | loss: 0.44332 - acc: 0.8275 | val_loss: 1.10640 - val_acc: 0.4107 -- iter: 176/176
--
Training Step: 97  | total loss: [1m[32m0.43726[0m[0m | time: 31.089s
[2K
| RMSProp | epoch: 017 | loss: 0.43726 - acc: 0.8292 -- iter: 032/176
[A[ATraining Step: 98  | total loss: [1m[32m0.42873[0m[0m | time: 42.650s
[2K
| RMSProp | epoch: 017 | loss: 0.42873 - acc: 0.8275 -- iter: 064/176
[A[ATraining Step: 99  | total loss: [1m[32m0.40224[0m[0m | time: 158.539s
[2K
| RMSProp | epoch: 017 | loss: 0.40224 - acc: 0.8447 -- iter: 096/176
[A[ATraining Step: 100  | total loss: [1m[32m0.38497[0m[0m | time: 198.512s
[2K
| RMSProp | epoch: 017 | loss: 0.38497 - acc: 0.8603 -- iter: 128/176
[A[ATraining Step: 101  | total loss: [1m[32m0.36631[0m[0m | time: 214.669s
[2K
| RMSProp | epoch: 017 | loss: 0.36631 - acc: 0.8711 -- iter: 160/176
[A[ATraining Step: 102  | total loss: [1m[32m0.34692[0m[0m | time: 226.919s
[2K
| RMSProp | epoch: 017 | loss: 0.34692 - acc: 0.8809 | val_loss: 1.08750 - val_acc: 0.6250 -- iter: 176/176
--
Training Step: 103  | total loss: [1m[32m0.34491[0m[0m | time: 13.209s
[2K
| RMSProp | epoch: 018 | loss: 0.34491 - acc: 0.8834 -- iter: 032/176
[A[ATraining Step: 104  | total loss: [1m[32m0.33868[0m[0m | time: 24.428s
[2K
| RMSProp | epoch: 018 | loss: 0.33868 - acc: 0.8857 -- iter: 064/176
[A[ATraining Step: 105  | total loss: [1m[32m0.34916[0m[0m | time: 39.939s
[2K
| RMSProp | epoch: 018 | loss: 0.34916 - acc: 0.8784 -- iter: 096/176
[A[ATraining Step: 106  | total loss: [1m[32m0.33306[0m[0m | time: 122.729s
[2K
| RMSProp | epoch: 018 | loss: 0.33306 - acc: 0.8905 -- iter: 128/176
[A[ATraining Step: 107  | total loss: [1m[32m0.34167[0m[0m | time: 159.929s
[2K
| RMSProp | epoch: 018 | loss: 0.34167 - acc: 0.8827 -- iter: 160/176
[A[ATraining Step: 108  | total loss: [1m[32m0.32919[0m[0m | time: 222.635s
[2K
| RMSProp | epoch: 018 | loss: 0.32919 - acc: 0.8913 | val_loss: 1.12756 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 109  | total loss: [1m[32m0.32374[0m[0m | time: 71.151s
[2K
| RMSProp | epoch: 019 | loss: 0.32374 - acc: 0.8960 -- iter: 032/176
[A[ATraining Step: 110  | total loss: [1m[32m0.30771[0m[0m | time: 104.999s
[2K
| RMSProp | epoch: 019 | loss: 0.30771 - acc: 0.9032 -- iter: 064/176
[A[ATraining Step: 111  | total loss: [1m[32m0.28931[0m[0m | time: 119.240s
[2K
| RMSProp | epoch: 019 | loss: 0.28931 - acc: 0.9098 -- iter: 096/176
[A[ATraining Step: 112  | total loss: [1m[32m0.29020[0m[0m | time: 155.623s
[2K
| RMSProp | epoch: 019 | loss: 0.29020 - acc: 0.9063 -- iter: 128/176
[A[ATraining Step: 113  | total loss: [1m[32m0.26726[0m[0m | time: 170.929s
[2K
| RMSProp | epoch: 019 | loss: 0.26726 - acc: 0.9157 -- iter: 160/176
[A[ATraining Step: 114  | total loss: [1m[32m0.25072[0m[0m | time: 182.242s
[2K
| RMSProp | epoch: 019 | loss: 0.25072 - acc: 0.9241 | val_loss: 0.76444 - val_acc: 0.8036 -- iter: 176/176
--
Training Step: 115  | total loss: [1m[32m0.25700[0m[0m | time: 88.900s
[2K
| RMSProp | epoch: 020 | loss: 0.25700 - acc: 0.9254 -- iter: 032/176
[A[ATraining Step: 116  | total loss: [1m[32m0.26071[0m[0m | time: 123.697s
[2K
| RMSProp | epoch: 020 | loss: 0.26071 - acc: 0.9267 -- iter: 064/176
[A[ATraining Step: 117  | total loss: [1m[32m0.25451[0m[0m | time: 147.528s
[2K
| RMSProp | epoch: 020 | loss: 0.25451 - acc: 0.9309 -- iter: 096/176
[A[ATraining Step: 118  | total loss: [1m[32m0.24555[0m[0m | time: 158.196s
[2K
| RMSProp | epoch: 020 | loss: 0.24555 - acc: 0.9315 -- iter: 128/176
[A[ATraining Step: 119  | total loss: [1m[32m0.23600[0m[0m | time: 165.661s
[2K
| RMSProp | epoch: 020 | loss: 0.23600 - acc: 0.9384 -- iter: 160/176
[A[ATraining Step: 120  | total loss: [1m[32m0.21703[0m[0m | time: 183.262s
[2K
| RMSProp | epoch: 020 | loss: 0.21703 - acc: 0.9445 | val_loss: 2.37680 - val_acc: 0.3929 -- iter: 176/176
--
Training Step: 121  | total loss: [1m[32m0.27368[0m[0m | time: 16.781s
[2K
| RMSProp | epoch: 021 | loss: 0.27368 - acc: 0.9157 -- iter: 032/176
[A[ATraining Step: 122  | total loss: [1m[32m0.26883[0m[0m | time: 36.322s
[2K
| RMSProp | epoch: 021 | loss: 0.26883 - acc: 0.9210 -- iter: 064/176
[A[ATraining Step: 123  | total loss: [1m[32m0.25772[0m[0m | time: 49.140s
[2K
| RMSProp | epoch: 021 | loss: 0.25772 - acc: 0.9227 -- iter: 096/176
[A[ATraining Step: 124  | total loss: [1m[32m0.24476[0m[0m | time: 63.148s
[2K
| RMSProp | epoch: 021 | loss: 0.24476 - acc: 0.9273 -- iter: 128/176
[A[ATraining Step: 125  | total loss: [1m[32m0.25949[0m[0m | time: 70.582s
[2K
| RMSProp | epoch: 021 | loss: 0.25949 - acc: 0.9220 -- iter: 160/176
[A[ATraining Step: 126  | total loss: [1m[32m0.24161[0m[0m | time: 89.839s
[2K
| RMSProp | epoch: 021 | loss: 0.24161 - acc: 0.9298 | val_loss: 13.97998 - val_acc: 0.3929 -- iter: 176/176
--
Training Step: 127  | total loss: [1m[32m0.23880[0m[0m | time: 25.405s
[2K
| RMSProp | epoch: 022 | loss: 0.23880 - acc: 0.9244 -- iter: 032/176
[A[ATraining Step: 128  | total loss: [1m[32m0.22372[0m[0m | time: 74.612s
[2K
| RMSProp | epoch: 022 | loss: 0.22372 - acc: 0.9288 -- iter: 064/176
[A[ATraining Step: 129  | total loss: [1m[32m0.21521[0m[0m | time: 92.433s
[2K
| RMSProp | epoch: 022 | loss: 0.21521 - acc: 0.9328 -- iter: 096/176
[A[ATraining Step: 130  | total loss: [1m[32m0.22687[0m[0m | time: 112.613s
[2K
| RMSProp | epoch: 022 | loss: 0.22687 - acc: 0.9364 -- iter: 128/176
[A[ATraining Step: 131  | total loss: [1m[32m0.21064[0m[0m | time: 135.491s
[2K
| RMSProp | epoch: 022 | loss: 0.21064 - acc: 0.9427 -- iter: 160/176
[A[ATraining Step: 132  | total loss: [1m[32m0.20008[0m[0m | time: 151.532s
[2K
| RMSProp | epoch: 022 | loss: 0.20008 - acc: 0.9453 | val_loss: 9.00699 - val_acc: 0.6071 -- iter: 176/176
--
Training Step: 133  | total loss: [1m[32m0.19543[0m[0m | time: 9.369s
[2K
| RMSProp | epoch: 023 | loss: 0.19543 - acc: 0.9383 -- iter: 032/176
[A[ATraining Step: 134  | total loss: [1m[32m0.18281[0m[0m | time: 35.495s
[2K
| RMSProp | epoch: 023 | loss: 0.18281 - acc: 0.9445 -- iter: 064/176
[A[ATraining Step: 135  | total loss: [1m[32m0.17123[0m[0m | time: 51.735s
[2K
| RMSProp | epoch: 023 | loss: 0.17123 - acc: 0.9469 -- iter: 096/176
[A[ATraining Step: 136  | total loss: [1m[32m0.18434[0m[0m | time: 66.227s
[2K
| RMSProp | epoch: 023 | loss: 0.18434 - acc: 0.9460 -- iter: 128/176
[A[ATraining Step: 137  | total loss: [1m[32m0.20486[0m[0m | time: 82.315s
[2K
| RMSProp | epoch: 023 | loss: 0.20486 - acc: 0.9482 -- iter: 160/176
[A[ATraining Step: 138  | total loss: [1m[32m0.20073[0m[0m | time: 99.186s
[2K
| RMSProp | epoch: 023 | loss: 0.20073 - acc: 0.9503 | val_loss: 8.42039 - val_acc: 0.3929 -- iter: 176/176
--
Training Step: 139  | total loss: [1m[32m0.18871[0m[0m | time: 15.680s
[2K
| RMSProp | epoch: 024 | loss: 0.18871 - acc: 0.9553 -- iter: 032/176
[A[ATraining Step: 140  | total loss: [1m[32m0.18028[0m[0m | time: 26.258s
[2K
| RMSProp | epoch: 024 | loss: 0.18028 - acc: 0.9535 -- iter: 064/176
[A[ATraining Step: 141  | total loss: [1m[32m0.17776[0m[0m | time: 46.584s
[2K
| RMSProp | epoch: 024 | loss: 0.17776 - acc: 0.9456 -- iter: 096/176
[A[ATraining Step: 142  | total loss: [1m[32m0.18195[0m[0m | time: 59.711s
[2K
| RMSProp | epoch: 024 | loss: 0.18195 - acc: 0.9386 -- iter: 128/176
[A[ATraining Step: 143  | total loss: [1m[32m0.41058[0m[0m | time: 78.924s
[2K
| RMSProp | epoch: 024 | loss: 0.41058 - acc: 0.8885 -- iter: 160/176
[A[ATraining Step: 144  | total loss: [1m[32m0.42505[0m[0m | time: 158.411s
[2K
| RMSProp | epoch: 024 | loss: 0.42505 - acc: 0.8746 | val_loss: 13.97998 - val_acc: 0.3929 -- iter: 176/176
--
Training Step: 145  | total loss: [1m[32m0.42795[0m[0m | time: 17.004s
[2K
| RMSProp | epoch: 025 | loss: 0.42795 - acc: 0.8622 -- iter: 032/176
[A[ATraining Step: 146  | total loss: [1m[32m0.40177[0m[0m | time: 22.865s
[2K
| RMSProp | epoch: 025 | loss: 0.40177 - acc: 0.8759 -- iter: 064/176
[A[ATraining Step: 147  | total loss: [1m[32m0.36458[0m[0m | time: 27.865s
[2K
| RMSProp | epoch: 025 | loss: 0.36458 - acc: 0.8883 -- iter: 096/176
[A[ATraining Step: 148  | total loss: [1m[32m0.32892[0m[0m | time: 37.470s
[2K
| RMSProp | epoch: 025 | loss: 0.32892 - acc: 0.8995 -- iter: 128/176
[A[ATraining Step: 149  | total loss: [1m[32m0.34419[0m[0m | time: 52.910s
[2K
| RMSProp | epoch: 025 | loss: 0.34419 - acc: 0.8939 -- iter: 160/176
[A[ATraining Step: 150  | total loss: [1m[32m0.36183[0m[0m | time: 76.074s
[2K
| RMSProp | epoch: 025 | loss: 0.36183 - acc: 0.8889 | val_loss: 5.06128 - val_acc: 0.3929 -- iter: 176/176
--
Training Step: 151  | total loss: [1m[32m0.35294[0m[0m | time: 19.568s
[2K
| RMSProp | epoch: 026 | loss: 0.35294 - acc: 0.8875 -- iter: 032/176
[A[ATraining Step: 152  | total loss: [1m[32m0.34568[0m[0m | time: 38.341s
[2K
| RMSProp | epoch: 026 | loss: 0.34568 - acc: 0.8831 -- iter: 064/176
[A[ATraining Step: 153  | total loss: [1m[32m0.35372[0m[0m | time: 49.107s
[2K
| RMSProp | epoch: 026 | loss: 0.35372 - acc: 0.8667 -- iter: 096/176
[A[ATraining Step: 154  | total loss: [1m[32m0.33796[0m[0m | time: 60.943s
[2K
| RMSProp | epoch: 026 | loss: 0.33796 - acc: 0.8738 -- iter: 128/176
[A[ATraining Step: 155  | total loss: [1m[32m0.30671[0m[0m | time: 77.084s
[2K
| RMSProp | epoch: 026 | loss: 0.30671 - acc: 0.8864 -- iter: 160/176
[A[ATraining Step: 156  | total loss: [1m[32m0.30033[0m[0m | time: 94.187s
[2K
| RMSProp | epoch: 026 | loss: 0.30033 - acc: 0.8884 | val_loss: 1.64797 - val_acc: 0.4464 -- iter: 176/176
--
Training Step: 157  | total loss: [1m[32m0.27420[0m[0m | time: 16.916s
[2K
| RMSProp | epoch: 027 | loss: 0.27420 - acc: 0.8996 -- iter: 032/176
[A[ATraining Step: 158  | total loss: [1m[32m0.25217[0m[0m | time: 30.376s
[2K
| RMSProp | epoch: 027 | loss: 0.25217 - acc: 0.9065 -- iter: 064/176
[A[ATraining Step: 159  | total loss: [1m[32m0.23094[0m[0m | time: 47.036s
[2K
| RMSProp | epoch: 027 | loss: 0.23094 - acc: 0.9158 -- iter: 096/176
[A[ATraining Step: 160  | total loss: [1m[32m0.21542[0m[0m | time: 57.207s
[2K
| RMSProp | epoch: 027 | loss: 0.21542 - acc: 0.9211 -- iter: 128/176
[A[ATraining Step: 161  | total loss: [1m[32m0.20019[0m[0m | time: 65.197s
[2K
| RMSProp | epoch: 027 | loss: 0.20019 - acc: 0.9290 -- iter: 160/176
[A[ATraining Step: 162  | total loss: [1m[32m0.21094[0m[0m | time: 82.778s
[2K
| RMSProp | epoch: 027 | loss: 0.21094 - acc: 0.9174 | val_loss: 13.97998 - val_acc: 0.3929 -- iter: 176/176
--
Training Step: 163  | total loss: [1m[32m0.22777[0m[0m | time: 21.427s
[2K
| RMSProp | epoch: 028 | loss: 0.22777 - acc: 0.9131 -- iter: 032/176
[A[ATraining Step: 164  | total loss: [1m[32m0.31373[0m[0m | time: 40.822s
[2K
| RMSProp | epoch: 028 | loss: 0.31373 - acc: 0.8968 -- iter: 064/176
[A[ATraining Step: 165  | total loss: [1m[32m0.33817[0m[0m | time: 61.347s
[2K
| RMSProp | epoch: 028 | loss: 0.33817 - acc: 0.8821 -- iter: 096/176
[A[ATraining Step: 166  | total loss: [1m[32m0.32017[0m[0m | time: 74.643s
[2K
| RMSProp | epoch: 028 | loss: 0.32017 - acc: 0.8908 -- iter: 128/176
[A[ATraining Step: 167  | total loss: [1m[32m0.30668[0m[0m | time: 81.997s
[2K
| RMSProp | epoch: 028 | loss: 0.30668 - acc: 0.8892 -- iter: 160/176
[A[ATraining Step: 168  | total loss: [1m[32m0.29882[0m[0m | time: 95.457s
[2K
| RMSProp | epoch: 028 | loss: 0.29882 - acc: 0.8878 | val_loss: 3.36793 - val_acc: 0.3929 -- iter: 176/176
--
Training Step: 169  | total loss: [1m[32m0.27386[0m[0m | time: 29.628s
[2K
| RMSProp | epoch: 029 | loss: 0.27386 - acc: 0.8990 -- iter: 032/176
[A[ATraining Step: 170  | total loss: [1m[32m0.25653[0m[0m | time: 45.137s
[2K
| RMSProp | epoch: 029 | loss: 0.25653 - acc: 0.9060 -- iter: 064/176
[A[ATraining Step: 171  | total loss: [1m[32m0.39663[0m[0m | time: 53.772s
[2K
| RMSProp | epoch: 029 | loss: 0.39663 - acc: 0.8873 -- iter: 096/176
[A[ATraining Step: 172  | total loss: [1m[32m0.38549[0m[0m | time: 63.494s
[2K
| RMSProp | epoch: 029 | loss: 0.38549 - acc: 0.8923 -- iter: 128/176
[A[ATraining Step: 173  | total loss: [1m[32m0.36638[0m[0m | time: 77.760s
[2K
| RMSProp | epoch: 029 | loss: 0.36638 - acc: 0.8999 -- iter: 160/176
[A[ATraining Step: 174  | total loss: [1m[32m0.34006[0m[0m | time: 90.227s
[2K
| RMSProp | epoch: 029 | loss: 0.34006 - acc: 0.9037 | val_loss: 0.67173 - val_acc: 0.8036 -- iter: 176/176
--
Training Step: 175  | total loss: [1m[32m0.32266[0m[0m | time: 6.584s
[2K
| RMSProp | epoch: 030 | loss: 0.32266 - acc: 0.9071 -- iter: 032/176
[A[ATraining Step: 176  | total loss: [1m[32m0.29376[0m[0m | time: 19.338s
[2K
| RMSProp | epoch: 030 | loss: 0.29376 - acc: 0.9164 -- iter: 064/176
[A[ATraining Step: 177  | total loss: [1m[32m0.30577[0m[0m | time: 32.010s
[2K
| RMSProp | epoch: 030 | loss: 0.30577 - acc: 0.9060 -- iter: 096/176
[A[ATraining Step: 178  | total loss: [1m[32m0.28982[0m[0m | time: 44.336s
[2K
| RMSProp | epoch: 030 | loss: 0.28982 - acc: 0.9091 -- iter: 128/176
[A[ATraining Step: 179  | total loss: [1m[32m0.27550[0m[0m | time: 57.269s
[2K
| RMSProp | epoch: 030 | loss: 0.27550 - acc: 0.9088 -- iter: 160/176
[A[ATraining Step: 180  | total loss: [1m[32m0.26284[0m[0m | time: 74.077s
[2K
| RMSProp | epoch: 030 | loss: 0.26284 - acc: 0.9148 | val_loss: 0.51979 - val_acc: 0.8571 -- iter: 176/176
--
Validation AUC:0.8957219251336899
Validation AUPRC:0.917707919855884
Test AUC:0.935483870967742
Test AUPRC:0.9633240880571248
BestTestF1Score	0.89	0.75	0.88	0.88	0.9	28	4	21	3	0.52
BestTestMCCScore	0.86	0.73	0.86	0.96	0.77	24	1	24	7	0.86
BestTestAccuracyScore	0.92	0.82	0.91	0.93	0.9	28	2	23	3	0.68
BestValidationF1Score	0.89	0.7	0.86	0.84	0.94	32	6	16	2	0.52
BestValidationMCC	0.85	0.7	0.84	0.96	0.76	26	1	21	8	0.86
BestValidationAccuracy	0.88	0.7	0.86	0.88	0.88	30	4	18	4	0.68
TestPredictions (Threshold:0.86)
CHEMBL3684046,FN,ACT,0.699999988079071	CHEMBL517154,TN,INACT,0.019999999552965164	CHEMBL3684049,TP,ACT,0.9700000286102295	CHEMBL1336,TP,ACT,1.0	CHEMBL607707,FN,ACT,0.7599999904632568	CHEMBL521734,TN,INACT,0.75	CHEMBL2392388,TN,INACT,0.3799999952316284	CHEMBL215152,TP,ACT,0.9900000095367432	CHEMBL386051,TP,ACT,0.949999988079071	CHEMBL318461,TN,INACT,0.009999999776482582	CHEMBL456112,TN,INACT,0.5099999904632568	CHEMBL3684042,TP,ACT,1.0	CHEMBL486487,TN,INACT,0.5099999904632568	CHEMBL3684000,TP,ACT,0.9700000286102295	CHEMBL1933802,FP,INACT,0.949999988079071	CHEMBL512658,TN,INACT,0.2199999988079071	CHEMBL560278,TN,INACT,0.0	CHEMBL1909651,TN,INACT,0.6499999761581421	CHEMBL559882,TN,INACT,0.0	CHEMBL2392236,TN,INACT,0.05000000074505806	CHEMBL2392366,TN,INACT,0.12999999523162842	CHEMBL3684004,TP,ACT,0.9700000286102295	CHEMBL558752,TP,ACT,0.9800000190734863	CHEMBL1331525,TN,INACT,0.0	CHEMBL3683988,TP,ACT,0.9599999785423279	CHEMBL1933806,TN,INACT,0.36000001430511475	CHEMBL456797,TN,INACT,0.009999999776482582	CHEMBL278041,FN,ACT,0.029999999329447746	CHEMBL3684055,TP,ACT,1.0	CHEMBL522760,TN,INACT,0.17000000178813934	CHEMBL3684052,TP,ACT,0.9900000095367432	CHEMBL1725279,FN,ACT,0.0	CHEMBL2312148,TP,ACT,0.9900000095367432	CHEMBL1908396,TP,ACT,0.9900000095367432	CHEMBL456965,TN,INACT,0.029999999329447746	CHEMBL3684016,TP,ACT,0.9700000286102295	CHEMBL2312151,TP,ACT,0.9900000095367432	CHEMBL576982,TP,ACT,0.9900000095367432	CHEMBL3684038,TP,ACT,0.9900000095367432	CHEMBL522892,TP,ACT,0.8700000047683716	CHEMBL515674,TN,INACT,0.009999999776482582	CHEMBL2392385,TN,INACT,0.0	CHEMBL3609569,TN,INACT,0.0	CHEMBL1910762,TN,INACT,0.18000000715255737	CHEMBL3683985,FN,ACT,0.5099999904632568	CHEMBL2312152,TP,ACT,0.9900000095367432	CHEMBL498520,TN,INACT,0.1899999976158142	CHEMBL562198,TN,INACT,0.0	CHEMBL1721885,FN,ACT,0.8100000023841858	CHEMBL3684017,TP,ACT,0.9700000286102295	CHEMBL3684034,TP,ACT,0.9900000095367432	CHEMBL1910759,TN,INACT,0.6000000238418579	CHEMBL3684031,TP,ACT,0.949999988079071	CHEMBL3683992,TP,ACT,0.9800000190734863	CHEMBL939,FN,ACT,0.6899999976158142	CHEMBL3684020,TP,ACT,0.9599999785423279	

