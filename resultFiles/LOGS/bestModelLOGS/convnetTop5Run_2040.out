CNNModel CHEMBL5932 adam 0.001 30 128 0 0.6 False True
Number of active compounds :	199
Number of inactive compounds :	199
---------------------------------
Run id: CNNModel_CHEMBL5932_adam_0.001_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5932_adam_0.001_30_128_0.6_True/
---------------------------------
Training samples: 242
Validation samples: 76
--
Training Step: 1  | time: 1.545s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/242
[A[ATraining Step: 2  | total loss: [1m[32m0.62409[0m[0m | time: 2.730s
[2K
| Adam | epoch: 001 | loss: 0.62409 - acc: 0.2812 -- iter: 064/242
[A[ATraining Step: 3  | total loss: [1m[32m0.68063[0m[0m | time: 3.925s
[2K
| Adam | epoch: 001 | loss: 0.68063 - acc: 0.4347 -- iter: 096/242
[A[ATraining Step: 4  | total loss: [1m[32m0.69063[0m[0m | time: 5.172s
[2K
| Adam | epoch: 001 | loss: 0.69063 - acc: 0.3196 -- iter: 128/242
[A[ATraining Step: 5  | total loss: [1m[32m0.69179[0m[0m | time: 6.465s
[2K
| Adam | epoch: 001 | loss: 0.69179 - acc: 0.4661 -- iter: 160/242
[A[ATraining Step: 6  | total loss: [1m[32m0.70126[0m[0m | time: 7.839s
[2K
| Adam | epoch: 001 | loss: 0.70126 - acc: 0.3674 -- iter: 192/242
[A[ATraining Step: 7  | total loss: [1m[32m0.69636[0m[0m | time: 8.924s
[2K
| Adam | epoch: 001 | loss: 0.69636 - acc: 0.4469 -- iter: 224/242
[A[ATraining Step: 8  | total loss: [1m[32m0.69454[0m[0m | time: 10.562s
[2K
| Adam | epoch: 001 | loss: 0.69454 - acc: 0.4944 | val_loss: 0.69324 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 9  | total loss: [1m[32m0.69372[0m[0m | time: 0.786s
[2K
| Adam | epoch: 002 | loss: 0.69372 - acc: 0.5562 -- iter: 032/242
[A[ATraining Step: 10  | total loss: [1m[32m0.69332[0m[0m | time: 1.952s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.5559 -- iter: 064/242
[A[ATraining Step: 11  | total loss: [1m[32m0.69300[0m[0m | time: 2.891s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5886 -- iter: 096/242
[A[ATraining Step: 12  | total loss: [1m[32m0.69266[0m[0m | time: 4.024s
[2K
| Adam | epoch: 002 | loss: 0.69266 - acc: 0.5909 -- iter: 128/242
[A[ATraining Step: 13  | total loss: [1m[32m0.69356[0m[0m | time: 5.188s
[2K
| Adam | epoch: 002 | loss: 0.69356 - acc: 0.5118 -- iter: 160/242
[A[ATraining Step: 14  | total loss: [1m[32m0.69204[0m[0m | time: 6.316s
[2K
| Adam | epoch: 002 | loss: 0.69204 - acc: 0.5837 -- iter: 192/242
[A[ATraining Step: 15  | total loss: [1m[32m0.69300[0m[0m | time: 7.440s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5265 -- iter: 224/242
[A[ATraining Step: 16  | total loss: [1m[32m0.69253[0m[0m | time: 9.664s
[2K
| Adam | epoch: 002 | loss: 0.69253 - acc: 0.5400 | val_loss: 0.69445 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 17  | total loss: [1m[32m0.69312[0m[0m | time: 0.707s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.5143 -- iter: 032/242
[A[ATraining Step: 18  | total loss: [1m[32m0.69310[0m[0m | time: 1.451s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5094 -- iter: 064/242
[A[ATraining Step: 19  | total loss: [1m[32m0.69313[0m[0m | time: 2.737s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5062 -- iter: 096/242
[A[ATraining Step: 20  | total loss: [1m[32m0.69171[0m[0m | time: 4.091s
[2K
| Adam | epoch: 003 | loss: 0.69171 - acc: 0.5444 -- iter: 128/242
[A[ATraining Step: 21  | total loss: [1m[32m0.69221[0m[0m | time: 5.266s
[2K
| Adam | epoch: 003 | loss: 0.69221 - acc: 0.5306 -- iter: 160/242
[A[ATraining Step: 22  | total loss: [1m[32m0.69134[0m[0m | time: 6.504s
[2K
| Adam | epoch: 003 | loss: 0.69134 - acc: 0.5496 -- iter: 192/242
[A[ATraining Step: 23  | total loss: [1m[32m0.69410[0m[0m | time: 7.834s
[2K
| Adam | epoch: 003 | loss: 0.69410 - acc: 0.4898 -- iter: 224/242
[A[ATraining Step: 24  | total loss: [1m[32m0.69183[0m[0m | time: 10.095s
[2K
| Adam | epoch: 003 | loss: 0.69183 - acc: 0.5366 | val_loss: 0.69577 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 25  | total loss: [1m[32m0.69051[0m[0m | time: 1.212s
[2K
| Adam | epoch: 004 | loss: 0.69051 - acc: 0.5607 -- iter: 032/242
[A[ATraining Step: 26  | total loss: [1m[32m0.68986[0m[0m | time: 1.934s
[2K
| Adam | epoch: 004 | loss: 0.68986 - acc: 0.5695 -- iter: 064/242
[A[ATraining Step: 27  | total loss: [1m[32m0.69190[0m[0m | time: 2.696s
[2K
| Adam | epoch: 004 | loss: 0.69190 - acc: 0.5373 -- iter: 096/242
[A[ATraining Step: 28  | total loss: [1m[32m0.69332[0m[0m | time: 3.887s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.5141 -- iter: 128/242
[A[ATraining Step: 29  | total loss: [1m[32m0.69558[0m[0m | time: 5.069s
[2K
| Adam | epoch: 004 | loss: 0.69558 - acc: 0.4803 -- iter: 160/242
[A[ATraining Step: 30  | total loss: [1m[32m0.69468[0m[0m | time: 6.211s
[2K
| Adam | epoch: 004 | loss: 0.69468 - acc: 0.4923 -- iter: 192/242
[A[ATraining Step: 31  | total loss: [1m[32m0.69393[0m[0m | time: 7.149s
[2K
| Adam | epoch: 004 | loss: 0.69393 - acc: 0.5013 -- iter: 224/242
[A[ATraining Step: 32  | total loss: [1m[32m0.69432[0m[0m | time: 9.047s
[2K
| Adam | epoch: 004 | loss: 0.69432 - acc: 0.4940 | val_loss: 0.69583 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 33  | total loss: [1m[32m0.69371[0m[0m | time: 0.821s
[2K
| Adam | epoch: 005 | loss: 0.69371 - acc: 0.5022 -- iter: 032/242
[A[ATraining Step: 34  | total loss: [1m[32m0.69328[0m[0m | time: 1.798s
[2K
| Adam | epoch: 005 | loss: 0.69328 - acc: 0.5084 -- iter: 064/242
[A[ATraining Step: 35  | total loss: [1m[32m0.69182[0m[0m | time: 2.425s
[2K
| Adam | epoch: 005 | loss: 0.69182 - acc: 0.5328 -- iter: 096/242
[A[ATraining Step: 36  | total loss: [1m[32m0.69414[0m[0m | time: 3.028s
[2K
| Adam | epoch: 005 | loss: 0.69414 - acc: 0.4920 -- iter: 128/242
[A[ATraining Step: 37  | total loss: [1m[32m0.69599[0m[0m | time: 3.942s
[2K
| Adam | epoch: 005 | loss: 0.69599 - acc: 0.4603 -- iter: 160/242
[A[ATraining Step: 38  | total loss: [1m[32m0.69387[0m[0m | time: 4.823s
[2K
| Adam | epoch: 005 | loss: 0.69387 - acc: 0.4986 -- iter: 192/242
[A[ATraining Step: 39  | total loss: [1m[32m0.69441[0m[0m | time: 5.715s
[2K
| Adam | epoch: 005 | loss: 0.69441 - acc: 0.4869 -- iter: 224/242
[A[ATraining Step: 40  | total loss: [1m[32m0.69309[0m[0m | time: 7.609s
[2K
| Adam | epoch: 005 | loss: 0.69309 - acc: 0.5128 | val_loss: 0.69534 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 41  | total loss: [1m[32m0.69315[0m[0m | time: 0.919s
[2K
| Adam | epoch: 006 | loss: 0.69315 - acc: 0.5105 -- iter: 032/242
[A[ATraining Step: 42  | total loss: [1m[32m0.69375[0m[0m | time: 1.827s
[2K
| Adam | epoch: 006 | loss: 0.69375 - acc: 0.4973 -- iter: 064/242
[A[ATraining Step: 43  | total loss: [1m[32m0.69291[0m[0m | time: 2.755s
[2K
| Adam | epoch: 006 | loss: 0.69291 - acc: 0.5143 -- iter: 096/242
[A[ATraining Step: 44  | total loss: [1m[32m0.69300[0m[0m | time: 3.232s
[2K
| Adam | epoch: 006 | loss: 0.69300 - acc: 0.5119 -- iter: 128/242
[A[ATraining Step: 45  | total loss: [1m[32m0.69347[0m[0m | time: 3.726s
[2K
| Adam | epoch: 006 | loss: 0.69347 - acc: 0.5004 -- iter: 160/242
[A[ATraining Step: 46  | total loss: [1m[32m0.69392[0m[0m | time: 4.719s
[2K
| Adam | epoch: 006 | loss: 0.69392 - acc: 0.4911 -- iter: 192/242
[A[ATraining Step: 47  | total loss: [1m[32m0.69360[0m[0m | time: 5.780s
[2K
| Adam | epoch: 006 | loss: 0.69360 - acc: 0.4977 -- iter: 224/242
[A[ATraining Step: 48  | total loss: [1m[32m0.69338[0m[0m | time: 7.787s
[2K
| Adam | epoch: 006 | loss: 0.69338 - acc: 0.5031 | val_loss: 0.69492 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 49  | total loss: [1m[32m0.69358[0m[0m | time: 0.903s
[2K
| Adam | epoch: 007 | loss: 0.69358 - acc: 0.4976 -- iter: 032/242
[A[ATraining Step: 50  | total loss: [1m[32m0.69378[0m[0m | time: 1.785s
[2K
| Adam | epoch: 007 | loss: 0.69378 - acc: 0.4932 -- iter: 064/242
[A[ATraining Step: 51  | total loss: [1m[32m0.69334[0m[0m | time: 2.671s
[2K
| Adam | epoch: 007 | loss: 0.69334 - acc: 0.5037 -- iter: 096/242
[A[ATraining Step: 52  | total loss: [1m[32m0.69332[0m[0m | time: 3.592s
[2K
| Adam | epoch: 007 | loss: 0.69332 - acc: 0.5032 -- iter: 128/242
[A[ATraining Step: 53  | total loss: [1m[32m0.69261[0m[0m | time: 4.121s
[2K
| Adam | epoch: 007 | loss: 0.69261 - acc: 0.5211 -- iter: 160/242
[A[ATraining Step: 54  | total loss: [1m[32m0.69179[0m[0m | time: 4.684s
[2K
| Adam | epoch: 007 | loss: 0.69179 - acc: 0.5423 -- iter: 192/242
[A[ATraining Step: 55  | total loss: [1m[32m0.69105[0m[0m | time: 5.608s
[2K
| Adam | epoch: 007 | loss: 0.69105 - acc: 0.5600 -- iter: 224/242
[A[ATraining Step: 56  | total loss: [1m[32m0.69180[0m[0m | time: 7.600s
[2K
| Adam | epoch: 007 | loss: 0.69180 - acc: 0.5428 | val_loss: 0.69536 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 57  | total loss: [1m[32m0.69182[0m[0m | time: 1.094s
[2K
| Adam | epoch: 008 | loss: 0.69182 - acc: 0.5412 -- iter: 032/242
[A[ATraining Step: 58  | total loss: [1m[32m0.69182[0m[0m | time: 2.408s
[2K
| Adam | epoch: 008 | loss: 0.69182 - acc: 0.5399 -- iter: 064/242
[A[ATraining Step: 59  | total loss: [1m[32m0.69115[0m[0m | time: 3.528s
[2K
| Adam | epoch: 008 | loss: 0.69115 - acc: 0.5513 -- iter: 096/242
[A[ATraining Step: 60  | total loss: [1m[32m0.69149[0m[0m | time: 4.748s
[2K
| Adam | epoch: 008 | loss: 0.69149 - acc: 0.5445 -- iter: 128/242
[A[ATraining Step: 61  | total loss: [1m[32m0.69253[0m[0m | time: 13.602s
[2K
| Adam | epoch: 008 | loss: 0.69253 - acc: 0.5265 -- iter: 160/242
[A[ATraining Step: 62  | total loss: [1m[32m0.69263[0m[0m | time: 18.035s
[2K
| Adam | epoch: 008 | loss: 0.69263 - acc: 0.5231 -- iter: 192/242
[A[ATraining Step: 63  | total loss: [1m[32m0.69227[0m[0m | time: 25.852s
[2K
| Adam | epoch: 008 | loss: 0.69227 - acc: 0.5272 -- iter: 224/242
[A[ATraining Step: 64  | total loss: [1m[32m0.69196[0m[0m | time: 27.971s
[2K
| Adam | epoch: 008 | loss: 0.69196 - acc: 0.5307 | val_loss: 0.69599 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 65  | total loss: [1m[32m0.69291[0m[0m | time: 1.055s
[2K
| Adam | epoch: 009 | loss: 0.69291 - acc: 0.5154 -- iter: 032/242
[A[ATraining Step: 66  | total loss: [1m[32m0.69144[0m[0m | time: 2.050s
[2K
| Adam | epoch: 009 | loss: 0.69144 - acc: 0.5363 -- iter: 064/242
[A[ATraining Step: 67  | total loss: [1m[32m0.69273[0m[0m | time: 3.182s
[2K
| Adam | epoch: 009 | loss: 0.69273 - acc: 0.5170 -- iter: 096/242
[A[ATraining Step: 68  | total loss: [1m[32m0.69296[0m[0m | time: 4.351s
[2K
| Adam | epoch: 009 | loss: 0.69296 - acc: 0.5112 -- iter: 128/242
[A[ATraining Step: 69  | total loss: [1m[32m0.69176[0m[0m | time: 5.455s
[2K
| Adam | epoch: 009 | loss: 0.69176 - acc: 0.5282 -- iter: 160/242
[A[ATraining Step: 70  | total loss: [1m[32m0.69256[0m[0m | time: 6.659s
[2K
| Adam | epoch: 009 | loss: 0.69256 - acc: 0.5141 -- iter: 192/242
[A[ATraining Step: 71  | total loss: [1m[32m0.69214[0m[0m | time: 7.410s
[2K
| Adam | epoch: 009 | loss: 0.69214 - acc: 0.5161 -- iter: 224/242
[A[ATraining Step: 72  | total loss: [1m[32m0.69251[0m[0m | time: 9.139s
[2K
| Adam | epoch: 009 | loss: 0.69251 - acc: 0.5080 | val_loss: 0.69219 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 73  | total loss: [1m[32m0.69265[0m[0m | time: 1.431s
[2K
| Adam | epoch: 010 | loss: 0.69265 - acc: 0.5010 -- iter: 032/242
[A[ATraining Step: 74  | total loss: [1m[32m0.69173[0m[0m | time: 2.501s
[2K
| Adam | epoch: 010 | loss: 0.69173 - acc: 0.5214 -- iter: 064/242
[A[ATraining Step: 75  | total loss: [1m[32m0.69093[0m[0m | time: 3.592s
[2K
| Adam | epoch: 010 | loss: 0.69093 - acc: 0.5293 -- iter: 096/242
[A[ATraining Step: 76  | total loss: [1m[32m0.68785[0m[0m | time: 4.857s
[2K
| Adam | epoch: 010 | loss: 0.68785 - acc: 0.5496 -- iter: 128/242
[A[ATraining Step: 77  | total loss: [1m[32m0.68781[0m[0m | time: 6.086s
[2K
| Adam | epoch: 010 | loss: 0.68781 - acc: 0.5476 -- iter: 160/242
[A[ATraining Step: 78  | total loss: [1m[32m0.68883[0m[0m | time: 7.148s
[2K
| Adam | epoch: 010 | loss: 0.68883 - acc: 0.5426 -- iter: 192/242
[A[ATraining Step: 79  | total loss: [1m[32m0.69248[0m[0m | time: 8.116s
[2K
| Adam | epoch: 010 | loss: 0.69248 - acc: 0.5253 -- iter: 224/242
[A[ATraining Step: 80  | total loss: [1m[32m0.69150[0m[0m | time: 9.858s
[2K
| Adam | epoch: 010 | loss: 0.69150 - acc: 0.5227 | val_loss: 0.68821 - val_acc: 0.4605 -- iter: 242/242
--
Training Step: 81  | total loss: [1m[32m0.69031[0m[0m | time: 0.738s
[2K
| Adam | epoch: 011 | loss: 0.69031 - acc: 0.5204 -- iter: 032/242
[A[ATraining Step: 82  | total loss: [1m[32m0.68939[0m[0m | time: 1.873s
[2K
| Adam | epoch: 011 | loss: 0.68939 - acc: 0.5184 -- iter: 064/242
[A[ATraining Step: 83  | total loss: [1m[32m0.68936[0m[0m | time: 2.951s
[2K
| Adam | epoch: 011 | loss: 0.68936 - acc: 0.5197 -- iter: 096/242
[A[ATraining Step: 84  | total loss: [1m[32m0.68788[0m[0m | time: 4.119s
[2K
| Adam | epoch: 011 | loss: 0.68788 - acc: 0.5364 -- iter: 128/242
[A[ATraining Step: 85  | total loss: [1m[32m0.68524[0m[0m | time: 5.350s
[2K
| Adam | epoch: 011 | loss: 0.68524 - acc: 0.5547 -- iter: 160/242
[A[ATraining Step: 86  | total loss: [1m[32m0.68353[0m[0m | time: 6.555s
[2K
| Adam | epoch: 011 | loss: 0.68353 - acc: 0.5492 -- iter: 192/242
[A[ATraining Step: 87  | total loss: [1m[32m0.68501[0m[0m | time: 7.814s
[2K
| Adam | epoch: 011 | loss: 0.68501 - acc: 0.5412 -- iter: 224/242
[A[ATraining Step: 88  | total loss: [1m[32m0.68101[0m[0m | time: 9.723s
[2K
| Adam | epoch: 011 | loss: 0.68101 - acc: 0.5495 | val_loss: 0.64593 - val_acc: 0.6711 -- iter: 242/242
--
Training Step: 89  | total loss: [1m[32m0.67453[0m[0m | time: 0.813s
[2K
| Adam | epoch: 012 | loss: 0.67453 - acc: 0.5790 -- iter: 032/242
[A[ATraining Step: 90  | total loss: [1m[32m0.66557[0m[0m | time: 1.548s
[2K
| Adam | epoch: 012 | loss: 0.66557 - acc: 0.5933 -- iter: 064/242
[A[ATraining Step: 91  | total loss: [1m[32m0.65126[0m[0m | time: 2.540s
[2K
| Adam | epoch: 012 | loss: 0.65126 - acc: 0.6117 -- iter: 096/242
[A[ATraining Step: 92  | total loss: [1m[32m0.65655[0m[0m | time: 3.724s
[2K
| Adam | epoch: 012 | loss: 0.65655 - acc: 0.6068 -- iter: 128/242
[A[ATraining Step: 93  | total loss: [1m[32m0.64829[0m[0m | time: 4.925s
[2K
| Adam | epoch: 012 | loss: 0.64829 - acc: 0.6149 -- iter: 160/242
[A[ATraining Step: 94  | total loss: [1m[32m0.64391[0m[0m | time: 6.050s
[2K
| Adam | epoch: 012 | loss: 0.64391 - acc: 0.6221 -- iter: 192/242
[A[ATraining Step: 95  | total loss: [1m[32m0.63727[0m[0m | time: 7.284s
[2K
| Adam | epoch: 012 | loss: 0.63727 - acc: 0.6381 -- iter: 224/242
[A[ATraining Step: 96  | total loss: [1m[32m0.62534[0m[0m | time: 9.365s
[2K
| Adam | epoch: 012 | loss: 0.62534 - acc: 0.6555 | val_loss: 0.63894 - val_acc: 0.6842 -- iter: 242/242
--
Training Step: 97  | total loss: [1m[32m0.61874[0m[0m | time: 1.002s
[2K
| Adam | epoch: 013 | loss: 0.61874 - acc: 0.6681 -- iter: 032/242
[A[ATraining Step: 98  | total loss: [1m[32m0.60744[0m[0m | time: 1.639s
[2K
| Adam | epoch: 013 | loss: 0.60744 - acc: 0.6794 -- iter: 064/242
[A[ATraining Step: 99  | total loss: [1m[32m0.59739[0m[0m | time: 2.298s
[2K
| Adam | epoch: 013 | loss: 0.59739 - acc: 0.6837 -- iter: 096/242
[A[ATraining Step: 100  | total loss: [1m[32m0.58111[0m[0m | time: 3.295s
[2K
| Adam | epoch: 013 | loss: 0.58111 - acc: 0.7042 -- iter: 128/242
[A[ATraining Step: 101  | total loss: [1m[32m0.58771[0m[0m | time: 4.452s
[2K
| Adam | epoch: 013 | loss: 0.58771 - acc: 0.6994 -- iter: 160/242
[A[ATraining Step: 102  | total loss: [1m[32m0.59016[0m[0m | time: 5.625s
[2K
| Adam | epoch: 013 | loss: 0.59016 - acc: 0.7013 -- iter: 192/242
[A[ATraining Step: 103  | total loss: [1m[32m0.58213[0m[0m | time: 6.888s
[2K
| Adam | epoch: 013 | loss: 0.58213 - acc: 0.7062 -- iter: 224/242
[A[ATraining Step: 104  | total loss: [1m[32m0.57186[0m[0m | time: 8.981s
[2K
| Adam | epoch: 013 | loss: 0.57186 - acc: 0.7137 | val_loss: 0.56012 - val_acc: 0.7500 -- iter: 242/242
--
Training Step: 105  | total loss: [1m[32m0.56908[0m[0m | time: 1.151s
[2K
| Adam | epoch: 014 | loss: 0.56908 - acc: 0.7080 -- iter: 032/242
[A[ATraining Step: 106  | total loss: [1m[32m0.55008[0m[0m | time: 2.258s
[2K
| Adam | epoch: 014 | loss: 0.55008 - acc: 0.7247 -- iter: 064/242
[A[ATraining Step: 107  | total loss: [1m[32m0.52727[0m[0m | time: 2.867s
[2K
| Adam | epoch: 014 | loss: 0.52727 - acc: 0.7397 -- iter: 096/242
[A[ATraining Step: 108  | total loss: [1m[32m0.53024[0m[0m | time: 3.504s
[2K
| Adam | epoch: 014 | loss: 0.53024 - acc: 0.7324 -- iter: 128/242
[A[ATraining Step: 109  | total loss: [1m[32m0.52541[0m[0m | time: 4.687s
[2K
| Adam | epoch: 014 | loss: 0.52541 - acc: 0.7369 -- iter: 160/242
[A[ATraining Step: 110  | total loss: [1m[32m0.51378[0m[0m | time: 5.890s
[2K
| Adam | epoch: 014 | loss: 0.51378 - acc: 0.7445 -- iter: 192/242
[A[ATraining Step: 111  | total loss: [1m[32m0.50230[0m[0m | time: 7.150s
[2K
| Adam | epoch: 014 | loss: 0.50230 - acc: 0.7575 -- iter: 224/242
[A[ATraining Step: 112  | total loss: [1m[32m0.51555[0m[0m | time: 9.288s
[2K
| Adam | epoch: 014 | loss: 0.51555 - acc: 0.7443 | val_loss: 0.69494 - val_acc: 0.5789 -- iter: 242/242
--
Training Step: 113  | total loss: [1m[32m0.55979[0m[0m | time: 1.242s
[2K
| Adam | epoch: 015 | loss: 0.55979 - acc: 0.7042 -- iter: 032/242
[A[ATraining Step: 114  | total loss: [1m[32m0.57231[0m[0m | time: 2.435s
[2K
| Adam | epoch: 015 | loss: 0.57231 - acc: 0.6869 -- iter: 064/242
[A[ATraining Step: 115  | total loss: [1m[32m0.57481[0m[0m | time: 3.691s
[2K
| Adam | epoch: 015 | loss: 0.57481 - acc: 0.6839 -- iter: 096/242
[A[ATraining Step: 116  | total loss: [1m[32m0.55872[0m[0m | time: 4.394s
[2K
| Adam | epoch: 015 | loss: 0.55872 - acc: 0.6999 -- iter: 128/242
[A[ATraining Step: 117  | total loss: [1m[32m0.54992[0m[0m | time: 4.991s
[2K
| Adam | epoch: 015 | loss: 0.54992 - acc: 0.7021 -- iter: 160/242
[A[ATraining Step: 118  | total loss: [1m[32m0.54831[0m[0m | time: 6.167s
[2K
| Adam | epoch: 015 | loss: 0.54831 - acc: 0.7041 -- iter: 192/242
[A[ATraining Step: 119  | total loss: [1m[32m0.53702[0m[0m | time: 7.318s
[2K
| Adam | epoch: 015 | loss: 0.53702 - acc: 0.7149 -- iter: 224/242
[A[ATraining Step: 120  | total loss: [1m[32m0.53313[0m[0m | time: 9.540s
[2K
| Adam | epoch: 015 | loss: 0.53313 - acc: 0.7185 | val_loss: 0.54279 - val_acc: 0.7368 -- iter: 242/242
--
Training Step: 121  | total loss: [1m[32m0.53095[0m[0m | time: 1.289s
[2K
| Adam | epoch: 016 | loss: 0.53095 - acc: 0.7216 -- iter: 032/242
[A[ATraining Step: 122  | total loss: [1m[32m0.51339[0m[0m | time: 2.643s
[2K
| Adam | epoch: 016 | loss: 0.51339 - acc: 0.7307 -- iter: 064/242
[A[ATraining Step: 123  | total loss: [1m[32m0.50192[0m[0m | time: 3.803s
[2K
| Adam | epoch: 016 | loss: 0.50192 - acc: 0.7514 -- iter: 096/242
[A[ATraining Step: 124  | total loss: [1m[32m0.48570[0m[0m | time: 4.818s
[2K
| Adam | epoch: 016 | loss: 0.48570 - acc: 0.7700 -- iter: 128/242
[A[ATraining Step: 125  | total loss: [1m[32m0.48277[0m[0m | time: 5.413s
[2K
| Adam | epoch: 016 | loss: 0.48277 - acc: 0.7711 -- iter: 160/242
[A[ATraining Step: 126  | total loss: [1m[32m0.48115[0m[0m | time: 6.044s
[2K
| Adam | epoch: 016 | loss: 0.48115 - acc: 0.7662 -- iter: 192/242
[A[ATraining Step: 127  | total loss: [1m[32m0.47754[0m[0m | time: 7.225s
[2K
| Adam | epoch: 016 | loss: 0.47754 - acc: 0.7674 -- iter: 224/242
[A[ATraining Step: 128  | total loss: [1m[32m0.47022[0m[0m | time: 9.440s
[2K
| Adam | epoch: 016 | loss: 0.47022 - acc: 0.7719 | val_loss: 0.50969 - val_acc: 0.7632 -- iter: 242/242
--
Training Step: 129  | total loss: [1m[32m0.44760[0m[0m | time: 1.020s
[2K
| Adam | epoch: 017 | loss: 0.44760 - acc: 0.7916 -- iter: 032/242
[A[ATraining Step: 130  | total loss: [1m[32m0.50579[0m[0m | time: 2.090s
[2K
| Adam | epoch: 017 | loss: 0.50579 - acc: 0.7655 -- iter: 064/242
[A[ATraining Step: 131  | total loss: [1m[32m0.48731[0m[0m | time: 3.308s
[2K
| Adam | epoch: 017 | loss: 0.48731 - acc: 0.7796 -- iter: 096/242
[A[ATraining Step: 132  | total loss: [1m[32m0.46969[0m[0m | time: 4.447s
[2K
| Adam | epoch: 017 | loss: 0.46969 - acc: 0.7923 -- iter: 128/242
[A[ATraining Step: 133  | total loss: [1m[32m0.45491[0m[0m | time: 5.526s
[2K
| Adam | epoch: 017 | loss: 0.45491 - acc: 0.8006 -- iter: 160/242
[A[ATraining Step: 134  | total loss: [1m[32m0.44397[0m[0m | time: 6.323s
[2K
| Adam | epoch: 017 | loss: 0.44397 - acc: 0.8080 -- iter: 192/242
[A[ATraining Step: 135  | total loss: [1m[32m0.43719[0m[0m | time: 7.065s
[2K
| Adam | epoch: 017 | loss: 0.43719 - acc: 0.8105 -- iter: 224/242
[A[ATraining Step: 136  | total loss: [1m[32m0.42793[0m[0m | time: 9.399s
[2K
| Adam | epoch: 017 | loss: 0.42793 - acc: 0.8073 | val_loss: 0.64819 - val_acc: 0.7368 -- iter: 242/242
--
Training Step: 137  | total loss: [1m[32m0.41680[0m[0m | time: 1.007s
[2K
| Adam | epoch: 018 | loss: 0.41680 - acc: 0.8109 -- iter: 032/242
[A[ATraining Step: 138  | total loss: [1m[32m0.39682[0m[0m | time: 2.171s
[2K
| Adam | epoch: 018 | loss: 0.39682 - acc: 0.8236 -- iter: 064/242
[A[ATraining Step: 139  | total loss: [1m[32m0.38969[0m[0m | time: 3.359s
[2K
| Adam | epoch: 018 | loss: 0.38969 - acc: 0.8225 -- iter: 096/242
[A[ATraining Step: 140  | total loss: [1m[32m0.38078[0m[0m | time: 4.701s
[2K
| Adam | epoch: 018 | loss: 0.38078 - acc: 0.8277 -- iter: 128/242
[A[ATraining Step: 141  | total loss: [1m[32m0.37887[0m[0m | time: 5.991s
[2K
| Adam | epoch: 018 | loss: 0.37887 - acc: 0.8231 -- iter: 160/242
[A[ATraining Step: 142  | total loss: [1m[32m0.35814[0m[0m | time: 7.164s
[2K
| Adam | epoch: 018 | loss: 0.35814 - acc: 0.8376 -- iter: 192/242
[A[ATraining Step: 143  | total loss: [1m[32m0.33941[0m[0m | time: 7.720s
[2K
| Adam | epoch: 018 | loss: 0.33941 - acc: 0.8507 -- iter: 224/242
[A[ATraining Step: 144  | total loss: [1m[32m0.32159[0m[0m | time: 9.449s
[2K
| Adam | epoch: 018 | loss: 0.32159 - acc: 0.8601 | val_loss: 0.59758 - val_acc: 0.7763 -- iter: 242/242
--
Training Step: 145  | total loss: [1m[32m0.29932[0m[0m | time: 1.122s
[2K
| Adam | epoch: 019 | loss: 0.29932 - acc: 0.8741 -- iter: 032/242
[A[ATraining Step: 146  | total loss: [1m[32m0.28656[0m[0m | time: 2.396s
[2K
| Adam | epoch: 019 | loss: 0.28656 - acc: 0.8804 -- iter: 064/242
[A[ATraining Step: 147  | total loss: [1m[32m0.29466[0m[0m | time: 3.727s
[2K
| Adam | epoch: 019 | loss: 0.29466 - acc: 0.8830 -- iter: 096/242
[A[ATraining Step: 148  | total loss: [1m[32m0.28602[0m[0m | time: 5.061s
[2K
| Adam | epoch: 019 | loss: 0.28602 - acc: 0.8822 -- iter: 128/242
[A[ATraining Step: 149  | total loss: [1m[32m0.26768[0m[0m | time: 6.165s
[2K
| Adam | epoch: 019 | loss: 0.26768 - acc: 0.8909 -- iter: 160/242
[A[ATraining Step: 150  | total loss: [1m[32m0.25095[0m[0m | time: 7.307s
[2K
| Adam | epoch: 019 | loss: 0.25095 - acc: 0.8987 -- iter: 192/242
[A[ATraining Step: 151  | total loss: [1m[32m0.23401[0m[0m | time: 8.521s
[2K
| Adam | epoch: 019 | loss: 0.23401 - acc: 0.9088 -- iter: 224/242
[A[ATraining Step: 152  | total loss: [1m[32m0.23610[0m[0m | time: 10.204s
[2K
| Adam | epoch: 019 | loss: 0.23610 - acc: 0.9085 | val_loss: 0.53787 - val_acc: 0.8026 -- iter: 242/242
--
Training Step: 153  | total loss: [1m[32m0.23686[0m[0m | time: 0.731s
[2K
| Adam | epoch: 020 | loss: 0.23686 - acc: 0.9066 -- iter: 032/242
[A[ATraining Step: 154  | total loss: [1m[32m0.23246[0m[0m | time: 2.006s
[2K
| Adam | epoch: 020 | loss: 0.23246 - acc: 0.9104 -- iter: 064/242
[A[ATraining Step: 155  | total loss: [1m[32m0.22710[0m[0m | time: 3.006s
[2K
| Adam | epoch: 020 | loss: 0.22710 - acc: 0.9131 -- iter: 096/242
[A[ATraining Step: 156  | total loss: [1m[32m0.21992[0m[0m | time: 4.108s
[2K
| Adam | epoch: 020 | loss: 0.21992 - acc: 0.9155 -- iter: 128/242
[A[ATraining Step: 157  | total loss: [1m[32m0.26306[0m[0m | time: 5.172s
[2K
| Adam | epoch: 020 | loss: 0.26306 - acc: 0.9115 -- iter: 160/242
[A[ATraining Step: 158  | total loss: [1m[32m0.23978[0m[0m | time: 6.316s
[2K
| Adam | epoch: 020 | loss: 0.23978 - acc: 0.9203 -- iter: 192/242
[A[ATraining Step: 159  | total loss: [1m[32m0.22662[0m[0m | time: 7.567s
[2K
| Adam | epoch: 020 | loss: 0.22662 - acc: 0.9220 -- iter: 224/242
[A[ATraining Step: 160  | total loss: [1m[32m0.22067[0m[0m | time: 9.872s
[2K
| Adam | epoch: 020 | loss: 0.22067 - acc: 0.9236 | val_loss: 0.50638 - val_acc: 0.7895 -- iter: 242/242
--
Training Step: 161  | total loss: [1m[32m0.20886[0m[0m | time: 0.671s
[2K
| Adam | epoch: 021 | loss: 0.20886 - acc: 0.9281 -- iter: 032/242
[A[ATraining Step: 162  | total loss: [1m[32m0.22042[0m[0m | time: 1.355s
[2K
| Adam | epoch: 021 | loss: 0.22042 - acc: 0.9242 -- iter: 064/242
[A[ATraining Step: 163  | total loss: [1m[32m0.21442[0m[0m | time: 2.480s
[2K
| Adam | epoch: 021 | loss: 0.21442 - acc: 0.9262 -- iter: 096/242
[A[ATraining Step: 164  | total loss: [1m[32m0.21446[0m[0m | time: 3.654s
[2K
| Adam | epoch: 021 | loss: 0.21446 - acc: 0.9242 -- iter: 128/242
[A[ATraining Step: 165  | total loss: [1m[32m0.23992[0m[0m | time: 4.733s
[2K
| Adam | epoch: 021 | loss: 0.23992 - acc: 0.9162 -- iter: 160/242
[A[ATraining Step: 166  | total loss: [1m[32m0.27970[0m[0m | time: 6.057s
[2K
| Adam | epoch: 021 | loss: 0.27970 - acc: 0.9120 -- iter: 192/242
[A[ATraining Step: 167  | total loss: [1m[32m0.26452[0m[0m | time: 7.355s
[2K
| Adam | epoch: 021 | loss: 0.26452 - acc: 0.9177 -- iter: 224/242
[A[ATraining Step: 168  | total loss: [1m[32m0.25618[0m[0m | time: 9.692s
[2K
| Adam | epoch: 021 | loss: 0.25618 - acc: 0.9197 | val_loss: 0.39396 - val_acc: 0.8421 -- iter: 242/242
--
Training Step: 169  | total loss: [1m[32m0.25317[0m[0m | time: 1.356s
[2K
| Adam | epoch: 022 | loss: 0.25317 - acc: 0.9184 -- iter: 032/242
[A[ATraining Step: 170  | total loss: [1m[32m0.24997[0m[0m | time: 2.069s
[2K
| Adam | epoch: 022 | loss: 0.24997 - acc: 0.9171 -- iter: 064/242
[A[ATraining Step: 171  | total loss: [1m[32m0.23619[0m[0m | time: 2.843s
[2K
| Adam | epoch: 022 | loss: 0.23619 - acc: 0.9199 -- iter: 096/242
[A[ATraining Step: 172  | total loss: [1m[32m0.22506[0m[0m | time: 4.095s
[2K
| Adam | epoch: 022 | loss: 0.22506 - acc: 0.9279 -- iter: 128/242
[A[ATraining Step: 173  | total loss: [1m[32m0.22852[0m[0m | time: 5.113s
[2K
| Adam | epoch: 022 | loss: 0.22852 - acc: 0.9226 -- iter: 160/242
[A[ATraining Step: 174  | total loss: [1m[32m0.22162[0m[0m | time: 6.218s
[2K
| Adam | epoch: 022 | loss: 0.22162 - acc: 0.9241 -- iter: 192/242
[A[ATraining Step: 175  | total loss: [1m[32m0.37750[0m[0m | time: 7.354s
[2K
| Adam | epoch: 022 | loss: 0.37750 - acc: 0.8911 -- iter: 224/242
[A[ATraining Step: 176  | total loss: [1m[32m0.35053[0m[0m | time: 9.530s
[2K
| Adam | epoch: 022 | loss: 0.35053 - acc: 0.8988 | val_loss: 0.46767 - val_acc: 0.8289 -- iter: 242/242
--
Training Step: 177  | total loss: [1m[32m0.32991[0m[0m | time: 1.383s
[2K
| Adam | epoch: 023 | loss: 0.32991 - acc: 0.9058 -- iter: 032/242
[A[ATraining Step: 178  | total loss: [1m[32m0.31425[0m[0m | time: 2.653s
[2K
| Adam | epoch: 023 | loss: 0.31425 - acc: 0.9090 -- iter: 064/242
[A[ATraining Step: 179  | total loss: [1m[32m0.31692[0m[0m | time: 3.423s
[2K
| Adam | epoch: 023 | loss: 0.31692 - acc: 0.9056 -- iter: 096/242
[A[ATraining Step: 180  | total loss: [1m[32m0.29747[0m[0m | time: 4.100s
[2K
| Adam | epoch: 023 | loss: 0.29747 - acc: 0.9150 -- iter: 128/242
[A[ATraining Step: 181  | total loss: [1m[32m0.27647[0m[0m | time: 5.080s
[2K
| Adam | epoch: 023 | loss: 0.27647 - acc: 0.9235 -- iter: 160/242
[A[ATraining Step: 182  | total loss: [1m[32m0.25794[0m[0m | time: 6.101s
[2K
| Adam | epoch: 023 | loss: 0.25794 - acc: 0.9312 -- iter: 192/242
[A[ATraining Step: 183  | total loss: [1m[32m0.24746[0m[0m | time: 7.382s
[2K
| Adam | epoch: 023 | loss: 0.24746 - acc: 0.9349 -- iter: 224/242
[A[ATraining Step: 184  | total loss: [1m[32m0.35665[0m[0m | time: 9.683s
[2K
| Adam | epoch: 023 | loss: 0.35665 - acc: 0.8977 | val_loss: 0.50933 - val_acc: 0.7368 -- iter: 242/242
--
Training Step: 185  | total loss: [1m[32m0.33404[0m[0m | time: 8.892s
[2K
| Adam | epoch: 024 | loss: 0.33404 - acc: 0.9017 -- iter: 032/242
[A[ATraining Step: 186  | total loss: [1m[32m0.31262[0m[0m | time: 20.874s
[2K
| Adam | epoch: 024 | loss: 0.31262 - acc: 0.9115 -- iter: 064/242
[A[ATraining Step: 187  | total loss: [1m[32m0.29362[0m[0m | time: 21.978s
[2K
| Adam | epoch: 024 | loss: 0.29362 - acc: 0.9172 -- iter: 096/242
[A[ATraining Step: 188  | total loss: [1m[32m0.27389[0m[0m | time: 22.713s
[2K
| Adam | epoch: 024 | loss: 0.27389 - acc: 0.9255 -- iter: 128/242
[A[ATraining Step: 189  | total loss: [1m[32m0.25274[0m[0m | time: 23.470s
[2K
| Adam | epoch: 024 | loss: 0.25274 - acc: 0.9330 -- iter: 160/242
[A[ATraining Step: 190  | total loss: [1m[32m0.23327[0m[0m | time: 24.589s
[2K
| Adam | epoch: 024 | loss: 0.23327 - acc: 0.9397 -- iter: 192/242
[A[ATraining Step: 191  | total loss: [1m[32m0.23012[0m[0m | time: 25.546s
[2K
| Adam | epoch: 024 | loss: 0.23012 - acc: 0.9426 -- iter: 224/242
[A[ATraining Step: 192  | total loss: [1m[32m0.22138[0m[0m | time: 27.687s
[2K
| Adam | epoch: 024 | loss: 0.22138 - acc: 0.9452 | val_loss: 0.39241 - val_acc: 0.8421 -- iter: 242/242
--
Training Step: 193  | total loss: [1m[32m0.23533[0m[0m | time: 1.214s
[2K
| Adam | epoch: 025 | loss: 0.23533 - acc: 0.9382 -- iter: 032/242
[A[ATraining Step: 194  | total loss: [1m[32m0.21600[0m[0m | time: 2.359s
[2K
| Adam | epoch: 025 | loss: 0.21600 - acc: 0.9444 -- iter: 064/242
[A[ATraining Step: 195  | total loss: [1m[32m0.19960[0m[0m | time: 3.510s
[2K
| Adam | epoch: 025 | loss: 0.19960 - acc: 0.9499 -- iter: 096/242
[A[ATraining Step: 196  | total loss: [1m[32m0.18389[0m[0m | time: 4.554s
[2K
| Adam | epoch: 025 | loss: 0.18389 - acc: 0.9549 -- iter: 128/242
[A[ATraining Step: 197  | total loss: [1m[32m0.16889[0m[0m | time: 5.289s
[2K
| Adam | epoch: 025 | loss: 0.16889 - acc: 0.9594 -- iter: 160/242
[A[ATraining Step: 198  | total loss: [1m[32m0.15731[0m[0m | time: 6.093s
[2K
| Adam | epoch: 025 | loss: 0.15731 - acc: 0.9635 -- iter: 192/242
[A[ATraining Step: 199  | total loss: [1m[32m0.14730[0m[0m | time: 7.332s
[2K
| Adam | epoch: 025 | loss: 0.14730 - acc: 0.9671 -- iter: 224/242
[A[ATraining Step: 200  | total loss: [1m[32m0.14120[0m[0m | time: 9.580s
[2K
| Adam | epoch: 025 | loss: 0.14120 - acc: 0.9673 | val_loss: 0.58350 - val_acc: 0.7763 -- iter: 242/242
--
Training Step: 201  | total loss: [1m[32m0.13528[0m[0m | time: 1.242s
[2K
| Adam | epoch: 026 | loss: 0.13528 - acc: 0.9674 -- iter: 032/242
[A[ATraining Step: 202  | total loss: [1m[32m0.18675[0m[0m | time: 2.364s
[2K
| Adam | epoch: 026 | loss: 0.18675 - acc: 0.9551 -- iter: 064/242
[A[ATraining Step: 203  | total loss: [1m[32m0.17014[0m[0m | time: 3.374s
[2K
| Adam | epoch: 026 | loss: 0.17014 - acc: 0.9596 -- iter: 096/242
[A[ATraining Step: 204  | total loss: [1m[32m0.16533[0m[0m | time: 4.463s
[2K
| Adam | epoch: 026 | loss: 0.16533 - acc: 0.9605 -- iter: 128/242
[A[ATraining Step: 205  | total loss: [1m[32m0.15163[0m[0m | time: 5.611s
[2K
| Adam | epoch: 026 | loss: 0.15163 - acc: 0.9644 -- iter: 160/242
[A[ATraining Step: 206  | total loss: [1m[32m0.13951[0m[0m | time: 6.288s
[2K
| Adam | epoch: 026 | loss: 0.13951 - acc: 0.9680 -- iter: 192/242
[A[ATraining Step: 207  | total loss: [1m[32m0.12823[0m[0m | time: 6.945s
[2K
| Adam | epoch: 026 | loss: 0.12823 - acc: 0.9712 -- iter: 224/242
[A[ATraining Step: 208  | total loss: [1m[32m0.11744[0m[0m | time: 9.114s
[2K
| Adam | epoch: 026 | loss: 0.11744 - acc: 0.9741 | val_loss: 0.38814 - val_acc: 0.8289 -- iter: 242/242
--
Training Step: 209  | total loss: [1m[32m0.10754[0m[0m | time: 1.223s
[2K
| Adam | epoch: 027 | loss: 0.10754 - acc: 0.9767 -- iter: 032/242
[A[ATraining Step: 210  | total loss: [1m[32m0.11433[0m[0m | time: 2.608s
[2K
| Adam | epoch: 027 | loss: 0.11433 - acc: 0.9728 -- iter: 064/242
[A[ATraining Step: 211  | total loss: [1m[32m0.10669[0m[0m | time: 3.981s
[2K
| Adam | epoch: 027 | loss: 0.10669 - acc: 0.9755 -- iter: 096/242
[A[ATraining Step: 212  | total loss: [1m[32m0.09951[0m[0m | time: 5.009s
[2K
| Adam | epoch: 027 | loss: 0.09951 - acc: 0.9779 -- iter: 128/242
[A[ATraining Step: 213  | total loss: [1m[32m0.09084[0m[0m | time: 6.121s
[2K
| Adam | epoch: 027 | loss: 0.09084 - acc: 0.9801 -- iter: 160/242
[A[ATraining Step: 214  | total loss: [1m[32m0.08329[0m[0m | time: 7.384s
[2K
| Adam | epoch: 027 | loss: 0.08329 - acc: 0.9821 -- iter: 192/242
[A[ATraining Step: 215  | total loss: [1m[32m0.07645[0m[0m | time: 8.083s
[2K
| Adam | epoch: 027 | loss: 0.07645 - acc: 0.9839 -- iter: 224/242
[A[ATraining Step: 216  | total loss: [1m[32m0.07018[0m[0m | time: 9.846s
[2K
| Adam | epoch: 027 | loss: 0.07018 - acc: 0.9855 | val_loss: 0.47550 - val_acc: 0.8421 -- iter: 242/242
--
Training Step: 217  | total loss: [1m[32m0.06435[0m[0m | time: 1.177s
[2K
| Adam | epoch: 028 | loss: 0.06435 - acc: 0.9870 -- iter: 032/242
[A[ATraining Step: 218  | total loss: [1m[32m0.05996[0m[0m | time: 2.350s
[2K
| Adam | epoch: 028 | loss: 0.05996 - acc: 0.9883 -- iter: 064/242
[A[ATraining Step: 219  | total loss: [1m[32m0.07165[0m[0m | time: 3.467s
[2K
| Adam | epoch: 028 | loss: 0.07165 - acc: 0.9832 -- iter: 096/242
[A[ATraining Step: 220  | total loss: [1m[32m0.07904[0m[0m | time: 4.690s
[2K
| Adam | epoch: 028 | loss: 0.07904 - acc: 0.9786 -- iter: 128/242
[A[ATraining Step: 221  | total loss: [1m[32m0.07243[0m[0m | time: 5.916s
[2K
| Adam | epoch: 028 | loss: 0.07243 - acc: 0.9808 -- iter: 160/242
[A[ATraining Step: 222  | total loss: [1m[32m0.08930[0m[0m | time: 7.092s
[2K
| Adam | epoch: 028 | loss: 0.08930 - acc: 0.9671 -- iter: 192/242
[A[ATraining Step: 223  | total loss: [1m[32m0.09596[0m[0m | time: 8.408s
[2K
| Adam | epoch: 028 | loss: 0.09596 - acc: 0.9610 -- iter: 224/242
[A[ATraining Step: 224  | total loss: [1m[32m0.08946[0m[0m | time: 10.165s
[2K
| Adam | epoch: 028 | loss: 0.08946 - acc: 0.9649 | val_loss: 0.37122 - val_acc: 0.9079 -- iter: 242/242
--
Training Step: 225  | total loss: [1m[32m0.08188[0m[0m | time: 0.674s
[2K
| Adam | epoch: 029 | loss: 0.08188 - acc: 0.9684 -- iter: 032/242
[A[ATraining Step: 226  | total loss: [1m[32m0.07493[0m[0m | time: 1.916s
[2K
| Adam | epoch: 029 | loss: 0.07493 - acc: 0.9716 -- iter: 064/242
[A[ATraining Step: 227  | total loss: [1m[32m0.07099[0m[0m | time: 3.140s
[2K
| Adam | epoch: 029 | loss: 0.07099 - acc: 0.9744 -- iter: 096/242
[A[ATraining Step: 228  | total loss: [1m[32m0.07416[0m[0m | time: 4.079s
[2K
| Adam | epoch: 029 | loss: 0.07416 - acc: 0.9707 -- iter: 128/242
[A[ATraining Step: 229  | total loss: [1m[32m0.28565[0m[0m | time: 5.206s
[2K
| Adam | epoch: 029 | loss: 0.28565 - acc: 0.9361 -- iter: 160/242
[A[ATraining Step: 230  | total loss: [1m[32m0.26234[0m[0m | time: 6.399s
[2K
| Adam | epoch: 029 | loss: 0.26234 - acc: 0.9425 -- iter: 192/242
[A[ATraining Step: 231  | total loss: [1m[32m0.24394[0m[0m | time: 7.538s
[2K
| Adam | epoch: 029 | loss: 0.24394 - acc: 0.9483 -- iter: 224/242
[A[ATraining Step: 232  | total loss: [1m[32m0.22279[0m[0m | time: 9.650s
[2K
| Adam | epoch: 029 | loss: 0.22279 - acc: 0.9534 | val_loss: 0.27907 - val_acc: 0.8947 -- iter: 242/242
--
Training Step: 233  | total loss: [1m[32m0.20583[0m[0m | time: 0.680s
[2K
| Adam | epoch: 030 | loss: 0.20583 - acc: 0.9550 -- iter: 032/242
[A[ATraining Step: 234  | total loss: [1m[32m0.18842[0m[0m | time: 1.372s
[2K
| Adam | epoch: 030 | loss: 0.18842 - acc: 0.9595 -- iter: 064/242
[A[ATraining Step: 235  | total loss: [1m[32m0.17308[0m[0m | time: 2.658s
[2K
| Adam | epoch: 030 | loss: 0.17308 - acc: 0.9635 -- iter: 096/242
[A[ATraining Step: 236  | total loss: [1m[32m0.15975[0m[0m | time: 3.969s
[2K
| Adam | epoch: 030 | loss: 0.15975 - acc: 0.9672 -- iter: 128/242
[A[ATraining Step: 237  | total loss: [1m[32m0.15525[0m[0m | time: 5.195s
[2K
| Adam | epoch: 030 | loss: 0.15525 - acc: 0.9673 -- iter: 160/242
[A[ATraining Step: 238  | total loss: [1m[32m0.23867[0m[0m | time: 6.258s
[2K
| Adam | epoch: 030 | loss: 0.23867 - acc: 0.9456 -- iter: 192/242
[A[ATraining Step: 239  | total loss: [1m[32m0.22177[0m[0m | time: 7.406s
[2K
| Adam | epoch: 030 | loss: 0.22177 - acc: 0.9510 -- iter: 224/242
[A[ATraining Step: 240  | total loss: [1m[32m0.20596[0m[0m | time: 9.603s
[2K
| Adam | epoch: 030 | loss: 0.20596 - acc: 0.9559 | val_loss: 0.28979 - val_acc: 0.8816 -- iter: 242/242
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9400696864111499
Validation AUPRC:0.9568931975798668
Test AUC:0.930937279774489
Test AUPRC:0.9388097174195245
BestTestF1Score	0.88	0.79	0.89	0.9	0.85	28	3	40	5	0.63
BestTestMCCScore	0.88	0.79	0.89	0.9	0.85	28	3	40	5	0.63
BestTestAccuracyScore	0.88	0.79	0.89	0.9	0.85	28	3	40	5	0.63
BestValidationF1Score	0.94	0.9	0.95	1.0	0.89	31	0	41	4	0.63
BestValidationMCC	0.94	0.9	0.95	1.0	0.89	31	0	41	4	0.63
BestValidationAccuracy	0.94	0.9	0.95	1.0	0.89	31	0	41	4	0.63
TestPredictions (Threshold:0.63)
CHEMBL1287945,TN,INACT,0.05999999865889549	CHEMBL3613602,TP,ACT,0.9800000190734863	CHEMBL172973,TN,INACT,0.20000000298023224	CHEMBL487526,FP,INACT,0.8700000047683716	CHEMBL3797333,TP,ACT,0.949999988079071	CHEMBL2392238,TN,INACT,0.05000000074505806	CHEMBL1288005,TN,INACT,0.11999999731779099	CHEMBL3356426,TP,ACT,0.9800000190734863	CHEMBL1909651,TN,INACT,0.5899999737739563	CHEMBL2070612,TP,ACT,0.8199999928474426	CHEMBL498130,TN,INACT,0.029999999329447746	CHEMBL576283,TP,ACT,0.7699999809265137	CHEMBL3613610,TP,ACT,0.9800000190734863	CHEMBL1933802,TN,INACT,0.07000000029802322	CHEMBL3623442,FN,ACT,0.20000000298023224	CHEMBL452812,TN,INACT,0.3199999928474426	CHEMBL2392385,TN,INACT,0.05999999865889549	CHEMBL3355501,TP,ACT,0.949999988079071	CHEMBL456964,TN,INACT,0.03999999910593033	CHEMBL568706,TP,ACT,0.9700000286102295	CHEMBL3691604,TN,INACT,0.25999999046325684	CHEMBL599519,TN,INACT,0.2800000011920929	CHEMBL560393,TN,INACT,0.18000000715255737	CHEMBL469770,TN,INACT,0.18000000715255737	CHEMBL558601,TN,INACT,0.10000000149011612	CHEMBL3800555,TP,ACT,0.9200000166893005	CHEMBL1910754,TN,INACT,0.2199999988079071	CHEMBL3356117,TN,INACT,0.5400000214576721	CHEMBL489627,TN,INACT,0.10000000149011612	CHEMBL3355498,TP,ACT,0.9700000286102295	CHEMBL230761,TN,INACT,0.1899999976158142	CHEMBL563948,TN,INACT,0.05999999865889549	CHEMBL3356068,TP,ACT,0.9599999785423279	CHEMBL570116,TP,ACT,0.9800000190734863	CHEMBL569861,TP,ACT,0.9599999785423279	CHEMBL3613601,TP,ACT,0.9800000190734863	CHEMBL3355489,TP,ACT,0.9900000095367432	CHEMBL2070497,TP,ACT,0.9399999976158142	CHEMBL2070504,FN,ACT,0.5699999928474426	CHEMBL456143,TN,INACT,0.05000000074505806	CHEMBL521201,TN,INACT,0.2199999988079071	CHEMBL457180,TN,INACT,0.10000000149011612	CHEMBL3798142,TP,ACT,0.8399999737739563	CHEMBL570831,TP,ACT,0.9700000286102295	CHEMBL3355507,TP,ACT,0.9900000095367432	CHEMBL3623439,FN,ACT,0.38999998569488525	CHEMBL487737,FP,INACT,0.7799999713897705	CHEMBL456760,TN,INACT,0.029999999329447746	CHEMBL234944,TN,INACT,0.30000001192092896	CHEMBL522760,TN,INACT,0.17000000178813934	CHEMBL557525,TN,INACT,0.07999999821186066	CHEMBL584090,TP,ACT,0.9700000286102295	CHEMBL332342,TN,INACT,0.09000000357627869	CHEMBL1767126,TN,INACT,0.03999999910593033	CHEMBL3347683,TP,ACT,0.7900000214576721	CHEMBL559882,TN,INACT,0.09000000357627869	CHEMBL570109,TP,ACT,0.9100000262260437	CHEMBL77262,TN,INACT,0.4099999964237213	CHEMBL571942,TP,ACT,0.9700000286102295	CHEMBL2392235,TN,INACT,0.05999999865889549	CHEMBL101868,FP,INACT,0.8100000023841858	CHEMBL3799054,TP,ACT,0.9800000190734863	CHEMBL3356063,TP,ACT,0.9800000190734863	CHEMBL470851,TN,INACT,0.15000000596046448	CHEMBL2070617,TP,ACT,0.6499999761581421	CHEMBL2392366,TN,INACT,0.23999999463558197	CHEMBL490053,TN,INACT,0.4300000071525574	CHEMBL3799326,TP,ACT,0.9700000286102295	CHEMBL102622,TN,INACT,0.25999999046325684	CHEMBL1734241,TN,INACT,0.5799999833106995	CHEMBL3613621,TP,ACT,0.9700000286102295	CHEMBL2392232,TN,INACT,0.05000000074505806	CHEMBL3623443,FN,ACT,0.10999999940395355	CHEMBL463384,TN,INACT,0.550000011920929	CHEMBL176815,TN,INACT,0.27000001072883606	CHEMBL601719,FN,ACT,0.07999999821186066	

