CNNModel CHEMBL1914 adam 0.0005 15 256 0 0.8 False True
Number of active compounds :	1331
Number of inactive compounds :	1331
---------------------------------
Run id: CNNModel_CHEMBL1914_adam_0.0005_15_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1914_adam_0.0005_15_256_0.8_True/
---------------------------------
Training samples: 1668
Validation samples: 522
--
Training Step: 1  | time: 15.964s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1668
[A[ATraining Step: 2  | total loss: [1m[32m0.62364[0m[0m | time: 26.224s
[2K
| Adam | epoch: 001 | loss: 0.62364 - acc: 0.5344 -- iter: 0064/1668
[A[ATraining Step: 3  | total loss: [1m[32m0.68038[0m[0m | time: 33.070s
[2K
| Adam | epoch: 001 | loss: 0.68038 - acc: 0.5574 -- iter: 0096/1668
[A[ATraining Step: 4  | total loss: [1m[32m0.68934[0m[0m | time: 37.315s
[2K
| Adam | epoch: 001 | loss: 0.68934 - acc: 0.6081 -- iter: 0128/1668
[A[ATraining Step: 5  | total loss: [1m[32m0.69029[0m[0m | time: 38.270s
[2K
| Adam | epoch: 001 | loss: 0.69029 - acc: 0.5765 -- iter: 0160/1668
[A[ATraining Step: 6  | total loss: [1m[32m0.69360[0m[0m | time: 39.258s
[2K
| Adam | epoch: 001 | loss: 0.69360 - acc: 0.5072 -- iter: 0192/1668
[A[ATraining Step: 7  | total loss: [1m[32m0.69148[0m[0m | time: 40.238s
[2K
| Adam | epoch: 001 | loss: 0.69148 - acc: 0.5216 -- iter: 0224/1668
[A[ATraining Step: 8  | total loss: [1m[32m0.69771[0m[0m | time: 41.241s
[2K
| Adam | epoch: 001 | loss: 0.69771 - acc: 0.4743 -- iter: 0256/1668
[A[ATraining Step: 9  | total loss: [1m[32m0.69016[0m[0m | time: 42.410s
[2K
| Adam | epoch: 001 | loss: 0.69016 - acc: 0.5541 -- iter: 0288/1668
[A[ATraining Step: 10  | total loss: [1m[32m0.69274[0m[0m | time: 43.516s
[2K
| Adam | epoch: 001 | loss: 0.69274 - acc: 0.5270 -- iter: 0320/1668
[A[ATraining Step: 11  | total loss: [1m[32m0.69368[0m[0m | time: 44.499s
[2K
| Adam | epoch: 001 | loss: 0.69368 - acc: 0.5142 -- iter: 0352/1668
[A[ATraining Step: 12  | total loss: [1m[32m0.68824[0m[0m | time: 45.551s
[2K
| Adam | epoch: 001 | loss: 0.68824 - acc: 0.5781 -- iter: 0384/1668
[A[ATraining Step: 13  | total loss: [1m[32m0.69494[0m[0m | time: 46.821s
[2K
| Adam | epoch: 001 | loss: 0.69494 - acc: 0.4911 -- iter: 0416/1668
[A[ATraining Step: 14  | total loss: [1m[32m0.69633[0m[0m | time: 53.998s
[2K
| Adam | epoch: 001 | loss: 0.69633 - acc: 0.4819 -- iter: 0448/1668
[A[ATraining Step: 15  | total loss: [1m[32m0.69086[0m[0m | time: 65.858s
[2K
| Adam | epoch: 001 | loss: 0.69086 - acc: 0.5379 -- iter: 0480/1668
[A[ATraining Step: 16  | total loss: [1m[32m0.69418[0m[0m | time: 80.620s
[2K
| Adam | epoch: 001 | loss: 0.69418 - acc: 0.4885 -- iter: 0512/1668
[A[ATraining Step: 17  | total loss: [1m[32m0.69190[0m[0m | time: 90.708s
[2K
| Adam | epoch: 001 | loss: 0.69190 - acc: 0.5152 -- iter: 0544/1668
[A[ATraining Step: 18  | total loss: [1m[32m0.69155[0m[0m | time: 102.834s
[2K
| Adam | epoch: 001 | loss: 0.69155 - acc: 0.5207 -- iter: 0576/1668
[A[ATraining Step: 19  | total loss: [1m[32m0.68993[0m[0m | time: 112.211s
[2K
| Adam | epoch: 001 | loss: 0.68993 - acc: 0.5555 -- iter: 0608/1668
[A[ATraining Step: 20  | total loss: [1m[32m0.69259[0m[0m | time: 119.991s
[2K
| Adam | epoch: 001 | loss: 0.69259 - acc: 0.5176 -- iter: 0640/1668
[A[ATraining Step: 21  | total loss: [1m[32m0.69214[0m[0m | time: 125.159s
[2K
| Adam | epoch: 001 | loss: 0.69214 - acc: 0.5218 -- iter: 0672/1668
[A[ATraining Step: 22  | total loss: [1m[32m0.68850[0m[0m | time: 129.767s
[2K
| Adam | epoch: 001 | loss: 0.68850 - acc: 0.5715 -- iter: 0704/1668
[A[ATraining Step: 23  | total loss: [1m[32m0.68798[0m[0m | time: 136.166s
[2K
| Adam | epoch: 001 | loss: 0.68798 - acc: 0.5689 -- iter: 0736/1668
[A[ATraining Step: 24  | total loss: [1m[32m0.69163[0m[0m | time: 137.092s
[2K
| Adam | epoch: 001 | loss: 0.69163 - acc: 0.5407 -- iter: 0768/1668
[A[ATraining Step: 25  | total loss: [1m[32m0.69307[0m[0m | time: 138.091s
[2K
| Adam | epoch: 001 | loss: 0.69307 - acc: 0.5296 -- iter: 0800/1668
[A[ATraining Step: 26  | total loss: [1m[32m0.69486[0m[0m | time: 139.147s
[2K
| Adam | epoch: 001 | loss: 0.69486 - acc: 0.5135 -- iter: 0832/1668
[A[ATraining Step: 27  | total loss: [1m[32m0.69652[0m[0m | time: 140.248s
[2K
| Adam | epoch: 001 | loss: 0.69652 - acc: 0.5020 -- iter: 0864/1668
[A[ATraining Step: 28  | total loss: [1m[32m0.69811[0m[0m | time: 141.382s
[2K
| Adam | epoch: 001 | loss: 0.69811 - acc: 0.4781 -- iter: 0896/1668
[A[ATraining Step: 29  | total loss: [1m[32m0.69884[0m[0m | time: 142.577s
[2K
| Adam | epoch: 001 | loss: 0.69884 - acc: 0.4606 -- iter: 0928/1668
[A[ATraining Step: 30  | total loss: [1m[32m0.69662[0m[0m | time: 143.683s
[2K
| Adam | epoch: 001 | loss: 0.69662 - acc: 0.4921 -- iter: 0960/1668
[A[ATraining Step: 31  | total loss: [1m[32m0.69618[0m[0m | time: 144.838s
[2K
| Adam | epoch: 001 | loss: 0.69618 - acc: 0.4867 -- iter: 0992/1668
[A[ATraining Step: 32  | total loss: [1m[32m0.69437[0m[0m | time: 146.046s
[2K
| Adam | epoch: 001 | loss: 0.69437 - acc: 0.5460 -- iter: 1024/1668
[A[ATraining Step: 33  | total loss: [1m[32m0.69465[0m[0m | time: 147.181s
[2K
| Adam | epoch: 001 | loss: 0.69465 - acc: 0.5084 -- iter: 1056/1668
[A[ATraining Step: 34  | total loss: [1m[32m0.69413[0m[0m | time: 152.411s
[2K
| Adam | epoch: 001 | loss: 0.69413 - acc: 0.5133 -- iter: 1088/1668
[A[ATraining Step: 35  | total loss: [1m[32m0.69412[0m[0m | time: 157.339s
[2K
| Adam | epoch: 001 | loss: 0.69412 - acc: 0.4975 -- iter: 1120/1668
[A[ATraining Step: 36  | total loss: [1m[32m0.69355[0m[0m | time: 159.451s
[2K
| Adam | epoch: 001 | loss: 0.69355 - acc: 0.5235 -- iter: 1152/1668
[A[ATraining Step: 37  | total loss: [1m[32m0.69345[0m[0m | time: 160.544s
[2K
| Adam | epoch: 001 | loss: 0.69345 - acc: 0.5188 -- iter: 1184/1668
[A[ATraining Step: 38  | total loss: [1m[32m0.69377[0m[0m | time: 161.578s
[2K
| Adam | epoch: 001 | loss: 0.69377 - acc: 0.4846 -- iter: 1216/1668
[A[ATraining Step: 39  | total loss: [1m[32m0.69359[0m[0m | time: 162.624s
[2K
| Adam | epoch: 001 | loss: 0.69359 - acc: 0.4875 -- iter: 1248/1668
[A[ATraining Step: 40  | total loss: [1m[32m0.69353[0m[0m | time: 163.658s
[2K
| Adam | epoch: 001 | loss: 0.69353 - acc: 0.4840 -- iter: 1280/1668
[A[ATraining Step: 41  | total loss: [1m[32m0.69338[0m[0m | time: 164.829s
[2K
| Adam | epoch: 001 | loss: 0.69338 - acc: 0.4984 -- iter: 1312/1668
[A[ATraining Step: 42  | total loss: [1m[32m0.69322[0m[0m | time: 165.883s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.5100 -- iter: 1344/1668
[A[ATraining Step: 43  | total loss: [1m[32m0.69312[0m[0m | time: 166.805s
[2K
| Adam | epoch: 001 | loss: 0.69312 - acc: 0.5192 -- iter: 1376/1668
[A[ATraining Step: 44  | total loss: [1m[32m0.69301[0m[0m | time: 168.100s
[2K
| Adam | epoch: 001 | loss: 0.69301 - acc: 0.5213 -- iter: 1408/1668
[A[ATraining Step: 45  | total loss: [1m[32m0.69298[0m[0m | time: 169.338s
[2K
| Adam | epoch: 001 | loss: 0.69298 - acc: 0.5177 -- iter: 1440/1668
[A[ATraining Step: 46  | total loss: [1m[32m0.69298[0m[0m | time: 170.158s
[2K
| Adam | epoch: 001 | loss: 0.69298 - acc: 0.5200 -- iter: 1472/1668
[A[ATraining Step: 47  | total loss: [1m[32m0.69298[0m[0m | time: 177.217s
[2K
| Adam | epoch: 001 | loss: 0.69298 - acc: 0.5116 -- iter: 1504/1668
[A[ATraining Step: 48  | total loss: [1m[32m0.69277[0m[0m | time: 182.169s
[2K
| Adam | epoch: 001 | loss: 0.69277 - acc: 0.5248 -- iter: 1536/1668
[A[ATraining Step: 49  | total loss: [1m[32m0.69284[0m[0m | time: 187.898s
[2K
| Adam | epoch: 001 | loss: 0.69284 - acc: 0.5209 -- iter: 1568/1668
[A[ATraining Step: 50  | total loss: [1m[32m0.69299[0m[0m | time: 197.690s
[2K
| Adam | epoch: 001 | loss: 0.69299 - acc: 0.5079 -- iter: 1600/1668
[A[ATraining Step: 51  | total loss: [1m[32m0.69317[0m[0m | time: 205.551s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.4972 -- iter: 1632/1668
[A[ATraining Step: 52  | total loss: [1m[32m0.69260[0m[0m | time: 211.286s
[2K
| Adam | epoch: 001 | loss: 0.69260 - acc: 0.5210 -- iter: 1664/1668
[A[ATraining Step: 53  | total loss: [1m[32m0.69277[0m[0m | time: 214.691s
[2K
| Adam | epoch: 001 | loss: 0.69277 - acc: 0.5133 | val_loss: 0.69420 - val_acc: 0.4540 -- iter: 1668/1668
--
Training Step: 54  | total loss: [1m[32m0.69260[0m[0m | time: 0.188s
[2K
| Adam | epoch: 002 | loss: 0.69260 - acc: 0.5114 -- iter: 0032/1668
[A[ATraining Step: 55  | total loss: [1m[32m0.69254[0m[0m | time: 1.192s
[2K
| Adam | epoch: 002 | loss: 0.69254 - acc: 0.5098 -- iter: 0064/1668
[A[ATraining Step: 56  | total loss: [1m[32m0.69244[0m[0m | time: 2.295s
[2K
| Adam | epoch: 002 | loss: 0.69244 - acc: 0.5128 -- iter: 0096/1668
[A[ATraining Step: 57  | total loss: [1m[32m0.69267[0m[0m | time: 3.523s
[2K
| Adam | epoch: 002 | loss: 0.69267 - acc: 0.5067 -- iter: 0128/1668
[A[ATraining Step: 58  | total loss: [1m[32m0.69346[0m[0m | time: 4.727s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.4845 -- iter: 0160/1668
[A[ATraining Step: 59  | total loss: [1m[32m0.69339[0m[0m | time: 5.678s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.4866 -- iter: 0192/1668
[A[ATraining Step: 60  | total loss: [1m[32m0.69333[0m[0m | time: 6.749s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4842 -- iter: 0224/1668
[A[ATraining Step: 61  | total loss: [1m[32m0.69335[0m[0m | time: 7.949s
[2K
| Adam | epoch: 002 | loss: 0.69335 - acc: 0.4781 -- iter: 0256/1668
[A[ATraining Step: 62  | total loss: [1m[32m0.69342[0m[0m | time: 11.357s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4689 -- iter: 0288/1668
[A[ATraining Step: 63  | total loss: [1m[32m0.69338[0m[0m | time: 15.880s
[2K
| Adam | epoch: 002 | loss: 0.69338 - acc: 0.4570 -- iter: 0320/1668
[A[ATraining Step: 64  | total loss: [1m[32m0.69337[0m[0m | time: 19.965s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4467 -- iter: 0352/1668
[A[ATraining Step: 65  | total loss: [1m[32m0.69340[0m[0m | time: 23.969s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.4417 -- iter: 0384/1668
[A[ATraining Step: 66  | total loss: [1m[32m0.69332[0m[0m | time: 27.276s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4564 -- iter: 0416/1668
[A[ATraining Step: 67  | total loss: [1m[32m0.69319[0m[0m | time: 28.228s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.4654 -- iter: 0448/1668
[A[ATraining Step: 68  | total loss: [1m[32m0.69304[0m[0m | time: 29.225s
[2K
| Adam | epoch: 002 | loss: 0.69304 - acc: 0.4954 -- iter: 0480/1668
[A[ATraining Step: 69  | total loss: [1m[32m0.69292[0m[0m | time: 30.300s
[2K
| Adam | epoch: 002 | loss: 0.69292 - acc: 0.5032 -- iter: 0512/1668
[A[ATraining Step: 70  | total loss: [1m[32m0.69300[0m[0m | time: 31.290s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.4993 -- iter: 0544/1668
[A[ATraining Step: 71  | total loss: [1m[32m0.69300[0m[0m | time: 32.292s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.4993 -- iter: 0576/1668
[A[ATraining Step: 72  | total loss: [1m[32m0.69319[0m[0m | time: 33.360s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.4924 -- iter: 0608/1668
[A[ATraining Step: 73  | total loss: [1m[32m0.69304[0m[0m | time: 34.474s
[2K
| Adam | epoch: 002 | loss: 0.69304 - acc: 0.4932 -- iter: 0640/1668
[A[ATraining Step: 74  | total loss: [1m[32m0.69254[0m[0m | time: 35.366s
[2K
| Adam | epoch: 002 | loss: 0.69254 - acc: 0.5008 -- iter: 0672/1668
[A[ATraining Step: 75  | total loss: [1m[32m0.69168[0m[0m | time: 36.419s
[2K
| Adam | epoch: 002 | loss: 0.69168 - acc: 0.5143 -- iter: 0704/1668
[A[ATraining Step: 76  | total loss: [1m[32m0.69196[0m[0m | time: 37.830s
[2K
| Adam | epoch: 002 | loss: 0.69196 - acc: 0.5094 -- iter: 0736/1668
[A[ATraining Step: 77  | total loss: [1m[32m0.69186[0m[0m | time: 43.690s
[2K
| Adam | epoch: 002 | loss: 0.69186 - acc: 0.5084 -- iter: 0768/1668
[A[ATraining Step: 78  | total loss: [1m[32m0.69064[0m[0m | time: 51.412s
[2K
| Adam | epoch: 002 | loss: 0.69064 - acc: 0.5141 -- iter: 0800/1668
[A[ATraining Step: 79  | total loss: [1m[32m0.69277[0m[0m | time: 57.982s
[2K
| Adam | epoch: 002 | loss: 0.69277 - acc: 0.4997 -- iter: 0832/1668
[A[ATraining Step: 80  | total loss: [1m[32m0.69192[0m[0m | time: 63.332s
[2K
| Adam | epoch: 002 | loss: 0.69192 - acc: 0.5029 -- iter: 0864/1668
[A[ATraining Step: 81  | total loss: [1m[32m0.69040[0m[0m | time: 72.840s
[2K
| Adam | epoch: 002 | loss: 0.69040 - acc: 0.5121 -- iter: 0896/1668
[A[ATraining Step: 82  | total loss: [1m[32m0.69075[0m[0m | time: 82.707s
[2K
| Adam | epoch: 002 | loss: 0.69075 - acc: 0.5078 -- iter: 0928/1668
[A[ATraining Step: 83  | total loss: [1m[32m0.69042[0m[0m | time: 87.848s
[2K
| Adam | epoch: 002 | loss: 0.69042 - acc: 0.5039 -- iter: 0960/1668
[A[ATraining Step: 84  | total loss: [1m[32m0.69087[0m[0m | time: 92.952s
[2K
| Adam | epoch: 002 | loss: 0.69087 - acc: 0.4972 -- iter: 0992/1668
[A[ATraining Step: 85  | total loss: [1m[32m0.68944[0m[0m | time: 101.826s
[2K
| Adam | epoch: 002 | loss: 0.68944 - acc: 0.5038 -- iter: 1024/1668
[A[ATraining Step: 86  | total loss: [1m[32m0.68921[0m[0m | time: 104.993s
[2K
| Adam | epoch: 002 | loss: 0.68921 - acc: 0.5034 -- iter: 1056/1668
[A[ATraining Step: 87  | total loss: [1m[32m0.68837[0m[0m | time: 107.746s
[2K
| Adam | epoch: 002 | loss: 0.68837 - acc: 0.5030 -- iter: 1088/1668
[A[ATraining Step: 88  | total loss: [1m[32m0.68789[0m[0m | time: 108.793s
[2K
| Adam | epoch: 002 | loss: 0.68789 - acc: 0.4934 -- iter: 1120/1668
[A[ATraining Step: 89  | total loss: [1m[32m0.68493[0m[0m | time: 109.911s
[2K
| Adam | epoch: 002 | loss: 0.68493 - acc: 0.5128 -- iter: 1152/1668
[A[ATraining Step: 90  | total loss: [1m[32m0.68223[0m[0m | time: 110.935s
[2K
| Adam | epoch: 002 | loss: 0.68223 - acc: 0.5209 -- iter: 1184/1668
[A[ATraining Step: 91  | total loss: [1m[32m0.68728[0m[0m | time: 111.978s
[2K
| Adam | epoch: 002 | loss: 0.68728 - acc: 0.5094 -- iter: 1216/1668
[A[ATraining Step: 92  | total loss: [1m[32m0.68416[0m[0m | time: 113.151s
[2K
| Adam | epoch: 002 | loss: 0.68416 - acc: 0.5147 -- iter: 1248/1668
[A[ATraining Step: 93  | total loss: [1m[32m0.68695[0m[0m | time: 114.334s
[2K
| Adam | epoch: 002 | loss: 0.68695 - acc: 0.5007 -- iter: 1280/1668
[A[ATraining Step: 94  | total loss: [1m[32m0.68331[0m[0m | time: 115.313s
[2K
| Adam | epoch: 002 | loss: 0.68331 - acc: 0.5132 -- iter: 1312/1668
[A[ATraining Step: 95  | total loss: [1m[32m0.68239[0m[0m | time: 116.694s
[2K
| Adam | epoch: 002 | loss: 0.68239 - acc: 0.5337 -- iter: 1344/1668
[A[ATraining Step: 96  | total loss: [1m[32m0.68115[0m[0m | time: 117.778s
[2K
| Adam | epoch: 002 | loss: 0.68115 - acc: 0.5522 -- iter: 1376/1668
[A[ATraining Step: 97  | total loss: [1m[32m0.68150[0m[0m | time: 120.581s
[2K
| Adam | epoch: 002 | loss: 0.68150 - acc: 0.5595 -- iter: 1408/1668
[A[ATraining Step: 98  | total loss: [1m[32m0.68101[0m[0m | time: 124.113s
[2K
| Adam | epoch: 002 | loss: 0.68101 - acc: 0.5692 -- iter: 1440/1668
[A[ATraining Step: 99  | total loss: [1m[32m0.67757[0m[0m | time: 128.587s
[2K
| Adam | epoch: 002 | loss: 0.67757 - acc: 0.5779 -- iter: 1472/1668
[A[ATraining Step: 100  | total loss: [1m[32m0.67634[0m[0m | time: 131.012s
[2K
| Adam | epoch: 002 | loss: 0.67634 - acc: 0.5670 -- iter: 1504/1668
[A[ATraining Step: 101  | total loss: [1m[32m0.67937[0m[0m | time: 133.718s
[2K
| Adam | epoch: 002 | loss: 0.67937 - acc: 0.5540 -- iter: 1536/1668
[A[ATraining Step: 102  | total loss: [1m[32m0.67663[0m[0m | time: 138.154s
[2K
| Adam | epoch: 002 | loss: 0.67663 - acc: 0.5643 -- iter: 1568/1668
[A[ATraining Step: 103  | total loss: [1m[32m0.67702[0m[0m | time: 139.017s
[2K
| Adam | epoch: 002 | loss: 0.67702 - acc: 0.5672 -- iter: 1600/1668
[A[ATraining Step: 104  | total loss: [1m[32m0.67670[0m[0m | time: 140.039s
[2K
| Adam | epoch: 002 | loss: 0.67670 - acc: 0.5699 -- iter: 1632/1668
[A[ATraining Step: 105  | total loss: [1m[32m0.67654[0m[0m | time: 141.000s
[2K
| Adam | epoch: 002 | loss: 0.67654 - acc: 0.5691 -- iter: 1664/1668
[A[ATraining Step: 106  | total loss: [1m[32m0.67317[0m[0m | time: 145.511s
[2K
| Adam | epoch: 002 | loss: 0.67317 - acc: 0.5747 | val_loss: 0.65607 - val_acc: 0.5958 -- iter: 1668/1668
--
Training Step: 107  | total loss: [1m[32m0.67006[0m[0m | time: 0.174s
[2K
| Adam | epoch: 003 | loss: 0.67006 - acc: 0.5829 -- iter: 0032/1668
[A[ATraining Step: 108  | total loss: [1m[32m0.66373[0m[0m | time: 0.342s
[2K
| Adam | epoch: 003 | loss: 0.66373 - acc: 0.6246 -- iter: 0064/1668
[A[ATraining Step: 109  | total loss: [1m[32m0.65586[0m[0m | time: 1.341s
[2K
| Adam | epoch: 003 | loss: 0.65586 - acc: 0.6371 -- iter: 0096/1668
[A[ATraining Step: 110  | total loss: [1m[32m0.65153[0m[0m | time: 2.283s
[2K
| Adam | epoch: 003 | loss: 0.65153 - acc: 0.6359 -- iter: 0128/1668
[A[ATraining Step: 111  | total loss: [1m[32m0.65142[0m[0m | time: 3.149s
[2K
| Adam | epoch: 003 | loss: 0.65142 - acc: 0.6348 -- iter: 0160/1668
[A[ATraining Step: 112  | total loss: [1m[32m0.64407[0m[0m | time: 4.023s
[2K
| Adam | epoch: 003 | loss: 0.64407 - acc: 0.6338 -- iter: 0192/1668
[A[ATraining Step: 113  | total loss: [1m[32m0.62262[0m[0m | time: 4.748s
[2K
| Adam | epoch: 003 | loss: 0.62262 - acc: 0.6548 -- iter: 0224/1668
[A[ATraining Step: 114  | total loss: [1m[32m0.62026[0m[0m | time: 5.414s
[2K
| Adam | epoch: 003 | loss: 0.62026 - acc: 0.6487 -- iter: 0256/1668
[A[ATraining Step: 115  | total loss: [1m[32m0.62245[0m[0m | time: 6.134s
[2K
| Adam | epoch: 003 | loss: 0.62245 - acc: 0.6495 -- iter: 0288/1668
[A[ATraining Step: 116  | total loss: [1m[32m0.62504[0m[0m | time: 6.830s
[2K
| Adam | epoch: 003 | loss: 0.62504 - acc: 0.6470 -- iter: 0320/1668
[A[ATraining Step: 117  | total loss: [1m[32m0.63690[0m[0m | time: 7.555s
[2K
| Adam | epoch: 003 | loss: 0.63690 - acc: 0.6354 -- iter: 0352/1668
[A[ATraining Step: 118  | total loss: [1m[32m0.64120[0m[0m | time: 8.269s
[2K
| Adam | epoch: 003 | loss: 0.64120 - acc: 0.6282 -- iter: 0384/1668
[A[ATraining Step: 119  | total loss: [1m[32m0.63923[0m[0m | time: 8.950s
[2K
| Adam | epoch: 003 | loss: 0.63923 - acc: 0.6247 -- iter: 0416/1668
[A[ATraining Step: 120  | total loss: [1m[32m0.63214[0m[0m | time: 9.656s
[2K
| Adam | epoch: 003 | loss: 0.63214 - acc: 0.6341 -- iter: 0448/1668
[A[ATraining Step: 121  | total loss: [1m[32m0.61849[0m[0m | time: 10.347s
[2K
| Adam | epoch: 003 | loss: 0.61849 - acc: 0.6488 -- iter: 0480/1668
[A[ATraining Step: 122  | total loss: [1m[32m0.63284[0m[0m | time: 11.423s
[2K
| Adam | epoch: 003 | loss: 0.63284 - acc: 0.6402 -- iter: 0512/1668
[A[ATraining Step: 123  | total loss: [1m[32m0.62956[0m[0m | time: 12.542s
[2K
| Adam | epoch: 003 | loss: 0.62956 - acc: 0.6356 -- iter: 0544/1668
[A[ATraining Step: 124  | total loss: [1m[32m0.63105[0m[0m | time: 13.866s
[2K
| Adam | epoch: 003 | loss: 0.63105 - acc: 0.6376 -- iter: 0576/1668
[A[ATraining Step: 125  | total loss: [1m[32m0.63091[0m[0m | time: 14.977s
[2K
| Adam | epoch: 003 | loss: 0.63091 - acc: 0.6395 -- iter: 0608/1668
[A[ATraining Step: 126  | total loss: [1m[32m0.62323[0m[0m | time: 16.194s
[2K
| Adam | epoch: 003 | loss: 0.62323 - acc: 0.6537 -- iter: 0640/1668
[A[ATraining Step: 127  | total loss: [1m[32m0.62785[0m[0m | time: 17.409s
[2K
| Adam | epoch: 003 | loss: 0.62785 - acc: 0.6445 -- iter: 0672/1668
[A[ATraining Step: 128  | total loss: [1m[32m0.62920[0m[0m | time: 18.582s
[2K
| Adam | epoch: 003 | loss: 0.62920 - acc: 0.6426 -- iter: 0704/1668
[A[ATraining Step: 129  | total loss: [1m[32m0.63143[0m[0m | time: 19.781s
[2K
| Adam | epoch: 003 | loss: 0.63143 - acc: 0.6346 -- iter: 0736/1668
[A[ATraining Step: 130  | total loss: [1m[32m0.63262[0m[0m | time: 20.940s
[2K
| Adam | epoch: 003 | loss: 0.63262 - acc: 0.6399 -- iter: 0768/1668
[A[ATraining Step: 131  | total loss: [1m[32m0.63550[0m[0m | time: 21.861s
[2K
| Adam | epoch: 003 | loss: 0.63550 - acc: 0.6321 -- iter: 0800/1668
[A[ATraining Step: 132  | total loss: [1m[32m0.63990[0m[0m | time: 22.556s
[2K
| Adam | epoch: 003 | loss: 0.63990 - acc: 0.6189 -- iter: 0832/1668
[A[ATraining Step: 133  | total loss: [1m[32m0.63721[0m[0m | time: 23.216s
[2K
| Adam | epoch: 003 | loss: 0.63721 - acc: 0.6227 -- iter: 0864/1668
[A[ATraining Step: 134  | total loss: [1m[32m0.63371[0m[0m | time: 23.863s
[2K
| Adam | epoch: 003 | loss: 0.63371 - acc: 0.6323 -- iter: 0896/1668
[A[ATraining Step: 135  | total loss: [1m[32m0.62918[0m[0m | time: 24.566s
[2K
| Adam | epoch: 003 | loss: 0.62918 - acc: 0.6378 -- iter: 0928/1668
[A[ATraining Step: 136  | total loss: [1m[32m0.62624[0m[0m | time: 25.244s
[2K
| Adam | epoch: 003 | loss: 0.62624 - acc: 0.6365 -- iter: 0960/1668
[A[ATraining Step: 137  | total loss: [1m[32m0.62454[0m[0m | time: 25.914s
[2K
| Adam | epoch: 003 | loss: 0.62454 - acc: 0.6322 -- iter: 0992/1668
[A[ATraining Step: 138  | total loss: [1m[32m0.62528[0m[0m | time: 26.578s
[2K
| Adam | epoch: 003 | loss: 0.62528 - acc: 0.6346 -- iter: 1024/1668
[A[ATraining Step: 139  | total loss: [1m[32m0.61874[0m[0m | time: 27.253s
[2K
| Adam | epoch: 003 | loss: 0.61874 - acc: 0.6430 -- iter: 1056/1668
[A[ATraining Step: 140  | total loss: [1m[32m0.61530[0m[0m | time: 27.987s
[2K
| Adam | epoch: 003 | loss: 0.61530 - acc: 0.6537 -- iter: 1088/1668
[A[ATraining Step: 141  | total loss: [1m[32m0.61238[0m[0m | time: 28.671s
[2K
| Adam | epoch: 003 | loss: 0.61238 - acc: 0.6665 -- iter: 1120/1668
[A[ATraining Step: 142  | total loss: [1m[32m0.61570[0m[0m | time: 29.321s
[2K
| Adam | epoch: 003 | loss: 0.61570 - acc: 0.6686 -- iter: 1152/1668
[A[ATraining Step: 143  | total loss: [1m[32m0.61382[0m[0m | time: 30.002s
[2K
| Adam | epoch: 003 | loss: 0.61382 - acc: 0.6705 -- iter: 1184/1668
[A[ATraining Step: 144  | total loss: [1m[32m0.60990[0m[0m | time: 30.685s
[2K
| Adam | epoch: 003 | loss: 0.60990 - acc: 0.6722 -- iter: 1216/1668
[A[ATraining Step: 145  | total loss: [1m[32m0.61076[0m[0m | time: 31.377s
[2K
| Adam | epoch: 003 | loss: 0.61076 - acc: 0.6643 -- iter: 1248/1668
[A[ATraining Step: 146  | total loss: [1m[32m0.60432[0m[0m | time: 32.053s
[2K
| Adam | epoch: 003 | loss: 0.60432 - acc: 0.6667 -- iter: 1280/1668
[A[ATraining Step: 147  | total loss: [1m[32m0.60365[0m[0m | time: 32.755s
[2K
| Adam | epoch: 003 | loss: 0.60365 - acc: 0.6656 -- iter: 1312/1668
[A[ATraining Step: 148  | total loss: [1m[32m0.60158[0m[0m | time: 33.475s
[2K
| Adam | epoch: 003 | loss: 0.60158 - acc: 0.6709 -- iter: 1344/1668
[A[ATraining Step: 149  | total loss: [1m[32m0.59967[0m[0m | time: 34.196s
[2K
| Adam | epoch: 003 | loss: 0.59967 - acc: 0.6726 -- iter: 1376/1668
[A[ATraining Step: 150  | total loss: [1m[32m0.59026[0m[0m | time: 34.893s
[2K
| Adam | epoch: 003 | loss: 0.59026 - acc: 0.6803 -- iter: 1408/1668
[A[ATraining Step: 151  | total loss: [1m[32m0.59114[0m[0m | time: 35.569s
[2K
| Adam | epoch: 003 | loss: 0.59114 - acc: 0.6748 -- iter: 1440/1668
[A[ATraining Step: 152  | total loss: [1m[32m0.58762[0m[0m | time: 36.235s
[2K
| Adam | epoch: 003 | loss: 0.58762 - acc: 0.6854 -- iter: 1472/1668
[A[ATraining Step: 153  | total loss: [1m[32m0.59731[0m[0m | time: 36.913s
[2K
| Adam | epoch: 003 | loss: 0.59731 - acc: 0.6856 -- iter: 1504/1668
[A[ATraining Step: 154  | total loss: [1m[32m0.62199[0m[0m | time: 37.599s
[2K
| Adam | epoch: 003 | loss: 0.62199 - acc: 0.6796 -- iter: 1536/1668
[A[ATraining Step: 155  | total loss: [1m[32m0.62146[0m[0m | time: 38.321s
[2K
| Adam | epoch: 003 | loss: 0.62146 - acc: 0.6741 -- iter: 1568/1668
[A[ATraining Step: 156  | total loss: [1m[32m0.62120[0m[0m | time: 39.030s
[2K
| Adam | epoch: 003 | loss: 0.62120 - acc: 0.6755 -- iter: 1600/1668
[A[ATraining Step: 157  | total loss: [1m[32m0.62362[0m[0m | time: 39.692s
[2K
| Adam | epoch: 003 | loss: 0.62362 - acc: 0.6735 -- iter: 1632/1668
[A[ATraining Step: 158  | total loss: [1m[32m0.63961[0m[0m | time: 40.406s
[2K
| Adam | epoch: 003 | loss: 0.63961 - acc: 0.6437 -- iter: 1664/1668
[A[ATraining Step: 159  | total loss: [1m[32m0.64426[0m[0m | time: 43.278s
[2K
| Adam | epoch: 003 | loss: 0.64426 - acc: 0.6387 | val_loss: 0.65020 - val_acc: 0.6226 -- iter: 1668/1668
--
Training Step: 160  | total loss: [1m[32m0.65062[0m[0m | time: 0.675s
[2K
| Adam | epoch: 004 | loss: 0.65062 - acc: 0.6279 -- iter: 0032/1668
[A[ATraining Step: 161  | total loss: [1m[32m0.64427[0m[0m | time: 0.787s
[2K
| Adam | epoch: 004 | loss: 0.64427 - acc: 0.6370 -- iter: 0064/1668
[A[ATraining Step: 162  | total loss: [1m[32m0.64009[0m[0m | time: 0.892s
[2K
| Adam | epoch: 004 | loss: 0.64009 - acc: 0.6483 -- iter: 0096/1668
[A[ATraining Step: 163  | total loss: [1m[32m0.63638[0m[0m | time: 1.562s
[2K
| Adam | epoch: 004 | loss: 0.63638 - acc: 0.6585 -- iter: 0128/1668
[A[ATraining Step: 164  | total loss: [1m[32m0.63756[0m[0m | time: 2.246s
[2K
| Adam | epoch: 004 | loss: 0.63756 - acc: 0.6520 -- iter: 0160/1668
[A[ATraining Step: 165  | total loss: [1m[32m0.63659[0m[0m | time: 2.938s
[2K
| Adam | epoch: 004 | loss: 0.63659 - acc: 0.6524 -- iter: 0192/1668
[A[ATraining Step: 166  | total loss: [1m[32m0.63560[0m[0m | time: 3.622s
[2K
| Adam | epoch: 004 | loss: 0.63560 - acc: 0.6559 -- iter: 0224/1668
[A[ATraining Step: 167  | total loss: [1m[32m0.63698[0m[0m | time: 4.310s
[2K
| Adam | epoch: 004 | loss: 0.63698 - acc: 0.6529 -- iter: 0256/1668
[A[ATraining Step: 168  | total loss: [1m[32m0.63602[0m[0m | time: 4.999s
[2K
| Adam | epoch: 004 | loss: 0.63602 - acc: 0.6469 -- iter: 0288/1668
[A[ATraining Step: 169  | total loss: [1m[32m0.63235[0m[0m | time: 5.835s
[2K
| Adam | epoch: 004 | loss: 0.63235 - acc: 0.6510 -- iter: 0320/1668
[A[ATraining Step: 170  | total loss: [1m[32m0.63569[0m[0m | time: 6.647s
[2K
| Adam | epoch: 004 | loss: 0.63569 - acc: 0.6421 -- iter: 0352/1668
[A[ATraining Step: 171  | total loss: [1m[32m0.63254[0m[0m | time: 7.585s
[2K
| Adam | epoch: 004 | loss: 0.63254 - acc: 0.6529 -- iter: 0384/1668
[A[ATraining Step: 172  | total loss: [1m[32m0.62630[0m[0m | time: 8.574s
[2K
| Adam | epoch: 004 | loss: 0.62630 - acc: 0.6564 -- iter: 0416/1668
[A[ATraining Step: 173  | total loss: [1m[32m0.62236[0m[0m | time: 9.952s
[2K
| Adam | epoch: 004 | loss: 0.62236 - acc: 0.6564 -- iter: 0448/1668
[A[ATraining Step: 174  | total loss: [1m[32m0.61682[0m[0m | time: 11.495s
[2K
| Adam | epoch: 004 | loss: 0.61682 - acc: 0.6595 -- iter: 0480/1668
[A[ATraining Step: 175  | total loss: [1m[32m0.62123[0m[0m | time: 15.116s
[2K
| Adam | epoch: 004 | loss: 0.62123 - acc: 0.6498 -- iter: 0512/1668
[A[ATraining Step: 176  | total loss: [1m[32m0.62025[0m[0m | time: 17.085s
[2K
| Adam | epoch: 004 | loss: 0.62025 - acc: 0.6536 -- iter: 0544/1668
[A[ATraining Step: 177  | total loss: [1m[32m0.62686[0m[0m | time: 19.311s
[2K
| Adam | epoch: 004 | loss: 0.62686 - acc: 0.6445 -- iter: 0576/1668
[A[ATraining Step: 178  | total loss: [1m[32m0.62136[0m[0m | time: 22.797s
[2K
| Adam | epoch: 004 | loss: 0.62136 - acc: 0.6456 -- iter: 0608/1668
[A[ATraining Step: 179  | total loss: [1m[32m0.60786[0m[0m | time: 27.167s
[2K
| Adam | epoch: 004 | loss: 0.60786 - acc: 0.6592 -- iter: 0640/1668
[A[ATraining Step: 180  | total loss: [1m[32m0.60995[0m[0m | time: 30.896s
[2K
| Adam | epoch: 004 | loss: 0.60995 - acc: 0.6589 -- iter: 0672/1668
[A[ATraining Step: 181  | total loss: [1m[32m0.61040[0m[0m | time: 36.259s
[2K
| Adam | epoch: 004 | loss: 0.61040 - acc: 0.6586 -- iter: 0704/1668
[A[ATraining Step: 182  | total loss: [1m[32m0.61123[0m[0m | time: 40.424s
[2K
| Adam | epoch: 004 | loss: 0.61123 - acc: 0.6584 -- iter: 0736/1668
[A[ATraining Step: 183  | total loss: [1m[32m0.60931[0m[0m | time: 43.455s
[2K
| Adam | epoch: 004 | loss: 0.60931 - acc: 0.6613 -- iter: 0768/1668
[A[ATraining Step: 184  | total loss: [1m[32m0.61610[0m[0m | time: 45.985s
[2K
| Adam | epoch: 004 | loss: 0.61610 - acc: 0.6577 -- iter: 0800/1668
[A[ATraining Step: 185  | total loss: [1m[32m0.61241[0m[0m | time: 49.957s
[2K
| Adam | epoch: 004 | loss: 0.61241 - acc: 0.6607 -- iter: 0832/1668
[A[ATraining Step: 186  | total loss: [1m[32m0.61218[0m[0m | time: 52.457s
[2K
| Adam | epoch: 004 | loss: 0.61218 - acc: 0.6602 -- iter: 0864/1668
[A[ATraining Step: 187  | total loss: [1m[32m0.61143[0m[0m | time: 53.499s
[2K
| Adam | epoch: 004 | loss: 0.61143 - acc: 0.6536 -- iter: 0896/1668
[A[ATraining Step: 188  | total loss: [1m[32m0.61177[0m[0m | time: 54.593s
[2K
| Adam | epoch: 004 | loss: 0.61177 - acc: 0.6507 -- iter: 0928/1668
[A[ATraining Step: 189  | total loss: [1m[32m0.60913[0m[0m | time: 55.692s
[2K
| Adam | epoch: 004 | loss: 0.60913 - acc: 0.6575 -- iter: 0960/1668
[A[ATraining Step: 190  | total loss: [1m[32m0.60358[0m[0m | time: 56.901s
[2K
| Adam | epoch: 004 | loss: 0.60358 - acc: 0.6668 -- iter: 0992/1668
[A[ATraining Step: 191  | total loss: [1m[32m0.59303[0m[0m | time: 58.087s
[2K
| Adam | epoch: 004 | loss: 0.59303 - acc: 0.6720 -- iter: 1024/1668
[A[ATraining Step: 192  | total loss: [1m[32m0.58177[0m[0m | time: 59.054s
[2K
| Adam | epoch: 004 | loss: 0.58177 - acc: 0.6829 -- iter: 1056/1668
[A[ATraining Step: 193  | total loss: [1m[32m0.58221[0m[0m | time: 60.211s
[2K
| Adam | epoch: 004 | loss: 0.58221 - acc: 0.6802 -- iter: 1088/1668
[A[ATraining Step: 194  | total loss: [1m[32m0.57903[0m[0m | time: 61.264s
[2K
| Adam | epoch: 004 | loss: 0.57903 - acc: 0.6810 -- iter: 1120/1668
[A[ATraining Step: 195  | total loss: [1m[32m0.57142[0m[0m | time: 62.527s
[2K
| Adam | epoch: 004 | loss: 0.57142 - acc: 0.6910 -- iter: 1152/1668
[A[ATraining Step: 196  | total loss: [1m[32m0.56886[0m[0m | time: 63.853s
[2K
| Adam | epoch: 004 | loss: 0.56886 - acc: 0.6938 -- iter: 1184/1668
[A[ATraining Step: 197  | total loss: [1m[32m0.57976[0m[0m | time: 71.748s
[2K
| Adam | epoch: 004 | loss: 0.57976 - acc: 0.6869 -- iter: 1216/1668
[A[ATraining Step: 198  | total loss: [1m[32m0.58034[0m[0m | time: 76.308s
[2K
| Adam | epoch: 004 | loss: 0.58034 - acc: 0.6838 -- iter: 1248/1668
[A[ATraining Step: 199  | total loss: [1m[32m0.58089[0m[0m | time: 78.903s
[2K
| Adam | epoch: 004 | loss: 0.58089 - acc: 0.6873 -- iter: 1280/1668
[A[ATraining Step: 200  | total loss: [1m[32m0.58025[0m[0m | time: 120.784s
[2K
| Adam | epoch: 004 | loss: 0.58025 - acc: 0.6873 | val_loss: 0.61677 - val_acc: 0.6667 -- iter: 1312/1668
--
Training Step: 201  | total loss: [1m[32m0.57527[0m[0m | time: 123.007s
[2K
| Adam | epoch: 004 | loss: 0.57527 - acc: 0.6905 -- iter: 1344/1668
[A[ATraining Step: 202  | total loss: [1m[32m0.58793[0m[0m | time: 124.797s
[2K
| Adam | epoch: 004 | loss: 0.58793 - acc: 0.6808 -- iter: 1376/1668
[A[ATraining Step: 203  | total loss: [1m[32m0.58743[0m[0m | time: 128.045s
[2K
| Adam | epoch: 004 | loss: 0.58743 - acc: 0.6815 -- iter: 1408/1668
[A[ATraining Step: 204  | total loss: [1m[32m0.57422[0m[0m | time: 129.106s
[2K
| Adam | epoch: 004 | loss: 0.57422 - acc: 0.6946 -- iter: 1440/1668
[A[ATraining Step: 205  | total loss: [1m[32m0.57803[0m[0m | time: 129.997s
[2K
| Adam | epoch: 004 | loss: 0.57803 - acc: 0.6939 -- iter: 1472/1668
[A[ATraining Step: 206  | total loss: [1m[32m0.57267[0m[0m | time: 130.971s
[2K
| Adam | epoch: 004 | loss: 0.57267 - acc: 0.7057 -- iter: 1504/1668
[A[ATraining Step: 207  | total loss: [1m[32m0.58310[0m[0m | time: 131.957s
[2K
| Adam | epoch: 004 | loss: 0.58310 - acc: 0.7070 -- iter: 1536/1668
[A[ATraining Step: 208  | total loss: [1m[32m0.58490[0m[0m | time: 132.962s
[2K
| Adam | epoch: 004 | loss: 0.58490 - acc: 0.7051 -- iter: 1568/1668
[A[ATraining Step: 209  | total loss: [1m[32m0.58374[0m[0m | time: 134.022s
[2K
| Adam | epoch: 004 | loss: 0.58374 - acc: 0.7033 -- iter: 1600/1668
[A[ATraining Step: 210  | total loss: [1m[32m0.59001[0m[0m | time: 135.137s
[2K
| Adam | epoch: 004 | loss: 0.59001 - acc: 0.6924 -- iter: 1632/1668
[A[ATraining Step: 211  | total loss: [1m[32m0.57593[0m[0m | time: 136.205s
[2K
| Adam | epoch: 004 | loss: 0.57593 - acc: 0.6981 -- iter: 1664/1668
[A[ATraining Step: 212  | total loss: [1m[32m0.57824[0m[0m | time: 183.353s
[2K
| Adam | epoch: 004 | loss: 0.57824 - acc: 0.6971 | val_loss: 0.61322 - val_acc: 0.6743 -- iter: 1668/1668
--
Training Step: 213  | total loss: [1m[32m0.58093[0m[0m | time: 4.564s
[2K
| Adam | epoch: 005 | loss: 0.58093 - acc: 0.6961 -- iter: 0032/1668
[A[ATraining Step: 214  | total loss: [1m[32m0.57924[0m[0m | time: 9.800s
[2K
| Adam | epoch: 005 | loss: 0.57924 - acc: 0.6952 -- iter: 0064/1668
[A[ATraining Step: 215  | total loss: [1m[32m0.57855[0m[0m | time: 9.957s
[2K
| Adam | epoch: 005 | loss: 0.57855 - acc: 0.6945 -- iter: 0096/1668
[A[ATraining Step: 216  | total loss: [1m[32m0.58464[0m[0m | time: 10.122s
[2K
| Adam | epoch: 005 | loss: 0.58464 - acc: 0.6750 -- iter: 0128/1668
[A[ATraining Step: 217  | total loss: [1m[32m0.58637[0m[0m | time: 14.716s
[2K
| Adam | epoch: 005 | loss: 0.58637 - acc: 0.6575 -- iter: 0160/1668
[A[ATraining Step: 218  | total loss: [1m[32m0.58826[0m[0m | time: 17.386s
[2K
| Adam | epoch: 005 | loss: 0.58826 - acc: 0.6605 -- iter: 0192/1668
[A[ATraining Step: 219  | total loss: [1m[32m0.58433[0m[0m | time: 21.556s
[2K
| Adam | epoch: 005 | loss: 0.58433 - acc: 0.6632 -- iter: 0224/1668
[A[ATraining Step: 220  | total loss: [1m[32m0.58200[0m[0m | time: 25.483s
[2K
| Adam | epoch: 005 | loss: 0.58200 - acc: 0.6625 -- iter: 0256/1668
[A[ATraining Step: 221  | total loss: [1m[32m0.57716[0m[0m | time: 27.818s
[2K
| Adam | epoch: 005 | loss: 0.57716 - acc: 0.6775 -- iter: 0288/1668
[A[ATraining Step: 222  | total loss: [1m[32m0.58678[0m[0m | time: 31.105s
[2K
| Adam | epoch: 005 | loss: 0.58678 - acc: 0.6691 -- iter: 0320/1668
[A[ATraining Step: 223  | total loss: [1m[32m0.58637[0m[0m | time: 35.186s
[2K
| Adam | epoch: 005 | loss: 0.58637 - acc: 0.6710 -- iter: 0352/1668
[A[ATraining Step: 224  | total loss: [1m[32m0.58148[0m[0m | time: 39.622s
[2K
| Adam | epoch: 005 | loss: 0.58148 - acc: 0.6758 -- iter: 0384/1668
[A[ATraining Step: 225  | total loss: [1m[32m0.58732[0m[0m | time: 42.750s
[2K
| Adam | epoch: 005 | loss: 0.58732 - acc: 0.6769 -- iter: 0416/1668
[A[ATraining Step: 226  | total loss: [1m[32m0.59041[0m[0m | time: 45.476s
[2K
| Adam | epoch: 005 | loss: 0.59041 - acc: 0.6749 -- iter: 0448/1668
[A[ATraining Step: 227  | total loss: [1m[32m0.58601[0m[0m | time: 47.714s
[2K
| Adam | epoch: 005 | loss: 0.58601 - acc: 0.6855 -- iter: 0480/1668
[A[ATraining Step: 228  | total loss: [1m[32m0.58958[0m[0m | time: 48.553s
[2K
| Adam | epoch: 005 | loss: 0.58958 - acc: 0.6701 -- iter: 0512/1668
[A[ATraining Step: 229  | total loss: [1m[32m0.58605[0m[0m | time: 49.604s
[2K
| Adam | epoch: 005 | loss: 0.58605 - acc: 0.6843 -- iter: 0544/1668
[A[ATraining Step: 230  | total loss: [1m[32m0.58705[0m[0m | time: 50.599s
[2K
| Adam | epoch: 005 | loss: 0.58705 - acc: 0.6846 -- iter: 0576/1668
[A[ATraining Step: 231  | total loss: [1m[32m0.58277[0m[0m | time: 51.656s
[2K
| Adam | epoch: 005 | loss: 0.58277 - acc: 0.6912 -- iter: 0608/1668
[A[ATraining Step: 232  | total loss: [1m[32m0.57755[0m[0m | time: 52.739s
[2K
| Adam | epoch: 005 | loss: 0.57755 - acc: 0.7002 -- iter: 0640/1668
[A[ATraining Step: 233  | total loss: [1m[32m0.58507[0m[0m | time: 53.905s
[2K
| Adam | epoch: 005 | loss: 0.58507 - acc: 0.6895 -- iter: 0672/1668
[A[ATraining Step: 234  | total loss: [1m[32m0.58191[0m[0m | time: 55.016s
[2K
| Adam | epoch: 005 | loss: 0.58191 - acc: 0.6831 -- iter: 0704/1668
[A[ATraining Step: 235  | total loss: [1m[32m0.58557[0m[0m | time: 55.983s
[2K
| Adam | epoch: 005 | loss: 0.58557 - acc: 0.6773 -- iter: 0736/1668
[A[ATraining Step: 236  | total loss: [1m[32m0.58168[0m[0m | time: 57.420s
[2K
| Adam | epoch: 005 | loss: 0.58168 - acc: 0.6814 -- iter: 0768/1668
[A[ATraining Step: 237  | total loss: [1m[32m0.58562[0m[0m | time: 58.520s
[2K
| Adam | epoch: 005 | loss: 0.58562 - acc: 0.6664 -- iter: 0800/1668
[A[ATraining Step: 238  | total loss: [1m[32m0.57924[0m[0m | time: 61.763s
[2K
| Adam | epoch: 005 | loss: 0.57924 - acc: 0.6748 -- iter: 0832/1668
[A[ATraining Step: 239  | total loss: [1m[32m0.57817[0m[0m | time: 64.561s
[2K
| Adam | epoch: 005 | loss: 0.57817 - acc: 0.6823 -- iter: 0864/1668
[A[ATraining Step: 240  | total loss: [1m[32m0.57452[0m[0m | time: 67.643s
[2K
| Adam | epoch: 005 | loss: 0.57452 - acc: 0.6891 -- iter: 0896/1668
[A[ATraining Step: 241  | total loss: [1m[32m0.57522[0m[0m | time: 68.623s
[2K
| Adam | epoch: 005 | loss: 0.57522 - acc: 0.6827 -- iter: 0928/1668
[A[ATraining Step: 242  | total loss: [1m[32m0.55702[0m[0m | time: 69.639s
[2K
| Adam | epoch: 005 | loss: 0.55702 - acc: 0.7019 -- iter: 0960/1668
[A[ATraining Step: 243  | total loss: [1m[32m0.54987[0m[0m | time: 70.688s
[2K
| Adam | epoch: 005 | loss: 0.54987 - acc: 0.7098 -- iter: 0992/1668
[A[ATraining Step: 244  | total loss: [1m[32m0.55196[0m[0m | time: 71.799s
[2K
| Adam | epoch: 005 | loss: 0.55196 - acc: 0.7138 -- iter: 1024/1668
[A[ATraining Step: 245  | total loss: [1m[32m0.55059[0m[0m | time: 73.012s
[2K
| Adam | epoch: 005 | loss: 0.55059 - acc: 0.7112 -- iter: 1056/1668
[A[ATraining Step: 246  | total loss: [1m[32m0.55073[0m[0m | time: 74.192s
[2K
| Adam | epoch: 005 | loss: 0.55073 - acc: 0.7057 -- iter: 1088/1668
[A[ATraining Step: 247  | total loss: [1m[32m0.55363[0m[0m | time: 75.184s
[2K
| Adam | epoch: 005 | loss: 0.55363 - acc: 0.7070 -- iter: 1120/1668
[A[ATraining Step: 248  | total loss: [1m[32m0.55765[0m[0m | time: 76.343s
[2K
| Adam | epoch: 005 | loss: 0.55765 - acc: 0.7019 -- iter: 1152/1668
[A[ATraining Step: 249  | total loss: [1m[32m0.55224[0m[0m | time: 77.408s
[2K
| Adam | epoch: 005 | loss: 0.55224 - acc: 0.7130 -- iter: 1184/1668
[A[ATraining Step: 250  | total loss: [1m[32m0.55547[0m[0m | time: 78.370s
[2K
| Adam | epoch: 005 | loss: 0.55547 - acc: 0.7073 -- iter: 1216/1668
[A[ATraining Step: 251  | total loss: [1m[32m0.55239[0m[0m | time: 79.227s
[2K
| Adam | epoch: 005 | loss: 0.55239 - acc: 0.7116 -- iter: 1248/1668
[A[ATraining Step: 252  | total loss: [1m[32m0.56293[0m[0m | time: 80.273s
[2K
| Adam | epoch: 005 | loss: 0.56293 - acc: 0.7061 -- iter: 1280/1668
[A[ATraining Step: 253  | total loss: [1m[32m0.55519[0m[0m | time: 81.278s
[2K
| Adam | epoch: 005 | loss: 0.55519 - acc: 0.7073 -- iter: 1312/1668
[A[ATraining Step: 254  | total loss: [1m[32m0.54485[0m[0m | time: 82.282s
[2K
| Adam | epoch: 005 | loss: 0.54485 - acc: 0.7178 -- iter: 1344/1668
[A[ATraining Step: 255  | total loss: [1m[32m0.53728[0m[0m | time: 83.286s
[2K
| Adam | epoch: 005 | loss: 0.53728 - acc: 0.7304 -- iter: 1376/1668
[A[ATraining Step: 256  | total loss: [1m[32m0.54357[0m[0m | time: 84.390s
[2K
| Adam | epoch: 005 | loss: 0.54357 - acc: 0.7230 -- iter: 1408/1668
[A[ATraining Step: 257  | total loss: [1m[32m0.54693[0m[0m | time: 85.467s
[2K
| Adam | epoch: 005 | loss: 0.54693 - acc: 0.7132 -- iter: 1440/1668
[A[ATraining Step: 258  | total loss: [1m[32m0.55845[0m[0m | time: 86.407s
[2K
| Adam | epoch: 005 | loss: 0.55845 - acc: 0.7013 -- iter: 1472/1668
[A[ATraining Step: 259  | total loss: [1m[32m0.54632[0m[0m | time: 87.848s
[2K
| Adam | epoch: 005 | loss: 0.54632 - acc: 0.7155 -- iter: 1504/1668
[A[ATraining Step: 260  | total loss: [1m[32m0.54312[0m[0m | time: 89.686s
[2K
| Adam | epoch: 005 | loss: 0.54312 - acc: 0.7158 -- iter: 1536/1668
[A[ATraining Step: 261  | total loss: [1m[32m0.55676[0m[0m | time: 99.680s
[2K
| Adam | epoch: 005 | loss: 0.55676 - acc: 0.7068 -- iter: 1568/1668
[A[ATraining Step: 262  | total loss: [1m[32m0.55752[0m[0m | time: 107.879s
[2K
| Adam | epoch: 005 | loss: 0.55752 - acc: 0.7111 -- iter: 1600/1668
[A[ATraining Step: 263  | total loss: [1m[32m0.56388[0m[0m | time: 112.095s
[2K
| Adam | epoch: 005 | loss: 0.56388 - acc: 0.7087 -- iter: 1632/1668
[A[ATraining Step: 264  | total loss: [1m[32m0.56921[0m[0m | time: 119.855s
[2K
| Adam | epoch: 005 | loss: 0.56921 - acc: 0.7160 -- iter: 1664/1668
[A[ATraining Step: 265  | total loss: [1m[32m0.56617[0m[0m | time: 172.002s
[2K
| Adam | epoch: 005 | loss: 0.56617 - acc: 0.7163 | val_loss: 0.60256 - val_acc: 0.6877 -- iter: 1668/1668
--
Training Step: 266  | total loss: [1m[32m0.55576[0m[0m | time: 2.284s
[2K
| Adam | epoch: 006 | loss: 0.55576 - acc: 0.7290 -- iter: 0032/1668
[A[ATraining Step: 267  | total loss: [1m[32m0.55064[0m[0m | time: 3.152s
[2K
| Adam | epoch: 006 | loss: 0.55064 - acc: 0.7374 -- iter: 0064/1668
[A[ATraining Step: 268  | total loss: [1m[32m0.56027[0m[0m | time: 4.143s
[2K
| Adam | epoch: 006 | loss: 0.56027 - acc: 0.7261 -- iter: 0096/1668
[A[ATraining Step: 269  | total loss: [1m[32m0.56380[0m[0m | time: 4.293s
[2K
| Adam | epoch: 006 | loss: 0.56380 - acc: 0.7191 -- iter: 0128/1668
[A[ATraining Step: 270  | total loss: [1m[32m0.57830[0m[0m | time: 4.453s
[2K
| Adam | epoch: 006 | loss: 0.57830 - acc: 0.6972 -- iter: 0160/1668
[A[ATraining Step: 271  | total loss: [1m[32m0.57549[0m[0m | time: 5.499s
[2K
| Adam | epoch: 006 | loss: 0.57549 - acc: 0.7025 -- iter: 0192/1668
[A[ATraining Step: 272  | total loss: [1m[32m0.56703[0m[0m | time: 6.487s
[2K
| Adam | epoch: 006 | loss: 0.56703 - acc: 0.7041 -- iter: 0224/1668
[A[ATraining Step: 273  | total loss: [1m[32m0.55099[0m[0m | time: 7.538s
[2K
| Adam | epoch: 006 | loss: 0.55099 - acc: 0.7150 -- iter: 0256/1668
[A[ATraining Step: 274  | total loss: [1m[32m0.57637[0m[0m | time: 8.720s
[2K
| Adam | epoch: 006 | loss: 0.57637 - acc: 0.6935 -- iter: 0288/1668
[A[ATraining Step: 275  | total loss: [1m[32m0.58033[0m[0m | time: 9.800s
[2K
| Adam | epoch: 006 | loss: 0.58033 - acc: 0.6960 -- iter: 0320/1668
[A[ATraining Step: 276  | total loss: [1m[32m0.58471[0m[0m | time: 10.787s
[2K
| Adam | epoch: 006 | loss: 0.58471 - acc: 0.6858 -- iter: 0352/1668
[A[ATraining Step: 277  | total loss: [1m[32m0.58706[0m[0m | time: 12.028s
[2K
| Adam | epoch: 006 | loss: 0.58706 - acc: 0.6891 -- iter: 0384/1668
[A[ATraining Step: 278  | total loss: [1m[32m0.58779[0m[0m | time: 13.107s
[2K
| Adam | epoch: 006 | loss: 0.58779 - acc: 0.6920 -- iter: 0416/1668
[A[ATraining Step: 279  | total loss: [1m[32m0.58705[0m[0m | time: 18.922s
[2K
| Adam | epoch: 006 | loss: 0.58705 - acc: 0.6978 -- iter: 0448/1668
[A[ATraining Step: 280  | total loss: [1m[32m0.59865[0m[0m | time: 20.279s
[2K
| Adam | epoch: 006 | loss: 0.59865 - acc: 0.6812 -- iter: 0480/1668
[A[ATraining Step: 281  | total loss: [1m[32m0.59958[0m[0m | time: 22.976s
[2K
| Adam | epoch: 006 | loss: 0.59958 - acc: 0.6849 -- iter: 0512/1668
[A[ATraining Step: 282  | total loss: [1m[32m0.60344[0m[0m | time: 24.852s
[2K
| Adam | epoch: 006 | loss: 0.60344 - acc: 0.6821 -- iter: 0544/1668
[A[ATraining Step: 283  | total loss: [1m[32m0.60744[0m[0m | time: 26.638s
[2K
| Adam | epoch: 006 | loss: 0.60744 - acc: 0.6795 -- iter: 0576/1668
[A[ATraining Step: 284  | total loss: [1m[32m0.61814[0m[0m | time: 30.310s
[2K
| Adam | epoch: 006 | loss: 0.61814 - acc: 0.6584 -- iter: 0608/1668
[A[ATraining Step: 285  | total loss: [1m[32m0.61784[0m[0m | time: 34.609s
[2K
| Adam | epoch: 006 | loss: 0.61784 - acc: 0.6582 -- iter: 0640/1668
[A[ATraining Step: 286  | total loss: [1m[32m0.61759[0m[0m | time: 37.849s
[2K
| Adam | epoch: 006 | loss: 0.61759 - acc: 0.6580 -- iter: 0672/1668
[A[ATraining Step: 287  | total loss: [1m[32m0.60727[0m[0m | time: 38.788s
[2K
| Adam | epoch: 006 | loss: 0.60727 - acc: 0.6734 -- iter: 0704/1668
[A[ATraining Step: 288  | total loss: [1m[32m0.61215[0m[0m | time: 39.764s
[2K
| Adam | epoch: 006 | loss: 0.61215 - acc: 0.6624 -- iter: 0736/1668
[A[ATraining Step: 289  | total loss: [1m[32m0.61093[0m[0m | time: 40.752s
[2K
| Adam | epoch: 006 | loss: 0.61093 - acc: 0.6586 -- iter: 0768/1668
[A[ATraining Step: 290  | total loss: [1m[32m0.61190[0m[0m | time: 41.747s
[2K
| Adam | epoch: 006 | loss: 0.61190 - acc: 0.6678 -- iter: 0800/1668
[A[ATraining Step: 291  | total loss: [1m[32m0.60850[0m[0m | time: 42.808s
[2K
| Adam | epoch: 006 | loss: 0.60850 - acc: 0.6635 -- iter: 0832/1668
[A[ATraining Step: 292  | total loss: [1m[32m0.61446[0m[0m | time: 43.895s
[2K
| Adam | epoch: 006 | loss: 0.61446 - acc: 0.6596 -- iter: 0864/1668
[A[ATraining Step: 293  | total loss: [1m[32m0.61031[0m[0m | time: 44.919s
[2K
| Adam | epoch: 006 | loss: 0.61031 - acc: 0.6593 -- iter: 0896/1668
[A[ATraining Step: 294  | total loss: [1m[32m0.60607[0m[0m | time: 45.901s
[2K
| Adam | epoch: 006 | loss: 0.60607 - acc: 0.6652 -- iter: 0928/1668
[A[ATraining Step: 295  | total loss: [1m[32m0.61192[0m[0m | time: 47.172s
[2K
| Adam | epoch: 006 | loss: 0.61192 - acc: 0.6487 -- iter: 0960/1668
[A[ATraining Step: 296  | total loss: [1m[32m0.60996[0m[0m | time: 49.967s
[2K
| Adam | epoch: 006 | loss: 0.60996 - acc: 0.6588 -- iter: 0992/1668
[A[ATraining Step: 297  | total loss: [1m[32m0.60313[0m[0m | time: 52.008s
[2K
| Adam | epoch: 006 | loss: 0.60313 - acc: 0.6617 -- iter: 1024/1668
[A[ATraining Step: 298  | total loss: [1m[32m0.59843[0m[0m | time: 55.787s
[2K
| Adam | epoch: 006 | loss: 0.59843 - acc: 0.6643 -- iter: 1056/1668
[A[ATraining Step: 299  | total loss: [1m[32m0.60128[0m[0m | time: 58.303s
[2K
| Adam | epoch: 006 | loss: 0.60128 - acc: 0.6572 -- iter: 1088/1668
[A[ATraining Step: 300  | total loss: [1m[32m0.57422[0m[0m | time: 61.642s
[2K
| Adam | epoch: 006 | loss: 0.57422 - acc: 0.6821 -- iter: 1120/1668
[A[ATraining Step: 301  | total loss: [1m[32m0.57107[0m[0m | time: 62.576s
[2K
| Adam | epoch: 006 | loss: 0.57107 - acc: 0.6827 -- iter: 1152/1668
[A[ATraining Step: 302  | total loss: [1m[32m0.57523[0m[0m | time: 63.623s
[2K
| Adam | epoch: 006 | loss: 0.57523 - acc: 0.6769 -- iter: 1184/1668
[A[ATraining Step: 303  | total loss: [1m[32m0.56408[0m[0m | time: 64.680s
[2K
| Adam | epoch: 006 | loss: 0.56408 - acc: 0.6811 -- iter: 1216/1668
[A[ATraining Step: 304  | total loss: [1m[32m0.56344[0m[0m | time: 65.739s
[2K
| Adam | epoch: 006 | loss: 0.56344 - acc: 0.6880 -- iter: 1248/1668
[A[ATraining Step: 305  | total loss: [1m[32m0.56324[0m[0m | time: 66.898s
[2K
| Adam | epoch: 006 | loss: 0.56324 - acc: 0.6973 -- iter: 1280/1668
[A[ATraining Step: 306  | total loss: [1m[32m0.55458[0m[0m | time: 67.900s
[2K
| Adam | epoch: 006 | loss: 0.55458 - acc: 0.7057 -- iter: 1312/1668
[A[ATraining Step: 307  | total loss: [1m[32m0.55249[0m[0m | time: 68.876s
[2K
| Adam | epoch: 006 | loss: 0.55249 - acc: 0.7101 -- iter: 1344/1668
[A[ATraining Step: 308  | total loss: [1m[32m0.54381[0m[0m | time: 70.261s
[2K
| Adam | epoch: 006 | loss: 0.54381 - acc: 0.7141 -- iter: 1376/1668
[A[ATraining Step: 309  | total loss: [1m[32m0.54537[0m[0m | time: 72.166s
[2K
| Adam | epoch: 006 | loss: 0.54537 - acc: 0.7177 -- iter: 1408/1668
[A[ATraining Step: 310  | total loss: [1m[32m0.54458[0m[0m | time: 82.772s
[2K
| Adam | epoch: 006 | loss: 0.54458 - acc: 0.7147 -- iter: 1440/1668
[A[ATraining Step: 311  | total loss: [1m[32m0.54834[0m[0m | time: 87.527s
[2K
| Adam | epoch: 006 | loss: 0.54834 - acc: 0.7120 -- iter: 1472/1668
[A[ATraining Step: 312  | total loss: [1m[32m0.54021[0m[0m | time: 89.755s
[2K
| Adam | epoch: 006 | loss: 0.54021 - acc: 0.7189 -- iter: 1504/1668
[A[ATraining Step: 313  | total loss: [1m[32m0.54781[0m[0m | time: 92.413s
[2K
| Adam | epoch: 006 | loss: 0.54781 - acc: 0.7158 -- iter: 1536/1668
[A[ATraining Step: 314  | total loss: [1m[32m0.55367[0m[0m | time: 95.499s
[2K
| Adam | epoch: 006 | loss: 0.55367 - acc: 0.7067 -- iter: 1568/1668
[A[ATraining Step: 315  | total loss: [1m[32m0.56748[0m[0m | time: 102.226s
[2K
| Adam | epoch: 006 | loss: 0.56748 - acc: 0.6923 -- iter: 1600/1668
[A[ATraining Step: 316  | total loss: [1m[32m0.56347[0m[0m | time: 104.484s
[2K
| Adam | epoch: 006 | loss: 0.56347 - acc: 0.7012 -- iter: 1632/1668
[A[ATraining Step: 317  | total loss: [1m[32m0.56120[0m[0m | time: 106.294s
[2K
| Adam | epoch: 006 | loss: 0.56120 - acc: 0.7029 -- iter: 1664/1668
[A[ATraining Step: 318  | total loss: [1m[32m0.54776[0m[0m | time: 121.840s
[2K
| Adam | epoch: 006 | loss: 0.54776 - acc: 0.7170 | val_loss: 0.61750 - val_acc: 0.6590 -- iter: 1668/1668
--
Training Step: 319  | total loss: [1m[32m0.56443[0m[0m | time: 1.035s
[2K
| Adam | epoch: 007 | loss: 0.56443 - acc: 0.7016 -- iter: 0032/1668
[A[ATraining Step: 320  | total loss: [1m[32m0.56189[0m[0m | time: 2.036s
[2K
| Adam | epoch: 007 | loss: 0.56189 - acc: 0.7064 -- iter: 0064/1668
[A[ATraining Step: 321  | total loss: [1m[32m0.55488[0m[0m | time: 3.083s
[2K
| Adam | epoch: 007 | loss: 0.55488 - acc: 0.7045 -- iter: 0096/1668
[A[ATraining Step: 322  | total loss: [1m[32m0.55285[0m[0m | time: 4.116s
[2K
| Adam | epoch: 007 | loss: 0.55285 - acc: 0.7059 -- iter: 0128/1668
[A[ATraining Step: 323  | total loss: [1m[32m0.54694[0m[0m | time: 4.314s
[2K
| Adam | epoch: 007 | loss: 0.54694 - acc: 0.7135 -- iter: 0160/1668
[A[ATraining Step: 324  | total loss: [1m[32m0.53003[0m[0m | time: 4.488s
[2K
| Adam | epoch: 007 | loss: 0.53003 - acc: 0.7421 -- iter: 0192/1668
[A[ATraining Step: 325  | total loss: [1m[32m0.51255[0m[0m | time: 5.577s
[2K
| Adam | epoch: 007 | loss: 0.51255 - acc: 0.7679 -- iter: 0224/1668
[A[ATraining Step: 326  | total loss: [1m[32m0.51912[0m[0m | time: 6.589s
[2K
| Adam | epoch: 007 | loss: 0.51912 - acc: 0.7599 -- iter: 0256/1668
[A[ATraining Step: 327  | total loss: [1m[32m0.51760[0m[0m | time: 7.923s
[2K
| Adam | epoch: 007 | loss: 0.51760 - acc: 0.7620 -- iter: 0288/1668
[A[ATraining Step: 328  | total loss: [1m[32m0.52070[0m[0m | time: 12.072s
[2K
| Adam | epoch: 007 | loss: 0.52070 - acc: 0.7608 -- iter: 0320/1668
[A[ATraining Step: 329  | total loss: [1m[32m0.53450[0m[0m | time: 14.274s
[2K
| Adam | epoch: 007 | loss: 0.53450 - acc: 0.7472 -- iter: 0352/1668
[A[ATraining Step: 330  | total loss: [1m[32m0.53288[0m[0m | time: 17.058s
[2K
| Adam | epoch: 007 | loss: 0.53288 - acc: 0.7475 -- iter: 0384/1668
[A[ATraining Step: 331  | total loss: [1m[32m0.52693[0m[0m | time: 19.688s
[2K
| Adam | epoch: 007 | loss: 0.52693 - acc: 0.7509 -- iter: 0416/1668
[A[ATraining Step: 332  | total loss: [1m[32m0.53469[0m[0m | time: 23.391s
[2K
| Adam | epoch: 007 | loss: 0.53469 - acc: 0.7414 -- iter: 0448/1668
[A[ATraining Step: 333  | total loss: [1m[32m0.52930[0m[0m | time: 28.813s
[2K
| Adam | epoch: 007 | loss: 0.52930 - acc: 0.7485 -- iter: 0480/1668
[A[ATraining Step: 334  | total loss: [1m[32m0.53154[0m[0m | time: 31.179s
[2K
| Adam | epoch: 007 | loss: 0.53154 - acc: 0.7518 -- iter: 0512/1668
[A[ATraining Step: 335  | total loss: [1m[32m0.53165[0m[0m | time: 33.877s
[2K
| Adam | epoch: 007 | loss: 0.53165 - acc: 0.7516 -- iter: 0544/1668
[A[ATraining Step: 336  | total loss: [1m[32m0.53144[0m[0m | time: 36.056s
[2K
| Adam | epoch: 007 | loss: 0.53144 - acc: 0.7546 -- iter: 0576/1668
[A[ATraining Step: 337  | total loss: [1m[32m0.53011[0m[0m | time: 37.055s
[2K
| Adam | epoch: 007 | loss: 0.53011 - acc: 0.7541 -- iter: 0608/1668
[A[ATraining Step: 338  | total loss: [1m[32m0.53417[0m[0m | time: 38.045s
[2K
| Adam | epoch: 007 | loss: 0.53417 - acc: 0.7443 -- iter: 0640/1668
[A[ATraining Step: 339  | total loss: [1m[32m0.54155[0m[0m | time: 39.038s
[2K
| Adam | epoch: 007 | loss: 0.54155 - acc: 0.7480 -- iter: 0672/1668
[A[ATraining Step: 340  | total loss: [1m[32m0.54697[0m[0m | time: 40.085s
[2K
| Adam | epoch: 007 | loss: 0.54697 - acc: 0.7420 -- iter: 0704/1668
[A[ATraining Step: 341  | total loss: [1m[32m0.54147[0m[0m | time: 41.061s
[2K
| Adam | epoch: 007 | loss: 0.54147 - acc: 0.7397 -- iter: 0736/1668
[A[ATraining Step: 342  | total loss: [1m[32m0.53469[0m[0m | time: 42.164s
[2K
| Adam | epoch: 007 | loss: 0.53469 - acc: 0.7438 -- iter: 0768/1668
[A[ATraining Step: 343  | total loss: [1m[32m0.52593[0m[0m | time: 43.186s
[2K
| Adam | epoch: 007 | loss: 0.52593 - acc: 0.7476 -- iter: 0800/1668
[A[ATraining Step: 344  | total loss: [1m[32m0.52356[0m[0m | time: 44.330s
[2K
| Adam | epoch: 007 | loss: 0.52356 - acc: 0.7447 -- iter: 0832/1668
[A[ATraining Step: 345  | total loss: [1m[32m0.51376[0m[0m | time: 45.554s
[2K
| Adam | epoch: 007 | loss: 0.51376 - acc: 0.7452 -- iter: 0864/1668
[A[ATraining Step: 346  | total loss: [1m[32m0.50445[0m[0m | time: 46.611s
[2K
| Adam | epoch: 007 | loss: 0.50445 - acc: 0.7519 -- iter: 0896/1668
[A[ATraining Step: 347  | total loss: [1m[32m0.51546[0m[0m | time: 47.990s
[2K
| Adam | epoch: 007 | loss: 0.51546 - acc: 0.7486 -- iter: 0928/1668
[A[ATraining Step: 348  | total loss: [1m[32m0.51862[0m[0m | time: 49.041s
[2K
| Adam | epoch: 007 | loss: 0.51862 - acc: 0.7488 -- iter: 0960/1668
[A[ATraining Step: 349  | total loss: [1m[32m0.51487[0m[0m | time: 50.087s
[2K
| Adam | epoch: 007 | loss: 0.51487 - acc: 0.7551 -- iter: 0992/1668
[A[ATraining Step: 350  | total loss: [1m[32m0.51248[0m[0m | time: 51.183s
[2K
| Adam | epoch: 007 | loss: 0.51248 - acc: 0.7546 -- iter: 1024/1668
[A[ATraining Step: 351  | total loss: [1m[32m0.51026[0m[0m | time: 52.297s
[2K
| Adam | epoch: 007 | loss: 0.51026 - acc: 0.7604 -- iter: 1056/1668
[A[ATraining Step: 352  | total loss: [1m[32m0.50716[0m[0m | time: 53.401s
[2K
| Adam | epoch: 007 | loss: 0.50716 - acc: 0.7625 -- iter: 1088/1668
[A[ATraining Step: 353  | total loss: [1m[32m0.49136[0m[0m | time: 54.390s
[2K
| Adam | epoch: 007 | loss: 0.49136 - acc: 0.7769 -- iter: 1120/1668
[A[ATraining Step: 354  | total loss: [1m[32m0.49910[0m[0m | time: 55.692s
[2K
| Adam | epoch: 007 | loss: 0.49910 - acc: 0.7679 -- iter: 1152/1668
[A[ATraining Step: 355  | total loss: [1m[32m0.50220[0m[0m | time: 56.854s
[2K
| Adam | epoch: 007 | loss: 0.50220 - acc: 0.7630 -- iter: 1184/1668
[A[ATraining Step: 356  | total loss: [1m[32m0.49597[0m[0m | time: 58.388s
[2K
| Adam | epoch: 007 | loss: 0.49597 - acc: 0.7680 -- iter: 1216/1668
[A[ATraining Step: 357  | total loss: [1m[32m0.48649[0m[0m | time: 59.803s
[2K
| Adam | epoch: 007 | loss: 0.48649 - acc: 0.7755 -- iter: 1248/1668
[A[ATraining Step: 358  | total loss: [1m[32m0.48025[0m[0m | time: 63.410s
[2K
| Adam | epoch: 007 | loss: 0.48025 - acc: 0.7792 -- iter: 1280/1668
[A[ATraining Step: 359  | total loss: [1m[32m0.47904[0m[0m | time: 66.966s
[2K
| Adam | epoch: 007 | loss: 0.47904 - acc: 0.7826 -- iter: 1312/1668
[A[ATraining Step: 360  | total loss: [1m[32m0.47836[0m[0m | time: 67.804s
[2K
| Adam | epoch: 007 | loss: 0.47836 - acc: 0.7762 -- iter: 1344/1668
[A[ATraining Step: 361  | total loss: [1m[32m0.47786[0m[0m | time: 68.794s
[2K
| Adam | epoch: 007 | loss: 0.47786 - acc: 0.7767 -- iter: 1376/1668
[A[ATraining Step: 362  | total loss: [1m[32m0.48666[0m[0m | time: 69.803s
[2K
| Adam | epoch: 007 | loss: 0.48666 - acc: 0.7678 -- iter: 1408/1668
[A[ATraining Step: 363  | total loss: [1m[32m0.48234[0m[0m | time: 70.792s
[2K
| Adam | epoch: 007 | loss: 0.48234 - acc: 0.7629 -- iter: 1440/1668
[A[ATraining Step: 364  | total loss: [1m[32m0.48322[0m[0m | time: 71.832s
[2K
| Adam | epoch: 007 | loss: 0.48322 - acc: 0.7585 -- iter: 1472/1668
[A[ATraining Step: 365  | total loss: [1m[32m0.47314[0m[0m | time: 72.853s
[2K
| Adam | epoch: 007 | loss: 0.47314 - acc: 0.7639 -- iter: 1504/1668
[A[ATraining Step: 366  | total loss: [1m[32m0.49321[0m[0m | time: 73.907s
[2K
| Adam | epoch: 007 | loss: 0.49321 - acc: 0.7500 -- iter: 1536/1668
[A[ATraining Step: 367  | total loss: [1m[32m0.49159[0m[0m | time: 74.864s
[2K
| Adam | epoch: 007 | loss: 0.49159 - acc: 0.7531 -- iter: 1568/1668
[A[ATraining Step: 368  | total loss: [1m[32m0.50218[0m[0m | time: 76.064s
[2K
| Adam | epoch: 007 | loss: 0.50218 - acc: 0.7434 -- iter: 1600/1668
[A[ATraining Step: 369  | total loss: [1m[32m0.49937[0m[0m | time: 77.093s
[2K
| Adam | epoch: 007 | loss: 0.49937 - acc: 0.7503 -- iter: 1632/1668
[A[ATraining Step: 370  | total loss: [1m[32m0.50021[0m[0m | time: 79.414s
[2K
| Adam | epoch: 007 | loss: 0.50021 - acc: 0.7565 -- iter: 1664/1668
[A[ATraining Step: 371  | total loss: [1m[32m0.48445[0m[0m | time: 102.126s
[2K
| Adam | epoch: 007 | loss: 0.48445 - acc: 0.7715 | val_loss: 0.58679 - val_acc: 0.6954 -- iter: 1668/1668
--
Training Step: 372  | total loss: [1m[32m0.49243[0m[0m | time: 1.034s
[2K
| Adam | epoch: 008 | loss: 0.49243 - acc: 0.7662 -- iter: 0032/1668
[A[ATraining Step: 373  | total loss: [1m[32m0.49777[0m[0m | time: 2.050s
[2K
| Adam | epoch: 008 | loss: 0.49777 - acc: 0.7584 -- iter: 0064/1668
[A[ATraining Step: 374  | total loss: [1m[32m0.51351[0m[0m | time: 3.036s
[2K
| Adam | epoch: 008 | loss: 0.51351 - acc: 0.7325 -- iter: 0096/1668
[A[ATraining Step: 375  | total loss: [1m[32m0.50856[0m[0m | time: 4.106s
[2K
| Adam | epoch: 008 | loss: 0.50856 - acc: 0.7436 -- iter: 0128/1668
[A[ATraining Step: 376  | total loss: [1m[32m0.52498[0m[0m | time: 5.179s
[2K
| Adam | epoch: 008 | loss: 0.52498 - acc: 0.7349 -- iter: 0160/1668
[A[ATraining Step: 377  | total loss: [1m[32m0.52185[0m[0m | time: 5.343s
[2K
| Adam | epoch: 008 | loss: 0.52185 - acc: 0.7395 -- iter: 0192/1668
[A[ATraining Step: 378  | total loss: [1m[32m0.53746[0m[0m | time: 5.528s
[2K
| Adam | epoch: 008 | loss: 0.53746 - acc: 0.7156 -- iter: 0224/1668
[A[ATraining Step: 379  | total loss: [1m[32m0.53601[0m[0m | time: 6.551s
[2K
| Adam | epoch: 008 | loss: 0.53601 - acc: 0.7190 -- iter: 0256/1668
[A[ATraining Step: 380  | total loss: [1m[32m0.54923[0m[0m | time: 7.880s
[2K
| Adam | epoch: 008 | loss: 0.54923 - acc: 0.7128 -- iter: 0288/1668
[A[ATraining Step: 381  | total loss: [1m[32m0.53749[0m[0m | time: 8.933s
[2K
| Adam | epoch: 008 | loss: 0.53749 - acc: 0.7196 -- iter: 0320/1668
[A[ATraining Step: 382  | total loss: [1m[32m0.53704[0m[0m | time: 10.429s
[2K
| Adam | epoch: 008 | loss: 0.53704 - acc: 0.7226 -- iter: 0352/1668
[A[ATraining Step: 383  | total loss: [1m[32m0.53976[0m[0m | time: 14.309s
[2K
| Adam | epoch: 008 | loss: 0.53976 - acc: 0.7254 -- iter: 0384/1668
[A[ATraining Step: 384  | total loss: [1m[32m0.51912[0m[0m | time: 17.199s
[2K
| Adam | epoch: 008 | loss: 0.51912 - acc: 0.7435 -- iter: 0416/1668
[A[ATraining Step: 385  | total loss: [1m[32m0.53924[0m[0m | time: 18.960s
[2K
| Adam | epoch: 008 | loss: 0.53924 - acc: 0.7410 -- iter: 0448/1668
[A[ATraining Step: 386  | total loss: [1m[32m0.52908[0m[0m | time: 22.779s
[2K
| Adam | epoch: 008 | loss: 0.52908 - acc: 0.7419 -- iter: 0480/1668
[A[ATraining Step: 387  | total loss: [1m[32m0.53109[0m[0m | time: 25.319s
[2K
| Adam | epoch: 008 | loss: 0.53109 - acc: 0.7427 -- iter: 0512/1668
[A[ATraining Step: 388  | total loss: [1m[32m0.52840[0m[0m | time: 29.694s
[2K
| Adam | epoch: 008 | loss: 0.52840 - acc: 0.7403 -- iter: 0544/1668
[A[ATraining Step: 389  | total loss: [1m[32m0.51819[0m[0m | time: 31.473s
[2K
| Adam | epoch: 008 | loss: 0.51819 - acc: 0.7413 -- iter: 0576/1668
[A[ATraining Step: 390  | total loss: [1m[32m0.51280[0m[0m | time: 32.459s
[2K
| Adam | epoch: 008 | loss: 0.51280 - acc: 0.7484 -- iter: 0608/1668
[A[ATraining Step: 391  | total loss: [1m[32m0.51811[0m[0m | time: 33.439s
[2K
| Adam | epoch: 008 | loss: 0.51811 - acc: 0.7486 -- iter: 0640/1668
[A[ATraining Step: 392  | total loss: [1m[32m0.51071[0m[0m | time: 34.433s
[2K
| Adam | epoch: 008 | loss: 0.51071 - acc: 0.7487 -- iter: 0672/1668
[A[ATraining Step: 393  | total loss: [1m[32m0.51312[0m[0m | time: 35.397s
[2K
| Adam | epoch: 008 | loss: 0.51312 - acc: 0.7426 -- iter: 0704/1668
[A[ATraining Step: 394  | total loss: [1m[32m0.51899[0m[0m | time: 36.439s
[2K
| Adam | epoch: 008 | loss: 0.51899 - acc: 0.7371 -- iter: 0736/1668
[A[ATraining Step: 395  | total loss: [1m[32m0.52370[0m[0m | time: 37.495s
[2K
| Adam | epoch: 008 | loss: 0.52370 - acc: 0.7321 -- iter: 0768/1668
[A[ATraining Step: 396  | total loss: [1m[32m0.50899[0m[0m | time: 38.437s
[2K
| Adam | epoch: 008 | loss: 0.50899 - acc: 0.7464 -- iter: 0800/1668
[A[ATraining Step: 397  | total loss: [1m[32m0.51932[0m[0m | time: 39.500s
[2K
| Adam | epoch: 008 | loss: 0.51932 - acc: 0.7436 -- iter: 0832/1668
[A[ATraining Step: 398  | total loss: [1m[32m0.51722[0m[0m | time: 40.693s
[2K
| Adam | epoch: 008 | loss: 0.51722 - acc: 0.7443 -- iter: 0864/1668
[A[ATraining Step: 399  | total loss: [1m[32m0.51427[0m[0m | time: 43.267s
[2K
| Adam | epoch: 008 | loss: 0.51427 - acc: 0.7417 -- iter: 0896/1668
[A[ATraining Step: 400  | total loss: [1m[32m0.53254[0m[0m | time: 58.349s
[2K
| Adam | epoch: 008 | loss: 0.53254 - acc: 0.7457 | val_loss: 0.66963 - val_acc: 0.6494 -- iter: 0928/1668
--
Training Step: 401  | total loss: [1m[32m0.53085[0m[0m | time: 59.390s
[2K
| Adam | epoch: 008 | loss: 0.53085 - acc: 0.7430 -- iter: 0960/1668
[A[ATraining Step: 402  | total loss: [1m[32m0.54342[0m[0m | time: 60.503s
[2K
| Adam | epoch: 008 | loss: 0.54342 - acc: 0.7312 -- iter: 0992/1668
[A[ATraining Step: 403  | total loss: [1m[32m0.54202[0m[0m | time: 61.515s
[2K
| Adam | epoch: 008 | loss: 0.54202 - acc: 0.7299 -- iter: 1024/1668
[A[ATraining Step: 404  | total loss: [1m[32m0.51711[0m[0m | time: 62.589s
[2K
| Adam | epoch: 008 | loss: 0.51711 - acc: 0.7538 -- iter: 1056/1668
[A[ATraining Step: 405  | total loss: [1m[32m0.51580[0m[0m | time: 63.689s
[2K
| Adam | epoch: 008 | loss: 0.51580 - acc: 0.7534 -- iter: 1088/1668
[A[ATraining Step: 406  | total loss: [1m[32m0.51575[0m[0m | time: 64.670s
[2K
| Adam | epoch: 008 | loss: 0.51575 - acc: 0.7625 -- iter: 1120/1668
[A[ATraining Step: 407  | total loss: [1m[32m0.51313[0m[0m | time: 65.997s
[2K
| Adam | epoch: 008 | loss: 0.51313 - acc: 0.7643 -- iter: 1152/1668
[A[ATraining Step: 408  | total loss: [1m[32m0.49891[0m[0m | time: 67.106s
[2K
| Adam | epoch: 008 | loss: 0.49891 - acc: 0.7754 -- iter: 1184/1668
[A[ATraining Step: 409  | total loss: [1m[32m0.48613[0m[0m | time: 67.965s
[2K
| Adam | epoch: 008 | loss: 0.48613 - acc: 0.7947 -- iter: 1216/1668
[A[ATraining Step: 410  | total loss: [1m[32m0.48792[0m[0m | time: 73.911s
[2K
| Adam | epoch: 008 | loss: 0.48792 - acc: 0.7934 -- iter: 1248/1668
[A[ATraining Step: 411  | total loss: [1m[32m0.48850[0m[0m | time: 74.868s
[2K
| Adam | epoch: 008 | loss: 0.48850 - acc: 0.7828 -- iter: 1280/1668
[A[ATraining Step: 412  | total loss: [1m[32m0.48420[0m[0m | time: 75.866s
[2K
| Adam | epoch: 008 | loss: 0.48420 - acc: 0.7858 -- iter: 1312/1668
[A[ATraining Step: 413  | total loss: [1m[32m0.49288[0m[0m | time: 76.925s
[2K
| Adam | epoch: 008 | loss: 0.49288 - acc: 0.7791 -- iter: 1344/1668
[A[ATraining Step: 414  | total loss: [1m[32m0.50805[0m[0m | time: 77.952s
[2K
| Adam | epoch: 008 | loss: 0.50805 - acc: 0.7668 -- iter: 1376/1668
[A[ATraining Step: 415  | total loss: [1m[32m0.51038[0m[0m | time: 79.096s
[2K
| Adam | epoch: 008 | loss: 0.51038 - acc: 0.7589 -- iter: 1408/1668
[A[ATraining Step: 416  | total loss: [1m[32m0.49811[0m[0m | time: 80.142s
[2K
| Adam | epoch: 008 | loss: 0.49811 - acc: 0.7705 -- iter: 1440/1668
[A[ATraining Step: 417  | total loss: [1m[32m0.49823[0m[0m | time: 81.095s
[2K
| Adam | epoch: 008 | loss: 0.49823 - acc: 0.7716 -- iter: 1472/1668
[A[ATraining Step: 418  | total loss: [1m[32m0.48003[0m[0m | time: 82.410s
[2K
| Adam | epoch: 008 | loss: 0.48003 - acc: 0.7819 -- iter: 1504/1668
[A[ATraining Step: 419  | total loss: [1m[32m0.48048[0m[0m | time: 83.543s
[2K
| Adam | epoch: 008 | loss: 0.48048 - acc: 0.7756 -- iter: 1536/1668
[A[ATraining Step: 420  | total loss: [1m[32m0.48260[0m[0m | time: 85.893s
[2K
| Adam | epoch: 008 | loss: 0.48260 - acc: 0.7762 -- iter: 1568/1668
[A[ATraining Step: 421  | total loss: [1m[32m0.48197[0m[0m | time: 86.840s
[2K
| Adam | epoch: 008 | loss: 0.48197 - acc: 0.7767 -- iter: 1600/1668
[A[ATraining Step: 422  | total loss: [1m[32m0.48233[0m[0m | time: 87.786s
[2K
| Adam | epoch: 008 | loss: 0.48233 - acc: 0.7740 -- iter: 1632/1668
[A[ATraining Step: 423  | total loss: [1m[32m0.47151[0m[0m | time: 88.768s
[2K
| Adam | epoch: 008 | loss: 0.47151 - acc: 0.7810 -- iter: 1664/1668
[A[ATraining Step: 424  | total loss: [1m[32m0.46831[0m[0m | time: 93.251s
[2K
| Adam | epoch: 008 | loss: 0.46831 - acc: 0.7841 | val_loss: 0.61320 - val_acc: 0.6973 -- iter: 1668/1668
--
Training Step: 425  | total loss: [1m[32m0.47352[0m[0m | time: 1.015s
[2K
| Adam | epoch: 009 | loss: 0.47352 - acc: 0.7838 -- iter: 0032/1668
[A[ATraining Step: 426  | total loss: [1m[32m0.48330[0m[0m | time: 2.142s
[2K
| Adam | epoch: 009 | loss: 0.48330 - acc: 0.7773 -- iter: 0064/1668
[A[ATraining Step: 427  | total loss: [1m[32m0.48696[0m[0m | time: 3.418s
[2K
| Adam | epoch: 009 | loss: 0.48696 - acc: 0.7715 -- iter: 0096/1668
[A[ATraining Step: 428  | total loss: [1m[32m0.47675[0m[0m | time: 4.561s
[2K
| Adam | epoch: 009 | loss: 0.47675 - acc: 0.7818 -- iter: 0128/1668
[A[ATraining Step: 429  | total loss: [1m[32m0.48065[0m[0m | time: 5.753s
[2K
| Adam | epoch: 009 | loss: 0.48065 - acc: 0.7786 -- iter: 0160/1668
[A[ATraining Step: 430  | total loss: [1m[32m0.48438[0m[0m | time: 6.855s
[2K
| Adam | epoch: 009 | loss: 0.48438 - acc: 0.7820 -- iter: 0192/1668
[A[ATraining Step: 431  | total loss: [1m[32m0.47518[0m[0m | time: 7.061s
[2K
| Adam | epoch: 009 | loss: 0.47518 - acc: 0.7913 -- iter: 0224/1668
[A[ATraining Step: 432  | total loss: [1m[32m0.47359[0m[0m | time: 7.291s
[2K
| Adam | epoch: 009 | loss: 0.47359 - acc: 0.7622 -- iter: 0256/1668
[A[ATraining Step: 433  | total loss: [1m[32m0.44463[0m[0m | time: 8.421s
[2K
| Adam | epoch: 009 | loss: 0.44463 - acc: 0.7860 -- iter: 0288/1668
[A[ATraining Step: 434  | total loss: [1m[32m0.50340[0m[0m | time: 9.614s
[2K
| Adam | epoch: 009 | loss: 0.50340 - acc: 0.7574 -- iter: 0320/1668
[A[ATraining Step: 435  | total loss: [1m[32m0.51637[0m[0m | time: 10.735s
[2K
| Adam | epoch: 009 | loss: 0.51637 - acc: 0.7598 -- iter: 0352/1668
[A[ATraining Step: 436  | total loss: [1m[32m0.54443[0m[0m | time: 11.665s
[2K
| Adam | epoch: 009 | loss: 0.54443 - acc: 0.7463 -- iter: 0384/1668
[A[ATraining Step: 437  | total loss: [1m[32m0.52936[0m[0m | time: 12.354s
[2K
| Adam | epoch: 009 | loss: 0.52936 - acc: 0.7560 -- iter: 0416/1668
[A[ATraining Step: 438  | total loss: [1m[32m0.53252[0m[0m | time: 13.066s
[2K
| Adam | epoch: 009 | loss: 0.53252 - acc: 0.7492 -- iter: 0448/1668
[A[ATraining Step: 439  | total loss: [1m[32m0.52776[0m[0m | time: 13.778s
[2K
| Adam | epoch: 009 | loss: 0.52776 - acc: 0.7461 -- iter: 0480/1668
[A[ATraining Step: 440  | total loss: [1m[32m0.53682[0m[0m | time: 14.498s
[2K
| Adam | epoch: 009 | loss: 0.53682 - acc: 0.7340 -- iter: 0512/1668
[A[ATraining Step: 441  | total loss: [1m[32m0.54070[0m[0m | time: 15.189s
[2K
| Adam | epoch: 009 | loss: 0.54070 - acc: 0.7262 -- iter: 0544/1668
[A[ATraining Step: 442  | total loss: [1m[32m0.54658[0m[0m | time: 15.912s
[2K
| Adam | epoch: 009 | loss: 0.54658 - acc: 0.7161 -- iter: 0576/1668
[A[ATraining Step: 443  | total loss: [1m[32m0.53853[0m[0m | time: 16.607s
[2K
| Adam | epoch: 009 | loss: 0.53853 - acc: 0.7258 -- iter: 0608/1668
[A[ATraining Step: 444  | total loss: [1m[32m0.53086[0m[0m | time: 17.314s
[2K
| Adam | epoch: 009 | loss: 0.53086 - acc: 0.7344 -- iter: 0640/1668
[A[ATraining Step: 445  | total loss: [1m[32m0.51814[0m[0m | time: 17.994s
[2K
| Adam | epoch: 009 | loss: 0.51814 - acc: 0.7454 -- iter: 0672/1668
[A[ATraining Step: 446  | total loss: [1m[32m0.50447[0m[0m | time: 18.662s
[2K
| Adam | epoch: 009 | loss: 0.50447 - acc: 0.7615 -- iter: 0704/1668
[A[ATraining Step: 447  | total loss: [1m[32m0.49511[0m[0m | time: 19.359s
[2K
| Adam | epoch: 009 | loss: 0.49511 - acc: 0.7666 -- iter: 0736/1668
[A[ATraining Step: 448  | total loss: [1m[32m0.49659[0m[0m | time: 20.067s
[2K
| Adam | epoch: 009 | loss: 0.49659 - acc: 0.7680 -- iter: 0768/1668
[A[ATraining Step: 449  | total loss: [1m[32m0.50313[0m[0m | time: 20.760s
[2K
| Adam | epoch: 009 | loss: 0.50313 - acc: 0.7631 -- iter: 0800/1668
[A[ATraining Step: 450  | total loss: [1m[32m0.50628[0m[0m | time: 21.415s
[2K
| Adam | epoch: 009 | loss: 0.50628 - acc: 0.7618 -- iter: 0832/1668
[A[ATraining Step: 451  | total loss: [1m[32m0.49543[0m[0m | time: 22.107s
[2K
| Adam | epoch: 009 | loss: 0.49543 - acc: 0.7731 -- iter: 0864/1668
[A[ATraining Step: 452  | total loss: [1m[32m0.48069[0m[0m | time: 22.820s
[2K
| Adam | epoch: 009 | loss: 0.48069 - acc: 0.7802 -- iter: 0896/1668
[A[ATraining Step: 453  | total loss: [1m[32m0.47658[0m[0m | time: 23.509s
[2K
| Adam | epoch: 009 | loss: 0.47658 - acc: 0.7834 -- iter: 0928/1668
[A[ATraining Step: 454  | total loss: [1m[32m0.47818[0m[0m | time: 24.192s
[2K
| Adam | epoch: 009 | loss: 0.47818 - acc: 0.7801 -- iter: 0960/1668
[A[ATraining Step: 455  | total loss: [1m[32m0.49358[0m[0m | time: 24.932s
[2K
| Adam | epoch: 009 | loss: 0.49358 - acc: 0.7739 -- iter: 0992/1668
[A[ATraining Step: 456  | total loss: [1m[32m0.48051[0m[0m | time: 25.618s
[2K
| Adam | epoch: 009 | loss: 0.48051 - acc: 0.7872 -- iter: 1024/1668
[A[ATraining Step: 457  | total loss: [1m[32m0.47493[0m[0m | time: 26.289s
[2K
| Adam | epoch: 009 | loss: 0.47493 - acc: 0.7928 -- iter: 1056/1668
[A[ATraining Step: 458  | total loss: [1m[32m0.47283[0m[0m | time: 26.974s
[2K
| Adam | epoch: 009 | loss: 0.47283 - acc: 0.7917 -- iter: 1088/1668
[A[ATraining Step: 459  | total loss: [1m[32m0.46431[0m[0m | time: 27.677s
[2K
| Adam | epoch: 009 | loss: 0.46431 - acc: 0.7969 -- iter: 1120/1668
[A[ATraining Step: 460  | total loss: [1m[32m0.45389[0m[0m | time: 28.344s
[2K
| Adam | epoch: 009 | loss: 0.45389 - acc: 0.8047 -- iter: 1152/1668
[A[ATraining Step: 461  | total loss: [1m[32m0.44188[0m[0m | time: 29.047s
[2K
| Adam | epoch: 009 | loss: 0.44188 - acc: 0.8086 -- iter: 1184/1668
[A[ATraining Step: 462  | total loss: [1m[32m0.45345[0m[0m | time: 29.754s
[2K
| Adam | epoch: 009 | loss: 0.45345 - acc: 0.7965 -- iter: 1216/1668
[A[ATraining Step: 463  | total loss: [1m[32m0.43410[0m[0m | time: 30.569s
[2K
| Adam | epoch: 009 | loss: 0.43410 - acc: 0.8075 -- iter: 1248/1668
[A[ATraining Step: 464  | total loss: [1m[32m0.42467[0m[0m | time: 31.466s
[2K
| Adam | epoch: 009 | loss: 0.42467 - acc: 0.8173 -- iter: 1280/1668
[A[ATraining Step: 465  | total loss: [1m[32m0.43046[0m[0m | time: 32.387s
[2K
| Adam | epoch: 009 | loss: 0.43046 - acc: 0.8137 -- iter: 1312/1668
[A[ATraining Step: 466  | total loss: [1m[32m0.43703[0m[0m | time: 33.337s
[2K
| Adam | epoch: 009 | loss: 0.43703 - acc: 0.8105 -- iter: 1344/1668
[A[ATraining Step: 467  | total loss: [1m[32m0.44098[0m[0m | time: 34.223s
[2K
| Adam | epoch: 009 | loss: 0.44098 - acc: 0.8013 -- iter: 1376/1668
[A[ATraining Step: 468  | total loss: [1m[32m0.42656[0m[0m | time: 35.110s
[2K
| Adam | epoch: 009 | loss: 0.42656 - acc: 0.8118 -- iter: 1408/1668
[A[ATraining Step: 469  | total loss: [1m[32m0.41240[0m[0m | time: 36.078s
[2K
| Adam | epoch: 009 | loss: 0.41240 - acc: 0.8212 -- iter: 1440/1668
[A[ATraining Step: 470  | total loss: [1m[32m0.41044[0m[0m | time: 37.391s
[2K
| Adam | epoch: 009 | loss: 0.41044 - acc: 0.8172 -- iter: 1472/1668
[A[ATraining Step: 471  | total loss: [1m[32m0.41284[0m[0m | time: 38.542s
[2K
| Adam | epoch: 009 | loss: 0.41284 - acc: 0.8105 -- iter: 1504/1668
[A[ATraining Step: 472  | total loss: [1m[32m0.40682[0m[0m | time: 39.671s
[2K
| Adam | epoch: 009 | loss: 0.40682 - acc: 0.8107 -- iter: 1536/1668
[A[ATraining Step: 473  | total loss: [1m[32m0.40134[0m[0m | time: 40.603s
[2K
| Adam | epoch: 009 | loss: 0.40134 - acc: 0.8140 -- iter: 1568/1668
[A[ATraining Step: 474  | total loss: [1m[32m0.40850[0m[0m | time: 41.593s
[2K
| Adam | epoch: 009 | loss: 0.40850 - acc: 0.8045 -- iter: 1600/1668
[A[ATraining Step: 475  | total loss: [1m[32m0.42615[0m[0m | time: 42.605s
[2K
| Adam | epoch: 009 | loss: 0.42615 - acc: 0.7897 -- iter: 1632/1668
[A[ATraining Step: 476  | total loss: [1m[32m0.42479[0m[0m | time: 43.642s
[2K
| Adam | epoch: 009 | loss: 0.42479 - acc: 0.7888 -- iter: 1664/1668
[A[ATraining Step: 477  | total loss: [1m[32m0.41591[0m[0m | time: 48.009s
[2K
| Adam | epoch: 009 | loss: 0.41591 - acc: 0.7974 | val_loss: 0.67145 - val_acc: 0.6762 -- iter: 1668/1668
--
Training Step: 478  | total loss: [1m[32m0.41187[0m[0m | time: 1.229s
[2K
| Adam | epoch: 010 | loss: 0.41187 - acc: 0.8021 -- iter: 0032/1668
[A[ATraining Step: 479  | total loss: [1m[32m0.42420[0m[0m | time: 3.977s
[2K
| Adam | epoch: 010 | loss: 0.42420 - acc: 0.7937 -- iter: 0064/1668
[A[ATraining Step: 480  | total loss: [1m[32m0.42866[0m[0m | time: 7.582s
[2K
| Adam | epoch: 010 | loss: 0.42866 - acc: 0.7894 -- iter: 0096/1668
[A[ATraining Step: 481  | total loss: [1m[32m0.41825[0m[0m | time: 10.406s
[2K
| Adam | epoch: 010 | loss: 0.41825 - acc: 0.8011 -- iter: 0128/1668
[A[ATraining Step: 482  | total loss: [1m[32m0.42484[0m[0m | time: 13.369s
[2K
| Adam | epoch: 010 | loss: 0.42484 - acc: 0.7960 -- iter: 0160/1668
[A[ATraining Step: 483  | total loss: [1m[32m0.41656[0m[0m | time: 15.459s
[2K
| Adam | epoch: 010 | loss: 0.41656 - acc: 0.8007 -- iter: 0192/1668
[A[ATraining Step: 484  | total loss: [1m[32m0.42122[0m[0m | time: 18.484s
[2K
| Adam | epoch: 010 | loss: 0.42122 - acc: 0.8019 -- iter: 0224/1668
[A[ATraining Step: 485  | total loss: [1m[32m0.42538[0m[0m | time: 18.919s
[2K
| Adam | epoch: 010 | loss: 0.42538 - acc: 0.7998 -- iter: 0256/1668
[A[ATraining Step: 486  | total loss: [1m[32m0.41510[0m[0m | time: 19.041s
[2K
| Adam | epoch: 010 | loss: 0.41510 - acc: 0.8199 -- iter: 0288/1668
[A[ATraining Step: 487  | total loss: [1m[32m0.39889[0m[0m | time: 21.124s
[2K
| Adam | epoch: 010 | loss: 0.39889 - acc: 0.8379 -- iter: 0320/1668
[A[ATraining Step: 488  | total loss: [1m[32m0.39601[0m[0m | time: 22.086s
[2K
| Adam | epoch: 010 | loss: 0.39601 - acc: 0.8447 -- iter: 0352/1668
[A[ATraining Step: 489  | total loss: [1m[32m0.40204[0m[0m | time: 23.174s
[2K
| Adam | epoch: 010 | loss: 0.40204 - acc: 0.8352 -- iter: 0384/1668
[A[ATraining Step: 490  | total loss: [1m[32m0.40771[0m[0m | time: 24.174s
[2K
| Adam | epoch: 010 | loss: 0.40771 - acc: 0.8267 -- iter: 0416/1668
[A[ATraining Step: 491  | total loss: [1m[32m0.41058[0m[0m | time: 25.220s
[2K
| Adam | epoch: 010 | loss: 0.41058 - acc: 0.8253 -- iter: 0448/1668
[A[ATraining Step: 492  | total loss: [1m[32m0.39736[0m[0m | time: 26.286s
[2K
| Adam | epoch: 010 | loss: 0.39736 - acc: 0.8334 -- iter: 0480/1668
[A[ATraining Step: 493  | total loss: [1m[32m0.40753[0m[0m | time: 27.354s
[2K
| Adam | epoch: 010 | loss: 0.40753 - acc: 0.8188 -- iter: 0512/1668
[A[ATraining Step: 494  | total loss: [1m[32m0.40703[0m[0m | time: 28.287s
[2K
| Adam | epoch: 010 | loss: 0.40703 - acc: 0.8119 -- iter: 0544/1668
[A[ATraining Step: 495  | total loss: [1m[32m0.39818[0m[0m | time: 29.556s
[2K
| Adam | epoch: 010 | loss: 0.39818 - acc: 0.8182 -- iter: 0576/1668
[A[ATraining Step: 496  | total loss: [1m[32m0.39230[0m[0m | time: 30.611s
[2K
| Adam | epoch: 010 | loss: 0.39230 - acc: 0.8208 -- iter: 0608/1668
[A[ATraining Step: 497  | total loss: [1m[32m0.40587[0m[0m | time: 31.552s
[2K
| Adam | epoch: 010 | loss: 0.40587 - acc: 0.8106 -- iter: 0640/1668
[A[ATraining Step: 498  | total loss: [1m[32m0.39896[0m[0m | time: 37.263s
[2K
| Adam | epoch: 010 | loss: 0.39896 - acc: 0.8170 -- iter: 0672/1668
[A[ATraining Step: 499  | total loss: [1m[32m0.41734[0m[0m | time: 42.453s
[2K
| Adam | epoch: 010 | loss: 0.41734 - acc: 0.8009 -- iter: 0704/1668
[A[ATraining Step: 500  | total loss: [1m[32m0.40557[0m[0m | time: 44.951s
[2K
| Adam | epoch: 010 | loss: 0.40557 - acc: 0.8052 -- iter: 0736/1668
[A[ATraining Step: 501  | total loss: [1m[32m0.40518[0m[0m | time: 48.176s
[2K
| Adam | epoch: 010 | loss: 0.40518 - acc: 0.8122 -- iter: 0768/1668
[A[ATraining Step: 502  | total loss: [1m[32m0.40185[0m[0m | time: 51.534s
[2K
| Adam | epoch: 010 | loss: 0.40185 - acc: 0.8216 -- iter: 0800/1668
[A[ATraining Step: 503  | total loss: [1m[32m0.39557[0m[0m | time: 55.697s
[2K
| Adam | epoch: 010 | loss: 0.39557 - acc: 0.8207 -- iter: 0832/1668
[A[ATraining Step: 504  | total loss: [1m[32m0.38218[0m[0m | time: 57.835s
[2K
| Adam | epoch: 010 | loss: 0.38218 - acc: 0.8293 -- iter: 0864/1668
[A[ATraining Step: 505  | total loss: [1m[32m0.37668[0m[0m | time: 60.792s
[2K
| Adam | epoch: 010 | loss: 0.37668 - acc: 0.8338 -- iter: 0896/1668
[A[ATraining Step: 506  | total loss: [1m[32m0.39033[0m[0m | time: 63.419s
[2K
| Adam | epoch: 010 | loss: 0.39033 - acc: 0.8286 -- iter: 0928/1668
[A[ATraining Step: 507  | total loss: [1m[32m0.37377[0m[0m | time: 65.796s
[2K
| Adam | epoch: 010 | loss: 0.37377 - acc: 0.8363 -- iter: 0960/1668
[A[ATraining Step: 508  | total loss: [1m[32m0.37435[0m[0m | time: 66.602s
[2K
| Adam | epoch: 010 | loss: 0.37435 - acc: 0.8371 -- iter: 0992/1668
[A[ATraining Step: 509  | total loss: [1m[32m0.35709[0m[0m | time: 67.600s
[2K
| Adam | epoch: 010 | loss: 0.35709 - acc: 0.8440 -- iter: 1024/1668
[A[ATraining Step: 510  | total loss: [1m[32m0.37504[0m[0m | time: 68.571s
[2K
| Adam | epoch: 010 | loss: 0.37504 - acc: 0.8346 -- iter: 1056/1668
[A[ATraining Step: 511  | total loss: [1m[32m0.38010[0m[0m | time: 69.604s
[2K
| Adam | epoch: 010 | loss: 0.38010 - acc: 0.8293 -- iter: 1088/1668
[A[ATraining Step: 512  | total loss: [1m[32m0.37098[0m[0m | time: 70.615s
[2K
| Adam | epoch: 010 | loss: 0.37098 - acc: 0.8307 -- iter: 1120/1668
[A[ATraining Step: 513  | total loss: [1m[32m0.36251[0m[0m | time: 71.764s
[2K
| Adam | epoch: 010 | loss: 0.36251 - acc: 0.8351 -- iter: 1152/1668
[A[ATraining Step: 514  | total loss: [1m[32m0.34808[0m[0m | time: 72.860s
[2K
| Adam | epoch: 010 | loss: 0.34808 - acc: 0.8391 -- iter: 1184/1668
[A[ATraining Step: 515  | total loss: [1m[32m0.33830[0m[0m | time: 73.843s
[2K
| Adam | epoch: 010 | loss: 0.33830 - acc: 0.8427 -- iter: 1216/1668
[A[ATraining Step: 516  | total loss: [1m[32m0.32230[0m[0m | time: 75.138s
[2K
| Adam | epoch: 010 | loss: 0.32230 - acc: 0.8522 -- iter: 1248/1668
[A[ATraining Step: 517  | total loss: [1m[32m0.33504[0m[0m | time: 82.934s
[2K
| Adam | epoch: 010 | loss: 0.33504 - acc: 0.8482 -- iter: 1280/1668
[A[ATraining Step: 518  | total loss: [1m[32m0.32591[0m[0m | time: 87.718s
[2K
| Adam | epoch: 010 | loss: 0.32591 - acc: 0.8571 -- iter: 1312/1668
[A[ATraining Step: 519  | total loss: [1m[32m0.33777[0m[0m | time: 92.096s
[2K
| Adam | epoch: 010 | loss: 0.33777 - acc: 0.8464 -- iter: 1344/1668
[A[ATraining Step: 520  | total loss: [1m[32m0.35068[0m[0m | time: 96.959s
[2K
| Adam | epoch: 010 | loss: 0.35068 - acc: 0.8399 -- iter: 1376/1668
[A[ATraining Step: 521  | total loss: [1m[32m0.34782[0m[0m | time: 97.990s
[2K
| Adam | epoch: 010 | loss: 0.34782 - acc: 0.8372 -- iter: 1408/1668
[A[ATraining Step: 522  | total loss: [1m[32m0.34609[0m[0m | time: 102.442s
[2K
| Adam | epoch: 010 | loss: 0.34609 - acc: 0.8378 -- iter: 1440/1668
[A[ATraining Step: 523  | total loss: [1m[32m0.32814[0m[0m | time: 106.095s
[2K
| Adam | epoch: 010 | loss: 0.32814 - acc: 0.8509 -- iter: 1472/1668
[A[ATraining Step: 524  | total loss: [1m[32m0.32019[0m[0m | time: 113.398s
[2K
| Adam | epoch: 010 | loss: 0.32019 - acc: 0.8596 -- iter: 1504/1668
[A[ATraining Step: 525  | total loss: [1m[32m0.31216[0m[0m | time: 120.294s
[2K
| Adam | epoch: 010 | loss: 0.31216 - acc: 0.8705 -- iter: 1536/1668
[A[ATraining Step: 526  | total loss: [1m[32m0.30336[0m[0m | time: 123.643s
[2K
| Adam | epoch: 010 | loss: 0.30336 - acc: 0.8741 -- iter: 1568/1668
[A[ATraining Step: 527  | total loss: [1m[32m0.30991[0m[0m | time: 127.628s
[2K
| Adam | epoch: 010 | loss: 0.30991 - acc: 0.8710 -- iter: 1600/1668
[A[ATraining Step: 528  | total loss: [1m[32m0.30579[0m[0m | time: 131.134s
[2K
| Adam | epoch: 010 | loss: 0.30579 - acc: 0.8683 -- iter: 1632/1668
[A[ATraining Step: 529  | total loss: [1m[32m0.30635[0m[0m | time: 133.765s
[2K
| Adam | epoch: 010 | loss: 0.30635 - acc: 0.8721 -- iter: 1664/1668
[A[ATraining Step: 530  | total loss: [1m[32m0.30741[0m[0m | time: 143.014s
[2K
| Adam | epoch: 010 | loss: 0.30741 - acc: 0.8786 | val_loss: 0.76252 - val_acc: 0.6762 -- iter: 1668/1668
--
Training Step: 531  | total loss: [1m[32m0.32279[0m[0m | time: 0.967s
[2K
| Adam | epoch: 011 | loss: 0.32279 - acc: 0.8689 -- iter: 0032/1668
[A[ATraining Step: 532  | total loss: [1m[32m0.32680[0m[0m | time: 1.909s
[2K
| Adam | epoch: 011 | loss: 0.32680 - acc: 0.8695 -- iter: 0064/1668
[A[ATraining Step: 533  | total loss: [1m[32m0.34742[0m[0m | time: 2.908s
[2K
| Adam | epoch: 011 | loss: 0.34742 - acc: 0.8544 -- iter: 0096/1668
[A[ATraining Step: 534  | total loss: [1m[32m0.37136[0m[0m | time: 3.971s
[2K
| Adam | epoch: 011 | loss: 0.37136 - acc: 0.8409 -- iter: 0128/1668
[A[ATraining Step: 535  | total loss: [1m[32m0.35527[0m[0m | time: 4.998s
[2K
| Adam | epoch: 011 | loss: 0.35527 - acc: 0.8505 -- iter: 0160/1668
[A[ATraining Step: 536  | total loss: [1m[32m0.35725[0m[0m | time: 5.913s
[2K
| Adam | epoch: 011 | loss: 0.35725 - acc: 0.8499 -- iter: 0192/1668
[A[ATraining Step: 537  | total loss: [1m[32m0.35647[0m[0m | time: 6.982s
[2K
| Adam | epoch: 011 | loss: 0.35647 - acc: 0.8524 -- iter: 0224/1668
[A[ATraining Step: 538  | total loss: [1m[32m0.34880[0m[0m | time: 8.162s
[2K
| Adam | epoch: 011 | loss: 0.34880 - acc: 0.8515 -- iter: 0256/1668
[A[ATraining Step: 539  | total loss: [1m[32m0.35418[0m[0m | time: 8.357s
[2K
| Adam | epoch: 011 | loss: 0.35418 - acc: 0.8445 -- iter: 0288/1668
[A[ATraining Step: 540  | total loss: [1m[32m0.33947[0m[0m | time: 8.566s
[2K
| Adam | epoch: 011 | loss: 0.33947 - acc: 0.8600 -- iter: 0320/1668
[A[ATraining Step: 541  | total loss: [1m[32m0.31691[0m[0m | time: 14.283s
[2K
| Adam | epoch: 011 | loss: 0.31691 - acc: 0.8740 -- iter: 0352/1668
[A[ATraining Step: 542  | total loss: [1m[32m0.30841[0m[0m | time: 18.496s
[2K
| Adam | epoch: 011 | loss: 0.30841 - acc: 0.8710 -- iter: 0384/1668
[A[ATraining Step: 543  | total loss: [1m[32m0.30897[0m[0m | time: 21.006s
[2K
| Adam | epoch: 011 | loss: 0.30897 - acc: 0.8652 -- iter: 0416/1668
[A[ATraining Step: 544  | total loss: [1m[32m0.30996[0m[0m | time: 22.995s
[2K
| Adam | epoch: 011 | loss: 0.30996 - acc: 0.8661 -- iter: 0448/1668
[A[ATraining Step: 545  | total loss: [1m[32m0.30269[0m[0m | time: 25.312s
[2K
| Adam | epoch: 011 | loss: 0.30269 - acc: 0.8701 -- iter: 0480/1668
[A[ATraining Step: 546  | total loss: [1m[32m0.32177[0m[0m | time: 27.918s
[2K
| Adam | epoch: 011 | loss: 0.32177 - acc: 0.8581 -- iter: 0512/1668
[A[ATraining Step: 547  | total loss: [1m[32m0.33945[0m[0m | time: 28.727s
[2K
| Adam | epoch: 011 | loss: 0.33945 - acc: 0.8504 -- iter: 0544/1668
[A[ATraining Step: 548  | total loss: [1m[32m0.35221[0m[0m | time: 29.701s
[2K
| Adam | epoch: 011 | loss: 0.35221 - acc: 0.8435 -- iter: 0576/1668
[A[ATraining Step: 549  | total loss: [1m[32m0.34051[0m[0m | time: 30.614s
[2K
| Adam | epoch: 011 | loss: 0.34051 - acc: 0.8498 -- iter: 0608/1668
[A[ATraining Step: 550  | total loss: [1m[32m0.35220[0m[0m | time: 31.553s
[2K
| Adam | epoch: 011 | loss: 0.35220 - acc: 0.8492 -- iter: 0640/1668
[A[ATraining Step: 551  | total loss: [1m[32m0.33778[0m[0m | time: 32.575s
[2K
| Adam | epoch: 011 | loss: 0.33778 - acc: 0.8611 -- iter: 0672/1668
[A[ATraining Step: 552  | total loss: [1m[32m0.36352[0m[0m | time: 33.667s
[2K
| Adam | epoch: 011 | loss: 0.36352 - acc: 0.8500 -- iter: 0704/1668
[A[ATraining Step: 553  | total loss: [1m[32m0.38975[0m[0m | time: 34.754s
[2K
| Adam | epoch: 011 | loss: 0.38975 - acc: 0.8369 -- iter: 0736/1668
[A[ATraining Step: 554  | total loss: [1m[32m0.42984[0m[0m | time: 35.752s
[2K
| Adam | epoch: 011 | loss: 0.42984 - acc: 0.8188 -- iter: 0768/1668
[A[ATraining Step: 555  | total loss: [1m[32m0.43918[0m[0m | time: 36.750s
[2K
| Adam | epoch: 011 | loss: 0.43918 - acc: 0.8088 -- iter: 0800/1668
[A[ATraining Step: 556  | total loss: [1m[32m0.43332[0m[0m | time: 37.996s
[2K
| Adam | epoch: 011 | loss: 0.43332 - acc: 0.8123 -- iter: 0832/1668
[A[ATraining Step: 557  | total loss: [1m[32m0.41839[0m[0m | time: 39.073s
[2K
| Adam | epoch: 011 | loss: 0.41839 - acc: 0.8217 -- iter: 0864/1668
[A[ATraining Step: 558  | total loss: [1m[32m0.41328[0m[0m | time: 41.795s
[2K
| Adam | epoch: 011 | loss: 0.41328 - acc: 0.8177 -- iter: 0896/1668
[A[ATraining Step: 559  | total loss: [1m[32m0.41742[0m[0m | time: 44.059s
[2K
| Adam | epoch: 011 | loss: 0.41742 - acc: 0.8140 -- iter: 0928/1668
[A[ATraining Step: 560  | total loss: [1m[32m0.41058[0m[0m | time: 45.000s
[2K
| Adam | epoch: 011 | loss: 0.41058 - acc: 0.8139 -- iter: 0960/1668
[A[ATraining Step: 561  | total loss: [1m[32m0.39857[0m[0m | time: 46.017s
[2K
| Adam | epoch: 011 | loss: 0.39857 - acc: 0.8231 -- iter: 0992/1668
[A[ATraining Step: 562  | total loss: [1m[32m0.39930[0m[0m | time: 47.013s
[2K
| Adam | epoch: 011 | loss: 0.39930 - acc: 0.8314 -- iter: 1024/1668
[A[ATraining Step: 563  | total loss: [1m[32m0.38585[0m[0m | time: 48.027s
[2K
| Adam | epoch: 011 | loss: 0.38585 - acc: 0.8420 -- iter: 1056/1668
[A[ATraining Step: 564  | total loss: [1m[32m0.37378[0m[0m | time: 49.143s
[2K
| Adam | epoch: 011 | loss: 0.37378 - acc: 0.8516 -- iter: 1088/1668
[A[ATraining Step: 565  | total loss: [1m[32m0.36306[0m[0m | time: 50.200s
[2K
| Adam | epoch: 011 | loss: 0.36306 - acc: 0.8602 -- iter: 1120/1668
[A[ATraining Step: 566  | total loss: [1m[32m0.34996[0m[0m | time: 51.138s
[2K
| Adam | epoch: 011 | loss: 0.34996 - acc: 0.8648 -- iter: 1152/1668
[A[ATraining Step: 567  | total loss: [1m[32m0.34139[0m[0m | time: 52.283s
[2K
| Adam | epoch: 011 | loss: 0.34139 - acc: 0.8752 -- iter: 1184/1668
[A[ATraining Step: 568  | total loss: [1m[32m0.32739[0m[0m | time: 53.402s
[2K
| Adam | epoch: 011 | loss: 0.32739 - acc: 0.8845 -- iter: 1216/1668
[A[ATraining Step: 569  | total loss: [1m[32m0.32322[0m[0m | time: 54.380s
[2K
| Adam | epoch: 011 | loss: 0.32322 - acc: 0.8836 -- iter: 1248/1668
[A[ATraining Step: 570  | total loss: [1m[32m0.32222[0m[0m | time: 55.331s
[2K
| Adam | epoch: 011 | loss: 0.32222 - acc: 0.8796 -- iter: 1280/1668
[A[ATraining Step: 571  | total loss: [1m[32m0.30676[0m[0m | time: 56.299s
[2K
| Adam | epoch: 011 | loss: 0.30676 - acc: 0.8916 -- iter: 1312/1668
[A[ATraining Step: 572  | total loss: [1m[32m0.29782[0m[0m | time: 57.300s
[2K
| Adam | epoch: 011 | loss: 0.29782 - acc: 0.8931 -- iter: 1344/1668
[A[ATraining Step: 573  | total loss: [1m[32m0.27659[0m[0m | time: 58.277s
[2K
| Adam | epoch: 011 | loss: 0.27659 - acc: 0.9038 -- iter: 1376/1668
[A[ATraining Step: 574  | total loss: [1m[32m0.27159[0m[0m | time: 59.334s
[2K
| Adam | epoch: 011 | loss: 0.27159 - acc: 0.9072 -- iter: 1408/1668
[A[ATraining Step: 575  | total loss: [1m[32m0.27015[0m[0m | time: 60.363s
[2K
| Adam | epoch: 011 | loss: 0.27015 - acc: 0.9102 -- iter: 1440/1668
[A[ATraining Step: 576  | total loss: [1m[32m0.26638[0m[0m | time: 61.385s
[2K
| Adam | epoch: 011 | loss: 0.26638 - acc: 0.9098 -- iter: 1472/1668
[A[ATraining Step: 577  | total loss: [1m[32m0.28434[0m[0m | time: 62.387s
[2K
| Adam | epoch: 011 | loss: 0.28434 - acc: 0.8969 -- iter: 1504/1668
[A[ATraining Step: 578  | total loss: [1m[32m0.28047[0m[0m | time: 63.572s
[2K
| Adam | epoch: 011 | loss: 0.28047 - acc: 0.8916 -- iter: 1536/1668
[A[ATraining Step: 579  | total loss: [1m[32m0.27319[0m[0m | time: 64.826s
[2K
| Adam | epoch: 011 | loss: 0.27319 - acc: 0.8931 -- iter: 1568/1668
[A[ATraining Step: 580  | total loss: [1m[32m0.26485[0m[0m | time: 66.491s
[2K
| Adam | epoch: 011 | loss: 0.26485 - acc: 0.8975 -- iter: 1600/1668
[A[ATraining Step: 581  | total loss: [1m[32m0.26390[0m[0m | time: 68.673s
[2K
| Adam | epoch: 011 | loss: 0.26390 - acc: 0.8922 -- iter: 1632/1668
[A[ATraining Step: 582  | total loss: [1m[32m0.25818[0m[0m | time: 70.983s
[2K
| Adam | epoch: 011 | loss: 0.25818 - acc: 0.8936 -- iter: 1664/1668
[A[ATraining Step: 583  | total loss: [1m[32m0.26459[0m[0m | time: 75.000s
[2K
| Adam | epoch: 011 | loss: 0.26459 - acc: 0.8948 | val_loss: 0.64773 - val_acc: 0.7280 -- iter: 1668/1668
--
Training Step: 584  | total loss: [1m[32m0.25381[0m[0m | time: 1.027s
[2K
| Adam | epoch: 012 | loss: 0.25381 - acc: 0.8991 -- iter: 0032/1668
[A[ATraining Step: 585  | total loss: [1m[32m0.24856[0m[0m | time: 2.102s
[2K
| Adam | epoch: 012 | loss: 0.24856 - acc: 0.8998 -- iter: 0064/1668
[A[ATraining Step: 586  | total loss: [1m[32m0.23935[0m[0m | time: 3.177s
[2K
| Adam | epoch: 012 | loss: 0.23935 - acc: 0.9036 -- iter: 0096/1668
[A[ATraining Step: 587  | total loss: [1m[32m0.24615[0m[0m | time: 4.114s
[2K
| Adam | epoch: 012 | loss: 0.24615 - acc: 0.9038 -- iter: 0128/1668
[A[ATraining Step: 588  | total loss: [1m[32m0.24120[0m[0m | time: 5.292s
[2K
| Adam | epoch: 012 | loss: 0.24120 - acc: 0.9072 -- iter: 0160/1668
[A[ATraining Step: 589  | total loss: [1m[32m0.23086[0m[0m | time: 6.411s
[2K
| Adam | epoch: 012 | loss: 0.23086 - acc: 0.9102 -- iter: 0192/1668
[A[ATraining Step: 590  | total loss: [1m[32m0.24142[0m[0m | time: 12.188s
[2K
| Adam | epoch: 012 | loss: 0.24142 - acc: 0.9067 -- iter: 0224/1668
[A[ATraining Step: 591  | total loss: [1m[32m0.24791[0m[0m | time: 16.811s
[2K
| Adam | epoch: 012 | loss: 0.24791 - acc: 0.9035 -- iter: 0256/1668
[A[ATraining Step: 592  | total loss: [1m[32m0.26454[0m[0m | time: 20.496s
[2K
| Adam | epoch: 012 | loss: 0.26454 - acc: 0.9007 -- iter: 0288/1668
[A[ATraining Step: 593  | total loss: [1m[32m0.27734[0m[0m | time: 20.864s
[2K
| Adam | epoch: 012 | loss: 0.27734 - acc: 0.8919 -- iter: 0320/1668
[A[ATraining Step: 594  | total loss: [1m[32m0.36039[0m[0m | time: 21.034s
[2K
| Adam | epoch: 012 | loss: 0.36039 - acc: 0.8527 -- iter: 0352/1668
[A[ATraining Step: 595  | total loss: [1m[32m0.40687[0m[0m | time: 22.969s
[2K
| Adam | epoch: 012 | loss: 0.40687 - acc: 0.8174 -- iter: 0384/1668
[A[ATraining Step: 596  | total loss: [1m[32m0.39742[0m[0m | time: 25.160s
[2K
| Adam | epoch: 012 | loss: 0.39742 - acc: 0.8169 -- iter: 0416/1668
[A[ATraining Step: 597  | total loss: [1m[32m0.37690[0m[0m | time: 28.581s
[2K
| Adam | epoch: 012 | loss: 0.37690 - acc: 0.8321 -- iter: 0448/1668
[A[ATraining Step: 598  | total loss: [1m[32m0.36480[0m[0m | time: 30.939s
[2K
| Adam | epoch: 012 | loss: 0.36480 - acc: 0.8426 -- iter: 0480/1668
[A[ATraining Step: 599  | total loss: [1m[32m0.37299[0m[0m | time: 31.759s
[2K
| Adam | epoch: 012 | loss: 0.37299 - acc: 0.8396 -- iter: 0512/1668
[A[ATraining Step: 600  | total loss: [1m[32m0.37957[0m[0m | time: 35.810s
[2K
| Adam | epoch: 012 | loss: 0.37957 - acc: 0.8338 | val_loss: 0.60033 - val_acc: 0.7011 -- iter: 0544/1668
--
Training Step: 601  | total loss: [1m[32m0.36857[0m[0m | time: 36.889s
[2K
| Adam | epoch: 012 | loss: 0.36857 - acc: 0.8442 -- iter: 0576/1668
[A[ATraining Step: 602  | total loss: [1m[32m0.36507[0m[0m | time: 38.030s
[2K
| Adam | epoch: 012 | loss: 0.36507 - acc: 0.8504 -- iter: 0608/1668
[A[ATraining Step: 603  | total loss: [1m[32m0.34773[0m[0m | time: 39.010s
[2K
| Adam | epoch: 012 | loss: 0.34773 - acc: 0.8653 -- iter: 0640/1668
[A[ATraining Step: 604  | total loss: [1m[32m0.32993[0m[0m | time: 40.118s
[2K
| Adam | epoch: 012 | loss: 0.32993 - acc: 0.8726 -- iter: 0672/1668
[A[ATraining Step: 605  | total loss: [1m[32m0.35047[0m[0m | time: 41.354s
[2K
| Adam | epoch: 012 | loss: 0.35047 - acc: 0.8634 -- iter: 0704/1668
[A[ATraining Step: 606  | total loss: [1m[32m0.35058[0m[0m | time: 45.780s
[2K
| Adam | epoch: 012 | loss: 0.35058 - acc: 0.8677 -- iter: 0736/1668
[A[ATraining Step: 607  | total loss: [1m[32m0.36054[0m[0m | time: 48.073s
[2K
| Adam | epoch: 012 | loss: 0.36054 - acc: 0.8559 -- iter: 0768/1668
[A[ATraining Step: 608  | total loss: [1m[32m0.35049[0m[0m | time: 51.174s
[2K
| Adam | epoch: 012 | loss: 0.35049 - acc: 0.8610 -- iter: 0800/1668
[A[ATraining Step: 609  | total loss: [1m[32m0.33724[0m[0m | time: 54.314s
[2K
| Adam | epoch: 012 | loss: 0.33724 - acc: 0.8655 -- iter: 0832/1668
[A[ATraining Step: 610  | total loss: [1m[32m0.31734[0m[0m | time: 56.163s
[2K
| Adam | epoch: 012 | loss: 0.31734 - acc: 0.8758 -- iter: 0864/1668
[A[ATraining Step: 611  | total loss: [1m[32m0.31617[0m[0m | time: 58.674s
[2K
| Adam | epoch: 012 | loss: 0.31617 - acc: 0.8726 -- iter: 0896/1668
[A[ATraining Step: 612  | total loss: [1m[32m0.31039[0m[0m | time: 61.148s
[2K
| Adam | epoch: 012 | loss: 0.31039 - acc: 0.8729 -- iter: 0928/1668
[A[ATraining Step: 613  | total loss: [1m[32m0.30550[0m[0m | time: 63.173s
[2K
| Adam | epoch: 012 | loss: 0.30550 - acc: 0.8762 -- iter: 0960/1668
[A[ATraining Step: 614  | total loss: [1m[32m0.30244[0m[0m | time: 64.117s
[2K
| Adam | epoch: 012 | loss: 0.30244 - acc: 0.8792 -- iter: 0992/1668
[A[ATraining Step: 615  | total loss: [1m[32m0.31610[0m[0m | time: 65.119s
[2K
| Adam | epoch: 012 | loss: 0.31610 - acc: 0.8694 -- iter: 1024/1668
[A[ATraining Step: 616  | total loss: [1m[32m0.36862[0m[0m | time: 66.125s
[2K
| Adam | epoch: 012 | loss: 0.36862 - acc: 0.8637 -- iter: 1056/1668
[A[ATraining Step: 617  | total loss: [1m[32m0.34857[0m[0m | time: 67.194s
[2K
| Adam | epoch: 012 | loss: 0.34857 - acc: 0.8711 -- iter: 1088/1668
[A[ATraining Step: 618  | total loss: [1m[32m0.32736[0m[0m | time: 68.197s
[2K
| Adam | epoch: 012 | loss: 0.32736 - acc: 0.8809 -- iter: 1120/1668
[A[ATraining Step: 619  | total loss: [1m[32m0.30663[0m[0m | time: 69.204s
[2K
| Adam | epoch: 012 | loss: 0.30663 - acc: 0.8896 -- iter: 1152/1668
[A[ATraining Step: 620  | total loss: [1m[32m0.28959[0m[0m | time: 70.169s
[2K
| Adam | epoch: 012 | loss: 0.28959 - acc: 0.9007 -- iter: 1184/1668
[A[ATraining Step: 621  | total loss: [1m[32m0.27915[0m[0m | time: 71.183s
[2K
| Adam | epoch: 012 | loss: 0.27915 - acc: 0.9044 -- iter: 1216/1668
[A[ATraining Step: 622  | total loss: [1m[32m0.26637[0m[0m | time: 72.341s
[2K
| Adam | epoch: 012 | loss: 0.26637 - acc: 0.9077 -- iter: 1248/1668
[A[ATraining Step: 623  | total loss: [1m[32m0.26429[0m[0m | time: 73.258s
[2K
| Adam | epoch: 012 | loss: 0.26429 - acc: 0.9044 -- iter: 1280/1668
[A[ATraining Step: 624  | total loss: [1m[32m0.26051[0m[0m | time: 75.454s
[2K
| Adam | epoch: 012 | loss: 0.26051 - acc: 0.9046 -- iter: 1312/1668
[A[ATraining Step: 625  | total loss: [1m[32m0.24888[0m[0m | time: 79.790s
[2K
| Adam | epoch: 012 | loss: 0.24888 - acc: 0.9110 -- iter: 1344/1668
[A[ATraining Step: 626  | total loss: [1m[32m0.24680[0m[0m | time: 84.092s
[2K
| Adam | epoch: 012 | loss: 0.24680 - acc: 0.9105 -- iter: 1376/1668
[A[ATraining Step: 627  | total loss: [1m[32m0.23188[0m[0m | time: 86.732s
[2K
| Adam | epoch: 012 | loss: 0.23188 - acc: 0.9195 -- iter: 1408/1668
[A[ATraining Step: 628  | total loss: [1m[32m0.23165[0m[0m | time: 88.121s
[2K
| Adam | epoch: 012 | loss: 0.23165 - acc: 0.9244 -- iter: 1440/1668
[A[ATraining Step: 629  | total loss: [1m[32m0.21694[0m[0m | time: 89.087s
[2K
| Adam | epoch: 012 | loss: 0.21694 - acc: 0.9320 -- iter: 1472/1668
[A[ATraining Step: 630  | total loss: [1m[32m0.21224[0m[0m | time: 90.127s
[2K
| Adam | epoch: 012 | loss: 0.21224 - acc: 0.9325 -- iter: 1504/1668
[A[ATraining Step: 631  | total loss: [1m[32m0.20744[0m[0m | time: 91.059s
[2K
| Adam | epoch: 012 | loss: 0.20744 - acc: 0.9361 -- iter: 1536/1668
[A[ATraining Step: 632  | total loss: [1m[32m0.19796[0m[0m | time: 92.100s
[2K
| Adam | epoch: 012 | loss: 0.19796 - acc: 0.9394 -- iter: 1568/1668
[A[ATraining Step: 633  | total loss: [1m[32m0.19291[0m[0m | time: 93.183s
[2K
| Adam | epoch: 012 | loss: 0.19291 - acc: 0.9392 -- iter: 1600/1668
[A[ATraining Step: 634  | total loss: [1m[32m0.18394[0m[0m | time: 94.227s
[2K
| Adam | epoch: 012 | loss: 0.18394 - acc: 0.9453 -- iter: 1632/1668
[A[ATraining Step: 635  | total loss: [1m[32m0.17285[0m[0m | time: 95.112s
[2K
| Adam | epoch: 012 | loss: 0.17285 - acc: 0.9508 -- iter: 1664/1668
[A[ATraining Step: 636  | total loss: [1m[32m0.16935[0m[0m | time: 100.697s
[2K
| Adam | epoch: 012 | loss: 0.16935 - acc: 0.9494 | val_loss: 0.70652 - val_acc: 0.7433 -- iter: 1668/1668
--
Training Step: 637  | total loss: [1m[32m0.17366[0m[0m | time: 1.037s
[2K
| Adam | epoch: 013 | loss: 0.17366 - acc: 0.9420 -- iter: 0032/1668
[A[ATraining Step: 638  | total loss: [1m[32m0.17601[0m[0m | time: 2.069s
[2K
| Adam | epoch: 013 | loss: 0.17601 - acc: 0.9415 -- iter: 0064/1668
[A[ATraining Step: 639  | total loss: [1m[32m0.17310[0m[0m | time: 3.163s
[2K
| Adam | epoch: 013 | loss: 0.17310 - acc: 0.9443 -- iter: 0096/1668
[A[ATraining Step: 640  | total loss: [1m[32m0.17476[0m[0m | time: 4.139s
[2K
| Adam | epoch: 013 | loss: 0.17476 - acc: 0.9467 -- iter: 0128/1668
[A[ATraining Step: 641  | total loss: [1m[32m0.17659[0m[0m | time: 5.181s
[2K
| Adam | epoch: 013 | loss: 0.17659 - acc: 0.9489 -- iter: 0160/1668
[A[ATraining Step: 642  | total loss: [1m[32m0.17508[0m[0m | time: 6.403s
[2K
| Adam | epoch: 013 | loss: 0.17508 - acc: 0.9446 -- iter: 0192/1668
[A[ATraining Step: 643  | total loss: [1m[32m0.16491[0m[0m | time: 7.527s
[2K
| Adam | epoch: 013 | loss: 0.16491 - acc: 0.9471 -- iter: 0224/1668
[A[ATraining Step: 644  | total loss: [1m[32m0.16698[0m[0m | time: 12.446s
[2K
| Adam | epoch: 013 | loss: 0.16698 - acc: 0.9430 -- iter: 0256/1668
[A[ATraining Step: 645  | total loss: [1m[32m0.15902[0m[0m | time: 13.436s
[2K
| Adam | epoch: 013 | loss: 0.15902 - acc: 0.9456 -- iter: 0288/1668
[A[ATraining Step: 646  | total loss: [1m[32m0.17784[0m[0m | time: 14.444s
[2K
| Adam | epoch: 013 | loss: 0.17784 - acc: 0.9416 -- iter: 0320/1668
[A[ATraining Step: 647  | total loss: [1m[32m0.17169[0m[0m | time: 14.617s
[2K
| Adam | epoch: 013 | loss: 0.17169 - acc: 0.9412 -- iter: 0352/1668
[A[ATraining Step: 648  | total loss: [1m[32m0.16226[0m[0m | time: 14.784s
[2K
| Adam | epoch: 013 | loss: 0.16226 - acc: 0.9471 -- iter: 0384/1668
[A[ATraining Step: 649  | total loss: [1m[32m0.15126[0m[0m | time: 15.759s
[2K
| Adam | epoch: 013 | loss: 0.15126 - acc: 0.9524 -- iter: 0416/1668
[A[ATraining Step: 650  | total loss: [1m[32m0.16041[0m[0m | time: 16.805s
[2K
| Adam | epoch: 013 | loss: 0.16041 - acc: 0.9478 -- iter: 0448/1668
[A[ATraining Step: 651  | total loss: [1m[32m0.17046[0m[0m | time: 17.900s
[2K
| Adam | epoch: 013 | loss: 0.17046 - acc: 0.9436 -- iter: 0480/1668
[A[ATraining Step: 652  | total loss: [1m[32m0.18027[0m[0m | time: 18.883s
[2K
| Adam | epoch: 013 | loss: 0.18027 - acc: 0.9399 -- iter: 0512/1668
[A[ATraining Step: 653  | total loss: [1m[32m0.17253[0m[0m | time: 19.889s
[2K
| Adam | epoch: 013 | loss: 0.17253 - acc: 0.9428 -- iter: 0544/1668
[A[ATraining Step: 654  | total loss: [1m[32m0.16813[0m[0m | time: 21.150s
[2K
| Adam | epoch: 013 | loss: 0.16813 - acc: 0.9391 -- iter: 0576/1668
[A[ATraining Step: 655  | total loss: [1m[32m0.19776[0m[0m | time: 22.290s
[2K
| Adam | epoch: 013 | loss: 0.19776 - acc: 0.9265 -- iter: 0608/1668
[A[ATraining Step: 656  | total loss: [1m[32m0.19727[0m[0m | time: 23.680s
[2K
| Adam | epoch: 013 | loss: 0.19727 - acc: 0.9213 -- iter: 0640/1668
[A[ATraining Step: 657  | total loss: [1m[32m0.21145[0m[0m | time: 24.705s
[2K
| Adam | epoch: 013 | loss: 0.21145 - acc: 0.9229 -- iter: 0672/1668
[A[ATraining Step: 658  | total loss: [1m[32m0.21453[0m[0m | time: 25.666s
[2K
| Adam | epoch: 013 | loss: 0.21453 - acc: 0.9213 -- iter: 0704/1668
[A[ATraining Step: 659  | total loss: [1m[32m0.21583[0m[0m | time: 26.715s
[2K
| Adam | epoch: 013 | loss: 0.21583 - acc: 0.9198 -- iter: 0736/1668
[A[ATraining Step: 660  | total loss: [1m[32m0.20156[0m[0m | time: 27.763s
[2K
| Adam | epoch: 013 | loss: 0.20156 - acc: 0.9278 -- iter: 0768/1668
[A[ATraining Step: 661  | total loss: [1m[32m0.20580[0m[0m | time: 28.812s
[2K
| Adam | epoch: 013 | loss: 0.20580 - acc: 0.9288 -- iter: 0800/1668
[A[ATraining Step: 662  | total loss: [1m[32m0.22509[0m[0m | time: 29.882s
[2K
| Adam | epoch: 013 | loss: 0.22509 - acc: 0.9203 -- iter: 0832/1668
[A[ATraining Step: 663  | total loss: [1m[32m0.22811[0m[0m | time: 30.852s
[2K
| Adam | epoch: 013 | loss: 0.22811 - acc: 0.9189 -- iter: 0864/1668
[A[ATraining Step: 664  | total loss: [1m[32m0.21655[0m[0m | time: 32.092s
[2K
| Adam | epoch: 013 | loss: 0.21655 - acc: 0.9238 -- iter: 0896/1668
[A[ATraining Step: 665  | total loss: [1m[32m0.22405[0m[0m | time: 33.199s
[2K
| Adam | epoch: 013 | loss: 0.22405 - acc: 0.9190 -- iter: 0928/1668
[A[ATraining Step: 666  | total loss: [1m[32m0.21749[0m[0m | time: 36.976s
[2K
| Adam | epoch: 013 | loss: 0.21749 - acc: 0.9208 -- iter: 0960/1668
[A[ATraining Step: 667  | total loss: [1m[32m0.24924[0m[0m | time: 40.861s
[2K
| Adam | epoch: 013 | loss: 0.24924 - acc: 0.9037 -- iter: 0992/1668
[A[ATraining Step: 668  | total loss: [1m[32m0.25400[0m[0m | time: 43.542s
[2K
| Adam | epoch: 013 | loss: 0.25400 - acc: 0.8977 -- iter: 1024/1668
[A[ATraining Step: 669  | total loss: [1m[32m0.25204[0m[0m | time: 46.032s
[2K
| Adam | epoch: 013 | loss: 0.25204 - acc: 0.9017 -- iter: 1056/1668
[A[ATraining Step: 670  | total loss: [1m[32m0.25295[0m[0m | time: 47.625s
[2K
| Adam | epoch: 013 | loss: 0.25295 - acc: 0.9053 -- iter: 1088/1668
[A[ATraining Step: 671  | total loss: [1m[32m0.24434[0m[0m | time: 49.494s
[2K
| Adam | epoch: 013 | loss: 0.24434 - acc: 0.9085 -- iter: 1120/1668
[A[ATraining Step: 672  | total loss: [1m[32m0.23140[0m[0m | time: 50.370s
[2K
| Adam | epoch: 013 | loss: 0.23140 - acc: 0.9145 -- iter: 1152/1668
[A[ATraining Step: 673  | total loss: [1m[32m0.22340[0m[0m | time: 51.321s
[2K
| Adam | epoch: 013 | loss: 0.22340 - acc: 0.9200 -- iter: 1184/1668
[A[ATraining Step: 674  | total loss: [1m[32m0.21562[0m[0m | time: 52.360s
[2K
| Adam | epoch: 013 | loss: 0.21562 - acc: 0.9217 -- iter: 1216/1668
[A[ATraining Step: 675  | total loss: [1m[32m0.21163[0m[0m | time: 53.355s
[2K
| Adam | epoch: 013 | loss: 0.21163 - acc: 0.9233 -- iter: 1248/1668
[A[ATraining Step: 676  | total loss: [1m[32m0.20111[0m[0m | time: 54.454s
[2K
| Adam | epoch: 013 | loss: 0.20111 - acc: 0.9278 -- iter: 1280/1668
[A[ATraining Step: 677  | total loss: [1m[32m0.19190[0m[0m | time: 55.500s
[2K
| Adam | epoch: 013 | loss: 0.19190 - acc: 0.9351 -- iter: 1312/1668
[A[ATraining Step: 678  | total loss: [1m[32m0.19769[0m[0m | time: 56.428s
[2K
| Adam | epoch: 013 | loss: 0.19769 - acc: 0.9353 -- iter: 1344/1668
[A[ATraining Step: 679  | total loss: [1m[32m0.18798[0m[0m | time: 57.575s
[2K
| Adam | epoch: 013 | loss: 0.18798 - acc: 0.9386 -- iter: 1376/1668
[A[ATraining Step: 680  | total loss: [1m[32m0.18992[0m[0m | time: 58.749s
[2K
| Adam | epoch: 013 | loss: 0.18992 - acc: 0.9323 -- iter: 1408/1668
[A[ATraining Step: 681  | total loss: [1m[32m0.18405[0m[0m | time: 59.589s
[2K
| Adam | epoch: 013 | loss: 0.18405 - acc: 0.9328 -- iter: 1440/1668
[A[ATraining Step: 682  | total loss: [1m[32m0.17994[0m[0m | time: 63.294s
[2K
| Adam | epoch: 013 | loss: 0.17994 - acc: 0.9364 -- iter: 1472/1668
[A[ATraining Step: 683  | total loss: [1m[32m0.18859[0m[0m | time: 66.162s
[2K
| Adam | epoch: 013 | loss: 0.18859 - acc: 0.9365 -- iter: 1504/1668
[A[ATraining Step: 684  | total loss: [1m[32m0.17270[0m[0m | time: 68.837s
[2K
| Adam | epoch: 013 | loss: 0.17270 - acc: 0.9429 -- iter: 1536/1668
[A[ATraining Step: 685  | total loss: [1m[32m0.17859[0m[0m | time: 69.774s
[2K
| Adam | epoch: 013 | loss: 0.17859 - acc: 0.9423 -- iter: 1568/1668
[A[ATraining Step: 686  | total loss: [1m[32m0.17720[0m[0m | time: 70.659s
[2K
| Adam | epoch: 013 | loss: 0.17720 - acc: 0.9450 -- iter: 1600/1668
[A[ATraining Step: 687  | total loss: [1m[32m0.17142[0m[0m | time: 71.645s
[2K
| Adam | epoch: 013 | loss: 0.17142 - acc: 0.9442 -- iter: 1632/1668
[A[ATraining Step: 688  | total loss: [1m[32m0.17664[0m[0m | time: 72.589s
[2K
| Adam | epoch: 013 | loss: 0.17664 - acc: 0.9373 -- iter: 1664/1668
[A[ATraining Step: 689  | total loss: [1m[32m0.16810[0m[0m | time: 76.896s
[2K
| Adam | epoch: 013 | loss: 0.16810 - acc: 0.9404 | val_loss: 0.59374 - val_acc: 0.7835 -- iter: 1668/1668
--
Training Step: 690  | total loss: [1m[32m0.16939[0m[0m | time: 1.168s
[2K
| Adam | epoch: 014 | loss: 0.16939 - acc: 0.9370 -- iter: 0032/1668
[A[ATraining Step: 691  | total loss: [1m[32m0.16840[0m[0m | time: 2.343s
[2K
| Adam | epoch: 014 | loss: 0.16840 - acc: 0.9371 -- iter: 0064/1668
[A[ATraining Step: 692  | total loss: [1m[32m0.17361[0m[0m | time: 3.497s
[2K
| Adam | epoch: 014 | loss: 0.17361 - acc: 0.9340 -- iter: 0096/1668
[A[ATraining Step: 693  | total loss: [1m[32m0.17155[0m[0m | time: 4.593s
[2K
| Adam | epoch: 014 | loss: 0.17155 - acc: 0.9343 -- iter: 0128/1668
[A[ATraining Step: 694  | total loss: [1m[32m0.18132[0m[0m | time: 5.776s
[2K
| Adam | epoch: 014 | loss: 0.18132 - acc: 0.9315 -- iter: 0160/1668
[A[ATraining Step: 695  | total loss: [1m[32m0.17164[0m[0m | time: 6.906s
[2K
| Adam | epoch: 014 | loss: 0.17164 - acc: 0.9353 -- iter: 0192/1668
[A[ATraining Step: 696  | total loss: [1m[32m0.15816[0m[0m | time: 8.049s
[2K
| Adam | epoch: 014 | loss: 0.15816 - acc: 0.9417 -- iter: 0224/1668
[A[ATraining Step: 697  | total loss: [1m[32m0.15909[0m[0m | time: 9.234s
[2K
| Adam | epoch: 014 | loss: 0.15909 - acc: 0.9382 -- iter: 0256/1668
[A[ATraining Step: 698  | total loss: [1m[32m0.15301[0m[0m | time: 10.146s
[2K
| Adam | epoch: 014 | loss: 0.15301 - acc: 0.9412 -- iter: 0288/1668
[A[ATraining Step: 699  | total loss: [1m[32m0.14374[0m[0m | time: 10.842s
[2K
| Adam | epoch: 014 | loss: 0.14374 - acc: 0.9471 -- iter: 0320/1668
[A[ATraining Step: 700  | total loss: [1m[32m0.14055[0m[0m | time: 11.544s
[2K
| Adam | epoch: 014 | loss: 0.14055 - acc: 0.9493 -- iter: 0352/1668
[A[ATraining Step: 701  | total loss: [1m[32m0.13510[0m[0m | time: 11.673s
[2K
| Adam | epoch: 014 | loss: 0.13510 - acc: 0.9512 -- iter: 0384/1668
[A[ATraining Step: 702  | total loss: [1m[32m0.12489[0m[0m | time: 11.799s
[2K
| Adam | epoch: 014 | loss: 0.12489 - acc: 0.9561 -- iter: 0416/1668
[A[ATraining Step: 703  | total loss: [1m[32m0.11427[0m[0m | time: 12.517s
[2K
| Adam | epoch: 014 | loss: 0.11427 - acc: 0.9605 -- iter: 0448/1668
[A[ATraining Step: 704  | total loss: [1m[32m0.11636[0m[0m | time: 13.232s
[2K
| Adam | epoch: 014 | loss: 0.11636 - acc: 0.9582 -- iter: 0480/1668
[A[ATraining Step: 705  | total loss: [1m[32m0.13393[0m[0m | time: 13.964s
[2K
| Adam | epoch: 014 | loss: 0.13393 - acc: 0.9499 -- iter: 0512/1668
[A[ATraining Step: 706  | total loss: [1m[32m0.12968[0m[0m | time: 14.669s
[2K
| Adam | epoch: 014 | loss: 0.12968 - acc: 0.9486 -- iter: 0544/1668
[A[ATraining Step: 707  | total loss: [1m[32m0.13989[0m[0m | time: 15.384s
[2K
| Adam | epoch: 014 | loss: 0.13989 - acc: 0.9413 -- iter: 0576/1668
[A[ATraining Step: 708  | total loss: [1m[32m0.13714[0m[0m | time: 16.043s
[2K
| Adam | epoch: 014 | loss: 0.13714 - acc: 0.9440 -- iter: 0608/1668
[A[ATraining Step: 709  | total loss: [1m[32m0.14175[0m[0m | time: 16.753s
[2K
| Adam | epoch: 014 | loss: 0.14175 - acc: 0.9371 -- iter: 0640/1668
[A[ATraining Step: 710  | total loss: [1m[32m0.15367[0m[0m | time: 17.445s
[2K
| Adam | epoch: 014 | loss: 0.15367 - acc: 0.9340 -- iter: 0672/1668
[A[ATraining Step: 711  | total loss: [1m[32m0.14574[0m[0m | time: 18.148s
[2K
| Adam | epoch: 014 | loss: 0.14574 - acc: 0.9375 -- iter: 0704/1668
[A[ATraining Step: 712  | total loss: [1m[32m0.15574[0m[0m | time: 18.883s
[2K
| Adam | epoch: 014 | loss: 0.15574 - acc: 0.9406 -- iter: 0736/1668
[A[ATraining Step: 713  | total loss: [1m[32m0.16815[0m[0m | time: 19.583s
[2K
| Adam | epoch: 014 | loss: 0.16815 - acc: 0.9403 -- iter: 0768/1668
[A[ATraining Step: 714  | total loss: [1m[32m0.20247[0m[0m | time: 20.273s
[2K
| Adam | epoch: 014 | loss: 0.20247 - acc: 0.9244 -- iter: 0800/1668
[A[ATraining Step: 715  | total loss: [1m[32m0.21934[0m[0m | time: 20.996s
[2K
| Adam | epoch: 014 | loss: 0.21934 - acc: 0.9195 -- iter: 0832/1668
[A[ATraining Step: 716  | total loss: [1m[32m0.20480[0m[0m | time: 21.682s
[2K
| Adam | epoch: 014 | loss: 0.20480 - acc: 0.9244 -- iter: 0864/1668
[A[ATraining Step: 717  | total loss: [1m[32m0.19463[0m[0m | time: 22.373s
[2K
| Adam | epoch: 014 | loss: 0.19463 - acc: 0.9288 -- iter: 0896/1668
[A[ATraining Step: 718  | total loss: [1m[32m0.21971[0m[0m | time: 23.078s
[2K
| Adam | epoch: 014 | loss: 0.21971 - acc: 0.9203 -- iter: 0928/1668
[A[ATraining Step: 719  | total loss: [1m[32m0.22245[0m[0m | time: 23.753s
[2K
| Adam | epoch: 014 | loss: 0.22245 - acc: 0.9189 -- iter: 0960/1668
[A[ATraining Step: 720  | total loss: [1m[32m0.20890[0m[0m | time: 24.456s
[2K
| Adam | epoch: 014 | loss: 0.20890 - acc: 0.9239 -- iter: 0992/1668
[A[ATraining Step: 721  | total loss: [1m[32m0.19943[0m[0m | time: 25.177s
[2K
| Adam | epoch: 014 | loss: 0.19943 - acc: 0.9284 -- iter: 1024/1668
[A[ATraining Step: 722  | total loss: [1m[32m0.19616[0m[0m | time: 25.892s
[2K
| Adam | epoch: 014 | loss: 0.19616 - acc: 0.9262 -- iter: 1056/1668
[A[ATraining Step: 723  | total loss: [1m[32m0.19845[0m[0m | time: 26.616s
[2K
| Adam | epoch: 014 | loss: 0.19845 - acc: 0.9242 -- iter: 1088/1668
[A[ATraining Step: 724  | total loss: [1m[32m0.20925[0m[0m | time: 27.330s
[2K
| Adam | epoch: 014 | loss: 0.20925 - acc: 0.9224 -- iter: 1120/1668
[A[ATraining Step: 725  | total loss: [1m[32m0.20416[0m[0m | time: 28.045s
[2K
| Adam | epoch: 014 | loss: 0.20416 - acc: 0.9239 -- iter: 1152/1668
[A[ATraining Step: 726  | total loss: [1m[32m0.20044[0m[0m | time: 28.774s
[2K
| Adam | epoch: 014 | loss: 0.20044 - acc: 0.9253 -- iter: 1184/1668
[A[ATraining Step: 727  | total loss: [1m[32m0.18766[0m[0m | time: 29.523s
[2K
| Adam | epoch: 014 | loss: 0.18766 - acc: 0.9327 -- iter: 1216/1668
[A[ATraining Step: 728  | total loss: [1m[32m0.18701[0m[0m | time: 30.225s
[2K
| Adam | epoch: 014 | loss: 0.18701 - acc: 0.9363 -- iter: 1248/1668
[A[ATraining Step: 729  | total loss: [1m[32m0.18092[0m[0m | time: 30.952s
[2K
| Adam | epoch: 014 | loss: 0.18092 - acc: 0.9427 -- iter: 1280/1668
[A[ATraining Step: 730  | total loss: [1m[32m0.17628[0m[0m | time: 31.613s
[2K
| Adam | epoch: 014 | loss: 0.17628 - acc: 0.9453 -- iter: 1312/1668
[A[ATraining Step: 731  | total loss: [1m[32m0.16599[0m[0m | time: 32.288s
[2K
| Adam | epoch: 014 | loss: 0.16599 - acc: 0.9508 -- iter: 1344/1668
[A[ATraining Step: 732  | total loss: [1m[32m0.15717[0m[0m | time: 32.990s
[2K
| Adam | epoch: 014 | loss: 0.15717 - acc: 0.9526 -- iter: 1376/1668
[A[ATraining Step: 733  | total loss: [1m[32m0.16658[0m[0m | time: 33.688s
[2K
| Adam | epoch: 014 | loss: 0.16658 - acc: 0.9479 -- iter: 1408/1668
[A[ATraining Step: 734  | total loss: [1m[32m0.17539[0m[0m | time: 34.393s
[2K
| Adam | epoch: 014 | loss: 0.17539 - acc: 0.9469 -- iter: 1440/1668
[A[ATraining Step: 735  | total loss: [1m[32m0.16077[0m[0m | time: 35.077s
[2K
| Adam | epoch: 014 | loss: 0.16077 - acc: 0.9522 -- iter: 1472/1668
[A[ATraining Step: 736  | total loss: [1m[32m0.15422[0m[0m | time: 35.778s
[2K
| Adam | epoch: 014 | loss: 0.15422 - acc: 0.9539 -- iter: 1504/1668
[A[ATraining Step: 737  | total loss: [1m[32m0.14401[0m[0m | time: 36.619s
[2K
| Adam | epoch: 014 | loss: 0.14401 - acc: 0.9585 -- iter: 1536/1668
[A[ATraining Step: 738  | total loss: [1m[32m0.14342[0m[0m | time: 37.895s
[2K
| Adam | epoch: 014 | loss: 0.14342 - acc: 0.9595 -- iter: 1568/1668
[A[ATraining Step: 739  | total loss: [1m[32m0.16629[0m[0m | time: 38.943s
[2K
| Adam | epoch: 014 | loss: 0.16629 - acc: 0.9511 -- iter: 1600/1668
[A[ATraining Step: 740  | total loss: [1m[32m0.17245[0m[0m | time: 40.756s
[2K
| Adam | epoch: 014 | loss: 0.17245 - acc: 0.9403 -- iter: 1632/1668
[A[ATraining Step: 741  | total loss: [1m[32m0.16108[0m[0m | time: 41.733s
[2K
| Adam | epoch: 014 | loss: 0.16108 - acc: 0.9432 -- iter: 1664/1668
[A[ATraining Step: 742  | total loss: [1m[32m0.16002[0m[0m | time: 46.042s
[2K
| Adam | epoch: 014 | loss: 0.16002 - acc: 0.9426 | val_loss: 0.70793 - val_acc: 0.7471 -- iter: 1668/1668
--
Training Step: 743  | total loss: [1m[32m0.14907[0m[0m | time: 0.953s
[2K
| Adam | epoch: 015 | loss: 0.14907 - acc: 0.9483 -- iter: 0032/1668
[A[ATraining Step: 744  | total loss: [1m[32m0.14509[0m[0m | time: 1.849s
[2K
| Adam | epoch: 015 | loss: 0.14509 - acc: 0.9504 -- iter: 0064/1668
[A[ATraining Step: 745  | total loss: [1m[32m0.14096[0m[0m | time: 2.748s
[2K
| Adam | epoch: 015 | loss: 0.14096 - acc: 0.9522 -- iter: 0096/1668
[A[ATraining Step: 746  | total loss: [1m[32m0.13010[0m[0m | time: 3.751s
[2K
| Adam | epoch: 015 | loss: 0.13010 - acc: 0.9570 -- iter: 0128/1668
[A[ATraining Step: 747  | total loss: [1m[32m0.12397[0m[0m | time: 4.654s
[2K
| Adam | epoch: 015 | loss: 0.12397 - acc: 0.9582 -- iter: 0160/1668
[A[ATraining Step: 748  | total loss: [1m[32m0.13803[0m[0m | time: 5.509s
[2K
| Adam | epoch: 015 | loss: 0.13803 - acc: 0.9561 -- iter: 0192/1668
[A[ATraining Step: 749  | total loss: [1m[32m0.12666[0m[0m | time: 6.417s
[2K
| Adam | epoch: 015 | loss: 0.12666 - acc: 0.9605 -- iter: 0224/1668
[A[ATraining Step: 750  | total loss: [1m[32m0.12269[0m[0m | time: 7.703s
[2K
| Adam | epoch: 015 | loss: 0.12269 - acc: 0.9582 -- iter: 0256/1668
[A[ATraining Step: 751  | total loss: [1m[32m0.15324[0m[0m | time: 8.627s
[2K
| Adam | epoch: 015 | loss: 0.15324 - acc: 0.9436 -- iter: 0288/1668
[A[ATraining Step: 752  | total loss: [1m[32m0.14978[0m[0m | time: 14.267s
[2K
| Adam | epoch: 015 | loss: 0.14978 - acc: 0.9430 -- iter: 0320/1668
[A[ATraining Step: 753  | total loss: [1m[32m0.14589[0m[0m | time: 16.534s
[2K
| Adam | epoch: 015 | loss: 0.14589 - acc: 0.9456 -- iter: 0352/1668
[A[ATraining Step: 754  | total loss: [1m[32m0.14031[0m[0m | time: 18.508s
[2K
| Adam | epoch: 015 | loss: 0.14031 - acc: 0.9510 -- iter: 0384/1668
[A[ATraining Step: 755  | total loss: [1m[32m0.14464[0m[0m | time: 18.618s
[2K
| Adam | epoch: 015 | loss: 0.14464 - acc: 0.9465 -- iter: 0416/1668
[A[ATraining Step: 756  | total loss: [1m[32m0.13622[0m[0m | time: 18.787s
[2K
| Adam | epoch: 015 | loss: 0.13622 - acc: 0.9519 -- iter: 0448/1668
[A[ATraining Step: 757  | total loss: [1m[32m0.12531[0m[0m | time: 21.120s
[2K
| Adam | epoch: 015 | loss: 0.12531 - acc: 0.9567 -- iter: 0480/1668
[A[ATraining Step: 758  | total loss: [1m[32m0.12707[0m[0m | time: 24.359s
[2K
| Adam | epoch: 015 | loss: 0.12707 - acc: 0.9548 -- iter: 0512/1668
[A[ATraining Step: 759  | total loss: [1m[32m0.13267[0m[0m | time: 25.291s
[2K
| Adam | epoch: 015 | loss: 0.13267 - acc: 0.9562 -- iter: 0544/1668
[A[ATraining Step: 760  | total loss: [1m[32m0.13550[0m[0m | time: 26.353s
[2K
| Adam | epoch: 015 | loss: 0.13550 - acc: 0.9543 -- iter: 0576/1668
[A[ATraining Step: 761  | total loss: [1m[32m0.12680[0m[0m | time: 27.324s
[2K
| Adam | epoch: 015 | loss: 0.12680 - acc: 0.9589 -- iter: 0608/1668
[A[ATraining Step: 762  | total loss: [1m[32m0.11815[0m[0m | time: 28.327s
[2K
| Adam | epoch: 015 | loss: 0.11815 - acc: 0.9630 -- iter: 0640/1668
[A[ATraining Step: 763  | total loss: [1m[32m0.12417[0m[0m | time: 29.348s
[2K
| Adam | epoch: 015 | loss: 0.12417 - acc: 0.9636 -- iter: 0672/1668
[A[ATraining Step: 764  | total loss: [1m[32m0.12377[0m[0m | time: 30.365s
[2K
| Adam | epoch: 015 | loss: 0.12377 - acc: 0.9610 -- iter: 0704/1668
[A[ATraining Step: 765  | total loss: [1m[32m0.14140[0m[0m | time: 31.304s
[2K
| Adam | epoch: 015 | loss: 0.14140 - acc: 0.9555 -- iter: 0736/1668
[A[ATraining Step: 766  | total loss: [1m[32m0.13525[0m[0m | time: 32.439s
[2K
| Adam | epoch: 015 | loss: 0.13525 - acc: 0.9568 -- iter: 0768/1668
[A[ATraining Step: 767  | total loss: [1m[32m0.14152[0m[0m | time: 33.598s
[2K
| Adam | epoch: 015 | loss: 0.14152 - acc: 0.9549 -- iter: 0800/1668
[A[ATraining Step: 768  | total loss: [1m[32m0.14707[0m[0m | time: 34.586s
[2K
| Adam | epoch: 015 | loss: 0.14707 - acc: 0.9531 -- iter: 0832/1668
[A[ATraining Step: 769  | total loss: [1m[32m0.14370[0m[0m | time: 39.509s
[2K
| Adam | epoch: 015 | loss: 0.14370 - acc: 0.9485 -- iter: 0864/1668
[A[ATraining Step: 770  | total loss: [1m[32m0.14079[0m[0m | time: 41.084s
[2K
| Adam | epoch: 015 | loss: 0.14079 - acc: 0.9505 -- iter: 0896/1668
[A[ATraining Step: 771  | total loss: [1m[32m0.12803[0m[0m | time: 42.086s
[2K
| Adam | epoch: 015 | loss: 0.12803 - acc: 0.9554 -- iter: 0928/1668
[A[ATraining Step: 772  | total loss: [1m[32m0.15976[0m[0m | time: 43.108s
[2K
| Adam | epoch: 015 | loss: 0.15976 - acc: 0.9474 -- iter: 0960/1668
[A[ATraining Step: 773  | total loss: [1m[32m0.18928[0m[0m | time: 44.138s
[2K
| Adam | epoch: 015 | loss: 0.18928 - acc: 0.9339 -- iter: 0992/1668
[A[ATraining Step: 774  | total loss: [1m[32m0.19144[0m[0m | time: 45.235s
[2K
| Adam | epoch: 015 | loss: 0.19144 - acc: 0.9343 -- iter: 1024/1668
[A[ATraining Step: 775  | total loss: [1m[32m0.18221[0m[0m | time: 46.255s
[2K
| Adam | epoch: 015 | loss: 0.18221 - acc: 0.9377 -- iter: 1056/1668
[A[ATraining Step: 776  | total loss: [1m[32m0.17576[0m[0m | time: 47.165s
[2K
| Adam | epoch: 015 | loss: 0.17576 - acc: 0.9408 -- iter: 1088/1668
[A[ATraining Step: 777  | total loss: [1m[32m0.18855[0m[0m | time: 48.317s
[2K
| Adam | epoch: 015 | loss: 0.18855 - acc: 0.9374 -- iter: 1120/1668
[A[ATraining Step: 778  | total loss: [1m[32m0.20107[0m[0m | time: 49.402s
[2K
| Adam | epoch: 015 | loss: 0.20107 - acc: 0.9342 -- iter: 1152/1668
[A[ATraining Step: 779  | total loss: [1m[32m0.19890[0m[0m | time: 50.415s
[2K
| Adam | epoch: 015 | loss: 0.19890 - acc: 0.9283 -- iter: 1184/1668
[A[ATraining Step: 780  | total loss: [1m[32m0.18414[0m[0m | time: 54.229s
[2K
| Adam | epoch: 015 | loss: 0.18414 - acc: 0.9355 -- iter: 1216/1668
[A[ATraining Step: 781  | total loss: [1m[32m0.16966[0m[0m | time: 55.235s
[2K
| Adam | epoch: 015 | loss: 0.16966 - acc: 0.9419 -- iter: 1248/1668
[A[ATraining Step: 782  | total loss: [1m[32m0.15962[0m[0m | time: 56.209s
[2K
| Adam | epoch: 015 | loss: 0.15962 - acc: 0.9446 -- iter: 1280/1668
[A[ATraining Step: 783  | total loss: [1m[32m0.15368[0m[0m | time: 57.223s
[2K
| Adam | epoch: 015 | loss: 0.15368 - acc: 0.9470 -- iter: 1312/1668
[A[ATraining Step: 784  | total loss: [1m[32m0.14927[0m[0m | time: 58.205s
[2K
| Adam | epoch: 015 | loss: 0.14927 - acc: 0.9492 -- iter: 1344/1668
[A[ATraining Step: 785  | total loss: [1m[32m0.14159[0m[0m | time: 59.215s
[2K
| Adam | epoch: 015 | loss: 0.14159 - acc: 0.9512 -- iter: 1376/1668
[A[ATraining Step: 786  | total loss: [1m[32m0.13265[0m[0m | time: 60.264s
[2K
| Adam | epoch: 015 | loss: 0.13265 - acc: 0.9560 -- iter: 1408/1668
[A[ATraining Step: 787  | total loss: [1m[32m0.12208[0m[0m | time: 61.212s
[2K
| Adam | epoch: 015 | loss: 0.12208 - acc: 0.9604 -- iter: 1440/1668
[A[ATraining Step: 788  | total loss: [1m[32m0.11423[0m[0m | time: 62.455s
[2K
| Adam | epoch: 015 | loss: 0.11423 - acc: 0.9644 -- iter: 1472/1668
[A[ATraining Step: 789  | total loss: [1m[32m0.11828[0m[0m | time: 63.562s
[2K
| Adam | epoch: 015 | loss: 0.11828 - acc: 0.9617 -- iter: 1504/1668
[A[ATraining Step: 790  | total loss: [1m[32m0.11472[0m[0m | time: 65.890s
[2K
| Adam | epoch: 015 | loss: 0.11472 - acc: 0.9655 -- iter: 1536/1668
[A[ATraining Step: 791  | total loss: [1m[32m0.11892[0m[0m | time: 70.719s
[2K
| Adam | epoch: 015 | loss: 0.11892 - acc: 0.9659 -- iter: 1568/1668
[A[ATraining Step: 792  | total loss: [1m[32m0.11021[0m[0m | time: 72.194s
[2K
| Adam | epoch: 015 | loss: 0.11021 - acc: 0.9693 -- iter: 1600/1668
[A[ATraining Step: 793  | total loss: [1m[32m0.11715[0m[0m | time: 73.172s
[2K
| Adam | epoch: 015 | loss: 0.11715 - acc: 0.9692 -- iter: 1632/1668
[A[ATraining Step: 794  | total loss: [1m[32m0.11762[0m[0m | time: 74.201s
[2K
| Adam | epoch: 015 | loss: 0.11762 - acc: 0.9692 -- iter: 1664/1668
[A[ATraining Step: 795  | total loss: [1m[32m0.10890[0m[0m | time: 78.579s
[2K
| Adam | epoch: 015 | loss: 0.10890 - acc: 0.9723 | val_loss: 0.71787 - val_acc: 0.7605 -- iter: 1668/1668
--
2018-08-01 17:52:27.343756: W tensorflow/core/framework/allocator.cc:101] Allocation of 4727632896 exceeds 10% of system memory.
2018-08-01 17:53:05.312757: W tensorflow/core/framework/allocator.cc:101] Allocation of 4727632896 exceeds 10% of system memory.
Validation AUC:0.8396624472573839
Validation AUPRC:0.834443976497555
Test AUC:0.8504393206746079
Test AUPRC:0.8580953910623378
BestTestF1Score	0.76	0.55	0.78	0.77	0.74	181	54	224	63	0.58
BestTestMCCScore	0.76	0.58	0.79	0.81	0.72	175	40	238	69	0.72
BestTestAccuracyScore	0.76	0.58	0.79	0.81	0.72	175	40	238	69	0.72
BestValidationF1Score	0.76	0.55	0.78	0.75	0.76	181	61	224	56	0.58
BestValidationMCC	0.75	0.55	0.78	0.77	0.73	172	51	234	65	0.72
BestValidationAccuracy	0.75	0.55	0.78	0.77	0.73	172	51	234	65	0.72
TestPredictions (Threshold:0.72)
CHEMBL523830,TP,ACT,1.0	CHEMBL388627,TP,ACT,1.0	CHEMBL2058985,FP,INACT,0.8500000238418579	CHEMBL3593658,FN,ACT,0.019999999552965164	CHEMBL3133307,TN,INACT,0.009999999776482582	CHEMBL421501,TP,ACT,1.0	CHEMBL1669482,TN,INACT,0.12999999523162842	CHEMBL497686,TN,INACT,0.0	CHEMBL2402160,TN,INACT,0.03999999910593033	CHEMBL3360487,FP,INACT,0.9399999976158142	CHEMBL384886,TP,ACT,1.0	CHEMBL3823197,TP,ACT,0.9900000095367432	CHEMBL2296114,TN,INACT,0.0	CHEMBL106771,TN,INACT,0.6600000262260437	CHEMBL2234516,FP,INACT,0.9399999976158142	CHEMBL3326705,TP,ACT,1.0	CHEMBL1917825,FN,ACT,0.10999999940395355	CHEMBL3401023,TN,INACT,0.0	CHEMBL3309944,TP,ACT,0.9200000166893005	CHEMBL239616,TP,ACT,0.9700000286102295	CHEMBL137059,TP,ACT,0.9900000095367432	CHEMBL1084709,TN,INACT,0.6800000071525574	CHEMBL3612820,TN,INACT,0.029999999329447746	CHEMBL335133,TP,ACT,0.8199999928474426	CHEMBL1766142,TN,INACT,0.009999999776482582	CHEMBL3311542,TN,INACT,0.019999999552965164	CHEMBL3233993,TN,INACT,0.28999999165534973	CHEMBL224202,TP,ACT,1.0	CHEMBL32778,TN,INACT,0.009999999776482582	CHEMBL19470,TN,INACT,0.009999999776482582	CHEMBL151369,TN,INACT,0.009999999776482582	CHEMBL3642052,TP,ACT,1.0	CHEMBL375862,TP,ACT,0.949999988079071	CHEMBL74257,TP,ACT,0.9800000190734863	CHEMBL1087131,TN,INACT,0.03999999910593033	CHEMBL3401022,TN,INACT,0.019999999552965164	CHEMBL220731,TN,INACT,0.14000000059604645	CHEMBL1081810,TP,ACT,0.7799999713897705	CHEMBL3642043,TP,ACT,1.0	CHEMBL452321,FN,ACT,0.03999999910593033	CHEMBL321808,FN,ACT,0.07000000029802322	CHEMBL1087180,TN,INACT,0.009999999776482582	CHEMBL97501,FP,INACT,0.9599999785423279	CHEMBL1512936,FN,ACT,0.009999999776482582	CHEMBL229105,TP,ACT,0.9700000286102295	CHEMBL2152549,TN,INACT,0.6100000143051147	CHEMBL491526,TN,INACT,0.009999999776482582	CHEMBL602937,TN,INACT,0.029999999329447746	CHEMBL3617368,TN,INACT,0.0	CHEMBL3605422,TN,INACT,0.009999999776482582	CHEMBL390737,TP,ACT,1.0	CHEMBL95695,FN,ACT,0.49000000953674316	CHEMBL1651044,TN,INACT,0.019999999552965164	CHEMBL2425832,TN,INACT,0.05000000074505806	CHEMBL223001,FP,INACT,0.949999988079071	CHEMBL3335028,TN,INACT,0.0	CHEMBL239834,FN,ACT,0.5199999809265137	CHEMBL240899,TP,ACT,0.9900000095367432	CHEMBL13122,FN,ACT,0.07999999821186066	CHEMBL518543,TP,ACT,0.949999988079071	CHEMBL222043,TP,ACT,0.8500000238418579	CHEMBL271746,TP,ACT,1.0	CHEMBL295124,FN,ACT,0.03999999910593033	CHEMBL175949,TP,ACT,1.0	CHEMBL3337471,TN,INACT,0.019999999552965164	CHEMBL556161,FP,INACT,0.9399999976158142	CHEMBL1629787,TN,INACT,0.4000000059604645	CHEMBL235565,TN,INACT,0.5799999833106995	CHEMBL3401029,TN,INACT,0.009999999776482582	CHEMBL3410957,TP,ACT,1.0	CHEMBL541363,TN,INACT,0.1599999964237213	CHEMBL1915764,TN,INACT,0.009999999776482582	CHEMBL3597939,TN,INACT,0.009999999776482582	CHEMBL542497,TP,ACT,0.949999988079071	CHEMBL3764714,TN,INACT,0.1599999964237213	CHEMBL389825,TN,INACT,0.009999999776482582	CHEMBL1082749,TN,INACT,0.05999999865889549	CHEMBL2234520,TN,INACT,0.47999998927116394	CHEMBL51085,TP,ACT,0.9399999976158142	CHEMBL3260182,TN,INACT,0.03999999910593033	CHEMBL3628059,TP,ACT,0.9900000095367432	CHEMBL151236,TN,INACT,0.009999999776482582	CHEMBL225688,TN,INACT,0.550000011920929	CHEMBL130458,TP,ACT,1.0	CHEMBL452742,TN,INACT,0.009999999776482582	CHEMBL3823317,TP,ACT,0.9599999785423279	CHEMBL3827872,TN,INACT,0.019999999552965164	CHEMBL3277222,FN,ACT,0.2800000011920929	CHEMBL3339001,FN,ACT,0.009999999776482582	CHEMBL2047529,TP,ACT,1.0	CHEMBL435673,TN,INACT,0.0	CHEMBL2295846,TN,INACT,0.0	CHEMBL1618217,TP,ACT,0.9100000262260437	CHEMBL3260556,FN,ACT,0.029999999329447746	CHEMBL2019041,TP,ACT,1.0	CHEMBL318517,FN,ACT,0.23999999463558197	CHEMBL464006,FN,ACT,0.019999999552965164	CHEMBL2337268,FP,INACT,0.8299999833106995	CHEMBL189957,TP,ACT,0.9900000095367432	CHEMBL3360486,TN,INACT,0.009999999776482582	CHEMBL1914930,TN,INACT,0.10000000149011612	CHEMBL572480,FN,ACT,0.05000000074505806	CHEMBL2019044,TP,ACT,1.0	CHEMBL507174,TP,ACT,1.0	CHEMBL3617365,TN,INACT,0.009999999776482582	CHEMBL3581573,TN,INACT,0.2199999988079071	CHEMBL136669,TN,INACT,0.6800000071525574	CHEMBL104387,TP,ACT,1.0	CHEMBL3416643,TN,INACT,0.0	CHEMBL3338998,TN,INACT,0.019999999552965164	CHEMBL54956,FN,ACT,0.5699999928474426	CHEMBL241548,FN,ACT,0.009999999776482582	CHEMBL2088784,FN,ACT,0.5	CHEMBL3764762,TP,ACT,0.8500000238418579	CHEMBL2011404,TN,INACT,0.20999999344348907	CHEMBL2334732,TN,INACT,0.0	CHEMBL3819423,FP,INACT,0.9200000166893005	CHEMBL2334727,TN,INACT,0.009999999776482582	CHEMBL497755,TP,ACT,0.8199999928474426	CHEMBL491528,TN,INACT,0.33000001311302185	CHEMBL2022933,TN,INACT,0.029999999329447746	CHEMBL481305,TP,ACT,0.9900000095367432	CHEMBL149230,TN,INACT,0.029999999329447746	CHEMBL307004,TP,ACT,1.0	CHEMBL173018,TP,ACT,0.9900000095367432	CHEMBL3289929,TN,INACT,0.0	CHEMBL3133249,TN,INACT,0.009999999776482582	CHEMBL340807,TN,INACT,0.05999999865889549	CHEMBL539045,FN,ACT,0.4099999964237213	CHEMBL2334728,TN,INACT,0.03999999910593033	CHEMBL1642972,TN,INACT,0.12999999523162842	CHEMBL2152550,TN,INACT,0.029999999329447746	CHEMBL343365,TN,INACT,0.4699999988079071	CHEMBL13166,FN,ACT,0.12999999523162842	CHEMBL130738,TN,INACT,0.1899999976158142	CHEMBL3215572,TP,ACT,0.9599999785423279	CHEMBL183130,TN,INACT,0.4000000059604645	CHEMBL609977,TP,ACT,0.9900000095367432	CHEMBL2335967,TP,ACT,1.0	CHEMBL409858,TN,INACT,0.09000000357627869	CHEMBL555214,TP,ACT,1.0	CHEMBL3277217,TN,INACT,0.4300000071525574	CHEMBL1214951,TN,INACT,0.20000000298023224	CHEMBL2088781,TP,ACT,0.9900000095367432	CHEMBL561846,TN,INACT,0.019999999552965164	CHEMBL1770313,FN,ACT,0.6800000071525574	CHEMBL570764,TP,ACT,0.9900000095367432	CHEMBL225326,TP,ACT,1.0	CHEMBL3621333,FN,ACT,0.0	CHEMBL2163791,FN,ACT,0.029999999329447746	CHEMBL507885,TP,ACT,0.9900000095367432	CHEMBL1088155,FP,INACT,0.9800000190734863	CHEMBL365207,FP,INACT,0.7300000190734863	CHEMBL3286942,TN,INACT,0.03999999910593033	CHEMBL51168,FP,INACT,0.7900000214576721	CHEMBL1912059,TP,ACT,1.0	CHEMBL2147630,TP,ACT,0.7699999809265137	CHEMBL75729,FN,ACT,0.6200000047683716	CHEMBL175047,TP,ACT,0.949999988079071	CHEMBL493460,TP,ACT,0.9800000190734863	CHEMBL2425409,TN,INACT,0.009999999776482582	CHEMBL512948,TN,INACT,0.009999999776482582	CHEMBL153934,FP,INACT,0.949999988079071	CHEMBL3289933,TN,INACT,0.0	CHEMBL345124,TN,INACT,0.6000000238418579	CHEMBL3116300,TP,ACT,1.0	CHEMBL164,TN,INACT,0.019999999552965164	CHEMBL1669479,TP,ACT,1.0	CHEMBL2296111,TN,INACT,0.009999999776482582	CHEMBL3277221,TP,ACT,0.8299999833106995	CHEMBL3819231,TP,ACT,1.0	CHEMBL478706,TN,INACT,0.05999999865889549	CHEMBL2181437,TN,INACT,0.009999999776482582	CHEMBL3628183,TP,ACT,1.0	CHEMBL3216018,TP,ACT,1.0	CHEMBL320291,TP,ACT,0.9300000071525574	CHEMBL262565,TP,ACT,1.0	CHEMBL517605,TN,INACT,0.12999999523162842	CHEMBL190152,TN,INACT,0.10000000149011612	CHEMBL2334726,TN,INACT,0.0	CHEMBL1642975,TP,ACT,0.9800000190734863	CHEMBL258468,TN,INACT,0.09000000357627869	CHEMBL2234517,TN,INACT,0.14000000059604645	CHEMBL2393509,FP,INACT,0.9700000286102295	CHEMBL555666,TP,ACT,1.0	CHEMBL52181,TN,INACT,0.14000000059604645	CHEMBL3087799,TN,INACT,0.009999999776482582	CHEMBL362583,TN,INACT,0.009999999776482582	CHEMBL1773485,FP,INACT,0.8500000238418579	CHEMBL1766144,TN,INACT,0.009999999776482582	CHEMBL492898,TP,ACT,1.0	CHEMBL3617366,TN,INACT,0.009999999776482582	CHEMBL3794486,TN,INACT,0.019999999552965164	CHEMBL27675,TN,INACT,0.07000000029802322	CHEMBL3632850,TP,ACT,1.0	CHEMBL2159662,TP,ACT,0.9900000095367432	CHEMBL3104329,TN,INACT,0.009999999776482582	CHEMBL3361270,FN,ACT,0.05000000074505806	CHEMBL415423,TN,INACT,0.0	CHEMBL3617390,TN,INACT,0.009999999776482582	CHEMBL32147,TN,INACT,0.019999999552965164	CHEMBL2181431,TN,INACT,0.30000001192092896	CHEMBL2425843,TN,INACT,0.10000000149011612	CHEMBL2160223,FN,ACT,0.4399999976158142	CHEMBL225611,TP,ACT,0.9800000190734863	CHEMBL3819383,TP,ACT,0.9900000095367432	CHEMBL2058980,FP,INACT,0.9300000071525574	CHEMBL3361109,TN,INACT,0.6700000166893005	CHEMBL95,TP,ACT,0.9100000262260437	CHEMBL130831,TN,INACT,0.009999999776482582	CHEMBL3235221,TN,INACT,0.03999999910593033	CHEMBL176773,TP,ACT,0.949999988079071	CHEMBL496127,TP,ACT,1.0	CHEMBL574734,TN,INACT,0.009999999776482582	CHEMBL3642042,TP,ACT,0.9800000190734863	CHEMBL2425408,TN,INACT,0.3499999940395355	CHEMBL427082,TP,ACT,1.0	CHEMBL521874,TP,ACT,1.0	CHEMBL106936,TP,ACT,0.9900000095367432	CHEMBL481525,TP,ACT,1.0	CHEMBL282920,TN,INACT,0.0	CHEMBL1257887,TN,INACT,0.03999999910593033	CHEMBL3632848,TP,ACT,1.0	CHEMBL3770816,TN,INACT,0.009999999776482582	CHEMBL3407584,TP,ACT,0.7599999904632568	CHEMBL2160229,FP,INACT,1.0	CHEMBL2337280,TN,INACT,0.009999999776482582	CHEMBL599057,TP,ACT,0.8199999928474426	CHEMBL1771556,FN,ACT,0.019999999552965164	CHEMBL490264,TP,ACT,0.9599999785423279	CHEMBL3628065,FN,ACT,0.009999999776482582	CHEMBL526476,TN,INACT,0.38999998569488525	CHEMBL3087801,TN,INACT,0.019999999552965164	CHEMBL243254,TN,INACT,0.009999999776482582	CHEMBL3235948,TN,INACT,0.019999999552965164	CHEMBL2113368,TP,ACT,1.0	CHEMBL3262667,TP,ACT,1.0	CHEMBL241114,FN,ACT,0.029999999329447746	CHEMBL228950,TP,ACT,0.9800000190734863	CHEMBL341437,FN,ACT,0.4000000059604645	CHEMBL3632847,TP,ACT,1.0	CHEMBL3216210,TP,ACT,0.9300000071525574	CHEMBL3407581,TP,ACT,0.9900000095367432	CHEMBL3356950,TP,ACT,0.9599999785423279	CHEMBL3217208,TP,ACT,1.0	CHEMBL2235388,TN,INACT,0.019999999552965164	CHEMBL270349,TP,ACT,1.0	CHEMBL2335974,TP,ACT,0.9900000095367432	CHEMBL472969,TN,INACT,0.009999999776482582	CHEMBL3623564,TN,INACT,0.009999999776482582	CHEMBL3093802,TP,ACT,1.0	CHEMBL591234,TP,ACT,0.9800000190734863	CHEMBL122834,TP,ACT,0.7900000214576721	CHEMBL1761995,TP,ACT,1.0	CHEMBL329231,FN,ACT,0.09000000357627869	CHEMBL3770408,TN,INACT,0.019999999552965164	CHEMBL3400158,TN,INACT,0.019999999552965164	CHEMBL2064464,TP,ACT,1.0	CHEMBL278020,FP,INACT,0.8899999856948853	CHEMBL549936,FP,INACT,0.75	CHEMBL2022927,TN,INACT,0.20000000298023224	CHEMBL279924,TN,INACT,0.4399999976158142	CHEMBL572865,FP,INACT,0.9800000190734863	CHEMBL27673,FN,ACT,0.5799999833106995	CHEMBL119389,TN,INACT,0.019999999552965164	CHEMBL335167,TP,ACT,0.9599999785423279	CHEMBL268499,TP,ACT,0.9700000286102295	CHEMBL2111583,FN,ACT,0.05000000074505806	CHEMBL74533,TN,INACT,0.009999999776482582	CHEMBL2147635,TP,ACT,0.9300000071525574	CHEMBL46917,TN,INACT,0.550000011920929	CHEMBL99284,TP,ACT,0.9700000286102295	CHEMBL376514,TP,ACT,1.0	CHEMBL148771,TN,INACT,0.009999999776482582	CHEMBL19949,TP,ACT,0.9800000190734863	CHEMBL1084518,TN,INACT,0.019999999552965164	CHEMBL604046,TN,INACT,0.36000001430511475	CHEMBL2113367,TP,ACT,0.9800000190734863	CHEMBL2323352,TN,INACT,0.009999999776482582	CHEMBL205321,TP,ACT,1.0	CHEMBL121374,TN,INACT,0.009999999776482582	CHEMBL123248,TP,ACT,0.8700000047683716	CHEMBL1651038,TN,INACT,0.029999999329447746	CHEMBL382260,TP,ACT,1.0	CHEMBL2409140,TN,INACT,0.009999999776482582	CHEMBL592185,FN,ACT,0.09000000357627869	CHEMBL492481,TP,ACT,1.0	CHEMBL3087907,TN,INACT,0.3799999952316284	CHEMBL541885,TN,INACT,0.009999999776482582	CHEMBL502,FN,ACT,0.009999999776482582	CHEMBL1082750,TN,INACT,0.019999999552965164	CHEMBL480176,TP,ACT,1.0	CHEMBL3617364,TN,INACT,0.009999999776482582	CHEMBL8320,FN,ACT,0.029999999329447746	CHEMBL2334737,TN,INACT,0.019999999552965164	CHEMBL1082427,TN,INACT,0.009999999776482582	CHEMBL2064470,TP,ACT,1.0	CHEMBL544636,TN,INACT,0.009999999776482582	CHEMBL3116282,FN,ACT,0.009999999776482582	CHEMBL494519,TP,ACT,0.9399999976158142	CHEMBL174046,TP,ACT,0.9900000095367432	CHEMBL2181432,TN,INACT,0.0	CHEMBL25629,TN,INACT,0.019999999552965164	CHEMBL3323387,TN,INACT,0.6600000262260437	CHEMBL2113010,TN,INACT,0.6200000047683716	CHEMBL3754005,FN,ACT,0.44999998807907104	CHEMBL492233,TP,ACT,1.0	CHEMBL382351,TP,ACT,0.9900000095367432	CHEMBL3233991,TN,INACT,0.019999999552965164	CHEMBL394755,TP,ACT,0.9900000095367432	CHEMBL2181438,FP,INACT,0.9900000095367432	CHEMBL2381400,FN,ACT,0.0	CHEMBL3632949,TN,INACT,0.25	CHEMBL589252,TP,ACT,0.9900000095367432	CHEMBL3752873,TN,INACT,0.019999999552965164	CHEMBL395281,FP,INACT,1.0	CHEMBL1784958,FP,INACT,0.9800000190734863	CHEMBL2177712,TN,INACT,0.019999999552965164	CHEMBL3338392,FN,ACT,0.009999999776482582	CHEMBL2152542,TN,INACT,0.05999999865889549	CHEMBL172442,FN,ACT,0.36000001430511475	CHEMBL338755,TP,ACT,1.0	CHEMBL452339,TP,ACT,1.0	CHEMBL109869,TP,ACT,0.9399999976158142	CHEMBL2441690,TN,INACT,0.019999999552965164	CHEMBL3819024,TN,INACT,0.019999999552965164	CHEMBL3764609,TP,ACT,0.9100000262260437	CHEMBL373537,TP,ACT,0.8299999833106995	CHEMBL3237539,FP,INACT,0.9599999785423279	CHEMBL187870,TP,ACT,0.9700000286102295	CHEMBL1783519,TP,ACT,0.9900000095367432	CHEMBL1914495,TN,INACT,0.029999999329447746	CHEMBL521935,TP,ACT,0.9800000190734863	CHEMBL2159656,TP,ACT,0.9900000095367432	CHEMBL373651,TN,INACT,0.12999999523162842	CHEMBL492636,FN,ACT,0.6899999976158142	CHEMBL3818332,TP,ACT,0.9800000190734863	CHEMBL2310905,TN,INACT,0.019999999552965164	CHEMBL1097952,TN,INACT,0.009999999776482582	CHEMBL492635,TP,ACT,0.9900000095367432	CHEMBL159333,TN,INACT,0.05000000074505806	CHEMBL1642970,TN,INACT,0.23999999463558197	CHEMBL3322161,TP,ACT,1.0	CHEMBL2375930,TN,INACT,0.07000000029802322	CHEMBL133388,TP,ACT,0.9100000262260437	CHEMBL3753906,FP,INACT,0.8399999737739563	CHEMBL3753110,TN,INACT,0.3199999928474426	CHEMBL2391652,FP,INACT,0.9800000190734863	CHEMBL1643944,TP,ACT,1.0	CHEMBL75985,TP,ACT,1.0	CHEMBL2058983,FP,INACT,0.7599999904632568	CHEMBL3817936,TN,INACT,0.019999999552965164	CHEMBL1084788,TN,INACT,0.07000000029802322	CHEMBL426230,TN,INACT,0.009999999776482582	CHEMBL335355,TP,ACT,0.9900000095367432	CHEMBL3235952,TN,INACT,0.009999999776482582	CHEMBL507438,TP,ACT,1.0	CHEMBL228360,TP,ACT,1.0	CHEMBL241828,TN,INACT,0.009999999776482582	CHEMBL103959,TN,INACT,0.029999999329447746	CHEMBL340427,TN,INACT,0.5400000214576721	CHEMBL473767,TN,INACT,0.009999999776482582	CHEMBL460969,TN,INACT,0.019999999552965164	CHEMBL3235227,TN,INACT,0.09000000357627869	CHEMBL305670,TP,ACT,0.9700000286102295	CHEMBL391686,FN,ACT,0.05000000074505806	CHEMBL95020,FN,ACT,0.07000000029802322	CHEMBL3237780,TN,INACT,0.05999999865889549	CHEMBL147465,TN,INACT,0.029999999329447746	CHEMBL243269,TP,ACT,0.9800000190734863	CHEMBL333313,TN,INACT,0.6200000047683716	CHEMBL372710,FP,INACT,0.9700000286102295	CHEMBL2011491,TP,ACT,1.0	CHEMBL508510,FN,ACT,0.0	CHEMBL434948,TN,INACT,0.18000000715255737	CHEMBL1834065,TN,INACT,0.10000000149011612	CHEMBL411226,TN,INACT,0.03999999910593033	CHEMBL1084786,TN,INACT,0.03999999910593033	CHEMBL572811,FN,ACT,0.019999999552965164	CHEMBL375126,FP,INACT,0.7699999809265137	CHEMBL3133248,TN,INACT,0.019999999552965164	CHEMBL31184,TN,INACT,0.07000000029802322	CHEMBL339484,TN,INACT,0.2800000011920929	CHEMBL1915763,TN,INACT,0.0	CHEMBL74107,TP,ACT,0.8399999737739563	CHEMBL3770401,TN,INACT,0.05999999865889549	CHEMBL137721,TN,INACT,0.03999999910593033	CHEMBL95375,TP,ACT,0.9200000166893005	CHEMBL222904,TP,ACT,1.0	CHEMBL1940614,FN,ACT,0.03999999910593033	CHEMBL104355,FN,ACT,0.019999999552965164	CHEMBL3827044,TP,ACT,0.9800000190734863	CHEMBL1256415,TN,INACT,0.3100000023841858	CHEMBL433041,FN,ACT,0.5099999904632568	CHEMBL391727,TP,ACT,0.8799999952316284	CHEMBL1085275,TN,INACT,0.009999999776482582	CHEMBL1173605,TP,ACT,0.9300000071525574	CHEMBL1588892,FN,ACT,0.009999999776482582	CHEMBL583687,TP,ACT,0.9900000095367432	CHEMBL599058,FP,INACT,0.8999999761581421	CHEMBL224822,TN,INACT,0.03999999910593033	CHEMBL3216886,TP,ACT,1.0	CHEMBL1257885,TP,ACT,0.8500000238418579	CHEMBL228361,TP,ACT,1.0	CHEMBL1773489,FN,ACT,0.12999999523162842	CHEMBL3339007,TN,INACT,0.009999999776482582	CHEMBL105496,TN,INACT,0.12999999523162842	CHEMBL3827734,TP,ACT,1.0	CHEMBL3771281,TN,INACT,0.009999999776482582	CHEMBL3617397,TN,INACT,0.0	CHEMBL99414,TP,ACT,0.9900000095367432	CHEMBL589063,TP,ACT,0.9599999785423279	CHEMBL153556,TN,INACT,0.029999999329447746	CHEMBL3127043,TN,INACT,0.019999999552965164	CHEMBL188821,FN,ACT,0.009999999776482582	CHEMBL496488,FN,ACT,0.18000000715255737	CHEMBL1928384,TN,INACT,0.009999999776482582	CHEMBL3220507,TN,INACT,0.009999999776482582	CHEMBL3753070,TN,INACT,0.11999999731779099	CHEMBL3133247,TN,INACT,0.029999999329447746	CHEMBL3122168,TP,ACT,0.9900000095367432	CHEMBL1642987,FN,ACT,0.14000000059604645	CHEMBL364678,FP,INACT,0.9900000095367432	CHEMBL3261989,TN,INACT,0.23000000417232513	CHEMBL3605428,TN,INACT,0.009999999776482582	CHEMBL514186,TN,INACT,0.0	CHEMBL2419686,FN,ACT,0.41999998688697815	CHEMBL1766148,TN,INACT,0.009999999776482582	CHEMBL486699,FN,ACT,0.009999999776482582	CHEMBL2160216,TP,ACT,0.9900000095367432	CHEMBL1257413,TN,INACT,0.6600000262260437	CHEMBL1629785,FP,INACT,0.9700000286102295	CHEMBL589565,TP,ACT,0.9800000190734863	CHEMBL3771233,FP,INACT,0.9800000190734863	CHEMBL19325,TN,INACT,0.009999999776482582	CHEMBL510363,TN,INACT,0.4699999988079071	CHEMBL3787613,FN,ACT,0.019999999552965164	CHEMBL329012,FN,ACT,0.019999999552965164	CHEMBL173694,TN,INACT,0.03999999910593033	CHEMBL3416649,TN,INACT,0.0	CHEMBL3818177,FP,INACT,0.8199999928474426	CHEMBL3116299,TP,ACT,0.9900000095367432	CHEMBL3764065,TN,INACT,0.029999999329447746	CHEMBL3581576,TN,INACT,0.019999999552965164	CHEMBL1085281,TN,INACT,0.07999999821186066	CHEMBL2296115,TN,INACT,0.0	CHEMBL3754778,TP,ACT,0.9900000095367432	CHEMBL2332538,TN,INACT,0.029999999329447746	CHEMBL3769862,TP,ACT,0.9300000071525574	CHEMBL360055,TN,INACT,0.05000000074505806	CHEMBL3237778,TN,INACT,0.009999999776482582	CHEMBL606034,TN,INACT,0.03999999910593033	CHEMBL1766019,TN,INACT,0.019999999552965164	CHEMBL2237293,TN,INACT,0.009999999776482582	CHEMBL453480,TN,INACT,0.029999999329447746	CHEMBL343673,TN,INACT,0.009999999776482582	CHEMBL80221,TP,ACT,0.949999988079071	CHEMBL3099496,TP,ACT,1.0	CHEMBL453096,FP,INACT,0.9399999976158142	CHEMBL2413734,TN,INACT,0.009999999776482582	CHEMBL2403496,TN,INACT,0.009999999776482582	CHEMBL376186,TP,ACT,0.949999988079071	CHEMBL2160219,FP,INACT,0.9900000095367432	CHEMBL3127383,TN,INACT,0.6100000143051147	CHEMBL277665,TN,INACT,0.019999999552965164	CHEMBL3754585,TN,INACT,0.019999999552965164	CHEMBL456131,TN,INACT,0.009999999776482582	CHEMBL2385784,TN,INACT,0.009999999776482582	CHEMBL1629786,TN,INACT,0.6800000071525574	CHEMBL3133309,TN,INACT,0.029999999329447746	CHEMBL216159,TP,ACT,1.0	CHEMBL120279,TP,ACT,0.9800000190734863	CHEMBL390083,FN,ACT,0.03999999910593033	CHEMBL3612818,FP,INACT,0.9399999976158142	CHEMBL3402288,TN,INACT,0.6100000143051147	CHEMBL422905,TN,INACT,0.07000000029802322	CHEMBL3335048,TP,ACT,0.949999988079071	CHEMBL292314,FN,ACT,0.3100000023841858	CHEMBL107892,TP,ACT,0.8500000238418579	CHEMBL187385,TP,ACT,0.9700000286102295	CHEMBL3311549,TN,INACT,0.12999999523162842	CHEMBL3628060,TP,ACT,1.0	CHEMBL176366,FN,ACT,0.3400000035762787	CHEMBL335033,FN,ACT,0.3100000023841858	CHEMBL3754480,TP,ACT,1.0	CHEMBL294413,FP,INACT,0.9200000166893005	CHEMBL340171,TP,ACT,1.0	CHEMBL538358,FP,INACT,1.0	CHEMBL2113016,TN,INACT,0.5	CHEMBL2047528,TP,ACT,1.0	CHEMBL3745983,TN,INACT,0.15000000596046448	CHEMBL1819172,TP,ACT,1.0	CHEMBL3093799,FN,ACT,0.6600000262260437	CHEMBL428683,TN,INACT,0.009999999776482582	CHEMBL3818689,FN,ACT,0.47999998927116394	CHEMBL192627,FN,ACT,0.019999999552965164	CHEMBL105537,TP,ACT,1.0	CHEMBL222378,TP,ACT,0.949999988079071	CHEMBL447232,TP,ACT,0.7300000190734863	CHEMBL2334744,TN,INACT,0.009999999776482582	CHEMBL447857,FP,INACT,0.9399999976158142	CHEMBL1094972,TN,INACT,0.009999999776482582	CHEMBL357492,TN,INACT,0.33000001311302185	CHEMBL388615,TP,ACT,1.0	CHEMBL3822890,TP,ACT,0.9900000095367432	CHEMBL2375925,TN,INACT,0.019999999552965164	CHEMBL2375929,TN,INACT,0.009999999776482582	CHEMBL3754448,FN,ACT,0.6600000262260437	CHEMBL3133314,TN,INACT,0.6299999952316284	CHEMBL42531,FN,ACT,0.07000000029802322	CHEMBL274029,TN,INACT,0.1599999964237213	CHEMBL3335023,TN,INACT,0.029999999329447746	CHEMBL125278,TN,INACT,0.44999998807907104	CHEMBL3621334,FN,ACT,0.36000001430511475	CHEMBL1086014,TN,INACT,0.029999999329447746	CHEMBL243055,TP,ACT,0.9800000190734863	CHEMBL544592,TP,ACT,0.9700000286102295	CHEMBL3127020,TN,INACT,0.20999999344348907	CHEMBL330299,FN,ACT,0.5899999737739563	CHEMBL75743,TP,ACT,0.9599999785423279	CHEMBL340854,TN,INACT,0.009999999776482582	CHEMBL3818061,FP,INACT,0.8700000047683716	

