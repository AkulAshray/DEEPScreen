ImageNetInceptionV2 CHEMBL3465 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	149
Number of inactive compounds :	130
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3465_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3465_adam_0.0005_30_0.8/
---------------------------------
Training samples: 178
Validation samples: 56
--
Training Step: 1  | time: 69.639s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/178
[A[ATraining Step: 2  | total loss: [1m[32m0.67989[0m[0m | time: 83.283s
[2K
| Adam | epoch: 001 | loss: 0.67989 - acc: 0.3937 -- iter: 064/178
[A[ATraining Step: 3  | total loss: [1m[32m0.60445[0m[0m | time: 96.937s
[2K
| Adam | epoch: 001 | loss: 0.60445 - acc: 0.6597 -- iter: 096/178
[A[ATraining Step: 4  | total loss: [1m[32m0.50946[0m[0m | time: 109.992s
[2K
| Adam | epoch: 001 | loss: 0.50946 - acc: 0.7509 -- iter: 128/178
[A[ATraining Step: 5  | total loss: [1m[32m0.54962[0m[0m | time: 123.348s
[2K
| Adam | epoch: 001 | loss: 0.54962 - acc: 0.7719 -- iter: 160/178
[A[ATraining Step: 6  | total loss: [1m[32m0.54178[0m[0m | time: 146.495s
[2K
| Adam | epoch: 001 | loss: 0.54178 - acc: 0.7779 | val_loss: 0.98831 - val_acc: 0.6429 -- iter: 178/178
--
Training Step: 7  | total loss: [1m[32m0.66703[0m[0m | time: 7.923s
[2K
| Adam | epoch: 002 | loss: 0.66703 - acc: 0.6112 -- iter: 032/178
[A[ATraining Step: 8  | total loss: [1m[32m0.43563[0m[0m | time: 20.286s
[2K
| Adam | epoch: 002 | loss: 0.43563 - acc: 0.8299 -- iter: 064/178
[A[ATraining Step: 9  | total loss: [1m[32m0.43758[0m[0m | time: 32.873s
[2K
| Adam | epoch: 002 | loss: 0.43758 - acc: 0.8041 -- iter: 096/178
[A[ATraining Step: 10  | total loss: [1m[32m0.39938[0m[0m | time: 45.271s
[2K
| Adam | epoch: 002 | loss: 0.39938 - acc: 0.8396 -- iter: 128/178
[A[ATraining Step: 11  | total loss: [1m[32m0.39741[0m[0m | time: 57.584s
[2K
| Adam | epoch: 002 | loss: 0.39741 - acc: 0.8415 -- iter: 160/178
[A[ATraining Step: 12  | total loss: [1m[32m0.31119[0m[0m | time: 75.374s
[2K
| Adam | epoch: 002 | loss: 0.31119 - acc: 0.8847 | val_loss: 0.68813 - val_acc: 0.6429 -- iter: 178/178
--
Training Step: 13  | total loss: [1m[32m0.33161[0m[0m | time: 7.451s
[2K
| Adam | epoch: 003 | loss: 0.33161 - acc: 0.8806 -- iter: 032/178
[A[ATraining Step: 14  | total loss: [1m[32m0.31098[0m[0m | time: 15.605s
[2K
| Adam | epoch: 003 | loss: 0.31098 - acc: 0.8840 -- iter: 064/178
[A[ATraining Step: 15  | total loss: [1m[32m0.21920[0m[0m | time: 28.027s
[2K
| Adam | epoch: 003 | loss: 0.21920 - acc: 0.9294 -- iter: 096/178
[A[ATraining Step: 16  | total loss: [1m[32m0.28936[0m[0m | time: 40.465s
[2K
| Adam | epoch: 003 | loss: 0.28936 - acc: 0.9090 -- iter: 128/178
[A[ATraining Step: 17  | total loss: [1m[32m0.26849[0m[0m | time: 53.913s
[2K
| Adam | epoch: 003 | loss: 0.26849 - acc: 0.9192 -- iter: 160/178
[A[ATraining Step: 18  | total loss: [1m[32m0.22553[0m[0m | time: 70.833s
[2K
| Adam | epoch: 003 | loss: 0.22553 - acc: 0.9256 | val_loss: 0.68582 - val_acc: 0.6429 -- iter: 178/178
--
Training Step: 19  | total loss: [1m[32m0.21730[0m[0m | time: 12.365s
[2K
| Adam | epoch: 004 | loss: 0.21730 - acc: 0.9295 -- iter: 032/178
[A[ATraining Step: 20  | total loss: [1m[32m0.17888[0m[0m | time: 20.309s
[2K
| Adam | epoch: 004 | loss: 0.17888 - acc: 0.9522 -- iter: 064/178
[A[ATraining Step: 21  | total loss: [1m[32m0.14109[0m[0m | time: 28.160s
[2K
| Adam | epoch: 004 | loss: 0.14109 - acc: 0.9670 -- iter: 096/178
[A[ATraining Step: 22  | total loss: [1m[32m0.10908[0m[0m | time: 40.075s
[2K
| Adam | epoch: 004 | loss: 0.10908 - acc: 0.9769 -- iter: 128/178
[A[ATraining Step: 23  | total loss: [1m[32m0.10724[0m[0m | time: 52.410s
[2K
| Adam | epoch: 004 | loss: 0.10724 - acc: 0.9745 -- iter: 160/178
[A[ATraining Step: 24  | total loss: [1m[32m0.09257[0m[0m | time: 68.711s
[2K
| Adam | epoch: 004 | loss: 0.09257 - acc: 0.9817 | val_loss: 0.94626 - val_acc: 0.6429 -- iter: 178/178
--
Training Step: 25  | total loss: [1m[32m0.13720[0m[0m | time: 11.638s
[2K
| Adam | epoch: 005 | loss: 0.13720 - acc: 0.9697 -- iter: 032/178
[A[ATraining Step: 26  | total loss: [1m[32m0.12062[0m[0m | time: 25.020s
[2K
| Adam | epoch: 005 | loss: 0.12062 - acc: 0.9694 -- iter: 064/178
[A[ATraining Step: 27  | total loss: [1m[32m0.11794[0m[0m | time: 33.009s
[2K
| Adam | epoch: 005 | loss: 0.11794 - acc: 0.9692 -- iter: 096/178
[A[ATraining Step: 28  | total loss: [1m[32m0.09438[0m[0m | time: 41.015s
[2K
| Adam | epoch: 005 | loss: 0.09438 - acc: 0.9769 -- iter: 128/178
[A[ATraining Step: 29  | total loss: [1m[32m0.07563[0m[0m | time: 53.244s
[2K
| Adam | epoch: 005 | loss: 0.07563 - acc: 0.9825 -- iter: 160/178
[A[ATraining Step: 30  | total loss: [1m[32m0.06879[0m[0m | time: 69.144s
[2K
| Adam | epoch: 005 | loss: 0.06879 - acc: 0.9867 | val_loss: 0.69198 - val_acc: 0.3571 -- iter: 178/178
--
Training Step: 31  | total loss: [1m[32m0.07735[0m[0m | time: 12.256s
[2K
| Adam | epoch: 006 | loss: 0.07735 - acc: 0.9753 -- iter: 032/178
[A[ATraining Step: 32  | total loss: [1m[32m0.06852[0m[0m | time: 24.595s
[2K
| Adam | epoch: 006 | loss: 0.06852 - acc: 0.9809 -- iter: 064/178
[A[ATraining Step: 33  | total loss: [1m[32m0.08594[0m[0m | time: 36.907s
[2K
| Adam | epoch: 006 | loss: 0.08594 - acc: 0.9714 -- iter: 096/178
[A[ATraining Step: 34  | total loss: [1m[32m0.13089[0m[0m | time: 44.636s
[2K
| Adam | epoch: 006 | loss: 0.13089 - acc: 0.9574 -- iter: 128/178
[A[ATraining Step: 35  | total loss: [1m[32m0.17473[0m[0m | time: 52.632s
[2K
| Adam | epoch: 006 | loss: 0.17473 - acc: 0.9431 -- iter: 160/178
[A[ATraining Step: 36  | total loss: [1m[32m0.15464[0m[0m | time: 69.156s
[2K
| Adam | epoch: 006 | loss: 0.15464 - acc: 0.9547 | val_loss: 0.96176 - val_acc: 0.3571 -- iter: 178/178
--
Training Step: 37  | total loss: [1m[32m0.13605[0m[0m | time: 12.219s
[2K
| Adam | epoch: 007 | loss: 0.13605 - acc: 0.9575 -- iter: 032/178
[A[ATraining Step: 38  | total loss: [1m[32m0.16720[0m[0m | time: 23.855s
[2K
| Adam | epoch: 007 | loss: 0.16720 - acc: 0.9536 -- iter: 064/178
[A[ATraining Step: 39  | total loss: [1m[32m0.14256[0m[0m | time: 36.239s
[2K
| Adam | epoch: 007 | loss: 0.14256 - acc: 0.9625 -- iter: 096/178
[A[ATraining Step: 40  | total loss: [1m[32m0.11755[0m[0m | time: 49.018s
[2K
| Adam | epoch: 007 | loss: 0.11755 - acc: 0.9695 -- iter: 128/178
[A[ATraining Step: 41  | total loss: [1m[32m0.09688[0m[0m | time: 56.798s
[2K
| Adam | epoch: 007 | loss: 0.09688 - acc: 0.9751 -- iter: 160/178
[A[ATraining Step: 42  | total loss: [1m[32m0.08191[0m[0m | time: 64.565s
[2K
| Adam | epoch: 007 | loss: 0.08191 - acc: 0.9796 | val_loss: 1.25394 - val_acc: 0.3571 -- iter: 178/178
--
Training Step: 43  | total loss: [1m[32m0.06857[0m[0m | time: 10.104s
[2K
| Adam | epoch: 008 | loss: 0.06857 - acc: 0.9832 -- iter: 032/178
[A[ATraining Step: 44  | total loss: [1m[32m0.10582[0m[0m | time: 21.961s
[2K
| Adam | epoch: 008 | loss: 0.10582 - acc: 0.9753 -- iter: 064/178
[A[ATraining Step: 45  | total loss: [1m[32m0.09436[0m[0m | time: 34.333s
[2K
| Adam | epoch: 008 | loss: 0.09436 - acc: 0.9742 -- iter: 096/178
[A[ATraining Step: 46  | total loss: [1m[32m0.08269[0m[0m | time: 46.693s
[2K
| Adam | epoch: 008 | loss: 0.08269 - acc: 0.9785 -- iter: 128/178
[A[ATraining Step: 47  | total loss: [1m[32m0.07373[0m[0m | time: 58.373s
[2K
| Adam | epoch: 008 | loss: 0.07373 - acc: 0.9820 -- iter: 160/178
[A[ATraining Step: 48  | total loss: [1m[32m0.07420[0m[0m | time: 70.218s
[2K
| Adam | epoch: 008 | loss: 0.07420 - acc: 0.9799 | val_loss: 1.90901 - val_acc: 0.3571 -- iter: 178/178
--
Training Step: 49  | total loss: [1m[32m0.06625[0m[0m | time: 7.353s
[2K
| Adam | epoch: 009 | loss: 0.06625 - acc: 0.9831 -- iter: 032/178
[A[ATraining Step: 50  | total loss: [1m[32m0.05686[0m[0m | time: 19.145s
[2K
| Adam | epoch: 009 | loss: 0.05686 - acc: 0.9857 -- iter: 064/178
[A[ATraining Step: 51  | total loss: [1m[32m0.06081[0m[0m | time: 31.121s
[2K
| Adam | epoch: 009 | loss: 0.06081 - acc: 0.9783 -- iter: 096/178
[A[ATraining Step: 52  | total loss: [1m[32m0.10533[0m[0m | time: 42.373s
[2K
| Adam | epoch: 009 | loss: 0.10533 - acc: 0.9769 -- iter: 128/178
[A[ATraining Step: 53  | total loss: [1m[32m0.09539[0m[0m | time: 53.550s
[2K
| Adam | epoch: 009 | loss: 0.09539 - acc: 0.9803 -- iter: 160/178
[A[ATraining Step: 54  | total loss: [1m[32m0.08235[0m[0m | time: 69.891s
[2K
| Adam | epoch: 009 | loss: 0.08235 - acc: 0.9832 | val_loss: 1.23696 - val_acc: 0.4643 -- iter: 178/178
--
Training Step: 55  | total loss: [1m[32m0.07295[0m[0m | time: 8.081s
[2K
| Adam | epoch: 010 | loss: 0.07295 - acc: 0.9856 -- iter: 032/178
[A[ATraining Step: 56  | total loss: [1m[32m0.07399[0m[0m | time: 15.893s
[2K
| Adam | epoch: 010 | loss: 0.07399 - acc: 0.9798 -- iter: 064/178
[A[ATraining Step: 57  | total loss: [1m[32m0.06597[0m[0m | time: 29.319s
[2K
| Adam | epoch: 010 | loss: 0.06597 - acc: 0.9826 -- iter: 096/178
[A[ATraining Step: 58  | total loss: [1m[32m0.06418[0m[0m | time: 41.416s
[2K
| Adam | epoch: 010 | loss: 0.06418 - acc: 0.9807 -- iter: 128/178
[A[ATraining Step: 59  | total loss: [1m[32m0.05831[0m[0m | time: 53.369s
[2K
| Adam | epoch: 010 | loss: 0.05831 - acc: 0.9833 -- iter: 160/178
[A[ATraining Step: 60  | total loss: [1m[32m0.05439[0m[0m | time: 69.855s
[2K
| Adam | epoch: 010 | loss: 0.05439 - acc: 0.9855 | val_loss: 0.77923 - val_acc: 0.6964 -- iter: 178/178
--
Training Step: 61  | total loss: [1m[32m0.04853[0m[0m | time: 12.224s
[2K
| Adam | epoch: 011 | loss: 0.04853 - acc: 0.9874 -- iter: 032/178
[A[ATraining Step: 62  | total loss: [1m[32m0.04366[0m[0m | time: 19.857s
[2K
| Adam | epoch: 011 | loss: 0.04366 - acc: 0.9890 -- iter: 064/178
[A[ATraining Step: 63  | total loss: [1m[32m0.03867[0m[0m | time: 27.670s
[2K
| Adam | epoch: 011 | loss: 0.03867 - acc: 0.9904 -- iter: 096/178
[A[ATraining Step: 64  | total loss: [1m[32m0.03419[0m[0m | time: 39.968s
[2K
| Adam | epoch: 011 | loss: 0.03419 - acc: 0.9916 -- iter: 128/178
[A[ATraining Step: 65  | total loss: [1m[32m0.05172[0m[0m | time: 52.362s
[2K
| Adam | epoch: 011 | loss: 0.05172 - acc: 0.9849 -- iter: 160/178
[A[ATraining Step: 66  | total loss: [1m[32m0.08576[0m[0m | time: 68.510s
[2K
| Adam | epoch: 011 | loss: 0.08576 - acc: 0.9830 | val_loss: 1.00710 - val_acc: 0.8036 -- iter: 178/178
--
Training Step: 67  | total loss: [1m[32m0.07906[0m[0m | time: 8.800s
[2K
| Adam | epoch: 012 | loss: 0.07906 - acc: 0.9850 -- iter: 032/178
[A[ATraining Step: 68  | total loss: [1m[32m0.07028[0m[0m | time: 20.786s
[2K
| Adam | epoch: 012 | loss: 0.07028 - acc: 0.9868 -- iter: 064/178
[A[ATraining Step: 69  | total loss: [1m[32m0.06281[0m[0m | time: 28.435s
[2K
| Adam | epoch: 012 | loss: 0.06281 - acc: 0.9883 -- iter: 096/178
[A[ATraining Step: 70  | total loss: [1m[32m0.08141[0m[0m | time: 36.521s
[2K
| Adam | epoch: 012 | loss: 0.08141 - acc: 0.9769 -- iter: 128/178
[A[ATraining Step: 71  | total loss: [1m[32m0.07401[0m[0m | time: 48.755s
[2K
| Adam | epoch: 012 | loss: 0.07401 - acc: 0.9795 -- iter: 160/178
[A[ATraining Step: 72  | total loss: [1m[32m0.09239[0m[0m | time: 65.028s
[2K
| Adam | epoch: 012 | loss: 0.09239 - acc: 0.9783 | val_loss: 4.43353 - val_acc: 0.3571 -- iter: 178/178
--
Training Step: 73  | total loss: [1m[32m0.08567[0m[0m | time: 12.297s
[2K
| Adam | epoch: 013 | loss: 0.08567 - acc: 0.9772 -- iter: 032/178
[A[ATraining Step: 74  | total loss: [1m[32m0.07695[0m[0m | time: 24.789s
[2K
| Adam | epoch: 013 | loss: 0.07695 - acc: 0.9797 -- iter: 064/178
[A[ATraining Step: 75  | total loss: [1m[32m0.07587[0m[0m | time: 36.826s
[2K
| Adam | epoch: 013 | loss: 0.07587 - acc: 0.9785 -- iter: 096/178
[A[ATraining Step: 76  | total loss: [1m[32m0.06946[0m[0m | time: 44.884s
[2K
| Adam | epoch: 013 | loss: 0.06946 - acc: 0.9808 -- iter: 128/178
[A[ATraining Step: 77  | total loss: [1m[32m0.06529[0m[0m | time: 52.543s
[2K
| Adam | epoch: 013 | loss: 0.06529 - acc: 0.9829 -- iter: 160/178
[A[ATraining Step: 78  | total loss: [1m[32m0.06048[0m[0m | time: 67.256s
[2K
| Adam | epoch: 013 | loss: 0.06048 - acc: 0.9847 | val_loss: 1.78496 - val_acc: 0.4643 -- iter: 178/178
--
Training Step: 79  | total loss: [1m[32m0.06280[0m[0m | time: 12.218s
[2K
| Adam | epoch: 014 | loss: 0.06280 - acc: 0.9830 -- iter: 032/178
[A[ATraining Step: 80  | total loss: [1m[32m0.05807[0m[0m | time: 27.804s
[2K
| Adam | epoch: 014 | loss: 0.05807 - acc: 0.9847 -- iter: 064/178
[A[ATraining Step: 81  | total loss: [1m[32m0.05428[0m[0m | time: 40.339s
[2K
| Adam | epoch: 014 | loss: 0.05428 - acc: 0.9863 -- iter: 096/178
[A[ATraining Step: 82  | total loss: [1m[32m0.04920[0m[0m | time: 52.606s
[2K
| Adam | epoch: 014 | loss: 0.04920 - acc: 0.9877 -- iter: 128/178
[A[ATraining Step: 83  | total loss: [1m[32m0.04445[0m[0m | time: 60.632s
[2K
| Adam | epoch: 014 | loss: 0.04445 - acc: 0.9889 -- iter: 160/178
[A[ATraining Step: 84  | total loss: [1m[32m0.04055[0m[0m | time: 72.812s
[2K
| Adam | epoch: 014 | loss: 0.04055 - acc: 0.9900 | val_loss: 0.90496 - val_acc: 0.8036 -- iter: 178/178
--
Training Step: 85  | total loss: [1m[32m0.03708[0m[0m | time: 12.497s
[2K
| Adam | epoch: 015 | loss: 0.03708 - acc: 0.9910 -- iter: 032/178
[A[ATraining Step: 86  | total loss: [1m[32m0.03374[0m[0m | time: 25.060s
[2K
| Adam | epoch: 015 | loss: 0.03374 - acc: 0.9919 -- iter: 064/178
[A[ATraining Step: 87  | total loss: [1m[32m0.09343[0m[0m | time: 40.261s
[2K
| Adam | epoch: 015 | loss: 0.09343 - acc: 0.9833 -- iter: 096/178
[A[ATraining Step: 88  | total loss: [1m[32m0.08436[0m[0m | time: 55.885s
[2K
| Adam | epoch: 015 | loss: 0.08436 - acc: 0.9850 -- iter: 128/178
[A[ATraining Step: 89  | total loss: [1m[32m0.09539[0m[0m | time: 71.465s
[2K
| Adam | epoch: 015 | loss: 0.09539 - acc: 0.9803 -- iter: 160/178
[A[ATraining Step: 90  | total loss: [1m[32m0.08690[0m[0m | time: 87.164s
[2K
| Adam | epoch: 015 | loss: 0.08690 - acc: 0.9822 | val_loss: 1.57841 - val_acc: 0.7143 -- iter: 178/178
--
Training Step: 91  | total loss: [1m[32m0.08130[0m[0m | time: 14.418s
[2K
| Adam | epoch: 016 | loss: 0.08130 - acc: 0.9840 -- iter: 032/178
[A[ATraining Step: 92  | total loss: [1m[32m0.07453[0m[0m | time: 54.180s
[2K
| Adam | epoch: 016 | loss: 0.07453 - acc: 0.9856 -- iter: 064/178
[A[ATraining Step: 93  | total loss: [1m[32m0.06921[0m[0m | time: 201.801s
[2K
| Adam | epoch: 016 | loss: 0.06921 - acc: 0.9870 -- iter: 096/178
[A[ATraining Step: 94  | total loss: [1m[32m0.14521[0m[0m | time: 344.906s
[2K
| Adam | epoch: 016 | loss: 0.14521 - acc: 0.9790 -- iter: 128/178
[A[ATraining Step: 95  | total loss: [1m[32m0.13241[0m[0m | time: 435.579s
[2K
| Adam | epoch: 016 | loss: 0.13241 - acc: 0.9811 -- iter: 160/178
[A[ATraining Step: 96  | total loss: [1m[32m0.12796[0m[0m | time: 456.194s
[2K
| Adam | epoch: 016 | loss: 0.12796 - acc: 0.9767 | val_loss: 0.20438 - val_acc: 0.9107 -- iter: 178/178
--
Training Step: 97  | total loss: [1m[32m0.12197[0m[0m | time: 11.823s
[2K
| Adam | epoch: 017 | loss: 0.12197 - acc: 0.9759 -- iter: 032/178
[A[ATraining Step: 98  | total loss: [1m[32m0.11121[0m[0m | time: 24.177s
[2K
| Adam | epoch: 017 | loss: 0.11121 - acc: 0.9783 -- iter: 064/178
[A[ATraining Step: 99  | total loss: [1m[32m0.10118[0m[0m | time: 42.938s
[2K
| Adam | epoch: 017 | loss: 0.10118 - acc: 0.9805 -- iter: 096/178
[A[ATraining Step: 100  | total loss: [1m[32m0.09254[0m[0m | time: 61.110s
[2K
| Adam | epoch: 017 | loss: 0.09254 - acc: 0.9824 -- iter: 128/178
[A[ATraining Step: 101  | total loss: [1m[32m0.14192[0m[0m | time: 79.676s
[2K
| Adam | epoch: 017 | loss: 0.14192 - acc: 0.9748 -- iter: 160/178
[A[ATraining Step: 102  | total loss: [1m[32m0.12923[0m[0m | time: 105.889s
[2K
| Adam | epoch: 017 | loss: 0.12923 - acc: 0.9773 | val_loss: 0.30856 - val_acc: 0.8571 -- iter: 178/178
--
Training Step: 103  | total loss: [1m[32m0.11868[0m[0m | time: 19.383s
[2K
| Adam | epoch: 018 | loss: 0.11868 - acc: 0.9796 -- iter: 032/178
[A[ATraining Step: 104  | total loss: [1m[32m0.11079[0m[0m | time: 31.273s
[2K
| Adam | epoch: 018 | loss: 0.11079 - acc: 0.9816 -- iter: 064/178
[A[ATraining Step: 105  | total loss: [1m[32m0.13045[0m[0m | time: 43.385s
[2K
| Adam | epoch: 018 | loss: 0.13045 - acc: 0.9779 -- iter: 096/178
[A[ATraining Step: 106  | total loss: [1m[32m0.12543[0m[0m | time: 62.091s
[2K
| Adam | epoch: 018 | loss: 0.12543 - acc: 0.9746 -- iter: 128/178
[A[ATraining Step: 107  | total loss: [1m[32m0.11996[0m[0m | time: 78.175s
[2K
| Adam | epoch: 018 | loss: 0.11996 - acc: 0.9740 -- iter: 160/178
[A[ATraining Step: 108  | total loss: [1m[32m0.11025[0m[0m | time: 99.802s
[2K
| Adam | epoch: 018 | loss: 0.11025 - acc: 0.9766 | val_loss: 0.34276 - val_acc: 0.8750 -- iter: 178/178
--
Training Step: 109  | total loss: [1m[32m0.10104[0m[0m | time: 13.187s
[2K
| Adam | epoch: 019 | loss: 0.10104 - acc: 0.9789 -- iter: 032/178
[A[ATraining Step: 110  | total loss: [1m[32m0.09462[0m[0m | time: 26.518s
[2K
| Adam | epoch: 019 | loss: 0.09462 - acc: 0.9810 -- iter: 064/178
[A[ATraining Step: 111  | total loss: [1m[32m0.09175[0m[0m | time: 38.343s
[2K
| Adam | epoch: 019 | loss: 0.09175 - acc: 0.9798 -- iter: 096/178
[A[ATraining Step: 112  | total loss: [1m[32m0.09423[0m[0m | time: 50.873s
[2K
| Adam | epoch: 019 | loss: 0.09423 - acc: 0.9763 -- iter: 128/178
[A[ATraining Step: 113  | total loss: [1m[32m0.08949[0m[0m | time: 68.611s
[2K
| Adam | epoch: 019 | loss: 0.08949 - acc: 0.9786 -- iter: 160/178
[A[ATraining Step: 114  | total loss: [1m[32m0.08200[0m[0m | time: 95.102s
[2K
| Adam | epoch: 019 | loss: 0.08200 - acc: 0.9808 | val_loss: 0.59117 - val_acc: 0.8393 -- iter: 178/178
--
Training Step: 115  | total loss: [1m[32m0.25451[0m[0m | time: 19.616s
[2K
| Adam | epoch: 020 | loss: 0.25451 - acc: 0.9515 -- iter: 032/178
[A[ATraining Step: 116  | total loss: [1m[32m0.23326[0m[0m | time: 34.836s
[2K
| Adam | epoch: 020 | loss: 0.23326 - acc: 0.9563 -- iter: 064/178
[A[ATraining Step: 117  | total loss: [1m[32m0.21392[0m[0m | time: 50.323s
[2K
| Adam | epoch: 020 | loss: 0.21392 - acc: 0.9607 -- iter: 096/178
[A[ATraining Step: 118  | total loss: [1m[32m0.20038[0m[0m | time: 60.289s
[2K
| Adam | epoch: 020 | loss: 0.20038 - acc: 0.9646 -- iter: 128/178
[A[ATraining Step: 119  | total loss: [1m[32m0.19879[0m[0m | time: 70.807s
[2K
| Adam | epoch: 020 | loss: 0.19879 - acc: 0.9570 -- iter: 160/178
[A[ATraining Step: 120  | total loss: [1m[32m0.18236[0m[0m | time: 91.170s
[2K
| Adam | epoch: 020 | loss: 0.18236 - acc: 0.9613 | val_loss: 1.94575 - val_acc: 0.3750 -- iter: 178/178
--
Training Step: 121  | total loss: [1m[32m0.16817[0m[0m | time: 15.740s
[2K
| Adam | epoch: 021 | loss: 0.16817 - acc: 0.9652 -- iter: 032/178
[A[ATraining Step: 122  | total loss: [1m[32m0.17479[0m[0m | time: 30.910s
[2K
| Adam | epoch: 021 | loss: 0.17479 - acc: 0.9656 -- iter: 064/178
[A[ATraining Step: 123  | total loss: [1m[32m0.16629[0m[0m | time: 46.076s
[2K
| Adam | epoch: 021 | loss: 0.16629 - acc: 0.9690 -- iter: 096/178
[A[ATraining Step: 124  | total loss: [1m[32m0.16157[0m[0m | time: 61.018s
[2K
| Adam | epoch: 021 | loss: 0.16157 - acc: 0.9690 -- iter: 128/178
[A[ATraining Step: 125  | total loss: [1m[32m0.14730[0m[0m | time: 71.436s
[2K
| Adam | epoch: 021 | loss: 0.14730 - acc: 0.9721 -- iter: 160/178
[A[ATraining Step: 126  | total loss: [1m[32m0.13597[0m[0m | time: 86.528s
[2K
| Adam | epoch: 021 | loss: 0.13597 - acc: 0.9749 | val_loss: 0.47922 - val_acc: 0.8393 -- iter: 178/178
--
Training Step: 127  | total loss: [1m[32m0.12406[0m[0m | time: 16.294s
[2K
| Adam | epoch: 022 | loss: 0.12406 - acc: 0.9774 -- iter: 032/178
[A[ATraining Step: 128  | total loss: [1m[32m0.11362[0m[0m | time: 31.529s
[2K
| Adam | epoch: 022 | loss: 0.11362 - acc: 0.9796 -- iter: 064/178
[A[ATraining Step: 129  | total loss: [1m[32m0.25535[0m[0m | time: 41.261s
[2K
| Adam | epoch: 022 | loss: 0.25535 - acc: 0.9536 -- iter: 096/178
[A[ATraining Step: 130  | total loss: [1m[32m0.23516[0m[0m | time: 51.419s
[2K
| Adam | epoch: 022 | loss: 0.23516 - acc: 0.9551 -- iter: 128/178
[A[ATraining Step: 131  | total loss: [1m[32m0.21439[0m[0m | time: 62.953s
[2K
| Adam | epoch: 022 | loss: 0.21439 - acc: 0.9596 -- iter: 160/178
[A[ATraining Step: 132  | total loss: [1m[32m0.20235[0m[0m | time: 77.631s
[2K
| Adam | epoch: 022 | loss: 0.20235 - acc: 0.9605 | val_loss: 0.42665 - val_acc: 0.8036 -- iter: 178/178
--
Training Step: 133  | total loss: [1m[32m0.19751[0m[0m | time: 10.263s
[2K
| Adam | epoch: 023 | loss: 0.19751 - acc: 0.9589 -- iter: 032/178
[A[ATraining Step: 134  | total loss: [1m[32m0.18254[0m[0m | time: 25.617s
[2K
| Adam | epoch: 023 | loss: 0.18254 - acc: 0.9630 -- iter: 064/178
[A[ATraining Step: 135  | total loss: [1m[32m0.16651[0m[0m | time: 41.132s
[2K
| Adam | epoch: 023 | loss: 0.16651 - acc: 0.9667 -- iter: 096/178
[A[ATraining Step: 136  | total loss: [1m[32m0.16872[0m[0m | time: 56.582s
[2K
| Adam | epoch: 023 | loss: 0.16872 - acc: 0.9669 -- iter: 128/178
[A[ATraining Step: 137  | total loss: [1m[32m0.17043[0m[0m | time: 72.699s
[2K
| Adam | epoch: 023 | loss: 0.17043 - acc: 0.9577 -- iter: 160/178
[A[ATraining Step: 138  | total loss: [1m[32m0.17390[0m[0m | time: 93.351s
[2K
| Adam | epoch: 023 | loss: 0.17390 - acc: 0.9526 | val_loss: 3.32489 - val_acc: 0.3571 -- iter: 178/178
--
Training Step: 139  | total loss: [1m[32m0.16013[0m[0m | time: 8.135s
[2K
| Adam | epoch: 024 | loss: 0.16013 - acc: 0.9573 -- iter: 032/178
[A[ATraining Step: 140  | total loss: [1m[32m0.15002[0m[0m | time: 16.315s
[2K
| Adam | epoch: 024 | loss: 0.15002 - acc: 0.9616 -- iter: 064/178
[A[ATraining Step: 141  | total loss: [1m[32m0.13735[0m[0m | time: 28.974s
[2K
| Adam | epoch: 024 | loss: 0.13735 - acc: 0.9654 -- iter: 096/178
[A[ATraining Step: 142  | total loss: [1m[32m0.12900[0m[0m | time: 41.390s
[2K
| Adam | epoch: 024 | loss: 0.12900 - acc: 0.9689 -- iter: 128/178
[A[ATraining Step: 143  | total loss: [1m[32m0.12361[0m[0m | time: 54.186s
[2K
| Adam | epoch: 024 | loss: 0.12361 - acc: 0.9720 -- iter: 160/178
[A[ATraining Step: 144  | total loss: [1m[32m0.11344[0m[0m | time: 71.141s
[2K
| Adam | epoch: 024 | loss: 0.11344 - acc: 0.9748 | val_loss: 6.02582 - val_acc: 0.3571 -- iter: 178/178
--
Training Step: 145  | total loss: [1m[32m0.10430[0m[0m | time: 12.525s
[2K
| Adam | epoch: 025 | loss: 0.10430 - acc: 0.9773 -- iter: 032/178
[A[ATraining Step: 146  | total loss: [1m[32m0.09503[0m[0m | time: 20.998s
[2K
| Adam | epoch: 025 | loss: 0.09503 - acc: 0.9796 -- iter: 064/178
[A[ATraining Step: 147  | total loss: [1m[32m0.08654[0m[0m | time: 29.672s
[2K
| Adam | epoch: 025 | loss: 0.08654 - acc: 0.9816 -- iter: 096/178
[A[ATraining Step: 148  | total loss: [1m[32m0.07887[0m[0m | time: 38.754s
[2K
| Adam | epoch: 025 | loss: 0.07887 - acc: 0.9835 -- iter: 128/178
[A[ATraining Step: 149  | total loss: [1m[32m0.07960[0m[0m | time: 46.559s
[2K
| Adam | epoch: 025 | loss: 0.07960 - acc: 0.9820 -- iter: 160/178
[A[ATraining Step: 150  | total loss: [1m[32m0.07259[0m[0m | time: 57.037s
[2K
| Adam | epoch: 025 | loss: 0.07259 - acc: 0.9838 | val_loss: 1.10609 - val_acc: 0.6786 -- iter: 178/178
--
Training Step: 151  | total loss: [1m[32m0.06833[0m[0m | time: 12.430s
[2K
| Adam | epoch: 026 | loss: 0.06833 - acc: 0.9854 -- iter: 032/178
[A[ATraining Step: 152  | total loss: [1m[32m0.06217[0m[0m | time: 24.908s
[2K
| Adam | epoch: 026 | loss: 0.06217 - acc: 0.9869 -- iter: 064/178
[A[ATraining Step: 153  | total loss: [1m[32m0.05651[0m[0m | time: 32.961s
[2K
| Adam | epoch: 026 | loss: 0.05651 - acc: 0.9882 -- iter: 096/178
[A[ATraining Step: 154  | total loss: [1m[32m0.05249[0m[0m | time: 40.950s
[2K
| Adam | epoch: 026 | loss: 0.05249 - acc: 0.9894 -- iter: 128/178
[A[ATraining Step: 155  | total loss: [1m[32m0.04853[0m[0m | time: 53.087s
[2K
| Adam | epoch: 026 | loss: 0.04853 - acc: 0.9904 -- iter: 160/178
[A[ATraining Step: 156  | total loss: [1m[32m0.04453[0m[0m | time: 69.918s
[2K
| Adam | epoch: 026 | loss: 0.04453 - acc: 0.9914 | val_loss: 0.55535 - val_acc: 0.8214 -- iter: 178/178
--
Training Step: 157  | total loss: [1m[32m0.09283[0m[0m | time: 12.650s
[2K
| Adam | epoch: 027 | loss: 0.09283 - acc: 0.9829 -- iter: 032/178
[A[ATraining Step: 158  | total loss: [1m[32m0.08531[0m[0m | time: 25.267s
[2K
| Adam | epoch: 027 | loss: 0.08531 - acc: 0.9846 -- iter: 064/178
[A[ATraining Step: 159  | total loss: [1m[32m0.07773[0m[0m | time: 37.899s
[2K
| Adam | epoch: 027 | loss: 0.07773 - acc: 0.9861 -- iter: 096/178
[A[ATraining Step: 160  | total loss: [1m[32m0.07677[0m[0m | time: 45.675s
[2K
| Adam | epoch: 027 | loss: 0.07677 - acc: 0.9844 -- iter: 128/178
[A[ATraining Step: 161  | total loss: [1m[32m0.07015[0m[0m | time: 53.982s
[2K
| Adam | epoch: 027 | loss: 0.07015 - acc: 0.9859 -- iter: 160/178
[A[ATraining Step: 162  | total loss: [1m[32m0.06414[0m[0m | time: 70.676s
[2K
| Adam | epoch: 027 | loss: 0.06414 - acc: 0.9874 | val_loss: 0.43582 - val_acc: 0.8393 -- iter: 178/178
--
Training Step: 163  | total loss: [1m[32m0.05817[0m[0m | time: 12.546s
[2K
| Adam | epoch: 028 | loss: 0.05817 - acc: 0.9886 -- iter: 032/178
[A[ATraining Step: 164  | total loss: [1m[32m0.05421[0m[0m | time: 24.945s
[2K
| Adam | epoch: 028 | loss: 0.05421 - acc: 0.9898 -- iter: 064/178
[A[ATraining Step: 165  | total loss: [1m[32m0.04921[0m[0m | time: 37.827s
[2K
| Adam | epoch: 028 | loss: 0.04921 - acc: 0.9908 -- iter: 096/178
[A[ATraining Step: 166  | total loss: [1m[32m0.05728[0m[0m | time: 49.905s
[2K
| Adam | epoch: 028 | loss: 0.05728 - acc: 0.9886 -- iter: 128/178
[A[ATraining Step: 167  | total loss: [1m[32m0.05216[0m[0m | time: 55.014s
[2K
| Adam | epoch: 028 | loss: 0.05216 - acc: 0.9897 -- iter: 160/178
[A[ATraining Step: 168  | total loss: [1m[32m0.04743[0m[0m | time: 62.494s
[2K
| Adam | epoch: 028 | loss: 0.04743 - acc: 0.9907 | val_loss: 0.63730 - val_acc: 0.8036 -- iter: 178/178
--
Training Step: 169  | total loss: [1m[32m0.04310[0m[0m | time: 10.567s
[2K
| Adam | epoch: 029 | loss: 0.04310 - acc: 0.9917 -- iter: 032/178
[A[ATraining Step: 170  | total loss: [1m[32m0.04194[0m[0m | time: 22.607s
[2K
| Adam | epoch: 029 | loss: 0.04194 - acc: 0.9894 -- iter: 064/178
[A[ATraining Step: 171  | total loss: [1m[32m0.06126[0m[0m | time: 34.768s
[2K
| Adam | epoch: 029 | loss: 0.06126 - acc: 0.9873 -- iter: 096/178
[A[ATraining Step: 172  | total loss: [1m[32m0.05579[0m[0m | time: 47.414s
[2K
| Adam | epoch: 029 | loss: 0.05579 - acc: 0.9886 -- iter: 128/178
[A[ATraining Step: 173  | total loss: [1m[32m0.05127[0m[0m | time: 59.722s
[2K
| Adam | epoch: 029 | loss: 0.05127 - acc: 0.9897 -- iter: 160/178
[A[ATraining Step: 174  | total loss: [1m[32m0.04731[0m[0m | time: 72.281s
[2K
| Adam | epoch: 029 | loss: 0.04731 - acc: 0.9908 | val_loss: 0.49038 - val_acc: 0.8393 -- iter: 178/178
--
Training Step: 175  | total loss: [1m[32m0.04407[0m[0m | time: 8.106s
[2K
| Adam | epoch: 030 | loss: 0.04407 - acc: 0.9917 -- iter: 032/178
[A[ATraining Step: 176  | total loss: [1m[32m0.04074[0m[0m | time: 20.842s
[2K
| Adam | epoch: 030 | loss: 0.04074 - acc: 0.9925 -- iter: 064/178
[A[ATraining Step: 177  | total loss: [1m[32m0.03785[0m[0m | time: 33.299s
[2K
| Adam | epoch: 030 | loss: 0.03785 - acc: 0.9933 -- iter: 096/178
[A[ATraining Step: 178  | total loss: [1m[32m0.05526[0m[0m | time: 45.835s
[2K
| Adam | epoch: 030 | loss: 0.05526 - acc: 0.9908 -- iter: 128/178
[A[ATraining Step: 179  | total loss: [1m[32m0.05005[0m[0m | time: 58.354s
[2K
| Adam | epoch: 030 | loss: 0.05005 - acc: 0.9917 -- iter: 160/178
[A[ATraining Step: 180  | total loss: [1m[32m0.04950[0m[0m | time: 75.066s
[2K
| Adam | epoch: 030 | loss: 0.04950 - acc: 0.9894 | val_loss: 0.63148 - val_acc: 0.8393 -- iter: 178/178
--
Validation AUC:0.9402777777777778
Validation AUPRC:0.9698127066456896
Test AUC:0.9380645161290324
Test AUPRC:0.9526369847669656
BestTestF1Score	0.85	0.62	0.8	0.75	0.97	30	10	15	1	0.61
BestTestMCCScore	0.85	0.62	0.8	0.75	0.97	30	10	15	1	0.61
BestTestAccuracyScore	0.85	0.62	0.8	0.75	0.97	30	10	15	1	0.61
BestValidationF1Score	0.9	0.7	0.86	0.82	1.0	36	8	12	0	0.61
BestValidationMCC	0.9	0.7	0.86	0.82	1.0	36	8	12	0	0.61
BestValidationAccuracy	0.9	0.7	0.86	0.82	1.0	36	8	12	0	0.61
TestPredictions (Threshold:0.61)
CHEMBL136064,FN,ACT,0.47999998927116394	CHEMBL595988,TN,INACT,0.1599999964237213	CHEMBL2368897,FP,INACT,0.9599999785423279	CHEMBL3262519,TN,INACT,0.05999999865889549	CHEMBL343802,TP,ACT,0.8700000047683716	CHEMBL156577,TN,INACT,0.009999999776482582	CHEMBL136388,TP,ACT,1.0	CHEMBL562926,FP,INACT,0.8600000143051147	CHEMBL137776,TP,ACT,0.9700000286102295	CHEMBL71301,TP,ACT,0.9900000095367432	CHEMBL2368125,TP,ACT,1.0	CHEMBL139370,TP,ACT,1.0	CHEMBL2368893,FP,INACT,0.6899999976158142	CHEMBL2332504,TN,INACT,0.30000001192092896	CHEMBL522211,FP,INACT,0.9100000262260437	CHEMBL3262793,TN,INACT,0.0	CHEMBL139102,TP,ACT,1.0	CHEMBL3220543,TN,INACT,0.20999999344348907	CHEMBL2368130,TP,ACT,0.9900000095367432	CHEMBL2368128,TP,ACT,0.9900000095367432	CHEMBL539567,TP,ACT,1.0	CHEMBL545552,TP,ACT,0.9900000095367432	CHEMBL539553,TP,ACT,1.0	CHEMBL542881,TP,ACT,0.9900000095367432	CHEMBL99898,FP,INACT,0.7900000214576721	CHEMBL3246893,FP,INACT,0.9900000095367432	CHEMBL136781,TP,ACT,0.9900000095367432	CHEMBL3262532,TN,INACT,0.019999999552965164	CHEMBL2391372,FP,INACT,0.8500000238418579	CHEMBL543917,TP,ACT,1.0	CHEMBL137085,TP,ACT,1.0	CHEMBL291954,FP,INACT,0.949999988079071	CHEMBL2368133,TP,ACT,0.9800000190734863	CHEMBL540585,TP,ACT,0.9900000095367432	CHEMBL136621,TP,ACT,1.0	CHEMBL323256,TN,INACT,0.18000000715255737	CHEMBL542737,TP,ACT,1.0	CHEMBL259240,TN,INACT,0.05999999865889549	CHEMBL156576,TN,INACT,0.009999999776482582	CHEMBL136395,TP,ACT,1.0	CHEMBL136615,TP,ACT,0.9900000095367432	CHEMBL554678,TP,ACT,1.0	CHEMBL105511,TN,INACT,0.019999999552965164	CHEMBL389261,TN,INACT,0.3199999928474426	CHEMBL337810,TP,ACT,0.9800000190734863	CHEMBL3246898,TN,INACT,0.5899999737739563	CHEMBL552619,TP,ACT,0.9900000095367432	CHEMBL50348,FP,INACT,0.9900000095367432	CHEMBL136590,TP,ACT,1.0	CHEMBL3246892,FP,INACT,0.9900000095367432	CHEMBL343926,TP,ACT,1.0	CHEMBL543439,TP,ACT,1.0	CHEMBL137658,TP,ACT,0.7200000286102295	CHEMBL23720,TN,INACT,0.17000000178813934	CHEMBL392336,TN,INACT,0.019999999552965164	CHEMBL337124,TP,ACT,1.0	

