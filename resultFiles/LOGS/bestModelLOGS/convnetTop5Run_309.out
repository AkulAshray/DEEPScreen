CNNModel CHEMBL1163101 adam 0.0005 30 256 0 0.8 False True
Number of active compounds :	299
Number of inactive compounds :	299
---------------------------------
Run id: CNNModel_CHEMBL1163101_adam_0.0005_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1163101_adam_0.0005_30_256_0.8_True/
---------------------------------
Training samples: 361
Validation samples: 114
--
Training Step: 1  | time: 0.799s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/361
[A[ATraining Step: 2  | total loss: [1m[32m0.62398[0m[0m | time: 1.428s
[2K
| Adam | epoch: 001 | loss: 0.62398 - acc: 0.4500 -- iter: 064/361
[A[ATraining Step: 3  | total loss: [1m[32m0.68041[0m[0m | time: 2.064s
[2K
| Adam | epoch: 001 | loss: 0.68041 - acc: 0.4909 -- iter: 096/361
[A[ATraining Step: 4  | total loss: [1m[32m0.69074[0m[0m | time: 2.712s
[2K
| Adam | epoch: 001 | loss: 0.69074 - acc: 0.4509 -- iter: 128/361
[A[ATraining Step: 5  | total loss: [1m[32m0.69186[0m[0m | time: 3.357s
[2K
| Adam | epoch: 001 | loss: 0.69186 - acc: 0.5498 -- iter: 160/361
[A[ATraining Step: 6  | total loss: [1m[32m0.69183[0m[0m | time: 3.997s
[2K
| Adam | epoch: 001 | loss: 0.69183 - acc: 0.6182 -- iter: 192/361
[A[ATraining Step: 7  | total loss: [1m[32m0.69262[0m[0m | time: 4.662s
[2K
| Adam | epoch: 001 | loss: 0.69262 - acc: 0.5473 -- iter: 224/361
[A[ATraining Step: 8  | total loss: [1m[32m0.69582[0m[0m | time: 5.303s
[2K
| Adam | epoch: 001 | loss: 0.69582 - acc: 0.4855 -- iter: 256/361
[A[ATraining Step: 9  | total loss: [1m[32m0.69330[0m[0m | time: 5.970s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.5263 -- iter: 288/361
[A[ATraining Step: 10  | total loss: [1m[32m0.69326[0m[0m | time: 6.619s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.5131 -- iter: 320/361
[A[ATraining Step: 11  | total loss: [1m[32m0.69248[0m[0m | time: 7.254s
[2K
| Adam | epoch: 001 | loss: 0.69248 - acc: 0.5217 -- iter: 352/361
[A[ATraining Step: 12  | total loss: [1m[32m0.69728[0m[0m | time: 8.499s
[2K
| Adam | epoch: 001 | loss: 0.69728 - acc: 0.4557 | val_loss: 0.69540 - val_acc: 0.4386 -- iter: 361/361
--
Training Step: 13  | total loss: [1m[32m0.69714[0m[0m | time: 0.348s
[2K
| Adam | epoch: 002 | loss: 0.69714 - acc: 0.4509 -- iter: 032/361
[A[ATraining Step: 14  | total loss: [1m[32m0.69669[0m[0m | time: 1.410s
[2K
| Adam | epoch: 002 | loss: 0.69669 - acc: 0.4482 -- iter: 064/361
[A[ATraining Step: 15  | total loss: [1m[32m0.69646[0m[0m | time: 2.426s
[2K
| Adam | epoch: 002 | loss: 0.69646 - acc: 0.4074 -- iter: 096/361
[A[ATraining Step: 16  | total loss: [1m[32m0.69475[0m[0m | time: 3.512s
[2K
| Adam | epoch: 002 | loss: 0.69475 - acc: 0.4890 -- iter: 128/361
[A[ATraining Step: 17  | total loss: [1m[32m0.69430[0m[0m | time: 4.619s
[2K
| Adam | epoch: 002 | loss: 0.69430 - acc: 0.4817 -- iter: 160/361
[A[ATraining Step: 18  | total loss: [1m[32m0.69394[0m[0m | time: 5.531s
[2K
| Adam | epoch: 002 | loss: 0.69394 - acc: 0.4880 -- iter: 192/361
[A[ATraining Step: 19  | total loss: [1m[32m0.69369[0m[0m | time: 6.469s
[2K
| Adam | epoch: 002 | loss: 0.69369 - acc: 0.5024 -- iter: 224/361
[A[ATraining Step: 20  | total loss: [1m[32m0.69354[0m[0m | time: 7.555s
[2K
| Adam | epoch: 002 | loss: 0.69354 - acc: 0.4916 -- iter: 256/361
[A[ATraining Step: 21  | total loss: [1m[32m0.69344[0m[0m | time: 8.679s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.4554 -- iter: 288/361
[A[ATraining Step: 22  | total loss: [1m[32m0.69335[0m[0m | time: 9.633s
[2K
| Adam | epoch: 002 | loss: 0.69335 - acc: 0.4688 -- iter: 320/361
[A[ATraining Step: 23  | total loss: [1m[32m0.69333[0m[0m | time: 10.677s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4597 -- iter: 352/361
[A[ATraining Step: 24  | total loss: [1m[32m0.69332[0m[0m | time: 12.685s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4535 | val_loss: 0.69311 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 25  | total loss: [1m[32m0.69334[0m[0m | time: 0.383s
[2K
| Adam | epoch: 003 | loss: 0.69334 - acc: 0.4150 -- iter: 032/361
[A[ATraining Step: 26  | total loss: [1m[32m0.69331[0m[0m | time: 0.773s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.4816 -- iter: 064/361
[A[ATraining Step: 27  | total loss: [1m[32m0.69316[0m[0m | time: 1.925s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.5292 -- iter: 096/361
[A[ATraining Step: 28  | total loss: [1m[32m0.69310[0m[0m | time: 2.808s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5297 -- iter: 128/361
[A[ATraining Step: 29  | total loss: [1m[32m0.69327[0m[0m | time: 3.847s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.5073 -- iter: 160/361
[A[ATraining Step: 30  | total loss: [1m[32m0.69333[0m[0m | time: 4.872s
[2K
| Adam | epoch: 003 | loss: 0.69333 - acc: 0.4982 -- iter: 192/361
[A[ATraining Step: 31  | total loss: [1m[32m0.69300[0m[0m | time: 5.864s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5202 -- iter: 224/361
[A[ATraining Step: 32  | total loss: [1m[32m0.69315[0m[0m | time: 6.912s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5086 -- iter: 256/361
[A[ATraining Step: 33  | total loss: [1m[32m0.69303[0m[0m | time: 8.009s
[2K
| Adam | epoch: 003 | loss: 0.69303 - acc: 0.5136 -- iter: 288/361
[A[ATraining Step: 34  | total loss: [1m[32m0.69271[0m[0m | time: 8.929s
[2K
| Adam | epoch: 003 | loss: 0.69271 - acc: 0.5308 -- iter: 320/361
[A[ATraining Step: 35  | total loss: [1m[32m0.69233[0m[0m | time: 9.880s
[2K
| Adam | epoch: 003 | loss: 0.69233 - acc: 0.5440 -- iter: 352/361
[A[ATraining Step: 36  | total loss: [1m[32m0.69293[0m[0m | time: 11.973s
[2K
| Adam | epoch: 003 | loss: 0.69293 - acc: 0.5222 | val_loss: 0.69097 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 37  | total loss: [1m[32m0.69263[0m[0m | time: 1.072s
[2K
| Adam | epoch: 004 | loss: 0.69263 - acc: 0.5302 -- iter: 032/361
[A[ATraining Step: 38  | total loss: [1m[32m0.69370[0m[0m | time: 1.505s
[2K
| Adam | epoch: 004 | loss: 0.69370 - acc: 0.4999 -- iter: 064/361
[A[ATraining Step: 39  | total loss: [1m[32m0.69478[0m[0m | time: 1.862s
[2K
| Adam | epoch: 004 | loss: 0.69478 - acc: 0.4680 -- iter: 096/361
[A[ATraining Step: 40  | total loss: [1m[32m0.69545[0m[0m | time: 2.823s
[2K
| Adam | epoch: 004 | loss: 0.69545 - acc: 0.4427 -- iter: 128/361
[A[ATraining Step: 41  | total loss: [1m[32m0.69535[0m[0m | time: 3.938s
[2K
| Adam | epoch: 004 | loss: 0.69535 - acc: 0.4418 -- iter: 160/361
[A[ATraining Step: 42  | total loss: [1m[32m0.69474[0m[0m | time: 5.073s
[2K
| Adam | epoch: 004 | loss: 0.69474 - acc: 0.4635 -- iter: 192/361
[A[ATraining Step: 43  | total loss: [1m[32m0.69426[0m[0m | time: 5.945s
[2K
| Adam | epoch: 004 | loss: 0.69426 - acc: 0.4810 -- iter: 224/361
[A[ATraining Step: 44  | total loss: [1m[32m0.69407[0m[0m | time: 6.921s
[2K
| Adam | epoch: 004 | loss: 0.69407 - acc: 0.4843 -- iter: 256/361
[A[ATraining Step: 45  | total loss: [1m[32m0.69384[0m[0m | time: 7.859s
[2K
| Adam | epoch: 004 | loss: 0.69384 - acc: 0.4922 -- iter: 288/361
[A[ATraining Step: 46  | total loss: [1m[32m0.69373[0m[0m | time: 8.848s
[2K
| Adam | epoch: 004 | loss: 0.69373 - acc: 0.4935 -- iter: 320/361
[A[ATraining Step: 47  | total loss: [1m[32m0.69347[0m[0m | time: 10.099s
[2K
| Adam | epoch: 004 | loss: 0.69347 - acc: 0.5048 -- iter: 352/361
[A[ATraining Step: 48  | total loss: [1m[32m0.69350[0m[0m | time: 12.075s
[2K
| Adam | epoch: 004 | loss: 0.69350 - acc: 0.4990 | val_loss: 0.69222 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 49  | total loss: [1m[32m0.69330[0m[0m | time: 1.012s
[2K
| Adam | epoch: 005 | loss: 0.69330 - acc: 0.5090 -- iter: 032/361
[A[ATraining Step: 50  | total loss: [1m[32m0.69291[0m[0m | time: 2.014s
[2K
| Adam | epoch: 005 | loss: 0.69291 - acc: 0.5319 -- iter: 064/361
[A[ATraining Step: 51  | total loss: [1m[32m0.69256[0m[0m | time: 2.359s
[2K
| Adam | epoch: 005 | loss: 0.69256 - acc: 0.5509 -- iter: 096/361
[A[ATraining Step: 52  | total loss: [1m[32m0.69341[0m[0m | time: 2.707s
[2K
| Adam | epoch: 005 | loss: 0.69341 - acc: 0.5016 -- iter: 128/361
[A[ATraining Step: 53  | total loss: [1m[32m0.69411[0m[0m | time: 3.687s
[2K
| Adam | epoch: 005 | loss: 0.69411 - acc: 0.4603 -- iter: 160/361
[A[ATraining Step: 54  | total loss: [1m[32m0.69399[0m[0m | time: 4.821s
[2K
| Adam | epoch: 005 | loss: 0.69399 - acc: 0.4661 -- iter: 192/361
[A[ATraining Step: 55  | total loss: [1m[32m0.69401[0m[0m | time: 5.888s
[2K
| Adam | epoch: 005 | loss: 0.69401 - acc: 0.4620 -- iter: 224/361
[A[ATraining Step: 56  | total loss: [1m[32m0.69407[0m[0m | time: 6.778s
[2K
| Adam | epoch: 005 | loss: 0.69407 - acc: 0.4542 -- iter: 256/361
[A[ATraining Step: 57  | total loss: [1m[32m0.69375[0m[0m | time: 7.826s
[2K
| Adam | epoch: 005 | loss: 0.69375 - acc: 0.4778 -- iter: 288/361
[A[ATraining Step: 58  | total loss: [1m[32m0.69391[0m[0m | time: 8.930s
[2K
| Adam | epoch: 005 | loss: 0.69391 - acc: 0.4595 -- iter: 320/361
[A[ATraining Step: 59  | total loss: [1m[32m0.69368[0m[0m | time: 9.959s
[2K
| Adam | epoch: 005 | loss: 0.69368 - acc: 0.4776 -- iter: 352/361
[A[ATraining Step: 60  | total loss: [1m[32m0.69362[0m[0m | time: 11.595s
[2K
| Adam | epoch: 005 | loss: 0.69362 - acc: 0.4805 | val_loss: 0.69266 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 61  | total loss: [1m[32m0.69353[0m[0m | time: 0.622s
[2K
| Adam | epoch: 006 | loss: 0.69353 - acc: 0.4872 -- iter: 032/361
[A[ATraining Step: 62  | total loss: [1m[32m0.69335[0m[0m | time: 1.245s
[2K
| Adam | epoch: 006 | loss: 0.69335 - acc: 0.5049 -- iter: 064/361
[A[ATraining Step: 63  | total loss: [1m[32m0.69338[0m[0m | time: 1.897s
[2K
| Adam | epoch: 006 | loss: 0.69338 - acc: 0.4963 -- iter: 096/361
[A[ATraining Step: 64  | total loss: [1m[32m0.69339[0m[0m | time: 2.117s
[2K
| Adam | epoch: 006 | loss: 0.69339 - acc: 0.4929 -- iter: 128/361
[A[ATraining Step: 65  | total loss: [1m[32m0.69299[0m[0m | time: 2.322s
[2K
| Adam | epoch: 006 | loss: 0.69299 - acc: 0.5417 -- iter: 160/361
[A[ATraining Step: 66  | total loss: [1m[32m0.69258[0m[0m | time: 2.950s
[2K
| Adam | epoch: 006 | loss: 0.69258 - acc: 0.5839 -- iter: 192/361
[A[ATraining Step: 67  | total loss: [1m[32m0.69265[0m[0m | time: 3.601s
[2K
| Adam | epoch: 006 | loss: 0.69265 - acc: 0.5739 -- iter: 224/361
[A[ATraining Step: 68  | total loss: [1m[32m0.69276[0m[0m | time: 4.228s
[2K
| Adam | epoch: 006 | loss: 0.69276 - acc: 0.5614 -- iter: 256/361
[A[ATraining Step: 69  | total loss: [1m[32m0.69264[0m[0m | time: 4.865s
[2K
| Adam | epoch: 006 | loss: 0.69264 - acc: 0.5652 -- iter: 288/361
[A[ATraining Step: 70  | total loss: [1m[32m0.69270[0m[0m | time: 5.489s
[2K
| Adam | epoch: 006 | loss: 0.69270 - acc: 0.5577 -- iter: 320/361
[A[ATraining Step: 71  | total loss: [1m[32m0.69315[0m[0m | time: 6.139s
[2K
| Adam | epoch: 006 | loss: 0.69315 - acc: 0.5297 -- iter: 352/361
[A[ATraining Step: 72  | total loss: [1m[32m0.69329[0m[0m | time: 7.768s
[2K
| Adam | epoch: 006 | loss: 0.69329 - acc: 0.5194 | val_loss: 0.69197 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 73  | total loss: [1m[32m0.69340[0m[0m | time: 0.691s
[2K
| Adam | epoch: 007 | loss: 0.69340 - acc: 0.5103 -- iter: 032/361
[A[ATraining Step: 74  | total loss: [1m[32m0.69344[0m[0m | time: 1.324s
[2K
| Adam | epoch: 007 | loss: 0.69344 - acc: 0.5057 -- iter: 064/361
[A[ATraining Step: 75  | total loss: [1m[32m0.69330[0m[0m | time: 1.977s
[2K
| Adam | epoch: 007 | loss: 0.69330 - acc: 0.5119 -- iter: 096/361
[A[ATraining Step: 76  | total loss: [1m[32m0.69342[0m[0m | time: 2.612s
[2K
| Adam | epoch: 007 | loss: 0.69342 - acc: 0.5039 -- iter: 128/361
[A[ATraining Step: 77  | total loss: [1m[32m0.69321[0m[0m | time: 2.821s
[2K
| Adam | epoch: 007 | loss: 0.69321 - acc: 0.5134 -- iter: 160/361
[A[ATraining Step: 78  | total loss: [1m[32m0.69308[0m[0m | time: 3.029s
[2K
| Adam | epoch: 007 | loss: 0.69308 - acc: 0.5178 -- iter: 192/361
[A[ATraining Step: 79  | total loss: [1m[32m0.69295[0m[0m | time: 3.658s
[2K
| Adam | epoch: 007 | loss: 0.69295 - acc: 0.5217 -- iter: 224/361
[A[ATraining Step: 80  | total loss: [1m[32m0.69299[0m[0m | time: 4.281s
[2K
| Adam | epoch: 007 | loss: 0.69299 - acc: 0.5195 -- iter: 256/361
[A[ATraining Step: 81  | total loss: [1m[32m0.69293[0m[0m | time: 4.903s
[2K
| Adam | epoch: 007 | loss: 0.69293 - acc: 0.5207 -- iter: 288/361
[A[ATraining Step: 82  | total loss: [1m[32m0.69276[0m[0m | time: 5.530s
[2K
| Adam | epoch: 007 | loss: 0.69276 - acc: 0.5280 -- iter: 320/361
[A[ATraining Step: 83  | total loss: [1m[32m0.69303[0m[0m | time: 6.166s
[2K
| Adam | epoch: 007 | loss: 0.69303 - acc: 0.5158 -- iter: 352/361
[A[ATraining Step: 84  | total loss: [1m[32m0.69268[0m[0m | time: 7.850s
[2K
| Adam | epoch: 007 | loss: 0.69268 - acc: 0.5299 | val_loss: 0.69170 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 85  | total loss: [1m[32m0.69304[0m[0m | time: 0.909s
[2K
| Adam | epoch: 008 | loss: 0.69304 - acc: 0.5144 -- iter: 032/361
[A[ATraining Step: 86  | total loss: [1m[32m0.69305[0m[0m | time: 1.939s
[2K
| Adam | epoch: 008 | loss: 0.69305 - acc: 0.5129 -- iter: 064/361
[A[ATraining Step: 87  | total loss: [1m[32m0.69268[0m[0m | time: 2.908s
[2K
| Adam | epoch: 008 | loss: 0.69268 - acc: 0.5273 -- iter: 096/361
[A[ATraining Step: 88  | total loss: [1m[32m0.69248[0m[0m | time: 3.920s
[2K
| Adam | epoch: 008 | loss: 0.69248 - acc: 0.5339 -- iter: 128/361
[A[ATraining Step: 89  | total loss: [1m[32m0.69256[0m[0m | time: 5.090s
[2K
| Adam | epoch: 008 | loss: 0.69256 - acc: 0.5305 -- iter: 160/361
[A[ATraining Step: 90  | total loss: [1m[32m0.69280[0m[0m | time: 5.514s
[2K
| Adam | epoch: 008 | loss: 0.69280 - acc: 0.5212 -- iter: 192/361
[A[ATraining Step: 91  | total loss: [1m[32m0.69234[0m[0m | time: 5.870s
[2K
| Adam | epoch: 008 | loss: 0.69234 - acc: 0.5358 -- iter: 224/361
[A[ATraining Step: 92  | total loss: [1m[32m0.69191[0m[0m | time: 6.760s
[2K
| Adam | epoch: 008 | loss: 0.69191 - acc: 0.5489 -- iter: 256/361
[A[ATraining Step: 93  | total loss: [1m[32m0.69246[0m[0m | time: 7.828s
[2K
| Adam | epoch: 008 | loss: 0.69246 - acc: 0.5315 -- iter: 288/361
[A[ATraining Step: 94  | total loss: [1m[32m0.69278[0m[0m | time: 9.073s
[2K
| Adam | epoch: 008 | loss: 0.69278 - acc: 0.5221 -- iter: 320/361
[A[ATraining Step: 95  | total loss: [1m[32m0.69281[0m[0m | time: 10.288s
[2K
| Adam | epoch: 008 | loss: 0.69281 - acc: 0.5199 -- iter: 352/361
[A[ATraining Step: 96  | total loss: [1m[32m0.69219[0m[0m | time: 12.223s
[2K
| Adam | epoch: 008 | loss: 0.69219 - acc: 0.5366 | val_loss: 0.69096 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 97  | total loss: [1m[32m0.69221[0m[0m | time: 1.177s
[2K
| Adam | epoch: 009 | loss: 0.69221 - acc: 0.5361 -- iter: 032/361
[A[ATraining Step: 98  | total loss: [1m[32m0.69245[0m[0m | time: 2.107s
[2K
| Adam | epoch: 009 | loss: 0.69245 - acc: 0.5294 -- iter: 064/361
[A[ATraining Step: 99  | total loss: [1m[32m0.69230[0m[0m | time: 3.164s
[2K
| Adam | epoch: 009 | loss: 0.69230 - acc: 0.5327 -- iter: 096/361
[A[ATraining Step: 100  | total loss: [1m[32m0.69227[0m[0m | time: 4.225s
[2K
| Adam | epoch: 009 | loss: 0.69227 - acc: 0.5325 -- iter: 128/361
[A[ATraining Step: 101  | total loss: [1m[32m0.69251[0m[0m | time: 5.265s
[2K
| Adam | epoch: 009 | loss: 0.69251 - acc: 0.5262 -- iter: 160/361
[A[ATraining Step: 102  | total loss: [1m[32m0.69248[0m[0m | time: 6.230s
[2K
| Adam | epoch: 009 | loss: 0.69248 - acc: 0.5267 -- iter: 192/361
[A[ATraining Step: 103  | total loss: [1m[32m0.69269[0m[0m | time: 6.540s
[2K
| Adam | epoch: 009 | loss: 0.69269 - acc: 0.5209 -- iter: 224/361
[A[ATraining Step: 104  | total loss: [1m[32m0.69256[0m[0m | time: 6.865s
[2K
| Adam | epoch: 009 | loss: 0.69256 - acc: 0.5243 -- iter: 256/361
[A[ATraining Step: 105  | total loss: [1m[32m0.69244[0m[0m | time: 7.908s
[2K
| Adam | epoch: 009 | loss: 0.69244 - acc: 0.5275 -- iter: 288/361
[A[ATraining Step: 106  | total loss: [1m[32m0.69253[0m[0m | time: 8.985s
[2K
| Adam | epoch: 009 | loss: 0.69253 - acc: 0.5247 -- iter: 320/361
[A[ATraining Step: 107  | total loss: [1m[32m0.69230[0m[0m | time: 10.014s
[2K
| Adam | epoch: 009 | loss: 0.69230 - acc: 0.5285 -- iter: 352/361
[A[ATraining Step: 108  | total loss: [1m[32m0.69241[0m[0m | time: 12.219s
[2K
| Adam | epoch: 009 | loss: 0.69241 - acc: 0.5256 | val_loss: 0.69034 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 109  | total loss: [1m[32m0.69283[0m[0m | time: 1.067s
[2K
| Adam | epoch: 010 | loss: 0.69283 - acc: 0.5168 -- iter: 032/361
[A[ATraining Step: 110  | total loss: [1m[32m0.69243[0m[0m | time: 1.990s
[2K
| Adam | epoch: 010 | loss: 0.69243 - acc: 0.5245 -- iter: 064/361
[A[ATraining Step: 111  | total loss: [1m[32m0.69271[0m[0m | time: 3.026s
[2K
| Adam | epoch: 010 | loss: 0.69271 - acc: 0.5189 -- iter: 096/361
[A[ATraining Step: 112  | total loss: [1m[32m0.69263[0m[0m | time: 4.040s
[2K
| Adam | epoch: 010 | loss: 0.69263 - acc: 0.5202 -- iter: 128/361
[A[ATraining Step: 113  | total loss: [1m[32m0.69319[0m[0m | time: 5.089s
[2K
| Adam | epoch: 010 | loss: 0.69319 - acc: 0.5088 -- iter: 160/361
[A[ATraining Step: 114  | total loss: [1m[32m0.69319[0m[0m | time: 6.206s
[2K
| Adam | epoch: 010 | loss: 0.69319 - acc: 0.5079 -- iter: 192/361
[A[ATraining Step: 115  | total loss: [1m[32m0.69292[0m[0m | time: 7.185s
[2K
| Adam | epoch: 010 | loss: 0.69292 - acc: 0.5134 -- iter: 224/361
[A[ATraining Step: 116  | total loss: [1m[32m0.69239[0m[0m | time: 7.455s
[2K
| Adam | epoch: 010 | loss: 0.69239 - acc: 0.5245 -- iter: 256/361
[A[ATraining Step: 117  | total loss: [1m[32m0.69169[0m[0m | time: 7.792s
[2K
| Adam | epoch: 010 | loss: 0.69169 - acc: 0.5387 -- iter: 288/361
[A[ATraining Step: 118  | total loss: [1m[32m0.69095[0m[0m | time: 8.867s
[2K
| Adam | epoch: 010 | loss: 0.69095 - acc: 0.5515 -- iter: 320/361
[A[ATraining Step: 119  | total loss: [1m[32m0.69161[0m[0m | time: 9.948s
[2K
| Adam | epoch: 010 | loss: 0.69161 - acc: 0.5401 -- iter: 352/361
[A[ATraining Step: 120  | total loss: [1m[32m0.69121[0m[0m | time: 11.819s
[2K
| Adam | epoch: 010 | loss: 0.69121 - acc: 0.5455 | val_loss: 0.68935 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 121  | total loss: [1m[32m0.69212[0m[0m | time: 1.189s
[2K
| Adam | epoch: 011 | loss: 0.69212 - acc: 0.5316 -- iter: 032/361
[A[ATraining Step: 122  | total loss: [1m[32m0.69229[0m[0m | time: 2.194s
[2K
| Adam | epoch: 011 | loss: 0.69229 - acc: 0.5284 -- iter: 064/361
[A[ATraining Step: 123  | total loss: [1m[32m0.69198[0m[0m | time: 3.300s
[2K
| Adam | epoch: 011 | loss: 0.69198 - acc: 0.5318 -- iter: 096/361
[A[ATraining Step: 124  | total loss: [1m[32m0.69241[0m[0m | time: 4.346s
[2K
| Adam | epoch: 011 | loss: 0.69241 - acc: 0.5255 -- iter: 128/361
[A[ATraining Step: 125  | total loss: [1m[32m0.69190[0m[0m | time: 5.266s
[2K
| Adam | epoch: 011 | loss: 0.69190 - acc: 0.5323 -- iter: 160/361
[A[ATraining Step: 126  | total loss: [1m[32m0.69258[0m[0m | time: 6.289s
[2K
| Adam | epoch: 011 | loss: 0.69258 - acc: 0.5229 -- iter: 192/361
[A[ATraining Step: 127  | total loss: [1m[32m0.69296[0m[0m | time: 7.275s
[2K
| Adam | epoch: 011 | loss: 0.69296 - acc: 0.5174 -- iter: 224/361
[A[ATraining Step: 128  | total loss: [1m[32m0.69302[0m[0m | time: 8.259s
[2K
| Adam | epoch: 011 | loss: 0.69302 - acc: 0.5157 -- iter: 256/361
[A[ATraining Step: 129  | total loss: [1m[32m0.69375[0m[0m | time: 8.663s
[2K
| Adam | epoch: 011 | loss: 0.69375 - acc: 0.5048 -- iter: 288/361
[A[ATraining Step: 130  | total loss: [1m[32m0.69414[0m[0m | time: 9.063s
[2K
| Adam | epoch: 011 | loss: 0.69414 - acc: 0.4987 -- iter: 320/361
[A[ATraining Step: 131  | total loss: [1m[32m0.69443[0m[0m | time: 10.036s
[2K
| Adam | epoch: 011 | loss: 0.69443 - acc: 0.4933 -- iter: 352/361
[A[ATraining Step: 132  | total loss: [1m[32m0.69434[0m[0m | time: 12.068s
[2K
| Adam | epoch: 011 | loss: 0.69434 - acc: 0.4940 | val_loss: 0.69026 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 133  | total loss: [1m[32m0.69345[0m[0m | time: 0.635s
[2K
| Adam | epoch: 012 | loss: 0.69345 - acc: 0.5102 -- iter: 032/361
[A[ATraining Step: 134  | total loss: [1m[32m0.69312[0m[0m | time: 1.288s
[2K
| Adam | epoch: 012 | loss: 0.69312 - acc: 0.5154 -- iter: 064/361
[A[ATraining Step: 135  | total loss: [1m[32m0.69335[0m[0m | time: 1.908s
[2K
| Adam | epoch: 012 | loss: 0.69335 - acc: 0.5108 -- iter: 096/361
[A[ATraining Step: 136  | total loss: [1m[32m0.69288[0m[0m | time: 2.529s
[2K
| Adam | epoch: 012 | loss: 0.69288 - acc: 0.5191 -- iter: 128/361
[A[ATraining Step: 137  | total loss: [1m[32m0.69261[0m[0m | time: 3.169s
[2K
| Adam | epoch: 012 | loss: 0.69261 - acc: 0.5234 -- iter: 160/361
[A[ATraining Step: 138  | total loss: [1m[32m0.69284[0m[0m | time: 3.786s
[2K
| Adam | epoch: 012 | loss: 0.69284 - acc: 0.5179 -- iter: 192/361
[A[ATraining Step: 139  | total loss: [1m[32m0.69289[0m[0m | time: 4.427s
[2K
| Adam | epoch: 012 | loss: 0.69289 - acc: 0.5161 -- iter: 224/361
[A[ATraining Step: 140  | total loss: [1m[32m0.69282[0m[0m | time: 5.058s
[2K
| Adam | epoch: 012 | loss: 0.69282 - acc: 0.5177 -- iter: 256/361
[A[ATraining Step: 141  | total loss: [1m[32m0.69271[0m[0m | time: 5.711s
[2K
| Adam | epoch: 012 | loss: 0.69271 - acc: 0.5190 -- iter: 288/361
[A[ATraining Step: 142  | total loss: [1m[32m0.69310[0m[0m | time: 5.933s
[2K
| Adam | epoch: 012 | loss: 0.69310 - acc: 0.5109 -- iter: 320/361
[A[ATraining Step: 143  | total loss: [1m[32m0.69287[0m[0m | time: 6.145s
[2K
| Adam | epoch: 012 | loss: 0.69287 - acc: 0.5153 -- iter: 352/361
[A[ATraining Step: 144  | total loss: [1m[32m0.69263[0m[0m | time: 7.789s
[2K
| Adam | epoch: 012 | loss: 0.69263 - acc: 0.5194 | val_loss: 0.69025 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 145  | total loss: [1m[32m0.69289[0m[0m | time: 0.619s
[2K
| Adam | epoch: 013 | loss: 0.69289 - acc: 0.5143 -- iter: 032/361
[A[ATraining Step: 146  | total loss: [1m[32m0.69294[0m[0m | time: 1.258s
[2K
| Adam | epoch: 013 | loss: 0.69294 - acc: 0.5129 -- iter: 064/361
[A[ATraining Step: 147  | total loss: [1m[32m0.69280[0m[0m | time: 1.901s
[2K
| Adam | epoch: 013 | loss: 0.69280 - acc: 0.5147 -- iter: 096/361
[A[ATraining Step: 148  | total loss: [1m[32m0.69288[0m[0m | time: 2.511s
[2K
| Adam | epoch: 013 | loss: 0.69288 - acc: 0.5132 -- iter: 128/361
[A[ATraining Step: 149  | total loss: [1m[32m0.69243[0m[0m | time: 3.138s
[2K
| Adam | epoch: 013 | loss: 0.69243 - acc: 0.5213 -- iter: 160/361
[A[ATraining Step: 150  | total loss: [1m[32m0.69305[0m[0m | time: 3.774s
[2K
| Adam | epoch: 013 | loss: 0.69305 - acc: 0.5098 -- iter: 192/361
[A[ATraining Step: 151  | total loss: [1m[32m0.69325[0m[0m | time: 4.402s
[2K
| Adam | epoch: 013 | loss: 0.69325 - acc: 0.5057 -- iter: 224/361
[A[ATraining Step: 152  | total loss: [1m[32m0.69310[0m[0m | time: 5.012s
[2K
| Adam | epoch: 013 | loss: 0.69310 - acc: 0.5082 -- iter: 256/361
[A[ATraining Step: 153  | total loss: [1m[32m0.69298[0m[0m | time: 5.658s
[2K
| Adam | epoch: 013 | loss: 0.69298 - acc: 0.5105 -- iter: 288/361
[A[ATraining Step: 154  | total loss: [1m[32m0.69270[0m[0m | time: 6.321s
[2K
| Adam | epoch: 013 | loss: 0.69270 - acc: 0.5157 -- iter: 320/361
[A[ATraining Step: 155  | total loss: [1m[32m0.69292[0m[0m | time: 6.659s
[2K
| Adam | epoch: 013 | loss: 0.69292 - acc: 0.5110 -- iter: 352/361
[A[ATraining Step: 156  | total loss: [1m[32m0.69383[0m[0m | time: 8.008s
[2K
| Adam | epoch: 013 | loss: 0.69383 - acc: 0.4933 | val_loss: 0.69048 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 157  | total loss: [1m[32m0.69462[0m[0m | time: 1.026s
[2K
| Adam | epoch: 014 | loss: 0.69462 - acc: 0.4773 -- iter: 032/361
[A[ATraining Step: 158  | total loss: [1m[32m0.69449[0m[0m | time: 2.014s
[2K
| Adam | epoch: 014 | loss: 0.69449 - acc: 0.4795 -- iter: 064/361
[A[ATraining Step: 159  | total loss: [1m[32m0.69466[0m[0m | time: 3.035s
[2K
| Adam | epoch: 014 | loss: 0.69466 - acc: 0.4753 -- iter: 096/361
[A[ATraining Step: 160  | total loss: [1m[32m0.69405[0m[0m | time: 4.265s
[2K
| Adam | epoch: 014 | loss: 0.69405 - acc: 0.4903 -- iter: 128/361
[A[ATraining Step: 161  | total loss: [1m[32m0.69384[0m[0m | time: 5.324s
[2K
| Adam | epoch: 014 | loss: 0.69384 - acc: 0.4944 -- iter: 160/361
[A[ATraining Step: 162  | total loss: [1m[32m0.69330[0m[0m | time: 6.353s
[2K
| Adam | epoch: 014 | loss: 0.69330 - acc: 0.5075 -- iter: 192/361
[A[ATraining Step: 163  | total loss: [1m[32m0.69291[0m[0m | time: 7.439s
[2K
| Adam | epoch: 014 | loss: 0.69291 - acc: 0.5161 -- iter: 224/361
[A[ATraining Step: 164  | total loss: [1m[32m0.69357[0m[0m | time: 8.510s
[2K
| Adam | epoch: 014 | loss: 0.69357 - acc: 0.4989 -- iter: 256/361
[A[ATraining Step: 165  | total loss: [1m[32m0.69341[0m[0m | time: 9.565s
[2K
| Adam | epoch: 014 | loss: 0.69341 - acc: 0.5021 -- iter: 288/361
[A[ATraining Step: 166  | total loss: [1m[32m0.69315[0m[0m | time: 10.478s
[2K
| Adam | epoch: 014 | loss: 0.69315 - acc: 0.5081 -- iter: 320/361
[A[ATraining Step: 167  | total loss: [1m[32m0.69337[0m[0m | time: 11.511s
[2K
| Adam | epoch: 014 | loss: 0.69337 - acc: 0.5011 -- iter: 352/361
[A[ATraining Step: 168  | total loss: [1m[32m0.69299[0m[0m | time: 12.845s
[2K
| Adam | epoch: 014 | loss: 0.69299 - acc: 0.5103 | val_loss: 0.69088 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 169  | total loss: [1m[32m0.69362[0m[0m | time: 0.299s
[2K
| Adam | epoch: 015 | loss: 0.69362 - acc: 0.4926 -- iter: 032/361
[A[ATraining Step: 170  | total loss: [1m[32m0.69412[0m[0m | time: 1.394s
[2K
| Adam | epoch: 015 | loss: 0.69412 - acc: 0.4767 -- iter: 064/361
[A[ATraining Step: 171  | total loss: [1m[32m0.69366[0m[0m | time: 2.570s
[2K
| Adam | epoch: 015 | loss: 0.69366 - acc: 0.4915 -- iter: 096/361
[A[ATraining Step: 172  | total loss: [1m[32m0.69385[0m[0m | time: 3.634s
[2K
| Adam | epoch: 015 | loss: 0.69385 - acc: 0.4830 -- iter: 128/361
[A[ATraining Step: 173  | total loss: [1m[32m0.69340[0m[0m | time: 4.576s
[2K
| Adam | epoch: 015 | loss: 0.69340 - acc: 0.5003 -- iter: 160/361
[A[ATraining Step: 174  | total loss: [1m[32m0.69379[0m[0m | time: 5.599s
[2K
| Adam | epoch: 015 | loss: 0.69379 - acc: 0.4815 -- iter: 192/361
[A[ATraining Step: 175  | total loss: [1m[32m0.69346[0m[0m | time: 6.611s
[2K
| Adam | epoch: 015 | loss: 0.69346 - acc: 0.4959 -- iter: 224/361
[A[ATraining Step: 176  | total loss: [1m[32m0.69336[0m[0m | time: 7.600s
[2K
| Adam | epoch: 015 | loss: 0.69336 - acc: 0.4963 -- iter: 256/361
[A[ATraining Step: 177  | total loss: [1m[32m0.69307[0m[0m | time: 8.830s
[2K
| Adam | epoch: 015 | loss: 0.69307 - acc: 0.5092 -- iter: 288/361
[A[ATraining Step: 178  | total loss: [1m[32m0.69298[0m[0m | time: 9.909s
[2K
| Adam | epoch: 015 | loss: 0.69298 - acc: 0.5114 -- iter: 320/361
[A[ATraining Step: 179  | total loss: [1m[32m0.69279[0m[0m | time: 10.856s
[2K
| Adam | epoch: 015 | loss: 0.69279 - acc: 0.5165 -- iter: 352/361
[A[ATraining Step: 180  | total loss: [1m[32m0.69250[0m[0m | time: 12.985s
[2K
| Adam | epoch: 015 | loss: 0.69250 - acc: 0.5242 | val_loss: 0.69078 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 181  | total loss: [1m[32m0.69221[0m[0m | time: 0.342s
[2K
| Adam | epoch: 016 | loss: 0.69221 - acc: 0.5343 -- iter: 032/361
[A[ATraining Step: 182  | total loss: [1m[32m0.69279[0m[0m | time: 0.704s
[2K
| Adam | epoch: 016 | loss: 0.69279 - acc: 0.5142 -- iter: 064/361
[A[ATraining Step: 183  | total loss: [1m[32m0.69302[0m[0m | time: 1.721s
[2K
| Adam | epoch: 016 | loss: 0.69302 - acc: 0.4961 -- iter: 096/361
[A[ATraining Step: 184  | total loss: [1m[32m0.69294[0m[0m | time: 2.796s
[2K
| Adam | epoch: 016 | loss: 0.69294 - acc: 0.4996 -- iter: 128/361
[A[ATraining Step: 185  | total loss: [1m[32m0.69277[0m[0m | time: 3.944s
[2K
| Adam | epoch: 016 | loss: 0.69277 - acc: 0.5215 -- iter: 160/361
[A[ATraining Step: 186  | total loss: [1m[32m0.69255[0m[0m | time: 4.966s
[2K
| Adam | epoch: 016 | loss: 0.69255 - acc: 0.5225 -- iter: 192/361
[A[ATraining Step: 187  | total loss: [1m[32m0.69217[0m[0m | time: 5.956s
[2K
| Adam | epoch: 016 | loss: 0.69217 - acc: 0.5265 -- iter: 224/361
[A[ATraining Step: 188  | total loss: [1m[32m0.69231[0m[0m | time: 7.040s
[2K
| Adam | epoch: 016 | loss: 0.69231 - acc: 0.5239 -- iter: 256/361
[A[ATraining Step: 189  | total loss: [1m[32m0.69231[0m[0m | time: 8.181s
[2K
| Adam | epoch: 016 | loss: 0.69231 - acc: 0.5215 -- iter: 288/361
[A[ATraining Step: 190  | total loss: [1m[32m0.69271[0m[0m | time: 9.186s
[2K
| Adam | epoch: 016 | loss: 0.69271 - acc: 0.5193 -- iter: 320/361
[A[ATraining Step: 191  | total loss: [1m[32m0.69280[0m[0m | time: 10.131s
[2K
| Adam | epoch: 016 | loss: 0.69280 - acc: 0.5143 -- iter: 352/361
[A[ATraining Step: 192  | total loss: [1m[32m0.69269[0m[0m | time: 12.194s
[2K
| Adam | epoch: 016 | loss: 0.69269 - acc: 0.5128 | val_loss: 0.69059 - val_acc: 0.5702 -- iter: 361/361
--
Training Step: 193  | total loss: [1m[32m0.69290[0m[0m | time: 1.012s
[2K
| Adam | epoch: 017 | loss: 0.69290 - acc: 0.5022 -- iter: 032/361
[A[ATraining Step: 194  | total loss: [1m[32m0.69298[0m[0m | time: 1.362s
[2K
| Adam | epoch: 017 | loss: 0.69298 - acc: 0.4957 -- iter: 064/361
[A[ATraining Step: 195  | total loss: [1m[32m0.69296[0m[0m | time: 1.692s
[2K
| Adam | epoch: 017 | loss: 0.69296 - acc: 0.4906 -- iter: 096/361
[A[ATraining Step: 196  | total loss: [1m[32m0.69299[0m[0m | time: 2.757s
[2K
| Adam | epoch: 017 | loss: 0.69299 - acc: 0.4860 -- iter: 128/361
[A[ATraining Step: 197  | total loss: [1m[32m0.69324[0m[0m | time: 3.807s
[2K
| Adam | epoch: 017 | loss: 0.69324 - acc: 0.4749 -- iter: 160/361
[A[ATraining Step: 198  | total loss: [1m[32m0.69321[0m[0m | time: 4.763s
[2K
| Adam | epoch: 017 | loss: 0.69321 - acc: 0.4743 -- iter: 192/361
[A[ATraining Step: 199  | total loss: [1m[32m0.69316[0m[0m | time: 5.881s
[2K
| Adam | epoch: 017 | loss: 0.69316 - acc: 0.4800 -- iter: 224/361
[A[ATraining Step: 200  | total loss: [1m[32m0.69312[0m[0m | time: 7.952s
[2K
| Adam | epoch: 017 | loss: 0.69312 - acc: 0.4882 | val_loss: 0.69368 - val_acc: 0.4386 -- iter: 256/361
--
Training Step: 201  | total loss: [1m[32m0.69305[0m[0m | time: 8.612s
[2K
| Adam | epoch: 017 | loss: 0.69305 - acc: 0.4956 -- iter: 288/361
[A[ATraining Step: 202  | total loss: [1m[32m0.69309[0m[0m | time: 9.267s
[2K
| Adam | epoch: 017 | loss: 0.69309 - acc: 0.4930 -- iter: 320/361
[A[ATraining Step: 203  | total loss: [1m[32m0.69288[0m[0m | time: 9.898s
[2K
| Adam | epoch: 017 | loss: 0.69288 - acc: 0.5030 -- iter: 352/361
[A[ATraining Step: 204  | total loss: [1m[32m0.69259[0m[0m | time: 11.551s
[2K
| Adam | epoch: 017 | loss: 0.69259 - acc: 0.5121 | val_loss: 0.69717 - val_acc: 0.4386 -- iter: 361/361
--
Training Step: 205  | total loss: [1m[32m0.69274[0m[0m | time: 0.654s
[2K
| Adam | epoch: 018 | loss: 0.69274 - acc: 0.5078 -- iter: 032/361
[A[ATraining Step: 206  | total loss: [1m[32m0.69268[0m[0m | time: 1.285s
[2K
| Adam | epoch: 018 | loss: 0.69268 - acc: 0.5070 -- iter: 064/361
[A[ATraining Step: 207  | total loss: [1m[32m0.69267[0m[0m | time: 1.504s
[2K
| Adam | epoch: 018 | loss: 0.69267 - acc: 0.5063 -- iter: 096/361
[A[ATraining Step: 208  | total loss: [1m[32m0.69516[0m[0m | time: 1.730s
[2K
| Adam | epoch: 018 | loss: 0.69516 - acc: 0.4779 -- iter: 128/361
[A[ATraining Step: 209  | total loss: [1m[32m0.69605[0m[0m | time: 2.369s
[2K
| Adam | epoch: 018 | loss: 0.69605 - acc: 0.4523 -- iter: 160/361
[A[ATraining Step: 210  | total loss: [1m[32m0.69546[0m[0m | time: 2.986s
[2K
| Adam | epoch: 018 | loss: 0.69546 - acc: 0.4852 -- iter: 192/361
[A[ATraining Step: 211  | total loss: [1m[32m0.69488[0m[0m | time: 3.647s
[2K
| Adam | epoch: 018 | loss: 0.69488 - acc: 0.4961 -- iter: 224/361
[A[ATraining Step: 212  | total loss: [1m[32m0.69542[0m[0m | time: 4.282s
[2K
| Adam | epoch: 018 | loss: 0.69542 - acc: 0.4808 -- iter: 256/361
[A[ATraining Step: 213  | total loss: [1m[32m0.69460[0m[0m | time: 4.907s
[2K
| Adam | epoch: 018 | loss: 0.69460 - acc: 0.4953 -- iter: 288/361
[A[ATraining Step: 214  | total loss: [1m[32m0.69342[0m[0m | time: 5.552s
[2K
| Adam | epoch: 018 | loss: 0.69342 - acc: 0.5145 -- iter: 320/361
[A[ATraining Step: 215  | total loss: [1m[32m0.69316[0m[0m | time: 6.191s
[2K
| Adam | epoch: 018 | loss: 0.69316 - acc: 0.5162 -- iter: 352/361
[A[ATraining Step: 216  | total loss: [1m[32m0.69285[0m[0m | time: 7.830s
[2K
| Adam | epoch: 018 | loss: 0.69285 - acc: 0.5177 | val_loss: 0.68768 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 217  | total loss: [1m[32m0.69362[0m[0m | time: 1.122s
[2K
| Adam | epoch: 019 | loss: 0.69362 - acc: 0.5065 -- iter: 032/361
[A[ATraining Step: 218  | total loss: [1m[32m0.69275[0m[0m | time: 2.327s
[2K
| Adam | epoch: 019 | loss: 0.69275 - acc: 0.5152 -- iter: 064/361
[A[ATraining Step: 219  | total loss: [1m[32m0.69215[0m[0m | time: 3.162s
[2K
| Adam | epoch: 019 | loss: 0.69215 - acc: 0.5200 -- iter: 096/361
[A[ATraining Step: 220  | total loss: [1m[32m0.69204[0m[0m | time: 3.498s
[2K
| Adam | epoch: 019 | loss: 0.69204 - acc: 0.5180 -- iter: 128/361
[A[ATraining Step: 221  | total loss: [1m[32m0.69167[0m[0m | time: 3.847s
[2K
| Adam | epoch: 019 | loss: 0.69167 - acc: 0.5217 -- iter: 160/361
[A[ATraining Step: 222  | total loss: [1m[32m0.69129[0m[0m | time: 4.820s
[2K
| Adam | epoch: 019 | loss: 0.69129 - acc: 0.5251 -- iter: 192/361
[A[ATraining Step: 223  | total loss: [1m[32m0.69080[0m[0m | time: 5.834s
[2K
| Adam | epoch: 019 | loss: 0.69080 - acc: 0.5289 -- iter: 224/361
[A[ATraining Step: 224  | total loss: [1m[32m0.69029[0m[0m | time: 6.934s
[2K
| Adam | epoch: 019 | loss: 0.69029 - acc: 0.5291 -- iter: 256/361
[A[ATraining Step: 225  | total loss: [1m[32m0.69090[0m[0m | time: 7.890s
[2K
| Adam | epoch: 019 | loss: 0.69090 - acc: 0.5199 -- iter: 288/361
[A[ATraining Step: 226  | total loss: [1m[32m0.69155[0m[0m | time: 8.852s
[2K
| Adam | epoch: 019 | loss: 0.69155 - acc: 0.5148 -- iter: 320/361
[A[ATraining Step: 227  | total loss: [1m[32m0.69092[0m[0m | time: 9.970s
[2K
| Adam | epoch: 019 | loss: 0.69092 - acc: 0.5133 -- iter: 352/361
[A[ATraining Step: 228  | total loss: [1m[32m0.69079[0m[0m | time: 12.082s
[2K
| Adam | epoch: 019 | loss: 0.69079 - acc: 0.5089 | val_loss: 0.67861 - val_acc: 0.5614 -- iter: 361/361
--
Training Step: 229  | total loss: [1m[32m0.69017[0m[0m | time: 1.241s
[2K
| Adam | epoch: 020 | loss: 0.69017 - acc: 0.5080 -- iter: 032/361
[A[ATraining Step: 230  | total loss: [1m[32m0.68911[0m[0m | time: 2.326s
[2K
| Adam | epoch: 020 | loss: 0.68911 - acc: 0.5103 -- iter: 064/361
[A[ATraining Step: 231  | total loss: [1m[32m0.68829[0m[0m | time: 3.248s
[2K
| Adam | epoch: 020 | loss: 0.68829 - acc: 0.5093 -- iter: 096/361
[A[ATraining Step: 232  | total loss: [1m[32m0.68667[0m[0m | time: 4.400s
[2K
| Adam | epoch: 020 | loss: 0.68667 - acc: 0.5115 -- iter: 128/361
[A[ATraining Step: 233  | total loss: [1m[32m0.68724[0m[0m | time: 4.794s
[2K
| Adam | epoch: 020 | loss: 0.68724 - acc: 0.5103 -- iter: 160/361
[A[ATraining Step: 234  | total loss: [1m[32m0.67081[0m[0m | time: 5.160s
[2K
| Adam | epoch: 020 | loss: 0.67081 - acc: 0.5371 -- iter: 192/361
[A[ATraining Step: 235  | total loss: [1m[32m0.65002[0m[0m | time: 6.223s
[2K
| Adam | epoch: 020 | loss: 0.65002 - acc: 0.5611 -- iter: 224/361
[A[ATraining Step: 236  | total loss: [1m[32m0.67036[0m[0m | time: 7.202s
[2K
| Adam | epoch: 020 | loss: 0.67036 - acc: 0.5488 -- iter: 256/361
[A[ATraining Step: 237  | total loss: [1m[32m0.67273[0m[0m | time: 8.185s
[2K
| Adam | epoch: 020 | loss: 0.67273 - acc: 0.5502 -- iter: 288/361
[A[ATraining Step: 238  | total loss: [1m[32m0.66835[0m[0m | time: 9.173s
[2K
| Adam | epoch: 020 | loss: 0.66835 - acc: 0.5514 -- iter: 320/361
[A[ATraining Step: 239  | total loss: [1m[32m0.66538[0m[0m | time: 10.228s
[2K
| Adam | epoch: 020 | loss: 0.66538 - acc: 0.5650 -- iter: 352/361
[A[ATraining Step: 240  | total loss: [1m[32m0.66682[0m[0m | time: 12.434s
[2K
| Adam | epoch: 020 | loss: 0.66682 - acc: 0.5679 | val_loss: 0.66970 - val_acc: 0.6316 -- iter: 361/361
--
Training Step: 241  | total loss: [1m[32m0.66808[0m[0m | time: 0.967s
[2K
| Adam | epoch: 021 | loss: 0.66808 - acc: 0.5830 -- iter: 032/361
[A[ATraining Step: 242  | total loss: [1m[32m0.66856[0m[0m | time: 1.887s
[2K
| Adam | epoch: 021 | loss: 0.66856 - acc: 0.5840 -- iter: 064/361
[A[ATraining Step: 243  | total loss: [1m[32m0.66647[0m[0m | time: 2.881s
[2K
| Adam | epoch: 021 | loss: 0.66647 - acc: 0.6038 -- iter: 096/361
[A[ATraining Step: 244  | total loss: [1m[32m0.66325[0m[0m | time: 3.930s
[2K
| Adam | epoch: 021 | loss: 0.66325 - acc: 0.6028 -- iter: 128/361
[A[ATraining Step: 245  | total loss: [1m[32m0.66273[0m[0m | time: 5.038s
[2K
| Adam | epoch: 021 | loss: 0.66273 - acc: 0.5987 -- iter: 160/361
[A[ATraining Step: 246  | total loss: [1m[32m0.65598[0m[0m | time: 5.440s
[2K
| Adam | epoch: 021 | loss: 0.65598 - acc: 0.6170 -- iter: 192/361
[A[ATraining Step: 247  | total loss: [1m[32m0.64765[0m[0m | time: 5.848s
[2K
| Adam | epoch: 021 | loss: 0.64765 - acc: 0.6331 -- iter: 224/361
[A[ATraining Step: 248  | total loss: [1m[32m0.63746[0m[0m | time: 6.868s
[2K
| Adam | epoch: 021 | loss: 0.63746 - acc: 0.6364 -- iter: 256/361
[A[ATraining Step: 249  | total loss: [1m[32m0.64280[0m[0m | time: 7.861s
[2K
| Adam | epoch: 021 | loss: 0.64280 - acc: 0.6322 -- iter: 288/361
[A[ATraining Step: 250  | total loss: [1m[32m0.64941[0m[0m | time: 8.949s
[2K
| Adam | epoch: 021 | loss: 0.64941 - acc: 0.6158 -- iter: 320/361
[A[ATraining Step: 251  | total loss: [1m[32m0.64359[0m[0m | time: 10.157s
[2K
| Adam | epoch: 021 | loss: 0.64359 - acc: 0.6230 -- iter: 352/361
[A[ATraining Step: 252  | total loss: [1m[32m0.63630[0m[0m | time: 12.188s
[2K
| Adam | epoch: 021 | loss: 0.63630 - acc: 0.6388 | val_loss: 0.63261 - val_acc: 0.6316 -- iter: 361/361
--
Training Step: 253  | total loss: [1m[32m0.63358[0m[0m | time: 1.094s
[2K
| Adam | epoch: 022 | loss: 0.63358 - acc: 0.6437 -- iter: 032/361
[A[ATraining Step: 254  | total loss: [1m[32m0.63486[0m[0m | time: 2.167s
[2K
| Adam | epoch: 022 | loss: 0.63486 - acc: 0.6481 -- iter: 064/361
[A[ATraining Step: 255  | total loss: [1m[32m0.62486[0m[0m | time: 3.017s
[2K
| Adam | epoch: 022 | loss: 0.62486 - acc: 0.6583 -- iter: 096/361
[A[ATraining Step: 256  | total loss: [1m[32m0.62149[0m[0m | time: 4.143s
[2K
| Adam | epoch: 022 | loss: 0.62149 - acc: 0.6612 -- iter: 128/361
[A[ATraining Step: 257  | total loss: [1m[32m0.60981[0m[0m | time: 5.270s
[2K
| Adam | epoch: 022 | loss: 0.60981 - acc: 0.6701 -- iter: 160/361
[A[ATraining Step: 258  | total loss: [1m[32m0.62265[0m[0m | time: 6.426s
[2K
| Adam | epoch: 022 | loss: 0.62265 - acc: 0.6499 -- iter: 192/361
[A[ATraining Step: 259  | total loss: [1m[32m0.60189[0m[0m | time: 6.708s
[2K
| Adam | epoch: 022 | loss: 0.60189 - acc: 0.6693 -- iter: 224/361
[A[ATraining Step: 260  | total loss: [1m[32m0.60225[0m[0m | time: 7.012s
[2K
| Adam | epoch: 022 | loss: 0.60225 - acc: 0.6579 -- iter: 256/361
[A[ATraining Step: 261  | total loss: [1m[32m0.59920[0m[0m | time: 8.007s
[2K
| Adam | epoch: 022 | loss: 0.59920 - acc: 0.6588 -- iter: 288/361
[A[ATraining Step: 262  | total loss: [1m[32m0.62735[0m[0m | time: 8.992s
[2K
| Adam | epoch: 022 | loss: 0.62735 - acc: 0.6461 -- iter: 320/361
[A[ATraining Step: 263  | total loss: [1m[32m0.64333[0m[0m | time: 10.026s
[2K
| Adam | epoch: 022 | loss: 0.64333 - acc: 0.6346 -- iter: 352/361
[A[ATraining Step: 264  | total loss: [1m[32m0.64109[0m[0m | time: 12.112s
[2K
| Adam | epoch: 022 | loss: 0.64109 - acc: 0.6336 | val_loss: 0.56633 - val_acc: 0.6228 -- iter: 361/361
--
Training Step: 265  | total loss: [1m[32m0.63662[0m[0m | time: 1.067s
[2K
| Adam | epoch: 023 | loss: 0.63662 - acc: 0.6359 -- iter: 032/361
[A[ATraining Step: 266  | total loss: [1m[32m0.63598[0m[0m | time: 2.057s
[2K
| Adam | epoch: 023 | loss: 0.63598 - acc: 0.6285 -- iter: 064/361
[A[ATraining Step: 267  | total loss: [1m[32m0.64168[0m[0m | time: 2.732s
[2K
| Adam | epoch: 023 | loss: 0.64168 - acc: 0.6188 -- iter: 096/361
[A[ATraining Step: 268  | total loss: [1m[32m0.63711[0m[0m | time: 3.349s
[2K
| Adam | epoch: 023 | loss: 0.63711 - acc: 0.6257 -- iter: 128/361
[A[ATraining Step: 269  | total loss: [1m[32m0.62491[0m[0m | time: 3.965s
[2K
| Adam | epoch: 023 | loss: 0.62491 - acc: 0.6381 -- iter: 160/361
[A[ATraining Step: 270  | total loss: [1m[32m0.61372[0m[0m | time: 4.614s
[2K
| Adam | epoch: 023 | loss: 0.61372 - acc: 0.6587 -- iter: 192/361
[A[ATraining Step: 271  | total loss: [1m[32m0.60597[0m[0m | time: 5.237s
[2K
| Adam | epoch: 023 | loss: 0.60597 - acc: 0.6772 -- iter: 224/361
[A[ATraining Step: 272  | total loss: [1m[32m0.59814[0m[0m | time: 5.461s
[2K
| Adam | epoch: 023 | loss: 0.59814 - acc: 0.6970 -- iter: 256/361
[A[ATraining Step: 273  | total loss: [1m[32m0.58104[0m[0m | time: 5.666s
[2K
| Adam | epoch: 023 | loss: 0.58104 - acc: 0.7162 -- iter: 288/361
[A[ATraining Step: 274  | total loss: [1m[32m0.55643[0m[0m | time: 6.328s
[2K
| Adam | epoch: 023 | loss: 0.55643 - acc: 0.7223 -- iter: 320/361
[A[ATraining Step: 275  | total loss: [1m[32m0.55648[0m[0m | time: 6.977s
[2K
| Adam | epoch: 023 | loss: 0.55648 - acc: 0.7126 -- iter: 352/361
[A[ATraining Step: 276  | total loss: [1m[32m0.56626[0m[0m | time: 8.649s
[2K
| Adam | epoch: 023 | loss: 0.56626 - acc: 0.7007 | val_loss: 0.53809 - val_acc: 0.7456 -- iter: 361/361
--
Training Step: 277  | total loss: [1m[32m0.58478[0m[0m | time: 0.652s
[2K
| Adam | epoch: 024 | loss: 0.58478 - acc: 0.6963 -- iter: 032/361
[A[ATraining Step: 278  | total loss: [1m[32m0.58550[0m[0m | time: 1.300s
[2K
| Adam | epoch: 024 | loss: 0.58550 - acc: 0.6985 -- iter: 064/361
[A[ATraining Step: 279  | total loss: [1m[32m0.58098[0m[0m | time: 1.944s
[2K
| Adam | epoch: 024 | loss: 0.58098 - acc: 0.7005 -- iter: 096/361
[A[ATraining Step: 280  | total loss: [1m[32m0.59372[0m[0m | time: 2.592s
[2K
| Adam | epoch: 024 | loss: 0.59372 - acc: 0.6774 -- iter: 128/361
[A[ATraining Step: 281  | total loss: [1m[32m0.59338[0m[0m | time: 3.219s
[2K
| Adam | epoch: 024 | loss: 0.59338 - acc: 0.6752 -- iter: 160/361
[A[ATraining Step: 282  | total loss: [1m[32m0.59847[0m[0m | time: 3.852s
[2K
| Adam | epoch: 024 | loss: 0.59847 - acc: 0.6640 -- iter: 192/361
[A[ATraining Step: 283  | total loss: [1m[32m0.59533[0m[0m | time: 4.470s
[2K
| Adam | epoch: 024 | loss: 0.59533 - acc: 0.6694 -- iter: 224/361
[A[ATraining Step: 284  | total loss: [1m[32m0.59533[0m[0m | time: 5.099s
[2K
| Adam | epoch: 024 | loss: 0.59533 - acc: 0.6681 -- iter: 256/361
[A[ATraining Step: 285  | total loss: [1m[32m0.59991[0m[0m | time: 5.321s
[2K
| Adam | epoch: 024 | loss: 0.59991 - acc: 0.6638 -- iter: 288/361
[A[ATraining Step: 286  | total loss: [1m[32m0.59282[0m[0m | time: 5.544s
[2K
| Adam | epoch: 024 | loss: 0.59282 - acc: 0.6752 -- iter: 320/361
[A[ATraining Step: 287  | total loss: [1m[32m0.57559[0m[0m | time: 6.193s
[2K
| Adam | epoch: 024 | loss: 0.57559 - acc: 0.6855 -- iter: 352/361
[A[ATraining Step: 288  | total loss: [1m[32m0.56062[0m[0m | time: 7.833s
[2K
| Adam | epoch: 024 | loss: 0.56062 - acc: 0.7013 | val_loss: 0.60033 - val_acc: 0.6579 -- iter: 361/361
--
Training Step: 289  | total loss: [1m[32m0.56173[0m[0m | time: 0.629s
[2K
| Adam | epoch: 025 | loss: 0.56173 - acc: 0.7030 -- iter: 032/361
[A[ATraining Step: 290  | total loss: [1m[32m0.57062[0m[0m | time: 1.465s
[2K
| Adam | epoch: 025 | loss: 0.57062 - acc: 0.7046 -- iter: 064/361
[A[ATraining Step: 291  | total loss: [1m[32m0.55661[0m[0m | time: 2.524s
[2K
| Adam | epoch: 025 | loss: 0.55661 - acc: 0.7060 -- iter: 096/361
[A[ATraining Step: 292  | total loss: [1m[32m0.54800[0m[0m | time: 3.520s
[2K
| Adam | epoch: 025 | loss: 0.54800 - acc: 0.7135 -- iter: 128/361
[A[ATraining Step: 293  | total loss: [1m[32m0.54515[0m[0m | time: 4.475s
[2K
| Adam | epoch: 025 | loss: 0.54515 - acc: 0.7203 -- iter: 160/361
[A[ATraining Step: 294  | total loss: [1m[32m0.54443[0m[0m | time: 5.462s
[2K
| Adam | epoch: 025 | loss: 0.54443 - acc: 0.7170 -- iter: 192/361
[A[ATraining Step: 295  | total loss: [1m[32m0.53424[0m[0m | time: 6.417s
[2K
| Adam | epoch: 025 | loss: 0.53424 - acc: 0.7297 -- iter: 224/361
[A[ATraining Step: 296  | total loss: [1m[32m0.53662[0m[0m | time: 7.428s
[2K
| Adam | epoch: 025 | loss: 0.53662 - acc: 0.7286 -- iter: 256/361
[A[ATraining Step: 297  | total loss: [1m[32m0.54002[0m[0m | time: 8.560s
[2K
| Adam | epoch: 025 | loss: 0.54002 - acc: 0.7214 -- iter: 288/361
[A[ATraining Step: 298  | total loss: [1m[32m0.52410[0m[0m | time: 8.895s
[2K
| Adam | epoch: 025 | loss: 0.52410 - acc: 0.7399 -- iter: 320/361
[A[ATraining Step: 299  | total loss: [1m[32m0.51095[0m[0m | time: 9.175s
[2K
| Adam | epoch: 025 | loss: 0.51095 - acc: 0.7548 -- iter: 352/361
[A[ATraining Step: 300  | total loss: [1m[32m0.49818[0m[0m | time: 11.133s
[2K
| Adam | epoch: 025 | loss: 0.49818 - acc: 0.7682 | val_loss: 0.47945 - val_acc: 0.7544 -- iter: 361/361
--
Training Step: 301  | total loss: [1m[32m0.48750[0m[0m | time: 1.045s
[2K
| Adam | epoch: 026 | loss: 0.48750 - acc: 0.7726 -- iter: 032/361
[A[ATraining Step: 302  | total loss: [1m[32m0.47990[0m[0m | time: 2.143s
[2K
| Adam | epoch: 026 | loss: 0.47990 - acc: 0.7703 -- iter: 064/361
[A[ATraining Step: 303  | total loss: [1m[32m0.47378[0m[0m | time: 3.042s
[2K
| Adam | epoch: 026 | loss: 0.47378 - acc: 0.7777 -- iter: 096/361
[A[ATraining Step: 304  | total loss: [1m[32m0.45664[0m[0m | time: 4.116s
[2K
| Adam | epoch: 026 | loss: 0.45664 - acc: 0.7905 -- iter: 128/361
[A[ATraining Step: 305  | total loss: [1m[32m0.45411[0m[0m | time: 5.206s
[2K
| Adam | epoch: 026 | loss: 0.45411 - acc: 0.7896 -- iter: 160/361
[A[ATraining Step: 306  | total loss: [1m[32m0.46816[0m[0m | time: 6.354s
[2K
| Adam | epoch: 026 | loss: 0.46816 - acc: 0.7763 -- iter: 192/361
[A[ATraining Step: 307  | total loss: [1m[32m0.46291[0m[0m | time: 7.359s
[2K
| Adam | epoch: 026 | loss: 0.46291 - acc: 0.7830 -- iter: 224/361
[A[ATraining Step: 308  | total loss: [1m[32m0.46751[0m[0m | time: 8.310s
[2K
| Adam | epoch: 026 | loss: 0.46751 - acc: 0.7766 -- iter: 256/361
[A[ATraining Step: 309  | total loss: [1m[32m0.45385[0m[0m | time: 9.340s
[2K
| Adam | epoch: 026 | loss: 0.45385 - acc: 0.7833 -- iter: 288/361
[A[ATraining Step: 310  | total loss: [1m[32m0.44971[0m[0m | time: 10.402s
[2K
| Adam | epoch: 026 | loss: 0.44971 - acc: 0.7894 -- iter: 320/361
[A[ATraining Step: 311  | total loss: [1m[32m0.44086[0m[0m | time: 10.816s
[2K
| Adam | epoch: 026 | loss: 0.44086 - acc: 0.7917 -- iter: 352/361
[A[ATraining Step: 312  | total loss: [1m[32m0.41822[0m[0m | time: 12.226s
[2K
| Adam | epoch: 026 | loss: 0.41822 - acc: 0.8014 | val_loss: 0.42115 - val_acc: 0.8070 -- iter: 361/361
--
Training Step: 313  | total loss: [1m[32m0.39667[0m[0m | time: 1.032s
[2K
| Adam | epoch: 027 | loss: 0.39667 - acc: 0.8101 -- iter: 032/361
[A[ATraining Step: 314  | total loss: [1m[32m0.38372[0m[0m | time: 2.055s
[2K
| Adam | epoch: 027 | loss: 0.38372 - acc: 0.8166 -- iter: 064/361
[A[ATraining Step: 315  | total loss: [1m[32m0.37219[0m[0m | time: 3.027s
[2K
| Adam | epoch: 027 | loss: 0.37219 - acc: 0.8318 -- iter: 096/361
[A[ATraining Step: 316  | total loss: [1m[32m0.38097[0m[0m | time: 4.054s
[2K
| Adam | epoch: 027 | loss: 0.38097 - acc: 0.8299 -- iter: 128/361
[A[ATraining Step: 317  | total loss: [1m[32m0.36965[0m[0m | time: 5.048s
[2K
| Adam | epoch: 027 | loss: 0.36965 - acc: 0.8375 -- iter: 160/361
[A[ATraining Step: 318  | total loss: [1m[32m0.35198[0m[0m | time: 6.106s
[2K
| Adam | epoch: 027 | loss: 0.35198 - acc: 0.8507 -- iter: 192/361
[A[ATraining Step: 319  | total loss: [1m[32m0.33749[0m[0m | time: 7.121s
[2K
| Adam | epoch: 027 | loss: 0.33749 - acc: 0.8593 -- iter: 224/361
[A[ATraining Step: 320  | total loss: [1m[32m0.32042[0m[0m | time: 8.070s
[2K
| Adam | epoch: 027 | loss: 0.32042 - acc: 0.8734 -- iter: 256/361
[A[ATraining Step: 321  | total loss: [1m[32m0.32536[0m[0m | time: 9.168s
[2K
| Adam | epoch: 027 | loss: 0.32536 - acc: 0.8673 -- iter: 288/361
[A[ATraining Step: 322  | total loss: [1m[32m0.34194[0m[0m | time: 10.344s
[2K
| Adam | epoch: 027 | loss: 0.34194 - acc: 0.8493 -- iter: 320/361
[A[ATraining Step: 323  | total loss: [1m[32m0.34644[0m[0m | time: 11.363s
[2K
| Adam | epoch: 027 | loss: 0.34644 - acc: 0.8457 -- iter: 352/361
[A[ATraining Step: 324  | total loss: [1m[32m0.34468[0m[0m | time: 12.733s
[2K
| Adam | epoch: 027 | loss: 0.34468 - acc: 0.8517 | val_loss: 0.42697 - val_acc: 0.8596 -- iter: 361/361
--
Training Step: 325  | total loss: [1m[32m0.31865[0m[0m | time: 0.356s
[2K
| Adam | epoch: 028 | loss: 0.31865 - acc: 0.8665 -- iter: 032/361
[A[ATraining Step: 326  | total loss: [1m[32m0.29304[0m[0m | time: 1.244s
[2K
| Adam | epoch: 028 | loss: 0.29304 - acc: 0.8799 -- iter: 064/361
[A[ATraining Step: 327  | total loss: [1m[32m0.31189[0m[0m | time: 2.231s
[2K
| Adam | epoch: 028 | loss: 0.31189 - acc: 0.8763 -- iter: 096/361
[A[ATraining Step: 328  | total loss: [1m[32m0.30354[0m[0m | time: 3.339s
[2K
| Adam | epoch: 028 | loss: 0.30354 - acc: 0.8761 -- iter: 128/361
[A[ATraining Step: 329  | total loss: [1m[32m0.30468[0m[0m | time: 4.540s
[2K
| Adam | epoch: 028 | loss: 0.30468 - acc: 0.8823 -- iter: 160/361
[A[ATraining Step: 330  | total loss: [1m[32m0.30108[0m[0m | time: 5.466s
[2K
| Adam | epoch: 028 | loss: 0.30108 - acc: 0.8847 -- iter: 192/361
[A[ATraining Step: 331  | total loss: [1m[32m0.29517[0m[0m | time: 6.409s
[2K
| Adam | epoch: 028 | loss: 0.29517 - acc: 0.8868 -- iter: 224/361
[A[ATraining Step: 332  | total loss: [1m[32m0.35969[0m[0m | time: 7.431s
[2K
| Adam | epoch: 028 | loss: 0.35969 - acc: 0.8700 -- iter: 256/361
[A[ATraining Step: 333  | total loss: [1m[32m0.36090[0m[0m | time: 8.500s
[2K
| Adam | epoch: 028 | loss: 0.36090 - acc: 0.8705 -- iter: 288/361
[A[ATraining Step: 334  | total loss: [1m[32m0.35465[0m[0m | time: 9.561s
[2K
| Adam | epoch: 028 | loss: 0.35465 - acc: 0.8772 -- iter: 320/361
[A[ATraining Step: 335  | total loss: [1m[32m0.34273[0m[0m | time: 10.706s
[2K
| Adam | epoch: 028 | loss: 0.34273 - acc: 0.8833 -- iter: 352/361
[A[ATraining Step: 336  | total loss: [1m[32m0.32574[0m[0m | time: 12.700s
[2K
| Adam | epoch: 028 | loss: 0.32574 - acc: 0.8887 | val_loss: 0.41076 - val_acc: 0.8246 -- iter: 361/361
--
Training Step: 337  | total loss: [1m[32m0.33226[0m[0m | time: 0.305s
[2K
| Adam | epoch: 029 | loss: 0.33226 - acc: 0.8779 -- iter: 032/361
[A[ATraining Step: 338  | total loss: [1m[32m0.31889[0m[0m | time: 0.515s
[2K
| Adam | epoch: 029 | loss: 0.31889 - acc: 0.8901 -- iter: 064/361
[A[ATraining Step: 339  | total loss: [1m[32m0.30250[0m[0m | time: 1.136s
[2K
| Adam | epoch: 029 | loss: 0.30250 - acc: 0.9011 -- iter: 096/361
[A[ATraining Step: 340  | total loss: [1m[32m0.28560[0m[0m | time: 1.759s
[2K
| Adam | epoch: 029 | loss: 0.28560 - acc: 0.9079 -- iter: 128/361
[A[ATraining Step: 341  | total loss: [1m[32m0.28758[0m[0m | time: 2.381s
[2K
| Adam | epoch: 029 | loss: 0.28758 - acc: 0.9077 -- iter: 160/361
[A[ATraining Step: 342  | total loss: [1m[32m0.29023[0m[0m | time: 3.014s
[2K
| Adam | epoch: 029 | loss: 0.29023 - acc: 0.9107 -- iter: 192/361
[A[ATraining Step: 343  | total loss: [1m[32m0.29207[0m[0m | time: 3.661s
[2K
| Adam | epoch: 029 | loss: 0.29207 - acc: 0.9040 -- iter: 224/361
[A[ATraining Step: 344  | total loss: [1m[32m0.29897[0m[0m | time: 4.315s
[2K
| Adam | epoch: 029 | loss: 0.29897 - acc: 0.8980 -- iter: 256/361
[A[ATraining Step: 345  | total loss: [1m[32m0.36274[0m[0m | time: 4.938s
[2K
| Adam | epoch: 029 | loss: 0.36274 - acc: 0.8832 -- iter: 288/361
[A[ATraining Step: 346  | total loss: [1m[32m0.34870[0m[0m | time: 5.556s
[2K
| Adam | epoch: 029 | loss: 0.34870 - acc: 0.8886 -- iter: 320/361
[A[ATraining Step: 347  | total loss: [1m[32m0.33351[0m[0m | time: 6.185s
[2K
| Adam | epoch: 029 | loss: 0.33351 - acc: 0.8904 -- iter: 352/361
[A[ATraining Step: 348  | total loss: [1m[32m0.31513[0m[0m | time: 7.862s
[2K
| Adam | epoch: 029 | loss: 0.31513 - acc: 0.8951 | val_loss: 0.47158 - val_acc: 0.7632 -- iter: 361/361
--
Training Step: 349  | total loss: [1m[32m0.29620[0m[0m | time: 0.633s
[2K
| Adam | epoch: 030 | loss: 0.29620 - acc: 0.9025 -- iter: 032/361
[A[ATraining Step: 350  | total loss: [1m[32m0.29565[0m[0m | time: 0.850s
[2K
| Adam | epoch: 030 | loss: 0.29565 - acc: 0.9028 -- iter: 064/361
[A[ATraining Step: 351  | total loss: [1m[32m0.30129[0m[0m | time: 1.059s
[2K
| Adam | epoch: 030 | loss: 0.30129 - acc: 0.8903 -- iter: 096/361
[A[ATraining Step: 352  | total loss: [1m[32m0.29044[0m[0m | time: 1.694s
[2K
| Adam | epoch: 030 | loss: 0.29044 - acc: 0.9013 -- iter: 128/361
[A[ATraining Step: 353  | total loss: [1m[32m0.27918[0m[0m | time: 2.320s
[2K
| Adam | epoch: 030 | loss: 0.27918 - acc: 0.9049 -- iter: 160/361
[A[ATraining Step: 354  | total loss: [1m[32m0.28758[0m[0m | time: 2.973s
[2K
| Adam | epoch: 030 | loss: 0.28758 - acc: 0.9051 -- iter: 192/361
[A[ATraining Step: 355  | total loss: [1m[32m0.28855[0m[0m | time: 3.594s
[2K
| Adam | epoch: 030 | loss: 0.28855 - acc: 0.9020 -- iter: 224/361
[A[ATraining Step: 356  | total loss: [1m[32m0.28988[0m[0m | time: 4.238s
[2K
| Adam | epoch: 030 | loss: 0.28988 - acc: 0.8993 -- iter: 256/361
[A[ATraining Step: 357  | total loss: [1m[32m0.28329[0m[0m | time: 4.874s
[2K
| Adam | epoch: 030 | loss: 0.28329 - acc: 0.9032 -- iter: 288/361
[A[ATraining Step: 358  | total loss: [1m[32m0.29216[0m[0m | time: 5.511s
[2K
| Adam | epoch: 030 | loss: 0.29216 - acc: 0.9035 -- iter: 320/361
[A[ATraining Step: 359  | total loss: [1m[32m0.28881[0m[0m | time: 6.159s
[2K
| Adam | epoch: 030 | loss: 0.28881 - acc: 0.9006 -- iter: 352/361
[A[ATraining Step: 360  | total loss: [1m[32m0.28883[0m[0m | time: 7.786s
[2K
| Adam | epoch: 030 | loss: 0.28883 - acc: 0.8981 | val_loss: 0.31521 - val_acc: 0.8684 -- iter: 361/361
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9359375
Validation AUPRC:0.9577152047558511
Test AUC:0.9128125
Test AUPRC:0.9438318632409806
BestTestF1Score	0.88	0.77	0.88	0.96	0.81	52	2	48	12	0.58
BestTestMCCScore	0.88	0.77	0.88	0.96	0.81	52	2	48	12	0.58
BestTestAccuracyScore	0.88	0.77	0.88	0.96	0.81	52	2	48	12	0.58
BestValidationF1Score	0.89	0.78	0.89	0.96	0.83	53	2	48	11	0.58
BestValidationMCC	0.89	0.78	0.89	0.96	0.83	53	2	48	11	0.58
BestValidationAccuracy	0.89	0.78	0.89	0.96	0.83	53	2	48	11	0.58
TestPredictions (Threshold:0.58)
CHEMBL1910602,TN,INACT,0.11999999731779099	CHEMBL3660377,TP,ACT,0.9900000095367432	CHEMBL489646,TN,INACT,0.09000000357627869	CHEMBL3660360,TP,ACT,0.9399999976158142	CHEMBL1908397,FN,ACT,0.17000000178813934	CHEMBL3660453,TP,ACT,0.9900000095367432	CHEMBL550608,TN,INACT,0.07000000029802322	CHEMBL3660400,TP,ACT,0.9800000190734863	CHEMBL3660447,TP,ACT,0.9700000286102295	CHEMBL3665094,FN,ACT,0.1899999976158142	CHEMBL3665052,TP,ACT,0.8399999737739563	CHEMBL3660436,TP,ACT,0.9900000095367432	CHEMBL550855,TN,INACT,0.17000000178813934	CHEMBL104264,TN,INACT,0.09000000357627869	CHEMBL3660395,TP,ACT,0.9599999785423279	CHEMBL3665053,TP,ACT,0.7200000286102295	CHEMBL1910373,TN,INACT,0.23000000417232513	CHEMBL3421636,TN,INACT,0.15000000596046448	CHEMBL100811,TN,INACT,0.07000000029802322	CHEMBL3665031,TP,ACT,0.949999988079071	CHEMBL3660309,TP,ACT,1.0	CHEMBL3665054,TP,ACT,0.699999988079071	CHEMBL3356003,FN,ACT,0.09000000357627869	CHEMBL3665062,TP,ACT,0.9700000286102295	CHEMBL491064,TN,INACT,0.07999999821186066	CHEMBL485502,TN,INACT,0.18000000715255737	CHEMBL173478,TN,INACT,0.15000000596046448	CHEMBL1801932,TN,INACT,0.10999999940395355	CHEMBL476189,TN,INACT,0.12999999523162842	CHEMBL3660440,TP,ACT,1.0	CHEMBL490241,TN,INACT,0.07000000029802322	CHEMBL3660397,TP,ACT,1.0	CHEMBL2163610,TN,INACT,0.07999999821186066	CHEMBL3660376,TP,ACT,1.0	CHEMBL3660341,TP,ACT,1.0	CHEMBL2346665,TN,INACT,0.07999999821186066	CHEMBL456378,TN,INACT,0.3400000035762787	CHEMBL3660334,TP,ACT,0.9900000095367432	CHEMBL99699,TN,INACT,0.10999999940395355	CHEMBL1922122,TN,INACT,0.07000000029802322	CHEMBL101558,TN,INACT,0.07000000029802322	CHEMBL3660390,TP,ACT,0.9900000095367432	CHEMBL3665060,TP,ACT,0.75	CHEMBL120703,TN,INACT,0.07000000029802322	CHEMBL418793,TN,INACT,0.07000000029802322	CHEMBL3660355,TP,ACT,0.8299999833106995	CHEMBL3660330,TP,ACT,0.9900000095367432	CHEMBL513336,FP,INACT,0.9700000286102295	CHEMBL190201,TN,INACT,0.23000000417232513	CHEMBL3660418,TP,ACT,1.0	CHEMBL525921,TN,INACT,0.10999999940395355	CHEMBL328627,TN,INACT,0.07999999821186066	CHEMBL3665077,FN,ACT,0.09000000357627869	CHEMBL1235213,TN,INACT,0.25	CHEMBL3660340,TP,ACT,0.9700000286102295	CHEMBL3660467,TP,ACT,0.9800000190734863	CHEMBL3660439,TP,ACT,0.6800000071525574	CHEMBL3660469,TP,ACT,0.9900000095367432	CHEMBL3665037,FN,ACT,0.5299999713897705	CHEMBL3665032,FN,ACT,0.44999998807907104	CHEMBL3660343,TP,ACT,0.9300000071525574	CHEMBL133214,TN,INACT,0.05999999865889549	CHEMBL3356004,FN,ACT,0.1599999964237213	CHEMBL335966,TN,INACT,0.20999999344348907	CHEMBL1734241,TN,INACT,0.1599999964237213	CHEMBL3660391,TP,ACT,0.9900000095367432	CHEMBL100675,TN,INACT,0.07000000029802322	CHEMBL3660319,TP,ACT,0.9900000095367432	CHEMBL234944,TN,INACT,0.09000000357627869	CHEMBL1910759,TN,INACT,0.18000000715255737	CHEMBL3660337,TP,ACT,1.0	CHEMBL1721885,FN,ACT,0.10999999940395355	CHEMBL77262,TN,INACT,0.10999999940395355	CHEMBL563733,TN,INACT,0.15000000596046448	CHEMBL3665065,TP,ACT,0.9700000286102295	CHEMBL558859,TN,INACT,0.07000000029802322	CHEMBL551663,TN,INACT,0.09000000357627869	CHEMBL3265268,TP,ACT,0.8100000023841858	CHEMBL388978,FN,ACT,0.10999999940395355	CHEMBL1910758,TN,INACT,0.1599999964237213	CHEMBL249697,FN,ACT,0.09000000357627869	CHEMBL3660322,TP,ACT,1.0	CHEMBL486302,TN,INACT,0.17000000178813934	CHEMBL337454,TN,INACT,0.2800000011920929	CHEMBL1910762,TN,INACT,0.12999999523162842	CHEMBL3665026,TP,ACT,0.800000011920929	CHEMBL1789941,FN,ACT,0.07000000029802322	CHEMBL86795,TN,INACT,0.5199999809265137	CHEMBL3660437,TP,ACT,0.9800000190734863	CHEMBL3660463,TP,ACT,0.9900000095367432	CHEMBL3665066,TP,ACT,0.9399999976158142	CHEMBL3356000,TP,ACT,0.9599999785423279	CHEMBL3660336,TP,ACT,1.0	CHEMBL3660373,TP,ACT,1.0	CHEMBL483535,TN,INACT,0.09000000357627869	CHEMBL3660317,TP,ACT,0.9300000071525574	CHEMBL3355999,TP,ACT,0.9599999785423279	CHEMBL1784660,TN,INACT,0.46000000834465027	CHEMBL3660423,TP,ACT,0.9900000095367432	CHEMBL2042136,TN,INACT,0.09000000357627869	CHEMBL2163612,TN,INACT,0.3499999940395355	CHEMBL3660352,TP,ACT,0.9900000095367432	CHEMBL3660412,TP,ACT,0.7799999713897705	CHEMBL3265261,TP,ACT,0.8799999952316284	CHEMBL3265269,TP,ACT,0.8899999856948853	CHEMBL551318,TN,INACT,0.38999998569488525	CHEMBL151,FP,INACT,0.8299999833106995	CHEMBL490251,TN,INACT,0.07999999821186066	CHEMBL3660410,TP,ACT,0.9900000095367432	CHEMBL3660354,TP,ACT,1.0	CHEMBL3665081,TP,ACT,0.6700000166893005	CHEMBL3665020,FN,ACT,0.4699999988079071	CHEMBL3665050,TP,ACT,0.949999988079071	CHEMBL517154,TN,INACT,0.18000000715255737	

