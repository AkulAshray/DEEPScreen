CNNModel CHEMBL2288 adam 0.0005 30 128 0 0.6 False True
Number of active compounds :	165
Number of inactive compounds :	165
---------------------------------
Run id: CNNModel_CHEMBL2288_adam_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2288_adam_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 211
Validation samples: 66
--
Training Step: 1  | time: 0.753s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/211
[A[ATraining Step: 2  | total loss: [1m[32m0.62383[0m[0m | time: 1.356s
[2K
| Adam | epoch: 001 | loss: 0.62383 - acc: 0.3937 -- iter: 064/211
[A[ATraining Step: 3  | total loss: [1m[32m0.68091[0m[0m | time: 1.982s
[2K
| Adam | epoch: 001 | loss: 0.68091 - acc: 0.4551 -- iter: 096/211
[A[ATraining Step: 4  | total loss: [1m[32m0.68997[0m[0m | time: 2.609s
[2K
| Adam | epoch: 001 | loss: 0.68997 - acc: 0.4653 -- iter: 128/211
[A[ATraining Step: 5  | total loss: [1m[32m0.69241[0m[0m | time: 3.225s
[2K
| Adam | epoch: 001 | loss: 0.69241 - acc: 0.4028 -- iter: 160/211
[A[ATraining Step: 6  | total loss: [1m[32m0.69315[0m[0m | time: 3.854s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.4452 -- iter: 192/211
[A[ATraining Step: 7  | total loss: [1m[32m0.69410[0m[0m | time: 5.255s
[2K
| Adam | epoch: 001 | loss: 0.69410 - acc: 0.4031 | val_loss: 0.69272 - val_acc: 0.6515 -- iter: 211/211
--
Training Step: 8  | total loss: [1m[32m0.69349[0m[0m | time: 0.388s
[2K
| Adam | epoch: 002 | loss: 0.69349 - acc: 0.5020 -- iter: 032/211
[A[ATraining Step: 9  | total loss: [1m[32m0.69352[0m[0m | time: 1.009s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.5706 -- iter: 064/211
[A[ATraining Step: 10  | total loss: [1m[32m0.69338[0m[0m | time: 1.626s
[2K
| Adam | epoch: 002 | loss: 0.69338 - acc: 0.5509 -- iter: 096/211
[A[ATraining Step: 11  | total loss: [1m[32m0.69313[0m[0m | time: 2.269s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.5860 -- iter: 128/211
[A[ATraining Step: 12  | total loss: [1m[32m0.69353[0m[0m | time: 2.885s
[2K
| Adam | epoch: 002 | loss: 0.69353 - acc: 0.5192 -- iter: 160/211
[A[ATraining Step: 13  | total loss: [1m[32m0.69275[0m[0m | time: 3.517s
[2K
| Adam | epoch: 002 | loss: 0.69275 - acc: 0.5511 -- iter: 192/211
[A[ATraining Step: 14  | total loss: [1m[32m0.69274[0m[0m | time: 5.135s
[2K
| Adam | epoch: 002 | loss: 0.69274 - acc: 0.5174 | val_loss: 0.69188 - val_acc: 0.6667 -- iter: 211/211
--
Training Step: 15  | total loss: [1m[32m0.69280[0m[0m | time: 0.407s
[2K
| Adam | epoch: 003 | loss: 0.69280 - acc: 0.5106 -- iter: 032/211
[A[ATraining Step: 16  | total loss: [1m[32m0.69280[0m[0m | time: 0.786s
[2K
| Adam | epoch: 003 | loss: 0.69280 - acc: 0.5362 -- iter: 064/211
[A[ATraining Step: 17  | total loss: [1m[32m0.69267[0m[0m | time: 1.410s
[2K
| Adam | epoch: 003 | loss: 0.69267 - acc: 0.5516 -- iter: 096/211
[A[ATraining Step: 18  | total loss: [1m[32m0.69246[0m[0m | time: 2.030s
[2K
| Adam | epoch: 003 | loss: 0.69246 - acc: 0.5878 -- iter: 128/211
[A[ATraining Step: 19  | total loss: [1m[32m0.69204[0m[0m | time: 2.652s
[2K
| Adam | epoch: 003 | loss: 0.69204 - acc: 0.6002 -- iter: 160/211
[A[ATraining Step: 20  | total loss: [1m[32m0.69208[0m[0m | time: 3.253s
[2K
| Adam | epoch: 003 | loss: 0.69208 - acc: 0.5881 -- iter: 192/211
[A[ATraining Step: 21  | total loss: [1m[32m0.69136[0m[0m | time: 4.879s
[2K
| Adam | epoch: 003 | loss: 0.69136 - acc: 0.6092 | val_loss: 0.68758 - val_acc: 0.6515 -- iter: 211/211
--
Training Step: 22  | total loss: [1m[32m0.69107[0m[0m | time: 0.623s
[2K
| Adam | epoch: 004 | loss: 0.69107 - acc: 0.6140 -- iter: 032/211
[A[ATraining Step: 23  | total loss: [1m[32m0.69003[0m[0m | time: 1.006s
[2K
| Adam | epoch: 004 | loss: 0.69003 - acc: 0.6262 -- iter: 064/211
[A[ATraining Step: 24  | total loss: [1m[32m0.68964[0m[0m | time: 1.385s
[2K
| Adam | epoch: 004 | loss: 0.68964 - acc: 0.6425 -- iter: 096/211
[A[ATraining Step: 25  | total loss: [1m[32m0.68832[0m[0m | time: 2.005s
[2K
| Adam | epoch: 004 | loss: 0.68832 - acc: 0.6683 -- iter: 128/211
[A[ATraining Step: 26  | total loss: [1m[32m0.68778[0m[0m | time: 2.631s
[2K
| Adam | epoch: 004 | loss: 0.68778 - acc: 0.6403 -- iter: 160/211
[A[ATraining Step: 27  | total loss: [1m[32m0.68668[0m[0m | time: 3.271s
[2K
| Adam | epoch: 004 | loss: 0.68668 - acc: 0.6122 -- iter: 192/211
[A[ATraining Step: 28  | total loss: [1m[32m0.68388[0m[0m | time: 4.915s
[2K
| Adam | epoch: 004 | loss: 0.68388 - acc: 0.6154 | val_loss: 0.65698 - val_acc: 0.6364 -- iter: 211/211
--
Training Step: 29  | total loss: [1m[32m0.68140[0m[0m | time: 0.630s
[2K
| Adam | epoch: 005 | loss: 0.68140 - acc: 0.6330 -- iter: 032/211
[A[ATraining Step: 30  | total loss: [1m[32m0.67677[0m[0m | time: 1.242s
[2K
| Adam | epoch: 005 | loss: 0.67677 - acc: 0.6459 -- iter: 064/211
[A[ATraining Step: 31  | total loss: [1m[32m0.67296[0m[0m | time: 1.640s
[2K
| Adam | epoch: 005 | loss: 0.67296 - acc: 0.6194 -- iter: 096/211
[A[ATraining Step: 32  | total loss: [1m[32m0.66290[0m[0m | time: 2.018s
[2K
| Adam | epoch: 005 | loss: 0.66290 - acc: 0.6577 -- iter: 128/211
[A[ATraining Step: 33  | total loss: [1m[32m0.65063[0m[0m | time: 2.623s
[2K
| Adam | epoch: 005 | loss: 0.65063 - acc: 0.6751 -- iter: 160/211
[A[ATraining Step: 34  | total loss: [1m[32m0.64101[0m[0m | time: 3.225s
[2K
| Adam | epoch: 005 | loss: 0.64101 - acc: 0.6777 -- iter: 192/211
[A[ATraining Step: 35  | total loss: [1m[32m0.65617[0m[0m | time: 4.841s
[2K
| Adam | epoch: 005 | loss: 0.65617 - acc: 0.6536 | val_loss: 0.65509 - val_acc: 0.5909 -- iter: 211/211
--
Training Step: 36  | total loss: [1m[32m0.63700[0m[0m | time: 0.636s
[2K
| Adam | epoch: 006 | loss: 0.63700 - acc: 0.6797 -- iter: 032/211
[A[ATraining Step: 37  | total loss: [1m[32m0.65071[0m[0m | time: 1.253s
[2K
| Adam | epoch: 006 | loss: 0.65071 - acc: 0.6500 -- iter: 064/211
[A[ATraining Step: 38  | total loss: [1m[32m0.66923[0m[0m | time: 1.863s
[2K
| Adam | epoch: 006 | loss: 0.66923 - acc: 0.6329 -- iter: 096/211
[A[ATraining Step: 39  | total loss: [1m[32m0.65629[0m[0m | time: 2.244s
[2K
| Adam | epoch: 006 | loss: 0.65629 - acc: 0.6434 -- iter: 128/211
[A[ATraining Step: 40  | total loss: [1m[32m0.66446[0m[0m | time: 2.619s
[2K
| Adam | epoch: 006 | loss: 0.66446 - acc: 0.6214 -- iter: 160/211
[A[ATraining Step: 41  | total loss: [1m[32m0.67758[0m[0m | time: 3.239s
[2K
| Adam | epoch: 006 | loss: 0.67758 - acc: 0.6039 -- iter: 192/211
[A[ATraining Step: 42  | total loss: [1m[32m0.66487[0m[0m | time: 4.858s
[2K
| Adam | epoch: 006 | loss: 0.66487 - acc: 0.6190 | val_loss: 0.62279 - val_acc: 0.6061 -- iter: 211/211
--
Training Step: 43  | total loss: [1m[32m0.65219[0m[0m | time: 0.618s
[2K
| Adam | epoch: 007 | loss: 0.65219 - acc: 0.6311 -- iter: 032/211
[A[ATraining Step: 44  | total loss: [1m[32m0.64289[0m[0m | time: 1.247s
[2K
| Adam | epoch: 007 | loss: 0.64289 - acc: 0.6354 -- iter: 064/211
[A[ATraining Step: 45  | total loss: [1m[32m0.63979[0m[0m | time: 1.855s
[2K
| Adam | epoch: 007 | loss: 0.63979 - acc: 0.6443 -- iter: 096/211
[A[ATraining Step: 46  | total loss: [1m[32m0.63329[0m[0m | time: 2.454s
[2K
| Adam | epoch: 007 | loss: 0.63329 - acc: 0.6411 -- iter: 128/211
[A[ATraining Step: 47  | total loss: [1m[32m0.62701[0m[0m | time: 2.846s
[2K
| Adam | epoch: 007 | loss: 0.62701 - acc: 0.6589 -- iter: 160/211
[A[ATraining Step: 48  | total loss: [1m[32m0.62832[0m[0m | time: 3.231s
[2K
| Adam | epoch: 007 | loss: 0.62832 - acc: 0.6545 -- iter: 192/211
[A[ATraining Step: 49  | total loss: [1m[32m0.63053[0m[0m | time: 4.846s
[2K
| Adam | epoch: 007 | loss: 0.63053 - acc: 0.6509 | val_loss: 0.59352 - val_acc: 0.6364 -- iter: 211/211
--
Training Step: 50  | total loss: [1m[32m0.61797[0m[0m | time: 0.619s
[2K
| Adam | epoch: 008 | loss: 0.61797 - acc: 0.6663 -- iter: 032/211
[A[ATraining Step: 51  | total loss: [1m[32m0.61261[0m[0m | time: 1.224s
[2K
| Adam | epoch: 008 | loss: 0.61261 - acc: 0.6695 -- iter: 064/211
[A[ATraining Step: 52  | total loss: [1m[32m0.60765[0m[0m | time: 1.849s
[2K
| Adam | epoch: 008 | loss: 0.60765 - acc: 0.6628 -- iter: 096/211
[A[ATraining Step: 53  | total loss: [1m[32m0.59097[0m[0m | time: 2.453s
[2K
| Adam | epoch: 008 | loss: 0.59097 - acc: 0.6711 -- iter: 128/211
[A[ATraining Step: 54  | total loss: [1m[32m0.58552[0m[0m | time: 3.062s
[2K
| Adam | epoch: 008 | loss: 0.58552 - acc: 0.6871 -- iter: 160/211
[A[ATraining Step: 55  | total loss: [1m[32m0.58849[0m[0m | time: 3.436s
[2K
| Adam | epoch: 008 | loss: 0.58849 - acc: 0.6827 -- iter: 192/211
[A[ATraining Step: 56  | total loss: [1m[32m0.59486[0m[0m | time: 4.822s
[2K
| Adam | epoch: 008 | loss: 0.59486 - acc: 0.6681 | val_loss: 0.62715 - val_acc: 0.6061 -- iter: 211/211
--
Training Step: 57  | total loss: [1m[32m0.59887[0m[0m | time: 0.620s
[2K
| Adam | epoch: 009 | loss: 0.59887 - acc: 0.6630 -- iter: 032/211
[A[ATraining Step: 58  | total loss: [1m[32m0.60329[0m[0m | time: 1.224s
[2K
| Adam | epoch: 009 | loss: 0.60329 - acc: 0.6621 -- iter: 064/211
[A[ATraining Step: 59  | total loss: [1m[32m0.57666[0m[0m | time: 1.829s
[2K
| Adam | epoch: 009 | loss: 0.57666 - acc: 0.6865 -- iter: 096/211
[A[ATraining Step: 60  | total loss: [1m[32m0.56720[0m[0m | time: 2.448s
[2K
| Adam | epoch: 009 | loss: 0.56720 - acc: 0.6949 -- iter: 128/211
[A[ATraining Step: 61  | total loss: [1m[32m0.57418[0m[0m | time: 3.066s
[2K
| Adam | epoch: 009 | loss: 0.57418 - acc: 0.6980 -- iter: 160/211
[A[ATraining Step: 62  | total loss: [1m[32m0.56508[0m[0m | time: 3.682s
[2K
| Adam | epoch: 009 | loss: 0.56508 - acc: 0.6967 -- iter: 192/211
[A[ATraining Step: 63  | total loss: [1m[32m0.55504[0m[0m | time: 5.062s
[2K
| Adam | epoch: 009 | loss: 0.55504 - acc: 0.7034 | val_loss: 0.57643 - val_acc: 0.6212 -- iter: 211/211
--
Training Step: 64  | total loss: [1m[32m0.53835[0m[0m | time: 0.410s
[2K
| Adam | epoch: 010 | loss: 0.53835 - acc: 0.7142 -- iter: 032/211
[A[ATraining Step: 65  | total loss: [1m[32m0.51993[0m[0m | time: 1.038s
[2K
| Adam | epoch: 010 | loss: 0.51993 - acc: 0.7429 -- iter: 064/211
[A[ATraining Step: 66  | total loss: [1m[32m0.50449[0m[0m | time: 1.652s
[2K
| Adam | epoch: 010 | loss: 0.50449 - acc: 0.7514 -- iter: 096/211
[A[ATraining Step: 67  | total loss: [1m[32m0.52395[0m[0m | time: 2.257s
[2K
| Adam | epoch: 010 | loss: 0.52395 - acc: 0.7325 -- iter: 128/211
[A[ATraining Step: 68  | total loss: [1m[32m0.50398[0m[0m | time: 2.903s
[2K
| Adam | epoch: 010 | loss: 0.50398 - acc: 0.7420 -- iter: 160/211
[A[ATraining Step: 69  | total loss: [1m[32m0.50903[0m[0m | time: 3.514s
[2K
| Adam | epoch: 010 | loss: 0.50903 - acc: 0.7319 -- iter: 192/211
[A[ATraining Step: 70  | total loss: [1m[32m0.50940[0m[0m | time: 5.121s
[2K
| Adam | epoch: 010 | loss: 0.50940 - acc: 0.7376 | val_loss: 0.70539 - val_acc: 0.6970 -- iter: 211/211
--
Training Step: 71  | total loss: [1m[32m0.50981[0m[0m | time: 0.386s
[2K
| Adam | epoch: 011 | loss: 0.50981 - acc: 0.7462 -- iter: 032/211
[A[ATraining Step: 72  | total loss: [1m[32m0.50992[0m[0m | time: 0.766s
[2K
| Adam | epoch: 011 | loss: 0.50992 - acc: 0.7510 -- iter: 064/211
[A[ATraining Step: 73  | total loss: [1m[32m0.50765[0m[0m | time: 1.369s
[2K
| Adam | epoch: 011 | loss: 0.50765 - acc: 0.7553 -- iter: 096/211
[A[ATraining Step: 74  | total loss: [1m[32m0.49285[0m[0m | time: 2.001s
[2K
| Adam | epoch: 011 | loss: 0.49285 - acc: 0.7650 -- iter: 128/211
[A[ATraining Step: 75  | total loss: [1m[32m0.49318[0m[0m | time: 2.626s
[2K
| Adam | epoch: 011 | loss: 0.49318 - acc: 0.7600 -- iter: 160/211
[A[ATraining Step: 76  | total loss: [1m[32m0.48291[0m[0m | time: 3.234s
[2K
| Adam | epoch: 011 | loss: 0.48291 - acc: 0.7690 -- iter: 192/211
[A[ATraining Step: 77  | total loss: [1m[32m0.48204[0m[0m | time: 4.850s
[2K
| Adam | epoch: 011 | loss: 0.48204 - acc: 0.7703 | val_loss: 0.57194 - val_acc: 0.6970 -- iter: 211/211
--
Training Step: 78  | total loss: [1m[32m0.47357[0m[0m | time: 0.634s
[2K
| Adam | epoch: 012 | loss: 0.47357 - acc: 0.7714 -- iter: 032/211
[A[ATraining Step: 79  | total loss: [1m[32m0.47517[0m[0m | time: 1.020s
[2K
| Adam | epoch: 012 | loss: 0.47517 - acc: 0.7757 -- iter: 064/211
[A[ATraining Step: 80  | total loss: [1m[32m0.47867[0m[0m | time: 1.408s
[2K
| Adam | epoch: 012 | loss: 0.47867 - acc: 0.7609 -- iter: 096/211
[A[ATraining Step: 81  | total loss: [1m[32m0.46692[0m[0m | time: 2.031s
[2K
| Adam | epoch: 012 | loss: 0.46692 - acc: 0.7798 -- iter: 128/211
[A[ATraining Step: 82  | total loss: [1m[32m0.45638[0m[0m | time: 2.644s
[2K
| Adam | epoch: 012 | loss: 0.45638 - acc: 0.7831 -- iter: 160/211
[A[ATraining Step: 83  | total loss: [1m[32m0.46737[0m[0m | time: 3.249s
[2K
| Adam | epoch: 012 | loss: 0.46737 - acc: 0.7766 -- iter: 192/211
[A[ATraining Step: 84  | total loss: [1m[32m0.50078[0m[0m | time: 4.875s
[2K
| Adam | epoch: 012 | loss: 0.50078 - acc: 0.7490 | val_loss: 0.55809 - val_acc: 0.6818 -- iter: 211/211
--
Training Step: 85  | total loss: [1m[32m0.48330[0m[0m | time: 0.604s
[2K
| Adam | epoch: 013 | loss: 0.48330 - acc: 0.7616 -- iter: 032/211
[A[ATraining Step: 86  | total loss: [1m[32m0.47776[0m[0m | time: 1.219s
[2K
| Adam | epoch: 013 | loss: 0.47776 - acc: 0.7635 -- iter: 064/211
[A[ATraining Step: 87  | total loss: [1m[32m0.47086[0m[0m | time: 1.599s
[2K
| Adam | epoch: 013 | loss: 0.47086 - acc: 0.7653 -- iter: 096/211
[A[ATraining Step: 88  | total loss: [1m[32m0.48590[0m[0m | time: 1.977s
[2K
| Adam | epoch: 013 | loss: 0.48590 - acc: 0.7519 -- iter: 128/211
[A[ATraining Step: 89  | total loss: [1m[32m0.50621[0m[0m | time: 2.594s
[2K
| Adam | epoch: 013 | loss: 0.50621 - acc: 0.7346 -- iter: 160/211
[A[ATraining Step: 90  | total loss: [1m[32m0.50714[0m[0m | time: 3.211s
[2K
| Adam | epoch: 013 | loss: 0.50714 - acc: 0.7299 -- iter: 192/211
[A[ATraining Step: 91  | total loss: [1m[32m0.50863[0m[0m | time: 4.836s
[2K
| Adam | epoch: 013 | loss: 0.50863 - acc: 0.7226 | val_loss: 0.63118 - val_acc: 0.5909 -- iter: 211/211
--
Training Step: 92  | total loss: [1m[32m0.49397[0m[0m | time: 0.615s
[2K
| Adam | epoch: 014 | loss: 0.49397 - acc: 0.7347 -- iter: 032/211
[A[ATraining Step: 93  | total loss: [1m[32m0.49868[0m[0m | time: 1.220s
[2K
| Adam | epoch: 014 | loss: 0.49868 - acc: 0.7268 -- iter: 064/211
[A[ATraining Step: 94  | total loss: [1m[32m0.48878[0m[0m | time: 1.815s
[2K
| Adam | epoch: 014 | loss: 0.48878 - acc: 0.7354 -- iter: 096/211
[A[ATraining Step: 95  | total loss: [1m[32m0.48728[0m[0m | time: 2.189s
[2K
| Adam | epoch: 014 | loss: 0.48728 - acc: 0.7369 -- iter: 128/211
[A[ATraining Step: 96  | total loss: [1m[32m0.48328[0m[0m | time: 2.603s
[2K
| Adam | epoch: 014 | loss: 0.48328 - acc: 0.7421 -- iter: 160/211
[A[ATraining Step: 97  | total loss: [1m[32m0.47424[0m[0m | time: 3.243s
[2K
| Adam | epoch: 014 | loss: 0.47424 - acc: 0.7521 -- iter: 192/211
[A[ATraining Step: 98  | total loss: [1m[32m0.46337[0m[0m | time: 4.855s
[2K
| Adam | epoch: 014 | loss: 0.46337 - acc: 0.7613 | val_loss: 0.60181 - val_acc: 0.7424 -- iter: 211/211
--
Training Step: 99  | total loss: [1m[32m0.47483[0m[0m | time: 0.771s
[2K
| Adam | epoch: 015 | loss: 0.47483 - acc: 0.7508 -- iter: 032/211
[A[ATraining Step: 100  | total loss: [1m[32m0.46392[0m[0m | time: 1.388s
[2K
| Adam | epoch: 015 | loss: 0.46392 - acc: 0.7570 -- iter: 064/211
[A[ATraining Step: 101  | total loss: [1m[32m0.47597[0m[0m | time: 1.990s
[2K
| Adam | epoch: 015 | loss: 0.47597 - acc: 0.7469 -- iter: 096/211
[A[ATraining Step: 102  | total loss: [1m[32m0.46117[0m[0m | time: 2.601s
[2K
| Adam | epoch: 015 | loss: 0.46117 - acc: 0.7597 -- iter: 128/211
[A[ATraining Step: 103  | total loss: [1m[32m0.44756[0m[0m | time: 2.985s
[2K
| Adam | epoch: 015 | loss: 0.44756 - acc: 0.7681 -- iter: 160/211
[A[ATraining Step: 104  | total loss: [1m[32m0.45801[0m[0m | time: 3.366s
[2K
| Adam | epoch: 015 | loss: 0.45801 - acc: 0.7702 -- iter: 192/211
[A[ATraining Step: 105  | total loss: [1m[32m0.44245[0m[0m | time: 4.981s
[2K
| Adam | epoch: 015 | loss: 0.44245 - acc: 0.7827 | val_loss: 0.55513 - val_acc: 0.6970 -- iter: 211/211
--
Training Step: 106  | total loss: [1m[32m0.44866[0m[0m | time: 0.627s
[2K
| Adam | epoch: 016 | loss: 0.44866 - acc: 0.7763 -- iter: 032/211
[A[ATraining Step: 107  | total loss: [1m[32m0.44826[0m[0m | time: 1.239s
[2K
| Adam | epoch: 016 | loss: 0.44826 - acc: 0.7799 -- iter: 064/211
[A[ATraining Step: 108  | total loss: [1m[32m0.43072[0m[0m | time: 1.850s
[2K
| Adam | epoch: 016 | loss: 0.43072 - acc: 0.7957 -- iter: 096/211
[A[ATraining Step: 109  | total loss: [1m[32m0.42412[0m[0m | time: 2.457s
[2K
| Adam | epoch: 016 | loss: 0.42412 - acc: 0.8036 -- iter: 128/211
[A[ATraining Step: 110  | total loss: [1m[32m0.41867[0m[0m | time: 3.075s
[2K
| Adam | epoch: 016 | loss: 0.41867 - acc: 0.8045 -- iter: 160/211
[A[ATraining Step: 111  | total loss: [1m[32m0.40530[0m[0m | time: 3.459s
[2K
| Adam | epoch: 016 | loss: 0.40530 - acc: 0.8147 -- iter: 192/211
[A[ATraining Step: 112  | total loss: [1m[32m0.40087[0m[0m | time: 4.848s
[2K
| Adam | epoch: 016 | loss: 0.40087 - acc: 0.8227 | val_loss: 0.56294 - val_acc: 0.7121 -- iter: 211/211
--
Training Step: 113  | total loss: [1m[32m0.39295[0m[0m | time: 0.627s
[2K
| Adam | epoch: 017 | loss: 0.39295 - acc: 0.8299 -- iter: 032/211
[A[ATraining Step: 114  | total loss: [1m[32m0.38592[0m[0m | time: 1.246s
[2K
| Adam | epoch: 017 | loss: 0.38592 - acc: 0.8406 -- iter: 064/211
[A[ATraining Step: 115  | total loss: [1m[32m0.37302[0m[0m | time: 1.853s
[2K
| Adam | epoch: 017 | loss: 0.37302 - acc: 0.8535 -- iter: 096/211
[A[ATraining Step: 116  | total loss: [1m[32m0.38035[0m[0m | time: 2.446s
[2K
| Adam | epoch: 017 | loss: 0.38035 - acc: 0.8462 -- iter: 128/211
[A[ATraining Step: 117  | total loss: [1m[32m0.36629[0m[0m | time: 3.051s
[2K
| Adam | epoch: 017 | loss: 0.36629 - acc: 0.8460 -- iter: 160/211
[A[ATraining Step: 118  | total loss: [1m[32m0.35396[0m[0m | time: 3.673s
[2K
| Adam | epoch: 017 | loss: 0.35396 - acc: 0.8520 -- iter: 192/211
[A[ATraining Step: 119  | total loss: [1m[32m0.35544[0m[0m | time: 5.053s
[2K
| Adam | epoch: 017 | loss: 0.35544 - acc: 0.8512 | val_loss: 0.67517 - val_acc: 0.6364 -- iter: 211/211
--
Training Step: 120  | total loss: [1m[32m0.37189[0m[0m | time: 0.403s
[2K
| Adam | epoch: 018 | loss: 0.37189 - acc: 0.8450 -- iter: 032/211
[A[ATraining Step: 121  | total loss: [1m[32m0.37544[0m[0m | time: 1.026s
[2K
| Adam | epoch: 018 | loss: 0.37544 - acc: 0.8395 -- iter: 064/211
[A[ATraining Step: 122  | total loss: [1m[32m0.36089[0m[0m | time: 1.645s
[2K
| Adam | epoch: 018 | loss: 0.36089 - acc: 0.8555 -- iter: 096/211
[A[ATraining Step: 123  | total loss: [1m[32m0.35318[0m[0m | time: 2.251s
[2K
| Adam | epoch: 018 | loss: 0.35318 - acc: 0.8606 -- iter: 128/211
[A[ATraining Step: 124  | total loss: [1m[32m0.35537[0m[0m | time: 2.860s
[2K
| Adam | epoch: 018 | loss: 0.35537 - acc: 0.8589 -- iter: 160/211
[A[ATraining Step: 125  | total loss: [1m[32m0.35120[0m[0m | time: 3.483s
[2K
| Adam | epoch: 018 | loss: 0.35120 - acc: 0.8605 -- iter: 192/211
[A[ATraining Step: 126  | total loss: [1m[32m0.33780[0m[0m | time: 5.098s
[2K
| Adam | epoch: 018 | loss: 0.33780 - acc: 0.8682 | val_loss: 0.59435 - val_acc: 0.7424 -- iter: 211/211
--
Training Step: 127  | total loss: [1m[32m0.32486[0m[0m | time: 0.466s
[2K
| Adam | epoch: 019 | loss: 0.32486 - acc: 0.8689 -- iter: 032/211
[A[ATraining Step: 128  | total loss: [1m[32m0.32936[0m[0m | time: 0.910s
[2K
| Adam | epoch: 019 | loss: 0.32936 - acc: 0.8662 -- iter: 064/211
[A[ATraining Step: 129  | total loss: [1m[32m0.32093[0m[0m | time: 1.635s
[2K
| Adam | epoch: 019 | loss: 0.32093 - acc: 0.8743 -- iter: 096/211
[A[ATraining Step: 130  | total loss: [1m[32m0.31726[0m[0m | time: 2.332s
[2K
| Adam | epoch: 019 | loss: 0.31726 - acc: 0.8806 -- iter: 128/211
[A[ATraining Step: 131  | total loss: [1m[32m0.30077[0m[0m | time: 2.933s
[2K
| Adam | epoch: 019 | loss: 0.30077 - acc: 0.8926 -- iter: 160/211
[A[ATraining Step: 132  | total loss: [1m[32m0.29129[0m[0m | time: 3.550s
[2K
| Adam | epoch: 019 | loss: 0.29129 - acc: 0.8971 -- iter: 192/211
[A[ATraining Step: 133  | total loss: [1m[32m0.28072[0m[0m | time: 5.181s
[2K
| Adam | epoch: 019 | loss: 0.28072 - acc: 0.9011 | val_loss: 0.61068 - val_acc: 0.7273 -- iter: 211/211
--
Training Step: 134  | total loss: [1m[32m0.28520[0m[0m | time: 0.732s
[2K
| Adam | epoch: 020 | loss: 0.28520 - acc: 0.8985 -- iter: 032/211
[A[ATraining Step: 135  | total loss: [1m[32m0.28045[0m[0m | time: 1.108s
[2K
| Adam | epoch: 020 | loss: 0.28045 - acc: 0.9024 -- iter: 064/211
[A[ATraining Step: 136  | total loss: [1m[32m0.32004[0m[0m | time: 1.482s
[2K
| Adam | epoch: 020 | loss: 0.32004 - acc: 0.8964 -- iter: 096/211
[A[ATraining Step: 137  | total loss: [1m[32m0.31675[0m[0m | time: 2.100s
[2K
| Adam | epoch: 020 | loss: 0.31675 - acc: 0.8962 -- iter: 128/211
[A[ATraining Step: 138  | total loss: [1m[32m0.30046[0m[0m | time: 2.733s
[2K
| Adam | epoch: 020 | loss: 0.30046 - acc: 0.9035 -- iter: 160/211
[A[ATraining Step: 139  | total loss: [1m[32m0.29686[0m[0m | time: 3.349s
[2K
| Adam | epoch: 020 | loss: 0.29686 - acc: 0.9006 -- iter: 192/211
[A[ATraining Step: 140  | total loss: [1m[32m0.28876[0m[0m | time: 4.966s
[2K
| Adam | epoch: 020 | loss: 0.28876 - acc: 0.9043 | val_loss: 0.56896 - val_acc: 0.7273 -- iter: 211/211
--
Training Step: 141  | total loss: [1m[32m0.28409[0m[0m | time: 0.752s
[2K
| Adam | epoch: 021 | loss: 0.28409 - acc: 0.9076 -- iter: 032/211
[A[ATraining Step: 142  | total loss: [1m[32m0.27528[0m[0m | time: 1.486s
[2K
| Adam | epoch: 021 | loss: 0.27528 - acc: 0.9137 -- iter: 064/211
[A[ATraining Step: 143  | total loss: [1m[32m0.26270[0m[0m | time: 1.856s
[2K
| Adam | epoch: 021 | loss: 0.26270 - acc: 0.9192 -- iter: 096/211
[A[ATraining Step: 144  | total loss: [1m[32m0.26501[0m[0m | time: 2.248s
[2K
| Adam | epoch: 021 | loss: 0.26501 - acc: 0.9221 -- iter: 128/211
[A[ATraining Step: 145  | total loss: [1m[32m0.24413[0m[0m | time: 2.866s
[2K
| Adam | epoch: 021 | loss: 0.24413 - acc: 0.9298 -- iter: 160/211
[A[ATraining Step: 146  | total loss: [1m[32m0.22825[0m[0m | time: 3.489s
[2K
| Adam | epoch: 021 | loss: 0.22825 - acc: 0.9369 -- iter: 192/211
[A[ATraining Step: 147  | total loss: [1m[32m0.22614[0m[0m | time: 5.144s
[2K
| Adam | epoch: 021 | loss: 0.22614 - acc: 0.9369 | val_loss: 0.67367 - val_acc: 0.7121 -- iter: 211/211
--
Training Step: 148  | total loss: [1m[32m0.23035[0m[0m | time: 0.610s
[2K
| Adam | epoch: 022 | loss: 0.23035 - acc: 0.9307 -- iter: 032/211
[A[ATraining Step: 149  | total loss: [1m[32m0.22595[0m[0m | time: 1.223s
[2K
| Adam | epoch: 022 | loss: 0.22595 - acc: 0.9314 -- iter: 064/211
[A[ATraining Step: 150  | total loss: [1m[32m0.21298[0m[0m | time: 1.841s
[2K
| Adam | epoch: 022 | loss: 0.21298 - acc: 0.9351 -- iter: 096/211
[A[ATraining Step: 151  | total loss: [1m[32m0.20575[0m[0m | time: 2.217s
[2K
| Adam | epoch: 022 | loss: 0.20575 - acc: 0.9354 -- iter: 128/211
[A[ATraining Step: 152  | total loss: [1m[32m0.23087[0m[0m | time: 2.600s
[2K
| Adam | epoch: 022 | loss: 0.23087 - acc: 0.9261 -- iter: 160/211
[A[ATraining Step: 153  | total loss: [1m[32m0.22283[0m[0m | time: 3.212s
[2K
| Adam | epoch: 022 | loss: 0.22283 - acc: 0.9282 -- iter: 192/211
[A[ATraining Step: 154  | total loss: [1m[32m0.21580[0m[0m | time: 4.912s
[2K
| Adam | epoch: 022 | loss: 0.21580 - acc: 0.9291 | val_loss: 0.68802 - val_acc: 0.7273 -- iter: 211/211
--
Training Step: 155  | total loss: [1m[32m0.20447[0m[0m | time: 0.617s
[2K
| Adam | epoch: 023 | loss: 0.20447 - acc: 0.9331 -- iter: 032/211
[A[ATraining Step: 156  | total loss: [1m[32m0.19562[0m[0m | time: 1.221s
[2K
| Adam | epoch: 023 | loss: 0.19562 - acc: 0.9366 -- iter: 064/211
[A[ATraining Step: 157  | total loss: [1m[32m0.18571[0m[0m | time: 1.949s
[2K
| Adam | epoch: 023 | loss: 0.18571 - acc: 0.9399 -- iter: 096/211
[A[ATraining Step: 158  | total loss: [1m[32m0.17407[0m[0m | time: 2.677s
[2K
| Adam | epoch: 023 | loss: 0.17407 - acc: 0.9459 -- iter: 128/211
[A[ATraining Step: 159  | total loss: [1m[32m0.16796[0m[0m | time: 3.135s
[2K
| Adam | epoch: 023 | loss: 0.16796 - acc: 0.9482 -- iter: 160/211
[A[ATraining Step: 160  | total loss: [1m[32m0.18321[0m[0m | time: 3.581s
[2K
| Adam | epoch: 023 | loss: 0.18321 - acc: 0.9428 -- iter: 192/211
[A[ATraining Step: 161  | total loss: [1m[32m0.18170[0m[0m | time: 5.353s
[2K
| Adam | epoch: 023 | loss: 0.18170 - acc: 0.9380 | val_loss: 0.70563 - val_acc: 0.7424 -- iter: 211/211
--
Training Step: 162  | total loss: [1m[32m0.17108[0m[0m | time: 0.632s
[2K
| Adam | epoch: 024 | loss: 0.17108 - acc: 0.9411 -- iter: 032/211
[A[ATraining Step: 163  | total loss: [1m[32m0.16912[0m[0m | time: 1.399s
[2K
| Adam | epoch: 024 | loss: 0.16912 - acc: 0.9438 -- iter: 064/211
[A[ATraining Step: 164  | total loss: [1m[32m0.15744[0m[0m | time: 2.174s
[2K
| Adam | epoch: 024 | loss: 0.15744 - acc: 0.9495 -- iter: 096/211
[A[ATraining Step: 165  | total loss: [1m[32m0.16821[0m[0m | time: 2.986s
[2K
| Adam | epoch: 024 | loss: 0.16821 - acc: 0.9420 -- iter: 128/211
[A[ATraining Step: 166  | total loss: [1m[32m0.17531[0m[0m | time: 3.759s
[2K
| Adam | epoch: 024 | loss: 0.17531 - acc: 0.9384 -- iter: 160/211
[A[ATraining Step: 167  | total loss: [1m[32m0.17725[0m[0m | time: 4.275s
[2K
| Adam | epoch: 024 | loss: 0.17725 - acc: 0.9383 -- iter: 192/211
[A[ATraining Step: 168  | total loss: [1m[32m0.16482[0m[0m | time: 5.743s
[2K
| Adam | epoch: 024 | loss: 0.16482 - acc: 0.9445 | val_loss: 1.18478 - val_acc: 0.6364 -- iter: 211/211
--
Training Step: 169  | total loss: [1m[32m0.15484[0m[0m | time: 0.828s
[2K
| Adam | epoch: 025 | loss: 0.15484 - acc: 0.9501 -- iter: 032/211
[A[ATraining Step: 170  | total loss: [1m[32m0.20211[0m[0m | time: 1.560s
[2K
| Adam | epoch: 025 | loss: 0.20211 - acc: 0.9269 -- iter: 064/211
[A[ATraining Step: 171  | total loss: [1m[32m0.23552[0m[0m | time: 2.308s
[2K
| Adam | epoch: 025 | loss: 0.23552 - acc: 0.9092 -- iter: 096/211
[A[ATraining Step: 172  | total loss: [1m[32m0.22920[0m[0m | time: 3.052s
[2K
| Adam | epoch: 025 | loss: 0.22920 - acc: 0.9089 -- iter: 128/211
[A[ATraining Step: 173  | total loss: [1m[32m0.20977[0m[0m | time: 3.662s
[2K
| Adam | epoch: 025 | loss: 0.20977 - acc: 0.9180 -- iter: 160/211
[A[ATraining Step: 174  | total loss: [1m[32m0.21817[0m[0m | time: 4.270s
[2K
| Adam | epoch: 025 | loss: 0.21817 - acc: 0.9169 -- iter: 192/211
[A[ATraining Step: 175  | total loss: [1m[32m0.23322[0m[0m | time: 5.649s
[2K
| Adam | epoch: 025 | loss: 0.23322 - acc: 0.9096 | val_loss: 0.66421 - val_acc: 0.7576 -- iter: 211/211
--
Training Step: 176  | total loss: [1m[32m0.27836[0m[0m | time: 0.413s
[2K
| Adam | epoch: 026 | loss: 0.27836 - acc: 0.8975 -- iter: 032/211
[A[ATraining Step: 177  | total loss: [1m[32m0.27005[0m[0m | time: 1.053s
[2K
| Adam | epoch: 026 | loss: 0.27005 - acc: 0.8973 -- iter: 064/211
[A[ATraining Step: 178  | total loss: [1m[32m0.24873[0m[0m | time: 1.685s
[2K
| Adam | epoch: 026 | loss: 0.24873 - acc: 0.9075 -- iter: 096/211
[A[ATraining Step: 179  | total loss: [1m[32m0.23929[0m[0m | time: 2.294s
[2K
| Adam | epoch: 026 | loss: 0.23929 - acc: 0.9168 -- iter: 128/211
[A[ATraining Step: 180  | total loss: [1m[32m0.23895[0m[0m | time: 2.990s
[2K
| Adam | epoch: 026 | loss: 0.23895 - acc: 0.9189 -- iter: 160/211
[A[ATraining Step: 181  | total loss: [1m[32m0.23758[0m[0m | time: 3.775s
[2K
| Adam | epoch: 026 | loss: 0.23758 - acc: 0.9207 -- iter: 192/211
[A[ATraining Step: 182  | total loss: [1m[32m0.24825[0m[0m | time: 5.548s
[2K
| Adam | epoch: 026 | loss: 0.24825 - acc: 0.9099 | val_loss: 0.57987 - val_acc: 0.7273 -- iter: 211/211
--
Training Step: 183  | total loss: [1m[32m0.23230[0m[0m | time: 0.381s
[2K
| Adam | epoch: 027 | loss: 0.23230 - acc: 0.9189 -- iter: 032/211
[A[ATraining Step: 184  | total loss: [1m[32m0.22321[0m[0m | time: 0.758s
[2K
| Adam | epoch: 027 | loss: 0.22321 - acc: 0.9270 -- iter: 064/211
[A[ATraining Step: 185  | total loss: [1m[32m0.21766[0m[0m | time: 1.388s
[2K
| Adam | epoch: 027 | loss: 0.21766 - acc: 0.9343 -- iter: 096/211
[A[ATraining Step: 186  | total loss: [1m[32m0.21737[0m[0m | time: 2.008s
[2K
| Adam | epoch: 027 | loss: 0.21737 - acc: 0.9346 -- iter: 128/211
[A[ATraining Step: 187  | total loss: [1m[32m0.21157[0m[0m | time: 2.618s
[2K
| Adam | epoch: 027 | loss: 0.21157 - acc: 0.9380 -- iter: 160/211
[A[ATraining Step: 188  | total loss: [1m[32m0.19682[0m[0m | time: 3.378s
[2K
| Adam | epoch: 027 | loss: 0.19682 - acc: 0.9442 -- iter: 192/211
[A[ATraining Step: 189  | total loss: [1m[32m0.18299[0m[0m | time: 5.141s
[2K
| Adam | epoch: 027 | loss: 0.18299 - acc: 0.9498 | val_loss: 0.82271 - val_acc: 0.7121 -- iter: 211/211
--
Training Step: 190  | total loss: [1m[32m0.16658[0m[0m | time: 0.641s
[2K
| Adam | epoch: 028 | loss: 0.16658 - acc: 0.9548 -- iter: 032/211
[A[ATraining Step: 191  | total loss: [1m[32m0.15834[0m[0m | time: 1.018s
[2K
| Adam | epoch: 028 | loss: 0.15834 - acc: 0.9562 -- iter: 064/211
[A[ATraining Step: 192  | total loss: [1m[32m0.16289[0m[0m | time: 1.392s
[2K
| Adam | epoch: 028 | loss: 0.16289 - acc: 0.9501 -- iter: 096/211
[A[ATraining Step: 193  | total loss: [1m[32m0.15195[0m[0m | time: 1.999s
[2K
| Adam | epoch: 028 | loss: 0.15195 - acc: 0.9551 -- iter: 128/211
[A[ATraining Step: 194  | total loss: [1m[32m0.15670[0m[0m | time: 2.605s
[2K
| Adam | epoch: 028 | loss: 0.15670 - acc: 0.9471 -- iter: 160/211
[A[ATraining Step: 195  | total loss: [1m[32m0.14491[0m[0m | time: 3.369s
[2K
| Adam | epoch: 028 | loss: 0.14491 - acc: 0.9492 -- iter: 192/211
[A[ATraining Step: 196  | total loss: [1m[32m0.14518[0m[0m | time: 5.182s
[2K
| Adam | epoch: 028 | loss: 0.14518 - acc: 0.9481 | val_loss: 0.91894 - val_acc: 0.7576 -- iter: 211/211
--
Training Step: 197  | total loss: [1m[32m0.14707[0m[0m | time: 0.608s
[2K
| Adam | epoch: 029 | loss: 0.14707 - acc: 0.9470 -- iter: 032/211
[A[ATraining Step: 198  | total loss: [1m[32m0.14356[0m[0m | time: 1.218s
[2K
| Adam | epoch: 029 | loss: 0.14356 - acc: 0.9492 -- iter: 064/211
[A[ATraining Step: 199  | total loss: [1m[32m0.13881[0m[0m | time: 1.616s
[2K
| Adam | epoch: 029 | loss: 0.13881 - acc: 0.9480 -- iter: 096/211
[A[ATraining Step: 200  | total loss: [1m[32m0.16394[0m[0m | time: 3.012s
[2K
| Adam | epoch: 029 | loss: 0.16394 - acc: 0.9479 | val_loss: 0.78885 - val_acc: 0.7273 -- iter: 128/211
--
Training Step: 201  | total loss: [1m[32m0.15009[0m[0m | time: 3.744s
[2K
| Adam | epoch: 029 | loss: 0.15009 - acc: 0.9532 -- iter: 160/211
[A[ATraining Step: 202  | total loss: [1m[32m0.13834[0m[0m | time: 4.347s
[2K
| Adam | epoch: 029 | loss: 0.13834 - acc: 0.9578 -- iter: 192/211
[A[ATraining Step: 203  | total loss: [1m[32m0.13144[0m[0m | time: 5.967s
[2K
| Adam | epoch: 029 | loss: 0.13144 - acc: 0.9621 | val_loss: 0.75014 - val_acc: 0.7273 -- iter: 211/211
--
Training Step: 204  | total loss: [1m[32m0.12407[0m[0m | time: 0.702s
[2K
| Adam | epoch: 030 | loss: 0.12407 - acc: 0.9658 -- iter: 032/211
[A[ATraining Step: 205  | total loss: [1m[32m0.11614[0m[0m | time: 1.313s
[2K
| Adam | epoch: 030 | loss: 0.11614 - acc: 0.9693 -- iter: 064/211
[A[ATraining Step: 206  | total loss: [1m[32m0.11009[0m[0m | time: 1.913s
[2K
| Adam | epoch: 030 | loss: 0.11009 - acc: 0.9723 -- iter: 096/211
[A[ATraining Step: 207  | total loss: [1m[32m0.10082[0m[0m | time: 2.289s
[2K
| Adam | epoch: 030 | loss: 0.10082 - acc: 0.9751 -- iter: 128/211
[A[ATraining Step: 208  | total loss: [1m[32m0.09577[0m[0m | time: 2.662s
[2K
| Adam | epoch: 030 | loss: 0.09577 - acc: 0.9776 -- iter: 160/211
[A[ATraining Step: 209  | total loss: [1m[32m0.09221[0m[0m | time: 3.257s
[2K
| Adam | epoch: 030 | loss: 0.09221 - acc: 0.9798 -- iter: 192/211
[A[ATraining Step: 210  | total loss: [1m[32m0.09217[0m[0m | time: 4.862s
[2K
| Adam | epoch: 030 | loss: 0.09217 - acc: 0.9787 | val_loss: 0.80011 - val_acc: 0.7424 -- iter: 211/211
--
Validation AUC:0.8309591642924977
Validation AUPRC:0.8930970061733975
Test AUC:0.8861111111111112
Test AUPRC:0.8856446638201856
BestTestF1Score	0.78	0.56	0.77	0.7	0.87	26	11	25	4	0.05
BestTestMCCScore	0.65	0.55	0.76	0.94	0.5	15	1	35	15	0.93
BestTestAccuracyScore	0.72	0.59	0.79	0.9	0.6	18	2	34	12	0.8
BestValidationF1Score	0.81	0.46	0.74	0.72	0.92	36	14	13	3	0.05
BestValidationMCC	0.75	0.53	0.74	0.89	0.64	25	3	24	14	0.93
BestValidationAccuracy	0.78	0.51	0.76	0.83	0.74	29	6	21	10	0.8
TestPredictions (Threshold:0.93)
CHEMBL1091804,FN,ACT,0.18000000715255737	CHEMBL3134368,TN,INACT,0.009999999776482582	CHEMBL1091059,FN,ACT,0.6000000238418579	CHEMBL595028,FN,ACT,0.05999999865889549	CHEMBL1774782,TN,INACT,0.4699999988079071	CHEMBL1089942,TN,INACT,0.30000001192092896	CHEMBL3134374,TN,INACT,0.009999999776482582	CHEMBL2334187,TN,INACT,0.029999999329447746	CHEMBL3357850,TP,ACT,0.949999988079071	CHEMBL2334488,TN,INACT,0.05000000074505806	CHEMBL3590358,TP,ACT,1.0	CHEMBL3134321,TN,INACT,0.0	CHEMBL1230276,FN,ACT,0.0	CHEMBL2440536,TN,INACT,0.0	CHEMBL595948,FN,ACT,0.03999999910593033	CHEMBL3322217,TP,ACT,0.9800000190734863	CHEMBL1091065,FN,ACT,0.029999999329447746	CHEMBL3590344,TP,ACT,1.0	CHEMBL3415546,TN,INACT,0.009999999776482582	CHEMBL190868,TN,INACT,0.0	CHEMBL1774786,FP,INACT,0.9800000190734863	CHEMBL364227,TN,INACT,0.07999999821186066	CHEMBL595949,FN,ACT,0.7599999904632568	CHEMBL1272245,FN,ACT,0.75	CHEMBL3633018,TN,INACT,0.019999999552965164	CHEMBL2409072,FN,ACT,0.0	CHEMBL3590311,TP,ACT,1.0	CHEMBL3134322,TN,INACT,0.0	CHEMBL2409074,TP,ACT,0.9800000190734863	CHEMBL3633013,TN,INACT,0.0	CHEMBL1090380,TP,ACT,0.9800000190734863	CHEMBL1269199,TN,INACT,0.0	CHEMBL1232889,TN,INACT,0.019999999552965164	CHEMBL1091060,TP,ACT,0.9300000071525574	CHEMBL2440570,TN,INACT,0.0	CHEMBL1255743,TN,INACT,0.009999999776482582	CHEMBL412591,TN,INACT,0.6000000238418579	CHEMBL3134373,TN,INACT,0.009999999776482582	CHEMBL2440542,TN,INACT,0.0	CHEMBL2440571,TN,INACT,0.0	CHEMBL3590352,TP,ACT,1.0	CHEMBL566825,FN,ACT,0.8199999928474426	CHEMBL3134334,TN,INACT,0.009999999776482582	CHEMBL3633020,TN,INACT,0.8700000047683716	CHEMBL3590317,TP,ACT,1.0	CHEMBL2334498,TN,INACT,0.0	CHEMBL3758402,TN,INACT,0.0	CHEMBL1790636,TN,INACT,0.10999999940395355	CHEMBL1089008,TP,ACT,0.9700000286102295	CHEMBL583415,FN,ACT,0.1899999976158142	CHEMBL3134349,TN,INACT,0.1599999964237213	CHEMBL576239,FN,ACT,0.3100000023841858	CHEMBL2334485,TN,INACT,0.03999999910593033	CHEMBL3134371,TN,INACT,0.0	CHEMBL3099677,FN,ACT,0.800000011920929	CHEMBL1230284,TN,INACT,0.23999999463558197	CHEMBL2334489,TN,INACT,0.019999999552965164	CHEMBL593069,FN,ACT,0.8999999761581421	CHEMBL3134339,TN,INACT,0.0	CHEMBL3590362,TP,ACT,1.0	CHEMBL3415543,TN,INACT,0.0	CHEMBL371852,TP,ACT,0.9599999785423279	CHEMBL1093345,FN,ACT,0.5799999833106995	CHEMBL3134337,TN,INACT,0.23000000417232513	CHEMBL3590363,TP,ACT,1.0	CHEMBL3590370,TP,ACT,1.0	

