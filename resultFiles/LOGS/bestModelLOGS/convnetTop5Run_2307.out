ImageNetInceptionV2 CHEMBL5697 adam 0.001 30 0 0 0.6 False True
Number of active compounds :	178
Number of inactive compounds :	119
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5697_adam_0.001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5697_adam_0.001_30_0.6/
---------------------------------
Training samples: 189
Validation samples: 60
--
Training Step: 1  | time: 186.819s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/189
[A[ATraining Step: 2  | total loss: [1m[32m0.65055[0m[0m | time: 384.640s
[2K
| Adam | epoch: 001 | loss: 0.65055 - acc: 0.4500 -- iter: 064/189
[A[ATraining Step: 3  | total loss: [1m[32m0.68060[0m[0m | time: 471.668s
[2K
| Adam | epoch: 001 | loss: 0.68060 - acc: 0.5676 -- iter: 096/189
[A[ATraining Step: 4  | total loss: [1m[32m0.66844[0m[0m | time: 517.046s
[2K
| Adam | epoch: 001 | loss: 0.66844 - acc: 0.6341 -- iter: 128/189
[A[ATraining Step: 5  | total loss: [1m[32m0.70881[0m[0m | time: 707.980s
[2K
| Adam | epoch: 001 | loss: 0.70881 - acc: 0.5845 -- iter: 160/189
[A[ATraining Step: 6  | total loss: [1m[32m0.69599[0m[0m | time: 816.473s
[2K
| Adam | epoch: 001 | loss: 0.69599 - acc: 0.6306 | val_loss: 0.67390 - val_acc: 0.6333 -- iter: 189/189
--
Training Step: 7  | total loss: [1m[32m0.67068[0m[0m | time: 142.359s
[2K
| Adam | epoch: 002 | loss: 0.67068 - acc: 0.6454 -- iter: 032/189
[A[ATraining Step: 8  | total loss: [1m[32m0.54381[0m[0m | time: 354.291s
[2K
| Adam | epoch: 002 | loss: 0.54381 - acc: 0.7867 -- iter: 064/189
[A[ATraining Step: 9  | total loss: [1m[32m0.61250[0m[0m | time: 532.924s
[2K
| Adam | epoch: 002 | loss: 0.61250 - acc: 0.6680 -- iter: 096/189
[A[ATraining Step: 10  | total loss: [1m[32m0.50728[0m[0m | time: 669.982s
[2K
| Adam | epoch: 002 | loss: 0.50728 - acc: 0.7402 -- iter: 128/189
[A[ATraining Step: 11  | total loss: [1m[32m0.47751[0m[0m | time: 708.857s
[2K
| Adam | epoch: 002 | loss: 0.47751 - acc: 0.7893 -- iter: 160/189
[A[ATraining Step: 12  | total loss: [1m[32m0.54904[0m[0m | time: 844.771s
[2K
| Adam | epoch: 002 | loss: 0.54904 - acc: 0.7153 | val_loss: 0.79839 - val_acc: 0.3667 -- iter: 189/189
--
Training Step: 13  | total loss: [1m[32m0.58590[0m[0m | time: 18.823s
[2K
| Adam | epoch: 003 | loss: 0.58590 - acc: 0.6632 -- iter: 032/189
[A[ATraining Step: 14  | total loss: [1m[32m0.48774[0m[0m | time: 67.355s
[2K
| Adam | epoch: 003 | loss: 0.48774 - acc: 0.7587 -- iter: 064/189
[A[ATraining Step: 15  | total loss: [1m[32m0.39663[0m[0m | time: 94.494s
[2K
| Adam | epoch: 003 | loss: 0.39663 - acc: 0.8396 -- iter: 096/189
[A[ATraining Step: 16  | total loss: [1m[32m0.43329[0m[0m | time: 186.236s
[2K
| Adam | epoch: 003 | loss: 0.43329 - acc: 0.8412 -- iter: 128/189
[A[ATraining Step: 17  | total loss: [1m[32m0.34873[0m[0m | time: 198.705s
[2K
| Adam | epoch: 003 | loss: 0.34873 - acc: 0.8758 -- iter: 160/189
[A[ATraining Step: 18  | total loss: [1m[32m0.27766[0m[0m | time: 240.015s
[2K
| Adam | epoch: 003 | loss: 0.27766 - acc: 0.8972 | val_loss: 0.65503 - val_acc: 0.6333 -- iter: 189/189
--
Training Step: 19  | total loss: [1m[32m0.22753[0m[0m | time: 14.089s
[2K
| Adam | epoch: 004 | loss: 0.22753 - acc: 0.9210 -- iter: 032/189
[A[ATraining Step: 20  | total loss: [1m[32m0.30111[0m[0m | time: 23.157s
[2K
| Adam | epoch: 004 | loss: 0.30111 - acc: 0.8962 -- iter: 064/189
[A[ATraining Step: 21  | total loss: [1m[32m0.31159[0m[0m | time: 32.577s
[2K
| Adam | epoch: 004 | loss: 0.31159 - acc: 0.8856 -- iter: 096/189
[A[ATraining Step: 22  | total loss: [1m[32m0.24867[0m[0m | time: 43.448s
[2K
| Adam | epoch: 004 | loss: 0.24867 - acc: 0.9096 -- iter: 128/189
[A[ATraining Step: 23  | total loss: [1m[32m0.30834[0m[0m | time: 70.389s
[2K
| Adam | epoch: 004 | loss: 0.30834 - acc: 0.8995 -- iter: 160/189
[A[ATraining Step: 24  | total loss: [1m[32m0.32940[0m[0m | time: 106.808s
[2K
| Adam | epoch: 004 | loss: 0.32940 - acc: 0.8751 | val_loss: 0.92363 - val_acc: 0.3667 -- iter: 189/189
--
Training Step: 25  | total loss: [1m[32m0.29253[0m[0m | time: 58.200s
[2K
| Adam | epoch: 005 | loss: 0.29253 - acc: 0.8836 -- iter: 032/189
[A[ATraining Step: 26  | total loss: [1m[32m0.25830[0m[0m | time: 72.920s
[2K
| Adam | epoch: 005 | loss: 0.25830 - acc: 0.8978 -- iter: 064/189
[A[ATraining Step: 27  | total loss: [1m[32m0.26540[0m[0m | time: 94.205s
[2K
| Adam | epoch: 005 | loss: 0.26540 - acc: 0.8839 -- iter: 096/189
[A[ATraining Step: 28  | total loss: [1m[32m0.34541[0m[0m | time: 112.154s
[2K
| Adam | epoch: 005 | loss: 0.34541 - acc: 0.8440 -- iter: 128/189
[A[ATraining Step: 29  | total loss: [1m[32m0.35163[0m[0m | time: 121.992s
[2K
| Adam | epoch: 005 | loss: 0.35163 - acc: 0.8316 -- iter: 160/189
[A[ATraining Step: 30  | total loss: [1m[32m0.29374[0m[0m | time: 134.626s
[2K
| Adam | epoch: 005 | loss: 0.29374 - acc: 0.8641 | val_loss: 0.72849 - val_acc: 0.6333 -- iter: 189/189
--
Training Step: 31  | total loss: [1m[32m0.28211[0m[0m | time: 17.425s
[2K
| Adam | epoch: 006 | loss: 0.28211 - acc: 0.8810 -- iter: 032/189
[A[ATraining Step: 32  | total loss: [1m[32m0.24073[0m[0m | time: 100.475s
[2K
| Adam | epoch: 006 | loss: 0.24073 - acc: 0.9008 -- iter: 064/189
[A[ATraining Step: 33  | total loss: [1m[32m0.20985[0m[0m | time: 113.948s
[2K
| Adam | epoch: 006 | loss: 0.20985 - acc: 0.9157 -- iter: 096/189
[A[ATraining Step: 34  | total loss: [1m[32m0.24839[0m[0m | time: 122.964s
[2K
| Adam | epoch: 006 | loss: 0.24839 - acc: 0.9003 -- iter: 128/189
[A[ATraining Step: 35  | total loss: [1m[32m0.25572[0m[0m | time: 131.950s
[2K
| Adam | epoch: 006 | loss: 0.25572 - acc: 0.9139 -- iter: 160/189
[A[ATraining Step: 36  | total loss: [1m[32m0.22334[0m[0m | time: 144.703s
[2K
| Adam | epoch: 006 | loss: 0.22334 - acc: 0.9245 | val_loss: 1.70638 - val_acc: 0.3667 -- iter: 189/189
--
Training Step: 37  | total loss: [1m[32m0.24340[0m[0m | time: 28.488s
[2K
| Adam | epoch: 007 | loss: 0.24340 - acc: 0.9208 -- iter: 032/189
[A[ATraining Step: 38  | total loss: [1m[32m0.24152[0m[0m | time: 37.899s
[2K
| Adam | epoch: 007 | loss: 0.24152 - acc: 0.9180 -- iter: 064/189
[A[ATraining Step: 39  | total loss: [1m[32m0.22808[0m[0m | time: 47.274s
[2K
| Adam | epoch: 007 | loss: 0.22808 - acc: 0.9217 -- iter: 096/189
[A[ATraining Step: 40  | total loss: [1m[32m0.20131[0m[0m | time: 58.858s
[2K
| Adam | epoch: 007 | loss: 0.20131 - acc: 0.9305 -- iter: 128/189
[A[ATraining Step: 41  | total loss: [1m[32m0.19203[0m[0m | time: 74.002s
[2K
| Adam | epoch: 007 | loss: 0.19203 - acc: 0.9318 -- iter: 160/189
[A[ATraining Step: 42  | total loss: [1m[32m0.17418[0m[0m | time: 92.426s
[2K
| Adam | epoch: 007 | loss: 0.17418 - acc: 0.9379 | val_loss: 1.88742 - val_acc: 0.3667 -- iter: 189/189
--
Training Step: 43  | total loss: [1m[32m0.14885[0m[0m | time: 9.077s
[2K
| Adam | epoch: 008 | loss: 0.14885 - acc: 0.9488 -- iter: 032/189
[A[ATraining Step: 44  | total loss: [1m[32m0.14112[0m[0m | time: 32.513s
[2K
| Adam | epoch: 008 | loss: 0.14112 - acc: 0.9523 -- iter: 064/189
[A[ATraining Step: 45  | total loss: [1m[32m0.32509[0m[0m | time: 50.062s
[2K
| Adam | epoch: 008 | loss: 0.32509 - acc: 0.9179 -- iter: 096/189
[A[ATraining Step: 46  | total loss: [1m[32m0.28766[0m[0m | time: 74.104s
[2K
| Adam | epoch: 008 | loss: 0.28766 - acc: 0.9212 -- iter: 128/189
[A[ATraining Step: 47  | total loss: [1m[32m0.30167[0m[0m | time: 88.144s
[2K
| Adam | epoch: 008 | loss: 0.30167 - acc: 0.9136 -- iter: 160/189
[A[ATraining Step: 48  | total loss: [1m[32m0.27686[0m[0m | time: 99.601s
[2K
| Adam | epoch: 008 | loss: 0.27686 - acc: 0.9225 | val_loss: 0.48951 - val_acc: 0.8000 -- iter: 189/189
--
Training Step: 49  | total loss: [1m[32m0.25671[0m[0m | time: 12.058s
[2K
| Adam | epoch: 009 | loss: 0.25671 - acc: 0.9238 -- iter: 032/189
[A[ATraining Step: 50  | total loss: [1m[32m0.23031[0m[0m | time: 21.573s
[2K
| Adam | epoch: 009 | loss: 0.23031 - acc: 0.9357 -- iter: 064/189
[A[ATraining Step: 51  | total loss: [1m[32m0.23198[0m[0m | time: 31.051s
[2K
| Adam | epoch: 009 | loss: 0.23198 - acc: 0.9264 -- iter: 096/189
[A[ATraining Step: 52  | total loss: [1m[32m0.22545[0m[0m | time: 42.554s
[2K
| Adam | epoch: 009 | loss: 0.22545 - acc: 0.9281 -- iter: 128/189
[A[ATraining Step: 53  | total loss: [1m[32m0.21009[0m[0m | time: 63.440s
[2K
| Adam | epoch: 009 | loss: 0.21009 - acc: 0.9341 -- iter: 160/189
[A[ATraining Step: 54  | total loss: [1m[32m0.19818[0m[0m | time: 96.790s
[2K
| Adam | epoch: 009 | loss: 0.19818 - acc: 0.9346 | val_loss: 0.78039 - val_acc: 0.7833 -- iter: 189/189
--
Training Step: 55  | total loss: [1m[32m0.20149[0m[0m | time: 10.134s
[2K
| Adam | epoch: 010 | loss: 0.20149 - acc: 0.9350 -- iter: 032/189
[A[ATraining Step: 56  | total loss: [1m[32m0.19542[0m[0m | time: 21.967s
[2K
| Adam | epoch: 010 | loss: 0.19542 - acc: 0.9393 -- iter: 064/189
[A[ATraining Step: 57  | total loss: [1m[32m0.17619[0m[0m | time: 45.294s
[2K
| Adam | epoch: 010 | loss: 0.17619 - acc: 0.9477 -- iter: 096/189
[A[ATraining Step: 58  | total loss: [1m[32m0.16704[0m[0m | time: 57.960s
[2K
| Adam | epoch: 010 | loss: 0.16704 - acc: 0.9463 -- iter: 128/189
[A[ATraining Step: 59  | total loss: [1m[32m0.15384[0m[0m | time: 69.868s
[2K
| Adam | epoch: 010 | loss: 0.15384 - acc: 0.9493 -- iter: 160/189
[A[ATraining Step: 60  | total loss: [1m[32m0.17664[0m[0m | time: 82.471s
[2K
| Adam | epoch: 010 | loss: 0.17664 - acc: 0.9353 | val_loss: 1.65547 - val_acc: 0.5500 -- iter: 189/189
--
Training Step: 61  | total loss: [1m[32m0.16206[0m[0m | time: 13.353s
[2K
| Adam | epoch: 011 | loss: 0.16206 - acc: 0.9397 -- iter: 032/189
[A[ATraining Step: 62  | total loss: [1m[32m0.15098[0m[0m | time: 25.849s
[2K
| Adam | epoch: 011 | loss: 0.15098 - acc: 0.9434 -- iter: 064/189
[A[ATraining Step: 63  | total loss: [1m[32m0.14150[0m[0m | time: 35.954s
[2K
| Adam | epoch: 011 | loss: 0.14150 - acc: 0.9462 -- iter: 096/189
[A[ATraining Step: 64  | total loss: [1m[32m0.13469[0m[0m | time: 45.447s
[2K
| Adam | epoch: 011 | loss: 0.13469 - acc: 0.9443 -- iter: 128/189
[A[ATraining Step: 65  | total loss: [1m[32m0.15285[0m[0m | time: 54.528s
[2K
| Adam | epoch: 011 | loss: 0.15285 - acc: 0.9358 -- iter: 160/189
[A[ATraining Step: 66  | total loss: [1m[32m0.13540[0m[0m | time: 66.655s
[2K
| Adam | epoch: 011 | loss: 0.13540 - acc: 0.9436 | val_loss: 2.88395 - val_acc: 0.7000 -- iter: 189/189
--
Training Step: 67  | total loss: [1m[32m0.12894[0m[0m | time: 16.053s
[2K
| Adam | epoch: 012 | loss: 0.12894 - acc: 0.9429 -- iter: 032/189
[A[ATraining Step: 68  | total loss: [1m[32m0.15513[0m[0m | time: 28.852s
[2K
| Adam | epoch: 012 | loss: 0.15513 - acc: 0.9237 -- iter: 064/189
[A[ATraining Step: 69  | total loss: [1m[32m0.15247[0m[0m | time: 37.544s
[2K
| Adam | epoch: 012 | loss: 0.15247 - acc: 0.9253 -- iter: 096/189
[A[ATraining Step: 70  | total loss: [1m[32m0.13938[0m[0m | time: 46.243s
[2K
| Adam | epoch: 012 | loss: 0.13938 - acc: 0.9300 -- iter: 128/189
[A[ATraining Step: 71  | total loss: [1m[32m0.12578[0m[0m | time: 56.691s
[2K
| Adam | epoch: 012 | loss: 0.12578 - acc: 0.9380 -- iter: 160/189
[A[ATraining Step: 72  | total loss: [1m[32m0.11670[0m[0m | time: 73.935s
[2K
| Adam | epoch: 012 | loss: 0.11670 - acc: 0.9449 | val_loss: 0.77262 - val_acc: 0.7500 -- iter: 189/189
--
Training Step: 73  | total loss: [1m[32m0.14585[0m[0m | time: 9.381s
[2K
| Adam | epoch: 013 | loss: 0.14585 - acc: 0.9372 -- iter: 032/189
[A[ATraining Step: 74  | total loss: [1m[32m0.14365[0m[0m | time: 18.718s
[2K
| Adam | epoch: 013 | loss: 0.14365 - acc: 0.9372 -- iter: 064/189
[A[ATraining Step: 75  | total loss: [1m[32m0.14102[0m[0m | time: 48.967s
[2K
| Adam | epoch: 013 | loss: 0.14102 - acc: 0.9406 -- iter: 096/189
[A[ATraining Step: 76  | total loss: [1m[32m0.12982[0m[0m | time: 61.282s
[2K
| Adam | epoch: 013 | loss: 0.12982 - acc: 0.9436 -- iter: 128/189
[A[ATraining Step: 77  | total loss: [1m[32m0.15944[0m[0m | time: 73.696s
[2K
| Adam | epoch: 013 | loss: 0.15944 - acc: 0.9350 -- iter: 160/189
[A[ATraining Step: 78  | total loss: [1m[32m0.16083[0m[0m | time: 93.899s
[2K
| Adam | epoch: 013 | loss: 0.16083 - acc: 0.9346 | val_loss: 1.69811 - val_acc: 0.7333 -- iter: 189/189
--
Training Step: 79  | total loss: [1m[32m0.15572[0m[0m | time: 15.115s
[2K
| Adam | epoch: 014 | loss: 0.15572 - acc: 0.9381 -- iter: 032/189
[A[ATraining Step: 80  | total loss: [1m[32m0.16533[0m[0m | time: 27.259s
[2K
| Adam | epoch: 014 | loss: 0.16533 - acc: 0.9412 -- iter: 064/189
[A[ATraining Step: 81  | total loss: [1m[32m0.15108[0m[0m | time: 38.361s
[2K
| Adam | epoch: 014 | loss: 0.15108 - acc: 0.9472 -- iter: 096/189
[A[ATraining Step: 82  | total loss: [1m[32m0.14383[0m[0m | time: 47.317s
[2K
| Adam | epoch: 014 | loss: 0.14383 - acc: 0.9493 -- iter: 128/189
[A[ATraining Step: 83  | total loss: [1m[32m0.14683[0m[0m | time: 55.961s
[2K
| Adam | epoch: 014 | loss: 0.14683 - acc: 0.9482 -- iter: 160/189
[A[ATraining Step: 84  | total loss: [1m[32m0.15120[0m[0m | time: 67.508s
[2K
| Adam | epoch: 014 | loss: 0.15120 - acc: 0.9464 | val_loss: 2.62262 - val_acc: 0.6167 -- iter: 189/189
--
Training Step: 85  | total loss: [1m[32m0.14175[0m[0m | time: 13.287s
[2K
| Adam | epoch: 015 | loss: 0.14175 - acc: 0.9484 -- iter: 032/189
[A[ATraining Step: 86  | total loss: [1m[32m0.14294[0m[0m | time: 25.249s
[2K
| Adam | epoch: 015 | loss: 0.14294 - acc: 0.9473 -- iter: 064/189
[A[ATraining Step: 87  | total loss: [1m[32m0.16986[0m[0m | time: 34.644s
[2K
| Adam | epoch: 015 | loss: 0.16986 - acc: 0.9494 -- iter: 096/189
[A[ATraining Step: 88  | total loss: [1m[32m0.15469[0m[0m | time: 44.170s
[2K
| Adam | epoch: 015 | loss: 0.15469 - acc: 0.9545 -- iter: 128/189
[A[ATraining Step: 89  | total loss: [1m[32m0.14397[0m[0m | time: 55.787s
[2K
| Adam | epoch: 015 | loss: 0.14397 - acc: 0.9590 -- iter: 160/189
[A[ATraining Step: 90  | total loss: [1m[32m0.14838[0m[0m | time: 73.735s
[2K
| Adam | epoch: 015 | loss: 0.14838 - acc: 0.9506 | val_loss: 4.15475 - val_acc: 0.3667 -- iter: 189/189
--
Training Step: 91  | total loss: [1m[32m0.14050[0m[0m | time: 8.792s
[2K
| Adam | epoch: 016 | loss: 0.14050 - acc: 0.9556 -- iter: 032/189
[A[ATraining Step: 92  | total loss: [1m[32m0.12991[0m[0m | time: 17.847s
[2K
| Adam | epoch: 016 | loss: 0.12991 - acc: 0.9600 -- iter: 064/189
[A[ATraining Step: 93  | total loss: [1m[32m0.13384[0m[0m | time: 30.722s
[2K
| Adam | epoch: 016 | loss: 0.13384 - acc: 0.9578 -- iter: 096/189
[A[ATraining Step: 94  | total loss: [1m[32m0.15324[0m[0m | time: 43.603s
[2K
| Adam | epoch: 016 | loss: 0.15324 - acc: 0.9557 -- iter: 128/189
[A[ATraining Step: 95  | total loss: [1m[32m0.14234[0m[0m | time: 56.919s
[2K
| Adam | epoch: 016 | loss: 0.14234 - acc: 0.9602 -- iter: 160/189
[A[ATraining Step: 96  | total loss: [1m[32m0.13846[0m[0m | time: 72.586s
[2K
| Adam | epoch: 016 | loss: 0.13846 - acc: 0.9610 | val_loss: 2.16523 - val_acc: 0.4667 -- iter: 189/189
--
Training Step: 97  | total loss: [1m[32m0.13072[0m[0m | time: 12.223s
[2K
| Adam | epoch: 017 | loss: 0.13072 - acc: 0.9649 -- iter: 032/189
[A[ATraining Step: 98  | total loss: [1m[32m0.12301[0m[0m | time: 24.218s
[2K
| Adam | epoch: 017 | loss: 0.12301 - acc: 0.9684 -- iter: 064/189
[A[ATraining Step: 99  | total loss: [1m[32m0.11347[0m[0m | time: 39.106s
[2K
| Adam | epoch: 017 | loss: 0.11347 - acc: 0.9716 -- iter: 096/189
[A[ATraining Step: 100  | total loss: [1m[32m0.11379[0m[0m | time: 50.019s
[2K
| Adam | epoch: 017 | loss: 0.11379 - acc: 0.9650 -- iter: 128/189
[A[ATraining Step: 101  | total loss: [1m[32m0.12918[0m[0m | time: 58.957s
[2K
| Adam | epoch: 017 | loss: 0.12918 - acc: 0.9654 -- iter: 160/189
[A[ATraining Step: 102  | total loss: [1m[32m0.12575[0m[0m | time: 71.097s
[2K
| Adam | epoch: 017 | loss: 0.12575 - acc: 0.9658 | val_loss: 1.06560 - val_acc: 0.7333 -- iter: 189/189
--
Training Step: 103  | total loss: [1m[32m0.11606[0m[0m | time: 12.989s
[2K
| Adam | epoch: 018 | loss: 0.11606 - acc: 0.9692 -- iter: 032/189
[A[ATraining Step: 104  | total loss: [1m[32m0.10546[0m[0m | time: 22.080s
[2K
| Adam | epoch: 018 | loss: 0.10546 - acc: 0.9723 -- iter: 064/189
[A[ATraining Step: 105  | total loss: [1m[32m0.10459[0m[0m | time: 30.830s
[2K
| Adam | epoch: 018 | loss: 0.10459 - acc: 0.9681 -- iter: 096/189
[A[ATraining Step: 106  | total loss: [1m[32m0.09685[0m[0m | time: 40.194s
[2K
| Adam | epoch: 018 | loss: 0.09685 - acc: 0.9713 -- iter: 128/189
[A[ATraining Step: 107  | total loss: [1m[32m0.08919[0m[0m | time: 49.603s
[2K
| Adam | epoch: 018 | loss: 0.08919 - acc: 0.9742 -- iter: 160/189
[A[ATraining Step: 108  | total loss: [1m[32m0.10524[0m[0m | time: 63.510s
[2K
| Adam | epoch: 018 | loss: 0.10524 - acc: 0.9736 | val_loss: 0.90215 - val_acc: 0.7500 -- iter: 189/189
--
Training Step: 109  | total loss: [1m[32m0.10080[0m[0m | time: 8.767s
[2K
| Adam | epoch: 019 | loss: 0.10080 - acc: 0.9763 -- iter: 032/189
[A[ATraining Step: 110  | total loss: [1m[32m0.09428[0m[0m | time: 17.391s
[2K
| Adam | epoch: 019 | loss: 0.09428 - acc: 0.9787 -- iter: 064/189
[A[ATraining Step: 111  | total loss: [1m[32m0.08973[0m[0m | time: 25.468s
[2K
| Adam | epoch: 019 | loss: 0.08973 - acc: 0.9808 -- iter: 096/189
[A[ATraining Step: 112  | total loss: [1m[32m0.08424[0m[0m | time: 33.516s
[2K
| Adam | epoch: 019 | loss: 0.08424 - acc: 0.9827 -- iter: 128/189
[A[ATraining Step: 113  | total loss: [1m[32m0.07643[0m[0m | time: 42.124s
[2K
| Adam | epoch: 019 | loss: 0.07643 - acc: 0.9844 -- iter: 160/189
[A[ATraining Step: 114  | total loss: [1m[32m0.07064[0m[0m | time: 53.876s
[2K
| Adam | epoch: 019 | loss: 0.07064 - acc: 0.9860 | val_loss: 0.95372 - val_acc: 0.8167 -- iter: 189/189
--
Training Step: 115  | total loss: [1m[32m0.06746[0m[0m | time: 26.525s
[2K
| Adam | epoch: 020 | loss: 0.06746 - acc: 0.9874 -- iter: 032/189
[A[ATraining Step: 116  | total loss: [1m[32m0.06098[0m[0m | time: 57.769s
[2K
| Adam | epoch: 020 | loss: 0.06098 - acc: 0.9887 -- iter: 064/189
[A[ATraining Step: 117  | total loss: [1m[32m0.05552[0m[0m | time: 75.758s
[2K
| Adam | epoch: 020 | loss: 0.05552 - acc: 0.9898 -- iter: 096/189
[A[ATraining Step: 118  | total loss: [1m[32m0.05029[0m[0m | time: 93.675s
[2K
| Adam | epoch: 020 | loss: 0.05029 - acc: 0.9908 -- iter: 128/189
[A[ATraining Step: 119  | total loss: [1m[32m0.04599[0m[0m | time: 118.362s
[2K
| Adam | epoch: 020 | loss: 0.04599 - acc: 0.9917 -- iter: 160/189
[A[ATraining Step: 120  | total loss: [1m[32m0.04178[0m[0m | time: 149.776s
[2K
| Adam | epoch: 020 | loss: 0.04178 - acc: 0.9926 | val_loss: 1.10711 - val_acc: 0.7667 -- iter: 189/189
--
Training Step: 121  | total loss: [1m[32m0.03967[0m[0m | time: 22.076s
[2K
| Adam | epoch: 021 | loss: 0.03967 - acc: 0.9933 -- iter: 032/189
[A[ATraining Step: 122  | total loss: [1m[32m0.08682[0m[0m | time: 52.041s
[2K
| Adam | epoch: 021 | loss: 0.08682 - acc: 0.9877 -- iter: 064/189
[A[ATraining Step: 123  | total loss: [1m[32m0.08190[0m[0m | time: 67.484s
[2K
| Adam | epoch: 021 | loss: 0.08190 - acc: 0.9858 -- iter: 096/189
[A[ATraining Step: 124  | total loss: [1m[32m0.07853[0m[0m | time: 78.914s
[2K
| Adam | epoch: 021 | loss: 0.07853 - acc: 0.9841 -- iter: 128/189
[A[ATraining Step: 125  | total loss: [1m[32m0.07170[0m[0m | time: 90.408s
[2K
| Adam | epoch: 021 | loss: 0.07170 - acc: 0.9857 -- iter: 160/189
[A[ATraining Step: 126  | total loss: [1m[32m0.07370[0m[0m | time: 101.431s
[2K
| Adam | epoch: 021 | loss: 0.07370 - acc: 0.9837 | val_loss: 2.56577 - val_acc: 0.3833 -- iter: 189/189
--
Training Step: 127  | total loss: [1m[32m0.06674[0m[0m | time: 18.754s
[2K
| Adam | epoch: 022 | loss: 0.06674 - acc: 0.9853 -- iter: 032/189
[A[ATraining Step: 128  | total loss: [1m[32m0.06296[0m[0m | time: 40.479s
[2K
| Adam | epoch: 022 | loss: 0.06296 - acc: 0.9868 -- iter: 064/189
[A[ATraining Step: 129  | total loss: [1m[32m0.05834[0m[0m | time: 61.656s
[2K
| Adam | epoch: 022 | loss: 0.05834 - acc: 0.9881 -- iter: 096/189
[A[ATraining Step: 130  | total loss: [1m[32m0.05902[0m[0m | time: 79.296s
[2K
| Adam | epoch: 022 | loss: 0.05902 - acc: 0.9862 -- iter: 128/189
[A[ATraining Step: 131  | total loss: [1m[32m0.05586[0m[0m | time: 104.599s
[2K
| Adam | epoch: 022 | loss: 0.05586 - acc: 0.9876 -- iter: 160/189
[A[ATraining Step: 132  | total loss: [1m[32m0.05252[0m[0m | time: 127.622s
[2K
| Adam | epoch: 022 | loss: 0.05252 - acc: 0.9888 | val_loss: 1.97829 - val_acc: 0.4667 -- iter: 189/189
--
Training Step: 133  | total loss: [1m[32m0.04963[0m[0m | time: 39.097s
[2K
| Adam | epoch: 023 | loss: 0.04963 - acc: 0.9899 -- iter: 032/189
[A[ATraining Step: 134  | total loss: [1m[32m0.04534[0m[0m | time: 75.128s
[2K
| Adam | epoch: 023 | loss: 0.04534 - acc: 0.9909 -- iter: 064/189
[A[ATraining Step: 135  | total loss: [1m[32m0.04108[0m[0m | time: 89.743s
[2K
| Adam | epoch: 023 | loss: 0.04108 - acc: 0.9918 -- iter: 096/189
[A[ATraining Step: 136  | total loss: [1m[32m0.05883[0m[0m | time: 99.349s
[2K
| Adam | epoch: 023 | loss: 0.05883 - acc: 0.9895 -- iter: 128/189
[A[ATraining Step: 137  | total loss: [1m[32m0.05351[0m[0m | time: 108.387s
[2K
| Adam | epoch: 023 | loss: 0.05351 - acc: 0.9906 -- iter: 160/189
[A[ATraining Step: 138  | total loss: [1m[32m0.04860[0m[0m | time: 120.226s
[2K
| Adam | epoch: 023 | loss: 0.04860 - acc: 0.9915 | val_loss: 1.81580 - val_acc: 0.6833 -- iter: 189/189
--
Training Step: 139  | total loss: [1m[32m0.04425[0m[0m | time: 46.115s
[2K
| Adam | epoch: 024 | loss: 0.04425 - acc: 0.9924 -- iter: 032/189
[A[ATraining Step: 140  | total loss: [1m[32m0.04325[0m[0m | time: 81.981s
[2K
| Adam | epoch: 024 | loss: 0.04325 - acc: 0.9931 -- iter: 064/189
[A[ATraining Step: 141  | total loss: [1m[32m0.04062[0m[0m | time: 96.464s
[2K
| Adam | epoch: 024 | loss: 0.04062 - acc: 0.9938 -- iter: 096/189
[A[ATraining Step: 142  | total loss: [1m[32m0.04346[0m[0m | time: 133.087s
[2K
| Adam | epoch: 024 | loss: 0.04346 - acc: 0.9913 -- iter: 128/189
[A[ATraining Step: 143  | total loss: [1m[32m0.03971[0m[0m | time: 175.890s
[2K
| Adam | epoch: 024 | loss: 0.03971 - acc: 0.9922 -- iter: 160/189
[A[ATraining Step: 144  | total loss: [1m[32m0.04171[0m[0m | time: 217.647s
[2K
| Adam | epoch: 024 | loss: 0.04171 - acc: 0.9898 | val_loss: 1.76720 - val_acc: 0.7167 -- iter: 189/189
--
Training Step: 145  | total loss: [1m[32m0.04475[0m[0m | time: 55.314s
[2K
| Adam | epoch: 025 | loss: 0.04475 - acc: 0.9877 -- iter: 032/189
[A[ATraining Step: 146  | total loss: [1m[32m0.04125[0m[0m | time: 67.957s
[2K
| Adam | epoch: 025 | loss: 0.04125 - acc: 0.9890 -- iter: 064/189
[A[ATraining Step: 147  | total loss: [1m[32m0.03767[0m[0m | time: 78.676s
[2K
| Adam | epoch: 025 | loss: 0.03767 - acc: 0.9901 -- iter: 096/189
[A[ATraining Step: 148  | total loss: [1m[32m0.03429[0m[0m | time: 108.294s
[2K
| Adam | epoch: 025 | loss: 0.03429 - acc: 0.9911 -- iter: 128/189
[A[ATraining Step: 149  | total loss: [1m[32m0.04180[0m[0m | time: 154.858s
[2K
| Adam | epoch: 025 | loss: 0.04180 - acc: 0.9857 -- iter: 160/189
[A[ATraining Step: 150  | total loss: [1m[32m0.15929[0m[0m | time: 187.681s
[2K
| Adam | epoch: 025 | loss: 0.15929 - acc: 0.9621 | val_loss: 1.63694 - val_acc: 0.6667 -- iter: 189/189
--
Training Step: 151  | total loss: [1m[32m0.14399[0m[0m | time: 43.590s
[2K
| Adam | epoch: 026 | loss: 0.14399 - acc: 0.9659 -- iter: 032/189
[A[ATraining Step: 152  | total loss: [1m[32m0.15819[0m[0m | time: 65.020s
[2K
| Adam | epoch: 026 | loss: 0.15819 - acc: 0.9599 -- iter: 064/189
[A[ATraining Step: 153  | total loss: [1m[32m0.14915[0m[0m | time: 98.144s
[2K
| Adam | epoch: 026 | loss: 0.14915 - acc: 0.9608 -- iter: 096/189
[A[ATraining Step: 154  | total loss: [1m[32m0.14006[0m[0m | time: 151.805s
[2K
| Adam | epoch: 026 | loss: 0.14006 - acc: 0.9613 -- iter: 128/189
[A[ATraining Step: 155  | total loss: [1m[32m0.12646[0m[0m | time: 244.936s
[2K
| Adam | epoch: 026 | loss: 0.12646 - acc: 0.9652 -- iter: 160/189
[A[ATraining Step: 156  | total loss: [1m[32m0.11532[0m[0m | time: 297.386s
[2K
| Adam | epoch: 026 | loss: 0.11532 - acc: 0.9687 | val_loss: 1.38939 - val_acc: 0.7333 -- iter: 189/189
--
Training Step: 157  | total loss: [1m[32m0.10547[0m[0m | time: 33.805s
[2K
| Adam | epoch: 027 | loss: 0.10547 - acc: 0.9718 -- iter: 032/189
[A[ATraining Step: 158  | total loss: [1m[32m0.09912[0m[0m | time: 46.870s
[2K
| Adam | epoch: 027 | loss: 0.09912 - acc: 0.9715 -- iter: 064/189
[A[ATraining Step: 159  | total loss: [1m[32m0.09027[0m[0m | time: 57.668s
[2K
| Adam | epoch: 027 | loss: 0.09027 - acc: 0.9743 -- iter: 096/189
[A[ATraining Step: 160  | total loss: [1m[32m0.08362[0m[0m | time: 67.816s
[2K
| Adam | epoch: 027 | loss: 0.08362 - acc: 0.9769 -- iter: 128/189
[A[ATraining Step: 161  | total loss: [1m[32m0.07613[0m[0m | time: 84.834s
[2K
| Adam | epoch: 027 | loss: 0.07613 - acc: 0.9792 -- iter: 160/189
[A[ATraining Step: 162  | total loss: [1m[32m0.06912[0m[0m | time: 118.390s
[2K
| Adam | epoch: 027 | loss: 0.06912 - acc: 0.9813 | val_loss: 1.26153 - val_acc: 0.7833 -- iter: 189/189
--
Training Step: 163  | total loss: [1m[32m0.06320[0m[0m | time: 51.931s
[2K
| Adam | epoch: 028 | loss: 0.06320 - acc: 0.9832 -- iter: 032/189
[A[ATraining Step: 164  | total loss: [1m[32m0.05804[0m[0m | time: 75.639s
[2K
| Adam | epoch: 028 | loss: 0.05804 - acc: 0.9848 -- iter: 064/189
[A[ATraining Step: 165  | total loss: [1m[32m0.05432[0m[0m | time: 104.650s
[2K
| Adam | epoch: 028 | loss: 0.05432 - acc: 0.9864 -- iter: 096/189
[A[ATraining Step: 166  | total loss: [1m[32m0.05495[0m[0m | time: 126.229s
[2K
| Adam | epoch: 028 | loss: 0.05495 - acc: 0.9846 -- iter: 128/189
[A[ATraining Step: 167  | total loss: [1m[32m0.05721[0m[0m | time: 142.053s
[2K
| Adam | epoch: 028 | loss: 0.05721 - acc: 0.9830 -- iter: 160/189
[A[ATraining Step: 168  | total loss: [1m[32m0.05171[0m[0m | time: 167.590s
[2K
| Adam | epoch: 028 | loss: 0.05171 - acc: 0.9847 | val_loss: 2.04250 - val_acc: 0.5333 -- iter: 189/189
--
Training Step: 169  | total loss: [1m[32m0.04686[0m[0m | time: 22.209s
[2K
| Adam | epoch: 029 | loss: 0.04686 - acc: 0.9862 -- iter: 032/189
[A[ATraining Step: 170  | total loss: [1m[32m0.04308[0m[0m | time: 43.662s
[2K
| Adam | epoch: 029 | loss: 0.04308 - acc: 0.9876 -- iter: 064/189
[A[ATraining Step: 171  | total loss: [1m[32m0.05934[0m[0m | time: 61.509s
[2K
| Adam | epoch: 029 | loss: 0.05934 - acc: 0.9857 -- iter: 096/189
[A[ATraining Step: 172  | total loss: [1m[32m0.06260[0m[0m | time: 73.443s
[2K
| Adam | epoch: 029 | loss: 0.06260 - acc: 0.9809 -- iter: 128/189
[A[ATraining Step: 173  | total loss: [1m[32m0.06746[0m[0m | time: 84.951s
[2K
| Adam | epoch: 029 | loss: 0.06746 - acc: 0.9766 -- iter: 160/189
[A[ATraining Step: 174  | total loss: [1m[32m0.06363[0m[0m | time: 99.728s
[2K
| Adam | epoch: 029 | loss: 0.06363 - acc: 0.9789 | val_loss: 1.71443 - val_acc: 0.6500 -- iter: 189/189
--
Training Step: 175  | total loss: [1m[32m0.05813[0m[0m | time: 39.910s
[2K
| Adam | epoch: 030 | loss: 0.05813 - acc: 0.9810 -- iter: 032/189
[A[ATraining Step: 176  | total loss: [1m[32m0.05326[0m[0m | time: 60.428s
[2K
| Adam | epoch: 030 | loss: 0.05326 - acc: 0.9829 -- iter: 064/189
[A[ATraining Step: 177  | total loss: [1m[32m0.05457[0m[0m | time: 78.159s
[2K
| Adam | epoch: 030 | loss: 0.05457 - acc: 0.9815 -- iter: 096/189
[A[ATraining Step: 178  | total loss: [1m[32m0.08155[0m[0m | time: 97.653s
[2K
| Adam | epoch: 030 | loss: 0.08155 - acc: 0.9771 -- iter: 128/189
[A[ATraining Step: 179  | total loss: [1m[32m0.07812[0m[0m | time: 118.850s
[2K
| Adam | epoch: 030 | loss: 0.07812 - acc: 0.9763 -- iter: 160/189
[A[ATraining Step: 180  | total loss: [1m[32m0.08145[0m[0m | time: 141.091s
[2K
| Adam | epoch: 030 | loss: 0.08145 - acc: 0.9693 | val_loss: 1.62313 - val_acc: 0.6333 -- iter: 189/189
--
Validation AUC:0.8516746411483255
Validation AUPRC:0.9319747557937141
Test AUC:0.7779083431257345
Test AUPRC:0.786382649645675
BestTestF1Score	0.8	0.42	0.73	0.73	0.89	33	12	11	4	1.0
BestTestMCCScore	0.8	0.42	0.73	0.73	0.89	33	12	11	4	1.0
BestTestAccuracyScore	0.8	0.42	0.73	0.73	0.89	33	12	11	4	1.0
BestValidationF1Score	0.84	0.52	0.78	0.8	0.87	33	8	14	5	1.0
BestValidationMCC	0.84	0.52	0.78	0.8	0.87	33	8	14	5	1.0
BestValidationAccuracy	0.84	0.52	0.78	0.8	0.87	33	8	14	5	1.0
TestPredictions (Threshold:1.0)
CHEMBL2443127,TP,ACT,1.0	CHEMBL2043010,TP,ACT,1.0	CHEMBL2042994,TP,ACT,1.0	CHEMBL3115302,TP,ACT,1.0	CHEMBL1098764,FP,INACT,1.0	CHEMBL3671953,TP,ACT,1.0	CHEMBL2040897,TP,ACT,1.0	CHEMBL2043172,TP,ACT,1.0	CHEMBL222114,TP,ACT,1.0	CHEMBL1688404,TP,ACT,1.0	CHEMBL489155,TP,ACT,1.0	CHEMBL447994,TP,ACT,1.0	CHEMBL3309273,TP,ACT,1.0	CHEMBL3671889,TP,ACT,1.0	CHEMBL2041178,TP,ACT,1.0	CHEMBL448208,FN,ACT,0.9900000095367432	CHEMBL3671877,FN,ACT,0.9300000071525574	CHEMBL3676830,TN,INACT,0.9800000190734863	CHEMBL3310399,TP,ACT,1.0	CHEMBL2043008,TP,ACT,1.0	CHEMBL3671965,TP,ACT,1.0	CHEMBL2042855,TP,ACT,1.0	CHEMBL2443129,TP,ACT,1.0	CHEMBL3672008,TP,ACT,1.0	CHEMBL2042993,FN,ACT,0.9900000095367432	CHEMBL3671947,TP,ACT,1.0	CHEMBL1256568,TN,INACT,0.009999999776482582	CHEMBL3671927,TP,ACT,1.0	CHEMBL2042848,TP,ACT,1.0	CHEMBL3676841,FN,ACT,0.3700000047683716	CHEMBL3671943,TN,INACT,0.4399999976158142	CHEMBL450821,FP,INACT,1.0	CHEMBL3671923,TN,INACT,0.949999988079071	CHEMBL3671892,TP,ACT,1.0	CHEMBL3676788,FP,INACT,1.0	CHEMBL2042998,TP,ACT,1.0	CHEMBL504756,FP,INACT,1.0	CHEMBL2042992,TP,ACT,1.0	CHEMBL3590521,FP,INACT,1.0	CHEMBL3775245,FP,INACT,1.0	CHEMBL505486,FP,INACT,1.0	CHEMBL1094197,FP,INACT,1.0	CHEMBL220546,FP,INACT,1.0	CHEMBL3115312,TP,ACT,1.0	CHEMBL3671968,TN,INACT,0.07999999821186066	CHEMBL3115313,TP,ACT,1.0	CHEMBL576,TN,INACT,0.8999999761581421	CHEMBL2041168,TP,ACT,1.0	CHEMBL3676837,FP,INACT,1.0	CHEMBL3310392,TP,ACT,1.0	CHEMBL3671979,TN,INACT,0.8600000143051147	CHEMBL3671883,FP,INACT,1.0	CHEMBL3671985,TN,INACT,0.8899999856948853	CHEMBL568873,TN,INACT,0.6100000143051147	CHEMBL453188,TN,INACT,0.46000000834465027	CHEMBL480160,TP,ACT,1.0	CHEMBL221604,TP,ACT,1.0	CHEMBL3108952,TP,ACT,1.0	CHEMBL3671915,TN,INACT,0.9900000095367432	CHEMBL2170979,FP,INACT,1.0	

