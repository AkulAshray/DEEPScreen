ImageNetInceptionV2 CHEMBL3004 adam 0.0005 30 0 0 0.6 False True
Number of active compounds :	180
Number of inactive compounds :	180
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3004_adam_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3004_adam_0.0005_30_0.6/
---------------------------------
Training samples: 187
Validation samples: 59
--
Training Step: 1  | time: 36.763s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/187
[A[ATraining Step: 2  | total loss: [1m[32m0.71357[0m[0m | time: 45.102s
[2K
| Adam | epoch: 001 | loss: 0.71357 - acc: 0.3656 -- iter: 064/187
[A[ATraining Step: 3  | total loss: [1m[32m0.67964[0m[0m | time: 53.594s
[2K
| Adam | epoch: 001 | loss: 0.67964 - acc: 0.5778 -- iter: 096/187
[A[ATraining Step: 4  | total loss: [1m[32m0.73801[0m[0m | time: 62.066s
[2K
| Adam | epoch: 001 | loss: 0.73801 - acc: 0.4960 -- iter: 128/187
[A[ATraining Step: 5  | total loss: [1m[32m0.86776[0m[0m | time: 70.464s
[2K
| Adam | epoch: 001 | loss: 0.86776 - acc: 0.4339 -- iter: 160/187
[A[ATraining Step: 6  | total loss: [1m[32m0.69884[0m[0m | time: 86.194s
[2K
| Adam | epoch: 001 | loss: 0.69884 - acc: 0.5768 | val_loss: 1.11132 - val_acc: 0.3390 -- iter: 187/187
--
Training Step: 7  | total loss: [1m[32m0.53761[0m[0m | time: 7.530s
[2K
| Adam | epoch: 002 | loss: 0.53761 - acc: 0.7641 -- iter: 032/187
[A[ATraining Step: 8  | total loss: [1m[32m0.35380[0m[0m | time: 16.080s
[2K
| Adam | epoch: 002 | loss: 0.35380 - acc: 0.8759 -- iter: 064/187
[A[ATraining Step: 9  | total loss: [1m[32m0.41763[0m[0m | time: 24.642s
[2K
| Adam | epoch: 002 | loss: 0.41763 - acc: 0.8589 -- iter: 096/187
[A[ATraining Step: 10  | total loss: [1m[32m0.40747[0m[0m | time: 39.707s
[2K
| Adam | epoch: 002 | loss: 0.40747 - acc: 0.8513 -- iter: 128/187
[A[ATraining Step: 11  | total loss: [1m[32m0.68383[0m[0m | time: 51.833s
[2K
| Adam | epoch: 002 | loss: 0.68383 - acc: 0.8181 -- iter: 160/187
[A[ATraining Step: 12  | total loss: [1m[32m0.49410[0m[0m | time: 69.810s
[2K
| Adam | epoch: 002 | loss: 0.49410 - acc: 0.8718 | val_loss: 0.99765 - val_acc: 0.6610 -- iter: 187/187
--
Training Step: 13  | total loss: [1m[32m0.44686[0m[0m | time: 7.065s
[2K
| Adam | epoch: 003 | loss: 0.44686 - acc: 0.8464 -- iter: 032/187
[A[ATraining Step: 14  | total loss: [1m[32m0.43321[0m[0m | time: 14.412s
[2K
| Adam | epoch: 003 | loss: 0.43321 - acc: 0.8486 -- iter: 064/187
[A[ATraining Step: 15  | total loss: [1m[32m0.35423[0m[0m | time: 22.713s
[2K
| Adam | epoch: 003 | loss: 0.35423 - acc: 0.8789 -- iter: 096/187
[A[ATraining Step: 16  | total loss: [1m[32m0.35061[0m[0m | time: 31.386s
[2K
| Adam | epoch: 003 | loss: 0.35061 - acc: 0.8423 -- iter: 128/187
[A[ATraining Step: 17  | total loss: [1m[32m0.37253[0m[0m | time: 43.183s
[2K
| Adam | epoch: 003 | loss: 0.37253 - acc: 0.8653 -- iter: 160/187
[A[ATraining Step: 18  | total loss: [1m[32m0.29410[0m[0m | time: 61.051s
[2K
| Adam | epoch: 003 | loss: 0.29410 - acc: 0.9011 | val_loss: 1.01978 - val_acc: 0.6610 -- iter: 187/187
--
Training Step: 19  | total loss: [1m[32m0.29890[0m[0m | time: 11.900s
[2K
| Adam | epoch: 004 | loss: 0.29890 - acc: 0.8924 -- iter: 032/187
[A[ATraining Step: 20  | total loss: [1m[32m0.23497[0m[0m | time: 19.190s
[2K
| Adam | epoch: 004 | loss: 0.23497 - acc: 0.9169 -- iter: 064/187
[A[ATraining Step: 21  | total loss: [1m[32m0.23260[0m[0m | time: 26.537s
[2K
| Adam | epoch: 004 | loss: 0.23260 - acc: 0.9197 -- iter: 096/187
[A[ATraining Step: 22  | total loss: [1m[32m0.20628[0m[0m | time: 34.986s
[2K
| Adam | epoch: 004 | loss: 0.20628 - acc: 0.9327 -- iter: 128/187
[A[ATraining Step: 23  | total loss: [1m[32m0.23881[0m[0m | time: 46.705s
[2K
| Adam | epoch: 004 | loss: 0.23881 - acc: 0.9159 -- iter: 160/187
[A[ATraining Step: 24  | total loss: [1m[32m0.20707[0m[0m | time: 66.236s
[2K
| Adam | epoch: 004 | loss: 0.20707 - acc: 0.9308 | val_loss: 1.51167 - val_acc: 0.6610 -- iter: 187/187
--
Training Step: 25  | total loss: [1m[32m0.17603[0m[0m | time: 8.852s
[2K
| Adam | epoch: 005 | loss: 0.17603 - acc: 0.9411 -- iter: 032/187
[A[ATraining Step: 26  | total loss: [1m[32m0.15894[0m[0m | time: 16.952s
[2K
| Adam | epoch: 005 | loss: 0.15894 - acc: 0.9485 -- iter: 064/187
[A[ATraining Step: 27  | total loss: [1m[32m0.15729[0m[0m | time: 23.998s
[2K
| Adam | epoch: 005 | loss: 0.15729 - acc: 0.9537 -- iter: 096/187
[A[ATraining Step: 28  | total loss: [1m[32m0.13377[0m[0m | time: 34.650s
[2K
| Adam | epoch: 005 | loss: 0.13377 - acc: 0.9653 -- iter: 128/187
[A[ATraining Step: 29  | total loss: [1m[32m0.11026[0m[0m | time: 46.426s
[2K
| Adam | epoch: 005 | loss: 0.11026 - acc: 0.9737 -- iter: 160/187
[A[ATraining Step: 30  | total loss: [1m[32m0.15136[0m[0m | time: 64.504s
[2K
| Adam | epoch: 005 | loss: 0.15136 - acc: 0.9503 | val_loss: 1.40277 - val_acc: 0.6610 -- iter: 187/187
--
Training Step: 31  | total loss: [1m[32m0.15316[0m[0m | time: 10.299s
[2K
| Adam | epoch: 006 | loss: 0.15316 - acc: 0.9546 -- iter: 032/187
[A[ATraining Step: 32  | total loss: [1m[32m0.12497[0m[0m | time: 20.368s
[2K
| Adam | epoch: 006 | loss: 0.12497 - acc: 0.9648 -- iter: 064/187
[A[ATraining Step: 33  | total loss: [1m[32m0.13256[0m[0m | time: 33.471s
[2K
| Adam | epoch: 006 | loss: 0.13256 - acc: 0.9519 -- iter: 096/187
[A[ATraining Step: 34  | total loss: [1m[32m0.12082[0m[0m | time: 47.310s
[2K
| Adam | epoch: 006 | loss: 0.12082 - acc: 0.9555 -- iter: 128/187
[A[ATraining Step: 35  | total loss: [1m[32m0.10613[0m[0m | time: 60.942s
[2K
| Adam | epoch: 006 | loss: 0.10613 - acc: 0.9649 -- iter: 160/187
[A[ATraining Step: 36  | total loss: [1m[32m0.08904[0m[0m | time: 80.741s
[2K
| Adam | epoch: 006 | loss: 0.08904 - acc: 0.9720 | val_loss: 0.79347 - val_acc: 0.6610 -- iter: 187/187
--
Training Step: 37  | total loss: [1m[32m0.11083[0m[0m | time: 9.880s
[2K
| Adam | epoch: 007 | loss: 0.11083 - acc: 0.9714 -- iter: 032/187
[A[ATraining Step: 38  | total loss: [1m[32m0.15553[0m[0m | time: 19.642s
[2K
| Adam | epoch: 007 | loss: 0.15553 - acc: 0.9586 -- iter: 064/187
[A[ATraining Step: 39  | total loss: [1m[32m0.12977[0m[0m | time: 44.337s
[2K
| Adam | epoch: 007 | loss: 0.12977 - acc: 0.9666 -- iter: 096/187
[A[ATraining Step: 40  | total loss: [1m[32m0.13034[0m[0m | time: 62.539s
[2K
| Adam | epoch: 007 | loss: 0.13034 - acc: 0.9670 -- iter: 128/187
[A[ATraining Step: 41  | total loss: [1m[32m0.11578[0m[0m | time: 76.667s
[2K
| Adam | epoch: 007 | loss: 0.11578 - acc: 0.9730 -- iter: 160/187
[A[ATraining Step: 42  | total loss: [1m[32m0.10014[0m[0m | time: 94.703s
[2K
| Adam | epoch: 007 | loss: 0.10014 - acc: 0.9779 | val_loss: 1.29495 - val_acc: 0.6610 -- iter: 187/187
--
Training Step: 43  | total loss: [1m[32m0.08617[0m[0m | time: 8.190s
[2K
| Adam | epoch: 008 | loss: 0.08617 - acc: 0.9818 -- iter: 032/187
[A[ATraining Step: 44  | total loss: [1m[32m0.09832[0m[0m | time: 16.557s
[2K
| Adam | epoch: 008 | loss: 0.09832 - acc: 0.9741 -- iter: 064/187
[A[ATraining Step: 45  | total loss: [1m[32m0.14042[0m[0m | time: 43.163s
[2K
| Adam | epoch: 008 | loss: 0.14042 - acc: 0.9626 -- iter: 096/187
[A[ATraining Step: 46  | total loss: [1m[32m0.13485[0m[0m | time: 66.484s
[2K
| Adam | epoch: 008 | loss: 0.13485 - acc: 0.9636 -- iter: 128/187
[A[ATraining Step: 47  | total loss: [1m[32m0.17069[0m[0m | time: 110.814s
[2K
| Adam | epoch: 008 | loss: 0.17069 - acc: 0.9593 -- iter: 160/187
[A[ATraining Step: 48  | total loss: [1m[32m0.16245[0m[0m | time: 126.315s
[2K
| Adam | epoch: 008 | loss: 0.16245 - acc: 0.9508 | val_loss: 0.98917 - val_acc: 0.6610 -- iter: 187/187
--
Training Step: 49  | total loss: [1m[32m0.14831[0m[0m | time: 7.068s
[2K
| Adam | epoch: 009 | loss: 0.14831 - acc: 0.9527 -- iter: 032/187
[A[ATraining Step: 50  | total loss: [1m[32m0.12731[0m[0m | time: 19.230s
[2K
| Adam | epoch: 009 | loss: 0.12731 - acc: 0.9601 -- iter: 064/187
[A[ATraining Step: 51  | total loss: [1m[32m0.12670[0m[0m | time: 31.887s
[2K
| Adam | epoch: 009 | loss: 0.12670 - acc: 0.9519 -- iter: 096/187
[A[ATraining Step: 52  | total loss: [1m[32m0.23220[0m[0m | time: 44.496s
[2K
| Adam | epoch: 009 | loss: 0.23220 - acc: 0.9403 -- iter: 128/187
[A[ATraining Step: 53  | total loss: [1m[32m0.21280[0m[0m | time: 57.032s
[2K
| Adam | epoch: 009 | loss: 0.21280 - acc: 0.9445 -- iter: 160/187
[A[ATraining Step: 54  | total loss: [1m[32m0.20515[0m[0m | time: 74.183s
[2K
| Adam | epoch: 009 | loss: 0.20515 - acc: 0.9344 | val_loss: 0.63891 - val_acc: 0.6102 -- iter: 187/187
--
Training Step: 55  | total loss: [1m[32m0.19092[0m[0m | time: 9.649s
[2K
| Adam | epoch: 010 | loss: 0.19092 - acc: 0.9349 -- iter: 032/187
[A[ATraining Step: 56  | total loss: [1m[32m0.17552[0m[0m | time: 21.125s
[2K
| Adam | epoch: 010 | loss: 0.17552 - acc: 0.9440 -- iter: 064/187
[A[ATraining Step: 57  | total loss: [1m[32m0.15675[0m[0m | time: 34.295s
[2K
| Adam | epoch: 010 | loss: 0.15675 - acc: 0.9518 -- iter: 096/187
[A[ATraining Step: 58  | total loss: [1m[32m0.15892[0m[0m | time: 46.990s
[2K
| Adam | epoch: 010 | loss: 0.15892 - acc: 0.9456 -- iter: 128/187
[A[ATraining Step: 59  | total loss: [1m[32m0.16768[0m[0m | time: 60.047s
[2K
| Adam | epoch: 010 | loss: 0.16768 - acc: 0.9403 -- iter: 160/187
[A[ATraining Step: 60  | total loss: [1m[32m0.15389[0m[0m | time: 76.946s
[2K
| Adam | epoch: 010 | loss: 0.15389 - acc: 0.9482 | val_loss: 0.91043 - val_acc: 0.6949 -- iter: 187/187
--
Training Step: 61  | total loss: [1m[32m0.15235[0m[0m | time: 12.737s
[2K
| Adam | epoch: 011 | loss: 0.15235 - acc: 0.9468 -- iter: 032/187
[A[ATraining Step: 62  | total loss: [1m[32m0.14286[0m[0m | time: 23.928s
[2K
| Adam | epoch: 011 | loss: 0.14286 - acc: 0.9496 -- iter: 064/187
[A[ATraining Step: 63  | total loss: [1m[32m0.12959[0m[0m | time: 35.055s
[2K
| Adam | epoch: 011 | loss: 0.12959 - acc: 0.9560 -- iter: 096/187
[A[ATraining Step: 64  | total loss: [1m[32m0.11845[0m[0m | time: 43.303s
[2K
| Adam | epoch: 011 | loss: 0.11845 - acc: 0.9615 -- iter: 128/187
[A[ATraining Step: 65  | total loss: [1m[32m0.10715[0m[0m | time: 51.679s
[2K
| Adam | epoch: 011 | loss: 0.10715 - acc: 0.9663 -- iter: 160/187
[A[ATraining Step: 66  | total loss: [1m[32m0.10817[0m[0m | time: 66.534s
[2K
| Adam | epoch: 011 | loss: 0.10817 - acc: 0.9666 | val_loss: 2.41067 - val_acc: 0.6610 -- iter: 187/187
--
Training Step: 67  | total loss: [1m[32m0.10040[0m[0m | time: 13.118s
[2K
| Adam | epoch: 012 | loss: 0.10040 - acc: 0.9706 -- iter: 032/187
[A[ATraining Step: 68  | total loss: [1m[32m0.09616[0m[0m | time: 23.782s
[2K
| Adam | epoch: 012 | loss: 0.09616 - acc: 0.9704 -- iter: 064/187
[A[ATraining Step: 69  | total loss: [1m[32m0.08827[0m[0m | time: 30.810s
[2K
| Adam | epoch: 012 | loss: 0.08827 - acc: 0.9738 -- iter: 096/187
[A[ATraining Step: 70  | total loss: [1m[32m0.08264[0m[0m | time: 37.954s
[2K
| Adam | epoch: 012 | loss: 0.08264 - acc: 0.9768 -- iter: 128/187
[A[ATraining Step: 71  | total loss: [1m[32m0.07531[0m[0m | time: 45.974s
[2K
| Adam | epoch: 012 | loss: 0.07531 - acc: 0.9795 -- iter: 160/187
[A[ATraining Step: 72  | total loss: [1m[32m0.07506[0m[0m | time: 58.285s
[2K
| Adam | epoch: 012 | loss: 0.07506 - acc: 0.9783 | val_loss: 0.82421 - val_acc: 0.7797 -- iter: 187/187
--
Training Step: 73  | total loss: [1m[32m0.12718[0m[0m | time: 8.626s
[2K
| Adam | epoch: 013 | loss: 0.12718 - acc: 0.9668 -- iter: 032/187
[A[ATraining Step: 74  | total loss: [1m[32m0.11528[0m[0m | time: 16.736s
[2K
| Adam | epoch: 013 | loss: 0.11528 - acc: 0.9704 -- iter: 064/187
[A[ATraining Step: 75  | total loss: [1m[32m0.10443[0m[0m | time: 24.773s
[2K
| Adam | epoch: 013 | loss: 0.10443 - acc: 0.9736 -- iter: 096/187
[A[ATraining Step: 76  | total loss: [1m[32m0.10024[0m[0m | time: 31.823s
[2K
| Adam | epoch: 013 | loss: 0.10024 - acc: 0.9731 -- iter: 128/187
[A[ATraining Step: 77  | total loss: [1m[32m0.09604[0m[0m | time: 40.895s
[2K
| Adam | epoch: 013 | loss: 0.09604 - acc: 0.9760 -- iter: 160/187
[A[ATraining Step: 78  | total loss: [1m[32m0.08654[0m[0m | time: 58.270s
[2K
| Adam | epoch: 013 | loss: 0.08654 - acc: 0.9785 | val_loss: 1.20349 - val_acc: 0.6949 -- iter: 187/187
--
Training Step: 79  | total loss: [1m[32m0.07874[0m[0m | time: 9.867s
[2K
| Adam | epoch: 014 | loss: 0.07874 - acc: 0.9807 -- iter: 032/187
[A[ATraining Step: 80  | total loss: [1m[32m0.11695[0m[0m | time: 18.055s
[2K
| Adam | epoch: 014 | loss: 0.11695 - acc: 0.9731 -- iter: 064/187
[A[ATraining Step: 81  | total loss: [1m[32m0.10797[0m[0m | time: 26.357s
[2K
| Adam | epoch: 014 | loss: 0.10797 - acc: 0.9758 -- iter: 096/187
[A[ATraining Step: 82  | total loss: [1m[32m0.11210[0m[0m | time: 39.384s
[2K
| Adam | epoch: 014 | loss: 0.11210 - acc: 0.9720 -- iter: 128/187
[A[ATraining Step: 83  | total loss: [1m[32m0.12316[0m[0m | time: 50.289s
[2K
| Adam | epoch: 014 | loss: 0.12316 - acc: 0.9623 -- iter: 160/187
[A[ATraining Step: 84  | total loss: [1m[32m0.11752[0m[0m | time: 65.424s
[2K
| Adam | epoch: 014 | loss: 0.11752 - acc: 0.9624 | val_loss: 0.86453 - val_acc: 0.8136 -- iter: 187/187
--
Training Step: 85  | total loss: [1m[32m0.10690[0m[0m | time: 8.101s
[2K
| Adam | epoch: 015 | loss: 0.10690 - acc: 0.9661 -- iter: 032/187
[A[ATraining Step: 86  | total loss: [1m[32m0.12943[0m[0m | time: 20.093s
[2K
| Adam | epoch: 015 | loss: 0.12943 - acc: 0.9601 -- iter: 064/187
[A[ATraining Step: 87  | total loss: [1m[32m0.14371[0m[0m | time: 33.044s
[2K
| Adam | epoch: 015 | loss: 0.14371 - acc: 0.9547 -- iter: 096/187
[A[ATraining Step: 88  | total loss: [1m[32m0.13573[0m[0m | time: 45.029s
[2K
| Adam | epoch: 015 | loss: 0.13573 - acc: 0.9561 -- iter: 128/187
[A[ATraining Step: 89  | total loss: [1m[32m0.13561[0m[0m | time: 57.344s
[2K
| Adam | epoch: 015 | loss: 0.13561 - acc: 0.9574 -- iter: 160/187
[A[ATraining Step: 90  | total loss: [1m[32m0.13331[0m[0m | time: 72.802s
[2K
| Adam | epoch: 015 | loss: 0.13331 - acc: 0.9585 | val_loss: 2.80132 - val_acc: 0.4746 -- iter: 187/187
--
Training Step: 91  | total loss: [1m[32m0.12307[0m[0m | time: 7.108s
[2K
| Adam | epoch: 016 | loss: 0.12307 - acc: 0.9627 -- iter: 032/187
[A[ATraining Step: 92  | total loss: [1m[32m0.11396[0m[0m | time: 15.195s
[2K
| Adam | epoch: 016 | loss: 0.11396 - acc: 0.9664 -- iter: 064/187
[A[ATraining Step: 93  | total loss: [1m[32m0.12039[0m[0m | time: 25.395s
[2K
| Adam | epoch: 016 | loss: 0.12039 - acc: 0.9604 -- iter: 096/187
[A[ATraining Step: 94  | total loss: [1m[32m0.23122[0m[0m | time: 34.536s
[2K
| Adam | epoch: 016 | loss: 0.23122 - acc: 0.9362 -- iter: 128/187
[A[ATraining Step: 95  | total loss: [1m[32m0.21212[0m[0m | time: 42.659s
[2K
| Adam | epoch: 016 | loss: 0.21212 - acc: 0.9426 -- iter: 160/187
[A[ATraining Step: 96  | total loss: [1m[32m0.21025[0m[0m | time: 53.653s
[2K
| Adam | epoch: 016 | loss: 0.21025 - acc: 0.9390 | val_loss: 0.69869 - val_acc: 0.7288 -- iter: 187/187
--
Training Step: 97  | total loss: [1m[32m0.19857[0m[0m | time: 6.979s
[2K
| Adam | epoch: 017 | loss: 0.19857 - acc: 0.9451 -- iter: 032/187
[A[ATraining Step: 98  | total loss: [1m[32m0.19184[0m[0m | time: 14.168s
[2K
| Adam | epoch: 017 | loss: 0.19184 - acc: 0.9469 -- iter: 064/187
[A[ATraining Step: 99  | total loss: [1m[32m0.17950[0m[0m | time: 22.202s
[2K
| Adam | epoch: 017 | loss: 0.17950 - acc: 0.9522 -- iter: 096/187
[A[ATraining Step: 100  | total loss: [1m[32m0.17320[0m[0m | time: 30.030s
[2K
| Adam | epoch: 017 | loss: 0.17320 - acc: 0.9538 -- iter: 128/187
[A[ATraining Step: 101  | total loss: [1m[32m0.16183[0m[0m | time: 38.017s
[2K
| Adam | epoch: 017 | loss: 0.16183 - acc: 0.9585 -- iter: 160/187
[A[ATraining Step: 102  | total loss: [1m[32m0.15210[0m[0m | time: 48.616s
[2K
| Adam | epoch: 017 | loss: 0.15210 - acc: 0.9595 | val_loss: 0.77723 - val_acc: 0.7627 -- iter: 187/187
--
Training Step: 103  | total loss: [1m[32m0.14159[0m[0m | time: 7.907s
[2K
| Adam | epoch: 018 | loss: 0.14159 - acc: 0.9635 -- iter: 032/187
[A[ATraining Step: 104  | total loss: [1m[32m0.15194[0m[0m | time: 15.071s
[2K
| Adam | epoch: 018 | loss: 0.15194 - acc: 0.9547 -- iter: 064/187
[A[ATraining Step: 105  | total loss: [1m[32m0.14247[0m[0m | time: 22.361s
[2K
| Adam | epoch: 018 | loss: 0.14247 - acc: 0.9592 -- iter: 096/187
[A[ATraining Step: 106  | total loss: [1m[32m0.13243[0m[0m | time: 30.485s
[2K
| Adam | epoch: 018 | loss: 0.13243 - acc: 0.9633 -- iter: 128/187
[A[ATraining Step: 107  | total loss: [1m[32m0.12504[0m[0m | time: 38.412s
[2K
| Adam | epoch: 018 | loss: 0.12504 - acc: 0.9638 -- iter: 160/187
[A[ATraining Step: 108  | total loss: [1m[32m0.13806[0m[0m | time: 49.009s
[2K
| Adam | epoch: 018 | loss: 0.13806 - acc: 0.9612 | val_loss: 0.90022 - val_acc: 0.7797 -- iter: 187/187
--
Training Step: 109  | total loss: [1m[32m0.12641[0m[0m | time: 7.973s
[2K
| Adam | epoch: 019 | loss: 0.12641 - acc: 0.9651 -- iter: 032/187
[A[ATraining Step: 110  | total loss: [1m[32m0.11734[0m[0m | time: 16.115s
[2K
| Adam | epoch: 019 | loss: 0.11734 - acc: 0.9654 -- iter: 064/187
[A[ATraining Step: 111  | total loss: [1m[32m0.11871[0m[0m | time: 23.138s
[2K
| Adam | epoch: 019 | loss: 0.11871 - acc: 0.9658 -- iter: 096/187
[A[ATraining Step: 112  | total loss: [1m[32m0.10808[0m[0m | time: 30.176s
[2K
| Adam | epoch: 019 | loss: 0.10808 - acc: 0.9692 -- iter: 128/187
[A[ATraining Step: 113  | total loss: [1m[32m0.09837[0m[0m | time: 38.302s
[2K
| Adam | epoch: 019 | loss: 0.09837 - acc: 0.9723 -- iter: 160/187
[A[ATraining Step: 114  | total loss: [1m[32m0.09323[0m[0m | time: 51.107s
[2K
| Adam | epoch: 019 | loss: 0.09323 - acc: 0.9719 | val_loss: 0.57947 - val_acc: 0.7966 -- iter: 187/187
--
Training Step: 115  | total loss: [1m[32m0.10506[0m[0m | time: 10.004s
[2K
| Adam | epoch: 020 | loss: 0.10506 - acc: 0.9654 -- iter: 032/187
[A[ATraining Step: 116  | total loss: [1m[32m0.09513[0m[0m | time: 19.905s
[2K
| Adam | epoch: 020 | loss: 0.09513 - acc: 0.9688 -- iter: 064/187
[A[ATraining Step: 117  | total loss: [1m[32m0.08719[0m[0m | time: 30.133s
[2K
| Adam | epoch: 020 | loss: 0.08719 - acc: 0.9719 -- iter: 096/187
[A[ATraining Step: 118  | total loss: [1m[32m0.08178[0m[0m | time: 38.673s
[2K
| Adam | epoch: 020 | loss: 0.08178 - acc: 0.9747 -- iter: 128/187
[A[ATraining Step: 119  | total loss: [1m[32m0.07607[0m[0m | time: 47.849s
[2K
| Adam | epoch: 020 | loss: 0.07607 - acc: 0.9773 -- iter: 160/187
[A[ATraining Step: 120  | total loss: [1m[32m0.06995[0m[0m | time: 61.166s
[2K
| Adam | epoch: 020 | loss: 0.06995 - acc: 0.9795 | val_loss: 0.87615 - val_acc: 0.7627 -- iter: 187/187
--
Training Step: 121  | total loss: [1m[32m0.08016[0m[0m | time: 9.993s
[2K
| Adam | epoch: 021 | loss: 0.08016 - acc: 0.9785 -- iter: 032/187
[A[ATraining Step: 122  | total loss: [1m[32m0.11805[0m[0m | time: 20.306s
[2K
| Adam | epoch: 021 | loss: 0.11805 - acc: 0.9744 -- iter: 064/187
[A[ATraining Step: 123  | total loss: [1m[32m0.10859[0m[0m | time: 30.773s
[2K
| Adam | epoch: 021 | loss: 0.10859 - acc: 0.9769 -- iter: 096/187
[A[ATraining Step: 124  | total loss: [1m[32m0.09884[0m[0m | time: 40.933s
[2K
| Adam | epoch: 021 | loss: 0.09884 - acc: 0.9792 -- iter: 128/187
[A[ATraining Step: 125  | total loss: [1m[32m0.08971[0m[0m | time: 50.065s
[2K
| Adam | epoch: 021 | loss: 0.08971 - acc: 0.9813 -- iter: 160/187
[A[ATraining Step: 126  | total loss: [1m[32m0.08234[0m[0m | time: 62.561s
[2K
| Adam | epoch: 021 | loss: 0.08234 - acc: 0.9832 | val_loss: 0.93502 - val_acc: 0.7966 -- iter: 187/187
--
Training Step: 127  | total loss: [1m[32m0.07566[0m[0m | time: 10.265s
[2K
| Adam | epoch: 022 | loss: 0.07566 - acc: 0.9849 -- iter: 032/187
[A[ATraining Step: 128  | total loss: [1m[32m0.07382[0m[0m | time: 19.982s
[2K
| Adam | epoch: 022 | loss: 0.07382 - acc: 0.9833 -- iter: 064/187
[A[ATraining Step: 129  | total loss: [1m[32m0.06778[0m[0m | time: 29.817s
[2K
| Adam | epoch: 022 | loss: 0.06778 - acc: 0.9849 -- iter: 096/187
[A[ATraining Step: 130  | total loss: [1m[32m0.06766[0m[0m | time: 39.800s
[2K
| Adam | epoch: 022 | loss: 0.06766 - acc: 0.9833 -- iter: 128/187
[A[ATraining Step: 131  | total loss: [1m[32m0.06428[0m[0m | time: 49.732s
[2K
| Adam | epoch: 022 | loss: 0.06428 - acc: 0.9819 -- iter: 160/187
[A[ATraining Step: 132  | total loss: [1m[32m0.05872[0m[0m | time: 62.434s
[2K
| Adam | epoch: 022 | loss: 0.05872 - acc: 0.9837 | val_loss: 0.84534 - val_acc: 0.8305 -- iter: 187/187
--
Training Step: 133  | total loss: [1m[32m0.05395[0m[0m | time: 8.752s
[2K
| Adam | epoch: 023 | loss: 0.05395 - acc: 0.9853 -- iter: 032/187
[A[ATraining Step: 134  | total loss: [1m[32m0.04921[0m[0m | time: 19.011s
[2K
| Adam | epoch: 023 | loss: 0.04921 - acc: 0.9868 -- iter: 064/187
[A[ATraining Step: 135  | total loss: [1m[32m0.06357[0m[0m | time: 28.697s
[2K
| Adam | epoch: 023 | loss: 0.06357 - acc: 0.9818 -- iter: 096/187
[A[ATraining Step: 136  | total loss: [1m[32m0.05763[0m[0m | time: 38.943s
[2K
| Adam | epoch: 023 | loss: 0.05763 - acc: 0.9837 -- iter: 128/187
[A[ATraining Step: 137  | total loss: [1m[32m0.05286[0m[0m | time: 48.798s
[2K
| Adam | epoch: 023 | loss: 0.05286 - acc: 0.9853 -- iter: 160/187
[A[ATraining Step: 138  | total loss: [1m[32m0.04815[0m[0m | time: 61.948s
[2K
| Adam | epoch: 023 | loss: 0.04815 - acc: 0.9868 | val_loss: 2.36420 - val_acc: 0.5424 -- iter: 187/187
--
Training Step: 139  | total loss: [1m[32m0.04526[0m[0m | time: 9.071s
[2K
| Adam | epoch: 024 | loss: 0.04526 - acc: 0.9881 -- iter: 032/187
[A[ATraining Step: 140  | total loss: [1m[32m0.05588[0m[0m | time: 18.263s
[2K
| Adam | epoch: 024 | loss: 0.05588 - acc: 0.9856 -- iter: 064/187
[A[ATraining Step: 141  | total loss: [1m[32m0.05508[0m[0m | time: 27.950s
[2K
| Adam | epoch: 024 | loss: 0.05508 - acc: 0.9870 -- iter: 096/187
[A[ATraining Step: 142  | total loss: [1m[32m0.05940[0m[0m | time: 37.915s
[2K
| Adam | epoch: 024 | loss: 0.05940 - acc: 0.9852 -- iter: 128/187
[A[ATraining Step: 143  | total loss: [1m[32m0.10806[0m[0m | time: 48.266s
[2K
| Adam | epoch: 024 | loss: 0.10806 - acc: 0.9804 -- iter: 160/187
[A[ATraining Step: 144  | total loss: [1m[32m0.09754[0m[0m | time: 62.234s
[2K
| Adam | epoch: 024 | loss: 0.09754 - acc: 0.9824 | val_loss: 3.47570 - val_acc: 0.3390 -- iter: 187/187
--
Training Step: 145  | total loss: [1m[32m0.08828[0m[0m | time: 9.889s
[2K
| Adam | epoch: 025 | loss: 0.08828 - acc: 0.9841 -- iter: 032/187
[A[ATraining Step: 146  | total loss: [1m[32m0.08184[0m[0m | time: 18.731s
[2K
| Adam | epoch: 025 | loss: 0.08184 - acc: 0.9857 -- iter: 064/187
[A[ATraining Step: 147  | total loss: [1m[32m0.07665[0m[0m | time: 27.494s
[2K
| Adam | epoch: 025 | loss: 0.07665 - acc: 0.9872 -- iter: 096/187
[A[ATraining Step: 148  | total loss: [1m[32m0.07132[0m[0m | time: 37.587s
[2K
| Adam | epoch: 025 | loss: 0.07132 - acc: 0.9884 -- iter: 128/187
[A[ATraining Step: 149  | total loss: [1m[32m0.07161[0m[0m | time: 47.293s
[2K
| Adam | epoch: 025 | loss: 0.07161 - acc: 0.9865 -- iter: 160/187
[A[ATraining Step: 150  | total loss: [1m[32m0.06689[0m[0m | time: 61.564s
[2K
| Adam | epoch: 025 | loss: 0.06689 - acc: 0.9878 | val_loss: 1.20822 - val_acc: 0.7119 -- iter: 187/187
--
Training Step: 151  | total loss: [1m[32m0.06155[0m[0m | time: 9.867s
[2K
| Adam | epoch: 026 | loss: 0.06155 - acc: 0.9890 -- iter: 032/187
[A[ATraining Step: 152  | total loss: [1m[32m0.05676[0m[0m | time: 19.814s
[2K
| Adam | epoch: 026 | loss: 0.05676 - acc: 0.9901 -- iter: 064/187
[A[ATraining Step: 153  | total loss: [1m[32m0.05184[0m[0m | time: 29.360s
[2K
| Adam | epoch: 026 | loss: 0.05184 - acc: 0.9911 -- iter: 096/187
[A[ATraining Step: 154  | total loss: [1m[32m0.04835[0m[0m | time: 38.297s
[2K
| Adam | epoch: 026 | loss: 0.04835 - acc: 0.9920 -- iter: 128/187
[A[ATraining Step: 155  | total loss: [1m[32m0.04450[0m[0m | time: 48.934s
[2K
| Adam | epoch: 026 | loss: 0.04450 - acc: 0.9928 -- iter: 160/187
[A[ATraining Step: 156  | total loss: [1m[32m0.04919[0m[0m | time: 63.320s
[2K
| Adam | epoch: 026 | loss: 0.04919 - acc: 0.9904 | val_loss: 0.96540 - val_acc: 0.7797 -- iter: 187/187
--
Training Step: 157  | total loss: [1m[32m0.07761[0m[0m | time: 9.765s
[2K
| Adam | epoch: 027 | loss: 0.07761 - acc: 0.9851 -- iter: 032/187
[A[ATraining Step: 158  | total loss: [1m[32m0.07012[0m[0m | time: 20.194s
[2K
| Adam | epoch: 027 | loss: 0.07012 - acc: 0.9866 -- iter: 064/187
[A[ATraining Step: 159  | total loss: [1m[32m0.07977[0m[0m | time: 30.592s
[2K
| Adam | epoch: 027 | loss: 0.07977 - acc: 0.9848 -- iter: 096/187
[A[ATraining Step: 160  | total loss: [1m[32m0.07567[0m[0m | time: 39.673s
[2K
| Adam | epoch: 027 | loss: 0.07567 - acc: 0.9832 -- iter: 128/187
[A[ATraining Step: 161  | total loss: [1m[32m0.07724[0m[0m | time: 48.722s
[2K
| Adam | epoch: 027 | loss: 0.07724 - acc: 0.9812 -- iter: 160/187
[A[ATraining Step: 162  | total loss: [1m[32m0.07324[0m[0m | time: 62.436s
[2K
| Adam | epoch: 027 | loss: 0.07324 - acc: 0.9831 | val_loss: 0.76940 - val_acc: 0.8305 -- iter: 187/187
--
Training Step: 163  | total loss: [1m[32m0.10527[0m[0m | time: 9.781s
[2K
| Adam | epoch: 028 | loss: 0.10527 - acc: 0.9816 -- iter: 032/187
[A[ATraining Step: 164  | total loss: [1m[32m0.09870[0m[0m | time: 20.002s
[2K
| Adam | epoch: 028 | loss: 0.09870 - acc: 0.9835 -- iter: 064/187
[A[ATraining Step: 165  | total loss: [1m[32m0.11422[0m[0m | time: 30.329s
[2K
| Adam | epoch: 028 | loss: 0.11422 - acc: 0.9820 -- iter: 096/187
[A[ATraining Step: 166  | total loss: [1m[32m0.10335[0m[0m | time: 40.048s
[2K
| Adam | epoch: 028 | loss: 0.10335 - acc: 0.9838 -- iter: 128/187
[A[ATraining Step: 167  | total loss: [1m[32m0.09516[0m[0m | time: 49.204s
[2K
| Adam | epoch: 028 | loss: 0.09516 - acc: 0.9854 -- iter: 160/187
[A[ATraining Step: 168  | total loss: [1m[32m0.08910[0m[0m | time: 60.784s
[2K
| Adam | epoch: 028 | loss: 0.08910 - acc: 0.9869 | val_loss: 0.91045 - val_acc: 0.7458 -- iter: 187/187
--
Training Step: 169  | total loss: [1m[32m0.08250[0m[0m | time: 8.023s
[2K
| Adam | epoch: 029 | loss: 0.08250 - acc: 0.9882 -- iter: 032/187
[A[ATraining Step: 170  | total loss: [1m[32m0.07502[0m[0m | time: 15.967s
[2K
| Adam | epoch: 029 | loss: 0.07502 - acc: 0.9894 -- iter: 064/187
[A[ATraining Step: 171  | total loss: [1m[32m0.06838[0m[0m | time: 23.910s
[2K
| Adam | epoch: 029 | loss: 0.06838 - acc: 0.9904 -- iter: 096/187
[A[ATraining Step: 172  | total loss: [1m[32m0.06224[0m[0m | time: 31.789s
[2K
| Adam | epoch: 029 | loss: 0.06224 - acc: 0.9914 -- iter: 128/187
[A[ATraining Step: 173  | total loss: [1m[32m0.05659[0m[0m | time: 39.642s
[2K
| Adam | epoch: 029 | loss: 0.05659 - acc: 0.9923 -- iter: 160/187
[A[ATraining Step: 174  | total loss: [1m[32m0.05185[0m[0m | time: 49.417s
[2K
| Adam | epoch: 029 | loss: 0.05185 - acc: 0.9930 | val_loss: 0.99675 - val_acc: 0.8475 -- iter: 187/187
--
Training Step: 175  | total loss: [1m[32m0.04796[0m[0m | time: 7.159s
[2K
| Adam | epoch: 030 | loss: 0.04796 - acc: 0.9937 -- iter: 032/187
[A[ATraining Step: 176  | total loss: [1m[32m0.04428[0m[0m | time: 15.098s
[2K
| Adam | epoch: 030 | loss: 0.04428 - acc: 0.9944 -- iter: 064/187
[A[ATraining Step: 177  | total loss: [1m[32m0.04087[0m[0m | time: 23.194s
[2K
| Adam | epoch: 030 | loss: 0.04087 - acc: 0.9949 -- iter: 096/187
[A[ATraining Step: 178  | total loss: [1m[32m0.03730[0m[0m | time: 31.104s
[2K
| Adam | epoch: 030 | loss: 0.03730 - acc: 0.9954 -- iter: 128/187
[A[ATraining Step: 179  | total loss: [1m[32m0.03456[0m[0m | time: 38.933s
[2K
| Adam | epoch: 030 | loss: 0.03456 - acc: 0.9959 -- iter: 160/187
[A[ATraining Step: 180  | total loss: [1m[32m0.03177[0m[0m | time: 49.682s
[2K
| Adam | epoch: 030 | loss: 0.03177 - acc: 0.9963 | val_loss: 1.12025 - val_acc: 0.7966 -- iter: 187/187
--
Validation AUC:0.8153846153846155
Validation AUPRC:0.6924193873166137
Test AUC:0.8152173913043478
Test AUPRC:0.7914943981688541
BestTestF1Score	0.74	0.65	0.83	0.93	0.61	14	1	35	9	0.25
BestTestMCCScore	0.74	0.65	0.83	0.93	0.61	14	1	35	9	0.25
BestTestAccuracyScore	0.74	0.65	0.83	0.93	0.61	14	1	35	9	0.25
BestValidationF1Score	0.76	0.65	0.85	0.82	0.7	14	3	36	6	0.25
BestValidationMCC	0.76	0.65	0.85	0.82	0.7	14	3	36	6	0.25
BestValidationAccuracy	0.76	0.65	0.85	0.82	0.7	14	3	36	6	0.25
TestPredictions (Threshold:0.25)
CHEMBL418382,TP,ACT,0.9900000095367432	CHEMBL353506,TN,INACT,0.009999999776482582	CHEMBL473133,TN,INACT,0.05000000074505806	CHEMBL285343,TP,ACT,0.9900000095367432	CHEMBL371544,TN,INACT,0.0	CHEMBL3806254,TP,ACT,1.0	CHEMBL3582167,TP,ACT,0.7599999904632568	CHEMBL281326,TP,ACT,0.9900000095367432	CHEMBL3805257,TP,ACT,0.9100000262260437	CHEMBL3763290,TN,INACT,0.05999999865889549	CHEMBL82279,TN,INACT,0.03999999910593033	CHEMBL3763583,TP,ACT,0.6600000262260437	CHEMBL308954,FN,ACT,0.009999999776482582	CHEMBL488016,TN,INACT,0.029999999329447746	CHEMBL1170610,TN,INACT,0.0	CHEMBL561227,TN,INACT,0.0	CHEMBL28168,TP,ACT,0.9599999785423279	CHEMBL29743,TP,ACT,0.7699999809265137	CHEMBL3763752,TN,INACT,0.029999999329447746	CHEMBL26017,TP,ACT,0.8399999737739563	CHEMBL282610,TP,ACT,0.9800000190734863	CHEMBL27634,FN,ACT,0.0	CHEMBL1506885,FN,ACT,0.03999999910593033	CHEMBL453377,TN,INACT,0.0	CHEMBL90568,FN,ACT,0.0	CHEMBL171661,TN,INACT,0.0	CHEMBL353170,TN,INACT,0.0	CHEMBL2420083,FN,ACT,0.0	CHEMBL2420089,TN,INACT,0.0	CHEMBL388590,FN,ACT,0.0	CHEMBL3765551,FN,ACT,0.009999999776482582	CHEMBL168268,TN,INACT,0.0	CHEMBL3337743,TN,INACT,0.0	CHEMBL286272,TP,ACT,0.9900000095367432	CHEMBL1945513,TN,INACT,0.0	CHEMBL470100,TN,INACT,0.0	CHEMBL186008,TN,INACT,0.0	CHEMBL452564,TN,INACT,0.0	CHEMBL560229,TN,INACT,0.009999999776482582	CHEMBL571667,TN,INACT,0.0	CHEMBL74898,TN,INACT,0.0	CHEMBL280981,FN,ACT,0.07999999821186066	CHEMBL3764781,TN,INACT,0.019999999552965164	CHEMBL283693,TP,ACT,0.9900000095367432	CHEMBL440746,TN,INACT,0.0	CHEMBL3317938,TN,INACT,0.0	CHEMBL257286,TN,INACT,0.0	CHEMBL1215577,TN,INACT,0.009999999776482582	CHEMBL500095,TN,INACT,0.0	CHEMBL1945808,TN,INACT,0.0	CHEMBL171591,TN,INACT,0.0	CHEMBL169810,TN,INACT,0.05999999865889549	CHEMBL473132,TN,INACT,0.0	CHEMBL370771,TN,INACT,0.0	CHEMBL197,TP,ACT,0.46000000834465027	CHEMBL2338107,TN,INACT,0.0	CHEMBL336467,TN,INACT,0.0	CHEMBL304717,FP,INACT,0.9900000095367432	CHEMBL1945974,FN,ACT,0.05000000074505806	

