CNNModel CHEMBL5160 adam 0.001 30 128 0 0.6 False True
Number of active compounds :	137
Number of inactive compounds :	137
---------------------------------
Run id: CNNModel_CHEMBL5160_adam_0.001_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5160_adam_0.001_30_128_0.6_True/
---------------------------------
Training samples: 151
Validation samples: 48
--
Training Step: 1  | time: 0.780s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/151
[A[ATraining Step: 2  | total loss: [1m[32m0.62403[0m[0m | time: 1.473s
[2K
| Adam | epoch: 001 | loss: 0.62403 - acc: 0.3656 -- iter: 064/151
[A[ATraining Step: 3  | total loss: [1m[32m0.68461[0m[0m | time: 2.229s
[2K
| Adam | epoch: 001 | loss: 0.68461 - acc: 0.3733 -- iter: 096/151
[A[ATraining Step: 4  | total loss: [1m[32m0.69025[0m[0m | time: 2.951s
[2K
| Adam | epoch: 001 | loss: 0.69025 - acc: 0.5386 -- iter: 128/151
[A[ATraining Step: 5  | total loss: [1m[32m0.69274[0m[0m | time: 4.551s
[2K
| Adam | epoch: 001 | loss: 0.69274 - acc: 0.4903 | val_loss: 0.69439 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 6  | total loss: [1m[32m0.69165[0m[0m | time: 0.490s
[2K
| Adam | epoch: 002 | loss: 0.69165 - acc: 0.5664 -- iter: 032/151
[A[ATraining Step: 7  | total loss: [1m[32m0.69041[0m[0m | time: 1.125s
[2K
| Adam | epoch: 002 | loss: 0.69041 - acc: 0.5918 -- iter: 064/151
[A[ATraining Step: 8  | total loss: [1m[32m0.69313[0m[0m | time: 1.721s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.5226 -- iter: 096/151
[A[ATraining Step: 9  | total loss: [1m[32m0.69224[0m[0m | time: 2.432s
[2K
| Adam | epoch: 002 | loss: 0.69224 - acc: 0.5272 -- iter: 128/151
[A[ATraining Step: 10  | total loss: [1m[32m0.69175[0m[0m | time: 4.174s
[2K
| Adam | epoch: 002 | loss: 0.69175 - acc: 0.5292 | val_loss: 0.69973 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 11  | total loss: [1m[32m0.69248[0m[0m | time: 0.615s
[2K
| Adam | epoch: 003 | loss: 0.69248 - acc: 0.5154 -- iter: 032/151
[A[ATraining Step: 12  | total loss: [1m[32m0.68702[0m[0m | time: 1.183s
[2K
| Adam | epoch: 003 | loss: 0.68702 - acc: 0.5574 -- iter: 064/151
[A[ATraining Step: 13  | total loss: [1m[32m0.68192[0m[0m | time: 1.791s
[2K
| Adam | epoch: 003 | loss: 0.68192 - acc: 0.5794 -- iter: 096/151
[A[ATraining Step: 14  | total loss: [1m[32m0.70244[0m[0m | time: 2.403s
[2K
| Adam | epoch: 003 | loss: 0.70244 - acc: 0.5213 -- iter: 128/151
[A[ATraining Step: 15  | total loss: [1m[32m0.69210[0m[0m | time: 4.075s
[2K
| Adam | epoch: 003 | loss: 0.69210 - acc: 0.5497 | val_loss: 0.70427 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 16  | total loss: [1m[32m0.69142[0m[0m | time: 0.804s
[2K
| Adam | epoch: 004 | loss: 0.69142 - acc: 0.5428 -- iter: 032/151
[A[ATraining Step: 17  | total loss: [1m[32m0.69499[0m[0m | time: 1.354s
[2K
| Adam | epoch: 004 | loss: 0.69499 - acc: 0.5161 -- iter: 064/151
[A[ATraining Step: 18  | total loss: [1m[32m0.69408[0m[0m | time: 1.899s
[2K
| Adam | epoch: 004 | loss: 0.69408 - acc: 0.5181 -- iter: 096/151
[A[ATraining Step: 19  | total loss: [1m[32m0.69310[0m[0m | time: 2.693s
[2K
| Adam | epoch: 004 | loss: 0.69310 - acc: 0.5193 -- iter: 128/151
[A[ATraining Step: 20  | total loss: [1m[32m0.69239[0m[0m | time: 4.318s
[2K
| Adam | epoch: 004 | loss: 0.69239 - acc: 0.5231 | val_loss: 0.69595 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 21  | total loss: [1m[32m0.69081[0m[0m | time: 0.788s
[2K
| Adam | epoch: 005 | loss: 0.69081 - acc: 0.5450 -- iter: 032/151
[A[ATraining Step: 22  | total loss: [1m[32m0.69133[0m[0m | time: 1.527s
[2K
| Adam | epoch: 005 | loss: 0.69133 - acc: 0.5315 -- iter: 064/151
[A[ATraining Step: 23  | total loss: [1m[32m0.68874[0m[0m | time: 2.055s
[2K
| Adam | epoch: 005 | loss: 0.68874 - acc: 0.5768 -- iter: 096/151
[A[ATraining Step: 24  | total loss: [1m[32m0.68971[0m[0m | time: 2.624s
[2K
| Adam | epoch: 005 | loss: 0.68971 - acc: 0.5613 -- iter: 128/151
[A[ATraining Step: 25  | total loss: [1m[32m0.69039[0m[0m | time: 4.326s
[2K
| Adam | epoch: 005 | loss: 0.69039 - acc: 0.5505 | val_loss: 0.69621 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 26  | total loss: [1m[32m0.69169[0m[0m | time: 0.804s
[2K
| Adam | epoch: 006 | loss: 0.69169 - acc: 0.5289 -- iter: 032/151
[A[ATraining Step: 27  | total loss: [1m[32m0.69254[0m[0m | time: 1.578s
[2K
| Adam | epoch: 006 | loss: 0.69254 - acc: 0.5134 -- iter: 064/151
[A[ATraining Step: 28  | total loss: [1m[32m0.69266[0m[0m | time: 2.329s
[2K
| Adam | epoch: 006 | loss: 0.69266 - acc: 0.5101 -- iter: 096/151
[A[ATraining Step: 29  | total loss: [1m[32m0.69433[0m[0m | time: 2.860s
[2K
| Adam | epoch: 006 | loss: 0.69433 - acc: 0.4848 -- iter: 128/151
[A[ATraining Step: 30  | total loss: [1m[32m0.69381[0m[0m | time: 4.363s
[2K
| Adam | epoch: 006 | loss: 0.69381 - acc: 0.4936 | val_loss: 0.69534 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 31  | total loss: [1m[32m0.69357[0m[0m | time: 0.618s
[2K
| Adam | epoch: 007 | loss: 0.69357 - acc: 0.5001 -- iter: 032/151
[A[ATraining Step: 32  | total loss: [1m[32m0.69199[0m[0m | time: 1.252s
[2K
| Adam | epoch: 007 | loss: 0.69199 - acc: 0.5282 -- iter: 064/151
[A[ATraining Step: 33  | total loss: [1m[32m0.69180[0m[0m | time: 1.967s
[2K
| Adam | epoch: 007 | loss: 0.69180 - acc: 0.5288 -- iter: 096/151
[A[ATraining Step: 34  | total loss: [1m[32m0.69126[0m[0m | time: 2.718s
[2K
| Adam | epoch: 007 | loss: 0.69126 - acc: 0.5361 -- iter: 128/151
[A[ATraining Step: 35  | total loss: [1m[32m0.69116[0m[0m | time: 4.299s
[2K
| Adam | epoch: 007 | loss: 0.69116 - acc: 0.5351 | val_loss: 0.69589 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 36  | total loss: [1m[32m0.69121[0m[0m | time: 0.573s
[2K
| Adam | epoch: 008 | loss: 0.69121 - acc: 0.5323 -- iter: 032/151
[A[ATraining Step: 37  | total loss: [1m[32m0.69134[0m[0m | time: 1.290s
[2K
| Adam | epoch: 008 | loss: 0.69134 - acc: 0.5302 -- iter: 064/151
[A[ATraining Step: 38  | total loss: [1m[32m0.69274[0m[0m | time: 1.905s
[2K
| Adam | epoch: 008 | loss: 0.69274 - acc: 0.5121 -- iter: 096/151
[A[ATraining Step: 39  | total loss: [1m[32m0.69136[0m[0m | time: 2.712s
[2K
| Adam | epoch: 008 | loss: 0.69136 - acc: 0.5277 -- iter: 128/151
[A[ATraining Step: 40  | total loss: [1m[32m0.69086[0m[0m | time: 4.330s
[2K
| Adam | epoch: 008 | loss: 0.69086 - acc: 0.5284 | val_loss: 0.69756 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 41  | total loss: [1m[32m0.68868[0m[0m | time: 0.554s
[2K
| Adam | epoch: 009 | loss: 0.68868 - acc: 0.5519 -- iter: 032/151
[A[ATraining Step: 42  | total loss: [1m[32m0.68864[0m[0m | time: 1.121s
[2K
| Adam | epoch: 009 | loss: 0.68864 - acc: 0.5464 -- iter: 064/151
[A[ATraining Step: 43  | total loss: [1m[32m0.68833[0m[0m | time: 1.889s
[2K
| Adam | epoch: 009 | loss: 0.68833 - acc: 0.5421 -- iter: 096/151
[A[ATraining Step: 44  | total loss: [1m[32m0.68741[0m[0m | time: 2.628s
[2K
| Adam | epoch: 009 | loss: 0.68741 - acc: 0.5456 -- iter: 128/151
[A[ATraining Step: 45  | total loss: [1m[32m0.69428[0m[0m | time: 4.315s
[2K
| Adam | epoch: 009 | loss: 0.69428 - acc: 0.5166 | val_loss: 0.70315 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 46  | total loss: [1m[32m0.68918[0m[0m | time: 0.678s
[2K
| Adam | epoch: 010 | loss: 0.68918 - acc: 0.5399 -- iter: 032/151
[A[ATraining Step: 47  | total loss: [1m[32m0.68761[0m[0m | time: 1.230s
[2K
| Adam | epoch: 010 | loss: 0.68761 - acc: 0.5436 -- iter: 064/151
[A[ATraining Step: 48  | total loss: [1m[32m0.69466[0m[0m | time: 1.823s
[2K
| Adam | epoch: 010 | loss: 0.69466 - acc: 0.5121 -- iter: 096/151
[A[ATraining Step: 49  | total loss: [1m[32m0.69906[0m[0m | time: 2.466s
[2K
| Adam | epoch: 010 | loss: 0.69906 - acc: 0.4862 -- iter: 128/151
[A[ATraining Step: 50  | total loss: [1m[32m0.69744[0m[0m | time: 4.082s
[2K
| Adam | epoch: 010 | loss: 0.69744 - acc: 0.4883 | val_loss: 0.69475 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 51  | total loss: [1m[32m0.69597[0m[0m | time: 0.776s
[2K
| Adam | epoch: 011 | loss: 0.69597 - acc: 0.4949 -- iter: 032/151
[A[ATraining Step: 52  | total loss: [1m[32m0.69336[0m[0m | time: 1.373s
[2K
| Adam | epoch: 011 | loss: 0.69336 - acc: 0.5238 -- iter: 064/151
[A[ATraining Step: 53  | total loss: [1m[32m0.69333[0m[0m | time: 1.833s
[2K
| Adam | epoch: 011 | loss: 0.69333 - acc: 0.5157 -- iter: 096/151
[A[ATraining Step: 54  | total loss: [1m[32m0.69393[0m[0m | time: 2.280s
[2K
| Adam | epoch: 011 | loss: 0.69393 - acc: 0.4976 -- iter: 128/151
[A[ATraining Step: 55  | total loss: [1m[32m0.69433[0m[0m | time: 3.912s
[2K
| Adam | epoch: 011 | loss: 0.69433 - acc: 0.4824 | val_loss: 0.69362 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 56  | total loss: [1m[32m0.69385[0m[0m | time: 0.711s
[2K
| Adam | epoch: 012 | loss: 0.69385 - acc: 0.4893 -- iter: 032/151
[A[ATraining Step: 57  | total loss: [1m[32m0.69351[0m[0m | time: 1.495s
[2K
| Adam | epoch: 012 | loss: 0.69351 - acc: 0.4951 -- iter: 064/151
[A[ATraining Step: 58  | total loss: [1m[32m0.69346[0m[0m | time: 2.254s
[2K
| Adam | epoch: 012 | loss: 0.69346 - acc: 0.4872 -- iter: 096/151
[A[ATraining Step: 59  | total loss: [1m[32m0.69304[0m[0m | time: 2.852s
[2K
| Adam | epoch: 012 | loss: 0.69304 - acc: 0.4932 -- iter: 128/151
[A[ATraining Step: 60  | total loss: [1m[32m0.69211[0m[0m | time: 4.307s
[2K
| Adam | epoch: 012 | loss: 0.69211 - acc: 0.5200 | val_loss: 0.69349 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 61  | total loss: [1m[32m0.69100[0m[0m | time: 0.623s
[2K
| Adam | epoch: 013 | loss: 0.69100 - acc: 0.5429 -- iter: 032/151
[A[ATraining Step: 62  | total loss: [1m[32m0.69082[0m[0m | time: 1.259s
[2K
| Adam | epoch: 013 | loss: 0.69082 - acc: 0.5374 -- iter: 064/151
[A[ATraining Step: 63  | total loss: [1m[32m0.69042[0m[0m | time: 1.861s
[2K
| Adam | epoch: 013 | loss: 0.69042 - acc: 0.5366 -- iter: 096/151
[A[ATraining Step: 64  | total loss: [1m[32m0.69128[0m[0m | time: 2.495s
[2K
| Adam | epoch: 013 | loss: 0.69128 - acc: 0.5203 -- iter: 128/151
[A[ATraining Step: 65  | total loss: [1m[32m0.68927[0m[0m | time: 3.944s
[2K
| Adam | epoch: 013 | loss: 0.68927 - acc: 0.5371 | val_loss: 0.69604 - val_acc: 0.4583 -- iter: 151/151
--
Training Step: 66  | total loss: [1m[32m0.68706[0m[0m | time: 0.448s
[2K
| Adam | epoch: 014 | loss: 0.68706 - acc: 0.5511 -- iter: 032/151
[A[ATraining Step: 67  | total loss: [1m[32m0.68431[0m[0m | time: 1.068s
[2K
| Adam | epoch: 014 | loss: 0.68431 - acc: 0.5632 -- iter: 064/151
[A[ATraining Step: 68  | total loss: [1m[32m0.68270[0m[0m | time: 1.678s
[2K
| Adam | epoch: 014 | loss: 0.68270 - acc: 0.5631 -- iter: 096/151
[A[ATraining Step: 69  | total loss: [1m[32m0.68702[0m[0m | time: 2.367s
[2K
| Adam | epoch: 014 | loss: 0.68702 - acc: 0.5448 -- iter: 128/151
[A[ATraining Step: 70  | total loss: [1m[32m0.68609[0m[0m | time: 3.991s
[2K
| Adam | epoch: 014 | loss: 0.68609 - acc: 0.5432 | val_loss: 0.68419 - val_acc: 0.4792 -- iter: 151/151
--
Training Step: 71  | total loss: [1m[32m0.68240[0m[0m | time: 0.473s
[2K
| Adam | epoch: 015 | loss: 0.68240 - acc: 0.5419 -- iter: 032/151
[A[ATraining Step: 72  | total loss: [1m[32m0.67885[0m[0m | time: 1.005s
[2K
| Adam | epoch: 015 | loss: 0.67885 - acc: 0.5592 -- iter: 064/151
[A[ATraining Step: 73  | total loss: [1m[32m0.67385[0m[0m | time: 1.626s
[2K
| Adam | epoch: 015 | loss: 0.67385 - acc: 0.5743 -- iter: 096/151
[A[ATraining Step: 74  | total loss: [1m[32m0.67215[0m[0m | time: 2.252s
[2K
| Adam | epoch: 015 | loss: 0.67215 - acc: 0.5730 -- iter: 128/151
[A[ATraining Step: 75  | total loss: [1m[32m0.67376[0m[0m | time: 3.864s
[2K
| Adam | epoch: 015 | loss: 0.67376 - acc: 0.5583 | val_loss: 0.64291 - val_acc: 0.6250 -- iter: 151/151
--
Training Step: 76  | total loss: [1m[32m0.66611[0m[0m | time: 0.712s
[2K
| Adam | epoch: 016 | loss: 0.66611 - acc: 0.5688 -- iter: 032/151
[A[ATraining Step: 77  | total loss: [1m[32m0.66564[0m[0m | time: 1.163s
[2K
| Adam | epoch: 016 | loss: 0.66564 - acc: 0.5682 -- iter: 064/151
[A[ATraining Step: 78  | total loss: [1m[32m0.65610[0m[0m | time: 1.616s
[2K
| Adam | epoch: 016 | loss: 0.65610 - acc: 0.5951 -- iter: 096/151
[A[ATraining Step: 79  | total loss: [1m[32m0.64842[0m[0m | time: 2.216s
[2K
| Adam | epoch: 016 | loss: 0.64842 - acc: 0.6010 -- iter: 128/151
[A[ATraining Step: 80  | total loss: [1m[32m0.64284[0m[0m | time: 3.837s
[2K
| Adam | epoch: 016 | loss: 0.64284 - acc: 0.6099 | val_loss: 0.63758 - val_acc: 0.6250 -- iter: 151/151
--
Training Step: 81  | total loss: [1m[32m0.63622[0m[0m | time: 0.693s
[2K
| Adam | epoch: 017 | loss: 0.63622 - acc: 0.6114 -- iter: 032/151
[A[ATraining Step: 82  | total loss: [1m[32m0.63400[0m[0m | time: 1.302s
[2K
| Adam | epoch: 017 | loss: 0.63400 - acc: 0.6096 -- iter: 064/151
[A[ATraining Step: 83  | total loss: [1m[32m0.62289[0m[0m | time: 1.745s
[2K
| Adam | epoch: 017 | loss: 0.62289 - acc: 0.6237 -- iter: 096/151
[A[ATraining Step: 84  | total loss: [1m[32m0.60947[0m[0m | time: 2.195s
[2K
| Adam | epoch: 017 | loss: 0.60947 - acc: 0.6483 -- iter: 128/151
[A[ATraining Step: 85  | total loss: [1m[32m0.59817[0m[0m | time: 3.810s
[2K
| Adam | epoch: 017 | loss: 0.59817 - acc: 0.6574 | val_loss: 0.60589 - val_acc: 0.6667 -- iter: 151/151
--
Training Step: 86  | total loss: [1m[32m0.58937[0m[0m | time: 0.641s
[2K
| Adam | epoch: 018 | loss: 0.58937 - acc: 0.6729 -- iter: 032/151
[A[ATraining Step: 87  | total loss: [1m[32m0.58791[0m[0m | time: 1.246s
[2K
| Adam | epoch: 018 | loss: 0.58791 - acc: 0.6712 -- iter: 064/151
[A[ATraining Step: 88  | total loss: [1m[32m0.59013[0m[0m | time: 1.986s
[2K
| Adam | epoch: 018 | loss: 0.59013 - acc: 0.6603 -- iter: 096/151
[A[ATraining Step: 89  | total loss: [1m[32m0.56944[0m[0m | time: 2.428s
[2K
| Adam | epoch: 018 | loss: 0.56944 - acc: 0.6787 -- iter: 128/151
[A[ATraining Step: 90  | total loss: [1m[32m0.56029[0m[0m | time: 3.875s
[2K
| Adam | epoch: 018 | loss: 0.56029 - acc: 0.6978 | val_loss: 0.58998 - val_acc: 0.6667 -- iter: 151/151
--
Training Step: 91  | total loss: [1m[32m0.54372[0m[0m | time: 0.634s
[2K
| Adam | epoch: 019 | loss: 0.54372 - acc: 0.7106 -- iter: 032/151
[A[ATraining Step: 92  | total loss: [1m[32m0.54824[0m[0m | time: 1.247s
[2K
| Adam | epoch: 019 | loss: 0.54824 - acc: 0.7020 -- iter: 064/151
[A[ATraining Step: 93  | total loss: [1m[32m0.52661[0m[0m | time: 1.844s
[2K
| Adam | epoch: 019 | loss: 0.52661 - acc: 0.7193 -- iter: 096/151
[A[ATraining Step: 94  | total loss: [1m[32m0.50858[0m[0m | time: 2.446s
[2K
| Adam | epoch: 019 | loss: 0.50858 - acc: 0.7255 -- iter: 128/151
[A[ATraining Step: 95  | total loss: [1m[32m0.49773[0m[0m | time: 3.893s
[2K
| Adam | epoch: 019 | loss: 0.49773 - acc: 0.7373 | val_loss: 0.65888 - val_acc: 0.6667 -- iter: 151/151
--
Training Step: 96  | total loss: [1m[32m0.49027[0m[0m | time: 0.465s
[2K
| Adam | epoch: 020 | loss: 0.49027 - acc: 0.7462 -- iter: 032/151
[A[ATraining Step: 97  | total loss: [1m[32m0.48058[0m[0m | time: 1.092s
[2K
| Adam | epoch: 020 | loss: 0.48058 - acc: 0.7499 -- iter: 064/151
[A[ATraining Step: 98  | total loss: [1m[32m0.47211[0m[0m | time: 1.686s
[2K
| Adam | epoch: 020 | loss: 0.47211 - acc: 0.7468 -- iter: 096/151
[A[ATraining Step: 99  | total loss: [1m[32m0.46102[0m[0m | time: 2.300s
[2K
| Adam | epoch: 020 | loss: 0.46102 - acc: 0.7565 -- iter: 128/151
[A[ATraining Step: 100  | total loss: [1m[32m0.44933[0m[0m | time: 3.926s
[2K
| Adam | epoch: 020 | loss: 0.44933 - acc: 0.7652 | val_loss: 0.60229 - val_acc: 0.7083 -- iter: 151/151
--
Training Step: 101  | total loss: [1m[32m0.42839[0m[0m | time: 0.454s
[2K
| Adam | epoch: 021 | loss: 0.42839 - acc: 0.7824 -- iter: 032/151
[A[ATraining Step: 102  | total loss: [1m[32m0.40597[0m[0m | time: 0.918s
[2K
| Adam | epoch: 021 | loss: 0.40597 - acc: 0.8042 -- iter: 064/151
[A[ATraining Step: 103  | total loss: [1m[32m0.38625[0m[0m | time: 1.577s
[2K
| Adam | epoch: 021 | loss: 0.38625 - acc: 0.8194 -- iter: 096/151
[A[ATraining Step: 104  | total loss: [1m[32m0.38939[0m[0m | time: 2.204s
[2K
| Adam | epoch: 021 | loss: 0.38939 - acc: 0.8156 -- iter: 128/151
[A[ATraining Step: 105  | total loss: [1m[32m0.36290[0m[0m | time: 3.853s
[2K
| Adam | epoch: 021 | loss: 0.36290 - acc: 0.8278 | val_loss: 1.13831 - val_acc: 0.6667 -- iter: 151/151
--
Training Step: 106  | total loss: [1m[32m0.37179[0m[0m | time: 0.619s
[2K
| Adam | epoch: 022 | loss: 0.37179 - acc: 0.8263 -- iter: 032/151
[A[ATraining Step: 107  | total loss: [1m[32m0.37614[0m[0m | time: 1.071s
[2K
| Adam | epoch: 022 | loss: 0.37614 - acc: 0.8218 -- iter: 064/151
[A[ATraining Step: 108  | total loss: [1m[32m0.35329[0m[0m | time: 1.757s
[2K
| Adam | epoch: 022 | loss: 0.35329 - acc: 0.8352 -- iter: 096/151
[A[ATraining Step: 109  | total loss: [1m[32m0.35027[0m[0m | time: 2.363s
[2K
| Adam | epoch: 022 | loss: 0.35027 - acc: 0.8343 -- iter: 128/151
[A[ATraining Step: 110  | total loss: [1m[32m0.36719[0m[0m | time: 3.976s
[2K
| Adam | epoch: 022 | loss: 0.36719 - acc: 0.8228 | val_loss: 0.66745 - val_acc: 0.7500 -- iter: 151/151
--
Training Step: 111  | total loss: [1m[32m0.36946[0m[0m | time: 0.612s
[2K
| Adam | epoch: 023 | loss: 0.36946 - acc: 0.8217 -- iter: 032/151
[A[ATraining Step: 112  | total loss: [1m[32m0.36168[0m[0m | time: 1.212s
[2K
| Adam | epoch: 023 | loss: 0.36168 - acc: 0.8302 -- iter: 064/151
[A[ATraining Step: 113  | total loss: [1m[32m0.35036[0m[0m | time: 1.660s
[2K
| Adam | epoch: 023 | loss: 0.35036 - acc: 0.8378 -- iter: 096/151
[A[ATraining Step: 114  | total loss: [1m[32m0.33190[0m[0m | time: 2.112s
[2K
| Adam | epoch: 023 | loss: 0.33190 - acc: 0.8540 -- iter: 128/151
[A[ATraining Step: 115  | total loss: [1m[32m0.31054[0m[0m | time: 3.724s
[2K
| Adam | epoch: 023 | loss: 0.31054 - acc: 0.8643 | val_loss: 0.54481 - val_acc: 0.7500 -- iter: 151/151
--
Training Step: 116  | total loss: [1m[32m0.29855[0m[0m | time: 0.617s
[2K
| Adam | epoch: 024 | loss: 0.29855 - acc: 0.8747 -- iter: 032/151
[A[ATraining Step: 117  | total loss: [1m[32m0.28064[0m[0m | time: 1.220s
[2K
| Adam | epoch: 024 | loss: 0.28064 - acc: 0.8841 -- iter: 064/151
[A[ATraining Step: 118  | total loss: [1m[32m0.26893[0m[0m | time: 1.834s
[2K
| Adam | epoch: 024 | loss: 0.26893 - acc: 0.8895 -- iter: 096/151
[A[ATraining Step: 119  | total loss: [1m[32m0.25294[0m[0m | time: 2.280s
[2K
| Adam | epoch: 024 | loss: 0.25294 - acc: 0.8974 -- iter: 128/151
[A[ATraining Step: 120  | total loss: [1m[32m0.23265[0m[0m | time: 3.739s
[2K
| Adam | epoch: 024 | loss: 0.23265 - acc: 0.9076 | val_loss: 0.91973 - val_acc: 0.6667 -- iter: 151/151
--
Training Step: 121  | total loss: [1m[32m0.21189[0m[0m | time: 0.617s
[2K
| Adam | epoch: 025 | loss: 0.21189 - acc: 0.9169 -- iter: 032/151
[A[ATraining Step: 122  | total loss: [1m[32m0.20219[0m[0m | time: 1.274s
[2K
| Adam | epoch: 025 | loss: 0.20219 - acc: 0.9189 -- iter: 064/151
[A[ATraining Step: 123  | total loss: [1m[32m0.19208[0m[0m | time: 1.891s
[2K
| Adam | epoch: 025 | loss: 0.19208 - acc: 0.9239 -- iter: 096/151
[A[ATraining Step: 124  | total loss: [1m[32m0.17848[0m[0m | time: 2.495s
[2K
| Adam | epoch: 025 | loss: 0.17848 - acc: 0.9284 -- iter: 128/151
[A[ATraining Step: 125  | total loss: [1m[32m0.16766[0m[0m | time: 3.947s
[2K
| Adam | epoch: 025 | loss: 0.16766 - acc: 0.9324 | val_loss: 0.86385 - val_acc: 0.7292 -- iter: 151/151
--
Training Step: 126  | total loss: [1m[32m0.16506[0m[0m | time: 0.454s
[2K
| Adam | epoch: 026 | loss: 0.16506 - acc: 0.9348 -- iter: 032/151
[A[ATraining Step: 127  | total loss: [1m[32m0.16098[0m[0m | time: 1.059s
[2K
| Adam | epoch: 026 | loss: 0.16098 - acc: 0.9370 -- iter: 064/151
[A[ATraining Step: 128  | total loss: [1m[32m0.15036[0m[0m | time: 1.667s
[2K
| Adam | epoch: 026 | loss: 0.15036 - acc: 0.9402 -- iter: 096/151
[A[ATraining Step: 129  | total loss: [1m[32m0.14027[0m[0m | time: 2.305s
[2K
| Adam | epoch: 026 | loss: 0.14027 - acc: 0.9430 -- iter: 128/151
[A[ATraining Step: 130  | total loss: [1m[32m0.12710[0m[0m | time: 3.976s
[2K
| Adam | epoch: 026 | loss: 0.12710 - acc: 0.9487 | val_loss: 1.11158 - val_acc: 0.6875 -- iter: 151/151
--
Training Step: 131  | total loss: [1m[32m0.11466[0m[0m | time: 0.457s
[2K
| Adam | epoch: 027 | loss: 0.11466 - acc: 0.9539 -- iter: 032/151
[A[ATraining Step: 132  | total loss: [1m[32m0.10382[0m[0m | time: 0.909s
[2K
| Adam | epoch: 027 | loss: 0.10382 - acc: 0.9585 -- iter: 064/151
[A[ATraining Step: 133  | total loss: [1m[32m0.09462[0m[0m | time: 1.527s
[2K
| Adam | epoch: 027 | loss: 0.09462 - acc: 0.9626 -- iter: 096/151
[A[ATraining Step: 134  | total loss: [1m[32m0.10948[0m[0m | time: 2.122s
[2K
| Adam | epoch: 027 | loss: 0.10948 - acc: 0.9601 -- iter: 128/151
[A[ATraining Step: 135  | total loss: [1m[32m0.10493[0m[0m | time: 3.733s
[2K
| Adam | epoch: 027 | loss: 0.10493 - acc: 0.9579 | val_loss: 0.77853 - val_acc: 0.7917 -- iter: 151/151
--
Training Step: 136  | total loss: [1m[32m0.11171[0m[0m | time: 0.609s
[2K
| Adam | epoch: 028 | loss: 0.11171 - acc: 0.9589 -- iter: 032/151
[A[ATraining Step: 137  | total loss: [1m[32m0.10135[0m[0m | time: 1.060s
[2K
| Adam | epoch: 028 | loss: 0.10135 - acc: 0.9631 -- iter: 064/151
[A[ATraining Step: 138  | total loss: [1m[32m0.09216[0m[0m | time: 1.509s
[2K
| Adam | epoch: 028 | loss: 0.09216 - acc: 0.9667 -- iter: 096/151
[A[ATraining Step: 139  | total loss: [1m[32m0.08420[0m[0m | time: 2.111s
[2K
| Adam | epoch: 028 | loss: 0.08420 - acc: 0.9701 -- iter: 128/151
[A[ATraining Step: 140  | total loss: [1m[32m0.07664[0m[0m | time: 3.736s
[2K
| Adam | epoch: 028 | loss: 0.07664 - acc: 0.9731 | val_loss: 0.64402 - val_acc: 0.8125 -- iter: 151/151
--
Training Step: 141  | total loss: [1m[32m0.08767[0m[0m | time: 0.606s
[2K
| Adam | epoch: 029 | loss: 0.08767 - acc: 0.9726 -- iter: 032/151
[A[ATraining Step: 142  | total loss: [1m[32m0.08342[0m[0m | time: 1.209s
[2K
| Adam | epoch: 029 | loss: 0.08342 - acc: 0.9722 -- iter: 064/151
[A[ATraining Step: 143  | total loss: [1m[32m0.07834[0m[0m | time: 1.658s
[2K
| Adam | epoch: 029 | loss: 0.07834 - acc: 0.9750 -- iter: 096/151
[A[ATraining Step: 144  | total loss: [1m[32m0.07276[0m[0m | time: 2.159s
[2K
| Adam | epoch: 029 | loss: 0.07276 - acc: 0.9775 -- iter: 128/151
[A[ATraining Step: 145  | total loss: [1m[32m0.06779[0m[0m | time: 3.764s
[2K
| Adam | epoch: 029 | loss: 0.06779 - acc: 0.9798 | val_loss: 1.00638 - val_acc: 0.6875 -- iter: 151/151
--
Training Step: 146  | total loss: [1m[32m0.06590[0m[0m | time: 0.605s
[2K
| Adam | epoch: 030 | loss: 0.06590 - acc: 0.9787 -- iter: 032/151
[A[ATraining Step: 147  | total loss: [1m[32m0.08246[0m[0m | time: 1.205s
[2K
| Adam | epoch: 030 | loss: 0.08246 - acc: 0.9777 -- iter: 064/151
[A[ATraining Step: 148  | total loss: [1m[32m0.10220[0m[0m | time: 1.819s
[2K
| Adam | epoch: 030 | loss: 0.10220 - acc: 0.9737 -- iter: 096/151
[A[ATraining Step: 149  | total loss: [1m[32m0.09247[0m[0m | time: 2.266s
[2K
| Adam | epoch: 030 | loss: 0.09247 - acc: 0.9763 -- iter: 128/151
[A[ATraining Step: 150  | total loss: [1m[32m0.09990[0m[0m | time: 3.718s
[2K
| Adam | epoch: 030 | loss: 0.09990 - acc: 0.9700 | val_loss: 0.76801 - val_acc: 0.8333 -- iter: 151/151
--
Validation AUC:0.8583916083916084
Validation AUPRC:0.877069663618117
Test AUC:0.9562937062937062
Test AUPRC:0.9402163713408191
BestTestF1Score	0.89	0.79	0.9	0.87	0.91	20	3	23	2	0.43
BestTestMCCScore	0.89	0.79	0.9	0.87	0.91	20	3	23	2	0.43
BestTestAccuracyScore	0.89	0.79	0.9	0.87	0.91	20	3	23	2	0.43
BestValidationF1Score	0.86	0.71	0.85	0.88	0.85	22	3	19	4	0.43
BestValidationMCC	0.86	0.71	0.85	0.88	0.85	22	3	19	4	0.43
BestValidationAccuracy	0.86	0.71	0.85	0.88	0.85	22	3	19	4	0.43
TestPredictions (Threshold:0.43)
CHEMBL411931,TN,INACT,0.0	CHEMBL210208,TN,INACT,0.0	CHEMBL182120,TN,INACT,0.0	CHEMBL1287836,TN,INACT,0.0	CHEMBL3355283,TP,ACT,1.0	CHEMBL3355307,TP,ACT,0.9900000095367432	CHEMBL2087068,TP,ACT,0.6600000262260437	CHEMBL3355284,TP,ACT,1.0	CHEMBL2430160,TN,INACT,0.0	CHEMBL215583,TP,ACT,0.9399999976158142	CHEMBL2087050,FN,ACT,0.25	CHEMBL3298431,TP,ACT,0.550000011920929	CHEMBL2376852,TN,INACT,0.05000000074505806	CHEMBL3593946,TN,INACT,0.009999999776482582	CHEMBL2322555,TN,INACT,0.009999999776482582	CHEMBL476678,TP,ACT,0.9900000095367432	CHEMBL469537,TN,INACT,0.009999999776482582	CHEMBL2322553,TN,INACT,0.1599999964237213	CHEMBL3355297,TP,ACT,0.9900000095367432	CHEMBL2430158,TN,INACT,0.0	CHEMBL2087056,TN,INACT,0.009999999776482582	CHEMBL1369384,FP,INACT,0.7900000214576721	CHEMBL3355303,TP,ACT,1.0	CHEMBL2376845,TN,INACT,0.029999999329447746	CHEMBL2087052,FN,ACT,0.30000001192092896	CHEMBL2430155,TP,ACT,1.0	CHEMBL3355300,TP,ACT,1.0	CHEMBL584211,TN,INACT,0.009999999776482582	CHEMBL184238,TN,INACT,0.029999999329447746	CHEMBL2087074,TN,INACT,0.019999999552965164	CHEMBL2322551,TN,INACT,0.05000000074505806	CHEMBL3787249,TP,ACT,0.9900000095367432	CHEMBL359965,FP,INACT,1.0	CHEMBL2322277,TN,INACT,0.019999999552965164	CHEMBL2387062,TP,ACT,1.0	CHEMBL2312041,TP,ACT,0.949999988079071	CHEMBL2322279,FP,INACT,0.8199999928474426	CHEMBL3355290,TP,ACT,1.0	CHEMBL3786010,TP,ACT,0.6899999976158142	CHEMBL2208211,TN,INACT,0.05000000074505806	CHEMBL3786810,TP,ACT,1.0	CHEMBL3787328,TP,ACT,0.949999988079071	CHEMBL3787010,TP,ACT,1.0	CHEMBL2322252,TN,INACT,0.03999999910593033	CHEMBL2376869,TN,INACT,0.009999999776482582	CHEMBL3786508,TP,ACT,0.5899999737739563	CHEMBL2322273,TN,INACT,0.07000000029802322	CHEMBL2321884,TN,INACT,0.009999999776482582	

