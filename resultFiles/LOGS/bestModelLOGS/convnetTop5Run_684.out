ImageNetInceptionV2 CHEMBL4801 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	288
Number of inactive compounds :	192
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4801_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4801_adam_0.0005_30_0.8/
---------------------------------
Training samples: 307
Validation samples: 96
--
Training Step: 1  | time: 1745.479s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/307
[A[ATraining Step: 2  | total loss: [1m[32m0.59418[0m[0m | time: 1856.944s
[2K
| Adam | epoch: 001 | loss: 0.59418 - acc: 0.5625 -- iter: 064/307
[A[ATraining Step: 3  | total loss: [1m[32m1.02608[0m[0m | time: 1866.660s
[2K
| Adam | epoch: 001 | loss: 1.02608 - acc: 0.5625 -- iter: 096/307
[A[ATraining Step: 4  | total loss: [1m[32m0.78566[0m[0m | time: 1876.898s
[2K
| Adam | epoch: 001 | loss: 0.78566 - acc: 0.6328 -- iter: 128/307
[A[ATraining Step: 5  | total loss: [1m[32m0.73690[0m[0m | time: 1886.550s
[2K
| Adam | epoch: 001 | loss: 0.73690 - acc: 0.5841 -- iter: 160/307
[A[ATraining Step: 6  | total loss: [1m[32m0.64929[0m[0m | time: 1896.630s
[2K
| Adam | epoch: 001 | loss: 0.64929 - acc: 0.6104 -- iter: 192/307
[A[ATraining Step: 7  | total loss: [1m[32m0.57412[0m[0m | time: 1906.217s
[2K
| Adam | epoch: 001 | loss: 0.57412 - acc: 0.6942 -- iter: 224/307
[A[ATraining Step: 8  | total loss: [1m[32m0.53647[0m[0m | time: 1916.416s
[2K
| Adam | epoch: 001 | loss: 0.53647 - acc: 0.7256 -- iter: 256/307
[A[ATraining Step: 9  | total loss: [1m[32m0.67102[0m[0m | time: 1926.967s
[2K
| Adam | epoch: 001 | loss: 0.67102 - acc: 0.5565 -- iter: 288/307
[A[ATraining Step: 10  | total loss: [1m[32m0.68511[0m[0m | time: 1946.421s
[2K
| Adam | epoch: 001 | loss: 0.68511 - acc: 0.5595 | val_loss: 2.04449 - val_acc: 0.4375 -- iter: 307/307
--
Training Step: 11  | total loss: [1m[32m0.72112[0m[0m | time: 6.883s
[2K
| Adam | epoch: 002 | loss: 0.72112 - acc: 0.5438 -- iter: 032/307
[A[ATraining Step: 12  | total loss: [1m[32m0.57324[0m[0m | time: 16.655s
[2K
| Adam | epoch: 002 | loss: 0.57324 - acc: 0.6780 -- iter: 064/307
[A[ATraining Step: 13  | total loss: [1m[32m0.54377[0m[0m | time: 26.448s
[2K
| Adam | epoch: 002 | loss: 0.54377 - acc: 0.7223 -- iter: 096/307
[A[ATraining Step: 14  | total loss: [1m[32m0.47833[0m[0m | time: 36.478s
[2K
| Adam | epoch: 002 | loss: 0.47833 - acc: 0.7592 -- iter: 128/307
[A[ATraining Step: 15  | total loss: [1m[32m0.44456[0m[0m | time: 46.685s
[2K
| Adam | epoch: 002 | loss: 0.44456 - acc: 0.7923 -- iter: 160/307
[A[ATraining Step: 16  | total loss: [1m[32m0.41526[0m[0m | time: 56.895s
[2K
| Adam | epoch: 002 | loss: 0.41526 - acc: 0.8233 -- iter: 192/307
[A[ATraining Step: 17  | total loss: [1m[32m0.44182[0m[0m | time: 66.743s
[2K
| Adam | epoch: 002 | loss: 0.44182 - acc: 0.7857 -- iter: 224/307
[A[ATraining Step: 18  | total loss: [1m[32m0.37588[0m[0m | time: 77.042s
[2K
| Adam | epoch: 002 | loss: 0.37588 - acc: 0.8274 -- iter: 256/307
[A[ATraining Step: 19  | total loss: [1m[32m0.41344[0m[0m | time: 86.703s
[2K
| Adam | epoch: 002 | loss: 0.41344 - acc: 0.8224 -- iter: 288/307
[A[ATraining Step: 20  | total loss: [1m[32m0.41874[0m[0m | time: 102.149s
[2K
| Adam | epoch: 002 | loss: 0.41874 - acc: 0.8192 | val_loss: 1.23402 - val_acc: 0.4375 -- iter: 307/307
--
Training Step: 21  | total loss: [1m[32m0.42237[0m[0m | time: 6.637s
[2K
| Adam | epoch: 003 | loss: 0.42237 - acc: 0.8171 -- iter: 032/307
[A[ATraining Step: 22  | total loss: [1m[32m0.32838[0m[0m | time: 13.231s
[2K
| Adam | epoch: 003 | loss: 0.32838 - acc: 0.8720 -- iter: 064/307
[A[ATraining Step: 23  | total loss: [1m[32m0.25546[0m[0m | time: 23.344s
[2K
| Adam | epoch: 003 | loss: 0.25546 - acc: 0.9092 -- iter: 096/307
[A[ATraining Step: 24  | total loss: [1m[32m0.22201[0m[0m | time: 33.147s
[2K
| Adam | epoch: 003 | loss: 0.22201 - acc: 0.9259 -- iter: 128/307
[A[ATraining Step: 25  | total loss: [1m[32m0.21859[0m[0m | time: 43.127s
[2K
| Adam | epoch: 003 | loss: 0.21859 - acc: 0.9291 -- iter: 160/307
[A[ATraining Step: 26  | total loss: [1m[32m0.23660[0m[0m | time: 52.934s
[2K
| Adam | epoch: 003 | loss: 0.23660 - acc: 0.9148 -- iter: 192/307
[A[ATraining Step: 27  | total loss: [1m[32m0.20960[0m[0m | time: 62.926s
[2K
| Adam | epoch: 003 | loss: 0.20960 - acc: 0.9286 -- iter: 224/307
[A[ATraining Step: 28  | total loss: [1m[32m0.17480[0m[0m | time: 73.144s
[2K
| Adam | epoch: 003 | loss: 0.17480 - acc: 0.9465 -- iter: 256/307
[A[ATraining Step: 29  | total loss: [1m[32m0.20383[0m[0m | time: 83.079s
[2K
| Adam | epoch: 003 | loss: 0.20383 - acc: 0.9215 -- iter: 288/307
[A[ATraining Step: 30  | total loss: [1m[32m0.28903[0m[0m | time: 98.639s
[2K
| Adam | epoch: 003 | loss: 0.28903 - acc: 0.8957 | val_loss: 3.93643 - val_acc: 0.4375 -- iter: 307/307
--
Training Step: 31  | total loss: [1m[32m0.23702[0m[0m | time: 10.016s
[2K
| Adam | epoch: 004 | loss: 0.23702 - acc: 0.9198 -- iter: 032/307
[A[ATraining Step: 32  | total loss: [1m[32m0.20452[0m[0m | time: 16.431s
[2K
| Adam | epoch: 004 | loss: 0.20452 - acc: 0.9308 -- iter: 064/307
[A[ATraining Step: 33  | total loss: [1m[32m0.22654[0m[0m | time: 23.355s
[2K
| Adam | epoch: 004 | loss: 0.22654 - acc: 0.9229 -- iter: 096/307
[A[ATraining Step: 34  | total loss: [1m[32m0.26269[0m[0m | time: 33.130s
[2K
| Adam | epoch: 004 | loss: 0.26269 - acc: 0.9281 -- iter: 128/307
[A[ATraining Step: 35  | total loss: [1m[32m0.22929[0m[0m | time: 43.110s
[2K
| Adam | epoch: 004 | loss: 0.22929 - acc: 0.9366 -- iter: 160/307
[A[ATraining Step: 36  | total loss: [1m[32m0.20731[0m[0m | time: 52.637s
[2K
| Adam | epoch: 004 | loss: 0.20731 - acc: 0.9368 -- iter: 192/307
[A[ATraining Step: 37  | total loss: [1m[32m0.18292[0m[0m | time: 62.341s
[2K
| Adam | epoch: 004 | loss: 0.18292 - acc: 0.9432 -- iter: 224/307
[A[ATraining Step: 38  | total loss: [1m[32m0.16427[0m[0m | time: 72.281s
[2K
| Adam | epoch: 004 | loss: 0.16427 - acc: 0.9482 -- iter: 256/307
[A[ATraining Step: 39  | total loss: [1m[32m0.17637[0m[0m | time: 81.773s
[2K
| Adam | epoch: 004 | loss: 0.17637 - acc: 0.9461 -- iter: 288/307
[A[ATraining Step: 40  | total loss: [1m[32m0.17700[0m[0m | time: 96.980s
[2K
| Adam | epoch: 004 | loss: 0.17700 - acc: 0.9445 | val_loss: 5.05787 - val_acc: 0.4375 -- iter: 307/307
--
Training Step: 41  | total loss: [1m[32m0.18637[0m[0m | time: 9.781s
[2K
| Adam | epoch: 005 | loss: 0.18637 - acc: 0.9432 -- iter: 032/307
[A[ATraining Step: 42  | total loss: [1m[32m0.18048[0m[0m | time: 19.536s
[2K
| Adam | epoch: 005 | loss: 0.18048 - acc: 0.9366 -- iter: 064/307
[A[ATraining Step: 43  | total loss: [1m[32m0.23332[0m[0m | time: 26.237s
[2K
| Adam | epoch: 005 | loss: 0.23332 - acc: 0.9147 -- iter: 096/307
[A[ATraining Step: 44  | total loss: [1m[32m0.19730[0m[0m | time: 32.819s
[2K
| Adam | epoch: 005 | loss: 0.19730 - acc: 0.9294 -- iter: 128/307
[A[ATraining Step: 45  | total loss: [1m[32m0.18056[0m[0m | time: 42.594s
[2K
| Adam | epoch: 005 | loss: 0.18056 - acc: 0.9325 -- iter: 160/307
[A[ATraining Step: 46  | total loss: [1m[32m0.15754[0m[0m | time: 52.499s
[2K
| Adam | epoch: 005 | loss: 0.15754 - acc: 0.9385 -- iter: 192/307
[A[ATraining Step: 47  | total loss: [1m[32m0.14291[0m[0m | time: 62.154s
[2K
| Adam | epoch: 005 | loss: 0.14291 - acc: 0.9486 -- iter: 224/307
[A[ATraining Step: 48  | total loss: [1m[32m0.12831[0m[0m | time: 71.883s
[2K
| Adam | epoch: 005 | loss: 0.12831 - acc: 0.9569 -- iter: 256/307
[A[ATraining Step: 49  | total loss: [1m[32m0.11239[0m[0m | time: 81.905s
[2K
| Adam | epoch: 005 | loss: 0.11239 - acc: 0.9637 -- iter: 288/307
[A[ATraining Step: 50  | total loss: [1m[32m0.11804[0m[0m | time: 95.880s
[2K
| Adam | epoch: 005 | loss: 0.11804 - acc: 0.9596 | val_loss: 2.72015 - val_acc: 0.4375 -- iter: 307/307
--
Training Step: 51  | total loss: [1m[32m0.10335[0m[0m | time: 8.043s
[2K
| Adam | epoch: 006 | loss: 0.10335 - acc: 0.9658 -- iter: 032/307
[A[ATraining Step: 52  | total loss: [1m[32m0.09979[0m[0m | time: 16.046s
[2K
| Adam | epoch: 006 | loss: 0.09979 - acc: 0.9615 -- iter: 064/307
[A[ATraining Step: 53  | total loss: [1m[32m0.08779[0m[0m | time: 24.151s
[2K
| Adam | epoch: 006 | loss: 0.08779 - acc: 0.9672 -- iter: 096/307
[A[ATraining Step: 54  | total loss: [1m[32m0.14252[0m[0m | time: 29.380s
[2K
| Adam | epoch: 006 | loss: 0.14252 - acc: 0.9584 -- iter: 128/307
[A[ATraining Step: 55  | total loss: [1m[32m0.12728[0m[0m | time: 34.677s
[2K
| Adam | epoch: 006 | loss: 0.12728 - acc: 0.9643 -- iter: 160/307
[A[ATraining Step: 56  | total loss: [1m[32m0.17883[0m[0m | time: 42.755s
[2K
| Adam | epoch: 006 | loss: 0.17883 - acc: 0.9471 -- iter: 192/307
[A[ATraining Step: 57  | total loss: [1m[32m0.18227[0m[0m | time: 50.699s
[2K
| Adam | epoch: 006 | loss: 0.18227 - acc: 0.9415 -- iter: 224/307
[A[ATraining Step: 58  | total loss: [1m[32m0.16087[0m[0m | time: 58.677s
[2K
| Adam | epoch: 006 | loss: 0.16087 - acc: 0.9494 -- iter: 256/307
[A[ATraining Step: 59  | total loss: [1m[32m0.17029[0m[0m | time: 66.614s
[2K
| Adam | epoch: 006 | loss: 0.17029 - acc: 0.9436 -- iter: 288/307
[A[ATraining Step: 60  | total loss: [1m[32m0.19382[0m[0m | time: 79.058s
[2K
| Adam | epoch: 006 | loss: 0.19382 - acc: 0.9387 | val_loss: 2.55011 - val_acc: 0.5833 -- iter: 307/307
--
Training Step: 61  | total loss: [1m[32m0.17344[0m[0m | time: 8.064s
[2K
| Adam | epoch: 007 | loss: 0.17344 - acc: 0.9467 -- iter: 032/307
[A[ATraining Step: 62  | total loss: [1m[32m0.16053[0m[0m | time: 16.051s
[2K
| Adam | epoch: 007 | loss: 0.16053 - acc: 0.9495 -- iter: 064/307
[A[ATraining Step: 63  | total loss: [1m[32m0.18024[0m[0m | time: 24.303s
[2K
| Adam | epoch: 007 | loss: 0.18024 - acc: 0.9480 -- iter: 096/307
[A[ATraining Step: 64  | total loss: [1m[32m0.16519[0m[0m | time: 32.354s
[2K
| Adam | epoch: 007 | loss: 0.16519 - acc: 0.9545 -- iter: 128/307
[A[ATraining Step: 65  | total loss: [1m[32m0.14876[0m[0m | time: 37.700s
[2K
| Adam | epoch: 007 | loss: 0.14876 - acc: 0.9601 -- iter: 160/307
[A[ATraining Step: 66  | total loss: [1m[32m0.13187[0m[0m | time: 42.944s
[2K
| Adam | epoch: 007 | loss: 0.13187 - acc: 0.9650 -- iter: 192/307
[A[ATraining Step: 67  | total loss: [1m[32m0.17799[0m[0m | time: 51.055s
[2K
| Adam | epoch: 007 | loss: 0.17799 - acc: 0.9565 -- iter: 224/307
[A[ATraining Step: 68  | total loss: [1m[32m0.16475[0m[0m | time: 59.104s
[2K
| Adam | epoch: 007 | loss: 0.16475 - acc: 0.9617 -- iter: 256/307
[A[ATraining Step: 69  | total loss: [1m[32m0.14907[0m[0m | time: 67.120s
[2K
| Adam | epoch: 007 | loss: 0.14907 - acc: 0.9662 -- iter: 288/307
[A[ATraining Step: 70  | total loss: [1m[32m0.14700[0m[0m | time: 79.404s
[2K
| Adam | epoch: 007 | loss: 0.14700 - acc: 0.9629 | val_loss: 1.19089 - val_acc: 0.6354 -- iter: 307/307
--
Training Step: 71  | total loss: [1m[32m0.16390[0m[0m | time: 7.919s
[2K
| Adam | epoch: 008 | loss: 0.16390 - acc: 0.9564 -- iter: 032/307
[A[ATraining Step: 72  | total loss: [1m[32m0.19067[0m[0m | time: 15.903s
[2K
| Adam | epoch: 008 | loss: 0.19067 - acc: 0.9508 -- iter: 064/307
[A[ATraining Step: 73  | total loss: [1m[32m0.19721[0m[0m | time: 23.984s
[2K
| Adam | epoch: 008 | loss: 0.19721 - acc: 0.9354 -- iter: 096/307
[A[ATraining Step: 74  | total loss: [1m[32m0.18092[0m[0m | time: 32.063s
[2K
| Adam | epoch: 008 | loss: 0.18092 - acc: 0.9425 -- iter: 128/307
[A[ATraining Step: 75  | total loss: [1m[32m0.17929[0m[0m | time: 40.049s
[2K
| Adam | epoch: 008 | loss: 0.17929 - acc: 0.9453 -- iter: 160/307
[A[ATraining Step: 76  | total loss: [1m[32m0.16527[0m[0m | time: 45.456s
[2K
| Adam | epoch: 008 | loss: 0.16527 - acc: 0.9512 -- iter: 192/307
[A[ATraining Step: 77  | total loss: [1m[32m0.16367[0m[0m | time: 50.703s
[2K
| Adam | epoch: 008 | loss: 0.16367 - acc: 0.9508 -- iter: 224/307
[A[ATraining Step: 78  | total loss: [1m[32m0.15525[0m[0m | time: 58.741s
[2K
| Adam | epoch: 008 | loss: 0.15525 - acc: 0.9504 -- iter: 256/307
[A[ATraining Step: 79  | total loss: [1m[32m0.14620[0m[0m | time: 66.814s
[2K
| Adam | epoch: 008 | loss: 0.14620 - acc: 0.9523 -- iter: 288/307
[A[ATraining Step: 80  | total loss: [1m[32m0.13327[0m[0m | time: 78.992s
[2K
| Adam | epoch: 008 | loss: 0.13327 - acc: 0.9572 | val_loss: 1.22441 - val_acc: 0.6250 -- iter: 307/307
--
Training Step: 81  | total loss: [1m[32m0.13194[0m[0m | time: 8.227s
[2K
| Adam | epoch: 009 | loss: 0.13194 - acc: 0.9552 -- iter: 032/307
[A[ATraining Step: 82  | total loss: [1m[32m0.12065[0m[0m | time: 16.183s
[2K
| Adam | epoch: 009 | loss: 0.12065 - acc: 0.9597 -- iter: 064/307
[A[ATraining Step: 83  | total loss: [1m[32m0.12245[0m[0m | time: 24.122s
[2K
| Adam | epoch: 009 | loss: 0.12245 - acc: 0.9575 -- iter: 096/307
[A[ATraining Step: 84  | total loss: [1m[32m0.11644[0m[0m | time: 32.305s
[2K
| Adam | epoch: 009 | loss: 0.11644 - acc: 0.9586 -- iter: 128/307
[A[ATraining Step: 85  | total loss: [1m[32m0.10753[0m[0m | time: 40.245s
[2K
| Adam | epoch: 009 | loss: 0.10753 - acc: 0.9627 -- iter: 160/307
[A[ATraining Step: 86  | total loss: [1m[32m0.10796[0m[0m | time: 48.554s
[2K
| Adam | epoch: 009 | loss: 0.10796 - acc: 0.9633 -- iter: 192/307
[A[ATraining Step: 87  | total loss: [1m[32m0.13419[0m[0m | time: 53.898s
[2K
| Adam | epoch: 009 | loss: 0.13419 - acc: 0.9545 -- iter: 224/307
[A[ATraining Step: 88  | total loss: [1m[32m0.14249[0m[0m | time: 59.193s
[2K
| Adam | epoch: 009 | loss: 0.14249 - acc: 0.9538 -- iter: 256/307
[A[ATraining Step: 89  | total loss: [1m[32m0.18296[0m[0m | time: 67.133s
[2K
| Adam | epoch: 009 | loss: 0.18296 - acc: 0.9531 -- iter: 288/307
[A[ATraining Step: 90  | total loss: [1m[32m0.17427[0m[0m | time: 79.741s
[2K
| Adam | epoch: 009 | loss: 0.17427 - acc: 0.9547 | val_loss: 1.33581 - val_acc: 0.6562 -- iter: 307/307
--
Training Step: 91  | total loss: [1m[32m0.15882[0m[0m | time: 8.031s
[2K
| Adam | epoch: 010 | loss: 0.15882 - acc: 0.9592 -- iter: 032/307
[A[ATraining Step: 92  | total loss: [1m[32m0.14626[0m[0m | time: 16.056s
[2K
| Adam | epoch: 010 | loss: 0.14626 - acc: 0.9633 -- iter: 064/307
[A[ATraining Step: 93  | total loss: [1m[32m0.13334[0m[0m | time: 24.143s
[2K
| Adam | epoch: 010 | loss: 0.13334 - acc: 0.9670 -- iter: 096/307
[A[ATraining Step: 94  | total loss: [1m[32m0.12780[0m[0m | time: 32.143s
[2K
| Adam | epoch: 010 | loss: 0.12780 - acc: 0.9672 -- iter: 128/307
[A[ATraining Step: 95  | total loss: [1m[32m0.11960[0m[0m | time: 40.120s
[2K
| Adam | epoch: 010 | loss: 0.11960 - acc: 0.9673 -- iter: 160/307
[A[ATraining Step: 96  | total loss: [1m[32m0.11213[0m[0m | time: 48.219s
[2K
| Adam | epoch: 010 | loss: 0.11213 - acc: 0.9706 -- iter: 192/307
[A[ATraining Step: 97  | total loss: [1m[32m0.11081[0m[0m | time: 56.264s
[2K
| Adam | epoch: 010 | loss: 0.11081 - acc: 0.9673 -- iter: 224/307
[A[ATraining Step: 98  | total loss: [1m[32m0.10203[0m[0m | time: 61.623s
[2K
| Adam | epoch: 010 | loss: 0.10203 - acc: 0.9706 -- iter: 256/307
[A[ATraining Step: 99  | total loss: [1m[32m0.09259[0m[0m | time: 67.078s
[2K
| Adam | epoch: 010 | loss: 0.09259 - acc: 0.9735 -- iter: 288/307
[A[ATraining Step: 100  | total loss: [1m[32m0.12644[0m[0m | time: 79.375s
[2K
| Adam | epoch: 010 | loss: 0.12644 - acc: 0.9656 | val_loss: 0.67837 - val_acc: 0.8021 -- iter: 307/307
--
Training Step: 101  | total loss: [1m[32m0.11515[0m[0m | time: 7.767s
[2K
| Adam | epoch: 011 | loss: 0.11515 - acc: 0.9691 -- iter: 032/307
[A[ATraining Step: 102  | total loss: [1m[32m0.10776[0m[0m | time: 15.860s
[2K
| Adam | epoch: 011 | loss: 0.10776 - acc: 0.9690 -- iter: 064/307
[A[ATraining Step: 103  | total loss: [1m[32m0.10524[0m[0m | time: 23.891s
[2K
| Adam | epoch: 011 | loss: 0.10524 - acc: 0.9690 -- iter: 096/307
[A[ATraining Step: 104  | total loss: [1m[32m0.09956[0m[0m | time: 31.992s
[2K
| Adam | epoch: 011 | loss: 0.09956 - acc: 0.9721 -- iter: 128/307
[A[ATraining Step: 105  | total loss: [1m[32m0.09811[0m[0m | time: 39.833s
[2K
| Adam | epoch: 011 | loss: 0.09811 - acc: 0.9686 -- iter: 160/307
[A[ATraining Step: 106  | total loss: [1m[32m0.09698[0m[0m | time: 47.909s
[2K
| Adam | epoch: 011 | loss: 0.09698 - acc: 0.9687 -- iter: 192/307
[A[ATraining Step: 107  | total loss: [1m[32m0.11238[0m[0m | time: 56.021s
[2K
| Adam | epoch: 011 | loss: 0.11238 - acc: 0.9687 -- iter: 224/307
[A[ATraining Step: 108  | total loss: [1m[32m0.10208[0m[0m | time: 63.957s
[2K
| Adam | epoch: 011 | loss: 0.10208 - acc: 0.9718 -- iter: 256/307
[A[ATraining Step: 109  | total loss: [1m[32m0.09649[0m[0m | time: 69.194s
[2K
| Adam | epoch: 011 | loss: 0.09649 - acc: 0.9746 -- iter: 288/307
[A[ATraining Step: 110  | total loss: [1m[32m0.08876[0m[0m | time: 78.837s
[2K
| Adam | epoch: 011 | loss: 0.08876 - acc: 0.9772 | val_loss: 3.21973 - val_acc: 0.5729 -- iter: 307/307
--
Training Step: 111  | total loss: [1m[32m0.10083[0m[0m | time: 7.834s
[2K
| Adam | epoch: 012 | loss: 0.10083 - acc: 0.9742 -- iter: 032/307
[A[ATraining Step: 112  | total loss: [1m[32m0.09163[0m[0m | time: 15.855s
[2K
| Adam | epoch: 012 | loss: 0.09163 - acc: 0.9768 -- iter: 064/307
[A[ATraining Step: 113  | total loss: [1m[32m0.09149[0m[0m | time: 23.745s
[2K
| Adam | epoch: 012 | loss: 0.09149 - acc: 0.9760 -- iter: 096/307
[A[ATraining Step: 114  | total loss: [1m[32m0.08665[0m[0m | time: 31.606s
[2K
| Adam | epoch: 012 | loss: 0.08665 - acc: 0.9752 -- iter: 128/307
[A[ATraining Step: 115  | total loss: [1m[32m0.08892[0m[0m | time: 39.508s
[2K
| Adam | epoch: 012 | loss: 0.08892 - acc: 0.9746 -- iter: 160/307
[A[ATraining Step: 116  | total loss: [1m[32m0.08122[0m[0m | time: 47.464s
[2K
| Adam | epoch: 012 | loss: 0.08122 - acc: 0.9771 -- iter: 192/307
[A[ATraining Step: 117  | total loss: [1m[32m0.07657[0m[0m | time: 55.315s
[2K
| Adam | epoch: 012 | loss: 0.07657 - acc: 0.9794 -- iter: 224/307
[A[ATraining Step: 118  | total loss: [1m[32m0.07695[0m[0m | time: 63.301s
[2K
| Adam | epoch: 012 | loss: 0.07695 - acc: 0.9783 -- iter: 256/307
[A[ATraining Step: 119  | total loss: [1m[32m0.07992[0m[0m | time: 71.297s
[2K
| Adam | epoch: 012 | loss: 0.07992 - acc: 0.9774 -- iter: 288/307
[A[ATraining Step: 120  | total loss: [1m[32m0.09766[0m[0m | time: 80.831s
[2K
| Adam | epoch: 012 | loss: 0.09766 - acc: 0.9734 | val_loss: 2.12682 - val_acc: 0.5521 -- iter: 307/307
--
Training Step: 121  | total loss: [1m[32m0.08830[0m[0m | time: 5.269s
[2K
| Adam | epoch: 013 | loss: 0.08830 - acc: 0.9761 -- iter: 032/307
[A[ATraining Step: 122  | total loss: [1m[32m0.08023[0m[0m | time: 13.307s
[2K
| Adam | epoch: 013 | loss: 0.08023 - acc: 0.9785 -- iter: 064/307
[A[ATraining Step: 123  | total loss: [1m[32m0.07861[0m[0m | time: 21.203s
[2K
| Adam | epoch: 013 | loss: 0.07861 - acc: 0.9806 -- iter: 096/307
[A[ATraining Step: 124  | total loss: [1m[32m0.08472[0m[0m | time: 29.214s
[2K
| Adam | epoch: 013 | loss: 0.08472 - acc: 0.9763 -- iter: 128/307
[A[ATraining Step: 125  | total loss: [1m[32m0.07922[0m[0m | time: 37.293s
[2K
| Adam | epoch: 013 | loss: 0.07922 - acc: 0.9787 -- iter: 160/307
[A[ATraining Step: 126  | total loss: [1m[32m0.08597[0m[0m | time: 45.445s
[2K
| Adam | epoch: 013 | loss: 0.08597 - acc: 0.9777 -- iter: 192/307
[A[ATraining Step: 127  | total loss: [1m[32m0.07925[0m[0m | time: 53.479s
[2K
| Adam | epoch: 013 | loss: 0.07925 - acc: 0.9799 -- iter: 224/307
[A[ATraining Step: 128  | total loss: [1m[32m0.07342[0m[0m | time: 61.473s
[2K
| Adam | epoch: 013 | loss: 0.07342 - acc: 0.9819 -- iter: 256/307
[A[ATraining Step: 129  | total loss: [1m[32m0.07445[0m[0m | time: 69.589s
[2K
| Adam | epoch: 013 | loss: 0.07445 - acc: 0.9806 -- iter: 288/307
[A[ATraining Step: 130  | total loss: [1m[32m0.06871[0m[0m | time: 81.782s
[2K
| Adam | epoch: 013 | loss: 0.06871 - acc: 0.9825 | val_loss: 0.97469 - val_acc: 0.6979 -- iter: 307/307
--
Training Step: 131  | total loss: [1m[32m0.06288[0m[0m | time: 5.259s
[2K
| Adam | epoch: 014 | loss: 0.06288 - acc: 0.9843 -- iter: 032/307
[A[ATraining Step: 132  | total loss: [1m[32m0.05832[0m[0m | time: 10.558s
[2K
| Adam | epoch: 014 | loss: 0.05832 - acc: 0.9859 -- iter: 064/307
[A[ATraining Step: 133  | total loss: [1m[32m0.13781[0m[0m | time: 18.432s
[2K
| Adam | epoch: 014 | loss: 0.13781 - acc: 0.9767 -- iter: 096/307
[A[ATraining Step: 134  | total loss: [1m[32m0.12642[0m[0m | time: 26.259s
[2K
| Adam | epoch: 014 | loss: 0.12642 - acc: 0.9791 -- iter: 128/307
[A[ATraining Step: 135  | total loss: [1m[32m0.11638[0m[0m | time: 34.170s
[2K
| Adam | epoch: 014 | loss: 0.11638 - acc: 0.9812 -- iter: 160/307
[A[ATraining Step: 136  | total loss: [1m[32m0.11212[0m[0m | time: 42.020s
[2K
| Adam | epoch: 014 | loss: 0.11212 - acc: 0.9799 -- iter: 192/307
[A[ATraining Step: 137  | total loss: [1m[32m0.10962[0m[0m | time: 50.068s
[2K
| Adam | epoch: 014 | loss: 0.10962 - acc: 0.9757 -- iter: 224/307
[A[ATraining Step: 138  | total loss: [1m[32m0.10628[0m[0m | time: 57.808s
[2K
| Adam | epoch: 014 | loss: 0.10628 - acc: 0.9750 -- iter: 256/307
[A[ATraining Step: 139  | total loss: [1m[32m0.09807[0m[0m | time: 65.769s
[2K
| Adam | epoch: 014 | loss: 0.09807 - acc: 0.9775 -- iter: 288/307
[A[ATraining Step: 140  | total loss: [1m[32m0.10776[0m[0m | time: 78.114s
[2K
| Adam | epoch: 014 | loss: 0.10776 - acc: 0.9735 | val_loss: 4.09818 - val_acc: 0.5625 -- iter: 307/307
--
Training Step: 141  | total loss: [1m[32m0.09780[0m[0m | time: 8.034s
[2K
| Adam | epoch: 015 | loss: 0.09780 - acc: 0.9761 -- iter: 032/307
[A[ATraining Step: 142  | total loss: [1m[32m0.09244[0m[0m | time: 13.315s
[2K
| Adam | epoch: 015 | loss: 0.09244 - acc: 0.9785 -- iter: 064/307
[A[ATraining Step: 143  | total loss: [1m[32m0.10401[0m[0m | time: 18.613s
[2K
| Adam | epoch: 015 | loss: 0.10401 - acc: 0.9754 -- iter: 096/307
[A[ATraining Step: 144  | total loss: [1m[32m0.10575[0m[0m | time: 26.610s
[2K
| Adam | epoch: 015 | loss: 0.10575 - acc: 0.9726 -- iter: 128/307
[A[ATraining Step: 145  | total loss: [1m[32m0.09709[0m[0m | time: 34.628s
[2K
| Adam | epoch: 015 | loss: 0.09709 - acc: 0.9753 -- iter: 160/307
[A[ATraining Step: 146  | total loss: [1m[32m0.09174[0m[0m | time: 42.564s
[2K
| Adam | epoch: 015 | loss: 0.09174 - acc: 0.9778 -- iter: 192/307
[A[ATraining Step: 147  | total loss: [1m[32m0.09043[0m[0m | time: 50.559s
[2K
| Adam | epoch: 015 | loss: 0.09043 - acc: 0.9769 -- iter: 224/307
[A[ATraining Step: 148  | total loss: [1m[32m0.08364[0m[0m | time: 58.762s
[2K
| Adam | epoch: 015 | loss: 0.08364 - acc: 0.9792 -- iter: 256/307
[A[ATraining Step: 149  | total loss: [1m[32m0.08256[0m[0m | time: 66.690s
[2K
| Adam | epoch: 015 | loss: 0.08256 - acc: 0.9750 -- iter: 288/307
[A[ATraining Step: 150  | total loss: [1m[32m0.08610[0m[0m | time: 79.042s
[2K
| Adam | epoch: 015 | loss: 0.08610 - acc: 0.9682 | val_loss: 0.67292 - val_acc: 0.7292 -- iter: 307/307
--
Training Step: 151  | total loss: [1m[32m0.07969[0m[0m | time: 8.000s
[2K
| Adam | epoch: 016 | loss: 0.07969 - acc: 0.9713 -- iter: 032/307
[A[ATraining Step: 152  | total loss: [1m[32m0.08496[0m[0m | time: 15.935s
[2K
| Adam | epoch: 016 | loss: 0.08496 - acc: 0.9711 -- iter: 064/307
[A[ATraining Step: 153  | total loss: [1m[32m0.08858[0m[0m | time: 21.444s
[2K
| Adam | epoch: 016 | loss: 0.08858 - acc: 0.9709 -- iter: 096/307
[A[ATraining Step: 154  | total loss: [1m[32m0.09367[0m[0m | time: 26.682s
[2K
| Adam | epoch: 016 | loss: 0.09367 - acc: 0.9632 -- iter: 128/307
[A[ATraining Step: 155  | total loss: [1m[32m0.08706[0m[0m | time: 34.488s
[2K
| Adam | epoch: 016 | loss: 0.08706 - acc: 0.9669 -- iter: 160/307
[A[ATraining Step: 156  | total loss: [1m[32m0.07993[0m[0m | time: 42.396s
[2K
| Adam | epoch: 016 | loss: 0.07993 - acc: 0.9702 -- iter: 192/307
[A[ATraining Step: 157  | total loss: [1m[32m0.07288[0m[0m | time: 50.336s
[2K
| Adam | epoch: 016 | loss: 0.07288 - acc: 0.9732 -- iter: 224/307
[A[ATraining Step: 158  | total loss: [1m[32m0.07673[0m[0m | time: 58.273s
[2K
| Adam | epoch: 016 | loss: 0.07673 - acc: 0.9728 -- iter: 256/307
[A[ATraining Step: 159  | total loss: [1m[32m0.06970[0m[0m | time: 66.110s
[2K
| Adam | epoch: 016 | loss: 0.06970 - acc: 0.9755 -- iter: 288/307
[A[ATraining Step: 160  | total loss: [1m[32m0.06949[0m[0m | time: 78.496s
[2K
| Adam | epoch: 016 | loss: 0.06949 - acc: 0.9779 | val_loss: 0.79366 - val_acc: 0.7708 -- iter: 307/307
--
Training Step: 161  | total loss: [1m[32m0.06550[0m[0m | time: 8.030s
[2K
| Adam | epoch: 017 | loss: 0.06550 - acc: 0.9801 -- iter: 032/307
[A[ATraining Step: 162  | total loss: [1m[32m0.06899[0m[0m | time: 15.874s
[2K
| Adam | epoch: 017 | loss: 0.06899 - acc: 0.9759 -- iter: 064/307
[A[ATraining Step: 163  | total loss: [1m[32m0.06987[0m[0m | time: 23.926s
[2K
| Adam | epoch: 017 | loss: 0.06987 - acc: 0.9752 -- iter: 096/307
[A[ATraining Step: 164  | total loss: [1m[32m0.07230[0m[0m | time: 29.160s
[2K
| Adam | epoch: 017 | loss: 0.07230 - acc: 0.9745 -- iter: 128/307
[A[ATraining Step: 165  | total loss: [1m[32m0.06556[0m[0m | time: 34.388s
[2K
| Adam | epoch: 017 | loss: 0.06556 - acc: 0.9771 -- iter: 160/307
[A[ATraining Step: 166  | total loss: [1m[32m0.06458[0m[0m | time: 42.452s
[2K
| Adam | epoch: 017 | loss: 0.06458 - acc: 0.9741 -- iter: 192/307
[A[ATraining Step: 167  | total loss: [1m[32m0.06475[0m[0m | time: 50.524s
[2K
| Adam | epoch: 017 | loss: 0.06475 - acc: 0.9736 -- iter: 224/307
[A[ATraining Step: 168  | total loss: [1m[32m0.06015[0m[0m | time: 58.371s
[2K
| Adam | epoch: 017 | loss: 0.06015 - acc: 0.9762 -- iter: 256/307
[A[ATraining Step: 169  | total loss: [1m[32m0.05471[0m[0m | time: 66.221s
[2K
| Adam | epoch: 017 | loss: 0.05471 - acc: 0.9786 -- iter: 288/307
[A[ATraining Step: 170  | total loss: [1m[32m0.05015[0m[0m | time: 78.523s
[2K
| Adam | epoch: 017 | loss: 0.05015 - acc: 0.9807 | val_loss: 0.83804 - val_acc: 0.7708 -- iter: 307/307
--
Training Step: 171  | total loss: [1m[32m0.05068[0m[0m | time: 8.098s
[2K
| Adam | epoch: 018 | loss: 0.05068 - acc: 0.9795 -- iter: 032/307
[A[ATraining Step: 172  | total loss: [1m[32m0.04821[0m[0m | time: 16.007s
[2K
| Adam | epoch: 018 | loss: 0.04821 - acc: 0.9816 -- iter: 064/307
[A[ATraining Step: 173  | total loss: [1m[32m0.05774[0m[0m | time: 24.124s
[2K
| Adam | epoch: 018 | loss: 0.05774 - acc: 0.9803 -- iter: 096/307
[A[ATraining Step: 174  | total loss: [1m[32m0.05351[0m[0m | time: 32.467s
[2K
| Adam | epoch: 018 | loss: 0.05351 - acc: 0.9823 -- iter: 128/307
[A[ATraining Step: 175  | total loss: [1m[32m0.04862[0m[0m | time: 37.917s
[2K
| Adam | epoch: 018 | loss: 0.04862 - acc: 0.9840 -- iter: 160/307
[A[ATraining Step: 176  | total loss: [1m[32m0.04410[0m[0m | time: 43.245s
[2K
| Adam | epoch: 018 | loss: 0.04410 - acc: 0.9856 -- iter: 192/307
[A[ATraining Step: 177  | total loss: [1m[32m0.08562[0m[0m | time: 51.254s
[2K
| Adam | epoch: 018 | loss: 0.08562 - acc: 0.9818 -- iter: 224/307
[A[ATraining Step: 178  | total loss: [1m[32m0.07795[0m[0m | time: 59.257s
[2K
| Adam | epoch: 018 | loss: 0.07795 - acc: 0.9836 -- iter: 256/307
[A[ATraining Step: 179  | total loss: [1m[32m0.07236[0m[0m | time: 67.404s
[2K
| Adam | epoch: 018 | loss: 0.07236 - acc: 0.9853 -- iter: 288/307
[A[ATraining Step: 180  | total loss: [1m[32m0.06741[0m[0m | time: 79.688s
[2K
| Adam | epoch: 018 | loss: 0.06741 - acc: 0.9867 | val_loss: 1.64567 - val_acc: 0.6250 -- iter: 307/307
--
Training Step: 181  | total loss: [1m[32m0.06095[0m[0m | time: 7.981s
[2K
| Adam | epoch: 019 | loss: 0.06095 - acc: 0.9881 -- iter: 032/307
[A[ATraining Step: 182  | total loss: [1m[32m0.07687[0m[0m | time: 15.815s
[2K
| Adam | epoch: 019 | loss: 0.07687 - acc: 0.9830 -- iter: 064/307
[A[ATraining Step: 183  | total loss: [1m[32m0.08491[0m[0m | time: 23.646s
[2K
| Adam | epoch: 019 | loss: 0.08491 - acc: 0.9816 -- iter: 096/307
[A[ATraining Step: 184  | total loss: [1m[32m0.07720[0m[0m | time: 31.706s
[2K
| Adam | epoch: 019 | loss: 0.07720 - acc: 0.9834 -- iter: 128/307
[A[ATraining Step: 185  | total loss: [1m[32m0.06980[0m[0m | time: 40.066s
[2K
| Adam | epoch: 019 | loss: 0.06980 - acc: 0.9851 -- iter: 160/307
[A[ATraining Step: 186  | total loss: [1m[32m0.06925[0m[0m | time: 45.325s
[2K
| Adam | epoch: 019 | loss: 0.06925 - acc: 0.9834 -- iter: 192/307
[A[ATraining Step: 187  | total loss: [1m[32m0.11791[0m[0m | time: 50.573s
[2K
| Adam | epoch: 019 | loss: 0.11791 - acc: 0.9798 -- iter: 224/307
[A[ATraining Step: 188  | total loss: [1m[32m0.21381[0m[0m | time: 58.499s
[2K
| Adam | epoch: 019 | loss: 0.21381 - acc: 0.9713 -- iter: 256/307
[A[ATraining Step: 189  | total loss: [1m[32m0.19522[0m[0m | time: 66.669s
[2K
| Adam | epoch: 019 | loss: 0.19522 - acc: 0.9742 -- iter: 288/307
[A[ATraining Step: 190  | total loss: [1m[32m0.18076[0m[0m | time: 79.297s
[2K
| Adam | epoch: 019 | loss: 0.18076 - acc: 0.9737 | val_loss: 2.76219 - val_acc: 0.5729 -- iter: 307/307
--
Training Step: 191  | total loss: [1m[32m0.18936[0m[0m | time: 7.988s
[2K
| Adam | epoch: 020 | loss: 0.18936 - acc: 0.9638 -- iter: 032/307
[A[ATraining Step: 192  | total loss: [1m[32m0.17207[0m[0m | time: 16.038s
[2K
| Adam | epoch: 020 | loss: 0.17207 - acc: 0.9674 -- iter: 064/307
[A[ATraining Step: 193  | total loss: [1m[32m0.16609[0m[0m | time: 23.953s
[2K
| Adam | epoch: 020 | loss: 0.16609 - acc: 0.9675 -- iter: 096/307
[A[ATraining Step: 194  | total loss: [1m[32m0.15209[0m[0m | time: 32.129s
[2K
| Adam | epoch: 020 | loss: 0.15209 - acc: 0.9708 -- iter: 128/307
[A[ATraining Step: 195  | total loss: [1m[32m0.13942[0m[0m | time: 39.999s
[2K
| Adam | epoch: 020 | loss: 0.13942 - acc: 0.9737 -- iter: 160/307
[A[ATraining Step: 196  | total loss: [1m[32m0.13692[0m[0m | time: 48.050s
[2K
| Adam | epoch: 020 | loss: 0.13692 - acc: 0.9732 -- iter: 192/307
[A[ATraining Step: 197  | total loss: [1m[32m0.12902[0m[0m | time: 53.409s
[2K
| Adam | epoch: 020 | loss: 0.12902 - acc: 0.9759 -- iter: 224/307
[A[ATraining Step: 198  | total loss: [1m[32m0.11754[0m[0m | time: 58.603s
[2K
| Adam | epoch: 020 | loss: 0.11754 - acc: 0.9783 -- iter: 256/307
[A[ATraining Step: 199  | total loss: [1m[32m0.13977[0m[0m | time: 66.650s
[2K
| Adam | epoch: 020 | loss: 0.13977 - acc: 0.9699 -- iter: 288/307
[A[ATraining Step: 200  | total loss: [1m[32m0.14317[0m[0m | time: 79.250s
[2K
| Adam | epoch: 020 | loss: 0.14317 - acc: 0.9636 | val_loss: 3.04853 - val_acc: 0.5729 -- iter: 307/307
--
Training Step: 201  | total loss: [1m[32m0.13084[0m[0m | time: 7.957s
[2K
| Adam | epoch: 021 | loss: 0.13084 - acc: 0.9672 -- iter: 032/307
[A[ATraining Step: 202  | total loss: [1m[32m0.13277[0m[0m | time: 16.065s
[2K
| Adam | epoch: 021 | loss: 0.13277 - acc: 0.9642 -- iter: 064/307
[A[ATraining Step: 203  | total loss: [1m[32m0.12324[0m[0m | time: 24.019s
[2K
| Adam | epoch: 021 | loss: 0.12324 - acc: 0.9678 -- iter: 096/307
[A[ATraining Step: 204  | total loss: [1m[32m0.11331[0m[0m | time: 31.984s
[2K
| Adam | epoch: 021 | loss: 0.11331 - acc: 0.9710 -- iter: 128/307
[A[ATraining Step: 205  | total loss: [1m[32m0.11535[0m[0m | time: 39.930s
[2K
| Adam | epoch: 021 | loss: 0.11535 - acc: 0.9708 -- iter: 160/307
[A[ATraining Step: 206  | total loss: [1m[32m0.10648[0m[0m | time: 48.194s
[2K
| Adam | epoch: 021 | loss: 0.10648 - acc: 0.9737 -- iter: 192/307
[A[ATraining Step: 207  | total loss: [1m[32m0.11962[0m[0m | time: 56.100s
[2K
| Adam | epoch: 021 | loss: 0.11962 - acc: 0.9732 -- iter: 224/307
[A[ATraining Step: 208  | total loss: [1m[32m0.11049[0m[0m | time: 61.326s
[2K
| Adam | epoch: 021 | loss: 0.11049 - acc: 0.9759 -- iter: 256/307
[A[ATraining Step: 209  | total loss: [1m[32m0.10066[0m[0m | time: 66.640s
[2K
| Adam | epoch: 021 | loss: 0.10066 - acc: 0.9783 -- iter: 288/307
[A[ATraining Step: 210  | total loss: [1m[32m0.09191[0m[0m | time: 78.862s
[2K
| Adam | epoch: 021 | loss: 0.09191 - acc: 0.9805 | val_loss: 1.06305 - val_acc: 0.6771 -- iter: 307/307
--
Training Step: 211  | total loss: [1m[32m0.10062[0m[0m | time: 8.042s
[2K
| Adam | epoch: 022 | loss: 0.10062 - acc: 0.9731 -- iter: 032/307
[A[ATraining Step: 212  | total loss: [1m[32m0.09870[0m[0m | time: 15.982s
[2K
| Adam | epoch: 022 | loss: 0.09870 - acc: 0.9758 -- iter: 064/307
[A[ATraining Step: 213  | total loss: [1m[32m0.09024[0m[0m | time: 24.064s
[2K
| Adam | epoch: 022 | loss: 0.09024 - acc: 0.9782 -- iter: 096/307
[A[ATraining Step: 214  | total loss: [1m[32m0.08318[0m[0m | time: 32.090s
[2K
| Adam | epoch: 022 | loss: 0.08318 - acc: 0.9804 -- iter: 128/307
[A[ATraining Step: 215  | total loss: [1m[32m0.07671[0m[0m | time: 40.002s
[2K
| Adam | epoch: 022 | loss: 0.07671 - acc: 0.9823 -- iter: 160/307
[A[ATraining Step: 216  | total loss: [1m[32m0.07099[0m[0m | time: 47.985s
[2K
| Adam | epoch: 022 | loss: 0.07099 - acc: 0.9841 -- iter: 192/307
[A[ATraining Step: 217  | total loss: [1m[32m0.06539[0m[0m | time: 56.107s
[2K
| Adam | epoch: 022 | loss: 0.06539 - acc: 0.9857 -- iter: 224/307
[A[ATraining Step: 218  | total loss: [1m[32m0.06190[0m[0m | time: 63.905s
[2K
| Adam | epoch: 022 | loss: 0.06190 - acc: 0.9871 -- iter: 256/307
[A[ATraining Step: 219  | total loss: [1m[32m0.06804[0m[0m | time: 69.189s
[2K
| Adam | epoch: 022 | loss: 0.06804 - acc: 0.9853 -- iter: 288/307
[A[ATraining Step: 220  | total loss: [1m[32m0.06217[0m[0m | time: 78.705s
[2K
| Adam | epoch: 022 | loss: 0.06217 - acc: 0.9868 | val_loss: 1.07655 - val_acc: 0.6875 -- iter: 307/307
--
Training Step: 221  | total loss: [1m[32m0.08272[0m[0m | time: 7.954s
[2K
| Adam | epoch: 023 | loss: 0.08272 - acc: 0.9828 -- iter: 032/307
[A[ATraining Step: 222  | total loss: [1m[32m0.07555[0m[0m | time: 15.841s
[2K
| Adam | epoch: 023 | loss: 0.07555 - acc: 0.9845 -- iter: 064/307
[A[ATraining Step: 223  | total loss: [1m[32m0.06954[0m[0m | time: 23.761s
[2K
| Adam | epoch: 023 | loss: 0.06954 - acc: 0.9861 -- iter: 096/307
[A[ATraining Step: 224  | total loss: [1m[32m0.06346[0m[0m | time: 31.522s
[2K
| Adam | epoch: 023 | loss: 0.06346 - acc: 0.9875 -- iter: 128/307
[A[ATraining Step: 225  | total loss: [1m[32m0.07217[0m[0m | time: 39.780s
[2K
| Adam | epoch: 023 | loss: 0.07217 - acc: 0.9856 -- iter: 160/307
[A[ATraining Step: 226  | total loss: [1m[32m0.09533[0m[0m | time: 47.763s
[2K
| Adam | epoch: 023 | loss: 0.09533 - acc: 0.9839 -- iter: 192/307
[A[ATraining Step: 227  | total loss: [1m[32m0.08669[0m[0m | time: 55.679s
[2K
| Adam | epoch: 023 | loss: 0.08669 - acc: 0.9855 -- iter: 224/307
[A[ATraining Step: 228  | total loss: [1m[32m0.10434[0m[0m | time: 63.632s
[2K
| Adam | epoch: 023 | loss: 0.10434 - acc: 0.9838 -- iter: 256/307
[A[ATraining Step: 229  | total loss: [1m[32m0.09872[0m[0m | time: 71.780s
[2K
| Adam | epoch: 023 | loss: 0.09872 - acc: 0.9855 -- iter: 288/307
[A[ATraining Step: 230  | total loss: [1m[32m0.09261[0m[0m | time: 81.314s
[2K
| Adam | epoch: 023 | loss: 0.09261 - acc: 0.9869 | val_loss: 0.61216 - val_acc: 0.7396 -- iter: 307/307
--
Training Step: 231  | total loss: [1m[32m0.08477[0m[0m | time: 5.411s
[2K
| Adam | epoch: 024 | loss: 0.08477 - acc: 0.9882 -- iter: 032/307
[A[ATraining Step: 232  | total loss: [1m[32m0.09621[0m[0m | time: 13.274s
[2K
| Adam | epoch: 024 | loss: 0.09621 - acc: 0.9841 -- iter: 064/307
[A[ATraining Step: 233  | total loss: [1m[32m0.08935[0m[0m | time: 21.287s
[2K
| Adam | epoch: 024 | loss: 0.08935 - acc: 0.9857 -- iter: 096/307
[A[ATraining Step: 234  | total loss: [1m[32m0.08122[0m[0m | time: 29.104s
[2K
| Adam | epoch: 024 | loss: 0.08122 - acc: 0.9872 -- iter: 128/307
[A[ATraining Step: 235  | total loss: [1m[32m0.09214[0m[0m | time: 37.000s
[2K
| Adam | epoch: 024 | loss: 0.09214 - acc: 0.9853 -- iter: 160/307
[A[ATraining Step: 236  | total loss: [1m[32m0.08643[0m[0m | time: 45.076s
[2K
| Adam | epoch: 024 | loss: 0.08643 - acc: 0.9868 -- iter: 192/307
[A[ATraining Step: 237  | total loss: [1m[32m0.07899[0m[0m | time: 52.991s
[2K
| Adam | epoch: 024 | loss: 0.07899 - acc: 0.9881 -- iter: 224/307
[A[ATraining Step: 238  | total loss: [1m[32m0.07214[0m[0m | time: 61.070s
[2K
| Adam | epoch: 024 | loss: 0.07214 - acc: 0.9893 -- iter: 256/307
[A[ATraining Step: 239  | total loss: [1m[32m0.07001[0m[0m | time: 68.905s
[2K
| Adam | epoch: 024 | loss: 0.07001 - acc: 0.9872 -- iter: 288/307
[A[ATraining Step: 240  | total loss: [1m[32m0.06881[0m[0m | time: 81.083s
[2K
| Adam | epoch: 024 | loss: 0.06881 - acc: 0.9854 | val_loss: 1.15620 - val_acc: 0.6458 -- iter: 307/307
--
Training Step: 241  | total loss: [1m[32m0.06421[0m[0m | time: 5.338s
[2K
| Adam | epoch: 025 | loss: 0.06421 - acc: 0.9869 -- iter: 032/307
[A[ATraining Step: 242  | total loss: [1m[32m0.05810[0m[0m | time: 10.670s
[2K
| Adam | epoch: 025 | loss: 0.05810 - acc: 0.9882 -- iter: 064/307
[A[ATraining Step: 243  | total loss: [1m[32m0.09023[0m[0m | time: 18.566s
[2K
| Adam | epoch: 025 | loss: 0.09023 - acc: 0.9841 -- iter: 096/307
[A[ATraining Step: 244  | total loss: [1m[32m0.08946[0m[0m | time: 26.551s
[2K
| Adam | epoch: 025 | loss: 0.08946 - acc: 0.9826 -- iter: 128/307
[A[ATraining Step: 245  | total loss: [1m[32m0.08216[0m[0m | time: 34.494s
[2K
| Adam | epoch: 025 | loss: 0.08216 - acc: 0.9843 -- iter: 160/307
[A[ATraining Step: 246  | total loss: [1m[32m0.07537[0m[0m | time: 42.532s
[2K
| Adam | epoch: 025 | loss: 0.07537 - acc: 0.9859 -- iter: 192/307
[A[ATraining Step: 247  | total loss: [1m[32m0.07002[0m[0m | time: 50.524s
[2K
| Adam | epoch: 025 | loss: 0.07002 - acc: 0.9873 -- iter: 224/307
[A[ATraining Step: 248  | total loss: [1m[32m0.07446[0m[0m | time: 58.479s
[2K
| Adam | epoch: 025 | loss: 0.07446 - acc: 0.9854 -- iter: 256/307
[A[ATraining Step: 249  | total loss: [1m[32m0.06820[0m[0m | time: 66.565s
[2K
| Adam | epoch: 025 | loss: 0.06820 - acc: 0.9869 -- iter: 288/307
[A[ATraining Step: 250  | total loss: [1m[32m0.06261[0m[0m | time: 78.702s
[2K
| Adam | epoch: 025 | loss: 0.06261 - acc: 0.9882 | val_loss: 0.68260 - val_acc: 0.6979 -- iter: 307/307
--
Training Step: 251  | total loss: [1m[32m0.05869[0m[0m | time: 7.892s
[2K
| Adam | epoch: 026 | loss: 0.05869 - acc: 0.9894 -- iter: 032/307
[A[ATraining Step: 252  | total loss: [1m[32m0.05749[0m[0m | time: 13.142s
[2K
| Adam | epoch: 026 | loss: 0.05749 - acc: 0.9904 -- iter: 064/307
[A[ATraining Step: 253  | total loss: [1m[32m0.07543[0m[0m | time: 18.490s
[2K
| Adam | epoch: 026 | loss: 0.07543 - acc: 0.9861 -- iter: 096/307
[A[ATraining Step: 254  | total loss: [1m[32m0.06845[0m[0m | time: 26.496s
[2K
| Adam | epoch: 026 | loss: 0.06845 - acc: 0.9875 -- iter: 128/307
[A[ATraining Step: 255  | total loss: [1m[32m0.06236[0m[0m | time: 34.407s
[2K
| Adam | epoch: 026 | loss: 0.06236 - acc: 0.9888 -- iter: 160/307
[A[ATraining Step: 256  | total loss: [1m[32m0.05872[0m[0m | time: 42.259s
[2K
| Adam | epoch: 026 | loss: 0.05872 - acc: 0.9899 -- iter: 192/307
[A[ATraining Step: 257  | total loss: [1m[32m0.05368[0m[0m | time: 50.292s
[2K
| Adam | epoch: 026 | loss: 0.05368 - acc: 0.9909 -- iter: 224/307
[A[ATraining Step: 258  | total loss: [1m[32m0.05477[0m[0m | time: 58.388s
[2K
| Adam | epoch: 026 | loss: 0.05477 - acc: 0.9856 -- iter: 256/307
[A[ATraining Step: 259  | total loss: [1m[32m0.05118[0m[0m | time: 66.379s
[2K
| Adam | epoch: 026 | loss: 0.05118 - acc: 0.9870 -- iter: 288/307
[A[ATraining Step: 260  | total loss: [1m[32m0.04827[0m[0m | time: 78.607s
[2K
| Adam | epoch: 026 | loss: 0.04827 - acc: 0.9883 | val_loss: 1.04832 - val_acc: 0.6458 -- iter: 307/307
--
Training Step: 261  | total loss: [1m[32m0.04819[0m[0m | time: 7.989s
[2K
| Adam | epoch: 027 | loss: 0.04819 - acc: 0.9863 -- iter: 032/307
[A[ATraining Step: 262  | total loss: [1m[32m0.04492[0m[0m | time: 15.972s
[2K
| Adam | epoch: 027 | loss: 0.04492 - acc: 0.9877 -- iter: 064/307
[A[ATraining Step: 263  | total loss: [1m[32m0.04152[0m[0m | time: 21.246s
[2K
| Adam | epoch: 027 | loss: 0.04152 - acc: 0.9889 -- iter: 096/307
[A[ATraining Step: 264  | total loss: [1m[32m0.03815[0m[0m | time: 26.475s
[2K
| Adam | epoch: 027 | loss: 0.03815 - acc: 0.9900 -- iter: 128/307
[A[ATraining Step: 265  | total loss: [1m[32m0.07004[0m[0m | time: 34.594s
[2K
| Adam | epoch: 027 | loss: 0.07004 - acc: 0.9805 -- iter: 160/307
[A[ATraining Step: 266  | total loss: [1m[32m0.06364[0m[0m | time: 42.423s
[2K
| Adam | epoch: 027 | loss: 0.06364 - acc: 0.9825 -- iter: 192/307
[A[ATraining Step: 267  | total loss: [1m[32m0.05805[0m[0m | time: 50.216s
[2K
| Adam | epoch: 027 | loss: 0.05805 - acc: 0.9842 -- iter: 224/307
[A[ATraining Step: 268  | total loss: [1m[32m0.05304[0m[0m | time: 58.191s
[2K
| Adam | epoch: 027 | loss: 0.05304 - acc: 0.9858 -- iter: 256/307
[A[ATraining Step: 269  | total loss: [1m[32m0.06200[0m[0m | time: 66.415s
[2K
| Adam | epoch: 027 | loss: 0.06200 - acc: 0.9841 -- iter: 288/307
[A[ATraining Step: 270  | total loss: [1m[32m0.05615[0m[0m | time: 78.769s
[2K
| Adam | epoch: 027 | loss: 0.05615 - acc: 0.9857 | val_loss: 2.60375 - val_acc: 0.6250 -- iter: 307/307
--
Training Step: 271  | total loss: [1m[32m0.07131[0m[0m | time: 8.185s
[2K
| Adam | epoch: 028 | loss: 0.07131 - acc: 0.9840 -- iter: 032/307
[A[ATraining Step: 272  | total loss: [1m[32m0.06619[0m[0m | time: 16.042s
[2K
| Adam | epoch: 028 | loss: 0.06619 - acc: 0.9856 -- iter: 064/307
[A[ATraining Step: 273  | total loss: [1m[32m0.06448[0m[0m | time: 23.952s
[2K
| Adam | epoch: 028 | loss: 0.06448 - acc: 0.9870 -- iter: 096/307
[A[ATraining Step: 274  | total loss: [1m[32m0.06014[0m[0m | time: 29.337s
[2K
| Adam | epoch: 028 | loss: 0.06014 - acc: 0.9883 -- iter: 128/307
[A[ATraining Step: 275  | total loss: [1m[32m0.05665[0m[0m | time: 34.604s
[2K
| Adam | epoch: 028 | loss: 0.05665 - acc: 0.9895 -- iter: 160/307
[A[ATraining Step: 276  | total loss: [1m[32m0.05492[0m[0m | time: 42.459s
[2K
| Adam | epoch: 028 | loss: 0.05492 - acc: 0.9905 -- iter: 192/307
[A[ATraining Step: 277  | total loss: [1m[32m0.05076[0m[0m | time: 50.519s
[2K
| Adam | epoch: 028 | loss: 0.05076 - acc: 0.9915 -- iter: 224/307
[A[ATraining Step: 278  | total loss: [1m[32m0.04944[0m[0m | time: 58.455s
[2K
| Adam | epoch: 028 | loss: 0.04944 - acc: 0.9892 -- iter: 256/307
[A[ATraining Step: 279  | total loss: [1m[32m0.04877[0m[0m | time: 66.360s
[2K
| Adam | epoch: 028 | loss: 0.04877 - acc: 0.9903 -- iter: 288/307
[A[ATraining Step: 280  | total loss: [1m[32m0.04437[0m[0m | time: 78.578s
[2K
| Adam | epoch: 028 | loss: 0.04437 - acc: 0.9913 | val_loss: 1.31559 - val_acc: 0.6146 -- iter: 307/307
--
Training Step: 281  | total loss: [1m[32m0.04120[0m[0m | time: 8.080s
[2K
| Adam | epoch: 029 | loss: 0.04120 - acc: 0.9921 -- iter: 032/307
[A[ATraining Step: 282  | total loss: [1m[32m0.03787[0m[0m | time: 16.066s
[2K
| Adam | epoch: 029 | loss: 0.03787 - acc: 0.9929 -- iter: 064/307
[A[ATraining Step: 283  | total loss: [1m[32m0.03427[0m[0m | time: 24.141s
[2K
| Adam | epoch: 029 | loss: 0.03427 - acc: 0.9936 -- iter: 096/307
[A[ATraining Step: 284  | total loss: [1m[32m0.03123[0m[0m | time: 32.080s
[2K
| Adam | epoch: 029 | loss: 0.03123 - acc: 0.9943 -- iter: 128/307
[A[ATraining Step: 285  | total loss: [1m[32m0.02984[0m[0m | time: 37.323s
[2K
| Adam | epoch: 029 | loss: 0.02984 - acc: 0.9948 -- iter: 160/307
[A[ATraining Step: 286  | total loss: [1m[32m0.03112[0m[0m | time: 42.786s
[2K
| Adam | epoch: 029 | loss: 0.03112 - acc: 0.9901 -- iter: 192/307
[A[ATraining Step: 287  | total loss: [1m[32m0.05733[0m[0m | time: 50.725s
[2K
| Adam | epoch: 029 | loss: 0.05733 - acc: 0.9858 -- iter: 224/307
[A[ATraining Step: 288  | total loss: [1m[32m0.05185[0m[0m | time: 58.817s
[2K
| Adam | epoch: 029 | loss: 0.05185 - acc: 0.9872 -- iter: 256/307
[A[ATraining Step: 289  | total loss: [1m[32m0.04799[0m[0m | time: 66.742s
[2K
| Adam | epoch: 029 | loss: 0.04799 - acc: 0.9885 -- iter: 288/307
[A[ATraining Step: 290  | total loss: [1m[32m0.04414[0m[0m | time: 79.122s
[2K
| Adam | epoch: 029 | loss: 0.04414 - acc: 0.9897 | val_loss: 1.24596 - val_acc: 0.6354 -- iter: 307/307
--
Training Step: 291  | total loss: [1m[32m0.04180[0m[0m | time: 7.960s
[2K
| Adam | epoch: 030 | loss: 0.04180 - acc: 0.9907 -- iter: 032/307
[A[ATraining Step: 292  | total loss: [1m[32m0.04060[0m[0m | time: 15.913s
[2K
| Adam | epoch: 030 | loss: 0.04060 - acc: 0.9885 -- iter: 064/307
[A[ATraining Step: 293  | total loss: [1m[32m0.03845[0m[0m | time: 24.082s
[2K
| Adam | epoch: 030 | loss: 0.03845 - acc: 0.9897 -- iter: 096/307
[A[ATraining Step: 294  | total loss: [1m[32m0.03495[0m[0m | time: 32.127s
[2K
| Adam | epoch: 030 | loss: 0.03495 - acc: 0.9907 -- iter: 128/307
[A[ATraining Step: 295  | total loss: [1m[32m0.03922[0m[0m | time: 40.172s
[2K
| Adam | epoch: 030 | loss: 0.03922 - acc: 0.9885 -- iter: 160/307
[A[ATraining Step: 296  | total loss: [1m[32m0.06971[0m[0m | time: 45.409s
[2K
| Adam | epoch: 030 | loss: 0.06971 - acc: 0.9865 -- iter: 192/307
[A[ATraining Step: 297  | total loss: [1m[32m0.06293[0m[0m | time: 50.599s
[2K
| Adam | epoch: 030 | loss: 0.06293 - acc: 0.9879 -- iter: 224/307
[A[ATraining Step: 298  | total loss: [1m[32m0.08926[0m[0m | time: 58.409s
[2K
| Adam | epoch: 030 | loss: 0.08926 - acc: 0.9838 -- iter: 256/307
[A[ATraining Step: 299  | total loss: [1m[32m0.08471[0m[0m | time: 66.537s
[2K
| Adam | epoch: 030 | loss: 0.08471 - acc: 0.9823 -- iter: 288/307
[A[ATraining Step: 300  | total loss: [1m[32m0.08418[0m[0m | time: 78.969s
[2K
| Adam | epoch: 030 | loss: 0.08418 - acc: 0.9810 | val_loss: 0.60422 - val_acc: 0.7917 -- iter: 307/307
--
Validation AUC:0.8708112874779542
Validation AUPRC:0.9121990190349443
Test AUC:0.8857399910031489
Test AUPRC:0.9122554819087398
BestTestF1Score	0.85	0.61	0.81	0.82	0.88	50	11	28	7	0.55
BestTestMCCScore	0.84	0.66	0.82	0.92	0.77	44	4	35	13	0.91
BestTestAccuracyScore	0.84	0.66	0.82	0.92	0.77	44	4	35	13	0.91
BestValidationF1Score	0.84	0.62	0.81	0.79	0.91	49	13	29	5	0.55
BestValidationMCC	0.82	0.64	0.81	0.89	0.76	41	5	37	13	0.91
BestValidationAccuracy	0.82	0.64	0.81	0.89	0.76	41	5	37	13	0.91
TestPredictions (Threshold:0.91)
CHEMBL374478,TP,ACT,1.0	CHEMBL195577,TN,INACT,0.5	CHEMBL181785,TN,INACT,0.12999999523162842	CHEMBL1221811,TP,ACT,1.0	CHEMBL476927,TN,INACT,0.5099999904632568	CHEMBL178674,FN,ACT,0.6100000143051147	CHEMBL78028,FN,ACT,0.8999999761581421	CHEMBL213784,FN,ACT,0.15000000596046448	CHEMBL101684,TP,ACT,1.0	CHEMBL2023148,TN,INACT,0.0	CHEMBL503641,TN,INACT,0.009999999776482582	CHEMBL396625,TP,ACT,1.0	CHEMBL2041045,FP,INACT,0.9900000095367432	CHEMBL2011679,TN,INACT,0.3700000047683716	CHEMBL197811,TP,ACT,0.9300000071525574	CHEMBL3600726,TN,INACT,0.10999999940395355	CHEMBL1221744,TP,ACT,0.9800000190734863	CHEMBL1221688,FN,ACT,0.12999999523162842	CHEMBL60306,TN,INACT,0.009999999776482582	CHEMBL214044,TP,ACT,0.9599999785423279	CHEMBL26719,TP,ACT,1.0	CHEMBL2391913,TN,INACT,0.0	CHEMBL352426,TP,ACT,1.0	CHEMBL284415,TP,ACT,1.0	CHEMBL302480,TP,ACT,1.0	CHEMBL3360318,TN,INACT,0.17000000178813934	CHEMBL1222906,TP,ACT,0.9800000190734863	CHEMBL6439,FN,ACT,0.5699999928474426	CHEMBL382090,TP,ACT,0.9599999785423279	CHEMBL101442,FN,ACT,0.8299999833106995	CHEMBL477047,TP,ACT,0.9800000190734863	CHEMBL411178,TP,ACT,1.0	CHEMBL1222616,TP,ACT,1.0	CHEMBL3696497,TN,INACT,0.5400000214576721	CHEMBL23226,FN,ACT,0.12999999523162842	CHEMBL591280,TP,ACT,1.0	CHEMBL2041042,TN,INACT,0.7400000095367432	CHEMBL114791,TP,ACT,1.0	CHEMBL3600729,TN,INACT,0.009999999776482582	CHEMBL304276,TN,INACT,0.0	CHEMBL246887,TP,ACT,1.0	CHEMBL100114,TP,ACT,0.9800000190734863	CHEMBL202044,TP,ACT,1.0	CHEMBL198845,TP,ACT,1.0	CHEMBL1223037,TN,INACT,0.09000000357627869	CHEMBL490850,TP,ACT,1.0	CHEMBL458563,TN,INACT,0.03999999910593033	CHEMBL366534,TP,ACT,1.0	CHEMBL166754,TP,ACT,1.0	CHEMBL322183,TP,ACT,1.0	CHEMBL1222758,TP,ACT,0.9900000095367432	CHEMBL262596,FP,INACT,0.9900000095367432	CHEMBL29601,FN,ACT,0.3799999952316284	CHEMBL100578,FP,INACT,1.0	CHEMBL1222686,TP,ACT,0.9900000095367432	CHEMBL103820,FN,ACT,0.8600000143051147	CHEMBL2391863,TN,INACT,0.029999999329447746	CHEMBL377298,TP,ACT,0.9900000095367432	CHEMBL67349,TN,INACT,0.10000000149011612	CHEMBL321074,TP,ACT,1.0	CHEMBL2023147,TN,INACT,0.009999999776482582	CHEMBL600458,TP,ACT,1.0	CHEMBL179130,TN,INACT,0.019999999552965164	CHEMBL1222835,TP,ACT,0.9800000190734863	CHEMBL420458,TP,ACT,0.9200000166893005	CHEMBL2348861,TN,INACT,0.07999999821186066	CHEMBL359598,TP,ACT,0.9700000286102295	CHEMBL62187,TN,INACT,0.6000000238418579	CHEMBL3218010,TN,INACT,0.23999999463558197	CHEMBL567134,TN,INACT,0.8299999833106995	CHEMBL90840,FN,ACT,0.8600000143051147	CHEMBL1835401,FP,INACT,0.9900000095367432	CHEMBL115952,TP,ACT,1.0	CHEMBL2391981,TN,INACT,0.8799999952316284	CHEMBL172549,TP,ACT,1.0	CHEMBL3696499,TN,INACT,0.05000000074505806	CHEMBL2041032,TN,INACT,0.7900000214576721	CHEMBL88381,TN,INACT,0.25	CHEMBL101644,FN,ACT,0.07000000029802322	CHEMBL361825,TP,ACT,0.9800000190734863	CHEMBL30983,TN,INACT,0.0	CHEMBL180623,TP,ACT,1.0	CHEMBL26359,TP,ACT,1.0	CHEMBL59463,TP,ACT,1.0	CHEMBL101108,TP,ACT,1.0	CHEMBL30411,FN,ACT,0.07000000029802322	CHEMBL319776,TP,ACT,0.9399999976158142	CHEMBL418573,FN,ACT,0.46000000834465027	CHEMBL100769,TP,ACT,1.0	CHEMBL409053,TN,INACT,0.0	CHEMBL455368,TN,INACT,0.5199999809265137	CHEMBL500256,TN,INACT,0.8299999833106995	CHEMBL202329,TP,ACT,1.0	CHEMBL1835404,TN,INACT,0.009999999776482582	CHEMBL1352007,TN,INACT,0.6299999952316284	CHEMBL590826,TN,INACT,0.07999999821186066	

