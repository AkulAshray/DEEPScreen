ImageNetInceptionV2 CHEMBL2803 adam 0.0001 5 0 0 0.6 False True
Number of active compounds :	204
Number of inactive compounds :	204
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2803_adam_0.0001_5_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2803_adam_0.0001_5_0.6/
---------------------------------
Training samples: 248
Validation samples: 78
--
Training Step: 1  | time: 77.593s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/248
[A[ATraining Step: 2  | total loss: [1m[32m0.64903[0m[0m | time: 126.203s
[2K
| Adam | epoch: 001 | loss: 0.64903 - acc: 0.5062 -- iter: 064/248
[A[ATraining Step: 3  | total loss: [1m[32m0.73657[0m[0m | time: 207.380s
[2K
| Adam | epoch: 001 | loss: 0.73657 - acc: 0.4756 -- iter: 096/248
[A[ATraining Step: 4  | total loss: [1m[32m0.71105[0m[0m | time: 266.796s
[2K
| Adam | epoch: 001 | loss: 0.71105 - acc: 0.4939 -- iter: 128/248
[A[ATraining Step: 5  | total loss: [1m[32m0.73357[0m[0m | time: 324.165s
[2K
| Adam | epoch: 001 | loss: 0.73357 - acc: 0.5198 -- iter: 160/248
[A[ATraining Step: 6  | total loss: [1m[32m0.69410[0m[0m | time: 389.996s
[2K
| Adam | epoch: 001 | loss: 0.69410 - acc: 0.5271 -- iter: 192/248
[A[ATraining Step: 7  | total loss: [1m[32m0.64778[0m[0m | time: 455.298s
[2K
| Adam | epoch: 001 | loss: 0.64778 - acc: 0.5859 -- iter: 224/248
[A[ATraining Step: 8  | total loss: [1m[32m0.62563[0m[0m | time: 488.504s
[2K
| Adam | epoch: 001 | loss: 0.62563 - acc: 0.5903 | val_loss: 0.72418 - val_acc: 0.5128 -- iter: 248/248
--
Training Step: 9  | total loss: [1m[32m0.59137[0m[0m | time: 22.655s
[2K
| Adam | epoch: 002 | loss: 0.59137 - acc: 0.6748 -- iter: 032/248
[A[ATraining Step: 10  | total loss: [1m[32m0.54509[0m[0m | time: 51.990s
[2K
| Adam | epoch: 002 | loss: 0.54509 - acc: 0.7124 -- iter: 064/248
[A[ATraining Step: 11  | total loss: [1m[32m0.57861[0m[0m | time: 74.164s
[2K
| Adam | epoch: 002 | loss: 0.57861 - acc: 0.6710 -- iter: 096/248
[A[ATraining Step: 12  | total loss: [1m[32m0.54170[0m[0m | time: 89.611s
[2K
| Adam | epoch: 002 | loss: 0.54170 - acc: 0.7487 -- iter: 128/248
[A[ATraining Step: 13  | total loss: [1m[32m0.57137[0m[0m | time: 105.345s
[2K
| Adam | epoch: 002 | loss: 0.57137 - acc: 0.7225 -- iter: 160/248
[A[ATraining Step: 14  | total loss: [1m[32m0.51626[0m[0m | time: 120.672s
[2K
| Adam | epoch: 002 | loss: 0.51626 - acc: 0.7721 -- iter: 192/248
[A[ATraining Step: 15  | total loss: [1m[32m0.44759[0m[0m | time: 134.029s
[2K
| Adam | epoch: 002 | loss: 0.44759 - acc: 0.8491 -- iter: 224/248
[A[ATraining Step: 16  | total loss: [1m[32m0.42819[0m[0m | time: 152.347s
[2K
| Adam | epoch: 002 | loss: 0.42819 - acc: 0.8588 | val_loss: 0.79129 - val_acc: 0.4872 -- iter: 248/248
--
Training Step: 17  | total loss: [1m[32m0.39718[0m[0m | time: 10.246s
[2K
| Adam | epoch: 003 | loss: 0.39718 - acc: 0.8984 -- iter: 032/248
[A[ATraining Step: 18  | total loss: [1m[32m0.38240[0m[0m | time: 21.003s
[2K
| Adam | epoch: 003 | loss: 0.38240 - acc: 0.9191 -- iter: 064/248
[A[ATraining Step: 19  | total loss: [1m[32m0.34359[0m[0m | time: 34.244s
[2K
| Adam | epoch: 003 | loss: 0.34359 - acc: 0.9322 -- iter: 096/248
[A[ATraining Step: 20  | total loss: [1m[32m0.39106[0m[0m | time: 47.306s
[2K
| Adam | epoch: 003 | loss: 0.39106 - acc: 0.8937 -- iter: 128/248
[A[ATraining Step: 21  | total loss: [1m[32m0.38576[0m[0m | time: 60.083s
[2K
| Adam | epoch: 003 | loss: 0.38576 - acc: 0.8685 -- iter: 160/248
[A[ATraining Step: 22  | total loss: [1m[32m0.37553[0m[0m | time: 73.398s
[2K
| Adam | epoch: 003 | loss: 0.37553 - acc: 0.8798 -- iter: 192/248
[A[ATraining Step: 23  | total loss: [1m[32m0.32411[0m[0m | time: 86.543s
[2K
| Adam | epoch: 003 | loss: 0.32411 - acc: 0.9056 -- iter: 224/248
[A[ATraining Step: 24  | total loss: [1m[32m0.27956[0m[0m | time: 102.588s
[2K
| Adam | epoch: 003 | loss: 0.27956 - acc: 0.9146 | val_loss: 0.77045 - val_acc: 0.4872 -- iter: 248/248
--
Training Step: 25  | total loss: [1m[32m0.24960[0m[0m | time: 13.094s
[2K
| Adam | epoch: 004 | loss: 0.24960 - acc: 0.9294 -- iter: 032/248
[A[ATraining Step: 26  | total loss: [1m[32m0.22412[0m[0m | time: 23.119s
[2K
| Adam | epoch: 004 | loss: 0.22412 - acc: 0.9481 -- iter: 064/248
[A[ATraining Step: 27  | total loss: [1m[32m0.22677[0m[0m | time: 33.488s
[2K
| Adam | epoch: 004 | loss: 0.22677 - acc: 0.9400 -- iter: 096/248
[A[ATraining Step: 28  | total loss: [1m[32m0.20321[0m[0m | time: 46.556s
[2K
| Adam | epoch: 004 | loss: 0.20321 - acc: 0.9550 -- iter: 128/248
[A[ATraining Step: 29  | total loss: [1m[32m0.18685[0m[0m | time: 59.995s
[2K
| Adam | epoch: 004 | loss: 0.18685 - acc: 0.9583 -- iter: 160/248
[A[ATraining Step: 30  | total loss: [1m[32m0.17756[0m[0m | time: 73.350s
[2K
| Adam | epoch: 004 | loss: 0.17756 - acc: 0.9608 -- iter: 192/248
[A[ATraining Step: 31  | total loss: [1m[32m0.17943[0m[0m | time: 86.688s
[2K
| Adam | epoch: 004 | loss: 0.17943 - acc: 0.9554 -- iter: 224/248
[A[ATraining Step: 32  | total loss: [1m[32m0.14947[0m[0m | time: 105.800s
[2K
| Adam | epoch: 004 | loss: 0.14947 - acc: 0.9655 | val_loss: 1.04244 - val_acc: 0.4872 -- iter: 248/248
--
Training Step: 33  | total loss: [1m[32m0.13937[0m[0m | time: 13.079s
[2K
| Adam | epoch: 005 | loss: 0.13937 - acc: 0.9730 -- iter: 032/248
[A[ATraining Step: 34  | total loss: [1m[32m0.14090[0m[0m | time: 26.667s
[2K
| Adam | epoch: 005 | loss: 0.14090 - acc: 0.9721 -- iter: 064/248
[A[ATraining Step: 35  | total loss: [1m[32m0.11884[0m[0m | time: 36.718s
[2K
| Adam | epoch: 005 | loss: 0.11884 - acc: 0.9780 -- iter: 096/248
[A[ATraining Step: 36  | total loss: [1m[32m0.10004[0m[0m | time: 47.155s
[2K
| Adam | epoch: 005 | loss: 0.10004 - acc: 0.9825 -- iter: 128/248
[A[ATraining Step: 37  | total loss: [1m[32m0.08348[0m[0m | time: 60.337s
[2K
| Adam | epoch: 005 | loss: 0.08348 - acc: 0.9860 -- iter: 160/248
[A[ATraining Step: 38  | total loss: [1m[32m0.09597[0m[0m | time: 73.711s
[2K
| Adam | epoch: 005 | loss: 0.09597 - acc: 0.9826 -- iter: 192/248
[A[ATraining Step: 39  | total loss: [1m[32m0.08051[0m[0m | time: 87.054s
[2K
| Adam | epoch: 005 | loss: 0.08051 - acc: 0.9859 -- iter: 224/248
[A[ATraining Step: 40  | total loss: [1m[32m0.09325[0m[0m | time: 106.363s
[2K
| Adam | epoch: 005 | loss: 0.09325 - acc: 0.9827 | val_loss: 0.73781 - val_acc: 0.5128 -- iter: 248/248
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.6782894736842106
Validation AUPRC:0.7083516168500553
Test AUC:0.7907754010695187
Test AUPRC:0.8461195736759878
BestTestF1Score	0.75	0.28	0.64	0.62	0.95	42	26	8	2	0.27
BestTestMCCScore	0.77	0.48	0.74	0.77	0.77	34	10	24	10	0.33
BestTestAccuracyScore	0.77	0.48	0.74	0.77	0.77	34	10	24	10	0.33
BestValidationF1Score	0.7	0.28	0.63	0.6	0.85	34	23	15	6	0.27
BestValidationMCC	0.66	0.31	0.65	0.67	0.65	26	13	25	14	0.33
BestValidationAccuracy	0.66	0.31	0.65	0.67	0.65	26	13	25	14	0.33
TestPredictions (Threshold:0.33)
CHEMBL473229,TP,ACT,0.4000000059604645	CHEMBL520608,TP,ACT,0.36000001430511475	CHEMBL100312,TN,INACT,0.3100000023841858	CHEMBL551722,TN,INACT,0.2199999988079071	CHEMBL584570,TP,ACT,0.38999998569488525	CHEMBL3642578,TP,ACT,0.3700000047683716	CHEMBL100079,TN,INACT,0.1899999976158142	CHEMBL1910758,TN,INACT,0.30000001192092896	CHEMBL336864,TP,ACT,0.550000011920929	CHEMBL386760,TP,ACT,0.4000000059604645	CHEMBL578450,TP,ACT,0.4399999976158142	CHEMBL112518,TP,ACT,0.44999998807907104	CHEMBL471819,FN,ACT,0.25	CHEMBL465098,TP,ACT,0.41999998688697815	CHEMBL99280,TN,INACT,0.3100000023841858	CHEMBL584148,TP,ACT,0.3499999940395355	CHEMBL3085242,TN,INACT,0.27000001072883606	CHEMBL563948,TN,INACT,0.23000000417232513	CHEMBL324576,TP,ACT,0.4399999976158142	CHEMBL3262617,TP,ACT,0.49000000953674316	CHEMBL1910761,TN,INACT,0.23000000417232513	CHEMBL373834,TN,INACT,0.28999999165534973	CHEMBL457179,TN,INACT,0.2800000011920929	CHEMBL130401,FP,INACT,0.41999998688697815	CHEMBL477064,TN,INACT,0.3199999928474426	CHEMBL483081,TN,INACT,0.3100000023841858	CHEMBL489646,TN,INACT,0.30000001192092896	CHEMBL99779,FP,INACT,0.33000001311302185	CHEMBL511670,FN,ACT,0.28999999165534973	CHEMBL573488,TP,ACT,0.3799999952316284	CHEMBL475575,TP,ACT,0.46000000834465027	CHEMBL465464,TP,ACT,0.5099999904632568	CHEMBL3262356,TP,ACT,0.5	CHEMBL517154,TN,INACT,0.27000001072883606	CHEMBL471776,FN,ACT,0.2800000011920929	CHEMBL573484,TP,ACT,0.3799999952316284	CHEMBL3642584,FN,ACT,0.30000001192092896	CHEMBL573719,TP,ACT,0.46000000834465027	CHEMBL74799,TN,INACT,0.27000001072883606	CHEMBL511977,TP,ACT,0.4699999988079071	CHEMBL1240703,TP,ACT,0.5199999809265137	CHEMBL134004,TP,ACT,0.3499999940395355	CHEMBL3262618,TP,ACT,0.3499999940395355	CHEMBL131382,TN,INACT,0.17000000178813934	CHEMBL120703,FP,INACT,0.36000001430511475	CHEMBL515674,TN,INACT,0.30000001192092896	CHEMBL134243,FN,ACT,0.3199999928474426	CHEMBL498248,FP,INACT,0.3400000035762787	CHEMBL485730,FN,ACT,0.27000001072883606	CHEMBL3642592,TP,ACT,0.36000001430511475	CHEMBL100485,FP,INACT,0.3700000047683716	CHEMBL500086,FN,ACT,0.27000001072883606	CHEMBL456113,FP,INACT,0.33000001311302185	CHEMBL132007,TP,ACT,0.3400000035762787	CHEMBL2403108,TP,ACT,0.3499999940395355	CHEMBL525538,TN,INACT,0.25999999046325684	CHEMBL339077,TP,ACT,0.36000001430511475	CHEMBL334979,TP,ACT,0.3799999952316284	CHEMBL551936,TN,INACT,0.2800000011920929	CHEMBL463384,TN,INACT,0.2800000011920929	CHEMBL3642585,TP,ACT,0.41999998688697815	CHEMBL485731,FN,ACT,0.27000001072883606	CHEMBL310313,FP,INACT,0.4300000071525574	CHEMBL27085,TN,INACT,0.2199999988079071	CHEMBL419757,TP,ACT,0.36000001430511475	CHEMBL336314,TP,ACT,0.3400000035762787	CHEMBL3642593,TP,ACT,0.3499999940395355	CHEMBL475249,FN,ACT,0.2800000011920929	CHEMBL471727,TP,ACT,0.36000001430511475	CHEMBL3642586,TP,ACT,0.4399999976158142	CHEMBL335284,FP,INACT,0.36000001430511475	CHEMBL452812,TN,INACT,0.27000001072883606	CHEMBL530335,TN,INACT,0.2800000011920929	CHEMBL515757,FN,ACT,0.17000000178813934	CHEMBL477165,FP,INACT,0.41999998688697815	CHEMBL484350,TP,ACT,0.4699999988079071	CHEMBL509499,TN,INACT,0.2199999988079071	CHEMBL3691629,FP,INACT,0.36000001430511475	

