ImageNetInceptionV2 CHEMBL5103 adam 0.0001 15 0 0 0.8 False True
Number of active compounds :	214
Number of inactive compounds :	214
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5103_adam_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5103_adam_0.0001_15_0.8/
---------------------------------
Training samples: 269
Validation samples: 85
--
Training Step: 1  | time: 63.984s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/269
[A[ATraining Step: 2  | total loss: [1m[32m0.63284[0m[0m | time: 119.263s
[2K
| Adam | epoch: 001 | loss: 0.63284 - acc: 0.3937 -- iter: 064/269
[A[ATraining Step: 3  | total loss: [1m[32m0.65194[0m[0m | time: 194.108s
[2K
| Adam | epoch: 001 | loss: 0.65194 - acc: 0.5318 -- iter: 096/269
[A[ATraining Step: 4  | total loss: [1m[32m0.64370[0m[0m | time: 222.523s
[2K
| Adam | epoch: 001 | loss: 0.64370 - acc: 0.6017 -- iter: 128/269
[A[ATraining Step: 5  | total loss: [1m[32m0.68731[0m[0m | time: 246.323s
[2K
| Adam | epoch: 001 | loss: 0.68731 - acc: 0.5746 -- iter: 160/269
[A[ATraining Step: 6  | total loss: [1m[32m0.69925[0m[0m | time: 306.078s
[2K
| Adam | epoch: 001 | loss: 0.69925 - acc: 0.5869 -- iter: 192/269
[A[ATraining Step: 7  | total loss: [1m[32m0.70180[0m[0m | time: 345.695s
[2K
| Adam | epoch: 001 | loss: 0.70180 - acc: 0.5535 -- iter: 224/269
[A[ATraining Step: 8  | total loss: [1m[32m0.61280[0m[0m | time: 389.617s
[2K
| Adam | epoch: 001 | loss: 0.61280 - acc: 0.7168 -- iter: 256/269
[A[ATraining Step: 9  | total loss: [1m[32m0.55061[0m[0m | time: 489.611s
[2K
| Adam | epoch: 001 | loss: 0.55061 - acc: 0.8005 | val_loss: 0.74262 - val_acc: 0.4706 -- iter: 269/269
--
Training Step: 10  | total loss: [1m[32m0.51005[0m[0m | time: 28.518s
[2K
| Adam | epoch: 002 | loss: 0.51005 - acc: 0.8233 -- iter: 032/269
[A[ATraining Step: 11  | total loss: [1m[32m0.43442[0m[0m | time: 99.019s
[2K
| Adam | epoch: 002 | loss: 0.43442 - acc: 0.9070 -- iter: 064/269
[A[ATraining Step: 12  | total loss: [1m[32m0.47494[0m[0m | time: 135.041s
[2K
| Adam | epoch: 002 | loss: 0.47494 - acc: 0.8504 -- iter: 096/269
[A[ATraining Step: 13  | total loss: [1m[32m0.45761[0m[0m | time: 167.229s
[2K
| Adam | epoch: 002 | loss: 0.45761 - acc: 0.8342 -- iter: 128/269
[A[ATraining Step: 14  | total loss: [1m[32m0.45600[0m[0m | time: 190.674s
[2K
| Adam | epoch: 002 | loss: 0.45600 - acc: 0.8381 -- iter: 160/269
[A[ATraining Step: 15  | total loss: [1m[32m0.46229[0m[0m | time: 213.741s
[2K
| Adam | epoch: 002 | loss: 0.46229 - acc: 0.8281 -- iter: 192/269
[A[ATraining Step: 16  | total loss: [1m[32m0.44390[0m[0m | time: 239.735s
[2K
| Adam | epoch: 002 | loss: 0.44390 - acc: 0.8340 -- iter: 224/269
[A[ATraining Step: 17  | total loss: [1m[32m0.42534[0m[0m | time: 261.829s
[2K
| Adam | epoch: 002 | loss: 0.42534 - acc: 0.8262 -- iter: 256/269
[A[ATraining Step: 18  | total loss: [1m[32m0.41421[0m[0m | time: 293.772s
[2K
| Adam | epoch: 002 | loss: 0.41421 - acc: 0.8107 | val_loss: 0.69106 - val_acc: 0.5294 -- iter: 269/269
--
Training Step: 19  | total loss: [1m[32m0.38377[0m[0m | time: 5.466s
[2K
| Adam | epoch: 003 | loss: 0.38377 - acc: 0.8217 -- iter: 032/269
[A[ATraining Step: 20  | total loss: [1m[32m0.33948[0m[0m | time: 10.701s
[2K
| Adam | epoch: 003 | loss: 0.33948 - acc: 0.8790 -- iter: 064/269
[A[ATraining Step: 21  | total loss: [1m[32m0.28008[0m[0m | time: 72.201s
[2K
| Adam | epoch: 003 | loss: 0.28008 - acc: 0.9166 -- iter: 096/269
[A[ATraining Step: 22  | total loss: [1m[32m0.26188[0m[0m | time: 175.526s
[2K
| Adam | epoch: 003 | loss: 0.26188 - acc: 0.9228 -- iter: 128/269
[A[ATraining Step: 23  | total loss: [1m[32m0.24820[0m[0m | time: 197.223s
[2K
| Adam | epoch: 003 | loss: 0.24820 - acc: 0.9271 -- iter: 160/269
[A[ATraining Step: 24  | total loss: [1m[32m0.22059[0m[0m | time: 226.506s
[2K
| Adam | epoch: 003 | loss: 0.22059 - acc: 0.9300 -- iter: 192/269
[A[ATraining Step: 25  | total loss: [1m[32m0.20095[0m[0m | time: 259.559s
[2K
| Adam | epoch: 003 | loss: 0.20095 - acc: 0.9491 -- iter: 224/269
[A[ATraining Step: 26  | total loss: [1m[32m0.19456[0m[0m | time: 280.737s
[2K
| Adam | epoch: 003 | loss: 0.19456 - acc: 0.9543 -- iter: 256/269
[A[ATraining Step: 27  | total loss: [1m[32m0.21380[0m[0m | time: 309.271s
[2K
| Adam | epoch: 003 | loss: 0.21380 - acc: 0.9339 | val_loss: 0.78493 - val_acc: 0.5294 -- iter: 269/269
--
Training Step: 28  | total loss: [1m[32m0.20627[0m[0m | time: 16.277s
[2K
| Adam | epoch: 004 | loss: 0.20627 - acc: 0.9426 -- iter: 032/269
[A[ATraining Step: 29  | total loss: [1m[32m0.19067[0m[0m | time: 21.503s
[2K
| Adam | epoch: 004 | loss: 0.19067 - acc: 0.9414 -- iter: 064/269
[A[ATraining Step: 30  | total loss: [1m[32m0.17853[0m[0m | time: 26.550s
[2K
| Adam | epoch: 004 | loss: 0.17853 - acc: 0.9553 -- iter: 096/269
[A[ATraining Step: 31  | total loss: [1m[32m0.15157[0m[0m | time: 39.093s
[2K
| Adam | epoch: 004 | loss: 0.15157 - acc: 0.9656 -- iter: 128/269
[A[ATraining Step: 32  | total loss: [1m[32m0.13162[0m[0m | time: 66.790s
[2K
| Adam | epoch: 004 | loss: 0.13162 - acc: 0.9733 -- iter: 160/269
[A[ATraining Step: 33  | total loss: [1m[32m0.13494[0m[0m | time: 90.062s
[2K
| Adam | epoch: 004 | loss: 0.13494 - acc: 0.9655 -- iter: 192/269
[A[ATraining Step: 34  | total loss: [1m[32m0.11657[0m[0m | time: 121.099s
[2K
| Adam | epoch: 004 | loss: 0.11657 - acc: 0.9729 -- iter: 224/269
[A[ATraining Step: 35  | total loss: [1m[32m0.11501[0m[0m | time: 147.534s
[2K
| Adam | epoch: 004 | loss: 0.11501 - acc: 0.9720 -- iter: 256/269
[A[ATraining Step: 36  | total loss: [1m[32m0.09884[0m[0m | time: 167.642s
[2K
| Adam | epoch: 004 | loss: 0.09884 - acc: 0.9777 | val_loss: 1.34226 - val_acc: 0.5294 -- iter: 269/269
--
Training Step: 37  | total loss: [1m[32m0.11788[0m[0m | time: 16.610s
[2K
| Adam | epoch: 005 | loss: 0.11788 - acc: 0.9759 -- iter: 032/269
[A[ATraining Step: 38  | total loss: [1m[32m0.16394[0m[0m | time: 30.431s
[2K
| Adam | epoch: 005 | loss: 0.16394 - acc: 0.9623 -- iter: 064/269
[A[ATraining Step: 39  | total loss: [1m[32m0.13877[0m[0m | time: 37.263s
[2K
| Adam | epoch: 005 | loss: 0.13877 - acc: 0.9695 -- iter: 096/269
[A[ATraining Step: 40  | total loss: [1m[32m0.12466[0m[0m | time: 44.236s
[2K
| Adam | epoch: 005 | loss: 0.12466 - acc: 0.9752 -- iter: 128/269
[A[ATraining Step: 41  | total loss: [1m[32m0.10462[0m[0m | time: 53.438s
[2K
| Adam | epoch: 005 | loss: 0.10462 - acc: 0.9798 -- iter: 160/269
[A[ATraining Step: 42  | total loss: [1m[32m0.13116[0m[0m | time: 62.212s
[2K
| Adam | epoch: 005 | loss: 0.13116 - acc: 0.9665 -- iter: 192/269
[A[ATraining Step: 43  | total loss: [1m[32m0.12336[0m[0m | time: 77.652s
[2K
| Adam | epoch: 005 | loss: 0.12336 - acc: 0.9725 -- iter: 224/269
[A[ATraining Step: 44  | total loss: [1m[32m0.10572[0m[0m | time: 123.217s
[2K
| Adam | epoch: 005 | loss: 0.10572 - acc: 0.9772 -- iter: 256/269
[A[ATraining Step: 45  | total loss: [1m[32m0.09499[0m[0m | time: 187.308s
[2K
| Adam | epoch: 005 | loss: 0.09499 - acc: 0.9811 | val_loss: 1.22865 - val_acc: 0.4706 -- iter: 269/269
--
Training Step: 46  | total loss: [1m[32m0.08654[0m[0m | time: 125.900s
[2K
| Adam | epoch: 006 | loss: 0.08654 - acc: 0.9790 -- iter: 032/269
[A[ATraining Step: 47  | total loss: [1m[32m0.07486[0m[0m | time: 195.318s
[2K
| Adam | epoch: 006 | loss: 0.07486 - acc: 0.9825 -- iter: 064/269
[A[ATraining Step: 48  | total loss: [1m[32m0.08953[0m[0m | time: 263.408s
[2K
| Adam | epoch: 006 | loss: 0.08953 - acc: 0.9803 -- iter: 096/269
[A[ATraining Step: 49  | total loss: [1m[32m0.07763[0m[0m | time: 322.339s
[2K
| Adam | epoch: 006 | loss: 0.07763 - acc: 0.9834 -- iter: 128/269
[A[ATraining Step: 50  | total loss: [1m[32m0.06942[0m[0m | time: 356.062s
[2K
| Adam | epoch: 006 | loss: 0.06942 - acc: 0.9860 -- iter: 160/269
[A[ATraining Step: 51  | total loss: [1m[32m0.06113[0m[0m | time: 477.226s
[2K
| Adam | epoch: 006 | loss: 0.06113 - acc: 0.9881 -- iter: 192/269
[A[ATraining Step: 52  | total loss: [1m[32m0.05564[0m[0m | time: 604.829s
[2K
| Adam | epoch: 006 | loss: 0.05564 - acc: 0.9899 -- iter: 224/269
[A[ATraining Step: 53  | total loss: [1m[32m0.05309[0m[0m | time: 670.978s
[2K
| Adam | epoch: 006 | loss: 0.05309 - acc: 0.9914 -- iter: 256/269
[A[ATraining Step: 54  | total loss: [1m[32m0.08497[0m[0m | time: 687.521s
[2K
| Adam | epoch: 006 | loss: 0.08497 - acc: 0.9881 | val_loss: 0.62157 - val_acc: 0.7059 -- iter: 269/269
--
Training Step: 55  | total loss: [1m[32m0.07850[0m[0m | time: 31.568s
[2K
| Adam | epoch: 007 | loss: 0.07850 - acc: 0.9898 -- iter: 032/269
[A[ATraining Step: 56  | total loss: [1m[32m0.06935[0m[0m | time: 44.652s
[2K
| Adam | epoch: 007 | loss: 0.06935 - acc: 0.9912 -- iter: 064/269
[A[ATraining Step: 57  | total loss: [1m[32m0.06613[0m[0m | time: 58.436s
[2K
| Adam | epoch: 007 | loss: 0.06613 - acc: 0.9924 -- iter: 096/269
[A[ATraining Step: 58  | total loss: [1m[32m0.09126[0m[0m | time: 72.253s
[2K
| Adam | epoch: 007 | loss: 0.09126 - acc: 0.9892 -- iter: 128/269
[A[ATraining Step: 59  | total loss: [1m[32m0.07998[0m[0m | time: 78.947s
[2K
| Adam | epoch: 007 | loss: 0.07998 - acc: 0.9907 -- iter: 160/269
[A[ATraining Step: 60  | total loss: [1m[32m0.07076[0m[0m | time: 85.392s
[2K
| Adam | epoch: 007 | loss: 0.07076 - acc: 0.9919 -- iter: 192/269
[A[ATraining Step: 61  | total loss: [1m[32m0.06278[0m[0m | time: 98.513s
[2K
| Adam | epoch: 007 | loss: 0.06278 - acc: 0.9930 -- iter: 224/269
[A[ATraining Step: 62  | total loss: [1m[32m0.05577[0m[0m | time: 111.928s
[2K
| Adam | epoch: 007 | loss: 0.05577 - acc: 0.9939 -- iter: 256/269
[A[ATraining Step: 63  | total loss: [1m[32m0.05007[0m[0m | time: 131.989s
[2K
| Adam | epoch: 007 | loss: 0.05007 - acc: 0.9946 | val_loss: 2.54505 - val_acc: 0.5412 -- iter: 269/269
--
Training Step: 64  | total loss: [1m[32m0.05616[0m[0m | time: 8.773s
[2K
| Adam | epoch: 008 | loss: 0.05616 - acc: 0.9875 -- iter: 032/269
[A[ATraining Step: 65  | total loss: [1m[32m0.05179[0m[0m | time: 17.589s
[2K
| Adam | epoch: 008 | loss: 0.05179 - acc: 0.9890 -- iter: 064/269
[A[ATraining Step: 66  | total loss: [1m[32m0.04771[0m[0m | time: 28.266s
[2K
| Adam | epoch: 008 | loss: 0.04771 - acc: 0.9904 -- iter: 096/269
[A[ATraining Step: 67  | total loss: [1m[32m0.07441[0m[0m | time: 41.982s
[2K
| Adam | epoch: 008 | loss: 0.07441 - acc: 0.9840 -- iter: 128/269
[A[ATraining Step: 68  | total loss: [1m[32m0.06807[0m[0m | time: 87.474s
[2K
| Adam | epoch: 008 | loss: 0.06807 - acc: 0.9859 -- iter: 160/269
[A[ATraining Step: 69  | total loss: [1m[32m0.07429[0m[0m | time: 113.419s
[2K
| Adam | epoch: 008 | loss: 0.07429 - acc: 0.9839 -- iter: 192/269
[A[ATraining Step: 70  | total loss: [1m[32m0.07328[0m[0m | time: 120.150s
[2K
| Adam | epoch: 008 | loss: 0.07328 - acc: 0.9858 -- iter: 224/269
[A[ATraining Step: 71  | total loss: [1m[32m0.06733[0m[0m | time: 144.312s
[2K
| Adam | epoch: 008 | loss: 0.06733 - acc: 0.9874 -- iter: 256/269
[A[ATraining Step: 72  | total loss: [1m[32m0.06128[0m[0m | time: 167.424s
[2K
| Adam | epoch: 008 | loss: 0.06128 - acc: 0.9888 | val_loss: 2.49399 - val_acc: 0.5412 -- iter: 269/269
--
Training Step: 73  | total loss: [1m[32m0.05516[0m[0m | time: 89.220s
[2K
| Adam | epoch: 009 | loss: 0.05516 - acc: 0.9901 -- iter: 032/269
[A[ATraining Step: 74  | total loss: [1m[32m0.05042[0m[0m | time: 156.468s
[2K
| Adam | epoch: 009 | loss: 0.05042 - acc: 0.9911 -- iter: 064/269
[A[ATraining Step: 75  | total loss: [1m[32m0.04619[0m[0m | time: 203.916s
[2K
| Adam | epoch: 009 | loss: 0.04619 - acc: 0.9921 -- iter: 096/269
[A[ATraining Step: 76  | total loss: [1m[32m0.04306[0m[0m | time: 348.807s
[2K
| Adam | epoch: 009 | loss: 0.04306 - acc: 0.9929 -- iter: 128/269
[A[ATraining Step: 77  | total loss: [1m[32m0.03976[0m[0m | time: 516.430s
[2K
| Adam | epoch: 009 | loss: 0.03976 - acc: 0.9937 -- iter: 160/269
[A[ATraining Step: 78  | total loss: [1m[32m0.06900[0m[0m | time: 530.548s
[2K
| Adam | epoch: 009 | loss: 0.06900 - acc: 0.9911 -- iter: 192/269
[A[ATraining Step: 79  | total loss: [1m[32m0.06282[0m[0m | time: 536.738s
[2K
| Adam | epoch: 009 | loss: 0.06282 - acc: 0.9920 -- iter: 224/269
[A[ATraining Step: 80  | total loss: [1m[32m0.05713[0m[0m | time: 543.751s
[2K
| Adam | epoch: 009 | loss: 0.05713 - acc: 0.9928 -- iter: 256/269
[A[ATraining Step: 81  | total loss: [1m[32m0.05191[0m[0m | time: 563.722s
[2K
| Adam | epoch: 009 | loss: 0.05191 - acc: 0.9936 | val_loss: 1.21485 - val_acc: 0.6706 -- iter: 269/269
--
Training Step: 82  | total loss: [1m[32m0.04709[0m[0m | time: 14.249s
[2K
| Adam | epoch: 010 | loss: 0.04709 - acc: 0.9942 -- iter: 032/269
[A[ATraining Step: 83  | total loss: [1m[32m0.04270[0m[0m | time: 28.332s
[2K
| Adam | epoch: 010 | loss: 0.04270 - acc: 0.9948 -- iter: 064/269
[A[ATraining Step: 84  | total loss: [1m[32m0.03886[0m[0m | time: 42.309s
[2K
| Adam | epoch: 010 | loss: 0.03886 - acc: 0.9953 -- iter: 096/269
[A[ATraining Step: 85  | total loss: [1m[32m0.03583[0m[0m | time: 56.637s
[2K
| Adam | epoch: 010 | loss: 0.03583 - acc: 0.9958 -- iter: 128/269
[A[ATraining Step: 86  | total loss: [1m[32m0.03729[0m[0m | time: 66.334s
[2K
| Adam | epoch: 010 | loss: 0.03729 - acc: 0.9931 -- iter: 160/269
[A[ATraining Step: 87  | total loss: [1m[32m0.03393[0m[0m | time: 75.722s
[2K
| Adam | epoch: 010 | loss: 0.03393 - acc: 0.9938 -- iter: 192/269
[A[ATraining Step: 88  | total loss: [1m[32m0.03140[0m[0m | time: 87.982s
[2K
| Adam | epoch: 010 | loss: 0.03140 - acc: 0.9944 -- iter: 224/269
[A[ATraining Step: 89  | total loss: [1m[32m0.02855[0m[0m | time: 95.158s
[2K
| Adam | epoch: 010 | loss: 0.02855 - acc: 0.9949 -- iter: 256/269
[A[ATraining Step: 90  | total loss: [1m[32m0.02610[0m[0m | time: 108.536s
[2K
| Adam | epoch: 010 | loss: 0.02610 - acc: 0.9955 | val_loss: 0.93954 - val_acc: 0.7059 -- iter: 269/269
--
Training Step: 91  | total loss: [1m[32m0.02381[0m[0m | time: 14.033s
[2K
| Adam | epoch: 011 | loss: 0.02381 - acc: 0.9959 -- iter: 032/269
[A[ATraining Step: 92  | total loss: [1m[32m0.02204[0m[0m | time: 27.857s
[2K
| Adam | epoch: 011 | loss: 0.02204 - acc: 0.9963 -- iter: 064/269
[A[ATraining Step: 93  | total loss: [1m[32m0.02005[0m[0m | time: 41.585s
[2K
| Adam | epoch: 011 | loss: 0.02005 - acc: 0.9967 -- iter: 096/269
[A[ATraining Step: 94  | total loss: [1m[32m0.01845[0m[0m | time: 55.635s
[2K
| Adam | epoch: 011 | loss: 0.01845 - acc: 0.9970 -- iter: 128/269
[A[ATraining Step: 95  | total loss: [1m[32m0.01682[0m[0m | time: 71.241s
[2K
| Adam | epoch: 011 | loss: 0.01682 - acc: 0.9973 -- iter: 160/269
[A[ATraining Step: 96  | total loss: [1m[32m0.04152[0m[0m | time: 83.160s
[2K
| Adam | epoch: 011 | loss: 0.04152 - acc: 0.9945 -- iter: 192/269
[A[ATraining Step: 97  | total loss: [1m[32m0.03853[0m[0m | time: 92.386s
[2K
| Adam | epoch: 011 | loss: 0.03853 - acc: 0.9950 -- iter: 224/269
[A[ATraining Step: 98  | total loss: [1m[32m0.03478[0m[0m | time: 101.935s
[2K
| Adam | epoch: 011 | loss: 0.03478 - acc: 0.9955 -- iter: 256/269
[A[ATraining Step: 99  | total loss: [1m[32m0.03202[0m[0m | time: 115.213s
[2K
| Adam | epoch: 011 | loss: 0.03202 - acc: 0.9960 | val_loss: 2.46913 - val_acc: 0.5882 -- iter: 269/269
--
Training Step: 100  | total loss: [1m[32m0.02995[0m[0m | time: 6.939s
[2K
| Adam | epoch: 012 | loss: 0.02995 - acc: 0.9964 -- iter: 032/269
[A[ATraining Step: 101  | total loss: [1m[32m0.02738[0m[0m | time: 21.441s
[2K
| Adam | epoch: 012 | loss: 0.02738 - acc: 0.9967 -- iter: 064/269
[A[ATraining Step: 102  | total loss: [1m[32m0.02513[0m[0m | time: 219.919s
[2K
| Adam | epoch: 012 | loss: 0.02513 - acc: 0.9971 -- iter: 096/269
[A[ATraining Step: 103  | total loss: [1m[32m0.02284[0m[0m | time: 501.812s
[2K
| Adam | epoch: 012 | loss: 0.02284 - acc: 0.9973 -- iter: 128/269
[A[ATraining Step: 104  | total loss: [1m[32m0.02278[0m[0m | time: 631.355s
[2K
| Adam | epoch: 012 | loss: 0.02278 - acc: 0.9976 -- iter: 160/269
[A[ATraining Step: 105  | total loss: [1m[32m0.02071[0m[0m | time: 1036.226s
[2K
| Adam | epoch: 012 | loss: 0.02071 - acc: 0.9979 -- iter: 192/269
[A[ATraining Step: 106  | total loss: [1m[32m0.01881[0m[0m | time: 1049.695s
[2K
| Adam | epoch: 012 | loss: 0.01881 - acc: 0.9981 -- iter: 224/269
[A[ATraining Step: 107  | total loss: [1m[32m0.01721[0m[0m | time: 1061.847s
[2K
| Adam | epoch: 012 | loss: 0.01721 - acc: 0.9983 -- iter: 256/269
[A[ATraining Step: 108  | total loss: [1m[32m0.03380[0m[0m | time: 1075.229s
[2K
| Adam | epoch: 012 | loss: 0.03380 - acc: 0.9922 | val_loss: 0.79462 - val_acc: 0.7294 -- iter: 269/269
--
Training Step: 109  | total loss: [1m[32m0.03064[0m[0m | time: 6.951s
[2K
| Adam | epoch: 013 | loss: 0.03064 - acc: 0.9930 -- iter: 032/269
[A[ATraining Step: 110  | total loss: [1m[32m0.03023[0m[0m | time: 14.233s
[2K
| Adam | epoch: 013 | loss: 0.03023 - acc: 0.9937 -- iter: 064/269
[A[ATraining Step: 111  | total loss: [1m[32m0.02832[0m[0m | time: 28.459s
[2K
| Adam | epoch: 013 | loss: 0.02832 - acc: 0.9943 -- iter: 096/269
[A[ATraining Step: 112  | total loss: [1m[32m0.02592[0m[0m | time: 42.236s
[2K
| Adam | epoch: 013 | loss: 0.02592 - acc: 0.9949 -- iter: 128/269
[A[ATraining Step: 113  | total loss: [1m[32m0.02494[0m[0m | time: 58.877s
[2K
| Adam | epoch: 013 | loss: 0.02494 - acc: 0.9954 -- iter: 160/269
[A[ATraining Step: 114  | total loss: [1m[32m0.04520[0m[0m | time: 72.064s
[2K
| Adam | epoch: 013 | loss: 0.04520 - acc: 0.9927 -- iter: 192/269
[A[ATraining Step: 115  | total loss: [1m[32m0.04129[0m[0m | time: 85.814s
[2K
| Adam | epoch: 013 | loss: 0.04129 - acc: 0.9934 -- iter: 224/269
[A[ATraining Step: 116  | total loss: [1m[32m0.03759[0m[0m | time: 99.136s
[2K
| Adam | epoch: 013 | loss: 0.03759 - acc: 0.9941 -- iter: 256/269
[A[ATraining Step: 117  | total loss: [1m[32m0.06993[0m[0m | time: 112.376s
[2K
| Adam | epoch: 013 | loss: 0.06993 - acc: 0.9916 | val_loss: 0.80659 - val_acc: 0.7529 -- iter: 269/269
--
Training Step: 118  | total loss: [1m[32m0.13224[0m[0m | time: 13.315s
[2K
| Adam | epoch: 014 | loss: 0.13224 - acc: 0.9830 -- iter: 032/269
[A[ATraining Step: 119  | total loss: [1m[32m0.11916[0m[0m | time: 19.986s
[2K
| Adam | epoch: 014 | loss: 0.11916 - acc: 0.9847 -- iter: 064/269
[A[ATraining Step: 120  | total loss: [1m[32m0.10794[0m[0m | time: 26.484s
[2K
| Adam | epoch: 014 | loss: 0.10794 - acc: 0.9863 -- iter: 096/269
[A[ATraining Step: 121  | total loss: [1m[32m0.09762[0m[0m | time: 40.444s
[2K
| Adam | epoch: 014 | loss: 0.09762 - acc: 0.9876 -- iter: 128/269
[A[ATraining Step: 122  | total loss: [1m[32m0.08832[0m[0m | time: 53.985s
[2K
| Adam | epoch: 014 | loss: 0.08832 - acc: 0.9889 -- iter: 160/269
[A[ATraining Step: 123  | total loss: [1m[32m0.08006[0m[0m | time: 67.102s
[2K
| Adam | epoch: 014 | loss: 0.08006 - acc: 0.9900 -- iter: 192/269
[A[ATraining Step: 124  | total loss: [1m[32m0.07263[0m[0m | time: 81.012s
[2K
| Adam | epoch: 014 | loss: 0.07263 - acc: 0.9910 -- iter: 224/269
[A[ATraining Step: 125  | total loss: [1m[32m0.06603[0m[0m | time: 94.320s
[2K
| Adam | epoch: 014 | loss: 0.06603 - acc: 0.9919 -- iter: 256/269
[A[ATraining Step: 126  | total loss: [1m[32m0.05991[0m[0m | time: 113.292s
[2K
| Adam | epoch: 014 | loss: 0.05991 - acc: 0.9927 | val_loss: 0.74111 - val_acc: 0.7412 -- iter: 269/269
--
Training Step: 127  | total loss: [1m[32m0.07661[0m[0m | time: 13.873s
[2K
| Adam | epoch: 015 | loss: 0.07661 - acc: 0.9903 -- iter: 032/269
[A[ATraining Step: 128  | total loss: [1m[32m0.10617[0m[0m | time: 27.650s
[2K
| Adam | epoch: 015 | loss: 0.10617 - acc: 0.9881 -- iter: 064/269
[A[ATraining Step: 129  | total loss: [1m[32m0.11009[0m[0m | time: 34.395s
[2K
| Adam | epoch: 015 | loss: 0.11009 - acc: 0.9862 -- iter: 096/269
[A[ATraining Step: 130  | total loss: [1m[32m0.10035[0m[0m | time: 41.381s
[2K
| Adam | epoch: 015 | loss: 0.10035 - acc: 0.9876 -- iter: 128/269
[A[ATraining Step: 131  | total loss: [1m[32m0.09132[0m[0m | time: 55.256s
[2K
| Adam | epoch: 015 | loss: 0.09132 - acc: 0.9888 -- iter: 160/269
[A[ATraining Step: 132  | total loss: [1m[32m0.08500[0m[0m | time: 68.853s
[2K
| Adam | epoch: 015 | loss: 0.08500 - acc: 0.9899 -- iter: 192/269
[A[ATraining Step: 133  | total loss: [1m[32m0.07855[0m[0m | time: 82.667s
[2K
| Adam | epoch: 015 | loss: 0.07855 - acc: 0.9910 -- iter: 224/269
[A[ATraining Step: 134  | total loss: [1m[32m0.07124[0m[0m | time: 96.203s
[2K
| Adam | epoch: 015 | loss: 0.07124 - acc: 0.9919 -- iter: 256/269
[A[ATraining Step: 135  | total loss: [1m[32m0.06977[0m[0m | time: 116.753s
[2K
| Adam | epoch: 015 | loss: 0.06977 - acc: 0.9895 | val_loss: 0.68394 - val_acc: 0.7529 -- iter: 269/269
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7977777777777778
Validation AUPRC:0.7590049030867664
Test AUC:0.8289036544850498
Test AUPRC:0.8290534555169911
BestTestF1Score	0.77	0.55	0.78	0.8	0.74	32	8	34	11	0.47
BestTestMCCScore	0.77	0.55	0.78	0.8	0.74	32	8	34	11	0.47
BestTestAccuracyScore	0.77	0.55	0.78	0.8	0.74	32	8	34	11	0.47
BestValidationF1Score	0.75	0.53	0.76	0.75	0.75	30	10	35	10	0.47
BestValidationMCC	0.75	0.53	0.76	0.75	0.75	30	10	35	10	0.47
BestValidationAccuracy	0.75	0.53	0.76	0.75	0.75	30	10	35	10	0.47
TestPredictions (Threshold:0.47)
CHEMBL3104851,FN,ACT,0.0	CHEMBL3798848,TN,INACT,0.0	CHEMBL3335283,FN,ACT,0.36000001430511475	CHEMBL3098689,TP,ACT,0.8399999737739563	CHEMBL483477,TP,ACT,0.9800000190734863	CHEMBL1094707,TP,ACT,0.9900000095367432	CHEMBL3356927,TP,ACT,0.9399999976158142	CHEMBL3770119,TN,INACT,0.0	CHEMBL1796689,TP,ACT,0.75	CHEMBL2046617,FP,INACT,0.9700000286102295	CHEMBL1083439,TP,ACT,0.949999988079071	CHEMBL324670,TN,INACT,0.009999999776482582	CHEMBL389687,TP,ACT,0.6800000071525574	CHEMBL3769491,FP,INACT,0.8700000047683716	CHEMBL1767036,TN,INACT,0.3199999928474426	CHEMBL439842,TN,INACT,0.07000000029802322	CHEMBL467998,TP,ACT,0.8899999856948853	CHEMBL3309451,TN,INACT,0.009999999776482582	CHEMBL2417785,FP,INACT,0.9399999976158142	CHEMBL3415629,TN,INACT,0.0	CHEMBL1094709,TP,ACT,0.9900000095367432	CHEMBL2177588,FN,ACT,0.009999999776482582	CHEMBL3827993,TN,INACT,0.019999999552965164	CHEMBL402363,FN,ACT,0.1899999976158142	CHEMBL3235790,TN,INACT,0.019999999552965164	CHEMBL3098690,TP,ACT,0.9100000262260437	CHEMBL488747,TP,ACT,0.800000011920929	CHEMBL328521,TN,INACT,0.0	CHEMBL469274,TP,ACT,0.9100000262260437	CHEMBL1767035,FP,INACT,0.7099999785423279	CHEMBL1830537,TP,ACT,0.8899999856948853	CHEMBL3110016,TN,INACT,0.019999999552965164	CHEMBL487943,TP,ACT,0.949999988079071	CHEMBL257972,FN,ACT,0.3199999928474426	CHEMBL2088205,TN,INACT,0.019999999552965164	CHEMBL3417292,TN,INACT,0.4300000071525574	CHEMBL2170174,FP,INACT,0.8700000047683716	CHEMBL3827894,TP,ACT,0.9599999785423279	CHEMBL1684142,TN,INACT,0.0	CHEMBL519746,TP,ACT,0.949999988079071	CHEMBL2088207,TN,INACT,0.4099999964237213	CHEMBL3670668,FN,ACT,0.1899999976158142	CHEMBL3335298,FN,ACT,0.0	CHEMBL109,FP,INACT,0.8399999737739563	CHEMBL227118,FN,ACT,0.23999999463558197	CHEMBL3356925,TP,ACT,0.9599999785423279	CHEMBL3098602,TP,ACT,0.9700000286102295	CHEMBL593229,TN,INACT,0.0	CHEMBL505199,TN,INACT,0.019999999552965164	CHEMBL1631914,TP,ACT,0.9800000190734863	CHEMBL489332,TP,ACT,0.5600000023841858	CHEMBL3664109,TN,INACT,0.11999999731779099	CHEMBL3318732,TN,INACT,0.23000000417232513	CHEMBL3770566,TN,INACT,0.0	CHEMBL3262727,TP,ACT,0.5	CHEMBL3356922,FN,ACT,0.05999999865889549	CHEMBL2178345,TN,INACT,0.07999999821186066	CHEMBL487253,TP,ACT,0.7599999904632568	CHEMBL3621348,FN,ACT,0.28999999165534973	CHEMBL2381517,TN,INACT,0.05999999865889549	CHEMBL491316,TP,ACT,0.5	CHEMBL594544,FN,ACT,0.11999999731779099	CHEMBL472346,TN,INACT,0.05000000074505806	CHEMBL1851943,TP,ACT,0.5099999904632568	CHEMBL1934906,FP,INACT,0.47999998927116394	CHEMBL399879,TN,INACT,0.0	CHEMBL3353925,TP,ACT,0.8999999761581421	CHEMBL2047538,TN,INACT,0.1599999964237213	CHEMBL1096982,TN,INACT,0.2199999988079071	CHEMBL235674,TN,INACT,0.20000000298023224	CHEMBL1934907,FP,INACT,0.5	CHEMBL3352992,TP,ACT,0.800000011920929	CHEMBL3098697,TP,ACT,0.9700000286102295	CHEMBL446512,TP,ACT,0.7900000214576721	CHEMBL3797314,TN,INACT,0.009999999776482582	CHEMBL1630108,TN,INACT,0.46000000834465027	CHEMBL468595,TP,ACT,0.9700000286102295	CHEMBL1173445,TP,ACT,0.9200000166893005	CHEMBL2011673,TN,INACT,0.14000000059604645	CHEMBL475099,TN,INACT,0.019999999552965164	CHEMBL487106,TP,ACT,0.9200000166893005	CHEMBL3770029,TN,INACT,0.05999999865889549	CHEMBL405417,TN,INACT,0.0	CHEMBL3770606,TN,INACT,0.0	CHEMBL487742,TP,ACT,0.8299999833106995	

