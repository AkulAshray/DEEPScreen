ImageNetInceptionV2 CHEMBL3122 adam 0.0001 30 0 0 0.8 False True
Number of active compounds :	128
Number of inactive compounds :	128
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3122_adam_0.0001_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3122_adam_0.0001_30_0.8/
---------------------------------
Training samples: 163
Validation samples: 52
--
Training Step: 1  | time: 35.692s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/163
[A[ATraining Step: 2  | total loss: [1m[32m0.68469[0m[0m | time: 43.583s
[2K
| Adam | epoch: 001 | loss: 0.68469 - acc: 0.3937 -- iter: 064/163
[A[ATraining Step: 3  | total loss: [1m[32m0.57368[0m[0m | time: 51.470s
[2K
| Adam | epoch: 001 | loss: 0.57368 - acc: 0.7108 -- iter: 096/163
[A[ATraining Step: 4  | total loss: [1m[32m0.60343[0m[0m | time: 59.446s
[2K
| Adam | epoch: 001 | loss: 0.60343 - acc: 0.6933 -- iter: 128/163
[A[ATraining Step: 5  | total loss: [1m[32m0.61598[0m[0m | time: 67.290s
[2K
| Adam | epoch: 001 | loss: 0.61598 - acc: 0.6460 -- iter: 160/163
[A[ATraining Step: 6  | total loss: [1m[32m0.59633[0m[0m | time: 76.626s
[2K
| Adam | epoch: 001 | loss: 0.59633 - acc: 0.7129 | val_loss: 0.84583 - val_acc: 0.5385 -- iter: 163/163
--
Training Step: 7  | total loss: [1m[32m0.63019[0m[0m | time: 1.582s
[2K
| Adam | epoch: 002 | loss: 0.63019 - acc: 0.6851 -- iter: 032/163
[A[ATraining Step: 8  | total loss: [1m[32m0.57838[0m[0m | time: 9.477s
[2K
| Adam | epoch: 002 | loss: 0.57838 - acc: 0.8623 -- iter: 064/163
[A[ATraining Step: 9  | total loss: [1m[32m0.50316[0m[0m | time: 17.277s
[2K
| Adam | epoch: 002 | loss: 0.50316 - acc: 0.8855 -- iter: 096/163
[A[ATraining Step: 10  | total loss: [1m[32m0.44597[0m[0m | time: 24.995s
[2K
| Adam | epoch: 002 | loss: 0.44597 - acc: 0.8803 -- iter: 128/163
[A[ATraining Step: 11  | total loss: [1m[32m0.39768[0m[0m | time: 32.768s
[2K
| Adam | epoch: 002 | loss: 0.39768 - acc: 0.9074 -- iter: 160/163
[A[ATraining Step: 12  | total loss: [1m[32m0.38289[0m[0m | time: 42.863s
[2K
| Adam | epoch: 002 | loss: 0.38289 - acc: 0.8787 | val_loss: 0.78520 - val_acc: 0.5385 -- iter: 163/163
--
Training Step: 13  | total loss: [1m[32m0.31862[0m[0m | time: 1.538s
[2K
| Adam | epoch: 003 | loss: 0.31862 - acc: 0.9173 -- iter: 032/163
[A[ATraining Step: 14  | total loss: [1m[32m0.34462[0m[0m | time: 3.074s
[2K
| Adam | epoch: 003 | loss: 0.34462 - acc: 0.8148 -- iter: 064/163
[A[ATraining Step: 15  | total loss: [1m[32m0.29161[0m[0m | time: 10.801s
[2K
| Adam | epoch: 003 | loss: 0.29161 - acc: 0.8873 -- iter: 096/163
[A[ATraining Step: 16  | total loss: [1m[32m0.25612[0m[0m | time: 18.426s
[2K
| Adam | epoch: 003 | loss: 0.25612 - acc: 0.9178 -- iter: 128/163
[A[ATraining Step: 17  | total loss: [1m[32m0.24707[0m[0m | time: 26.091s
[2K
| Adam | epoch: 003 | loss: 0.24707 - acc: 0.9362 -- iter: 160/163
[A[ATraining Step: 18  | total loss: [1m[32m0.19315[0m[0m | time: 36.027s
[2K
| Adam | epoch: 003 | loss: 0.19315 - acc: 0.9583 | val_loss: 0.99899 - val_acc: 0.5385 -- iter: 163/163
--
Training Step: 19  | total loss: [1m[32m0.15988[0m[0m | time: 7.658s
[2K
| Adam | epoch: 004 | loss: 0.15988 - acc: 0.9722 -- iter: 032/163
[A[ATraining Step: 20  | total loss: [1m[32m0.15647[0m[0m | time: 9.304s
[2K
| Adam | epoch: 004 | loss: 0.15647 - acc: 0.9711 -- iter: 064/163
[A[ATraining Step: 21  | total loss: [1m[32m0.13287[0m[0m | time: 10.880s
[2K
| Adam | epoch: 004 | loss: 0.13287 - acc: 0.9800 -- iter: 096/163
[A[ATraining Step: 22  | total loss: [1m[32m0.10665[0m[0m | time: 18.577s
[2K
| Adam | epoch: 004 | loss: 0.10665 - acc: 0.9860 -- iter: 128/163
[A[ATraining Step: 23  | total loss: [1m[32m0.08800[0m[0m | time: 26.352s
[2K
| Adam | epoch: 004 | loss: 0.08800 - acc: 0.9901 -- iter: 160/163
[A[ATraining Step: 24  | total loss: [1m[32m0.10887[0m[0m | time: 36.496s
[2K
| Adam | epoch: 004 | loss: 0.10887 - acc: 0.9841 | val_loss: 0.97694 - val_acc: 0.5385 -- iter: 163/163
--
Training Step: 25  | total loss: [1m[32m0.09497[0m[0m | time: 7.777s
[2K
| Adam | epoch: 005 | loss: 0.09497 - acc: 0.9884 -- iter: 032/163
[A[ATraining Step: 26  | total loss: [1m[32m0.07903[0m[0m | time: 15.488s
[2K
| Adam | epoch: 005 | loss: 0.07903 - acc: 0.9915 -- iter: 064/163
[A[ATraining Step: 27  | total loss: [1m[32m0.06485[0m[0m | time: 16.996s
[2K
| Adam | epoch: 005 | loss: 0.06485 - acc: 0.9937 -- iter: 096/163
[A[ATraining Step: 28  | total loss: [1m[32m0.34053[0m[0m | time: 18.543s
[2K
| Adam | epoch: 005 | loss: 0.34053 - acc: 0.9119 -- iter: 128/163
[A[ATraining Step: 29  | total loss: [1m[32m0.41638[0m[0m | time: 26.230s
[2K
| Adam | epoch: 005 | loss: 0.41638 - acc: 0.8523 -- iter: 160/163
[A[ATraining Step: 30  | total loss: [1m[32m0.32448[0m[0m | time: 36.310s
[2K
| Adam | epoch: 005 | loss: 0.32448 - acc: 0.8873 | val_loss: 0.73365 - val_acc: 0.4615 -- iter: 163/163
--
Training Step: 31  | total loss: [1m[32m0.29775[0m[0m | time: 7.689s
[2K
| Adam | epoch: 006 | loss: 0.29775 - acc: 0.8989 -- iter: 032/163
[A[ATraining Step: 32  | total loss: [1m[32m0.23326[0m[0m | time: 15.428s
[2K
| Adam | epoch: 006 | loss: 0.23326 - acc: 0.9216 -- iter: 064/163
[A[ATraining Step: 33  | total loss: [1m[32m0.18843[0m[0m | time: 23.100s
[2K
| Adam | epoch: 006 | loss: 0.18843 - acc: 0.9388 -- iter: 096/163
[A[ATraining Step: 34  | total loss: [1m[32m0.15188[0m[0m | time: 24.604s
[2K
| Adam | epoch: 006 | loss: 0.15188 - acc: 0.9519 -- iter: 128/163
[A[ATraining Step: 35  | total loss: [1m[32m0.29643[0m[0m | time: 26.099s
[2K
| Adam | epoch: 006 | loss: 0.29643 - acc: 0.8225 -- iter: 160/163
[A[ATraining Step: 36  | total loss: [1m[32m0.40610[0m[0m | time: 36.262s
[2K
| Adam | epoch: 006 | loss: 0.40610 - acc: 0.7224 | val_loss: 1.65236 - val_acc: 0.4615 -- iter: 163/163
--
Training Step: 37  | total loss: [1m[32m0.37793[0m[0m | time: 7.815s
[2K
| Adam | epoch: 007 | loss: 0.37793 - acc: 0.7654 -- iter: 032/163
[A[ATraining Step: 38  | total loss: [1m[32m0.30747[0m[0m | time: 15.463s
[2K
| Adam | epoch: 007 | loss: 0.30747 - acc: 0.8113 -- iter: 064/163
[A[ATraining Step: 39  | total loss: [1m[32m0.25073[0m[0m | time: 23.233s
[2K
| Adam | epoch: 007 | loss: 0.25073 - acc: 0.8475 -- iter: 096/163
[A[ATraining Step: 40  | total loss: [1m[32m0.20991[0m[0m | time: 31.134s
[2K
| Adam | epoch: 007 | loss: 0.20991 - acc: 0.8761 -- iter: 128/163
[A[ATraining Step: 41  | total loss: [1m[32m0.20664[0m[0m | time: 32.626s
[2K
| Adam | epoch: 007 | loss: 0.20664 - acc: 0.8873 -- iter: 160/163
[A[ATraining Step: 42  | total loss: [1m[32m0.18298[0m[0m | time: 36.508s
[2K
| Adam | epoch: 007 | loss: 0.18298 - acc: 0.9076 | val_loss: 2.29900 - val_acc: 0.4615 -- iter: 163/163
--
Training Step: 43  | total loss: [1m[32m0.16040[0m[0m | time: 7.818s
[2K
| Adam | epoch: 008 | loss: 0.16040 - acc: 0.9239 -- iter: 032/163
[A[ATraining Step: 44  | total loss: [1m[32m0.13800[0m[0m | time: 15.534s
[2K
| Adam | epoch: 008 | loss: 0.13800 - acc: 0.9371 -- iter: 064/163
[A[ATraining Step: 45  | total loss: [1m[32m0.14529[0m[0m | time: 23.290s
[2K
| Adam | epoch: 008 | loss: 0.14529 - acc: 0.9425 -- iter: 096/163
[A[ATraining Step: 46  | total loss: [1m[32m0.12625[0m[0m | time: 31.168s
[2K
| Adam | epoch: 008 | loss: 0.12625 - acc: 0.9521 -- iter: 128/163
[A[ATraining Step: 47  | total loss: [1m[32m0.10782[0m[0m | time: 39.074s
[2K
| Adam | epoch: 008 | loss: 0.10782 - acc: 0.9599 -- iter: 160/163
[A[ATraining Step: 48  | total loss: [1m[32m0.09159[0m[0m | time: 42.900s
[2K
| Adam | epoch: 008 | loss: 0.09159 - acc: 0.9663 | val_loss: 1.84132 - val_acc: 0.4615 -- iter: 163/163
--
Training Step: 49  | total loss: [1m[32m0.09780[0m[0m | time: 1.647s
[2K
| Adam | epoch: 009 | loss: 0.09780 - acc: 0.9717 -- iter: 032/163
[A[ATraining Step: 50  | total loss: [1m[32m0.08420[0m[0m | time: 9.328s
[2K
| Adam | epoch: 009 | loss: 0.08420 - acc: 0.9761 -- iter: 064/163
[A[ATraining Step: 51  | total loss: [1m[32m0.07324[0m[0m | time: 17.389s
[2K
| Adam | epoch: 009 | loss: 0.07324 - acc: 0.9797 -- iter: 096/163
[A[ATraining Step: 52  | total loss: [1m[32m0.11773[0m[0m | time: 25.050s
[2K
| Adam | epoch: 009 | loss: 0.11773 - acc: 0.9687 -- iter: 128/163
[A[ATraining Step: 53  | total loss: [1m[32m0.10260[0m[0m | time: 33.242s
[2K
| Adam | epoch: 009 | loss: 0.10260 - acc: 0.9733 -- iter: 160/163
[A[ATraining Step: 54  | total loss: [1m[32m0.09368[0m[0m | time: 43.466s
[2K
| Adam | epoch: 009 | loss: 0.09368 - acc: 0.9772 | val_loss: 1.93906 - val_acc: 0.4808 -- iter: 163/163
--
Training Step: 55  | total loss: [1m[32m0.08186[0m[0m | time: 1.550s
[2K
| Adam | epoch: 010 | loss: 0.08186 - acc: 0.9804 -- iter: 032/163
[A[ATraining Step: 56  | total loss: [1m[32m0.16148[0m[0m | time: 3.068s
[2K
| Adam | epoch: 010 | loss: 0.16148 - acc: 0.8894 -- iter: 064/163
[A[ATraining Step: 57  | total loss: [1m[32m0.24047[0m[0m | time: 10.848s
[2K
| Adam | epoch: 010 | loss: 0.24047 - acc: 0.8586 -- iter: 096/163
[A[ATraining Step: 58  | total loss: [1m[32m0.20936[0m[0m | time: 18.610s
[2K
| Adam | epoch: 010 | loss: 0.20936 - acc: 0.8779 -- iter: 128/163
[A[ATraining Step: 59  | total loss: [1m[32m0.18268[0m[0m | time: 26.283s
[2K
| Adam | epoch: 010 | loss: 0.18268 - acc: 0.8943 -- iter: 160/163
[A[ATraining Step: 60  | total loss: [1m[32m0.16978[0m[0m | time: 36.454s
[2K
| Adam | epoch: 010 | loss: 0.16978 - acc: 0.9041 | val_loss: 1.04689 - val_acc: 0.5962 -- iter: 163/163
--
Training Step: 61  | total loss: [1m[32m0.16207[0m[0m | time: 7.771s
[2K
| Adam | epoch: 011 | loss: 0.16207 - acc: 0.9126 -- iter: 032/163
[A[ATraining Step: 62  | total loss: [1m[32m0.15030[0m[0m | time: 9.273s
[2K
| Adam | epoch: 011 | loss: 0.15030 - acc: 0.9198 -- iter: 064/163
[A[ATraining Step: 63  | total loss: [1m[32m0.13347[0m[0m | time: 10.782s
[2K
| Adam | epoch: 011 | loss: 0.13347 - acc: 0.9300 -- iter: 096/163
[A[ATraining Step: 64  | total loss: [1m[32m0.11823[0m[0m | time: 18.527s
[2K
| Adam | epoch: 011 | loss: 0.11823 - acc: 0.9387 -- iter: 128/163
[A[ATraining Step: 65  | total loss: [1m[32m0.10541[0m[0m | time: 26.376s
[2K
| Adam | epoch: 011 | loss: 0.10541 - acc: 0.9463 -- iter: 160/163
[A[ATraining Step: 66  | total loss: [1m[32m0.09425[0m[0m | time: 36.439s
[2K
| Adam | epoch: 011 | loss: 0.09425 - acc: 0.9528 | val_loss: 1.46020 - val_acc: 0.6731 -- iter: 163/163
--
Training Step: 67  | total loss: [1m[32m0.08474[0m[0m | time: 7.670s
[2K
| Adam | epoch: 012 | loss: 0.08474 - acc: 0.9585 -- iter: 032/163
[A[ATraining Step: 68  | total loss: [1m[32m0.07533[0m[0m | time: 15.458s
[2K
| Adam | epoch: 012 | loss: 0.07533 - acc: 0.9634 -- iter: 064/163
[A[ATraining Step: 69  | total loss: [1m[32m0.06875[0m[0m | time: 16.958s
[2K
| Adam | epoch: 012 | loss: 0.06875 - acc: 0.9677 -- iter: 096/163
[A[ATraining Step: 70  | total loss: [1m[32m0.06318[0m[0m | time: 18.431s
[2K
| Adam | epoch: 012 | loss: 0.06318 - acc: 0.9714 -- iter: 128/163
[A[ATraining Step: 71  | total loss: [1m[32m0.05692[0m[0m | time: 26.229s
[2K
| Adam | epoch: 012 | loss: 0.05692 - acc: 0.9747 -- iter: 160/163
[A[ATraining Step: 72  | total loss: [1m[32m0.05149[0m[0m | time: 36.251s
[2K
| Adam | epoch: 012 | loss: 0.05149 - acc: 0.9775 | val_loss: 1.06843 - val_acc: 0.6538 -- iter: 163/163
--
Training Step: 73  | total loss: [1m[32m0.07441[0m[0m | time: 7.731s
[2K
| Adam | epoch: 013 | loss: 0.07441 - acc: 0.9765 -- iter: 032/163
[A[ATraining Step: 74  | total loss: [1m[32m0.06661[0m[0m | time: 15.499s
[2K
| Adam | epoch: 013 | loss: 0.06661 - acc: 0.9791 -- iter: 064/163
[A[ATraining Step: 75  | total loss: [1m[32m0.06014[0m[0m | time: 23.225s
[2K
| Adam | epoch: 013 | loss: 0.06014 - acc: 0.9814 -- iter: 096/163
[A[ATraining Step: 76  | total loss: [1m[32m0.05444[0m[0m | time: 24.720s
[2K
| Adam | epoch: 013 | loss: 0.05444 - acc: 0.9834 -- iter: 128/163
[A[ATraining Step: 77  | total loss: [1m[32m0.19268[0m[0m | time: 26.204s
[2K
| Adam | epoch: 013 | loss: 0.19268 - acc: 0.9145 -- iter: 160/163
[A[ATraining Step: 78  | total loss: [1m[32m0.24557[0m[0m | time: 36.123s
[2K
| Adam | epoch: 013 | loss: 0.24557 - acc: 0.8537 | val_loss: 1.51025 - val_acc: 0.6731 -- iter: 163/163
--
Training Step: 79  | total loss: [1m[32m0.22076[0m[0m | time: 7.779s
[2K
| Adam | epoch: 014 | loss: 0.22076 - acc: 0.8689 -- iter: 032/163
[A[ATraining Step: 80  | total loss: [1m[32m0.20303[0m[0m | time: 15.306s
[2K
| Adam | epoch: 014 | loss: 0.20303 - acc: 0.8791 -- iter: 064/163
[A[ATraining Step: 81  | total loss: [1m[32m0.18306[0m[0m | time: 22.914s
[2K
| Adam | epoch: 014 | loss: 0.18306 - acc: 0.8913 -- iter: 096/163
[A[ATraining Step: 82  | total loss: [1m[32m0.16861[0m[0m | time: 30.627s
[2K
| Adam | epoch: 014 | loss: 0.16861 - acc: 0.8990 -- iter: 128/163
[A[ATraining Step: 83  | total loss: [1m[32m0.15689[0m[0m | time: 32.061s
[2K
| Adam | epoch: 014 | loss: 0.15689 - acc: 0.9060 -- iter: 160/163
[A[ATraining Step: 84  | total loss: [1m[32m0.24899[0m[0m | time: 35.913s
[2K
| Adam | epoch: 014 | loss: 0.24899 - acc: 0.8821 | val_loss: 1.23114 - val_acc: 0.6731 -- iter: 163/163
--
Training Step: 85  | total loss: [1m[32m0.27919[0m[0m | time: 7.791s
[2K
| Adam | epoch: 015 | loss: 0.27919 - acc: 0.8605 -- iter: 032/163
[A[ATraining Step: 86  | total loss: [1m[32m0.25366[0m[0m | time: 15.579s
[2K
| Adam | epoch: 015 | loss: 0.25366 - acc: 0.8745 -- iter: 064/163
[A[ATraining Step: 87  | total loss: [1m[32m0.25438[0m[0m | time: 23.289s
[2K
| Adam | epoch: 015 | loss: 0.25438 - acc: 0.8839 -- iter: 096/163
[A[ATraining Step: 88  | total loss: [1m[32m0.22979[0m[0m | time: 31.103s
[2K
| Adam | epoch: 015 | loss: 0.22979 - acc: 0.8955 -- iter: 128/163
[A[ATraining Step: 89  | total loss: [1m[32m0.20779[0m[0m | time: 38.892s
[2K
| Adam | epoch: 015 | loss: 0.20779 - acc: 0.9060 -- iter: 160/163
[A[ATraining Step: 90  | total loss: [1m[32m0.18833[0m[0m | time: 42.663s
[2K
| Adam | epoch: 015 | loss: 0.18833 - acc: 0.9154 | val_loss: 0.68974 - val_acc: 0.6731 -- iter: 163/163
--
Training Step: 91  | total loss: [1m[32m0.17194[0m[0m | time: 1.511s
[2K
| Adam | epoch: 016 | loss: 0.17194 - acc: 0.9238 -- iter: 032/163
[A[ATraining Step: 92  | total loss: [1m[32m0.15604[0m[0m | time: 9.193s
[2K
| Adam | epoch: 016 | loss: 0.15604 - acc: 0.9315 -- iter: 064/163
[A[ATraining Step: 93  | total loss: [1m[32m0.14611[0m[0m | time: 16.958s
[2K
| Adam | epoch: 016 | loss: 0.14611 - acc: 0.9383 -- iter: 096/163
[A[ATraining Step: 94  | total loss: [1m[32m0.14339[0m[0m | time: 24.625s
[2K
| Adam | epoch: 016 | loss: 0.14339 - acc: 0.9413 -- iter: 128/163
[A[ATraining Step: 95  | total loss: [1m[32m0.13633[0m[0m | time: 32.369s
[2K
| Adam | epoch: 016 | loss: 0.13633 - acc: 0.9441 -- iter: 160/163
[A[ATraining Step: 96  | total loss: [1m[32m0.12373[0m[0m | time: 42.302s
[2K
| Adam | epoch: 016 | loss: 0.12373 - acc: 0.9497 | val_loss: 0.59876 - val_acc: 0.8269 -- iter: 163/163
--
Training Step: 97  | total loss: [1m[32m0.11210[0m[0m | time: 1.510s
[2K
| Adam | epoch: 017 | loss: 0.11210 - acc: 0.9547 -- iter: 032/163
[A[ATraining Step: 98  | total loss: [1m[32m0.10841[0m[0m | time: 3.086s
[2K
| Adam | epoch: 017 | loss: 0.10841 - acc: 0.9592 -- iter: 064/163
[A[ATraining Step: 99  | total loss: [1m[32m0.09988[0m[0m | time: 10.923s
[2K
| Adam | epoch: 017 | loss: 0.09988 - acc: 0.9633 -- iter: 096/163
[A[ATraining Step: 100  | total loss: [1m[32m0.09118[0m[0m | time: 18.567s
[2K
| Adam | epoch: 017 | loss: 0.09118 - acc: 0.9670 -- iter: 128/163
[A[ATraining Step: 101  | total loss: [1m[32m0.09993[0m[0m | time: 26.447s
[2K
| Adam | epoch: 017 | loss: 0.09993 - acc: 0.9672 -- iter: 160/163
[A[ATraining Step: 102  | total loss: [1m[32m0.09116[0m[0m | time: 36.493s
[2K
| Adam | epoch: 017 | loss: 0.09116 - acc: 0.9704 | val_loss: 0.91658 - val_acc: 0.7115 -- iter: 163/163
--
Training Step: 103  | total loss: [1m[32m0.09154[0m[0m | time: 7.823s
[2K
| Adam | epoch: 018 | loss: 0.09154 - acc: 0.9703 -- iter: 032/163
[A[ATraining Step: 104  | total loss: [1m[32m0.08685[0m[0m | time: 9.351s
[2K
| Adam | epoch: 018 | loss: 0.08685 - acc: 0.9732 -- iter: 064/163
[A[ATraining Step: 105  | total loss: [1m[32m0.07928[0m[0m | time: 10.831s
[2K
| Adam | epoch: 018 | loss: 0.07928 - acc: 0.9759 -- iter: 096/163
[A[ATraining Step: 106  | total loss: [1m[32m0.07205[0m[0m | time: 18.610s
[2K
| Adam | epoch: 018 | loss: 0.07205 - acc: 0.9783 -- iter: 128/163
[A[ATraining Step: 107  | total loss: [1m[32m0.08215[0m[0m | time: 26.445s
[2K
| Adam | epoch: 018 | loss: 0.08215 - acc: 0.9774 -- iter: 160/163
[A[ATraining Step: 108  | total loss: [1m[32m0.07451[0m[0m | time: 36.533s
[2K
| Adam | epoch: 018 | loss: 0.07451 - acc: 0.9796 | val_loss: 2.22229 - val_acc: 0.6731 -- iter: 163/163
--
Training Step: 109  | total loss: [1m[32m0.07126[0m[0m | time: 7.614s
[2K
| Adam | epoch: 019 | loss: 0.07126 - acc: 0.9785 -- iter: 032/163
[A[ATraining Step: 110  | total loss: [1m[32m0.06463[0m[0m | time: 15.336s
[2K
| Adam | epoch: 019 | loss: 0.06463 - acc: 0.9807 -- iter: 064/163
[A[ATraining Step: 111  | total loss: [1m[32m0.05905[0m[0m | time: 16.820s
[2K
| Adam | epoch: 019 | loss: 0.05905 - acc: 0.9826 -- iter: 096/163
[A[ATraining Step: 112  | total loss: [1m[32m0.05403[0m[0m | time: 18.344s
[2K
| Adam | epoch: 019 | loss: 0.05403 - acc: 0.9844 -- iter: 128/163
[A[ATraining Step: 113  | total loss: [1m[32m0.04937[0m[0m | time: 26.019s
[2K
| Adam | epoch: 019 | loss: 0.04937 - acc: 0.9859 -- iter: 160/163
[A[ATraining Step: 114  | total loss: [1m[32m0.04767[0m[0m | time: 36.145s
[2K
| Adam | epoch: 019 | loss: 0.04767 - acc: 0.9873 | val_loss: 2.29286 - val_acc: 0.6538 -- iter: 163/163
--
Training Step: 115  | total loss: [1m[32m0.06236[0m[0m | time: 7.710s
[2K
| Adam | epoch: 020 | loss: 0.06236 - acc: 0.9855 -- iter: 032/163
[A[ATraining Step: 116  | total loss: [1m[32m0.05673[0m[0m | time: 15.397s
[2K
| Adam | epoch: 020 | loss: 0.05673 - acc: 0.9869 -- iter: 064/163
[A[ATraining Step: 117  | total loss: [1m[32m0.05902[0m[0m | time: 23.166s
[2K
| Adam | epoch: 020 | loss: 0.05902 - acc: 0.9851 -- iter: 096/163
[A[ATraining Step: 118  | total loss: [1m[32m0.05428[0m[0m | time: 24.626s
[2K
| Adam | epoch: 020 | loss: 0.05428 - acc: 0.9866 -- iter: 128/163
[A[ATraining Step: 119  | total loss: [1m[32m0.15653[0m[0m | time: 26.093s
[2K
| Adam | epoch: 020 | loss: 0.15653 - acc: 0.9546 -- iter: 160/163
[A[ATraining Step: 120  | total loss: [1m[32m0.17404[0m[0m | time: 36.311s
[2K
| Adam | epoch: 020 | loss: 0.17404 - acc: 0.9591 | val_loss: 1.27439 - val_acc: 0.6538 -- iter: 163/163
--
Training Step: 121  | total loss: [1m[32m0.15710[0m[0m | time: 7.891s
[2K
| Adam | epoch: 021 | loss: 0.15710 - acc: 0.9632 -- iter: 032/163
[A[ATraining Step: 122  | total loss: [1m[32m0.17916[0m[0m | time: 15.804s
[2K
| Adam | epoch: 021 | loss: 0.17916 - acc: 0.9638 -- iter: 064/163
[A[ATraining Step: 123  | total loss: [1m[32m0.16227[0m[0m | time: 23.588s
[2K
| Adam | epoch: 021 | loss: 0.16227 - acc: 0.9674 -- iter: 096/163
[A[ATraining Step: 124  | total loss: [1m[32m0.14924[0m[0m | time: 31.349s
[2K
| Adam | epoch: 021 | loss: 0.14924 - acc: 0.9707 -- iter: 128/163
[A[ATraining Step: 125  | total loss: [1m[32m0.14983[0m[0m | time: 32.820s
[2K
| Adam | epoch: 021 | loss: 0.14983 - acc: 0.9705 -- iter: 160/163
[A[ATraining Step: 126  | total loss: [1m[32m0.19914[0m[0m | time: 36.677s
[2K
| Adam | epoch: 021 | loss: 0.19914 - acc: 0.9401 | val_loss: 1.24723 - val_acc: 0.6731 -- iter: 163/163
--
Training Step: 127  | total loss: [1m[32m0.18382[0m[0m | time: 7.628s
[2K
| Adam | epoch: 022 | loss: 0.18382 - acc: 0.9461 -- iter: 032/163
[A[ATraining Step: 128  | total loss: [1m[32m0.16834[0m[0m | time: 15.283s
[2K
| Adam | epoch: 022 | loss: 0.16834 - acc: 0.9515 -- iter: 064/163
[A[ATraining Step: 129  | total loss: [1m[32m0.17022[0m[0m | time: 23.003s
[2K
| Adam | epoch: 022 | loss: 0.17022 - acc: 0.9532 -- iter: 096/163
[A[ATraining Step: 130  | total loss: [1m[32m0.15731[0m[0m | time: 30.606s
[2K
| Adam | epoch: 022 | loss: 0.15731 - acc: 0.9579 -- iter: 128/163
[A[ATraining Step: 131  | total loss: [1m[32m0.14604[0m[0m | time: 38.274s
[2K
| Adam | epoch: 022 | loss: 0.14604 - acc: 0.9590 -- iter: 160/163
[A[ATraining Step: 132  | total loss: [1m[32m0.13710[0m[0m | time: 42.077s
[2K
| Adam | epoch: 022 | loss: 0.13710 - acc: 0.9631 | val_loss: 0.63650 - val_acc: 0.7308 -- iter: 163/163
--
Training Step: 133  | total loss: [1m[32m0.12372[0m[0m | time: 1.455s
[2K
| Adam | epoch: 023 | loss: 0.12372 - acc: 0.9668 -- iter: 032/163
[A[ATraining Step: 134  | total loss: [1m[32m0.11167[0m[0m | time: 9.105s
[2K
| Adam | epoch: 023 | loss: 0.11167 - acc: 0.9701 -- iter: 064/163
[A[ATraining Step: 135  | total loss: [1m[32m0.11433[0m[0m | time: 16.822s
[2K
| Adam | epoch: 023 | loss: 0.11433 - acc: 0.9700 -- iter: 096/163
[A[ATraining Step: 136  | total loss: [1m[32m0.13987[0m[0m | time: 24.602s
[2K
| Adam | epoch: 023 | loss: 0.13987 - acc: 0.9667 -- iter: 128/163
[A[ATraining Step: 137  | total loss: [1m[32m0.13075[0m[0m | time: 32.375s
[2K
| Adam | epoch: 023 | loss: 0.13075 - acc: 0.9700 -- iter: 160/163
[A[ATraining Step: 138  | total loss: [1m[32m0.11851[0m[0m | time: 42.473s
[2K
| Adam | epoch: 023 | loss: 0.11851 - acc: 0.9730 | val_loss: 1.03655 - val_acc: 0.6154 -- iter: 163/163
--
Training Step: 139  | total loss: [1m[32m0.10744[0m[0m | time: 1.484s
[2K
| Adam | epoch: 024 | loss: 0.10744 - acc: 0.9757 -- iter: 032/163
[A[ATraining Step: 140  | total loss: [1m[32m0.09767[0m[0m | time: 2.959s
[2K
| Adam | epoch: 024 | loss: 0.09767 - acc: 0.9782 -- iter: 064/163
[A[ATraining Step: 141  | total loss: [1m[32m0.08837[0m[0m | time: 11.000s
[2K
| Adam | epoch: 024 | loss: 0.08837 - acc: 0.9803 -- iter: 096/163
[A[ATraining Step: 142  | total loss: [1m[32m0.08488[0m[0m | time: 18.658s
[2K
| Adam | epoch: 024 | loss: 0.08488 - acc: 0.9792 -- iter: 128/163
[A[ATraining Step: 143  | total loss: [1m[32m0.09306[0m[0m | time: 26.283s
[2K
| Adam | epoch: 024 | loss: 0.09306 - acc: 0.9781 -- iter: 160/163
[A[ATraining Step: 144  | total loss: [1m[32m0.08558[0m[0m | time: 36.251s
[2K
| Adam | epoch: 024 | loss: 0.08558 - acc: 0.9803 | val_loss: 1.93347 - val_acc: 0.5577 -- iter: 163/163
--
Training Step: 145  | total loss: [1m[32m0.07851[0m[0m | time: 7.554s
[2K
| Adam | epoch: 025 | loss: 0.07851 - acc: 0.9823 -- iter: 032/163
[A[ATraining Step: 146  | total loss: [1m[32m0.08399[0m[0m | time: 9.022s
[2K
| Adam | epoch: 025 | loss: 0.08399 - acc: 0.9809 -- iter: 064/163
[A[ATraining Step: 147  | total loss: [1m[32m0.07668[0m[0m | time: 10.478s
[2K
| Adam | epoch: 025 | loss: 0.07668 - acc: 0.9828 -- iter: 096/163
[A[ATraining Step: 148  | total loss: [1m[32m0.07022[0m[0m | time: 18.172s
[2K
| Adam | epoch: 025 | loss: 0.07022 - acc: 0.9846 -- iter: 128/163
[A[ATraining Step: 149  | total loss: [1m[32m0.06433[0m[0m | time: 25.960s
[2K
| Adam | epoch: 025 | loss: 0.06433 - acc: 0.9861 -- iter: 160/163
[A[ATraining Step: 150  | total loss: [1m[32m0.08711[0m[0m | time: 35.964s
[2K
| Adam | epoch: 025 | loss: 0.08711 - acc: 0.9812 | val_loss: 1.52514 - val_acc: 0.5385 -- iter: 163/163
--
Training Step: 151  | total loss: [1m[32m0.08154[0m[0m | time: 7.808s
[2K
| Adam | epoch: 026 | loss: 0.08154 - acc: 0.9831 -- iter: 032/163
[A[ATraining Step: 152  | total loss: [1m[32m0.07533[0m[0m | time: 15.388s
[2K
| Adam | epoch: 026 | loss: 0.07533 - acc: 0.9848 -- iter: 064/163
[A[ATraining Step: 153  | total loss: [1m[32m0.06906[0m[0m | time: 16.861s
[2K
| Adam | epoch: 026 | loss: 0.06906 - acc: 0.9863 -- iter: 096/163
[A[ATraining Step: 154  | total loss: [1m[32m0.06871[0m[0m | time: 18.307s
[2K
| Adam | epoch: 026 | loss: 0.06871 - acc: 0.9877 -- iter: 128/163
[A[ATraining Step: 155  | total loss: [1m[32m0.06235[0m[0m | time: 26.130s
[2K
| Adam | epoch: 026 | loss: 0.06235 - acc: 0.9889 -- iter: 160/163
[A[ATraining Step: 156  | total loss: [1m[32m0.05823[0m[0m | time: 36.279s
[2K
| Adam | epoch: 026 | loss: 0.05823 - acc: 0.9900 | val_loss: 1.64033 - val_acc: 0.6731 -- iter: 163/163
--
Training Step: 157  | total loss: [1m[32m0.05278[0m[0m | time: 7.520s
[2K
| Adam | epoch: 027 | loss: 0.05278 - acc: 0.9910 -- iter: 032/163
[A[ATraining Step: 158  | total loss: [1m[32m0.04920[0m[0m | time: 15.318s
[2K
| Adam | epoch: 027 | loss: 0.04920 - acc: 0.9919 -- iter: 064/163
[A[ATraining Step: 159  | total loss: [1m[32m0.04489[0m[0m | time: 23.113s
[2K
| Adam | epoch: 027 | loss: 0.04489 - acc: 0.9927 -- iter: 096/163
[A[ATraining Step: 160  | total loss: [1m[32m0.04116[0m[0m | time: 24.579s
[2K
| Adam | epoch: 027 | loss: 0.04116 - acc: 0.9935 -- iter: 128/163
[A[ATraining Step: 161  | total loss: [1m[32m0.04000[0m[0m | time: 26.044s
[2K
| Adam | epoch: 027 | loss: 0.04000 - acc: 0.9941 -- iter: 160/163
[A[ATraining Step: 162  | total loss: [1m[32m0.03662[0m[0m | time: 36.266s
[2K
| Adam | epoch: 027 | loss: 0.03662 - acc: 0.9947 | val_loss: 3.03187 - val_acc: 0.5577 -- iter: 163/163
--
Training Step: 163  | total loss: [1m[32m0.03352[0m[0m | time: 7.938s
[2K
| Adam | epoch: 028 | loss: 0.03352 - acc: 0.9952 -- iter: 032/163
[A[ATraining Step: 164  | total loss: [1m[32m0.05278[0m[0m | time: 15.867s
[2K
| Adam | epoch: 028 | loss: 0.05278 - acc: 0.9926 -- iter: 064/163
[A[ATraining Step: 165  | total loss: [1m[32m0.04968[0m[0m | time: 23.500s
[2K
| Adam | epoch: 028 | loss: 0.04968 - acc: 0.9933 -- iter: 096/163
[A[ATraining Step: 166  | total loss: [1m[32m0.04502[0m[0m | time: 31.165s
[2K
| Adam | epoch: 028 | loss: 0.04502 - acc: 0.9940 -- iter: 128/163
[A[ATraining Step: 167  | total loss: [1m[32m0.04787[0m[0m | time: 32.632s
[2K
| Adam | epoch: 028 | loss: 0.04787 - acc: 0.9915 -- iter: 160/163
[A[ATraining Step: 168  | total loss: [1m[32m0.04341[0m[0m | time: 36.372s
[2K
| Adam | epoch: 028 | loss: 0.04341 - acc: 0.9923 | val_loss: 2.94533 - val_acc: 0.5577 -- iter: 163/163
--
Training Step: 169  | total loss: [1m[32m0.03947[0m[0m | time: 7.928s
[2K
| Adam | epoch: 029 | loss: 0.03947 - acc: 0.9931 -- iter: 032/163
[A[ATraining Step: 170  | total loss: [1m[32m0.03604[0m[0m | time: 15.752s
[2K
| Adam | epoch: 029 | loss: 0.03604 - acc: 0.9938 -- iter: 064/163
[A[ATraining Step: 171  | total loss: [1m[32m0.04818[0m[0m | time: 23.396s
[2K
| Adam | epoch: 029 | loss: 0.04818 - acc: 0.9913 -- iter: 096/163
[A[ATraining Step: 172  | total loss: [1m[32m0.04358[0m[0m | time: 31.141s
[2K
| Adam | epoch: 029 | loss: 0.04358 - acc: 0.9922 -- iter: 128/163
[A[ATraining Step: 173  | total loss: [1m[32m0.04507[0m[0m | time: 38.945s
[2K
| Adam | epoch: 029 | loss: 0.04507 - acc: 0.9898 -- iter: 160/163
[A[ATraining Step: 174  | total loss: [1m[32m0.05306[0m[0m | time: 42.964s
[2K
| Adam | epoch: 029 | loss: 0.05306 - acc: 0.9877 | val_loss: 1.91679 - val_acc: 0.6154 -- iter: 163/163
--
Training Step: 175  | total loss: [1m[32m0.04809[0m[0m | time: 1.686s
[2K
| Adam | epoch: 030 | loss: 0.04809 - acc: 0.9889 -- iter: 032/163
[A[ATraining Step: 176  | total loss: [1m[32m0.04361[0m[0m | time: 9.537s
[2K
| Adam | epoch: 030 | loss: 0.04361 - acc: 0.9900 -- iter: 064/163
[A[ATraining Step: 177  | total loss: [1m[32m0.03963[0m[0m | time: 17.308s
[2K
| Adam | epoch: 030 | loss: 0.03963 - acc: 0.9910 -- iter: 096/163
[A[ATraining Step: 178  | total loss: [1m[32m0.07627[0m[0m | time: 24.873s
[2K
| Adam | epoch: 030 | loss: 0.07627 - acc: 0.9888 -- iter: 128/163
[A[ATraining Step: 179  | total loss: [1m[32m0.07104[0m[0m | time: 33.365s
[2K
| Adam | epoch: 030 | loss: 0.07104 - acc: 0.9899 -- iter: 160/163
[A[ATraining Step: 180  | total loss: [1m[32m0.06424[0m[0m | time: 53.011s
[2K
| Adam | epoch: 030 | loss: 0.06424 - acc: 0.9909 | val_loss: 0.64795 - val_acc: 0.7308 -- iter: 163/163
--
Validation AUC:0.8824404761904762
Validation AUPRC:0.8619680960794895
Test AUC:0.9408284023668639
Test AUPRC:0.95750171115781
BestTestF1Score	0.87	0.74	0.87	0.83	0.92	24	5	21	2	0.09
BestTestMCCScore	0.87	0.74	0.87	0.83	0.92	24	5	21	2	0.09
BestTestAccuracyScore	0.9	0.81	0.9	0.92	0.88	23	2	24	3	0.17
BestValidationF1Score	0.87	0.7	0.85	0.81	0.93	26	6	18	2	0.09
BestValidationMCC	0.87	0.7	0.85	0.81	0.93	26	6	18	2	0.09
BestValidationAccuracy	0.85	0.69	0.85	0.88	0.82	23	3	21	5	0.17
TestPredictions (Threshold:0.09)
CHEMBL169553,TN,INACT,0.05000000074505806	CHEMBL98241,FN,ACT,0.019999999552965164	CHEMBL246585,FP,INACT,0.20000000298023224	CHEMBL110976,TP,ACT,0.4000000059604645	CHEMBL111554,TP,ACT,0.9900000095367432	CHEMBL1170027,TN,INACT,0.0	CHEMBL123099,TN,INACT,0.05000000074505806	CHEMBL114478,TN,INACT,0.0	CHEMBL279225,FP,INACT,0.14000000059604645	CHEMBL99331,TN,INACT,0.009999999776482582	CHEMBL1983100,TN,INACT,0.009999999776482582	CHEMBL108804,TP,ACT,0.9399999976158142	CHEMBL109827,TP,ACT,0.7200000286102295	CHEMBL1259043,TP,ACT,0.9900000095367432	CHEMBL118553,FP,INACT,0.10999999940395355	CHEMBL290387,TP,ACT,1.0	CHEMBL1259023,TP,ACT,0.9900000095367432	CHEMBL593861,TN,INACT,0.019999999552965164	CHEMBL2113072,TN,INACT,0.05999999865889549	CHEMBL595022,TN,INACT,0.0	CHEMBL42799,TN,INACT,0.0	CHEMBL1259241,TN,INACT,0.07999999821186066	CHEMBL40896,TP,ACT,1.0	CHEMBL39037,TP,ACT,0.9900000095367432	CHEMBL2312376,FP,INACT,0.6399999856948853	CHEMBL1259079,TP,ACT,0.33000001311302185	CHEMBL336161,TP,ACT,0.9599999785423279	CHEMBL318901,FN,ACT,0.0	CHEMBL317912,TP,ACT,0.9100000262260437	CHEMBL107680,TN,INACT,0.029999999329447746	CHEMBL1259216,TP,ACT,0.7300000190734863	CHEMBL1259024,TP,ACT,0.9900000095367432	CHEMBL42360,TN,INACT,0.0	CHEMBL291262,TP,ACT,1.0	CHEMBL1259145,TP,ACT,0.9800000190734863	CHEMBL1259231,TP,ACT,0.8700000047683716	CHEMBL40819,TP,ACT,0.6800000071525574	CHEMBL228144,TN,INACT,0.0	CHEMBL233552,TN,INACT,0.0	CHEMBL1258999,TN,INACT,0.07999999821186066	CHEMBL2042401,TN,INACT,0.0	CHEMBL297218,TP,ACT,0.8700000047683716	CHEMBL1259232,TP,ACT,0.8799999952316284	CHEMBL415879,TN,INACT,0.029999999329447746	CHEMBL21509,TN,INACT,0.07999999821186066	CHEMBL461502,TN,INACT,0.0	CHEMBL1259187,TP,ACT,0.3799999952316284	CHEMBL162095,FP,INACT,0.1599999964237213	CHEMBL217002,TN,INACT,0.0	CHEMBL762,TP,ACT,0.09000000357627869	CHEMBL43573,TP,ACT,0.3799999952316284	CHEMBL40754,TP,ACT,1.0	

