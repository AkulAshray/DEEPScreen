ImageNetInceptionV2 CHEMBL2055 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	167
Number of inactive compounds :	167
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2055_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2055_adam_0.0005_15_0.8/
---------------------------------
Training samples: 211
Validation samples: 67
--
Training Step: 1  | time: 36.086s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/211
[A[ATraining Step: 2  | total loss: [1m[32m0.63603[0m[0m | time: 44.514s
[2K
| Adam | epoch: 001 | loss: 0.63603 - acc: 0.4781 -- iter: 064/211
[A[ATraining Step: 3  | total loss: [1m[32m0.97075[0m[0m | time: 53.064s
[2K
| Adam | epoch: 001 | loss: 0.97075 - acc: 0.6239 -- iter: 096/211
[A[ATraining Step: 4  | total loss: [1m[32m0.80336[0m[0m | time: 61.632s
[2K
| Adam | epoch: 001 | loss: 0.80336 - acc: 0.6950 -- iter: 128/211
[A[ATraining Step: 5  | total loss: [1m[32m0.70595[0m[0m | time: 70.176s
[2K
| Adam | epoch: 001 | loss: 0.70595 - acc: 0.6898 -- iter: 160/211
[A[ATraining Step: 6  | total loss: [1m[32m0.60823[0m[0m | time: 78.558s
[2K
| Adam | epoch: 001 | loss: 0.60823 - acc: 0.7084 -- iter: 192/211
[A[ATraining Step: 7  | total loss: [1m[32m0.59480[0m[0m | time: 92.354s
[2K
| Adam | epoch: 001 | loss: 0.59480 - acc: 0.7146 | val_loss: 0.85598 - val_acc: 0.5075 -- iter: 211/211
--
Training Step: 8  | total loss: [1m[32m0.54060[0m[0m | time: 5.714s
[2K
| Adam | epoch: 002 | loss: 0.54060 - acc: 0.6975 -- iter: 032/211
[A[ATraining Step: 9  | total loss: [1m[32m0.37198[0m[0m | time: 14.202s
[2K
| Adam | epoch: 002 | loss: 0.37198 - acc: 0.8298 -- iter: 064/211
[A[ATraining Step: 10  | total loss: [1m[32m0.37188[0m[0m | time: 22.705s
[2K
| Adam | epoch: 002 | loss: 0.37188 - acc: 0.8524 -- iter: 096/211
[A[ATraining Step: 11  | total loss: [1m[32m0.28359[0m[0m | time: 31.204s
[2K
| Adam | epoch: 002 | loss: 0.28359 - acc: 0.9075 -- iter: 128/211
[A[ATraining Step: 12  | total loss: [1m[32m0.27591[0m[0m | time: 39.941s
[2K
| Adam | epoch: 002 | loss: 0.27591 - acc: 0.8788 -- iter: 160/211
[A[ATraining Step: 13  | total loss: [1m[32m0.27461[0m[0m | time: 48.582s
[2K
| Adam | epoch: 002 | loss: 0.27461 - acc: 0.9040 -- iter: 192/211
[A[ATraining Step: 14  | total loss: [1m[32m0.24501[0m[0m | time: 59.783s
[2K
| Adam | epoch: 002 | loss: 0.24501 - acc: 0.8921 | val_loss: 0.84399 - val_acc: 0.4925 -- iter: 211/211
--
Training Step: 15  | total loss: [1m[32m0.23815[0m[0m | time: 5.528s
[2K
| Adam | epoch: 003 | loss: 0.23815 - acc: 0.8976 -- iter: 032/211
[A[ATraining Step: 16  | total loss: [1m[32m0.17168[0m[0m | time: 10.843s
[2K
| Adam | epoch: 003 | loss: 0.17168 - acc: 0.9360 -- iter: 064/211
[A[ATraining Step: 17  | total loss: [1m[32m0.12333[0m[0m | time: 19.494s
[2K
| Adam | epoch: 003 | loss: 0.12333 - acc: 0.9591 -- iter: 096/211
[A[ATraining Step: 18  | total loss: [1m[32m0.10860[0m[0m | time: 27.969s
[2K
| Adam | epoch: 003 | loss: 0.10860 - acc: 0.9732 -- iter: 128/211
[A[ATraining Step: 19  | total loss: [1m[32m0.08764[0m[0m | time: 36.641s
[2K
| Adam | epoch: 003 | loss: 0.08764 - acc: 0.9717 -- iter: 160/211
[A[ATraining Step: 20  | total loss: [1m[32m0.07347[0m[0m | time: 44.838s
[2K
| Adam | epoch: 003 | loss: 0.07347 - acc: 0.9708 -- iter: 192/211
[A[ATraining Step: 21  | total loss: [1m[32m0.09430[0m[0m | time: 55.988s
[2K
| Adam | epoch: 003 | loss: 0.09430 - acc: 0.9604 | val_loss: 1.79344 - val_acc: 0.4925 -- iter: 211/211
--
Training Step: 22  | total loss: [1m[32m0.07428[0m[0m | time: 8.285s
[2K
| Adam | epoch: 004 | loss: 0.07428 - acc: 0.9723 -- iter: 032/211
[A[ATraining Step: 23  | total loss: [1m[32m0.06902[0m[0m | time: 13.589s
[2K
| Adam | epoch: 004 | loss: 0.06902 - acc: 0.9713 -- iter: 064/211
[A[ATraining Step: 24  | total loss: [1m[32m0.13247[0m[0m | time: 18.950s
[2K
| Adam | epoch: 004 | loss: 0.13247 - acc: 0.9646 -- iter: 096/211
[A[ATraining Step: 25  | total loss: [1m[32m0.10262[0m[0m | time: 27.388s
[2K
| Adam | epoch: 004 | loss: 0.10262 - acc: 0.9742 -- iter: 128/211
[A[ATraining Step: 26  | total loss: [1m[32m0.10025[0m[0m | time: 36.030s
[2K
| Adam | epoch: 004 | loss: 0.10025 - acc: 0.9645 -- iter: 160/211
[A[ATraining Step: 27  | total loss: [1m[32m0.15888[0m[0m | time: 44.526s
[2K
| Adam | epoch: 004 | loss: 0.15888 - acc: 0.9656 -- iter: 192/211
[A[ATraining Step: 28  | total loss: [1m[32m0.12154[0m[0m | time: 56.187s
[2K
| Adam | epoch: 004 | loss: 0.12154 - acc: 0.9742 | val_loss: 0.79500 - val_acc: 0.4627 -- iter: 211/211
--
Training Step: 29  | total loss: [1m[32m0.09607[0m[0m | time: 8.758s
[2K
| Adam | epoch: 005 | loss: 0.09607 - acc: 0.9805 -- iter: 032/211
[A[ATraining Step: 30  | total loss: [1m[32m0.08289[0m[0m | time: 17.496s
[2K
| Adam | epoch: 005 | loss: 0.08289 - acc: 0.9777 -- iter: 064/211
[A[ATraining Step: 31  | total loss: [1m[32m0.12705[0m[0m | time: 23.147s
[2K
| Adam | epoch: 005 | loss: 0.12705 - acc: 0.9684 -- iter: 096/211
[A[ATraining Step: 32  | total loss: [1m[32m0.13521[0m[0m | time: 28.798s
[2K
| Adam | epoch: 005 | loss: 0.13521 - acc: 0.9637 -- iter: 128/211
[A[ATraining Step: 33  | total loss: [1m[32m0.11247[0m[0m | time: 37.230s
[2K
| Adam | epoch: 005 | loss: 0.11247 - acc: 0.9717 -- iter: 160/211
[A[ATraining Step: 34  | total loss: [1m[32m0.09156[0m[0m | time: 45.749s
[2K
| Adam | epoch: 005 | loss: 0.09156 - acc: 0.9777 -- iter: 192/211
[A[ATraining Step: 35  | total loss: [1m[32m0.07437[0m[0m | time: 57.211s
[2K
| Adam | epoch: 005 | loss: 0.07437 - acc: 0.9824 | val_loss: 1.34508 - val_acc: 0.4776 -- iter: 211/211
--
Training Step: 36  | total loss: [1m[32m0.06361[0m[0m | time: 8.584s
[2K
| Adam | epoch: 006 | loss: 0.06361 - acc: 0.9860 -- iter: 032/211
[A[ATraining Step: 37  | total loss: [1m[32m0.07274[0m[0m | time: 16.895s
[2K
| Adam | epoch: 006 | loss: 0.07274 - acc: 0.9825 -- iter: 064/211
[A[ATraining Step: 38  | total loss: [1m[32m0.07112[0m[0m | time: 25.224s
[2K
| Adam | epoch: 006 | loss: 0.07112 - acc: 0.9798 -- iter: 096/211
[A[ATraining Step: 39  | total loss: [1m[32m0.06961[0m[0m | time: 30.703s
[2K
| Adam | epoch: 006 | loss: 0.06961 - acc: 0.9777 -- iter: 128/211
[A[ATraining Step: 40  | total loss: [1m[32m0.10144[0m[0m | time: 36.041s
[2K
| Adam | epoch: 006 | loss: 0.10144 - acc: 0.9720 -- iter: 160/211
[A[ATraining Step: 41  | total loss: [1m[32m0.08652[0m[0m | time: 44.439s
[2K
| Adam | epoch: 006 | loss: 0.08652 - acc: 0.9772 -- iter: 192/211
[A[ATraining Step: 42  | total loss: [1m[32m0.07501[0m[0m | time: 55.894s
[2K
| Adam | epoch: 006 | loss: 0.07501 - acc: 0.9813 | val_loss: 2.85574 - val_acc: 0.5075 -- iter: 211/211
--
Training Step: 43  | total loss: [1m[32m0.06388[0m[0m | time: 8.522s
[2K
| Adam | epoch: 007 | loss: 0.06388 - acc: 0.9846 -- iter: 032/211
[A[ATraining Step: 44  | total loss: [1m[32m0.06571[0m[0m | time: 16.766s
[2K
| Adam | epoch: 007 | loss: 0.06571 - acc: 0.9818 -- iter: 064/211
[A[ATraining Step: 45  | total loss: [1m[32m0.05640[0m[0m | time: 25.366s
[2K
| Adam | epoch: 007 | loss: 0.05640 - acc: 0.9849 -- iter: 096/211
[A[ATraining Step: 46  | total loss: [1m[32m0.04971[0m[0m | time: 33.903s
[2K
| Adam | epoch: 007 | loss: 0.04971 - acc: 0.9874 -- iter: 128/211
[A[ATraining Step: 47  | total loss: [1m[32m0.09041[0m[0m | time: 39.842s
[2K
| Adam | epoch: 007 | loss: 0.09041 - acc: 0.9793 -- iter: 160/211
[A[ATraining Step: 48  | total loss: [1m[32m0.13852[0m[0m | time: 45.359s
[2K
| Adam | epoch: 007 | loss: 0.13852 - acc: 0.9657 -- iter: 192/211
[A[ATraining Step: 49  | total loss: [1m[32m0.15914[0m[0m | time: 56.929s
[2K
| Adam | epoch: 007 | loss: 0.15914 - acc: 0.9628 | val_loss: 2.85228 - val_acc: 0.5075 -- iter: 211/211
--
Training Step: 50  | total loss: [1m[32m0.13716[0m[0m | time: 8.543s
[2K
| Adam | epoch: 008 | loss: 0.13716 - acc: 0.9686 -- iter: 032/211
[A[ATraining Step: 51  | total loss: [1m[32m0.12140[0m[0m | time: 17.075s
[2K
| Adam | epoch: 008 | loss: 0.12140 - acc: 0.9734 -- iter: 064/211
[A[ATraining Step: 52  | total loss: [1m[32m0.11141[0m[0m | time: 25.738s
[2K
| Adam | epoch: 008 | loss: 0.11141 - acc: 0.9727 -- iter: 096/211
[A[ATraining Step: 53  | total loss: [1m[32m0.10872[0m[0m | time: 34.265s
[2K
| Adam | epoch: 008 | loss: 0.10872 - acc: 0.9675 -- iter: 128/211
[A[ATraining Step: 54  | total loss: [1m[32m0.09777[0m[0m | time: 42.869s
[2K
| Adam | epoch: 008 | loss: 0.09777 - acc: 0.9722 -- iter: 160/211
[A[ATraining Step: 55  | total loss: [1m[32m0.08829[0m[0m | time: 48.319s
[2K
| Adam | epoch: 008 | loss: 0.08829 - acc: 0.9762 -- iter: 192/211
[A[ATraining Step: 56  | total loss: [1m[32m0.08744[0m[0m | time: 56.734s
[2K
| Adam | epoch: 008 | loss: 0.08744 - acc: 0.9795 | val_loss: 2.36308 - val_acc: 0.5075 -- iter: 211/211
--
Training Step: 57  | total loss: [1m[32m0.08144[0m[0m | time: 8.674s
[2K
| Adam | epoch: 009 | loss: 0.08144 - acc: 0.9824 -- iter: 032/211
[A[ATraining Step: 58  | total loss: [1m[32m0.07175[0m[0m | time: 17.574s
[2K
| Adam | epoch: 009 | loss: 0.07175 - acc: 0.9848 -- iter: 064/211
[A[ATraining Step: 59  | total loss: [1m[32m0.06492[0m[0m | time: 26.355s
[2K
| Adam | epoch: 009 | loss: 0.06492 - acc: 0.9868 -- iter: 096/211
[A[ATraining Step: 60  | total loss: [1m[32m0.05703[0m[0m | time: 37.332s
[2K
| Adam | epoch: 009 | loss: 0.05703 - acc: 0.9886 -- iter: 128/211
[A[ATraining Step: 61  | total loss: [1m[32m0.05018[0m[0m | time: 61.698s
[2K
| Adam | epoch: 009 | loss: 0.05018 - acc: 0.9900 -- iter: 160/211
[A[ATraining Step: 62  | total loss: [1m[32m0.04675[0m[0m | time: 87.359s
[2K
| Adam | epoch: 009 | loss: 0.04675 - acc: 0.9913 -- iter: 192/211
[A[ATraining Step: 63  | total loss: [1m[32m0.04658[0m[0m | time: 96.674s
[2K
| Adam | epoch: 009 | loss: 0.04658 - acc: 0.9885 | val_loss: 1.97928 - val_acc: 0.5075 -- iter: 211/211
--
Training Step: 64  | total loss: [1m[32m0.04129[0m[0m | time: 6.444s
[2K
| Adam | epoch: 010 | loss: 0.04129 - acc: 0.9899 -- iter: 032/211
[A[ATraining Step: 65  | total loss: [1m[32m0.03699[0m[0m | time: 42.614s
[2K
| Adam | epoch: 010 | loss: 0.03699 - acc: 0.9912 -- iter: 064/211
[A[ATraining Step: 66  | total loss: [1m[32m0.03774[0m[0m | time: 52.591s
[2K
| Adam | epoch: 010 | loss: 0.03774 - acc: 0.9884 -- iter: 096/211
[A[ATraining Step: 67  | total loss: [1m[32m0.03501[0m[0m | time: 62.629s
[2K
| Adam | epoch: 010 | loss: 0.03501 - acc: 0.9898 -- iter: 128/211
[A[ATraining Step: 68  | total loss: [1m[32m0.03225[0m[0m | time: 72.524s
[2K
| Adam | epoch: 010 | loss: 0.03225 - acc: 0.9910 -- iter: 160/211
[A[ATraining Step: 69  | total loss: [1m[32m0.03722[0m[0m | time: 82.290s
[2K
| Adam | epoch: 010 | loss: 0.03722 - acc: 0.9884 -- iter: 192/211
[A[ATraining Step: 70  | total loss: [1m[32m0.03465[0m[0m | time: 96.021s
[2K
| Adam | epoch: 010 | loss: 0.03465 - acc: 0.9898 | val_loss: 0.89031 - val_acc: 0.8507 -- iter: 211/211
--
Training Step: 71  | total loss: [1m[32m0.03452[0m[0m | time: 6.724s
[2K
| Adam | epoch: 011 | loss: 0.03452 - acc: 0.9909 -- iter: 032/211
[A[ATraining Step: 72  | total loss: [1m[32m0.13502[0m[0m | time: 13.330s
[2K
| Adam | epoch: 011 | loss: 0.13502 - acc: 0.9801 -- iter: 064/211
[A[ATraining Step: 73  | total loss: [1m[32m0.12283[0m[0m | time: 23.059s
[2K
| Adam | epoch: 011 | loss: 0.12283 - acc: 0.9823 -- iter: 096/211
[A[ATraining Step: 74  | total loss: [1m[32m0.11893[0m[0m | time: 33.108s
[2K
| Adam | epoch: 011 | loss: 0.11893 - acc: 0.9808 -- iter: 128/211
[A[ATraining Step: 75  | total loss: [1m[32m0.11844[0m[0m | time: 43.136s
[2K
| Adam | epoch: 011 | loss: 0.11844 - acc: 0.9795 -- iter: 160/211
[A[ATraining Step: 76  | total loss: [1m[32m0.12487[0m[0m | time: 53.086s
[2K
| Adam | epoch: 011 | loss: 0.12487 - acc: 0.9750 -- iter: 192/211
[A[ATraining Step: 77  | total loss: [1m[32m0.11557[0m[0m | time: 65.945s
[2K
| Adam | epoch: 011 | loss: 0.11557 - acc: 0.9743 | val_loss: 1.74808 - val_acc: 0.5970 -- iter: 211/211
--
Training Step: 78  | total loss: [1m[32m0.13547[0m[0m | time: 9.191s
[2K
| Adam | epoch: 012 | loss: 0.13547 - acc: 0.9672 -- iter: 032/211
[A[ATraining Step: 79  | total loss: [1m[32m0.12404[0m[0m | time: 15.441s
[2K
| Adam | epoch: 012 | loss: 0.12404 - acc: 0.9706 -- iter: 064/211
[A[ATraining Step: 80  | total loss: [1m[32m0.20558[0m[0m | time: 21.662s
[2K
| Adam | epoch: 012 | loss: 0.20558 - acc: 0.9629 -- iter: 096/211
[A[ATraining Step: 81  | total loss: [1m[32m0.18615[0m[0m | time: 30.778s
[2K
| Adam | epoch: 012 | loss: 0.18615 - acc: 0.9666 -- iter: 128/211
[A[ATraining Step: 82  | total loss: [1m[32m0.17250[0m[0m | time: 39.852s
[2K
| Adam | epoch: 012 | loss: 0.17250 - acc: 0.9668 -- iter: 160/211
[A[ATraining Step: 83  | total loss: [1m[32m0.15705[0m[0m | time: 48.697s
[2K
| Adam | epoch: 012 | loss: 0.15705 - acc: 0.9701 -- iter: 192/211
[A[ATraining Step: 84  | total loss: [1m[32m0.14454[0m[0m | time: 60.817s
[2K
| Adam | epoch: 012 | loss: 0.14454 - acc: 0.9731 | val_loss: 1.94703 - val_acc: 0.6119 -- iter: 211/211
--
Training Step: 85  | total loss: [1m[32m0.13516[0m[0m | time: 8.940s
[2K
| Adam | epoch: 013 | loss: 0.13516 - acc: 0.9727 -- iter: 032/211
[A[ATraining Step: 86  | total loss: [1m[32m0.13673[0m[0m | time: 17.920s
[2K
| Adam | epoch: 013 | loss: 0.13673 - acc: 0.9723 -- iter: 064/211
[A[ATraining Step: 87  | total loss: [1m[32m0.13561[0m[0m | time: 23.891s
[2K
| Adam | epoch: 013 | loss: 0.13561 - acc: 0.9688 -- iter: 096/211
[A[ATraining Step: 88  | total loss: [1m[32m0.14902[0m[0m | time: 29.954s
[2K
| Adam | epoch: 013 | loss: 0.14902 - acc: 0.9667 -- iter: 128/211
[A[ATraining Step: 89  | total loss: [1m[32m0.13542[0m[0m | time: 38.845s
[2K
| Adam | epoch: 013 | loss: 0.13542 - acc: 0.9700 -- iter: 160/211
[A[ATraining Step: 90  | total loss: [1m[32m0.12995[0m[0m | time: 47.792s
[2K
| Adam | epoch: 013 | loss: 0.12995 - acc: 0.9699 -- iter: 192/211
[A[ATraining Step: 91  | total loss: [1m[32m0.12145[0m[0m | time: 59.677s
[2K
| Adam | epoch: 013 | loss: 0.12145 - acc: 0.9729 | val_loss: 0.58099 - val_acc: 0.7761 -- iter: 211/211
--
Training Step: 92  | total loss: [1m[32m0.12483[0m[0m | time: 9.194s
[2K
| Adam | epoch: 014 | loss: 0.12483 - acc: 0.9725 -- iter: 032/211
[A[ATraining Step: 93  | total loss: [1m[32m0.11486[0m[0m | time: 18.204s
[2K
| Adam | epoch: 014 | loss: 0.11486 - acc: 0.9752 -- iter: 064/211
[A[ATraining Step: 94  | total loss: [1m[32m0.10600[0m[0m | time: 27.089s
[2K
| Adam | epoch: 014 | loss: 0.10600 - acc: 0.9777 -- iter: 096/211
[A[ATraining Step: 95  | total loss: [1m[32m0.09875[0m[0m | time: 33.187s
[2K
| Adam | epoch: 014 | loss: 0.09875 - acc: 0.9799 -- iter: 128/211
[A[ATraining Step: 96  | total loss: [1m[32m0.09122[0m[0m | time: 39.221s
[2K
| Adam | epoch: 014 | loss: 0.09122 - acc: 0.9819 -- iter: 160/211
[A[ATraining Step: 97  | total loss: [1m[32m0.08330[0m[0m | time: 48.266s
[2K
| Adam | epoch: 014 | loss: 0.08330 - acc: 0.9837 -- iter: 192/211
[A[ATraining Step: 98  | total loss: [1m[32m0.07728[0m[0m | time: 60.131s
[2K
| Adam | epoch: 014 | loss: 0.07728 - acc: 0.9854 | val_loss: 0.32098 - val_acc: 0.8806 -- iter: 211/211
--
Training Step: 99  | total loss: [1m[32m0.07035[0m[0m | time: 9.037s
[2K
| Adam | epoch: 015 | loss: 0.07035 - acc: 0.9868 -- iter: 032/211
[A[ATraining Step: 100  | total loss: [1m[32m0.06402[0m[0m | time: 17.808s
[2K
| Adam | epoch: 015 | loss: 0.06402 - acc: 0.9882 -- iter: 064/211
[A[ATraining Step: 101  | total loss: [1m[32m0.06151[0m[0m | time: 26.807s
[2K
| Adam | epoch: 015 | loss: 0.06151 - acc: 0.9893 -- iter: 096/211
[A[ATraining Step: 102  | total loss: [1m[32m0.05679[0m[0m | time: 35.800s
[2K
| Adam | epoch: 015 | loss: 0.05679 - acc: 0.9904 -- iter: 128/211
[A[ATraining Step: 103  | total loss: [1m[32m0.05230[0m[0m | time: 41.968s
[2K
| Adam | epoch: 015 | loss: 0.05230 - acc: 0.9914 -- iter: 160/211
[A[ATraining Step: 104  | total loss: [1m[32m0.07482[0m[0m | time: 48.055s
[2K
| Adam | epoch: 015 | loss: 0.07482 - acc: 0.9870 -- iter: 192/211
[A[ATraining Step: 105  | total loss: [1m[32m0.07140[0m[0m | time: 59.875s
[2K
| Adam | epoch: 015 | loss: 0.07140 - acc: 0.9883 | val_loss: 0.19716 - val_acc: 0.9254 -- iter: 211/211
--
Validation AUC:0.9875222816399287
Validation AUPRC:0.9884545516124461
Test AUC:0.9824074074074074
Test AUPRC:0.9910714285714286
BestTestF1Score	0.93	0.86	0.93	1.0	0.88	35	0	27	5	0.93
BestTestMCCScore	0.93	0.86	0.93	1.0	0.88	35	0	27	5	0.93
BestTestAccuracyScore	0.93	0.86	0.93	1.0	0.88	35	0	27	5	0.93
BestValidationF1Score	0.95	0.91	0.96	1.0	0.91	30	0	34	3	0.93
BestValidationMCC	0.95	0.91	0.96	1.0	0.91	30	0	34	3	0.93
BestValidationAccuracy	0.95	0.91	0.96	1.0	0.91	30	0	34	3	0.93
TestPredictions (Threshold:0.93)
CHEMBL80820,TP,ACT,1.0	CHEMBL3400678,TP,ACT,1.0	CHEMBL981,TN,INACT,0.4399999976158142	CHEMBL2011540,TN,INACT,0.07000000029802322	CHEMBL550796,TP,ACT,1.0	CHEMBL596544,TN,INACT,0.0	CHEMBL36718,FN,ACT,0.5899999737739563	CHEMBL2204687,TN,INACT,0.09000000357627869	CHEMBL198997,FN,ACT,0.0	CHEMBL290761,TP,ACT,1.0	CHEMBL1173474,TN,INACT,0.0	CHEMBL374682,TN,INACT,0.029999999329447746	CHEMBL25202,TP,ACT,0.9599999785423279	CHEMBL309282,TP,ACT,1.0	CHEMBL131810,TP,ACT,0.9900000095367432	CHEMBL25361,TP,ACT,1.0	CHEMBL555726,TN,INACT,0.019999999552965164	CHEMBL387094,TN,INACT,0.0	CHEMBL75732,TP,ACT,1.0	CHEMBL3400677,TP,ACT,1.0	CHEMBL130231,TP,ACT,1.0	CHEMBL155325,TP,ACT,1.0	CHEMBL489597,TN,INACT,0.0	CHEMBL2011545,TN,INACT,0.009999999776482582	CHEMBL218591,TN,INACT,0.0	CHEMBL156997,TP,ACT,1.0	CHEMBL80271,TP,ACT,1.0	CHEMBL2348879,TN,INACT,0.0	CHEMBL108861,TN,INACT,0.019999999552965164	CHEMBL2348890,TN,INACT,0.0	CHEMBL3752362,TN,INACT,0.10999999940395355	CHEMBL2348884,TN,INACT,0.0	CHEMBL492046,TN,INACT,0.019999999552965164	CHEMBL237600,TN,INACT,0.009999999776482582	CHEMBL424639,TP,ACT,0.9800000190734863	CHEMBL77961,TP,ACT,1.0	CHEMBL156940,TP,ACT,1.0	CHEMBL132568,TP,ACT,1.0	CHEMBL1956370,TN,INACT,0.3400000035762787	CHEMBL133725,TP,ACT,0.9900000095367432	CHEMBL350485,FN,ACT,0.2800000011920929	CHEMBL3758549,TN,INACT,0.0	CHEMBL42314,TP,ACT,1.0	CHEMBL69367,TP,ACT,1.0	CHEMBL2204685,TN,INACT,0.03999999910593033	CHEMBL162345,TP,ACT,1.0	CHEMBL439780,TP,ACT,1.0	CHEMBL118972,TN,INACT,0.009999999776482582	CHEMBL41675,FN,ACT,0.8299999833106995	CHEMBL342051,TP,ACT,1.0	CHEMBL78587,TP,ACT,1.0	CHEMBL146449,TP,ACT,1.0	CHEMBL487561,TN,INACT,0.0	CHEMBL85322,TN,INACT,0.4399999976158142	CHEMBL1657,FN,ACT,0.6299999952316284	CHEMBL424190,TP,ACT,1.0	CHEMBL2204695,TN,INACT,0.0	CHEMBL74826,TP,ACT,0.9800000190734863	CHEMBL148327,TP,ACT,1.0	CHEMBL73321,TP,ACT,1.0	CHEMBL237241,TN,INACT,0.019999999552965164	CHEMBL3397549,TN,INACT,0.009999999776482582	CHEMBL284937,TP,ACT,1.0	CHEMBL153974,TP,ACT,1.0	CHEMBL345022,TP,ACT,1.0	CHEMBL275311,TP,ACT,1.0	CHEMBL134375,TP,ACT,0.9900000095367432	

