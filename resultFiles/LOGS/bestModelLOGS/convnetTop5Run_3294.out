ImageNetInceptionV2 CHEMBL4028 RMSprop 0.0001 30 0 0 0.8 False True
Number of active compounds :	129
Number of inactive compounds :	129
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4028_RMSprop_0.0001_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4028_RMSprop_0.0001_30_0.8/
---------------------------------
Training samples: 160
Validation samples: 50
--
Training Step: 1  | time: 37.606s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/160
[A[ATraining Step: 2  | total loss: [1m[32m0.60029[0m[0m | time: 45.627s
[2K
| RMSProp | epoch: 001 | loss: 0.60029 - acc: 0.5062 -- iter: 064/160
[A[ATraining Step: 3  | total loss: [1m[32m0.66887[0m[0m | time: 53.580s
[2K
| RMSProp | epoch: 001 | loss: 0.66887 - acc: 0.5267 -- iter: 096/160
[A[ATraining Step: 4  | total loss: [1m[32m0.69400[0m[0m | time: 61.503s
[2K
| RMSProp | epoch: 001 | loss: 0.69400 - acc: 0.5301 -- iter: 128/160
[A[ATraining Step: 5  | total loss: [1m[32m0.70178[0m[0m | time: 77.684s
[2K
| RMSProp | epoch: 001 | loss: 0.70178 - acc: 0.4876 | val_loss: 0.68885 - val_acc: 0.5800 -- iter: 160/160
--
Training Step: 6  | total loss: [1m[32m0.67549[0m[0m | time: 7.898s
[2K
| RMSProp | epoch: 002 | loss: 0.67549 - acc: 0.5157 -- iter: 032/160
[A[ATraining Step: 7  | total loss: [1m[32m0.68038[0m[0m | time: 16.770s
[2K
| RMSProp | epoch: 002 | loss: 0.68038 - acc: 0.5625 -- iter: 064/160
[A[ATraining Step: 8  | total loss: [1m[32m0.68362[0m[0m | time: 24.710s
[2K
| RMSProp | epoch: 002 | loss: 0.68362 - acc: 0.5625 -- iter: 096/160
[A[ATraining Step: 9  | total loss: [1m[32m0.70544[0m[0m | time: 32.455s
[2K
| RMSProp | epoch: 002 | loss: 0.70544 - acc: 0.5129 -- iter: 128/160
[A[ATraining Step: 10  | total loss: [1m[32m0.67578[0m[0m | time: 42.691s
[2K
| RMSProp | epoch: 002 | loss: 0.67578 - acc: 0.6002 | val_loss: 0.68953 - val_acc: 0.5800 -- iter: 160/160
--
Training Step: 11  | total loss: [1m[32m0.71133[0m[0m | time: 8.034s
[2K
| RMSProp | epoch: 003 | loss: 0.71133 - acc: 0.4935 -- iter: 032/160
[A[ATraining Step: 12  | total loss: [1m[32m0.69623[0m[0m | time: 15.848s
[2K
| RMSProp | epoch: 003 | loss: 0.69623 - acc: 0.4964 -- iter: 064/160
[A[ATraining Step: 13  | total loss: [1m[32m0.69884[0m[0m | time: 23.721s
[2K
| RMSProp | epoch: 003 | loss: 0.69884 - acc: 0.4980 -- iter: 096/160
[A[ATraining Step: 14  | total loss: [1m[32m0.68683[0m[0m | time: 31.663s
[2K
| RMSProp | epoch: 003 | loss: 0.68683 - acc: 0.5499 -- iter: 128/160
[A[ATraining Step: 15  | total loss: [1m[32m0.68016[0m[0m | time: 41.986s
[2K
| RMSProp | epoch: 003 | loss: 0.68016 - acc: 0.5549 | val_loss: 0.69432 - val_acc: 0.4200 -- iter: 160/160
--
Training Step: 16  | total loss: [1m[32m0.69584[0m[0m | time: 7.959s
[2K
| RMSProp | epoch: 004 | loss: 0.69584 - acc: 0.5343 -- iter: 032/160
[A[ATraining Step: 17  | total loss: [1m[32m0.67389[0m[0m | time: 15.887s
[2K
| RMSProp | epoch: 004 | loss: 0.67389 - acc: 0.5669 -- iter: 064/160
[A[ATraining Step: 18  | total loss: [1m[32m0.67528[0m[0m | time: 23.780s
[2K
| RMSProp | epoch: 004 | loss: 0.67528 - acc: 0.5546 -- iter: 096/160
[A[ATraining Step: 19  | total loss: [1m[32m0.66939[0m[0m | time: 31.620s
[2K
| RMSProp | epoch: 004 | loss: 0.66939 - acc: 0.5260 -- iter: 128/160
[A[ATraining Step: 20  | total loss: [1m[32m0.68272[0m[0m | time: 41.801s
[2K
| RMSProp | epoch: 004 | loss: 0.68272 - acc: 0.4975 | val_loss: 0.69852 - val_acc: 0.4200 -- iter: 160/160
--
Training Step: 21  | total loss: [1m[32m0.67797[0m[0m | time: 7.909s
[2K
| RMSProp | epoch: 005 | loss: 0.67797 - acc: 0.5274 -- iter: 032/160
[A[ATraining Step: 22  | total loss: [1m[32m0.68171[0m[0m | time: 15.858s
[2K
| RMSProp | epoch: 005 | loss: 0.68171 - acc: 0.5286 -- iter: 064/160
[A[ATraining Step: 23  | total loss: [1m[32m0.66915[0m[0m | time: 23.795s
[2K
| RMSProp | epoch: 005 | loss: 0.66915 - acc: 0.5566 -- iter: 096/160
[A[ATraining Step: 24  | total loss: [1m[32m0.66366[0m[0m | time: 31.607s
[2K
| RMSProp | epoch: 005 | loss: 0.66366 - acc: 0.5670 -- iter: 128/160
[A[ATraining Step: 25  | total loss: [1m[32m0.65129[0m[0m | time: 41.763s
[2K
| RMSProp | epoch: 005 | loss: 0.65129 - acc: 0.5828 | val_loss: 0.70898 - val_acc: 0.4200 -- iter: 160/160
--
Training Step: 26  | total loss: [1m[32m0.65268[0m[0m | time: 7.881s
[2K
| RMSProp | epoch: 006 | loss: 0.65268 - acc: 0.5774 -- iter: 032/160
[A[ATraining Step: 27  | total loss: [1m[32m0.65673[0m[0m | time: 15.719s
[2K
| RMSProp | epoch: 006 | loss: 0.65673 - acc: 0.6057 -- iter: 064/160
[A[ATraining Step: 28  | total loss: [1m[32m0.66155[0m[0m | time: 23.945s
[2K
| RMSProp | epoch: 006 | loss: 0.66155 - acc: 0.5949 -- iter: 096/160
[A[ATraining Step: 29  | total loss: [1m[32m0.65826[0m[0m | time: 31.729s
[2K
| RMSProp | epoch: 006 | loss: 0.65826 - acc: 0.6175 -- iter: 128/160
[A[ATraining Step: 30  | total loss: [1m[32m0.66636[0m[0m | time: 41.919s
[2K
| RMSProp | epoch: 006 | loss: 0.66636 - acc: 0.5970 | val_loss: 0.72917 - val_acc: 0.4200 -- iter: 160/160
--
Training Step: 31  | total loss: [1m[32m0.66840[0m[0m | time: 7.794s
[2K
| RMSProp | epoch: 007 | loss: 0.66840 - acc: 0.5746 -- iter: 032/160
[A[ATraining Step: 32  | total loss: [1m[32m0.66793[0m[0m | time: 15.627s
[2K
| RMSProp | epoch: 007 | loss: 0.66793 - acc: 0.5649 -- iter: 064/160
[A[ATraining Step: 33  | total loss: [1m[32m0.65459[0m[0m | time: 23.558s
[2K
| RMSProp | epoch: 007 | loss: 0.65459 - acc: 0.6192 -- iter: 096/160
[A[ATraining Step: 34  | total loss: [1m[32m0.65667[0m[0m | time: 31.300s
[2K
| RMSProp | epoch: 007 | loss: 0.65667 - acc: 0.6138 -- iter: 128/160
[A[ATraining Step: 35  | total loss: [1m[32m0.65920[0m[0m | time: 41.497s
[2K
| RMSProp | epoch: 007 | loss: 0.65920 - acc: 0.6030 | val_loss: 0.73165 - val_acc: 0.4200 -- iter: 160/160
--
Training Step: 36  | total loss: [1m[32m0.65624[0m[0m | time: 7.891s
[2K
| RMSProp | epoch: 008 | loss: 0.65624 - acc: 0.6203 -- iter: 032/160
[A[ATraining Step: 37  | total loss: [1m[32m0.64904[0m[0m | time: 15.622s
[2K
| RMSProp | epoch: 008 | loss: 0.64904 - acc: 0.6400 -- iter: 064/160
[A[ATraining Step: 38  | total loss: [1m[32m0.65292[0m[0m | time: 23.553s
[2K
| RMSProp | epoch: 008 | loss: 0.65292 - acc: 0.6248 -- iter: 096/160
[A[ATraining Step: 39  | total loss: [1m[32m0.64786[0m[0m | time: 31.474s
[2K
| RMSProp | epoch: 008 | loss: 0.64786 - acc: 0.6309 -- iter: 128/160
[A[ATraining Step: 40  | total loss: [1m[32m0.65740[0m[0m | time: 41.563s
[2K
| RMSProp | epoch: 008 | loss: 0.65740 - acc: 0.6063 | val_loss: 0.72977 - val_acc: 0.4200 -- iter: 160/160
--
Training Step: 41  | total loss: [1m[32m0.64808[0m[0m | time: 7.809s
[2K
| RMSProp | epoch: 009 | loss: 0.64808 - acc: 0.6327 -- iter: 032/160
[A[ATraining Step: 42  | total loss: [1m[32m0.64596[0m[0m | time: 15.534s
[2K
| RMSProp | epoch: 009 | loss: 0.64596 - acc: 0.6201 -- iter: 064/160
[A[ATraining Step: 43  | total loss: [1m[32m0.63425[0m[0m | time: 23.327s
[2K
| RMSProp | epoch: 009 | loss: 0.63425 - acc: 0.6540 -- iter: 096/160
[A[ATraining Step: 44  | total loss: [1m[32m0.63593[0m[0m | time: 31.185s
[2K
| RMSProp | epoch: 009 | loss: 0.63593 - acc: 0.6436 -- iter: 128/160
[A[ATraining Step: 45  | total loss: [1m[32m0.63653[0m[0m | time: 41.380s
[2K
| RMSProp | epoch: 009 | loss: 0.63653 - acc: 0.6564 | val_loss: 0.70707 - val_acc: 0.4200 -- iter: 160/160
--
Training Step: 46  | total loss: [1m[32m0.63261[0m[0m | time: 7.843s
[2K
| RMSProp | epoch: 010 | loss: 0.63261 - acc: 0.6563 -- iter: 032/160
[A[ATraining Step: 47  | total loss: [1m[32m0.63056[0m[0m | time: 15.851s
[2K
| RMSProp | epoch: 010 | loss: 0.63056 - acc: 0.6563 -- iter: 064/160
[A[ATraining Step: 48  | total loss: [1m[32m0.63971[0m[0m | time: 23.767s
[2K
| RMSProp | epoch: 010 | loss: 0.63971 - acc: 0.6262 -- iter: 096/160
[A[ATraining Step: 49  | total loss: [1m[32m0.64259[0m[0m | time: 31.889s
[2K
| RMSProp | epoch: 010 | loss: 0.64259 - acc: 0.6211 -- iter: 128/160
[A[ATraining Step: 50  | total loss: [1m[32m0.64004[0m[0m | time: 47.067s
[2K
| RMSProp | epoch: 010 | loss: 0.64004 - acc: 0.6411 | val_loss: 0.69651 - val_acc: 0.4200 -- iter: 160/160
--
Training Step: 51  | total loss: [1m[32m0.63486[0m[0m | time: 13.080s
[2K
| RMSProp | epoch: 011 | loss: 0.63486 - acc: 0.6529 -- iter: 032/160
[A[ATraining Step: 52  | total loss: [1m[32m0.63774[0m[0m | time: 27.666s
[2K
| RMSProp | epoch: 011 | loss: 0.63774 - acc: 0.6628 -- iter: 064/160
[A[ATraining Step: 53  | total loss: [1m[32m0.63059[0m[0m | time: 41.260s
[2K
| RMSProp | epoch: 011 | loss: 0.63059 - acc: 0.6803 -- iter: 096/160
[A[ATraining Step: 54  | total loss: [1m[32m0.62553[0m[0m | time: 54.665s
[2K
| RMSProp | epoch: 011 | loss: 0.62553 - acc: 0.6904 -- iter: 128/160
[A[ATraining Step: 55  | total loss: [1m[32m0.62151[0m[0m | time: 71.309s
[2K
| RMSProp | epoch: 011 | loss: 0.62151 - acc: 0.6989 | val_loss: 0.67423 - val_acc: 0.4800 -- iter: 160/160
--
Training Step: 56  | total loss: [1m[32m0.61993[0m[0m | time: 10.363s
[2K
| RMSProp | epoch: 012 | loss: 0.61993 - acc: 0.7017 -- iter: 032/160
[A[ATraining Step: 57  | total loss: [1m[32m0.61809[0m[0m | time: 18.323s
[2K
| RMSProp | epoch: 012 | loss: 0.61809 - acc: 0.7041 -- iter: 064/160
[A[ATraining Step: 58  | total loss: [1m[32m0.61906[0m[0m | time: 30.089s
[2K
| RMSProp | epoch: 012 | loss: 0.61906 - acc: 0.6975 -- iter: 096/160
[A[ATraining Step: 59  | total loss: [1m[32m0.61035[0m[0m | time: 37.894s
[2K
| RMSProp | epoch: 012 | loss: 0.61035 - acc: 0.7172 -- iter: 128/160
[A[ATraining Step: 60  | total loss: [1m[32m0.60306[0m[0m | time: 48.036s
[2K
| RMSProp | epoch: 012 | loss: 0.60306 - acc: 0.7215 | val_loss: 0.64068 - val_acc: 0.6600 -- iter: 160/160
--
Training Step: 61  | total loss: [1m[32m0.59121[0m[0m | time: 12.357s
[2K
| RMSProp | epoch: 013 | loss: 0.59121 - acc: 0.7456 -- iter: 032/160
[A[ATraining Step: 62  | total loss: [1m[32m0.59108[0m[0m | time: 24.534s
[2K
| RMSProp | epoch: 013 | loss: 0.59108 - acc: 0.7462 -- iter: 064/160
[A[ATraining Step: 63  | total loss: [1m[32m0.59712[0m[0m | time: 36.599s
[2K
| RMSProp | epoch: 013 | loss: 0.59712 - acc: 0.7348 -- iter: 096/160
[A[ATraining Step: 64  | total loss: [1m[32m0.59382[0m[0m | time: 49.330s
[2K
| RMSProp | epoch: 013 | loss: 0.59382 - acc: 0.7406 -- iter: 128/160
[A[ATraining Step: 65  | total loss: [1m[32m0.59393[0m[0m | time: 65.606s
[2K
| RMSProp | epoch: 013 | loss: 0.59393 - acc: 0.7495 | val_loss: 0.61017 - val_acc: 0.7400 -- iter: 160/160
--
Training Step: 66  | total loss: [1m[32m0.58784[0m[0m | time: 12.593s
[2K
| RMSProp | epoch: 014 | loss: 0.58784 - acc: 0.7571 -- iter: 032/160
[A[ATraining Step: 67  | total loss: [1m[32m0.58386[0m[0m | time: 24.128s
[2K
| RMSProp | epoch: 014 | loss: 0.58386 - acc: 0.7563 -- iter: 064/160
[A[ATraining Step: 68  | total loss: [1m[32m0.58014[0m[0m | time: 31.931s
[2K
| RMSProp | epoch: 014 | loss: 0.58014 - acc: 0.7629 -- iter: 096/160
[A[ATraining Step: 69  | total loss: [1m[32m0.57454[0m[0m | time: 39.786s
[2K
| RMSProp | epoch: 014 | loss: 0.57454 - acc: 0.7687 -- iter: 128/160
[A[ATraining Step: 70  | total loss: [1m[32m0.56748[0m[0m | time: 51.365s
[2K
| RMSProp | epoch: 014 | loss: 0.56748 - acc: 0.7774 | val_loss: 0.57806 - val_acc: 0.7400 -- iter: 160/160
--
Training Step: 71  | total loss: [1m[32m0.56126[0m[0m | time: 11.847s
[2K
| RMSProp | epoch: 015 | loss: 0.56126 - acc: 0.7849 -- iter: 032/160
[A[ATraining Step: 72  | total loss: [1m[32m0.55855[0m[0m | time: 24.267s
[2K
| RMSProp | epoch: 015 | loss: 0.55855 - acc: 0.7916 -- iter: 064/160
[A[ATraining Step: 73  | total loss: [1m[32m0.55231[0m[0m | time: 36.425s
[2K
| RMSProp | epoch: 015 | loss: 0.55231 - acc: 0.8008 -- iter: 096/160
[A[ATraining Step: 74  | total loss: [1m[32m0.55019[0m[0m | time: 48.683s
[2K
| RMSProp | epoch: 015 | loss: 0.55019 - acc: 0.8021 -- iter: 128/160
[A[ATraining Step: 75  | total loss: [1m[32m0.54832[0m[0m | time: 64.935s
[2K
| RMSProp | epoch: 015 | loss: 0.54832 - acc: 0.7998 | val_loss: 0.55288 - val_acc: 0.7400 -- iter: 160/160
--
Training Step: 76  | total loss: [1m[32m0.54138[0m[0m | time: 11.845s
[2K
| RMSProp | epoch: 016 | loss: 0.54138 - acc: 0.8079 -- iter: 032/160
[A[ATraining Step: 77  | total loss: [1m[32m0.53882[0m[0m | time: 24.627s
[2K
| RMSProp | epoch: 016 | loss: 0.53882 - acc: 0.7985 -- iter: 064/160
[A[ATraining Step: 78  | total loss: [1m[32m0.53218[0m[0m | time: 33.247s
[2K
| RMSProp | epoch: 016 | loss: 0.53218 - acc: 0.7967 -- iter: 096/160
[A[ATraining Step: 79  | total loss: [1m[32m0.52253[0m[0m | time: 41.139s
[2K
| RMSProp | epoch: 016 | loss: 0.52253 - acc: 0.8015 -- iter: 128/160
[A[ATraining Step: 80  | total loss: [1m[32m0.52416[0m[0m | time: 51.494s
[2K
| RMSProp | epoch: 016 | loss: 0.52416 - acc: 0.7995 | val_loss: 0.53173 - val_acc: 0.7400 -- iter: 160/160
--
Training Step: 81  | total loss: [1m[32m0.52637[0m[0m | time: 12.373s
[2K
| RMSProp | epoch: 017 | loss: 0.52637 - acc: 0.7913 -- iter: 032/160
[A[ATraining Step: 82  | total loss: [1m[32m0.53329[0m[0m | time: 24.635s
[2K
| RMSProp | epoch: 017 | loss: 0.53329 - acc: 0.7778 -- iter: 064/160
[A[ATraining Step: 83  | total loss: [1m[32m0.52440[0m[0m | time: 36.789s
[2K
| RMSProp | epoch: 017 | loss: 0.52440 - acc: 0.7875 -- iter: 096/160
[A[ATraining Step: 84  | total loss: [1m[32m0.51118[0m[0m | time: 48.708s
[2K
| RMSProp | epoch: 017 | loss: 0.51118 - acc: 0.8025 -- iter: 128/160
[A[ATraining Step: 85  | total loss: [1m[32m0.49421[0m[0m | time: 64.447s
[2K
| RMSProp | epoch: 017 | loss: 0.49421 - acc: 0.8223 | val_loss: 0.52733 - val_acc: 0.7000 -- iter: 160/160
--
Training Step: 86  | total loss: [1m[32m0.49558[0m[0m | time: 12.528s
[2K
| RMSProp | epoch: 018 | loss: 0.49558 - acc: 0.8182 -- iter: 032/160
[A[ATraining Step: 87  | total loss: [1m[32m0.49306[0m[0m | time: 25.445s
[2K
| RMSProp | epoch: 018 | loss: 0.49306 - acc: 0.8207 -- iter: 064/160
[A[ATraining Step: 88  | total loss: [1m[32m0.49092[0m[0m | time: 33.432s
[2K
| RMSProp | epoch: 018 | loss: 0.49092 - acc: 0.8136 -- iter: 096/160
[A[ATraining Step: 89  | total loss: [1m[32m0.48674[0m[0m | time: 41.263s
[2K
| RMSProp | epoch: 018 | loss: 0.48674 - acc: 0.8135 -- iter: 128/160
[A[ATraining Step: 90  | total loss: [1m[32m0.48620[0m[0m | time: 51.480s
[2K
| RMSProp | epoch: 018 | loss: 0.48620 - acc: 0.8134 | val_loss: 0.48349 - val_acc: 0.7600 -- iter: 160/160
--
Training Step: 91  | total loss: [1m[32m0.47984[0m[0m | time: 12.188s
[2K
| RMSProp | epoch: 019 | loss: 0.47984 - acc: 0.8165 -- iter: 032/160
[A[ATraining Step: 92  | total loss: [1m[32m0.47041[0m[0m | time: 24.601s
[2K
| RMSProp | epoch: 019 | loss: 0.47041 - acc: 0.8254 -- iter: 064/160
[A[ATraining Step: 93  | total loss: [1m[32m0.46386[0m[0m | time: 37.079s
[2K
| RMSProp | epoch: 019 | loss: 0.46386 - acc: 0.8304 -- iter: 096/160
[A[ATraining Step: 94  | total loss: [1m[32m0.45704[0m[0m | time: 49.362s
[2K
| RMSProp | epoch: 019 | loss: 0.45704 - acc: 0.8286 -- iter: 128/160
[A[ATraining Step: 95  | total loss: [1m[32m0.45458[0m[0m | time: 65.399s
[2K
| RMSProp | epoch: 019 | loss: 0.45458 - acc: 0.8301 | val_loss: 0.48183 - val_acc: 0.7200 -- iter: 160/160
--
Training Step: 96  | total loss: [1m[32m0.44929[0m[0m | time: 12.158s
[2K
| RMSProp | epoch: 020 | loss: 0.44929 - acc: 0.8284 -- iter: 032/160
[A[ATraining Step: 97  | total loss: [1m[32m0.43707[0m[0m | time: 23.570s
[2K
| RMSProp | epoch: 020 | loss: 0.43707 - acc: 0.8393 -- iter: 064/160
[A[ATraining Step: 98  | total loss: [1m[32m0.42781[0m[0m | time: 31.440s
[2K
| RMSProp | epoch: 020 | loss: 0.42781 - acc: 0.8428 -- iter: 096/160
[A[ATraining Step: 99  | total loss: [1m[32m0.43240[0m[0m | time: 39.406s
[2K
| RMSProp | epoch: 020 | loss: 0.43240 - acc: 0.8336 -- iter: 128/160
[A[ATraining Step: 100  | total loss: [1m[32m0.42538[0m[0m | time: 49.563s
[2K
| RMSProp | epoch: 020 | loss: 0.42538 - acc: 0.8471 | val_loss: 0.48493 - val_acc: 0.7200 -- iter: 160/160
--
Training Step: 101  | total loss: [1m[32m0.41033[0m[0m | time: 10.596s
[2K
| RMSProp | epoch: 021 | loss: 0.41033 - acc: 0.8592 -- iter: 032/160
[A[ATraining Step: 102  | total loss: [1m[32m0.39864[0m[0m | time: 22.528s
[2K
| RMSProp | epoch: 021 | loss: 0.39864 - acc: 0.8733 -- iter: 064/160
[A[ATraining Step: 103  | total loss: [1m[32m0.38093[0m[0m | time: 34.703s
[2K
| RMSProp | epoch: 021 | loss: 0.38093 - acc: 0.8860 -- iter: 096/160
[A[ATraining Step: 104  | total loss: [1m[32m0.38561[0m[0m | time: 46.606s
[2K
| RMSProp | epoch: 021 | loss: 0.38561 - acc: 0.8724 -- iter: 128/160
[A[ATraining Step: 105  | total loss: [1m[32m0.39325[0m[0m | time: 62.580s
[2K
| RMSProp | epoch: 021 | loss: 0.39325 - acc: 0.8664 | val_loss: 0.41305 - val_acc: 0.8200 -- iter: 160/160
--
Training Step: 106  | total loss: [1m[32m0.38718[0m[0m | time: 15.595s
[2K
| RMSProp | epoch: 022 | loss: 0.38718 - acc: 0.8704 -- iter: 032/160
[A[ATraining Step: 107  | total loss: [1m[32m0.38293[0m[0m | time: 30.455s
[2K
| RMSProp | epoch: 022 | loss: 0.38293 - acc: 0.8677 -- iter: 064/160
[A[ATraining Step: 108  | total loss: [1m[32m0.37064[0m[0m | time: 43.057s
[2K
| RMSProp | epoch: 022 | loss: 0.37064 - acc: 0.8778 -- iter: 096/160
[A[ATraining Step: 109  | total loss: [1m[32m0.35437[0m[0m | time: 55.854s
[2K
| RMSProp | epoch: 022 | loss: 0.35437 - acc: 0.8900 -- iter: 128/160
[A[ATraining Step: 110  | total loss: [1m[32m0.34250[0m[0m | time: 77.701s
[2K
| RMSProp | epoch: 022 | loss: 0.34250 - acc: 0.8979 | val_loss: 0.41167 - val_acc: 0.7800 -- iter: 160/160
--
Training Step: 111  | total loss: [1m[32m0.34413[0m[0m | time: 17.668s
[2K
| RMSProp | epoch: 023 | loss: 0.34413 - acc: 0.8925 -- iter: 032/160
[A[ATraining Step: 112  | total loss: [1m[32m0.34576[0m[0m | time: 34.555s
[2K
| RMSProp | epoch: 023 | loss: 0.34576 - acc: 0.8876 -- iter: 064/160
[A[ATraining Step: 113  | total loss: [1m[32m0.34333[0m[0m | time: 51.164s
[2K
| RMSProp | epoch: 023 | loss: 0.34333 - acc: 0.8832 -- iter: 096/160
[A[ATraining Step: 114  | total loss: [1m[32m0.33141[0m[0m | time: 68.700s
[2K
| RMSProp | epoch: 023 | loss: 0.33141 - acc: 0.8949 -- iter: 128/160
[A[ATraining Step: 115  | total loss: [1m[32m0.31588[0m[0m | time: 92.720s
[2K
| RMSProp | epoch: 023 | loss: 0.31588 - acc: 0.9054 | val_loss: 0.39247 - val_acc: 0.8000 -- iter: 160/160
--
Training Step: 116  | total loss: [1m[32m0.31042[0m[0m | time: 17.921s
[2K
| RMSProp | epoch: 024 | loss: 0.31042 - acc: 0.9086 -- iter: 032/160
[A[ATraining Step: 117  | total loss: [1m[32m0.29946[0m[0m | time: 36.090s
[2K
| RMSProp | epoch: 024 | loss: 0.29946 - acc: 0.9178 -- iter: 064/160
[A[ATraining Step: 118  | total loss: [1m[32m0.31806[0m[0m | time: 53.794s
[2K
| RMSProp | epoch: 024 | loss: 0.31806 - acc: 0.9104 -- iter: 096/160
[A[ATraining Step: 119  | total loss: [1m[32m0.30659[0m[0m | time: 71.330s
[2K
| RMSProp | epoch: 024 | loss: 0.30659 - acc: 0.9193 -- iter: 128/160
[A[ATraining Step: 120  | total loss: [1m[32m0.29965[0m[0m | time: 88.262s
[2K
| RMSProp | epoch: 024 | loss: 0.29965 - acc: 0.9243 | val_loss: 0.34220 - val_acc: 0.8400 -- iter: 160/160
--
Training Step: 121  | total loss: [1m[32m0.28698[0m[0m | time: 23.876s
[2K
| RMSProp | epoch: 025 | loss: 0.28698 - acc: 0.9287 -- iter: 032/160
[A[ATraining Step: 122  | total loss: [1m[32m0.27492[0m[0m | time: 46.454s
[2K
| RMSProp | epoch: 025 | loss: 0.27492 - acc: 0.9327 -- iter: 064/160
[A[ATraining Step: 123  | total loss: [1m[32m0.26778[0m[0m | time: 63.782s
[2K
| RMSProp | epoch: 025 | loss: 0.26778 - acc: 0.9332 -- iter: 096/160
[A[ATraining Step: 124  | total loss: [1m[32m0.27103[0m[0m | time: 80.082s
[2K
| RMSProp | epoch: 025 | loss: 0.27103 - acc: 0.9274 -- iter: 128/160
[A[ATraining Step: 125  | total loss: [1m[32m0.25698[0m[0m | time: 103.680s
[2K
| RMSProp | epoch: 025 | loss: 0.25698 - acc: 0.9346 | val_loss: 0.51589 - val_acc: 0.6600 -- iter: 160/160
--
Training Step: 126  | total loss: [1m[32m0.24435[0m[0m | time: 17.310s
[2K
| RMSProp | epoch: 026 | loss: 0.24435 - acc: 0.9412 -- iter: 032/160
[A[ATraining Step: 127  | total loss: [1m[32m0.22791[0m[0m | time: 35.058s
[2K
| RMSProp | epoch: 026 | loss: 0.22791 - acc: 0.9471 -- iter: 064/160
[A[ATraining Step: 128  | total loss: [1m[32m0.21498[0m[0m | time: 53.183s
[2K
| RMSProp | epoch: 026 | loss: 0.21498 - acc: 0.9524 -- iter: 096/160
[A[ATraining Step: 129  | total loss: [1m[32m0.22169[0m[0m | time: 70.918s
[2K
| RMSProp | epoch: 026 | loss: 0.22169 - acc: 0.9509 -- iter: 128/160
[A[ATraining Step: 130  | total loss: [1m[32m0.22353[0m[0m | time: 88.143s
[2K
| RMSProp | epoch: 026 | loss: 0.22353 - acc: 0.9464 | val_loss: 0.28720 - val_acc: 0.8600 -- iter: 160/160
--
Training Step: 131  | total loss: [1m[32m0.21895[0m[0m | time: 17.601s
[2K
| RMSProp | epoch: 027 | loss: 0.21895 - acc: 0.9486 -- iter: 032/160
[A[ATraining Step: 132  | total loss: [1m[32m0.21899[0m[0m | time: 34.950s
[2K
| RMSProp | epoch: 027 | loss: 0.21899 - acc: 0.9507 -- iter: 064/160
[A[ATraining Step: 133  | total loss: [1m[32m0.20608[0m[0m | time: 51.783s
[2K
| RMSProp | epoch: 027 | loss: 0.20608 - acc: 0.9556 -- iter: 096/160
[A[ATraining Step: 134  | total loss: [1m[32m0.19689[0m[0m | time: 68.895s
[2K
| RMSProp | epoch: 027 | loss: 0.19689 - acc: 0.9569 -- iter: 128/160
[A[ATraining Step: 135  | total loss: [1m[32m0.18420[0m[0m | time: 91.155s
[2K
| RMSProp | epoch: 027 | loss: 0.18420 - acc: 0.9612 | val_loss: 0.33600 - val_acc: 0.8000 -- iter: 160/160
--
Training Step: 136  | total loss: [1m[32m0.18315[0m[0m | time: 18.049s
[2K
| RMSProp | epoch: 028 | loss: 0.18315 - acc: 0.9620 -- iter: 032/160
[A[ATraining Step: 137  | total loss: [1m[32m0.17087[0m[0m | time: 39.773s
[2K
| RMSProp | epoch: 028 | loss: 0.17087 - acc: 0.9658 -- iter: 064/160
[A[ATraining Step: 138  | total loss: [1m[32m0.16917[0m[0m | time: 53.317s
[2K
| RMSProp | epoch: 028 | loss: 0.16917 - acc: 0.9598 -- iter: 096/160
[A[ATraining Step: 139  | total loss: [1m[32m0.15757[0m[0m | time: 69.073s
[2K
| RMSProp | epoch: 028 | loss: 0.15757 - acc: 0.9638 -- iter: 128/160
[A[ATraining Step: 140  | total loss: [1m[32m0.15113[0m[0m | time: 87.140s
[2K
| RMSProp | epoch: 028 | loss: 0.15113 - acc: 0.9675 | val_loss: 0.43938 - val_acc: 0.7800 -- iter: 160/160
--
Training Step: 141  | total loss: [1m[32m0.14081[0m[0m | time: 12.289s
[2K
| RMSProp | epoch: 029 | loss: 0.14081 - acc: 0.9707 -- iter: 032/160
[A[ATraining Step: 142  | total loss: [1m[32m0.15086[0m[0m | time: 24.554s
[2K
| RMSProp | epoch: 029 | loss: 0.15086 - acc: 0.9674 -- iter: 064/160
[A[ATraining Step: 143  | total loss: [1m[32m0.14766[0m[0m | time: 40.465s
[2K
| RMSProp | epoch: 029 | loss: 0.14766 - acc: 0.9706 -- iter: 096/160
[A[ATraining Step: 144  | total loss: [1m[32m0.13599[0m[0m | time: 58.576s
[2K
| RMSProp | epoch: 029 | loss: 0.13599 - acc: 0.9736 -- iter: 128/160
[A[ATraining Step: 145  | total loss: [1m[32m0.12423[0m[0m | time: 80.896s
[2K
| RMSProp | epoch: 029 | loss: 0.12423 - acc: 0.9762 | val_loss: 0.98501 - val_acc: 0.6200 -- iter: 160/160
--
Training Step: 146  | total loss: [1m[32m0.13680[0m[0m | time: 18.581s
[2K
| RMSProp | epoch: 030 | loss: 0.13680 - acc: 0.9692 -- iter: 032/160
[A[ATraining Step: 147  | total loss: [1m[32m0.12768[0m[0m | time: 36.283s
[2K
| RMSProp | epoch: 030 | loss: 0.12768 - acc: 0.9723 -- iter: 064/160
[A[ATraining Step: 148  | total loss: [1m[32m0.11794[0m[0m | time: 54.422s
[2K
| RMSProp | epoch: 030 | loss: 0.11794 - acc: 0.9751 -- iter: 096/160
[A[ATraining Step: 149  | total loss: [1m[32m0.10884[0m[0m | time: 74.105s
[2K
| RMSProp | epoch: 030 | loss: 0.10884 - acc: 0.9776 -- iter: 128/160
[A[ATraining Step: 150  | total loss: [1m[32m0.10053[0m[0m | time: 92.025s
[2K
| RMSProp | epoch: 030 | loss: 0.10053 - acc: 0.9798 | val_loss: 0.30197 - val_acc: 0.8400 -- iter: 160/160
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9704433497536945
Validation AUPRC:0.9452212074654534
Test AUC:0.9533011272141707
Test AUPRC:0.9701903412088595
BestTestF1Score	0.88	0.76	0.88	0.92	0.85	23	2	21	4	0.2
BestTestMCCScore	0.88	0.76	0.88	0.92	0.85	23	2	21	4	0.2
BestTestAccuracyScore	0.88	0.76	0.88	0.92	0.85	23	2	21	4	0.2
BestValidationF1Score	0.95	0.92	0.96	0.91	1.0	21	2	27	0	0.2
BestValidationMCC	0.95	0.92	0.96	0.91	1.0	21	2	27	0	0.2
BestValidationAccuracy	0.95	0.92	0.96	0.91	1.0	21	2	27	0	0.2
TestPredictions (Threshold:0.2)
CHEMBL337251,TN,INACT,0.12999999523162842	CHEMBL223983,TN,INACT,0.0	CHEMBL1629801,TN,INACT,0.0	CHEMBL3105527,TN,INACT,0.019999999552965164	CHEMBL541827,TP,ACT,0.6100000143051147	CHEMBL345586,TN,INACT,0.12999999523162842	CHEMBL120250,TP,ACT,0.4000000059604645	CHEMBL72923,FN,ACT,0.09000000357627869	CHEMBL73143,TP,ACT,0.6700000166893005	CHEMBL118184,TP,ACT,0.800000011920929	CHEMBL73850,TP,ACT,0.7799999713897705	CHEMBL3664707,TN,INACT,0.009999999776482582	CHEMBL74693,TP,ACT,0.6100000143051147	CHEMBL495574,TN,INACT,0.009999999776482582	CHEMBL297608,FP,INACT,0.3400000035762787	CHEMBL429786,FP,INACT,0.36000001430511475	CHEMBL1171991,TN,INACT,0.019999999552965164	CHEMBL307631,TP,ACT,0.7799999713897705	CHEMBL2011183,TN,INACT,0.10000000149011612	CHEMBL73426,TP,ACT,0.6899999976158142	CHEMBL8778,TP,ACT,0.8600000143051147	CHEMBL330837,TP,ACT,0.699999988079071	CHEMBL443530,TN,INACT,0.0	CHEMBL168820,TP,ACT,0.44999998807907104	CHEMBL335687,FN,ACT,0.009999999776482582	CHEMBL8879,TP,ACT,0.8799999952316284	CHEMBL99370,TN,INACT,0.009999999776482582	CHEMBL179589,TN,INACT,0.029999999329447746	CHEMBL3664694,TN,INACT,0.0	CHEMBL148928,TP,ACT,0.8299999833106995	CHEMBL75451,TP,ACT,0.6499999761581421	CHEMBL3664682,TN,INACT,0.029999999329447746	CHEMBL74915,TP,ACT,0.7099999785423279	CHEMBL1743613,FN,ACT,0.1899999976158142	CHEMBL120019,TP,ACT,0.5299999713897705	CHEMBL76234,FN,ACT,0.18000000715255737	CHEMBL121043,TP,ACT,0.7400000095367432	CHEMBL72273,TP,ACT,0.7900000214576721	CHEMBL333236,TP,ACT,0.7200000286102295	CHEMBL73407,TP,ACT,0.7400000095367432	CHEMBL3699341,TN,INACT,0.009999999776482582	CHEMBL75334,TP,ACT,0.4099999964237213	CHEMBL128678,TN,INACT,0.15000000596046448	CHEMBL120811,TP,ACT,0.2199999988079071	CHEMBL112908,TN,INACT,0.0	CHEMBL417603,TP,ACT,0.699999988079071	CHEMBL458188,TN,INACT,0.009999999776482582	CHEMBL39275,TN,INACT,0.009999999776482582	CHEMBL544903,TN,INACT,0.019999999552965164	CHEMBL3664695,TN,INACT,0.0	

