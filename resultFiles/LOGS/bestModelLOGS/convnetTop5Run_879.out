CNNModel CHEMBL4793 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	420
Number of inactive compounds :	420
---------------------------------
Run id: CNNModel_CHEMBL4793_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4793_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 478
Validation samples: 150
--
Training Step: 1  | time: 0.999s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/478
[A[ATraining Step: 2  | total loss: [1m[32m0.62368[0m[0m | time: 1.784s
[2K
| Adam | epoch: 001 | loss: 0.62368 - acc: 0.5062 -- iter: 064/478
[A[ATraining Step: 3  | total loss: [1m[32m0.67922[0m[0m | time: 2.727s
[2K
| Adam | epoch: 001 | loss: 0.67922 - acc: 0.5523 -- iter: 096/478
[A[ATraining Step: 4  | total loss: [1m[32m0.69033[0m[0m | time: 3.943s
[2K
| Adam | epoch: 001 | loss: 0.69033 - acc: 0.5131 -- iter: 128/478
[A[ATraining Step: 5  | total loss: [1m[32m0.69439[0m[0m | time: 5.233s
[2K
| Adam | epoch: 001 | loss: 0.69439 - acc: 0.4824 -- iter: 160/478
[A[ATraining Step: 6  | total loss: [1m[32m0.69706[0m[0m | time: 7.855s
[2K
| Adam | epoch: 001 | loss: 0.69706 - acc: 0.4535 -- iter: 192/478
[A[ATraining Step: 7  | total loss: [1m[32m0.69549[0m[0m | time: 12.605s
[2K
| Adam | epoch: 001 | loss: 0.69549 - acc: 0.4627 -- iter: 224/478
[A[ATraining Step: 8  | total loss: [1m[32m0.69486[0m[0m | time: 13.479s
[2K
| Adam | epoch: 001 | loss: 0.69486 - acc: 0.4485 -- iter: 256/478
[A[ATraining Step: 9  | total loss: [1m[32m0.69376[0m[0m | time: 14.368s
[2K
| Adam | epoch: 001 | loss: 0.69376 - acc: 0.5089 -- iter: 288/478
[A[ATraining Step: 10  | total loss: [1m[32m0.69335[0m[0m | time: 15.324s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.5044 -- iter: 320/478
[A[ATraining Step: 11  | total loss: [1m[32m0.69323[0m[0m | time: 16.255s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.4875 -- iter: 352/478
[A[ATraining Step: 12  | total loss: [1m[32m0.69304[0m[0m | time: 17.309s
[2K
| Adam | epoch: 001 | loss: 0.69304 - acc: 0.5494 -- iter: 384/478
[A[ATraining Step: 13  | total loss: [1m[32m0.69316[0m[0m | time: 18.243s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5148 -- iter: 416/478
[A[ATraining Step: 14  | total loss: [1m[32m0.69280[0m[0m | time: 19.102s
[2K
| Adam | epoch: 001 | loss: 0.69280 - acc: 0.5599 -- iter: 448/478
[A[ATraining Step: 15  | total loss: [1m[32m0.69347[0m[0m | time: 21.473s
[2K
| Adam | epoch: 001 | loss: 0.69347 - acc: 0.4998 | val_loss: 0.69109 - val_acc: 0.6000 -- iter: 478/478
--
Training Step: 16  | total loss: [1m[32m0.69266[0m[0m | time: 0.761s
[2K
| Adam | epoch: 002 | loss: 0.69266 - acc: 0.5374 -- iter: 032/478
[A[ATraining Step: 17  | total loss: [1m[32m0.69210[0m[0m | time: 1.674s
[2K
| Adam | epoch: 002 | loss: 0.69210 - acc: 0.5599 -- iter: 064/478
[A[ATraining Step: 18  | total loss: [1m[32m0.69099[0m[0m | time: 2.580s
[2K
| Adam | epoch: 002 | loss: 0.69099 - acc: 0.5933 -- iter: 096/478
[A[ATraining Step: 19  | total loss: [1m[32m0.69171[0m[0m | time: 3.516s
[2K
| Adam | epoch: 002 | loss: 0.69171 - acc: 0.5622 -- iter: 128/478
[A[ATraining Step: 20  | total loss: [1m[32m0.69122[0m[0m | time: 4.520s
[2K
| Adam | epoch: 002 | loss: 0.69122 - acc: 0.5623 -- iter: 160/478
[A[ATraining Step: 21  | total loss: [1m[32m0.69357[0m[0m | time: 5.500s
[2K
| Adam | epoch: 002 | loss: 0.69357 - acc: 0.5236 -- iter: 192/478
[A[ATraining Step: 22  | total loss: [1m[32m0.69460[0m[0m | time: 6.454s
[2K
| Adam | epoch: 002 | loss: 0.69460 - acc: 0.5071 -- iter: 224/478
[A[ATraining Step: 23  | total loss: [1m[32m0.69592[0m[0m | time: 7.266s
[2K
| Adam | epoch: 002 | loss: 0.69592 - acc: 0.4869 -- iter: 256/478
[A[ATraining Step: 24  | total loss: [1m[32m0.69302[0m[0m | time: 8.554s
[2K
| Adam | epoch: 002 | loss: 0.69302 - acc: 0.5257 -- iter: 288/478
[A[ATraining Step: 25  | total loss: [1m[32m0.69599[0m[0m | time: 9.857s
[2K
| Adam | epoch: 002 | loss: 0.69599 - acc: 0.4761 -- iter: 320/478
[A[ATraining Step: 26  | total loss: [1m[32m0.69353[0m[0m | time: 10.817s
[2K
| Adam | epoch: 002 | loss: 0.69353 - acc: 0.5155 -- iter: 352/478
[A[ATraining Step: 27  | total loss: [1m[32m0.69229[0m[0m | time: 12.735s
[2K
| Adam | epoch: 002 | loss: 0.69229 - acc: 0.5356 -- iter: 384/478
[A[ATraining Step: 28  | total loss: [1m[32m0.69341[0m[0m | time: 19.096s
[2K
| Adam | epoch: 002 | loss: 0.69341 - acc: 0.5111 -- iter: 416/478
[A[ATraining Step: 29  | total loss: [1m[32m0.69315[0m[0m | time: 20.013s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5160 -- iter: 448/478
[A[ATraining Step: 30  | total loss: [1m[32m0.69354[0m[0m | time: 22.011s
[2K
| Adam | epoch: 002 | loss: 0.69354 - acc: 0.5048 | val_loss: 0.68914 - val_acc: 0.6000 -- iter: 478/478
--
Training Step: 31  | total loss: [1m[32m0.69388[0m[0m | time: 1.222s
[2K
| Adam | epoch: 003 | loss: 0.69388 - acc: 0.4965 -- iter: 032/478
[A[ATraining Step: 32  | total loss: [1m[32m0.69277[0m[0m | time: 2.596s
[2K
| Adam | epoch: 003 | loss: 0.69277 - acc: 0.5198 -- iter: 064/478
[A[ATraining Step: 33  | total loss: [1m[32m0.69446[0m[0m | time: 4.611s
[2K
| Adam | epoch: 003 | loss: 0.69446 - acc: 0.4789 -- iter: 096/478
[A[ATraining Step: 34  | total loss: [1m[32m0.69298[0m[0m | time: 12.938s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5169 -- iter: 128/478
[A[ATraining Step: 35  | total loss: [1m[32m0.69258[0m[0m | time: 13.883s
[2K
| Adam | epoch: 003 | loss: 0.69258 - acc: 0.5264 -- iter: 160/478
[A[ATraining Step: 36  | total loss: [1m[32m0.69272[0m[0m | time: 14.804s
[2K
| Adam | epoch: 003 | loss: 0.69272 - acc: 0.5210 -- iter: 192/478
[A[ATraining Step: 37  | total loss: [1m[32m0.69236[0m[0m | time: 15.759s
[2K
| Adam | epoch: 003 | loss: 0.69236 - acc: 0.5293 -- iter: 224/478
[A[ATraining Step: 38  | total loss: [1m[32m0.69210[0m[0m | time: 16.763s
[2K
| Adam | epoch: 003 | loss: 0.69210 - acc: 0.5358 -- iter: 256/478
[A[ATraining Step: 39  | total loss: [1m[32m0.69230[0m[0m | time: 17.753s
[2K
| Adam | epoch: 003 | loss: 0.69230 - acc: 0.5289 -- iter: 288/478
[A[ATraining Step: 40  | total loss: [1m[32m0.69201[0m[0m | time: 18.672s
[2K
| Adam | epoch: 003 | loss: 0.69201 - acc: 0.5352 -- iter: 320/478
[A[ATraining Step: 41  | total loss: [1m[32m0.69273[0m[0m | time: 19.687s
[2K
| Adam | epoch: 003 | loss: 0.69273 - acc: 0.5173 -- iter: 352/478
[A[ATraining Step: 42  | total loss: [1m[32m0.69277[0m[0m | time: 20.710s
[2K
| Adam | epoch: 003 | loss: 0.69277 - acc: 0.5142 -- iter: 384/478
[A[ATraining Step: 43  | total loss: [1m[32m0.69217[0m[0m | time: 21.720s
[2K
| Adam | epoch: 003 | loss: 0.69217 - acc: 0.5282 -- iter: 416/478
[A[ATraining Step: 44  | total loss: [1m[32m0.69239[0m[0m | time: 22.526s
[2K
| Adam | epoch: 003 | loss: 0.69239 - acc: 0.5233 -- iter: 448/478
[A[ATraining Step: 45  | total loss: [1m[32m0.69208[0m[0m | time: 24.143s
[2K
| Adam | epoch: 003 | loss: 0.69208 - acc: 0.5300 | val_loss: 0.68826 - val_acc: 0.6000 -- iter: 478/478
--
Training Step: 46  | total loss: [1m[32m0.69179[0m[0m | time: 0.641s
[2K
| Adam | epoch: 004 | loss: 0.69179 - acc: 0.5354 -- iter: 032/478
[A[ATraining Step: 47  | total loss: [1m[32m0.69339[0m[0m | time: 1.233s
[2K
| Adam | epoch: 004 | loss: 0.69339 - acc: 0.5040 -- iter: 064/478
[A[ATraining Step: 48  | total loss: [1m[32m0.69260[0m[0m | time: 1.818s
[2K
| Adam | epoch: 004 | loss: 0.69260 - acc: 0.5195 -- iter: 096/478
[A[ATraining Step: 49  | total loss: [1m[32m0.69193[0m[0m | time: 2.440s
[2K
| Adam | epoch: 004 | loss: 0.69193 - acc: 0.5322 -- iter: 128/478
[A[ATraining Step: 50  | total loss: [1m[32m0.69051[0m[0m | time: 3.058s
[2K
| Adam | epoch: 004 | loss: 0.69051 - acc: 0.5563 -- iter: 160/478
[A[ATraining Step: 51  | total loss: [1m[32m0.69096[0m[0m | time: 3.684s
[2K
| Adam | epoch: 004 | loss: 0.69096 - acc: 0.5477 -- iter: 192/478
[A[ATraining Step: 52  | total loss: [1m[32m0.69160[0m[0m | time: 4.342s
[2K
| Adam | epoch: 004 | loss: 0.69160 - acc: 0.5359 -- iter: 224/478
[A[ATraining Step: 53  | total loss: [1m[32m0.69223[0m[0m | time: 4.976s
[2K
| Adam | epoch: 004 | loss: 0.69223 - acc: 0.5260 -- iter: 256/478
[A[ATraining Step: 54  | total loss: [1m[32m0.69138[0m[0m | time: 5.591s
[2K
| Adam | epoch: 004 | loss: 0.69138 - acc: 0.5358 -- iter: 288/478
[A[ATraining Step: 55  | total loss: [1m[32m0.69246[0m[0m | time: 6.187s
[2K
| Adam | epoch: 004 | loss: 0.69246 - acc: 0.5218 -- iter: 320/478
[A[ATraining Step: 56  | total loss: [1m[32m0.69340[0m[0m | time: 6.795s
[2K
| Adam | epoch: 004 | loss: 0.69340 - acc: 0.5099 -- iter: 352/478
[A[ATraining Step: 57  | total loss: [1m[32m0.69423[0m[0m | time: 7.400s
[2K
| Adam | epoch: 004 | loss: 0.69423 - acc: 0.4999 -- iter: 384/478
[A[ATraining Step: 58  | total loss: [1m[32m0.69448[0m[0m | time: 8.015s
[2K
| Adam | epoch: 004 | loss: 0.69448 - acc: 0.4956 -- iter: 416/478
[A[ATraining Step: 59  | total loss: [1m[32m0.69386[0m[0m | time: 8.640s
[2K
| Adam | epoch: 004 | loss: 0.69386 - acc: 0.5046 -- iter: 448/478
[A[ATraining Step: 60  | total loss: [1m[32m0.69383[0m[0m | time: 10.288s
[2K
| Adam | epoch: 004 | loss: 0.69383 - acc: 0.5040 | val_loss: 0.68809 - val_acc: 0.6000 -- iter: 478/478
--
Training Step: 61  | total loss: [1m[32m0.69380[0m[0m | time: 0.599s
[2K
| Adam | epoch: 005 | loss: 0.69380 - acc: 0.5035 -- iter: 032/478
[A[ATraining Step: 62  | total loss: [1m[32m0.69333[0m[0m | time: 1.225s
[2K
| Adam | epoch: 005 | loss: 0.69333 - acc: 0.5111 -- iter: 064/478
[A[ATraining Step: 63  | total loss: [1m[32m0.69317[0m[0m | time: 1.822s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.5136 -- iter: 096/478
[A[ATraining Step: 64  | total loss: [1m[32m0.69298[0m[0m | time: 2.405s
[2K
| Adam | epoch: 005 | loss: 0.69298 - acc: 0.5161 -- iter: 128/478
[A[ATraining Step: 65  | total loss: [1m[32m0.69281[0m[0m | time: 3.044s
[2K
| Adam | epoch: 005 | loss: 0.69281 - acc: 0.5182 -- iter: 160/478
[A[ATraining Step: 66  | total loss: [1m[32m0.69267[0m[0m | time: 3.659s
[2K
| Adam | epoch: 005 | loss: 0.69267 - acc: 0.5198 -- iter: 192/478
[A[ATraining Step: 67  | total loss: [1m[32m0.69254[0m[0m | time: 4.288s
[2K
| Adam | epoch: 005 | loss: 0.69254 - acc: 0.5212 -- iter: 224/478
[A[ATraining Step: 68  | total loss: [1m[32m0.69170[0m[0m | time: 4.889s
[2K
| Adam | epoch: 005 | loss: 0.69170 - acc: 0.5372 -- iter: 256/478
[A[ATraining Step: 69  | total loss: [1m[32m0.69303[0m[0m | time: 5.518s
[2K
| Adam | epoch: 005 | loss: 0.69303 - acc: 0.5109 -- iter: 288/478
[A[ATraining Step: 70  | total loss: [1m[32m0.69306[0m[0m | time: 6.148s
[2K
| Adam | epoch: 005 | loss: 0.69306 - acc: 0.5097 -- iter: 320/478
[A[ATraining Step: 71  | total loss: [1m[32m0.69269[0m[0m | time: 6.744s
[2K
| Adam | epoch: 005 | loss: 0.69269 - acc: 0.5157 -- iter: 352/478
[A[ATraining Step: 72  | total loss: [1m[32m0.69255[0m[0m | time: 7.357s
[2K
| Adam | epoch: 005 | loss: 0.69255 - acc: 0.5174 -- iter: 384/478
[A[ATraining Step: 73  | total loss: [1m[32m0.69263[0m[0m | time: 7.995s
[2K
| Adam | epoch: 005 | loss: 0.69263 - acc: 0.5155 -- iter: 416/478
[A[ATraining Step: 74  | total loss: [1m[32m0.69291[0m[0m | time: 8.602s
[2K
| Adam | epoch: 005 | loss: 0.69291 - acc: 0.5104 -- iter: 448/478
[A[ATraining Step: 75  | total loss: [1m[32m0.69336[0m[0m | time: 10.221s
[2K
| Adam | epoch: 005 | loss: 0.69336 - acc: 0.5025 | val_loss: 0.68830 - val_acc: 0.6000 -- iter: 478/478
--
Training Step: 76  | total loss: [1m[32m0.69269[0m[0m | time: 0.696s
[2K
| Adam | epoch: 006 | loss: 0.69269 - acc: 0.5156 -- iter: 032/478
[A[ATraining Step: 77  | total loss: [1m[32m0.69259[0m[0m | time: 2.017s
[2K
| Adam | epoch: 006 | loss: 0.69259 - acc: 0.5172 -- iter: 064/478
[A[ATraining Step: 78  | total loss: [1m[32m0.69244[0m[0m | time: 3.250s
[2K
| Adam | epoch: 006 | loss: 0.69244 - acc: 0.5187 -- iter: 096/478
[A[ATraining Step: 79  | total loss: [1m[32m0.69255[0m[0m | time: 4.258s
[2K
| Adam | epoch: 006 | loss: 0.69255 - acc: 0.5168 -- iter: 128/478
[A[ATraining Step: 80  | total loss: [1m[32m0.69231[0m[0m | time: 5.042s
[2K
| Adam | epoch: 006 | loss: 0.69231 - acc: 0.5219 -- iter: 160/478
[A[ATraining Step: 81  | total loss: [1m[32m0.69204[0m[0m | time: 5.926s
[2K
| Adam | epoch: 006 | loss: 0.69204 - acc: 0.5264 -- iter: 192/478
[A[ATraining Step: 82  | total loss: [1m[32m0.69178[0m[0m | time: 6.829s
[2K
| Adam | epoch: 006 | loss: 0.69178 - acc: 0.5300 -- iter: 224/478
[A[ATraining Step: 83  | total loss: [1m[32m0.69153[0m[0m | time: 7.789s
[2K
| Adam | epoch: 006 | loss: 0.69153 - acc: 0.5333 -- iter: 256/478
[A[ATraining Step: 84  | total loss: [1m[32m0.69073[0m[0m | time: 8.735s
[2K
| Adam | epoch: 006 | loss: 0.69073 - acc: 0.5456 -- iter: 288/478
[A[ATraining Step: 85  | total loss: [1m[32m0.69085[0m[0m | time: 9.723s
[2K
| Adam | epoch: 006 | loss: 0.69085 - acc: 0.5441 -- iter: 320/478
[A[ATraining Step: 86  | total loss: [1m[32m0.69086[0m[0m | time: 10.727s
[2K
| Adam | epoch: 006 | loss: 0.69086 - acc: 0.5428 -- iter: 352/478
[A[ATraining Step: 87  | total loss: [1m[32m0.69144[0m[0m | time: 11.731s
[2K
| Adam | epoch: 006 | loss: 0.69144 - acc: 0.5354 -- iter: 384/478
[A[ATraining Step: 88  | total loss: [1m[32m0.69139[0m[0m | time: 13.025s
[2K
| Adam | epoch: 006 | loss: 0.69139 - acc: 0.5350 -- iter: 416/478
[A[ATraining Step: 89  | total loss: [1m[32m0.69172[0m[0m | time: 14.339s
[2K
| Adam | epoch: 006 | loss: 0.69172 - acc: 0.5315 -- iter: 448/478
[A[ATraining Step: 90  | total loss: [1m[32m0.69225[0m[0m | time: 17.917s
[2K
| Adam | epoch: 006 | loss: 0.69225 - acc: 0.5252 | val_loss: 0.68453 - val_acc: 0.6000 -- iter: 478/478
--
Training Step: 91  | total loss: [1m[32m0.69296[0m[0m | time: 1.048s
[2K
| Adam | epoch: 007 | loss: 0.69296 - acc: 0.5165 -- iter: 032/478
[A[ATraining Step: 92  | total loss: [1m[32m0.69279[0m[0m | time: 2.069s
[2K
| Adam | epoch: 007 | loss: 0.69279 - acc: 0.5179 -- iter: 064/478
[A[ATraining Step: 93  | total loss: [1m[32m0.69348[0m[0m | time: 3.062s
[2K
| Adam | epoch: 007 | loss: 0.69348 - acc: 0.5099 -- iter: 096/478
[A[ATraining Step: 94  | total loss: [1m[32m0.69426[0m[0m | time: 3.988s
[2K
| Adam | epoch: 007 | loss: 0.69426 - acc: 0.4995 -- iter: 128/478
[A[ATraining Step: 95  | total loss: [1m[32m0.69372[0m[0m | time: 4.824s
[2K
| Adam | epoch: 007 | loss: 0.69372 - acc: 0.5058 -- iter: 160/478
[A[ATraining Step: 96  | total loss: [1m[32m0.69297[0m[0m | time: 5.593s
[2K
| Adam | epoch: 007 | loss: 0.69297 - acc: 0.5152 -- iter: 192/478
[A[ATraining Step: 97  | total loss: [1m[32m0.69227[0m[0m | time: 6.388s
[2K
| Adam | epoch: 007 | loss: 0.69227 - acc: 0.5237 -- iter: 224/478
[A[ATraining Step: 98  | total loss: [1m[32m0.69130[0m[0m | time: 7.253s
[2K
| Adam | epoch: 007 | loss: 0.69130 - acc: 0.5370 -- iter: 256/478
[A[ATraining Step: 99  | total loss: [1m[32m0.69108[0m[0m | time: 8.144s
[2K
| Adam | epoch: 007 | loss: 0.69108 - acc: 0.5395 -- iter: 288/478
[A[ATraining Step: 100  | total loss: [1m[32m0.69100[0m[0m | time: 8.982s
[2K
| Adam | epoch: 007 | loss: 0.69100 - acc: 0.5387 -- iter: 320/478
[A[ATraining Step: 101  | total loss: [1m[32m0.69073[0m[0m | time: 9.826s
[2K
| Adam | epoch: 007 | loss: 0.69073 - acc: 0.5411 -- iter: 352/478
[A[ATraining Step: 102  | total loss: [1m[32m0.69188[0m[0m | time: 10.679s
[2K
| Adam | epoch: 007 | loss: 0.69188 - acc: 0.5276 -- iter: 384/478
[A[ATraining Step: 103  | total loss: [1m[32m0.69124[0m[0m | time: 11.739s
[2K
| Adam | epoch: 007 | loss: 0.69124 - acc: 0.5342 -- iter: 416/478
[A[ATraining Step: 104  | total loss: [1m[32m0.69126[0m[0m | time: 13.029s
[2K
| Adam | epoch: 007 | loss: 0.69126 - acc: 0.5339 -- iter: 448/478
[A[ATraining Step: 105  | total loss: [1m[32m0.69126[0m[0m | time: 31.813s
[2K
| Adam | epoch: 007 | loss: 0.69126 - acc: 0.5336 | val_loss: 0.68471 - val_acc: 0.6000 -- iter: 478/478
--
Training Step: 106  | total loss: [1m[32m0.69274[0m[0m | time: 0.973s
[2K
| Adam | epoch: 008 | loss: 0.69274 - acc: 0.5178 -- iter: 032/478
[A[ATraining Step: 107  | total loss: [1m[32m0.69367[0m[0m | time: 2.004s
[2K
| Adam | epoch: 008 | loss: 0.69367 - acc: 0.5066 -- iter: 064/478
[A[ATraining Step: 108  | total loss: [1m[32m0.69316[0m[0m | time: 3.058s
[2K
| Adam | epoch: 008 | loss: 0.69316 - acc: 0.5122 -- iter: 096/478
[A[ATraining Step: 109  | total loss: [1m[32m0.69297[0m[0m | time: 4.024s
[2K
| Adam | epoch: 008 | loss: 0.69297 - acc: 0.5141 -- iter: 128/478
[A[ATraining Step: 110  | total loss: [1m[32m0.69387[0m[0m | time: 5.078s
[2K
| Adam | epoch: 008 | loss: 0.69387 - acc: 0.5002 -- iter: 160/478
[A[ATraining Step: 111  | total loss: [1m[32m0.69357[0m[0m | time: 6.244s
[2K
| Adam | epoch: 008 | loss: 0.69357 - acc: 0.5033 -- iter: 192/478
[A[ATraining Step: 112  | total loss: [1m[32m0.69369[0m[0m | time: 7.468s
[2K
| Adam | epoch: 008 | loss: 0.69369 - acc: 0.4996 -- iter: 224/478
[A[ATraining Step: 113  | total loss: [1m[32m0.69383[0m[0m | time: 14.024s
[2K
| Adam | epoch: 008 | loss: 0.69383 - acc: 0.4964 -- iter: 256/478
[A[ATraining Step: 114  | total loss: [1m[32m0.69410[0m[0m | time: 19.225s
[2K
| Adam | epoch: 008 | loss: 0.69410 - acc: 0.4905 -- iter: 288/478
[A[ATraining Step: 115  | total loss: [1m[32m0.69357[0m[0m | time: 24.366s
[2K
| Adam | epoch: 008 | loss: 0.69357 - acc: 0.5008 -- iter: 320/478
[A[ATraining Step: 116  | total loss: [1m[32m0.69360[0m[0m | time: 25.278s
[2K
| Adam | epoch: 008 | loss: 0.69360 - acc: 0.4976 -- iter: 352/478
[A[ATraining Step: 117  | total loss: [1m[32m0.69282[0m[0m | time: 26.235s
[2K
| Adam | epoch: 008 | loss: 0.69282 - acc: 0.5135 -- iter: 384/478
[A[ATraining Step: 118  | total loss: [1m[32m0.69323[0m[0m | time: 27.188s
[2K
| Adam | epoch: 008 | loss: 0.69323 - acc: 0.5027 -- iter: 416/478
[A[ATraining Step: 119  | total loss: [1m[32m0.69280[0m[0m | time: 28.182s
[2K
| Adam | epoch: 008 | loss: 0.69280 - acc: 0.5087 -- iter: 448/478
[A[ATraining Step: 120  | total loss: [1m[32m0.69264[0m[0m | time: 30.235s
[2K
| Adam | epoch: 008 | loss: 0.69264 - acc: 0.5110 | val_loss: 0.68625 - val_acc: 0.6000 -- iter: 478/478
--
Training Step: 121  | total loss: [1m[32m0.69223[0m[0m | time: 1.335s
[2K
| Adam | epoch: 009 | loss: 0.69223 - acc: 0.5161 -- iter: 032/478
[A[ATraining Step: 122  | total loss: [1m[32m0.69137[0m[0m | time: 2.756s
[2K
| Adam | epoch: 009 | loss: 0.69137 - acc: 0.5270 -- iter: 064/478
[A[ATraining Step: 123  | total loss: [1m[32m0.69167[0m[0m | time: 6.483s
[2K
| Adam | epoch: 009 | loss: 0.69167 - acc: 0.5212 -- iter: 096/478
[A[ATraining Step: 124  | total loss: [1m[32m0.69174[0m[0m | time: 9.888s
[2K
| Adam | epoch: 009 | loss: 0.69174 - acc: 0.5191 -- iter: 128/478
[A[ATraining Step: 125  | total loss: [1m[32m0.69197[0m[0m | time: 10.827s
[2K
| Adam | epoch: 009 | loss: 0.69197 - acc: 0.5109 -- iter: 160/478
[A[ATraining Step: 126  | total loss: [1m[32m0.69168[0m[0m | time: 11.787s
[2K
| Adam | epoch: 009 | loss: 0.69168 - acc: 0.5067 -- iter: 192/478
[A[ATraining Step: 127  | total loss: [1m[32m0.69130[0m[0m | time: 12.714s
[2K
| Adam | epoch: 009 | loss: 0.69130 - acc: 0.5185 -- iter: 224/478
[A[ATraining Step: 128  | total loss: [1m[32m0.69120[0m[0m | time: 13.534s
[2K
| Adam | epoch: 009 | loss: 0.69120 - acc: 0.5267 -- iter: 256/478
[A[ATraining Step: 129  | total loss: [1m[32m0.69095[0m[0m | time: 14.545s
[2K
| Adam | epoch: 009 | loss: 0.69095 - acc: 0.5340 -- iter: 288/478
[A[ATraining Step: 130  | total loss: [1m[32m0.68968[0m[0m | time: 15.613s
[2K
| Adam | epoch: 009 | loss: 0.68968 - acc: 0.5494 -- iter: 320/478
[A[ATraining Step: 131  | total loss: [1m[32m0.68854[0m[0m | time: 16.419s
[2K
| Adam | epoch: 009 | loss: 0.68854 - acc: 0.5507 -- iter: 352/478
[A[ATraining Step: 132  | total loss: [1m[32m0.68913[0m[0m | time: 17.624s
[2K
| Adam | epoch: 009 | loss: 0.68913 - acc: 0.5394 -- iter: 384/478
[A[ATraining Step: 133  | total loss: [1m[32m0.68882[0m[0m | time: 18.688s
[2K
| Adam | epoch: 009 | loss: 0.68882 - acc: 0.5417 -- iter: 416/478
[A[ATraining Step: 134  | total loss: [1m[32m0.68876[0m[0m | time: 19.805s
[2K
| Adam | epoch: 009 | loss: 0.68876 - acc: 0.5469 -- iter: 448/478
[A[ATraining Step: 135  | total loss: [1m[32m0.68755[0m[0m | time: 21.479s
[2K
| Adam | epoch: 009 | loss: 0.68755 - acc: 0.5641 | val_loss: 0.67284 - val_acc: 0.6533 -- iter: 478/478
--
Training Step: 136  | total loss: [1m[32m0.68722[0m[0m | time: 0.638s
[2K
| Adam | epoch: 010 | loss: 0.68722 - acc: 0.5670 -- iter: 032/478
[A[ATraining Step: 137  | total loss: [1m[32m0.68514[0m[0m | time: 1.268s
[2K
| Adam | epoch: 010 | loss: 0.68514 - acc: 0.5760 -- iter: 064/478
[A[ATraining Step: 138  | total loss: [1m[32m0.68485[0m[0m | time: 1.937s
[2K
| Adam | epoch: 010 | loss: 0.68485 - acc: 0.5715 -- iter: 096/478
[A[ATraining Step: 139  | total loss: [1m[32m0.68469[0m[0m | time: 2.606s
[2K
| Adam | epoch: 010 | loss: 0.68469 - acc: 0.5737 -- iter: 128/478
[A[ATraining Step: 140  | total loss: [1m[32m0.68217[0m[0m | time: 3.282s
[2K
| Adam | epoch: 010 | loss: 0.68217 - acc: 0.5820 -- iter: 160/478
[A[ATraining Step: 141  | total loss: [1m[32m0.68435[0m[0m | time: 3.903s
[2K
| Adam | epoch: 010 | loss: 0.68435 - acc: 0.5738 -- iter: 192/478
[A[ATraining Step: 142  | total loss: [1m[32m0.68295[0m[0m | time: 4.555s
[2K
| Adam | epoch: 010 | loss: 0.68295 - acc: 0.5695 -- iter: 224/478
[A[ATraining Step: 143  | total loss: [1m[32m0.67918[0m[0m | time: 5.151s
[2K
| Adam | epoch: 010 | loss: 0.67918 - acc: 0.5782 -- iter: 256/478
[A[ATraining Step: 144  | total loss: [1m[32m0.67666[0m[0m | time: 5.753s
[2K
| Adam | epoch: 010 | loss: 0.67666 - acc: 0.5837 -- iter: 288/478
[A[ATraining Step: 145  | total loss: [1m[32m0.67358[0m[0m | time: 6.409s
[2K
| Adam | epoch: 010 | loss: 0.67358 - acc: 0.5920 -- iter: 320/478
[A[ATraining Step: 146  | total loss: [1m[32m0.67521[0m[0m | time: 7.009s
[2K
| Adam | epoch: 010 | loss: 0.67521 - acc: 0.5984 -- iter: 352/478
[A[ATraining Step: 147  | total loss: [1m[32m0.66766[0m[0m | time: 7.612s
[2K
| Adam | epoch: 010 | loss: 0.66766 - acc: 0.6136 -- iter: 384/478
[A[ATraining Step: 148  | total loss: [1m[32m0.67659[0m[0m | time: 8.224s
[2K
| Adam | epoch: 010 | loss: 0.67659 - acc: 0.6022 -- iter: 416/478
[A[ATraining Step: 149  | total loss: [1m[32m0.67710[0m[0m | time: 8.865s
[2K
| Adam | epoch: 010 | loss: 0.67710 - acc: 0.6045 -- iter: 448/478
[A[ATraining Step: 150  | total loss: [1m[32m0.67094[0m[0m | time: 10.523s
[2K
| Adam | epoch: 010 | loss: 0.67094 - acc: 0.6191 | val_loss: 0.68328 - val_acc: 0.5733 -- iter: 478/478
--
Training Step: 151  | total loss: [1m[32m0.67061[0m[0m | time: 0.618s
[2K
| Adam | epoch: 011 | loss: 0.67061 - acc: 0.6134 -- iter: 032/478
[A[ATraining Step: 152  | total loss: [1m[32m0.67295[0m[0m | time: 1.238s
[2K
| Adam | epoch: 011 | loss: 0.67295 - acc: 0.6114 -- iter: 064/478
[A[ATraining Step: 153  | total loss: [1m[32m0.66739[0m[0m | time: 1.890s
[2K
| Adam | epoch: 011 | loss: 0.66739 - acc: 0.6222 -- iter: 096/478
[A[ATraining Step: 154  | total loss: [1m[32m0.66084[0m[0m | time: 2.542s
[2K
| Adam | epoch: 011 | loss: 0.66084 - acc: 0.6349 -- iter: 128/478
[A[ATraining Step: 155  | total loss: [1m[32m0.65982[0m[0m | time: 3.191s
[2K
| Adam | epoch: 011 | loss: 0.65982 - acc: 0.6277 -- iter: 160/478
[A[ATraining Step: 156  | total loss: [1m[32m0.65779[0m[0m | time: 3.798s
[2K
| Adam | epoch: 011 | loss: 0.65779 - acc: 0.6212 -- iter: 192/478
[A[ATraining Step: 157  | total loss: [1m[32m0.64767[0m[0m | time: 4.455s
[2K
| Adam | epoch: 011 | loss: 0.64767 - acc: 0.6403 -- iter: 224/478
[A[ATraining Step: 158  | total loss: [1m[32m0.64467[0m[0m | time: 5.098s
[2K
| Adam | epoch: 011 | loss: 0.64467 - acc: 0.6419 -- iter: 256/478
[A[ATraining Step: 159  | total loss: [1m[32m0.64339[0m[0m | time: 5.830s
[2K
| Adam | epoch: 011 | loss: 0.64339 - acc: 0.6465 -- iter: 288/478
[A[ATraining Step: 160  | total loss: [1m[32m0.63910[0m[0m | time: 7.263s
[2K
| Adam | epoch: 011 | loss: 0.63910 - acc: 0.6452 -- iter: 320/478
[A[ATraining Step: 161  | total loss: [1m[32m0.63066[0m[0m | time: 8.545s
[2K
| Adam | epoch: 011 | loss: 0.63066 - acc: 0.6440 -- iter: 352/478
[A[ATraining Step: 162  | total loss: [1m[32m0.62894[0m[0m | time: 9.569s
[2K
| Adam | epoch: 011 | loss: 0.62894 - acc: 0.6483 -- iter: 384/478
[A[ATraining Step: 163  | total loss: [1m[32m0.61228[0m[0m | time: 15.828s
[2K
| Adam | epoch: 011 | loss: 0.61228 - acc: 0.6710 -- iter: 416/478
[A[ATraining Step: 164  | total loss: [1m[32m0.60318[0m[0m | time: 16.793s
[2K
| Adam | epoch: 011 | loss: 0.60318 - acc: 0.6851 -- iter: 448/478
[A[ATraining Step: 165  | total loss: [1m[32m0.60134[0m[0m | time: 18.736s
[2K
| Adam | epoch: 011 | loss: 0.60134 - acc: 0.6885 | val_loss: 0.70132 - val_acc: 0.6000 -- iter: 478/478
--
Training Step: 166  | total loss: [1m[32m0.59599[0m[0m | time: 0.880s
[2K
| Adam | epoch: 012 | loss: 0.59599 - acc: 0.6947 -- iter: 032/478
[A[ATraining Step: 167  | total loss: [1m[32m0.59974[0m[0m | time: 1.995s
[2K
| Adam | epoch: 012 | loss: 0.59974 - acc: 0.6846 -- iter: 064/478
[A[ATraining Step: 168  | total loss: [1m[32m0.59608[0m[0m | time: 3.396s
[2K
| Adam | epoch: 012 | loss: 0.59608 - acc: 0.6817 -- iter: 096/478
[A[ATraining Step: 169  | total loss: [1m[32m0.58752[0m[0m | time: 4.496s
[2K
| Adam | epoch: 012 | loss: 0.58752 - acc: 0.6854 -- iter: 128/478
[A[ATraining Step: 170  | total loss: [1m[32m0.58994[0m[0m | time: 9.023s
[2K
| Adam | epoch: 012 | loss: 0.58994 - acc: 0.6856 -- iter: 160/478
[A[ATraining Step: 171  | total loss: [1m[32m0.59166[0m[0m | time: 17.162s
[2K
| Adam | epoch: 012 | loss: 0.59166 - acc: 0.6796 -- iter: 192/478
[A[ATraining Step: 172  | total loss: [1m[32m0.59802[0m[0m | time: 23.524s
[2K
| Adam | epoch: 012 | loss: 0.59802 - acc: 0.6679 -- iter: 224/478
[A[ATraining Step: 173  | total loss: [1m[32m0.62884[0m[0m | time: 24.519s
[2K
| Adam | epoch: 012 | loss: 0.62884 - acc: 0.6448 -- iter: 256/478
[A[ATraining Step: 174  | total loss: [1m[32m0.63230[0m[0m | time: 25.433s
[2K
| Adam | epoch: 012 | loss: 0.63230 - acc: 0.6460 -- iter: 288/478
[A[ATraining Step: 175  | total loss: [1m[32m0.64890[0m[0m | time: 26.384s
[2K
| Adam | epoch: 012 | loss: 0.64890 - acc: 0.6251 -- iter: 320/478
[A[ATraining Step: 176  | total loss: [1m[32m0.64138[0m[0m | time: 27.272s
[2K
| Adam | epoch: 012 | loss: 0.64138 - acc: 0.6293 -- iter: 352/478
[A[ATraining Step: 177  | total loss: [1m[32m0.62734[0m[0m | time: 28.277s
[2K
| Adam | epoch: 012 | loss: 0.62734 - acc: 0.6464 -- iter: 384/478
[A[ATraining Step: 178  | total loss: [1m[32m0.62212[0m[0m | time: 29.261s
[2K
| Adam | epoch: 012 | loss: 0.62212 - acc: 0.6505 -- iter: 416/478
[A[ATraining Step: 179  | total loss: [1m[32m0.61831[0m[0m | time: 30.373s
[2K
| Adam | epoch: 012 | loss: 0.61831 - acc: 0.6542 -- iter: 448/478
[A[ATraining Step: 180  | total loss: [1m[32m0.63369[0m[0m | time: 32.675s
[2K
| Adam | epoch: 012 | loss: 0.63369 - acc: 0.6388 | val_loss: 0.60433 - val_acc: 0.6867 -- iter: 478/478
--
Training Step: 181  | total loss: [1m[32m0.62456[0m[0m | time: 6.458s
[2K
| Adam | epoch: 013 | loss: 0.62456 - acc: 0.6436 -- iter: 032/478
[A[ATraining Step: 182  | total loss: [1m[32m0.62340[0m[0m | time: 7.305s
[2K
| Adam | epoch: 013 | loss: 0.62340 - acc: 0.6386 -- iter: 064/478
[A[ATraining Step: 183  | total loss: [1m[32m0.62047[0m[0m | time: 8.293s
[2K
| Adam | epoch: 013 | loss: 0.62047 - acc: 0.6404 -- iter: 096/478
[A[ATraining Step: 184  | total loss: [1m[32m0.61655[0m[0m | time: 9.398s
[2K
| Adam | epoch: 013 | loss: 0.61655 - acc: 0.6451 -- iter: 128/478
[A[ATraining Step: 185  | total loss: [1m[32m0.61379[0m[0m | time: 10.556s
[2K
| Adam | epoch: 013 | loss: 0.61379 - acc: 0.6493 -- iter: 160/478
[A[ATraining Step: 186  | total loss: [1m[32m0.61168[0m[0m | time: 11.663s
[2K
| Adam | epoch: 013 | loss: 0.61168 - acc: 0.6563 -- iter: 192/478
[A[ATraining Step: 187  | total loss: [1m[32m0.59180[0m[0m | time: 12.500s
[2K
| Adam | epoch: 013 | loss: 0.59180 - acc: 0.6813 -- iter: 224/478
[A[ATraining Step: 188  | total loss: [1m[32m0.57702[0m[0m | time: 13.502s
[2K
| Adam | epoch: 013 | loss: 0.57702 - acc: 0.7038 -- iter: 256/478
[A[ATraining Step: 189  | total loss: [1m[32m0.56823[0m[0m | time: 14.296s
[2K
| Adam | epoch: 013 | loss: 0.56823 - acc: 0.7084 -- iter: 288/478
[A[ATraining Step: 190  | total loss: [1m[32m0.56468[0m[0m | time: 15.091s
[2K
| Adam | epoch: 013 | loss: 0.56468 - acc: 0.7094 -- iter: 320/478
[A[ATraining Step: 191  | total loss: [1m[32m0.56322[0m[0m | time: 15.900s
[2K
| Adam | epoch: 013 | loss: 0.56322 - acc: 0.7104 -- iter: 352/478
[A[ATraining Step: 192  | total loss: [1m[32m0.55830[0m[0m | time: 16.824s
[2K
| Adam | epoch: 013 | loss: 0.55830 - acc: 0.7093 -- iter: 384/478
[A[ATraining Step: 193  | total loss: [1m[32m0.55084[0m[0m | time: 17.653s
[2K
| Adam | epoch: 013 | loss: 0.55084 - acc: 0.7151 -- iter: 416/478
[A[ATraining Step: 194  | total loss: [1m[32m0.53814[0m[0m | time: 18.453s
[2K
| Adam | epoch: 013 | loss: 0.53814 - acc: 0.7311 -- iter: 448/478
[A[ATraining Step: 195  | total loss: [1m[32m0.52718[0m[0m | time: 20.286s
[2K
| Adam | epoch: 013 | loss: 0.52718 - acc: 0.7361 | val_loss: 0.58625 - val_acc: 0.6867 -- iter: 478/478
--
Training Step: 196  | total loss: [1m[32m0.52802[0m[0m | time: 1.162s
[2K
| Adam | epoch: 014 | loss: 0.52802 - acc: 0.7375 -- iter: 032/478
[A[ATraining Step: 197  | total loss: [1m[32m0.51673[0m[0m | time: 2.022s
[2K
| Adam | epoch: 014 | loss: 0.51673 - acc: 0.7512 -- iter: 064/478
[A[ATraining Step: 198  | total loss: [1m[32m0.51049[0m[0m | time: 2.935s
[2K
| Adam | epoch: 014 | loss: 0.51049 - acc: 0.7511 -- iter: 096/478
[A[ATraining Step: 199  | total loss: [1m[32m0.49505[0m[0m | time: 3.892s
[2K
| Adam | epoch: 014 | loss: 0.49505 - acc: 0.7697 -- iter: 128/478
[A[ATraining Step: 200  | total loss: [1m[32m0.49442[0m[0m | time: 5.875s
[2K
| Adam | epoch: 014 | loss: 0.49442 - acc: 0.7740 | val_loss: 0.57407 - val_acc: 0.6933 -- iter: 160/478
--
Training Step: 201  | total loss: [1m[32m0.51094[0m[0m | time: 7.224s
[2K
| Adam | epoch: 014 | loss: 0.51094 - acc: 0.7622 -- iter: 192/478
[A[ATraining Step: 202  | total loss: [1m[32m0.49307[0m[0m | time: 8.479s
[2K
| Adam | epoch: 014 | loss: 0.49307 - acc: 0.7735 -- iter: 224/478
[A[ATraining Step: 203  | total loss: [1m[32m0.49049[0m[0m | time: 9.518s
[2K
| Adam | epoch: 014 | loss: 0.49049 - acc: 0.7774 -- iter: 256/478
[A[ATraining Step: 204  | total loss: [1m[32m0.47945[0m[0m | time: 10.373s
[2K
| Adam | epoch: 014 | loss: 0.47945 - acc: 0.7778 -- iter: 288/478
[A[ATraining Step: 205  | total loss: [1m[32m0.47030[0m[0m | time: 11.384s
[2K
| Adam | epoch: 014 | loss: 0.47030 - acc: 0.7844 -- iter: 320/478
[A[ATraining Step: 206  | total loss: [1m[32m0.45233[0m[0m | time: 12.345s
[2K
| Adam | epoch: 014 | loss: 0.45233 - acc: 0.7966 -- iter: 352/478
[A[ATraining Step: 207  | total loss: [1m[32m0.43073[0m[0m | time: 13.265s
[2K
| Adam | epoch: 014 | loss: 0.43073 - acc: 0.8075 -- iter: 384/478
[A[ATraining Step: 208  | total loss: [1m[32m0.43550[0m[0m | time: 14.385s
[2K
| Adam | epoch: 014 | loss: 0.43550 - acc: 0.8101 -- iter: 416/478
[A[ATraining Step: 209  | total loss: [1m[32m0.43258[0m[0m | time: 15.382s
[2K
| Adam | epoch: 014 | loss: 0.43258 - acc: 0.8124 -- iter: 448/478
[A[ATraining Step: 210  | total loss: [1m[32m0.41727[0m[0m | time: 17.359s
[2K
| Adam | epoch: 014 | loss: 0.41727 - acc: 0.8125 | val_loss: 0.54976 - val_acc: 0.7267 -- iter: 478/478
--
Training Step: 211  | total loss: [1m[32m0.41502[0m[0m | time: 0.634s
[2K
| Adam | epoch: 015 | loss: 0.41502 - acc: 0.8125 -- iter: 032/478
[A[ATraining Step: 212  | total loss: [1m[32m0.40705[0m[0m | time: 1.278s
[2K
| Adam | epoch: 015 | loss: 0.40705 - acc: 0.8156 -- iter: 064/478
[A[ATraining Step: 213  | total loss: [1m[32m0.38615[0m[0m | time: 1.920s
[2K
| Adam | epoch: 015 | loss: 0.38615 - acc: 0.8309 -- iter: 096/478
[A[ATraining Step: 214  | total loss: [1m[32m0.38934[0m[0m | time: 2.546s
[2K
| Adam | epoch: 015 | loss: 0.38934 - acc: 0.8259 -- iter: 128/478
[A[ATraining Step: 215  | total loss: [1m[32m0.38729[0m[0m | time: 3.318s
[2K
| Adam | epoch: 015 | loss: 0.38729 - acc: 0.8308 -- iter: 160/478
[A[ATraining Step: 216  | total loss: [1m[32m0.37750[0m[0m | time: 4.098s
[2K
| Adam | epoch: 015 | loss: 0.37750 - acc: 0.8321 -- iter: 192/478
[A[ATraining Step: 217  | total loss: [1m[32m0.39174[0m[0m | time: 4.927s
[2K
| Adam | epoch: 015 | loss: 0.39174 - acc: 0.8208 -- iter: 224/478
[A[ATraining Step: 218  | total loss: [1m[32m0.43532[0m[0m | time: 5.751s
[2K
| Adam | epoch: 015 | loss: 0.43532 - acc: 0.7918 -- iter: 256/478
[A[ATraining Step: 219  | total loss: [1m[32m0.43635[0m[0m | time: 6.556s
[2K
| Adam | epoch: 015 | loss: 0.43635 - acc: 0.7908 -- iter: 288/478
[A[ATraining Step: 220  | total loss: [1m[32m0.41789[0m[0m | time: 7.334s
[2K
| Adam | epoch: 015 | loss: 0.41789 - acc: 0.7992 -- iter: 320/478
[A[ATraining Step: 221  | total loss: [1m[32m0.40787[0m[0m | time: 8.130s
[2K
| Adam | epoch: 015 | loss: 0.40787 - acc: 0.8068 -- iter: 352/478
[A[ATraining Step: 222  | total loss: [1m[32m0.41425[0m[0m | time: 8.962s
[2K
| Adam | epoch: 015 | loss: 0.41425 - acc: 0.8042 -- iter: 384/478
[A[ATraining Step: 223  | total loss: [1m[32m0.40649[0m[0m | time: 9.734s
[2K
| Adam | epoch: 015 | loss: 0.40649 - acc: 0.8051 -- iter: 416/478
[A[ATraining Step: 224  | total loss: [1m[32m0.40155[0m[0m | time: 10.476s
[2K
| Adam | epoch: 015 | loss: 0.40155 - acc: 0.8079 -- iter: 448/478
[A[ATraining Step: 225  | total loss: [1m[32m0.39978[0m[0m | time: 12.283s
[2K
| Adam | epoch: 015 | loss: 0.39978 - acc: 0.8104 | val_loss: 0.97637 - val_acc: 0.5467 -- iter: 478/478
--
Training Step: 226  | total loss: [1m[32m0.41413[0m[0m | time: 0.843s
[2K
| Adam | epoch: 016 | loss: 0.41413 - acc: 0.7981 -- iter: 032/478
[A[ATraining Step: 227  | total loss: [1m[32m0.45245[0m[0m | time: 1.633s
[2K
| Adam | epoch: 016 | loss: 0.45245 - acc: 0.7808 -- iter: 064/478
[A[ATraining Step: 228  | total loss: [1m[32m0.46613[0m[0m | time: 2.439s
[2K
| Adam | epoch: 016 | loss: 0.46613 - acc: 0.7746 -- iter: 096/478
[A[ATraining Step: 229  | total loss: [1m[32m0.44346[0m[0m | time: 3.256s
[2K
| Adam | epoch: 016 | loss: 0.44346 - acc: 0.7909 -- iter: 128/478
[A[ATraining Step: 230  | total loss: [1m[32m0.42578[0m[0m | time: 4.067s
[2K
| Adam | epoch: 016 | loss: 0.42578 - acc: 0.8024 -- iter: 160/478
[A[ATraining Step: 231  | total loss: [1m[32m0.41579[0m[0m | time: 5.019s
[2K
| Adam | epoch: 016 | loss: 0.41579 - acc: 0.8034 -- iter: 192/478
[A[ATraining Step: 232  | total loss: [1m[32m0.40666[0m[0m | time: 5.787s
[2K
| Adam | epoch: 016 | loss: 0.40666 - acc: 0.8075 -- iter: 224/478
[A[ATraining Step: 233  | total loss: [1m[32m0.39343[0m[0m | time: 6.462s
[2K
| Adam | epoch: 016 | loss: 0.39343 - acc: 0.8236 -- iter: 256/478
[A[ATraining Step: 234  | total loss: [1m[32m0.37625[0m[0m | time: 7.312s
[2K
| Adam | epoch: 016 | loss: 0.37625 - acc: 0.8350 -- iter: 288/478
[A[ATraining Step: 235  | total loss: [1m[32m0.36519[0m[0m | time: 8.670s
[2K
| Adam | epoch: 016 | loss: 0.36519 - acc: 0.8390 -- iter: 320/478
[A[ATraining Step: 236  | total loss: [1m[32m0.35020[0m[0m | time: 10.262s
[2K
| Adam | epoch: 016 | loss: 0.35020 - acc: 0.8488 -- iter: 352/478
[A[ATraining Step: 237  | total loss: [1m[32m0.33941[0m[0m | time: 11.649s
[2K
| Adam | epoch: 016 | loss: 0.33941 - acc: 0.8546 -- iter: 384/478
[A[ATraining Step: 238  | total loss: [1m[32m0.33159[0m[0m | time: 14.457s
[2K
| Adam | epoch: 016 | loss: 0.33159 - acc: 0.8598 -- iter: 416/478
[A[ATraining Step: 239  | total loss: [1m[32m0.31630[0m[0m | time: 18.671s
[2K
| Adam | epoch: 016 | loss: 0.31630 - acc: 0.8707 -- iter: 448/478
[A[ATraining Step: 240  | total loss: [1m[32m0.30624[0m[0m | time: 25.312s
[2K
| Adam | epoch: 016 | loss: 0.30624 - acc: 0.8769 | val_loss: 0.58187 - val_acc: 0.7533 -- iter: 478/478
--
Training Step: 241  | total loss: [1m[32m0.29532[0m[0m | time: 1.178s
[2K
| Adam | epoch: 017 | loss: 0.29532 - acc: 0.8859 -- iter: 032/478
[A[ATraining Step: 242  | total loss: [1m[32m0.29995[0m[0m | time: 2.306s
[2K
| Adam | epoch: 017 | loss: 0.29995 - acc: 0.8879 -- iter: 064/478
[A[ATraining Step: 243  | total loss: [1m[32m0.29192[0m[0m | time: 3.517s
[2K
| Adam | epoch: 017 | loss: 0.29192 - acc: 0.8898 -- iter: 096/478
[A[ATraining Step: 244  | total loss: [1m[32m0.28584[0m[0m | time: 4.771s
[2K
| Adam | epoch: 017 | loss: 0.28584 - acc: 0.8914 -- iter: 128/478
[A[ATraining Step: 245  | total loss: [1m[32m0.27445[0m[0m | time: 6.058s
[2K
| Adam | epoch: 017 | loss: 0.27445 - acc: 0.8991 -- iter: 160/478
[A[ATraining Step: 246  | total loss: [1m[32m0.25770[0m[0m | time: 7.249s
[2K
| Adam | epoch: 017 | loss: 0.25770 - acc: 0.9061 -- iter: 192/478
[A[ATraining Step: 247  | total loss: [1m[32m0.25179[0m[0m | time: 8.618s
[2K
| Adam | epoch: 017 | loss: 0.25179 - acc: 0.9061 -- iter: 224/478
[A[ATraining Step: 248  | total loss: [1m[32m0.27407[0m[0m | time: 10.141s
[2K
| Adam | epoch: 017 | loss: 0.27407 - acc: 0.8874 -- iter: 256/478
[A[ATraining Step: 249  | total loss: [1m[32m0.25297[0m[0m | time: 16.244s
[2K
| Adam | epoch: 017 | loss: 0.25297 - acc: 0.8986 -- iter: 288/478
[A[ATraining Step: 250  | total loss: [1m[32m0.24205[0m[0m | time: 20.870s
[2K
| Adam | epoch: 017 | loss: 0.24205 - acc: 0.9025 -- iter: 320/478
[A[ATraining Step: 251  | total loss: [1m[32m0.22750[0m[0m | time: 24.008s
[2K
| Adam | epoch: 017 | loss: 0.22750 - acc: 0.9123 -- iter: 352/478
[A[ATraining Step: 252  | total loss: [1m[32m0.22805[0m[0m | time: 25.061s
[2K
| Adam | epoch: 017 | loss: 0.22805 - acc: 0.9085 -- iter: 384/478
[A[ATraining Step: 253  | total loss: [1m[32m0.24378[0m[0m | time: 26.141s
[2K
| Adam | epoch: 017 | loss: 0.24378 - acc: 0.8958 -- iter: 416/478
[A[ATraining Step: 254  | total loss: [1m[32m0.25108[0m[0m | time: 27.385s
[2K
| Adam | epoch: 017 | loss: 0.25108 - acc: 0.8969 -- iter: 448/478
[A[ATraining Step: 255  | total loss: [1m[32m0.25346[0m[0m | time: 29.709s
[2K
| Adam | epoch: 017 | loss: 0.25346 - acc: 0.8978 | val_loss: 0.70515 - val_acc: 0.7133 -- iter: 478/478
--
Training Step: 256  | total loss: [1m[32m0.27426[0m[0m | time: 1.291s
[2K
| Adam | epoch: 018 | loss: 0.27426 - acc: 0.8914 -- iter: 032/478
[A[ATraining Step: 257  | total loss: [1m[32m0.26060[0m[0m | time: 2.588s
[2K
| Adam | epoch: 018 | loss: 0.26060 - acc: 0.9022 -- iter: 064/478
[A[ATraining Step: 258  | total loss: [1m[32m0.24175[0m[0m | time: 4.124s
[2K
| Adam | epoch: 018 | loss: 0.24175 - acc: 0.9120 -- iter: 096/478
[A[ATraining Step: 259  | total loss: [1m[32m0.22965[0m[0m | time: 5.597s
[2K
| Adam | epoch: 018 | loss: 0.22965 - acc: 0.9177 -- iter: 128/478
[A[ATraining Step: 260  | total loss: [1m[32m0.22522[0m[0m | time: 10.483s
[2K
| Adam | epoch: 018 | loss: 0.22522 - acc: 0.9165 -- iter: 160/478
[A[ATraining Step: 261  | total loss: [1m[32m0.21558[0m[0m | time: 16.077s
[2K
| Adam | epoch: 018 | loss: 0.21558 - acc: 0.9186 -- iter: 192/478
[A[ATraining Step: 262  | total loss: [1m[32m0.20479[0m[0m | time: 23.514s
[2K
| Adam | epoch: 018 | loss: 0.20479 - acc: 0.9236 -- iter: 224/478
[A[ATraining Step: 263  | total loss: [1m[32m0.20273[0m[0m | time: 29.834s
[2K
| Adam | epoch: 018 | loss: 0.20273 - acc: 0.9250 -- iter: 256/478
[A[ATraining Step: 264  | total loss: [1m[32m0.19738[0m[0m | time: 30.962s
[2K
| Adam | epoch: 018 | loss: 0.19738 - acc: 0.9263 -- iter: 288/478
[A[ATraining Step: 265  | total loss: [1m[32m0.18179[0m[0m | time: 32.159s
[2K
| Adam | epoch: 018 | loss: 0.18179 - acc: 0.9336 -- iter: 320/478
[A[ATraining Step: 266  | total loss: [1m[32m0.17271[0m[0m | time: 33.361s
[2K
| Adam | epoch: 018 | loss: 0.17271 - acc: 0.9372 -- iter: 352/478
[A[ATraining Step: 267  | total loss: [1m[32m0.17929[0m[0m | time: 34.542s
[2K
| Adam | epoch: 018 | loss: 0.17929 - acc: 0.9372 -- iter: 384/478
[A[ATraining Step: 268  | total loss: [1m[32m0.16842[0m[0m | time: 35.875s
[2K
| Adam | epoch: 018 | loss: 0.16842 - acc: 0.9403 -- iter: 416/478
[A[ATraining Step: 269  | total loss: [1m[32m0.16301[0m[0m | time: 37.299s
[2K
| Adam | epoch: 018 | loss: 0.16301 - acc: 0.9401 -- iter: 448/478
[A[ATraining Step: 270  | total loss: [1m[32m0.15315[0m[0m | time: 39.647s
[2K
| Adam | epoch: 018 | loss: 0.15315 - acc: 0.9429 | val_loss: 0.84624 - val_acc: 0.7067 -- iter: 478/478
--
Training Step: 271  | total loss: [1m[32m0.16005[0m[0m | time: 1.252s
[2K
| Adam | epoch: 019 | loss: 0.16005 - acc: 0.9361 -- iter: 032/478
[A[ATraining Step: 272  | total loss: [1m[32m0.17208[0m[0m | time: 3.388s
[2K
| Adam | epoch: 019 | loss: 0.17208 - acc: 0.9325 -- iter: 064/478
[A[ATraining Step: 273  | total loss: [1m[32m0.16791[0m[0m | time: 8.766s
[2K
| Adam | epoch: 019 | loss: 0.16791 - acc: 0.9359 -- iter: 096/478
[A[ATraining Step: 274  | total loss: [1m[32m0.15723[0m[0m | time: 11.535s
[2K
| Adam | epoch: 019 | loss: 0.15723 - acc: 0.9423 -- iter: 128/478
[A[ATraining Step: 275  | total loss: [1m[32m0.16738[0m[0m | time: 12.660s
[2K
| Adam | epoch: 019 | loss: 0.16738 - acc: 0.9387 -- iter: 160/478
[A[ATraining Step: 276  | total loss: [1m[32m0.17125[0m[0m | time: 13.820s
[2K
| Adam | epoch: 019 | loss: 0.17125 - acc: 0.9324 -- iter: 192/478
[A[ATraining Step: 277  | total loss: [1m[32m0.16885[0m[0m | time: 15.107s
[2K
| Adam | epoch: 019 | loss: 0.16885 - acc: 0.9329 -- iter: 224/478
[A[ATraining Step: 278  | total loss: [1m[32m0.15533[0m[0m | time: 16.311s
[2K
| Adam | epoch: 019 | loss: 0.15533 - acc: 0.9396 -- iter: 256/478
[A[ATraining Step: 279  | total loss: [1m[32m0.15271[0m[0m | time: 17.664s
[2K
| Adam | epoch: 019 | loss: 0.15271 - acc: 0.9394 -- iter: 288/478
[A[ATraining Step: 280  | total loss: [1m[32m0.15042[0m[0m | time: 19.048s
[2K
| Adam | epoch: 019 | loss: 0.15042 - acc: 0.9392 -- iter: 320/478
[A[ATraining Step: 281  | total loss: [1m[32m0.15095[0m[0m | time: 20.148s
[2K
| Adam | epoch: 019 | loss: 0.15095 - acc: 0.9328 -- iter: 352/478
[A[ATraining Step: 282  | total loss: [1m[32m0.14116[0m[0m | time: 21.384s
[2K
| Adam | epoch: 019 | loss: 0.14116 - acc: 0.9364 -- iter: 384/478
[A[ATraining Step: 283  | total loss: [1m[32m0.14317[0m[0m | time: 22.388s
[2K
| Adam | epoch: 019 | loss: 0.14317 - acc: 0.9396 -- iter: 416/478
[A[ATraining Step: 284  | total loss: [1m[32m0.14582[0m[0m | time: 23.433s
[2K
| Adam | epoch: 019 | loss: 0.14582 - acc: 0.9394 -- iter: 448/478
[A[ATraining Step: 285  | total loss: [1m[32m0.15253[0m[0m | time: 25.528s
[2K
| Adam | epoch: 019 | loss: 0.15253 - acc: 0.9392 | val_loss: 0.83383 - val_acc: 0.7200 -- iter: 478/478
--
Training Step: 286  | total loss: [1m[32m0.15563[0m[0m | time: 1.234s
[2K
| Adam | epoch: 020 | loss: 0.15563 - acc: 0.9359 -- iter: 032/478
[A[ATraining Step: 287  | total loss: [1m[32m0.15933[0m[0m | time: 2.223s
[2K
| Adam | epoch: 020 | loss: 0.15933 - acc: 0.9361 -- iter: 064/478
[A[ATraining Step: 288  | total loss: [1m[32m0.15579[0m[0m | time: 3.339s
[2K
| Adam | epoch: 020 | loss: 0.15579 - acc: 0.9391 -- iter: 096/478
[A[ATraining Step: 289  | total loss: [1m[32m0.14416[0m[0m | time: 4.735s
[2K
| Adam | epoch: 020 | loss: 0.14416 - acc: 0.9452 -- iter: 128/478
[A[ATraining Step: 290  | total loss: [1m[32m0.13950[0m[0m | time: 6.050s
[2K
| Adam | epoch: 020 | loss: 0.13950 - acc: 0.9476 -- iter: 160/478
[A[ATraining Step: 291  | total loss: [1m[32m0.13411[0m[0m | time: 8.397s
[2K
| Adam | epoch: 020 | loss: 0.13411 - acc: 0.9497 -- iter: 192/478
[A[ATraining Step: 292  | total loss: [1m[32m0.13109[0m[0m | time: 11.175s
[2K
| Adam | epoch: 020 | loss: 0.13109 - acc: 0.9485 -- iter: 224/478
[A[ATraining Step: 293  | total loss: [1m[32m0.12199[0m[0m | time: 12.972s
[2K
| Adam | epoch: 020 | loss: 0.12199 - acc: 0.9536 -- iter: 256/478
[A[ATraining Step: 294  | total loss: [1m[32m0.11719[0m[0m | time: 16.141s
[2K
| Adam | epoch: 020 | loss: 0.11719 - acc: 0.9520 -- iter: 288/478
[A[ATraining Step: 295  | total loss: [1m[32m0.10860[0m[0m | time: 19.234s
[2K
| Adam | epoch: 020 | loss: 0.10860 - acc: 0.9568 -- iter: 320/478
[A[ATraining Step: 296  | total loss: [1m[32m0.11305[0m[0m | time: 20.388s
[2K
| Adam | epoch: 020 | loss: 0.11305 - acc: 0.9486 -- iter: 352/478
[A[ATraining Step: 297  | total loss: [1m[32m0.11309[0m[0m | time: 21.606s
[2K
| Adam | epoch: 020 | loss: 0.11309 - acc: 0.9506 -- iter: 384/478
[A[ATraining Step: 298  | total loss: [1m[32m0.10426[0m[0m | time: 22.893s
[2K
| Adam | epoch: 020 | loss: 0.10426 - acc: 0.9556 -- iter: 416/478
[A[ATraining Step: 299  | total loss: [1m[32m0.09605[0m[0m | time: 24.221s
[2K
| Adam | epoch: 020 | loss: 0.09605 - acc: 0.9600 -- iter: 448/478
[A[ATraining Step: 300  | total loss: [1m[32m0.08887[0m[0m | time: 26.761s
[2K
| Adam | epoch: 020 | loss: 0.08887 - acc: 0.9640 | val_loss: 0.80188 - val_acc: 0.7467 -- iter: 478/478
--
Training Step: 301  | total loss: [1m[32m0.10059[0m[0m | time: 1.429s
[2K
| Adam | epoch: 021 | loss: 0.10059 - acc: 0.9551 -- iter: 032/478
[A[ATraining Step: 302  | total loss: [1m[32m0.10522[0m[0m | time: 2.710s
[2K
| Adam | epoch: 021 | loss: 0.10522 - acc: 0.9565 -- iter: 064/478
[A[ATraining Step: 303  | total loss: [1m[32m0.10940[0m[0m | time: 3.900s
[2K
| Adam | epoch: 021 | loss: 0.10940 - acc: 0.9546 -- iter: 096/478
[A[ATraining Step: 304  | total loss: [1m[32m0.10715[0m[0m | time: 4.999s
[2K
| Adam | epoch: 021 | loss: 0.10715 - acc: 0.9558 -- iter: 128/478
[A[ATraining Step: 305  | total loss: [1m[32m0.10355[0m[0m | time: 6.002s
[2K
| Adam | epoch: 021 | loss: 0.10355 - acc: 0.9569 -- iter: 160/478
[A[ATraining Step: 306  | total loss: [1m[32m0.10723[0m[0m | time: 6.796s
[2K
| Adam | epoch: 021 | loss: 0.10723 - acc: 0.9549 -- iter: 192/478
[A[ATraining Step: 307  | total loss: [1m[32m0.09927[0m[0m | time: 7.685s
[2K
| Adam | epoch: 021 | loss: 0.09927 - acc: 0.9594 -- iter: 224/478
[A[ATraining Step: 308  | total loss: [1m[32m0.09654[0m[0m | time: 8.527s
[2K
| Adam | epoch: 021 | loss: 0.09654 - acc: 0.9604 -- iter: 256/478
[A[ATraining Step: 309  | total loss: [1m[32m0.10116[0m[0m | time: 9.328s
[2K
| Adam | epoch: 021 | loss: 0.10116 - acc: 0.9612 -- iter: 288/478
[A[ATraining Step: 310  | total loss: [1m[32m0.09509[0m[0m | time: 10.193s
[2K
| Adam | epoch: 021 | loss: 0.09509 - acc: 0.9651 -- iter: 320/478
[A[ATraining Step: 311  | total loss: [1m[32m0.09207[0m[0m | time: 11.030s
[2K
| Adam | epoch: 021 | loss: 0.09207 - acc: 0.9623 -- iter: 352/478
[A[ATraining Step: 312  | total loss: [1m[32m0.11063[0m[0m | time: 11.845s
[2K
| Adam | epoch: 021 | loss: 0.11063 - acc: 0.9567 -- iter: 384/478
[A[ATraining Step: 313  | total loss: [1m[32m0.11848[0m[0m | time: 12.663s
[2K
| Adam | epoch: 021 | loss: 0.11848 - acc: 0.9454 -- iter: 416/478
[A[ATraining Step: 314  | total loss: [1m[32m0.16378[0m[0m | time: 13.519s
[2K
| Adam | epoch: 021 | loss: 0.16378 - acc: 0.9290 -- iter: 448/478
[A[ATraining Step: 315  | total loss: [1m[32m0.15774[0m[0m | time: 15.359s
[2K
| Adam | epoch: 021 | loss: 0.15774 - acc: 0.9330 | val_loss: 1.00477 - val_acc: 0.6933 -- iter: 478/478
--
Training Step: 316  | total loss: [1m[32m0.15300[0m[0m | time: 0.846s
[2K
| Adam | epoch: 022 | loss: 0.15300 - acc: 0.9334 -- iter: 032/478
[A[ATraining Step: 317  | total loss: [1m[32m0.15590[0m[0m | time: 1.681s
[2K
| Adam | epoch: 022 | loss: 0.15590 - acc: 0.9338 -- iter: 064/478
[A[ATraining Step: 318  | total loss: [1m[32m0.15318[0m[0m | time: 2.525s
[2K
| Adam | epoch: 022 | loss: 0.15318 - acc: 0.9342 -- iter: 096/478
[A[ATraining Step: 319  | total loss: [1m[32m0.14062[0m[0m | time: 3.297s
[2K
| Adam | epoch: 022 | loss: 0.14062 - acc: 0.9408 -- iter: 128/478
[A[ATraining Step: 320  | total loss: [1m[32m0.12845[0m[0m | time: 4.072s
[2K
| Adam | epoch: 022 | loss: 0.12845 - acc: 0.9467 -- iter: 160/478
[A[ATraining Step: 321  | total loss: [1m[32m0.11938[0m[0m | time: 4.951s
[2K
| Adam | epoch: 022 | loss: 0.11938 - acc: 0.9520 -- iter: 192/478
[A[ATraining Step: 322  | total loss: [1m[32m0.12110[0m[0m | time: 5.947s
[2K
| Adam | epoch: 022 | loss: 0.12110 - acc: 0.9506 -- iter: 224/478
[A[ATraining Step: 323  | total loss: [1m[32m0.12181[0m[0m | time: 6.762s
[2K
| Adam | epoch: 022 | loss: 0.12181 - acc: 0.9493 -- iter: 256/478
[A[ATraining Step: 324  | total loss: [1m[32m0.11190[0m[0m | time: 7.575s
[2K
| Adam | epoch: 022 | loss: 0.11190 - acc: 0.9543 -- iter: 288/478
[A[ATraining Step: 325  | total loss: [1m[32m0.10514[0m[0m | time: 8.472s
[2K
| Adam | epoch: 022 | loss: 0.10514 - acc: 0.9589 -- iter: 320/478
[A[ATraining Step: 326  | total loss: [1m[32m0.11486[0m[0m | time: 9.282s
[2K
| Adam | epoch: 022 | loss: 0.11486 - acc: 0.9568 -- iter: 352/478
[A[ATraining Step: 327  | total loss: [1m[32m0.10657[0m[0m | time: 10.095s
[2K
| Adam | epoch: 022 | loss: 0.10657 - acc: 0.9611 -- iter: 384/478
[A[ATraining Step: 328  | total loss: [1m[32m0.10446[0m[0m | time: 10.830s
[2K
| Adam | epoch: 022 | loss: 0.10446 - acc: 0.9619 -- iter: 416/478
[A[ATraining Step: 329  | total loss: [1m[32m0.09691[0m[0m | time: 11.673s
[2K
| Adam | epoch: 022 | loss: 0.09691 - acc: 0.9657 -- iter: 448/478
[A[ATraining Step: 330  | total loss: [1m[32m0.10037[0m[0m | time: 13.487s
[2K
| Adam | epoch: 022 | loss: 0.10037 - acc: 0.9629 | val_loss: 0.90284 - val_acc: 0.7200 -- iter: 478/478
--
Training Step: 331  | total loss: [1m[32m0.11188[0m[0m | time: 0.844s
[2K
| Adam | epoch: 023 | loss: 0.11188 - acc: 0.9572 -- iter: 032/478
[A[ATraining Step: 332  | total loss: [1m[32m0.10444[0m[0m | time: 2.315s
[2K
| Adam | epoch: 023 | loss: 0.10444 - acc: 0.9615 -- iter: 064/478
[A[ATraining Step: 333  | total loss: [1m[32m0.12642[0m[0m | time: 3.736s
[2K
| Adam | epoch: 023 | loss: 0.12642 - acc: 0.9560 -- iter: 096/478
[A[ATraining Step: 334  | total loss: [1m[32m0.11621[0m[0m | time: 4.975s
[2K
| Adam | epoch: 023 | loss: 0.11621 - acc: 0.9604 -- iter: 128/478
[A[ATraining Step: 335  | total loss: [1m[32m0.12637[0m[0m | time: 6.164s
[2K
| Adam | epoch: 023 | loss: 0.12637 - acc: 0.9612 -- iter: 160/478
[A[ATraining Step: 336  | total loss: [1m[32m0.19626[0m[0m | time: 7.585s
[2K
| Adam | epoch: 023 | loss: 0.19626 - acc: 0.9451 -- iter: 192/478
[A[ATraining Step: 337  | total loss: [1m[32m0.18683[0m[0m | time: 8.982s
[2K
| Adam | epoch: 023 | loss: 0.18683 - acc: 0.9472 -- iter: 224/478
[A[ATraining Step: 338  | total loss: [1m[32m0.20648[0m[0m | time: 10.352s
[2K
| Adam | epoch: 023 | loss: 0.20648 - acc: 0.9338 -- iter: 256/478
[A[ATraining Step: 339  | total loss: [1m[32m0.19314[0m[0m | time: 11.273s
[2K
| Adam | epoch: 023 | loss: 0.19314 - acc: 0.9404 -- iter: 288/478
[A[ATraining Step: 340  | total loss: [1m[32m0.17579[0m[0m | time: 12.271s
[2K
| Adam | epoch: 023 | loss: 0.17579 - acc: 0.9463 -- iter: 320/478
[A[ATraining Step: 341  | total loss: [1m[32m0.16996[0m[0m | time: 13.071s
[2K
| Adam | epoch: 023 | loss: 0.16996 - acc: 0.9486 -- iter: 352/478
[A[ATraining Step: 342  | total loss: [1m[32m0.15988[0m[0m | time: 13.859s
[2K
| Adam | epoch: 023 | loss: 0.15988 - acc: 0.9537 -- iter: 384/478
[A[ATraining Step: 343  | total loss: [1m[32m0.14813[0m[0m | time: 14.677s
[2K
| Adam | epoch: 023 | loss: 0.14813 - acc: 0.9584 -- iter: 416/478
[A[ATraining Step: 344  | total loss: [1m[32m0.14666[0m[0m | time: 15.506s
[2K
| Adam | epoch: 023 | loss: 0.14666 - acc: 0.9563 -- iter: 448/478
[A[ATraining Step: 345  | total loss: [1m[32m0.13416[0m[0m | time: 17.284s
[2K
| Adam | epoch: 023 | loss: 0.13416 - acc: 0.9606 | val_loss: 0.87789 - val_acc: 0.7267 -- iter: 478/478
--
Training Step: 346  | total loss: [1m[32m0.12422[0m[0m | time: 0.889s
[2K
| Adam | epoch: 024 | loss: 0.12422 - acc: 0.9646 -- iter: 032/478
[A[ATraining Step: 347  | total loss: [1m[32m0.11793[0m[0m | time: 1.648s
[2K
| Adam | epoch: 024 | loss: 0.11793 - acc: 0.9681 -- iter: 064/478
[A[ATraining Step: 348  | total loss: [1m[32m0.11265[0m[0m | time: 2.448s
[2K
| Adam | epoch: 024 | loss: 0.11265 - acc: 0.9713 -- iter: 096/478
[A[ATraining Step: 349  | total loss: [1m[32m0.11487[0m[0m | time: 3.207s
[2K
| Adam | epoch: 024 | loss: 0.11487 - acc: 0.9711 -- iter: 128/478
[A[ATraining Step: 350  | total loss: [1m[32m0.12142[0m[0m | time: 4.031s
[2K
| Adam | epoch: 024 | loss: 0.12142 - acc: 0.9677 -- iter: 160/478
[A[ATraining Step: 351  | total loss: [1m[32m0.11243[0m[0m | time: 4.820s
[2K
| Adam | epoch: 024 | loss: 0.11243 - acc: 0.9709 -- iter: 192/478
[A[ATraining Step: 352  | total loss: [1m[32m0.11333[0m[0m | time: 5.587s
[2K
| Adam | epoch: 024 | loss: 0.11333 - acc: 0.9672 -- iter: 224/478
[A[ATraining Step: 353  | total loss: [1m[32m0.11231[0m[0m | time: 6.375s
[2K
| Adam | epoch: 024 | loss: 0.11231 - acc: 0.9671 -- iter: 256/478
[A[ATraining Step: 354  | total loss: [1m[32m0.11055[0m[0m | time: 7.160s
[2K
| Adam | epoch: 024 | loss: 0.11055 - acc: 0.9673 -- iter: 288/478
[A[ATraining Step: 355  | total loss: [1m[32m0.11078[0m[0m | time: 7.968s
[2K
| Adam | epoch: 024 | loss: 0.11078 - acc: 0.9643 -- iter: 320/478
[A[ATraining Step: 356  | total loss: [1m[32m0.10387[0m[0m | time: 8.786s
[2K
| Adam | epoch: 024 | loss: 0.10387 - acc: 0.9679 -- iter: 352/478
[A[ATraining Step: 357  | total loss: [1m[32m0.09894[0m[0m | time: 9.651s
[2K
| Adam | epoch: 024 | loss: 0.09894 - acc: 0.9680 -- iter: 384/478
[A[ATraining Step: 358  | total loss: [1m[32m0.10451[0m[0m | time: 10.685s
[2K
| Adam | epoch: 024 | loss: 0.10451 - acc: 0.9680 -- iter: 416/478
[A[ATraining Step: 359  | total loss: [1m[32m0.10016[0m[0m | time: 11.418s
[2K
| Adam | epoch: 024 | loss: 0.10016 - acc: 0.9681 -- iter: 448/478
[A[ATraining Step: 360  | total loss: [1m[32m0.09585[0m[0m | time: 13.267s
[2K
| Adam | epoch: 024 | loss: 0.09585 - acc: 0.9682 | val_loss: 0.75945 - val_acc: 0.7533 -- iter: 478/478
--
Training Step: 361  | total loss: [1m[32m0.09426[0m[0m | time: 0.805s
[2K
| Adam | epoch: 025 | loss: 0.09426 - acc: 0.9682 -- iter: 032/478
[A[ATraining Step: 362  | total loss: [1m[32m0.09813[0m[0m | time: 1.615s
[2K
| Adam | epoch: 025 | loss: 0.09813 - acc: 0.9683 -- iter: 064/478
[A[ATraining Step: 363  | total loss: [1m[32m0.09013[0m[0m | time: 2.314s
[2K
| Adam | epoch: 025 | loss: 0.09013 - acc: 0.9715 -- iter: 096/478
[A[ATraining Step: 364  | total loss: [1m[32m0.09137[0m[0m | time: 3.150s
[2K
| Adam | epoch: 025 | loss: 0.09137 - acc: 0.9712 -- iter: 128/478
[A[ATraining Step: 365  | total loss: [1m[32m0.09742[0m[0m | time: 3.941s
[2K
| Adam | epoch: 025 | loss: 0.09742 - acc: 0.9678 -- iter: 160/478
[A[ATraining Step: 366  | total loss: [1m[32m0.10001[0m[0m | time: 4.762s
[2K
| Adam | epoch: 025 | loss: 0.10001 - acc: 0.9679 -- iter: 192/478
[A[ATraining Step: 367  | total loss: [1m[32m0.09624[0m[0m | time: 5.553s
[2K
| Adam | epoch: 025 | loss: 0.09624 - acc: 0.9680 -- iter: 224/478
[A[ATraining Step: 368  | total loss: [1m[32m0.18590[0m[0m | time: 6.341s
[2K
| Adam | epoch: 025 | loss: 0.18590 - acc: 0.9445 -- iter: 256/478
[A[ATraining Step: 369  | total loss: [1m[32m0.17323[0m[0m | time: 7.130s
[2K
| Adam | epoch: 025 | loss: 0.17323 - acc: 0.9467 -- iter: 288/478
[A[ATraining Step: 370  | total loss: [1m[32m0.15965[0m[0m | time: 7.898s
[2K
| Adam | epoch: 025 | loss: 0.15965 - acc: 0.9521 -- iter: 320/478
[A[ATraining Step: 371  | total loss: [1m[32m0.15033[0m[0m | time: 8.657s
[2K
| Adam | epoch: 025 | loss: 0.15033 - acc: 0.9537 -- iter: 352/478
[A[ATraining Step: 372  | total loss: [1m[32m0.15241[0m[0m | time: 9.484s
[2K
| Adam | epoch: 025 | loss: 0.15241 - acc: 0.9490 -- iter: 384/478
[A[ATraining Step: 373  | total loss: [1m[32m0.14018[0m[0m | time: 10.328s
[2K
| Adam | epoch: 025 | loss: 0.14018 - acc: 0.9541 -- iter: 416/478
[A[ATraining Step: 374  | total loss: [1m[32m0.12922[0m[0m | time: 11.054s
[2K
| Adam | epoch: 025 | loss: 0.12922 - acc: 0.9587 -- iter: 448/478
[A[ATraining Step: 375  | total loss: [1m[32m0.12319[0m[0m | time: 12.856s
[2K
| Adam | epoch: 025 | loss: 0.12319 - acc: 0.9628 | val_loss: 0.78514 - val_acc: 0.7200 -- iter: 478/478
--
Training Step: 376  | total loss: [1m[32m0.12109[0m[0m | time: 0.816s
[2K
| Adam | epoch: 026 | loss: 0.12109 - acc: 0.9634 -- iter: 032/478
[A[ATraining Step: 377  | total loss: [1m[32m0.11474[0m[0m | time: 1.665s
[2K
| Adam | epoch: 026 | loss: 0.11474 - acc: 0.9639 -- iter: 064/478
[A[ATraining Step: 378  | total loss: [1m[32m0.11893[0m[0m | time: 2.495s
[2K
| Adam | epoch: 026 | loss: 0.11893 - acc: 0.9644 -- iter: 096/478
[A[ATraining Step: 379  | total loss: [1m[32m0.11134[0m[0m | time: 3.263s
[2K
| Adam | epoch: 026 | loss: 0.11134 - acc: 0.9680 -- iter: 128/478
[A[ATraining Step: 380  | total loss: [1m[32m0.10173[0m[0m | time: 4.135s
[2K
| Adam | epoch: 026 | loss: 0.10173 - acc: 0.9712 -- iter: 160/478
[A[ATraining Step: 381  | total loss: [1m[32m0.09910[0m[0m | time: 4.947s
[2K
| Adam | epoch: 026 | loss: 0.09910 - acc: 0.9709 -- iter: 192/478
[A[ATraining Step: 382  | total loss: [1m[32m0.09143[0m[0m | time: 5.820s
[2K
| Adam | epoch: 026 | loss: 0.09143 - acc: 0.9738 -- iter: 224/478
[A[ATraining Step: 383  | total loss: [1m[32m0.09026[0m[0m | time: 6.595s
[2K
| Adam | epoch: 026 | loss: 0.09026 - acc: 0.9702 -- iter: 256/478
[A[ATraining Step: 384  | total loss: [1m[32m0.09822[0m[0m | time: 7.298s
[2K
| Adam | epoch: 026 | loss: 0.09822 - acc: 0.9699 -- iter: 288/478
[A[ATraining Step: 385  | total loss: [1m[32m0.08961[0m[0m | time: 8.168s
[2K
| Adam | epoch: 026 | loss: 0.08961 - acc: 0.9729 -- iter: 320/478
[A[ATraining Step: 386  | total loss: [1m[32m0.08441[0m[0m | time: 9.003s
[2K
| Adam | epoch: 026 | loss: 0.08441 - acc: 0.9725 -- iter: 352/478
[A[ATraining Step: 387  | total loss: [1m[32m0.08882[0m[0m | time: 9.782s
[2K
| Adam | epoch: 026 | loss: 0.08882 - acc: 0.9658 -- iter: 384/478
[A[ATraining Step: 388  | total loss: [1m[32m0.08416[0m[0m | time: 10.549s
[2K
| Adam | epoch: 026 | loss: 0.08416 - acc: 0.9661 -- iter: 416/478
[A[ATraining Step: 389  | total loss: [1m[32m0.07753[0m[0m | time: 11.295s
[2K
| Adam | epoch: 026 | loss: 0.07753 - acc: 0.9695 -- iter: 448/478
[A[ATraining Step: 390  | total loss: [1m[32m0.07729[0m[0m | time: 13.084s
[2K
| Adam | epoch: 026 | loss: 0.07729 - acc: 0.9694 | val_loss: 0.88566 - val_acc: 0.7267 -- iter: 478/478
--
Training Step: 391  | total loss: [1m[32m0.07130[0m[0m | time: 0.708s
[2K
| Adam | epoch: 027 | loss: 0.07130 - acc: 0.9725 -- iter: 032/478
[A[ATraining Step: 392  | total loss: [1m[32m0.06871[0m[0m | time: 1.605s
[2K
| Adam | epoch: 027 | loss: 0.06871 - acc: 0.9721 -- iter: 064/478
[A[ATraining Step: 393  | total loss: [1m[32m0.06697[0m[0m | time: 2.427s
[2K
| Adam | epoch: 027 | loss: 0.06697 - acc: 0.9718 -- iter: 096/478
[A[ATraining Step: 394  | total loss: [1m[32m0.06650[0m[0m | time: 3.129s
[2K
| Adam | epoch: 027 | loss: 0.06650 - acc: 0.9715 -- iter: 128/478
[A[ATraining Step: 395  | total loss: [1m[32m0.06068[0m[0m | time: 3.891s
[2K
| Adam | epoch: 027 | loss: 0.06068 - acc: 0.9743 -- iter: 160/478
[A[ATraining Step: 396  | total loss: [1m[32m0.05966[0m[0m | time: 4.696s
[2K
| Adam | epoch: 027 | loss: 0.05966 - acc: 0.9738 -- iter: 192/478
[A[ATraining Step: 397  | total loss: [1m[32m0.06071[0m[0m | time: 5.531s
[2K
| Adam | epoch: 027 | loss: 0.06071 - acc: 0.9701 -- iter: 224/478
[A[ATraining Step: 398  | total loss: [1m[32m0.05963[0m[0m | time: 6.252s
[2K
| Adam | epoch: 027 | loss: 0.05963 - acc: 0.9700 -- iter: 256/478
[A[ATraining Step: 399  | total loss: [1m[32m0.05460[0m[0m | time: 6.997s
[2K
| Adam | epoch: 027 | loss: 0.05460 - acc: 0.9730 -- iter: 288/478
[A[ATraining Step: 400  | total loss: [1m[32m0.04970[0m[0m | time: 8.812s
[2K
| Adam | epoch: 027 | loss: 0.04970 - acc: 0.9757 | val_loss: 0.94445 - val_acc: 0.7333 -- iter: 320/478
--
Training Step: 401  | total loss: [1m[32m0.04510[0m[0m | time: 9.644s
[2K
| Adam | epoch: 027 | loss: 0.04510 - acc: 0.9781 -- iter: 352/478
[A[ATraining Step: 402  | total loss: [1m[32m0.05320[0m[0m | time: 10.405s
[2K
| Adam | epoch: 027 | loss: 0.05320 - acc: 0.9741 -- iter: 384/478
[A[ATraining Step: 403  | total loss: [1m[32m0.04841[0m[0m | time: 11.229s
[2K
| Adam | epoch: 027 | loss: 0.04841 - acc: 0.9767 -- iter: 416/478
[A[ATraining Step: 404  | total loss: [1m[32m0.04728[0m[0m | time: 12.103s
[2K
| Adam | epoch: 027 | loss: 0.04728 - acc: 0.9759 -- iter: 448/478
[A[ATraining Step: 405  | total loss: [1m[32m0.04486[0m[0m | time: 13.919s
[2K
| Adam | epoch: 027 | loss: 0.04486 - acc: 0.9783 | val_loss: 1.03679 - val_acc: 0.7467 -- iter: 478/478
--
Training Step: 406  | total loss: [1m[32m0.04112[0m[0m | time: 0.774s
[2K
| Adam | epoch: 028 | loss: 0.04112 - acc: 0.9805 -- iter: 032/478
[A[ATraining Step: 407  | total loss: [1m[32m0.05468[0m[0m | time: 1.579s
[2K
| Adam | epoch: 028 | loss: 0.05468 - acc: 0.9762 -- iter: 064/478
[A[ATraining Step: 408  | total loss: [1m[32m0.06383[0m[0m | time: 2.349s
[2K
| Adam | epoch: 028 | loss: 0.06383 - acc: 0.9754 -- iter: 096/478
[A[ATraining Step: 409  | total loss: [1m[32m0.05827[0m[0m | time: 3.196s
[2K
| Adam | epoch: 028 | loss: 0.05827 - acc: 0.9779 -- iter: 128/478
[A[ATraining Step: 410  | total loss: [1m[32m0.05295[0m[0m | time: 4.058s
[2K
| Adam | epoch: 028 | loss: 0.05295 - acc: 0.9801 -- iter: 160/478
[A[ATraining Step: 411  | total loss: [1m[32m0.04840[0m[0m | time: 4.867s
[2K
| Adam | epoch: 028 | loss: 0.04840 - acc: 0.9821 -- iter: 192/478
[A[ATraining Step: 412  | total loss: [1m[32m0.04450[0m[0m | time: 5.653s
[2K
| Adam | epoch: 028 | loss: 0.04450 - acc: 0.9839 -- iter: 224/478
[A[ATraining Step: 413  | total loss: [1m[32m0.05565[0m[0m | time: 6.397s
[2K
| Adam | epoch: 028 | loss: 0.05565 - acc: 0.9792 -- iter: 256/478
[A[ATraining Step: 414  | total loss: [1m[32m0.07550[0m[0m | time: 7.151s
[2K
| Adam | epoch: 028 | loss: 0.07550 - acc: 0.9719 -- iter: 288/478
[A[ATraining Step: 415  | total loss: [1m[32m0.07646[0m[0m | time: 7.964s
[2K
| Adam | epoch: 028 | loss: 0.07646 - acc: 0.9716 -- iter: 320/478
[A[ATraining Step: 416  | total loss: [1m[32m0.09017[0m[0m | time: 8.746s
[2K
| Adam | epoch: 028 | loss: 0.09017 - acc: 0.9678 -- iter: 352/478
[A[ATraining Step: 417  | total loss: [1m[32m0.10101[0m[0m | time: 9.578s
[2K
| Adam | epoch: 028 | loss: 0.10101 - acc: 0.9643 -- iter: 384/478
[A[ATraining Step: 418  | total loss: [1m[32m0.09289[0m[0m | time: 10.432s
[2K
| Adam | epoch: 028 | loss: 0.09289 - acc: 0.9679 -- iter: 416/478
[A[ATraining Step: 419  | total loss: [1m[32m0.08580[0m[0m | time: 11.262s
[2K
| Adam | epoch: 028 | loss: 0.08580 - acc: 0.9711 -- iter: 448/478
[A[ATraining Step: 420  | total loss: [1m[32m0.07861[0m[0m | time: 13.140s
[2K
| Adam | epoch: 028 | loss: 0.07861 - acc: 0.9740 | val_loss: 0.81742 - val_acc: 0.7467 -- iter: 478/478
--
Training Step: 421  | total loss: [1m[32m0.07286[0m[0m | time: 0.819s
[2K
| Adam | epoch: 029 | loss: 0.07286 - acc: 0.9766 -- iter: 032/478
[A[ATraining Step: 422  | total loss: [1m[32m0.08333[0m[0m | time: 1.669s
[2K
| Adam | epoch: 029 | loss: 0.08333 - acc: 0.9758 -- iter: 064/478
[A[ATraining Step: 423  | total loss: [1m[32m0.07648[0m[0m | time: 2.439s
[2K
| Adam | epoch: 029 | loss: 0.07648 - acc: 0.9782 -- iter: 096/478
[A[ATraining Step: 424  | total loss: [1m[32m0.08054[0m[0m | time: 3.314s
[2K
| Adam | epoch: 029 | loss: 0.08054 - acc: 0.9742 -- iter: 128/478
[A[ATraining Step: 425  | total loss: [1m[32m0.09732[0m[0m | time: 4.174s
[2K
| Adam | epoch: 029 | loss: 0.09732 - acc: 0.9705 -- iter: 160/478
[A[ATraining Step: 426  | total loss: [1m[32m0.12124[0m[0m | time: 5.065s
[2K
| Adam | epoch: 029 | loss: 0.12124 - acc: 0.9672 -- iter: 192/478
[A[ATraining Step: 427  | total loss: [1m[32m0.11024[0m[0m | time: 5.978s
[2K
| Adam | epoch: 029 | loss: 0.11024 - acc: 0.9705 -- iter: 224/478
[A[ATraining Step: 428  | total loss: [1m[32m0.11174[0m[0m | time: 6.645s
[2K
| Adam | epoch: 029 | loss: 0.11174 - acc: 0.9672 -- iter: 256/478
[A[ATraining Step: 429  | total loss: [1m[32m0.10289[0m[0m | time: 7.553s
[2K
| Adam | epoch: 029 | loss: 0.10289 - acc: 0.9705 -- iter: 288/478
[A[ATraining Step: 430  | total loss: [1m[32m0.11563[0m[0m | time: 8.366s
[2K
| Adam | epoch: 029 | loss: 0.11563 - acc: 0.9640 -- iter: 320/478
[A[ATraining Step: 431  | total loss: [1m[32m0.13085[0m[0m | time: 9.179s
[2K
| Adam | epoch: 029 | loss: 0.13085 - acc: 0.9489 -- iter: 352/478
[A[ATraining Step: 432  | total loss: [1m[32m0.16011[0m[0m | time: 9.968s
[2K
| Adam | epoch: 029 | loss: 0.16011 - acc: 0.9407 -- iter: 384/478
[A[ATraining Step: 433  | total loss: [1m[32m0.15601[0m[0m | time: 10.847s
[2K
| Adam | epoch: 029 | loss: 0.15601 - acc: 0.9366 -- iter: 416/478
[A[ATraining Step: 434  | total loss: [1m[32m0.14241[0m[0m | time: 11.632s
[2K
| Adam | epoch: 029 | loss: 0.14241 - acc: 0.9429 -- iter: 448/478
[A[ATraining Step: 435  | total loss: [1m[32m0.13803[0m[0m | time: 13.492s
[2K
| Adam | epoch: 029 | loss: 0.13803 - acc: 0.9455 | val_loss: 0.92369 - val_acc: 0.6933 -- iter: 478/478
--
Training Step: 436  | total loss: [1m[32m0.13773[0m[0m | time: 0.766s
[2K
| Adam | epoch: 030 | loss: 0.13773 - acc: 0.9478 -- iter: 032/478
[A[ATraining Step: 437  | total loss: [1m[32m0.15437[0m[0m | time: 1.625s
[2K
| Adam | epoch: 030 | loss: 0.15437 - acc: 0.9468 -- iter: 064/478
[A[ATraining Step: 438  | total loss: [1m[32m0.14245[0m[0m | time: 2.506s
[2K
| Adam | epoch: 030 | loss: 0.14245 - acc: 0.9521 -- iter: 096/478
[A[ATraining Step: 439  | total loss: [1m[32m0.12989[0m[0m | time: 3.430s
[2K
| Adam | epoch: 030 | loss: 0.12989 - acc: 0.9569 -- iter: 128/478
[A[ATraining Step: 440  | total loss: [1m[32m0.13004[0m[0m | time: 4.225s
[2K
| Adam | epoch: 030 | loss: 0.13004 - acc: 0.9581 -- iter: 160/478
[A[ATraining Step: 441  | total loss: [1m[32m0.12378[0m[0m | time: 5.055s
[2K
| Adam | epoch: 030 | loss: 0.12378 - acc: 0.9623 -- iter: 192/478
[A[ATraining Step: 442  | total loss: [1m[32m0.12528[0m[0m | time: 5.874s
[2K
| Adam | epoch: 030 | loss: 0.12528 - acc: 0.9629 -- iter: 224/478
[A[ATraining Step: 443  | total loss: [1m[32m0.11625[0m[0m | time: 6.704s
[2K
| Adam | epoch: 030 | loss: 0.11625 - acc: 0.9666 -- iter: 256/478
[A[ATraining Step: 444  | total loss: [1m[32m0.11270[0m[0m | time: 7.565s
[2K
| Adam | epoch: 030 | loss: 0.11270 - acc: 0.9669 -- iter: 288/478
[A[ATraining Step: 445  | total loss: [1m[32m0.11545[0m[0m | time: 8.451s
[2K
| Adam | epoch: 030 | loss: 0.11545 - acc: 0.9670 -- iter: 320/478
[A[ATraining Step: 446  | total loss: [1m[32m0.10682[0m[0m | time: 9.125s
[2K
| Adam | epoch: 030 | loss: 0.10682 - acc: 0.9703 -- iter: 352/478
[A[ATraining Step: 447  | total loss: [1m[32m0.09862[0m[0m | time: 9.936s
[2K
| Adam | epoch: 030 | loss: 0.09862 - acc: 0.9733 -- iter: 384/478
[A[ATraining Step: 448  | total loss: [1m[32m0.12065[0m[0m | time: 10.718s
[2K
| Adam | epoch: 030 | loss: 0.12065 - acc: 0.9693 -- iter: 416/478
[A[ATraining Step: 449  | total loss: [1m[32m0.11129[0m[0m | time: 11.502s
[2K
| Adam | epoch: 030 | loss: 0.11129 - acc: 0.9724 -- iter: 448/478
[A[ATraining Step: 450  | total loss: [1m[32m0.10746[0m[0m | time: 13.287s
[2K
| Adam | epoch: 030 | loss: 0.10746 - acc: 0.9720 | val_loss: 0.82455 - val_acc: 0.7067 -- iter: 478/478
--
Validation AUC:0.7957407407407407
Validation AUPRC:0.7403024824864337
Test AUC:0.8564705882352942
Test AUPRC:0.8385421831950957
BestTestF1Score	0.77	0.56	0.77	0.69	0.86	56	25	60	9	0.18
BestTestMCCScore	0.77	0.56	0.77	0.69	0.86	56	25	60	9	0.18
BestTestAccuracyScore	0.77	0.56	0.77	0.69	0.86	56	25	60	9	0.18
BestValidationF1Score	0.73	0.52	0.75	0.65	0.82	49	26	64	11	0.18
BestValidationMCC	0.73	0.52	0.75	0.65	0.82	49	26	64	11	0.18
BestValidationAccuracy	0.73	0.52	0.75	0.65	0.82	49	26	64	11	0.18
TestPredictions (Threshold:0.18)
CHEMBL1672127,TN,INACT,0.019999999552965164	CHEMBL1683138,TN,INACT,0.0	CHEMBL171733,FP,INACT,0.9599999785423279	CHEMBL1929391,TP,ACT,0.9900000095367432	CHEMBL233563,TN,INACT,0.05999999865889549	CHEMBL243231,TN,INACT,0.0	CHEMBL3085037,FN,ACT,0.10000000149011612	CHEMBL3091488,TP,ACT,0.9700000286102295	CHEMBL377296,TP,ACT,0.7200000286102295	CHEMBL231294,TN,INACT,0.0	CHEMBL3093900,TP,ACT,0.9300000071525574	CHEMBL1085269,TP,ACT,0.9900000095367432	CHEMBL3093910,TP,ACT,0.7799999713897705	CHEMBL1682983,TN,INACT,0.009999999776482582	CHEMBL1783633,FP,INACT,0.4699999988079071	CHEMBL1082350,TP,ACT,0.9900000095367432	CHEMBL452520,FP,INACT,0.3700000047683716	CHEMBL455298,TP,ACT,0.38999998569488525	CHEMBL506177,TP,ACT,0.9900000095367432	CHEMBL363375,TN,INACT,0.009999999776482582	CHEMBL557990,TN,INACT,0.009999999776482582	CHEMBL601860,FP,INACT,0.949999988079071	CHEMBL558323,TP,ACT,0.9800000190734863	CHEMBL427259,TN,INACT,0.0	CHEMBL97483,TN,INACT,0.009999999776482582	CHEMBL1243373,TP,ACT,0.9599999785423279	CHEMBL223497,TP,ACT,0.23000000417232513	CHEMBL191258,TN,INACT,0.0	CHEMBL3127990,TP,ACT,0.27000001072883606	CHEMBL196114,TN,INACT,0.029999999329447746	CHEMBL2069860,TP,ACT,0.9900000095367432	CHEMBL1683130,TN,INACT,0.019999999552965164	CHEMBL567727,TP,ACT,0.9900000095367432	CHEMBL251404,TN,INACT,0.0	CHEMBL269277,FP,INACT,0.9599999785423279	CHEMBL3330053,TP,ACT,0.9900000095367432	CHEMBL235198,FP,INACT,0.5600000023841858	CHEMBL2385287,FP,INACT,0.9800000190734863	CHEMBL437557,FP,INACT,0.5600000023841858	CHEMBL488047,FN,ACT,0.05000000074505806	CHEMBL1683125,TP,ACT,0.9700000286102295	CHEMBL249945,TN,INACT,0.0	CHEMBL3093907,TP,ACT,0.4399999976158142	CHEMBL390193,TN,INACT,0.0	CHEMBL17347,TN,INACT,0.14000000059604645	CHEMBL3233567,FP,INACT,0.9599999785423279	CHEMBL3216719,FN,ACT,0.029999999329447746	CHEMBL382382,FP,INACT,0.9900000095367432	CHEMBL1683111,TN,INACT,0.11999999731779099	CHEMBL2441951,FN,ACT,0.11999999731779099	CHEMBL63860,TP,ACT,0.38999998569488525	CHEMBL2425077,TN,INACT,0.09000000357627869	CHEMBL559477,TN,INACT,0.009999999776482582	CHEMBL197352,FN,ACT,0.019999999552965164	CHEMBL3093903,TP,ACT,0.9900000095367432	CHEMBL469538,FP,INACT,0.9700000286102295	CHEMBL438265,TN,INACT,0.0	CHEMBL561120,TP,ACT,0.9399999976158142	CHEMBL3818472,FP,INACT,0.33000001311302185	CHEMBL552503,TN,INACT,0.0	CHEMBL508494,TN,INACT,0.029999999329447746	CHEMBL1910107,TP,ACT,1.0	CHEMBL389538,TN,INACT,0.0	CHEMBL230340,TN,INACT,0.0	CHEMBL562530,TN,INACT,0.0	CHEMBL151461,FP,INACT,0.5699999928474426	CHEMBL501521,FP,INACT,0.949999988079071	CHEMBL2063034,TP,ACT,0.9900000095367432	CHEMBL3686741,FP,INACT,0.8399999737739563	CHEMBL1215374,TP,ACT,0.41999998688697815	CHEMBL147691,TN,INACT,0.009999999776482582	CHEMBL395213,TP,ACT,0.9399999976158142	CHEMBL390513,TP,ACT,0.949999988079071	CHEMBL1208841,TP,ACT,0.9900000095367432	CHEMBL364093,TN,INACT,0.0	CHEMBL1929395,TP,ACT,0.9800000190734863	CHEMBL563901,TP,ACT,0.9900000095367432	CHEMBL466590,TP,ACT,0.9900000095367432	CHEMBL1909993,TP,ACT,0.9900000095367432	CHEMBL3357775,TP,ACT,1.0	CHEMBL269926,FP,INACT,0.4099999964237213	CHEMBL2441950,TP,ACT,0.9900000095367432	CHEMBL511346,TN,INACT,0.009999999776482582	CHEMBL2063030,TP,ACT,0.949999988079071	CHEMBL539611,TN,INACT,0.0	CHEMBL139770,FP,INACT,0.9800000190734863	CHEMBL194852,FN,ACT,0.009999999776482582	CHEMBL346877,TN,INACT,0.0	CHEMBL481669,TP,ACT,0.9800000190734863	CHEMBL67279,TP,ACT,0.9900000095367432	CHEMBL305170,FP,INACT,0.9900000095367432	CHEMBL539350,TN,INACT,0.0	CHEMBL560669,TN,INACT,0.0	CHEMBL480712,TP,ACT,0.9900000095367432	CHEMBL1909994,TP,ACT,1.0	CHEMBL3233541,TN,INACT,0.0	CHEMBL389804,TN,INACT,0.019999999552965164	CHEMBL2203319,TP,ACT,0.9900000095367432	CHEMBL2418629,TP,ACT,0.9700000286102295	CHEMBL234610,TN,INACT,0.0	CHEMBL394748,TN,INACT,0.009999999776482582	CHEMBL151379,FP,INACT,0.949999988079071	CHEMBL2441836,FN,ACT,0.03999999910593033	CHEMBL2069859,TP,ACT,0.9900000095367432	CHEMBL461496,TN,INACT,0.0	CHEMBL195378,TN,INACT,0.009999999776482582	CHEMBL235004,TN,INACT,0.009999999776482582	CHEMBL453582,TP,ACT,0.9900000095367432	CHEMBL191775,FN,ACT,0.0	CHEMBL1215448,TP,ACT,1.0	CHEMBL425380,TN,INACT,0.009999999776482582	CHEMBL223914,TP,ACT,0.9900000095367432	CHEMBL3093916,TP,ACT,0.75	CHEMBL1683104,TN,INACT,0.009999999776482582	CHEMBL584698,TN,INACT,0.019999999552965164	CHEMBL1682981,TN,INACT,0.0	CHEMBL189055,FN,ACT,0.0	CHEMBL3093899,FP,INACT,0.9700000286102295	CHEMBL407296,FP,INACT,0.9399999976158142	CHEMBL3233575,TN,INACT,0.009999999776482582	CHEMBL557514,TN,INACT,0.0	CHEMBL94278,TP,ACT,0.25999999046325684	CHEMBL1087094,TN,INACT,0.029999999329447746	CHEMBL564283,TP,ACT,0.9700000286102295	CHEMBL2069848,TP,ACT,0.9900000095367432	CHEMBL362018,TP,ACT,1.0	CHEMBL1812729,TN,INACT,0.009999999776482582	CHEMBL3593604,TN,INACT,0.05999999865889549	CHEMBL382127,TN,INACT,0.009999999776482582	CHEMBL461291,TN,INACT,0.0	CHEMBL2441839,TP,ACT,0.9900000095367432	CHEMBL191812,TN,INACT,0.0	CHEMBL599763,FP,INACT,0.949999988079071	CHEMBL3357771,TP,ACT,0.9900000095367432	CHEMBL2063024,TP,ACT,0.9900000095367432	CHEMBL230342,TN,INACT,0.0	CHEMBL1683095,FP,INACT,0.20000000298023224	CHEMBL1683137,TN,INACT,0.0	CHEMBL9237,FP,INACT,0.7400000095367432	CHEMBL3686740,FP,INACT,0.7900000214576721	CHEMBL3330065,TN,INACT,0.11999999731779099	CHEMBL494497,TP,ACT,0.27000001072883606	CHEMBL469891,TP,ACT,0.3400000035762787	CHEMBL1570910,TN,INACT,0.009999999776482582	CHEMBL148954,TN,INACT,0.09000000357627869	CHEMBL195173,TN,INACT,0.0	CHEMBL3112968,TP,ACT,0.1899999976158142	CHEMBL427261,TN,INACT,0.019999999552965164	CHEMBL2418630,TP,ACT,0.9300000071525574	CHEMBL3233570,TN,INACT,0.009999999776482582	

