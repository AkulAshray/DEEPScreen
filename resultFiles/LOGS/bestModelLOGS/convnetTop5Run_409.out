CNNModel CHEMBL312 RMSprop 0.0005 30 128 0 0.6 False True
Number of active compounds :	516
Number of inactive compounds :	344
---------------------------------
Run id: CNNModel_CHEMBL312_RMSprop_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL312_RMSprop_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 534
Validation samples: 168
--
Training Step: 1  | time: 1.359s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/534
[A[ATraining Step: 2  | total loss: [1m[32m0.62371[0m[0m | time: 2.461s
[2K
| RMSProp | epoch: 001 | loss: 0.62371 - acc: 0.4500 -- iter: 064/534
[A[ATraining Step: 3  | total loss: [1m[32m0.68099[0m[0m | time: 3.540s
[2K
| RMSProp | epoch: 001 | loss: 0.68099 - acc: 0.3886 -- iter: 096/534
[A[ATraining Step: 4  | total loss: [1m[32m0.69098[0m[0m | time: 4.741s
[2K
| RMSProp | epoch: 001 | loss: 0.69098 - acc: 0.2847 -- iter: 128/534
[A[ATraining Step: 5  | total loss: [1m[32m0.69297[0m[0m | time: 5.840s
[2K
| RMSProp | epoch: 001 | loss: 0.69297 - acc: 0.3256 -- iter: 160/534
[A[ATraining Step: 6  | total loss: [1m[32m0.69358[0m[0m | time: 7.149s
[2K
| RMSProp | epoch: 001 | loss: 0.69358 - acc: 0.2971 -- iter: 192/534
[A[ATraining Step: 7  | total loss: [1m[32m0.69336[0m[0m | time: 8.790s
[2K
| RMSProp | epoch: 001 | loss: 0.69336 - acc: 0.4188 -- iter: 224/534
[A[ATraining Step: 8  | total loss: [1m[32m0.69338[0m[0m | time: 10.312s
[2K
| RMSProp | epoch: 001 | loss: 0.69338 - acc: 0.4293 -- iter: 256/534
[A[ATraining Step: 9  | total loss: [1m[32m0.69343[0m[0m | time: 11.941s
[2K
| RMSProp | epoch: 001 | loss: 0.69343 - acc: 0.4006 -- iter: 288/534
[A[ATraining Step: 10  | total loss: [1m[32m0.69322[0m[0m | time: 21.395s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4659 -- iter: 320/534
[A[ATraining Step: 11  | total loss: [1m[32m0.69334[0m[0m | time: 27.013s
[2K
| RMSProp | epoch: 001 | loss: 0.69334 - acc: 0.4821 -- iter: 352/534
[A[ATraining Step: 12  | total loss: [1m[32m0.69340[0m[0m | time: 28.205s
[2K
| RMSProp | epoch: 001 | loss: 0.69340 - acc: 0.4620 -- iter: 384/534
[A[ATraining Step: 13  | total loss: [1m[32m0.69347[0m[0m | time: 29.413s
[2K
| RMSProp | epoch: 001 | loss: 0.69347 - acc: 0.4381 -- iter: 416/534
[A[ATraining Step: 14  | total loss: [1m[32m0.69337[0m[0m | time: 30.588s
[2K
| RMSProp | epoch: 001 | loss: 0.69337 - acc: 0.4251 -- iter: 448/534
[A[ATraining Step: 15  | total loss: [1m[32m0.69329[0m[0m | time: 31.800s
[2K
| RMSProp | epoch: 001 | loss: 0.69329 - acc: 0.4666 -- iter: 480/534
[A[ATraining Step: 16  | total loss: [1m[32m0.69337[0m[0m | time: 33.072s
[2K
| RMSProp | epoch: 001 | loss: 0.69337 - acc: 0.4323 -- iter: 512/534
[A[ATraining Step: 17  | total loss: [1m[32m0.69316[0m[0m | time: 35.299s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.5016 | val_loss: 0.69330 - val_acc: 0.4048 -- iter: 534/534
--
Training Step: 18  | total loss: [1m[32m0.69331[0m[0m | time: 0.923s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4539 -- iter: 032/534
[A[ATraining Step: 19  | total loss: [1m[32m0.69341[0m[0m | time: 2.233s
[2K
| RMSProp | epoch: 002 | loss: 0.69341 - acc: 0.3935 -- iter: 064/534
[A[ATraining Step: 20  | total loss: [1m[32m0.69338[0m[0m | time: 3.451s
[2K
| RMSProp | epoch: 002 | loss: 0.69338 - acc: 0.4076 -- iter: 096/534
[A[ATraining Step: 21  | total loss: [1m[32m0.69338[0m[0m | time: 4.744s
[2K
| RMSProp | epoch: 002 | loss: 0.69338 - acc: 0.4072 -- iter: 128/534
[A[ATraining Step: 22  | total loss: [1m[32m0.69324[0m[0m | time: 6.014s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4819 -- iter: 160/534
[A[ATraining Step: 23  | total loss: [1m[32m0.69319[0m[0m | time: 7.210s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4872 -- iter: 192/534
[A[ATraining Step: 24  | total loss: [1m[32m0.69312[0m[0m | time: 7.957s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5084 -- iter: 224/534
[A[ATraining Step: 25  | total loss: [1m[32m0.69316[0m[0m | time: 8.827s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.4890 -- iter: 256/534
[A[ATraining Step: 26  | total loss: [1m[32m0.69320[0m[0m | time: 9.719s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4754 -- iter: 288/534
[A[ATraining Step: 27  | total loss: [1m[32m0.69315[0m[0m | time: 10.603s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4898 -- iter: 320/534
[A[ATraining Step: 28  | total loss: [1m[32m0.69311[0m[0m | time: 11.501s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5079 -- iter: 352/534
[A[ATraining Step: 29  | total loss: [1m[32m0.69310[0m[0m | time: 12.397s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5288 -- iter: 384/534
[A[ATraining Step: 30  | total loss: [1m[32m0.69304[0m[0m | time: 13.308s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5516 -- iter: 416/534
[A[ATraining Step: 31  | total loss: [1m[32m0.69305[0m[0m | time: 14.211s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5469 -- iter: 448/534
[A[ATraining Step: 32  | total loss: [1m[32m0.69304[0m[0m | time: 15.100s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5363 -- iter: 480/534
[A[ATraining Step: 33  | total loss: [1m[32m0.69290[0m[0m | time: 16.120s
[2K
| RMSProp | epoch: 002 | loss: 0.69290 - acc: 0.5764 -- iter: 512/534
[A[ATraining Step: 34  | total loss: [1m[32m0.69290[0m[0m | time: 18.437s
[2K
| RMSProp | epoch: 002 | loss: 0.69290 - acc: 0.5667 | val_loss: 0.69267 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 35  | total loss: [1m[32m0.69290[0m[0m | time: 0.608s
[2K
| RMSProp | epoch: 003 | loss: 0.69290 - acc: 0.5658 -- iter: 032/534
[A[ATraining Step: 36  | total loss: [1m[32m0.69302[0m[0m | time: 1.295s
[2K
| RMSProp | epoch: 003 | loss: 0.69302 - acc: 0.5431 -- iter: 064/534
[A[ATraining Step: 37  | total loss: [1m[32m0.69307[0m[0m | time: 2.236s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5254 -- iter: 096/534
[A[ATraining Step: 38  | total loss: [1m[32m0.69281[0m[0m | time: 3.156s
[2K
| RMSProp | epoch: 003 | loss: 0.69281 - acc: 0.5815 -- iter: 128/534
[A[ATraining Step: 39  | total loss: [1m[32m0.69264[0m[0m | time: 4.131s
[2K
| RMSProp | epoch: 003 | loss: 0.69264 - acc: 0.5958 -- iter: 160/534
[A[ATraining Step: 40  | total loss: [1m[32m0.69263[0m[0m | time: 5.120s
[2K
| RMSProp | epoch: 003 | loss: 0.69263 - acc: 0.5896 -- iter: 192/534
[A[ATraining Step: 41  | total loss: [1m[32m0.69255[0m[0m | time: 6.016s
[2K
| RMSProp | epoch: 003 | loss: 0.69255 - acc: 0.6018 -- iter: 224/534
[A[ATraining Step: 42  | total loss: [1m[32m0.69263[0m[0m | time: 6.901s
[2K
| RMSProp | epoch: 003 | loss: 0.69263 - acc: 0.5835 -- iter: 256/534
[A[ATraining Step: 43  | total loss: [1m[32m0.69264[0m[0m | time: 8.018s
[2K
| RMSProp | epoch: 003 | loss: 0.69264 - acc: 0.5798 -- iter: 288/534
[A[ATraining Step: 44  | total loss: [1m[32m0.69263[0m[0m | time: 9.235s
[2K
| RMSProp | epoch: 003 | loss: 0.69263 - acc: 0.5768 -- iter: 320/534
[A[ATraining Step: 45  | total loss: [1m[32m0.69236[0m[0m | time: 10.262s
[2K
| RMSProp | epoch: 003 | loss: 0.69236 - acc: 0.6009 -- iter: 352/534
[A[ATraining Step: 46  | total loss: [1m[32m0.69220[0m[0m | time: 11.139s
[2K
| RMSProp | epoch: 003 | loss: 0.69220 - acc: 0.6101 -- iter: 384/534
[A[ATraining Step: 47  | total loss: [1m[32m0.69211[0m[0m | time: 12.005s
[2K
| RMSProp | epoch: 003 | loss: 0.69211 - acc: 0.6126 -- iter: 416/534
[A[ATraining Step: 48  | total loss: [1m[32m0.69228[0m[0m | time: 13.070s
[2K
| RMSProp | epoch: 003 | loss: 0.69228 - acc: 0.5945 -- iter: 448/534
[A[ATraining Step: 49  | total loss: [1m[32m0.69221[0m[0m | time: 14.456s
[2K
| RMSProp | epoch: 003 | loss: 0.69221 - acc: 0.5944 -- iter: 480/534
[A[ATraining Step: 50  | total loss: [1m[32m0.69183[0m[0m | time: 15.827s
[2K
| RMSProp | epoch: 003 | loss: 0.69183 - acc: 0.6137 -- iter: 512/534
[A[ATraining Step: 51  | total loss: [1m[32m0.69185[0m[0m | time: 18.561s
[2K
| RMSProp | epoch: 003 | loss: 0.69185 - acc: 0.6059 | val_loss: 0.69152 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 52  | total loss: [1m[32m0.69190[0m[0m | time: 1.086s
[2K
| RMSProp | epoch: 004 | loss: 0.69190 - acc: 0.5994 -- iter: 032/534
[A[ATraining Step: 53  | total loss: [1m[32m0.69219[0m[0m | time: 1.912s
[2K
| RMSProp | epoch: 004 | loss: 0.69219 - acc: 0.5801 -- iter: 064/534
[A[ATraining Step: 54  | total loss: [1m[32m0.69223[0m[0m | time: 2.887s
[2K
| RMSProp | epoch: 004 | loss: 0.69223 - acc: 0.5751 -- iter: 096/534
[A[ATraining Step: 55  | total loss: [1m[32m0.69224[0m[0m | time: 4.319s
[2K
| RMSProp | epoch: 004 | loss: 0.69224 - acc: 0.5708 -- iter: 128/534
[A[ATraining Step: 56  | total loss: [1m[32m0.69192[0m[0m | time: 5.732s
[2K
| RMSProp | epoch: 004 | loss: 0.69192 - acc: 0.5872 -- iter: 160/534
[A[ATraining Step: 57  | total loss: [1m[32m0.69184[0m[0m | time: 7.313s
[2K
| RMSProp | epoch: 004 | loss: 0.69184 - acc: 0.5881 -- iter: 192/534
[A[ATraining Step: 58  | total loss: [1m[32m0.69202[0m[0m | time: 8.528s
[2K
| RMSProp | epoch: 004 | loss: 0.69202 - acc: 0.5761 -- iter: 224/534
[A[ATraining Step: 59  | total loss: [1m[32m0.69174[0m[0m | time: 9.714s
[2K
| RMSProp | epoch: 004 | loss: 0.69174 - acc: 0.5869 -- iter: 256/534
[A[ATraining Step: 60  | total loss: [1m[32m0.69135[0m[0m | time: 10.919s
[2K
| RMSProp | epoch: 004 | loss: 0.69135 - acc: 0.6002 -- iter: 288/534
[A[ATraining Step: 61  | total loss: [1m[32m0.69201[0m[0m | time: 12.287s
[2K
| RMSProp | epoch: 004 | loss: 0.69201 - acc: 0.5708 -- iter: 320/534
[A[ATraining Step: 62  | total loss: [1m[32m0.69172[0m[0m | time: 13.648s
[2K
| RMSProp | epoch: 004 | loss: 0.69172 - acc: 0.5818 -- iter: 352/534
[A[ATraining Step: 63  | total loss: [1m[32m0.69150[0m[0m | time: 15.121s
[2K
| RMSProp | epoch: 004 | loss: 0.69150 - acc: 0.5873 -- iter: 384/534
[A[ATraining Step: 64  | total loss: [1m[32m0.69129[0m[0m | time: 16.267s
[2K
| RMSProp | epoch: 004 | loss: 0.69129 - acc: 0.5920 -- iter: 416/534
[A[ATraining Step: 65  | total loss: [1m[32m0.69096[0m[0m | time: 17.549s
[2K
| RMSProp | epoch: 004 | loss: 0.69096 - acc: 0.5999 -- iter: 448/534
[A[ATraining Step: 66  | total loss: [1m[32m0.69102[0m[0m | time: 18.781s
[2K
| RMSProp | epoch: 004 | loss: 0.69102 - acc: 0.5954 -- iter: 480/534
[A[ATraining Step: 67  | total loss: [1m[32m0.69049[0m[0m | time: 20.054s
[2K
| RMSProp | epoch: 004 | loss: 0.69049 - acc: 0.6102 -- iter: 512/534
[A[ATraining Step: 68  | total loss: [1m[32m0.69018[0m[0m | time: 22.866s
[2K
| RMSProp | epoch: 004 | loss: 0.69018 - acc: 0.6156 | val_loss: 0.68972 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 69  | total loss: [1m[32m0.68965[0m[0m | time: 1.498s
[2K
| RMSProp | epoch: 005 | loss: 0.68965 - acc: 0.6277 -- iter: 032/534
[A[ATraining Step: 70  | total loss: [1m[32m0.68982[0m[0m | time: 2.570s
[2K
| RMSProp | epoch: 005 | loss: 0.68982 - acc: 0.6202 -- iter: 064/534
[A[ATraining Step: 71  | total loss: [1m[32m0.68966[0m[0m | time: 3.334s
[2K
| RMSProp | epoch: 005 | loss: 0.68966 - acc: 0.6207 -- iter: 096/534
[A[ATraining Step: 72  | total loss: [1m[32m0.69086[0m[0m | time: 4.309s
[2K
| RMSProp | epoch: 005 | loss: 0.69086 - acc: 0.5867 -- iter: 128/534
[A[ATraining Step: 73  | total loss: [1m[32m0.69189[0m[0m | time: 5.725s
[2K
| RMSProp | epoch: 005 | loss: 0.69189 - acc: 0.5568 -- iter: 160/534
[A[ATraining Step: 74  | total loss: [1m[32m0.69157[0m[0m | time: 7.168s
[2K
| RMSProp | epoch: 005 | loss: 0.69157 - acc: 0.5643 -- iter: 192/534
[A[ATraining Step: 75  | total loss: [1m[32m0.69201[0m[0m | time: 8.537s
[2K
| RMSProp | epoch: 005 | loss: 0.69201 - acc: 0.5506 -- iter: 224/534
[A[ATraining Step: 76  | total loss: [1m[32m0.69178[0m[0m | time: 9.704s
[2K
| RMSProp | epoch: 005 | loss: 0.69178 - acc: 0.5552 -- iter: 256/534
[A[ATraining Step: 77  | total loss: [1m[32m0.69143[0m[0m | time: 11.045s
[2K
| RMSProp | epoch: 005 | loss: 0.69143 - acc: 0.5626 -- iter: 288/534
[A[ATraining Step: 78  | total loss: [1m[32m0.69050[0m[0m | time: 12.435s
[2K
| RMSProp | epoch: 005 | loss: 0.69050 - acc: 0.5855 -- iter: 320/534
[A[ATraining Step: 79  | total loss: [1m[32m0.69038[0m[0m | time: 13.647s
[2K
| RMSProp | epoch: 005 | loss: 0.69038 - acc: 0.5863 -- iter: 352/534
[A[ATraining Step: 80  | total loss: [1m[32m0.68984[0m[0m | time: 15.011s
[2K
| RMSProp | epoch: 005 | loss: 0.68984 - acc: 0.5967 -- iter: 384/534
[A[ATraining Step: 81  | total loss: [1m[32m0.69094[0m[0m | time: 16.512s
[2K
| RMSProp | epoch: 005 | loss: 0.69094 - acc: 0.5711 -- iter: 416/534
[A[ATraining Step: 82  | total loss: [1m[32m0.69064[0m[0m | time: 18.099s
[2K
| RMSProp | epoch: 005 | loss: 0.69064 - acc: 0.5765 -- iter: 448/534
[A[ATraining Step: 83  | total loss: [1m[32m0.69075[0m[0m | time: 19.329s
[2K
| RMSProp | epoch: 005 | loss: 0.69075 - acc: 0.5720 -- iter: 480/534
[A[ATraining Step: 84  | total loss: [1m[32m0.69041[0m[0m | time: 20.597s
[2K
| RMSProp | epoch: 005 | loss: 0.69041 - acc: 0.5773 -- iter: 512/534
[A[ATraining Step: 85  | total loss: [1m[32m0.69072[0m[0m | time: 23.323s
[2K
| RMSProp | epoch: 005 | loss: 0.69072 - acc: 0.5695 | val_loss: 0.68873 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 86  | total loss: [1m[32m0.69067[0m[0m | time: 1.190s
[2K
| RMSProp | epoch: 006 | loss: 0.69067 - acc: 0.5688 -- iter: 032/534
[A[ATraining Step: 87  | total loss: [1m[32m0.69018[0m[0m | time: 2.378s
[2K
| RMSProp | epoch: 006 | loss: 0.69018 - acc: 0.5776 -- iter: 064/534
[A[ATraining Step: 88  | total loss: [1m[32m0.68984[0m[0m | time: 3.558s
[2K
| RMSProp | epoch: 006 | loss: 0.68984 - acc: 0.5823 -- iter: 096/534
[A[ATraining Step: 89  | total loss: [1m[32m0.68916[0m[0m | time: 4.468s
[2K
| RMSProp | epoch: 006 | loss: 0.68916 - acc: 0.5928 -- iter: 128/534
[A[ATraining Step: 90  | total loss: [1m[32m0.68880[0m[0m | time: 5.375s
[2K
| RMSProp | epoch: 006 | loss: 0.68880 - acc: 0.5972 -- iter: 160/534
[A[ATraining Step: 91  | total loss: [1m[32m0.68845[0m[0m | time: 6.622s
[2K
| RMSProp | epoch: 006 | loss: 0.68845 - acc: 0.6011 -- iter: 192/534
[A[ATraining Step: 92  | total loss: [1m[32m0.68875[0m[0m | time: 7.843s
[2K
| RMSProp | epoch: 006 | loss: 0.68875 - acc: 0.5941 -- iter: 224/534
[A[ATraining Step: 93  | total loss: [1m[32m0.68923[0m[0m | time: 9.341s
[2K
| RMSProp | epoch: 006 | loss: 0.68923 - acc: 0.5847 -- iter: 256/534
[A[ATraining Step: 94  | total loss: [1m[32m0.68929[0m[0m | time: 10.635s
[2K
| RMSProp | epoch: 006 | loss: 0.68929 - acc: 0.5825 -- iter: 288/534
[A[ATraining Step: 95  | total loss: [1m[32m0.68931[0m[0m | time: 11.949s
[2K
| RMSProp | epoch: 006 | loss: 0.68931 - acc: 0.5805 -- iter: 320/534
[A[ATraining Step: 96  | total loss: [1m[32m0.68976[0m[0m | time: 13.236s
[2K
| RMSProp | epoch: 006 | loss: 0.68976 - acc: 0.5724 -- iter: 352/534
[A[ATraining Step: 97  | total loss: [1m[32m0.68866[0m[0m | time: 14.575s
[2K
| RMSProp | epoch: 006 | loss: 0.68866 - acc: 0.5871 -- iter: 384/534
[A[ATraining Step: 98  | total loss: [1m[32m0.68804[0m[0m | time: 15.694s
[2K
| RMSProp | epoch: 006 | loss: 0.68804 - acc: 0.5940 -- iter: 416/534
[A[ATraining Step: 99  | total loss: [1m[32m0.68836[0m[0m | time: 16.743s
[2K
| RMSProp | epoch: 006 | loss: 0.68836 - acc: 0.5877 -- iter: 448/534
[A[ATraining Step: 100  | total loss: [1m[32m0.68789[0m[0m | time: 17.894s
[2K
| RMSProp | epoch: 006 | loss: 0.68789 - acc: 0.5914 -- iter: 480/534
[A[ATraining Step: 101  | total loss: [1m[32m0.68824[0m[0m | time: 19.113s
[2K
| RMSProp | epoch: 006 | loss: 0.68824 - acc: 0.5854 -- iter: 512/534
[A[ATraining Step: 102  | total loss: [1m[32m0.68882[0m[0m | time: 21.877s
[2K
| RMSProp | epoch: 006 | loss: 0.68882 - acc: 0.5769 | val_loss: 0.68581 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 103  | total loss: [1m[32m0.68831[0m[0m | time: 1.384s
[2K
| RMSProp | epoch: 007 | loss: 0.68831 - acc: 0.5817 -- iter: 032/534
[A[ATraining Step: 104  | total loss: [1m[32m0.68643[0m[0m | time: 2.801s
[2K
| RMSProp | epoch: 007 | loss: 0.68643 - acc: 0.6016 -- iter: 064/534
[A[ATraining Step: 105  | total loss: [1m[32m0.68659[0m[0m | time: 4.031s
[2K
| RMSProp | epoch: 007 | loss: 0.68659 - acc: 0.5977 -- iter: 096/534
[A[ATraining Step: 106  | total loss: [1m[32m0.68767[0m[0m | time: 5.384s
[2K
| RMSProp | epoch: 007 | loss: 0.68767 - acc: 0.5848 -- iter: 128/534
[A[ATraining Step: 107  | total loss: [1m[32m0.68742[0m[0m | time: 6.398s
[2K
| RMSProp | epoch: 007 | loss: 0.68742 - acc: 0.5857 -- iter: 160/534
[A[ATraining Step: 108  | total loss: [1m[32m0.68582[0m[0m | time: 7.240s
[2K
| RMSProp | epoch: 007 | loss: 0.68582 - acc: 0.5999 -- iter: 192/534
[A[ATraining Step: 109  | total loss: [1m[32m0.68407[0m[0m | time: 8.393s
[2K
| RMSProp | epoch: 007 | loss: 0.68407 - acc: 0.6126 -- iter: 224/534
[A[ATraining Step: 110  | total loss: [1m[32m0.68320[0m[0m | time: 9.701s
[2K
| RMSProp | epoch: 007 | loss: 0.68320 - acc: 0.6170 -- iter: 256/534
[A[ATraining Step: 111  | total loss: [1m[32m0.68395[0m[0m | time: 10.827s
[2K
| RMSProp | epoch: 007 | loss: 0.68395 - acc: 0.6084 -- iter: 288/534
[A[ATraining Step: 112  | total loss: [1m[32m0.68250[0m[0m | time: 12.191s
[2K
| RMSProp | epoch: 007 | loss: 0.68250 - acc: 0.6163 -- iter: 320/534
[A[ATraining Step: 113  | total loss: [1m[32m0.68344[0m[0m | time: 13.421s
[2K
| RMSProp | epoch: 007 | loss: 0.68344 - acc: 0.6078 -- iter: 352/534
[A[ATraining Step: 114  | total loss: [1m[32m0.68525[0m[0m | time: 14.694s
[2K
| RMSProp | epoch: 007 | loss: 0.68525 - acc: 0.5939 -- iter: 384/534
[A[ATraining Step: 115  | total loss: [1m[32m0.68321[0m[0m | time: 16.017s
[2K
| RMSProp | epoch: 007 | loss: 0.68321 - acc: 0.6064 -- iter: 416/534
[A[ATraining Step: 116  | total loss: [1m[32m0.68137[0m[0m | time: 17.015s
[2K
| RMSProp | epoch: 007 | loss: 0.68137 - acc: 0.6145 -- iter: 448/534
[A[ATraining Step: 117  | total loss: [1m[32m0.67866[0m[0m | time: 17.888s
[2K
| RMSProp | epoch: 007 | loss: 0.67866 - acc: 0.6249 -- iter: 480/534
[A[ATraining Step: 118  | total loss: [1m[32m0.67922[0m[0m | time: 18.929s
[2K
| RMSProp | epoch: 007 | loss: 0.67922 - acc: 0.6187 -- iter: 512/534
[A[ATraining Step: 119  | total loss: [1m[32m0.67928[0m[0m | time: 21.246s
[2K
| RMSProp | epoch: 007 | loss: 0.67928 - acc: 0.6162 | val_loss: 0.68007 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 120  | total loss: [1m[32m0.68497[0m[0m | time: 0.858s
[2K
| RMSProp | epoch: 008 | loss: 0.68497 - acc: 0.5921 -- iter: 032/534
[A[ATraining Step: 121  | total loss: [1m[32m0.68333[0m[0m | time: 1.728s
[2K
| RMSProp | epoch: 008 | loss: 0.68333 - acc: 0.5985 -- iter: 064/534
[A[ATraining Step: 122  | total loss: [1m[32m0.68159[0m[0m | time: 2.634s
[2K
| RMSProp | epoch: 008 | loss: 0.68159 - acc: 0.6043 -- iter: 096/534
[A[ATraining Step: 123  | total loss: [1m[32m0.68190[0m[0m | time: 3.519s
[2K
| RMSProp | epoch: 008 | loss: 0.68190 - acc: 0.6001 -- iter: 128/534
[A[ATraining Step: 124  | total loss: [1m[32m0.68211[0m[0m | time: 4.466s
[2K
| RMSProp | epoch: 008 | loss: 0.68211 - acc: 0.5963 -- iter: 160/534
[A[ATraining Step: 125  | total loss: [1m[32m0.68241[0m[0m | time: 5.122s
[2K
| RMSProp | epoch: 008 | loss: 0.68241 - acc: 0.5929 -- iter: 192/534
[A[ATraining Step: 126  | total loss: [1m[32m0.68300[0m[0m | time: 5.782s
[2K
| RMSProp | epoch: 008 | loss: 0.68300 - acc: 0.5882 -- iter: 224/534
[A[ATraining Step: 127  | total loss: [1m[32m0.68364[0m[0m | time: 6.662s
[2K
| RMSProp | epoch: 008 | loss: 0.68364 - acc: 0.5839 -- iter: 256/534
[A[ATraining Step: 128  | total loss: [1m[32m0.68157[0m[0m | time: 7.730s
[2K
| RMSProp | epoch: 008 | loss: 0.68157 - acc: 0.5912 -- iter: 288/534
[A[ATraining Step: 129  | total loss: [1m[32m0.68287[0m[0m | time: 8.911s
[2K
| RMSProp | epoch: 008 | loss: 0.68287 - acc: 0.5852 -- iter: 320/534
[A[ATraining Step: 130  | total loss: [1m[32m0.67983[0m[0m | time: 10.191s
[2K
| RMSProp | epoch: 008 | loss: 0.67983 - acc: 0.5954 -- iter: 352/534
[A[ATraining Step: 131  | total loss: [1m[32m0.67815[0m[0m | time: 11.023s
[2K
| RMSProp | epoch: 008 | loss: 0.67815 - acc: 0.5984 -- iter: 384/534
[A[ATraining Step: 132  | total loss: [1m[32m0.67370[0m[0m | time: 11.885s
[2K
| RMSProp | epoch: 008 | loss: 0.67370 - acc: 0.6073 -- iter: 416/534
[A[ATraining Step: 133  | total loss: [1m[32m0.67932[0m[0m | time: 12.833s
[2K
| RMSProp | epoch: 008 | loss: 0.67932 - acc: 0.5997 -- iter: 448/534
[A[ATraining Step: 134  | total loss: [1m[32m0.68444[0m[0m | time: 13.698s
[2K
| RMSProp | epoch: 008 | loss: 0.68444 - acc: 0.5803 -- iter: 480/534
[A[ATraining Step: 135  | total loss: [1m[32m0.68224[0m[0m | time: 14.617s
[2K
| RMSProp | epoch: 008 | loss: 0.68224 - acc: 0.5910 -- iter: 512/534
[A[ATraining Step: 136  | total loss: [1m[32m0.68100[0m[0m | time: 16.597s
[2K
| RMSProp | epoch: 008 | loss: 0.68100 - acc: 0.5944 | val_loss: 0.67503 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 137  | total loss: [1m[32m0.67815[0m[0m | time: 0.918s
[2K
| RMSProp | epoch: 009 | loss: 0.67815 - acc: 0.6037 -- iter: 032/534
[A[ATraining Step: 138  | total loss: [1m[32m0.68261[0m[0m | time: 2.440s
[2K
| RMSProp | epoch: 009 | loss: 0.68261 - acc: 0.5902 -- iter: 064/534
[A[ATraining Step: 139  | total loss: [1m[32m0.68221[0m[0m | time: 4.037s
[2K
| RMSProp | epoch: 009 | loss: 0.68221 - acc: 0.5906 -- iter: 096/534
[A[ATraining Step: 140  | total loss: [1m[32m0.68029[0m[0m | time: 5.503s
[2K
| RMSProp | epoch: 009 | loss: 0.68029 - acc: 0.5972 -- iter: 128/534
[A[ATraining Step: 141  | total loss: [1m[32m0.68369[0m[0m | time: 10.058s
[2K
| RMSProp | epoch: 009 | loss: 0.68369 - acc: 0.5843 -- iter: 160/534
[A[ATraining Step: 142  | total loss: [1m[32m0.68390[0m[0m | time: 16.040s
[2K
| RMSProp | epoch: 009 | loss: 0.68390 - acc: 0.5821 -- iter: 192/534
[A[ATraining Step: 143  | total loss: [1m[32m0.68335[0m[0m | time: 24.935s
[2K
| RMSProp | epoch: 009 | loss: 0.68335 - acc: 0.5833 -- iter: 224/534
[A[ATraining Step: 144  | total loss: [1m[32m0.68179[0m[0m | time: 25.591s
[2K
| RMSProp | epoch: 009 | loss: 0.68179 - acc: 0.5886 -- iter: 256/534
[A[ATraining Step: 145  | total loss: [1m[32m0.67997[0m[0m | time: 26.704s
[2K
| RMSProp | epoch: 009 | loss: 0.67997 - acc: 0.5934 -- iter: 288/534
[A[ATraining Step: 146  | total loss: [1m[32m0.67734[0m[0m | time: 27.880s
[2K
| RMSProp | epoch: 009 | loss: 0.67734 - acc: 0.5997 -- iter: 320/534
[A[ATraining Step: 147  | total loss: [1m[32m0.68056[0m[0m | time: 29.083s
[2K
| RMSProp | epoch: 009 | loss: 0.68056 - acc: 0.5928 -- iter: 352/534
[A[ATraining Step: 148  | total loss: [1m[32m0.67991[0m[0m | time: 30.361s
[2K
| RMSProp | epoch: 009 | loss: 0.67991 - acc: 0.5929 -- iter: 384/534
[A[ATraining Step: 149  | total loss: [1m[32m0.67766[0m[0m | time: 31.599s
[2K
| RMSProp | epoch: 009 | loss: 0.67766 - acc: 0.5993 -- iter: 416/534
[A[ATraining Step: 150  | total loss: [1m[32m0.67750[0m[0m | time: 32.971s
[2K
| RMSProp | epoch: 009 | loss: 0.67750 - acc: 0.5987 -- iter: 448/534
[A[ATraining Step: 151  | total loss: [1m[32m0.67029[0m[0m | time: 34.219s
[2K
| RMSProp | epoch: 009 | loss: 0.67029 - acc: 0.6170 -- iter: 480/534
[A[ATraining Step: 152  | total loss: [1m[32m0.66845[0m[0m | time: 35.426s
[2K
| RMSProp | epoch: 009 | loss: 0.66845 - acc: 0.6209 -- iter: 512/534
[A[ATraining Step: 153  | total loss: [1m[32m0.67405[0m[0m | time: 38.378s
[2K
| RMSProp | epoch: 009 | loss: 0.67405 - acc: 0.6088 | val_loss: 0.67852 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 154  | total loss: [1m[32m0.67769[0m[0m | time: 1.394s
[2K
| RMSProp | epoch: 010 | loss: 0.67769 - acc: 0.5948 -- iter: 032/534
[A[ATraining Step: 155  | total loss: [1m[32m0.67713[0m[0m | time: 2.642s
[2K
| RMSProp | epoch: 010 | loss: 0.67713 - acc: 0.5978 -- iter: 064/534
[A[ATraining Step: 156  | total loss: [1m[32m0.68106[0m[0m | time: 3.917s
[2K
| RMSProp | epoch: 010 | loss: 0.68106 - acc: 0.5818 -- iter: 096/534
[A[ATraining Step: 157  | total loss: [1m[32m0.68091[0m[0m | time: 5.121s
[2K
| RMSProp | epoch: 010 | loss: 0.68091 - acc: 0.5830 -- iter: 128/534
[A[ATraining Step: 158  | total loss: [1m[32m0.67935[0m[0m | time: 6.323s
[2K
| RMSProp | epoch: 010 | loss: 0.67935 - acc: 0.5903 -- iter: 160/534
[A[ATraining Step: 159  | total loss: [1m[32m0.67752[0m[0m | time: 7.643s
[2K
| RMSProp | epoch: 010 | loss: 0.67752 - acc: 0.5969 -- iter: 192/534
[A[ATraining Step: 160  | total loss: [1m[32m0.67820[0m[0m | time: 9.005s
[2K
| RMSProp | epoch: 010 | loss: 0.67820 - acc: 0.5935 -- iter: 224/534
[A[ATraining Step: 161  | total loss: [1m[32m0.67796[0m[0m | time: 9.912s
[2K
| RMSProp | epoch: 010 | loss: 0.67796 - acc: 0.5935 -- iter: 256/534
[A[ATraining Step: 162  | total loss: [1m[32m0.67495[0m[0m | time: 10.795s
[2K
| RMSProp | epoch: 010 | loss: 0.67495 - acc: 0.6023 -- iter: 288/534
[A[ATraining Step: 163  | total loss: [1m[32m0.67059[0m[0m | time: 11.908s
[2K
| RMSProp | epoch: 010 | loss: 0.67059 - acc: 0.6103 -- iter: 320/534
[A[ATraining Step: 164  | total loss: [1m[32m0.67086[0m[0m | time: 13.374s
[2K
| RMSProp | epoch: 010 | loss: 0.67086 - acc: 0.6117 -- iter: 352/534
[A[ATraining Step: 165  | total loss: [1m[32m0.67730[0m[0m | time: 14.924s
[2K
| RMSProp | epoch: 010 | loss: 0.67730 - acc: 0.5943 -- iter: 384/534
[A[ATraining Step: 166  | total loss: [1m[32m0.67346[0m[0m | time: 16.356s
[2K
| RMSProp | epoch: 010 | loss: 0.67346 - acc: 0.6130 -- iter: 416/534
[A[ATraining Step: 167  | total loss: [1m[32m0.67470[0m[0m | time: 17.697s
[2K
| RMSProp | epoch: 010 | loss: 0.67470 - acc: 0.6080 -- iter: 448/534
[A[ATraining Step: 168  | total loss: [1m[32m0.67017[0m[0m | time: 19.035s
[2K
| RMSProp | epoch: 010 | loss: 0.67017 - acc: 0.6222 -- iter: 480/534
[A[ATraining Step: 169  | total loss: [1m[32m0.67080[0m[0m | time: 20.538s
[2K
| RMSProp | epoch: 010 | loss: 0.67080 - acc: 0.6193 -- iter: 512/534
[A[ATraining Step: 170  | total loss: [1m[32m0.67519[0m[0m | time: 22.703s
[2K
| RMSProp | epoch: 010 | loss: 0.67519 - acc: 0.6074 | val_loss: 0.67701 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 171  | total loss: [1m[32m0.67710[0m[0m | time: 1.165s
[2K
| RMSProp | epoch: 011 | loss: 0.67710 - acc: 0.5998 -- iter: 032/534
[A[ATraining Step: 172  | total loss: [1m[32m0.67790[0m[0m | time: 2.477s
[2K
| RMSProp | epoch: 011 | loss: 0.67790 - acc: 0.5960 -- iter: 064/534
[A[ATraining Step: 173  | total loss: [1m[32m0.67538[0m[0m | time: 3.676s
[2K
| RMSProp | epoch: 011 | loss: 0.67538 - acc: 0.6052 -- iter: 096/534
[A[ATraining Step: 174  | total loss: [1m[32m0.67249[0m[0m | time: 4.895s
[2K
| RMSProp | epoch: 011 | loss: 0.67249 - acc: 0.6134 -- iter: 128/534
[A[ATraining Step: 175  | total loss: [1m[32m0.67146[0m[0m | time: 6.112s
[2K
| RMSProp | epoch: 011 | loss: 0.67146 - acc: 0.6146 -- iter: 160/534
[A[ATraining Step: 176  | total loss: [1m[32m0.67686[0m[0m | time: 7.467s
[2K
| RMSProp | epoch: 011 | loss: 0.67686 - acc: 0.6031 -- iter: 192/534
[A[ATraining Step: 177  | total loss: [1m[32m0.67691[0m[0m | time: 8.907s
[2K
| RMSProp | epoch: 011 | loss: 0.67691 - acc: 0.6022 -- iter: 224/534
[A[ATraining Step: 178  | total loss: [1m[32m0.68225[0m[0m | time: 10.322s
[2K
| RMSProp | epoch: 011 | loss: 0.68225 - acc: 0.5826 -- iter: 256/534
[A[ATraining Step: 179  | total loss: [1m[32m0.68066[0m[0m | time: 11.057s
[2K
| RMSProp | epoch: 011 | loss: 0.68066 - acc: 0.5900 -- iter: 288/534
[A[ATraining Step: 180  | total loss: [1m[32m0.68372[0m[0m | time: 11.994s
[2K
| RMSProp | epoch: 011 | loss: 0.68372 - acc: 0.5764 -- iter: 320/534
[A[ATraining Step: 181  | total loss: [1m[32m0.68613[0m[0m | time: 13.431s
[2K
| RMSProp | epoch: 011 | loss: 0.68613 - acc: 0.5642 -- iter: 352/534
[A[ATraining Step: 182  | total loss: [1m[32m0.68555[0m[0m | time: 14.993s
[2K
| RMSProp | epoch: 011 | loss: 0.68555 - acc: 0.5672 -- iter: 384/534
[A[ATraining Step: 183  | total loss: [1m[32m0.68563[0m[0m | time: 16.245s
[2K
| RMSProp | epoch: 011 | loss: 0.68563 - acc: 0.5667 -- iter: 416/534
[A[ATraining Step: 184  | total loss: [1m[32m0.68504[0m[0m | time: 17.552s
[2K
| RMSProp | epoch: 011 | loss: 0.68504 - acc: 0.5694 -- iter: 448/534
[A[ATraining Step: 185  | total loss: [1m[32m0.68709[0m[0m | time: 18.974s
[2K
| RMSProp | epoch: 011 | loss: 0.68709 - acc: 0.5594 -- iter: 480/534
[A[ATraining Step: 186  | total loss: [1m[32m0.68694[0m[0m | time: 20.253s
[2K
| RMSProp | epoch: 011 | loss: 0.68694 - acc: 0.5597 -- iter: 512/534
[A[ATraining Step: 187  | total loss: [1m[32m0.68506[0m[0m | time: 22.599s
[2K
| RMSProp | epoch: 011 | loss: 0.68506 - acc: 0.5693 | val_loss: 0.67631 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 188  | total loss: [1m[32m0.68226[0m[0m | time: 1.516s
[2K
| RMSProp | epoch: 012 | loss: 0.68226 - acc: 0.5811 -- iter: 032/534
[A[ATraining Step: 189  | total loss: [1m[32m0.67901[0m[0m | time: 3.008s
[2K
| RMSProp | epoch: 012 | loss: 0.67901 - acc: 0.5918 -- iter: 064/534
[A[ATraining Step: 190  | total loss: [1m[32m0.68131[0m[0m | time: 4.158s
[2K
| RMSProp | epoch: 012 | loss: 0.68131 - acc: 0.5857 -- iter: 096/534
[A[ATraining Step: 191  | total loss: [1m[32m0.67910[0m[0m | time: 5.255s
[2K
| RMSProp | epoch: 012 | loss: 0.67910 - acc: 0.5928 -- iter: 128/534
[A[ATraining Step: 192  | total loss: [1m[32m0.68429[0m[0m | time: 6.731s
[2K
| RMSProp | epoch: 012 | loss: 0.68429 - acc: 0.5772 -- iter: 160/534
[A[ATraining Step: 193  | total loss: [1m[32m0.68585[0m[0m | time: 8.090s
[2K
| RMSProp | epoch: 012 | loss: 0.68585 - acc: 0.5695 -- iter: 192/534
[A[ATraining Step: 194  | total loss: [1m[32m0.68200[0m[0m | time: 9.538s
[2K
| RMSProp | epoch: 012 | loss: 0.68200 - acc: 0.5876 -- iter: 224/534
[A[ATraining Step: 195  | total loss: [1m[32m0.68305[0m[0m | time: 10.765s
[2K
| RMSProp | epoch: 012 | loss: 0.68305 - acc: 0.5819 -- iter: 256/534
[A[ATraining Step: 196  | total loss: [1m[32m0.68168[0m[0m | time: 11.973s
[2K
| RMSProp | epoch: 012 | loss: 0.68168 - acc: 0.5862 -- iter: 288/534
[A[ATraining Step: 197  | total loss: [1m[32m0.67943[0m[0m | time: 13.027s
[2K
| RMSProp | epoch: 012 | loss: 0.67943 - acc: 0.5932 -- iter: 320/534
[A[ATraining Step: 198  | total loss: [1m[32m0.68218[0m[0m | time: 13.950s
[2K
| RMSProp | epoch: 012 | loss: 0.68218 - acc: 0.5839 -- iter: 352/534
[A[ATraining Step: 199  | total loss: [1m[32m0.68406[0m[0m | time: 15.215s
[2K
| RMSProp | epoch: 012 | loss: 0.68406 - acc: 0.5755 -- iter: 384/534
[A[ATraining Step: 200  | total loss: [1m[32m0.68635[0m[0m | time: 17.925s
[2K
| RMSProp | epoch: 012 | loss: 0.68635 - acc: 0.5649 | val_loss: 0.67687 - val_acc: 0.5952 -- iter: 416/534
--
Training Step: 201  | total loss: [1m[32m0.68252[0m[0m | time: 18.993s
[2K
| RMSProp | epoch: 012 | loss: 0.68252 - acc: 0.5834 -- iter: 448/534
[A[ATraining Step: 202  | total loss: [1m[32m0.68207[0m[0m | time: 20.270s
[2K
| RMSProp | epoch: 012 | loss: 0.68207 - acc: 0.5844 -- iter: 480/534
[A[ATraining Step: 203  | total loss: [1m[32m0.67985[0m[0m | time: 21.371s
[2K
| RMSProp | epoch: 012 | loss: 0.67985 - acc: 0.5916 -- iter: 512/534
[A[ATraining Step: 204  | total loss: [1m[32m0.67936[0m[0m | time: 24.068s
[2K
| RMSProp | epoch: 012 | loss: 0.67936 - acc: 0.5918 | val_loss: 0.67551 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 205  | total loss: [1m[32m0.68015[0m[0m | time: 1.461s
[2K
| RMSProp | epoch: 013 | loss: 0.68015 - acc: 0.5889 -- iter: 032/534
[A[ATraining Step: 206  | total loss: [1m[32m0.67593[0m[0m | time: 2.697s
[2K
| RMSProp | epoch: 013 | loss: 0.67593 - acc: 0.6019 -- iter: 064/534
[A[ATraining Step: 207  | total loss: [1m[32m0.68097[0m[0m | time: 3.856s
[2K
| RMSProp | epoch: 013 | loss: 0.68097 - acc: 0.5917 -- iter: 096/534
[A[ATraining Step: 208  | total loss: [1m[32m0.67973[0m[0m | time: 5.045s
[2K
| RMSProp | epoch: 013 | loss: 0.67973 - acc: 0.5950 -- iter: 128/534
[A[ATraining Step: 209  | total loss: [1m[32m0.67670[0m[0m | time: 6.330s
[2K
| RMSProp | epoch: 013 | loss: 0.67670 - acc: 0.6043 -- iter: 160/534
[A[ATraining Step: 210  | total loss: [1m[32m0.67094[0m[0m | time: 7.295s
[2K
| RMSProp | epoch: 013 | loss: 0.67094 - acc: 0.6188 -- iter: 192/534
[A[ATraining Step: 211  | total loss: [1m[32m0.67370[0m[0m | time: 8.210s
[2K
| RMSProp | epoch: 013 | loss: 0.67370 - acc: 0.6132 -- iter: 224/534
[A[ATraining Step: 212  | total loss: [1m[32m0.67868[0m[0m | time: 9.192s
[2K
| RMSProp | epoch: 013 | loss: 0.67868 - acc: 0.5988 -- iter: 256/534
[A[ATraining Step: 213  | total loss: [1m[32m0.68181[0m[0m | time: 10.117s
[2K
| RMSProp | epoch: 013 | loss: 0.68181 - acc: 0.5858 -- iter: 288/534
[A[ATraining Step: 214  | total loss: [1m[32m0.68007[0m[0m | time: 11.006s
[2K
| RMSProp | epoch: 013 | loss: 0.68007 - acc: 0.5928 -- iter: 320/534
[A[ATraining Step: 215  | total loss: [1m[32m0.67716[0m[0m | time: 11.735s
[2K
| RMSProp | epoch: 013 | loss: 0.67716 - acc: 0.6023 -- iter: 352/534
[A[ATraining Step: 216  | total loss: [1m[32m0.68842[0m[0m | time: 12.564s
[2K
| RMSProp | epoch: 013 | loss: 0.68842 - acc: 0.5693 -- iter: 384/534
[A[ATraining Step: 217  | total loss: [1m[32m0.69448[0m[0m | time: 13.837s
[2K
| RMSProp | epoch: 013 | loss: 0.69448 - acc: 0.5397 -- iter: 416/534
[A[ATraining Step: 218  | total loss: [1m[32m0.69416[0m[0m | time: 14.942s
[2K
| RMSProp | epoch: 013 | loss: 0.69416 - acc: 0.5388 -- iter: 448/534
[A[ATraining Step: 219  | total loss: [1m[32m0.69100[0m[0m | time: 15.778s
[2K
| RMSProp | epoch: 013 | loss: 0.69100 - acc: 0.5537 -- iter: 480/534
[A[ATraining Step: 220  | total loss: [1m[32m0.69045[0m[0m | time: 16.620s
[2K
| RMSProp | epoch: 013 | loss: 0.69045 - acc: 0.5546 -- iter: 512/534
[A[ATraining Step: 221  | total loss: [1m[32m0.68862[0m[0m | time: 18.535s
[2K
| RMSProp | epoch: 013 | loss: 0.68862 - acc: 0.5616 | val_loss: 0.67769 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 222  | total loss: [1m[32m0.68690[0m[0m | time: 0.881s
[2K
| RMSProp | epoch: 014 | loss: 0.68690 - acc: 0.5679 -- iter: 032/534
[A[ATraining Step: 223  | total loss: [1m[32m0.68816[0m[0m | time: 1.823s
[2K
| RMSProp | epoch: 014 | loss: 0.68816 - acc: 0.5612 -- iter: 064/534
[A[ATraining Step: 224  | total loss: [1m[32m0.68781[0m[0m | time: 2.725s
[2K
| RMSProp | epoch: 014 | loss: 0.68781 - acc: 0.5613 -- iter: 096/534
[A[ATraining Step: 225  | total loss: [1m[32m0.69186[0m[0m | time: 3.578s
[2K
| RMSProp | epoch: 014 | loss: 0.69186 - acc: 0.5427 -- iter: 128/534
[A[ATraining Step: 226  | total loss: [1m[32m0.68946[0m[0m | time: 4.513s
[2K
| RMSProp | epoch: 014 | loss: 0.68946 - acc: 0.5540 -- iter: 160/534
[A[ATraining Step: 227  | total loss: [1m[32m0.69223[0m[0m | time: 5.780s
[2K
| RMSProp | epoch: 014 | loss: 0.69223 - acc: 0.5392 -- iter: 192/534
[A[ATraining Step: 228  | total loss: [1m[32m0.68759[0m[0m | time: 6.989s
[2K
| RMSProp | epoch: 014 | loss: 0.68759 - acc: 0.5634 -- iter: 224/534
[A[ATraining Step: 229  | total loss: [1m[32m0.68416[0m[0m | time: 7.811s
[2K
| RMSProp | epoch: 014 | loss: 0.68416 - acc: 0.5790 -- iter: 256/534
[A[ATraining Step: 230  | total loss: [1m[32m0.68264[0m[0m | time: 8.680s
[2K
| RMSProp | epoch: 014 | loss: 0.68264 - acc: 0.5836 -- iter: 288/534
[A[ATraining Step: 231  | total loss: [1m[32m0.68369[0m[0m | time: 9.547s
[2K
| RMSProp | epoch: 014 | loss: 0.68369 - acc: 0.5783 -- iter: 320/534
[A[ATraining Step: 232  | total loss: [1m[32m0.68082[0m[0m | time: 10.411s
[2K
| RMSProp | epoch: 014 | loss: 0.68082 - acc: 0.5893 -- iter: 352/534
[A[ATraining Step: 233  | total loss: [1m[32m0.68120[0m[0m | time: 11.054s
[2K
| RMSProp | epoch: 014 | loss: 0.68120 - acc: 0.5866 -- iter: 384/534
[A[ATraining Step: 234  | total loss: [1m[32m0.68338[0m[0m | time: 11.759s
[2K
| RMSProp | epoch: 014 | loss: 0.68338 - acc: 0.5779 -- iter: 416/534
[A[ATraining Step: 235  | total loss: [1m[32m0.68505[0m[0m | time: 12.754s
[2K
| RMSProp | epoch: 014 | loss: 0.68505 - acc: 0.5701 -- iter: 448/534
[A[ATraining Step: 236  | total loss: [1m[32m0.68516[0m[0m | time: 14.045s
[2K
| RMSProp | epoch: 014 | loss: 0.68516 - acc: 0.5694 -- iter: 480/534
[A[ATraining Step: 237  | total loss: [1m[32m0.68077[0m[0m | time: 15.498s
[2K
| RMSProp | epoch: 014 | loss: 0.68077 - acc: 0.5874 -- iter: 512/534
[A[ATraining Step: 238  | total loss: [1m[32m0.67846[0m[0m | time: 17.980s
[2K
| RMSProp | epoch: 014 | loss: 0.67846 - acc: 0.5943 | val_loss: 0.67683 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 239  | total loss: [1m[32m0.68239[0m[0m | time: 1.396s
[2K
| RMSProp | epoch: 015 | loss: 0.68239 - acc: 0.5818 -- iter: 032/534
[A[ATraining Step: 240  | total loss: [1m[32m0.68027[0m[0m | time: 2.626s
[2K
| RMSProp | epoch: 015 | loss: 0.68027 - acc: 0.5892 -- iter: 064/534
[A[ATraining Step: 241  | total loss: [1m[32m0.68340[0m[0m | time: 3.774s
[2K
| RMSProp | epoch: 015 | loss: 0.68340 - acc: 0.5772 -- iter: 096/534
[A[ATraining Step: 242  | total loss: [1m[32m0.68036[0m[0m | time: 5.022s
[2K
| RMSProp | epoch: 015 | loss: 0.68036 - acc: 0.5882 -- iter: 128/534
[A[ATraining Step: 243  | total loss: [1m[32m0.68191[0m[0m | time: 6.120s
[2K
| RMSProp | epoch: 015 | loss: 0.68191 - acc: 0.5825 -- iter: 160/534
[A[ATraining Step: 244  | total loss: [1m[32m0.68549[0m[0m | time: 7.549s
[2K
| RMSProp | epoch: 015 | loss: 0.68549 - acc: 0.5680 -- iter: 192/534
[A[ATraining Step: 245  | total loss: [1m[32m0.68324[0m[0m | time: 8.965s
[2K
| RMSProp | epoch: 015 | loss: 0.68324 - acc: 0.5768 -- iter: 224/534
[A[ATraining Step: 246  | total loss: [1m[32m0.68425[0m[0m | time: 10.452s
[2K
| RMSProp | epoch: 015 | loss: 0.68425 - acc: 0.5723 -- iter: 256/534
[A[ATraining Step: 247  | total loss: [1m[32m0.67738[0m[0m | time: 11.643s
[2K
| RMSProp | epoch: 015 | loss: 0.67738 - acc: 0.5994 -- iter: 288/534
[A[ATraining Step: 248  | total loss: [1m[32m0.67912[0m[0m | time: 12.936s
[2K
| RMSProp | epoch: 015 | loss: 0.67912 - acc: 0.5926 -- iter: 320/534
[A[ATraining Step: 249  | total loss: [1m[32m0.67619[0m[0m | time: 14.114s
[2K
| RMSProp | epoch: 015 | loss: 0.67619 - acc: 0.6021 -- iter: 352/534
[A[ATraining Step: 250  | total loss: [1m[32m0.67504[0m[0m | time: 15.518s
[2K
| RMSProp | epoch: 015 | loss: 0.67504 - acc: 0.6044 -- iter: 384/534
[A[ATraining Step: 251  | total loss: [1m[32m0.67503[0m[0m | time: 16.524s
[2K
| RMSProp | epoch: 015 | loss: 0.67503 - acc: 0.6033 -- iter: 416/534
[A[ATraining Step: 252  | total loss: [1m[32m0.67357[0m[0m | time: 17.679s
[2K
| RMSProp | epoch: 015 | loss: 0.67357 - acc: 0.6066 -- iter: 448/534
[A[ATraining Step: 253  | total loss: [1m[32m0.67175[0m[0m | time: 19.227s
[2K
| RMSProp | epoch: 015 | loss: 0.67175 - acc: 0.6096 -- iter: 480/534
[A[ATraining Step: 254  | total loss: [1m[32m0.67774[0m[0m | time: 20.513s
[2K
| RMSProp | epoch: 015 | loss: 0.67774 - acc: 0.5986 -- iter: 512/534
[A[ATraining Step: 255  | total loss: [1m[32m0.67766[0m[0m | time: 22.915s
[2K
| RMSProp | epoch: 015 | loss: 0.67766 - acc: 0.5981 | val_loss: 0.67503 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 256  | total loss: [1m[32m0.67556[0m[0m | time: 1.477s
[2K
| RMSProp | epoch: 016 | loss: 0.67556 - acc: 0.6040 -- iter: 032/534
[A[ATraining Step: 257  | total loss: [1m[32m0.67543[0m[0m | time: 2.904s
[2K
| RMSProp | epoch: 016 | loss: 0.67543 - acc: 0.6029 -- iter: 064/534
[A[ATraining Step: 258  | total loss: [1m[32m0.68082[0m[0m | time: 4.010s
[2K
| RMSProp | epoch: 016 | loss: 0.68082 - acc: 0.5864 -- iter: 096/534
[A[ATraining Step: 259  | total loss: [1m[32m0.68045[0m[0m | time: 5.200s
[2K
| RMSProp | epoch: 016 | loss: 0.68045 - acc: 0.5871 -- iter: 128/534
[A[ATraining Step: 260  | total loss: [1m[32m0.68461[0m[0m | time: 6.468s
[2K
| RMSProp | epoch: 016 | loss: 0.68461 - acc: 0.5722 -- iter: 160/534
[A[ATraining Step: 261  | total loss: [1m[32m0.68547[0m[0m | time: 7.736s
[2K
| RMSProp | epoch: 016 | loss: 0.68547 - acc: 0.5681 -- iter: 192/534
[A[ATraining Step: 262  | total loss: [1m[32m0.68554[0m[0m | time: 8.966s
[2K
| RMSProp | epoch: 016 | loss: 0.68554 - acc: 0.5675 -- iter: 224/534
[A[ATraining Step: 263  | total loss: [1m[32m0.68267[0m[0m | time: 10.322s
[2K
| RMSProp | epoch: 016 | loss: 0.68267 - acc: 0.5795 -- iter: 256/534
[A[ATraining Step: 264  | total loss: [1m[32m0.68119[0m[0m | time: 11.895s
[2K
| RMSProp | epoch: 016 | loss: 0.68119 - acc: 0.5841 -- iter: 288/534
[A[ATraining Step: 265  | total loss: [1m[32m0.67885[0m[0m | time: 13.514s
[2K
| RMSProp | epoch: 016 | loss: 0.67885 - acc: 0.5913 -- iter: 320/534
[A[ATraining Step: 266  | total loss: [1m[32m0.67758[0m[0m | time: 14.605s
[2K
| RMSProp | epoch: 016 | loss: 0.67758 - acc: 0.5947 -- iter: 352/534
[A[ATraining Step: 267  | total loss: [1m[32m0.67831[0m[0m | time: 16.004s
[2K
| RMSProp | epoch: 016 | loss: 0.67831 - acc: 0.5914 -- iter: 384/534
[A[ATraining Step: 268  | total loss: [1m[32m0.67691[0m[0m | time: 17.292s
[2K
| RMSProp | epoch: 016 | loss: 0.67691 - acc: 0.5948 -- iter: 416/534
[A[ATraining Step: 269  | total loss: [1m[32m0.67559[0m[0m | time: 18.237s
[2K
| RMSProp | epoch: 016 | loss: 0.67559 - acc: 0.5978 -- iter: 448/534
[A[ATraining Step: 270  | total loss: [1m[32m0.67002[0m[0m | time: 19.278s
[2K
| RMSProp | epoch: 016 | loss: 0.67002 - acc: 0.6108 -- iter: 480/534
[A[ATraining Step: 271  | total loss: [1m[32m0.66260[0m[0m | time: 20.483s
[2K
| RMSProp | epoch: 016 | loss: 0.66260 - acc: 0.6224 -- iter: 512/534
[A[ATraining Step: 272  | total loss: [1m[32m0.67973[0m[0m | time: 22.903s
[2K
| RMSProp | epoch: 016 | loss: 0.67973 - acc: 0.6133 | val_loss: 0.67509 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 273  | total loss: [1m[32m0.67941[0m[0m | time: 1.402s
[2K
| RMSProp | epoch: 017 | loss: 0.67941 - acc: 0.6113 -- iter: 032/534
[A[ATraining Step: 274  | total loss: [1m[32m0.68051[0m[0m | time: 2.575s
[2K
| RMSProp | epoch: 017 | loss: 0.68051 - acc: 0.6065 -- iter: 064/534
[A[ATraining Step: 275  | total loss: [1m[32m0.67737[0m[0m | time: 4.039s
[2K
| RMSProp | epoch: 017 | loss: 0.67737 - acc: 0.6114 -- iter: 096/534
[A[ATraining Step: 276  | total loss: [1m[32m0.67997[0m[0m | time: 5.326s
[2K
| RMSProp | epoch: 017 | loss: 0.67997 - acc: 0.6034 -- iter: 128/534
[A[ATraining Step: 277  | total loss: [1m[32m0.67721[0m[0m | time: 6.690s
[2K
| RMSProp | epoch: 017 | loss: 0.67721 - acc: 0.6087 -- iter: 160/534
[A[ATraining Step: 278  | total loss: [1m[32m0.67571[0m[0m | time: 8.291s
[2K
| RMSProp | epoch: 017 | loss: 0.67571 - acc: 0.6103 -- iter: 192/534
[A[ATraining Step: 279  | total loss: [1m[32m0.67448[0m[0m | time: 9.762s
[2K
| RMSProp | epoch: 017 | loss: 0.67448 - acc: 0.6118 -- iter: 224/534
[A[ATraining Step: 280  | total loss: [1m[32m0.68470[0m[0m | time: 11.276s
[2K
| RMSProp | epoch: 017 | loss: 0.68470 - acc: 0.5881 -- iter: 256/534
[A[ATraining Step: 281  | total loss: [1m[32m0.68392[0m[0m | time: 12.601s
[2K
| RMSProp | epoch: 017 | loss: 0.68392 - acc: 0.5887 -- iter: 288/534
[A[ATraining Step: 282  | total loss: [1m[32m0.68105[0m[0m | time: 13.741s
[2K
| RMSProp | epoch: 017 | loss: 0.68105 - acc: 0.5954 -- iter: 320/534
[A[ATraining Step: 283  | total loss: [1m[32m0.67936[0m[0m | time: 14.956s
[2K
| RMSProp | epoch: 017 | loss: 0.67936 - acc: 0.5984 -- iter: 352/534
[A[ATraining Step: 284  | total loss: [1m[32m0.68247[0m[0m | time: 16.177s
[2K
| RMSProp | epoch: 017 | loss: 0.68247 - acc: 0.5886 -- iter: 384/534
[A[ATraining Step: 285  | total loss: [1m[32m0.68466[0m[0m | time: 17.431s
[2K
| RMSProp | epoch: 017 | loss: 0.68466 - acc: 0.5797 -- iter: 416/534
[A[ATraining Step: 286  | total loss: [1m[32m0.68186[0m[0m | time: 18.687s
[2K
| RMSProp | epoch: 017 | loss: 0.68186 - acc: 0.5874 -- iter: 448/534
[A[ATraining Step: 287  | total loss: [1m[32m0.68240[0m[0m | time: 19.676s
[2K
| RMSProp | epoch: 017 | loss: 0.68240 - acc: 0.5849 -- iter: 480/534
[A[ATraining Step: 288  | total loss: [1m[32m0.68031[0m[0m | time: 20.644s
[2K
| RMSProp | epoch: 017 | loss: 0.68031 - acc: 0.5900 -- iter: 512/534
[A[ATraining Step: 289  | total loss: [1m[32m0.67821[0m[0m | time: 23.021s
[2K
| RMSProp | epoch: 017 | loss: 0.67821 - acc: 0.5947 | val_loss: 0.67478 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 290  | total loss: [1m[32m0.67664[0m[0m | time: 1.325s
[2K
| RMSProp | epoch: 018 | loss: 0.67664 - acc: 0.5977 -- iter: 032/534
[A[ATraining Step: 291  | total loss: [1m[32m0.67142[0m[0m | time: 2.850s
[2K
| RMSProp | epoch: 018 | loss: 0.67142 - acc: 0.6098 -- iter: 064/534
[A[ATraining Step: 292  | total loss: [1m[32m0.67343[0m[0m | time: 4.360s
[2K
| RMSProp | epoch: 018 | loss: 0.67343 - acc: 0.6051 -- iter: 096/534
[A[ATraining Step: 293  | total loss: [1m[32m0.67237[0m[0m | time: 5.744s
[2K
| RMSProp | epoch: 018 | loss: 0.67237 - acc: 0.6071 -- iter: 128/534
[A[ATraining Step: 294  | total loss: [1m[32m0.66991[0m[0m | time: 6.932s
[2K
| RMSProp | epoch: 018 | loss: 0.66991 - acc: 0.6120 -- iter: 160/534
[A[ATraining Step: 295  | total loss: [1m[32m0.66747[0m[0m | time: 8.241s
[2K
| RMSProp | epoch: 018 | loss: 0.66747 - acc: 0.6164 -- iter: 192/534
[A[ATraining Step: 296  | total loss: [1m[32m0.67242[0m[0m | time: 9.444s
[2K
| RMSProp | epoch: 018 | loss: 0.67242 - acc: 0.6079 -- iter: 224/534
[A[ATraining Step: 297  | total loss: [1m[32m0.67178[0m[0m | time: 10.753s
[2K
| RMSProp | epoch: 018 | loss: 0.67178 - acc: 0.6096 -- iter: 256/534
[A[ATraining Step: 298  | total loss: [1m[32m0.66830[0m[0m | time: 11.930s
[2K
| RMSProp | epoch: 018 | loss: 0.66830 - acc: 0.6174 -- iter: 288/534
[A[ATraining Step: 299  | total loss: [1m[32m0.67238[0m[0m | time: 13.204s
[2K
| RMSProp | epoch: 018 | loss: 0.67238 - acc: 0.6088 -- iter: 320/534
[A[ATraining Step: 300  | total loss: [1m[32m0.67394[0m[0m | time: 14.147s
[2K
| RMSProp | epoch: 018 | loss: 0.67394 - acc: 0.6041 -- iter: 352/534
[A[ATraining Step: 301  | total loss: [1m[32m0.67622[0m[0m | time: 15.130s
[2K
| RMSProp | epoch: 018 | loss: 0.67622 - acc: 0.5969 -- iter: 384/534
[A[ATraining Step: 302  | total loss: [1m[32m0.68020[0m[0m | time: 16.194s
[2K
| RMSProp | epoch: 018 | loss: 0.68020 - acc: 0.5840 -- iter: 416/534
[A[ATraining Step: 303  | total loss: [1m[32m0.68238[0m[0m | time: 17.203s
[2K
| RMSProp | epoch: 018 | loss: 0.68238 - acc: 0.5756 -- iter: 448/534
[A[ATraining Step: 304  | total loss: [1m[32m0.67942[0m[0m | time: 18.052s
[2K
| RMSProp | epoch: 018 | loss: 0.67942 - acc: 0.5868 -- iter: 480/534
[A[ATraining Step: 305  | total loss: [1m[32m0.68097[0m[0m | time: 18.487s
[2K
| RMSProp | epoch: 018 | loss: 0.68097 - acc: 0.5813 -- iter: 512/534
[A[ATraining Step: 306  | total loss: [1m[32m0.68188[0m[0m | time: 19.942s
[2K
| RMSProp | epoch: 018 | loss: 0.68188 - acc: 0.5777 | val_loss: 0.67651 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 307  | total loss: [1m[32m0.68276[0m[0m | time: 0.649s
[2K
| RMSProp | epoch: 019 | loss: 0.68276 - acc: 0.5745 -- iter: 032/534
[A[ATraining Step: 308  | total loss: [1m[32m0.68053[0m[0m | time: 1.291s
[2K
| RMSProp | epoch: 019 | loss: 0.68053 - acc: 0.5826 -- iter: 064/534
[A[ATraining Step: 309  | total loss: [1m[32m0.67643[0m[0m | time: 1.919s
[2K
| RMSProp | epoch: 019 | loss: 0.67643 - acc: 0.5963 -- iter: 096/534
[A[ATraining Step: 310  | total loss: [1m[32m0.67636[0m[0m | time: 2.554s
[2K
| RMSProp | epoch: 019 | loss: 0.67636 - acc: 0.5960 -- iter: 128/534
[A[ATraining Step: 311  | total loss: [1m[32m0.67729[0m[0m | time: 3.179s
[2K
| RMSProp | epoch: 019 | loss: 0.67729 - acc: 0.5927 -- iter: 160/534
[A[ATraining Step: 312  | total loss: [1m[32m0.67927[0m[0m | time: 3.806s
[2K
| RMSProp | epoch: 019 | loss: 0.67927 - acc: 0.5865 -- iter: 192/534
[A[ATraining Step: 313  | total loss: [1m[32m0.67700[0m[0m | time: 4.410s
[2K
| RMSProp | epoch: 019 | loss: 0.67700 - acc: 0.5935 -- iter: 224/534
[A[ATraining Step: 314  | total loss: [1m[32m0.68692[0m[0m | time: 5.059s
[2K
| RMSProp | epoch: 019 | loss: 0.68692 - acc: 0.5654 -- iter: 256/534
[A[ATraining Step: 315  | total loss: [1m[32m0.68674[0m[0m | time: 5.700s
[2K
| RMSProp | epoch: 019 | loss: 0.68674 - acc: 0.5651 -- iter: 288/534
[A[ATraining Step: 316  | total loss: [1m[32m0.68901[0m[0m | time: 6.358s
[2K
| RMSProp | epoch: 019 | loss: 0.68901 - acc: 0.5555 -- iter: 320/534
[A[ATraining Step: 317  | total loss: [1m[32m0.68363[0m[0m | time: 7.018s
[2K
| RMSProp | epoch: 019 | loss: 0.68363 - acc: 0.5780 -- iter: 352/534
[A[ATraining Step: 318  | total loss: [1m[32m0.68135[0m[0m | time: 7.678s
[2K
| RMSProp | epoch: 019 | loss: 0.68135 - acc: 0.5859 -- iter: 384/534
[A[ATraining Step: 319  | total loss: [1m[32m0.67723[0m[0m | time: 8.324s
[2K
| RMSProp | epoch: 019 | loss: 0.67723 - acc: 0.5992 -- iter: 416/534
[A[ATraining Step: 320  | total loss: [1m[32m0.67287[0m[0m | time: 8.935s
[2K
| RMSProp | epoch: 019 | loss: 0.67287 - acc: 0.6111 -- iter: 448/534
[A[ATraining Step: 321  | total loss: [1m[32m0.67326[0m[0m | time: 9.567s
[2K
| RMSProp | epoch: 019 | loss: 0.67326 - acc: 0.6094 -- iter: 480/534
[A[ATraining Step: 322  | total loss: [1m[32m0.67618[0m[0m | time: 10.169s
[2K
| RMSProp | epoch: 019 | loss: 0.67618 - acc: 0.6016 -- iter: 512/534
[A[ATraining Step: 323  | total loss: [1m[32m0.66977[0m[0m | time: 11.611s
[2K
| RMSProp | epoch: 019 | loss: 0.66977 - acc: 0.6195 | val_loss: 0.67475 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 324  | total loss: [1m[32m0.67061[0m[0m | time: 0.778s
[2K
| RMSProp | epoch: 020 | loss: 0.67061 - acc: 0.6167 -- iter: 032/534
[A[ATraining Step: 325  | total loss: [1m[32m0.67137[0m[0m | time: 1.975s
[2K
| RMSProp | epoch: 020 | loss: 0.67137 - acc: 0.6141 -- iter: 064/534
[A[ATraining Step: 326  | total loss: [1m[32m0.67549[0m[0m | time: 2.759s
[2K
| RMSProp | epoch: 020 | loss: 0.67549 - acc: 0.6027 -- iter: 096/534
[A[ATraining Step: 327  | total loss: [1m[32m0.67769[0m[0m | time: 3.642s
[2K
| RMSProp | epoch: 020 | loss: 0.67769 - acc: 0.5955 -- iter: 128/534
[A[ATraining Step: 328  | total loss: [1m[32m0.67749[0m[0m | time: 4.708s
[2K
| RMSProp | epoch: 020 | loss: 0.67749 - acc: 0.5954 -- iter: 160/534
[A[ATraining Step: 329  | total loss: [1m[32m0.68022[0m[0m | time: 6.081s
[2K
| RMSProp | epoch: 020 | loss: 0.68022 - acc: 0.5858 -- iter: 192/534
[A[ATraining Step: 330  | total loss: [1m[32m0.67970[0m[0m | time: 7.451s
[2K
| RMSProp | epoch: 020 | loss: 0.67970 - acc: 0.5866 -- iter: 224/534
[A[ATraining Step: 331  | total loss: [1m[32m0.68022[0m[0m | time: 8.544s
[2K
| RMSProp | epoch: 020 | loss: 0.68022 - acc: 0.5842 -- iter: 256/534
[A[ATraining Step: 332  | total loss: [1m[32m0.68076[0m[0m | time: 9.815s
[2K
| RMSProp | epoch: 020 | loss: 0.68076 - acc: 0.5820 -- iter: 288/534
[A[ATraining Step: 333  | total loss: [1m[32m0.67764[0m[0m | time: 11.147s
[2K
| RMSProp | epoch: 020 | loss: 0.67764 - acc: 0.5926 -- iter: 320/534
[A[ATraining Step: 334  | total loss: [1m[32m0.67536[0m[0m | time: 12.337s
[2K
| RMSProp | epoch: 020 | loss: 0.67536 - acc: 0.5989 -- iter: 352/534
[A[ATraining Step: 335  | total loss: [1m[32m0.67876[0m[0m | time: 13.591s
[2K
| RMSProp | epoch: 020 | loss: 0.67876 - acc: 0.5891 -- iter: 384/534
[A[ATraining Step: 336  | total loss: [1m[32m0.67959[0m[0m | time: 14.883s
[2K
| RMSProp | epoch: 020 | loss: 0.67959 - acc: 0.5864 -- iter: 416/534
[A[ATraining Step: 337  | total loss: [1m[32m0.67720[0m[0m | time: 16.471s
[2K
| RMSProp | epoch: 020 | loss: 0.67720 - acc: 0.5934 -- iter: 448/534
[A[ATraining Step: 338  | total loss: [1m[32m0.68045[0m[0m | time: 17.883s
[2K
| RMSProp | epoch: 020 | loss: 0.68045 - acc: 0.5840 -- iter: 480/534
[A[ATraining Step: 339  | total loss: [1m[32m0.67714[0m[0m | time: 19.014s
[2K
| RMSProp | epoch: 020 | loss: 0.67714 - acc: 0.5944 -- iter: 512/534
[A[ATraining Step: 340  | total loss: [1m[32m0.67350[0m[0m | time: 21.416s
[2K
| RMSProp | epoch: 020 | loss: 0.67350 - acc: 0.6037 | val_loss: 0.67463 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 341  | total loss: [1m[32m0.67354[0m[0m | time: 0.865s
[2K
| RMSProp | epoch: 021 | loss: 0.67354 - acc: 0.6027 -- iter: 032/534
[A[ATraining Step: 342  | total loss: [1m[32m0.67941[0m[0m | time: 1.745s
[2K
| RMSProp | epoch: 021 | loss: 0.67941 - acc: 0.5879 -- iter: 064/534
[A[ATraining Step: 343  | total loss: [1m[32m0.68340[0m[0m | time: 2.991s
[2K
| RMSProp | epoch: 021 | loss: 0.68340 - acc: 0.5746 -- iter: 096/534
[A[ATraining Step: 344  | total loss: [1m[32m0.68185[0m[0m | time: 4.307s
[2K
| RMSProp | epoch: 021 | loss: 0.68185 - acc: 0.5796 -- iter: 128/534
[A[ATraining Step: 345  | total loss: [1m[32m0.68033[0m[0m | time: 5.679s
[2K
| RMSProp | epoch: 021 | loss: 0.68033 - acc: 0.5841 -- iter: 160/534
[A[ATraining Step: 346  | total loss: [1m[32m0.68090[0m[0m | time: 7.130s
[2K
| RMSProp | epoch: 021 | loss: 0.68090 - acc: 0.5820 -- iter: 192/534
[A[ATraining Step: 347  | total loss: [1m[32m0.68134[0m[0m | time: 8.663s
[2K
| RMSProp | epoch: 021 | loss: 0.68134 - acc: 0.5800 -- iter: 224/534
[A[ATraining Step: 348  | total loss: [1m[32m0.67986[0m[0m | time: 10.021s
[2K
| RMSProp | epoch: 021 | loss: 0.67986 - acc: 0.5845 -- iter: 256/534
[A[ATraining Step: 349  | total loss: [1m[32m0.68152[0m[0m | time: 11.292s
[2K
| RMSProp | epoch: 021 | loss: 0.68152 - acc: 0.5792 -- iter: 288/534
[A[ATraining Step: 350  | total loss: [1m[32m0.67910[0m[0m | time: 12.830s
[2K
| RMSProp | epoch: 021 | loss: 0.67910 - acc: 0.5869 -- iter: 320/534
[A[ATraining Step: 351  | total loss: [1m[32m0.67557[0m[0m | time: 13.954s
[2K
| RMSProp | epoch: 021 | loss: 0.67557 - acc: 0.5970 -- iter: 352/534
[A[ATraining Step: 352  | total loss: [1m[32m0.67318[0m[0m | time: 15.155s
[2K
| RMSProp | epoch: 021 | loss: 0.67318 - acc: 0.6029 -- iter: 384/534
[A[ATraining Step: 353  | total loss: [1m[32m0.67359[0m[0m | time: 16.401s
[2K
| RMSProp | epoch: 021 | loss: 0.67359 - acc: 0.6020 -- iter: 416/534
[A[ATraining Step: 354  | total loss: [1m[32m0.67380[0m[0m | time: 17.693s
[2K
| RMSProp | epoch: 021 | loss: 0.67380 - acc: 0.6012 -- iter: 448/534
[A[ATraining Step: 355  | total loss: [1m[32m0.67660[0m[0m | time: 18.919s
[2K
| RMSProp | epoch: 021 | loss: 0.67660 - acc: 0.5942 -- iter: 480/534
[A[ATraining Step: 356  | total loss: [1m[32m0.67956[0m[0m | time: 19.969s
[2K
| RMSProp | epoch: 021 | loss: 0.67956 - acc: 0.5847 -- iter: 512/534
[A[ATraining Step: 357  | total loss: [1m[32m0.67410[0m[0m | time: 22.670s
[2K
| RMSProp | epoch: 021 | loss: 0.67410 - acc: 0.6044 | val_loss: 0.67508 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 358  | total loss: [1m[32m0.67648[0m[0m | time: 1.497s
[2K
| RMSProp | epoch: 022 | loss: 0.67648 - acc: 0.5971 -- iter: 032/534
[A[ATraining Step: 359  | total loss: [1m[32m0.67447[0m[0m | time: 2.322s
[2K
| RMSProp | epoch: 022 | loss: 0.67447 - acc: 0.6030 -- iter: 064/534
[A[ATraining Step: 360  | total loss: [1m[32m0.67609[0m[0m | time: 3.150s
[2K
| RMSProp | epoch: 022 | loss: 0.67609 - acc: 0.5972 -- iter: 096/534
[A[ATraining Step: 361  | total loss: [1m[32m0.67769[0m[0m | time: 4.511s
[2K
| RMSProp | epoch: 022 | loss: 0.67769 - acc: 0.5921 -- iter: 128/534
[A[ATraining Step: 362  | total loss: [1m[32m0.68060[0m[0m | time: 6.012s
[2K
| RMSProp | epoch: 022 | loss: 0.68060 - acc: 0.5829 -- iter: 160/534
[A[ATraining Step: 363  | total loss: [1m[32m0.68112[0m[0m | time: 7.255s
[2K
| RMSProp | epoch: 022 | loss: 0.68112 - acc: 0.5808 -- iter: 192/534
[A[ATraining Step: 364  | total loss: [1m[32m0.67792[0m[0m | time: 8.547s
[2K
| RMSProp | epoch: 022 | loss: 0.67792 - acc: 0.5915 -- iter: 224/534
[A[ATraining Step: 365  | total loss: [1m[32m0.67674[0m[0m | time: 9.803s
[2K
| RMSProp | epoch: 022 | loss: 0.67674 - acc: 0.5948 -- iter: 256/534
[A[ATraining Step: 366  | total loss: [1m[32m0.67872[0m[0m | time: 11.084s
[2K
| RMSProp | epoch: 022 | loss: 0.67872 - acc: 0.5885 -- iter: 288/534
[A[ATraining Step: 367  | total loss: [1m[32m0.67350[0m[0m | time: 12.283s
[2K
| RMSProp | epoch: 022 | loss: 0.67350 - acc: 0.6046 -- iter: 320/534
[A[ATraining Step: 368  | total loss: [1m[32m0.67732[0m[0m | time: 13.364s
[2K
| RMSProp | epoch: 022 | loss: 0.67732 - acc: 0.5942 -- iter: 352/534
[A[ATraining Step: 369  | total loss: [1m[32m0.67912[0m[0m | time: 14.745s
[2K
| RMSProp | epoch: 022 | loss: 0.67912 - acc: 0.5879 -- iter: 384/534
[A[ATraining Step: 370  | total loss: [1m[32m0.67978[0m[0m | time: 16.284s
[2K
| RMSProp | epoch: 022 | loss: 0.67978 - acc: 0.5853 -- iter: 416/534
[A[ATraining Step: 371  | total loss: [1m[32m0.68337[0m[0m | time: 17.744s
[2K
| RMSProp | epoch: 022 | loss: 0.68337 - acc: 0.5737 -- iter: 448/534
[A[ATraining Step: 372  | total loss: [1m[32m0.67792[0m[0m | time: 18.892s
[2K
| RMSProp | epoch: 022 | loss: 0.67792 - acc: 0.5944 -- iter: 480/534
[A[ATraining Step: 373  | total loss: [1m[32m0.68080[0m[0m | time: 20.057s
[2K
| RMSProp | epoch: 022 | loss: 0.68080 - acc: 0.5850 -- iter: 512/534
[A[ATraining Step: 374  | total loss: [1m[32m0.67858[0m[0m | time: 22.566s
[2K
| RMSProp | epoch: 022 | loss: 0.67858 - acc: 0.5921 | val_loss: 0.67471 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 375  | total loss: [1m[32m0.67643[0m[0m | time: 1.283s
[2K
| RMSProp | epoch: 023 | loss: 0.67643 - acc: 0.5985 -- iter: 032/534
[A[ATraining Step: 376  | total loss: [1m[32m0.67624[0m[0m | time: 2.777s
[2K
| RMSProp | epoch: 023 | loss: 0.67624 - acc: 0.5981 -- iter: 064/534
[A[ATraining Step: 377  | total loss: [1m[32m0.67596[0m[0m | time: 3.838s
[2K
| RMSProp | epoch: 023 | loss: 0.67596 - acc: 0.5976 -- iter: 096/534
[A[ATraining Step: 378  | total loss: [1m[32m0.67767[0m[0m | time: 4.762s
[2K
| RMSProp | epoch: 023 | loss: 0.67767 - acc: 0.5924 -- iter: 128/534
[A[ATraining Step: 379  | total loss: [1m[32m0.67903[0m[0m | time: 5.922s
[2K
| RMSProp | epoch: 023 | loss: 0.67903 - acc: 0.5877 -- iter: 160/534
[A[ATraining Step: 380  | total loss: [1m[32m0.67952[0m[0m | time: 7.210s
[2K
| RMSProp | epoch: 023 | loss: 0.67952 - acc: 0.5852 -- iter: 192/534
[A[ATraining Step: 381  | total loss: [1m[32m0.68091[0m[0m | time: 8.563s
[2K
| RMSProp | epoch: 023 | loss: 0.68091 - acc: 0.5798 -- iter: 224/534
[A[ATraining Step: 382  | total loss: [1m[32m0.67941[0m[0m | time: 10.100s
[2K
| RMSProp | epoch: 023 | loss: 0.67941 - acc: 0.5843 -- iter: 256/534
[A[ATraining Step: 383  | total loss: [1m[32m0.67367[0m[0m | time: 11.358s
[2K
| RMSProp | epoch: 023 | loss: 0.67367 - acc: 0.6009 -- iter: 288/534
[A[ATraining Step: 384  | total loss: [1m[32m0.67523[0m[0m | time: 12.454s
[2K
| RMSProp | epoch: 023 | loss: 0.67523 - acc: 0.5970 -- iter: 320/534
[A[ATraining Step: 385  | total loss: [1m[32m0.67157[0m[0m | time: 13.702s
[2K
| RMSProp | epoch: 023 | loss: 0.67157 - acc: 0.6061 -- iter: 352/534
[A[ATraining Step: 386  | total loss: [1m[32m0.67182[0m[0m | time: 15.135s
[2K
| RMSProp | epoch: 023 | loss: 0.67182 - acc: 0.6049 -- iter: 384/534
[A[ATraining Step: 387  | total loss: [1m[32m0.67064[0m[0m | time: 16.443s
[2K
| RMSProp | epoch: 023 | loss: 0.67064 - acc: 0.6069 -- iter: 416/534
[A[ATraining Step: 388  | total loss: [1m[32m0.67073[0m[0m | time: 17.736s
[2K
| RMSProp | epoch: 023 | loss: 0.67073 - acc: 0.6056 -- iter: 448/534
[A[ATraining Step: 389  | total loss: [1m[32m0.67408[0m[0m | time: 19.161s
[2K
| RMSProp | epoch: 023 | loss: 0.67408 - acc: 0.5981 -- iter: 480/534
[A[ATraining Step: 390  | total loss: [1m[32m0.67514[0m[0m | time: 20.541s
[2K
| RMSProp | epoch: 023 | loss: 0.67514 - acc: 0.5946 -- iter: 512/534
[A[ATraining Step: 391  | total loss: [1m[32m0.67502[0m[0m | time: 23.080s
[2K
| RMSProp | epoch: 023 | loss: 0.67502 - acc: 0.5945 | val_loss: 0.67564 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 392  | total loss: [1m[32m0.67814[0m[0m | time: 1.308s
[2K
| RMSProp | epoch: 024 | loss: 0.67814 - acc: 0.5850 -- iter: 032/534
[A[ATraining Step: 393  | total loss: [1m[32m0.68250[0m[0m | time: 2.719s
[2K
| RMSProp | epoch: 024 | loss: 0.68250 - acc: 0.5703 -- iter: 064/534
[A[ATraining Step: 394  | total loss: [1m[32m0.68200[0m[0m | time: 3.971s
[2K
| RMSProp | epoch: 024 | loss: 0.68200 - acc: 0.5726 -- iter: 096/534
[A[ATraining Step: 395  | total loss: [1m[32m0.67966[0m[0m | time: 4.601s
[2K
| RMSProp | epoch: 024 | loss: 0.67966 - acc: 0.5810 -- iter: 128/534
[A[ATraining Step: 396  | total loss: [1m[32m0.67918[0m[0m | time: 5.078s
[2K
| RMSProp | epoch: 024 | loss: 0.67918 - acc: 0.5820 -- iter: 160/534
[A[ATraining Step: 397  | total loss: [1m[32m0.67893[0m[0m | time: 5.707s
[2K
| RMSProp | epoch: 024 | loss: 0.67893 - acc: 0.5829 -- iter: 192/534
[A[ATraining Step: 398  | total loss: [1m[32m0.67755[0m[0m | time: 6.329s
[2K
| RMSProp | epoch: 024 | loss: 0.67755 - acc: 0.5871 -- iter: 224/534
[A[ATraining Step: 399  | total loss: [1m[32m0.67823[0m[0m | time: 6.973s
[2K
| RMSProp | epoch: 024 | loss: 0.67823 - acc: 0.5846 -- iter: 256/534
[A[ATraining Step: 400  | total loss: [1m[32m0.67859[0m[0m | time: 8.598s
[2K
| RMSProp | epoch: 024 | loss: 0.67859 - acc: 0.5824 | val_loss: 0.67603 - val_acc: 0.5952 -- iter: 288/534
--
Training Step: 401  | total loss: [1m[32m0.68130[0m[0m | time: 9.234s
[2K
| RMSProp | epoch: 024 | loss: 0.68130 - acc: 0.5742 -- iter: 320/534
[A[ATraining Step: 402  | total loss: [1m[32m0.68413[0m[0m | time: 9.862s
[2K
| RMSProp | epoch: 024 | loss: 0.68413 - acc: 0.5636 -- iter: 352/534
[A[ATraining Step: 403  | total loss: [1m[32m0.68309[0m[0m | time: 10.483s
[2K
| RMSProp | epoch: 024 | loss: 0.68309 - acc: 0.5666 -- iter: 384/534
[A[ATraining Step: 404  | total loss: [1m[32m0.68405[0m[0m | time: 11.129s
[2K
| RMSProp | epoch: 024 | loss: 0.68405 - acc: 0.5631 -- iter: 416/534
[A[ATraining Step: 405  | total loss: [1m[32m0.68164[0m[0m | time: 11.773s
[2K
| RMSProp | epoch: 024 | loss: 0.68164 - acc: 0.5724 -- iter: 448/534
[A[ATraining Step: 406  | total loss: [1m[32m0.68247[0m[0m | time: 12.447s
[2K
| RMSProp | epoch: 024 | loss: 0.68247 - acc: 0.5683 -- iter: 480/534
[A[ATraining Step: 407  | total loss: [1m[32m0.67840[0m[0m | time: 13.080s
[2K
| RMSProp | epoch: 024 | loss: 0.67840 - acc: 0.5802 -- iter: 512/534
[A[ATraining Step: 408  | total loss: [1m[32m0.67536[0m[0m | time: 14.732s
[2K
| RMSProp | epoch: 024 | loss: 0.67536 - acc: 0.5878 | val_loss: 0.75351 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 409  | total loss: [1m[32m0.66560[0m[0m | time: 1.114s
[2K
| RMSProp | epoch: 025 | loss: 0.66560 - acc: 0.6040 -- iter: 032/534
[A[ATraining Step: 410  | total loss: [1m[32m0.66639[0m[0m | time: 2.163s
[2K
| RMSProp | epoch: 025 | loss: 0.66639 - acc: 0.6093 -- iter: 064/534
[A[ATraining Step: 411  | total loss: [1m[32m0.67467[0m[0m | time: 3.012s
[2K
| RMSProp | epoch: 025 | loss: 0.67467 - acc: 0.5921 -- iter: 096/534
[A[ATraining Step: 412  | total loss: [1m[32m0.67318[0m[0m | time: 3.886s
[2K
| RMSProp | epoch: 025 | loss: 0.67318 - acc: 0.5954 -- iter: 128/534
[A[ATraining Step: 413  | total loss: [1m[32m0.67090[0m[0m | time: 4.523s
[2K
| RMSProp | epoch: 025 | loss: 0.67090 - acc: 0.6015 -- iter: 160/534
[A[ATraining Step: 414  | total loss: [1m[32m0.67088[0m[0m | time: 5.188s
[2K
| RMSProp | epoch: 025 | loss: 0.67088 - acc: 0.6004 -- iter: 192/534
[A[ATraining Step: 415  | total loss: [1m[32m0.67067[0m[0m | time: 6.084s
[2K
| RMSProp | epoch: 025 | loss: 0.67067 - acc: 0.5995 -- iter: 224/534
[A[ATraining Step: 416  | total loss: [1m[32m0.67585[0m[0m | time: 7.084s
[2K
| RMSProp | epoch: 025 | loss: 0.67585 - acc: 0.5864 -- iter: 256/534
[A[ATraining Step: 417  | total loss: [1m[32m0.67170[0m[0m | time: 8.049s
[2K
| RMSProp | epoch: 025 | loss: 0.67170 - acc: 0.5996 -- iter: 288/534
[A[ATraining Step: 418  | total loss: [1m[32m0.66846[0m[0m | time: 8.939s
[2K
| RMSProp | epoch: 025 | loss: 0.66846 - acc: 0.6053 -- iter: 320/534
[A[ATraining Step: 419  | total loss: [1m[32m0.66679[0m[0m | time: 10.021s
[2K
| RMSProp | epoch: 025 | loss: 0.66679 - acc: 0.6073 -- iter: 352/534
[A[ATraining Step: 420  | total loss: [1m[32m0.66007[0m[0m | time: 11.367s
[2K
| RMSProp | epoch: 025 | loss: 0.66007 - acc: 0.6184 -- iter: 384/534
[A[ATraining Step: 421  | total loss: [1m[32m0.65764[0m[0m | time: 12.754s
[2K
| RMSProp | epoch: 025 | loss: 0.65764 - acc: 0.6191 -- iter: 416/534
[A[ATraining Step: 422  | total loss: [1m[32m0.66444[0m[0m | time: 14.198s
[2K
| RMSProp | epoch: 025 | loss: 0.66444 - acc: 0.6103 -- iter: 448/534
[A[ATraining Step: 423  | total loss: [1m[32m0.66325[0m[0m | time: 17.103s
[2K
| RMSProp | epoch: 025 | loss: 0.66325 - acc: 0.6118 -- iter: 480/534
[A[ATraining Step: 424  | total loss: [1m[32m0.66030[0m[0m | time: 22.580s
[2K
| RMSProp | epoch: 025 | loss: 0.66030 - acc: 0.6162 -- iter: 512/534
[A[ATraining Step: 425  | total loss: [1m[32m0.65432[0m[0m | time: 24.940s
[2K
| RMSProp | epoch: 025 | loss: 0.65432 - acc: 0.6265 | val_loss: 0.66986 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 426  | total loss: [1m[32m0.66631[0m[0m | time: 1.309s
[2K
| RMSProp | epoch: 026 | loss: 0.66631 - acc: 0.6107 -- iter: 032/534
[A[ATraining Step: 427  | total loss: [1m[32m0.66699[0m[0m | time: 2.498s
[2K
| RMSProp | epoch: 026 | loss: 0.66699 - acc: 0.6059 -- iter: 064/534
[A[ATraining Step: 428  | total loss: [1m[32m0.66837[0m[0m | time: 3.815s
[2K
| RMSProp | epoch: 026 | loss: 0.66837 - acc: 0.5984 -- iter: 096/534
[A[ATraining Step: 429  | total loss: [1m[32m0.66935[0m[0m | time: 5.163s
[2K
| RMSProp | epoch: 026 | loss: 0.66935 - acc: 0.5948 -- iter: 128/534
[A[ATraining Step: 430  | total loss: [1m[32m0.66721[0m[0m | time: 6.345s
[2K
| RMSProp | epoch: 026 | loss: 0.66721 - acc: 0.6010 -- iter: 160/534
[A[ATraining Step: 431  | total loss: [1m[32m0.66557[0m[0m | time: 7.298s
[2K
| RMSProp | epoch: 026 | loss: 0.66557 - acc: 0.6002 -- iter: 192/534
[A[ATraining Step: 432  | total loss: [1m[32m0.66659[0m[0m | time: 8.134s
[2K
| RMSProp | epoch: 026 | loss: 0.66659 - acc: 0.5948 -- iter: 224/534
[A[ATraining Step: 433  | total loss: [1m[32m0.66625[0m[0m | time: 9.348s
[2K
| RMSProp | epoch: 026 | loss: 0.66625 - acc: 0.5898 -- iter: 256/534
[A[ATraining Step: 434  | total loss: [1m[32m0.66815[0m[0m | time: 10.488s
[2K
| RMSProp | epoch: 026 | loss: 0.66815 - acc: 0.5871 -- iter: 288/534
[A[ATraining Step: 435  | total loss: [1m[32m0.67308[0m[0m | time: 11.821s
[2K
| RMSProp | epoch: 026 | loss: 0.67308 - acc: 0.5721 -- iter: 320/534
[A[ATraining Step: 436  | total loss: [1m[32m0.67353[0m[0m | time: 13.141s
[2K
| RMSProp | epoch: 026 | loss: 0.67353 - acc: 0.5868 -- iter: 352/534
[A[ATraining Step: 437  | total loss: [1m[32m0.67203[0m[0m | time: 14.270s
[2K
| RMSProp | epoch: 026 | loss: 0.67203 - acc: 0.5906 -- iter: 384/534
[A[ATraining Step: 438  | total loss: [1m[32m0.67204[0m[0m | time: 15.426s
[2K
| RMSProp | epoch: 026 | loss: 0.67204 - acc: 0.5909 -- iter: 416/534
[A[ATraining Step: 439  | total loss: [1m[32m0.67554[0m[0m | time: 16.717s
[2K
| RMSProp | epoch: 026 | loss: 0.67554 - acc: 0.5787 -- iter: 448/534
[A[ATraining Step: 440  | total loss: [1m[32m0.67578[0m[0m | time: 17.823s
[2K
| RMSProp | epoch: 026 | loss: 0.67578 - acc: 0.5771 -- iter: 480/534
[A[ATraining Step: 441  | total loss: [1m[32m0.67508[0m[0m | time: 19.091s
[2K
| RMSProp | epoch: 026 | loss: 0.67508 - acc: 0.5725 -- iter: 512/534
[A[ATraining Step: 442  | total loss: [1m[32m0.67032[0m[0m | time: 21.471s
[2K
| RMSProp | epoch: 026 | loss: 0.67032 - acc: 0.5840 | val_loss: 0.66662 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 443  | total loss: [1m[32m0.67190[0m[0m | time: 1.230s
[2K
| RMSProp | epoch: 027 | loss: 0.67190 - acc: 0.5819 -- iter: 032/534
[A[ATraining Step: 444  | total loss: [1m[32m0.66951[0m[0m | time: 2.376s
[2K
| RMSProp | epoch: 027 | loss: 0.66951 - acc: 0.5862 -- iter: 064/534
[A[ATraining Step: 445  | total loss: [1m[32m0.66927[0m[0m | time: 3.714s
[2K
| RMSProp | epoch: 027 | loss: 0.66927 - acc: 0.5838 -- iter: 096/534
[A[ATraining Step: 446  | total loss: [1m[32m0.66912[0m[0m | time: 4.989s
[2K
| RMSProp | epoch: 027 | loss: 0.66912 - acc: 0.5817 -- iter: 128/534
[A[ATraining Step: 447  | total loss: [1m[32m0.67177[0m[0m | time: 6.267s
[2K
| RMSProp | epoch: 027 | loss: 0.67177 - acc: 0.5704 -- iter: 160/534
[A[ATraining Step: 448  | total loss: [1m[32m0.67146[0m[0m | time: 7.496s
[2K
| RMSProp | epoch: 027 | loss: 0.67146 - acc: 0.5758 -- iter: 192/534
[A[ATraining Step: 449  | total loss: [1m[32m0.67030[0m[0m | time: 8.459s
[2K
| RMSProp | epoch: 027 | loss: 0.67030 - acc: 0.5745 -- iter: 224/534
[A[ATraining Step: 450  | total loss: [1m[32m0.66602[0m[0m | time: 9.443s
[2K
| RMSProp | epoch: 027 | loss: 0.66602 - acc: 0.5807 -- iter: 256/534
[A[ATraining Step: 451  | total loss: [1m[32m0.66013[0m[0m | time: 10.808s
[2K
| RMSProp | epoch: 027 | loss: 0.66013 - acc: 0.5863 -- iter: 288/534
[A[ATraining Step: 452  | total loss: [1m[32m0.65571[0m[0m | time: 11.858s
[2K
| RMSProp | epoch: 027 | loss: 0.65571 - acc: 0.5901 -- iter: 320/534
[A[ATraining Step: 453  | total loss: [1m[32m0.64654[0m[0m | time: 13.152s
[2K
| RMSProp | epoch: 027 | loss: 0.64654 - acc: 0.5999 -- iter: 352/534
[A[ATraining Step: 454  | total loss: [1m[32m0.63647[0m[0m | time: 14.438s
[2K
| RMSProp | epoch: 027 | loss: 0.63647 - acc: 0.6118 -- iter: 384/534
[A[ATraining Step: 455  | total loss: [1m[32m0.63352[0m[0m | time: 15.716s
[2K
| RMSProp | epoch: 027 | loss: 0.63352 - acc: 0.6193 -- iter: 416/534
[A[ATraining Step: 456  | total loss: [1m[32m0.64168[0m[0m | time: 16.998s
[2K
| RMSProp | epoch: 027 | loss: 0.64168 - acc: 0.6074 -- iter: 448/534
[A[ATraining Step: 457  | total loss: [1m[32m0.64186[0m[0m | time: 18.404s
[2K
| RMSProp | epoch: 027 | loss: 0.64186 - acc: 0.6092 -- iter: 480/534
[A[ATraining Step: 458  | total loss: [1m[32m0.64630[0m[0m | time: 19.739s
[2K
| RMSProp | epoch: 027 | loss: 0.64630 - acc: 0.5982 -- iter: 512/534
[A[ATraining Step: 459  | total loss: [1m[32m0.64619[0m[0m | time: 22.396s
[2K
| RMSProp | epoch: 027 | loss: 0.64619 - acc: 0.5947 | val_loss: 0.67432 - val_acc: 0.6250 -- iter: 534/534
--
Training Step: 460  | total loss: [1m[32m0.64511[0m[0m | time: 1.220s
[2K
| RMSProp | epoch: 028 | loss: 0.64511 - acc: 0.5852 -- iter: 032/534
[A[ATraining Step: 461  | total loss: [1m[32m0.64799[0m[0m | time: 2.641s
[2K
| RMSProp | epoch: 028 | loss: 0.64799 - acc: 0.5861 -- iter: 064/534
[A[ATraining Step: 462  | total loss: [1m[32m0.63932[0m[0m | time: 3.628s
[2K
| RMSProp | epoch: 028 | loss: 0.63932 - acc: 0.5962 -- iter: 096/534
[A[ATraining Step: 463  | total loss: [1m[32m0.63960[0m[0m | time: 4.950s
[2K
| RMSProp | epoch: 028 | loss: 0.63960 - acc: 0.5928 -- iter: 128/534
[A[ATraining Step: 464  | total loss: [1m[32m0.64019[0m[0m | time: 6.145s
[2K
| RMSProp | epoch: 028 | loss: 0.64019 - acc: 0.6054 -- iter: 160/534
[A[ATraining Step: 465  | total loss: [1m[32m0.63532[0m[0m | time: 7.491s
[2K
| RMSProp | epoch: 028 | loss: 0.63532 - acc: 0.6168 -- iter: 192/534
[A[ATraining Step: 466  | total loss: [1m[32m0.64141[0m[0m | time: 8.799s
[2K
| RMSProp | epoch: 028 | loss: 0.64141 - acc: 0.6145 -- iter: 224/534
[A[ATraining Step: 467  | total loss: [1m[32m0.64565[0m[0m | time: 9.761s
[2K
| RMSProp | epoch: 028 | loss: 0.64565 - acc: 0.6124 -- iter: 256/534
[A[ATraining Step: 468  | total loss: [1m[32m0.64369[0m[0m | time: 10.721s
[2K
| RMSProp | epoch: 028 | loss: 0.64369 - acc: 0.6148 -- iter: 288/534
[A[ATraining Step: 469  | total loss: [1m[32m0.63869[0m[0m | time: 11.941s
[2K
| RMSProp | epoch: 028 | loss: 0.63869 - acc: 0.6215 -- iter: 320/534
[A[ATraining Step: 470  | total loss: [1m[32m0.63677[0m[0m | time: 13.234s
[2K
| RMSProp | epoch: 028 | loss: 0.63677 - acc: 0.6375 -- iter: 352/534
[A[ATraining Step: 471  | total loss: [1m[32m0.62549[0m[0m | time: 14.735s
[2K
| RMSProp | epoch: 028 | loss: 0.62549 - acc: 0.6425 -- iter: 384/534
[A[ATraining Step: 472  | total loss: [1m[32m0.63475[0m[0m | time: 16.210s
[2K
| RMSProp | epoch: 028 | loss: 0.63475 - acc: 0.6376 -- iter: 416/534
[A[ATraining Step: 473  | total loss: [1m[32m0.63441[0m[0m | time: 17.521s
[2K
| RMSProp | epoch: 028 | loss: 0.63441 - acc: 0.6426 -- iter: 448/534
[A[ATraining Step: 474  | total loss: [1m[32m0.62860[0m[0m | time: 19.220s
[2K
| RMSProp | epoch: 028 | loss: 0.62860 - acc: 0.6471 -- iter: 480/534
[A[ATraining Step: 475  | total loss: [1m[32m0.63021[0m[0m | time: 20.405s
[2K
| RMSProp | epoch: 028 | loss: 0.63021 - acc: 0.6386 -- iter: 512/534
[A[ATraining Step: 476  | total loss: [1m[32m0.63880[0m[0m | time: 22.888s
[2K
| RMSProp | epoch: 028 | loss: 0.63880 - acc: 0.6216 | val_loss: 0.70827 - val_acc: 0.5952 -- iter: 534/534
--
Training Step: 477  | total loss: [1m[32m0.63500[0m[0m | time: 1.325s
[2K
| RMSProp | epoch: 029 | loss: 0.63500 - acc: 0.6345 -- iter: 032/534
[A[ATraining Step: 478  | total loss: [1m[32m0.63263[0m[0m | time: 2.725s
[2K
| RMSProp | epoch: 029 | loss: 0.63263 - acc: 0.6335 -- iter: 064/534
[A[ATraining Step: 479  | total loss: [1m[32m0.63505[0m[0m | time: 4.205s
[2K
| RMSProp | epoch: 029 | loss: 0.63505 - acc: 0.6327 -- iter: 096/534
[A[ATraining Step: 480  | total loss: [1m[32m0.64177[0m[0m | time: 5.398s
[2K
| RMSProp | epoch: 029 | loss: 0.64177 - acc: 0.6132 -- iter: 128/534
[A[ATraining Step: 481  | total loss: [1m[32m0.63457[0m[0m | time: 6.539s
[2K
| RMSProp | epoch: 029 | loss: 0.63457 - acc: 0.6268 -- iter: 160/534
[A[ATraining Step: 482  | total loss: [1m[32m0.64265[0m[0m | time: 7.786s
[2K
| RMSProp | epoch: 029 | loss: 0.64265 - acc: 0.6173 -- iter: 192/534
[A[ATraining Step: 483  | total loss: [1m[32m0.64442[0m[0m | time: 8.943s
[2K
| RMSProp | epoch: 029 | loss: 0.64442 - acc: 0.6212 -- iter: 224/534
[A[ATraining Step: 484  | total loss: [1m[32m0.63565[0m[0m | time: 10.067s
[2K
| RMSProp | epoch: 029 | loss: 0.63565 - acc: 0.6372 -- iter: 256/534
[A[ATraining Step: 485  | total loss: [1m[32m0.63313[0m[0m | time: 10.622s
[2K
| RMSProp | epoch: 029 | loss: 0.63313 - acc: 0.6422 -- iter: 288/534
[A[ATraining Step: 486  | total loss: [1m[32m0.61610[0m[0m | time: 11.211s
[2K
| RMSProp | epoch: 029 | loss: 0.61610 - acc: 0.6598 -- iter: 320/534
[A[ATraining Step: 487  | total loss: [1m[32m0.59440[0m[0m | time: 12.005s
[2K
| RMSProp | epoch: 029 | loss: 0.59440 - acc: 0.6666 -- iter: 352/534
[A[ATraining Step: 488  | total loss: [1m[32m0.59127[0m[0m | time: 12.912s
[2K
| RMSProp | epoch: 029 | loss: 0.59127 - acc: 0.6749 -- iter: 384/534
[A[ATraining Step: 489  | total loss: [1m[32m0.60715[0m[0m | time: 13.711s
[2K
| RMSProp | epoch: 029 | loss: 0.60715 - acc: 0.6637 -- iter: 416/534
[A[ATraining Step: 490  | total loss: [1m[32m0.60728[0m[0m | time: 14.528s
[2K
| RMSProp | epoch: 029 | loss: 0.60728 - acc: 0.6692 -- iter: 448/534
[A[ATraining Step: 491  | total loss: [1m[32m0.60922[0m[0m | time: 15.359s
[2K
| RMSProp | epoch: 029 | loss: 0.60922 - acc: 0.6648 -- iter: 480/534
[A[ATraining Step: 492  | total loss: [1m[32m0.60675[0m[0m | time: 16.362s
[2K
| RMSProp | epoch: 029 | loss: 0.60675 - acc: 0.6639 -- iter: 512/534
[A[ATraining Step: 493  | total loss: [1m[32m0.60822[0m[0m | time: 18.520s
[2K
| RMSProp | epoch: 029 | loss: 0.60822 - acc: 0.6725 | val_loss: 0.65961 - val_acc: 0.6250 -- iter: 534/534
--
Training Step: 494  | total loss: [1m[32m0.59876[0m[0m | time: 0.806s
[2K
| RMSProp | epoch: 030 | loss: 0.59876 - acc: 0.6740 -- iter: 032/534
[A[ATraining Step: 495  | total loss: [1m[32m0.59034[0m[0m | time: 1.727s
[2K
| RMSProp | epoch: 030 | loss: 0.59034 - acc: 0.6847 -- iter: 064/534
[A[ATraining Step: 496  | total loss: [1m[32m0.57720[0m[0m | time: 2.708s
[2K
| RMSProp | epoch: 030 | loss: 0.57720 - acc: 0.6944 -- iter: 096/534
[A[ATraining Step: 497  | total loss: [1m[32m0.57635[0m[0m | time: 3.567s
[2K
| RMSProp | epoch: 030 | loss: 0.57635 - acc: 0.6999 -- iter: 128/534
[A[ATraining Step: 498  | total loss: [1m[32m0.57729[0m[0m | time: 4.485s
[2K
| RMSProp | epoch: 030 | loss: 0.57729 - acc: 0.6956 -- iter: 160/534
[A[ATraining Step: 499  | total loss: [1m[32m0.58429[0m[0m | time: 5.433s
[2K
| RMSProp | epoch: 030 | loss: 0.58429 - acc: 0.6916 -- iter: 192/534
[A[ATraining Step: 500  | total loss: [1m[32m0.58806[0m[0m | time: 6.338s
[2K
| RMSProp | epoch: 030 | loss: 0.58806 - acc: 0.6819 -- iter: 224/534
[A[ATraining Step: 501  | total loss: [1m[32m0.58768[0m[0m | time: 7.156s
[2K
| RMSProp | epoch: 030 | loss: 0.58768 - acc: 0.6949 -- iter: 256/534
[A[ATraining Step: 502  | total loss: [1m[32m0.58271[0m[0m | time: 8.330s
[2K
| RMSProp | epoch: 030 | loss: 0.58271 - acc: 0.7129 -- iter: 288/534
[A[ATraining Step: 503  | total loss: [1m[32m0.56940[0m[0m | time: 9.125s
[2K
| RMSProp | epoch: 030 | loss: 0.56940 - acc: 0.7198 -- iter: 320/534
[A[ATraining Step: 504  | total loss: [1m[32m0.60361[0m[0m | time: 9.900s
[2K
| RMSProp | epoch: 030 | loss: 0.60361 - acc: 0.6978 -- iter: 352/534
[A[ATraining Step: 505  | total loss: [1m[32m0.61336[0m[0m | time: 10.691s
[2K
| RMSProp | epoch: 030 | loss: 0.61336 - acc: 0.6780 -- iter: 384/534
[A[ATraining Step: 506  | total loss: [1m[32m0.61184[0m[0m | time: 11.570s
[2K
| RMSProp | epoch: 030 | loss: 0.61184 - acc: 0.6790 -- iter: 416/534
[A[ATraining Step: 507  | total loss: [1m[32m0.61193[0m[0m | time: 12.494s
[2K
| RMSProp | epoch: 030 | loss: 0.61193 - acc: 0.6829 -- iter: 448/534
[A[ATraining Step: 508  | total loss: [1m[32m0.60606[0m[0m | time: 13.430s
[2K
| RMSProp | epoch: 030 | loss: 0.60606 - acc: 0.6896 -- iter: 480/534
[A[ATraining Step: 509  | total loss: [1m[32m0.59453[0m[0m | time: 14.322s
[2K
| RMSProp | epoch: 030 | loss: 0.59453 - acc: 0.6988 -- iter: 512/534
[A[ATraining Step: 510  | total loss: [1m[32m0.59986[0m[0m | time: 16.257s
[2K
| RMSProp | epoch: 030 | loss: 0.59986 - acc: 0.6883 | val_loss: 0.65268 - val_acc: 0.6250 -- iter: 534/534
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.635
Validation AUPRC:0.6991082193889413
Test AUC:0.6827355887904749
Test AUPRC:0.6983645906026281
BestTestF1Score	0.73	0.0	0.58	0.58	1.0	97	71	0	0	0.34
BestTestMCCScore	0.71	0.35	0.68	0.74	0.69	67	24	47	30	0.55
BestTestAccuracyScore	0.71	0.35	0.68	0.74	0.69	67	24	47	30	0.55
BestValidationF1Score	0.75	0.0	0.6	0.6	1.0	100	68	0	0	0.34
BestValidationMCC	0.68	0.28	0.64	0.73	0.64	64	24	44	36	0.55
BestValidationAccuracy	0.68	0.28	0.64	0.73	0.64	64	24	44	36	0.55
TestPredictions (Threshold:0.55)
CHEMBL368148,TP,ACT,0.7599999904632568	CHEMBL317482,TP,ACT,0.6700000166893005	CHEMBL8575,TP,ACT,0.6000000238418579	CHEMBL1555743,FP,INACT,0.8600000143051147	CHEMBL341498,TN,INACT,0.5	CHEMBL49249,TP,ACT,0.7599999904632568	CHEMBL65759,TP,ACT,0.550000011920929	CHEMBL3746849,TP,ACT,0.7599999904632568	CHEMBL28093,FN,ACT,0.46000000834465027	CHEMBL368145,TP,ACT,0.8799999952316284	CHEMBL165682,TN,INACT,0.3700000047683716	CHEMBL303900,TP,ACT,0.6899999976158142	CHEMBL146017,TN,INACT,0.5400000214576721	CHEMBL2088233,FP,INACT,0.8100000023841858	CHEMBL285744,TN,INACT,0.5400000214576721	CHEMBL1743607,FN,ACT,0.4300000071525574	CHEMBL512897,FP,INACT,0.7400000095367432	CHEMBL104195,TN,INACT,0.4099999964237213	CHEMBL93022,TP,ACT,0.8799999952316284	CHEMBL72821,TP,ACT,0.7599999904632568	CHEMBL133689,TP,ACT,0.5600000023841858	CHEMBL105777,FP,INACT,0.699999988079071	CHEMBL106990,TN,INACT,0.4399999976158142	CHEMBL1392167,TN,INACT,0.38999998569488525	CHEMBL355899,TP,ACT,0.6499999761581421	CHEMBL414425,FN,ACT,0.5	CHEMBL174161,FN,ACT,0.3700000047683716	CHEMBL316040,TP,ACT,0.800000011920929	CHEMBL435907,TP,ACT,0.9100000262260437	CHEMBL304663,TP,ACT,0.5600000023841858	CHEMBL2165871,TN,INACT,0.47999998927116394	CHEMBL1164396,TN,INACT,0.4399999976158142	CHEMBL2165864,FP,INACT,0.8100000023841858	CHEMBL358414,TP,ACT,0.6299999952316284	CHEMBL70055,FP,INACT,0.6299999952316284	CHEMBL126804,TN,INACT,0.47999998927116394	CHEMBL126647,TP,ACT,0.5899999737739563	CHEMBL276063,TP,ACT,0.5600000023841858	CHEMBL1606580,FN,ACT,0.4099999964237213	CHEMBL2163373,TN,INACT,0.4099999964237213	CHEMBL91531,TN,INACT,0.3799999952316284	CHEMBL280265,TN,INACT,0.4699999988079071	CHEMBL96353,TP,ACT,0.8500000238418579	CHEMBL3349320,TN,INACT,0.4099999964237213	CHEMBL1929094,TN,INACT,0.4099999964237213	CHEMBL303706,FN,ACT,0.4399999976158142	CHEMBL2165869,TN,INACT,0.5299999713897705	CHEMBL91004,FN,ACT,0.46000000834465027	CHEMBL8797,TP,ACT,0.550000011920929	CHEMBL331629,FN,ACT,0.38999998569488525	CHEMBL88774,FP,INACT,0.6299999952316284	CHEMBL286635,FP,INACT,0.8700000047683716	CHEMBL116496,TP,ACT,0.5899999737739563	CHEMBL17722,FN,ACT,0.5099999904632568	CHEMBL176945,FP,INACT,0.8500000238418579	CHEMBL155319,TN,INACT,0.4399999976158142	CHEMBL3262913,TN,INACT,0.46000000834465027	CHEMBL129369,FP,INACT,0.6499999761581421	CHEMBL58866,TP,ACT,0.6800000071525574	CHEMBL62916,TP,ACT,0.8600000143051147	CHEMBL178053,TP,ACT,0.6899999976158142	CHEMBL164332,TN,INACT,0.4699999988079071	CHEMBL105139,TP,ACT,0.5799999833106995	CHEMBL1202802,FN,ACT,0.5299999713897705	CHEMBL306144,TP,ACT,0.8199999928474426	CHEMBL1907659,TN,INACT,0.36000001430511475	CHEMBL93598,FN,ACT,0.5199999809265137	CHEMBL160626,FP,INACT,0.5899999737739563	CHEMBL125151,TP,ACT,0.699999988079071	CHEMBL126345,TP,ACT,0.6399999856948853	CHEMBL2165862,TN,INACT,0.5400000214576721	CHEMBL1202797,TP,ACT,0.550000011920929	CHEMBL54360,TP,ACT,0.6100000143051147	CHEMBL16979,FN,ACT,0.38999998569488525	CHEMBL2164434,FP,INACT,0.7400000095367432	CHEMBL305533,FN,ACT,0.5400000214576721	CHEMBL3085211,TN,INACT,0.4000000059604645	CHEMBL57284,TN,INACT,0.4000000059604645	CHEMBL146701,TP,ACT,0.7799999713897705	CHEMBL340121,FN,ACT,0.4699999988079071	CHEMBL311401,TP,ACT,0.7900000214576721	CHEMBL129538,TN,INACT,0.3799999952316284	CHEMBL280317,TN,INACT,0.5	CHEMBL27410,TN,INACT,0.38999998569488525	CHEMBL121928,FP,INACT,0.5600000023841858	CHEMBL18584,TN,INACT,0.3700000047683716	CHEMBL152346,TN,INACT,0.3799999952316284	CHEMBL1916435,TN,INACT,0.3400000035762787	CHEMBL17775,TN,INACT,0.36000001430511475	CHEMBL177702,TP,ACT,0.6200000047683716	CHEMBL124956,TP,ACT,0.7400000095367432	CHEMBL274187,TP,ACT,0.5699999928474426	CHEMBL129160,TP,ACT,0.6499999761581421	CHEMBL8562,TP,ACT,0.7200000286102295	CHEMBL104575,TN,INACT,0.4399999976158142	CHEMBL129154,FP,INACT,0.5600000023841858	CHEMBL325065,TP,ACT,0.5899999737739563	CHEMBL156835,TN,INACT,0.4699999988079071	CHEMBL303412,FN,ACT,0.44999998807907104	CHEMBL329781,TP,ACT,0.6200000047683716	CHEMBL129765,TP,ACT,0.6600000262260437	CHEMBL3745985,TP,ACT,0.6899999976158142	CHEMBL1163238,TN,INACT,0.38999998569488525	CHEMBL230922,TP,ACT,0.7699999809265137	CHEMBL324408,FP,INACT,0.800000011920929	CHEMBL18201,FN,ACT,0.36000001430511475	CHEMBL123003,TP,ACT,0.6100000143051147	CHEMBL2163384,FP,INACT,0.6499999761581421	CHEMBL561262,FP,INACT,0.6499999761581421	CHEMBL71552,FP,INACT,0.550000011920929	CHEMBL2165863,TN,INACT,0.4399999976158142	CHEMBL53532,FN,ACT,0.4699999988079071	CHEMBL155033,TP,ACT,0.6200000047683716	CHEMBL1929090,TN,INACT,0.46000000834465027	CHEMBL307341,FP,INACT,0.75	CHEMBL68703,FN,ACT,0.3700000047683716	CHEMBL105496,TN,INACT,0.4699999988079071	CHEMBL292118,FP,INACT,0.7699999809265137	CHEMBL275848,TN,INACT,0.36000001430511475	CHEMBL65655,TP,ACT,0.7900000214576721	CHEMBL17370,TP,ACT,0.5600000023841858	CHEMBL112720,TP,ACT,0.6299999952316284	CHEMBL245349,TN,INACT,0.5299999713897705	CHEMBL96412,TP,ACT,0.7099999785423279	CHEMBL74570,TP,ACT,0.6399999856948853	CHEMBL293858,TP,ACT,0.8199999928474426	CHEMBL88863,TN,INACT,0.4099999964237213	CHEMBL52749,TP,ACT,0.6100000143051147	CHEMBL73503,TP,ACT,0.8199999928474426	CHEMBL93670,TP,ACT,0.7699999809265137	CHEMBL1626563,FN,ACT,0.4699999988079071	CHEMBL287012,FN,ACT,0.46000000834465027	CHEMBL129799,FN,ACT,0.44999998807907104	CHEMBL302879,TP,ACT,0.8899999856948853	CHEMBL96767,TP,ACT,0.5799999833106995	CHEMBL130908,FN,ACT,0.4399999976158142	CHEMBL175134,TP,ACT,0.6000000238418579	CHEMBL17148,TP,ACT,0.7900000214576721	CHEMBL126191,TP,ACT,0.5699999928474426	CHEMBL96899,FN,ACT,0.41999998688697815	CHEMBL8927,FP,INACT,0.6399999856948853	CHEMBL120672,FN,ACT,0.4000000059604645	CHEMBL60165,FP,INACT,0.8899999856948853	CHEMBL41520,TP,ACT,0.800000011920929	CHEMBL377542,TN,INACT,0.4399999976158142	CHEMBL304690,TP,ACT,0.8299999833106995	CHEMBL122058,FN,ACT,0.41999998688697815	CHEMBL130273,TP,ACT,0.6800000071525574	CHEMBL18435,TN,INACT,0.3700000047683716	CHEMBL3113158,FP,INACT,0.7400000095367432	CHEMBL37180,TP,ACT,0.6299999952316284	CHEMBL1163237,TN,INACT,0.4399999976158142	CHEMBL1200596,TN,INACT,0.38999998569488525	CHEMBL712,FN,ACT,0.5199999809265137	CHEMBL42593,TP,ACT,0.800000011920929	CHEMBL1202812,FN,ACT,0.44999998807907104	CHEMBL338199,TP,ACT,0.6700000166893005	CHEMBL18129,FN,ACT,0.3700000047683716	CHEMBL68990,TP,ACT,0.6899999976158142	CHEMBL314449,FN,ACT,0.44999998807907104	CHEMBL187472,TN,INACT,0.3799999952316284	CHEMBL89275,FP,INACT,0.6899999976158142	CHEMBL227560,TN,INACT,0.4300000071525574	CHEMBL155236,TP,ACT,0.6499999761581421	CHEMBL17883,TN,INACT,0.36000001430511475	CHEMBL313548,TN,INACT,0.4099999964237213	CHEMBL154517,FN,ACT,0.47999998927116394	CHEMBL368764,TP,ACT,0.6700000166893005	

