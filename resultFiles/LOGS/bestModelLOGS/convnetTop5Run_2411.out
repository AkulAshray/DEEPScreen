CNNModel CHEMBL2756 adam 0.001 30 32 0 0.8 False True
Number of active compounds :	153
Number of inactive compounds :	153
---------------------------------
Run id: CNNModel_CHEMBL2756_adam_0.001_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2756_adam_0.001_30_32_0.8_True/
---------------------------------
Training samples: 192
Validation samples: 61
--
Training Step: 1  | time: 1.233s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/192
[A[ATraining Step: 2  | total loss: [1m[32m0.62365[0m[0m | time: 2.113s
[2K
| Adam | epoch: 001 | loss: 0.62365 - acc: 0.5344 -- iter: 064/192
[A[ATraining Step: 3  | total loss: [1m[32m0.67876[0m[0m | time: 3.042s
[2K
| Adam | epoch: 001 | loss: 0.67876 - acc: 0.6341 -- iter: 096/192
[A[ATraining Step: 4  | total loss: [1m[32m0.69759[0m[0m | time: 3.979s
[2K
| Adam | epoch: 001 | loss: 0.69759 - acc: 0.4866 -- iter: 128/192
[A[ATraining Step: 5  | total loss: [1m[32m0.69122[0m[0m | time: 4.941s
[2K
| Adam | epoch: 001 | loss: 0.69122 - acc: 0.5392 -- iter: 160/192
[A[ATraining Step: 6  | total loss: [1m[32m0.70236[0m[0m | time: 6.930s
[2K
| Adam | epoch: 001 | loss: 0.70236 - acc: 0.3734 | val_loss: 0.69348 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 7  | total loss: [1m[32m0.69786[0m[0m | time: 0.921s
[2K
| Adam | epoch: 002 | loss: 0.69786 - acc: 0.3743 -- iter: 032/192
[A[ATraining Step: 8  | total loss: [1m[32m0.69454[0m[0m | time: 1.909s
[2K
| Adam | epoch: 002 | loss: 0.69454 - acc: 0.5153 -- iter: 064/192
[A[ATraining Step: 9  | total loss: [1m[32m0.69522[0m[0m | time: 2.786s
[2K
| Adam | epoch: 002 | loss: 0.69522 - acc: 0.4576 -- iter: 096/192
[A[ATraining Step: 10  | total loss: [1m[32m0.69428[0m[0m | time: 3.717s
[2K
| Adam | epoch: 002 | loss: 0.69428 - acc: 0.4788 -- iter: 128/192
[A[ATraining Step: 11  | total loss: [1m[32m0.69397[0m[0m | time: 4.603s
[2K
| Adam | epoch: 002 | loss: 0.69397 - acc: 0.4740 -- iter: 160/192
[A[ATraining Step: 12  | total loss: [1m[32m0.69233[0m[0m | time: 6.508s
[2K
| Adam | epoch: 002 | loss: 0.69233 - acc: 0.5420 | val_loss: 0.69451 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 13  | total loss: [1m[32m0.69401[0m[0m | time: 0.726s
[2K
| Adam | epoch: 003 | loss: 0.69401 - acc: 0.4838 -- iter: 032/192
[A[ATraining Step: 14  | total loss: [1m[32m0.69335[0m[0m | time: 1.334s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.5032 -- iter: 064/192
[A[ATraining Step: 15  | total loss: [1m[32m0.69283[0m[0m | time: 1.970s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5142 -- iter: 096/192
[A[ATraining Step: 16  | total loss: [1m[32m0.69214[0m[0m | time: 2.605s
[2K
| Adam | epoch: 003 | loss: 0.69214 - acc: 0.5323 -- iter: 128/192
[A[ATraining Step: 17  | total loss: [1m[32m0.69268[0m[0m | time: 3.245s
[2K
| Adam | epoch: 003 | loss: 0.69268 - acc: 0.5207 -- iter: 160/192
[A[ATraining Step: 18  | total loss: [1m[32m0.69231[0m[0m | time: 4.891s
[2K
| Adam | epoch: 003 | loss: 0.69231 - acc: 0.5243 | val_loss: 0.69725 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 19  | total loss: [1m[32m0.69079[0m[0m | time: 0.615s
[2K
| Adam | epoch: 004 | loss: 0.69079 - acc: 0.5475 -- iter: 032/192
[A[ATraining Step: 20  | total loss: [1m[32m0.69182[0m[0m | time: 1.221s
[2K
| Adam | epoch: 004 | loss: 0.69182 - acc: 0.5322 -- iter: 064/192
[A[ATraining Step: 21  | total loss: [1m[32m0.69160[0m[0m | time: 1.862s
[2K
| Adam | epoch: 004 | loss: 0.69160 - acc: 0.5319 -- iter: 096/192
[A[ATraining Step: 22  | total loss: [1m[32m0.69153[0m[0m | time: 2.478s
[2K
| Adam | epoch: 004 | loss: 0.69153 - acc: 0.5317 -- iter: 128/192
[A[ATraining Step: 23  | total loss: [1m[32m0.69494[0m[0m | time: 3.113s
[2K
| Adam | epoch: 004 | loss: 0.69494 - acc: 0.5044 -- iter: 160/192
[A[ATraining Step: 24  | total loss: [1m[32m0.68978[0m[0m | time: 5.013s
[2K
| Adam | epoch: 004 | loss: 0.68978 - acc: 0.5471 | val_loss: 0.70410 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 25  | total loss: [1m[32m0.68779[0m[0m | time: 0.838s
[2K
| Adam | epoch: 005 | loss: 0.68779 - acc: 0.5598 -- iter: 032/192
[A[ATraining Step: 26  | total loss: [1m[32m0.69471[0m[0m | time: 1.711s
[2K
| Adam | epoch: 005 | loss: 0.69471 - acc: 0.5192 -- iter: 064/192
[A[ATraining Step: 27  | total loss: [1m[32m0.69268[0m[0m | time: 2.563s
[2K
| Adam | epoch: 005 | loss: 0.69268 - acc: 0.5303 -- iter: 096/192
[A[ATraining Step: 28  | total loss: [1m[32m0.69481[0m[0m | time: 3.391s
[2K
| Adam | epoch: 005 | loss: 0.69481 - acc: 0.5149 -- iter: 128/192
[A[ATraining Step: 29  | total loss: [1m[32m0.69565[0m[0m | time: 4.168s
[2K
| Adam | epoch: 005 | loss: 0.69565 - acc: 0.5037 -- iter: 160/192
[A[ATraining Step: 30  | total loss: [1m[32m0.69746[0m[0m | time: 6.079s
[2K
| Adam | epoch: 005 | loss: 0.69746 - acc: 0.4806 | val_loss: 0.69584 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 31  | total loss: [1m[32m0.69605[0m[0m | time: 0.860s
[2K
| Adam | epoch: 006 | loss: 0.69605 - acc: 0.4923 -- iter: 032/192
[A[ATraining Step: 32  | total loss: [1m[32m0.69618[0m[0m | time: 1.703s
[2K
| Adam | epoch: 006 | loss: 0.69618 - acc: 0.4800 -- iter: 064/192
[A[ATraining Step: 33  | total loss: [1m[32m0.69475[0m[0m | time: 2.598s
[2K
| Adam | epoch: 006 | loss: 0.69475 - acc: 0.5049 -- iter: 096/192
[A[ATraining Step: 34  | total loss: [1m[32m0.69440[0m[0m | time: 3.411s
[2K
| Adam | epoch: 006 | loss: 0.69440 - acc: 0.5039 -- iter: 128/192
[A[ATraining Step: 35  | total loss: [1m[32m0.69443[0m[0m | time: 4.233s
[2K
| Adam | epoch: 006 | loss: 0.69443 - acc: 0.4965 -- iter: 160/192
[A[ATraining Step: 36  | total loss: [1m[32m0.69441[0m[0m | time: 6.053s
[2K
| Adam | epoch: 006 | loss: 0.69441 - acc: 0.4908 | val_loss: 0.69411 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 37  | total loss: [1m[32m0.69391[0m[0m | time: 0.836s
[2K
| Adam | epoch: 007 | loss: 0.69391 - acc: 0.5052 -- iter: 032/192
[A[ATraining Step: 38  | total loss: [1m[32m0.69325[0m[0m | time: 1.641s
[2K
| Adam | epoch: 007 | loss: 0.69325 - acc: 0.5286 -- iter: 064/192
[A[ATraining Step: 39  | total loss: [1m[32m0.69336[0m[0m | time: 2.492s
[2K
| Adam | epoch: 007 | loss: 0.69336 - acc: 0.5172 -- iter: 096/192
[A[ATraining Step: 40  | total loss: [1m[32m0.69329[0m[0m | time: 3.337s
[2K
| Adam | epoch: 007 | loss: 0.69329 - acc: 0.5139 -- iter: 128/192
[A[ATraining Step: 41  | total loss: [1m[32m0.69387[0m[0m | time: 4.196s
[2K
| Adam | epoch: 007 | loss: 0.69387 - acc: 0.4827 -- iter: 160/192
[A[ATraining Step: 42  | total loss: [1m[32m0.69377[0m[0m | time: 6.018s
[2K
| Adam | epoch: 007 | loss: 0.69377 - acc: 0.4858 | val_loss: 0.69381 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 43  | total loss: [1m[32m0.69369[0m[0m | time: 0.772s
[2K
| Adam | epoch: 008 | loss: 0.69369 - acc: 0.4883 -- iter: 032/192
[A[ATraining Step: 44  | total loss: [1m[32m0.69319[0m[0m | time: 1.588s
[2K
| Adam | epoch: 008 | loss: 0.69319 - acc: 0.5174 -- iter: 064/192
[A[ATraining Step: 45  | total loss: [1m[32m0.69292[0m[0m | time: 2.406s
[2K
| Adam | epoch: 008 | loss: 0.69292 - acc: 0.5303 -- iter: 096/192
[A[ATraining Step: 46  | total loss: [1m[32m0.69306[0m[0m | time: 3.218s
[2K
| Adam | epoch: 008 | loss: 0.69306 - acc: 0.5201 -- iter: 128/192
[A[ATraining Step: 47  | total loss: [1m[32m0.69321[0m[0m | time: 4.069s
[2K
| Adam | epoch: 008 | loss: 0.69321 - acc: 0.5117 -- iter: 160/192
[A[ATraining Step: 48  | total loss: [1m[32m0.69304[0m[0m | time: 5.917s
[2K
| Adam | epoch: 008 | loss: 0.69304 - acc: 0.5198 | val_loss: 0.69397 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 49  | total loss: [1m[32m0.69314[0m[0m | time: 1.003s
[2K
| Adam | epoch: 009 | loss: 0.69314 - acc: 0.5118 -- iter: 032/192
[A[ATraining Step: 50  | total loss: [1m[32m0.69323[0m[0m | time: 1.857s
[2K
| Adam | epoch: 009 | loss: 0.69323 - acc: 0.5051 -- iter: 064/192
[A[ATraining Step: 51  | total loss: [1m[32m0.69313[0m[0m | time: 2.629s
[2K
| Adam | epoch: 009 | loss: 0.69313 - acc: 0.5091 -- iter: 096/192
[A[ATraining Step: 52  | total loss: [1m[32m0.69313[0m[0m | time: 3.483s
[2K
| Adam | epoch: 009 | loss: 0.69313 - acc: 0.5077 -- iter: 128/192
[A[ATraining Step: 53  | total loss: [1m[32m0.69314[0m[0m | time: 4.344s
[2K
| Adam | epoch: 009 | loss: 0.69314 - acc: 0.5066 -- iter: 160/192
[A[ATraining Step: 54  | total loss: [1m[32m0.69333[0m[0m | time: 6.186s
[2K
| Adam | epoch: 009 | loss: 0.69333 - acc: 0.4966 | val_loss: 0.69401 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 55  | total loss: [1m[32m0.69286[0m[0m | time: 0.946s
[2K
| Adam | epoch: 010 | loss: 0.69286 - acc: 0.5194 -- iter: 032/192
[A[ATraining Step: 56  | total loss: [1m[32m0.69291[0m[0m | time: 1.816s
[2K
| Adam | epoch: 010 | loss: 0.69291 - acc: 0.5166 -- iter: 064/192
[A[ATraining Step: 57  | total loss: [1m[32m0.69292[0m[0m | time: 2.514s
[2K
| Adam | epoch: 010 | loss: 0.69292 - acc: 0.5143 -- iter: 096/192
[A[ATraining Step: 58  | total loss: [1m[32m0.69296[0m[0m | time: 3.408s
[2K
| Adam | epoch: 010 | loss: 0.69296 - acc: 0.5124 -- iter: 128/192
[A[ATraining Step: 59  | total loss: [1m[32m0.69309[0m[0m | time: 4.229s
[2K
| Adam | epoch: 010 | loss: 0.69309 - acc: 0.5065 -- iter: 160/192
[A[ATraining Step: 60  | total loss: [1m[32m0.69348[0m[0m | time: 6.054s
[2K
| Adam | epoch: 010 | loss: 0.69348 - acc: 0.4891 | val_loss: 0.69404 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 61  | total loss: [1m[32m0.69317[0m[0m | time: 0.789s
[2K
| Adam | epoch: 011 | loss: 0.69317 - acc: 0.5028 -- iter: 032/192
[A[ATraining Step: 62  | total loss: [1m[32m0.69272[0m[0m | time: 1.766s
[2K
| Adam | epoch: 011 | loss: 0.69272 - acc: 0.5225 -- iter: 064/192
[A[ATraining Step: 63  | total loss: [1m[32m0.69256[0m[0m | time: 2.767s
[2K
| Adam | epoch: 011 | loss: 0.69256 - acc: 0.5276 -- iter: 096/192
[A[ATraining Step: 64  | total loss: [1m[32m0.69247[0m[0m | time: 3.518s
[2K
| Adam | epoch: 011 | loss: 0.69247 - acc: 0.5319 -- iter: 128/192
[A[ATraining Step: 65  | total loss: [1m[32m0.69276[0m[0m | time: 4.247s
[2K
| Adam | epoch: 011 | loss: 0.69276 - acc: 0.5203 -- iter: 160/192
[A[ATraining Step: 66  | total loss: [1m[32m0.69281[0m[0m | time: 6.059s
[2K
| Adam | epoch: 011 | loss: 0.69281 - acc: 0.5178 | val_loss: 0.69455 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 67  | total loss: [1m[32m0.69296[0m[0m | time: 0.831s
[2K
| Adam | epoch: 012 | loss: 0.69296 - acc: 0.5119 -- iter: 032/192
[A[ATraining Step: 68  | total loss: [1m[32m0.69261[0m[0m | time: 1.609s
[2K
| Adam | epoch: 012 | loss: 0.69261 - acc: 0.5216 -- iter: 064/192
[A[ATraining Step: 69  | total loss: [1m[32m0.69309[0m[0m | time: 2.437s
[2K
| Adam | epoch: 012 | loss: 0.69309 - acc: 0.5081 -- iter: 096/192
[A[ATraining Step: 70  | total loss: [1m[32m0.69269[0m[0m | time: 3.387s
[2K
| Adam | epoch: 012 | loss: 0.69269 - acc: 0.5180 -- iter: 128/192
[A[ATraining Step: 71  | total loss: [1m[32m0.69235[0m[0m | time: 4.340s
[2K
| Adam | epoch: 012 | loss: 0.69235 - acc: 0.5266 -- iter: 160/192
[A[ATraining Step: 72  | total loss: [1m[32m0.69227[0m[0m | time: 6.033s
[2K
| Adam | epoch: 012 | loss: 0.69227 - acc: 0.5272 | val_loss: 0.69559 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 73  | total loss: [1m[32m0.69235[0m[0m | time: 0.847s
[2K
| Adam | epoch: 013 | loss: 0.69235 - acc: 0.5241 -- iter: 032/192
[A[ATraining Step: 74  | total loss: [1m[32m0.69231[0m[0m | time: 1.725s
[2K
| Adam | epoch: 013 | loss: 0.69231 - acc: 0.5249 -- iter: 064/192
[A[ATraining Step: 75  | total loss: [1m[32m0.69196[0m[0m | time: 2.508s
[2K
| Adam | epoch: 013 | loss: 0.69196 - acc: 0.5290 -- iter: 096/192
[A[ATraining Step: 76  | total loss: [1m[32m0.69159[0m[0m | time: 3.491s
[2K
| Adam | epoch: 013 | loss: 0.69159 - acc: 0.5326 -- iter: 128/192
[A[ATraining Step: 77  | total loss: [1m[32m0.69244[0m[0m | time: 4.525s
[2K
| Adam | epoch: 013 | loss: 0.69244 - acc: 0.5225 -- iter: 160/192
[A[ATraining Step: 78  | total loss: [1m[32m0.69313[0m[0m | time: 6.347s
[2K
| Adam | epoch: 013 | loss: 0.69313 - acc: 0.5136 | val_loss: 0.69651 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 79  | total loss: [1m[32m0.69308[0m[0m | time: 0.881s
[2K
| Adam | epoch: 014 | loss: 0.69308 - acc: 0.5122 -- iter: 032/192
[A[ATraining Step: 80  | total loss: [1m[32m0.69302[0m[0m | time: 1.730s
[2K
| Adam | epoch: 014 | loss: 0.69302 - acc: 0.5110 -- iter: 064/192
[A[ATraining Step: 81  | total loss: [1m[32m0.69273[0m[0m | time: 2.621s
[2K
| Adam | epoch: 014 | loss: 0.69273 - acc: 0.5130 -- iter: 096/192
[A[ATraining Step: 82  | total loss: [1m[32m0.69367[0m[0m | time: 3.404s
[2K
| Adam | epoch: 014 | loss: 0.69367 - acc: 0.4961 -- iter: 128/192
[A[ATraining Step: 83  | total loss: [1m[32m0.69277[0m[0m | time: 4.594s
[2K
| Adam | epoch: 014 | loss: 0.69277 - acc: 0.5121 -- iter: 160/192
[A[ATraining Step: 84  | total loss: [1m[32m0.69214[0m[0m | time: 6.539s
[2K
| Adam | epoch: 014 | loss: 0.69214 - acc: 0.5234 | val_loss: 0.69595 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 85  | total loss: [1m[32m0.69148[0m[0m | time: 0.876s
[2K
| Adam | epoch: 015 | loss: 0.69148 - acc: 0.5336 -- iter: 032/192
[A[ATraining Step: 86  | total loss: [1m[32m0.69194[0m[0m | time: 1.761s
[2K
| Adam | epoch: 015 | loss: 0.69194 - acc: 0.5239 -- iter: 064/192
[A[ATraining Step: 87  | total loss: [1m[32m0.69179[0m[0m | time: 2.544s
[2K
| Adam | epoch: 015 | loss: 0.69179 - acc: 0.5247 -- iter: 096/192
[A[ATraining Step: 88  | total loss: [1m[32m0.69120[0m[0m | time: 3.394s
[2K
| Adam | epoch: 015 | loss: 0.69120 - acc: 0.5285 -- iter: 128/192
[A[ATraining Step: 89  | total loss: [1m[32m0.69045[0m[0m | time: 4.338s
[2K
| Adam | epoch: 015 | loss: 0.69045 - acc: 0.5350 -- iter: 160/192
[A[ATraining Step: 90  | total loss: [1m[32m0.69122[0m[0m | time: 6.319s
[2K
| Adam | epoch: 015 | loss: 0.69122 - acc: 0.5252 | val_loss: 0.69879 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 91  | total loss: [1m[32m0.69192[0m[0m | time: 0.910s
[2K
| Adam | epoch: 016 | loss: 0.69192 - acc: 0.5165 -- iter: 032/192
[A[ATraining Step: 92  | total loss: [1m[32m0.69237[0m[0m | time: 1.764s
[2K
| Adam | epoch: 016 | loss: 0.69237 - acc: 0.5086 -- iter: 064/192
[A[ATraining Step: 93  | total loss: [1m[32m0.69183[0m[0m | time: 2.607s
[2K
| Adam | epoch: 016 | loss: 0.69183 - acc: 0.5108 -- iter: 096/192
[A[ATraining Step: 94  | total loss: [1m[32m0.69284[0m[0m | time: 3.422s
[2K
| Adam | epoch: 016 | loss: 0.69284 - acc: 0.4973 -- iter: 128/192
[A[ATraining Step: 95  | total loss: [1m[32m0.69209[0m[0m | time: 4.405s
[2K
| Adam | epoch: 016 | loss: 0.69209 - acc: 0.5069 -- iter: 160/192
[A[ATraining Step: 96  | total loss: [1m[32m0.69184[0m[0m | time: 6.331s
[2K
| Adam | epoch: 016 | loss: 0.69184 - acc: 0.5062 | val_loss: 0.69784 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 97  | total loss: [1m[32m0.69098[0m[0m | time: 0.842s
[2K
| Adam | epoch: 017 | loss: 0.69098 - acc: 0.5087 -- iter: 032/192
[A[ATraining Step: 98  | total loss: [1m[32m0.68963[0m[0m | time: 1.705s
[2K
| Adam | epoch: 017 | loss: 0.68963 - acc: 0.5078 -- iter: 064/192
[A[ATraining Step: 99  | total loss: [1m[32m0.68777[0m[0m | time: 2.501s
[2K
| Adam | epoch: 017 | loss: 0.68777 - acc: 0.5071 -- iter: 096/192
[A[ATraining Step: 100  | total loss: [1m[32m0.68462[0m[0m | time: 3.276s
[2K
| Adam | epoch: 017 | loss: 0.68462 - acc: 0.5157 -- iter: 128/192
[A[ATraining Step: 101  | total loss: [1m[32m0.68603[0m[0m | time: 4.293s
[2K
| Adam | epoch: 017 | loss: 0.68603 - acc: 0.5142 -- iter: 160/192
[A[ATraining Step: 102  | total loss: [1m[32m0.68306[0m[0m | time: 6.268s
[2K
| Adam | epoch: 017 | loss: 0.68306 - acc: 0.5190 | val_loss: 0.68671 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 103  | total loss: [1m[32m0.68289[0m[0m | time: 0.824s
[2K
| Adam | epoch: 018 | loss: 0.68289 - acc: 0.5140 -- iter: 032/192
[A[ATraining Step: 104  | total loss: [1m[32m0.68220[0m[0m | time: 1.681s
[2K
| Adam | epoch: 018 | loss: 0.68220 - acc: 0.5188 -- iter: 064/192
[A[ATraining Step: 105  | total loss: [1m[32m0.67968[0m[0m | time: 2.678s
[2K
| Adam | epoch: 018 | loss: 0.67968 - acc: 0.5419 -- iter: 096/192
[A[ATraining Step: 106  | total loss: [1m[32m0.67332[0m[0m | time: 3.609s
[2K
| Adam | epoch: 018 | loss: 0.67332 - acc: 0.5596 -- iter: 128/192
[A[ATraining Step: 107  | total loss: [1m[32m0.67300[0m[0m | time: 4.347s
[2K
| Adam | epoch: 018 | loss: 0.67300 - acc: 0.5599 -- iter: 160/192
[A[ATraining Step: 108  | total loss: [1m[32m0.68056[0m[0m | time: 6.124s
[2K
| Adam | epoch: 018 | loss: 0.68056 - acc: 0.5508 | val_loss: 0.68161 - val_acc: 0.5246 -- iter: 192/192
--
Training Step: 109  | total loss: [1m[32m0.67425[0m[0m | time: 0.850s
[2K
| Adam | epoch: 019 | loss: 0.67425 - acc: 0.5645 -- iter: 032/192
[A[ATraining Step: 110  | total loss: [1m[32m0.67701[0m[0m | time: 1.692s
[2K
| Adam | epoch: 019 | loss: 0.67701 - acc: 0.5643 -- iter: 064/192
[A[ATraining Step: 111  | total loss: [1m[32m0.67041[0m[0m | time: 2.565s
[2K
| Adam | epoch: 019 | loss: 0.67041 - acc: 0.5797 -- iter: 096/192
[A[ATraining Step: 112  | total loss: [1m[32m0.66467[0m[0m | time: 3.356s
[2K
| Adam | epoch: 019 | loss: 0.66467 - acc: 0.5905 -- iter: 128/192
[A[ATraining Step: 113  | total loss: [1m[32m0.65025[0m[0m | time: 4.309s
[2K
| Adam | epoch: 019 | loss: 0.65025 - acc: 0.6189 -- iter: 160/192
[A[ATraining Step: 114  | total loss: [1m[32m0.65971[0m[0m | time: 6.305s
[2K
| Adam | epoch: 019 | loss: 0.65971 - acc: 0.6008 | val_loss: 0.75643 - val_acc: 0.4918 -- iter: 192/192
--
Training Step: 115  | total loss: [1m[32m0.65249[0m[0m | time: 0.830s
[2K
| Adam | epoch: 020 | loss: 0.65249 - acc: 0.6063 -- iter: 032/192
[A[ATraining Step: 116  | total loss: [1m[32m0.65090[0m[0m | time: 1.688s
[2K
| Adam | epoch: 020 | loss: 0.65090 - acc: 0.5988 -- iter: 064/192
[A[ATraining Step: 117  | total loss: [1m[32m0.64280[0m[0m | time: 2.581s
[2K
| Adam | epoch: 020 | loss: 0.64280 - acc: 0.6108 -- iter: 096/192
[A[ATraining Step: 118  | total loss: [1m[32m0.63284[0m[0m | time: 3.383s
[2K
| Adam | epoch: 020 | loss: 0.63284 - acc: 0.6247 -- iter: 128/192
[A[ATraining Step: 119  | total loss: [1m[32m0.63722[0m[0m | time: 4.223s
[2K
| Adam | epoch: 020 | loss: 0.63722 - acc: 0.6185 -- iter: 160/192
[A[ATraining Step: 120  | total loss: [1m[32m0.63593[0m[0m | time: 6.164s
[2K
| Adam | epoch: 020 | loss: 0.63593 - acc: 0.6223 | val_loss: 0.78466 - val_acc: 0.4754 -- iter: 192/192
--
Training Step: 121  | total loss: [1m[32m0.61893[0m[0m | time: 0.827s
[2K
| Adam | epoch: 021 | loss: 0.61893 - acc: 0.6351 -- iter: 032/192
[A[ATraining Step: 122  | total loss: [1m[32m0.60777[0m[0m | time: 1.735s
[2K
| Adam | epoch: 021 | loss: 0.60777 - acc: 0.6497 -- iter: 064/192
[A[ATraining Step: 123  | total loss: [1m[32m0.59924[0m[0m | time: 2.655s
[2K
| Adam | epoch: 021 | loss: 0.59924 - acc: 0.6566 -- iter: 096/192
[A[ATraining Step: 124  | total loss: [1m[32m0.57943[0m[0m | time: 3.534s
[2K
| Adam | epoch: 021 | loss: 0.57943 - acc: 0.6784 -- iter: 128/192
[A[ATraining Step: 125  | total loss: [1m[32m0.58129[0m[0m | time: 4.336s
[2K
| Adam | epoch: 021 | loss: 0.58129 - acc: 0.6731 -- iter: 160/192
[A[ATraining Step: 126  | total loss: [1m[32m0.56185[0m[0m | time: 6.131s
[2K
| Adam | epoch: 021 | loss: 0.56185 - acc: 0.6933 | val_loss: 0.93124 - val_acc: 0.4918 -- iter: 192/192
--
Training Step: 127  | total loss: [1m[32m0.54617[0m[0m | time: 0.799s
[2K
| Adam | epoch: 022 | loss: 0.54617 - acc: 0.7052 -- iter: 032/192
[A[ATraining Step: 128  | total loss: [1m[32m0.55886[0m[0m | time: 1.668s
[2K
| Adam | epoch: 022 | loss: 0.55886 - acc: 0.6941 -- iter: 064/192
[A[ATraining Step: 129  | total loss: [1m[32m0.54146[0m[0m | time: 2.548s
[2K
| Adam | epoch: 022 | loss: 0.54146 - acc: 0.7090 -- iter: 096/192
[A[ATraining Step: 130  | total loss: [1m[32m0.55495[0m[0m | time: 3.412s
[2K
| Adam | epoch: 022 | loss: 0.55495 - acc: 0.7037 -- iter: 128/192
[A[ATraining Step: 131  | total loss: [1m[32m0.54098[0m[0m | time: 4.195s
[2K
| Adam | epoch: 022 | loss: 0.54098 - acc: 0.7177 -- iter: 160/192
[A[ATraining Step: 132  | total loss: [1m[32m0.52846[0m[0m | time: 6.173s
[2K
| Adam | epoch: 022 | loss: 0.52846 - acc: 0.7272 | val_loss: 0.88442 - val_acc: 0.5082 -- iter: 192/192
--
Training Step: 133  | total loss: [1m[32m0.53214[0m[0m | time: 0.826s
[2K
| Adam | epoch: 023 | loss: 0.53214 - acc: 0.7264 -- iter: 032/192
[A[ATraining Step: 134  | total loss: [1m[32m0.53531[0m[0m | time: 1.693s
[2K
| Adam | epoch: 023 | loss: 0.53531 - acc: 0.7225 -- iter: 064/192
[A[ATraining Step: 135  | total loss: [1m[32m0.51084[0m[0m | time: 2.537s
[2K
| Adam | epoch: 023 | loss: 0.51084 - acc: 0.7409 -- iter: 096/192
[A[ATraining Step: 136  | total loss: [1m[32m0.50663[0m[0m | time: 3.405s
[2K
| Adam | epoch: 023 | loss: 0.50663 - acc: 0.7449 -- iter: 128/192
[A[ATraining Step: 137  | total loss: [1m[32m0.49040[0m[0m | time: 4.278s
[2K
| Adam | epoch: 023 | loss: 0.49040 - acc: 0.7610 -- iter: 160/192
[A[ATraining Step: 138  | total loss: [1m[32m0.48527[0m[0m | time: 6.084s
[2K
| Adam | epoch: 023 | loss: 0.48527 - acc: 0.7693 | val_loss: 0.74467 - val_acc: 0.6885 -- iter: 192/192
--
Training Step: 139  | total loss: [1m[32m0.46738[0m[0m | time: 0.873s
[2K
| Adam | epoch: 024 | loss: 0.46738 - acc: 0.7861 -- iter: 032/192
[A[ATraining Step: 140  | total loss: [1m[32m0.45633[0m[0m | time: 1.727s
[2K
| Adam | epoch: 024 | loss: 0.45633 - acc: 0.7950 -- iter: 064/192
[A[ATraining Step: 141  | total loss: [1m[32m0.44083[0m[0m | time: 2.580s
[2K
| Adam | epoch: 024 | loss: 0.44083 - acc: 0.8061 -- iter: 096/192
[A[ATraining Step: 142  | total loss: [1m[32m0.45055[0m[0m | time: 3.445s
[2K
| Adam | epoch: 024 | loss: 0.45055 - acc: 0.8036 -- iter: 128/192
[A[ATraining Step: 143  | total loss: [1m[32m0.44035[0m[0m | time: 4.242s
[2K
| Adam | epoch: 024 | loss: 0.44035 - acc: 0.8108 -- iter: 160/192
[A[ATraining Step: 144  | total loss: [1m[32m0.42685[0m[0m | time: 6.126s
[2K
| Adam | epoch: 024 | loss: 0.42685 - acc: 0.8203 | val_loss: 0.87936 - val_acc: 0.5410 -- iter: 192/192
--
Training Step: 145  | total loss: [1m[32m0.41171[0m[0m | time: 0.839s
[2K
| Adam | epoch: 025 | loss: 0.41171 - acc: 0.8258 -- iter: 032/192
[A[ATraining Step: 146  | total loss: [1m[32m0.41043[0m[0m | time: 1.690s
[2K
| Adam | epoch: 025 | loss: 0.41043 - acc: 0.8276 -- iter: 064/192
[A[ATraining Step: 147  | total loss: [1m[32m0.40519[0m[0m | time: 2.482s
[2K
| Adam | epoch: 025 | loss: 0.40519 - acc: 0.8261 -- iter: 096/192
[A[ATraining Step: 148  | total loss: [1m[32m0.39933[0m[0m | time: 3.386s
[2K
| Adam | epoch: 025 | loss: 0.39933 - acc: 0.8279 -- iter: 128/192
[A[ATraining Step: 149  | total loss: [1m[32m0.37723[0m[0m | time: 4.234s
[2K
| Adam | epoch: 025 | loss: 0.37723 - acc: 0.8419 -- iter: 160/192
[A[ATraining Step: 150  | total loss: [1m[32m0.36957[0m[0m | time: 6.146s
[2K
| Adam | epoch: 025 | loss: 0.36957 - acc: 0.8452 | val_loss: 0.94689 - val_acc: 0.6230 -- iter: 192/192
--
Training Step: 151  | total loss: [1m[32m0.34487[0m[0m | time: 0.867s
[2K
| Adam | epoch: 026 | loss: 0.34487 - acc: 0.8576 -- iter: 032/192
[A[ATraining Step: 152  | total loss: [1m[32m0.33174[0m[0m | time: 1.726s
[2K
| Adam | epoch: 026 | loss: 0.33174 - acc: 0.8656 -- iter: 064/192
[A[ATraining Step: 153  | total loss: [1m[32m0.31555[0m[0m | time: 2.572s
[2K
| Adam | epoch: 026 | loss: 0.31555 - acc: 0.8728 -- iter: 096/192
[A[ATraining Step: 154  | total loss: [1m[32m0.32196[0m[0m | time: 3.406s
[2K
| Adam | epoch: 026 | loss: 0.32196 - acc: 0.8699 -- iter: 128/192
[A[ATraining Step: 155  | total loss: [1m[32m0.31950[0m[0m | time: 4.235s
[2K
| Adam | epoch: 026 | loss: 0.31950 - acc: 0.8735 -- iter: 160/192
[A[ATraining Step: 156  | total loss: [1m[32m0.31339[0m[0m | time: 6.100s
[2K
| Adam | epoch: 026 | loss: 0.31339 - acc: 0.8737 | val_loss: 1.09006 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 157  | total loss: [1m[32m0.30594[0m[0m | time: 0.874s
[2K
| Adam | epoch: 027 | loss: 0.30594 - acc: 0.8800 -- iter: 032/192
[A[ATraining Step: 158  | total loss: [1m[32m0.28724[0m[0m | time: 1.774s
[2K
| Adam | epoch: 027 | loss: 0.28724 - acc: 0.8889 -- iter: 064/192
[A[ATraining Step: 159  | total loss: [1m[32m0.28111[0m[0m | time: 2.641s
[2K
| Adam | epoch: 027 | loss: 0.28111 - acc: 0.8875 -- iter: 096/192
[A[ATraining Step: 160  | total loss: [1m[32m0.27697[0m[0m | time: 3.500s
[2K
| Adam | epoch: 027 | loss: 0.27697 - acc: 0.8894 -- iter: 128/192
[A[ATraining Step: 161  | total loss: [1m[32m0.26211[0m[0m | time: 4.332s
[2K
| Adam | epoch: 027 | loss: 0.26211 - acc: 0.8973 -- iter: 160/192
[A[ATraining Step: 162  | total loss: [1m[32m0.24657[0m[0m | time: 6.230s
[2K
| Adam | epoch: 027 | loss: 0.24657 - acc: 0.9076 | val_loss: 1.21533 - val_acc: 0.6230 -- iter: 192/192
--
Training Step: 163  | total loss: [1m[32m0.24141[0m[0m | time: 0.871s
[2K
| Adam | epoch: 028 | loss: 0.24141 - acc: 0.9106 -- iter: 032/192
[A[ATraining Step: 164  | total loss: [1m[32m0.25564[0m[0m | time: 1.720s
[2K
| Adam | epoch: 028 | loss: 0.25564 - acc: 0.9039 -- iter: 064/192
[A[ATraining Step: 165  | total loss: [1m[32m0.25833[0m[0m | time: 2.580s
[2K
| Adam | epoch: 028 | loss: 0.25833 - acc: 0.9073 -- iter: 096/192
[A[ATraining Step: 166  | total loss: [1m[32m0.23794[0m[0m | time: 3.503s
[2K
| Adam | epoch: 028 | loss: 0.23794 - acc: 0.9165 -- iter: 128/192
[A[ATraining Step: 167  | total loss: [1m[32m0.21786[0m[0m | time: 4.342s
[2K
| Adam | epoch: 028 | loss: 0.21786 - acc: 0.9249 -- iter: 160/192
[A[ATraining Step: 168  | total loss: [1m[32m0.20576[0m[0m | time: 6.161s
[2K
| Adam | epoch: 028 | loss: 0.20576 - acc: 0.9293 | val_loss: 1.30510 - val_acc: 0.6557 -- iter: 192/192
--
Training Step: 169  | total loss: [1m[32m0.19240[0m[0m | time: 0.919s
[2K
| Adam | epoch: 029 | loss: 0.19240 - acc: 0.9332 -- iter: 032/192
[A[ATraining Step: 170  | total loss: [1m[32m0.18718[0m[0m | time: 1.747s
[2K
| Adam | epoch: 029 | loss: 0.18718 - acc: 0.9305 -- iter: 064/192
[A[ATraining Step: 171  | total loss: [1m[32m0.19112[0m[0m | time: 2.572s
[2K
| Adam | epoch: 029 | loss: 0.19112 - acc: 0.9312 -- iter: 096/192
[A[ATraining Step: 172  | total loss: [1m[32m0.17644[0m[0m | time: 3.442s
[2K
| Adam | epoch: 029 | loss: 0.17644 - acc: 0.9381 -- iter: 128/192
[A[ATraining Step: 173  | total loss: [1m[32m0.18041[0m[0m | time: 4.300s
[2K
| Adam | epoch: 029 | loss: 0.18041 - acc: 0.9318 -- iter: 160/192
[A[ATraining Step: 174  | total loss: [1m[32m0.17432[0m[0m | time: 6.147s
[2K
| Adam | epoch: 029 | loss: 0.17432 - acc: 0.9355 | val_loss: 1.56158 - val_acc: 0.6230 -- iter: 192/192
--
Training Step: 175  | total loss: [1m[32m0.17785[0m[0m | time: 0.787s
[2K
| Adam | epoch: 030 | loss: 0.17785 - acc: 0.9326 -- iter: 032/192
[A[ATraining Step: 176  | total loss: [1m[32m0.17422[0m[0m | time: 1.633s
[2K
| Adam | epoch: 030 | loss: 0.17422 - acc: 0.9331 -- iter: 064/192
[A[ATraining Step: 177  | total loss: [1m[32m0.16586[0m[0m | time: 2.482s
[2K
| Adam | epoch: 030 | loss: 0.16586 - acc: 0.9366 -- iter: 096/192
[A[ATraining Step: 178  | total loss: [1m[32m0.19287[0m[0m | time: 3.309s
[2K
| Adam | epoch: 030 | loss: 0.19287 - acc: 0.9273 -- iter: 128/192
[A[ATraining Step: 179  | total loss: [1m[32m0.22093[0m[0m | time: 4.158s
[2K
| Adam | epoch: 030 | loss: 0.22093 - acc: 0.9159 -- iter: 160/192
[A[ATraining Step: 180  | total loss: [1m[32m0.23151[0m[0m | time: 6.033s
[2K
| Adam | epoch: 030 | loss: 0.23151 - acc: 0.9149 | val_loss: 1.66572 - val_acc: 0.5574 -- iter: 192/192
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.6655844155844156
Validation AUPRC:0.6219758366342508
Test AUC:0.6745689655172414
Test AUPRC:0.6253341159551202
BestTestF1Score	0.67	0.37	0.69	0.68	0.66	19	9	23	10	0.01
BestTestMCCScore	0.67	0.37	0.69	0.68	0.66	19	9	23	10	0.01
BestTestAccuracyScore	0.67	0.37	0.69	0.68	0.66	19	9	23	10	0.02
BestValidationF1Score	0.7	0.42	0.7	0.66	0.75	21	11	22	7	0.01
BestValidationMCC	0.7	0.42	0.7	0.66	0.75	21	11	22	7	0.01
BestValidationAccuracy	0.69	0.41	0.7	0.67	0.71	20	10	23	8	0.02
TestPredictions (Threshold:0.01)
CHEMBL412711,TP,ACT,0.12999999523162842	CHEMBL3394519,TN,INACT,0.0	CHEMBL199600,TN,INACT,0.0	CHEMBL3770333,TN,INACT,0.0	CHEMBL1939857,TP,ACT,0.12999999523162842	CHEMBL2178433,TP,ACT,0.949999988079071	CHEMBL17562,FN,ACT,0.009999999776482582	CHEMBL457235,FN,ACT,0.009999999776482582	CHEMBL2178430,TP,ACT,0.7799999713897705	CHEMBL460828,FP,INACT,0.5099999904632568	CHEMBL374237,TP,ACT,0.9700000286102295	CHEMBL1242965,TN,INACT,0.0	CHEMBL2178438,TP,ACT,0.9399999976158142	CHEMBL354639,TP,ACT,0.029999999329447746	CHEMBL50,TN,INACT,0.0	CHEMBL2178440,TP,ACT,0.6100000143051147	CHEMBL1830139,TN,INACT,0.009999999776482582	CHEMBL499266,TN,INACT,0.009999999776482582	CHEMBL2178429,TP,ACT,0.5699999928474426	CHEMBL1830796,TN,INACT,0.0	CHEMBL447022,FN,ACT,0.0	CHEMBL489084,FP,INACT,0.15000000596046448	CHEMBL2058407,TN,INACT,0.0	CHEMBL220677,FP,INACT,0.800000011920929	CHEMBL1830809,TN,INACT,0.0	CHEMBL1814055,FP,INACT,0.1899999976158142	CHEMBL523765,FN,ACT,0.0	CHEMBL1939856,FP,INACT,0.699999988079071	CHEMBL462097,TP,ACT,0.3400000035762787	CHEMBL3134340,FP,INACT,0.9900000095367432	CHEMBL511967,TN,INACT,0.0	CHEMBL3655328,TN,INACT,0.0	CHEMBL3651587,TN,INACT,0.0	CHEMBL186576,TN,INACT,0.0	CHEMBL375415,TP,ACT,0.7900000214576721	CHEMBL972,FN,ACT,0.0	CHEMBL460609,FN,ACT,0.009999999776482582	CHEMBL170647,FP,INACT,0.03999999910593033	CHEMBL3740100,FP,INACT,0.10000000149011612	CHEMBL1939854,TN,INACT,0.0	CHEMBL475885,TN,INACT,0.0	CHEMBL212069,TP,ACT,0.07999999821186066	CHEMBL466769,TN,INACT,0.0	CHEMBL1946643,TN,INACT,0.0	CHEMBL389728,TP,ACT,0.1599999964237213	CHEMBL508959,TP,ACT,0.05999999865889549	CHEMBL39537,FN,ACT,0.0	CHEMBL515250,TN,INACT,0.0	CHEMBL3261200,FP,INACT,0.9300000071525574	CHEMBL456107,TP,ACT,0.20999999344348907	CHEMBL435101,TN,INACT,0.0	CHEMBL186191,TN,INACT,0.0	CHEMBL1777849,TN,INACT,0.009999999776482582	CHEMBL464597,FN,ACT,0.0	CHEMBL221392,TP,ACT,0.46000000834465027	CHEMBL3771277,TN,INACT,0.0	CHEMBL515237,FN,ACT,0.0	CHEMBL224191,TP,ACT,0.10000000149011612	CHEMBL457422,TP,ACT,0.20000000298023224	CHEMBL387736,TP,ACT,0.6600000262260437	CHEMBL65135,FN,ACT,0.0	

