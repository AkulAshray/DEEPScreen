CNNModel CHEMBL4561 RMSprop 0.0005 30 256 0 0.6 False True
Number of active compounds :	987
Number of inactive compounds :	987
---------------------------------
Run id: CNNModel_CHEMBL4561_RMSprop_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4561_RMSprop_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 1257
Validation samples: 394
--
Training Step: 1  | time: 1.258s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1257
[A[ATraining Step: 2  | total loss: [1m[32m0.62351[0m[0m | time: 2.120s
[2K
| RMSProp | epoch: 001 | loss: 0.62351 - acc: 0.4500 -- iter: 0064/1257
[A[ATraining Step: 3  | total loss: [1m[32m0.68085[0m[0m | time: 3.028s
[2K
| RMSProp | epoch: 001 | loss: 0.68085 - acc: 0.3375 -- iter: 0096/1257
[A[ATraining Step: 4  | total loss: [1m[32m0.69033[0m[0m | time: 3.914s
[2K
| RMSProp | epoch: 001 | loss: 0.69033 - acc: 0.3891 -- iter: 0128/1257
[A[ATraining Step: 5  | total loss: [1m[32m0.69248[0m[0m | time: 4.847s
[2K
| RMSProp | epoch: 001 | loss: 0.69248 - acc: 0.4010 -- iter: 0160/1257
[A[ATraining Step: 6  | total loss: [1m[32m0.69302[0m[0m | time: 5.896s
[2K
| RMSProp | epoch: 001 | loss: 0.69302 - acc: 0.4646 -- iter: 0192/1257
[A[ATraining Step: 7  | total loss: [1m[32m0.69294[0m[0m | time: 6.889s
[2K
| RMSProp | epoch: 001 | loss: 0.69294 - acc: 0.5421 -- iter: 0224/1257
[A[ATraining Step: 8  | total loss: [1m[32m0.69317[0m[0m | time: 7.840s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4657 -- iter: 0256/1257
[A[ATraining Step: 9  | total loss: [1m[32m0.69309[0m[0m | time: 8.926s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.4673 -- iter: 0288/1257
[A[ATraining Step: 10  | total loss: [1m[32m0.69324[0m[0m | time: 10.001s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4680 -- iter: 0320/1257
[A[ATraining Step: 11  | total loss: [1m[32m0.69300[0m[0m | time: 10.902s
[2K
| RMSProp | epoch: 001 | loss: 0.69300 - acc: 0.5276 -- iter: 0352/1257
[A[ATraining Step: 12  | total loss: [1m[32m0.69318[0m[0m | time: 11.765s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4589 -- iter: 0384/1257
[A[ATraining Step: 13  | total loss: [1m[32m0.69324[0m[0m | time: 12.648s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4363 -- iter: 0416/1257
[A[ATraining Step: 14  | total loss: [1m[32m0.69306[0m[0m | time: 13.540s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5135 -- iter: 0448/1257
[A[ATraining Step: 15  | total loss: [1m[32m0.69306[0m[0m | time: 14.435s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5082 -- iter: 0480/1257
[A[ATraining Step: 16  | total loss: [1m[32m0.69332[0m[0m | time: 15.403s
[2K
| RMSProp | epoch: 001 | loss: 0.69332 - acc: 0.4348 -- iter: 0512/1257
[A[ATraining Step: 17  | total loss: [1m[32m0.69321[0m[0m | time: 16.379s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.5033 -- iter: 0544/1257
[A[ATraining Step: 18  | total loss: [1m[32m0.69319[0m[0m | time: 17.280s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4805 -- iter: 0576/1257
[A[ATraining Step: 19  | total loss: [1m[32m0.69323[0m[0m | time: 18.271s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4662 -- iter: 0608/1257
[A[ATraining Step: 20  | total loss: [1m[32m0.69327[0m[0m | time: 19.256s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.4469 -- iter: 0640/1257
[A[ATraining Step: 21  | total loss: [1m[32m0.69331[0m[0m | time: 20.283s
[2K
| RMSProp | epoch: 001 | loss: 0.69331 - acc: 0.4246 -- iter: 0672/1257
[A[ATraining Step: 22  | total loss: [1m[32m0.69333[0m[0m | time: 21.064s
[2K
| RMSProp | epoch: 001 | loss: 0.69333 - acc: 0.4285 -- iter: 0704/1257
[A[ATraining Step: 23  | total loss: [1m[32m0.69330[0m[0m | time: 21.924s
[2K
| RMSProp | epoch: 001 | loss: 0.69330 - acc: 0.4674 -- iter: 0736/1257
[A[ATraining Step: 24  | total loss: [1m[32m0.69319[0m[0m | time: 22.784s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.5029 -- iter: 0768/1257
[A[ATraining Step: 25  | total loss: [1m[32m0.69310[0m[0m | time: 23.629s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5362 -- iter: 0800/1257
[A[ATraining Step: 26  | total loss: [1m[32m0.69313[0m[0m | time: 24.491s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5266 -- iter: 0832/1257
[A[ATraining Step: 27  | total loss: [1m[32m0.69310[0m[0m | time: 25.469s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5198 -- iter: 0864/1257
[A[ATraining Step: 28  | total loss: [1m[32m0.69318[0m[0m | time: 26.450s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4680 -- iter: 0896/1257
[A[ATraining Step: 29  | total loss: [1m[32m0.69317[0m[0m | time: 27.295s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4986 -- iter: 0928/1257
[A[ATraining Step: 30  | total loss: [1m[32m0.69317[0m[0m | time: 28.305s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4841 -- iter: 0960/1257
[A[ATraining Step: 31  | total loss: [1m[32m0.69324[0m[0m | time: 29.341s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4517 -- iter: 0992/1257
[A[ATraining Step: 32  | total loss: [1m[32m0.69327[0m[0m | time: 30.264s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.4344 -- iter: 1024/1257
[A[ATraining Step: 33  | total loss: [1m[32m0.69323[0m[0m | time: 31.058s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4351 -- iter: 1056/1257
[A[ATraining Step: 34  | total loss: [1m[32m0.69325[0m[0m | time: 31.953s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4490 -- iter: 1088/1257
[A[ATraining Step: 35  | total loss: [1m[32m0.69323[0m[0m | time: 32.874s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4793 -- iter: 1120/1257
[A[ATraining Step: 36  | total loss: [1m[32m0.69319[0m[0m | time: 33.738s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4899 -- iter: 1152/1257
[A[ATraining Step: 37  | total loss: [1m[32m0.69320[0m[0m | time: 34.671s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4669 -- iter: 1184/1257
[A[ATraining Step: 38  | total loss: [1m[32m0.69319[0m[0m | time: 35.690s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4551 -- iter: 1216/1257
[A[ATraining Step: 39  | total loss: [1m[32m0.69325[0m[0m | time: 36.623s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4278 -- iter: 1248/1257
[A[ATraining Step: 40  | total loss: [1m[32m0.69325[0m[0m | time: 38.783s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4472 | val_loss: 0.69312 - val_acc: 0.5076 -- iter: 1257/1257
--
Training Step: 41  | total loss: [1m[32m0.69318[0m[0m | time: 0.359s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4671 -- iter: 0032/1257
[A[ATraining Step: 42  | total loss: [1m[32m0.69318[0m[0m | time: 1.194s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.5030 -- iter: 0064/1257
[A[ATraining Step: 43  | total loss: [1m[32m0.69317[0m[0m | time: 2.030s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.5080 -- iter: 0096/1257
[A[ATraining Step: 44  | total loss: [1m[32m0.69314[0m[0m | time: 2.969s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.5282 -- iter: 0128/1257
[A[ATraining Step: 45  | total loss: [1m[32m0.69311[0m[0m | time: 3.938s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5234 -- iter: 0160/1257
[A[ATraining Step: 46  | total loss: [1m[32m0.69304[0m[0m | time: 4.886s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5404 -- iter: 0192/1257
[A[ATraining Step: 47  | total loss: [1m[32m0.69310[0m[0m | time: 5.876s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5184 -- iter: 0224/1257
[A[ATraining Step: 48  | total loss: [1m[32m0.69309[0m[0m | time: 6.830s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5255 -- iter: 0256/1257
[A[ATraining Step: 49  | total loss: [1m[32m0.69311[0m[0m | time: 7.722s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5116 -- iter: 0288/1257
[A[ATraining Step: 50  | total loss: [1m[32m0.69311[0m[0m | time: 8.796s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5195 -- iter: 0320/1257
[A[ATraining Step: 51  | total loss: [1m[32m0.69311[0m[0m | time: 9.859s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5261 -- iter: 0352/1257
[A[ATraining Step: 52  | total loss: [1m[32m0.69317[0m[0m | time: 10.659s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.5128 -- iter: 0384/1257
[A[ATraining Step: 53  | total loss: [1m[32m0.69319[0m[0m | time: 11.460s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4971 -- iter: 0416/1257
[A[ATraining Step: 54  | total loss: [1m[32m0.69315[0m[0m | time: 12.333s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5111 -- iter: 0448/1257
[A[ATraining Step: 55  | total loss: [1m[32m0.69317[0m[0m | time: 13.199s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4961 -- iter: 0480/1257
[A[ATraining Step: 56  | total loss: [1m[32m0.69310[0m[0m | time: 14.062s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5230 -- iter: 0512/1257
[A[ATraining Step: 57  | total loss: [1m[32m0.69313[0m[0m | time: 14.995s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5155 -- iter: 0544/1257
[A[ATraining Step: 58  | total loss: [1m[32m0.69312[0m[0m | time: 16.015s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5049 -- iter: 0576/1257
[A[ATraining Step: 59  | total loss: [1m[32m0.69311[0m[0m | time: 16.872s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5042 -- iter: 0608/1257
[A[ATraining Step: 60  | total loss: [1m[32m0.69315[0m[0m | time: 17.857s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4954 -- iter: 0640/1257
[A[ATraining Step: 61  | total loss: [1m[32m0.69314[0m[0m | time: 18.877s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4919 -- iter: 0672/1257
[A[ATraining Step: 62  | total loss: [1m[32m0.69307[0m[0m | time: 19.896s
[2K
| RMSProp | epoch: 002 | loss: 0.69307 - acc: 0.5130 -- iter: 0704/1257
[A[ATraining Step: 63  | total loss: [1m[32m0.69310[0m[0m | time: 20.643s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5114 -- iter: 0736/1257
[A[ATraining Step: 64  | total loss: [1m[32m0.69305[0m[0m | time: 21.556s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5295 -- iter: 0768/1257
[A[ATraining Step: 65  | total loss: [1m[32m0.69297[0m[0m | time: 22.420s
[2K
| RMSProp | epoch: 002 | loss: 0.69297 - acc: 0.5451 -- iter: 0800/1257
[A[ATraining Step: 66  | total loss: [1m[32m0.69315[0m[0m | time: 23.287s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5206 -- iter: 0832/1257
[A[ATraining Step: 67  | total loss: [1m[32m0.69313[0m[0m | time: 24.162s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5182 -- iter: 0864/1257
[A[ATraining Step: 68  | total loss: [1m[32m0.69329[0m[0m | time: 25.170s
[2K
| RMSProp | epoch: 002 | loss: 0.69329 - acc: 0.4938 -- iter: 0896/1257
[A[ATraining Step: 69  | total loss: [1m[32m0.69331[0m[0m | time: 26.090s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4763 -- iter: 0928/1257
[A[ATraining Step: 70  | total loss: [1m[32m0.69328[0m[0m | time: 26.923s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4898 -- iter: 0960/1257
[A[ATraining Step: 71  | total loss: [1m[32m0.69330[0m[0m | time: 27.998s
[2K
| RMSProp | epoch: 002 | loss: 0.69330 - acc: 0.4945 -- iter: 0992/1257
[A[ATraining Step: 72  | total loss: [1m[32m0.69330[0m[0m | time: 29.123s
[2K
| RMSProp | epoch: 002 | loss: 0.69330 - acc: 0.4952 -- iter: 1024/1257
[A[ATraining Step: 73  | total loss: [1m[32m0.69327[0m[0m | time: 29.956s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.4922 -- iter: 1056/1257
[A[ATraining Step: 74  | total loss: [1m[32m0.69328[0m[0m | time: 30.793s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4794 -- iter: 1088/1257
[A[ATraining Step: 75  | total loss: [1m[32m0.69328[0m[0m | time: 31.676s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4748 -- iter: 1120/1257
[A[ATraining Step: 76  | total loss: [1m[32m0.69325[0m[0m | time: 32.582s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4742 -- iter: 1152/1257
[A[ATraining Step: 77  | total loss: [1m[32m0.69322[0m[0m | time: 33.459s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4868 -- iter: 1184/1257
[A[ATraining Step: 78  | total loss: [1m[32m0.69321[0m[0m | time: 34.476s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4980 -- iter: 1216/1257
[A[ATraining Step: 79  | total loss: [1m[32m0.69320[0m[0m | time: 35.459s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.5047 -- iter: 1248/1257
[A[ATraining Step: 80  | total loss: [1m[32m0.69322[0m[0m | time: 38.204s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.5042 | val_loss: 0.69311 - val_acc: 0.4924 -- iter: 1257/1257
--
Training Step: 81  | total loss: [1m[32m0.69327[0m[0m | time: 0.346s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.4943 -- iter: 0032/1257
[A[ATraining Step: 82  | total loss: [1m[32m0.69324[0m[0m | time: 0.698s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.5004 -- iter: 0064/1257
[A[ATraining Step: 83  | total loss: [1m[32m0.69326[0m[0m | time: 1.468s
[2K
| RMSProp | epoch: 003 | loss: 0.69326 - acc: 0.4948 -- iter: 0096/1257
[A[ATraining Step: 84  | total loss: [1m[32m0.69322[0m[0m | time: 2.326s
[2K
| RMSProp | epoch: 003 | loss: 0.69322 - acc: 0.5078 -- iter: 0128/1257
[A[ATraining Step: 85  | total loss: [1m[32m0.69318[0m[0m | time: 3.237s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.5133 -- iter: 0160/1257
[A[ATraining Step: 86  | total loss: [1m[32m0.69319[0m[0m | time: 4.188s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5057 -- iter: 0192/1257
[A[ATraining Step: 87  | total loss: [1m[32m0.69312[0m[0m | time: 5.132s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5145 -- iter: 0224/1257
[A[ATraining Step: 88  | total loss: [1m[32m0.69316[0m[0m | time: 6.181s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.5068 -- iter: 0256/1257
[A[ATraining Step: 89  | total loss: [1m[32m0.69322[0m[0m | time: 7.115s
[2K
| RMSProp | epoch: 003 | loss: 0.69322 - acc: 0.5030 -- iter: 0288/1257
[A[ATraining Step: 90  | total loss: [1m[32m0.69323[0m[0m | time: 7.961s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.5027 -- iter: 0320/1257
[A[ATraining Step: 91  | total loss: [1m[32m0.69320[0m[0m | time: 8.956s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.5056 -- iter: 0352/1257
[A[ATraining Step: 92  | total loss: [1m[32m0.69319[0m[0m | time: 10.034s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5019 -- iter: 0384/1257
[A[ATraining Step: 93  | total loss: [1m[32m0.69324[0m[0m | time: 10.871s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.4892 -- iter: 0416/1257
[A[ATraining Step: 94  | total loss: [1m[32m0.69321[0m[0m | time: 11.712s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4840 -- iter: 0448/1257
[A[ATraining Step: 95  | total loss: [1m[32m0.69327[0m[0m | time: 12.615s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.4731 -- iter: 0480/1257
[A[ATraining Step: 96  | total loss: [1m[32m0.69327[0m[0m | time: 13.549s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.4727 -- iter: 0512/1257
[A[ATraining Step: 97  | total loss: [1m[32m0.69321[0m[0m | time: 14.462s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4848 -- iter: 0544/1257
[A[ATraining Step: 98  | total loss: [1m[32m0.69327[0m[0m | time: 15.488s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.4801 -- iter: 0576/1257
[A[ATraining Step: 99  | total loss: [1m[32m0.69331[0m[0m | time: 16.469s
[2K
| RMSProp | epoch: 003 | loss: 0.69331 - acc: 0.4758 -- iter: 0608/1257
[A[ATraining Step: 100  | total loss: [1m[32m0.69326[0m[0m | time: 17.228s
[2K
| RMSProp | epoch: 003 | loss: 0.69326 - acc: 0.4939 -- iter: 0640/1257
[A[ATraining Step: 101  | total loss: [1m[32m0.69322[0m[0m | time: 18.278s
[2K
| RMSProp | epoch: 003 | loss: 0.69322 - acc: 0.4976 -- iter: 0672/1257
[A[ATraining Step: 102  | total loss: [1m[32m0.69317[0m[0m | time: 19.339s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.5041 -- iter: 0704/1257
[A[ATraining Step: 103  | total loss: [1m[32m0.69322[0m[0m | time: 20.226s
[2K
| RMSProp | epoch: 003 | loss: 0.69322 - acc: 0.5006 -- iter: 0736/1257
[A[ATraining Step: 104  | total loss: [1m[32m0.69346[0m[0m | time: 21.024s
[2K
| RMSProp | epoch: 003 | loss: 0.69346 - acc: 0.4755 -- iter: 0768/1257
[A[ATraining Step: 105  | total loss: [1m[32m0.69339[0m[0m | time: 21.909s
[2K
| RMSProp | epoch: 003 | loss: 0.69339 - acc: 0.4811 -- iter: 0800/1257
[A[ATraining Step: 106  | total loss: [1m[32m0.69339[0m[0m | time: 22.796s
[2K
| RMSProp | epoch: 003 | loss: 0.69339 - acc: 0.4798 -- iter: 0832/1257
[A[ATraining Step: 107  | total loss: [1m[32m0.69334[0m[0m | time: 23.672s
[2K
| RMSProp | epoch: 003 | loss: 0.69334 - acc: 0.4881 -- iter: 0864/1257
[A[ATraining Step: 108  | total loss: [1m[32m0.69336[0m[0m | time: 24.598s
[2K
| RMSProp | epoch: 003 | loss: 0.69336 - acc: 0.4830 -- iter: 0896/1257
[A[ATraining Step: 109  | total loss: [1m[32m0.69331[0m[0m | time: 25.612s
[2K
| RMSProp | epoch: 003 | loss: 0.69331 - acc: 0.4847 -- iter: 0928/1257
[A[ATraining Step: 110  | total loss: [1m[32m0.69325[0m[0m | time: 26.557s
[2K
| RMSProp | epoch: 003 | loss: 0.69325 - acc: 0.4863 -- iter: 0960/1257
[A[ATraining Step: 111  | total loss: [1m[32m0.69323[0m[0m | time: 27.461s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4876 -- iter: 0992/1257
[A[ATraining Step: 112  | total loss: [1m[32m0.69317[0m[0m | time: 28.521s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.4983 -- iter: 1024/1257
[A[ATraining Step: 113  | total loss: [1m[32m0.69312[0m[0m | time: 29.611s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5016 -- iter: 1056/1257
[A[ATraining Step: 114  | total loss: [1m[32m0.69311[0m[0m | time: 30.393s
[2K
| RMSProp | epoch: 003 | loss: 0.69311 - acc: 0.5045 -- iter: 1088/1257
[A[ATraining Step: 115  | total loss: [1m[32m0.69295[0m[0m | time: 31.261s
[2K
| RMSProp | epoch: 003 | loss: 0.69295 - acc: 0.5166 -- iter: 1120/1257
[A[ATraining Step: 116  | total loss: [1m[32m0.69348[0m[0m | time: 32.155s
[2K
| RMSProp | epoch: 003 | loss: 0.69348 - acc: 0.4930 -- iter: 1152/1257
[A[ATraining Step: 117  | total loss: [1m[32m0.69337[0m[0m | time: 33.028s
[2K
| RMSProp | epoch: 003 | loss: 0.69337 - acc: 0.5062 -- iter: 1184/1257
[A[ATraining Step: 118  | total loss: [1m[32m0.69324[0m[0m | time: 33.954s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.5119 -- iter: 1216/1257
[A[ATraining Step: 119  | total loss: [1m[32m0.69303[0m[0m | time: 35.072s
[2K
| RMSProp | epoch: 003 | loss: 0.69303 - acc: 0.5200 -- iter: 1248/1257
[A[ATraining Step: 120  | total loss: [1m[32m0.69281[0m[0m | time: 37.807s
[2K
| RMSProp | epoch: 003 | loss: 0.69281 - acc: 0.5274 | val_loss: 0.69299 - val_acc: 0.5076 -- iter: 1257/1257
--
Training Step: 121  | total loss: [1m[32m0.69308[0m[0m | time: 1.061s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5184 -- iter: 0032/1257
[A[ATraining Step: 122  | total loss: [1m[32m0.69274[0m[0m | time: 1.349s
[2K
| RMSProp | epoch: 004 | loss: 0.69274 - acc: 0.5291 -- iter: 0064/1257
[A[ATraining Step: 123  | total loss: [1m[32m0.69301[0m[0m | time: 1.575s
[2K
| RMSProp | epoch: 004 | loss: 0.69301 - acc: 0.5206 -- iter: 0096/1257
[A[ATraining Step: 124  | total loss: [1m[32m0.69323[0m[0m | time: 2.411s
[2K
| RMSProp | epoch: 004 | loss: 0.69323 - acc: 0.5130 -- iter: 0128/1257
[A[ATraining Step: 125  | total loss: [1m[32m0.69316[0m[0m | time: 3.322s
[2K
| RMSProp | epoch: 004 | loss: 0.69316 - acc: 0.5148 -- iter: 0160/1257
[A[ATraining Step: 126  | total loss: [1m[32m0.69293[0m[0m | time: 4.296s
[2K
| RMSProp | epoch: 004 | loss: 0.69293 - acc: 0.5227 -- iter: 0192/1257
[A[ATraining Step: 127  | total loss: [1m[32m0.69311[0m[0m | time: 5.225s
[2K
| RMSProp | epoch: 004 | loss: 0.69311 - acc: 0.5173 -- iter: 0224/1257
[A[ATraining Step: 128  | total loss: [1m[32m0.69364[0m[0m | time: 6.208s
[2K
| RMSProp | epoch: 004 | loss: 0.69364 - acc: 0.4968 -- iter: 0256/1257
[A[ATraining Step: 129  | total loss: [1m[32m0.69364[0m[0m | time: 7.204s
[2K
| RMSProp | epoch: 004 | loss: 0.69364 - acc: 0.4940 -- iter: 0288/1257
[A[ATraining Step: 130  | total loss: [1m[32m0.69359[0m[0m | time: 8.029s
[2K
| RMSProp | epoch: 004 | loss: 0.69359 - acc: 0.4978 -- iter: 0320/1257
[A[ATraining Step: 131  | total loss: [1m[32m0.69362[0m[0m | time: 9.111s
[2K
| RMSProp | epoch: 004 | loss: 0.69362 - acc: 0.4886 -- iter: 0352/1257
[A[ATraining Step: 132  | total loss: [1m[32m0.69353[0m[0m | time: 10.166s
[2K
| RMSProp | epoch: 004 | loss: 0.69353 - acc: 0.5085 -- iter: 0384/1257
[A[ATraining Step: 133  | total loss: [1m[32m0.69346[0m[0m | time: 11.025s
[2K
| RMSProp | epoch: 004 | loss: 0.69346 - acc: 0.5108 -- iter: 0416/1257
[A[ATraining Step: 134  | total loss: [1m[32m0.69363[0m[0m | time: 11.819s
[2K
| RMSProp | epoch: 004 | loss: 0.69363 - acc: 0.4972 -- iter: 0448/1257
[A[ATraining Step: 135  | total loss: [1m[32m0.69365[0m[0m | time: 12.666s
[2K
| RMSProp | epoch: 004 | loss: 0.69365 - acc: 0.4818 -- iter: 0480/1257
[A[ATraining Step: 136  | total loss: [1m[32m0.69372[0m[0m | time: 13.539s
[2K
| RMSProp | epoch: 004 | loss: 0.69372 - acc: 0.4743 -- iter: 0512/1257
[A[ATraining Step: 137  | total loss: [1m[32m0.69365[0m[0m | time: 14.424s
[2K
| RMSProp | epoch: 004 | loss: 0.69365 - acc: 0.4800 -- iter: 0544/1257
[A[ATraining Step: 138  | total loss: [1m[32m0.69357[0m[0m | time: 15.366s
[2K
| RMSProp | epoch: 004 | loss: 0.69357 - acc: 0.4851 -- iter: 0576/1257
[A[ATraining Step: 139  | total loss: [1m[32m0.69359[0m[0m | time: 16.373s
[2K
| RMSProp | epoch: 004 | loss: 0.69359 - acc: 0.4803 -- iter: 0608/1257
[A[ATraining Step: 140  | total loss: [1m[32m0.69350[0m[0m | time: 17.319s
[2K
| RMSProp | epoch: 004 | loss: 0.69350 - acc: 0.4854 -- iter: 0640/1257
[A[ATraining Step: 141  | total loss: [1m[32m0.69364[0m[0m | time: 18.199s
[2K
| RMSProp | epoch: 004 | loss: 0.69364 - acc: 0.4650 -- iter: 0672/1257
[A[ATraining Step: 142  | total loss: [1m[32m0.69367[0m[0m | time: 19.264s
[2K
| RMSProp | epoch: 004 | loss: 0.69367 - acc: 0.4591 -- iter: 0704/1257
[A[ATraining Step: 143  | total loss: [1m[32m0.69361[0m[0m | time: 20.279s
[2K
| RMSProp | epoch: 004 | loss: 0.69361 - acc: 0.4757 -- iter: 0736/1257
[A[ATraining Step: 144  | total loss: [1m[32m0.69354[0m[0m | time: 21.090s
[2K
| RMSProp | epoch: 004 | loss: 0.69354 - acc: 0.4813 -- iter: 0768/1257
[A[ATraining Step: 145  | total loss: [1m[32m0.69334[0m[0m | time: 21.928s
[2K
| RMSProp | epoch: 004 | loss: 0.69334 - acc: 0.4925 -- iter: 0800/1257
[A[ATraining Step: 146  | total loss: [1m[32m0.69341[0m[0m | time: 22.812s
[2K
| RMSProp | epoch: 004 | loss: 0.69341 - acc: 0.4902 -- iter: 0832/1257
[A[ATraining Step: 147  | total loss: [1m[32m0.69351[0m[0m | time: 23.704s
[2K
| RMSProp | epoch: 004 | loss: 0.69351 - acc: 0.4849 -- iter: 0864/1257
[A[ATraining Step: 148  | total loss: [1m[32m0.69354[0m[0m | time: 24.598s
[2K
| RMSProp | epoch: 004 | loss: 0.69354 - acc: 0.4801 -- iter: 0896/1257
[A[ATraining Step: 149  | total loss: [1m[32m0.69350[0m[0m | time: 25.606s
[2K
| RMSProp | epoch: 004 | loss: 0.69350 - acc: 0.4790 -- iter: 0928/1257
[A[ATraining Step: 150  | total loss: [1m[32m0.69343[0m[0m | time: 26.603s
[2K
| RMSProp | epoch: 004 | loss: 0.69343 - acc: 0.4936 -- iter: 0960/1257
[A[ATraining Step: 151  | total loss: [1m[32m0.69337[0m[0m | time: 27.432s
[2K
| RMSProp | epoch: 004 | loss: 0.69337 - acc: 0.4974 -- iter: 0992/1257
[A[ATraining Step: 152  | total loss: [1m[32m0.69316[0m[0m | time: 28.546s
[2K
| RMSProp | epoch: 004 | loss: 0.69316 - acc: 0.5101 -- iter: 1024/1257
[A[ATraining Step: 153  | total loss: [1m[32m0.69328[0m[0m | time: 29.687s
[2K
| RMSProp | epoch: 004 | loss: 0.69328 - acc: 0.5060 -- iter: 1056/1257
[A[ATraining Step: 154  | total loss: [1m[32m0.69308[0m[0m | time: 30.592s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5148 -- iter: 1088/1257
[A[ATraining Step: 155  | total loss: [1m[32m0.69309[0m[0m | time: 31.425s
[2K
| RMSProp | epoch: 004 | loss: 0.69309 - acc: 0.5133 -- iter: 1120/1257
[A[ATraining Step: 156  | total loss: [1m[32m0.69300[0m[0m | time: 32.340s
[2K
| RMSProp | epoch: 004 | loss: 0.69300 - acc: 0.5151 -- iter: 1152/1257
[A[ATraining Step: 157  | total loss: [1m[32m0.69337[0m[0m | time: 33.241s
[2K
| RMSProp | epoch: 004 | loss: 0.69337 - acc: 0.5042 -- iter: 1184/1257
[A[ATraining Step: 158  | total loss: [1m[32m0.69334[0m[0m | time: 34.140s
[2K
| RMSProp | epoch: 004 | loss: 0.69334 - acc: 0.5069 -- iter: 1216/1257
[A[ATraining Step: 159  | total loss: [1m[32m0.69330[0m[0m | time: 35.149s
[2K
| RMSProp | epoch: 004 | loss: 0.69330 - acc: 0.5062 -- iter: 1248/1257
[A[ATraining Step: 160  | total loss: [1m[32m0.69327[0m[0m | time: 37.837s
[2K
| RMSProp | epoch: 004 | loss: 0.69327 - acc: 0.5056 | val_loss: 0.69332 - val_acc: 0.4924 -- iter: 1257/1257
--
Training Step: 161  | total loss: [1m[32m0.69346[0m[0m | time: 1.069s
[2K
| RMSProp | epoch: 005 | loss: 0.69346 - acc: 0.4863 -- iter: 0032/1257
[A[ATraining Step: 162  | total loss: [1m[32m0.69345[0m[0m | time: 2.007s
[2K
| RMSProp | epoch: 005 | loss: 0.69345 - acc: 0.4877 -- iter: 0064/1257
[A[ATraining Step: 163  | total loss: [1m[32m0.69313[0m[0m | time: 2.250s
[2K
| RMSProp | epoch: 005 | loss: 0.69313 - acc: 0.4983 -- iter: 0096/1257
[A[ATraining Step: 164  | total loss: [1m[32m0.69347[0m[0m | time: 2.532s
[2K
| RMSProp | epoch: 005 | loss: 0.69347 - acc: 0.4929 -- iter: 0128/1257
[A[ATraining Step: 165  | total loss: [1m[32m0.69348[0m[0m | time: 3.393s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.4880 -- iter: 0160/1257
[A[ATraining Step: 166  | total loss: [1m[32m0.69348[0m[0m | time: 4.274s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.4830 -- iter: 0192/1257
[A[ATraining Step: 167  | total loss: [1m[32m0.69337[0m[0m | time: 5.171s
[2K
| RMSProp | epoch: 005 | loss: 0.69337 - acc: 0.4909 -- iter: 0224/1257
[A[ATraining Step: 168  | total loss: [1m[32m0.69310[0m[0m | time: 6.080s
[2K
| RMSProp | epoch: 005 | loss: 0.69310 - acc: 0.5012 -- iter: 0256/1257
[A[ATraining Step: 169  | total loss: [1m[32m0.69314[0m[0m | time: 7.144s
[2K
| RMSProp | epoch: 005 | loss: 0.69314 - acc: 0.5011 -- iter: 0288/1257
[A[ATraining Step: 170  | total loss: [1m[32m0.69335[0m[0m | time: 8.084s
[2K
| RMSProp | epoch: 005 | loss: 0.69335 - acc: 0.4979 -- iter: 0320/1257
[A[ATraining Step: 171  | total loss: [1m[32m0.69315[0m[0m | time: 8.955s
[2K
| RMSProp | epoch: 005 | loss: 0.69315 - acc: 0.5075 -- iter: 0352/1257
[A[ATraining Step: 172  | total loss: [1m[32m0.69349[0m[0m | time: 9.992s
[2K
| RMSProp | epoch: 005 | loss: 0.69349 - acc: 0.5005 -- iter: 0384/1257
[A[ATraining Step: 173  | total loss: [1m[32m0.69345[0m[0m | time: 11.053s
[2K
| RMSProp | epoch: 005 | loss: 0.69345 - acc: 0.5004 -- iter: 0416/1257
[A[ATraining Step: 174  | total loss: [1m[32m0.69318[0m[0m | time: 11.868s
[2K
| RMSProp | epoch: 005 | loss: 0.69318 - acc: 0.5129 -- iter: 0448/1257
[A[ATraining Step: 175  | total loss: [1m[32m0.69263[0m[0m | time: 12.704s
[2K
| RMSProp | epoch: 005 | loss: 0.69263 - acc: 0.5241 -- iter: 0480/1257
[A[ATraining Step: 176  | total loss: [1m[32m0.69128[0m[0m | time: 13.559s
[2K
| RMSProp | epoch: 005 | loss: 0.69128 - acc: 0.5373 -- iter: 0512/1257
[A[ATraining Step: 177  | total loss: [1m[32m0.69192[0m[0m | time: 14.409s
[2K
| RMSProp | epoch: 005 | loss: 0.69192 - acc: 0.5367 -- iter: 0544/1257
[A[ATraining Step: 178  | total loss: [1m[32m0.69183[0m[0m | time: 15.260s
[2K
| RMSProp | epoch: 005 | loss: 0.69183 - acc: 0.5362 -- iter: 0576/1257
[A[ATraining Step: 179  | total loss: [1m[32m0.69335[0m[0m | time: 16.277s
[2K
| RMSProp | epoch: 005 | loss: 0.69335 - acc: 0.5200 -- iter: 0608/1257
[A[ATraining Step: 180  | total loss: [1m[32m0.69356[0m[0m | time: 17.256s
[2K
| RMSProp | epoch: 005 | loss: 0.69356 - acc: 0.5087 -- iter: 0640/1257
[A[ATraining Step: 181  | total loss: [1m[32m0.69344[0m[0m | time: 18.099s
[2K
| RMSProp | epoch: 005 | loss: 0.69344 - acc: 0.5203 -- iter: 0672/1257
[A[ATraining Step: 182  | total loss: [1m[32m0.69324[0m[0m | time: 19.075s
[2K
| RMSProp | epoch: 005 | loss: 0.69324 - acc: 0.5245 -- iter: 0704/1257
[A[ATraining Step: 183  | total loss: [1m[32m0.69348[0m[0m | time: 20.139s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.5158 -- iter: 0736/1257
[A[ATraining Step: 184  | total loss: [1m[32m0.69344[0m[0m | time: 21.157s
[2K
| RMSProp | epoch: 005 | loss: 0.69344 - acc: 0.5142 -- iter: 0768/1257
[A[ATraining Step: 185  | total loss: [1m[32m0.69320[0m[0m | time: 21.918s
[2K
| RMSProp | epoch: 005 | loss: 0.69320 - acc: 0.5191 -- iter: 0800/1257
[A[ATraining Step: 186  | total loss: [1m[32m0.69360[0m[0m | time: 22.791s
[2K
| RMSProp | epoch: 005 | loss: 0.69360 - acc: 0.5078 -- iter: 0832/1257
[A[ATraining Step: 187  | total loss: [1m[32m0.69349[0m[0m | time: 23.701s
[2K
| RMSProp | epoch: 005 | loss: 0.69349 - acc: 0.5101 -- iter: 0864/1257
[A[ATraining Step: 188  | total loss: [1m[32m0.69315[0m[0m | time: 24.603s
[2K
| RMSProp | epoch: 005 | loss: 0.69315 - acc: 0.5216 -- iter: 0896/1257
[A[ATraining Step: 189  | total loss: [1m[32m0.69327[0m[0m | time: 25.549s
[2K
| RMSProp | epoch: 005 | loss: 0.69327 - acc: 0.5163 -- iter: 0928/1257
[A[ATraining Step: 190  | total loss: [1m[32m0.69304[0m[0m | time: 26.557s
[2K
| RMSProp | epoch: 005 | loss: 0.69304 - acc: 0.5209 -- iter: 0960/1257
[A[ATraining Step: 191  | total loss: [1m[32m0.69374[0m[0m | time: 27.412s
[2K
| RMSProp | epoch: 005 | loss: 0.69374 - acc: 0.5032 -- iter: 0992/1257
[A[ATraining Step: 192  | total loss: [1m[32m0.69368[0m[0m | time: 28.312s
[2K
| RMSProp | epoch: 005 | loss: 0.69368 - acc: 0.5029 -- iter: 1024/1257
[A[ATraining Step: 193  | total loss: [1m[32m0.69362[0m[0m | time: 29.313s
[2K
| RMSProp | epoch: 005 | loss: 0.69362 - acc: 0.5026 -- iter: 1056/1257
[A[ATraining Step: 194  | total loss: [1m[32m0.69381[0m[0m | time: 30.352s
[2K
| RMSProp | epoch: 005 | loss: 0.69381 - acc: 0.4898 -- iter: 1088/1257
[A[ATraining Step: 195  | total loss: [1m[32m0.69371[0m[0m | time: 31.164s
[2K
| RMSProp | epoch: 005 | loss: 0.69371 - acc: 0.4940 -- iter: 1120/1257
[A[ATraining Step: 196  | total loss: [1m[32m0.69370[0m[0m | time: 32.002s
[2K
| RMSProp | epoch: 005 | loss: 0.69370 - acc: 0.4852 -- iter: 1152/1257
[A[ATraining Step: 197  | total loss: [1m[32m0.69364[0m[0m | time: 32.917s
[2K
| RMSProp | epoch: 005 | loss: 0.69364 - acc: 0.4867 -- iter: 1184/1257
[A[ATraining Step: 198  | total loss: [1m[32m0.69369[0m[0m | time: 33.788s
[2K
| RMSProp | epoch: 005 | loss: 0.69369 - acc: 0.4786 -- iter: 1216/1257
[A[ATraining Step: 199  | total loss: [1m[32m0.69356[0m[0m | time: 34.672s
[2K
| RMSProp | epoch: 005 | loss: 0.69356 - acc: 0.4839 -- iter: 1248/1257
[A[ATraining Step: 200  | total loss: [1m[32m0.69357[0m[0m | time: 37.555s
[2K
| RMSProp | epoch: 005 | loss: 0.69357 - acc: 0.4824 | val_loss: 0.69287 - val_acc: 0.4924 -- iter: 1257/1257
--
Training Step: 201  | total loss: [1m[32m0.69362[0m[0m | time: 0.899s
[2K
| RMSProp | epoch: 006 | loss: 0.69362 - acc: 0.4717 -- iter: 0032/1257
[A[ATraining Step: 202  | total loss: [1m[32m0.69348[0m[0m | time: 1.881s
[2K
| RMSProp | epoch: 006 | loss: 0.69348 - acc: 0.4776 -- iter: 0064/1257
[A[ATraining Step: 203  | total loss: [1m[32m0.69311[0m[0m | time: 2.895s
[2K
| RMSProp | epoch: 006 | loss: 0.69311 - acc: 0.4892 -- iter: 0096/1257
[A[ATraining Step: 204  | total loss: [1m[32m0.69410[0m[0m | time: 3.211s
[2K
| RMSProp | epoch: 006 | loss: 0.69410 - acc: 0.4841 -- iter: 0128/1257
[A[ATraining Step: 205  | total loss: [1m[32m0.69408[0m[0m | time: 3.551s
[2K
| RMSProp | epoch: 006 | loss: 0.69408 - acc: 0.4690 -- iter: 0160/1257
[A[ATraining Step: 206  | total loss: [1m[32m0.69360[0m[0m | time: 4.560s
[2K
| RMSProp | epoch: 006 | loss: 0.69360 - acc: 0.4888 -- iter: 0192/1257
[A[ATraining Step: 207  | total loss: [1m[32m0.69419[0m[0m | time: 5.552s
[2K
| RMSProp | epoch: 006 | loss: 0.69419 - acc: 0.4805 -- iter: 0224/1257
[A[ATraining Step: 208  | total loss: [1m[32m0.69399[0m[0m | time: 6.595s
[2K
| RMSProp | epoch: 006 | loss: 0.69399 - acc: 0.4887 -- iter: 0256/1257
[A[ATraining Step: 209  | total loss: [1m[32m0.69405[0m[0m | time: 7.594s
[2K
| RMSProp | epoch: 006 | loss: 0.69405 - acc: 0.4836 -- iter: 0288/1257
[A[ATraining Step: 210  | total loss: [1m[32m0.69392[0m[0m | time: 8.662s
[2K
| RMSProp | epoch: 006 | loss: 0.69392 - acc: 0.4852 -- iter: 0320/1257
[A[ATraining Step: 211  | total loss: [1m[32m0.69391[0m[0m | time: 9.695s
[2K
| RMSProp | epoch: 006 | loss: 0.69391 - acc: 0.4805 -- iter: 0352/1257
[A[ATraining Step: 212  | total loss: [1m[32m0.69375[0m[0m | time: 10.650s
[2K
| RMSProp | epoch: 006 | loss: 0.69375 - acc: 0.4949 -- iter: 0384/1257
[A[ATraining Step: 213  | total loss: [1m[32m0.69377[0m[0m | time: 11.713s
[2K
| RMSProp | epoch: 006 | loss: 0.69377 - acc: 0.4892 -- iter: 0416/1257
[A[ATraining Step: 214  | total loss: [1m[32m0.69357[0m[0m | time: 12.658s
[2K
| RMSProp | epoch: 006 | loss: 0.69357 - acc: 0.4934 -- iter: 0448/1257
[A[ATraining Step: 215  | total loss: [1m[32m0.69346[0m[0m | time: 13.699s
[2K
| RMSProp | epoch: 006 | loss: 0.69346 - acc: 0.4878 -- iter: 0480/1257
[A[ATraining Step: 216  | total loss: [1m[32m0.69338[0m[0m | time: 14.645s
[2K
| RMSProp | epoch: 006 | loss: 0.69338 - acc: 0.4859 -- iter: 0512/1257
[A[ATraining Step: 217  | total loss: [1m[32m0.69307[0m[0m | time: 15.678s
[2K
| RMSProp | epoch: 006 | loss: 0.69307 - acc: 0.5154 -- iter: 0544/1257
[A[ATraining Step: 218  | total loss: [1m[32m0.69256[0m[0m | time: 16.664s
[2K
| RMSProp | epoch: 006 | loss: 0.69256 - acc: 0.5201 -- iter: 0576/1257
[A[ATraining Step: 219  | total loss: [1m[32m0.69221[0m[0m | time: 17.599s
[2K
| RMSProp | epoch: 006 | loss: 0.69221 - acc: 0.5150 -- iter: 0608/1257
[A[ATraining Step: 220  | total loss: [1m[32m0.69239[0m[0m | time: 18.568s
[2K
| RMSProp | epoch: 006 | loss: 0.69239 - acc: 0.5072 -- iter: 0640/1257
[A[ATraining Step: 221  | total loss: [1m[32m0.69284[0m[0m | time: 19.618s
[2K
| RMSProp | epoch: 006 | loss: 0.69284 - acc: 0.4909 -- iter: 0672/1257
[A[ATraining Step: 222  | total loss: [1m[32m0.69270[0m[0m | time: 20.590s
[2K
| RMSProp | epoch: 006 | loss: 0.69270 - acc: 0.4918 -- iter: 0704/1257
[A[ATraining Step: 223  | total loss: [1m[32m0.69260[0m[0m | time: 21.505s
[2K
| RMSProp | epoch: 006 | loss: 0.69260 - acc: 0.4957 -- iter: 0736/1257
[A[ATraining Step: 224  | total loss: [1m[32m0.69241[0m[0m | time: 22.525s
[2K
| RMSProp | epoch: 006 | loss: 0.69241 - acc: 0.5055 -- iter: 0768/1257
[A[ATraining Step: 225  | total loss: [1m[32m0.69111[0m[0m | time: 23.482s
[2K
| RMSProp | epoch: 006 | loss: 0.69111 - acc: 0.5144 -- iter: 0800/1257
[A[ATraining Step: 226  | total loss: [1m[32m0.69033[0m[0m | time: 24.488s
[2K
| RMSProp | epoch: 006 | loss: 0.69033 - acc: 0.5192 -- iter: 0832/1257
[A[ATraining Step: 227  | total loss: [1m[32m0.68929[0m[0m | time: 25.496s
[2K
| RMSProp | epoch: 006 | loss: 0.68929 - acc: 0.5141 -- iter: 0864/1257
[A[ATraining Step: 228  | total loss: [1m[32m0.68804[0m[0m | time: 26.481s
[2K
| RMSProp | epoch: 006 | loss: 0.68804 - acc: 0.5283 -- iter: 0896/1257
[A[ATraining Step: 229  | total loss: [1m[32m0.68732[0m[0m | time: 27.495s
[2K
| RMSProp | epoch: 006 | loss: 0.68732 - acc: 0.5255 -- iter: 0928/1257
[A[ATraining Step: 230  | total loss: [1m[32m0.68514[0m[0m | time: 28.494s
[2K
| RMSProp | epoch: 006 | loss: 0.68514 - acc: 0.5386 -- iter: 0960/1257
[A[ATraining Step: 231  | total loss: [1m[32m0.68623[0m[0m | time: 29.501s
[2K
| RMSProp | epoch: 006 | loss: 0.68623 - acc: 0.5316 -- iter: 0992/1257
[A[ATraining Step: 232  | total loss: [1m[32m0.68502[0m[0m | time: 30.479s
[2K
| RMSProp | epoch: 006 | loss: 0.68502 - acc: 0.5347 -- iter: 1024/1257
[A[ATraining Step: 233  | total loss: [1m[32m0.68107[0m[0m | time: 31.532s
[2K
| RMSProp | epoch: 006 | loss: 0.68107 - acc: 0.5437 -- iter: 1056/1257
[A[ATraining Step: 234  | total loss: [1m[32m0.67778[0m[0m | time: 32.504s
[2K
| RMSProp | epoch: 006 | loss: 0.67778 - acc: 0.5519 -- iter: 1088/1257
[A[ATraining Step: 235  | total loss: [1m[32m0.67869[0m[0m | time: 33.463s
[2K
| RMSProp | epoch: 006 | loss: 0.67869 - acc: 0.5467 -- iter: 1120/1257
[A[ATraining Step: 236  | total loss: [1m[32m0.67950[0m[0m | time: 34.480s
[2K
| RMSProp | epoch: 006 | loss: 0.67950 - acc: 0.5514 -- iter: 1152/1257
[A[ATraining Step: 237  | total loss: [1m[32m0.67658[0m[0m | time: 35.494s
[2K
| RMSProp | epoch: 006 | loss: 0.67658 - acc: 0.5587 -- iter: 1184/1257
[A[ATraining Step: 238  | total loss: [1m[32m0.67483[0m[0m | time: 36.479s
[2K
| RMSProp | epoch: 006 | loss: 0.67483 - acc: 0.5622 -- iter: 1216/1257
[A[ATraining Step: 239  | total loss: [1m[32m0.67260[0m[0m | time: 37.473s
[2K
| RMSProp | epoch: 006 | loss: 0.67260 - acc: 0.5654 -- iter: 1248/1257
[A[ATraining Step: 240  | total loss: [1m[32m0.66845[0m[0m | time: 40.252s
[2K
| RMSProp | epoch: 006 | loss: 0.66845 - acc: 0.5776 | val_loss: 0.60236 - val_acc: 0.6878 -- iter: 1257/1257
--
Training Step: 241  | total loss: [1m[32m0.66326[0m[0m | time: 0.618s
[2K
| RMSProp | epoch: 007 | loss: 0.66326 - acc: 0.5855 -- iter: 0032/1257
[A[ATraining Step: 242  | total loss: [1m[32m0.65669[0m[0m | time: 1.226s
[2K
| RMSProp | epoch: 007 | loss: 0.65669 - acc: 0.6019 -- iter: 0064/1257
[A[ATraining Step: 243  | total loss: [1m[32m0.65515[0m[0m | time: 1.816s
[2K
| RMSProp | epoch: 007 | loss: 0.65515 - acc: 0.6042 -- iter: 0096/1257
[A[ATraining Step: 244  | total loss: [1m[32m0.65229[0m[0m | time: 2.395s
[2K
| RMSProp | epoch: 007 | loss: 0.65229 - acc: 0.6126 -- iter: 0128/1257
[A[ATraining Step: 245  | total loss: [1m[32m0.65049[0m[0m | time: 2.601s
[2K
| RMSProp | epoch: 007 | loss: 0.65049 - acc: 0.6200 -- iter: 0160/1257
[A[ATraining Step: 246  | total loss: [1m[32m0.63751[0m[0m | time: 2.804s
[2K
| RMSProp | epoch: 007 | loss: 0.63751 - acc: 0.6247 -- iter: 0192/1257
[A[ATraining Step: 247  | total loss: [1m[32m0.61845[0m[0m | time: 3.407s
[2K
| RMSProp | epoch: 007 | loss: 0.61845 - acc: 0.6511 -- iter: 0224/1257
[A[ATraining Step: 248  | total loss: [1m[32m0.63338[0m[0m | time: 4.006s
[2K
| RMSProp | epoch: 007 | loss: 0.63338 - acc: 0.6485 -- iter: 0256/1257
[A[ATraining Step: 249  | total loss: [1m[32m0.61951[0m[0m | time: 4.615s
[2K
| RMSProp | epoch: 007 | loss: 0.61951 - acc: 0.6649 -- iter: 0288/1257
[A[ATraining Step: 250  | total loss: [1m[32m0.67257[0m[0m | time: 5.237s
[2K
| RMSProp | epoch: 007 | loss: 0.67257 - acc: 0.6422 -- iter: 0320/1257
[A[ATraining Step: 251  | total loss: [1m[32m0.66418[0m[0m | time: 5.855s
[2K
| RMSProp | epoch: 007 | loss: 0.66418 - acc: 0.6561 -- iter: 0352/1257
[A[ATraining Step: 252  | total loss: [1m[32m0.65537[0m[0m | time: 6.457s
[2K
| RMSProp | epoch: 007 | loss: 0.65537 - acc: 0.6655 -- iter: 0384/1257
[A[ATraining Step: 253  | total loss: [1m[32m0.64152[0m[0m | time: 7.054s
[2K
| RMSProp | epoch: 007 | loss: 0.64152 - acc: 0.6771 -- iter: 0416/1257
[A[ATraining Step: 254  | total loss: [1m[32m0.63976[0m[0m | time: 7.652s
[2K
| RMSProp | epoch: 007 | loss: 0.63976 - acc: 0.6750 -- iter: 0448/1257
[A[ATraining Step: 255  | total loss: [1m[32m0.64248[0m[0m | time: 8.228s
[2K
| RMSProp | epoch: 007 | loss: 0.64248 - acc: 0.6668 -- iter: 0480/1257
[A[ATraining Step: 256  | total loss: [1m[32m0.63961[0m[0m | time: 8.860s
[2K
| RMSProp | epoch: 007 | loss: 0.63961 - acc: 0.6627 -- iter: 0512/1257
[A[ATraining Step: 257  | total loss: [1m[32m0.63120[0m[0m | time: 9.459s
[2K
| RMSProp | epoch: 007 | loss: 0.63120 - acc: 0.6683 -- iter: 0544/1257
[A[ATraining Step: 258  | total loss: [1m[32m0.63783[0m[0m | time: 10.065s
[2K
| RMSProp | epoch: 007 | loss: 0.63783 - acc: 0.6577 -- iter: 0576/1257
[A[ATraining Step: 259  | total loss: [1m[32m0.63955[0m[0m | time: 10.701s
[2K
| RMSProp | epoch: 007 | loss: 0.63955 - acc: 0.6576 -- iter: 0608/1257
[A[ATraining Step: 260  | total loss: [1m[32m0.62455[0m[0m | time: 11.300s
[2K
| RMSProp | epoch: 007 | loss: 0.62455 - acc: 0.6730 -- iter: 0640/1257
[A[ATraining Step: 261  | total loss: [1m[32m0.62149[0m[0m | time: 11.902s
[2K
| RMSProp | epoch: 007 | loss: 0.62149 - acc: 0.6714 -- iter: 0672/1257
[A[ATraining Step: 262  | total loss: [1m[32m0.62766[0m[0m | time: 12.508s
[2K
| RMSProp | epoch: 007 | loss: 0.62766 - acc: 0.6699 -- iter: 0704/1257
[A[ATraining Step: 263  | total loss: [1m[32m0.61432[0m[0m | time: 13.136s
[2K
| RMSProp | epoch: 007 | loss: 0.61432 - acc: 0.6872 -- iter: 0736/1257
[A[ATraining Step: 264  | total loss: [1m[32m0.60613[0m[0m | time: 13.738s
[2K
| RMSProp | epoch: 007 | loss: 0.60613 - acc: 0.6966 -- iter: 0768/1257
[A[ATraining Step: 265  | total loss: [1m[32m0.59901[0m[0m | time: 14.377s
[2K
| RMSProp | epoch: 007 | loss: 0.59901 - acc: 0.7020 -- iter: 0800/1257
[A[ATraining Step: 266  | total loss: [1m[32m0.59350[0m[0m | time: 14.986s
[2K
| RMSProp | epoch: 007 | loss: 0.59350 - acc: 0.7068 -- iter: 0832/1257
[A[ATraining Step: 267  | total loss: [1m[32m0.58041[0m[0m | time: 15.595s
[2K
| RMSProp | epoch: 007 | loss: 0.58041 - acc: 0.7142 -- iter: 0864/1257
[A[ATraining Step: 268  | total loss: [1m[32m0.57095[0m[0m | time: 16.273s
[2K
| RMSProp | epoch: 007 | loss: 0.57095 - acc: 0.7209 -- iter: 0896/1257
[A[ATraining Step: 269  | total loss: [1m[32m0.57967[0m[0m | time: 17.315s
[2K
| RMSProp | epoch: 007 | loss: 0.57967 - acc: 0.7145 -- iter: 0928/1257
[A[ATraining Step: 270  | total loss: [1m[32m0.58135[0m[0m | time: 18.362s
[2K
| RMSProp | epoch: 007 | loss: 0.58135 - acc: 0.7149 -- iter: 0960/1257
[A[ATraining Step: 271  | total loss: [1m[32m0.59503[0m[0m | time: 19.221s
[2K
| RMSProp | epoch: 007 | loss: 0.59503 - acc: 0.6997 -- iter: 0992/1257
[A[ATraining Step: 272  | total loss: [1m[32m0.59950[0m[0m | time: 20.066s
[2K
| RMSProp | epoch: 007 | loss: 0.59950 - acc: 0.6859 -- iter: 1024/1257
[A[ATraining Step: 273  | total loss: [1m[32m0.60137[0m[0m | time: 20.942s
[2K
| RMSProp | epoch: 007 | loss: 0.60137 - acc: 0.6861 -- iter: 1056/1257
[A[ATraining Step: 274  | total loss: [1m[32m0.59465[0m[0m | time: 21.873s
[2K
| RMSProp | epoch: 007 | loss: 0.59465 - acc: 0.6925 -- iter: 1088/1257
[A[ATraining Step: 275  | total loss: [1m[32m0.59446[0m[0m | time: 22.783s
[2K
| RMSProp | epoch: 007 | loss: 0.59446 - acc: 0.6857 -- iter: 1120/1257
[A[ATraining Step: 276  | total loss: [1m[32m0.59208[0m[0m | time: 23.747s
[2K
| RMSProp | epoch: 007 | loss: 0.59208 - acc: 0.6890 -- iter: 1152/1257
[A[ATraining Step: 277  | total loss: [1m[32m0.58214[0m[0m | time: 24.737s
[2K
| RMSProp | epoch: 007 | loss: 0.58214 - acc: 0.6983 -- iter: 1184/1257
[A[ATraining Step: 278  | total loss: [1m[32m0.58738[0m[0m | time: 25.653s
[2K
| RMSProp | epoch: 007 | loss: 0.58738 - acc: 0.6941 -- iter: 1216/1257
[A[ATraining Step: 279  | total loss: [1m[32m0.58886[0m[0m | time: 26.607s
[2K
| RMSProp | epoch: 007 | loss: 0.58886 - acc: 0.6903 -- iter: 1248/1257
[A[ATraining Step: 280  | total loss: [1m[32m0.59525[0m[0m | time: 29.438s
[2K
| RMSProp | epoch: 007 | loss: 0.59525 - acc: 0.6869 | val_loss: 0.56381 - val_acc: 0.7360 -- iter: 1257/1257
--
Training Step: 281  | total loss: [1m[32m0.60253[0m[0m | time: 0.864s
[2K
| RMSProp | epoch: 008 | loss: 0.60253 - acc: 0.6776 -- iter: 0032/1257
[A[ATraining Step: 282  | total loss: [1m[32m0.60893[0m[0m | time: 1.764s
[2K
| RMSProp | epoch: 008 | loss: 0.60893 - acc: 0.6598 -- iter: 0064/1257
[A[ATraining Step: 283  | total loss: [1m[32m0.60985[0m[0m | time: 2.703s
[2K
| RMSProp | epoch: 008 | loss: 0.60985 - acc: 0.6626 -- iter: 0096/1257
[A[ATraining Step: 284  | total loss: [1m[32m0.61988[0m[0m | time: 3.719s
[2K
| RMSProp | epoch: 008 | loss: 0.61988 - acc: 0.6557 -- iter: 0128/1257
[A[ATraining Step: 285  | total loss: [1m[32m0.61612[0m[0m | time: 4.709s
[2K
| RMSProp | epoch: 008 | loss: 0.61612 - acc: 0.6651 -- iter: 0160/1257
[A[ATraining Step: 286  | total loss: [1m[32m0.61739[0m[0m | time: 4.991s
[2K
| RMSProp | epoch: 008 | loss: 0.61739 - acc: 0.6705 -- iter: 0192/1257
[A[ATraining Step: 287  | total loss: [1m[32m0.60426[0m[0m | time: 5.310s
[2K
| RMSProp | epoch: 008 | loss: 0.60426 - acc: 0.6923 -- iter: 0224/1257
[A[ATraining Step: 288  | total loss: [1m[32m0.58512[0m[0m | time: 6.139s
[2K
| RMSProp | epoch: 008 | loss: 0.58512 - acc: 0.7120 -- iter: 0256/1257
[A[ATraining Step: 289  | total loss: [1m[32m0.58408[0m[0m | time: 7.153s
[2K
| RMSProp | epoch: 008 | loss: 0.58408 - acc: 0.7095 -- iter: 0288/1257
[A[ATraining Step: 290  | total loss: [1m[32m0.58463[0m[0m | time: 8.163s
[2K
| RMSProp | epoch: 008 | loss: 0.58463 - acc: 0.7042 -- iter: 0320/1257
[A[ATraining Step: 291  | total loss: [1m[32m0.60972[0m[0m | time: 9.008s
[2K
| RMSProp | epoch: 008 | loss: 0.60972 - acc: 0.6838 -- iter: 0352/1257
[A[ATraining Step: 292  | total loss: [1m[32m0.60542[0m[0m | time: 9.836s
[2K
| RMSProp | epoch: 008 | loss: 0.60542 - acc: 0.6935 -- iter: 0384/1257
[A[ATraining Step: 293  | total loss: [1m[32m0.59715[0m[0m | time: 10.712s
[2K
| RMSProp | epoch: 008 | loss: 0.59715 - acc: 0.7023 -- iter: 0416/1257
[A[ATraining Step: 294  | total loss: [1m[32m0.59408[0m[0m | time: 11.606s
[2K
| RMSProp | epoch: 008 | loss: 0.59408 - acc: 0.7008 -- iter: 0448/1257
[A[ATraining Step: 295  | total loss: [1m[32m0.58926[0m[0m | time: 12.505s
[2K
| RMSProp | epoch: 008 | loss: 0.58926 - acc: 0.7089 -- iter: 0480/1257
[A[ATraining Step: 296  | total loss: [1m[32m0.58445[0m[0m | time: 13.493s
[2K
| RMSProp | epoch: 008 | loss: 0.58445 - acc: 0.7130 -- iter: 0512/1257
[A[ATraining Step: 297  | total loss: [1m[32m0.58369[0m[0m | time: 14.521s
[2K
| RMSProp | epoch: 008 | loss: 0.58369 - acc: 0.7042 -- iter: 0544/1257
[A[ATraining Step: 298  | total loss: [1m[32m0.60118[0m[0m | time: 15.360s
[2K
| RMSProp | epoch: 008 | loss: 0.60118 - acc: 0.6963 -- iter: 0576/1257
[A[ATraining Step: 299  | total loss: [1m[32m0.59989[0m[0m | time: 16.416s
[2K
| RMSProp | epoch: 008 | loss: 0.59989 - acc: 0.6954 -- iter: 0608/1257
[A[ATraining Step: 300  | total loss: [1m[32m0.60027[0m[0m | time: 17.497s
[2K
| RMSProp | epoch: 008 | loss: 0.60027 - acc: 0.6946 -- iter: 0640/1257
[A[ATraining Step: 301  | total loss: [1m[32m0.58971[0m[0m | time: 18.360s
[2K
| RMSProp | epoch: 008 | loss: 0.58971 - acc: 0.7033 -- iter: 0672/1257
[A[ATraining Step: 302  | total loss: [1m[32m0.58433[0m[0m | time: 19.168s
[2K
| RMSProp | epoch: 008 | loss: 0.58433 - acc: 0.7111 -- iter: 0704/1257
[A[ATraining Step: 303  | total loss: [1m[32m0.57276[0m[0m | time: 20.032s
[2K
| RMSProp | epoch: 008 | loss: 0.57276 - acc: 0.7181 -- iter: 0736/1257
[A[ATraining Step: 304  | total loss: [1m[32m0.55455[0m[0m | time: 20.873s
[2K
| RMSProp | epoch: 008 | loss: 0.55455 - acc: 0.7244 -- iter: 0768/1257
[A[ATraining Step: 305  | total loss: [1m[32m0.56960[0m[0m | time: 21.776s
[2K
| RMSProp | epoch: 008 | loss: 0.56960 - acc: 0.7176 -- iter: 0800/1257
[A[ATraining Step: 306  | total loss: [1m[32m0.60159[0m[0m | time: 22.672s
[2K
| RMSProp | epoch: 008 | loss: 0.60159 - acc: 0.6896 -- iter: 0832/1257
[A[ATraining Step: 307  | total loss: [1m[32m0.59530[0m[0m | time: 23.639s
[2K
| RMSProp | epoch: 008 | loss: 0.59530 - acc: 0.6956 -- iter: 0864/1257
[A[ATraining Step: 308  | total loss: [1m[32m0.59414[0m[0m | time: 24.625s
[2K
| RMSProp | epoch: 008 | loss: 0.59414 - acc: 0.6854 -- iter: 0896/1257
[A[ATraining Step: 309  | total loss: [1m[32m0.58891[0m[0m | time: 25.514s
[2K
| RMSProp | epoch: 008 | loss: 0.58891 - acc: 0.6888 -- iter: 0928/1257
[A[ATraining Step: 310  | total loss: [1m[32m0.58805[0m[0m | time: 26.626s
[2K
| RMSProp | epoch: 008 | loss: 0.58805 - acc: 0.6855 -- iter: 0960/1257
[A[ATraining Step: 311  | total loss: [1m[32m0.58471[0m[0m | time: 27.660s
[2K
| RMSProp | epoch: 008 | loss: 0.58471 - acc: 0.6920 -- iter: 0992/1257
[A[ATraining Step: 312  | total loss: [1m[32m0.57676[0m[0m | time: 28.483s
[2K
| RMSProp | epoch: 008 | loss: 0.57676 - acc: 0.6946 -- iter: 1024/1257
[A[ATraining Step: 313  | total loss: [1m[32m0.57206[0m[0m | time: 29.328s
[2K
| RMSProp | epoch: 008 | loss: 0.57206 - acc: 0.7002 -- iter: 1056/1257
[A[ATraining Step: 314  | total loss: [1m[32m0.56871[0m[0m | time: 30.254s
[2K
| RMSProp | epoch: 008 | loss: 0.56871 - acc: 0.7052 -- iter: 1088/1257
[A[ATraining Step: 315  | total loss: [1m[32m0.55929[0m[0m | time: 31.158s
[2K
| RMSProp | epoch: 008 | loss: 0.55929 - acc: 0.7128 -- iter: 1120/1257
[A[ATraining Step: 316  | total loss: [1m[32m0.54932[0m[0m | time: 32.069s
[2K
| RMSProp | epoch: 008 | loss: 0.54932 - acc: 0.7196 -- iter: 1152/1257
[A[ATraining Step: 317  | total loss: [1m[32m0.54939[0m[0m | time: 33.123s
[2K
| RMSProp | epoch: 008 | loss: 0.54939 - acc: 0.7164 -- iter: 1184/1257
[A[ATraining Step: 318  | total loss: [1m[32m0.55260[0m[0m | time: 34.125s
[2K
| RMSProp | epoch: 008 | loss: 0.55260 - acc: 0.7104 -- iter: 1216/1257
[A[ATraining Step: 319  | total loss: [1m[32m0.56625[0m[0m | time: 34.970s
[2K
| RMSProp | epoch: 008 | loss: 0.56625 - acc: 0.7018 -- iter: 1248/1257
[A[ATraining Step: 320  | total loss: [1m[32m0.56012[0m[0m | time: 38.050s
[2K
| RMSProp | epoch: 008 | loss: 0.56012 - acc: 0.7129 | val_loss: 0.50059 - val_acc: 0.7868 -- iter: 1257/1257
--
Training Step: 321  | total loss: [1m[32m0.55745[0m[0m | time: 0.916s
[2K
| RMSProp | epoch: 009 | loss: 0.55745 - acc: 0.7197 -- iter: 0032/1257
[A[ATraining Step: 322  | total loss: [1m[32m0.55154[0m[0m | time: 1.875s
[2K
| RMSProp | epoch: 009 | loss: 0.55154 - acc: 0.7353 -- iter: 0064/1257
[A[ATraining Step: 323  | total loss: [1m[32m0.55321[0m[0m | time: 2.811s
[2K
| RMSProp | epoch: 009 | loss: 0.55321 - acc: 0.7336 -- iter: 0096/1257
[A[ATraining Step: 324  | total loss: [1m[32m0.54700[0m[0m | time: 3.783s
[2K
| RMSProp | epoch: 009 | loss: 0.54700 - acc: 0.7384 -- iter: 0128/1257
[A[ATraining Step: 325  | total loss: [1m[32m0.53163[0m[0m | time: 4.776s
[2K
| RMSProp | epoch: 009 | loss: 0.53163 - acc: 0.7520 -- iter: 0160/1257
[A[ATraining Step: 326  | total loss: [1m[32m0.54448[0m[0m | time: 5.713s
[2K
| RMSProp | epoch: 009 | loss: 0.54448 - acc: 0.7393 -- iter: 0192/1257
[A[ATraining Step: 327  | total loss: [1m[32m0.55646[0m[0m | time: 6.003s
[2K
| RMSProp | epoch: 009 | loss: 0.55646 - acc: 0.7310 -- iter: 0224/1257
[A[ATraining Step: 328  | total loss: [1m[32m0.54852[0m[0m | time: 6.249s
[2K
| RMSProp | epoch: 009 | loss: 0.54852 - acc: 0.7357 -- iter: 0256/1257
[A[ATraining Step: 329  | total loss: [1m[32m0.51839[0m[0m | time: 7.263s
[2K
| RMSProp | epoch: 009 | loss: 0.51839 - acc: 0.7510 -- iter: 0288/1257
[A[ATraining Step: 330  | total loss: [1m[32m0.50552[0m[0m | time: 8.332s
[2K
| RMSProp | epoch: 009 | loss: 0.50552 - acc: 0.7603 -- iter: 0320/1257
[A[ATraining Step: 331  | total loss: [1m[32m0.50978[0m[0m | time: 9.262s
[2K
| RMSProp | epoch: 009 | loss: 0.50978 - acc: 0.7530 -- iter: 0352/1257
[A[ATraining Step: 332  | total loss: [1m[32m0.52187[0m[0m | time: 10.049s
[2K
| RMSProp | epoch: 009 | loss: 0.52187 - acc: 0.7433 -- iter: 0384/1257
[A[ATraining Step: 333  | total loss: [1m[32m0.51643[0m[0m | time: 10.925s
[2K
| RMSProp | epoch: 009 | loss: 0.51643 - acc: 0.7503 -- iter: 0416/1257
[A[ATraining Step: 334  | total loss: [1m[32m0.51614[0m[0m | time: 11.853s
[2K
| RMSProp | epoch: 009 | loss: 0.51614 - acc: 0.7502 -- iter: 0448/1257
[A[ATraining Step: 335  | total loss: [1m[32m0.51025[0m[0m | time: 12.788s
[2K
| RMSProp | epoch: 009 | loss: 0.51025 - acc: 0.7565 -- iter: 0480/1257
[A[ATraining Step: 336  | total loss: [1m[32m0.50604[0m[0m | time: 13.769s
[2K
| RMSProp | epoch: 009 | loss: 0.50604 - acc: 0.7621 -- iter: 0512/1257
[A[ATraining Step: 337  | total loss: [1m[32m0.51178[0m[0m | time: 14.826s
[2K
| RMSProp | epoch: 009 | loss: 0.51178 - acc: 0.7546 -- iter: 0544/1257
[A[ATraining Step: 338  | total loss: [1m[32m0.51060[0m[0m | time: 15.718s
[2K
| RMSProp | epoch: 009 | loss: 0.51060 - acc: 0.7604 -- iter: 0576/1257
[A[ATraining Step: 339  | total loss: [1m[32m0.51602[0m[0m | time: 16.737s
[2K
| RMSProp | epoch: 009 | loss: 0.51602 - acc: 0.7531 -- iter: 0608/1257
[A[ATraining Step: 340  | total loss: [1m[32m0.53384[0m[0m | time: 17.777s
[2K
| RMSProp | epoch: 009 | loss: 0.53384 - acc: 0.7340 -- iter: 0640/1257
[A[ATraining Step: 341  | total loss: [1m[32m0.53447[0m[0m | time: 18.791s
[2K
| RMSProp | epoch: 009 | loss: 0.53447 - acc: 0.7263 -- iter: 0672/1257
[A[ATraining Step: 342  | total loss: [1m[32m0.52970[0m[0m | time: 19.522s
[2K
| RMSProp | epoch: 009 | loss: 0.52970 - acc: 0.7349 -- iter: 0704/1257
[A[ATraining Step: 343  | total loss: [1m[32m0.50952[0m[0m | time: 20.386s
[2K
| RMSProp | epoch: 009 | loss: 0.50952 - acc: 0.7583 -- iter: 0736/1257
[A[ATraining Step: 344  | total loss: [1m[32m0.48761[0m[0m | time: 21.279s
[2K
| RMSProp | epoch: 009 | loss: 0.48761 - acc: 0.7731 -- iter: 0768/1257
[A[ATraining Step: 345  | total loss: [1m[32m0.48112[0m[0m | time: 22.165s
[2K
| RMSProp | epoch: 009 | loss: 0.48112 - acc: 0.7801 -- iter: 0800/1257
[A[ATraining Step: 346  | total loss: [1m[32m0.47164[0m[0m | time: 23.109s
[2K
| RMSProp | epoch: 009 | loss: 0.47164 - acc: 0.7865 -- iter: 0832/1257
[A[ATraining Step: 347  | total loss: [1m[32m0.48698[0m[0m | time: 24.131s
[2K
| RMSProp | epoch: 009 | loss: 0.48698 - acc: 0.7797 -- iter: 0864/1257
[A[ATraining Step: 348  | total loss: [1m[32m0.48619[0m[0m | time: 25.123s
[2K
| RMSProp | epoch: 009 | loss: 0.48619 - acc: 0.7799 -- iter: 0896/1257
[A[ATraining Step: 349  | total loss: [1m[32m0.48543[0m[0m | time: 25.957s
[2K
| RMSProp | epoch: 009 | loss: 0.48543 - acc: 0.7738 -- iter: 0928/1257
[A[ATraining Step: 350  | total loss: [1m[32m0.46861[0m[0m | time: 26.968s
[2K
| RMSProp | epoch: 009 | loss: 0.46861 - acc: 0.7839 -- iter: 0960/1257
[A[ATraining Step: 351  | total loss: [1m[32m0.45721[0m[0m | time: 27.856s
[2K
| RMSProp | epoch: 009 | loss: 0.45721 - acc: 0.7868 -- iter: 0992/1257
[A[ATraining Step: 352  | total loss: [1m[32m0.45081[0m[0m | time: 28.723s
[2K
| RMSProp | epoch: 009 | loss: 0.45081 - acc: 0.7956 -- iter: 1024/1257
[A[ATraining Step: 353  | total loss: [1m[32m0.47673[0m[0m | time: 29.637s
[2K
| RMSProp | epoch: 009 | loss: 0.47673 - acc: 0.7910 -- iter: 1056/1257
[A[ATraining Step: 354  | total loss: [1m[32m0.48309[0m[0m | time: 30.524s
[2K
| RMSProp | epoch: 009 | loss: 0.48309 - acc: 0.7900 -- iter: 1088/1257
[A[ATraining Step: 355  | total loss: [1m[32m0.48065[0m[0m | time: 31.498s
[2K
| RMSProp | epoch: 009 | loss: 0.48065 - acc: 0.7923 -- iter: 1120/1257
[A[ATraining Step: 356  | total loss: [1m[32m0.48718[0m[0m | time: 32.403s
[2K
| RMSProp | epoch: 009 | loss: 0.48718 - acc: 0.7818 -- iter: 1152/1257
[A[ATraining Step: 357  | total loss: [1m[32m0.48014[0m[0m | time: 33.442s
[2K
| RMSProp | epoch: 009 | loss: 0.48014 - acc: 0.7818 -- iter: 1184/1257
[A[ATraining Step: 358  | total loss: [1m[32m0.48953[0m[0m | time: 34.355s
[2K
| RMSProp | epoch: 009 | loss: 0.48953 - acc: 0.7786 -- iter: 1216/1257
[A[ATraining Step: 359  | total loss: [1m[32m0.48268[0m[0m | time: 35.257s
[2K
| RMSProp | epoch: 009 | loss: 0.48268 - acc: 0.7882 -- iter: 1248/1257
[A[ATraining Step: 360  | total loss: [1m[32m0.48065[0m[0m | time: 37.987s
[2K
| RMSProp | epoch: 009 | loss: 0.48065 - acc: 0.7875 | val_loss: 0.44711 - val_acc: 0.7640 -- iter: 1257/1257
--
Training Step: 361  | total loss: [1m[32m0.47588[0m[0m | time: 0.875s
[2K
| RMSProp | epoch: 010 | loss: 0.47588 - acc: 0.7931 -- iter: 0032/1257
[A[ATraining Step: 362  | total loss: [1m[32m0.46408[0m[0m | time: 1.974s
[2K
| RMSProp | epoch: 010 | loss: 0.46408 - acc: 0.7951 -- iter: 0064/1257
[A[ATraining Step: 363  | total loss: [1m[32m0.44503[0m[0m | time: 2.983s
[2K
| RMSProp | epoch: 010 | loss: 0.44503 - acc: 0.8031 -- iter: 0096/1257
[A[ATraining Step: 364  | total loss: [1m[32m0.42403[0m[0m | time: 3.880s
[2K
| RMSProp | epoch: 010 | loss: 0.42403 - acc: 0.8165 -- iter: 0128/1257
[A[ATraining Step: 365  | total loss: [1m[32m0.43352[0m[0m | time: 4.733s
[2K
| RMSProp | epoch: 010 | loss: 0.43352 - acc: 0.8099 -- iter: 0160/1257
[A[ATraining Step: 366  | total loss: [1m[32m0.44183[0m[0m | time: 5.700s
[2K
| RMSProp | epoch: 010 | loss: 0.44183 - acc: 0.8039 -- iter: 0192/1257
[A[ATraining Step: 367  | total loss: [1m[32m0.42662[0m[0m | time: 6.618s
[2K
| RMSProp | epoch: 010 | loss: 0.42662 - acc: 0.8204 -- iter: 0224/1257
[A[ATraining Step: 368  | total loss: [1m[32m0.43177[0m[0m | time: 6.937s
[2K
| RMSProp | epoch: 010 | loss: 0.43177 - acc: 0.8133 -- iter: 0256/1257
[A[ATraining Step: 369  | total loss: [1m[32m0.43195[0m[0m | time: 7.244s
[2K
| RMSProp | epoch: 010 | loss: 0.43195 - acc: 0.8098 -- iter: 0288/1257
[A[ATraining Step: 370  | total loss: [1m[32m0.41733[0m[0m | time: 8.199s
[2K
| RMSProp | epoch: 010 | loss: 0.41733 - acc: 0.8177 -- iter: 0320/1257
[A[ATraining Step: 371  | total loss: [1m[32m0.42372[0m[0m | time: 9.217s
[2K
| RMSProp | epoch: 010 | loss: 0.42372 - acc: 0.8109 -- iter: 0352/1257
[A[ATraining Step: 372  | total loss: [1m[32m0.41381[0m[0m | time: 10.102s
[2K
| RMSProp | epoch: 010 | loss: 0.41381 - acc: 0.8204 -- iter: 0384/1257
[A[ATraining Step: 373  | total loss: [1m[32m0.43948[0m[0m | time: 11.038s
[2K
| RMSProp | epoch: 010 | loss: 0.43948 - acc: 0.8040 -- iter: 0416/1257
[A[ATraining Step: 374  | total loss: [1m[32m0.48682[0m[0m | time: 12.151s
[2K
| RMSProp | epoch: 010 | loss: 0.48682 - acc: 0.7768 -- iter: 0448/1257
[A[ATraining Step: 375  | total loss: [1m[32m0.48060[0m[0m | time: 13.182s
[2K
| RMSProp | epoch: 010 | loss: 0.48060 - acc: 0.7835 -- iter: 0480/1257
[A[ATraining Step: 376  | total loss: [1m[32m0.48513[0m[0m | time: 13.970s
[2K
| RMSProp | epoch: 010 | loss: 0.48513 - acc: 0.7770 -- iter: 0512/1257
[A[ATraining Step: 377  | total loss: [1m[32m0.47166[0m[0m | time: 14.873s
[2K
| RMSProp | epoch: 010 | loss: 0.47166 - acc: 0.7868 -- iter: 0544/1257
[A[ATraining Step: 378  | total loss: [1m[32m0.46422[0m[0m | time: 15.806s
[2K
| RMSProp | epoch: 010 | loss: 0.46422 - acc: 0.7862 -- iter: 0576/1257
[A[ATraining Step: 379  | total loss: [1m[32m0.47078[0m[0m | time: 16.731s
[2K
| RMSProp | epoch: 010 | loss: 0.47078 - acc: 0.7764 -- iter: 0608/1257
[A[ATraining Step: 380  | total loss: [1m[32m0.48220[0m[0m | time: 17.628s
[2K
| RMSProp | epoch: 010 | loss: 0.48220 - acc: 0.7612 -- iter: 0640/1257
[A[ATraining Step: 381  | total loss: [1m[32m0.47815[0m[0m | time: 18.704s
[2K
| RMSProp | epoch: 010 | loss: 0.47815 - acc: 0.7726 -- iter: 0672/1257
[A[ATraining Step: 382  | total loss: [1m[32m0.47949[0m[0m | time: 19.688s
[2K
| RMSProp | epoch: 010 | loss: 0.47949 - acc: 0.7672 -- iter: 0704/1257
[A[ATraining Step: 383  | total loss: [1m[32m0.48441[0m[0m | time: 20.605s
[2K
| RMSProp | epoch: 010 | loss: 0.48441 - acc: 0.7624 -- iter: 0736/1257
[A[ATraining Step: 384  | total loss: [1m[32m0.48050[0m[0m | time: 21.665s
[2K
| RMSProp | epoch: 010 | loss: 0.48050 - acc: 0.7674 -- iter: 0768/1257
[A[ATraining Step: 385  | total loss: [1m[32m0.46357[0m[0m | time: 22.713s
[2K
| RMSProp | epoch: 010 | loss: 0.46357 - acc: 0.7875 -- iter: 0800/1257
[A[ATraining Step: 386  | total loss: [1m[32m0.44162[0m[0m | time: 23.582s
[2K
| RMSProp | epoch: 010 | loss: 0.44162 - acc: 0.8025 -- iter: 0832/1257
[A[ATraining Step: 387  | total loss: [1m[32m0.43159[0m[0m | time: 24.451s
[2K
| RMSProp | epoch: 010 | loss: 0.43159 - acc: 0.8066 -- iter: 0864/1257
[A[ATraining Step: 388  | total loss: [1m[32m0.42292[0m[0m | time: 25.361s
[2K
| RMSProp | epoch: 010 | loss: 0.42292 - acc: 0.8041 -- iter: 0896/1257
[A[ATraining Step: 389  | total loss: [1m[32m0.40431[0m[0m | time: 26.286s
[2K
| RMSProp | epoch: 010 | loss: 0.40431 - acc: 0.8174 -- iter: 0928/1257
[A[ATraining Step: 390  | total loss: [1m[32m0.41062[0m[0m | time: 27.257s
[2K
| RMSProp | epoch: 010 | loss: 0.41062 - acc: 0.8169 -- iter: 0960/1257
[A[ATraining Step: 391  | total loss: [1m[32m0.41981[0m[0m | time: 28.278s
[2K
| RMSProp | epoch: 010 | loss: 0.41981 - acc: 0.8071 -- iter: 0992/1257
[A[ATraining Step: 392  | total loss: [1m[32m0.45930[0m[0m | time: 29.293s
[2K
| RMSProp | epoch: 010 | loss: 0.45930 - acc: 0.7827 -- iter: 1024/1257
[A[ATraining Step: 393  | total loss: [1m[32m0.45534[0m[0m | time: 30.280s
[2K
| RMSProp | epoch: 010 | loss: 0.45534 - acc: 0.7825 -- iter: 1056/1257
[A[ATraining Step: 394  | total loss: [1m[32m0.43780[0m[0m | time: 31.348s
[2K
| RMSProp | epoch: 010 | loss: 0.43780 - acc: 0.7949 -- iter: 1088/1257
[A[ATraining Step: 395  | total loss: [1m[32m0.43387[0m[0m | time: 32.392s
[2K
| RMSProp | epoch: 010 | loss: 0.43387 - acc: 0.8029 -- iter: 1120/1257
[A[ATraining Step: 396  | total loss: [1m[32m0.44226[0m[0m | time: 33.161s
[2K
| RMSProp | epoch: 010 | loss: 0.44226 - acc: 0.7914 -- iter: 1152/1257
[A[ATraining Step: 397  | total loss: [1m[32m0.43081[0m[0m | time: 34.042s
[2K
| RMSProp | epoch: 010 | loss: 0.43081 - acc: 0.7966 -- iter: 1184/1257
[A[ATraining Step: 398  | total loss: [1m[32m0.41251[0m[0m | time: 34.980s
[2K
| RMSProp | epoch: 010 | loss: 0.41251 - acc: 0.8138 -- iter: 1216/1257
[A[ATraining Step: 399  | total loss: [1m[32m0.39763[0m[0m | time: 35.901s
[2K
| RMSProp | epoch: 010 | loss: 0.39763 - acc: 0.8231 -- iter: 1248/1257
[A[ATraining Step: 400  | total loss: [1m[32m0.37364[0m[0m | time: 38.927s
[2K
| RMSProp | epoch: 010 | loss: 0.37364 - acc: 0.8376 | val_loss: 0.42743 - val_acc: 0.8046 -- iter: 1257/1257
--
Training Step: 401  | total loss: [1m[32m0.38794[0m[0m | time: 1.012s
[2K
| RMSProp | epoch: 011 | loss: 0.38794 - acc: 0.8289 -- iter: 0032/1257
[A[ATraining Step: 402  | total loss: [1m[32m0.38993[0m[0m | time: 2.039s
[2K
| RMSProp | epoch: 011 | loss: 0.38993 - acc: 0.8272 -- iter: 0064/1257
[A[ATraining Step: 403  | total loss: [1m[32m0.40209[0m[0m | time: 3.068s
[2K
| RMSProp | epoch: 011 | loss: 0.40209 - acc: 0.8226 -- iter: 0096/1257
[A[ATraining Step: 404  | total loss: [1m[32m0.41625[0m[0m | time: 3.820s
[2K
| RMSProp | epoch: 011 | loss: 0.41625 - acc: 0.8154 -- iter: 0128/1257
[A[ATraining Step: 405  | total loss: [1m[32m0.40768[0m[0m | time: 4.691s
[2K
| RMSProp | epoch: 011 | loss: 0.40768 - acc: 0.8213 -- iter: 0160/1257
[A[ATraining Step: 406  | total loss: [1m[32m0.39182[0m[0m | time: 5.574s
[2K
| RMSProp | epoch: 011 | loss: 0.39182 - acc: 0.8329 -- iter: 0192/1257
[A[ATraining Step: 407  | total loss: [1m[32m0.40374[0m[0m | time: 6.481s
[2K
| RMSProp | epoch: 011 | loss: 0.40374 - acc: 0.8340 -- iter: 0224/1257
[A[ATraining Step: 408  | total loss: [1m[32m0.39148[0m[0m | time: 7.328s
[2K
| RMSProp | epoch: 011 | loss: 0.39148 - acc: 0.8444 -- iter: 0256/1257
[A[ATraining Step: 409  | total loss: [1m[32m0.40222[0m[0m | time: 7.665s
[2K
| RMSProp | epoch: 011 | loss: 0.40222 - acc: 0.8381 -- iter: 0288/1257
[A[ATraining Step: 410  | total loss: [1m[32m0.38459[0m[0m | time: 8.021s
[2K
| RMSProp | epoch: 011 | loss: 0.38459 - acc: 0.8543 -- iter: 0320/1257
[A[ATraining Step: 411  | total loss: [1m[32m0.35378[0m[0m | time: 9.034s
[2K
| RMSProp | epoch: 011 | loss: 0.35378 - acc: 0.8688 -- iter: 0352/1257
[A[ATraining Step: 412  | total loss: [1m[32m0.34900[0m[0m | time: 9.900s
[2K
| RMSProp | epoch: 011 | loss: 0.34900 - acc: 0.8694 -- iter: 0384/1257
[A[ATraining Step: 413  | total loss: [1m[32m0.36564[0m[0m | time: 10.910s
[2K
| RMSProp | epoch: 011 | loss: 0.36564 - acc: 0.8544 -- iter: 0416/1257
[A[ATraining Step: 414  | total loss: [1m[32m0.37008[0m[0m | time: 11.945s
[2K
| RMSProp | epoch: 011 | loss: 0.37008 - acc: 0.8533 -- iter: 0448/1257
[A[ATraining Step: 415  | total loss: [1m[32m0.35099[0m[0m | time: 12.872s
[2K
| RMSProp | epoch: 011 | loss: 0.35099 - acc: 0.8649 -- iter: 0480/1257
[A[ATraining Step: 416  | total loss: [1m[32m0.36777[0m[0m | time: 13.647s
[2K
| RMSProp | epoch: 011 | loss: 0.36777 - acc: 0.8565 -- iter: 0512/1257
[A[ATraining Step: 417  | total loss: [1m[32m0.37008[0m[0m | time: 14.550s
[2K
| RMSProp | epoch: 011 | loss: 0.37008 - acc: 0.8552 -- iter: 0544/1257
[A[ATraining Step: 418  | total loss: [1m[32m0.36273[0m[0m | time: 15.440s
[2K
| RMSProp | epoch: 011 | loss: 0.36273 - acc: 0.8603 -- iter: 0576/1257
[A[ATraining Step: 419  | total loss: [1m[32m0.36741[0m[0m | time: 16.343s
[2K
| RMSProp | epoch: 011 | loss: 0.36741 - acc: 0.8555 -- iter: 0608/1257
[A[ATraining Step: 420  | total loss: [1m[32m0.36230[0m[0m | time: 17.289s
[2K
| RMSProp | epoch: 011 | loss: 0.36230 - acc: 0.8544 -- iter: 0640/1257
[A[ATraining Step: 421  | total loss: [1m[32m0.35097[0m[0m | time: 18.266s
[2K
| RMSProp | epoch: 011 | loss: 0.35097 - acc: 0.8596 -- iter: 0672/1257
[A[ATraining Step: 422  | total loss: [1m[32m0.34986[0m[0m | time: 19.195s
[2K
| RMSProp | epoch: 011 | loss: 0.34986 - acc: 0.8548 -- iter: 0704/1257
[A[ATraining Step: 423  | total loss: [1m[32m0.33917[0m[0m | time: 20.045s
[2K
| RMSProp | epoch: 011 | loss: 0.33917 - acc: 0.8600 -- iter: 0736/1257
[A[ATraining Step: 424  | total loss: [1m[32m0.33499[0m[0m | time: 21.119s
[2K
| RMSProp | epoch: 011 | loss: 0.33499 - acc: 0.8646 -- iter: 0768/1257
[A[ATraining Step: 425  | total loss: [1m[32m0.31873[0m[0m | time: 22.148s
[2K
| RMSProp | epoch: 011 | loss: 0.31873 - acc: 0.8750 -- iter: 0800/1257
[A[ATraining Step: 426  | total loss: [1m[32m0.32517[0m[0m | time: 23.028s
[2K
| RMSProp | epoch: 011 | loss: 0.32517 - acc: 0.8719 -- iter: 0832/1257
[A[ATraining Step: 427  | total loss: [1m[32m0.33943[0m[0m | time: 23.850s
[2K
| RMSProp | epoch: 011 | loss: 0.33943 - acc: 0.8628 -- iter: 0864/1257
[A[ATraining Step: 428  | total loss: [1m[32m0.37213[0m[0m | time: 24.737s
[2K
| RMSProp | epoch: 011 | loss: 0.37213 - acc: 0.8422 -- iter: 0896/1257
[A[ATraining Step: 429  | total loss: [1m[32m0.39450[0m[0m | time: 25.632s
[2K
| RMSProp | epoch: 011 | loss: 0.39450 - acc: 0.8236 -- iter: 0928/1257
[A[ATraining Step: 430  | total loss: [1m[32m0.39021[0m[0m | time: 26.552s
[2K
| RMSProp | epoch: 011 | loss: 0.39021 - acc: 0.8225 -- iter: 0960/1257
[A[ATraining Step: 431  | total loss: [1m[32m0.37866[0m[0m | time: 27.515s
[2K
| RMSProp | epoch: 011 | loss: 0.37866 - acc: 0.8340 -- iter: 0992/1257
[A[ATraining Step: 432  | total loss: [1m[32m0.37960[0m[0m | time: 28.459s
[2K
| RMSProp | epoch: 011 | loss: 0.37960 - acc: 0.8381 -- iter: 1024/1257
[A[ATraining Step: 433  | total loss: [1m[32m0.37796[0m[0m | time: 29.279s
[2K
| RMSProp | epoch: 011 | loss: 0.37796 - acc: 0.8418 -- iter: 1056/1257
[A[ATraining Step: 434  | total loss: [1m[32m0.35904[0m[0m | time: 30.272s
[2K
| RMSProp | epoch: 011 | loss: 0.35904 - acc: 0.8545 -- iter: 1088/1257
[A[ATraining Step: 435  | total loss: [1m[32m0.34421[0m[0m | time: 31.296s
[2K
| RMSProp | epoch: 011 | loss: 0.34421 - acc: 0.8628 -- iter: 1120/1257
[A[ATraining Step: 436  | total loss: [1m[32m0.34183[0m[0m | time: 32.336s
[2K
| RMSProp | epoch: 011 | loss: 0.34183 - acc: 0.8671 -- iter: 1152/1257
[A[ATraining Step: 437  | total loss: [1m[32m0.33314[0m[0m | time: 33.067s
[2K
| RMSProp | epoch: 011 | loss: 0.33314 - acc: 0.8710 -- iter: 1184/1257
[A[ATraining Step: 438  | total loss: [1m[32m0.33333[0m[0m | time: 33.934s
[2K
| RMSProp | epoch: 011 | loss: 0.33333 - acc: 0.8714 -- iter: 1216/1257
[A[ATraining Step: 439  | total loss: [1m[32m0.34130[0m[0m | time: 34.819s
[2K
| RMSProp | epoch: 011 | loss: 0.34130 - acc: 0.8655 -- iter: 1248/1257
[A[ATraining Step: 440  | total loss: [1m[32m0.34775[0m[0m | time: 37.361s
[2K
| RMSProp | epoch: 011 | loss: 0.34775 - acc: 0.8602 | val_loss: 0.37165 - val_acc: 0.8553 -- iter: 1257/1257
--
Training Step: 441  | total loss: [1m[32m0.33686[0m[0m | time: 0.957s
[2K
| RMSProp | epoch: 012 | loss: 0.33686 - acc: 0.8680 -- iter: 0032/1257
[A[ATraining Step: 442  | total loss: [1m[32m0.34717[0m[0m | time: 1.807s
[2K
| RMSProp | epoch: 012 | loss: 0.34717 - acc: 0.8562 -- iter: 0064/1257
[A[ATraining Step: 443  | total loss: [1m[32m0.34408[0m[0m | time: 2.780s
[2K
| RMSProp | epoch: 012 | loss: 0.34408 - acc: 0.8580 -- iter: 0096/1257
[A[ATraining Step: 444  | total loss: [1m[32m0.32494[0m[0m | time: 3.820s
[2K
| RMSProp | epoch: 012 | loss: 0.32494 - acc: 0.8691 -- iter: 0128/1257
[A[ATraining Step: 445  | total loss: [1m[32m0.31190[0m[0m | time: 4.808s
[2K
| RMSProp | epoch: 012 | loss: 0.31190 - acc: 0.8760 -- iter: 0160/1257
[A[ATraining Step: 446  | total loss: [1m[32m0.32423[0m[0m | time: 5.561s
[2K
| RMSProp | epoch: 012 | loss: 0.32423 - acc: 0.8634 -- iter: 0192/1257
[A[ATraining Step: 447  | total loss: [1m[32m0.34420[0m[0m | time: 6.448s
[2K
| RMSProp | epoch: 012 | loss: 0.34420 - acc: 0.8551 -- iter: 0224/1257
[A[ATraining Step: 448  | total loss: [1m[32m0.33556[0m[0m | time: 7.383s
[2K
| RMSProp | epoch: 012 | loss: 0.33556 - acc: 0.8603 -- iter: 0256/1257
[A[ATraining Step: 449  | total loss: [1m[32m0.32295[0m[0m | time: 8.241s
[2K
| RMSProp | epoch: 012 | loss: 0.32295 - acc: 0.8649 -- iter: 0288/1257
[A[ATraining Step: 450  | total loss: [1m[32m0.32133[0m[0m | time: 8.526s
[2K
| RMSProp | epoch: 012 | loss: 0.32133 - acc: 0.8659 -- iter: 0320/1257
[A[ATraining Step: 451  | total loss: [1m[32m0.30587[0m[0m | time: 8.820s
[2K
| RMSProp | epoch: 012 | loss: 0.30587 - acc: 0.8793 -- iter: 0352/1257
[A[ATraining Step: 452  | total loss: [1m[32m0.28140[0m[0m | time: 9.789s
[2K
| RMSProp | epoch: 012 | loss: 0.28140 - acc: 0.8914 -- iter: 0384/1257
[A[ATraining Step: 453  | total loss: [1m[32m0.27058[0m[0m | time: 10.791s
[2K
| RMSProp | epoch: 012 | loss: 0.27058 - acc: 0.8960 -- iter: 0416/1257
[A[ATraining Step: 454  | total loss: [1m[32m0.27459[0m[0m | time: 11.650s
[2K
| RMSProp | epoch: 012 | loss: 0.27459 - acc: 0.8907 -- iter: 0448/1257
[A[ATraining Step: 455  | total loss: [1m[32m0.26531[0m[0m | time: 12.641s
[2K
| RMSProp | epoch: 012 | loss: 0.26531 - acc: 0.8954 -- iter: 0480/1257
[A[ATraining Step: 456  | total loss: [1m[32m0.26998[0m[0m | time: 13.712s
[2K
| RMSProp | epoch: 012 | loss: 0.26998 - acc: 0.8903 -- iter: 0512/1257
[A[ATraining Step: 457  | total loss: [1m[32m0.26666[0m[0m | time: 14.687s
[2K
| RMSProp | epoch: 012 | loss: 0.26666 - acc: 0.8919 -- iter: 0544/1257
[A[ATraining Step: 458  | total loss: [1m[32m0.27821[0m[0m | time: 15.491s
[2K
| RMSProp | epoch: 012 | loss: 0.27821 - acc: 0.8839 -- iter: 0576/1257
[A[ATraining Step: 459  | total loss: [1m[32m0.32605[0m[0m | time: 16.367s
[2K
| RMSProp | epoch: 012 | loss: 0.32605 - acc: 0.8612 -- iter: 0608/1257
[A[ATraining Step: 460  | total loss: [1m[32m0.34748[0m[0m | time: 17.243s
[2K
| RMSProp | epoch: 012 | loss: 0.34748 - acc: 0.8563 -- iter: 0640/1257
[A[ATraining Step: 461  | total loss: [1m[32m0.33844[0m[0m | time: 18.110s
[2K
| RMSProp | epoch: 012 | loss: 0.33844 - acc: 0.8582 -- iter: 0672/1257
[A[ATraining Step: 462  | total loss: [1m[32m0.32413[0m[0m | time: 19.019s
[2K
| RMSProp | epoch: 012 | loss: 0.32413 - acc: 0.8661 -- iter: 0704/1257
[A[ATraining Step: 463  | total loss: [1m[32m0.31716[0m[0m | time: 20.041s
[2K
| RMSProp | epoch: 012 | loss: 0.31716 - acc: 0.8732 -- iter: 0736/1257
[A[ATraining Step: 464  | total loss: [1m[32m0.30490[0m[0m | time: 20.966s
[2K
| RMSProp | epoch: 012 | loss: 0.30490 - acc: 0.8734 -- iter: 0768/1257
[A[ATraining Step: 465  | total loss: [1m[32m0.30730[0m[0m | time: 21.881s
[2K
| RMSProp | epoch: 012 | loss: 0.30730 - acc: 0.8736 -- iter: 0800/1257
[A[ATraining Step: 466  | total loss: [1m[32m0.29637[0m[0m | time: 22.969s
[2K
| RMSProp | epoch: 012 | loss: 0.29637 - acc: 0.8800 -- iter: 0832/1257
[A[ATraining Step: 467  | total loss: [1m[32m0.28156[0m[0m | time: 24.021s
[2K
| RMSProp | epoch: 012 | loss: 0.28156 - acc: 0.8888 -- iter: 0864/1257
[A[ATraining Step: 468  | total loss: [1m[32m0.29317[0m[0m | time: 24.799s
[2K
| RMSProp | epoch: 012 | loss: 0.29317 - acc: 0.8750 -- iter: 0896/1257
[A[ATraining Step: 469  | total loss: [1m[32m0.31440[0m[0m | time: 25.651s
[2K
| RMSProp | epoch: 012 | loss: 0.31440 - acc: 0.8656 -- iter: 0928/1257
[A[ATraining Step: 470  | total loss: [1m[32m0.29794[0m[0m | time: 26.558s
[2K
| RMSProp | epoch: 012 | loss: 0.29794 - acc: 0.8790 -- iter: 0960/1257
[A[ATraining Step: 471  | total loss: [1m[32m0.28278[0m[0m | time: 27.465s
[2K
| RMSProp | epoch: 012 | loss: 0.28278 - acc: 0.8849 -- iter: 0992/1257
[A[ATraining Step: 472  | total loss: [1m[32m0.26603[0m[0m | time: 28.402s
[2K
| RMSProp | epoch: 012 | loss: 0.26603 - acc: 0.8964 -- iter: 1024/1257
[A[ATraining Step: 473  | total loss: [1m[32m0.26763[0m[0m | time: 29.382s
[2K
| RMSProp | epoch: 012 | loss: 0.26763 - acc: 0.8974 -- iter: 1056/1257
[A[ATraining Step: 474  | total loss: [1m[32m0.28000[0m[0m | time: 30.376s
[2K
| RMSProp | epoch: 012 | loss: 0.28000 - acc: 0.8920 -- iter: 1088/1257
[A[ATraining Step: 475  | total loss: [1m[32m0.27058[0m[0m | time: 31.193s
[2K
| RMSProp | epoch: 012 | loss: 0.27058 - acc: 0.8966 -- iter: 1120/1257
[A[ATraining Step: 476  | total loss: [1m[32m0.27222[0m[0m | time: 32.222s
[2K
| RMSProp | epoch: 012 | loss: 0.27222 - acc: 0.8975 -- iter: 1152/1257
[A[ATraining Step: 477  | total loss: [1m[32m0.27457[0m[0m | time: 33.289s
[2K
| RMSProp | epoch: 012 | loss: 0.27457 - acc: 0.8984 -- iter: 1184/1257
[A[ATraining Step: 478  | total loss: [1m[32m0.29044[0m[0m | time: 34.177s
[2K
| RMSProp | epoch: 012 | loss: 0.29044 - acc: 0.8929 -- iter: 1216/1257
[A[ATraining Step: 479  | total loss: [1m[32m0.27592[0m[0m | time: 34.990s
[2K
| RMSProp | epoch: 012 | loss: 0.27592 - acc: 0.8974 -- iter: 1248/1257
[A[ATraining Step: 480  | total loss: [1m[32m0.26414[0m[0m | time: 37.637s
[2K
| RMSProp | epoch: 012 | loss: 0.26414 - acc: 0.9045 | val_loss: 0.38000 - val_acc: 0.8477 -- iter: 1257/1257
--
Training Step: 481  | total loss: [1m[32m0.25061[0m[0m | time: 0.962s
[2K
| RMSProp | epoch: 013 | loss: 0.25061 - acc: 0.9078 -- iter: 0032/1257
[A[ATraining Step: 482  | total loss: [1m[32m0.23401[0m[0m | time: 1.983s
[2K
| RMSProp | epoch: 013 | loss: 0.23401 - acc: 0.9108 -- iter: 0064/1257
[A[ATraining Step: 483  | total loss: [1m[32m0.22124[0m[0m | time: 2.873s
[2K
| RMSProp | epoch: 013 | loss: 0.22124 - acc: 0.9166 -- iter: 0096/1257
[A[ATraining Step: 484  | total loss: [1m[32m0.21204[0m[0m | time: 3.735s
[2K
| RMSProp | epoch: 013 | loss: 0.21204 - acc: 0.9187 -- iter: 0128/1257
[A[ATraining Step: 485  | total loss: [1m[32m0.20903[0m[0m | time: 4.757s
[2K
| RMSProp | epoch: 013 | loss: 0.20903 - acc: 0.9206 -- iter: 0160/1257
[A[ATraining Step: 486  | total loss: [1m[32m0.19514[0m[0m | time: 5.769s
[2K
| RMSProp | epoch: 013 | loss: 0.19514 - acc: 0.9285 -- iter: 0192/1257
[A[ATraining Step: 487  | total loss: [1m[32m0.21111[0m[0m | time: 6.532s
[2K
| RMSProp | epoch: 013 | loss: 0.21111 - acc: 0.9200 -- iter: 0224/1257
[A[ATraining Step: 488  | total loss: [1m[32m0.25914[0m[0m | time: 7.448s
[2K
| RMSProp | epoch: 013 | loss: 0.25914 - acc: 0.8937 -- iter: 0256/1257
[A[ATraining Step: 489  | total loss: [1m[32m0.25520[0m[0m | time: 8.338s
[2K
| RMSProp | epoch: 013 | loss: 0.25520 - acc: 0.8980 -- iter: 0288/1257
[A[ATraining Step: 490  | total loss: [1m[32m0.27626[0m[0m | time: 9.241s
[2K
| RMSProp | epoch: 013 | loss: 0.27626 - acc: 0.8895 -- iter: 0320/1257
[A[ATraining Step: 491  | total loss: [1m[32m0.27339[0m[0m | time: 9.532s
[2K
| RMSProp | epoch: 013 | loss: 0.27339 - acc: 0.8943 -- iter: 0352/1257
[A[ATraining Step: 492  | total loss: [1m[32m0.25345[0m[0m | time: 9.847s
[2K
| RMSProp | epoch: 013 | loss: 0.25345 - acc: 0.9049 -- iter: 0384/1257
[A[ATraining Step: 493  | total loss: [1m[32m0.23148[0m[0m | time: 10.791s
[2K
| RMSProp | epoch: 013 | loss: 0.23148 - acc: 0.9144 -- iter: 0416/1257
[A[ATraining Step: 494  | total loss: [1m[32m0.22928[0m[0m | time: 11.801s
[2K
| RMSProp | epoch: 013 | loss: 0.22928 - acc: 0.9198 -- iter: 0448/1257
[A[ATraining Step: 495  | total loss: [1m[32m0.22990[0m[0m | time: 12.638s
[2K
| RMSProp | epoch: 013 | loss: 0.22990 - acc: 0.9185 -- iter: 0480/1257
[A[ATraining Step: 496  | total loss: [1m[32m0.22076[0m[0m | time: 13.541s
[2K
| RMSProp | epoch: 013 | loss: 0.22076 - acc: 0.9235 -- iter: 0512/1257
[A[ATraining Step: 497  | total loss: [1m[32m0.23570[0m[0m | time: 14.593s
[2K
| RMSProp | epoch: 013 | loss: 0.23570 - acc: 0.9155 -- iter: 0544/1257
[A[ATraining Step: 498  | total loss: [1m[32m0.27624[0m[0m | time: 15.646s
[2K
| RMSProp | epoch: 013 | loss: 0.27624 - acc: 0.8927 -- iter: 0576/1257
[A[ATraining Step: 499  | total loss: [1m[32m0.26739[0m[0m | time: 16.382s
[2K
| RMSProp | epoch: 013 | loss: 0.26739 - acc: 0.8941 -- iter: 0608/1257
[A[ATraining Step: 500  | total loss: [1m[32m0.26262[0m[0m | time: 17.270s
[2K
| RMSProp | epoch: 013 | loss: 0.26262 - acc: 0.8984 -- iter: 0640/1257
[A[ATraining Step: 501  | total loss: [1m[32m0.25547[0m[0m | time: 18.165s
[2K
| RMSProp | epoch: 013 | loss: 0.25547 - acc: 0.9054 -- iter: 0672/1257
[A[ATraining Step: 502  | total loss: [1m[32m0.24485[0m[0m | time: 19.049s
[2K
| RMSProp | epoch: 013 | loss: 0.24485 - acc: 0.9118 -- iter: 0704/1257
[A[ATraining Step: 503  | total loss: [1m[32m0.23621[0m[0m | time: 19.975s
[2K
| RMSProp | epoch: 013 | loss: 0.23621 - acc: 0.9175 -- iter: 0736/1257
[A[ATraining Step: 504  | total loss: [1m[32m0.22107[0m[0m | time: 21.048s
[2K
| RMSProp | epoch: 013 | loss: 0.22107 - acc: 0.9257 -- iter: 0768/1257
[A[ATraining Step: 505  | total loss: [1m[32m0.20759[0m[0m | time: 22.018s
[2K
| RMSProp | epoch: 013 | loss: 0.20759 - acc: 0.9332 -- iter: 0800/1257
[A[ATraining Step: 506  | total loss: [1m[32m0.19504[0m[0m | time: 22.902s
[2K
| RMSProp | epoch: 013 | loss: 0.19504 - acc: 0.9367 -- iter: 0832/1257
[A[ATraining Step: 507  | total loss: [1m[32m0.19100[0m[0m | time: 23.954s
[2K
| RMSProp | epoch: 013 | loss: 0.19100 - acc: 0.9368 -- iter: 0864/1257
[A[ATraining Step: 508  | total loss: [1m[32m0.21900[0m[0m | time: 25.013s
[2K
| RMSProp | epoch: 013 | loss: 0.21900 - acc: 0.9212 -- iter: 0896/1257
[A[ATraining Step: 509  | total loss: [1m[32m0.25060[0m[0m | time: 25.807s
[2K
| RMSProp | epoch: 013 | loss: 0.25060 - acc: 0.9072 -- iter: 0928/1257
[A[ATraining Step: 510  | total loss: [1m[32m0.23675[0m[0m | time: 26.678s
[2K
| RMSProp | epoch: 013 | loss: 0.23675 - acc: 0.9134 -- iter: 0960/1257
[A[ATraining Step: 511  | total loss: [1m[32m0.22425[0m[0m | time: 27.555s
[2K
| RMSProp | epoch: 013 | loss: 0.22425 - acc: 0.9220 -- iter: 0992/1257
[A[ATraining Step: 512  | total loss: [1m[32m0.21835[0m[0m | time: 28.448s
[2K
| RMSProp | epoch: 013 | loss: 0.21835 - acc: 0.9267 -- iter: 1024/1257
[A[ATraining Step: 513  | total loss: [1m[32m0.20482[0m[0m | time: 29.339s
[2K
| RMSProp | epoch: 013 | loss: 0.20482 - acc: 0.9340 -- iter: 1056/1257
[A[ATraining Step: 514  | total loss: [1m[32m0.19685[0m[0m | time: 30.368s
[2K
| RMSProp | epoch: 013 | loss: 0.19685 - acc: 0.9375 -- iter: 1088/1257
[A[ATraining Step: 515  | total loss: [1m[32m0.20308[0m[0m | time: 31.323s
[2K
| RMSProp | epoch: 013 | loss: 0.20308 - acc: 0.9344 -- iter: 1120/1257
[A[ATraining Step: 516  | total loss: [1m[32m0.20721[0m[0m | time: 32.140s
[2K
| RMSProp | epoch: 013 | loss: 0.20721 - acc: 0.9316 -- iter: 1152/1257
[A[ATraining Step: 517  | total loss: [1m[32m0.20946[0m[0m | time: 33.186s
[2K
| RMSProp | epoch: 013 | loss: 0.20946 - acc: 0.9290 -- iter: 1184/1257
[A[ATraining Step: 518  | total loss: [1m[32m0.22223[0m[0m | time: 34.227s
[2K
| RMSProp | epoch: 013 | loss: 0.22223 - acc: 0.9236 -- iter: 1216/1257
[A[ATraining Step: 519  | total loss: [1m[32m0.23281[0m[0m | time: 35.106s
[2K
| RMSProp | epoch: 013 | loss: 0.23281 - acc: 0.9219 -- iter: 1248/1257
[A[ATraining Step: 520  | total loss: [1m[32m0.23346[0m[0m | time: 37.771s
[2K
| RMSProp | epoch: 013 | loss: 0.23346 - acc: 0.9203 | val_loss: 0.41693 - val_acc: 0.8274 -- iter: 1257/1257
--
Training Step: 521  | total loss: [1m[32m0.24422[0m[0m | time: 0.920s
[2K
| RMSProp | epoch: 014 | loss: 0.24422 - acc: 0.9096 -- iter: 0032/1257
[A[ATraining Step: 522  | total loss: [1m[32m0.23287[0m[0m | time: 1.917s
[2K
| RMSProp | epoch: 014 | loss: 0.23287 - acc: 0.9186 -- iter: 0064/1257
[A[ATraining Step: 523  | total loss: [1m[32m0.23568[0m[0m | time: 2.870s
[2K
| RMSProp | epoch: 014 | loss: 0.23568 - acc: 0.9142 -- iter: 0096/1257
[A[ATraining Step: 524  | total loss: [1m[32m0.22786[0m[0m | time: 3.724s
[2K
| RMSProp | epoch: 014 | loss: 0.22786 - acc: 0.9197 -- iter: 0128/1257
[A[ATraining Step: 525  | total loss: [1m[32m0.21538[0m[0m | time: 4.723s
[2K
| RMSProp | epoch: 014 | loss: 0.21538 - acc: 0.9246 -- iter: 0160/1257
[A[ATraining Step: 526  | total loss: [1m[32m0.20469[0m[0m | time: 5.762s
[2K
| RMSProp | epoch: 014 | loss: 0.20469 - acc: 0.9290 -- iter: 0192/1257
[A[ATraining Step: 527  | total loss: [1m[32m0.21306[0m[0m | time: 6.724s
[2K
| RMSProp | epoch: 014 | loss: 0.21306 - acc: 0.9267 -- iter: 0224/1257
[A[ATraining Step: 528  | total loss: [1m[32m0.20534[0m[0m | time: 7.450s
[2K
| RMSProp | epoch: 014 | loss: 0.20534 - acc: 0.9278 -- iter: 0256/1257
[A[ATraining Step: 529  | total loss: [1m[32m0.23429[0m[0m | time: 8.309s
[2K
| RMSProp | epoch: 014 | loss: 0.23429 - acc: 0.9194 -- iter: 0288/1257
[A[ATraining Step: 530  | total loss: [1m[32m0.25069[0m[0m | time: 9.167s
[2K
| RMSProp | epoch: 014 | loss: 0.25069 - acc: 0.9118 -- iter: 0320/1257
[A[ATraining Step: 531  | total loss: [1m[32m0.23912[0m[0m | time: 10.100s
[2K
| RMSProp | epoch: 014 | loss: 0.23912 - acc: 0.9175 -- iter: 0352/1257
[A[ATraining Step: 532  | total loss: [1m[32m0.23002[0m[0m | time: 10.390s
[2K
| RMSProp | epoch: 014 | loss: 0.23002 - acc: 0.9227 -- iter: 0384/1257
[A[ATraining Step: 533  | total loss: [1m[32m0.21830[0m[0m | time: 10.708s
[2K
| RMSProp | epoch: 014 | loss: 0.21830 - acc: 0.9304 -- iter: 0416/1257
[A[ATraining Step: 534  | total loss: [1m[32m0.19930[0m[0m | time: 11.658s
[2K
| RMSProp | epoch: 014 | loss: 0.19930 - acc: 0.9373 -- iter: 0448/1257
[A[ATraining Step: 535  | total loss: [1m[32m0.19676[0m[0m | time: 12.662s
[2K
| RMSProp | epoch: 014 | loss: 0.19676 - acc: 0.9374 -- iter: 0480/1257
[A[ATraining Step: 536  | total loss: [1m[32m0.19446[0m[0m | time: 13.518s
[2K
| RMSProp | epoch: 014 | loss: 0.19446 - acc: 0.9374 -- iter: 0512/1257
[A[ATraining Step: 537  | total loss: [1m[32m0.18594[0m[0m | time: 14.511s
[2K
| RMSProp | epoch: 014 | loss: 0.18594 - acc: 0.9405 -- iter: 0544/1257
[A[ATraining Step: 538  | total loss: [1m[32m0.19840[0m[0m | time: 15.541s
[2K
| RMSProp | epoch: 014 | loss: 0.19840 - acc: 0.9308 -- iter: 0576/1257
[A[ATraining Step: 539  | total loss: [1m[32m0.19802[0m[0m | time: 16.538s
[2K
| RMSProp | epoch: 014 | loss: 0.19802 - acc: 0.9253 -- iter: 0608/1257
[A[ATraining Step: 540  | total loss: [1m[32m0.19025[0m[0m | time: 17.269s
[2K
| RMSProp | epoch: 014 | loss: 0.19025 - acc: 0.9296 -- iter: 0640/1257
[A[ATraining Step: 541  | total loss: [1m[32m0.19800[0m[0m | time: 18.153s
[2K
| RMSProp | epoch: 014 | loss: 0.19800 - acc: 0.9241 -- iter: 0672/1257
[A[ATraining Step: 542  | total loss: [1m[32m0.19379[0m[0m | time: 19.080s
[2K
| RMSProp | epoch: 014 | loss: 0.19379 - acc: 0.9255 -- iter: 0704/1257
[A[ATraining Step: 543  | total loss: [1m[32m0.18206[0m[0m | time: 19.980s
[2K
| RMSProp | epoch: 014 | loss: 0.18206 - acc: 0.9298 -- iter: 0736/1257
[A[ATraining Step: 544  | total loss: [1m[32m0.16818[0m[0m | time: 20.874s
[2K
| RMSProp | epoch: 014 | loss: 0.16818 - acc: 0.9368 -- iter: 0768/1257
[A[ATraining Step: 545  | total loss: [1m[32m0.16059[0m[0m | time: 21.863s
[2K
| RMSProp | epoch: 014 | loss: 0.16059 - acc: 0.9400 -- iter: 0800/1257
[A[ATraining Step: 546  | total loss: [1m[32m0.15350[0m[0m | time: 22.787s
[2K
| RMSProp | epoch: 014 | loss: 0.15350 - acc: 0.9398 -- iter: 0832/1257
[A[ATraining Step: 547  | total loss: [1m[32m0.15575[0m[0m | time: 23.649s
[2K
| RMSProp | epoch: 014 | loss: 0.15575 - acc: 0.9364 -- iter: 0864/1257
[A[ATraining Step: 548  | total loss: [1m[32m0.19284[0m[0m | time: 24.729s
[2K
| RMSProp | epoch: 014 | loss: 0.19284 - acc: 0.9178 -- iter: 0896/1257
[A[ATraining Step: 549  | total loss: [1m[32m0.18494[0m[0m | time: 25.817s
[2K
| RMSProp | epoch: 014 | loss: 0.18494 - acc: 0.9229 -- iter: 0928/1257
[A[ATraining Step: 550  | total loss: [1m[32m0.17587[0m[0m | time: 26.682s
[2K
| RMSProp | epoch: 014 | loss: 0.17587 - acc: 0.9306 -- iter: 0960/1257
[A[ATraining Step: 551  | total loss: [1m[32m0.16800[0m[0m | time: 27.596s
[2K
| RMSProp | epoch: 014 | loss: 0.16800 - acc: 0.9344 -- iter: 0992/1257
[A[ATraining Step: 552  | total loss: [1m[32m0.19621[0m[0m | time: 28.514s
[2K
| RMSProp | epoch: 014 | loss: 0.19621 - acc: 0.9285 -- iter: 1024/1257
[A[ATraining Step: 553  | total loss: [1m[32m0.18983[0m[0m | time: 29.414s
[2K
| RMSProp | epoch: 014 | loss: 0.18983 - acc: 0.9325 -- iter: 1056/1257
[A[ATraining Step: 554  | total loss: [1m[32m0.19094[0m[0m | time: 30.379s
[2K
| RMSProp | epoch: 014 | loss: 0.19094 - acc: 0.9361 -- iter: 1088/1257
[A[ATraining Step: 555  | total loss: [1m[32m0.17688[0m[0m | time: 31.489s
[2K
| RMSProp | epoch: 014 | loss: 0.17688 - acc: 0.9425 -- iter: 1120/1257
[A[ATraining Step: 556  | total loss: [1m[32m0.16761[0m[0m | time: 32.452s
[2K
| RMSProp | epoch: 014 | loss: 0.16761 - acc: 0.9451 -- iter: 1152/1257
[A[ATraining Step: 557  | total loss: [1m[32m0.15878[0m[0m | time: 33.307s
[2K
| RMSProp | epoch: 014 | loss: 0.15878 - acc: 0.9475 -- iter: 1184/1257
[A[ATraining Step: 558  | total loss: [1m[32m0.16057[0m[0m | time: 34.358s
[2K
| RMSProp | epoch: 014 | loss: 0.16057 - acc: 0.9434 -- iter: 1216/1257
[A[ATraining Step: 559  | total loss: [1m[32m0.16868[0m[0m | time: 35.402s
[2K
| RMSProp | epoch: 014 | loss: 0.16868 - acc: 0.9365 -- iter: 1248/1257
[A[ATraining Step: 560  | total loss: [1m[32m0.16764[0m[0m | time: 37.885s
[2K
| RMSProp | epoch: 014 | loss: 0.16764 - acc: 0.9366 | val_loss: 0.31293 - val_acc: 0.8807 -- iter: 1257/1257
--
Training Step: 561  | total loss: [1m[32m0.15613[0m[0m | time: 0.899s
[2K
| RMSProp | epoch: 015 | loss: 0.15613 - acc: 0.9398 -- iter: 0032/1257
[A[ATraining Step: 562  | total loss: [1m[32m0.14940[0m[0m | time: 1.792s
[2K
| RMSProp | epoch: 015 | loss: 0.14940 - acc: 0.9396 -- iter: 0064/1257
[A[ATraining Step: 563  | total loss: [1m[32m0.14168[0m[0m | time: 2.806s
[2K
| RMSProp | epoch: 015 | loss: 0.14168 - acc: 0.9394 -- iter: 0096/1257
[A[ATraining Step: 564  | total loss: [1m[32m0.13185[0m[0m | time: 3.757s
[2K
| RMSProp | epoch: 015 | loss: 0.13185 - acc: 0.9455 -- iter: 0128/1257
[A[ATraining Step: 565  | total loss: [1m[32m0.12749[0m[0m | time: 4.599s
[2K
| RMSProp | epoch: 015 | loss: 0.12749 - acc: 0.9478 -- iter: 0160/1257
[A[ATraining Step: 566  | total loss: [1m[32m0.12008[0m[0m | time: 5.602s
[2K
| RMSProp | epoch: 015 | loss: 0.12008 - acc: 0.9530 -- iter: 0192/1257
[A[ATraining Step: 567  | total loss: [1m[32m0.11635[0m[0m | time: 6.713s
[2K
| RMSProp | epoch: 015 | loss: 0.11635 - acc: 0.9546 -- iter: 0224/1257
[A[ATraining Step: 568  | total loss: [1m[32m0.11717[0m[0m | time: 7.637s
[2K
| RMSProp | epoch: 015 | loss: 0.11717 - acc: 0.9529 -- iter: 0256/1257
[A[ATraining Step: 569  | total loss: [1m[32m0.11974[0m[0m | time: 8.426s
[2K
| RMSProp | epoch: 015 | loss: 0.11974 - acc: 0.9545 -- iter: 0288/1257
[A[ATraining Step: 570  | total loss: [1m[32m0.12795[0m[0m | time: 9.316s
[2K
| RMSProp | epoch: 015 | loss: 0.12795 - acc: 0.9496 -- iter: 0320/1257
[A[ATraining Step: 571  | total loss: [1m[32m0.12482[0m[0m | time: 10.207s
[2K
| RMSProp | epoch: 015 | loss: 0.12482 - acc: 0.9484 -- iter: 0352/1257
[A[ATraining Step: 572  | total loss: [1m[32m0.12134[0m[0m | time: 11.067s
[2K
| RMSProp | epoch: 015 | loss: 0.12134 - acc: 0.9505 -- iter: 0384/1257
[A[ATraining Step: 573  | total loss: [1m[32m0.12573[0m[0m | time: 11.360s
[2K
| RMSProp | epoch: 015 | loss: 0.12573 - acc: 0.9492 -- iter: 0416/1257
[A[ATraining Step: 574  | total loss: [1m[32m0.12028[0m[0m | time: 11.665s
[2K
| RMSProp | epoch: 015 | loss: 0.12028 - acc: 0.9542 -- iter: 0448/1257
[A[ATraining Step: 575  | total loss: [1m[32m0.10975[0m[0m | time: 12.681s
[2K
| RMSProp | epoch: 015 | loss: 0.10975 - acc: 0.9588 -- iter: 0480/1257
[A[ATraining Step: 576  | total loss: [1m[32m0.12499[0m[0m | time: 13.662s
[2K
| RMSProp | epoch: 015 | loss: 0.12499 - acc: 0.9536 -- iter: 0512/1257
[A[ATraining Step: 577  | total loss: [1m[32m0.15477[0m[0m | time: 14.458s
[2K
| RMSProp | epoch: 015 | loss: 0.15477 - acc: 0.9363 -- iter: 0544/1257
[A[ATraining Step: 578  | total loss: [1m[32m0.15779[0m[0m | time: 15.542s
[2K
| RMSProp | epoch: 015 | loss: 0.15779 - acc: 0.9364 -- iter: 0576/1257
[A[ATraining Step: 579  | total loss: [1m[32m0.14980[0m[0m | time: 16.586s
[2K
| RMSProp | epoch: 015 | loss: 0.14980 - acc: 0.9397 -- iter: 0608/1257
[A[ATraining Step: 580  | total loss: [1m[32m0.13795[0m[0m | time: 17.435s
[2K
| RMSProp | epoch: 015 | loss: 0.13795 - acc: 0.9457 -- iter: 0640/1257
[A[ATraining Step: 581  | total loss: [1m[32m0.13348[0m[0m | time: 18.250s
[2K
| RMSProp | epoch: 015 | loss: 0.13348 - acc: 0.9449 -- iter: 0672/1257
[A[ATraining Step: 582  | total loss: [1m[32m0.13840[0m[0m | time: 19.186s
[2K
| RMSProp | epoch: 015 | loss: 0.13840 - acc: 0.9410 -- iter: 0704/1257
[A[ATraining Step: 583  | total loss: [1m[32m0.21484[0m[0m | time: 20.123s
[2K
| RMSProp | epoch: 015 | loss: 0.21484 - acc: 0.9250 -- iter: 0736/1257
[A[ATraining Step: 584  | total loss: [1m[32m0.21283[0m[0m | time: 21.059s
[2K
| RMSProp | epoch: 015 | loss: 0.21283 - acc: 0.9263 -- iter: 0768/1257
[A[ATraining Step: 585  | total loss: [1m[32m0.19579[0m[0m | time: 22.034s
[2K
| RMSProp | epoch: 015 | loss: 0.19579 - acc: 0.9337 -- iter: 0800/1257
[A[ATraining Step: 586  | total loss: [1m[32m0.18002[0m[0m | time: 23.008s
[2K
| RMSProp | epoch: 015 | loss: 0.18002 - acc: 0.9403 -- iter: 0832/1257
[A[ATraining Step: 587  | total loss: [1m[32m0.16344[0m[0m | time: 23.767s
[2K
| RMSProp | epoch: 015 | loss: 0.16344 - acc: 0.9463 -- iter: 0864/1257
[A[ATraining Step: 588  | total loss: [1m[32m0.14917[0m[0m | time: 24.866s
[2K
| RMSProp | epoch: 015 | loss: 0.14917 - acc: 0.9516 -- iter: 0896/1257
[A[ATraining Step: 589  | total loss: [1m[32m0.13806[0m[0m | time: 25.862s
[2K
| RMSProp | epoch: 015 | loss: 0.13806 - acc: 0.9534 -- iter: 0928/1257
[A[ATraining Step: 590  | total loss: [1m[32m0.13018[0m[0m | time: 26.771s
[2K
| RMSProp | epoch: 015 | loss: 0.13018 - acc: 0.9549 -- iter: 0960/1257
[A[ATraining Step: 591  | total loss: [1m[32m0.14242[0m[0m | time: 27.605s
[2K
| RMSProp | epoch: 015 | loss: 0.14242 - acc: 0.9532 -- iter: 0992/1257
[A[ATraining Step: 592  | total loss: [1m[32m0.13050[0m[0m | time: 28.500s
[2K
| RMSProp | epoch: 015 | loss: 0.13050 - acc: 0.9578 -- iter: 1024/1257
[A[ATraining Step: 593  | total loss: [1m[32m0.12493[0m[0m | time: 29.368s
[2K
| RMSProp | epoch: 015 | loss: 0.12493 - acc: 0.9589 -- iter: 1056/1257
[A[ATraining Step: 594  | total loss: [1m[32m0.11585[0m[0m | time: 30.270s
[2K
| RMSProp | epoch: 015 | loss: 0.11585 - acc: 0.9630 -- iter: 1088/1257
[A[ATraining Step: 595  | total loss: [1m[32m0.10894[0m[0m | time: 31.274s
[2K
| RMSProp | epoch: 015 | loss: 0.10894 - acc: 0.9667 -- iter: 1120/1257
[A[ATraining Step: 596  | total loss: [1m[32m0.10278[0m[0m | time: 32.298s
[2K
| RMSProp | epoch: 015 | loss: 0.10278 - acc: 0.9701 -- iter: 1152/1257
[A[ATraining Step: 597  | total loss: [1m[32m0.10354[0m[0m | time: 33.203s
[2K
| RMSProp | epoch: 015 | loss: 0.10354 - acc: 0.9699 -- iter: 1184/1257
[A[ATraining Step: 598  | total loss: [1m[32m0.10062[0m[0m | time: 34.208s
[2K
| RMSProp | epoch: 015 | loss: 0.10062 - acc: 0.9698 -- iter: 1216/1257
[A[ATraining Step: 599  | total loss: [1m[32m0.10661[0m[0m | time: 35.267s
[2K
| RMSProp | epoch: 015 | loss: 0.10661 - acc: 0.9666 -- iter: 1248/1257
[A[ATraining Step: 600  | total loss: [1m[32m0.16493[0m[0m | time: 37.811s
[2K
| RMSProp | epoch: 015 | loss: 0.16493 - acc: 0.9480 | val_loss: 0.41755 - val_acc: 0.8350 -- iter: 1257/1257
--
Training Step: 601  | total loss: [1m[32m0.15977[0m[0m | time: 0.889s
[2K
| RMSProp | epoch: 016 | loss: 0.15977 - acc: 0.9501 -- iter: 0032/1257
[A[ATraining Step: 602  | total loss: [1m[32m0.15582[0m[0m | time: 1.764s
[2K
| RMSProp | epoch: 016 | loss: 0.15582 - acc: 0.9520 -- iter: 0064/1257
[A[ATraining Step: 603  | total loss: [1m[32m0.16070[0m[0m | time: 2.664s
[2K
| RMSProp | epoch: 016 | loss: 0.16070 - acc: 0.9474 -- iter: 0096/1257
[A[ATraining Step: 604  | total loss: [1m[32m0.16993[0m[0m | time: 3.601s
[2K
| RMSProp | epoch: 016 | loss: 0.16993 - acc: 0.9464 -- iter: 0128/1257
[A[ATraining Step: 605  | total loss: [1m[32m0.16574[0m[0m | time: 4.598s
[2K
| RMSProp | epoch: 016 | loss: 0.16574 - acc: 0.9455 -- iter: 0160/1257
[A[ATraining Step: 606  | total loss: [1m[32m0.16580[0m[0m | time: 5.447s
[2K
| RMSProp | epoch: 016 | loss: 0.16580 - acc: 0.9416 -- iter: 0192/1257
[A[ATraining Step: 607  | total loss: [1m[32m0.16164[0m[0m | time: 6.424s
[2K
| RMSProp | epoch: 016 | loss: 0.16164 - acc: 0.9443 -- iter: 0224/1257
[A[ATraining Step: 608  | total loss: [1m[32m0.14871[0m[0m | time: 7.456s
[2K
| RMSProp | epoch: 016 | loss: 0.14871 - acc: 0.9499 -- iter: 0256/1257
[A[ATraining Step: 609  | total loss: [1m[32m0.13640[0m[0m | time: 8.494s
[2K
| RMSProp | epoch: 016 | loss: 0.13640 - acc: 0.9549 -- iter: 0288/1257
[A[ATraining Step: 610  | total loss: [1m[32m0.12995[0m[0m | time: 9.258s
[2K
| RMSProp | epoch: 016 | loss: 0.12995 - acc: 0.9563 -- iter: 0320/1257
[A[ATraining Step: 611  | total loss: [1m[32m0.12959[0m[0m | time: 10.136s
[2K
| RMSProp | epoch: 016 | loss: 0.12959 - acc: 0.9544 -- iter: 0352/1257
[A[ATraining Step: 612  | total loss: [1m[32m0.12002[0m[0m | time: 11.074s
[2K
| RMSProp | epoch: 016 | loss: 0.12002 - acc: 0.9590 -- iter: 0384/1257
[A[ATraining Step: 613  | total loss: [1m[32m0.11036[0m[0m | time: 11.984s
[2K
| RMSProp | epoch: 016 | loss: 0.11036 - acc: 0.9631 -- iter: 0416/1257
[A[ATraining Step: 614  | total loss: [1m[32m0.10182[0m[0m | time: 12.262s
[2K
| RMSProp | epoch: 016 | loss: 0.10182 - acc: 0.9668 -- iter: 0448/1257
[A[ATraining Step: 615  | total loss: [1m[32m0.09350[0m[0m | time: 12.568s
[2K
| RMSProp | epoch: 016 | loss: 0.09350 - acc: 0.9701 -- iter: 0480/1257
[A[ATraining Step: 616  | total loss: [1m[32m0.08487[0m[0m | time: 13.596s
[2K
| RMSProp | epoch: 016 | loss: 0.08487 - acc: 0.9731 -- iter: 0512/1257
[A[ATraining Step: 617  | total loss: [1m[32m0.07985[0m[0m | time: 14.569s
[2K
| RMSProp | epoch: 016 | loss: 0.07985 - acc: 0.9726 -- iter: 0544/1257
[A[ATraining Step: 618  | total loss: [1m[32m0.08898[0m[0m | time: 15.379s
[2K
| RMSProp | epoch: 016 | loss: 0.08898 - acc: 0.9691 -- iter: 0576/1257
[A[ATraining Step: 619  | total loss: [1m[32m0.13290[0m[0m | time: 16.392s
[2K
| RMSProp | epoch: 016 | loss: 0.13290 - acc: 0.9535 -- iter: 0608/1257
[A[ATraining Step: 620  | total loss: [1m[32m0.13764[0m[0m | time: 17.443s
[2K
| RMSProp | epoch: 016 | loss: 0.13764 - acc: 0.9519 -- iter: 0640/1257
[A[ATraining Step: 621  | total loss: [1m[32m0.13024[0m[0m | time: 18.387s
[2K
| RMSProp | epoch: 016 | loss: 0.13024 - acc: 0.9567 -- iter: 0672/1257
[A[ATraining Step: 622  | total loss: [1m[32m0.12138[0m[0m | time: 19.169s
[2K
| RMSProp | epoch: 016 | loss: 0.12138 - acc: 0.9610 -- iter: 0704/1257
[A[ATraining Step: 623  | total loss: [1m[32m0.11123[0m[0m | time: 20.056s
[2K
| RMSProp | epoch: 016 | loss: 0.11123 - acc: 0.9649 -- iter: 0736/1257
[A[ATraining Step: 624  | total loss: [1m[32m0.16847[0m[0m | time: 20.967s
[2K
| RMSProp | epoch: 016 | loss: 0.16847 - acc: 0.9559 -- iter: 0768/1257
[A[ATraining Step: 625  | total loss: [1m[32m0.16362[0m[0m | time: 21.856s
[2K
| RMSProp | epoch: 016 | loss: 0.16362 - acc: 0.9572 -- iter: 0800/1257
[A[ATraining Step: 626  | total loss: [1m[32m0.14946[0m[0m | time: 22.914s
[2K
| RMSProp | epoch: 016 | loss: 0.14946 - acc: 0.9615 -- iter: 0832/1257
[A[ATraining Step: 627  | total loss: [1m[32m0.13766[0m[0m | time: 23.916s
[2K
| RMSProp | epoch: 016 | loss: 0.13766 - acc: 0.9653 -- iter: 0864/1257
[A[ATraining Step: 628  | total loss: [1m[32m0.12563[0m[0m | time: 24.794s
[2K
| RMSProp | epoch: 016 | loss: 0.12563 - acc: 0.9688 -- iter: 0896/1257
[A[ATraining Step: 629  | total loss: [1m[32m0.11621[0m[0m | time: 25.818s
[2K
| RMSProp | epoch: 016 | loss: 0.11621 - acc: 0.9719 -- iter: 0928/1257
[A[ATraining Step: 630  | total loss: [1m[32m0.10600[0m[0m | time: 26.859s
[2K
| RMSProp | epoch: 016 | loss: 0.10600 - acc: 0.9747 -- iter: 0960/1257
[A[ATraining Step: 631  | total loss: [1m[32m0.09697[0m[0m | time: 27.879s
[2K
| RMSProp | epoch: 016 | loss: 0.09697 - acc: 0.9773 -- iter: 0992/1257
[A[ATraining Step: 632  | total loss: [1m[32m0.08857[0m[0m | time: 28.640s
[2K
| RMSProp | epoch: 016 | loss: 0.08857 - acc: 0.9795 -- iter: 1024/1257
[A[ATraining Step: 633  | total loss: [1m[32m0.08182[0m[0m | time: 29.578s
[2K
| RMSProp | epoch: 016 | loss: 0.08182 - acc: 0.9816 -- iter: 1056/1257
[A[ATraining Step: 634  | total loss: [1m[32m0.07422[0m[0m | time: 30.440s
[2K
| RMSProp | epoch: 016 | loss: 0.07422 - acc: 0.9834 -- iter: 1088/1257
[A[ATraining Step: 635  | total loss: [1m[32m0.07091[0m[0m | time: 31.332s
[2K
| RMSProp | epoch: 016 | loss: 0.07091 - acc: 0.9820 -- iter: 1120/1257
[A[ATraining Step: 636  | total loss: [1m[32m0.08448[0m[0m | time: 32.280s
[2K
| RMSProp | epoch: 016 | loss: 0.08448 - acc: 0.9775 -- iter: 1152/1257
[A[ATraining Step: 637  | total loss: [1m[32m0.13164[0m[0m | time: 33.331s
[2K
| RMSProp | epoch: 016 | loss: 0.13164 - acc: 0.9610 -- iter: 1184/1257
[A[ATraining Step: 638  | total loss: [1m[32m0.15736[0m[0m | time: 34.258s
[2K
| RMSProp | epoch: 016 | loss: 0.15736 - acc: 0.9462 -- iter: 1216/1257
[A[ATraining Step: 639  | total loss: [1m[32m0.14802[0m[0m | time: 35.116s
[2K
| RMSProp | epoch: 016 | loss: 0.14802 - acc: 0.9515 -- iter: 1248/1257
[A[ATraining Step: 640  | total loss: [1m[32m0.13702[0m[0m | time: 38.045s
[2K
| RMSProp | epoch: 016 | loss: 0.13702 - acc: 0.9564 | val_loss: 0.33625 - val_acc: 0.8731 -- iter: 1257/1257
--
Training Step: 641  | total loss: [1m[32m0.12447[0m[0m | time: 0.855s
[2K
| RMSProp | epoch: 017 | loss: 0.12447 - acc: 0.9607 -- iter: 0032/1257
[A[ATraining Step: 642  | total loss: [1m[32m0.11321[0m[0m | time: 1.750s
[2K
| RMSProp | epoch: 017 | loss: 0.11321 - acc: 0.9647 -- iter: 0064/1257
[A[ATraining Step: 643  | total loss: [1m[32m0.10348[0m[0m | time: 2.641s
[2K
| RMSProp | epoch: 017 | loss: 0.10348 - acc: 0.9682 -- iter: 0096/1257
[A[ATraining Step: 644  | total loss: [1m[32m0.09403[0m[0m | time: 3.501s
[2K
| RMSProp | epoch: 017 | loss: 0.09403 - acc: 0.9714 -- iter: 0128/1257
[A[ATraining Step: 645  | total loss: [1m[32m0.08677[0m[0m | time: 4.443s
[2K
| RMSProp | epoch: 017 | loss: 0.08677 - acc: 0.9742 -- iter: 0160/1257
[A[ATraining Step: 646  | total loss: [1m[32m0.07986[0m[0m | time: 5.448s
[2K
| RMSProp | epoch: 017 | loss: 0.07986 - acc: 0.9768 -- iter: 0192/1257
[A[ATraining Step: 647  | total loss: [1m[32m0.07432[0m[0m | time: 6.345s
[2K
| RMSProp | epoch: 017 | loss: 0.07432 - acc: 0.9791 -- iter: 0224/1257
[A[ATraining Step: 648  | total loss: [1m[32m0.08310[0m[0m | time: 7.347s
[2K
| RMSProp | epoch: 017 | loss: 0.08310 - acc: 0.9781 -- iter: 0256/1257
[A[ATraining Step: 649  | total loss: [1m[32m0.08775[0m[0m | time: 8.384s
[2K
| RMSProp | epoch: 017 | loss: 0.08775 - acc: 0.9740 -- iter: 0288/1257
[A[ATraining Step: 650  | total loss: [1m[32m0.11165[0m[0m | time: 9.373s
[2K
| RMSProp | epoch: 017 | loss: 0.11165 - acc: 0.9641 -- iter: 0320/1257
[A[ATraining Step: 651  | total loss: [1m[32m0.11279[0m[0m | time: 10.099s
[2K
| RMSProp | epoch: 017 | loss: 0.11279 - acc: 0.9615 -- iter: 0352/1257
[A[ATraining Step: 652  | total loss: [1m[32m0.11756[0m[0m | time: 10.965s
[2K
| RMSProp | epoch: 017 | loss: 0.11756 - acc: 0.9591 -- iter: 0384/1257
[A[ATraining Step: 653  | total loss: [1m[32m0.11568[0m[0m | time: 11.826s
[2K
| RMSProp | epoch: 017 | loss: 0.11568 - acc: 0.9600 -- iter: 0416/1257
[A[ATraining Step: 654  | total loss: [1m[32m0.10698[0m[0m | time: 12.723s
[2K
| RMSProp | epoch: 017 | loss: 0.10698 - acc: 0.9640 -- iter: 0448/1257
[A[ATraining Step: 655  | total loss: [1m[32m0.09697[0m[0m | time: 13.014s
[2K
| RMSProp | epoch: 017 | loss: 0.09697 - acc: 0.9676 -- iter: 0480/1257
[A[ATraining Step: 656  | total loss: [1m[32m0.08772[0m[0m | time: 13.298s
[2K
| RMSProp | epoch: 017 | loss: 0.08772 - acc: 0.9709 -- iter: 0512/1257
[A[ATraining Step: 657  | total loss: [1m[32m0.07930[0m[0m | time: 14.280s
[2K
| RMSProp | epoch: 017 | loss: 0.07930 - acc: 0.9738 -- iter: 0544/1257
[A[ATraining Step: 658  | total loss: [1m[32m0.07239[0m[0m | time: 15.235s
[2K
| RMSProp | epoch: 017 | loss: 0.07239 - acc: 0.9764 -- iter: 0576/1257
[A[ATraining Step: 659  | total loss: [1m[32m0.06824[0m[0m | time: 16.081s
[2K
| RMSProp | epoch: 017 | loss: 0.06824 - acc: 0.9788 -- iter: 0608/1257
[A[ATraining Step: 660  | total loss: [1m[32m0.06422[0m[0m | time: 17.043s
[2K
| RMSProp | epoch: 017 | loss: 0.06422 - acc: 0.9809 -- iter: 0640/1257
[A[ATraining Step: 661  | total loss: [1m[32m0.06375[0m[0m | time: 18.040s
[2K
| RMSProp | epoch: 017 | loss: 0.06375 - acc: 0.9797 -- iter: 0672/1257
[A[ATraining Step: 662  | total loss: [1m[32m0.06998[0m[0m | time: 19.053s
[2K
| RMSProp | epoch: 017 | loss: 0.06998 - acc: 0.9755 -- iter: 0704/1257
[A[ATraining Step: 663  | total loss: [1m[32m0.07779[0m[0m | time: 19.817s
[2K
| RMSProp | epoch: 017 | loss: 0.07779 - acc: 0.9685 -- iter: 0736/1257
[A[ATraining Step: 664  | total loss: [1m[32m0.14313[0m[0m | time: 20.714s
[2K
| RMSProp | epoch: 017 | loss: 0.14313 - acc: 0.9529 -- iter: 0768/1257
[A[ATraining Step: 665  | total loss: [1m[32m0.20758[0m[0m | time: 21.574s
[2K
| RMSProp | epoch: 017 | loss: 0.20758 - acc: 0.9451 -- iter: 0800/1257
[A[ATraining Step: 666  | total loss: [1m[32m0.20522[0m[0m | time: 22.517s
[2K
| RMSProp | epoch: 017 | loss: 0.20522 - acc: 0.9413 -- iter: 0832/1257
[A[ATraining Step: 667  | total loss: [1m[32m0.19442[0m[0m | time: 23.389s
[2K
| RMSProp | epoch: 017 | loss: 0.19442 - acc: 0.9440 -- iter: 0864/1257
[A[ATraining Step: 668  | total loss: [1m[32m0.18151[0m[0m | time: 24.391s
[2K
| RMSProp | epoch: 017 | loss: 0.18151 - acc: 0.9496 -- iter: 0896/1257
[A[ATraining Step: 669  | total loss: [1m[32m0.16500[0m[0m | time: 25.350s
[2K
| RMSProp | epoch: 017 | loss: 0.16500 - acc: 0.9546 -- iter: 0928/1257
[A[ATraining Step: 670  | total loss: [1m[32m0.15022[0m[0m | time: 26.245s
[2K
| RMSProp | epoch: 017 | loss: 0.15022 - acc: 0.9592 -- iter: 0960/1257
[A[ATraining Step: 671  | total loss: [1m[32m0.14149[0m[0m | time: 27.275s
[2K
| RMSProp | epoch: 017 | loss: 0.14149 - acc: 0.9601 -- iter: 0992/1257
[A[ATraining Step: 672  | total loss: [1m[32m0.13174[0m[0m | time: 28.296s
[2K
| RMSProp | epoch: 017 | loss: 0.13174 - acc: 0.9641 -- iter: 1024/1257
[A[ATraining Step: 673  | total loss: [1m[32m0.12078[0m[0m | time: 29.118s
[2K
| RMSProp | epoch: 017 | loss: 0.12078 - acc: 0.9677 -- iter: 1056/1257
[A[ATraining Step: 674  | total loss: [1m[32m0.11237[0m[0m | time: 29.935s
[2K
| RMSProp | epoch: 017 | loss: 0.11237 - acc: 0.9709 -- iter: 1088/1257
[A[ATraining Step: 675  | total loss: [1m[32m0.11019[0m[0m | time: 30.824s
[2K
| RMSProp | epoch: 017 | loss: 0.11019 - acc: 0.9676 -- iter: 1120/1257
[A[ATraining Step: 676  | total loss: [1m[32m0.11037[0m[0m | time: 31.689s
[2K
| RMSProp | epoch: 017 | loss: 0.11037 - acc: 0.9677 -- iter: 1152/1257
[A[ATraining Step: 677  | total loss: [1m[32m0.10056[0m[0m | time: 32.597s
[2K
| RMSProp | epoch: 017 | loss: 0.10056 - acc: 0.9709 -- iter: 1184/1257
[A[ATraining Step: 678  | total loss: [1m[32m0.09802[0m[0m | time: 33.560s
[2K
| RMSProp | epoch: 017 | loss: 0.09802 - acc: 0.9707 -- iter: 1216/1257
[A[ATraining Step: 679  | total loss: [1m[32m0.10488[0m[0m | time: 34.564s
[2K
| RMSProp | epoch: 017 | loss: 0.10488 - acc: 0.9643 -- iter: 1248/1257
[A[ATraining Step: 680  | total loss: [1m[32m0.10235[0m[0m | time: 37.239s
[2K
| RMSProp | epoch: 017 | loss: 0.10235 - acc: 0.9647 | val_loss: 0.35050 - val_acc: 0.8883 -- iter: 1257/1257
--
Training Step: 681  | total loss: [1m[32m0.09413[0m[0m | time: 1.000s
[2K
| RMSProp | epoch: 018 | loss: 0.09413 - acc: 0.9682 -- iter: 0032/1257
[A[ATraining Step: 682  | total loss: [1m[32m0.08839[0m[0m | time: 1.837s
[2K
| RMSProp | epoch: 018 | loss: 0.08839 - acc: 0.9683 -- iter: 0064/1257
[A[ATraining Step: 683  | total loss: [1m[32m0.08078[0m[0m | time: 2.757s
[2K
| RMSProp | epoch: 018 | loss: 0.08078 - acc: 0.9715 -- iter: 0096/1257
[A[ATraining Step: 684  | total loss: [1m[32m0.07419[0m[0m | time: 3.618s
[2K
| RMSProp | epoch: 018 | loss: 0.07419 - acc: 0.9743 -- iter: 0128/1257
[A[ATraining Step: 685  | total loss: [1m[32m0.06735[0m[0m | time: 4.494s
[2K
| RMSProp | epoch: 018 | loss: 0.06735 - acc: 0.9769 -- iter: 0160/1257
[A[ATraining Step: 686  | total loss: [1m[32m0.06133[0m[0m | time: 5.552s
[2K
| RMSProp | epoch: 018 | loss: 0.06133 - acc: 0.9792 -- iter: 0192/1257
[A[ATraining Step: 687  | total loss: [1m[32m0.06091[0m[0m | time: 6.576s
[2K
| RMSProp | epoch: 018 | loss: 0.06091 - acc: 0.9782 -- iter: 0224/1257
[A[ATraining Step: 688  | total loss: [1m[32m0.07511[0m[0m | time: 7.451s
[2K
| RMSProp | epoch: 018 | loss: 0.07511 - acc: 0.9772 -- iter: 0256/1257
[A[ATraining Step: 689  | total loss: [1m[32m0.06872[0m[0m | time: 8.321s
[2K
| RMSProp | epoch: 018 | loss: 0.06872 - acc: 0.9795 -- iter: 0288/1257
[A[ATraining Step: 690  | total loss: [1m[32m0.06469[0m[0m | time: 9.325s
[2K
| RMSProp | epoch: 018 | loss: 0.06469 - acc: 0.9815 -- iter: 0320/1257
[A[ATraining Step: 691  | total loss: [1m[32m0.06050[0m[0m | time: 10.318s
[2K
| RMSProp | epoch: 018 | loss: 0.06050 - acc: 0.9834 -- iter: 0352/1257
[A[ATraining Step: 692  | total loss: [1m[32m0.05663[0m[0m | time: 11.229s
[2K
| RMSProp | epoch: 018 | loss: 0.05663 - acc: 0.9851 -- iter: 0384/1257
[A[ATraining Step: 693  | total loss: [1m[32m0.05245[0m[0m | time: 12.079s
[2K
| RMSProp | epoch: 018 | loss: 0.05245 - acc: 0.9865 -- iter: 0416/1257
[A[ATraining Step: 694  | total loss: [1m[32m0.05165[0m[0m | time: 12.990s
[2K
| RMSProp | epoch: 018 | loss: 0.05165 - acc: 0.9879 -- iter: 0448/1257
[A[ATraining Step: 695  | total loss: [1m[32m0.06006[0m[0m | time: 13.953s
[2K
| RMSProp | epoch: 018 | loss: 0.06006 - acc: 0.9860 -- iter: 0480/1257
[A[ATraining Step: 696  | total loss: [1m[32m0.05822[0m[0m | time: 14.257s
[2K
| RMSProp | epoch: 018 | loss: 0.05822 - acc: 0.9874 -- iter: 0512/1257
[A[ATraining Step: 697  | total loss: [1m[32m0.05292[0m[0m | time: 14.583s
[2K
| RMSProp | epoch: 018 | loss: 0.05292 - acc: 0.9886 -- iter: 0544/1257
[A[ATraining Step: 698  | total loss: [1m[32m0.04793[0m[0m | time: 15.598s
[2K
| RMSProp | epoch: 018 | loss: 0.04793 - acc: 0.9898 -- iter: 0576/1257
[A[ATraining Step: 699  | total loss: [1m[32m0.06436[0m[0m | time: 16.550s
[2K
| RMSProp | epoch: 018 | loss: 0.06436 - acc: 0.9845 -- iter: 0608/1257
[A[ATraining Step: 700  | total loss: [1m[32m0.08066[0m[0m | time: 17.472s
[2K
| RMSProp | epoch: 018 | loss: 0.08066 - acc: 0.9736 -- iter: 0640/1257
[A[ATraining Step: 701  | total loss: [1m[32m0.08439[0m[0m | time: 18.505s
[2K
| RMSProp | epoch: 018 | loss: 0.08439 - acc: 0.9700 -- iter: 0672/1257
[A[ATraining Step: 702  | total loss: [1m[32m0.08109[0m[0m | time: 19.625s
[2K
| RMSProp | epoch: 018 | loss: 0.08109 - acc: 0.9699 -- iter: 0704/1257
[A[ATraining Step: 703  | total loss: [1m[32m0.07558[0m[0m | time: 20.526s
[2K
| RMSProp | epoch: 018 | loss: 0.07558 - acc: 0.9729 -- iter: 0736/1257
[A[ATraining Step: 704  | total loss: [1m[32m0.07226[0m[0m | time: 21.409s
[2K
| RMSProp | epoch: 018 | loss: 0.07226 - acc: 0.9756 -- iter: 0768/1257
[A[ATraining Step: 705  | total loss: [1m[32m0.06617[0m[0m | time: 22.338s
[2K
| RMSProp | epoch: 018 | loss: 0.06617 - acc: 0.9780 -- iter: 0800/1257
[A[ATraining Step: 706  | total loss: [1m[32m0.07360[0m[0m | time: 23.250s
[2K
| RMSProp | epoch: 018 | loss: 0.07360 - acc: 0.9771 -- iter: 0832/1257
[A[ATraining Step: 707  | total loss: [1m[32m0.06685[0m[0m | time: 24.151s
[2K
| RMSProp | epoch: 018 | loss: 0.06685 - acc: 0.9794 -- iter: 0864/1257
[A[ATraining Step: 708  | total loss: [1m[32m0.06248[0m[0m | time: 25.136s
[2K
| RMSProp | epoch: 018 | loss: 0.06248 - acc: 0.9815 -- iter: 0896/1257
[A[ATraining Step: 709  | total loss: [1m[32m0.05743[0m[0m | time: 26.104s
[2K
| RMSProp | epoch: 018 | loss: 0.05743 - acc: 0.9833 -- iter: 0928/1257
[A[ATraining Step: 710  | total loss: [1m[32m0.05223[0m[0m | time: 26.962s
[2K
| RMSProp | epoch: 018 | loss: 0.05223 - acc: 0.9850 -- iter: 0960/1257
[A[ATraining Step: 711  | total loss: [1m[32m0.04757[0m[0m | time: 28.001s
[2K
| RMSProp | epoch: 018 | loss: 0.04757 - acc: 0.9865 -- iter: 0992/1257
[A[ATraining Step: 712  | total loss: [1m[32m0.04332[0m[0m | time: 29.089s
[2K
| RMSProp | epoch: 018 | loss: 0.04332 - acc: 0.9878 -- iter: 1024/1257
[A[ATraining Step: 713  | total loss: [1m[32m0.05694[0m[0m | time: 29.989s
[2K
| RMSProp | epoch: 018 | loss: 0.05694 - acc: 0.9859 -- iter: 1056/1257
[A[ATraining Step: 714  | total loss: [1m[32m0.05192[0m[0m | time: 30.780s
[2K
| RMSProp | epoch: 018 | loss: 0.05192 - acc: 0.9873 -- iter: 1088/1257
[A[ATraining Step: 715  | total loss: [1m[32m0.04758[0m[0m | time: 31.665s
[2K
| RMSProp | epoch: 018 | loss: 0.04758 - acc: 0.9886 -- iter: 1120/1257
[A[ATraining Step: 716  | total loss: [1m[32m0.04308[0m[0m | time: 32.592s
[2K
| RMSProp | epoch: 018 | loss: 0.04308 - acc: 0.9897 -- iter: 1152/1257
[A[ATraining Step: 717  | total loss: [1m[32m0.03935[0m[0m | time: 33.485s
[2K
| RMSProp | epoch: 018 | loss: 0.03935 - acc: 0.9908 -- iter: 1184/1257
[A[ATraining Step: 718  | total loss: [1m[32m0.03812[0m[0m | time: 34.486s
[2K
| RMSProp | epoch: 018 | loss: 0.03812 - acc: 0.9886 -- iter: 1216/1257
[A[ATraining Step: 719  | total loss: [1m[32m0.05003[0m[0m | time: 35.467s
[2K
| RMSProp | epoch: 018 | loss: 0.05003 - acc: 0.9835 -- iter: 1248/1257
[A[ATraining Step: 720  | total loss: [1m[32m0.05825[0m[0m | time: 38.115s
[2K
| RMSProp | epoch: 018 | loss: 0.05825 - acc: 0.9789 | val_loss: 0.38222 - val_acc: 0.8553 -- iter: 1257/1257
--
Training Step: 721  | total loss: [1m[32m0.05581[0m[0m | time: 1.062s
[2K
| RMSProp | epoch: 019 | loss: 0.05581 - acc: 0.9778 -- iter: 0032/1257
[A[ATraining Step: 722  | total loss: [1m[32m0.05222[0m[0m | time: 1.846s
[2K
| RMSProp | epoch: 019 | loss: 0.05222 - acc: 0.9801 -- iter: 0064/1257
[A[ATraining Step: 723  | total loss: [1m[32m0.05156[0m[0m | time: 2.705s
[2K
| RMSProp | epoch: 019 | loss: 0.05156 - acc: 0.9821 -- iter: 0096/1257
[A[ATraining Step: 724  | total loss: [1m[32m0.05019[0m[0m | time: 3.564s
[2K
| RMSProp | epoch: 019 | loss: 0.05019 - acc: 0.9839 -- iter: 0128/1257
[A[ATraining Step: 725  | total loss: [1m[32m0.05203[0m[0m | time: 4.470s
[2K
| RMSProp | epoch: 019 | loss: 0.05203 - acc: 0.9823 -- iter: 0160/1257
[A[ATraining Step: 726  | total loss: [1m[32m0.05363[0m[0m | time: 5.376s
[2K
| RMSProp | epoch: 019 | loss: 0.05363 - acc: 0.9810 -- iter: 0192/1257
[A[ATraining Step: 727  | total loss: [1m[32m0.05098[0m[0m | time: 6.324s
[2K
| RMSProp | epoch: 019 | loss: 0.05098 - acc: 0.9798 -- iter: 0224/1257
[A[ATraining Step: 728  | total loss: [1m[32m0.04623[0m[0m | time: 7.303s
[2K
| RMSProp | epoch: 019 | loss: 0.04623 - acc: 0.9818 -- iter: 0256/1257
[A[ATraining Step: 729  | total loss: [1m[32m0.04189[0m[0m | time: 8.148s
[2K
| RMSProp | epoch: 019 | loss: 0.04189 - acc: 0.9836 -- iter: 0288/1257
[A[ATraining Step: 730  | total loss: [1m[32m0.03893[0m[0m | time: 9.189s
[2K
| RMSProp | epoch: 019 | loss: 0.03893 - acc: 0.9852 -- iter: 0320/1257
[A[ATraining Step: 731  | total loss: [1m[32m0.03551[0m[0m | time: 10.285s
[2K
| RMSProp | epoch: 019 | loss: 0.03551 - acc: 0.9867 -- iter: 0352/1257
[A[ATraining Step: 732  | total loss: [1m[32m0.03218[0m[0m | time: 11.236s
[2K
| RMSProp | epoch: 019 | loss: 0.03218 - acc: 0.9880 -- iter: 0384/1257
[A[ATraining Step: 733  | total loss: [1m[32m0.02998[0m[0m | time: 11.977s
[2K
| RMSProp | epoch: 019 | loss: 0.02998 - acc: 0.9892 -- iter: 0416/1257
[A[ATraining Step: 734  | total loss: [1m[32m0.03661[0m[0m | time: 12.840s
[2K
| RMSProp | epoch: 019 | loss: 0.03661 - acc: 0.9872 -- iter: 0448/1257
[A[ATraining Step: 735  | total loss: [1m[32m0.08762[0m[0m | time: 13.739s
[2K
| RMSProp | epoch: 019 | loss: 0.08762 - acc: 0.9728 -- iter: 0480/1257
[A[ATraining Step: 736  | total loss: [1m[32m0.09858[0m[0m | time: 14.652s
[2K
| RMSProp | epoch: 019 | loss: 0.09858 - acc: 0.9693 -- iter: 0512/1257
[A[ATraining Step: 737  | total loss: [1m[32m0.09784[0m[0m | time: 14.976s
[2K
| RMSProp | epoch: 019 | loss: 0.09784 - acc: 0.9693 -- iter: 0544/1257
[A[ATraining Step: 738  | total loss: [1m[32m0.08830[0m[0m | time: 15.268s
[2K
| RMSProp | epoch: 019 | loss: 0.08830 - acc: 0.9723 -- iter: 0576/1257
[A[ATraining Step: 739  | total loss: [1m[32m0.07969[0m[0m | time: 16.258s
[2K
| RMSProp | epoch: 019 | loss: 0.07969 - acc: 0.9751 -- iter: 0608/1257
[A[ATraining Step: 740  | total loss: [1m[32m0.07223[0m[0m | time: 17.262s
[2K
| RMSProp | epoch: 019 | loss: 0.07223 - acc: 0.9776 -- iter: 0640/1257
[A[ATraining Step: 741  | total loss: [1m[32m0.06599[0m[0m | time: 18.060s
[2K
| RMSProp | epoch: 019 | loss: 0.06599 - acc: 0.9798 -- iter: 0672/1257
[A[ATraining Step: 742  | total loss: [1m[32m0.06291[0m[0m | time: 19.074s
[2K
| RMSProp | epoch: 019 | loss: 0.06291 - acc: 0.9787 -- iter: 0704/1257
[A[ATraining Step: 743  | total loss: [1m[32m0.05688[0m[0m | time: 20.147s
[2K
| RMSProp | epoch: 019 | loss: 0.05688 - acc: 0.9809 -- iter: 0736/1257
[A[ATraining Step: 744  | total loss: [1m[32m0.05291[0m[0m | time: 21.077s
[2K
| RMSProp | epoch: 019 | loss: 0.05291 - acc: 0.9828 -- iter: 0768/1257
[A[ATraining Step: 745  | total loss: [1m[32m0.04786[0m[0m | time: 21.869s
[2K
| RMSProp | epoch: 019 | loss: 0.04786 - acc: 0.9845 -- iter: 0800/1257
[A[ATraining Step: 746  | total loss: [1m[32m0.04556[0m[0m | time: 22.721s
[2K
| RMSProp | epoch: 019 | loss: 0.04556 - acc: 0.9860 -- iter: 0832/1257
[A[ATraining Step: 747  | total loss: [1m[32m0.07059[0m[0m | time: 23.587s
[2K
| RMSProp | epoch: 019 | loss: 0.07059 - acc: 0.9843 -- iter: 0864/1257
[A[ATraining Step: 748  | total loss: [1m[32m0.09138[0m[0m | time: 24.447s
[2K
| RMSProp | epoch: 019 | loss: 0.09138 - acc: 0.9796 -- iter: 0896/1257
[A[ATraining Step: 749  | total loss: [1m[32m0.08519[0m[0m | time: 25.364s
[2K
| RMSProp | epoch: 019 | loss: 0.08519 - acc: 0.9817 -- iter: 0928/1257
[A[ATraining Step: 750  | total loss: [1m[32m0.07787[0m[0m | time: 26.339s
[2K
| RMSProp | epoch: 019 | loss: 0.07787 - acc: 0.9835 -- iter: 0960/1257
[A[ATraining Step: 751  | total loss: [1m[32m0.07084[0m[0m | time: 27.314s
[2K
| RMSProp | epoch: 019 | loss: 0.07084 - acc: 0.9852 -- iter: 0992/1257
[A[ATraining Step: 752  | total loss: [1m[32m0.06508[0m[0m | time: 28.071s
[2K
| RMSProp | epoch: 019 | loss: 0.06508 - acc: 0.9866 -- iter: 1024/1257
[A[ATraining Step: 753  | total loss: [1m[32m0.06006[0m[0m | time: 29.137s
[2K
| RMSProp | epoch: 019 | loss: 0.06006 - acc: 0.9880 -- iter: 1056/1257
[A[ATraining Step: 754  | total loss: [1m[32m0.05464[0m[0m | time: 30.195s
[2K
| RMSProp | epoch: 019 | loss: 0.05464 - acc: 0.9892 -- iter: 1088/1257
[A[ATraining Step: 755  | total loss: [1m[32m0.05124[0m[0m | time: 31.088s
[2K
| RMSProp | epoch: 019 | loss: 0.05124 - acc: 0.9903 -- iter: 1120/1257
[A[ATraining Step: 756  | total loss: [1m[32m0.04684[0m[0m | time: 31.896s
[2K
| RMSProp | epoch: 019 | loss: 0.04684 - acc: 0.9912 -- iter: 1152/1257
[A[ATraining Step: 757  | total loss: [1m[32m0.04234[0m[0m | time: 32.834s
[2K
| RMSProp | epoch: 019 | loss: 0.04234 - acc: 0.9921 -- iter: 1184/1257
[A[ATraining Step: 758  | total loss: [1m[32m0.03826[0m[0m | time: 33.705s
[2K
| RMSProp | epoch: 019 | loss: 0.03826 - acc: 0.9929 -- iter: 1216/1257
[A[ATraining Step: 759  | total loss: [1m[32m0.03464[0m[0m | time: 34.605s
[2K
| RMSProp | epoch: 019 | loss: 0.03464 - acc: 0.9936 -- iter: 1248/1257
[A[ATraining Step: 760  | total loss: [1m[32m0.03141[0m[0m | time: 37.498s
[2K
| RMSProp | epoch: 019 | loss: 0.03141 - acc: 0.9942 | val_loss: 0.42532 - val_acc: 0.8909 -- iter: 1257/1257
--
Training Step: 761  | total loss: [1m[32m0.02847[0m[0m | time: 0.901s
[2K
| RMSProp | epoch: 020 | loss: 0.02847 - acc: 0.9948 -- iter: 0032/1257
[A[ATraining Step: 762  | total loss: [1m[32m0.02599[0m[0m | time: 1.923s
[2K
| RMSProp | epoch: 020 | loss: 0.02599 - acc: 0.9953 -- iter: 0064/1257
[A[ATraining Step: 763  | total loss: [1m[32m0.02392[0m[0m | time: 2.946s
[2K
| RMSProp | epoch: 020 | loss: 0.02392 - acc: 0.9958 -- iter: 0096/1257
[A[ATraining Step: 764  | total loss: [1m[32m0.02240[0m[0m | time: 3.718s
[2K
| RMSProp | epoch: 020 | loss: 0.02240 - acc: 0.9962 -- iter: 0128/1257
[A[ATraining Step: 765  | total loss: [1m[32m0.02101[0m[0m | time: 4.576s
[2K
| RMSProp | epoch: 020 | loss: 0.02101 - acc: 0.9966 -- iter: 0160/1257
[A[ATraining Step: 766  | total loss: [1m[32m0.02038[0m[0m | time: 5.465s
[2K
| RMSProp | epoch: 020 | loss: 0.02038 - acc: 0.9969 -- iter: 0192/1257
[A[ATraining Step: 767  | total loss: [1m[32m0.03751[0m[0m | time: 6.345s
[2K
| RMSProp | epoch: 020 | loss: 0.03751 - acc: 0.9910 -- iter: 0224/1257
[A[ATraining Step: 768  | total loss: [1m[32m0.08540[0m[0m | time: 7.251s
[2K
| RMSProp | epoch: 020 | loss: 0.08540 - acc: 0.9763 -- iter: 0256/1257
[A[ATraining Step: 769  | total loss: [1m[32m0.08765[0m[0m | time: 8.229s
[2K
| RMSProp | epoch: 020 | loss: 0.08765 - acc: 0.9724 -- iter: 0288/1257
[A[ATraining Step: 770  | total loss: [1m[32m0.08760[0m[0m | time: 9.215s
[2K
| RMSProp | epoch: 020 | loss: 0.08760 - acc: 0.9689 -- iter: 0320/1257
[A[ATraining Step: 771  | total loss: [1m[32m0.08733[0m[0m | time: 10.018s
[2K
| RMSProp | epoch: 020 | loss: 0.08733 - acc: 0.9689 -- iter: 0352/1257
[A[ATraining Step: 772  | total loss: [1m[32m0.09319[0m[0m | time: 11.083s
[2K
| RMSProp | epoch: 020 | loss: 0.09319 - acc: 0.9626 -- iter: 0384/1257
[A[ATraining Step: 773  | total loss: [1m[32m0.08682[0m[0m | time: 12.122s
[2K
| RMSProp | epoch: 020 | loss: 0.08682 - acc: 0.9664 -- iter: 0416/1257
[A[ATraining Step: 774  | total loss: [1m[32m0.08225[0m[0m | time: 13.030s
[2K
| RMSProp | epoch: 020 | loss: 0.08225 - acc: 0.9666 -- iter: 0448/1257
[A[ATraining Step: 775  | total loss: [1m[32m0.07457[0m[0m | time: 13.865s
[2K
| RMSProp | epoch: 020 | loss: 0.07457 - acc: 0.9699 -- iter: 0480/1257
[A[ATraining Step: 776  | total loss: [1m[32m0.07940[0m[0m | time: 14.776s
[2K
| RMSProp | epoch: 020 | loss: 0.07940 - acc: 0.9667 -- iter: 0512/1257
[A[ATraining Step: 777  | total loss: [1m[32m0.07304[0m[0m | time: 15.701s
[2K
| RMSProp | epoch: 020 | loss: 0.07304 - acc: 0.9700 -- iter: 0544/1257
[A[ATraining Step: 778  | total loss: [1m[32m0.07252[0m[0m | time: 15.993s
[2K
| RMSProp | epoch: 020 | loss: 0.07252 - acc: 0.9699 -- iter: 0576/1257
[A[ATraining Step: 779  | total loss: [1m[32m0.06535[0m[0m | time: 16.293s
[2K
| RMSProp | epoch: 020 | loss: 0.06535 - acc: 0.9729 -- iter: 0608/1257
[A[ATraining Step: 780  | total loss: [1m[32m0.05892[0m[0m | time: 17.278s
[2K
| RMSProp | epoch: 020 | loss: 0.05892 - acc: 0.9756 -- iter: 0640/1257
[A[ATraining Step: 781  | total loss: [1m[32m0.05856[0m[0m | time: 18.354s
[2K
| RMSProp | epoch: 020 | loss: 0.05856 - acc: 0.9749 -- iter: 0672/1257
[A[ATraining Step: 782  | total loss: [1m[32m0.05534[0m[0m | time: 19.240s
[2K
| RMSProp | epoch: 020 | loss: 0.05534 - acc: 0.9774 -- iter: 0704/1257
[A[ATraining Step: 783  | total loss: [1m[32m0.05049[0m[0m | time: 20.221s
[2K
| RMSProp | epoch: 020 | loss: 0.05049 - acc: 0.9797 -- iter: 0736/1257
[A[ATraining Step: 784  | total loss: [1m[32m0.04602[0m[0m | time: 21.293s
[2K
| RMSProp | epoch: 020 | loss: 0.04602 - acc: 0.9817 -- iter: 0768/1257
[A[ATraining Step: 785  | total loss: [1m[32m0.04187[0m[0m | time: 22.344s
[2K
| RMSProp | epoch: 020 | loss: 0.04187 - acc: 0.9836 -- iter: 0800/1257
[A[ATraining Step: 786  | total loss: [1m[32m0.03846[0m[0m | time: 23.142s
[2K
| RMSProp | epoch: 020 | loss: 0.03846 - acc: 0.9852 -- iter: 0832/1257
[A[ATraining Step: 787  | total loss: [1m[32m0.03501[0m[0m | time: 24.031s
[2K
| RMSProp | epoch: 020 | loss: 0.03501 - acc: 0.9867 -- iter: 0864/1257
[A[ATraining Step: 788  | total loss: [1m[32m0.09238[0m[0m | time: 24.910s
[2K
| RMSProp | epoch: 020 | loss: 0.09238 - acc: 0.9818 -- iter: 0896/1257
[A[ATraining Step: 789  | total loss: [1m[32m0.09071[0m[0m | time: 25.812s
[2K
| RMSProp | epoch: 020 | loss: 0.09071 - acc: 0.9773 -- iter: 0928/1257
[A[ATraining Step: 790  | total loss: [1m[32m0.08372[0m[0m | time: 26.753s
[2K
| RMSProp | epoch: 020 | loss: 0.08372 - acc: 0.9796 -- iter: 0960/1257
[A[ATraining Step: 791  | total loss: [1m[32m0.07656[0m[0m | time: 27.848s
[2K
| RMSProp | epoch: 020 | loss: 0.07656 - acc: 0.9816 -- iter: 0992/1257
[A[ATraining Step: 792  | total loss: [1m[32m0.06971[0m[0m | time: 28.787s
[2K
| RMSProp | epoch: 020 | loss: 0.06971 - acc: 0.9835 -- iter: 1024/1257
[A[ATraining Step: 793  | total loss: [1m[32m0.06344[0m[0m | time: 29.680s
[2K
| RMSProp | epoch: 020 | loss: 0.06344 - acc: 0.9851 -- iter: 1056/1257
[A[ATraining Step: 794  | total loss: [1m[32m0.05782[0m[0m | time: 30.735s
[2K
| RMSProp | epoch: 020 | loss: 0.05782 - acc: 0.9866 -- iter: 1088/1257
[A[ATraining Step: 795  | total loss: [1m[32m0.05293[0m[0m | time: 31.774s
[2K
| RMSProp | epoch: 020 | loss: 0.05293 - acc: 0.9880 -- iter: 1120/1257
[A[ATraining Step: 796  | total loss: [1m[32m0.04801[0m[0m | time: 32.590s
[2K
| RMSProp | epoch: 020 | loss: 0.04801 - acc: 0.9892 -- iter: 1152/1257
[A[ATraining Step: 797  | total loss: [1m[32m0.04376[0m[0m | time: 33.484s
[2K
| RMSProp | epoch: 020 | loss: 0.04376 - acc: 0.9902 -- iter: 1184/1257
[A[ATraining Step: 798  | total loss: [1m[32m0.03956[0m[0m | time: 34.407s
[2K
| RMSProp | epoch: 020 | loss: 0.03956 - acc: 0.9912 -- iter: 1216/1257
[A[ATraining Step: 799  | total loss: [1m[32m0.03577[0m[0m | time: 35.321s
[2K
| RMSProp | epoch: 020 | loss: 0.03577 - acc: 0.9921 -- iter: 1248/1257
[A[ATraining Step: 800  | total loss: [1m[32m0.03235[0m[0m | time: 38.234s
[2K
| RMSProp | epoch: 020 | loss: 0.03235 - acc: 0.9929 | val_loss: 0.43062 - val_acc: 0.8909 -- iter: 1257/1257
--
Training Step: 801  | total loss: [1m[32m0.02947[0m[0m | time: 0.814s
[2K
| RMSProp | epoch: 021 | loss: 0.02947 - acc: 0.9936 -- iter: 0032/1257
[A[ATraining Step: 802  | total loss: [1m[32m0.02667[0m[0m | time: 1.871s
[2K
| RMSProp | epoch: 021 | loss: 0.02667 - acc: 0.9942 -- iter: 0064/1257
[A[ATraining Step: 803  | total loss: [1m[32m0.02424[0m[0m | time: 2.948s
[2K
| RMSProp | epoch: 021 | loss: 0.02424 - acc: 0.9948 -- iter: 0096/1257
[A[ATraining Step: 804  | total loss: [1m[32m0.02206[0m[0m | time: 3.817s
[2K
| RMSProp | epoch: 021 | loss: 0.02206 - acc: 0.9953 -- iter: 0128/1257
[A[ATraining Step: 805  | total loss: [1m[32m0.01995[0m[0m | time: 4.656s
[2K
| RMSProp | epoch: 021 | loss: 0.01995 - acc: 0.9958 -- iter: 0160/1257
[A[ATraining Step: 806  | total loss: [1m[32m0.01809[0m[0m | time: 5.552s
[2K
| RMSProp | epoch: 021 | loss: 0.01809 - acc: 0.9962 -- iter: 0192/1257
[A[ATraining Step: 807  | total loss: [1m[32m0.01646[0m[0m | time: 6.453s
[2K
| RMSProp | epoch: 021 | loss: 0.01646 - acc: 0.9966 -- iter: 0224/1257
[A[ATraining Step: 808  | total loss: [1m[32m0.01497[0m[0m | time: 7.376s
[2K
| RMSProp | epoch: 021 | loss: 0.01497 - acc: 0.9969 -- iter: 0256/1257
[A[ATraining Step: 809  | total loss: [1m[32m0.01351[0m[0m | time: 8.418s
[2K
| RMSProp | epoch: 021 | loss: 0.01351 - acc: 0.9972 -- iter: 0288/1257
[A[ATraining Step: 810  | total loss: [1m[32m0.01223[0m[0m | time: 9.425s
[2K
| RMSProp | epoch: 021 | loss: 0.01223 - acc: 0.9975 -- iter: 0320/1257
[A[ATraining Step: 811  | total loss: [1m[32m0.01113[0m[0m | time: 10.204s
[2K
| RMSProp | epoch: 021 | loss: 0.01113 - acc: 0.9978 -- iter: 0352/1257
[A[ATraining Step: 812  | total loss: [1m[32m0.01005[0m[0m | time: 11.344s
[2K
| RMSProp | epoch: 021 | loss: 0.01005 - acc: 0.9980 -- iter: 0384/1257
[A[ATraining Step: 813  | total loss: [1m[32m0.00916[0m[0m | time: 12.443s
[2K
| RMSProp | epoch: 021 | loss: 0.00916 - acc: 0.9982 -- iter: 0416/1257
[A[ATraining Step: 814  | total loss: [1m[32m0.00840[0m[0m | time: 13.312s
[2K
| RMSProp | epoch: 021 | loss: 0.00840 - acc: 0.9984 -- iter: 0448/1257
[A[ATraining Step: 815  | total loss: [1m[32m0.00761[0m[0m | time: 14.143s
[2K
| RMSProp | epoch: 021 | loss: 0.00761 - acc: 0.9985 -- iter: 0480/1257
[A[ATraining Step: 816  | total loss: [1m[32m0.00705[0m[0m | time: 15.046s
[2K
| RMSProp | epoch: 021 | loss: 0.00705 - acc: 0.9987 -- iter: 0512/1257
[A[ATraining Step: 817  | total loss: [1m[32m0.00646[0m[0m | time: 15.962s
[2K
| RMSProp | epoch: 021 | loss: 0.00646 - acc: 0.9988 -- iter: 0544/1257
[A[ATraining Step: 818  | total loss: [1m[32m0.00586[0m[0m | time: 16.842s
[2K
| RMSProp | epoch: 021 | loss: 0.00586 - acc: 0.9989 -- iter: 0576/1257
[A[ATraining Step: 819  | total loss: [1m[32m0.00535[0m[0m | time: 17.166s
[2K
| RMSProp | epoch: 021 | loss: 0.00535 - acc: 0.9990 -- iter: 0608/1257
[A[ATraining Step: 820  | total loss: [1m[32m0.00485[0m[0m | time: 17.527s
[2K
| RMSProp | epoch: 021 | loss: 0.00485 - acc: 0.9991 -- iter: 0640/1257
[A[ATraining Step: 821  | total loss: [1m[32m0.00439[0m[0m | time: 18.632s
[2K
| RMSProp | epoch: 021 | loss: 0.00439 - acc: 0.9992 -- iter: 0672/1257
[A[ATraining Step: 822  | total loss: [1m[32m0.00399[0m[0m | time: 19.527s
[2K
| RMSProp | epoch: 021 | loss: 0.00399 - acc: 0.9993 -- iter: 0704/1257
[A[ATraining Step: 823  | total loss: [1m[32m0.00364[0m[0m | time: 20.537s
[2K
| RMSProp | epoch: 021 | loss: 0.00364 - acc: 0.9994 -- iter: 0736/1257
[A[ATraining Step: 824  | total loss: [1m[32m0.00335[0m[0m | time: 21.609s
[2K
| RMSProp | epoch: 021 | loss: 0.00335 - acc: 0.9994 -- iter: 0768/1257
[A[ATraining Step: 825  | total loss: [1m[32m0.00302[0m[0m | time: 22.609s
[2K
| RMSProp | epoch: 021 | loss: 0.00302 - acc: 0.9995 -- iter: 0800/1257
[A[ATraining Step: 826  | total loss: [1m[32m0.00339[0m[0m | time: 23.393s
[2K
| RMSProp | epoch: 021 | loss: 0.00339 - acc: 0.9995 -- iter: 0832/1257
[A[ATraining Step: 827  | total loss: [1m[32m0.05708[0m[0m | time: 24.281s
[2K
| RMSProp | epoch: 021 | loss: 0.05708 - acc: 0.9808 -- iter: 0864/1257
[A[ATraining Step: 828  | total loss: [1m[32m0.12800[0m[0m | time: 25.188s
[2K
| RMSProp | epoch: 021 | loss: 0.12800 - acc: 0.9578 -- iter: 0896/1257
[A[ATraining Step: 829  | total loss: [1m[32m0.11648[0m[0m | time: 26.085s
[2K
| RMSProp | epoch: 021 | loss: 0.11648 - acc: 0.9620 -- iter: 0928/1257
[A[ATraining Step: 830  | total loss: [1m[32m0.10541[0m[0m | time: 27.031s
[2K
| RMSProp | epoch: 021 | loss: 0.10541 - acc: 0.9658 -- iter: 0960/1257
[A[ATraining Step: 831  | total loss: [1m[32m0.09739[0m[0m | time: 28.036s
[2K
| RMSProp | epoch: 021 | loss: 0.09739 - acc: 0.9692 -- iter: 0992/1257
[A[ATraining Step: 832  | total loss: [1m[32m0.08776[0m[0m | time: 28.986s
[2K
| RMSProp | epoch: 021 | loss: 0.08776 - acc: 0.9723 -- iter: 1024/1257
[A[ATraining Step: 833  | total loss: [1m[32m0.07954[0m[0m | time: 29.882s
[2K
| RMSProp | epoch: 021 | loss: 0.07954 - acc: 0.9751 -- iter: 1056/1257
[A[ATraining Step: 834  | total loss: [1m[32m0.07288[0m[0m | time: 30.918s
[2K
| RMSProp | epoch: 021 | loss: 0.07288 - acc: 0.9775 -- iter: 1088/1257
[A[ATraining Step: 835  | total loss: [1m[32m0.07716[0m[0m | time: 31.935s
[2K
| RMSProp | epoch: 021 | loss: 0.07716 - acc: 0.9735 -- iter: 1120/1257
[A[ATraining Step: 836  | total loss: [1m[32m0.07299[0m[0m | time: 32.715s
[2K
| RMSProp | epoch: 021 | loss: 0.07299 - acc: 0.9731 -- iter: 1152/1257
[A[ATraining Step: 837  | total loss: [1m[32m0.06585[0m[0m | time: 33.572s
[2K
| RMSProp | epoch: 021 | loss: 0.06585 - acc: 0.9758 -- iter: 1184/1257
[A[ATraining Step: 838  | total loss: [1m[32m0.06186[0m[0m | time: 34.446s
[2K
| RMSProp | epoch: 021 | loss: 0.06186 - acc: 0.9751 -- iter: 1216/1257
[A[ATraining Step: 839  | total loss: [1m[32m0.05650[0m[0m | time: 35.396s
[2K
| RMSProp | epoch: 021 | loss: 0.05650 - acc: 0.9776 -- iter: 1248/1257
[A[ATraining Step: 840  | total loss: [1m[32m0.05184[0m[0m | time: 38.301s
[2K
| RMSProp | epoch: 021 | loss: 0.05184 - acc: 0.9798 | val_loss: 0.47220 - val_acc: 0.8883 -- iter: 1257/1257
--
Training Step: 841  | total loss: [1m[32m0.04770[0m[0m | time: 0.847s
[2K
| RMSProp | epoch: 022 | loss: 0.04770 - acc: 0.9818 -- iter: 0032/1257
[A[ATraining Step: 842  | total loss: [1m[32m0.04306[0m[0m | time: 1.941s
[2K
| RMSProp | epoch: 022 | loss: 0.04306 - acc: 0.9836 -- iter: 0064/1257
[A[ATraining Step: 843  | total loss: [1m[32m0.03900[0m[0m | time: 3.037s
[2K
| RMSProp | epoch: 022 | loss: 0.03900 - acc: 0.9853 -- iter: 0096/1257
[A[ATraining Step: 844  | total loss: [1m[32m0.03520[0m[0m | time: 3.917s
[2K
| RMSProp | epoch: 022 | loss: 0.03520 - acc: 0.9867 -- iter: 0128/1257
[A[ATraining Step: 845  | total loss: [1m[32m0.03183[0m[0m | time: 4.751s
[2K
| RMSProp | epoch: 022 | loss: 0.03183 - acc: 0.9881 -- iter: 0160/1257
[A[ATraining Step: 846  | total loss: [1m[32m0.02878[0m[0m | time: 5.613s
[2K
| RMSProp | epoch: 022 | loss: 0.02878 - acc: 0.9893 -- iter: 0192/1257
[A[ATraining Step: 847  | total loss: [1m[32m0.02592[0m[0m | time: 6.624s
[2K
| RMSProp | epoch: 022 | loss: 0.02592 - acc: 0.9903 -- iter: 0224/1257
[A[ATraining Step: 848  | total loss: [1m[32m0.02340[0m[0m | time: 7.545s
[2K
| RMSProp | epoch: 022 | loss: 0.02340 - acc: 0.9913 -- iter: 0256/1257
[A[ATraining Step: 849  | total loss: [1m[32m0.02160[0m[0m | time: 8.567s
[2K
| RMSProp | epoch: 022 | loss: 0.02160 - acc: 0.9922 -- iter: 0288/1257
[A[ATraining Step: 850  | total loss: [1m[32m0.01949[0m[0m | time: 9.464s
[2K
| RMSProp | epoch: 022 | loss: 0.01949 - acc: 0.9930 -- iter: 0320/1257
[A[ATraining Step: 851  | total loss: [1m[32m0.01782[0m[0m | time: 10.286s
[2K
| RMSProp | epoch: 022 | loss: 0.01782 - acc: 0.9937 -- iter: 0352/1257
[A[ATraining Step: 852  | total loss: [1m[32m0.01616[0m[0m | time: 11.274s
[2K
| RMSProp | epoch: 022 | loss: 0.01616 - acc: 0.9943 -- iter: 0384/1257
[A[ATraining Step: 853  | total loss: [1m[32m0.01461[0m[0m | time: 12.365s
[2K
| RMSProp | epoch: 022 | loss: 0.01461 - acc: 0.9949 -- iter: 0416/1257
[A[ATraining Step: 854  | total loss: [1m[32m0.01320[0m[0m | time: 13.317s
[2K
| RMSProp | epoch: 022 | loss: 0.01320 - acc: 0.9954 -- iter: 0448/1257
[A[ATraining Step: 855  | total loss: [1m[32m0.01193[0m[0m | time: 14.090s
[2K
| RMSProp | epoch: 022 | loss: 0.01193 - acc: 0.9958 -- iter: 0480/1257
[A[ATraining Step: 856  | total loss: [1m[32m0.01091[0m[0m | time: 14.958s
[2K
| RMSProp | epoch: 022 | loss: 0.01091 - acc: 0.9963 -- iter: 0512/1257
[A[ATraining Step: 857  | total loss: [1m[32m0.00996[0m[0m | time: 15.834s
[2K
| RMSProp | epoch: 022 | loss: 0.00996 - acc: 0.9966 -- iter: 0544/1257
[A[ATraining Step: 858  | total loss: [1m[32m0.00925[0m[0m | time: 16.771s
[2K
| RMSProp | epoch: 022 | loss: 0.00925 - acc: 0.9970 -- iter: 0576/1257
[A[ATraining Step: 859  | total loss: [1m[32m0.00834[0m[0m | time: 17.750s
[2K
| RMSProp | epoch: 022 | loss: 0.00834 - acc: 0.9973 -- iter: 0608/1257
[A[ATraining Step: 860  | total loss: [1m[32m0.00753[0m[0m | time: 18.093s
[2K
| RMSProp | epoch: 022 | loss: 0.00753 - acc: 0.9975 -- iter: 0640/1257
[A[ATraining Step: 861  | total loss: [1m[32m0.00680[0m[0m | time: 18.427s
[2K
| RMSProp | epoch: 022 | loss: 0.00680 - acc: 0.9978 -- iter: 0672/1257
[A[ATraining Step: 862  | total loss: [1m[32m0.00613[0m[0m | time: 19.360s
[2K
| RMSProp | epoch: 022 | loss: 0.00613 - acc: 0.9980 -- iter: 0704/1257
[A[ATraining Step: 863  | total loss: [1m[32m0.00571[0m[0m | time: 20.232s
[2K
| RMSProp | epoch: 022 | loss: 0.00571 - acc: 0.9982 -- iter: 0736/1257
[A[ATraining Step: 864  | total loss: [1m[32m0.00626[0m[0m | time: 21.298s
[2K
| RMSProp | epoch: 022 | loss: 0.00626 - acc: 0.9984 -- iter: 0768/1257
[A[ATraining Step: 865  | total loss: [1m[32m0.05486[0m[0m | time: 22.384s
[2K
| RMSProp | epoch: 022 | loss: 0.05486 - acc: 0.9860 -- iter: 0800/1257
[A[ATraining Step: 866  | total loss: [1m[32m0.13955[0m[0m | time: 23.189s
[2K
| RMSProp | epoch: 022 | loss: 0.13955 - acc: 0.9656 -- iter: 0832/1257
[A[ATraining Step: 867  | total loss: [1m[32m0.12581[0m[0m | time: 24.077s
[2K
| RMSProp | epoch: 022 | loss: 0.12581 - acc: 0.9690 -- iter: 0864/1257
[A[ATraining Step: 868  | total loss: [1m[32m0.11613[0m[0m | time: 24.965s
[2K
| RMSProp | epoch: 022 | loss: 0.11613 - acc: 0.9721 -- iter: 0896/1257
[A[ATraining Step: 869  | total loss: [1m[32m0.10468[0m[0m | time: 25.901s
[2K
| RMSProp | epoch: 022 | loss: 0.10468 - acc: 0.9749 -- iter: 0928/1257
[A[ATraining Step: 870  | total loss: [1m[32m0.18173[0m[0m | time: 26.882s
[2K
| RMSProp | epoch: 022 | loss: 0.18173 - acc: 0.9649 -- iter: 0960/1257
[A[ATraining Step: 871  | total loss: [1m[32m0.19841[0m[0m | time: 27.910s
[2K
| RMSProp | epoch: 022 | loss: 0.19841 - acc: 0.9559 -- iter: 0992/1257
[A[ATraining Step: 872  | total loss: [1m[32m0.18382[0m[0m | time: 28.861s
[2K
| RMSProp | epoch: 022 | loss: 0.18382 - acc: 0.9572 -- iter: 1024/1257
[A[ATraining Step: 873  | total loss: [1m[32m0.17412[0m[0m | time: 29.736s
[2K
| RMSProp | epoch: 022 | loss: 0.17412 - acc: 0.9584 -- iter: 1056/1257
[A[ATraining Step: 874  | total loss: [1m[32m0.15736[0m[0m | time: 30.795s
[2K
| RMSProp | epoch: 022 | loss: 0.15736 - acc: 0.9625 -- iter: 1088/1257
[A[ATraining Step: 875  | total loss: [1m[32m0.14269[0m[0m | time: 31.833s
[2K
| RMSProp | epoch: 022 | loss: 0.14269 - acc: 0.9663 -- iter: 1120/1257
[A[ATraining Step: 876  | total loss: [1m[32m0.12862[0m[0m | time: 32.607s
[2K
| RMSProp | epoch: 022 | loss: 0.12862 - acc: 0.9696 -- iter: 1152/1257
[A[ATraining Step: 877  | total loss: [1m[32m0.11662[0m[0m | time: 33.488s
[2K
| RMSProp | epoch: 022 | loss: 0.11662 - acc: 0.9727 -- iter: 1184/1257
[A[ATraining Step: 878  | total loss: [1m[32m0.10517[0m[0m | time: 34.448s
[2K
| RMSProp | epoch: 022 | loss: 0.10517 - acc: 0.9754 -- iter: 1216/1257
[A[ATraining Step: 879  | total loss: [1m[32m0.09568[0m[0m | time: 35.350s
[2K
| RMSProp | epoch: 022 | loss: 0.09568 - acc: 0.9779 -- iter: 1248/1257
[A[ATraining Step: 880  | total loss: [1m[32m0.08711[0m[0m | time: 38.287s
[2K
| RMSProp | epoch: 022 | loss: 0.08711 - acc: 0.9801 | val_loss: 0.52915 - val_acc: 0.8883 -- iter: 1257/1257
--
Training Step: 881  | total loss: [1m[32m0.07859[0m[0m | time: 0.805s
[2K
| RMSProp | epoch: 023 | loss: 0.07859 - acc: 0.9821 -- iter: 0032/1257
[A[ATraining Step: 882  | total loss: [1m[32m0.07147[0m[0m | time: 1.895s
[2K
| RMSProp | epoch: 023 | loss: 0.07147 - acc: 0.9839 -- iter: 0064/1257
[A[ATraining Step: 883  | total loss: [1m[32m0.06449[0m[0m | time: 2.951s
[2K
| RMSProp | epoch: 023 | loss: 0.06449 - acc: 0.9855 -- iter: 0096/1257
[A[ATraining Step: 884  | total loss: [1m[32m0.05820[0m[0m | time: 3.810s
[2K
| RMSProp | epoch: 023 | loss: 0.05820 - acc: 0.9869 -- iter: 0128/1257
[A[ATraining Step: 885  | total loss: [1m[32m0.05353[0m[0m | time: 4.648s
[2K
| RMSProp | epoch: 023 | loss: 0.05353 - acc: 0.9882 -- iter: 0160/1257
[A[ATraining Step: 886  | total loss: [1m[32m0.05149[0m[0m | time: 5.575s
[2K
| RMSProp | epoch: 023 | loss: 0.05149 - acc: 0.9863 -- iter: 0192/1257
[A[ATraining Step: 887  | total loss: [1m[32m0.04650[0m[0m | time: 6.506s
[2K
| RMSProp | epoch: 023 | loss: 0.04650 - acc: 0.9877 -- iter: 0224/1257
[A[ATraining Step: 888  | total loss: [1m[32m0.04189[0m[0m | time: 7.456s
[2K
| RMSProp | epoch: 023 | loss: 0.04189 - acc: 0.9889 -- iter: 0256/1257
[A[ATraining Step: 889  | total loss: [1m[32m0.04310[0m[0m | time: 8.506s
[2K
| RMSProp | epoch: 023 | loss: 0.04310 - acc: 0.9869 -- iter: 0288/1257
[A[ATraining Step: 890  | total loss: [1m[32m0.07540[0m[0m | time: 9.458s
[2K
| RMSProp | epoch: 023 | loss: 0.07540 - acc: 0.9788 -- iter: 0320/1257
[A[ATraining Step: 891  | total loss: [1m[32m0.07048[0m[0m | time: 10.297s
[2K
| RMSProp | epoch: 023 | loss: 0.07048 - acc: 0.9809 -- iter: 0352/1257
[A[ATraining Step: 892  | total loss: [1m[32m0.06421[0m[0m | time: 11.358s
[2K
| RMSProp | epoch: 023 | loss: 0.06421 - acc: 0.9828 -- iter: 0384/1257
[A[ATraining Step: 893  | total loss: [1m[32m0.05787[0m[0m | time: 12.467s
[2K
| RMSProp | epoch: 023 | loss: 0.05787 - acc: 0.9846 -- iter: 0416/1257
[A[ATraining Step: 894  | total loss: [1m[32m0.05260[0m[0m | time: 13.345s
[2K
| RMSProp | epoch: 023 | loss: 0.05260 - acc: 0.9861 -- iter: 0448/1257
[A[ATraining Step: 895  | total loss: [1m[32m0.05522[0m[0m | time: 14.212s
[2K
| RMSProp | epoch: 023 | loss: 0.05522 - acc: 0.9844 -- iter: 0480/1257
[A[ATraining Step: 896  | total loss: [1m[32m0.05027[0m[0m | time: 15.185s
[2K
| RMSProp | epoch: 023 | loss: 0.05027 - acc: 0.9859 -- iter: 0512/1257
[A[ATraining Step: 897  | total loss: [1m[32m0.04530[0m[0m | time: 16.063s
[2K
| RMSProp | epoch: 023 | loss: 0.04530 - acc: 0.9873 -- iter: 0544/1257
[A[ATraining Step: 898  | total loss: [1m[32m0.04978[0m[0m | time: 16.941s
[2K
| RMSProp | epoch: 023 | loss: 0.04978 - acc: 0.9855 -- iter: 0576/1257
[A[ATraining Step: 899  | total loss: [1m[32m0.05006[0m[0m | time: 17.951s
[2K
| RMSProp | epoch: 023 | loss: 0.05006 - acc: 0.9838 -- iter: 0608/1257
[A[ATraining Step: 900  | total loss: [1m[32m0.04665[0m[0m | time: 18.957s
[2K
| RMSProp | epoch: 023 | loss: 0.04665 - acc: 0.9854 -- iter: 0640/1257
[A[ATraining Step: 901  | total loss: [1m[32m0.04205[0m[0m | time: 19.236s
[2K
| RMSProp | epoch: 023 | loss: 0.04205 - acc: 0.9869 -- iter: 0672/1257
[A[ATraining Step: 902  | total loss: [1m[32m0.03796[0m[0m | time: 19.480s
[2K
| RMSProp | epoch: 023 | loss: 0.03796 - acc: 0.9882 -- iter: 0704/1257
[A[ATraining Step: 903  | total loss: [1m[32m0.03426[0m[0m | time: 20.447s
[2K
| RMSProp | epoch: 023 | loss: 0.03426 - acc: 0.9894 -- iter: 0736/1257
[A[ATraining Step: 904  | total loss: [1m[32m0.03146[0m[0m | time: 21.523s
[2K
| RMSProp | epoch: 023 | loss: 0.03146 - acc: 0.9904 -- iter: 0768/1257
[A[ATraining Step: 905  | total loss: [1m[32m0.03322[0m[0m | time: 22.500s
[2K
| RMSProp | epoch: 023 | loss: 0.03322 - acc: 0.9883 -- iter: 0800/1257
[A[ATraining Step: 906  | total loss: [1m[32m0.05806[0m[0m | time: 23.271s
[2K
| RMSProp | epoch: 023 | loss: 0.05806 - acc: 0.9769 -- iter: 0832/1257
[A[ATraining Step: 907  | total loss: [1m[32m0.05269[0m[0m | time: 24.214s
[2K
| RMSProp | epoch: 023 | loss: 0.05269 - acc: 0.9792 -- iter: 0864/1257
[A[ATraining Step: 908  | total loss: [1m[32m0.04749[0m[0m | time: 25.088s
[2K
| RMSProp | epoch: 023 | loss: 0.04749 - acc: 0.9813 -- iter: 0896/1257
[A[ATraining Step: 909  | total loss: [1m[32m0.04709[0m[0m | time: 25.966s
[2K
| RMSProp | epoch: 023 | loss: 0.04709 - acc: 0.9801 -- iter: 0928/1257
[A[ATraining Step: 910  | total loss: [1m[32m0.04263[0m[0m | time: 26.919s
[2K
| RMSProp | epoch: 023 | loss: 0.04263 - acc: 0.9821 -- iter: 0960/1257
[A[ATraining Step: 911  | total loss: [1m[32m0.06653[0m[0m | time: 27.904s
[2K
| RMSProp | epoch: 023 | loss: 0.06653 - acc: 0.9776 -- iter: 0992/1257
[A[ATraining Step: 912  | total loss: [1m[32m0.07999[0m[0m | time: 28.795s
[2K
| RMSProp | epoch: 023 | loss: 0.07999 - acc: 0.9705 -- iter: 1024/1257
[A[ATraining Step: 913  | total loss: [1m[32m0.09052[0m[0m | time: 29.644s
[2K
| RMSProp | epoch: 023 | loss: 0.09052 - acc: 0.9672 -- iter: 1056/1257
[A[ATraining Step: 914  | total loss: [1m[32m0.09136[0m[0m | time: 30.717s
[2K
| RMSProp | epoch: 023 | loss: 0.09136 - acc: 0.9673 -- iter: 1088/1257
[A[ATraining Step: 915  | total loss: [1m[32m0.08456[0m[0m | time: 31.814s
[2K
| RMSProp | epoch: 023 | loss: 0.08456 - acc: 0.9706 -- iter: 1120/1257
[A[ATraining Step: 916  | total loss: [1m[32m0.07630[0m[0m | time: 32.666s
[2K
| RMSProp | epoch: 023 | loss: 0.07630 - acc: 0.9735 -- iter: 1152/1257
[A[ATraining Step: 917  | total loss: [1m[32m0.06887[0m[0m | time: 33.494s
[2K
| RMSProp | epoch: 023 | loss: 0.06887 - acc: 0.9762 -- iter: 1184/1257
[A[ATraining Step: 918  | total loss: [1m[32m0.06423[0m[0m | time: 34.392s
[2K
| RMSProp | epoch: 023 | loss: 0.06423 - acc: 0.9786 -- iter: 1216/1257
[A[ATraining Step: 919  | total loss: [1m[32m0.05826[0m[0m | time: 35.272s
[2K
| RMSProp | epoch: 023 | loss: 0.05826 - acc: 0.9807 -- iter: 1248/1257
[A[ATraining Step: 920  | total loss: [1m[32m0.05274[0m[0m | time: 38.092s
[2K
| RMSProp | epoch: 023 | loss: 0.05274 - acc: 0.9826 | val_loss: 0.47310 - val_acc: 0.8832 -- iter: 1257/1257
--
Training Step: 921  | total loss: [1m[32m0.04777[0m[0m | time: 0.883s
[2K
| RMSProp | epoch: 024 | loss: 0.04777 - acc: 0.9844 -- iter: 0032/1257
[A[ATraining Step: 922  | total loss: [1m[32m0.04313[0m[0m | time: 1.845s
[2K
| RMSProp | epoch: 024 | loss: 0.04313 - acc: 0.9859 -- iter: 0064/1257
[A[ATraining Step: 923  | total loss: [1m[32m0.03900[0m[0m | time: 2.893s
[2K
| RMSProp | epoch: 024 | loss: 0.03900 - acc: 0.9873 -- iter: 0096/1257
[A[ATraining Step: 924  | total loss: [1m[32m0.03521[0m[0m | time: 3.841s
[2K
| RMSProp | epoch: 024 | loss: 0.03521 - acc: 0.9886 -- iter: 0128/1257
[A[ATraining Step: 925  | total loss: [1m[32m0.03247[0m[0m | time: 4.661s
[2K
| RMSProp | epoch: 024 | loss: 0.03247 - acc: 0.9897 -- iter: 0160/1257
[A[ATraining Step: 926  | total loss: [1m[32m0.02927[0m[0m | time: 5.598s
[2K
| RMSProp | epoch: 024 | loss: 0.02927 - acc: 0.9908 -- iter: 0192/1257
[A[ATraining Step: 927  | total loss: [1m[32m0.02752[0m[0m | time: 6.498s
[2K
| RMSProp | epoch: 024 | loss: 0.02752 - acc: 0.9917 -- iter: 0224/1257
[A[ATraining Step: 928  | total loss: [1m[32m0.02482[0m[0m | time: 7.390s
[2K
| RMSProp | epoch: 024 | loss: 0.02482 - acc: 0.9925 -- iter: 0256/1257
[A[ATraining Step: 929  | total loss: [1m[32m0.02260[0m[0m | time: 8.334s
[2K
| RMSProp | epoch: 024 | loss: 0.02260 - acc: 0.9933 -- iter: 0288/1257
[A[ATraining Step: 930  | total loss: [1m[32m0.02047[0m[0m | time: 9.356s
[2K
| RMSProp | epoch: 024 | loss: 0.02047 - acc: 0.9939 -- iter: 0320/1257
[A[ATraining Step: 931  | total loss: [1m[32m0.01850[0m[0m | time: 10.232s
[2K
| RMSProp | epoch: 024 | loss: 0.01850 - acc: 0.9946 -- iter: 0352/1257
[A[ATraining Step: 932  | total loss: [1m[32m0.01679[0m[0m | time: 11.108s
[2K
| RMSProp | epoch: 024 | loss: 0.01679 - acc: 0.9951 -- iter: 0384/1257
[A[ATraining Step: 933  | total loss: [1m[32m0.01517[0m[0m | time: 12.131s
[2K
| RMSProp | epoch: 024 | loss: 0.01517 - acc: 0.9956 -- iter: 0416/1257
[A[ATraining Step: 934  | total loss: [1m[32m0.01368[0m[0m | time: 13.171s
[2K
| RMSProp | epoch: 024 | loss: 0.01368 - acc: 0.9960 -- iter: 0448/1257
[A[ATraining Step: 935  | total loss: [1m[32m0.01242[0m[0m | time: 13.953s
[2K
| RMSProp | epoch: 024 | loss: 0.01242 - acc: 0.9964 -- iter: 0480/1257
[A[ATraining Step: 936  | total loss: [1m[32m0.01122[0m[0m | time: 14.808s
[2K
| RMSProp | epoch: 024 | loss: 0.01122 - acc: 0.9968 -- iter: 0512/1257
[A[ATraining Step: 937  | total loss: [1m[32m0.01120[0m[0m | time: 15.681s
[2K
| RMSProp | epoch: 024 | loss: 0.01120 - acc: 0.9971 -- iter: 0544/1257
[A[ATraining Step: 938  | total loss: [1m[32m0.01354[0m[0m | time: 16.593s
[2K
| RMSProp | epoch: 024 | loss: 0.01354 - acc: 0.9974 -- iter: 0576/1257
[A[ATraining Step: 939  | total loss: [1m[32m0.01317[0m[0m | time: 17.523s
[2K
| RMSProp | epoch: 024 | loss: 0.01317 - acc: 0.9977 -- iter: 0608/1257
[A[ATraining Step: 940  | total loss: [1m[32m0.01200[0m[0m | time: 18.520s
[2K
| RMSProp | epoch: 024 | loss: 0.01200 - acc: 0.9979 -- iter: 0640/1257
[A[ATraining Step: 941  | total loss: [1m[32m0.01086[0m[0m | time: 19.512s
[2K
| RMSProp | epoch: 024 | loss: 0.01086 - acc: 0.9981 -- iter: 0672/1257
[A[ATraining Step: 942  | total loss: [1m[32m0.01038[0m[0m | time: 19.792s
[2K
| RMSProp | epoch: 024 | loss: 0.01038 - acc: 0.9983 -- iter: 0704/1257
[A[ATraining Step: 943  | total loss: [1m[32m0.00974[0m[0m | time: 20.049s
[2K
| RMSProp | epoch: 024 | loss: 0.00974 - acc: 0.9985 -- iter: 0736/1257
[A[ATraining Step: 944  | total loss: [1m[32m0.00878[0m[0m | time: 21.068s
[2K
| RMSProp | epoch: 024 | loss: 0.00878 - acc: 0.9986 -- iter: 0768/1257
[A[ATraining Step: 945  | total loss: [1m[32m0.00798[0m[0m | time: 22.130s
[2K
| RMSProp | epoch: 024 | loss: 0.00798 - acc: 0.9988 -- iter: 0800/1257
[A[ATraining Step: 946  | total loss: [1m[32m0.00720[0m[0m | time: 23.127s
[2K
| RMSProp | epoch: 024 | loss: 0.00720 - acc: 0.9989 -- iter: 0832/1257
[A[ATraining Step: 947  | total loss: [1m[32m0.02218[0m[0m | time: 23.949s
[2K
| RMSProp | epoch: 024 | loss: 0.02218 - acc: 0.9959 -- iter: 0864/1257
[A[ATraining Step: 948  | total loss: [1m[32m0.09530[0m[0m | time: 24.828s
[2K
| RMSProp | epoch: 024 | loss: 0.09530 - acc: 0.9713 -- iter: 0896/1257
[A[ATraining Step: 949  | total loss: [1m[32m0.10988[0m[0m | time: 25.708s
[2K
| RMSProp | epoch: 024 | loss: 0.10988 - acc: 0.9679 -- iter: 0928/1257
[A[ATraining Step: 950  | total loss: [1m[32m0.10071[0m[0m | time: 26.626s
[2K
| RMSProp | epoch: 024 | loss: 0.10071 - acc: 0.9711 -- iter: 0960/1257
[A[ATraining Step: 951  | total loss: [1m[32m0.09078[0m[0m | time: 27.610s
[2K
| RMSProp | epoch: 024 | loss: 0.09078 - acc: 0.9740 -- iter: 0992/1257
[A[ATraining Step: 952  | total loss: [1m[32m0.08186[0m[0m | time: 28.655s
[2K
| RMSProp | epoch: 024 | loss: 0.08186 - acc: 0.9766 -- iter: 1024/1257
[A[ATraining Step: 953  | total loss: [1m[32m0.07376[0m[0m | time: 29.546s
[2K
| RMSProp | epoch: 024 | loss: 0.07376 - acc: 0.9789 -- iter: 1056/1257
[A[ATraining Step: 954  | total loss: [1m[32m0.06646[0m[0m | time: 30.568s
[2K
| RMSProp | epoch: 024 | loss: 0.06646 - acc: 0.9810 -- iter: 1088/1257
[A[ATraining Step: 955  | total loss: [1m[32m0.05997[0m[0m | time: 31.608s
[2K
| RMSProp | epoch: 024 | loss: 0.05997 - acc: 0.9829 -- iter: 1120/1257
[A[ATraining Step: 956  | total loss: [1m[32m0.05410[0m[0m | time: 32.621s
[2K
| RMSProp | epoch: 024 | loss: 0.05410 - acc: 0.9846 -- iter: 1152/1257
[A[ATraining Step: 957  | total loss: [1m[32m0.04873[0m[0m | time: 33.373s
[2K
| RMSProp | epoch: 024 | loss: 0.04873 - acc: 0.9862 -- iter: 1184/1257
[A[ATraining Step: 958  | total loss: [1m[32m0.04465[0m[0m | time: 34.218s
[2K
| RMSProp | epoch: 024 | loss: 0.04465 - acc: 0.9876 -- iter: 1216/1257
[A[ATraining Step: 959  | total loss: [1m[32m0.04113[0m[0m | time: 35.093s
[2K
| RMSProp | epoch: 024 | loss: 0.04113 - acc: 0.9888 -- iter: 1248/1257
[A[ATraining Step: 960  | total loss: [1m[32m0.03705[0m[0m | time: 37.818s
[2K
| RMSProp | epoch: 024 | loss: 0.03705 - acc: 0.9899 | val_loss: 0.53089 - val_acc: 0.8756 -- iter: 1257/1257
--
Training Step: 961  | total loss: [1m[32m0.03342[0m[0m | time: 0.970s
[2K
| RMSProp | epoch: 025 | loss: 0.03342 - acc: 0.9909 -- iter: 0032/1257
[A[ATraining Step: 962  | total loss: [1m[32m0.03022[0m[0m | time: 1.788s
[2K
| RMSProp | epoch: 025 | loss: 0.03022 - acc: 0.9918 -- iter: 0064/1257
[A[ATraining Step: 963  | total loss: [1m[32m0.02723[0m[0m | time: 2.889s
[2K
| RMSProp | epoch: 025 | loss: 0.02723 - acc: 0.9927 -- iter: 0096/1257
[A[ATraining Step: 964  | total loss: [1m[32m0.02677[0m[0m | time: 3.890s
[2K
| RMSProp | epoch: 025 | loss: 0.02677 - acc: 0.9934 -- iter: 0128/1257
[A[ATraining Step: 965  | total loss: [1m[32m0.05011[0m[0m | time: 4.738s
[2K
| RMSProp | epoch: 025 | loss: 0.05011 - acc: 0.9847 -- iter: 0160/1257
[A[ATraining Step: 966  | total loss: [1m[32m0.06994[0m[0m | time: 5.587s
[2K
| RMSProp | epoch: 025 | loss: 0.06994 - acc: 0.9831 -- iter: 0192/1257
[A[ATraining Step: 967  | total loss: [1m[32m0.06346[0m[0m | time: 6.475s
[2K
| RMSProp | epoch: 025 | loss: 0.06346 - acc: 0.9848 -- iter: 0224/1257
[A[ATraining Step: 968  | total loss: [1m[32m0.05856[0m[0m | time: 7.385s
[2K
| RMSProp | epoch: 025 | loss: 0.05856 - acc: 0.9863 -- iter: 0256/1257
[A[ATraining Step: 969  | total loss: [1m[32m0.05343[0m[0m | time: 8.293s
[2K
| RMSProp | epoch: 025 | loss: 0.05343 - acc: 0.9877 -- iter: 0288/1257
[A[ATraining Step: 970  | total loss: [1m[32m0.04856[0m[0m | time: 9.298s
[2K
| RMSProp | epoch: 025 | loss: 0.04856 - acc: 0.9889 -- iter: 0320/1257
[A[ATraining Step: 971  | total loss: [1m[32m0.04387[0m[0m | time: 10.299s
[2K
| RMSProp | epoch: 025 | loss: 0.04387 - acc: 0.9900 -- iter: 0352/1257
[A[ATraining Step: 972  | total loss: [1m[32m0.04988[0m[0m | time: 11.116s
[2K
| RMSProp | epoch: 025 | loss: 0.04988 - acc: 0.9848 -- iter: 0384/1257
[A[ATraining Step: 973  | total loss: [1m[32m0.06695[0m[0m | time: 12.160s
[2K
| RMSProp | epoch: 025 | loss: 0.06695 - acc: 0.9769 -- iter: 0416/1257
[A[ATraining Step: 974  | total loss: [1m[32m0.07554[0m[0m | time: 13.251s
[2K
| RMSProp | epoch: 025 | loss: 0.07554 - acc: 0.9730 -- iter: 0448/1257
[A[ATraining Step: 975  | total loss: [1m[32m0.06842[0m[0m | time: 14.133s
[2K
| RMSProp | epoch: 025 | loss: 0.06842 - acc: 0.9757 -- iter: 0480/1257
[A[ATraining Step: 976  | total loss: [1m[32m0.06173[0m[0m | time: 15.034s
[2K
| RMSProp | epoch: 025 | loss: 0.06173 - acc: 0.9781 -- iter: 0512/1257
[A[ATraining Step: 977  | total loss: [1m[32m0.05566[0m[0m | time: 15.957s
[2K
| RMSProp | epoch: 025 | loss: 0.05566 - acc: 0.9803 -- iter: 0544/1257
[A[ATraining Step: 978  | total loss: [1m[32m0.05095[0m[0m | time: 16.848s
[2K
| RMSProp | epoch: 025 | loss: 0.05095 - acc: 0.9823 -- iter: 0576/1257
[A[ATraining Step: 979  | total loss: [1m[32m0.04595[0m[0m | time: 17.762s
[2K
| RMSProp | epoch: 025 | loss: 0.04595 - acc: 0.9840 -- iter: 0608/1257
[A[ATraining Step: 980  | total loss: [1m[32m0.04146[0m[0m | time: 18.819s
[2K
| RMSProp | epoch: 025 | loss: 0.04146 - acc: 0.9856 -- iter: 0640/1257
[A[ATraining Step: 981  | total loss: [1m[32m0.03761[0m[0m | time: 19.821s
[2K
| RMSProp | epoch: 025 | loss: 0.03761 - acc: 0.9871 -- iter: 0672/1257
[A[ATraining Step: 982  | total loss: [1m[32m0.03388[0m[0m | time: 20.641s
[2K
| RMSProp | epoch: 025 | loss: 0.03388 - acc: 0.9884 -- iter: 0704/1257
[A[ATraining Step: 983  | total loss: [1m[32m0.03065[0m[0m | time: 20.970s
[2K
| RMSProp | epoch: 025 | loss: 0.03065 - acc: 0.9895 -- iter: 0736/1257
[A[ATraining Step: 984  | total loss: [1m[32m0.02761[0m[0m | time: 21.308s
[2K
| RMSProp | epoch: 025 | loss: 0.02761 - acc: 0.9906 -- iter: 0768/1257
[A[ATraining Step: 985  | total loss: [1m[32m0.02487[0m[0m | time: 22.283s
[2K
| RMSProp | epoch: 025 | loss: 0.02487 - acc: 0.9915 -- iter: 0800/1257
[A[ATraining Step: 986  | total loss: [1m[32m0.02249[0m[0m | time: 23.279s
[2K
| RMSProp | epoch: 025 | loss: 0.02249 - acc: 0.9924 -- iter: 0832/1257
[A[ATraining Step: 987  | total loss: [1m[32m0.02031[0m[0m | time: 24.265s
[2K
| RMSProp | epoch: 025 | loss: 0.02031 - acc: 0.9931 -- iter: 0864/1257
[A[ATraining Step: 988  | total loss: [1m[32m0.01835[0m[0m | time: 25.311s
[2K
| RMSProp | epoch: 025 | loss: 0.01835 - acc: 0.9938 -- iter: 0896/1257
[A[ATraining Step: 989  | total loss: [1m[32m0.01653[0m[0m | time: 26.248s
[2K
| RMSProp | epoch: 025 | loss: 0.01653 - acc: 0.9944 -- iter: 0928/1257
[A[ATraining Step: 990  | total loss: [1m[32m0.01493[0m[0m | time: 27.219s
[2K
| RMSProp | epoch: 025 | loss: 0.01493 - acc: 0.9950 -- iter: 0960/1257
[A[ATraining Step: 991  | total loss: [1m[32m0.01348[0m[0m | time: 28.167s
[2K
| RMSProp | epoch: 025 | loss: 0.01348 - acc: 0.9955 -- iter: 0992/1257
[A[ATraining Step: 992  | total loss: [1m[32m0.01221[0m[0m | time: 29.178s
[2K
| RMSProp | epoch: 025 | loss: 0.01221 - acc: 0.9959 -- iter: 1024/1257
[A[ATraining Step: 993  | total loss: [1m[32m0.04512[0m[0m | time: 30.192s
[2K
| RMSProp | epoch: 025 | loss: 0.04512 - acc: 0.9932 -- iter: 1056/1257
[A[ATraining Step: 994  | total loss: [1m[32m0.04399[0m[0m | time: 31.214s
[2K
| RMSProp | epoch: 025 | loss: 0.04399 - acc: 0.9908 -- iter: 1088/1257
[A[ATraining Step: 995  | total loss: [1m[32m0.04145[0m[0m | time: 32.253s
[2K
| RMSProp | epoch: 025 | loss: 0.04145 - acc: 0.9917 -- iter: 1120/1257
[A[ATraining Step: 996  | total loss: [1m[32m0.05032[0m[0m | time: 33.226s
[2K
| RMSProp | epoch: 025 | loss: 0.05032 - acc: 0.9894 -- iter: 1152/1257
[A[ATraining Step: 997  | total loss: [1m[32m0.05649[0m[0m | time: 34.246s
[2K
| RMSProp | epoch: 025 | loss: 0.05649 - acc: 0.9811 -- iter: 1184/1257
[A[ATraining Step: 998  | total loss: [1m[32m0.05500[0m[0m | time: 35.213s
[2K
| RMSProp | epoch: 025 | loss: 0.05500 - acc: 0.9799 -- iter: 1216/1257
[A[ATraining Step: 999  | total loss: [1m[32m0.04976[0m[0m | time: 36.199s
[2K
| RMSProp | epoch: 025 | loss: 0.04976 - acc: 0.9819 -- iter: 1248/1257
[A[ATraining Step: 1000  | total loss: [1m[32m0.04499[0m[0m | time: 39.154s
[2K
| RMSProp | epoch: 025 | loss: 0.04499 - acc: 0.9837 | val_loss: 0.51731 - val_acc: 0.8706 -- iter: 1257/1257
--
Training Step: 1001  | total loss: [1m[32m0.04242[0m[0m | time: 0.970s
[2K
| RMSProp | epoch: 026 | loss: 0.04242 - acc: 0.9853 -- iter: 0032/1257
[A[ATraining Step: 1002  | total loss: [1m[32m0.03832[0m[0m | time: 1.964s
[2K
| RMSProp | epoch: 026 | loss: 0.03832 - acc: 0.9868 -- iter: 0064/1257
[A[ATraining Step: 1003  | total loss: [1m[32m0.03544[0m[0m | time: 3.018s
[2K
| RMSProp | epoch: 026 | loss: 0.03544 - acc: 0.9881 -- iter: 0096/1257
[A[ATraining Step: 1004  | total loss: [1m[32m0.03207[0m[0m | time: 4.022s
[2K
| RMSProp | epoch: 026 | loss: 0.03207 - acc: 0.9893 -- iter: 0128/1257
[A[ATraining Step: 1005  | total loss: [1m[32m0.02905[0m[0m | time: 4.984s
[2K
| RMSProp | epoch: 026 | loss: 0.02905 - acc: 0.9904 -- iter: 0160/1257
[A[ATraining Step: 1006  | total loss: [1m[32m0.02622[0m[0m | time: 6.002s
[2K
| RMSProp | epoch: 026 | loss: 0.02622 - acc: 0.9913 -- iter: 0192/1257
[A[ATraining Step: 1007  | total loss: [1m[32m0.02366[0m[0m | time: 7.013s
[2K
| RMSProp | epoch: 026 | loss: 0.02366 - acc: 0.9922 -- iter: 0224/1257
[A[ATraining Step: 1008  | total loss: [1m[32m0.02138[0m[0m | time: 8.079s
[2K
| RMSProp | epoch: 026 | loss: 0.02138 - acc: 0.9930 -- iter: 0256/1257
[A[ATraining Step: 1009  | total loss: [1m[32m0.01929[0m[0m | time: 9.135s
[2K
| RMSProp | epoch: 026 | loss: 0.01929 - acc: 0.9937 -- iter: 0288/1257
[A[ATraining Step: 1010  | total loss: [1m[32m0.01748[0m[0m | time: 10.096s
[2K
| RMSProp | epoch: 026 | loss: 0.01748 - acc: 0.9943 -- iter: 0320/1257
[A[ATraining Step: 1011  | total loss: [1m[32m0.01579[0m[0m | time: 11.124s
[2K
| RMSProp | epoch: 026 | loss: 0.01579 - acc: 0.9949 -- iter: 0352/1257
[A[ATraining Step: 1012  | total loss: [1m[32m0.01425[0m[0m | time: 12.111s
[2K
| RMSProp | epoch: 026 | loss: 0.01425 - acc: 0.9954 -- iter: 0384/1257
[A[ATraining Step: 1013  | total loss: [1m[32m0.01288[0m[0m | time: 13.146s
[2K
| RMSProp | epoch: 026 | loss: 0.01288 - acc: 0.9959 -- iter: 0416/1257
[A[ATraining Step: 1014  | total loss: [1m[32m0.01203[0m[0m | time: 14.151s
[2K
| RMSProp | epoch: 026 | loss: 0.01203 - acc: 0.9963 -- iter: 0448/1257
[A[ATraining Step: 1015  | total loss: [1m[32m0.01128[0m[0m | time: 15.083s
[2K
| RMSProp | epoch: 026 | loss: 0.01128 - acc: 0.9966 -- iter: 0480/1257
[A[ATraining Step: 1016  | total loss: [1m[32m0.01025[0m[0m | time: 16.059s
[2K
| RMSProp | epoch: 026 | loss: 0.01025 - acc: 0.9970 -- iter: 0512/1257
[A[ATraining Step: 1017  | total loss: [1m[32m0.00931[0m[0m | time: 17.055s
[2K
| RMSProp | epoch: 026 | loss: 0.00931 - acc: 0.9973 -- iter: 0544/1257
[A[ATraining Step: 1018  | total loss: [1m[32m0.00841[0m[0m | time: 18.076s
[2K
| RMSProp | epoch: 026 | loss: 0.00841 - acc: 0.9976 -- iter: 0576/1257
[A[ATraining Step: 1019  | total loss: [1m[32m0.00763[0m[0m | time: 19.052s
[2K
| RMSProp | epoch: 026 | loss: 0.00763 - acc: 0.9978 -- iter: 0608/1257
[A[ATraining Step: 1020  | total loss: [1m[32m0.00689[0m[0m | time: 20.070s
[2K
| RMSProp | epoch: 026 | loss: 0.00689 - acc: 0.9980 -- iter: 0640/1257
[A[ATraining Step: 1021  | total loss: [1m[32m0.00623[0m[0m | time: 21.002s
[2K
| RMSProp | epoch: 026 | loss: 0.00623 - acc: 0.9982 -- iter: 0672/1257
[A[ATraining Step: 1022  | total loss: [1m[32m0.00566[0m[0m | time: 21.631s
[2K
| RMSProp | epoch: 026 | loss: 0.00566 - acc: 0.9984 -- iter: 0704/1257
[A[ATraining Step: 1023  | total loss: [1m[32m0.00518[0m[0m | time: 22.264s
[2K
| RMSProp | epoch: 026 | loss: 0.00518 - acc: 0.9986 -- iter: 0736/1257
[A[ATraining Step: 1024  | total loss: [1m[32m0.00489[0m[0m | time: 22.468s
[2K
| RMSProp | epoch: 026 | loss: 0.00489 - acc: 0.9987 -- iter: 0768/1257
[A[ATraining Step: 1025  | total loss: [1m[32m0.00442[0m[0m | time: 22.682s
[2K
| RMSProp | epoch: 026 | loss: 0.00442 - acc: 0.9988 -- iter: 0800/1257
[A[ATraining Step: 1026  | total loss: [1m[32m0.00400[0m[0m | time: 23.283s
[2K
| RMSProp | epoch: 026 | loss: 0.00400 - acc: 0.9989 -- iter: 0832/1257
[A[ATraining Step: 1027  | total loss: [1m[32m0.00363[0m[0m | time: 23.888s
[2K
| RMSProp | epoch: 026 | loss: 0.00363 - acc: 0.9991 -- iter: 0864/1257
[A[ATraining Step: 1028  | total loss: [1m[32m0.00334[0m[0m | time: 24.481s
[2K
| RMSProp | epoch: 026 | loss: 0.00334 - acc: 0.9991 -- iter: 0896/1257
[A[ATraining Step: 1029  | total loss: [1m[32m0.00303[0m[0m | time: 25.092s
[2K
| RMSProp | epoch: 026 | loss: 0.00303 - acc: 0.9992 -- iter: 0928/1257
[A[ATraining Step: 1030  | total loss: [1m[32m0.00282[0m[0m | time: 25.703s
[2K
| RMSProp | epoch: 026 | loss: 0.00282 - acc: 0.9993 -- iter: 0960/1257
[A[ATraining Step: 1031  | total loss: [1m[32m0.00298[0m[0m | time: 26.292s
[2K
| RMSProp | epoch: 026 | loss: 0.00298 - acc: 0.9994 -- iter: 0992/1257
[A[ATraining Step: 1032  | total loss: [1m[32m0.00276[0m[0m | time: 26.902s
[2K
| RMSProp | epoch: 026 | loss: 0.00276 - acc: 0.9994 -- iter: 1024/1257
[A[ATraining Step: 1033  | total loss: [1m[32m0.00250[0m[0m | time: 27.494s
[2K
| RMSProp | epoch: 026 | loss: 0.00250 - acc: 0.9995 -- iter: 1056/1257
[A[ATraining Step: 1034  | total loss: [1m[32m0.03910[0m[0m | time: 28.108s
[2K
| RMSProp | epoch: 026 | loss: 0.03910 - acc: 0.9964 -- iter: 1088/1257
[A[ATraining Step: 1035  | total loss: [1m[32m0.06227[0m[0m | time: 28.731s
[2K
| RMSProp | epoch: 026 | loss: 0.06227 - acc: 0.9843 -- iter: 1120/1257
[A[ATraining Step: 1036  | total loss: [1m[32m0.08221[0m[0m | time: 29.343s
[2K
| RMSProp | epoch: 026 | loss: 0.08221 - acc: 0.9796 -- iter: 1152/1257
[A[ATraining Step: 1037  | total loss: [1m[32m0.08489[0m[0m | time: 29.942s
[2K
| RMSProp | epoch: 026 | loss: 0.08489 - acc: 0.9723 -- iter: 1184/1257
[A[ATraining Step: 1038  | total loss: [1m[32m0.09375[0m[0m | time: 30.559s
[2K
| RMSProp | epoch: 026 | loss: 0.09375 - acc: 0.9657 -- iter: 1216/1257
[A[ATraining Step: 1039  | total loss: [1m[32m0.09403[0m[0m | time: 31.158s
[2K
| RMSProp | epoch: 026 | loss: 0.09403 - acc: 0.9628 -- iter: 1248/1257
[A[ATraining Step: 1040  | total loss: [1m[32m0.08515[0m[0m | time: 32.994s
[2K
| RMSProp | epoch: 026 | loss: 0.08515 - acc: 0.9666 | val_loss: 0.41966 - val_acc: 0.8858 -- iter: 1257/1257
--
Training Step: 1041  | total loss: [1m[32m0.07716[0m[0m | time: 0.600s
[2K
| RMSProp | epoch: 027 | loss: 0.07716 - acc: 0.9699 -- iter: 0032/1257
[A[ATraining Step: 1042  | total loss: [1m[32m0.07105[0m[0m | time: 1.188s
[2K
| RMSProp | epoch: 027 | loss: 0.07105 - acc: 0.9729 -- iter: 0064/1257
[A[ATraining Step: 1043  | total loss: [1m[32m0.06426[0m[0m | time: 1.784s
[2K
| RMSProp | epoch: 027 | loss: 0.06426 - acc: 0.9756 -- iter: 0096/1257
[A[ATraining Step: 1044  | total loss: [1m[32m0.05807[0m[0m | time: 2.385s
[2K
| RMSProp | epoch: 027 | loss: 0.05807 - acc: 0.9781 -- iter: 0128/1257
[A[ATraining Step: 1045  | total loss: [1m[32m0.05244[0m[0m | time: 3.001s
[2K
| RMSProp | epoch: 027 | loss: 0.05244 - acc: 0.9803 -- iter: 0160/1257
[A[ATraining Step: 1046  | total loss: [1m[32m0.04743[0m[0m | time: 3.594s
[2K
| RMSProp | epoch: 027 | loss: 0.04743 - acc: 0.9822 -- iter: 0192/1257
[A[ATraining Step: 1047  | total loss: [1m[32m0.04288[0m[0m | time: 4.214s
[2K
| RMSProp | epoch: 027 | loss: 0.04288 - acc: 0.9840 -- iter: 0224/1257
[A[ATraining Step: 1048  | total loss: [1m[32m0.03876[0m[0m | time: 4.819s
[2K
| RMSProp | epoch: 027 | loss: 0.03876 - acc: 0.9856 -- iter: 0256/1257
[A[ATraining Step: 1049  | total loss: [1m[32m0.03615[0m[0m | time: 5.732s
[2K
| RMSProp | epoch: 027 | loss: 0.03615 - acc: 0.9870 -- iter: 0288/1257
[A[ATraining Step: 1050  | total loss: [1m[32m0.03415[0m[0m | time: 6.760s
[2K
| RMSProp | epoch: 027 | loss: 0.03415 - acc: 0.9883 -- iter: 0320/1257
[A[ATraining Step: 1051  | total loss: [1m[32m0.03106[0m[0m | time: 7.758s
[2K
| RMSProp | epoch: 027 | loss: 0.03106 - acc: 0.9895 -- iter: 0352/1257
[A[ATraining Step: 1052  | total loss: [1m[32m0.02805[0m[0m | time: 8.555s
[2K
| RMSProp | epoch: 027 | loss: 0.02805 - acc: 0.9906 -- iter: 0384/1257
[A[ATraining Step: 1053  | total loss: [1m[32m0.02540[0m[0m | time: 9.425s
[2K
| RMSProp | epoch: 027 | loss: 0.02540 - acc: 0.9915 -- iter: 0416/1257
[A[ATraining Step: 1054  | total loss: [1m[32m0.02292[0m[0m | time: 10.348s
[2K
| RMSProp | epoch: 027 | loss: 0.02292 - acc: 0.9924 -- iter: 0448/1257
[A[ATraining Step: 1055  | total loss: [1m[32m0.02065[0m[0m | time: 11.263s
[2K
| RMSProp | epoch: 027 | loss: 0.02065 - acc: 0.9931 -- iter: 0480/1257
[A[ATraining Step: 1056  | total loss: [1m[32m0.01862[0m[0m | time: 12.256s
[2K
| RMSProp | epoch: 027 | loss: 0.01862 - acc: 0.9938 -- iter: 0512/1257
[A[ATraining Step: 1057  | total loss: [1m[32m0.01691[0m[0m | time: 13.253s
[2K
| RMSProp | epoch: 027 | loss: 0.01691 - acc: 0.9944 -- iter: 0544/1257
[A[ATraining Step: 1058  | total loss: [1m[32m0.01525[0m[0m | time: 14.131s
[2K
| RMSProp | epoch: 027 | loss: 0.01525 - acc: 0.9950 -- iter: 0576/1257
[A[ATraining Step: 1059  | total loss: [1m[32m0.01383[0m[0m | time: 15.051s
[2K
| RMSProp | epoch: 027 | loss: 0.01383 - acc: 0.9955 -- iter: 0608/1257
[A[ATraining Step: 1060  | total loss: [1m[32m0.01257[0m[0m | time: 16.096s
[2K
| RMSProp | epoch: 027 | loss: 0.01257 - acc: 0.9959 -- iter: 0640/1257
[A[ATraining Step: 1061  | total loss: [1m[32m0.01148[0m[0m | time: 17.139s
[2K
| RMSProp | epoch: 027 | loss: 0.01148 - acc: 0.9963 -- iter: 0672/1257
[A[ATraining Step: 1062  | total loss: [1m[32m0.01037[0m[0m | time: 17.915s
[2K
| RMSProp | epoch: 027 | loss: 0.01037 - acc: 0.9967 -- iter: 0704/1257
[A[ATraining Step: 1063  | total loss: [1m[32m0.00997[0m[0m | time: 18.810s
[2K
| RMSProp | epoch: 027 | loss: 0.00997 - acc: 0.9970 -- iter: 0736/1257
[A[ATraining Step: 1064  | total loss: [1m[32m0.01016[0m[0m | time: 19.718s
[2K
| RMSProp | epoch: 027 | loss: 0.01016 - acc: 0.9973 -- iter: 0768/1257
[A[ATraining Step: 1065  | total loss: [1m[32m0.01646[0m[0m | time: 20.049s
[2K
| RMSProp | epoch: 027 | loss: 0.01646 - acc: 0.9913 -- iter: 0800/1257
[A[ATraining Step: 1066  | total loss: [1m[32m0.25440[0m[0m | time: 20.359s
[2K
| RMSProp | epoch: 027 | loss: 0.25440 - acc: 0.9478 -- iter: 0832/1257
[A[ATraining Step: 1067  | total loss: [1m[32m0.22900[0m[0m | time: 21.292s
[2K
| RMSProp | epoch: 027 | loss: 0.22900 - acc: 0.9530 -- iter: 0864/1257
[A[ATraining Step: 1068  | total loss: [1m[32m0.20662[0m[0m | time: 22.306s
[2K
| RMSProp | epoch: 027 | loss: 0.20662 - acc: 0.9577 -- iter: 0896/1257
[A[ATraining Step: 1069  | total loss: [1m[32m0.21035[0m[0m | time: 23.332s
[2K
| RMSProp | epoch: 027 | loss: 0.21035 - acc: 0.9588 -- iter: 0928/1257
[A[ATraining Step: 1070  | total loss: [1m[32m0.19078[0m[0m | time: 24.117s
[2K
| RMSProp | epoch: 027 | loss: 0.19078 - acc: 0.9629 -- iter: 0960/1257
[A[ATraining Step: 1071  | total loss: [1m[32m0.17239[0m[0m | time: 25.233s
[2K
| RMSProp | epoch: 027 | loss: 0.17239 - acc: 0.9666 -- iter: 0992/1257
[A[ATraining Step: 1072  | total loss: [1m[32m0.15563[0m[0m | time: 26.313s
[2K
| RMSProp | epoch: 027 | loss: 0.15563 - acc: 0.9700 -- iter: 1024/1257
[A[ATraining Step: 1073  | total loss: [1m[32m0.14068[0m[0m | time: 27.225s
[2K
| RMSProp | epoch: 027 | loss: 0.14068 - acc: 0.9730 -- iter: 1056/1257
[A[ATraining Step: 1074  | total loss: [1m[32m0.12676[0m[0m | time: 28.082s
[2K
| RMSProp | epoch: 027 | loss: 0.12676 - acc: 0.9757 -- iter: 1088/1257
[A[ATraining Step: 1075  | total loss: [1m[32m0.13616[0m[0m | time: 28.985s
[2K
| RMSProp | epoch: 027 | loss: 0.13616 - acc: 0.9750 -- iter: 1120/1257
[A[ATraining Step: 1076  | total loss: [1m[32m0.13528[0m[0m | time: 29.946s
[2K
| RMSProp | epoch: 027 | loss: 0.13528 - acc: 0.9744 -- iter: 1152/1257
[A[ATraining Step: 1077  | total loss: [1m[32m0.12239[0m[0m | time: 30.913s
[2K
| RMSProp | epoch: 027 | loss: 0.12239 - acc: 0.9769 -- iter: 1184/1257
[A[ATraining Step: 1078  | total loss: [1m[32m0.11380[0m[0m | time: 31.931s
[2K
| RMSProp | epoch: 027 | loss: 0.11380 - acc: 0.9792 -- iter: 1216/1257
[A[ATraining Step: 1079  | total loss: [1m[32m0.10312[0m[0m | time: 32.986s
[2K
| RMSProp | epoch: 027 | loss: 0.10312 - acc: 0.9813 -- iter: 1248/1257
[A[ATraining Step: 1080  | total loss: [1m[32m0.09318[0m[0m | time: 35.752s
[2K
| RMSProp | epoch: 027 | loss: 0.09318 - acc: 0.9832 | val_loss: 0.39008 - val_acc: 0.8934 -- iter: 1257/1257
--
Training Step: 1081  | total loss: [1m[32m0.08439[0m[0m | time: 0.855s
[2K
| RMSProp | epoch: 028 | loss: 0.08439 - acc: 0.9849 -- iter: 0032/1257
[A[ATraining Step: 1082  | total loss: [1m[32m0.07610[0m[0m | time: 1.741s
[2K
| RMSProp | epoch: 028 | loss: 0.07610 - acc: 0.9864 -- iter: 0064/1257
[A[ATraining Step: 1083  | total loss: [1m[32m0.06866[0m[0m | time: 2.714s
[2K
| RMSProp | epoch: 028 | loss: 0.06866 - acc: 0.9877 -- iter: 0096/1257
[A[ATraining Step: 1084  | total loss: [1m[32m0.06190[0m[0m | time: 3.663s
[2K
| RMSProp | epoch: 028 | loss: 0.06190 - acc: 0.9890 -- iter: 0128/1257
[A[ATraining Step: 1085  | total loss: [1m[32m0.05607[0m[0m | time: 4.609s
[2K
| RMSProp | epoch: 028 | loss: 0.05607 - acc: 0.9901 -- iter: 0160/1257
[A[ATraining Step: 1086  | total loss: [1m[32m0.05050[0m[0m | time: 5.663s
[2K
| RMSProp | epoch: 028 | loss: 0.05050 - acc: 0.9911 -- iter: 0192/1257
[A[ATraining Step: 1087  | total loss: [1m[32m0.04554[0m[0m | time: 6.614s
[2K
| RMSProp | epoch: 028 | loss: 0.04554 - acc: 0.9920 -- iter: 0224/1257
[A[ATraining Step: 1088  | total loss: [1m[32m0.04111[0m[0m | time: 7.429s
[2K
| RMSProp | epoch: 028 | loss: 0.04111 - acc: 0.9928 -- iter: 0256/1257
[A[ATraining Step: 1089  | total loss: [1m[32m0.03706[0m[0m | time: 8.534s
[2K
| RMSProp | epoch: 028 | loss: 0.03706 - acc: 0.9935 -- iter: 0288/1257
[A[ATraining Step: 1090  | total loss: [1m[32m0.04532[0m[0m | time: 9.634s
[2K
| RMSProp | epoch: 028 | loss: 0.04532 - acc: 0.9910 -- iter: 0320/1257
[A[ATraining Step: 1091  | total loss: [1m[32m0.04993[0m[0m | time: 10.529s
[2K
| RMSProp | epoch: 028 | loss: 0.04993 - acc: 0.9888 -- iter: 0352/1257
[A[ATraining Step: 1092  | total loss: [1m[32m0.04515[0m[0m | time: 11.379s
[2K
| RMSProp | epoch: 028 | loss: 0.04515 - acc: 0.9899 -- iter: 0384/1257
[A[ATraining Step: 1093  | total loss: [1m[32m0.04154[0m[0m | time: 12.356s
[2K
| RMSProp | epoch: 028 | loss: 0.04154 - acc: 0.9909 -- iter: 0416/1257
[A[ATraining Step: 1094  | total loss: [1m[32m0.03740[0m[0m | time: 13.316s
[2K
| RMSProp | epoch: 028 | loss: 0.03740 - acc: 0.9918 -- iter: 0448/1257
[A[ATraining Step: 1095  | total loss: [1m[32m0.03399[0m[0m | time: 14.261s
[2K
| RMSProp | epoch: 028 | loss: 0.03399 - acc: 0.9926 -- iter: 0480/1257
[A[ATraining Step: 1096  | total loss: [1m[32m0.03061[0m[0m | time: 15.318s
[2K
| RMSProp | epoch: 028 | loss: 0.03061 - acc: 0.9934 -- iter: 0512/1257
[A[ATraining Step: 1097  | total loss: [1m[32m0.02758[0m[0m | time: 16.318s
[2K
| RMSProp | epoch: 028 | loss: 0.02758 - acc: 0.9940 -- iter: 0544/1257
[A[ATraining Step: 1098  | total loss: [1m[32m0.02486[0m[0m | time: 17.245s
[2K
| RMSProp | epoch: 028 | loss: 0.02486 - acc: 0.9946 -- iter: 0576/1257
[A[ATraining Step: 1099  | total loss: [1m[32m0.02241[0m[0m | time: 18.310s
[2K
| RMSProp | epoch: 028 | loss: 0.02241 - acc: 0.9952 -- iter: 0608/1257
[A[ATraining Step: 1100  | total loss: [1m[32m0.02018[0m[0m | time: 19.347s
[2K
| RMSProp | epoch: 028 | loss: 0.02018 - acc: 0.9957 -- iter: 0640/1257
[A[ATraining Step: 1101  | total loss: [1m[32m0.01819[0m[0m | time: 20.243s
[2K
| RMSProp | epoch: 028 | loss: 0.01819 - acc: 0.9961 -- iter: 0672/1257
[A[ATraining Step: 1102  | total loss: [1m[32m0.01639[0m[0m | time: 21.150s
[2K
| RMSProp | epoch: 028 | loss: 0.01639 - acc: 0.9965 -- iter: 0704/1257
[A[ATraining Step: 1103  | total loss: [1m[32m0.01476[0m[0m | time: 22.085s
[2K
| RMSProp | epoch: 028 | loss: 0.01476 - acc: 0.9968 -- iter: 0736/1257
[A[ATraining Step: 1104  | total loss: [1m[32m0.01332[0m[0m | time: 22.959s
[2K
| RMSProp | epoch: 028 | loss: 0.01332 - acc: 0.9971 -- iter: 0768/1257
[A[ATraining Step: 1105  | total loss: [1m[32m0.01200[0m[0m | time: 23.879s
[2K
| RMSProp | epoch: 028 | loss: 0.01200 - acc: 0.9974 -- iter: 0800/1257
[A[ATraining Step: 1106  | total loss: [1m[32m0.01085[0m[0m | time: 24.240s
[2K
| RMSProp | epoch: 028 | loss: 0.01085 - acc: 0.9977 -- iter: 0832/1257
[A[ATraining Step: 1107  | total loss: [1m[32m0.00980[0m[0m | time: 24.573s
[2K
| RMSProp | epoch: 028 | loss: 0.00980 - acc: 0.9979 -- iter: 0864/1257
[A[ATraining Step: 1108  | total loss: [1m[32m0.00883[0m[0m | time: 25.663s
[2K
| RMSProp | epoch: 028 | loss: 0.00883 - acc: 0.9981 -- iter: 0896/1257
[A[ATraining Step: 1109  | total loss: [1m[32m0.00797[0m[0m | time: 26.552s
[2K
| RMSProp | epoch: 028 | loss: 0.00797 - acc: 0.9983 -- iter: 0928/1257
[A[ATraining Step: 1110  | total loss: [1m[32m0.00718[0m[0m | time: 27.515s
[2K
| RMSProp | epoch: 028 | loss: 0.00718 - acc: 0.9985 -- iter: 0960/1257
[A[ATraining Step: 1111  | total loss: [1m[32m0.00647[0m[0m | time: 28.575s
[2K
| RMSProp | epoch: 028 | loss: 0.00647 - acc: 0.9986 -- iter: 0992/1257
[A[ATraining Step: 1112  | total loss: [1m[32m0.00583[0m[0m | time: 29.559s
[2K
| RMSProp | epoch: 028 | loss: 0.00583 - acc: 0.9988 -- iter: 1024/1257
[A[ATraining Step: 1113  | total loss: [1m[32m0.00536[0m[0m | time: 30.308s
[2K
| RMSProp | epoch: 028 | loss: 0.00536 - acc: 0.9989 -- iter: 1056/1257
[A[ATraining Step: 1114  | total loss: [1m[32m0.00485[0m[0m | time: 31.264s
[2K
| RMSProp | epoch: 028 | loss: 0.00485 - acc: 0.9990 -- iter: 1088/1257
[A[ATraining Step: 1115  | total loss: [1m[32m0.00437[0m[0m | time: 32.279s
[2K
| RMSProp | epoch: 028 | loss: 0.00437 - acc: 0.9991 -- iter: 1120/1257
[A[ATraining Step: 1116  | total loss: [1m[32m0.03696[0m[0m | time: 33.189s
[2K
| RMSProp | epoch: 028 | loss: 0.03696 - acc: 0.9961 -- iter: 1152/1257
[A[ATraining Step: 1117  | total loss: [1m[32m0.05034[0m[0m | time: 34.117s
[2K
| RMSProp | epoch: 028 | loss: 0.05034 - acc: 0.9902 -- iter: 1184/1257
[A[ATraining Step: 1118  | total loss: [1m[32m0.04670[0m[0m | time: 35.139s
[2K
| RMSProp | epoch: 028 | loss: 0.04670 - acc: 0.9912 -- iter: 1216/1257
[A[ATraining Step: 1119  | total loss: [1m[32m0.06016[0m[0m | time: 36.072s
[2K
| RMSProp | epoch: 028 | loss: 0.06016 - acc: 0.9889 -- iter: 1248/1257
[A[ATraining Step: 1120  | total loss: [1m[32m0.06053[0m[0m | time: 38.929s
[2K
| RMSProp | epoch: 028 | loss: 0.06053 - acc: 0.9838 | val_loss: 0.43448 - val_acc: 0.8680 -- iter: 1257/1257
--
Training Step: 1121  | total loss: [1m[32m0.05596[0m[0m | time: 0.879s
[2K
| RMSProp | epoch: 029 | loss: 0.05596 - acc: 0.9854 -- iter: 0032/1257
[A[ATraining Step: 1122  | total loss: [1m[32m0.05088[0m[0m | time: 1.707s
[2K
| RMSProp | epoch: 029 | loss: 0.05088 - acc: 0.9869 -- iter: 0064/1257
[A[ATraining Step: 1123  | total loss: [1m[32m0.04686[0m[0m | time: 2.638s
[2K
| RMSProp | epoch: 029 | loss: 0.04686 - acc: 0.9882 -- iter: 0096/1257
[A[ATraining Step: 1124  | total loss: [1m[32m0.04541[0m[0m | time: 3.572s
[2K
| RMSProp | epoch: 029 | loss: 0.04541 - acc: 0.9894 -- iter: 0128/1257
[A[ATraining Step: 1125  | total loss: [1m[32m0.04145[0m[0m | time: 4.502s
[2K
| RMSProp | epoch: 029 | loss: 0.04145 - acc: 0.9904 -- iter: 0160/1257
[A[ATraining Step: 1126  | total loss: [1m[32m0.03784[0m[0m | time: 5.496s
[2K
| RMSProp | epoch: 029 | loss: 0.03784 - acc: 0.9914 -- iter: 0192/1257
[A[ATraining Step: 1127  | total loss: [1m[32m0.03445[0m[0m | time: 6.515s
[2K
| RMSProp | epoch: 029 | loss: 0.03445 - acc: 0.9923 -- iter: 0224/1257
[A[ATraining Step: 1128  | total loss: [1m[32m0.03121[0m[0m | time: 7.355s
[2K
| RMSProp | epoch: 029 | loss: 0.03121 - acc: 0.9930 -- iter: 0256/1257
[A[ATraining Step: 1129  | total loss: [1m[32m0.02892[0m[0m | time: 8.379s
[2K
| RMSProp | epoch: 029 | loss: 0.02892 - acc: 0.9937 -- iter: 0288/1257
[A[ATraining Step: 1130  | total loss: [1m[32m0.02650[0m[0m | time: 9.470s
[2K
| RMSProp | epoch: 029 | loss: 0.02650 - acc: 0.9944 -- iter: 0320/1257
[A[ATraining Step: 1131  | total loss: [1m[32m0.02437[0m[0m | time: 10.437s
[2K
| RMSProp | epoch: 029 | loss: 0.02437 - acc: 0.9949 -- iter: 0352/1257
[A[ATraining Step: 1132  | total loss: [1m[32m0.02208[0m[0m | time: 11.237s
[2K
| RMSProp | epoch: 029 | loss: 0.02208 - acc: 0.9954 -- iter: 0384/1257
[A[ATraining Step: 1133  | total loss: [1m[32m0.02076[0m[0m | time: 12.134s
[2K
| RMSProp | epoch: 029 | loss: 0.02076 - acc: 0.9959 -- iter: 0416/1257
[A[ATraining Step: 1134  | total loss: [1m[32m0.01889[0m[0m | time: 13.059s
[2K
| RMSProp | epoch: 029 | loss: 0.01889 - acc: 0.9963 -- iter: 0448/1257
[A[ATraining Step: 1135  | total loss: [1m[32m0.01779[0m[0m | time: 13.980s
[2K
| RMSProp | epoch: 029 | loss: 0.01779 - acc: 0.9967 -- iter: 0480/1257
[A[ATraining Step: 1136  | total loss: [1m[32m0.01884[0m[0m | time: 14.970s
[2K
| RMSProp | epoch: 029 | loss: 0.01884 - acc: 0.9970 -- iter: 0512/1257
[A[ATraining Step: 1137  | total loss: [1m[32m0.02628[0m[0m | time: 15.978s
[2K
| RMSProp | epoch: 029 | loss: 0.02628 - acc: 0.9942 -- iter: 0544/1257
[A[ATraining Step: 1138  | total loss: [1m[32m0.02369[0m[0m | time: 16.891s
[2K
| RMSProp | epoch: 029 | loss: 0.02369 - acc: 0.9948 -- iter: 0576/1257
[A[ATraining Step: 1139  | total loss: [1m[32m0.02143[0m[0m | time: 17.820s
[2K
| RMSProp | epoch: 029 | loss: 0.02143 - acc: 0.9953 -- iter: 0608/1257
[A[ATraining Step: 1140  | total loss: [1m[32m0.01934[0m[0m | time: 18.805s
[2K
| RMSProp | epoch: 029 | loss: 0.01934 - acc: 0.9958 -- iter: 0640/1257
[A[ATraining Step: 1141  | total loss: [1m[32m0.01743[0m[0m | time: 19.596s
[2K
| RMSProp | epoch: 029 | loss: 0.01743 - acc: 0.9962 -- iter: 0672/1257
[A[ATraining Step: 1142  | total loss: [1m[32m0.01636[0m[0m | time: 20.469s
[2K
| RMSProp | epoch: 029 | loss: 0.01636 - acc: 0.9966 -- iter: 0704/1257
[A[ATraining Step: 1143  | total loss: [1m[32m0.01529[0m[0m | time: 21.351s
[2K
| RMSProp | epoch: 029 | loss: 0.01529 - acc: 0.9969 -- iter: 0736/1257
[A[ATraining Step: 1144  | total loss: [1m[32m0.01387[0m[0m | time: 22.274s
[2K
| RMSProp | epoch: 029 | loss: 0.01387 - acc: 0.9972 -- iter: 0768/1257
[A[ATraining Step: 1145  | total loss: [1m[32m0.01250[0m[0m | time: 23.131s
[2K
| RMSProp | epoch: 029 | loss: 0.01250 - acc: 0.9975 -- iter: 0800/1257
[A[ATraining Step: 1146  | total loss: [1m[32m0.01129[0m[0m | time: 24.104s
[2K
| RMSProp | epoch: 029 | loss: 0.01129 - acc: 0.9977 -- iter: 0832/1257
[A[ATraining Step: 1147  | total loss: [1m[32m0.01017[0m[0m | time: 24.456s
[2K
| RMSProp | epoch: 029 | loss: 0.01017 - acc: 0.9980 -- iter: 0864/1257
[A[ATraining Step: 1148  | total loss: [1m[32m0.00917[0m[0m | time: 24.812s
[2K
| RMSProp | epoch: 029 | loss: 0.00917 - acc: 0.9982 -- iter: 0896/1257
[A[ATraining Step: 1149  | total loss: [1m[32m0.00826[0m[0m | time: 25.597s
[2K
| RMSProp | epoch: 029 | loss: 0.00826 - acc: 0.9984 -- iter: 0928/1257
[A[ATraining Step: 1150  | total loss: [1m[32m0.03452[0m[0m | time: 26.444s
[2K
| RMSProp | epoch: 029 | loss: 0.03452 - acc: 0.9954 -- iter: 0960/1257
[A[ATraining Step: 1151  | total loss: [1m[32m0.03330[0m[0m | time: 27.314s
[2K
| RMSProp | epoch: 029 | loss: 0.03330 - acc: 0.9959 -- iter: 0992/1257
[A[ATraining Step: 1152  | total loss: [1m[32m0.03025[0m[0m | time: 28.198s
[2K
| RMSProp | epoch: 029 | loss: 0.03025 - acc: 0.9963 -- iter: 1024/1257
[A[ATraining Step: 1153  | total loss: [1m[32m0.04051[0m[0m | time: 29.098s
[2K
| RMSProp | epoch: 029 | loss: 0.04051 - acc: 0.9935 -- iter: 1056/1257
[A[ATraining Step: 1154  | total loss: [1m[32m0.04984[0m[0m | time: 30.068s
[2K
| RMSProp | epoch: 029 | loss: 0.04984 - acc: 0.9879 -- iter: 1088/1257
[A[ATraining Step: 1155  | total loss: [1m[32m0.05571[0m[0m | time: 31.102s
[2K
| RMSProp | epoch: 029 | loss: 0.05571 - acc: 0.9829 -- iter: 1120/1257
[A[ATraining Step: 1156  | total loss: [1m[32m0.05020[0m[0m | time: 32.098s
[2K
| RMSProp | epoch: 029 | loss: 0.05020 - acc: 0.9846 -- iter: 1152/1257
[A[ATraining Step: 1157  | total loss: [1m[32m0.08947[0m[0m | time: 32.858s
[2K
| RMSProp | epoch: 029 | loss: 0.08947 - acc: 0.9799 -- iter: 1184/1257
[A[ATraining Step: 1158  | total loss: [1m[32m0.08197[0m[0m | time: 33.711s
[2K
| RMSProp | epoch: 029 | loss: 0.08197 - acc: 0.9819 -- iter: 1216/1257
[A[ATraining Step: 1159  | total loss: [1m[32m0.07460[0m[0m | time: 34.589s
[2K
| RMSProp | epoch: 029 | loss: 0.07460 - acc: 0.9837 -- iter: 1248/1257
[A[ATraining Step: 1160  | total loss: [1m[32m0.06758[0m[0m | time: 37.224s
[2K
| RMSProp | epoch: 029 | loss: 0.06758 - acc: 0.9853 | val_loss: 0.43617 - val_acc: 0.8756 -- iter: 1257/1257
--
Training Step: 1161  | total loss: [1m[32m0.06140[0m[0m | time: 0.992s
[2K
| RMSProp | epoch: 030 | loss: 0.06140 - acc: 0.9868 -- iter: 0032/1257
[A[ATraining Step: 1162  | total loss: [1m[32m0.05775[0m[0m | time: 1.860s
[2K
| RMSProp | epoch: 030 | loss: 0.05775 - acc: 0.9881 -- iter: 0064/1257
[A[ATraining Step: 1163  | total loss: [1m[32m0.05812[0m[0m | time: 2.782s
[2K
| RMSProp | epoch: 030 | loss: 0.05812 - acc: 0.9862 -- iter: 0096/1257
[A[ATraining Step: 1164  | total loss: [1m[32m0.05733[0m[0m | time: 3.858s
[2K
| RMSProp | epoch: 030 | loss: 0.05733 - acc: 0.9844 -- iter: 0128/1257
[A[ATraining Step: 1165  | total loss: [1m[32m0.09347[0m[0m | time: 4.833s
[2K
| RMSProp | epoch: 030 | loss: 0.09347 - acc: 0.9735 -- iter: 0160/1257
[A[ATraining Step: 1166  | total loss: [1m[32m0.08618[0m[0m | time: 5.568s
[2K
| RMSProp | epoch: 030 | loss: 0.08618 - acc: 0.9761 -- iter: 0192/1257
[A[ATraining Step: 1167  | total loss: [1m[32m0.07861[0m[0m | time: 6.486s
[2K
| RMSProp | epoch: 030 | loss: 0.07861 - acc: 0.9785 -- iter: 0224/1257
[A[ATraining Step: 1168  | total loss: [1m[32m0.07122[0m[0m | time: 7.368s
[2K
| RMSProp | epoch: 030 | loss: 0.07122 - acc: 0.9807 -- iter: 0256/1257
[A[ATraining Step: 1169  | total loss: [1m[32m0.06425[0m[0m | time: 8.275s
[2K
| RMSProp | epoch: 030 | loss: 0.06425 - acc: 0.9826 -- iter: 0288/1257
[A[ATraining Step: 1170  | total loss: [1m[32m0.05864[0m[0m | time: 9.248s
[2K
| RMSProp | epoch: 030 | loss: 0.05864 - acc: 0.9843 -- iter: 0320/1257
[A[ATraining Step: 1171  | total loss: [1m[32m0.05299[0m[0m | time: 10.312s
[2K
| RMSProp | epoch: 030 | loss: 0.05299 - acc: 0.9859 -- iter: 0352/1257
[A[ATraining Step: 1172  | total loss: [1m[32m0.04825[0m[0m | time: 11.228s
[2K
| RMSProp | epoch: 030 | loss: 0.04825 - acc: 0.9873 -- iter: 0384/1257
[A[ATraining Step: 1173  | total loss: [1m[32m0.04372[0m[0m | time: 12.081s
[2K
| RMSProp | epoch: 030 | loss: 0.04372 - acc: 0.9886 -- iter: 0416/1257
[A[ATraining Step: 1174  | total loss: [1m[32m0.03946[0m[0m | time: 13.122s
[2K
| RMSProp | epoch: 030 | loss: 0.03946 - acc: 0.9897 -- iter: 0448/1257
[A[ATraining Step: 1175  | total loss: [1m[32m0.03565[0m[0m | time: 14.163s
[2K
| RMSProp | epoch: 030 | loss: 0.03565 - acc: 0.9908 -- iter: 0480/1257
[A[ATraining Step: 1176  | total loss: [1m[32m0.03219[0m[0m | time: 14.987s
[2K
| RMSProp | epoch: 030 | loss: 0.03219 - acc: 0.9917 -- iter: 0512/1257
[A[ATraining Step: 1177  | total loss: [1m[32m0.02902[0m[0m | time: 15.822s
[2K
| RMSProp | epoch: 030 | loss: 0.02902 - acc: 0.9925 -- iter: 0544/1257
[A[ATraining Step: 1178  | total loss: [1m[32m0.02755[0m[0m | time: 16.738s
[2K
| RMSProp | epoch: 030 | loss: 0.02755 - acc: 0.9933 -- iter: 0576/1257
[A[ATraining Step: 1179  | total loss: [1m[32m0.02494[0m[0m | time: 17.665s
[2K
| RMSProp | epoch: 030 | loss: 0.02494 - acc: 0.9939 -- iter: 0608/1257
[A[ATraining Step: 1180  | total loss: [1m[32m0.02256[0m[0m | time: 18.614s
[2K
| RMSProp | epoch: 030 | loss: 0.02256 - acc: 0.9945 -- iter: 0640/1257
[A[ATraining Step: 1181  | total loss: [1m[32m0.02037[0m[0m | time: 19.641s
[2K
| RMSProp | epoch: 030 | loss: 0.02037 - acc: 0.9951 -- iter: 0672/1257
[A[ATraining Step: 1182  | total loss: [1m[32m0.01902[0m[0m | time: 20.587s
[2K
| RMSProp | epoch: 030 | loss: 0.01902 - acc: 0.9956 -- iter: 0704/1257
[A[ATraining Step: 1183  | total loss: [1m[32m0.01721[0m[0m | time: 21.394s
[2K
| RMSProp | epoch: 030 | loss: 0.01721 - acc: 0.9960 -- iter: 0736/1257
[A[ATraining Step: 1184  | total loss: [1m[32m0.01556[0m[0m | time: 22.495s
[2K
| RMSProp | epoch: 030 | loss: 0.01556 - acc: 0.9964 -- iter: 0768/1257
[A[ATraining Step: 1185  | total loss: [1m[32m0.01403[0m[0m | time: 23.535s
[2K
| RMSProp | epoch: 030 | loss: 0.01403 - acc: 0.9968 -- iter: 0800/1257
[A[ATraining Step: 1186  | total loss: [1m[32m0.01271[0m[0m | time: 24.405s
[2K
| RMSProp | epoch: 030 | loss: 0.01271 - acc: 0.9971 -- iter: 0832/1257
[A[ATraining Step: 1187  | total loss: [1m[32m0.01190[0m[0m | time: 25.257s
[2K
| RMSProp | epoch: 030 | loss: 0.01190 - acc: 0.9974 -- iter: 0864/1257
[A[ATraining Step: 1188  | total loss: [1m[32m0.01087[0m[0m | time: 25.535s
[2K
| RMSProp | epoch: 030 | loss: 0.01087 - acc: 0.9977 -- iter: 0896/1257
[A[ATraining Step: 1189  | total loss: [1m[32m0.00979[0m[0m | time: 25.842s
[2K
| RMSProp | epoch: 030 | loss: 0.00979 - acc: 0.9979 -- iter: 0928/1257
[A[ATraining Step: 1190  | total loss: [1m[32m0.00882[0m[0m | time: 26.777s
[2K
| RMSProp | epoch: 030 | loss: 0.00882 - acc: 0.9981 -- iter: 0960/1257
[A[ATraining Step: 1191  | total loss: [1m[32m0.00796[0m[0m | time: 27.683s
[2K
| RMSProp | epoch: 030 | loss: 0.00796 - acc: 0.9983 -- iter: 0992/1257
[A[ATraining Step: 1192  | total loss: [1m[32m0.00721[0m[0m | time: 28.655s
[2K
| RMSProp | epoch: 030 | loss: 0.00721 - acc: 0.9985 -- iter: 1024/1257
[A[ATraining Step: 1193  | total loss: [1m[32m0.00651[0m[0m | time: 29.685s
[2K
| RMSProp | epoch: 030 | loss: 0.00651 - acc: 0.9986 -- iter: 1056/1257
[A[ATraining Step: 1194  | total loss: [1m[32m0.00600[0m[0m | time: 30.679s
[2K
| RMSProp | epoch: 030 | loss: 0.00600 - acc: 0.9988 -- iter: 1088/1257
[A[ATraining Step: 1195  | total loss: [1m[32m0.00542[0m[0m | time: 31.593s
[2K
| RMSProp | epoch: 030 | loss: 0.00542 - acc: 0.9989 -- iter: 1120/1257
[A[ATraining Step: 1196  | total loss: [1m[32m0.00489[0m[0m | time: 32.639s
[2K
| RMSProp | epoch: 030 | loss: 0.00489 - acc: 0.9990 -- iter: 1152/1257
[A[ATraining Step: 1197  | total loss: [1m[32m0.00443[0m[0m | time: 33.637s
[2K
| RMSProp | epoch: 030 | loss: 0.00443 - acc: 0.9991 -- iter: 1184/1257
[A[ATraining Step: 1198  | total loss: [1m[32m0.07271[0m[0m | time: 34.395s
[2K
| RMSProp | epoch: 030 | loss: 0.07271 - acc: 0.9929 -- iter: 1216/1257
[A[ATraining Step: 1199  | total loss: [1m[32m0.07657[0m[0m | time: 35.260s
[2K
| RMSProp | epoch: 030 | loss: 0.07657 - acc: 0.9905 -- iter: 1248/1257
[A[ATraining Step: 1200  | total loss: [1m[32m0.07121[0m[0m | time: 38.004s
[2K
| RMSProp | epoch: 030 | loss: 0.07121 - acc: 0.9915 | val_loss: 0.46209 - val_acc: 0.8680 -- iter: 1257/1257
--
Validation AUC:0.9381958762886597
Validation AUPRC:0.9501743409810768
Test AUC:0.9600608106367079
Test AUPRC:0.9649436426835168
BestTestF1Score	0.91	0.82	0.91	0.91	0.91	179	17	180	18	0.61
BestTestMCCScore	0.91	0.82	0.91	0.93	0.89	175	13	184	22	0.81
BestTestAccuracyScore	0.91	0.82	0.91	0.93	0.89	175	13	184	22	0.81
BestValidationF1Score	0.87	0.74	0.87	0.87	0.88	176	27	167	24	0.61
BestValidationMCC	0.87	0.75	0.87	0.89	0.86	171	21	173	29	0.81
BestValidationAccuracy	0.87	0.75	0.87	0.89	0.86	171	21	173	29	0.81
TestPredictions (Threshold:0.81)
CHEMBL48024,TN,INACT,0.009999999776482582	CHEMBL3764306,TN,INACT,0.029999999329447746	CHEMBL2376804,TN,INACT,0.0	CHEMBL283320,TN,INACT,0.0	CHEMBL3403343,TN,INACT,0.009999999776482582	CHEMBL104377,TN,INACT,0.009999999776482582	CHEMBL104994,TN,INACT,0.0	CHEMBL233721,TN,INACT,0.07000000029802322	CHEMBL77962,TN,INACT,0.0	CHEMBL273410,TN,INACT,0.0	CHEMBL284965,TN,INACT,0.009999999776482582	CHEMBL137258,TP,ACT,0.9200000166893005	CHEMBL37512,TN,INACT,0.0	CHEMBL393675,TN,INACT,0.0	CHEMBL495854,TN,INACT,0.009999999776482582	CHEMBL137786,TP,ACT,1.0	CHEMBL298203,TN,INACT,0.0	CHEMBL118931,TP,ACT,0.9900000095367432	CHEMBL496399,TP,ACT,1.0	CHEMBL303386,TN,INACT,0.0	CHEMBL2112095,TN,INACT,0.12999999523162842	CHEMBL2331793,TN,INACT,0.10000000149011612	CHEMBL72738,TN,INACT,0.019999999552965164	CHEMBL453822,TN,INACT,0.4300000071525574	CHEMBL2237151,FP,INACT,1.0	CHEMBL181393,TP,ACT,1.0	CHEMBL577398,TP,ACT,1.0	CHEMBL1783920,TP,ACT,1.0	CHEMBL42096,TP,ACT,1.0	CHEMBL157588,TP,ACT,1.0	CHEMBL303203,TN,INACT,0.0	CHEMBL574089,TP,ACT,1.0	CHEMBL41673,TN,INACT,0.0	CHEMBL58241,TN,INACT,0.0	CHEMBL497972,TP,ACT,0.9900000095367432	CHEMBL297215,TN,INACT,0.019999999552965164	CHEMBL324311,TP,ACT,1.0	CHEMBL404557,TN,INACT,0.009999999776482582	CHEMBL81551,TP,ACT,1.0	CHEMBL1784132,TP,ACT,1.0	CHEMBL577358,TP,ACT,1.0	CHEMBL554692,TN,INACT,0.009999999776482582	CHEMBL421523,TN,INACT,0.009999999776482582	CHEMBL17513,FN,ACT,0.10000000149011612	CHEMBL429005,FN,ACT,0.10999999940395355	CHEMBL1909726,FN,ACT,0.5099999904632568	CHEMBL17165,FN,ACT,0.7699999809265137	CHEMBL522192,TP,ACT,1.0	CHEMBL112777,TN,INACT,0.009999999776482582	CHEMBL419951,TP,ACT,1.0	CHEMBL164805,TP,ACT,1.0	CHEMBL572688,TP,ACT,1.0	CHEMBL72295,TN,INACT,0.019999999552965164	CHEMBL81427,TP,ACT,1.0	CHEMBL18016,FN,ACT,0.4000000059604645	CHEMBL7370,TP,ACT,1.0	CHEMBL3780633,TN,INACT,0.029999999329447746	CHEMBL576726,TP,ACT,1.0	CHEMBL167558,TP,ACT,0.9900000095367432	CHEMBL2042551,TN,INACT,0.0	CHEMBL75358,TN,INACT,0.029999999329447746	CHEMBL151668,TN,INACT,0.019999999552965164	CHEMBL72166,TN,INACT,0.0	CHEMBL227429,TN,INACT,0.009999999776482582	CHEMBL50,TN,INACT,0.009999999776482582	CHEMBL140495,TN,INACT,0.0	CHEMBL492393,TP,ACT,1.0	CHEMBL7441,TN,INACT,0.009999999776482582	CHEMBL428953,TP,ACT,1.0	CHEMBL3735265,TN,INACT,0.0	CHEMBL444319,TP,ACT,1.0	CHEMBL100874,TN,INACT,0.0	CHEMBL76933,TN,INACT,0.0	CHEMBL3764246,FP,INACT,0.9800000190734863	CHEMBL2367888,TN,INACT,0.009999999776482582	CHEMBL489608,TP,ACT,1.0	CHEMBL104180,TN,INACT,0.0	CHEMBL344228,FN,ACT,0.03999999910593033	CHEMBL1912068,TP,ACT,0.9900000095367432	CHEMBL24781,TN,INACT,0.07999999821186066	CHEMBL490008,TP,ACT,1.0	CHEMBL490824,TP,ACT,1.0	CHEMBL1912076,TP,ACT,0.9599999785423279	CHEMBL304353,TP,ACT,0.9900000095367432	CHEMBL2311547,TN,INACT,0.0	CHEMBL138435,FN,ACT,0.019999999552965164	CHEMBL147238,TN,INACT,0.0	CHEMBL307034,TN,INACT,0.009999999776482582	CHEMBL1765668,TN,INACT,0.03999999910593033	CHEMBL467550,TP,ACT,0.9800000190734863	CHEMBL1912065,TP,ACT,0.9900000095367432	CHEMBL228738,TN,INACT,0.009999999776482582	CHEMBL343817,TP,ACT,1.0	CHEMBL81636,TP,ACT,1.0	CHEMBL490123,TP,ACT,1.0	CHEMBL438914,TP,ACT,1.0	CHEMBL483239,TP,ACT,1.0	CHEMBL299879,TP,ACT,1.0	CHEMBL3114151,FP,INACT,0.9800000190734863	CHEMBL305558,TN,INACT,0.0	CHEMBL501756,TN,INACT,0.009999999776482582	CHEMBL458409,TN,INACT,0.0	CHEMBL337105,TP,ACT,0.9900000095367432	CHEMBL1829330,TP,ACT,1.0	CHEMBL3126041,TP,ACT,0.9900000095367432	CHEMBL1478530,FP,INACT,0.9800000190734863	CHEMBL120760,TP,ACT,1.0	CHEMBL440647,TP,ACT,0.9100000262260437	CHEMBL324685,TN,INACT,0.0	CHEMBL521947,TP,ACT,1.0	CHEMBL135988,TN,INACT,0.009999999776482582	CHEMBL190,TN,INACT,0.009999999776482582	CHEMBL572451,TP,ACT,0.9900000095367432	CHEMBL3314929,FP,INACT,0.9900000095367432	CHEMBL137260,TP,ACT,1.0	CHEMBL312958,TN,INACT,0.0	CHEMBL272964,TP,ACT,0.9900000095367432	CHEMBL79915,TN,INACT,0.0	CHEMBL45875,TN,INACT,0.0	CHEMBL120431,TP,ACT,1.0	CHEMBL367355,TP,ACT,1.0	CHEMBL275642,TP,ACT,1.0	CHEMBL535602,TN,INACT,0.0	CHEMBL175228,TN,INACT,0.029999999329447746	CHEMBL2436814,TN,INACT,0.009999999776482582	CHEMBL413426,TP,ACT,0.9800000190734863	CHEMBL496326,TP,ACT,0.9900000095367432	CHEMBL497644,TP,ACT,0.9200000166893005	CHEMBL51138,TP,ACT,1.0	CHEMBL78601,TN,INACT,0.0	CHEMBL73392,TN,INACT,0.0	CHEMBL3084863,TP,ACT,1.0	CHEMBL335145,TP,ACT,1.0	CHEMBL572450,TP,ACT,1.0	CHEMBL215278,TN,INACT,0.05999999865889549	CHEMBL495725,TP,ACT,1.0	CHEMBL311159,FN,ACT,0.800000011920929	CHEMBL137538,TP,ACT,0.949999988079071	CHEMBL109206,TN,INACT,0.0	CHEMBL307901,TP,ACT,1.0	CHEMBL408395,TN,INACT,0.0	CHEMBL414020,TP,ACT,1.0	CHEMBL403414,TP,ACT,1.0	CHEMBL310292,TP,ACT,0.9900000095367432	CHEMBL196866,TN,INACT,0.25	CHEMBL3084876,TP,ACT,1.0	CHEMBL331551,TP,ACT,1.0	CHEMBL59517,TN,INACT,0.0	CHEMBL323517,TN,INACT,0.0	CHEMBL106235,TN,INACT,0.0	CHEMBL48031,TN,INACT,0.0	CHEMBL45160,TN,INACT,0.009999999776482582	CHEMBL366737,TN,INACT,0.4399999976158142	CHEMBL521844,TP,ACT,1.0	CHEMBL64559,TN,INACT,0.019999999552965164	CHEMBL432352,TP,ACT,0.9800000190734863	CHEMBL2436716,TN,INACT,0.0	CHEMBL76218,TP,ACT,0.9900000095367432	CHEMBL1783923,TP,ACT,1.0	CHEMBL66371,TP,ACT,0.9599999785423279	CHEMBL523134,TP,ACT,1.0	CHEMBL3604301,TN,INACT,0.0	CHEMBL3264204,FP,INACT,1.0	CHEMBL173708,TN,INACT,0.47999998927116394	CHEMBL9746,TN,INACT,0.0	CHEMBL432931,TP,ACT,1.0	CHEMBL336029,TP,ACT,0.9800000190734863	CHEMBL246585,TN,INACT,0.800000011920929	CHEMBL434,TN,INACT,0.33000001311302185	CHEMBL137404,TP,ACT,1.0	CHEMBL166399,FN,ACT,0.03999999910593033	CHEMBL316968,TN,INACT,0.05999999865889549	CHEMBL2440182,FN,ACT,0.25999999046325684	CHEMBL276283,TP,ACT,1.0	CHEMBL300926,FP,INACT,0.9100000262260437	CHEMBL1093044,TN,INACT,0.0	CHEMBL137360,TP,ACT,0.9900000095367432	CHEMBL593443,TN,INACT,0.03999999910593033	CHEMBL199186,FP,INACT,1.0	CHEMBL2163916,TN,INACT,0.0	CHEMBL109778,TN,INACT,0.0	CHEMBL103950,TN,INACT,0.009999999776482582	CHEMBL181466,TP,ACT,1.0	CHEMBL1907839,TN,INACT,0.0	CHEMBL324586,TN,INACT,0.0	CHEMBL434284,TN,INACT,0.009999999776482582	CHEMBL45305,TN,INACT,0.009999999776482582	CHEMBL165012,TN,INACT,0.17000000178813934	CHEMBL42020,FN,ACT,0.20999999344348907	CHEMBL380054,TN,INACT,0.009999999776482582	CHEMBL289284,TN,INACT,0.029999999329447746	CHEMBL73619,TP,ACT,1.0	CHEMBL494592,TP,ACT,1.0	CHEMBL120513,TN,INACT,0.0	CHEMBL48448,TN,INACT,0.0	CHEMBL1909719,TP,ACT,0.9900000095367432	CHEMBL524044,TP,ACT,1.0	CHEMBL1829310,TP,ACT,1.0	CHEMBL296908,TN,INACT,0.029999999329447746	CHEMBL2369710,TN,INACT,0.009999999776482582	CHEMBL74515,TN,INACT,0.0	CHEMBL506163,FN,ACT,0.0	CHEMBL167709,TP,ACT,1.0	CHEMBL74161,TP,ACT,1.0	CHEMBL137236,TP,ACT,0.9800000190734863	CHEMBL111218,TN,INACT,0.0	CHEMBL492766,TP,ACT,1.0	CHEMBL191915,TN,INACT,0.25999999046325684	CHEMBL52332,TP,ACT,0.949999988079071	CHEMBL1080298,FN,ACT,0.009999999776482582	CHEMBL142295,TN,INACT,0.23000000417232513	CHEMBL576158,TP,ACT,0.9900000095367432	CHEMBL354126,TN,INACT,0.0	CHEMBL491239,TP,ACT,1.0	CHEMBL91362,TN,INACT,0.009999999776482582	CHEMBL80006,TP,ACT,1.0	CHEMBL349505,TN,INACT,0.0	CHEMBL54885,TN,INACT,0.009999999776482582	CHEMBL497359,TP,ACT,1.0	CHEMBL2016681,TP,ACT,0.9300000071525574	CHEMBL150696,TN,INACT,0.009999999776482582	CHEMBL177546,TN,INACT,0.009999999776482582	CHEMBL2013015,TP,ACT,0.9900000095367432	CHEMBL583007,TP,ACT,1.0	CHEMBL403223,TP,ACT,1.0	CHEMBL306099,TP,ACT,0.9900000095367432	CHEMBL1192069,TN,INACT,0.0	CHEMBL467813,TP,ACT,0.9900000095367432	CHEMBL161724,TP,ACT,0.9800000190734863	CHEMBL2207493,TN,INACT,0.11999999731779099	CHEMBL15689,TN,INACT,0.009999999776482582	CHEMBL298168,TP,ACT,1.0	CHEMBL521545,TP,ACT,1.0	CHEMBL523305,TP,ACT,0.8999999761581421	CHEMBL3099724,TP,ACT,0.9800000190734863	CHEMBL40796,TN,INACT,0.009999999776482582	CHEMBL17022,TP,ACT,1.0	CHEMBL3238444,FP,INACT,0.9900000095367432	CHEMBL66011,TN,INACT,0.009999999776482582	CHEMBL311781,TN,INACT,0.009999999776482582	CHEMBL491288,TP,ACT,1.0	CHEMBL64120,TN,INACT,0.10999999940395355	CHEMBL292521,TN,INACT,0.6200000047683716	CHEMBL426385,TN,INACT,0.0	CHEMBL3234532,TN,INACT,0.09000000357627869	CHEMBL89457,TN,INACT,0.0	CHEMBL1829316,TP,ACT,1.0	CHEMBL1829328,TP,ACT,1.0	CHEMBL506888,TN,INACT,0.05000000074505806	CHEMBL1912079,TP,ACT,0.9900000095367432	CHEMBL1783927,TP,ACT,1.0	CHEMBL257940,TP,ACT,1.0	CHEMBL32996,TN,INACT,0.0	CHEMBL74430,TN,INACT,0.6000000238418579	CHEMBL408493,TN,INACT,0.07000000029802322	CHEMBL32301,TN,INACT,0.09000000357627869	CHEMBL608816,TN,INACT,0.0	CHEMBL296387,FN,ACT,0.029999999329447746	CHEMBL2013010,TP,ACT,1.0	CHEMBL16986,TP,ACT,1.0	CHEMBL78853,TN,INACT,0.009999999776482582	CHEMBL353088,TN,INACT,0.009999999776482582	CHEMBL66168,TP,ACT,1.0	CHEMBL404888,TN,INACT,0.23000000417232513	CHEMBL323245,TN,INACT,0.0	CHEMBL351183,FP,INACT,0.9399999976158142	CHEMBL2436715,TN,INACT,0.009999999776482582	CHEMBL490949,TP,ACT,0.9100000262260437	CHEMBL294087,TN,INACT,0.0	CHEMBL138278,TP,ACT,1.0	CHEMBL135261,FN,ACT,0.019999999552965164	CHEMBL584732,TP,ACT,1.0	CHEMBL311455,TN,INACT,0.0	CHEMBL106259,TN,INACT,0.009999999776482582	CHEMBL337152,TP,ACT,1.0	CHEMBL276819,TN,INACT,0.05000000074505806	CHEMBL63289,TN,INACT,0.2199999988079071	CHEMBL137711,TP,ACT,1.0	CHEMBL2013027,TP,ACT,0.9900000095367432	CHEMBL75369,TP,ACT,0.8999999761581421	CHEMBL572431,TP,ACT,1.0	CHEMBL514606,TN,INACT,0.0	CHEMBL495034,TP,ACT,1.0	CHEMBL2042403,TN,INACT,0.03999999910593033	CHEMBL27065,FP,INACT,0.8100000023841858	CHEMBL492375,TP,ACT,0.9900000095367432	CHEMBL2016736,TP,ACT,0.9900000095367432	CHEMBL141051,TN,INACT,0.009999999776482582	CHEMBL468847,TP,ACT,0.9800000190734863	CHEMBL522609,TP,ACT,1.0	CHEMBL2372075,TN,INACT,0.029999999329447746	CHEMBL141365,TN,INACT,0.0	CHEMBL343564,TP,ACT,1.0	CHEMBL312308,FN,ACT,0.029999999329447746	CHEMBL607144,TP,ACT,1.0	CHEMBL594888,TP,ACT,1.0	CHEMBL3633656,TN,INACT,0.20999999344348907	CHEMBL3335535,TN,INACT,0.0	CHEMBL255793,TN,INACT,0.75	CHEMBL118710,FN,ACT,0.03999999910593033	CHEMBL495200,TP,ACT,1.0	CHEMBL342256,TN,INACT,0.0	CHEMBL6646,TP,ACT,1.0	CHEMBL63937,TN,INACT,0.0	CHEMBL404304,TP,ACT,0.9700000286102295	CHEMBL325475,TP,ACT,1.0	CHEMBL104223,TN,INACT,0.0	CHEMBL492567,TP,ACT,0.9900000095367432	CHEMBL2112488,TN,INACT,0.0	CHEMBL19808,TN,INACT,0.0	CHEMBL103828,TN,INACT,0.0	CHEMBL109478,TN,INACT,0.0	CHEMBL343969,TN,INACT,0.03999999910593033	CHEMBL2373213,TN,INACT,0.0	CHEMBL523945,TP,ACT,1.0	CHEMBL2013011,TP,ACT,0.9900000095367432	CHEMBL523330,TP,ACT,0.9800000190734863	CHEMBL558364,TN,INACT,0.03999999910593033	CHEMBL3084889,TP,ACT,1.0	CHEMBL344154,TN,INACT,0.0	CHEMBL2312346,TN,INACT,0.0	CHEMBL162095,TN,INACT,0.30000001192092896	CHEMBL162094,TP,ACT,1.0	CHEMBL273182,TP,ACT,1.0	CHEMBL3099727,TP,ACT,0.9700000286102295	CHEMBL42620,FN,ACT,0.019999999552965164	CHEMBL510130,TN,INACT,0.27000001072883606	CHEMBL157905,TP,ACT,1.0	CHEMBL1765667,TN,INACT,0.029999999329447746	CHEMBL135883,TP,ACT,1.0	CHEMBL2016738,TP,ACT,1.0	CHEMBL103497,TN,INACT,0.0	CHEMBL1762308,TN,INACT,0.0	CHEMBL3126052,TP,ACT,0.8799999952316284	CHEMBL308087,TN,INACT,0.0	CHEMBL1909728,TP,ACT,0.9900000095367432	CHEMBL319910,TN,INACT,0.05000000074505806	CHEMBL3084874,TP,ACT,0.9900000095367432	CHEMBL3104112,FN,ACT,0.3199999928474426	CHEMBL491427,TP,ACT,1.0	CHEMBL81442,TP,ACT,0.9399999976158142	CHEMBL167926,TP,ACT,1.0	CHEMBL484267,TP,ACT,1.0	CHEMBL297335,TN,INACT,0.019999999552965164	CHEMBL154412,TP,ACT,0.9900000095367432	CHEMBL595022,TN,INACT,0.009999999776482582	CHEMBL137669,FN,ACT,0.0	CHEMBL1829324,TP,ACT,0.9900000095367432	CHEMBL70246,TN,INACT,0.009999999776482582	CHEMBL160595,TP,ACT,0.9800000190734863	CHEMBL73791,TN,INACT,0.019999999552965164	CHEMBL3114164,TN,INACT,0.009999999776482582	CHEMBL435784,TN,INACT,0.7200000286102295	CHEMBL2016745,FN,ACT,0.6700000166893005	CHEMBL423720,TP,ACT,1.0	CHEMBL1909718,TP,ACT,0.9900000095367432	CHEMBL79815,TP,ACT,1.0	CHEMBL75141,TN,INACT,0.0	CHEMBL495593,TP,ACT,1.0	CHEMBL59866,TP,ACT,1.0	CHEMBL114074,TN,INACT,0.0	CHEMBL603858,TN,INACT,0.0	CHEMBL523776,TP,ACT,1.0	CHEMBL309017,TN,INACT,0.0	CHEMBL3314917,FP,INACT,0.9800000190734863	CHEMBL217002,TN,INACT,0.029999999329447746	CHEMBL1829312,TP,ACT,0.9700000286102295	CHEMBL335039,TP,ACT,1.0	CHEMBL352925,TN,INACT,0.019999999552965164	CHEMBL3114144,TN,INACT,0.20000000298023224	CHEMBL334960,TP,ACT,1.0	CHEMBL154889,TP,ACT,0.9900000095367432	CHEMBL522388,TP,ACT,1.0	CHEMBL7505,TN,INACT,0.0	CHEMBL79659,TP,ACT,1.0	CHEMBL45199,FN,ACT,0.6399999856948853	CHEMBL576159,TP,ACT,1.0	CHEMBL1907665,TN,INACT,0.029999999329447746	CHEMBL83255,TP,ACT,0.9599999785423279	CHEMBL445613,TP,ACT,1.0	CHEMBL1437,TN,INACT,0.0	CHEMBL594802,TN,INACT,0.009999999776482582	CHEMBL43788,TN,INACT,0.009999999776482582	CHEMBL417719,TN,INACT,0.0	CHEMBL10808,TN,INACT,0.019999999552965164	CHEMBL565626,TP,ACT,1.0	CHEMBL48904,TP,ACT,1.0	CHEMBL89445,FP,INACT,0.949999988079071	CHEMBL27403,TN,INACT,0.4099999964237213	CHEMBL119726,TP,ACT,0.9900000095367432	CHEMBL120586,TP,ACT,0.9800000190734863	CHEMBL496393,TP,ACT,0.9900000095367432	CHEMBL2370509,TN,INACT,0.029999999329447746	CHEMBL367024,TN,INACT,0.019999999552965164	

