CNNModel CHEMBL2334 adam 0.001 30 256 0 0.6 False True
Number of active compounds :	216
Number of inactive compounds :	144
---------------------------------
Run id: CNNModel_CHEMBL2334_adam_0.001_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2334_adam_0.001_30_256_0.6_True/
---------------------------------
Training samples: 213
Validation samples: 67
--
Training Step: 1  | time: 0.792s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/213
[A[ATraining Step: 2  | total loss: [1m[32m0.62379[0m[0m | time: 1.395s
[2K
| Adam | epoch: 001 | loss: 0.62379 - acc: 0.4500 -- iter: 064/213
[A[ATraining Step: 3  | total loss: [1m[32m0.67157[0m[0m | time: 2.035s
[2K
| Adam | epoch: 001 | loss: 0.67157 - acc: 0.6187 -- iter: 096/213
[A[ATraining Step: 4  | total loss: [1m[32m0.68214[0m[0m | time: 2.656s
[2K
| Adam | epoch: 001 | loss: 0.68214 - acc: 0.5766 -- iter: 128/213
[A[ATraining Step: 5  | total loss: [1m[32m0.65671[0m[0m | time: 3.267s
[2K
| Adam | epoch: 001 | loss: 0.65671 - acc: 0.6317 -- iter: 160/213
[A[ATraining Step: 6  | total loss: [1m[32m0.63949[0m[0m | time: 3.873s
[2K
| Adam | epoch: 001 | loss: 0.63949 - acc: 0.6676 -- iter: 192/213
[A[ATraining Step: 7  | total loss: [1m[32m0.71148[0m[0m | time: 5.325s
[2K
| Adam | epoch: 001 | loss: 0.71148 - acc: 0.5670 | val_loss: 0.69480 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 8  | total loss: [1m[32m0.66823[0m[0m | time: 0.426s
[2K
| Adam | epoch: 002 | loss: 0.66823 - acc: 0.6499 -- iter: 032/213
[A[ATraining Step: 9  | total loss: [1m[32m0.65823[0m[0m | time: 1.034s
[2K
| Adam | epoch: 002 | loss: 0.65823 - acc: 0.6840 -- iter: 064/213
[A[ATraining Step: 10  | total loss: [1m[32m0.67566[0m[0m | time: 1.650s
[2K
| Adam | epoch: 002 | loss: 0.67566 - acc: 0.6076 -- iter: 096/213
[A[ATraining Step: 11  | total loss: [1m[32m0.68835[0m[0m | time: 2.280s
[2K
| Adam | epoch: 002 | loss: 0.68835 - acc: 0.5418 -- iter: 128/213
[A[ATraining Step: 12  | total loss: [1m[32m0.67403[0m[0m | time: 2.891s
[2K
| Adam | epoch: 002 | loss: 0.67403 - acc: 0.6355 -- iter: 160/213
[A[ATraining Step: 13  | total loss: [1m[32m0.67677[0m[0m | time: 3.495s
[2K
| Adam | epoch: 002 | loss: 0.67677 - acc: 0.6176 -- iter: 192/213
[A[ATraining Step: 14  | total loss: [1m[32m0.67861[0m[0m | time: 5.107s
[2K
| Adam | epoch: 002 | loss: 0.67861 - acc: 0.6079 | val_loss: 0.69456 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 15  | total loss: [1m[32m0.67398[0m[0m | time: 0.437s
[2K
| Adam | epoch: 003 | loss: 0.67398 - acc: 0.6268 -- iter: 032/213
[A[ATraining Step: 16  | total loss: [1m[32m0.67276[0m[0m | time: 0.876s
[2K
| Adam | epoch: 003 | loss: 0.67276 - acc: 0.6239 -- iter: 064/213
[A[ATraining Step: 17  | total loss: [1m[32m0.67261[0m[0m | time: 1.493s
[2K
| Adam | epoch: 003 | loss: 0.67261 - acc: 0.6221 -- iter: 096/213
[A[ATraining Step: 18  | total loss: [1m[32m0.67773[0m[0m | time: 2.107s
[2K
| Adam | epoch: 003 | loss: 0.67773 - acc: 0.6015 -- iter: 128/213
[A[ATraining Step: 19  | total loss: [1m[32m0.67293[0m[0m | time: 2.709s
[2K
| Adam | epoch: 003 | loss: 0.67293 - acc: 0.6093 -- iter: 160/213
[A[ATraining Step: 20  | total loss: [1m[32m0.67281[0m[0m | time: 3.313s
[2K
| Adam | epoch: 003 | loss: 0.67281 - acc: 0.6043 -- iter: 192/213
[A[ATraining Step: 21  | total loss: [1m[32m0.65317[0m[0m | time: 4.942s
[2K
| Adam | epoch: 003 | loss: 0.65317 - acc: 0.6398 | val_loss: 0.73276 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 22  | total loss: [1m[32m0.67613[0m[0m | time: 0.636s
[2K
| Adam | epoch: 004 | loss: 0.67613 - acc: 0.6073 -- iter: 032/213
[A[ATraining Step: 23  | total loss: [1m[32m0.67148[0m[0m | time: 1.048s
[2K
| Adam | epoch: 004 | loss: 0.67148 - acc: 0.6124 -- iter: 064/213
[A[ATraining Step: 24  | total loss: [1m[32m0.68757[0m[0m | time: 1.466s
[2K
| Adam | epoch: 004 | loss: 0.68757 - acc: 0.5875 -- iter: 096/213
[A[ATraining Step: 25  | total loss: [1m[32m0.69377[0m[0m | time: 2.075s
[2K
| Adam | epoch: 004 | loss: 0.69377 - acc: 0.5701 -- iter: 128/213
[A[ATraining Step: 26  | total loss: [1m[32m0.69109[0m[0m | time: 2.685s
[2K
| Adam | epoch: 004 | loss: 0.69109 - acc: 0.5681 -- iter: 160/213
[A[ATraining Step: 27  | total loss: [1m[32m0.68378[0m[0m | time: 3.294s
[2K
| Adam | epoch: 004 | loss: 0.68378 - acc: 0.5908 -- iter: 192/213
[A[ATraining Step: 28  | total loss: [1m[32m0.67830[0m[0m | time: 4.910s
[2K
| Adam | epoch: 004 | loss: 0.67830 - acc: 0.6150 | val_loss: 0.69288 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 29  | total loss: [1m[32m0.67868[0m[0m | time: 0.634s
[2K
| Adam | epoch: 005 | loss: 0.67868 - acc: 0.6098 -- iter: 032/213
[A[ATraining Step: 30  | total loss: [1m[32m0.67890[0m[0m | time: 1.239s
[2K
| Adam | epoch: 005 | loss: 0.67890 - acc: 0.6060 -- iter: 064/213
[A[ATraining Step: 31  | total loss: [1m[32m0.67836[0m[0m | time: 1.658s
[2K
| Adam | epoch: 005 | loss: 0.67836 - acc: 0.6104 -- iter: 096/213
[A[ATraining Step: 32  | total loss: [1m[32m0.67795[0m[0m | time: 2.094s
[2K
| Adam | epoch: 005 | loss: 0.67795 - acc: 0.6123 -- iter: 128/213
[A[ATraining Step: 33  | total loss: [1m[32m0.67762[0m[0m | time: 2.697s
[2K
| Adam | epoch: 005 | loss: 0.67762 - acc: 0.6138 -- iter: 160/213
[A[ATraining Step: 34  | total loss: [1m[32m0.67777[0m[0m | time: 3.303s
[2K
| Adam | epoch: 005 | loss: 0.67777 - acc: 0.6095 -- iter: 192/213
[A[ATraining Step: 35  | total loss: [1m[32m0.67956[0m[0m | time: 4.919s
[2K
| Adam | epoch: 005 | loss: 0.67956 - acc: 0.5997 | val_loss: 0.69522 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 36  | total loss: [1m[32m0.68077[0m[0m | time: 0.629s
[2K
| Adam | epoch: 006 | loss: 0.68077 - acc: 0.5921 -- iter: 032/213
[A[ATraining Step: 37  | total loss: [1m[32m0.68425[0m[0m | time: 1.258s
[2K
| Adam | epoch: 006 | loss: 0.68425 - acc: 0.5737 -- iter: 064/213
[A[ATraining Step: 38  | total loss: [1m[32m0.67657[0m[0m | time: 1.855s
[2K
| Adam | epoch: 006 | loss: 0.67657 - acc: 0.6020 -- iter: 096/213
[A[ATraining Step: 39  | total loss: [1m[32m0.66976[0m[0m | time: 2.258s
[2K
| Adam | epoch: 006 | loss: 0.66976 - acc: 0.6244 -- iter: 128/213
[A[ATraining Step: 40  | total loss: [1m[32m0.67221[0m[0m | time: 2.682s
[2K
| Adam | epoch: 006 | loss: 0.67221 - acc: 0.6145 -- iter: 160/213
[A[ATraining Step: 41  | total loss: [1m[32m0.67420[0m[0m | time: 3.288s
[2K
| Adam | epoch: 006 | loss: 0.67420 - acc: 0.6066 -- iter: 192/213
[A[ATraining Step: 42  | total loss: [1m[32m0.67475[0m[0m | time: 4.885s
[2K
| Adam | epoch: 006 | loss: 0.67475 - acc: 0.6043 | val_loss: 0.72396 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 43  | total loss: [1m[32m0.66382[0m[0m | time: 0.610s
[2K
| Adam | epoch: 007 | loss: 0.66382 - acc: 0.6245 -- iter: 032/213
[A[ATraining Step: 44  | total loss: [1m[32m0.65999[0m[0m | time: 1.223s
[2K
| Adam | epoch: 007 | loss: 0.65999 - acc: 0.6300 -- iter: 064/213
[A[ATraining Step: 45  | total loss: [1m[32m0.67977[0m[0m | time: 1.833s
[2K
| Adam | epoch: 007 | loss: 0.67977 - acc: 0.6026 -- iter: 096/213
[A[ATraining Step: 46  | total loss: [1m[32m0.68140[0m[0m | time: 2.456s
[2K
| Adam | epoch: 007 | loss: 0.68140 - acc: 0.6011 -- iter: 128/213
[A[ATraining Step: 47  | total loss: [1m[32m0.67532[0m[0m | time: 2.876s
[2K
| Adam | epoch: 007 | loss: 0.67532 - acc: 0.6101 -- iter: 160/213
[A[ATraining Step: 48  | total loss: [1m[32m0.66314[0m[0m | time: 3.297s
[2K
| Adam | epoch: 007 | loss: 0.66314 - acc: 0.6345 -- iter: 192/213
[A[ATraining Step: 49  | total loss: [1m[32m0.65361[0m[0m | time: 4.919s
[2K
| Adam | epoch: 007 | loss: 0.65361 - acc: 0.6546 | val_loss: 0.71515 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 50  | total loss: [1m[32m0.65726[0m[0m | time: 0.624s
[2K
| Adam | epoch: 008 | loss: 0.65726 - acc: 0.6452 -- iter: 032/213
[A[ATraining Step: 51  | total loss: [1m[32m0.66530[0m[0m | time: 1.226s
[2K
| Adam | epoch: 008 | loss: 0.66530 - acc: 0.6278 -- iter: 064/213
[A[ATraining Step: 52  | total loss: [1m[32m0.66500[0m[0m | time: 1.858s
[2K
| Adam | epoch: 008 | loss: 0.66500 - acc: 0.6274 -- iter: 096/213
[A[ATraining Step: 53  | total loss: [1m[32m0.66692[0m[0m | time: 2.508s
[2K
| Adam | epoch: 008 | loss: 0.66692 - acc: 0.6224 -- iter: 128/213
[A[ATraining Step: 54  | total loss: [1m[32m0.66605[0m[0m | time: 3.114s
[2K
| Adam | epoch: 008 | loss: 0.66605 - acc: 0.6228 -- iter: 160/213
[A[ATraining Step: 55  | total loss: [1m[32m0.66671[0m[0m | time: 3.554s
[2K
| Adam | epoch: 008 | loss: 0.66671 - acc: 0.6186 -- iter: 192/213
[A[ATraining Step: 56  | total loss: [1m[32m0.65443[0m[0m | time: 4.973s
[2K
| Adam | epoch: 008 | loss: 0.65443 - acc: 0.6455 | val_loss: 0.72439 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 57  | total loss: [1m[32m0.64302[0m[0m | time: 0.617s
[2K
| Adam | epoch: 009 | loss: 0.64302 - acc: 0.6682 -- iter: 032/213
[A[ATraining Step: 58  | total loss: [1m[32m0.64847[0m[0m | time: 1.231s
[2K
| Adam | epoch: 009 | loss: 0.64847 - acc: 0.6581 -- iter: 064/213
[A[ATraining Step: 59  | total loss: [1m[32m0.65102[0m[0m | time: 1.838s
[2K
| Adam | epoch: 009 | loss: 0.65102 - acc: 0.6536 -- iter: 096/213
[A[ATraining Step: 60  | total loss: [1m[32m0.65966[0m[0m | time: 2.450s
[2K
| Adam | epoch: 009 | loss: 0.65966 - acc: 0.6416 -- iter: 128/213
[A[ATraining Step: 61  | total loss: [1m[32m0.65723[0m[0m | time: 3.066s
[2K
| Adam | epoch: 009 | loss: 0.65723 - acc: 0.6435 -- iter: 160/213
[A[ATraining Step: 62  | total loss: [1m[32m0.65800[0m[0m | time: 3.667s
[2K
| Adam | epoch: 009 | loss: 0.65800 - acc: 0.6411 -- iter: 192/213
[A[ATraining Step: 63  | total loss: [1m[32m0.67105[0m[0m | time: 5.081s
[2K
| Adam | epoch: 009 | loss: 0.67105 - acc: 0.6192 | val_loss: 0.70700 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 64  | total loss: [1m[32m0.66749[0m[0m | time: 0.417s
[2K
| Adam | epoch: 010 | loss: 0.66749 - acc: 0.6252 -- iter: 032/213
[A[ATraining Step: 65  | total loss: [1m[32m0.66464[0m[0m | time: 1.028s
[2K
| Adam | epoch: 010 | loss: 0.66464 - acc: 0.6303 -- iter: 064/213
[A[ATraining Step: 66  | total loss: [1m[32m0.66860[0m[0m | time: 1.633s
[2K
| Adam | epoch: 010 | loss: 0.66860 - acc: 0.6182 -- iter: 096/213
[A[ATraining Step: 67  | total loss: [1m[32m0.66803[0m[0m | time: 2.266s
[2K
| Adam | epoch: 010 | loss: 0.66803 - acc: 0.6191 -- iter: 128/213
[A[ATraining Step: 68  | total loss: [1m[32m0.66731[0m[0m | time: 2.881s
[2K
| Adam | epoch: 010 | loss: 0.66731 - acc: 0.6198 -- iter: 160/213
[A[ATraining Step: 69  | total loss: [1m[32m0.66947[0m[0m | time: 3.488s
[2K
| Adam | epoch: 010 | loss: 0.66947 - acc: 0.6131 -- iter: 192/213
[A[ATraining Step: 70  | total loss: [1m[32m0.66713[0m[0m | time: 5.095s
[2K
| Adam | epoch: 010 | loss: 0.66713 - acc: 0.6217 | val_loss: 0.69655 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 71  | total loss: [1m[32m0.66808[0m[0m | time: 0.434s
[2K
| Adam | epoch: 011 | loss: 0.66808 - acc: 0.6185 -- iter: 032/213
[A[ATraining Step: 72  | total loss: [1m[32m0.66832[0m[0m | time: 0.846s
[2K
| Adam | epoch: 011 | loss: 0.66832 - acc: 0.6185 -- iter: 064/213
[A[ATraining Step: 73  | total loss: [1m[32m0.66824[0m[0m | time: 1.482s
[2K
| Adam | epoch: 011 | loss: 0.66824 - acc: 0.6186 -- iter: 096/213
[A[ATraining Step: 74  | total loss: [1m[32m0.66721[0m[0m | time: 2.084s
[2K
| Adam | epoch: 011 | loss: 0.66721 - acc: 0.6227 -- iter: 128/213
[A[ATraining Step: 75  | total loss: [1m[32m0.67120[0m[0m | time: 2.695s
[2K
| Adam | epoch: 011 | loss: 0.67120 - acc: 0.6094 -- iter: 160/213
[A[ATraining Step: 76  | total loss: [1m[32m0.67365[0m[0m | time: 3.308s
[2K
| Adam | epoch: 011 | loss: 0.67365 - acc: 0.6010 -- iter: 192/213
[A[ATraining Step: 77  | total loss: [1m[32m0.67185[0m[0m | time: 4.925s
[2K
| Adam | epoch: 011 | loss: 0.67185 - acc: 0.6069 | val_loss: 0.69931 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 78  | total loss: [1m[32m0.67314[0m[0m | time: 0.612s
[2K
| Adam | epoch: 012 | loss: 0.67314 - acc: 0.6022 -- iter: 032/213
[A[ATraining Step: 79  | total loss: [1m[32m0.66818[0m[0m | time: 1.026s
[2K
| Adam | epoch: 012 | loss: 0.66818 - acc: 0.6175 -- iter: 064/213
[A[ATraining Step: 80  | total loss: [1m[32m0.66612[0m[0m | time: 1.448s
[2K
| Adam | epoch: 012 | loss: 0.66612 - acc: 0.6226 -- iter: 096/213
[A[ATraining Step: 81  | total loss: [1m[32m0.66408[0m[0m | time: 2.043s
[2K
| Adam | epoch: 012 | loss: 0.66408 - acc: 0.6270 -- iter: 128/213
[A[ATraining Step: 82  | total loss: [1m[32m0.67081[0m[0m | time: 2.658s
[2K
| Adam | epoch: 012 | loss: 0.67081 - acc: 0.6112 -- iter: 160/213
[A[ATraining Step: 83  | total loss: [1m[32m0.66534[0m[0m | time: 3.271s
[2K
| Adam | epoch: 012 | loss: 0.66534 - acc: 0.6219 -- iter: 192/213
[A[ATraining Step: 84  | total loss: [1m[32m0.66608[0m[0m | time: 4.883s
[2K
| Adam | epoch: 012 | loss: 0.66608 - acc: 0.6191 | val_loss: 0.72705 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 85  | total loss: [1m[32m0.66015[0m[0m | time: 0.606s
[2K
| Adam | epoch: 013 | loss: 0.66015 - acc: 0.6291 -- iter: 032/213
[A[ATraining Step: 86  | total loss: [1m[32m0.67006[0m[0m | time: 1.213s
[2K
| Adam | epoch: 013 | loss: 0.67006 - acc: 0.6131 -- iter: 064/213
[A[ATraining Step: 87  | total loss: [1m[32m0.66742[0m[0m | time: 1.657s
[2K
| Adam | epoch: 013 | loss: 0.66742 - acc: 0.6174 -- iter: 096/213
[A[ATraining Step: 88  | total loss: [1m[32m0.66212[0m[0m | time: 2.070s
[2K
| Adam | epoch: 013 | loss: 0.66212 - acc: 0.6271 -- iter: 128/213
[A[ATraining Step: 89  | total loss: [1m[32m0.65699[0m[0m | time: 2.683s
[2K
| Adam | epoch: 013 | loss: 0.65699 - acc: 0.6358 -- iter: 160/213
[A[ATraining Step: 90  | total loss: [1m[32m0.66293[0m[0m | time: 3.284s
[2K
| Adam | epoch: 013 | loss: 0.66293 - acc: 0.6253 -- iter: 192/213
[A[ATraining Step: 91  | total loss: [1m[32m0.66256[0m[0m | time: 4.887s
[2K
| Adam | epoch: 013 | loss: 0.66256 - acc: 0.6253 | val_loss: 0.72136 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 92  | total loss: [1m[32m0.66218[0m[0m | time: 0.617s
[2K
| Adam | epoch: 014 | loss: 0.66218 - acc: 0.6253 -- iter: 032/213
[A[ATraining Step: 93  | total loss: [1m[32m0.66747[0m[0m | time: 1.224s
[2K
| Adam | epoch: 014 | loss: 0.66747 - acc: 0.6159 -- iter: 064/213
[A[ATraining Step: 94  | total loss: [1m[32m0.66218[0m[0m | time: 1.841s
[2K
| Adam | epoch: 014 | loss: 0.66218 - acc: 0.6262 -- iter: 096/213
[A[ATraining Step: 95  | total loss: [1m[32m0.66531[0m[0m | time: 2.270s
[2K
| Adam | epoch: 014 | loss: 0.66531 - acc: 0.6198 -- iter: 128/213
[A[ATraining Step: 96  | total loss: [1m[32m0.66523[0m[0m | time: 2.682s
[2K
| Adam | epoch: 014 | loss: 0.66523 - acc: 0.6197 -- iter: 160/213
[A[ATraining Step: 97  | total loss: [1m[32m0.66551[0m[0m | time: 3.313s
[2K
| Adam | epoch: 014 | loss: 0.66551 - acc: 0.6196 -- iter: 192/213
[A[ATraining Step: 98  | total loss: [1m[32m0.66123[0m[0m | time: 4.920s
[2K
| Adam | epoch: 014 | loss: 0.66123 - acc: 0.6296 | val_loss: 0.70690 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 99  | total loss: [1m[32m0.65738[0m[0m | time: 0.620s
[2K
| Adam | epoch: 015 | loss: 0.65738 - acc: 0.6385 -- iter: 032/213
[A[ATraining Step: 100  | total loss: [1m[32m0.66213[0m[0m | time: 1.246s
[2K
| Adam | epoch: 015 | loss: 0.66213 - acc: 0.6278 -- iter: 064/213
[A[ATraining Step: 101  | total loss: [1m[32m0.66750[0m[0m | time: 1.846s
[2K
| Adam | epoch: 015 | loss: 0.66750 - acc: 0.6150 -- iter: 096/213
[A[ATraining Step: 102  | total loss: [1m[32m0.66964[0m[0m | time: 2.450s
[2K
| Adam | epoch: 015 | loss: 0.66964 - acc: 0.6097 -- iter: 128/213
[A[ATraining Step: 103  | total loss: [1m[32m0.66865[0m[0m | time: 2.864s
[2K
| Adam | epoch: 015 | loss: 0.66865 - acc: 0.6113 -- iter: 160/213
[A[ATraining Step: 104  | total loss: [1m[32m0.67033[0m[0m | time: 3.289s
[2K
| Adam | epoch: 015 | loss: 0.67033 - acc: 0.6073 -- iter: 192/213
[A[ATraining Step: 105  | total loss: [1m[32m0.67162[0m[0m | time: 4.905s
[2K
| Adam | epoch: 015 | loss: 0.67162 - acc: 0.6037 | val_loss: 0.70018 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 106  | total loss: [1m[32m0.67405[0m[0m | time: 0.610s
[2K
| Adam | epoch: 016 | loss: 0.67405 - acc: 0.5964 -- iter: 032/213
[A[ATraining Step: 107  | total loss: [1m[32m0.67520[0m[0m | time: 1.211s
[2K
| Adam | epoch: 016 | loss: 0.67520 - acc: 0.5931 -- iter: 064/213
[A[ATraining Step: 108  | total loss: [1m[32m0.67091[0m[0m | time: 1.822s
[2K
| Adam | epoch: 016 | loss: 0.67091 - acc: 0.6056 -- iter: 096/213
[A[ATraining Step: 109  | total loss: [1m[32m0.67015[0m[0m | time: 2.441s
[2K
| Adam | epoch: 016 | loss: 0.67015 - acc: 0.6076 -- iter: 128/213
[A[ATraining Step: 110  | total loss: [1m[32m0.66870[0m[0m | time: 3.046s
[2K
| Adam | epoch: 016 | loss: 0.66870 - acc: 0.6124 -- iter: 160/213
[A[ATraining Step: 111  | total loss: [1m[32m0.66927[0m[0m | time: 3.465s
[2K
| Adam | epoch: 016 | loss: 0.66927 - acc: 0.6106 -- iter: 192/213
[A[ATraining Step: 112  | total loss: [1m[32m0.67029[0m[0m | time: 4.908s
[2K
| Adam | epoch: 016 | loss: 0.67029 - acc: 0.6066 | val_loss: 0.70139 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 113  | total loss: [1m[32m0.67156[0m[0m | time: 0.611s
[2K
| Adam | epoch: 017 | loss: 0.67156 - acc: 0.6031 -- iter: 032/213
[A[ATraining Step: 114  | total loss: [1m[32m0.66951[0m[0m | time: 1.210s
[2K
| Adam | epoch: 017 | loss: 0.66951 - acc: 0.6084 -- iter: 064/213
[A[ATraining Step: 115  | total loss: [1m[32m0.67109[0m[0m | time: 1.817s
[2K
| Adam | epoch: 017 | loss: 0.67109 - acc: 0.6038 -- iter: 096/213
[A[ATraining Step: 116  | total loss: [1m[32m0.66788[0m[0m | time: 2.425s
[2K
| Adam | epoch: 017 | loss: 0.66788 - acc: 0.6122 -- iter: 128/213
[A[ATraining Step: 117  | total loss: [1m[32m0.66877[0m[0m | time: 3.041s
[2K
| Adam | epoch: 017 | loss: 0.66877 - acc: 0.6104 -- iter: 160/213
[A[ATraining Step: 118  | total loss: [1m[32m0.66942[0m[0m | time: 3.643s
[2K
| Adam | epoch: 017 | loss: 0.66942 - acc: 0.6087 -- iter: 192/213
[A[ATraining Step: 119  | total loss: [1m[32m0.66985[0m[0m | time: 5.058s
[2K
| Adam | epoch: 017 | loss: 0.66985 - acc: 0.6072 | val_loss: 0.70732 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 120  | total loss: [1m[32m0.67560[0m[0m | time: 0.440s
[2K
| Adam | epoch: 018 | loss: 0.67560 - acc: 0.5941 -- iter: 032/213
[A[ATraining Step: 121  | total loss: [1m[32m0.68039[0m[0m | time: 1.043s
[2K
| Adam | epoch: 018 | loss: 0.68039 - acc: 0.5823 -- iter: 064/213
[A[ATraining Step: 122  | total loss: [1m[32m0.67448[0m[0m | time: 1.646s
[2K
| Adam | epoch: 018 | loss: 0.67448 - acc: 0.5960 -- iter: 096/213
[A[ATraining Step: 123  | total loss: [1m[32m0.67203[0m[0m | time: 2.263s
[2K
| Adam | epoch: 018 | loss: 0.67203 - acc: 0.6020 -- iter: 128/213
[A[ATraining Step: 124  | total loss: [1m[32m0.67224[0m[0m | time: 2.896s
[2K
| Adam | epoch: 018 | loss: 0.67224 - acc: 0.6012 -- iter: 160/213
[A[ATraining Step: 125  | total loss: [1m[32m0.67478[0m[0m | time: 3.513s
[2K
| Adam | epoch: 018 | loss: 0.67478 - acc: 0.5942 -- iter: 192/213
[A[ATraining Step: 126  | total loss: [1m[32m0.67219[0m[0m | time: 5.122s
[2K
| Adam | epoch: 018 | loss: 0.67219 - acc: 0.6004 | val_loss: 0.70262 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 127  | total loss: [1m[32m0.67213[0m[0m | time: 0.443s
[2K
| Adam | epoch: 019 | loss: 0.67213 - acc: 0.5997 -- iter: 032/213
[A[ATraining Step: 128  | total loss: [1m[32m0.67304[0m[0m | time: 0.854s
[2K
| Adam | epoch: 019 | loss: 0.67304 - acc: 0.5969 -- iter: 064/213
[A[ATraining Step: 129  | total loss: [1m[32m0.67343[0m[0m | time: 1.456s
[2K
| Adam | epoch: 019 | loss: 0.67343 - acc: 0.5943 -- iter: 096/213
[A[ATraining Step: 130  | total loss: [1m[32m0.66961[0m[0m | time: 2.068s
[2K
| Adam | epoch: 019 | loss: 0.66961 - acc: 0.6037 -- iter: 128/213
[A[ATraining Step: 131  | total loss: [1m[32m0.67233[0m[0m | time: 2.673s
[2K
| Adam | epoch: 019 | loss: 0.67233 - acc: 0.5964 -- iter: 160/213
[A[ATraining Step: 132  | total loss: [1m[32m0.67223[0m[0m | time: 3.299s
[2K
| Adam | epoch: 019 | loss: 0.67223 - acc: 0.5962 -- iter: 192/213
[A[ATraining Step: 133  | total loss: [1m[32m0.67086[0m[0m | time: 4.888s
[2K
| Adam | epoch: 019 | loss: 0.67086 - acc: 0.5990 | val_loss: 0.70722 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 134  | total loss: [1m[32m0.66845[0m[0m | time: 0.623s
[2K
| Adam | epoch: 020 | loss: 0.66845 - acc: 0.6048 -- iter: 032/213
[A[ATraining Step: 135  | total loss: [1m[32m0.66872[0m[0m | time: 1.034s
[2K
| Adam | epoch: 020 | loss: 0.66872 - acc: 0.6037 -- iter: 064/213
[A[ATraining Step: 136  | total loss: [1m[32m0.66842[0m[0m | time: 1.453s
[2K
| Adam | epoch: 020 | loss: 0.66842 - acc: 0.6052 -- iter: 096/213
[A[ATraining Step: 137  | total loss: [1m[32m0.66767[0m[0m | time: 2.053s
[2K
| Adam | epoch: 020 | loss: 0.66767 - acc: 0.6066 -- iter: 128/213
[A[ATraining Step: 138  | total loss: [1m[32m0.66693[0m[0m | time: 2.678s
[2K
| Adam | epoch: 020 | loss: 0.66693 - acc: 0.6084 -- iter: 160/213
[A[ATraining Step: 139  | total loss: [1m[32m0.67073[0m[0m | time: 3.276s
[2K
| Adam | epoch: 020 | loss: 0.67073 - acc: 0.6007 -- iter: 192/213
[A[ATraining Step: 140  | total loss: [1m[32m0.66594[0m[0m | time: 4.889s
[2K
| Adam | epoch: 020 | loss: 0.66594 - acc: 0.6094 | val_loss: 0.71262 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 141  | total loss: [1m[32m0.66145[0m[0m | time: 0.641s
[2K
| Adam | epoch: 021 | loss: 0.66145 - acc: 0.6172 -- iter: 032/213
[A[ATraining Step: 142  | total loss: [1m[32m0.65725[0m[0m | time: 1.247s
[2K
| Adam | epoch: 021 | loss: 0.65725 - acc: 0.6242 -- iter: 064/213
[A[ATraining Step: 143  | total loss: [1m[32m0.66880[0m[0m | time: 1.675s
[2K
| Adam | epoch: 021 | loss: 0.66880 - acc: 0.6056 -- iter: 096/213
[A[ATraining Step: 144  | total loss: [1m[32m0.66963[0m[0m | time: 2.089s
[2K
| Adam | epoch: 021 | loss: 0.66963 - acc: 0.6021 -- iter: 128/213
[A[ATraining Step: 145  | total loss: [1m[32m0.66970[0m[0m | time: 2.700s
[2K
| Adam | epoch: 021 | loss: 0.66970 - acc: 0.5991 -- iter: 160/213
[A[ATraining Step: 146  | total loss: [1m[32m0.67310[0m[0m | time: 3.307s
[2K
| Adam | epoch: 021 | loss: 0.67310 - acc: 0.5892 -- iter: 192/213
[A[ATraining Step: 147  | total loss: [1m[32m0.67230[0m[0m | time: 4.922s
[2K
| Adam | epoch: 021 | loss: 0.67230 - acc: 0.5896 | val_loss: 0.69237 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 148  | total loss: [1m[32m0.67226[0m[0m | time: 0.613s
[2K
| Adam | epoch: 022 | loss: 0.67226 - acc: 0.5900 -- iter: 032/213
[A[ATraining Step: 149  | total loss: [1m[32m0.67045[0m[0m | time: 1.249s
[2K
| Adam | epoch: 022 | loss: 0.67045 - acc: 0.5967 -- iter: 064/213
[A[ATraining Step: 150  | total loss: [1m[32m0.66749[0m[0m | time: 1.866s
[2K
| Adam | epoch: 022 | loss: 0.66749 - acc: 0.6057 -- iter: 096/213
[A[ATraining Step: 151  | total loss: [1m[32m0.66536[0m[0m | time: 2.297s
[2K
| Adam | epoch: 022 | loss: 0.66536 - acc: 0.6108 -- iter: 128/213
[A[ATraining Step: 152  | total loss: [1m[32m0.67191[0m[0m | time: 2.721s
[2K
| Adam | epoch: 022 | loss: 0.67191 - acc: 0.5926 -- iter: 160/213
[A[ATraining Step: 153  | total loss: [1m[32m0.67705[0m[0m | time: 3.321s
[2K
| Adam | epoch: 022 | loss: 0.67705 - acc: 0.5762 -- iter: 192/213
[A[ATraining Step: 154  | total loss: [1m[32m0.67558[0m[0m | time: 4.955s
[2K
| Adam | epoch: 022 | loss: 0.67558 - acc: 0.5779 | val_loss: 0.69099 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 155  | total loss: [1m[32m0.67466[0m[0m | time: 0.607s
[2K
| Adam | epoch: 023 | loss: 0.67466 - acc: 0.5795 -- iter: 032/213
[A[ATraining Step: 156  | total loss: [1m[32m0.67172[0m[0m | time: 1.215s
[2K
| Adam | epoch: 023 | loss: 0.67172 - acc: 0.5872 -- iter: 064/213
[A[ATraining Step: 157  | total loss: [1m[32m0.66999[0m[0m | time: 1.839s
[2K
| Adam | epoch: 023 | loss: 0.66999 - acc: 0.5878 -- iter: 096/213
[A[ATraining Step: 158  | total loss: [1m[32m0.65952[0m[0m | time: 2.441s
[2K
| Adam | epoch: 023 | loss: 0.65952 - acc: 0.6166 -- iter: 128/213
[A[ATraining Step: 159  | total loss: [1m[32m0.66505[0m[0m | time: 2.860s
[2K
| Adam | epoch: 023 | loss: 0.66505 - acc: 0.6018 -- iter: 160/213
[A[ATraining Step: 160  | total loss: [1m[32m0.66354[0m[0m | time: 3.278s
[2K
| Adam | epoch: 023 | loss: 0.66354 - acc: 0.6035 -- iter: 192/213
[A[ATraining Step: 161  | total loss: [1m[32m0.66121[0m[0m | time: 4.905s
[2K
| Adam | epoch: 023 | loss: 0.66121 - acc: 0.6051 | val_loss: 0.70953 - val_acc: 0.5224 -- iter: 213/213
--
Training Step: 162  | total loss: [1m[32m0.66163[0m[0m | time: 0.609s
[2K
| Adam | epoch: 024 | loss: 0.66163 - acc: 0.6008 -- iter: 032/213
[A[ATraining Step: 163  | total loss: [1m[32m0.65431[0m[0m | time: 1.218s
[2K
| Adam | epoch: 024 | loss: 0.65431 - acc: 0.6095 -- iter: 064/213
[A[ATraining Step: 164  | total loss: [1m[32m0.65379[0m[0m | time: 1.831s
[2K
| Adam | epoch: 024 | loss: 0.65379 - acc: 0.6048 -- iter: 096/213
[A[ATraining Step: 165  | total loss: [1m[32m0.64928[0m[0m | time: 2.435s
[2K
| Adam | epoch: 024 | loss: 0.64928 - acc: 0.6068 -- iter: 128/213
[A[ATraining Step: 166  | total loss: [1m[32m0.64797[0m[0m | time: 3.043s
[2K
| Adam | epoch: 024 | loss: 0.64797 - acc: 0.5992 -- iter: 160/213
[A[ATraining Step: 167  | total loss: [1m[32m0.64209[0m[0m | time: 3.456s
[2K
| Adam | epoch: 024 | loss: 0.64209 - acc: 0.6081 -- iter: 192/213
[A[ATraining Step: 168  | total loss: [1m[32m0.64023[0m[0m | time: 4.880s
[2K
| Adam | epoch: 024 | loss: 0.64023 - acc: 0.6044 | val_loss: 0.65762 - val_acc: 0.6119 -- iter: 213/213
--
Training Step: 169  | total loss: [1m[32m0.63464[0m[0m | time: 0.640s
[2K
| Adam | epoch: 025 | loss: 0.63464 - acc: 0.6011 -- iter: 032/213
[A[ATraining Step: 170  | total loss: [1m[32m0.62627[0m[0m | time: 1.248s
[2K
| Adam | epoch: 025 | loss: 0.62627 - acc: 0.6066 -- iter: 064/213
[A[ATraining Step: 171  | total loss: [1m[32m0.62096[0m[0m | time: 1.850s
[2K
| Adam | epoch: 025 | loss: 0.62096 - acc: 0.6178 -- iter: 096/213
[A[ATraining Step: 172  | total loss: [1m[32m0.61247[0m[0m | time: 2.487s
[2K
| Adam | epoch: 025 | loss: 0.61247 - acc: 0.6404 -- iter: 128/213
[A[ATraining Step: 173  | total loss: [1m[32m0.58774[0m[0m | time: 3.089s
[2K
| Adam | epoch: 025 | loss: 0.58774 - acc: 0.6576 -- iter: 160/213
[A[ATraining Step: 174  | total loss: [1m[32m0.57389[0m[0m | time: 3.696s
[2K
| Adam | epoch: 025 | loss: 0.57389 - acc: 0.6669 -- iter: 192/213
[A[ATraining Step: 175  | total loss: [1m[32m0.62580[0m[0m | time: 5.107s
[2K
| Adam | epoch: 025 | loss: 0.62580 - acc: 0.6346 | val_loss: 0.77020 - val_acc: 0.6716 -- iter: 213/213
--
Training Step: 176  | total loss: [1m[32m0.63693[0m[0m | time: 0.417s
[2K
| Adam | epoch: 026 | loss: 0.63693 - acc: 0.6235 -- iter: 032/213
[A[ATraining Step: 177  | total loss: [1m[32m0.61193[0m[0m | time: 1.018s
[2K
| Adam | epoch: 026 | loss: 0.61193 - acc: 0.6468 -- iter: 064/213
[A[ATraining Step: 178  | total loss: [1m[32m0.59308[0m[0m | time: 1.624s
[2K
| Adam | epoch: 026 | loss: 0.59308 - acc: 0.6665 -- iter: 096/213
[A[ATraining Step: 179  | total loss: [1m[32m0.57315[0m[0m | time: 2.234s
[2K
| Adam | epoch: 026 | loss: 0.57315 - acc: 0.6843 -- iter: 128/213
[A[ATraining Step: 180  | total loss: [1m[32m0.55557[0m[0m | time: 2.853s
[2K
| Adam | epoch: 026 | loss: 0.55557 - acc: 0.7033 -- iter: 160/213
[A[ATraining Step: 181  | total loss: [1m[32m0.56275[0m[0m | time: 3.457s
[2K
| Adam | epoch: 026 | loss: 0.56275 - acc: 0.7018 -- iter: 192/213
[A[ATraining Step: 182  | total loss: [1m[32m0.54942[0m[0m | time: 5.081s
[2K
| Adam | epoch: 026 | loss: 0.54942 - acc: 0.7128 | val_loss: 0.69665 - val_acc: 0.5672 -- iter: 213/213
--
Training Step: 183  | total loss: [1m[32m0.53850[0m[0m | time: 0.434s
[2K
| Adam | epoch: 027 | loss: 0.53850 - acc: 0.7228 -- iter: 032/213
[A[ATraining Step: 184  | total loss: [1m[32m0.54293[0m[0m | time: 0.854s
[2K
| Adam | epoch: 027 | loss: 0.54293 - acc: 0.7172 -- iter: 064/213
[A[ATraining Step: 185  | total loss: [1m[32m0.52934[0m[0m | time: 1.482s
[2K
| Adam | epoch: 027 | loss: 0.52934 - acc: 0.7359 -- iter: 096/213
[A[ATraining Step: 186  | total loss: [1m[32m0.50836[0m[0m | time: 2.083s
[2K
| Adam | epoch: 027 | loss: 0.50836 - acc: 0.7498 -- iter: 128/213
[A[ATraining Step: 187  | total loss: [1m[32m0.50693[0m[0m | time: 2.692s
[2K
| Adam | epoch: 027 | loss: 0.50693 - acc: 0.7467 -- iter: 160/213
[A[ATraining Step: 188  | total loss: [1m[32m0.49865[0m[0m | time: 3.321s
[2K
| Adam | epoch: 027 | loss: 0.49865 - acc: 0.7502 -- iter: 192/213
[A[ATraining Step: 189  | total loss: [1m[32m0.47838[0m[0m | time: 4.928s
[2K
| Adam | epoch: 027 | loss: 0.47838 - acc: 0.7658 | val_loss: 0.72189 - val_acc: 0.5672 -- iter: 213/213
--
Training Step: 190  | total loss: [1m[32m0.46956[0m[0m | time: 0.628s
[2K
| Adam | epoch: 028 | loss: 0.46956 - acc: 0.7705 -- iter: 032/213
[A[ATraining Step: 191  | total loss: [1m[32m0.45626[0m[0m | time: 1.052s
[2K
| Adam | epoch: 028 | loss: 0.45626 - acc: 0.7840 -- iter: 064/213
[A[ATraining Step: 192  | total loss: [1m[32m0.43886[0m[0m | time: 1.470s
[2K
| Adam | epoch: 028 | loss: 0.43886 - acc: 0.7961 -- iter: 096/213
[A[ATraining Step: 193  | total loss: [1m[32m0.42149[0m[0m | time: 2.067s
[2K
| Adam | epoch: 028 | loss: 0.42149 - acc: 0.7975 -- iter: 128/213
[A[ATraining Step: 194  | total loss: [1m[32m0.39988[0m[0m | time: 2.647s
[2K
| Adam | epoch: 028 | loss: 0.39988 - acc: 0.8115 -- iter: 160/213
[A[ATraining Step: 195  | total loss: [1m[32m0.39119[0m[0m | time: 3.257s
[2K
| Adam | epoch: 028 | loss: 0.39119 - acc: 0.8241 -- iter: 192/213
[A[ATraining Step: 196  | total loss: [1m[32m0.37897[0m[0m | time: 4.875s
[2K
| Adam | epoch: 028 | loss: 0.37897 - acc: 0.8292 | val_loss: 0.86569 - val_acc: 0.6567 -- iter: 213/213
--
Training Step: 197  | total loss: [1m[32m0.39037[0m[0m | time: 0.612s
[2K
| Adam | epoch: 029 | loss: 0.39037 - acc: 0.8212 -- iter: 032/213
[A[ATraining Step: 198  | total loss: [1m[32m0.38200[0m[0m | time: 1.207s
[2K
| Adam | epoch: 029 | loss: 0.38200 - acc: 0.8266 -- iter: 064/213
[A[ATraining Step: 199  | total loss: [1m[32m0.36690[0m[0m | time: 1.627s
[2K
| Adam | epoch: 029 | loss: 0.36690 - acc: 0.8315 -- iter: 096/213
[A[ATraining Step: 200  | total loss: [1m[32m0.34962[0m[0m | time: 3.047s
[2K
| Adam | epoch: 029 | loss: 0.34962 - acc: 0.8435 | val_loss: 0.97260 - val_acc: 0.6866 -- iter: 128/213
--
Training Step: 201  | total loss: [1m[32m0.32770[0m[0m | time: 3.655s
[2K
| Adam | epoch: 029 | loss: 0.32770 - acc: 0.8592 -- iter: 160/213
[A[ATraining Step: 202  | total loss: [1m[32m0.31066[0m[0m | time: 4.258s
[2K
| Adam | epoch: 029 | loss: 0.31066 - acc: 0.8701 -- iter: 192/213
[A[ATraining Step: 203  | total loss: [1m[32m0.29839[0m[0m | time: 5.855s
[2K
| Adam | epoch: 029 | loss: 0.29839 - acc: 0.8800 | val_loss: 1.06008 - val_acc: 0.6418 -- iter: 213/213
--
Training Step: 204  | total loss: [1m[32m0.29248[0m[0m | time: 0.611s
[2K
| Adam | epoch: 030 | loss: 0.29248 - acc: 0.8826 -- iter: 032/213
[A[ATraining Step: 205  | total loss: [1m[32m0.28509[0m[0m | time: 1.212s
[2K
| Adam | epoch: 030 | loss: 0.28509 - acc: 0.8819 -- iter: 064/213
[A[ATraining Step: 206  | total loss: [1m[32m0.26706[0m[0m | time: 1.817s
[2K
| Adam | epoch: 030 | loss: 0.26706 - acc: 0.8874 -- iter: 096/213
[A[ATraining Step: 207  | total loss: [1m[32m0.26082[0m[0m | time: 2.237s
[2K
| Adam | epoch: 030 | loss: 0.26082 - acc: 0.8893 -- iter: 128/213
[A[ATraining Step: 208  | total loss: [1m[32m0.27959[0m[0m | time: 2.655s
[2K
| Adam | epoch: 030 | loss: 0.27959 - acc: 0.8909 -- iter: 160/213
[A[ATraining Step: 209  | total loss: [1m[32m0.26876[0m[0m | time: 3.281s
[2K
| Adam | epoch: 030 | loss: 0.26876 - acc: 0.8970 -- iter: 192/213
[A[ATraining Step: 210  | total loss: [1m[32m0.25768[0m[0m | time: 4.883s
[2K
| Adam | epoch: 030 | loss: 0.25768 - acc: 0.9042 | val_loss: 1.14165 - val_acc: 0.7015 -- iter: 213/213
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7330357142857143
Validation AUPRC:0.6894822604605659
Test AUC:0.7603603603603604
Test AUPRC:0.8018194680797868
BestTestF1Score	0.67	0.36	0.67	0.76	0.59	22	7	23	15	0.63
BestTestMCCScore	0.67	0.36	0.67	0.76	0.59	22	7	23	15	0.63
BestTestAccuracyScore	0.67	0.36	0.67	0.76	0.59	22	7	23	15	0.63
BestValidationF1Score	0.78	0.52	0.76	0.74	0.83	29	10	22	6	0.63
BestValidationMCC	0.78	0.52	0.76	0.74	0.83	29	10	22	6	0.63
BestValidationAccuracy	0.78	0.52	0.76	0.74	0.83	29	10	22	6	0.63
TestPredictions (Threshold:0.63)
CHEMBL62993,TP,ACT,1.0	CHEMBL180511,TN,INACT,0.09000000357627869	CHEMBL1242886,FP,INACT,0.9399999976158142	CHEMBL1835210,TP,ACT,0.7900000214576721	CHEMBL166476,TN,INACT,0.029999999329447746	CHEMBL233958,TN,INACT,0.14000000059604645	CHEMBL2348696,FN,ACT,0.6299999952316284	CHEMBL385930,TP,ACT,1.0	CHEMBL318035,TP,ACT,1.0	CHEMBL428647,FP,INACT,0.9599999785423279	CHEMBL2041044,TP,ACT,0.8999999761581421	CHEMBL101545,FN,ACT,0.029999999329447746	CHEMBL1762351,TP,ACT,0.7300000190734863	CHEMBL101442,TP,ACT,0.7400000095367432	CHEMBL92930,TN,INACT,0.03999999910593033	CHEMBL237088,TP,ACT,1.0	CHEMBL443565,TP,ACT,0.949999988079071	CHEMBL117075,TP,ACT,1.0	CHEMBL492385,FN,ACT,0.4099999964237213	CHEMBL3133149,FN,ACT,0.1599999964237213	CHEMBL3805088,TN,INACT,0.20000000298023224	CHEMBL567893,FN,ACT,0.1599999964237213	CHEMBL367587,FP,INACT,1.0	CHEMBL2381343,FN,ACT,0.36000001430511475	CHEMBL90307,TP,ACT,1.0	CHEMBL1683177,FN,ACT,0.5400000214576721	CHEMBL3359187,TP,ACT,1.0	CHEMBL1603488,FP,INACT,0.8700000047683716	CHEMBL2381345,FN,ACT,0.3400000035762787	CHEMBL195136,FN,ACT,0.07999999821186066	CHEMBL165763,TN,INACT,0.03999999910593033	CHEMBL602472,FP,INACT,1.0	CHEMBL186691,TP,ACT,1.0	CHEMBL3133259,TP,ACT,1.0	CHEMBL1710047,TN,INACT,0.07000000029802322	CHEMBL2011680,TN,INACT,0.30000001192092896	CHEMBL400366,FP,INACT,0.9200000166893005	CHEMBL2391863,TN,INACT,0.07000000029802322	CHEMBL195568,TN,INACT,0.12999999523162842	CHEMBL2391855,TN,INACT,0.1599999964237213	CHEMBL409053,TN,INACT,0.5099999904632568	CHEMBL3335244,TN,INACT,0.6299999952316284	CHEMBL246166,TN,INACT,0.4000000059604645	CHEMBL3330093,FN,ACT,0.5899999737739563	CHEMBL367365,TP,ACT,1.0	CHEMBL67349,TN,INACT,0.6200000047683716	CHEMBL493127,FN,ACT,0.550000011920929	CHEMBL281751,TN,INACT,0.019999999552965164	CHEMBL2391854,TN,INACT,0.05999999865889549	CHEMBL3360041,TP,ACT,1.0	CHEMBL420366,TP,ACT,1.0	CHEMBL180763,TP,ACT,1.0	CHEMBL395665,TN,INACT,0.05999999865889549	CHEMBL364906,FN,ACT,0.1599999964237213	CHEMBL32246,TN,INACT,0.03999999910593033	CHEMBL1222970,TN,INACT,0.3400000035762787	CHEMBL2381348,FN,ACT,0.3499999940395355	CHEMBL1223038,TN,INACT,0.029999999329447746	CHEMBL146130,TP,ACT,0.9900000095367432	CHEMBL3360060,TP,ACT,1.0	CHEMBL119879,TP,ACT,0.9900000095367432	CHEMBL321112,TN,INACT,0.4399999976158142	CHEMBL182247,TP,ACT,1.0	CHEMBL354612,FN,ACT,0.05000000074505806	CHEMBL168816,FN,ACT,0.27000001072883606	CHEMBL1738705,TN,INACT,0.07000000029802322	CHEMBL602471,FP,INACT,1.0	

