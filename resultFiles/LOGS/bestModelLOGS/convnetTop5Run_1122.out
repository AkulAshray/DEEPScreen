CNNModel CHEMBL1667665 adam 0.0005 30 32 0 0.8 False True
Number of active compounds :	142
Number of inactive compounds :	142
---------------------------------
Run id: CNNModel_CHEMBL1667665_adam_0.0005_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1667665_adam_0.0005_30_32_0.8_True/
---------------------------------
Training samples: 180
Validation samples: 57
--
Training Step: 1  | time: 0.803s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/180
[A[ATraining Step: 2  | total loss: [1m[32m0.62391[0m[0m | time: 1.409s
[2K
| Adam | epoch: 001 | loss: 0.62391 - acc: 0.3937 -- iter: 064/180
[A[ATraining Step: 3  | total loss: [1m[32m0.68001[0m[0m | time: 2.012s
[2K
| Adam | epoch: 001 | loss: 0.68001 - acc: 0.5318 -- iter: 096/180
[A[ATraining Step: 4  | total loss: [1m[32m0.69208[0m[0m | time: 2.614s
[2K
| Adam | epoch: 001 | loss: 0.69208 - acc: 0.4376 -- iter: 128/180
[A[ATraining Step: 5  | total loss: [1m[32m0.69172[0m[0m | time: 3.226s
[2K
| Adam | epoch: 001 | loss: 0.69172 - acc: 0.5457 -- iter: 160/180
[A[ATraining Step: 6  | total loss: [1m[32m0.69330[0m[0m | time: 4.654s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.4962 | val_loss: 0.69141 - val_acc: 0.5614 -- iter: 180/180
--
Training Step: 7  | total loss: [1m[32m0.69260[0m[0m | time: 0.412s
[2K
| Adam | epoch: 002 | loss: 0.69260 - acc: 0.5285 -- iter: 032/180
[A[ATraining Step: 8  | total loss: [1m[32m0.69204[0m[0m | time: 1.024s
[2K
| Adam | epoch: 002 | loss: 0.69204 - acc: 0.5406 -- iter: 064/180
[A[ATraining Step: 9  | total loss: [1m[32m0.69480[0m[0m | time: 1.649s
[2K
| Adam | epoch: 002 | loss: 0.69480 - acc: 0.4695 -- iter: 096/180
[A[ATraining Step: 10  | total loss: [1m[32m0.69206[0m[0m | time: 2.249s
[2K
| Adam | epoch: 002 | loss: 0.69206 - acc: 0.5316 -- iter: 128/180
[A[ATraining Step: 11  | total loss: [1m[32m0.69200[0m[0m | time: 2.856s
[2K
| Adam | epoch: 002 | loss: 0.69200 - acc: 0.5314 -- iter: 160/180
[A[ATraining Step: 12  | total loss: [1m[32m0.69479[0m[0m | time: 4.491s
[2K
| Adam | epoch: 002 | loss: 0.69479 - acc: 0.4610 | val_loss: 0.69193 - val_acc: 0.5614 -- iter: 180/180
--
Training Step: 13  | total loss: [1m[32m0.69508[0m[0m | time: 0.416s
[2K
| Adam | epoch: 003 | loss: 0.69508 - acc: 0.4510 -- iter: 032/180
[A[ATraining Step: 14  | total loss: [1m[32m0.69477[0m[0m | time: 0.815s
[2K
| Adam | epoch: 003 | loss: 0.69477 - acc: 0.4710 -- iter: 064/180
[A[ATraining Step: 15  | total loss: [1m[32m0.69424[0m[0m | time: 1.454s
[2K
| Adam | epoch: 003 | loss: 0.69424 - acc: 0.4824 -- iter: 096/180
[A[ATraining Step: 16  | total loss: [1m[32m0.69373[0m[0m | time: 2.067s
[2K
| Adam | epoch: 003 | loss: 0.69373 - acc: 0.4890 -- iter: 128/180
[A[ATraining Step: 17  | total loss: [1m[32m0.69357[0m[0m | time: 2.676s
[2K
| Adam | epoch: 003 | loss: 0.69357 - acc: 0.4817 -- iter: 160/180
[A[ATraining Step: 18  | total loss: [1m[32m0.69335[0m[0m | time: 4.292s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4988 | val_loss: 0.69342 - val_acc: 0.4386 -- iter: 180/180
--
Training Step: 19  | total loss: [1m[32m0.69328[0m[0m | time: 0.626s
[2K
| Adam | epoch: 004 | loss: 0.69328 - acc: 0.4888 -- iter: 032/180
[A[ATraining Step: 20  | total loss: [1m[32m0.69313[0m[0m | time: 1.023s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.4924 -- iter: 064/180
[A[ATraining Step: 21  | total loss: [1m[32m0.69371[0m[0m | time: 1.409s
[2K
| Adam | epoch: 004 | loss: 0.69371 - acc: 0.4327 -- iter: 096/180
[A[ATraining Step: 22  | total loss: [1m[32m0.69381[0m[0m | time: 2.046s
[2K
| Adam | epoch: 004 | loss: 0.69381 - acc: 0.3779 -- iter: 128/180
[A[ATraining Step: 23  | total loss: [1m[32m0.69369[0m[0m | time: 2.661s
[2K
| Adam | epoch: 004 | loss: 0.69369 - acc: 0.3770 -- iter: 160/180
[A[ATraining Step: 24  | total loss: [1m[32m0.69406[0m[0m | time: 4.275s
[2K
| Adam | epoch: 004 | loss: 0.69406 - acc: 0.3589 | val_loss: 0.69248 - val_acc: 0.5614 -- iter: 180/180
--
Training Step: 25  | total loss: [1m[32m0.69374[0m[0m | time: 0.613s
[2K
| Adam | epoch: 005 | loss: 0.69374 - acc: 0.3974 -- iter: 032/180
[A[ATraining Step: 26  | total loss: [1m[32m0.69337[0m[0m | time: 1.224s
[2K
| Adam | epoch: 005 | loss: 0.69337 - acc: 0.4494 -- iter: 064/180
[A[ATraining Step: 27  | total loss: [1m[32m0.69307[0m[0m | time: 1.608s
[2K
| Adam | epoch: 005 | loss: 0.69307 - acc: 0.4865 -- iter: 096/180
[A[ATraining Step: 28  | total loss: [1m[32m0.69291[0m[0m | time: 2.000s
[2K
| Adam | epoch: 005 | loss: 0.69291 - acc: 0.5024 -- iter: 128/180
[A[ATraining Step: 29  | total loss: [1m[32m0.69275[0m[0m | time: 2.604s
[2K
| Adam | epoch: 005 | loss: 0.69275 - acc: 0.5140 -- iter: 160/180
[A[ATraining Step: 30  | total loss: [1m[32m0.69308[0m[0m | time: 4.207s
[2K
| Adam | epoch: 005 | loss: 0.69308 - acc: 0.4958 | val_loss: 0.69165 - val_acc: 0.5614 -- iter: 180/180
--
Training Step: 31  | total loss: [1m[32m0.69397[0m[0m | time: 0.609s
[2K
| Adam | epoch: 006 | loss: 0.69397 - acc: 0.4535 -- iter: 032/180
[A[ATraining Step: 32  | total loss: [1m[32m0.69374[0m[0m | time: 1.216s
[2K
| Adam | epoch: 006 | loss: 0.69374 - acc: 0.4640 -- iter: 064/180
[A[ATraining Step: 33  | total loss: [1m[32m0.69356[0m[0m | time: 1.819s
[2K
| Adam | epoch: 006 | loss: 0.69356 - acc: 0.4719 -- iter: 096/180
[A[ATraining Step: 34  | total loss: [1m[32m0.69365[0m[0m | time: 2.205s
[2K
| Adam | epoch: 006 | loss: 0.69365 - acc: 0.4578 -- iter: 128/180
[A[ATraining Step: 35  | total loss: [1m[32m0.69336[0m[0m | time: 2.584s
[2K
| Adam | epoch: 006 | loss: 0.69336 - acc: 0.4771 -- iter: 160/180
[A[ATraining Step: 36  | total loss: [1m[32m0.69309[0m[0m | time: 4.204s
[2K
| Adam | epoch: 006 | loss: 0.69309 - acc: 0.4920 | val_loss: 0.69138 - val_acc: 0.5614 -- iter: 180/180
--
Training Step: 37  | total loss: [1m[32m0.69302[0m[0m | time: 0.609s
[2K
| Adam | epoch: 007 | loss: 0.69302 - acc: 0.4936 -- iter: 032/180
[A[ATraining Step: 38  | total loss: [1m[32m0.69297[0m[0m | time: 1.216s
[2K
| Adam | epoch: 007 | loss: 0.69297 - acc: 0.4888 -- iter: 064/180
[A[ATraining Step: 39  | total loss: [1m[32m0.69284[0m[0m | time: 1.856s
[2K
| Adam | epoch: 007 | loss: 0.69284 - acc: 0.4849 -- iter: 096/180
[A[ATraining Step: 40  | total loss: [1m[32m0.69265[0m[0m | time: 2.456s
[2K
| Adam | epoch: 007 | loss: 0.69265 - acc: 0.4936 -- iter: 128/180
[A[ATraining Step: 41  | total loss: [1m[32m0.69239[0m[0m | time: 2.850s
[2K
| Adam | epoch: 007 | loss: 0.69239 - acc: 0.5063 -- iter: 160/180
[A[ATraining Step: 42  | total loss: [1m[32m0.69244[0m[0m | time: 4.263s
[2K
| Adam | epoch: 007 | loss: 0.69244 - acc: 0.4871 | val_loss: 0.68871 - val_acc: 0.9298 -- iter: 180/180
--
Training Step: 43  | total loss: [1m[32m0.69219[0m[0m | time: 0.621s
[2K
| Adam | epoch: 008 | loss: 0.69219 - acc: 0.5071 -- iter: 032/180
[A[ATraining Step: 44  | total loss: [1m[32m0.69197[0m[0m | time: 1.223s
[2K
| Adam | epoch: 008 | loss: 0.69197 - acc: 0.5383 -- iter: 064/180
[A[ATraining Step: 45  | total loss: [1m[32m0.69148[0m[0m | time: 1.822s
[2K
| Adam | epoch: 008 | loss: 0.69148 - acc: 0.5742 -- iter: 096/180
[A[ATraining Step: 46  | total loss: [1m[32m0.69089[0m[0m | time: 2.426s
[2K
| Adam | epoch: 008 | loss: 0.69089 - acc: 0.6087 -- iter: 128/180
[A[ATraining Step: 47  | total loss: [1m[32m0.69028[0m[0m | time: 3.038s
[2K
| Adam | epoch: 008 | loss: 0.69028 - acc: 0.6165 -- iter: 160/180
[A[ATraining Step: 48  | total loss: [1m[32m0.68922[0m[0m | time: 4.431s
[2K
| Adam | epoch: 008 | loss: 0.68922 - acc: 0.6329 | val_loss: 0.66870 - val_acc: 0.9649 -- iter: 180/180
--
Training Step: 49  | total loss: [1m[32m0.68835[0m[0m | time: 0.390s
[2K
| Adam | epoch: 009 | loss: 0.68835 - acc: 0.6435 -- iter: 032/180
[A[ATraining Step: 50  | total loss: [1m[32m0.68695[0m[0m | time: 0.985s
[2K
| Adam | epoch: 009 | loss: 0.68695 - acc: 0.6523 -- iter: 064/180
[A[ATraining Step: 51  | total loss: [1m[32m0.68630[0m[0m | time: 1.580s
[2K
| Adam | epoch: 009 | loss: 0.68630 - acc: 0.6577 -- iter: 096/180
[A[ATraining Step: 52  | total loss: [1m[32m0.68347[0m[0m | time: 2.184s
[2K
| Adam | epoch: 009 | loss: 0.68347 - acc: 0.6809 -- iter: 128/180
[A[ATraining Step: 53  | total loss: [1m[32m0.68149[0m[0m | time: 2.789s
[2K
| Adam | epoch: 009 | loss: 0.68149 - acc: 0.6773 -- iter: 160/180
[A[ATraining Step: 54  | total loss: [1m[32m0.68156[0m[0m | time: 4.402s
[2K
| Adam | epoch: 009 | loss: 0.68156 - acc: 0.6515 | val_loss: 0.60069 - val_acc: 0.9298 -- iter: 180/180
--
Training Step: 55  | total loss: [1m[32m0.67598[0m[0m | time: 0.390s
[2K
| Adam | epoch: 010 | loss: 0.67598 - acc: 0.6701 -- iter: 032/180
[A[ATraining Step: 56  | total loss: [1m[32m0.66915[0m[0m | time: 0.776s
[2K
| Adam | epoch: 010 | loss: 0.66915 - acc: 0.6883 -- iter: 064/180
[A[ATraining Step: 57  | total loss: [1m[32m0.65807[0m[0m | time: 1.406s
[2K
| Adam | epoch: 010 | loss: 0.65807 - acc: 0.7107 -- iter: 096/180
[A[ATraining Step: 58  | total loss: [1m[32m0.65410[0m[0m | time: 2.017s
[2K
| Adam | epoch: 010 | loss: 0.65410 - acc: 0.7033 -- iter: 128/180
[A[ATraining Step: 59  | total loss: [1m[32m0.64512[0m[0m | time: 2.609s
[2K
| Adam | epoch: 010 | loss: 0.64512 - acc: 0.7096 -- iter: 160/180
[A[ATraining Step: 60  | total loss: [1m[32m0.63555[0m[0m | time: 4.211s
[2K
| Adam | epoch: 010 | loss: 0.63555 - acc: 0.7191 | val_loss: 0.40062 - val_acc: 0.9474 -- iter: 180/180
--
Training Step: 61  | total loss: [1m[32m0.61576[0m[0m | time: 0.612s
[2K
| Adam | epoch: 011 | loss: 0.61576 - acc: 0.7353 -- iter: 032/180
[A[ATraining Step: 62  | total loss: [1m[32m0.60556[0m[0m | time: 1.016s
[2K
| Adam | epoch: 011 | loss: 0.60556 - acc: 0.7292 -- iter: 064/180
[A[ATraining Step: 63  | total loss: [1m[32m0.59827[0m[0m | time: 1.434s
[2K
| Adam | epoch: 011 | loss: 0.59827 - acc: 0.7255 -- iter: 096/180
[A[ATraining Step: 64  | total loss: [1m[32m0.57816[0m[0m | time: 2.041s
[2K
| Adam | epoch: 011 | loss: 0.57816 - acc: 0.7348 -- iter: 128/180
[A[ATraining Step: 65  | total loss: [1m[32m0.59099[0m[0m | time: 2.658s
[2K
| Adam | epoch: 011 | loss: 0.59099 - acc: 0.7251 -- iter: 160/180
[A[ATraining Step: 66  | total loss: [1m[32m0.59587[0m[0m | time: 4.265s
[2K
| Adam | epoch: 011 | loss: 0.59587 - acc: 0.7167 | val_loss: 0.37408 - val_acc: 0.7895 -- iter: 180/180
--
Training Step: 67  | total loss: [1m[32m0.57223[0m[0m | time: 0.612s
[2K
| Adam | epoch: 012 | loss: 0.57223 - acc: 0.7282 -- iter: 032/180
[A[ATraining Step: 68  | total loss: [1m[32m0.59058[0m[0m | time: 1.235s
[2K
| Adam | epoch: 012 | loss: 0.59058 - acc: 0.7123 -- iter: 064/180
[A[ATraining Step: 69  | total loss: [1m[32m0.61560[0m[0m | time: 1.622s
[2K
| Adam | epoch: 012 | loss: 0.61560 - acc: 0.7021 -- iter: 096/180
[A[ATraining Step: 70  | total loss: [1m[32m0.60467[0m[0m | time: 2.017s
[2K
| Adam | epoch: 012 | loss: 0.60467 - acc: 0.7076 -- iter: 128/180
[A[ATraining Step: 71  | total loss: [1m[32m0.58031[0m[0m | time: 2.626s
[2K
| Adam | epoch: 012 | loss: 0.58031 - acc: 0.7181 -- iter: 160/180
[A[ATraining Step: 72  | total loss: [1m[32m0.56245[0m[0m | time: 4.249s
[2K
| Adam | epoch: 012 | loss: 0.56245 - acc: 0.7358 | val_loss: 0.43403 - val_acc: 0.7895 -- iter: 180/180
--
Training Step: 73  | total loss: [1m[32m0.56085[0m[0m | time: 0.620s
[2K
| Adam | epoch: 013 | loss: 0.56085 - acc: 0.7339 -- iter: 032/180
[A[ATraining Step: 74  | total loss: [1m[32m0.56169[0m[0m | time: 1.226s
[2K
| Adam | epoch: 013 | loss: 0.56169 - acc: 0.7254 -- iter: 064/180
[A[ATraining Step: 75  | total loss: [1m[32m0.55508[0m[0m | time: 1.827s
[2K
| Adam | epoch: 013 | loss: 0.55508 - acc: 0.7314 -- iter: 096/180
[A[ATraining Step: 76  | total loss: [1m[32m0.54548[0m[0m | time: 2.213s
[2K
| Adam | epoch: 013 | loss: 0.54548 - acc: 0.7435 -- iter: 128/180
[A[ATraining Step: 77  | total loss: [1m[32m0.53336[0m[0m | time: 2.615s
[2K
| Adam | epoch: 013 | loss: 0.53336 - acc: 0.7547 -- iter: 160/180
[A[ATraining Step: 78  | total loss: [1m[32m0.52520[0m[0m | time: 4.230s
[2K
| Adam | epoch: 013 | loss: 0.52520 - acc: 0.7543 | val_loss: 0.21005 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 79  | total loss: [1m[32m0.52022[0m[0m | time: 0.609s
[2K
| Adam | epoch: 014 | loss: 0.52022 - acc: 0.7603 -- iter: 032/180
[A[ATraining Step: 80  | total loss: [1m[32m0.50019[0m[0m | time: 1.224s
[2K
| Adam | epoch: 014 | loss: 0.50019 - acc: 0.7752 -- iter: 064/180
[A[ATraining Step: 81  | total loss: [1m[32m0.48180[0m[0m | time: 1.820s
[2K
| Adam | epoch: 014 | loss: 0.48180 - acc: 0.7885 -- iter: 096/180
[A[ATraining Step: 82  | total loss: [1m[32m0.47324[0m[0m | time: 2.419s
[2K
| Adam | epoch: 014 | loss: 0.47324 - acc: 0.7971 -- iter: 128/180
[A[ATraining Step: 83  | total loss: [1m[32m0.46298[0m[0m | time: 2.798s
[2K
| Adam | epoch: 014 | loss: 0.46298 - acc: 0.8018 -- iter: 160/180
[A[ATraining Step: 84  | total loss: [1m[32m0.44283[0m[0m | time: 4.191s
[2K
| Adam | epoch: 014 | loss: 0.44283 - acc: 0.8116 | val_loss: 0.32172 - val_acc: 0.8070 -- iter: 180/180
--
Training Step: 85  | total loss: [1m[32m0.41909[0m[0m | time: 0.655s
[2K
| Adam | epoch: 015 | loss: 0.41909 - acc: 0.8304 -- iter: 032/180
[A[ATraining Step: 86  | total loss: [1m[32m0.42434[0m[0m | time: 1.259s
[2K
| Adam | epoch: 015 | loss: 0.42434 - acc: 0.8224 -- iter: 064/180
[A[ATraining Step: 87  | total loss: [1m[32m0.42836[0m[0m | time: 1.893s
[2K
| Adam | epoch: 015 | loss: 0.42836 - acc: 0.8152 -- iter: 096/180
[A[ATraining Step: 88  | total loss: [1m[32m0.42334[0m[0m | time: 2.494s
[2K
| Adam | epoch: 015 | loss: 0.42334 - acc: 0.8149 -- iter: 128/180
[A[ATraining Step: 89  | total loss: [1m[32m0.41775[0m[0m | time: 3.103s
[2K
| Adam | epoch: 015 | loss: 0.41775 - acc: 0.8178 -- iter: 160/180
[A[ATraining Step: 90  | total loss: [1m[32m0.41139[0m[0m | time: 4.498s
[2K
| Adam | epoch: 015 | loss: 0.41139 - acc: 0.8141 | val_loss: 0.10644 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 91  | total loss: [1m[32m0.40575[0m[0m | time: 0.373s
[2K
| Adam | epoch: 016 | loss: 0.40575 - acc: 0.8077 -- iter: 032/180
[A[ATraining Step: 92  | total loss: [1m[32m0.38833[0m[0m | time: 0.974s
[2K
| Adam | epoch: 016 | loss: 0.38833 - acc: 0.8169 -- iter: 064/180
[A[ATraining Step: 93  | total loss: [1m[32m0.37204[0m[0m | time: 1.581s
[2K
| Adam | epoch: 016 | loss: 0.37204 - acc: 0.8290 -- iter: 096/180
[A[ATraining Step: 94  | total loss: [1m[32m0.43003[0m[0m | time: 2.182s
[2K
| Adam | epoch: 016 | loss: 0.43003 - acc: 0.8148 -- iter: 128/180
[A[ATraining Step: 95  | total loss: [1m[32m0.39908[0m[0m | time: 2.794s
[2K
| Adam | epoch: 016 | loss: 0.39908 - acc: 0.8334 -- iter: 160/180
[A[ATraining Step: 96  | total loss: [1m[32m0.37549[0m[0m | time: 4.411s
[2K
| Adam | epoch: 016 | loss: 0.37549 - acc: 0.8438 | val_loss: 0.11016 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 97  | total loss: [1m[32m0.35334[0m[0m | time: 0.496s
[2K
| Adam | epoch: 017 | loss: 0.35334 - acc: 0.8563 -- iter: 032/180
[A[ATraining Step: 98  | total loss: [1m[32m0.33548[0m[0m | time: 0.913s
[2K
| Adam | epoch: 017 | loss: 0.33548 - acc: 0.8606 -- iter: 064/180
[A[ATraining Step: 99  | total loss: [1m[32m0.31672[0m[0m | time: 1.516s
[2K
| Adam | epoch: 017 | loss: 0.31672 - acc: 0.8696 -- iter: 096/180
[A[ATraining Step: 100  | total loss: [1m[32m0.30793[0m[0m | time: 2.138s
[2K
| Adam | epoch: 017 | loss: 0.30793 - acc: 0.8764 -- iter: 128/180
[A[ATraining Step: 101  | total loss: [1m[32m0.29817[0m[0m | time: 2.748s
[2K
| Adam | epoch: 017 | loss: 0.29817 - acc: 0.8856 -- iter: 160/180
[A[ATraining Step: 102  | total loss: [1m[32m0.27666[0m[0m | time: 4.361s
[2K
| Adam | epoch: 017 | loss: 0.27666 - acc: 0.8939 | val_loss: 0.10108 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 103  | total loss: [1m[32m0.26435[0m[0m | time: 0.633s
[2K
| Adam | epoch: 018 | loss: 0.26435 - acc: 0.8983 -- iter: 032/180
[A[ATraining Step: 104  | total loss: [1m[32m0.24349[0m[0m | time: 1.018s
[2K
| Adam | epoch: 018 | loss: 0.24349 - acc: 0.9085 -- iter: 064/180
[A[ATraining Step: 105  | total loss: [1m[32m0.23851[0m[0m | time: 1.416s
[2K
| Adam | epoch: 018 | loss: 0.23851 - acc: 0.9076 -- iter: 096/180
[A[ATraining Step: 106  | total loss: [1m[32m0.22895[0m[0m | time: 2.021s
[2K
| Adam | epoch: 018 | loss: 0.22895 - acc: 0.9118 -- iter: 128/180
[A[ATraining Step: 107  | total loss: [1m[32m0.21846[0m[0m | time: 2.621s
[2K
| Adam | epoch: 018 | loss: 0.21846 - acc: 0.9175 -- iter: 160/180
[A[ATraining Step: 108  | total loss: [1m[32m0.22269[0m[0m | time: 4.226s
[2K
| Adam | epoch: 018 | loss: 0.22269 - acc: 0.9227 | val_loss: 0.12445 - val_acc: 0.9649 -- iter: 180/180
--
Training Step: 109  | total loss: [1m[32m0.20893[0m[0m | time: 0.634s
[2K
| Adam | epoch: 019 | loss: 0.20893 - acc: 0.9273 -- iter: 032/180
[A[ATraining Step: 110  | total loss: [1m[32m0.19690[0m[0m | time: 1.232s
[2K
| Adam | epoch: 019 | loss: 0.19690 - acc: 0.9345 -- iter: 064/180
[A[ATraining Step: 111  | total loss: [1m[32m0.19552[0m[0m | time: 1.627s
[2K
| Adam | epoch: 019 | loss: 0.19552 - acc: 0.9380 -- iter: 096/180
[A[ATraining Step: 112  | total loss: [1m[32m0.17845[0m[0m | time: 2.010s
[2K
| Adam | epoch: 019 | loss: 0.17845 - acc: 0.9442 -- iter: 128/180
[A[ATraining Step: 113  | total loss: [1m[32m0.16268[0m[0m | time: 2.626s
[2K
| Adam | epoch: 019 | loss: 0.16268 - acc: 0.9497 -- iter: 160/180
[A[ATraining Step: 114  | total loss: [1m[32m0.15306[0m[0m | time: 4.224s
[2K
| Adam | epoch: 019 | loss: 0.15306 - acc: 0.9548 | val_loss: 0.09103 - val_acc: 0.9649 -- iter: 180/180
--
Training Step: 115  | total loss: [1m[32m0.15865[0m[0m | time: 0.605s
[2K
| Adam | epoch: 020 | loss: 0.15865 - acc: 0.9530 -- iter: 032/180
[A[ATraining Step: 116  | total loss: [1m[32m0.14563[0m[0m | time: 1.212s
[2K
| Adam | epoch: 020 | loss: 0.14563 - acc: 0.9577 -- iter: 064/180
[A[ATraining Step: 117  | total loss: [1m[32m0.14589[0m[0m | time: 1.815s
[2K
| Adam | epoch: 020 | loss: 0.14589 - acc: 0.9588 -- iter: 096/180
[A[ATraining Step: 118  | total loss: [1m[32m0.13391[0m[0m | time: 2.197s
[2K
| Adam | epoch: 020 | loss: 0.13391 - acc: 0.9630 -- iter: 128/180
[A[ATraining Step: 119  | total loss: [1m[32m0.12170[0m[0m | time: 2.582s
[2K
| Adam | epoch: 020 | loss: 0.12170 - acc: 0.9667 -- iter: 160/180
[A[ATraining Step: 120  | total loss: [1m[32m0.11067[0m[0m | time: 4.192s
[2K
| Adam | epoch: 020 | loss: 0.11067 - acc: 0.9700 | val_loss: 0.09899 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 121  | total loss: [1m[32m0.10412[0m[0m | time: 0.623s
[2K
| Adam | epoch: 021 | loss: 0.10412 - acc: 0.9730 -- iter: 032/180
[A[ATraining Step: 122  | total loss: [1m[32m0.11281[0m[0m | time: 1.228s
[2K
| Adam | epoch: 021 | loss: 0.11281 - acc: 0.9726 -- iter: 064/180
[A[ATraining Step: 123  | total loss: [1m[32m0.11193[0m[0m | time: 1.829s
[2K
| Adam | epoch: 021 | loss: 0.11193 - acc: 0.9722 -- iter: 096/180
[A[ATraining Step: 124  | total loss: [1m[32m0.10365[0m[0m | time: 2.430s
[2K
| Adam | epoch: 021 | loss: 0.10365 - acc: 0.9750 -- iter: 128/180
[A[ATraining Step: 125  | total loss: [1m[32m0.09826[0m[0m | time: 2.815s
[2K
| Adam | epoch: 021 | loss: 0.09826 - acc: 0.9775 -- iter: 160/180
[A[ATraining Step: 126  | total loss: [1m[32m0.08961[0m[0m | time: 4.202s
[2K
| Adam | epoch: 021 | loss: 0.08961 - acc: 0.9797 | val_loss: 0.09358 - val_acc: 0.9649 -- iter: 180/180
--
Training Step: 127  | total loss: [1m[32m0.08177[0m[0m | time: 0.602s
[2K
| Adam | epoch: 022 | loss: 0.08177 - acc: 0.9818 -- iter: 032/180
[A[ATraining Step: 128  | total loss: [1m[32m0.07740[0m[0m | time: 1.220s
[2K
| Adam | epoch: 022 | loss: 0.07740 - acc: 0.9836 -- iter: 064/180
[A[ATraining Step: 129  | total loss: [1m[32m0.08684[0m[0m | time: 1.838s
[2K
| Adam | epoch: 022 | loss: 0.08684 - acc: 0.9821 -- iter: 096/180
[A[ATraining Step: 130  | total loss: [1m[32m0.07935[0m[0m | time: 2.451s
[2K
| Adam | epoch: 022 | loss: 0.07935 - acc: 0.9839 -- iter: 128/180
[A[ATraining Step: 131  | total loss: [1m[32m0.07738[0m[0m | time: 3.056s
[2K
| Adam | epoch: 022 | loss: 0.07738 - acc: 0.9824 -- iter: 160/180
[A[ATraining Step: 132  | total loss: [1m[32m0.07178[0m[0m | time: 4.452s
[2K
| Adam | epoch: 022 | loss: 0.07178 - acc: 0.9841 | val_loss: 0.10873 - val_acc: 0.9474 -- iter: 180/180
--
Training Step: 133  | total loss: [1m[32m0.07018[0m[0m | time: 0.406s
[2K
| Adam | epoch: 023 | loss: 0.07018 - acc: 0.9857 -- iter: 032/180
[A[ATraining Step: 134  | total loss: [1m[32m0.06648[0m[0m | time: 1.017s
[2K
| Adam | epoch: 023 | loss: 0.06648 - acc: 0.9871 -- iter: 064/180
[A[ATraining Step: 135  | total loss: [1m[32m0.06228[0m[0m | time: 1.643s
[2K
| Adam | epoch: 023 | loss: 0.06228 - acc: 0.9884 -- iter: 096/180
[A[ATraining Step: 136  | total loss: [1m[32m0.05956[0m[0m | time: 2.257s
[2K
| Adam | epoch: 023 | loss: 0.05956 - acc: 0.9865 -- iter: 128/180
[A[ATraining Step: 137  | total loss: [1m[32m0.05768[0m[0m | time: 2.866s
[2K
| Adam | epoch: 023 | loss: 0.05768 - acc: 0.9847 -- iter: 160/180
[A[ATraining Step: 138  | total loss: [1m[32m0.05318[0m[0m | time: 4.482s
[2K
| Adam | epoch: 023 | loss: 0.05318 - acc: 0.9862 | val_loss: 0.08059 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 139  | total loss: [1m[32m0.04865[0m[0m | time: 0.396s
[2K
| Adam | epoch: 024 | loss: 0.04865 - acc: 0.9876 -- iter: 032/180
[A[ATraining Step: 140  | total loss: [1m[32m0.04455[0m[0m | time: 0.785s
[2K
| Adam | epoch: 024 | loss: 0.04455 - acc: 0.9888 -- iter: 064/180
[A[ATraining Step: 141  | total loss: [1m[32m0.04110[0m[0m | time: 1.384s
[2K
| Adam | epoch: 024 | loss: 0.04110 - acc: 0.9900 -- iter: 096/180
[A[ATraining Step: 142  | total loss: [1m[32m0.03823[0m[0m | time: 2.019s
[2K
| Adam | epoch: 024 | loss: 0.03823 - acc: 0.9910 -- iter: 128/180
[A[ATraining Step: 143  | total loss: [1m[32m0.06877[0m[0m | time: 2.618s
[2K
| Adam | epoch: 024 | loss: 0.06877 - acc: 0.9856 -- iter: 160/180
[A[ATraining Step: 144  | total loss: [1m[32m0.06238[0m[0m | time: 4.232s
[2K
| Adam | epoch: 024 | loss: 0.06238 - acc: 0.9871 | val_loss: 0.08035 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 145  | total loss: [1m[32m0.05666[0m[0m | time: 0.615s
[2K
| Adam | epoch: 025 | loss: 0.05666 - acc: 0.9883 -- iter: 032/180
[A[ATraining Step: 146  | total loss: [1m[32m0.05234[0m[0m | time: 1.017s
[2K
| Adam | epoch: 025 | loss: 0.05234 - acc: 0.9895 -- iter: 064/180
[A[ATraining Step: 147  | total loss: [1m[32m0.04912[0m[0m | time: 1.402s
[2K
| Adam | epoch: 025 | loss: 0.04912 - acc: 0.9906 -- iter: 096/180
[A[ATraining Step: 148  | total loss: [1m[32m0.04540[0m[0m | time: 2.017s
[2K
| Adam | epoch: 025 | loss: 0.04540 - acc: 0.9915 -- iter: 128/180
[A[ATraining Step: 149  | total loss: [1m[32m0.04203[0m[0m | time: 2.623s
[2K
| Adam | epoch: 025 | loss: 0.04203 - acc: 0.9924 -- iter: 160/180
[A[ATraining Step: 150  | total loss: [1m[32m0.05171[0m[0m | time: 4.235s
[2K
| Adam | epoch: 025 | loss: 0.05171 - acc: 0.9900 | val_loss: 0.05370 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 151  | total loss: [1m[32m0.04745[0m[0m | time: 0.621s
[2K
| Adam | epoch: 026 | loss: 0.04745 - acc: 0.9910 -- iter: 032/180
[A[ATraining Step: 152  | total loss: [1m[32m0.04369[0m[0m | time: 1.215s
[2K
| Adam | epoch: 026 | loss: 0.04369 - acc: 0.9919 -- iter: 064/180
[A[ATraining Step: 153  | total loss: [1m[32m0.03962[0m[0m | time: 1.607s
[2K
| Adam | epoch: 026 | loss: 0.03962 - acc: 0.9927 -- iter: 096/180
[A[ATraining Step: 154  | total loss: [1m[32m0.03613[0m[0m | time: 1.997s
[2K
| Adam | epoch: 026 | loss: 0.03613 - acc: 0.9934 -- iter: 128/180
[A[ATraining Step: 155  | total loss: [1m[32m0.03305[0m[0m | time: 2.599s
[2K
| Adam | epoch: 026 | loss: 0.03305 - acc: 0.9941 -- iter: 160/180
[A[ATraining Step: 156  | total loss: [1m[32m0.03123[0m[0m | time: 4.229s
[2K
| Adam | epoch: 026 | loss: 0.03123 - acc: 0.9947 | val_loss: 0.04412 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 157  | total loss: [1m[32m0.05007[0m[0m | time: 0.616s
[2K
| Adam | epoch: 027 | loss: 0.05007 - acc: 0.9921 -- iter: 032/180
[A[ATraining Step: 158  | total loss: [1m[32m0.04838[0m[0m | time: 1.211s
[2K
| Adam | epoch: 027 | loss: 0.04838 - acc: 0.9898 -- iter: 064/180
[A[ATraining Step: 159  | total loss: [1m[32m0.04693[0m[0m | time: 1.822s
[2K
| Adam | epoch: 027 | loss: 0.04693 - acc: 0.9908 -- iter: 096/180
[A[ATraining Step: 160  | total loss: [1m[32m0.04489[0m[0m | time: 2.203s
[2K
| Adam | epoch: 027 | loss: 0.04489 - acc: 0.9917 -- iter: 128/180
[A[ATraining Step: 161  | total loss: [1m[32m0.04283[0m[0m | time: 2.584s
[2K
| Adam | epoch: 027 | loss: 0.04283 - acc: 0.9925 -- iter: 160/180
[A[ATraining Step: 162  | total loss: [1m[32m0.03902[0m[0m | time: 4.189s
[2K
| Adam | epoch: 027 | loss: 0.03902 - acc: 0.9933 | val_loss: 0.06401 - val_acc: 0.9825 -- iter: 180/180
--
Training Step: 163  | total loss: [1m[32m0.03541[0m[0m | time: 0.609s
[2K
| Adam | epoch: 028 | loss: 0.03541 - acc: 0.9940 -- iter: 032/180
[A[ATraining Step: 164  | total loss: [1m[32m0.05218[0m[0m | time: 1.218s
[2K
| Adam | epoch: 028 | loss: 0.05218 - acc: 0.9914 -- iter: 064/180
[A[ATraining Step: 165  | total loss: [1m[32m0.04728[0m[0m | time: 1.823s
[2K
| Adam | epoch: 028 | loss: 0.04728 - acc: 0.9923 -- iter: 096/180
[A[ATraining Step: 166  | total loss: [1m[32m0.05721[0m[0m | time: 2.439s
[2K
| Adam | epoch: 028 | loss: 0.05721 - acc: 0.9837 -- iter: 128/180
[A[ATraining Step: 167  | total loss: [1m[32m0.06386[0m[0m | time: 2.824s
[2K
| Adam | epoch: 028 | loss: 0.06386 - acc: 0.9822 -- iter: 160/180
[A[ATraining Step: 168  | total loss: [1m[32m0.05846[0m[0m | time: 4.218s
[2K
| Adam | epoch: 028 | loss: 0.05846 - acc: 0.9840 | val_loss: 0.20175 - val_acc: 0.9123 -- iter: 180/180
--
Training Step: 169  | total loss: [1m[32m0.05327[0m[0m | time: 0.614s
[2K
| Adam | epoch: 029 | loss: 0.05327 - acc: 0.9856 -- iter: 032/180
[A[ATraining Step: 170  | total loss: [1m[32m0.05172[0m[0m | time: 1.217s
[2K
| Adam | epoch: 029 | loss: 0.05172 - acc: 0.9870 -- iter: 064/180
[A[ATraining Step: 171  | total loss: [1m[32m0.08629[0m[0m | time: 1.830s
[2K
| Adam | epoch: 029 | loss: 0.08629 - acc: 0.9821 -- iter: 096/180
[A[ATraining Step: 172  | total loss: [1m[32m0.08712[0m[0m | time: 2.443s
[2K
| Adam | epoch: 029 | loss: 0.08712 - acc: 0.9807 -- iter: 128/180
[A[ATraining Step: 173  | total loss: [1m[32m0.08056[0m[0m | time: 3.045s
[2K
| Adam | epoch: 029 | loss: 0.08056 - acc: 0.9827 -- iter: 160/180
[A[ATraining Step: 174  | total loss: [1m[32m0.07383[0m[0m | time: 4.429s
[2K
| Adam | epoch: 029 | loss: 0.07383 - acc: 0.9844 | val_loss: 0.12718 - val_acc: 0.9474 -- iter: 180/180
--
Training Step: 175  | total loss: [1m[32m0.07031[0m[0m | time: 0.397s
[2K
| Adam | epoch: 030 | loss: 0.07031 - acc: 0.9860 -- iter: 032/180
[A[ATraining Step: 176  | total loss: [1m[32m0.06940[0m[0m | time: 0.997s
[2K
| Adam | epoch: 030 | loss: 0.06940 - acc: 0.9874 -- iter: 064/180
[A[ATraining Step: 177  | total loss: [1m[32m0.06391[0m[0m | time: 1.608s
[2K
| Adam | epoch: 030 | loss: 0.06391 - acc: 0.9886 -- iter: 096/180
[A[ATraining Step: 178  | total loss: [1m[32m0.05924[0m[0m | time: 2.217s
[2K
| Adam | epoch: 030 | loss: 0.05924 - acc: 0.9898 -- iter: 128/180
[A[ATraining Step: 179  | total loss: [1m[32m0.05486[0m[0m | time: 2.841s
[2K
| Adam | epoch: 030 | loss: 0.05486 - acc: 0.9908 -- iter: 160/180
[A[ATraining Step: 180  | total loss: [1m[32m0.05043[0m[0m | time: 4.447s
[2K
| Adam | epoch: 030 | loss: 0.05043 - acc: 0.9917 | val_loss: 0.04399 - val_acc: 0.9825 -- iter: 180/180
--
Validation AUC:1.0
Validation AUPRC:1.0
Test AUC:1.0
Test AUPRC:0.9999999999999998
BestTestF1Score	1.0	1.0	1.0	1.0	1.0	29	0	28	0	0.79
BestTestMCCScore	1.0	1.0	1.0	1.0	1.0	29	0	28	0	0.79
BestTestAccuracyScore	1.0	1.0	1.0	1.0	1.0	29	0	28	0	0.79
BestValidationF1Score	1.0	1.0	1.0	1.0	1.0	25	0	32	0	0.79
BestValidationMCC	1.0	1.0	1.0	1.0	1.0	25	0	32	0	0.79
BestValidationAccuracy	1.0	1.0	1.0	1.0	1.0	25	0	32	0	0.79
TestPredictions (Threshold:0.79)
CHEMBL78968,TN,INACT,0.03999999910593033	CHEMBL558,TN,INACT,0.019999999552965164	CHEMBL3639871,TP,ACT,0.9900000095367432	CHEMBL3355308,TN,INACT,0.009999999776482582	CHEMBL454015,TN,INACT,0.009999999776482582	CHEMBL400960,TN,INACT,0.03999999910593033	CHEMBL3688332,TP,ACT,1.0	CHEMBL3688268,TP,ACT,1.0	CHEMBL3688262,TP,ACT,1.0	CHEMBL2376854,TN,INACT,0.0	CHEMBL3688289,TP,ACT,1.0	CHEMBL3688308,TP,ACT,0.9900000095367432	CHEMBL3688299,TP,ACT,0.9900000095367432	CHEMBL3355303,TN,INACT,0.0	CHEMBL3688297,TP,ACT,0.9900000095367432	CHEMBL3688264,TP,ACT,0.9900000095367432	CHEMBL2385997,TN,INACT,0.009999999776482582	CHEMBL186366,TN,INACT,0.009999999776482582	CHEMBL27768,TN,INACT,0.6000000238418579	CHEMBL2348667,TP,ACT,0.8700000047683716	CHEMBL3688230,TP,ACT,0.9900000095367432	CHEMBL3688244,TP,ACT,0.9800000190734863	CHEMBL1277793,TN,INACT,0.009999999776482582	CHEMBL3359449,TN,INACT,0.0	CHEMBL3688286,TP,ACT,0.9900000095367432	CHEMBL99326,TN,INACT,0.029999999329447746	CHEMBL3688322,TP,ACT,0.9900000095367432	CHEMBL3688325,TP,ACT,0.9900000095367432	CHEMBL466201,TN,INACT,0.009999999776482582	CHEMBL3688277,TP,ACT,1.0	CHEMBL3688293,TP,ACT,1.0	CHEMBL3688259,TP,ACT,1.0	CHEMBL595187,TN,INACT,0.23000000417232513	CHEMBL3688261,TP,ACT,1.0	CHEMBL3688306,TP,ACT,0.9900000095367432	CHEMBL3110214,TN,INACT,0.029999999329447746	CHEMBL3688235,TP,ACT,0.9800000190734863	CHEMBL2385996,TN,INACT,0.029999999329447746	CHEMBL3092995,TN,INACT,0.019999999552965164	CHEMBL2087074,TN,INACT,0.10999999940395355	CHEMBL3688247,TP,ACT,1.0	CHEMBL3688266,TP,ACT,0.9900000095367432	CHEMBL3688327,TP,ACT,0.9900000095367432	CHEMBL3787319,TN,INACT,0.0	CHEMBL3688267,TP,ACT,1.0	CHEMBL558900,TN,INACT,0.0	CHEMBL3422797,TN,INACT,0.03999999910593033	CHEMBL304786,TN,INACT,0.029999999329447746	CHEMBL3688284,TP,ACT,0.9900000095367432	CHEMBL3688324,TP,ACT,1.0	CHEMBL1097701,TN,INACT,0.0	CHEMBL551067,TN,INACT,0.009999999776482582	CHEMBL2348672,TP,ACT,0.9900000095367432	CHEMBL3688285,TP,ACT,0.9900000095367432	CHEMBL3355287,TN,INACT,0.009999999776482582	CHEMBL525920,TN,INACT,0.029999999329447746	CHEMBL294199,TN,INACT,0.009999999776482582	

