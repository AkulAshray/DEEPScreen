ImageNetInceptionV2 CHEMBL340 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	253
Number of inactive compounds :	253
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL340_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL340_adam_0.0005_15_0.6/
---------------------------------
Training samples: 323
Validation samples: 102
--
Training Step: 1  | time: 38.357s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/323
[A[ATraining Step: 2  | total loss: [1m[32m0.65851[0m[0m | time: 47.772s
[2K
| Adam | epoch: 001 | loss: 0.65851 - acc: 0.5062 -- iter: 064/323
[A[ATraining Step: 3  | total loss: [1m[32m0.58939[0m[0m | time: 57.027s
[2K
| Adam | epoch: 001 | loss: 0.58939 - acc: 0.6290 -- iter: 096/323
[A[ATraining Step: 4  | total loss: [1m[32m0.50805[0m[0m | time: 66.384s
[2K
| Adam | epoch: 001 | loss: 0.50805 - acc: 0.7432 -- iter: 128/323
[A[ATraining Step: 5  | total loss: [1m[32m0.55418[0m[0m | time: 75.772s
[2K
| Adam | epoch: 001 | loss: 0.55418 - acc: 0.7263 -- iter: 160/323
[A[ATraining Step: 6  | total loss: [1m[32m0.53217[0m[0m | time: 85.257s
[2K
| Adam | epoch: 001 | loss: 0.53217 - acc: 0.7817 -- iter: 192/323
[A[ATraining Step: 7  | total loss: [1m[32m0.55417[0m[0m | time: 95.144s
[2K
| Adam | epoch: 001 | loss: 0.55417 - acc: 0.8002 -- iter: 224/323
[A[ATraining Step: 8  | total loss: [1m[32m0.54398[0m[0m | time: 104.716s
[2K
| Adam | epoch: 001 | loss: 0.54398 - acc: 0.8071 -- iter: 256/323
[A[ATraining Step: 9  | total loss: [1m[32m0.49094[0m[0m | time: 114.972s
[2K
| Adam | epoch: 001 | loss: 0.49094 - acc: 0.7769 -- iter: 288/323
[A[ATraining Step: 10  | total loss: [1m[32m0.50490[0m[0m | time: 125.405s
[2K
| Adam | epoch: 001 | loss: 0.50490 - acc: 0.7634 -- iter: 320/323
[A[ATraining Step: 11  | total loss: [1m[32m0.36634[0m[0m | time: 138.182s
[2K
| Adam | epoch: 001 | loss: 0.36634 - acc: 0.8607 | val_loss: 1.97071 - val_acc: 0.5000 -- iter: 323/323
--
Training Step: 12  | total loss: [1m[32m1.59123[0m[0m | time: 1.916s
[2K
| Adam | epoch: 002 | loss: 1.59123 - acc: 0.6234 -- iter: 032/323
[A[ATraining Step: 13  | total loss: [1m[32m1.58128[0m[0m | time: 12.634s
[2K
| Adam | epoch: 002 | loss: 1.58128 - acc: 0.4991 -- iter: 064/323
[A[ATraining Step: 14  | total loss: [1m[32m1.18061[0m[0m | time: 22.903s
[2K
| Adam | epoch: 002 | loss: 1.18061 - acc: 0.5762 -- iter: 096/323
[A[ATraining Step: 15  | total loss: [1m[32m0.90207[0m[0m | time: 33.598s
[2K
| Adam | epoch: 002 | loss: 0.90207 - acc: 0.6809 -- iter: 128/323
[A[ATraining Step: 16  | total loss: [1m[32m0.67795[0m[0m | time: 43.880s
[2K
| Adam | epoch: 002 | loss: 0.67795 - acc: 0.7654 -- iter: 160/323
[A[ATraining Step: 17  | total loss: [1m[32m0.55900[0m[0m | time: 54.209s
[2K
| Adam | epoch: 002 | loss: 0.55900 - acc: 0.8048 -- iter: 192/323
[A[ATraining Step: 18  | total loss: [1m[32m0.51736[0m[0m | time: 64.687s
[2K
| Adam | epoch: 002 | loss: 0.51736 - acc: 0.8075 -- iter: 224/323
[A[ATraining Step: 19  | total loss: [1m[32m0.43657[0m[0m | time: 75.103s
[2K
| Adam | epoch: 002 | loss: 0.43657 - acc: 0.8300 -- iter: 256/323
[A[ATraining Step: 20  | total loss: [1m[32m0.41220[0m[0m | time: 90.166s
[2K
| Adam | epoch: 002 | loss: 0.41220 - acc: 0.8545 -- iter: 288/323
[A[ATraining Step: 21  | total loss: [1m[32m0.37760[0m[0m | time: 103.557s
[2K
| Adam | epoch: 002 | loss: 0.37760 - acc: 0.8706 -- iter: 320/323
[A[ATraining Step: 22  | total loss: [1m[32m0.33824[0m[0m | time: 121.128s
[2K
| Adam | epoch: 002 | loss: 0.33824 - acc: 0.8813 | val_loss: 0.72917 - val_acc: 0.5000 -- iter: 323/323
--
Training Step: 23  | total loss: [1m[32m0.27400[0m[0m | time: 1.877s
[2K
| Adam | epoch: 003 | loss: 0.27400 - acc: 0.9067 -- iter: 032/323
[A[ATraining Step: 24  | total loss: [1m[32m0.40976[0m[0m | time: 3.752s
[2K
| Adam | epoch: 003 | loss: 0.40976 - acc: 0.8392 -- iter: 064/323
[A[ATraining Step: 25  | total loss: [1m[32m0.32372[0m[0m | time: 28.526s
[2K
| Adam | epoch: 003 | loss: 0.32372 - acc: 0.8830 -- iter: 096/323
[A[ATraining Step: 26  | total loss: [1m[32m0.33798[0m[0m | time: 53.111s
[2K
| Adam | epoch: 003 | loss: 0.33798 - acc: 0.8644 -- iter: 128/323
[A[ATraining Step: 27  | total loss: [1m[32m0.31615[0m[0m | time: 63.418s
[2K
| Adam | epoch: 003 | loss: 0.31615 - acc: 0.8751 -- iter: 160/323
[A[ATraining Step: 28  | total loss: [1m[32m0.26783[0m[0m | time: 73.878s
[2K
| Adam | epoch: 003 | loss: 0.26783 - acc: 0.8985 -- iter: 192/323
[A[ATraining Step: 29  | total loss: [1m[32m0.23808[0m[0m | time: 85.017s
[2K
| Adam | epoch: 003 | loss: 0.23808 - acc: 0.9080 -- iter: 224/323
[A[ATraining Step: 30  | total loss: [1m[32m0.21808[0m[0m | time: 99.802s
[2K
| Adam | epoch: 003 | loss: 0.21808 - acc: 0.9224 -- iter: 256/323
[A[ATraining Step: 31  | total loss: [1m[32m0.22299[0m[0m | time: 120.653s
[2K
| Adam | epoch: 003 | loss: 0.22299 - acc: 0.9187 -- iter: 288/323
[A[ATraining Step: 32  | total loss: [1m[32m0.22707[0m[0m | time: 142.438s
[2K
| Adam | epoch: 003 | loss: 0.22707 - acc: 0.9229 -- iter: 320/323
[A[ATraining Step: 33  | total loss: [1m[32m0.26960[0m[0m | time: 157.974s
[2K
| Adam | epoch: 003 | loss: 0.26960 - acc: 0.9193 | val_loss: 3.94731 - val_acc: 0.5000 -- iter: 323/323
--
Training Step: 34  | total loss: [1m[32m0.25264[0m[0m | time: 12.062s
[2K
| Adam | epoch: 004 | loss: 0.25264 - acc: 0.9165 -- iter: 032/323
[A[ATraining Step: 35  | total loss: [1m[32m0.22508[0m[0m | time: 13.925s
[2K
| Adam | epoch: 004 | loss: 0.22508 - acc: 0.9274 -- iter: 064/323
[A[ATraining Step: 36  | total loss: [1m[32m0.46268[0m[0m | time: 15.710s
[2K
| Adam | epoch: 004 | loss: 0.46268 - acc: 0.8059 -- iter: 096/323
[A[ATraining Step: 37  | total loss: [1m[32m0.55406[0m[0m | time: 26.054s
[2K
| Adam | epoch: 004 | loss: 0.55406 - acc: 0.7780 -- iter: 128/323
[A[ATraining Step: 38  | total loss: [1m[32m0.52416[0m[0m | time: 42.369s
[2K
| Adam | epoch: 004 | loss: 0.52416 - acc: 0.7909 -- iter: 160/323
[A[ATraining Step: 39  | total loss: [1m[32m0.45951[0m[0m | time: 52.664s
[2K
| Adam | epoch: 004 | loss: 0.45951 - acc: 0.8130 -- iter: 192/323
[A[ATraining Step: 40  | total loss: [1m[32m0.41855[0m[0m | time: 62.773s
[2K
| Adam | epoch: 004 | loss: 0.41855 - acc: 0.8305 -- iter: 224/323
[A[ATraining Step: 41  | total loss: [1m[32m0.36205[0m[0m | time: 73.329s
[2K
| Adam | epoch: 004 | loss: 0.36205 - acc: 0.8559 -- iter: 256/323
[A[ATraining Step: 42  | total loss: [1m[32m0.33275[0m[0m | time: 83.425s
[2K
| Adam | epoch: 004 | loss: 0.33275 - acc: 0.8762 -- iter: 288/323
[A[ATraining Step: 43  | total loss: [1m[32m0.29631[0m[0m | time: 93.692s
[2K
| Adam | epoch: 004 | loss: 0.29631 - acc: 0.8925 -- iter: 320/323
[A[ATraining Step: 44  | total loss: [1m[32m0.26807[0m[0m | time: 109.439s
[2K
| Adam | epoch: 004 | loss: 0.26807 - acc: 0.9057 | val_loss: 1.98916 - val_acc: 0.5392 -- iter: 323/323
--
Training Step: 45  | total loss: [1m[32m0.23552[0m[0m | time: 10.093s
[2K
| Adam | epoch: 005 | loss: 0.23552 - acc: 0.9164 -- iter: 032/323
[A[ATraining Step: 46  | total loss: [1m[32m0.22142[0m[0m | time: 20.197s
[2K
| Adam | epoch: 005 | loss: 0.22142 - acc: 0.9199 -- iter: 064/323
[A[ATraining Step: 47  | total loss: [1m[32m0.19675[0m[0m | time: 22.016s
[2K
| Adam | epoch: 005 | loss: 0.19675 - acc: 0.9279 -- iter: 096/323
[A[ATraining Step: 48  | total loss: [1m[32m0.36273[0m[0m | time: 23.815s
[2K
| Adam | epoch: 005 | loss: 0.36273 - acc: 0.8859 -- iter: 128/323
[A[ATraining Step: 49  | total loss: [1m[32m0.56542[0m[0m | time: 33.839s
[2K
| Adam | epoch: 005 | loss: 0.56542 - acc: 0.7987 -- iter: 160/323
[A[ATraining Step: 50  | total loss: [1m[32m0.52503[0m[0m | time: 43.963s
[2K
| Adam | epoch: 005 | loss: 0.52503 - acc: 0.8057 -- iter: 192/323
[A[ATraining Step: 51  | total loss: [1m[32m0.46433[0m[0m | time: 53.775s
[2K
| Adam | epoch: 005 | loss: 0.46433 - acc: 0.8306 -- iter: 224/323
[A[ATraining Step: 52  | total loss: [1m[32m0.40404[0m[0m | time: 63.671s
[2K
| Adam | epoch: 005 | loss: 0.40404 - acc: 0.8513 -- iter: 256/323
[A[ATraining Step: 53  | total loss: [1m[32m0.34627[0m[0m | time: 73.789s
[2K
| Adam | epoch: 005 | loss: 0.34627 - acc: 0.8732 -- iter: 288/323
[A[ATraining Step: 54  | total loss: [1m[32m0.30054[0m[0m | time: 83.870s
[2K
| Adam | epoch: 005 | loss: 0.30054 - acc: 0.8916 -- iter: 320/323
[A[ATraining Step: 55  | total loss: [1m[32m0.26257[0m[0m | time: 99.812s
[2K
| Adam | epoch: 005 | loss: 0.26257 - acc: 0.9071 | val_loss: 3.15204 - val_acc: 0.5098 -- iter: 323/323
--
Training Step: 56  | total loss: [1m[32m0.24725[0m[0m | time: 10.114s
[2K
| Adam | epoch: 006 | loss: 0.24725 - acc: 0.9114 -- iter: 032/323
[A[ATraining Step: 57  | total loss: [1m[32m0.22539[0m[0m | time: 20.030s
[2K
| Adam | epoch: 006 | loss: 0.22539 - acc: 0.9193 -- iter: 064/323
[A[ATraining Step: 58  | total loss: [1m[32m0.20183[0m[0m | time: 30.119s
[2K
| Adam | epoch: 006 | loss: 0.20183 - acc: 0.9303 -- iter: 096/323
[A[ATraining Step: 59  | total loss: [1m[32m0.17999[0m[0m | time: 31.848s
[2K
| Adam | epoch: 006 | loss: 0.17999 - acc: 0.9397 -- iter: 128/323
[A[ATraining Step: 60  | total loss: [1m[32m0.32607[0m[0m | time: 33.642s
[2K
| Adam | epoch: 006 | loss: 0.32607 - acc: 0.8153 -- iter: 160/323
[A[ATraining Step: 61  | total loss: [1m[32m0.46465[0m[0m | time: 50.714s
[2K
| Adam | epoch: 006 | loss: 0.46465 - acc: 0.7959 -- iter: 192/323
[A[ATraining Step: 62  | total loss: [1m[32m0.42261[0m[0m | time: 60.956s
[2K
| Adam | epoch: 006 | loss: 0.42261 - acc: 0.8181 -- iter: 224/323
[A[ATraining Step: 63  | total loss: [1m[32m0.38585[0m[0m | time: 71.186s
[2K
| Adam | epoch: 006 | loss: 0.38585 - acc: 0.8293 -- iter: 256/323
[A[ATraining Step: 64  | total loss: [1m[32m0.36794[0m[0m | time: 81.236s
[2K
| Adam | epoch: 006 | loss: 0.36794 - acc: 0.8389 -- iter: 288/323
[A[ATraining Step: 65  | total loss: [1m[32m0.32547[0m[0m | time: 91.338s
[2K
| Adam | epoch: 006 | loss: 0.32547 - acc: 0.8588 -- iter: 320/323
[A[ATraining Step: 66  | total loss: [1m[32m0.29268[0m[0m | time: 106.663s
[2K
| Adam | epoch: 006 | loss: 0.29268 - acc: 0.8760 | val_loss: 1.47330 - val_acc: 0.6373 -- iter: 323/323
--
Training Step: 67  | total loss: [1m[32m0.26062[0m[0m | time: 9.009s
[2K
| Adam | epoch: 007 | loss: 0.26062 - acc: 0.8908 -- iter: 032/323
[A[ATraining Step: 68  | total loss: [1m[32m0.24825[0m[0m | time: 18.043s
[2K
| Adam | epoch: 007 | loss: 0.24825 - acc: 0.8964 -- iter: 064/323
[A[ATraining Step: 69  | total loss: [1m[32m0.24830[0m[0m | time: 27.107s
[2K
| Adam | epoch: 007 | loss: 0.24830 - acc: 0.9012 -- iter: 096/323
[A[ATraining Step: 70  | total loss: [1m[32m0.24473[0m[0m | time: 36.305s
[2K
| Adam | epoch: 007 | loss: 0.24473 - acc: 0.9018 -- iter: 128/323
[A[ATraining Step: 71  | total loss: [1m[32m0.24234[0m[0m | time: 37.836s
[2K
| Adam | epoch: 007 | loss: 0.24234 - acc: 0.9094 -- iter: 160/323
[A[ATraining Step: 72  | total loss: [1m[32m0.22080[0m[0m | time: 39.413s
[2K
| Adam | epoch: 007 | loss: 0.22080 - acc: 0.9196 -- iter: 192/323
[A[ATraining Step: 73  | total loss: [1m[32m0.19687[0m[0m | time: 48.506s
[2K
| Adam | epoch: 007 | loss: 0.19687 - acc: 0.9285 -- iter: 224/323
[A[ATraining Step: 74  | total loss: [1m[32m0.18788[0m[0m | time: 57.602s
[2K
| Adam | epoch: 007 | loss: 0.18788 - acc: 0.9295 -- iter: 256/323
[A[ATraining Step: 75  | total loss: [1m[32m0.17666[0m[0m | time: 66.954s
[2K
| Adam | epoch: 007 | loss: 0.17666 - acc: 0.9372 -- iter: 288/323
[A[ATraining Step: 76  | total loss: [1m[32m0.19153[0m[0m | time: 76.189s
[2K
| Adam | epoch: 007 | loss: 0.19153 - acc: 0.9372 -- iter: 320/323
[A[ATraining Step: 77  | total loss: [1m[32m0.18325[0m[0m | time: 89.812s
[2K
| Adam | epoch: 007 | loss: 0.18325 - acc: 0.9405 | val_loss: 2.74646 - val_acc: 0.5000 -- iter: 323/323
--
Training Step: 78  | total loss: [1m[32m0.17405[0m[0m | time: 9.167s
[2K
| Adam | epoch: 008 | loss: 0.17405 - acc: 0.9435 -- iter: 032/323
[A[ATraining Step: 79  | total loss: [1m[32m0.15965[0m[0m | time: 18.444s
[2K
| Adam | epoch: 008 | loss: 0.15965 - acc: 0.9493 -- iter: 064/323
[A[ATraining Step: 80  | total loss: [1m[32m0.15417[0m[0m | time: 27.545s
[2K
| Adam | epoch: 008 | loss: 0.15417 - acc: 0.9513 -- iter: 096/323
[A[ATraining Step: 81  | total loss: [1m[32m0.15110[0m[0m | time: 36.818s
[2K
| Adam | epoch: 008 | loss: 0.15110 - acc: 0.9499 -- iter: 128/323
[A[ATraining Step: 82  | total loss: [1m[32m0.14207[0m[0m | time: 46.182s
[2K
| Adam | epoch: 008 | loss: 0.14207 - acc: 0.9518 -- iter: 160/323
[A[ATraining Step: 83  | total loss: [1m[32m0.14473[0m[0m | time: 47.784s
[2K
| Adam | epoch: 008 | loss: 0.14473 - acc: 0.9472 -- iter: 192/323
[A[ATraining Step: 84  | total loss: [1m[32m0.14422[0m[0m | time: 49.336s
[2K
| Adam | epoch: 008 | loss: 0.14422 - acc: 0.9525 -- iter: 224/323
[A[ATraining Step: 85  | total loss: [1m[32m0.13262[0m[0m | time: 58.831s
[2K
| Adam | epoch: 008 | loss: 0.13262 - acc: 0.9573 -- iter: 256/323
[A[ATraining Step: 86  | total loss: [1m[32m0.12237[0m[0m | time: 68.420s
[2K
| Adam | epoch: 008 | loss: 0.12237 - acc: 0.9615 -- iter: 288/323
[A[ATraining Step: 87  | total loss: [1m[32m0.13259[0m[0m | time: 78.138s
[2K
| Adam | epoch: 008 | loss: 0.13259 - acc: 0.9591 -- iter: 320/323
[A[ATraining Step: 88  | total loss: [1m[32m0.14084[0m[0m | time: 92.311s
[2K
| Adam | epoch: 008 | loss: 0.14084 - acc: 0.9601 | val_loss: 2.19858 - val_acc: 0.5196 -- iter: 323/323
--
Training Step: 89  | total loss: [1m[32m0.13615[0m[0m | time: 9.665s
[2K
| Adam | epoch: 009 | loss: 0.13615 - acc: 0.9610 -- iter: 032/323
[A[ATraining Step: 90  | total loss: [1m[32m0.14009[0m[0m | time: 19.448s
[2K
| Adam | epoch: 009 | loss: 0.14009 - acc: 0.9555 -- iter: 064/323
[A[ATraining Step: 91  | total loss: [1m[32m0.12841[0m[0m | time: 29.223s
[2K
| Adam | epoch: 009 | loss: 0.12841 - acc: 0.9599 -- iter: 096/323
[A[ATraining Step: 92  | total loss: [1m[32m0.12160[0m[0m | time: 39.334s
[2K
| Adam | epoch: 009 | loss: 0.12160 - acc: 0.9639 -- iter: 128/323
[A[ATraining Step: 93  | total loss: [1m[32m0.12423[0m[0m | time: 49.410s
[2K
| Adam | epoch: 009 | loss: 0.12423 - acc: 0.9644 -- iter: 160/323
[A[ATraining Step: 94  | total loss: [1m[32m0.11389[0m[0m | time: 59.019s
[2K
| Adam | epoch: 009 | loss: 0.11389 - acc: 0.9680 -- iter: 192/323
[A[ATraining Step: 95  | total loss: [1m[32m0.10387[0m[0m | time: 60.679s
[2K
| Adam | epoch: 009 | loss: 0.10387 - acc: 0.9712 -- iter: 224/323
[A[ATraining Step: 96  | total loss: [1m[32m0.09433[0m[0m | time: 62.407s
[2K
| Adam | epoch: 009 | loss: 0.09433 - acc: 0.9741 -- iter: 256/323
[A[ATraining Step: 97  | total loss: [1m[32m0.08550[0m[0m | time: 72.273s
[2K
| Adam | epoch: 009 | loss: 0.08550 - acc: 0.9767 -- iter: 288/323
[A[ATraining Step: 98  | total loss: [1m[32m0.08490[0m[0m | time: 82.213s
[2K
| Adam | epoch: 009 | loss: 0.08490 - acc: 0.9727 -- iter: 320/323
[A[ATraining Step: 99  | total loss: [1m[32m0.07672[0m[0m | time: 97.361s
[2K
| Adam | epoch: 009 | loss: 0.07672 - acc: 0.9755 | val_loss: 1.19478 - val_acc: 0.7157 -- iter: 323/323
--
Training Step: 100  | total loss: [1m[32m0.07019[0m[0m | time: 10.153s
[2K
| Adam | epoch: 010 | loss: 0.07019 - acc: 0.9779 -- iter: 032/323
[A[ATraining Step: 101  | total loss: [1m[32m0.06454[0m[0m | time: 19.818s
[2K
| Adam | epoch: 010 | loss: 0.06454 - acc: 0.9801 -- iter: 064/323
[A[ATraining Step: 102  | total loss: [1m[32m0.06041[0m[0m | time: 29.826s
[2K
| Adam | epoch: 010 | loss: 0.06041 - acc: 0.9821 -- iter: 096/323
[A[ATraining Step: 103  | total loss: [1m[32m0.05659[0m[0m | time: 39.613s
[2K
| Adam | epoch: 010 | loss: 0.05659 - acc: 0.9839 -- iter: 128/323
[A[ATraining Step: 104  | total loss: [1m[32m0.05254[0m[0m | time: 49.358s
[2K
| Adam | epoch: 010 | loss: 0.05254 - acc: 0.9855 -- iter: 160/323
[A[ATraining Step: 105  | total loss: [1m[32m0.05342[0m[0m | time: 59.339s
[2K
| Adam | epoch: 010 | loss: 0.05342 - acc: 0.9838 -- iter: 192/323
[A[ATraining Step: 106  | total loss: [1m[32m0.06130[0m[0m | time: 69.144s
[2K
| Adam | epoch: 010 | loss: 0.06130 - acc: 0.9823 -- iter: 224/323
[A[ATraining Step: 107  | total loss: [1m[32m0.05572[0m[0m | time: 70.853s
[2K
| Adam | epoch: 010 | loss: 0.05572 - acc: 0.9841 -- iter: 256/323
[A[ATraining Step: 108  | total loss: [1m[32m0.05172[0m[0m | time: 72.588s
[2K
| Adam | epoch: 010 | loss: 0.05172 - acc: 0.9857 -- iter: 288/323
[A[ATraining Step: 109  | total loss: [1m[32m0.04689[0m[0m | time: 82.501s
[2K
| Adam | epoch: 010 | loss: 0.04689 - acc: 0.9871 -- iter: 320/323
[A[ATraining Step: 110  | total loss: [1m[32m0.04537[0m[0m | time: 97.867s
[2K
| Adam | epoch: 010 | loss: 0.04537 - acc: 0.9884 | val_loss: 3.20959 - val_acc: 0.5000 -- iter: 323/323
--
Training Step: 111  | total loss: [1m[32m0.04199[0m[0m | time: 9.931s
[2K
| Adam | epoch: 011 | loss: 0.04199 - acc: 0.9896 -- iter: 032/323
[A[ATraining Step: 112  | total loss: [1m[32m0.06285[0m[0m | time: 19.912s
[2K
| Adam | epoch: 011 | loss: 0.06285 - acc: 0.9875 -- iter: 064/323
[A[ATraining Step: 113  | total loss: [1m[32m0.06630[0m[0m | time: 29.847s
[2K
| Adam | epoch: 011 | loss: 0.06630 - acc: 0.9856 -- iter: 096/323
[A[ATraining Step: 114  | total loss: [1m[32m0.06249[0m[0m | time: 39.918s
[2K
| Adam | epoch: 011 | loss: 0.06249 - acc: 0.9871 -- iter: 128/323
[A[ATraining Step: 115  | total loss: [1m[32m0.05778[0m[0m | time: 49.810s
[2K
| Adam | epoch: 011 | loss: 0.05778 - acc: 0.9883 -- iter: 160/323
[A[ATraining Step: 116  | total loss: [1m[32m0.05246[0m[0m | time: 59.779s
[2K
| Adam | epoch: 011 | loss: 0.05246 - acc: 0.9895 -- iter: 192/323
[A[ATraining Step: 117  | total loss: [1m[32m0.04797[0m[0m | time: 69.638s
[2K
| Adam | epoch: 011 | loss: 0.04797 - acc: 0.9906 -- iter: 224/323
[A[ATraining Step: 118  | total loss: [1m[32m0.04509[0m[0m | time: 79.416s
[2K
| Adam | epoch: 011 | loss: 0.04509 - acc: 0.9915 -- iter: 256/323
[A[ATraining Step: 119  | total loss: [1m[32m0.04821[0m[0m | time: 81.121s
[2K
| Adam | epoch: 011 | loss: 0.04821 - acc: 0.9892 -- iter: 288/323
[A[ATraining Step: 120  | total loss: [1m[32m0.05392[0m[0m | time: 82.813s
[2K
| Adam | epoch: 011 | loss: 0.05392 - acc: 0.9903 -- iter: 320/323
[A[ATraining Step: 121  | total loss: [1m[32m0.04904[0m[0m | time: 97.674s
[2K
| Adam | epoch: 011 | loss: 0.04904 - acc: 0.9913 | val_loss: 0.53229 - val_acc: 0.8627 -- iter: 323/323
--
Training Step: 122  | total loss: [1m[32m0.04736[0m[0m | time: 9.885s
[2K
| Adam | epoch: 012 | loss: 0.04736 - acc: 0.9890 -- iter: 032/323
[A[ATraining Step: 123  | total loss: [1m[32m0.04524[0m[0m | time: 19.732s
[2K
| Adam | epoch: 012 | loss: 0.04524 - acc: 0.9901 -- iter: 064/323
[A[ATraining Step: 124  | total loss: [1m[32m0.06476[0m[0m | time: 29.658s
[2K
| Adam | epoch: 012 | loss: 0.06476 - acc: 0.9880 -- iter: 096/323
[A[ATraining Step: 125  | total loss: [1m[32m0.05876[0m[0m | time: 39.691s
[2K
| Adam | epoch: 012 | loss: 0.05876 - acc: 0.9892 -- iter: 128/323
[A[ATraining Step: 126  | total loss: [1m[32m0.06575[0m[0m | time: 49.276s
[2K
| Adam | epoch: 012 | loss: 0.06575 - acc: 0.9840 -- iter: 160/323
[A[ATraining Step: 127  | total loss: [1m[32m0.06481[0m[0m | time: 59.037s
[2K
| Adam | epoch: 012 | loss: 0.06481 - acc: 0.9825 -- iter: 192/323
[A[ATraining Step: 128  | total loss: [1m[32m0.06700[0m[0m | time: 68.778s
[2K
| Adam | epoch: 012 | loss: 0.06700 - acc: 0.9842 -- iter: 224/323
[A[ATraining Step: 129  | total loss: [1m[32m0.07453[0m[0m | time: 78.560s
[2K
| Adam | epoch: 012 | loss: 0.07453 - acc: 0.9827 -- iter: 256/323
[A[ATraining Step: 130  | total loss: [1m[32m0.07039[0m[0m | time: 88.283s
[2K
| Adam | epoch: 012 | loss: 0.07039 - acc: 0.9813 -- iter: 288/323
[A[ATraining Step: 131  | total loss: [1m[32m0.06457[0m[0m | time: 89.982s
[2K
| Adam | epoch: 012 | loss: 0.06457 - acc: 0.9832 -- iter: 320/323
[A[ATraining Step: 132  | total loss: [1m[32m0.07070[0m[0m | time: 96.921s
[2K
| Adam | epoch: 012 | loss: 0.07070 - acc: 0.9849 | val_loss: 0.49529 - val_acc: 0.8235 -- iter: 323/323
--
Training Step: 133  | total loss: [1m[32m0.06390[0m[0m | time: 9.839s
[2K
| Adam | epoch: 013 | loss: 0.06390 - acc: 0.9864 -- iter: 032/323
[A[ATraining Step: 134  | total loss: [1m[32m0.07023[0m[0m | time: 19.533s
[2K
| Adam | epoch: 013 | loss: 0.07023 - acc: 0.9815 -- iter: 064/323
[A[ATraining Step: 135  | total loss: [1m[32m0.07810[0m[0m | time: 29.175s
[2K
| Adam | epoch: 013 | loss: 0.07810 - acc: 0.9771 -- iter: 096/323
[A[ATraining Step: 136  | total loss: [1m[32m0.08615[0m[0m | time: 38.893s
[2K
| Adam | epoch: 013 | loss: 0.08615 - acc: 0.9762 -- iter: 128/323
[A[ATraining Step: 137  | total loss: [1m[32m0.07919[0m[0m | time: 48.752s
[2K
| Adam | epoch: 013 | loss: 0.07919 - acc: 0.9786 -- iter: 160/323
[A[ATraining Step: 138  | total loss: [1m[32m0.07569[0m[0m | time: 58.292s
[2K
| Adam | epoch: 013 | loss: 0.07569 - acc: 0.9776 -- iter: 192/323
[A[ATraining Step: 139  | total loss: [1m[32m0.07063[0m[0m | time: 68.235s
[2K
| Adam | epoch: 013 | loss: 0.07063 - acc: 0.9799 -- iter: 224/323
[A[ATraining Step: 140  | total loss: [1m[32m0.06834[0m[0m | time: 77.889s
[2K
| Adam | epoch: 013 | loss: 0.06834 - acc: 0.9819 -- iter: 256/323
[A[ATraining Step: 141  | total loss: [1m[32m0.06444[0m[0m | time: 87.721s
[2K
| Adam | epoch: 013 | loss: 0.06444 - acc: 0.9837 -- iter: 288/323
[A[ATraining Step: 142  | total loss: [1m[32m0.07360[0m[0m | time: 97.576s
[2K
| Adam | epoch: 013 | loss: 0.07360 - acc: 0.9791 -- iter: 320/323
[A[ATraining Step: 143  | total loss: [1m[32m0.07138[0m[0m | time: 104.569s
[2K
| Adam | epoch: 013 | loss: 0.07138 - acc: 0.9780 | val_loss: 2.30072 - val_acc: 0.5980 -- iter: 323/323
--
Training Step: 144  | total loss: [1m[32m0.09930[0m[0m | time: 1.638s
[2K
| Adam | epoch: 014 | loss: 0.09930 - acc: 0.9469 -- iter: 032/323
[A[ATraining Step: 145  | total loss: [1m[32m0.09095[0m[0m | time: 11.551s
[2K
| Adam | epoch: 014 | loss: 0.09095 - acc: 0.9522 -- iter: 064/323
[A[ATraining Step: 146  | total loss: [1m[32m0.09241[0m[0m | time: 21.556s
[2K
| Adam | epoch: 014 | loss: 0.09241 - acc: 0.9539 -- iter: 096/323
[A[ATraining Step: 147  | total loss: [1m[32m0.09474[0m[0m | time: 31.526s
[2K
| Adam | epoch: 014 | loss: 0.09474 - acc: 0.9554 -- iter: 128/323
[A[ATraining Step: 148  | total loss: [1m[32m0.08711[0m[0m | time: 41.295s
[2K
| Adam | epoch: 014 | loss: 0.08711 - acc: 0.9598 -- iter: 160/323
[A[ATraining Step: 149  | total loss: [1m[32m0.08003[0m[0m | time: 50.983s
[2K
| Adam | epoch: 014 | loss: 0.08003 - acc: 0.9638 -- iter: 192/323
[A[ATraining Step: 150  | total loss: [1m[32m0.07879[0m[0m | time: 60.732s
[2K
| Adam | epoch: 014 | loss: 0.07879 - acc: 0.9643 -- iter: 224/323
[A[ATraining Step: 151  | total loss: [1m[32m0.08479[0m[0m | time: 70.578s
[2K
| Adam | epoch: 014 | loss: 0.08479 - acc: 0.9616 -- iter: 256/323
[A[ATraining Step: 152  | total loss: [1m[32m0.07942[0m[0m | time: 80.492s
[2K
| Adam | epoch: 014 | loss: 0.07942 - acc: 0.9624 -- iter: 288/323
[A[ATraining Step: 153  | total loss: [1m[32m0.09709[0m[0m | time: 90.324s
[2K
| Adam | epoch: 014 | loss: 0.09709 - acc: 0.9567 -- iter: 320/323
[A[ATraining Step: 154  | total loss: [1m[32m0.10132[0m[0m | time: 105.521s
[2K
| Adam | epoch: 014 | loss: 0.10132 - acc: 0.9579 | val_loss: 0.58826 - val_acc: 0.7843 -- iter: 323/323
--
Training Step: 155  | total loss: [1m[32m0.10688[0m[0m | time: 1.770s
[2K
| Adam | epoch: 015 | loss: 0.10688 - acc: 0.9559 -- iter: 032/323
[A[ATraining Step: 156  | total loss: [1m[32m0.10305[0m[0m | time: 3.430s
[2K
| Adam | epoch: 015 | loss: 0.10305 - acc: 0.9603 -- iter: 064/323
[A[ATraining Step: 157  | total loss: [1m[32m0.09307[0m[0m | time: 13.040s
[2K
| Adam | epoch: 015 | loss: 0.09307 - acc: 0.9643 -- iter: 096/323
[A[ATraining Step: 158  | total loss: [1m[32m0.08842[0m[0m | time: 22.927s
[2K
| Adam | epoch: 015 | loss: 0.08842 - acc: 0.9679 -- iter: 128/323
[A[ATraining Step: 159  | total loss: [1m[32m0.09006[0m[0m | time: 32.907s
[2K
| Adam | epoch: 015 | loss: 0.09006 - acc: 0.9679 -- iter: 160/323
[A[ATraining Step: 160  | total loss: [1m[32m0.08267[0m[0m | time: 42.513s
[2K
| Adam | epoch: 015 | loss: 0.08267 - acc: 0.9711 -- iter: 192/323
[A[ATraining Step: 161  | total loss: [1m[32m0.07593[0m[0m | time: 52.261s
[2K
| Adam | epoch: 015 | loss: 0.07593 - acc: 0.9740 -- iter: 224/323
[A[ATraining Step: 162  | total loss: [1m[32m0.07051[0m[0m | time: 61.974s
[2K
| Adam | epoch: 015 | loss: 0.07051 - acc: 0.9766 -- iter: 256/323
[A[ATraining Step: 163  | total loss: [1m[32m0.06608[0m[0m | time: 71.757s
[2K
| Adam | epoch: 015 | loss: 0.06608 - acc: 0.9790 -- iter: 288/323
[A[ATraining Step: 164  | total loss: [1m[32m0.06206[0m[0m | time: 81.577s
[2K
| Adam | epoch: 015 | loss: 0.06206 - acc: 0.9811 -- iter: 320/323
[A[ATraining Step: 165  | total loss: [1m[32m0.06042[0m[0m | time: 96.582s
[2K
| Adam | epoch: 015 | loss: 0.06042 - acc: 0.9830 | val_loss: 0.61355 - val_acc: 0.8235 -- iter: 323/323
--
Validation AUC:0.8931180315263361
Validation AUPRC:0.8990137590209112
Test AUC:0.9380053908355797
Test AUPRC:0.9449853660116784
BestTestF1Score	0.89	0.76	0.88	0.89	0.89	47	6	43	6	0.3
BestTestMCCScore	0.89	0.76	0.88	0.89	0.89	47	6	43	6	0.3
BestTestAccuracyScore	0.89	0.76	0.88	0.89	0.89	47	6	43	6	0.3
BestValidationF1Score	0.87	0.75	0.87	0.88	0.86	44	6	45	7	0.3
BestValidationMCC	0.87	0.75	0.87	0.88	0.86	44	6	45	7	0.3
BestValidationAccuracy	0.87	0.75	0.87	0.88	0.86	44	6	45	7	0.3
TestPredictions (Threshold:0.3)
CHEMBL3702808,FP,INACT,0.9800000190734863	CHEMBL390152,TN,INACT,0.10999999940395355	CHEMBL3702707,TP,ACT,0.9599999785423279	CHEMBL223983,TN,INACT,0.0	CHEMBL359736,TN,INACT,0.0	CHEMBL26065,TN,INACT,0.0	CHEMBL3702756,TP,ACT,0.6399999856948853	CHEMBL442,FN,ACT,0.23999999463558197	CHEMBL1203649,TN,INACT,0.23000000417232513	CHEMBL12340,FP,INACT,0.3199999928474426	CHEMBL495574,TN,INACT,0.0	CHEMBL3682506,TN,INACT,0.09000000357627869	CHEMBL104566,TN,INACT,0.0	CHEMBL3664696,TN,INACT,0.10000000149011612	CHEMBL3702733,TP,ACT,0.9700000286102295	CHEMBL3702738,TP,ACT,0.9399999976158142	CHEMBL465879,TN,INACT,0.0	CHEMBL3664685,FP,INACT,0.6700000166893005	CHEMBL3125537,TP,ACT,0.9599999785423279	CHEMBL39782,TN,INACT,0.0	CHEMBL3664707,FP,INACT,0.6200000047683716	CHEMBL3702779,TP,ACT,1.0	CHEMBL3664717,TN,INACT,0.0	CHEMBL116,FN,ACT,0.09000000357627869	CHEMBL128678,TN,INACT,0.019999999552965164	CHEMBL179962,TN,INACT,0.0	CHEMBL3702672,TP,ACT,0.9900000095367432	CHEMBL3702807,TP,ACT,0.9800000190734863	CHEMBL345586,TN,INACT,0.0	CHEMBL3673939,TP,ACT,0.9900000095367432	CHEMBL3664689,TN,INACT,0.25	CHEMBL3358217,TN,INACT,0.0	CHEMBL3656910,TN,INACT,0.11999999731779099	CHEMBL3669005,TP,ACT,0.9900000095367432	CHEMBL3673950,TP,ACT,0.9700000286102295	CHEMBL544903,TN,INACT,0.019999999552965164	CHEMBL3702685,TP,ACT,1.0	CHEMBL76904,TN,INACT,0.0	CHEMBL3702739,TP,ACT,0.9200000166893005	CHEMBL3358211,TN,INACT,0.0	CHEMBL3702705,TP,ACT,0.9900000095367432	CHEMBL3672580,TP,ACT,0.9200000166893005	CHEMBL295698,TP,ACT,0.8600000143051147	CHEMBL1969102,TP,ACT,0.9300000071525574	CHEMBL456807,FN,ACT,0.029999999329447746	CHEMBL1262,TP,ACT,0.8399999737739563	CHEMBL3672582,TP,ACT,0.9900000095367432	CHEMBL12131,TP,ACT,0.8500000238418579	CHEMBL3702800,TP,ACT,0.9900000095367432	CHEMBL3672573,TP,ACT,0.9700000286102295	CHEMBL3702678,TP,ACT,0.9900000095367432	CHEMBL3702776,TP,ACT,1.0	CHEMBL179589,TN,INACT,0.0	CHEMBL3702797,TP,ACT,1.0	CHEMBL3702724,TP,ACT,1.0	CHEMBL3664694,TN,INACT,0.0	CHEMBL3702825,TP,ACT,0.9599999785423279	CHEMBL3656921,TN,INACT,0.009999999776482582	CHEMBL325461,TN,INACT,0.0	CHEMBL157346,TN,INACT,0.0	CHEMBL3702757,TP,ACT,0.9800000190734863	CHEMBL3702679,TP,ACT,1.0	CHEMBL3702721,TP,ACT,1.0	CHEMBL362702,TN,INACT,0.0	CHEMBL3702686,TP,ACT,1.0	CHEMBL3664677,TN,INACT,0.009999999776482582	CHEMBL3699326,TP,ACT,0.9900000095367432	CHEMBL3699322,TP,ACT,1.0	CHEMBL3640779,TN,INACT,0.0	CHEMBL431843,TN,INACT,0.0	CHEMBL410851,TN,INACT,0.0	CHEMBL3702761,TP,ACT,0.7599999904632568	CHEMBL138170,FP,INACT,0.8299999833106995	CHEMBL3673974,TP,ACT,0.9900000095367432	CHEMBL3702770,TP,ACT,0.9900000095367432	CHEMBL3672585,TP,ACT,0.8100000023841858	CHEMBL3702751,TP,ACT,1.0	CHEMBL115769,FN,ACT,0.0	CHEMBL39275,TN,INACT,0.0	CHEMBL166709,TN,INACT,0.0	CHEMBL179477,TN,INACT,0.0	CHEMBL83668,TN,INACT,0.009999999776482582	CHEMBL184952,TN,INACT,0.0	CHEMBL1172842,FP,INACT,0.9800000190734863	CHEMBL109347,TN,INACT,0.05999999865889549	CHEMBL3702737,TP,ACT,0.9300000071525574	CHEMBL3702783,TP,ACT,1.0	CHEMBL3702680,TP,ACT,1.0	CHEMBL3702750,TP,ACT,0.800000011920929	CHEMBL3673981,TP,ACT,0.9800000190734863	CHEMBL502823,TN,INACT,0.0	CHEMBL501740,TN,INACT,0.0	CHEMBL3702781,TP,ACT,0.9800000190734863	CHEMBL3672577,TP,ACT,0.9100000262260437	CHEMBL1765217,TN,INACT,0.0	CHEMBL3702788,TP,ACT,0.9700000286102295	CHEMBL3640780,TN,INACT,0.0	CHEMBL3702822,TP,ACT,0.49000000953674316	CHEMBL8273,TN,INACT,0.07999999821186066	CHEMBL413,FN,ACT,0.009999999776482582	CHEMBL3702792,FN,ACT,0.009999999776482582	CHEMBL1645413,TN,INACT,0.25	

