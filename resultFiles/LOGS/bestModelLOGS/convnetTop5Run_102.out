CNNModel CHEMBL3948 adam 0.0005 15 256 0 0.8 False True
Number of active compounds :	808
Number of inactive compounds :	808
---------------------------------
Run id: CNNModel_CHEMBL3948_adam_0.0005_15_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3948_adam_0.0005_15_256_0.8_True/
---------------------------------
Training samples: 1033
Validation samples: 324
--
Training Step: 1  | time: 0.804s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1033
[A[ATraining Step: 2  | total loss: [1m[32m0.62392[0m[0m | time: 1.399s
[2K
| Adam | epoch: 001 | loss: 0.62392 - acc: 0.4219 -- iter: 0064/1033
[A[ATraining Step: 3  | total loss: [1m[32m0.68005[0m[0m | time: 2.010s
[2K
| Adam | epoch: 001 | loss: 0.68005 - acc: 0.5369 -- iter: 0096/1033
[A[ATraining Step: 4  | total loss: [1m[32m0.69253[0m[0m | time: 2.614s
[2K
| Adam | epoch: 001 | loss: 0.69253 - acc: 0.4624 -- iter: 0128/1033
[A[ATraining Step: 5  | total loss: [1m[32m0.69566[0m[0m | time: 3.215s
[2K
| Adam | epoch: 001 | loss: 0.69566 - acc: 0.4019 -- iter: 0160/1033
[A[ATraining Step: 6  | total loss: [1m[32m0.69410[0m[0m | time: 3.843s
[2K
| Adam | epoch: 001 | loss: 0.69410 - acc: 0.4650 -- iter: 0192/1033
[A[ATraining Step: 7  | total loss: [1m[32m0.69444[0m[0m | time: 4.440s
[2K
| Adam | epoch: 001 | loss: 0.69444 - acc: 0.3922 -- iter: 0224/1033
[A[ATraining Step: 8  | total loss: [1m[32m0.69376[0m[0m | time: 5.074s
[2K
| Adam | epoch: 001 | loss: 0.69376 - acc: 0.4529 -- iter: 0256/1033
[A[ATraining Step: 9  | total loss: [1m[32m0.69358[0m[0m | time: 5.692s
[2K
| Adam | epoch: 001 | loss: 0.69358 - acc: 0.3785 -- iter: 0288/1033
[A[ATraining Step: 10  | total loss: [1m[32m0.69337[0m[0m | time: 6.310s
[2K
| Adam | epoch: 001 | loss: 0.69337 - acc: 0.4393 -- iter: 0320/1033
[A[ATraining Step: 11  | total loss: [1m[32m0.69323[0m[0m | time: 6.934s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.5124 -- iter: 0352/1033
[A[ATraining Step: 12  | total loss: [1m[32m0.69318[0m[0m | time: 7.550s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.5209 -- iter: 0384/1033
[A[ATraining Step: 13  | total loss: [1m[32m0.69313[0m[0m | time: 8.161s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.5387 -- iter: 0416/1033
[A[ATraining Step: 14  | total loss: [1m[32m0.69312[0m[0m | time: 8.803s
[2K
| Adam | epoch: 001 | loss: 0.69312 - acc: 0.5357 -- iter: 0448/1033
[A[ATraining Step: 15  | total loss: [1m[32m0.69317[0m[0m | time: 9.411s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.4973 -- iter: 0480/1033
[A[ATraining Step: 16  | total loss: [1m[32m0.69316[0m[0m | time: 10.029s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.4983 -- iter: 0512/1033
[A[ATraining Step: 17  | total loss: [1m[32m0.69316[0m[0m | time: 10.643s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.4989 -- iter: 0544/1033
[A[ATraining Step: 18  | total loss: [1m[32m0.69318[0m[0m | time: 11.245s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.4776 -- iter: 0576/1033
[A[ATraining Step: 19  | total loss: [1m[32m0.69322[0m[0m | time: 11.855s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.4538 -- iter: 0608/1033
[A[ATraining Step: 20  | total loss: [1m[32m0.69318[0m[0m | time: 12.471s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.4787 -- iter: 0640/1033
[A[ATraining Step: 21  | total loss: [1m[32m0.69318[0m[0m | time: 13.091s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.4659 -- iter: 0672/1033
[A[ATraining Step: 22  | total loss: [1m[32m0.69315[0m[0m | time: 13.700s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.4949 -- iter: 0704/1033
[A[ATraining Step: 23  | total loss: [1m[32m0.69326[0m[0m | time: 14.291s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.4692 -- iter: 0736/1033
[A[ATraining Step: 24  | total loss: [1m[32m0.69316[0m[0m | time: 14.898s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.4690 -- iter: 0768/1033
[A[ATraining Step: 25  | total loss: [1m[32m0.69314[0m[0m | time: 15.513s
[2K
| Adam | epoch: 001 | loss: 0.69314 - acc: 0.4690 -- iter: 0800/1033
[A[ATraining Step: 26  | total loss: [1m[32m0.69304[0m[0m | time: 16.119s
[2K
| Adam | epoch: 001 | loss: 0.69304 - acc: 0.5020 -- iter: 0832/1033
[A[ATraining Step: 27  | total loss: [1m[32m0.69292[0m[0m | time: 16.724s
[2K
| Adam | epoch: 001 | loss: 0.69292 - acc: 0.5176 -- iter: 0864/1033
[A[ATraining Step: 28  | total loss: [1m[32m0.69277[0m[0m | time: 17.332s
[2K
| Adam | epoch: 001 | loss: 0.69277 - acc: 0.5210 -- iter: 0896/1033
[A[ATraining Step: 29  | total loss: [1m[32m0.69306[0m[0m | time: 17.943s
[2K
| Adam | epoch: 001 | loss: 0.69306 - acc: 0.5083 -- iter: 0928/1033
[A[ATraining Step: 30  | total loss: [1m[32m0.69308[0m[0m | time: 18.557s
[2K
| Adam | epoch: 001 | loss: 0.69308 - acc: 0.5063 -- iter: 0960/1033
[A[ATraining Step: 31  | total loss: [1m[32m0.69344[0m[0m | time: 19.164s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.4904 -- iter: 0992/1033
[A[ATraining Step: 32  | total loss: [1m[32m0.69263[0m[0m | time: 19.784s
[2K
| Adam | epoch: 001 | loss: 0.69263 - acc: 0.5137 -- iter: 1024/1033
[A[ATraining Step: 33  | total loss: [1m[32m0.69329[0m[0m | time: 21.110s
[2K
| Adam | epoch: 001 | loss: 0.69329 - acc: 0.4901 | val_loss: 0.69355 - val_acc: 0.4568 -- iter: 1033/1033
--
Training Step: 34  | total loss: [1m[32m0.69413[0m[0m | time: 0.213s
[2K
| Adam | epoch: 002 | loss: 0.69413 - acc: 0.4565 -- iter: 0032/1033
[A[ATraining Step: 35  | total loss: [1m[32m0.69457[0m[0m | time: 0.828s
[2K
| Adam | epoch: 002 | loss: 0.69457 - acc: 0.4307 -- iter: 0064/1033
[A[ATraining Step: 36  | total loss: [1m[32m0.69428[0m[0m | time: 1.444s
[2K
| Adam | epoch: 002 | loss: 0.69428 - acc: 0.4321 -- iter: 0096/1033
[A[ATraining Step: 37  | total loss: [1m[32m0.69405[0m[0m | time: 2.069s
[2K
| Adam | epoch: 002 | loss: 0.69405 - acc: 0.4394 -- iter: 0128/1033
[A[ATraining Step: 38  | total loss: [1m[32m0.69407[0m[0m | time: 2.666s
[2K
| Adam | epoch: 002 | loss: 0.69407 - acc: 0.4207 -- iter: 0160/1033
[A[ATraining Step: 39  | total loss: [1m[32m0.69385[0m[0m | time: 3.292s
[2K
| Adam | epoch: 002 | loss: 0.69385 - acc: 0.4419 -- iter: 0192/1033
[A[ATraining Step: 40  | total loss: [1m[32m0.69337[0m[0m | time: 3.907s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4997 -- iter: 0224/1033
[A[ATraining Step: 41  | total loss: [1m[32m0.69325[0m[0m | time: 4.509s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.5055 -- iter: 0256/1033
[A[ATraining Step: 42  | total loss: [1m[32m0.69342[0m[0m | time: 5.121s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4876 -- iter: 0288/1033
[A[ATraining Step: 43  | total loss: [1m[32m0.69366[0m[0m | time: 5.729s
[2K
| Adam | epoch: 002 | loss: 0.69366 - acc: 0.4677 -- iter: 0320/1033
[A[ATraining Step: 44  | total loss: [1m[32m0.69349[0m[0m | time: 6.339s
[2K
| Adam | epoch: 002 | loss: 0.69349 - acc: 0.4787 -- iter: 0352/1033
[A[ATraining Step: 45  | total loss: [1m[32m0.69355[0m[0m | time: 6.944s
[2K
| Adam | epoch: 002 | loss: 0.69355 - acc: 0.4717 -- iter: 0384/1033
[A[ATraining Step: 46  | total loss: [1m[32m0.69354[0m[0m | time: 7.556s
[2K
| Adam | epoch: 002 | loss: 0.69354 - acc: 0.4712 -- iter: 0416/1033
[A[ATraining Step: 47  | total loss: [1m[32m0.69352[0m[0m | time: 8.151s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.4708 -- iter: 0448/1033
[A[ATraining Step: 48  | total loss: [1m[32m0.69346[0m[0m | time: 8.762s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.4755 -- iter: 0480/1033
[A[ATraining Step: 49  | total loss: [1m[32m0.69346[0m[0m | time: 9.381s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.4744 -- iter: 0512/1033
[A[ATraining Step: 50  | total loss: [1m[32m0.69358[0m[0m | time: 9.984s
[2K
| Adam | epoch: 002 | loss: 0.69358 - acc: 0.4590 -- iter: 0544/1033
[A[ATraining Step: 51  | total loss: [1m[32m0.69342[0m[0m | time: 10.596s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4796 -- iter: 0576/1033
[A[ATraining Step: 52  | total loss: [1m[32m0.69325[0m[0m | time: 11.218s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.5014 -- iter: 0608/1033
[A[ATraining Step: 53  | total loss: [1m[32m0.69327[0m[0m | time: 11.832s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4966 -- iter: 0640/1033
[A[ATraining Step: 54  | total loss: [1m[32m0.69318[0m[0m | time: 12.441s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5061 -- iter: 0672/1033
[A[ATraining Step: 55  | total loss: [1m[32m0.69310[0m[0m | time: 13.046s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5142 -- iter: 0704/1033
[A[ATraining Step: 56  | total loss: [1m[32m0.69319[0m[0m | time: 13.662s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.4990 -- iter: 0736/1033
[A[ATraining Step: 57  | total loss: [1m[32m0.69295[0m[0m | time: 14.268s
[2K
| Adam | epoch: 002 | loss: 0.69295 - acc: 0.5251 -- iter: 0768/1033
[A[ATraining Step: 58  | total loss: [1m[32m0.69334[0m[0m | time: 14.881s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4833 -- iter: 0800/1033
[A[ATraining Step: 59  | total loss: [1m[32m0.69328[0m[0m | time: 15.478s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.4856 -- iter: 0832/1033
[A[ATraining Step: 60  | total loss: [1m[32m0.69309[0m[0m | time: 16.076s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5040 -- iter: 0864/1033
[A[ATraining Step: 61  | total loss: [1m[32m0.69303[0m[0m | time: 16.663s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5076 -- iter: 0896/1033
[A[ATraining Step: 62  | total loss: [1m[32m0.69302[0m[0m | time: 17.276s
[2K
| Adam | epoch: 002 | loss: 0.69302 - acc: 0.5026 -- iter: 0928/1033
[A[ATraining Step: 63  | total loss: [1m[32m0.69299[0m[0m | time: 17.885s
[2K
| Adam | epoch: 002 | loss: 0.69299 - acc: 0.5023 -- iter: 0960/1033
[A[ATraining Step: 64  | total loss: [1m[32m0.69303[0m[0m | time: 18.481s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.4903 -- iter: 0992/1033
[A[ATraining Step: 65  | total loss: [1m[32m0.69300[0m[0m | time: 19.084s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.4953 -- iter: 1024/1033
[A[ATraining Step: 66  | total loss: [1m[32m0.69290[0m[0m | time: 20.721s
[2K
| Adam | epoch: 002 | loss: 0.69290 - acc: 0.5111 | val_loss: 0.69190 - val_acc: 0.5432 -- iter: 1033/1033
--
Training Step: 67  | total loss: [1m[32m0.69288[0m[0m | time: 0.207s
[2K
| Adam | epoch: 003 | loss: 0.69288 - acc: 0.5060 -- iter: 0032/1033
[A[ATraining Step: 68  | total loss: [1m[32m0.69270[0m[0m | time: 0.411s
[2K
| Adam | epoch: 003 | loss: 0.69270 - acc: 0.5382 -- iter: 0064/1033
[A[ATraining Step: 69  | total loss: [1m[32m0.69226[0m[0m | time: 1.018s
[2K
| Adam | epoch: 003 | loss: 0.69226 - acc: 0.5662 -- iter: 0096/1033
[A[ATraining Step: 70  | total loss: [1m[32m0.69287[0m[0m | time: 1.609s
[2K
| Adam | epoch: 003 | loss: 0.69287 - acc: 0.5333 -- iter: 0128/1033
[A[ATraining Step: 71  | total loss: [1m[32m0.69256[0m[0m | time: 2.216s
[2K
| Adam | epoch: 003 | loss: 0.69256 - acc: 0.5438 -- iter: 0160/1033
[A[ATraining Step: 72  | total loss: [1m[32m0.69233[0m[0m | time: 2.830s
[2K
| Adam | epoch: 003 | loss: 0.69233 - acc: 0.5494 -- iter: 0192/1033
[A[ATraining Step: 73  | total loss: [1m[32m0.69220[0m[0m | time: 3.439s
[2K
| Adam | epoch: 003 | loss: 0.69220 - acc: 0.5508 -- iter: 0224/1033
[A[ATraining Step: 74  | total loss: [1m[32m0.69196[0m[0m | time: 4.053s
[2K
| Adam | epoch: 003 | loss: 0.69196 - acc: 0.5555 -- iter: 0256/1033
[A[ATraining Step: 75  | total loss: [1m[32m0.69171[0m[0m | time: 4.641s
[2K
| Adam | epoch: 003 | loss: 0.69171 - acc: 0.5597 -- iter: 0288/1033
[A[ATraining Step: 76  | total loss: [1m[32m0.69223[0m[0m | time: 5.269s
[2K
| Adam | epoch: 003 | loss: 0.69223 - acc: 0.5466 -- iter: 0320/1033
[A[ATraining Step: 77  | total loss: [1m[32m0.69252[0m[0m | time: 5.861s
[2K
| Adam | epoch: 003 | loss: 0.69252 - acc: 0.5384 -- iter: 0352/1033
[A[ATraining Step: 78  | total loss: [1m[32m0.69180[0m[0m | time: 6.488s
[2K
| Adam | epoch: 003 | loss: 0.69180 - acc: 0.5474 -- iter: 0384/1033
[A[ATraining Step: 79  | total loss: [1m[32m0.69222[0m[0m | time: 7.098s
[2K
| Adam | epoch: 003 | loss: 0.69222 - acc: 0.5393 -- iter: 0416/1033
[A[ATraining Step: 80  | total loss: [1m[32m0.69283[0m[0m | time: 7.705s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5289 -- iter: 0448/1033
[A[ATraining Step: 81  | total loss: [1m[32m0.69191[0m[0m | time: 8.314s
[2K
| Adam | epoch: 003 | loss: 0.69191 - acc: 0.5386 -- iter: 0480/1033
[A[ATraining Step: 82  | total loss: [1m[32m0.69280[0m[0m | time: 8.942s
[2K
| Adam | epoch: 003 | loss: 0.69280 - acc: 0.5254 -- iter: 0512/1033
[A[ATraining Step: 83  | total loss: [1m[32m0.69289[0m[0m | time: 9.554s
[2K
| Adam | epoch: 003 | loss: 0.69289 - acc: 0.5228 -- iter: 0544/1033
[A[ATraining Step: 84  | total loss: [1m[32m0.69220[0m[0m | time: 10.166s
[2K
| Adam | epoch: 003 | loss: 0.69220 - acc: 0.5299 -- iter: 0576/1033
[A[ATraining Step: 85  | total loss: [1m[32m0.69273[0m[0m | time: 10.775s
[2K
| Adam | epoch: 003 | loss: 0.69273 - acc: 0.5207 -- iter: 0608/1033
[A[ATraining Step: 86  | total loss: [1m[32m0.69194[0m[0m | time: 11.379s
[2K
| Adam | epoch: 003 | loss: 0.69194 - acc: 0.5280 -- iter: 0640/1033
[A[ATraining Step: 87  | total loss: [1m[32m0.69143[0m[0m | time: 11.986s
[2K
| Adam | epoch: 003 | loss: 0.69143 - acc: 0.5314 -- iter: 0672/1033
[A[ATraining Step: 88  | total loss: [1m[32m0.69091[0m[0m | time: 12.597s
[2K
| Adam | epoch: 003 | loss: 0.69091 - acc: 0.5345 -- iter: 0704/1033
[A[ATraining Step: 89  | total loss: [1m[32m0.69161[0m[0m | time: 13.202s
[2K
| Adam | epoch: 003 | loss: 0.69161 - acc: 0.5248 -- iter: 0736/1033
[A[ATraining Step: 90  | total loss: [1m[32m0.69212[0m[0m | time: 13.808s
[2K
| Adam | epoch: 003 | loss: 0.69212 - acc: 0.5161 -- iter: 0768/1033
[A[ATraining Step: 91  | total loss: [1m[32m0.69071[0m[0m | time: 14.434s
[2K
| Adam | epoch: 003 | loss: 0.69071 - acc: 0.5270 -- iter: 0800/1033
[A[ATraining Step: 92  | total loss: [1m[32m0.69073[0m[0m | time: 15.039s
[2K
| Adam | epoch: 003 | loss: 0.69073 - acc: 0.5243 -- iter: 0832/1033
[A[ATraining Step: 93  | total loss: [1m[32m0.69222[0m[0m | time: 15.648s
[2K
| Adam | epoch: 003 | loss: 0.69222 - acc: 0.5062 -- iter: 0864/1033
[A[ATraining Step: 94  | total loss: [1m[32m0.69207[0m[0m | time: 16.275s
[2K
| Adam | epoch: 003 | loss: 0.69207 - acc: 0.5025 -- iter: 0896/1033
[A[ATraining Step: 95  | total loss: [1m[32m0.69267[0m[0m | time: 16.886s
[2K
| Adam | epoch: 003 | loss: 0.69267 - acc: 0.4866 -- iter: 0928/1033
[A[ATraining Step: 96  | total loss: [1m[32m0.69262[0m[0m | time: 17.498s
[2K
| Adam | epoch: 003 | loss: 0.69262 - acc: 0.4817 -- iter: 0960/1033
[A[ATraining Step: 97  | total loss: [1m[32m0.69155[0m[0m | time: 18.112s
[2K
| Adam | epoch: 003 | loss: 0.69155 - acc: 0.4804 -- iter: 0992/1033
[A[ATraining Step: 98  | total loss: [1m[32m0.69103[0m[0m | time: 18.708s
[2K
| Adam | epoch: 003 | loss: 0.69103 - acc: 0.4667 -- iter: 1024/1033
[A[ATraining Step: 99  | total loss: [1m[32m0.68926[0m[0m | time: 20.346s
[2K
| Adam | epoch: 003 | loss: 0.68926 - acc: 0.4857 | val_loss: 0.65684 - val_acc: 0.5679 -- iter: 1033/1033
--
Training Step: 100  | total loss: [1m[32m0.68901[0m[0m | time: 0.616s
[2K
| Adam | epoch: 004 | loss: 0.68901 - acc: 0.4809 -- iter: 0032/1033
[A[ATraining Step: 101  | total loss: [1m[32m0.68526[0m[0m | time: 0.828s
[2K
| Adam | epoch: 004 | loss: 0.68526 - acc: 0.4984 -- iter: 0064/1033
[A[ATraining Step: 102  | total loss: [1m[32m0.68124[0m[0m | time: 1.041s
[2K
| Adam | epoch: 004 | loss: 0.68124 - acc: 0.5263 -- iter: 0096/1033
[A[ATraining Step: 103  | total loss: [1m[32m0.67494[0m[0m | time: 1.647s
[2K
| Adam | epoch: 004 | loss: 0.67494 - acc: 0.5515 -- iter: 0128/1033
[A[ATraining Step: 104  | total loss: [1m[32m0.67312[0m[0m | time: 2.240s
[2K
| Adam | epoch: 004 | loss: 0.67312 - acc: 0.5620 -- iter: 0160/1033
[A[ATraining Step: 105  | total loss: [1m[32m0.66991[0m[0m | time: 2.849s
[2K
| Adam | epoch: 004 | loss: 0.66991 - acc: 0.5589 -- iter: 0192/1033
[A[ATraining Step: 106  | total loss: [1m[32m0.66819[0m[0m | time: 3.478s
[2K
| Adam | epoch: 004 | loss: 0.66819 - acc: 0.5718 -- iter: 0224/1033
[A[ATraining Step: 107  | total loss: [1m[32m0.66123[0m[0m | time: 4.094s
[2K
| Adam | epoch: 004 | loss: 0.66123 - acc: 0.5865 -- iter: 0256/1033
[A[ATraining Step: 108  | total loss: [1m[32m0.65050[0m[0m | time: 4.721s
[2K
| Adam | epoch: 004 | loss: 0.65050 - acc: 0.6091 -- iter: 0288/1033
[A[ATraining Step: 109  | total loss: [1m[32m0.64392[0m[0m | time: 5.329s
[2K
| Adam | epoch: 004 | loss: 0.64392 - acc: 0.6075 -- iter: 0320/1033
[A[ATraining Step: 110  | total loss: [1m[32m0.63316[0m[0m | time: 5.952s
[2K
| Adam | epoch: 004 | loss: 0.63316 - acc: 0.6218 -- iter: 0352/1033
[A[ATraining Step: 111  | total loss: [1m[32m0.62372[0m[0m | time: 6.561s
[2K
| Adam | epoch: 004 | loss: 0.62372 - acc: 0.6315 -- iter: 0384/1033
[A[ATraining Step: 112  | total loss: [1m[32m0.61739[0m[0m | time: 7.156s
[2K
| Adam | epoch: 004 | loss: 0.61739 - acc: 0.6371 -- iter: 0416/1033
[A[ATraining Step: 113  | total loss: [1m[32m0.61237[0m[0m | time: 7.754s
[2K
| Adam | epoch: 004 | loss: 0.61237 - acc: 0.6452 -- iter: 0448/1033
[A[ATraining Step: 114  | total loss: [1m[32m0.60035[0m[0m | time: 8.363s
[2K
| Adam | epoch: 004 | loss: 0.60035 - acc: 0.6557 -- iter: 0480/1033
[A[ATraining Step: 115  | total loss: [1m[32m0.57376[0m[0m | time: 8.984s
[2K
| Adam | epoch: 004 | loss: 0.57376 - acc: 0.6808 -- iter: 0512/1033
[A[ATraining Step: 116  | total loss: [1m[32m0.55964[0m[0m | time: 9.598s
[2K
| Adam | epoch: 004 | loss: 0.55964 - acc: 0.6877 -- iter: 0544/1033
[A[ATraining Step: 117  | total loss: [1m[32m0.57081[0m[0m | time: 10.202s
[2K
| Adam | epoch: 004 | loss: 0.57081 - acc: 0.6721 -- iter: 0576/1033
[A[ATraining Step: 118  | total loss: [1m[32m0.54536[0m[0m | time: 10.794s
[2K
| Adam | epoch: 004 | loss: 0.54536 - acc: 0.6955 -- iter: 0608/1033
[A[ATraining Step: 119  | total loss: [1m[32m0.54082[0m[0m | time: 11.423s
[2K
| Adam | epoch: 004 | loss: 0.54082 - acc: 0.7009 -- iter: 0640/1033
[A[ATraining Step: 120  | total loss: [1m[32m0.54033[0m[0m | time: 12.024s
[2K
| Adam | epoch: 004 | loss: 0.54033 - acc: 0.6996 -- iter: 0672/1033
[A[ATraining Step: 121  | total loss: [1m[32m0.52134[0m[0m | time: 12.626s
[2K
| Adam | epoch: 004 | loss: 0.52134 - acc: 0.7202 -- iter: 0704/1033
[A[ATraining Step: 122  | total loss: [1m[32m0.50922[0m[0m | time: 13.220s
[2K
| Adam | epoch: 004 | loss: 0.50922 - acc: 0.7295 -- iter: 0736/1033
[A[ATraining Step: 123  | total loss: [1m[32m0.50658[0m[0m | time: 13.845s
[2K
| Adam | epoch: 004 | loss: 0.50658 - acc: 0.7347 -- iter: 0768/1033
[A[ATraining Step: 124  | total loss: [1m[32m0.48912[0m[0m | time: 14.453s
[2K
| Adam | epoch: 004 | loss: 0.48912 - acc: 0.7487 -- iter: 0800/1033
[A[ATraining Step: 125  | total loss: [1m[32m0.48188[0m[0m | time: 15.063s
[2K
| Adam | epoch: 004 | loss: 0.48188 - acc: 0.7613 -- iter: 0832/1033
[A[ATraining Step: 126  | total loss: [1m[32m0.46749[0m[0m | time: 15.679s
[2K
| Adam | epoch: 004 | loss: 0.46749 - acc: 0.7664 -- iter: 0864/1033
[A[ATraining Step: 127  | total loss: [1m[32m0.46588[0m[0m | time: 16.275s
[2K
| Adam | epoch: 004 | loss: 0.46588 - acc: 0.7648 -- iter: 0896/1033
[A[ATraining Step: 128  | total loss: [1m[32m0.48871[0m[0m | time: 16.877s
[2K
| Adam | epoch: 004 | loss: 0.48871 - acc: 0.7602 -- iter: 0928/1033
[A[ATraining Step: 129  | total loss: [1m[32m0.47302[0m[0m | time: 17.509s
[2K
| Adam | epoch: 004 | loss: 0.47302 - acc: 0.7717 -- iter: 0960/1033
[A[ATraining Step: 130  | total loss: [1m[32m0.46940[0m[0m | time: 18.098s
[2K
| Adam | epoch: 004 | loss: 0.46940 - acc: 0.7695 -- iter: 0992/1033
[A[ATraining Step: 131  | total loss: [1m[32m0.48389[0m[0m | time: 18.696s
[2K
| Adam | epoch: 004 | loss: 0.48389 - acc: 0.7551 -- iter: 1024/1033
[A[ATraining Step: 132  | total loss: [1m[32m0.52353[0m[0m | time: 20.315s
[2K
| Adam | epoch: 004 | loss: 0.52353 - acc: 0.7389 | val_loss: 0.34315 - val_acc: 0.8580 -- iter: 1033/1033
--
Training Step: 133  | total loss: [1m[32m0.50731[0m[0m | time: 0.604s
[2K
| Adam | epoch: 005 | loss: 0.50731 - acc: 0.7494 -- iter: 0032/1033
[A[ATraining Step: 134  | total loss: [1m[32m0.49284[0m[0m | time: 1.236s
[2K
| Adam | epoch: 005 | loss: 0.49284 - acc: 0.7620 -- iter: 0064/1033
[A[ATraining Step: 135  | total loss: [1m[32m0.48076[0m[0m | time: 1.456s
[2K
| Adam | epoch: 005 | loss: 0.48076 - acc: 0.7701 -- iter: 0096/1033
[A[ATraining Step: 136  | total loss: [1m[32m0.47978[0m[0m | time: 1.674s
[2K
| Adam | epoch: 005 | loss: 0.47978 - acc: 0.7598 -- iter: 0128/1033
[A[ATraining Step: 137  | total loss: [1m[32m0.46643[0m[0m | time: 2.270s
[2K
| Adam | epoch: 005 | loss: 0.46643 - acc: 0.7727 -- iter: 0160/1033
[A[ATraining Step: 138  | total loss: [1m[32m0.45259[0m[0m | time: 2.862s
[2K
| Adam | epoch: 005 | loss: 0.45259 - acc: 0.7892 -- iter: 0192/1033
[A[ATraining Step: 139  | total loss: [1m[32m0.46453[0m[0m | time: 3.465s
[2K
| Adam | epoch: 005 | loss: 0.46453 - acc: 0.7790 -- iter: 0224/1033
[A[ATraining Step: 140  | total loss: [1m[32m0.45387[0m[0m | time: 4.058s
[2K
| Adam | epoch: 005 | loss: 0.45387 - acc: 0.7855 -- iter: 0256/1033
[A[ATraining Step: 141  | total loss: [1m[32m0.43243[0m[0m | time: 4.695s
[2K
| Adam | epoch: 005 | loss: 0.43243 - acc: 0.8007 -- iter: 0288/1033
[A[ATraining Step: 142  | total loss: [1m[32m0.42162[0m[0m | time: 5.321s
[2K
| Adam | epoch: 005 | loss: 0.42162 - acc: 0.8081 -- iter: 0320/1033
[A[ATraining Step: 143  | total loss: [1m[32m0.41588[0m[0m | time: 5.913s
[2K
| Adam | epoch: 005 | loss: 0.41588 - acc: 0.8117 -- iter: 0352/1033
[A[ATraining Step: 144  | total loss: [1m[32m0.40741[0m[0m | time: 6.514s
[2K
| Adam | epoch: 005 | loss: 0.40741 - acc: 0.8211 -- iter: 0384/1033
[A[ATraining Step: 145  | total loss: [1m[32m0.39006[0m[0m | time: 7.115s
[2K
| Adam | epoch: 005 | loss: 0.39006 - acc: 0.8328 -- iter: 0416/1033
[A[ATraining Step: 146  | total loss: [1m[32m0.38381[0m[0m | time: 7.719s
[2K
| Adam | epoch: 005 | loss: 0.38381 - acc: 0.8339 -- iter: 0448/1033
[A[ATraining Step: 147  | total loss: [1m[32m0.37381[0m[0m | time: 8.323s
[2K
| Adam | epoch: 005 | loss: 0.37381 - acc: 0.8442 -- iter: 0480/1033
[A[ATraining Step: 148  | total loss: [1m[32m0.35902[0m[0m | time: 8.940s
[2K
| Adam | epoch: 005 | loss: 0.35902 - acc: 0.8473 -- iter: 0512/1033
[A[ATraining Step: 149  | total loss: [1m[32m0.36635[0m[0m | time: 9.522s
[2K
| Adam | epoch: 005 | loss: 0.36635 - acc: 0.8438 -- iter: 0544/1033
[A[ATraining Step: 150  | total loss: [1m[32m0.35922[0m[0m | time: 10.114s
[2K
| Adam | epoch: 005 | loss: 0.35922 - acc: 0.8469 -- iter: 0576/1033
[A[ATraining Step: 151  | total loss: [1m[32m0.35390[0m[0m | time: 10.706s
[2K
| Adam | epoch: 005 | loss: 0.35390 - acc: 0.8498 -- iter: 0608/1033
[A[ATraining Step: 152  | total loss: [1m[32m0.36570[0m[0m | time: 11.303s
[2K
| Adam | epoch: 005 | loss: 0.36570 - acc: 0.8460 -- iter: 0640/1033
[A[ATraining Step: 153  | total loss: [1m[32m0.35663[0m[0m | time: 11.899s
[2K
| Adam | epoch: 005 | loss: 0.35663 - acc: 0.8489 -- iter: 0672/1033
[A[ATraining Step: 154  | total loss: [1m[32m0.36554[0m[0m | time: 12.506s
[2K
| Adam | epoch: 005 | loss: 0.36554 - acc: 0.8484 -- iter: 0704/1033
[A[ATraining Step: 155  | total loss: [1m[32m0.39106[0m[0m | time: 13.118s
[2K
| Adam | epoch: 005 | loss: 0.39106 - acc: 0.8417 -- iter: 0736/1033
[A[ATraining Step: 156  | total loss: [1m[32m0.39989[0m[0m | time: 13.766s
[2K
| Adam | epoch: 005 | loss: 0.39989 - acc: 0.8356 -- iter: 0768/1033
[A[ATraining Step: 157  | total loss: [1m[32m0.37941[0m[0m | time: 14.379s
[2K
| Adam | epoch: 005 | loss: 0.37941 - acc: 0.8458 -- iter: 0800/1033
[A[ATraining Step: 158  | total loss: [1m[32m0.38176[0m[0m | time: 15.001s
[2K
| Adam | epoch: 005 | loss: 0.38176 - acc: 0.8394 -- iter: 0832/1033
[A[ATraining Step: 159  | total loss: [1m[32m0.36542[0m[0m | time: 15.610s
[2K
| Adam | epoch: 005 | loss: 0.36542 - acc: 0.8492 -- iter: 0864/1033
[A[ATraining Step: 160  | total loss: [1m[32m0.35815[0m[0m | time: 16.218s
[2K
| Adam | epoch: 005 | loss: 0.35815 - acc: 0.8518 -- iter: 0896/1033
[A[ATraining Step: 161  | total loss: [1m[32m0.33987[0m[0m | time: 16.829s
[2K
| Adam | epoch: 005 | loss: 0.33987 - acc: 0.8572 -- iter: 0928/1033
[A[ATraining Step: 162  | total loss: [1m[32m0.33147[0m[0m | time: 17.453s
[2K
| Adam | epoch: 005 | loss: 0.33147 - acc: 0.8559 -- iter: 0960/1033
[A[ATraining Step: 163  | total loss: [1m[32m0.32484[0m[0m | time: 18.065s
[2K
| Adam | epoch: 005 | loss: 0.32484 - acc: 0.8578 -- iter: 0992/1033
[A[ATraining Step: 164  | total loss: [1m[32m0.31285[0m[0m | time: 18.676s
[2K
| Adam | epoch: 005 | loss: 0.31285 - acc: 0.8595 -- iter: 1024/1033
[A[ATraining Step: 165  | total loss: [1m[32m0.30101[0m[0m | time: 20.333s
[2K
| Adam | epoch: 005 | loss: 0.30101 - acc: 0.8642 | val_loss: 0.30564 - val_acc: 0.8519 -- iter: 1033/1033
--
Training Step: 166  | total loss: [1m[32m0.30007[0m[0m | time: 0.637s
[2K
| Adam | epoch: 006 | loss: 0.30007 - acc: 0.8715 -- iter: 0032/1033
[A[ATraining Step: 167  | total loss: [1m[32m0.28595[0m[0m | time: 1.265s
[2K
| Adam | epoch: 006 | loss: 0.28595 - acc: 0.8781 -- iter: 0064/1033
[A[ATraining Step: 168  | total loss: [1m[32m0.29505[0m[0m | time: 1.894s
[2K
| Adam | epoch: 006 | loss: 0.29505 - acc: 0.8715 -- iter: 0096/1033
[A[ATraining Step: 169  | total loss: [1m[32m0.29940[0m[0m | time: 2.099s
[2K
| Adam | epoch: 006 | loss: 0.29940 - acc: 0.8750 -- iter: 0128/1033
[A[ATraining Step: 170  | total loss: [1m[32m0.31369[0m[0m | time: 2.316s
[2K
| Adam | epoch: 006 | loss: 0.31369 - acc: 0.8653 -- iter: 0160/1033
[A[ATraining Step: 171  | total loss: [1m[32m0.31305[0m[0m | time: 2.949s
[2K
| Adam | epoch: 006 | loss: 0.31305 - acc: 0.8565 -- iter: 0192/1033
[A[ATraining Step: 172  | total loss: [1m[32m0.32099[0m[0m | time: 3.579s
[2K
| Adam | epoch: 006 | loss: 0.32099 - acc: 0.8584 -- iter: 0224/1033
[A[ATraining Step: 173  | total loss: [1m[32m0.32616[0m[0m | time: 4.185s
[2K
| Adam | epoch: 006 | loss: 0.32616 - acc: 0.8601 -- iter: 0256/1033
[A[ATraining Step: 174  | total loss: [1m[32m0.31936[0m[0m | time: 4.798s
[2K
| Adam | epoch: 006 | loss: 0.31936 - acc: 0.8647 -- iter: 0288/1033
[A[ATraining Step: 175  | total loss: [1m[32m0.30784[0m[0m | time: 5.402s
[2K
| Adam | epoch: 006 | loss: 0.30784 - acc: 0.8720 -- iter: 0320/1033
[A[ATraining Step: 176  | total loss: [1m[32m0.31305[0m[0m | time: 6.018s
[2K
| Adam | epoch: 006 | loss: 0.31305 - acc: 0.8691 -- iter: 0352/1033
[A[ATraining Step: 177  | total loss: [1m[32m0.29386[0m[0m | time: 6.619s
[2K
| Adam | epoch: 006 | loss: 0.29386 - acc: 0.8791 -- iter: 0384/1033
[A[ATraining Step: 178  | total loss: [1m[32m0.28232[0m[0m | time: 7.228s
[2K
| Adam | epoch: 006 | loss: 0.28232 - acc: 0.8849 -- iter: 0416/1033
[A[ATraining Step: 179  | total loss: [1m[32m0.27884[0m[0m | time: 7.846s
[2K
| Adam | epoch: 006 | loss: 0.27884 - acc: 0.8871 -- iter: 0448/1033
[A[ATraining Step: 180  | total loss: [1m[32m0.25923[0m[0m | time: 8.464s
[2K
| Adam | epoch: 006 | loss: 0.25923 - acc: 0.8984 -- iter: 0480/1033
[A[ATraining Step: 181  | total loss: [1m[32m0.23878[0m[0m | time: 9.049s
[2K
| Adam | epoch: 006 | loss: 0.23878 - acc: 0.9085 -- iter: 0512/1033
[A[ATraining Step: 182  | total loss: [1m[32m0.23924[0m[0m | time: 9.680s
[2K
| Adam | epoch: 006 | loss: 0.23924 - acc: 0.9114 -- iter: 0544/1033
[A[ATraining Step: 183  | total loss: [1m[32m0.23197[0m[0m | time: 10.291s
[2K
| Adam | epoch: 006 | loss: 0.23197 - acc: 0.9172 -- iter: 0576/1033
[A[ATraining Step: 184  | total loss: [1m[32m0.23292[0m[0m | time: 10.907s
[2K
| Adam | epoch: 006 | loss: 0.23292 - acc: 0.9129 -- iter: 0608/1033
[A[ATraining Step: 185  | total loss: [1m[32m0.23705[0m[0m | time: 11.514s
[2K
| Adam | epoch: 006 | loss: 0.23705 - acc: 0.9091 -- iter: 0640/1033
[A[ATraining Step: 186  | total loss: [1m[32m0.22938[0m[0m | time: 12.125s
[2K
| Adam | epoch: 006 | loss: 0.22938 - acc: 0.9151 -- iter: 0672/1033
[A[ATraining Step: 187  | total loss: [1m[32m0.21843[0m[0m | time: 12.738s
[2K
| Adam | epoch: 006 | loss: 0.21843 - acc: 0.9205 -- iter: 0704/1033
[A[ATraining Step: 188  | total loss: [1m[32m0.22127[0m[0m | time: 13.349s
[2K
| Adam | epoch: 006 | loss: 0.22127 - acc: 0.9159 -- iter: 0736/1033
[A[ATraining Step: 189  | total loss: [1m[32m0.24247[0m[0m | time: 13.958s
[2K
| Adam | epoch: 006 | loss: 0.24247 - acc: 0.9056 -- iter: 0768/1033
[A[ATraining Step: 190  | total loss: [1m[32m0.23465[0m[0m | time: 14.562s
[2K
| Adam | epoch: 006 | loss: 0.23465 - acc: 0.9088 -- iter: 0800/1033
[A[ATraining Step: 191  | total loss: [1m[32m0.22646[0m[0m | time: 15.183s
[2K
| Adam | epoch: 006 | loss: 0.22646 - acc: 0.9116 -- iter: 0832/1033
[A[ATraining Step: 192  | total loss: [1m[32m0.22348[0m[0m | time: 15.805s
[2K
| Adam | epoch: 006 | loss: 0.22348 - acc: 0.9142 -- iter: 0864/1033
[A[ATraining Step: 193  | total loss: [1m[32m0.21782[0m[0m | time: 16.438s
[2K
| Adam | epoch: 006 | loss: 0.21782 - acc: 0.9166 -- iter: 0896/1033
[A[ATraining Step: 194  | total loss: [1m[32m0.23233[0m[0m | time: 17.051s
[2K
| Adam | epoch: 006 | loss: 0.23233 - acc: 0.9124 -- iter: 0928/1033
[A[ATraining Step: 195  | total loss: [1m[32m0.21815[0m[0m | time: 17.696s
[2K
| Adam | epoch: 006 | loss: 0.21815 - acc: 0.9180 -- iter: 0960/1033
[A[ATraining Step: 196  | total loss: [1m[32m0.26040[0m[0m | time: 18.309s
[2K
| Adam | epoch: 006 | loss: 0.26040 - acc: 0.9075 -- iter: 0992/1033
[A[ATraining Step: 197  | total loss: [1m[32m0.26575[0m[0m | time: 18.952s
[2K
| Adam | epoch: 006 | loss: 0.26575 - acc: 0.9042 -- iter: 1024/1033
[A[ATraining Step: 198  | total loss: [1m[32m0.27555[0m[0m | time: 20.580s
[2K
| Adam | epoch: 006 | loss: 0.27555 - acc: 0.8982 | val_loss: 0.30592 - val_acc: 0.8920 -- iter: 1033/1033
--
Training Step: 199  | total loss: [1m[32m0.26861[0m[0m | time: 0.608s
[2K
| Adam | epoch: 007 | loss: 0.26861 - acc: 0.8990 -- iter: 0032/1033
[A[ATraining Step: 200  | total loss: [1m[32m0.25638[0m[0m | time: 2.253s
[2K
| Adam | epoch: 007 | loss: 0.25638 - acc: 0.9028 | val_loss: 0.54780 - val_acc: 0.7593 -- iter: 0064/1033
--
Training Step: 201  | total loss: [1m[32m0.26891[0m[0m | time: 2.881s
[2K
| Adam | epoch: 007 | loss: 0.26891 - acc: 0.8938 -- iter: 0096/1033
[A[ATraining Step: 202  | total loss: [1m[32m0.30623[0m[0m | time: 3.479s
[2K
| Adam | epoch: 007 | loss: 0.30623 - acc: 0.8794 -- iter: 0128/1033
[A[ATraining Step: 203  | total loss: [1m[32m0.29722[0m[0m | time: 3.682s
[2K
| Adam | epoch: 007 | loss: 0.29722 - acc: 0.8790 -- iter: 0160/1033
[A[ATraining Step: 204  | total loss: [1m[32m0.27165[0m[0m | time: 3.892s
[2K
| Adam | epoch: 007 | loss: 0.27165 - acc: 0.8911 -- iter: 0192/1033
[A[ATraining Step: 205  | total loss: [1m[32m0.25139[0m[0m | time: 4.509s
[2K
| Adam | epoch: 007 | loss: 0.25139 - acc: 0.9020 -- iter: 0224/1033
[A[ATraining Step: 206  | total loss: [1m[32m0.26270[0m[0m | time: 5.117s
[2K
| Adam | epoch: 007 | loss: 0.26270 - acc: 0.9024 -- iter: 0256/1033
[A[ATraining Step: 207  | total loss: [1m[32m0.24290[0m[0m | time: 5.733s
[2K
| Adam | epoch: 007 | loss: 0.24290 - acc: 0.9122 -- iter: 0288/1033
[A[ATraining Step: 208  | total loss: [1m[32m0.22748[0m[0m | time: 6.362s
[2K
| Adam | epoch: 007 | loss: 0.22748 - acc: 0.9178 -- iter: 0320/1033
[A[ATraining Step: 209  | total loss: [1m[32m0.21116[0m[0m | time: 6.982s
[2K
| Adam | epoch: 007 | loss: 0.21116 - acc: 0.9260 -- iter: 0352/1033
[A[ATraining Step: 210  | total loss: [1m[32m0.20850[0m[0m | time: 7.591s
[2K
| Adam | epoch: 007 | loss: 0.20850 - acc: 0.9272 -- iter: 0384/1033
[A[ATraining Step: 211  | total loss: [1m[32m0.19695[0m[0m | time: 8.194s
[2K
| Adam | epoch: 007 | loss: 0.19695 - acc: 0.9313 -- iter: 0416/1033
[A[ATraining Step: 212  | total loss: [1m[32m0.19090[0m[0m | time: 8.805s
[2K
| Adam | epoch: 007 | loss: 0.19090 - acc: 0.9351 -- iter: 0448/1033
[A[ATraining Step: 213  | total loss: [1m[32m0.19453[0m[0m | time: 9.418s
[2K
| Adam | epoch: 007 | loss: 0.19453 - acc: 0.9322 -- iter: 0480/1033
[A[ATraining Step: 214  | total loss: [1m[32m0.19773[0m[0m | time: 10.045s
[2K
| Adam | epoch: 007 | loss: 0.19773 - acc: 0.9296 -- iter: 0512/1033
[A[ATraining Step: 215  | total loss: [1m[32m0.19763[0m[0m | time: 10.674s
[2K
| Adam | epoch: 007 | loss: 0.19763 - acc: 0.9273 -- iter: 0544/1033
[A[ATraining Step: 216  | total loss: [1m[32m0.19939[0m[0m | time: 11.284s
[2K
| Adam | epoch: 007 | loss: 0.19939 - acc: 0.9220 -- iter: 0576/1033
[A[ATraining Step: 217  | total loss: [1m[32m0.18883[0m[0m | time: 11.909s
[2K
| Adam | epoch: 007 | loss: 0.18883 - acc: 0.9267 -- iter: 0608/1033
[A[ATraining Step: 218  | total loss: [1m[32m0.17580[0m[0m | time: 12.522s
[2K
| Adam | epoch: 007 | loss: 0.17580 - acc: 0.9309 -- iter: 0640/1033
[A[ATraining Step: 219  | total loss: [1m[32m0.17305[0m[0m | time: 13.138s
[2K
| Adam | epoch: 007 | loss: 0.17305 - acc: 0.9316 -- iter: 0672/1033
[A[ATraining Step: 220  | total loss: [1m[32m0.17275[0m[0m | time: 13.748s
[2K
| Adam | epoch: 007 | loss: 0.17275 - acc: 0.9290 -- iter: 0704/1033
[A[ATraining Step: 221  | total loss: [1m[32m0.18283[0m[0m | time: 14.379s
[2K
| Adam | epoch: 007 | loss: 0.18283 - acc: 0.9268 -- iter: 0736/1033
[A[ATraining Step: 222  | total loss: [1m[32m0.18110[0m[0m | time: 14.987s
[2K
| Adam | epoch: 007 | loss: 0.18110 - acc: 0.9310 -- iter: 0768/1033
[A[ATraining Step: 223  | total loss: [1m[32m0.17585[0m[0m | time: 15.606s
[2K
| Adam | epoch: 007 | loss: 0.17585 - acc: 0.9285 -- iter: 0800/1033
[A[ATraining Step: 224  | total loss: [1m[32m0.19104[0m[0m | time: 16.237s
[2K
| Adam | epoch: 007 | loss: 0.19104 - acc: 0.9231 -- iter: 0832/1033
[A[ATraining Step: 225  | total loss: [1m[32m0.19725[0m[0m | time: 16.850s
[2K
| Adam | epoch: 007 | loss: 0.19725 - acc: 0.9246 -- iter: 0864/1033
[A[ATraining Step: 226  | total loss: [1m[32m0.19415[0m[0m | time: 17.473s
[2K
| Adam | epoch: 007 | loss: 0.19415 - acc: 0.9259 -- iter: 0896/1033
[A[ATraining Step: 227  | total loss: [1m[32m0.19020[0m[0m | time: 18.092s
[2K
| Adam | epoch: 007 | loss: 0.19020 - acc: 0.9270 -- iter: 0928/1033
[A[ATraining Step: 228  | total loss: [1m[32m0.18178[0m[0m | time: 18.718s
[2K
| Adam | epoch: 007 | loss: 0.18178 - acc: 0.9312 -- iter: 0960/1033
[A[ATraining Step: 229  | total loss: [1m[32m0.18563[0m[0m | time: 19.360s
[2K
| Adam | epoch: 007 | loss: 0.18563 - acc: 0.9287 -- iter: 0992/1033
[A[ATraining Step: 230  | total loss: [1m[32m0.17168[0m[0m | time: 19.976s
[2K
| Adam | epoch: 007 | loss: 0.17168 - acc: 0.9358 -- iter: 1024/1033
[A[ATraining Step: 231  | total loss: [1m[32m0.16290[0m[0m | time: 21.646s
[2K
| Adam | epoch: 007 | loss: 0.16290 - acc: 0.9360 | val_loss: 0.32041 - val_acc: 0.8611 -- iter: 1033/1033
--
Training Step: 232  | total loss: [1m[32m0.16775[0m[0m | time: 0.627s
[2K
| Adam | epoch: 008 | loss: 0.16775 - acc: 0.9362 -- iter: 0032/1033
[A[ATraining Step: 233  | total loss: [1m[32m0.16449[0m[0m | time: 1.237s
[2K
| Adam | epoch: 008 | loss: 0.16449 - acc: 0.9394 -- iter: 0064/1033
[A[ATraining Step: 234  | total loss: [1m[32m0.17184[0m[0m | time: 1.856s
[2K
| Adam | epoch: 008 | loss: 0.17184 - acc: 0.9392 -- iter: 0096/1033
[A[ATraining Step: 235  | total loss: [1m[32m0.16353[0m[0m | time: 2.474s
[2K
| Adam | epoch: 008 | loss: 0.16353 - acc: 0.9453 -- iter: 0128/1033
[A[ATraining Step: 236  | total loss: [1m[32m0.15708[0m[0m | time: 3.082s
[2K
| Adam | epoch: 008 | loss: 0.15708 - acc: 0.9476 -- iter: 0160/1033
[A[ATraining Step: 237  | total loss: [1m[32m0.17205[0m[0m | time: 3.300s
[2K
| Adam | epoch: 008 | loss: 0.17205 - acc: 0.9373 -- iter: 0192/1033
[A[ATraining Step: 238  | total loss: [1m[32m0.16431[0m[0m | time: 3.504s
[2K
| Adam | epoch: 008 | loss: 0.16431 - acc: 0.9324 -- iter: 0224/1033
[A[ATraining Step: 239  | total loss: [1m[32m0.15044[0m[0m | time: 4.118s
[2K
| Adam | epoch: 008 | loss: 0.15044 - acc: 0.9392 -- iter: 0256/1033
[A[ATraining Step: 240  | total loss: [1m[32m0.15054[0m[0m | time: 4.730s
[2K
| Adam | epoch: 008 | loss: 0.15054 - acc: 0.9421 -- iter: 0288/1033
[A[ATraining Step: 241  | total loss: [1m[32m0.14364[0m[0m | time: 5.342s
[2K
| Adam | epoch: 008 | loss: 0.14364 - acc: 0.9448 -- iter: 0320/1033
[A[ATraining Step: 242  | total loss: [1m[32m0.13130[0m[0m | time: 5.952s
[2K
| Adam | epoch: 008 | loss: 0.13130 - acc: 0.9503 -- iter: 0352/1033
[A[ATraining Step: 243  | total loss: [1m[32m0.12304[0m[0m | time: 6.561s
[2K
| Adam | epoch: 008 | loss: 0.12304 - acc: 0.9553 -- iter: 0384/1033
[A[ATraining Step: 244  | total loss: [1m[32m0.12058[0m[0m | time: 7.169s
[2K
| Adam | epoch: 008 | loss: 0.12058 - acc: 0.9535 -- iter: 0416/1033
[A[ATraining Step: 245  | total loss: [1m[32m0.11185[0m[0m | time: 7.794s
[2K
| Adam | epoch: 008 | loss: 0.11185 - acc: 0.9582 -- iter: 0448/1033
[A[ATraining Step: 246  | total loss: [1m[32m0.10887[0m[0m | time: 8.398s
[2K
| Adam | epoch: 008 | loss: 0.10887 - acc: 0.9592 -- iter: 0480/1033
[A[ATraining Step: 247  | total loss: [1m[32m0.12156[0m[0m | time: 8.996s
[2K
| Adam | epoch: 008 | loss: 0.12156 - acc: 0.9539 -- iter: 0512/1033
[A[ATraining Step: 248  | total loss: [1m[32m0.11530[0m[0m | time: 9.612s
[2K
| Adam | epoch: 008 | loss: 0.11530 - acc: 0.9585 -- iter: 0544/1033
[A[ATraining Step: 249  | total loss: [1m[32m0.10714[0m[0m | time: 10.246s
[2K
| Adam | epoch: 008 | loss: 0.10714 - acc: 0.9627 -- iter: 0576/1033
[A[ATraining Step: 250  | total loss: [1m[32m0.10286[0m[0m | time: 10.905s
[2K
| Adam | epoch: 008 | loss: 0.10286 - acc: 0.9664 -- iter: 0608/1033
[A[ATraining Step: 251  | total loss: [1m[32m0.10360[0m[0m | time: 11.551s
[2K
| Adam | epoch: 008 | loss: 0.10360 - acc: 0.9666 -- iter: 0640/1033
[A[ATraining Step: 252  | total loss: [1m[32m0.09812[0m[0m | time: 12.160s
[2K
| Adam | epoch: 008 | loss: 0.09812 - acc: 0.9700 -- iter: 0672/1033
[A[ATraining Step: 253  | total loss: [1m[32m0.09916[0m[0m | time: 12.778s
[2K
| Adam | epoch: 008 | loss: 0.09916 - acc: 0.9699 -- iter: 0704/1033
[A[ATraining Step: 254  | total loss: [1m[32m0.09826[0m[0m | time: 13.382s
[2K
| Adam | epoch: 008 | loss: 0.09826 - acc: 0.9697 -- iter: 0736/1033
[A[ATraining Step: 255  | total loss: [1m[32m0.10514[0m[0m | time: 13.997s
[2K
| Adam | epoch: 008 | loss: 0.10514 - acc: 0.9665 -- iter: 0768/1033
[A[ATraining Step: 256  | total loss: [1m[32m0.10162[0m[0m | time: 14.619s
[2K
| Adam | epoch: 008 | loss: 0.10162 - acc: 0.9636 -- iter: 0800/1033
[A[ATraining Step: 257  | total loss: [1m[32m0.10174[0m[0m | time: 15.249s
[2K
| Adam | epoch: 008 | loss: 0.10174 - acc: 0.9641 -- iter: 0832/1033
[A[ATraining Step: 258  | total loss: [1m[32m0.10434[0m[0m | time: 15.859s
[2K
| Adam | epoch: 008 | loss: 0.10434 - acc: 0.9646 -- iter: 0864/1033
[A[ATraining Step: 259  | total loss: [1m[32m0.11063[0m[0m | time: 16.480s
[2K
| Adam | epoch: 008 | loss: 0.11063 - acc: 0.9619 -- iter: 0896/1033
[A[ATraining Step: 260  | total loss: [1m[32m0.10133[0m[0m | time: 17.081s
[2K
| Adam | epoch: 008 | loss: 0.10133 - acc: 0.9657 -- iter: 0928/1033
[A[ATraining Step: 261  | total loss: [1m[32m0.09352[0m[0m | time: 17.696s
[2K
| Adam | epoch: 008 | loss: 0.09352 - acc: 0.9691 -- iter: 0960/1033
[A[ATraining Step: 262  | total loss: [1m[32m0.08676[0m[0m | time: 18.303s
[2K
| Adam | epoch: 008 | loss: 0.08676 - acc: 0.9722 -- iter: 0992/1033
[A[ATraining Step: 263  | total loss: [1m[32m0.10698[0m[0m | time: 18.927s
[2K
| Adam | epoch: 008 | loss: 0.10698 - acc: 0.9656 -- iter: 1024/1033
[A[ATraining Step: 264  | total loss: [1m[32m0.13282[0m[0m | time: 20.549s
[2K
| Adam | epoch: 008 | loss: 0.13282 - acc: 0.9597 | val_loss: 0.17798 - val_acc: 0.9506 -- iter: 1033/1033
--
Training Step: 265  | total loss: [1m[32m0.13329[0m[0m | time: 0.610s
[2K
| Adam | epoch: 009 | loss: 0.13329 - acc: 0.9575 -- iter: 0032/1033
[A[ATraining Step: 266  | total loss: [1m[32m0.14138[0m[0m | time: 1.229s
[2K
| Adam | epoch: 009 | loss: 0.14138 - acc: 0.9555 -- iter: 0064/1033
[A[ATraining Step: 267  | total loss: [1m[32m0.14523[0m[0m | time: 1.870s
[2K
| Adam | epoch: 009 | loss: 0.14523 - acc: 0.9537 -- iter: 0096/1033
[A[ATraining Step: 268  | total loss: [1m[32m0.14119[0m[0m | time: 2.474s
[2K
| Adam | epoch: 009 | loss: 0.14119 - acc: 0.9552 -- iter: 0128/1033
[A[ATraining Step: 269  | total loss: [1m[32m0.14264[0m[0m | time: 3.079s
[2K
| Adam | epoch: 009 | loss: 0.14264 - acc: 0.9534 -- iter: 0160/1033
[A[ATraining Step: 270  | total loss: [1m[32m0.13657[0m[0m | time: 3.695s
[2K
| Adam | epoch: 009 | loss: 0.13657 - acc: 0.9549 -- iter: 0192/1033
[A[ATraining Step: 271  | total loss: [1m[32m0.13501[0m[0m | time: 3.901s
[2K
| Adam | epoch: 009 | loss: 0.13501 - acc: 0.9532 -- iter: 0224/1033
[A[ATraining Step: 272  | total loss: [1m[32m0.12318[0m[0m | time: 4.103s
[2K
| Adam | epoch: 009 | loss: 0.12318 - acc: 0.9579 -- iter: 0256/1033
[A[ATraining Step: 273  | total loss: [1m[32m0.11248[0m[0m | time: 4.727s
[2K
| Adam | epoch: 009 | loss: 0.11248 - acc: 0.9621 -- iter: 0288/1033
[A[ATraining Step: 274  | total loss: [1m[32m0.10665[0m[0m | time: 5.332s
[2K
| Adam | epoch: 009 | loss: 0.10665 - acc: 0.9659 -- iter: 0320/1033
[A[ATraining Step: 275  | total loss: [1m[32m0.10031[0m[0m | time: 5.937s
[2K
| Adam | epoch: 009 | loss: 0.10031 - acc: 0.9693 -- iter: 0352/1033
[A[ATraining Step: 276  | total loss: [1m[32m0.09566[0m[0m | time: 6.551s
[2K
| Adam | epoch: 009 | loss: 0.09566 - acc: 0.9724 -- iter: 0384/1033
[A[ATraining Step: 277  | total loss: [1m[32m0.10244[0m[0m | time: 7.202s
[2K
| Adam | epoch: 009 | loss: 0.10244 - acc: 0.9689 -- iter: 0416/1033
[A[ATraining Step: 278  | total loss: [1m[32m0.09763[0m[0m | time: 7.809s
[2K
| Adam | epoch: 009 | loss: 0.09763 - acc: 0.9720 -- iter: 0448/1033
[A[ATraining Step: 279  | total loss: [1m[32m0.10110[0m[0m | time: 8.421s
[2K
| Adam | epoch: 009 | loss: 0.10110 - acc: 0.9717 -- iter: 0480/1033
[A[ATraining Step: 280  | total loss: [1m[32m0.10621[0m[0m | time: 9.033s
[2K
| Adam | epoch: 009 | loss: 0.10621 - acc: 0.9682 -- iter: 0512/1033
[A[ATraining Step: 281  | total loss: [1m[32m0.10477[0m[0m | time: 9.669s
[2K
| Adam | epoch: 009 | loss: 0.10477 - acc: 0.9683 -- iter: 0544/1033
[A[ATraining Step: 282  | total loss: [1m[32m0.11876[0m[0m | time: 10.284s
[2K
| Adam | epoch: 009 | loss: 0.11876 - acc: 0.9590 -- iter: 0576/1033
[A[ATraining Step: 283  | total loss: [1m[32m0.10848[0m[0m | time: 10.899s
[2K
| Adam | epoch: 009 | loss: 0.10848 - acc: 0.9631 -- iter: 0608/1033
[A[ATraining Step: 284  | total loss: [1m[32m0.11019[0m[0m | time: 11.510s
[2K
| Adam | epoch: 009 | loss: 0.11019 - acc: 0.9605 -- iter: 0640/1033
[A[ATraining Step: 285  | total loss: [1m[32m0.10078[0m[0m | time: 12.128s
[2K
| Adam | epoch: 009 | loss: 0.10078 - acc: 0.9645 -- iter: 0672/1033
[A[ATraining Step: 286  | total loss: [1m[32m0.10438[0m[0m | time: 12.753s
[2K
| Adam | epoch: 009 | loss: 0.10438 - acc: 0.9649 -- iter: 0704/1033
[A[ATraining Step: 287  | total loss: [1m[32m0.10712[0m[0m | time: 13.370s
[2K
| Adam | epoch: 009 | loss: 0.10712 - acc: 0.9622 -- iter: 0736/1033
[A[ATraining Step: 288  | total loss: [1m[32m0.09936[0m[0m | time: 14.015s
[2K
| Adam | epoch: 009 | loss: 0.09936 - acc: 0.9659 -- iter: 0768/1033
[A[ATraining Step: 289  | total loss: [1m[32m0.09213[0m[0m | time: 14.640s
[2K
| Adam | epoch: 009 | loss: 0.09213 - acc: 0.9693 -- iter: 0800/1033
[A[ATraining Step: 290  | total loss: [1m[32m0.08515[0m[0m | time: 15.256s
[2K
| Adam | epoch: 009 | loss: 0.08515 - acc: 0.9724 -- iter: 0832/1033
[A[ATraining Step: 291  | total loss: [1m[32m0.07871[0m[0m | time: 15.877s
[2K
| Adam | epoch: 009 | loss: 0.07871 - acc: 0.9752 -- iter: 0864/1033
[A[ATraining Step: 292  | total loss: [1m[32m0.07825[0m[0m | time: 16.491s
[2K
| Adam | epoch: 009 | loss: 0.07825 - acc: 0.9714 -- iter: 0896/1033
[A[ATraining Step: 293  | total loss: [1m[32m0.07361[0m[0m | time: 17.108s
[2K
| Adam | epoch: 009 | loss: 0.07361 - acc: 0.9743 -- iter: 0928/1033
[A[ATraining Step: 294  | total loss: [1m[32m0.06943[0m[0m | time: 17.734s
[2K
| Adam | epoch: 009 | loss: 0.06943 - acc: 0.9768 -- iter: 0960/1033
[A[ATraining Step: 295  | total loss: [1m[32m0.06722[0m[0m | time: 18.351s
[2K
| Adam | epoch: 009 | loss: 0.06722 - acc: 0.9792 -- iter: 0992/1033
[A[ATraining Step: 296  | total loss: [1m[32m0.06472[0m[0m | time: 18.971s
[2K
| Adam | epoch: 009 | loss: 0.06472 - acc: 0.9812 -- iter: 1024/1033
[A[ATraining Step: 297  | total loss: [1m[32m0.06189[0m[0m | time: 20.630s
[2K
| Adam | epoch: 009 | loss: 0.06189 - acc: 0.9800 | val_loss: 0.17585 - val_acc: 0.9444 -- iter: 1033/1033
--
Training Step: 298  | total loss: [1m[32m0.05694[0m[0m | time: 0.615s
[2K
| Adam | epoch: 010 | loss: 0.05694 - acc: 0.9820 -- iter: 0032/1033
[A[ATraining Step: 299  | total loss: [1m[32m0.06283[0m[0m | time: 1.229s
[2K
| Adam | epoch: 010 | loss: 0.06283 - acc: 0.9807 -- iter: 0064/1033
[A[ATraining Step: 300  | total loss: [1m[32m0.05767[0m[0m | time: 1.885s
[2K
| Adam | epoch: 010 | loss: 0.05767 - acc: 0.9826 -- iter: 0096/1033
[A[ATraining Step: 301  | total loss: [1m[32m0.05607[0m[0m | time: 2.501s
[2K
| Adam | epoch: 010 | loss: 0.05607 - acc: 0.9843 -- iter: 0128/1033
[A[ATraining Step: 302  | total loss: [1m[32m0.05171[0m[0m | time: 3.126s
[2K
| Adam | epoch: 010 | loss: 0.05171 - acc: 0.9859 -- iter: 0160/1033
[A[ATraining Step: 303  | total loss: [1m[32m0.05584[0m[0m | time: 3.743s
[2K
| Adam | epoch: 010 | loss: 0.05584 - acc: 0.9779 -- iter: 0192/1033
[A[ATraining Step: 304  | total loss: [1m[32m0.05249[0m[0m | time: 4.361s
[2K
| Adam | epoch: 010 | loss: 0.05249 - acc: 0.9801 -- iter: 0224/1033
[A[ATraining Step: 305  | total loss: [1m[32m0.06091[0m[0m | time: 4.572s
[2K
| Adam | epoch: 010 | loss: 0.06091 - acc: 0.9759 -- iter: 0256/1033
[A[ATraining Step: 306  | total loss: [1m[32m0.05515[0m[0m | time: 4.808s
[2K
| Adam | epoch: 010 | loss: 0.05515 - acc: 0.9783 -- iter: 0288/1033
[A[ATraining Step: 307  | total loss: [1m[32m0.04987[0m[0m | time: 5.417s
[2K
| Adam | epoch: 010 | loss: 0.04987 - acc: 0.9805 -- iter: 0320/1033
[A[ATraining Step: 308  | total loss: [1m[32m0.04626[0m[0m | time: 6.029s
[2K
| Adam | epoch: 010 | loss: 0.04626 - acc: 0.9824 -- iter: 0352/1033
[A[ATraining Step: 309  | total loss: [1m[32m0.04311[0m[0m | time: 6.646s
[2K
| Adam | epoch: 010 | loss: 0.04311 - acc: 0.9842 -- iter: 0384/1033
[A[ATraining Step: 310  | total loss: [1m[32m0.04184[0m[0m | time: 7.275s
[2K
| Adam | epoch: 010 | loss: 0.04184 - acc: 0.9858 -- iter: 0416/1033
[A[ATraining Step: 311  | total loss: [1m[32m0.03972[0m[0m | time: 7.928s
[2K
| Adam | epoch: 010 | loss: 0.03972 - acc: 0.9872 -- iter: 0448/1033
[A[ATraining Step: 312  | total loss: [1m[32m0.04339[0m[0m | time: 8.538s
[2K
| Adam | epoch: 010 | loss: 0.04339 - acc: 0.9853 -- iter: 0480/1033
[A[ATraining Step: 313  | total loss: [1m[32m0.04000[0m[0m | time: 9.150s
[2K
| Adam | epoch: 010 | loss: 0.04000 - acc: 0.9868 -- iter: 0512/1033
[A[ATraining Step: 314  | total loss: [1m[32m0.05415[0m[0m | time: 9.765s
[2K
| Adam | epoch: 010 | loss: 0.05415 - acc: 0.9819 -- iter: 0544/1033
[A[ATraining Step: 315  | total loss: [1m[32m0.05388[0m[0m | time: 10.409s
[2K
| Adam | epoch: 010 | loss: 0.05388 - acc: 0.9837 -- iter: 0576/1033
[A[ATraining Step: 316  | total loss: [1m[32m0.05162[0m[0m | time: 11.021s
[2K
| Adam | epoch: 010 | loss: 0.05162 - acc: 0.9853 -- iter: 0608/1033
[A[ATraining Step: 317  | total loss: [1m[32m0.04924[0m[0m | time: 11.671s
[2K
| Adam | epoch: 010 | loss: 0.04924 - acc: 0.9868 -- iter: 0640/1033
[A[ATraining Step: 318  | total loss: [1m[32m0.04497[0m[0m | time: 12.304s
[2K
| Adam | epoch: 010 | loss: 0.04497 - acc: 0.9881 -- iter: 0672/1033
[A[ATraining Step: 319  | total loss: [1m[32m0.04243[0m[0m | time: 12.930s
[2K
| Adam | epoch: 010 | loss: 0.04243 - acc: 0.9893 -- iter: 0704/1033
[A[ATraining Step: 320  | total loss: [1m[32m0.05146[0m[0m | time: 13.556s
[2K
| Adam | epoch: 010 | loss: 0.05146 - acc: 0.9872 -- iter: 0736/1033
[A[ATraining Step: 321  | total loss: [1m[32m0.05761[0m[0m | time: 14.188s
[2K
| Adam | epoch: 010 | loss: 0.05761 - acc: 0.9854 -- iter: 0768/1033
[A[ATraining Step: 322  | total loss: [1m[32m0.05299[0m[0m | time: 14.800s
[2K
| Adam | epoch: 010 | loss: 0.05299 - acc: 0.9869 -- iter: 0800/1033
[A[ATraining Step: 323  | total loss: [1m[32m0.06179[0m[0m | time: 15.448s
[2K
| Adam | epoch: 010 | loss: 0.06179 - acc: 0.9850 -- iter: 0832/1033
[A[ATraining Step: 324  | total loss: [1m[32m0.06651[0m[0m | time: 16.089s
[2K
| Adam | epoch: 010 | loss: 0.06651 - acc: 0.9803 -- iter: 0864/1033
[A[ATraining Step: 325  | total loss: [1m[32m0.06081[0m[0m | time: 16.714s
[2K
| Adam | epoch: 010 | loss: 0.06081 - acc: 0.9823 -- iter: 0896/1033
[A[ATraining Step: 326  | total loss: [1m[32m0.05757[0m[0m | time: 17.356s
[2K
| Adam | epoch: 010 | loss: 0.05757 - acc: 0.9840 -- iter: 0928/1033
[A[ATraining Step: 327  | total loss: [1m[32m0.05358[0m[0m | time: 17.978s
[2K
| Adam | epoch: 010 | loss: 0.05358 - acc: 0.9856 -- iter: 0960/1033
[A[ATraining Step: 328  | total loss: [1m[32m0.04871[0m[0m | time: 18.589s
[2K
| Adam | epoch: 010 | loss: 0.04871 - acc: 0.9871 -- iter: 0992/1033
[A[ATraining Step: 329  | total loss: [1m[32m0.05023[0m[0m | time: 19.230s
[2K
| Adam | epoch: 010 | loss: 0.05023 - acc: 0.9852 -- iter: 1024/1033
[A[ATraining Step: 330  | total loss: [1m[32m0.04873[0m[0m | time: 20.948s
[2K
| Adam | epoch: 010 | loss: 0.04873 - acc: 0.9867 | val_loss: 0.15007 - val_acc: 0.9568 -- iter: 1033/1033
--
Training Step: 331  | total loss: [1m[32m0.04420[0m[0m | time: 0.628s
[2K
| Adam | epoch: 011 | loss: 0.04420 - acc: 0.9880 -- iter: 0032/1033
[A[ATraining Step: 332  | total loss: [1m[32m0.04019[0m[0m | time: 1.234s
[2K
| Adam | epoch: 011 | loss: 0.04019 - acc: 0.9892 -- iter: 0064/1033
[A[ATraining Step: 333  | total loss: [1m[32m0.03791[0m[0m | time: 1.869s
[2K
| Adam | epoch: 011 | loss: 0.03791 - acc: 0.9903 -- iter: 0096/1033
[A[ATraining Step: 334  | total loss: [1m[32m0.03669[0m[0m | time: 2.496s
[2K
| Adam | epoch: 011 | loss: 0.03669 - acc: 0.9913 -- iter: 0128/1033
[A[ATraining Step: 335  | total loss: [1m[32m0.03472[0m[0m | time: 3.109s
[2K
| Adam | epoch: 011 | loss: 0.03472 - acc: 0.9922 -- iter: 0160/1033
[A[ATraining Step: 336  | total loss: [1m[32m0.03173[0m[0m | time: 3.751s
[2K
| Adam | epoch: 011 | loss: 0.03173 - acc: 0.9929 -- iter: 0192/1033
[A[ATraining Step: 337  | total loss: [1m[32m0.02935[0m[0m | time: 4.367s
[2K
| Adam | epoch: 011 | loss: 0.02935 - acc: 0.9936 -- iter: 0224/1033
[A[ATraining Step: 338  | total loss: [1m[32m0.03207[0m[0m | time: 5.002s
[2K
| Adam | epoch: 011 | loss: 0.03207 - acc: 0.9912 -- iter: 0256/1033
[A[ATraining Step: 339  | total loss: [1m[32m0.03728[0m[0m | time: 5.217s
[2K
| Adam | epoch: 011 | loss: 0.03728 - acc: 0.9889 -- iter: 0288/1033
[A[ATraining Step: 340  | total loss: [1m[32m0.03430[0m[0m | time: 5.423s
[2K
| Adam | epoch: 011 | loss: 0.03430 - acc: 0.9900 -- iter: 0320/1033
[A[ATraining Step: 341  | total loss: [1m[32m0.03161[0m[0m | time: 6.055s
[2K
| Adam | epoch: 011 | loss: 0.03161 - acc: 0.9910 -- iter: 0352/1033
[A[ATraining Step: 342  | total loss: [1m[32m0.05411[0m[0m | time: 6.666s
[2K
| Adam | epoch: 011 | loss: 0.05411 - acc: 0.9857 -- iter: 0384/1033
[A[ATraining Step: 343  | total loss: [1m[32m0.04905[0m[0m | time: 7.317s
[2K
| Adam | epoch: 011 | loss: 0.04905 - acc: 0.9871 -- iter: 0416/1033
[A[ATraining Step: 344  | total loss: [1m[32m0.04498[0m[0m | time: 7.941s
[2K
| Adam | epoch: 011 | loss: 0.04498 - acc: 0.9884 -- iter: 0448/1033
[A[ATraining Step: 345  | total loss: [1m[32m0.04153[0m[0m | time: 8.567s
[2K
| Adam | epoch: 011 | loss: 0.04153 - acc: 0.9896 -- iter: 0480/1033
[A[ATraining Step: 346  | total loss: [1m[32m0.03812[0m[0m | time: 9.204s
[2K
| Adam | epoch: 011 | loss: 0.03812 - acc: 0.9906 -- iter: 0512/1033
[A[ATraining Step: 347  | total loss: [1m[32m0.04762[0m[0m | time: 9.858s
[2K
| Adam | epoch: 011 | loss: 0.04762 - acc: 0.9884 -- iter: 0544/1033
[A[ATraining Step: 348  | total loss: [1m[32m0.04336[0m[0m | time: 10.478s
[2K
| Adam | epoch: 011 | loss: 0.04336 - acc: 0.9896 -- iter: 0576/1033
[A[ATraining Step: 349  | total loss: [1m[32m0.04033[0m[0m | time: 11.088s
[2K
| Adam | epoch: 011 | loss: 0.04033 - acc: 0.9906 -- iter: 0608/1033
[A[ATraining Step: 350  | total loss: [1m[32m0.03896[0m[0m | time: 11.767s
[2K
| Adam | epoch: 011 | loss: 0.03896 - acc: 0.9916 -- iter: 0640/1033
[A[ATraining Step: 351  | total loss: [1m[32m0.03541[0m[0m | time: 12.403s
[2K
| Adam | epoch: 011 | loss: 0.03541 - acc: 0.9924 -- iter: 0672/1033
[A[ATraining Step: 352  | total loss: [1m[32m0.03279[0m[0m | time: 13.016s
[2K
| Adam | epoch: 011 | loss: 0.03279 - acc: 0.9932 -- iter: 0704/1033
[A[ATraining Step: 353  | total loss: [1m[32m0.03072[0m[0m | time: 13.640s
[2K
| Adam | epoch: 011 | loss: 0.03072 - acc: 0.9938 -- iter: 0736/1033
[A[ATraining Step: 354  | total loss: [1m[32m0.02842[0m[0m | time: 14.263s
[2K
| Adam | epoch: 011 | loss: 0.02842 - acc: 0.9945 -- iter: 0768/1033
[A[ATraining Step: 355  | total loss: [1m[32m0.02909[0m[0m | time: 14.881s
[2K
| Adam | epoch: 011 | loss: 0.02909 - acc: 0.9919 -- iter: 0800/1033
[A[ATraining Step: 356  | total loss: [1m[32m0.02950[0m[0m | time: 15.498s
[2K
| Adam | epoch: 011 | loss: 0.02950 - acc: 0.9927 -- iter: 0832/1033
[A[ATraining Step: 357  | total loss: [1m[32m0.02707[0m[0m | time: 16.155s
[2K
| Adam | epoch: 011 | loss: 0.02707 - acc: 0.9934 -- iter: 0864/1033
[A[ATraining Step: 358  | total loss: [1m[32m0.02472[0m[0m | time: 16.784s
[2K
| Adam | epoch: 011 | loss: 0.02472 - acc: 0.9941 -- iter: 0896/1033
[A[ATraining Step: 359  | total loss: [1m[32m0.02504[0m[0m | time: 17.411s
[2K
| Adam | epoch: 011 | loss: 0.02504 - acc: 0.9916 -- iter: 0928/1033
[A[ATraining Step: 360  | total loss: [1m[32m0.02919[0m[0m | time: 18.027s
[2K
| Adam | epoch: 011 | loss: 0.02919 - acc: 0.9893 -- iter: 0960/1033
[A[ATraining Step: 361  | total loss: [1m[32m0.03734[0m[0m | time: 18.639s
[2K
| Adam | epoch: 011 | loss: 0.03734 - acc: 0.9841 -- iter: 0992/1033
[A[ATraining Step: 362  | total loss: [1m[32m0.03899[0m[0m | time: 19.248s
[2K
| Adam | epoch: 011 | loss: 0.03899 - acc: 0.9826 -- iter: 1024/1033
[A[ATraining Step: 363  | total loss: [1m[32m0.03574[0m[0m | time: 20.922s
[2K
| Adam | epoch: 011 | loss: 0.03574 - acc: 0.9843 | val_loss: 0.55453 - val_acc: 0.8395 -- iter: 1033/1033
--
Training Step: 364  | total loss: [1m[32m0.03391[0m[0m | time: 0.610s
[2K
| Adam | epoch: 012 | loss: 0.03391 - acc: 0.9859 -- iter: 0032/1033
[A[ATraining Step: 365  | total loss: [1m[32m0.03831[0m[0m | time: 1.237s
[2K
| Adam | epoch: 012 | loss: 0.03831 - acc: 0.9842 -- iter: 0064/1033
[A[ATraining Step: 366  | total loss: [1m[32m0.05211[0m[0m | time: 1.857s
[2K
| Adam | epoch: 012 | loss: 0.05211 - acc: 0.9764 -- iter: 0096/1033
[A[ATraining Step: 367  | total loss: [1m[32m0.04921[0m[0m | time: 2.470s
[2K
| Adam | epoch: 012 | loss: 0.04921 - acc: 0.9787 -- iter: 0128/1033
[A[ATraining Step: 368  | total loss: [1m[32m0.05252[0m[0m | time: 3.080s
[2K
| Adam | epoch: 012 | loss: 0.05252 - acc: 0.9777 -- iter: 0160/1033
[A[ATraining Step: 369  | total loss: [1m[32m0.04798[0m[0m | time: 3.705s
[2K
| Adam | epoch: 012 | loss: 0.04798 - acc: 0.9800 -- iter: 0192/1033
[A[ATraining Step: 370  | total loss: [1m[32m0.05601[0m[0m | time: 4.337s
[2K
| Adam | epoch: 012 | loss: 0.05601 - acc: 0.9757 -- iter: 0224/1033
[A[ATraining Step: 371  | total loss: [1m[32m0.06587[0m[0m | time: 4.975s
[2K
| Adam | epoch: 012 | loss: 0.06587 - acc: 0.9719 -- iter: 0256/1033
[A[ATraining Step: 372  | total loss: [1m[32m0.06067[0m[0m | time: 5.594s
[2K
| Adam | epoch: 012 | loss: 0.06067 - acc: 0.9747 -- iter: 0288/1033
[A[ATraining Step: 373  | total loss: [1m[32m0.05507[0m[0m | time: 5.801s
[2K
| Adam | epoch: 012 | loss: 0.05507 - acc: 0.9772 -- iter: 0320/1033
[A[ATraining Step: 374  | total loss: [1m[32m0.05020[0m[0m | time: 6.030s
[2K
| Adam | epoch: 012 | loss: 0.05020 - acc: 0.9795 -- iter: 0352/1033
[A[ATraining Step: 375  | total loss: [1m[32m0.04569[0m[0m | time: 6.652s
[2K
| Adam | epoch: 012 | loss: 0.04569 - acc: 0.9816 -- iter: 0384/1033
[A[ATraining Step: 376  | total loss: [1m[32m0.05360[0m[0m | time: 7.258s
[2K
| Adam | epoch: 012 | loss: 0.05360 - acc: 0.9803 -- iter: 0416/1033
[A[ATraining Step: 377  | total loss: [1m[32m0.04909[0m[0m | time: 7.880s
[2K
| Adam | epoch: 012 | loss: 0.04909 - acc: 0.9823 -- iter: 0448/1033
[A[ATraining Step: 378  | total loss: [1m[32m0.04993[0m[0m | time: 8.492s
[2K
| Adam | epoch: 012 | loss: 0.04993 - acc: 0.9809 -- iter: 0480/1033
[A[ATraining Step: 379  | total loss: [1m[32m0.06008[0m[0m | time: 9.101s
[2K
| Adam | epoch: 012 | loss: 0.06008 - acc: 0.9797 -- iter: 0512/1033
[A[ATraining Step: 380  | total loss: [1m[32m0.05441[0m[0m | time: 9.733s
[2K
| Adam | epoch: 012 | loss: 0.05441 - acc: 0.9817 -- iter: 0544/1033
[A[ATraining Step: 381  | total loss: [1m[32m0.06727[0m[0m | time: 10.339s
[2K
| Adam | epoch: 012 | loss: 0.06727 - acc: 0.9804 -- iter: 0576/1033
[A[ATraining Step: 382  | total loss: [1m[32m0.06526[0m[0m | time: 10.949s
[2K
| Adam | epoch: 012 | loss: 0.06526 - acc: 0.9793 -- iter: 0608/1033
[A[ATraining Step: 383  | total loss: [1m[32m0.05906[0m[0m | time: 11.571s
[2K
| Adam | epoch: 012 | loss: 0.05906 - acc: 0.9813 -- iter: 0640/1033
[A[ATraining Step: 384  | total loss: [1m[32m0.05975[0m[0m | time: 12.174s
[2K
| Adam | epoch: 012 | loss: 0.05975 - acc: 0.9801 -- iter: 0672/1033
[A[ATraining Step: 385  | total loss: [1m[32m0.05464[0m[0m | time: 12.790s
[2K
| Adam | epoch: 012 | loss: 0.05464 - acc: 0.9821 -- iter: 0704/1033
[A[ATraining Step: 386  | total loss: [1m[32m0.05250[0m[0m | time: 13.417s
[2K
| Adam | epoch: 012 | loss: 0.05250 - acc: 0.9807 -- iter: 0736/1033
[A[ATraining Step: 387  | total loss: [1m[32m0.04741[0m[0m | time: 14.030s
[2K
| Adam | epoch: 012 | loss: 0.04741 - acc: 0.9827 -- iter: 0768/1033
[A[ATraining Step: 388  | total loss: [1m[32m0.04326[0m[0m | time: 14.645s
[2K
| Adam | epoch: 012 | loss: 0.04326 - acc: 0.9844 -- iter: 0800/1033
[A[ATraining Step: 389  | total loss: [1m[32m0.04008[0m[0m | time: 15.265s
[2K
| Adam | epoch: 012 | loss: 0.04008 - acc: 0.9860 -- iter: 0832/1033
[A[ATraining Step: 390  | total loss: [1m[32m0.03755[0m[0m | time: 15.892s
[2K
| Adam | epoch: 012 | loss: 0.03755 - acc: 0.9874 -- iter: 0864/1033
[A[ATraining Step: 391  | total loss: [1m[32m0.03431[0m[0m | time: 16.527s
[2K
| Adam | epoch: 012 | loss: 0.03431 - acc: 0.9886 -- iter: 0896/1033
[A[ATraining Step: 392  | total loss: [1m[32m0.03158[0m[0m | time: 17.143s
[2K
| Adam | epoch: 012 | loss: 0.03158 - acc: 0.9898 -- iter: 0928/1033
[A[ATraining Step: 393  | total loss: [1m[32m0.02929[0m[0m | time: 17.739s
[2K
| Adam | epoch: 012 | loss: 0.02929 - acc: 0.9908 -- iter: 0960/1033
[A[ATraining Step: 394  | total loss: [1m[32m0.02653[0m[0m | time: 18.388s
[2K
| Adam | epoch: 012 | loss: 0.02653 - acc: 0.9917 -- iter: 0992/1033
[A[ATraining Step: 395  | total loss: [1m[32m0.02429[0m[0m | time: 19.027s
[2K
| Adam | epoch: 012 | loss: 0.02429 - acc: 0.9925 -- iter: 1024/1033
[A[ATraining Step: 396  | total loss: [1m[32m0.02200[0m[0m | time: 20.725s
[2K
| Adam | epoch: 012 | loss: 0.02200 - acc: 0.9933 | val_loss: 0.15693 - val_acc: 0.9537 -- iter: 1033/1033
--
Training Step: 397  | total loss: [1m[32m0.02395[0m[0m | time: 0.634s
[2K
| Adam | epoch: 013 | loss: 0.02395 - acc: 0.9908 -- iter: 0032/1033
[A[ATraining Step: 398  | total loss: [1m[32m0.02216[0m[0m | time: 1.275s
[2K
| Adam | epoch: 013 | loss: 0.02216 - acc: 0.9917 -- iter: 0064/1033
[A[ATraining Step: 399  | total loss: [1m[32m0.02253[0m[0m | time: 1.878s
[2K
| Adam | epoch: 013 | loss: 0.02253 - acc: 0.9926 -- iter: 0096/1033
[A[ATraining Step: 400  | total loss: [1m[32m0.02081[0m[0m | time: 3.557s
[2K
| Adam | epoch: 013 | loss: 0.02081 - acc: 0.9933 | val_loss: 0.27257 - val_acc: 0.9259 -- iter: 0128/1033
--
Training Step: 401  | total loss: [1m[32m0.01936[0m[0m | time: 4.184s
[2K
| Adam | epoch: 013 | loss: 0.01936 - acc: 0.9940 -- iter: 0160/1033
[A[ATraining Step: 402  | total loss: [1m[32m0.03140[0m[0m | time: 4.813s
[2K
| Adam | epoch: 013 | loss: 0.03140 - acc: 0.9915 -- iter: 0192/1033
[A[ATraining Step: 403  | total loss: [1m[32m0.03488[0m[0m | time: 5.464s
[2K
| Adam | epoch: 013 | loss: 0.03488 - acc: 0.9892 -- iter: 0224/1033
[A[ATraining Step: 404  | total loss: [1m[32m0.03180[0m[0m | time: 6.119s
[2K
| Adam | epoch: 013 | loss: 0.03180 - acc: 0.9903 -- iter: 0256/1033
[A[ATraining Step: 405  | total loss: [1m[32m0.02888[0m[0m | time: 6.728s
[2K
| Adam | epoch: 013 | loss: 0.02888 - acc: 0.9912 -- iter: 0288/1033
[A[ATraining Step: 406  | total loss: [1m[32m0.02659[0m[0m | time: 7.349s
[2K
| Adam | epoch: 013 | loss: 0.02659 - acc: 0.9921 -- iter: 0320/1033
[A[ATraining Step: 407  | total loss: [1m[32m0.02758[0m[0m | time: 7.562s
[2K
| Adam | epoch: 013 | loss: 0.02758 - acc: 0.9898 -- iter: 0352/1033
[A[ATraining Step: 408  | total loss: [1m[32m0.02522[0m[0m | time: 7.769s
[2K
| Adam | epoch: 013 | loss: 0.02522 - acc: 0.9908 -- iter: 0384/1033
[A[ATraining Step: 409  | total loss: [1m[32m0.02311[0m[0m | time: 8.391s
[2K
| Adam | epoch: 013 | loss: 0.02311 - acc: 0.9917 -- iter: 0416/1033
[A[ATraining Step: 410  | total loss: [1m[32m0.06847[0m[0m | time: 9.024s
[2K
| Adam | epoch: 013 | loss: 0.06847 - acc: 0.9801 -- iter: 0448/1033
[A[ATraining Step: 411  | total loss: [1m[32m0.06325[0m[0m | time: 9.633s
[2K
| Adam | epoch: 013 | loss: 0.06325 - acc: 0.9820 -- iter: 0480/1033
[A[ATraining Step: 412  | total loss: [1m[32m0.05705[0m[0m | time: 10.250s
[2K
| Adam | epoch: 013 | loss: 0.05705 - acc: 0.9838 -- iter: 0512/1033
[A[ATraining Step: 413  | total loss: [1m[32m0.05579[0m[0m | time: 10.865s
[2K
| Adam | epoch: 013 | loss: 0.05579 - acc: 0.9823 -- iter: 0544/1033
[A[ATraining Step: 414  | total loss: [1m[32m0.05043[0m[0m | time: 11.498s
[2K
| Adam | epoch: 013 | loss: 0.05043 - acc: 0.9841 -- iter: 0576/1033
[A[ATraining Step: 415  | total loss: [1m[32m0.04667[0m[0m | time: 12.127s
[2K
| Adam | epoch: 013 | loss: 0.04667 - acc: 0.9857 -- iter: 0608/1033
[A[ATraining Step: 416  | total loss: [1m[32m0.06641[0m[0m | time: 12.751s
[2K
| Adam | epoch: 013 | loss: 0.06641 - acc: 0.9777 -- iter: 0640/1033
[A[ATraining Step: 417  | total loss: [1m[32m0.06160[0m[0m | time: 13.388s
[2K
| Adam | epoch: 013 | loss: 0.06160 - acc: 0.9800 -- iter: 0672/1033
[A[ATraining Step: 418  | total loss: [1m[32m0.05592[0m[0m | time: 14.011s
[2K
| Adam | epoch: 013 | loss: 0.05592 - acc: 0.9820 -- iter: 0704/1033
[A[ATraining Step: 419  | total loss: [1m[32m0.05420[0m[0m | time: 14.625s
[2K
| Adam | epoch: 013 | loss: 0.05420 - acc: 0.9807 -- iter: 0736/1033
[A[ATraining Step: 420  | total loss: [1m[32m0.04942[0m[0m | time: 15.254s
[2K
| Adam | epoch: 013 | loss: 0.04942 - acc: 0.9826 -- iter: 0768/1033
[A[ATraining Step: 421  | total loss: [1m[32m0.04489[0m[0m | time: 15.896s
[2K
| Adam | epoch: 013 | loss: 0.04489 - acc: 0.9843 -- iter: 0800/1033
[A[ATraining Step: 422  | total loss: [1m[32m0.04081[0m[0m | time: 16.537s
[2K
| Adam | epoch: 013 | loss: 0.04081 - acc: 0.9859 -- iter: 0832/1033
[A[ATraining Step: 423  | total loss: [1m[32m0.03729[0m[0m | time: 17.151s
[2K
| Adam | epoch: 013 | loss: 0.03729 - acc: 0.9873 -- iter: 0864/1033
[A[ATraining Step: 424  | total loss: [1m[32m0.03452[0m[0m | time: 17.791s
[2K
| Adam | epoch: 013 | loss: 0.03452 - acc: 0.9886 -- iter: 0896/1033
[A[ATraining Step: 425  | total loss: [1m[32m0.03140[0m[0m | time: 18.406s
[2K
| Adam | epoch: 013 | loss: 0.03140 - acc: 0.9897 -- iter: 0928/1033
[A[ATraining Step: 426  | total loss: [1m[32m0.03005[0m[0m | time: 19.013s
[2K
| Adam | epoch: 013 | loss: 0.03005 - acc: 0.9907 -- iter: 0960/1033
[A[ATraining Step: 427  | total loss: [1m[32m0.02747[0m[0m | time: 19.629s
[2K
| Adam | epoch: 013 | loss: 0.02747 - acc: 0.9917 -- iter: 0992/1033
[A[ATraining Step: 428  | total loss: [1m[32m0.02509[0m[0m | time: 20.254s
[2K
| Adam | epoch: 013 | loss: 0.02509 - acc: 0.9925 -- iter: 1024/1033
[A[ATraining Step: 429  | total loss: [1m[32m0.02322[0m[0m | time: 21.947s
[2K
| Adam | epoch: 013 | loss: 0.02322 - acc: 0.9933 | val_loss: 0.15401 - val_acc: 0.9537 -- iter: 1033/1033
--
Training Step: 430  | total loss: [1m[32m0.02253[0m[0m | time: 0.609s
[2K
| Adam | epoch: 014 | loss: 0.02253 - acc: 0.9939 -- iter: 0032/1033
[A[ATraining Step: 431  | total loss: [1m[32m0.02089[0m[0m | time: 1.243s
[2K
| Adam | epoch: 014 | loss: 0.02089 - acc: 0.9945 -- iter: 0064/1033
[A[ATraining Step: 432  | total loss: [1m[32m0.01961[0m[0m | time: 1.877s
[2K
| Adam | epoch: 014 | loss: 0.01961 - acc: 0.9951 -- iter: 0096/1033
[A[ATraining Step: 433  | total loss: [1m[32m0.01819[0m[0m | time: 2.493s
[2K
| Adam | epoch: 014 | loss: 0.01819 - acc: 0.9956 -- iter: 0128/1033
[A[ATraining Step: 434  | total loss: [1m[32m0.01674[0m[0m | time: 3.105s
[2K
| Adam | epoch: 014 | loss: 0.01674 - acc: 0.9960 -- iter: 0160/1033
[A[ATraining Step: 435  | total loss: [1m[32m0.01532[0m[0m | time: 3.723s
[2K
| Adam | epoch: 014 | loss: 0.01532 - acc: 0.9964 -- iter: 0192/1033
[A[ATraining Step: 436  | total loss: [1m[32m0.01545[0m[0m | time: 4.371s
[2K
| Adam | epoch: 014 | loss: 0.01545 - acc: 0.9968 -- iter: 0224/1033
[A[ATraining Step: 437  | total loss: [1m[32m0.01669[0m[0m | time: 4.991s
[2K
| Adam | epoch: 014 | loss: 0.01669 - acc: 0.9940 -- iter: 0256/1033
[A[ATraining Step: 438  | total loss: [1m[32m0.01559[0m[0m | time: 5.662s
[2K
| Adam | epoch: 014 | loss: 0.01559 - acc: 0.9946 -- iter: 0288/1033
[A[ATraining Step: 439  | total loss: [1m[32m0.03353[0m[0m | time: 6.340s
[2K
| Adam | epoch: 014 | loss: 0.03353 - acc: 0.9920 -- iter: 0320/1033
[A[ATraining Step: 440  | total loss: [1m[32m0.03047[0m[0m | time: 7.013s
[2K
| Adam | epoch: 014 | loss: 0.03047 - acc: 0.9928 -- iter: 0352/1033
[A[ATraining Step: 441  | total loss: [1m[32m0.02786[0m[0m | time: 7.260s
[2K
| Adam | epoch: 014 | loss: 0.02786 - acc: 0.9935 -- iter: 0384/1033
[A[ATraining Step: 442  | total loss: [1m[32m0.02516[0m[0m | time: 7.480s
[2K
| Adam | epoch: 014 | loss: 0.02516 - acc: 0.9942 -- iter: 0416/1033
[A[ATraining Step: 443  | total loss: [1m[32m0.02272[0m[0m | time: 8.148s
[2K
| Adam | epoch: 014 | loss: 0.02272 - acc: 0.9947 -- iter: 0448/1033
[A[ATraining Step: 444  | total loss: [1m[32m0.03963[0m[0m | time: 8.788s
[2K
| Adam | epoch: 014 | loss: 0.03963 - acc: 0.9921 -- iter: 0480/1033
[A[ATraining Step: 445  | total loss: [1m[32m0.03597[0m[0m | time: 9.405s
[2K
| Adam | epoch: 014 | loss: 0.03597 - acc: 0.9929 -- iter: 0512/1033
[A[ATraining Step: 446  | total loss: [1m[32m0.03305[0m[0m | time: 10.072s
[2K
| Adam | epoch: 014 | loss: 0.03305 - acc: 0.9936 -- iter: 0544/1033
[A[ATraining Step: 447  | total loss: [1m[32m0.03012[0m[0m | time: 10.746s
[2K
| Adam | epoch: 014 | loss: 0.03012 - acc: 0.9943 -- iter: 0576/1033
[A[ATraining Step: 448  | total loss: [1m[32m0.02778[0m[0m | time: 11.442s
[2K
| Adam | epoch: 014 | loss: 0.02778 - acc: 0.9948 -- iter: 0608/1033
[A[ATraining Step: 449  | total loss: [1m[32m0.02586[0m[0m | time: 12.112s
[2K
| Adam | epoch: 014 | loss: 0.02586 - acc: 0.9954 -- iter: 0640/1033
[A[ATraining Step: 450  | total loss: [1m[32m0.02426[0m[0m | time: 12.777s
[2K
| Adam | epoch: 014 | loss: 0.02426 - acc: 0.9958 -- iter: 0672/1033
[A[ATraining Step: 451  | total loss: [1m[32m0.02247[0m[0m | time: 13.446s
[2K
| Adam | epoch: 014 | loss: 0.02247 - acc: 0.9962 -- iter: 0704/1033
[A[ATraining Step: 452  | total loss: [1m[32m0.02061[0m[0m | time: 14.107s
[2K
| Adam | epoch: 014 | loss: 0.02061 - acc: 0.9966 -- iter: 0736/1033
[A[ATraining Step: 453  | total loss: [1m[32m0.01905[0m[0m | time: 14.762s
[2K
| Adam | epoch: 014 | loss: 0.01905 - acc: 0.9970 -- iter: 0768/1033
[A[ATraining Step: 454  | total loss: [1m[32m0.01760[0m[0m | time: 15.412s
[2K
| Adam | epoch: 014 | loss: 0.01760 - acc: 0.9973 -- iter: 0800/1033
[A[ATraining Step: 455  | total loss: [1m[32m0.01616[0m[0m | time: 16.051s
[2K
| Adam | epoch: 014 | loss: 0.01616 - acc: 0.9975 -- iter: 0832/1033
[A[ATraining Step: 456  | total loss: [1m[32m0.01498[0m[0m | time: 16.715s
[2K
| Adam | epoch: 014 | loss: 0.01498 - acc: 0.9978 -- iter: 0864/1033
[A[ATraining Step: 457  | total loss: [1m[32m0.01387[0m[0m | time: 17.387s
[2K
| Adam | epoch: 014 | loss: 0.01387 - acc: 0.9980 -- iter: 0896/1033
[A[ATraining Step: 458  | total loss: [1m[32m0.01350[0m[0m | time: 18.076s
[2K
| Adam | epoch: 014 | loss: 0.01350 - acc: 0.9982 -- iter: 0928/1033
[A[ATraining Step: 459  | total loss: [1m[32m0.01304[0m[0m | time: 18.743s
[2K
| Adam | epoch: 014 | loss: 0.01304 - acc: 0.9984 -- iter: 0960/1033
[A[ATraining Step: 460  | total loss: [1m[32m0.01197[0m[0m | time: 19.407s
[2K
| Adam | epoch: 014 | loss: 0.01197 - acc: 0.9985 -- iter: 0992/1033
[A[ATraining Step: 461  | total loss: [1m[32m0.01793[0m[0m | time: 20.085s
[2K
| Adam | epoch: 014 | loss: 0.01793 - acc: 0.9956 -- iter: 1024/1033
[A[ATraining Step: 462  | total loss: [1m[32m0.01640[0m[0m | time: 21.993s
[2K
| Adam | epoch: 014 | loss: 0.01640 - acc: 0.9960 | val_loss: 0.21346 - val_acc: 0.9444 -- iter: 1033/1033
--
Training Step: 463  | total loss: [1m[32m0.01545[0m[0m | time: 0.682s
[2K
| Adam | epoch: 015 | loss: 0.01545 - acc: 0.9964 -- iter: 0032/1033
[A[ATraining Step: 464  | total loss: [1m[32m0.01646[0m[0m | time: 1.378s
[2K
| Adam | epoch: 015 | loss: 0.01646 - acc: 0.9968 -- iter: 0064/1033
[A[ATraining Step: 465  | total loss: [1m[32m0.01733[0m[0m | time: 2.056s
[2K
| Adam | epoch: 015 | loss: 0.01733 - acc: 0.9971 -- iter: 0096/1033
[A[ATraining Step: 466  | total loss: [1m[32m0.01655[0m[0m | time: 2.711s
[2K
| Adam | epoch: 015 | loss: 0.01655 - acc: 0.9974 -- iter: 0128/1033
[A[ATraining Step: 467  | total loss: [1m[32m0.01523[0m[0m | time: 3.367s
[2K
| Adam | epoch: 015 | loss: 0.01523 - acc: 0.9976 -- iter: 0160/1033
[A[ATraining Step: 468  | total loss: [1m[32m0.01404[0m[0m | time: 4.074s
[2K
| Adam | epoch: 015 | loss: 0.01404 - acc: 0.9979 -- iter: 0192/1033
[A[ATraining Step: 469  | total loss: [1m[32m0.01347[0m[0m | time: 4.750s
[2K
| Adam | epoch: 015 | loss: 0.01347 - acc: 0.9981 -- iter: 0224/1033
[A[ATraining Step: 470  | total loss: [1m[32m0.01234[0m[0m | time: 5.443s
[2K
| Adam | epoch: 015 | loss: 0.01234 - acc: 0.9983 -- iter: 0256/1033
[A[ATraining Step: 471  | total loss: [1m[32m0.01141[0m[0m | time: 6.155s
[2K
| Adam | epoch: 015 | loss: 0.01141 - acc: 0.9985 -- iter: 0288/1033
[A[ATraining Step: 472  | total loss: [1m[32m0.01857[0m[0m | time: 6.831s
[2K
| Adam | epoch: 015 | loss: 0.01857 - acc: 0.9955 -- iter: 0320/1033
[A[ATraining Step: 473  | total loss: [1m[32m0.01682[0m[0m | time: 7.537s
[2K
| Adam | epoch: 015 | loss: 0.01682 - acc: 0.9959 -- iter: 0352/1033
[A[ATraining Step: 474  | total loss: [1m[32m0.01532[0m[0m | time: 8.182s
[2K
| Adam | epoch: 015 | loss: 0.01532 - acc: 0.9963 -- iter: 0384/1033
[A[ATraining Step: 475  | total loss: [1m[32m0.01389[0m[0m | time: 8.395s
[2K
| Adam | epoch: 015 | loss: 0.01389 - acc: 0.9967 -- iter: 0416/1033
[A[ATraining Step: 476  | total loss: [1m[32m0.01263[0m[0m | time: 8.630s
[2K
| Adam | epoch: 015 | loss: 0.01263 - acc: 0.9970 -- iter: 0448/1033
[A[ATraining Step: 477  | total loss: [1m[32m0.01149[0m[0m | time: 9.328s
[2K
| Adam | epoch: 015 | loss: 0.01149 - acc: 0.9973 -- iter: 0480/1033
[A[ATraining Step: 478  | total loss: [1m[32m0.01044[0m[0m | time: 10.011s
[2K
| Adam | epoch: 015 | loss: 0.01044 - acc: 0.9976 -- iter: 0512/1033
[A[ATraining Step: 479  | total loss: [1m[32m0.00952[0m[0m | time: 10.695s
[2K
| Adam | epoch: 015 | loss: 0.00952 - acc: 0.9978 -- iter: 0544/1033
[A[ATraining Step: 480  | total loss: [1m[32m0.00867[0m[0m | time: 11.362s
[2K
| Adam | epoch: 015 | loss: 0.00867 - acc: 0.9981 -- iter: 0576/1033
[A[ATraining Step: 481  | total loss: [1m[32m0.00811[0m[0m | time: 12.067s
[2K
| Adam | epoch: 015 | loss: 0.00811 - acc: 0.9983 -- iter: 0608/1033
[A[ATraining Step: 482  | total loss: [1m[32m0.00743[0m[0m | time: 12.735s
[2K
| Adam | epoch: 015 | loss: 0.00743 - acc: 0.9984 -- iter: 0640/1033
[A[ATraining Step: 483  | total loss: [1m[32m0.02755[0m[0m | time: 13.414s
[2K
| Adam | epoch: 015 | loss: 0.02755 - acc: 0.9955 -- iter: 0672/1033
[A[ATraining Step: 484  | total loss: [1m[32m0.02490[0m[0m | time: 14.097s
[2K
| Adam | epoch: 015 | loss: 0.02490 - acc: 0.9959 -- iter: 0704/1033
[A[ATraining Step: 485  | total loss: [1m[32m0.02253[0m[0m | time: 14.773s
[2K
| Adam | epoch: 015 | loss: 0.02253 - acc: 0.9963 -- iter: 0736/1033
[A[ATraining Step: 486  | total loss: [1m[32m0.02099[0m[0m | time: 15.414s
[2K
| Adam | epoch: 015 | loss: 0.02099 - acc: 0.9967 -- iter: 0768/1033
[A[ATraining Step: 487  | total loss: [1m[32m0.01895[0m[0m | time: 16.094s
[2K
| Adam | epoch: 015 | loss: 0.01895 - acc: 0.9970 -- iter: 0800/1033
[A[ATraining Step: 488  | total loss: [1m[32m0.01715[0m[0m | time: 16.781s
[2K
| Adam | epoch: 015 | loss: 0.01715 - acc: 0.9973 -- iter: 0832/1033
[A[ATraining Step: 489  | total loss: [1m[32m0.01815[0m[0m | time: 17.436s
[2K
| Adam | epoch: 015 | loss: 0.01815 - acc: 0.9945 -- iter: 0864/1033
[A[ATraining Step: 490  | total loss: [1m[32m0.01954[0m[0m | time: 18.088s
[2K
| Adam | epoch: 015 | loss: 0.01954 - acc: 0.9950 -- iter: 0896/1033
[A[ATraining Step: 491  | total loss: [1m[32m0.01776[0m[0m | time: 18.753s
[2K
| Adam | epoch: 015 | loss: 0.01776 - acc: 0.9955 -- iter: 0928/1033
[A[ATraining Step: 492  | total loss: [1m[32m0.01613[0m[0m | time: 19.438s
[2K
| Adam | epoch: 015 | loss: 0.01613 - acc: 0.9960 -- iter: 0960/1033
[A[ATraining Step: 493  | total loss: [1m[32m0.01474[0m[0m | time: 20.126s
[2K
| Adam | epoch: 015 | loss: 0.01474 - acc: 0.9964 -- iter: 0992/1033
[A[ATraining Step: 494  | total loss: [1m[32m0.01337[0m[0m | time: 20.803s
[2K
| Adam | epoch: 015 | loss: 0.01337 - acc: 0.9967 -- iter: 1024/1033
[A[ATraining Step: 495  | total loss: [1m[32m0.01393[0m[0m | time: 22.658s
[2K
| Adam | epoch: 015 | loss: 0.01393 - acc: 0.9971 | val_loss: 0.14374 - val_acc: 0.9537 -- iter: 1033/1033
--
Validation AUC:0.9901335995085996
Validation AUPRC:0.9887790746578642
Test AUC:0.9926369339045287
Test AUPRC:0.9934715429790294
BestTestF1Score	0.97	0.94	0.97	0.98	0.97	166	4	148	6	0.56
BestTestMCCScore	0.96	0.92	0.96	0.98	0.94	162	3	149	10	0.83
BestTestAccuracyScore	0.96	0.92	0.96	0.98	0.94	162	3	149	10	0.83
BestValidationF1Score	0.96	0.92	0.96	0.96	0.95	141	6	170	7	0.56
BestValidationMCC	0.96	0.92	0.96	0.98	0.93	138	3	173	10	0.83
BestValidationAccuracy	0.96	0.92	0.96	0.98	0.93	138	3	173	10	0.83
TestPredictions (Threshold:0.83)
CHEMBL169279,TP,ACT,1.0	CHEMBL422333,TP,ACT,1.0	CHEMBL136911,TP,ACT,1.0	CHEMBL110053,TN,INACT,0.0	CHEMBL136465,TP,ACT,1.0	CHEMBL608813,TN,INACT,0.0	CHEMBL283292,TP,ACT,1.0	CHEMBL89689,TN,INACT,0.009999999776482582	CHEMBL2372075,TN,INACT,0.07999999821186066	CHEMBL121872,TP,ACT,1.0	CHEMBL51622,TP,ACT,1.0	CHEMBL175698,TN,INACT,0.0	CHEMBL603858,TN,INACT,0.0	CHEMBL338888,TP,ACT,1.0	CHEMBL327791,TP,ACT,1.0	CHEMBL594801,TN,INACT,0.0	CHEMBL106487,TN,INACT,0.0	CHEMBL25075,TP,ACT,1.0	CHEMBL202861,TN,INACT,0.0	CHEMBL259131,TN,INACT,0.0	CHEMBL9746,TN,INACT,0.0	CHEMBL293949,FN,ACT,0.47999998927116394	CHEMBL293874,TN,INACT,0.0	CHEMBL71388,TP,ACT,1.0	CHEMBL269576,TN,INACT,0.0	CHEMBL169889,TN,INACT,0.0	CHEMBL197159,TN,INACT,0.0	CHEMBL2425138,TP,ACT,1.0	CHEMBL422200,TP,ACT,1.0	CHEMBL262787,TN,INACT,0.0	CHEMBL60071,TP,ACT,0.9200000166893005	CHEMBL2237608,TP,ACT,1.0	CHEMBL62744,TP,ACT,0.9900000095367432	CHEMBL327626,TN,INACT,0.0	CHEMBL367095,TP,ACT,0.9900000095367432	CHEMBL29853,TP,ACT,0.9599999785423279	CHEMBL3735492,TP,ACT,0.9700000286102295	CHEMBL343142,TP,ACT,1.0	CHEMBL294649,TN,INACT,0.0	CHEMBL110064,TN,INACT,0.0	CHEMBL167584,TP,ACT,1.0	CHEMBL15458,TP,ACT,1.0	CHEMBL40381,TP,ACT,1.0	CHEMBL353502,TN,INACT,0.0	CHEMBL1098359,TN,INACT,0.09000000357627869	CHEMBL440961,TN,INACT,0.0	CHEMBL89688,TN,INACT,0.0	CHEMBL138358,TP,ACT,1.0	CHEMBL302519,FN,ACT,0.6200000047683716	CHEMBL1263,TN,INACT,0.0	CHEMBL157577,TP,ACT,1.0	CHEMBL37919,TP,ACT,1.0	CHEMBL157203,TP,ACT,1.0	CHEMBL461087,TN,INACT,0.0	CHEMBL552615,TN,INACT,0.0	CHEMBL431411,TP,ACT,1.0	CHEMBL308238,FN,ACT,0.6299999952316284	CHEMBL61120,TN,INACT,0.0	CHEMBL418354,FN,ACT,0.25	CHEMBL351531,TN,INACT,0.0	CHEMBL352925,TN,INACT,0.0	CHEMBL304947,TP,ACT,0.8899999856948853	CHEMBL259843,TP,ACT,1.0	CHEMBL29512,TP,ACT,1.0	CHEMBL155992,TP,ACT,1.0	CHEMBL38861,TN,INACT,0.0	CHEMBL274710,TP,ACT,1.0	CHEMBL307659,TN,INACT,0.0	CHEMBL2237584,TP,ACT,1.0	CHEMBL245319,TN,INACT,0.009999999776482582	CHEMBL122157,TP,ACT,1.0	CHEMBL30015,TP,ACT,1.0	CHEMBL68786,FN,ACT,0.7099999785423279	CHEMBL345459,TP,ACT,0.9800000190734863	CHEMBL328925,TN,INACT,0.0	CHEMBL24861,TP,ACT,1.0	CHEMBL357077,TN,INACT,0.0	CHEMBL154531,TP,ACT,1.0	CHEMBL411487,TP,ACT,1.0	CHEMBL45269,TN,INACT,0.0	CHEMBL155154,TP,ACT,1.0	CHEMBL352639,TP,ACT,1.0	CHEMBL56549,TP,ACT,1.0	CHEMBL36218,TP,ACT,1.0	CHEMBL292939,TN,INACT,0.7900000214576721	CHEMBL98453,TP,ACT,1.0	CHEMBL26514,TP,ACT,1.0	CHEMBL323175,TN,INACT,0.0	CHEMBL3577344,TN,INACT,0.0	CHEMBL133257,TN,INACT,0.0	CHEMBL2164434,TN,INACT,0.0	CHEMBL319387,TN,INACT,0.0	CHEMBL154068,TN,INACT,0.0	CHEMBL298612,TN,INACT,0.0	CHEMBL437842,TN,INACT,0.0	CHEMBL89457,TN,INACT,0.0	CHEMBL345570,TP,ACT,1.0	CHEMBL246585,FP,INACT,0.9900000095367432	CHEMBL72710,TN,INACT,0.0	CHEMBL112314,TN,INACT,0.0	CHEMBL343309,TP,ACT,1.0	CHEMBL322537,TN,INACT,0.0	CHEMBL344466,FN,ACT,0.05000000074505806	CHEMBL156449,TP,ACT,1.0	CHEMBL78642,TN,INACT,0.0	CHEMBL327191,TP,ACT,1.0	CHEMBL429238,TN,INACT,0.44999998807907104	CHEMBL29734,TP,ACT,1.0	CHEMBL3393999,TN,INACT,0.0	CHEMBL86255,TP,ACT,1.0	CHEMBL1091790,TN,INACT,0.0	CHEMBL321313,TP,ACT,1.0	CHEMBL139041,TP,ACT,1.0	CHEMBL284764,TP,ACT,0.8799999952316284	CHEMBL87513,TP,ACT,1.0	CHEMBL227429,TN,INACT,0.0	CHEMBL349856,TP,ACT,1.0	CHEMBL3735446,TP,ACT,1.0	CHEMBL129198,TN,INACT,0.0	CHEMBL104223,TN,INACT,0.05000000074505806	CHEMBL28917,TP,ACT,1.0	CHEMBL7550,TP,ACT,1.0	CHEMBL99331,TN,INACT,0.0	CHEMBL25585,TP,ACT,1.0	CHEMBL78830,TN,INACT,0.0	CHEMBL48799,TP,ACT,0.9800000190734863	CHEMBL302027,TN,INACT,0.0	CHEMBL434284,TN,INACT,0.0	CHEMBL344154,TN,INACT,0.0	CHEMBL130861,TN,INACT,0.0	CHEMBL30086,TP,ACT,1.0	CHEMBL94910,TP,ACT,1.0	CHEMBL47382,TP,ACT,1.0	CHEMBL78853,TN,INACT,0.0	CHEMBL3735036,FP,INACT,1.0	CHEMBL87392,TP,ACT,1.0	CHEMBL241080,TN,INACT,0.0	CHEMBL108981,TP,ACT,1.0	CHEMBL282426,TN,INACT,0.0	CHEMBL421473,TP,ACT,1.0	CHEMBL155661,TP,ACT,1.0	CHEMBL282236,TP,ACT,0.9800000190734863	CHEMBL289640,TP,ACT,1.0	CHEMBL535602,TN,INACT,0.019999999552965164	CHEMBL537834,TN,INACT,0.0	CHEMBL394642,TN,INACT,0.0	CHEMBL93907,TP,ACT,1.0	CHEMBL289284,TN,INACT,0.49000000953674316	CHEMBL318891,TP,ACT,1.0	CHEMBL59733,TN,INACT,0.0	CHEMBL112777,TN,INACT,0.029999999329447746	CHEMBL165541,TP,ACT,1.0	CHEMBL352502,TP,ACT,1.0	CHEMBL593685,TN,INACT,0.0	CHEMBL2237585,TP,ACT,1.0	CHEMBL2203713,TN,INACT,0.0	CHEMBL42065,TN,INACT,0.0	CHEMBL85765,TP,ACT,0.9900000095367432	CHEMBL321086,TP,ACT,1.0	CHEMBL2237600,TP,ACT,1.0	CHEMBL337588,TP,ACT,1.0	CHEMBL62421,TN,INACT,0.0	CHEMBL305647,TP,ACT,1.0	CHEMBL436396,TP,ACT,1.0	CHEMBL107574,TN,INACT,0.0	CHEMBL307430,TP,ACT,1.0	CHEMBL306362,TP,ACT,1.0	CHEMBL205768,TN,INACT,0.23999999463558197	CHEMBL110695,TN,INACT,0.0	CHEMBL240001,TN,INACT,0.0	CHEMBL441837,TP,ACT,1.0	CHEMBL29722,TP,ACT,1.0	CHEMBL315776,TP,ACT,1.0	CHEMBL329858,TP,ACT,1.0	CHEMBL3665433,TN,INACT,0.0	CHEMBL308414,TN,INACT,0.029999999329447746	CHEMBL278305,TP,ACT,1.0	CHEMBL2237595,TP,ACT,1.0	CHEMBL40585,TP,ACT,1.0	CHEMBL110265,TP,ACT,1.0	CHEMBL2093084,TN,INACT,0.0	CHEMBL322471,TP,ACT,1.0	CHEMBL311386,TP,ACT,1.0	CHEMBL149763,TN,INACT,0.0	CHEMBL48459,TP,ACT,1.0	CHEMBL48868,TP,ACT,0.9700000286102295	CHEMBL302829,TN,INACT,0.0	CHEMBL287253,FN,ACT,0.8199999928474426	CHEMBL80532,TN,INACT,0.0	CHEMBL408798,TP,ACT,0.9700000286102295	CHEMBL46195,TN,INACT,0.0	CHEMBL46392,TP,ACT,1.0	CHEMBL3633656,TN,INACT,0.009999999776482582	CHEMBL310427,TN,INACT,0.0	CHEMBL160932,TN,INACT,0.0	CHEMBL43330,TN,INACT,0.0	CHEMBL323951,TN,INACT,0.0	CHEMBL287250,TP,ACT,1.0	CHEMBL48031,TN,INACT,0.0	CHEMBL3810142,TN,INACT,0.0	CHEMBL1765667,TN,INACT,0.0	CHEMBL27903,TP,ACT,1.0	CHEMBL98014,TN,INACT,0.0	CHEMBL95579,TP,ACT,1.0	CHEMBL345404,TP,ACT,1.0	CHEMBL241082,TN,INACT,0.0	CHEMBL3735744,TP,ACT,1.0	CHEMBL166428,TP,ACT,1.0	CHEMBL2373213,TN,INACT,0.0	CHEMBL422932,TP,ACT,1.0	CHEMBL7441,TN,INACT,0.0	CHEMBL291582,TP,ACT,1.0	CHEMBL320763,TN,INACT,0.0	CHEMBL26548,TP,ACT,1.0	CHEMBL291821,TN,INACT,0.0	CHEMBL155305,TP,ACT,1.0	CHEMBL279103,TP,ACT,0.9900000095367432	CHEMBL174463,TN,INACT,0.0	CHEMBL177546,TN,INACT,0.009999999776482582	CHEMBL164617,TP,ACT,0.9900000095367432	CHEMBL301826,TN,INACT,0.0	CHEMBL1667998,TP,ACT,1.0	CHEMBL352235,TP,ACT,1.0	CHEMBL97688,TP,ACT,1.0	CHEMBL86084,TP,ACT,1.0	CHEMBL284969,TN,INACT,0.029999999329447746	CHEMBL25315,TP,ACT,1.0	CHEMBL169968,TP,ACT,1.0	CHEMBL339806,TP,ACT,1.0	CHEMBL286800,TN,INACT,0.0	CHEMBL262296,TP,ACT,1.0	CHEMBL150260,TN,INACT,0.0	CHEMBL300438,TP,ACT,1.0	CHEMBL95955,TP,ACT,1.0	CHEMBL71925,TP,ACT,0.9900000095367432	CHEMBL98140,TP,ACT,1.0	CHEMBL2112592,TN,INACT,0.0	CHEMBL156408,TP,ACT,1.0	CHEMBL1259071,TN,INACT,0.0	CHEMBL345127,TP,ACT,1.0	CHEMBL423801,TP,ACT,0.9900000095367432	CHEMBL104551,TN,INACT,0.0	CHEMBL312958,TN,INACT,0.0	CHEMBL158196,TP,ACT,1.0	CHEMBL123208,TP,ACT,1.0	CHEMBL317547,TP,ACT,1.0	CHEMBL1916635,FP,INACT,0.9800000190734863	CHEMBL15517,TP,ACT,1.0	CHEMBL444065,TP,ACT,1.0	CHEMBL314812,TP,ACT,1.0	CHEMBL50109,TP,ACT,1.0	CHEMBL254500,TN,INACT,0.009999999776482582	CHEMBL437,TN,INACT,0.0	CHEMBL64674,FN,ACT,0.3400000035762787	CHEMBL26277,TP,ACT,1.0	CHEMBL86613,TP,ACT,1.0	CHEMBL49848,TP,ACT,1.0	CHEMBL2370511,TN,INACT,0.0	CHEMBL62703,TN,INACT,0.0	CHEMBL431172,TN,INACT,0.0	CHEMBL3238446,TN,INACT,0.0	CHEMBL40796,TN,INACT,0.0	CHEMBL449648,TP,ACT,1.0	CHEMBL106259,TN,INACT,0.5299999713897705	CHEMBL44615,TN,INACT,0.0	CHEMBL25313,TP,ACT,1.0	CHEMBL435784,TN,INACT,0.14000000059604645	CHEMBL103828,TN,INACT,0.0	CHEMBL281890,TP,ACT,0.9800000190734863	CHEMBL339040,TP,ACT,1.0	CHEMBL125218,TP,ACT,1.0	CHEMBL347392,TP,ACT,1.0	CHEMBL299538,TN,INACT,0.09000000357627869	CHEMBL344602,TN,INACT,0.0	CHEMBL112417,TN,INACT,0.0	CHEMBL158133,TP,ACT,0.9900000095367432	CHEMBL288618,TP,ACT,0.9900000095367432	CHEMBL321367,TP,ACT,1.0	CHEMBL68111,TP,ACT,0.9900000095367432	CHEMBL1201353,TN,INACT,0.0	CHEMBL3354069,TN,INACT,0.0	CHEMBL313579,TP,ACT,1.0	CHEMBL158795,TP,ACT,1.0	CHEMBL111218,TN,INACT,0.0	CHEMBL337787,TP,ACT,0.9900000095367432	CHEMBL432392,TP,ACT,1.0	CHEMBL108417,TN,INACT,0.0	CHEMBL29658,TP,ACT,1.0	CHEMBL1923416,TN,INACT,0.0	CHEMBL462650,TN,INACT,0.029999999329447746	CHEMBL76779,TN,INACT,0.0	CHEMBL141051,TN,INACT,0.03999999910593033	CHEMBL2042400,TN,INACT,0.0	CHEMBL263038,FN,ACT,0.0	CHEMBL320222,TP,ACT,1.0	CHEMBL165349,TP,ACT,1.0	CHEMBL451335,TN,INACT,0.0	CHEMBL49952,TP,ACT,0.9900000095367432	CHEMBL278234,TP,ACT,0.9700000286102295	CHEMBL2435818,FN,ACT,0.0	CHEMBL151619,TN,INACT,0.07000000029802322	CHEMBL3665441,TN,INACT,0.0	CHEMBL345696,TP,ACT,1.0	CHEMBL298203,TN,INACT,0.009999999776482582	CHEMBL3290984,TN,INACT,0.0	CHEMBL294087,TN,INACT,0.0	CHEMBL62804,TN,INACT,0.0	CHEMBL324629,TP,ACT,1.0	CHEMBL143539,TN,INACT,0.0	CHEMBL87057,TP,ACT,1.0	CHEMBL3217760,TN,INACT,0.03999999910593033	CHEMBL312266,TN,INACT,0.0	CHEMBL19018,TP,ACT,1.0	CHEMBL2163917,TN,INACT,0.0	CHEMBL72841,TN,INACT,0.0	CHEMBL391191,TN,INACT,0.0	CHEMBL156084,TP,ACT,1.0	CHEMBL122273,TP,ACT,1.0	CHEMBL3335536,TN,INACT,0.0	CHEMBL211696,TN,INACT,0.0	CHEMBL157185,TP,ACT,1.0	CHEMBL172788,TN,INACT,0.0	CHEMBL15669,TP,ACT,0.8899999856948853	CHEMBL420359,TN,INACT,0.0	

