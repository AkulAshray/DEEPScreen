CNNModel CHEMBL231 RMSprop 0.0005 30 256 0 0.6 False True
Number of active compounds :	906
Number of inactive compounds :	906
---------------------------------
Run id: CNNModel_CHEMBL231_RMSprop_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL231_RMSprop_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 1133
Validation samples: 355
--
Training Step: 1  | time: 0.829s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1133
[A[ATraining Step: 2  | total loss: [1m[32m0.62367[0m[0m | time: 1.478s
[2K
| RMSProp | epoch: 001 | loss: 0.62367 - acc: 0.4500 -- iter: 0064/1133
[A[ATraining Step: 3  | total loss: [1m[32m0.68050[0m[0m | time: 2.151s
[2K
| RMSProp | epoch: 001 | loss: 0.68050 - acc: 0.4909 -- iter: 0096/1133
[A[ATraining Step: 4  | total loss: [1m[32m0.68989[0m[0m | time: 3.208s
[2K
| RMSProp | epoch: 001 | loss: 0.68989 - acc: 0.4743 -- iter: 0128/1133
[A[ATraining Step: 5  | total loss: [1m[32m0.69217[0m[0m | time: 4.369s
[2K
| RMSProp | epoch: 001 | loss: 0.69217 - acc: 0.4272 -- iter: 0160/1133
[A[ATraining Step: 6  | total loss: [1m[32m0.69282[0m[0m | time: 5.345s
[2K
| RMSProp | epoch: 001 | loss: 0.69282 - acc: 0.4740 -- iter: 0192/1133
[A[ATraining Step: 7  | total loss: [1m[32m0.69294[0m[0m | time: 6.126s
[2K
| RMSProp | epoch: 001 | loss: 0.69294 - acc: 0.5271 -- iter: 0224/1133
[A[ATraining Step: 8  | total loss: [1m[32m0.69308[0m[0m | time: 7.027s
[2K
| RMSProp | epoch: 001 | loss: 0.69308 - acc: 0.5294 -- iter: 0256/1133
[A[ATraining Step: 9  | total loss: [1m[32m0.69313[0m[0m | time: 7.962s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4973 -- iter: 0288/1133
[A[ATraining Step: 10  | total loss: [1m[32m0.69320[0m[0m | time: 8.827s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.5143 -- iter: 0320/1133
[A[ATraining Step: 11  | total loss: [1m[32m0.69311[0m[0m | time: 9.709s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.4927 -- iter: 0352/1133
[A[ATraining Step: 12  | total loss: [1m[32m0.69306[0m[0m | time: 10.623s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.4960 -- iter: 0384/1133
[A[ATraining Step: 13  | total loss: [1m[32m0.69311[0m[0m | time: 11.536s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.4441 -- iter: 0416/1133
[A[ATraining Step: 14  | total loss: [1m[32m0.69307[0m[0m | time: 12.498s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5181 -- iter: 0448/1133
[A[ATraining Step: 15  | total loss: [1m[32m0.69299[0m[0m | time: 13.415s
[2K
| RMSProp | epoch: 001 | loss: 0.69299 - acc: 0.5599 -- iter: 0480/1133
[A[ATraining Step: 16  | total loss: [1m[32m0.69301[0m[0m | time: 14.239s
[2K
| RMSProp | epoch: 001 | loss: 0.69301 - acc: 0.5375 -- iter: 0512/1133
[A[ATraining Step: 17  | total loss: [1m[32m0.69301[0m[0m | time: 15.470s
[2K
| RMSProp | epoch: 001 | loss: 0.69301 - acc: 0.5577 -- iter: 0544/1133
[A[ATraining Step: 18  | total loss: [1m[32m0.69304[0m[0m | time: 16.603s
[2K
| RMSProp | epoch: 001 | loss: 0.69304 - acc: 0.5269 -- iter: 0576/1133
[A[ATraining Step: 19  | total loss: [1m[32m0.69313[0m[0m | time: 17.481s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4971 -- iter: 0608/1133
[A[ATraining Step: 20  | total loss: [1m[32m0.69310[0m[0m | time: 18.288s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5181 -- iter: 0640/1133
[A[ATraining Step: 21  | total loss: [1m[32m0.69315[0m[0m | time: 19.182s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.4834 -- iter: 0672/1133
[A[ATraining Step: 22  | total loss: [1m[32m0.69323[0m[0m | time: 20.119s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4603 -- iter: 0704/1133
[A[ATraining Step: 23  | total loss: [1m[32m0.69312[0m[0m | time: 21.010s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.5081 -- iter: 0736/1133
[A[ATraining Step: 24  | total loss: [1m[32m0.69310[0m[0m | time: 21.902s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.4970 -- iter: 0768/1133
[A[ATraining Step: 25  | total loss: [1m[32m0.69318[0m[0m | time: 22.821s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4637 -- iter: 0800/1133
[A[ATraining Step: 26  | total loss: [1m[32m0.69320[0m[0m | time: 23.741s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4733 -- iter: 0832/1133
[A[ATraining Step: 27  | total loss: [1m[32m0.69308[0m[0m | time: 24.704s
[2K
| RMSProp | epoch: 001 | loss: 0.69308 - acc: 0.5043 -- iter: 0864/1133
[A[ATraining Step: 28  | total loss: [1m[32m0.69310[0m[0m | time: 25.566s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.4954 -- iter: 0896/1133
[A[ATraining Step: 29  | total loss: [1m[32m0.69309[0m[0m | time: 26.552s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5193 -- iter: 0928/1133
[A[ATraining Step: 30  | total loss: [1m[32m0.69302[0m[0m | time: 27.705s
[2K
| RMSProp | epoch: 001 | loss: 0.69302 - acc: 0.5296 -- iter: 0960/1133
[A[ATraining Step: 31  | total loss: [1m[32m0.69305[0m[0m | time: 28.877s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.5372 -- iter: 0992/1133
[A[ATraining Step: 32  | total loss: [1m[32m0.69313[0m[0m | time: 29.620s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5077 -- iter: 1024/1133
[A[ATraining Step: 33  | total loss: [1m[32m0.69317[0m[0m | time: 30.544s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4923 -- iter: 1056/1133
[A[ATraining Step: 34  | total loss: [1m[32m0.69317[0m[0m | time: 31.473s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5006 -- iter: 1088/1133
[A[ATraining Step: 35  | total loss: [1m[32m0.69313[0m[0m | time: 32.416s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5398 -- iter: 1120/1133
[A[ATraining Step: 36  | total loss: [1m[32m0.69307[0m[0m | time: 34.814s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5444 | val_loss: 0.69315 - val_acc: 0.4986 -- iter: 1133/1133
--
Training Step: 37  | total loss: [1m[32m0.69297[0m[0m | time: 0.518s
[2K
| RMSProp | epoch: 002 | loss: 0.69297 - acc: 0.5894 -- iter: 0032/1133
[A[ATraining Step: 38  | total loss: [1m[32m0.69304[0m[0m | time: 1.620s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5794 -- iter: 0064/1133
[A[ATraining Step: 39  | total loss: [1m[32m0.69321[0m[0m | time: 2.572s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.5283 -- iter: 0096/1133
[A[ATraining Step: 40  | total loss: [1m[32m0.69324[0m[0m | time: 3.323s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4996 -- iter: 0128/1133
[A[ATraining Step: 41  | total loss: [1m[32m0.69332[0m[0m | time: 4.129s
[2K
| RMSProp | epoch: 002 | loss: 0.69332 - acc: 0.4824 -- iter: 0160/1133
[A[ATraining Step: 42  | total loss: [1m[32m0.69333[0m[0m | time: 5.040s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.4631 -- iter: 0192/1133
[A[ATraining Step: 43  | total loss: [1m[32m0.69331[0m[0m | time: 5.919s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4531 -- iter: 0224/1133
[A[ATraining Step: 44  | total loss: [1m[32m0.69329[0m[0m | time: 6.837s
[2K
| RMSProp | epoch: 002 | loss: 0.69329 - acc: 0.4666 -- iter: 0256/1133
[A[ATraining Step: 45  | total loss: [1m[32m0.69323[0m[0m | time: 7.780s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4935 -- iter: 0288/1133
[A[ATraining Step: 46  | total loss: [1m[32m0.69334[0m[0m | time: 8.669s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4633 -- iter: 0320/1133
[A[ATraining Step: 47  | total loss: [1m[32m0.69331[0m[0m | time: 9.635s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4847 -- iter: 0352/1133
[A[ATraining Step: 48  | total loss: [1m[32m0.69332[0m[0m | time: 10.487s
[2K
| RMSProp | epoch: 002 | loss: 0.69332 - acc: 0.4721 -- iter: 0384/1133
[A[ATraining Step: 49  | total loss: [1m[32m0.69338[0m[0m | time: 11.398s
[2K
| RMSProp | epoch: 002 | loss: 0.69338 - acc: 0.4419 -- iter: 0416/1133
[A[ATraining Step: 50  | total loss: [1m[32m0.69334[0m[0m | time: 12.538s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4509 -- iter: 0448/1133
[A[ATraining Step: 51  | total loss: [1m[32m0.69324[0m[0m | time: 13.612s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4775 -- iter: 0480/1133
[A[ATraining Step: 52  | total loss: [1m[32m0.69318[0m[0m | time: 14.380s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4949 -- iter: 0512/1133
[A[ATraining Step: 53  | total loss: [1m[32m0.69322[0m[0m | time: 15.245s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4865 -- iter: 0544/1133
[A[ATraining Step: 54  | total loss: [1m[32m0.69319[0m[0m | time: 16.141s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4884 -- iter: 0576/1133
[A[ATraining Step: 55  | total loss: [1m[32m0.69322[0m[0m | time: 17.062s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4812 -- iter: 0608/1133
[A[ATraining Step: 56  | total loss: [1m[32m0.69320[0m[0m | time: 17.959s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4926 -- iter: 0640/1133
[A[ATraining Step: 57  | total loss: [1m[32m0.69321[0m[0m | time: 18.878s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4893 -- iter: 0672/1133
[A[ATraining Step: 58  | total loss: [1m[32m0.69318[0m[0m | time: 19.877s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.5035 -- iter: 0704/1133
[A[ATraining Step: 59  | total loss: [1m[32m0.69323[0m[0m | time: 20.818s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4905 -- iter: 0736/1133
[A[ATraining Step: 60  | total loss: [1m[32m0.69324[0m[0m | time: 21.705s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4876 -- iter: 0768/1133
[A[ATraining Step: 61  | total loss: [1m[32m0.69323[0m[0m | time: 22.619s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4933 -- iter: 0800/1133
[A[ATraining Step: 62  | total loss: [1m[32m0.69325[0m[0m | time: 23.818s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4821 -- iter: 0832/1133
[A[ATraining Step: 63  | total loss: [1m[32m0.69323[0m[0m | time: 24.927s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4883 -- iter: 0864/1133
[A[ATraining Step: 64  | total loss: [1m[32m0.69328[0m[0m | time: 25.654s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4742 -- iter: 0896/1133
[A[ATraining Step: 65  | total loss: [1m[32m0.69327[0m[0m | time: 26.520s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.4696 -- iter: 0928/1133
[A[ATraining Step: 66  | total loss: [1m[32m0.69323[0m[0m | time: 27.502s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4885 -- iter: 0960/1133
[A[ATraining Step: 67  | total loss: [1m[32m0.69319[0m[0m | time: 28.397s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4937 -- iter: 0992/1133
[A[ATraining Step: 68  | total loss: [1m[32m0.69317[0m[0m | time: 29.259s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4981 -- iter: 1024/1133
[A[ATraining Step: 69  | total loss: [1m[32m0.69320[0m[0m | time: 30.157s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4874 -- iter: 1056/1133
[A[ATraining Step: 70  | total loss: [1m[32m0.69320[0m[0m | time: 31.023s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4888 -- iter: 1088/1133
[A[ATraining Step: 71  | total loss: [1m[32m0.69317[0m[0m | time: 31.958s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.5008 -- iter: 1120/1133
[A[ATraining Step: 72  | total loss: [1m[32m0.69315[0m[0m | time: 34.461s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5042 | val_loss: 0.69314 - val_acc: 0.5155 -- iter: 1133/1133
--
Training Step: 73  | total loss: [1m[32m0.69314[0m[0m | time: 0.449s
[2K
| RMSProp | epoch: 003 | loss: 0.69314 - acc: 0.5037 -- iter: 0032/1133
[A[ATraining Step: 74  | total loss: [1m[32m0.69321[0m[0m | time: 0.876s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4907 -- iter: 0064/1133
[A[ATraining Step: 75  | total loss: [1m[32m0.69322[0m[0m | time: 1.834s
[2K
| RMSProp | epoch: 003 | loss: 0.69322 - acc: 0.4792 -- iter: 0096/1133
[A[ATraining Step: 76  | total loss: [1m[32m0.69320[0m[0m | time: 2.734s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.4914 -- iter: 0128/1133
[A[ATraining Step: 77  | total loss: [1m[32m0.69317[0m[0m | time: 3.668s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.5023 -- iter: 0160/1133
[A[ATraining Step: 78  | total loss: [1m[32m0.69318[0m[0m | time: 4.573s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.5020 -- iter: 0192/1133
[A[ATraining Step: 79  | total loss: [1m[32m0.69313[0m[0m | time: 5.491s
[2K
| RMSProp | epoch: 003 | loss: 0.69313 - acc: 0.5212 -- iter: 0224/1133
[A[ATraining Step: 80  | total loss: [1m[32m0.69308[0m[0m | time: 6.369s
[2K
| RMSProp | epoch: 003 | loss: 0.69308 - acc: 0.5382 -- iter: 0256/1133
[A[ATraining Step: 81  | total loss: [1m[32m0.69310[0m[0m | time: 7.203s
[2K
| RMSProp | epoch: 003 | loss: 0.69310 - acc: 0.5344 -- iter: 0288/1133
[A[ATraining Step: 82  | total loss: [1m[32m0.69309[0m[0m | time: 8.396s
[2K
| RMSProp | epoch: 003 | loss: 0.69309 - acc: 0.5309 -- iter: 0320/1133
[A[ATraining Step: 83  | total loss: [1m[32m0.69300[0m[0m | time: 9.525s
[2K
| RMSProp | epoch: 003 | loss: 0.69300 - acc: 0.5403 -- iter: 0352/1133
[A[ATraining Step: 84  | total loss: [1m[32m0.69317[0m[0m | time: 10.388s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.5238 -- iter: 0384/1133
[A[ATraining Step: 85  | total loss: [1m[32m0.69319[0m[0m | time: 11.262s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5183 -- iter: 0416/1133
[A[ATraining Step: 86  | total loss: [1m[32m0.69312[0m[0m | time: 12.155s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5258 -- iter: 0448/1133
[A[ATraining Step: 87  | total loss: [1m[32m0.69309[0m[0m | time: 13.062s
[2K
| RMSProp | epoch: 003 | loss: 0.69309 - acc: 0.5264 -- iter: 0480/1133
[A[ATraining Step: 88  | total loss: [1m[32m0.69319[0m[0m | time: 13.970s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5144 -- iter: 0512/1133
[A[ATraining Step: 89  | total loss: [1m[32m0.69325[0m[0m | time: 14.822s
[2K
| RMSProp | epoch: 003 | loss: 0.69325 - acc: 0.5098 -- iter: 0544/1133
[A[ATraining Step: 90  | total loss: [1m[32m0.69327[0m[0m | time: 15.774s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.5026 -- iter: 0576/1133
[A[ATraining Step: 91  | total loss: [1m[32m0.69329[0m[0m | time: 16.668s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.4929 -- iter: 0608/1133
[A[ATraining Step: 92  | total loss: [1m[32m0.69329[0m[0m | time: 17.578s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.4999 -- iter: 0640/1133
[A[ATraining Step: 93  | total loss: [1m[32m0.69328[0m[0m | time: 18.425s
[2K
| RMSProp | epoch: 003 | loss: 0.69328 - acc: 0.4968 -- iter: 0672/1133
[A[ATraining Step: 94  | total loss: [1m[32m0.69328[0m[0m | time: 19.397s
[2K
| RMSProp | epoch: 003 | loss: 0.69328 - acc: 0.4815 -- iter: 0704/1133
[A[ATraining Step: 95  | total loss: [1m[32m0.69330[0m[0m | time: 20.582s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.4740 -- iter: 0736/1133
[A[ATraining Step: 96  | total loss: [1m[32m0.69326[0m[0m | time: 21.698s
[2K
| RMSProp | epoch: 003 | loss: 0.69326 - acc: 0.4953 -- iter: 0768/1133
[A[ATraining Step: 97  | total loss: [1m[32m0.69319[0m[0m | time: 22.448s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5020 -- iter: 0800/1133
[A[ATraining Step: 98  | total loss: [1m[32m0.69304[0m[0m | time: 23.361s
[2K
| RMSProp | epoch: 003 | loss: 0.69304 - acc: 0.5175 -- iter: 0832/1133
[A[ATraining Step: 99  | total loss: [1m[32m0.69306[0m[0m | time: 24.289s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5157 -- iter: 0864/1133
[A[ATraining Step: 100  | total loss: [1m[32m0.69304[0m[0m | time: 25.199s
[2K
| RMSProp | epoch: 003 | loss: 0.69304 - acc: 0.5141 -- iter: 0896/1133
[A[ATraining Step: 101  | total loss: [1m[32m0.69309[0m[0m | time: 26.139s
[2K
| RMSProp | epoch: 003 | loss: 0.69309 - acc: 0.5096 -- iter: 0928/1133
[A[ATraining Step: 102  | total loss: [1m[32m0.69304[0m[0m | time: 27.140s
[2K
| RMSProp | epoch: 003 | loss: 0.69304 - acc: 0.5118 -- iter: 0960/1133
[A[ATraining Step: 103  | total loss: [1m[32m0.69314[0m[0m | time: 28.073s
[2K
| RMSProp | epoch: 003 | loss: 0.69314 - acc: 0.5043 -- iter: 0992/1133
[A[ATraining Step: 104  | total loss: [1m[32m0.69324[0m[0m | time: 29.020s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.4945 -- iter: 1024/1133
[A[ATraining Step: 105  | total loss: [1m[32m0.69318[0m[0m | time: 29.890s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.5013 -- iter: 1056/1133
[A[ATraining Step: 106  | total loss: [1m[32m0.69323[0m[0m | time: 30.651s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4918 -- iter: 1088/1133
[A[ATraining Step: 107  | total loss: [1m[32m0.69323[0m[0m | time: 31.426s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4926 -- iter: 1120/1133
[A[ATraining Step: 108  | total loss: [1m[32m0.69327[0m[0m | time: 34.315s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.4840 | val_loss: 0.69314 - val_acc: 0.4986 -- iter: 1133/1133
--
Training Step: 109  | total loss: [1m[32m0.69336[0m[0m | time: 0.905s
[2K
| RMSProp | epoch: 004 | loss: 0.69336 - acc: 0.4762 -- iter: 0032/1133
[A[ATraining Step: 110  | total loss: [1m[32m0.69336[0m[0m | time: 1.320s
[2K
| RMSProp | epoch: 004 | loss: 0.69336 - acc: 0.4630 -- iter: 0064/1133
[A[ATraining Step: 111  | total loss: [1m[32m0.69333[0m[0m | time: 1.783s
[2K
| RMSProp | epoch: 004 | loss: 0.69333 - acc: 0.4705 -- iter: 0096/1133
[A[ATraining Step: 112  | total loss: [1m[32m0.69324[0m[0m | time: 2.726s
[2K
| RMSProp | epoch: 004 | loss: 0.69324 - acc: 0.4850 -- iter: 0128/1133
[A[ATraining Step: 113  | total loss: [1m[32m0.69327[0m[0m | time: 3.641s
[2K
| RMSProp | epoch: 004 | loss: 0.69327 - acc: 0.4771 -- iter: 0160/1133
[A[ATraining Step: 114  | total loss: [1m[32m0.69326[0m[0m | time: 4.562s
[2K
| RMSProp | epoch: 004 | loss: 0.69326 - acc: 0.4825 -- iter: 0192/1133
[A[ATraining Step: 115  | total loss: [1m[32m0.69321[0m[0m | time: 5.513s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.4968 -- iter: 0224/1133
[A[ATraining Step: 116  | total loss: [1m[32m0.69328[0m[0m | time: 6.436s
[2K
| RMSProp | epoch: 004 | loss: 0.69328 - acc: 0.4909 -- iter: 0256/1133
[A[ATraining Step: 117  | total loss: [1m[32m0.69327[0m[0m | time: 7.231s
[2K
| RMSProp | epoch: 004 | loss: 0.69327 - acc: 0.4918 -- iter: 0288/1133
[A[ATraining Step: 118  | total loss: [1m[32m0.69317[0m[0m | time: 8.329s
[2K
| RMSProp | epoch: 004 | loss: 0.69317 - acc: 0.5082 -- iter: 0320/1133
[A[ATraining Step: 119  | total loss: [1m[32m0.69299[0m[0m | time: 9.548s
[2K
| RMSProp | epoch: 004 | loss: 0.69299 - acc: 0.5168 -- iter: 0352/1133
[A[ATraining Step: 120  | total loss: [1m[32m0.69296[0m[0m | time: 10.566s
[2K
| RMSProp | epoch: 004 | loss: 0.69296 - acc: 0.5182 -- iter: 0384/1133
[A[ATraining Step: 121  | total loss: [1m[32m0.69283[0m[0m | time: 11.344s
[2K
| RMSProp | epoch: 004 | loss: 0.69283 - acc: 0.5227 -- iter: 0416/1133
[A[ATraining Step: 122  | total loss: [1m[32m0.69298[0m[0m | time: 12.204s
[2K
| RMSProp | epoch: 004 | loss: 0.69298 - acc: 0.5173 -- iter: 0448/1133
[A[ATraining Step: 123  | total loss: [1m[32m0.69291[0m[0m | time: 13.127s
[2K
| RMSProp | epoch: 004 | loss: 0.69291 - acc: 0.5187 -- iter: 0480/1133
[A[ATraining Step: 124  | total loss: [1m[32m0.69282[0m[0m | time: 14.047s
[2K
| RMSProp | epoch: 004 | loss: 0.69282 - acc: 0.5199 -- iter: 0512/1133
[A[ATraining Step: 125  | total loss: [1m[32m0.69264[0m[0m | time: 14.936s
[2K
| RMSProp | epoch: 004 | loss: 0.69264 - acc: 0.5242 -- iter: 0544/1133
[A[ATraining Step: 126  | total loss: [1m[32m0.69307[0m[0m | time: 15.867s
[2K
| RMSProp | epoch: 004 | loss: 0.69307 - acc: 0.5124 -- iter: 0576/1133
[A[ATraining Step: 127  | total loss: [1m[32m0.69343[0m[0m | time: 16.790s
[2K
| RMSProp | epoch: 004 | loss: 0.69343 - acc: 0.4986 -- iter: 0608/1133
[A[ATraining Step: 128  | total loss: [1m[32m0.69338[0m[0m | time: 17.724s
[2K
| RMSProp | epoch: 004 | loss: 0.69338 - acc: 0.4988 -- iter: 0640/1133
[A[ATraining Step: 129  | total loss: [1m[32m0.69326[0m[0m | time: 18.670s
[2K
| RMSProp | epoch: 004 | loss: 0.69326 - acc: 0.5083 -- iter: 0672/1133
[A[ATraining Step: 130  | total loss: [1m[32m0.69311[0m[0m | time: 19.498s
[2K
| RMSProp | epoch: 004 | loss: 0.69311 - acc: 0.5137 -- iter: 0704/1133
[A[ATraining Step: 131  | total loss: [1m[32m0.69313[0m[0m | time: 20.672s
[2K
| RMSProp | epoch: 004 | loss: 0.69313 - acc: 0.5123 -- iter: 0736/1133
[A[ATraining Step: 132  | total loss: [1m[32m0.69335[0m[0m | time: 21.853s
[2K
| RMSProp | epoch: 004 | loss: 0.69335 - acc: 0.5048 -- iter: 0768/1133
[A[ATraining Step: 133  | total loss: [1m[32m0.69315[0m[0m | time: 22.852s
[2K
| RMSProp | epoch: 004 | loss: 0.69315 - acc: 0.5137 -- iter: 0800/1133
[A[ATraining Step: 134  | total loss: [1m[32m0.69295[0m[0m | time: 23.638s
[2K
| RMSProp | epoch: 004 | loss: 0.69295 - acc: 0.5186 -- iter: 0832/1133
[A[ATraining Step: 135  | total loss: [1m[32m0.69331[0m[0m | time: 24.503s
[2K
| RMSProp | epoch: 004 | loss: 0.69331 - acc: 0.5074 -- iter: 0864/1133
[A[ATraining Step: 136  | total loss: [1m[32m0.69343[0m[0m | time: 25.403s
[2K
| RMSProp | epoch: 004 | loss: 0.69343 - acc: 0.5004 -- iter: 0896/1133
[A[ATraining Step: 137  | total loss: [1m[32m0.69332[0m[0m | time: 26.300s
[2K
| RMSProp | epoch: 004 | loss: 0.69332 - acc: 0.5035 -- iter: 0928/1133
[A[ATraining Step: 138  | total loss: [1m[32m0.69380[0m[0m | time: 27.244s
[2K
| RMSProp | epoch: 004 | loss: 0.69380 - acc: 0.4750 -- iter: 0960/1133
[A[ATraining Step: 139  | total loss: [1m[32m0.69380[0m[0m | time: 28.215s
[2K
| RMSProp | epoch: 004 | loss: 0.69380 - acc: 0.4744 -- iter: 0992/1133
[A[ATraining Step: 140  | total loss: [1m[32m0.69373[0m[0m | time: 29.141s
[2K
| RMSProp | epoch: 004 | loss: 0.69373 - acc: 0.4832 -- iter: 1024/1133
[A[ATraining Step: 141  | total loss: [1m[32m0.69358[0m[0m | time: 30.091s
[2K
| RMSProp | epoch: 004 | loss: 0.69358 - acc: 0.4911 -- iter: 1056/1133
[A[ATraining Step: 142  | total loss: [1m[32m0.69366[0m[0m | time: 30.968s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.4858 -- iter: 1088/1133
[A[ATraining Step: 143  | total loss: [1m[32m0.69360[0m[0m | time: 31.975s
[2K
| RMSProp | epoch: 004 | loss: 0.69360 - acc: 0.4872 -- iter: 1120/1133
[A[ATraining Step: 144  | total loss: [1m[32m0.69349[0m[0m | time: 35.131s
[2K
| RMSProp | epoch: 004 | loss: 0.69349 - acc: 0.5010 | val_loss: 0.69324 - val_acc: 0.4986 -- iter: 1133/1133
--
Training Step: 145  | total loss: [1m[32m0.69336[0m[0m | time: 0.913s
[2K
| RMSProp | epoch: 005 | loss: 0.69336 - acc: 0.5040 -- iter: 0032/1133
[A[ATraining Step: 146  | total loss: [1m[32m0.69359[0m[0m | time: 1.837s
[2K
| RMSProp | epoch: 005 | loss: 0.69359 - acc: 0.4942 -- iter: 0064/1133
[A[ATraining Step: 147  | total loss: [1m[32m0.69360[0m[0m | time: 2.236s
[2K
| RMSProp | epoch: 005 | loss: 0.69360 - acc: 0.4917 -- iter: 0096/1133
[A[ATraining Step: 148  | total loss: [1m[32m0.69353[0m[0m | time: 2.676s
[2K
| RMSProp | epoch: 005 | loss: 0.69353 - acc: 0.4964 -- iter: 0128/1133
[A[ATraining Step: 149  | total loss: [1m[32m0.69348[0m[0m | time: 3.583s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.5006 -- iter: 0160/1133
[A[ATraining Step: 150  | total loss: [1m[32m0.69343[0m[0m | time: 4.458s
[2K
| RMSProp | epoch: 005 | loss: 0.69343 - acc: 0.5068 -- iter: 0192/1133
[A[ATraining Step: 151  | total loss: [1m[32m0.69349[0m[0m | time: 5.349s
[2K
| RMSProp | epoch: 005 | loss: 0.69349 - acc: 0.4967 -- iter: 0224/1133
[A[ATraining Step: 152  | total loss: [1m[32m0.69346[0m[0m | time: 6.346s
[2K
| RMSProp | epoch: 005 | loss: 0.69346 - acc: 0.5033 -- iter: 0256/1133
[A[ATraining Step: 153  | total loss: [1m[32m0.69342[0m[0m | time: 7.437s
[2K
| RMSProp | epoch: 005 | loss: 0.69342 - acc: 0.5030 -- iter: 0288/1133
[A[ATraining Step: 154  | total loss: [1m[32m0.69331[0m[0m | time: 8.464s
[2K
| RMSProp | epoch: 005 | loss: 0.69331 - acc: 0.5120 -- iter: 0320/1133
[A[ATraining Step: 155  | total loss: [1m[32m0.69325[0m[0m | time: 9.225s
[2K
| RMSProp | epoch: 005 | loss: 0.69325 - acc: 0.5140 -- iter: 0352/1133
[A[ATraining Step: 156  | total loss: [1m[32m0.69331[0m[0m | time: 10.097s
[2K
| RMSProp | epoch: 005 | loss: 0.69331 - acc: 0.5094 -- iter: 0384/1133
[A[ATraining Step: 157  | total loss: [1m[32m0.69322[0m[0m | time: 10.992s
[2K
| RMSProp | epoch: 005 | loss: 0.69322 - acc: 0.5116 -- iter: 0416/1133
[A[ATraining Step: 158  | total loss: [1m[32m0.69301[0m[0m | time: 11.858s
[2K
| RMSProp | epoch: 005 | loss: 0.69301 - acc: 0.5230 -- iter: 0448/1133
[A[ATraining Step: 159  | total loss: [1m[32m0.69321[0m[0m | time: 12.750s
[2K
| RMSProp | epoch: 005 | loss: 0.69321 - acc: 0.5175 -- iter: 0480/1133
[A[ATraining Step: 160  | total loss: [1m[32m0.69338[0m[0m | time: 13.633s
[2K
| RMSProp | epoch: 005 | loss: 0.69338 - acc: 0.5095 -- iter: 0512/1133
[A[ATraining Step: 161  | total loss: [1m[32m0.69359[0m[0m | time: 14.568s
[2K
| RMSProp | epoch: 005 | loss: 0.69359 - acc: 0.4930 -- iter: 0544/1133
[A[ATraining Step: 162  | total loss: [1m[32m0.69353[0m[0m | time: 15.498s
[2K
| RMSProp | epoch: 005 | loss: 0.69353 - acc: 0.4999 -- iter: 0576/1133
[A[ATraining Step: 163  | total loss: [1m[32m0.69345[0m[0m | time: 16.404s
[2K
| RMSProp | epoch: 005 | loss: 0.69345 - acc: 0.5062 -- iter: 0608/1133
[A[ATraining Step: 164  | total loss: [1m[32m0.69357[0m[0m | time: 17.206s
[2K
| RMSProp | epoch: 005 | loss: 0.69357 - acc: 0.4993 -- iter: 0640/1133
[A[ATraining Step: 165  | total loss: [1m[32m0.69356[0m[0m | time: 18.258s
[2K
| RMSProp | epoch: 005 | loss: 0.69356 - acc: 0.4931 -- iter: 0672/1133
[A[ATraining Step: 166  | total loss: [1m[32m0.69352[0m[0m | time: 19.392s
[2K
| RMSProp | epoch: 005 | loss: 0.69352 - acc: 0.4938 -- iter: 0704/1133
[A[ATraining Step: 167  | total loss: [1m[32m0.69356[0m[0m | time: 20.319s
[2K
| RMSProp | epoch: 005 | loss: 0.69356 - acc: 0.4882 -- iter: 0736/1133
[A[ATraining Step: 168  | total loss: [1m[32m0.69348[0m[0m | time: 21.107s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.5050 -- iter: 0768/1133
[A[ATraining Step: 169  | total loss: [1m[32m0.69346[0m[0m | time: 22.004s
[2K
| RMSProp | epoch: 005 | loss: 0.69346 - acc: 0.5045 -- iter: 0800/1133
[A[ATraining Step: 170  | total loss: [1m[32m0.69345[0m[0m | time: 22.931s
[2K
| RMSProp | epoch: 005 | loss: 0.69345 - acc: 0.5009 -- iter: 0832/1133
[A[ATraining Step: 171  | total loss: [1m[32m0.69343[0m[0m | time: 23.839s
[2K
| RMSProp | epoch: 005 | loss: 0.69343 - acc: 0.5008 -- iter: 0864/1133
[A[ATraining Step: 172  | total loss: [1m[32m0.69322[0m[0m | time: 24.787s
[2K
| RMSProp | epoch: 005 | loss: 0.69322 - acc: 0.5195 -- iter: 0896/1133
[A[ATraining Step: 173  | total loss: [1m[32m0.69322[0m[0m | time: 25.679s
[2K
| RMSProp | epoch: 005 | loss: 0.69322 - acc: 0.5175 -- iter: 0928/1133
[A[ATraining Step: 174  | total loss: [1m[32m0.69329[0m[0m | time: 26.637s
[2K
| RMSProp | epoch: 005 | loss: 0.69329 - acc: 0.5127 -- iter: 0960/1133
[A[ATraining Step: 175  | total loss: [1m[32m0.69332[0m[0m | time: 27.611s
[2K
| RMSProp | epoch: 005 | loss: 0.69332 - acc: 0.5083 -- iter: 0992/1133
[A[ATraining Step: 176  | total loss: [1m[32m0.69355[0m[0m | time: 28.481s
[2K
| RMSProp | epoch: 005 | loss: 0.69355 - acc: 0.4918 -- iter: 1024/1133
[A[ATraining Step: 177  | total loss: [1m[32m0.69348[0m[0m | time: 29.574s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.4958 -- iter: 1056/1133
[A[ATraining Step: 178  | total loss: [1m[32m0.69335[0m[0m | time: 30.731s
[2K
| RMSProp | epoch: 005 | loss: 0.69335 - acc: 0.5024 -- iter: 1088/1133
[A[ATraining Step: 179  | total loss: [1m[32m0.69249[0m[0m | time: 31.711s
[2K
| RMSProp | epoch: 005 | loss: 0.69249 - acc: 0.5209 -- iter: 1120/1133
[A[ATraining Step: 180  | total loss: [1m[32m0.69490[0m[0m | time: 34.230s
[2K
| RMSProp | epoch: 005 | loss: 0.69490 - acc: 0.5126 | val_loss: 0.69327 - val_acc: 0.4986 -- iter: 1133/1133
--
Training Step: 181  | total loss: [1m[32m0.69473[0m[0m | time: 0.910s
[2K
| RMSProp | epoch: 006 | loss: 0.69473 - acc: 0.5113 -- iter: 0032/1133
[A[ATraining Step: 182  | total loss: [1m[32m0.69484[0m[0m | time: 1.840s
[2K
| RMSProp | epoch: 006 | loss: 0.69484 - acc: 0.5008 -- iter: 0064/1133
[A[ATraining Step: 183  | total loss: [1m[32m0.69471[0m[0m | time: 2.752s
[2K
| RMSProp | epoch: 006 | loss: 0.69471 - acc: 0.4976 -- iter: 0096/1133
[A[ATraining Step: 184  | total loss: [1m[32m0.69452[0m[0m | time: 3.158s
[2K
| RMSProp | epoch: 006 | loss: 0.69452 - acc: 0.5072 -- iter: 0128/1133
[A[ATraining Step: 185  | total loss: [1m[32m0.69406[0m[0m | time: 3.543s
[2K
| RMSProp | epoch: 006 | loss: 0.69406 - acc: 0.5411 -- iter: 0160/1133
[A[ATraining Step: 186  | total loss: [1m[32m0.69186[0m[0m | time: 4.394s
[2K
| RMSProp | epoch: 006 | loss: 0.69186 - acc: 0.5716 -- iter: 0192/1133
[A[ATraining Step: 187  | total loss: [1m[32m0.69346[0m[0m | time: 5.519s
[2K
| RMSProp | epoch: 006 | loss: 0.69346 - acc: 0.5613 -- iter: 0224/1133
[A[ATraining Step: 188  | total loss: [1m[32m0.69349[0m[0m | time: 6.633s
[2K
| RMSProp | epoch: 006 | loss: 0.69349 - acc: 0.5552 -- iter: 0256/1133
[A[ATraining Step: 189  | total loss: [1m[32m0.69302[0m[0m | time: 7.489s
[2K
| RMSProp | epoch: 006 | loss: 0.69302 - acc: 0.5559 -- iter: 0288/1133
[A[ATraining Step: 190  | total loss: [1m[32m0.69387[0m[0m | time: 8.417s
[2K
| RMSProp | epoch: 006 | loss: 0.69387 - acc: 0.5441 -- iter: 0320/1133
[A[ATraining Step: 191  | total loss: [1m[32m0.69364[0m[0m | time: 9.346s
[2K
| RMSProp | epoch: 006 | loss: 0.69364 - acc: 0.5428 -- iter: 0352/1133
[A[ATraining Step: 192  | total loss: [1m[32m0.69357[0m[0m | time: 10.273s
[2K
| RMSProp | epoch: 006 | loss: 0.69357 - acc: 0.5385 -- iter: 0384/1133
[A[ATraining Step: 193  | total loss: [1m[32m0.69307[0m[0m | time: 11.275s
[2K
| RMSProp | epoch: 006 | loss: 0.69307 - acc: 0.5440 -- iter: 0416/1133
[A[ATraining Step: 194  | total loss: [1m[32m0.69370[0m[0m | time: 12.193s
[2K
| RMSProp | epoch: 006 | loss: 0.69370 - acc: 0.5334 -- iter: 0448/1133
[A[ATraining Step: 195  | total loss: [1m[32m0.69273[0m[0m | time: 13.113s
[2K
| RMSProp | epoch: 006 | loss: 0.69273 - acc: 0.5488 -- iter: 0480/1133
[A[ATraining Step: 196  | total loss: [1m[32m0.69323[0m[0m | time: 14.009s
[2K
| RMSProp | epoch: 006 | loss: 0.69323 - acc: 0.5408 -- iter: 0512/1133
[A[ATraining Step: 197  | total loss: [1m[32m0.69396[0m[0m | time: 14.894s
[2K
| RMSProp | epoch: 006 | loss: 0.69396 - acc: 0.5273 -- iter: 0544/1133
[A[ATraining Step: 198  | total loss: [1m[32m0.69378[0m[0m | time: 15.779s
[2K
| RMSProp | epoch: 006 | loss: 0.69378 - acc: 0.5277 -- iter: 0576/1133
[A[ATraining Step: 199  | total loss: [1m[32m0.69277[0m[0m | time: 16.950s
[2K
| RMSProp | epoch: 006 | loss: 0.69277 - acc: 0.5468 -- iter: 0608/1133
[A[ATraining Step: 200  | total loss: [1m[32m0.69404[0m[0m | time: 19.678s
[2K
| RMSProp | epoch: 006 | loss: 0.69404 - acc: 0.5297 | val_loss: 0.69339 - val_acc: 0.4986 -- iter: 0640/1133
--
Training Step: 201  | total loss: [1m[32m0.69381[0m[0m | time: 20.569s
[2K
| RMSProp | epoch: 006 | loss: 0.69381 - acc: 0.5298 -- iter: 0672/1133
[A[ATraining Step: 202  | total loss: [1m[32m0.69430[0m[0m | time: 21.449s
[2K
| RMSProp | epoch: 006 | loss: 0.69430 - acc: 0.5143 -- iter: 0704/1133
[A[ATraining Step: 203  | total loss: [1m[32m0.69404[0m[0m | time: 22.360s
[2K
| RMSProp | epoch: 006 | loss: 0.69404 - acc: 0.5191 -- iter: 0736/1133
[A[ATraining Step: 204  | total loss: [1m[32m0.69425[0m[0m | time: 23.259s
[2K
| RMSProp | epoch: 006 | loss: 0.69425 - acc: 0.5079 -- iter: 0768/1133
[A[ATraining Step: 205  | total loss: [1m[32m0.69439[0m[0m | time: 24.216s
[2K
| RMSProp | epoch: 006 | loss: 0.69439 - acc: 0.4946 -- iter: 0800/1133
[A[ATraining Step: 206  | total loss: [1m[32m0.69432[0m[0m | time: 25.131s
[2K
| RMSProp | epoch: 006 | loss: 0.69432 - acc: 0.4826 -- iter: 0832/1133
[A[ATraining Step: 207  | total loss: [1m[32m0.69406[0m[0m | time: 25.998s
[2K
| RMSProp | epoch: 006 | loss: 0.69406 - acc: 0.4969 -- iter: 0864/1133
[A[ATraining Step: 208  | total loss: [1m[32m0.69384[0m[0m | time: 26.845s
[2K
| RMSProp | epoch: 006 | loss: 0.69384 - acc: 0.5003 -- iter: 0896/1133
[A[ATraining Step: 209  | total loss: [1m[32m0.69313[0m[0m | time: 28.050s
[2K
| RMSProp | epoch: 006 | loss: 0.69313 - acc: 0.5128 -- iter: 0928/1133
[A[ATraining Step: 210  | total loss: [1m[32m0.69505[0m[0m | time: 29.289s
[2K
| RMSProp | epoch: 006 | loss: 0.69505 - acc: 0.5021 -- iter: 0960/1133
[A[ATraining Step: 211  | total loss: [1m[32m0.69439[0m[0m | time: 30.202s
[2K
| RMSProp | epoch: 006 | loss: 0.69439 - acc: 0.5175 -- iter: 0992/1133
[A[ATraining Step: 212  | total loss: [1m[32m0.69483[0m[0m | time: 31.077s
[2K
| RMSProp | epoch: 006 | loss: 0.69483 - acc: 0.5064 -- iter: 1024/1133
[A[ATraining Step: 213  | total loss: [1m[32m0.69510[0m[0m | time: 31.957s
[2K
| RMSProp | epoch: 006 | loss: 0.69510 - acc: 0.4933 -- iter: 1056/1133
[A[ATraining Step: 214  | total loss: [1m[32m0.69475[0m[0m | time: 32.877s
[2K
| RMSProp | epoch: 006 | loss: 0.69475 - acc: 0.5033 -- iter: 1088/1133
[A[ATraining Step: 215  | total loss: [1m[32m0.69485[0m[0m | time: 33.929s
[2K
| RMSProp | epoch: 006 | loss: 0.69485 - acc: 0.4936 -- iter: 1120/1133
[A[ATraining Step: 216  | total loss: [1m[32m0.69465[0m[0m | time: 36.656s
[2K
| RMSProp | epoch: 006 | loss: 0.69465 - acc: 0.4974 | val_loss: 0.69311 - val_acc: 0.5014 -- iter: 1133/1133
--
Training Step: 217  | total loss: [1m[32m0.69451[0m[0m | time: 0.954s
[2K
| RMSProp | epoch: 007 | loss: 0.69451 - acc: 0.4976 -- iter: 0032/1133
[A[ATraining Step: 218  | total loss: [1m[32m0.69438[0m[0m | time: 2.148s
[2K
| RMSProp | epoch: 007 | loss: 0.69438 - acc: 0.4979 -- iter: 0064/1133
[A[ATraining Step: 219  | total loss: [1m[32m0.69435[0m[0m | time: 3.269s
[2K
| RMSProp | epoch: 007 | loss: 0.69435 - acc: 0.4918 -- iter: 0096/1133
[A[ATraining Step: 220  | total loss: [1m[32m0.69425[0m[0m | time: 4.056s
[2K
| RMSProp | epoch: 007 | loss: 0.69425 - acc: 0.4801 -- iter: 0128/1133
[A[ATraining Step: 221  | total loss: [1m[32m0.69412[0m[0m | time: 4.456s
[2K
| RMSProp | epoch: 007 | loss: 0.69412 - acc: 0.4853 -- iter: 0160/1133
[A[ATraining Step: 222  | total loss: [1m[32m0.69386[0m[0m | time: 4.877s
[2K
| RMSProp | epoch: 007 | loss: 0.69386 - acc: 0.4983 -- iter: 0192/1133
[A[ATraining Step: 223  | total loss: [1m[32m0.69335[0m[0m | time: 5.844s
[2K
| RMSProp | epoch: 007 | loss: 0.69335 - acc: 0.5100 -- iter: 0224/1133
[A[ATraining Step: 224  | total loss: [1m[32m0.69266[0m[0m | time: 6.801s
[2K
| RMSProp | epoch: 007 | loss: 0.69266 - acc: 0.5184 -- iter: 0256/1133
[A[ATraining Step: 225  | total loss: [1m[32m0.69193[0m[0m | time: 7.752s
[2K
| RMSProp | epoch: 007 | loss: 0.69193 - acc: 0.5228 -- iter: 0288/1133
[A[ATraining Step: 226  | total loss: [1m[32m0.69211[0m[0m | time: 8.662s
[2K
| RMSProp | epoch: 007 | loss: 0.69211 - acc: 0.5236 -- iter: 0320/1133
[A[ATraining Step: 227  | total loss: [1m[32m0.69199[0m[0m | time: 9.562s
[2K
| RMSProp | epoch: 007 | loss: 0.69199 - acc: 0.5244 -- iter: 0352/1133
[A[ATraining Step: 228  | total loss: [1m[32m0.69179[0m[0m | time: 10.489s
[2K
| RMSProp | epoch: 007 | loss: 0.69179 - acc: 0.5251 -- iter: 0384/1133
[A[ATraining Step: 229  | total loss: [1m[32m0.69074[0m[0m | time: 11.396s
[2K
| RMSProp | epoch: 007 | loss: 0.69074 - acc: 0.5319 -- iter: 0416/1133
[A[ATraining Step: 230  | total loss: [1m[32m0.69480[0m[0m | time: 12.327s
[2K
| RMSProp | epoch: 007 | loss: 0.69480 - acc: 0.5225 -- iter: 0448/1133
[A[ATraining Step: 231  | total loss: [1m[32m0.69502[0m[0m | time: 13.352s
[2K
| RMSProp | epoch: 007 | loss: 0.69502 - acc: 0.5140 -- iter: 0480/1133
[A[ATraining Step: 232  | total loss: [1m[32m0.69457[0m[0m | time: 14.448s
[2K
| RMSProp | epoch: 007 | loss: 0.69457 - acc: 0.5188 -- iter: 0512/1133
[A[ATraining Step: 233  | total loss: [1m[32m0.69518[0m[0m | time: 15.217s
[2K
| RMSProp | epoch: 007 | loss: 0.69518 - acc: 0.5045 -- iter: 0544/1133
[A[ATraining Step: 234  | total loss: [1m[32m0.69511[0m[0m | time: 16.076s
[2K
| RMSProp | epoch: 007 | loss: 0.69511 - acc: 0.4978 -- iter: 0576/1133
[A[ATraining Step: 235  | total loss: [1m[32m0.69489[0m[0m | time: 16.964s
[2K
| RMSProp | epoch: 007 | loss: 0.69489 - acc: 0.4980 -- iter: 0608/1133
[A[ATraining Step: 236  | total loss: [1m[32m0.69471[0m[0m | time: 17.913s
[2K
| RMSProp | epoch: 007 | loss: 0.69471 - acc: 0.5044 -- iter: 0640/1133
[A[ATraining Step: 237  | total loss: [1m[32m0.69461[0m[0m | time: 18.819s
[2K
| RMSProp | epoch: 007 | loss: 0.69461 - acc: 0.4915 -- iter: 0672/1133
[A[ATraining Step: 238  | total loss: [1m[32m0.69432[0m[0m | time: 19.730s
[2K
| RMSProp | epoch: 007 | loss: 0.69432 - acc: 0.4986 -- iter: 0704/1133
[A[ATraining Step: 239  | total loss: [1m[32m0.69397[0m[0m | time: 20.627s
[2K
| RMSProp | epoch: 007 | loss: 0.69397 - acc: 0.5050 -- iter: 0736/1133
[A[ATraining Step: 240  | total loss: [1m[32m0.69405[0m[0m | time: 21.600s
[2K
| RMSProp | epoch: 007 | loss: 0.69405 - acc: 0.5014 -- iter: 0768/1133
[A[ATraining Step: 241  | total loss: [1m[32m0.69426[0m[0m | time: 22.549s
[2K
| RMSProp | epoch: 007 | loss: 0.69426 - acc: 0.4919 -- iter: 0800/1133
[A[ATraining Step: 242  | total loss: [1m[32m0.69422[0m[0m | time: 23.364s
[2K
| RMSProp | epoch: 007 | loss: 0.69422 - acc: 0.4770 -- iter: 0832/1133
[A[ATraining Step: 243  | total loss: [1m[32m0.69438[0m[0m | time: 24.530s
[2K
| RMSProp | epoch: 007 | loss: 0.69438 - acc: 0.4700 -- iter: 0864/1133
[A[ATraining Step: 244  | total loss: [1m[32m0.69429[0m[0m | time: 25.730s
[2K
| RMSProp | epoch: 007 | loss: 0.69429 - acc: 0.4698 -- iter: 0896/1133
[A[ATraining Step: 245  | total loss: [1m[32m0.69421[0m[0m | time: 26.674s
[2K
| RMSProp | epoch: 007 | loss: 0.69421 - acc: 0.4635 -- iter: 0928/1133
[A[ATraining Step: 246  | total loss: [1m[32m0.69416[0m[0m | time: 27.493s
[2K
| RMSProp | epoch: 007 | loss: 0.69416 - acc: 0.4609 -- iter: 0960/1133
[A[ATraining Step: 247  | total loss: [1m[32m0.69408[0m[0m | time: 28.428s
[2K
| RMSProp | epoch: 007 | loss: 0.69408 - acc: 0.4585 -- iter: 0992/1133
[A[ATraining Step: 248  | total loss: [1m[32m0.69399[0m[0m | time: 29.372s
[2K
| RMSProp | epoch: 007 | loss: 0.69399 - acc: 0.4658 -- iter: 1024/1133
[A[ATraining Step: 249  | total loss: [1m[32m0.69403[0m[0m | time: 30.293s
[2K
| RMSProp | epoch: 007 | loss: 0.69403 - acc: 0.4567 -- iter: 1056/1133
[A[ATraining Step: 250  | total loss: [1m[32m0.69396[0m[0m | time: 31.200s
[2K
| RMSProp | epoch: 007 | loss: 0.69396 - acc: 0.4642 -- iter: 1088/1133
[A[ATraining Step: 251  | total loss: [1m[32m0.69382[0m[0m | time: 32.118s
[2K
| RMSProp | epoch: 007 | loss: 0.69382 - acc: 0.4740 -- iter: 1120/1133
[A[ATraining Step: 252  | total loss: [1m[32m0.69380[0m[0m | time: 34.812s
[2K
| RMSProp | epoch: 007 | loss: 0.69380 - acc: 0.4735 | val_loss: 0.69316 - val_acc: 0.4986 -- iter: 1133/1133
--
Training Step: 253  | total loss: [1m[32m0.69365[0m[0m | time: 1.157s
[2K
| RMSProp | epoch: 008 | loss: 0.69365 - acc: 0.4824 -- iter: 0032/1133
[A[ATraining Step: 254  | total loss: [1m[32m0.69340[0m[0m | time: 1.881s
[2K
| RMSProp | epoch: 008 | loss: 0.69340 - acc: 0.4935 -- iter: 0064/1133
[A[ATraining Step: 255  | total loss: [1m[32m0.69278[0m[0m | time: 2.765s
[2K
| RMSProp | epoch: 008 | loss: 0.69278 - acc: 0.5098 -- iter: 0096/1133
[A[ATraining Step: 256  | total loss: [1m[32m0.69245[0m[0m | time: 3.733s
[2K
| RMSProp | epoch: 008 | loss: 0.69245 - acc: 0.5151 -- iter: 0128/1133
[A[ATraining Step: 257  | total loss: [1m[32m0.69299[0m[0m | time: 4.706s
[2K
| RMSProp | epoch: 008 | loss: 0.69299 - acc: 0.5104 -- iter: 0160/1133
[A[ATraining Step: 258  | total loss: [1m[32m0.69319[0m[0m | time: 5.102s
[2K
| RMSProp | epoch: 008 | loss: 0.69319 - acc: 0.5063 -- iter: 0192/1133
[A[ATraining Step: 259  | total loss: [1m[32m0.69337[0m[0m | time: 5.510s
[2K
| RMSProp | epoch: 008 | loss: 0.69337 - acc: 0.5018 -- iter: 0224/1133
[A[ATraining Step: 260  | total loss: [1m[32m0.69339[0m[0m | time: 6.470s
[2K
| RMSProp | epoch: 008 | loss: 0.69339 - acc: 0.4978 -- iter: 0256/1133
[A[ATraining Step: 261  | total loss: [1m[32m0.69340[0m[0m | time: 7.379s
[2K
| RMSProp | epoch: 008 | loss: 0.69340 - acc: 0.4949 -- iter: 0288/1133
[A[ATraining Step: 262  | total loss: [1m[32m0.69337[0m[0m | time: 8.325s
[2K
| RMSProp | epoch: 008 | loss: 0.69337 - acc: 0.4923 -- iter: 0320/1133
[A[ATraining Step: 263  | total loss: [1m[32m0.69336[0m[0m | time: 9.260s
[2K
| RMSProp | epoch: 008 | loss: 0.69336 - acc: 0.4899 -- iter: 0352/1133
[A[ATraining Step: 264  | total loss: [1m[32m0.69326[0m[0m | time: 10.198s
[2K
| RMSProp | epoch: 008 | loss: 0.69326 - acc: 0.4940 -- iter: 0384/1133
[A[ATraining Step: 265  | total loss: [1m[32m0.69383[0m[0m | time: 11.313s
[2K
| RMSProp | epoch: 008 | loss: 0.69383 - acc: 0.4853 -- iter: 0416/1133
[A[ATraining Step: 266  | total loss: [1m[32m0.69393[0m[0m | time: 12.400s
[2K
| RMSProp | epoch: 008 | loss: 0.69393 - acc: 0.4649 -- iter: 0448/1133
[A[ATraining Step: 267  | total loss: [1m[32m0.69399[0m[0m | time: 13.234s
[2K
| RMSProp | epoch: 008 | loss: 0.69399 - acc: 0.4590 -- iter: 0480/1133
[A[ATraining Step: 268  | total loss: [1m[32m0.69393[0m[0m | time: 14.075s
[2K
| RMSProp | epoch: 008 | loss: 0.69393 - acc: 0.4537 -- iter: 0512/1133
[A[ATraining Step: 269  | total loss: [1m[32m0.69357[0m[0m | time: 14.939s
[2K
| RMSProp | epoch: 008 | loss: 0.69357 - acc: 0.4740 -- iter: 0544/1133
[A[ATraining Step: 270  | total loss: [1m[32m0.69420[0m[0m | time: 15.828s
[2K
| RMSProp | epoch: 008 | loss: 0.69420 - acc: 0.4672 -- iter: 0576/1133
[A[ATraining Step: 271  | total loss: [1m[32m0.69432[0m[0m | time: 16.696s
[2K
| RMSProp | epoch: 008 | loss: 0.69432 - acc: 0.4580 -- iter: 0608/1133
[A[ATraining Step: 272  | total loss: [1m[32m0.69419[0m[0m | time: 17.637s
[2K
| RMSProp | epoch: 008 | loss: 0.69419 - acc: 0.4622 -- iter: 0640/1133
[A[ATraining Step: 273  | total loss: [1m[32m0.69410[0m[0m | time: 18.525s
[2K
| RMSProp | epoch: 008 | loss: 0.69410 - acc: 0.4566 -- iter: 0672/1133
[A[ATraining Step: 274  | total loss: [1m[32m0.69378[0m[0m | time: 19.462s
[2K
| RMSProp | epoch: 008 | loss: 0.69378 - acc: 0.4859 -- iter: 0704/1133
[A[ATraining Step: 275  | total loss: [1m[32m0.69351[0m[0m | time: 20.444s
[2K
| RMSProp | epoch: 008 | loss: 0.69351 - acc: 0.4936 -- iter: 0736/1133
[A[ATraining Step: 276  | total loss: [1m[32m0.69376[0m[0m | time: 21.302s
[2K
| RMSProp | epoch: 008 | loss: 0.69376 - acc: 0.4880 -- iter: 0768/1133
[A[ATraining Step: 277  | total loss: [1m[32m0.69371[0m[0m | time: 22.316s
[2K
| RMSProp | epoch: 008 | loss: 0.69371 - acc: 0.4892 -- iter: 0800/1133
[A[ATraining Step: 278  | total loss: [1m[32m0.69358[0m[0m | time: 23.438s
[2K
| RMSProp | epoch: 008 | loss: 0.69358 - acc: 0.4934 -- iter: 0832/1133
[A[ATraining Step: 279  | total loss: [1m[32m0.69347[0m[0m | time: 24.598s
[2K
| RMSProp | epoch: 008 | loss: 0.69347 - acc: 0.4972 -- iter: 0864/1133
[A[ATraining Step: 280  | total loss: [1m[32m0.69358[0m[0m | time: 25.403s
[2K
| RMSProp | epoch: 008 | loss: 0.69358 - acc: 0.4943 -- iter: 0896/1133
[A[ATraining Step: 281  | total loss: [1m[32m0.69345[0m[0m | time: 26.261s
[2K
| RMSProp | epoch: 008 | loss: 0.69345 - acc: 0.4980 -- iter: 0928/1133
[A[ATraining Step: 282  | total loss: [1m[32m0.69369[0m[0m | time: 27.144s
[2K
| RMSProp | epoch: 008 | loss: 0.69369 - acc: 0.4888 -- iter: 0960/1133
[A[ATraining Step: 283  | total loss: [1m[32m0.69377[0m[0m | time: 28.090s
[2K
| RMSProp | epoch: 008 | loss: 0.69377 - acc: 0.4743 -- iter: 0992/1133
[A[ATraining Step: 284  | total loss: [1m[32m0.69392[0m[0m | time: 29.028s
[2K
| RMSProp | epoch: 008 | loss: 0.69392 - acc: 0.4613 -- iter: 1024/1133
[A[ATraining Step: 285  | total loss: [1m[32m0.69390[0m[0m | time: 29.953s
[2K
| RMSProp | epoch: 008 | loss: 0.69390 - acc: 0.4527 -- iter: 1056/1133
[A[ATraining Step: 286  | total loss: [1m[32m0.69377[0m[0m | time: 30.842s
[2K
| RMSProp | epoch: 008 | loss: 0.69377 - acc: 0.4699 -- iter: 1088/1133
[A[ATraining Step: 287  | total loss: [1m[32m0.69375[0m[0m | time: 31.726s
[2K
| RMSProp | epoch: 008 | loss: 0.69375 - acc: 0.4698 -- iter: 1120/1133
[A[ATraining Step: 288  | total loss: [1m[32m0.69363[0m[0m | time: 34.384s
[2K
| RMSProp | epoch: 008 | loss: 0.69363 - acc: 0.4790 | val_loss: 0.69326 - val_acc: 0.4986 -- iter: 1133/1133
--
Training Step: 289  | total loss: [1m[32m0.69328[0m[0m | time: 0.770s
[2K
| RMSProp | epoch: 009 | loss: 0.69328 - acc: 0.5030 -- iter: 0032/1133
[A[ATraining Step: 290  | total loss: [1m[32m0.69301[0m[0m | time: 1.627s
[2K
| RMSProp | epoch: 009 | loss: 0.69301 - acc: 0.5121 -- iter: 0064/1133
[A[ATraining Step: 291  | total loss: [1m[32m0.69354[0m[0m | time: 2.588s
[2K
| RMSProp | epoch: 009 | loss: 0.69354 - acc: 0.4984 -- iter: 0096/1133
[A[ATraining Step: 292  | total loss: [1m[32m0.69379[0m[0m | time: 3.488s
[2K
| RMSProp | epoch: 009 | loss: 0.69379 - acc: 0.4860 -- iter: 0128/1133
[A[ATraining Step: 293  | total loss: [1m[32m0.69359[0m[0m | time: 4.416s
[2K
| RMSProp | epoch: 009 | loss: 0.69359 - acc: 0.4968 -- iter: 0160/1133
[A[ATraining Step: 294  | total loss: [1m[32m0.69380[0m[0m | time: 5.379s
[2K
| RMSProp | epoch: 009 | loss: 0.69380 - acc: 0.4846 -- iter: 0192/1133
[A[ATraining Step: 295  | total loss: [1m[32m0.69376[0m[0m | time: 5.791s
[2K
| RMSProp | epoch: 009 | loss: 0.69376 - acc: 0.4830 -- iter: 0224/1133
[A[ATraining Step: 296  | total loss: [1m[32m0.69381[0m[0m | time: 6.213s
[2K
| RMSProp | epoch: 009 | loss: 0.69381 - acc: 0.4732 -- iter: 0256/1133
[A[ATraining Step: 297  | total loss: [1m[32m0.69375[0m[0m | time: 7.144s
[2K
| RMSProp | epoch: 009 | loss: 0.69375 - acc: 0.4643 -- iter: 0288/1133
[A[ATraining Step: 298  | total loss: [1m[32m0.69365[0m[0m | time: 8.010s
[2K
| RMSProp | epoch: 009 | loss: 0.69365 - acc: 0.4710 -- iter: 0320/1133
[A[ATraining Step: 299  | total loss: [1m[32m0.69358[0m[0m | time: 9.005s
[2K
| RMSProp | epoch: 009 | loss: 0.69358 - acc: 0.4739 -- iter: 0352/1133
[A[ATraining Step: 300  | total loss: [1m[32m0.69354[0m[0m | time: 10.148s
[2K
| RMSProp | epoch: 009 | loss: 0.69354 - acc: 0.4734 -- iter: 0384/1133
[A[ATraining Step: 301  | total loss: [1m[32m0.69350[0m[0m | time: 11.323s
[2K
| RMSProp | epoch: 009 | loss: 0.69350 - acc: 0.4823 -- iter: 0416/1133
[A[ATraining Step: 302  | total loss: [1m[32m0.69340[0m[0m | time: 12.050s
[2K
| RMSProp | epoch: 009 | loss: 0.69340 - acc: 0.4841 -- iter: 0448/1133
[A[ATraining Step: 303  | total loss: [1m[32m0.69334[0m[0m | time: 12.984s
[2K
| RMSProp | epoch: 009 | loss: 0.69334 - acc: 0.4951 -- iter: 0480/1133
[A[ATraining Step: 304  | total loss: [1m[32m0.69334[0m[0m | time: 13.912s
[2K
| RMSProp | epoch: 009 | loss: 0.69334 - acc: 0.4893 -- iter: 0512/1133
[A[ATraining Step: 305  | total loss: [1m[32m0.69317[0m[0m | time: 14.837s
[2K
| RMSProp | epoch: 009 | loss: 0.69317 - acc: 0.5060 -- iter: 0544/1133
[A[ATraining Step: 306  | total loss: [1m[32m0.69323[0m[0m | time: 15.780s
[2K
| RMSProp | epoch: 009 | loss: 0.69323 - acc: 0.4991 -- iter: 0576/1133
[A[ATraining Step: 307  | total loss: [1m[32m0.69299[0m[0m | time: 16.751s
[2K
| RMSProp | epoch: 009 | loss: 0.69299 - acc: 0.5117 -- iter: 0608/1133
[A[ATraining Step: 308  | total loss: [1m[32m0.69291[0m[0m | time: 17.688s
[2K
| RMSProp | epoch: 009 | loss: 0.69291 - acc: 0.5137 -- iter: 0640/1133
[A[ATraining Step: 309  | total loss: [1m[32m0.69293[0m[0m | time: 18.578s
[2K
| RMSProp | epoch: 009 | loss: 0.69293 - acc: 0.5123 -- iter: 0672/1133
[A[ATraining Step: 310  | total loss: [1m[32m0.69261[0m[0m | time: 19.500s
[2K
| RMSProp | epoch: 009 | loss: 0.69261 - acc: 0.5173 -- iter: 0704/1133
[A[ATraining Step: 311  | total loss: [1m[32m0.69302[0m[0m | time: 20.454s
[2K
| RMSProp | epoch: 009 | loss: 0.69302 - acc: 0.5125 -- iter: 0736/1133
[A[ATraining Step: 312  | total loss: [1m[32m0.69276[0m[0m | time: 21.673s
[2K
| RMSProp | epoch: 009 | loss: 0.69276 - acc: 0.5175 -- iter: 0768/1133
[A[ATraining Step: 313  | total loss: [1m[32m0.69278[0m[0m | time: 22.739s
[2K
| RMSProp | epoch: 009 | loss: 0.69278 - acc: 0.5126 -- iter: 0800/1133
[A[ATraining Step: 314  | total loss: [1m[32m0.69274[0m[0m | time: 23.643s
[2K
| RMSProp | epoch: 009 | loss: 0.69274 - acc: 0.5051 -- iter: 0832/1133
[A[ATraining Step: 315  | total loss: [1m[32m0.69272[0m[0m | time: 24.519s
[2K
| RMSProp | epoch: 009 | loss: 0.69272 - acc: 0.5077 -- iter: 0864/1133
[A[ATraining Step: 316  | total loss: [1m[32m0.69215[0m[0m | time: 25.468s
[2K
| RMSProp | epoch: 009 | loss: 0.69215 - acc: 0.5163 -- iter: 0896/1133
[A[ATraining Step: 317  | total loss: [1m[32m0.69079[0m[0m | time: 26.371s
[2K
| RMSProp | epoch: 009 | loss: 0.69079 - acc: 0.5303 -- iter: 0928/1133
[A[ATraining Step: 318  | total loss: [1m[32m0.69329[0m[0m | time: 27.288s
[2K
| RMSProp | epoch: 009 | loss: 0.69329 - acc: 0.5242 -- iter: 0960/1133
[A[ATraining Step: 319  | total loss: [1m[32m0.69185[0m[0m | time: 28.255s
[2K
| RMSProp | epoch: 009 | loss: 0.69185 - acc: 0.5374 -- iter: 0992/1133
[A[ATraining Step: 320  | total loss: [1m[32m0.69124[0m[0m | time: 29.195s
[2K
| RMSProp | epoch: 009 | loss: 0.69124 - acc: 0.5399 -- iter: 1024/1133
[A[ATraining Step: 321  | total loss: [1m[32m0.68918[0m[0m | time: 30.090s
[2K
| RMSProp | epoch: 009 | loss: 0.68918 - acc: 0.5515 -- iter: 1056/1133
[A[ATraining Step: 322  | total loss: [1m[32m0.69793[0m[0m | time: 30.955s
[2K
| RMSProp | epoch: 009 | loss: 0.69793 - acc: 0.5245 -- iter: 1088/1133
[A[ATraining Step: 323  | total loss: [1m[32m0.69680[0m[0m | time: 31.842s
[2K
| RMSProp | epoch: 009 | loss: 0.69680 - acc: 0.5283 -- iter: 1120/1133
[A[ATraining Step: 324  | total loss: [1m[32m0.69579[0m[0m | time: 35.012s
[2K
| RMSProp | epoch: 009 | loss: 0.69579 - acc: 0.5317 | val_loss: 0.69267 - val_acc: 0.5014 -- iter: 1133/1133
--
Training Step: 325  | total loss: [1m[32m0.69511[0m[0m | time: 0.909s
[2K
| RMSProp | epoch: 010 | loss: 0.69511 - acc: 0.5317 -- iter: 0032/1133
[A[ATraining Step: 326  | total loss: [1m[32m0.69689[0m[0m | time: 1.903s
[2K
| RMSProp | epoch: 010 | loss: 0.69689 - acc: 0.5097 -- iter: 0064/1133
[A[ATraining Step: 327  | total loss: [1m[32m0.69660[0m[0m | time: 2.859s
[2K
| RMSProp | epoch: 010 | loss: 0.69660 - acc: 0.5056 -- iter: 0096/1133
[A[ATraining Step: 328  | total loss: [1m[32m0.69690[0m[0m | time: 3.802s
[2K
| RMSProp | epoch: 010 | loss: 0.69690 - acc: 0.4863 -- iter: 0128/1133
[A[ATraining Step: 329  | total loss: [1m[32m0.69570[0m[0m | time: 4.680s
[2K
| RMSProp | epoch: 010 | loss: 0.69570 - acc: 0.5033 -- iter: 0160/1133
[A[ATraining Step: 330  | total loss: [1m[32m0.69626[0m[0m | time: 5.799s
[2K
| RMSProp | epoch: 010 | loss: 0.69626 - acc: 0.4967 -- iter: 0192/1133
[A[ATraining Step: 331  | total loss: [1m[32m0.69543[0m[0m | time: 6.960s
[2K
| RMSProp | epoch: 010 | loss: 0.69543 - acc: 0.5127 -- iter: 0224/1133
[A[ATraining Step: 332  | total loss: [1m[32m0.69439[0m[0m | time: 7.546s
[2K
| RMSProp | epoch: 010 | loss: 0.69439 - acc: 0.5302 -- iter: 0256/1133
[A[ATraining Step: 333  | total loss: [1m[32m0.69292[0m[0m | time: 8.049s
[2K
| RMSProp | epoch: 010 | loss: 0.69292 - acc: 0.5387 -- iter: 0288/1133
[A[ATraining Step: 334  | total loss: [1m[32m0.69027[0m[0m | time: 8.779s
[2K
| RMSProp | epoch: 010 | loss: 0.69027 - acc: 0.5464 -- iter: 0320/1133
[A[ATraining Step: 335  | total loss: [1m[32m0.69151[0m[0m | time: 9.661s
[2K
| RMSProp | epoch: 010 | loss: 0.69151 - acc: 0.5324 -- iter: 0352/1133
[A[ATraining Step: 336  | total loss: [1m[32m0.69323[0m[0m | time: 10.612s
[2K
| RMSProp | epoch: 010 | loss: 0.69323 - acc: 0.5135 -- iter: 0384/1133
[A[ATraining Step: 337  | total loss: [1m[32m0.69202[0m[0m | time: 11.560s
[2K
| RMSProp | epoch: 010 | loss: 0.69202 - acc: 0.5371 -- iter: 0416/1133
[A[ATraining Step: 338  | total loss: [1m[32m0.69342[0m[0m | time: 12.510s
[2K
| RMSProp | epoch: 010 | loss: 0.69342 - acc: 0.5303 -- iter: 0448/1133
[A[ATraining Step: 339  | total loss: [1m[32m0.69232[0m[0m | time: 13.446s
[2K
| RMSProp | epoch: 010 | loss: 0.69232 - acc: 0.5429 -- iter: 0480/1133
[A[ATraining Step: 340  | total loss: [1m[32m0.69446[0m[0m | time: 14.368s
[2K
| RMSProp | epoch: 010 | loss: 0.69446 - acc: 0.5292 -- iter: 0512/1133
[A[ATraining Step: 341  | total loss: [1m[32m0.69399[0m[0m | time: 15.298s
[2K
| RMSProp | epoch: 010 | loss: 0.69399 - acc: 0.5326 -- iter: 0544/1133
[A[ATraining Step: 342  | total loss: [1m[32m0.69365[0m[0m | time: 16.180s
[2K
| RMSProp | epoch: 010 | loss: 0.69365 - acc: 0.5293 -- iter: 0576/1133
[A[ATraining Step: 343  | total loss: [1m[32m0.69340[0m[0m | time: 17.089s
[2K
| RMSProp | epoch: 010 | loss: 0.69340 - acc: 0.5295 -- iter: 0608/1133
[A[ATraining Step: 344  | total loss: [1m[32m0.69317[0m[0m | time: 18.314s
[2K
| RMSProp | epoch: 010 | loss: 0.69317 - acc: 0.5297 -- iter: 0640/1133
[A[ATraining Step: 345  | total loss: [1m[32m0.69141[0m[0m | time: 19.397s
[2K
| RMSProp | epoch: 010 | loss: 0.69141 - acc: 0.5423 -- iter: 0672/1133
[A[ATraining Step: 346  | total loss: [1m[32m0.69239[0m[0m | time: 20.246s
[2K
| RMSProp | epoch: 010 | loss: 0.69239 - acc: 0.5318 -- iter: 0704/1133
[A[ATraining Step: 347  | total loss: [1m[32m0.69228[0m[0m | time: 21.105s
[2K
| RMSProp | epoch: 010 | loss: 0.69228 - acc: 0.5380 -- iter: 0736/1133
[A[ATraining Step: 348  | total loss: [1m[32m0.69166[0m[0m | time: 22.005s
[2K
| RMSProp | epoch: 010 | loss: 0.69166 - acc: 0.5436 -- iter: 0768/1133
[A[ATraining Step: 349  | total loss: [1m[32m0.68946[0m[0m | time: 22.946s
[2K
| RMSProp | epoch: 010 | loss: 0.68946 - acc: 0.5486 -- iter: 0800/1133
[A[ATraining Step: 350  | total loss: [1m[32m0.68968[0m[0m | time: 23.842s
[2K
| RMSProp | epoch: 010 | loss: 0.68968 - acc: 0.5438 -- iter: 0832/1133
[A[ATraining Step: 351  | total loss: [1m[32m0.68802[0m[0m | time: 24.760s
[2K
| RMSProp | epoch: 010 | loss: 0.68802 - acc: 0.5519 -- iter: 0864/1133
[A[ATraining Step: 352  | total loss: [1m[32m0.68723[0m[0m | time: 25.662s
[2K
| RMSProp | epoch: 010 | loss: 0.68723 - acc: 0.5529 -- iter: 0896/1133
[A[ATraining Step: 353  | total loss: [1m[32m0.68636[0m[0m | time: 26.588s
[2K
| RMSProp | epoch: 010 | loss: 0.68636 - acc: 0.5539 -- iter: 0928/1133
[A[ATraining Step: 354  | total loss: [1m[32m0.68701[0m[0m | time: 27.559s
[2K
| RMSProp | epoch: 010 | loss: 0.68701 - acc: 0.5485 -- iter: 0960/1133
[A[ATraining Step: 355  | total loss: [1m[32m0.68667[0m[0m | time: 28.457s
[2K
| RMSProp | epoch: 010 | loss: 0.68667 - acc: 0.5468 -- iter: 0992/1133
[A[ATraining Step: 356  | total loss: [1m[32m0.68390[0m[0m | time: 29.385s
[2K
| RMSProp | epoch: 010 | loss: 0.68390 - acc: 0.5577 -- iter: 1024/1133
[A[ATraining Step: 357  | total loss: [1m[32m0.68133[0m[0m | time: 30.531s
[2K
| RMSProp | epoch: 010 | loss: 0.68133 - acc: 0.5582 -- iter: 1056/1133
[A[ATraining Step: 358  | total loss: [1m[32m0.69165[0m[0m | time: 31.603s
[2K
| RMSProp | epoch: 010 | loss: 0.69165 - acc: 0.5368 -- iter: 1088/1133
[A[ATraining Step: 359  | total loss: [1m[32m0.68903[0m[0m | time: 32.436s
[2K
| RMSProp | epoch: 010 | loss: 0.68903 - acc: 0.5550 -- iter: 1120/1133
[A[ATraining Step: 360  | total loss: [1m[32m0.68761[0m[0m | time: 35.050s
[2K
| RMSProp | epoch: 010 | loss: 0.68761 - acc: 0.5651 | val_loss: 0.67649 - val_acc: 0.5915 -- iter: 1133/1133
--
Training Step: 361  | total loss: [1m[32m0.68422[0m[0m | time: 0.847s
[2K
| RMSProp | epoch: 011 | loss: 0.68422 - acc: 0.5680 -- iter: 0032/1133
[A[ATraining Step: 362  | total loss: [1m[32m0.68024[0m[0m | time: 1.922s
[2K
| RMSProp | epoch: 011 | loss: 0.68024 - acc: 0.5830 -- iter: 0064/1133
[A[ATraining Step: 363  | total loss: [1m[32m0.67784[0m[0m | time: 3.107s
[2K
| RMSProp | epoch: 011 | loss: 0.67784 - acc: 0.5841 -- iter: 0096/1133
[A[ATraining Step: 364  | total loss: [1m[32m0.67293[0m[0m | time: 4.131s
[2K
| RMSProp | epoch: 011 | loss: 0.67293 - acc: 0.5944 -- iter: 0128/1133
[A[ATraining Step: 365  | total loss: [1m[32m0.67190[0m[0m | time: 4.883s
[2K
| RMSProp | epoch: 011 | loss: 0.67190 - acc: 0.6006 -- iter: 0160/1133
[A[ATraining Step: 366  | total loss: [1m[32m0.67049[0m[0m | time: 5.768s
[2K
| RMSProp | epoch: 011 | loss: 0.67049 - acc: 0.6031 -- iter: 0192/1133
[A[ATraining Step: 367  | total loss: [1m[32m0.66926[0m[0m | time: 6.685s
[2K
| RMSProp | epoch: 011 | loss: 0.66926 - acc: 0.6053 -- iter: 0224/1133
[A[ATraining Step: 368  | total loss: [1m[32m0.67280[0m[0m | time: 7.581s
[2K
| RMSProp | epoch: 011 | loss: 0.67280 - acc: 0.6010 -- iter: 0256/1133
[A[ATraining Step: 369  | total loss: [1m[32m0.67392[0m[0m | time: 8.002s
[2K
| RMSProp | epoch: 011 | loss: 0.67392 - acc: 0.5940 -- iter: 0288/1133
[A[ATraining Step: 370  | total loss: [1m[32m0.66050[0m[0m | time: 8.401s
[2K
| RMSProp | epoch: 011 | loss: 0.66050 - acc: 0.6192 -- iter: 0320/1133
[A[ATraining Step: 371  | total loss: [1m[32m0.64052[0m[0m | time: 9.313s
[2K
| RMSProp | epoch: 011 | loss: 0.64052 - acc: 0.6342 -- iter: 0352/1133
[A[ATraining Step: 372  | total loss: [1m[32m0.64978[0m[0m | time: 10.211s
[2K
| RMSProp | epoch: 011 | loss: 0.64978 - acc: 0.6208 -- iter: 0384/1133
[A[ATraining Step: 373  | total loss: [1m[32m0.65099[0m[0m | time: 11.134s
[2K
| RMSProp | epoch: 011 | loss: 0.65099 - acc: 0.6150 -- iter: 0416/1133
[A[ATraining Step: 374  | total loss: [1m[32m0.65023[0m[0m | time: 12.087s
[2K
| RMSProp | epoch: 011 | loss: 0.65023 - acc: 0.6191 -- iter: 0448/1133
[A[ATraining Step: 375  | total loss: [1m[32m0.65131[0m[0m | time: 12.907s
[2K
| RMSProp | epoch: 011 | loss: 0.65131 - acc: 0.6166 -- iter: 0480/1133
[A[ATraining Step: 376  | total loss: [1m[32m0.65053[0m[0m | time: 14.049s
[2K
| RMSProp | epoch: 011 | loss: 0.65053 - acc: 0.6112 -- iter: 0512/1133
[A[ATraining Step: 377  | total loss: [1m[32m0.65429[0m[0m | time: 15.162s
[2K
| RMSProp | epoch: 011 | loss: 0.65429 - acc: 0.6188 -- iter: 0544/1133
[A[ATraining Step: 378  | total loss: [1m[32m0.65457[0m[0m | time: 16.114s
[2K
| RMSProp | epoch: 011 | loss: 0.65457 - acc: 0.6100 -- iter: 0576/1133
[A[ATraining Step: 379  | total loss: [1m[32m0.66115[0m[0m | time: 16.991s
[2K
| RMSProp | epoch: 011 | loss: 0.66115 - acc: 0.6022 -- iter: 0608/1133
[A[ATraining Step: 380  | total loss: [1m[32m0.66184[0m[0m | time: 17.908s
[2K
| RMSProp | epoch: 011 | loss: 0.66184 - acc: 0.6013 -- iter: 0640/1133
[A[ATraining Step: 381  | total loss: [1m[32m0.66247[0m[0m | time: 18.854s
[2K
| RMSProp | epoch: 011 | loss: 0.66247 - acc: 0.5943 -- iter: 0672/1133
[A[ATraining Step: 382  | total loss: [1m[32m0.66515[0m[0m | time: 19.778s
[2K
| RMSProp | epoch: 011 | loss: 0.66515 - acc: 0.5911 -- iter: 0704/1133
[A[ATraining Step: 383  | total loss: [1m[32m0.66451[0m[0m | time: 20.737s
[2K
| RMSProp | epoch: 011 | loss: 0.66451 - acc: 0.5976 -- iter: 0736/1133
[A[ATraining Step: 384  | total loss: [1m[32m0.66036[0m[0m | time: 21.737s
[2K
| RMSProp | epoch: 011 | loss: 0.66036 - acc: 0.6066 -- iter: 0768/1133
[A[ATraining Step: 385  | total loss: [1m[32m0.65585[0m[0m | time: 22.751s
[2K
| RMSProp | epoch: 011 | loss: 0.65585 - acc: 0.6116 -- iter: 0800/1133
[A[ATraining Step: 386  | total loss: [1m[32m0.64912[0m[0m | time: 23.625s
[2K
| RMSProp | epoch: 011 | loss: 0.64912 - acc: 0.6254 -- iter: 0832/1133
[A[ATraining Step: 387  | total loss: [1m[32m0.65867[0m[0m | time: 24.526s
[2K
| RMSProp | epoch: 011 | loss: 0.65867 - acc: 0.6160 -- iter: 0864/1133
[A[ATraining Step: 388  | total loss: [1m[32m0.65902[0m[0m | time: 25.628s
[2K
| RMSProp | epoch: 011 | loss: 0.65902 - acc: 0.6107 -- iter: 0896/1133
[A[ATraining Step: 389  | total loss: [1m[32m0.65342[0m[0m | time: 26.779s
[2K
| RMSProp | epoch: 011 | loss: 0.65342 - acc: 0.6215 -- iter: 0928/1133
[A[ATraining Step: 390  | total loss: [1m[32m0.65098[0m[0m | time: 27.694s
[2K
| RMSProp | epoch: 011 | loss: 0.65098 - acc: 0.6218 -- iter: 0960/1133
[A[ATraining Step: 391  | total loss: [1m[32m0.65096[0m[0m | time: 28.511s
[2K
| RMSProp | epoch: 011 | loss: 0.65096 - acc: 0.6190 -- iter: 0992/1133
[A[ATraining Step: 392  | total loss: [1m[32m0.64366[0m[0m | time: 29.421s
[2K
| RMSProp | epoch: 011 | loss: 0.64366 - acc: 0.6259 -- iter: 1024/1133
[A[ATraining Step: 393  | total loss: [1m[32m0.64618[0m[0m | time: 30.341s
[2K
| RMSProp | epoch: 011 | loss: 0.64618 - acc: 0.6195 -- iter: 1056/1133
[A[ATraining Step: 394  | total loss: [1m[32m0.64793[0m[0m | time: 31.271s
[2K
| RMSProp | epoch: 011 | loss: 0.64793 - acc: 0.6201 -- iter: 1088/1133
[A[ATraining Step: 395  | total loss: [1m[32m0.64681[0m[0m | time: 32.128s
[2K
| RMSProp | epoch: 011 | loss: 0.64681 - acc: 0.6331 -- iter: 1120/1133
[A[ATraining Step: 396  | total loss: [1m[32m0.65426[0m[0m | time: 34.879s
[2K
| RMSProp | epoch: 011 | loss: 0.65426 - acc: 0.6166 | val_loss: 0.63390 - val_acc: 0.5944 -- iter: 1133/1133
--
Training Step: 397  | total loss: [1m[32m0.64375[0m[0m | time: 1.084s
[2K
| RMSProp | epoch: 012 | loss: 0.64375 - acc: 0.6393 -- iter: 0032/1133
[A[ATraining Step: 398  | total loss: [1m[32m0.63768[0m[0m | time: 1.941s
[2K
| RMSProp | epoch: 012 | loss: 0.63768 - acc: 0.6410 -- iter: 0064/1133
[A[ATraining Step: 399  | total loss: [1m[32m0.64214[0m[0m | time: 2.746s
[2K
| RMSProp | epoch: 012 | loss: 0.64214 - acc: 0.6238 -- iter: 0096/1133
[A[ATraining Step: 400  | total loss: [1m[32m0.63810[0m[0m | time: 5.381s
[2K
| RMSProp | epoch: 012 | loss: 0.63810 - acc: 0.6271 | val_loss: 0.61989 - val_acc: 0.6873 -- iter: 0128/1133
--
Training Step: 401  | total loss: [1m[32m0.64418[0m[0m | time: 6.398s
[2K
| RMSProp | epoch: 012 | loss: 0.64418 - acc: 0.6237 -- iter: 0160/1133
[A[ATraining Step: 402  | total loss: [1m[32m0.63744[0m[0m | time: 7.321s
[2K
| RMSProp | epoch: 012 | loss: 0.63744 - acc: 0.6395 -- iter: 0192/1133
[A[ATraining Step: 403  | total loss: [1m[32m0.63131[0m[0m | time: 8.228s
[2K
| RMSProp | epoch: 012 | loss: 0.63131 - acc: 0.6474 -- iter: 0224/1133
[A[ATraining Step: 404  | total loss: [1m[32m0.63558[0m[0m | time: 9.181s
[2K
| RMSProp | epoch: 012 | loss: 0.63558 - acc: 0.6452 -- iter: 0256/1133
[A[ATraining Step: 405  | total loss: [1m[32m0.64002[0m[0m | time: 10.206s
[2K
| RMSProp | epoch: 012 | loss: 0.64002 - acc: 0.6369 -- iter: 0288/1133
[A[ATraining Step: 406  | total loss: [1m[32m0.63578[0m[0m | time: 10.722s
[2K
| RMSProp | epoch: 012 | loss: 0.63578 - acc: 0.6482 -- iter: 0320/1133
[A[ATraining Step: 407  | total loss: [1m[32m0.63038[0m[0m | time: 11.231s
[2K
| RMSProp | epoch: 012 | loss: 0.63038 - acc: 0.6526 -- iter: 0352/1133
[A[ATraining Step: 408  | total loss: [1m[32m0.61972[0m[0m | time: 12.319s
[2K
| RMSProp | epoch: 012 | loss: 0.61972 - acc: 0.6720 -- iter: 0384/1133
[A[ATraining Step: 409  | total loss: [1m[32m0.61152[0m[0m | time: 13.020s
[2K
| RMSProp | epoch: 012 | loss: 0.61152 - acc: 0.6766 -- iter: 0416/1133
[A[ATraining Step: 410  | total loss: [1m[32m0.60517[0m[0m | time: 13.841s
[2K
| RMSProp | epoch: 012 | loss: 0.60517 - acc: 0.6715 -- iter: 0448/1133
[A[ATraining Step: 411  | total loss: [1m[32m0.60895[0m[0m | time: 14.716s
[2K
| RMSProp | epoch: 012 | loss: 0.60895 - acc: 0.6575 -- iter: 0480/1133
[A[ATraining Step: 412  | total loss: [1m[32m0.64652[0m[0m | time: 15.622s
[2K
| RMSProp | epoch: 012 | loss: 0.64652 - acc: 0.6230 -- iter: 0512/1133
[A[ATraining Step: 413  | total loss: [1m[32m0.64431[0m[0m | time: 16.521s
[2K
| RMSProp | epoch: 012 | loss: 0.64431 - acc: 0.6232 -- iter: 0544/1133
[A[ATraining Step: 414  | total loss: [1m[32m0.63856[0m[0m | time: 17.413s
[2K
| RMSProp | epoch: 012 | loss: 0.63856 - acc: 0.6296 -- iter: 0576/1133
[A[ATraining Step: 415  | total loss: [1m[32m0.63476[0m[0m | time: 18.303s
[2K
| RMSProp | epoch: 012 | loss: 0.63476 - acc: 0.6385 -- iter: 0608/1133
[A[ATraining Step: 416  | total loss: [1m[32m0.62066[0m[0m | time: 19.155s
[2K
| RMSProp | epoch: 012 | loss: 0.62066 - acc: 0.6559 -- iter: 0640/1133
[A[ATraining Step: 417  | total loss: [1m[32m0.61966[0m[0m | time: 20.054s
[2K
| RMSProp | epoch: 012 | loss: 0.61966 - acc: 0.6622 -- iter: 0672/1133
[A[ATraining Step: 418  | total loss: [1m[32m0.63060[0m[0m | time: 20.956s
[2K
| RMSProp | epoch: 012 | loss: 0.63060 - acc: 0.6491 -- iter: 0704/1133
[A[ATraining Step: 419  | total loss: [1m[32m0.63555[0m[0m | time: 21.918s
[2K
| RMSProp | epoch: 012 | loss: 0.63555 - acc: 0.6404 -- iter: 0736/1133
[A[ATraining Step: 420  | total loss: [1m[32m0.62751[0m[0m | time: 22.989s
[2K
| RMSProp | epoch: 012 | loss: 0.62751 - acc: 0.6514 -- iter: 0768/1133
[A[ATraining Step: 421  | total loss: [1m[32m0.61460[0m[0m | time: 24.053s
[2K
| RMSProp | epoch: 012 | loss: 0.61460 - acc: 0.6675 -- iter: 0800/1133
[A[ATraining Step: 422  | total loss: [1m[32m0.60584[0m[0m | time: 24.777s
[2K
| RMSProp | epoch: 012 | loss: 0.60584 - acc: 0.6820 -- iter: 0832/1133
[A[ATraining Step: 423  | total loss: [1m[32m0.60434[0m[0m | time: 25.647s
[2K
| RMSProp | epoch: 012 | loss: 0.60434 - acc: 0.6888 -- iter: 0864/1133
[A[ATraining Step: 424  | total loss: [1m[32m0.60003[0m[0m | time: 26.575s
[2K
| RMSProp | epoch: 012 | loss: 0.60003 - acc: 0.6918 -- iter: 0896/1133
[A[ATraining Step: 425  | total loss: [1m[32m0.60742[0m[0m | time: 27.464s
[2K
| RMSProp | epoch: 012 | loss: 0.60742 - acc: 0.6851 -- iter: 0928/1133
[A[ATraining Step: 426  | total loss: [1m[32m0.59757[0m[0m | time: 28.396s
[2K
| RMSProp | epoch: 012 | loss: 0.59757 - acc: 0.6916 -- iter: 0960/1133
[A[ATraining Step: 427  | total loss: [1m[32m0.58533[0m[0m | time: 29.322s
[2K
| RMSProp | epoch: 012 | loss: 0.58533 - acc: 0.7068 -- iter: 0992/1133
[A[ATraining Step: 428  | total loss: [1m[32m0.58407[0m[0m | time: 30.233s
[2K
| RMSProp | epoch: 012 | loss: 0.58407 - acc: 0.7080 -- iter: 1024/1133
[A[ATraining Step: 429  | total loss: [1m[32m0.57358[0m[0m | time: 31.138s
[2K
| RMSProp | epoch: 012 | loss: 0.57358 - acc: 0.7185 -- iter: 1056/1133
[A[ATraining Step: 430  | total loss: [1m[32m0.56451[0m[0m | time: 32.051s
[2K
| RMSProp | epoch: 012 | loss: 0.56451 - acc: 0.7247 -- iter: 1088/1133
[A[ATraining Step: 431  | total loss: [1m[32m0.57646[0m[0m | time: 32.846s
[2K
| RMSProp | epoch: 012 | loss: 0.57646 - acc: 0.7085 -- iter: 1120/1133
[A[ATraining Step: 432  | total loss: [1m[32m0.59465[0m[0m | time: 36.174s
[2K
| RMSProp | epoch: 012 | loss: 0.59465 - acc: 0.6877 | val_loss: 0.60479 - val_acc: 0.6563 -- iter: 1133/1133
--
Training Step: 433  | total loss: [1m[32m0.58998[0m[0m | time: 1.022s
[2K
| RMSProp | epoch: 013 | loss: 0.58998 - acc: 0.7002 -- iter: 0032/1133
[A[ATraining Step: 434  | total loss: [1m[32m0.58332[0m[0m | time: 1.970s
[2K
| RMSProp | epoch: 013 | loss: 0.58332 - acc: 0.7020 -- iter: 0064/1133
[A[ATraining Step: 435  | total loss: [1m[32m0.57806[0m[0m | time: 2.871s
[2K
| RMSProp | epoch: 013 | loss: 0.57806 - acc: 0.7068 -- iter: 0096/1133
[A[ATraining Step: 436  | total loss: [1m[32m0.57490[0m[0m | time: 3.794s
[2K
| RMSProp | epoch: 013 | loss: 0.57490 - acc: 0.7018 -- iter: 0128/1133
[A[ATraining Step: 437  | total loss: [1m[32m0.56816[0m[0m | time: 4.716s
[2K
| RMSProp | epoch: 013 | loss: 0.56816 - acc: 0.7128 -- iter: 0160/1133
[A[ATraining Step: 438  | total loss: [1m[32m0.55160[0m[0m | time: 5.610s
[2K
| RMSProp | epoch: 013 | loss: 0.55160 - acc: 0.7259 -- iter: 0192/1133
[A[ATraining Step: 439  | total loss: [1m[32m0.54985[0m[0m | time: 6.480s
[2K
| RMSProp | epoch: 013 | loss: 0.54985 - acc: 0.7252 -- iter: 0224/1133
[A[ATraining Step: 440  | total loss: [1m[32m0.54517[0m[0m | time: 7.424s
[2K
| RMSProp | epoch: 013 | loss: 0.54517 - acc: 0.7308 -- iter: 0256/1133
[A[ATraining Step: 441  | total loss: [1m[32m0.55605[0m[0m | time: 8.618s
[2K
| RMSProp | epoch: 013 | loss: 0.55605 - acc: 0.7202 -- iter: 0288/1133
[A[ATraining Step: 442  | total loss: [1m[32m0.55391[0m[0m | time: 9.753s
[2K
| RMSProp | epoch: 013 | loss: 0.55391 - acc: 0.7232 -- iter: 0320/1133
[A[ATraining Step: 443  | total loss: [1m[32m0.55068[0m[0m | time: 10.156s
[2K
| RMSProp | epoch: 013 | loss: 0.55068 - acc: 0.7259 -- iter: 0352/1133
[A[ATraining Step: 444  | total loss: [1m[32m0.54276[0m[0m | time: 10.454s
[2K
| RMSProp | epoch: 013 | loss: 0.54276 - acc: 0.7225 -- iter: 0384/1133
[A[ATraining Step: 445  | total loss: [1m[32m0.52362[0m[0m | time: 11.364s
[2K
| RMSProp | epoch: 013 | loss: 0.52362 - acc: 0.7426 -- iter: 0416/1133
[A[ATraining Step: 446  | total loss: [1m[32m0.52308[0m[0m | time: 12.274s
[2K
| RMSProp | epoch: 013 | loss: 0.52308 - acc: 0.7402 -- iter: 0448/1133
[A[ATraining Step: 447  | total loss: [1m[32m0.54669[0m[0m | time: 13.169s
[2K
| RMSProp | epoch: 013 | loss: 0.54669 - acc: 0.7256 -- iter: 0480/1133
[A[ATraining Step: 448  | total loss: [1m[32m0.55378[0m[0m | time: 14.111s
[2K
| RMSProp | epoch: 013 | loss: 0.55378 - acc: 0.7311 -- iter: 0512/1133
[A[ATraining Step: 449  | total loss: [1m[32m0.55234[0m[0m | time: 15.011s
[2K
| RMSProp | epoch: 013 | loss: 0.55234 - acc: 0.7299 -- iter: 0544/1133
[A[ATraining Step: 450  | total loss: [1m[32m0.54181[0m[0m | time: 15.924s
[2K
| RMSProp | epoch: 013 | loss: 0.54181 - acc: 0.7475 -- iter: 0576/1133
[A[ATraining Step: 451  | total loss: [1m[32m0.53627[0m[0m | time: 16.942s
[2K
| RMSProp | epoch: 013 | loss: 0.53627 - acc: 0.7540 -- iter: 0608/1133
[A[ATraining Step: 452  | total loss: [1m[32m0.52542[0m[0m | time: 17.829s
[2K
| RMSProp | epoch: 013 | loss: 0.52542 - acc: 0.7630 -- iter: 0640/1133
[A[ATraining Step: 453  | total loss: [1m[32m0.51263[0m[0m | time: 18.683s
[2K
| RMSProp | epoch: 013 | loss: 0.51263 - acc: 0.7711 -- iter: 0672/1133
[A[ATraining Step: 454  | total loss: [1m[32m0.53043[0m[0m | time: 19.919s
[2K
| RMSProp | epoch: 013 | loss: 0.53043 - acc: 0.7533 -- iter: 0704/1133
[A[ATraining Step: 455  | total loss: [1m[32m0.52571[0m[0m | time: 21.033s
[2K
| RMSProp | epoch: 013 | loss: 0.52571 - acc: 0.7468 -- iter: 0736/1133
[A[ATraining Step: 456  | total loss: [1m[32m0.51731[0m[0m | time: 21.930s
[2K
| RMSProp | epoch: 013 | loss: 0.51731 - acc: 0.7533 -- iter: 0768/1133
[A[ATraining Step: 457  | total loss: [1m[32m0.52267[0m[0m | time: 22.835s
[2K
| RMSProp | epoch: 013 | loss: 0.52267 - acc: 0.7436 -- iter: 0800/1133
[A[ATraining Step: 458  | total loss: [1m[32m0.51202[0m[0m | time: 23.739s
[2K
| RMSProp | epoch: 013 | loss: 0.51202 - acc: 0.7536 -- iter: 0832/1133
[A[ATraining Step: 459  | total loss: [1m[32m0.52932[0m[0m | time: 24.702s
[2K
| RMSProp | epoch: 013 | loss: 0.52932 - acc: 0.7376 -- iter: 0864/1133
[A[ATraining Step: 460  | total loss: [1m[32m0.53314[0m[0m | time: 25.630s
[2K
| RMSProp | epoch: 013 | loss: 0.53314 - acc: 0.7389 -- iter: 0896/1133
[A[ATraining Step: 461  | total loss: [1m[32m0.52652[0m[0m | time: 26.530s
[2K
| RMSProp | epoch: 013 | loss: 0.52652 - acc: 0.7462 -- iter: 0928/1133
[A[ATraining Step: 462  | total loss: [1m[32m0.52471[0m[0m | time: 27.454s
[2K
| RMSProp | epoch: 013 | loss: 0.52471 - acc: 0.7466 -- iter: 0960/1133
[A[ATraining Step: 463  | total loss: [1m[32m0.51935[0m[0m | time: 28.378s
[2K
| RMSProp | epoch: 013 | loss: 0.51935 - acc: 0.7532 -- iter: 0992/1133
[A[ATraining Step: 464  | total loss: [1m[32m0.50804[0m[0m | time: 29.320s
[2K
| RMSProp | epoch: 013 | loss: 0.50804 - acc: 0.7591 -- iter: 1024/1133
[A[ATraining Step: 465  | total loss: [1m[32m0.51019[0m[0m | time: 30.142s
[2K
| RMSProp | epoch: 013 | loss: 0.51019 - acc: 0.7613 -- iter: 1056/1133
[A[ATraining Step: 466  | total loss: [1m[32m0.50228[0m[0m | time: 31.203s
[2K
| RMSProp | epoch: 013 | loss: 0.50228 - acc: 0.7696 -- iter: 1088/1133
[A[ATraining Step: 467  | total loss: [1m[32m0.49009[0m[0m | time: 32.333s
[2K
| RMSProp | epoch: 013 | loss: 0.49009 - acc: 0.7801 -- iter: 1120/1133
[A[ATraining Step: 468  | total loss: [1m[32m0.49204[0m[0m | time: 34.940s
[2K
| RMSProp | epoch: 013 | loss: 0.49204 - acc: 0.7771 | val_loss: 0.75716 - val_acc: 0.6113 -- iter: 1133/1133
--
Training Step: 469  | total loss: [1m[32m0.49229[0m[0m | time: 0.936s
[2K
| RMSProp | epoch: 014 | loss: 0.49229 - acc: 0.7775 -- iter: 0032/1133
[A[ATraining Step: 470  | total loss: [1m[32m0.51260[0m[0m | time: 1.843s
[2K
| RMSProp | epoch: 014 | loss: 0.51260 - acc: 0.7560 -- iter: 0064/1133
[A[ATraining Step: 471  | total loss: [1m[32m0.49856[0m[0m | time: 2.761s
[2K
| RMSProp | epoch: 014 | loss: 0.49856 - acc: 0.7648 -- iter: 0096/1133
[A[ATraining Step: 472  | total loss: [1m[32m0.49885[0m[0m | time: 3.704s
[2K
| RMSProp | epoch: 014 | loss: 0.49885 - acc: 0.7633 -- iter: 0128/1133
[A[ATraining Step: 473  | total loss: [1m[32m0.48508[0m[0m | time: 4.640s
[2K
| RMSProp | epoch: 014 | loss: 0.48508 - acc: 0.7745 -- iter: 0160/1133
[A[ATraining Step: 474  | total loss: [1m[32m0.48394[0m[0m | time: 5.569s
[2K
| RMSProp | epoch: 014 | loss: 0.48394 - acc: 0.7689 -- iter: 0192/1133
[A[ATraining Step: 475  | total loss: [1m[32m0.48794[0m[0m | time: 6.427s
[2K
| RMSProp | epoch: 014 | loss: 0.48794 - acc: 0.7670 -- iter: 0224/1133
[A[ATraining Step: 476  | total loss: [1m[32m0.50643[0m[0m | time: 7.352s
[2K
| RMSProp | epoch: 014 | loss: 0.50643 - acc: 0.7497 -- iter: 0256/1133
[A[ATraining Step: 477  | total loss: [1m[32m0.51476[0m[0m | time: 8.490s
[2K
| RMSProp | epoch: 014 | loss: 0.51476 - acc: 0.7435 -- iter: 0288/1133
[A[ATraining Step: 478  | total loss: [1m[32m0.50770[0m[0m | time: 9.636s
[2K
| RMSProp | epoch: 014 | loss: 0.50770 - acc: 0.7441 -- iter: 0320/1133
[A[ATraining Step: 479  | total loss: [1m[32m0.50318[0m[0m | time: 10.397s
[2K
| RMSProp | epoch: 014 | loss: 0.50318 - acc: 0.7447 -- iter: 0352/1133
[A[ATraining Step: 480  | total loss: [1m[32m0.53093[0m[0m | time: 10.781s
[2K
| RMSProp | epoch: 014 | loss: 0.53093 - acc: 0.7296 -- iter: 0384/1133
[A[ATraining Step: 481  | total loss: [1m[32m0.52055[0m[0m | time: 11.198s
[2K
| RMSProp | epoch: 014 | loss: 0.52055 - acc: 0.7413 -- iter: 0416/1133
[A[ATraining Step: 482  | total loss: [1m[32m0.49416[0m[0m | time: 12.119s
[2K
| RMSProp | epoch: 014 | loss: 0.49416 - acc: 0.7595 -- iter: 0448/1133
[A[ATraining Step: 483  | total loss: [1m[32m0.49169[0m[0m | time: 13.058s
[2K
| RMSProp | epoch: 014 | loss: 0.49169 - acc: 0.7616 -- iter: 0480/1133
[A[ATraining Step: 484  | total loss: [1m[32m0.48042[0m[0m | time: 14.032s
[2K
| RMSProp | epoch: 014 | loss: 0.48042 - acc: 0.7636 -- iter: 0512/1133
[A[ATraining Step: 485  | total loss: [1m[32m0.47256[0m[0m | time: 14.939s
[2K
| RMSProp | epoch: 014 | loss: 0.47256 - acc: 0.7716 -- iter: 0544/1133
[A[ATraining Step: 486  | total loss: [1m[32m0.53866[0m[0m | time: 15.891s
[2K
| RMSProp | epoch: 014 | loss: 0.53866 - acc: 0.7444 -- iter: 0576/1133
[A[ATraining Step: 487  | total loss: [1m[32m0.53608[0m[0m | time: 16.824s
[2K
| RMSProp | epoch: 014 | loss: 0.53608 - acc: 0.7388 -- iter: 0608/1133
[A[ATraining Step: 488  | total loss: [1m[32m0.52153[0m[0m | time: 17.696s
[2K
| RMSProp | epoch: 014 | loss: 0.52153 - acc: 0.7586 -- iter: 0640/1133
[A[ATraining Step: 489  | total loss: [1m[32m0.50505[0m[0m | time: 18.702s
[2K
| RMSProp | epoch: 014 | loss: 0.50505 - acc: 0.7671 -- iter: 0672/1133
[A[ATraining Step: 490  | total loss: [1m[32m0.50918[0m[0m | time: 19.777s
[2K
| RMSProp | epoch: 014 | loss: 0.50918 - acc: 0.7592 -- iter: 0704/1133
[A[ATraining Step: 491  | total loss: [1m[32m0.51332[0m[0m | time: 20.890s
[2K
| RMSProp | epoch: 014 | loss: 0.51332 - acc: 0.7551 -- iter: 0736/1133
[A[ATraining Step: 492  | total loss: [1m[32m0.50197[0m[0m | time: 21.593s
[2K
| RMSProp | epoch: 014 | loss: 0.50197 - acc: 0.7640 -- iter: 0768/1133
[A[ATraining Step: 493  | total loss: [1m[32m0.49009[0m[0m | time: 22.474s
[2K
| RMSProp | epoch: 014 | loss: 0.49009 - acc: 0.7720 -- iter: 0800/1133
[A[ATraining Step: 494  | total loss: [1m[32m0.48917[0m[0m | time: 23.352s
[2K
| RMSProp | epoch: 014 | loss: 0.48917 - acc: 0.7729 -- iter: 0832/1133
[A[ATraining Step: 495  | total loss: [1m[32m0.49885[0m[0m | time: 24.269s
[2K
| RMSProp | epoch: 014 | loss: 0.49885 - acc: 0.7612 -- iter: 0864/1133
[A[ATraining Step: 496  | total loss: [1m[32m0.52111[0m[0m | time: 25.161s
[2K
| RMSProp | epoch: 014 | loss: 0.52111 - acc: 0.7476 -- iter: 0896/1133
[A[ATraining Step: 497  | total loss: [1m[32m0.51524[0m[0m | time: 26.053s
[2K
| RMSProp | epoch: 014 | loss: 0.51524 - acc: 0.7572 -- iter: 0928/1133
[A[ATraining Step: 498  | total loss: [1m[32m0.50828[0m[0m | time: 26.964s
[2K
| RMSProp | epoch: 014 | loss: 0.50828 - acc: 0.7659 -- iter: 0960/1133
[A[ATraining Step: 499  | total loss: [1m[32m0.49635[0m[0m | time: 27.914s
[2K
| RMSProp | epoch: 014 | loss: 0.49635 - acc: 0.7768 -- iter: 0992/1133
[A[ATraining Step: 500  | total loss: [1m[32m0.49036[0m[0m | time: 28.794s
[2K
| RMSProp | epoch: 014 | loss: 0.49036 - acc: 0.7741 -- iter: 1024/1133
[A[ATraining Step: 501  | total loss: [1m[32m0.48556[0m[0m | time: 29.661s
[2K
| RMSProp | epoch: 014 | loss: 0.48556 - acc: 0.7811 -- iter: 1056/1133
[A[ATraining Step: 502  | total loss: [1m[32m0.48670[0m[0m | time: 30.773s
[2K
| RMSProp | epoch: 014 | loss: 0.48670 - acc: 0.7842 -- iter: 1088/1133
[A[ATraining Step: 503  | total loss: [1m[32m0.49093[0m[0m | time: 31.861s
[2K
| RMSProp | epoch: 014 | loss: 0.49093 - acc: 0.7839 -- iter: 1120/1133
[A[ATraining Step: 504  | total loss: [1m[32m0.48139[0m[0m | time: 34.358s
[2K
| RMSProp | epoch: 014 | loss: 0.48139 - acc: 0.7868 | val_loss: 0.53352 - val_acc: 0.7324 -- iter: 1133/1133
--
Training Step: 505  | total loss: [1m[32m0.47673[0m[0m | time: 0.896s
[2K
| RMSProp | epoch: 015 | loss: 0.47673 - acc: 0.7862 -- iter: 0032/1133
[A[ATraining Step: 506  | total loss: [1m[32m0.46823[0m[0m | time: 1.829s
[2K
| RMSProp | epoch: 015 | loss: 0.46823 - acc: 0.7920 -- iter: 0064/1133
[A[ATraining Step: 507  | total loss: [1m[32m0.46132[0m[0m | time: 2.725s
[2K
| RMSProp | epoch: 015 | loss: 0.46132 - acc: 0.7940 -- iter: 0096/1133
[A[ATraining Step: 508  | total loss: [1m[32m0.45212[0m[0m | time: 3.601s
[2K
| RMSProp | epoch: 015 | loss: 0.45212 - acc: 0.7990 -- iter: 0128/1133
[A[ATraining Step: 509  | total loss: [1m[32m0.45844[0m[0m | time: 4.525s
[2K
| RMSProp | epoch: 015 | loss: 0.45844 - acc: 0.7972 -- iter: 0160/1133
[A[ATraining Step: 510  | total loss: [1m[32m0.47263[0m[0m | time: 5.684s
[2K
| RMSProp | epoch: 015 | loss: 0.47263 - acc: 0.7863 -- iter: 0192/1133
[A[ATraining Step: 511  | total loss: [1m[32m0.48077[0m[0m | time: 6.745s
[2K
| RMSProp | epoch: 015 | loss: 0.48077 - acc: 0.7795 -- iter: 0224/1133
[A[ATraining Step: 512  | total loss: [1m[32m0.46685[0m[0m | time: 7.526s
[2K
| RMSProp | epoch: 015 | loss: 0.46685 - acc: 0.7953 -- iter: 0256/1133
[A[ATraining Step: 513  | total loss: [1m[32m0.48035[0m[0m | time: 8.427s
[2K
| RMSProp | epoch: 015 | loss: 0.48035 - acc: 0.7908 -- iter: 0288/1133
[A[ATraining Step: 514  | total loss: [1m[32m0.49070[0m[0m | time: 9.370s
[2K
| RMSProp | epoch: 015 | loss: 0.49070 - acc: 0.7804 -- iter: 0320/1133
[A[ATraining Step: 515  | total loss: [1m[32m0.48600[0m[0m | time: 10.266s
[2K
| RMSProp | epoch: 015 | loss: 0.48600 - acc: 0.7805 -- iter: 0352/1133
[A[ATraining Step: 516  | total loss: [1m[32m0.46995[0m[0m | time: 11.167s
[2K
| RMSProp | epoch: 015 | loss: 0.46995 - acc: 0.7900 -- iter: 0384/1133
[A[ATraining Step: 517  | total loss: [1m[32m0.46613[0m[0m | time: 11.565s
[2K
| RMSProp | epoch: 015 | loss: 0.46613 - acc: 0.7922 -- iter: 0416/1133
[A[ATraining Step: 518  | total loss: [1m[32m0.46828[0m[0m | time: 11.948s
[2K
| RMSProp | epoch: 015 | loss: 0.46828 - acc: 0.7899 -- iter: 0448/1133
[A[ATraining Step: 519  | total loss: [1m[32m0.45820[0m[0m | time: 12.876s
[2K
| RMSProp | epoch: 015 | loss: 0.45820 - acc: 0.7955 -- iter: 0480/1133
[A[ATraining Step: 520  | total loss: [1m[32m0.44365[0m[0m | time: 13.800s
[2K
| RMSProp | epoch: 015 | loss: 0.44365 - acc: 0.8035 -- iter: 0512/1133
[A[ATraining Step: 521  | total loss: [1m[32m0.44208[0m[0m | time: 14.711s
[2K
| RMSProp | epoch: 015 | loss: 0.44208 - acc: 0.8044 -- iter: 0544/1133
[A[ATraining Step: 522  | total loss: [1m[32m0.43243[0m[0m | time: 15.544s
[2K
| RMSProp | epoch: 015 | loss: 0.43243 - acc: 0.8083 -- iter: 0576/1133
[A[ATraining Step: 523  | total loss: [1m[32m0.43650[0m[0m | time: 16.729s
[2K
| RMSProp | epoch: 015 | loss: 0.43650 - acc: 0.8056 -- iter: 0608/1133
[A[ATraining Step: 524  | total loss: [1m[32m0.42131[0m[0m | time: 17.911s
[2K
| RMSProp | epoch: 015 | loss: 0.42131 - acc: 0.8188 -- iter: 0640/1133
[A[ATraining Step: 525  | total loss: [1m[32m0.42077[0m[0m | time: 18.885s
[2K
| RMSProp | epoch: 015 | loss: 0.42077 - acc: 0.8151 -- iter: 0672/1133
[A[ATraining Step: 526  | total loss: [1m[32m0.41711[0m[0m | time: 19.662s
[2K
| RMSProp | epoch: 015 | loss: 0.41711 - acc: 0.8148 -- iter: 0704/1133
[A[ATraining Step: 527  | total loss: [1m[32m0.41362[0m[0m | time: 20.557s
[2K
| RMSProp | epoch: 015 | loss: 0.41362 - acc: 0.8146 -- iter: 0736/1133
[A[ATraining Step: 528  | total loss: [1m[32m0.43832[0m[0m | time: 21.450s
[2K
| RMSProp | epoch: 015 | loss: 0.43832 - acc: 0.8050 -- iter: 0768/1133
[A[ATraining Step: 529  | total loss: [1m[32m0.43053[0m[0m | time: 22.352s
[2K
| RMSProp | epoch: 015 | loss: 0.43053 - acc: 0.8089 -- iter: 0800/1133
[A[ATraining Step: 530  | total loss: [1m[32m0.42747[0m[0m | time: 23.217s
[2K
| RMSProp | epoch: 015 | loss: 0.42747 - acc: 0.8061 -- iter: 0832/1133
[A[ATraining Step: 531  | total loss: [1m[32m0.42137[0m[0m | time: 24.187s
[2K
| RMSProp | epoch: 015 | loss: 0.42137 - acc: 0.8067 -- iter: 0864/1133
[A[ATraining Step: 532  | total loss: [1m[32m0.42528[0m[0m | time: 25.084s
[2K
| RMSProp | epoch: 015 | loss: 0.42528 - acc: 0.8042 -- iter: 0896/1133
[A[ATraining Step: 533  | total loss: [1m[32m0.46645[0m[0m | time: 26.004s
[2K
| RMSProp | epoch: 015 | loss: 0.46645 - acc: 0.7769 -- iter: 0928/1133
[A[ATraining Step: 534  | total loss: [1m[32m0.45226[0m[0m | time: 26.886s
[2K
| RMSProp | epoch: 015 | loss: 0.45226 - acc: 0.7867 -- iter: 0960/1133
[A[ATraining Step: 535  | total loss: [1m[32m0.44329[0m[0m | time: 27.701s
[2K
| RMSProp | epoch: 015 | loss: 0.44329 - acc: 0.7955 -- iter: 0992/1133
[A[ATraining Step: 536  | total loss: [1m[32m0.44478[0m[0m | time: 28.814s
[2K
| RMSProp | epoch: 015 | loss: 0.44478 - acc: 0.7972 -- iter: 1024/1133
[A[ATraining Step: 537  | total loss: [1m[32m0.42583[0m[0m | time: 29.978s
[2K
| RMSProp | epoch: 015 | loss: 0.42583 - acc: 0.8144 -- iter: 1056/1133
[A[ATraining Step: 538  | total loss: [1m[32m0.42827[0m[0m | time: 30.941s
[2K
| RMSProp | epoch: 015 | loss: 0.42827 - acc: 0.8111 -- iter: 1088/1133
[A[ATraining Step: 539  | total loss: [1m[32m0.42979[0m[0m | time: 31.718s
[2K
| RMSProp | epoch: 015 | loss: 0.42979 - acc: 0.8143 -- iter: 1120/1133
[A[ATraining Step: 540  | total loss: [1m[32m0.42818[0m[0m | time: 34.238s
[2K
| RMSProp | epoch: 015 | loss: 0.42818 - acc: 0.8079 | val_loss: 0.49630 - val_acc: 0.7690 -- iter: 1133/1133
--
Training Step: 541  | total loss: [1m[32m0.45279[0m[0m | time: 0.896s
[2K
| RMSProp | epoch: 016 | loss: 0.45279 - acc: 0.7865 -- iter: 0032/1133
[A[ATraining Step: 542  | total loss: [1m[32m0.44307[0m[0m | time: 1.778s
[2K
| RMSProp | epoch: 016 | loss: 0.44307 - acc: 0.7922 -- iter: 0064/1133
[A[ATraining Step: 543  | total loss: [1m[32m0.42862[0m[0m | time: 2.636s
[2K
| RMSProp | epoch: 016 | loss: 0.42862 - acc: 0.8005 -- iter: 0096/1133
[A[ATraining Step: 544  | total loss: [1m[32m0.41965[0m[0m | time: 3.717s
[2K
| RMSProp | epoch: 016 | loss: 0.41965 - acc: 0.8079 -- iter: 0128/1133
[A[ATraining Step: 545  | total loss: [1m[32m0.41622[0m[0m | time: 4.804s
[2K
| RMSProp | epoch: 016 | loss: 0.41622 - acc: 0.8084 -- iter: 0160/1133
[A[ATraining Step: 546  | total loss: [1m[32m0.40229[0m[0m | time: 5.842s
[2K
| RMSProp | epoch: 016 | loss: 0.40229 - acc: 0.8151 -- iter: 0192/1133
[A[ATraining Step: 547  | total loss: [1m[32m0.39300[0m[0m | time: 6.550s
[2K
| RMSProp | epoch: 016 | loss: 0.39300 - acc: 0.8211 -- iter: 0224/1133
[A[ATraining Step: 548  | total loss: [1m[32m0.36718[0m[0m | time: 7.382s
[2K
| RMSProp | epoch: 016 | loss: 0.36718 - acc: 0.8389 -- iter: 0256/1133
[A[ATraining Step: 549  | total loss: [1m[32m0.35604[0m[0m | time: 8.265s
[2K
| RMSProp | epoch: 016 | loss: 0.35604 - acc: 0.8488 -- iter: 0288/1133
[A[ATraining Step: 550  | total loss: [1m[32m0.42340[0m[0m | time: 9.143s
[2K
| RMSProp | epoch: 016 | loss: 0.42340 - acc: 0.8170 -- iter: 0320/1133
[A[ATraining Step: 551  | total loss: [1m[32m0.40065[0m[0m | time: 10.007s
[2K
| RMSProp | epoch: 016 | loss: 0.40065 - acc: 0.8291 -- iter: 0352/1133
[A[ATraining Step: 552  | total loss: [1m[32m0.37940[0m[0m | time: 10.905s
[2K
| RMSProp | epoch: 016 | loss: 0.37940 - acc: 0.8431 -- iter: 0384/1133
[A[ATraining Step: 553  | total loss: [1m[32m0.38947[0m[0m | time: 11.858s
[2K
| RMSProp | epoch: 016 | loss: 0.38947 - acc: 0.8369 -- iter: 0416/1133
[A[ATraining Step: 554  | total loss: [1m[32m0.40879[0m[0m | time: 12.276s
[2K
| RMSProp | epoch: 016 | loss: 0.40879 - acc: 0.8219 -- iter: 0448/1133
[A[ATraining Step: 555  | total loss: [1m[32m0.45528[0m[0m | time: 12.703s
[2K
| RMSProp | epoch: 016 | loss: 0.45528 - acc: 0.8013 -- iter: 0480/1133
[A[ATraining Step: 556  | total loss: [1m[32m0.43809[0m[0m | time: 13.574s
[2K
| RMSProp | epoch: 016 | loss: 0.43809 - acc: 0.8135 -- iter: 0512/1133
[A[ATraining Step: 557  | total loss: [1m[32m0.42968[0m[0m | time: 14.431s
[2K
| RMSProp | epoch: 016 | loss: 0.42968 - acc: 0.8134 -- iter: 0544/1133
[A[ATraining Step: 558  | total loss: [1m[32m0.42458[0m[0m | time: 15.459s
[2K
| RMSProp | epoch: 016 | loss: 0.42458 - acc: 0.8195 -- iter: 0576/1133
[A[ATraining Step: 559  | total loss: [1m[32m0.40982[0m[0m | time: 16.598s
[2K
| RMSProp | epoch: 016 | loss: 0.40982 - acc: 0.8220 -- iter: 0608/1133
[A[ATraining Step: 560  | total loss: [1m[32m0.39114[0m[0m | time: 17.728s
[2K
| RMSProp | epoch: 016 | loss: 0.39114 - acc: 0.8335 -- iter: 0640/1133
[A[ATraining Step: 561  | total loss: [1m[32m0.38819[0m[0m | time: 18.441s
[2K
| RMSProp | epoch: 016 | loss: 0.38819 - acc: 0.8314 -- iter: 0672/1133
[A[ATraining Step: 562  | total loss: [1m[32m0.38168[0m[0m | time: 19.405s
[2K
| RMSProp | epoch: 016 | loss: 0.38168 - acc: 0.8326 -- iter: 0704/1133
[A[ATraining Step: 563  | total loss: [1m[32m0.36292[0m[0m | time: 20.327s
[2K
| RMSProp | epoch: 016 | loss: 0.36292 - acc: 0.8431 -- iter: 0736/1133
[A[ATraining Step: 564  | total loss: [1m[32m0.35271[0m[0m | time: 21.222s
[2K
| RMSProp | epoch: 016 | loss: 0.35271 - acc: 0.8463 -- iter: 0768/1133
[A[ATraining Step: 565  | total loss: [1m[32m0.35770[0m[0m | time: 22.131s
[2K
| RMSProp | epoch: 016 | loss: 0.35770 - acc: 0.8429 -- iter: 0800/1133
[A[ATraining Step: 566  | total loss: [1m[32m0.36045[0m[0m | time: 23.045s
[2K
| RMSProp | epoch: 016 | loss: 0.36045 - acc: 0.8399 -- iter: 0832/1133
[A[ATraining Step: 567  | total loss: [1m[32m0.35106[0m[0m | time: 23.948s
[2K
| RMSProp | epoch: 016 | loss: 0.35106 - acc: 0.8465 -- iter: 0864/1133
[A[ATraining Step: 568  | total loss: [1m[32m0.34127[0m[0m | time: 24.848s
[2K
| RMSProp | epoch: 016 | loss: 0.34127 - acc: 0.8525 -- iter: 0896/1133
[A[ATraining Step: 569  | total loss: [1m[32m0.34623[0m[0m | time: 25.728s
[2K
| RMSProp | epoch: 016 | loss: 0.34623 - acc: 0.8485 -- iter: 0928/1133
[A[ATraining Step: 570  | total loss: [1m[32m0.33058[0m[0m | time: 26.635s
[2K
| RMSProp | epoch: 016 | loss: 0.33058 - acc: 0.8636 -- iter: 0960/1133
[A[ATraining Step: 571  | total loss: [1m[32m0.33072[0m[0m | time: 27.707s
[2K
| RMSProp | epoch: 016 | loss: 0.33072 - acc: 0.8617 -- iter: 0992/1133
[A[ATraining Step: 572  | total loss: [1m[32m0.33983[0m[0m | time: 28.842s
[2K
| RMSProp | epoch: 016 | loss: 0.33983 - acc: 0.8536 -- iter: 1024/1133
[A[ATraining Step: 573  | total loss: [1m[32m0.32480[0m[0m | time: 29.620s
[2K
| RMSProp | epoch: 016 | loss: 0.32480 - acc: 0.8651 -- iter: 1056/1133
[A[ATraining Step: 574  | total loss: [1m[32m0.32424[0m[0m | time: 30.544s
[2K
| RMSProp | epoch: 016 | loss: 0.32424 - acc: 0.8599 -- iter: 1088/1133
[A[ATraining Step: 575  | total loss: [1m[32m0.32364[0m[0m | time: 31.490s
[2K
| RMSProp | epoch: 016 | loss: 0.32364 - acc: 0.8614 -- iter: 1120/1133
[A[ATraining Step: 576  | total loss: [1m[32m0.32997[0m[0m | time: 34.205s
[2K
| RMSProp | epoch: 016 | loss: 0.32997 - acc: 0.8627 | val_loss: 0.58295 - val_acc: 0.7493 -- iter: 1133/1133
--
Training Step: 577  | total loss: [1m[32m0.33232[0m[0m | time: 0.900s
[2K
| RMSProp | epoch: 017 | loss: 0.33232 - acc: 0.8671 -- iter: 0032/1133
[A[ATraining Step: 578  | total loss: [1m[32m0.34587[0m[0m | time: 1.802s
[2K
| RMSProp | epoch: 017 | loss: 0.34587 - acc: 0.8679 -- iter: 0064/1133
[A[ATraining Step: 579  | total loss: [1m[32m0.33687[0m[0m | time: 2.677s
[2K
| RMSProp | epoch: 017 | loss: 0.33687 - acc: 0.8686 -- iter: 0096/1133
[A[ATraining Step: 580  | total loss: [1m[32m0.33348[0m[0m | time: 3.847s
[2K
| RMSProp | epoch: 017 | loss: 0.33348 - acc: 0.8661 -- iter: 0128/1133
[A[ATraining Step: 581  | total loss: [1m[32m0.32123[0m[0m | time: 5.003s
[2K
| RMSProp | epoch: 017 | loss: 0.32123 - acc: 0.8701 -- iter: 0160/1133
[A[ATraining Step: 582  | total loss: [1m[32m0.32541[0m[0m | time: 5.775s
[2K
| RMSProp | epoch: 017 | loss: 0.32541 - acc: 0.8644 -- iter: 0192/1133
[A[ATraining Step: 583  | total loss: [1m[32m0.34168[0m[0m | time: 6.651s
[2K
| RMSProp | epoch: 017 | loss: 0.34168 - acc: 0.8592 -- iter: 0224/1133
[A[ATraining Step: 584  | total loss: [1m[32m0.33280[0m[0m | time: 7.662s
[2K
| RMSProp | epoch: 017 | loss: 0.33280 - acc: 0.8670 -- iter: 0256/1133
[A[ATraining Step: 585  | total loss: [1m[32m0.33703[0m[0m | time: 8.559s
[2K
| RMSProp | epoch: 017 | loss: 0.33703 - acc: 0.8647 -- iter: 0288/1133
[A[ATraining Step: 586  | total loss: [1m[32m0.32566[0m[0m | time: 9.475s
[2K
| RMSProp | epoch: 017 | loss: 0.32566 - acc: 0.8751 -- iter: 0320/1133
[A[ATraining Step: 587  | total loss: [1m[32m0.30950[0m[0m | time: 10.401s
[2K
| RMSProp | epoch: 017 | loss: 0.30950 - acc: 0.8845 -- iter: 0352/1133
[A[ATraining Step: 588  | total loss: [1m[32m0.30992[0m[0m | time: 11.362s
[2K
| RMSProp | epoch: 017 | loss: 0.30992 - acc: 0.8804 -- iter: 0384/1133
[A[ATraining Step: 589  | total loss: [1m[32m0.33131[0m[0m | time: 12.307s
[2K
| RMSProp | epoch: 017 | loss: 0.33131 - acc: 0.8705 -- iter: 0416/1133
[A[ATraining Step: 590  | total loss: [1m[32m0.33084[0m[0m | time: 13.248s
[2K
| RMSProp | epoch: 017 | loss: 0.33084 - acc: 0.8709 -- iter: 0448/1133
[A[ATraining Step: 591  | total loss: [1m[32m0.32970[0m[0m | time: 13.619s
[2K
| RMSProp | epoch: 017 | loss: 0.32970 - acc: 0.8713 -- iter: 0480/1133
[A[ATraining Step: 592  | total loss: [1m[32m0.31966[0m[0m | time: 14.051s
[2K
| RMSProp | epoch: 017 | loss: 0.31966 - acc: 0.8765 -- iter: 0512/1133
[A[ATraining Step: 593  | total loss: [1m[32m0.29518[0m[0m | time: 15.215s
[2K
| RMSProp | epoch: 017 | loss: 0.29518 - acc: 0.8889 -- iter: 0544/1133
[A[ATraining Step: 594  | total loss: [1m[32m0.28895[0m[0m | time: 16.345s
[2K
| RMSProp | epoch: 017 | loss: 0.28895 - acc: 0.8906 -- iter: 0576/1133
[A[ATraining Step: 595  | total loss: [1m[32m0.27845[0m[0m | time: 17.263s
[2K
| RMSProp | epoch: 017 | loss: 0.27845 - acc: 0.8984 -- iter: 0608/1133
[A[ATraining Step: 596  | total loss: [1m[32m0.26036[0m[0m | time: 18.072s
[2K
| RMSProp | epoch: 017 | loss: 0.26036 - acc: 0.9054 -- iter: 0640/1133
[A[ATraining Step: 597  | total loss: [1m[32m0.25213[0m[0m | time: 18.999s
[2K
| RMSProp | epoch: 017 | loss: 0.25213 - acc: 0.9087 -- iter: 0672/1133
[A[ATraining Step: 598  | total loss: [1m[32m0.26110[0m[0m | time: 19.935s
[2K
| RMSProp | epoch: 017 | loss: 0.26110 - acc: 0.9022 -- iter: 0704/1133
[A[ATraining Step: 599  | total loss: [1m[32m0.29426[0m[0m | time: 20.828s
[2K
| RMSProp | epoch: 017 | loss: 0.29426 - acc: 0.8963 -- iter: 0736/1133
[A[ATraining Step: 600  | total loss: [1m[32m0.30084[0m[0m | time: 23.604s
[2K
| RMSProp | epoch: 017 | loss: 0.30084 - acc: 0.8942 | val_loss: 0.67436 - val_acc: 0.7239 -- iter: 0768/1133
--
Training Step: 601  | total loss: [1m[32m0.30097[0m[0m | time: 24.479s
[2K
| RMSProp | epoch: 017 | loss: 0.30097 - acc: 0.8954 -- iter: 0800/1133
[A[ATraining Step: 602  | total loss: [1m[32m0.30832[0m[0m | time: 25.463s
[2K
| RMSProp | epoch: 017 | loss: 0.30832 - acc: 0.8902 -- iter: 0832/1133
[A[ATraining Step: 603  | total loss: [1m[32m0.30588[0m[0m | time: 26.537s
[2K
| RMSProp | epoch: 017 | loss: 0.30588 - acc: 0.8887 -- iter: 0864/1133
[A[ATraining Step: 604  | total loss: [1m[32m0.29292[0m[0m | time: 27.577s
[2K
| RMSProp | epoch: 017 | loss: 0.29292 - acc: 0.8936 -- iter: 0896/1133
[A[ATraining Step: 605  | total loss: [1m[32m0.27771[0m[0m | time: 28.362s
[2K
| RMSProp | epoch: 017 | loss: 0.27771 - acc: 0.9011 -- iter: 0928/1133
[A[ATraining Step: 606  | total loss: [1m[32m0.27120[0m[0m | time: 29.194s
[2K
| RMSProp | epoch: 017 | loss: 0.27120 - acc: 0.9047 -- iter: 0960/1133
[A[ATraining Step: 607  | total loss: [1m[32m0.26297[0m[0m | time: 30.077s
[2K
| RMSProp | epoch: 017 | loss: 0.26297 - acc: 0.9049 -- iter: 0992/1133
[A[ATraining Step: 608  | total loss: [1m[32m0.30517[0m[0m | time: 30.947s
[2K
| RMSProp | epoch: 017 | loss: 0.30517 - acc: 0.8832 -- iter: 1024/1133
[A[ATraining Step: 609  | total loss: [1m[32m0.30215[0m[0m | time: 31.811s
[2K
| RMSProp | epoch: 017 | loss: 0.30215 - acc: 0.8855 -- iter: 1056/1133
[A[ATraining Step: 610  | total loss: [1m[32m0.29349[0m[0m | time: 32.728s
[2K
| RMSProp | epoch: 017 | loss: 0.29349 - acc: 0.8844 -- iter: 1088/1133
[A[ATraining Step: 611  | total loss: [1m[32m0.27715[0m[0m | time: 33.729s
[2K
| RMSProp | epoch: 017 | loss: 0.27715 - acc: 0.8929 -- iter: 1120/1133
[A[ATraining Step: 612  | total loss: [1m[32m0.26539[0m[0m | time: 36.445s
[2K
| RMSProp | epoch: 017 | loss: 0.26539 - acc: 0.9004 | val_loss: 0.44319 - val_acc: 0.8056 -- iter: 1133/1133
--
Training Step: 613  | total loss: [1m[32m0.25426[0m[0m | time: 0.902s
[2K
| RMSProp | epoch: 018 | loss: 0.25426 - acc: 0.9041 -- iter: 0032/1133
[A[ATraining Step: 614  | total loss: [1m[32m0.24298[0m[0m | time: 1.825s
[2K
| RMSProp | epoch: 018 | loss: 0.24298 - acc: 0.9106 -- iter: 0064/1133
[A[ATraining Step: 615  | total loss: [1m[32m0.24687[0m[0m | time: 2.761s
[2K
| RMSProp | epoch: 018 | loss: 0.24687 - acc: 0.9039 -- iter: 0096/1133
[A[ATraining Step: 616  | total loss: [1m[32m0.28394[0m[0m | time: 3.710s
[2K
| RMSProp | epoch: 018 | loss: 0.28394 - acc: 0.8792 -- iter: 0128/1133
[A[ATraining Step: 617  | total loss: [1m[32m0.30138[0m[0m | time: 4.657s
[2K
| RMSProp | epoch: 018 | loss: 0.30138 - acc: 0.8694 -- iter: 0160/1133
[A[ATraining Step: 618  | total loss: [1m[32m0.30439[0m[0m | time: 5.543s
[2K
| RMSProp | epoch: 018 | loss: 0.30439 - acc: 0.8668 -- iter: 0192/1133
[A[ATraining Step: 619  | total loss: [1m[32m0.29890[0m[0m | time: 6.477s
[2K
| RMSProp | epoch: 018 | loss: 0.29890 - acc: 0.8707 -- iter: 0224/1133
[A[ATraining Step: 620  | total loss: [1m[32m0.28764[0m[0m | time: 7.365s
[2K
| RMSProp | epoch: 018 | loss: 0.28764 - acc: 0.8774 -- iter: 0256/1133
[A[ATraining Step: 621  | total loss: [1m[32m0.32192[0m[0m | time: 8.429s
[2K
| RMSProp | epoch: 018 | loss: 0.32192 - acc: 0.8616 -- iter: 0288/1133
[A[ATraining Step: 622  | total loss: [1m[32m0.32379[0m[0m | time: 9.540s
[2K
| RMSProp | epoch: 018 | loss: 0.32379 - acc: 0.8566 -- iter: 0320/1133
[A[ATraining Step: 623  | total loss: [1m[32m0.31431[0m[0m | time: 10.579s
[2K
| RMSProp | epoch: 018 | loss: 0.31431 - acc: 0.8616 -- iter: 0352/1133
[A[ATraining Step: 624  | total loss: [1m[32m0.30873[0m[0m | time: 11.341s
[2K
| RMSProp | epoch: 018 | loss: 0.30873 - acc: 0.8661 -- iter: 0384/1133
[A[ATraining Step: 625  | total loss: [1m[32m0.32127[0m[0m | time: 12.214s
[2K
| RMSProp | epoch: 018 | loss: 0.32127 - acc: 0.8638 -- iter: 0416/1133
[A[ATraining Step: 626  | total loss: [1m[32m0.33277[0m[0m | time: 13.153s
[2K
| RMSProp | epoch: 018 | loss: 0.33277 - acc: 0.8587 -- iter: 0448/1133
[A[ATraining Step: 627  | total loss: [1m[32m0.31587[0m[0m | time: 14.066s
[2K
| RMSProp | epoch: 018 | loss: 0.31587 - acc: 0.8697 -- iter: 0480/1133
[A[ATraining Step: 628  | total loss: [1m[32m0.30653[0m[0m | time: 14.473s
[2K
| RMSProp | epoch: 018 | loss: 0.30653 - acc: 0.8734 -- iter: 0512/1133
[A[ATraining Step: 629  | total loss: [1m[32m0.30942[0m[0m | time: 14.879s
[2K
| RMSProp | epoch: 018 | loss: 0.30942 - acc: 0.8783 -- iter: 0544/1133
[A[ATraining Step: 630  | total loss: [1m[32m0.31503[0m[0m | time: 15.817s
[2K
| RMSProp | epoch: 018 | loss: 0.31503 - acc: 0.8751 -- iter: 0576/1133
[A[ATraining Step: 631  | total loss: [1m[32m0.30419[0m[0m | time: 16.723s
[2K
| RMSProp | epoch: 018 | loss: 0.30419 - acc: 0.8751 -- iter: 0608/1133
[A[ATraining Step: 632  | total loss: [1m[32m0.30076[0m[0m | time: 17.631s
[2K
| RMSProp | epoch: 018 | loss: 0.30076 - acc: 0.8720 -- iter: 0640/1133
[A[ATraining Step: 633  | total loss: [1m[32m0.29392[0m[0m | time: 18.542s
[2K
| RMSProp | epoch: 018 | loss: 0.29392 - acc: 0.8754 -- iter: 0672/1133
[A[ATraining Step: 634  | total loss: [1m[32m0.30444[0m[0m | time: 19.475s
[2K
| RMSProp | epoch: 018 | loss: 0.30444 - acc: 0.8785 -- iter: 0704/1133
[A[ATraining Step: 635  | total loss: [1m[32m0.29766[0m[0m | time: 20.563s
[2K
| RMSProp | epoch: 018 | loss: 0.29766 - acc: 0.8813 -- iter: 0736/1133
[A[ATraining Step: 636  | total loss: [1m[32m0.30312[0m[0m | time: 21.666s
[2K
| RMSProp | epoch: 018 | loss: 0.30312 - acc: 0.8744 -- iter: 0768/1133
[A[ATraining Step: 637  | total loss: [1m[32m0.31003[0m[0m | time: 22.409s
[2K
| RMSProp | epoch: 018 | loss: 0.31003 - acc: 0.8744 -- iter: 0800/1133
[A[ATraining Step: 638  | total loss: [1m[32m0.30602[0m[0m | time: 23.264s
[2K
| RMSProp | epoch: 018 | loss: 0.30602 - acc: 0.8808 -- iter: 0832/1133
[A[ATraining Step: 639  | total loss: [1m[32m0.29182[0m[0m | time: 24.170s
[2K
| RMSProp | epoch: 018 | loss: 0.29182 - acc: 0.8864 -- iter: 0864/1133
[A[ATraining Step: 640  | total loss: [1m[32m0.27727[0m[0m | time: 25.113s
[2K
| RMSProp | epoch: 018 | loss: 0.27727 - acc: 0.8947 -- iter: 0896/1133
[A[ATraining Step: 641  | total loss: [1m[32m0.26524[0m[0m | time: 26.067s
[2K
| RMSProp | epoch: 018 | loss: 0.26524 - acc: 0.8989 -- iter: 0928/1133
[A[ATraining Step: 642  | total loss: [1m[32m0.25319[0m[0m | time: 26.979s
[2K
| RMSProp | epoch: 018 | loss: 0.25319 - acc: 0.9059 -- iter: 0960/1133
[A[ATraining Step: 643  | total loss: [1m[32m0.26223[0m[0m | time: 27.875s
[2K
| RMSProp | epoch: 018 | loss: 0.26223 - acc: 0.8997 -- iter: 0992/1133
[A[ATraining Step: 644  | total loss: [1m[32m0.28077[0m[0m | time: 28.758s
[2K
| RMSProp | epoch: 018 | loss: 0.28077 - acc: 0.8910 -- iter: 1024/1133
[A[ATraining Step: 645  | total loss: [1m[32m0.26227[0m[0m | time: 29.672s
[2K
| RMSProp | epoch: 018 | loss: 0.26227 - acc: 0.9019 -- iter: 1056/1133
[A[ATraining Step: 646  | total loss: [1m[32m0.24575[0m[0m | time: 30.503s
[2K
| RMSProp | epoch: 018 | loss: 0.24575 - acc: 0.9086 -- iter: 1088/1133
[A[ATraining Step: 647  | total loss: [1m[32m0.24803[0m[0m | time: 31.653s
[2K
| RMSProp | epoch: 018 | loss: 0.24803 - acc: 0.9083 -- iter: 1120/1133
[A[ATraining Step: 648  | total loss: [1m[32m0.24144[0m[0m | time: 34.599s
[2K
| RMSProp | epoch: 018 | loss: 0.24144 - acc: 0.9144 | val_loss: 0.58488 - val_acc: 0.7493 -- iter: 1133/1133
--
Training Step: 649  | total loss: [1m[32m0.25751[0m[0m | time: 0.923s
[2K
| RMSProp | epoch: 019 | loss: 0.25751 - acc: 0.9073 -- iter: 0032/1133
[A[ATraining Step: 650  | total loss: [1m[32m0.26860[0m[0m | time: 1.822s
[2K
| RMSProp | epoch: 019 | loss: 0.26860 - acc: 0.9010 -- iter: 0064/1133
[A[ATraining Step: 651  | total loss: [1m[32m0.26381[0m[0m | time: 2.736s
[2K
| RMSProp | epoch: 019 | loss: 0.26381 - acc: 0.9015 -- iter: 0096/1133
[A[ATraining Step: 652  | total loss: [1m[32m0.26228[0m[0m | time: 3.634s
[2K
| RMSProp | epoch: 019 | loss: 0.26228 - acc: 0.9051 -- iter: 0128/1133
[A[ATraining Step: 653  | total loss: [1m[32m0.24832[0m[0m | time: 4.533s
[2K
| RMSProp | epoch: 019 | loss: 0.24832 - acc: 0.9115 -- iter: 0160/1133
[A[ATraining Step: 654  | total loss: [1m[32m0.23083[0m[0m | time: 5.441s
[2K
| RMSProp | epoch: 019 | loss: 0.23083 - acc: 0.9203 -- iter: 0192/1133
[A[ATraining Step: 655  | total loss: [1m[32m0.21988[0m[0m | time: 6.351s
[2K
| RMSProp | epoch: 019 | loss: 0.21988 - acc: 0.9252 -- iter: 0224/1133
[A[ATraining Step: 656  | total loss: [1m[32m0.23241[0m[0m | time: 7.191s
[2K
| RMSProp | epoch: 019 | loss: 0.23241 - acc: 0.9201 -- iter: 0256/1133
[A[ATraining Step: 657  | total loss: [1m[32m0.24920[0m[0m | time: 8.392s
[2K
| RMSProp | epoch: 019 | loss: 0.24920 - acc: 0.9063 -- iter: 0288/1133
[A[ATraining Step: 658  | total loss: [1m[32m0.24269[0m[0m | time: 9.622s
[2K
| RMSProp | epoch: 019 | loss: 0.24269 - acc: 0.9094 -- iter: 0320/1133
[A[ATraining Step: 659  | total loss: [1m[32m0.23001[0m[0m | time: 10.599s
[2K
| RMSProp | epoch: 019 | loss: 0.23001 - acc: 0.9184 -- iter: 0352/1133
[A[ATraining Step: 660  | total loss: [1m[32m0.23995[0m[0m | time: 11.372s
[2K
| RMSProp | epoch: 019 | loss: 0.23995 - acc: 0.9110 -- iter: 0384/1133
[A[ATraining Step: 661  | total loss: [1m[32m0.25524[0m[0m | time: 12.249s
[2K
| RMSProp | epoch: 019 | loss: 0.25524 - acc: 0.9042 -- iter: 0416/1133
[A[ATraining Step: 662  | total loss: [1m[32m0.25171[0m[0m | time: 13.198s
[2K
| RMSProp | epoch: 019 | loss: 0.25171 - acc: 0.9044 -- iter: 0448/1133
[A[ATraining Step: 663  | total loss: [1m[32m0.24485[0m[0m | time: 14.094s
[2K
| RMSProp | epoch: 019 | loss: 0.24485 - acc: 0.9078 -- iter: 0480/1133
[A[ATraining Step: 664  | total loss: [1m[32m0.24499[0m[0m | time: 15.057s
[2K
| RMSProp | epoch: 019 | loss: 0.24499 - acc: 0.9076 -- iter: 0512/1133
[A[ATraining Step: 665  | total loss: [1m[32m0.25379[0m[0m | time: 15.512s
[2K
| RMSProp | epoch: 019 | loss: 0.25379 - acc: 0.9043 -- iter: 0544/1133
[A[ATraining Step: 666  | total loss: [1m[32m0.26954[0m[0m | time: 15.936s
[2K
| RMSProp | epoch: 019 | loss: 0.26954 - acc: 0.8985 -- iter: 0576/1133
[A[ATraining Step: 667  | total loss: [1m[32m0.25078[0m[0m | time: 16.855s
[2K
| RMSProp | epoch: 019 | loss: 0.25078 - acc: 0.9087 -- iter: 0608/1133
[A[ATraining Step: 668  | total loss: [1m[32m0.25899[0m[0m | time: 17.772s
[2K
| RMSProp | epoch: 019 | loss: 0.25899 - acc: 0.9022 -- iter: 0640/1133
[A[ATraining Step: 669  | total loss: [1m[32m0.24214[0m[0m | time: 18.631s
[2K
| RMSProp | epoch: 019 | loss: 0.24214 - acc: 0.9120 -- iter: 0672/1133
[A[ATraining Step: 670  | total loss: [1m[32m0.23230[0m[0m | time: 19.549s
[2K
| RMSProp | epoch: 019 | loss: 0.23230 - acc: 0.9176 -- iter: 0704/1133
[A[ATraining Step: 671  | total loss: [1m[32m0.24158[0m[0m | time: 20.628s
[2K
| RMSProp | epoch: 019 | loss: 0.24158 - acc: 0.9165 -- iter: 0736/1133
[A[ATraining Step: 672  | total loss: [1m[32m0.23202[0m[0m | time: 21.759s
[2K
| RMSProp | epoch: 019 | loss: 0.23202 - acc: 0.9186 -- iter: 0768/1133
[A[ATraining Step: 673  | total loss: [1m[32m0.24082[0m[0m | time: 22.678s
[2K
| RMSProp | epoch: 019 | loss: 0.24082 - acc: 0.9080 -- iter: 0800/1133
[A[ATraining Step: 674  | total loss: [1m[32m0.23941[0m[0m | time: 23.454s
[2K
| RMSProp | epoch: 019 | loss: 0.23941 - acc: 0.9078 -- iter: 0832/1133
[A[ATraining Step: 675  | total loss: [1m[32m0.23132[0m[0m | time: 24.346s
[2K
| RMSProp | epoch: 019 | loss: 0.23132 - acc: 0.9108 -- iter: 0864/1133
[A[ATraining Step: 676  | total loss: [1m[32m0.22168[0m[0m | time: 25.268s
[2K
| RMSProp | epoch: 019 | loss: 0.22168 - acc: 0.9166 -- iter: 0896/1133
[A[ATraining Step: 677  | total loss: [1m[32m0.20771[0m[0m | time: 26.161s
[2K
| RMSProp | epoch: 019 | loss: 0.20771 - acc: 0.9218 -- iter: 0928/1133
[A[ATraining Step: 678  | total loss: [1m[32m0.19320[0m[0m | time: 27.038s
[2K
| RMSProp | epoch: 019 | loss: 0.19320 - acc: 0.9296 -- iter: 0960/1133
[A[ATraining Step: 679  | total loss: [1m[32m0.19196[0m[0m | time: 27.991s
[2K
| RMSProp | epoch: 019 | loss: 0.19196 - acc: 0.9304 -- iter: 0992/1133
[A[ATraining Step: 680  | total loss: [1m[32m0.19801[0m[0m | time: 28.902s
[2K
| RMSProp | epoch: 019 | loss: 0.19801 - acc: 0.9280 -- iter: 1024/1133
[A[ATraining Step: 681  | total loss: [1m[32m0.20432[0m[0m | time: 29.792s
[2K
| RMSProp | epoch: 019 | loss: 0.20432 - acc: 0.9196 -- iter: 1056/1133
[A[ATraining Step: 682  | total loss: [1m[32m0.22428[0m[0m | time: 30.682s
[2K
| RMSProp | epoch: 019 | loss: 0.22428 - acc: 0.9151 -- iter: 1088/1133
[A[ATraining Step: 683  | total loss: [1m[32m0.22909[0m[0m | time: 31.575s
[2K
| RMSProp | epoch: 019 | loss: 0.22909 - acc: 0.9080 -- iter: 1120/1133
[A[ATraining Step: 684  | total loss: [1m[32m0.21600[0m[0m | time: 34.796s
[2K
| RMSProp | epoch: 019 | loss: 0.21600 - acc: 0.9141 | val_loss: 0.54047 - val_acc: 0.8113 -- iter: 1133/1133
--
Training Step: 685  | total loss: [1m[32m0.21122[0m[0m | time: 0.909s
[2K
| RMSProp | epoch: 020 | loss: 0.21122 - acc: 0.9133 -- iter: 0032/1133
[A[ATraining Step: 686  | total loss: [1m[32m0.20184[0m[0m | time: 1.845s
[2K
| RMSProp | epoch: 020 | loss: 0.20184 - acc: 0.9188 -- iter: 0064/1133
[A[ATraining Step: 687  | total loss: [1m[32m0.21184[0m[0m | time: 2.793s
[2K
| RMSProp | epoch: 020 | loss: 0.21184 - acc: 0.9113 -- iter: 0096/1133
[A[ATraining Step: 688  | total loss: [1m[32m0.20142[0m[0m | time: 3.750s
[2K
| RMSProp | epoch: 020 | loss: 0.20142 - acc: 0.9171 -- iter: 0128/1133
[A[ATraining Step: 689  | total loss: [1m[32m0.19008[0m[0m | time: 4.602s
[2K
| RMSProp | epoch: 020 | loss: 0.19008 - acc: 0.9222 -- iter: 0160/1133
[A[ATraining Step: 690  | total loss: [1m[32m0.18231[0m[0m | time: 5.531s
[2K
| RMSProp | epoch: 020 | loss: 0.18231 - acc: 0.9238 -- iter: 0192/1133
[A[ATraining Step: 691  | total loss: [1m[32m0.16685[0m[0m | time: 6.653s
[2K
| RMSProp | epoch: 020 | loss: 0.16685 - acc: 0.9314 -- iter: 0224/1133
[A[ATraining Step: 692  | total loss: [1m[32m0.15878[0m[0m | time: 7.909s
[2K
| RMSProp | epoch: 020 | loss: 0.15878 - acc: 0.9351 -- iter: 0256/1133
[A[ATraining Step: 693  | total loss: [1m[32m0.16475[0m[0m | time: 8.766s
[2K
| RMSProp | epoch: 020 | loss: 0.16475 - acc: 0.9291 -- iter: 0288/1133
[A[ATraining Step: 694  | total loss: [1m[32m0.19673[0m[0m | time: 9.640s
[2K
| RMSProp | epoch: 020 | loss: 0.19673 - acc: 0.9206 -- iter: 0320/1133
[A[ATraining Step: 695  | total loss: [1m[32m0.20500[0m[0m | time: 10.520s
[2K
| RMSProp | epoch: 020 | loss: 0.20500 - acc: 0.9191 -- iter: 0352/1133
[A[ATraining Step: 696  | total loss: [1m[32m0.20402[0m[0m | time: 11.451s
[2K
| RMSProp | epoch: 020 | loss: 0.20402 - acc: 0.9178 -- iter: 0384/1133
[A[ATraining Step: 697  | total loss: [1m[32m0.20291[0m[0m | time: 12.371s
[2K
| RMSProp | epoch: 020 | loss: 0.20291 - acc: 0.9167 -- iter: 0416/1133
[A[ATraining Step: 698  | total loss: [1m[32m0.19739[0m[0m | time: 13.397s
[2K
| RMSProp | epoch: 020 | loss: 0.19739 - acc: 0.9188 -- iter: 0448/1133
[A[ATraining Step: 699  | total loss: [1m[32m0.19291[0m[0m | time: 14.298s
[2K
| RMSProp | epoch: 020 | loss: 0.19291 - acc: 0.9206 -- iter: 0480/1133
[A[ATraining Step: 700  | total loss: [1m[32m0.19177[0m[0m | time: 15.167s
[2K
| RMSProp | epoch: 020 | loss: 0.19177 - acc: 0.9192 -- iter: 0512/1133
[A[ATraining Step: 701  | total loss: [1m[32m0.18294[0m[0m | time: 16.125s
[2K
| RMSProp | epoch: 020 | loss: 0.18294 - acc: 0.9273 -- iter: 0544/1133
[A[ATraining Step: 702  | total loss: [1m[32m0.17261[0m[0m | time: 16.515s
[2K
| RMSProp | epoch: 020 | loss: 0.17261 - acc: 0.9314 -- iter: 0576/1133
[A[ATraining Step: 703  | total loss: [1m[32m0.16262[0m[0m | time: 16.895s
[2K
| RMSProp | epoch: 020 | loss: 0.16262 - acc: 0.9383 -- iter: 0608/1133
[A[ATraining Step: 704  | total loss: [1m[32m0.14848[0m[0m | time: 17.920s
[2K
| RMSProp | epoch: 020 | loss: 0.14848 - acc: 0.9445 -- iter: 0640/1133
[A[ATraining Step: 705  | total loss: [1m[32m0.15432[0m[0m | time: 19.074s
[2K
| RMSProp | epoch: 020 | loss: 0.15432 - acc: 0.9438 -- iter: 0672/1133
[A[ATraining Step: 706  | total loss: [1m[32m0.21291[0m[0m | time: 20.070s
[2K
| RMSProp | epoch: 020 | loss: 0.21291 - acc: 0.9213 -- iter: 0704/1133
[A[ATraining Step: 707  | total loss: [1m[32m0.21099[0m[0m | time: 20.822s
[2K
| RMSProp | epoch: 020 | loss: 0.21099 - acc: 0.9229 -- iter: 0736/1133
[A[ATraining Step: 708  | total loss: [1m[32m0.20419[0m[0m | time: 21.788s
[2K
| RMSProp | epoch: 020 | loss: 0.20419 - acc: 0.9275 -- iter: 0768/1133
[A[ATraining Step: 709  | total loss: [1m[32m0.18717[0m[0m | time: 22.689s
[2K
| RMSProp | epoch: 020 | loss: 0.18717 - acc: 0.9347 -- iter: 0800/1133
[A[ATraining Step: 710  | total loss: [1m[32m0.19434[0m[0m | time: 23.643s
[2K
| RMSProp | epoch: 020 | loss: 0.19434 - acc: 0.9319 -- iter: 0832/1133
[A[ATraining Step: 711  | total loss: [1m[32m0.18864[0m[0m | time: 24.560s
[2K
| RMSProp | epoch: 020 | loss: 0.18864 - acc: 0.9324 -- iter: 0864/1133
[A[ATraining Step: 712  | total loss: [1m[32m0.20851[0m[0m | time: 25.478s
[2K
| RMSProp | epoch: 020 | loss: 0.20851 - acc: 0.9204 -- iter: 0896/1133
[A[ATraining Step: 713  | total loss: [1m[32m0.19984[0m[0m | time: 26.399s
[2K
| RMSProp | epoch: 020 | loss: 0.19984 - acc: 0.9222 -- iter: 0928/1133
[A[ATraining Step: 714  | total loss: [1m[32m0.18889[0m[0m | time: 27.309s
[2K
| RMSProp | epoch: 020 | loss: 0.18889 - acc: 0.9268 -- iter: 0960/1133
[A[ATraining Step: 715  | total loss: [1m[32m0.17668[0m[0m | time: 28.163s
[2K
| RMSProp | epoch: 020 | loss: 0.17668 - acc: 0.9341 -- iter: 0992/1133
[A[ATraining Step: 716  | total loss: [1m[32m0.18409[0m[0m | time: 29.030s
[2K
| RMSProp | epoch: 020 | loss: 0.18409 - acc: 0.9313 -- iter: 1024/1133
[A[ATraining Step: 717  | total loss: [1m[32m0.19263[0m[0m | time: 30.085s
[2K
| RMSProp | epoch: 020 | loss: 0.19263 - acc: 0.9288 -- iter: 1056/1133
[A[ATraining Step: 718  | total loss: [1m[32m0.19240[0m[0m | time: 31.172s
[2K
| RMSProp | epoch: 020 | loss: 0.19240 - acc: 0.9328 -- iter: 1088/1133
[A[ATraining Step: 719  | total loss: [1m[32m0.19216[0m[0m | time: 32.023s
[2K
| RMSProp | epoch: 020 | loss: 0.19216 - acc: 0.9302 -- iter: 1120/1133
[A[ATraining Step: 720  | total loss: [1m[32m0.21441[0m[0m | time: 34.664s
[2K
| RMSProp | epoch: 020 | loss: 0.21441 - acc: 0.9153 | val_loss: 0.57606 - val_acc: 0.7662 -- iter: 1133/1133
--
Training Step: 721  | total loss: [1m[32m0.21680[0m[0m | time: 0.949s
[2K
| RMSProp | epoch: 021 | loss: 0.21680 - acc: 0.9144 -- iter: 0032/1133
[A[ATraining Step: 722  | total loss: [1m[32m0.20939[0m[0m | time: 1.867s
[2K
| RMSProp | epoch: 021 | loss: 0.20939 - acc: 0.9136 -- iter: 0064/1133
[A[ATraining Step: 723  | total loss: [1m[32m0.19591[0m[0m | time: 2.782s
[2K
| RMSProp | epoch: 021 | loss: 0.19591 - acc: 0.9222 -- iter: 0096/1133
[A[ATraining Step: 724  | total loss: [1m[32m0.18457[0m[0m | time: 3.722s
[2K
| RMSProp | epoch: 021 | loss: 0.18457 - acc: 0.9300 -- iter: 0128/1133
[A[ATraining Step: 725  | total loss: [1m[32m0.17087[0m[0m | time: 4.562s
[2K
| RMSProp | epoch: 021 | loss: 0.17087 - acc: 0.9339 -- iter: 0160/1133
[A[ATraining Step: 726  | total loss: [1m[32m0.15603[0m[0m | time: 5.871s
[2K
| RMSProp | epoch: 021 | loss: 0.15603 - acc: 0.9405 -- iter: 0192/1133
[A[ATraining Step: 727  | total loss: [1m[32m0.14332[0m[0m | time: 7.074s
[2K
| RMSProp | epoch: 021 | loss: 0.14332 - acc: 0.9464 -- iter: 0224/1133
[A[ATraining Step: 728  | total loss: [1m[32m0.13302[0m[0m | time: 8.077s
[2K
| RMSProp | epoch: 021 | loss: 0.13302 - acc: 0.9518 -- iter: 0256/1133
[A[ATraining Step: 729  | total loss: [1m[32m0.13070[0m[0m | time: 8.911s
[2K
| RMSProp | epoch: 021 | loss: 0.13070 - acc: 0.9535 -- iter: 0288/1133
[A[ATraining Step: 730  | total loss: [1m[32m0.12761[0m[0m | time: 9.880s
[2K
| RMSProp | epoch: 021 | loss: 0.12761 - acc: 0.9550 -- iter: 0320/1133
[A[ATraining Step: 731  | total loss: [1m[32m0.12902[0m[0m | time: 10.805s
[2K
| RMSProp | epoch: 021 | loss: 0.12902 - acc: 0.9501 -- iter: 0352/1133
[A[ATraining Step: 732  | total loss: [1m[32m0.14819[0m[0m | time: 11.724s
[2K
| RMSProp | epoch: 021 | loss: 0.14819 - acc: 0.9395 -- iter: 0384/1133
[A[ATraining Step: 733  | total loss: [1m[32m0.14645[0m[0m | time: 12.654s
[2K
| RMSProp | epoch: 021 | loss: 0.14645 - acc: 0.9393 -- iter: 0416/1133
[A[ATraining Step: 734  | total loss: [1m[32m0.16974[0m[0m | time: 13.589s
[2K
| RMSProp | epoch: 021 | loss: 0.16974 - acc: 0.9297 -- iter: 0448/1133
[A[ATraining Step: 735  | total loss: [1m[32m0.16301[0m[0m | time: 14.466s
[2K
| RMSProp | epoch: 021 | loss: 0.16301 - acc: 0.9336 -- iter: 0480/1133
[A[ATraining Step: 736  | total loss: [1m[32m0.15558[0m[0m | time: 15.410s
[2K
| RMSProp | epoch: 021 | loss: 0.15558 - acc: 0.9372 -- iter: 0512/1133
[A[ATraining Step: 737  | total loss: [1m[32m0.14791[0m[0m | time: 16.228s
[2K
| RMSProp | epoch: 021 | loss: 0.14791 - acc: 0.9434 -- iter: 0544/1133
[A[ATraining Step: 738  | total loss: [1m[32m0.15084[0m[0m | time: 17.420s
[2K
| RMSProp | epoch: 021 | loss: 0.15084 - acc: 0.9428 -- iter: 0576/1133
[A[ATraining Step: 739  | total loss: [1m[32m0.14984[0m[0m | time: 17.926s
[2K
| RMSProp | epoch: 021 | loss: 0.14984 - acc: 0.9392 -- iter: 0608/1133
[A[ATraining Step: 740  | total loss: [1m[32m0.15417[0m[0m | time: 18.401s
[2K
| RMSProp | epoch: 021 | loss: 0.15417 - acc: 0.9376 -- iter: 0640/1133
[A[ATraining Step: 741  | total loss: [1m[32m0.14123[0m[0m | time: 19.460s
[2K
| RMSProp | epoch: 021 | loss: 0.14123 - acc: 0.9438 -- iter: 0672/1133
[A[ATraining Step: 742  | total loss: [1m[32m0.14772[0m[0m | time: 20.208s
[2K
| RMSProp | epoch: 021 | loss: 0.14772 - acc: 0.9432 -- iter: 0704/1133
[A[ATraining Step: 743  | total loss: [1m[32m0.14356[0m[0m | time: 21.077s
[2K
| RMSProp | epoch: 021 | loss: 0.14356 - acc: 0.9426 -- iter: 0736/1133
[A[ATraining Step: 744  | total loss: [1m[32m0.13760[0m[0m | time: 21.965s
[2K
| RMSProp | epoch: 021 | loss: 0.13760 - acc: 0.9452 -- iter: 0768/1133
[A[ATraining Step: 745  | total loss: [1m[32m0.31446[0m[0m | time: 22.833s
[2K
| RMSProp | epoch: 021 | loss: 0.31446 - acc: 0.9163 -- iter: 0800/1133
[A[ATraining Step: 746  | total loss: [1m[32m0.30342[0m[0m | time: 23.707s
[2K
| RMSProp | epoch: 021 | loss: 0.30342 - acc: 0.9184 -- iter: 0832/1133
[A[ATraining Step: 747  | total loss: [1m[32m0.28416[0m[0m | time: 24.609s
[2K
| RMSProp | epoch: 021 | loss: 0.28416 - acc: 0.9235 -- iter: 0864/1133
[A[ATraining Step: 748  | total loss: [1m[32m0.25942[0m[0m | time: 25.546s
[2K
| RMSProp | epoch: 021 | loss: 0.25942 - acc: 0.9311 -- iter: 0896/1133
[A[ATraining Step: 749  | total loss: [1m[32m0.23609[0m[0m | time: 26.469s
[2K
| RMSProp | epoch: 021 | loss: 0.23609 - acc: 0.9380 -- iter: 0928/1133
[A[ATraining Step: 750  | total loss: [1m[32m0.22145[0m[0m | time: 27.380s
[2K
| RMSProp | epoch: 021 | loss: 0.22145 - acc: 0.9380 -- iter: 0960/1133
[A[ATraining Step: 751  | total loss: [1m[32m0.20398[0m[0m | time: 28.205s
[2K
| RMSProp | epoch: 021 | loss: 0.20398 - acc: 0.9442 -- iter: 0992/1133
[A[ATraining Step: 752  | total loss: [1m[32m0.19483[0m[0m | time: 29.312s
[2K
| RMSProp | epoch: 021 | loss: 0.19483 - acc: 0.9466 -- iter: 1024/1133
[A[ATraining Step: 753  | total loss: [1m[32m0.19854[0m[0m | time: 30.441s
[2K
| RMSProp | epoch: 021 | loss: 0.19854 - acc: 0.9395 -- iter: 1056/1133
[A[ATraining Step: 754  | total loss: [1m[32m0.19533[0m[0m | time: 31.422s
[2K
| RMSProp | epoch: 021 | loss: 0.19533 - acc: 0.9393 -- iter: 1088/1133
[A[ATraining Step: 755  | total loss: [1m[32m0.18695[0m[0m | time: 32.200s
[2K
| RMSProp | epoch: 021 | loss: 0.18695 - acc: 0.9422 -- iter: 1120/1133
[A[ATraining Step: 756  | total loss: [1m[32m0.17712[0m[0m | time: 34.871s
[2K
| RMSProp | epoch: 021 | loss: 0.17712 - acc: 0.9449 | val_loss: 0.60071 - val_acc: 0.8113 -- iter: 1133/1133
--
Training Step: 757  | total loss: [1m[32m0.16919[0m[0m | time: 0.988s
[2K
| RMSProp | epoch: 022 | loss: 0.16919 - acc: 0.9473 -- iter: 0032/1133
[A[ATraining Step: 758  | total loss: [1m[32m0.16309[0m[0m | time: 1.863s
[2K
| RMSProp | epoch: 022 | loss: 0.16309 - acc: 0.9494 -- iter: 0064/1133
[A[ATraining Step: 759  | total loss: [1m[32m0.16413[0m[0m | time: 2.817s
[2K
| RMSProp | epoch: 022 | loss: 0.16413 - acc: 0.9482 -- iter: 0096/1133
[A[ATraining Step: 760  | total loss: [1m[32m0.15994[0m[0m | time: 3.989s
[2K
| RMSProp | epoch: 022 | loss: 0.15994 - acc: 0.9440 -- iter: 0128/1133
[A[ATraining Step: 761  | total loss: [1m[32m0.15017[0m[0m | time: 5.187s
[2K
| RMSProp | epoch: 022 | loss: 0.15017 - acc: 0.9496 -- iter: 0160/1133
[A[ATraining Step: 762  | total loss: [1m[32m0.14617[0m[0m | time: 5.984s
[2K
| RMSProp | epoch: 022 | loss: 0.14617 - acc: 0.9515 -- iter: 0192/1133
[A[ATraining Step: 763  | total loss: [1m[32m0.13476[0m[0m | time: 6.836s
[2K
| RMSProp | epoch: 022 | loss: 0.13476 - acc: 0.9564 -- iter: 0224/1133
[A[ATraining Step: 764  | total loss: [1m[32m0.12658[0m[0m | time: 7.736s
[2K
| RMSProp | epoch: 022 | loss: 0.12658 - acc: 0.9607 -- iter: 0256/1133
[A[ATraining Step: 765  | total loss: [1m[32m0.11954[0m[0m | time: 8.637s
[2K
| RMSProp | epoch: 022 | loss: 0.11954 - acc: 0.9615 -- iter: 0288/1133
[A[ATraining Step: 766  | total loss: [1m[32m0.11453[0m[0m | time: 9.546s
[2K
| RMSProp | epoch: 022 | loss: 0.11453 - acc: 0.9654 -- iter: 0320/1133
[A[ATraining Step: 767  | total loss: [1m[32m0.12765[0m[0m | time: 10.481s
[2K
| RMSProp | epoch: 022 | loss: 0.12765 - acc: 0.9595 -- iter: 0352/1133
[A[ATraining Step: 768  | total loss: [1m[32m0.11813[0m[0m | time: 11.414s
[2K
| RMSProp | epoch: 022 | loss: 0.11813 - acc: 0.9635 -- iter: 0384/1133
[A[ATraining Step: 769  | total loss: [1m[32m0.10872[0m[0m | time: 12.318s
[2K
| RMSProp | epoch: 022 | loss: 0.10872 - acc: 0.9672 -- iter: 0416/1133
[A[ATraining Step: 770  | total loss: [1m[32m0.10087[0m[0m | time: 13.232s
[2K
| RMSProp | epoch: 022 | loss: 0.10087 - acc: 0.9705 -- iter: 0448/1133
[A[ATraining Step: 771  | total loss: [1m[32m0.11015[0m[0m | time: 14.101s
[2K
| RMSProp | epoch: 022 | loss: 0.11015 - acc: 0.9672 -- iter: 0480/1133
[A[ATraining Step: 772  | total loss: [1m[32m0.11576[0m[0m | time: 15.005s
[2K
| RMSProp | epoch: 022 | loss: 0.11576 - acc: 0.9579 -- iter: 0512/1133
[A[ATraining Step: 773  | total loss: [1m[32m0.11625[0m[0m | time: 16.115s
[2K
| RMSProp | epoch: 022 | loss: 0.11625 - acc: 0.9559 -- iter: 0544/1133
[A[ATraining Step: 774  | total loss: [1m[32m0.11240[0m[0m | time: 17.209s
[2K
| RMSProp | epoch: 022 | loss: 0.11240 - acc: 0.9572 -- iter: 0576/1133
[A[ATraining Step: 775  | total loss: [1m[32m0.10899[0m[0m | time: 18.028s
[2K
| RMSProp | epoch: 022 | loss: 0.10899 - acc: 0.9583 -- iter: 0608/1133
[A[ATraining Step: 776  | total loss: [1m[32m0.11134[0m[0m | time: 18.414s
[2K
| RMSProp | epoch: 022 | loss: 0.11134 - acc: 0.9531 -- iter: 0640/1133
[A[ATraining Step: 777  | total loss: [1m[32m0.17116[0m[0m | time: 18.827s
[2K
| RMSProp | epoch: 022 | loss: 0.17116 - acc: 0.9270 -- iter: 0672/1133
[A[ATraining Step: 778  | total loss: [1m[32m0.17332[0m[0m | time: 19.731s
[2K
| RMSProp | epoch: 022 | loss: 0.17332 - acc: 0.9267 -- iter: 0704/1133
[A[ATraining Step: 779  | total loss: [1m[32m0.18070[0m[0m | time: 20.661s
[2K
| RMSProp | epoch: 022 | loss: 0.18070 - acc: 0.9277 -- iter: 0736/1133
[A[ATraining Step: 780  | total loss: [1m[32m0.19514[0m[0m | time: 21.603s
[2K
| RMSProp | epoch: 022 | loss: 0.19514 - acc: 0.9225 -- iter: 0768/1133
[A[ATraining Step: 781  | total loss: [1m[32m0.21619[0m[0m | time: 22.538s
[2K
| RMSProp | epoch: 022 | loss: 0.21619 - acc: 0.9177 -- iter: 0800/1133
[A[ATraining Step: 782  | total loss: [1m[32m0.23127[0m[0m | time: 23.476s
[2K
| RMSProp | epoch: 022 | loss: 0.23127 - acc: 0.9166 -- iter: 0832/1133
[A[ATraining Step: 783  | total loss: [1m[32m0.21598[0m[0m | time: 24.338s
[2K
| RMSProp | epoch: 022 | loss: 0.21598 - acc: 0.9249 -- iter: 0864/1133
[A[ATraining Step: 784  | total loss: [1m[32m0.20761[0m[0m | time: 25.256s
[2K
| RMSProp | epoch: 022 | loss: 0.20761 - acc: 0.9293 -- iter: 0896/1133
[A[ATraining Step: 785  | total loss: [1m[32m0.19778[0m[0m | time: 26.139s
[2K
| RMSProp | epoch: 022 | loss: 0.19778 - acc: 0.9332 -- iter: 0928/1133
[A[ATraining Step: 786  | total loss: [1m[32m0.18005[0m[0m | time: 27.318s
[2K
| RMSProp | epoch: 022 | loss: 0.18005 - acc: 0.9399 -- iter: 0960/1133
[A[ATraining Step: 787  | total loss: [1m[32m0.16545[0m[0m | time: 28.501s
[2K
| RMSProp | epoch: 022 | loss: 0.16545 - acc: 0.9459 -- iter: 0992/1133
[A[ATraining Step: 788  | total loss: [1m[32m0.16533[0m[0m | time: 29.475s
[2K
| RMSProp | epoch: 022 | loss: 0.16533 - acc: 0.9451 -- iter: 1024/1133
[A[ATraining Step: 789  | total loss: [1m[32m0.16167[0m[0m | time: 30.258s
[2K
| RMSProp | epoch: 022 | loss: 0.16167 - acc: 0.9443 -- iter: 1056/1133
[A[ATraining Step: 790  | total loss: [1m[32m0.14938[0m[0m | time: 31.153s
[2K
| RMSProp | epoch: 022 | loss: 0.14938 - acc: 0.9499 -- iter: 1088/1133
[A[ATraining Step: 791  | total loss: [1m[32m0.13664[0m[0m | time: 32.052s
[2K
| RMSProp | epoch: 022 | loss: 0.13664 - acc: 0.9549 -- iter: 1120/1133
[A[ATraining Step: 792  | total loss: [1m[32m0.12743[0m[0m | time: 34.810s
[2K
| RMSProp | epoch: 022 | loss: 0.12743 - acc: 0.9594 | val_loss: 0.61208 - val_acc: 0.8225 -- iter: 1133/1133
--
Training Step: 793  | total loss: [1m[32m0.11645[0m[0m | time: 1.239s
[2K
| RMSProp | epoch: 023 | loss: 0.11645 - acc: 0.9635 -- iter: 0032/1133
[A[ATraining Step: 794  | total loss: [1m[32m0.10852[0m[0m | time: 2.394s
[2K
| RMSProp | epoch: 023 | loss: 0.10852 - acc: 0.9671 -- iter: 0064/1133
[A[ATraining Step: 795  | total loss: [1m[32m0.09913[0m[0m | time: 3.314s
[2K
| RMSProp | epoch: 023 | loss: 0.09913 - acc: 0.9704 -- iter: 0096/1133
[A[ATraining Step: 796  | total loss: [1m[32m0.10130[0m[0m | time: 4.214s
[2K
| RMSProp | epoch: 023 | loss: 0.10130 - acc: 0.9702 -- iter: 0128/1133
[A[ATraining Step: 797  | total loss: [1m[32m0.11973[0m[0m | time: 5.144s
[2K
| RMSProp | epoch: 023 | loss: 0.11973 - acc: 0.9638 -- iter: 0160/1133
[A[ATraining Step: 798  | total loss: [1m[32m0.12230[0m[0m | time: 6.063s
[2K
| RMSProp | epoch: 023 | loss: 0.12230 - acc: 0.9612 -- iter: 0192/1133
[A[ATraining Step: 799  | total loss: [1m[32m0.12570[0m[0m | time: 6.952s
[2K
| RMSProp | epoch: 023 | loss: 0.12570 - acc: 0.9588 -- iter: 0224/1133
[A[ATraining Step: 800  | total loss: [1m[32m0.11948[0m[0m | time: 9.674s
[2K
| RMSProp | epoch: 023 | loss: 0.11948 - acc: 0.9598 | val_loss: 0.50745 - val_acc: 0.8535 -- iter: 0256/1133
--
Training Step: 801  | total loss: [1m[32m0.11136[0m[0m | time: 10.748s
[2K
| RMSProp | epoch: 023 | loss: 0.11136 - acc: 0.9638 -- iter: 0288/1133
[A[ATraining Step: 802  | total loss: [1m[32m0.11730[0m[0m | time: 11.896s
[2K
| RMSProp | epoch: 023 | loss: 0.11730 - acc: 0.9612 -- iter: 0320/1133
[A[ATraining Step: 803  | total loss: [1m[32m0.11091[0m[0m | time: 13.047s
[2K
| RMSProp | epoch: 023 | loss: 0.11091 - acc: 0.9651 -- iter: 0352/1133
[A[ATraining Step: 804  | total loss: [1m[32m0.10176[0m[0m | time: 13.800s
[2K
| RMSProp | epoch: 023 | loss: 0.10176 - acc: 0.9686 -- iter: 0384/1133
[A[ATraining Step: 805  | total loss: [1m[32m0.09588[0m[0m | time: 14.670s
[2K
| RMSProp | epoch: 023 | loss: 0.09588 - acc: 0.9686 -- iter: 0416/1133
[A[ATraining Step: 806  | total loss: [1m[32m0.10126[0m[0m | time: 15.592s
[2K
| RMSProp | epoch: 023 | loss: 0.10126 - acc: 0.9655 -- iter: 0448/1133
[A[ATraining Step: 807  | total loss: [1m[32m0.09485[0m[0m | time: 16.478s
[2K
| RMSProp | epoch: 023 | loss: 0.09485 - acc: 0.9689 -- iter: 0480/1133
[A[ATraining Step: 808  | total loss: [1m[32m0.09778[0m[0m | time: 17.400s
[2K
| RMSProp | epoch: 023 | loss: 0.09778 - acc: 0.9658 -- iter: 0512/1133
[A[ATraining Step: 809  | total loss: [1m[32m0.12813[0m[0m | time: 18.309s
[2K
| RMSProp | epoch: 023 | loss: 0.12813 - acc: 0.9536 -- iter: 0544/1133
[A[ATraining Step: 810  | total loss: [1m[32m0.12338[0m[0m | time: 19.219s
[2K
| RMSProp | epoch: 023 | loss: 0.12338 - acc: 0.9551 -- iter: 0576/1133
[A[ATraining Step: 811  | total loss: [1m[32m0.11746[0m[0m | time: 20.133s
[2K
| RMSProp | epoch: 023 | loss: 0.11746 - acc: 0.9596 -- iter: 0608/1133
[A[ATraining Step: 812  | total loss: [1m[32m0.10790[0m[0m | time: 21.125s
[2K
| RMSProp | epoch: 023 | loss: 0.10790 - acc: 0.9636 -- iter: 0640/1133
[A[ATraining Step: 813  | total loss: [1m[32m0.10927[0m[0m | time: 21.515s
[2K
| RMSProp | epoch: 023 | loss: 0.10927 - acc: 0.9641 -- iter: 0672/1133
[A[ATraining Step: 814  | total loss: [1m[32m0.10067[0m[0m | time: 21.884s
[2K
| RMSProp | epoch: 023 | loss: 0.10067 - acc: 0.9677 -- iter: 0704/1133
[A[ATraining Step: 815  | total loss: [1m[32m0.09128[0m[0m | time: 23.033s
[2K
| RMSProp | epoch: 023 | loss: 0.09128 - acc: 0.9710 -- iter: 0736/1133
[A[ATraining Step: 816  | total loss: [1m[32m0.09759[0m[0m | time: 24.164s
[2K
| RMSProp | epoch: 023 | loss: 0.09759 - acc: 0.9676 -- iter: 0768/1133
[A[ATraining Step: 817  | total loss: [1m[32m0.13829[0m[0m | time: 25.005s
[2K
| RMSProp | epoch: 023 | loss: 0.13829 - acc: 0.9584 -- iter: 0800/1133
[A[ATraining Step: 818  | total loss: [1m[32m0.13165[0m[0m | time: 25.877s
[2K
| RMSProp | epoch: 023 | loss: 0.13165 - acc: 0.9594 -- iter: 0832/1133
[A[ATraining Step: 819  | total loss: [1m[32m0.14986[0m[0m | time: 26.797s
[2K
| RMSProp | epoch: 023 | loss: 0.14986 - acc: 0.9541 -- iter: 0864/1133
[A[ATraining Step: 820  | total loss: [1m[32m0.16197[0m[0m | time: 27.752s
[2K
| RMSProp | epoch: 023 | loss: 0.16197 - acc: 0.9462 -- iter: 0896/1133
[A[ATraining Step: 821  | total loss: [1m[32m0.14827[0m[0m | time: 28.641s
[2K
| RMSProp | epoch: 023 | loss: 0.14827 - acc: 0.9516 -- iter: 0928/1133
[A[ATraining Step: 822  | total loss: [1m[32m0.14526[0m[0m | time: 29.577s
[2K
| RMSProp | epoch: 023 | loss: 0.14526 - acc: 0.9501 -- iter: 0960/1133
[A[ATraining Step: 823  | total loss: [1m[32m0.13687[0m[0m | time: 30.496s
[2K
| RMSProp | epoch: 023 | loss: 0.13687 - acc: 0.9520 -- iter: 0992/1133
[A[ATraining Step: 824  | total loss: [1m[32m0.13091[0m[0m | time: 31.417s
[2K
| RMSProp | epoch: 023 | loss: 0.13091 - acc: 0.9537 -- iter: 1024/1133
[A[ATraining Step: 825  | total loss: [1m[32m0.12109[0m[0m | time: 32.395s
[2K
| RMSProp | epoch: 023 | loss: 0.12109 - acc: 0.9583 -- iter: 1056/1133
[A[ATraining Step: 826  | total loss: [1m[32m0.13491[0m[0m | time: 33.187s
[2K
| RMSProp | epoch: 023 | loss: 0.13491 - acc: 0.9531 -- iter: 1088/1133
[A[ATraining Step: 827  | total loss: [1m[32m0.14533[0m[0m | time: 34.286s
[2K
| RMSProp | epoch: 023 | loss: 0.14533 - acc: 0.9484 -- iter: 1120/1133
[A[ATraining Step: 828  | total loss: [1m[32m0.14694[0m[0m | time: 37.320s
[2K
| RMSProp | epoch: 023 | loss: 0.14694 - acc: 0.9473 | val_loss: 0.49735 - val_acc: 0.8225 -- iter: 1133/1133
--
Training Step: 829  | total loss: [1m[32m0.13769[0m[0m | time: 0.900s
[2K
| RMSProp | epoch: 024 | loss: 0.13769 - acc: 0.9526 -- iter: 0032/1133
[A[ATraining Step: 830  | total loss: [1m[32m0.12668[0m[0m | time: 1.848s
[2K
| RMSProp | epoch: 024 | loss: 0.12668 - acc: 0.9573 -- iter: 0064/1133
[A[ATraining Step: 831  | total loss: [1m[32m0.11582[0m[0m | time: 2.787s
[2K
| RMSProp | epoch: 024 | loss: 0.11582 - acc: 0.9616 -- iter: 0096/1133
[A[ATraining Step: 832  | total loss: [1m[32m0.10845[0m[0m | time: 3.664s
[2K
| RMSProp | epoch: 024 | loss: 0.10845 - acc: 0.9623 -- iter: 0128/1133
[A[ATraining Step: 833  | total loss: [1m[32m0.11860[0m[0m | time: 4.495s
[2K
| RMSProp | epoch: 024 | loss: 0.11860 - acc: 0.9567 -- iter: 0160/1133
[A[ATraining Step: 834  | total loss: [1m[32m0.15136[0m[0m | time: 5.491s
[2K
| RMSProp | epoch: 024 | loss: 0.15136 - acc: 0.9392 -- iter: 0192/1133
[A[ATraining Step: 835  | total loss: [1m[32m0.13987[0m[0m | time: 6.614s
[2K
| RMSProp | epoch: 024 | loss: 0.13987 - acc: 0.9452 -- iter: 0224/1133
[A[ATraining Step: 836  | total loss: [1m[32m0.13996[0m[0m | time: 7.716s
[2K
| RMSProp | epoch: 024 | loss: 0.13996 - acc: 0.9476 -- iter: 0256/1133
[A[ATraining Step: 837  | total loss: [1m[32m0.12975[0m[0m | time: 8.628s
[2K
| RMSProp | epoch: 024 | loss: 0.12975 - acc: 0.9528 -- iter: 0288/1133
[A[ATraining Step: 838  | total loss: [1m[32m0.13387[0m[0m | time: 9.470s
[2K
| RMSProp | epoch: 024 | loss: 0.13387 - acc: 0.9513 -- iter: 0320/1133
[A[ATraining Step: 839  | total loss: [1m[32m0.12487[0m[0m | time: 10.395s
[2K
| RMSProp | epoch: 024 | loss: 0.12487 - acc: 0.9562 -- iter: 0352/1133
[A[ATraining Step: 840  | total loss: [1m[32m0.11345[0m[0m | time: 11.333s
[2K
| RMSProp | epoch: 024 | loss: 0.11345 - acc: 0.9606 -- iter: 0384/1133
[A[ATraining Step: 841  | total loss: [1m[32m0.10373[0m[0m | time: 12.273s
[2K
| RMSProp | epoch: 024 | loss: 0.10373 - acc: 0.9645 -- iter: 0416/1133
[A[ATraining Step: 842  | total loss: [1m[32m0.09838[0m[0m | time: 13.173s
[2K
| RMSProp | epoch: 024 | loss: 0.09838 - acc: 0.9681 -- iter: 0448/1133
[A[ATraining Step: 843  | total loss: [1m[32m0.11439[0m[0m | time: 14.096s
[2K
| RMSProp | epoch: 024 | loss: 0.11439 - acc: 0.9619 -- iter: 0480/1133
[A[ATraining Step: 844  | total loss: [1m[32m0.10821[0m[0m | time: 15.013s
[2K
| RMSProp | epoch: 024 | loss: 0.10821 - acc: 0.9657 -- iter: 0512/1133
[A[ATraining Step: 845  | total loss: [1m[32m0.09997[0m[0m | time: 15.966s
[2K
| RMSProp | epoch: 024 | loss: 0.09997 - acc: 0.9691 -- iter: 0544/1133
[A[ATraining Step: 846  | total loss: [1m[32m0.09381[0m[0m | time: 16.754s
[2K
| RMSProp | epoch: 024 | loss: 0.09381 - acc: 0.9722 -- iter: 0576/1133
[A[ATraining Step: 847  | total loss: [1m[32m0.08687[0m[0m | time: 17.738s
[2K
| RMSProp | epoch: 024 | loss: 0.08687 - acc: 0.9750 -- iter: 0608/1133
[A[ATraining Step: 848  | total loss: [1m[32m0.08000[0m[0m | time: 18.897s
[2K
| RMSProp | epoch: 024 | loss: 0.08000 - acc: 0.9775 -- iter: 0640/1133
[A[ATraining Step: 849  | total loss: [1m[32m0.07266[0m[0m | time: 20.069s
[2K
| RMSProp | epoch: 024 | loss: 0.07266 - acc: 0.9797 -- iter: 0672/1133
[A[ATraining Step: 850  | total loss: [1m[32m0.07310[0m[0m | time: 20.356s
[2K
| RMSProp | epoch: 024 | loss: 0.07310 - acc: 0.9755 -- iter: 0704/1133
[A[ATraining Step: 851  | total loss: [1m[32m0.07634[0m[0m | time: 20.726s
[2K
| RMSProp | epoch: 024 | loss: 0.07634 - acc: 0.9780 -- iter: 0736/1133
[A[ATraining Step: 852  | total loss: [1m[32m0.07401[0m[0m | time: 21.611s
[2K
| RMSProp | epoch: 024 | loss: 0.07401 - acc: 0.9802 -- iter: 0768/1133
[A[ATraining Step: 853  | total loss: [1m[32m0.07598[0m[0m | time: 22.489s
[2K
| RMSProp | epoch: 024 | loss: 0.07598 - acc: 0.9790 -- iter: 0800/1133
[A[ATraining Step: 854  | total loss: [1m[32m0.08585[0m[0m | time: 23.356s
[2K
| RMSProp | epoch: 024 | loss: 0.08585 - acc: 0.9780 -- iter: 0832/1133
[A[ATraining Step: 855  | total loss: [1m[32m0.09549[0m[0m | time: 24.264s
[2K
| RMSProp | epoch: 024 | loss: 0.09549 - acc: 0.9739 -- iter: 0864/1133
[A[ATraining Step: 856  | total loss: [1m[32m0.11503[0m[0m | time: 25.188s
[2K
| RMSProp | epoch: 024 | loss: 0.11503 - acc: 0.9672 -- iter: 0896/1133
[A[ATraining Step: 857  | total loss: [1m[32m0.10612[0m[0m | time: 26.129s
[2K
| RMSProp | epoch: 024 | loss: 0.10612 - acc: 0.9705 -- iter: 0928/1133
[A[ATraining Step: 858  | total loss: [1m[32m0.09701[0m[0m | time: 27.027s
[2K
| RMSProp | epoch: 024 | loss: 0.09701 - acc: 0.9734 -- iter: 0960/1133
[A[ATraining Step: 859  | total loss: [1m[32m0.10563[0m[0m | time: 27.934s
[2K
| RMSProp | epoch: 024 | loss: 0.10563 - acc: 0.9667 -- iter: 0992/1133
[A[ATraining Step: 860  | total loss: [1m[32m0.11944[0m[0m | time: 28.805s
[2K
| RMSProp | epoch: 024 | loss: 0.11944 - acc: 0.9638 -- iter: 1024/1133
[A[ATraining Step: 861  | total loss: [1m[32m0.14794[0m[0m | time: 30.039s
[2K
| RMSProp | epoch: 024 | loss: 0.14794 - acc: 0.9518 -- iter: 1056/1133
[A[ATraining Step: 862  | total loss: [1m[32m0.15792[0m[0m | time: 31.195s
[2K
| RMSProp | epoch: 024 | loss: 0.15792 - acc: 0.9441 -- iter: 1088/1133
[A[ATraining Step: 863  | total loss: [1m[32m0.15581[0m[0m | time: 32.017s
[2K
| RMSProp | epoch: 024 | loss: 0.15581 - acc: 0.9434 -- iter: 1120/1133
[A[ATraining Step: 864  | total loss: [1m[32m0.16135[0m[0m | time: 34.689s
[2K
| RMSProp | epoch: 024 | loss: 0.16135 - acc: 0.9428 | val_loss: 0.52816 - val_acc: 0.8338 -- iter: 1133/1133
--
Training Step: 865  | total loss: [1m[32m0.14727[0m[0m | time: 0.881s
[2K
| RMSProp | epoch: 025 | loss: 0.14727 - acc: 0.9486 -- iter: 0032/1133
[A[ATraining Step: 866  | total loss: [1m[32m0.13422[0m[0m | time: 1.789s
[2K
| RMSProp | epoch: 025 | loss: 0.13422 - acc: 0.9537 -- iter: 0064/1133
[A[ATraining Step: 867  | total loss: [1m[32m0.12299[0m[0m | time: 2.722s
[2K
| RMSProp | epoch: 025 | loss: 0.12299 - acc: 0.9583 -- iter: 0096/1133
[A[ATraining Step: 868  | total loss: [1m[32m0.11205[0m[0m | time: 3.641s
[2K
| RMSProp | epoch: 025 | loss: 0.11205 - acc: 0.9625 -- iter: 0128/1133
[A[ATraining Step: 869  | total loss: [1m[32m0.10368[0m[0m | time: 4.441s
[2K
| RMSProp | epoch: 025 | loss: 0.10368 - acc: 0.9662 -- iter: 0160/1133
[A[ATraining Step: 870  | total loss: [1m[32m0.09698[0m[0m | time: 5.584s
[2K
| RMSProp | epoch: 025 | loss: 0.09698 - acc: 0.9696 -- iter: 0192/1133
[A[ATraining Step: 871  | total loss: [1m[32m0.09076[0m[0m | time: 6.713s
[2K
| RMSProp | epoch: 025 | loss: 0.09076 - acc: 0.9727 -- iter: 0224/1133
[A[ATraining Step: 872  | total loss: [1m[32m0.08723[0m[0m | time: 7.608s
[2K
| RMSProp | epoch: 025 | loss: 0.08723 - acc: 0.9723 -- iter: 0256/1133
[A[ATraining Step: 873  | total loss: [1m[32m0.10341[0m[0m | time: 8.479s
[2K
| RMSProp | epoch: 025 | loss: 0.10341 - acc: 0.9719 -- iter: 0288/1133
[A[ATraining Step: 874  | total loss: [1m[32m0.09531[0m[0m | time: 9.410s
[2K
| RMSProp | epoch: 025 | loss: 0.09531 - acc: 0.9747 -- iter: 0320/1133
[A[ATraining Step: 875  | total loss: [1m[32m0.08735[0m[0m | time: 10.380s
[2K
| RMSProp | epoch: 025 | loss: 0.08735 - acc: 0.9773 -- iter: 0352/1133
[A[ATraining Step: 876  | total loss: [1m[32m0.07949[0m[0m | time: 11.301s
[2K
| RMSProp | epoch: 025 | loss: 0.07949 - acc: 0.9795 -- iter: 0384/1133
[A[ATraining Step: 877  | total loss: [1m[32m0.07511[0m[0m | time: 12.205s
[2K
| RMSProp | epoch: 025 | loss: 0.07511 - acc: 0.9785 -- iter: 0416/1133
[A[ATraining Step: 878  | total loss: [1m[32m0.06912[0m[0m | time: 13.147s
[2K
| RMSProp | epoch: 025 | loss: 0.06912 - acc: 0.9806 -- iter: 0448/1133
[A[ATraining Step: 879  | total loss: [1m[32m0.06429[0m[0m | time: 14.073s
[2K
| RMSProp | epoch: 025 | loss: 0.06429 - acc: 0.9825 -- iter: 0480/1133
[A[ATraining Step: 880  | total loss: [1m[32m0.07469[0m[0m | time: 14.995s
[2K
| RMSProp | epoch: 025 | loss: 0.07469 - acc: 0.9812 -- iter: 0512/1133
[A[ATraining Step: 881  | total loss: [1m[32m0.07144[0m[0m | time: 15.823s
[2K
| RMSProp | epoch: 025 | loss: 0.07144 - acc: 0.9830 -- iter: 0544/1133
[A[ATraining Step: 882  | total loss: [1m[32m0.07610[0m[0m | time: 16.881s
[2K
| RMSProp | epoch: 025 | loss: 0.07610 - acc: 0.9785 -- iter: 0576/1133
[A[ATraining Step: 883  | total loss: [1m[32m0.08479[0m[0m | time: 17.914s
[2K
| RMSProp | epoch: 025 | loss: 0.08479 - acc: 0.9744 -- iter: 0608/1133
[A[ATraining Step: 884  | total loss: [1m[32m0.08565[0m[0m | time: 18.881s
[2K
| RMSProp | epoch: 025 | loss: 0.08565 - acc: 0.9738 -- iter: 0640/1133
[A[ATraining Step: 885  | total loss: [1m[32m0.08054[0m[0m | time: 19.642s
[2K
| RMSProp | epoch: 025 | loss: 0.08054 - acc: 0.9764 -- iter: 0672/1133
[A[ATraining Step: 886  | total loss: [1m[32m0.07320[0m[0m | time: 20.482s
[2K
| RMSProp | epoch: 025 | loss: 0.07320 - acc: 0.9788 -- iter: 0704/1133
[A[ATraining Step: 887  | total loss: [1m[32m0.06756[0m[0m | time: 20.870s
[2K
| RMSProp | epoch: 025 | loss: 0.06756 - acc: 0.9809 -- iter: 0736/1133
[A[ATraining Step: 888  | total loss: [1m[32m0.06436[0m[0m | time: 21.273s
[2K
| RMSProp | epoch: 025 | loss: 0.06436 - acc: 0.9828 -- iter: 0768/1133
[A[ATraining Step: 889  | total loss: [1m[32m0.05917[0m[0m | time: 22.191s
[2K
| RMSProp | epoch: 025 | loss: 0.05917 - acc: 0.9845 -- iter: 0800/1133
[A[ATraining Step: 890  | total loss: [1m[32m0.06193[0m[0m | time: 23.130s
[2K
| RMSProp | epoch: 025 | loss: 0.06193 - acc: 0.9830 -- iter: 0832/1133
[A[ATraining Step: 891  | total loss: [1m[32m0.07282[0m[0m | time: 24.039s
[2K
| RMSProp | epoch: 025 | loss: 0.07282 - acc: 0.9753 -- iter: 0864/1133
[A[ATraining Step: 892  | total loss: [1m[32m0.08421[0m[0m | time: 24.958s
[2K
| RMSProp | epoch: 025 | loss: 0.08421 - acc: 0.9715 -- iter: 0896/1133
[A[ATraining Step: 893  | total loss: [1m[32m0.14475[0m[0m | time: 25.845s
[2K
| RMSProp | epoch: 025 | loss: 0.14475 - acc: 0.9525 -- iter: 0928/1133
[A[ATraining Step: 894  | total loss: [1m[32m0.13609[0m[0m | time: 26.761s
[2K
| RMSProp | epoch: 025 | loss: 0.13609 - acc: 0.9541 -- iter: 0960/1133
[A[ATraining Step: 895  | total loss: [1m[32m0.12679[0m[0m | time: 27.609s
[2K
| RMSProp | epoch: 025 | loss: 0.12679 - acc: 0.9587 -- iter: 0992/1133
[A[ATraining Step: 896  | total loss: [1m[32m0.12128[0m[0m | time: 28.695s
[2K
| RMSProp | epoch: 025 | loss: 0.12128 - acc: 0.9597 -- iter: 1024/1133
[A[ATraining Step: 897  | total loss: [1m[32m0.11049[0m[0m | time: 29.882s
[2K
| RMSProp | epoch: 025 | loss: 0.11049 - acc: 0.9637 -- iter: 1056/1133
[A[ATraining Step: 898  | total loss: [1m[32m0.10115[0m[0m | time: 30.917s
[2K
| RMSProp | epoch: 025 | loss: 0.10115 - acc: 0.9674 -- iter: 1088/1133
[A[ATraining Step: 899  | total loss: [1m[32m0.10164[0m[0m | time: 31.653s
[2K
| RMSProp | epoch: 025 | loss: 0.10164 - acc: 0.9675 -- iter: 1120/1133
[A[ATraining Step: 900  | total loss: [1m[32m0.09527[0m[0m | time: 34.251s
[2K
| RMSProp | epoch: 025 | loss: 0.09527 - acc: 0.9708 | val_loss: 0.79067 - val_acc: 0.8028 -- iter: 1133/1133
--
Training Step: 901  | total loss: [1m[32m0.09320[0m[0m | time: 1.002s
[2K
| RMSProp | epoch: 026 | loss: 0.09320 - acc: 0.9706 -- iter: 0032/1133
[A[ATraining Step: 902  | total loss: [1m[32m0.09037[0m[0m | time: 1.952s
[2K
| RMSProp | epoch: 026 | loss: 0.09037 - acc: 0.9704 -- iter: 0064/1133
[A[ATraining Step: 903  | total loss: [1m[32m0.08287[0m[0m | time: 2.887s
[2K
| RMSProp | epoch: 026 | loss: 0.08287 - acc: 0.9733 -- iter: 0096/1133
[A[ATraining Step: 904  | total loss: [1m[32m0.07526[0m[0m | time: 3.745s
[2K
| RMSProp | epoch: 026 | loss: 0.07526 - acc: 0.9760 -- iter: 0128/1133
[A[ATraining Step: 905  | total loss: [1m[32m0.07064[0m[0m | time: 4.802s
[2K
| RMSProp | epoch: 026 | loss: 0.07064 - acc: 0.9784 -- iter: 0160/1133
[A[ATraining Step: 906  | total loss: [1m[32m0.09413[0m[0m | time: 5.851s
[2K
| RMSProp | epoch: 026 | loss: 0.09413 - acc: 0.9712 -- iter: 0192/1133
[A[ATraining Step: 907  | total loss: [1m[32m0.10101[0m[0m | time: 6.939s
[2K
| RMSProp | epoch: 026 | loss: 0.10101 - acc: 0.9678 -- iter: 0224/1133
[A[ATraining Step: 908  | total loss: [1m[32m0.09203[0m[0m | time: 7.646s
[2K
| RMSProp | epoch: 026 | loss: 0.09203 - acc: 0.9710 -- iter: 0256/1133
[A[ATraining Step: 909  | total loss: [1m[32m0.08632[0m[0m | time: 8.501s
[2K
| RMSProp | epoch: 026 | loss: 0.08632 - acc: 0.9708 -- iter: 0288/1133
[A[ATraining Step: 910  | total loss: [1m[32m0.08060[0m[0m | time: 9.384s
[2K
| RMSProp | epoch: 026 | loss: 0.08060 - acc: 0.9737 -- iter: 0320/1133
[A[ATraining Step: 911  | total loss: [1m[32m0.09303[0m[0m | time: 10.251s
[2K
| RMSProp | epoch: 026 | loss: 0.09303 - acc: 0.9732 -- iter: 0352/1133
[A[ATraining Step: 912  | total loss: [1m[32m0.08760[0m[0m | time: 11.168s
[2K
| RMSProp | epoch: 026 | loss: 0.08760 - acc: 0.9759 -- iter: 0384/1133
[A[ATraining Step: 913  | total loss: [1m[32m0.08555[0m[0m | time: 12.025s
[2K
| RMSProp | epoch: 026 | loss: 0.08555 - acc: 0.9752 -- iter: 0416/1133
[A[ATraining Step: 914  | total loss: [1m[32m0.08085[0m[0m | time: 12.937s
[2K
| RMSProp | epoch: 026 | loss: 0.08085 - acc: 0.9745 -- iter: 0448/1133
[A[ATraining Step: 915  | total loss: [1m[32m0.07331[0m[0m | time: 13.814s
[2K
| RMSProp | epoch: 026 | loss: 0.07331 - acc: 0.9771 -- iter: 0480/1133
[A[ATraining Step: 916  | total loss: [1m[32m0.06860[0m[0m | time: 14.744s
[2K
| RMSProp | epoch: 026 | loss: 0.06860 - acc: 0.9794 -- iter: 0512/1133
[A[ATraining Step: 917  | total loss: [1m[32m0.07650[0m[0m | time: 15.609s
[2K
| RMSProp | epoch: 026 | loss: 0.07650 - acc: 0.9783 -- iter: 0544/1133
[A[ATraining Step: 918  | total loss: [1m[32m0.07008[0m[0m | time: 16.603s
[2K
| RMSProp | epoch: 026 | loss: 0.07008 - acc: 0.9805 -- iter: 0576/1133
[A[ATraining Step: 919  | total loss: [1m[32m0.06770[0m[0m | time: 17.730s
[2K
| RMSProp | epoch: 026 | loss: 0.06770 - acc: 0.9793 -- iter: 0608/1133
[A[ATraining Step: 920  | total loss: [1m[32m0.06282[0m[0m | time: 18.817s
[2K
| RMSProp | epoch: 026 | loss: 0.06282 - acc: 0.9814 -- iter: 0640/1133
[A[ATraining Step: 921  | total loss: [1m[32m0.06340[0m[0m | time: 19.534s
[2K
| RMSProp | epoch: 026 | loss: 0.06340 - acc: 0.9801 -- iter: 0672/1133
[A[ATraining Step: 922  | total loss: [1m[32m0.06709[0m[0m | time: 20.437s
[2K
| RMSProp | epoch: 026 | loss: 0.06709 - acc: 0.9790 -- iter: 0704/1133
[A[ATraining Step: 923  | total loss: [1m[32m0.08569[0m[0m | time: 21.402s
[2K
| RMSProp | epoch: 026 | loss: 0.08569 - acc: 0.9748 -- iter: 0736/1133
[A[ATraining Step: 924  | total loss: [1m[32m0.10351[0m[0m | time: 21.820s
[2K
| RMSProp | epoch: 026 | loss: 0.10351 - acc: 0.9711 -- iter: 0768/1133
[A[ATraining Step: 925  | total loss: [1m[32m0.09455[0m[0m | time: 22.257s
[2K
| RMSProp | epoch: 026 | loss: 0.09455 - acc: 0.9740 -- iter: 0800/1133
[A[ATraining Step: 926  | total loss: [1m[32m0.08583[0m[0m | time: 23.165s
[2K
| RMSProp | epoch: 026 | loss: 0.08583 - acc: 0.9766 -- iter: 0832/1133
[A[ATraining Step: 927  | total loss: [1m[32m0.07795[0m[0m | time: 24.099s
[2K
| RMSProp | epoch: 026 | loss: 0.07795 - acc: 0.9789 -- iter: 0864/1133
[A[ATraining Step: 928  | total loss: [1m[32m0.07099[0m[0m | time: 25.072s
[2K
| RMSProp | epoch: 026 | loss: 0.07099 - acc: 0.9810 -- iter: 0896/1133
[A[ATraining Step: 929  | total loss: [1m[32m0.06474[0m[0m | time: 26.098s
[2K
| RMSProp | epoch: 026 | loss: 0.06474 - acc: 0.9829 -- iter: 0928/1133
[A[ATraining Step: 930  | total loss: [1m[32m0.07800[0m[0m | time: 26.964s
[2K
| RMSProp | epoch: 026 | loss: 0.07800 - acc: 0.9815 -- iter: 0960/1133
[A[ATraining Step: 931  | total loss: [1m[32m0.07576[0m[0m | time: 28.026s
[2K
| RMSProp | epoch: 026 | loss: 0.07576 - acc: 0.9834 -- iter: 0992/1133
[A[ATraining Step: 932  | total loss: [1m[32m0.06964[0m[0m | time: 29.101s
[2K
| RMSProp | epoch: 026 | loss: 0.06964 - acc: 0.9850 -- iter: 1024/1133
[A[ATraining Step: 933  | total loss: [1m[32m0.06348[0m[0m | time: 30.143s
[2K
| RMSProp | epoch: 026 | loss: 0.06348 - acc: 0.9865 -- iter: 1056/1133
[A[ATraining Step: 934  | total loss: [1m[32m0.05799[0m[0m | time: 30.939s
[2K
| RMSProp | epoch: 026 | loss: 0.05799 - acc: 0.9879 -- iter: 1088/1133
[A[ATraining Step: 935  | total loss: [1m[32m0.05245[0m[0m | time: 31.820s
[2K
| RMSProp | epoch: 026 | loss: 0.05245 - acc: 0.9891 -- iter: 1120/1133
[A[ATraining Step: 936  | total loss: [1m[32m0.04766[0m[0m | time: 34.525s
[2K
| RMSProp | epoch: 026 | loss: 0.04766 - acc: 0.9902 | val_loss: 0.74383 - val_acc: 0.8000 -- iter: 1133/1133
--
Training Step: 937  | total loss: [1m[32m0.05419[0m[0m | time: 0.924s
[2K
| RMSProp | epoch: 027 | loss: 0.05419 - acc: 0.9849 -- iter: 0032/1133
[A[ATraining Step: 938  | total loss: [1m[32m0.06718[0m[0m | time: 1.849s
[2K
| RMSProp | epoch: 027 | loss: 0.06718 - acc: 0.9802 -- iter: 0064/1133
[A[ATraining Step: 939  | total loss: [1m[32m0.07830[0m[0m | time: 2.723s
[2K
| RMSProp | epoch: 027 | loss: 0.07830 - acc: 0.9759 -- iter: 0096/1133
[A[ATraining Step: 940  | total loss: [1m[32m0.07346[0m[0m | time: 3.729s
[2K
| RMSProp | epoch: 027 | loss: 0.07346 - acc: 0.9783 -- iter: 0128/1133
[A[ATraining Step: 941  | total loss: [1m[32m0.06697[0m[0m | time: 4.843s
[2K
| RMSProp | epoch: 027 | loss: 0.06697 - acc: 0.9805 -- iter: 0160/1133
[A[ATraining Step: 942  | total loss: [1m[32m0.06096[0m[0m | time: 6.001s
[2K
| RMSProp | epoch: 027 | loss: 0.06096 - acc: 0.9824 -- iter: 0192/1133
[A[ATraining Step: 943  | total loss: [1m[32m0.06458[0m[0m | time: 6.814s
[2K
| RMSProp | epoch: 027 | loss: 0.06458 - acc: 0.9811 -- iter: 0224/1133
[A[ATraining Step: 944  | total loss: [1m[32m0.06249[0m[0m | time: 7.688s
[2K
| RMSProp | epoch: 027 | loss: 0.06249 - acc: 0.9798 -- iter: 0256/1133
[A[ATraining Step: 945  | total loss: [1m[32m0.05733[0m[0m | time: 8.582s
[2K
| RMSProp | epoch: 027 | loss: 0.05733 - acc: 0.9818 -- iter: 0288/1133
[A[ATraining Step: 946  | total loss: [1m[32m0.05300[0m[0m | time: 9.489s
[2K
| RMSProp | epoch: 027 | loss: 0.05300 - acc: 0.9837 -- iter: 0320/1133
[A[ATraining Step: 947  | total loss: [1m[32m0.04806[0m[0m | time: 10.404s
[2K
| RMSProp | epoch: 027 | loss: 0.04806 - acc: 0.9853 -- iter: 0352/1133
[A[ATraining Step: 948  | total loss: [1m[32m0.05033[0m[0m | time: 11.362s
[2K
| RMSProp | epoch: 027 | loss: 0.05033 - acc: 0.9836 -- iter: 0384/1133
[A[ATraining Step: 949  | total loss: [1m[32m0.07332[0m[0m | time: 12.281s
[2K
| RMSProp | epoch: 027 | loss: 0.07332 - acc: 0.9697 -- iter: 0416/1133
[A[ATraining Step: 950  | total loss: [1m[32m0.08494[0m[0m | time: 13.187s
[2K
| RMSProp | epoch: 027 | loss: 0.08494 - acc: 0.9633 -- iter: 0448/1133
[A[ATraining Step: 951  | total loss: [1m[32m0.08092[0m[0m | time: 14.048s
[2K
| RMSProp | epoch: 027 | loss: 0.08092 - acc: 0.9670 -- iter: 0480/1133
[A[ATraining Step: 952  | total loss: [1m[32m0.08628[0m[0m | time: 15.030s
[2K
| RMSProp | epoch: 027 | loss: 0.08628 - acc: 0.9672 -- iter: 0512/1133
[A[ATraining Step: 953  | total loss: [1m[32m0.08243[0m[0m | time: 16.079s
[2K
| RMSProp | epoch: 027 | loss: 0.08243 - acc: 0.9704 -- iter: 0544/1133
[A[ATraining Step: 954  | total loss: [1m[32m0.07579[0m[0m | time: 17.174s
[2K
| RMSProp | epoch: 027 | loss: 0.07579 - acc: 0.9734 -- iter: 0576/1133
[A[ATraining Step: 955  | total loss: [1m[32m0.08281[0m[0m | time: 17.939s
[2K
| RMSProp | epoch: 027 | loss: 0.08281 - acc: 0.9729 -- iter: 0608/1133
[A[ATraining Step: 956  | total loss: [1m[32m0.08050[0m[0m | time: 18.770s
[2K
| RMSProp | epoch: 027 | loss: 0.08050 - acc: 0.9725 -- iter: 0640/1133
[A[ATraining Step: 957  | total loss: [1m[32m0.08310[0m[0m | time: 19.735s
[2K
| RMSProp | epoch: 027 | loss: 0.08310 - acc: 0.9721 -- iter: 0672/1133
[A[ATraining Step: 958  | total loss: [1m[32m0.07655[0m[0m | time: 20.686s
[2K
| RMSProp | epoch: 027 | loss: 0.07655 - acc: 0.9749 -- iter: 0704/1133
[A[ATraining Step: 959  | total loss: [1m[32m0.06975[0m[0m | time: 21.586s
[2K
| RMSProp | epoch: 027 | loss: 0.06975 - acc: 0.9774 -- iter: 0736/1133
[A[ATraining Step: 960  | total loss: [1m[32m0.06331[0m[0m | time: 22.485s
[2K
| RMSProp | epoch: 027 | loss: 0.06331 - acc: 0.9797 -- iter: 0768/1133
[A[ATraining Step: 961  | total loss: [1m[32m0.05784[0m[0m | time: 22.896s
[2K
| RMSProp | epoch: 027 | loss: 0.05784 - acc: 0.9817 -- iter: 0800/1133
[A[ATraining Step: 962  | total loss: [1m[32m0.09014[0m[0m | time: 23.315s
[2K
| RMSProp | epoch: 027 | loss: 0.09014 - acc: 0.9759 -- iter: 0832/1133
[A[ATraining Step: 963  | total loss: [1m[32m0.09157[0m[0m | time: 24.275s
[2K
| RMSProp | epoch: 027 | loss: 0.09157 - acc: 0.9706 -- iter: 0864/1133
[A[ATraining Step: 964  | total loss: [1m[32m0.08859[0m[0m | time: 25.140s
[2K
| RMSProp | epoch: 027 | loss: 0.08859 - acc: 0.9704 -- iter: 0896/1133
[A[ATraining Step: 965  | total loss: [1m[32m0.08088[0m[0m | time: 26.056s
[2K
| RMSProp | epoch: 027 | loss: 0.08088 - acc: 0.9734 -- iter: 0928/1133
[A[ATraining Step: 966  | total loss: [1m[32m0.07478[0m[0m | time: 27.296s
[2K
| RMSProp | epoch: 027 | loss: 0.07478 - acc: 0.9760 -- iter: 0960/1133
[A[ATraining Step: 967  | total loss: [1m[32m0.13740[0m[0m | time: 28.386s
[2K
| RMSProp | epoch: 027 | loss: 0.13740 - acc: 0.9690 -- iter: 0992/1133
[A[ATraining Step: 968  | total loss: [1m[32m0.13072[0m[0m | time: 29.165s
[2K
| RMSProp | epoch: 027 | loss: 0.13072 - acc: 0.9721 -- iter: 1024/1133
[A[ATraining Step: 969  | total loss: [1m[32m0.12132[0m[0m | time: 30.067s
[2K
| RMSProp | epoch: 027 | loss: 0.12132 - acc: 0.9749 -- iter: 1056/1133
[A[ATraining Step: 970  | total loss: [1m[32m0.11117[0m[0m | time: 31.019s
[2K
| RMSProp | epoch: 027 | loss: 0.11117 - acc: 0.9774 -- iter: 1088/1133
[A[ATraining Step: 971  | total loss: [1m[32m0.10104[0m[0m | time: 31.920s
[2K
| RMSProp | epoch: 027 | loss: 0.10104 - acc: 0.9797 -- iter: 1120/1133
[A[ATraining Step: 972  | total loss: [1m[32m0.09208[0m[0m | time: 34.613s
[2K
| RMSProp | epoch: 027 | loss: 0.09208 - acc: 0.9817 | val_loss: 0.50235 - val_acc: 0.8563 -- iter: 1133/1133
--
Training Step: 973  | total loss: [1m[32m0.08369[0m[0m | time: 1.011s
[2K
| RMSProp | epoch: 028 | loss: 0.08369 - acc: 0.9835 -- iter: 0032/1133
[A[ATraining Step: 974  | total loss: [1m[32m0.08112[0m[0m | time: 1.900s
[2K
| RMSProp | epoch: 028 | loss: 0.08112 - acc: 0.9821 -- iter: 0064/1133
[A[ATraining Step: 975  | total loss: [1m[32m0.07981[0m[0m | time: 2.842s
[2K
| RMSProp | epoch: 028 | loss: 0.07981 - acc: 0.9807 -- iter: 0096/1133
[A[ATraining Step: 976  | total loss: [1m[32m0.09028[0m[0m | time: 3.969s
[2K
| RMSProp | epoch: 028 | loss: 0.09028 - acc: 0.9795 -- iter: 0128/1133
[A[ATraining Step: 977  | total loss: [1m[32m0.08272[0m[0m | time: 5.046s
[2K
| RMSProp | epoch: 028 | loss: 0.08272 - acc: 0.9816 -- iter: 0160/1133
[A[ATraining Step: 978  | total loss: [1m[32m0.07668[0m[0m | time: 5.793s
[2K
| RMSProp | epoch: 028 | loss: 0.07668 - acc: 0.9834 -- iter: 0192/1133
[A[ATraining Step: 979  | total loss: [1m[32m0.07047[0m[0m | time: 6.673s
[2K
| RMSProp | epoch: 028 | loss: 0.07047 - acc: 0.9851 -- iter: 0224/1133
[A[ATraining Step: 980  | total loss: [1m[32m0.06743[0m[0m | time: 7.597s
[2K
| RMSProp | epoch: 028 | loss: 0.06743 - acc: 0.9834 -- iter: 0256/1133
[A[ATraining Step: 981  | total loss: [1m[32m0.06169[0m[0m | time: 8.582s
[2K
| RMSProp | epoch: 028 | loss: 0.06169 - acc: 0.9851 -- iter: 0288/1133
[A[ATraining Step: 982  | total loss: [1m[32m0.05671[0m[0m | time: 9.460s
[2K
| RMSProp | epoch: 028 | loss: 0.05671 - acc: 0.9866 -- iter: 0320/1133
[A[ATraining Step: 983  | total loss: [1m[32m0.07441[0m[0m | time: 10.350s
[2K
| RMSProp | epoch: 028 | loss: 0.07441 - acc: 0.9848 -- iter: 0352/1133
[A[ATraining Step: 984  | total loss: [1m[32m0.06750[0m[0m | time: 11.333s
[2K
| RMSProp | epoch: 028 | loss: 0.06750 - acc: 0.9863 -- iter: 0384/1133
[A[ATraining Step: 985  | total loss: [1m[32m0.08047[0m[0m | time: 12.277s
[2K
| RMSProp | epoch: 028 | loss: 0.08047 - acc: 0.9846 -- iter: 0416/1133
[A[ATraining Step: 986  | total loss: [1m[32m0.07395[0m[0m | time: 13.154s
[2K
| RMSProp | epoch: 028 | loss: 0.07395 - acc: 0.9861 -- iter: 0448/1133
[A[ATraining Step: 987  | total loss: [1m[32m0.07635[0m[0m | time: 14.085s
[2K
| RMSProp | epoch: 028 | loss: 0.07635 - acc: 0.9844 -- iter: 0480/1133
[A[ATraining Step: 988  | total loss: [1m[32m0.08261[0m[0m | time: 15.203s
[2K
| RMSProp | epoch: 028 | loss: 0.08261 - acc: 0.9797 -- iter: 0512/1133
[A[ATraining Step: 989  | total loss: [1m[32m0.07708[0m[0m | time: 16.265s
[2K
| RMSProp | epoch: 028 | loss: 0.07708 - acc: 0.9817 -- iter: 0544/1133
[A[ATraining Step: 990  | total loss: [1m[32m0.07255[0m[0m | time: 17.065s
[2K
| RMSProp | epoch: 028 | loss: 0.07255 - acc: 0.9835 -- iter: 0576/1133
[A[ATraining Step: 991  | total loss: [1m[32m0.07088[0m[0m | time: 17.970s
[2K
| RMSProp | epoch: 028 | loss: 0.07088 - acc: 0.9821 -- iter: 0608/1133
[A[ATraining Step: 992  | total loss: [1m[32m0.08564[0m[0m | time: 18.968s
[2K
| RMSProp | epoch: 028 | loss: 0.08564 - acc: 0.9745 -- iter: 0640/1133
[A[ATraining Step: 993  | total loss: [1m[32m0.08685[0m[0m | time: 19.896s
[2K
| RMSProp | epoch: 028 | loss: 0.08685 - acc: 0.9708 -- iter: 0672/1133
[A[ATraining Step: 994  | total loss: [1m[32m0.08080[0m[0m | time: 20.855s
[2K
| RMSProp | epoch: 028 | loss: 0.08080 - acc: 0.9737 -- iter: 0704/1133
[A[ATraining Step: 995  | total loss: [1m[32m0.09838[0m[0m | time: 21.767s
[2K
| RMSProp | epoch: 028 | loss: 0.09838 - acc: 0.9670 -- iter: 0736/1133
[A[ATraining Step: 996  | total loss: [1m[32m0.09140[0m[0m | time: 22.721s
[2K
| RMSProp | epoch: 028 | loss: 0.09140 - acc: 0.9703 -- iter: 0768/1133
[A[ATraining Step: 997  | total loss: [1m[32m0.08390[0m[0m | time: 23.636s
[2K
| RMSProp | epoch: 028 | loss: 0.08390 - acc: 0.9732 -- iter: 0800/1133
[A[ATraining Step: 998  | total loss: [1m[32m0.07619[0m[0m | time: 24.042s
[2K
| RMSProp | epoch: 028 | loss: 0.07619 - acc: 0.9759 -- iter: 0832/1133
[A[ATraining Step: 999  | total loss: [1m[32m0.07308[0m[0m | time: 24.415s
[2K
| RMSProp | epoch: 028 | loss: 0.07308 - acc: 0.9783 -- iter: 0864/1133
[A[ATraining Step: 1000  | total loss: [1m[32m0.07099[0m[0m | time: 27.474s
[2K
| RMSProp | epoch: 028 | loss: 0.07099 - acc: 0.9805 | val_loss: 0.67660 - val_acc: 0.8366 -- iter: 0896/1133
--
Training Step: 1001  | total loss: [1m[32m0.06529[0m[0m | time: 28.364s
[2K
| RMSProp | epoch: 028 | loss: 0.06529 - acc: 0.9824 -- iter: 0928/1133
[A[ATraining Step: 1002  | total loss: [1m[32m0.07748[0m[0m | time: 29.165s
[2K
| RMSProp | epoch: 028 | loss: 0.07748 - acc: 0.9811 -- iter: 0960/1133
[A[ATraining Step: 1003  | total loss: [1m[32m0.07111[0m[0m | time: 30.079s
[2K
| RMSProp | epoch: 028 | loss: 0.07111 - acc: 0.9830 -- iter: 0992/1133
[A[ATraining Step: 1004  | total loss: [1m[32m0.11849[0m[0m | time: 30.985s
[2K
| RMSProp | epoch: 028 | loss: 0.11849 - acc: 0.9753 -- iter: 1024/1133
[A[ATraining Step: 1005  | total loss: [1m[32m0.11141[0m[0m | time: 31.909s
[2K
| RMSProp | epoch: 028 | loss: 0.11141 - acc: 0.9778 -- iter: 1056/1133
[A[ATraining Step: 1006  | total loss: [1m[32m0.10554[0m[0m | time: 32.795s
[2K
| RMSProp | epoch: 028 | loss: 0.10554 - acc: 0.9769 -- iter: 1088/1133
[A[ATraining Step: 1007  | total loss: [1m[32m0.09767[0m[0m | time: 33.726s
[2K
| RMSProp | epoch: 028 | loss: 0.09767 - acc: 0.9792 -- iter: 1120/1133
[A[ATraining Step: 1008  | total loss: [1m[32m0.09492[0m[0m | time: 36.553s
[2K
| RMSProp | epoch: 028 | loss: 0.09492 - acc: 0.9781 | val_loss: 0.58019 - val_acc: 0.8197 -- iter: 1133/1133
--
Training Step: 1009  | total loss: [1m[32m0.08673[0m[0m | time: 0.959s
[2K
| RMSProp | epoch: 029 | loss: 0.08673 - acc: 0.9803 -- iter: 0032/1133
[A[ATraining Step: 1010  | total loss: [1m[32m0.08050[0m[0m | time: 2.138s
[2K
| RMSProp | epoch: 029 | loss: 0.08050 - acc: 0.9823 -- iter: 0064/1133
[A[ATraining Step: 1011  | total loss: [1m[32m0.07329[0m[0m | time: 3.289s
[2K
| RMSProp | epoch: 029 | loss: 0.07329 - acc: 0.9841 -- iter: 0096/1133
[A[ATraining Step: 1012  | total loss: [1m[32m0.06978[0m[0m | time: 4.082s
[2K
| RMSProp | epoch: 029 | loss: 0.06978 - acc: 0.9857 -- iter: 0128/1133
[A[ATraining Step: 1013  | total loss: [1m[32m0.06615[0m[0m | time: 4.992s
[2K
| RMSProp | epoch: 029 | loss: 0.06615 - acc: 0.9871 -- iter: 0160/1133
[A[ATraining Step: 1014  | total loss: [1m[32m0.06009[0m[0m | time: 5.861s
[2K
| RMSProp | epoch: 029 | loss: 0.06009 - acc: 0.9884 -- iter: 0192/1133
[A[ATraining Step: 1015  | total loss: [1m[32m0.05482[0m[0m | time: 6.761s
[2K
| RMSProp | epoch: 029 | loss: 0.05482 - acc: 0.9895 -- iter: 0224/1133
[A[ATraining Step: 1016  | total loss: [1m[32m0.04990[0m[0m | time: 7.655s
[2K
| RMSProp | epoch: 029 | loss: 0.04990 - acc: 0.9906 -- iter: 0256/1133
[A[ATraining Step: 1017  | total loss: [1m[32m0.04587[0m[0m | time: 8.626s
[2K
| RMSProp | epoch: 029 | loss: 0.04587 - acc: 0.9915 -- iter: 0288/1133
[A[ATraining Step: 1018  | total loss: [1m[32m0.04136[0m[0m | time: 9.549s
[2K
| RMSProp | epoch: 029 | loss: 0.04136 - acc: 0.9924 -- iter: 0320/1133
[A[ATraining Step: 1019  | total loss: [1m[32m0.03733[0m[0m | time: 10.518s
[2K
| RMSProp | epoch: 029 | loss: 0.03733 - acc: 0.9931 -- iter: 0352/1133
[A[ATraining Step: 1020  | total loss: [1m[32m0.04833[0m[0m | time: 11.419s
[2K
| RMSProp | epoch: 029 | loss: 0.04833 - acc: 0.9907 -- iter: 0384/1133
[A[ATraining Step: 1021  | total loss: [1m[32m0.04853[0m[0m | time: 12.311s
[2K
| RMSProp | epoch: 029 | loss: 0.04853 - acc: 0.9885 -- iter: 0416/1133
[A[ATraining Step: 1022  | total loss: [1m[32m0.05950[0m[0m | time: 13.466s
[2K
| RMSProp | epoch: 029 | loss: 0.05950 - acc: 0.9834 -- iter: 0448/1133
[A[ATraining Step: 1023  | total loss: [1m[32m0.05484[0m[0m | time: 14.606s
[2K
| RMSProp | epoch: 029 | loss: 0.05484 - acc: 0.9851 -- iter: 0480/1133
[A[ATraining Step: 1024  | total loss: [1m[32m0.05113[0m[0m | time: 16.308s
[2K
| RMSProp | epoch: 029 | loss: 0.05113 - acc: 0.9866 -- iter: 0512/1133
[A[ATraining Step: 1025  | total loss: [1m[32m0.05043[0m[0m | time: 17.661s
[2K
| RMSProp | epoch: 029 | loss: 0.05043 - acc: 0.9848 -- iter: 0544/1133
[A[ATraining Step: 1026  | total loss: [1m[32m0.06831[0m[0m | time: 21.550s
[2K
| RMSProp | epoch: 029 | loss: 0.06831 - acc: 0.9800 -- iter: 0576/1133
[A[ATraining Step: 1027  | total loss: [1m[32m0.07479[0m[0m | time: 27.934s
[2K
| RMSProp | epoch: 029 | loss: 0.07479 - acc: 0.9758 -- iter: 0608/1133
[A[ATraining Step: 1028  | total loss: [1m[32m0.08016[0m[0m | time: 30.118s
[2K
| RMSProp | epoch: 029 | loss: 0.08016 - acc: 0.9720 -- iter: 0640/1133
[A[ATraining Step: 1029  | total loss: [1m[32m0.07580[0m[0m | time: 44.146s
[2K
| RMSProp | epoch: 029 | loss: 0.07580 - acc: 0.9748 -- iter: 0672/1133
[A[ATraining Step: 1030  | total loss: [1m[32m0.07724[0m[0m | time: 55.799s
[2K
| RMSProp | epoch: 029 | loss: 0.07724 - acc: 0.9710 -- iter: 0704/1133
[A[ATraining Step: 1031  | total loss: [1m[32m0.07109[0m[0m | time: 63.535s
[2K
| RMSProp | epoch: 029 | loss: 0.07109 - acc: 0.9739 -- iter: 0736/1133
[A[ATraining Step: 1032  | total loss: [1m[32m0.07350[0m[0m | time: 74.379s
[2K
| RMSProp | epoch: 029 | loss: 0.07350 - acc: 0.9734 -- iter: 0768/1133
[A[ATraining Step: 1033  | total loss: [1m[32m0.07322[0m[0m | time: 79.575s
[2K
| RMSProp | epoch: 029 | loss: 0.07322 - acc: 0.9730 -- iter: 0800/1133
[A[ATraining Step: 1034  | total loss: [1m[32m0.06718[0m[0m | time: 82.423s
[2K
| RMSProp | epoch: 029 | loss: 0.06718 - acc: 0.9757 -- iter: 0832/1133
[A[ATraining Step: 1035  | total loss: [1m[32m0.06841[0m[0m | time: 82.932s
[2K
| RMSProp | epoch: 029 | loss: 0.06841 - acc: 0.9750 -- iter: 0864/1133
[A[ATraining Step: 1036  | total loss: [1m[32m0.06391[0m[0m | time: 83.390s
[2K
| RMSProp | epoch: 029 | loss: 0.06391 - acc: 0.9775 -- iter: 0896/1133
[A[ATraining Step: 1037  | total loss: [1m[32m0.05858[0m[0m | time: 84.534s
[2K
| RMSProp | epoch: 029 | loss: 0.05858 - acc: 0.9797 -- iter: 0928/1133
[A[ATraining Step: 1038  | total loss: [1m[32m0.05475[0m[0m | time: 85.880s
[2K
| RMSProp | epoch: 029 | loss: 0.05475 - acc: 0.9818 -- iter: 0960/1133
[A[ATraining Step: 1039  | total loss: [1m[32m0.05048[0m[0m | time: 87.278s
[2K
| RMSProp | epoch: 029 | loss: 0.05048 - acc: 0.9836 -- iter: 0992/1133
[A[ATraining Step: 1040  | total loss: [1m[32m0.06939[0m[0m | time: 88.688s
[2K
| RMSProp | epoch: 029 | loss: 0.06939 - acc: 0.9790 -- iter: 1024/1133
[A[ATraining Step: 1041  | total loss: [1m[32m0.13770[0m[0m | time: 90.401s
[2K
| RMSProp | epoch: 029 | loss: 0.13770 - acc: 0.9686 -- iter: 1056/1133
[A[ATraining Step: 1042  | total loss: [1m[32m0.12986[0m[0m | time: 91.767s
[2K
| RMSProp | epoch: 029 | loss: 0.12986 - acc: 0.9717 -- iter: 1088/1133
[A[ATraining Step: 1043  | total loss: [1m[32m0.12204[0m[0m | time: 92.890s
[2K
| RMSProp | epoch: 029 | loss: 0.12204 - acc: 0.9745 -- iter: 1120/1133
[A[ATraining Step: 1044  | total loss: [1m[32m0.11395[0m[0m | time: 96.664s
[2K
| RMSProp | epoch: 029 | loss: 0.11395 - acc: 0.9740 | val_loss: 0.58490 - val_acc: 0.8310 -- iter: 1133/1133
--
Training Step: 1045  | total loss: [1m[32m0.10768[0m[0m | time: 1.244s
[2K
| RMSProp | epoch: 030 | loss: 0.10768 - acc: 0.9734 -- iter: 0032/1133
[A[ATraining Step: 1046  | total loss: [1m[32m0.09865[0m[0m | time: 8.121s
[2K
| RMSProp | epoch: 030 | loss: 0.09865 - acc: 0.9761 -- iter: 0064/1133
[A[ATraining Step: 1047  | total loss: [1m[32m0.08983[0m[0m | time: 19.008s
[2K
| RMSProp | epoch: 030 | loss: 0.08983 - acc: 0.9785 -- iter: 0096/1133
[A[ATraining Step: 1048  | total loss: [1m[32m0.09452[0m[0m | time: 30.100s
[2K
| RMSProp | epoch: 030 | loss: 0.09452 - acc: 0.9775 -- iter: 0128/1133
[A[ATraining Step: 1049  | total loss: [1m[32m0.08607[0m[0m | time: 34.893s
[2K
| RMSProp | epoch: 030 | loss: 0.08607 - acc: 0.9798 -- iter: 0160/1133
[A[ATraining Step: 1050  | total loss: [1m[32m0.07818[0m[0m | time: 36.055s
[2K
| RMSProp | epoch: 030 | loss: 0.07818 - acc: 0.9818 -- iter: 0192/1133
[A[ATraining Step: 1051  | total loss: [1m[32m0.07080[0m[0m | time: 37.423s
[2K
| RMSProp | epoch: 030 | loss: 0.07080 - acc: 0.9836 -- iter: 0224/1133
[A[ATraining Step: 1052  | total loss: [1m[32m0.06427[0m[0m | time: 38.642s
[2K
| RMSProp | epoch: 030 | loss: 0.06427 - acc: 0.9852 -- iter: 0256/1133
[A[ATraining Step: 1053  | total loss: [1m[32m0.06228[0m[0m | time: 39.952s
[2K
| RMSProp | epoch: 030 | loss: 0.06228 - acc: 0.9836 -- iter: 0288/1133
[A[ATraining Step: 1054  | total loss: [1m[32m0.06652[0m[0m | time: 41.287s
[2K
| RMSProp | epoch: 030 | loss: 0.06652 - acc: 0.9821 -- iter: 0320/1133
[A[ATraining Step: 1055  | total loss: [1m[32m0.06770[0m[0m | time: 42.832s
[2K
| RMSProp | epoch: 030 | loss: 0.06770 - acc: 0.9808 -- iter: 0352/1133
[A[ATraining Step: 1056  | total loss: [1m[32m0.06209[0m[0m | time: 44.351s
[2K
| RMSProp | epoch: 030 | loss: 0.06209 - acc: 0.9827 -- iter: 0384/1133
[A[ATraining Step: 1057  | total loss: [1m[32m0.05696[0m[0m | time: 45.674s
[2K
| RMSProp | epoch: 030 | loss: 0.05696 - acc: 0.9844 -- iter: 0416/1133
[A[ATraining Step: 1058  | total loss: [1m[32m0.06587[0m[0m | time: 47.209s
[2K
| RMSProp | epoch: 030 | loss: 0.06587 - acc: 0.9797 -- iter: 0448/1133
[A[ATraining Step: 1059  | total loss: [1m[32m0.11162[0m[0m | time: 48.805s
[2K
| RMSProp | epoch: 030 | loss: 0.11162 - acc: 0.9661 -- iter: 0480/1133
[A[ATraining Step: 1060  | total loss: [1m[32m0.11105[0m[0m | time: 50.165s
[2K
| RMSProp | epoch: 030 | loss: 0.11105 - acc: 0.9633 -- iter: 0512/1133
[A[ATraining Step: 1061  | total loss: [1m[32m0.10634[0m[0m | time: 54.689s
[2K
| RMSProp | epoch: 030 | loss: 0.10634 - acc: 0.9638 -- iter: 0544/1133
[A[ATraining Step: 1062  | total loss: [1m[32m0.11719[0m[0m | time: 61.055s
[2K
| RMSProp | epoch: 030 | loss: 0.11719 - acc: 0.9612 -- iter: 0576/1133
[A[ATraining Step: 1063  | total loss: [1m[32m0.10870[0m[0m | time: 66.915s
[2K
| RMSProp | epoch: 030 | loss: 0.10870 - acc: 0.9651 -- iter: 0608/1133
[A[ATraining Step: 1064  | total loss: [1m[32m0.09893[0m[0m | time: 75.905s
[2K
| RMSProp | epoch: 030 | loss: 0.09893 - acc: 0.9686 -- iter: 0640/1133
[A[ATraining Step: 1065  | total loss: [1m[32m0.09178[0m[0m | time: 79.599s
[2K
| RMSProp | epoch: 030 | loss: 0.09178 - acc: 0.9717 -- iter: 0672/1133
[A[ATraining Step: 1066  | total loss: [1m[32m0.08312[0m[0m | time: 83.053s
[2K
| RMSProp | epoch: 030 | loss: 0.08312 - acc: 0.9745 -- iter: 0704/1133
[A[ATraining Step: 1067  | total loss: [1m[32m0.07560[0m[0m | time: 91.934s
[2K
| RMSProp | epoch: 030 | loss: 0.07560 - acc: 0.9771 -- iter: 0736/1133
[A[ATraining Step: 1068  | total loss: [1m[32m0.06972[0m[0m | time: 98.197s
[2K
| RMSProp | epoch: 030 | loss: 0.06972 - acc: 0.9794 -- iter: 0768/1133
[A[ATraining Step: 1069  | total loss: [1m[32m0.06304[0m[0m | time: 101.116s
[2K
| RMSProp | epoch: 030 | loss: 0.06304 - acc: 0.9814 -- iter: 0800/1133
[A[ATraining Step: 1070  | total loss: [1m[32m0.05708[0m[0m | time: 102.175s
[2K
| RMSProp | epoch: 030 | loss: 0.05708 - acc: 0.9833 -- iter: 0832/1133
[A[ATraining Step: 1071  | total loss: [1m[32m0.05226[0m[0m | time: 103.512s
[2K
| RMSProp | epoch: 030 | loss: 0.05226 - acc: 0.9850 -- iter: 0864/1133
[A[ATraining Step: 1072  | total loss: [1m[32m0.04723[0m[0m | time: 104.151s
[2K
| RMSProp | epoch: 030 | loss: 0.04723 - acc: 0.9865 -- iter: 0896/1133
[A[ATraining Step: 1073  | total loss: [1m[32m0.04276[0m[0m | time: 104.803s
[2K
| RMSProp | epoch: 030 | loss: 0.04276 - acc: 0.9878 -- iter: 0928/1133
[A[ATraining Step: 1074  | total loss: [1m[32m0.03854[0m[0m | time: 106.198s
[2K
| RMSProp | epoch: 030 | loss: 0.03854 - acc: 0.9890 -- iter: 0960/1133
[A[ATraining Step: 1075  | total loss: [1m[32m0.03484[0m[0m | time: 107.752s
[2K
| RMSProp | epoch: 030 | loss: 0.03484 - acc: 0.9901 -- iter: 0992/1133
[A[ATraining Step: 1076  | total loss: [1m[32m0.03144[0m[0m | time: 109.205s
[2K
| RMSProp | epoch: 030 | loss: 0.03144 - acc: 0.9911 -- iter: 1024/1133
[A[ATraining Step: 1077  | total loss: [1m[32m0.03013[0m[0m | time: 110.436s
[2K
| RMSProp | epoch: 030 | loss: 0.03013 - acc: 0.9920 -- iter: 1056/1133
[A[ATraining Step: 1078  | total loss: [1m[32m0.24163[0m[0m | time: 111.679s
[2K
| RMSProp | epoch: 030 | loss: 0.24163 - acc: 0.9616 -- iter: 1088/1133
[A[ATraining Step: 1079  | total loss: [1m[32m0.22487[0m[0m | time: 113.210s
[2K
| RMSProp | epoch: 030 | loss: 0.22487 - acc: 0.9623 -- iter: 1120/1133
[A[ATraining Step: 1080  | total loss: [1m[32m0.20478[0m[0m | time: 196.087s
[2K
| RMSProp | epoch: 030 | loss: 0.20478 - acc: 0.9660 | val_loss: 0.65182 - val_acc: 0.8225 -- iter: 1133/1133
--
Validation AUC:0.8897035485304386
Validation AUPRC:0.9080254957756688
Test AUC:0.919450276770376
Test AUPRC:0.9225389113504002
BestTestF1Score	0.85	0.66	0.83	0.81	0.89	165	39	130	21	0.68
BestTestMCCScore	0.85	0.66	0.83	0.81	0.89	165	39	130	21	0.68
BestTestAccuracyScore	0.85	0.66	0.83	0.81	0.89	165	39	130	21	0.68
BestValidationF1Score	0.83	0.66	0.83	0.82	0.85	151	33	144	27	0.68
BestValidationMCC	0.83	0.66	0.83	0.82	0.85	151	33	144	27	0.68
BestValidationAccuracy	0.83	0.66	0.83	0.82	0.85	151	33	144	27	0.68
TestPredictions (Threshold:0.68)
CHEMBL1940403,TP,ACT,1.0	CHEMBL404956,TP,ACT,0.9700000286102295	CHEMBL79249,TP,ACT,1.0	CHEMBL444353,TP,ACT,0.9900000095367432	CHEMBL130331,FP,INACT,0.9399999976158142	CHEMBL15499,FP,INACT,0.9399999976158142	CHEMBL3321789,TP,ACT,1.0	CHEMBL1669409,TP,ACT,0.9900000095367432	CHEMBL549598,TP,ACT,1.0	CHEMBL321644,TN,INACT,0.07999999821186066	CHEMBL2158789,TP,ACT,0.9900000095367432	CHEMBL151668,FP,INACT,0.800000011920929	CHEMBL343324,FN,ACT,0.1599999964237213	CHEMBL44134,TN,INACT,0.009999999776482582	CHEMBL86782,FP,INACT,0.9900000095367432	CHEMBL572034,TP,ACT,1.0	CHEMBL465170,TP,ACT,0.9399999976158142	CHEMBL105483,TP,ACT,0.9900000095367432	CHEMBL2208417,TP,ACT,0.9200000166893005	CHEMBL595022,TN,INACT,0.09000000357627869	CHEMBL3350741,TN,INACT,0.0	CHEMBL174649,FP,INACT,0.6899999976158142	CHEMBL3739820,FP,INACT,0.9900000095367432	CHEMBL278129,TN,INACT,0.0	CHEMBL393718,TP,ACT,0.9700000286102295	CHEMBL2093082,TN,INACT,0.009999999776482582	CHEMBL1000,TP,ACT,1.0	CHEMBL305338,TP,ACT,0.9800000190734863	CHEMBL227378,TN,INACT,0.0	CHEMBL2171029,TP,ACT,0.9900000095367432	CHEMBL451,FN,ACT,0.23000000417232513	CHEMBL389734,TN,INACT,0.0	CHEMBL1092126,TP,ACT,0.949999988079071	CHEMBL2324200,TN,INACT,0.009999999776482582	CHEMBL3238446,FP,INACT,0.9800000190734863	CHEMBL602269,FP,INACT,0.9200000166893005	CHEMBL452955,TN,INACT,0.019999999552965164	CHEMBL560120,TP,ACT,1.0	CHEMBL395110,TP,ACT,1.0	CHEMBL292911,TN,INACT,0.0	CHEMBL3357024,TP,ACT,0.9900000095367432	CHEMBL357077,TN,INACT,0.0	CHEMBL558933,TP,ACT,1.0	CHEMBL1090527,TP,ACT,0.9900000095367432	CHEMBL326263,FN,ACT,0.20999999344348907	CHEMBL450729,TN,INACT,0.0	CHEMBL1098607,TN,INACT,0.0	CHEMBL505,TP,ACT,1.0	CHEMBL23529,FP,INACT,0.949999988079071	CHEMBL1091069,FN,ACT,0.4300000071525574	CHEMBL657,TP,ACT,1.0	CHEMBL344568,TN,INACT,0.0	CHEMBL1090176,TP,ACT,0.9800000190734863	CHEMBL508011,FP,INACT,1.0	CHEMBL26904,TN,INACT,0.1599999964237213	CHEMBL450463,TN,INACT,0.009999999776482582	CHEMBL1092767,TP,ACT,0.949999988079071	CHEMBL32688,FP,INACT,0.9900000095367432	CHEMBL110695,TN,INACT,0.009999999776482582	CHEMBL1091776,FN,ACT,0.0	CHEMBL1774505,TP,ACT,1.0	CHEMBL181085,TP,ACT,1.0	CHEMBL60559,FN,ACT,0.05000000074505806	CHEMBL2426689,FP,INACT,0.9800000190734863	CHEMBL32590,TN,INACT,0.0	CHEMBL1940402,TP,ACT,1.0	CHEMBL64249,TP,ACT,1.0	CHEMBL1774494,TP,ACT,0.9800000190734863	CHEMBL62601,FP,INACT,0.7200000286102295	CHEMBL102452,TP,ACT,1.0	CHEMBL327651,TP,ACT,1.0	CHEMBL338310,TN,INACT,0.009999999776482582	CHEMBL351550,TN,INACT,0.10999999940395355	CHEMBL1910381,TP,ACT,0.9800000190734863	CHEMBL594801,TN,INACT,0.009999999776482582	CHEMBL89688,TN,INACT,0.009999999776482582	CHEMBL534,TP,ACT,0.9900000095367432	CHEMBL40966,TN,INACT,0.019999999552965164	CHEMBL141048,FP,INACT,0.949999988079071	CHEMBL475621,TP,ACT,0.949999988079071	CHEMBL11671,TN,INACT,0.019999999552965164	CHEMBL3754008,FN,ACT,0.5400000214576721	CHEMBL561489,TP,ACT,1.0	CHEMBL307609,TP,ACT,0.9900000095367432	CHEMBL2207658,TP,ACT,0.9800000190734863	CHEMBL1096429,TP,ACT,1.0	CHEMBL321709,TP,ACT,1.0	CHEMBL9746,TN,INACT,0.0	CHEMBL1909072,TP,ACT,0.9900000095367432	CHEMBL1923523,FN,ACT,0.009999999776482582	CHEMBL130005,FP,INACT,0.9100000262260437	CHEMBL2207281,TP,ACT,0.9700000286102295	CHEMBL25649,TN,INACT,0.009999999776482582	CHEMBL3818994,TP,ACT,1.0	CHEMBL559061,TP,ACT,1.0	CHEMBL1078240,TP,ACT,0.9900000095367432	CHEMBL80532,TN,INACT,0.4000000059604645	CHEMBL621,TP,ACT,0.8799999952316284	CHEMBL2158819,TP,ACT,1.0	CHEMBL1923521,TP,ACT,1.0	CHEMBL173629,TN,INACT,0.009999999776482582	CHEMBL311781,TN,INACT,0.05000000074505806	CHEMBL2429890,TP,ACT,1.0	CHEMBL62527,TP,ACT,0.9100000262260437	CHEMBL62115,TP,ACT,1.0	CHEMBL194837,TP,ACT,0.9900000095367432	CHEMBL476108,TP,ACT,1.0	CHEMBL83073,FN,ACT,0.05000000074505806	CHEMBL86224,TN,INACT,0.019999999552965164	CHEMBL716,TP,ACT,1.0	CHEMBL1202152,FP,INACT,0.8399999737739563	CHEMBL461502,TN,INACT,0.0	CHEMBL328356,TP,ACT,1.0	CHEMBL112314,TN,INACT,0.0	CHEMBL69904,TN,INACT,0.019999999552965164	CHEMBL2205836,FN,ACT,0.5	CHEMBL345185,TP,ACT,0.9900000095367432	CHEMBL105594,TP,ACT,0.9700000286102295	CHEMBL236610,FN,ACT,0.0	CHEMBL303538,FP,INACT,0.7099999785423279	CHEMBL1765671,TN,INACT,0.009999999776482582	CHEMBL476839,TP,ACT,0.9900000095367432	CHEMBL325258,TP,ACT,0.9599999785423279	CHEMBL44463,TN,INACT,0.0	CHEMBL10602,TP,ACT,0.9900000095367432	CHEMBL1946125,TP,ACT,1.0	CHEMBL64775,TP,ACT,1.0	CHEMBL140872,TP,ACT,1.0	CHEMBL187637,TP,ACT,1.0	CHEMBL384248,TN,INACT,0.0	CHEMBL2031884,TP,ACT,0.9800000190734863	CHEMBL45087,TN,INACT,0.0	CHEMBL74122,TN,INACT,0.05000000074505806	CHEMBL343242,TN,INACT,0.0	CHEMBL1774507,TP,ACT,1.0	CHEMBL195437,FP,INACT,1.0	CHEMBL151619,TN,INACT,0.009999999776482582	CHEMBL563451,TP,ACT,1.0	CHEMBL264418,FN,ACT,0.6299999952316284	CHEMBL2158784,TP,ACT,1.0	CHEMBL1092377,TP,ACT,0.9700000286102295	CHEMBL79915,TN,INACT,0.0	CHEMBL3752978,TP,ACT,0.9900000095367432	CHEMBL568400,TP,ACT,1.0	CHEMBL229616,TN,INACT,0.0	CHEMBL1559151,TN,INACT,0.0	CHEMBL608985,TN,INACT,0.029999999329447746	CHEMBL251541,FP,INACT,0.9599999785423279	CHEMBL63114,TN,INACT,0.009999999776482582	CHEMBL610739,TP,ACT,1.0	CHEMBL275481,TN,INACT,0.3499999940395355	CHEMBL42219,TN,INACT,0.10000000149011612	CHEMBL541424,TN,INACT,0.0	CHEMBL296245,TN,INACT,0.10999999940395355	CHEMBL1092813,TP,ACT,0.9399999976158142	CHEMBL296927,TN,INACT,0.0	CHEMBL629,TP,ACT,1.0	CHEMBL2158782,TP,ACT,1.0	CHEMBL169553,FP,INACT,0.9800000190734863	CHEMBL1923534,TP,ACT,1.0	CHEMBL142822,TN,INACT,0.029999999329447746	CHEMBL84810,TP,ACT,0.9900000095367432	CHEMBL92333,TP,ACT,1.0	CHEMBL593864,TN,INACT,0.0	CHEMBL107574,TN,INACT,0.0	CHEMBL549599,TP,ACT,0.9900000095367432	CHEMBL2171047,TP,ACT,1.0	CHEMBL319231,TN,INACT,0.05999999865889549	CHEMBL1084132,TP,ACT,0.9599999785423279	CHEMBL110904,TN,INACT,0.0	CHEMBL267853,TN,INACT,0.0	CHEMBL21508,TN,INACT,0.009999999776482582	CHEMBL495409,TN,INACT,0.009999999776482582	CHEMBL48120,TN,INACT,0.10999999940395355	CHEMBL421531,TN,INACT,0.30000001192092896	CHEMBL571389,TP,ACT,1.0	CHEMBL1079686,TP,ACT,0.9900000095367432	CHEMBL109248,TN,INACT,0.0	CHEMBL21328,TN,INACT,0.009999999776482582	CHEMBL2376800,TN,INACT,0.0	CHEMBL80807,TN,INACT,0.23999999463558197	CHEMBL2158793,TP,ACT,0.9900000095367432	CHEMBL417215,TP,ACT,1.0	CHEMBL2171021,TP,ACT,1.0	CHEMBL1259071,FP,INACT,0.8500000238418579	CHEMBL513665,TN,INACT,0.009999999776482582	CHEMBL157217,TP,ACT,0.9900000095367432	CHEMBL284672,TN,INACT,0.029999999329447746	CHEMBL76385,TN,INACT,0.009999999776482582	CHEMBL37150,FP,INACT,1.0	CHEMBL1765668,TN,INACT,0.019999999552965164	CHEMBL119385,TN,INACT,0.25999999046325684	CHEMBL308243,TN,INACT,0.019999999552965164	CHEMBL92337,TP,ACT,1.0	CHEMBL155314,TP,ACT,0.9399999976158142	CHEMBL78669,TN,INACT,0.009999999776482582	CHEMBL197159,TN,INACT,0.0	CHEMBL291306,TN,INACT,0.029999999329447746	CHEMBL320763,TN,INACT,0.0	CHEMBL3752900,TP,ACT,1.0	CHEMBL275507,TP,ACT,1.0	CHEMBL19215,TP,ACT,0.8299999833106995	CHEMBL593494,TP,ACT,0.9900000095367432	CHEMBL62066,TP,ACT,0.9900000095367432	CHEMBL1910386,TP,ACT,1.0	CHEMBL560917,TP,ACT,1.0	CHEMBL490632,TP,ACT,0.9900000095367432	CHEMBL63421,TN,INACT,0.009999999776482582	CHEMBL107680,FP,INACT,0.9800000190734863	CHEMBL2158836,TP,ACT,1.0	CHEMBL550818,TP,ACT,1.0	CHEMBL322873,TP,ACT,1.0	CHEMBL133184,TN,INACT,0.0	CHEMBL648,TP,ACT,0.9900000095367432	CHEMBL167223,TP,ACT,1.0	CHEMBL45269,TN,INACT,0.019999999552965164	CHEMBL3357041,TP,ACT,1.0	CHEMBL310250,TN,INACT,0.009999999776482582	CHEMBL309397,TN,INACT,0.009999999776482582	CHEMBL515170,TN,INACT,0.0	CHEMBL101748,FN,ACT,0.14000000059604645	CHEMBL2171046,TP,ACT,1.0	CHEMBL102416,TP,ACT,1.0	CHEMBL309017,TN,INACT,0.11999999731779099	CHEMBL558339,TP,ACT,1.0	CHEMBL1125,FN,ACT,0.23000000417232513	CHEMBL3752195,FN,ACT,0.009999999776482582	CHEMBL1090526,TP,ACT,0.9900000095367432	CHEMBL113956,TP,ACT,1.0	CHEMBL241279,TN,INACT,0.44999998807907104	CHEMBL1076625,TN,INACT,0.0	CHEMBL578170,TP,ACT,0.9900000095367432	CHEMBL1092496,TP,ACT,0.9900000095367432	CHEMBL1346,FP,INACT,0.9399999976158142	CHEMBL292275,TP,ACT,0.949999988079071	CHEMBL101691,TP,ACT,0.6800000071525574	CHEMBL418386,TN,INACT,0.0	CHEMBL426317,TP,ACT,0.9900000095367432	CHEMBL545363,TN,INACT,0.09000000357627869	CHEMBL88506,TN,INACT,0.019999999552965164	CHEMBL2158834,TP,ACT,1.0	CHEMBL2322893,FP,INACT,0.9800000190734863	CHEMBL282255,FP,INACT,0.699999988079071	CHEMBL83874,TN,INACT,0.009999999776482582	CHEMBL2171034,TP,ACT,1.0	CHEMBL133257,TN,INACT,0.0	CHEMBL474448,FN,ACT,0.019999999552965164	CHEMBL1907840,TN,INACT,0.25	CHEMBL109467,FP,INACT,0.7200000286102295	CHEMBL39583,FP,INACT,1.0	CHEMBL2208426,TP,ACT,0.9700000286102295	CHEMBL2115123,TN,INACT,0.009999999776482582	CHEMBL64875,TP,ACT,1.0	CHEMBL1093058,TP,ACT,0.9900000095367432	CHEMBL16639,TN,INACT,0.0	CHEMBL900,TP,ACT,1.0	CHEMBL1669413,TP,ACT,1.0	CHEMBL85735,TP,ACT,1.0	CHEMBL73096,FP,INACT,0.9800000190734863	CHEMBL1088900,FN,ACT,0.3100000023841858	CHEMBL81878,TN,INACT,0.019999999552965164	CHEMBL1669411,TP,ACT,0.9900000095367432	CHEMBL2171026,TP,ACT,1.0	CHEMBL156071,TP,ACT,0.9700000286102295	CHEMBL602474,TN,INACT,0.10000000149011612	CHEMBL2312376,TN,INACT,0.009999999776482582	CHEMBL45875,TN,INACT,0.0	CHEMBL140620,TN,INACT,0.019999999552965164	CHEMBL110053,TN,INACT,0.0	CHEMBL728,TP,ACT,0.9800000190734863	CHEMBL1669412,TP,ACT,1.0	CHEMBL109593,TN,INACT,0.019999999552965164	CHEMBL42799,TN,INACT,0.0	CHEMBL10211,TN,INACT,0.05000000074505806	CHEMBL311455,TN,INACT,0.009999999776482582	CHEMBL138458,TP,ACT,1.0	CHEMBL1669425,TP,ACT,1.0	CHEMBL3818989,TP,ACT,1.0	CHEMBL48448,TN,INACT,0.0	CHEMBL85999,TN,INACT,0.009999999776482582	CHEMBL432144,TP,ACT,0.949999988079071	CHEMBL315308,FN,ACT,0.20999999344348907	CHEMBL3753784,TP,ACT,0.949999988079071	CHEMBL315044,FN,ACT,0.5	CHEMBL2113072,FP,INACT,0.9700000286102295	CHEMBL310183,TP,ACT,1.0	CHEMBL2208436,TP,ACT,0.9900000095367432	CHEMBL330674,TN,INACT,0.05000000074505806	CHEMBL104808,TP,ACT,1.0	CHEMBL1092259,TP,ACT,1.0	CHEMBL295001,TP,ACT,1.0	CHEMBL1946257,TP,ACT,1.0	CHEMBL106483,TP,ACT,0.9700000286102295	CHEMBL392888,FP,INACT,0.9100000262260437	CHEMBL565083,TP,ACT,0.9599999785423279	CHEMBL319000,TP,ACT,0.9900000095367432	CHEMBL74515,TN,INACT,0.0	CHEMBL60401,TN,INACT,0.029999999329447746	CHEMBL268190,TN,INACT,0.009999999776482582	CHEMBL83658,TP,ACT,1.0	CHEMBL2207641,FN,ACT,0.28999999165534973	CHEMBL59733,TN,INACT,0.03999999910593033	CHEMBL25622,TN,INACT,0.46000000834465027	CHEMBL571073,TP,ACT,0.6899999976158142	CHEMBL346230,TP,ACT,1.0	CHEMBL3238447,TP,ACT,0.949999988079071	CHEMBL316968,FP,INACT,0.7200000286102295	CHEMBL303204,TN,INACT,0.0	CHEMBL2158774,TP,ACT,1.0	CHEMBL182150,TP,ACT,0.9700000286102295	CHEMBL1092812,TP,ACT,0.9900000095367432	CHEMBL297473,TN,INACT,0.0	CHEMBL59517,TN,INACT,0.009999999776482582	CHEMBL294349,TN,INACT,0.6499999761581421	CHEMBL59798,TP,ACT,0.9200000166893005	CHEMBL1093044,FP,INACT,0.9399999976158142	CHEMBL2391352,TN,INACT,0.009999999776482582	CHEMBL553602,TN,INACT,0.029999999329447746	CHEMBL3799986,FP,INACT,0.9100000262260437	CHEMBL2207666,TP,ACT,1.0	CHEMBL549,TP,ACT,0.8899999856948853	CHEMBL3704833,FP,INACT,0.8500000238418579	CHEMBL280684,TN,INACT,0.0	CHEMBL62266,TP,ACT,1.0	CHEMBL570033,TP,ACT,1.0	CHEMBL166736,TN,INACT,0.07000000029802322	CHEMBL47404,TN,INACT,0.0	CHEMBL45456,TN,INACT,0.0	CHEMBL43788,TN,INACT,0.0	CHEMBL2031885,TP,ACT,0.9900000095367432	CHEMBL80317,TN,INACT,0.009999999776482582	CHEMBL3753334,TP,ACT,1.0	CHEMBL336081,TN,INACT,0.009999999776482582	CHEMBL78830,TN,INACT,0.019999999552965164	CHEMBL241329,TP,ACT,0.9900000095367432	CHEMBL2052004,TN,INACT,0.029999999329447746	CHEMBL2151155,TP,ACT,1.0	CHEMBL264761,TP,ACT,1.0	CHEMBL2158791,TP,ACT,0.9900000095367432	CHEMBL420108,FN,ACT,0.009999999776482582	CHEMBL2335158,TN,INACT,0.0	CHEMBL298612,TN,INACT,0.03999999910593033	CHEMBL1259189,TP,ACT,1.0	CHEMBL84135,FP,INACT,0.9100000262260437	CHEMBL259662,TN,INACT,0.12999999523162842	CHEMBL169675,FP,INACT,0.9399999976158142	CHEMBL60360,TP,ACT,0.8500000238418579	CHEMBL231825,TN,INACT,0.009999999776482582	CHEMBL53842,FP,INACT,0.949999988079071	CHEMBL495247,TN,INACT,0.009999999776482582	CHEMBL287987,FP,INACT,1.0	CHEMBL312082,TP,ACT,0.9900000095367432	CHEMBL17157,TP,ACT,1.0	CHEMBL194659,TP,ACT,1.0	CHEMBL303313,TP,ACT,1.0	

