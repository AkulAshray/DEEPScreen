CNNModel CHEMBL330 adam 0.001 15 128 0 0.6 False True
Number of active compounds :	543
Number of inactive compounds :	362
---------------------------------
Run id: CNNModel_CHEMBL330_adam_0.001_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL330_adam_0.001_15_128_0.6_True/
---------------------------------
Training samples: 569
Validation samples: 178
--
Training Step: 1  | time: 1.321s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/569
[A[ATraining Step: 2  | total loss: [1m[32m0.62466[0m[0m | time: 2.369s
[2K
| Adam | epoch: 001 | loss: 0.62466 - acc: 0.3375 -- iter: 064/569
[A[ATraining Step: 3  | total loss: [1m[32m0.67899[0m[0m | time: 3.436s
[2K
| Adam | epoch: 001 | loss: 0.67899 - acc: 0.5472 -- iter: 096/569
[A[ATraining Step: 4  | total loss: [1m[32m0.68624[0m[0m | time: 4.544s
[2K
| Adam | epoch: 001 | loss: 0.68624 - acc: 0.5587 -- iter: 128/569
[A[ATraining Step: 5  | total loss: [1m[32m0.65138[0m[0m | time: 5.781s
[2K
| Adam | epoch: 001 | loss: 0.65138 - acc: 0.6695 -- iter: 160/569
[A[ATraining Step: 6  | total loss: [1m[32m0.66379[0m[0m | time: 7.113s
[2K
| Adam | epoch: 001 | loss: 0.66379 - acc: 0.6409 -- iter: 192/569
[A[ATraining Step: 7  | total loss: [1m[32m0.62104[0m[0m | time: 8.190s
[2K
| Adam | epoch: 001 | loss: 0.62104 - acc: 0.6876 -- iter: 224/569
[A[ATraining Step: 8  | total loss: [1m[32m0.73565[0m[0m | time: 9.309s
[2K
| Adam | epoch: 001 | loss: 0.73565 - acc: 0.5645 -- iter: 256/569
[A[ATraining Step: 9  | total loss: [1m[32m0.74300[0m[0m | time: 10.660s
[2K
| Adam | epoch: 001 | loss: 0.74300 - acc: 0.5138 -- iter: 288/569
[A[ATraining Step: 10  | total loss: [1m[32m0.70580[0m[0m | time: 11.970s
[2K
| Adam | epoch: 001 | loss: 0.70580 - acc: 0.5694 -- iter: 320/569
[A[ATraining Step: 11  | total loss: [1m[32m0.69263[0m[0m | time: 13.006s
[2K
| Adam | epoch: 001 | loss: 0.69263 - acc: 0.5957 -- iter: 352/569
[A[ATraining Step: 12  | total loss: [1m[32m0.68517[0m[0m | time: 14.000s
[2K
| Adam | epoch: 001 | loss: 0.68517 - acc: 0.6370 -- iter: 384/569
[A[ATraining Step: 13  | total loss: [1m[32m0.68982[0m[0m | time: 15.185s
[2K
| Adam | epoch: 001 | loss: 0.68982 - acc: 0.5649 -- iter: 416/569
[A[ATraining Step: 14  | total loss: [1m[32m0.69203[0m[0m | time: 16.277s
[2K
| Adam | epoch: 001 | loss: 0.69203 - acc: 0.5256 -- iter: 448/569
[A[ATraining Step: 15  | total loss: [1m[32m0.69259[0m[0m | time: 17.428s
[2K
| Adam | epoch: 001 | loss: 0.69259 - acc: 0.5156 -- iter: 480/569
[A[ATraining Step: 16  | total loss: [1m[32m0.69034[0m[0m | time: 18.737s
[2K
| Adam | epoch: 001 | loss: 0.69034 - acc: 0.5683 -- iter: 512/569
[A[ATraining Step: 17  | total loss: [1m[32m0.69199[0m[0m | time: 19.797s
[2K
| Adam | epoch: 001 | loss: 0.69199 - acc: 0.5325 -- iter: 544/569
[A[ATraining Step: 18  | total loss: [1m[32m0.68879[0m[0m | time: 21.915s
[2K
| Adam | epoch: 001 | loss: 0.68879 - acc: 0.6078 | val_loss: 0.68679 - val_acc: 0.6404 -- iter: 569/569
--
Training Step: 19  | total loss: [1m[32m0.68873[0m[0m | time: 1.128s
[2K
| Adam | epoch: 002 | loss: 0.68873 - acc: 0.6052 -- iter: 032/569
[A[ATraining Step: 20  | total loss: [1m[32m0.68876[0m[0m | time: 2.299s
[2K
| Adam | epoch: 002 | loss: 0.68876 - acc: 0.6035 -- iter: 064/569
[A[ATraining Step: 21  | total loss: [1m[32m0.68821[0m[0m | time: 3.231s
[2K
| Adam | epoch: 002 | loss: 0.68821 - acc: 0.6102 -- iter: 096/569
[A[ATraining Step: 22  | total loss: [1m[32m0.68566[0m[0m | time: 4.251s
[2K
| Adam | epoch: 002 | loss: 0.68566 - acc: 0.6521 -- iter: 128/569
[A[ATraining Step: 23  | total loss: [1m[32m0.68626[0m[0m | time: 5.255s
[2K
| Adam | epoch: 002 | loss: 0.68626 - acc: 0.6352 -- iter: 160/569
[A[ATraining Step: 24  | total loss: [1m[32m0.68529[0m[0m | time: 6.267s
[2K
| Adam | epoch: 002 | loss: 0.68529 - acc: 0.6411 -- iter: 192/569
[A[ATraining Step: 25  | total loss: [1m[32m0.68175[0m[0m | time: 7.462s
[2K
| Adam | epoch: 002 | loss: 0.68175 - acc: 0.6793 -- iter: 224/569
[A[ATraining Step: 26  | total loss: [1m[32m0.68224[0m[0m | time: 8.686s
[2K
| Adam | epoch: 002 | loss: 0.68224 - acc: 0.6649 -- iter: 256/569
[A[ATraining Step: 27  | total loss: [1m[32m0.68548[0m[0m | time: 9.801s
[2K
| Adam | epoch: 002 | loss: 0.68548 - acc: 0.6225 -- iter: 288/569
[A[ATraining Step: 28  | total loss: [1m[32m0.68438[0m[0m | time: 10.966s
[2K
| Adam | epoch: 002 | loss: 0.68438 - acc: 0.6231 -- iter: 320/569
[A[ATraining Step: 29  | total loss: [1m[32m0.68879[0m[0m | time: 12.342s
[2K
| Adam | epoch: 002 | loss: 0.68879 - acc: 0.5780 -- iter: 352/569
[A[ATraining Step: 30  | total loss: [1m[32m0.68493[0m[0m | time: 13.629s
[2K
| Adam | epoch: 002 | loss: 0.68493 - acc: 0.6039 -- iter: 384/569
[A[ATraining Step: 31  | total loss: [1m[32m0.68921[0m[0m | time: 14.659s
[2K
| Adam | epoch: 002 | loss: 0.68921 - acc: 0.5655 -- iter: 416/569
[A[ATraining Step: 32  | total loss: [1m[32m0.68760[0m[0m | time: 15.549s
[2K
| Adam | epoch: 002 | loss: 0.68760 - acc: 0.5719 -- iter: 448/569
[A[ATraining Step: 33  | total loss: [1m[32m0.68453[0m[0m | time: 16.530s
[2K
| Adam | epoch: 002 | loss: 0.68453 - acc: 0.5904 -- iter: 480/569
[A[ATraining Step: 34  | total loss: [1m[32m0.68399[0m[0m | time: 17.511s
[2K
| Adam | epoch: 002 | loss: 0.68399 - acc: 0.5911 -- iter: 512/569
[A[ATraining Step: 35  | total loss: [1m[32m0.68228[0m[0m | time: 18.567s
[2K
| Adam | epoch: 002 | loss: 0.68228 - acc: 0.5982 -- iter: 544/569
[A[ATraining Step: 36  | total loss: [1m[32m0.68087[0m[0m | time: 20.927s
[2K
| Adam | epoch: 002 | loss: 0.68087 - acc: 0.6037 | val_loss: 0.66968 - val_acc: 0.6404 -- iter: 569/569
--
Training Step: 37  | total loss: [1m[32m0.68069[0m[0m | time: 0.816s
[2K
| Adam | epoch: 003 | loss: 0.68069 - acc: 0.6017 -- iter: 032/569
[A[ATraining Step: 38  | total loss: [1m[32m0.68648[0m[0m | time: 1.930s
[2K
| Adam | epoch: 003 | loss: 0.68648 - acc: 0.5701 -- iter: 064/569
[A[ATraining Step: 39  | total loss: [1m[32m0.69117[0m[0m | time: 3.162s
[2K
| Adam | epoch: 003 | loss: 0.69117 - acc: 0.5452 -- iter: 096/569
[A[ATraining Step: 40  | total loss: [1m[32m0.68524[0m[0m | time: 4.462s
[2K
| Adam | epoch: 003 | loss: 0.68524 - acc: 0.5718 -- iter: 128/569
[A[ATraining Step: 41  | total loss: [1m[32m0.68659[0m[0m | time: 5.345s
[2K
| Adam | epoch: 003 | loss: 0.68659 - acc: 0.5644 -- iter: 160/569
[A[ATraining Step: 42  | total loss: [1m[32m0.68261[0m[0m | time: 6.268s
[2K
| Adam | epoch: 003 | loss: 0.68261 - acc: 0.5809 -- iter: 192/569
[A[ATraining Step: 43  | total loss: [1m[32m0.68028[0m[0m | time: 7.245s
[2K
| Adam | epoch: 003 | loss: 0.68028 - acc: 0.5887 -- iter: 224/569
[A[ATraining Step: 44  | total loss: [1m[32m0.68249[0m[0m | time: 8.274s
[2K
| Adam | epoch: 003 | loss: 0.68249 - acc: 0.5788 -- iter: 256/569
[A[ATraining Step: 45  | total loss: [1m[32m0.68554[0m[0m | time: 9.297s
[2K
| Adam | epoch: 003 | loss: 0.68554 - acc: 0.5654 -- iter: 288/569
[A[ATraining Step: 46  | total loss: [1m[32m0.67853[0m[0m | time: 10.547s
[2K
| Adam | epoch: 003 | loss: 0.67853 - acc: 0.5909 -- iter: 320/569
[A[ATraining Step: 47  | total loss: [1m[32m0.67798[0m[0m | time: 11.831s
[2K
| Adam | epoch: 003 | loss: 0.67798 - acc: 0.5914 -- iter: 352/569
[A[ATraining Step: 48  | total loss: [1m[32m0.67771[0m[0m | time: 12.851s
[2K
| Adam | epoch: 003 | loss: 0.67771 - acc: 0.5918 -- iter: 384/569
[A[ATraining Step: 49  | total loss: [1m[32m0.67419[0m[0m | time: 14.022s
[2K
| Adam | epoch: 003 | loss: 0.67419 - acc: 0.6020 -- iter: 416/569
[A[ATraining Step: 50  | total loss: [1m[32m0.67945[0m[0m | time: 15.429s
[2K
| Adam | epoch: 003 | loss: 0.67945 - acc: 0.5861 -- iter: 448/569
[A[ATraining Step: 51  | total loss: [1m[32m0.67552[0m[0m | time: 16.719s
[2K
| Adam | epoch: 003 | loss: 0.67552 - acc: 0.5968 -- iter: 480/569
[A[ATraining Step: 52  | total loss: [1m[32m0.65907[0m[0m | time: 17.720s
[2K
| Adam | epoch: 003 | loss: 0.65907 - acc: 0.6386 -- iter: 512/569
[A[ATraining Step: 53  | total loss: [1m[32m0.66597[0m[0m | time: 18.669s
[2K
| Adam | epoch: 003 | loss: 0.66597 - acc: 0.6227 -- iter: 544/569
[A[ATraining Step: 54  | total loss: [1m[32m0.67014[0m[0m | time: 20.714s
[2K
| Adam | epoch: 003 | loss: 0.67014 - acc: 0.6140 | val_loss: 0.65328 - val_acc: 0.6404 -- iter: 569/569
--
Training Step: 55  | total loss: [1m[32m0.67368[0m[0m | time: 0.966s
[2K
| Adam | epoch: 004 | loss: 0.67368 - acc: 0.6066 -- iter: 032/569
[A[ATraining Step: 56  | total loss: [1m[32m0.67157[0m[0m | time: 1.933s
[2K
| Adam | epoch: 004 | loss: 0.67157 - acc: 0.6092 -- iter: 064/569
[A[ATraining Step: 57  | total loss: [1m[32m0.67798[0m[0m | time: 2.878s
[2K
| Adam | epoch: 004 | loss: 0.67798 - acc: 0.5969 -- iter: 096/569
[A[ATraining Step: 58  | total loss: [1m[32m0.68320[0m[0m | time: 3.956s
[2K
| Adam | epoch: 004 | loss: 0.68320 - acc: 0.5864 -- iter: 128/569
[A[ATraining Step: 59  | total loss: [1m[32m0.67835[0m[0m | time: 5.160s
[2K
| Adam | epoch: 004 | loss: 0.67835 - acc: 0.5958 -- iter: 160/569
[A[ATraining Step: 60  | total loss: [1m[32m0.67807[0m[0m | time: 6.569s
[2K
| Adam | epoch: 004 | loss: 0.67807 - acc: 0.5955 -- iter: 192/569
[A[ATraining Step: 61  | total loss: [1m[32m0.68271[0m[0m | time: 7.842s
[2K
| Adam | epoch: 004 | loss: 0.68271 - acc: 0.5830 -- iter: 224/569
[A[ATraining Step: 62  | total loss: [1m[32m0.68328[0m[0m | time: 8.876s
[2K
| Adam | epoch: 004 | loss: 0.68328 - acc: 0.5804 -- iter: 256/569
[A[ATraining Step: 63  | total loss: [1m[32m0.68248[0m[0m | time: 9.848s
[2K
| Adam | epoch: 004 | loss: 0.68248 - acc: 0.5821 -- iter: 288/569
[A[ATraining Step: 64  | total loss: [1m[32m0.68310[0m[0m | time: 10.956s
[2K
| Adam | epoch: 004 | loss: 0.68310 - acc: 0.5796 -- iter: 320/569
[A[ATraining Step: 65  | total loss: [1m[32m0.68472[0m[0m | time: 12.001s
[2K
| Adam | epoch: 004 | loss: 0.68472 - acc: 0.5737 -- iter: 352/569
[A[ATraining Step: 66  | total loss: [1m[32m0.68828[0m[0m | time: 13.167s
[2K
| Adam | epoch: 004 | loss: 0.68828 - acc: 0.5609 -- iter: 384/569
[A[ATraining Step: 67  | total loss: [1m[32m0.68493[0m[0m | time: 14.435s
[2K
| Adam | epoch: 004 | loss: 0.68493 - acc: 0.5724 -- iter: 416/569
[A[ATraining Step: 68  | total loss: [1m[32m0.68685[0m[0m | time: 15.528s
[2K
| Adam | epoch: 004 | loss: 0.68685 - acc: 0.5638 -- iter: 448/569
[A[ATraining Step: 69  | total loss: [1m[32m0.68388[0m[0m | time: 16.571s
[2K
| Adam | epoch: 004 | loss: 0.68388 - acc: 0.5746 -- iter: 480/569
[A[ATraining Step: 70  | total loss: [1m[32m0.68135[0m[0m | time: 18.036s
[2K
| Adam | epoch: 004 | loss: 0.68135 - acc: 0.5840 -- iter: 512/569
[A[ATraining Step: 71  | total loss: [1m[32m0.68089[0m[0m | time: 19.275s
[2K
| Adam | epoch: 004 | loss: 0.68089 - acc: 0.5851 -- iter: 544/569
[A[ATraining Step: 72  | total loss: [1m[32m0.67954[0m[0m | time: 21.375s
[2K
| Adam | epoch: 004 | loss: 0.67954 - acc: 0.5896 | val_loss: 0.66552 - val_acc: 0.6404 -- iter: 569/569
--
Training Step: 73  | total loss: [1m[32m0.67751[0m[0m | time: 1.091s
[2K
| Adam | epoch: 005 | loss: 0.67751 - acc: 0.5970 -- iter: 032/569
[A[ATraining Step: 74  | total loss: [1m[32m0.67492[0m[0m | time: 2.116s
[2K
| Adam | epoch: 005 | loss: 0.67492 - acc: 0.6069 -- iter: 064/569
[A[ATraining Step: 75  | total loss: [1m[32m0.67431[0m[0m | time: 2.994s
[2K
| Adam | epoch: 005 | loss: 0.67431 - acc: 0.6089 -- iter: 096/569
[A[ATraining Step: 76  | total loss: [1m[32m0.67226[0m[0m | time: 3.967s
[2K
| Adam | epoch: 005 | loss: 0.67226 - acc: 0.6165 -- iter: 128/569
[A[ATraining Step: 77  | total loss: [1m[32m0.67047[0m[0m | time: 5.328s
[2K
| Adam | epoch: 005 | loss: 0.67047 - acc: 0.6232 -- iter: 160/569
[A[ATraining Step: 78  | total loss: [1m[32m0.67197[0m[0m | time: 6.479s
[2K
| Adam | epoch: 005 | loss: 0.67197 - acc: 0.6169 -- iter: 192/569
[A[ATraining Step: 79  | total loss: [1m[32m0.67522[0m[0m | time: 7.650s
[2K
| Adam | epoch: 005 | loss: 0.67522 - acc: 0.6048 -- iter: 224/569
[A[ATraining Step: 80  | total loss: [1m[32m0.67526[0m[0m | time: 9.020s
[2K
| Adam | epoch: 005 | loss: 0.67526 - acc: 0.6037 -- iter: 256/569
[A[ATraining Step: 81  | total loss: [1m[32m0.67443[0m[0m | time: 10.445s
[2K
| Adam | epoch: 005 | loss: 0.67443 - acc: 0.6058 -- iter: 288/569
[A[ATraining Step: 82  | total loss: [1m[32m0.67645[0m[0m | time: 11.448s
[2K
| Adam | epoch: 005 | loss: 0.67645 - acc: 0.5984 -- iter: 320/569
[A[ATraining Step: 83  | total loss: [1m[32m0.67352[0m[0m | time: 12.426s
[2K
| Adam | epoch: 005 | loss: 0.67352 - acc: 0.6073 -- iter: 352/569
[A[ATraining Step: 84  | total loss: [1m[32m0.67569[0m[0m | time: 13.467s
[2K
| Adam | epoch: 005 | loss: 0.67569 - acc: 0.5997 -- iter: 384/569
[A[ATraining Step: 85  | total loss: [1m[32m0.67360[0m[0m | time: 14.512s
[2K
| Adam | epoch: 005 | loss: 0.67360 - acc: 0.6053 -- iter: 416/569
[A[ATraining Step: 86  | total loss: [1m[32m0.67274[0m[0m | time: 15.647s
[2K
| Adam | epoch: 005 | loss: 0.67274 - acc: 0.6073 -- iter: 448/569
[A[ATraining Step: 87  | total loss: [1m[32m0.67088[0m[0m | time: 16.863s
[2K
| Adam | epoch: 005 | loss: 0.67088 - acc: 0.6122 -- iter: 480/569
[A[ATraining Step: 88  | total loss: [1m[32m0.66899[0m[0m | time: 18.141s
[2K
| Adam | epoch: 005 | loss: 0.66899 - acc: 0.6166 -- iter: 512/569
[A[ATraining Step: 89  | total loss: [1m[32m0.66496[0m[0m | time: 19.190s
[2K
| Adam | epoch: 005 | loss: 0.66496 - acc: 0.6268 -- iter: 544/569
[A[ATraining Step: 90  | total loss: [1m[32m0.66365[0m[0m | time: 21.801s
[2K
| Adam | epoch: 005 | loss: 0.66365 - acc: 0.6298 | val_loss: 0.65640 - val_acc: 0.6404 -- iter: 569/569
--
Training Step: 91  | total loss: [1m[32m0.67125[0m[0m | time: 1.050s
[2K
| Adam | epoch: 006 | loss: 0.67125 - acc: 0.6105 -- iter: 032/569
[A[ATraining Step: 92  | total loss: [1m[32m0.67168[0m[0m | time: 1.982s
[2K
| Adam | epoch: 006 | loss: 0.67168 - acc: 0.6089 -- iter: 064/569
[A[ATraining Step: 93  | total loss: [1m[32m0.67466[0m[0m | time: 2.999s
[2K
| Adam | epoch: 006 | loss: 0.67466 - acc: 0.6011 -- iter: 096/569
[A[ATraining Step: 94  | total loss: [1m[32m0.67463[0m[0m | time: 3.866s
[2K
| Adam | epoch: 006 | loss: 0.67463 - acc: 0.6004 -- iter: 128/569
[A[ATraining Step: 95  | total loss: [1m[32m0.67467[0m[0m | time: 4.689s
[2K
| Adam | epoch: 006 | loss: 0.67467 - acc: 0.6003 -- iter: 160/569
[A[ATraining Step: 96  | total loss: [1m[32m0.67451[0m[0m | time: 5.809s
[2K
| Adam | epoch: 006 | loss: 0.67451 - acc: 0.6003 -- iter: 192/569
[A[ATraining Step: 97  | total loss: [1m[32m0.67862[0m[0m | time: 7.017s
[2K
| Adam | epoch: 006 | loss: 0.67862 - acc: 0.5903 -- iter: 224/569
[A[ATraining Step: 98  | total loss: [1m[32m0.67958[0m[0m | time: 8.079s
[2K
| Adam | epoch: 006 | loss: 0.67958 - acc: 0.5875 -- iter: 256/569
[A[ATraining Step: 99  | total loss: [1m[32m0.67286[0m[0m | time: 9.153s
[2K
| Adam | epoch: 006 | loss: 0.67286 - acc: 0.6037 -- iter: 288/569
[A[ATraining Step: 100  | total loss: [1m[32m0.67836[0m[0m | time: 10.584s
[2K
| Adam | epoch: 006 | loss: 0.67836 - acc: 0.5902 -- iter: 320/569
[A[ATraining Step: 101  | total loss: [1m[32m0.67567[0m[0m | time: 11.820s
[2K
| Adam | epoch: 006 | loss: 0.67567 - acc: 0.5968 -- iter: 352/569
[A[ATraining Step: 102  | total loss: [1m[32m0.67157[0m[0m | time: 12.863s
[2K
| Adam | epoch: 006 | loss: 0.67157 - acc: 0.6059 -- iter: 384/569
[A[ATraining Step: 103  | total loss: [1m[32m0.67184[0m[0m | time: 13.845s
[2K
| Adam | epoch: 006 | loss: 0.67184 - acc: 0.6047 -- iter: 416/569
[A[ATraining Step: 104  | total loss: [1m[32m0.67221[0m[0m | time: 14.891s
[2K
| Adam | epoch: 006 | loss: 0.67221 - acc: 0.6036 -- iter: 448/569
[A[ATraining Step: 105  | total loss: [1m[32m0.67247[0m[0m | time: 15.906s
[2K
| Adam | epoch: 006 | loss: 0.67247 - acc: 0.6026 -- iter: 480/569
[A[ATraining Step: 106  | total loss: [1m[32m0.67549[0m[0m | time: 16.950s
[2K
| Adam | epoch: 006 | loss: 0.67549 - acc: 0.5955 -- iter: 512/569
[A[ATraining Step: 107  | total loss: [1m[32m0.67804[0m[0m | time: 18.202s
[2K
| Adam | epoch: 006 | loss: 0.67804 - acc: 0.5891 -- iter: 544/569
[A[ATraining Step: 108  | total loss: [1m[32m0.66880[0m[0m | time: 20.390s
[2K
| Adam | epoch: 006 | loss: 0.66880 - acc: 0.6114 | val_loss: 0.65592 - val_acc: 0.6404 -- iter: 569/569
--
Training Step: 109  | total loss: [1m[32m0.66820[0m[0m | time: 1.384s
[2K
| Adam | epoch: 007 | loss: 0.66820 - acc: 0.6128 -- iter: 032/569
[A[ATraining Step: 110  | total loss: [1m[32m0.67426[0m[0m | time: 2.719s
[2K
| Adam | epoch: 007 | loss: 0.67426 - acc: 0.5984 -- iter: 064/569
[A[ATraining Step: 111  | total loss: [1m[32m0.67717[0m[0m | time: 4.075s
[2K
| Adam | epoch: 007 | loss: 0.67717 - acc: 0.5916 -- iter: 096/569
[A[ATraining Step: 112  | total loss: [1m[32m0.67448[0m[0m | time: 4.925s
[2K
| Adam | epoch: 007 | loss: 0.67448 - acc: 0.5981 -- iter: 128/569
[A[ATraining Step: 113  | total loss: [1m[32m0.67698[0m[0m | time: 5.788s
[2K
| Adam | epoch: 007 | loss: 0.67698 - acc: 0.5914 -- iter: 160/569
[A[ATraining Step: 114  | total loss: [1m[32m0.67650[0m[0m | time: 6.575s
[2K
| Adam | epoch: 007 | loss: 0.67650 - acc: 0.5923 -- iter: 192/569
[A[ATraining Step: 115  | total loss: [1m[32m0.67606[0m[0m | time: 7.586s
[2K
| Adam | epoch: 007 | loss: 0.67606 - acc: 0.5931 -- iter: 224/569
[A[ATraining Step: 116  | total loss: [1m[32m0.68094[0m[0m | time: 8.604s
[2K
| Adam | epoch: 007 | loss: 0.68094 - acc: 0.5806 -- iter: 256/569
[A[ATraining Step: 117  | total loss: [1m[32m0.68277[0m[0m | time: 9.876s
[2K
| Adam | epoch: 007 | loss: 0.68277 - acc: 0.5757 -- iter: 288/569
[A[ATraining Step: 118  | total loss: [1m[32m0.67958[0m[0m | time: 11.110s
[2K
| Adam | epoch: 007 | loss: 0.67958 - acc: 0.5837 -- iter: 320/569
[A[ATraining Step: 119  | total loss: [1m[32m0.67549[0m[0m | time: 12.114s
[2K
| Adam | epoch: 007 | loss: 0.67549 - acc: 0.5941 -- iter: 352/569
[A[ATraining Step: 120  | total loss: [1m[32m0.67664[0m[0m | time: 13.433s
[2K
| Adam | epoch: 007 | loss: 0.67664 - acc: 0.5910 -- iter: 384/569
[A[ATraining Step: 121  | total loss: [1m[32m0.67655[0m[0m | time: 14.808s
[2K
| Adam | epoch: 007 | loss: 0.67655 - acc: 0.5912 -- iter: 416/569
[A[ATraining Step: 122  | total loss: [1m[32m0.67654[0m[0m | time: 16.100s
[2K
| Adam | epoch: 007 | loss: 0.67654 - acc: 0.5915 -- iter: 448/569
[A[ATraining Step: 123  | total loss: [1m[32m0.67891[0m[0m | time: 16.994s
[2K
| Adam | epoch: 007 | loss: 0.67891 - acc: 0.5855 -- iter: 480/569
[A[ATraining Step: 124  | total loss: [1m[32m0.67869[0m[0m | time: 17.973s
[2K
| Adam | epoch: 007 | loss: 0.67869 - acc: 0.5863 -- iter: 512/569
[A[ATraining Step: 125  | total loss: [1m[32m0.67620[0m[0m | time: 19.012s
[2K
| Adam | epoch: 007 | loss: 0.67620 - acc: 0.5933 -- iter: 544/569
[A[ATraining Step: 126  | total loss: [1m[32m0.67388[0m[0m | time: 21.093s
[2K
| Adam | epoch: 007 | loss: 0.67388 - acc: 0.5996 | val_loss: 0.65807 - val_acc: 0.6404 -- iter: 569/569
--
Training Step: 127  | total loss: [1m[32m0.67184[0m[0m | time: 1.085s
[2K
| Adam | epoch: 008 | loss: 0.67184 - acc: 0.6052 -- iter: 032/569
[A[ATraining Step: 128  | total loss: [1m[32m0.67343[0m[0m | time: 2.213s
[2K
| Adam | epoch: 008 | loss: 0.67343 - acc: 0.6010 -- iter: 064/569
[A[ATraining Step: 129  | total loss: [1m[32m0.67014[0m[0m | time: 3.573s
[2K
| Adam | epoch: 008 | loss: 0.67014 - acc: 0.6096 -- iter: 096/569
[A[ATraining Step: 130  | total loss: [1m[32m0.67074[0m[0m | time: 4.910s
[2K
| Adam | epoch: 008 | loss: 0.67074 - acc: 0.6080 -- iter: 128/569
[A[ATraining Step: 131  | total loss: [1m[32m0.67484[0m[0m | time: 5.902s
[2K
| Adam | epoch: 008 | loss: 0.67484 - acc: 0.5972 -- iter: 160/569
[A[ATraining Step: 132  | total loss: [1m[32m0.67587[0m[0m | time: 6.700s
[2K
| Adam | epoch: 008 | loss: 0.67587 - acc: 0.5938 -- iter: 192/569
[A[ATraining Step: 133  | total loss: [1m[32m0.68032[0m[0m | time: 7.515s
[2K
| Adam | epoch: 008 | loss: 0.68032 - acc: 0.5824 -- iter: 224/569
[A[ATraining Step: 134  | total loss: [1m[32m0.68416[0m[0m | time: 8.604s
[2K
| Adam | epoch: 008 | loss: 0.68416 - acc: 0.5721 -- iter: 256/569
[A[ATraining Step: 135  | total loss: [1m[32m0.68472[0m[0m | time: 9.622s
[2K
| Adam | epoch: 008 | loss: 0.68472 - acc: 0.5712 -- iter: 288/569
[A[ATraining Step: 136  | total loss: [1m[32m0.68040[0m[0m | time: 10.810s
[2K
| Adam | epoch: 008 | loss: 0.68040 - acc: 0.5828 -- iter: 320/569
[A[ATraining Step: 137  | total loss: [1m[32m0.67534[0m[0m | time: 12.018s
[2K
| Adam | epoch: 008 | loss: 0.67534 - acc: 0.5964 -- iter: 352/569
[A[ATraining Step: 138  | total loss: [1m[32m0.67745[0m[0m | time: 13.043s
[2K
| Adam | epoch: 008 | loss: 0.67745 - acc: 0.5899 -- iter: 384/569
[A[ATraining Step: 139  | total loss: [1m[32m0.67511[0m[0m | time: 14.343s
[2K
| Adam | epoch: 008 | loss: 0.67511 - acc: 0.5965 -- iter: 416/569
[A[ATraining Step: 140  | total loss: [1m[32m0.68409[0m[0m | time: 15.709s
[2K
| Adam | epoch: 008 | loss: 0.68409 - acc: 0.5713 -- iter: 448/569
[A[ATraining Step: 141  | total loss: [1m[32m0.68004[0m[0m | time: 17.039s
[2K
| Adam | epoch: 008 | loss: 0.68004 - acc: 0.5829 -- iter: 480/569
[A[ATraining Step: 142  | total loss: [1m[32m0.67731[0m[0m | time: 17.933s
[2K
| Adam | epoch: 008 | loss: 0.67731 - acc: 0.5902 -- iter: 512/569
[A[ATraining Step: 143  | total loss: [1m[32m0.67488[0m[0m | time: 18.978s
[2K
| Adam | epoch: 008 | loss: 0.67488 - acc: 0.5968 -- iter: 544/569
[A[ATraining Step: 144  | total loss: [1m[32m0.67377[0m[0m | time: 21.014s
[2K
| Adam | epoch: 008 | loss: 0.67377 - acc: 0.5996 | val_loss: 0.65824 - val_acc: 0.6404 -- iter: 569/569
--
Training Step: 145  | total loss: [1m[32m0.67280[0m[0m | time: 1.232s
[2K
| Adam | epoch: 009 | loss: 0.67280 - acc: 0.6022 -- iter: 032/569
[A[ATraining Step: 146  | total loss: [1m[32m0.67396[0m[0m | time: 2.502s
[2K
| Adam | epoch: 009 | loss: 0.67396 - acc: 0.5982 -- iter: 064/569
[A[ATraining Step: 147  | total loss: [1m[32m0.67745[0m[0m | time: 3.568s
[2K
| Adam | epoch: 009 | loss: 0.67745 - acc: 0.5884 -- iter: 096/569
[A[ATraining Step: 148  | total loss: [1m[32m0.67522[0m[0m | time: 4.660s
[2K
| Adam | epoch: 009 | loss: 0.67522 - acc: 0.5952 -- iter: 128/569
[A[ATraining Step: 149  | total loss: [1m[32m0.67426[0m[0m | time: 6.031s
[2K
| Adam | epoch: 009 | loss: 0.67426 - acc: 0.5982 -- iter: 160/569
[A[ATraining Step: 150  | total loss: [1m[32m0.67775[0m[0m | time: 7.317s
[2K
| Adam | epoch: 009 | loss: 0.67775 - acc: 0.5883 -- iter: 192/569
[A[ATraining Step: 151  | total loss: [1m[32m0.67046[0m[0m | time: 8.178s
[2K
| Adam | epoch: 009 | loss: 0.67046 - acc: 0.6076 -- iter: 224/569
[A[ATraining Step: 152  | total loss: [1m[32m0.67225[0m[0m | time: 9.007s
[2K
| Adam | epoch: 009 | loss: 0.67225 - acc: 0.6029 -- iter: 256/569
[A[ATraining Step: 153  | total loss: [1m[32m0.67377[0m[0m | time: 10.066s
[2K
| Adam | epoch: 009 | loss: 0.67377 - acc: 0.5986 -- iter: 288/569
[A[ATraining Step: 154  | total loss: [1m[32m0.67250[0m[0m | time: 11.138s
[2K
| Adam | epoch: 009 | loss: 0.67250 - acc: 0.6012 -- iter: 320/569
[A[ATraining Step: 155  | total loss: [1m[32m0.67631[0m[0m | time: 12.148s
[2K
| Adam | epoch: 009 | loss: 0.67631 - acc: 0.5911 -- iter: 352/569
[A[ATraining Step: 156  | total loss: [1m[32m0.67614[0m[0m | time: 13.287s
[2K
| Adam | epoch: 009 | loss: 0.67614 - acc: 0.5914 -- iter: 384/569
[A[ATraining Step: 157  | total loss: [1m[32m0.67613[0m[0m | time: 14.472s
[2K
| Adam | epoch: 009 | loss: 0.67613 - acc: 0.5916 -- iter: 416/569
[A[ATraining Step: 158  | total loss: [1m[32m0.66597[0m[0m | time: 15.500s
[2K
| Adam | epoch: 009 | loss: 0.66597 - acc: 0.6168 -- iter: 448/569
[A[ATraining Step: 159  | total loss: [1m[32m0.66807[0m[0m | time: 16.803s
[2K
| Adam | epoch: 009 | loss: 0.66807 - acc: 0.6114 -- iter: 480/569
[A[ATraining Step: 160  | total loss: [1m[32m0.67287[0m[0m | time: 18.126s
[2K
| Adam | epoch: 009 | loss: 0.67287 - acc: 0.6002 -- iter: 512/569
[A[ATraining Step: 161  | total loss: [1m[32m0.67281[0m[0m | time: 19.482s
[2K
| Adam | epoch: 009 | loss: 0.67281 - acc: 0.5996 -- iter: 544/569
[A[ATraining Step: 162  | total loss: [1m[32m0.67273[0m[0m | time: 21.396s
[2K
| Adam | epoch: 009 | loss: 0.67273 - acc: 0.5990 | val_loss: 0.65242 - val_acc: 0.6404 -- iter: 569/569
--
Training Step: 163  | total loss: [1m[32m0.67136[0m[0m | time: 1.067s
[2K
| Adam | epoch: 010 | loss: 0.67136 - acc: 0.6016 -- iter: 032/569
[A[ATraining Step: 164  | total loss: [1m[32m0.67002[0m[0m | time: 2.046s
[2K
| Adam | epoch: 010 | loss: 0.67002 - acc: 0.6040 -- iter: 064/569
[A[ATraining Step: 165  | total loss: [1m[32m0.67157[0m[0m | time: 3.247s
[2K
| Adam | epoch: 010 | loss: 0.67157 - acc: 0.5998 -- iter: 096/569
[A[ATraining Step: 166  | total loss: [1m[32m0.67725[0m[0m | time: 4.459s
[2K
| Adam | epoch: 010 | loss: 0.67725 - acc: 0.5867 -- iter: 128/569
[A[ATraining Step: 167  | total loss: [1m[32m0.67783[0m[0m | time: 5.489s
[2K
| Adam | epoch: 010 | loss: 0.67783 - acc: 0.5843 -- iter: 160/569
[A[ATraining Step: 168  | total loss: [1m[32m0.67209[0m[0m | time: 6.594s
[2K
| Adam | epoch: 010 | loss: 0.67209 - acc: 0.5977 -- iter: 192/569
[A[ATraining Step: 169  | total loss: [1m[32m0.66891[0m[0m | time: 7.908s
[2K
| Adam | epoch: 010 | loss: 0.66891 - acc: 0.6036 -- iter: 224/569
[A[ATraining Step: 170  | total loss: [1m[32m0.66992[0m[0m | time: 8.935s
[2K
| Adam | epoch: 010 | loss: 0.66992 - acc: 0.5995 -- iter: 256/569
[A[ATraining Step: 171  | total loss: [1m[32m0.66713[0m[0m | time: 9.905s
[2K
| Adam | epoch: 010 | loss: 0.66713 - acc: 0.6035 -- iter: 288/569
[A[ATraining Step: 172  | total loss: [1m[32m0.66418[0m[0m | time: 10.817s
[2K
| Adam | epoch: 010 | loss: 0.66418 - acc: 0.6072 -- iter: 320/569
[A[ATraining Step: 173  | total loss: [1m[32m0.66268[0m[0m | time: 11.853s
[2K
| Adam | epoch: 010 | loss: 0.66268 - acc: 0.6058 -- iter: 352/569
[A[ATraining Step: 174  | total loss: [1m[32m0.67020[0m[0m | time: 12.913s
[2K
| Adam | epoch: 010 | loss: 0.67020 - acc: 0.5890 -- iter: 384/569
[A[ATraining Step: 175  | total loss: [1m[32m0.66686[0m[0m | time: 13.963s
[2K
| Adam | epoch: 010 | loss: 0.66686 - acc: 0.5926 -- iter: 416/569
[A[ATraining Step: 176  | total loss: [1m[32m0.66338[0m[0m | time: 15.020s
[2K
| Adam | epoch: 010 | loss: 0.66338 - acc: 0.5927 -- iter: 448/569
[A[ATraining Step: 177  | total loss: [1m[32m0.66147[0m[0m | time: 16.251s
[2K
| Adam | epoch: 010 | loss: 0.66147 - acc: 0.5803 -- iter: 480/569
[A[ATraining Step: 178  | total loss: [1m[32m0.65925[0m[0m | time: 17.329s
[2K
| Adam | epoch: 010 | loss: 0.65925 - acc: 0.5817 -- iter: 512/569
[A[ATraining Step: 179  | total loss: [1m[32m0.65507[0m[0m | time: 18.416s
[2K
| Adam | epoch: 010 | loss: 0.65507 - acc: 0.5829 -- iter: 544/569
[A[ATraining Step: 180  | total loss: [1m[32m0.64832[0m[0m | time: 20.825s
[2K
| Adam | epoch: 010 | loss: 0.64832 - acc: 0.5996 | val_loss: 0.60432 - val_acc: 0.6629 -- iter: 569/569
--
Training Step: 181  | total loss: [1m[32m0.63811[0m[0m | time: 0.947s
[2K
| Adam | epoch: 011 | loss: 0.63811 - acc: 0.6240 -- iter: 032/569
[A[ATraining Step: 182  | total loss: [1m[32m0.63996[0m[0m | time: 1.958s
[2K
| Adam | epoch: 011 | loss: 0.63996 - acc: 0.6210 -- iter: 064/569
[A[ATraining Step: 183  | total loss: [1m[32m0.62369[0m[0m | time: 3.060s
[2K
| Adam | epoch: 011 | loss: 0.62369 - acc: 0.6339 -- iter: 096/569
[A[ATraining Step: 184  | total loss: [1m[32m0.62272[0m[0m | time: 4.100s
[2K
| Adam | epoch: 011 | loss: 0.62272 - acc: 0.6330 -- iter: 128/569
[A[ATraining Step: 185  | total loss: [1m[32m0.61641[0m[0m | time: 5.166s
[2K
| Adam | epoch: 011 | loss: 0.61641 - acc: 0.6384 -- iter: 160/569
[A[ATraining Step: 186  | total loss: [1m[32m0.61889[0m[0m | time: 6.322s
[2K
| Adam | epoch: 011 | loss: 0.61889 - acc: 0.6433 -- iter: 192/569
[A[ATraining Step: 187  | total loss: [1m[32m0.60575[0m[0m | time: 7.436s
[2K
| Adam | epoch: 011 | loss: 0.60575 - acc: 0.6634 -- iter: 224/569
[A[ATraining Step: 188  | total loss: [1m[32m0.60032[0m[0m | time: 8.494s
[2K
| Adam | epoch: 011 | loss: 0.60032 - acc: 0.6627 -- iter: 256/569
[A[ATraining Step: 189  | total loss: [1m[32m0.60690[0m[0m | time: 9.621s
[2K
| Adam | epoch: 011 | loss: 0.60690 - acc: 0.6620 -- iter: 288/569
[A[ATraining Step: 190  | total loss: [1m[32m0.59520[0m[0m | time: 10.723s
[2K
| Adam | epoch: 011 | loss: 0.59520 - acc: 0.6758 -- iter: 320/569
[A[ATraining Step: 191  | total loss: [1m[32m0.58592[0m[0m | time: 11.973s
[2K
| Adam | epoch: 011 | loss: 0.58592 - acc: 0.6882 -- iter: 352/569
[A[ATraining Step: 192  | total loss: [1m[32m0.57398[0m[0m | time: 12.870s
[2K
| Adam | epoch: 011 | loss: 0.57398 - acc: 0.6944 -- iter: 384/569
[A[ATraining Step: 193  | total loss: [1m[32m0.56546[0m[0m | time: 13.909s
[2K
| Adam | epoch: 011 | loss: 0.56546 - acc: 0.7000 -- iter: 416/569
[A[ATraining Step: 194  | total loss: [1m[32m0.55568[0m[0m | time: 14.946s
[2K
| Adam | epoch: 011 | loss: 0.55568 - acc: 0.7081 -- iter: 448/569
[A[ATraining Step: 195  | total loss: [1m[32m0.56000[0m[0m | time: 15.948s
[2K
| Adam | epoch: 011 | loss: 0.56000 - acc: 0.7060 -- iter: 480/569
[A[ATraining Step: 196  | total loss: [1m[32m0.55479[0m[0m | time: 17.082s
[2K
| Adam | epoch: 011 | loss: 0.55479 - acc: 0.7104 -- iter: 512/569
[A[ATraining Step: 197  | total loss: [1m[32m0.54126[0m[0m | time: 18.301s
[2K
| Adam | epoch: 011 | loss: 0.54126 - acc: 0.7269 -- iter: 544/569
[A[ATraining Step: 198  | total loss: [1m[32m0.52931[0m[0m | time: 20.470s
[2K
| Adam | epoch: 011 | loss: 0.52931 - acc: 0.7323 | val_loss: 0.53072 - val_acc: 0.7135 -- iter: 569/569
--
Training Step: 199  | total loss: [1m[32m0.53025[0m[0m | time: 1.306s
[2K
| Adam | epoch: 012 | loss: 0.53025 - acc: 0.7310 -- iter: 032/569
[A[ATraining Step: 200  | total loss: [1m[32m0.52522[0m[0m | time: 3.556s
[2K
| Adam | epoch: 012 | loss: 0.52522 - acc: 0.7360 | val_loss: 0.54017 - val_acc: 0.7303 -- iter: 064/569
--
Training Step: 201  | total loss: [1m[32m0.52458[0m[0m | time: 4.558s
[2K
| Adam | epoch: 012 | loss: 0.52458 - acc: 0.7343 -- iter: 096/569
[A[ATraining Step: 202  | total loss: [1m[32m0.51504[0m[0m | time: 5.602s
[2K
| Adam | epoch: 012 | loss: 0.51504 - acc: 0.7390 -- iter: 128/569
[A[ATraining Step: 203  | total loss: [1m[32m0.51070[0m[0m | time: 6.605s
[2K
| Adam | epoch: 012 | loss: 0.51070 - acc: 0.7432 -- iter: 160/569
[A[ATraining Step: 204  | total loss: [1m[32m0.51329[0m[0m | time: 7.902s
[2K
| Adam | epoch: 012 | loss: 0.51329 - acc: 0.7408 -- iter: 192/569
[A[ATraining Step: 205  | total loss: [1m[32m0.51207[0m[0m | time: 9.197s
[2K
| Adam | epoch: 012 | loss: 0.51207 - acc: 0.7448 -- iter: 224/569
[A[ATraining Step: 206  | total loss: [1m[32m0.51264[0m[0m | time: 10.105s
[2K
| Adam | epoch: 012 | loss: 0.51264 - acc: 0.7391 -- iter: 256/569
[A[ATraining Step: 207  | total loss: [1m[32m0.50538[0m[0m | time: 11.368s
[2K
| Adam | epoch: 012 | loss: 0.50538 - acc: 0.7464 -- iter: 288/569
[A[ATraining Step: 208  | total loss: [1m[32m0.48683[0m[0m | time: 12.522s
[2K
| Adam | epoch: 012 | loss: 0.48683 - acc: 0.7655 -- iter: 320/569
[A[ATraining Step: 209  | total loss: [1m[32m0.48424[0m[0m | time: 13.527s
[2K
| Adam | epoch: 012 | loss: 0.48424 - acc: 0.7730 -- iter: 352/569
[A[ATraining Step: 210  | total loss: [1m[32m0.47228[0m[0m | time: 14.564s
[2K
| Adam | epoch: 012 | loss: 0.47228 - acc: 0.7837 -- iter: 384/569
[A[ATraining Step: 211  | total loss: [1m[32m0.47654[0m[0m | time: 15.486s
[2K
| Adam | epoch: 012 | loss: 0.47654 - acc: 0.7866 -- iter: 416/569
[A[ATraining Step: 212  | total loss: [1m[32m0.47857[0m[0m | time: 16.543s
[2K
| Adam | epoch: 012 | loss: 0.47857 - acc: 0.7798 -- iter: 448/569
[A[ATraining Step: 213  | total loss: [1m[32m0.45334[0m[0m | time: 17.662s
[2K
| Adam | epoch: 012 | loss: 0.45334 - acc: 0.7987 -- iter: 480/569
[A[ATraining Step: 214  | total loss: [1m[32m0.45884[0m[0m | time: 18.687s
[2K
| Adam | epoch: 012 | loss: 0.45884 - acc: 0.8001 -- iter: 512/569
[A[ATraining Step: 215  | total loss: [1m[32m0.44116[0m[0m | time: 19.879s
[2K
| Adam | epoch: 012 | loss: 0.44116 - acc: 0.8107 -- iter: 544/569
[A[ATraining Step: 216  | total loss: [1m[32m0.44941[0m[0m | time: 22.030s
[2K
| Adam | epoch: 012 | loss: 0.44941 - acc: 0.8109 | val_loss: 0.52654 - val_acc: 0.7584 -- iter: 569/569
--
Training Step: 217  | total loss: [1m[32m0.42852[0m[0m | time: 1.390s
[2K
| Adam | epoch: 013 | loss: 0.42852 - acc: 0.8173 -- iter: 032/569
[A[ATraining Step: 218  | total loss: [1m[32m0.43121[0m[0m | time: 2.725s
[2K
| Adam | epoch: 013 | loss: 0.43121 - acc: 0.8168 -- iter: 064/569
[A[ATraining Step: 219  | total loss: [1m[32m0.43311[0m[0m | time: 3.857s
[2K
| Adam | epoch: 013 | loss: 0.43311 - acc: 0.8195 -- iter: 096/569
[A[ATraining Step: 220  | total loss: [1m[32m0.44212[0m[0m | time: 4.801s
[2K
| Adam | epoch: 013 | loss: 0.44212 - acc: 0.8157 -- iter: 128/569
[A[ATraining Step: 221  | total loss: [1m[32m0.44080[0m[0m | time: 5.839s
[2K
| Adam | epoch: 013 | loss: 0.44080 - acc: 0.8154 -- iter: 160/569
[A[ATraining Step: 222  | total loss: [1m[32m0.41919[0m[0m | time: 6.934s
[2K
| Adam | epoch: 013 | loss: 0.41919 - acc: 0.8213 -- iter: 192/569
[A[ATraining Step: 223  | total loss: [1m[32m0.43236[0m[0m | time: 7.981s
[2K
| Adam | epoch: 013 | loss: 0.43236 - acc: 0.8111 -- iter: 224/569
[A[ATraining Step: 224  | total loss: [1m[32m0.42475[0m[0m | time: 9.083s
[2K
| Adam | epoch: 013 | loss: 0.42475 - acc: 0.8143 -- iter: 256/569
[A[ATraining Step: 225  | total loss: [1m[32m0.41887[0m[0m | time: 10.279s
[2K
| Adam | epoch: 013 | loss: 0.41887 - acc: 0.8141 -- iter: 288/569
[A[ATraining Step: 226  | total loss: [1m[32m0.40442[0m[0m | time: 11.285s
[2K
| Adam | epoch: 013 | loss: 0.40442 - acc: 0.8265 -- iter: 320/569
[A[ATraining Step: 227  | total loss: [1m[32m0.40127[0m[0m | time: 12.089s
[2K
| Adam | epoch: 013 | loss: 0.40127 - acc: 0.8220 -- iter: 352/569
[A[ATraining Step: 228  | total loss: [1m[32m0.38282[0m[0m | time: 13.231s
[2K
| Adam | epoch: 013 | loss: 0.38282 - acc: 0.8358 -- iter: 384/569
[A[ATraining Step: 229  | total loss: [1m[32m0.36600[0m[0m | time: 14.525s
[2K
| Adam | epoch: 013 | loss: 0.36600 - acc: 0.8442 -- iter: 416/569
[A[ATraining Step: 230  | total loss: [1m[32m0.36357[0m[0m | time: 15.800s
[2K
| Adam | epoch: 013 | loss: 0.36357 - acc: 0.8379 -- iter: 448/569
[A[ATraining Step: 231  | total loss: [1m[32m0.37045[0m[0m | time: 16.644s
[2K
| Adam | epoch: 013 | loss: 0.37045 - acc: 0.8291 -- iter: 480/569
[A[ATraining Step: 232  | total loss: [1m[32m0.38128[0m[0m | time: 17.741s
[2K
| Adam | epoch: 013 | loss: 0.38128 - acc: 0.8212 -- iter: 512/569
[A[ATraining Step: 233  | total loss: [1m[32m0.40154[0m[0m | time: 18.738s
[2K
| Adam | epoch: 013 | loss: 0.40154 - acc: 0.8141 -- iter: 544/569
[A[ATraining Step: 234  | total loss: [1m[32m0.39097[0m[0m | time: 20.778s
[2K
| Adam | epoch: 013 | loss: 0.39097 - acc: 0.8170 | val_loss: 0.43991 - val_acc: 0.8034 -- iter: 569/569
--
Training Step: 235  | total loss: [1m[32m0.37816[0m[0m | time: 1.314s
[2K
| Adam | epoch: 014 | loss: 0.37816 - acc: 0.8291 -- iter: 032/569
[A[ATraining Step: 236  | total loss: [1m[32m0.37103[0m[0m | time: 2.262s
[2K
| Adam | epoch: 014 | loss: 0.37103 - acc: 0.8399 -- iter: 064/569
[A[ATraining Step: 237  | total loss: [1m[32m0.36994[0m[0m | time: 3.628s
[2K
| Adam | epoch: 014 | loss: 0.36994 - acc: 0.8403 -- iter: 096/569
[A[ATraining Step: 238  | total loss: [1m[32m0.35651[0m[0m | time: 4.941s
[2K
| Adam | epoch: 014 | loss: 0.35651 - acc: 0.8469 -- iter: 128/569
[A[ATraining Step: 239  | total loss: [1m[32m0.34330[0m[0m | time: 6.231s
[2K
| Adam | epoch: 014 | loss: 0.34330 - acc: 0.8528 -- iter: 160/569
[A[ATraining Step: 240  | total loss: [1m[32m0.33353[0m[0m | time: 7.056s
[2K
| Adam | epoch: 014 | loss: 0.33353 - acc: 0.8582 -- iter: 192/569
[A[ATraining Step: 241  | total loss: [1m[32m0.33844[0m[0m | time: 8.045s
[2K
| Adam | epoch: 014 | loss: 0.33844 - acc: 0.8567 -- iter: 224/569
[A[ATraining Step: 242  | total loss: [1m[32m0.33955[0m[0m | time: 9.123s
[2K
| Adam | epoch: 014 | loss: 0.33955 - acc: 0.8554 -- iter: 256/569
[A[ATraining Step: 243  | total loss: [1m[32m0.32278[0m[0m | time: 10.121s
[2K
| Adam | epoch: 014 | loss: 0.32278 - acc: 0.8636 -- iter: 288/569
[A[ATraining Step: 244  | total loss: [1m[32m0.32826[0m[0m | time: 11.170s
[2K
| Adam | epoch: 014 | loss: 0.32826 - acc: 0.8585 -- iter: 320/569
[A[ATraining Step: 245  | total loss: [1m[32m0.31852[0m[0m | time: 12.432s
[2K
| Adam | epoch: 014 | loss: 0.31852 - acc: 0.8633 -- iter: 352/569
[A[ATraining Step: 246  | total loss: [1m[32m0.31116[0m[0m | time: 13.377s
[2K
| Adam | epoch: 014 | loss: 0.31116 - acc: 0.8613 -- iter: 384/569
[A[ATraining Step: 247  | total loss: [1m[32m0.30977[0m[0m | time: 14.115s
[2K
| Adam | epoch: 014 | loss: 0.30977 - acc: 0.8592 -- iter: 416/569
[A[ATraining Step: 248  | total loss: [1m[32m0.29769[0m[0m | time: 15.556s
[2K
| Adam | epoch: 014 | loss: 0.29769 - acc: 0.8653 -- iter: 448/569
[A[ATraining Step: 249  | total loss: [1m[32m0.29908[0m[0m | time: 16.889s
[2K
| Adam | epoch: 014 | loss: 0.29908 - acc: 0.8631 -- iter: 480/569
[A[ATraining Step: 250  | total loss: [1m[32m0.28284[0m[0m | time: 18.244s
[2K
| Adam | epoch: 014 | loss: 0.28284 - acc: 0.8737 -- iter: 512/569
[A[ATraining Step: 251  | total loss: [1m[32m0.27120[0m[0m | time: 19.148s
[2K
| Adam | epoch: 014 | loss: 0.27120 - acc: 0.8801 -- iter: 544/569
[A[ATraining Step: 252  | total loss: [1m[32m0.26594[0m[0m | time: 21.128s
[2K
| Adam | epoch: 014 | loss: 0.26594 - acc: 0.8796 | val_loss: 0.64720 - val_acc: 0.7584 -- iter: 569/569
--
Training Step: 253  | total loss: [1m[32m0.27812[0m[0m | time: 1.077s
[2K
| Adam | epoch: 015 | loss: 0.27812 - acc: 0.8822 -- iter: 032/569
[A[ATraining Step: 254  | total loss: [1m[32m0.29923[0m[0m | time: 2.226s
[2K
| Adam | epoch: 015 | loss: 0.29923 - acc: 0.8753 -- iter: 064/569
[A[ATraining Step: 255  | total loss: [1m[32m0.29093[0m[0m | time: 3.463s
[2K
| Adam | epoch: 015 | loss: 0.29093 - acc: 0.8752 -- iter: 096/569
[A[ATraining Step: 256  | total loss: [1m[32m0.28043[0m[0m | time: 4.660s
[2K
| Adam | epoch: 015 | loss: 0.28043 - acc: 0.8815 -- iter: 128/569
[A[ATraining Step: 257  | total loss: [1m[32m0.27153[0m[0m | time: 5.787s
[2K
| Adam | epoch: 015 | loss: 0.27153 - acc: 0.8871 -- iter: 160/569
[A[ATraining Step: 258  | total loss: [1m[32m0.25752[0m[0m | time: 7.090s
[2K
| Adam | epoch: 015 | loss: 0.25752 - acc: 0.8921 -- iter: 192/569
[A[ATraining Step: 259  | total loss: [1m[32m0.23775[0m[0m | time: 8.452s
[2K
| Adam | epoch: 015 | loss: 0.23775 - acc: 0.9029 -- iter: 224/569
[A[ATraining Step: 260  | total loss: [1m[32m0.22070[0m[0m | time: 9.514s
[2K
| Adam | epoch: 015 | loss: 0.22070 - acc: 0.9126 -- iter: 256/569
[A[ATraining Step: 261  | total loss: [1m[32m0.20298[0m[0m | time: 10.431s
[2K
| Adam | epoch: 015 | loss: 0.20298 - acc: 0.9213 -- iter: 288/569
[A[ATraining Step: 262  | total loss: [1m[32m0.21257[0m[0m | time: 11.527s
[2K
| Adam | epoch: 015 | loss: 0.21257 - acc: 0.9136 -- iter: 320/569
[A[ATraining Step: 263  | total loss: [1m[32m0.20260[0m[0m | time: 12.617s
[2K
| Adam | epoch: 015 | loss: 0.20260 - acc: 0.9191 -- iter: 352/569
[A[ATraining Step: 264  | total loss: [1m[32m0.19614[0m[0m | time: 13.701s
[2K
| Adam | epoch: 015 | loss: 0.19614 - acc: 0.9241 -- iter: 384/569
[A[ATraining Step: 265  | total loss: [1m[32m0.18795[0m[0m | time: 14.764s
[2K
| Adam | epoch: 015 | loss: 0.18795 - acc: 0.9254 -- iter: 416/569
[A[ATraining Step: 266  | total loss: [1m[32m0.18955[0m[0m | time: 15.766s
[2K
| Adam | epoch: 015 | loss: 0.18955 - acc: 0.9289 -- iter: 448/569
[A[ATraining Step: 267  | total loss: [1m[32m0.18918[0m[0m | time: 16.821s
[2K
| Adam | epoch: 015 | loss: 0.18918 - acc: 0.9320 -- iter: 480/569
[A[ATraining Step: 268  | total loss: [1m[32m0.18495[0m[0m | time: 18.204s
[2K
| Adam | epoch: 015 | loss: 0.18495 - acc: 0.9294 -- iter: 512/569
[A[ATraining Step: 269  | total loss: [1m[32m0.19409[0m[0m | time: 19.646s
[2K
| Adam | epoch: 015 | loss: 0.19409 - acc: 0.9271 -- iter: 544/569
[A[ATraining Step: 270  | total loss: [1m[32m0.18532[0m[0m | time: 21.901s
[2K
| Adam | epoch: 015 | loss: 0.18532 - acc: 0.9313 | val_loss: 0.49289 - val_acc: 0.8146 -- iter: 569/569
--
Validation AUC:0.8945997807017545
Validation AUPRC:0.9395335213052033
Test AUC:0.9363636363636364
Test AUPRC:0.9641697122231706
BestTestF1Score	0.9	0.74	0.88	0.9	0.9	99	11	57	11	0.28
BestTestMCCScore	0.9	0.74	0.88	0.9	0.9	99	11	57	11	0.28
BestTestAccuracyScore	0.9	0.74	0.88	0.9	0.9	99	11	57	11	0.28
BestValidationF1Score	0.88	0.66	0.84	0.88	0.88	100	14	50	14	0.28
BestValidationMCC	0.88	0.66	0.84	0.88	0.88	100	14	50	14	0.28
BestValidationAccuracy	0.88	0.66	0.84	0.88	0.88	100	14	50	14	0.28
TestPredictions (Threshold:0.28)
CHEMBL1649654,FP,INACT,0.5699999928474426	CHEMBL355298,TP,ACT,0.9900000095367432	CHEMBL169566,TP,ACT,0.9900000095367432	CHEMBL543708,TP,ACT,0.5899999737739563	CHEMBL433908,TP,ACT,0.44999998807907104	CHEMBL611036,TN,INACT,0.019999999552965164	CHEMBL57937,TP,ACT,0.9700000286102295	CHEMBL329176,TP,ACT,1.0	CHEMBL300558,TP,ACT,0.9900000095367432	CHEMBL494881,TP,ACT,0.9900000095367432	CHEMBL294561,TP,ACT,1.0	CHEMBL307267,TP,ACT,1.0	CHEMBL147895,TP,ACT,0.9700000286102295	CHEMBL2426076,TN,INACT,0.029999999329447746	CHEMBL39773,TP,ACT,0.9900000095367432	CHEMBL305187,TP,ACT,0.8899999856948853	CHEMBL3823394,TN,INACT,0.10999999940395355	CHEMBL73698,TN,INACT,0.009999999776482582	CHEMBL59011,TP,ACT,0.9800000190734863	CHEMBL2021372,TN,INACT,0.05000000074505806	CHEMBL2440701,TN,INACT,0.03999999910593033	CHEMBL521808,TP,ACT,0.8799999952316284	CHEMBL79556,TP,ACT,0.7300000190734863	CHEMBL424429,TP,ACT,0.8399999737739563	CHEMBL90705,FN,ACT,0.03999999910593033	CHEMBL114823,TN,INACT,0.009999999776482582	CHEMBL144640,TP,ACT,0.6399999856948853	CHEMBL88804,TN,INACT,0.009999999776482582	CHEMBL165149,TP,ACT,0.9800000190734863	CHEMBL494918,TP,ACT,0.9900000095367432	CHEMBL29024,TN,INACT,0.009999999776482582	CHEMBL147146,TP,ACT,1.0	CHEMBL8693,TP,ACT,0.7799999713897705	CHEMBL2425977,TN,INACT,0.0	CHEMBL435473,TP,ACT,0.9900000095367432	CHEMBL334842,TN,INACT,0.009999999776482582	CHEMBL285123,FN,ACT,0.009999999776482582	CHEMBL61740,TP,ACT,1.0	CHEMBL523345,TP,ACT,1.0	CHEMBL164342,TP,ACT,0.9900000095367432	CHEMBL61447,TP,ACT,0.9800000190734863	CHEMBL262537,TP,ACT,1.0	CHEMBL58898,TP,ACT,0.699999988079071	CHEMBL494710,FN,ACT,0.23000000417232513	CHEMBL493078,TP,ACT,1.0	CHEMBL8910,TP,ACT,0.6700000166893005	CHEMBL93062,TP,ACT,1.0	CHEMBL3735472,TN,INACT,0.009999999776482582	CHEMBL42482,TP,ACT,0.9900000095367432	CHEMBL2426085,TN,INACT,0.019999999552965164	CHEMBL301634,TP,ACT,0.6200000047683716	CHEMBL493087,TP,ACT,1.0	CHEMBL424610,TP,ACT,0.9200000166893005	CHEMBL42466,TP,ACT,0.9900000095367432	CHEMBL2426102,TN,INACT,0.009999999776482582	CHEMBL31661,TP,ACT,1.0	CHEMBL63386,FP,INACT,0.6200000047683716	CHEMBL311221,TP,ACT,0.6600000262260437	CHEMBL169264,TN,INACT,0.07999999821186066	CHEMBL77569,TP,ACT,1.0	CHEMBL89477,FP,INACT,0.6700000166893005	CHEMBL2425978,TN,INACT,0.0	CHEMBL113936,TN,INACT,0.019999999552965164	CHEMBL280853,TP,ACT,0.9900000095367432	CHEMBL348558,FP,INACT,0.3100000023841858	CHEMBL198310,TN,INACT,0.009999999776482582	CHEMBL284193,TN,INACT,0.0	CHEMBL1738726,TN,INACT,0.25	CHEMBL148223,TP,ACT,0.6600000262260437	CHEMBL495334,TP,ACT,0.7799999713897705	CHEMBL43412,TN,INACT,0.0	CHEMBL341813,TP,ACT,0.9200000166893005	CHEMBL91677,TN,INACT,0.009999999776482582	CHEMBL164930,TP,ACT,0.9700000286102295	CHEMBL31718,TP,ACT,0.3700000047683716	CHEMBL1332173,TN,INACT,0.15000000596046448	CHEMBL523195,TP,ACT,1.0	CHEMBL83919,TP,ACT,0.9599999785423279	CHEMBL2426104,TN,INACT,0.05000000074505806	CHEMBL291278,TN,INACT,0.2199999988079071	CHEMBL392420,FP,INACT,0.9100000262260437	CHEMBL343429,TP,ACT,0.6499999761581421	CHEMBL771,FN,ACT,0.009999999776482582	CHEMBL302680,TN,INACT,0.03999999910593033	CHEMBL435378,TP,ACT,0.41999998688697815	CHEMBL2426069,TN,INACT,0.07999999821186066	CHEMBL2322997,TN,INACT,0.029999999329447746	CHEMBL89739,FP,INACT,0.8299999833106995	CHEMBL167201,TP,ACT,0.9900000095367432	CHEMBL523502,TP,ACT,1.0	CHEMBL2426096,TN,INACT,0.0	CHEMBL23754,TP,ACT,0.949999988079071	CHEMBL267259,TN,INACT,0.23999999463558197	CHEMBL3088073,TN,INACT,0.03999999910593033	CHEMBL168394,TP,ACT,1.0	CHEMBL164831,TP,ACT,0.33000001311302185	CHEMBL301556,TP,ACT,0.36000001430511475	CHEMBL1649667,FP,INACT,0.7599999904632568	CHEMBL523671,TP,ACT,1.0	CHEMBL492865,TP,ACT,0.8199999928474426	CHEMBL2336586,TN,INACT,0.17000000178813934	CHEMBL291170,TP,ACT,0.8199999928474426	CHEMBL291169,FN,ACT,0.18000000715255737	CHEMBL146836,FN,ACT,0.1599999964237213	CHEMBL147708,TP,ACT,0.9900000095367432	CHEMBL494711,TP,ACT,0.6000000238418579	CHEMBL3799103,TN,INACT,0.0	CHEMBL92143,TP,ACT,1.0	CHEMBL222519,TN,INACT,0.2199999988079071	CHEMBL303080,TP,ACT,0.9900000095367432	CHEMBL492676,TP,ACT,0.9900000095367432	CHEMBL429540,TN,INACT,0.029999999329447746	CHEMBL92005,TP,ACT,0.4399999976158142	CHEMBL83901,TP,ACT,0.5199999809265137	CHEMBL144365,FN,ACT,0.15000000596046448	CHEMBL2426099,TN,INACT,0.009999999776482582	CHEMBL42148,TN,INACT,0.019999999552965164	CHEMBL543689,TP,ACT,0.9599999785423279	CHEMBL2426083,TN,INACT,0.019999999552965164	CHEMBL123259,FP,INACT,0.7900000214576721	CHEMBL480169,TN,INACT,0.009999999776482582	CHEMBL276863,TP,ACT,0.9599999785423279	CHEMBL2312400,TN,INACT,0.009999999776482582	CHEMBL2426095,TN,INACT,0.009999999776482582	CHEMBL419045,TP,ACT,1.0	CHEMBL139982,TP,ACT,0.4699999988079071	CHEMBL518313,TN,INACT,0.009999999776482582	CHEMBL287327,TP,ACT,1.0	CHEMBL351884,TP,ACT,0.9900000095367432	CHEMBL1594422,FP,INACT,0.5	CHEMBL321171,FN,ACT,0.019999999552965164	CHEMBL91698,TP,ACT,1.0	CHEMBL467234,TN,INACT,0.019999999552965164	CHEMBL90625,TN,INACT,0.27000001072883606	CHEMBL329680,TP,ACT,0.8999999761581421	CHEMBL493275,TP,ACT,1.0	CHEMBL83551,TP,ACT,1.0	CHEMBL9790,FN,ACT,0.019999999552965164	CHEMBL168881,TP,ACT,0.9900000095367432	CHEMBL78784,TP,ACT,0.9399999976158142	CHEMBL1835336,TN,INACT,0.07999999821186066	CHEMBL494707,TP,ACT,0.5	CHEMBL10704,TP,ACT,0.9599999785423279	CHEMBL556378,TP,ACT,0.9300000071525574	CHEMBL1555332,FP,INACT,0.41999998688697815	CHEMBL2322996,TN,INACT,0.029999999329447746	CHEMBL11068,TP,ACT,0.9800000190734863	CHEMBL495283,TP,ACT,1.0	CHEMBL2426077,TN,INACT,0.009999999776482582	CHEMBL169368,TP,ACT,0.9900000095367432	CHEMBL298284,TP,ACT,0.9700000286102295	CHEMBL1209591,TN,INACT,0.029999999329447746	CHEMBL14935,TN,INACT,0.05999999865889549	CHEMBL354980,TP,ACT,0.9900000095367432	CHEMBL40745,TP,ACT,1.0	CHEMBL2312403,TN,INACT,0.019999999552965164	CHEMBL300118,TP,ACT,1.0	CHEMBL39881,TP,ACT,0.9700000286102295	CHEMBL493886,TP,ACT,1.0	CHEMBL3633664,TN,INACT,0.10000000149011612	CHEMBL93873,TN,INACT,0.009999999776482582	CHEMBL424499,FN,ACT,0.029999999329447746	CHEMBL264709,FP,INACT,0.5400000214576721	CHEMBL290555,TP,ACT,0.9900000095367432	CHEMBL333463,TP,ACT,0.9900000095367432	CHEMBL147729,TP,ACT,0.9900000095367432	CHEMBL2323552,TN,INACT,0.009999999776482582	CHEMBL492425,TP,ACT,0.6899999976158142	CHEMBL40649,TP,ACT,1.0	CHEMBL10656,FN,ACT,0.05999999865889549	CHEMBL276907,TP,ACT,0.7200000286102295	CHEMBL31741,TP,ACT,0.9800000190734863	CHEMBL3799162,TN,INACT,0.019999999552965164	CHEMBL59299,TN,INACT,0.20999999344348907	CHEMBL3787264,TN,INACT,0.029999999329447746	CHEMBL82050,TP,ACT,0.9900000095367432	CHEMBL154700,TN,INACT,0.009999999776482582	CHEMBL358455,TP,ACT,0.9900000095367432	

