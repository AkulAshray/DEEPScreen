ImageNetInceptionV2 CHEMBL5024 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	135
Number of inactive compounds :	135
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5024_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5024_adam_0.0005_15_0.6/
---------------------------------
Training samples: 169
Validation samples: 54
--
Training Step: 1  | time: 361.065s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/169
[A[ATraining Step: 2  | total loss: [1m[32m0.62273[0m[0m | time: 658.972s
[2K
| Adam | epoch: 001 | loss: 0.62273 - acc: 0.4500 -- iter: 064/169
[A[ATraining Step: 3  | total loss: [1m[32m0.58955[0m[0m | time: 934.096s
[2K
| Adam | epoch: 001 | loss: 0.58955 - acc: 0.6443 -- iter: 096/169
[A[ATraining Step: 4  | total loss: [1m[32m0.62655[0m[0m | time: 974.660s
[2K
| Adam | epoch: 001 | loss: 0.62655 - acc: 0.6533 -- iter: 128/169
[A[ATraining Step: 5  | total loss: [1m[32m0.46443[0m[0m | time: 995.398s
[2K
| Adam | epoch: 001 | loss: 0.46443 - acc: 0.8068 -- iter: 160/169
[A[ATraining Step: 6  | total loss: [1m[32m0.41194[0m[0m | time: 1007.913s
[2K
| Adam | epoch: 001 | loss: 0.41194 - acc: 0.8707 | val_loss: 1.04844 - val_acc: 0.4074 -- iter: 169/169
--
Training Step: 7  | total loss: [1m[32m0.70095[0m[0m | time: 3.256s
[2K
| Adam | epoch: 002 | loss: 0.70095 - acc: 0.6816 -- iter: 032/169
[A[ATraining Step: 8  | total loss: [1m[32m0.47224[0m[0m | time: 31.544s
[2K
| Adam | epoch: 002 | loss: 0.47224 - acc: 0.7982 -- iter: 064/169
[A[ATraining Step: 9  | total loss: [1m[32m0.44800[0m[0m | time: 71.010s
[2K
| Adam | epoch: 002 | loss: 0.44800 - acc: 0.8223 -- iter: 096/169
[A[ATraining Step: 10  | total loss: [1m[32m0.31668[0m[0m | time: 79.829s
[2K
| Adam | epoch: 002 | loss: 0.31668 - acc: 0.9112 -- iter: 128/169
[A[ATraining Step: 11  | total loss: [1m[32m0.32370[0m[0m | time: 108.170s
[2K
| Adam | epoch: 002 | loss: 0.32370 - acc: 0.8792 -- iter: 160/169
[A[ATraining Step: 12  | total loss: [1m[32m0.25412[0m[0m | time: 119.345s
[2K
| Adam | epoch: 002 | loss: 0.25412 - acc: 0.8773 | val_loss: 1.95277 - val_acc: 0.4074 -- iter: 169/169
--
Training Step: 13  | total loss: [1m[32m0.22244[0m[0m | time: 3.195s
[2K
| Adam | epoch: 003 | loss: 0.22244 - acc: 0.8897 -- iter: 032/169
[A[ATraining Step: 14  | total loss: [1m[32m0.17240[0m[0m | time: 6.471s
[2K
| Adam | epoch: 003 | loss: 0.17240 - acc: 0.9348 -- iter: 064/169
[A[ATraining Step: 15  | total loss: [1m[32m0.10819[0m[0m | time: 25.608s
[2K
| Adam | epoch: 003 | loss: 0.10819 - acc: 0.9603 -- iter: 096/169
[A[ATraining Step: 16  | total loss: [1m[32m0.14918[0m[0m | time: 59.588s
[2K
| Adam | epoch: 003 | loss: 0.14918 - acc: 0.9635 -- iter: 128/169
[A[ATraining Step: 17  | total loss: [1m[32m0.13812[0m[0m | time: 94.484s
[2K
| Adam | epoch: 003 | loss: 0.13812 - acc: 0.9654 -- iter: 160/169
[A[ATraining Step: 18  | total loss: [1m[32m0.09847[0m[0m | time: 105.534s
[2K
| Adam | epoch: 003 | loss: 0.09847 - acc: 0.9774 | val_loss: 2.55021 - val_acc: 0.5926 -- iter: 169/169
--
Training Step: 19  | total loss: [1m[32m0.18338[0m[0m | time: 8.752s
[2K
| Adam | epoch: 004 | loss: 0.18338 - acc: 0.9537 -- iter: 032/169
[A[ATraining Step: 20  | total loss: [1m[32m0.32956[0m[0m | time: 11.783s
[2K
| Adam | epoch: 004 | loss: 0.32956 - acc: 0.8982 -- iter: 064/169
[A[ATraining Step: 21  | total loss: [1m[32m0.23964[0m[0m | time: 14.937s
[2K
| Adam | epoch: 004 | loss: 0.23964 - acc: 0.9298 -- iter: 096/169
[A[ATraining Step: 22  | total loss: [1m[32m0.17104[0m[0m | time: 23.955s
[2K
| Adam | epoch: 004 | loss: 0.17104 - acc: 0.9509 -- iter: 128/169
[A[ATraining Step: 23  | total loss: [1m[32m0.14085[0m[0m | time: 44.342s
[2K
| Adam | epoch: 004 | loss: 0.14085 - acc: 0.9561 -- iter: 160/169
[A[ATraining Step: 24  | total loss: [1m[32m0.22299[0m[0m | time: 55.315s
[2K
| Adam | epoch: 004 | loss: 0.22299 - acc: 0.9421 | val_loss: 1.40341 - val_acc: 0.4074 -- iter: 169/169
--
Training Step: 25  | total loss: [1m[32m0.22422[0m[0m | time: 8.994s
[2K
| Adam | epoch: 005 | loss: 0.22422 - acc: 0.9408 -- iter: 032/169
[A[ATraining Step: 26  | total loss: [1m[32m0.21280[0m[0m | time: 22.631s
[2K
| Adam | epoch: 005 | loss: 0.21280 - acc: 0.9482 -- iter: 064/169
[A[ATraining Step: 27  | total loss: [1m[32m0.16996[0m[0m | time: 25.824s
[2K
| Adam | epoch: 005 | loss: 0.16996 - acc: 0.9615 -- iter: 096/169
[A[ATraining Step: 28  | total loss: [1m[32m0.18364[0m[0m | time: 29.049s
[2K
| Adam | epoch: 005 | loss: 0.18364 - acc: 0.9434 -- iter: 128/169
[A[ATraining Step: 29  | total loss: [1m[32m0.14473[0m[0m | time: 40.461s
[2K
| Adam | epoch: 005 | loss: 0.14473 - acc: 0.9571 -- iter: 160/169
[A[ATraining Step: 30  | total loss: [1m[32m0.15327[0m[0m | time: 51.635s
[2K
| Adam | epoch: 005 | loss: 0.15327 - acc: 0.9377 | val_loss: 0.67541 - val_acc: 0.5926 -- iter: 169/169
--
Training Step: 31  | total loss: [1m[32m0.12692[0m[0m | time: 8.970s
[2K
| Adam | epoch: 006 | loss: 0.12692 - acc: 0.9521 -- iter: 032/169
[A[ATraining Step: 32  | total loss: [1m[32m0.10559[0m[0m | time: 17.837s
[2K
| Adam | epoch: 006 | loss: 0.10559 - acc: 0.9629 -- iter: 064/169
[A[ATraining Step: 33  | total loss: [1m[32m0.09603[0m[0m | time: 26.745s
[2K
| Adam | epoch: 006 | loss: 0.09603 - acc: 0.9641 -- iter: 096/169
[A[ATraining Step: 34  | total loss: [1m[32m0.08696[0m[0m | time: 29.827s
[2K
| Adam | epoch: 006 | loss: 0.08696 - acc: 0.9718 -- iter: 128/169
[A[ATraining Step: 35  | total loss: [1m[32m0.07753[0m[0m | time: 33.105s
[2K
| Adam | epoch: 006 | loss: 0.07753 - acc: 0.9777 -- iter: 160/169
[A[ATraining Step: 36  | total loss: [1m[32m0.06509[0m[0m | time: 53.222s
[2K
| Adam | epoch: 006 | loss: 0.06509 - acc: 0.9823 | val_loss: 0.89869 - val_acc: 0.4074 -- iter: 169/169
--
Training Step: 37  | total loss: [1m[32m0.06397[0m[0m | time: 9.298s
[2K
| Adam | epoch: 007 | loss: 0.06397 - acc: 0.9858 -- iter: 032/169
[A[ATraining Step: 38  | total loss: [1m[32m0.09576[0m[0m | time: 25.637s
[2K
| Adam | epoch: 007 | loss: 0.09576 - acc: 0.9825 -- iter: 064/169
[A[ATraining Step: 39  | total loss: [1m[32m0.07959[0m[0m | time: 34.487s
[2K
| Adam | epoch: 007 | loss: 0.07959 - acc: 0.9858 -- iter: 096/169
[A[ATraining Step: 40  | total loss: [1m[32m0.07486[0m[0m | time: 58.352s
[2K
| Adam | epoch: 007 | loss: 0.07486 - acc: 0.9826 -- iter: 128/169
[A[ATraining Step: 41  | total loss: [1m[32m0.06362[0m[0m | time: 61.739s
[2K
| Adam | epoch: 007 | loss: 0.06362 - acc: 0.9858 -- iter: 160/169
[A[ATraining Step: 42  | total loss: [1m[32m0.05315[0m[0m | time: 67.783s
[2K
| Adam | epoch: 007 | loss: 0.05315 - acc: 0.9884 | val_loss: 1.11358 - val_acc: 0.4074 -- iter: 169/169
--
Training Step: 43  | total loss: [1m[32m0.04480[0m[0m | time: 22.377s
[2K
| Adam | epoch: 008 | loss: 0.04480 - acc: 0.9904 -- iter: 032/169
[A[ATraining Step: 44  | total loss: [1m[32m0.06050[0m[0m | time: 31.665s
[2K
| Adam | epoch: 008 | loss: 0.06050 - acc: 0.9759 -- iter: 064/169
[A[ATraining Step: 45  | total loss: [1m[32m0.12006[0m[0m | time: 41.553s
[2K
| Adam | epoch: 008 | loss: 0.12006 - acc: 0.9693 -- iter: 096/169
[A[ATraining Step: 46  | total loss: [1m[32m0.11390[0m[0m | time: 50.873s
[2K
| Adam | epoch: 008 | loss: 0.11390 - acc: 0.9640 -- iter: 128/169
[A[ATraining Step: 47  | total loss: [1m[32m0.11763[0m[0m | time: 65.422s
[2K
| Adam | epoch: 008 | loss: 0.11763 - acc: 0.9648 -- iter: 160/169
[A[ATraining Step: 48  | total loss: [1m[32m0.10300[0m[0m | time: 71.575s
[2K
| Adam | epoch: 008 | loss: 0.10300 - acc: 0.9705 | val_loss: 2.03773 - val_acc: 0.4259 -- iter: 169/169
--
Training Step: 49  | total loss: [1m[32m0.09171[0m[0m | time: 3.151s
[2K
| Adam | epoch: 009 | loss: 0.09171 - acc: 0.9751 -- iter: 032/169
[A[ATraining Step: 50  | total loss: [1m[32m0.07854[0m[0m | time: 12.235s
[2K
| Adam | epoch: 009 | loss: 0.07854 - acc: 0.9790 -- iter: 064/169
[A[ATraining Step: 51  | total loss: [1m[32m0.11835[0m[0m | time: 21.283s
[2K
| Adam | epoch: 009 | loss: 0.11835 - acc: 0.9631 -- iter: 096/169
[A[ATraining Step: 52  | total loss: [1m[32m0.13923[0m[0m | time: 30.446s
[2K
| Adam | epoch: 009 | loss: 0.13923 - acc: 0.9593 -- iter: 128/169
[A[ATraining Step: 53  | total loss: [1m[32m0.12405[0m[0m | time: 59.128s
[2K
| Adam | epoch: 009 | loss: 0.12405 - acc: 0.9653 -- iter: 160/169
[A[ATraining Step: 54  | total loss: [1m[32m0.13140[0m[0m | time: 71.741s
[2K
| Adam | epoch: 009 | loss: 0.13140 - acc: 0.9613 | val_loss: 0.30137 - val_acc: 0.8333 -- iter: 169/169
--
Training Step: 55  | total loss: [1m[32m0.14613[0m[0m | time: 3.143s
[2K
| Adam | epoch: 010 | loss: 0.14613 - acc: 0.9534 -- iter: 032/169
[A[ATraining Step: 56  | total loss: [1m[32m0.13645[0m[0m | time: 6.403s
[2K
| Adam | epoch: 010 | loss: 0.13645 - acc: 0.9600 -- iter: 064/169
[A[ATraining Step: 57  | total loss: [1m[32m0.11923[0m[0m | time: 15.416s
[2K
| Adam | epoch: 010 | loss: 0.11923 - acc: 0.9655 -- iter: 096/169
[A[ATraining Step: 58  | total loss: [1m[32m0.10742[0m[0m | time: 24.535s
[2K
| Adam | epoch: 010 | loss: 0.10742 - acc: 0.9702 -- iter: 128/169
[A[ATraining Step: 59  | total loss: [1m[32m0.10851[0m[0m | time: 44.242s
[2K
| Adam | epoch: 010 | loss: 0.10851 - acc: 0.9700 -- iter: 160/169
[A[ATraining Step: 60  | total loss: [1m[32m0.10339[0m[0m | time: 73.324s
[2K
| Adam | epoch: 010 | loss: 0.10339 - acc: 0.9740 | val_loss: 0.26363 - val_acc: 0.8704 -- iter: 169/169
--
Training Step: 61  | total loss: [1m[32m0.10366[0m[0m | time: 9.052s
[2K
| Adam | epoch: 011 | loss: 0.10366 - acc: 0.9733 -- iter: 032/169
[A[ATraining Step: 62  | total loss: [1m[32m0.09682[0m[0m | time: 12.378s
[2K
| Adam | epoch: 011 | loss: 0.09682 - acc: 0.9727 -- iter: 064/169
[A[ATraining Step: 63  | total loss: [1m[32m0.09727[0m[0m | time: 15.602s
[2K
| Adam | epoch: 011 | loss: 0.09727 - acc: 0.9762 -- iter: 096/169
[A[ATraining Step: 64  | total loss: [1m[32m0.09034[0m[0m | time: 27.837s
[2K
| Adam | epoch: 011 | loss: 0.09034 - acc: 0.9791 -- iter: 128/169
[A[ATraining Step: 65  | total loss: [1m[32m0.08045[0m[0m | time: 37.740s
[2K
| Adam | epoch: 011 | loss: 0.08045 - acc: 0.9817 -- iter: 160/169
[A[ATraining Step: 66  | total loss: [1m[32m0.09581[0m[0m | time: 55.702s
[2K
| Adam | epoch: 011 | loss: 0.09581 - acc: 0.9801 | val_loss: 2.37973 - val_acc: 0.4630 -- iter: 169/169
--
Training Step: 67  | total loss: [1m[32m0.08650[0m[0m | time: 8.998s
[2K
| Adam | epoch: 012 | loss: 0.08650 - acc: 0.9825 -- iter: 032/169
[A[ATraining Step: 68  | total loss: [1m[32m0.07698[0m[0m | time: 18.255s
[2K
| Adam | epoch: 012 | loss: 0.07698 - acc: 0.9846 -- iter: 064/169
[A[ATraining Step: 69  | total loss: [1m[32m0.07101[0m[0m | time: 21.462s
[2K
| Adam | epoch: 012 | loss: 0.07101 - acc: 0.9864 -- iter: 096/169
[A[ATraining Step: 70  | total loss: [1m[32m0.07223[0m[0m | time: 24.793s
[2K
| Adam | epoch: 012 | loss: 0.07223 - acc: 0.9880 -- iter: 128/169
[A[ATraining Step: 71  | total loss: [1m[32m0.06606[0m[0m | time: 34.212s
[2K
| Adam | epoch: 012 | loss: 0.06606 - acc: 0.9893 -- iter: 160/169
[A[ATraining Step: 72  | total loss: [1m[32m0.05941[0m[0m | time: 46.259s
[2K
| Adam | epoch: 012 | loss: 0.05941 - acc: 0.9905 | val_loss: 0.41257 - val_acc: 0.8148 -- iter: 169/169
--
Training Step: 73  | total loss: [1m[32m0.05376[0m[0m | time: 11.908s
[2K
| Adam | epoch: 013 | loss: 0.05376 - acc: 0.9916 -- iter: 032/169
[A[ATraining Step: 74  | total loss: [1m[32m0.06755[0m[0m | time: 21.051s
[2K
| Adam | epoch: 013 | loss: 0.06755 - acc: 0.9857 -- iter: 064/169
[A[ATraining Step: 75  | total loss: [1m[32m0.06063[0m[0m | time: 29.897s
[2K
| Adam | epoch: 013 | loss: 0.06063 - acc: 0.9872 -- iter: 096/169
[A[ATraining Step: 76  | total loss: [1m[32m0.05565[0m[0m | time: 33.099s
[2K
| Adam | epoch: 013 | loss: 0.05565 - acc: 0.9886 -- iter: 128/169
[A[ATraining Step: 77  | total loss: [1m[32m0.08905[0m[0m | time: 36.268s
[2K
| Adam | epoch: 013 | loss: 0.08905 - acc: 0.9780 -- iter: 160/169
[A[ATraining Step: 78  | total loss: [1m[32m0.08284[0m[0m | time: 48.031s
[2K
| Adam | epoch: 013 | loss: 0.08284 - acc: 0.9803 | val_loss: 1.39478 - val_acc: 0.7222 -- iter: 169/169
--
Training Step: 79  | total loss: [1m[32m0.08105[0m[0m | time: 9.029s
[2K
| Adam | epoch: 014 | loss: 0.08105 - acc: 0.9791 -- iter: 032/169
[A[ATraining Step: 80  | total loss: [1m[32m0.09056[0m[0m | time: 22.926s
[2K
| Adam | epoch: 014 | loss: 0.09056 - acc: 0.9781 -- iter: 064/169
[A[ATraining Step: 81  | total loss: [1m[32m0.09163[0m[0m | time: 31.856s
[2K
| Adam | epoch: 014 | loss: 0.09163 - acc: 0.9771 -- iter: 096/169
[A[ATraining Step: 82  | total loss: [1m[32m0.08451[0m[0m | time: 40.712s
[2K
| Adam | epoch: 014 | loss: 0.08451 - acc: 0.9794 -- iter: 128/169
[A[ATraining Step: 83  | total loss: [1m[32m0.07648[0m[0m | time: 43.958s
[2K
| Adam | epoch: 014 | loss: 0.07648 - acc: 0.9815 -- iter: 160/169
[A[ATraining Step: 84  | total loss: [1m[32m0.06982[0m[0m | time: 49.784s
[2K
| Adam | epoch: 014 | loss: 0.06982 - acc: 0.9833 | val_loss: 0.62623 - val_acc: 0.7963 -- iter: 169/169
--
Training Step: 85  | total loss: [1m[32m0.06376[0m[0m | time: 9.097s
[2K
| Adam | epoch: 015 | loss: 0.06376 - acc: 0.9850 -- iter: 032/169
[A[ATraining Step: 86  | total loss: [1m[32m0.05788[0m[0m | time: 23.418s
[2K
| Adam | epoch: 015 | loss: 0.05788 - acc: 0.9865 -- iter: 064/169
[A[ATraining Step: 87  | total loss: [1m[32m0.08752[0m[0m | time: 33.390s
[2K
| Adam | epoch: 015 | loss: 0.08752 - acc: 0.9816 -- iter: 096/169
[A[ATraining Step: 88  | total loss: [1m[32m0.08302[0m[0m | time: 42.494s
[2K
| Adam | epoch: 015 | loss: 0.08302 - acc: 0.9834 -- iter: 128/169
[A[ATraining Step: 89  | total loss: [1m[32m0.08289[0m[0m | time: 51.318s
[2K
| Adam | epoch: 015 | loss: 0.08289 - acc: 0.9820 -- iter: 160/169
[A[ATraining Step: 90  | total loss: [1m[32m0.07688[0m[0m | time: 57.250s
[2K
| Adam | epoch: 015 | loss: 0.07688 - acc: 0.9838 | val_loss: 0.64228 - val_acc: 0.7963 -- iter: 169/169
--
Validation AUC:0.9460227272727272
Validation AUPRC:0.9660422965460636
Test AUC:0.9793956043956044
Test AUPRC:0.9826049385271349
BestTestF1Score	0.87	0.74	0.87	0.89	0.86	24	3	23	4	0.95
BestTestMCCScore	0.92	0.86	0.93	1.0	0.86	24	0	26	4	1.0
BestTestAccuracyScore	0.92	0.86	0.93	1.0	0.86	24	0	26	4	1.0
BestValidationF1Score	0.89	0.73	0.87	0.88	0.91	29	4	18	3	0.95
BestValidationMCC	0.88	0.75	0.87	0.96	0.81	26	1	21	6	1.0
BestValidationAccuracy	0.88	0.75	0.87	0.96	0.81	26	1	21	6	1.0
TestPredictions (Threshold:1.0)
CHEMBL2325695,TP,ACT,1.0	CHEMBL3600686,TN,INACT,0.019999999552965164	CHEMBL3355476,FN,ACT,0.8299999833106995	CHEMBL3589320,TN,INACT,0.12999999523162842	CHEMBL1241389,TN,INACT,0.019999999552965164	CHEMBL1242109,TN,INACT,0.019999999552965164	CHEMBL1241487,TN,INACT,0.009999999776482582	CHEMBL3355469,FN,ACT,0.9200000166893005	CHEMBL173928,TN,INACT,0.09000000357627869	CHEMBL3648330,TP,ACT,1.0	CHEMBL1242850,TN,INACT,0.009999999776482582	CHEMBL1766798,TP,ACT,1.0	CHEMBL3355069,TP,ACT,1.0	CHEMBL58782,TN,INACT,0.0	CHEMBL2030436,TP,ACT,1.0	CHEMBL1242849,TN,INACT,0.7300000190734863	CHEMBL1242660,TN,INACT,0.0	CHEMBL3355070,TP,ACT,1.0	CHEMBL2325722,TP,ACT,1.0	CHEMBL3648328,TP,ACT,1.0	CHEMBL3355074,TP,ACT,1.0	CHEMBL3600769,TN,INACT,0.10000000149011612	CHEMBL1766777,TP,ACT,1.0	CHEMBL3355078,TP,ACT,1.0	CHEMBL2325710,TP,ACT,1.0	CHEMBL1241491,TN,INACT,0.7200000286102295	CHEMBL1766780,TP,ACT,1.0	CHEMBL1241859,TN,INACT,0.0	CHEMBL2325716,TP,ACT,1.0	CHEMBL2325696,TP,ACT,1.0	CHEMBL2409216,TP,ACT,1.0	CHEMBL2158430,TN,INACT,0.18000000715255737	CHEMBL1241769,TN,INACT,0.0	CHEMBL2418960,TN,INACT,0.0	CHEMBL1241441,TN,INACT,0.0	CHEMBL1766768,TP,ACT,1.0	CHEMBL1241488,TN,INACT,0.7099999785423279	CHEMBL2325439,TP,ACT,1.0	CHEMBL1760160,TN,INACT,0.33000001311302185	CHEMBL453232,TN,INACT,0.9900000095367432	CHEMBL1241390,TN,INACT,0.019999999552965164	CHEMBL3334621,FN,ACT,0.8600000143051147	CHEMBL3695214,TP,ACT,1.0	CHEMBL1766783,TP,ACT,1.0	CHEMBL1242025,TN,INACT,0.9900000095367432	CHEMBL1766799,TP,ACT,1.0	CHEMBL1766802,TP,ACT,1.0	CHEMBL2325721,FN,ACT,0.5899999737739563	CHEMBL1242473,TN,INACT,0.029999999329447746	CHEMBL1231371,TN,INACT,0.10999999940395355	CHEMBL3355479,TP,ACT,1.0	CHEMBL3648334,TP,ACT,1.0	CHEMBL1242474,TN,INACT,0.9700000286102295	CHEMBL379156,TN,INACT,0.019999999552965164	

