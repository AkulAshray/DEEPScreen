ImageNetInceptionV2 CHEMBL5804 adam 0.0005 30 0 0 0.6 False True
Number of active compounds :	189
Number of inactive compounds :	133
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5804_adam_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5804_adam_0.0005_30_0.6/
---------------------------------
Training samples: 205
Validation samples: 65
--
Training Step: 1  | time: 425.778s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/205
[A[ATraining Step: 2  | total loss: [1m[32m0.60612[0m[0m | time: 594.081s
[2K
| Adam | epoch: 001 | loss: 0.60612 - acc: 0.5344 -- iter: 064/205
[A[ATraining Step: 3  | total loss: [1m[32m0.66883[0m[0m | time: 726.387s
[2K
| Adam | epoch: 001 | loss: 0.66883 - acc: 0.6341 -- iter: 096/205
[A[ATraining Step: 4  | total loss: [1m[32m0.91896[0m[0m | time: 785.894s
[2K
| Adam | epoch: 001 | loss: 0.91896 - acc: 0.5804 -- iter: 128/205
[A[ATraining Step: 5  | total loss: [1m[32m0.81025[0m[0m | time: 813.856s
[2K
| Adam | epoch: 001 | loss: 0.81025 - acc: 0.6113 -- iter: 160/205
[A[ATraining Step: 6  | total loss: [1m[32m0.75754[0m[0m | time: 888.543s
[2K
| Adam | epoch: 001 | loss: 0.75754 - acc: 0.6000 -- iter: 192/205
[A[ATraining Step: 7  | total loss: [1m[32m0.75415[0m[0m | time: 910.530s
[2K
| Adam | epoch: 001 | loss: 0.75415 - acc: 0.5963 | val_loss: 0.90208 - val_acc: 0.4000 -- iter: 205/205
--
Training Step: 8  | total loss: [1m[32m0.66261[0m[0m | time: 17.138s
[2K
| Adam | epoch: 002 | loss: 0.66261 - acc: 0.6070 -- iter: 032/205
[A[ATraining Step: 9  | total loss: [1m[32m0.45814[0m[0m | time: 34.701s
[2K
| Adam | epoch: 002 | loss: 0.45814 - acc: 0.8151 -- iter: 064/205
[A[ATraining Step: 10  | total loss: [1m[32m0.53699[0m[0m | time: 55.583s
[2K
| Adam | epoch: 002 | loss: 0.53699 - acc: 0.7200 -- iter: 096/205
[A[ATraining Step: 11  | total loss: [1m[32m0.54798[0m[0m | time: 113.967s
[2K
| Adam | epoch: 002 | loss: 0.54798 - acc: 0.7342 -- iter: 128/205
[A[ATraining Step: 12  | total loss: [1m[32m0.53322[0m[0m | time: 135.564s
[2K
| Adam | epoch: 002 | loss: 0.53322 - acc: 0.7413 -- iter: 160/205
[A[ATraining Step: 13  | total loss: [1m[32m0.57533[0m[0m | time: 195.734s
[2K
| Adam | epoch: 002 | loss: 0.57533 - acc: 0.7049 -- iter: 192/205
[A[ATraining Step: 14  | total loss: [1m[32m0.54150[0m[0m | time: 276.500s
[2K
| Adam | epoch: 002 | loss: 0.54150 - acc: 0.7105 | val_loss: 0.74954 - val_acc: 0.6000 -- iter: 205/205
--
Training Step: 15  | total loss: [1m[32m0.54052[0m[0m | time: 7.068s
[2K
| Adam | epoch: 003 | loss: 0.54052 - acc: 0.7015 -- iter: 032/205
[A[ATraining Step: 16  | total loss: [1m[32m0.42939[0m[0m | time: 14.084s
[2K
| Adam | epoch: 003 | loss: 0.42939 - acc: 0.7846 -- iter: 064/205
[A[ATraining Step: 17  | total loss: [1m[32m0.31304[0m[0m | time: 55.462s
[2K
| Adam | epoch: 003 | loss: 0.31304 - acc: 0.8621 -- iter: 096/205
[A[ATraining Step: 18  | total loss: [1m[32m0.31296[0m[0m | time: 112.988s
[2K
| Adam | epoch: 003 | loss: 0.31296 - acc: 0.8450 -- iter: 128/205
[A[ATraining Step: 19  | total loss: [1m[32m0.26999[0m[0m | time: 146.652s
[2K
| Adam | epoch: 003 | loss: 0.26999 - acc: 0.8862 -- iter: 160/205
[A[ATraining Step: 20  | total loss: [1m[32m0.22049[0m[0m | time: 166.480s
[2K
| Adam | epoch: 003 | loss: 0.22049 - acc: 0.9128 -- iter: 192/205
[A[ATraining Step: 21  | total loss: [1m[32m0.21523[0m[0m | time: 185.705s
[2K
| Adam | epoch: 003 | loss: 0.21523 - acc: 0.9107 | val_loss: 0.77524 - val_acc: 0.6000 -- iter: 205/205
--
Training Step: 22  | total loss: [1m[32m0.22681[0m[0m | time: 17.728s
[2K
| Adam | epoch: 004 | loss: 0.22681 - acc: 0.9094 -- iter: 032/205
[A[ATraining Step: 23  | total loss: [1m[32m0.22213[0m[0m | time: 24.957s
[2K
| Adam | epoch: 004 | loss: 0.22213 - acc: 0.9175 -- iter: 064/205
[A[ATraining Step: 24  | total loss: [1m[32m0.30531[0m[0m | time: 31.574s
[2K
| Adam | epoch: 004 | loss: 0.30531 - acc: 0.9191 -- iter: 096/205
[A[ATraining Step: 25  | total loss: [1m[32m0.23332[0m[0m | time: 78.440s
[2K
| Adam | epoch: 004 | loss: 0.23332 - acc: 0.9412 -- iter: 128/205
[A[ATraining Step: 26  | total loss: [1m[32m0.19812[0m[0m | time: 125.696s
[2K
| Adam | epoch: 004 | loss: 0.19812 - acc: 0.9485 -- iter: 160/205
[A[ATraining Step: 27  | total loss: [1m[32m0.17214[0m[0m | time: 139.264s
[2K
| Adam | epoch: 004 | loss: 0.17214 - acc: 0.9537 -- iter: 192/205
[A[ATraining Step: 28  | total loss: [1m[32m0.13908[0m[0m | time: 162.126s
[2K
| Adam | epoch: 004 | loss: 0.13908 - acc: 0.9653 | val_loss: 0.75120 - val_acc: 0.6000 -- iter: 205/205
--
Training Step: 29  | total loss: [1m[32m0.12057[0m[0m | time: 15.283s
[2K
| Adam | epoch: 005 | loss: 0.12057 - acc: 0.9661 -- iter: 032/205
[A[ATraining Step: 30  | total loss: [1m[32m0.12120[0m[0m | time: 29.197s
[2K
| Adam | epoch: 005 | loss: 0.12120 - acc: 0.9593 -- iter: 064/205
[A[ATraining Step: 31  | total loss: [1m[32m0.10225[0m[0m | time: 35.697s
[2K
| Adam | epoch: 005 | loss: 0.10225 - acc: 0.9687 -- iter: 096/205
[A[ATraining Step: 32  | total loss: [1m[32m0.11436[0m[0m | time: 42.994s
[2K
| Adam | epoch: 005 | loss: 0.11436 - acc: 0.9584 -- iter: 128/205
[A[ATraining Step: 33  | total loss: [1m[32m0.09570[0m[0m | time: 57.806s
[2K
| Adam | epoch: 005 | loss: 0.09570 - acc: 0.9676 -- iter: 160/205
[A[ATraining Step: 34  | total loss: [1m[32m0.07788[0m[0m | time: 71.629s
[2K
| Adam | epoch: 005 | loss: 0.07788 - acc: 0.9745 -- iter: 192/205
[A[ATraining Step: 35  | total loss: [1m[32m0.06885[0m[0m | time: 90.533s
[2K
| Adam | epoch: 005 | loss: 0.06885 - acc: 0.9799 | val_loss: 1.21521 - val_acc: 0.6000 -- iter: 205/205
--
Training Step: 36  | total loss: [1m[32m0.06363[0m[0m | time: 14.431s
[2K
| Adam | epoch: 006 | loss: 0.06363 - acc: 0.9776 -- iter: 032/205
[A[ATraining Step: 37  | total loss: [1m[32m0.05413[0m[0m | time: 33.097s
[2K
| Adam | epoch: 006 | loss: 0.05413 - acc: 0.9821 -- iter: 064/205
[A[ATraining Step: 38  | total loss: [1m[32m0.04968[0m[0m | time: 46.501s
[2K
| Adam | epoch: 006 | loss: 0.04968 - acc: 0.9856 -- iter: 096/205
[A[ATraining Step: 39  | total loss: [1m[32m0.04445[0m[0m | time: 53.364s
[2K
| Adam | epoch: 006 | loss: 0.04445 - acc: 0.9883 -- iter: 128/205
[A[ATraining Step: 40  | total loss: [1m[32m0.13219[0m[0m | time: 60.392s
[2K
| Adam | epoch: 006 | loss: 0.13219 - acc: 0.9617 -- iter: 160/205
[A[ATraining Step: 41  | total loss: [1m[32m0.10880[0m[0m | time: 74.192s
[2K
| Adam | epoch: 006 | loss: 0.10880 - acc: 0.9687 -- iter: 192/205
[A[ATraining Step: 42  | total loss: [1m[32m0.09173[0m[0m | time: 93.232s
[2K
| Adam | epoch: 006 | loss: 0.09173 - acc: 0.9743 | val_loss: 2.67424 - val_acc: 0.6000 -- iter: 205/205
--
Training Step: 43  | total loss: [1m[32m0.07858[0m[0m | time: 40.414s
[2K
| Adam | epoch: 007 | loss: 0.07858 - acc: 0.9789 -- iter: 032/205
[A[ATraining Step: 44  | total loss: [1m[32m0.07627[0m[0m | time: 79.742s
[2K
| Adam | epoch: 007 | loss: 0.07627 - acc: 0.9771 -- iter: 064/205
[A[ATraining Step: 45  | total loss: [1m[32m0.06487[0m[0m | time: 94.119s
[2K
| Adam | epoch: 007 | loss: 0.06487 - acc: 0.9810 -- iter: 096/205
[A[ATraining Step: 46  | total loss: [1m[32m0.05685[0m[0m | time: 108.768s
[2K
| Adam | epoch: 007 | loss: 0.05685 - acc: 0.9842 -- iter: 128/205
[A[ATraining Step: 47  | total loss: [1m[32m0.05565[0m[0m | time: 116.225s
[2K
| Adam | epoch: 007 | loss: 0.05565 - acc: 0.9868 -- iter: 160/205
[A[ATraining Step: 48  | total loss: [1m[32m0.05098[0m[0m | time: 123.877s
[2K
| Adam | epoch: 007 | loss: 0.05098 - acc: 0.9889 -- iter: 192/205
[A[ATraining Step: 49  | total loss: [1m[32m0.04401[0m[0m | time: 144.592s
[2K
| Adam | epoch: 007 | loss: 0.04401 - acc: 0.9906 | val_loss: 3.90935 - val_acc: 0.6000 -- iter: 205/205
--
Training Step: 50  | total loss: [1m[32m0.05154[0m[0m | time: 8.811s
[2K
| Adam | epoch: 008 | loss: 0.05154 - acc: 0.9775 -- iter: 032/205
[A[ATraining Step: 51  | total loss: [1m[32m0.04945[0m[0m | time: 24.837s
[2K
| Adam | epoch: 008 | loss: 0.04945 - acc: 0.9810 -- iter: 064/205
[A[ATraining Step: 52  | total loss: [1m[32m0.05434[0m[0m | time: 38.349s
[2K
| Adam | epoch: 008 | loss: 0.05434 - acc: 0.9745 -- iter: 096/205
[A[ATraining Step: 53  | total loss: [1m[32m0.04856[0m[0m | time: 51.984s
[2K
| Adam | epoch: 008 | loss: 0.04856 - acc: 0.9782 -- iter: 128/205
[A[ATraining Step: 54  | total loss: [1m[32m0.05902[0m[0m | time: 65.356s
[2K
| Adam | epoch: 008 | loss: 0.05902 - acc: 0.9723 -- iter: 160/205
[A[ATraining Step: 55  | total loss: [1m[32m0.06883[0m[0m | time: 71.937s
[2K
| Adam | epoch: 008 | loss: 0.06883 - acc: 0.9718 -- iter: 192/205
[A[ATraining Step: 56  | total loss: [1m[32m0.13881[0m[0m | time: 82.902s
[2K
| Adam | epoch: 008 | loss: 0.13881 - acc: 0.9541 | val_loss: 6.11598 - val_acc: 0.6000 -- iter: 205/205
--
Training Step: 57  | total loss: [1m[32m0.12305[0m[0m | time: 13.526s
[2K
| Adam | epoch: 009 | loss: 0.12305 - acc: 0.9605 -- iter: 032/205
[A[ATraining Step: 58  | total loss: [1m[32m0.10874[0m[0m | time: 27.122s
[2K
| Adam | epoch: 009 | loss: 0.10874 - acc: 0.9659 -- iter: 064/205
[A[ATraining Step: 59  | total loss: [1m[32m0.17685[0m[0m | time: 40.656s
[2K
| Adam | epoch: 009 | loss: 0.17685 - acc: 0.9579 -- iter: 096/205
[A[ATraining Step: 60  | total loss: [1m[32m0.20118[0m[0m | time: 54.052s
[2K
| Adam | epoch: 009 | loss: 0.20118 - acc: 0.9469 -- iter: 128/205
[A[ATraining Step: 61  | total loss: [1m[32m0.17735[0m[0m | time: 68.047s
[2K
| Adam | epoch: 009 | loss: 0.17735 - acc: 0.9538 -- iter: 160/205
[A[ATraining Step: 62  | total loss: [1m[32m0.16288[0m[0m | time: 81.612s
[2K
| Adam | epoch: 009 | loss: 0.16288 - acc: 0.9557 -- iter: 192/205
[A[ATraining Step: 63  | total loss: [1m[32m0.14652[0m[0m | time: 93.011s
[2K
| Adam | epoch: 009 | loss: 0.14652 - acc: 0.9614 | val_loss: 6.45119 - val_acc: 0.4000 -- iter: 205/205
--
Training Step: 64  | total loss: [1m[32m0.28464[0m[0m | time: 6.525s
[2K
| Adam | epoch: 010 | loss: 0.28464 - acc: 0.9277 -- iter: 032/205
[A[ATraining Step: 65  | total loss: [1m[32m0.27506[0m[0m | time: 19.740s
[2K
| Adam | epoch: 010 | loss: 0.27506 - acc: 0.9271 -- iter: 064/205
[A[ATraining Step: 66  | total loss: [1m[32m0.26691[0m[0m | time: 32.871s
[2K
| Adam | epoch: 010 | loss: 0.26691 - acc: 0.9246 -- iter: 096/205
[A[ATraining Step: 67  | total loss: [1m[32m0.25663[0m[0m | time: 46.206s
[2K
| Adam | epoch: 010 | loss: 0.25663 - acc: 0.9224 -- iter: 128/205
[A[ATraining Step: 68  | total loss: [1m[32m0.27070[0m[0m | time: 59.589s
[2K
| Adam | epoch: 010 | loss: 0.27070 - acc: 0.9094 -- iter: 160/205
[A[ATraining Step: 69  | total loss: [1m[32m0.26958[0m[0m | time: 73.205s
[2K
| Adam | epoch: 010 | loss: 0.26958 - acc: 0.9127 -- iter: 192/205
[A[ATraining Step: 70  | total loss: [1m[32m0.26029[0m[0m | time: 91.299s
[2K
| Adam | epoch: 010 | loss: 0.26029 - acc: 0.9119 | val_loss: 1.38885 - val_acc: 0.6000 -- iter: 205/205
--
Training Step: 71  | total loss: [1m[32m0.25605[0m[0m | time: 6.222s
[2K
| Adam | epoch: 011 | loss: 0.25605 - acc: 0.9113 -- iter: 032/205
[A[ATraining Step: 72  | total loss: [1m[32m0.28591[0m[0m | time: 13.049s
[2K
| Adam | epoch: 011 | loss: 0.28591 - acc: 0.8867 -- iter: 064/205
[A[ATraining Step: 73  | total loss: [1m[32m0.26053[0m[0m | time: 25.946s
[2K
| Adam | epoch: 011 | loss: 0.26053 - acc: 0.8992 -- iter: 096/205
[A[ATraining Step: 74  | total loss: [1m[32m0.24144[0m[0m | time: 39.334s
[2K
| Adam | epoch: 011 | loss: 0.24144 - acc: 0.9069 -- iter: 128/205
[A[ATraining Step: 75  | total loss: [1m[32m0.26916[0m[0m | time: 52.867s
[2K
| Adam | epoch: 011 | loss: 0.26916 - acc: 0.8933 -- iter: 160/205
[A[ATraining Step: 76  | total loss: [1m[32m0.25500[0m[0m | time: 66.680s
[2K
| Adam | epoch: 011 | loss: 0.25500 - acc: 0.8980 -- iter: 192/205
[A[ATraining Step: 77  | total loss: [1m[32m0.23840[0m[0m | time: 85.158s
[2K
| Adam | epoch: 011 | loss: 0.23840 - acc: 0.9055 | val_loss: 0.86035 - val_acc: 0.6462 -- iter: 205/205
--
Training Step: 78  | total loss: [1m[32m0.24182[0m[0m | time: 13.446s
[2K
| Adam | epoch: 012 | loss: 0.24182 - acc: 0.9088 -- iter: 032/205
[A[ATraining Step: 79  | total loss: [1m[32m0.23085[0m[0m | time: 19.853s
[2K
| Adam | epoch: 012 | loss: 0.23085 - acc: 0.9150 -- iter: 064/205
[A[ATraining Step: 80  | total loss: [1m[32m0.21293[0m[0m | time: 26.540s
[2K
| Adam | epoch: 012 | loss: 0.21293 - acc: 0.9237 -- iter: 096/205
[A[ATraining Step: 81  | total loss: [1m[32m0.19259[0m[0m | time: 39.778s
[2K
| Adam | epoch: 012 | loss: 0.19259 - acc: 0.9314 -- iter: 128/205
[A[ATraining Step: 82  | total loss: [1m[32m0.18800[0m[0m | time: 53.158s
[2K
| Adam | epoch: 012 | loss: 0.18800 - acc: 0.9352 -- iter: 160/205
[A[ATraining Step: 83  | total loss: [1m[32m0.17076[0m[0m | time: 66.616s
[2K
| Adam | epoch: 012 | loss: 0.17076 - acc: 0.9417 -- iter: 192/205
[A[ATraining Step: 84  | total loss: [1m[32m0.15637[0m[0m | time: 84.563s
[2K
| Adam | epoch: 012 | loss: 0.15637 - acc: 0.9475 | val_loss: 4.60866 - val_acc: 0.4000 -- iter: 205/205
--
Training Step: 85  | total loss: [1m[32m0.16012[0m[0m | time: 13.079s
[2K
| Adam | epoch: 013 | loss: 0.16012 - acc: 0.9434 -- iter: 032/205
[A[ATraining Step: 86  | total loss: [1m[32m0.14770[0m[0m | time: 26.325s
[2K
| Adam | epoch: 013 | loss: 0.14770 - acc: 0.9490 -- iter: 064/205
[A[ATraining Step: 87  | total loss: [1m[32m0.13628[0m[0m | time: 32.984s
[2K
| Adam | epoch: 013 | loss: 0.13628 - acc: 0.9541 -- iter: 096/205
[A[ATraining Step: 88  | total loss: [1m[32m0.12380[0m[0m | time: 39.736s
[2K
| Adam | epoch: 013 | loss: 0.12380 - acc: 0.9587 -- iter: 128/205
[A[ATraining Step: 89  | total loss: [1m[32m0.11287[0m[0m | time: 53.092s
[2K
| Adam | epoch: 013 | loss: 0.11287 - acc: 0.9628 -- iter: 160/205
[A[ATraining Step: 90  | total loss: [1m[32m0.10336[0m[0m | time: 66.146s
[2K
| Adam | epoch: 013 | loss: 0.10336 - acc: 0.9666 -- iter: 192/205
[A[ATraining Step: 91  | total loss: [1m[32m0.09659[0m[0m | time: 85.842s
[2K
| Adam | epoch: 013 | loss: 0.09659 - acc: 0.9699 | val_loss: 1.73010 - val_acc: 0.6308 -- iter: 205/205
--
Training Step: 92  | total loss: [1m[32m0.08976[0m[0m | time: 14.674s
[2K
| Adam | epoch: 014 | loss: 0.08976 - acc: 0.9729 -- iter: 032/205
[A[ATraining Step: 93  | total loss: [1m[32m0.08734[0m[0m | time: 29.554s
[2K
| Adam | epoch: 014 | loss: 0.08734 - acc: 0.9756 -- iter: 064/205
[A[ATraining Step: 94  | total loss: [1m[32m0.07913[0m[0m | time: 39.925s
[2K
| Adam | epoch: 014 | loss: 0.07913 - acc: 0.9781 -- iter: 096/205
[A[ATraining Step: 95  | total loss: [1m[32m0.07594[0m[0m | time: 44.069s
[2K
| Adam | epoch: 014 | loss: 0.07594 - acc: 0.9771 -- iter: 128/205
[A[ATraining Step: 96  | total loss: [1m[32m0.17374[0m[0m | time: 48.391s
[2K
| Adam | epoch: 014 | loss: 0.17374 - acc: 0.9640 -- iter: 160/205
[A[ATraining Step: 97  | total loss: [1m[32m0.16251[0m[0m | time: 57.683s
[2K
| Adam | epoch: 014 | loss: 0.16251 - acc: 0.9676 -- iter: 192/205
[A[ATraining Step: 98  | total loss: [1m[32m0.14918[0m[0m | time: 70.176s
[2K
| Adam | epoch: 014 | loss: 0.14918 - acc: 0.9709 | val_loss: 1.43284 - val_acc: 0.6462 -- iter: 205/205
--
Training Step: 99  | total loss: [1m[32m0.13514[0m[0m | time: 13.347s
[2K
| Adam | epoch: 015 | loss: 0.13514 - acc: 0.9738 -- iter: 032/205
[A[ATraining Step: 100  | total loss: [1m[32m0.13179[0m[0m | time: 26.110s
[2K
| Adam | epoch: 015 | loss: 0.13179 - acc: 0.9701 -- iter: 064/205
[A[ATraining Step: 101  | total loss: [1m[32m0.14452[0m[0m | time: 39.910s
[2K
| Adam | epoch: 015 | loss: 0.14452 - acc: 0.9700 -- iter: 096/205
[A[ATraining Step: 102  | total loss: [1m[32m0.13115[0m[0m | time: 53.268s
[2K
| Adam | epoch: 015 | loss: 0.13115 - acc: 0.9730 -- iter: 128/205
[A[ATraining Step: 103  | total loss: [1m[32m0.13189[0m[0m | time: 59.383s
[2K
| Adam | epoch: 015 | loss: 0.13189 - acc: 0.9726 -- iter: 160/205
[A[ATraining Step: 104  | total loss: [1m[32m0.28324[0m[0m | time: 65.333s
[2K
| Adam | epoch: 015 | loss: 0.28324 - acc: 0.9522 -- iter: 192/205
[A[ATraining Step: 105  | total loss: [1m[32m0.25718[0m[0m | time: 84.390s
[2K
| Adam | epoch: 015 | loss: 0.25718 - acc: 0.9570 | val_loss: 1.41364 - val_acc: 0.6308 -- iter: 205/205
--
Training Step: 106  | total loss: [1m[32m0.24352[0m[0m | time: 13.942s
[2K
| Adam | epoch: 016 | loss: 0.24352 - acc: 0.9551 -- iter: 032/205
[A[ATraining Step: 107  | total loss: [1m[32m0.22254[0m[0m | time: 27.546s
[2K
| Adam | epoch: 016 | loss: 0.22254 - acc: 0.9596 -- iter: 064/205
[A[ATraining Step: 108  | total loss: [1m[32m0.21238[0m[0m | time: 41.113s
[2K
| Adam | epoch: 016 | loss: 0.21238 - acc: 0.9605 -- iter: 096/205
[A[ATraining Step: 109  | total loss: [1m[32m0.19489[0m[0m | time: 54.759s
[2K
| Adam | epoch: 016 | loss: 0.19489 - acc: 0.9644 -- iter: 128/205
[A[ATraining Step: 110  | total loss: [1m[32m0.18868[0m[0m | time: 68.539s
[2K
| Adam | epoch: 016 | loss: 0.18868 - acc: 0.9649 -- iter: 160/205
[A[ATraining Step: 111  | total loss: [1m[32m0.17698[0m[0m | time: 74.918s
[2K
| Adam | epoch: 016 | loss: 0.17698 - acc: 0.9653 -- iter: 192/205
[A[ATraining Step: 112  | total loss: [1m[32m0.19816[0m[0m | time: 86.850s
[2K
| Adam | epoch: 016 | loss: 0.19816 - acc: 0.9610 | val_loss: 0.96821 - val_acc: 0.5077 -- iter: 205/205
--
Training Step: 113  | total loss: [1m[32m0.17960[0m[0m | time: 13.579s
[2K
| Adam | epoch: 017 | loss: 0.17960 - acc: 0.9649 -- iter: 032/205
[A[ATraining Step: 114  | total loss: [1m[32m0.17052[0m[0m | time: 26.907s
[2K
| Adam | epoch: 017 | loss: 0.17052 - acc: 0.9653 -- iter: 064/205
[A[ATraining Step: 115  | total loss: [1m[32m0.17853[0m[0m | time: 40.736s
[2K
| Adam | epoch: 017 | loss: 0.17853 - acc: 0.9594 -- iter: 096/205
[A[ATraining Step: 116  | total loss: [1m[32m0.17566[0m[0m | time: 53.474s
[2K
| Adam | epoch: 017 | loss: 0.17566 - acc: 0.9541 -- iter: 128/205
[A[ATraining Step: 117  | total loss: [1m[32m0.17204[0m[0m | time: 66.956s
[2K
| Adam | epoch: 017 | loss: 0.17204 - acc: 0.9524 -- iter: 160/205
[A[ATraining Step: 118  | total loss: [1m[32m0.15829[0m[0m | time: 80.420s
[2K
| Adam | epoch: 017 | loss: 0.15829 - acc: 0.9572 -- iter: 192/205
[A[ATraining Step: 119  | total loss: [1m[32m0.14377[0m[0m | time: 92.690s
[2K
| Adam | epoch: 017 | loss: 0.14377 - acc: 0.9615 | val_loss: 1.43742 - val_acc: 0.6615 -- iter: 205/205
--
Training Step: 120  | total loss: [1m[32m0.20191[0m[0m | time: 6.720s
[2K
| Adam | epoch: 018 | loss: 0.20191 - acc: 0.9576 -- iter: 032/205
[A[ATraining Step: 121  | total loss: [1m[32m0.18253[0m[0m | time: 20.238s
[2K
| Adam | epoch: 018 | loss: 0.18253 - acc: 0.9619 -- iter: 064/205
[A[ATraining Step: 122  | total loss: [1m[32m0.16762[0m[0m | time: 33.680s
[2K
| Adam | epoch: 018 | loss: 0.16762 - acc: 0.9657 -- iter: 096/205
[A[ATraining Step: 123  | total loss: [1m[32m0.15335[0m[0m | time: 47.496s
[2K
| Adam | epoch: 018 | loss: 0.15335 - acc: 0.9691 -- iter: 128/205
[A[ATraining Step: 124  | total loss: [1m[32m0.13986[0m[0m | time: 61.394s
[2K
| Adam | epoch: 018 | loss: 0.13986 - acc: 0.9722 -- iter: 160/205
[A[ATraining Step: 125  | total loss: [1m[32m0.14825[0m[0m | time: 74.504s
[2K
| Adam | epoch: 018 | loss: 0.14825 - acc: 0.9687 -- iter: 192/205
[A[ATraining Step: 126  | total loss: [1m[32m0.13920[0m[0m | time: 93.111s
[2K
| Adam | epoch: 018 | loss: 0.13920 - acc: 0.9719 | val_loss: 1.51195 - val_acc: 0.6462 -- iter: 205/205
--
Training Step: 127  | total loss: [1m[32m0.12745[0m[0m | time: 7.223s
[2K
| Adam | epoch: 019 | loss: 0.12745 - acc: 0.9747 -- iter: 032/205
[A[ATraining Step: 128  | total loss: [1m[32m0.16532[0m[0m | time: 13.325s
[2K
| Adam | epoch: 019 | loss: 0.16532 - acc: 0.9618 -- iter: 064/205
[A[ATraining Step: 129  | total loss: [1m[32m0.15252[0m[0m | time: 26.745s
[2K
| Adam | epoch: 019 | loss: 0.15252 - acc: 0.9656 -- iter: 096/205
[A[ATraining Step: 130  | total loss: [1m[32m0.14223[0m[0m | time: 39.851s
[2K
| Adam | epoch: 019 | loss: 0.14223 - acc: 0.9659 -- iter: 128/205
[A[ATraining Step: 131  | total loss: [1m[32m0.12920[0m[0m | time: 53.446s
[2K
| Adam | epoch: 019 | loss: 0.12920 - acc: 0.9694 -- iter: 160/205
[A[ATraining Step: 132  | total loss: [1m[32m0.11759[0m[0m | time: 66.708s
[2K
| Adam | epoch: 019 | loss: 0.11759 - acc: 0.9724 -- iter: 192/205
[A[ATraining Step: 133  | total loss: [1m[32m0.12405[0m[0m | time: 85.330s
[2K
| Adam | epoch: 019 | loss: 0.12405 - acc: 0.9689 | val_loss: 0.72498 - val_acc: 0.7231 -- iter: 205/205
--
Training Step: 134  | total loss: [1m[32m0.11318[0m[0m | time: 13.395s
[2K
| Adam | epoch: 020 | loss: 0.11318 - acc: 0.9720 -- iter: 032/205
[A[ATraining Step: 135  | total loss: [1m[32m0.10345[0m[0m | time: 19.958s
[2K
| Adam | epoch: 020 | loss: 0.10345 - acc: 0.9748 -- iter: 064/205
[A[ATraining Step: 136  | total loss: [1m[32m0.13939[0m[0m | time: 26.542s
[2K
| Adam | epoch: 020 | loss: 0.13939 - acc: 0.9543 -- iter: 096/205
[A[ATraining Step: 137  | total loss: [1m[32m0.12810[0m[0m | time: 40.154s
[2K
| Adam | epoch: 020 | loss: 0.12810 - acc: 0.9588 -- iter: 128/205
[A[ATraining Step: 138  | total loss: [1m[32m0.11840[0m[0m | time: 53.341s
[2K
| Adam | epoch: 020 | loss: 0.11840 - acc: 0.9630 -- iter: 160/205
[A[ATraining Step: 139  | total loss: [1m[32m0.12093[0m[0m | time: 66.727s
[2K
| Adam | epoch: 020 | loss: 0.12093 - acc: 0.9604 -- iter: 192/205
[A[ATraining Step: 140  | total loss: [1m[32m0.11011[0m[0m | time: 85.363s
[2K
| Adam | epoch: 020 | loss: 0.11011 - acc: 0.9644 | val_loss: 0.78595 - val_acc: 0.7077 -- iter: 205/205
--
Training Step: 141  | total loss: [1m[32m0.10605[0m[0m | time: 13.344s
[2K
| Adam | epoch: 021 | loss: 0.10605 - acc: 0.9648 -- iter: 032/205
[A[ATraining Step: 142  | total loss: [1m[32m0.09683[0m[0m | time: 26.842s
[2K
| Adam | epoch: 021 | loss: 0.09683 - acc: 0.9683 -- iter: 064/205
[A[ATraining Step: 143  | total loss: [1m[32m0.09236[0m[0m | time: 33.556s
[2K
| Adam | epoch: 021 | loss: 0.09236 - acc: 0.9684 -- iter: 096/205
[A[ATraining Step: 144  | total loss: [1m[32m0.09065[0m[0m | time: 39.992s
[2K
| Adam | epoch: 021 | loss: 0.09065 - acc: 0.9638 -- iter: 128/205
[A[ATraining Step: 145  | total loss: [1m[32m0.08494[0m[0m | time: 53.545s
[2K
| Adam | epoch: 021 | loss: 0.08494 - acc: 0.9675 -- iter: 160/205
[A[ATraining Step: 146  | total loss: [1m[32m0.07947[0m[0m | time: 67.275s
[2K
| Adam | epoch: 021 | loss: 0.07947 - acc: 0.9707 -- iter: 192/205
[A[ATraining Step: 147  | total loss: [1m[32m0.07353[0m[0m | time: 86.014s
[2K
| Adam | epoch: 021 | loss: 0.07353 - acc: 0.9736 | val_loss: 5.03362 - val_acc: 0.4308 -- iter: 205/205
--
Training Step: 148  | total loss: [1m[32m0.07473[0m[0m | time: 13.413s
[2K
| Adam | epoch: 022 | loss: 0.07473 - acc: 0.9700 -- iter: 032/205
[A[ATraining Step: 149  | total loss: [1m[32m0.06926[0m[0m | time: 27.082s
[2K
| Adam | epoch: 022 | loss: 0.06926 - acc: 0.9730 -- iter: 064/205
[A[ATraining Step: 150  | total loss: [1m[32m0.06330[0m[0m | time: 40.588s
[2K
| Adam | epoch: 022 | loss: 0.06330 - acc: 0.9757 -- iter: 096/205
[A[ATraining Step: 151  | total loss: [1m[32m0.05795[0m[0m | time: 47.593s
[2K
| Adam | epoch: 022 | loss: 0.05795 - acc: 0.9781 -- iter: 128/205
[A[ATraining Step: 152  | total loss: [1m[32m0.14937[0m[0m | time: 54.047s
[2K
| Adam | epoch: 022 | loss: 0.14937 - acc: 0.9726 -- iter: 160/205
[A[ATraining Step: 153  | total loss: [1m[32m0.14706[0m[0m | time: 109.318s
[2K
| Adam | epoch: 022 | loss: 0.14706 - acc: 0.9754 -- iter: 192/205
[A[ATraining Step: 154  | total loss: [1m[32m0.14202[0m[0m | time: 151.657s
[2K
| Adam | epoch: 022 | loss: 0.14202 - acc: 0.9747 | val_loss: 6.28510 - val_acc: 0.4000 -- iter: 205/205
--
Training Step: 155  | total loss: [1m[32m0.13191[0m[0m | time: 32.933s
[2K
| Adam | epoch: 023 | loss: 0.13191 - acc: 0.9772 -- iter: 032/205
[A[ATraining Step: 156  | total loss: [1m[32m0.11922[0m[0m | time: 63.759s
[2K
| Adam | epoch: 023 | loss: 0.11922 - acc: 0.9795 -- iter: 064/205
[A[ATraining Step: 157  | total loss: [1m[32m0.13042[0m[0m | time: 160.086s
[2K
| Adam | epoch: 023 | loss: 0.13042 - acc: 0.9784 -- iter: 096/205
[A[ATraining Step: 158  | total loss: [1m[32m0.11780[0m[0m | time: 180.117s
[2K
| Adam | epoch: 023 | loss: 0.11780 - acc: 0.9806 -- iter: 128/205
[A[ATraining Step: 159  | total loss: [1m[32m0.10949[0m[0m | time: 188.697s
[2K
| Adam | epoch: 023 | loss: 0.10949 - acc: 0.9825 -- iter: 160/205
[A[ATraining Step: 160  | total loss: [1m[32m0.11266[0m[0m | time: 195.520s
[2K
| Adam | epoch: 023 | loss: 0.11266 - acc: 0.9843 -- iter: 192/205
[A[ATraining Step: 161  | total loss: [1m[32m0.11035[0m[0m | time: 214.012s
[2K
| Adam | epoch: 023 | loss: 0.11035 - acc: 0.9859 | val_loss: 0.86719 - val_acc: 0.7077 -- iter: 205/205
--
Training Step: 162  | total loss: [1m[32m0.10009[0m[0m | time: 38.728s
[2K
| Adam | epoch: 024 | loss: 0.10009 - acc: 0.9873 -- iter: 032/205
[A[ATraining Step: 163  | total loss: [1m[32m0.09055[0m[0m | time: 62.417s
[2K
| Adam | epoch: 024 | loss: 0.09055 - acc: 0.9885 -- iter: 064/205
[A[ATraining Step: 164  | total loss: [1m[32m0.08231[0m[0m | time: 119.661s
[2K
| Adam | epoch: 024 | loss: 0.08231 - acc: 0.9897 -- iter: 096/205
[A[ATraining Step: 165  | total loss: [1m[32m0.07540[0m[0m | time: 180.344s
[2K
| Adam | epoch: 024 | loss: 0.07540 - acc: 0.9907 -- iter: 128/205
[A[ATraining Step: 166  | total loss: [1m[32m0.07467[0m[0m | time: 219.698s
[2K
| Adam | epoch: 024 | loss: 0.07467 - acc: 0.9885 -- iter: 160/205
[A[ATraining Step: 167  | total loss: [1m[32m0.06779[0m[0m | time: 255.271s
[2K
| Adam | epoch: 024 | loss: 0.06779 - acc: 0.9897 -- iter: 192/205
[A[ATraining Step: 168  | total loss: [1m[32m0.12579[0m[0m | time: 270.549s
[2K
| Adam | epoch: 024 | loss: 0.12579 - acc: 0.9753 | val_loss: 2.50233 - val_acc: 0.6615 -- iter: 205/205
--
Training Step: 169  | total loss: [1m[32m0.11354[0m[0m | time: 28.169s
[2K
| Adam | epoch: 025 | loss: 0.11354 - acc: 0.9778 -- iter: 032/205
[A[ATraining Step: 170  | total loss: [1m[32m0.11569[0m[0m | time: 68.179s
[2K
| Adam | epoch: 025 | loss: 0.11569 - acc: 0.9769 -- iter: 064/205
[A[ATraining Step: 171  | total loss: [1m[32m0.12293[0m[0m | time: 99.710s
[2K
| Adam | epoch: 025 | loss: 0.12293 - acc: 0.9761 -- iter: 096/205
[A[ATraining Step: 172  | total loss: [1m[32m0.11249[0m[0m | time: 120.817s
[2K
| Adam | epoch: 025 | loss: 0.11249 - acc: 0.9785 -- iter: 128/205
[A[ATraining Step: 173  | total loss: [1m[32m0.10274[0m[0m | time: 149.581s
[2K
| Adam | epoch: 025 | loss: 0.10274 - acc: 0.9806 -- iter: 160/205
[A[ATraining Step: 174  | total loss: [1m[32m0.09293[0m[0m | time: 163.258s
[2K
| Adam | epoch: 025 | loss: 0.09293 - acc: 0.9826 -- iter: 192/205
[A[ATraining Step: 175  | total loss: [1m[32m0.09414[0m[0m | time: 178.049s
[2K
| Adam | epoch: 025 | loss: 0.09414 - acc: 0.9812 | val_loss: 5.00956 - val_acc: 0.6000 -- iter: 205/205
--
Training Step: 176  | total loss: [1m[32m0.08531[0m[0m | time: 17.821s
[2K
| Adam | epoch: 026 | loss: 0.08531 - acc: 0.9831 -- iter: 032/205
[A[ATraining Step: 177  | total loss: [1m[32m0.07771[0m[0m | time: 39.515s
[2K
| Adam | epoch: 026 | loss: 0.07771 - acc: 0.9848 -- iter: 064/205
[A[ATraining Step: 178  | total loss: [1m[32m0.07706[0m[0m | time: 64.102s
[2K
| Adam | epoch: 026 | loss: 0.07706 - acc: 0.9832 -- iter: 096/205
[A[ATraining Step: 179  | total loss: [1m[32m0.07005[0m[0m | time: 82.714s
[2K
| Adam | epoch: 026 | loss: 0.07005 - acc: 0.9848 -- iter: 128/205
[A[ATraining Step: 180  | total loss: [1m[32m0.06571[0m[0m | time: 96.177s
[2K
| Adam | epoch: 026 | loss: 0.06571 - acc: 0.9864 -- iter: 160/205
[A[ATraining Step: 181  | total loss: [1m[32m0.06307[0m[0m | time: 110.694s
[2K
| Adam | epoch: 026 | loss: 0.06307 - acc: 0.9846 -- iter: 192/205
[A[ATraining Step: 182  | total loss: [1m[32m0.05813[0m[0m | time: 177.557s
[2K
| Adam | epoch: 026 | loss: 0.05813 - acc: 0.9861 | val_loss: 0.87283 - val_acc: 0.7538 -- iter: 205/205
--
Training Step: 183  | total loss: [1m[32m0.05359[0m[0m | time: 52.333s
[2K
| Adam | epoch: 027 | loss: 0.05359 - acc: 0.9875 -- iter: 032/205
[A[ATraining Step: 184  | total loss: [1m[32m0.13794[0m[0m | time: 64.204s
[2K
| Adam | epoch: 027 | loss: 0.13794 - acc: 0.9811 -- iter: 064/205
[A[ATraining Step: 185  | total loss: [1m[32m0.12483[0m[0m | time: 123.062s
[2K
| Adam | epoch: 027 | loss: 0.12483 - acc: 0.9830 -- iter: 096/205
[A[ATraining Step: 186  | total loss: [1m[32m0.11585[0m[0m | time: 138.648s
[2K
| Adam | epoch: 027 | loss: 0.11585 - acc: 0.9815 -- iter: 128/205
[A[ATraining Step: 187  | total loss: [1m[32m0.11299[0m[0m | time: 153.879s
[2K
| Adam | epoch: 027 | loss: 0.11299 - acc: 0.9771 -- iter: 160/205
[A[ATraining Step: 188  | total loss: [1m[32m0.10497[0m[0m | time: 180.597s
[2K
| Adam | epoch: 027 | loss: 0.10497 - acc: 0.9763 -- iter: 192/205
[A[ATraining Step: 189  | total loss: [1m[32m0.09586[0m[0m | time: 204.822s
[2K
| Adam | epoch: 027 | loss: 0.09586 - acc: 0.9787 | val_loss: 0.97100 - val_acc: 0.6615 -- iter: 205/205
--
Training Step: 190  | total loss: [1m[32m0.08858[0m[0m | time: 18.739s
[2K
| Adam | epoch: 028 | loss: 0.08858 - acc: 0.9808 -- iter: 032/205
[A[ATraining Step: 191  | total loss: [1m[32m0.08015[0m[0m | time: 28.402s
[2K
| Adam | epoch: 028 | loss: 0.08015 - acc: 0.9827 -- iter: 064/205
[A[ATraining Step: 192  | total loss: [1m[32m0.16659[0m[0m | time: 37.036s
[2K
| Adam | epoch: 028 | loss: 0.16659 - acc: 0.9691 -- iter: 096/205
[A[ATraining Step: 193  | total loss: [1m[32m0.15040[0m[0m | time: 50.655s
[2K
| Adam | epoch: 028 | loss: 0.15040 - acc: 0.9722 -- iter: 128/205
[A[ATraining Step: 194  | total loss: [1m[32m0.13733[0m[0m | time: 63.938s
[2K
| Adam | epoch: 028 | loss: 0.13733 - acc: 0.9749 -- iter: 160/205
[A[ATraining Step: 195  | total loss: [1m[32m0.15964[0m[0m | time: 79.608s
[2K
| Adam | epoch: 028 | loss: 0.15964 - acc: 0.9587 -- iter: 192/205
[A[ATraining Step: 196  | total loss: [1m[32m0.14676[0m[0m | time: 107.134s
[2K
| Adam | epoch: 028 | loss: 0.14676 - acc: 0.9628 | val_loss: 0.99369 - val_acc: 0.6615 -- iter: 205/205
--
Training Step: 197  | total loss: [1m[32m0.14011[0m[0m | time: 19.268s
[2K
| Adam | epoch: 029 | loss: 0.14011 - acc: 0.9634 -- iter: 032/205
[A[ATraining Step: 198  | total loss: [1m[32m0.13369[0m[0m | time: 37.630s
[2K
| Adam | epoch: 029 | loss: 0.13369 - acc: 0.9640 -- iter: 064/205
[A[ATraining Step: 199  | total loss: [1m[32m0.12132[0m[0m | time: 44.462s
[2K
| Adam | epoch: 029 | loss: 0.12132 - acc: 0.9676 -- iter: 096/205
[A[ATraining Step: 200  | total loss: [1m[32m0.22745[0m[0m | time: 56.502s
[2K
| Adam | epoch: 029 | loss: 0.22745 - acc: 0.9554 | val_loss: 0.75380 - val_acc: 0.7385 -- iter: 128/205
--
Training Step: 201  | total loss: [1m[32m0.20929[0m[0m | time: 75.524s
[2K
| Adam | epoch: 029 | loss: 0.20929 - acc: 0.9599 -- iter: 160/205
[A[ATraining Step: 202  | total loss: [1m[32m0.19499[0m[0m | time: 96.129s
[2K
| Adam | epoch: 029 | loss: 0.19499 - acc: 0.9608 -- iter: 192/205
[A[ATraining Step: 203  | total loss: [1m[32m0.18184[0m[0m | time: 126.000s
[2K
| Adam | epoch: 029 | loss: 0.18184 - acc: 0.9616 | val_loss: 0.96959 - val_acc: 0.7077 -- iter: 205/205
--
Training Step: 204  | total loss: [1m[32m0.16740[0m[0m | time: 13.313s
[2K
| Adam | epoch: 030 | loss: 0.16740 - acc: 0.9654 -- iter: 032/205
[A[ATraining Step: 205  | total loss: [1m[32m0.15302[0m[0m | time: 28.273s
[2K
| Adam | epoch: 030 | loss: 0.15302 - acc: 0.9689 -- iter: 064/205
[A[ATraining Step: 206  | total loss: [1m[32m0.13954[0m[0m | time: 51.227s
[2K
| Adam | epoch: 030 | loss: 0.13954 - acc: 0.9720 -- iter: 096/205
[A[ATraining Step: 207  | total loss: [1m[32m0.13201[0m[0m | time: 61.981s
[2K
| Adam | epoch: 030 | loss: 0.13201 - acc: 0.9717 -- iter: 128/205
[A[ATraining Step: 208  | total loss: [1m[32m0.13157[0m[0m | time: 71.706s
[2K
| Adam | epoch: 030 | loss: 0.13157 - acc: 0.9668 -- iter: 160/205
[A[ATraining Step: 209  | total loss: [1m[32m0.12025[0m[0m | time: 91.861s
[2K
| Adam | epoch: 030 | loss: 0.12025 - acc: 0.9701 -- iter: 192/205
[A[ATraining Step: 210  | total loss: [1m[32m0.11006[0m[0m | time: 119.698s
[2K
| Adam | epoch: 030 | loss: 0.11006 - acc: 0.9731 | val_loss: 1.45755 - val_acc: 0.6154 -- iter: 205/205
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7938856015779093
Validation AUPRC:0.8642421159355081
Test AUC:0.8541666666666666
Test AUPRC:0.8597726297753057
BestTestF1Score	0.79	0.56	0.77	0.71	0.91	29	12	21	3	0.99
BestTestMCCScore	0.79	0.56	0.77	0.71	0.91	29	12	21	3	0.99
BestTestAccuracyScore	0.79	0.56	0.77	0.71	0.91	29	12	21	3	0.99
BestValidationF1Score	0.81	0.48	0.75	0.76	0.87	34	11	15	5	0.99
BestValidationMCC	0.81	0.48	0.75	0.76	0.87	34	11	15	5	0.99
BestValidationAccuracy	0.81	0.48	0.75	0.76	0.87	34	11	15	5	0.99
TestPredictions (Threshold:0.99)
CHEMBL179512,TP,ACT,1.0	CHEMBL3215658,FP,INACT,1.0	CHEMBL502072,FP,INACT,0.9900000095367432	CHEMBL3199893,TP,ACT,1.0	CHEMBL1497139,TP,ACT,1.0	CHEMBL1316002,TP,ACT,1.0	CHEMBL1824682,TN,INACT,0.41999998688697815	CHEMBL1824701,TN,INACT,0.800000011920929	CHEMBL1440303,TP,ACT,0.9900000095367432	CHEMBL1824690,FP,INACT,0.9900000095367432	CHEMBL1586067,TP,ACT,1.0	CHEMBL1790039,TP,ACT,1.0	CHEMBL3216549,FP,INACT,0.9900000095367432	CHEMBL1824697,TN,INACT,0.9800000190734863	CHEMBL2326261,TN,INACT,0.9200000166893005	CHEMBL3357070,TP,ACT,1.0	CHEMBL1269667,TN,INACT,0.7400000095367432	CHEMBL1418428,FN,ACT,0.3799999952316284	CHEMBL1269666,TN,INACT,0.019999999552965164	CHEMBL1611182,TP,ACT,1.0	CHEMBL1301731,TP,ACT,1.0	CHEMBL1726592,FP,INACT,0.9900000095367432	CHEMBL2005437,TP,ACT,1.0	CHEMBL3357060,TP,ACT,1.0	CHEMBL1929238,FP,INACT,0.9900000095367432	CHEMBL429095,TP,ACT,1.0	CHEMBL3357066,TP,ACT,0.9900000095367432	CHEMBL1338304,TP,ACT,1.0	CHEMBL1644500,TN,INACT,0.9100000262260437	CHEMBL3116325,TN,INACT,0.9599999785423279	CHEMBL1308404,TP,ACT,1.0	CHEMBL1269664,TN,INACT,0.9200000166893005	CHEMBL1424562,TP,ACT,0.9900000095367432	CHEMBL1910031,FP,INACT,1.0	CHEMBL3343699,TN,INACT,0.029999999329447746	CHEMBL3116317,FP,INACT,0.9900000095367432	CHEMBL3356619,TP,ACT,1.0	CHEMBL477504,TN,INACT,0.05999999865889549	CHEMBL1308255,FN,ACT,0.949999988079071	CHEMBL1910027,TN,INACT,0.8799999952316284	CHEMBL3805307,TN,INACT,0.9200000166893005	CHEMBL1824680,FP,INACT,1.0	CHEMBL377353,FP,INACT,1.0	CHEMBL3629608,TN,INACT,0.9700000286102295	CHEMBL1558462,TP,ACT,1.0	CHEMBL1734268,TP,ACT,1.0	CHEMBL1707429,TP,ACT,0.9900000095367432	CHEMBL1824685,TN,INACT,0.4300000071525574	CHEMBL1504077,TP,ACT,1.0	CHEMBL3629607,FP,INACT,1.0	CHEMBL3216775,TN,INACT,0.5699999928474426	CHEMBL3216546,TN,INACT,0.3199999928474426	CHEMBL1713905,FN,ACT,0.6700000166893005	CHEMBL1390797,TP,ACT,1.0	CHEMBL1458022,TP,ACT,1.0	CHEMBL3577584,FP,INACT,1.0	CHEMBL3356613,TP,ACT,1.0	CHEMBL1644502,TN,INACT,0.9100000262260437	CHEMBL1532668,TP,ACT,1.0	CHEMBL505670,TP,ACT,1.0	CHEMBL1710816,TP,ACT,0.9900000095367432	CHEMBL1583998,TP,ACT,0.9900000095367432	CHEMBL1824698,TN,INACT,0.9599999785423279	CHEMBL1824691,TN,INACT,0.75	CHEMBL1644514,TN,INACT,0.8700000047683716	

