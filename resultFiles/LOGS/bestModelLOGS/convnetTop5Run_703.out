CNNModel CHEMBL2327 adam 0.0005 15 128 0 0.8 False True
Number of active compounds :	849
Number of inactive compounds :	849
---------------------------------
Run id: CNNModel_CHEMBL2327_adam_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2327_adam_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 1072
Validation samples: 336
--
Training Step: 1  | time: 2.725s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1072
[A[ATraining Step: 2  | total loss: [1m[32m0.62373[0m[0m | time: 4.815s
[2K
| Adam | epoch: 001 | loss: 0.62373 - acc: 0.5062 -- iter: 0064/1072
[A[ATraining Step: 3  | total loss: [1m[32m0.68076[0m[0m | time: 6.686s
[2K
| Adam | epoch: 001 | loss: 0.68076 - acc: 0.4500 -- iter: 0096/1072
[A[ATraining Step: 4  | total loss: [1m[32m0.68876[0m[0m | time: 8.333s
[2K
| Adam | epoch: 001 | loss: 0.68876 - acc: 0.5578 -- iter: 0128/1072
[A[ATraining Step: 5  | total loss: [1m[32m0.69240[0m[0m | time: 10.246s
[2K
| Adam | epoch: 001 | loss: 0.69240 - acc: 0.4962 -- iter: 0160/1072
[A[ATraining Step: 6  | total loss: [1m[32m0.68661[0m[0m | time: 12.156s
[2K
| Adam | epoch: 001 | loss: 0.68661 - acc: 0.5790 -- iter: 0192/1072
[A[ATraining Step: 7  | total loss: [1m[32m0.69204[0m[0m | time: 14.045s
[2K
| Adam | epoch: 001 | loss: 0.69204 - acc: 0.5316 -- iter: 0224/1072
[A[ATraining Step: 8  | total loss: [1m[32m0.69212[0m[0m | time: 15.810s
[2K
| Adam | epoch: 001 | loss: 0.69212 - acc: 0.5314 -- iter: 0256/1072
[A[ATraining Step: 9  | total loss: [1m[32m0.69357[0m[0m | time: 17.780s
[2K
| Adam | epoch: 001 | loss: 0.69357 - acc: 0.5148 -- iter: 0288/1072
[A[ATraining Step: 10  | total loss: [1m[32m0.71376[0m[0m | time: 19.722s
[2K
| Adam | epoch: 001 | loss: 0.71376 - acc: 0.3980 -- iter: 0320/1072
[A[ATraining Step: 11  | total loss: [1m[32m0.70962[0m[0m | time: 21.458s
[2K
| Adam | epoch: 001 | loss: 0.70962 - acc: 0.4019 -- iter: 0352/1072
[A[ATraining Step: 12  | total loss: [1m[32m0.70429[0m[0m | time: 23.254s
[2K
| Adam | epoch: 001 | loss: 0.70429 - acc: 0.4179 -- iter: 0384/1072
[A[ATraining Step: 13  | total loss: [1m[32m0.70015[0m[0m | time: 25.088s
[2K
| Adam | epoch: 001 | loss: 0.70015 - acc: 0.4397 -- iter: 0416/1072
[A[ATraining Step: 14  | total loss: [1m[32m0.69603[0m[0m | time: 26.878s
[2K
| Adam | epoch: 001 | loss: 0.69603 - acc: 0.5539 -- iter: 0448/1072
[A[ATraining Step: 15  | total loss: [1m[32m0.69458[0m[0m | time: 28.733s
[2K
| Adam | epoch: 001 | loss: 0.69458 - acc: 0.5450 -- iter: 0480/1072
[A[ATraining Step: 16  | total loss: [1m[32m0.69373[0m[0m | time: 30.561s
[2K
| Adam | epoch: 001 | loss: 0.69373 - acc: 0.5750 -- iter: 0512/1072
[A[ATraining Step: 17  | total loss: [1m[32m0.69348[0m[0m | time: 32.304s
[2K
| Adam | epoch: 001 | loss: 0.69348 - acc: 0.5480 -- iter: 0544/1072
[A[ATraining Step: 18  | total loss: [1m[32m0.69350[0m[0m | time: 34.024s
[2K
| Adam | epoch: 001 | loss: 0.69350 - acc: 0.5206 -- iter: 0576/1072
[A[ATraining Step: 19  | total loss: [1m[32m0.69339[0m[0m | time: 35.915s
[2K
| Adam | epoch: 001 | loss: 0.69339 - acc: 0.5137 -- iter: 0608/1072
[A[ATraining Step: 20  | total loss: [1m[32m0.69322[0m[0m | time: 37.544s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.5394 -- iter: 0640/1072
[A[ATraining Step: 21  | total loss: [1m[32m0.69322[0m[0m | time: 39.306s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.5175 -- iter: 0672/1072
[A[ATraining Step: 22  | total loss: [1m[32m0.69320[0m[0m | time: 41.158s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.5123 -- iter: 0704/1072
[A[ATraining Step: 23  | total loss: [1m[32m0.69321[0m[0m | time: 43.125s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.4905 -- iter: 0736/1072
[A[ATraining Step: 24  | total loss: [1m[32m0.69321[0m[0m | time: 44.892s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.4844 -- iter: 0768/1072
[A[ATraining Step: 25  | total loss: [1m[32m0.69323[0m[0m | time: 46.532s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.4716 -- iter: 0800/1072
[A[ATraining Step: 26  | total loss: [1m[32m0.69320[0m[0m | time: 48.469s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.4709 -- iter: 0832/1072
[A[ATraining Step: 27  | total loss: [1m[32m0.69321[0m[0m | time: 50.420s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.4623 -- iter: 0864/1072
[A[ATraining Step: 28  | total loss: [1m[32m0.69315[0m[0m | time: 52.266s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.4873 -- iter: 0896/1072
[A[ATraining Step: 29  | total loss: [1m[32m0.69332[0m[0m | time: 54.100s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.4448 -- iter: 0928/1072
[A[ATraining Step: 30  | total loss: [1m[32m0.69334[0m[0m | time: 55.985s
[2K
| Adam | epoch: 001 | loss: 0.69334 - acc: 0.4505 -- iter: 0960/1072
[A[ATraining Step: 31  | total loss: [1m[32m0.69332[0m[0m | time: 57.746s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.4547 -- iter: 0992/1072
[A[ATraining Step: 32  | total loss: [1m[32m0.69321[0m[0m | time: 59.764s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.4930 -- iter: 1024/1072
[A[ATraining Step: 33  | total loss: [1m[32m0.69324[0m[0m | time: 61.794s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.4740 -- iter: 1056/1072
[A[ATraining Step: 34  | total loss: [1m[32m0.69327[0m[0m | time: 67.606s
[2K
| Adam | epoch: 001 | loss: 0.69327 - acc: 0.4729 | val_loss: 0.69312 - val_acc: 0.5208 -- iter: 1072/1072
--
Training Step: 35  | total loss: [1m[32m0.69332[0m[0m | time: 1.018s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4393 -- iter: 0032/1072
[A[ATraining Step: 36  | total loss: [1m[32m0.69323[0m[0m | time: 2.904s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.5028 -- iter: 0064/1072
[A[ATraining Step: 37  | total loss: [1m[32m0.69332[0m[0m | time: 4.896s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4773 -- iter: 0096/1072
[A[ATraining Step: 38  | total loss: [1m[32m0.69319[0m[0m | time: 6.740s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5001 -- iter: 0128/1072
[A[ATraining Step: 39  | total loss: [1m[32m0.69331[0m[0m | time: 8.624s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4821 -- iter: 0160/1072
[A[ATraining Step: 40  | total loss: [1m[32m0.69318[0m[0m | time: 10.261s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.4972 -- iter: 0192/1072
[A[ATraining Step: 41  | total loss: [1m[32m0.69331[0m[0m | time: 12.158s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4862 -- iter: 0224/1072
[A[ATraining Step: 42  | total loss: [1m[32m0.69330[0m[0m | time: 13.816s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.4887 -- iter: 0256/1072
[A[ATraining Step: 43  | total loss: [1m[32m0.69335[0m[0m | time: 15.641s
[2K
| Adam | epoch: 002 | loss: 0.69335 - acc: 0.4852 -- iter: 0288/1072
[A[ATraining Step: 44  | total loss: [1m[32m0.69311[0m[0m | time: 17.998s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5040 -- iter: 0320/1072
[A[ATraining Step: 45  | total loss: [1m[32m0.69332[0m[0m | time: 19.987s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4874 -- iter: 0352/1072
[A[ATraining Step: 46  | total loss: [1m[32m0.69337[0m[0m | time: 21.644s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4843 -- iter: 0384/1072
[A[ATraining Step: 47  | total loss: [1m[32m0.69291[0m[0m | time: 23.556s
[2K
| Adam | epoch: 002 | loss: 0.69291 - acc: 0.5175 -- iter: 0416/1072
[A[ATraining Step: 48  | total loss: [1m[32m0.69281[0m[0m | time: 25.392s
[2K
| Adam | epoch: 002 | loss: 0.69281 - acc: 0.5248 -- iter: 0448/1072
[A[ATraining Step: 49  | total loss: [1m[32m0.69311[0m[0m | time: 27.603s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5060 -- iter: 0480/1072
[A[ATraining Step: 50  | total loss: [1m[32m0.69337[0m[0m | time: 29.319s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4906 -- iter: 0512/1072
[A[ATraining Step: 51  | total loss: [1m[32m0.69320[0m[0m | time: 31.099s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5015 -- iter: 0544/1072
[A[ATraining Step: 52  | total loss: [1m[32m0.69342[0m[0m | time: 32.797s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4872 -- iter: 0576/1072
[A[ATraining Step: 53  | total loss: [1m[32m0.69330[0m[0m | time: 34.700s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.4937 -- iter: 0608/1072
[A[ATraining Step: 54  | total loss: [1m[32m0.69298[0m[0m | time: 36.398s
[2K
| Adam | epoch: 002 | loss: 0.69298 - acc: 0.5128 -- iter: 0640/1072
[A[ATraining Step: 55  | total loss: [1m[32m0.69300[0m[0m | time: 38.092s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5110 -- iter: 0672/1072
[A[ATraining Step: 56  | total loss: [1m[32m0.69280[0m[0m | time: 39.844s
[2K
| Adam | epoch: 002 | loss: 0.69280 - acc: 0.5226 -- iter: 0704/1072
[A[ATraining Step: 57  | total loss: [1m[32m0.69285[0m[0m | time: 41.698s
[2K
| Adam | epoch: 002 | loss: 0.69285 - acc: 0.5195 -- iter: 0736/1072
[A[ATraining Step: 58  | total loss: [1m[32m0.69263[0m[0m | time: 43.751s
[2K
| Adam | epoch: 002 | loss: 0.69263 - acc: 0.5296 -- iter: 0768/1072
[A[ATraining Step: 59  | total loss: [1m[32m0.69264[0m[0m | time: 45.561s
[2K
| Adam | epoch: 002 | loss: 0.69264 - acc: 0.5298 -- iter: 0800/1072
[A[ATraining Step: 60  | total loss: [1m[32m0.69272[0m[0m | time: 47.347s
[2K
| Adam | epoch: 002 | loss: 0.69272 - acc: 0.5259 -- iter: 0832/1072
[A[ATraining Step: 61  | total loss: [1m[32m0.69239[0m[0m | time: 49.164s
[2K
| Adam | epoch: 002 | loss: 0.69239 - acc: 0.5388 -- iter: 0864/1072
[A[ATraining Step: 62  | total loss: [1m[32m0.69260[0m[0m | time: 50.973s
[2K
| Adam | epoch: 002 | loss: 0.69260 - acc: 0.5298 -- iter: 0896/1072
[A[ATraining Step: 63  | total loss: [1m[32m0.69257[0m[0m | time: 52.645s
[2K
| Adam | epoch: 002 | loss: 0.69257 - acc: 0.5300 -- iter: 0928/1072
[A[ATraining Step: 64  | total loss: [1m[32m0.69253[0m[0m | time: 54.339s
[2K
| Adam | epoch: 002 | loss: 0.69253 - acc: 0.5301 -- iter: 0960/1072
[A[ATraining Step: 65  | total loss: [1m[32m0.69296[0m[0m | time: 56.429s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5149 -- iter: 0992/1072
[A[ATraining Step: 66  | total loss: [1m[32m0.69310[0m[0m | time: 58.040s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5093 -- iter: 1024/1072
[A[ATraining Step: 67  | total loss: [1m[32m0.69288[0m[0m | time: 60.016s
[2K
| Adam | epoch: 002 | loss: 0.69288 - acc: 0.5156 -- iter: 1056/1072
[A[ATraining Step: 68  | total loss: [1m[32m0.69315[0m[0m | time: 66.726s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5064 | val_loss: 0.69255 - val_acc: 0.5208 -- iter: 1072/1072
--
Training Step: 69  | total loss: [1m[32m0.69326[0m[0m | time: 0.990s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.5020 -- iter: 0032/1072
[A[ATraining Step: 70  | total loss: [1m[32m0.69347[0m[0m | time: 1.903s
[2K
| Adam | epoch: 003 | loss: 0.69347 - acc: 0.4946 -- iter: 0064/1072
[A[ATraining Step: 71  | total loss: [1m[32m0.69363[0m[0m | time: 4.080s
[2K
| Adam | epoch: 003 | loss: 0.69363 - acc: 0.4881 -- iter: 0096/1072
[A[ATraining Step: 72  | total loss: [1m[32m0.69329[0m[0m | time: 5.772s
[2K
| Adam | epoch: 003 | loss: 0.69329 - acc: 0.4999 -- iter: 0128/1072
[A[ATraining Step: 73  | total loss: [1m[32m0.69300[0m[0m | time: 7.342s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5104 -- iter: 0160/1072
[A[ATraining Step: 74  | total loss: [1m[32m0.69320[0m[0m | time: 9.313s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.5024 -- iter: 0192/1072
[A[ATraining Step: 75  | total loss: [1m[32m0.69310[0m[0m | time: 10.878s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5055 -- iter: 0224/1072
[A[ATraining Step: 76  | total loss: [1m[32m0.69329[0m[0m | time: 12.650s
[2K
| Adam | epoch: 003 | loss: 0.69329 - acc: 0.4982 -- iter: 0256/1072
[A[ATraining Step: 77  | total loss: [1m[32m0.69326[0m[0m | time: 14.577s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.4984 -- iter: 0288/1072
[A[ATraining Step: 78  | total loss: [1m[32m0.69370[0m[0m | time: 16.395s
[2K
| Adam | epoch: 003 | loss: 0.69370 - acc: 0.4822 -- iter: 0320/1072
[A[ATraining Step: 79  | total loss: [1m[32m0.69364[0m[0m | time: 18.293s
[2K
| Adam | epoch: 003 | loss: 0.69364 - acc: 0.4841 -- iter: 0352/1072
[A[ATraining Step: 80  | total loss: [1m[32m0.69389[0m[0m | time: 20.224s
[2K
| Adam | epoch: 003 | loss: 0.69389 - acc: 0.4729 -- iter: 0384/1072
[A[ATraining Step: 81  | total loss: [1m[32m0.69368[0m[0m | time: 22.157s
[2K
| Adam | epoch: 003 | loss: 0.69368 - acc: 0.4820 -- iter: 0416/1072
[A[ATraining Step: 82  | total loss: [1m[32m0.69368[0m[0m | time: 23.919s
[2K
| Adam | epoch: 003 | loss: 0.69368 - acc: 0.4806 -- iter: 0448/1072
[A[ATraining Step: 83  | total loss: [1m[32m0.69362[0m[0m | time: 25.810s
[2K
| Adam | epoch: 003 | loss: 0.69362 - acc: 0.4826 -- iter: 0480/1072
[A[ATraining Step: 84  | total loss: [1m[32m0.69343[0m[0m | time: 27.594s
[2K
| Adam | epoch: 003 | loss: 0.69343 - acc: 0.4906 -- iter: 0512/1072
[A[ATraining Step: 85  | total loss: [1m[32m0.69325[0m[0m | time: 29.667s
[2K
| Adam | epoch: 003 | loss: 0.69325 - acc: 0.4978 -- iter: 0544/1072
[A[ATraining Step: 86  | total loss: [1m[32m0.69300[0m[0m | time: 31.412s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5074 -- iter: 0576/1072
[A[ATraining Step: 87  | total loss: [1m[32m0.69297[0m[0m | time: 33.112s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5066 -- iter: 0608/1072
[A[ATraining Step: 88  | total loss: [1m[32m0.69307[0m[0m | time: 34.705s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5028 -- iter: 0640/1072
[A[ATraining Step: 89  | total loss: [1m[32m0.69337[0m[0m | time: 36.628s
[2K
| Adam | epoch: 003 | loss: 0.69337 - acc: 0.4932 -- iter: 0672/1072
[A[ATraining Step: 90  | total loss: [1m[32m0.69283[0m[0m | time: 38.302s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5095 -- iter: 0704/1072
[A[ATraining Step: 91  | total loss: [1m[32m0.69307[0m[0m | time: 40.228s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5023 -- iter: 0736/1072
[A[ATraining Step: 92  | total loss: [1m[32m0.69317[0m[0m | time: 41.912s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4989 -- iter: 0768/1072
[A[ATraining Step: 93  | total loss: [1m[32m0.69298[0m[0m | time: 43.639s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5022 -- iter: 0800/1072
[A[ATraining Step: 94  | total loss: [1m[32m0.69277[0m[0m | time: 45.680s
[2K
| Adam | epoch: 003 | loss: 0.69277 - acc: 0.5051 -- iter: 0832/1072
[A[ATraining Step: 95  | total loss: [1m[32m0.69278[0m[0m | time: 47.609s
[2K
| Adam | epoch: 003 | loss: 0.69278 - acc: 0.5014 -- iter: 0864/1072
[A[ATraining Step: 96  | total loss: [1m[32m0.69213[0m[0m | time: 49.865s
[2K
| Adam | epoch: 003 | loss: 0.69213 - acc: 0.5169 -- iter: 0896/1072
[A[ATraining Step: 97  | total loss: [1m[32m0.69226[0m[0m | time: 51.797s
[2K
| Adam | epoch: 003 | loss: 0.69226 - acc: 0.5121 -- iter: 0928/1072
[A[ATraining Step: 98  | total loss: [1m[32m0.69197[0m[0m | time: 53.507s
[2K
| Adam | epoch: 003 | loss: 0.69197 - acc: 0.5140 -- iter: 0960/1072
[A[ATraining Step: 99  | total loss: [1m[32m0.69200[0m[0m | time: 55.521s
[2K
| Adam | epoch: 003 | loss: 0.69200 - acc: 0.5095 -- iter: 0992/1072
[A[ATraining Step: 100  | total loss: [1m[32m0.69115[0m[0m | time: 57.383s
[2K
| Adam | epoch: 003 | loss: 0.69115 - acc: 0.5179 -- iter: 1024/1072
[A[ATraining Step: 101  | total loss: [1m[32m0.69068[0m[0m | time: 59.283s
[2K
| Adam | epoch: 003 | loss: 0.69068 - acc: 0.5161 -- iter: 1056/1072
[A[ATraining Step: 102  | total loss: [1m[32m0.69063[0m[0m | time: 65.706s
[2K
| Adam | epoch: 003 | loss: 0.69063 - acc: 0.5145 | val_loss: 0.68174 - val_acc: 0.5208 -- iter: 1072/1072
--
Training Step: 103  | total loss: [1m[32m0.69004[0m[0m | time: 1.807s
[2K
| Adam | epoch: 004 | loss: 0.69004 - acc: 0.5193 -- iter: 0032/1072
[A[ATraining Step: 104  | total loss: [1m[32m0.69217[0m[0m | time: 2.832s
[2K
| Adam | epoch: 004 | loss: 0.69217 - acc: 0.5018 -- iter: 0064/1072
[A[ATraining Step: 105  | total loss: [1m[32m0.69064[0m[0m | time: 3.655s
[2K
| Adam | epoch: 004 | loss: 0.69064 - acc: 0.5016 -- iter: 0096/1072
[A[ATraining Step: 106  | total loss: [1m[32m0.68923[0m[0m | time: 5.477s
[2K
| Adam | epoch: 004 | loss: 0.68923 - acc: 0.5014 -- iter: 0128/1072
[A[ATraining Step: 107  | total loss: [1m[32m0.68791[0m[0m | time: 7.491s
[2K
| Adam | epoch: 004 | loss: 0.68791 - acc: 0.5200 -- iter: 0160/1072
[A[ATraining Step: 108  | total loss: [1m[32m0.68772[0m[0m | time: 9.183s
[2K
| Adam | epoch: 004 | loss: 0.68772 - acc: 0.5149 -- iter: 0192/1072
[A[ATraining Step: 109  | total loss: [1m[32m0.68463[0m[0m | time: 10.926s
[2K
| Adam | epoch: 004 | loss: 0.68463 - acc: 0.5228 -- iter: 0224/1072
[A[ATraining Step: 110  | total loss: [1m[32m0.68684[0m[0m | time: 12.806s
[2K
| Adam | epoch: 004 | loss: 0.68684 - acc: 0.5143 -- iter: 0256/1072
[A[ATraining Step: 111  | total loss: [1m[32m0.68502[0m[0m | time: 14.489s
[2K
| Adam | epoch: 004 | loss: 0.68502 - acc: 0.5160 -- iter: 0288/1072
[A[ATraining Step: 112  | total loss: [1m[32m0.68563[0m[0m | time: 16.291s
[2K
| Adam | epoch: 004 | loss: 0.68563 - acc: 0.5112 -- iter: 0320/1072
[A[ATraining Step: 113  | total loss: [1m[32m0.68179[0m[0m | time: 18.314s
[2K
| Adam | epoch: 004 | loss: 0.68179 - acc: 0.5257 -- iter: 0352/1072
[A[ATraining Step: 114  | total loss: [1m[32m0.67968[0m[0m | time: 20.108s
[2K
| Adam | epoch: 004 | loss: 0.67968 - acc: 0.5325 -- iter: 0384/1072
[A[ATraining Step: 115  | total loss: [1m[32m0.68036[0m[0m | time: 22.087s
[2K
| Adam | epoch: 004 | loss: 0.68036 - acc: 0.5230 -- iter: 0416/1072
[A[ATraining Step: 116  | total loss: [1m[32m0.67830[0m[0m | time: 23.824s
[2K
| Adam | epoch: 004 | loss: 0.67830 - acc: 0.5395 -- iter: 0448/1072
[A[ATraining Step: 117  | total loss: [1m[32m0.67370[0m[0m | time: 25.857s
[2K
| Adam | epoch: 004 | loss: 0.67370 - acc: 0.5543 -- iter: 0480/1072
[A[ATraining Step: 118  | total loss: [1m[32m0.67043[0m[0m | time: 28.110s
[2K
| Adam | epoch: 004 | loss: 0.67043 - acc: 0.5582 -- iter: 0512/1072
[A[ATraining Step: 119  | total loss: [1m[32m0.66317[0m[0m | time: 29.796s
[2K
| Adam | epoch: 004 | loss: 0.66317 - acc: 0.5805 -- iter: 0544/1072
[A[ATraining Step: 120  | total loss: [1m[32m0.68280[0m[0m | time: 31.660s
[2K
| Adam | epoch: 004 | loss: 0.68280 - acc: 0.5600 -- iter: 0576/1072
[A[ATraining Step: 121  | total loss: [1m[32m0.67716[0m[0m | time: 33.270s
[2K
| Adam | epoch: 004 | loss: 0.67716 - acc: 0.5727 -- iter: 0608/1072
[A[ATraining Step: 122  | total loss: [1m[32m0.67521[0m[0m | time: 35.138s
[2K
| Adam | epoch: 004 | loss: 0.67521 - acc: 0.5748 -- iter: 0640/1072
[A[ATraining Step: 123  | total loss: [1m[32m0.67104[0m[0m | time: 37.234s
[2K
| Adam | epoch: 004 | loss: 0.67104 - acc: 0.5986 -- iter: 0672/1072
[A[ATraining Step: 124  | total loss: [1m[32m0.66937[0m[0m | time: 38.952s
[2K
| Adam | epoch: 004 | loss: 0.66937 - acc: 0.6075 -- iter: 0704/1072
[A[ATraining Step: 125  | total loss: [1m[32m0.66860[0m[0m | time: 40.738s
[2K
| Adam | epoch: 004 | loss: 0.66860 - acc: 0.6124 -- iter: 0736/1072
[A[ATraining Step: 126  | total loss: [1m[32m0.66397[0m[0m | time: 42.777s
[2K
| Adam | epoch: 004 | loss: 0.66397 - acc: 0.6230 -- iter: 0768/1072
[A[ATraining Step: 127  | total loss: [1m[32m0.66434[0m[0m | time: 44.607s
[2K
| Adam | epoch: 004 | loss: 0.66434 - acc: 0.6232 -- iter: 0800/1072
[A[ATraining Step: 128  | total loss: [1m[32m0.66044[0m[0m | time: 46.442s
[2K
| Adam | epoch: 004 | loss: 0.66044 - acc: 0.6296 -- iter: 0832/1072
[A[ATraining Step: 129  | total loss: [1m[32m0.65917[0m[0m | time: 48.371s
[2K
| Adam | epoch: 004 | loss: 0.65917 - acc: 0.6292 -- iter: 0864/1072
[A[ATraining Step: 130  | total loss: [1m[32m0.65922[0m[0m | time: 50.292s
[2K
| Adam | epoch: 004 | loss: 0.65922 - acc: 0.6288 -- iter: 0896/1072
[A[ATraining Step: 131  | total loss: [1m[32m0.65957[0m[0m | time: 52.160s
[2K
| Adam | epoch: 004 | loss: 0.65957 - acc: 0.6253 -- iter: 0928/1072
[A[ATraining Step: 132  | total loss: [1m[32m0.66149[0m[0m | time: 53.722s
[2K
| Adam | epoch: 004 | loss: 0.66149 - acc: 0.6190 -- iter: 0960/1072
[A[ATraining Step: 133  | total loss: [1m[32m0.65368[0m[0m | time: 55.534s
[2K
| Adam | epoch: 004 | loss: 0.65368 - acc: 0.6258 -- iter: 0992/1072
[A[ATraining Step: 134  | total loss: [1m[32m0.64634[0m[0m | time: 57.151s
[2K
| Adam | epoch: 004 | loss: 0.64634 - acc: 0.6414 -- iter: 1024/1072
[A[ATraining Step: 135  | total loss: [1m[32m0.64384[0m[0m | time: 59.021s
[2K
| Adam | epoch: 004 | loss: 0.64384 - acc: 0.6429 -- iter: 1056/1072
[A[ATraining Step: 136  | total loss: [1m[32m0.63747[0m[0m | time: 65.508s
[2K
| Adam | epoch: 004 | loss: 0.63747 - acc: 0.6473 | val_loss: 0.59343 - val_acc: 0.6577 -- iter: 1072/1072
--
Training Step: 137  | total loss: [1m[32m0.63270[0m[0m | time: 1.687s
[2K
| Adam | epoch: 005 | loss: 0.63270 - acc: 0.6545 -- iter: 0032/1072
[A[ATraining Step: 138  | total loss: [1m[32m0.61554[0m[0m | time: 3.531s
[2K
| Adam | epoch: 005 | loss: 0.61554 - acc: 0.6671 -- iter: 0064/1072
[A[ATraining Step: 139  | total loss: [1m[32m0.61344[0m[0m | time: 4.533s
[2K
| Adam | epoch: 005 | loss: 0.61344 - acc: 0.6692 -- iter: 0096/1072
[A[ATraining Step: 140  | total loss: [1m[32m0.60633[0m[0m | time: 5.439s
[2K
| Adam | epoch: 005 | loss: 0.60633 - acc: 0.6835 -- iter: 0128/1072
[A[ATraining Step: 141  | total loss: [1m[32m0.60140[0m[0m | time: 7.235s
[2K
| Adam | epoch: 005 | loss: 0.60140 - acc: 0.6839 -- iter: 0160/1072
[A[ATraining Step: 142  | total loss: [1m[32m0.60529[0m[0m | time: 9.186s
[2K
| Adam | epoch: 005 | loss: 0.60529 - acc: 0.6780 -- iter: 0192/1072
[A[ATraining Step: 143  | total loss: [1m[32m0.61175[0m[0m | time: 11.057s
[2K
| Adam | epoch: 005 | loss: 0.61175 - acc: 0.6790 -- iter: 0224/1072
[A[ATraining Step: 144  | total loss: [1m[32m0.60717[0m[0m | time: 12.983s
[2K
| Adam | epoch: 005 | loss: 0.60717 - acc: 0.6892 -- iter: 0256/1072
[A[ATraining Step: 145  | total loss: [1m[32m0.60956[0m[0m | time: 14.752s
[2K
| Adam | epoch: 005 | loss: 0.60956 - acc: 0.6828 -- iter: 0288/1072
[A[ATraining Step: 146  | total loss: [1m[32m0.60670[0m[0m | time: 16.768s
[2K
| Adam | epoch: 005 | loss: 0.60670 - acc: 0.6801 -- iter: 0320/1072
[A[ATraining Step: 147  | total loss: [1m[32m0.59271[0m[0m | time: 18.556s
[2K
| Adam | epoch: 005 | loss: 0.59271 - acc: 0.6934 -- iter: 0352/1072
[A[ATraining Step: 148  | total loss: [1m[32m0.58832[0m[0m | time: 20.246s
[2K
| Adam | epoch: 005 | loss: 0.58832 - acc: 0.6959 -- iter: 0384/1072
[A[ATraining Step: 149  | total loss: [1m[32m0.58636[0m[0m | time: 21.938s
[2K
| Adam | epoch: 005 | loss: 0.58636 - acc: 0.6982 -- iter: 0416/1072
[A[ATraining Step: 150  | total loss: [1m[32m0.58255[0m[0m | time: 23.817s
[2K
| Adam | epoch: 005 | loss: 0.58255 - acc: 0.6971 -- iter: 0448/1072
[A[ATraining Step: 151  | total loss: [1m[32m0.59051[0m[0m | time: 25.596s
[2K
| Adam | epoch: 005 | loss: 0.59051 - acc: 0.6837 -- iter: 0480/1072
[A[ATraining Step: 152  | total loss: [1m[32m0.57878[0m[0m | time: 27.419s
[2K
| Adam | epoch: 005 | loss: 0.57878 - acc: 0.6965 -- iter: 0512/1072
[A[ATraining Step: 153  | total loss: [1m[32m0.57013[0m[0m | time: 29.359s
[2K
| Adam | epoch: 005 | loss: 0.57013 - acc: 0.7050 -- iter: 0544/1072
[A[ATraining Step: 154  | total loss: [1m[32m0.57178[0m[0m | time: 31.066s
[2K
| Adam | epoch: 005 | loss: 0.57178 - acc: 0.7033 -- iter: 0576/1072
[A[ATraining Step: 155  | total loss: [1m[32m0.55922[0m[0m | time: 32.695s
[2K
| Adam | epoch: 005 | loss: 0.55922 - acc: 0.7173 -- iter: 0608/1072
[A[ATraining Step: 156  | total loss: [1m[32m0.54972[0m[0m | time: 34.611s
[2K
| Adam | epoch: 005 | loss: 0.54972 - acc: 0.7268 -- iter: 0640/1072
[A[ATraining Step: 157  | total loss: [1m[32m0.54122[0m[0m | time: 36.602s
[2K
| Adam | epoch: 005 | loss: 0.54122 - acc: 0.7291 -- iter: 0672/1072
[A[ATraining Step: 158  | total loss: [1m[32m0.55212[0m[0m | time: 38.537s
[2K
| Adam | epoch: 005 | loss: 0.55212 - acc: 0.7219 -- iter: 0704/1072
[A[ATraining Step: 159  | total loss: [1m[32m0.54603[0m[0m | time: 40.421s
[2K
| Adam | epoch: 005 | loss: 0.54603 - acc: 0.7278 -- iter: 0736/1072
[A[ATraining Step: 160  | total loss: [1m[32m0.54417[0m[0m | time: 42.387s
[2K
| Adam | epoch: 005 | loss: 0.54417 - acc: 0.7363 -- iter: 0768/1072
[A[ATraining Step: 161  | total loss: [1m[32m0.54346[0m[0m | time: 44.205s
[2K
| Adam | epoch: 005 | loss: 0.54346 - acc: 0.7345 -- iter: 0800/1072
[A[ATraining Step: 162  | total loss: [1m[32m0.53392[0m[0m | time: 46.224s
[2K
| Adam | epoch: 005 | loss: 0.53392 - acc: 0.7423 -- iter: 0832/1072
[A[ATraining Step: 163  | total loss: [1m[32m0.52298[0m[0m | time: 48.098s
[2K
| Adam | epoch: 005 | loss: 0.52298 - acc: 0.7525 -- iter: 0864/1072
[A[ATraining Step: 164  | total loss: [1m[32m0.50515[0m[0m | time: 49.826s
[2K
| Adam | epoch: 005 | loss: 0.50515 - acc: 0.7647 -- iter: 0896/1072
[A[ATraining Step: 165  | total loss: [1m[32m0.49803[0m[0m | time: 51.781s
[2K
| Adam | epoch: 005 | loss: 0.49803 - acc: 0.7664 -- iter: 0928/1072
[A[ATraining Step: 166  | total loss: [1m[32m0.48105[0m[0m | time: 53.560s
[2K
| Adam | epoch: 005 | loss: 0.48105 - acc: 0.7741 -- iter: 0960/1072
[A[ATraining Step: 167  | total loss: [1m[32m0.48060[0m[0m | time: 55.557s
[2K
| Adam | epoch: 005 | loss: 0.48060 - acc: 0.7779 -- iter: 0992/1072
[A[ATraining Step: 168  | total loss: [1m[32m0.47820[0m[0m | time: 57.359s
[2K
| Adam | epoch: 005 | loss: 0.47820 - acc: 0.7814 -- iter: 1024/1072
[A[ATraining Step: 169  | total loss: [1m[32m0.48506[0m[0m | time: 59.283s
[2K
| Adam | epoch: 005 | loss: 0.48506 - acc: 0.7783 -- iter: 1056/1072
[A[ATraining Step: 170  | total loss: [1m[32m0.49692[0m[0m | time: 66.202s
[2K
| Adam | epoch: 005 | loss: 0.49692 - acc: 0.7754 | val_loss: 0.39514 - val_acc: 0.8274 -- iter: 1072/1072
--
Training Step: 171  | total loss: [1m[32m0.48538[0m[0m | time: 1.986s
[2K
| Adam | epoch: 006 | loss: 0.48538 - acc: 0.7791 -- iter: 0032/1072
[A[ATraining Step: 172  | total loss: [1m[32m0.47371[0m[0m | time: 4.111s
[2K
| Adam | epoch: 006 | loss: 0.47371 - acc: 0.7856 -- iter: 0064/1072
[A[ATraining Step: 173  | total loss: [1m[32m0.46163[0m[0m | time: 5.909s
[2K
| Adam | epoch: 006 | loss: 0.46163 - acc: 0.7883 -- iter: 0096/1072
[A[ATraining Step: 174  | total loss: [1m[32m0.44060[0m[0m | time: 6.861s
[2K
| Adam | epoch: 006 | loss: 0.44060 - acc: 0.7970 -- iter: 0128/1072
[A[ATraining Step: 175  | total loss: [1m[32m0.42982[0m[0m | time: 7.828s
[2K
| Adam | epoch: 006 | loss: 0.42982 - acc: 0.8048 -- iter: 0160/1072
[A[ATraining Step: 176  | total loss: [1m[32m0.41523[0m[0m | time: 9.888s
[2K
| Adam | epoch: 006 | loss: 0.41523 - acc: 0.8118 -- iter: 0192/1072
[A[ATraining Step: 177  | total loss: [1m[32m0.40816[0m[0m | time: 11.768s
[2K
| Adam | epoch: 006 | loss: 0.40816 - acc: 0.8181 -- iter: 0224/1072
[A[ATraining Step: 178  | total loss: [1m[32m0.46072[0m[0m | time: 13.706s
[2K
| Adam | epoch: 006 | loss: 0.46072 - acc: 0.7925 -- iter: 0256/1072
[A[ATraining Step: 179  | total loss: [1m[32m0.46331[0m[0m | time: 15.588s
[2K
| Adam | epoch: 006 | loss: 0.46331 - acc: 0.7789 -- iter: 0288/1072
[A[ATraining Step: 180  | total loss: [1m[32m0.45544[0m[0m | time: 17.639s
[2K
| Adam | epoch: 006 | loss: 0.45544 - acc: 0.7854 -- iter: 0320/1072
[A[ATraining Step: 181  | total loss: [1m[32m0.44851[0m[0m | time: 19.378s
[2K
| Adam | epoch: 006 | loss: 0.44851 - acc: 0.7819 -- iter: 0352/1072
[A[ATraining Step: 182  | total loss: [1m[32m0.43980[0m[0m | time: 21.281s
[2K
| Adam | epoch: 006 | loss: 0.43980 - acc: 0.7912 -- iter: 0384/1072
[A[ATraining Step: 183  | total loss: [1m[32m0.44755[0m[0m | time: 23.246s
[2K
| Adam | epoch: 006 | loss: 0.44755 - acc: 0.7902 -- iter: 0416/1072
[A[ATraining Step: 184  | total loss: [1m[32m0.42274[0m[0m | time: 25.144s
[2K
| Adam | epoch: 006 | loss: 0.42274 - acc: 0.8049 -- iter: 0448/1072
[A[ATraining Step: 185  | total loss: [1m[32m0.43039[0m[0m | time: 26.846s
[2K
| Adam | epoch: 006 | loss: 0.43039 - acc: 0.8088 -- iter: 0480/1072
[A[ATraining Step: 186  | total loss: [1m[32m0.43443[0m[0m | time: 28.787s
[2K
| Adam | epoch: 006 | loss: 0.43443 - acc: 0.8092 -- iter: 0512/1072
[A[ATraining Step: 187  | total loss: [1m[32m0.44512[0m[0m | time: 30.564s
[2K
| Adam | epoch: 006 | loss: 0.44512 - acc: 0.8033 -- iter: 0544/1072
[A[ATraining Step: 188  | total loss: [1m[32m0.44332[0m[0m | time: 32.339s
[2K
| Adam | epoch: 006 | loss: 0.44332 - acc: 0.8011 -- iter: 0576/1072
[A[ATraining Step: 189  | total loss: [1m[32m0.44875[0m[0m | time: 34.162s
[2K
| Adam | epoch: 006 | loss: 0.44875 - acc: 0.7991 -- iter: 0608/1072
[A[ATraining Step: 190  | total loss: [1m[32m0.43270[0m[0m | time: 35.944s
[2K
| Adam | epoch: 006 | loss: 0.43270 - acc: 0.8129 -- iter: 0640/1072
[A[ATraining Step: 191  | total loss: [1m[32m0.42670[0m[0m | time: 37.849s
[2K
| Adam | epoch: 006 | loss: 0.42670 - acc: 0.8191 -- iter: 0672/1072
[A[ATraining Step: 192  | total loss: [1m[32m0.42331[0m[0m | time: 39.886s
[2K
| Adam | epoch: 006 | loss: 0.42331 - acc: 0.8185 -- iter: 0704/1072
[A[ATraining Step: 193  | total loss: [1m[32m0.41196[0m[0m | time: 42.099s
[2K
| Adam | epoch: 006 | loss: 0.41196 - acc: 0.8241 -- iter: 0736/1072
[A[ATraining Step: 194  | total loss: [1m[32m0.41610[0m[0m | time: 44.097s
[2K
| Adam | epoch: 006 | loss: 0.41610 - acc: 0.8167 -- iter: 0768/1072
[A[ATraining Step: 195  | total loss: [1m[32m0.41886[0m[0m | time: 46.093s
[2K
| Adam | epoch: 006 | loss: 0.41886 - acc: 0.8100 -- iter: 0800/1072
[A[ATraining Step: 196  | total loss: [1m[32m0.42763[0m[0m | time: 48.209s
[2K
| Adam | epoch: 006 | loss: 0.42763 - acc: 0.8009 -- iter: 0832/1072
[A[ATraining Step: 197  | total loss: [1m[32m0.43250[0m[0m | time: 50.351s
[2K
| Adam | epoch: 006 | loss: 0.43250 - acc: 0.7958 -- iter: 0864/1072
[A[ATraining Step: 198  | total loss: [1m[32m0.41707[0m[0m | time: 52.169s
[2K
| Adam | epoch: 006 | loss: 0.41707 - acc: 0.8100 -- iter: 0896/1072
[A[ATraining Step: 199  | total loss: [1m[32m0.40945[0m[0m | time: 53.874s
[2K
| Adam | epoch: 006 | loss: 0.40945 - acc: 0.8134 -- iter: 0928/1072
[A[ATraining Step: 200  | total loss: [1m[32m0.41824[0m[0m | time: 60.257s
[2K
| Adam | epoch: 006 | loss: 0.41824 - acc: 0.8070 | val_loss: 0.39826 - val_acc: 0.8155 -- iter: 0960/1072
--
Training Step: 201  | total loss: [1m[32m0.39625[0m[0m | time: 62.171s
[2K
| Adam | epoch: 006 | loss: 0.39625 - acc: 0.8169 -- iter: 0992/1072
[A[ATraining Step: 202  | total loss: [1m[32m0.40734[0m[0m | time: 63.934s
[2K
| Adam | epoch: 006 | loss: 0.40734 - acc: 0.8071 -- iter: 1024/1072
[A[ATraining Step: 203  | total loss: [1m[32m0.42513[0m[0m | time: 65.630s
[2K
| Adam | epoch: 006 | loss: 0.42513 - acc: 0.7952 -- iter: 1056/1072
[A[ATraining Step: 204  | total loss: [1m[32m0.40774[0m[0m | time: 72.062s
[2K
| Adam | epoch: 006 | loss: 0.40774 - acc: 0.8094 | val_loss: 0.41029 - val_acc: 0.8125 -- iter: 1072/1072
--
Training Step: 205  | total loss: [1m[32m0.41353[0m[0m | time: 2.012s
[2K
| Adam | epoch: 007 | loss: 0.41353 - acc: 0.8003 -- iter: 0032/1072
[A[ATraining Step: 206  | total loss: [1m[32m0.39651[0m[0m | time: 3.869s
[2K
| Adam | epoch: 007 | loss: 0.39651 - acc: 0.8109 -- iter: 0064/1072
[A[ATraining Step: 207  | total loss: [1m[32m0.40277[0m[0m | time: 5.606s
[2K
| Adam | epoch: 007 | loss: 0.40277 - acc: 0.8111 -- iter: 0096/1072
[A[ATraining Step: 208  | total loss: [1m[32m0.41541[0m[0m | time: 7.466s
[2K
| Adam | epoch: 007 | loss: 0.41541 - acc: 0.8112 -- iter: 0128/1072
[A[ATraining Step: 209  | total loss: [1m[32m0.40356[0m[0m | time: 8.483s
[2K
| Adam | epoch: 007 | loss: 0.40356 - acc: 0.8145 -- iter: 0160/1072
[A[ATraining Step: 210  | total loss: [1m[32m0.38191[0m[0m | time: 9.244s
[2K
| Adam | epoch: 007 | loss: 0.38191 - acc: 0.8330 -- iter: 0192/1072
[A[ATraining Step: 211  | total loss: [1m[32m0.35886[0m[0m | time: 10.774s
[2K
| Adam | epoch: 007 | loss: 0.35886 - acc: 0.8497 -- iter: 0224/1072
[A[ATraining Step: 212  | total loss: [1m[32m0.35344[0m[0m | time: 12.705s
[2K
| Adam | epoch: 007 | loss: 0.35344 - acc: 0.8554 -- iter: 0256/1072
[A[ATraining Step: 213  | total loss: [1m[32m0.43489[0m[0m | time: 14.519s
[2K
| Adam | epoch: 007 | loss: 0.43489 - acc: 0.8230 -- iter: 0288/1072
[A[ATraining Step: 214  | total loss: [1m[32m0.42816[0m[0m | time: 16.428s
[2K
| Adam | epoch: 007 | loss: 0.42816 - acc: 0.8344 -- iter: 0320/1072
[A[ATraining Step: 215  | total loss: [1m[32m0.41546[0m[0m | time: 18.295s
[2K
| Adam | epoch: 007 | loss: 0.41546 - acc: 0.8354 -- iter: 0352/1072
[A[ATraining Step: 216  | total loss: [1m[32m0.39391[0m[0m | time: 20.030s
[2K
| Adam | epoch: 007 | loss: 0.39391 - acc: 0.8487 -- iter: 0384/1072
[A[ATraining Step: 217  | total loss: [1m[32m0.37331[0m[0m | time: 21.849s
[2K
| Adam | epoch: 007 | loss: 0.37331 - acc: 0.8544 -- iter: 0416/1072
[A[ATraining Step: 218  | total loss: [1m[32m0.36364[0m[0m | time: 23.616s
[2K
| Adam | epoch: 007 | loss: 0.36364 - acc: 0.8596 -- iter: 0448/1072
[A[ATraining Step: 219  | total loss: [1m[32m0.35377[0m[0m | time: 25.184s
[2K
| Adam | epoch: 007 | loss: 0.35377 - acc: 0.8643 -- iter: 0480/1072
[A[ATraining Step: 220  | total loss: [1m[32m0.35518[0m[0m | time: 27.000s
[2K
| Adam | epoch: 007 | loss: 0.35518 - acc: 0.8622 -- iter: 0512/1072
[A[ATraining Step: 221  | total loss: [1m[32m0.35200[0m[0m | time: 28.844s
[2K
| Adam | epoch: 007 | loss: 0.35200 - acc: 0.8635 -- iter: 0544/1072
[A[ATraining Step: 222  | total loss: [1m[32m0.34574[0m[0m | time: 30.828s
[2K
| Adam | epoch: 007 | loss: 0.34574 - acc: 0.8647 -- iter: 0576/1072
[A[ATraining Step: 223  | total loss: [1m[32m0.34006[0m[0m | time: 32.709s
[2K
| Adam | epoch: 007 | loss: 0.34006 - acc: 0.8657 -- iter: 0608/1072
[A[ATraining Step: 224  | total loss: [1m[32m0.33054[0m[0m | time: 34.484s
[2K
| Adam | epoch: 007 | loss: 0.33054 - acc: 0.8729 -- iter: 0640/1072
[A[ATraining Step: 225  | total loss: [1m[32m0.31752[0m[0m | time: 36.570s
[2K
| Adam | epoch: 007 | loss: 0.31752 - acc: 0.8793 -- iter: 0672/1072
[A[ATraining Step: 226  | total loss: [1m[32m0.32965[0m[0m | time: 38.183s
[2K
| Adam | epoch: 007 | loss: 0.32965 - acc: 0.8695 -- iter: 0704/1072
[A[ATraining Step: 227  | total loss: [1m[32m0.32480[0m[0m | time: 40.142s
[2K
| Adam | epoch: 007 | loss: 0.32480 - acc: 0.8701 -- iter: 0736/1072
[A[ATraining Step: 228  | total loss: [1m[32m0.31710[0m[0m | time: 42.179s
[2K
| Adam | epoch: 007 | loss: 0.31710 - acc: 0.8737 -- iter: 0768/1072
[A[ATraining Step: 229  | total loss: [1m[32m0.30312[0m[0m | time: 43.879s
[2K
| Adam | epoch: 007 | loss: 0.30312 - acc: 0.8801 -- iter: 0800/1072
[A[ATraining Step: 230  | total loss: [1m[32m0.32818[0m[0m | time: 45.574s
[2K
| Adam | epoch: 007 | loss: 0.32818 - acc: 0.8671 -- iter: 0832/1072
[A[ATraining Step: 231  | total loss: [1m[32m0.33382[0m[0m | time: 47.647s
[2K
| Adam | epoch: 007 | loss: 0.33382 - acc: 0.8647 -- iter: 0864/1072
[A[ATraining Step: 232  | total loss: [1m[32m0.36287[0m[0m | time: 49.472s
[2K
| Adam | epoch: 007 | loss: 0.36287 - acc: 0.8533 -- iter: 0896/1072
[A[ATraining Step: 233  | total loss: [1m[32m0.35788[0m[0m | time: 51.191s
[2K
| Adam | epoch: 007 | loss: 0.35788 - acc: 0.8523 -- iter: 0928/1072
[A[ATraining Step: 234  | total loss: [1m[32m0.35848[0m[0m | time: 52.819s
[2K
| Adam | epoch: 007 | loss: 0.35848 - acc: 0.8515 -- iter: 0960/1072
[A[ATraining Step: 235  | total loss: [1m[32m0.35037[0m[0m | time: 54.775s
[2K
| Adam | epoch: 007 | loss: 0.35037 - acc: 0.8569 -- iter: 0992/1072
[A[ATraining Step: 236  | total loss: [1m[32m0.34429[0m[0m | time: 56.859s
[2K
| Adam | epoch: 007 | loss: 0.34429 - acc: 0.8619 -- iter: 1024/1072
[A[ATraining Step: 237  | total loss: [1m[32m0.33806[0m[0m | time: 58.460s
[2K
| Adam | epoch: 007 | loss: 0.33806 - acc: 0.8663 -- iter: 1056/1072
[A[ATraining Step: 238  | total loss: [1m[32m0.36986[0m[0m | time: 64.537s
[2K
| Adam | epoch: 007 | loss: 0.36986 - acc: 0.8547 | val_loss: 0.43537 - val_acc: 0.7887 -- iter: 1072/1072
--
Training Step: 239  | total loss: [1m[32m0.36777[0m[0m | time: 1.579s
[2K
| Adam | epoch: 008 | loss: 0.36777 - acc: 0.8473 -- iter: 0032/1072
[A[ATraining Step: 240  | total loss: [1m[32m0.37365[0m[0m | time: 3.405s
[2K
| Adam | epoch: 008 | loss: 0.37365 - acc: 0.8501 -- iter: 0064/1072
[A[ATraining Step: 241  | total loss: [1m[32m0.36669[0m[0m | time: 5.560s
[2K
| Adam | epoch: 008 | loss: 0.36669 - acc: 0.8557 -- iter: 0096/1072
[A[ATraining Step: 242  | total loss: [1m[32m0.36438[0m[0m | time: 7.403s
[2K
| Adam | epoch: 008 | loss: 0.36438 - acc: 0.8545 -- iter: 0128/1072
[A[ATraining Step: 243  | total loss: [1m[32m0.35852[0m[0m | time: 9.327s
[2K
| Adam | epoch: 008 | loss: 0.35852 - acc: 0.8503 -- iter: 0160/1072
[A[ATraining Step: 244  | total loss: [1m[32m0.35443[0m[0m | time: 10.311s
[2K
| Adam | epoch: 008 | loss: 0.35443 - acc: 0.8559 -- iter: 0192/1072
[A[ATraining Step: 245  | total loss: [1m[32m0.35050[0m[0m | time: 11.235s
[2K
| Adam | epoch: 008 | loss: 0.35050 - acc: 0.8641 -- iter: 0224/1072
[A[ATraining Step: 246  | total loss: [1m[32m0.34467[0m[0m | time: 13.049s
[2K
| Adam | epoch: 008 | loss: 0.34467 - acc: 0.8714 -- iter: 0256/1072
[A[ATraining Step: 247  | total loss: [1m[32m0.34210[0m[0m | time: 14.834s
[2K
| Adam | epoch: 008 | loss: 0.34210 - acc: 0.8749 -- iter: 0288/1072
[A[ATraining Step: 248  | total loss: [1m[32m0.45305[0m[0m | time: 16.613s
[2K
| Adam | epoch: 008 | loss: 0.45305 - acc: 0.8280 -- iter: 0320/1072
[A[ATraining Step: 249  | total loss: [1m[32m0.43509[0m[0m | time: 18.337s
[2K
| Adam | epoch: 008 | loss: 0.43509 - acc: 0.8327 -- iter: 0352/1072
[A[ATraining Step: 250  | total loss: [1m[32m0.42273[0m[0m | time: 20.137s
[2K
| Adam | epoch: 008 | loss: 0.42273 - acc: 0.8307 -- iter: 0384/1072
[A[ATraining Step: 251  | total loss: [1m[32m0.40708[0m[0m | time: 21.759s
[2K
| Adam | epoch: 008 | loss: 0.40708 - acc: 0.8414 -- iter: 0416/1072
[A[ATraining Step: 252  | total loss: [1m[32m0.41969[0m[0m | time: 23.590s
[2K
| Adam | epoch: 008 | loss: 0.41969 - acc: 0.8260 -- iter: 0448/1072
[A[ATraining Step: 253  | total loss: [1m[32m0.41244[0m[0m | time: 25.499s
[2K
| Adam | epoch: 008 | loss: 0.41244 - acc: 0.8246 -- iter: 0480/1072
[A[ATraining Step: 254  | total loss: [1m[32m0.39773[0m[0m | time: 27.357s
[2K
| Adam | epoch: 008 | loss: 0.39773 - acc: 0.8391 -- iter: 0512/1072
[A[ATraining Step: 255  | total loss: [1m[32m0.39569[0m[0m | time: 29.190s
[2K
| Adam | epoch: 008 | loss: 0.39569 - acc: 0.8364 -- iter: 0544/1072
[A[ATraining Step: 256  | total loss: [1m[32m0.38248[0m[0m | time: 30.982s
[2K
| Adam | epoch: 008 | loss: 0.38248 - acc: 0.8403 -- iter: 0576/1072
[A[ATraining Step: 257  | total loss: [1m[32m0.37957[0m[0m | time: 32.752s
[2K
| Adam | epoch: 008 | loss: 0.37957 - acc: 0.8406 -- iter: 0608/1072
[A[ATraining Step: 258  | total loss: [1m[32m0.36170[0m[0m | time: 34.752s
[2K
| Adam | epoch: 008 | loss: 0.36170 - acc: 0.8503 -- iter: 0640/1072
[A[ATraining Step: 259  | total loss: [1m[32m0.37661[0m[0m | time: 36.555s
[2K
| Adam | epoch: 008 | loss: 0.37661 - acc: 0.8371 -- iter: 0672/1072
[A[ATraining Step: 260  | total loss: [1m[32m0.37809[0m[0m | time: 38.382s
[2K
| Adam | epoch: 008 | loss: 0.37809 - acc: 0.8316 -- iter: 0704/1072
[A[ATraining Step: 261  | total loss: [1m[32m0.37651[0m[0m | time: 40.066s
[2K
| Adam | epoch: 008 | loss: 0.37651 - acc: 0.8296 -- iter: 0736/1072
[A[ATraining Step: 262  | total loss: [1m[32m0.36009[0m[0m | time: 41.750s
[2K
| Adam | epoch: 008 | loss: 0.36009 - acc: 0.8373 -- iter: 0768/1072
[A[ATraining Step: 263  | total loss: [1m[32m0.35140[0m[0m | time: 43.546s
[2K
| Adam | epoch: 008 | loss: 0.35140 - acc: 0.8473 -- iter: 0800/1072
[A[ATraining Step: 264  | total loss: [1m[32m0.36459[0m[0m | time: 45.400s
[2K
| Adam | epoch: 008 | loss: 0.36459 - acc: 0.8407 -- iter: 0832/1072
[A[ATraining Step: 265  | total loss: [1m[32m0.37549[0m[0m | time: 47.080s
[2K
| Adam | epoch: 008 | loss: 0.37549 - acc: 0.8348 -- iter: 0864/1072
[A[ATraining Step: 266  | total loss: [1m[32m0.36220[0m[0m | time: 49.231s
[2K
| Adam | epoch: 008 | loss: 0.36220 - acc: 0.8450 -- iter: 0896/1072
[A[ATraining Step: 267  | total loss: [1m[32m0.34866[0m[0m | time: 50.986s
[2K
| Adam | epoch: 008 | loss: 0.34866 - acc: 0.8512 -- iter: 0928/1072
[A[ATraining Step: 268  | total loss: [1m[32m0.34688[0m[0m | time: 52.642s
[2K
| Adam | epoch: 008 | loss: 0.34688 - acc: 0.8535 -- iter: 0960/1072
[A[ATraining Step: 269  | total loss: [1m[32m0.32952[0m[0m | time: 54.390s
[2K
| Adam | epoch: 008 | loss: 0.32952 - acc: 0.8682 -- iter: 0992/1072
[A[ATraining Step: 270  | total loss: [1m[32m0.32497[0m[0m | time: 56.090s
[2K
| Adam | epoch: 008 | loss: 0.32497 - acc: 0.8689 -- iter: 1024/1072
[A[ATraining Step: 271  | total loss: [1m[32m0.31626[0m[0m | time: 57.833s
[2K
| Adam | epoch: 008 | loss: 0.31626 - acc: 0.8726 -- iter: 1056/1072
[A[ATraining Step: 272  | total loss: [1m[32m0.34020[0m[0m | time: 64.001s
[2K
| Adam | epoch: 008 | loss: 0.34020 - acc: 0.8604 | val_loss: 0.33683 - val_acc: 0.8423 -- iter: 1072/1072
--
Training Step: 273  | total loss: [1m[32m0.33493[0m[0m | time: 1.784s
[2K
| Adam | epoch: 009 | loss: 0.33493 - acc: 0.8681 -- iter: 0032/1072
[A[ATraining Step: 274  | total loss: [1m[32m0.33145[0m[0m | time: 3.562s
[2K
| Adam | epoch: 009 | loss: 0.33145 - acc: 0.8688 -- iter: 0064/1072
[A[ATraining Step: 275  | total loss: [1m[32m0.32034[0m[0m | time: 5.468s
[2K
| Adam | epoch: 009 | loss: 0.32034 - acc: 0.8756 -- iter: 0096/1072
[A[ATraining Step: 276  | total loss: [1m[32m0.30930[0m[0m | time: 7.195s
[2K
| Adam | epoch: 009 | loss: 0.30930 - acc: 0.8787 -- iter: 0128/1072
[A[ATraining Step: 277  | total loss: [1m[32m0.30066[0m[0m | time: 8.739s
[2K
| Adam | epoch: 009 | loss: 0.30066 - acc: 0.8846 -- iter: 0160/1072
[A[ATraining Step: 278  | total loss: [1m[32m0.29510[0m[0m | time: 10.457s
[2K
| Adam | epoch: 009 | loss: 0.29510 - acc: 0.8899 -- iter: 0192/1072
[A[ATraining Step: 279  | total loss: [1m[32m0.29297[0m[0m | time: 11.265s
[2K
| Adam | epoch: 009 | loss: 0.29297 - acc: 0.8915 -- iter: 0224/1072
[A[ATraining Step: 280  | total loss: [1m[32m0.29600[0m[0m | time: 12.074s
[2K
| Adam | epoch: 009 | loss: 0.29600 - acc: 0.8899 -- iter: 0256/1072
[A[ATraining Step: 281  | total loss: [1m[32m0.29274[0m[0m | time: 13.627s
[2K
| Adam | epoch: 009 | loss: 0.29274 - acc: 0.8884 -- iter: 0288/1072
[A[ATraining Step: 282  | total loss: [1m[32m0.27974[0m[0m | time: 15.155s
[2K
| Adam | epoch: 009 | loss: 0.27974 - acc: 0.8933 -- iter: 0320/1072
[A[ATraining Step: 283  | total loss: [1m[32m0.27097[0m[0m | time: 16.701s
[2K
| Adam | epoch: 009 | loss: 0.27097 - acc: 0.8946 -- iter: 0352/1072
[A[ATraining Step: 284  | total loss: [1m[32m0.26255[0m[0m | time: 18.472s
[2K
| Adam | epoch: 009 | loss: 0.26255 - acc: 0.8957 -- iter: 0384/1072
[A[ATraining Step: 285  | total loss: [1m[32m0.24710[0m[0m | time: 20.285s
[2K
| Adam | epoch: 009 | loss: 0.24710 - acc: 0.9062 -- iter: 0416/1072
[A[ATraining Step: 286  | total loss: [1m[32m0.24572[0m[0m | time: 21.816s
[2K
| Adam | epoch: 009 | loss: 0.24572 - acc: 0.9031 -- iter: 0448/1072
[A[ATraining Step: 287  | total loss: [1m[32m0.23822[0m[0m | time: 23.294s
[2K
| Adam | epoch: 009 | loss: 0.23822 - acc: 0.9096 -- iter: 0480/1072
[A[ATraining Step: 288  | total loss: [1m[32m0.22138[0m[0m | time: 25.016s
[2K
| Adam | epoch: 009 | loss: 0.22138 - acc: 0.9187 -- iter: 0512/1072
[A[ATraining Step: 289  | total loss: [1m[32m0.21883[0m[0m | time: 26.597s
[2K
| Adam | epoch: 009 | loss: 0.21883 - acc: 0.9237 -- iter: 0544/1072
[A[ATraining Step: 290  | total loss: [1m[32m0.21265[0m[0m | time: 28.322s
[2K
| Adam | epoch: 009 | loss: 0.21265 - acc: 0.9188 -- iter: 0576/1072
[A[ATraining Step: 291  | total loss: [1m[32m0.21107[0m[0m | time: 30.053s
[2K
| Adam | epoch: 009 | loss: 0.21107 - acc: 0.9207 -- iter: 0608/1072
[A[ATraining Step: 292  | total loss: [1m[32m0.20234[0m[0m | time: 31.584s
[2K
| Adam | epoch: 009 | loss: 0.20234 - acc: 0.9224 -- iter: 0640/1072
[A[ATraining Step: 293  | total loss: [1m[32m0.19100[0m[0m | time: 33.231s
[2K
| Adam | epoch: 009 | loss: 0.19100 - acc: 0.9301 -- iter: 0672/1072
[A[ATraining Step: 294  | total loss: [1m[32m0.19827[0m[0m | time: 34.840s
[2K
| Adam | epoch: 009 | loss: 0.19827 - acc: 0.9246 -- iter: 0704/1072
[A[ATraining Step: 295  | total loss: [1m[32m0.20576[0m[0m | time: 36.394s
[2K
| Adam | epoch: 009 | loss: 0.20576 - acc: 0.9259 -- iter: 0736/1072
[A[ATraining Step: 296  | total loss: [1m[32m0.19764[0m[0m | time: 37.985s
[2K
| Adam | epoch: 009 | loss: 0.19764 - acc: 0.9302 -- iter: 0768/1072
[A[ATraining Step: 297  | total loss: [1m[32m0.18497[0m[0m | time: 39.812s
[2K
| Adam | epoch: 009 | loss: 0.18497 - acc: 0.9372 -- iter: 0800/1072
[A[ATraining Step: 298  | total loss: [1m[32m0.18962[0m[0m | time: 41.717s
[2K
| Adam | epoch: 009 | loss: 0.18962 - acc: 0.9341 -- iter: 0832/1072
[A[ATraining Step: 299  | total loss: [1m[32m0.19583[0m[0m | time: 43.645s
[2K
| Adam | epoch: 009 | loss: 0.19583 - acc: 0.9313 -- iter: 0864/1072
[A[ATraining Step: 300  | total loss: [1m[32m0.19069[0m[0m | time: 45.412s
[2K
| Adam | epoch: 009 | loss: 0.19069 - acc: 0.9350 -- iter: 0896/1072
[A[ATraining Step: 301  | total loss: [1m[32m0.18551[0m[0m | time: 47.369s
[2K
| Adam | epoch: 009 | loss: 0.18551 - acc: 0.9322 -- iter: 0928/1072
[A[ATraining Step: 302  | total loss: [1m[32m0.19086[0m[0m | time: 49.440s
[2K
| Adam | epoch: 009 | loss: 0.19086 - acc: 0.9327 -- iter: 0960/1072
[A[ATraining Step: 303  | total loss: [1m[32m0.20025[0m[0m | time: 51.112s
[2K
| Adam | epoch: 009 | loss: 0.20025 - acc: 0.9238 -- iter: 0992/1072
[A[ATraining Step: 304  | total loss: [1m[32m0.20281[0m[0m | time: 52.759s
[2K
| Adam | epoch: 009 | loss: 0.20281 - acc: 0.9252 -- iter: 1024/1072
[A[ATraining Step: 305  | total loss: [1m[32m0.21373[0m[0m | time: 54.923s
[2K
| Adam | epoch: 009 | loss: 0.21373 - acc: 0.9202 -- iter: 1056/1072
[A[ATraining Step: 306  | total loss: [1m[32m0.20973[0m[0m | time: 61.214s
[2K
| Adam | epoch: 009 | loss: 0.20973 - acc: 0.9219 | val_loss: 0.48277 - val_acc: 0.8065 -- iter: 1072/1072
--
Training Step: 307  | total loss: [1m[32m0.20342[0m[0m | time: 1.933s
[2K
| Adam | epoch: 010 | loss: 0.20342 - acc: 0.9234 -- iter: 0032/1072
[A[ATraining Step: 308  | total loss: [1m[32m0.22082[0m[0m | time: 3.985s
[2K
| Adam | epoch: 010 | loss: 0.22082 - acc: 0.9155 -- iter: 0064/1072
[A[ATraining Step: 309  | total loss: [1m[32m0.21835[0m[0m | time: 5.873s
[2K
| Adam | epoch: 010 | loss: 0.21835 - acc: 0.9177 -- iter: 0096/1072
[A[ATraining Step: 310  | total loss: [1m[32m0.21107[0m[0m | time: 7.829s
[2K
| Adam | epoch: 010 | loss: 0.21107 - acc: 0.9197 -- iter: 0128/1072
[A[ATraining Step: 311  | total loss: [1m[32m0.21017[0m[0m | time: 9.580s
[2K
| Adam | epoch: 010 | loss: 0.21017 - acc: 0.9183 -- iter: 0160/1072
[A[ATraining Step: 312  | total loss: [1m[32m0.20579[0m[0m | time: 11.593s
[2K
| Adam | epoch: 010 | loss: 0.20579 - acc: 0.9202 -- iter: 0192/1072
[A[ATraining Step: 313  | total loss: [1m[32m0.21565[0m[0m | time: 13.536s
[2K
| Adam | epoch: 010 | loss: 0.21565 - acc: 0.9157 -- iter: 0224/1072
[A[ATraining Step: 314  | total loss: [1m[32m0.21612[0m[0m | time: 14.608s
[2K
| Adam | epoch: 010 | loss: 0.21612 - acc: 0.9116 -- iter: 0256/1072
[A[ATraining Step: 315  | total loss: [1m[32m0.20859[0m[0m | time: 15.691s
[2K
| Adam | epoch: 010 | loss: 0.20859 - acc: 0.9142 -- iter: 0288/1072
[A[ATraining Step: 316  | total loss: [1m[32m0.19528[0m[0m | time: 18.016s
[2K
| Adam | epoch: 010 | loss: 0.19528 - acc: 0.9228 -- iter: 0320/1072
[A[ATraining Step: 317  | total loss: [1m[32m0.18637[0m[0m | time: 19.954s
[2K
| Adam | epoch: 010 | loss: 0.18637 - acc: 0.9305 -- iter: 0352/1072
[A[ATraining Step: 318  | total loss: [1m[32m0.33180[0m[0m | time: 21.707s
[2K
| Adam | epoch: 010 | loss: 0.33180 - acc: 0.8937 -- iter: 0384/1072
[A[ATraining Step: 319  | total loss: [1m[32m0.31734[0m[0m | time: 23.380s
[2K
| Adam | epoch: 010 | loss: 0.31734 - acc: 0.9012 -- iter: 0416/1072
[A[ATraining Step: 320  | total loss: [1m[32m0.29917[0m[0m | time: 25.399s
[2K
| Adam | epoch: 010 | loss: 0.29917 - acc: 0.9049 -- iter: 0448/1072
[A[ATraining Step: 321  | total loss: [1m[32m0.27847[0m[0m | time: 27.394s
[2K
| Adam | epoch: 010 | loss: 0.27847 - acc: 0.9112 -- iter: 0480/1072
[A[ATraining Step: 322  | total loss: [1m[32m0.26031[0m[0m | time: 29.449s
[2K
| Adam | epoch: 010 | loss: 0.26031 - acc: 0.9201 -- iter: 0512/1072
[A[ATraining Step: 323  | total loss: [1m[32m0.23888[0m[0m | time: 31.546s
[2K
| Adam | epoch: 010 | loss: 0.23888 - acc: 0.9281 -- iter: 0544/1072
[A[ATraining Step: 324  | total loss: [1m[32m0.23148[0m[0m | time: 33.281s
[2K
| Adam | epoch: 010 | loss: 0.23148 - acc: 0.9290 -- iter: 0576/1072
[A[ATraining Step: 325  | total loss: [1m[32m0.22541[0m[0m | time: 35.265s
[2K
| Adam | epoch: 010 | loss: 0.22541 - acc: 0.9299 -- iter: 0608/1072
[A[ATraining Step: 326  | total loss: [1m[32m0.20784[0m[0m | time: 37.270s
[2K
| Adam | epoch: 010 | loss: 0.20784 - acc: 0.9369 -- iter: 0640/1072
[A[ATraining Step: 327  | total loss: [1m[32m0.20433[0m[0m | time: 39.185s
[2K
| Adam | epoch: 010 | loss: 0.20433 - acc: 0.9370 -- iter: 0672/1072
[A[ATraining Step: 328  | total loss: [1m[32m0.19031[0m[0m | time: 41.003s
[2K
| Adam | epoch: 010 | loss: 0.19031 - acc: 0.9433 -- iter: 0704/1072
[A[ATraining Step: 329  | total loss: [1m[32m0.17602[0m[0m | time: 42.796s
[2K
| Adam | epoch: 010 | loss: 0.17602 - acc: 0.9489 -- iter: 0736/1072
[A[ATraining Step: 330  | total loss: [1m[32m0.16700[0m[0m | time: 44.712s
[2K
| Adam | epoch: 010 | loss: 0.16700 - acc: 0.9540 -- iter: 0768/1072
[A[ATraining Step: 331  | total loss: [1m[32m0.16242[0m[0m | time: 46.685s
[2K
| Adam | epoch: 010 | loss: 0.16242 - acc: 0.9524 -- iter: 0800/1072
[A[ATraining Step: 332  | total loss: [1m[32m0.16444[0m[0m | time: 48.787s
[2K
| Adam | epoch: 010 | loss: 0.16444 - acc: 0.9509 -- iter: 0832/1072
[A[ATraining Step: 333  | total loss: [1m[32m0.15716[0m[0m | time: 50.629s
[2K
| Adam | epoch: 010 | loss: 0.15716 - acc: 0.9527 -- iter: 0864/1072
[A[ATraining Step: 334  | total loss: [1m[32m0.15251[0m[0m | time: 52.333s
[2K
| Adam | epoch: 010 | loss: 0.15251 - acc: 0.9543 -- iter: 0896/1072
[A[ATraining Step: 335  | total loss: [1m[32m0.15557[0m[0m | time: 54.240s
[2K
| Adam | epoch: 010 | loss: 0.15557 - acc: 0.9557 -- iter: 0928/1072
[A[ATraining Step: 336  | total loss: [1m[32m0.15233[0m[0m | time: 55.844s
[2K
| Adam | epoch: 010 | loss: 0.15233 - acc: 0.9539 -- iter: 0960/1072
[A[ATraining Step: 337  | total loss: [1m[32m0.14692[0m[0m | time: 57.830s
[2K
| Adam | epoch: 010 | loss: 0.14692 - acc: 0.9523 -- iter: 0992/1072
[A[ATraining Step: 338  | total loss: [1m[32m0.15333[0m[0m | time: 59.680s
[2K
| Adam | epoch: 010 | loss: 0.15333 - acc: 0.9508 -- iter: 1024/1072
[A[ATraining Step: 339  | total loss: [1m[32m0.15059[0m[0m | time: 61.553s
[2K
| Adam | epoch: 010 | loss: 0.15059 - acc: 0.9495 -- iter: 1056/1072
[A[ATraining Step: 340  | total loss: [1m[32m0.14614[0m[0m | time: 67.243s
[2K
| Adam | epoch: 010 | loss: 0.14614 - acc: 0.9514 | val_loss: 0.30383 - val_acc: 0.8720 -- iter: 1072/1072
--
Training Step: 341  | total loss: [1m[32m0.13514[0m[0m | time: 1.666s
[2K
| Adam | epoch: 011 | loss: 0.13514 - acc: 0.9563 -- iter: 0032/1072
[A[ATraining Step: 342  | total loss: [1m[32m0.14280[0m[0m | time: 3.553s
[2K
| Adam | epoch: 011 | loss: 0.14280 - acc: 0.9481 -- iter: 0064/1072
[A[ATraining Step: 343  | total loss: [1m[32m0.13365[0m[0m | time: 5.218s
[2K
| Adam | epoch: 011 | loss: 0.13365 - acc: 0.9502 -- iter: 0096/1072
[A[ATraining Step: 344  | total loss: [1m[32m0.12646[0m[0m | time: 7.107s
[2K
| Adam | epoch: 011 | loss: 0.12646 - acc: 0.9552 -- iter: 0128/1072
[A[ATraining Step: 345  | total loss: [1m[32m0.13906[0m[0m | time: 8.749s
[2K
| Adam | epoch: 011 | loss: 0.13906 - acc: 0.9503 -- iter: 0160/1072
[A[ATraining Step: 346  | total loss: [1m[32m0.13766[0m[0m | time: 10.478s
[2K
| Adam | epoch: 011 | loss: 0.13766 - acc: 0.9521 -- iter: 0192/1072
[A[ATraining Step: 347  | total loss: [1m[32m0.13664[0m[0m | time: 12.506s
[2K
| Adam | epoch: 011 | loss: 0.13664 - acc: 0.9538 -- iter: 0224/1072
[A[ATraining Step: 348  | total loss: [1m[32m0.12874[0m[0m | time: 14.511s
[2K
| Adam | epoch: 011 | loss: 0.12874 - acc: 0.9584 -- iter: 0256/1072
[A[ATraining Step: 349  | total loss: [1m[32m0.12506[0m[0m | time: 15.471s
[2K
| Adam | epoch: 011 | loss: 0.12506 - acc: 0.9626 -- iter: 0288/1072
[A[ATraining Step: 350  | total loss: [1m[32m0.13168[0m[0m | time: 16.404s
[2K
| Adam | epoch: 011 | loss: 0.13168 - acc: 0.9476 -- iter: 0320/1072
[A[ATraining Step: 351  | total loss: [1m[32m0.13232[0m[0m | time: 18.001s
[2K
| Adam | epoch: 011 | loss: 0.13232 - acc: 0.9466 -- iter: 0352/1072
[A[ATraining Step: 352  | total loss: [1m[32m0.13681[0m[0m | time: 19.877s
[2K
| Adam | epoch: 011 | loss: 0.13681 - acc: 0.9488 -- iter: 0384/1072
[A[ATraining Step: 353  | total loss: [1m[32m0.14235[0m[0m | time: 21.580s
[2K
| Adam | epoch: 011 | loss: 0.14235 - acc: 0.9445 -- iter: 0416/1072
[A[ATraining Step: 354  | total loss: [1m[32m0.13781[0m[0m | time: 23.443s
[2K
| Adam | epoch: 011 | loss: 0.13781 - acc: 0.9438 -- iter: 0448/1072
[A[ATraining Step: 355  | total loss: [1m[32m0.13436[0m[0m | time: 25.288s
[2K
| Adam | epoch: 011 | loss: 0.13436 - acc: 0.9463 -- iter: 0480/1072
[A[ATraining Step: 356  | total loss: [1m[32m0.14644[0m[0m | time: 26.962s
[2K
| Adam | epoch: 011 | loss: 0.14644 - acc: 0.9423 -- iter: 0512/1072
[A[ATraining Step: 357  | total loss: [1m[32m0.13492[0m[0m | time: 28.656s
[2K
| Adam | epoch: 011 | loss: 0.13492 - acc: 0.9481 -- iter: 0544/1072
[A[ATraining Step: 358  | total loss: [1m[32m0.13366[0m[0m | time: 30.693s
[2K
| Adam | epoch: 011 | loss: 0.13366 - acc: 0.9470 -- iter: 0576/1072
[A[ATraining Step: 359  | total loss: [1m[32m0.12578[0m[0m | time: 32.426s
[2K
| Adam | epoch: 011 | loss: 0.12578 - acc: 0.9523 -- iter: 0608/1072
[A[ATraining Step: 360  | total loss: [1m[32m0.11534[0m[0m | time: 34.330s
[2K
| Adam | epoch: 011 | loss: 0.11534 - acc: 0.9571 -- iter: 0640/1072
[A[ATraining Step: 361  | total loss: [1m[32m0.11360[0m[0m | time: 36.367s
[2K
| Adam | epoch: 011 | loss: 0.11360 - acc: 0.9583 -- iter: 0672/1072
[A[ATraining Step: 362  | total loss: [1m[32m0.10579[0m[0m | time: 38.415s
[2K
| Adam | epoch: 011 | loss: 0.10579 - acc: 0.9624 -- iter: 0704/1072
[A[ATraining Step: 363  | total loss: [1m[32m0.11596[0m[0m | time: 40.392s
[2K
| Adam | epoch: 011 | loss: 0.11596 - acc: 0.9568 -- iter: 0736/1072
[A[ATraining Step: 364  | total loss: [1m[32m0.10859[0m[0m | time: 42.096s
[2K
| Adam | epoch: 011 | loss: 0.10859 - acc: 0.9611 -- iter: 0768/1072
[A[ATraining Step: 365  | total loss: [1m[32m0.11254[0m[0m | time: 43.907s
[2K
| Adam | epoch: 011 | loss: 0.11254 - acc: 0.9619 -- iter: 0800/1072
[A[ATraining Step: 366  | total loss: [1m[32m0.11068[0m[0m | time: 45.682s
[2K
| Adam | epoch: 011 | loss: 0.11068 - acc: 0.9595 -- iter: 0832/1072
[A[ATraining Step: 367  | total loss: [1m[32m0.10685[0m[0m | time: 47.440s
[2K
| Adam | epoch: 011 | loss: 0.10685 - acc: 0.9604 -- iter: 0864/1072
[A[ATraining Step: 368  | total loss: [1m[32m0.10462[0m[0m | time: 49.372s
[2K
| Adam | epoch: 011 | loss: 0.10462 - acc: 0.9612 -- iter: 0896/1072
[A[ATraining Step: 369  | total loss: [1m[32m0.09722[0m[0m | time: 51.088s
[2K
| Adam | epoch: 011 | loss: 0.09722 - acc: 0.9651 -- iter: 0928/1072
[A[ATraining Step: 370  | total loss: [1m[32m0.10304[0m[0m | time: 52.956s
[2K
| Adam | epoch: 011 | loss: 0.10304 - acc: 0.9592 -- iter: 0960/1072
[A[ATraining Step: 371  | total loss: [1m[32m0.09764[0m[0m | time: 54.416s
[2K
| Adam | epoch: 011 | loss: 0.09764 - acc: 0.9602 -- iter: 0992/1072
[A[ATraining Step: 372  | total loss: [1m[32m0.09103[0m[0m | time: 55.989s
[2K
| Adam | epoch: 011 | loss: 0.09103 - acc: 0.9641 -- iter: 1024/1072
[A[ATraining Step: 373  | total loss: [1m[32m0.08719[0m[0m | time: 57.661s
[2K
| Adam | epoch: 011 | loss: 0.08719 - acc: 0.9677 -- iter: 1056/1072
[A[ATraining Step: 374  | total loss: [1m[32m0.08287[0m[0m | time: 64.614s
[2K
| Adam | epoch: 011 | loss: 0.08287 - acc: 0.9710 | val_loss: 0.26876 - val_acc: 0.8839 -- iter: 1072/1072
--
Training Step: 375  | total loss: [1m[32m0.09243[0m[0m | time: 1.939s
[2K
| Adam | epoch: 012 | loss: 0.09243 - acc: 0.9707 -- iter: 0032/1072
[A[ATraining Step: 376  | total loss: [1m[32m0.08669[0m[0m | time: 3.760s
[2K
| Adam | epoch: 012 | loss: 0.08669 - acc: 0.9737 -- iter: 0064/1072
[A[ATraining Step: 377  | total loss: [1m[32m0.08036[0m[0m | time: 5.463s
[2K
| Adam | epoch: 012 | loss: 0.08036 - acc: 0.9763 -- iter: 0096/1072
[A[ATraining Step: 378  | total loss: [1m[32m0.10092[0m[0m | time: 7.297s
[2K
| Adam | epoch: 012 | loss: 0.10092 - acc: 0.9724 -- iter: 0128/1072
[A[ATraining Step: 379  | total loss: [1m[32m0.10157[0m[0m | time: 9.079s
[2K
| Adam | epoch: 012 | loss: 0.10157 - acc: 0.9689 -- iter: 0160/1072
[A[ATraining Step: 380  | total loss: [1m[32m0.11164[0m[0m | time: 10.934s
[2K
| Adam | epoch: 012 | loss: 0.11164 - acc: 0.9658 -- iter: 0192/1072
[A[ATraining Step: 381  | total loss: [1m[32m0.10411[0m[0m | time: 12.895s
[2K
| Adam | epoch: 012 | loss: 0.10411 - acc: 0.9692 -- iter: 0224/1072
[A[ATraining Step: 382  | total loss: [1m[32m0.11091[0m[0m | time: 14.792s
[2K
| Adam | epoch: 012 | loss: 0.11091 - acc: 0.9660 -- iter: 0256/1072
[A[ATraining Step: 383  | total loss: [1m[32m0.10737[0m[0m | time: 16.553s
[2K
| Adam | epoch: 012 | loss: 0.10737 - acc: 0.9663 -- iter: 0288/1072
[A[ATraining Step: 384  | total loss: [1m[32m0.10993[0m[0m | time: 17.572s
[2K
| Adam | epoch: 012 | loss: 0.10993 - acc: 0.9666 -- iter: 0320/1072
[A[ATraining Step: 385  | total loss: [1m[32m0.11016[0m[0m | time: 18.443s
[2K
| Adam | epoch: 012 | loss: 0.11016 - acc: 0.9636 -- iter: 0352/1072
[A[ATraining Step: 386  | total loss: [1m[32m0.12014[0m[0m | time: 20.478s
[2K
| Adam | epoch: 012 | loss: 0.12014 - acc: 0.9548 -- iter: 0384/1072
[A[ATraining Step: 387  | total loss: [1m[32m0.16190[0m[0m | time: 22.308s
[2K
| Adam | epoch: 012 | loss: 0.16190 - acc: 0.9406 -- iter: 0416/1072
[A[ATraining Step: 388  | total loss: [1m[32m0.31225[0m[0m | time: 24.045s
[2K
| Adam | epoch: 012 | loss: 0.31225 - acc: 0.9090 -- iter: 0448/1072
[A[ATraining Step: 389  | total loss: [1m[32m0.29019[0m[0m | time: 25.868s
[2K
| Adam | epoch: 012 | loss: 0.29019 - acc: 0.9150 -- iter: 0480/1072
[A[ATraining Step: 390  | total loss: [1m[32m0.27067[0m[0m | time: 27.705s
[2K
| Adam | epoch: 012 | loss: 0.27067 - acc: 0.9204 -- iter: 0512/1072
[A[ATraining Step: 391  | total loss: [1m[32m0.24783[0m[0m | time: 29.585s
[2K
| Adam | epoch: 012 | loss: 0.24783 - acc: 0.9283 -- iter: 0544/1072
[A[ATraining Step: 392  | total loss: [1m[32m0.23503[0m[0m | time: 31.423s
[2K
| Adam | epoch: 012 | loss: 0.23503 - acc: 0.9324 -- iter: 0576/1072
[A[ATraining Step: 393  | total loss: [1m[32m0.21967[0m[0m | time: 33.225s
[2K
| Adam | epoch: 012 | loss: 0.21967 - acc: 0.9360 -- iter: 0608/1072
[A[ATraining Step: 394  | total loss: [1m[32m0.20132[0m[0m | time: 35.100s
[2K
| Adam | epoch: 012 | loss: 0.20132 - acc: 0.9424 -- iter: 0640/1072
[A[ATraining Step: 395  | total loss: [1m[32m0.18698[0m[0m | time: 36.948s
[2K
| Adam | epoch: 012 | loss: 0.18698 - acc: 0.9482 -- iter: 0672/1072
[A[ATraining Step: 396  | total loss: [1m[32m0.17196[0m[0m | time: 39.136s
[2K
| Adam | epoch: 012 | loss: 0.17196 - acc: 0.9533 -- iter: 0704/1072
[A[ATraining Step: 397  | total loss: [1m[32m0.15828[0m[0m | time: 41.146s
[2K
| Adam | epoch: 012 | loss: 0.15828 - acc: 0.9580 -- iter: 0736/1072
[A[ATraining Step: 398  | total loss: [1m[32m0.15315[0m[0m | time: 42.782s
[2K
| Adam | epoch: 012 | loss: 0.15315 - acc: 0.9591 -- iter: 0768/1072
[A[ATraining Step: 399  | total loss: [1m[32m0.14338[0m[0m | time: 44.634s
[2K
| Adam | epoch: 012 | loss: 0.14338 - acc: 0.9600 -- iter: 0800/1072
[A[ATraining Step: 400  | total loss: [1m[32m0.13270[0m[0m | time: 50.241s
[2K
| Adam | epoch: 012 | loss: 0.13270 - acc: 0.9640 | val_loss: 0.36525 - val_acc: 0.8542 -- iter: 0832/1072
--
Training Step: 401  | total loss: [1m[32m0.13868[0m[0m | time: 52.188s
[2K
| Adam | epoch: 012 | loss: 0.13868 - acc: 0.9645 -- iter: 0864/1072
[A[ATraining Step: 402  | total loss: [1m[32m0.13307[0m[0m | time: 54.107s
[2K
| Adam | epoch: 012 | loss: 0.13307 - acc: 0.9681 -- iter: 0896/1072
[A[ATraining Step: 403  | total loss: [1m[32m0.13347[0m[0m | time: 55.920s
[2K
| Adam | epoch: 012 | loss: 0.13347 - acc: 0.9681 -- iter: 0928/1072
[A[ATraining Step: 404  | total loss: [1m[32m0.12513[0m[0m | time: 58.321s
[2K
| Adam | epoch: 012 | loss: 0.12513 - acc: 0.9713 -- iter: 0960/1072
[A[ATraining Step: 405  | total loss: [1m[32m0.11475[0m[0m | time: 60.275s
[2K
| Adam | epoch: 012 | loss: 0.11475 - acc: 0.9742 -- iter: 0992/1072
[A[ATraining Step: 406  | total loss: [1m[32m0.11961[0m[0m | time: 62.158s
[2K
| Adam | epoch: 012 | loss: 0.11961 - acc: 0.9705 -- iter: 1024/1072
[A[ATraining Step: 407  | total loss: [1m[32m0.11294[0m[0m | time: 63.903s
[2K
| Adam | epoch: 012 | loss: 0.11294 - acc: 0.9703 -- iter: 1056/1072
[A[ATraining Step: 408  | total loss: [1m[32m0.10443[0m[0m | time: 70.272s
[2K
| Adam | epoch: 012 | loss: 0.10443 - acc: 0.9733 | val_loss: 0.32761 - val_acc: 0.8690 -- iter: 1072/1072
--
Training Step: 409  | total loss: [1m[32m0.10041[0m[0m | time: 1.908s
[2K
| Adam | epoch: 013 | loss: 0.10041 - acc: 0.9729 -- iter: 0032/1072
[A[ATraining Step: 410  | total loss: [1m[32m0.10559[0m[0m | time: 3.736s
[2K
| Adam | epoch: 013 | loss: 0.10559 - acc: 0.9724 -- iter: 0064/1072
[A[ATraining Step: 411  | total loss: [1m[32m0.10601[0m[0m | time: 5.532s
[2K
| Adam | epoch: 013 | loss: 0.10601 - acc: 0.9689 -- iter: 0096/1072
[A[ATraining Step: 412  | total loss: [1m[32m0.09791[0m[0m | time: 7.580s
[2K
| Adam | epoch: 013 | loss: 0.09791 - acc: 0.9721 -- iter: 0128/1072
[A[ATraining Step: 413  | total loss: [1m[32m0.09109[0m[0m | time: 9.671s
[2K
| Adam | epoch: 013 | loss: 0.09109 - acc: 0.9748 -- iter: 0160/1072
[A[ATraining Step: 414  | total loss: [1m[32m0.09056[0m[0m | time: 11.366s
[2K
| Adam | epoch: 013 | loss: 0.09056 - acc: 0.9742 -- iter: 0192/1072
[A[ATraining Step: 415  | total loss: [1m[32m0.09524[0m[0m | time: 13.306s
[2K
| Adam | epoch: 013 | loss: 0.09524 - acc: 0.9737 -- iter: 0224/1072
[A[ATraining Step: 416  | total loss: [1m[32m0.08826[0m[0m | time: 15.078s
[2K
| Adam | epoch: 013 | loss: 0.08826 - acc: 0.9763 -- iter: 0256/1072
[A[ATraining Step: 417  | total loss: [1m[32m0.08471[0m[0m | time: 16.765s
[2K
| Adam | epoch: 013 | loss: 0.08471 - acc: 0.9756 -- iter: 0288/1072
[A[ATraining Step: 418  | total loss: [1m[32m0.08361[0m[0m | time: 18.601s
[2K
| Adam | epoch: 013 | loss: 0.08361 - acc: 0.9749 -- iter: 0320/1072
[A[ATraining Step: 419  | total loss: [1m[32m0.08336[0m[0m | time: 19.625s
[2K
| Adam | epoch: 013 | loss: 0.08336 - acc: 0.9743 -- iter: 0352/1072
[A[ATraining Step: 420  | total loss: [1m[32m0.09428[0m[0m | time: 20.755s
[2K
| Adam | epoch: 013 | loss: 0.09428 - acc: 0.9706 -- iter: 0384/1072
[A[ATraining Step: 421  | total loss: [1m[32m0.09695[0m[0m | time: 22.533s
[2K
| Adam | epoch: 013 | loss: 0.09695 - acc: 0.9673 -- iter: 0416/1072
[A[ATraining Step: 422  | total loss: [1m[32m0.09725[0m[0m | time: 24.362s
[2K
| Adam | epoch: 013 | loss: 0.09725 - acc: 0.9674 -- iter: 0448/1072
[A[ATraining Step: 423  | total loss: [1m[32m0.22803[0m[0m | time: 26.391s
[2K
| Adam | epoch: 013 | loss: 0.22803 - acc: 0.9457 -- iter: 0480/1072
[A[ATraining Step: 424  | total loss: [1m[32m0.20897[0m[0m | time: 28.307s
[2K
| Adam | epoch: 013 | loss: 0.20897 - acc: 0.9511 -- iter: 0512/1072
[A[ATraining Step: 425  | total loss: [1m[32m0.19022[0m[0m | time: 30.359s
[2K
| Adam | epoch: 013 | loss: 0.19022 - acc: 0.9560 -- iter: 0544/1072
[A[ATraining Step: 426  | total loss: [1m[32m0.18169[0m[0m | time: 32.221s
[2K
| Adam | epoch: 013 | loss: 0.18169 - acc: 0.9542 -- iter: 0576/1072
[A[ATraining Step: 427  | total loss: [1m[32m0.16921[0m[0m | time: 34.269s
[2K
| Adam | epoch: 013 | loss: 0.16921 - acc: 0.9587 -- iter: 0608/1072
[A[ATraining Step: 428  | total loss: [1m[32m0.15934[0m[0m | time: 35.889s
[2K
| Adam | epoch: 013 | loss: 0.15934 - acc: 0.9629 -- iter: 0640/1072
[A[ATraining Step: 429  | total loss: [1m[32m0.14776[0m[0m | time: 37.618s
[2K
| Adam | epoch: 013 | loss: 0.14776 - acc: 0.9666 -- iter: 0672/1072
[A[ATraining Step: 430  | total loss: [1m[32m0.13481[0m[0m | time: 39.383s
[2K
| Adam | epoch: 013 | loss: 0.13481 - acc: 0.9699 -- iter: 0704/1072
[A[ATraining Step: 431  | total loss: [1m[32m0.12347[0m[0m | time: 41.141s
[2K
| Adam | epoch: 013 | loss: 0.12347 - acc: 0.9729 -- iter: 0736/1072
[A[ATraining Step: 432  | total loss: [1m[32m0.11737[0m[0m | time: 42.931s
[2K
| Adam | epoch: 013 | loss: 0.11737 - acc: 0.9756 -- iter: 0768/1072
[A[ATraining Step: 433  | total loss: [1m[32m0.11993[0m[0m | time: 44.645s
[2K
| Adam | epoch: 013 | loss: 0.11993 - acc: 0.9718 -- iter: 0800/1072
[A[ATraining Step: 434  | total loss: [1m[32m0.11093[0m[0m | time: 46.301s
[2K
| Adam | epoch: 013 | loss: 0.11093 - acc: 0.9746 -- iter: 0832/1072
[A[ATraining Step: 435  | total loss: [1m[32m0.11611[0m[0m | time: 48.017s
[2K
| Adam | epoch: 013 | loss: 0.11611 - acc: 0.9741 -- iter: 0864/1072
[A[ATraining Step: 436  | total loss: [1m[32m0.10863[0m[0m | time: 49.868s
[2K
| Adam | epoch: 013 | loss: 0.10863 - acc: 0.9766 -- iter: 0896/1072
[A[ATraining Step: 437  | total loss: [1m[32m0.10392[0m[0m | time: 51.646s
[2K
| Adam | epoch: 013 | loss: 0.10392 - acc: 0.9790 -- iter: 0928/1072
[A[ATraining Step: 438  | total loss: [1m[32m0.10082[0m[0m | time: 53.252s
[2K
| Adam | epoch: 013 | loss: 0.10082 - acc: 0.9780 -- iter: 0960/1072
[A[ATraining Step: 439  | total loss: [1m[32m0.09655[0m[0m | time: 55.124s
[2K
| Adam | epoch: 013 | loss: 0.09655 - acc: 0.9770 -- iter: 0992/1072
[A[ATraining Step: 440  | total loss: [1m[32m0.08996[0m[0m | time: 56.688s
[2K
| Adam | epoch: 013 | loss: 0.08996 - acc: 0.9793 -- iter: 1024/1072
[A[ATraining Step: 441  | total loss: [1m[32m0.08503[0m[0m | time: 58.585s
[2K
| Adam | epoch: 013 | loss: 0.08503 - acc: 0.9814 -- iter: 1056/1072
[A[ATraining Step: 442  | total loss: [1m[32m0.07875[0m[0m | time: 64.713s
[2K
| Adam | epoch: 013 | loss: 0.07875 - acc: 0.9833 | val_loss: 0.27858 - val_acc: 0.8810 -- iter: 1072/1072
--
Training Step: 443  | total loss: [1m[32m0.08302[0m[0m | time: 1.899s
[2K
| Adam | epoch: 014 | loss: 0.08302 - acc: 0.9787 -- iter: 0032/1072
[A[ATraining Step: 444  | total loss: [1m[32m0.07644[0m[0m | time: 3.699s
[2K
| Adam | epoch: 014 | loss: 0.07644 - acc: 0.9808 -- iter: 0064/1072
[A[ATraining Step: 445  | total loss: [1m[32m0.07382[0m[0m | time: 5.706s
[2K
| Adam | epoch: 014 | loss: 0.07382 - acc: 0.9796 -- iter: 0096/1072
[A[ATraining Step: 446  | total loss: [1m[32m0.07000[0m[0m | time: 7.525s
[2K
| Adam | epoch: 014 | loss: 0.07000 - acc: 0.9816 -- iter: 0128/1072
[A[ATraining Step: 447  | total loss: [1m[32m0.06450[0m[0m | time: 9.205s
[2K
| Adam | epoch: 014 | loss: 0.06450 - acc: 0.9835 -- iter: 0160/1072
[A[ATraining Step: 448  | total loss: [1m[32m0.05934[0m[0m | time: 11.089s
[2K
| Adam | epoch: 014 | loss: 0.05934 - acc: 0.9851 -- iter: 0192/1072
[A[ATraining Step: 449  | total loss: [1m[32m0.05492[0m[0m | time: 12.700s
[2K
| Adam | epoch: 014 | loss: 0.05492 - acc: 0.9866 -- iter: 0224/1072
[A[ATraining Step: 450  | total loss: [1m[32m0.05794[0m[0m | time: 14.535s
[2K
| Adam | epoch: 014 | loss: 0.05794 - acc: 0.9848 -- iter: 0256/1072
[A[ATraining Step: 451  | total loss: [1m[32m0.05418[0m[0m | time: 16.287s
[2K
| Adam | epoch: 014 | loss: 0.05418 - acc: 0.9864 -- iter: 0288/1072
[A[ATraining Step: 452  | total loss: [1m[32m0.05275[0m[0m | time: 18.200s
[2K
| Adam | epoch: 014 | loss: 0.05275 - acc: 0.9877 -- iter: 0320/1072
[A[ATraining Step: 453  | total loss: [1m[32m0.06381[0m[0m | time: 19.873s
[2K
| Adam | epoch: 014 | loss: 0.06381 - acc: 0.9827 -- iter: 0352/1072
[A[ATraining Step: 454  | total loss: [1m[32m0.05908[0m[0m | time: 20.970s
[2K
| Adam | epoch: 014 | loss: 0.05908 - acc: 0.9844 -- iter: 0384/1072
[A[ATraining Step: 455  | total loss: [1m[32m0.07061[0m[0m | time: 22.022s
[2K
| Adam | epoch: 014 | loss: 0.07061 - acc: 0.9797 -- iter: 0416/1072
[A[ATraining Step: 456  | total loss: [1m[32m0.06734[0m[0m | time: 23.730s
[2K
| Adam | epoch: 014 | loss: 0.06734 - acc: 0.9818 -- iter: 0448/1072
[A[ATraining Step: 457  | total loss: [1m[32m0.06165[0m[0m | time: 25.389s
[2K
| Adam | epoch: 014 | loss: 0.06165 - acc: 0.9836 -- iter: 0480/1072
[A[ATraining Step: 458  | total loss: [1m[32m0.07026[0m[0m | time: 27.535s
[2K
| Adam | epoch: 014 | loss: 0.07026 - acc: 0.9821 -- iter: 0512/1072
[A[ATraining Step: 459  | total loss: [1m[32m0.06575[0m[0m | time: 29.210s
[2K
| Adam | epoch: 014 | loss: 0.06575 - acc: 0.9839 -- iter: 0544/1072
[A[ATraining Step: 460  | total loss: [1m[32m0.06010[0m[0m | time: 31.355s
[2K
| Adam | epoch: 014 | loss: 0.06010 - acc: 0.9855 -- iter: 0576/1072
[A[ATraining Step: 461  | total loss: [1m[32m0.05737[0m[0m | time: 33.289s
[2K
| Adam | epoch: 014 | loss: 0.05737 - acc: 0.9870 -- iter: 0608/1072
[A[ATraining Step: 462  | total loss: [1m[32m0.05372[0m[0m | time: 35.324s
[2K
| Adam | epoch: 014 | loss: 0.05372 - acc: 0.9883 -- iter: 0640/1072
[A[ATraining Step: 463  | total loss: [1m[32m0.07391[0m[0m | time: 37.073s
[2K
| Adam | epoch: 014 | loss: 0.07391 - acc: 0.9832 -- iter: 0672/1072
[A[ATraining Step: 464  | total loss: [1m[32m0.07080[0m[0m | time: 38.766s
[2K
| Adam | epoch: 014 | loss: 0.07080 - acc: 0.9817 -- iter: 0704/1072
[A[ATraining Step: 465  | total loss: [1m[32m0.06984[0m[0m | time: 40.610s
[2K
| Adam | epoch: 014 | loss: 0.06984 - acc: 0.9804 -- iter: 0736/1072
[A[ATraining Step: 466  | total loss: [1m[32m0.06378[0m[0m | time: 42.484s
[2K
| Adam | epoch: 014 | loss: 0.06378 - acc: 0.9824 -- iter: 0768/1072
[A[ATraining Step: 467  | total loss: [1m[32m0.05979[0m[0m | time: 44.326s
[2K
| Adam | epoch: 014 | loss: 0.05979 - acc: 0.9842 -- iter: 0800/1072
[A[ATraining Step: 468  | total loss: [1m[32m0.06474[0m[0m | time: 46.099s
[2K
| Adam | epoch: 014 | loss: 0.06474 - acc: 0.9795 -- iter: 0832/1072
[A[ATraining Step: 469  | total loss: [1m[32m0.06258[0m[0m | time: 47.822s
[2K
| Adam | epoch: 014 | loss: 0.06258 - acc: 0.9784 -- iter: 0864/1072
[A[ATraining Step: 470  | total loss: [1m[32m0.05937[0m[0m | time: 49.724s
[2K
| Adam | epoch: 014 | loss: 0.05937 - acc: 0.9806 -- iter: 0896/1072
[A[ATraining Step: 471  | total loss: [1m[32m0.06831[0m[0m | time: 51.705s
[2K
| Adam | epoch: 014 | loss: 0.06831 - acc: 0.9731 -- iter: 0928/1072
[A[ATraining Step: 472  | total loss: [1m[32m0.06268[0m[0m | time: 53.623s
[2K
| Adam | epoch: 014 | loss: 0.06268 - acc: 0.9758 -- iter: 0960/1072
[A[ATraining Step: 473  | total loss: [1m[32m0.05754[0m[0m | time: 55.669s
[2K
| Adam | epoch: 014 | loss: 0.05754 - acc: 0.9782 -- iter: 0992/1072
[A[ATraining Step: 474  | total loss: [1m[32m0.05340[0m[0m | time: 57.412s
[2K
| Adam | epoch: 014 | loss: 0.05340 - acc: 0.9804 -- iter: 1024/1072
[A[ATraining Step: 475  | total loss: [1m[32m0.06693[0m[0m | time: 59.218s
[2K
| Adam | epoch: 014 | loss: 0.06693 - acc: 0.9761 -- iter: 1056/1072
[A[ATraining Step: 476  | total loss: [1m[32m0.07126[0m[0m | time: 65.300s
[2K
| Adam | epoch: 014 | loss: 0.07126 - acc: 0.9754 | val_loss: 0.31391 - val_acc: 0.8929 -- iter: 1072/1072
--
Training Step: 477  | total loss: [1m[32m0.07640[0m[0m | time: 1.854s
[2K
| Adam | epoch: 015 | loss: 0.07640 - acc: 0.9747 -- iter: 0032/1072
[A[ATraining Step: 478  | total loss: [1m[32m0.07099[0m[0m | time: 3.569s
[2K
| Adam | epoch: 015 | loss: 0.07099 - acc: 0.9773 -- iter: 0064/1072
[A[ATraining Step: 479  | total loss: [1m[32m0.06908[0m[0m | time: 5.364s
[2K
| Adam | epoch: 015 | loss: 0.06908 - acc: 0.9795 -- iter: 0096/1072
[A[ATraining Step: 480  | total loss: [1m[32m0.07901[0m[0m | time: 7.483s
[2K
| Adam | epoch: 015 | loss: 0.07901 - acc: 0.9753 -- iter: 0128/1072
[A[ATraining Step: 481  | total loss: [1m[32m0.07185[0m[0m | time: 9.321s
[2K
| Adam | epoch: 015 | loss: 0.07185 - acc: 0.9778 -- iter: 0160/1072
[A[ATraining Step: 482  | total loss: [1m[32m0.06554[0m[0m | time: 10.999s
[2K
| Adam | epoch: 015 | loss: 0.06554 - acc: 0.9800 -- iter: 0192/1072
[A[ATraining Step: 483  | total loss: [1m[32m0.06775[0m[0m | time: 12.724s
[2K
| Adam | epoch: 015 | loss: 0.06775 - acc: 0.9789 -- iter: 0224/1072
[A[ATraining Step: 484  | total loss: [1m[32m0.06955[0m[0m | time: 14.509s
[2K
| Adam | epoch: 015 | loss: 0.06955 - acc: 0.9747 -- iter: 0256/1072
[A[ATraining Step: 485  | total loss: [1m[32m0.06451[0m[0m | time: 16.241s
[2K
| Adam | epoch: 015 | loss: 0.06451 - acc: 0.9773 -- iter: 0288/1072
[A[ATraining Step: 486  | total loss: [1m[32m0.05965[0m[0m | time: 18.066s
[2K
| Adam | epoch: 015 | loss: 0.05965 - acc: 0.9795 -- iter: 0320/1072
[A[ATraining Step: 487  | total loss: [1m[32m0.05837[0m[0m | time: 20.005s
[2K
| Adam | epoch: 015 | loss: 0.05837 - acc: 0.9816 -- iter: 0352/1072
[A[ATraining Step: 488  | total loss: [1m[32m0.05422[0m[0m | time: 21.772s
[2K
| Adam | epoch: 015 | loss: 0.05422 - acc: 0.9834 -- iter: 0384/1072
[A[ATraining Step: 489  | total loss: [1m[32m0.05143[0m[0m | time: 22.857s
[2K
| Adam | epoch: 015 | loss: 0.05143 - acc: 0.9851 -- iter: 0416/1072
[A[ATraining Step: 490  | total loss: [1m[32m0.04743[0m[0m | time: 24.008s
[2K
| Adam | epoch: 015 | loss: 0.04743 - acc: 0.9866 -- iter: 0448/1072
[A[ATraining Step: 491  | total loss: [1m[32m0.04467[0m[0m | time: 25.596s
[2K
| Adam | epoch: 015 | loss: 0.04467 - acc: 0.9879 -- iter: 0480/1072
[A[ATraining Step: 492  | total loss: [1m[32m0.04096[0m[0m | time: 27.678s
[2K
| Adam | epoch: 015 | loss: 0.04096 - acc: 0.9891 -- iter: 0512/1072
[A[ATraining Step: 493  | total loss: [1m[32m0.05247[0m[0m | time: 29.713s
[2K
| Adam | epoch: 015 | loss: 0.05247 - acc: 0.9871 -- iter: 0544/1072
[A[ATraining Step: 494  | total loss: [1m[32m0.04898[0m[0m | time: 31.433s
[2K
| Adam | epoch: 015 | loss: 0.04898 - acc: 0.9884 -- iter: 0576/1072
[A[ATraining Step: 495  | total loss: [1m[32m0.04474[0m[0m | time: 33.290s
[2K
| Adam | epoch: 015 | loss: 0.04474 - acc: 0.9895 -- iter: 0608/1072
[A[ATraining Step: 496  | total loss: [1m[32m0.04125[0m[0m | time: 34.942s
[2K
| Adam | epoch: 015 | loss: 0.04125 - acc: 0.9906 -- iter: 0640/1072
[A[ATraining Step: 497  | total loss: [1m[32m0.03838[0m[0m | time: 36.849s
[2K
| Adam | epoch: 015 | loss: 0.03838 - acc: 0.9915 -- iter: 0672/1072
[A[ATraining Step: 498  | total loss: [1m[32m0.04963[0m[0m | time: 38.744s
[2K
| Adam | epoch: 015 | loss: 0.04963 - acc: 0.9861 -- iter: 0704/1072
[A[ATraining Step: 499  | total loss: [1m[32m0.04641[0m[0m | time: 40.468s
[2K
| Adam | epoch: 015 | loss: 0.04641 - acc: 0.9875 -- iter: 0736/1072
[A[ATraining Step: 500  | total loss: [1m[32m0.04224[0m[0m | time: 42.239s
[2K
| Adam | epoch: 015 | loss: 0.04224 - acc: 0.9888 -- iter: 0768/1072
[A[ATraining Step: 501  | total loss: [1m[32m0.03907[0m[0m | time: 43.954s
[2K
| Adam | epoch: 015 | loss: 0.03907 - acc: 0.9899 -- iter: 0800/1072
[A[ATraining Step: 502  | total loss: [1m[32m0.03713[0m[0m | time: 45.799s
[2K
| Adam | epoch: 015 | loss: 0.03713 - acc: 0.9909 -- iter: 0832/1072
[A[ATraining Step: 503  | total loss: [1m[32m0.03410[0m[0m | time: 47.560s
[2K
| Adam | epoch: 015 | loss: 0.03410 - acc: 0.9918 -- iter: 0864/1072
[A[ATraining Step: 504  | total loss: [1m[32m0.03198[0m[0m | time: 49.468s
[2K
| Adam | epoch: 015 | loss: 0.03198 - acc: 0.9926 -- iter: 0896/1072
[A[ATraining Step: 505  | total loss: [1m[32m0.03066[0m[0m | time: 51.220s
[2K
| Adam | epoch: 015 | loss: 0.03066 - acc: 0.9934 -- iter: 0928/1072
[A[ATraining Step: 506  | total loss: [1m[32m0.04335[0m[0m | time: 53.053s
[2K
| Adam | epoch: 015 | loss: 0.04335 - acc: 0.9909 -- iter: 0960/1072
[A[ATraining Step: 507  | total loss: [1m[32m0.03940[0m[0m | time: 54.790s
[2K
| Adam | epoch: 015 | loss: 0.03940 - acc: 0.9918 -- iter: 0992/1072
[A[ATraining Step: 508  | total loss: [1m[32m0.03604[0m[0m | time: 56.683s
[2K
| Adam | epoch: 015 | loss: 0.03604 - acc: 0.9926 -- iter: 1024/1072
[A[ATraining Step: 509  | total loss: [1m[32m0.03297[0m[0m | time: 58.354s
[2K
| Adam | epoch: 015 | loss: 0.03297 - acc: 0.9934 -- iter: 1056/1072
[A[ATraining Step: 510  | total loss: [1m[32m0.02996[0m[0m | time: 64.502s
[2K
| Adam | epoch: 015 | loss: 0.02996 - acc: 0.9940 | val_loss: 0.32230 - val_acc: 0.8869 -- iter: 1072/1072
--
Validation AUC:0.9575155279503105
Validation AUPRC:0.9667015335566715
Test AUC:0.9566206798463947
Test AUPRC:0.9615465507599327
BestTestF1Score	0.9	0.82	0.91	0.93	0.88	139	11	167	19	0.68
BestTestMCCScore	0.9	0.82	0.91	0.93	0.88	139	11	167	19	0.68
BestTestAccuracyScore	0.9	0.82	0.91	0.93	0.88	139	11	167	19	0.68
BestValidationF1Score	0.9	0.8	0.9	0.92	0.89	155	13	148	20	0.68
BestValidationMCC	0.9	0.8	0.9	0.92	0.89	155	13	148	20	0.68
BestValidationAccuracy	0.9	0.8	0.9	0.92	0.89	155	13	148	20	0.68
TestPredictions (Threshold:0.68)
CHEMBL475496,TN,INACT,0.009999999776482582	CHEMBL406024,TP,ACT,0.9399999976158142	CHEMBL170068,TN,INACT,0.009999999776482582	CHEMBL305119,TP,ACT,0.8799999952316284	CHEMBL275017,TP,ACT,0.9900000095367432	CHEMBL316561,TN,INACT,0.009999999776482582	CHEMBL76823,TP,ACT,1.0	CHEMBL1927443,TN,INACT,0.009999999776482582	CHEMBL2113740,TP,ACT,1.0	CHEMBL62948,TN,INACT,0.0	CHEMBL2071537,TN,INACT,0.0	CHEMBL244363,TP,ACT,1.0	CHEMBL339767,TP,ACT,1.0	CHEMBL242848,TP,ACT,1.0	CHEMBL10224,TP,ACT,1.0	CHEMBL295698,FP,INACT,0.9200000166893005	CHEMBL3143400,TN,INACT,0.0	CHEMBL354196,TP,ACT,1.0	CHEMBL346178,TP,ACT,1.0	CHEMBL321644,TN,INACT,0.009999999776482582	CHEMBL74122,TN,INACT,0.009999999776482582	CHEMBL21502,TN,INACT,0.0	CHEMBL443264,TP,ACT,1.0	CHEMBL44722,TP,ACT,1.0	CHEMBL3665436,TN,INACT,0.009999999776482582	CHEMBL350596,TP,ACT,1.0	CHEMBL230324,FN,ACT,0.09000000357627869	CHEMBL285010,TN,INACT,0.0	CHEMBL160210,FN,ACT,0.6399999856948853	CHEMBL95986,TN,INACT,0.0	CHEMBL395974,TP,ACT,1.0	CHEMBL260120,TN,INACT,0.0	CHEMBL170325,TP,ACT,1.0	CHEMBL183232,TP,ACT,0.9900000095367432	CHEMBL97140,FN,ACT,0.05000000074505806	CHEMBL136990,TN,INACT,0.46000000834465027	CHEMBL183917,TP,ACT,0.9399999976158142	CHEMBL3739799,TN,INACT,0.07000000029802322	CHEMBL3642134,TN,INACT,0.07000000029802322	CHEMBL436981,TP,ACT,1.0	CHEMBL1083974,FN,ACT,0.0	CHEMBL1223054,TN,INACT,0.0	CHEMBL71644,TP,ACT,1.0	CHEMBL369174,TP,ACT,1.0	CHEMBL250715,FP,INACT,0.75	CHEMBL426421,TP,ACT,1.0	CHEMBL32163,TP,ACT,1.0	CHEMBL808,TP,ACT,0.9900000095367432	CHEMBL2442638,TN,INACT,0.0	CHEMBL316943,TP,ACT,0.9700000286102295	CHEMBL73272,TN,INACT,0.0	CHEMBL62527,TN,INACT,0.0	CHEMBL41457,TN,INACT,0.019999999552965164	CHEMBL7185,TN,INACT,0.0	CHEMBL3423404,TN,INACT,0.009999999776482582	CHEMBL62808,TN,INACT,0.0	CHEMBL33046,TP,ACT,1.0	CHEMBL16565,TN,INACT,0.0	CHEMBL398039,TN,INACT,0.009999999776482582	CHEMBL63544,TN,INACT,0.0	CHEMBL341843,TP,ACT,1.0	CHEMBL557997,TN,INACT,0.05999999865889549	CHEMBL125316,TN,INACT,0.019999999552965164	CHEMBL359141,TN,INACT,0.029999999329447746	CHEMBL61231,TN,INACT,0.0	CHEMBL243711,TP,ACT,1.0	CHEMBL339069,TN,INACT,0.0	CHEMBL3350496,TN,INACT,0.0	CHEMBL229390,TN,INACT,0.0	CHEMBL416151,TN,INACT,0.009999999776482582	CHEMBL182104,TP,ACT,0.9800000190734863	CHEMBL306065,TP,ACT,1.0	CHEMBL47412,TP,ACT,0.7599999904632568	CHEMBL308756,TN,INACT,0.0	CHEMBL183414,TP,ACT,1.0	CHEMBL32309,TP,ACT,0.9900000095367432	CHEMBL100297,TP,ACT,0.9900000095367432	CHEMBL168584,TP,ACT,1.0	CHEMBL429063,TN,INACT,0.0	CHEMBL277149,TN,INACT,0.0	CHEMBL1076625,TN,INACT,0.009999999776482582	CHEMBL1083876,TP,ACT,1.0	CHEMBL16056,TN,INACT,0.0	CHEMBL176811,TP,ACT,1.0	CHEMBL140620,TN,INACT,0.0	CHEMBL310703,TP,ACT,1.0	CHEMBL342572,TP,ACT,1.0	CHEMBL72707,TN,INACT,0.0	CHEMBL3651897,TP,ACT,1.0	CHEMBL387542,TP,ACT,0.8999999761581421	CHEMBL302027,TN,INACT,0.009999999776482582	CHEMBL365026,TN,INACT,0.009999999776482582	CHEMBL602474,TN,INACT,0.009999999776482582	CHEMBL3114163,TN,INACT,0.009999999776482582	CHEMBL298612,TN,INACT,0.0	CHEMBL3104222,TN,INACT,0.0	CHEMBL290175,FP,INACT,1.0	CHEMBL1083850,TP,ACT,1.0	CHEMBL3144353,TP,ACT,1.0	CHEMBL394889,TP,ACT,1.0	CHEMBL446693,TN,INACT,0.07000000029802322	CHEMBL287321,TN,INACT,0.0	CHEMBL38861,TN,INACT,0.009999999776482582	CHEMBL3314917,TN,INACT,0.0	CHEMBL1289,FN,ACT,0.0	CHEMBL185282,TN,INACT,0.019999999552965164	CHEMBL172354,TN,INACT,0.07000000029802322	CHEMBL226694,TN,INACT,0.03999999910593033	CHEMBL76093,TP,ACT,0.9900000095367432	CHEMBL306121,TP,ACT,1.0	CHEMBL388626,TP,ACT,1.0	CHEMBL2369631,TP,ACT,0.7599999904632568	CHEMBL2372075,TN,INACT,0.3799999952316284	CHEMBL3327376,TN,INACT,0.0	CHEMBL328812,TN,INACT,0.009999999776482582	CHEMBL64461,TN,INACT,0.0	CHEMBL230426,TP,ACT,1.0	CHEMBL496,FN,ACT,0.009999999776482582	CHEMBL323741,TP,ACT,1.0	CHEMBL417215,TN,INACT,0.009999999776482582	CHEMBL59733,TN,INACT,0.0	CHEMBL2413877,TN,INACT,0.0	CHEMBL106602,TN,INACT,0.0	CHEMBL318606,TP,ACT,1.0	CHEMBL171108,TN,INACT,0.0	CHEMBL1084251,TP,ACT,1.0	CHEMBL430118,TP,ACT,1.0	CHEMBL1076,TN,INACT,0.0	CHEMBL1084160,TP,ACT,1.0	CHEMBL286640,FN,ACT,0.38999998569488525	CHEMBL44345,TN,INACT,0.009999999776482582	CHEMBL389511,FN,ACT,0.09000000357627869	CHEMBL310273,TP,ACT,1.0	CHEMBL71784,TP,ACT,1.0	CHEMBL69889,TP,ACT,1.0	CHEMBL66106,TP,ACT,0.9399999976158142	CHEMBL360023,FN,ACT,0.0	CHEMBL2370238,TN,INACT,0.14000000059604645	CHEMBL193,TN,INACT,0.009999999776482582	CHEMBL63014,TP,ACT,1.0	CHEMBL324106,TP,ACT,0.9800000190734863	CHEMBL114442,TP,ACT,1.0	CHEMBL68917,TP,ACT,1.0	CHEMBL328285,TN,INACT,0.27000001072883606	CHEMBL3394775,TN,INACT,0.019999999552965164	CHEMBL369735,TP,ACT,0.9300000071525574	CHEMBL294502,TN,INACT,0.0	CHEMBL2018542,TN,INACT,0.36000001430511475	CHEMBL318221,TN,INACT,0.0	CHEMBL302668,FP,INACT,0.9399999976158142	CHEMBL146983,TN,INACT,0.009999999776482582	CHEMBL717,TN,INACT,0.019999999552965164	CHEMBL75436,TP,ACT,1.0	CHEMBL432986,TP,ACT,1.0	CHEMBL536800,TN,INACT,0.0	CHEMBL94902,TN,INACT,0.0	CHEMBL545363,TN,INACT,0.009999999776482582	CHEMBL45665,TN,INACT,0.03999999910593033	CHEMBL124459,TN,INACT,0.0	CHEMBL115633,TP,ACT,1.0	CHEMBL37512,TN,INACT,0.550000011920929	CHEMBL304888,TN,INACT,0.0	CHEMBL297776,FN,ACT,0.3199999928474426	CHEMBL309017,TN,INACT,0.009999999776482582	CHEMBL2092989,TN,INACT,0.0	CHEMBL32409,TN,INACT,0.009999999776482582	CHEMBL329749,TP,ACT,0.9700000286102295	CHEMBL2163917,FP,INACT,0.9100000262260437	CHEMBL3642172,TP,ACT,0.9900000095367432	CHEMBL545185,TN,INACT,0.009999999776482582	CHEMBL182600,TP,ACT,1.0	CHEMBL242624,TP,ACT,1.0	CHEMBL108364,TP,ACT,0.9900000095367432	CHEMBL330142,TN,INACT,0.0	CHEMBL1907728,TN,INACT,0.0	CHEMBL356268,TP,ACT,1.0	CHEMBL3642174,TP,ACT,0.8899999856948853	CHEMBL3642173,TP,ACT,1.0	CHEMBL75698,TP,ACT,1.0	CHEMBL319534,TN,INACT,0.009999999776482582	CHEMBL99331,TN,INACT,0.0	CHEMBL220334,FP,INACT,0.8100000023841858	CHEMBL3423403,TN,INACT,0.09000000357627869	CHEMBL354126,TN,INACT,0.46000000834465027	CHEMBL353027,TP,ACT,1.0	CHEMBL104377,TN,INACT,0.009999999776482582	CHEMBL2371928,TP,ACT,0.9900000095367432	CHEMBL3338850,TN,INACT,0.0	CHEMBL285422,TP,ACT,1.0	CHEMBL60435,TN,INACT,0.0	CHEMBL97764,FN,ACT,0.0	CHEMBL2115073,TP,ACT,0.9800000190734863	CHEMBL3218122,TN,INACT,0.49000000953674316	CHEMBL114,FN,ACT,0.05999999865889549	CHEMBL145314,TP,ACT,1.0	CHEMBL3818301,TN,INACT,0.41999998688697815	CHEMBL3608763,TN,INACT,0.0	CHEMBL307034,TN,INACT,0.0	CHEMBL95489,TN,INACT,0.009999999776482582	CHEMBL356923,TN,INACT,0.4300000071525574	CHEMBL63631,TN,INACT,0.009999999776482582	CHEMBL494093,TN,INACT,0.009999999776482582	CHEMBL173420,TP,ACT,1.0	CHEMBL394418,TP,ACT,0.9800000190734863	CHEMBL351508,TN,INACT,0.009999999776482582	CHEMBL42411,TN,INACT,0.0	CHEMBL2096822,TN,INACT,0.009999999776482582	CHEMBL231173,TP,ACT,1.0	CHEMBL10303,TP,ACT,0.9900000095367432	CHEMBL362889,TN,INACT,0.009999999776482582	CHEMBL359487,FN,ACT,0.009999999776482582	CHEMBL161242,TP,ACT,1.0	CHEMBL13095,TN,INACT,0.0	CHEMBL338045,TN,INACT,0.0	CHEMBL412591,FP,INACT,0.9700000286102295	CHEMBL321270,TP,ACT,1.0	CHEMBL1683146,FN,ACT,0.41999998688697815	CHEMBL289310,TN,INACT,0.0	CHEMBL125874,TN,INACT,0.25999999046325684	CHEMBL237082,TP,ACT,1.0	CHEMBL32173,TP,ACT,1.0	CHEMBL185133,TP,ACT,1.0	CHEMBL1083865,TP,ACT,0.8100000023841858	CHEMBL59931,TN,INACT,0.0	CHEMBL147767,TP,ACT,1.0	CHEMBL64479,TN,INACT,0.0	CHEMBL575027,FP,INACT,0.8100000023841858	CHEMBL243497,TP,ACT,1.0	CHEMBL372587,TP,ACT,0.9200000166893005	CHEMBL1201353,TN,INACT,0.009999999776482582	CHEMBL77023,TP,ACT,1.0	CHEMBL294349,TN,INACT,0.0	CHEMBL343969,TN,INACT,0.4699999988079071	CHEMBL166961,TP,ACT,1.0	CHEMBL362201,TP,ACT,0.9900000095367432	CHEMBL74860,TN,INACT,0.10000000149011612	CHEMBL295651,TN,INACT,0.009999999776482582	CHEMBL3642162,TP,ACT,1.0	CHEMBL3290978,TN,INACT,0.009999999776482582	CHEMBL56,TN,INACT,0.0	CHEMBL394607,TP,ACT,1.0	CHEMBL474991,TP,ACT,0.9700000286102295	CHEMBL3746620,TN,INACT,0.0	CHEMBL60509,TN,INACT,0.0	CHEMBL9643,TP,ACT,0.949999988079071	CHEMBL165506,TN,INACT,0.0	CHEMBL295770,FN,ACT,0.009999999776482582	CHEMBL355429,TP,ACT,1.0	CHEMBL407769,TP,ACT,0.9800000190734863	CHEMBL288300,TN,INACT,0.009999999776482582	CHEMBL1083559,TP,ACT,0.9900000095367432	CHEMBL400209,TP,ACT,1.0	CHEMBL243498,TP,ACT,1.0	CHEMBL365003,TN,INACT,0.0	CHEMBL322499,TN,INACT,0.49000000953674316	CHEMBL225297,TP,ACT,1.0	CHEMBL47555,FN,ACT,0.0	CHEMBL571492,TN,INACT,0.15000000596046448	CHEMBL3642127,TN,INACT,0.009999999776482582	CHEMBL1083846,TP,ACT,1.0	CHEMBL353088,TN,INACT,0.0	CHEMBL254505,TN,INACT,0.009999999776482582	CHEMBL306952,TP,ACT,1.0	CHEMBL149326,TP,ACT,0.949999988079071	CHEMBL265499,TP,ACT,1.0	CHEMBL316740,TP,ACT,1.0	CHEMBL2092991,TN,INACT,0.0	CHEMBL1083847,TP,ACT,1.0	CHEMBL328422,TN,INACT,0.0	CHEMBL26860,FN,ACT,0.25999999046325684	CHEMBL3343013,TN,INACT,0.0	CHEMBL1790763,TN,INACT,0.0	CHEMBL285475,TP,ACT,0.949999988079071	CHEMBL2391440,TN,INACT,0.009999999776482582	CHEMBL2371260,FP,INACT,0.8500000238418579	CHEMBL63785,TP,ACT,1.0	CHEMBL337269,TN,INACT,0.009999999776482582	CHEMBL353304,TN,INACT,0.0	CHEMBL557576,TN,INACT,0.009999999776482582	CHEMBL389744,TP,ACT,1.0	CHEMBL341143,TN,INACT,0.0	CHEMBL390168,TP,ACT,1.0	CHEMBL159585,TP,ACT,1.0	CHEMBL78132,TP,ACT,0.9900000095367432	CHEMBL397576,TP,ACT,1.0	CHEMBL11467,TN,INACT,0.0	CHEMBL162111,TN,INACT,0.09000000357627869	CHEMBL32385,TP,ACT,1.0	CHEMBL540360,TN,INACT,0.009999999776482582	CHEMBL3327368,TN,INACT,0.18000000715255737	CHEMBL187856,TN,INACT,0.019999999552965164	CHEMBL217548,TP,ACT,1.0	CHEMBL418411,TN,INACT,0.009999999776482582	CHEMBL1907932,TN,INACT,0.0	CHEMBL71918,TP,ACT,0.9200000166893005	CHEMBL307733,TP,ACT,1.0	CHEMBL3360196,TP,ACT,1.0	CHEMBL224888,TP,ACT,1.0	CHEMBL360721,FN,ACT,0.36000001430511475	CHEMBL2181969,TN,INACT,0.009999999776482582	CHEMBL141051,TN,INACT,0.0	CHEMBL3741290,TN,INACT,0.0	CHEMBL485576,TN,INACT,0.10000000149011612	CHEMBL3394007,TN,INACT,0.009999999776482582	CHEMBL249894,TN,INACT,0.0	CHEMBL47544,TP,ACT,1.0	CHEMBL109786,TN,INACT,0.0	CHEMBL225475,TP,ACT,0.9399999976158142	CHEMBL302468,TN,INACT,0.0	CHEMBL89445,TN,INACT,0.0	CHEMBL2391448,TN,INACT,0.009999999776482582	CHEMBL343158,TN,INACT,0.0	CHEMBL312750,TN,INACT,0.0	CHEMBL165175,TN,INACT,0.009999999776482582	CHEMBL62341,TP,ACT,0.9900000095367432	CHEMBL3650415,TN,INACT,0.009999999776482582	CHEMBL73618,TP,ACT,0.9599999785423279	CHEMBL2372525,FP,INACT,0.6899999976158142	CHEMBL10079,TP,ACT,1.0	CHEMBL2442636,TN,INACT,0.009999999776482582	CHEMBL167606,TP,ACT,1.0	CHEMBL1488893,TN,INACT,0.0	CHEMBL600610,TN,INACT,0.009999999776482582	CHEMBL39879,TN,INACT,0.0	CHEMBL1907856,TN,INACT,0.009999999776482582	CHEMBL417490,FN,ACT,0.5899999737739563	CHEMBL75018,TP,ACT,1.0	CHEMBL574602,FP,INACT,0.9100000262260437	CHEMBL1907845,TN,INACT,0.0	CHEMBL243726,TP,ACT,1.0	CHEMBL318081,TP,ACT,1.0	CHEMBL32124,TP,ACT,1.0	CHEMBL394419,TP,ACT,0.9800000190734863	CHEMBL306400,TP,ACT,1.0	CHEMBL362682,TP,ACT,0.9800000190734863	CHEMBL223994,TP,ACT,1.0	

