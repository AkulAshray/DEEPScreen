CNNModel CHEMBL232 RMSprop 0.001 30 128 0 0.6 False True
Number of active compounds :	1186
Number of inactive compounds :	1186
---------------------------------
Run id: CNNModel_CHEMBL232_RMSprop_0.001_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL232_RMSprop_0.001_30_128_0.6_True/
---------------------------------
Training samples: 1483
Validation samples: 464
--
Training Step: 1  | time: 0.785s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1483
[A[ATraining Step: 2  | total loss: [1m[32m0.62366[0m[0m | time: 1.400s
[2K
| RMSProp | epoch: 001 | loss: 0.62366 - acc: 0.5625 -- iter: 0064/1483
[A[ATraining Step: 3  | total loss: [1m[32m0.68053[0m[0m | time: 2.043s
[2K
| RMSProp | epoch: 001 | loss: 0.68053 - acc: 0.4602 -- iter: 0096/1483
[A[ATraining Step: 4  | total loss: [1m[32m0.68997[0m[0m | time: 2.683s
[2K
| RMSProp | epoch: 001 | loss: 0.68997 - acc: 0.4197 -- iter: 0128/1483
[A[ATraining Step: 5  | total loss: [1m[32m0.69232[0m[0m | time: 3.322s
[2K
| RMSProp | epoch: 001 | loss: 0.69232 - acc: 0.3671 -- iter: 0160/1483
[A[ATraining Step: 6  | total loss: [1m[32m0.69281[0m[0m | time: 3.931s
[2K
| RMSProp | epoch: 001 | loss: 0.69281 - acc: 0.5329 -- iter: 0192/1483
[A[ATraining Step: 7  | total loss: [1m[32m0.69300[0m[0m | time: 4.581s
[2K
| RMSProp | epoch: 001 | loss: 0.69300 - acc: 0.5319 -- iter: 0224/1483
[A[ATraining Step: 8  | total loss: [1m[32m0.69307[0m[0m | time: 5.223s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5491 -- iter: 0256/1483
[A[ATraining Step: 9  | total loss: [1m[32m0.69307[0m[0m | time: 5.842s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5562 -- iter: 0288/1483
[A[ATraining Step: 10  | total loss: [1m[32m0.69293[0m[0m | time: 6.487s
[2K
| RMSProp | epoch: 001 | loss: 0.69293 - acc: 0.6062 -- iter: 0320/1483
[A[ATraining Step: 11  | total loss: [1m[32m0.69314[0m[0m | time: 7.110s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5263 -- iter: 0352/1483
[A[ATraining Step: 12  | total loss: [1m[32m0.69316[0m[0m | time: 7.735s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.5004 -- iter: 0384/1483
[A[ATraining Step: 13  | total loss: [1m[32m0.69323[0m[0m | time: 8.382s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4868 -- iter: 0416/1483
[A[ATraining Step: 14  | total loss: [1m[32m0.69311[0m[0m | time: 9.039s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5306 -- iter: 0448/1483
[A[ATraining Step: 15  | total loss: [1m[32m0.69325[0m[0m | time: 9.684s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4942 -- iter: 0480/1483
[A[ATraining Step: 16  | total loss: [1m[32m0.69318[0m[0m | time: 10.321s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4963 -- iter: 0512/1483
[A[ATraining Step: 17  | total loss: [1m[32m0.69316[0m[0m | time: 10.972s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4864 -- iter: 0544/1483
[A[ATraining Step: 18  | total loss: [1m[32m0.69318[0m[0m | time: 11.651s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4911 -- iter: 0576/1483
[A[ATraining Step: 19  | total loss: [1m[32m0.69312[0m[0m | time: 12.314s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.5253 -- iter: 0608/1483
[A[ATraining Step: 20  | total loss: [1m[32m0.69310[0m[0m | time: 12.946s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5172 -- iter: 0640/1483
[A[ATraining Step: 21  | total loss: [1m[32m0.69312[0m[0m | time: 13.569s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.4925 -- iter: 0672/1483
[A[ATraining Step: 22  | total loss: [1m[32m0.69318[0m[0m | time: 14.182s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4853 -- iter: 0704/1483
[A[ATraining Step: 23  | total loss: [1m[32m0.69321[0m[0m | time: 14.894s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4533 -- iter: 0736/1483
[A[ATraining Step: 24  | total loss: [1m[32m0.69320[0m[0m | time: 15.510s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4577 -- iter: 0768/1483
[A[ATraining Step: 25  | total loss: [1m[32m0.69326[0m[0m | time: 16.123s
[2K
| RMSProp | epoch: 001 | loss: 0.69326 - acc: 0.4266 -- iter: 0800/1483
[A[ATraining Step: 26  | total loss: [1m[32m0.69323[0m[0m | time: 16.729s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4212 -- iter: 0832/1483
[A[ATraining Step: 27  | total loss: [1m[32m0.69324[0m[0m | time: 17.335s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4254 -- iter: 0864/1483
[A[ATraining Step: 28  | total loss: [1m[32m0.69322[0m[0m | time: 17.948s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4519 -- iter: 0896/1483
[A[ATraining Step: 29  | total loss: [1m[32m0.69319[0m[0m | time: 18.578s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4788 -- iter: 0928/1483
[A[ATraining Step: 30  | total loss: [1m[32m0.69309[0m[0m | time: 19.198s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5060 -- iter: 0960/1483
[A[ATraining Step: 31  | total loss: [1m[32m0.69316[0m[0m | time: 19.826s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4974 -- iter: 0992/1483
[A[ATraining Step: 32  | total loss: [1m[32m0.69313[0m[0m | time: 20.459s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4980 -- iter: 1024/1483
[A[ATraining Step: 33  | total loss: [1m[32m0.69316[0m[0m | time: 21.071s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4916 -- iter: 1056/1483
[A[ATraining Step: 34  | total loss: [1m[32m0.69325[0m[0m | time: 21.702s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4800 -- iter: 1088/1483
[A[ATraining Step: 35  | total loss: [1m[32m0.69325[0m[0m | time: 22.314s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4646 -- iter: 1120/1483
[A[ATraining Step: 36  | total loss: [1m[32m0.69327[0m[0m | time: 22.931s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.4462 -- iter: 1152/1483
[A[ATraining Step: 37  | total loss: [1m[32m0.69323[0m[0m | time: 23.548s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4757 -- iter: 1184/1483
[A[ATraining Step: 38  | total loss: [1m[32m0.69321[0m[0m | time: 24.171s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4866 -- iter: 1216/1483
[A[ATraining Step: 39  | total loss: [1m[32m0.69317[0m[0m | time: 24.797s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5071 -- iter: 1248/1483
[A[ATraining Step: 40  | total loss: [1m[32m0.69315[0m[0m | time: 25.435s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.5116 -- iter: 1280/1483
[A[ATraining Step: 41  | total loss: [1m[32m0.69314[0m[0m | time: 26.050s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5152 -- iter: 1312/1483
[A[ATraining Step: 42  | total loss: [1m[32m0.69317[0m[0m | time: 26.668s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5012 -- iter: 1344/1483
[A[ATraining Step: 43  | total loss: [1m[32m0.69320[0m[0m | time: 27.284s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4900 -- iter: 1376/1483
[A[ATraining Step: 44  | total loss: [1m[32m0.69317[0m[0m | time: 27.903s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5025 -- iter: 1408/1483
[A[ATraining Step: 45  | total loss: [1m[32m0.69316[0m[0m | time: 28.573s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.5233 -- iter: 1440/1483
[A[ATraining Step: 46  | total loss: [1m[32m0.69317[0m[0m | time: 29.186s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5038 -- iter: 1472/1483
[A[ATraining Step: 47  | total loss: [1m[32m0.69324[0m[0m | time: 30.998s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4776 | val_loss: 0.69314 - val_acc: 0.5108 -- iter: 1483/1483
--
Training Step: 48  | total loss: [1m[32m0.69324[0m[0m | time: 0.250s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4739 -- iter: 0032/1483
[A[ATraining Step: 49  | total loss: [1m[32m0.69325[0m[0m | time: 0.869s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4852 -- iter: 0064/1483
[A[ATraining Step: 50  | total loss: [1m[32m0.69323[0m[0m | time: 1.482s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4972 -- iter: 0096/1483
[A[ATraining Step: 51  | total loss: [1m[32m0.69319[0m[0m | time: 2.095s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.5024 -- iter: 0128/1483
[A[ATraining Step: 52  | total loss: [1m[32m0.69313[0m[0m | time: 2.729s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5114 -- iter: 0160/1483
[A[ATraining Step: 53  | total loss: [1m[32m0.69312[0m[0m | time: 3.346s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5051 -- iter: 0192/1483
[A[ATraining Step: 54  | total loss: [1m[32m0.69313[0m[0m | time: 3.981s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.4998 -- iter: 0224/1483
[A[ATraining Step: 55  | total loss: [1m[32m0.69320[0m[0m | time: 4.596s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4775 -- iter: 0256/1483
[A[ATraining Step: 56  | total loss: [1m[32m0.69319[0m[0m | time: 5.214s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4851 -- iter: 0288/1483
[A[ATraining Step: 57  | total loss: [1m[32m0.69315[0m[0m | time: 5.831s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4958 -- iter: 0320/1483
[A[ATraining Step: 58  | total loss: [1m[32m0.69314[0m[0m | time: 6.448s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4964 -- iter: 0352/1483
[A[ATraining Step: 59  | total loss: [1m[32m0.69324[0m[0m | time: 7.058s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4717 -- iter: 0384/1483
[A[ATraining Step: 60  | total loss: [1m[32m0.69325[0m[0m | time: 7.667s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4630 -- iter: 0416/1483
[A[ATraining Step: 61  | total loss: [1m[32m0.69321[0m[0m | time: 8.294s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4760 -- iter: 0448/1483
[A[ATraining Step: 62  | total loss: [1m[32m0.69314[0m[0m | time: 8.931s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4952 -- iter: 0480/1483
[A[ATraining Step: 63  | total loss: [1m[32m0.69325[0m[0m | time: 9.543s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4799 -- iter: 0512/1483
[A[ATraining Step: 64  | total loss: [1m[32m0.69333[0m[0m | time: 10.217s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.4551 -- iter: 0544/1483
[A[ATraining Step: 65  | total loss: [1m[32m0.69331[0m[0m | time: 10.827s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4568 -- iter: 0576/1483
[A[ATraining Step: 66  | total loss: [1m[32m0.69328[0m[0m | time: 11.453s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4658 -- iter: 0608/1483
[A[ATraining Step: 67  | total loss: [1m[32m0.69327[0m[0m | time: 12.069s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.4699 -- iter: 0640/1483
[A[ATraining Step: 68  | total loss: [1m[32m0.69325[0m[0m | time: 12.704s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4735 -- iter: 0672/1483
[A[ATraining Step: 69  | total loss: [1m[32m0.69322[0m[0m | time: 13.333s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4802 -- iter: 0704/1483
[A[ATraining Step: 70  | total loss: [1m[32m0.69320[0m[0m | time: 13.965s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4789 -- iter: 0736/1483
[A[ATraining Step: 71  | total loss: [1m[32m0.69319[0m[0m | time: 14.576s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4813 -- iter: 0768/1483
[A[ATraining Step: 72  | total loss: [1m[32m0.69324[0m[0m | time: 15.198s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4694 -- iter: 0800/1483
[A[ATraining Step: 73  | total loss: [1m[32m0.69325[0m[0m | time: 15.817s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4658 -- iter: 0832/1483
[A[ATraining Step: 74  | total loss: [1m[32m0.69322[0m[0m | time: 16.457s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4833 -- iter: 0864/1483
[A[ATraining Step: 75  | total loss: [1m[32m0.69321[0m[0m | time: 17.062s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4851 -- iter: 0896/1483
[A[ATraining Step: 76  | total loss: [1m[32m0.69320[0m[0m | time: 17.683s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4967 -- iter: 0928/1483
[A[ATraining Step: 77  | total loss: [1m[32m0.69324[0m[0m | time: 18.289s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4905 -- iter: 0960/1483
[A[ATraining Step: 78  | total loss: [1m[32m0.69320[0m[0m | time: 18.905s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.5013 -- iter: 0992/1483
[A[ATraining Step: 79  | total loss: [1m[32m0.69316[0m[0m | time: 19.536s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.5076 -- iter: 1024/1483
[A[ATraining Step: 80  | total loss: [1m[32m0.69332[0m[0m | time: 20.156s
[2K
| RMSProp | epoch: 002 | loss: 0.69332 - acc: 0.4909 -- iter: 1056/1483
[A[ATraining Step: 81  | total loss: [1m[32m0.69327[0m[0m | time: 20.787s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.5013 -- iter: 1088/1483
[A[ATraining Step: 82  | total loss: [1m[32m0.69335[0m[0m | time: 21.423s
[2K
| RMSProp | epoch: 002 | loss: 0.69335 - acc: 0.4886 -- iter: 1120/1483
[A[ATraining Step: 83  | total loss: [1m[32m0.69333[0m[0m | time: 22.068s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.4929 -- iter: 1152/1483
[A[ATraining Step: 84  | total loss: [1m[32m0.69333[0m[0m | time: 22.677s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.4874 -- iter: 1184/1483
[A[ATraining Step: 85  | total loss: [1m[32m0.69331[0m[0m | time: 23.291s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4855 -- iter: 1216/1483
[A[ATraining Step: 86  | total loss: [1m[32m0.69330[0m[0m | time: 23.929s
[2K
| RMSProp | epoch: 002 | loss: 0.69330 - acc: 0.4932 -- iter: 1248/1483
[A[ATraining Step: 87  | total loss: [1m[32m0.69330[0m[0m | time: 24.549s
[2K
| RMSProp | epoch: 002 | loss: 0.69330 - acc: 0.4908 -- iter: 1280/1483
[A[ATraining Step: 88  | total loss: [1m[32m0.69334[0m[0m | time: 25.165s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4823 -- iter: 1312/1483
[A[ATraining Step: 89  | total loss: [1m[32m0.69333[0m[0m | time: 25.774s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.4747 -- iter: 1344/1483
[A[ATraining Step: 90  | total loss: [1m[32m0.69334[0m[0m | time: 26.396s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4741 -- iter: 1376/1483
[A[ATraining Step: 91  | total loss: [1m[32m0.69331[0m[0m | time: 27.012s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4829 -- iter: 1408/1483
[A[ATraining Step: 92  | total loss: [1m[32m0.69330[0m[0m | time: 27.639s
[2K
| RMSProp | epoch: 002 | loss: 0.69330 - acc: 0.4846 -- iter: 1440/1483
[A[ATraining Step: 93  | total loss: [1m[32m0.69331[0m[0m | time: 28.286s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4831 -- iter: 1472/1483
[A[ATraining Step: 94  | total loss: [1m[32m0.69335[0m[0m | time: 30.395s
[2K
| RMSProp | epoch: 002 | loss: 0.69335 - acc: 0.4723 | val_loss: 0.69315 - val_acc: 0.4892 -- iter: 1483/1483
--
Training Step: 95  | total loss: [1m[32m0.69334[0m[0m | time: 0.281s
[2K
| RMSProp | epoch: 003 | loss: 0.69334 - acc: 0.4719 -- iter: 0032/1483
[A[ATraining Step: 96  | total loss: [1m[32m0.69329[0m[0m | time: 0.532s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.4883 -- iter: 0064/1483
[A[ATraining Step: 97  | total loss: [1m[32m0.69295[0m[0m | time: 1.152s
[2K
| RMSProp | epoch: 003 | loss: 0.69295 - acc: 0.5122 -- iter: 0096/1483
[A[ATraining Step: 98  | total loss: [1m[32m0.69299[0m[0m | time: 1.774s
[2K
| RMSProp | epoch: 003 | loss: 0.69299 - acc: 0.5110 -- iter: 0128/1483
[A[ATraining Step: 99  | total loss: [1m[32m0.69324[0m[0m | time: 2.405s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.5005 -- iter: 0160/1483
[A[ATraining Step: 100  | total loss: [1m[32m0.69317[0m[0m | time: 3.035s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.5036 -- iter: 0192/1483
[A[ATraining Step: 101  | total loss: [1m[32m0.69330[0m[0m | time: 3.650s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.4970 -- iter: 0224/1483
[A[ATraining Step: 102  | total loss: [1m[32m0.69334[0m[0m | time: 4.267s
[2K
| RMSProp | epoch: 003 | loss: 0.69334 - acc: 0.4942 -- iter: 0256/1483
[A[ATraining Step: 103  | total loss: [1m[32m0.69321[0m[0m | time: 4.886s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.5010 -- iter: 0288/1483
[A[ATraining Step: 104  | total loss: [1m[32m0.69282[0m[0m | time: 5.504s
[2K
| RMSProp | epoch: 003 | loss: 0.69282 - acc: 0.5197 -- iter: 0320/1483
[A[ATraining Step: 105  | total loss: [1m[32m0.69318[0m[0m | time: 6.130s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.5083 -- iter: 0352/1483
[A[ATraining Step: 106  | total loss: [1m[32m0.69287[0m[0m | time: 6.745s
[2K
| RMSProp | epoch: 003 | loss: 0.69287 - acc: 0.5200 -- iter: 0384/1483
[A[ATraining Step: 107  | total loss: [1m[32m0.69271[0m[0m | time: 7.366s
[2K
| RMSProp | epoch: 003 | loss: 0.69271 - acc: 0.5242 -- iter: 0416/1483
[A[ATraining Step: 108  | total loss: [1m[32m0.69264[0m[0m | time: 7.988s
[2K
| RMSProp | epoch: 003 | loss: 0.69264 - acc: 0.5249 -- iter: 0448/1483
[A[ATraining Step: 109  | total loss: [1m[32m0.69282[0m[0m | time: 8.593s
[2K
| RMSProp | epoch: 003 | loss: 0.69282 - acc: 0.5193 -- iter: 0480/1483
[A[ATraining Step: 110  | total loss: [1m[32m0.69254[0m[0m | time: 9.205s
[2K
| RMSProp | epoch: 003 | loss: 0.69254 - acc: 0.5268 -- iter: 0512/1483
[A[ATraining Step: 111  | total loss: [1m[32m0.69232[0m[0m | time: 9.827s
[2K
| RMSProp | epoch: 003 | loss: 0.69232 - acc: 0.5303 -- iter: 0544/1483
[A[ATraining Step: 112  | total loss: [1m[32m0.69182[0m[0m | time: 10.446s
[2K
| RMSProp | epoch: 003 | loss: 0.69182 - acc: 0.5398 -- iter: 0576/1483
[A[ATraining Step: 113  | total loss: [1m[32m0.69270[0m[0m | time: 11.075s
[2K
| RMSProp | epoch: 003 | loss: 0.69270 - acc: 0.5233 -- iter: 0608/1483
[A[ATraining Step: 114  | total loss: [1m[32m0.69219[0m[0m | time: 11.681s
[2K
| RMSProp | epoch: 003 | loss: 0.69219 - acc: 0.5335 -- iter: 0640/1483
[A[ATraining Step: 115  | total loss: [1m[32m0.69146[0m[0m | time: 12.295s
[2K
| RMSProp | epoch: 003 | loss: 0.69146 - acc: 0.5458 -- iter: 0672/1483
[A[ATraining Step: 116  | total loss: [1m[32m0.69188[0m[0m | time: 12.895s
[2K
| RMSProp | epoch: 003 | loss: 0.69188 - acc: 0.5381 -- iter: 0704/1483
[A[ATraining Step: 117  | total loss: [1m[32m0.69185[0m[0m | time: 13.500s
[2K
| RMSProp | epoch: 003 | loss: 0.69185 - acc: 0.5374 -- iter: 0736/1483
[A[ATraining Step: 118  | total loss: [1m[32m0.69265[0m[0m | time: 14.099s
[2K
| RMSProp | epoch: 003 | loss: 0.69265 - acc: 0.5243 -- iter: 0768/1483
[A[ATraining Step: 119  | total loss: [1m[32m0.69303[0m[0m | time: 14.746s
[2K
| RMSProp | epoch: 003 | loss: 0.69303 - acc: 0.5156 -- iter: 0800/1483
[A[ATraining Step: 120  | total loss: [1m[32m0.69360[0m[0m | time: 15.366s
[2K
| RMSProp | epoch: 003 | loss: 0.69360 - acc: 0.5015 -- iter: 0832/1483
[A[ATraining Step: 121  | total loss: [1m[32m0.69365[0m[0m | time: 15.984s
[2K
| RMSProp | epoch: 003 | loss: 0.69365 - acc: 0.4983 -- iter: 0864/1483
[A[ATraining Step: 122  | total loss: [1m[32m0.69366[0m[0m | time: 16.586s
[2K
| RMSProp | epoch: 003 | loss: 0.69366 - acc: 0.4953 -- iter: 0896/1483
[A[ATraining Step: 123  | total loss: [1m[32m0.69367[0m[0m | time: 17.228s
[2K
| RMSProp | epoch: 003 | loss: 0.69367 - acc: 0.4926 -- iter: 0928/1483
[A[ATraining Step: 124  | total loss: [1m[32m0.69372[0m[0m | time: 17.846s
[2K
| RMSProp | epoch: 003 | loss: 0.69372 - acc: 0.4840 -- iter: 0960/1483
[A[ATraining Step: 125  | total loss: [1m[32m0.69371[0m[0m | time: 18.459s
[2K
| RMSProp | epoch: 003 | loss: 0.69371 - acc: 0.4700 -- iter: 0992/1483
[A[ATraining Step: 126  | total loss: [1m[32m0.69381[0m[0m | time: 19.080s
[2K
| RMSProp | epoch: 003 | loss: 0.69381 - acc: 0.4636 -- iter: 1024/1483
[A[ATraining Step: 127  | total loss: [1m[32m0.69372[0m[0m | time: 19.691s
[2K
| RMSProp | epoch: 003 | loss: 0.69372 - acc: 0.4766 -- iter: 1056/1483
[A[ATraining Step: 128  | total loss: [1m[32m0.69380[0m[0m | time: 20.359s
[2K
| RMSProp | epoch: 003 | loss: 0.69380 - acc: 0.4665 -- iter: 1088/1483
[A[ATraining Step: 129  | total loss: [1m[32m0.69369[0m[0m | time: 20.965s
[2K
| RMSProp | epoch: 003 | loss: 0.69369 - acc: 0.4823 -- iter: 1120/1483
[A[ATraining Step: 130  | total loss: [1m[32m0.69342[0m[0m | time: 21.590s
[2K
| RMSProp | epoch: 003 | loss: 0.69342 - acc: 0.4966 -- iter: 1152/1483
[A[ATraining Step: 131  | total loss: [1m[32m0.69330[0m[0m | time: 22.205s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.5001 -- iter: 1184/1483
[A[ATraining Step: 132  | total loss: [1m[32m0.69352[0m[0m | time: 22.835s
[2K
| RMSProp | epoch: 003 | loss: 0.69352 - acc: 0.4938 -- iter: 1216/1483
[A[ATraining Step: 133  | total loss: [1m[32m0.69356[0m[0m | time: 23.456s
[2K
| RMSProp | epoch: 003 | loss: 0.69356 - acc: 0.4913 -- iter: 1248/1483
[A[ATraining Step: 134  | total loss: [1m[32m0.69338[0m[0m | time: 24.071s
[2K
| RMSProp | epoch: 003 | loss: 0.69338 - acc: 0.4984 -- iter: 1280/1483
[A[ATraining Step: 135  | total loss: [1m[32m0.69346[0m[0m | time: 24.718s
[2K
| RMSProp | epoch: 003 | loss: 0.69346 - acc: 0.4954 -- iter: 1312/1483
[A[ATraining Step: 136  | total loss: [1m[32m0.69283[0m[0m | time: 25.333s
[2K
| RMSProp | epoch: 003 | loss: 0.69283 - acc: 0.5209 -- iter: 1344/1483
[A[ATraining Step: 137  | total loss: [1m[32m0.69343[0m[0m | time: 25.946s
[2K
| RMSProp | epoch: 003 | loss: 0.69343 - acc: 0.5094 -- iter: 1376/1483
[A[ATraining Step: 138  | total loss: [1m[32m0.69351[0m[0m | time: 26.575s
[2K
| RMSProp | epoch: 003 | loss: 0.69351 - acc: 0.5054 -- iter: 1408/1483
[A[ATraining Step: 139  | total loss: [1m[32m0.69328[0m[0m | time: 27.192s
[2K
| RMSProp | epoch: 003 | loss: 0.69328 - acc: 0.5111 -- iter: 1440/1483
[A[ATraining Step: 140  | total loss: [1m[32m0.69300[0m[0m | time: 27.855s
[2K
| RMSProp | epoch: 003 | loss: 0.69300 - acc: 0.5162 -- iter: 1472/1483
[A[ATraining Step: 141  | total loss: [1m[32m0.69333[0m[0m | time: 29.974s
[2K
| RMSProp | epoch: 003 | loss: 0.69333 - acc: 0.5084 | val_loss: 0.69381 - val_acc: 0.4892 -- iter: 1483/1483
--
Training Step: 142  | total loss: [1m[32m0.69301[0m[0m | time: 0.613s
[2K
| RMSProp | epoch: 004 | loss: 0.69301 - acc: 0.5169 -- iter: 0032/1483
[A[ATraining Step: 143  | total loss: [1m[32m0.69336[0m[0m | time: 0.868s
[2K
| RMSProp | epoch: 004 | loss: 0.69336 - acc: 0.5090 -- iter: 0064/1483
[A[ATraining Step: 144  | total loss: [1m[32m0.69316[0m[0m | time: 1.112s
[2K
| RMSProp | epoch: 004 | loss: 0.69316 - acc: 0.5126 -- iter: 0096/1483
[A[ATraining Step: 145  | total loss: [1m[32m0.69294[0m[0m | time: 1.720s
[2K
| RMSProp | epoch: 004 | loss: 0.69294 - acc: 0.5159 -- iter: 0128/1483
[A[ATraining Step: 146  | total loss: [1m[32m0.69263[0m[0m | time: 2.357s
[2K
| RMSProp | epoch: 004 | loss: 0.69263 - acc: 0.5205 -- iter: 0160/1483
[A[ATraining Step: 147  | total loss: [1m[32m0.69273[0m[0m | time: 2.997s
[2K
| RMSProp | epoch: 004 | loss: 0.69273 - acc: 0.5185 -- iter: 0192/1483
[A[ATraining Step: 148  | total loss: [1m[32m0.69258[0m[0m | time: 3.625s
[2K
| RMSProp | epoch: 004 | loss: 0.69258 - acc: 0.5198 -- iter: 0224/1483
[A[ATraining Step: 149  | total loss: [1m[32m0.69269[0m[0m | time: 4.247s
[2K
| RMSProp | epoch: 004 | loss: 0.69269 - acc: 0.5178 -- iter: 0256/1483
[A[ATraining Step: 150  | total loss: [1m[32m0.69219[0m[0m | time: 4.882s
[2K
| RMSProp | epoch: 004 | loss: 0.69219 - acc: 0.5254 -- iter: 0288/1483
[A[ATraining Step: 151  | total loss: [1m[32m0.69305[0m[0m | time: 5.520s
[2K
| RMSProp | epoch: 004 | loss: 0.69305 - acc: 0.5166 -- iter: 0320/1483
[A[ATraining Step: 152  | total loss: [1m[32m0.69335[0m[0m | time: 6.183s
[2K
| RMSProp | epoch: 004 | loss: 0.69335 - acc: 0.5087 -- iter: 0352/1483
[A[ATraining Step: 153  | total loss: [1m[32m0.69313[0m[0m | time: 6.836s
[2K
| RMSProp | epoch: 004 | loss: 0.69313 - acc: 0.5141 -- iter: 0384/1483
[A[ATraining Step: 154  | total loss: [1m[32m0.69328[0m[0m | time: 7.477s
[2K
| RMSProp | epoch: 004 | loss: 0.69328 - acc: 0.5095 -- iter: 0416/1483
[A[ATraining Step: 155  | total loss: [1m[32m0.69357[0m[0m | time: 8.092s
[2K
| RMSProp | epoch: 004 | loss: 0.69357 - acc: 0.4992 -- iter: 0448/1483
[A[ATraining Step: 156  | total loss: [1m[32m0.69353[0m[0m | time: 8.708s
[2K
| RMSProp | epoch: 004 | loss: 0.69353 - acc: 0.4993 -- iter: 0480/1483
[A[ATraining Step: 157  | total loss: [1m[32m0.69356[0m[0m | time: 9.335s
[2K
| RMSProp | epoch: 004 | loss: 0.69356 - acc: 0.4962 -- iter: 0512/1483
[A[ATraining Step: 158  | total loss: [1m[32m0.69350[0m[0m | time: 9.971s
[2K
| RMSProp | epoch: 004 | loss: 0.69350 - acc: 0.4966 -- iter: 0544/1483
[A[ATraining Step: 159  | total loss: [1m[32m0.69334[0m[0m | time: 10.597s
[2K
| RMSProp | epoch: 004 | loss: 0.69334 - acc: 0.5001 -- iter: 0576/1483
[A[ATraining Step: 160  | total loss: [1m[32m0.69333[0m[0m | time: 11.214s
[2K
| RMSProp | epoch: 004 | loss: 0.69333 - acc: 0.5001 -- iter: 0608/1483
[A[ATraining Step: 161  | total loss: [1m[32m0.69280[0m[0m | time: 11.822s
[2K
| RMSProp | epoch: 004 | loss: 0.69280 - acc: 0.5157 -- iter: 0640/1483
[A[ATraining Step: 162  | total loss: [1m[32m0.69478[0m[0m | time: 12.465s
[2K
| RMSProp | epoch: 004 | loss: 0.69478 - acc: 0.4985 -- iter: 0672/1483
[A[ATraining Step: 163  | total loss: [1m[32m0.69490[0m[0m | time: 13.090s
[2K
| RMSProp | epoch: 004 | loss: 0.69490 - acc: 0.4799 -- iter: 0704/1483
[A[ATraining Step: 164  | total loss: [1m[32m0.69474[0m[0m | time: 13.717s
[2K
| RMSProp | epoch: 004 | loss: 0.69474 - acc: 0.4819 -- iter: 0736/1483
[A[ATraining Step: 165  | total loss: [1m[32m0.69452[0m[0m | time: 14.321s
[2K
| RMSProp | epoch: 004 | loss: 0.69452 - acc: 0.4900 -- iter: 0768/1483
[A[ATraining Step: 166  | total loss: [1m[32m0.69425[0m[0m | time: 14.942s
[2K
| RMSProp | epoch: 004 | loss: 0.69425 - acc: 0.4972 -- iter: 0800/1483
[A[ATraining Step: 167  | total loss: [1m[32m0.69380[0m[0m | time: 15.572s
[2K
| RMSProp | epoch: 004 | loss: 0.69380 - acc: 0.5069 -- iter: 0832/1483
[A[ATraining Step: 168  | total loss: [1m[32m0.69411[0m[0m | time: 16.188s
[2K
| RMSProp | epoch: 004 | loss: 0.69411 - acc: 0.5031 -- iter: 0864/1483
[A[ATraining Step: 169  | total loss: [1m[32m0.69388[0m[0m | time: 16.801s
[2K
| RMSProp | epoch: 004 | loss: 0.69388 - acc: 0.5059 -- iter: 0896/1483
[A[ATraining Step: 170  | total loss: [1m[32m0.69399[0m[0m | time: 17.419s
[2K
| RMSProp | epoch: 004 | loss: 0.69399 - acc: 0.5022 -- iter: 0928/1483
[A[ATraining Step: 171  | total loss: [1m[32m0.69337[0m[0m | time: 18.042s
[2K
| RMSProp | epoch: 004 | loss: 0.69337 - acc: 0.5207 -- iter: 0960/1483
[A[ATraining Step: 172  | total loss: [1m[32m0.69421[0m[0m | time: 18.668s
[2K
| RMSProp | epoch: 004 | loss: 0.69421 - acc: 0.5093 -- iter: 0992/1483
[A[ATraining Step: 173  | total loss: [1m[32m0.69474[0m[0m | time: 19.302s
[2K
| RMSProp | epoch: 004 | loss: 0.69474 - acc: 0.4896 -- iter: 1024/1483
[A[ATraining Step: 174  | total loss: [1m[32m0.69461[0m[0m | time: 19.917s
[2K
| RMSProp | epoch: 004 | loss: 0.69461 - acc: 0.4812 -- iter: 1056/1483
[A[ATraining Step: 175  | total loss: [1m[32m0.69449[0m[0m | time: 20.523s
[2K
| RMSProp | epoch: 004 | loss: 0.69449 - acc: 0.4800 -- iter: 1088/1483
[A[ATraining Step: 176  | total loss: [1m[32m0.69433[0m[0m | time: 21.135s
[2K
| RMSProp | epoch: 004 | loss: 0.69433 - acc: 0.4820 -- iter: 1120/1483
[A[ATraining Step: 177  | total loss: [1m[32m0.69424[0m[0m | time: 21.776s
[2K
| RMSProp | epoch: 004 | loss: 0.69424 - acc: 0.4807 -- iter: 1152/1483
[A[ATraining Step: 178  | total loss: [1m[32m0.69410[0m[0m | time: 22.432s
[2K
| RMSProp | epoch: 004 | loss: 0.69410 - acc: 0.4857 -- iter: 1184/1483
[A[ATraining Step: 179  | total loss: [1m[32m0.69393[0m[0m | time: 23.084s
[2K
| RMSProp | epoch: 004 | loss: 0.69393 - acc: 0.4934 -- iter: 1216/1483
[A[ATraining Step: 180  | total loss: [1m[32m0.69367[0m[0m | time: 23.737s
[2K
| RMSProp | epoch: 004 | loss: 0.69367 - acc: 0.5003 -- iter: 1248/1483
[A[ATraining Step: 181  | total loss: [1m[32m0.69433[0m[0m | time: 24.349s
[2K
| RMSProp | epoch: 004 | loss: 0.69433 - acc: 0.4878 -- iter: 1280/1483
[A[ATraining Step: 182  | total loss: [1m[32m0.69422[0m[0m | time: 25.383s
[2K
| RMSProp | epoch: 004 | loss: 0.69422 - acc: 0.4828 -- iter: 1312/1483
[A[ATraining Step: 183  | total loss: [1m[32m0.69358[0m[0m | time: 26.424s
[2K
| RMSProp | epoch: 004 | loss: 0.69358 - acc: 0.5032 -- iter: 1344/1483
[A[ATraining Step: 184  | total loss: [1m[32m0.69649[0m[0m | time: 27.810s
[2K
| RMSProp | epoch: 004 | loss: 0.69649 - acc: 0.4842 -- iter: 1376/1483
[A[ATraining Step: 185  | total loss: [1m[32m0.69597[0m[0m | time: 28.821s
[2K
| RMSProp | epoch: 004 | loss: 0.69597 - acc: 0.5107 -- iter: 1408/1483
[A[ATraining Step: 186  | total loss: [1m[32m0.69570[0m[0m | time: 29.813s
[2K
| RMSProp | epoch: 004 | loss: 0.69570 - acc: 0.5097 -- iter: 1440/1483
[A[ATraining Step: 187  | total loss: [1m[32m0.69527[0m[0m | time: 30.823s
[2K
| RMSProp | epoch: 004 | loss: 0.69527 - acc: 0.5150 -- iter: 1472/1483
[A[ATraining Step: 188  | total loss: [1m[32m0.69496[0m[0m | time: 34.356s
[2K
| RMSProp | epoch: 004 | loss: 0.69496 - acc: 0.5166 | val_loss: 0.69363 - val_acc: 0.4892 -- iter: 1483/1483
--
Training Step: 189  | total loss: [1m[32m0.69478[0m[0m | time: 0.872s
[2K
| RMSProp | epoch: 005 | loss: 0.69478 - acc: 0.5149 -- iter: 0032/1483
[A[ATraining Step: 190  | total loss: [1m[32m0.69476[0m[0m | time: 1.540s
[2K
| RMSProp | epoch: 005 | loss: 0.69476 - acc: 0.5103 -- iter: 0064/1483
[A[ATraining Step: 191  | total loss: [1m[32m0.69459[0m[0m | time: 1.802s
[2K
| RMSProp | epoch: 005 | loss: 0.69459 - acc: 0.5093 -- iter: 0096/1483
[A[ATraining Step: 192  | total loss: [1m[32m0.69432[0m[0m | time: 2.127s
[2K
| RMSProp | epoch: 005 | loss: 0.69432 - acc: 0.5129 -- iter: 0128/1483
[A[ATraining Step: 193  | total loss: [1m[32m0.69401[0m[0m | time: 3.184s
[2K
| RMSProp | epoch: 005 | loss: 0.69401 - acc: 0.5161 -- iter: 0160/1483
[A[ATraining Step: 194  | total loss: [1m[32m0.69407[0m[0m | time: 4.232s
[2K
| RMSProp | epoch: 005 | loss: 0.69407 - acc: 0.5114 -- iter: 0192/1483
[A[ATraining Step: 195  | total loss: [1m[32m0.69344[0m[0m | time: 5.610s
[2K
| RMSProp | epoch: 005 | loss: 0.69344 - acc: 0.5290 -- iter: 0224/1483
[A[ATraining Step: 196  | total loss: [1m[32m0.69408[0m[0m | time: 6.597s
[2K
| RMSProp | epoch: 005 | loss: 0.69408 - acc: 0.5167 -- iter: 0256/1483
[A[ATraining Step: 197  | total loss: [1m[32m0.69373[0m[0m | time: 7.571s
[2K
| RMSProp | epoch: 005 | loss: 0.69373 - acc: 0.5213 -- iter: 0288/1483
[A[ATraining Step: 198  | total loss: [1m[32m0.69353[0m[0m | time: 8.628s
[2K
| RMSProp | epoch: 005 | loss: 0.69353 - acc: 0.5223 -- iter: 0320/1483
[A[ATraining Step: 199  | total loss: [1m[32m0.69251[0m[0m | time: 9.681s
[2K
| RMSProp | epoch: 005 | loss: 0.69251 - acc: 0.5388 -- iter: 0352/1483
[A[ATraining Step: 200  | total loss: [1m[32m0.69211[0m[0m | time: 13.289s
[2K
| RMSProp | epoch: 005 | loss: 0.69211 - acc: 0.5412 | val_loss: 0.69614 - val_acc: 0.4892 -- iter: 0384/1483
--
Training Step: 201  | total loss: [1m[32m0.69196[0m[0m | time: 14.205s
[2K
| RMSProp | epoch: 005 | loss: 0.69196 - acc: 0.5402 -- iter: 0416/1483
[A[ATraining Step: 202  | total loss: [1m[32m0.69445[0m[0m | time: 15.249s
[2K
| RMSProp | epoch: 005 | loss: 0.69445 - acc: 0.5206 -- iter: 0448/1483
[A[ATraining Step: 203  | total loss: [1m[32m0.69507[0m[0m | time: 16.428s
[2K
| RMSProp | epoch: 005 | loss: 0.69507 - acc: 0.5029 -- iter: 0480/1483
[A[ATraining Step: 204  | total loss: [1m[32m0.69528[0m[0m | time: 17.688s
[2K
| RMSProp | epoch: 005 | loss: 0.69528 - acc: 0.4870 -- iter: 0512/1483
[A[ATraining Step: 205  | total loss: [1m[32m0.69500[0m[0m | time: 18.601s
[2K
| RMSProp | epoch: 005 | loss: 0.69500 - acc: 0.5101 -- iter: 0544/1483
[A[ATraining Step: 206  | total loss: [1m[32m0.69512[0m[0m | time: 19.558s
[2K
| RMSProp | epoch: 005 | loss: 0.69512 - acc: 0.4998 -- iter: 0576/1483
[A[ATraining Step: 207  | total loss: [1m[32m0.69488[0m[0m | time: 20.524s
[2K
| RMSProp | epoch: 005 | loss: 0.69488 - acc: 0.5029 -- iter: 0608/1483
[A[ATraining Step: 208  | total loss: [1m[32m0.69455[0m[0m | time: 21.498s
[2K
| RMSProp | epoch: 005 | loss: 0.69455 - acc: 0.5089 -- iter: 0640/1483
[A[ATraining Step: 209  | total loss: [1m[32m0.69459[0m[0m | time: 22.719s
[2K
| RMSProp | epoch: 005 | loss: 0.69459 - acc: 0.5017 -- iter: 0672/1483
[A[ATraining Step: 210  | total loss: [1m[32m0.69458[0m[0m | time: 23.749s
[2K
| RMSProp | epoch: 005 | loss: 0.69458 - acc: 0.4953 -- iter: 0704/1483
[A[ATraining Step: 211  | total loss: [1m[32m0.69439[0m[0m | time: 24.691s
[2K
| RMSProp | epoch: 005 | loss: 0.69439 - acc: 0.4989 -- iter: 0736/1483
[A[ATraining Step: 212  | total loss: [1m[32m0.69433[0m[0m | time: 25.765s
[2K
| RMSProp | epoch: 005 | loss: 0.69433 - acc: 0.4928 -- iter: 0768/1483
[A[ATraining Step: 213  | total loss: [1m[32m0.69405[0m[0m | time: 26.984s
[2K
| RMSProp | epoch: 005 | loss: 0.69405 - acc: 0.5029 -- iter: 0800/1483
[A[ATraining Step: 214  | total loss: [1m[32m0.69384[0m[0m | time: 28.232s
[2K
| RMSProp | epoch: 005 | loss: 0.69384 - acc: 0.5057 -- iter: 0832/1483
[A[ATraining Step: 215  | total loss: [1m[32m0.69411[0m[0m | time: 29.121s
[2K
| RMSProp | epoch: 005 | loss: 0.69411 - acc: 0.4958 -- iter: 0864/1483
[A[ATraining Step: 216  | total loss: [1m[32m0.69394[0m[0m | time: 30.095s
[2K
| RMSProp | epoch: 005 | loss: 0.69394 - acc: 0.4993 -- iter: 0896/1483
[A[ATraining Step: 217  | total loss: [1m[32m0.69360[0m[0m | time: 31.153s
[2K
| RMSProp | epoch: 005 | loss: 0.69360 - acc: 0.5087 -- iter: 0928/1483
[A[ATraining Step: 218  | total loss: [1m[32m0.69360[0m[0m | time: 32.166s
[2K
| RMSProp | epoch: 005 | loss: 0.69360 - acc: 0.5079 -- iter: 0960/1483
[A[ATraining Step: 219  | total loss: [1m[32m0.69328[0m[0m | time: 33.287s
[2K
| RMSProp | epoch: 005 | loss: 0.69328 - acc: 0.5165 -- iter: 0992/1483
[A[ATraining Step: 220  | total loss: [1m[32m0.69406[0m[0m | time: 34.329s
[2K
| RMSProp | epoch: 005 | loss: 0.69406 - acc: 0.4992 -- iter: 1024/1483
[A[ATraining Step: 221  | total loss: [1m[32m0.69382[0m[0m | time: 35.153s
[2K
| RMSProp | epoch: 005 | loss: 0.69382 - acc: 0.5086 -- iter: 1056/1483
[A[ATraining Step: 222  | total loss: [1m[32m0.69371[0m[0m | time: 36.204s
[2K
| RMSProp | epoch: 005 | loss: 0.69371 - acc: 0.5078 -- iter: 1088/1483
[A[ATraining Step: 223  | total loss: [1m[32m0.69391[0m[0m | time: 37.427s
[2K
| RMSProp | epoch: 005 | loss: 0.69391 - acc: 0.4976 -- iter: 1120/1483
[A[ATraining Step: 224  | total loss: [1m[32m0.69377[0m[0m | time: 38.757s
[2K
| RMSProp | epoch: 005 | loss: 0.69377 - acc: 0.4979 -- iter: 1152/1483
[A[ATraining Step: 225  | total loss: [1m[32m0.69363[0m[0m | time: 39.761s
[2K
| RMSProp | epoch: 005 | loss: 0.69363 - acc: 0.4950 -- iter: 1184/1483
[A[ATraining Step: 226  | total loss: [1m[32m0.69344[0m[0m | time: 40.755s
[2K
| RMSProp | epoch: 005 | loss: 0.69344 - acc: 0.5017 -- iter: 1216/1483
[A[ATraining Step: 227  | total loss: [1m[32m0.69306[0m[0m | time: 41.737s
[2K
| RMSProp | epoch: 005 | loss: 0.69306 - acc: 0.5109 -- iter: 1248/1483
[A[ATraining Step: 228  | total loss: [1m[32m0.69017[0m[0m | time: 42.748s
[2K
| RMSProp | epoch: 005 | loss: 0.69017 - acc: 0.5254 -- iter: 1280/1483
[A[ATraining Step: 229  | total loss: [1m[32m0.72337[0m[0m | time: 43.821s
[2K
| RMSProp | epoch: 005 | loss: 0.72337 - acc: 0.5198 -- iter: 1312/1483
[A[ATraining Step: 230  | total loss: [1m[32m0.71973[0m[0m | time: 44.901s
[2K
| RMSProp | epoch: 005 | loss: 0.71973 - acc: 0.5459 -- iter: 1344/1483
[A[ATraining Step: 231  | total loss: [1m[32m0.71725[0m[0m | time: 45.751s
[2K
| RMSProp | epoch: 005 | loss: 0.71725 - acc: 0.5320 -- iter: 1376/1483
[A[ATraining Step: 232  | total loss: [1m[32m0.71424[0m[0m | time: 46.876s
[2K
| RMSProp | epoch: 005 | loss: 0.71424 - acc: 0.5381 -- iter: 1408/1483
[A[ATraining Step: 233  | total loss: [1m[32m0.71310[0m[0m | time: 48.204s
[2K
| RMSProp | epoch: 005 | loss: 0.71310 - acc: 0.5124 -- iter: 1440/1483
[A[ATraining Step: 234  | total loss: [1m[32m0.70997[0m[0m | time: 49.563s
[2K
| RMSProp | epoch: 005 | loss: 0.70997 - acc: 0.5331 -- iter: 1472/1483
[A[ATraining Step: 235  | total loss: [1m[32m0.70797[0m[0m | time: 52.890s
[2K
| RMSProp | epoch: 005 | loss: 0.70797 - acc: 0.5266 | val_loss: 0.67354 - val_acc: 0.7241 -- iter: 1483/1483
--
Training Step: 236  | total loss: [1m[32m0.70516[0m[0m | time: 1.059s
[2K
| RMSProp | epoch: 006 | loss: 0.70516 - acc: 0.5396 -- iter: 0032/1483
[A[ATraining Step: 237  | total loss: [1m[32m0.70063[0m[0m | time: 2.179s
[2K
| RMSProp | epoch: 006 | loss: 0.70063 - acc: 0.5794 -- iter: 0064/1483
[A[ATraining Step: 238  | total loss: [1m[32m0.69791[0m[0m | time: 3.144s
[2K
| RMSProp | epoch: 006 | loss: 0.69791 - acc: 0.5808 -- iter: 0096/1483
[A[ATraining Step: 239  | total loss: [1m[32m0.69564[0m[0m | time: 3.483s
[2K
| RMSProp | epoch: 006 | loss: 0.69564 - acc: 0.5852 -- iter: 0128/1483
[A[ATraining Step: 240  | total loss: [1m[32m0.69348[0m[0m | time: 3.929s
[2K
| RMSProp | epoch: 006 | loss: 0.69348 - acc: 0.5904 -- iter: 0160/1483
[A[ATraining Step: 241  | total loss: [1m[32m0.68831[0m[0m | time: 5.063s
[2K
| RMSProp | epoch: 006 | loss: 0.68831 - acc: 0.5950 -- iter: 0192/1483
[A[ATraining Step: 242  | total loss: [1m[32m0.68452[0m[0m | time: 6.361s
[2K
| RMSProp | epoch: 006 | loss: 0.68452 - acc: 0.5948 -- iter: 0224/1483
[A[ATraining Step: 243  | total loss: [1m[32m0.67806[0m[0m | time: 7.663s
[2K
| RMSProp | epoch: 006 | loss: 0.67806 - acc: 0.6135 -- iter: 0256/1483
[A[ATraining Step: 244  | total loss: [1m[32m0.68722[0m[0m | time: 8.531s
[2K
| RMSProp | epoch: 006 | loss: 0.68722 - acc: 0.6115 -- iter: 0288/1483
[A[ATraining Step: 245  | total loss: [1m[32m0.68492[0m[0m | time: 9.568s
[2K
| RMSProp | epoch: 006 | loss: 0.68492 - acc: 0.6160 -- iter: 0320/1483
[A[ATraining Step: 246  | total loss: [1m[32m0.68223[0m[0m | time: 10.620s
[2K
| RMSProp | epoch: 006 | loss: 0.68223 - acc: 0.6263 -- iter: 0352/1483
[A[ATraining Step: 247  | total loss: [1m[32m0.68072[0m[0m | time: 11.549s
[2K
| RMSProp | epoch: 006 | loss: 0.68072 - acc: 0.6261 -- iter: 0384/1483
[A[ATraining Step: 248  | total loss: [1m[32m0.67785[0m[0m | time: 12.635s
[2K
| RMSProp | epoch: 006 | loss: 0.67785 - acc: 0.6260 -- iter: 0416/1483
[A[ATraining Step: 249  | total loss: [1m[32m0.67587[0m[0m | time: 13.646s
[2K
| RMSProp | epoch: 006 | loss: 0.67587 - acc: 0.6290 -- iter: 0448/1483
[A[ATraining Step: 250  | total loss: [1m[32m0.66919[0m[0m | time: 14.561s
[2K
| RMSProp | epoch: 006 | loss: 0.66919 - acc: 0.6380 -- iter: 0480/1483
[A[ATraining Step: 251  | total loss: [1m[32m0.68168[0m[0m | time: 15.783s
[2K
| RMSProp | epoch: 006 | loss: 0.68168 - acc: 0.6273 -- iter: 0512/1483
[A[ATraining Step: 252  | total loss: [1m[32m0.67905[0m[0m | time: 17.128s
[2K
| RMSProp | epoch: 006 | loss: 0.67905 - acc: 0.6334 -- iter: 0544/1483
[A[ATraining Step: 253  | total loss: [1m[32m0.67590[0m[0m | time: 18.366s
[2K
| RMSProp | epoch: 006 | loss: 0.67590 - acc: 0.6388 -- iter: 0576/1483
[A[ATraining Step: 254  | total loss: [1m[32m0.67144[0m[0m | time: 19.265s
[2K
| RMSProp | epoch: 006 | loss: 0.67144 - acc: 0.6436 -- iter: 0608/1483
[A[ATraining Step: 255  | total loss: [1m[32m0.67179[0m[0m | time: 20.223s
[2K
| RMSProp | epoch: 006 | loss: 0.67179 - acc: 0.6355 -- iter: 0640/1483
[A[ATraining Step: 256  | total loss: [1m[32m0.66297[0m[0m | time: 21.208s
[2K
| RMSProp | epoch: 006 | loss: 0.66297 - acc: 0.6532 -- iter: 0672/1483
[A[ATraining Step: 257  | total loss: [1m[32m0.66855[0m[0m | time: 22.178s
[2K
| RMSProp | epoch: 006 | loss: 0.66855 - acc: 0.6379 -- iter: 0704/1483
[A[ATraining Step: 258  | total loss: [1m[32m0.67365[0m[0m | time: 23.285s
[2K
| RMSProp | epoch: 006 | loss: 0.67365 - acc: 0.6241 -- iter: 0736/1483
[A[ATraining Step: 259  | total loss: [1m[32m0.67057[0m[0m | time: 24.335s
[2K
| RMSProp | epoch: 006 | loss: 0.67057 - acc: 0.6336 -- iter: 0768/1483
[A[ATraining Step: 260  | total loss: [1m[32m0.66652[0m[0m | time: 25.166s
[2K
| RMSProp | epoch: 006 | loss: 0.66652 - acc: 0.6327 -- iter: 0800/1483
[A[ATraining Step: 261  | total loss: [1m[32m0.65738[0m[0m | time: 26.261s
[2K
| RMSProp | epoch: 006 | loss: 0.65738 - acc: 0.6538 -- iter: 0832/1483
[A[ATraining Step: 262  | total loss: [1m[32m0.65737[0m[0m | time: 27.622s
[2K
| RMSProp | epoch: 006 | loss: 0.65737 - acc: 0.6509 -- iter: 0864/1483
[A[ATraining Step: 263  | total loss: [1m[32m0.66339[0m[0m | time: 28.968s
[2K
| RMSProp | epoch: 006 | loss: 0.66339 - acc: 0.6390 -- iter: 0896/1483
[A[ATraining Step: 264  | total loss: [1m[32m0.66842[0m[0m | time: 29.870s
[2K
| RMSProp | epoch: 006 | loss: 0.66842 - acc: 0.6157 -- iter: 0928/1483
[A[ATraining Step: 265  | total loss: [1m[32m0.66501[0m[0m | time: 30.896s
[2K
| RMSProp | epoch: 006 | loss: 0.66501 - acc: 0.6291 -- iter: 0960/1483
[A[ATraining Step: 266  | total loss: [1m[32m0.66119[0m[0m | time: 32.005s
[2K
| RMSProp | epoch: 006 | loss: 0.66119 - acc: 0.6318 -- iter: 0992/1483
[A[ATraining Step: 267  | total loss: [1m[32m0.65389[0m[0m | time: 32.960s
[2K
| RMSProp | epoch: 006 | loss: 0.65389 - acc: 0.6437 -- iter: 1024/1483
[A[ATraining Step: 268  | total loss: [1m[32m0.64627[0m[0m | time: 34.068s
[2K
| RMSProp | epoch: 006 | loss: 0.64627 - acc: 0.6480 -- iter: 1056/1483
[A[ATraining Step: 269  | total loss: [1m[32m0.64570[0m[0m | time: 35.122s
[2K
| RMSProp | epoch: 006 | loss: 0.64570 - acc: 0.6457 -- iter: 1088/1483
[A[ATraining Step: 270  | total loss: [1m[32m0.63715[0m[0m | time: 35.948s
[2K
| RMSProp | epoch: 006 | loss: 0.63715 - acc: 0.6562 -- iter: 1120/1483
[A[ATraining Step: 271  | total loss: [1m[32m0.65034[0m[0m | time: 37.139s
[2K
| RMSProp | epoch: 006 | loss: 0.65034 - acc: 0.6405 -- iter: 1152/1483
[A[ATraining Step: 272  | total loss: [1m[32m0.64788[0m[0m | time: 38.524s
[2K
| RMSProp | epoch: 006 | loss: 0.64788 - acc: 0.6390 -- iter: 1184/1483
[A[ATraining Step: 273  | total loss: [1m[32m0.64647[0m[0m | time: 39.933s
[2K
| RMSProp | epoch: 006 | loss: 0.64647 - acc: 0.6407 -- iter: 1216/1483
[A[ATraining Step: 274  | total loss: [1m[32m0.63861[0m[0m | time: 40.801s
[2K
| RMSProp | epoch: 006 | loss: 0.63861 - acc: 0.6454 -- iter: 1248/1483
[A[ATraining Step: 275  | total loss: [1m[32m0.62592[0m[0m | time: 41.825s
[2K
| RMSProp | epoch: 006 | loss: 0.62592 - acc: 0.6590 -- iter: 1280/1483
[A[ATraining Step: 276  | total loss: [1m[32m0.61566[0m[0m | time: 42.796s
[2K
| RMSProp | epoch: 006 | loss: 0.61566 - acc: 0.6681 -- iter: 1312/1483
[A[ATraining Step: 277  | total loss: [1m[32m0.61731[0m[0m | time: 43.844s
[2K
| RMSProp | epoch: 006 | loss: 0.61731 - acc: 0.6732 -- iter: 1344/1483
[A[ATraining Step: 278  | total loss: [1m[32m0.61073[0m[0m | time: 44.964s
[2K
| RMSProp | epoch: 006 | loss: 0.61073 - acc: 0.6840 -- iter: 1376/1483
[A[ATraining Step: 279  | total loss: [1m[32m0.60439[0m[0m | time: 46.062s
[2K
| RMSProp | epoch: 006 | loss: 0.60439 - acc: 0.6874 -- iter: 1408/1483
[A[ATraining Step: 280  | total loss: [1m[32m0.58724[0m[0m | time: 46.885s
[2K
| RMSProp | epoch: 006 | loss: 0.58724 - acc: 0.6999 -- iter: 1440/1483
[A[ATraining Step: 281  | total loss: [1m[32m0.58902[0m[0m | time: 48.049s
[2K
| RMSProp | epoch: 006 | loss: 0.58902 - acc: 0.7081 -- iter: 1472/1483
[A[ATraining Step: 282  | total loss: [1m[32m0.56372[0m[0m | time: 52.089s
[2K
| RMSProp | epoch: 006 | loss: 0.56372 - acc: 0.7216 | val_loss: 0.60128 - val_acc: 0.7543 -- iter: 1483/1483
--
Training Step: 283  | total loss: [1m[32m0.59582[0m[0m | time: 1.043s
[2K
| RMSProp | epoch: 007 | loss: 0.59582 - acc: 0.7182 -- iter: 0032/1483
[A[ATraining Step: 284  | total loss: [1m[32m0.60119[0m[0m | time: 2.010s
[2K
| RMSProp | epoch: 007 | loss: 0.60119 - acc: 0.7058 -- iter: 0064/1483
[A[ATraining Step: 285  | total loss: [1m[32m0.59173[0m[0m | time: 3.150s
[2K
| RMSProp | epoch: 007 | loss: 0.59173 - acc: 0.7165 -- iter: 0096/1483
[A[ATraining Step: 286  | total loss: [1m[32m0.58222[0m[0m | time: 4.289s
[2K
| RMSProp | epoch: 007 | loss: 0.58222 - acc: 0.7261 -- iter: 0128/1483
[A[ATraining Step: 287  | total loss: [1m[32m0.58655[0m[0m | time: 4.625s
[2K
| RMSProp | epoch: 007 | loss: 0.58655 - acc: 0.7160 -- iter: 0160/1483
[A[ATraining Step: 288  | total loss: [1m[32m0.60647[0m[0m | time: 4.923s
[2K
| RMSProp | epoch: 007 | loss: 0.60647 - acc: 0.6989 -- iter: 0192/1483
[A[ATraining Step: 289  | total loss: [1m[32m0.60630[0m[0m | time: 6.118s
[2K
| RMSProp | epoch: 007 | loss: 0.60630 - acc: 0.6926 -- iter: 0224/1483
[A[ATraining Step: 290  | total loss: [1m[32m0.60133[0m[0m | time: 7.393s
[2K
| RMSProp | epoch: 007 | loss: 0.60133 - acc: 0.6953 -- iter: 0256/1483
[A[ATraining Step: 291  | total loss: [1m[32m0.59320[0m[0m | time: 8.727s
[2K
| RMSProp | epoch: 007 | loss: 0.59320 - acc: 0.7101 -- iter: 0288/1483
[A[ATraining Step: 292  | total loss: [1m[32m0.59978[0m[0m | time: 9.728s
[2K
| RMSProp | epoch: 007 | loss: 0.59978 - acc: 0.7110 -- iter: 0320/1483
[A[ATraining Step: 293  | total loss: [1m[32m0.59418[0m[0m | time: 10.699s
[2K
| RMSProp | epoch: 007 | loss: 0.59418 - acc: 0.7117 -- iter: 0352/1483
[A[ATraining Step: 294  | total loss: [1m[32m0.58201[0m[0m | time: 11.716s
[2K
| RMSProp | epoch: 007 | loss: 0.58201 - acc: 0.7156 -- iter: 0384/1483
[A[ATraining Step: 295  | total loss: [1m[32m0.58733[0m[0m | time: 12.697s
[2K
| RMSProp | epoch: 007 | loss: 0.58733 - acc: 0.7065 -- iter: 0416/1483
[A[ATraining Step: 296  | total loss: [1m[32m0.59766[0m[0m | time: 13.758s
[2K
| RMSProp | epoch: 007 | loss: 0.59766 - acc: 0.6952 -- iter: 0448/1483
[A[ATraining Step: 297  | total loss: [1m[32m0.59433[0m[0m | time: 14.884s
[2K
| RMSProp | epoch: 007 | loss: 0.59433 - acc: 0.7007 -- iter: 0480/1483
[A[ATraining Step: 298  | total loss: [1m[32m0.60100[0m[0m | time: 15.723s
[2K
| RMSProp | epoch: 007 | loss: 0.60100 - acc: 0.6931 -- iter: 0512/1483
[A[ATraining Step: 299  | total loss: [1m[32m0.60151[0m[0m | time: 16.926s
[2K
| RMSProp | epoch: 007 | loss: 0.60151 - acc: 0.6926 -- iter: 0544/1483
[A[ATraining Step: 300  | total loss: [1m[32m0.60099[0m[0m | time: 18.184s
[2K
| RMSProp | epoch: 007 | loss: 0.60099 - acc: 0.6921 -- iter: 0576/1483
[A[ATraining Step: 301  | total loss: [1m[32m0.61054[0m[0m | time: 19.550s
[2K
| RMSProp | epoch: 007 | loss: 0.61054 - acc: 0.6760 -- iter: 0608/1483
[A[ATraining Step: 302  | total loss: [1m[32m0.59467[0m[0m | time: 20.463s
[2K
| RMSProp | epoch: 007 | loss: 0.59467 - acc: 0.6928 -- iter: 0640/1483
[A[ATraining Step: 303  | total loss: [1m[32m0.61000[0m[0m | time: 21.464s
[2K
| RMSProp | epoch: 007 | loss: 0.61000 - acc: 0.6766 -- iter: 0672/1483
[A[ATraining Step: 304  | total loss: [1m[32m0.60605[0m[0m | time: 22.507s
[2K
| RMSProp | epoch: 007 | loss: 0.60605 - acc: 0.6840 -- iter: 0704/1483
[A[ATraining Step: 305  | total loss: [1m[32m0.59382[0m[0m | time: 23.459s
[2K
| RMSProp | epoch: 007 | loss: 0.59382 - acc: 0.6937 -- iter: 0736/1483
[A[ATraining Step: 306  | total loss: [1m[32m0.57743[0m[0m | time: 24.573s
[2K
| RMSProp | epoch: 007 | loss: 0.57743 - acc: 0.7087 -- iter: 0768/1483
[A[ATraining Step: 307  | total loss: [1m[32m0.58456[0m[0m | time: 25.662s
[2K
| RMSProp | epoch: 007 | loss: 0.58456 - acc: 0.7128 -- iter: 0800/1483
[A[ATraining Step: 308  | total loss: [1m[32m0.57034[0m[0m | time: 26.462s
[2K
| RMSProp | epoch: 007 | loss: 0.57034 - acc: 0.7259 -- iter: 0832/1483
[A[ATraining Step: 309  | total loss: [1m[32m0.56178[0m[0m | time: 27.658s
[2K
| RMSProp | epoch: 007 | loss: 0.56178 - acc: 0.7346 -- iter: 0864/1483
[A[ATraining Step: 310  | total loss: [1m[32m0.55407[0m[0m | time: 28.992s
[2K
| RMSProp | epoch: 007 | loss: 0.55407 - acc: 0.7424 -- iter: 0896/1483
[A[ATraining Step: 311  | total loss: [1m[32m0.54251[0m[0m | time: 30.346s
[2K
| RMSProp | epoch: 007 | loss: 0.54251 - acc: 0.7431 -- iter: 0928/1483
[A[ATraining Step: 312  | total loss: [1m[32m0.53271[0m[0m | time: 31.321s
[2K
| RMSProp | epoch: 007 | loss: 0.53271 - acc: 0.7501 -- iter: 0960/1483
[A[ATraining Step: 313  | total loss: [1m[32m0.54720[0m[0m | time: 32.322s
[2K
| RMSProp | epoch: 007 | loss: 0.54720 - acc: 0.7438 -- iter: 0992/1483
[A[ATraining Step: 314  | total loss: [1m[32m0.54311[0m[0m | time: 33.381s
[2K
| RMSProp | epoch: 007 | loss: 0.54311 - acc: 0.7444 -- iter: 1024/1483
[A[ATraining Step: 315  | total loss: [1m[32m0.54988[0m[0m | time: 34.394s
[2K
| RMSProp | epoch: 007 | loss: 0.54988 - acc: 0.7325 -- iter: 1056/1483
[A[ATraining Step: 316  | total loss: [1m[32m0.54735[0m[0m | time: 35.490s
[2K
| RMSProp | epoch: 007 | loss: 0.54735 - acc: 0.7374 -- iter: 1088/1483
[A[ATraining Step: 317  | total loss: [1m[32m0.55080[0m[0m | time: 36.565s
[2K
| RMSProp | epoch: 007 | loss: 0.55080 - acc: 0.7293 -- iter: 1120/1483
[A[ATraining Step: 318  | total loss: [1m[32m0.55456[0m[0m | time: 37.454s
[2K
| RMSProp | epoch: 007 | loss: 0.55456 - acc: 0.7282 -- iter: 1152/1483
[A[ATraining Step: 319  | total loss: [1m[32m0.55348[0m[0m | time: 38.655s
[2K
| RMSProp | epoch: 007 | loss: 0.55348 - acc: 0.7304 -- iter: 1184/1483
[A[ATraining Step: 320  | total loss: [1m[32m0.54359[0m[0m | time: 40.037s
[2K
| RMSProp | epoch: 007 | loss: 0.54359 - acc: 0.7386 -- iter: 1216/1483
[A[ATraining Step: 321  | total loss: [1m[32m0.52931[0m[0m | time: 41.533s
[2K
| RMSProp | epoch: 007 | loss: 0.52931 - acc: 0.7522 -- iter: 1248/1483
[A[ATraining Step: 322  | total loss: [1m[32m0.52740[0m[0m | time: 42.414s
[2K
| RMSProp | epoch: 007 | loss: 0.52740 - acc: 0.7520 -- iter: 1280/1483
[A[ATraining Step: 323  | total loss: [1m[32m0.52336[0m[0m | time: 43.446s
[2K
| RMSProp | epoch: 007 | loss: 0.52336 - acc: 0.7549 -- iter: 1312/1483
[A[ATraining Step: 324  | total loss: [1m[32m0.52253[0m[0m | time: 44.458s
[2K
| RMSProp | epoch: 007 | loss: 0.52253 - acc: 0.7513 -- iter: 1344/1483
[A[ATraining Step: 325  | total loss: [1m[32m0.53218[0m[0m | time: 45.472s
[2K
| RMSProp | epoch: 007 | loss: 0.53218 - acc: 0.7449 -- iter: 1376/1483
[A[ATraining Step: 326  | total loss: [1m[32m0.54619[0m[0m | time: 46.613s
[2K
| RMSProp | epoch: 007 | loss: 0.54619 - acc: 0.7267 -- iter: 1408/1483
[A[ATraining Step: 327  | total loss: [1m[32m0.54131[0m[0m | time: 47.671s
[2K
| RMSProp | epoch: 007 | loss: 0.54131 - acc: 0.7321 -- iter: 1440/1483
[A[ATraining Step: 328  | total loss: [1m[32m0.54199[0m[0m | time: 48.488s
[2K
| RMSProp | epoch: 007 | loss: 0.54199 - acc: 0.7308 -- iter: 1472/1483
[A[ATraining Step: 329  | total loss: [1m[32m0.53573[0m[0m | time: 52.762s
[2K
| RMSProp | epoch: 007 | loss: 0.53573 - acc: 0.7390 | val_loss: 0.41502 - val_acc: 0.8211 -- iter: 1483/1483
--
Training Step: 330  | total loss: [1m[32m0.52127[0m[0m | time: 0.991s
[2K
| RMSProp | epoch: 008 | loss: 0.52127 - acc: 0.7557 -- iter: 0032/1483
[A[ATraining Step: 331  | total loss: [1m[32m0.52293[0m[0m | time: 2.042s
[2K
| RMSProp | epoch: 008 | loss: 0.52293 - acc: 0.7489 -- iter: 0064/1483
[A[ATraining Step: 332  | total loss: [1m[32m0.52023[0m[0m | time: 3.047s
[2K
| RMSProp | epoch: 008 | loss: 0.52023 - acc: 0.7459 -- iter: 0096/1483
[A[ATraining Step: 333  | total loss: [1m[32m0.51253[0m[0m | time: 4.080s
[2K
| RMSProp | epoch: 008 | loss: 0.51253 - acc: 0.7525 -- iter: 0128/1483
[A[ATraining Step: 334  | total loss: [1m[32m0.49991[0m[0m | time: 5.274s
[2K
| RMSProp | epoch: 008 | loss: 0.49991 - acc: 0.7617 -- iter: 0160/1483
[A[ATraining Step: 335  | total loss: [1m[32m0.50027[0m[0m | time: 5.682s
[2K
| RMSProp | epoch: 008 | loss: 0.50027 - acc: 0.7636 -- iter: 0192/1483
[A[ATraining Step: 336  | total loss: [1m[32m0.47763[0m[0m | time: 6.053s
[2K
| RMSProp | epoch: 008 | loss: 0.47763 - acc: 0.7782 -- iter: 0224/1483
[A[ATraining Step: 337  | total loss: [1m[32m0.46671[0m[0m | time: 6.939s
[2K
| RMSProp | epoch: 008 | loss: 0.46671 - acc: 0.7731 -- iter: 0256/1483
[A[ATraining Step: 338  | total loss: [1m[32m0.56256[0m[0m | time: 8.171s
[2K
| RMSProp | epoch: 008 | loss: 0.56256 - acc: 0.7458 -- iter: 0288/1483
[A[ATraining Step: 339  | total loss: [1m[32m0.55793[0m[0m | time: 9.487s
[2K
| RMSProp | epoch: 008 | loss: 0.55793 - acc: 0.7462 -- iter: 0320/1483
[A[ATraining Step: 340  | total loss: [1m[32m0.53729[0m[0m | time: 10.745s
[2K
| RMSProp | epoch: 008 | loss: 0.53729 - acc: 0.7653 -- iter: 0352/1483
[A[ATraining Step: 341  | total loss: [1m[32m0.51242[0m[0m | time: 11.653s
[2K
| RMSProp | epoch: 008 | loss: 0.51242 - acc: 0.7794 -- iter: 0384/1483
[A[ATraining Step: 342  | total loss: [1m[32m0.48888[0m[0m | time: 12.605s
[2K
| RMSProp | epoch: 008 | loss: 0.48888 - acc: 0.7952 -- iter: 0416/1483
[A[ATraining Step: 343  | total loss: [1m[32m0.48295[0m[0m | time: 13.600s
[2K
| RMSProp | epoch: 008 | loss: 0.48295 - acc: 0.7969 -- iter: 0448/1483
[A[ATraining Step: 344  | total loss: [1m[32m0.52421[0m[0m | time: 14.546s
[2K
| RMSProp | epoch: 008 | loss: 0.52421 - acc: 0.7798 -- iter: 0480/1483
[A[ATraining Step: 345  | total loss: [1m[32m0.51698[0m[0m | time: 15.681s
[2K
| RMSProp | epoch: 008 | loss: 0.51698 - acc: 0.7862 -- iter: 0512/1483
[A[ATraining Step: 346  | total loss: [1m[32m0.52011[0m[0m | time: 16.829s
[2K
| RMSProp | epoch: 008 | loss: 0.52011 - acc: 0.7763 -- iter: 0544/1483
[A[ATraining Step: 347  | total loss: [1m[32m0.52185[0m[0m | time: 17.654s
[2K
| RMSProp | epoch: 008 | loss: 0.52185 - acc: 0.7737 -- iter: 0576/1483
[A[ATraining Step: 348  | total loss: [1m[32m0.50469[0m[0m | time: 18.765s
[2K
| RMSProp | epoch: 008 | loss: 0.50469 - acc: 0.7900 -- iter: 0608/1483
[A[ATraining Step: 349  | total loss: [1m[32m0.50041[0m[0m | time: 20.059s
[2K
| RMSProp | epoch: 008 | loss: 0.50041 - acc: 0.7829 -- iter: 0640/1483
[A[ATraining Step: 350  | total loss: [1m[32m0.53189[0m[0m | time: 21.401s
[2K
| RMSProp | epoch: 008 | loss: 0.53189 - acc: 0.7577 -- iter: 0672/1483
[A[ATraining Step: 351  | total loss: [1m[32m0.52782[0m[0m | time: 22.372s
[2K
| RMSProp | epoch: 008 | loss: 0.52782 - acc: 0.7632 -- iter: 0704/1483
[A[ATraining Step: 352  | total loss: [1m[32m0.52923[0m[0m | time: 23.288s
[2K
| RMSProp | epoch: 008 | loss: 0.52923 - acc: 0.7588 -- iter: 0736/1483
[A[ATraining Step: 353  | total loss: [1m[32m0.52376[0m[0m | time: 24.359s
[2K
| RMSProp | epoch: 008 | loss: 0.52376 - acc: 0.7610 -- iter: 0768/1483
[A[ATraining Step: 354  | total loss: [1m[32m0.51485[0m[0m | time: 25.373s
[2K
| RMSProp | epoch: 008 | loss: 0.51485 - acc: 0.7693 -- iter: 0800/1483
[A[ATraining Step: 355  | total loss: [1m[32m0.50757[0m[0m | time: 26.368s
[2K
| RMSProp | epoch: 008 | loss: 0.50757 - acc: 0.7767 -- iter: 0832/1483
[A[ATraining Step: 356  | total loss: [1m[32m0.49462[0m[0m | time: 27.489s
[2K
| RMSProp | epoch: 008 | loss: 0.49462 - acc: 0.7834 -- iter: 0864/1483
[A[ATraining Step: 357  | total loss: [1m[32m0.48210[0m[0m | time: 28.338s
[2K
| RMSProp | epoch: 008 | loss: 0.48210 - acc: 0.7895 -- iter: 0896/1483
[A[ATraining Step: 358  | total loss: [1m[32m0.48451[0m[0m | time: 29.331s
[2K
| RMSProp | epoch: 008 | loss: 0.48451 - acc: 0.7887 -- iter: 0928/1483
[A[ATraining Step: 359  | total loss: [1m[32m0.47823[0m[0m | time: 30.676s
[2K
| RMSProp | epoch: 008 | loss: 0.47823 - acc: 0.7910 -- iter: 0960/1483
[A[ATraining Step: 360  | total loss: [1m[32m0.46675[0m[0m | time: 32.051s
[2K
| RMSProp | epoch: 008 | loss: 0.46675 - acc: 0.7994 -- iter: 0992/1483
[A[ATraining Step: 361  | total loss: [1m[32m0.45604[0m[0m | time: 33.089s
[2K
| RMSProp | epoch: 008 | loss: 0.45604 - acc: 0.8039 -- iter: 1024/1483
[A[ATraining Step: 362  | total loss: [1m[32m0.47145[0m[0m | time: 34.026s
[2K
| RMSProp | epoch: 008 | loss: 0.47145 - acc: 0.7954 -- iter: 1056/1483
[A[ATraining Step: 363  | total loss: [1m[32m0.46979[0m[0m | time: 35.195s
[2K
| RMSProp | epoch: 008 | loss: 0.46979 - acc: 0.8002 -- iter: 1088/1483
[A[ATraining Step: 364  | total loss: [1m[32m0.46498[0m[0m | time: 36.166s
[2K
| RMSProp | epoch: 008 | loss: 0.46498 - acc: 0.8014 -- iter: 1120/1483
[A[ATraining Step: 365  | total loss: [1m[32m0.45562[0m[0m | time: 37.261s
[2K
| RMSProp | epoch: 008 | loss: 0.45562 - acc: 0.8057 -- iter: 1152/1483
[A[ATraining Step: 366  | total loss: [1m[32m0.45711[0m[0m | time: 38.335s
[2K
| RMSProp | epoch: 008 | loss: 0.45711 - acc: 0.8032 -- iter: 1184/1483
[A[ATraining Step: 367  | total loss: [1m[32m0.44980[0m[0m | time: 39.234s
[2K
| RMSProp | epoch: 008 | loss: 0.44980 - acc: 0.8073 -- iter: 1216/1483
[A[ATraining Step: 368  | total loss: [1m[32m0.44751[0m[0m | time: 40.298s
[2K
| RMSProp | epoch: 008 | loss: 0.44751 - acc: 0.8078 -- iter: 1248/1483
[A[ATraining Step: 369  | total loss: [1m[32m0.45650[0m[0m | time: 41.669s
[2K
| RMSProp | epoch: 008 | loss: 0.45650 - acc: 0.7958 -- iter: 1280/1483
[A[ATraining Step: 370  | total loss: [1m[32m0.44711[0m[0m | time: 42.988s
[2K
| RMSProp | epoch: 008 | loss: 0.44711 - acc: 0.8068 -- iter: 1312/1483
[A[ATraining Step: 371  | total loss: [1m[32m0.44801[0m[0m | time: 44.003s
[2K
| RMSProp | epoch: 008 | loss: 0.44801 - acc: 0.8043 -- iter: 1344/1483
[A[ATraining Step: 372  | total loss: [1m[32m0.45460[0m[0m | time: 44.953s
[2K
| RMSProp | epoch: 008 | loss: 0.45460 - acc: 0.8020 -- iter: 1376/1483
[A[ATraining Step: 373  | total loss: [1m[32m0.45053[0m[0m | time: 46.015s
[2K
| RMSProp | epoch: 008 | loss: 0.45053 - acc: 0.8093 -- iter: 1408/1483
[A[ATraining Step: 374  | total loss: [1m[32m0.43930[0m[0m | time: 46.984s
[2K
| RMSProp | epoch: 008 | loss: 0.43930 - acc: 0.8065 -- iter: 1440/1483
[A[ATraining Step: 375  | total loss: [1m[32m0.42879[0m[0m | time: 48.060s
[2K
| RMSProp | epoch: 008 | loss: 0.42879 - acc: 0.8102 -- iter: 1472/1483
[A[ATraining Step: 376  | total loss: [1m[32m0.43507[0m[0m | time: 51.449s
[2K
| RMSProp | epoch: 008 | loss: 0.43507 - acc: 0.8010 | val_loss: 0.47123 - val_acc: 0.7909 -- iter: 1483/1483
--
Training Step: 377  | total loss: [1m[32m0.42461[0m[0m | time: 1.439s
[2K
| RMSProp | epoch: 009 | loss: 0.42461 - acc: 0.8084 -- iter: 0032/1483
[A[ATraining Step: 378  | total loss: [1m[32m0.43612[0m[0m | time: 2.748s
[2K
| RMSProp | epoch: 009 | loss: 0.43612 - acc: 0.8120 -- iter: 0064/1483
[A[ATraining Step: 379  | total loss: [1m[32m0.42249[0m[0m | time: 3.680s
[2K
| RMSProp | epoch: 009 | loss: 0.42249 - acc: 0.8214 -- iter: 0096/1483
[A[ATraining Step: 380  | total loss: [1m[32m0.40995[0m[0m | time: 4.671s
[2K
| RMSProp | epoch: 009 | loss: 0.40995 - acc: 0.8330 -- iter: 0128/1483
[A[ATraining Step: 381  | total loss: [1m[32m0.41929[0m[0m | time: 5.675s
[2K
| RMSProp | epoch: 009 | loss: 0.41929 - acc: 0.8247 -- iter: 0160/1483
[A[ATraining Step: 382  | total loss: [1m[32m0.42461[0m[0m | time: 6.664s
[2K
| RMSProp | epoch: 009 | loss: 0.42461 - acc: 0.8266 -- iter: 0192/1483
[A[ATraining Step: 383  | total loss: [1m[32m0.41704[0m[0m | time: 7.107s
[2K
| RMSProp | epoch: 009 | loss: 0.41704 - acc: 0.8315 -- iter: 0224/1483
[A[ATraining Step: 384  | total loss: [1m[32m0.44206[0m[0m | time: 7.579s
[2K
| RMSProp | epoch: 009 | loss: 0.44206 - acc: 0.8210 -- iter: 0256/1483
[A[ATraining Step: 385  | total loss: [1m[32m0.43055[0m[0m | time: 8.717s
[2K
| RMSProp | epoch: 009 | loss: 0.43055 - acc: 0.8298 -- iter: 0288/1483
[A[ATraining Step: 386  | total loss: [1m[32m0.44543[0m[0m | time: 9.563s
[2K
| RMSProp | epoch: 009 | loss: 0.44543 - acc: 0.8156 -- iter: 0320/1483
[A[ATraining Step: 387  | total loss: [1m[32m0.46759[0m[0m | time: 10.778s
[2K
| RMSProp | epoch: 009 | loss: 0.46759 - acc: 0.7903 -- iter: 0352/1483
[A[ATraining Step: 388  | total loss: [1m[32m0.45539[0m[0m | time: 12.049s
[2K
| RMSProp | epoch: 009 | loss: 0.45539 - acc: 0.8050 -- iter: 0384/1483
[A[ATraining Step: 389  | total loss: [1m[32m0.46448[0m[0m | time: 13.306s
[2K
| RMSProp | epoch: 009 | loss: 0.46448 - acc: 0.7995 -- iter: 0416/1483
[A[ATraining Step: 390  | total loss: [1m[32m0.44400[0m[0m | time: 14.334s
[2K
| RMSProp | epoch: 009 | loss: 0.44400 - acc: 0.8164 -- iter: 0448/1483
[A[ATraining Step: 391  | total loss: [1m[32m0.44255[0m[0m | time: 15.306s
[2K
| RMSProp | epoch: 009 | loss: 0.44255 - acc: 0.8160 -- iter: 0480/1483
[A[ATraining Step: 392  | total loss: [1m[32m0.45194[0m[0m | time: 16.309s
[2K
| RMSProp | epoch: 009 | loss: 0.45194 - acc: 0.8094 -- iter: 0512/1483
[A[ATraining Step: 393  | total loss: [1m[32m0.44497[0m[0m | time: 17.333s
[2K
| RMSProp | epoch: 009 | loss: 0.44497 - acc: 0.8066 -- iter: 0544/1483
[A[ATraining Step: 394  | total loss: [1m[32m0.44186[0m[0m | time: 18.421s
[2K
| RMSProp | epoch: 009 | loss: 0.44186 - acc: 0.8041 -- iter: 0576/1483
[A[ATraining Step: 395  | total loss: [1m[32m0.43496[0m[0m | time: 19.544s
[2K
| RMSProp | epoch: 009 | loss: 0.43496 - acc: 0.8112 -- iter: 0608/1483
[A[ATraining Step: 396  | total loss: [1m[32m0.43137[0m[0m | time: 20.321s
[2K
| RMSProp | epoch: 009 | loss: 0.43137 - acc: 0.8144 -- iter: 0640/1483
[A[ATraining Step: 397  | total loss: [1m[32m0.41975[0m[0m | time: 21.430s
[2K
| RMSProp | epoch: 009 | loss: 0.41975 - acc: 0.8236 -- iter: 0672/1483
[A[ATraining Step: 398  | total loss: [1m[32m0.39910[0m[0m | time: 22.837s
[2K
| RMSProp | epoch: 009 | loss: 0.39910 - acc: 0.8350 -- iter: 0704/1483
[A[ATraining Step: 399  | total loss: [1m[32m0.40170[0m[0m | time: 24.315s
[2K
| RMSProp | epoch: 009 | loss: 0.40170 - acc: 0.8359 -- iter: 0736/1483
[A[ATraining Step: 400  | total loss: [1m[32m0.41167[0m[0m | time: 27.762s
[2K
| RMSProp | epoch: 009 | loss: 0.41167 - acc: 0.8304 | val_loss: 0.34689 - val_acc: 0.8599 -- iter: 0768/1483
--
Training Step: 401  | total loss: [1m[32m0.41635[0m[0m | time: 28.860s
[2K
| RMSProp | epoch: 009 | loss: 0.41635 - acc: 0.8255 -- iter: 0800/1483
[A[ATraining Step: 402  | total loss: [1m[32m0.39546[0m[0m | time: 30.008s
[2K
| RMSProp | epoch: 009 | loss: 0.39546 - acc: 0.8367 -- iter: 0832/1483
[A[ATraining Step: 403  | total loss: [1m[32m0.38677[0m[0m | time: 30.915s
[2K
| RMSProp | epoch: 009 | loss: 0.38677 - acc: 0.8405 -- iter: 0864/1483
[A[ATraining Step: 404  | total loss: [1m[32m0.36647[0m[0m | time: 31.808s
[2K
| RMSProp | epoch: 009 | loss: 0.36647 - acc: 0.8502 -- iter: 0896/1483
[A[ATraining Step: 405  | total loss: [1m[32m0.38023[0m[0m | time: 33.207s
[2K
| RMSProp | epoch: 009 | loss: 0.38023 - acc: 0.8433 -- iter: 0928/1483
[A[ATraining Step: 406  | total loss: [1m[32m0.46374[0m[0m | time: 34.569s
[2K
| RMSProp | epoch: 009 | loss: 0.46374 - acc: 0.8246 -- iter: 0960/1483
[A[ATraining Step: 407  | total loss: [1m[32m0.45726[0m[0m | time: 35.634s
[2K
| RMSProp | epoch: 009 | loss: 0.45726 - acc: 0.8297 -- iter: 0992/1483
[A[ATraining Step: 408  | total loss: [1m[32m0.46891[0m[0m | time: 36.488s
[2K
| RMSProp | epoch: 009 | loss: 0.46891 - acc: 0.8217 -- iter: 1024/1483
[A[ATraining Step: 409  | total loss: [1m[32m0.46216[0m[0m | time: 37.483s
[2K
| RMSProp | epoch: 009 | loss: 0.46216 - acc: 0.8270 -- iter: 1056/1483
[A[ATraining Step: 410  | total loss: [1m[32m0.45000[0m[0m | time: 38.500s
[2K
| RMSProp | epoch: 009 | loss: 0.45000 - acc: 0.8318 -- iter: 1088/1483
[A[ATraining Step: 411  | total loss: [1m[32m0.43210[0m[0m | time: 39.450s
[2K
| RMSProp | epoch: 009 | loss: 0.43210 - acc: 0.8393 -- iter: 1120/1483
[A[ATraining Step: 412  | total loss: [1m[32m0.42871[0m[0m | time: 40.610s
[2K
| RMSProp | epoch: 009 | loss: 0.42871 - acc: 0.8397 -- iter: 1152/1483
[A[ATraining Step: 413  | total loss: [1m[32m0.39946[0m[0m | time: 41.674s
[2K
| RMSProp | epoch: 009 | loss: 0.39946 - acc: 0.8557 -- iter: 1184/1483
[A[ATraining Step: 414  | total loss: [1m[32m0.36853[0m[0m | time: 42.608s
[2K
| RMSProp | epoch: 009 | loss: 0.36853 - acc: 0.8670 -- iter: 1216/1483
[A[ATraining Step: 415  | total loss: [1m[32m0.37481[0m[0m | time: 43.991s
[2K
| RMSProp | epoch: 009 | loss: 0.37481 - acc: 0.8678 -- iter: 1248/1483
[A[ATraining Step: 416  | total loss: [1m[32m0.36687[0m[0m | time: 45.442s
[2K
| RMSProp | epoch: 009 | loss: 0.36687 - acc: 0.8717 -- iter: 1280/1483
[A[ATraining Step: 417  | total loss: [1m[32m0.34918[0m[0m | time: 46.625s
[2K
| RMSProp | epoch: 009 | loss: 0.34918 - acc: 0.8814 -- iter: 1312/1483
[A[ATraining Step: 418  | total loss: [1m[32m0.36458[0m[0m | time: 47.583s
[2K
| RMSProp | epoch: 009 | loss: 0.36458 - acc: 0.8776 -- iter: 1344/1483
[A[ATraining Step: 419  | total loss: [1m[32m0.38303[0m[0m | time: 48.565s
[2K
| RMSProp | epoch: 009 | loss: 0.38303 - acc: 0.8586 -- iter: 1376/1483
[A[ATraining Step: 420  | total loss: [1m[32m0.39736[0m[0m | time: 49.602s
[2K
| RMSProp | epoch: 009 | loss: 0.39736 - acc: 0.8415 -- iter: 1408/1483
[A[ATraining Step: 421  | total loss: [1m[32m0.38599[0m[0m | time: 50.642s
[2K
| RMSProp | epoch: 009 | loss: 0.38599 - acc: 0.8480 -- iter: 1440/1483
[A[ATraining Step: 422  | total loss: [1m[32m0.37791[0m[0m | time: 51.883s
[2K
| RMSProp | epoch: 009 | loss: 0.37791 - acc: 0.8507 -- iter: 1472/1483
[A[ATraining Step: 423  | total loss: [1m[32m0.38800[0m[0m | time: 55.491s
[2K
| RMSProp | epoch: 009 | loss: 0.38800 - acc: 0.8437 | val_loss: 0.35663 - val_acc: 0.8491 -- iter: 1483/1483
--
Training Step: 424  | total loss: [1m[32m0.37902[0m[0m | time: 1.278s
[2K
| RMSProp | epoch: 010 | loss: 0.37902 - acc: 0.8531 -- iter: 0032/1483
[A[ATraining Step: 425  | total loss: [1m[32m0.38960[0m[0m | time: 2.322s
[2K
| RMSProp | epoch: 010 | loss: 0.38960 - acc: 0.8459 -- iter: 0064/1483
[A[ATraining Step: 426  | total loss: [1m[32m0.38457[0m[0m | time: 3.264s
[2K
| RMSProp | epoch: 010 | loss: 0.38457 - acc: 0.8520 -- iter: 0096/1483
[A[ATraining Step: 427  | total loss: [1m[32m0.39451[0m[0m | time: 4.305s
[2K
| RMSProp | epoch: 010 | loss: 0.39451 - acc: 0.8480 -- iter: 0128/1483
[A[ATraining Step: 428  | total loss: [1m[32m0.38659[0m[0m | time: 5.384s
[2K
| RMSProp | epoch: 010 | loss: 0.38659 - acc: 0.8538 -- iter: 0160/1483
[A[ATraining Step: 429  | total loss: [1m[32m0.38785[0m[0m | time: 6.445s
[2K
| RMSProp | epoch: 010 | loss: 0.38785 - acc: 0.8497 -- iter: 0192/1483
[A[ATraining Step: 430  | total loss: [1m[32m0.37116[0m[0m | time: 7.608s
[2K
| RMSProp | epoch: 010 | loss: 0.37116 - acc: 0.8616 -- iter: 0224/1483
[A[ATraining Step: 431  | total loss: [1m[32m0.37159[0m[0m | time: 7.911s
[2K
| RMSProp | epoch: 010 | loss: 0.37159 - acc: 0.8598 -- iter: 0256/1483
[A[ATraining Step: 432  | total loss: [1m[32m0.38977[0m[0m | time: 8.205s
[2K
| RMSProp | epoch: 010 | loss: 0.38977 - acc: 0.8466 -- iter: 0288/1483
[A[ATraining Step: 433  | total loss: [1m[32m0.39829[0m[0m | time: 9.225s
[2K
| RMSProp | epoch: 010 | loss: 0.39829 - acc: 0.8346 -- iter: 0320/1483
[A[ATraining Step: 434  | total loss: [1m[32m0.38656[0m[0m | time: 10.549s
[2K
| RMSProp | epoch: 010 | loss: 0.38656 - acc: 0.8387 -- iter: 0352/1483
[A[ATraining Step: 435  | total loss: [1m[32m0.37737[0m[0m | time: 12.019s
[2K
| RMSProp | epoch: 010 | loss: 0.37737 - acc: 0.8454 -- iter: 0384/1483
[A[ATraining Step: 436  | total loss: [1m[32m0.36824[0m[0m | time: 13.097s
[2K
| RMSProp | epoch: 010 | loss: 0.36824 - acc: 0.8515 -- iter: 0416/1483
[A[ATraining Step: 437  | total loss: [1m[32m0.35716[0m[0m | time: 14.064s
[2K
| RMSProp | epoch: 010 | loss: 0.35716 - acc: 0.8570 -- iter: 0448/1483
[A[ATraining Step: 438  | total loss: [1m[32m0.36260[0m[0m | time: 15.051s
[2K
| RMSProp | epoch: 010 | loss: 0.36260 - acc: 0.8557 -- iter: 0480/1483
[A[ATraining Step: 439  | total loss: [1m[32m0.35747[0m[0m | time: 16.058s
[2K
| RMSProp | epoch: 010 | loss: 0.35747 - acc: 0.8576 -- iter: 0512/1483
[A[ATraining Step: 440  | total loss: [1m[32m0.34443[0m[0m | time: 17.110s
[2K
| RMSProp | epoch: 010 | loss: 0.34443 - acc: 0.8625 -- iter: 0544/1483
[A[ATraining Step: 441  | total loss: [1m[32m0.33669[0m[0m | time: 18.217s
[2K
| RMSProp | epoch: 010 | loss: 0.33669 - acc: 0.8668 -- iter: 0576/1483
[A[ATraining Step: 442  | total loss: [1m[32m0.35370[0m[0m | time: 19.154s
[2K
| RMSProp | epoch: 010 | loss: 0.35370 - acc: 0.8645 -- iter: 0608/1483
[A[ATraining Step: 443  | total loss: [1m[32m0.35331[0m[0m | time: 20.103s
[2K
| RMSProp | epoch: 010 | loss: 0.35331 - acc: 0.8593 -- iter: 0640/1483
[A[ATraining Step: 444  | total loss: [1m[32m0.35455[0m[0m | time: 21.501s
[2K
| RMSProp | epoch: 010 | loss: 0.35455 - acc: 0.8609 -- iter: 0672/1483
[A[ATraining Step: 445  | total loss: [1m[32m0.36168[0m[0m | time: 22.938s
[2K
| RMSProp | epoch: 010 | loss: 0.36168 - acc: 0.8529 -- iter: 0704/1483
[A[ATraining Step: 446  | total loss: [1m[32m0.34919[0m[0m | time: 23.976s
[2K
| RMSProp | epoch: 010 | loss: 0.34919 - acc: 0.8583 -- iter: 0736/1483
[A[ATraining Step: 447  | total loss: [1m[32m0.33000[0m[0m | time: 24.914s
[2K
| RMSProp | epoch: 010 | loss: 0.33000 - acc: 0.8693 -- iter: 0768/1483
[A[ATraining Step: 448  | total loss: [1m[32m0.31495[0m[0m | time: 25.902s
[2K
| RMSProp | epoch: 010 | loss: 0.31495 - acc: 0.8761 -- iter: 0800/1483
[A[ATraining Step: 449  | total loss: [1m[32m0.29998[0m[0m | time: 26.895s
[2K
| RMSProp | epoch: 010 | loss: 0.29998 - acc: 0.8823 -- iter: 0832/1483
[A[ATraining Step: 450  | total loss: [1m[32m0.29359[0m[0m | time: 27.870s
[2K
| RMSProp | epoch: 010 | loss: 0.29359 - acc: 0.8847 -- iter: 0864/1483
[A[ATraining Step: 451  | total loss: [1m[32m0.30660[0m[0m | time: 29.020s
[2K
| RMSProp | epoch: 010 | loss: 0.30660 - acc: 0.8806 -- iter: 0896/1483
[A[ATraining Step: 452  | total loss: [1m[32m0.30620[0m[0m | time: 30.017s
[2K
| RMSProp | epoch: 010 | loss: 0.30620 - acc: 0.8831 -- iter: 0928/1483
[A[ATraining Step: 453  | total loss: [1m[32m0.30139[0m[0m | time: 30.965s
[2K
| RMSProp | epoch: 010 | loss: 0.30139 - acc: 0.8886 -- iter: 0960/1483
[A[ATraining Step: 454  | total loss: [1m[32m0.31587[0m[0m | time: 32.473s
[2K
| RMSProp | epoch: 010 | loss: 0.31587 - acc: 0.8872 -- iter: 0992/1483
[A[ATraining Step: 455  | total loss: [1m[32m0.31029[0m[0m | time: 33.931s
[2K
| RMSProp | epoch: 010 | loss: 0.31029 - acc: 0.8891 -- iter: 1024/1483
[A[ATraining Step: 456  | total loss: [1m[32m0.29962[0m[0m | time: 34.967s
[2K
| RMSProp | epoch: 010 | loss: 0.29962 - acc: 0.8940 -- iter: 1056/1483
[A[ATraining Step: 457  | total loss: [1m[32m0.29123[0m[0m | time: 35.938s
[2K
| RMSProp | epoch: 010 | loss: 0.29123 - acc: 0.8983 -- iter: 1088/1483
[A[ATraining Step: 458  | total loss: [1m[32m0.28814[0m[0m | time: 37.003s
[2K
| RMSProp | epoch: 010 | loss: 0.28814 - acc: 0.9022 -- iter: 1120/1483
[A[ATraining Step: 459  | total loss: [1m[32m0.27798[0m[0m | time: 38.082s
[2K
| RMSProp | epoch: 010 | loss: 0.27798 - acc: 0.9089 -- iter: 1152/1483
[A[ATraining Step: 460  | total loss: [1m[32m0.26063[0m[0m | time: 39.142s
[2K
| RMSProp | epoch: 010 | loss: 0.26063 - acc: 0.9149 -- iter: 1184/1483
[A[ATraining Step: 461  | total loss: [1m[32m0.25768[0m[0m | time: 40.306s
[2K
| RMSProp | epoch: 010 | loss: 0.25768 - acc: 0.9109 -- iter: 1216/1483
[A[ATraining Step: 462  | total loss: [1m[32m0.26776[0m[0m | time: 41.167s
[2K
| RMSProp | epoch: 010 | loss: 0.26776 - acc: 0.9073 -- iter: 1248/1483
[A[ATraining Step: 463  | total loss: [1m[32m0.29510[0m[0m | time: 42.339s
[2K
| RMSProp | epoch: 010 | loss: 0.29510 - acc: 0.8916 -- iter: 1280/1483
[A[ATraining Step: 464  | total loss: [1m[32m0.32108[0m[0m | time: 43.666s
[2K
| RMSProp | epoch: 010 | loss: 0.32108 - acc: 0.8774 -- iter: 1312/1483
[A[ATraining Step: 465  | total loss: [1m[32m0.32247[0m[0m | time: 45.062s
[2K
| RMSProp | epoch: 010 | loss: 0.32247 - acc: 0.8772 -- iter: 1344/1483
[A[ATraining Step: 466  | total loss: [1m[32m0.34238[0m[0m | time: 45.973s
[2K
| RMSProp | epoch: 010 | loss: 0.34238 - acc: 0.8707 -- iter: 1376/1483
[A[ATraining Step: 467  | total loss: [1m[32m0.32674[0m[0m | time: 46.942s
[2K
| RMSProp | epoch: 010 | loss: 0.32674 - acc: 0.8805 -- iter: 1408/1483
[A[ATraining Step: 468  | total loss: [1m[32m0.31318[0m[0m | time: 47.988s
[2K
| RMSProp | epoch: 010 | loss: 0.31318 - acc: 0.8862 -- iter: 1440/1483
[A[ATraining Step: 469  | total loss: [1m[32m0.30775[0m[0m | time: 48.967s
[2K
| RMSProp | epoch: 010 | loss: 0.30775 - acc: 0.8851 -- iter: 1472/1483
[A[ATraining Step: 470  | total loss: [1m[32m0.32184[0m[0m | time: 52.390s
[2K
| RMSProp | epoch: 010 | loss: 0.32184 - acc: 0.8716 | val_loss: 0.32617 - val_acc: 0.8728 -- iter: 1483/1483
--
Training Step: 471  | total loss: [1m[32m0.32451[0m[0m | time: 1.317s
[2K
| RMSProp | epoch: 011 | loss: 0.32451 - acc: 0.8719 -- iter: 0032/1483
[A[ATraining Step: 472  | total loss: [1m[32m0.31105[0m[0m | time: 2.734s
[2K
| RMSProp | epoch: 011 | loss: 0.31105 - acc: 0.8816 -- iter: 0064/1483
[A[ATraining Step: 473  | total loss: [1m[32m0.29343[0m[0m | time: 3.969s
[2K
| RMSProp | epoch: 011 | loss: 0.29343 - acc: 0.8903 -- iter: 0096/1483
[A[ATraining Step: 474  | total loss: [1m[32m0.30106[0m[0m | time: 4.847s
[2K
| RMSProp | epoch: 011 | loss: 0.30106 - acc: 0.8857 -- iter: 0128/1483
[A[ATraining Step: 475  | total loss: [1m[32m0.29409[0m[0m | time: 5.902s
[2K
| RMSProp | epoch: 011 | loss: 0.29409 - acc: 0.8877 -- iter: 0160/1483
[A[ATraining Step: 476  | total loss: [1m[32m0.30681[0m[0m | time: 6.976s
[2K
| RMSProp | epoch: 011 | loss: 0.30681 - acc: 0.8833 -- iter: 0192/1483
[A[ATraining Step: 477  | total loss: [1m[32m0.29102[0m[0m | time: 7.997s
[2K
| RMSProp | epoch: 011 | loss: 0.29102 - acc: 0.8919 -- iter: 0224/1483
[A[ATraining Step: 478  | total loss: [1m[32m0.28986[0m[0m | time: 9.145s
[2K
| RMSProp | epoch: 011 | loss: 0.28986 - acc: 0.8902 -- iter: 0256/1483
[A[ATraining Step: 479  | total loss: [1m[32m0.30470[0m[0m | time: 9.539s
[2K
| RMSProp | epoch: 011 | loss: 0.30470 - acc: 0.8824 -- iter: 0288/1483
[A[ATraining Step: 480  | total loss: [1m[32m0.33101[0m[0m | time: 9.837s
[2K
| RMSProp | epoch: 011 | loss: 0.33101 - acc: 0.8669 -- iter: 0320/1483
[A[ATraining Step: 481  | total loss: [1m[32m0.32504[0m[0m | time: 10.717s
[2K
| RMSProp | epoch: 011 | loss: 0.32504 - acc: 0.8711 -- iter: 0352/1483
[A[ATraining Step: 482  | total loss: [1m[32m0.32893[0m[0m | time: 12.058s
[2K
| RMSProp | epoch: 011 | loss: 0.32893 - acc: 0.8621 -- iter: 0384/1483
[A[ATraining Step: 483  | total loss: [1m[32m0.33644[0m[0m | time: 13.400s
[2K
| RMSProp | epoch: 011 | loss: 0.33644 - acc: 0.8540 -- iter: 0416/1483
[A[ATraining Step: 484  | total loss: [1m[32m0.34291[0m[0m | time: 14.589s
[2K
| RMSProp | epoch: 011 | loss: 0.34291 - acc: 0.8530 -- iter: 0448/1483
[A[ATraining Step: 485  | total loss: [1m[32m0.33344[0m[0m | time: 15.552s
[2K
| RMSProp | epoch: 011 | loss: 0.33344 - acc: 0.8646 -- iter: 0480/1483
[A[ATraining Step: 486  | total loss: [1m[32m0.32779[0m[0m | time: 16.567s
[2K
| RMSProp | epoch: 011 | loss: 0.32779 - acc: 0.8688 -- iter: 0512/1483
[A[ATraining Step: 487  | total loss: [1m[32m0.31361[0m[0m | time: 17.588s
[2K
| RMSProp | epoch: 011 | loss: 0.31361 - acc: 0.8756 -- iter: 0544/1483
[A[ATraining Step: 488  | total loss: [1m[32m0.32536[0m[0m | time: 18.615s
[2K
| RMSProp | epoch: 011 | loss: 0.32536 - acc: 0.8724 -- iter: 0576/1483
[A[ATraining Step: 489  | total loss: [1m[32m0.30697[0m[0m | time: 19.812s
[2K
| RMSProp | epoch: 011 | loss: 0.30697 - acc: 0.8821 -- iter: 0608/1483
[A[ATraining Step: 490  | total loss: [1m[32m0.31199[0m[0m | time: 20.744s
[2K
| RMSProp | epoch: 011 | loss: 0.31199 - acc: 0.8845 -- iter: 0640/1483
[A[ATraining Step: 491  | total loss: [1m[32m0.33223[0m[0m | time: 21.668s
[2K
| RMSProp | epoch: 011 | loss: 0.33223 - acc: 0.8679 -- iter: 0672/1483
[A[ATraining Step: 492  | total loss: [1m[32m0.33447[0m[0m | time: 23.008s
[2K
| RMSProp | epoch: 011 | loss: 0.33447 - acc: 0.8717 -- iter: 0704/1483
[A[ATraining Step: 493  | total loss: [1m[32m0.31797[0m[0m | time: 24.552s
[2K
| RMSProp | epoch: 011 | loss: 0.31797 - acc: 0.8814 -- iter: 0736/1483
[A[ATraining Step: 494  | total loss: [1m[32m0.31484[0m[0m | time: 25.699s
[2K
| RMSProp | epoch: 011 | loss: 0.31484 - acc: 0.8839 -- iter: 0768/1483
[A[ATraining Step: 495  | total loss: [1m[32m0.30961[0m[0m | time: 26.643s
[2K
| RMSProp | epoch: 011 | loss: 0.30961 - acc: 0.8862 -- iter: 0800/1483
[A[ATraining Step: 496  | total loss: [1m[32m0.30406[0m[0m | time: 27.624s
[2K
| RMSProp | epoch: 011 | loss: 0.30406 - acc: 0.8882 -- iter: 0832/1483
[A[ATraining Step: 497  | total loss: [1m[32m0.28314[0m[0m | time: 28.617s
[2K
| RMSProp | epoch: 011 | loss: 0.28314 - acc: 0.8994 -- iter: 0864/1483
[A[ATraining Step: 498  | total loss: [1m[32m0.27469[0m[0m | time: 29.656s
[2K
| RMSProp | epoch: 011 | loss: 0.27469 - acc: 0.9032 -- iter: 0896/1483
[A[ATraining Step: 499  | total loss: [1m[32m0.25951[0m[0m | time: 30.769s
[2K
| RMSProp | epoch: 011 | loss: 0.25951 - acc: 0.9097 -- iter: 0928/1483
[A[ATraining Step: 500  | total loss: [1m[32m0.25202[0m[0m | time: 31.706s
[2K
| RMSProp | epoch: 011 | loss: 0.25202 - acc: 0.9125 -- iter: 0960/1483
[A[ATraining Step: 501  | total loss: [1m[32m0.22990[0m[0m | time: 32.786s
[2K
| RMSProp | epoch: 011 | loss: 0.22990 - acc: 0.9213 -- iter: 0992/1483
[A[ATraining Step: 502  | total loss: [1m[32m0.24357[0m[0m | time: 34.107s
[2K
| RMSProp | epoch: 011 | loss: 0.24357 - acc: 0.9166 -- iter: 1024/1483
[A[ATraining Step: 503  | total loss: [1m[32m0.24549[0m[0m | time: 35.512s
[2K
| RMSProp | epoch: 011 | loss: 0.24549 - acc: 0.9125 -- iter: 1056/1483
[A[ATraining Step: 504  | total loss: [1m[32m0.26698[0m[0m | time: 36.589s
[2K
| RMSProp | epoch: 011 | loss: 0.26698 - acc: 0.9025 -- iter: 1088/1483
[A[ATraining Step: 505  | total loss: [1m[32m0.26396[0m[0m | time: 37.495s
[2K
| RMSProp | epoch: 011 | loss: 0.26396 - acc: 0.9060 -- iter: 1120/1483
[A[ATraining Step: 506  | total loss: [1m[32m0.24650[0m[0m | time: 38.504s
[2K
| RMSProp | epoch: 011 | loss: 0.24650 - acc: 0.9122 -- iter: 1152/1483
[A[ATraining Step: 507  | total loss: [1m[32m0.23388[0m[0m | time: 39.519s
[2K
| RMSProp | epoch: 011 | loss: 0.23388 - acc: 0.9179 -- iter: 1184/1483
[A[ATraining Step: 508  | total loss: [1m[32m0.21734[0m[0m | time: 40.578s
[2K
| RMSProp | epoch: 011 | loss: 0.21734 - acc: 0.9230 -- iter: 1216/1483
[A[ATraining Step: 509  | total loss: [1m[32m0.21937[0m[0m | time: 41.723s
[2K
| RMSProp | epoch: 011 | loss: 0.21937 - acc: 0.9182 -- iter: 1248/1483
[A[ATraining Step: 510  | total loss: [1m[32m0.21155[0m[0m | time: 42.617s
[2K
| RMSProp | epoch: 011 | loss: 0.21155 - acc: 0.9232 -- iter: 1280/1483
[A[ATraining Step: 511  | total loss: [1m[32m0.20029[0m[0m | time: 43.682s
[2K
| RMSProp | epoch: 011 | loss: 0.20029 - acc: 0.9278 -- iter: 1312/1483
[A[ATraining Step: 512  | total loss: [1m[32m0.21752[0m[0m | time: 45.057s
[2K
| RMSProp | epoch: 011 | loss: 0.21752 - acc: 0.9194 -- iter: 1344/1483
[A[ATraining Step: 513  | total loss: [1m[32m0.24708[0m[0m | time: 46.386s
[2K
| RMSProp | epoch: 011 | loss: 0.24708 - acc: 0.9024 -- iter: 1376/1483
[A[ATraining Step: 514  | total loss: [1m[32m0.25749[0m[0m | time: 47.459s
[2K
| RMSProp | epoch: 011 | loss: 0.25749 - acc: 0.8935 -- iter: 1408/1483
[A[ATraining Step: 515  | total loss: [1m[32m0.24765[0m[0m | time: 48.403s
[2K
| RMSProp | epoch: 011 | loss: 0.24765 - acc: 0.8979 -- iter: 1440/1483
[A[ATraining Step: 516  | total loss: [1m[32m0.25487[0m[0m | time: 49.364s
[2K
| RMSProp | epoch: 011 | loss: 0.25487 - acc: 0.8956 -- iter: 1472/1483
[A[ATraining Step: 517  | total loss: [1m[32m0.26423[0m[0m | time: 52.857s
[2K
| RMSProp | epoch: 011 | loss: 0.26423 - acc: 0.8935 | val_loss: 0.31248 - val_acc: 0.8707 -- iter: 1483/1483
--
Training Step: 518  | total loss: [1m[32m0.25507[0m[0m | time: 0.879s
[2K
| RMSProp | epoch: 012 | loss: 0.25507 - acc: 0.8979 -- iter: 0032/1483
[A[ATraining Step: 519  | total loss: [1m[32m0.23888[0m[0m | time: 1.966s
[2K
| RMSProp | epoch: 012 | loss: 0.23888 - acc: 0.9050 -- iter: 0064/1483
[A[ATraining Step: 520  | total loss: [1m[32m0.23448[0m[0m | time: 3.487s
[2K
| RMSProp | epoch: 012 | loss: 0.23448 - acc: 0.9051 -- iter: 0096/1483
[A[ATraining Step: 521  | total loss: [1m[32m0.22628[0m[0m | time: 4.851s
[2K
| RMSProp | epoch: 012 | loss: 0.22628 - acc: 0.9115 -- iter: 0128/1483
[A[ATraining Step: 522  | total loss: [1m[32m0.22155[0m[0m | time: 5.893s
[2K
| RMSProp | epoch: 012 | loss: 0.22155 - acc: 0.9110 -- iter: 0160/1483
[A[ATraining Step: 523  | total loss: [1m[32m0.21028[0m[0m | time: 6.888s
[2K
| RMSProp | epoch: 012 | loss: 0.21028 - acc: 0.9136 -- iter: 0192/1483
[A[ATraining Step: 524  | total loss: [1m[32m0.20624[0m[0m | time: 7.878s
[2K
| RMSProp | epoch: 012 | loss: 0.20624 - acc: 0.9191 -- iter: 0224/1483
[A[ATraining Step: 525  | total loss: [1m[32m0.20131[0m[0m | time: 8.887s
[2K
| RMSProp | epoch: 012 | loss: 0.20131 - acc: 0.9210 -- iter: 0256/1483
[A[ATraining Step: 526  | total loss: [1m[32m0.21474[0m[0m | time: 9.928s
[2K
| RMSProp | epoch: 012 | loss: 0.21474 - acc: 0.9195 -- iter: 0288/1483
[A[ATraining Step: 527  | total loss: [1m[32m0.23158[0m[0m | time: 10.409s
[2K
| RMSProp | epoch: 012 | loss: 0.23158 - acc: 0.9150 -- iter: 0320/1483
[A[ATraining Step: 528  | total loss: [1m[32m0.22571[0m[0m | time: 10.841s
[2K
| RMSProp | epoch: 012 | loss: 0.22571 - acc: 0.9144 -- iter: 0352/1483
[A[ATraining Step: 529  | total loss: [1m[32m0.20659[0m[0m | time: 11.758s
[2K
| RMSProp | epoch: 012 | loss: 0.20659 - acc: 0.9230 -- iter: 0384/1483
[A[ATraining Step: 530  | total loss: [1m[32m0.19419[0m[0m | time: 12.838s
[2K
| RMSProp | epoch: 012 | loss: 0.19419 - acc: 0.9276 -- iter: 0416/1483
[A[ATraining Step: 531  | total loss: [1m[32m0.18060[0m[0m | time: 14.230s
[2K
| RMSProp | epoch: 012 | loss: 0.18060 - acc: 0.9317 -- iter: 0448/1483
[A[ATraining Step: 532  | total loss: [1m[32m0.18854[0m[0m | time: 15.598s
[2K
| RMSProp | epoch: 012 | loss: 0.18854 - acc: 0.9292 -- iter: 0480/1483
[A[ATraining Step: 533  | total loss: [1m[32m0.19945[0m[0m | time: 16.694s
[2K
| RMSProp | epoch: 012 | loss: 0.19945 - acc: 0.9269 -- iter: 0512/1483
[A[ATraining Step: 534  | total loss: [1m[32m0.20587[0m[0m | time: 17.736s
[2K
| RMSProp | epoch: 012 | loss: 0.20587 - acc: 0.9186 -- iter: 0544/1483
[A[ATraining Step: 535  | total loss: [1m[32m0.22020[0m[0m | time: 18.706s
[2K
| RMSProp | epoch: 012 | loss: 0.22020 - acc: 0.9079 -- iter: 0576/1483
[A[ATraining Step: 536  | total loss: [1m[32m0.21940[0m[0m | time: 19.704s
[2K
| RMSProp | epoch: 012 | loss: 0.21940 - acc: 0.9109 -- iter: 0608/1483
[A[ATraining Step: 537  | total loss: [1m[32m0.21908[0m[0m | time: 20.771s
[2K
| RMSProp | epoch: 012 | loss: 0.21908 - acc: 0.9136 -- iter: 0640/1483
[A[ATraining Step: 538  | total loss: [1m[32m0.21258[0m[0m | time: 21.798s
[2K
| RMSProp | epoch: 012 | loss: 0.21258 - acc: 0.9160 -- iter: 0672/1483
[A[ATraining Step: 539  | total loss: [1m[32m0.22321[0m[0m | time: 22.668s
[2K
| RMSProp | epoch: 012 | loss: 0.22321 - acc: 0.9119 -- iter: 0704/1483
[A[ATraining Step: 540  | total loss: [1m[32m0.23740[0m[0m | time: 23.682s
[2K
| RMSProp | epoch: 012 | loss: 0.23740 - acc: 0.9082 -- iter: 0736/1483
[A[ATraining Step: 541  | total loss: [1m[32m0.24201[0m[0m | time: 25.165s
[2K
| RMSProp | epoch: 012 | loss: 0.24201 - acc: 0.9080 -- iter: 0768/1483
[A[ATraining Step: 542  | total loss: [1m[32m0.24977[0m[0m | time: 26.573s
[2K
| RMSProp | epoch: 012 | loss: 0.24977 - acc: 0.9109 -- iter: 0800/1483
[A[ATraining Step: 543  | total loss: [1m[32m0.25603[0m[0m | time: 27.579s
[2K
| RMSProp | epoch: 012 | loss: 0.25603 - acc: 0.9042 -- iter: 0832/1483
[A[ATraining Step: 544  | total loss: [1m[32m0.23638[0m[0m | time: 28.535s
[2K
| RMSProp | epoch: 012 | loss: 0.23638 - acc: 0.9138 -- iter: 0864/1483
[A[ATraining Step: 545  | total loss: [1m[32m0.21815[0m[0m | time: 29.576s
[2K
| RMSProp | epoch: 012 | loss: 0.21815 - acc: 0.9224 -- iter: 0896/1483
[A[ATraining Step: 546  | total loss: [1m[32m0.23415[0m[0m | time: 30.578s
[2K
| RMSProp | epoch: 012 | loss: 0.23415 - acc: 0.9145 -- iter: 0928/1483
[A[ATraining Step: 547  | total loss: [1m[32m0.25319[0m[0m | time: 31.606s
[2K
| RMSProp | epoch: 012 | loss: 0.25319 - acc: 0.9043 -- iter: 0960/1483
[A[ATraining Step: 548  | total loss: [1m[32m0.25523[0m[0m | time: 32.739s
[2K
| RMSProp | epoch: 012 | loss: 0.25523 - acc: 0.9045 -- iter: 0992/1483
[A[ATraining Step: 549  | total loss: [1m[32m0.24314[0m[0m | time: 33.609s
[2K
| RMSProp | epoch: 012 | loss: 0.24314 - acc: 0.9110 -- iter: 1024/1483
[A[ATraining Step: 550  | total loss: [1m[32m0.22731[0m[0m | time: 34.747s
[2K
| RMSProp | epoch: 012 | loss: 0.22731 - acc: 0.9199 -- iter: 1056/1483
[A[ATraining Step: 551  | total loss: [1m[32m0.20887[0m[0m | time: 36.145s
[2K
| RMSProp | epoch: 012 | loss: 0.20887 - acc: 0.9247 -- iter: 1088/1483
[A[ATraining Step: 552  | total loss: [1m[32m0.21219[0m[0m | time: 37.479s
[2K
| RMSProp | epoch: 012 | loss: 0.21219 - acc: 0.9260 -- iter: 1120/1483
[A[ATraining Step: 553  | total loss: [1m[32m0.20366[0m[0m | time: 38.499s
[2K
| RMSProp | epoch: 012 | loss: 0.20366 - acc: 0.9303 -- iter: 1152/1483
[A[ATraining Step: 554  | total loss: [1m[32m0.19280[0m[0m | time: 39.407s
[2K
| RMSProp | epoch: 012 | loss: 0.19280 - acc: 0.9341 -- iter: 1184/1483
[A[ATraining Step: 555  | total loss: [1m[32m0.19123[0m[0m | time: 40.393s
[2K
| RMSProp | epoch: 012 | loss: 0.19123 - acc: 0.9376 -- iter: 1216/1483
[A[ATraining Step: 556  | total loss: [1m[32m0.18490[0m[0m | time: 41.405s
[2K
| RMSProp | epoch: 012 | loss: 0.18490 - acc: 0.9407 -- iter: 1248/1483
[A[ATraining Step: 557  | total loss: [1m[32m0.17560[0m[0m | time: 42.513s
[2K
| RMSProp | epoch: 012 | loss: 0.17560 - acc: 0.9404 -- iter: 1280/1483
[A[ATraining Step: 558  | total loss: [1m[32m0.18003[0m[0m | time: 43.645s
[2K
| RMSProp | epoch: 012 | loss: 0.18003 - acc: 0.9370 -- iter: 1312/1483
[A[ATraining Step: 559  | total loss: [1m[32m0.18294[0m[0m | time: 44.538s
[2K
| RMSProp | epoch: 012 | loss: 0.18294 - acc: 0.9339 -- iter: 1344/1483
[A[ATraining Step: 560  | total loss: [1m[32m0.17259[0m[0m | time: 45.575s
[2K
| RMSProp | epoch: 012 | loss: 0.17259 - acc: 0.9405 -- iter: 1376/1483
[A[ATraining Step: 561  | total loss: [1m[32m0.17840[0m[0m | time: 47.043s
[2K
| RMSProp | epoch: 012 | loss: 0.17840 - acc: 0.9371 -- iter: 1408/1483
[A[ATraining Step: 562  | total loss: [1m[32m0.18183[0m[0m | time: 48.394s
[2K
| RMSProp | epoch: 012 | loss: 0.18183 - acc: 0.9340 -- iter: 1440/1483
[A[ATraining Step: 563  | total loss: [1m[32m0.17593[0m[0m | time: 49.461s
[2K
| RMSProp | epoch: 012 | loss: 0.17593 - acc: 0.9375 -- iter: 1472/1483
[A[ATraining Step: 564  | total loss: [1m[32m0.18163[0m[0m | time: 52.829s
[2K
| RMSProp | epoch: 012 | loss: 0.18163 - acc: 0.9375 | val_loss: 0.30691 - val_acc: 0.8879 -- iter: 1483/1483
--
Training Step: 565  | total loss: [1m[32m0.17953[0m[0m | time: 1.130s
[2K
| RMSProp | epoch: 013 | loss: 0.17953 - acc: 0.9375 -- iter: 0032/1483
[A[ATraining Step: 566  | total loss: [1m[32m0.17052[0m[0m | time: 2.190s
[2K
| RMSProp | epoch: 013 | loss: 0.17052 - acc: 0.9375 -- iter: 0064/1483
[A[ATraining Step: 567  | total loss: [1m[32m0.16396[0m[0m | time: 3.069s
[2K
| RMSProp | epoch: 013 | loss: 0.16396 - acc: 0.9375 -- iter: 0096/1483
[A[ATraining Step: 568  | total loss: [1m[32m0.15628[0m[0m | time: 4.325s
[2K
| RMSProp | epoch: 013 | loss: 0.15628 - acc: 0.9406 -- iter: 0128/1483
[A[ATraining Step: 569  | total loss: [1m[32m0.14759[0m[0m | time: 5.710s
[2K
| RMSProp | epoch: 013 | loss: 0.14759 - acc: 0.9434 -- iter: 0160/1483
[A[ATraining Step: 570  | total loss: [1m[32m0.14675[0m[0m | time: 6.941s
[2K
| RMSProp | epoch: 013 | loss: 0.14675 - acc: 0.9460 -- iter: 0192/1483
[A[ATraining Step: 571  | total loss: [1m[32m0.15021[0m[0m | time: 7.826s
[2K
| RMSProp | epoch: 013 | loss: 0.15021 - acc: 0.9389 -- iter: 0224/1483
[A[ATraining Step: 572  | total loss: [1m[32m0.16149[0m[0m | time: 8.792s
[2K
| RMSProp | epoch: 013 | loss: 0.16149 - acc: 0.9325 -- iter: 0256/1483
[A[ATraining Step: 573  | total loss: [1m[32m0.17523[0m[0m | time: 9.757s
[2K
| RMSProp | epoch: 013 | loss: 0.17523 - acc: 0.9299 -- iter: 0288/1483
[A[ATraining Step: 574  | total loss: [1m[32m0.16529[0m[0m | time: 10.790s
[2K
| RMSProp | epoch: 013 | loss: 0.16529 - acc: 0.9369 -- iter: 0320/1483
[A[ATraining Step: 575  | total loss: [1m[32m0.16208[0m[0m | time: 11.161s
[2K
| RMSProp | epoch: 013 | loss: 0.16208 - acc: 0.9401 -- iter: 0352/1483
[A[ATraining Step: 576  | total loss: [1m[32m0.14916[0m[0m | time: 11.602s
[2K
| RMSProp | epoch: 013 | loss: 0.14916 - acc: 0.9461 -- iter: 0384/1483
[A[ATraining Step: 577  | total loss: [1m[32m0.13502[0m[0m | time: 12.771s
[2K
| RMSProp | epoch: 013 | loss: 0.13502 - acc: 0.9514 -- iter: 0416/1483
[A[ATraining Step: 578  | total loss: [1m[32m0.13655[0m[0m | time: 13.669s
[2K
| RMSProp | epoch: 013 | loss: 0.13655 - acc: 0.9501 -- iter: 0448/1483
[A[ATraining Step: 579  | total loss: [1m[32m0.13809[0m[0m | time: 14.687s
[2K
| RMSProp | epoch: 013 | loss: 0.13809 - acc: 0.9519 -- iter: 0480/1483
[A[ATraining Step: 580  | total loss: [1m[32m0.14664[0m[0m | time: 16.108s
[2K
| RMSProp | epoch: 013 | loss: 0.14664 - acc: 0.9442 -- iter: 0512/1483
[A[ATraining Step: 581  | total loss: [1m[32m0.15467[0m[0m | time: 17.591s
[2K
| RMSProp | epoch: 013 | loss: 0.15467 - acc: 0.9436 -- iter: 0544/1483
[A[ATraining Step: 582  | total loss: [1m[32m0.14387[0m[0m | time: 18.532s
[2K
| RMSProp | epoch: 013 | loss: 0.14387 - acc: 0.9492 -- iter: 0576/1483
[A[ATraining Step: 583  | total loss: [1m[32m0.14290[0m[0m | time: 19.471s
[2K
| RMSProp | epoch: 013 | loss: 0.14290 - acc: 0.9480 -- iter: 0608/1483
[A[ATraining Step: 584  | total loss: [1m[32m0.16983[0m[0m | time: 20.475s
[2K
| RMSProp | epoch: 013 | loss: 0.16983 - acc: 0.9345 -- iter: 0640/1483
[A[ATraining Step: 585  | total loss: [1m[32m0.20103[0m[0m | time: 21.467s
[2K
| RMSProp | epoch: 013 | loss: 0.20103 - acc: 0.9160 -- iter: 0672/1483
[A[ATraining Step: 586  | total loss: [1m[32m0.20734[0m[0m | time: 22.578s
[2K
| RMSProp | epoch: 013 | loss: 0.20734 - acc: 0.9119 -- iter: 0704/1483
[A[ATraining Step: 587  | total loss: [1m[32m0.20879[0m[0m | time: 23.662s
[2K
| RMSProp | epoch: 013 | loss: 0.20879 - acc: 0.9145 -- iter: 0736/1483
[A[ATraining Step: 588  | total loss: [1m[32m0.21089[0m[0m | time: 24.497s
[2K
| RMSProp | epoch: 013 | loss: 0.21089 - acc: 0.9137 -- iter: 0768/1483
[A[ATraining Step: 589  | total loss: [1m[32m0.20268[0m[0m | time: 25.618s
[2K
| RMSProp | epoch: 013 | loss: 0.20268 - acc: 0.9192 -- iter: 0800/1483
[A[ATraining Step: 590  | total loss: [1m[32m0.20231[0m[0m | time: 27.035s
[2K
| RMSProp | epoch: 013 | loss: 0.20231 - acc: 0.9210 -- iter: 0832/1483
[A[ATraining Step: 591  | total loss: [1m[32m0.20184[0m[0m | time: 28.388s
[2K
| RMSProp | epoch: 013 | loss: 0.20184 - acc: 0.9227 -- iter: 0864/1483
[A[ATraining Step: 592  | total loss: [1m[32m0.24100[0m[0m | time: 29.301s
[2K
| RMSProp | epoch: 013 | loss: 0.24100 - acc: 0.9148 -- iter: 0896/1483
[A[ATraining Step: 593  | total loss: [1m[32m0.24294[0m[0m | time: 30.223s
[2K
| RMSProp | epoch: 013 | loss: 0.24294 - acc: 0.9170 -- iter: 0928/1483
[A[ATraining Step: 594  | total loss: [1m[32m0.22440[0m[0m | time: 31.234s
[2K
| RMSProp | epoch: 013 | loss: 0.22440 - acc: 0.9253 -- iter: 0960/1483
[A[ATraining Step: 595  | total loss: [1m[32m0.21542[0m[0m | time: 32.201s
[2K
| RMSProp | epoch: 013 | loss: 0.21542 - acc: 0.9297 -- iter: 0992/1483
[A[ATraining Step: 596  | total loss: [1m[32m0.19771[0m[0m | time: 33.298s
[2K
| RMSProp | epoch: 013 | loss: 0.19771 - acc: 0.9367 -- iter: 1024/1483
[A[ATraining Step: 597  | total loss: [1m[32m0.20852[0m[0m | time: 34.432s
[2K
| RMSProp | epoch: 013 | loss: 0.20852 - acc: 0.9337 -- iter: 1056/1483
[A[ATraining Step: 598  | total loss: [1m[32m0.22301[0m[0m | time: 35.329s
[2K
| RMSProp | epoch: 013 | loss: 0.22301 - acc: 0.9309 -- iter: 1088/1483
[A[ATraining Step: 599  | total loss: [1m[32m0.22113[0m[0m | time: 36.174s
[2K
| RMSProp | epoch: 013 | loss: 0.22113 - acc: 0.9316 -- iter: 1120/1483
[A[ATraining Step: 600  | total loss: [1m[32m0.20832[0m[0m | time: 38.922s
[2K
| RMSProp | epoch: 013 | loss: 0.20832 - acc: 0.9384 | val_loss: 0.30798 - val_acc: 0.8858 -- iter: 1152/1483
--
Training Step: 601  | total loss: [1m[32m0.19831[0m[0m | time: 39.640s
[2K
| RMSProp | epoch: 013 | loss: 0.19831 - acc: 0.9415 -- iter: 1184/1483
[A[ATraining Step: 602  | total loss: [1m[32m0.18480[0m[0m | time: 40.245s
[2K
| RMSProp | epoch: 013 | loss: 0.18480 - acc: 0.9442 -- iter: 1216/1483
[A[ATraining Step: 603  | total loss: [1m[32m0.16867[0m[0m | time: 40.874s
[2K
| RMSProp | epoch: 013 | loss: 0.16867 - acc: 0.9498 -- iter: 1248/1483
[A[ATraining Step: 604  | total loss: [1m[32m0.16435[0m[0m | time: 41.488s
[2K
| RMSProp | epoch: 013 | loss: 0.16435 - acc: 0.9517 -- iter: 1280/1483
[A[ATraining Step: 605  | total loss: [1m[32m0.15441[0m[0m | time: 42.103s
[2K
| RMSProp | epoch: 013 | loss: 0.15441 - acc: 0.9534 -- iter: 1312/1483
[A[ATraining Step: 606  | total loss: [1m[32m0.14983[0m[0m | time: 42.739s
[2K
| RMSProp | epoch: 013 | loss: 0.14983 - acc: 0.9518 -- iter: 1344/1483
[A[ATraining Step: 607  | total loss: [1m[32m0.17376[0m[0m | time: 43.356s
[2K
| RMSProp | epoch: 013 | loss: 0.17376 - acc: 0.9379 -- iter: 1376/1483
[A[ATraining Step: 608  | total loss: [1m[32m0.17475[0m[0m | time: 43.957s
[2K
| RMSProp | epoch: 013 | loss: 0.17475 - acc: 0.9409 -- iter: 1408/1483
[A[ATraining Step: 609  | total loss: [1m[32m0.16577[0m[0m | time: 44.561s
[2K
| RMSProp | epoch: 013 | loss: 0.16577 - acc: 0.9469 -- iter: 1440/1483
[A[ATraining Step: 610  | total loss: [1m[32m0.16317[0m[0m | time: 45.165s
[2K
| RMSProp | epoch: 013 | loss: 0.16317 - acc: 0.9490 -- iter: 1472/1483
[A[ATraining Step: 611  | total loss: [1m[32m0.16406[0m[0m | time: 48.125s
[2K
| RMSProp | epoch: 013 | loss: 0.16406 - acc: 0.9479 | val_loss: 0.30713 - val_acc: 0.8879 -- iter: 1483/1483
--
Training Step: 612  | total loss: [1m[32m0.15413[0m[0m | time: 1.029s
[2K
| RMSProp | epoch: 014 | loss: 0.15413 - acc: 0.9531 -- iter: 0032/1483
[A[ATraining Step: 613  | total loss: [1m[32m0.14164[0m[0m | time: 2.110s
[2K
| RMSProp | epoch: 014 | loss: 0.14164 - acc: 0.9578 -- iter: 0064/1483
[A[ATraining Step: 614  | total loss: [1m[32m0.13492[0m[0m | time: 3.160s
[2K
| RMSProp | epoch: 014 | loss: 0.13492 - acc: 0.9589 -- iter: 0096/1483
[A[ATraining Step: 615  | total loss: [1m[32m0.12912[0m[0m | time: 4.227s
[2K
| RMSProp | epoch: 014 | loss: 0.12912 - acc: 0.9599 -- iter: 0128/1483
[A[ATraining Step: 616  | total loss: [1m[32m0.13231[0m[0m | time: 5.253s
[2K
| RMSProp | epoch: 014 | loss: 0.13231 - acc: 0.9576 -- iter: 0160/1483
[A[ATraining Step: 617  | total loss: [1m[32m0.12672[0m[0m | time: 6.313s
[2K
| RMSProp | epoch: 014 | loss: 0.12672 - acc: 0.9587 -- iter: 0192/1483
[A[ATraining Step: 618  | total loss: [1m[32m0.14174[0m[0m | time: 7.307s
[2K
| RMSProp | epoch: 014 | loss: 0.14174 - acc: 0.9535 -- iter: 0224/1483
[A[ATraining Step: 619  | total loss: [1m[32m0.13217[0m[0m | time: 8.462s
[2K
| RMSProp | epoch: 014 | loss: 0.13217 - acc: 0.9581 -- iter: 0256/1483
[A[ATraining Step: 620  | total loss: [1m[32m0.12039[0m[0m | time: 9.520s
[2K
| RMSProp | epoch: 014 | loss: 0.12039 - acc: 0.9623 -- iter: 0288/1483
[A[ATraining Step: 621  | total loss: [1m[32m0.10951[0m[0m | time: 10.637s
[2K
| RMSProp | epoch: 014 | loss: 0.10951 - acc: 0.9661 -- iter: 0320/1483
[A[ATraining Step: 622  | total loss: [1m[32m0.11799[0m[0m | time: 11.726s
[2K
| RMSProp | epoch: 014 | loss: 0.11799 - acc: 0.9632 -- iter: 0352/1483
[A[ATraining Step: 623  | total loss: [1m[32m0.11536[0m[0m | time: 12.154s
[2K
| RMSProp | epoch: 014 | loss: 0.11536 - acc: 0.9638 -- iter: 0384/1483
[A[ATraining Step: 624  | total loss: [1m[32m0.10724[0m[0m | time: 12.590s
[2K
| RMSProp | epoch: 014 | loss: 0.10724 - acc: 0.9674 -- iter: 0416/1483
[A[ATraining Step: 625  | total loss: [1m[32m0.09810[0m[0m | time: 13.667s
[2K
| RMSProp | epoch: 014 | loss: 0.09810 - acc: 0.9707 -- iter: 0448/1483
[A[ATraining Step: 626  | total loss: [1m[32m0.09064[0m[0m | time: 14.677s
[2K
| RMSProp | epoch: 014 | loss: 0.09064 - acc: 0.9736 -- iter: 0480/1483
[A[ATraining Step: 627  | total loss: [1m[32m0.09281[0m[0m | time: 15.740s
[2K
| RMSProp | epoch: 014 | loss: 0.09281 - acc: 0.9731 -- iter: 0512/1483
[A[ATraining Step: 628  | total loss: [1m[32m0.08802[0m[0m | time: 16.738s
[2K
| RMSProp | epoch: 014 | loss: 0.08802 - acc: 0.9727 -- iter: 0544/1483
[A[ATraining Step: 629  | total loss: [1m[32m0.08004[0m[0m | time: 17.839s
[2K
| RMSProp | epoch: 014 | loss: 0.08004 - acc: 0.9754 -- iter: 0576/1483
[A[ATraining Step: 630  | total loss: [1m[32m0.10155[0m[0m | time: 18.836s
[2K
| RMSProp | epoch: 014 | loss: 0.10155 - acc: 0.9716 -- iter: 0608/1483
[A[ATraining Step: 631  | total loss: [1m[32m0.12688[0m[0m | time: 19.867s
[2K
| RMSProp | epoch: 014 | loss: 0.12688 - acc: 0.9620 -- iter: 0640/1483
[A[ATraining Step: 632  | total loss: [1m[32m0.17999[0m[0m | time: 21.017s
[2K
| RMSProp | epoch: 014 | loss: 0.17999 - acc: 0.9345 -- iter: 0672/1483
[A[ATraining Step: 633  | total loss: [1m[32m0.17531[0m[0m | time: 22.049s
[2K
| RMSProp | epoch: 014 | loss: 0.17531 - acc: 0.9411 -- iter: 0704/1483
[A[ATraining Step: 634  | total loss: [1m[32m0.16622[0m[0m | time: 22.898s
[2K
| RMSProp | epoch: 014 | loss: 0.16622 - acc: 0.9438 -- iter: 0736/1483
[A[ATraining Step: 635  | total loss: [1m[32m0.16947[0m[0m | time: 23.518s
[2K
| RMSProp | epoch: 014 | loss: 0.16947 - acc: 0.9401 -- iter: 0768/1483
[A[ATraining Step: 636  | total loss: [1m[32m0.15852[0m[0m | time: 24.134s
[2K
| RMSProp | epoch: 014 | loss: 0.15852 - acc: 0.9461 -- iter: 0800/1483
[A[ATraining Step: 637  | total loss: [1m[32m0.16104[0m[0m | time: 24.753s
[2K
| RMSProp | epoch: 014 | loss: 0.16104 - acc: 0.9421 -- iter: 0832/1483
[A[ATraining Step: 638  | total loss: [1m[32m0.14773[0m[0m | time: 25.369s
[2K
| RMSProp | epoch: 014 | loss: 0.14773 - acc: 0.9479 -- iter: 0864/1483
[A[ATraining Step: 639  | total loss: [1m[32m0.17732[0m[0m | time: 25.984s
[2K
| RMSProp | epoch: 014 | loss: 0.17732 - acc: 0.9406 -- iter: 0896/1483
[A[ATraining Step: 640  | total loss: [1m[32m0.21492[0m[0m | time: 26.592s
[2K
| RMSProp | epoch: 014 | loss: 0.21492 - acc: 0.9247 -- iter: 0928/1483
[A[ATraining Step: 641  | total loss: [1m[32m0.20578[0m[0m | time: 27.196s
[2K
| RMSProp | epoch: 014 | loss: 0.20578 - acc: 0.9322 -- iter: 0960/1483
[A[ATraining Step: 642  | total loss: [1m[32m0.19199[0m[0m | time: 27.810s
[2K
| RMSProp | epoch: 014 | loss: 0.19199 - acc: 0.9358 -- iter: 0992/1483
[A[ATraining Step: 643  | total loss: [1m[32m0.18225[0m[0m | time: 28.421s
[2K
| RMSProp | epoch: 014 | loss: 0.18225 - acc: 0.9391 -- iter: 1024/1483
[A[ATraining Step: 644  | total loss: [1m[32m0.17653[0m[0m | time: 29.032s
[2K
| RMSProp | epoch: 014 | loss: 0.17653 - acc: 0.9421 -- iter: 1056/1483
[A[ATraining Step: 645  | total loss: [1m[32m0.17806[0m[0m | time: 29.639s
[2K
| RMSProp | epoch: 014 | loss: 0.17806 - acc: 0.9385 -- iter: 1088/1483
[A[ATraining Step: 646  | total loss: [1m[32m0.16349[0m[0m | time: 30.268s
[2K
| RMSProp | epoch: 014 | loss: 0.16349 - acc: 0.9447 -- iter: 1120/1483
[A[ATraining Step: 647  | total loss: [1m[32m0.15903[0m[0m | time: 30.884s
[2K
| RMSProp | epoch: 014 | loss: 0.15903 - acc: 0.9439 -- iter: 1152/1483
[A[ATraining Step: 648  | total loss: [1m[32m0.14690[0m[0m | time: 31.497s
[2K
| RMSProp | epoch: 014 | loss: 0.14690 - acc: 0.9496 -- iter: 1184/1483
[A[ATraining Step: 649  | total loss: [1m[32m0.13477[0m[0m | time: 32.125s
[2K
| RMSProp | epoch: 014 | loss: 0.13477 - acc: 0.9546 -- iter: 1216/1483
[A[ATraining Step: 650  | total loss: [1m[32m0.12322[0m[0m | time: 32.791s
[2K
| RMSProp | epoch: 014 | loss: 0.12322 - acc: 0.9591 -- iter: 1248/1483
[A[ATraining Step: 651  | total loss: [1m[32m0.11379[0m[0m | time: 33.603s
[2K
| RMSProp | epoch: 014 | loss: 0.11379 - acc: 0.9632 -- iter: 1280/1483
[A[ATraining Step: 652  | total loss: [1m[32m0.11619[0m[0m | time: 34.228s
[2K
| RMSProp | epoch: 014 | loss: 0.11619 - acc: 0.9638 -- iter: 1312/1483
[A[ATraining Step: 653  | total loss: [1m[32m0.12744[0m[0m | time: 34.857s
[2K
| RMSProp | epoch: 014 | loss: 0.12744 - acc: 0.9611 -- iter: 1344/1483
[A[ATraining Step: 654  | total loss: [1m[32m0.12126[0m[0m | time: 35.460s
[2K
| RMSProp | epoch: 014 | loss: 0.12126 - acc: 0.9650 -- iter: 1376/1483
[A[ATraining Step: 655  | total loss: [1m[32m0.11775[0m[0m | time: 36.200s
[2K
| RMSProp | epoch: 014 | loss: 0.11775 - acc: 0.9654 -- iter: 1408/1483
[A[ATraining Step: 656  | total loss: [1m[32m0.11268[0m[0m | time: 36.816s
[2K
| RMSProp | epoch: 014 | loss: 0.11268 - acc: 0.9657 -- iter: 1440/1483
[A[ATraining Step: 657  | total loss: [1m[32m0.12361[0m[0m | time: 37.434s
[2K
| RMSProp | epoch: 014 | loss: 0.12361 - acc: 0.9598 -- iter: 1472/1483
[A[ATraining Step: 658  | total loss: [1m[32m0.12039[0m[0m | time: 39.523s
[2K
| RMSProp | epoch: 014 | loss: 0.12039 - acc: 0.9607 | val_loss: 0.41035 - val_acc: 0.8534 -- iter: 1483/1483
--
Training Step: 659  | total loss: [1m[32m0.12911[0m[0m | time: 0.622s
[2K
| RMSProp | epoch: 015 | loss: 0.12911 - acc: 0.9521 -- iter: 0032/1483
[A[ATraining Step: 660  | total loss: [1m[32m0.12768[0m[0m | time: 1.239s
[2K
| RMSProp | epoch: 015 | loss: 0.12768 - acc: 0.9538 -- iter: 0064/1483
[A[ATraining Step: 661  | total loss: [1m[32m0.12450[0m[0m | time: 1.862s
[2K
| RMSProp | epoch: 015 | loss: 0.12450 - acc: 0.9553 -- iter: 0096/1483
[A[ATraining Step: 662  | total loss: [1m[32m0.11854[0m[0m | time: 2.476s
[2K
| RMSProp | epoch: 015 | loss: 0.11854 - acc: 0.9566 -- iter: 0128/1483
[A[ATraining Step: 663  | total loss: [1m[32m0.12155[0m[0m | time: 3.084s
[2K
| RMSProp | epoch: 015 | loss: 0.12155 - acc: 0.9547 -- iter: 0160/1483
[A[ATraining Step: 664  | total loss: [1m[32m0.12423[0m[0m | time: 3.712s
[2K
| RMSProp | epoch: 015 | loss: 0.12423 - acc: 0.9530 -- iter: 0192/1483
[A[ATraining Step: 665  | total loss: [1m[32m0.11896[0m[0m | time: 4.327s
[2K
| RMSProp | epoch: 015 | loss: 0.11896 - acc: 0.9546 -- iter: 0224/1483
[A[ATraining Step: 666  | total loss: [1m[32m0.10944[0m[0m | time: 4.931s
[2K
| RMSProp | epoch: 015 | loss: 0.10944 - acc: 0.9591 -- iter: 0256/1483
[A[ATraining Step: 667  | total loss: [1m[32m0.10111[0m[0m | time: 5.541s
[2K
| RMSProp | epoch: 015 | loss: 0.10111 - acc: 0.9632 -- iter: 0288/1483
[A[ATraining Step: 668  | total loss: [1m[32m0.10396[0m[0m | time: 6.186s
[2K
| RMSProp | epoch: 015 | loss: 0.10396 - acc: 0.9638 -- iter: 0320/1483
[A[ATraining Step: 669  | total loss: [1m[32m0.12265[0m[0m | time: 6.794s
[2K
| RMSProp | epoch: 015 | loss: 0.12265 - acc: 0.9580 -- iter: 0352/1483
[A[ATraining Step: 670  | total loss: [1m[32m0.12006[0m[0m | time: 7.489s
[2K
| RMSProp | epoch: 015 | loss: 0.12006 - acc: 0.9560 -- iter: 0384/1483
[A[ATraining Step: 671  | total loss: [1m[32m0.13498[0m[0m | time: 7.871s
[2K
| RMSProp | epoch: 015 | loss: 0.13498 - acc: 0.9510 -- iter: 0416/1483
[A[ATraining Step: 672  | total loss: [1m[32m0.14589[0m[0m | time: 8.202s
[2K
| RMSProp | epoch: 015 | loss: 0.14589 - acc: 0.9468 -- iter: 0448/1483
[A[ATraining Step: 673  | total loss: [1m[32m0.13285[0m[0m | time: 8.973s
[2K
| RMSProp | epoch: 015 | loss: 0.13285 - acc: 0.9521 -- iter: 0480/1483
[A[ATraining Step: 674  | total loss: [1m[32m0.13590[0m[0m | time: 9.812s
[2K
| RMSProp | epoch: 015 | loss: 0.13590 - acc: 0.9507 -- iter: 0512/1483
[A[ATraining Step: 675  | total loss: [1m[32m0.16058[0m[0m | time: 10.733s
[2K
| RMSProp | epoch: 015 | loss: 0.16058 - acc: 0.9337 -- iter: 0544/1483
[A[ATraining Step: 676  | total loss: [1m[32m0.20631[0m[0m | time: 11.985s
[2K
| RMSProp | epoch: 015 | loss: 0.20631 - acc: 0.9185 -- iter: 0576/1483
[A[ATraining Step: 677  | total loss: [1m[32m0.19193[0m[0m | time: 13.294s
[2K
| RMSProp | epoch: 015 | loss: 0.19193 - acc: 0.9266 -- iter: 0608/1483
[A[ATraining Step: 678  | total loss: [1m[32m0.18879[0m[0m | time: 14.678s
[2K
| RMSProp | epoch: 015 | loss: 0.18879 - acc: 0.9308 -- iter: 0640/1483
[A[ATraining Step: 679  | total loss: [1m[32m0.18919[0m[0m | time: 15.545s
[2K
| RMSProp | epoch: 015 | loss: 0.18919 - acc: 0.9315 -- iter: 0672/1483
[A[ATraining Step: 680  | total loss: [1m[32m0.18380[0m[0m | time: 16.508s
[2K
| RMSProp | epoch: 015 | loss: 0.18380 - acc: 0.9352 -- iter: 0704/1483
[A[ATraining Step: 681  | total loss: [1m[32m0.17196[0m[0m | time: 17.554s
[2K
| RMSProp | epoch: 015 | loss: 0.17196 - acc: 0.9417 -- iter: 0736/1483
[A[ATraining Step: 682  | total loss: [1m[32m0.16270[0m[0m | time: 18.550s
[2K
| RMSProp | epoch: 015 | loss: 0.16270 - acc: 0.9444 -- iter: 0768/1483
[A[ATraining Step: 683  | total loss: [1m[32m0.16939[0m[0m | time: 19.651s
[2K
| RMSProp | epoch: 015 | loss: 0.16939 - acc: 0.9375 -- iter: 0800/1483
[A[ATraining Step: 684  | total loss: [1m[32m0.18544[0m[0m | time: 20.689s
[2K
| RMSProp | epoch: 015 | loss: 0.18544 - acc: 0.9281 -- iter: 0832/1483
[A[ATraining Step: 685  | total loss: [1m[32m0.20329[0m[0m | time: 21.541s
[2K
| RMSProp | epoch: 015 | loss: 0.20329 - acc: 0.9259 -- iter: 0864/1483
[A[ATraining Step: 686  | total loss: [1m[32m0.19035[0m[0m | time: 22.713s
[2K
| RMSProp | epoch: 015 | loss: 0.19035 - acc: 0.9302 -- iter: 0896/1483
[A[ATraining Step: 687  | total loss: [1m[32m0.17483[0m[0m | time: 23.956s
[2K
| RMSProp | epoch: 015 | loss: 0.17483 - acc: 0.9372 -- iter: 0928/1483
[A[ATraining Step: 688  | total loss: [1m[32m0.16854[0m[0m | time: 25.246s
[2K
| RMSProp | epoch: 015 | loss: 0.16854 - acc: 0.9403 -- iter: 0960/1483
[A[ATraining Step: 689  | total loss: [1m[32m0.16214[0m[0m | time: 26.260s
[2K
| RMSProp | epoch: 015 | loss: 0.16214 - acc: 0.9432 -- iter: 0992/1483
[A[ATraining Step: 690  | total loss: [1m[32m0.14834[0m[0m | time: 27.248s
[2K
| RMSProp | epoch: 015 | loss: 0.14834 - acc: 0.9489 -- iter: 1024/1483
[A[ATraining Step: 691  | total loss: [1m[32m0.13435[0m[0m | time: 28.188s
[2K
| RMSProp | epoch: 015 | loss: 0.13435 - acc: 0.9540 -- iter: 1056/1483
[A[ATraining Step: 692  | total loss: [1m[32m0.12237[0m[0m | time: 29.181s
[2K
| RMSProp | epoch: 015 | loss: 0.12237 - acc: 0.9586 -- iter: 1088/1483
[A[ATraining Step: 693  | total loss: [1m[32m0.11157[0m[0m | time: 30.294s
[2K
| RMSProp | epoch: 015 | loss: 0.11157 - acc: 0.9627 -- iter: 1120/1483
[A[ATraining Step: 694  | total loss: [1m[32m0.10077[0m[0m | time: 31.370s
[2K
| RMSProp | epoch: 015 | loss: 0.10077 - acc: 0.9664 -- iter: 1152/1483
[A[ATraining Step: 695  | total loss: [1m[32m0.09107[0m[0m | time: 32.294s
[2K
| RMSProp | epoch: 015 | loss: 0.09107 - acc: 0.9698 -- iter: 1184/1483
[A[ATraining Step: 696  | total loss: [1m[32m0.08237[0m[0m | time: 33.332s
[2K
| RMSProp | epoch: 015 | loss: 0.08237 - acc: 0.9728 -- iter: 1216/1483
[A[ATraining Step: 697  | total loss: [1m[32m0.07918[0m[0m | time: 34.651s
[2K
| RMSProp | epoch: 015 | loss: 0.07918 - acc: 0.9724 -- iter: 1248/1483
[A[ATraining Step: 698  | total loss: [1m[32m0.08295[0m[0m | time: 36.100s
[2K
| RMSProp | epoch: 015 | loss: 0.08295 - acc: 0.9689 -- iter: 1280/1483
[A[ATraining Step: 699  | total loss: [1m[32m0.10440[0m[0m | time: 37.219s
[2K
| RMSProp | epoch: 015 | loss: 0.10440 - acc: 0.9564 -- iter: 1312/1483
[A[ATraining Step: 700  | total loss: [1m[32m0.10365[0m[0m | time: 38.176s
[2K
| RMSProp | epoch: 015 | loss: 0.10365 - acc: 0.9576 -- iter: 1344/1483
[A[ATraining Step: 701  | total loss: [1m[32m0.09933[0m[0m | time: 39.199s
[2K
| RMSProp | epoch: 015 | loss: 0.09933 - acc: 0.9588 -- iter: 1376/1483
[A[ATraining Step: 702  | total loss: [1m[32m0.11239[0m[0m | time: 40.171s
[2K
| RMSProp | epoch: 015 | loss: 0.11239 - acc: 0.9535 -- iter: 1408/1483
[A[ATraining Step: 703  | total loss: [1m[32m0.10788[0m[0m | time: 41.178s
[2K
| RMSProp | epoch: 015 | loss: 0.10788 - acc: 0.9582 -- iter: 1440/1483
[A[ATraining Step: 704  | total loss: [1m[32m0.10790[0m[0m | time: 42.289s
[2K
| RMSProp | epoch: 015 | loss: 0.10790 - acc: 0.9592 -- iter: 1472/1483
[A[ATraining Step: 705  | total loss: [1m[32m0.11117[0m[0m | time: 45.987s
[2K
| RMSProp | epoch: 015 | loss: 0.11117 - acc: 0.9602 | val_loss: 0.38270 - val_acc: 0.9095 -- iter: 1483/1483
--
Training Step: 706  | total loss: [1m[32m0.10208[0m[0m | time: 1.149s
[2K
| RMSProp | epoch: 016 | loss: 0.10208 - acc: 0.9641 -- iter: 0032/1483
[A[ATraining Step: 707  | total loss: [1m[32m0.10263[0m[0m | time: 2.075s
[2K
| RMSProp | epoch: 016 | loss: 0.10263 - acc: 0.9646 -- iter: 0064/1483
[A[ATraining Step: 708  | total loss: [1m[32m0.09433[0m[0m | time: 3.144s
[2K
| RMSProp | epoch: 016 | loss: 0.09433 - acc: 0.9681 -- iter: 0096/1483
[A[ATraining Step: 709  | total loss: [1m[32m0.08653[0m[0m | time: 4.157s
[2K
| RMSProp | epoch: 016 | loss: 0.08653 - acc: 0.9713 -- iter: 0128/1483
[A[ATraining Step: 710  | total loss: [1m[32m0.08895[0m[0m | time: 5.224s
[2K
| RMSProp | epoch: 016 | loss: 0.08895 - acc: 0.9679 -- iter: 0160/1483
[A[ATraining Step: 711  | total loss: [1m[32m0.17939[0m[0m | time: 6.271s
[2K
| RMSProp | epoch: 016 | loss: 0.17939 - acc: 0.9462 -- iter: 0192/1483
[A[ATraining Step: 712  | total loss: [1m[32m0.18014[0m[0m | time: 7.163s
[2K
| RMSProp | epoch: 016 | loss: 0.18014 - acc: 0.9453 -- iter: 0224/1483
[A[ATraining Step: 713  | total loss: [1m[32m0.17015[0m[0m | time: 8.192s
[2K
| RMSProp | epoch: 016 | loss: 0.17015 - acc: 0.9476 -- iter: 0256/1483
[A[ATraining Step: 714  | total loss: [1m[32m0.17428[0m[0m | time: 9.542s
[2K
| RMSProp | epoch: 016 | loss: 0.17428 - acc: 0.9435 -- iter: 0288/1483
[A[ATraining Step: 715  | total loss: [1m[32m0.16305[0m[0m | time: 10.935s
[2K
| RMSProp | epoch: 016 | loss: 0.16305 - acc: 0.9460 -- iter: 0320/1483
[A[ATraining Step: 716  | total loss: [1m[32m0.14947[0m[0m | time: 11.971s
[2K
| RMSProp | epoch: 016 | loss: 0.14947 - acc: 0.9514 -- iter: 0352/1483
[A[ATraining Step: 717  | total loss: [1m[32m0.13755[0m[0m | time: 12.925s
[2K
| RMSProp | epoch: 016 | loss: 0.13755 - acc: 0.9563 -- iter: 0384/1483
[A[ATraining Step: 718  | total loss: [1m[32m0.12537[0m[0m | time: 13.915s
[2K
| RMSProp | epoch: 016 | loss: 0.12537 - acc: 0.9606 -- iter: 0416/1483
[A[ATraining Step: 719  | total loss: [1m[32m0.12757[0m[0m | time: 14.289s
[2K
| RMSProp | epoch: 016 | loss: 0.12757 - acc: 0.9615 -- iter: 0448/1483
[A[ATraining Step: 720  | total loss: [1m[32m0.11794[0m[0m | time: 14.669s
[2K
| RMSProp | epoch: 016 | loss: 0.11794 - acc: 0.9653 -- iter: 0480/1483
[A[ATraining Step: 721  | total loss: [1m[32m0.10650[0m[0m | time: 15.661s
[2K
| RMSProp | epoch: 016 | loss: 0.10650 - acc: 0.9688 -- iter: 0512/1483
[A[ATraining Step: 722  | total loss: [1m[32m0.09905[0m[0m | time: 16.751s
[2K
| RMSProp | epoch: 016 | loss: 0.09905 - acc: 0.9719 -- iter: 0544/1483
[A[ATraining Step: 723  | total loss: [1m[32m0.12134[0m[0m | time: 17.756s
[2K
| RMSProp | epoch: 016 | loss: 0.12134 - acc: 0.9685 -- iter: 0576/1483
[A[ATraining Step: 724  | total loss: [1m[32m0.11033[0m[0m | time: 18.730s
[2K
| RMSProp | epoch: 016 | loss: 0.11033 - acc: 0.9716 -- iter: 0608/1483
[A[ATraining Step: 725  | total loss: [1m[32m0.11219[0m[0m | time: 20.145s
[2K
| RMSProp | epoch: 016 | loss: 0.11219 - acc: 0.9713 -- iter: 0640/1483
[A[ATraining Step: 726  | total loss: [1m[32m0.12950[0m[0m | time: 21.517s
[2K
| RMSProp | epoch: 016 | loss: 0.12950 - acc: 0.9648 -- iter: 0672/1483
[A[ATraining Step: 727  | total loss: [1m[32m0.14007[0m[0m | time: 22.596s
[2K
| RMSProp | epoch: 016 | loss: 0.14007 - acc: 0.9590 -- iter: 0704/1483
[A[ATraining Step: 728  | total loss: [1m[32m0.13069[0m[0m | time: 23.549s
[2K
| RMSProp | epoch: 016 | loss: 0.13069 - acc: 0.9631 -- iter: 0736/1483
[A[ATraining Step: 729  | total loss: [1m[32m0.11879[0m[0m | time: 24.604s
[2K
| RMSProp | epoch: 016 | loss: 0.11879 - acc: 0.9668 -- iter: 0768/1483
[A[ATraining Step: 730  | total loss: [1m[32m0.11312[0m[0m | time: 25.553s
[2K
| RMSProp | epoch: 016 | loss: 0.11312 - acc: 0.9670 -- iter: 0800/1483
[A[ATraining Step: 731  | total loss: [1m[32m0.11947[0m[0m | time: 26.620s
[2K
| RMSProp | epoch: 016 | loss: 0.11947 - acc: 0.9671 -- iter: 0832/1483
[A[ATraining Step: 732  | total loss: [1m[32m0.11932[0m[0m | time: 27.633s
[2K
| RMSProp | epoch: 016 | loss: 0.11932 - acc: 0.9673 -- iter: 0864/1483
[A[ATraining Step: 733  | total loss: [1m[32m0.11841[0m[0m | time: 28.497s
[2K
| RMSProp | epoch: 016 | loss: 0.11841 - acc: 0.9674 -- iter: 0896/1483
[A[ATraining Step: 734  | total loss: [1m[32m0.10987[0m[0m | time: 29.542s
[2K
| RMSProp | epoch: 016 | loss: 0.10987 - acc: 0.9707 -- iter: 0928/1483
[A[ATraining Step: 735  | total loss: [1m[32m0.10208[0m[0m | time: 30.904s
[2K
| RMSProp | epoch: 016 | loss: 0.10208 - acc: 0.9736 -- iter: 0960/1483
[A[ATraining Step: 736  | total loss: [1m[32m0.11319[0m[0m | time: 32.290s
[2K
| RMSProp | epoch: 016 | loss: 0.11319 - acc: 0.9700 -- iter: 0992/1483
[A[ATraining Step: 737  | total loss: [1m[32m0.13960[0m[0m | time: 33.235s
[2K
| RMSProp | epoch: 016 | loss: 0.13960 - acc: 0.9574 -- iter: 1024/1483
[A[ATraining Step: 738  | total loss: [1m[32m0.15236[0m[0m | time: 34.131s
[2K
| RMSProp | epoch: 016 | loss: 0.15236 - acc: 0.9523 -- iter: 1056/1483
[A[ATraining Step: 739  | total loss: [1m[32m0.14892[0m[0m | time: 35.130s
[2K
| RMSProp | epoch: 016 | loss: 0.14892 - acc: 0.9539 -- iter: 1088/1483
[A[ATraining Step: 740  | total loss: [1m[32m0.13706[0m[0m | time: 36.137s
[2K
| RMSProp | epoch: 016 | loss: 0.13706 - acc: 0.9585 -- iter: 1120/1483
[A[ATraining Step: 741  | total loss: [1m[32m0.12504[0m[0m | time: 37.189s
[2K
| RMSProp | epoch: 016 | loss: 0.12504 - acc: 0.9627 -- iter: 1152/1483
[A[ATraining Step: 742  | total loss: [1m[32m0.11828[0m[0m | time: 38.288s
[2K
| RMSProp | epoch: 016 | loss: 0.11828 - acc: 0.9633 -- iter: 1184/1483
[A[ATraining Step: 743  | total loss: [1m[32m0.11077[0m[0m | time: 39.204s
[2K
| RMSProp | epoch: 016 | loss: 0.11077 - acc: 0.9670 -- iter: 1216/1483
[A[ATraining Step: 744  | total loss: [1m[32m0.10498[0m[0m | time: 40.393s
[2K
| RMSProp | epoch: 016 | loss: 0.10498 - acc: 0.9671 -- iter: 1248/1483
[A[ATraining Step: 745  | total loss: [1m[32m0.09508[0m[0m | time: 41.688s
[2K
| RMSProp | epoch: 016 | loss: 0.09508 - acc: 0.9704 -- iter: 1280/1483
[A[ATraining Step: 746  | total loss: [1m[32m0.11215[0m[0m | time: 43.025s
[2K
| RMSProp | epoch: 016 | loss: 0.11215 - acc: 0.9671 -- iter: 1312/1483
[A[ATraining Step: 747  | total loss: [1m[32m0.10240[0m[0m | time: 43.949s
[2K
| RMSProp | epoch: 016 | loss: 0.10240 - acc: 0.9704 -- iter: 1344/1483
[A[ATraining Step: 748  | total loss: [1m[32m0.09788[0m[0m | time: 44.910s
[2K
| RMSProp | epoch: 016 | loss: 0.09788 - acc: 0.9703 -- iter: 1376/1483
[A[ATraining Step: 749  | total loss: [1m[32m0.08965[0m[0m | time: 45.870s
[2K
| RMSProp | epoch: 016 | loss: 0.08965 - acc: 0.9732 -- iter: 1408/1483
[A[ATraining Step: 750  | total loss: [1m[32m0.08226[0m[0m | time: 46.899s
[2K
| RMSProp | epoch: 016 | loss: 0.08226 - acc: 0.9759 -- iter: 1440/1483
[A[ATraining Step: 751  | total loss: [1m[32m0.07688[0m[0m | time: 48.027s
[2K
| RMSProp | epoch: 016 | loss: 0.07688 - acc: 0.9783 -- iter: 1472/1483
[A[ATraining Step: 752  | total loss: [1m[32m0.06949[0m[0m | time: 51.410s
[2K
| RMSProp | epoch: 016 | loss: 0.06949 - acc: 0.9805 | val_loss: 0.78415 - val_acc: 0.8405 -- iter: 1483/1483
--
Training Step: 753  | total loss: [1m[32m0.06796[0m[0m | time: 1.364s
[2K
| RMSProp | epoch: 017 | loss: 0.06796 - acc: 0.9793 -- iter: 0032/1483
[A[ATraining Step: 754  | total loss: [1m[32m0.08483[0m[0m | time: 2.645s
[2K
| RMSProp | epoch: 017 | loss: 0.08483 - acc: 0.9720 -- iter: 0064/1483
[A[ATraining Step: 755  | total loss: [1m[32m0.08477[0m[0m | time: 3.653s
[2K
| RMSProp | epoch: 017 | loss: 0.08477 - acc: 0.9717 -- iter: 0096/1483
[A[ATraining Step: 756  | total loss: [1m[32m0.07715[0m[0m | time: 4.605s
[2K
| RMSProp | epoch: 017 | loss: 0.07715 - acc: 0.9745 -- iter: 0128/1483
[A[ATraining Step: 757  | total loss: [1m[32m0.07064[0m[0m | time: 5.651s
[2K
| RMSProp | epoch: 017 | loss: 0.07064 - acc: 0.9771 -- iter: 0160/1483
[A[ATraining Step: 758  | total loss: [1m[32m0.06467[0m[0m | time: 6.641s
[2K
| RMSProp | epoch: 017 | loss: 0.06467 - acc: 0.9794 -- iter: 0192/1483
[A[ATraining Step: 759  | total loss: [1m[32m0.06195[0m[0m | time: 7.703s
[2K
| RMSProp | epoch: 017 | loss: 0.06195 - acc: 0.9783 -- iter: 0224/1483
[A[ATraining Step: 760  | total loss: [1m[32m0.05603[0m[0m | time: 8.760s
[2K
| RMSProp | epoch: 017 | loss: 0.05603 - acc: 0.9805 -- iter: 0256/1483
[A[ATraining Step: 761  | total loss: [1m[32m0.05884[0m[0m | time: 9.641s
[2K
| RMSProp | epoch: 017 | loss: 0.05884 - acc: 0.9793 -- iter: 0288/1483
[A[ATraining Step: 762  | total loss: [1m[32m0.05795[0m[0m | time: 10.746s
[2K
| RMSProp | epoch: 017 | loss: 0.05795 - acc: 0.9782 -- iter: 0320/1483
[A[ATraining Step: 763  | total loss: [1m[32m0.05234[0m[0m | time: 12.091s
[2K
| RMSProp | epoch: 017 | loss: 0.05234 - acc: 0.9804 -- iter: 0352/1483
[A[ATraining Step: 764  | total loss: [1m[32m0.05468[0m[0m | time: 13.481s
[2K
| RMSProp | epoch: 017 | loss: 0.05468 - acc: 0.9792 -- iter: 0384/1483
[A[ATraining Step: 765  | total loss: [1m[32m0.05383[0m[0m | time: 14.406s
[2K
| RMSProp | epoch: 017 | loss: 0.05383 - acc: 0.9782 -- iter: 0416/1483
[A[ATraining Step: 766  | total loss: [1m[32m0.05165[0m[0m | time: 15.271s
[2K
| RMSProp | epoch: 017 | loss: 0.05165 - acc: 0.9773 -- iter: 0448/1483
[A[ATraining Step: 767  | total loss: [1m[32m0.07995[0m[0m | time: 15.630s
[2K
| RMSProp | epoch: 017 | loss: 0.07995 - acc: 0.9702 -- iter: 0480/1483
[A[ATraining Step: 768  | total loss: [1m[32m0.07727[0m[0m | time: 16.016s
[2K
| RMSProp | epoch: 017 | loss: 0.07727 - acc: 0.9731 -- iter: 0512/1483
[A[ATraining Step: 769  | total loss: [1m[32m0.06992[0m[0m | time: 17.030s
[2K
| RMSProp | epoch: 017 | loss: 0.06992 - acc: 0.9758 -- iter: 0544/1483
[A[ATraining Step: 770  | total loss: [1m[32m0.07192[0m[0m | time: 18.006s
[2K
| RMSProp | epoch: 017 | loss: 0.07192 - acc: 0.9751 -- iter: 0576/1483
[A[ATraining Step: 771  | total loss: [1m[32m0.06611[0m[0m | time: 19.115s
[2K
| RMSProp | epoch: 017 | loss: 0.06611 - acc: 0.9776 -- iter: 0608/1483
[A[ATraining Step: 772  | total loss: [1m[32m0.06885[0m[0m | time: 20.093s
[2K
| RMSProp | epoch: 017 | loss: 0.06885 - acc: 0.9767 -- iter: 0640/1483
[A[ATraining Step: 773  | total loss: [1m[32m0.07546[0m[0m | time: 20.975s
[2K
| RMSProp | epoch: 017 | loss: 0.07546 - acc: 0.9728 -- iter: 0672/1483
[A[ATraining Step: 774  | total loss: [1m[32m0.06856[0m[0m | time: 22.310s
[2K
| RMSProp | epoch: 017 | loss: 0.06856 - acc: 0.9755 -- iter: 0704/1483
[A[ATraining Step: 775  | total loss: [1m[32m0.07028[0m[0m | time: 23.795s
[2K
| RMSProp | epoch: 017 | loss: 0.07028 - acc: 0.9748 -- iter: 0736/1483
[A[ATraining Step: 776  | total loss: [1m[32m0.09121[0m[0m | time: 25.053s
[2K
| RMSProp | epoch: 017 | loss: 0.09121 - acc: 0.9680 -- iter: 0768/1483
[A[ATraining Step: 777  | total loss: [1m[32m0.11108[0m[0m | time: 25.934s
[2K
| RMSProp | epoch: 017 | loss: 0.11108 - acc: 0.9618 -- iter: 0800/1483
[A[ATraining Step: 778  | total loss: [1m[32m0.11027[0m[0m | time: 26.964s
[2K
| RMSProp | epoch: 017 | loss: 0.11027 - acc: 0.9625 -- iter: 0832/1483
[A[ATraining Step: 779  | total loss: [1m[32m0.11786[0m[0m | time: 28.111s
[2K
| RMSProp | epoch: 017 | loss: 0.11786 - acc: 0.9600 -- iter: 0864/1483
[A[ATraining Step: 780  | total loss: [1m[32m0.10869[0m[0m | time: 29.205s
[2K
| RMSProp | epoch: 017 | loss: 0.10869 - acc: 0.9640 -- iter: 0896/1483
[A[ATraining Step: 781  | total loss: [1m[32m0.11162[0m[0m | time: 30.412s
[2K
| RMSProp | epoch: 017 | loss: 0.11162 - acc: 0.9645 -- iter: 0928/1483
[A[ATraining Step: 782  | total loss: [1m[32m0.10624[0m[0m | time: 31.388s
[2K
| RMSProp | epoch: 017 | loss: 0.10624 - acc: 0.9649 -- iter: 0960/1483
[A[ATraining Step: 783  | total loss: [1m[32m0.09663[0m[0m | time: 32.389s
[2K
| RMSProp | epoch: 017 | loss: 0.09663 - acc: 0.9684 -- iter: 0992/1483
[A[ATraining Step: 784  | total loss: [1m[32m0.11612[0m[0m | time: 33.675s
[2K
| RMSProp | epoch: 017 | loss: 0.11612 - acc: 0.9653 -- iter: 1024/1483
[A[ATraining Step: 785  | total loss: [1m[32m0.10597[0m[0m | time: 34.994s
[2K
| RMSProp | epoch: 017 | loss: 0.10597 - acc: 0.9688 -- iter: 1056/1483
[A[ATraining Step: 786  | total loss: [1m[32m0.09635[0m[0m | time: 36.116s
[2K
| RMSProp | epoch: 017 | loss: 0.09635 - acc: 0.9719 -- iter: 1088/1483
[A[ATraining Step: 787  | total loss: [1m[32m0.08726[0m[0m | time: 37.077s
[2K
| RMSProp | epoch: 017 | loss: 0.08726 - acc: 0.9747 -- iter: 1120/1483
[A[ATraining Step: 788  | total loss: [1m[32m0.07970[0m[0m | time: 38.071s
[2K
| RMSProp | epoch: 017 | loss: 0.07970 - acc: 0.9772 -- iter: 1152/1483
[A[ATraining Step: 789  | total loss: [1m[32m0.07236[0m[0m | time: 39.101s
[2K
| RMSProp | epoch: 017 | loss: 0.07236 - acc: 0.9795 -- iter: 1184/1483
[A[ATraining Step: 790  | total loss: [1m[32m0.06546[0m[0m | time: 40.119s
[2K
| RMSProp | epoch: 017 | loss: 0.06546 - acc: 0.9816 -- iter: 1216/1483
[A[ATraining Step: 791  | total loss: [1m[32m0.06089[0m[0m | time: 41.257s
[2K
| RMSProp | epoch: 017 | loss: 0.06089 - acc: 0.9834 -- iter: 1248/1483
[A[ATraining Step: 792  | total loss: [1m[32m0.05518[0m[0m | time: 42.173s
[2K
| RMSProp | epoch: 017 | loss: 0.05518 - acc: 0.9851 -- iter: 1280/1483
[A[ATraining Step: 793  | total loss: [1m[32m0.05132[0m[0m | time: 43.115s
[2K
| RMSProp | epoch: 017 | loss: 0.05132 - acc: 0.9866 -- iter: 1312/1483
[A[ATraining Step: 794  | total loss: [1m[32m0.04628[0m[0m | time: 44.400s
[2K
| RMSProp | epoch: 017 | loss: 0.04628 - acc: 0.9879 -- iter: 1344/1483
[A[ATraining Step: 795  | total loss: [1m[32m0.04229[0m[0m | time: 45.914s
[2K
| RMSProp | epoch: 017 | loss: 0.04229 - acc: 0.9891 -- iter: 1376/1483
[A[ATraining Step: 796  | total loss: [1m[32m0.04740[0m[0m | time: 47.102s
[2K
| RMSProp | epoch: 017 | loss: 0.04740 - acc: 0.9871 -- iter: 1408/1483
[A[ATraining Step: 797  | total loss: [1m[32m0.15286[0m[0m | time: 48.061s
[2K
| RMSProp | epoch: 017 | loss: 0.15286 - acc: 0.9602 -- iter: 1440/1483
[A[ATraining Step: 798  | total loss: [1m[32m0.16420[0m[0m | time: 48.977s
[2K
| RMSProp | epoch: 017 | loss: 0.16420 - acc: 0.9548 -- iter: 1472/1483
[A[ATraining Step: 799  | total loss: [1m[32m0.16510[0m[0m | time: 52.541s
[2K
| RMSProp | epoch: 017 | loss: 0.16510 - acc: 0.9562 | val_loss: 0.29857 - val_acc: 0.8966 -- iter: 1483/1483
--
Training Step: 800  | total loss: [1m[32m0.15509[0m[0m | time: 3.899s
[2K
| RMSProp | epoch: 018 | loss: 0.15509 - acc: 0.9606 | val_loss: 0.31178 - val_acc: 0.8901 -- iter: 0032/1483
--
Training Step: 801  | total loss: [1m[32m0.14880[0m[0m | time: 5.170s
[2K
| RMSProp | epoch: 018 | loss: 0.14880 - acc: 0.9583 -- iter: 0064/1483
[A[ATraining Step: 802  | total loss: [1m[32m0.13734[0m[0m | time: 6.014s
[2K
| RMSProp | epoch: 018 | loss: 0.13734 - acc: 0.9625 -- iter: 0096/1483
[A[ATraining Step: 803  | total loss: [1m[32m0.13880[0m[0m | time: 7.005s
[2K
| RMSProp | epoch: 018 | loss: 0.13880 - acc: 0.9600 -- iter: 0128/1483
[A[ATraining Step: 804  | total loss: [1m[32m0.14150[0m[0m | time: 7.990s
[2K
| RMSProp | epoch: 018 | loss: 0.14150 - acc: 0.9609 -- iter: 0160/1483
[A[ATraining Step: 805  | total loss: [1m[32m0.12922[0m[0m | time: 8.953s
[2K
| RMSProp | epoch: 018 | loss: 0.12922 - acc: 0.9648 -- iter: 0192/1483
[A[ATraining Step: 806  | total loss: [1m[32m0.11706[0m[0m | time: 10.017s
[2K
| RMSProp | epoch: 018 | loss: 0.11706 - acc: 0.9683 -- iter: 0224/1483
[A[ATraining Step: 807  | total loss: [1m[32m0.10658[0m[0m | time: 11.062s
[2K
| RMSProp | epoch: 018 | loss: 0.10658 - acc: 0.9715 -- iter: 0256/1483
[A[ATraining Step: 808  | total loss: [1m[32m0.09732[0m[0m | time: 11.935s
[2K
| RMSProp | epoch: 018 | loss: 0.09732 - acc: 0.9743 -- iter: 0288/1483
[A[ATraining Step: 809  | total loss: [1m[32m0.08787[0m[0m | time: 13.049s
[2K
| RMSProp | epoch: 018 | loss: 0.08787 - acc: 0.9769 -- iter: 0320/1483
[A[ATraining Step: 810  | total loss: [1m[32m0.07994[0m[0m | time: 14.417s
[2K
| RMSProp | epoch: 018 | loss: 0.07994 - acc: 0.9792 -- iter: 0352/1483
[A[ATraining Step: 811  | total loss: [1m[32m0.07223[0m[0m | time: 15.851s
[2K
| RMSProp | epoch: 018 | loss: 0.07223 - acc: 0.9813 -- iter: 0384/1483
[A[ATraining Step: 812  | total loss: [1m[32m0.06816[0m[0m | time: 16.817s
[2K
| RMSProp | epoch: 018 | loss: 0.06816 - acc: 0.9800 -- iter: 0416/1483
[A[ATraining Step: 813  | total loss: [1m[32m0.06585[0m[0m | time: 17.764s
[2K
| RMSProp | epoch: 018 | loss: 0.06585 - acc: 0.9789 -- iter: 0448/1483
[A[ATraining Step: 814  | total loss: [1m[32m0.06162[0m[0m | time: 18.754s
[2K
| RMSProp | epoch: 018 | loss: 0.06162 - acc: 0.9810 -- iter: 0480/1483
[A[ATraining Step: 815  | total loss: [1m[32m0.06850[0m[0m | time: 19.142s
[2K
| RMSProp | epoch: 018 | loss: 0.06850 - acc: 0.9798 -- iter: 0512/1483
[A[ATraining Step: 816  | total loss: [1m[32m0.08433[0m[0m | time: 19.521s
[2K
| RMSProp | epoch: 018 | loss: 0.08433 - acc: 0.9727 -- iter: 0544/1483
[A[ATraining Step: 817  | total loss: [1m[32m0.08595[0m[0m | time: 20.564s
[2K
| RMSProp | epoch: 018 | loss: 0.08595 - acc: 0.9663 -- iter: 0576/1483
[A[ATraining Step: 818  | total loss: [1m[32m0.09827[0m[0m | time: 21.718s
[2K
| RMSProp | epoch: 018 | loss: 0.09827 - acc: 0.9635 -- iter: 0608/1483
[A[ATraining Step: 819  | total loss: [1m[32m0.10731[0m[0m | time: 22.655s
[2K
| RMSProp | epoch: 018 | loss: 0.10731 - acc: 0.9577 -- iter: 0640/1483
[A[ATraining Step: 820  | total loss: [1m[32m0.10415[0m[0m | time: 23.627s
[2K
| RMSProp | epoch: 018 | loss: 0.10415 - acc: 0.9588 -- iter: 0672/1483
[A[ATraining Step: 821  | total loss: [1m[32m0.10205[0m[0m | time: 24.945s
[2K
| RMSProp | epoch: 018 | loss: 0.10205 - acc: 0.9567 -- iter: 0704/1483
[A[ATraining Step: 822  | total loss: [1m[32m0.09625[0m[0m | time: 26.260s
[2K
| RMSProp | epoch: 018 | loss: 0.09625 - acc: 0.9610 -- iter: 0736/1483
[A[ATraining Step: 823  | total loss: [1m[32m0.09456[0m[0m | time: 27.387s
[2K
| RMSProp | epoch: 018 | loss: 0.09456 - acc: 0.9618 -- iter: 0768/1483
[A[ATraining Step: 824  | total loss: [1m[32m0.08923[0m[0m | time: 28.285s
[2K
| RMSProp | epoch: 018 | loss: 0.08923 - acc: 0.9625 -- iter: 0800/1483
[A[ATraining Step: 825  | total loss: [1m[32m0.08553[0m[0m | time: 29.270s
[2K
| RMSProp | epoch: 018 | loss: 0.08553 - acc: 0.9631 -- iter: 0832/1483
[A[ATraining Step: 826  | total loss: [1m[32m0.08459[0m[0m | time: 30.243s
[2K
| RMSProp | epoch: 018 | loss: 0.08459 - acc: 0.9637 -- iter: 0864/1483
[A[ATraining Step: 827  | total loss: [1m[32m0.07905[0m[0m | time: 31.249s
[2K
| RMSProp | epoch: 018 | loss: 0.07905 - acc: 0.9673 -- iter: 0896/1483
[A[ATraining Step: 828  | total loss: [1m[32m0.07267[0m[0m | time: 32.453s
[2K
| RMSProp | epoch: 018 | loss: 0.07267 - acc: 0.9706 -- iter: 0928/1483
[A[ATraining Step: 829  | total loss: [1m[32m0.07978[0m[0m | time: 33.384s
[2K
| RMSProp | epoch: 018 | loss: 0.07978 - acc: 0.9704 -- iter: 0960/1483
[A[ATraining Step: 830  | total loss: [1m[32m0.07548[0m[0m | time: 34.362s
[2K
| RMSProp | epoch: 018 | loss: 0.07548 - acc: 0.9734 -- iter: 0992/1483
[A[ATraining Step: 831  | total loss: [1m[32m0.07187[0m[0m | time: 35.616s
[2K
| RMSProp | epoch: 018 | loss: 0.07187 - acc: 0.9729 -- iter: 1024/1483
[A[ATraining Step: 832  | total loss: [1m[32m0.16745[0m[0m | time: 36.871s
[2K
| RMSProp | epoch: 018 | loss: 0.16745 - acc: 0.9631 -- iter: 1056/1483
[A[ATraining Step: 833  | total loss: [1m[32m0.17077[0m[0m | time: 38.024s
[2K
| RMSProp | epoch: 018 | loss: 0.17077 - acc: 0.9606 -- iter: 1088/1483
[A[ATraining Step: 834  | total loss: [1m[32m0.15509[0m[0m | time: 38.945s
[2K
| RMSProp | epoch: 018 | loss: 0.15509 - acc: 0.9645 -- iter: 1120/1483
[A[ATraining Step: 835  | total loss: [1m[32m0.14214[0m[0m | time: 39.885s
[2K
| RMSProp | epoch: 018 | loss: 0.14214 - acc: 0.9680 -- iter: 1152/1483
[A[ATraining Step: 836  | total loss: [1m[32m0.13347[0m[0m | time: 40.917s
[2K
| RMSProp | epoch: 018 | loss: 0.13347 - acc: 0.9681 -- iter: 1184/1483
[A[ATraining Step: 837  | total loss: [1m[32m0.15161[0m[0m | time: 41.925s
[2K
| RMSProp | epoch: 018 | loss: 0.15161 - acc: 0.9651 -- iter: 1216/1483
[A[ATraining Step: 838  | total loss: [1m[32m0.14212[0m[0m | time: 43.101s
[2K
| RMSProp | epoch: 018 | loss: 0.14212 - acc: 0.9685 -- iter: 1248/1483
[A[ATraining Step: 839  | total loss: [1m[32m0.12945[0m[0m | time: 44.061s
[2K
| RMSProp | epoch: 018 | loss: 0.12945 - acc: 0.9717 -- iter: 1280/1483
[A[ATraining Step: 840  | total loss: [1m[32m0.11789[0m[0m | time: 45.048s
[2K
| RMSProp | epoch: 018 | loss: 0.11789 - acc: 0.9745 -- iter: 1312/1483
[A[ATraining Step: 841  | total loss: [1m[32m0.10681[0m[0m | time: 46.326s
[2K
| RMSProp | epoch: 018 | loss: 0.10681 - acc: 0.9771 -- iter: 1344/1483
[A[ATraining Step: 842  | total loss: [1m[32m0.09648[0m[0m | time: 47.620s
[2K
| RMSProp | epoch: 018 | loss: 0.09648 - acc: 0.9794 -- iter: 1376/1483
[A[ATraining Step: 843  | total loss: [1m[32m0.08912[0m[0m | time: 48.710s
[2K
| RMSProp | epoch: 018 | loss: 0.08912 - acc: 0.9814 -- iter: 1408/1483
[A[ATraining Step: 844  | total loss: [1m[32m0.08049[0m[0m | time: 49.607s
[2K
| RMSProp | epoch: 018 | loss: 0.08049 - acc: 0.9833 -- iter: 1440/1483
[A[ATraining Step: 845  | total loss: [1m[32m0.07955[0m[0m | time: 50.584s
[2K
| RMSProp | epoch: 018 | loss: 0.07955 - acc: 0.9818 -- iter: 1472/1483
[A[ATraining Step: 846  | total loss: [1m[32m0.09425[0m[0m | time: 54.183s
[2K
| RMSProp | epoch: 018 | loss: 0.09425 - acc: 0.9774 | val_loss: 0.39036 - val_acc: 0.8836 -- iter: 1483/1483
--
Training Step: 847  | total loss: [1m[32m0.14301[0m[0m | time: 0.931s
[2K
| RMSProp | epoch: 019 | loss: 0.14301 - acc: 0.9578 -- iter: 0032/1483
[A[ATraining Step: 848  | total loss: [1m[32m0.13092[0m[0m | time: 2.169s
[2K
| RMSProp | epoch: 019 | loss: 0.13092 - acc: 0.9620 -- iter: 0064/1483
[A[ATraining Step: 849  | total loss: [1m[32m0.11848[0m[0m | time: 3.499s
[2K
| RMSProp | epoch: 019 | loss: 0.11848 - acc: 0.9658 -- iter: 0096/1483
[A[ATraining Step: 850  | total loss: [1m[32m0.10898[0m[0m | time: 4.765s
[2K
| RMSProp | epoch: 019 | loss: 0.10898 - acc: 0.9692 -- iter: 0128/1483
[A[ATraining Step: 851  | total loss: [1m[32m0.10780[0m[0m | time: 5.611s
[2K
| RMSProp | epoch: 019 | loss: 0.10780 - acc: 0.9692 -- iter: 0160/1483
[A[ATraining Step: 852  | total loss: [1m[32m0.09823[0m[0m | time: 6.555s
[2K
| RMSProp | epoch: 019 | loss: 0.09823 - acc: 0.9723 -- iter: 0192/1483
[A[ATraining Step: 853  | total loss: [1m[32m0.08928[0m[0m | time: 7.609s
[2K
| RMSProp | epoch: 019 | loss: 0.08928 - acc: 0.9750 -- iter: 0224/1483
[A[ATraining Step: 854  | total loss: [1m[32m0.08123[0m[0m | time: 8.571s
[2K
| RMSProp | epoch: 019 | loss: 0.08123 - acc: 0.9775 -- iter: 0256/1483
[A[ATraining Step: 855  | total loss: [1m[32m0.07382[0m[0m | time: 9.628s
[2K
| RMSProp | epoch: 019 | loss: 0.07382 - acc: 0.9798 -- iter: 0288/1483
[A[ATraining Step: 856  | total loss: [1m[32m0.06675[0m[0m | time: 10.748s
[2K
| RMSProp | epoch: 019 | loss: 0.06675 - acc: 0.9818 -- iter: 0320/1483
[A[ATraining Step: 857  | total loss: [1m[32m0.06041[0m[0m | time: 11.597s
[2K
| RMSProp | epoch: 019 | loss: 0.06041 - acc: 0.9836 -- iter: 0352/1483
[A[ATraining Step: 858  | total loss: [1m[32m0.05474[0m[0m | time: 12.745s
[2K
| RMSProp | epoch: 019 | loss: 0.05474 - acc: 0.9853 -- iter: 0384/1483
[A[ATraining Step: 859  | total loss: [1m[32m0.04980[0m[0m | time: 14.121s
[2K
| RMSProp | epoch: 019 | loss: 0.04980 - acc: 0.9867 -- iter: 0416/1483
[A[ATraining Step: 860  | total loss: [1m[32m0.05678[0m[0m | time: 15.376s
[2K
| RMSProp | epoch: 019 | loss: 0.05678 - acc: 0.9849 -- iter: 0448/1483
[A[ATraining Step: 861  | total loss: [1m[32m0.06053[0m[0m | time: 16.257s
[2K
| RMSProp | epoch: 019 | loss: 0.06053 - acc: 0.9833 -- iter: 0480/1483
[A[ATraining Step: 862  | total loss: [1m[32m0.05582[0m[0m | time: 17.182s
[2K
| RMSProp | epoch: 019 | loss: 0.05582 - acc: 0.9850 -- iter: 0512/1483
[A[ATraining Step: 863  | total loss: [1m[32m0.05073[0m[0m | time: 17.583s
[2K
| RMSProp | epoch: 019 | loss: 0.05073 - acc: 0.9865 -- iter: 0544/1483
[A[ATraining Step: 864  | total loss: [1m[32m0.04585[0m[0m | time: 17.995s
[2K
| RMSProp | epoch: 019 | loss: 0.04585 - acc: 0.9878 -- iter: 0576/1483
[A[ATraining Step: 865  | total loss: [1m[32m0.04139[0m[0m | time: 19.006s
[2K
| RMSProp | epoch: 019 | loss: 0.04139 - acc: 0.9891 -- iter: 0608/1483
[A[ATraining Step: 866  | total loss: [1m[32m0.03743[0m[0m | time: 20.045s
[2K
| RMSProp | epoch: 019 | loss: 0.03743 - acc: 0.9901 -- iter: 0640/1483
[A[ATraining Step: 867  | total loss: [1m[32m0.03395[0m[0m | time: 21.174s
[2K
| RMSProp | epoch: 019 | loss: 0.03395 - acc: 0.9911 -- iter: 0672/1483
[A[ATraining Step: 868  | total loss: [1m[32m0.03091[0m[0m | time: 22.060s
[2K
| RMSProp | epoch: 019 | loss: 0.03091 - acc: 0.9920 -- iter: 0704/1483
[A[ATraining Step: 869  | total loss: [1m[32m0.02809[0m[0m | time: 23.147s
[2K
| RMSProp | epoch: 019 | loss: 0.02809 - acc: 0.9928 -- iter: 0736/1483
[A[ATraining Step: 870  | total loss: [1m[32m0.03052[0m[0m | time: 24.456s
[2K
| RMSProp | epoch: 019 | loss: 0.03052 - acc: 0.9904 -- iter: 0768/1483
[A[ATraining Step: 871  | total loss: [1m[32m0.05243[0m[0m | time: 25.792s
[2K
| RMSProp | epoch: 019 | loss: 0.05243 - acc: 0.9789 -- iter: 0800/1483
[A[ATraining Step: 872  | total loss: [1m[32m0.06058[0m[0m | time: 26.834s
[2K
| RMSProp | epoch: 019 | loss: 0.06058 - acc: 0.9747 -- iter: 0832/1483
[A[ATraining Step: 873  | total loss: [1m[32m0.05511[0m[0m | time: 27.727s
[2K
| RMSProp | epoch: 019 | loss: 0.05511 - acc: 0.9773 -- iter: 0864/1483
[A[ATraining Step: 874  | total loss: [1m[32m0.05454[0m[0m | time: 28.726s
[2K
| RMSProp | epoch: 019 | loss: 0.05454 - acc: 0.9764 -- iter: 0896/1483
[A[ATraining Step: 875  | total loss: [1m[32m0.04974[0m[0m | time: 29.738s
[2K
| RMSProp | epoch: 019 | loss: 0.04974 - acc: 0.9788 -- iter: 0928/1483
[A[ATraining Step: 876  | total loss: [1m[32m0.04958[0m[0m | time: 30.709s
[2K
| RMSProp | epoch: 019 | loss: 0.04958 - acc: 0.9778 -- iter: 0960/1483
[A[ATraining Step: 877  | total loss: [1m[32m0.04788[0m[0m | time: 31.934s
[2K
| RMSProp | epoch: 019 | loss: 0.04788 - acc: 0.9800 -- iter: 0992/1483
[A[ATraining Step: 878  | total loss: [1m[32m0.06370[0m[0m | time: 32.837s
[2K
| RMSProp | epoch: 019 | loss: 0.06370 - acc: 0.9757 -- iter: 1024/1483
[A[ATraining Step: 879  | total loss: [1m[32m0.05998[0m[0m | time: 33.813s
[2K
| RMSProp | epoch: 019 | loss: 0.05998 - acc: 0.9782 -- iter: 1056/1483
[A[ATraining Step: 880  | total loss: [1m[32m0.05878[0m[0m | time: 35.173s
[2K
| RMSProp | epoch: 019 | loss: 0.05878 - acc: 0.9772 -- iter: 1088/1483
[A[ATraining Step: 881  | total loss: [1m[32m0.05463[0m[0m | time: 36.513s
[2K
| RMSProp | epoch: 019 | loss: 0.05463 - acc: 0.9795 -- iter: 1120/1483
[A[ATraining Step: 882  | total loss: [1m[32m0.04934[0m[0m | time: 37.633s
[2K
| RMSProp | epoch: 019 | loss: 0.04934 - acc: 0.9816 -- iter: 1152/1483
[A[ATraining Step: 883  | total loss: [1m[32m0.04494[0m[0m | time: 38.581s
[2K
| RMSProp | epoch: 019 | loss: 0.04494 - acc: 0.9834 -- iter: 1184/1483
[A[ATraining Step: 884  | total loss: [1m[32m0.04064[0m[0m | time: 39.603s
[2K
| RMSProp | epoch: 019 | loss: 0.04064 - acc: 0.9851 -- iter: 1216/1483
[A[ATraining Step: 885  | total loss: [1m[32m0.03682[0m[0m | time: 40.602s
[2K
| RMSProp | epoch: 019 | loss: 0.03682 - acc: 0.9866 -- iter: 1248/1483
[A[ATraining Step: 886  | total loss: [1m[32m0.03338[0m[0m | time: 41.629s
[2K
| RMSProp | epoch: 019 | loss: 0.03338 - acc: 0.9879 -- iter: 1280/1483
[A[ATraining Step: 887  | total loss: [1m[32m0.03007[0m[0m | time: 42.709s
[2K
| RMSProp | epoch: 019 | loss: 0.03007 - acc: 0.9891 -- iter: 1312/1483
[A[ATraining Step: 888  | total loss: [1m[32m0.02743[0m[0m | time: 43.584s
[2K
| RMSProp | epoch: 019 | loss: 0.02743 - acc: 0.9902 -- iter: 1344/1483
[A[ATraining Step: 889  | total loss: [1m[32m0.02474[0m[0m | time: 44.659s
[2K
| RMSProp | epoch: 019 | loss: 0.02474 - acc: 0.9912 -- iter: 1376/1483
[A[ATraining Step: 890  | total loss: [1m[32m0.02242[0m[0m | time: 46.093s
[2K
| RMSProp | epoch: 019 | loss: 0.02242 - acc: 0.9921 -- iter: 1408/1483
[A[ATraining Step: 891  | total loss: [1m[32m0.02057[0m[0m | time: 47.350s
[2K
| RMSProp | epoch: 019 | loss: 0.02057 - acc: 0.9929 -- iter: 1440/1483
[A[ATraining Step: 892  | total loss: [1m[32m0.01858[0m[0m | time: 48.337s
[2K
| RMSProp | epoch: 019 | loss: 0.01858 - acc: 0.9936 -- iter: 1472/1483
[A[ATraining Step: 893  | total loss: [1m[32m0.01691[0m[0m | time: 51.633s
[2K
| RMSProp | epoch: 019 | loss: 0.01691 - acc: 0.9942 | val_loss: 0.46162 - val_acc: 0.9138 -- iter: 1483/1483
--
Training Step: 894  | total loss: [1m[32m0.01525[0m[0m | time: 1.041s
[2K
| RMSProp | epoch: 020 | loss: 0.01525 - acc: 0.9948 -- iter: 0032/1483
[A[ATraining Step: 895  | total loss: [1m[32m0.01490[0m[0m | time: 2.129s
[2K
| RMSProp | epoch: 020 | loss: 0.01490 - acc: 0.9953 -- iter: 0064/1483
[A[ATraining Step: 896  | total loss: [1m[32m0.01392[0m[0m | time: 3.005s
[2K
| RMSProp | epoch: 020 | loss: 0.01392 - acc: 0.9958 -- iter: 0096/1483
[A[ATraining Step: 897  | total loss: [1m[32m0.01267[0m[0m | time: 4.130s
[2K
| RMSProp | epoch: 020 | loss: 0.01267 - acc: 0.9962 -- iter: 0128/1483
[A[ATraining Step: 898  | total loss: [1m[32m0.01152[0m[0m | time: 5.413s
[2K
| RMSProp | epoch: 020 | loss: 0.01152 - acc: 0.9966 -- iter: 0160/1483
[A[ATraining Step: 899  | total loss: [1m[32m0.01038[0m[0m | time: 6.828s
[2K
| RMSProp | epoch: 020 | loss: 0.01038 - acc: 0.9969 -- iter: 0192/1483
[A[ATraining Step: 900  | total loss: [1m[32m0.00938[0m[0m | time: 7.721s
[2K
| RMSProp | epoch: 020 | loss: 0.00938 - acc: 0.9972 -- iter: 0224/1483
[A[ATraining Step: 901  | total loss: [1m[32m0.02839[0m[0m | time: 8.626s
[2K
| RMSProp | epoch: 020 | loss: 0.02839 - acc: 0.9944 -- iter: 0256/1483
[A[ATraining Step: 902  | total loss: [1m[32m0.32491[0m[0m | time: 9.616s
[2K
| RMSProp | epoch: 020 | loss: 0.32491 - acc: 0.9512 -- iter: 0288/1483
[A[ATraining Step: 903  | total loss: [1m[32m0.29512[0m[0m | time: 10.594s
[2K
| RMSProp | epoch: 020 | loss: 0.29512 - acc: 0.9561 -- iter: 0320/1483
[A[ATraining Step: 904  | total loss: [1m[32m0.26720[0m[0m | time: 11.747s
[2K
| RMSProp | epoch: 020 | loss: 0.26720 - acc: 0.9605 -- iter: 0352/1483
[A[ATraining Step: 905  | total loss: [1m[32m0.25626[0m[0m | time: 12.832s
[2K
| RMSProp | epoch: 020 | loss: 0.25626 - acc: 0.9550 -- iter: 0384/1483
[A[ATraining Step: 906  | total loss: [1m[32m0.30250[0m[0m | time: 13.756s
[2K
| RMSProp | epoch: 020 | loss: 0.30250 - acc: 0.9314 -- iter: 0416/1483
[A[ATraining Step: 907  | total loss: [1m[32m0.27417[0m[0m | time: 15.075s
[2K
| RMSProp | epoch: 020 | loss: 0.27417 - acc: 0.9383 -- iter: 0448/1483
[A[ATraining Step: 908  | total loss: [1m[32m0.24886[0m[0m | time: 16.442s
[2K
| RMSProp | epoch: 020 | loss: 0.24886 - acc: 0.9444 -- iter: 0480/1483
[A[ATraining Step: 909  | total loss: [1m[32m0.23820[0m[0m | time: 17.696s
[2K
| RMSProp | epoch: 020 | loss: 0.23820 - acc: 0.9469 -- iter: 0512/1483
[A[ATraining Step: 910  | total loss: [1m[32m0.21681[0m[0m | time: 18.597s
[2K
| RMSProp | epoch: 020 | loss: 0.21681 - acc: 0.9522 -- iter: 0544/1483
[A[ATraining Step: 911  | total loss: [1m[32m0.19606[0m[0m | time: 18.992s
[2K
| RMSProp | epoch: 020 | loss: 0.19606 - acc: 0.9570 -- iter: 0576/1483
[A[ATraining Step: 912  | total loss: [1m[32m0.17683[0m[0m | time: 19.405s
[2K
| RMSProp | epoch: 020 | loss: 0.17683 - acc: 0.9613 -- iter: 0608/1483
[A[ATraining Step: 913  | total loss: [1m[32m0.15930[0m[0m | time: 20.391s
[2K
| RMSProp | epoch: 020 | loss: 0.15930 - acc: 0.9651 -- iter: 0640/1483
[A[ATraining Step: 914  | total loss: [1m[32m0.14394[0m[0m | time: 21.352s
[2K
| RMSProp | epoch: 020 | loss: 0.14394 - acc: 0.9686 -- iter: 0672/1483
[A[ATraining Step: 915  | total loss: [1m[32m0.13321[0m[0m | time: 22.446s
[2K
| RMSProp | epoch: 020 | loss: 0.13321 - acc: 0.9686 -- iter: 0704/1483
[A[ATraining Step: 916  | total loss: [1m[32m0.13698[0m[0m | time: 23.535s
[2K
| RMSProp | epoch: 020 | loss: 0.13698 - acc: 0.9655 -- iter: 0736/1483
[A[ATraining Step: 917  | total loss: [1m[32m0.12362[0m[0m | time: 24.419s
[2K
| RMSProp | epoch: 020 | loss: 0.12362 - acc: 0.9690 -- iter: 0768/1483
[A[ATraining Step: 918  | total loss: [1m[32m0.11130[0m[0m | time: 25.522s
[2K
| RMSProp | epoch: 020 | loss: 0.11130 - acc: 0.9721 -- iter: 0800/1483
[A[ATraining Step: 919  | total loss: [1m[32m0.10275[0m[0m | time: 26.986s
[2K
| RMSProp | epoch: 020 | loss: 0.10275 - acc: 0.9749 -- iter: 0832/1483
[A[ATraining Step: 920  | total loss: [1m[32m0.11017[0m[0m | time: 28.420s
[2K
| RMSProp | epoch: 020 | loss: 0.11017 - acc: 0.9743 -- iter: 0864/1483
[A[ATraining Step: 921  | total loss: [1m[32m0.10156[0m[0m | time: 29.365s
[2K
| RMSProp | epoch: 020 | loss: 0.10156 - acc: 0.9768 -- iter: 0896/1483
[A[ATraining Step: 922  | total loss: [1m[32m0.09164[0m[0m | time: 30.329s
[2K
| RMSProp | epoch: 020 | loss: 0.09164 - acc: 0.9791 -- iter: 0928/1483
[A[ATraining Step: 923  | total loss: [1m[32m0.08936[0m[0m | time: 31.340s
[2K
| RMSProp | epoch: 020 | loss: 0.08936 - acc: 0.9781 -- iter: 0960/1483
[A[ATraining Step: 924  | total loss: [1m[32m0.12057[0m[0m | time: 32.398s
[2K
| RMSProp | epoch: 020 | loss: 0.12057 - acc: 0.9709 -- iter: 0992/1483
[A[ATraining Step: 925  | total loss: [1m[32m0.12589[0m[0m | time: 33.422s
[2K
| RMSProp | epoch: 020 | loss: 0.12589 - acc: 0.9676 -- iter: 1024/1483
[A[ATraining Step: 926  | total loss: [1m[32m0.12240[0m[0m | time: 34.546s
[2K
| RMSProp | epoch: 020 | loss: 0.12240 - acc: 0.9646 -- iter: 1056/1483
[A[ATraining Step: 927  | total loss: [1m[32m0.11350[0m[0m | time: 35.412s
[2K
| RMSProp | epoch: 020 | loss: 0.11350 - acc: 0.9681 -- iter: 1088/1483
[A[ATraining Step: 928  | total loss: [1m[32m0.10853[0m[0m | time: 36.608s
[2K
| RMSProp | epoch: 020 | loss: 0.10853 - acc: 0.9682 -- iter: 1120/1483
[A[ATraining Step: 929  | total loss: [1m[32m0.10011[0m[0m | time: 37.824s
[2K
| RMSProp | epoch: 020 | loss: 0.10011 - acc: 0.9714 -- iter: 1152/1483
[A[ATraining Step: 930  | total loss: [1m[32m0.09070[0m[0m | time: 39.161s
[2K
| RMSProp | epoch: 020 | loss: 0.09070 - acc: 0.9742 -- iter: 1184/1483
[A[ATraining Step: 931  | total loss: [1m[32m0.08249[0m[0m | time: 40.077s
[2K
| RMSProp | epoch: 020 | loss: 0.08249 - acc: 0.9768 -- iter: 1216/1483
[A[ATraining Step: 932  | total loss: [1m[32m0.07538[0m[0m | time: 41.016s
[2K
| RMSProp | epoch: 020 | loss: 0.07538 - acc: 0.9791 -- iter: 1248/1483
[A[ATraining Step: 933  | total loss: [1m[32m0.06807[0m[0m | time: 41.986s
[2K
| RMSProp | epoch: 020 | loss: 0.06807 - acc: 0.9812 -- iter: 1280/1483
[A[ATraining Step: 934  | total loss: [1m[32m0.07857[0m[0m | time: 42.971s
[2K
| RMSProp | epoch: 020 | loss: 0.07857 - acc: 0.9800 -- iter: 1312/1483
[A[ATraining Step: 935  | total loss: [1m[32m0.07522[0m[0m | time: 44.078s
[2K
| RMSProp | epoch: 020 | loss: 0.07522 - acc: 0.9788 -- iter: 1344/1483
[A[ATraining Step: 936  | total loss: [1m[32m0.07664[0m[0m | time: 45.124s
[2K
| RMSProp | epoch: 020 | loss: 0.07664 - acc: 0.9778 -- iter: 1376/1483
[A[ATraining Step: 937  | total loss: [1m[32m0.07323[0m[0m | time: 45.983s
[2K
| RMSProp | epoch: 020 | loss: 0.07323 - acc: 0.9769 -- iter: 1408/1483
[A[ATraining Step: 938  | total loss: [1m[32m0.06684[0m[0m | time: 47.059s
[2K
| RMSProp | epoch: 020 | loss: 0.06684 - acc: 0.9792 -- iter: 1440/1483
[A[ATraining Step: 939  | total loss: [1m[32m0.06089[0m[0m | time: 48.313s
[2K
| RMSProp | epoch: 020 | loss: 0.06089 - acc: 0.9813 -- iter: 1472/1483
[A[ATraining Step: 940  | total loss: [1m[32m0.05639[0m[0m | time: 51.982s
[2K
| RMSProp | epoch: 020 | loss: 0.05639 - acc: 0.9832 | val_loss: 0.45296 - val_acc: 0.8944 -- iter: 1483/1483
--
Training Step: 941  | total loss: [1m[32m0.05165[0m[0m | time: 0.999s
[2K
| RMSProp | epoch: 021 | loss: 0.05165 - acc: 0.9849 -- iter: 0032/1483
[A[ATraining Step: 942  | total loss: [1m[32m0.04657[0m[0m | time: 1.915s
[2K
| RMSProp | epoch: 021 | loss: 0.04657 - acc: 0.9864 -- iter: 0064/1483
[A[ATraining Step: 943  | total loss: [1m[32m0.04206[0m[0m | time: 2.975s
[2K
| RMSProp | epoch: 021 | loss: 0.04206 - acc: 0.9877 -- iter: 0096/1483
[A[ATraining Step: 944  | total loss: [1m[32m0.03851[0m[0m | time: 4.134s
[2K
| RMSProp | epoch: 021 | loss: 0.03851 - acc: 0.9890 -- iter: 0128/1483
[A[ATraining Step: 945  | total loss: [1m[32m0.03543[0m[0m | time: 4.984s
[2K
| RMSProp | epoch: 021 | loss: 0.03543 - acc: 0.9901 -- iter: 0160/1483
[A[ATraining Step: 946  | total loss: [1m[32m0.03200[0m[0m | time: 5.920s
[2K
| RMSProp | epoch: 021 | loss: 0.03200 - acc: 0.9911 -- iter: 0192/1483
[A[ATraining Step: 947  | total loss: [1m[32m0.02885[0m[0m | time: 7.214s
[2K
| RMSProp | epoch: 021 | loss: 0.02885 - acc: 0.9920 -- iter: 0224/1483
[A[ATraining Step: 948  | total loss: [1m[32m0.02750[0m[0m | time: 8.556s
[2K
| RMSProp | epoch: 021 | loss: 0.02750 - acc: 0.9928 -- iter: 0256/1483
[A[ATraining Step: 949  | total loss: [1m[32m0.04356[0m[0m | time: 9.691s
[2K
| RMSProp | epoch: 021 | loss: 0.04356 - acc: 0.9841 -- iter: 0288/1483
[A[ATraining Step: 950  | total loss: [1m[32m0.05242[0m[0m | time: 10.616s
[2K
| RMSProp | epoch: 021 | loss: 0.05242 - acc: 0.9826 -- iter: 0320/1483
[A[ATraining Step: 951  | total loss: [1m[32m0.04876[0m[0m | time: 11.583s
[2K
| RMSProp | epoch: 021 | loss: 0.04876 - acc: 0.9843 -- iter: 0352/1483
[A[ATraining Step: 952  | total loss: [1m[32m0.04481[0m[0m | time: 12.586s
[2K
| RMSProp | epoch: 021 | loss: 0.04481 - acc: 0.9859 -- iter: 0384/1483
[A[ATraining Step: 953  | total loss: [1m[32m0.06122[0m[0m | time: 13.625s
[2K
| RMSProp | epoch: 021 | loss: 0.06122 - acc: 0.9842 -- iter: 0416/1483
[A[ATraining Step: 954  | total loss: [1m[32m0.05796[0m[0m | time: 14.725s
[2K
| RMSProp | epoch: 021 | loss: 0.05796 - acc: 0.9858 -- iter: 0448/1483
[A[ATraining Step: 955  | total loss: [1m[32m0.05630[0m[0m | time: 15.653s
[2K
| RMSProp | epoch: 021 | loss: 0.05630 - acc: 0.9841 -- iter: 0480/1483
[A[ATraining Step: 956  | total loss: [1m[32m0.05420[0m[0m | time: 16.547s
[2K
| RMSProp | epoch: 021 | loss: 0.05420 - acc: 0.9825 -- iter: 0512/1483
[A[ATraining Step: 957  | total loss: [1m[32m0.04883[0m[0m | time: 17.937s
[2K
| RMSProp | epoch: 021 | loss: 0.04883 - acc: 0.9843 -- iter: 0544/1483
[A[ATraining Step: 958  | total loss: [1m[32m0.04406[0m[0m | time: 19.203s
[2K
| RMSProp | epoch: 021 | loss: 0.04406 - acc: 0.9858 -- iter: 0576/1483
[A[ATraining Step: 959  | total loss: [1m[32m0.03974[0m[0m | time: 19.753s
[2K
| RMSProp | epoch: 021 | loss: 0.03974 - acc: 0.9873 -- iter: 0608/1483
[A[ATraining Step: 960  | total loss: [1m[32m0.03605[0m[0m | time: 20.216s
[2K
| RMSProp | epoch: 021 | loss: 0.03605 - acc: 0.9885 -- iter: 0640/1483
[A[ATraining Step: 961  | total loss: [1m[32m0.03247[0m[0m | time: 21.085s
[2K
| RMSProp | epoch: 021 | loss: 0.03247 - acc: 0.9897 -- iter: 0672/1483
[A[ATraining Step: 962  | total loss: [1m[32m0.02927[0m[0m | time: 22.114s
[2K
| RMSProp | epoch: 021 | loss: 0.02927 - acc: 0.9907 -- iter: 0704/1483
[A[ATraining Step: 963  | total loss: [1m[32m0.02647[0m[0m | time: 23.106s
[2K
| RMSProp | epoch: 021 | loss: 0.02647 - acc: 0.9916 -- iter: 0736/1483
[A[ATraining Step: 964  | total loss: [1m[32m0.02700[0m[0m | time: 24.071s
[2K
| RMSProp | epoch: 021 | loss: 0.02700 - acc: 0.9925 -- iter: 0768/1483
[A[ATraining Step: 965  | total loss: [1m[32m0.04048[0m[0m | time: 25.173s
[2K
| RMSProp | epoch: 021 | loss: 0.04048 - acc: 0.9901 -- iter: 0800/1483
[A[ATraining Step: 966  | total loss: [1m[32m0.04902[0m[0m | time: 26.222s
[2K
| RMSProp | epoch: 021 | loss: 0.04902 - acc: 0.9880 -- iter: 0832/1483
[A[ATraining Step: 967  | total loss: [1m[32m0.04439[0m[0m | time: 27.143s
[2K
| RMSProp | epoch: 021 | loss: 0.04439 - acc: 0.9892 -- iter: 0864/1483
[A[ATraining Step: 968  | total loss: [1m[32m0.04014[0m[0m | time: 28.510s
[2K
| RMSProp | epoch: 021 | loss: 0.04014 - acc: 0.9903 -- iter: 0896/1483
[A[ATraining Step: 969  | total loss: [1m[32m0.03652[0m[0m | time: 29.936s
[2K
| RMSProp | epoch: 021 | loss: 0.03652 - acc: 0.9912 -- iter: 0928/1483
[A[ATraining Step: 970  | total loss: [1m[32m0.03336[0m[0m | time: 31.089s
[2K
| RMSProp | epoch: 021 | loss: 0.03336 - acc: 0.9921 -- iter: 0960/1483
[A[ATraining Step: 971  | total loss: [1m[32m0.03027[0m[0m | time: 31.983s
[2K
| RMSProp | epoch: 021 | loss: 0.03027 - acc: 0.9929 -- iter: 0992/1483
[A[ATraining Step: 972  | total loss: [1m[32m0.02795[0m[0m | time: 32.957s
[2K
| RMSProp | epoch: 021 | loss: 0.02795 - acc: 0.9936 -- iter: 1024/1483
[A[ATraining Step: 973  | total loss: [1m[32m0.02552[0m[0m | time: 33.901s
[2K
| RMSProp | epoch: 021 | loss: 0.02552 - acc: 0.9942 -- iter: 1056/1483
[A[ATraining Step: 974  | total loss: [1m[32m0.05263[0m[0m | time: 34.836s
[2K
| RMSProp | epoch: 021 | loss: 0.05263 - acc: 0.9917 -- iter: 1088/1483
[A[ATraining Step: 975  | total loss: [1m[32m0.04917[0m[0m | time: 35.965s
[2K
| RMSProp | epoch: 021 | loss: 0.04917 - acc: 0.9925 -- iter: 1120/1483
[A[ATraining Step: 976  | total loss: [1m[32m0.07780[0m[0m | time: 37.036s
[2K
| RMSProp | epoch: 021 | loss: 0.07780 - acc: 0.9839 -- iter: 1152/1483
[A[ATraining Step: 977  | total loss: [1m[32m0.08022[0m[0m | time: 37.902s
[2K
| RMSProp | epoch: 021 | loss: 0.08022 - acc: 0.9824 -- iter: 1184/1483
[A[ATraining Step: 978  | total loss: [1m[32m0.08790[0m[0m | time: 39.086s
[2K
| RMSProp | epoch: 021 | loss: 0.08790 - acc: 0.9748 -- iter: 1216/1483
[A[ATraining Step: 979  | total loss: [1m[32m0.08178[0m[0m | time: 40.316s
[2K
| RMSProp | epoch: 021 | loss: 0.08178 - acc: 0.9742 -- iter: 1248/1483
[A[ATraining Step: 980  | total loss: [1m[32m0.07383[0m[0m | time: 41.572s
[2K
| RMSProp | epoch: 021 | loss: 0.07383 - acc: 0.9768 -- iter: 1280/1483
[A[ATraining Step: 981  | total loss: [1m[32m0.06668[0m[0m | time: 42.521s
[2K
| RMSProp | epoch: 021 | loss: 0.06668 - acc: 0.9791 -- iter: 1312/1483
[A[ATraining Step: 982  | total loss: [1m[32m0.06051[0m[0m | time: 43.471s
[2K
| RMSProp | epoch: 021 | loss: 0.06051 - acc: 0.9812 -- iter: 1344/1483
[A[ATraining Step: 983  | total loss: [1m[32m0.09297[0m[0m | time: 44.380s
[2K
| RMSProp | epoch: 021 | loss: 0.09297 - acc: 0.9737 -- iter: 1376/1483
[A[ATraining Step: 984  | total loss: [1m[32m0.08672[0m[0m | time: 45.405s
[2K
| RMSProp | epoch: 021 | loss: 0.08672 - acc: 0.9763 -- iter: 1408/1483
[A[ATraining Step: 985  | total loss: [1m[32m0.07930[0m[0m | time: 46.594s
[2K
| RMSProp | epoch: 021 | loss: 0.07930 - acc: 0.9787 -- iter: 1440/1483
[A[ATraining Step: 986  | total loss: [1m[32m0.07518[0m[0m | time: 47.635s
[2K
| RMSProp | epoch: 021 | loss: 0.07518 - acc: 0.9777 -- iter: 1472/1483
[A[ATraining Step: 987  | total loss: [1m[32m0.07957[0m[0m | time: 51.284s
[2K
| RMSProp | epoch: 021 | loss: 0.07957 - acc: 0.9737 | val_loss: 0.47452 - val_acc: 0.8470 -- iter: 1483/1483
--
Training Step: 988  | total loss: [1m[32m0.09406[0m[0m | time: 1.220s
[2K
| RMSProp | epoch: 022 | loss: 0.09406 - acc: 0.9701 -- iter: 0032/1483
[A[ATraining Step: 989  | total loss: [1m[32m0.08785[0m[0m | time: 2.108s
[2K
| RMSProp | epoch: 022 | loss: 0.08785 - acc: 0.9730 -- iter: 0064/1483
[A[ATraining Step: 990  | total loss: [1m[32m0.08052[0m[0m | time: 3.078s
[2K
| RMSProp | epoch: 022 | loss: 0.08052 - acc: 0.9757 -- iter: 0096/1483
[A[ATraining Step: 991  | total loss: [1m[32m0.07288[0m[0m | time: 4.082s
[2K
| RMSProp | epoch: 022 | loss: 0.07288 - acc: 0.9782 -- iter: 0128/1483
[A[ATraining Step: 992  | total loss: [1m[32m0.06691[0m[0m | time: 5.091s
[2K
| RMSProp | epoch: 022 | loss: 0.06691 - acc: 0.9803 -- iter: 0160/1483
[A[ATraining Step: 993  | total loss: [1m[32m0.06227[0m[0m | time: 6.229s
[2K
| RMSProp | epoch: 022 | loss: 0.06227 - acc: 0.9823 -- iter: 0192/1483
[A[ATraining Step: 994  | total loss: [1m[32m0.05745[0m[0m | time: 7.289s
[2K
| RMSProp | epoch: 022 | loss: 0.05745 - acc: 0.9841 -- iter: 0224/1483
[A[ATraining Step: 995  | total loss: [1m[32m0.05207[0m[0m | time: 8.205s
[2K
| RMSProp | epoch: 022 | loss: 0.05207 - acc: 0.9857 -- iter: 0256/1483
[A[ATraining Step: 996  | total loss: [1m[32m0.04709[0m[0m | time: 9.456s
[2K
| RMSProp | epoch: 022 | loss: 0.04709 - acc: 0.9871 -- iter: 0288/1483
[A[ATraining Step: 997  | total loss: [1m[32m0.04432[0m[0m | time: 10.803s
[2K
| RMSProp | epoch: 022 | loss: 0.04432 - acc: 0.9884 -- iter: 0320/1483
[A[ATraining Step: 998  | total loss: [1m[32m0.05541[0m[0m | time: 12.048s
[2K
| RMSProp | epoch: 022 | loss: 0.05541 - acc: 0.9833 -- iter: 0352/1483
[A[ATraining Step: 999  | total loss: [1m[32m0.05514[0m[0m | time: 12.912s
[2K
| RMSProp | epoch: 022 | loss: 0.05514 - acc: 0.9819 -- iter: 0384/1483
[A[ATraining Step: 1000  | total loss: [1m[32m0.05725[0m[0m | time: 16.213s
[2K
| RMSProp | epoch: 022 | loss: 0.05725 - acc: 0.9805 | val_loss: 0.63272 - val_acc: 0.8427 -- iter: 0416/1483
--
Training Step: 1001  | total loss: [1m[32m0.05194[0m[0m | time: 17.370s
[2K
| RMSProp | epoch: 022 | loss: 0.05194 - acc: 0.9825 -- iter: 0448/1483
[A[ATraining Step: 1002  | total loss: [1m[32m0.05498[0m[0m | time: 18.446s
[2K
| RMSProp | epoch: 022 | loss: 0.05498 - acc: 0.9811 -- iter: 0480/1483
[A[ATraining Step: 1003  | total loss: [1m[32m0.05933[0m[0m | time: 19.346s
[2K
| RMSProp | epoch: 022 | loss: 0.05933 - acc: 0.9768 -- iter: 0512/1483
[A[ATraining Step: 1004  | total loss: [1m[32m0.05992[0m[0m | time: 20.583s
[2K
| RMSProp | epoch: 022 | loss: 0.05992 - acc: 0.9760 -- iter: 0544/1483
[A[ATraining Step: 1005  | total loss: [1m[32m0.05603[0m[0m | time: 21.836s
[2K
| RMSProp | epoch: 022 | loss: 0.05603 - acc: 0.9784 -- iter: 0576/1483
[A[ATraining Step: 1006  | total loss: [1m[32m0.05097[0m[0m | time: 23.091s
[2K
| RMSProp | epoch: 022 | loss: 0.05097 - acc: 0.9805 -- iter: 0608/1483
[A[ATraining Step: 1007  | total loss: [1m[32m0.04705[0m[0m | time: 23.392s
[2K
| RMSProp | epoch: 022 | loss: 0.04705 - acc: 0.9825 -- iter: 0640/1483
[A[ATraining Step: 1008  | total loss: [1m[32m0.04252[0m[0m | time: 23.713s
[2K
| RMSProp | epoch: 022 | loss: 0.04252 - acc: 0.9842 -- iter: 0672/1483
[A[ATraining Step: 1009  | total loss: [1m[32m0.03834[0m[0m | time: 24.617s
[2K
| RMSProp | epoch: 022 | loss: 0.03834 - acc: 0.9858 -- iter: 0704/1483
[A[ATraining Step: 1010  | total loss: [1m[32m0.03472[0m[0m | time: 25.566s
[2K
| RMSProp | epoch: 022 | loss: 0.03472 - acc: 0.9872 -- iter: 0736/1483
[A[ATraining Step: 1011  | total loss: [1m[32m0.03132[0m[0m | time: 26.575s
[2K
| RMSProp | epoch: 022 | loss: 0.03132 - acc: 0.9885 -- iter: 0768/1483
[A[ATraining Step: 1012  | total loss: [1m[32m0.02827[0m[0m | time: 27.620s
[2K
| RMSProp | epoch: 022 | loss: 0.02827 - acc: 0.9896 -- iter: 0800/1483
[A[ATraining Step: 1013  | total loss: [1m[32m0.02587[0m[0m | time: 28.656s
[2K
| RMSProp | epoch: 022 | loss: 0.02587 - acc: 0.9907 -- iter: 0832/1483
[A[ATraining Step: 1014  | total loss: [1m[32m0.04238[0m[0m | time: 29.557s
[2K
| RMSProp | epoch: 022 | loss: 0.04238 - acc: 0.9885 -- iter: 0864/1483
[A[ATraining Step: 1015  | total loss: [1m[32m0.06267[0m[0m | time: 30.552s
[2K
| RMSProp | epoch: 022 | loss: 0.06267 - acc: 0.9834 -- iter: 0896/1483
[A[ATraining Step: 1016  | total loss: [1m[32m0.07542[0m[0m | time: 31.823s
[2K
| RMSProp | epoch: 022 | loss: 0.07542 - acc: 0.9757 -- iter: 0928/1483
[A[ATraining Step: 1017  | total loss: [1m[32m0.09492[0m[0m | time: 33.042s
[2K
| RMSProp | epoch: 022 | loss: 0.09492 - acc: 0.9687 -- iter: 0960/1483
[A[ATraining Step: 1018  | total loss: [1m[32m0.09516[0m[0m | time: 34.149s
[2K
| RMSProp | epoch: 022 | loss: 0.09516 - acc: 0.9687 -- iter: 0992/1483
[A[ATraining Step: 1019  | total loss: [1m[32m0.09445[0m[0m | time: 35.036s
[2K
| RMSProp | epoch: 022 | loss: 0.09445 - acc: 0.9687 -- iter: 1024/1483
[A[ATraining Step: 1020  | total loss: [1m[32m0.08799[0m[0m | time: 35.992s
[2K
| RMSProp | epoch: 022 | loss: 0.08799 - acc: 0.9719 -- iter: 1056/1483
[A[ATraining Step: 1021  | total loss: [1m[32m0.08017[0m[0m | time: 36.952s
[2K
| RMSProp | epoch: 022 | loss: 0.08017 - acc: 0.9747 -- iter: 1088/1483
[A[ATraining Step: 1022  | total loss: [1m[32m0.07661[0m[0m | time: 37.956s
[2K
| RMSProp | epoch: 022 | loss: 0.07661 - acc: 0.9741 -- iter: 1120/1483
[A[ATraining Step: 1023  | total loss: [1m[32m0.07115[0m[0m | time: 39.074s
[2K
| RMSProp | epoch: 022 | loss: 0.07115 - acc: 0.9767 -- iter: 1152/1483
[A[ATraining Step: 1024  | total loss: [1m[32m0.09383[0m[0m | time: 40.078s
[2K
| RMSProp | epoch: 022 | loss: 0.09383 - acc: 0.9728 -- iter: 1184/1483
[A[ATraining Step: 1025  | total loss: [1m[32m0.09213[0m[0m | time: 40.928s
[2K
| RMSProp | epoch: 022 | loss: 0.09213 - acc: 0.9724 -- iter: 1216/1483
[A[ATraining Step: 1026  | total loss: [1m[32m0.08443[0m[0m | time: 42.175s
[2K
| RMSProp | epoch: 022 | loss: 0.08443 - acc: 0.9751 -- iter: 1248/1483
[A[ATraining Step: 1027  | total loss: [1m[32m0.08173[0m[0m | time: 43.574s
[2K
| RMSProp | epoch: 022 | loss: 0.08173 - acc: 0.9745 -- iter: 1280/1483
[A[ATraining Step: 1028  | total loss: [1m[32m0.08696[0m[0m | time: 44.895s
[2K
| RMSProp | epoch: 022 | loss: 0.08696 - acc: 0.9708 -- iter: 1312/1483
[A[ATraining Step: 1029  | total loss: [1m[32m0.07923[0m[0m | time: 45.823s
[2K
| RMSProp | epoch: 022 | loss: 0.07923 - acc: 0.9737 -- iter: 1344/1483
[A[ATraining Step: 1030  | total loss: [1m[32m0.07997[0m[0m | time: 46.815s
[2K
| RMSProp | epoch: 022 | loss: 0.07997 - acc: 0.9732 -- iter: 1376/1483
[A[ATraining Step: 1031  | total loss: [1m[32m0.07398[0m[0m | time: 47.840s
[2K
| RMSProp | epoch: 022 | loss: 0.07398 - acc: 0.9759 -- iter: 1408/1483
[A[ATraining Step: 1032  | total loss: [1m[32m0.06920[0m[0m | time: 48.797s
[2K
| RMSProp | epoch: 022 | loss: 0.06920 - acc: 0.9783 -- iter: 1440/1483
[A[ATraining Step: 1033  | total loss: [1m[32m0.07205[0m[0m | time: 49.999s
[2K
| RMSProp | epoch: 022 | loss: 0.07205 - acc: 0.9742 -- iter: 1472/1483
[A[ATraining Step: 1034  | total loss: [1m[32m0.08153[0m[0m | time: 53.608s
[2K
| RMSProp | epoch: 022 | loss: 0.08153 - acc: 0.9705 | val_loss: 0.37180 - val_acc: 0.8944 -- iter: 1483/1483
--
Training Step: 1035  | total loss: [1m[32m0.08080[0m[0m | time: 1.526s
[2K
| RMSProp | epoch: 023 | loss: 0.08080 - acc: 0.9704 -- iter: 0032/1483
[A[ATraining Step: 1036  | total loss: [1m[32m0.07482[0m[0m | time: 2.373s
[2K
| RMSProp | epoch: 023 | loss: 0.07482 - acc: 0.9733 -- iter: 0064/1483
[A[ATraining Step: 1037  | total loss: [1m[32m0.06807[0m[0m | time: 3.398s
[2K
| RMSProp | epoch: 023 | loss: 0.06807 - acc: 0.9760 -- iter: 0096/1483
[A[ATraining Step: 1038  | total loss: [1m[32m0.06139[0m[0m | time: 4.429s
[2K
| RMSProp | epoch: 023 | loss: 0.06139 - acc: 0.9784 -- iter: 0128/1483
[A[ATraining Step: 1039  | total loss: [1m[32m0.05544[0m[0m | time: 5.399s
[2K
| RMSProp | epoch: 023 | loss: 0.05544 - acc: 0.9806 -- iter: 0160/1483
[A[ATraining Step: 1040  | total loss: [1m[32m0.05693[0m[0m | time: 6.483s
[2K
| RMSProp | epoch: 023 | loss: 0.05693 - acc: 0.9763 -- iter: 0192/1483
[A[ATraining Step: 1041  | total loss: [1m[32m0.05185[0m[0m | time: 7.601s
[2K
| RMSProp | epoch: 023 | loss: 0.05185 - acc: 0.9786 -- iter: 0224/1483
[A[ATraining Step: 1042  | total loss: [1m[32m0.04794[0m[0m | time: 8.408s
[2K
| RMSProp | epoch: 023 | loss: 0.04794 - acc: 0.9808 -- iter: 0256/1483
[A[ATraining Step: 1043  | total loss: [1m[32m0.04330[0m[0m | time: 9.615s
[2K
| RMSProp | epoch: 023 | loss: 0.04330 - acc: 0.9827 -- iter: 0288/1483
[A[ATraining Step: 1044  | total loss: [1m[32m0.06203[0m[0m | time: 10.861s
[2K
| RMSProp | epoch: 023 | loss: 0.06203 - acc: 0.9813 -- iter: 0320/1483
[A[ATraining Step: 1045  | total loss: [1m[32m0.07797[0m[0m | time: 12.215s
[2K
| RMSProp | epoch: 023 | loss: 0.07797 - acc: 0.9769 -- iter: 0352/1483
[A[ATraining Step: 1046  | total loss: [1m[32m0.07209[0m[0m | time: 13.100s
[2K
| RMSProp | epoch: 023 | loss: 0.07209 - acc: 0.9792 -- iter: 0384/1483
[A[ATraining Step: 1047  | total loss: [1m[32m0.06516[0m[0m | time: 14.129s
[2K
| RMSProp | epoch: 023 | loss: 0.06516 - acc: 0.9813 -- iter: 0416/1483
[A[ATraining Step: 1048  | total loss: [1m[32m0.06745[0m[0m | time: 15.145s
[2K
| RMSProp | epoch: 023 | loss: 0.06745 - acc: 0.9800 -- iter: 0448/1483
[A[ATraining Step: 1049  | total loss: [1m[32m0.06332[0m[0m | time: 16.106s
[2K
| RMSProp | epoch: 023 | loss: 0.06332 - acc: 0.9820 -- iter: 0480/1483
[A[ATraining Step: 1050  | total loss: [1m[32m0.05710[0m[0m | time: 17.169s
[2K
| RMSProp | epoch: 023 | loss: 0.05710 - acc: 0.9838 -- iter: 0512/1483
[A[ATraining Step: 1051  | total loss: [1m[32m0.06860[0m[0m | time: 18.277s
[2K
| RMSProp | epoch: 023 | loss: 0.06860 - acc: 0.9792 -- iter: 0544/1483
[A[ATraining Step: 1052  | total loss: [1m[32m0.08341[0m[0m | time: 19.107s
[2K
| RMSProp | epoch: 023 | loss: 0.08341 - acc: 0.9750 -- iter: 0576/1483
[A[ATraining Step: 1053  | total loss: [1m[32m0.07746[0m[0m | time: 20.206s
[2K
| RMSProp | epoch: 023 | loss: 0.07746 - acc: 0.9775 -- iter: 0608/1483
[A[ATraining Step: 1054  | total loss: [1m[32m0.07043[0m[0m | time: 21.589s
[2K
| RMSProp | epoch: 023 | loss: 0.07043 - acc: 0.9798 -- iter: 0640/1483
[A[ATraining Step: 1055  | total loss: [1m[32m0.06537[0m[0m | time: 22.137s
[2K
| RMSProp | epoch: 023 | loss: 0.06537 - acc: 0.9818 -- iter: 0672/1483
[A[ATraining Step: 1056  | total loss: [1m[32m0.06122[0m[0m | time: 22.659s
[2K
| RMSProp | epoch: 023 | loss: 0.06122 - acc: 0.9836 -- iter: 0704/1483
[A[ATraining Step: 1057  | total loss: [1m[32m0.05541[0m[0m | time: 23.546s
[2K
| RMSProp | epoch: 023 | loss: 0.05541 - acc: 0.9853 -- iter: 0736/1483
[A[ATraining Step: 1058  | total loss: [1m[32m0.05123[0m[0m | time: 24.505s
[2K
| RMSProp | epoch: 023 | loss: 0.05123 - acc: 0.9867 -- iter: 0768/1483
[A[ATraining Step: 1059  | total loss: [1m[32m0.06214[0m[0m | time: 25.450s
[2K
| RMSProp | epoch: 023 | loss: 0.06214 - acc: 0.9849 -- iter: 0800/1483
[A[ATraining Step: 1060  | total loss: [1m[32m0.05797[0m[0m | time: 26.458s
[2K
| RMSProp | epoch: 023 | loss: 0.05797 - acc: 0.9864 -- iter: 0832/1483
[A[ATraining Step: 1061  | total loss: [1m[32m0.05263[0m[0m | time: 27.503s
[2K
| RMSProp | epoch: 023 | loss: 0.05263 - acc: 0.9878 -- iter: 0864/1483
[A[ATraining Step: 1062  | total loss: [1m[32m0.04807[0m[0m | time: 28.636s
[2K
| RMSProp | epoch: 023 | loss: 0.04807 - acc: 0.9890 -- iter: 0896/1483
[A[ATraining Step: 1063  | total loss: [1m[32m0.04430[0m[0m | time: 29.509s
[2K
| RMSProp | epoch: 023 | loss: 0.04430 - acc: 0.9901 -- iter: 0928/1483
[A[ATraining Step: 1064  | total loss: [1m[32m0.04422[0m[0m | time: 30.501s
[2K
| RMSProp | epoch: 023 | loss: 0.04422 - acc: 0.9880 -- iter: 0960/1483
[A[ATraining Step: 1065  | total loss: [1m[32m0.04483[0m[0m | time: 31.655s
[2K
| RMSProp | epoch: 023 | loss: 0.04483 - acc: 0.9892 -- iter: 0992/1483
[A[ATraining Step: 1066  | total loss: [1m[32m0.05512[0m[0m | time: 33.142s
[2K
| RMSProp | epoch: 023 | loss: 0.05512 - acc: 0.9840 -- iter: 1024/1483
[A[ATraining Step: 1067  | total loss: [1m[32m0.05237[0m[0m | time: 34.188s
[2K
| RMSProp | epoch: 023 | loss: 0.05237 - acc: 0.9856 -- iter: 1056/1483
[A[ATraining Step: 1068  | total loss: [1m[32m0.05225[0m[0m | time: 35.120s
[2K
| RMSProp | epoch: 023 | loss: 0.05225 - acc: 0.9839 -- iter: 1088/1483
[A[ATraining Step: 1069  | total loss: [1m[32m0.05032[0m[0m | time: 36.129s
[2K
| RMSProp | epoch: 023 | loss: 0.05032 - acc: 0.9824 -- iter: 1120/1483
[A[ATraining Step: 1070  | total loss: [1m[32m0.04597[0m[0m | time: 37.149s
[2K
| RMSProp | epoch: 023 | loss: 0.04597 - acc: 0.9842 -- iter: 1152/1483
[A[ATraining Step: 1071  | total loss: [1m[32m0.04208[0m[0m | time: 38.264s
[2K
| RMSProp | epoch: 023 | loss: 0.04208 - acc: 0.9858 -- iter: 1184/1483
[A[ATraining Step: 1072  | total loss: [1m[32m0.07772[0m[0m | time: 39.305s
[2K
| RMSProp | epoch: 023 | loss: 0.07772 - acc: 0.9809 -- iter: 1216/1483
[A[ATraining Step: 1073  | total loss: [1m[32m0.07426[0m[0m | time: 40.197s
[2K
| RMSProp | epoch: 023 | loss: 0.07426 - acc: 0.9828 -- iter: 1248/1483
[A[ATraining Step: 1074  | total loss: [1m[32m0.07007[0m[0m | time: 41.305s
[2K
| RMSProp | epoch: 023 | loss: 0.07007 - acc: 0.9814 -- iter: 1280/1483
[A[ATraining Step: 1075  | total loss: [1m[32m0.06400[0m[0m | time: 42.730s
[2K
| RMSProp | epoch: 023 | loss: 0.06400 - acc: 0.9833 -- iter: 1312/1483
[A[ATraining Step: 1076  | total loss: [1m[32m0.05800[0m[0m | time: 44.076s
[2K
| RMSProp | epoch: 023 | loss: 0.05800 - acc: 0.9850 -- iter: 1344/1483
[A[ATraining Step: 1077  | total loss: [1m[32m0.05240[0m[0m | time: 44.941s
[2K
| RMSProp | epoch: 023 | loss: 0.05240 - acc: 0.9865 -- iter: 1376/1483
[A[ATraining Step: 1078  | total loss: [1m[32m0.04754[0m[0m | time: 45.927s
[2K
| RMSProp | epoch: 023 | loss: 0.04754 - acc: 0.9878 -- iter: 1408/1483
[A[ATraining Step: 1079  | total loss: [1m[32m0.04364[0m[0m | time: 46.890s
[2K
| RMSProp | epoch: 023 | loss: 0.04364 - acc: 0.9890 -- iter: 1440/1483
[A[ATraining Step: 1080  | total loss: [1m[32m0.03945[0m[0m | time: 47.901s
[2K
| RMSProp | epoch: 023 | loss: 0.03945 - acc: 0.9901 -- iter: 1472/1483
[A[ATraining Step: 1081  | total loss: [1m[32m0.03564[0m[0m | time: 51.398s
[2K
| RMSProp | epoch: 023 | loss: 0.03564 - acc: 0.9911 | val_loss: 0.51111 - val_acc: 0.8707 -- iter: 1483/1483
--
Training Step: 1082  | total loss: [1m[32m0.03931[0m[0m | time: 1.292s
[2K
| RMSProp | epoch: 024 | loss: 0.03931 - acc: 0.9889 -- iter: 0032/1483
[A[ATraining Step: 1083  | total loss: [1m[32m0.03749[0m[0m | time: 2.515s
[2K
| RMSProp | epoch: 024 | loss: 0.03749 - acc: 0.9900 -- iter: 0064/1483
[A[ATraining Step: 1084  | total loss: [1m[32m0.05217[0m[0m | time: 3.739s
[2K
| RMSProp | epoch: 024 | loss: 0.05217 - acc: 0.9879 -- iter: 0096/1483
[A[ATraining Step: 1085  | total loss: [1m[32m0.04893[0m[0m | time: 4.609s
[2K
| RMSProp | epoch: 024 | loss: 0.04893 - acc: 0.9891 -- iter: 0128/1483
[A[ATraining Step: 1086  | total loss: [1m[32m0.04548[0m[0m | time: 5.618s
[2K
| RMSProp | epoch: 024 | loss: 0.04548 - acc: 0.9902 -- iter: 0160/1483
[A[ATraining Step: 1087  | total loss: [1m[32m0.05556[0m[0m | time: 6.560s
[2K
| RMSProp | epoch: 024 | loss: 0.05556 - acc: 0.9880 -- iter: 0192/1483
[A[ATraining Step: 1088  | total loss: [1m[32m0.05134[0m[0m | time: 7.527s
[2K
| RMSProp | epoch: 024 | loss: 0.05134 - acc: 0.9892 -- iter: 0224/1483
[A[ATraining Step: 1089  | total loss: [1m[32m0.04686[0m[0m | time: 8.693s
[2K
| RMSProp | epoch: 024 | loss: 0.04686 - acc: 0.9903 -- iter: 0256/1483
[A[ATraining Step: 1090  | total loss: [1m[32m0.04275[0m[0m | time: 9.710s
[2K
| RMSProp | epoch: 024 | loss: 0.04275 - acc: 0.9913 -- iter: 0288/1483
[A[ATraining Step: 1091  | total loss: [1m[32m0.03898[0m[0m | time: 10.632s
[2K
| RMSProp | epoch: 024 | loss: 0.03898 - acc: 0.9921 -- iter: 0320/1483
[A[ATraining Step: 1092  | total loss: [1m[32m0.03529[0m[0m | time: 11.603s
[2K
| RMSProp | epoch: 024 | loss: 0.03529 - acc: 0.9929 -- iter: 0352/1483
[A[ATraining Step: 1093  | total loss: [1m[32m0.03500[0m[0m | time: 12.602s
[2K
| RMSProp | epoch: 024 | loss: 0.03500 - acc: 0.9936 -- iter: 0384/1483
[A[ATraining Step: 1094  | total loss: [1m[32m0.07464[0m[0m | time: 13.638s
[2K
| RMSProp | epoch: 024 | loss: 0.07464 - acc: 0.9880 -- iter: 0416/1483
[A[ATraining Step: 1095  | total loss: [1m[32m0.07983[0m[0m | time: 14.776s
[2K
| RMSProp | epoch: 024 | loss: 0.07983 - acc: 0.9798 -- iter: 0448/1483
[A[ATraining Step: 1096  | total loss: [1m[32m0.07220[0m[0m | time: 15.948s
[2K
| RMSProp | epoch: 024 | loss: 0.07220 - acc: 0.9819 -- iter: 0480/1483
[A[ATraining Step: 1097  | total loss: [1m[32m0.06545[0m[0m | time: 16.965s
[2K
| RMSProp | epoch: 024 | loss: 0.06545 - acc: 0.9837 -- iter: 0512/1483
[A[ATraining Step: 1098  | total loss: [1m[32m0.05978[0m[0m | time: 18.032s
[2K
| RMSProp | epoch: 024 | loss: 0.05978 - acc: 0.9853 -- iter: 0544/1483
[A[ATraining Step: 1099  | total loss: [1m[32m0.05956[0m[0m | time: 19.023s
[2K
| RMSProp | epoch: 024 | loss: 0.05956 - acc: 0.9837 -- iter: 0576/1483
[A[ATraining Step: 1100  | total loss: [1m[32m0.05648[0m[0m | time: 20.093s
[2K
| RMSProp | epoch: 024 | loss: 0.05648 - acc: 0.9822 -- iter: 0608/1483
[A[ATraining Step: 1101  | total loss: [1m[32m0.05632[0m[0m | time: 21.147s
[2K
| RMSProp | epoch: 024 | loss: 0.05632 - acc: 0.9808 -- iter: 0640/1483
[A[ATraining Step: 1102  | total loss: [1m[32m0.05176[0m[0m | time: 22.155s
[2K
| RMSProp | epoch: 024 | loss: 0.05176 - acc: 0.9827 -- iter: 0672/1483
[A[ATraining Step: 1103  | total loss: [1m[32m0.04667[0m[0m | time: 22.572s
[2K
| RMSProp | epoch: 024 | loss: 0.04667 - acc: 0.9845 -- iter: 0704/1483
[A[ATraining Step: 1104  | total loss: [1m[32m0.04231[0m[0m | time: 22.983s
[2K
| RMSProp | epoch: 024 | loss: 0.04231 - acc: 0.9860 -- iter: 0736/1483
[A[ATraining Step: 1105  | total loss: [1m[32m0.03814[0m[0m | time: 24.013s
[2K
| RMSProp | epoch: 024 | loss: 0.03814 - acc: 0.9874 -- iter: 0768/1483
[A[ATraining Step: 1106  | total loss: [1m[32m0.03438[0m[0m | time: 25.047s
[2K
| RMSProp | epoch: 024 | loss: 0.03438 - acc: 0.9887 -- iter: 0800/1483
[A[ATraining Step: 1107  | total loss: [1m[32m0.03107[0m[0m | time: 26.129s
[2K
| RMSProp | epoch: 024 | loss: 0.03107 - acc: 0.9898 -- iter: 0832/1483
[A[ATraining Step: 1108  | total loss: [1m[32m0.02804[0m[0m | time: 27.155s
[2K
| RMSProp | epoch: 024 | loss: 0.02804 - acc: 0.9908 -- iter: 0864/1483
[A[ATraining Step: 1109  | total loss: [1m[32m0.02529[0m[0m | time: 28.231s
[2K
| RMSProp | epoch: 024 | loss: 0.02529 - acc: 0.9917 -- iter: 0896/1483
[A[ATraining Step: 1110  | total loss: [1m[32m0.02277[0m[0m | time: 29.333s
[2K
| RMSProp | epoch: 024 | loss: 0.02277 - acc: 0.9926 -- iter: 0928/1483
[A[ATraining Step: 1111  | total loss: [1m[32m0.02297[0m[0m | time: 30.366s
[2K
| RMSProp | epoch: 024 | loss: 0.02297 - acc: 0.9902 -- iter: 0960/1483
[A[ATraining Step: 1112  | total loss: [1m[32m0.03156[0m[0m | time: 31.440s
[2K
| RMSProp | epoch: 024 | loss: 0.03156 - acc: 0.9849 -- iter: 0992/1483
[A[ATraining Step: 1113  | total loss: [1m[32m0.03516[0m[0m | time: 32.497s
[2K
| RMSProp | epoch: 024 | loss: 0.03516 - acc: 0.9833 -- iter: 1024/1483
[A[ATraining Step: 1114  | total loss: [1m[32m0.04688[0m[0m | time: 33.571s
[2K
| RMSProp | epoch: 024 | loss: 0.04688 - acc: 0.9818 -- iter: 1056/1483
[A[ATraining Step: 1115  | total loss: [1m[32m0.04352[0m[0m | time: 34.433s
[2K
| RMSProp | epoch: 024 | loss: 0.04352 - acc: 0.9837 -- iter: 1088/1483
[A[ATraining Step: 1116  | total loss: [1m[32m0.03940[0m[0m | time: 35.032s
[2K
| RMSProp | epoch: 024 | loss: 0.03940 - acc: 0.9853 -- iter: 1120/1483
[A[ATraining Step: 1117  | total loss: [1m[32m0.03807[0m[0m | time: 35.657s
[2K
| RMSProp | epoch: 024 | loss: 0.03807 - acc: 0.9836 -- iter: 1152/1483
[A[ATraining Step: 1118  | total loss: [1m[32m0.04764[0m[0m | time: 36.283s
[2K
| RMSProp | epoch: 024 | loss: 0.04764 - acc: 0.9790 -- iter: 1184/1483
[A[ATraining Step: 1119  | total loss: [1m[32m0.05994[0m[0m | time: 36.894s
[2K
| RMSProp | epoch: 024 | loss: 0.05994 - acc: 0.9749 -- iter: 1216/1483
[A[ATraining Step: 1120  | total loss: [1m[32m0.17691[0m[0m | time: 37.519s
[2K
| RMSProp | epoch: 024 | loss: 0.17691 - acc: 0.9618 -- iter: 1248/1483
[A[ATraining Step: 1121  | total loss: [1m[32m0.17905[0m[0m | time: 38.127s
[2K
| RMSProp | epoch: 024 | loss: 0.17905 - acc: 0.9593 -- iter: 1280/1483
[A[ATraining Step: 1122  | total loss: [1m[32m0.16377[0m[0m | time: 38.728s
[2K
| RMSProp | epoch: 024 | loss: 0.16377 - acc: 0.9634 -- iter: 1312/1483
[A[ATraining Step: 1123  | total loss: [1m[32m0.14939[0m[0m | time: 39.342s
[2K
| RMSProp | epoch: 024 | loss: 0.14939 - acc: 0.9671 -- iter: 1344/1483
[A[ATraining Step: 1124  | total loss: [1m[32m0.13525[0m[0m | time: 39.975s
[2K
| RMSProp | epoch: 024 | loss: 0.13525 - acc: 0.9704 -- iter: 1376/1483
[A[ATraining Step: 1125  | total loss: [1m[32m0.12260[0m[0m | time: 40.572s
[2K
| RMSProp | epoch: 024 | loss: 0.12260 - acc: 0.9733 -- iter: 1408/1483
[A[ATraining Step: 1126  | total loss: [1m[32m0.11098[0m[0m | time: 41.179s
[2K
| RMSProp | epoch: 024 | loss: 0.11098 - acc: 0.9760 -- iter: 1440/1483
[A[ATraining Step: 1127  | total loss: [1m[32m0.10327[0m[0m | time: 41.784s
[2K
| RMSProp | epoch: 024 | loss: 0.10327 - acc: 0.9753 -- iter: 1472/1483
[A[ATraining Step: 1128  | total loss: [1m[32m0.10326[0m[0m | time: 43.908s
[2K
| RMSProp | epoch: 024 | loss: 0.10326 - acc: 0.9746 | val_loss: 0.55386 - val_acc: 0.8707 -- iter: 1483/1483
--
Training Step: 1129  | total loss: [1m[32m0.09616[0m[0m | time: 0.623s
[2K
| RMSProp | epoch: 025 | loss: 0.09616 - acc: 0.9772 -- iter: 0032/1483
[A[ATraining Step: 1130  | total loss: [1m[32m0.10403[0m[0m | time: 1.233s
[2K
| RMSProp | epoch: 025 | loss: 0.10403 - acc: 0.9732 -- iter: 0064/1483
[A[ATraining Step: 1131  | total loss: [1m[32m0.09464[0m[0m | time: 1.884s
[2K
| RMSProp | epoch: 025 | loss: 0.09464 - acc: 0.9759 -- iter: 0096/1483
[A[ATraining Step: 1132  | total loss: [1m[32m0.10383[0m[0m | time: 2.683s
[2K
| RMSProp | epoch: 025 | loss: 0.10383 - acc: 0.9752 -- iter: 0128/1483
[A[ATraining Step: 1133  | total loss: [1m[32m0.09442[0m[0m | time: 3.331s
[2K
| RMSProp | epoch: 025 | loss: 0.09442 - acc: 0.9776 -- iter: 0160/1483
[A[ATraining Step: 1134  | total loss: [1m[32m0.08544[0m[0m | time: 3.952s
[2K
| RMSProp | epoch: 025 | loss: 0.08544 - acc: 0.9799 -- iter: 0192/1483
[A[ATraining Step: 1135  | total loss: [1m[32m0.07910[0m[0m | time: 4.557s
[2K
| RMSProp | epoch: 025 | loss: 0.07910 - acc: 0.9819 -- iter: 0224/1483
[A[ATraining Step: 1136  | total loss: [1m[32m0.07161[0m[0m | time: 5.161s
[2K
| RMSProp | epoch: 025 | loss: 0.07161 - acc: 0.9837 -- iter: 0256/1483
[A[ATraining Step: 1137  | total loss: [1m[32m0.06471[0m[0m | time: 5.855s
[2K
| RMSProp | epoch: 025 | loss: 0.06471 - acc: 0.9853 -- iter: 0288/1483
[A[ATraining Step: 1138  | total loss: [1m[32m0.05859[0m[0m | time: 6.456s
[2K
| RMSProp | epoch: 025 | loss: 0.05859 - acc: 0.9868 -- iter: 0320/1483
[A[ATraining Step: 1139  | total loss: [1m[32m0.05290[0m[0m | time: 7.052s
[2K
| RMSProp | epoch: 025 | loss: 0.05290 - acc: 0.9881 -- iter: 0352/1483
[A[ATraining Step: 1140  | total loss: [1m[32m0.04882[0m[0m | time: 7.674s
[2K
| RMSProp | epoch: 025 | loss: 0.04882 - acc: 0.9893 -- iter: 0384/1483
[A[ATraining Step: 1141  | total loss: [1m[32m0.04453[0m[0m | time: 8.322s
[2K
| RMSProp | epoch: 025 | loss: 0.04453 - acc: 0.9904 -- iter: 0416/1483
[A[ATraining Step: 1142  | total loss: [1m[32m0.04029[0m[0m | time: 8.934s
[2K
| RMSProp | epoch: 025 | loss: 0.04029 - acc: 0.9913 -- iter: 0448/1483
[A[ATraining Step: 1143  | total loss: [1m[32m0.03638[0m[0m | time: 9.545s
[2K
| RMSProp | epoch: 025 | loss: 0.03638 - acc: 0.9922 -- iter: 0480/1483
[A[ATraining Step: 1144  | total loss: [1m[32m0.03352[0m[0m | time: 10.191s
[2K
| RMSProp | epoch: 025 | loss: 0.03352 - acc: 0.9930 -- iter: 0512/1483
[A[ATraining Step: 1145  | total loss: [1m[32m0.03044[0m[0m | time: 10.813s
[2K
| RMSProp | epoch: 025 | loss: 0.03044 - acc: 0.9937 -- iter: 0544/1483
[A[ATraining Step: 1146  | total loss: [1m[32m0.02756[0m[0m | time: 11.453s
[2K
| RMSProp | epoch: 025 | loss: 0.02756 - acc: 0.9943 -- iter: 0576/1483
[A[ATraining Step: 1147  | total loss: [1m[32m0.02494[0m[0m | time: 12.066s
[2K
| RMSProp | epoch: 025 | loss: 0.02494 - acc: 0.9949 -- iter: 0608/1483
[A[ATraining Step: 1148  | total loss: [1m[32m0.02249[0m[0m | time: 12.724s
[2K
| RMSProp | epoch: 025 | loss: 0.02249 - acc: 0.9954 -- iter: 0640/1483
[A[ATraining Step: 1149  | total loss: [1m[32m0.02031[0m[0m | time: 13.342s
[2K
| RMSProp | epoch: 025 | loss: 0.02031 - acc: 0.9959 -- iter: 0672/1483
[A[ATraining Step: 1150  | total loss: [1m[32m0.01834[0m[0m | time: 13.948s
[2K
| RMSProp | epoch: 025 | loss: 0.01834 - acc: 0.9963 -- iter: 0704/1483
[A[ATraining Step: 1151  | total loss: [1m[32m0.01654[0m[0m | time: 14.190s
[2K
| RMSProp | epoch: 025 | loss: 0.01654 - acc: 0.9966 -- iter: 0736/1483
[A[ATraining Step: 1152  | total loss: [1m[32m0.01490[0m[0m | time: 14.430s
[2K
| RMSProp | epoch: 025 | loss: 0.01490 - acc: 0.9970 -- iter: 0768/1483
[A[ATraining Step: 1153  | total loss: [1m[32m0.01342[0m[0m | time: 15.045s
[2K
| RMSProp | epoch: 025 | loss: 0.01342 - acc: 0.9973 -- iter: 0800/1483
[A[ATraining Step: 1154  | total loss: [1m[32m0.01211[0m[0m | time: 15.666s
[2K
| RMSProp | epoch: 025 | loss: 0.01211 - acc: 0.9976 -- iter: 0832/1483
[A[ATraining Step: 1155  | total loss: [1m[32m0.01100[0m[0m | time: 16.286s
[2K
| RMSProp | epoch: 025 | loss: 0.01100 - acc: 0.9978 -- iter: 0864/1483
[A[ATraining Step: 1156  | total loss: [1m[32m0.00991[0m[0m | time: 16.927s
[2K
| RMSProp | epoch: 025 | loss: 0.00991 - acc: 0.9980 -- iter: 0896/1483
[A[ATraining Step: 1157  | total loss: [1m[32m0.00904[0m[0m | time: 17.542s
[2K
| RMSProp | epoch: 025 | loss: 0.00904 - acc: 0.9982 -- iter: 0928/1483
[A[ATraining Step: 1158  | total loss: [1m[32m0.00814[0m[0m | time: 18.174s
[2K
| RMSProp | epoch: 025 | loss: 0.00814 - acc: 0.9984 -- iter: 0960/1483
[A[ATraining Step: 1159  | total loss: [1m[32m0.00734[0m[0m | time: 18.781s
[2K
| RMSProp | epoch: 025 | loss: 0.00734 - acc: 0.9986 -- iter: 0992/1483
[A[ATraining Step: 1160  | total loss: [1m[32m0.01486[0m[0m | time: 19.415s
[2K
| RMSProp | epoch: 025 | loss: 0.01486 - acc: 0.9956 -- iter: 1024/1483
[A[ATraining Step: 1161  | total loss: [1m[32m0.10490[0m[0m | time: 20.176s
[2K
| RMSProp | epoch: 025 | loss: 0.10490 - acc: 0.9773 -- iter: 1056/1483
[A[ATraining Step: 1162  | total loss: [1m[32m0.10297[0m[0m | time: 21.042s
[2K
| RMSProp | epoch: 025 | loss: 0.10297 - acc: 0.9764 -- iter: 1088/1483
[A[ATraining Step: 1163  | total loss: [1m[32m0.09524[0m[0m | time: 21.811s
[2K
| RMSProp | epoch: 025 | loss: 0.09524 - acc: 0.9788 -- iter: 1120/1483
[A[ATraining Step: 1164  | total loss: [1m[32m0.09409[0m[0m | time: 22.644s
[2K
| RMSProp | epoch: 025 | loss: 0.09409 - acc: 0.9778 -- iter: 1152/1483
[A[ATraining Step: 1165  | total loss: [1m[32m0.08714[0m[0m | time: 23.546s
[2K
| RMSProp | epoch: 025 | loss: 0.08714 - acc: 0.9800 -- iter: 1184/1483
[A[ATraining Step: 1166  | total loss: [1m[32m0.09169[0m[0m | time: 24.363s
[2K
| RMSProp | epoch: 025 | loss: 0.09169 - acc: 0.9789 -- iter: 1216/1483
[A[ATraining Step: 1167  | total loss: [1m[32m0.08478[0m[0m | time: 25.178s
[2K
| RMSProp | epoch: 025 | loss: 0.08478 - acc: 0.9810 -- iter: 1248/1483
[A[ATraining Step: 1168  | total loss: [1m[32m0.11208[0m[0m | time: 26.025s
[2K
| RMSProp | epoch: 025 | loss: 0.11208 - acc: 0.9798 -- iter: 1280/1483
[A[ATraining Step: 1169  | total loss: [1m[32m0.11320[0m[0m | time: 27.069s
[2K
| RMSProp | epoch: 025 | loss: 0.11320 - acc: 0.9787 -- iter: 1312/1483
[A[ATraining Step: 1170  | total loss: [1m[32m0.10396[0m[0m | time: 28.368s
[2K
| RMSProp | epoch: 025 | loss: 0.10396 - acc: 0.9808 -- iter: 1344/1483
[A[ATraining Step: 1171  | total loss: [1m[32m0.10120[0m[0m | time: 29.675s
[2K
| RMSProp | epoch: 025 | loss: 0.10120 - acc: 0.9796 -- iter: 1376/1483
[A[ATraining Step: 1172  | total loss: [1m[32m0.10971[0m[0m | time: 30.794s
[2K
| RMSProp | epoch: 025 | loss: 0.10971 - acc: 0.9754 -- iter: 1408/1483
[A[ATraining Step: 1173  | total loss: [1m[32m0.10487[0m[0m | time: 31.703s
[2K
| RMSProp | epoch: 025 | loss: 0.10487 - acc: 0.9747 -- iter: 1440/1483
[A[ATraining Step: 1174  | total loss: [1m[32m0.09549[0m[0m | time: 32.775s
[2K
| RMSProp | epoch: 025 | loss: 0.09549 - acc: 0.9772 -- iter: 1472/1483
[A[ATraining Step: 1175  | total loss: [1m[32m0.08634[0m[0m | time: 36.509s
[2K
| RMSProp | epoch: 025 | loss: 0.08634 - acc: 0.9795 | val_loss: 0.45009 - val_acc: 0.9030 -- iter: 1483/1483
--
Training Step: 1176  | total loss: [1m[32m0.07815[0m[0m | time: 0.899s
[2K
| RMSProp | epoch: 026 | loss: 0.07815 - acc: 0.9816 -- iter: 0032/1483
[A[ATraining Step: 1177  | total loss: [1m[32m0.07048[0m[0m | time: 2.168s
[2K
| RMSProp | epoch: 026 | loss: 0.07048 - acc: 0.9834 -- iter: 0064/1483
[A[ATraining Step: 1178  | total loss: [1m[32m0.06436[0m[0m | time: 3.525s
[2K
| RMSProp | epoch: 026 | loss: 0.06436 - acc: 0.9851 -- iter: 0096/1483
[A[ATraining Step: 1179  | total loss: [1m[32m0.05819[0m[0m | time: 4.765s
[2K
| RMSProp | epoch: 026 | loss: 0.05819 - acc: 0.9866 -- iter: 0128/1483
[A[ATraining Step: 1180  | total loss: [1m[32m0.05405[0m[0m | time: 5.645s
[2K
| RMSProp | epoch: 026 | loss: 0.05405 - acc: 0.9879 -- iter: 0160/1483
[A[ATraining Step: 1181  | total loss: [1m[32m0.04880[0m[0m | time: 6.623s
[2K
| RMSProp | epoch: 026 | loss: 0.04880 - acc: 0.9891 -- iter: 0192/1483
[A[ATraining Step: 1182  | total loss: [1m[32m0.04416[0m[0m | time: 7.573s
[2K
| RMSProp | epoch: 026 | loss: 0.04416 - acc: 0.9902 -- iter: 0224/1483
[A[ATraining Step: 1183  | total loss: [1m[32m0.03986[0m[0m | time: 8.561s
[2K
| RMSProp | epoch: 026 | loss: 0.03986 - acc: 0.9912 -- iter: 0256/1483
[A[ATraining Step: 1184  | total loss: [1m[32m0.03602[0m[0m | time: 9.594s
[2K
| RMSProp | epoch: 026 | loss: 0.03602 - acc: 0.9921 -- iter: 0288/1483
[A[ATraining Step: 1185  | total loss: [1m[32m0.03327[0m[0m | time: 10.686s
[2K
| RMSProp | epoch: 026 | loss: 0.03327 - acc: 0.9929 -- iter: 0320/1483
[A[ATraining Step: 1186  | total loss: [1m[32m0.03215[0m[0m | time: 11.491s
[2K
| RMSProp | epoch: 026 | loss: 0.03215 - acc: 0.9936 -- iter: 0352/1483
[A[ATraining Step: 1187  | total loss: [1m[32m0.03047[0m[0m | time: 12.685s
[2K
| RMSProp | epoch: 026 | loss: 0.03047 - acc: 0.9942 -- iter: 0384/1483
[A[ATraining Step: 1188  | total loss: [1m[32m0.02793[0m[0m | time: 13.788s
[2K
| RMSProp | epoch: 026 | loss: 0.02793 - acc: 0.9948 -- iter: 0416/1483
[A[ATraining Step: 1189  | total loss: [1m[32m0.04041[0m[0m | time: 15.198s
[2K
| RMSProp | epoch: 026 | loss: 0.04041 - acc: 0.9922 -- iter: 0448/1483
[A[ATraining Step: 1190  | total loss: [1m[32m0.04548[0m[0m | time: 16.143s
[2K
| RMSProp | epoch: 026 | loss: 0.04548 - acc: 0.9898 -- iter: 0480/1483
[A[ATraining Step: 1191  | total loss: [1m[32m0.04180[0m[0m | time: 17.072s
[2K
| RMSProp | epoch: 026 | loss: 0.04180 - acc: 0.9909 -- iter: 0512/1483
[A[ATraining Step: 1192  | total loss: [1m[32m0.04826[0m[0m | time: 18.110s
[2K
| RMSProp | epoch: 026 | loss: 0.04826 - acc: 0.9887 -- iter: 0544/1483
[A[ATraining Step: 1193  | total loss: [1m[32m0.04408[0m[0m | time: 19.127s
[2K
| RMSProp | epoch: 026 | loss: 0.04408 - acc: 0.9898 -- iter: 0576/1483
[A[ATraining Step: 1194  | total loss: [1m[32m0.04082[0m[0m | time: 20.102s
[2K
| RMSProp | epoch: 026 | loss: 0.04082 - acc: 0.9908 -- iter: 0608/1483
[A[ATraining Step: 1195  | total loss: [1m[32m0.03772[0m[0m | time: 21.160s
[2K
| RMSProp | epoch: 026 | loss: 0.03772 - acc: 0.9917 -- iter: 0640/1483
[A[ATraining Step: 1196  | total loss: [1m[32m0.05413[0m[0m | time: 22.109s
[2K
| RMSProp | epoch: 026 | loss: 0.05413 - acc: 0.9863 -- iter: 0672/1483
[A[ATraining Step: 1197  | total loss: [1m[32m0.08344[0m[0m | time: 23.030s
[2K
| RMSProp | epoch: 026 | loss: 0.08344 - acc: 0.9783 -- iter: 0704/1483
[A[ATraining Step: 1198  | total loss: [1m[32m0.08955[0m[0m | time: 24.262s
[2K
| RMSProp | epoch: 026 | loss: 0.08955 - acc: 0.9711 -- iter: 0736/1483
[A[ATraining Step: 1199  | total loss: [1m[32m0.08426[0m[0m | time: 24.759s
[2K
| RMSProp | epoch: 026 | loss: 0.08426 - acc: 0.9740 -- iter: 0768/1483
[A[ATraining Step: 1200  | total loss: [1m[32m0.07645[0m[0m | time: 27.939s
[2K
| RMSProp | epoch: 026 | loss: 0.07645 - acc: 0.9766 | val_loss: 0.40382 - val_acc: 0.8987 -- iter: 0800/1483
--
Training Step: 1201  | total loss: [1m[32m0.06908[0m[0m | time: 28.909s
[2K
| RMSProp | epoch: 026 | loss: 0.06908 - acc: 0.9789 -- iter: 0832/1483
[A[ATraining Step: 1202  | total loss: [1m[32m0.06269[0m[0m | time: 29.910s
[2K
| RMSProp | epoch: 026 | loss: 0.06269 - acc: 0.9810 -- iter: 0864/1483
[A[ATraining Step: 1203  | total loss: [1m[32m0.05833[0m[0m | time: 30.872s
[2K
| RMSProp | epoch: 026 | loss: 0.05833 - acc: 0.9829 -- iter: 0896/1483
[A[ATraining Step: 1204  | total loss: [1m[32m0.05281[0m[0m | time: 32.000s
[2K
| RMSProp | epoch: 026 | loss: 0.05281 - acc: 0.9846 -- iter: 0928/1483
[A[ATraining Step: 1205  | total loss: [1m[32m0.05670[0m[0m | time: 32.944s
[2K
| RMSProp | epoch: 026 | loss: 0.05670 - acc: 0.9830 -- iter: 0960/1483
[A[ATraining Step: 1206  | total loss: [1m[32m0.05198[0m[0m | time: 33.891s
[2K
| RMSProp | epoch: 026 | loss: 0.05198 - acc: 0.9847 -- iter: 0992/1483
[A[ATraining Step: 1207  | total loss: [1m[32m0.04711[0m[0m | time: 35.299s
[2K
| RMSProp | epoch: 026 | loss: 0.04711 - acc: 0.9863 -- iter: 1024/1483
[A[ATraining Step: 1208  | total loss: [1m[32m0.04446[0m[0m | time: 36.711s
[2K
| RMSProp | epoch: 026 | loss: 0.04446 - acc: 0.9876 -- iter: 1056/1483
[A[ATraining Step: 1209  | total loss: [1m[32m0.04028[0m[0m | time: 37.670s
[2K
| RMSProp | epoch: 026 | loss: 0.04028 - acc: 0.9889 -- iter: 1088/1483
[A[ATraining Step: 1210  | total loss: [1m[32m0.04662[0m[0m | time: 38.595s
[2K
| RMSProp | epoch: 026 | loss: 0.04662 - acc: 0.9869 -- iter: 1120/1483
[A[ATraining Step: 1211  | total loss: [1m[32m0.04816[0m[0m | time: 39.610s
[2K
| RMSProp | epoch: 026 | loss: 0.04816 - acc: 0.9851 -- iter: 1152/1483
[A[ATraining Step: 1212  | total loss: [1m[32m0.04657[0m[0m | time: 40.588s
[2K
| RMSProp | epoch: 026 | loss: 0.04657 - acc: 0.9865 -- iter: 1184/1483
[A[ATraining Step: 1213  | total loss: [1m[32m0.04211[0m[0m | time: 41.630s
[2K
| RMSProp | epoch: 026 | loss: 0.04211 - acc: 0.9879 -- iter: 1216/1483
[A[ATraining Step: 1214  | total loss: [1m[32m0.03890[0m[0m | time: 42.671s
[2K
| RMSProp | epoch: 026 | loss: 0.03890 - acc: 0.9891 -- iter: 1248/1483
[A[ATraining Step: 1215  | total loss: [1m[32m0.03549[0m[0m | time: 43.580s
[2K
| RMSProp | epoch: 026 | loss: 0.03549 - acc: 0.9902 -- iter: 1280/1483
[A[ATraining Step: 1216  | total loss: [1m[32m0.03210[0m[0m | time: 44.632s
[2K
| RMSProp | epoch: 026 | loss: 0.03210 - acc: 0.9912 -- iter: 1312/1483
[A[ATraining Step: 1217  | total loss: [1m[32m0.02896[0m[0m | time: 46.040s
[2K
| RMSProp | epoch: 026 | loss: 0.02896 - acc: 0.9921 -- iter: 1344/1483
[A[ATraining Step: 1218  | total loss: [1m[32m0.02609[0m[0m | time: 47.296s
[2K
| RMSProp | epoch: 026 | loss: 0.02609 - acc: 0.9929 -- iter: 1376/1483
[A[ATraining Step: 1219  | total loss: [1m[32m0.03622[0m[0m | time: 48.261s
[2K
| RMSProp | epoch: 026 | loss: 0.03622 - acc: 0.9904 -- iter: 1408/1483
[A[ATraining Step: 1220  | total loss: [1m[32m0.03298[0m[0m | time: 49.216s
[2K
| RMSProp | epoch: 026 | loss: 0.03298 - acc: 0.9914 -- iter: 1440/1483
[A[ATraining Step: 1221  | total loss: [1m[32m0.03006[0m[0m | time: 50.259s
[2K
| RMSProp | epoch: 026 | loss: 0.03006 - acc: 0.9923 -- iter: 1472/1483
[A[ATraining Step: 1222  | total loss: [1m[32m0.02785[0m[0m | time: 53.814s
[2K
| RMSProp | epoch: 026 | loss: 0.02785 - acc: 0.9930 | val_loss: 0.47057 - val_acc: 0.9052 -- iter: 1483/1483
--
Training Step: 1223  | total loss: [1m[32m0.02533[0m[0m | time: 0.919s
[2K
| RMSProp | epoch: 027 | loss: 0.02533 - acc: 0.9937 -- iter: 0032/1483
[A[ATraining Step: 1224  | total loss: [1m[32m0.02312[0m[0m | time: 2.264s
[2K
| RMSProp | epoch: 027 | loss: 0.02312 - acc: 0.9944 -- iter: 0064/1483
[A[ATraining Step: 1225  | total loss: [1m[32m0.02086[0m[0m | time: 3.666s
[2K
| RMSProp | epoch: 027 | loss: 0.02086 - acc: 0.9949 -- iter: 0096/1483
[A[ATraining Step: 1226  | total loss: [1m[32m0.01975[0m[0m | time: 4.918s
[2K
| RMSProp | epoch: 027 | loss: 0.01975 - acc: 0.9954 -- iter: 0128/1483
[A[ATraining Step: 1227  | total loss: [1m[32m0.02021[0m[0m | time: 5.789s
[2K
| RMSProp | epoch: 027 | loss: 0.02021 - acc: 0.9928 -- iter: 0160/1483
[A[ATraining Step: 1228  | total loss: [1m[32m0.03930[0m[0m | time: 6.789s
[2K
| RMSProp | epoch: 027 | loss: 0.03930 - acc: 0.9841 -- iter: 0192/1483
[A[ATraining Step: 1229  | total loss: [1m[32m0.04504[0m[0m | time: 7.758s
[2K
| RMSProp | epoch: 027 | loss: 0.04504 - acc: 0.9794 -- iter: 0224/1483
[A[ATraining Step: 1230  | total loss: [1m[32m0.04208[0m[0m | time: 8.759s
[2K
| RMSProp | epoch: 027 | loss: 0.04208 - acc: 0.9815 -- iter: 0256/1483
[A[ATraining Step: 1231  | total loss: [1m[32m0.03796[0m[0m | time: 9.848s
[2K
| RMSProp | epoch: 027 | loss: 0.03796 - acc: 0.9834 -- iter: 0288/1483
[A[ATraining Step: 1232  | total loss: [1m[32m0.03438[0m[0m | time: 10.912s
[2K
| RMSProp | epoch: 027 | loss: 0.03438 - acc: 0.9850 -- iter: 0320/1483
[A[ATraining Step: 1233  | total loss: [1m[32m0.03124[0m[0m | time: 11.810s
[2K
| RMSProp | epoch: 027 | loss: 0.03124 - acc: 0.9865 -- iter: 0352/1483
[A[ATraining Step: 1234  | total loss: [1m[32m0.02815[0m[0m | time: 13.041s
[2K
| RMSProp | epoch: 027 | loss: 0.02815 - acc: 0.9879 -- iter: 0384/1483
[A[ATraining Step: 1235  | total loss: [1m[32m0.02536[0m[0m | time: 14.362s
[2K
| RMSProp | epoch: 027 | loss: 0.02536 - acc: 0.9891 -- iter: 0416/1483
[A[ATraining Step: 1236  | total loss: [1m[32m0.02288[0m[0m | time: 15.627s
[2K
| RMSProp | epoch: 027 | loss: 0.02288 - acc: 0.9902 -- iter: 0448/1483
[A[ATraining Step: 1237  | total loss: [1m[32m0.02128[0m[0m | time: 16.435s
[2K
| RMSProp | epoch: 027 | loss: 0.02128 - acc: 0.9912 -- iter: 0480/1483
[A[ATraining Step: 1238  | total loss: [1m[32m0.01932[0m[0m | time: 17.365s
[2K
| RMSProp | epoch: 027 | loss: 0.01932 - acc: 0.9920 -- iter: 0512/1483
[A[ATraining Step: 1239  | total loss: [1m[32m0.01741[0m[0m | time: 18.351s
[2K
| RMSProp | epoch: 027 | loss: 0.01741 - acc: 0.9928 -- iter: 0544/1483
[A[ATraining Step: 1240  | total loss: [1m[32m0.01570[0m[0m | time: 19.390s
[2K
| RMSProp | epoch: 027 | loss: 0.01570 - acc: 0.9936 -- iter: 0576/1483
[A[ATraining Step: 1241  | total loss: [1m[32m0.01423[0m[0m | time: 20.491s
[2K
| RMSProp | epoch: 027 | loss: 0.01423 - acc: 0.9942 -- iter: 0608/1483
[A[ATraining Step: 1242  | total loss: [1m[32m0.01285[0m[0m | time: 21.630s
[2K
| RMSProp | epoch: 027 | loss: 0.01285 - acc: 0.9948 -- iter: 0640/1483
[A[ATraining Step: 1243  | total loss: [1m[32m0.01375[0m[0m | time: 22.492s
[2K
| RMSProp | epoch: 027 | loss: 0.01375 - acc: 0.9922 -- iter: 0672/1483
[A[ATraining Step: 1244  | total loss: [1m[32m0.01357[0m[0m | time: 23.497s
[2K
| RMSProp | epoch: 027 | loss: 0.01357 - acc: 0.9930 -- iter: 0704/1483
[A[ATraining Step: 1245  | total loss: [1m[32m0.01222[0m[0m | time: 24.785s
[2K
| RMSProp | epoch: 027 | loss: 0.01222 - acc: 0.9937 -- iter: 0736/1483
[A[ATraining Step: 1246  | total loss: [1m[32m0.01235[0m[0m | time: 26.035s
[2K
| RMSProp | epoch: 027 | loss: 0.01235 - acc: 0.9943 -- iter: 0768/1483
[A[ATraining Step: 1247  | total loss: [1m[32m0.02585[0m[0m | time: 26.540s
[2K
| RMSProp | epoch: 027 | loss: 0.02585 - acc: 0.9917 -- iter: 0800/1483
[A[ATraining Step: 1248  | total loss: [1m[32m0.03925[0m[0m | time: 26.909s
[2K
| RMSProp | epoch: 027 | loss: 0.03925 - acc: 0.9835 -- iter: 0832/1483
[A[ATraining Step: 1249  | total loss: [1m[32m0.03689[0m[0m | time: 27.778s
[2K
| RMSProp | epoch: 027 | loss: 0.03689 - acc: 0.9851 -- iter: 0864/1483
[A[ATraining Step: 1250  | total loss: [1m[32m0.04149[0m[0m | time: 28.754s
[2K
| RMSProp | epoch: 027 | loss: 0.04149 - acc: 0.9835 -- iter: 0896/1483
[A[ATraining Step: 1251  | total loss: [1m[32m0.10582[0m[0m | time: 29.688s
[2K
| RMSProp | epoch: 027 | loss: 0.10582 - acc: 0.9695 -- iter: 0928/1483
[A[ATraining Step: 1252  | total loss: [1m[32m0.09557[0m[0m | time: 30.623s
[2K
| RMSProp | epoch: 027 | loss: 0.09557 - acc: 0.9726 -- iter: 0960/1483
[A[ATraining Step: 1253  | total loss: [1m[32m0.08631[0m[0m | time: 31.665s
[2K
| RMSProp | epoch: 027 | loss: 0.08631 - acc: 0.9753 -- iter: 0992/1483
[A[ATraining Step: 1254  | total loss: [1m[32m0.07825[0m[0m | time: 32.713s
[2K
| RMSProp | epoch: 027 | loss: 0.07825 - acc: 0.9778 -- iter: 1024/1483
[A[ATraining Step: 1255  | total loss: [1m[32m0.07223[0m[0m | time: 33.547s
[2K
| RMSProp | epoch: 027 | loss: 0.07223 - acc: 0.9800 -- iter: 1056/1483
[A[ATraining Step: 1256  | total loss: [1m[32m0.07256[0m[0m | time: 34.807s
[2K
| RMSProp | epoch: 027 | loss: 0.07256 - acc: 0.9789 -- iter: 1088/1483
[A[ATraining Step: 1257  | total loss: [1m[32m0.06598[0m[0m | time: 36.127s
[2K
| RMSProp | epoch: 027 | loss: 0.06598 - acc: 0.9810 -- iter: 1120/1483
[A[ATraining Step: 1258  | total loss: [1m[32m0.05980[0m[0m | time: 37.359s
[2K
| RMSProp | epoch: 027 | loss: 0.05980 - acc: 0.9829 -- iter: 1152/1483
[A[ATraining Step: 1259  | total loss: [1m[32m0.07459[0m[0m | time: 38.268s
[2K
| RMSProp | epoch: 027 | loss: 0.07459 - acc: 0.9815 -- iter: 1184/1483
[A[ATraining Step: 1260  | total loss: [1m[32m0.06926[0m[0m | time: 39.193s
[2K
| RMSProp | epoch: 027 | loss: 0.06926 - acc: 0.9833 -- iter: 1216/1483
[A[ATraining Step: 1261  | total loss: [1m[32m0.08882[0m[0m | time: 40.105s
[2K
| RMSProp | epoch: 027 | loss: 0.08882 - acc: 0.9819 -- iter: 1248/1483
[A[ATraining Step: 1262  | total loss: [1m[32m0.08377[0m[0m | time: 41.042s
[2K
| RMSProp | epoch: 027 | loss: 0.08377 - acc: 0.9837 -- iter: 1280/1483
[A[ATraining Step: 1263  | total loss: [1m[32m0.07706[0m[0m | time: 42.057s
[2K
| RMSProp | epoch: 027 | loss: 0.07706 - acc: 0.9853 -- iter: 1312/1483
[A[ATraining Step: 1264  | total loss: [1m[32m0.09289[0m[0m | time: 43.128s
[2K
| RMSProp | epoch: 027 | loss: 0.09289 - acc: 0.9805 -- iter: 1344/1483
[A[ATraining Step: 1265  | total loss: [1m[32m0.08522[0m[0m | time: 44.123s
[2K
| RMSProp | epoch: 027 | loss: 0.08522 - acc: 0.9825 -- iter: 1376/1483
[A[ATraining Step: 1266  | total loss: [1m[32m0.07712[0m[0m | time: 44.987s
[2K
| RMSProp | epoch: 027 | loss: 0.07712 - acc: 0.9842 -- iter: 1408/1483
[A[ATraining Step: 1267  | total loss: [1m[32m0.07070[0m[0m | time: 46.280s
[2K
| RMSProp | epoch: 027 | loss: 0.07070 - acc: 0.9858 -- iter: 1440/1483
[A[ATraining Step: 1268  | total loss: [1m[32m0.06470[0m[0m | time: 47.591s
[2K
| RMSProp | epoch: 027 | loss: 0.06470 - acc: 0.9872 -- iter: 1472/1483
[A[ATraining Step: 1269  | total loss: [1m[32m0.05844[0m[0m | time: 51.051s
[2K
| RMSProp | epoch: 027 | loss: 0.05844 - acc: 0.9885 | val_loss: 0.46927 - val_acc: 0.9052 -- iter: 1483/1483
--
Training Step: 1270  | total loss: [1m[32m0.05276[0m[0m | time: 0.968s
[2K
| RMSProp | epoch: 028 | loss: 0.05276 - acc: 0.9897 -- iter: 0032/1483
[A[ATraining Step: 1271  | total loss: [1m[32m0.04792[0m[0m | time: 1.962s
[2K
| RMSProp | epoch: 028 | loss: 0.04792 - acc: 0.9907 -- iter: 0064/1483
[A[ATraining Step: 1272  | total loss: [1m[32m0.04320[0m[0m | time: 3.072s
[2K
| RMSProp | epoch: 028 | loss: 0.04320 - acc: 0.9916 -- iter: 0096/1483
[A[ATraining Step: 1273  | total loss: [1m[32m0.03909[0m[0m | time: 4.079s
[2K
| RMSProp | epoch: 028 | loss: 0.03909 - acc: 0.9925 -- iter: 0128/1483
[A[ATraining Step: 1274  | total loss: [1m[32m0.03521[0m[0m | time: 4.921s
[2K
| RMSProp | epoch: 028 | loss: 0.03521 - acc: 0.9932 -- iter: 0160/1483
[A[ATraining Step: 1275  | total loss: [1m[32m0.03173[0m[0m | time: 6.094s
[2K
| RMSProp | epoch: 028 | loss: 0.03173 - acc: 0.9939 -- iter: 0192/1483
[A[ATraining Step: 1276  | total loss: [1m[32m0.03760[0m[0m | time: 7.560s
[2K
| RMSProp | epoch: 028 | loss: 0.03760 - acc: 0.9914 -- iter: 0224/1483
[A[ATraining Step: 1277  | total loss: [1m[32m0.06750[0m[0m | time: 8.811s
[2K
| RMSProp | epoch: 028 | loss: 0.06750 - acc: 0.9797 -- iter: 0256/1483
[A[ATraining Step: 1278  | total loss: [1m[32m0.06288[0m[0m | time: 9.687s
[2K
| RMSProp | epoch: 028 | loss: 0.06288 - acc: 0.9818 -- iter: 0288/1483
[A[ATraining Step: 1279  | total loss: [1m[32m0.05796[0m[0m | time: 10.629s
[2K
| RMSProp | epoch: 028 | loss: 0.05796 - acc: 0.9836 -- iter: 0320/1483
[A[ATraining Step: 1280  | total loss: [1m[32m0.05337[0m[0m | time: 11.587s
[2K
| RMSProp | epoch: 028 | loss: 0.05337 - acc: 0.9852 -- iter: 0352/1483
[A[ATraining Step: 1281  | total loss: [1m[32m0.04941[0m[0m | time: 12.576s
[2K
| RMSProp | epoch: 028 | loss: 0.04941 - acc: 0.9867 -- iter: 0384/1483
[A[ATraining Step: 1282  | total loss: [1m[32m0.04449[0m[0m | time: 13.589s
[2K
| RMSProp | epoch: 028 | loss: 0.04449 - acc: 0.9880 -- iter: 0416/1483
[A[ATraining Step: 1283  | total loss: [1m[32m0.04008[0m[0m | time: 14.669s
[2K
| RMSProp | epoch: 028 | loss: 0.04008 - acc: 0.9892 -- iter: 0448/1483
[A[ATraining Step: 1284  | total loss: [1m[32m0.03611[0m[0m | time: 15.600s
[2K
| RMSProp | epoch: 028 | loss: 0.03611 - acc: 0.9903 -- iter: 0480/1483
[A[ATraining Step: 1285  | total loss: [1m[32m0.03254[0m[0m | time: 16.579s
[2K
| RMSProp | epoch: 028 | loss: 0.03254 - acc: 0.9913 -- iter: 0512/1483
[A[ATraining Step: 1286  | total loss: [1m[32m0.02942[0m[0m | time: 17.921s
[2K
| RMSProp | epoch: 028 | loss: 0.02942 - acc: 0.9922 -- iter: 0544/1483
[A[ATraining Step: 1287  | total loss: [1m[32m0.02798[0m[0m | time: 19.196s
[2K
| RMSProp | epoch: 028 | loss: 0.02798 - acc: 0.9929 -- iter: 0576/1483
[A[ATraining Step: 1288  | total loss: [1m[32m0.02982[0m[0m | time: 20.304s
[2K
| RMSProp | epoch: 028 | loss: 0.02982 - acc: 0.9905 -- iter: 0608/1483
[A[ATraining Step: 1289  | total loss: [1m[32m0.02686[0m[0m | time: 21.248s
[2K
| RMSProp | epoch: 028 | loss: 0.02686 - acc: 0.9915 -- iter: 0640/1483
[A[ATraining Step: 1290  | total loss: [1m[32m0.02418[0m[0m | time: 22.246s
[2K
| RMSProp | epoch: 028 | loss: 0.02418 - acc: 0.9923 -- iter: 0672/1483
[A[ATraining Step: 1291  | total loss: [1m[32m0.02180[0m[0m | time: 23.191s
[2K
| RMSProp | epoch: 028 | loss: 0.02180 - acc: 0.9931 -- iter: 0704/1483
[A[ATraining Step: 1292  | total loss: [1m[32m0.02023[0m[0m | time: 24.249s
[2K
| RMSProp | epoch: 028 | loss: 0.02023 - acc: 0.9938 -- iter: 0736/1483
[A[ATraining Step: 1293  | total loss: [1m[32m0.01830[0m[0m | time: 25.408s
[2K
| RMSProp | epoch: 028 | loss: 0.01830 - acc: 0.9944 -- iter: 0768/1483
[A[ATraining Step: 1294  | total loss: [1m[32m0.01705[0m[0m | time: 26.293s
[2K
| RMSProp | epoch: 028 | loss: 0.01705 - acc: 0.9950 -- iter: 0800/1483
[A[ATraining Step: 1295  | total loss: [1m[32m0.03052[0m[0m | time: 26.638s
[2K
| RMSProp | epoch: 028 | loss: 0.03052 - acc: 0.9923 -- iter: 0832/1483
[A[ATraining Step: 1296  | total loss: [1m[32m0.05033[0m[0m | time: 27.079s
[2K
| RMSProp | epoch: 028 | loss: 0.05033 - acc: 0.9840 -- iter: 0864/1483
[A[ATraining Step: 1297  | total loss: [1m[32m0.04569[0m[0m | time: 28.419s
[2K
| RMSProp | epoch: 028 | loss: 0.04569 - acc: 0.9856 -- iter: 0896/1483
[A[ATraining Step: 1298  | total loss: [1m[32m0.04257[0m[0m | time: 29.837s
[2K
| RMSProp | epoch: 028 | loss: 0.04257 - acc: 0.9871 -- iter: 0928/1483
[A[ATraining Step: 1299  | total loss: [1m[32m0.03873[0m[0m | time: 30.976s
[2K
| RMSProp | epoch: 028 | loss: 0.03873 - acc: 0.9883 -- iter: 0960/1483
[A[ATraining Step: 1300  | total loss: [1m[32m0.03720[0m[0m | time: 31.945s
[2K
| RMSProp | epoch: 028 | loss: 0.03720 - acc: 0.9895 -- iter: 0992/1483
[A[ATraining Step: 1301  | total loss: [1m[32m0.03696[0m[0m | time: 32.948s
[2K
| RMSProp | epoch: 028 | loss: 0.03696 - acc: 0.9874 -- iter: 1024/1483
[A[ATraining Step: 1302  | total loss: [1m[32m0.03342[0m[0m | time: 33.919s
[2K
| RMSProp | epoch: 028 | loss: 0.03342 - acc: 0.9887 -- iter: 1056/1483
[A[ATraining Step: 1303  | total loss: [1m[32m0.03032[0m[0m | time: 34.972s
[2K
| RMSProp | epoch: 028 | loss: 0.03032 - acc: 0.9898 -- iter: 1088/1483
[A[ATraining Step: 1304  | total loss: [1m[32m0.04111[0m[0m | time: 36.057s
[2K
| RMSProp | epoch: 028 | loss: 0.04111 - acc: 0.9877 -- iter: 1120/1483
[A[ATraining Step: 1305  | total loss: [1m[32m0.03740[0m[0m | time: 37.000s
[2K
| RMSProp | epoch: 028 | loss: 0.03740 - acc: 0.9889 -- iter: 1152/1483
[A[ATraining Step: 1306  | total loss: [1m[32m0.03393[0m[0m | time: 38.175s
[2K
| RMSProp | epoch: 028 | loss: 0.03393 - acc: 0.9900 -- iter: 1184/1483
[A[ATraining Step: 1307  | total loss: [1m[32m0.03065[0m[0m | time: 39.651s
[2K
| RMSProp | epoch: 028 | loss: 0.03065 - acc: 0.9910 -- iter: 1216/1483
[A[ATraining Step: 1308  | total loss: [1m[32m0.03253[0m[0m | time: 41.102s
[2K
| RMSProp | epoch: 028 | loss: 0.03253 - acc: 0.9888 -- iter: 1248/1483
[A[ATraining Step: 1309  | total loss: [1m[32m0.05788[0m[0m | time: 41.969s
[2K
| RMSProp | epoch: 028 | loss: 0.05788 - acc: 0.9837 -- iter: 1280/1483
[A[ATraining Step: 1310  | total loss: [1m[32m0.05510[0m[0m | time: 42.946s
[2K
| RMSProp | epoch: 028 | loss: 0.05510 - acc: 0.9853 -- iter: 1312/1483
[A[ATraining Step: 1311  | total loss: [1m[32m0.05025[0m[0m | time: 43.959s
[2K
| RMSProp | epoch: 028 | loss: 0.05025 - acc: 0.9868 -- iter: 1344/1483
[A[ATraining Step: 1312  | total loss: [1m[32m0.11789[0m[0m | time: 44.949s
[2K
| RMSProp | epoch: 028 | loss: 0.11789 - acc: 0.9787 -- iter: 1376/1483
[A[ATraining Step: 1313  | total loss: [1m[32m0.12066[0m[0m | time: 46.024s
[2K
| RMSProp | epoch: 028 | loss: 0.12066 - acc: 0.9809 -- iter: 1408/1483
[A[ATraining Step: 1314  | total loss: [1m[32m0.11090[0m[0m | time: 47.177s
[2K
| RMSProp | epoch: 028 | loss: 0.11090 - acc: 0.9828 -- iter: 1440/1483
[A[ATraining Step: 1315  | total loss: [1m[32m0.10079[0m[0m | time: 48.067s
[2K
| RMSProp | epoch: 028 | loss: 0.10079 - acc: 0.9845 -- iter: 1472/1483
[A[ATraining Step: 1316  | total loss: [1m[32m0.09366[0m[0m | time: 52.294s
[2K
| RMSProp | epoch: 028 | loss: 0.09366 - acc: 0.9860 | val_loss: 0.44082 - val_acc: 0.8944 -- iter: 1483/1483
--
Training Step: 1317  | total loss: [1m[32m0.08895[0m[0m | time: 0.834s
[2K
| RMSProp | epoch: 029 | loss: 0.08895 - acc: 0.9843 -- iter: 0032/1483
[A[ATraining Step: 1318  | total loss: [1m[32m0.08097[0m[0m | time: 1.789s
[2K
| RMSProp | epoch: 029 | loss: 0.08097 - acc: 0.9859 -- iter: 0064/1483
[A[ATraining Step: 1319  | total loss: [1m[32m0.07525[0m[0m | time: 2.757s
[2K
| RMSProp | epoch: 029 | loss: 0.07525 - acc: 0.9873 -- iter: 0096/1483
[A[ATraining Step: 1320  | total loss: [1m[32m0.06789[0m[0m | time: 3.730s
[2K
| RMSProp | epoch: 029 | loss: 0.06789 - acc: 0.9886 -- iter: 0128/1483
[A[ATraining Step: 1321  | total loss: [1m[32m0.06965[0m[0m | time: 4.738s
[2K
| RMSProp | epoch: 029 | loss: 0.06965 - acc: 0.9835 -- iter: 0160/1483
[A[ATraining Step: 1322  | total loss: [1m[32m0.09053[0m[0m | time: 5.889s
[2K
| RMSProp | epoch: 029 | loss: 0.09053 - acc: 0.9757 -- iter: 0192/1483
[A[ATraining Step: 1323  | total loss: [1m[32m0.08401[0m[0m | time: 6.778s
[2K
| RMSProp | epoch: 029 | loss: 0.08401 - acc: 0.9782 -- iter: 0224/1483
[A[ATraining Step: 1324  | total loss: [1m[32m0.07704[0m[0m | time: 7.824s
[2K
| RMSProp | epoch: 029 | loss: 0.07704 - acc: 0.9803 -- iter: 0256/1483
[A[ATraining Step: 1325  | total loss: [1m[32m0.07018[0m[0m | time: 9.183s
[2K
| RMSProp | epoch: 029 | loss: 0.07018 - acc: 0.9823 -- iter: 0288/1483
[A[ATraining Step: 1326  | total loss: [1m[32m0.06343[0m[0m | time: 10.495s
[2K
| RMSProp | epoch: 029 | loss: 0.06343 - acc: 0.9841 -- iter: 0320/1483
[A[ATraining Step: 1327  | total loss: [1m[32m0.05737[0m[0m | time: 11.537s
[2K
| RMSProp | epoch: 029 | loss: 0.05737 - acc: 0.9857 -- iter: 0352/1483
[A[ATraining Step: 1328  | total loss: [1m[32m0.05291[0m[0m | time: 12.465s
[2K
| RMSProp | epoch: 029 | loss: 0.05291 - acc: 0.9871 -- iter: 0384/1483
[A[ATraining Step: 1329  | total loss: [1m[32m0.06038[0m[0m | time: 13.448s
[2K
| RMSProp | epoch: 029 | loss: 0.06038 - acc: 0.9853 -- iter: 0416/1483
[A[ATraining Step: 1330  | total loss: [1m[32m0.05668[0m[0m | time: 14.418s
[2K
| RMSProp | epoch: 029 | loss: 0.05668 - acc: 0.9867 -- iter: 0448/1483
[A[ATraining Step: 1331  | total loss: [1m[32m0.05315[0m[0m | time: 15.373s
[2K
| RMSProp | epoch: 029 | loss: 0.05315 - acc: 0.9881 -- iter: 0480/1483
[A[ATraining Step: 1332  | total loss: [1m[32m0.04889[0m[0m | time: 16.409s
[2K
| RMSProp | epoch: 029 | loss: 0.04889 - acc: 0.9893 -- iter: 0512/1483
[A[ATraining Step: 1333  | total loss: [1m[32m0.04432[0m[0m | time: 17.359s
[2K
| RMSProp | epoch: 029 | loss: 0.04432 - acc: 0.9903 -- iter: 0544/1483
[A[ATraining Step: 1334  | total loss: [1m[32m0.04007[0m[0m | time: 18.319s
[2K
| RMSProp | epoch: 029 | loss: 0.04007 - acc: 0.9913 -- iter: 0576/1483
[A[ATraining Step: 1335  | total loss: [1m[32m0.03758[0m[0m | time: 19.576s
[2K
| RMSProp | epoch: 029 | loss: 0.03758 - acc: 0.9922 -- iter: 0608/1483
[A[ATraining Step: 1336  | total loss: [1m[32m0.03432[0m[0m | time: 21.101s
[2K
| RMSProp | epoch: 029 | loss: 0.03432 - acc: 0.9930 -- iter: 0640/1483
[A[ATraining Step: 1337  | total loss: [1m[32m0.03098[0m[0m | time: 22.168s
[2K
| RMSProp | epoch: 029 | loss: 0.03098 - acc: 0.9937 -- iter: 0672/1483
[A[ATraining Step: 1338  | total loss: [1m[32m0.04509[0m[0m | time: 23.044s
[2K
| RMSProp | epoch: 029 | loss: 0.04509 - acc: 0.9912 -- iter: 0704/1483
[A[ATraining Step: 1339  | total loss: [1m[32m0.04150[0m[0m | time: 23.992s
[2K
| RMSProp | epoch: 029 | loss: 0.04150 - acc: 0.9921 -- iter: 0736/1483
[A[ATraining Step: 1340  | total loss: [1m[32m0.03825[0m[0m | time: 24.970s
[2K
| RMSProp | epoch: 029 | loss: 0.03825 - acc: 0.9928 -- iter: 0768/1483
[A[ATraining Step: 1341  | total loss: [1m[32m0.03478[0m[0m | time: 25.994s
[2K
| RMSProp | epoch: 029 | loss: 0.03478 - acc: 0.9936 -- iter: 0800/1483
[A[ATraining Step: 1342  | total loss: [1m[32m0.03149[0m[0m | time: 27.095s
[2K
| RMSProp | epoch: 029 | loss: 0.03149 - acc: 0.9942 -- iter: 0832/1483
[A[ATraining Step: 1343  | total loss: [1m[32m0.04051[0m[0m | time: 27.510s
[2K
| RMSProp | epoch: 029 | loss: 0.04051 - acc: 0.9917 -- iter: 0864/1483
[A[ATraining Step: 1344  | total loss: [1m[32m0.04158[0m[0m | time: 27.850s
[2K
| RMSProp | epoch: 029 | loss: 0.04158 - acc: 0.9925 -- iter: 0896/1483
[A[ATraining Step: 1345  | total loss: [1m[32m0.03761[0m[0m | time: 28.706s
[2K
| RMSProp | epoch: 029 | loss: 0.03761 - acc: 0.9932 -- iter: 0928/1483
[A[ATraining Step: 1346  | total loss: [1m[32m0.03867[0m[0m | time: 29.984s
[2K
| RMSProp | epoch: 029 | loss: 0.03867 - acc: 0.9908 -- iter: 0960/1483
[A[ATraining Step: 1347  | total loss: [1m[32m0.04334[0m[0m | time: 31.455s
[2K
| RMSProp | epoch: 029 | loss: 0.04334 - acc: 0.9886 -- iter: 0992/1483
[A[ATraining Step: 1348  | total loss: [1m[32m0.04104[0m[0m | time: 32.601s
[2K
| RMSProp | epoch: 029 | loss: 0.04104 - acc: 0.9897 -- iter: 1024/1483
[A[ATraining Step: 1349  | total loss: [1m[32m0.03769[0m[0m | time: 33.498s
[2K
| RMSProp | epoch: 029 | loss: 0.03769 - acc: 0.9908 -- iter: 1056/1483
[A[ATraining Step: 1350  | total loss: [1m[32m0.03428[0m[0m | time: 34.533s
[2K
| RMSProp | epoch: 029 | loss: 0.03428 - acc: 0.9917 -- iter: 1088/1483
[A[ATraining Step: 1351  | total loss: [1m[32m0.03087[0m[0m | time: 35.566s
[2K
| RMSProp | epoch: 029 | loss: 0.03087 - acc: 0.9925 -- iter: 1120/1483
[A[ATraining Step: 1352  | total loss: [1m[32m0.02781[0m[0m | time: 36.553s
[2K
| RMSProp | epoch: 029 | loss: 0.02781 - acc: 0.9933 -- iter: 1152/1483
[A[ATraining Step: 1353  | total loss: [1m[32m0.02515[0m[0m | time: 37.648s
[2K
| RMSProp | epoch: 029 | loss: 0.02515 - acc: 0.9939 -- iter: 1184/1483
[A[ATraining Step: 1354  | total loss: [1m[32m0.05978[0m[0m | time: 38.568s
[2K
| RMSProp | epoch: 029 | loss: 0.05978 - acc: 0.9914 -- iter: 1216/1483
[A[ATraining Step: 1355  | total loss: [1m[32m0.06620[0m[0m | time: 39.640s
[2K
| RMSProp | epoch: 029 | loss: 0.06620 - acc: 0.9860 -- iter: 1248/1483
[A[ATraining Step: 1356  | total loss: [1m[32m0.06052[0m[0m | time: 40.953s
[2K
| RMSProp | epoch: 029 | loss: 0.06052 - acc: 0.9874 -- iter: 1280/1483
[A[ATraining Step: 1357  | total loss: [1m[32m0.06087[0m[0m | time: 42.230s
[2K
| RMSProp | epoch: 029 | loss: 0.06087 - acc: 0.9824 -- iter: 1312/1483
[A[ATraining Step: 1358  | total loss: [1m[32m0.06529[0m[0m | time: 43.306s
[2K
| RMSProp | epoch: 029 | loss: 0.06529 - acc: 0.9811 -- iter: 1344/1483
[A[ATraining Step: 1359  | total loss: [1m[32m0.05920[0m[0m | time: 44.172s
[2K
| RMSProp | epoch: 029 | loss: 0.05920 - acc: 0.9830 -- iter: 1376/1483
[A[ATraining Step: 1360  | total loss: [1m[32m0.16176[0m[0m | time: 45.123s
[2K
| RMSProp | epoch: 029 | loss: 0.16176 - acc: 0.9628 -- iter: 1408/1483
[A[ATraining Step: 1361  | total loss: [1m[32m0.17867[0m[0m | time: 46.090s
[2K
| RMSProp | epoch: 029 | loss: 0.17867 - acc: 0.9509 -- iter: 1440/1483
[A[ATraining Step: 1362  | total loss: [1m[32m0.16416[0m[0m | time: 47.114s
[2K
| RMSProp | epoch: 029 | loss: 0.16416 - acc: 0.9558 -- iter: 1472/1483
[A[ATraining Step: 1363  | total loss: [1m[32m0.15232[0m[0m | time: 50.409s
[2K
| RMSProp | epoch: 029 | loss: 0.15232 - acc: 0.9571 | val_loss: 0.38461 - val_acc: 0.8901 -- iter: 1483/1483
--
Training Step: 1364  | total loss: [1m[32m0.13785[0m[0m | time: 1.532s
[2K
| RMSProp | epoch: 030 | loss: 0.13785 - acc: 0.9614 -- iter: 0032/1483
[A[ATraining Step: 1365  | total loss: [1m[32m0.12931[0m[0m | time: 2.914s
[2K
| RMSProp | epoch: 030 | loss: 0.12931 - acc: 0.9621 -- iter: 0064/1483
[A[ATraining Step: 1366  | total loss: [1m[32m0.13206[0m[0m | time: 3.898s
[2K
| RMSProp | epoch: 030 | loss: 0.13206 - acc: 0.9628 -- iter: 0096/1483
[A[ATraining Step: 1367  | total loss: [1m[32m0.12347[0m[0m | time: 4.833s
[2K
| RMSProp | epoch: 030 | loss: 0.12347 - acc: 0.9634 -- iter: 0128/1483
[A[ATraining Step: 1368  | total loss: [1m[32m0.11405[0m[0m | time: 5.784s
[2K
| RMSProp | epoch: 030 | loss: 0.11405 - acc: 0.9670 -- iter: 0160/1483
[A[ATraining Step: 1369  | total loss: [1m[32m0.11091[0m[0m | time: 6.720s
[2K
| RMSProp | epoch: 030 | loss: 0.11091 - acc: 0.9672 -- iter: 0192/1483
[A[ATraining Step: 1370  | total loss: [1m[32m0.10864[0m[0m | time: 7.780s
[2K
| RMSProp | epoch: 030 | loss: 0.10864 - acc: 0.9674 -- iter: 0224/1483
[A[ATraining Step: 1371  | total loss: [1m[32m0.09996[0m[0m | time: 8.834s
[2K
| RMSProp | epoch: 030 | loss: 0.09996 - acc: 0.9706 -- iter: 0256/1483
[A[ATraining Step: 1372  | total loss: [1m[32m0.09074[0m[0m | time: 9.728s
[2K
| RMSProp | epoch: 030 | loss: 0.09074 - acc: 0.9736 -- iter: 0288/1483
[A[ATraining Step: 1373  | total loss: [1m[32m0.08208[0m[0m | time: 10.733s
[2K
| RMSProp | epoch: 030 | loss: 0.08208 - acc: 0.9762 -- iter: 0320/1483
[A[ATraining Step: 1374  | total loss: [1m[32m0.07406[0m[0m | time: 12.100s
[2K
| RMSProp | epoch: 030 | loss: 0.07406 - acc: 0.9786 -- iter: 0352/1483
[A[ATraining Step: 1375  | total loss: [1m[32m0.06795[0m[0m | time: 13.601s
[2K
| RMSProp | epoch: 030 | loss: 0.06795 - acc: 0.9807 -- iter: 0384/1483
[A[ATraining Step: 1376  | total loss: [1m[32m0.06279[0m[0m | time: 14.476s
[2K
| RMSProp | epoch: 030 | loss: 0.06279 - acc: 0.9827 -- iter: 0416/1483
[A[ATraining Step: 1377  | total loss: [1m[32m0.05661[0m[0m | time: 15.382s
[2K
| RMSProp | epoch: 030 | loss: 0.05661 - acc: 0.9844 -- iter: 0448/1483
[A[ATraining Step: 1378  | total loss: [1m[32m0.05105[0m[0m | time: 16.370s
[2K
| RMSProp | epoch: 030 | loss: 0.05105 - acc: 0.9860 -- iter: 0480/1483
[A[ATraining Step: 1379  | total loss: [1m[32m0.04687[0m[0m | time: 17.388s
[2K
| RMSProp | epoch: 030 | loss: 0.04687 - acc: 0.9874 -- iter: 0512/1483
[A[ATraining Step: 1380  | total loss: [1m[32m0.04225[0m[0m | time: 18.372s
[2K
| RMSProp | epoch: 030 | loss: 0.04225 - acc: 0.9886 -- iter: 0544/1483
[A[ATraining Step: 1381  | total loss: [1m[32m0.03809[0m[0m | time: 19.509s
[2K
| RMSProp | epoch: 030 | loss: 0.03809 - acc: 0.9898 -- iter: 0576/1483
[A[ATraining Step: 1382  | total loss: [1m[32m0.03431[0m[0m | time: 20.403s
[2K
| RMSProp | epoch: 030 | loss: 0.03431 - acc: 0.9908 -- iter: 0608/1483
[A[ATraining Step: 1383  | total loss: [1m[32m0.03098[0m[0m | time: 21.450s
[2K
| RMSProp | epoch: 030 | loss: 0.03098 - acc: 0.9917 -- iter: 0640/1483
[A[ATraining Step: 1384  | total loss: [1m[32m0.02791[0m[0m | time: 22.885s
[2K
| RMSProp | epoch: 030 | loss: 0.02791 - acc: 0.9925 -- iter: 0672/1483
[A[ATraining Step: 1385  | total loss: [1m[32m0.02544[0m[0m | time: 24.158s
[2K
| RMSProp | epoch: 030 | loss: 0.02544 - acc: 0.9933 -- iter: 0704/1483
[A[ATraining Step: 1386  | total loss: [1m[32m0.02291[0m[0m | time: 25.223s
[2K
| RMSProp | epoch: 030 | loss: 0.02291 - acc: 0.9940 -- iter: 0736/1483
[A[ATraining Step: 1387  | total loss: [1m[32m0.04049[0m[0m | time: 26.090s
[2K
| RMSProp | epoch: 030 | loss: 0.04049 - acc: 0.9914 -- iter: 0768/1483
[A[ATraining Step: 1388  | total loss: [1m[32m0.04663[0m[0m | time: 27.126s
[2K
| RMSProp | epoch: 030 | loss: 0.04663 - acc: 0.9860 -- iter: 0800/1483
[A[ATraining Step: 1389  | total loss: [1m[32m0.04693[0m[0m | time: 28.034s
[2K
| RMSProp | epoch: 030 | loss: 0.04693 - acc: 0.9874 -- iter: 0832/1483
[A[ATraining Step: 1390  | total loss: [1m[32m0.04334[0m[0m | time: 28.944s
[2K
| RMSProp | epoch: 030 | loss: 0.04334 - acc: 0.9887 -- iter: 0864/1483
[A[ATraining Step: 1391  | total loss: [1m[32m0.03919[0m[0m | time: 29.364s
[2K
| RMSProp | epoch: 030 | loss: 0.03919 - acc: 0.9898 -- iter: 0896/1483
[A[ATraining Step: 1392  | total loss: [1m[32m0.03547[0m[0m | time: 29.776s
[2K
| RMSProp | epoch: 030 | loss: 0.03547 - acc: 0.9908 -- iter: 0928/1483
[A[ATraining Step: 1393  | total loss: [1m[32m0.03201[0m[0m | time: 30.823s
[2K
| RMSProp | epoch: 030 | loss: 0.03201 - acc: 0.9918 -- iter: 0960/1483
[A[ATraining Step: 1394  | total loss: [1m[32m0.02906[0m[0m | time: 31.691s
[2K
| RMSProp | epoch: 030 | loss: 0.02906 - acc: 0.9926 -- iter: 0992/1483
[A[ATraining Step: 1395  | total loss: [1m[32m0.02627[0m[0m | time: 32.852s
[2K
| RMSProp | epoch: 030 | loss: 0.02627 - acc: 0.9933 -- iter: 1024/1483
[A[ATraining Step: 1396  | total loss: [1m[32m0.02392[0m[0m | time: 34.259s
[2K
| RMSProp | epoch: 030 | loss: 0.02392 - acc: 0.9940 -- iter: 1056/1483
[A[ATraining Step: 1397  | total loss: [1m[32m0.02177[0m[0m | time: 35.571s
[2K
| RMSProp | epoch: 030 | loss: 0.02177 - acc: 0.9946 -- iter: 1088/1483
[A[ATraining Step: 1398  | total loss: [1m[32m0.01977[0m[0m | time: 36.484s
[2K
| RMSProp | epoch: 030 | loss: 0.01977 - acc: 0.9951 -- iter: 1120/1483
[A[ATraining Step: 1399  | total loss: [1m[32m0.01907[0m[0m | time: 37.403s
[2K
| RMSProp | epoch: 030 | loss: 0.01907 - acc: 0.9956 -- iter: 1152/1483
[A[ATraining Step: 1400  | total loss: [1m[32m0.02669[0m[0m | time: 41.023s
[2K
| RMSProp | epoch: 030 | loss: 0.02669 - acc: 0.9929 | val_loss: 0.66428 - val_acc: 0.8211 -- iter: 1184/1483
--
Training Step: 1401  | total loss: [1m[32m0.04486[0m[0m | time: 42.112s
[2K
| RMSProp | epoch: 030 | loss: 0.04486 - acc: 0.9874 -- iter: 1216/1483
[A[ATraining Step: 1402  | total loss: [1m[32m0.06216[0m[0m | time: 42.915s
[2K
| RMSProp | epoch: 030 | loss: 0.06216 - acc: 0.9793 -- iter: 1248/1483
[A[ATraining Step: 1403  | total loss: [1m[32m0.06055[0m[0m | time: 44.039s
[2K
| RMSProp | epoch: 030 | loss: 0.06055 - acc: 0.9782 -- iter: 1280/1483
[A[ATraining Step: 1404  | total loss: [1m[32m0.05685[0m[0m | time: 45.373s
[2K
| RMSProp | epoch: 030 | loss: 0.05685 - acc: 0.9804 -- iter: 1312/1483
[A[ATraining Step: 1405  | total loss: [1m[32m0.05174[0m[0m | time: 46.738s
[2K
| RMSProp | epoch: 030 | loss: 0.05174 - acc: 0.9824 -- iter: 1344/1483
[A[ATraining Step: 1406  | total loss: [1m[32m0.04704[0m[0m | time: 47.670s
[2K
| RMSProp | epoch: 030 | loss: 0.04704 - acc: 0.9841 -- iter: 1376/1483
[A[ATraining Step: 1407  | total loss: [1m[32m0.04263[0m[0m | time: 48.620s
[2K
| RMSProp | epoch: 030 | loss: 0.04263 - acc: 0.9857 -- iter: 1408/1483
[A[ATraining Step: 1408  | total loss: [1m[32m0.06375[0m[0m | time: 49.630s
[2K
| RMSProp | epoch: 030 | loss: 0.06375 - acc: 0.9840 -- iter: 1440/1483
[A[ATraining Step: 1409  | total loss: [1m[32m0.05922[0m[0m | time: 50.667s
[2K
| RMSProp | epoch: 030 | loss: 0.05922 - acc: 0.9856 -- iter: 1472/1483
[A[ATraining Step: 1410  | total loss: [1m[32m0.06182[0m[0m | time: 54.093s
[2K
| RMSProp | epoch: 030 | loss: 0.06182 - acc: 0.9839 | val_loss: 0.46206 - val_acc: 0.8922 -- iter: 1483/1483
--
Validation AUC:0.9451105039127121
Validation AUPRC:0.954731536966693
Test AUC:0.9500402147279428
Test AUPRC:0.9618517774670121
BestTestF1Score	0.91	0.81	0.9	0.94	0.88	221	15	198	30	0.15
BestTestMCCScore	0.91	0.81	0.9	0.94	0.88	221	15	198	30	0.15
BestTestAccuracyScore	0.91	0.81	0.9	0.94	0.88	221	15	198	30	0.15
BestValidationF1Score	0.9	0.79	0.89	0.91	0.88	209	21	206	28	0.15
BestValidationMCC	0.9	0.79	0.89	0.91	0.88	209	21	206	28	0.15
BestValidationAccuracy	0.9	0.79	0.89	0.91	0.88	209	21	206	28	0.15
TestPredictions (Threshold:0.15)
CHEMBL52785,TN,INACT,0.009999999776482582	CHEMBL83226,TP,ACT,1.0	CHEMBL633,TN,INACT,0.0	CHEMBL301826,TN,INACT,0.0	CHEMBL285380,TN,INACT,0.0	CHEMBL301224,TP,ACT,1.0	CHEMBL11592,FP,INACT,0.9399999976158142	CHEMBL3604309,TN,INACT,0.009999999776482582	CHEMBL134428,TP,ACT,1.0	CHEMBL549764,TP,ACT,0.7799999713897705	CHEMBL1796031,TP,ACT,0.8700000047683716	CHEMBL312266,TN,INACT,0.0	CHEMBL91616,TP,ACT,1.0	CHEMBL445071,TP,ACT,1.0	CHEMBL279520,TN,INACT,0.0	CHEMBL95523,TP,ACT,0.9900000095367432	CHEMBL291293,TN,INACT,0.0	CHEMBL1630940,TP,ACT,1.0	CHEMBL460470,TN,INACT,0.009999999776482582	CHEMBL118553,TN,INACT,0.009999999776482582	CHEMBL299561,TN,INACT,0.0	CHEMBL62028,TP,ACT,1.0	CHEMBL1180343,TN,INACT,0.0	CHEMBL242723,TP,ACT,0.9900000095367432	CHEMBL149763,TN,INACT,0.0	CHEMBL315974,TN,INACT,0.009999999776482582	CHEMBL241100,FP,INACT,0.9900000095367432	CHEMBL228554,TP,ACT,0.9900000095367432	CHEMBL68964,TN,INACT,0.0	CHEMBL283535,TN,INACT,0.0	CHEMBL1242923,FN,ACT,0.019999999552965164	CHEMBL3400593,TP,ACT,0.8299999833106995	CHEMBL145587,TP,ACT,1.0	CHEMBL71479,FN,ACT,0.009999999776482582	CHEMBL304591,TP,ACT,0.30000001192092896	CHEMBL83041,TP,ACT,1.0	CHEMBL20168,TN,INACT,0.0	CHEMBL54246,TN,INACT,0.0	CHEMBL99979,FN,ACT,0.019999999552965164	CHEMBL202861,TN,INACT,0.0	CHEMBL90652,TP,ACT,1.0	CHEMBL257547,FP,INACT,0.9900000095367432	CHEMBL42220,TP,ACT,1.0	CHEMBL143539,TN,INACT,0.009999999776482582	CHEMBL160396,FP,INACT,0.9200000166893005	CHEMBL210578,FN,ACT,0.0	CHEMBL319387,TN,INACT,0.0	CHEMBL228658,TP,ACT,1.0	CHEMBL2419772,TP,ACT,1.0	CHEMBL3085215,TN,INACT,0.0	CHEMBL3342871,TP,ACT,1.0	CHEMBL1078954,TP,ACT,0.9900000095367432	CHEMBL234771,TN,INACT,0.0	CHEMBL286591,TP,ACT,0.28999999165534973	CHEMBL299984,TP,ACT,1.0	CHEMBL140450,FN,ACT,0.009999999776482582	CHEMBL461709,TN,INACT,0.009999999776482582	CHEMBL357842,TP,ACT,1.0	CHEMBL56489,TP,ACT,1.0	CHEMBL58476,TP,ACT,1.0	CHEMBL1796029,TP,ACT,0.9800000190734863	CHEMBL277375,TP,ACT,1.0	CHEMBL434228,TP,ACT,0.6899999976158142	CHEMBL21508,TN,INACT,0.0	CHEMBL145459,TP,ACT,1.0	CHEMBL1254582,TP,ACT,1.0	CHEMBL266290,TN,INACT,0.0	CHEMBL2312536,TP,ACT,0.9900000095367432	CHEMBL301726,TP,ACT,1.0	CHEMBL1767168,TP,ACT,1.0	CHEMBL99864,TP,ACT,1.0	CHEMBL1762308,TN,INACT,0.03999999910593033	CHEMBL145332,TP,ACT,1.0	CHEMBL78624,TN,INACT,0.019999999552965164	CHEMBL62045,TP,ACT,1.0	CHEMBL55882,TP,ACT,0.9700000286102295	CHEMBL1796046,TP,ACT,1.0	CHEMBL145793,TP,ACT,0.9300000071525574	CHEMBL2205808,TN,INACT,0.019999999552965164	CHEMBL117381,TP,ACT,1.0	CHEMBL299914,TP,ACT,1.0	CHEMBL148552,TP,ACT,1.0	CHEMBL302092,TP,ACT,1.0	CHEMBL142811,TN,INACT,0.019999999552965164	CHEMBL388361,TP,ACT,1.0	CHEMBL296245,TN,INACT,0.0	CHEMBL284470,TP,ACT,0.9900000095367432	CHEMBL61491,TP,ACT,1.0	CHEMBL233584,TP,ACT,1.0	CHEMBL80945,TN,INACT,0.009999999776482582	CHEMBL74114,FN,ACT,0.009999999776482582	CHEMBL59702,FP,INACT,1.0	CHEMBL116292,FN,ACT,0.0	CHEMBL26907,TN,INACT,0.0	CHEMBL3577342,TN,INACT,0.0	CHEMBL3739542,TP,ACT,1.0	CHEMBL130861,TN,INACT,0.0	CHEMBL439197,TP,ACT,1.0	CHEMBL436407,TP,ACT,1.0	CHEMBL63905,FP,INACT,0.9200000166893005	CHEMBL426385,FP,INACT,0.8700000047683716	CHEMBL268190,TN,INACT,0.0	CHEMBL15936,TN,INACT,0.0	CHEMBL1256414,FN,ACT,0.0	CHEMBL375591,TN,INACT,0.0	CHEMBL233592,TP,ACT,1.0	CHEMBL595265,TN,INACT,0.0	CHEMBL240895,TN,INACT,0.009999999776482582	CHEMBL148967,TN,INACT,0.0	CHEMBL437842,TN,INACT,0.0	CHEMBL214694,TP,ACT,1.0	CHEMBL405292,TN,INACT,0.019999999552965164	CHEMBL234423,TP,ACT,1.0	CHEMBL104210,TN,INACT,0.0	CHEMBL421349,TN,INACT,0.0	CHEMBL240001,TN,INACT,0.019999999552965164	CHEMBL292521,TN,INACT,0.009999999776482582	CHEMBL90421,TP,ACT,1.0	CHEMBL323579,TP,ACT,1.0	CHEMBL300766,TP,ACT,1.0	CHEMBL142957,TP,ACT,1.0	CHEMBL61643,TP,ACT,0.9599999785423279	CHEMBL267044,TN,INACT,0.0	CHEMBL295698,TN,INACT,0.0	CHEMBL93693,TP,ACT,1.0	CHEMBL137598,TP,ACT,0.9900000095367432	CHEMBL441305,TN,INACT,0.009999999776482582	CHEMBL3810005,TP,ACT,1.0	CHEMBL639,FN,ACT,0.0	CHEMBL1255616,TP,ACT,0.9599999785423279	CHEMBL3343975,TP,ACT,0.9599999785423279	CHEMBL294235,TP,ACT,0.949999988079071	CHEMBL2436715,TN,INACT,0.0	CHEMBL293149,TP,ACT,0.9900000095367432	CHEMBL3323005,TN,INACT,0.10000000149011612	CHEMBL104377,FP,INACT,0.800000011920929	CHEMBL594803,TN,INACT,0.0	CHEMBL593443,TN,INACT,0.009999999776482582	CHEMBL101054,TN,INACT,0.029999999329447746	CHEMBL59149,TP,ACT,1.0	CHEMBL2436717,TN,INACT,0.009999999776482582	CHEMBL344752,TN,INACT,0.019999999552965164	CHEMBL252232,TN,INACT,0.0	CHEMBL2062852,TN,INACT,0.0	CHEMBL327931,TP,ACT,1.0	CHEMBL320763,TN,INACT,0.0	CHEMBL49137,TP,ACT,0.9700000286102295	CHEMBL286139,TN,INACT,0.0	CHEMBL1091777,TN,INACT,0.0	CHEMBL297215,TN,INACT,0.0	CHEMBL267094,TN,INACT,0.0	CHEMBL1256565,TP,ACT,0.800000011920929	CHEMBL322405,FN,ACT,0.009999999776482582	CHEMBL135335,TN,INACT,0.009999999776482582	CHEMBL328763,TP,ACT,1.0	CHEMBL3742253,TP,ACT,1.0	CHEMBL1254743,TP,ACT,1.0	CHEMBL88506,TN,INACT,0.009999999776482582	CHEMBL2312376,TN,INACT,0.009999999776482582	CHEMBL13754,TP,ACT,0.9800000190734863	CHEMBL113472,TN,INACT,0.0	CHEMBL74283,TP,ACT,0.9900000095367432	CHEMBL553666,TN,INACT,0.07999999821186066	CHEMBL553276,TP,ACT,0.2199999988079071	CHEMBL539334,TN,INACT,0.0	CHEMBL298649,TN,INACT,0.0	CHEMBL145178,TP,ACT,1.0	CHEMBL42539,TP,ACT,0.9800000190734863	CHEMBL2153554,TP,ACT,1.0	CHEMBL359012,TP,ACT,0.9900000095367432	CHEMBL38033,TN,INACT,0.03999999910593033	CHEMBL145134,TP,ACT,1.0	CHEMBL70892,TP,ACT,1.0	CHEMBL191915,TN,INACT,0.0	CHEMBL72724,FN,ACT,0.0	CHEMBL304961,TN,INACT,0.0	CHEMBL302203,TP,ACT,1.0	CHEMBL91415,TP,ACT,1.0	CHEMBL78929,TN,INACT,0.019999999552965164	CHEMBL510130,TN,INACT,0.07999999821186066	CHEMBL29433,TP,ACT,1.0	CHEMBL96738,TN,INACT,0.0	CHEMBL284103,TP,ACT,1.0	CHEMBL106487,TN,INACT,0.0	CHEMBL3809319,TP,ACT,1.0	CHEMBL24781,TN,INACT,0.0	CHEMBL483991,TN,INACT,0.0	CHEMBL422701,TN,INACT,0.029999999329447746	CHEMBL91073,TN,INACT,0.0	CHEMBL1796028,TP,ACT,1.0	CHEMBL299538,TN,INACT,0.0	CHEMBL428197,TP,ACT,1.0	CHEMBL289916,TP,ACT,1.0	CHEMBL300821,TP,ACT,1.0	CHEMBL145562,TP,ACT,0.9900000095367432	CHEMBL2436713,TN,INACT,0.0	CHEMBL3343977,TP,ACT,0.949999988079071	CHEMBL11828,TP,ACT,1.0	CHEMBL217469,TP,ACT,1.0	CHEMBL219719,TP,ACT,1.0	CHEMBL220717,TP,ACT,0.9900000095367432	CHEMBL342126,TP,ACT,1.0	CHEMBL302359,TN,INACT,0.0	CHEMBL320397,FN,ACT,0.009999999776482582	CHEMBL150743,TN,INACT,0.0	CHEMBL236830,TP,ACT,1.0	CHEMBL3354069,TN,INACT,0.0	CHEMBL97044,TP,ACT,1.0	CHEMBL156283,TN,INACT,0.009999999776482582	CHEMBL1076625,TN,INACT,0.0	CHEMBL228333,TP,ACT,1.0	CHEMBL1078773,TP,ACT,1.0	CHEMBL279436,TP,ACT,1.0	CHEMBL433814,TN,INACT,0.0	CHEMBL3810110,TP,ACT,1.0	CHEMBL3238446,TN,INACT,0.0	CHEMBL229388,TN,INACT,0.0	CHEMBL359173,TP,ACT,1.0	CHEMBL3342864,TP,ACT,1.0	CHEMBL1076554,TN,INACT,0.0	CHEMBL353972,TP,ACT,0.1899999976158142	CHEMBL1242541,TP,ACT,0.9900000095367432	CHEMBL58384,TP,ACT,1.0	CHEMBL10085,TP,ACT,0.9599999785423279	CHEMBL114345,FN,ACT,0.0	CHEMBL72707,TN,INACT,0.0	CHEMBL561851,FN,ACT,0.05999999865889549	CHEMBL100481,TP,ACT,1.0	CHEMBL141604,TP,ACT,1.0	CHEMBL1082036,TN,INACT,0.009999999776482582	CHEMBL52438,TN,INACT,0.0	CHEMBL316358,TP,ACT,1.0	CHEMBL3400598,TP,ACT,1.0	CHEMBL314960,TP,ACT,1.0	CHEMBL303538,TN,INACT,0.0	CHEMBL198431,TP,ACT,0.9100000262260437	CHEMBL273410,TN,INACT,0.0	CHEMBL431354,TP,ACT,1.0	CHEMBL1086156,TP,ACT,1.0	CHEMBL2096751,TN,INACT,0.0	CHEMBL540035,TP,ACT,0.949999988079071	CHEMBL2367888,TN,INACT,0.009999999776482582	CHEMBL399195,TP,ACT,1.0	CHEMBL1765667,TN,INACT,0.05000000074505806	CHEMBL3810401,TP,ACT,1.0	CHEMBL85678,TN,INACT,0.0	CHEMBL269576,FP,INACT,0.9599999785423279	CHEMBL3665433,TN,INACT,0.0	CHEMBL96958,TN,INACT,0.0	CHEMBL58956,TP,ACT,1.0	CHEMBL25300,TP,ACT,0.9700000286102295	CHEMBL310768,TP,ACT,1.0	CHEMBL58612,TP,ACT,1.0	CHEMBL126472,TN,INACT,0.0	CHEMBL3088176,TN,INACT,0.0	CHEMBL3394007,TN,INACT,0.029999999329447746	CHEMBL2397476,FP,INACT,0.9800000190734863	CHEMBL229443,TN,INACT,0.0	CHEMBL193337,TN,INACT,0.0	CHEMBL68738,TN,INACT,0.009999999776482582	CHEMBL60435,TN,INACT,0.0	CHEMBL2164350,FN,ACT,0.05000000074505806	CHEMBL2391353,TN,INACT,0.0	CHEMBL358785,TP,ACT,1.0	CHEMBL2179222,TP,ACT,0.9900000095367432	CHEMBL143558,TP,ACT,1.0	CHEMBL296291,TN,INACT,0.0	CHEMBL234543,TN,INACT,0.0	CHEMBL305558,TN,INACT,0.0	CHEMBL3808726,TP,ACT,1.0	CHEMBL495854,TN,INACT,0.0	CHEMBL316983,TN,INACT,0.0	CHEMBL294027,TP,ACT,1.0	CHEMBL1079066,TP,ACT,1.0	CHEMBL1767148,TP,ACT,0.9900000095367432	CHEMBL474091,TN,INACT,0.0	CHEMBL32301,TN,INACT,0.0	CHEMBL110064,TN,INACT,0.0	CHEMBL67713,TP,ACT,1.0	CHEMBL104222,TN,INACT,0.0	CHEMBL1767162,TP,ACT,1.0	CHEMBL142243,TP,ACT,1.0	CHEMBL15675,TN,INACT,0.0	CHEMBL239806,TP,ACT,1.0	CHEMBL45305,TN,INACT,0.0	CHEMBL343969,TN,INACT,0.10999999940395355	CHEMBL97698,TP,ACT,1.0	CHEMBL320419,FN,ACT,0.019999999552965164	CHEMBL390667,TN,INACT,0.09000000357627869	CHEMBL393725,TP,ACT,1.0	CHEMBL63937,TN,INACT,0.0	CHEMBL1620339,FP,INACT,0.9900000095367432	CHEMBL251997,TN,INACT,0.009999999776482582	CHEMBL49851,FN,ACT,0.12999999523162842	CHEMBL63289,TN,INACT,0.07999999821186066	CHEMBL229615,TN,INACT,0.0	CHEMBL83450,TN,INACT,0.05000000074505806	CHEMBL319910,TN,INACT,0.0	CHEMBL94902,TN,INACT,0.0	CHEMBL40317,TN,INACT,0.0	CHEMBL1223696,TN,INACT,0.0	CHEMBL272340,TP,ACT,1.0	CHEMBL359141,TN,INACT,0.0	CHEMBL215421,TP,ACT,1.0	CHEMBL394139,TP,ACT,1.0	CHEMBL56248,TP,ACT,1.0	CHEMBL256041,TP,ACT,1.0	CHEMBL80438,TN,INACT,0.0	CHEMBL1767149,FN,ACT,0.03999999910593033	CHEMBL2443004,TN,INACT,0.0	CHEMBL137444,FN,ACT,0.0	CHEMBL228998,TN,INACT,0.0	CHEMBL294646,TP,ACT,0.9700000286102295	CHEMBL1242950,FN,ACT,0.019999999552965164	CHEMBL315914,TP,ACT,1.0	CHEMBL1112,TP,ACT,1.0	CHEMBL233552,TN,INACT,0.10999999940395355	CHEMBL417954,TP,ACT,0.7699999809265137	CHEMBL1767140,TP,ACT,1.0	CHEMBL294649,TN,INACT,0.0	CHEMBL144938,TP,ACT,1.0	CHEMBL104,FP,INACT,0.28999999165534973	CHEMBL2387335,TN,INACT,0.009999999776482582	CHEMBL311290,TP,ACT,0.949999988079071	CHEMBL11401,TN,INACT,0.0	CHEMBL2372075,TN,INACT,0.009999999776482582	CHEMBL323854,TN,INACT,0.0	CHEMBL3342859,TP,ACT,1.0	CHEMBL527880,TN,INACT,0.0	CHEMBL318544,TP,ACT,1.0	CHEMBL3298020,TP,ACT,1.0	CHEMBL144302,TN,INACT,0.0	CHEMBL390192,TP,ACT,1.0	CHEMBL347499,TP,ACT,0.23999999463558197	CHEMBL312372,TN,INACT,0.0	CHEMBL358406,TP,ACT,1.0	CHEMBL217002,TN,INACT,0.0	CHEMBL43661,FP,INACT,0.9900000095367432	CHEMBL137903,TP,ACT,1.0	CHEMBL234476,TP,ACT,0.6299999952316284	CHEMBL515472,TP,ACT,1.0	CHEMBL413707,FN,ACT,0.0	CHEMBL282214,FN,ACT,0.009999999776482582	CHEMBL115262,TP,ACT,0.9900000095367432	CHEMBL290153,TN,INACT,0.009999999776482582	CHEMBL2436824,TN,INACT,0.0	CHEMBL420578,TP,ACT,0.949999988079071	CHEMBL44496,TP,ACT,0.9900000095367432	CHEMBL64124,TN,INACT,0.0	CHEMBL228992,TN,INACT,0.0	CHEMBL303386,TN,INACT,0.0	CHEMBL57364,TP,ACT,1.0	CHEMBL422283,TN,INACT,0.0	CHEMBL74342,TN,INACT,0.009999999776482582	CHEMBL2112365,TP,ACT,1.0	CHEMBL1767134,TP,ACT,0.550000011920929	CHEMBL3400597,FN,ACT,0.05999999865889549	CHEMBL332446,TN,INACT,0.0	CHEMBL1767167,FN,ACT,0.10999999940395355	CHEMBL3780633,TN,INACT,0.0	CHEMBL2436815,TN,INACT,0.009999999776482582	CHEMBL168541,TN,INACT,0.019999999552965164	CHEMBL1796036,TP,ACT,0.9300000071525574	CHEMBL49935,TN,INACT,0.0	CHEMBL151619,TN,INACT,0.009999999776482582	CHEMBL50456,TN,INACT,0.019999999552965164	CHEMBL422959,TN,INACT,0.0	CHEMBL123349,FN,ACT,0.03999999910593033	CHEMBL469855,TN,INACT,0.0	CHEMBL543741,TP,ACT,0.9900000095367432	CHEMBL94917,TN,INACT,0.0	CHEMBL1437,TN,INACT,0.0	CHEMBL142822,TN,INACT,0.009999999776482582	CHEMBL388884,TP,ACT,0.9900000095367432	CHEMBL105383,TN,INACT,0.019999999552965164	CHEMBL142719,TP,ACT,0.949999988079071	CHEMBL267014,TN,INACT,0.0	CHEMBL242725,TP,ACT,0.9900000095367432	CHEMBL323175,TN,INACT,0.0	CHEMBL56438,TP,ACT,1.0	CHEMBL315538,TP,ACT,1.0	CHEMBL2153551,TP,ACT,1.0	CHEMBL3342872,TP,ACT,1.0	CHEMBL386152,TN,INACT,0.0	CHEMBL344339,TP,ACT,0.9900000095367432	CHEMBL7154,TN,INACT,0.009999999776482582	CHEMBL40325,TP,ACT,1.0	CHEMBL61598,TP,ACT,1.0	CHEMBL322547,TN,INACT,0.0	CHEMBL611,TP,ACT,0.9200000166893005	CHEMBL88629,TN,INACT,0.0	CHEMBL2164612,TN,INACT,0.0	CHEMBL302882,TP,ACT,0.15000000596046448	CHEMBL72441,TP,ACT,0.9100000262260437	CHEMBL228278,TP,ACT,1.0	CHEMBL70563,TP,ACT,0.9900000095367432	CHEMBL284912,TN,INACT,0.0	CHEMBL111023,TN,INACT,0.0	CHEMBL347522,FN,ACT,0.009999999776482582	CHEMBL68565,TP,ACT,1.0	CHEMBL3298745,TP,ACT,1.0	CHEMBL41677,TP,ACT,1.0	CHEMBL437,TN,INACT,0.009999999776482582	CHEMBL3342856,TP,ACT,1.0	CHEMBL1224608,TN,INACT,0.05999999865889549	CHEMBL3808999,TP,ACT,1.0	CHEMBL80504,TN,INACT,0.10999999940395355	CHEMBL56899,TP,ACT,1.0	CHEMBL234681,TP,ACT,1.0	CHEMBL3740351,TP,ACT,1.0	CHEMBL1242445,TP,ACT,0.9900000095367432	CHEMBL2164354,FN,ACT,0.03999999910593033	CHEMBL66789,TN,INACT,0.0	CHEMBL292365,TP,ACT,1.0	CHEMBL142635,TP,ACT,1.0	CHEMBL341849,TP,ACT,1.0	CHEMBL151825,TP,ACT,0.4399999976158142	CHEMBL11467,TN,INACT,0.0	CHEMBL233814,TP,ACT,1.0	CHEMBL2205823,FN,ACT,0.0	CHEMBL2158715,TN,INACT,0.10000000149011612	CHEMBL55695,TP,ACT,1.0	CHEMBL390184,TP,ACT,1.0	CHEMBL31354,TP,ACT,1.0	CHEMBL293577,TN,INACT,0.0	CHEMBL145267,TP,ACT,0.9900000095367432	CHEMBL347559,TP,ACT,1.0	CHEMBL324685,TN,INACT,0.0	CHEMBL342731,TP,ACT,1.0	CHEMBL440865,TP,ACT,1.0	CHEMBL341665,TP,ACT,0.9200000166893005	CHEMBL44288,TP,ACT,1.0	CHEMBL2261604,TP,ACT,0.9900000095367432	CHEMBL2042551,TN,INACT,0.0	CHEMBL3665443,TN,INACT,0.019999999552965164	CHEMBL2436722,TN,INACT,0.0	CHEMBL38861,TN,INACT,0.0	CHEMBL104848,TN,INACT,0.0	CHEMBL59597,TN,INACT,0.0	CHEMBL292759,FN,ACT,0.05000000074505806	CHEMBL2163920,TN,INACT,0.0	CHEMBL233957,TN,INACT,0.0	CHEMBL99142,TP,ACT,1.0	CHEMBL356923,FP,INACT,1.0	CHEMBL2062858,TN,INACT,0.009999999776482582	CHEMBL175934,TP,ACT,0.7799999713897705	CHEMBL283606,TN,INACT,0.009999999776482582	CHEMBL3740874,TP,ACT,1.0	CHEMBL232780,TP,ACT,1.0	CHEMBL481245,TN,INACT,0.07999999821186066	CHEMBL89457,TN,INACT,0.0	CHEMBL481415,TN,INACT,0.0	CHEMBL1767158,FN,ACT,0.0	CHEMBL1767164,TP,ACT,1.0	CHEMBL62110,TP,ACT,1.0	CHEMBL3742276,TP,ACT,1.0	CHEMBL1255085,TP,ACT,1.0	CHEMBL342111,TP,ACT,1.0	CHEMBL218732,TP,ACT,0.9800000190734863	CHEMBL320736,TP,ACT,1.0	CHEMBL1256608,TP,ACT,0.20999999344348907	CHEMBL3808981,TP,ACT,1.0	CHEMBL312268,FP,INACT,0.75	CHEMBL58105,TP,ACT,1.0	

