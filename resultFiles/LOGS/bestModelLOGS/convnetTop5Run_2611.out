ImageNetInceptionV2 CHEMBL1873 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	216
Number of inactive compounds :	216
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1873_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1873_adam_0.0001_15_0.6/
---------------------------------
Training samples: 276
Validation samples: 87
--
Training Step: 1  | time: 450.903s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/276
[A[ATraining Step: 2  | total loss: [1m[32m0.70734[0m[0m | time: 713.867s
[2K
| Adam | epoch: 001 | loss: 0.70734 - acc: 0.3656 -- iter: 064/276
[A[ATraining Step: 3  | total loss: [1m[32m0.81516[0m[0m | time: 980.107s
[2K
| Adam | epoch: 001 | loss: 0.81516 - acc: 0.4244 -- iter: 096/276
[A[ATraining Step: 4  | total loss: [1m[32m0.69596[0m[0m | time: 1448.796s
[2K
| Adam | epoch: 001 | loss: 0.69596 - acc: 0.4811 -- iter: 128/276
[A[ATraining Step: 5  | total loss: [1m[32m0.72136[0m[0m | time: 1678.523s
[2K
| Adam | epoch: 001 | loss: 0.72136 - acc: 0.4726 -- iter: 160/276
[A[ATraining Step: 6  | total loss: [1m[32m0.71392[0m[0m | time: 1820.195s
[2K
| Adam | epoch: 001 | loss: 0.71392 - acc: 0.5103 -- iter: 192/276
[A[ATraining Step: 7  | total loss: [1m[32m0.71985[0m[0m | time: 1904.890s
[2K
| Adam | epoch: 001 | loss: 0.71985 - acc: 0.4666 -- iter: 224/276
[A[ATraining Step: 8  | total loss: [1m[32m0.68413[0m[0m | time: 1940.840s
[2K
| Adam | epoch: 001 | loss: 0.68413 - acc: 0.5381 -- iter: 256/276
[A[ATraining Step: 9  | total loss: [1m[32m0.60804[0m[0m | time: 1982.207s
[2K
| Adam | epoch: 001 | loss: 0.60804 - acc: 0.6999 | val_loss: 0.68757 - val_acc: 0.5977 -- iter: 276/276
--
Training Step: 10  | total loss: [1m[32m0.56758[0m[0m | time: 9.021s
[2K
| Adam | epoch: 002 | loss: 0.56758 - acc: 0.7250 -- iter: 032/276
[A[ATraining Step: 11  | total loss: [1m[32m0.52709[0m[0m | time: 36.402s
[2K
| Adam | epoch: 002 | loss: 0.52709 - acc: 0.8079 -- iter: 064/276
[A[ATraining Step: 12  | total loss: [1m[32m0.52320[0m[0m | time: 142.142s
[2K
| Adam | epoch: 002 | loss: 0.52320 - acc: 0.8381 -- iter: 096/276
[A[ATraining Step: 13  | total loss: [1m[32m0.53321[0m[0m | time: 244.593s
[2K
| Adam | epoch: 002 | loss: 0.53321 - acc: 0.7869 -- iter: 128/276
[A[ATraining Step: 14  | total loss: [1m[32m0.55804[0m[0m | time: 303.819s
[2K
| Adam | epoch: 002 | loss: 0.55804 - acc: 0.7463 -- iter: 160/276
[A[ATraining Step: 15  | total loss: [1m[32m0.56350[0m[0m | time: 316.100s
[2K
| Adam | epoch: 002 | loss: 0.56350 - acc: 0.6988 -- iter: 192/276
[A[ATraining Step: 16  | total loss: [1m[32m0.52242[0m[0m | time: 328.508s
[2K
| Adam | epoch: 002 | loss: 0.52242 - acc: 0.7766 -- iter: 224/276
[A[ATraining Step: 17  | total loss: [1m[32m0.52092[0m[0m | time: 372.158s
[2K
| Adam | epoch: 002 | loss: 0.52092 - acc: 0.7670 -- iter: 256/276
[A[ATraining Step: 18  | total loss: [1m[32m0.47061[0m[0m | time: 399.571s
[2K
| Adam | epoch: 002 | loss: 0.47061 - acc: 0.8260 | val_loss: 0.92767 - val_acc: 0.4023 -- iter: 276/276
--
Training Step: 19  | total loss: [1m[32m0.42531[0m[0m | time: 6.207s
[2K
| Adam | epoch: 003 | loss: 0.42531 - acc: 0.8528 -- iter: 032/276
[A[ATraining Step: 20  | total loss: [1m[32m0.40023[0m[0m | time: 12.146s
[2K
| Adam | epoch: 003 | loss: 0.40023 - acc: 0.8840 -- iter: 064/276
[A[ATraining Step: 21  | total loss: [1m[32m0.34741[0m[0m | time: 21.109s
[2K
| Adam | epoch: 003 | loss: 0.34741 - acc: 0.9200 -- iter: 096/276
[A[ATraining Step: 22  | total loss: [1m[32m0.32731[0m[0m | time: 55.098s
[2K
| Adam | epoch: 003 | loss: 0.32731 - acc: 0.9440 -- iter: 128/276
[A[ATraining Step: 23  | total loss: [1m[32m0.32842[0m[0m | time: 74.562s
[2K
| Adam | epoch: 003 | loss: 0.32842 - acc: 0.9421 -- iter: 160/276
[A[ATraining Step: 24  | total loss: [1m[32m0.32019[0m[0m | time: 187.652s
[2K
| Adam | epoch: 003 | loss: 0.32019 - acc: 0.9408 -- iter: 192/276
[A[ATraining Step: 25  | total loss: [1m[32m0.30764[0m[0m | time: 198.431s
[2K
| Adam | epoch: 003 | loss: 0.30764 - acc: 0.9314 -- iter: 224/276
[A[ATraining Step: 26  | total loss: [1m[32m0.28583[0m[0m | time: 207.909s
[2K
| Adam | epoch: 003 | loss: 0.28583 - acc: 0.9496 -- iter: 256/276
[A[ATraining Step: 27  | total loss: [1m[32m0.27111[0m[0m | time: 273.777s
[2K
| Adam | epoch: 003 | loss: 0.27111 - acc: 0.9465 | val_loss: 0.70039 - val_acc: 0.4023 -- iter: 276/276
--
Training Step: 28  | total loss: [1m[32m0.23801[0m[0m | time: 55.276s
[2K
| Adam | epoch: 004 | loss: 0.23801 - acc: 0.9520 -- iter: 032/276
[A[ATraining Step: 29  | total loss: [1m[32m0.21033[0m[0m | time: 64.138s
[2K
| Adam | epoch: 004 | loss: 0.21033 - acc: 0.9561 -- iter: 064/276
[A[ATraining Step: 30  | total loss: [1m[32m0.19051[0m[0m | time: 72.536s
[2K
| Adam | epoch: 004 | loss: 0.19051 - acc: 0.9665 -- iter: 096/276
[A[ATraining Step: 31  | total loss: [1m[32m0.16690[0m[0m | time: 120.028s
[2K
| Adam | epoch: 004 | loss: 0.16690 - acc: 0.9742 -- iter: 128/276
[A[ATraining Step: 32  | total loss: [1m[32m0.15386[0m[0m | time: 211.059s
[2K
| Adam | epoch: 004 | loss: 0.15386 - acc: 0.9800 -- iter: 160/276
[A[ATraining Step: 33  | total loss: [1m[32m0.12989[0m[0m | time: 219.848s
[2K
| Adam | epoch: 004 | loss: 0.12989 - acc: 0.9844 -- iter: 192/276
[A[ATraining Step: 34  | total loss: [1m[32m0.11162[0m[0m | time: 228.488s
[2K
| Adam | epoch: 004 | loss: 0.11162 - acc: 0.9878 -- iter: 224/276
[A[ATraining Step: 35  | total loss: [1m[32m0.09923[0m[0m | time: 237.101s
[2K
| Adam | epoch: 004 | loss: 0.09923 - acc: 0.9903 -- iter: 256/276
[A[ATraining Step: 36  | total loss: [1m[32m0.08622[0m[0m | time: 249.867s
[2K
| Adam | epoch: 004 | loss: 0.08622 - acc: 0.9923 | val_loss: 1.10728 - val_acc: 0.4023 -- iter: 276/276
--
Training Step: 37  | total loss: [1m[32m0.07303[0m[0m | time: 8.530s
[2K
| Adam | epoch: 005 | loss: 0.07303 - acc: 0.9938 -- iter: 032/276
[A[ATraining Step: 38  | total loss: [1m[32m0.10252[0m[0m | time: 16.628s
[2K
| Adam | epoch: 005 | loss: 0.10252 - acc: 0.9889 -- iter: 064/276
[A[ATraining Step: 39  | total loss: [1m[32m0.08831[0m[0m | time: 22.497s
[2K
| Adam | epoch: 005 | loss: 0.08831 - acc: 0.9910 -- iter: 096/276
[A[ATraining Step: 40  | total loss: [1m[32m0.07928[0m[0m | time: 28.143s
[2K
| Adam | epoch: 005 | loss: 0.07928 - acc: 0.9927 -- iter: 128/276
[A[ATraining Step: 41  | total loss: [1m[32m0.06784[0m[0m | time: 36.813s
[2K
| Adam | epoch: 005 | loss: 0.06784 - acc: 0.9941 -- iter: 160/276
[A[ATraining Step: 42  | total loss: [1m[32m0.05779[0m[0m | time: 50.852s
[2K
| Adam | epoch: 005 | loss: 0.05779 - acc: 0.9951 -- iter: 192/276
[A[ATraining Step: 43  | total loss: [1m[32m0.05533[0m[0m | time: 59.826s
[2K
| Adam | epoch: 005 | loss: 0.05533 - acc: 0.9905 -- iter: 224/276
[A[ATraining Step: 44  | total loss: [1m[32m0.04848[0m[0m | time: 68.950s
[2K
| Adam | epoch: 005 | loss: 0.04848 - acc: 0.9921 -- iter: 256/276
[A[ATraining Step: 45  | total loss: [1m[32m0.04347[0m[0m | time: 81.575s
[2K
| Adam | epoch: 005 | loss: 0.04347 - acc: 0.9935 | val_loss: 0.73761 - val_acc: 0.6092 -- iter: 276/276
--
Training Step: 46  | total loss: [1m[32m0.03960[0m[0m | time: 8.537s
[2K
| Adam | epoch: 006 | loss: 0.03960 - acc: 0.9946 -- iter: 032/276
[A[ATraining Step: 47  | total loss: [1m[32m0.03548[0m[0m | time: 17.170s
[2K
| Adam | epoch: 006 | loss: 0.03548 - acc: 0.9954 -- iter: 064/276
[A[ATraining Step: 48  | total loss: [1m[32m0.03067[0m[0m | time: 25.446s
[2K
| Adam | epoch: 006 | loss: 0.03067 - acc: 0.9962 -- iter: 096/276
[A[ATraining Step: 49  | total loss: [1m[32m0.02647[0m[0m | time: 31.355s
[2K
| Adam | epoch: 006 | loss: 0.02647 - acc: 0.9968 -- iter: 128/276
[A[ATraining Step: 50  | total loss: [1m[32m0.02314[0m[0m | time: 37.130s
[2K
| Adam | epoch: 006 | loss: 0.02314 - acc: 0.9973 -- iter: 160/276
[A[ATraining Step: 51  | total loss: [1m[32m0.02033[0m[0m | time: 45.551s
[2K
| Adam | epoch: 006 | loss: 0.02033 - acc: 0.9977 -- iter: 192/276
[A[ATraining Step: 52  | total loss: [1m[32m0.01794[0m[0m | time: 53.845s
[2K
| Adam | epoch: 006 | loss: 0.01794 - acc: 0.9980 -- iter: 224/276
[A[ATraining Step: 53  | total loss: [1m[32m0.02470[0m[0m | time: 62.533s
[2K
| Adam | epoch: 006 | loss: 0.02470 - acc: 0.9937 -- iter: 256/276
[A[ATraining Step: 54  | total loss: [1m[32m0.02729[0m[0m | time: 75.226s
[2K
| Adam | epoch: 006 | loss: 0.02729 - acc: 0.9901 | val_loss: 0.87688 - val_acc: 0.6207 -- iter: 276/276
--
Training Step: 55  | total loss: [1m[32m0.02536[0m[0m | time: 8.536s
[2K
| Adam | epoch: 007 | loss: 0.02536 - acc: 0.9915 -- iter: 032/276
[A[ATraining Step: 56  | total loss: [1m[32m0.02281[0m[0m | time: 16.840s
[2K
| Adam | epoch: 007 | loss: 0.02281 - acc: 0.9927 -- iter: 064/276
[A[ATraining Step: 57  | total loss: [1m[32m0.06508[0m[0m | time: 25.340s
[2K
| Adam | epoch: 007 | loss: 0.06508 - acc: 0.9894 -- iter: 096/276
[A[ATraining Step: 58  | total loss: [1m[32m0.05665[0m[0m | time: 34.189s
[2K
| Adam | epoch: 007 | loss: 0.05665 - acc: 0.9908 -- iter: 128/276
[A[ATraining Step: 59  | total loss: [1m[32m0.04966[0m[0m | time: 39.833s
[2K
| Adam | epoch: 007 | loss: 0.04966 - acc: 0.9921 -- iter: 160/276
[A[ATraining Step: 60  | total loss: [1m[32m0.04340[0m[0m | time: 45.486s
[2K
| Adam | epoch: 007 | loss: 0.04340 - acc: 0.9931 -- iter: 192/276
[A[ATraining Step: 61  | total loss: [1m[32m0.03808[0m[0m | time: 54.007s
[2K
| Adam | epoch: 007 | loss: 0.03808 - acc: 0.9940 -- iter: 224/276
[A[ATraining Step: 62  | total loss: [1m[32m0.03354[0m[0m | time: 62.477s
[2K
| Adam | epoch: 007 | loss: 0.03354 - acc: 0.9948 -- iter: 256/276
[A[ATraining Step: 63  | total loss: [1m[32m0.03004[0m[0m | time: 76.112s
[2K
| Adam | epoch: 007 | loss: 0.03004 - acc: 0.9954 | val_loss: 2.97077 - val_acc: 0.4023 -- iter: 276/276
--
Training Step: 64  | total loss: [1m[32m0.03152[0m[0m | time: 8.534s
[2K
| Adam | epoch: 008 | loss: 0.03152 - acc: 0.9921 -- iter: 032/276
[A[ATraining Step: 65  | total loss: [1m[32m0.02836[0m[0m | time: 17.025s
[2K
| Adam | epoch: 008 | loss: 0.02836 - acc: 0.9931 -- iter: 064/276
[A[ATraining Step: 66  | total loss: [1m[32m0.02890[0m[0m | time: 25.381s
[2K
| Adam | epoch: 008 | loss: 0.02890 - acc: 0.9939 -- iter: 096/276
[A[ATraining Step: 67  | total loss: [1m[32m0.02596[0m[0m | time: 34.203s
[2K
| Adam | epoch: 008 | loss: 0.02596 - acc: 0.9947 -- iter: 128/276
[A[ATraining Step: 68  | total loss: [1m[32m0.04108[0m[0m | time: 42.636s
[2K
| Adam | epoch: 008 | loss: 0.04108 - acc: 0.9916 -- iter: 160/276
[A[ATraining Step: 69  | total loss: [1m[32m0.03713[0m[0m | time: 48.091s
[2K
| Adam | epoch: 008 | loss: 0.03713 - acc: 0.9926 -- iter: 192/276
[A[ATraining Step: 70  | total loss: [1m[32m0.03418[0m[0m | time: 53.616s
[2K
| Adam | epoch: 008 | loss: 0.03418 - acc: 0.9934 -- iter: 224/276
[A[ATraining Step: 71  | total loss: [1m[32m0.03103[0m[0m | time: 62.461s
[2K
| Adam | epoch: 008 | loss: 0.03103 - acc: 0.9942 -- iter: 256/276
[A[ATraining Step: 72  | total loss: [1m[32m0.02837[0m[0m | time: 75.140s
[2K
| Adam | epoch: 008 | loss: 0.02837 - acc: 0.9948 | val_loss: 2.19700 - val_acc: 0.6092 -- iter: 276/276
--
Training Step: 73  | total loss: [1m[32m0.02636[0m[0m | time: 8.522s
[2K
| Adam | epoch: 009 | loss: 0.02636 - acc: 0.9954 -- iter: 032/276
[A[ATraining Step: 74  | total loss: [1m[32m0.02466[0m[0m | time: 16.965s
[2K
| Adam | epoch: 009 | loss: 0.02466 - acc: 0.9959 -- iter: 064/276
[A[ATraining Step: 75  | total loss: [1m[32m0.07436[0m[0m | time: 25.428s
[2K
| Adam | epoch: 009 | loss: 0.07436 - acc: 0.9930 -- iter: 096/276
[A[ATraining Step: 76  | total loss: [1m[32m0.06724[0m[0m | time: 34.551s
[2K
| Adam | epoch: 009 | loss: 0.06724 - acc: 0.9937 -- iter: 128/276
[A[ATraining Step: 77  | total loss: [1m[32m0.06116[0m[0m | time: 43.060s
[2K
| Adam | epoch: 009 | loss: 0.06116 - acc: 0.9944 -- iter: 160/276
[A[ATraining Step: 78  | total loss: [1m[32m0.05554[0m[0m | time: 51.625s
[2K
| Adam | epoch: 009 | loss: 0.05554 - acc: 0.9950 -- iter: 192/276
[A[ATraining Step: 79  | total loss: [1m[32m0.06064[0m[0m | time: 57.309s
[2K
| Adam | epoch: 009 | loss: 0.06064 - acc: 0.9923 -- iter: 224/276
[A[ATraining Step: 80  | total loss: [1m[32m0.05522[0m[0m | time: 62.943s
[2K
| Adam | epoch: 009 | loss: 0.05522 - acc: 0.9930 -- iter: 256/276
[A[ATraining Step: 81  | total loss: [1m[32m0.05019[0m[0m | time: 75.493s
[2K
| Adam | epoch: 009 | loss: 0.05019 - acc: 0.9938 | val_loss: 6.04389 - val_acc: 0.5977 -- iter: 276/276
--
Training Step: 82  | total loss: [1m[32m0.04606[0m[0m | time: 8.419s
[2K
| Adam | epoch: 010 | loss: 0.04606 - acc: 0.9944 -- iter: 032/276
[A[ATraining Step: 83  | total loss: [1m[32m0.04252[0m[0m | time: 16.654s
[2K
| Adam | epoch: 010 | loss: 0.04252 - acc: 0.9949 -- iter: 064/276
[A[ATraining Step: 84  | total loss: [1m[32m0.03897[0m[0m | time: 26.179s
[2K
| Adam | epoch: 010 | loss: 0.03897 - acc: 0.9954 -- iter: 096/276
[A[ATraining Step: 85  | total loss: [1m[32m0.03716[0m[0m | time: 34.973s
[2K
| Adam | epoch: 010 | loss: 0.03716 - acc: 0.9959 -- iter: 128/276
[A[ATraining Step: 86  | total loss: [1m[32m0.03759[0m[0m | time: 43.491s
[2K
| Adam | epoch: 010 | loss: 0.03759 - acc: 0.9963 -- iter: 160/276
[A[ATraining Step: 87  | total loss: [1m[32m0.03548[0m[0m | time: 52.052s
[2K
| Adam | epoch: 010 | loss: 0.03548 - acc: 0.9967 -- iter: 192/276
[A[ATraining Step: 88  | total loss: [1m[32m0.05172[0m[0m | time: 60.979s
[2K
| Adam | epoch: 010 | loss: 0.05172 - acc: 0.9939 -- iter: 224/276
[A[ATraining Step: 89  | total loss: [1m[32m0.04708[0m[0m | time: 66.520s
[2K
| Adam | epoch: 010 | loss: 0.04708 - acc: 0.9945 -- iter: 256/276
[A[ATraining Step: 90  | total loss: [1m[32m0.04265[0m[0m | time: 76.262s
[2K
| Adam | epoch: 010 | loss: 0.04265 - acc: 0.9950 | val_loss: 7.14978 - val_acc: 0.4023 -- iter: 276/276
--
Training Step: 91  | total loss: [1m[32m0.03864[0m[0m | time: 8.604s
[2K
| Adam | epoch: 011 | loss: 0.03864 - acc: 0.9955 -- iter: 032/276
[A[ATraining Step: 92  | total loss: [1m[32m0.03545[0m[0m | time: 17.427s
[2K
| Adam | epoch: 011 | loss: 0.03545 - acc: 0.9960 -- iter: 064/276
[A[ATraining Step: 93  | total loss: [1m[32m0.04315[0m[0m | time: 26.359s
[2K
| Adam | epoch: 011 | loss: 0.04315 - acc: 0.9933 -- iter: 096/276
[A[ATraining Step: 94  | total loss: [1m[32m0.03974[0m[0m | time: 35.032s
[2K
| Adam | epoch: 011 | loss: 0.03974 - acc: 0.9939 -- iter: 128/276
[A[ATraining Step: 95  | total loss: [1m[32m0.10506[0m[0m | time: 43.259s
[2K
| Adam | epoch: 011 | loss: 0.10506 - acc: 0.9883 -- iter: 160/276
[A[ATraining Step: 96  | total loss: [1m[32m0.09551[0m[0m | time: 51.928s
[2K
| Adam | epoch: 011 | loss: 0.09551 - acc: 0.9895 -- iter: 192/276
[A[ATraining Step: 97  | total loss: [1m[32m0.09072[0m[0m | time: 60.224s
[2K
| Adam | epoch: 011 | loss: 0.09072 - acc: 0.9874 -- iter: 224/276
[A[ATraining Step: 98  | total loss: [1m[32m0.10285[0m[0m | time: 68.780s
[2K
| Adam | epoch: 011 | loss: 0.10285 - acc: 0.9855 -- iter: 256/276
[A[ATraining Step: 99  | total loss: [1m[32m0.09376[0m[0m | time: 78.671s
[2K
| Adam | epoch: 011 | loss: 0.09376 - acc: 0.9870 | val_loss: 5.03953 - val_acc: 0.5977 -- iter: 276/276
--
Training Step: 100  | total loss: [1m[32m0.08475[0m[0m | time: 5.501s
[2K
| Adam | epoch: 012 | loss: 0.08475 - acc: 0.9883 -- iter: 032/276
[A[ATraining Step: 101  | total loss: [1m[32m0.07669[0m[0m | time: 14.197s
[2K
| Adam | epoch: 012 | loss: 0.07669 - acc: 0.9895 -- iter: 064/276
[A[ATraining Step: 102  | total loss: [1m[32m0.08765[0m[0m | time: 22.724s
[2K
| Adam | epoch: 012 | loss: 0.08765 - acc: 0.9874 -- iter: 096/276
[A[ATraining Step: 103  | total loss: [1m[32m0.08124[0m[0m | time: 31.414s
[2K
| Adam | epoch: 012 | loss: 0.08124 - acc: 0.9886 -- iter: 128/276
[A[ATraining Step: 104  | total loss: [1m[32m0.07631[0m[0m | time: 39.624s
[2K
| Adam | epoch: 012 | loss: 0.07631 - acc: 0.9898 -- iter: 160/276
[A[ATraining Step: 105  | total loss: [1m[32m0.07106[0m[0m | time: 48.553s
[2K
| Adam | epoch: 012 | loss: 0.07106 - acc: 0.9908 -- iter: 192/276
[A[ATraining Step: 106  | total loss: [1m[32m0.06515[0m[0m | time: 56.857s
[2K
| Adam | epoch: 012 | loss: 0.06515 - acc: 0.9917 -- iter: 224/276
[A[ATraining Step: 107  | total loss: [1m[32m0.06416[0m[0m | time: 65.458s
[2K
| Adam | epoch: 012 | loss: 0.06416 - acc: 0.9925 -- iter: 256/276
[A[ATraining Step: 108  | total loss: [1m[32m0.13177[0m[0m | time: 77.913s
[2K
| Adam | epoch: 012 | loss: 0.13177 - acc: 0.9902 | val_loss: 0.85175 - val_acc: 0.6207 -- iter: 276/276
--
Training Step: 109  | total loss: [1m[32m0.12022[0m[0m | time: 5.791s
[2K
| Adam | epoch: 013 | loss: 0.12022 - acc: 0.9912 -- iter: 032/276
[A[ATraining Step: 110  | total loss: [1m[32m0.10985[0m[0m | time: 11.328s
[2K
| Adam | epoch: 013 | loss: 0.10985 - acc: 0.9920 -- iter: 064/276
[A[ATraining Step: 111  | total loss: [1m[32m0.10030[0m[0m | time: 19.954s
[2K
| Adam | epoch: 013 | loss: 0.10030 - acc: 0.9928 -- iter: 096/276
[A[ATraining Step: 112  | total loss: [1m[32m0.09318[0m[0m | time: 28.464s
[2K
| Adam | epoch: 013 | loss: 0.09318 - acc: 0.9935 -- iter: 128/276
[A[ATraining Step: 113  | total loss: [1m[32m0.08506[0m[0m | time: 37.066s
[2K
| Adam | epoch: 013 | loss: 0.08506 - acc: 0.9942 -- iter: 160/276
[A[ATraining Step: 114  | total loss: [1m[32m0.08785[0m[0m | time: 45.470s
[2K
| Adam | epoch: 013 | loss: 0.08785 - acc: 0.9917 -- iter: 192/276
[A[ATraining Step: 115  | total loss: [1m[32m0.08088[0m[0m | time: 54.061s
[2K
| Adam | epoch: 013 | loss: 0.08088 - acc: 0.9925 -- iter: 224/276
[A[ATraining Step: 116  | total loss: [1m[32m0.07392[0m[0m | time: 62.687s
[2K
| Adam | epoch: 013 | loss: 0.07392 - acc: 0.9932 -- iter: 256/276
[A[ATraining Step: 117  | total loss: [1m[32m0.06732[0m[0m | time: 75.284s
[2K
| Adam | epoch: 013 | loss: 0.06732 - acc: 0.9939 | val_loss: 3.41507 - val_acc: 0.4023 -- iter: 276/276
--
Training Step: 118  | total loss: [1m[32m0.06092[0m[0m | time: 8.409s
[2K
| Adam | epoch: 014 | loss: 0.06092 - acc: 0.9945 -- iter: 032/276
[A[ATraining Step: 119  | total loss: [1m[32m0.05527[0m[0m | time: 13.886s
[2K
| Adam | epoch: 014 | loss: 0.05527 - acc: 0.9951 -- iter: 064/276
[A[ATraining Step: 120  | total loss: [1m[32m0.05028[0m[0m | time: 19.511s
[2K
| Adam | epoch: 014 | loss: 0.05028 - acc: 0.9956 -- iter: 096/276
[A[ATraining Step: 121  | total loss: [1m[32m0.04579[0m[0m | time: 28.148s
[2K
| Adam | epoch: 014 | loss: 0.04579 - acc: 0.9960 -- iter: 128/276
[A[ATraining Step: 122  | total loss: [1m[32m0.04192[0m[0m | time: 36.841s
[2K
| Adam | epoch: 014 | loss: 0.04192 - acc: 0.9964 -- iter: 160/276
[A[ATraining Step: 123  | total loss: [1m[32m0.04552[0m[0m | time: 46.500s
[2K
| Adam | epoch: 014 | loss: 0.04552 - acc: 0.9936 -- iter: 192/276
[A[ATraining Step: 124  | total loss: [1m[32m0.04180[0m[0m | time: 54.879s
[2K
| Adam | epoch: 014 | loss: 0.04180 - acc: 0.9943 -- iter: 224/276
[A[ATraining Step: 125  | total loss: [1m[32m0.03928[0m[0m | time: 63.465s
[2K
| Adam | epoch: 014 | loss: 0.03928 - acc: 0.9948 -- iter: 256/276
[A[ATraining Step: 126  | total loss: [1m[32m0.03634[0m[0m | time: 106.427s
[2K
| Adam | epoch: 014 | loss: 0.03634 - acc: 0.9954 | val_loss: 2.42557 - val_acc: 0.6092 -- iter: 276/276
--
Training Step: 127  | total loss: [1m[32m0.04086[0m[0m | time: 9.876s
[2K
| Adam | epoch: 015 | loss: 0.04086 - acc: 0.9958 -- iter: 032/276
[A[ATraining Step: 128  | total loss: [1m[32m0.05977[0m[0m | time: 19.487s
[2K
| Adam | epoch: 015 | loss: 0.05977 - acc: 0.9931 -- iter: 064/276
[A[ATraining Step: 129  | total loss: [1m[32m0.05425[0m[0m | time: 26.136s
[2K
| Adam | epoch: 015 | loss: 0.05425 - acc: 0.9938 -- iter: 096/276
[A[ATraining Step: 130  | total loss: [1m[32m0.05303[0m[0m | time: 32.169s
[2K
| Adam | epoch: 015 | loss: 0.05303 - acc: 0.9944 -- iter: 128/276
[A[ATraining Step: 131  | total loss: [1m[32m0.04835[0m[0m | time: 41.774s
[2K
| Adam | epoch: 015 | loss: 0.04835 - acc: 0.9950 -- iter: 160/276
[A[ATraining Step: 132  | total loss: [1m[32m0.04429[0m[0m | time: 51.530s
[2K
| Adam | epoch: 015 | loss: 0.04429 - acc: 0.9955 -- iter: 192/276
[A[ATraining Step: 133  | total loss: [1m[32m0.04040[0m[0m | time: 62.547s
[2K
| Adam | epoch: 015 | loss: 0.04040 - acc: 0.9959 -- iter: 224/276
[A[ATraining Step: 134  | total loss: [1m[32m0.03708[0m[0m | time: 72.266s
[2K
| Adam | epoch: 015 | loss: 0.03708 - acc: 0.9963 -- iter: 256/276
[A[ATraining Step: 135  | total loss: [1m[32m0.03373[0m[0m | time: 85.696s
[2K
| Adam | epoch: 015 | loss: 0.03373 - acc: 0.9967 | val_loss: 2.35193 - val_acc: 0.4598 -- iter: 276/276
--
Validation AUC:0.6956043956043957
Validation AUPRC:0.7816735368037171
Test AUC:0.821845174973489
Test AUPRC:0.8255280030257048
BestTestF1Score	0.69	0.5	0.75	0.83	0.59	24	5	41	17	0.01
BestTestMCCScore	0.62	0.45	0.71	0.83	0.49	20	4	42	21	0.02
BestTestAccuracyScore	0.62	0.45	0.71	0.83	0.49	20	4	42	21	0.02
BestValidationF1Score	0.64	0.34	0.64	0.8	0.54	28	7	28	24	0.01
BestValidationMCC	0.62	0.38	0.64	0.86	0.48	25	4	31	27	0.02
BestValidationAccuracy	0.62	0.38	0.64	0.86	0.48	25	4	31	27	0.02
TestPredictions (Threshold:0.02)
CHEMBL1542752,TN,INACT,0.0	CHEMBL1392763,TN,INACT,0.0	CHEMBL2159291,FP,INACT,0.03999999910593033	CHEMBL270834,FN,ACT,0.009999999776482582	CHEMBL3109158,TN,INACT,0.0	CHEMBL411215,TP,ACT,0.029999999329447746	CHEMBL3143639,TN,INACT,0.009999999776482582	CHEMBL197593,TP,ACT,0.9599999785423279	CHEMBL1563513,TN,INACT,0.0	CHEMBL94864,TP,ACT,0.8100000023841858	CHEMBL1812011,TN,INACT,0.0	CHEMBL117803,FN,ACT,0.0	CHEMBL1462676,TN,INACT,0.0	CHEMBL92277,TN,INACT,0.0	CHEMBL540899,TN,INACT,0.0	CHEMBL381709,TP,ACT,0.9100000262260437	CHEMBL319997,TN,INACT,0.009999999776482582	CHEMBL227422,TN,INACT,0.0	CHEMBL3660178,TP,ACT,0.20999999344348907	CHEMBL3660183,TP,ACT,1.0	CHEMBL571837,FN,ACT,0.009999999776482582	CHEMBL442201,TP,ACT,0.09000000357627869	CHEMBL1907778,TN,INACT,0.009999999776482582	CHEMBL227421,TN,INACT,0.0	CHEMBL327715,TP,ACT,0.9300000071525574	CHEMBL393979,FN,ACT,0.019999999552965164	CHEMBL433275,TN,INACT,0.0	CHEMBL3660172,TP,ACT,0.03999999910593033	CHEMBL295786,TN,INACT,0.0	CHEMBL1392593,TN,INACT,0.0	CHEMBL318998,FN,ACT,0.009999999776482582	CHEMBL3143648,TN,INACT,0.0	CHEMBL94254,TN,INACT,0.0	CHEMBL435213,TN,INACT,0.009999999776482582	CHEMBL1704776,TN,INACT,0.0	CHEMBL3660186,TP,ACT,0.9300000071525574	CHEMBL1923468,FN,ACT,0.0	CHEMBL440755,TN,INACT,0.0	CHEMBL108202,TN,INACT,0.0	CHEMBL3408419,TN,INACT,0.0	CHEMBL3125571,TN,INACT,0.0	CHEMBL92615,TP,ACT,0.029999999329447746	CHEMBL2370863,TN,INACT,0.0	CHEMBL226714,TN,INACT,0.0	CHEMBL92964,TN,INACT,0.0	CHEMBL266349,FN,ACT,0.009999999776482582	CHEMBL3109060,TN,INACT,0.0	CHEMBL319264,TN,INACT,0.0	CHEMBL2159299,TN,INACT,0.0	CHEMBL1437349,TN,INACT,0.0	CHEMBL321848,TN,INACT,0.009999999776482582	CHEMBL116136,FN,ACT,0.019999999552965164	CHEMBL135723,FN,ACT,0.019999999552965164	CHEMBL310760,TN,INACT,0.009999999776482582	CHEMBL385900,TP,ACT,0.4399999976158142	CHEMBL426101,FN,ACT,0.009999999776482582	CHEMBL571841,FP,INACT,0.10999999940395355	CHEMBL96494,TP,ACT,0.7799999713897705	CHEMBL457702,FN,ACT,0.0	CHEMBL3109168,TN,INACT,0.019999999552965164	CHEMBL1451569,TN,INACT,0.0	CHEMBL64708,FN,ACT,0.009999999776482582	CHEMBL292300,TN,INACT,0.0	CHEMBL3580759,FP,INACT,0.23999999463558197	CHEMBL264760,FN,ACT,0.0	CHEMBL1945759,TP,ACT,0.05000000074505806	CHEMBL91962,FN,ACT,0.009999999776482582	CHEMBL3247193,TN,INACT,0.0	CHEMBL386275,TP,ACT,0.3700000047683716	CHEMBL3660185,FN,ACT,0.009999999776482582	CHEMBL182309,TN,INACT,0.009999999776482582	CHEMBL2419745,TP,ACT,0.9800000190734863	CHEMBL92251,FN,ACT,0.009999999776482582	CHEMBL479863,TN,INACT,0.009999999776482582	CHEMBL163174,FN,ACT,0.009999999776482582	CHEMBL572191,TP,ACT,0.029999999329447746	CHEMBL1464645,TN,INACT,0.0	CHEMBL1945764,TP,ACT,0.09000000357627869	CHEMBL238708,FN,ACT,0.0	CHEMBL3660174,TP,ACT,0.07999999821186066	CHEMBL444795,TP,ACT,0.029999999329447746	CHEMBL346607,FP,INACT,0.05000000074505806	CHEMBL94622,FN,ACT,0.009999999776482582	CHEMBL227607,TN,INACT,0.0	CHEMBL1907779,TN,INACT,0.009999999776482582	CHEMBL127909,FN,ACT,0.019999999552965164	CHEMBL96376,FN,ACT,0.0	

