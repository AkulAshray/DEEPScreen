ImageNetInceptionV2 CHEMBL3229 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	267
Number of inactive compounds :	178
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3229_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3229_adam_0.0001_15_0.6/
---------------------------------
Training samples: 256
Validation samples: 81
--
Training Step: 1  | time: 36.949s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/256
[A[ATraining Step: 2  | total loss: [1m[32m0.70516[0m[0m | time: 46.433s
[2K
| Adam | epoch: 001 | loss: 0.70516 - acc: 0.3094 -- iter: 064/256
[A[ATraining Step: 3  | total loss: [1m[32m0.69735[0m[0m | time: 55.993s
[2K
| Adam | epoch: 001 | loss: 0.69735 - acc: 0.5165 -- iter: 096/256
[A[ATraining Step: 4  | total loss: [1m[32m0.64997[0m[0m | time: 65.419s
[2K
| Adam | epoch: 001 | loss: 0.64997 - acc: 0.6213 -- iter: 128/256
[A[ATraining Step: 5  | total loss: [1m[32m0.66791[0m[0m | time: 75.120s
[2K
| Adam | epoch: 001 | loss: 0.66791 - acc: 0.6022 -- iter: 160/256
[A[ATraining Step: 6  | total loss: [1m[32m0.59100[0m[0m | time: 85.130s
[2K
| Adam | epoch: 001 | loss: 0.59100 - acc: 0.6972 -- iter: 192/256
[A[ATraining Step: 7  | total loss: [1m[32m0.59760[0m[0m | time: 95.068s
[2K
| Adam | epoch: 001 | loss: 0.59760 - acc: 0.6726 -- iter: 224/256
[A[ATraining Step: 8  | total loss: [1m[32m0.57609[0m[0m | time: 114.176s
[2K
| Adam | epoch: 001 | loss: 0.57609 - acc: 0.6810 | val_loss: 0.65902 - val_acc: 0.6296 -- iter: 256/256
--
Training Step: 9  | total loss: [1m[32m0.57724[0m[0m | time: 10.058s
[2K
| Adam | epoch: 002 | loss: 0.57724 - acc: 0.7175 -- iter: 032/256
[A[ATraining Step: 10  | total loss: [1m[32m0.52279[0m[0m | time: 20.018s
[2K
| Adam | epoch: 002 | loss: 0.52279 - acc: 0.7650 -- iter: 064/256
[A[ATraining Step: 11  | total loss: [1m[32m0.58631[0m[0m | time: 29.628s
[2K
| Adam | epoch: 002 | loss: 0.58631 - acc: 0.7135 -- iter: 096/256
[A[ATraining Step: 12  | total loss: [1m[32m0.61627[0m[0m | time: 38.983s
[2K
| Adam | epoch: 002 | loss: 0.61627 - acc: 0.6877 -- iter: 128/256
[A[ATraining Step: 13  | total loss: [1m[32m0.56215[0m[0m | time: 48.421s
[2K
| Adam | epoch: 002 | loss: 0.56215 - acc: 0.7278 -- iter: 160/256
[A[ATraining Step: 14  | total loss: [1m[32m0.54295[0m[0m | time: 57.747s
[2K
| Adam | epoch: 002 | loss: 0.54295 - acc: 0.7369 -- iter: 192/256
[A[ATraining Step: 15  | total loss: [1m[32m0.50296[0m[0m | time: 67.101s
[2K
| Adam | epoch: 002 | loss: 0.50296 - acc: 0.7665 -- iter: 224/256
[A[ATraining Step: 16  | total loss: [1m[32m0.45966[0m[0m | time: 80.175s
[2K
| Adam | epoch: 002 | loss: 0.45966 - acc: 0.7955 | val_loss: 0.82363 - val_acc: 0.6296 -- iter: 256/256
--
Training Step: 17  | total loss: [1m[32m0.49093[0m[0m | time: 9.175s
[2K
| Adam | epoch: 003 | loss: 0.49093 - acc: 0.7678 -- iter: 032/256
[A[ATraining Step: 18  | total loss: [1m[32m0.45892[0m[0m | time: 18.415s
[2K
| Adam | epoch: 003 | loss: 0.45892 - acc: 0.8266 -- iter: 064/256
[A[ATraining Step: 19  | total loss: [1m[32m0.41800[0m[0m | time: 27.563s
[2K
| Adam | epoch: 003 | loss: 0.41800 - acc: 0.8740 -- iter: 096/256
[A[ATraining Step: 20  | total loss: [1m[32m0.44294[0m[0m | time: 36.922s
[2K
| Adam | epoch: 003 | loss: 0.44294 - acc: 0.8140 -- iter: 128/256
[A[ATraining Step: 21  | total loss: [1m[32m0.41570[0m[0m | time: 46.058s
[2K
| Adam | epoch: 003 | loss: 0.41570 - acc: 0.8426 -- iter: 160/256
[A[ATraining Step: 22  | total loss: [1m[32m0.37597[0m[0m | time: 55.427s
[2K
| Adam | epoch: 003 | loss: 0.37597 - acc: 0.8899 -- iter: 192/256
[A[ATraining Step: 23  | total loss: [1m[32m0.33580[0m[0m | time: 64.634s
[2K
| Adam | epoch: 003 | loss: 0.33580 - acc: 0.9128 -- iter: 224/256
[A[ATraining Step: 24  | total loss: [1m[32m0.30258[0m[0m | time: 77.587s
[2K
| Adam | epoch: 003 | loss: 0.30258 - acc: 0.9285 | val_loss: 0.70082 - val_acc: 0.6296 -- iter: 256/256
--
Training Step: 25  | total loss: [1m[32m0.27681[0m[0m | time: 9.195s
[2K
| Adam | epoch: 004 | loss: 0.27681 - acc: 0.9395 -- iter: 032/256
[A[ATraining Step: 26  | total loss: [1m[32m0.26507[0m[0m | time: 18.731s
[2K
| Adam | epoch: 004 | loss: 0.26507 - acc: 0.9472 -- iter: 064/256
[A[ATraining Step: 27  | total loss: [1m[32m0.25467[0m[0m | time: 27.937s
[2K
| Adam | epoch: 004 | loss: 0.25467 - acc: 0.9447 -- iter: 096/256
[A[ATraining Step: 28  | total loss: [1m[32m0.22957[0m[0m | time: 37.595s
[2K
| Adam | epoch: 004 | loss: 0.22957 - acc: 0.9585 -- iter: 128/256
[A[ATraining Step: 29  | total loss: [1m[32m0.20801[0m[0m | time: 46.838s
[2K
| Adam | epoch: 004 | loss: 0.20801 - acc: 0.9610 -- iter: 160/256
[A[ATraining Step: 30  | total loss: [1m[32m0.20009[0m[0m | time: 55.990s
[2K
| Adam | epoch: 004 | loss: 0.20009 - acc: 0.9555 -- iter: 192/256
[A[ATraining Step: 31  | total loss: [1m[32m0.16820[0m[0m | time: 65.978s
[2K
| Adam | epoch: 004 | loss: 0.16820 - acc: 0.9657 -- iter: 224/256
[A[ATraining Step: 32  | total loss: [1m[32m0.14182[0m[0m | time: 79.028s
[2K
| Adam | epoch: 004 | loss: 0.14182 - acc: 0.9734 | val_loss: 1.06658 - val_acc: 0.3704 -- iter: 256/256
--
Training Step: 33  | total loss: [1m[32m0.11951[0m[0m | time: 9.521s
[2K
| Adam | epoch: 005 | loss: 0.11951 - acc: 0.9793 -- iter: 032/256
[A[ATraining Step: 34  | total loss: [1m[32m0.10429[0m[0m | time: 18.809s
[2K
| Adam | epoch: 005 | loss: 0.10429 - acc: 0.9837 -- iter: 064/256
[A[ATraining Step: 35  | total loss: [1m[32m0.09477[0m[0m | time: 27.921s
[2K
| Adam | epoch: 005 | loss: 0.09477 - acc: 0.9871 -- iter: 096/256
[A[ATraining Step: 36  | total loss: [1m[32m0.08047[0m[0m | time: 37.126s
[2K
| Adam | epoch: 005 | loss: 0.08047 - acc: 0.9898 -- iter: 128/256
[A[ATraining Step: 37  | total loss: [1m[32m0.06824[0m[0m | time: 46.595s
[2K
| Adam | epoch: 005 | loss: 0.06824 - acc: 0.9918 -- iter: 160/256
[A[ATraining Step: 38  | total loss: [1m[32m0.06075[0m[0m | time: 55.726s
[2K
| Adam | epoch: 005 | loss: 0.06075 - acc: 0.9934 -- iter: 192/256
[A[ATraining Step: 39  | total loss: [1m[32m0.05341[0m[0m | time: 64.873s
[2K
| Adam | epoch: 005 | loss: 0.05341 - acc: 0.9947 -- iter: 224/256
[A[ATraining Step: 40  | total loss: [1m[32m0.07269[0m[0m | time: 78.342s
[2K
| Adam | epoch: 005 | loss: 0.07269 - acc: 0.9898 | val_loss: 1.20448 - val_acc: 0.3704 -- iter: 256/256
--
Training Step: 41  | total loss: [1m[32m0.06279[0m[0m | time: 9.894s
[2K
| Adam | epoch: 006 | loss: 0.06279 - acc: 0.9917 -- iter: 032/256
[A[ATraining Step: 42  | total loss: [1m[32m0.05292[0m[0m | time: 21.215s
[2K
| Adam | epoch: 006 | loss: 0.05292 - acc: 0.9932 -- iter: 064/256
[A[ATraining Step: 43  | total loss: [1m[32m0.04490[0m[0m | time: 30.966s
[2K
| Adam | epoch: 006 | loss: 0.04490 - acc: 0.9944 -- iter: 096/256
[A[ATraining Step: 44  | total loss: [1m[32m0.03923[0m[0m | time: 41.101s
[2K
| Adam | epoch: 006 | loss: 0.03923 - acc: 0.9954 -- iter: 128/256
[A[ATraining Step: 45  | total loss: [1m[32m0.03415[0m[0m | time: 51.929s
[2K
| Adam | epoch: 006 | loss: 0.03415 - acc: 0.9961 -- iter: 160/256
[A[ATraining Step: 46  | total loss: [1m[32m0.02960[0m[0m | time: 61.198s
[2K
| Adam | epoch: 006 | loss: 0.02960 - acc: 0.9968 -- iter: 192/256
[A[ATraining Step: 47  | total loss: [1m[32m0.06971[0m[0m | time: 71.805s
[2K
| Adam | epoch: 006 | loss: 0.06971 - acc: 0.9922 -- iter: 224/256
[A[ATraining Step: 48  | total loss: [1m[32m0.05958[0m[0m | time: 85.219s
[2K
| Adam | epoch: 006 | loss: 0.05958 - acc: 0.9935 | val_loss: 1.22433 - val_acc: 0.3704 -- iter: 256/256
--
Training Step: 49  | total loss: [1m[32m0.07967[0m[0m | time: 13.189s
[2K
| Adam | epoch: 007 | loss: 0.07967 - acc: 0.9896 -- iter: 032/256
[A[ATraining Step: 50  | total loss: [1m[32m0.07860[0m[0m | time: 22.354s
[2K
| Adam | epoch: 007 | loss: 0.07860 - acc: 0.9863 -- iter: 064/256
[A[ATraining Step: 51  | total loss: [1m[32m0.06732[0m[0m | time: 35.315s
[2K
| Adam | epoch: 007 | loss: 0.06732 - acc: 0.9884 -- iter: 096/256
[A[ATraining Step: 52  | total loss: [1m[32m0.05804[0m[0m | time: 61.352s
[2K
| Adam | epoch: 007 | loss: 0.05804 - acc: 0.9901 -- iter: 128/256
[A[ATraining Step: 53  | total loss: [1m[32m0.05064[0m[0m | time: 93.513s
[2K
| Adam | epoch: 007 | loss: 0.05064 - acc: 0.9916 -- iter: 160/256
[A[ATraining Step: 54  | total loss: [1m[32m0.07082[0m[0m | time: 118.126s
[2K
| Adam | epoch: 007 | loss: 0.07082 - acc: 0.9883 -- iter: 192/256
[A[ATraining Step: 55  | total loss: [1m[32m0.07494[0m[0m | time: 144.846s
[2K
| Adam | epoch: 007 | loss: 0.07494 - acc: 0.9855 -- iter: 224/256
[A[ATraining Step: 56  | total loss: [1m[32m0.06725[0m[0m | time: 183.772s
[2K
| Adam | epoch: 007 | loss: 0.06725 - acc: 0.9875 | val_loss: 0.69137 - val_acc: 0.6420 -- iter: 256/256
--
Training Step: 57  | total loss: [1m[32m0.05915[0m[0m | time: 12.087s
[2K
| Adam | epoch: 008 | loss: 0.05915 - acc: 0.9893 -- iter: 032/256
[A[ATraining Step: 58  | total loss: [1m[32m0.05230[0m[0m | time: 24.328s
[2K
| Adam | epoch: 008 | loss: 0.05230 - acc: 0.9907 -- iter: 064/256
[A[ATraining Step: 59  | total loss: [1m[32m0.04655[0m[0m | time: 36.300s
[2K
| Adam | epoch: 008 | loss: 0.04655 - acc: 0.9920 -- iter: 096/256
[A[ATraining Step: 60  | total loss: [1m[32m0.04146[0m[0m | time: 54.231s
[2K
| Adam | epoch: 008 | loss: 0.04146 - acc: 0.9930 -- iter: 128/256
[A[ATraining Step: 61  | total loss: [1m[32m0.03951[0m[0m | time: 65.784s
[2K
| Adam | epoch: 008 | loss: 0.03951 - acc: 0.9939 -- iter: 160/256
[A[ATraining Step: 62  | total loss: [1m[32m0.03547[0m[0m | time: 77.582s
[2K
| Adam | epoch: 008 | loss: 0.03547 - acc: 0.9947 -- iter: 192/256
[A[ATraining Step: 63  | total loss: [1m[32m0.03208[0m[0m | time: 89.855s
[2K
| Adam | epoch: 008 | loss: 0.03208 - acc: 0.9954 -- iter: 224/256
[A[ATraining Step: 64  | total loss: [1m[32m0.02906[0m[0m | time: 113.808s
[2K
| Adam | epoch: 008 | loss: 0.02906 - acc: 0.9960 | val_loss: 1.19152 - val_acc: 0.5432 -- iter: 256/256
--
Training Step: 65  | total loss: [1m[32m0.02665[0m[0m | time: 14.577s
[2K
| Adam | epoch: 009 | loss: 0.02665 - acc: 0.9965 -- iter: 032/256
[A[ATraining Step: 66  | total loss: [1m[32m0.02406[0m[0m | time: 26.526s
[2K
| Adam | epoch: 009 | loss: 0.02406 - acc: 0.9969 -- iter: 064/256
[A[ATraining Step: 67  | total loss: [1m[32m0.04221[0m[0m | time: 39.989s
[2K
| Adam | epoch: 009 | loss: 0.04221 - acc: 0.9935 -- iter: 096/256
[A[ATraining Step: 68  | total loss: [1m[32m0.03977[0m[0m | time: 52.698s
[2K
| Adam | epoch: 009 | loss: 0.03977 - acc: 0.9943 -- iter: 128/256
[A[ATraining Step: 69  | total loss: [1m[32m0.03571[0m[0m | time: 64.983s
[2K
| Adam | epoch: 009 | loss: 0.03571 - acc: 0.9950 -- iter: 160/256
[A[ATraining Step: 70  | total loss: [1m[32m0.03263[0m[0m | time: 76.143s
[2K
| Adam | epoch: 009 | loss: 0.03263 - acc: 0.9955 -- iter: 192/256
[A[ATraining Step: 71  | total loss: [1m[32m0.03194[0m[0m | time: 89.105s
[2K
| Adam | epoch: 009 | loss: 0.03194 - acc: 0.9960 -- iter: 224/256
[A[ATraining Step: 72  | total loss: [1m[32m0.02939[0m[0m | time: 107.073s
[2K
| Adam | epoch: 009 | loss: 0.02939 - acc: 0.9965 | val_loss: 0.52173 - val_acc: 0.7531 -- iter: 256/256
--
Training Step: 73  | total loss: [1m[32m0.02684[0m[0m | time: 11.728s
[2K
| Adam | epoch: 010 | loss: 0.02684 - acc: 0.9969 -- iter: 032/256
[A[ATraining Step: 74  | total loss: [1m[32m0.02436[0m[0m | time: 26.435s
[2K
| Adam | epoch: 010 | loss: 0.02436 - acc: 0.9972 -- iter: 064/256
[A[ATraining Step: 75  | total loss: [1m[32m0.02205[0m[0m | time: 49.892s
[2K
| Adam | epoch: 010 | loss: 0.02205 - acc: 0.9975 -- iter: 096/256
[A[ATraining Step: 76  | total loss: [1m[32m0.04253[0m[0m | time: 61.058s
[2K
| Adam | epoch: 010 | loss: 0.04253 - acc: 0.9944 -- iter: 128/256
[A[ATraining Step: 77  | total loss: [1m[32m0.03894[0m[0m | time: 76.806s
[2K
| Adam | epoch: 010 | loss: 0.03894 - acc: 0.9950 -- iter: 160/256
[A[ATraining Step: 78  | total loss: [1m[32m0.03525[0m[0m | time: 98.143s
[2K
| Adam | epoch: 010 | loss: 0.03525 - acc: 0.9955 -- iter: 192/256
[A[ATraining Step: 79  | total loss: [1m[32m0.03190[0m[0m | time: 109.646s
[2K
| Adam | epoch: 010 | loss: 0.03190 - acc: 0.9960 -- iter: 224/256
[A[ATraining Step: 80  | total loss: [1m[32m0.02899[0m[0m | time: 128.365s
[2K
| Adam | epoch: 010 | loss: 0.02899 - acc: 0.9964 | val_loss: 0.50261 - val_acc: 0.7901 -- iter: 256/256
--
Training Step: 81  | total loss: [1m[32m0.02649[0m[0m | time: 11.990s
[2K
| Adam | epoch: 011 | loss: 0.02649 - acc: 0.9968 -- iter: 032/256
[A[ATraining Step: 82  | total loss: [1m[32m0.02426[0m[0m | time: 29.743s
[2K
| Adam | epoch: 011 | loss: 0.02426 - acc: 0.9971 -- iter: 064/256
[A[ATraining Step: 83  | total loss: [1m[32m0.02231[0m[0m | time: 46.909s
[2K
| Adam | epoch: 011 | loss: 0.02231 - acc: 0.9974 -- iter: 096/256
[A[ATraining Step: 84  | total loss: [1m[32m0.02041[0m[0m | time: 62.066s
[2K
| Adam | epoch: 011 | loss: 0.02041 - acc: 0.9977 -- iter: 128/256
[A[ATraining Step: 85  | total loss: [1m[32m0.05043[0m[0m | time: 87.136s
[2K
| Adam | epoch: 011 | loss: 0.05043 - acc: 0.9948 -- iter: 160/256
[A[ATraining Step: 86  | total loss: [1m[32m0.04660[0m[0m | time: 111.347s
[2K
| Adam | epoch: 011 | loss: 0.04660 - acc: 0.9953 -- iter: 192/256
[A[ATraining Step: 87  | total loss: [1m[32m0.04239[0m[0m | time: 137.150s
[2K
| Adam | epoch: 011 | loss: 0.04239 - acc: 0.9958 -- iter: 224/256
[A[ATraining Step: 88  | total loss: [1m[32m0.05435[0m[0m | time: 175.501s
[2K
| Adam | epoch: 011 | loss: 0.05435 - acc: 0.9931 | val_loss: 1.32306 - val_acc: 0.5062 -- iter: 256/256
--
Training Step: 89  | total loss: [1m[32m0.04987[0m[0m | time: 63.845s
[2K
| Adam | epoch: 012 | loss: 0.04987 - acc: 0.9938 -- iter: 032/256
[A[ATraining Step: 90  | total loss: [1m[32m0.04606[0m[0m | time: 75.791s
[2K
| Adam | epoch: 012 | loss: 0.04606 - acc: 0.9944 -- iter: 064/256
[A[ATraining Step: 91  | total loss: [1m[32m0.04244[0m[0m | time: 89.305s
[2K
| Adam | epoch: 012 | loss: 0.04244 - acc: 0.9949 -- iter: 096/256
[A[ATraining Step: 92  | total loss: [1m[32m0.06872[0m[0m | time: 106.967s
[2K
| Adam | epoch: 012 | loss: 0.06872 - acc: 0.9923 -- iter: 128/256
[A[ATraining Step: 93  | total loss: [1m[32m0.08578[0m[0m | time: 122.135s
[2K
| Adam | epoch: 012 | loss: 0.08578 - acc: 0.9900 -- iter: 160/256
[A[ATraining Step: 94  | total loss: [1m[32m0.09887[0m[0m | time: 133.093s
[2K
| Adam | epoch: 012 | loss: 0.09887 - acc: 0.9878 -- iter: 192/256
[A[ATraining Step: 95  | total loss: [1m[32m0.08985[0m[0m | time: 154.845s
[2K
| Adam | epoch: 012 | loss: 0.08985 - acc: 0.9891 -- iter: 224/256
[A[ATraining Step: 96  | total loss: [1m[32m0.08300[0m[0m | time: 171.535s
[2K
| Adam | epoch: 012 | loss: 0.08300 - acc: 0.9902 | val_loss: 3.55027 - val_acc: 0.6296 -- iter: 256/256
--
Training Step: 97  | total loss: [1m[32m0.08292[0m[0m | time: 11.592s
[2K
| Adam | epoch: 013 | loss: 0.08292 - acc: 0.9880 -- iter: 032/256
[A[ATraining Step: 98  | total loss: [1m[32m0.08179[0m[0m | time: 36.212s
[2K
| Adam | epoch: 013 | loss: 0.08179 - acc: 0.9861 -- iter: 064/256
[A[ATraining Step: 99  | total loss: [1m[32m0.07703[0m[0m | time: 52.194s
[2K
| Adam | epoch: 013 | loss: 0.07703 - acc: 0.9875 -- iter: 096/256
[A[ATraining Step: 100  | total loss: [1m[32m0.07169[0m[0m | time: 70.813s
[2K
| Adam | epoch: 013 | loss: 0.07169 - acc: 0.9887 -- iter: 128/256
[A[ATraining Step: 101  | total loss: [1m[32m0.06643[0m[0m | time: 88.206s
[2K
| Adam | epoch: 013 | loss: 0.06643 - acc: 0.9899 -- iter: 160/256
[A[ATraining Step: 102  | total loss: [1m[32m0.06384[0m[0m | time: 100.629s
[2K
| Adam | epoch: 013 | loss: 0.06384 - acc: 0.9909 -- iter: 192/256
[A[ATraining Step: 103  | total loss: [1m[32m0.08220[0m[0m | time: 119.392s
[2K
| Adam | epoch: 013 | loss: 0.08220 - acc: 0.9887 -- iter: 224/256
[A[ATraining Step: 104  | total loss: [1m[32m0.08275[0m[0m | time: 136.003s
[2K
| Adam | epoch: 013 | loss: 0.08275 - acc: 0.9898 | val_loss: 2.72622 - val_acc: 0.3827 -- iter: 256/256
--
Training Step: 105  | total loss: [1m[32m0.08507[0m[0m | time: 15.172s
[2K
| Adam | epoch: 014 | loss: 0.08507 - acc: 0.9877 -- iter: 032/256
[A[ATraining Step: 106  | total loss: [1m[32m0.07723[0m[0m | time: 32.430s
[2K
| Adam | epoch: 014 | loss: 0.07723 - acc: 0.9889 -- iter: 064/256
[A[ATraining Step: 107  | total loss: [1m[32m0.07076[0m[0m | time: 48.451s
[2K
| Adam | epoch: 014 | loss: 0.07076 - acc: 0.9900 -- iter: 096/256
[A[ATraining Step: 108  | total loss: [1m[32m0.06704[0m[0m | time: 61.188s
[2K
| Adam | epoch: 014 | loss: 0.06704 - acc: 0.9879 -- iter: 128/256
[A[ATraining Step: 109  | total loss: [1m[32m0.06111[0m[0m | time: 77.964s
[2K
| Adam | epoch: 014 | loss: 0.06111 - acc: 0.9891 -- iter: 160/256
[A[ATraining Step: 110  | total loss: [1m[32m0.05624[0m[0m | time: 93.866s
[2K
| Adam | epoch: 014 | loss: 0.05624 - acc: 0.9902 -- iter: 192/256
[A[ATraining Step: 111  | total loss: [1m[32m0.05139[0m[0m | time: 120.793s
[2K
| Adam | epoch: 014 | loss: 0.05139 - acc: 0.9912 -- iter: 224/256
[A[ATraining Step: 112  | total loss: [1m[32m0.04776[0m[0m | time: 137.838s
[2K
| Adam | epoch: 014 | loss: 0.04776 - acc: 0.9921 | val_loss: 6.06913 - val_acc: 0.3704 -- iter: 256/256
--
Training Step: 113  | total loss: [1m[32m0.04351[0m[0m | time: 11.683s
[2K
| Adam | epoch: 015 | loss: 0.04351 - acc: 0.9929 -- iter: 032/256
[A[ATraining Step: 114  | total loss: [1m[32m0.04109[0m[0m | time: 33.113s
[2K
| Adam | epoch: 015 | loss: 0.04109 - acc: 0.9936 -- iter: 064/256
[A[ATraining Step: 115  | total loss: [1m[32m0.04262[0m[0m | time: 42.134s
[2K
| Adam | epoch: 015 | loss: 0.04262 - acc: 0.9942 -- iter: 096/256
[A[ATraining Step: 116  | total loss: [1m[32m0.03904[0m[0m | time: 50.968s
[2K
| Adam | epoch: 015 | loss: 0.03904 - acc: 0.9948 -- iter: 128/256
[A[ATraining Step: 117  | total loss: [1m[32m0.03785[0m[0m | time: 59.950s
[2K
| Adam | epoch: 015 | loss: 0.03785 - acc: 0.9953 -- iter: 160/256
[A[ATraining Step: 118  | total loss: [1m[32m0.03513[0m[0m | time: 69.183s
[2K
| Adam | epoch: 015 | loss: 0.03513 - acc: 0.9958 -- iter: 192/256
[A[ATraining Step: 119  | total loss: [1m[32m0.03217[0m[0m | time: 78.284s
[2K
| Adam | epoch: 015 | loss: 0.03217 - acc: 0.9962 -- iter: 224/256
[A[ATraining Step: 120  | total loss: [1m[32m0.02946[0m[0m | time: 91.209s
[2K
| Adam | epoch: 015 | loss: 0.02946 - acc: 0.9966 | val_loss: 1.38448 - val_acc: 0.6049 -- iter: 256/256
--
Validation AUC:0.75359477124183
Validation AUPRC:0.8427632469816222
Test AUC:0.7450000000000001
Test AUPRC:0.8556083562182383
BestTestF1Score	0.8	0.38	0.73	0.81	0.79	44	10	15	12	0.02
BestTestMCCScore	0.8	0.38	0.73	0.81	0.79	44	10	15	12	0.02
BestTestAccuracyScore	0.8	0.38	0.73	0.81	0.79	44	10	15	12	0.02
BestValidationF1Score	0.79	0.41	0.73	0.77	0.8	41	12	18	10	0.02
BestValidationMCC	0.79	0.41	0.73	0.77	0.8	41	12	18	10	0.02
BestValidationAccuracy	0.79	0.41	0.73	0.77	0.8	41	12	18	10	0.02
TestPredictions (Threshold:0.02)
CHEMBL3125311,TP,ACT,0.9300000071525574	CHEMBL1651534,TP,ACT,0.9300000071525574	CHEMBL3683957,FP,INACT,0.28999999165534973	CHEMBL1798047,TN,INACT,0.0	CHEMBL2207341,TP,ACT,0.9599999785423279	CHEMBL567622,TN,INACT,0.0	CHEMBL2011311,TP,ACT,0.36000001430511475	CHEMBL177681,TN,INACT,0.0	CHEMBL466967,FP,INACT,0.2800000011920929	CHEMBL245215,TP,ACT,0.6399999856948853	CHEMBL2386566,TP,ACT,0.18000000715255737	CHEMBL2376859,FN,ACT,0.009999999776482582	CHEMBL513789,FN,ACT,0.0	CHEMBL504330,TP,ACT,0.9800000190734863	CHEMBL113263,TP,ACT,0.4099999964237213	CHEMBL270720,TP,ACT,0.07000000029802322	CHEMBL21427,FN,ACT,0.0	CHEMBL412117,TP,ACT,0.20999999344348907	CHEMBL461539,TP,ACT,0.7900000214576721	CHEMBL2262725,TN,INACT,0.0	CHEMBL3220520,TP,ACT,0.9700000286102295	CHEMBL2376856,FN,ACT,0.0	CHEMBL230970,FP,INACT,0.8799999952316284	CHEMBL469051,TP,ACT,0.800000011920929	CHEMBL255116,TP,ACT,0.029999999329447746	CHEMBL183390,TP,ACT,0.11999999731779099	CHEMBL227291,TP,ACT,1.0	CHEMBL560500,TN,INACT,0.0	CHEMBL396951,TP,ACT,0.7900000214576721	CHEMBL76745,TP,ACT,0.47999998927116394	CHEMBL573689,TN,INACT,0.0	CHEMBL2164588,TP,ACT,0.9599999785423279	CHEMBL3683973,TP,ACT,0.5299999713897705	CHEMBL562182,TP,ACT,0.3100000023841858	CHEMBL1812589,TP,ACT,0.05999999865889549	CHEMBL80950,TN,INACT,0.0	CHEMBL367504,TN,INACT,0.019999999552965164	CHEMBL39412,TP,ACT,0.05999999865889549	CHEMBL2448079,FP,INACT,0.7900000214576721	CHEMBL279796,TP,ACT,0.9800000190734863	CHEMBL2376220,TP,ACT,0.8700000047683716	CHEMBL597149,TN,INACT,0.0	CHEMBL228456,FP,INACT,0.029999999329447746	CHEMBL2011478,TP,ACT,0.9599999785423279	CHEMBL219615,FP,INACT,0.9900000095367432	CHEMBL272830,TP,ACT,0.9900000095367432	CHEMBL1952077,FN,ACT,0.0	CHEMBL1316,TN,INACT,0.0	CHEMBL565892,FP,INACT,0.5	CHEMBL2047526,TP,ACT,0.8600000143051147	CHEMBL213901,FP,INACT,0.49000000953674316	CHEMBL3113268,TP,ACT,0.9900000095367432	CHEMBL451441,FN,ACT,0.0	CHEMBL2402916,FN,ACT,0.0	CHEMBL77271,FN,ACT,0.0	CHEMBL1761296,TP,ACT,0.07000000029802322	CHEMBL512965,TP,ACT,0.5199999809265137	CHEMBL209996,FN,ACT,0.009999999776482582	CHEMBL2326196,TP,ACT,0.9900000095367432	CHEMBL1241253,TN,INACT,0.0	CHEMBL3264479,TP,ACT,0.9800000190734863	CHEMBL3264474,TP,ACT,0.9900000095367432	CHEMBL89508,TP,ACT,0.38999998569488525	CHEMBL3683944,TP,ACT,0.8799999952316284	CHEMBL287364,TN,INACT,0.0	CHEMBL3218803,TP,ACT,0.6200000047683716	CHEMBL2386561,TP,ACT,0.05999999865889549	CHEMBL462423,TP,ACT,0.8399999737739563	CHEMBL1761293,FN,ACT,0.0	CHEMBL1080129,TP,ACT,0.05999999865889549	CHEMBL236385,FP,INACT,0.23000000417232513	CHEMBL1242893,TN,INACT,0.0	CHEMBL2376845,FN,ACT,0.0	CHEMBL3318613,TP,ACT,0.6100000143051147	CHEMBL273075,FP,INACT,0.9599999785423279	CHEMBL1952090,FN,ACT,0.0	CHEMBL469241,TP,ACT,0.9800000190734863	CHEMBL2158922,TN,INACT,0.0	CHEMBL287130,TN,INACT,0.0	CHEMBL2376206,TP,ACT,0.5	CHEMBL448688,TP,ACT,0.9900000095367432	

