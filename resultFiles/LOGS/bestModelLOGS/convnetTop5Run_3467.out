CNNModel CHEMBL2413 RMSprop 0.001 30 128 0 0.8 False True
Number of active compounds :	611
Number of inactive compounds :	611
---------------------------------
Run id: CNNModel_CHEMBL2413_RMSprop_0.001_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2413_RMSprop_0.001_30_128_0.8_True/
---------------------------------
Training samples: 778
Validation samples: 244
--
Training Step: 1  | time: 1.755s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/778
[A[ATraining Step: 2  | total loss: [1m[32m0.62393[0m[0m | time: 3.771s
[2K
| RMSProp | epoch: 001 | loss: 0.62393 - acc: 0.4500 -- iter: 064/778
[A[ATraining Step: 3  | total loss: [1m[32m0.68034[0m[0m | time: 6.056s
[2K
| RMSProp | epoch: 001 | loss: 0.68034 - acc: 0.4909 -- iter: 096/778
[A[ATraining Step: 4  | total loss: [1m[32m0.69010[0m[0m | time: 7.789s
[2K
| RMSProp | epoch: 001 | loss: 0.69010 - acc: 0.4040 -- iter: 128/778
[A[ATraining Step: 5  | total loss: [1m[32m0.69210[0m[0m | time: 10.326s
[2K
| RMSProp | epoch: 001 | loss: 0.69210 - acc: 0.5137 -- iter: 160/778
[A[ATraining Step: 6  | total loss: [1m[32m0.69263[0m[0m | time: 17.246s
[2K
| RMSProp | epoch: 001 | loss: 0.69263 - acc: 0.5652 -- iter: 192/778
[A[ATraining Step: 7  | total loss: [1m[32m0.69287[0m[0m | time: 18.653s
[2K
| RMSProp | epoch: 001 | loss: 0.69287 - acc: 0.5636 -- iter: 224/778
[A[ATraining Step: 8  | total loss: [1m[32m0.69311[0m[0m | time: 19.730s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5278 -- iter: 256/778
[A[ATraining Step: 9  | total loss: [1m[32m0.69335[0m[0m | time: 21.134s
[2K
| RMSProp | epoch: 001 | loss: 0.69335 - acc: 0.4469 -- iter: 288/778
[A[ATraining Step: 10  | total loss: [1m[32m0.69327[0m[0m | time: 22.402s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.4735 -- iter: 320/778
[A[ATraining Step: 11  | total loss: [1m[32m0.69331[0m[0m | time: 23.719s
[2K
| RMSProp | epoch: 001 | loss: 0.69331 - acc: 0.4564 -- iter: 352/778
[A[ATraining Step: 12  | total loss: [1m[32m0.69331[0m[0m | time: 24.753s
[2K
| RMSProp | epoch: 001 | loss: 0.69331 - acc: 0.4479 -- iter: 384/778
[A[ATraining Step: 13  | total loss: [1m[32m0.69323[0m[0m | time: 25.780s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.5104 -- iter: 416/778
[A[ATraining Step: 14  | total loss: [1m[32m0.69298[0m[0m | time: 27.160s
[2K
| RMSProp | epoch: 001 | loss: 0.69298 - acc: 0.5701 -- iter: 448/778
[A[ATraining Step: 15  | total loss: [1m[32m0.69306[0m[0m | time: 28.846s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5549 -- iter: 480/778
[A[ATraining Step: 16  | total loss: [1m[32m0.69315[0m[0m | time: 30.464s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.4991 -- iter: 512/778
[A[ATraining Step: 17  | total loss: [1m[32m0.69328[0m[0m | time: 33.718s
[2K
| RMSProp | epoch: 001 | loss: 0.69328 - acc: 0.4770 -- iter: 544/778
[A[ATraining Step: 18  | total loss: [1m[32m0.69338[0m[0m | time: 42.190s
[2K
| RMSProp | epoch: 001 | loss: 0.69338 - acc: 0.4417 -- iter: 576/778
[A[ATraining Step: 19  | total loss: [1m[32m0.69332[0m[0m | time: 49.325s
[2K
| RMSProp | epoch: 001 | loss: 0.69332 - acc: 0.4611 -- iter: 608/778
[A[ATraining Step: 20  | total loss: [1m[32m0.69329[0m[0m | time: 56.512s
[2K
| RMSProp | epoch: 001 | loss: 0.69329 - acc: 0.4736 -- iter: 640/778
[A[ATraining Step: 21  | total loss: [1m[32m0.69309[0m[0m | time: 65.311s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5497 -- iter: 672/778
[A[ATraining Step: 22  | total loss: [1m[32m0.69310[0m[0m | time: 72.731s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5442 -- iter: 704/778
[A[ATraining Step: 23  | total loss: [1m[32m0.69320[0m[0m | time: 74.546s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.5223 -- iter: 736/778
[A[ATraining Step: 24  | total loss: [1m[32m0.69309[0m[0m | time: 75.733s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5424 -- iter: 768/778
[A[ATraining Step: 25  | total loss: [1m[32m0.69312[0m[0m | time: 78.120s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.5138 | val_loss: 0.69313 - val_acc: 0.5041 -- iter: 778/778
--
Training Step: 26  | total loss: [1m[32m0.69309[0m[0m | time: 0.535s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5366 -- iter: 032/778
[A[ATraining Step: 27  | total loss: [1m[32m0.69309[0m[0m | time: 1.945s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5529 -- iter: 064/778
[A[ATraining Step: 28  | total loss: [1m[32m0.69304[0m[0m | time: 3.369s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5475 -- iter: 096/778
[A[ATraining Step: 29  | total loss: [1m[32m0.69296[0m[0m | time: 4.760s
[2K
| RMSProp | epoch: 002 | loss: 0.69296 - acc: 0.5663 -- iter: 128/778
[A[ATraining Step: 30  | total loss: [1m[32m0.69305[0m[0m | time: 6.195s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5506 -- iter: 160/778
[A[ATraining Step: 31  | total loss: [1m[32m0.69310[0m[0m | time: 7.709s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5389 -- iter: 192/778
[A[ATraining Step: 32  | total loss: [1m[32m0.69309[0m[0m | time: 9.438s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5302 -- iter: 224/778
[A[ATraining Step: 33  | total loss: [1m[32m0.69306[0m[0m | time: 10.907s
[2K
| RMSProp | epoch: 002 | loss: 0.69306 - acc: 0.5373 -- iter: 256/778
[A[ATraining Step: 34  | total loss: [1m[32m0.69297[0m[0m | time: 14.079s
[2K
| RMSProp | epoch: 002 | loss: 0.69297 - acc: 0.5360 -- iter: 288/778
[A[ATraining Step: 35  | total loss: [1m[32m0.69278[0m[0m | time: 17.571s
[2K
| RMSProp | epoch: 002 | loss: 0.69278 - acc: 0.5742 -- iter: 320/778
[A[ATraining Step: 36  | total loss: [1m[32m0.69278[0m[0m | time: 23.497s
[2K
| RMSProp | epoch: 002 | loss: 0.69278 - acc: 0.5782 -- iter: 352/778
[A[ATraining Step: 37  | total loss: [1m[32m0.69297[0m[0m | time: 30.097s
[2K
| RMSProp | epoch: 002 | loss: 0.69297 - acc: 0.5438 -- iter: 384/778
[A[ATraining Step: 38  | total loss: [1m[32m0.69309[0m[0m | time: 33.603s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5230 -- iter: 416/778
[A[ATraining Step: 39  | total loss: [1m[32m0.69310[0m[0m | time: 38.225s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5246 -- iter: 448/778
[A[ATraining Step: 40  | total loss: [1m[32m0.69318[0m[0m | time: 42.495s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.5083 -- iter: 480/778
[A[ATraining Step: 41  | total loss: [1m[32m0.69322[0m[0m | time: 43.649s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4953 -- iter: 512/778
[A[ATraining Step: 42  | total loss: [1m[32m0.69327[0m[0m | time: 44.842s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.4961 -- iter: 544/778
[A[ATraining Step: 43  | total loss: [1m[32m0.69327[0m[0m | time: 46.158s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.4858 -- iter: 576/778
[A[ATraining Step: 44  | total loss: [1m[32m0.69325[0m[0m | time: 47.396s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4828 -- iter: 608/778
[A[ATraining Step: 45  | total loss: [1m[32m0.69328[0m[0m | time: 48.754s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4645 -- iter: 640/778
[A[ATraining Step: 46  | total loss: [1m[32m0.69334[0m[0m | time: 50.296s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4548 -- iter: 672/778
[A[ATraining Step: 47  | total loss: [1m[32m0.69332[0m[0m | time: 51.715s
[2K
| RMSProp | epoch: 002 | loss: 0.69332 - acc: 0.4673 -- iter: 704/778
[A[ATraining Step: 48  | total loss: [1m[32m0.69325[0m[0m | time: 52.978s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4826 -- iter: 736/778
[A[ATraining Step: 49  | total loss: [1m[32m0.69324[0m[0m | time: 54.464s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4706 -- iter: 768/778
[A[ATraining Step: 50  | total loss: [1m[32m0.69320[0m[0m | time: 70.188s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4751 | val_loss: 0.69313 - val_acc: 0.5041 -- iter: 778/778
--
Training Step: 51  | total loss: [1m[32m0.69324[0m[0m | time: 0.576s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.4694 -- iter: 032/778
[A[ATraining Step: 52  | total loss: [1m[32m0.69318[0m[0m | time: 2.398s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.4890 -- iter: 064/778
[A[ATraining Step: 53  | total loss: [1m[32m0.69319[0m[0m | time: 9.450s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5054 -- iter: 096/778
[A[ATraining Step: 54  | total loss: [1m[32m0.69319[0m[0m | time: 15.798s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5046 -- iter: 128/778
[A[ATraining Step: 55  | total loss: [1m[32m0.69327[0m[0m | time: 22.337s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.4905 -- iter: 160/778
[A[ATraining Step: 56  | total loss: [1m[32m0.69335[0m[0m | time: 30.879s
[2K
| RMSProp | epoch: 003 | loss: 0.69335 - acc: 0.4743 -- iter: 192/778
[A[ATraining Step: 57  | total loss: [1m[32m0.69330[0m[0m | time: 36.873s
[2K
| RMSProp | epoch: 003 | loss: 0.69330 - acc: 0.4692 -- iter: 224/778
[A[ATraining Step: 58  | total loss: [1m[32m0.69332[0m[0m | time: 41.053s
[2K
| RMSProp | epoch: 003 | loss: 0.69332 - acc: 0.4649 -- iter: 256/778
[A[ATraining Step: 59  | total loss: [1m[32m0.69333[0m[0m | time: 42.264s
[2K
| RMSProp | epoch: 003 | loss: 0.69333 - acc: 0.4570 -- iter: 288/778
[A[ATraining Step: 60  | total loss: [1m[32m0.69329[0m[0m | time: 43.685s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.4710 -- iter: 320/778
[A[ATraining Step: 61  | total loss: [1m[32m0.69331[0m[0m | time: 45.202s
[2K
| RMSProp | epoch: 003 | loss: 0.69331 - acc: 0.4544 -- iter: 352/778
[A[ATraining Step: 62  | total loss: [1m[32m0.69326[0m[0m | time: 46.625s
[2K
| RMSProp | epoch: 003 | loss: 0.69326 - acc: 0.4683 -- iter: 384/778
[A[ATraining Step: 63  | total loss: [1m[32m0.69317[0m[0m | time: 48.125s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.4881 -- iter: 416/778
[A[ATraining Step: 64  | total loss: [1m[32m0.69324[0m[0m | time: 49.966s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.4818 -- iter: 448/778
[A[ATraining Step: 65  | total loss: [1m[32m0.69321[0m[0m | time: 51.815s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4918 -- iter: 480/778
[A[ATraining Step: 66  | total loss: [1m[32m0.69329[0m[0m | time: 53.444s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.4814 -- iter: 512/778
[A[ATraining Step: 67  | total loss: [1m[32m0.69323[0m[0m | time: 54.920s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4911 -- iter: 544/778
[A[ATraining Step: 68  | total loss: [1m[32m0.69310[0m[0m | time: 57.006s
[2K
| RMSProp | epoch: 003 | loss: 0.69310 - acc: 0.5107 -- iter: 576/778
[A[ATraining Step: 69  | total loss: [1m[32m0.69333[0m[0m | time: 58.581s
[2K
| RMSProp | epoch: 003 | loss: 0.69333 - acc: 0.4948 -- iter: 608/778
[A[ATraining Step: 70  | total loss: [1m[32m0.69327[0m[0m | time: 64.460s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.5062 -- iter: 640/778
[A[ATraining Step: 71  | total loss: [1m[32m0.69326[0m[0m | time: 70.180s
[2K
| RMSProp | epoch: 003 | loss: 0.69326 - acc: 0.5055 -- iter: 672/778
[A[ATraining Step: 72  | total loss: [1m[32m0.69328[0m[0m | time: 75.495s
[2K
| RMSProp | epoch: 003 | loss: 0.69328 - acc: 0.5049 -- iter: 704/778
[A[ATraining Step: 73  | total loss: [1m[32m0.69312[0m[0m | time: 81.485s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5182 -- iter: 736/778
[A[ATraining Step: 74  | total loss: [1m[32m0.69305[0m[0m | time: 89.944s
[2K
| RMSProp | epoch: 003 | loss: 0.69305 - acc: 0.5197 -- iter: 768/778
[A[ATraining Step: 75  | total loss: [1m[32m0.69319[0m[0m | time: 117.154s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5108 | val_loss: 0.69308 - val_acc: 0.5041 -- iter: 778/778
--
Training Step: 76  | total loss: [1m[32m0.69307[0m[0m | time: 1.263s
[2K
| RMSProp | epoch: 004 | loss: 0.69307 - acc: 0.5163 -- iter: 032/778
[A[ATraining Step: 77  | total loss: [1m[32m0.69300[0m[0m | time: 1.921s
[2K
| RMSProp | epoch: 004 | loss: 0.69300 - acc: 0.5179 -- iter: 064/778
[A[ATraining Step: 78  | total loss: [1m[32m0.69265[0m[0m | time: 2.501s
[2K
| RMSProp | epoch: 004 | loss: 0.69265 - acc: 0.5369 -- iter: 096/778
[A[ATraining Step: 79  | total loss: [1m[32m0.69216[0m[0m | time: 3.998s
[2K
| RMSProp | epoch: 004 | loss: 0.69216 - acc: 0.5538 -- iter: 128/778
[A[ATraining Step: 80  | total loss: [1m[32m0.69212[0m[0m | time: 5.569s
[2K
| RMSProp | epoch: 004 | loss: 0.69212 - acc: 0.5515 -- iter: 160/778
[A[ATraining Step: 81  | total loss: [1m[32m0.69211[0m[0m | time: 7.202s
[2K
| RMSProp | epoch: 004 | loss: 0.69211 - acc: 0.5495 -- iter: 192/778
[A[ATraining Step: 82  | total loss: [1m[32m0.69262[0m[0m | time: 8.997s
[2K
| RMSProp | epoch: 004 | loss: 0.69262 - acc: 0.5351 -- iter: 224/778
[A[ATraining Step: 83  | total loss: [1m[32m0.69325[0m[0m | time: 10.808s
[2K
| RMSProp | epoch: 004 | loss: 0.69325 - acc: 0.5160 -- iter: 256/778
[A[ATraining Step: 84  | total loss: [1m[32m0.69315[0m[0m | time: 12.294s
[2K
| RMSProp | epoch: 004 | loss: 0.69315 - acc: 0.5175 -- iter: 288/778
[A[ATraining Step: 85  | total loss: [1m[32m0.69308[0m[0m | time: 14.303s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5189 -- iter: 320/778
[A[ATraining Step: 86  | total loss: [1m[32m0.69309[0m[0m | time: 16.094s
[2K
| RMSProp | epoch: 004 | loss: 0.69309 - acc: 0.5170 -- iter: 352/778
[A[ATraining Step: 87  | total loss: [1m[32m0.69321[0m[0m | time: 19.609s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.5122 -- iter: 384/778
[A[ATraining Step: 88  | total loss: [1m[32m0.69324[0m[0m | time: 22.097s
[2K
| RMSProp | epoch: 004 | loss: 0.69324 - acc: 0.5110 -- iter: 416/778
[A[ATraining Step: 89  | total loss: [1m[32m0.69331[0m[0m | time: 27.845s
[2K
| RMSProp | epoch: 004 | loss: 0.69331 - acc: 0.5067 -- iter: 448/778
[A[ATraining Step: 90  | total loss: [1m[32m0.69318[0m[0m | time: 34.170s
[2K
| RMSProp | epoch: 004 | loss: 0.69318 - acc: 0.5092 -- iter: 480/778
[A[ATraining Step: 91  | total loss: [1m[32m0.69294[0m[0m | time: 39.776s
[2K
| RMSProp | epoch: 004 | loss: 0.69294 - acc: 0.5176 -- iter: 512/778
[A[ATraining Step: 92  | total loss: [1m[32m0.69326[0m[0m | time: 44.898s
[2K
| RMSProp | epoch: 004 | loss: 0.69326 - acc: 0.5065 -- iter: 544/778
[A[ATraining Step: 93  | total loss: [1m[32m0.69333[0m[0m | time: 51.157s
[2K
| RMSProp | epoch: 004 | loss: 0.69333 - acc: 0.5027 -- iter: 576/778
[A[ATraining Step: 94  | total loss: [1m[32m0.69318[0m[0m | time: 54.907s
[2K
| RMSProp | epoch: 004 | loss: 0.69318 - acc: 0.5087 -- iter: 608/778
[A[ATraining Step: 95  | total loss: [1m[32m0.69338[0m[0m | time: 59.472s
[2K
| RMSProp | epoch: 004 | loss: 0.69338 - acc: 0.5016 -- iter: 640/778
[A[ATraining Step: 96  | total loss: [1m[32m0.69341[0m[0m | time: 64.306s
[2K
| RMSProp | epoch: 004 | loss: 0.69341 - acc: 0.4983 -- iter: 672/778
[A[ATraining Step: 97  | total loss: [1m[32m0.69322[0m[0m | time: 65.739s
[2K
| RMSProp | epoch: 004 | loss: 0.69322 - acc: 0.5078 -- iter: 704/778
[A[ATraining Step: 98  | total loss: [1m[32m0.69317[0m[0m | time: 67.201s
[2K
| RMSProp | epoch: 004 | loss: 0.69317 - acc: 0.5102 -- iter: 736/778
[A[ATraining Step: 99  | total loss: [1m[32m0.69317[0m[0m | time: 68.743s
[2K
| RMSProp | epoch: 004 | loss: 0.69317 - acc: 0.5092 -- iter: 768/778
[A[ATraining Step: 100  | total loss: [1m[32m0.69356[0m[0m | time: 73.002s
[2K
| RMSProp | epoch: 004 | loss: 0.69356 - acc: 0.4926 | val_loss: 0.69305 - val_acc: 0.5041 -- iter: 778/778
--
Training Step: 101  | total loss: [1m[32m0.69352[0m[0m | time: 1.637s
[2K
| RMSProp | epoch: 005 | loss: 0.69352 - acc: 0.4934 -- iter: 032/778
[A[ATraining Step: 102  | total loss: [1m[32m0.69342[0m[0m | time: 2.950s
[2K
| RMSProp | epoch: 005 | loss: 0.69342 - acc: 0.5003 -- iter: 064/778
[A[ATraining Step: 103  | total loss: [1m[32m0.69327[0m[0m | time: 3.702s
[2K
| RMSProp | epoch: 005 | loss: 0.69327 - acc: 0.5065 -- iter: 096/778
[A[ATraining Step: 104  | total loss: [1m[32m0.69354[0m[0m | time: 4.328s
[2K
| RMSProp | epoch: 005 | loss: 0.69354 - acc: 0.4959 -- iter: 128/778
[A[ATraining Step: 105  | total loss: [1m[32m0.69359[0m[0m | time: 6.190s
[2K
| RMSProp | epoch: 005 | loss: 0.69359 - acc: 0.4863 -- iter: 160/778
[A[ATraining Step: 106  | total loss: [1m[32m0.69357[0m[0m | time: 7.887s
[2K
| RMSProp | epoch: 005 | loss: 0.69357 - acc: 0.4720 -- iter: 192/778
[A[ATraining Step: 107  | total loss: [1m[32m0.69348[0m[0m | time: 14.685s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.4904 -- iter: 224/778
[A[ATraining Step: 108  | total loss: [1m[32m0.69329[0m[0m | time: 22.620s
[2K
| RMSProp | epoch: 005 | loss: 0.69329 - acc: 0.4976 -- iter: 256/778
[A[ATraining Step: 109  | total loss: [1m[32m0.69284[0m[0m | time: 24.378s
[2K
| RMSProp | epoch: 005 | loss: 0.69284 - acc: 0.5135 -- iter: 288/778
[A[ATraining Step: 110  | total loss: [1m[32m0.69334[0m[0m | time: 29.775s
[2K
| RMSProp | epoch: 005 | loss: 0.69334 - acc: 0.5028 -- iter: 320/778
[A[ATraining Step: 111  | total loss: [1m[32m0.69348[0m[0m | time: 35.377s
[2K
| RMSProp | epoch: 005 | loss: 0.69348 - acc: 0.4963 -- iter: 352/778
[A[ATraining Step: 112  | total loss: [1m[32m0.69362[0m[0m | time: 40.923s
[2K
| RMSProp | epoch: 005 | loss: 0.69362 - acc: 0.4904 -- iter: 384/778
[A[ATraining Step: 113  | total loss: [1m[32m0.69356[0m[0m | time: 43.655s
[2K
| RMSProp | epoch: 005 | loss: 0.69356 - acc: 0.4913 -- iter: 416/778
[A[ATraining Step: 114  | total loss: [1m[32m0.69343[0m[0m | time: 46.736s
[2K
| RMSProp | epoch: 005 | loss: 0.69343 - acc: 0.4985 -- iter: 448/778
[A[ATraining Step: 115  | total loss: [1m[32m0.69309[0m[0m | time: 51.068s
[2K
| RMSProp | epoch: 005 | loss: 0.69309 - acc: 0.5142 -- iter: 480/778
[A[ATraining Step: 116  | total loss: [1m[32m0.69326[0m[0m | time: 52.368s
[2K
| RMSProp | epoch: 005 | loss: 0.69326 - acc: 0.5097 -- iter: 512/778
[A[ATraining Step: 117  | total loss: [1m[32m0.69326[0m[0m | time: 53.761s
[2K
| RMSProp | epoch: 005 | loss: 0.69326 - acc: 0.5087 -- iter: 544/778
[A[ATraining Step: 118  | total loss: [1m[32m0.69361[0m[0m | time: 55.268s
[2K
| RMSProp | epoch: 005 | loss: 0.69361 - acc: 0.4985 -- iter: 576/778
[A[ATraining Step: 119  | total loss: [1m[32m0.69377[0m[0m | time: 56.744s
[2K
| RMSProp | epoch: 005 | loss: 0.69377 - acc: 0.4861 -- iter: 608/778
[A[ATraining Step: 120  | total loss: [1m[32m0.69371[0m[0m | time: 58.299s
[2K
| RMSProp | epoch: 005 | loss: 0.69371 - acc: 0.4875 -- iter: 640/778
[A[ATraining Step: 121  | total loss: [1m[32m0.69359[0m[0m | time: 59.907s
[2K
| RMSProp | epoch: 005 | loss: 0.69359 - acc: 0.4919 -- iter: 672/778
[A[ATraining Step: 122  | total loss: [1m[32m0.69364[0m[0m | time: 61.876s
[2K
| RMSProp | epoch: 005 | loss: 0.69364 - acc: 0.4864 -- iter: 704/778
[A[ATraining Step: 123  | total loss: [1m[32m0.69361[0m[0m | time: 63.692s
[2K
| RMSProp | epoch: 005 | loss: 0.69361 - acc: 0.4847 -- iter: 736/778
[A[ATraining Step: 124  | total loss: [1m[32m0.69354[0m[0m | time: 65.241s
[2K
| RMSProp | epoch: 005 | loss: 0.69354 - acc: 0.5018 -- iter: 768/778
[A[ATraining Step: 125  | total loss: [1m[32m0.69346[0m[0m | time: 69.632s
[2K
| RMSProp | epoch: 005 | loss: 0.69346 - acc: 0.5204 | val_loss: 0.69295 - val_acc: 0.5041 -- iter: 778/778
--
Training Step: 126  | total loss: [1m[32m0.69342[0m[0m | time: 5.368s
[2K
| RMSProp | epoch: 006 | loss: 0.69342 - acc: 0.5152 -- iter: 032/778
[A[ATraining Step: 127  | total loss: [1m[32m0.69344[0m[0m | time: 8.439s
[2K
| RMSProp | epoch: 006 | loss: 0.69344 - acc: 0.5106 -- iter: 064/778
[A[ATraining Step: 128  | total loss: [1m[32m0.69336[0m[0m | time: 10.994s
[2K
| RMSProp | epoch: 006 | loss: 0.69336 - acc: 0.5283 -- iter: 096/778
[A[ATraining Step: 129  | total loss: [1m[32m0.69332[0m[0m | time: 12.512s
[2K
| RMSProp | epoch: 006 | loss: 0.69332 - acc: 0.5255 -- iter: 128/778
[A[ATraining Step: 130  | total loss: [1m[32m0.69308[0m[0m | time: 13.662s
[2K
| RMSProp | epoch: 006 | loss: 0.69308 - acc: 0.5329 -- iter: 160/778
[A[ATraining Step: 131  | total loss: [1m[32m0.69269[0m[0m | time: 14.923s
[2K
| RMSProp | epoch: 006 | loss: 0.69269 - acc: 0.5396 -- iter: 192/778
[A[ATraining Step: 132  | total loss: [1m[32m0.69207[0m[0m | time: 16.431s
[2K
| RMSProp | epoch: 006 | loss: 0.69207 - acc: 0.5450 -- iter: 224/778
[A[ATraining Step: 133  | total loss: [1m[32m0.69239[0m[0m | time: 17.938s
[2K
| RMSProp | epoch: 006 | loss: 0.69239 - acc: 0.5405 -- iter: 256/778
[A[ATraining Step: 134  | total loss: [1m[32m0.69170[0m[0m | time: 19.453s
[2K
| RMSProp | epoch: 006 | loss: 0.69170 - acc: 0.5458 -- iter: 288/778
[A[ATraining Step: 135  | total loss: [1m[32m0.69155[0m[0m | time: 21.073s
[2K
| RMSProp | epoch: 006 | loss: 0.69155 - acc: 0.5444 -- iter: 320/778
[A[ATraining Step: 136  | total loss: [1m[32m0.69238[0m[0m | time: 22.778s
[2K
| RMSProp | epoch: 006 | loss: 0.69238 - acc: 0.5368 -- iter: 352/778
[A[ATraining Step: 137  | total loss: [1m[32m0.69270[0m[0m | time: 24.416s
[2K
| RMSProp | epoch: 006 | loss: 0.69270 - acc: 0.5300 -- iter: 384/778
[A[ATraining Step: 138  | total loss: [1m[32m0.69286[0m[0m | time: 26.262s
[2K
| RMSProp | epoch: 006 | loss: 0.69286 - acc: 0.5239 -- iter: 416/778
[A[ATraining Step: 139  | total loss: [1m[32m0.69282[0m[0m | time: 28.046s
[2K
| RMSProp | epoch: 006 | loss: 0.69282 - acc: 0.5215 -- iter: 448/778
[A[ATraining Step: 140  | total loss: [1m[32m0.69272[0m[0m | time: 29.803s
[2K
| RMSProp | epoch: 006 | loss: 0.69272 - acc: 0.5225 -- iter: 480/778
[A[ATraining Step: 141  | total loss: [1m[32m0.69282[0m[0m | time: 31.481s
[2K
| RMSProp | epoch: 006 | loss: 0.69282 - acc: 0.5171 -- iter: 512/778
[A[ATraining Step: 142  | total loss: [1m[32m0.69312[0m[0m | time: 33.448s
[2K
| RMSProp | epoch: 006 | loss: 0.69312 - acc: 0.4998 -- iter: 544/778
[A[ATraining Step: 143  | total loss: [1m[32m0.69318[0m[0m | time: 36.328s
[2K
| RMSProp | epoch: 006 | loss: 0.69318 - acc: 0.4998 -- iter: 576/778
[A[ATraining Step: 144  | total loss: [1m[32m0.69319[0m[0m | time: 43.340s
[2K
| RMSProp | epoch: 006 | loss: 0.69319 - acc: 0.4998 -- iter: 608/778
[A[ATraining Step: 145  | total loss: [1m[32m0.69312[0m[0m | time: 48.062s
[2K
| RMSProp | epoch: 006 | loss: 0.69312 - acc: 0.5030 -- iter: 640/778
[A[ATraining Step: 146  | total loss: [1m[32m0.69312[0m[0m | time: 50.434s
[2K
| RMSProp | epoch: 006 | loss: 0.69312 - acc: 0.5027 -- iter: 672/778
[A[ATraining Step: 147  | total loss: [1m[32m0.69306[0m[0m | time: 54.502s
[2K
| RMSProp | epoch: 006 | loss: 0.69306 - acc: 0.5024 -- iter: 704/778
[A[ATraining Step: 148  | total loss: [1m[32m0.69311[0m[0m | time: 57.113s
[2K
| RMSProp | epoch: 006 | loss: 0.69311 - acc: 0.4897 -- iter: 736/778
[A[ATraining Step: 149  | total loss: [1m[32m0.69363[0m[0m | time: 60.260s
[2K
| RMSProp | epoch: 006 | loss: 0.69363 - acc: 0.4844 -- iter: 768/778
[A[ATraining Step: 150  | total loss: [1m[32m0.69338[0m[0m | time: 66.774s
[2K
| RMSProp | epoch: 006 | loss: 0.69338 - acc: 0.4954 | val_loss: 0.69317 - val_acc: 0.5041 -- iter: 778/778
--
Training Step: 151  | total loss: [1m[32m0.69320[0m[0m | time: 1.547s
[2K
| RMSProp | epoch: 007 | loss: 0.69320 - acc: 0.4990 -- iter: 032/778
[A[ATraining Step: 152  | total loss: [1m[32m0.69340[0m[0m | time: 3.128s
[2K
| RMSProp | epoch: 007 | loss: 0.69340 - acc: 0.4959 -- iter: 064/778
[A[ATraining Step: 153  | total loss: [1m[32m0.69379[0m[0m | time: 4.627s
[2K
| RMSProp | epoch: 007 | loss: 0.69379 - acc: 0.4870 -- iter: 096/778
[A[ATraining Step: 154  | total loss: [1m[32m0.69377[0m[0m | time: 6.502s
[2K
| RMSProp | epoch: 007 | loss: 0.69377 - acc: 0.4820 -- iter: 128/778
[A[ATraining Step: 155  | total loss: [1m[32m0.69366[0m[0m | time: 7.169s
[2K
| RMSProp | epoch: 007 | loss: 0.69366 - acc: 0.4869 -- iter: 160/778
[A[ATraining Step: 156  | total loss: [1m[32m0.69340[0m[0m | time: 7.821s
[2K
| RMSProp | epoch: 007 | loss: 0.69340 - acc: 0.4983 -- iter: 192/778
[A[ATraining Step: 157  | total loss: [1m[32m0.69299[0m[0m | time: 9.305s
[2K
| RMSProp | epoch: 007 | loss: 0.69299 - acc: 0.5084 -- iter: 224/778
[A[ATraining Step: 158  | total loss: [1m[32m0.69299[0m[0m | time: 10.778s
[2K
| RMSProp | epoch: 007 | loss: 0.69299 - acc: 0.5076 -- iter: 256/778
[A[ATraining Step: 159  | total loss: [1m[32m0.69308[0m[0m | time: 12.625s
[2K
| RMSProp | epoch: 007 | loss: 0.69308 - acc: 0.5068 -- iter: 288/778
[A[ATraining Step: 160  | total loss: [1m[32m0.69240[0m[0m | time: 14.273s
[2K
| RMSProp | epoch: 007 | loss: 0.69240 - acc: 0.5186 -- iter: 320/778
[A[ATraining Step: 161  | total loss: [1m[32m0.69389[0m[0m | time: 15.938s
[2K
| RMSProp | epoch: 007 | loss: 0.69389 - acc: 0.5074 -- iter: 352/778
[A[ATraining Step: 162  | total loss: [1m[32m0.69424[0m[0m | time: 21.759s
[2K
| RMSProp | epoch: 007 | loss: 0.69424 - acc: 0.4942 -- iter: 384/778
[A[ATraining Step: 163  | total loss: [1m[32m0.69411[0m[0m | time: 26.053s
[2K
| RMSProp | epoch: 007 | loss: 0.69411 - acc: 0.5041 -- iter: 416/778
[A[ATraining Step: 164  | total loss: [1m[32m0.69408[0m[0m | time: 30.119s
[2K
| RMSProp | epoch: 007 | loss: 0.69408 - acc: 0.5006 -- iter: 448/778
[A[ATraining Step: 165  | total loss: [1m[32m0.69410[0m[0m | time: 31.421s
[2K
| RMSProp | epoch: 007 | loss: 0.69410 - acc: 0.4943 -- iter: 480/778
[A[ATraining Step: 166  | total loss: [1m[32m0.69394[0m[0m | time: 32.827s
[2K
| RMSProp | epoch: 007 | loss: 0.69394 - acc: 0.5073 -- iter: 512/778
[A[ATraining Step: 167  | total loss: [1m[32m0.69402[0m[0m | time: 34.438s
[2K
| RMSProp | epoch: 007 | loss: 0.69402 - acc: 0.5004 -- iter: 544/778
[A[ATraining Step: 168  | total loss: [1m[32m0.69400[0m[0m | time: 36.124s
[2K
| RMSProp | epoch: 007 | loss: 0.69400 - acc: 0.4972 -- iter: 576/778
[A[ATraining Step: 169  | total loss: [1m[32m0.69387[0m[0m | time: 37.820s
[2K
| RMSProp | epoch: 007 | loss: 0.69387 - acc: 0.5006 -- iter: 608/778
[A[ATraining Step: 170  | total loss: [1m[32m0.69412[0m[0m | time: 39.492s
[2K
| RMSProp | epoch: 007 | loss: 0.69412 - acc: 0.4849 -- iter: 640/778
[A[ATraining Step: 171  | total loss: [1m[32m0.69398[0m[0m | time: 41.130s
[2K
| RMSProp | epoch: 007 | loss: 0.69398 - acc: 0.4927 -- iter: 672/778
[A[ATraining Step: 172  | total loss: [1m[32m0.69366[0m[0m | time: 42.865s
[2K
| RMSProp | epoch: 007 | loss: 0.69366 - acc: 0.5028 -- iter: 704/778
[A[ATraining Step: 173  | total loss: [1m[32m0.69386[0m[0m | time: 44.582s
[2K
| RMSProp | epoch: 007 | loss: 0.69386 - acc: 0.4994 -- iter: 736/778
[A[ATraining Step: 174  | total loss: [1m[32m0.69398[0m[0m | time: 46.338s
[2K
| RMSProp | epoch: 007 | loss: 0.69398 - acc: 0.4901 -- iter: 768/778
[A[ATraining Step: 175  | total loss: [1m[32m0.69387[0m[0m | time: 54.488s
[2K
| RMSProp | epoch: 007 | loss: 0.69387 - acc: 0.4848 | val_loss: 0.69286 - val_acc: 0.5041 -- iter: 778/778
--
Training Step: 176  | total loss: [1m[32m0.69381[0m[0m | time: 3.651s
[2K
| RMSProp | epoch: 008 | loss: 0.69381 - acc: 0.4832 -- iter: 032/778
[A[ATraining Step: 177  | total loss: [1m[32m0.69376[0m[0m | time: 5.486s
[2K
| RMSProp | epoch: 008 | loss: 0.69376 - acc: 0.4818 -- iter: 064/778
[A[ATraining Step: 178  | total loss: [1m[32m0.69363[0m[0m | time: 6.928s
[2K
| RMSProp | epoch: 008 | loss: 0.69363 - acc: 0.4867 -- iter: 096/778
[A[ATraining Step: 179  | total loss: [1m[32m0.69356[0m[0m | time: 8.563s
[2K
| RMSProp | epoch: 008 | loss: 0.69356 - acc: 0.4880 -- iter: 128/778
[A[ATraining Step: 180  | total loss: [1m[32m0.69333[0m[0m | time: 10.019s
[2K
| RMSProp | epoch: 008 | loss: 0.69333 - acc: 0.4986 -- iter: 160/778
[A[ATraining Step: 181  | total loss: [1m[32m0.69292[0m[0m | time: 10.747s
[2K
| RMSProp | epoch: 008 | loss: 0.69292 - acc: 0.5050 -- iter: 192/778
[A[ATraining Step: 182  | total loss: [1m[32m0.69316[0m[0m | time: 11.333s
[2K
| RMSProp | epoch: 008 | loss: 0.69316 - acc: 0.4945 -- iter: 224/778
[A[ATraining Step: 183  | total loss: [1m[32m0.69104[0m[0m | time: 12.803s
[2K
| RMSProp | epoch: 008 | loss: 0.69104 - acc: 0.5050 -- iter: 256/778
[A[ATraining Step: 184  | total loss: [1m[32m0.71737[0m[0m | time: 14.549s
[2K
| RMSProp | epoch: 008 | loss: 0.71737 - acc: 0.5108 -- iter: 288/778
[A[ATraining Step: 185  | total loss: [1m[32m0.71480[0m[0m | time: 16.124s
[2K
| RMSProp | epoch: 008 | loss: 0.71480 - acc: 0.5128 -- iter: 320/778
[A[ATraining Step: 186  | total loss: [1m[32m0.71246[0m[0m | time: 17.771s
[2K
| RMSProp | epoch: 008 | loss: 0.71246 - acc: 0.5209 -- iter: 352/778
[A[ATraining Step: 187  | total loss: [1m[32m0.71030[0m[0m | time: 19.363s
[2K
| RMSProp | epoch: 008 | loss: 0.71030 - acc: 0.5251 -- iter: 384/778
[A[ATraining Step: 188  | total loss: [1m[32m0.70874[0m[0m | time: 20.788s
[2K
| RMSProp | epoch: 008 | loss: 0.70874 - acc: 0.5195 -- iter: 416/778
[A[ATraining Step: 189  | total loss: [1m[32m0.70726[0m[0m | time: 22.388s
[2K
| RMSProp | epoch: 008 | loss: 0.70726 - acc: 0.5144 -- iter: 448/778
[A[ATraining Step: 190  | total loss: [1m[32m0.70577[0m[0m | time: 24.388s
[2K
| RMSProp | epoch: 008 | loss: 0.70577 - acc: 0.5129 -- iter: 480/778
[A[ATraining Step: 191  | total loss: [1m[32m0.70411[0m[0m | time: 25.817s
[2K
| RMSProp | epoch: 008 | loss: 0.70411 - acc: 0.5242 -- iter: 512/778
[A[ATraining Step: 192  | total loss: [1m[32m0.70265[0m[0m | time: 27.372s
[2K
| RMSProp | epoch: 008 | loss: 0.70265 - acc: 0.5280 -- iter: 544/778
[A[ATraining Step: 193  | total loss: [1m[32m0.70172[0m[0m | time: 28.947s
[2K
| RMSProp | epoch: 008 | loss: 0.70172 - acc: 0.5252 -- iter: 576/778
[A[ATraining Step: 194  | total loss: [1m[32m0.70090[0m[0m | time: 30.675s
[2K
| RMSProp | epoch: 008 | loss: 0.70090 - acc: 0.5195 -- iter: 608/778
[A[ATraining Step: 195  | total loss: [1m[32m0.69995[0m[0m | time: 32.365s
[2K
| RMSProp | epoch: 008 | loss: 0.69995 - acc: 0.5207 -- iter: 640/778
[A[ATraining Step: 196  | total loss: [1m[32m0.69889[0m[0m | time: 33.975s
[2K
| RMSProp | epoch: 008 | loss: 0.69889 - acc: 0.5218 -- iter: 672/778
[A[ATraining Step: 197  | total loss: [1m[32m0.69833[0m[0m | time: 35.617s
[2K
| RMSProp | epoch: 008 | loss: 0.69833 - acc: 0.5196 -- iter: 704/778
[A[ATraining Step: 198  | total loss: [1m[32m0.69790[0m[0m | time: 37.263s
[2K
| RMSProp | epoch: 008 | loss: 0.69790 - acc: 0.5145 -- iter: 736/778
[A[ATraining Step: 199  | total loss: [1m[32m0.69689[0m[0m | time: 38.854s
[2K
| RMSProp | epoch: 008 | loss: 0.69689 - acc: 0.5256 -- iter: 768/778
[A[ATraining Step: 200  | total loss: [1m[32m0.69713[0m[0m | time: 42.702s
[2K
| RMSProp | epoch: 008 | loss: 0.69713 - acc: 0.5168 | val_loss: 0.69207 - val_acc: 0.4959 -- iter: 778/778
--
Training Step: 201  | total loss: [1m[32m0.69668[0m[0m | time: 1.475s
[2K
| RMSProp | epoch: 009 | loss: 0.69668 - acc: 0.5088 -- iter: 032/778
[A[ATraining Step: 202  | total loss: [1m[32m0.69721[0m[0m | time: 3.059s
[2K
| RMSProp | epoch: 009 | loss: 0.69721 - acc: 0.4829 -- iter: 064/778
[A[ATraining Step: 203  | total loss: [1m[32m0.69558[0m[0m | time: 4.605s
[2K
| RMSProp | epoch: 009 | loss: 0.69558 - acc: 0.4971 -- iter: 096/778
[A[ATraining Step: 204  | total loss: [1m[32m0.69547[0m[0m | time: 6.138s
[2K
| RMSProp | epoch: 009 | loss: 0.69547 - acc: 0.4974 -- iter: 128/778
[A[ATraining Step: 205  | total loss: [1m[32m0.69569[0m[0m | time: 7.752s
[2K
| RMSProp | epoch: 009 | loss: 0.69569 - acc: 0.4914 -- iter: 160/778
[A[ATraining Step: 206  | total loss: [1m[32m0.69553[0m[0m | time: 9.575s
[2K
| RMSProp | epoch: 009 | loss: 0.69553 - acc: 0.4860 -- iter: 192/778
[A[ATraining Step: 207  | total loss: [1m[32m0.69482[0m[0m | time: 10.194s
[2K
| RMSProp | epoch: 009 | loss: 0.69482 - acc: 0.4906 -- iter: 224/778
[A[ATraining Step: 208  | total loss: [1m[32m0.69476[0m[0m | time: 10.785s
[2K
| RMSProp | epoch: 009 | loss: 0.69476 - acc: 0.4815 -- iter: 256/778
[A[ATraining Step: 209  | total loss: [1m[32m0.69385[0m[0m | time: 12.384s
[2K
| RMSProp | epoch: 009 | loss: 0.69385 - acc: 0.5034 -- iter: 288/778
[A[ATraining Step: 210  | total loss: [1m[32m0.69302[0m[0m | time: 14.007s
[2K
| RMSProp | epoch: 009 | loss: 0.69302 - acc: 0.5061 -- iter: 320/778
[A[ATraining Step: 211  | total loss: [1m[32m0.69172[0m[0m | time: 15.594s
[2K
| RMSProp | epoch: 009 | loss: 0.69172 - acc: 0.5305 -- iter: 352/778
[A[ATraining Step: 212  | total loss: [1m[32m0.69077[0m[0m | time: 17.215s
[2K
| RMSProp | epoch: 009 | loss: 0.69077 - acc: 0.5306 -- iter: 384/778
[A[ATraining Step: 213  | total loss: [1m[32m0.68938[0m[0m | time: 18.666s
[2K
| RMSProp | epoch: 009 | loss: 0.68938 - acc: 0.5432 -- iter: 416/778
[A[ATraining Step: 214  | total loss: [1m[32m0.68672[0m[0m | time: 23.153s
[2K
| RMSProp | epoch: 009 | loss: 0.68672 - acc: 0.5420 -- iter: 448/778
[A[ATraining Step: 215  | total loss: [1m[32m0.69411[0m[0m | time: 28.018s
[2K
| RMSProp | epoch: 009 | loss: 0.69411 - acc: 0.5315 -- iter: 480/778
[A[ATraining Step: 216  | total loss: [1m[32m0.69408[0m[0m | time: 34.106s
[2K
| RMSProp | epoch: 009 | loss: 0.69408 - acc: 0.5315 -- iter: 512/778
[A[ATraining Step: 217  | total loss: [1m[32m0.69415[0m[0m | time: 35.413s
[2K
| RMSProp | epoch: 009 | loss: 0.69415 - acc: 0.5221 -- iter: 544/778
[A[ATraining Step: 218  | total loss: [1m[32m0.69345[0m[0m | time: 36.899s
[2K
| RMSProp | epoch: 009 | loss: 0.69345 - acc: 0.5199 -- iter: 576/778
[A[ATraining Step: 219  | total loss: [1m[32m0.69188[0m[0m | time: 38.628s
[2K
| RMSProp | epoch: 009 | loss: 0.69188 - acc: 0.5367 -- iter: 608/778
[A[ATraining Step: 220  | total loss: [1m[32m0.69194[0m[0m | time: 40.283s
[2K
| RMSProp | epoch: 009 | loss: 0.69194 - acc: 0.5236 -- iter: 640/778
[A[ATraining Step: 221  | total loss: [1m[32m0.69235[0m[0m | time: 41.769s
[2K
| RMSProp | epoch: 009 | loss: 0.69235 - acc: 0.5181 -- iter: 672/778
[A[ATraining Step: 222  | total loss: [1m[32m0.69016[0m[0m | time: 43.379s
[2K
| RMSProp | epoch: 009 | loss: 0.69016 - acc: 0.5444 -- iter: 704/778
[A[ATraining Step: 223  | total loss: [1m[32m0.68694[0m[0m | time: 44.821s
[2K
| RMSProp | epoch: 009 | loss: 0.68694 - acc: 0.5587 -- iter: 736/778
[A[ATraining Step: 224  | total loss: [1m[32m0.68134[0m[0m | time: 46.061s
[2K
| RMSProp | epoch: 009 | loss: 0.68134 - acc: 0.5779 -- iter: 768/778
[A[ATraining Step: 225  | total loss: [1m[32m0.68587[0m[0m | time: 49.639s
[2K
| RMSProp | epoch: 009 | loss: 0.68587 - acc: 0.5670 | val_loss: 0.69213 - val_acc: 0.4959 -- iter: 778/778
--
Training Step: 226  | total loss: [1m[32m0.69038[0m[0m | time: 0.985s
[2K
| RMSProp | epoch: 010 | loss: 0.69038 - acc: 0.5571 -- iter: 032/778
[A[ATraining Step: 227  | total loss: [1m[32m0.69127[0m[0m | time: 2.084s
[2K
| RMSProp | epoch: 010 | loss: 0.69127 - acc: 0.5452 -- iter: 064/778
[A[ATraining Step: 228  | total loss: [1m[32m0.69061[0m[0m | time: 3.257s
[2K
| RMSProp | epoch: 010 | loss: 0.69061 - acc: 0.5532 -- iter: 096/778
[A[ATraining Step: 229  | total loss: [1m[32m0.69107[0m[0m | time: 4.567s
[2K
| RMSProp | epoch: 010 | loss: 0.69107 - acc: 0.5447 -- iter: 128/778
[A[ATraining Step: 230  | total loss: [1m[32m0.68956[0m[0m | time: 6.156s
[2K
| RMSProp | epoch: 010 | loss: 0.68956 - acc: 0.5434 -- iter: 160/778
[A[ATraining Step: 231  | total loss: [1m[32m0.68808[0m[0m | time: 7.822s
[2K
| RMSProp | epoch: 010 | loss: 0.68808 - acc: 0.5578 -- iter: 192/778
[A[ATraining Step: 232  | total loss: [1m[32m0.68666[0m[0m | time: 9.689s
[2K
| RMSProp | epoch: 010 | loss: 0.68666 - acc: 0.5551 -- iter: 224/778
[A[ATraining Step: 233  | total loss: [1m[32m0.69116[0m[0m | time: 10.235s
[2K
| RMSProp | epoch: 010 | loss: 0.69116 - acc: 0.5434 -- iter: 256/778
[A[ATraining Step: 234  | total loss: [1m[32m0.68244[0m[0m | time: 10.849s
[2K
| RMSProp | epoch: 010 | loss: 0.68244 - acc: 0.5590 -- iter: 288/778
[A[ATraining Step: 235  | total loss: [1m[32m0.66475[0m[0m | time: 12.389s
[2K
| RMSProp | epoch: 010 | loss: 0.66475 - acc: 0.5731 -- iter: 320/778
[A[ATraining Step: 236  | total loss: [1m[32m0.66548[0m[0m | time: 14.199s
[2K
| RMSProp | epoch: 010 | loss: 0.66548 - acc: 0.5846 -- iter: 352/778
[A[ATraining Step: 237  | total loss: [1m[32m0.66906[0m[0m | time: 15.969s
[2K
| RMSProp | epoch: 010 | loss: 0.66906 - acc: 0.5761 -- iter: 384/778
[A[ATraining Step: 238  | total loss: [1m[32m0.66317[0m[0m | time: 17.659s
[2K
| RMSProp | epoch: 010 | loss: 0.66317 - acc: 0.5904 -- iter: 416/778
[A[ATraining Step: 239  | total loss: [1m[32m0.65207[0m[0m | time: 19.070s
[2K
| RMSProp | epoch: 010 | loss: 0.65207 - acc: 0.6063 -- iter: 448/778
[A[ATraining Step: 240  | total loss: [1m[32m0.64132[0m[0m | time: 20.490s
[2K
| RMSProp | epoch: 010 | loss: 0.64132 - acc: 0.6207 -- iter: 480/778
[A[ATraining Step: 241  | total loss: [1m[32m0.63429[0m[0m | time: 21.648s
[2K
| RMSProp | epoch: 010 | loss: 0.63429 - acc: 0.6243 -- iter: 512/778
[A[ATraining Step: 242  | total loss: [1m[32m0.65274[0m[0m | time: 22.783s
[2K
| RMSProp | epoch: 010 | loss: 0.65274 - acc: 0.6118 -- iter: 544/778
[A[ATraining Step: 243  | total loss: [1m[32m0.65578[0m[0m | time: 24.032s
[2K
| RMSProp | epoch: 010 | loss: 0.65578 - acc: 0.6038 -- iter: 576/778
[A[ATraining Step: 244  | total loss: [1m[32m0.65419[0m[0m | time: 25.340s
[2K
| RMSProp | epoch: 010 | loss: 0.65419 - acc: 0.6121 -- iter: 608/778
[A[ATraining Step: 245  | total loss: [1m[32m0.65583[0m[0m | time: 26.700s
[2K
| RMSProp | epoch: 010 | loss: 0.65583 - acc: 0.6103 -- iter: 640/778
[A[ATraining Step: 246  | total loss: [1m[32m0.64615[0m[0m | time: 27.932s
[2K
| RMSProp | epoch: 010 | loss: 0.64615 - acc: 0.6368 -- iter: 672/778
[A[ATraining Step: 247  | total loss: [1m[32m0.63901[0m[0m | time: 29.244s
[2K
| RMSProp | epoch: 010 | loss: 0.63901 - acc: 0.6481 -- iter: 704/778
[A[ATraining Step: 248  | total loss: [1m[32m0.65314[0m[0m | time: 30.639s
[2K
| RMSProp | epoch: 010 | loss: 0.65314 - acc: 0.6333 -- iter: 736/778
[A[ATraining Step: 249  | total loss: [1m[32m0.64992[0m[0m | time: 32.214s
[2K
| RMSProp | epoch: 010 | loss: 0.64992 - acc: 0.6387 -- iter: 768/778
[A[ATraining Step: 250  | total loss: [1m[32m0.64259[0m[0m | time: 35.320s
[2K
| RMSProp | epoch: 010 | loss: 0.64259 - acc: 0.6498 | val_loss: 0.65618 - val_acc: 0.6516 -- iter: 778/778
--
Training Step: 251  | total loss: [1m[32m0.63320[0m[0m | time: 1.200s
[2K
| RMSProp | epoch: 011 | loss: 0.63320 - acc: 0.6599 -- iter: 032/778
[A[ATraining Step: 252  | total loss: [1m[32m0.62519[0m[0m | time: 2.552s
[2K
| RMSProp | epoch: 011 | loss: 0.62519 - acc: 0.6720 -- iter: 064/778
[A[ATraining Step: 253  | total loss: [1m[32m0.61722[0m[0m | time: 3.836s
[2K
| RMSProp | epoch: 011 | loss: 0.61722 - acc: 0.6829 -- iter: 096/778
[A[ATraining Step: 254  | total loss: [1m[32m0.60484[0m[0m | time: 5.006s
[2K
| RMSProp | epoch: 011 | loss: 0.60484 - acc: 0.6896 -- iter: 128/778
[A[ATraining Step: 255  | total loss: [1m[32m0.61435[0m[0m | time: 6.423s
[2K
| RMSProp | epoch: 011 | loss: 0.61435 - acc: 0.6863 -- iter: 160/778
[A[ATraining Step: 256  | total loss: [1m[32m0.61383[0m[0m | time: 8.026s
[2K
| RMSProp | epoch: 011 | loss: 0.61383 - acc: 0.6833 -- iter: 192/778
[A[ATraining Step: 257  | total loss: [1m[32m0.61401[0m[0m | time: 9.514s
[2K
| RMSProp | epoch: 011 | loss: 0.61401 - acc: 0.6837 -- iter: 224/778
[A[ATraining Step: 258  | total loss: [1m[32m0.60562[0m[0m | time: 10.796s
[2K
| RMSProp | epoch: 011 | loss: 0.60562 - acc: 0.6966 -- iter: 256/778
[A[ATraining Step: 259  | total loss: [1m[32m0.60034[0m[0m | time: 11.198s
[2K
| RMSProp | epoch: 011 | loss: 0.60034 - acc: 0.7019 -- iter: 288/778
[A[ATraining Step: 260  | total loss: [1m[32m0.60233[0m[0m | time: 11.558s
[2K
| RMSProp | epoch: 011 | loss: 0.60233 - acc: 0.7017 -- iter: 320/778
[A[ATraining Step: 261  | total loss: [1m[32m0.59813[0m[0m | time: 12.720s
[2K
| RMSProp | epoch: 011 | loss: 0.59813 - acc: 0.7116 -- iter: 352/778
[A[ATraining Step: 262  | total loss: [1m[32m0.58878[0m[0m | time: 13.900s
[2K
| RMSProp | epoch: 011 | loss: 0.58878 - acc: 0.7217 -- iter: 384/778
[A[ATraining Step: 263  | total loss: [1m[32m0.57419[0m[0m | time: 15.129s
[2K
| RMSProp | epoch: 011 | loss: 0.57419 - acc: 0.7307 -- iter: 416/778
[A[ATraining Step: 264  | total loss: [1m[32m0.55718[0m[0m | time: 16.329s
[2K
| RMSProp | epoch: 011 | loss: 0.55718 - acc: 0.7420 -- iter: 448/778
[A[ATraining Step: 265  | total loss: [1m[32m0.56637[0m[0m | time: 17.708s
[2K
| RMSProp | epoch: 011 | loss: 0.56637 - acc: 0.7272 -- iter: 480/778
[A[ATraining Step: 266  | total loss: [1m[32m0.56304[0m[0m | time: 19.068s
[2K
| RMSProp | epoch: 011 | loss: 0.56304 - acc: 0.7201 -- iter: 512/778
[A[ATraining Step: 267  | total loss: [1m[32m0.57053[0m[0m | time: 20.583s
[2K
| RMSProp | epoch: 011 | loss: 0.57053 - acc: 0.7075 -- iter: 544/778
[A[ATraining Step: 268  | total loss: [1m[32m0.57530[0m[0m | time: 21.915s
[2K
| RMSProp | epoch: 011 | loss: 0.57530 - acc: 0.7055 -- iter: 576/778
[A[ATraining Step: 269  | total loss: [1m[32m0.56846[0m[0m | time: 23.246s
[2K
| RMSProp | epoch: 011 | loss: 0.56846 - acc: 0.7162 -- iter: 608/778
[A[ATraining Step: 270  | total loss: [1m[32m0.56082[0m[0m | time: 24.695s
[2K
| RMSProp | epoch: 011 | loss: 0.56082 - acc: 0.7133 -- iter: 640/778
[A[ATraining Step: 271  | total loss: [1m[32m0.58313[0m[0m | time: 26.471s
[2K
| RMSProp | epoch: 011 | loss: 0.58313 - acc: 0.6982 -- iter: 672/778
[A[ATraining Step: 272  | total loss: [1m[32m0.58033[0m[0m | time: 28.043s
[2K
| RMSProp | epoch: 011 | loss: 0.58033 - acc: 0.6972 -- iter: 704/778
[A[ATraining Step: 273  | total loss: [1m[32m0.57279[0m[0m | time: 29.569s
[2K
| RMSProp | epoch: 011 | loss: 0.57279 - acc: 0.7087 -- iter: 736/778
[A[ATraining Step: 274  | total loss: [1m[32m0.56487[0m[0m | time: 31.205s
[2K
| RMSProp | epoch: 011 | loss: 0.56487 - acc: 0.7191 -- iter: 768/778
[A[ATraining Step: 275  | total loss: [1m[32m0.56285[0m[0m | time: 35.479s
[2K
| RMSProp | epoch: 011 | loss: 0.56285 - acc: 0.7159 | val_loss: 0.62475 - val_acc: 0.6557 -- iter: 778/778
--
Training Step: 276  | total loss: [1m[32m0.57111[0m[0m | time: 1.493s
[2K
| RMSProp | epoch: 012 | loss: 0.57111 - acc: 0.7037 -- iter: 032/778
[A[ATraining Step: 277  | total loss: [1m[32m0.57148[0m[0m | time: 3.166s
[2K
| RMSProp | epoch: 012 | loss: 0.57148 - acc: 0.6958 -- iter: 064/778
[A[ATraining Step: 278  | total loss: [1m[32m0.57259[0m[0m | time: 4.920s
[2K
| RMSProp | epoch: 012 | loss: 0.57259 - acc: 0.6981 -- iter: 096/778
[A[ATraining Step: 279  | total loss: [1m[32m0.56563[0m[0m | time: 6.548s
[2K
| RMSProp | epoch: 012 | loss: 0.56563 - acc: 0.7096 -- iter: 128/778
[A[ATraining Step: 280  | total loss: [1m[32m0.55330[0m[0m | time: 8.298s
[2K
| RMSProp | epoch: 012 | loss: 0.55330 - acc: 0.7167 -- iter: 160/778
[A[ATraining Step: 281  | total loss: [1m[32m0.54879[0m[0m | time: 9.705s
[2K
| RMSProp | epoch: 012 | loss: 0.54879 - acc: 0.7201 -- iter: 192/778
[A[ATraining Step: 282  | total loss: [1m[32m0.53823[0m[0m | time: 11.306s
[2K
| RMSProp | epoch: 012 | loss: 0.53823 - acc: 0.7293 -- iter: 224/778
[A[ATraining Step: 283  | total loss: [1m[32m0.53387[0m[0m | time: 13.107s
[2K
| RMSProp | epoch: 012 | loss: 0.53387 - acc: 0.7282 -- iter: 256/778
[A[ATraining Step: 284  | total loss: [1m[32m0.51500[0m[0m | time: 14.694s
[2K
| RMSProp | epoch: 012 | loss: 0.51500 - acc: 0.7492 -- iter: 288/778
[A[ATraining Step: 285  | total loss: [1m[32m0.51972[0m[0m | time: 15.280s
[2K
| RMSProp | epoch: 012 | loss: 0.51972 - acc: 0.7493 -- iter: 320/778
[A[ATraining Step: 286  | total loss: [1m[32m0.50385[0m[0m | time: 15.941s
[2K
| RMSProp | epoch: 012 | loss: 0.50385 - acc: 0.7443 -- iter: 352/778
[A[ATraining Step: 287  | total loss: [1m[32m0.47998[0m[0m | time: 17.554s
[2K
| RMSProp | epoch: 012 | loss: 0.47998 - acc: 0.7599 -- iter: 384/778
[A[ATraining Step: 288  | total loss: [1m[32m0.52459[0m[0m | time: 19.587s
[2K
| RMSProp | epoch: 012 | loss: 0.52459 - acc: 0.7464 -- iter: 416/778
[A[ATraining Step: 289  | total loss: [1m[32m0.54475[0m[0m | time: 21.224s
[2K
| RMSProp | epoch: 012 | loss: 0.54475 - acc: 0.7374 -- iter: 448/778
[A[ATraining Step: 290  | total loss: [1m[32m0.54316[0m[0m | time: 22.867s
[2K
| RMSProp | epoch: 012 | loss: 0.54316 - acc: 0.7480 -- iter: 480/778
[A[ATraining Step: 291  | total loss: [1m[32m0.53371[0m[0m | time: 24.586s
[2K
| RMSProp | epoch: 012 | loss: 0.53371 - acc: 0.7607 -- iter: 512/778
[A[ATraining Step: 292  | total loss: [1m[32m0.54122[0m[0m | time: 26.125s
[2K
| RMSProp | epoch: 012 | loss: 0.54122 - acc: 0.7534 -- iter: 544/778
[A[ATraining Step: 293  | total loss: [1m[32m0.54105[0m[0m | time: 27.823s
[2K
| RMSProp | epoch: 012 | loss: 0.54105 - acc: 0.7499 -- iter: 576/778
[A[ATraining Step: 294  | total loss: [1m[32m0.53841[0m[0m | time: 29.332s
[2K
| RMSProp | epoch: 012 | loss: 0.53841 - acc: 0.7468 -- iter: 608/778
[A[ATraining Step: 295  | total loss: [1m[32m0.53563[0m[0m | time: 30.894s
[2K
| RMSProp | epoch: 012 | loss: 0.53563 - acc: 0.7503 -- iter: 640/778
[A[ATraining Step: 296  | total loss: [1m[32m0.54129[0m[0m | time: 32.394s
[2K
| RMSProp | epoch: 012 | loss: 0.54129 - acc: 0.7440 -- iter: 672/778
[A[ATraining Step: 297  | total loss: [1m[32m0.53027[0m[0m | time: 34.122s
[2K
| RMSProp | epoch: 012 | loss: 0.53027 - acc: 0.7508 -- iter: 704/778
[A[ATraining Step: 298  | total loss: [1m[32m0.52780[0m[0m | time: 35.724s
[2K
| RMSProp | epoch: 012 | loss: 0.52780 - acc: 0.7508 -- iter: 736/778
[A[ATraining Step: 299  | total loss: [1m[32m0.53548[0m[0m | time: 37.445s
[2K
| RMSProp | epoch: 012 | loss: 0.53548 - acc: 0.7288 -- iter: 768/778
[A[ATraining Step: 300  | total loss: [1m[32m0.52961[0m[0m | time: 42.343s
[2K
| RMSProp | epoch: 012 | loss: 0.52961 - acc: 0.7372 | val_loss: 0.56820 - val_acc: 0.7213 -- iter: 778/778
--
Training Step: 301  | total loss: [1m[32m0.54015[0m[0m | time: 1.853s
[2K
| RMSProp | epoch: 013 | loss: 0.54015 - acc: 0.7291 -- iter: 032/778
[A[ATraining Step: 302  | total loss: [1m[32m0.52939[0m[0m | time: 3.451s
[2K
| RMSProp | epoch: 013 | loss: 0.52939 - acc: 0.7405 -- iter: 064/778
[A[ATraining Step: 303  | total loss: [1m[32m0.50468[0m[0m | time: 5.008s
[2K
| RMSProp | epoch: 013 | loss: 0.50468 - acc: 0.7571 -- iter: 096/778
[A[ATraining Step: 304  | total loss: [1m[32m0.49661[0m[0m | time: 6.171s
[2K
| RMSProp | epoch: 013 | loss: 0.49661 - acc: 0.7595 -- iter: 128/778
[A[ATraining Step: 305  | total loss: [1m[32m0.49363[0m[0m | time: 7.363s
[2K
| RMSProp | epoch: 013 | loss: 0.49363 - acc: 0.7648 -- iter: 160/778
[A[ATraining Step: 306  | total loss: [1m[32m0.49712[0m[0m | time: 8.604s
[2K
| RMSProp | epoch: 013 | loss: 0.49712 - acc: 0.7633 -- iter: 192/778
[A[ATraining Step: 307  | total loss: [1m[32m0.49096[0m[0m | time: 9.906s
[2K
| RMSProp | epoch: 013 | loss: 0.49096 - acc: 0.7683 -- iter: 224/778
[A[ATraining Step: 308  | total loss: [1m[32m0.48214[0m[0m | time: 11.104s
[2K
| RMSProp | epoch: 013 | loss: 0.48214 - acc: 0.7789 -- iter: 256/778
[A[ATraining Step: 309  | total loss: [1m[32m0.46589[0m[0m | time: 12.539s
[2K
| RMSProp | epoch: 013 | loss: 0.46589 - acc: 0.7823 -- iter: 288/778
[A[ATraining Step: 310  | total loss: [1m[32m0.46138[0m[0m | time: 13.827s
[2K
| RMSProp | epoch: 013 | loss: 0.46138 - acc: 0.7916 -- iter: 320/778
[A[ATraining Step: 311  | total loss: [1m[32m0.49958[0m[0m | time: 14.337s
[2K
| RMSProp | epoch: 013 | loss: 0.49958 - acc: 0.7812 -- iter: 352/778
[A[ATraining Step: 312  | total loss: [1m[32m0.47762[0m[0m | time: 14.769s
[2K
| RMSProp | epoch: 013 | loss: 0.47762 - acc: 0.8030 -- iter: 384/778
[A[ATraining Step: 313  | total loss: [1m[32m0.44254[0m[0m | time: 16.102s
[2K
| RMSProp | epoch: 013 | loss: 0.44254 - acc: 0.8227 -- iter: 416/778
[A[ATraining Step: 314  | total loss: [1m[32m0.43702[0m[0m | time: 17.579s
[2K
| RMSProp | epoch: 013 | loss: 0.43702 - acc: 0.8248 -- iter: 448/778
[A[ATraining Step: 315  | total loss: [1m[32m0.43486[0m[0m | time: 19.028s
[2K
| RMSProp | epoch: 013 | loss: 0.43486 - acc: 0.8267 -- iter: 480/778
[A[ATraining Step: 316  | total loss: [1m[32m0.43134[0m[0m | time: 20.230s
[2K
| RMSProp | epoch: 013 | loss: 0.43134 - acc: 0.8222 -- iter: 512/778
[A[ATraining Step: 317  | total loss: [1m[32m0.44901[0m[0m | time: 21.367s
[2K
| RMSProp | epoch: 013 | loss: 0.44901 - acc: 0.8118 -- iter: 544/778
[A[ATraining Step: 318  | total loss: [1m[32m0.45991[0m[0m | time: 22.630s
[2K
| RMSProp | epoch: 013 | loss: 0.45991 - acc: 0.8088 -- iter: 576/778
[A[ATraining Step: 319  | total loss: [1m[32m0.45223[0m[0m | time: 23.901s
[2K
| RMSProp | epoch: 013 | loss: 0.45223 - acc: 0.8154 -- iter: 608/778
[A[ATraining Step: 320  | total loss: [1m[32m0.44781[0m[0m | time: 25.270s
[2K
| RMSProp | epoch: 013 | loss: 0.44781 - acc: 0.8151 -- iter: 640/778
[A[ATraining Step: 321  | total loss: [1m[32m0.44391[0m[0m | time: 26.681s
[2K
| RMSProp | epoch: 013 | loss: 0.44391 - acc: 0.8148 -- iter: 672/778
[A[ATraining Step: 322  | total loss: [1m[32m0.43411[0m[0m | time: 27.987s
[2K
| RMSProp | epoch: 013 | loss: 0.43411 - acc: 0.8177 -- iter: 704/778
[A[ATraining Step: 323  | total loss: [1m[32m0.45995[0m[0m | time: 29.211s
[2K
| RMSProp | epoch: 013 | loss: 0.45995 - acc: 0.8047 -- iter: 736/778
[A[ATraining Step: 324  | total loss: [1m[32m0.45579[0m[0m | time: 30.803s
[2K
| RMSProp | epoch: 013 | loss: 0.45579 - acc: 0.8086 -- iter: 768/778
[A[ATraining Step: 325  | total loss: [1m[32m0.45217[0m[0m | time: 34.233s
[2K
| RMSProp | epoch: 013 | loss: 0.45217 - acc: 0.8153 | val_loss: 0.51420 - val_acc: 0.7541 -- iter: 778/778
--
Training Step: 326  | total loss: [1m[32m0.44150[0m[0m | time: 1.352s
[2K
| RMSProp | epoch: 014 | loss: 0.44150 - acc: 0.8181 -- iter: 032/778
[A[ATraining Step: 327  | total loss: [1m[32m0.43164[0m[0m | time: 2.910s
[2K
| RMSProp | epoch: 014 | loss: 0.43164 - acc: 0.8269 -- iter: 064/778
[A[ATraining Step: 328  | total loss: [1m[32m0.41484[0m[0m | time: 4.378s
[2K
| RMSProp | epoch: 014 | loss: 0.41484 - acc: 0.8349 -- iter: 096/778
[A[ATraining Step: 329  | total loss: [1m[32m0.42514[0m[0m | time: 5.901s
[2K
| RMSProp | epoch: 014 | loss: 0.42514 - acc: 0.8357 -- iter: 128/778
[A[ATraining Step: 330  | total loss: [1m[32m0.42117[0m[0m | time: 7.471s
[2K
| RMSProp | epoch: 014 | loss: 0.42117 - acc: 0.8397 -- iter: 160/778
[A[ATraining Step: 331  | total loss: [1m[32m0.42401[0m[0m | time: 9.266s
[2K
| RMSProp | epoch: 014 | loss: 0.42401 - acc: 0.8370 -- iter: 192/778
[A[ATraining Step: 332  | total loss: [1m[32m0.41875[0m[0m | time: 10.846s
[2K
| RMSProp | epoch: 014 | loss: 0.41875 - acc: 0.8408 -- iter: 224/778
[A[ATraining Step: 333  | total loss: [1m[32m0.41488[0m[0m | time: 12.514s
[2K
| RMSProp | epoch: 014 | loss: 0.41488 - acc: 0.8411 -- iter: 256/778
[A[ATraining Step: 334  | total loss: [1m[32m0.41629[0m[0m | time: 14.187s
[2K
| RMSProp | epoch: 014 | loss: 0.41629 - acc: 0.8351 -- iter: 288/778
[A[ATraining Step: 335  | total loss: [1m[32m0.43970[0m[0m | time: 15.737s
[2K
| RMSProp | epoch: 014 | loss: 0.43970 - acc: 0.8203 -- iter: 320/778
[A[ATraining Step: 336  | total loss: [1m[32m0.44107[0m[0m | time: 17.698s
[2K
| RMSProp | epoch: 014 | loss: 0.44107 - acc: 0.8195 -- iter: 352/778
[A[ATraining Step: 337  | total loss: [1m[32m0.42934[0m[0m | time: 18.402s
[2K
| RMSProp | epoch: 014 | loss: 0.42934 - acc: 0.8313 -- iter: 384/778
[A[ATraining Step: 338  | total loss: [1m[32m0.40670[0m[0m | time: 19.041s
[2K
| RMSProp | epoch: 014 | loss: 0.40670 - acc: 0.8482 -- iter: 416/778
[A[ATraining Step: 339  | total loss: [1m[32m0.37365[0m[0m | time: 23.586s
[2K
| RMSProp | epoch: 014 | loss: 0.37365 - acc: 0.8634 -- iter: 448/778
[A[ATraining Step: 340  | total loss: [1m[32m0.39367[0m[0m | time: 25.159s
[2K
| RMSProp | epoch: 014 | loss: 0.39367 - acc: 0.8552 -- iter: 480/778
[A[ATraining Step: 341  | total loss: [1m[32m0.41707[0m[0m | time: 26.596s
[2K
| RMSProp | epoch: 014 | loss: 0.41707 - acc: 0.8384 -- iter: 512/778
[A[ATraining Step: 342  | total loss: [1m[32m0.41618[0m[0m | time: 28.211s
[2K
| RMSProp | epoch: 014 | loss: 0.41618 - acc: 0.8389 -- iter: 544/778
[A[ATraining Step: 343  | total loss: [1m[32m0.40559[0m[0m | time: 30.042s
[2K
| RMSProp | epoch: 014 | loss: 0.40559 - acc: 0.8457 -- iter: 576/778
[A[ATraining Step: 344  | total loss: [1m[32m0.41369[0m[0m | time: 31.707s
[2K
| RMSProp | epoch: 014 | loss: 0.41369 - acc: 0.8330 -- iter: 608/778
[A[ATraining Step: 345  | total loss: [1m[32m0.39838[0m[0m | time: 33.555s
[2K
| RMSProp | epoch: 014 | loss: 0.39838 - acc: 0.8434 -- iter: 640/778
[A[ATraining Step: 346  | total loss: [1m[32m0.39228[0m[0m | time: 35.221s
[2K
| RMSProp | epoch: 014 | loss: 0.39228 - acc: 0.8497 -- iter: 672/778
[A[ATraining Step: 347  | total loss: [1m[32m0.38741[0m[0m | time: 36.941s
[2K
| RMSProp | epoch: 014 | loss: 0.38741 - acc: 0.8460 -- iter: 704/778
[A[ATraining Step: 348  | total loss: [1m[32m0.40097[0m[0m | time: 38.551s
[2K
| RMSProp | epoch: 014 | loss: 0.40097 - acc: 0.8395 -- iter: 736/778
[A[ATraining Step: 349  | total loss: [1m[32m0.43282[0m[0m | time: 40.259s
[2K
| RMSProp | epoch: 014 | loss: 0.43282 - acc: 0.8149 -- iter: 768/778
[A[ATraining Step: 350  | total loss: [1m[32m0.42451[0m[0m | time: 47.223s
[2K
| RMSProp | epoch: 014 | loss: 0.42451 - acc: 0.8241 | val_loss: 0.44661 - val_acc: 0.7910 -- iter: 778/778
--
Training Step: 351  | total loss: [1m[32m0.42253[0m[0m | time: 1.324s
[2K
| RMSProp | epoch: 015 | loss: 0.42253 - acc: 0.8260 -- iter: 032/778
[A[ATraining Step: 352  | total loss: [1m[32m0.40275[0m[0m | time: 2.897s
[2K
| RMSProp | epoch: 015 | loss: 0.40275 - acc: 0.8403 -- iter: 064/778
[A[ATraining Step: 353  | total loss: [1m[32m0.39898[0m[0m | time: 4.402s
[2K
| RMSProp | epoch: 015 | loss: 0.39898 - acc: 0.8407 -- iter: 096/778
[A[ATraining Step: 354  | total loss: [1m[32m0.38178[0m[0m | time: 6.076s
[2K
| RMSProp | epoch: 015 | loss: 0.38178 - acc: 0.8472 -- iter: 128/778
[A[ATraining Step: 355  | total loss: [1m[32m0.36820[0m[0m | time: 7.879s
[2K
| RMSProp | epoch: 015 | loss: 0.36820 - acc: 0.8531 -- iter: 160/778
[A[ATraining Step: 356  | total loss: [1m[32m0.34267[0m[0m | time: 9.493s
[2K
| RMSProp | epoch: 015 | loss: 0.34267 - acc: 0.8647 -- iter: 192/778
[A[ATraining Step: 357  | total loss: [1m[32m0.32814[0m[0m | time: 11.131s
[2K
| RMSProp | epoch: 015 | loss: 0.32814 - acc: 0.8720 -- iter: 224/778
[A[ATraining Step: 358  | total loss: [1m[32m0.32566[0m[0m | time: 12.950s
[2K
| RMSProp | epoch: 015 | loss: 0.32566 - acc: 0.8723 -- iter: 256/778
[A[ATraining Step: 359  | total loss: [1m[32m0.31675[0m[0m | time: 14.724s
[2K
| RMSProp | epoch: 015 | loss: 0.31675 - acc: 0.8788 -- iter: 288/778
[A[ATraining Step: 360  | total loss: [1m[32m0.32038[0m[0m | time: 16.160s
[2K
| RMSProp | epoch: 015 | loss: 0.32038 - acc: 0.8815 -- iter: 320/778
[A[ATraining Step: 361  | total loss: [1m[32m0.31127[0m[0m | time: 20.213s
[2K
| RMSProp | epoch: 015 | loss: 0.31127 - acc: 0.8871 -- iter: 352/778
[A[ATraining Step: 362  | total loss: [1m[32m0.29655[0m[0m | time: 24.806s
[2K
| RMSProp | epoch: 015 | loss: 0.29655 - acc: 0.8922 -- iter: 384/778
[A[ATraining Step: 363  | total loss: [1m[32m0.28624[0m[0m | time: 27.170s
[2K
| RMSProp | epoch: 015 | loss: 0.28624 - acc: 0.8967 -- iter: 416/778
[A[ATraining Step: 364  | total loss: [1m[32m0.29107[0m[0m | time: 29.486s
[2K
| RMSProp | epoch: 015 | loss: 0.29107 - acc: 0.8970 -- iter: 448/778
[A[ATraining Step: 365  | total loss: [1m[32m0.29222[0m[0m | time: 36.147s
[2K
| RMSProp | epoch: 015 | loss: 0.29222 - acc: 0.8873 -- iter: 480/778
[A[ATraining Step: 366  | total loss: [1m[32m0.29053[0m[0m | time: 43.284s
[2K
| RMSProp | epoch: 015 | loss: 0.29053 - acc: 0.8861 -- iter: 512/778
[A[ATraining Step: 367  | total loss: [1m[32m0.31168[0m[0m | time: 45.062s
[2K
| RMSProp | epoch: 015 | loss: 0.31168 - acc: 0.8756 -- iter: 544/778
[A[ATraining Step: 368  | total loss: [1m[32m0.30660[0m[0m | time: 46.430s
[2K
| RMSProp | epoch: 015 | loss: 0.30660 - acc: 0.8818 -- iter: 576/778
[A[ATraining Step: 369  | total loss: [1m[32m0.29498[0m[0m | time: 47.898s
[2K
| RMSProp | epoch: 015 | loss: 0.29498 - acc: 0.8874 -- iter: 608/778
[A[ATraining Step: 370  | total loss: [1m[32m0.28583[0m[0m | time: 49.382s
[2K
| RMSProp | epoch: 015 | loss: 0.28583 - acc: 0.8924 -- iter: 640/778
[A[ATraining Step: 371  | total loss: [1m[32m0.28767[0m[0m | time: 50.935s
[2K
| RMSProp | epoch: 015 | loss: 0.28767 - acc: 0.8938 -- iter: 672/778
[A[ATraining Step: 372  | total loss: [1m[32m0.27691[0m[0m | time: 52.579s
[2K
| RMSProp | epoch: 015 | loss: 0.27691 - acc: 0.8981 -- iter: 704/778
[A[ATraining Step: 373  | total loss: [1m[32m0.25927[0m[0m | time: 54.126s
[2K
| RMSProp | epoch: 015 | loss: 0.25927 - acc: 0.9083 -- iter: 736/778
[A[ATraining Step: 374  | total loss: [1m[32m0.26245[0m[0m | time: 55.863s
[2K
| RMSProp | epoch: 015 | loss: 0.26245 - acc: 0.9050 -- iter: 768/778
[A[ATraining Step: 375  | total loss: [1m[32m0.24850[0m[0m | time: 60.074s
[2K
| RMSProp | epoch: 015 | loss: 0.24850 - acc: 0.9145 | val_loss: 0.62464 - val_acc: 0.7459 -- iter: 778/778
--
Training Step: 376  | total loss: [1m[32m0.25965[0m[0m | time: 1.600s
[2K
| RMSProp | epoch: 016 | loss: 0.25965 - acc: 0.9074 -- iter: 032/778
[A[ATraining Step: 377  | total loss: [1m[32m0.28438[0m[0m | time: 2.709s
[2K
| RMSProp | epoch: 016 | loss: 0.28438 - acc: 0.8979 -- iter: 064/778
[A[ATraining Step: 378  | total loss: [1m[32m0.33162[0m[0m | time: 5.792s
[2K
| RMSProp | epoch: 016 | loss: 0.33162 - acc: 0.8644 -- iter: 096/778
[A[ATraining Step: 379  | total loss: [1m[32m0.33520[0m[0m | time: 8.870s
[2K
| RMSProp | epoch: 016 | loss: 0.33520 - acc: 0.8654 -- iter: 128/778
[A[ATraining Step: 380  | total loss: [1m[32m0.33729[0m[0m | time: 14.752s
[2K
| RMSProp | epoch: 016 | loss: 0.33729 - acc: 0.8602 -- iter: 160/778
[A[ATraining Step: 381  | total loss: [1m[32m0.32445[0m[0m | time: 21.142s
[2K
| RMSProp | epoch: 016 | loss: 0.32445 - acc: 0.8710 -- iter: 192/778
[A[ATraining Step: 382  | total loss: [1m[32m0.32214[0m[0m | time: 25.801s
[2K
| RMSProp | epoch: 016 | loss: 0.32214 - acc: 0.8714 -- iter: 224/778
[A[ATraining Step: 383  | total loss: [1m[32m0.33273[0m[0m | time: 27.702s
[2K
| RMSProp | epoch: 016 | loss: 0.33273 - acc: 0.8655 -- iter: 256/778
[A[ATraining Step: 384  | total loss: [1m[32m0.32954[0m[0m | time: 29.146s
[2K
| RMSProp | epoch: 016 | loss: 0.32954 - acc: 0.8665 -- iter: 288/778
[A[ATraining Step: 385  | total loss: [1m[32m0.31458[0m[0m | time: 30.927s
[2K
| RMSProp | epoch: 016 | loss: 0.31458 - acc: 0.8767 -- iter: 320/778
[A[ATraining Step: 386  | total loss: [1m[32m0.29603[0m[0m | time: 32.378s
[2K
| RMSProp | epoch: 016 | loss: 0.29603 - acc: 0.8859 -- iter: 352/778
[A[ATraining Step: 387  | total loss: [1m[32m0.27480[0m[0m | time: 33.919s
[2K
| RMSProp | epoch: 016 | loss: 0.27480 - acc: 0.8973 -- iter: 384/778
[A[ATraining Step: 388  | total loss: [1m[32m0.25293[0m[0m | time: 35.565s
[2K
| RMSProp | epoch: 016 | loss: 0.25293 - acc: 0.9076 -- iter: 416/778
[A[ATraining Step: 389  | total loss: [1m[32m0.23143[0m[0m | time: 36.132s
[2K
| RMSProp | epoch: 016 | loss: 0.23143 - acc: 0.9168 -- iter: 448/778
[A[ATraining Step: 390  | total loss: [1m[32m0.20942[0m[0m | time: 36.781s
[2K
| RMSProp | epoch: 016 | loss: 0.20942 - acc: 0.9251 -- iter: 480/778
[A[ATraining Step: 391  | total loss: [1m[32m0.18900[0m[0m | time: 38.360s
[2K
| RMSProp | epoch: 016 | loss: 0.18900 - acc: 0.9326 -- iter: 512/778
[A[ATraining Step: 392  | total loss: [1m[32m0.18258[0m[0m | time: 40.023s
[2K
| RMSProp | epoch: 016 | loss: 0.18258 - acc: 0.9362 -- iter: 544/778
[A[ATraining Step: 393  | total loss: [1m[32m0.23995[0m[0m | time: 41.840s
[2K
| RMSProp | epoch: 016 | loss: 0.23995 - acc: 0.9239 -- iter: 576/778
[A[ATraining Step: 394  | total loss: [1m[32m0.25235[0m[0m | time: 43.535s
[2K
| RMSProp | epoch: 016 | loss: 0.25235 - acc: 0.9190 -- iter: 608/778
[A[ATraining Step: 395  | total loss: [1m[32m0.23492[0m[0m | time: 45.077s
[2K
| RMSProp | epoch: 016 | loss: 0.23492 - acc: 0.9271 -- iter: 640/778
[A[ATraining Step: 396  | total loss: [1m[32m0.22879[0m[0m | time: 46.658s
[2K
| RMSProp | epoch: 016 | loss: 0.22879 - acc: 0.9281 -- iter: 672/778
[A[ATraining Step: 397  | total loss: [1m[32m0.22080[0m[0m | time: 48.213s
[2K
| RMSProp | epoch: 016 | loss: 0.22080 - acc: 0.9322 -- iter: 704/778
[A[ATraining Step: 398  | total loss: [1m[32m0.21035[0m[0m | time: 49.690s
[2K
| RMSProp | epoch: 016 | loss: 0.21035 - acc: 0.9358 -- iter: 736/778
[A[ATraining Step: 399  | total loss: [1m[32m0.20522[0m[0m | time: 52.602s
[2K
| RMSProp | epoch: 016 | loss: 0.20522 - acc: 0.9391 -- iter: 768/778
[A[ATraining Step: 400  | total loss: [1m[32m0.18960[0m[0m | time: 56.477s
[2K
| RMSProp | epoch: 016 | loss: 0.18960 - acc: 0.9452 | val_loss: 0.40899 - val_acc: 0.8689 -- iter: 778/778
--
Training Step: 401  | total loss: [1m[32m0.18494[0m[0m | time: 1.701s
[2K
| RMSProp | epoch: 017 | loss: 0.18494 - acc: 0.9476 -- iter: 032/778
[A[ATraining Step: 402  | total loss: [1m[32m0.17795[0m[0m | time: 3.416s
[2K
| RMSProp | epoch: 017 | loss: 0.17795 - acc: 0.9497 -- iter: 064/778
[A[ATraining Step: 403  | total loss: [1m[32m0.17137[0m[0m | time: 5.016s
[2K
| RMSProp | epoch: 017 | loss: 0.17137 - acc: 0.9485 -- iter: 096/778
[A[ATraining Step: 404  | total loss: [1m[32m0.18587[0m[0m | time: 6.969s
[2K
| RMSProp | epoch: 017 | loss: 0.18587 - acc: 0.9442 -- iter: 128/778
[A[ATraining Step: 405  | total loss: [1m[32m0.19135[0m[0m | time: 8.632s
[2K
| RMSProp | epoch: 017 | loss: 0.19135 - acc: 0.9404 -- iter: 160/778
[A[ATraining Step: 406  | total loss: [1m[32m0.19836[0m[0m | time: 10.183s
[2K
| RMSProp | epoch: 017 | loss: 0.19836 - acc: 0.9339 -- iter: 192/778
[A[ATraining Step: 407  | total loss: [1m[32m0.23112[0m[0m | time: 11.680s
[2K
| RMSProp | epoch: 017 | loss: 0.23112 - acc: 0.9218 -- iter: 224/778
[A[ATraining Step: 408  | total loss: [1m[32m0.26090[0m[0m | time: 13.263s
[2K
| RMSProp | epoch: 017 | loss: 0.26090 - acc: 0.9077 -- iter: 256/778
[A[ATraining Step: 409  | total loss: [1m[32m0.25817[0m[0m | time: 14.793s
[2K
| RMSProp | epoch: 017 | loss: 0.25817 - acc: 0.9107 -- iter: 288/778
[A[ATraining Step: 410  | total loss: [1m[32m0.25352[0m[0m | time: 16.155s
[2K
| RMSProp | epoch: 017 | loss: 0.25352 - acc: 0.9102 -- iter: 320/778
[A[ATraining Step: 411  | total loss: [1m[32m0.24251[0m[0m | time: 17.642s
[2K
| RMSProp | epoch: 017 | loss: 0.24251 - acc: 0.9161 -- iter: 352/778
[A[ATraining Step: 412  | total loss: [1m[32m0.23014[0m[0m | time: 19.285s
[2K
| RMSProp | epoch: 017 | loss: 0.23014 - acc: 0.9182 -- iter: 384/778
[A[ATraining Step: 413  | total loss: [1m[32m0.21219[0m[0m | time: 21.005s
[2K
| RMSProp | epoch: 017 | loss: 0.21219 - acc: 0.9264 -- iter: 416/778
[A[ATraining Step: 414  | total loss: [1m[32m0.20775[0m[0m | time: 22.638s
[2K
| RMSProp | epoch: 017 | loss: 0.20775 - acc: 0.9275 -- iter: 448/778
[A[ATraining Step: 415  | total loss: [1m[32m0.21422[0m[0m | time: 23.141s
[2K
| RMSProp | epoch: 017 | loss: 0.21422 - acc: 0.9191 -- iter: 480/778
[A[ATraining Step: 416  | total loss: [1m[32m0.22546[0m[0m | time: 23.760s
[2K
| RMSProp | epoch: 017 | loss: 0.22546 - acc: 0.8972 -- iter: 512/778
[A[ATraining Step: 417  | total loss: [1m[32m0.22224[0m[0m | time: 25.665s
[2K
| RMSProp | epoch: 017 | loss: 0.22224 - acc: 0.8975 -- iter: 544/778
[A[ATraining Step: 418  | total loss: [1m[32m0.24717[0m[0m | time: 27.498s
[2K
| RMSProp | epoch: 017 | loss: 0.24717 - acc: 0.8859 -- iter: 576/778
[A[ATraining Step: 419  | total loss: [1m[32m0.24488[0m[0m | time: 29.047s
[2K
| RMSProp | epoch: 017 | loss: 0.24488 - acc: 0.8848 -- iter: 608/778
[A[ATraining Step: 420  | total loss: [1m[32m0.23056[0m[0m | time: 30.615s
[2K
| RMSProp | epoch: 017 | loss: 0.23056 - acc: 0.8963 -- iter: 640/778
[A[ATraining Step: 421  | total loss: [1m[32m0.21115[0m[0m | time: 32.138s
[2K
| RMSProp | epoch: 017 | loss: 0.21115 - acc: 0.9067 -- iter: 672/778
[A[ATraining Step: 422  | total loss: [1m[32m0.19372[0m[0m | time: 33.667s
[2K
| RMSProp | epoch: 017 | loss: 0.19372 - acc: 0.9160 -- iter: 704/778
[A[ATraining Step: 423  | total loss: [1m[32m0.18477[0m[0m | time: 35.027s
[2K
| RMSProp | epoch: 017 | loss: 0.18477 - acc: 0.9213 -- iter: 736/778
[A[ATraining Step: 424  | total loss: [1m[32m0.17621[0m[0m | time: 39.414s
[2K
| RMSProp | epoch: 017 | loss: 0.17621 - acc: 0.9260 -- iter: 768/778
[A[ATraining Step: 425  | total loss: [1m[32m0.17025[0m[0m | time: 43.610s
[2K
| RMSProp | epoch: 017 | loss: 0.17025 - acc: 0.9241 | val_loss: 0.58260 - val_acc: 0.8197 -- iter: 778/778
--
Training Step: 426  | total loss: [1m[32m0.18434[0m[0m | time: 1.666s
[2K
| RMSProp | epoch: 018 | loss: 0.18434 - acc: 0.9223 -- iter: 032/778
[A[ATraining Step: 427  | total loss: [1m[32m0.20243[0m[0m | time: 3.185s
[2K
| RMSProp | epoch: 018 | loss: 0.20243 - acc: 0.9144 -- iter: 064/778
[A[ATraining Step: 428  | total loss: [1m[32m0.21266[0m[0m | time: 4.790s
[2K
| RMSProp | epoch: 018 | loss: 0.21266 - acc: 0.9105 -- iter: 096/778
[A[ATraining Step: 429  | total loss: [1m[32m0.20744[0m[0m | time: 6.534s
[2K
| RMSProp | epoch: 018 | loss: 0.20744 - acc: 0.9163 -- iter: 128/778
[A[ATraining Step: 430  | total loss: [1m[32m0.20661[0m[0m | time: 8.398s
[2K
| RMSProp | epoch: 018 | loss: 0.20661 - acc: 0.9153 -- iter: 160/778
[A[ATraining Step: 431  | total loss: [1m[32m0.19612[0m[0m | time: 10.089s
[2K
| RMSProp | epoch: 018 | loss: 0.19612 - acc: 0.9238 -- iter: 192/778
[A[ATraining Step: 432  | total loss: [1m[32m0.18079[0m[0m | time: 11.412s
[2K
| RMSProp | epoch: 018 | loss: 0.18079 - acc: 0.9314 -- iter: 224/778
[A[ATraining Step: 433  | total loss: [1m[32m0.17126[0m[0m | time: 12.898s
[2K
| RMSProp | epoch: 018 | loss: 0.17126 - acc: 0.9383 -- iter: 256/778
[A[ATraining Step: 434  | total loss: [1m[32m0.17079[0m[0m | time: 14.328s
[2K
| RMSProp | epoch: 018 | loss: 0.17079 - acc: 0.9351 -- iter: 288/778
[A[ATraining Step: 435  | total loss: [1m[32m0.16632[0m[0m | time: 15.896s
[2K
| RMSProp | epoch: 018 | loss: 0.16632 - acc: 0.9384 -- iter: 320/778
[A[ATraining Step: 436  | total loss: [1m[32m0.22251[0m[0m | time: 17.213s
[2K
| RMSProp | epoch: 018 | loss: 0.22251 - acc: 0.9290 -- iter: 352/778
[A[ATraining Step: 437  | total loss: [1m[32m0.21479[0m[0m | time: 18.700s
[2K
| RMSProp | epoch: 018 | loss: 0.21479 - acc: 0.9361 -- iter: 384/778
[A[ATraining Step: 438  | total loss: [1m[32m0.20681[0m[0m | time: 20.326s
[2K
| RMSProp | epoch: 018 | loss: 0.20681 - acc: 0.9393 -- iter: 416/778
[A[ATraining Step: 439  | total loss: [1m[32m0.19825[0m[0m | time: 21.967s
[2K
| RMSProp | epoch: 018 | loss: 0.19825 - acc: 0.9391 -- iter: 448/778
[A[ATraining Step: 440  | total loss: [1m[32m0.18715[0m[0m | time: 23.527s
[2K
| RMSProp | epoch: 018 | loss: 0.18715 - acc: 0.9421 -- iter: 480/778
[A[ATraining Step: 441  | total loss: [1m[32m0.18245[0m[0m | time: 24.001s
[2K
| RMSProp | epoch: 018 | loss: 0.18245 - acc: 0.9448 -- iter: 512/778
[A[ATraining Step: 442  | total loss: [1m[32m0.17072[0m[0m | time: 24.598s
[2K
| RMSProp | epoch: 018 | loss: 0.17072 - acc: 0.9503 -- iter: 544/778
[A[ATraining Step: 443  | total loss: [1m[32m0.15386[0m[0m | time: 26.356s
[2K
| RMSProp | epoch: 018 | loss: 0.15386 - acc: 0.9553 -- iter: 576/778
[A[ATraining Step: 444  | total loss: [1m[32m0.15405[0m[0m | time: 28.313s
[2K
| RMSProp | epoch: 018 | loss: 0.15405 - acc: 0.9504 -- iter: 608/778
[A[ATraining Step: 445  | total loss: [1m[32m0.18903[0m[0m | time: 30.066s
[2K
| RMSProp | epoch: 018 | loss: 0.18903 - acc: 0.9335 -- iter: 640/778
[A[ATraining Step: 446  | total loss: [1m[32m0.19262[0m[0m | time: 31.476s
[2K
| RMSProp | epoch: 018 | loss: 0.19262 - acc: 0.9339 -- iter: 672/778
[A[ATraining Step: 447  | total loss: [1m[32m0.17861[0m[0m | time: 33.130s
[2K
| RMSProp | epoch: 018 | loss: 0.17861 - acc: 0.9405 -- iter: 704/778
[A[ATraining Step: 448  | total loss: [1m[32m0.16466[0m[0m | time: 34.889s
[2K
| RMSProp | epoch: 018 | loss: 0.16466 - acc: 0.9464 -- iter: 736/778
[A[ATraining Step: 449  | total loss: [1m[32m0.14994[0m[0m | time: 36.449s
[2K
| RMSProp | epoch: 018 | loss: 0.14994 - acc: 0.9518 -- iter: 768/778
[A[ATraining Step: 450  | total loss: [1m[32m0.14704[0m[0m | time: 40.833s
[2K
| RMSProp | epoch: 018 | loss: 0.14704 - acc: 0.9472 | val_loss: 0.50001 - val_acc: 0.8525 -- iter: 778/778
--
Training Step: 451  | total loss: [1m[32m0.15772[0m[0m | time: 1.836s
[2K
| RMSProp | epoch: 019 | loss: 0.15772 - acc: 0.9431 -- iter: 032/778
[A[ATraining Step: 452  | total loss: [1m[32m0.14858[0m[0m | time: 3.497s
[2K
| RMSProp | epoch: 019 | loss: 0.14858 - acc: 0.9488 -- iter: 064/778
[A[ATraining Step: 453  | total loss: [1m[32m0.13513[0m[0m | time: 4.996s
[2K
| RMSProp | epoch: 019 | loss: 0.13513 - acc: 0.9539 -- iter: 096/778
[A[ATraining Step: 454  | total loss: [1m[32m0.12637[0m[0m | time: 6.393s
[2K
| RMSProp | epoch: 019 | loss: 0.12637 - acc: 0.9585 -- iter: 128/778
[A[ATraining Step: 455  | total loss: [1m[32m0.13657[0m[0m | time: 7.682s
[2K
| RMSProp | epoch: 019 | loss: 0.13657 - acc: 0.9533 -- iter: 160/778
[A[ATraining Step: 456  | total loss: [1m[32m0.13517[0m[0m | time: 8.756s
[2K
| RMSProp | epoch: 019 | loss: 0.13517 - acc: 0.9549 -- iter: 192/778
[A[ATraining Step: 457  | total loss: [1m[32m0.13429[0m[0m | time: 10.001s
[2K
| RMSProp | epoch: 019 | loss: 0.13429 - acc: 0.9562 -- iter: 224/778
[A[ATraining Step: 458  | total loss: [1m[32m0.13078[0m[0m | time: 11.171s
[2K
| RMSProp | epoch: 019 | loss: 0.13078 - acc: 0.9575 -- iter: 256/778
[A[ATraining Step: 459  | total loss: [1m[32m0.12390[0m[0m | time: 12.348s
[2K
| RMSProp | epoch: 019 | loss: 0.12390 - acc: 0.9586 -- iter: 288/778
[A[ATraining Step: 460  | total loss: [1m[32m0.12028[0m[0m | time: 13.686s
[2K
| RMSProp | epoch: 019 | loss: 0.12028 - acc: 0.9596 -- iter: 320/778
[A[ATraining Step: 461  | total loss: [1m[32m0.11329[0m[0m | time: 15.029s
[2K
| RMSProp | epoch: 019 | loss: 0.11329 - acc: 0.9605 -- iter: 352/778
[A[ATraining Step: 462  | total loss: [1m[32m0.10643[0m[0m | time: 16.245s
[2K
| RMSProp | epoch: 019 | loss: 0.10643 - acc: 0.9614 -- iter: 384/778
[A[ATraining Step: 463  | total loss: [1m[32m0.10591[0m[0m | time: 17.549s
[2K
| RMSProp | epoch: 019 | loss: 0.10591 - acc: 0.9621 -- iter: 416/778
[A[ATraining Step: 464  | total loss: [1m[32m0.11418[0m[0m | time: 19.049s
[2K
| RMSProp | epoch: 019 | loss: 0.11418 - acc: 0.9596 -- iter: 448/778
[A[ATraining Step: 465  | total loss: [1m[32m0.10765[0m[0m | time: 20.633s
[2K
| RMSProp | epoch: 019 | loss: 0.10765 - acc: 0.9637 -- iter: 480/778
[A[ATraining Step: 466  | total loss: [1m[32m0.11033[0m[0m | time: 21.731s
[2K
| RMSProp | epoch: 019 | loss: 0.11033 - acc: 0.9642 -- iter: 512/778
[A[ATraining Step: 467  | total loss: [1m[32m0.10625[0m[0m | time: 22.063s
[2K
| RMSProp | epoch: 019 | loss: 0.10625 - acc: 0.9615 -- iter: 544/778
[A[ATraining Step: 468  | total loss: [1m[32m0.09799[0m[0m | time: 22.435s
[2K
| RMSProp | epoch: 019 | loss: 0.09799 - acc: 0.9654 -- iter: 576/778
[A[ATraining Step: 469  | total loss: [1m[32m0.08864[0m[0m | time: 23.635s
[2K
| RMSProp | epoch: 019 | loss: 0.08864 - acc: 0.9688 -- iter: 608/778
[A[ATraining Step: 470  | total loss: [1m[32m0.08471[0m[0m | time: 24.755s
[2K
| RMSProp | epoch: 019 | loss: 0.08471 - acc: 0.9719 -- iter: 640/778
[A[ATraining Step: 471  | total loss: [1m[32m0.07681[0m[0m | time: 25.965s
[2K
| RMSProp | epoch: 019 | loss: 0.07681 - acc: 0.9748 -- iter: 672/778
[A[ATraining Step: 472  | total loss: [1m[32m0.07019[0m[0m | time: 27.285s
[2K
| RMSProp | epoch: 019 | loss: 0.07019 - acc: 0.9773 -- iter: 704/778
[A[ATraining Step: 473  | total loss: [1m[32m0.06350[0m[0m | time: 28.682s
[2K
| RMSProp | epoch: 019 | loss: 0.06350 - acc: 0.9795 -- iter: 736/778
[A[ATraining Step: 474  | total loss: [1m[32m0.05744[0m[0m | time: 30.359s
[2K
| RMSProp | epoch: 019 | loss: 0.05744 - acc: 0.9816 -- iter: 768/778
[A[ATraining Step: 475  | total loss: [1m[32m0.05292[0m[0m | time: 34.259s
[2K
| RMSProp | epoch: 019 | loss: 0.05292 - acc: 0.9834 | val_loss: 0.63367 - val_acc: 0.8648 -- iter: 778/778
--
Training Step: 476  | total loss: [1m[32m0.04787[0m[0m | time: 1.750s
[2K
| RMSProp | epoch: 020 | loss: 0.04787 - acc: 0.9851 -- iter: 032/778
[A[ATraining Step: 477  | total loss: [1m[32m0.05062[0m[0m | time: 3.193s
[2K
| RMSProp | epoch: 020 | loss: 0.05062 - acc: 0.9835 -- iter: 064/778
[A[ATraining Step: 478  | total loss: [1m[32m0.08114[0m[0m | time: 4.651s
[2K
| RMSProp | epoch: 020 | loss: 0.08114 - acc: 0.9757 -- iter: 096/778
[A[ATraining Step: 479  | total loss: [1m[32m0.11686[0m[0m | time: 6.179s
[2K
| RMSProp | epoch: 020 | loss: 0.11686 - acc: 0.9657 -- iter: 128/778
[A[ATraining Step: 480  | total loss: [1m[32m0.13490[0m[0m | time: 7.536s
[2K
| RMSProp | epoch: 020 | loss: 0.13490 - acc: 0.9597 -- iter: 160/778
[A[ATraining Step: 481  | total loss: [1m[32m0.13569[0m[0m | time: 9.176s
[2K
| RMSProp | epoch: 020 | loss: 0.13569 - acc: 0.9606 -- iter: 192/778
[A[ATraining Step: 482  | total loss: [1m[32m0.13592[0m[0m | time: 10.747s
[2K
| RMSProp | epoch: 020 | loss: 0.13592 - acc: 0.9614 -- iter: 224/778
[A[ATraining Step: 483  | total loss: [1m[32m0.12593[0m[0m | time: 12.404s
[2K
| RMSProp | epoch: 020 | loss: 0.12593 - acc: 0.9653 -- iter: 256/778
[A[ATraining Step: 484  | total loss: [1m[32m0.11608[0m[0m | time: 13.949s
[2K
| RMSProp | epoch: 020 | loss: 0.11608 - acc: 0.9688 -- iter: 288/778
[A[ATraining Step: 485  | total loss: [1m[32m0.11060[0m[0m | time: 15.479s
[2K
| RMSProp | epoch: 020 | loss: 0.11060 - acc: 0.9688 -- iter: 320/778
[A[ATraining Step: 486  | total loss: [1m[32m0.10445[0m[0m | time: 16.971s
[2K
| RMSProp | epoch: 020 | loss: 0.10445 - acc: 0.9688 -- iter: 352/778
[A[ATraining Step: 487  | total loss: [1m[32m0.10986[0m[0m | time: 18.618s
[2K
| RMSProp | epoch: 020 | loss: 0.10986 - acc: 0.9625 -- iter: 384/778
[A[ATraining Step: 488  | total loss: [1m[32m0.25722[0m[0m | time: 20.292s
[2K
| RMSProp | epoch: 020 | loss: 0.25722 - acc: 0.9350 -- iter: 416/778
[A[ATraining Step: 489  | total loss: [1m[32m0.24782[0m[0m | time: 21.918s
[2K
| RMSProp | epoch: 020 | loss: 0.24782 - acc: 0.9415 -- iter: 448/778
[A[ATraining Step: 490  | total loss: [1m[32m0.22839[0m[0m | time: 23.374s
[2K
| RMSProp | epoch: 020 | loss: 0.22839 - acc: 0.9474 -- iter: 480/778
[A[ATraining Step: 491  | total loss: [1m[32m0.21007[0m[0m | time: 24.969s
[2K
| RMSProp | epoch: 020 | loss: 0.21007 - acc: 0.9526 -- iter: 512/778
[A[ATraining Step: 492  | total loss: [1m[32m0.19305[0m[0m | time: 26.491s
[2K
| RMSProp | epoch: 020 | loss: 0.19305 - acc: 0.9574 -- iter: 544/778
[A[ATraining Step: 493  | total loss: [1m[32m0.17480[0m[0m | time: 27.103s
[2K
| RMSProp | epoch: 020 | loss: 0.17480 - acc: 0.9616 -- iter: 576/778
[A[ATraining Step: 494  | total loss: [1m[32m0.15893[0m[0m | time: 27.721s
[2K
| RMSProp | epoch: 020 | loss: 0.15893 - acc: 0.9655 -- iter: 608/778
[A[ATraining Step: 495  | total loss: [1m[32m0.14372[0m[0m | time: 29.005s
[2K
| RMSProp | epoch: 020 | loss: 0.14372 - acc: 0.9689 -- iter: 640/778
[A[ATraining Step: 496  | total loss: [1m[32m0.13007[0m[0m | time: 30.578s
[2K
| RMSProp | epoch: 020 | loss: 0.13007 - acc: 0.9720 -- iter: 672/778
[A[ATraining Step: 497  | total loss: [1m[32m0.13456[0m[0m | time: 32.286s
[2K
| RMSProp | epoch: 020 | loss: 0.13456 - acc: 0.9686 -- iter: 704/778
[A[ATraining Step: 498  | total loss: [1m[32m0.13485[0m[0m | time: 33.977s
[2K
| RMSProp | epoch: 020 | loss: 0.13485 - acc: 0.9655 -- iter: 736/778
[A[ATraining Step: 499  | total loss: [1m[32m0.13046[0m[0m | time: 35.498s
[2K
| RMSProp | epoch: 020 | loss: 0.13046 - acc: 0.9658 -- iter: 768/778
[A[ATraining Step: 500  | total loss: [1m[32m0.13340[0m[0m | time: 39.871s
[2K
| RMSProp | epoch: 020 | loss: 0.13340 - acc: 0.9598 | val_loss: 0.49508 - val_acc: 0.8525 -- iter: 778/778
--
Training Step: 501  | total loss: [1m[32m0.12937[0m[0m | time: 1.571s
[2K
| RMSProp | epoch: 021 | loss: 0.12937 - acc: 0.9576 -- iter: 032/778
[A[ATraining Step: 502  | total loss: [1m[32m0.14347[0m[0m | time: 3.207s
[2K
| RMSProp | epoch: 021 | loss: 0.14347 - acc: 0.9556 -- iter: 064/778
[A[ATraining Step: 503  | total loss: [1m[32m0.13171[0m[0m | time: 4.971s
[2K
| RMSProp | epoch: 021 | loss: 0.13171 - acc: 0.9600 -- iter: 096/778
[A[ATraining Step: 504  | total loss: [1m[32m0.13551[0m[0m | time: 6.645s
[2K
| RMSProp | epoch: 021 | loss: 0.13551 - acc: 0.9609 -- iter: 128/778
[A[ATraining Step: 505  | total loss: [1m[32m0.12483[0m[0m | time: 8.410s
[2K
| RMSProp | epoch: 021 | loss: 0.12483 - acc: 0.9648 -- iter: 160/778
[A[ATraining Step: 506  | total loss: [1m[32m0.11344[0m[0m | time: 9.784s
[2K
| RMSProp | epoch: 021 | loss: 0.11344 - acc: 0.9683 -- iter: 192/778
[A[ATraining Step: 507  | total loss: [1m[32m0.10277[0m[0m | time: 11.514s
[2K
| RMSProp | epoch: 021 | loss: 0.10277 - acc: 0.9715 -- iter: 224/778
[A[ATraining Step: 508  | total loss: [1m[32m0.09602[0m[0m | time: 13.023s
[2K
| RMSProp | epoch: 021 | loss: 0.09602 - acc: 0.9744 -- iter: 256/778
[A[ATraining Step: 509  | total loss: [1m[32m0.10254[0m[0m | time: 14.604s
[2K
| RMSProp | epoch: 021 | loss: 0.10254 - acc: 0.9707 -- iter: 288/778
[A[ATraining Step: 510  | total loss: [1m[32m0.09941[0m[0m | time: 16.179s
[2K
| RMSProp | epoch: 021 | loss: 0.09941 - acc: 0.9705 -- iter: 320/778
[A[ATraining Step: 511  | total loss: [1m[32m0.09075[0m[0m | time: 17.975s
[2K
| RMSProp | epoch: 021 | loss: 0.09075 - acc: 0.9734 -- iter: 352/778
[A[ATraining Step: 512  | total loss: [1m[32m0.08438[0m[0m | time: 19.649s
[2K
| RMSProp | epoch: 021 | loss: 0.08438 - acc: 0.9761 -- iter: 384/778
[A[ATraining Step: 513  | total loss: [1m[32m0.08033[0m[0m | time: 21.286s
[2K
| RMSProp | epoch: 021 | loss: 0.08033 - acc: 0.9754 -- iter: 416/778
[A[ATraining Step: 514  | total loss: [1m[32m0.07746[0m[0m | time: 22.551s
[2K
| RMSProp | epoch: 021 | loss: 0.07746 - acc: 0.9778 -- iter: 448/778
[A[ATraining Step: 515  | total loss: [1m[32m0.07006[0m[0m | time: 24.062s
[2K
| RMSProp | epoch: 021 | loss: 0.07006 - acc: 0.9800 -- iter: 480/778
[A[ATraining Step: 516  | total loss: [1m[32m0.06338[0m[0m | time: 25.651s
[2K
| RMSProp | epoch: 021 | loss: 0.06338 - acc: 0.9820 -- iter: 512/778
[A[ATraining Step: 517  | total loss: [1m[32m0.06927[0m[0m | time: 27.231s
[2K
| RMSProp | epoch: 021 | loss: 0.06927 - acc: 0.9807 -- iter: 544/778
[A[ATraining Step: 518  | total loss: [1m[32m0.06462[0m[0m | time: 28.721s
[2K
| RMSProp | epoch: 021 | loss: 0.06462 - acc: 0.9826 -- iter: 576/778
[A[ATraining Step: 519  | total loss: [1m[32m0.05996[0m[0m | time: 29.287s
[2K
| RMSProp | epoch: 021 | loss: 0.05996 - acc: 0.9844 -- iter: 608/778
[A[ATraining Step: 520  | total loss: [1m[32m0.05986[0m[0m | time: 30.631s
[2K
| RMSProp | epoch: 021 | loss: 0.05986 - acc: 0.9859 -- iter: 640/778
[A[ATraining Step: 521  | total loss: [1m[32m0.08376[0m[0m | time: 31.946s
[2K
| RMSProp | epoch: 021 | loss: 0.08376 - acc: 0.9773 -- iter: 672/778
[A[ATraining Step: 522  | total loss: [1m[32m0.08664[0m[0m | time: 33.583s
[2K
| RMSProp | epoch: 021 | loss: 0.08664 - acc: 0.9765 -- iter: 704/778
[A[ATraining Step: 523  | total loss: [1m[32m0.07922[0m[0m | time: 35.189s
[2K
| RMSProp | epoch: 021 | loss: 0.07922 - acc: 0.9788 -- iter: 736/778
[A[ATraining Step: 524  | total loss: [1m[32m0.07510[0m[0m | time: 36.795s
[2K
| RMSProp | epoch: 021 | loss: 0.07510 - acc: 0.9809 -- iter: 768/778
[A[ATraining Step: 525  | total loss: [1m[32m0.08133[0m[0m | time: 41.255s
[2K
| RMSProp | epoch: 021 | loss: 0.08133 - acc: 0.9797 | val_loss: 0.46366 - val_acc: 0.8730 -- iter: 778/778
--
Training Step: 526  | total loss: [1m[32m0.07422[0m[0m | time: 1.393s
[2K
| RMSProp | epoch: 022 | loss: 0.07422 - acc: 0.9818 -- iter: 032/778
[A[ATraining Step: 527  | total loss: [1m[32m0.06803[0m[0m | time: 3.136s
[2K
| RMSProp | epoch: 022 | loss: 0.06803 - acc: 0.9836 -- iter: 064/778
[A[ATraining Step: 528  | total loss: [1m[32m0.06162[0m[0m | time: 4.757s
[2K
| RMSProp | epoch: 022 | loss: 0.06162 - acc: 0.9852 -- iter: 096/778
[A[ATraining Step: 529  | total loss: [1m[32m0.05577[0m[0m | time: 6.342s
[2K
| RMSProp | epoch: 022 | loss: 0.05577 - acc: 0.9867 -- iter: 128/778
[A[ATraining Step: 530  | total loss: [1m[32m0.05054[0m[0m | time: 8.308s
[2K
| RMSProp | epoch: 022 | loss: 0.05054 - acc: 0.9880 -- iter: 160/778
[A[ATraining Step: 531  | total loss: [1m[32m0.04689[0m[0m | time: 10.342s
[2K
| RMSProp | epoch: 022 | loss: 0.04689 - acc: 0.9892 -- iter: 192/778
[A[ATraining Step: 532  | total loss: [1m[32m0.04261[0m[0m | time: 15.323s
[2K
| RMSProp | epoch: 022 | loss: 0.04261 - acc: 0.9903 -- iter: 224/778
[A[ATraining Step: 533  | total loss: [1m[32m0.04143[0m[0m | time: 17.025s
[2K
| RMSProp | epoch: 022 | loss: 0.04143 - acc: 0.9913 -- iter: 256/778
[A[ATraining Step: 534  | total loss: [1m[32m0.07501[0m[0m | time: 18.599s
[2K
| RMSProp | epoch: 022 | loss: 0.07501 - acc: 0.9765 -- iter: 288/778
[A[ATraining Step: 535  | total loss: [1m[32m0.08691[0m[0m | time: 20.175s
[2K
| RMSProp | epoch: 022 | loss: 0.08691 - acc: 0.9726 -- iter: 320/778
[A[ATraining Step: 536  | total loss: [1m[32m0.09556[0m[0m | time: 21.798s
[2K
| RMSProp | epoch: 022 | loss: 0.09556 - acc: 0.9691 -- iter: 352/778
[A[ATraining Step: 537  | total loss: [1m[32m0.08804[0m[0m | time: 23.393s
[2K
| RMSProp | epoch: 022 | loss: 0.08804 - acc: 0.9722 -- iter: 384/778
[A[ATraining Step: 538  | total loss: [1m[32m0.09761[0m[0m | time: 24.984s
[2K
| RMSProp | epoch: 022 | loss: 0.09761 - acc: 0.9719 -- iter: 416/778
[A[ATraining Step: 539  | total loss: [1m[32m0.09468[0m[0m | time: 26.344s
[2K
| RMSProp | epoch: 022 | loss: 0.09468 - acc: 0.9715 -- iter: 448/778
[A[ATraining Step: 540  | total loss: [1m[32m0.11665[0m[0m | time: 27.856s
[2K
| RMSProp | epoch: 022 | loss: 0.11665 - acc: 0.9681 -- iter: 480/778
[A[ATraining Step: 541  | total loss: [1m[32m0.11067[0m[0m | time: 29.245s
[2K
| RMSProp | epoch: 022 | loss: 0.11067 - acc: 0.9713 -- iter: 512/778
[A[ATraining Step: 542  | total loss: [1m[32m0.10318[0m[0m | time: 30.761s
[2K
| RMSProp | epoch: 022 | loss: 0.10318 - acc: 0.9742 -- iter: 544/778
[A[ATraining Step: 543  | total loss: [1m[32m0.09348[0m[0m | time: 32.336s
[2K
| RMSProp | epoch: 022 | loss: 0.09348 - acc: 0.9768 -- iter: 576/778
[A[ATraining Step: 544  | total loss: [1m[32m0.08490[0m[0m | time: 33.903s
[2K
| RMSProp | epoch: 022 | loss: 0.08490 - acc: 0.9791 -- iter: 608/778
[A[ATraining Step: 545  | total loss: [1m[32m0.07693[0m[0m | time: 34.585s
[2K
| RMSProp | epoch: 022 | loss: 0.07693 - acc: 0.9812 -- iter: 640/778
[A[ATraining Step: 546  | total loss: [1m[32m0.06940[0m[0m | time: 35.142s
[2K
| RMSProp | epoch: 022 | loss: 0.06940 - acc: 0.9831 -- iter: 672/778
[A[ATraining Step: 547  | total loss: [1m[32m0.06256[0m[0m | time: 37.600s
[2K
| RMSProp | epoch: 022 | loss: 0.06256 - acc: 0.9848 -- iter: 704/778
[A[ATraining Step: 548  | total loss: [1m[32m0.06560[0m[0m | time: 39.142s
[2K
| RMSProp | epoch: 022 | loss: 0.06560 - acc: 0.9832 -- iter: 736/778
[A[ATraining Step: 549  | total loss: [1m[32m0.06066[0m[0m | time: 40.680s
[2K
| RMSProp | epoch: 022 | loss: 0.06066 - acc: 0.9848 -- iter: 768/778
[A[ATraining Step: 550  | total loss: [1m[32m0.05492[0m[0m | time: 45.352s
[2K
| RMSProp | epoch: 022 | loss: 0.05492 - acc: 0.9864 | val_loss: 0.55633 - val_acc: 0.8525 -- iter: 778/778
--
Training Step: 551  | total loss: [1m[32m0.04998[0m[0m | time: 1.488s
[2K
| RMSProp | epoch: 023 | loss: 0.04998 - acc: 0.9877 -- iter: 032/778
[A[ATraining Step: 552  | total loss: [1m[32m0.04533[0m[0m | time: 3.020s
[2K
| RMSProp | epoch: 023 | loss: 0.04533 - acc: 0.9890 -- iter: 064/778
[A[ATraining Step: 553  | total loss: [1m[32m0.04110[0m[0m | time: 4.436s
[2K
| RMSProp | epoch: 023 | loss: 0.04110 - acc: 0.9901 -- iter: 096/778
[A[ATraining Step: 554  | total loss: [1m[32m0.03716[0m[0m | time: 5.974s
[2K
| RMSProp | epoch: 023 | loss: 0.03716 - acc: 0.9911 -- iter: 128/778
[A[ATraining Step: 555  | total loss: [1m[32m0.03461[0m[0m | time: 7.513s
[2K
| RMSProp | epoch: 023 | loss: 0.03461 - acc: 0.9919 -- iter: 160/778
[A[ATraining Step: 556  | total loss: [1m[32m0.05072[0m[0m | time: 9.116s
[2K
| RMSProp | epoch: 023 | loss: 0.05072 - acc: 0.9865 -- iter: 192/778
[A[ATraining Step: 557  | total loss: [1m[32m0.05576[0m[0m | time: 10.761s
[2K
| RMSProp | epoch: 023 | loss: 0.05576 - acc: 0.9847 -- iter: 224/778
[A[ATraining Step: 558  | total loss: [1m[32m0.05178[0m[0m | time: 12.215s
[2K
| RMSProp | epoch: 023 | loss: 0.05178 - acc: 0.9863 -- iter: 256/778
[A[ATraining Step: 559  | total loss: [1m[32m0.04829[0m[0m | time: 13.864s
[2K
| RMSProp | epoch: 023 | loss: 0.04829 - acc: 0.9876 -- iter: 288/778
[A[ATraining Step: 560  | total loss: [1m[32m0.04409[0m[0m | time: 15.365s
[2K
| RMSProp | epoch: 023 | loss: 0.04409 - acc: 0.9889 -- iter: 320/778
[A[ATraining Step: 561  | total loss: [1m[32m0.03995[0m[0m | time: 17.095s
[2K
| RMSProp | epoch: 023 | loss: 0.03995 - acc: 0.9900 -- iter: 352/778
[A[ATraining Step: 562  | total loss: [1m[32m0.03607[0m[0m | time: 18.626s
[2K
| RMSProp | epoch: 023 | loss: 0.03607 - acc: 0.9910 -- iter: 384/778
[A[ATraining Step: 563  | total loss: [1m[32m0.03285[0m[0m | time: 20.138s
[2K
| RMSProp | epoch: 023 | loss: 0.03285 - acc: 0.9919 -- iter: 416/778
[A[ATraining Step: 564  | total loss: [1m[32m0.02969[0m[0m | time: 21.731s
[2K
| RMSProp | epoch: 023 | loss: 0.02969 - acc: 0.9927 -- iter: 448/778
[A[ATraining Step: 565  | total loss: [1m[32m0.02721[0m[0m | time: 23.205s
[2K
| RMSProp | epoch: 023 | loss: 0.02721 - acc: 0.9934 -- iter: 480/778
[A[ATraining Step: 566  | total loss: [1m[32m0.03864[0m[0m | time: 24.703s
[2K
| RMSProp | epoch: 023 | loss: 0.03864 - acc: 0.9910 -- iter: 512/778
[A[ATraining Step: 567  | total loss: [1m[32m0.03690[0m[0m | time: 26.345s
[2K
| RMSProp | epoch: 023 | loss: 0.03690 - acc: 0.9919 -- iter: 544/778
[A[ATraining Step: 568  | total loss: [1m[32m0.03356[0m[0m | time: 27.989s
[2K
| RMSProp | epoch: 023 | loss: 0.03356 - acc: 0.9927 -- iter: 576/778
[A[ATraining Step: 569  | total loss: [1m[32m0.03046[0m[0m | time: 29.729s
[2K
| RMSProp | epoch: 023 | loss: 0.03046 - acc: 0.9934 -- iter: 608/778
[A[ATraining Step: 570  | total loss: [1m[32m0.02749[0m[0m | time: 31.328s
[2K
| RMSProp | epoch: 023 | loss: 0.02749 - acc: 0.9941 -- iter: 640/778
[A[ATraining Step: 571  | total loss: [1m[32m0.02498[0m[0m | time: 31.852s
[2K
| RMSProp | epoch: 023 | loss: 0.02498 - acc: 0.9947 -- iter: 672/778
[A[ATraining Step: 572  | total loss: [1m[32m0.02260[0m[0m | time: 32.399s
[2K
| RMSProp | epoch: 023 | loss: 0.02260 - acc: 0.9952 -- iter: 704/778
[A[ATraining Step: 573  | total loss: [1m[32m0.02044[0m[0m | time: 34.064s
[2K
| RMSProp | epoch: 023 | loss: 0.02044 - acc: 0.9957 -- iter: 736/778
[A[ATraining Step: 574  | total loss: [1m[32m0.01844[0m[0m | time: 35.759s
[2K
| RMSProp | epoch: 023 | loss: 0.01844 - acc: 0.9961 -- iter: 768/778
[A[ATraining Step: 575  | total loss: [1m[32m0.01675[0m[0m | time: 40.392s
[2K
| RMSProp | epoch: 023 | loss: 0.01675 - acc: 0.9965 | val_loss: 0.77521 - val_acc: 0.8443 -- iter: 778/778
--
Training Step: 576  | total loss: [1m[32m0.01512[0m[0m | time: 1.594s
[2K
| RMSProp | epoch: 024 | loss: 0.01512 - acc: 0.9968 -- iter: 032/778
[A[ATraining Step: 577  | total loss: [1m[32m0.01389[0m[0m | time: 3.094s
[2K
| RMSProp | epoch: 024 | loss: 0.01389 - acc: 0.9972 -- iter: 064/778
[A[ATraining Step: 578  | total loss: [1m[32m0.01361[0m[0m | time: 4.651s
[2K
| RMSProp | epoch: 024 | loss: 0.01361 - acc: 0.9974 -- iter: 096/778
[A[ATraining Step: 579  | total loss: [1m[32m0.04224[0m[0m | time: 6.265s
[2K
| RMSProp | epoch: 024 | loss: 0.04224 - acc: 0.9883 -- iter: 128/778
[A[ATraining Step: 580  | total loss: [1m[32m0.09999[0m[0m | time: 7.904s
[2K
| RMSProp | epoch: 024 | loss: 0.09999 - acc: 0.9676 -- iter: 160/778
[A[ATraining Step: 581  | total loss: [1m[32m0.10184[0m[0m | time: 9.660s
[2K
| RMSProp | epoch: 024 | loss: 0.10184 - acc: 0.9677 -- iter: 192/778
[A[ATraining Step: 582  | total loss: [1m[32m0.10106[0m[0m | time: 11.151s
[2K
| RMSProp | epoch: 024 | loss: 0.10106 - acc: 0.9678 -- iter: 224/778
[A[ATraining Step: 583  | total loss: [1m[32m0.10013[0m[0m | time: 12.712s
[2K
| RMSProp | epoch: 024 | loss: 0.10013 - acc: 0.9679 -- iter: 256/778
[A[ATraining Step: 584  | total loss: [1m[32m0.09500[0m[0m | time: 14.475s
[2K
| RMSProp | epoch: 024 | loss: 0.09500 - acc: 0.9680 -- iter: 288/778
[A[ATraining Step: 585  | total loss: [1m[32m0.08646[0m[0m | time: 16.284s
[2K
| RMSProp | epoch: 024 | loss: 0.08646 - acc: 0.9712 -- iter: 320/778
[A[ATraining Step: 586  | total loss: [1m[32m0.07829[0m[0m | time: 17.725s
[2K
| RMSProp | epoch: 024 | loss: 0.07829 - acc: 0.9741 -- iter: 352/778
[A[ATraining Step: 587  | total loss: [1m[32m0.07383[0m[0m | time: 20.015s
[2K
| RMSProp | epoch: 024 | loss: 0.07383 - acc: 0.9736 -- iter: 384/778
[A[ATraining Step: 588  | total loss: [1m[32m0.09100[0m[0m | time: 22.110s
[2K
| RMSProp | epoch: 024 | loss: 0.09100 - acc: 0.9668 -- iter: 416/778
[A[ATraining Step: 589  | total loss: [1m[32m0.08795[0m[0m | time: 23.803s
[2K
| RMSProp | epoch: 024 | loss: 0.08795 - acc: 0.9670 -- iter: 448/778
[A[ATraining Step: 590  | total loss: [1m[32m0.08188[0m[0m | time: 25.534s
[2K
| RMSProp | epoch: 024 | loss: 0.08188 - acc: 0.9703 -- iter: 480/778
[A[ATraining Step: 591  | total loss: [1m[32m0.07462[0m[0m | time: 27.098s
[2K
| RMSProp | epoch: 024 | loss: 0.07462 - acc: 0.9733 -- iter: 512/778
[A[ATraining Step: 592  | total loss: [1m[32m0.08313[0m[0m | time: 28.559s
[2K
| RMSProp | epoch: 024 | loss: 0.08313 - acc: 0.9728 -- iter: 544/778
[A[ATraining Step: 593  | total loss: [1m[32m0.08011[0m[0m | time: 30.085s
[2K
| RMSProp | epoch: 024 | loss: 0.08011 - acc: 0.9724 -- iter: 576/778
[A[ATraining Step: 594  | total loss: [1m[32m0.07295[0m[0m | time: 31.774s
[2K
| RMSProp | epoch: 024 | loss: 0.07295 - acc: 0.9752 -- iter: 608/778
[A[ATraining Step: 595  | total loss: [1m[32m0.06637[0m[0m | time: 33.204s
[2K
| RMSProp | epoch: 024 | loss: 0.06637 - acc: 0.9777 -- iter: 640/778
[A[ATraining Step: 596  | total loss: [1m[32m0.06033[0m[0m | time: 34.780s
[2K
| RMSProp | epoch: 024 | loss: 0.06033 - acc: 0.9799 -- iter: 672/778
[A[ATraining Step: 597  | total loss: [1m[32m0.05466[0m[0m | time: 35.370s
[2K
| RMSProp | epoch: 024 | loss: 0.05466 - acc: 0.9819 -- iter: 704/778
[A[ATraining Step: 598  | total loss: [1m[32m0.08679[0m[0m | time: 36.008s
[2K
| RMSProp | epoch: 024 | loss: 0.08679 - acc: 0.9737 -- iter: 736/778
[A[ATraining Step: 599  | total loss: [1m[32m0.09077[0m[0m | time: 37.475s
[2K
| RMSProp | epoch: 024 | loss: 0.09077 - acc: 0.9663 -- iter: 768/778
[A[ATraining Step: 600  | total loss: [1m[32m0.08485[0m[0m | time: 41.415s
[2K
| RMSProp | epoch: 024 | loss: 0.08485 - acc: 0.9697 | val_loss: 0.47467 - val_acc: 0.8852 -- iter: 778/778
--
Training Step: 601  | total loss: [1m[32m0.08712[0m[0m | time: 1.615s
[2K
| RMSProp | epoch: 025 | loss: 0.08712 - acc: 0.9696 -- iter: 032/778
[A[ATraining Step: 602  | total loss: [1m[32m0.08992[0m[0m | time: 2.986s
[2K
| RMSProp | epoch: 025 | loss: 0.08992 - acc: 0.9664 -- iter: 064/778
[A[ATraining Step: 603  | total loss: [1m[32m0.09736[0m[0m | time: 4.602s
[2K
| RMSProp | epoch: 025 | loss: 0.09736 - acc: 0.9573 -- iter: 096/778
[A[ATraining Step: 604  | total loss: [1m[32m0.09239[0m[0m | time: 6.242s
[2K
| RMSProp | epoch: 025 | loss: 0.09239 - acc: 0.9615 -- iter: 128/778
[A[ATraining Step: 605  | total loss: [1m[32m0.08385[0m[0m | time: 8.014s
[2K
| RMSProp | epoch: 025 | loss: 0.08385 - acc: 0.9654 -- iter: 160/778
[A[ATraining Step: 606  | total loss: [1m[32m0.08232[0m[0m | time: 9.430s
[2K
| RMSProp | epoch: 025 | loss: 0.08232 - acc: 0.9657 -- iter: 192/778
[A[ATraining Step: 607  | total loss: [1m[32m0.07512[0m[0m | time: 10.756s
[2K
| RMSProp | epoch: 025 | loss: 0.07512 - acc: 0.9691 -- iter: 224/778
[A[ATraining Step: 608  | total loss: [1m[32m0.06885[0m[0m | time: 12.512s
[2K
| RMSProp | epoch: 025 | loss: 0.06885 - acc: 0.9722 -- iter: 256/778
[A[ATraining Step: 609  | total loss: [1m[32m0.06236[0m[0m | time: 14.169s
[2K
| RMSProp | epoch: 025 | loss: 0.06236 - acc: 0.9750 -- iter: 288/778
[A[ATraining Step: 610  | total loss: [1m[32m0.05662[0m[0m | time: 15.859s
[2K
| RMSProp | epoch: 025 | loss: 0.05662 - acc: 0.9775 -- iter: 320/778
[A[ATraining Step: 611  | total loss: [1m[32m0.06705[0m[0m | time: 17.524s
[2K
| RMSProp | epoch: 025 | loss: 0.06705 - acc: 0.9735 -- iter: 352/778
[A[ATraining Step: 612  | total loss: [1m[32m0.07333[0m[0m | time: 18.981s
[2K
| RMSProp | epoch: 025 | loss: 0.07333 - acc: 0.9668 -- iter: 384/778
[A[ATraining Step: 613  | total loss: [1m[32m0.07959[0m[0m | time: 20.497s
[2K
| RMSProp | epoch: 025 | loss: 0.07959 - acc: 0.9670 -- iter: 416/778
[A[ATraining Step: 614  | total loss: [1m[32m0.07416[0m[0m | time: 21.795s
[2K
| RMSProp | epoch: 025 | loss: 0.07416 - acc: 0.9703 -- iter: 448/778
[A[ATraining Step: 615  | total loss: [1m[32m0.06743[0m[0m | time: 23.375s
[2K
| RMSProp | epoch: 025 | loss: 0.06743 - acc: 0.9733 -- iter: 480/778
[A[ATraining Step: 616  | total loss: [1m[32m0.06146[0m[0m | time: 24.909s
[2K
| RMSProp | epoch: 025 | loss: 0.06146 - acc: 0.9759 -- iter: 512/778
[A[ATraining Step: 617  | total loss: [1m[32m0.05893[0m[0m | time: 26.393s
[2K
| RMSProp | epoch: 025 | loss: 0.05893 - acc: 0.9752 -- iter: 544/778
[A[ATraining Step: 618  | total loss: [1m[32m0.05447[0m[0m | time: 28.107s
[2K
| RMSProp | epoch: 025 | loss: 0.05447 - acc: 0.9777 -- iter: 576/778
[A[ATraining Step: 619  | total loss: [1m[32m0.04945[0m[0m | time: 29.501s
[2K
| RMSProp | epoch: 025 | loss: 0.04945 - acc: 0.9799 -- iter: 608/778
[A[ATraining Step: 620  | total loss: [1m[32m0.04470[0m[0m | time: 30.966s
[2K
| RMSProp | epoch: 025 | loss: 0.04470 - acc: 0.9819 -- iter: 640/778
[A[ATraining Step: 621  | total loss: [1m[32m0.04087[0m[0m | time: 32.760s
[2K
| RMSProp | epoch: 025 | loss: 0.04087 - acc: 0.9837 -- iter: 672/778
[A[ATraining Step: 622  | total loss: [1m[32m0.03686[0m[0m | time: 34.372s
[2K
| RMSProp | epoch: 025 | loss: 0.03686 - acc: 0.9854 -- iter: 704/778
[A[ATraining Step: 623  | total loss: [1m[32m0.03333[0m[0m | time: 34.926s
[2K
| RMSProp | epoch: 025 | loss: 0.03333 - acc: 0.9868 -- iter: 736/778
[A[ATraining Step: 624  | total loss: [1m[32m0.03002[0m[0m | time: 35.551s
[2K
| RMSProp | epoch: 025 | loss: 0.03002 - acc: 0.9881 -- iter: 768/778
[A[ATraining Step: 625  | total loss: [1m[32m0.02704[0m[0m | time: 39.578s
[2K
| RMSProp | epoch: 025 | loss: 0.02704 - acc: 0.9893 | val_loss: 0.61289 - val_acc: 0.8770 -- iter: 778/778
--
Training Step: 626  | total loss: [1m[32m0.02441[0m[0m | time: 1.392s
[2K
| RMSProp | epoch: 026 | loss: 0.02441 - acc: 0.9904 -- iter: 032/778
[A[ATraining Step: 627  | total loss: [1m[32m0.02205[0m[0m | time: 3.087s
[2K
| RMSProp | epoch: 026 | loss: 0.02205 - acc: 0.9914 -- iter: 064/778
[A[ATraining Step: 628  | total loss: [1m[32m0.02002[0m[0m | time: 4.722s
[2K
| RMSProp | epoch: 026 | loss: 0.02002 - acc: 0.9922 -- iter: 096/778
[A[ATraining Step: 629  | total loss: [1m[32m0.01805[0m[0m | time: 6.303s
[2K
| RMSProp | epoch: 026 | loss: 0.01805 - acc: 0.9930 -- iter: 128/778
[A[ATraining Step: 630  | total loss: [1m[32m0.01627[0m[0m | time: 7.837s
[2K
| RMSProp | epoch: 026 | loss: 0.01627 - acc: 0.9937 -- iter: 160/778
[A[ATraining Step: 631  | total loss: [1m[32m0.03041[0m[0m | time: 9.337s
[2K
| RMSProp | epoch: 026 | loss: 0.03041 - acc: 0.9912 -- iter: 192/778
[A[ATraining Step: 632  | total loss: [1m[32m0.03311[0m[0m | time: 11.016s
[2K
| RMSProp | epoch: 026 | loss: 0.03311 - acc: 0.9890 -- iter: 224/778
[A[ATraining Step: 633  | total loss: [1m[32m0.03274[0m[0m | time: 12.683s
[2K
| RMSProp | epoch: 026 | loss: 0.03274 - acc: 0.9901 -- iter: 256/778
[A[ATraining Step: 634  | total loss: [1m[32m0.03015[0m[0m | time: 14.320s
[2K
| RMSProp | epoch: 026 | loss: 0.03015 - acc: 0.9911 -- iter: 288/778
[A[ATraining Step: 635  | total loss: [1m[32m0.02725[0m[0m | time: 15.823s
[2K
| RMSProp | epoch: 026 | loss: 0.02725 - acc: 0.9920 -- iter: 320/778
[A[ATraining Step: 636  | total loss: [1m[32m0.02468[0m[0m | time: 17.401s
[2K
| RMSProp | epoch: 026 | loss: 0.02468 - acc: 0.9928 -- iter: 352/778
[A[ATraining Step: 637  | total loss: [1m[32m0.02498[0m[0m | time: 18.981s
[2K
| RMSProp | epoch: 026 | loss: 0.02498 - acc: 0.9904 -- iter: 384/778
[A[ATraining Step: 638  | total loss: [1m[32m0.08198[0m[0m | time: 20.495s
[2K
| RMSProp | epoch: 026 | loss: 0.08198 - acc: 0.9694 -- iter: 416/778
[A[ATraining Step: 639  | total loss: [1m[32m0.07563[0m[0m | time: 22.055s
[2K
| RMSProp | epoch: 026 | loss: 0.07563 - acc: 0.9725 -- iter: 448/778
[A[ATraining Step: 640  | total loss: [1m[32m0.06971[0m[0m | time: 23.589s
[2K
| RMSProp | epoch: 026 | loss: 0.06971 - acc: 0.9753 -- iter: 480/778
[A[ATraining Step: 641  | total loss: [1m[32m0.06326[0m[0m | time: 25.303s
[2K
| RMSProp | epoch: 026 | loss: 0.06326 - acc: 0.9777 -- iter: 512/778
[A[ATraining Step: 642  | total loss: [1m[32m0.05817[0m[0m | time: 26.872s
[2K
| RMSProp | epoch: 026 | loss: 0.05817 - acc: 0.9800 -- iter: 544/778
[A[ATraining Step: 643  | total loss: [1m[32m0.06487[0m[0m | time: 28.386s
[2K
| RMSProp | epoch: 026 | loss: 0.06487 - acc: 0.9788 -- iter: 576/778
[A[ATraining Step: 644  | total loss: [1m[32m0.16658[0m[0m | time: 30.180s
[2K
| RMSProp | epoch: 026 | loss: 0.16658 - acc: 0.9653 -- iter: 608/778
[A[ATraining Step: 645  | total loss: [1m[32m0.17719[0m[0m | time: 31.704s
[2K
| RMSProp | epoch: 026 | loss: 0.17719 - acc: 0.9688 -- iter: 640/778
[A[ATraining Step: 646  | total loss: [1m[32m0.16819[0m[0m | time: 33.220s
[2K
| RMSProp | epoch: 026 | loss: 0.16819 - acc: 0.9688 -- iter: 672/778
[A[ATraining Step: 647  | total loss: [1m[32m0.15609[0m[0m | time: 34.921s
[2K
| RMSProp | epoch: 026 | loss: 0.15609 - acc: 0.9719 -- iter: 704/778
[A[ATraining Step: 648  | total loss: [1m[32m0.14135[0m[0m | time: 36.539s
[2K
| RMSProp | epoch: 026 | loss: 0.14135 - acc: 0.9747 -- iter: 736/778
[A[ATraining Step: 649  | total loss: [1m[32m0.12855[0m[0m | time: 37.106s
[2K
| RMSProp | epoch: 026 | loss: 0.12855 - acc: 0.9772 -- iter: 768/778
[A[ATraining Step: 650  | total loss: [1m[32m0.11617[0m[0m | time: 39.007s
[2K
| RMSProp | epoch: 026 | loss: 0.11617 - acc: 0.9795 | val_loss: 0.53470 - val_acc: 0.8893 -- iter: 778/778
--
Training Step: 651  | total loss: [1m[32m0.10473[0m[0m | time: 1.139s
[2K
| RMSProp | epoch: 027 | loss: 0.10473 - acc: 0.9816 -- iter: 032/778
[A[ATraining Step: 652  | total loss: [1m[32m0.09466[0m[0m | time: 2.290s
[2K
| RMSProp | epoch: 027 | loss: 0.09466 - acc: 0.9834 -- iter: 064/778
[A[ATraining Step: 653  | total loss: [1m[32m0.08530[0m[0m | time: 3.510s
[2K
| RMSProp | epoch: 027 | loss: 0.08530 - acc: 0.9851 -- iter: 096/778
[A[ATraining Step: 654  | total loss: [1m[32m0.07693[0m[0m | time: 4.792s
[2K
| RMSProp | epoch: 027 | loss: 0.07693 - acc: 0.9866 -- iter: 128/778
[A[ATraining Step: 655  | total loss: [1m[32m0.07071[0m[0m | time: 5.992s
[2K
| RMSProp | epoch: 027 | loss: 0.07071 - acc: 0.9879 -- iter: 160/778
[A[ATraining Step: 656  | total loss: [1m[32m0.09588[0m[0m | time: 7.138s
[2K
| RMSProp | epoch: 027 | loss: 0.09588 - acc: 0.9766 -- iter: 192/778
[A[ATraining Step: 657  | total loss: [1m[32m0.09207[0m[0m | time: 8.436s
[2K
| RMSProp | epoch: 027 | loss: 0.09207 - acc: 0.9758 -- iter: 224/778
[A[ATraining Step: 658  | total loss: [1m[32m0.13610[0m[0m | time: 9.878s
[2K
| RMSProp | epoch: 027 | loss: 0.13610 - acc: 0.9689 -- iter: 256/778
[A[ATraining Step: 659  | total loss: [1m[32m0.12922[0m[0m | time: 11.186s
[2K
| RMSProp | epoch: 027 | loss: 0.12922 - acc: 0.9689 -- iter: 288/778
[A[ATraining Step: 660  | total loss: [1m[32m0.12182[0m[0m | time: 12.162s
[2K
| RMSProp | epoch: 027 | loss: 0.12182 - acc: 0.9688 -- iter: 320/778
[A[ATraining Step: 661  | total loss: [1m[32m0.11181[0m[0m | time: 13.343s
[2K
| RMSProp | epoch: 027 | loss: 0.11181 - acc: 0.9720 -- iter: 352/778
[A[ATraining Step: 662  | total loss: [1m[32m0.10144[0m[0m | time: 14.480s
[2K
| RMSProp | epoch: 027 | loss: 0.10144 - acc: 0.9748 -- iter: 384/778
[A[ATraining Step: 663  | total loss: [1m[32m0.09543[0m[0m | time: 15.536s
[2K
| RMSProp | epoch: 027 | loss: 0.09543 - acc: 0.9742 -- iter: 416/778
[A[ATraining Step: 664  | total loss: [1m[32m0.10203[0m[0m | time: 16.744s
[2K
| RMSProp | epoch: 027 | loss: 0.10203 - acc: 0.9705 -- iter: 448/778
[A[ATraining Step: 665  | total loss: [1m[32m0.10457[0m[0m | time: 18.071s
[2K
| RMSProp | epoch: 027 | loss: 0.10457 - acc: 0.9703 -- iter: 480/778
[A[ATraining Step: 666  | total loss: [1m[32m0.09559[0m[0m | time: 19.387s
[2K
| RMSProp | epoch: 027 | loss: 0.09559 - acc: 0.9733 -- iter: 512/778
[A[ATraining Step: 667  | total loss: [1m[32m0.08702[0m[0m | time: 20.576s
[2K
| RMSProp | epoch: 027 | loss: 0.08702 - acc: 0.9760 -- iter: 544/778
[A[ATraining Step: 668  | total loss: [1m[32m0.07903[0m[0m | time: 22.146s
[2K
| RMSProp | epoch: 027 | loss: 0.07903 - acc: 0.9784 -- iter: 576/778
[A[ATraining Step: 669  | total loss: [1m[32m0.07120[0m[0m | time: 23.881s
[2K
| RMSProp | epoch: 027 | loss: 0.07120 - acc: 0.9805 -- iter: 608/778
[A[ATraining Step: 670  | total loss: [1m[32m0.06436[0m[0m | time: 25.435s
[2K
| RMSProp | epoch: 027 | loss: 0.06436 - acc: 0.9825 -- iter: 640/778
[A[ATraining Step: 671  | total loss: [1m[32m0.05804[0m[0m | time: 32.079s
[2K
| RMSProp | epoch: 027 | loss: 0.05804 - acc: 0.9842 -- iter: 672/778
[A[ATraining Step: 672  | total loss: [1m[32m0.05235[0m[0m | time: 39.847s
[2K
| RMSProp | epoch: 027 | loss: 0.05235 - acc: 0.9858 -- iter: 704/778
[A[ATraining Step: 673  | total loss: [1m[32m0.04725[0m[0m | time: 44.083s
[2K
| RMSProp | epoch: 027 | loss: 0.04725 - acc: 0.9872 -- iter: 736/778
[A[ATraining Step: 674  | total loss: [1m[32m0.04265[0m[0m | time: 47.955s
[2K
| RMSProp | epoch: 027 | loss: 0.04265 - acc: 0.9885 -- iter: 768/778
[A[ATraining Step: 675  | total loss: [1m[32m0.03845[0m[0m | time: 56.245s
[2K
| RMSProp | epoch: 027 | loss: 0.03845 - acc: 0.9897 | val_loss: 0.65341 - val_acc: 0.8648 -- iter: 778/778
--
Training Step: 676  | total loss: [1m[32m0.03463[0m[0m | time: 0.482s
[2K
| RMSProp | epoch: 028 | loss: 0.03463 - acc: 0.9907 -- iter: 032/778
[A[ATraining Step: 677  | total loss: [1m[32m0.03120[0m[0m | time: 2.139s
[2K
| RMSProp | epoch: 028 | loss: 0.03120 - acc: 0.9916 -- iter: 064/778
[A[ATraining Step: 678  | total loss: [1m[32m0.02836[0m[0m | time: 8.788s
[2K
| RMSProp | epoch: 028 | loss: 0.02836 - acc: 0.9925 -- iter: 096/778
[A[ATraining Step: 679  | total loss: [1m[32m0.02555[0m[0m | time: 10.770s
[2K
| RMSProp | epoch: 028 | loss: 0.02555 - acc: 0.9932 -- iter: 128/778
[A[ATraining Step: 680  | total loss: [1m[32m0.02320[0m[0m | time: 17.413s
[2K
| RMSProp | epoch: 028 | loss: 0.02320 - acc: 0.9939 -- iter: 160/778
[A[ATraining Step: 681  | total loss: [1m[32m0.02094[0m[0m | time: 18.890s
[2K
| RMSProp | epoch: 028 | loss: 0.02094 - acc: 0.9945 -- iter: 192/778
[A[ATraining Step: 682  | total loss: [1m[32m0.01887[0m[0m | time: 20.341s
[2K
| RMSProp | epoch: 028 | loss: 0.01887 - acc: 0.9951 -- iter: 224/778
[A[ATraining Step: 683  | total loss: [1m[32m0.01701[0m[0m | time: 21.823s
[2K
| RMSProp | epoch: 028 | loss: 0.01701 - acc: 0.9955 -- iter: 256/778
[A[ATraining Step: 684  | total loss: [1m[32m0.01534[0m[0m | time: 23.102s
[2K
| RMSProp | epoch: 028 | loss: 0.01534 - acc: 0.9960 -- iter: 288/778
[A[ATraining Step: 685  | total loss: [1m[32m0.01386[0m[0m | time: 24.612s
[2K
| RMSProp | epoch: 028 | loss: 0.01386 - acc: 0.9964 -- iter: 320/778
[A[ATraining Step: 686  | total loss: [1m[32m0.01251[0m[0m | time: 26.102s
[2K
| RMSProp | epoch: 028 | loss: 0.01251 - acc: 0.9968 -- iter: 352/778
[A[ATraining Step: 687  | total loss: [1m[32m0.01128[0m[0m | time: 27.363s
[2K
| RMSProp | epoch: 028 | loss: 0.01128 - acc: 0.9971 -- iter: 384/778
[A[ATraining Step: 688  | total loss: [1m[32m0.01016[0m[0m | time: 28.633s
[2K
| RMSProp | epoch: 028 | loss: 0.01016 - acc: 0.9974 -- iter: 416/778
[A[ATraining Step: 689  | total loss: [1m[32m0.05110[0m[0m | time: 29.826s
[2K
| RMSProp | epoch: 028 | loss: 0.05110 - acc: 0.9883 -- iter: 448/778
[A[ATraining Step: 690  | total loss: [1m[32m0.10643[0m[0m | time: 31.031s
[2K
| RMSProp | epoch: 028 | loss: 0.10643 - acc: 0.9769 -- iter: 480/778
[A[ATraining Step: 691  | total loss: [1m[32m0.10362[0m[0m | time: 32.301s
[2K
| RMSProp | epoch: 028 | loss: 0.10362 - acc: 0.9792 -- iter: 512/778
[A[ATraining Step: 692  | total loss: [1m[32m0.09700[0m[0m | time: 33.601s
[2K
| RMSProp | epoch: 028 | loss: 0.09700 - acc: 0.9782 -- iter: 544/778
[A[ATraining Step: 693  | total loss: [1m[32m0.08943[0m[0m | time: 34.974s
[2K
| RMSProp | epoch: 028 | loss: 0.08943 - acc: 0.9804 -- iter: 576/778
[A[ATraining Step: 694  | total loss: [1m[32m0.08102[0m[0m | time: 36.499s
[2K
| RMSProp | epoch: 028 | loss: 0.08102 - acc: 0.9823 -- iter: 608/778
[A[ATraining Step: 695  | total loss: [1m[32m0.07356[0m[0m | time: 37.827s
[2K
| RMSProp | epoch: 028 | loss: 0.07356 - acc: 0.9841 -- iter: 640/778
[A[ATraining Step: 696  | total loss: [1m[32m0.38442[0m[0m | time: 39.020s
[2K
| RMSProp | epoch: 028 | loss: 0.38442 - acc: 0.9451 -- iter: 672/778
[A[ATraining Step: 697  | total loss: [1m[32m0.36829[0m[0m | time: 40.629s
[2K
| RMSProp | epoch: 028 | loss: 0.36829 - acc: 0.9506 -- iter: 704/778
[A[ATraining Step: 698  | total loss: [1m[32m0.33756[0m[0m | time: 41.999s
[2K
| RMSProp | epoch: 028 | loss: 0.33756 - acc: 0.9555 -- iter: 736/778
[A[ATraining Step: 699  | total loss: [1m[32m0.30600[0m[0m | time: 43.410s
[2K
| RMSProp | epoch: 028 | loss: 0.30600 - acc: 0.9600 -- iter: 768/778
[A[ATraining Step: 700  | total loss: [1m[32m0.27998[0m[0m | time: 46.525s
[2K
| RMSProp | epoch: 028 | loss: 0.27998 - acc: 0.9640 | val_loss: 0.45348 - val_acc: 0.8730 -- iter: 778/778
--
Training Step: 701  | total loss: [1m[32m0.25301[0m[0m | time: 0.546s
[2K
| RMSProp | epoch: 029 | loss: 0.25301 - acc: 0.9676 -- iter: 032/778
[A[ATraining Step: 702  | total loss: [1m[32m0.22839[0m[0m | time: 1.050s
[2K
| RMSProp | epoch: 029 | loss: 0.22839 - acc: 0.9708 -- iter: 064/778
[A[ATraining Step: 703  | total loss: [1m[32m0.20595[0m[0m | time: 2.371s
[2K
| RMSProp | epoch: 029 | loss: 0.20595 - acc: 0.9737 -- iter: 096/778
[A[ATraining Step: 704  | total loss: [1m[32m0.18582[0m[0m | time: 3.602s
[2K
| RMSProp | epoch: 029 | loss: 0.18582 - acc: 0.9764 -- iter: 128/778
[A[ATraining Step: 705  | total loss: [1m[32m0.17499[0m[0m | time: 4.920s
[2K
| RMSProp | epoch: 029 | loss: 0.17499 - acc: 0.9756 -- iter: 160/778
[A[ATraining Step: 706  | total loss: [1m[32m0.16755[0m[0m | time: 6.288s
[2K
| RMSProp | epoch: 029 | loss: 0.16755 - acc: 0.9749 -- iter: 192/778
[A[ATraining Step: 707  | total loss: [1m[32m0.15130[0m[0m | time: 7.589s
[2K
| RMSProp | epoch: 029 | loss: 0.15130 - acc: 0.9774 -- iter: 224/778
[A[ATraining Step: 708  | total loss: [1m[32m0.14412[0m[0m | time: 8.970s
[2K
| RMSProp | epoch: 029 | loss: 0.14412 - acc: 0.9766 -- iter: 256/778
[A[ATraining Step: 709  | total loss: [1m[32m0.13313[0m[0m | time: 10.504s
[2K
| RMSProp | epoch: 029 | loss: 0.13313 - acc: 0.9758 -- iter: 288/778
[A[ATraining Step: 710  | total loss: [1m[32m0.12033[0m[0m | time: 12.051s
[2K
| RMSProp | epoch: 029 | loss: 0.12033 - acc: 0.9782 -- iter: 320/778
[A[ATraining Step: 711  | total loss: [1m[32m0.11964[0m[0m | time: 13.462s
[2K
| RMSProp | epoch: 029 | loss: 0.11964 - acc: 0.9741 -- iter: 352/778
[A[ATraining Step: 712  | total loss: [1m[32m0.10858[0m[0m | time: 14.590s
[2K
| RMSProp | epoch: 029 | loss: 0.10858 - acc: 0.9767 -- iter: 384/778
[A[ATraining Step: 713  | total loss: [1m[32m0.09848[0m[0m | time: 16.000s
[2K
| RMSProp | epoch: 029 | loss: 0.09848 - acc: 0.9790 -- iter: 416/778
[A[ATraining Step: 714  | total loss: [1m[32m0.08891[0m[0m | time: 17.388s
[2K
| RMSProp | epoch: 029 | loss: 0.08891 - acc: 0.9811 -- iter: 448/778
[A[ATraining Step: 715  | total loss: [1m[32m0.08045[0m[0m | time: 18.762s
[2K
| RMSProp | epoch: 029 | loss: 0.08045 - acc: 0.9830 -- iter: 480/778
[A[ATraining Step: 716  | total loss: [1m[32m0.08183[0m[0m | time: 19.883s
[2K
| RMSProp | epoch: 029 | loss: 0.08183 - acc: 0.9816 -- iter: 512/778
[A[ATraining Step: 717  | total loss: [1m[32m0.07475[0m[0m | time: 21.179s
[2K
| RMSProp | epoch: 029 | loss: 0.07475 - acc: 0.9834 -- iter: 544/778
[A[ATraining Step: 718  | total loss: [1m[32m0.06738[0m[0m | time: 22.600s
[2K
| RMSProp | epoch: 029 | loss: 0.06738 - acc: 0.9851 -- iter: 576/778
[A[ATraining Step: 719  | total loss: [1m[32m0.06120[0m[0m | time: 23.882s
[2K
| RMSProp | epoch: 029 | loss: 0.06120 - acc: 0.9866 -- iter: 608/778
[A[ATraining Step: 720  | total loss: [1m[32m0.05554[0m[0m | time: 25.298s
[2K
| RMSProp | epoch: 029 | loss: 0.05554 - acc: 0.9879 -- iter: 640/778
[A[ATraining Step: 721  | total loss: [1m[32m0.05532[0m[0m | time: 26.831s
[2K
| RMSProp | epoch: 029 | loss: 0.05532 - acc: 0.9860 -- iter: 672/778
[A[ATraining Step: 722  | total loss: [1m[32m0.08926[0m[0m | time: 28.373s
[2K
| RMSProp | epoch: 029 | loss: 0.08926 - acc: 0.9718 -- iter: 704/778
[A[ATraining Step: 723  | total loss: [1m[32m0.14389[0m[0m | time: 29.717s
[2K
| RMSProp | epoch: 029 | loss: 0.14389 - acc: 0.9527 -- iter: 736/778
[A[ATraining Step: 724  | total loss: [1m[32m0.13528[0m[0m | time: 30.992s
[2K
| RMSProp | epoch: 029 | loss: 0.13528 - acc: 0.9575 -- iter: 768/778
[A[ATraining Step: 725  | total loss: [1m[32m0.12241[0m[0m | time: 34.396s
[2K
| RMSProp | epoch: 029 | loss: 0.12241 - acc: 0.9617 | val_loss: 0.46362 - val_acc: 0.8648 -- iter: 778/778
--
Training Step: 726  | total loss: [1m[32m0.11141[0m[0m | time: 1.078s
[2K
| RMSProp | epoch: 030 | loss: 0.11141 - acc: 0.9655 -- iter: 032/778
[A[ATraining Step: 727  | total loss: [1m[32m0.10088[0m[0m | time: 1.566s
[2K
| RMSProp | epoch: 030 | loss: 0.10088 - acc: 0.9690 -- iter: 064/778
[A[ATraining Step: 728  | total loss: [1m[32m0.09148[0m[0m | time: 2.022s
[2K
| RMSProp | epoch: 030 | loss: 0.09148 - acc: 0.9721 -- iter: 096/778
[A[ATraining Step: 729  | total loss: [1m[32m0.08266[0m[0m | time: 3.364s
[2K
| RMSProp | epoch: 030 | loss: 0.08266 - acc: 0.9749 -- iter: 128/778
[A[ATraining Step: 730  | total loss: [1m[32m0.07466[0m[0m | time: 4.791s
[2K
| RMSProp | epoch: 030 | loss: 0.07466 - acc: 0.9774 -- iter: 160/778
[A[ATraining Step: 731  | total loss: [1m[32m0.07218[0m[0m | time: 6.214s
[2K
| RMSProp | epoch: 030 | loss: 0.07218 - acc: 0.9765 -- iter: 192/778
[A[ATraining Step: 732  | total loss: [1m[32m0.07316[0m[0m | time: 7.635s
[2K
| RMSProp | epoch: 030 | loss: 0.07316 - acc: 0.9757 -- iter: 224/778
[A[ATraining Step: 733  | total loss: [1m[32m0.06629[0m[0m | time: 9.152s
[2K
| RMSProp | epoch: 030 | loss: 0.06629 - acc: 0.9782 -- iter: 256/778
[A[ATraining Step: 734  | total loss: [1m[32m0.05997[0m[0m | time: 10.511s
[2K
| RMSProp | epoch: 030 | loss: 0.05997 - acc: 0.9804 -- iter: 288/778
[A[ATraining Step: 735  | total loss: [1m[32m0.05420[0m[0m | time: 11.669s
[2K
| RMSProp | epoch: 030 | loss: 0.05420 - acc: 0.9823 -- iter: 320/778
[A[ATraining Step: 736  | total loss: [1m[32m0.04890[0m[0m | time: 13.121s
[2K
| RMSProp | epoch: 030 | loss: 0.04890 - acc: 0.9841 -- iter: 352/778
[A[ATraining Step: 737  | total loss: [1m[32m0.04441[0m[0m | time: 14.593s
[2K
| RMSProp | epoch: 030 | loss: 0.04441 - acc: 0.9857 -- iter: 384/778
[A[ATraining Step: 738  | total loss: [1m[32m0.04621[0m[0m | time: 16.018s
[2K
| RMSProp | epoch: 030 | loss: 0.04621 - acc: 0.9840 -- iter: 416/778
[A[ATraining Step: 739  | total loss: [1m[32m0.05233[0m[0m | time: 17.271s
[2K
| RMSProp | epoch: 030 | loss: 0.05233 - acc: 0.9793 -- iter: 448/778
[A[ATraining Step: 740  | total loss: [1m[32m0.04904[0m[0m | time: 18.582s
[2K
| RMSProp | epoch: 030 | loss: 0.04904 - acc: 0.9814 -- iter: 480/778
[A[ATraining Step: 741  | total loss: [1m[32m0.04474[0m[0m | time: 19.956s
[2K
| RMSProp | epoch: 030 | loss: 0.04474 - acc: 0.9833 -- iter: 512/778
[A[ATraining Step: 742  | total loss: [1m[32m0.04093[0m[0m | time: 21.260s
[2K
| RMSProp | epoch: 030 | loss: 0.04093 - acc: 0.9849 -- iter: 544/778
[A[ATraining Step: 743  | total loss: [1m[32m0.03713[0m[0m | time: 22.686s
[2K
| RMSProp | epoch: 030 | loss: 0.03713 - acc: 0.9864 -- iter: 576/778
[A[ATraining Step: 744  | total loss: [1m[32m0.03360[0m[0m | time: 24.152s
[2K
| RMSProp | epoch: 030 | loss: 0.03360 - acc: 0.9878 -- iter: 608/778
[A[ATraining Step: 745  | total loss: [1m[32m0.03041[0m[0m | time: 25.734s
[2K
| RMSProp | epoch: 030 | loss: 0.03041 - acc: 0.9890 -- iter: 640/778
[A[ATraining Step: 746  | total loss: [1m[32m0.02750[0m[0m | time: 27.046s
[2K
| RMSProp | epoch: 030 | loss: 0.02750 - acc: 0.9901 -- iter: 672/778
[A[ATraining Step: 747  | total loss: [1m[32m0.02488[0m[0m | time: 28.212s
[2K
| RMSProp | epoch: 030 | loss: 0.02488 - acc: 0.9911 -- iter: 704/778
[A[ATraining Step: 748  | total loss: [1m[32m0.04334[0m[0m | time: 29.718s
[2K
| RMSProp | epoch: 030 | loss: 0.04334 - acc: 0.9889 -- iter: 736/778
[A[ATraining Step: 749  | total loss: [1m[32m0.03948[0m[0m | time: 31.169s
[2K
| RMSProp | epoch: 030 | loss: 0.03948 - acc: 0.9900 -- iter: 768/778
[A[ATraining Step: 750  | total loss: [1m[32m0.05237[0m[0m | time: 34.419s
[2K
| RMSProp | epoch: 030 | loss: 0.05237 - acc: 0.9816 | val_loss: 0.36798 - val_acc: 0.8811 -- iter: 778/778
--
Validation AUC:0.9317341933749916
Validation AUPRC:0.9455629447521265
Test AUC:0.9625747497144392
Test AUPRC:0.9713344258934559
BestTestF1Score	0.9	0.8	0.9	0.92	0.89	109	10	111	14	0.21
BestTestMCCScore	0.9	0.8	0.9	0.92	0.88	108	10	111	15	0.23
BestTestAccuracyScore	0.9	0.8	0.9	0.92	0.88	108	10	111	15	0.23
BestValidationF1Score	0.89	0.79	0.89	0.9	0.88	107	12	111	14	0.21
BestValidationMCC	0.89	0.79	0.89	0.91	0.88	106	11	112	15	0.23
BestValidationAccuracy	0.89	0.79	0.89	0.91	0.88	106	11	112	15	0.23
TestPredictions (Threshold:0.23)
CHEMBL158078,TN,INACT,0.0	CHEMBL358232,TN,INACT,0.009999999776482582	CHEMBL274298,TN,INACT,0.019999999552965164	CHEMBL3098251,TN,INACT,0.009999999776482582	CHEMBL3679638,TP,ACT,0.8100000023841858	CHEMBL473531,TP,ACT,0.8999999761581421	CHEMBL1098359,TN,INACT,0.09000000357627869	CHEMBL2180498,TP,ACT,0.4300000071525574	CHEMBL3394008,TN,INACT,0.019999999552965164	CHEMBL69659,FN,ACT,0.10999999940395355	CHEMBL2436716,TN,INACT,0.03999999910593033	CHEMBL34732,TP,ACT,0.949999988079071	CHEMBL2205809,TP,ACT,0.9100000262260437	CHEMBL423734,FN,ACT,0.07999999821186066	CHEMBL255338,TP,ACT,0.9900000095367432	CHEMBL2398742,TP,ACT,0.9300000071525574	CHEMBL39879,TN,INACT,0.019999999552965164	CHEMBL426385,TN,INACT,0.0	CHEMBL202463,TN,INACT,0.019999999552965164	CHEMBL2322845,TP,ACT,0.9800000190734863	CHEMBL2207080,FN,ACT,0.11999999731779099	CHEMBL1090509,TN,INACT,0.0	CHEMBL3679656,TP,ACT,0.3700000047683716	CHEMBL540896,TN,INACT,0.019999999552965164	CHEMBL1224189,FN,ACT,0.20999999344348907	CHEMBL108417,TN,INACT,0.019999999552965164	CHEMBL2322850,TP,ACT,0.9700000286102295	CHEMBL555990,TN,INACT,0.0	CHEMBL3679653,TP,ACT,0.9100000262260437	CHEMBL69123,TP,ACT,0.4300000071525574	CHEMBL2322863,TP,ACT,0.7900000214576721	CHEMBL99331,TN,INACT,0.029999999329447746	CHEMBL1916635,TN,INACT,0.009999999776482582	CHEMBL2436815,TN,INACT,0.009999999776482582	CHEMBL2322852,TP,ACT,0.9800000190734863	CHEMBL285703,FN,ACT,0.07000000029802322	CHEMBL266077,TN,INACT,0.10000000149011612	CHEMBL61627,FP,INACT,0.8600000143051147	CHEMBL250713,TN,INACT,0.0	CHEMBL185283,TN,INACT,0.019999999552965164	CHEMBL240001,TN,INACT,0.05000000074505806	CHEMBL308911,TN,INACT,0.019999999552965164	CHEMBL3809189,TN,INACT,0.0	CHEMBL365889,TN,INACT,0.009999999776482582	CHEMBL326379,TN,INACT,0.009999999776482582	CHEMBL1076554,TN,INACT,0.019999999552965164	CHEMBL71499,FN,ACT,0.07999999821186066	CHEMBL291432,TN,INACT,0.019999999552965164	CHEMBL245319,TN,INACT,0.0	CHEMBL3334815,TP,ACT,0.9800000190734863	CHEMBL184582,TN,INACT,0.05999999865889549	CHEMBL344989,TP,ACT,0.9399999976158142	CHEMBL441188,TN,INACT,0.019999999552965164	CHEMBL1224118,TP,ACT,0.8700000047683716	CHEMBL2180191,TP,ACT,0.8799999952316284	CHEMBL462441,TP,ACT,0.9100000262260437	CHEMBL2180538,TP,ACT,0.9800000190734863	CHEMBL2391803,TP,ACT,0.9900000095367432	CHEMBL3394774,TN,INACT,0.019999999552965164	CHEMBL3287831,TN,INACT,0.0	CHEMBL2398745,TP,ACT,0.9700000286102295	CHEMBL156415,TN,INACT,0.009999999776482582	CHEMBL1813663,TN,INACT,0.009999999776482582	CHEMBL232042,TP,ACT,0.9800000190734863	CHEMBL2391794,TP,ACT,0.9900000095367432	CHEMBL109094,TN,INACT,0.019999999552965164	CHEMBL188170,TN,INACT,0.029999999329447746	CHEMBL361121,FP,INACT,0.23000000417232513	CHEMBL2322871,TP,ACT,0.8999999761581421	CHEMBL2180533,TP,ACT,0.9900000095367432	CHEMBL2332933,TP,ACT,0.9900000095367432	CHEMBL2180531,TP,ACT,0.9900000095367432	CHEMBL249723,TN,INACT,0.009999999776482582	CHEMBL270358,TP,ACT,1.0	CHEMBL187237,TN,INACT,0.18000000715255737	CHEMBL191,TN,INACT,0.019999999552965164	CHEMBL2436816,TN,INACT,0.0	CHEMBL2322843,TP,ACT,0.9399999976158142	CHEMBL344499,FN,ACT,0.0	CHEMBL145106,TP,ACT,1.0	CHEMBL2180499,TP,ACT,0.8999999761581421	CHEMBL95727,TN,INACT,0.019999999552965164	CHEMBL109786,TN,INACT,0.019999999552965164	CHEMBL420924,FN,ACT,0.029999999329447746	CHEMBL304845,TP,ACT,0.8799999952316284	CHEMBL536800,TN,INACT,0.019999999552965164	CHEMBL2180500,TP,ACT,0.5	CHEMBL257853,TP,ACT,0.7799999713897705	CHEMBL3218124,TN,INACT,0.029999999329447746	CHEMBL308209,TP,ACT,0.9100000262260437	CHEMBL2322882,TP,ACT,0.9200000166893005	CHEMBL2180535,TP,ACT,0.9800000190734863	CHEMBL234081,TP,ACT,0.9599999785423279	CHEMBL12190,FP,INACT,0.3499999940395355	CHEMBL3393993,TN,INACT,0.009999999776482582	CHEMBL3099957,TP,ACT,0.9800000190734863	CHEMBL187856,FP,INACT,0.800000011920929	CHEMBL2398724,TP,ACT,0.9800000190734863	CHEMBL3589940,TN,INACT,0.009999999776482582	CHEMBL69735,TP,ACT,0.8899999856948853	CHEMBL2436825,TN,INACT,0.03999999910593033	CHEMBL2180505,TP,ACT,0.9800000190734863	CHEMBL2207097,TP,ACT,0.9700000286102295	CHEMBL233552,TN,INACT,0.05000000074505806	CHEMBL2180539,TP,ACT,0.9800000190734863	CHEMBL173708,TN,INACT,0.009999999776482582	CHEMBL3604305,TN,INACT,0.009999999776482582	CHEMBL305423,TP,ACT,0.8299999833106995	CHEMBL2322889,TP,ACT,0.9700000286102295	CHEMBL1623498,TN,INACT,0.07999999821186066	CHEMBL293195,TN,INACT,0.07999999821186066	CHEMBL233042,FN,ACT,0.09000000357627869	CHEMBL2112830,FN,ACT,0.0	CHEMBL1907720,TN,INACT,0.0	CHEMBL2163918,TN,INACT,0.09000000357627869	CHEMBL69025,FP,INACT,0.8999999761581421	CHEMBL2398733,TP,ACT,0.9800000190734863	CHEMBL185282,FP,INACT,0.23000000417232513	CHEMBL2398738,TP,ACT,0.9300000071525574	CHEMBL333422,TP,ACT,0.9800000190734863	CHEMBL3650386,TN,INACT,0.009999999776482582	CHEMBL3665441,TN,INACT,0.09000000357627869	CHEMBL228686,TN,INACT,0.0	CHEMBL502593,TN,INACT,0.009999999776482582	CHEMBL310425,TN,INACT,0.0	CHEMBL400382,TN,INACT,0.18000000715255737	CHEMBL142161,TP,ACT,0.9700000286102295	CHEMBL411476,TP,ACT,0.9900000095367432	CHEMBL2180532,TP,ACT,0.9800000190734863	CHEMBL408493,TN,INACT,0.029999999329447746	CHEMBL2442635,TN,INACT,0.019999999552965164	CHEMBL28337,TN,INACT,0.0	CHEMBL141829,TP,ACT,0.9599999785423279	CHEMBL258361,TP,ACT,0.9900000095367432	CHEMBL215131,TN,INACT,0.019999999552965164	CHEMBL2322867,TP,ACT,0.9800000190734863	CHEMBL2398750,FN,ACT,0.07999999821186066	CHEMBL9746,TN,INACT,0.019999999552965164	CHEMBL2322861,TP,ACT,0.8999999761581421	CHEMBL69978,TP,ACT,0.9200000166893005	CHEMBL351508,TN,INACT,0.029999999329447746	CHEMBL71903,TP,ACT,0.8600000143051147	CHEMBL269957,TP,ACT,1.0	CHEMBL2322876,TP,ACT,0.9700000286102295	CHEMBL424324,TN,INACT,0.0	CHEMBL2436720,TN,INACT,0.009999999776482582	CHEMBL249894,TN,INACT,0.019999999552965164	CHEMBL2391812,TP,ACT,0.9900000095367432	CHEMBL143690,TP,ACT,0.9800000190734863	CHEMBL2426670,TN,INACT,0.009999999776482582	CHEMBL232252,TP,ACT,0.9300000071525574	CHEMBL3810125,TN,INACT,0.009999999776482582	CHEMBL2180501,TP,ACT,0.9300000071525574	CHEMBL2112592,TN,INACT,0.05000000074505806	CHEMBL433232,FN,ACT,0.029999999329447746	CHEMBL1907930,TN,INACT,0.0	CHEMBL234606,TP,ACT,0.8899999856948853	CHEMBL2398716,TP,ACT,0.9700000286102295	CHEMBL3810142,TN,INACT,0.019999999552965164	CHEMBL2180527,TP,ACT,0.9100000262260437	CHEMBL3326905,TN,INACT,0.029999999329447746	CHEMBL2180510,TP,ACT,0.9900000095367432	CHEMBL2180508,TP,ACT,0.9800000190734863	CHEMBL2322878,TP,ACT,0.9300000071525574	CHEMBL337269,TN,INACT,0.0	CHEMBL307614,TN,INACT,0.0	CHEMBL2207089,TP,ACT,0.6700000166893005	CHEMBL2391938,TP,ACT,0.9900000095367432	CHEMBL108426,TN,INACT,0.03999999910593033	CHEMBL3665436,TN,INACT,0.009999999776482582	CHEMBL289682,TP,ACT,0.9300000071525574	CHEMBL3099945,TP,ACT,0.9900000095367432	CHEMBL258360,TP,ACT,0.9900000095367432	CHEMBL270563,TP,ACT,0.9900000095367432	CHEMBL18797,TN,INACT,0.009999999776482582	CHEMBL2322893,FP,INACT,0.8299999833106995	CHEMBL2180187,TP,ACT,1.0	CHEMBL440061,TN,INACT,0.009999999776482582	CHEMBL68937,TP,ACT,0.7599999904632568	CHEMBL2180506,TP,ACT,0.9800000190734863	CHEMBL341306,TP,ACT,0.8899999856948853	CHEMBL3334726,TP,ACT,0.9800000190734863	CHEMBL44463,TN,INACT,0.0	CHEMBL402825,TP,ACT,0.9399999976158142	CHEMBL2391807,TP,ACT,0.9900000095367432	CHEMBL303247,TN,INACT,0.0	CHEMBL101706,TN,INACT,0.019999999552965164	CHEMBL101165,FN,ACT,0.05000000074505806	CHEMBL416788,TN,INACT,0.019999999552965164	CHEMBL3394775,FP,INACT,0.3199999928474426	CHEMBL3334824,TP,ACT,0.9399999976158142	CHEMBL2332934,TP,ACT,0.9800000190734863	CHEMBL321644,TN,INACT,0.07999999821186066	CHEMBL552615,TN,INACT,0.05000000074505806	CHEMBL3099944,TP,ACT,0.9900000095367432	CHEMBL1080153,TN,INACT,0.009999999776482582	CHEMBL2442640,TN,INACT,0.009999999776482582	CHEMBL2180522,TP,ACT,0.9599999785423279	CHEMBL608813,TN,INACT,0.029999999329447746	CHEMBL2322875,TP,ACT,0.9800000190734863	CHEMBL142925,TP,ACT,0.6899999976158142	CHEMBL3809230,TN,INACT,0.0	CHEMBL2322854,TP,ACT,0.9599999785423279	CHEMBL2369493,TN,INACT,0.03999999910593033	CHEMBL378173,TN,INACT,0.05000000074505806	CHEMBL400677,TN,INACT,0.009999999776482582	CHEMBL2322884,TP,ACT,0.8500000238418579	CHEMBL608831,TN,INACT,0.03999999910593033	CHEMBL473734,TP,ACT,0.8999999761581421	CHEMBL296245,TN,INACT,0.0	CHEMBL2207087,FN,ACT,0.2199999988079071	CHEMBL2158005,FP,INACT,0.7799999713897705	CHEMBL112637,TN,INACT,0.009999999776482582	CHEMBL2442636,TN,INACT,0.029999999329447746	CHEMBL545363,TN,INACT,0.05000000074505806	CHEMBL2398771,TP,ACT,0.9800000190734863	CHEMBL391238,TP,ACT,0.8100000023841858	CHEMBL287374,TN,INACT,0.0	CHEMBL3679641,TP,ACT,0.9900000095367432	CHEMBL11629,TN,INACT,0.10000000149011612	CHEMBL469856,TN,INACT,0.05000000074505806	CHEMBL509457,TP,ACT,0.9599999785423279	CHEMBL151976,TN,INACT,0.14000000059604645	CHEMBL2322869,TP,ACT,0.8799999952316284	CHEMBL462644,TP,ACT,0.8500000238418579	CHEMBL78137,FP,INACT,0.2800000011920929	CHEMBL3809333,TN,INACT,0.0	CHEMBL2322868,TP,ACT,0.9800000190734863	CHEMBL404465,TP,ACT,0.9800000190734863	CHEMBL3679655,FN,ACT,0.05000000074505806	CHEMBL3099950,TP,ACT,0.9900000095367432	CHEMBL234263,TP,ACT,0.9399999976158142	CHEMBL256271,TP,ACT,1.0	CHEMBL358283,TP,ACT,0.8500000238418579	CHEMBL25528,TN,INACT,0.0	CHEMBL2391804,TP,ACT,0.9900000095367432	CHEMBL98760,TN,INACT,0.009999999776482582	CHEMBL142811,TN,INACT,0.019999999552965164	CHEMBL3650378,TN,INACT,0.029999999329447746	CHEMBL2398734,TP,ACT,0.949999988079071	CHEMBL295849,TN,INACT,0.0	CHEMBL2398729,TP,ACT,0.9900000095367432	CHEMBL524026,TN,INACT,0.019999999552965164	CHEMBL104,TN,INACT,0.019999999552965164	

