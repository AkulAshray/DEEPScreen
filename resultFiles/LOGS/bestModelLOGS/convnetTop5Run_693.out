ImageNetInceptionV2 CHEMBL4235 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	327
Number of inactive compounds :	218
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4235_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4235_adam_0.001_15_0.8/
---------------------------------
Training samples: 348
Validation samples: 109
--
Training Step: 1  | time: 62.029s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/348
[A[ATraining Step: 2  | total loss: [1m[32m0.58608[0m[0m | time: 74.025s
[2K
| Adam | epoch: 001 | loss: 0.58608 - acc: 0.5625 -- iter: 064/348
[A[ATraining Step: 3  | total loss: [1m[32m0.53978[0m[0m | time: 86.128s
[2K
| Adam | epoch: 001 | loss: 0.53978 - acc: 0.7415 -- iter: 096/348
[A[ATraining Step: 4  | total loss: [1m[32m0.46395[0m[0m | time: 98.005s
[2K
| Adam | epoch: 001 | loss: 0.46395 - acc: 0.8182 -- iter: 128/348
[A[ATraining Step: 5  | total loss: [1m[32m0.90367[0m[0m | time: 109.790s
[2K
| Adam | epoch: 001 | loss: 0.90367 - acc: 0.6628 -- iter: 160/348
[A[ATraining Step: 6  | total loss: [1m[32m0.82654[0m[0m | time: 121.631s
[2K
| Adam | epoch: 001 | loss: 0.82654 - acc: 0.6184 -- iter: 192/348
[A[ATraining Step: 7  | total loss: [1m[32m0.66635[0m[0m | time: 133.300s
[2K
| Adam | epoch: 001 | loss: 0.66635 - acc: 0.7161 -- iter: 224/348
[A[ATraining Step: 8  | total loss: [1m[32m0.66827[0m[0m | time: 145.429s
[2K
| Adam | epoch: 001 | loss: 0.66827 - acc: 0.6473 -- iter: 256/348
[A[ATraining Step: 9  | total loss: [1m[32m0.57873[0m[0m | time: 157.348s
[2K
| Adam | epoch: 001 | loss: 0.57873 - acc: 0.7182 -- iter: 288/348
[A[ATraining Step: 10  | total loss: [1m[32m0.55143[0m[0m | time: 169.051s
[2K
| Adam | epoch: 001 | loss: 0.55143 - acc: 0.7341 -- iter: 320/348
[A[ATraining Step: 11  | total loss: [1m[32m0.61912[0m[0m | time: 199.427s
[2K
| Adam | epoch: 001 | loss: 0.61912 - acc: 0.7120 | val_loss: 1.27642 - val_acc: 0.6330 -- iter: 348/348
--
Training Step: 12  | total loss: [1m[32m0.61422[0m[0m | time: 10.666s
[2K
| Adam | epoch: 002 | loss: 0.61422 - acc: 0.6809 -- iter: 032/348
[A[ATraining Step: 13  | total loss: [1m[32m0.58373[0m[0m | time: 22.554s
[2K
| Adam | epoch: 002 | loss: 0.58373 - acc: 0.6952 -- iter: 064/348
[A[ATraining Step: 14  | total loss: [1m[32m0.57904[0m[0m | time: 34.138s
[2K
| Adam | epoch: 002 | loss: 0.57904 - acc: 0.7048 -- iter: 096/348
[A[ATraining Step: 15  | total loss: [1m[32m0.52862[0m[0m | time: 46.075s
[2K
| Adam | epoch: 002 | loss: 0.52862 - acc: 0.7837 -- iter: 128/348
[A[ATraining Step: 16  | total loss: [1m[32m0.60051[0m[0m | time: 58.028s
[2K
| Adam | epoch: 002 | loss: 0.60051 - acc: 0.7242 -- iter: 160/348
[A[ATraining Step: 17  | total loss: [1m[32m0.59845[0m[0m | time: 70.230s
[2K
| Adam | epoch: 002 | loss: 0.59845 - acc: 0.7110 -- iter: 192/348
[A[ATraining Step: 18  | total loss: [1m[32m0.55144[0m[0m | time: 82.481s
[2K
| Adam | epoch: 002 | loss: 0.55144 - acc: 0.7461 -- iter: 224/348
[A[ATraining Step: 19  | total loss: [1m[32m0.51620[0m[0m | time: 94.194s
[2K
| Adam | epoch: 002 | loss: 0.51620 - acc: 0.7787 -- iter: 256/348
[A[ATraining Step: 20  | total loss: [1m[32m0.47066[0m[0m | time: 105.903s
[2K
| Adam | epoch: 002 | loss: 0.47066 - acc: 0.8297 -- iter: 288/348
[A[ATraining Step: 21  | total loss: [1m[32m0.47429[0m[0m | time: 117.742s
[2K
| Adam | epoch: 002 | loss: 0.47429 - acc: 0.8147 -- iter: 320/348
[A[ATraining Step: 22  | total loss: [1m[32m0.46823[0m[0m | time: 138.034s
[2K
| Adam | epoch: 002 | loss: 0.46823 - acc: 0.8046 | val_loss: 1.23926 - val_acc: 0.6330 -- iter: 348/348
--
Training Step: 23  | total loss: [1m[32m0.50364[0m[0m | time: 10.399s
[2K
| Adam | epoch: 003 | loss: 0.50364 - acc: 0.7797 -- iter: 032/348
[A[ATraining Step: 24  | total loss: [1m[32m0.49229[0m[0m | time: 21.418s
[2K
| Adam | epoch: 003 | loss: 0.49229 - acc: 0.7914 -- iter: 064/348
[A[ATraining Step: 25  | total loss: [1m[32m0.43951[0m[0m | time: 32.891s
[2K
| Adam | epoch: 003 | loss: 0.43951 - acc: 0.8288 -- iter: 096/348
[A[ATraining Step: 26  | total loss: [1m[32m0.41668[0m[0m | time: 44.714s
[2K
| Adam | epoch: 003 | loss: 0.41668 - acc: 0.8245 -- iter: 128/348
[A[ATraining Step: 27  | total loss: [1m[32m0.43594[0m[0m | time: 56.704s
[2K
| Adam | epoch: 003 | loss: 0.43594 - acc: 0.8134 -- iter: 160/348
[A[ATraining Step: 28  | total loss: [1m[32m0.43524[0m[0m | time: 68.461s
[2K
| Adam | epoch: 003 | loss: 0.43524 - acc: 0.8054 -- iter: 192/348
[A[ATraining Step: 29  | total loss: [1m[32m0.41234[0m[0m | time: 80.812s
[2K
| Adam | epoch: 003 | loss: 0.41234 - acc: 0.8147 -- iter: 224/348
[A[ATraining Step: 30  | total loss: [1m[32m0.39264[0m[0m | time: 93.772s
[2K
| Adam | epoch: 003 | loss: 0.39264 - acc: 0.8142 -- iter: 256/348
[A[ATraining Step: 31  | total loss: [1m[32m0.36230[0m[0m | time: 106.602s
[2K
| Adam | epoch: 003 | loss: 0.36230 - acc: 0.8354 -- iter: 288/348
[A[ATraining Step: 32  | total loss: [1m[32m0.37175[0m[0m | time: 117.877s
[2K
| Adam | epoch: 003 | loss: 0.37175 - acc: 0.8303 -- iter: 320/348
[A[ATraining Step: 33  | total loss: [1m[32m0.38442[0m[0m | time: 130.591s
[2K
| Adam | epoch: 003 | loss: 0.38442 - acc: 0.8264 | val_loss: 7.11023 - val_acc: 0.3670 -- iter: 348/348
--
Training Step: 34  | total loss: [1m[32m0.35995[0m[0m | time: 11.840s
[2K
| Adam | epoch: 004 | loss: 0.35995 - acc: 0.8435 -- iter: 032/348
[A[ATraining Step: 35  | total loss: [1m[32m0.32664[0m[0m | time: 23.006s
[2K
| Adam | epoch: 004 | loss: 0.32664 - acc: 0.8632 -- iter: 064/348
[A[ATraining Step: 36  | total loss: [1m[32m0.35557[0m[0m | time: 33.984s
[2K
| Adam | epoch: 004 | loss: 0.35557 - acc: 0.8473 -- iter: 096/348
[A[ATraining Step: 37  | total loss: [1m[32m0.32222[0m[0m | time: 45.758s
[2K
| Adam | epoch: 004 | loss: 0.32222 - acc: 0.8707 -- iter: 128/348
[A[ATraining Step: 38  | total loss: [1m[32m0.30465[0m[0m | time: 57.918s
[2K
| Adam | epoch: 004 | loss: 0.30465 - acc: 0.8654 -- iter: 160/348
[A[ATraining Step: 39  | total loss: [1m[32m0.36132[0m[0m | time: 70.348s
[2K
| Adam | epoch: 004 | loss: 0.36132 - acc: 0.8553 -- iter: 192/348
[A[ATraining Step: 40  | total loss: [1m[32m0.39476[0m[0m | time: 83.219s
[2K
| Adam | epoch: 004 | loss: 0.39476 - acc: 0.8297 -- iter: 224/348
[A[ATraining Step: 41  | total loss: [1m[32m0.34891[0m[0m | time: 95.847s
[2K
| Adam | epoch: 004 | loss: 0.34891 - acc: 0.8552 -- iter: 256/348
[A[ATraining Step: 42  | total loss: [1m[32m0.35066[0m[0m | time: 109.351s
[2K
| Adam | epoch: 004 | loss: 0.35066 - acc: 0.8419 -- iter: 288/348
[A[ATraining Step: 43  | total loss: [1m[32m0.30321[0m[0m | time: 120.204s
[2K
| Adam | epoch: 004 | loss: 0.30321 - acc: 0.8698 -- iter: 320/348
[A[ATraining Step: 44  | total loss: [1m[32m0.27000[0m[0m | time: 141.068s
[2K
| Adam | epoch: 004 | loss: 0.27000 - acc: 0.8869 | val_loss: 3.50160 - val_acc: 0.4128 -- iter: 348/348
--
Training Step: 45  | total loss: [1m[32m0.25992[0m[0m | time: 14.887s
[2K
| Adam | epoch: 005 | loss: 0.25992 - acc: 0.8955 -- iter: 032/348
[A[ATraining Step: 46  | total loss: [1m[32m0.25983[0m[0m | time: 29.961s
[2K
| Adam | epoch: 005 | loss: 0.25983 - acc: 0.8973 -- iter: 064/348
[A[ATraining Step: 47  | total loss: [1m[32m0.26309[0m[0m | time: 43.824s
[2K
| Adam | epoch: 005 | loss: 0.26309 - acc: 0.8885 -- iter: 096/348
[A[ATraining Step: 48  | total loss: [1m[32m0.24208[0m[0m | time: 56.776s
[2K
| Adam | epoch: 005 | loss: 0.24208 - acc: 0.8950 -- iter: 128/348
[A[ATraining Step: 49  | total loss: [1m[32m0.21707[0m[0m | time: 71.056s
[2K
| Adam | epoch: 005 | loss: 0.21707 - acc: 0.9116 -- iter: 160/348
[A[ATraining Step: 50  | total loss: [1m[32m0.23531[0m[0m | time: 85.598s
[2K
| Adam | epoch: 005 | loss: 0.23531 - acc: 0.8913 -- iter: 192/348
[A[ATraining Step: 51  | total loss: [1m[32m0.25021[0m[0m | time: 99.908s
[2K
| Adam | epoch: 005 | loss: 0.25021 - acc: 0.8936 -- iter: 224/348
[A[ATraining Step: 52  | total loss: [1m[32m0.30334[0m[0m | time: 114.100s
[2K
| Adam | epoch: 005 | loss: 0.30334 - acc: 0.8814 -- iter: 256/348
[A[ATraining Step: 53  | total loss: [1m[32m0.28165[0m[0m | time: 128.871s
[2K
| Adam | epoch: 005 | loss: 0.28165 - acc: 0.8989 -- iter: 288/348
[A[ATraining Step: 54  | total loss: [1m[32m0.26615[0m[0m | time: 143.839s
[2K
| Adam | epoch: 005 | loss: 0.26615 - acc: 0.9091 -- iter: 320/348
[A[ATraining Step: 55  | total loss: [1m[32m0.24664[0m[0m | time: 168.457s
[2K
| Adam | epoch: 005 | loss: 0.24664 - acc: 0.9176 | val_loss: 0.79561 - val_acc: 0.7706 -- iter: 348/348
--
Training Step: 56  | total loss: [1m[32m0.24244[0m[0m | time: 14.957s
[2K
| Adam | epoch: 006 | loss: 0.24244 - acc: 0.9160 -- iter: 032/348
[A[ATraining Step: 57  | total loss: [1m[32m0.24418[0m[0m | time: 29.498s
[2K
| Adam | epoch: 006 | loss: 0.24418 - acc: 0.9103 -- iter: 064/348
[A[ATraining Step: 58  | total loss: [1m[32m0.25047[0m[0m | time: 43.816s
[2K
| Adam | epoch: 006 | loss: 0.25047 - acc: 0.8970 -- iter: 096/348
[A[ATraining Step: 59  | total loss: [1m[32m0.22870[0m[0m | time: 56.999s
[2K
| Adam | epoch: 006 | loss: 0.22870 - acc: 0.9066 -- iter: 128/348
[A[ATraining Step: 60  | total loss: [1m[32m0.21621[0m[0m | time: 70.300s
[2K
| Adam | epoch: 006 | loss: 0.21621 - acc: 0.9143 -- iter: 160/348
[A[ATraining Step: 61  | total loss: [1m[32m0.19786[0m[0m | time: 85.142s
[2K
| Adam | epoch: 006 | loss: 0.19786 - acc: 0.9254 -- iter: 192/348
[A[ATraining Step: 62  | total loss: [1m[32m0.20477[0m[0m | time: 100.067s
[2K
| Adam | epoch: 006 | loss: 0.20477 - acc: 0.9190 -- iter: 224/348
[A[ATraining Step: 63  | total loss: [1m[32m0.20332[0m[0m | time: 114.651s
[2K
| Adam | epoch: 006 | loss: 0.20332 - acc: 0.9213 -- iter: 256/348
[A[ATraining Step: 64  | total loss: [1m[32m0.18825[0m[0m | time: 132.109s
[2K
| Adam | epoch: 006 | loss: 0.18825 - acc: 0.9272 -- iter: 288/348
[A[ATraining Step: 65  | total loss: [1m[32m0.17520[0m[0m | time: 150.226s
[2K
| Adam | epoch: 006 | loss: 0.17520 - acc: 0.9324 -- iter: 320/348
[A[ATraining Step: 66  | total loss: [1m[32m0.16835[0m[0m | time: 182.157s
[2K
| Adam | epoch: 006 | loss: 0.16835 - acc: 0.9368 | val_loss: 4.68921 - val_acc: 0.3670 -- iter: 348/348
--
Training Step: 67  | total loss: [1m[32m0.16896[0m[0m | time: 23.391s
[2K
| Adam | epoch: 007 | loss: 0.16896 - acc: 0.9331 -- iter: 032/348
[A[ATraining Step: 68  | total loss: [1m[32m0.16015[0m[0m | time: 46.082s
[2K
| Adam | epoch: 007 | loss: 0.16015 - acc: 0.9336 -- iter: 064/348
[A[ATraining Step: 69  | total loss: [1m[32m0.16542[0m[0m | time: 69.491s
[2K
| Adam | epoch: 007 | loss: 0.16542 - acc: 0.9304 -- iter: 096/348
[A[ATraining Step: 70  | total loss: [1m[32m0.16040[0m[0m | time: 91.853s
[2K
| Adam | epoch: 007 | loss: 0.16040 - acc: 0.9313 -- iter: 128/348
[A[ATraining Step: 71  | total loss: [1m[32m0.19127[0m[0m | time: 112.291s
[2K
| Adam | epoch: 007 | loss: 0.19127 - acc: 0.9248 -- iter: 160/348
[A[ATraining Step: 72  | total loss: [1m[32m0.21222[0m[0m | time: 136.737s
[2K
| Adam | epoch: 007 | loss: 0.21222 - acc: 0.9212 -- iter: 192/348
[A[ATraining Step: 73  | total loss: [1m[32m0.21276[0m[0m | time: 190.856s
[2K
| Adam | epoch: 007 | loss: 0.21276 - acc: 0.9260 -- iter: 224/348
[A[ATraining Step: 74  | total loss: [1m[32m0.20616[0m[0m | time: 227.942s
[2K
| Adam | epoch: 007 | loss: 0.20616 - acc: 0.9273 -- iter: 256/348
[A[ATraining Step: 75  | total loss: [1m[32m0.19624[0m[0m | time: 249.798s
[2K
| Adam | epoch: 007 | loss: 0.19624 - acc: 0.9318 -- iter: 288/348
[A[ATraining Step: 76  | total loss: [1m[32m0.21258[0m[0m | time: 270.504s
[2K
| Adam | epoch: 007 | loss: 0.21258 - acc: 0.9257 -- iter: 320/348
[A[ATraining Step: 77  | total loss: [1m[32m0.20596[0m[0m | time: 306.704s
[2K
| Adam | epoch: 007 | loss: 0.20596 - acc: 0.9269 | val_loss: 0.81530 - val_acc: 0.7248 -- iter: 348/348
--
Training Step: 78  | total loss: [1m[32m0.22347[0m[0m | time: 17.299s
[2K
| Adam | epoch: 008 | loss: 0.22347 - acc: 0.9215 -- iter: 032/348
[A[ATraining Step: 79  | total loss: [1m[32m0.22606[0m[0m | time: 33.814s
[2K
| Adam | epoch: 008 | loss: 0.22606 - acc: 0.9199 -- iter: 064/348
[A[ATraining Step: 80  | total loss: [1m[32m0.22303[0m[0m | time: 51.335s
[2K
| Adam | epoch: 008 | loss: 0.22303 - acc: 0.9217 -- iter: 096/348
[A[ATraining Step: 81  | total loss: [1m[32m0.23056[0m[0m | time: 69.838s
[2K
| Adam | epoch: 008 | loss: 0.23056 - acc: 0.9107 -- iter: 128/348
[A[ATraining Step: 82  | total loss: [1m[32m0.22429[0m[0m | time: 88.311s
[2K
| Adam | epoch: 008 | loss: 0.22429 - acc: 0.9165 -- iter: 160/348
[A[ATraining Step: 83  | total loss: [1m[32m0.21711[0m[0m | time: 105.359s
[2K
| Adam | epoch: 008 | loss: 0.21711 - acc: 0.9186 -- iter: 192/348
[A[ATraining Step: 84  | total loss: [1m[32m0.21326[0m[0m | time: 118.158s
[2K
| Adam | epoch: 008 | loss: 0.21326 - acc: 0.9160 -- iter: 224/348
[A[ATraining Step: 85  | total loss: [1m[32m0.20686[0m[0m | time: 130.086s
[2K
| Adam | epoch: 008 | loss: 0.20686 - acc: 0.9173 -- iter: 256/348
[A[ATraining Step: 86  | total loss: [1m[32m0.20536[0m[0m | time: 143.829s
[2K
| Adam | epoch: 008 | loss: 0.20536 - acc: 0.9162 -- iter: 288/348
[A[ATraining Step: 87  | total loss: [1m[32m0.19770[0m[0m | time: 161.217s
[2K
| Adam | epoch: 008 | loss: 0.19770 - acc: 0.9214 -- iter: 320/348
[A[ATraining Step: 88  | total loss: [1m[32m0.20841[0m[0m | time: 189.924s
[2K
| Adam | epoch: 008 | loss: 0.20841 - acc: 0.9230 | val_loss: 1.00770 - val_acc: 0.6330 -- iter: 348/348
--
Training Step: 89  | total loss: [1m[32m0.19445[0m[0m | time: 17.699s
[2K
| Adam | epoch: 009 | loss: 0.19445 - acc: 0.9307 -- iter: 032/348
[A[ATraining Step: 90  | total loss: [1m[32m0.19569[0m[0m | time: 35.535s
[2K
| Adam | epoch: 009 | loss: 0.19569 - acc: 0.9283 -- iter: 064/348
[A[ATraining Step: 91  | total loss: [1m[32m0.17997[0m[0m | time: 52.974s
[2K
| Adam | epoch: 009 | loss: 0.17997 - acc: 0.9355 -- iter: 096/348
[A[ATraining Step: 92  | total loss: [1m[32m0.16837[0m[0m | time: 70.982s
[2K
| Adam | epoch: 009 | loss: 0.16837 - acc: 0.9419 -- iter: 128/348
[A[ATraining Step: 93  | total loss: [1m[32m0.16455[0m[0m | time: 88.318s
[2K
| Adam | epoch: 009 | loss: 0.16455 - acc: 0.9415 -- iter: 160/348
[A[ATraining Step: 94  | total loss: [1m[32m0.15425[0m[0m | time: 105.005s
[2K
| Adam | epoch: 009 | loss: 0.15425 - acc: 0.9473 -- iter: 192/348
[A[ATraining Step: 95  | total loss: [1m[32m0.14596[0m[0m | time: 120.229s
[2K
| Adam | epoch: 009 | loss: 0.14596 - acc: 0.9495 -- iter: 224/348
[A[ATraining Step: 96  | total loss: [1m[32m0.13801[0m[0m | time: 136.442s
[2K
| Adam | epoch: 009 | loss: 0.13801 - acc: 0.9509 -- iter: 256/348
[A[ATraining Step: 97  | total loss: [1m[32m0.12697[0m[0m | time: 154.092s
[2K
| Adam | epoch: 009 | loss: 0.12697 - acc: 0.9559 -- iter: 288/348
[A[ATraining Step: 98  | total loss: [1m[32m0.12520[0m[0m | time: 171.595s
[2K
| Adam | epoch: 009 | loss: 0.12520 - acc: 0.9540 -- iter: 320/348
[A[ATraining Step: 99  | total loss: [1m[32m0.12052[0m[0m | time: 200.348s
[2K
| Adam | epoch: 009 | loss: 0.12052 - acc: 0.9555 | val_loss: 1.75991 - val_acc: 0.5413 -- iter: 348/348
--
Training Step: 100  | total loss: [1m[32m0.10922[0m[0m | time: 17.498s
[2K
| Adam | epoch: 010 | loss: 0.10922 - acc: 0.9599 -- iter: 032/348
[A[ATraining Step: 101  | total loss: [1m[32m0.10131[0m[0m | time: 34.800s
[2K
| Adam | epoch: 010 | loss: 0.10131 - acc: 0.9639 -- iter: 064/348
[A[ATraining Step: 102  | total loss: [1m[32m0.10245[0m[0m | time: 52.396s
[2K
| Adam | epoch: 010 | loss: 0.10245 - acc: 0.9613 -- iter: 096/348
[A[ATraining Step: 103  | total loss: [1m[32m0.11201[0m[0m | time: 69.840s
[2K
| Adam | epoch: 010 | loss: 0.11201 - acc: 0.9558 -- iter: 128/348
[A[ATraining Step: 104  | total loss: [1m[32m0.10234[0m[0m | time: 87.458s
[2K
| Adam | epoch: 010 | loss: 0.10234 - acc: 0.9602 -- iter: 160/348
[A[ATraining Step: 105  | total loss: [1m[32m0.09700[0m[0m | time: 104.927s
[2K
| Adam | epoch: 010 | loss: 0.09700 - acc: 0.9642 -- iter: 192/348
[A[ATraining Step: 106  | total loss: [1m[32m0.09133[0m[0m | time: 122.176s
[2K
| Adam | epoch: 010 | loss: 0.09133 - acc: 0.9647 -- iter: 224/348
[A[ATraining Step: 107  | total loss: [1m[32m0.08661[0m[0m | time: 137.783s
[2K
| Adam | epoch: 010 | loss: 0.08661 - acc: 0.9651 -- iter: 256/348
[A[ATraining Step: 108  | total loss: [1m[32m0.08655[0m[0m | time: 153.533s
[2K
| Adam | epoch: 010 | loss: 0.08655 - acc: 0.9650 -- iter: 288/348
[A[ATraining Step: 109  | total loss: [1m[32m0.08132[0m[0m | time: 170.775s
[2K
| Adam | epoch: 010 | loss: 0.08132 - acc: 0.9685 -- iter: 320/348
[A[ATraining Step: 110  | total loss: [1m[32m0.07672[0m[0m | time: 200.335s
[2K
| Adam | epoch: 010 | loss: 0.07672 - acc: 0.9716 | val_loss: 1.00923 - val_acc: 0.6972 -- iter: 348/348
--
Training Step: 111  | total loss: [1m[32m0.07093[0m[0m | time: 17.601s
[2K
| Adam | epoch: 011 | loss: 0.07093 - acc: 0.9745 -- iter: 032/348
[A[ATraining Step: 112  | total loss: [1m[32m0.06791[0m[0m | time: 35.583s
[2K
| Adam | epoch: 011 | loss: 0.06791 - acc: 0.9770 -- iter: 064/348
[A[ATraining Step: 113  | total loss: [1m[32m0.06970[0m[0m | time: 53.314s
[2K
| Adam | epoch: 011 | loss: 0.06970 - acc: 0.9762 -- iter: 096/348
[A[ATraining Step: 114  | total loss: [1m[32m0.06349[0m[0m | time: 72.024s
[2K
| Adam | epoch: 011 | loss: 0.06349 - acc: 0.9786 -- iter: 128/348
[A[ATraining Step: 115  | total loss: [1m[32m0.07376[0m[0m | time: 86.223s
[2K
| Adam | epoch: 011 | loss: 0.07376 - acc: 0.9713 -- iter: 160/348
[A[ATraining Step: 116  | total loss: [1m[32m0.06892[0m[0m | time: 100.904s
[2K
| Adam | epoch: 011 | loss: 0.06892 - acc: 0.9742 -- iter: 192/348
[A[ATraining Step: 117  | total loss: [1m[32m0.06272[0m[0m | time: 115.238s
[2K
| Adam | epoch: 011 | loss: 0.06272 - acc: 0.9768 -- iter: 224/348
[A[ATraining Step: 118  | total loss: [1m[32m0.06751[0m[0m | time: 129.586s
[2K
| Adam | epoch: 011 | loss: 0.06751 - acc: 0.9760 -- iter: 256/348
[A[ATraining Step: 119  | total loss: [1m[32m0.08734[0m[0m | time: 142.864s
[2K
| Adam | epoch: 011 | loss: 0.08734 - acc: 0.9690 -- iter: 288/348
[A[ATraining Step: 120  | total loss: [1m[32m0.11221[0m[0m | time: 156.113s
[2K
| Adam | epoch: 011 | loss: 0.11221 - acc: 0.9650 -- iter: 320/348
[A[ATraining Step: 121  | total loss: [1m[32m0.10999[0m[0m | time: 178.243s
[2K
| Adam | epoch: 011 | loss: 0.10999 - acc: 0.9649 | val_loss: 4.22214 - val_acc: 0.6514 -- iter: 348/348
--
Training Step: 122  | total loss: [1m[32m0.10211[0m[0m | time: 11.773s
[2K
| Adam | epoch: 012 | loss: 0.10211 - acc: 0.9684 -- iter: 032/348
[A[ATraining Step: 123  | total loss: [1m[32m0.09539[0m[0m | time: 23.331s
[2K
| Adam | epoch: 012 | loss: 0.09539 - acc: 0.9716 -- iter: 064/348
[A[ATraining Step: 124  | total loss: [1m[32m0.15223[0m[0m | time: 34.947s
[2K
| Adam | epoch: 012 | loss: 0.15223 - acc: 0.9650 -- iter: 096/348
[A[ATraining Step: 125  | total loss: [1m[32m0.16137[0m[0m | time: 46.422s
[2K
| Adam | epoch: 012 | loss: 0.16137 - acc: 0.9592 -- iter: 128/348
[A[ATraining Step: 126  | total loss: [1m[32m0.15104[0m[0m | time: 58.122s
[2K
| Adam | epoch: 012 | loss: 0.15104 - acc: 0.9601 -- iter: 160/348
[A[ATraining Step: 127  | total loss: [1m[32m0.14632[0m[0m | time: 69.914s
[2K
| Adam | epoch: 012 | loss: 0.14632 - acc: 0.9610 -- iter: 192/348
[A[ATraining Step: 128  | total loss: [1m[32m0.16529[0m[0m | time: 81.805s
[2K
| Adam | epoch: 012 | loss: 0.16529 - acc: 0.9493 -- iter: 224/348
[A[ATraining Step: 129  | total loss: [1m[32m0.15182[0m[0m | time: 93.669s
[2K
| Adam | epoch: 012 | loss: 0.15182 - acc: 0.9543 -- iter: 256/348
[A[ATraining Step: 130  | total loss: [1m[32m0.13856[0m[0m | time: 105.359s
[2K
| Adam | epoch: 012 | loss: 0.13856 - acc: 0.9589 -- iter: 288/348
[A[ATraining Step: 131  | total loss: [1m[32m0.13245[0m[0m | time: 117.115s
[2K
| Adam | epoch: 012 | loss: 0.13245 - acc: 0.9599 -- iter: 320/348
[A[ATraining Step: 132  | total loss: [1m[32m0.12408[0m[0m | time: 137.167s
[2K
| Adam | epoch: 012 | loss: 0.12408 - acc: 0.9639 | val_loss: 3.40092 - val_acc: 0.6697 -- iter: 348/348
--
Training Step: 133  | total loss: [1m[32m0.11484[0m[0m | time: 7.797s
[2K
| Adam | epoch: 013 | loss: 0.11484 - acc: 0.9675 -- iter: 032/348
[A[ATraining Step: 134  | total loss: [1m[32m0.12139[0m[0m | time: 19.376s
[2K
| Adam | epoch: 013 | loss: 0.12139 - acc: 0.9676 -- iter: 064/348
[A[ATraining Step: 135  | total loss: [1m[32m0.13984[0m[0m | time: 31.239s
[2K
| Adam | epoch: 013 | loss: 0.13984 - acc: 0.9646 -- iter: 096/348
[A[ATraining Step: 136  | total loss: [1m[32m0.14041[0m[0m | time: 42.818s
[2K
| Adam | epoch: 013 | loss: 0.14041 - acc: 0.9650 -- iter: 128/348
[A[ATraining Step: 137  | total loss: [1m[32m0.12930[0m[0m | time: 54.298s
[2K
| Adam | epoch: 013 | loss: 0.12930 - acc: 0.9685 -- iter: 160/348
[A[ATraining Step: 138  | total loss: [1m[32m0.13306[0m[0m | time: 66.054s
[2K
| Adam | epoch: 013 | loss: 0.13306 - acc: 0.9623 -- iter: 192/348
[A[ATraining Step: 139  | total loss: [1m[32m0.12251[0m[0m | time: 77.789s
[2K
| Adam | epoch: 013 | loss: 0.12251 - acc: 0.9661 -- iter: 224/348
[A[ATraining Step: 140  | total loss: [1m[32m0.11275[0m[0m | time: 89.611s
[2K
| Adam | epoch: 013 | loss: 0.11275 - acc: 0.9695 -- iter: 256/348
[A[ATraining Step: 141  | total loss: [1m[32m0.10835[0m[0m | time: 101.360s
[2K
| Adam | epoch: 013 | loss: 0.10835 - acc: 0.9694 -- iter: 288/348
[A[ATraining Step: 142  | total loss: [1m[32m0.10236[0m[0m | time: 113.166s
[2K
| Adam | epoch: 013 | loss: 0.10236 - acc: 0.9693 -- iter: 320/348
[A[ATraining Step: 143  | total loss: [1m[32m0.09734[0m[0m | time: 131.320s
[2K
| Adam | epoch: 013 | loss: 0.09734 - acc: 0.9693 | val_loss: 3.27221 - val_acc: 0.6422 -- iter: 348/348
--
Training Step: 144  | total loss: [1m[32m0.10616[0m[0m | time: 10.810s
[2K
| Adam | epoch: 014 | loss: 0.10616 - acc: 0.9616 -- iter: 032/348
[A[ATraining Step: 145  | total loss: [1m[32m0.09991[0m[0m | time: 22.707s
[2K
| Adam | epoch: 014 | loss: 0.09991 - acc: 0.9655 -- iter: 064/348
[A[ATraining Step: 146  | total loss: [1m[32m0.09770[0m[0m | time: 34.601s
[2K
| Adam | epoch: 014 | loss: 0.09770 - acc: 0.9658 -- iter: 096/348
[A[ATraining Step: 147  | total loss: [1m[32m0.09630[0m[0m | time: 46.189s
[2K
| Adam | epoch: 014 | loss: 0.09630 - acc: 0.9630 -- iter: 128/348
[A[ATraining Step: 148  | total loss: [1m[32m0.10344[0m[0m | time: 57.866s
[2K
| Adam | epoch: 014 | loss: 0.10344 - acc: 0.9573 -- iter: 160/348
[A[ATraining Step: 149  | total loss: [1m[32m0.09479[0m[0m | time: 69.559s
[2K
| Adam | epoch: 014 | loss: 0.09479 - acc: 0.9616 -- iter: 192/348
[A[ATraining Step: 150  | total loss: [1m[32m0.08740[0m[0m | time: 80.711s
[2K
| Adam | epoch: 014 | loss: 0.08740 - acc: 0.9654 -- iter: 224/348
[A[ATraining Step: 151  | total loss: [1m[32m0.08106[0m[0m | time: 92.934s
[2K
| Adam | epoch: 014 | loss: 0.08106 - acc: 0.9689 -- iter: 256/348
[A[ATraining Step: 152  | total loss: [1m[32m0.07411[0m[0m | time: 104.502s
[2K
| Adam | epoch: 014 | loss: 0.07411 - acc: 0.9720 -- iter: 288/348
[A[ATraining Step: 153  | total loss: [1m[32m0.07108[0m[0m | time: 116.752s
[2K
| Adam | epoch: 014 | loss: 0.07108 - acc: 0.9717 -- iter: 320/348
[A[ATraining Step: 154  | total loss: [1m[32m0.09215[0m[0m | time: 136.477s
[2K
| Adam | epoch: 014 | loss: 0.09215 - acc: 0.9620 | val_loss: 2.04055 - val_acc: 0.7156 -- iter: 348/348
--
Training Step: 155  | total loss: [1m[32m0.08813[0m[0m | time: 10.777s
[2K
| Adam | epoch: 015 | loss: 0.08813 - acc: 0.9627 -- iter: 032/348
[A[ATraining Step: 156  | total loss: [1m[32m0.08161[0m[0m | time: 21.427s
[2K
| Adam | epoch: 015 | loss: 0.08161 - acc: 0.9664 -- iter: 064/348
[A[ATraining Step: 157  | total loss: [1m[32m0.07491[0m[0m | time: 33.064s
[2K
| Adam | epoch: 015 | loss: 0.07491 - acc: 0.9698 -- iter: 096/348
[A[ATraining Step: 158  | total loss: [1m[32m0.07291[0m[0m | time: 44.867s
[2K
| Adam | epoch: 015 | loss: 0.07291 - acc: 0.9697 -- iter: 128/348
[A[ATraining Step: 159  | total loss: [1m[32m0.07266[0m[0m | time: 56.752s
[2K
| Adam | epoch: 015 | loss: 0.07266 - acc: 0.9696 -- iter: 160/348
[A[ATraining Step: 160  | total loss: [1m[32m0.19768[0m[0m | time: 68.796s
[2K
| Adam | epoch: 015 | loss: 0.19768 - acc: 0.9570 -- iter: 192/348
[A[ATraining Step: 161  | total loss: [1m[32m0.17888[0m[0m | time: 80.598s
[2K
| Adam | epoch: 015 | loss: 0.17888 - acc: 0.9613 -- iter: 224/348
[A[ATraining Step: 162  | total loss: [1m[32m0.16277[0m[0m | time: 92.604s
[2K
| Adam | epoch: 015 | loss: 0.16277 - acc: 0.9652 -- iter: 256/348
[A[ATraining Step: 163  | total loss: [1m[32m0.15451[0m[0m | time: 104.514s
[2K
| Adam | epoch: 015 | loss: 0.15451 - acc: 0.9655 -- iter: 288/348
[A[ATraining Step: 164  | total loss: [1m[32m0.16427[0m[0m | time: 116.285s
[2K
| Adam | epoch: 015 | loss: 0.16427 - acc: 0.9596 -- iter: 320/348
[A[ATraining Step: 165  | total loss: [1m[32m0.16425[0m[0m | time: 135.419s
[2K
| Adam | epoch: 015 | loss: 0.16425 - acc: 0.9574 | val_loss: 0.81159 - val_acc: 0.7890 -- iter: 348/348
--
Validation AUC:0.8460144927536232
Validation AUPRC:0.8997873416941328
Test AUC:0.8357240437158471
Test AUPRC:0.8498383113568597
BestTestF1Score	0.8	0.53	0.77	0.79	0.8	49	13	35	12	0.74
BestTestMCCScore	0.75	0.5	0.74	0.82	0.69	42	9	39	19	0.93
BestTestAccuracyScore	0.75	0.5	0.74	0.82	0.69	42	9	39	19	0.93
BestValidationF1Score	0.84	0.59	0.81	0.86	0.83	57	9	31	12	0.74
BestValidationMCC	0.83	0.62	0.81	0.91	0.77	53	5	35	16	0.93
BestValidationAccuracy	0.83	0.62	0.81	0.91	0.77	53	5	35	16	0.93
TestPredictions (Threshold:0.93)
CHEMBL2041569,TN,INACT,0.0	CHEMBL2334911,TN,INACT,0.0	CHEMBL241160,FN,ACT,0.009999999776482582	CHEMBL1911687,FN,ACT,0.09000000357627869	CHEMBL1088517,TP,ACT,0.9900000095367432	CHEMBL472508,FP,INACT,1.0	CHEMBL2323487,TN,INACT,0.0	CHEMBL178499,TN,INACT,0.009999999776482582	CHEMBL403549,FN,ACT,0.8700000047683716	CHEMBL256514,FN,ACT,0.8799999952316284	CHEMBL2323522,TN,INACT,0.029999999329447746	CHEMBL2323478,TN,INACT,0.7699999809265137	CHEMBL2323499,TN,INACT,0.03999999910593033	CHEMBL1800118,TP,ACT,0.9700000286102295	CHEMBL1642620,FN,ACT,0.8700000047683716	CHEMBL3698193,TP,ACT,1.0	CHEMBL1270110,TP,ACT,1.0	CHEMBL459967,FN,ACT,0.07000000029802322	CHEMBL1058,FP,INACT,0.9700000286102295	CHEMBL3698218,FN,ACT,0.07000000029802322	CHEMBL245647,TP,ACT,1.0	CHEMBL1098131,TP,ACT,1.0	CHEMBL2152219,FN,ACT,0.3700000047683716	CHEMBL1642613,TP,ACT,1.0	CHEMBL2402452,TP,ACT,1.0	CHEMBL276915,TN,INACT,0.009999999776482582	CHEMBL3698248,TP,ACT,1.0	CHEMBL221749,TP,ACT,1.0	CHEMBL2348091,TN,INACT,0.05999999865889549	CHEMBL1081299,TP,ACT,1.0	CHEMBL3700626,TP,ACT,1.0	CHEMBL2323516,TN,INACT,0.6100000143051147	CHEMBL3765321,FP,INACT,1.0	CHEMBL2172251,TN,INACT,0.009999999776482582	CHEMBL1373742,TN,INACT,0.15000000596046448	CHEMBL521,TN,INACT,0.4699999988079071	CHEMBL391188,TP,ACT,1.0	CHEMBL2323511,TN,INACT,0.009999999776482582	CHEMBL220883,TP,ACT,1.0	CHEMBL549788,FN,ACT,0.8700000047683716	CHEMBL1915938,TN,INACT,0.8799999952316284	CHEMBL2322366,TN,INACT,0.8100000023841858	CHEMBL1163685,TN,INACT,0.25	CHEMBL393251,FN,ACT,0.44999998807907104	CHEMBL1800763,TP,ACT,0.9399999976158142	CHEMBL2152220,TP,ACT,0.9800000190734863	CHEMBL3669424,TP,ACT,1.0	CHEMBL3669354,TP,ACT,0.9700000286102295	CHEMBL396925,FP,INACT,0.9300000071525574	CHEMBL2041152,TN,INACT,0.009999999776482582	CHEMBL2323490,TN,INACT,0.009999999776482582	CHEMBL1760793,FN,ACT,0.6499999761581421	CHEMBL2323508,TN,INACT,0.28999999165534973	CHEMBL236476,TP,ACT,0.9900000095367432	CHEMBL2323520,TN,INACT,0.5699999928474426	CHEMBL3287024,TP,ACT,0.9399999976158142	CHEMBL1628094,FP,INACT,1.0	CHEMBL2041773,TN,INACT,0.0	CHEMBL247179,FN,ACT,0.8199999928474426	CHEMBL2023423,FN,ACT,0.7699999809265137	CHEMBL3669364,TP,ACT,1.0	CHEMBL3401674,TP,ACT,1.0	CHEMBL374283,TP,ACT,1.0	CHEMBL2323481,TN,INACT,0.019999999552965164	CHEMBL429501,TP,ACT,0.9800000190734863	CHEMBL563,TN,INACT,0.029999999329447746	CHEMBL2334902,TN,INACT,0.0	CHEMBL1761861,FN,ACT,0.10000000149011612	CHEMBL2041774,TN,INACT,0.0	CHEMBL238794,FN,ACT,0.019999999552965164	CHEMBL3663664,TP,ACT,1.0	CHEMBL3681927,TP,ACT,1.0	CHEMBL175,FP,INACT,0.9700000286102295	CHEMBL518275,TN,INACT,0.0	CHEMBL1800120,TP,ACT,1.0	CHEMBL2380643,TP,ACT,1.0	CHEMBL3674373,TP,ACT,1.0	CHEMBL247180,FP,INACT,1.0	CHEMBL3763512,FP,INACT,1.0	CHEMBL1915954,TN,INACT,0.029999999329447746	CHEMBL441370,TN,INACT,0.0	CHEMBL2152235,TP,ACT,1.0	CHEMBL219666,FN,ACT,0.03999999910593033	CHEMBL1527416,TN,INACT,0.0	CHEMBL2334151,FN,ACT,0.6899999976158142	CHEMBL1761860,TP,ACT,1.0	CHEMBL196782,TN,INACT,0.029999999329447746	CHEMBL2172249,TN,INACT,0.10000000149011612	CHEMBL2409608,TP,ACT,1.0	CHEMBL494180,TP,ACT,0.9900000095367432	CHEMBL3669314,TP,ACT,1.0	CHEMBL2070225,FN,ACT,0.47999998927116394	CHEMBL3339179,TN,INACT,0.9200000166893005	CHEMBL154,TN,INACT,0.36000001430511475	CHEMBL83270,TN,INACT,0.1599999964237213	CHEMBL1096870,TP,ACT,1.0	CHEMBL3669365,TP,ACT,1.0	CHEMBL2333529,FP,INACT,1.0	CHEMBL240504,TN,INACT,0.0	CHEMBL2158486,TP,ACT,1.0	CHEMBL2334921,TN,INACT,0.019999999552965164	CHEMBL436,TN,INACT,0.07999999821186066	CHEMBL448345,FN,ACT,0.7699999809265137	CHEMBL3681940,TP,ACT,1.0	CHEMBL3669318,TP,ACT,1.0	CHEMBL2036239,TP,ACT,1.0	CHEMBL221159,TP,ACT,1.0	CHEMBL3103322,TN,INACT,0.27000001072883606	CHEMBL3669393,TP,ACT,1.0	

