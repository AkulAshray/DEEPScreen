ImageNetInceptionV2 CHEMBL4792 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	1771
Number of inactive compounds :	1771
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4792_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4792_adam_0.0005_30_0.8/
---------------------------------
Training samples: 2163
Validation samples: 677
--
Training Step: 1  | time: 35.217s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2163
[A[ATraining Step: 2  | total loss: [1m[32m0.64821[0m[0m | time: 43.156s
[2K
| Adam | epoch: 001 | loss: 0.64821 - acc: 0.4500 -- iter: 0064/2163
[A[ATraining Step: 3  | total loss: [1m[32m0.70935[0m[0m | time: 51.014s
[2K
| Adam | epoch: 001 | loss: 0.70935 - acc: 0.5165 -- iter: 0096/2163
[A[ATraining Step: 4  | total loss: [1m[32m0.58885[0m[0m | time: 58.810s
[2K
| Adam | epoch: 001 | loss: 0.58885 - acc: 0.6916 -- iter: 0128/2163
[A[ATraining Step: 5  | total loss: [1m[32m0.69497[0m[0m | time: 66.616s
[2K
| Adam | epoch: 001 | loss: 0.69497 - acc: 0.5806 -- iter: 0160/2163
[A[ATraining Step: 6  | total loss: [1m[32m0.67055[0m[0m | time: 74.538s
[2K
| Adam | epoch: 001 | loss: 0.67055 - acc: 0.5690 -- iter: 0192/2163
[A[ATraining Step: 7  | total loss: [1m[32m0.69045[0m[0m | time: 82.448s
[2K
| Adam | epoch: 001 | loss: 0.69045 - acc: 0.5651 -- iter: 0224/2163
[A[ATraining Step: 8  | total loss: [1m[32m0.66185[0m[0m | time: 90.365s
[2K
| Adam | epoch: 001 | loss: 0.66185 - acc: 0.6339 -- iter: 0256/2163
[A[ATraining Step: 9  | total loss: [1m[32m0.68202[0m[0m | time: 98.241s
[2K
| Adam | epoch: 001 | loss: 0.68202 - acc: 0.6292 -- iter: 0288/2163
[A[ATraining Step: 10  | total loss: [1m[32m0.66240[0m[0m | time: 106.005s
[2K
| Adam | epoch: 001 | loss: 0.66240 - acc: 0.6427 -- iter: 0320/2163
[A[ATraining Step: 11  | total loss: [1m[32m0.53238[0m[0m | time: 113.938s
[2K
| Adam | epoch: 001 | loss: 0.53238 - acc: 0.7379 -- iter: 0352/2163
[A[ATraining Step: 12  | total loss: [1m[32m0.53364[0m[0m | time: 121.638s
[2K
| Adam | epoch: 001 | loss: 0.53364 - acc: 0.7152 -- iter: 0384/2163
[A[ATraining Step: 13  | total loss: [1m[32m0.55789[0m[0m | time: 129.403s
[2K
| Adam | epoch: 001 | loss: 0.55789 - acc: 0.7167 -- iter: 0416/2163
[A[ATraining Step: 14  | total loss: [1m[32m0.69486[0m[0m | time: 137.218s
[2K
| Adam | epoch: 001 | loss: 0.69486 - acc: 0.6409 -- iter: 0448/2163
[A[ATraining Step: 15  | total loss: [1m[32m0.72345[0m[0m | time: 144.955s
[2K
| Adam | epoch: 001 | loss: 0.72345 - acc: 0.6713 -- iter: 0480/2163
[A[ATraining Step: 16  | total loss: [1m[32m0.77198[0m[0m | time: 152.748s
[2K
| Adam | epoch: 001 | loss: 0.77198 - acc: 0.6422 -- iter: 0512/2163
[A[ATraining Step: 17  | total loss: [1m[32m0.65826[0m[0m | time: 160.449s
[2K
| Adam | epoch: 001 | loss: 0.65826 - acc: 0.7260 -- iter: 0544/2163
[A[ATraining Step: 18  | total loss: [1m[32m0.60443[0m[0m | time: 168.187s
[2K
| Adam | epoch: 001 | loss: 0.60443 - acc: 0.7343 -- iter: 0576/2163
[A[ATraining Step: 19  | total loss: [1m[32m0.55515[0m[0m | time: 175.818s
[2K
| Adam | epoch: 001 | loss: 0.55515 - acc: 0.7916 -- iter: 0608/2163
[A[ATraining Step: 20  | total loss: [1m[32m0.55625[0m[0m | time: 183.645s
[2K
| Adam | epoch: 001 | loss: 0.55625 - acc: 0.7682 -- iter: 0640/2163
[A[ATraining Step: 21  | total loss: [1m[32m0.55134[0m[0m | time: 191.567s
[2K
| Adam | epoch: 001 | loss: 0.55134 - acc: 0.7626 -- iter: 0672/2163
[A[ATraining Step: 22  | total loss: [1m[32m0.59085[0m[0m | time: 199.264s
[2K
| Adam | epoch: 001 | loss: 0.59085 - acc: 0.7119 -- iter: 0704/2163
[A[ATraining Step: 23  | total loss: [1m[32m0.59886[0m[0m | time: 207.144s
[2K
| Adam | epoch: 001 | loss: 0.59886 - acc: 0.6958 -- iter: 0736/2163
[A[ATraining Step: 24  | total loss: [1m[32m0.66472[0m[0m | time: 214.959s
[2K
| Adam | epoch: 001 | loss: 0.66472 - acc: 0.6846 -- iter: 0768/2163
[A[ATraining Step: 25  | total loss: [1m[32m0.61910[0m[0m | time: 222.818s
[2K
| Adam | epoch: 001 | loss: 0.61910 - acc: 0.7110 -- iter: 0800/2163
[A[ATraining Step: 26  | total loss: [1m[32m0.57111[0m[0m | time: 230.538s
[2K
| Adam | epoch: 001 | loss: 0.57111 - acc: 0.7379 -- iter: 0832/2163
[A[ATraining Step: 27  | total loss: [1m[32m0.56799[0m[0m | time: 238.381s
[2K
| Adam | epoch: 001 | loss: 0.56799 - acc: 0.7088 -- iter: 0864/2163
[A[ATraining Step: 28  | total loss: [1m[32m0.57280[0m[0m | time: 246.077s
[2K
| Adam | epoch: 001 | loss: 0.57280 - acc: 0.7035 -- iter: 0896/2163
[A[ATraining Step: 29  | total loss: [1m[32m0.53442[0m[0m | time: 253.814s
[2K
| Adam | epoch: 001 | loss: 0.53442 - acc: 0.7224 -- iter: 0928/2163
[A[ATraining Step: 30  | total loss: [1m[32m0.59217[0m[0m | time: 261.694s
[2K
| Adam | epoch: 001 | loss: 0.59217 - acc: 0.6771 -- iter: 0960/2163
[A[ATraining Step: 31  | total loss: [1m[32m0.63676[0m[0m | time: 269.540s
[2K
| Adam | epoch: 001 | loss: 0.63676 - acc: 0.6723 -- iter: 0992/2163
[A[ATraining Step: 32  | total loss: [1m[32m0.60948[0m[0m | time: 277.305s
[2K
| Adam | epoch: 001 | loss: 0.60948 - acc: 0.6757 -- iter: 1024/2163
[A[ATraining Step: 33  | total loss: [1m[32m0.56601[0m[0m | time: 285.073s
[2K
| Adam | epoch: 001 | loss: 0.56601 - acc: 0.7195 -- iter: 1056/2163
[A[ATraining Step: 34  | total loss: [1m[32m0.53818[0m[0m | time: 292.820s
[2K
| Adam | epoch: 001 | loss: 0.53818 - acc: 0.7394 -- iter: 1088/2163
[A[ATraining Step: 35  | total loss: [1m[32m0.51003[0m[0m | time: 300.518s
[2K
| Adam | epoch: 001 | loss: 0.51003 - acc: 0.7612 -- iter: 1120/2163
[A[ATraining Step: 36  | total loss: [1m[32m0.48625[0m[0m | time: 308.394s
[2K
| Adam | epoch: 001 | loss: 0.48625 - acc: 0.7653 -- iter: 1152/2163
[A[ATraining Step: 37  | total loss: [1m[32m0.50056[0m[0m | time: 316.234s
[2K
| Adam | epoch: 001 | loss: 0.50056 - acc: 0.7560 -- iter: 1184/2163
[A[ATraining Step: 38  | total loss: [1m[32m0.52139[0m[0m | time: 323.866s
[2K
| Adam | epoch: 001 | loss: 0.52139 - acc: 0.7365 -- iter: 1216/2163
[A[ATraining Step: 39  | total loss: [1m[32m0.48879[0m[0m | time: 331.677s
[2K
| Adam | epoch: 001 | loss: 0.48879 - acc: 0.7511 -- iter: 1248/2163
[A[ATraining Step: 40  | total loss: [1m[32m0.45650[0m[0m | time: 339.402s
[2K
| Adam | epoch: 001 | loss: 0.45650 - acc: 0.7802 -- iter: 1280/2163
[A[ATraining Step: 41  | total loss: [1m[32m0.45512[0m[0m | time: 347.322s
[2K
| Adam | epoch: 001 | loss: 0.45512 - acc: 0.7631 -- iter: 1312/2163
[A[ATraining Step: 42  | total loss: [1m[32m0.43791[0m[0m | time: 355.060s
[2K
| Adam | epoch: 001 | loss: 0.43791 - acc: 0.7664 -- iter: 1344/2163
[A[ATraining Step: 43  | total loss: [1m[32m0.42315[0m[0m | time: 362.662s
[2K
| Adam | epoch: 001 | loss: 0.42315 - acc: 0.7856 -- iter: 1376/2163
[A[ATraining Step: 44  | total loss: [1m[32m0.43286[0m[0m | time: 370.429s
[2K
| Adam | epoch: 001 | loss: 0.43286 - acc: 0.7686 -- iter: 1408/2163
[A[ATraining Step: 45  | total loss: [1m[32m0.42151[0m[0m | time: 378.205s
[2K
| Adam | epoch: 001 | loss: 0.42151 - acc: 0.7760 -- iter: 1440/2163
[A[ATraining Step: 46  | total loss: [1m[32m0.41302[0m[0m | time: 385.925s
[2K
| Adam | epoch: 001 | loss: 0.41302 - acc: 0.7873 -- iter: 1472/2163
[A[ATraining Step: 47  | total loss: [1m[32m0.42492[0m[0m | time: 393.703s
[2K
| Adam | epoch: 001 | loss: 0.42492 - acc: 0.7812 -- iter: 1504/2163
[A[ATraining Step: 48  | total loss: [1m[32m0.42127[0m[0m | time: 401.408s
[2K
| Adam | epoch: 001 | loss: 0.42127 - acc: 0.7812 -- iter: 1536/2163
[A[ATraining Step: 49  | total loss: [1m[32m0.40580[0m[0m | time: 409.011s
[2K
| Adam | epoch: 001 | loss: 0.40580 - acc: 0.7911 -- iter: 1568/2163
[A[ATraining Step: 50  | total loss: [1m[32m0.41749[0m[0m | time: 416.682s
[2K
| Adam | epoch: 001 | loss: 0.41749 - acc: 0.7847 -- iter: 1600/2163
[A[ATraining Step: 51  | total loss: [1m[32m0.39303[0m[0m | time: 424.395s
[2K
| Adam | epoch: 001 | loss: 0.39303 - acc: 0.8080 -- iter: 1632/2163
[A[ATraining Step: 52  | total loss: [1m[32m0.38129[0m[0m | time: 432.127s
[2K
| Adam | epoch: 001 | loss: 0.38129 - acc: 0.8134 -- iter: 1664/2163
[A[ATraining Step: 53  | total loss: [1m[32m0.39805[0m[0m | time: 439.816s
[2K
| Adam | epoch: 001 | loss: 0.39805 - acc: 0.8040 -- iter: 1696/2163
[A[ATraining Step: 54  | total loss: [1m[32m0.39650[0m[0m | time: 447.505s
[2K
| Adam | epoch: 001 | loss: 0.39650 - acc: 0.8053 -- iter: 1728/2163
[A[ATraining Step: 55  | total loss: [1m[32m0.43095[0m[0m | time: 455.081s
[2K
| Adam | epoch: 001 | loss: 0.43095 - acc: 0.7929 -- iter: 1760/2163
[A[ATraining Step: 56  | total loss: [1m[32m0.45195[0m[0m | time: 462.782s
[2K
| Adam | epoch: 001 | loss: 0.45195 - acc: 0.7957 -- iter: 1792/2163
[A[ATraining Step: 57  | total loss: [1m[32m0.48250[0m[0m | time: 470.526s
[2K
| Adam | epoch: 001 | loss: 0.48250 - acc: 0.7893 -- iter: 1824/2163
[A[ATraining Step: 58  | total loss: [1m[32m0.51726[0m[0m | time: 478.123s
[2K
| Adam | epoch: 001 | loss: 0.51726 - acc: 0.7755 -- iter: 1856/2163
[A[ATraining Step: 59  | total loss: [1m[32m0.51419[0m[0m | time: 485.776s
[2K
| Adam | epoch: 001 | loss: 0.51419 - acc: 0.7846 -- iter: 1888/2163
[A[ATraining Step: 60  | total loss: [1m[32m0.49935[0m[0m | time: 493.476s
[2K
| Adam | epoch: 001 | loss: 0.49935 - acc: 0.7925 -- iter: 1920/2163
[A[ATraining Step: 61  | total loss: [1m[32m0.50814[0m[0m | time: 501.138s
[2K
| Adam | epoch: 001 | loss: 0.50814 - acc: 0.7747 -- iter: 1952/2163
[A[ATraining Step: 62  | total loss: [1m[32m0.49108[0m[0m | time: 508.950s
[2K
| Adam | epoch: 001 | loss: 0.49108 - acc: 0.7755 -- iter: 1984/2163
[A[ATraining Step: 63  | total loss: [1m[32m0.47242[0m[0m | time: 516.703s
[2K
| Adam | epoch: 001 | loss: 0.47242 - acc: 0.7802 -- iter: 2016/2163
[A[ATraining Step: 64  | total loss: [1m[32m0.47038[0m[0m | time: 524.490s
[2K
| Adam | epoch: 001 | loss: 0.47038 - acc: 0.7803 -- iter: 2048/2163
[A[ATraining Step: 65  | total loss: [1m[32m0.44956[0m[0m | time: 532.205s
[2K
| Adam | epoch: 001 | loss: 0.44956 - acc: 0.7920 -- iter: 2080/2163
[A[ATraining Step: 66  | total loss: [1m[32m0.43074[0m[0m | time: 539.922s
[2K
| Adam | epoch: 001 | loss: 0.43074 - acc: 0.8021 -- iter: 2112/2163
[A[ATraining Step: 67  | total loss: [1m[32m0.44335[0m[0m | time: 547.616s
[2K
| Adam | epoch: 001 | loss: 0.44335 - acc: 0.7959 -- iter: 2144/2163
[A[ATraining Step: 68  | total loss: [1m[32m0.44660[0m[0m | time: 587.656s
[2K
| Adam | epoch: 001 | loss: 0.44660 - acc: 0.7904 | val_loss: 1.42350 - val_acc: 0.5022 -- iter: 2163/2163
--
Training Step: 69  | total loss: [1m[32m0.47149[0m[0m | time: 5.041s
[2K
| Adam | epoch: 002 | loss: 0.47149 - acc: 0.7657 -- iter: 0032/2163
[A[ATraining Step: 70  | total loss: [1m[32m0.45996[0m[0m | time: 12.653s
[2K
| Adam | epoch: 002 | loss: 0.45996 - acc: 0.7684 -- iter: 0064/2163
[A[ATraining Step: 71  | total loss: [1m[32m0.45161[0m[0m | time: 20.373s
[2K
| Adam | epoch: 002 | loss: 0.45161 - acc: 0.7699 -- iter: 0096/2163
[A[ATraining Step: 72  | total loss: [1m[32m0.45980[0m[0m | time: 28.043s
[2K
| Adam | epoch: 002 | loss: 0.45980 - acc: 0.7712 -- iter: 0128/2163
[A[ATraining Step: 73  | total loss: [1m[32m0.45693[0m[0m | time: 35.770s
[2K
| Adam | epoch: 002 | loss: 0.45693 - acc: 0.7758 -- iter: 0160/2163
[A[ATraining Step: 74  | total loss: [1m[32m0.44439[0m[0m | time: 43.537s
[2K
| Adam | epoch: 002 | loss: 0.44439 - acc: 0.7832 -- iter: 0192/2163
[A[ATraining Step: 75  | total loss: [1m[32m0.48361[0m[0m | time: 51.142s
[2K
| Adam | epoch: 002 | loss: 0.48361 - acc: 0.7627 -- iter: 0224/2163
[A[ATraining Step: 76  | total loss: [1m[32m0.48955[0m[0m | time: 58.841s
[2K
| Adam | epoch: 002 | loss: 0.48955 - acc: 0.7613 -- iter: 0256/2163
[A[ATraining Step: 77  | total loss: [1m[32m0.48096[0m[0m | time: 66.533s
[2K
| Adam | epoch: 002 | loss: 0.48096 - acc: 0.7667 -- iter: 0288/2163
[A[ATraining Step: 78  | total loss: [1m[32m0.47285[0m[0m | time: 74.197s
[2K
| Adam | epoch: 002 | loss: 0.47285 - acc: 0.7748 -- iter: 0320/2163
[A[ATraining Step: 79  | total loss: [1m[32m0.46029[0m[0m | time: 81.912s
[2K
| Adam | epoch: 002 | loss: 0.46029 - acc: 0.7852 -- iter: 0352/2163
[A[ATraining Step: 80  | total loss: [1m[32m0.44404[0m[0m | time: 89.609s
[2K
| Adam | epoch: 002 | loss: 0.44404 - acc: 0.7912 -- iter: 0384/2163
[A[ATraining Step: 81  | total loss: [1m[32m0.42599[0m[0m | time: 97.383s
[2K
| Adam | epoch: 002 | loss: 0.42599 - acc: 0.7996 -- iter: 0416/2163
[A[ATraining Step: 82  | total loss: [1m[32m0.42913[0m[0m | time: 105.209s
[2K
| Adam | epoch: 002 | loss: 0.42913 - acc: 0.8041 -- iter: 0448/2163
[A[ATraining Step: 83  | total loss: [1m[32m0.44611[0m[0m | time: 112.893s
[2K
| Adam | epoch: 002 | loss: 0.44611 - acc: 0.8018 -- iter: 0480/2163
[A[ATraining Step: 84  | total loss: [1m[32m0.46696[0m[0m | time: 120.580s
[2K
| Adam | epoch: 002 | loss: 0.46696 - acc: 0.7935 -- iter: 0512/2163
[A[ATraining Step: 85  | total loss: [1m[32m0.47661[0m[0m | time: 128.293s
[2K
| Adam | epoch: 002 | loss: 0.47661 - acc: 0.7829 -- iter: 0544/2163
[A[ATraining Step: 86  | total loss: [1m[32m0.47657[0m[0m | time: 135.897s
[2K
| Adam | epoch: 002 | loss: 0.47657 - acc: 0.7858 -- iter: 0576/2163
[A[ATraining Step: 87  | total loss: [1m[32m0.44820[0m[0m | time: 143.573s
[2K
| Adam | epoch: 002 | loss: 0.44820 - acc: 0.8010 -- iter: 0608/2163
[A[ATraining Step: 88  | total loss: [1m[32m0.43815[0m[0m | time: 151.292s
[2K
| Adam | epoch: 002 | loss: 0.43815 - acc: 0.8053 -- iter: 0640/2163
[A[ATraining Step: 89  | total loss: [1m[32m0.43896[0m[0m | time: 158.877s
[2K
| Adam | epoch: 002 | loss: 0.43896 - acc: 0.7997 -- iter: 0672/2163
[A[ATraining Step: 90  | total loss: [1m[32m0.43199[0m[0m | time: 166.559s
[2K
| Adam | epoch: 002 | loss: 0.43199 - acc: 0.8041 -- iter: 0704/2163
[A[ATraining Step: 91  | total loss: [1m[32m0.41131[0m[0m | time: 174.378s
[2K
| Adam | epoch: 002 | loss: 0.41131 - acc: 0.8175 -- iter: 0736/2163
[A[ATraining Step: 92  | total loss: [1m[32m0.41066[0m[0m | time: 182.036s
[2K
| Adam | epoch: 002 | loss: 0.41066 - acc: 0.8232 -- iter: 0768/2163
[A[ATraining Step: 93  | total loss: [1m[32m0.40710[0m[0m | time: 189.739s
[2K
| Adam | epoch: 002 | loss: 0.40710 - acc: 0.8159 -- iter: 0800/2163
[A[ATraining Step: 94  | total loss: [1m[32m0.41003[0m[0m | time: 197.443s
[2K
| Adam | epoch: 002 | loss: 0.41003 - acc: 0.8093 -- iter: 0832/2163
[A[ATraining Step: 95  | total loss: [1m[32m0.38992[0m[0m | time: 205.130s
[2K
| Adam | epoch: 002 | loss: 0.38992 - acc: 0.8253 -- iter: 0864/2163
[A[ATraining Step: 96  | total loss: [1m[32m0.37685[0m[0m | time: 212.935s
[2K
| Adam | epoch: 002 | loss: 0.37685 - acc: 0.8334 -- iter: 0896/2163
[A[ATraining Step: 97  | total loss: [1m[32m0.37459[0m[0m | time: 220.556s
[2K
| Adam | epoch: 002 | loss: 0.37459 - acc: 0.8375 -- iter: 0928/2163
[A[ATraining Step: 98  | total loss: [1m[32m0.36798[0m[0m | time: 228.290s
[2K
| Adam | epoch: 002 | loss: 0.36798 - acc: 0.8413 -- iter: 0960/2163
[A[ATraining Step: 99  | total loss: [1m[32m0.36608[0m[0m | time: 235.932s
[2K
| Adam | epoch: 002 | loss: 0.36608 - acc: 0.8415 -- iter: 0992/2163
[A[ATraining Step: 100  | total loss: [1m[32m0.36040[0m[0m | time: 243.600s
[2K
| Adam | epoch: 002 | loss: 0.36040 - acc: 0.8417 -- iter: 1024/2163
[A[ATraining Step: 101  | total loss: [1m[32m0.35061[0m[0m | time: 251.277s
[2K
| Adam | epoch: 002 | loss: 0.35061 - acc: 0.8419 -- iter: 1056/2163
[A[ATraining Step: 102  | total loss: [1m[32m0.35017[0m[0m | time: 259.000s
[2K
| Adam | epoch: 002 | loss: 0.35017 - acc: 0.8453 -- iter: 1088/2163
[A[ATraining Step: 103  | total loss: [1m[32m0.35408[0m[0m | time: 266.809s
[2K
| Adam | epoch: 002 | loss: 0.35408 - acc: 0.8389 -- iter: 1120/2163
[A[ATraining Step: 104  | total loss: [1m[32m0.34026[0m[0m | time: 274.536s
[2K
| Adam | epoch: 002 | loss: 0.34026 - acc: 0.8456 -- iter: 1152/2163
[A[ATraining Step: 105  | total loss: [1m[32m0.33309[0m[0m | time: 282.260s
[2K
| Adam | epoch: 002 | loss: 0.33309 - acc: 0.8454 -- iter: 1184/2163
[A[ATraining Step: 106  | total loss: [1m[32m0.34179[0m[0m | time: 289.909s
[2K
| Adam | epoch: 002 | loss: 0.34179 - acc: 0.8546 -- iter: 1216/2163
[A[ATraining Step: 107  | total loss: [1m[32m0.31991[0m[0m | time: 297.619s
[2K
| Adam | epoch: 002 | loss: 0.31991 - acc: 0.8692 -- iter: 1248/2163
[A[ATraining Step: 108  | total loss: [1m[32m0.30728[0m[0m | time: 305.306s
[2K
| Adam | epoch: 002 | loss: 0.30728 - acc: 0.8729 -- iter: 1280/2163
[A[ATraining Step: 109  | total loss: [1m[32m0.30255[0m[0m | time: 313.105s
[2K
| Adam | epoch: 002 | loss: 0.30255 - acc: 0.8700 -- iter: 1312/2163
[A[ATraining Step: 110  | total loss: [1m[32m0.29631[0m[0m | time: 320.795s
[2K
| Adam | epoch: 002 | loss: 0.29631 - acc: 0.8673 -- iter: 1344/2163
[A[ATraining Step: 111  | total loss: [1m[32m0.29080[0m[0m | time: 328.416s
[2K
| Adam | epoch: 002 | loss: 0.29080 - acc: 0.8712 -- iter: 1376/2163
[A[ATraining Step: 112  | total loss: [1m[32m0.28001[0m[0m | time: 336.187s
[2K
| Adam | epoch: 002 | loss: 0.28001 - acc: 0.8747 -- iter: 1408/2163
[A[ATraining Step: 113  | total loss: [1m[32m0.28042[0m[0m | time: 343.802s
[2K
| Adam | epoch: 002 | loss: 0.28042 - acc: 0.8810 -- iter: 1440/2163
[A[ATraining Step: 114  | total loss: [1m[32m0.27539[0m[0m | time: 351.533s
[2K
| Adam | epoch: 002 | loss: 0.27539 - acc: 0.8867 -- iter: 1472/2163
[A[ATraining Step: 115  | total loss: [1m[32m0.27791[0m[0m | time: 359.038s
[2K
| Adam | epoch: 002 | loss: 0.27791 - acc: 0.8855 -- iter: 1504/2163
[A[ATraining Step: 116  | total loss: [1m[32m0.27106[0m[0m | time: 366.699s
[2K
| Adam | epoch: 002 | loss: 0.27106 - acc: 0.8876 -- iter: 1536/2163
[A[ATraining Step: 117  | total loss: [1m[32m0.26070[0m[0m | time: 374.402s
[2K
| Adam | epoch: 002 | loss: 0.26070 - acc: 0.8926 -- iter: 1568/2163
[A[ATraining Step: 118  | total loss: [1m[32m0.28161[0m[0m | time: 382.121s
[2K
| Adam | epoch: 002 | loss: 0.28161 - acc: 0.8877 -- iter: 1600/2163
[A[ATraining Step: 119  | total loss: [1m[32m0.26240[0m[0m | time: 389.774s
[2K
| Adam | epoch: 002 | loss: 0.26240 - acc: 0.8958 -- iter: 1632/2163
[A[ATraining Step: 120  | total loss: [1m[32m0.27235[0m[0m | time: 397.383s
[2K
| Adam | epoch: 002 | loss: 0.27235 - acc: 0.8906 -- iter: 1664/2163
[A[ATraining Step: 121  | total loss: [1m[32m0.27670[0m[0m | time: 405.089s
[2K
| Adam | epoch: 002 | loss: 0.27670 - acc: 0.8890 -- iter: 1696/2163
[A[ATraining Step: 122  | total loss: [1m[32m0.30462[0m[0m | time: 412.699s
[2K
| Adam | epoch: 002 | loss: 0.30462 - acc: 0.8751 -- iter: 1728/2163
[A[ATraining Step: 123  | total loss: [1m[32m0.31717[0m[0m | time: 420.376s
[2K
| Adam | epoch: 002 | loss: 0.31717 - acc: 0.8595 -- iter: 1760/2163
[A[ATraining Step: 124  | total loss: [1m[32m0.30139[0m[0m | time: 428.120s
[2K
| Adam | epoch: 002 | loss: 0.30139 - acc: 0.8673 -- iter: 1792/2163
[A[ATraining Step: 125  | total loss: [1m[32m0.29536[0m[0m | time: 435.812s
[2K
| Adam | epoch: 002 | loss: 0.29536 - acc: 0.8681 -- iter: 1824/2163
[A[ATraining Step: 126  | total loss: [1m[32m0.29208[0m[0m | time: 443.441s
[2K
| Adam | epoch: 002 | loss: 0.29208 - acc: 0.8719 -- iter: 1856/2163
[A[ATraining Step: 127  | total loss: [1m[32m0.29997[0m[0m | time: 451.106s
[2K
| Adam | epoch: 002 | loss: 0.29997 - acc: 0.8691 -- iter: 1888/2163
[A[ATraining Step: 128  | total loss: [1m[32m0.31225[0m[0m | time: 458.866s
[2K
| Adam | epoch: 002 | loss: 0.31225 - acc: 0.8603 -- iter: 1920/2163
[A[ATraining Step: 129  | total loss: [1m[32m0.31237[0m[0m | time: 466.571s
[2K
| Adam | epoch: 002 | loss: 0.31237 - acc: 0.8649 -- iter: 1952/2163
[A[ATraining Step: 130  | total loss: [1m[32m0.30972[0m[0m | time: 474.340s
[2K
| Adam | epoch: 002 | loss: 0.30972 - acc: 0.8659 -- iter: 1984/2163
[A[ATraining Step: 131  | total loss: [1m[32m0.30070[0m[0m | time: 481.960s
[2K
| Adam | epoch: 002 | loss: 0.30070 - acc: 0.8731 -- iter: 2016/2163
[A[ATraining Step: 132  | total loss: [1m[32m0.31671[0m[0m | time: 489.781s
[2K
| Adam | epoch: 002 | loss: 0.31671 - acc: 0.8701 -- iter: 2048/2163
[A[ATraining Step: 133  | total loss: [1m[32m0.31268[0m[0m | time: 497.476s
[2K
| Adam | epoch: 002 | loss: 0.31268 - acc: 0.8737 -- iter: 2080/2163
[A[ATraining Step: 134  | total loss: [1m[32m0.33711[0m[0m | time: 505.191s
[2K
| Adam | epoch: 002 | loss: 0.33711 - acc: 0.8676 -- iter: 2112/2163
[A[ATraining Step: 135  | total loss: [1m[32m0.33676[0m[0m | time: 512.698s
[2K
| Adam | epoch: 002 | loss: 0.33676 - acc: 0.8652 -- iter: 2144/2163
[A[ATraining Step: 136  | total loss: [1m[32m0.34443[0m[0m | time: 549.746s
[2K
| Adam | epoch: 002 | loss: 0.34443 - acc: 0.8537 | val_loss: 3.77496 - val_acc: 0.4963 -- iter: 2163/2163
--
Training Step: 137  | total loss: [1m[32m0.33155[0m[0m | time: 5.086s
[2K
| Adam | epoch: 003 | loss: 0.33155 - acc: 0.8590 -- iter: 0032/2163
[A[ATraining Step: 138  | total loss: [1m[32m0.31159[0m[0m | time: 10.213s
[2K
| Adam | epoch: 003 | loss: 0.31159 - acc: 0.8731 -- iter: 0064/2163
[A[ATraining Step: 139  | total loss: [1m[32m0.29132[0m[0m | time: 17.814s
[2K
| Adam | epoch: 003 | loss: 0.29132 - acc: 0.8858 -- iter: 0096/2163
[A[ATraining Step: 140  | total loss: [1m[32m0.28961[0m[0m | time: 25.418s
[2K
| Adam | epoch: 003 | loss: 0.28961 - acc: 0.8847 -- iter: 0128/2163
[A[ATraining Step: 141  | total loss: [1m[32m0.28972[0m[0m | time: 33.141s
[2K
| Adam | epoch: 003 | loss: 0.28972 - acc: 0.8806 -- iter: 0160/2163
[A[ATraining Step: 142  | total loss: [1m[32m0.29175[0m[0m | time: 40.939s
[2K
| Adam | epoch: 003 | loss: 0.29175 - acc: 0.8769 -- iter: 0192/2163
[A[ATraining Step: 143  | total loss: [1m[32m0.29026[0m[0m | time: 48.651s
[2K
| Adam | epoch: 003 | loss: 0.29026 - acc: 0.8736 -- iter: 0224/2163
[A[ATraining Step: 144  | total loss: [1m[32m0.29621[0m[0m | time: 56.179s
[2K
| Adam | epoch: 003 | loss: 0.29621 - acc: 0.8706 -- iter: 0256/2163
[A[ATraining Step: 145  | total loss: [1m[32m0.29479[0m[0m | time: 63.824s
[2K
| Adam | epoch: 003 | loss: 0.29479 - acc: 0.8710 -- iter: 0288/2163
[A[ATraining Step: 146  | total loss: [1m[32m0.29611[0m[0m | time: 71.540s
[2K
| Adam | epoch: 003 | loss: 0.29611 - acc: 0.8714 -- iter: 0320/2163
[A[ATraining Step: 147  | total loss: [1m[32m0.28506[0m[0m | time: 79.012s
[2K
| Adam | epoch: 003 | loss: 0.28506 - acc: 0.8780 -- iter: 0352/2163
[A[ATraining Step: 148  | total loss: [1m[32m0.27182[0m[0m | time: 86.679s
[2K
| Adam | epoch: 003 | loss: 0.27182 - acc: 0.8840 -- iter: 0384/2163
[A[ATraining Step: 149  | total loss: [1m[32m0.25901[0m[0m | time: 94.266s
[2K
| Adam | epoch: 003 | loss: 0.25901 - acc: 0.8925 -- iter: 0416/2163
[A[ATraining Step: 150  | total loss: [1m[32m0.26024[0m[0m | time: 101.857s
[2K
| Adam | epoch: 003 | loss: 0.26024 - acc: 0.8907 -- iter: 0448/2163
[A[ATraining Step: 151  | total loss: [1m[32m0.26046[0m[0m | time: 109.487s
[2K
| Adam | epoch: 003 | loss: 0.26046 - acc: 0.8829 -- iter: 0480/2163
[A[ATraining Step: 152  | total loss: [1m[32m0.27964[0m[0m | time: 117.154s
[2K
| Adam | epoch: 003 | loss: 0.27964 - acc: 0.8790 -- iter: 0512/2163
[A[ATraining Step: 153  | total loss: [1m[32m0.28017[0m[0m | time: 124.811s
[2K
| Adam | epoch: 003 | loss: 0.28017 - acc: 0.8848 -- iter: 0544/2163
[A[ATraining Step: 154  | total loss: [1m[32m0.28550[0m[0m | time: 132.482s
[2K
| Adam | epoch: 003 | loss: 0.28550 - acc: 0.8839 -- iter: 0576/2163
[A[ATraining Step: 155  | total loss: [1m[32m0.27255[0m[0m | time: 140.119s
[2K
| Adam | epoch: 003 | loss: 0.27255 - acc: 0.8923 -- iter: 0608/2163
[A[ATraining Step: 156  | total loss: [1m[32m0.28660[0m[0m | time: 147.975s
[2K
| Adam | epoch: 003 | loss: 0.28660 - acc: 0.8875 -- iter: 0640/2163
[A[ATraining Step: 157  | total loss: [1m[32m0.29360[0m[0m | time: 155.665s
[2K
| Adam | epoch: 003 | loss: 0.29360 - acc: 0.8862 -- iter: 0672/2163
[A[ATraining Step: 158  | total loss: [1m[32m0.28128[0m[0m | time: 163.491s
[2K
| Adam | epoch: 003 | loss: 0.28128 - acc: 0.8882 -- iter: 0704/2163
[A[ATraining Step: 159  | total loss: [1m[32m0.27613[0m[0m | time: 171.268s
[2K
| Adam | epoch: 003 | loss: 0.27613 - acc: 0.8932 -- iter: 0736/2163
[A[ATraining Step: 160  | total loss: [1m[32m0.28028[0m[0m | time: 179.013s
[2K
| Adam | epoch: 003 | loss: 0.28028 - acc: 0.8945 -- iter: 0768/2163
[A[ATraining Step: 161  | total loss: [1m[32m0.26294[0m[0m | time: 186.631s
[2K
| Adam | epoch: 003 | loss: 0.26294 - acc: 0.9019 -- iter: 0800/2163
[A[ATraining Step: 162  | total loss: [1m[32m0.27237[0m[0m | time: 194.209s
[2K
| Adam | epoch: 003 | loss: 0.27237 - acc: 0.8961 -- iter: 0832/2163
[A[ATraining Step: 163  | total loss: [1m[32m0.28202[0m[0m | time: 201.752s
[2K
| Adam | epoch: 003 | loss: 0.28202 - acc: 0.8877 -- iter: 0864/2163
[A[ATraining Step: 164  | total loss: [1m[32m0.29033[0m[0m | time: 209.447s
[2K
| Adam | epoch: 003 | loss: 0.29033 - acc: 0.8896 -- iter: 0896/2163
[A[ATraining Step: 165  | total loss: [1m[32m0.30246[0m[0m | time: 217.189s
[2K
| Adam | epoch: 003 | loss: 0.30246 - acc: 0.8881 -- iter: 0928/2163
[A[ATraining Step: 166  | total loss: [1m[32m0.29310[0m[0m | time: 224.930s
[2K
| Adam | epoch: 003 | loss: 0.29310 - acc: 0.8931 -- iter: 0960/2163
[A[ATraining Step: 167  | total loss: [1m[32m0.27936[0m[0m | time: 232.549s
[2K
| Adam | epoch: 003 | loss: 0.27936 - acc: 0.8975 -- iter: 0992/2163
[A[ATraining Step: 168  | total loss: [1m[32m0.26991[0m[0m | time: 240.264s
[2K
| Adam | epoch: 003 | loss: 0.26991 - acc: 0.9015 -- iter: 1024/2163
[A[ATraining Step: 169  | total loss: [1m[32m0.26421[0m[0m | time: 247.970s
[2K
| Adam | epoch: 003 | loss: 0.26421 - acc: 0.9020 -- iter: 1056/2163
[A[ATraining Step: 170  | total loss: [1m[32m0.26923[0m[0m | time: 255.691s
[2K
| Adam | epoch: 003 | loss: 0.26923 - acc: 0.8930 -- iter: 1088/2163
[A[ATraining Step: 171  | total loss: [1m[32m0.26419[0m[0m | time: 263.437s
[2K
| Adam | epoch: 003 | loss: 0.26419 - acc: 0.8944 -- iter: 1120/2163
[A[ATraining Step: 172  | total loss: [1m[32m0.25715[0m[0m | time: 270.986s
[2K
| Adam | epoch: 003 | loss: 0.25715 - acc: 0.8987 -- iter: 1152/2163
[A[ATraining Step: 173  | total loss: [1m[32m0.26115[0m[0m | time: 278.671s
[2K
| Adam | epoch: 003 | loss: 0.26115 - acc: 0.8932 -- iter: 1184/2163
[A[ATraining Step: 174  | total loss: [1m[32m0.27400[0m[0m | time: 286.235s
[2K
| Adam | epoch: 003 | loss: 0.27400 - acc: 0.8882 -- iter: 1216/2163
[A[ATraining Step: 175  | total loss: [1m[32m0.26059[0m[0m | time: 293.977s
[2K
| Adam | epoch: 003 | loss: 0.26059 - acc: 0.8932 -- iter: 1248/2163
[A[ATraining Step: 176  | total loss: [1m[32m0.24423[0m[0m | time: 301.710s
[2K
| Adam | epoch: 003 | loss: 0.24423 - acc: 0.9038 -- iter: 1280/2163
[A[ATraining Step: 177  | total loss: [1m[32m0.24619[0m[0m | time: 309.259s
[2K
| Adam | epoch: 003 | loss: 0.24619 - acc: 0.9010 -- iter: 1312/2163
[A[ATraining Step: 178  | total loss: [1m[32m0.23251[0m[0m | time: 316.954s
[2K
| Adam | epoch: 003 | loss: 0.23251 - acc: 0.9077 -- iter: 1344/2163
[A[ATraining Step: 179  | total loss: [1m[32m0.21977[0m[0m | time: 324.458s
[2K
| Adam | epoch: 003 | loss: 0.21977 - acc: 0.9138 -- iter: 1376/2163
[A[ATraining Step: 180  | total loss: [1m[32m0.22148[0m[0m | time: 332.071s
[2K
| Adam | epoch: 003 | loss: 0.22148 - acc: 0.9131 -- iter: 1408/2163
[A[ATraining Step: 181  | total loss: [1m[32m0.22282[0m[0m | time: 339.736s
[2K
| Adam | epoch: 003 | loss: 0.22282 - acc: 0.9061 -- iter: 1440/2163
[A[ATraining Step: 182  | total loss: [1m[32m0.22217[0m[0m | time: 347.382s
[2K
| Adam | epoch: 003 | loss: 0.22217 - acc: 0.9062 -- iter: 1472/2163
[A[ATraining Step: 183  | total loss: [1m[32m0.21257[0m[0m | time: 354.899s
[2K
| Adam | epoch: 003 | loss: 0.21257 - acc: 0.9093 -- iter: 1504/2163
[A[ATraining Step: 184  | total loss: [1m[32m0.19606[0m[0m | time: 362.428s
[2K
| Adam | epoch: 003 | loss: 0.19606 - acc: 0.9184 -- iter: 1536/2163
[A[ATraining Step: 185  | total loss: [1m[32m0.18630[0m[0m | time: 370.167s
[2K
| Adam | epoch: 003 | loss: 0.18630 - acc: 0.9265 -- iter: 1568/2163
[A[ATraining Step: 186  | total loss: [1m[32m0.17275[0m[0m | time: 377.700s
[2K
| Adam | epoch: 003 | loss: 0.17275 - acc: 0.9339 -- iter: 1600/2163
[A[ATraining Step: 187  | total loss: [1m[32m0.17440[0m[0m | time: 385.439s
[2K
| Adam | epoch: 003 | loss: 0.17440 - acc: 0.9342 -- iter: 1632/2163
[A[ATraining Step: 188  | total loss: [1m[32m0.16329[0m[0m | time: 393.115s
[2K
| Adam | epoch: 003 | loss: 0.16329 - acc: 0.9377 -- iter: 1664/2163
[A[ATraining Step: 189  | total loss: [1m[32m0.18575[0m[0m | time: 400.662s
[2K
| Adam | epoch: 003 | loss: 0.18575 - acc: 0.9345 -- iter: 1696/2163
[A[ATraining Step: 190  | total loss: [1m[32m0.17392[0m[0m | time: 408.265s
[2K
| Adam | epoch: 003 | loss: 0.17392 - acc: 0.9380 -- iter: 1728/2163
[A[ATraining Step: 191  | total loss: [1m[32m0.17691[0m[0m | time: 415.898s
[2K
| Adam | epoch: 003 | loss: 0.17691 - acc: 0.9410 -- iter: 1760/2163
[A[ATraining Step: 192  | total loss: [1m[32m0.17497[0m[0m | time: 423.744s
[2K
| Adam | epoch: 003 | loss: 0.17497 - acc: 0.9407 -- iter: 1792/2163
[A[ATraining Step: 193  | total loss: [1m[32m0.17605[0m[0m | time: 431.418s
[2K
| Adam | epoch: 003 | loss: 0.17605 - acc: 0.9404 -- iter: 1824/2163
[A[ATraining Step: 194  | total loss: [1m[32m0.16960[0m[0m | time: 439.090s
[2K
| Adam | epoch: 003 | loss: 0.16960 - acc: 0.9401 -- iter: 1856/2163
[A[ATraining Step: 195  | total loss: [1m[32m0.16825[0m[0m | time: 446.619s
[2K
| Adam | epoch: 003 | loss: 0.16825 - acc: 0.9367 -- iter: 1888/2163
[A[ATraining Step: 196  | total loss: [1m[32m0.18755[0m[0m | time: 454.451s
[2K
| Adam | epoch: 003 | loss: 0.18755 - acc: 0.9305 -- iter: 1920/2163
[A[ATraining Step: 197  | total loss: [1m[32m0.20983[0m[0m | time: 462.168s
[2K
| Adam | epoch: 003 | loss: 0.20983 - acc: 0.9281 -- iter: 1952/2163
[A[ATraining Step: 198  | total loss: [1m[32m0.21187[0m[0m | time: 469.900s
[2K
| Adam | epoch: 003 | loss: 0.21187 - acc: 0.9259 -- iter: 1984/2163
[A[ATraining Step: 199  | total loss: [1m[32m0.21590[0m[0m | time: 477.580s
[2K
| Adam | epoch: 003 | loss: 0.21590 - acc: 0.9239 -- iter: 2016/2163
[A[ATraining Step: 200  | total loss: [1m[32m0.20668[0m[0m | time: 514.945s
[2K
| Adam | epoch: 003 | loss: 0.20668 - acc: 0.9284 | val_loss: 3.33596 - val_acc: 0.5318 -- iter: 2048/2163
--
Training Step: 201  | total loss: [1m[32m0.19780[0m[0m | time: 522.650s
[2K
| Adam | epoch: 003 | loss: 0.19780 - acc: 0.9262 -- iter: 2080/2163
[A[ATraining Step: 202  | total loss: [1m[32m0.21378[0m[0m | time: 530.310s
[2K
| Adam | epoch: 003 | loss: 0.21378 - acc: 0.9211 -- iter: 2112/2163
[A[ATraining Step: 203  | total loss: [1m[32m0.21373[0m[0m | time: 537.868s
[2K
| Adam | epoch: 003 | loss: 0.21373 - acc: 0.9196 -- iter: 2144/2163
[A[ATraining Step: 204  | total loss: [1m[32m0.21446[0m[0m | time: 574.643s
[2K
| Adam | epoch: 003 | loss: 0.21446 - acc: 0.9151 | val_loss: 3.38643 - val_acc: 0.5214 -- iter: 2163/2163
--
Training Step: 205  | total loss: [1m[32m0.22106[0m[0m | time: 7.651s
[2K
| Adam | epoch: 004 | loss: 0.22106 - acc: 0.9111 -- iter: 0032/2163
[A[ATraining Step: 206  | total loss: [1m[32m0.21727[0m[0m | time: 12.712s
[2K
| Adam | epoch: 004 | loss: 0.21727 - acc: 0.9106 -- iter: 0064/2163
[A[ATraining Step: 207  | total loss: [1m[32m0.23264[0m[0m | time: 17.793s
[2K
| Adam | epoch: 004 | loss: 0.23264 - acc: 0.9038 -- iter: 0096/2163
[A[ATraining Step: 208  | total loss: [1m[32m0.22359[0m[0m | time: 25.388s
[2K
| Adam | epoch: 004 | loss: 0.22359 - acc: 0.9029 -- iter: 0128/2163
[A[ATraining Step: 209  | total loss: [1m[32m0.21798[0m[0m | time: 32.947s
[2K
| Adam | epoch: 004 | loss: 0.21798 - acc: 0.9001 -- iter: 0160/2163
[A[ATraining Step: 210  | total loss: [1m[32m0.21600[0m[0m | time: 40.631s
[2K
| Adam | epoch: 004 | loss: 0.21600 - acc: 0.9070 -- iter: 0192/2163
[A[ATraining Step: 211  | total loss: [1m[32m0.20207[0m[0m | time: 48.257s
[2K
| Adam | epoch: 004 | loss: 0.20207 - acc: 0.9163 -- iter: 0224/2163
[A[ATraining Step: 212  | total loss: [1m[32m0.21001[0m[0m | time: 55.850s
[2K
| Adam | epoch: 004 | loss: 0.21001 - acc: 0.9153 -- iter: 0256/2163
[A[ATraining Step: 213  | total loss: [1m[32m0.21860[0m[0m | time: 63.476s
[2K
| Adam | epoch: 004 | loss: 0.21860 - acc: 0.9144 -- iter: 0288/2163
[A[ATraining Step: 214  | total loss: [1m[32m0.23860[0m[0m | time: 71.078s
[2K
| Adam | epoch: 004 | loss: 0.23860 - acc: 0.9104 -- iter: 0320/2163
[A[ATraining Step: 215  | total loss: [1m[32m0.22524[0m[0m | time: 78.674s
[2K
| Adam | epoch: 004 | loss: 0.22524 - acc: 0.9163 -- iter: 0352/2163
[A[ATraining Step: 216  | total loss: [1m[32m0.24657[0m[0m | time: 86.321s
[2K
| Adam | epoch: 004 | loss: 0.24657 - acc: 0.8965 -- iter: 0384/2163
[A[ATraining Step: 217  | total loss: [1m[32m0.23645[0m[0m | time: 93.922s
[2K
| Adam | epoch: 004 | loss: 0.23645 - acc: 0.9037 -- iter: 0416/2163
[A[ATraining Step: 218  | total loss: [1m[32m0.23673[0m[0m | time: 101.656s
[2K
| Adam | epoch: 004 | loss: 0.23673 - acc: 0.9071 -- iter: 0448/2163
[A[ATraining Step: 219  | total loss: [1m[32m0.24568[0m[0m | time: 109.199s
[2K
| Adam | epoch: 004 | loss: 0.24568 - acc: 0.9070 -- iter: 0480/2163
[A[ATraining Step: 220  | total loss: [1m[32m0.23472[0m[0m | time: 116.975s
[2K
| Adam | epoch: 004 | loss: 0.23472 - acc: 0.9101 -- iter: 0512/2163
[A[ATraining Step: 221  | total loss: [1m[32m0.22242[0m[0m | time: 124.572s
[2K
| Adam | epoch: 004 | loss: 0.22242 - acc: 0.9159 -- iter: 0544/2163
[A[ATraining Step: 222  | total loss: [1m[32m0.24001[0m[0m | time: 132.198s
[2K
| Adam | epoch: 004 | loss: 0.24001 - acc: 0.9025 -- iter: 0576/2163
[A[ATraining Step: 223  | total loss: [1m[32m0.22818[0m[0m | time: 139.899s
[2K
| Adam | epoch: 004 | loss: 0.22818 - acc: 0.9060 -- iter: 0608/2163
[A[ATraining Step: 224  | total loss: [1m[32m0.21468[0m[0m | time: 147.564s
[2K
| Adam | epoch: 004 | loss: 0.21468 - acc: 0.9154 -- iter: 0640/2163
[A[ATraining Step: 225  | total loss: [1m[32m0.21062[0m[0m | time: 155.218s
[2K
| Adam | epoch: 004 | loss: 0.21062 - acc: 0.9176 -- iter: 0672/2163
[A[ATraining Step: 226  | total loss: [1m[32m0.21860[0m[0m | time: 162.803s
[2K
| Adam | epoch: 004 | loss: 0.21860 - acc: 0.9102 -- iter: 0704/2163
[A[ATraining Step: 227  | total loss: [1m[32m0.20930[0m[0m | time: 170.356s
[2K
| Adam | epoch: 004 | loss: 0.20930 - acc: 0.9161 -- iter: 0736/2163
[A[ATraining Step: 228  | total loss: [1m[32m0.21494[0m[0m | time: 177.928s
[2K
| Adam | epoch: 004 | loss: 0.21494 - acc: 0.9151 -- iter: 0768/2163
[A[ATraining Step: 229  | total loss: [1m[32m0.20649[0m[0m | time: 185.574s
[2K
| Adam | epoch: 004 | loss: 0.20649 - acc: 0.9142 -- iter: 0800/2163
[A[ATraining Step: 230  | total loss: [1m[32m0.19569[0m[0m | time: 193.074s
[2K
| Adam | epoch: 004 | loss: 0.19569 - acc: 0.9197 -- iter: 0832/2163
[A[ATraining Step: 231  | total loss: [1m[32m0.18688[0m[0m | time: 200.710s
[2K
| Adam | epoch: 004 | loss: 0.18688 - acc: 0.9246 -- iter: 0864/2163
[A[ATraining Step: 232  | total loss: [1m[32m0.20182[0m[0m | time: 208.290s
[2K
| Adam | epoch: 004 | loss: 0.20182 - acc: 0.9165 -- iter: 0896/2163
[A[ATraining Step: 233  | total loss: [1m[32m0.20045[0m[0m | time: 215.800s
[2K
| Adam | epoch: 004 | loss: 0.20045 - acc: 0.9186 -- iter: 0928/2163
[A[ATraining Step: 234  | total loss: [1m[32m0.19044[0m[0m | time: 223.564s
[2K
| Adam | epoch: 004 | loss: 0.19044 - acc: 0.9205 -- iter: 0960/2163
[A[ATraining Step: 235  | total loss: [1m[32m0.18052[0m[0m | time: 231.195s
[2K
| Adam | epoch: 004 | loss: 0.18052 - acc: 0.9253 -- iter: 0992/2163
[A[ATraining Step: 236  | total loss: [1m[32m0.18542[0m[0m | time: 238.811s
[2K
| Adam | epoch: 004 | loss: 0.18542 - acc: 0.9171 -- iter: 1024/2163
[A[ATraining Step: 237  | total loss: [1m[32m0.18660[0m[0m | time: 246.448s
[2K
| Adam | epoch: 004 | loss: 0.18660 - acc: 0.9223 -- iter: 1056/2163
[A[ATraining Step: 238  | total loss: [1m[32m0.17301[0m[0m | time: 254.088s
[2K
| Adam | epoch: 004 | loss: 0.17301 - acc: 0.9301 -- iter: 1088/2163
[A[ATraining Step: 239  | total loss: [1m[32m0.17968[0m[0m | time: 261.709s
[2K
| Adam | epoch: 004 | loss: 0.17968 - acc: 0.9277 -- iter: 1120/2163
[A[ATraining Step: 240  | total loss: [1m[32m0.19014[0m[0m | time: 269.422s
[2K
| Adam | epoch: 004 | loss: 0.19014 - acc: 0.9255 -- iter: 1152/2163
[A[ATraining Step: 241  | total loss: [1m[32m0.17561[0m[0m | time: 277.171s
[2K
| Adam | epoch: 004 | loss: 0.17561 - acc: 0.9330 -- iter: 1184/2163
[A[ATraining Step: 242  | total loss: [1m[32m0.16372[0m[0m | time: 284.811s
[2K
| Adam | epoch: 004 | loss: 0.16372 - acc: 0.9366 -- iter: 1216/2163
[A[ATraining Step: 243  | total loss: [1m[32m0.16190[0m[0m | time: 292.556s
[2K
| Adam | epoch: 004 | loss: 0.16190 - acc: 0.9367 -- iter: 1248/2163
[A[ATraining Step: 244  | total loss: [1m[32m0.15140[0m[0m | time: 300.054s
[2K
| Adam | epoch: 004 | loss: 0.15140 - acc: 0.9430 -- iter: 1280/2163
[A[ATraining Step: 245  | total loss: [1m[32m0.18585[0m[0m | time: 307.571s
[2K
| Adam | epoch: 004 | loss: 0.18585 - acc: 0.9362 -- iter: 1312/2163
[A[ATraining Step: 246  | total loss: [1m[32m0.19971[0m[0m | time: 315.322s
[2K
| Adam | epoch: 004 | loss: 0.19971 - acc: 0.9238 -- iter: 1344/2163
[A[ATraining Step: 247  | total loss: [1m[32m0.19828[0m[0m | time: 322.920s
[2K
| Adam | epoch: 004 | loss: 0.19828 - acc: 0.9221 -- iter: 1376/2163
[A[ATraining Step: 248  | total loss: [1m[32m0.19474[0m[0m | time: 330.573s
[2K
| Adam | epoch: 004 | loss: 0.19474 - acc: 0.9267 -- iter: 1408/2163
[A[ATraining Step: 249  | total loss: [1m[32m0.18169[0m[0m | time: 338.141s
[2K
| Adam | epoch: 004 | loss: 0.18169 - acc: 0.9341 -- iter: 1440/2163
[A[ATraining Step: 250  | total loss: [1m[32m0.18085[0m[0m | time: 345.724s
[2K
| Adam | epoch: 004 | loss: 0.18085 - acc: 0.9344 -- iter: 1472/2163
[A[ATraining Step: 251  | total loss: [1m[32m0.17887[0m[0m | time: 353.372s
[2K
| Adam | epoch: 004 | loss: 0.17887 - acc: 0.9316 -- iter: 1504/2163
[A[ATraining Step: 252  | total loss: [1m[32m0.17603[0m[0m | time: 360.995s
[2K
| Adam | epoch: 004 | loss: 0.17603 - acc: 0.9322 -- iter: 1536/2163
[A[ATraining Step: 253  | total loss: [1m[32m0.16556[0m[0m | time: 368.729s
[2K
| Adam | epoch: 004 | loss: 0.16556 - acc: 0.9358 -- iter: 1568/2163
[A[ATraining Step: 254  | total loss: [1m[32m0.16705[0m[0m | time: 376.244s
[2K
| Adam | epoch: 004 | loss: 0.16705 - acc: 0.9360 -- iter: 1600/2163
[A[ATraining Step: 255  | total loss: [1m[32m0.18537[0m[0m | time: 383.861s
[2K
| Adam | epoch: 004 | loss: 0.18537 - acc: 0.9237 -- iter: 1632/2163
[A[ATraining Step: 256  | total loss: [1m[32m0.17914[0m[0m | time: 391.564s
[2K
| Adam | epoch: 004 | loss: 0.17914 - acc: 0.9282 -- iter: 1664/2163
[A[ATraining Step: 257  | total loss: [1m[32m0.17040[0m[0m | time: 399.242s
[2K
| Adam | epoch: 004 | loss: 0.17040 - acc: 0.9322 -- iter: 1696/2163
[A[ATraining Step: 258  | total loss: [1m[32m0.16165[0m[0m | time: 406.818s
[2K
| Adam | epoch: 004 | loss: 0.16165 - acc: 0.9359 -- iter: 1728/2163
[A[ATraining Step: 259  | total loss: [1m[32m0.14914[0m[0m | time: 414.499s
[2K
| Adam | epoch: 004 | loss: 0.14914 - acc: 0.9423 -- iter: 1760/2163
[A[ATraining Step: 260  | total loss: [1m[32m0.15698[0m[0m | time: 422.137s
[2K
| Adam | epoch: 004 | loss: 0.15698 - acc: 0.9418 -- iter: 1792/2163
[A[ATraining Step: 261  | total loss: [1m[32m0.15423[0m[0m | time: 429.749s
[2K
| Adam | epoch: 004 | loss: 0.15423 - acc: 0.9445 -- iter: 1824/2163
[A[ATraining Step: 262  | total loss: [1m[32m0.15856[0m[0m | time: 437.496s
[2K
| Adam | epoch: 004 | loss: 0.15856 - acc: 0.9438 -- iter: 1856/2163
[A[ATraining Step: 263  | total loss: [1m[32m0.15271[0m[0m | time: 445.060s
[2K
| Adam | epoch: 004 | loss: 0.15271 - acc: 0.9432 -- iter: 1888/2163
[A[ATraining Step: 264  | total loss: [1m[32m0.15306[0m[0m | time: 452.667s
[2K
| Adam | epoch: 004 | loss: 0.15306 - acc: 0.9395 -- iter: 1920/2163
[A[ATraining Step: 265  | total loss: [1m[32m0.15139[0m[0m | time: 460.230s
[2K
| Adam | epoch: 004 | loss: 0.15139 - acc: 0.9393 -- iter: 1952/2163
[A[ATraining Step: 266  | total loss: [1m[32m0.14607[0m[0m | time: 467.805s
[2K
| Adam | epoch: 004 | loss: 0.14607 - acc: 0.9454 -- iter: 1984/2163
[A[ATraining Step: 267  | total loss: [1m[32m0.15915[0m[0m | time: 475.366s
[2K
| Adam | epoch: 004 | loss: 0.15915 - acc: 0.9414 -- iter: 2016/2163
[A[ATraining Step: 268  | total loss: [1m[32m0.15945[0m[0m | time: 483.136s
[2K
| Adam | epoch: 004 | loss: 0.15945 - acc: 0.9379 -- iter: 2048/2163
[A[ATraining Step: 269  | total loss: [1m[32m0.15392[0m[0m | time: 490.745s
[2K
| Adam | epoch: 004 | loss: 0.15392 - acc: 0.9410 -- iter: 2080/2163
[A[ATraining Step: 270  | total loss: [1m[32m0.16196[0m[0m | time: 498.420s
[2K
| Adam | epoch: 004 | loss: 0.16196 - acc: 0.9375 -- iter: 2112/2163
[A[ATraining Step: 271  | total loss: [1m[32m0.14851[0m[0m | time: 505.899s
[2K
| Adam | epoch: 004 | loss: 0.14851 - acc: 0.9438 -- iter: 2144/2163
[A[ATraining Step: 272  | total loss: [1m[32m0.13615[0m[0m | time: 542.799s
[2K
| Adam | epoch: 004 | loss: 0.13615 - acc: 0.9494 | val_loss: 0.26768 - val_acc: 0.9129 -- iter: 2163/2163
--
Training Step: 273  | total loss: [1m[32m0.13204[0m[0m | time: 7.694s
[2K
| Adam | epoch: 005 | loss: 0.13204 - acc: 0.9513 -- iter: 0032/2163
[A[ATraining Step: 274  | total loss: [1m[32m0.12821[0m[0m | time: 15.303s
[2K
| Adam | epoch: 005 | loss: 0.12821 - acc: 0.9500 -- iter: 0064/2163
[A[ATraining Step: 275  | total loss: [1m[32m0.12297[0m[0m | time: 20.304s
[2K
| Adam | epoch: 005 | loss: 0.12297 - acc: 0.9550 -- iter: 0096/2163
[A[ATraining Step: 276  | total loss: [1m[32m0.12616[0m[0m | time: 25.408s
[2K
| Adam | epoch: 005 | loss: 0.12616 - acc: 0.9542 -- iter: 0128/2163
[A[ATraining Step: 277  | total loss: [1m[32m0.11808[0m[0m | time: 33.178s
[2K
| Adam | epoch: 005 | loss: 0.11808 - acc: 0.9588 -- iter: 0160/2163
[A[ATraining Step: 278  | total loss: [1m[32m0.11644[0m[0m | time: 40.730s
[2K
| Adam | epoch: 005 | loss: 0.11644 - acc: 0.9567 -- iter: 0192/2163
[A[ATraining Step: 279  | total loss: [1m[32m0.10743[0m[0m | time: 48.354s
[2K
| Adam | epoch: 005 | loss: 0.10743 - acc: 0.9610 -- iter: 0224/2163
[A[ATraining Step: 280  | total loss: [1m[32m0.13097[0m[0m | time: 55.936s
[2K
| Adam | epoch: 005 | loss: 0.13097 - acc: 0.9555 -- iter: 0256/2163
[A[ATraining Step: 281  | total loss: [1m[32m0.13626[0m[0m | time: 63.552s
[2K
| Adam | epoch: 005 | loss: 0.13626 - acc: 0.9537 -- iter: 0288/2163
[A[ATraining Step: 282  | total loss: [1m[32m0.13230[0m[0m | time: 71.242s
[2K
| Adam | epoch: 005 | loss: 0.13230 - acc: 0.9552 -- iter: 0320/2163
[A[ATraining Step: 283  | total loss: [1m[32m0.16853[0m[0m | time: 79.062s
[2K
| Adam | epoch: 005 | loss: 0.16853 - acc: 0.9316 -- iter: 0352/2163
[A[ATraining Step: 284  | total loss: [1m[32m0.15472[0m[0m | time: 86.829s
[2K
| Adam | epoch: 005 | loss: 0.15472 - acc: 0.9384 -- iter: 0384/2163
[A[ATraining Step: 285  | total loss: [1m[32m0.14150[0m[0m | time: 94.455s
[2K
| Adam | epoch: 005 | loss: 0.14150 - acc: 0.9446 -- iter: 0416/2163
[A[ATraining Step: 286  | total loss: [1m[32m0.13899[0m[0m | time: 102.149s
[2K
| Adam | epoch: 005 | loss: 0.13899 - acc: 0.9470 -- iter: 0448/2163
[A[ATraining Step: 287  | total loss: [1m[32m0.14307[0m[0m | time: 109.750s
[2K
| Adam | epoch: 005 | loss: 0.14307 - acc: 0.9460 -- iter: 0480/2163
[A[ATraining Step: 288  | total loss: [1m[32m0.14130[0m[0m | time: 117.287s
[2K
| Adam | epoch: 005 | loss: 0.14130 - acc: 0.9483 -- iter: 0512/2163
[A[ATraining Step: 289  | total loss: [1m[32m0.14471[0m[0m | time: 125.021s
[2K
| Adam | epoch: 005 | loss: 0.14471 - acc: 0.9441 -- iter: 0544/2163
[A[ATraining Step: 290  | total loss: [1m[32m0.15496[0m[0m | time: 132.462s
[2K
| Adam | epoch: 005 | loss: 0.15496 - acc: 0.9466 -- iter: 0576/2163
[A[ATraining Step: 291  | total loss: [1m[32m0.15461[0m[0m | time: 140.314s
[2K
| Adam | epoch: 005 | loss: 0.15461 - acc: 0.9425 -- iter: 0608/2163
[A[ATraining Step: 292  | total loss: [1m[32m0.17064[0m[0m | time: 148.001s
[2K
| Adam | epoch: 005 | loss: 0.17064 - acc: 0.9389 -- iter: 0640/2163
[A[ATraining Step: 293  | total loss: [1m[32m0.16745[0m[0m | time: 155.659s
[2K
| Adam | epoch: 005 | loss: 0.16745 - acc: 0.9356 -- iter: 0672/2163
[A[ATraining Step: 294  | total loss: [1m[32m0.15567[0m[0m | time: 163.306s
[2K
| Adam | epoch: 005 | loss: 0.15567 - acc: 0.9421 -- iter: 0704/2163
[A[ATraining Step: 295  | total loss: [1m[32m0.15095[0m[0m | time: 170.928s
[2K
| Adam | epoch: 005 | loss: 0.15095 - acc: 0.9416 -- iter: 0736/2163
[A[ATraining Step: 296  | total loss: [1m[32m0.15288[0m[0m | time: 178.503s
[2K
| Adam | epoch: 005 | loss: 0.15288 - acc: 0.9443 -- iter: 0768/2163
[A[ATraining Step: 297  | total loss: [1m[32m0.14804[0m[0m | time: 186.066s
[2K
| Adam | epoch: 005 | loss: 0.14804 - acc: 0.9468 -- iter: 0800/2163
[A[ATraining Step: 298  | total loss: [1m[32m0.14717[0m[0m | time: 193.637s
[2K
| Adam | epoch: 005 | loss: 0.14717 - acc: 0.9458 -- iter: 0832/2163
[A[ATraining Step: 299  | total loss: [1m[32m0.15119[0m[0m | time: 201.207s
[2K
| Adam | epoch: 005 | loss: 0.15119 - acc: 0.9419 -- iter: 0864/2163
[A[ATraining Step: 300  | total loss: [1m[32m0.15586[0m[0m | time: 208.753s
[2K
| Adam | epoch: 005 | loss: 0.15586 - acc: 0.9383 -- iter: 0896/2163
[A[ATraining Step: 301  | total loss: [1m[32m0.14511[0m[0m | time: 216.554s
[2K
| Adam | epoch: 005 | loss: 0.14511 - acc: 0.9445 -- iter: 0928/2163
[A[ATraining Step: 302  | total loss: [1m[32m0.13706[0m[0m | time: 224.058s
[2K
| Adam | epoch: 005 | loss: 0.13706 - acc: 0.9469 -- iter: 0960/2163
[A[ATraining Step: 303  | total loss: [1m[32m0.15333[0m[0m | time: 231.687s
[2K
| Adam | epoch: 005 | loss: 0.15333 - acc: 0.9429 -- iter: 0992/2163
[A[ATraining Step: 304  | total loss: [1m[32m0.15426[0m[0m | time: 239.288s
[2K
| Adam | epoch: 005 | loss: 0.15426 - acc: 0.9392 -- iter: 1024/2163
[A[ATraining Step: 305  | total loss: [1m[32m0.14952[0m[0m | time: 246.890s
[2K
| Adam | epoch: 005 | loss: 0.14952 - acc: 0.9421 -- iter: 1056/2163
[A[ATraining Step: 306  | total loss: [1m[32m0.14020[0m[0m | time: 254.462s
[2K
| Adam | epoch: 005 | loss: 0.14020 - acc: 0.9479 -- iter: 1088/2163
[A[ATraining Step: 307  | total loss: [1m[32m0.13339[0m[0m | time: 262.009s
[2K
| Adam | epoch: 005 | loss: 0.13339 - acc: 0.9500 -- iter: 1120/2163
[A[ATraining Step: 308  | total loss: [1m[32m0.13075[0m[0m | time: 269.655s
[2K
| Adam | epoch: 005 | loss: 0.13075 - acc: 0.9519 -- iter: 1152/2163
[A[ATraining Step: 309  | total loss: [1m[32m0.13435[0m[0m | time: 277.315s
[2K
| Adam | epoch: 005 | loss: 0.13435 - acc: 0.9504 -- iter: 1184/2163
[A[ATraining Step: 310  | total loss: [1m[32m0.13512[0m[0m | time: 285.014s
[2K
| Adam | epoch: 005 | loss: 0.13512 - acc: 0.9492 -- iter: 1216/2163
[A[ATraining Step: 311  | total loss: [1m[32m0.12873[0m[0m | time: 292.599s
[2K
| Adam | epoch: 005 | loss: 0.12873 - acc: 0.9480 -- iter: 1248/2163
[A[ATraining Step: 312  | total loss: [1m[32m0.12386[0m[0m | time: 300.227s
[2K
| Adam | epoch: 005 | loss: 0.12386 - acc: 0.9532 -- iter: 1280/2163
[A[ATraining Step: 313  | total loss: [1m[32m0.16637[0m[0m | time: 307.806s
[2K
| Adam | epoch: 005 | loss: 0.16637 - acc: 0.9485 -- iter: 1312/2163
[A[ATraining Step: 314  | total loss: [1m[32m0.15567[0m[0m | time: 315.384s
[2K
| Adam | epoch: 005 | loss: 0.15567 - acc: 0.9505 -- iter: 1344/2163
[A[ATraining Step: 315  | total loss: [1m[32m0.14653[0m[0m | time: 322.973s
[2K
| Adam | epoch: 005 | loss: 0.14653 - acc: 0.9555 -- iter: 1376/2163
[A[ATraining Step: 316  | total loss: [1m[32m0.13484[0m[0m | time: 330.563s
[2K
| Adam | epoch: 005 | loss: 0.13484 - acc: 0.9599 -- iter: 1408/2163
[A[ATraining Step: 317  | total loss: [1m[32m0.12809[0m[0m | time: 338.032s
[2K
| Adam | epoch: 005 | loss: 0.12809 - acc: 0.9639 -- iter: 1440/2163
[A[ATraining Step: 318  | total loss: [1m[32m0.13376[0m[0m | time: 345.899s
[2K
| Adam | epoch: 005 | loss: 0.13376 - acc: 0.9613 -- iter: 1472/2163
[A[ATraining Step: 319  | total loss: [1m[32m0.12266[0m[0m | time: 353.496s
[2K
| Adam | epoch: 005 | loss: 0.12266 - acc: 0.9652 -- iter: 1504/2163
[A[ATraining Step: 320  | total loss: [1m[32m0.11714[0m[0m | time: 361.111s
[2K
| Adam | epoch: 005 | loss: 0.11714 - acc: 0.9655 -- iter: 1536/2163
[A[ATraining Step: 321  | total loss: [1m[32m0.11444[0m[0m | time: 368.814s
[2K
| Adam | epoch: 005 | loss: 0.11444 - acc: 0.9658 -- iter: 1568/2163
[A[ATraining Step: 322  | total loss: [1m[32m0.10895[0m[0m | time: 376.453s
[2K
| Adam | epoch: 005 | loss: 0.10895 - acc: 0.9661 -- iter: 1600/2163
[A[ATraining Step: 323  | total loss: [1m[32m0.10016[0m[0m | time: 384.160s
[2K
| Adam | epoch: 005 | loss: 0.10016 - acc: 0.9695 -- iter: 1632/2163
[A[ATraining Step: 324  | total loss: [1m[32m0.09393[0m[0m | time: 391.774s
[2K
| Adam | epoch: 005 | loss: 0.09393 - acc: 0.9694 -- iter: 1664/2163
[A[ATraining Step: 325  | total loss: [1m[32m0.08617[0m[0m | time: 399.528s
[2K
| Adam | epoch: 005 | loss: 0.08617 - acc: 0.9725 -- iter: 1696/2163
[A[ATraining Step: 326  | total loss: [1m[32m0.08586[0m[0m | time: 407.218s
[2K
| Adam | epoch: 005 | loss: 0.08586 - acc: 0.9721 -- iter: 1728/2163
[A[ATraining Step: 327  | total loss: [1m[32m0.08063[0m[0m | time: 414.921s
[2K
| Adam | epoch: 005 | loss: 0.08063 - acc: 0.9749 -- iter: 1760/2163
[A[ATraining Step: 328  | total loss: [1m[32m0.07518[0m[0m | time: 422.592s
[2K
| Adam | epoch: 005 | loss: 0.07518 - acc: 0.9774 -- iter: 1792/2163
[A[ATraining Step: 329  | total loss: [1m[32m0.06958[0m[0m | time: 430.117s
[2K
| Adam | epoch: 005 | loss: 0.06958 - acc: 0.9797 -- iter: 1824/2163
[A[ATraining Step: 330  | total loss: [1m[32m0.06773[0m[0m | time: 437.830s
[2K
| Adam | epoch: 005 | loss: 0.06773 - acc: 0.9786 -- iter: 1856/2163
[A[ATraining Step: 331  | total loss: [1m[32m0.06921[0m[0m | time: 445.474s
[2K
| Adam | epoch: 005 | loss: 0.06921 - acc: 0.9776 -- iter: 1888/2163
[A[ATraining Step: 332  | total loss: [1m[32m0.09304[0m[0m | time: 453.099s
[2K
| Adam | epoch: 005 | loss: 0.09304 - acc: 0.9673 -- iter: 1920/2163
[A[ATraining Step: 333  | total loss: [1m[32m0.09141[0m[0m | time: 460.828s
[2K
| Adam | epoch: 005 | loss: 0.09141 - acc: 0.9675 -- iter: 1952/2163
[A[ATraining Step: 334  | total loss: [1m[32m0.08733[0m[0m | time: 468.529s
[2K
| Adam | epoch: 005 | loss: 0.08733 - acc: 0.9676 -- iter: 1984/2163
[A[ATraining Step: 335  | total loss: [1m[32m0.09421[0m[0m | time: 476.209s
[2K
| Adam | epoch: 005 | loss: 0.09421 - acc: 0.9583 -- iter: 2016/2163
[A[ATraining Step: 336  | total loss: [1m[32m0.08885[0m[0m | time: 483.793s
[2K
| Adam | epoch: 005 | loss: 0.08885 - acc: 0.9625 -- iter: 2048/2163
[A[ATraining Step: 337  | total loss: [1m[32m0.12402[0m[0m | time: 491.421s
[2K
| Adam | epoch: 005 | loss: 0.12402 - acc: 0.9444 -- iter: 2080/2163
[A[ATraining Step: 338  | total loss: [1m[32m0.15162[0m[0m | time: 499.092s
[2K
| Adam | epoch: 005 | loss: 0.15162 - acc: 0.9343 -- iter: 2112/2163
[A[ATraining Step: 339  | total loss: [1m[32m0.14259[0m[0m | time: 506.638s
[2K
| Adam | epoch: 005 | loss: 0.14259 - acc: 0.9378 -- iter: 2144/2163
[A[ATraining Step: 340  | total loss: [1m[32m0.13119[0m[0m | time: 543.623s
[2K
| Adam | epoch: 005 | loss: 0.13119 - acc: 0.9440 | val_loss: 4.11049 - val_acc: 0.5022 -- iter: 2163/2163
--
Training Step: 341  | total loss: [1m[32m0.14005[0m[0m | time: 7.607s
[2K
| Adam | epoch: 006 | loss: 0.14005 - acc: 0.9402 -- iter: 0032/2163
[A[ATraining Step: 342  | total loss: [1m[32m0.14968[0m[0m | time: 15.238s
[2K
| Adam | epoch: 006 | loss: 0.14968 - acc: 0.9399 -- iter: 0064/2163
[A[ATraining Step: 343  | total loss: [1m[32m0.16327[0m[0m | time: 22.674s
[2K
| Adam | epoch: 006 | loss: 0.16327 - acc: 0.9334 -- iter: 0096/2163
[A[ATraining Step: 344  | total loss: [1m[32m0.16330[0m[0m | time: 27.650s
[2K
| Adam | epoch: 006 | loss: 0.16330 - acc: 0.9370 -- iter: 0128/2163
[A[ATraining Step: 345  | total loss: [1m[32m0.15838[0m[0m | time: 32.624s
[2K
| Adam | epoch: 006 | loss: 0.15838 - acc: 0.9380 -- iter: 0160/2163
[A[ATraining Step: 346  | total loss: [1m[32m0.14510[0m[0m | time: 40.312s
[2K
| Adam | epoch: 006 | loss: 0.14510 - acc: 0.9442 -- iter: 0192/2163
[A[ATraining Step: 347  | total loss: [1m[32m0.13943[0m[0m | time: 47.968s
[2K
| Adam | epoch: 006 | loss: 0.13943 - acc: 0.9435 -- iter: 0224/2163
[A[ATraining Step: 348  | total loss: [1m[32m0.13063[0m[0m | time: 55.617s
[2K
| Adam | epoch: 006 | loss: 0.13063 - acc: 0.9492 -- iter: 0256/2163
[A[ATraining Step: 349  | total loss: [1m[32m0.12270[0m[0m | time: 63.226s
[2K
| Adam | epoch: 006 | loss: 0.12270 - acc: 0.9543 -- iter: 0288/2163
[A[ATraining Step: 350  | total loss: [1m[32m0.12016[0m[0m | time: 70.781s
[2K
| Adam | epoch: 006 | loss: 0.12016 - acc: 0.9557 -- iter: 0320/2163
[A[ATraining Step: 351  | total loss: [1m[32m0.12913[0m[0m | time: 78.397s
[2K
| Adam | epoch: 006 | loss: 0.12913 - acc: 0.9476 -- iter: 0352/2163
[A[ATraining Step: 352  | total loss: [1m[32m0.12224[0m[0m | time: 86.057s
[2K
| Adam | epoch: 006 | loss: 0.12224 - acc: 0.9498 -- iter: 0384/2163
[A[ATraining Step: 353  | total loss: [1m[32m0.12515[0m[0m | time: 93.788s
[2K
| Adam | epoch: 006 | loss: 0.12515 - acc: 0.9454 -- iter: 0416/2163
[A[ATraining Step: 354  | total loss: [1m[32m0.11627[0m[0m | time: 101.404s
[2K
| Adam | epoch: 006 | loss: 0.11627 - acc: 0.9509 -- iter: 0448/2163
[A[ATraining Step: 355  | total loss: [1m[32m0.11468[0m[0m | time: 109.101s
[2K
| Adam | epoch: 006 | loss: 0.11468 - acc: 0.9495 -- iter: 0480/2163
[A[ATraining Step: 356  | total loss: [1m[32m0.11734[0m[0m | time: 116.822s
[2K
| Adam | epoch: 006 | loss: 0.11734 - acc: 0.9483 -- iter: 0512/2163
[A[ATraining Step: 357  | total loss: [1m[32m0.11519[0m[0m | time: 124.301s
[2K
| Adam | epoch: 006 | loss: 0.11519 - acc: 0.9504 -- iter: 0544/2163
[A[ATraining Step: 358  | total loss: [1m[32m0.11329[0m[0m | time: 132.074s
[2K
| Adam | epoch: 006 | loss: 0.11329 - acc: 0.9491 -- iter: 0576/2163
[A[ATraining Step: 359  | total loss: [1m[32m0.10650[0m[0m | time: 139.586s
[2K
| Adam | epoch: 006 | loss: 0.10650 - acc: 0.9510 -- iter: 0608/2163
[A[ATraining Step: 360  | total loss: [1m[32m0.10799[0m[0m | time: 147.294s
[2K
| Adam | epoch: 006 | loss: 0.10799 - acc: 0.9497 -- iter: 0640/2163
[A[ATraining Step: 361  | total loss: [1m[32m0.11234[0m[0m | time: 154.890s
[2K
| Adam | epoch: 006 | loss: 0.11234 - acc: 0.9485 -- iter: 0672/2163
[A[ATraining Step: 362  | total loss: [1m[32m0.10520[0m[0m | time: 162.679s
[2K
| Adam | epoch: 006 | loss: 0.10520 - acc: 0.9505 -- iter: 0704/2163
[A[ATraining Step: 363  | total loss: [1m[32m0.10576[0m[0m | time: 170.399s
[2K
| Adam | epoch: 006 | loss: 0.10576 - acc: 0.9523 -- iter: 0736/2163
[A[ATraining Step: 364  | total loss: [1m[32m0.10656[0m[0m | time: 178.082s
[2K
| Adam | epoch: 006 | loss: 0.10656 - acc: 0.9508 -- iter: 0768/2163
[A[ATraining Step: 365  | total loss: [1m[32m0.09676[0m[0m | time: 185.718s
[2K
| Adam | epoch: 006 | loss: 0.09676 - acc: 0.9558 -- iter: 0800/2163
[A[ATraining Step: 366  | total loss: [1m[32m0.09484[0m[0m | time: 193.365s
[2K
| Adam | epoch: 006 | loss: 0.09484 - acc: 0.9571 -- iter: 0832/2163
[A[ATraining Step: 367  | total loss: [1m[32m0.08570[0m[0m | time: 200.930s
[2K
| Adam | epoch: 006 | loss: 0.08570 - acc: 0.9614 -- iter: 0864/2163
[A[ATraining Step: 368  | total loss: [1m[32m0.10732[0m[0m | time: 208.621s
[2K
| Adam | epoch: 006 | loss: 0.10732 - acc: 0.9527 -- iter: 0896/2163
[A[ATraining Step: 369  | total loss: [1m[32m0.11427[0m[0m | time: 216.348s
[2K
| Adam | epoch: 006 | loss: 0.11427 - acc: 0.9481 -- iter: 0928/2163
[A[ATraining Step: 370  | total loss: [1m[32m0.11390[0m[0m | time: 224.067s
[2K
| Adam | epoch: 006 | loss: 0.11390 - acc: 0.9501 -- iter: 0960/2163
[A[ATraining Step: 371  | total loss: [1m[32m0.12850[0m[0m | time: 231.666s
[2K
| Adam | epoch: 006 | loss: 0.12850 - acc: 0.9489 -- iter: 0992/2163
[A[ATraining Step: 372  | total loss: [1m[32m0.12342[0m[0m | time: 239.326s
[2K
| Adam | epoch: 006 | loss: 0.12342 - acc: 0.9540 -- iter: 1024/2163
[A[ATraining Step: 373  | total loss: [1m[32m0.11323[0m[0m | time: 246.973s
[2K
| Adam | epoch: 006 | loss: 0.11323 - acc: 0.9586 -- iter: 1056/2163
[A[ATraining Step: 374  | total loss: [1m[32m0.10858[0m[0m | time: 254.579s
[2K
| Adam | epoch: 006 | loss: 0.10858 - acc: 0.9596 -- iter: 1088/2163
[A[ATraining Step: 375  | total loss: [1m[32m0.10009[0m[0m | time: 262.340s
[2K
| Adam | epoch: 006 | loss: 0.10009 - acc: 0.9636 -- iter: 1120/2163
[A[ATraining Step: 376  | total loss: [1m[32m0.11399[0m[0m | time: 269.821s
[2K
| Adam | epoch: 006 | loss: 0.11399 - acc: 0.9548 -- iter: 1152/2163
[A[ATraining Step: 377  | total loss: [1m[32m0.11370[0m[0m | time: 277.542s
[2K
| Adam | epoch: 006 | loss: 0.11370 - acc: 0.9531 -- iter: 1184/2163
[A[ATraining Step: 378  | total loss: [1m[32m0.11623[0m[0m | time: 285.143s
[2K
| Adam | epoch: 006 | loss: 0.11623 - acc: 0.9515 -- iter: 1216/2163
[A[ATraining Step: 379  | total loss: [1m[32m0.11491[0m[0m | time: 292.672s
[2K
| Adam | epoch: 006 | loss: 0.11491 - acc: 0.9532 -- iter: 1248/2163
[A[ATraining Step: 380  | total loss: [1m[32m0.13664[0m[0m | time: 300.203s
[2K
| Adam | epoch: 006 | loss: 0.13664 - acc: 0.9454 -- iter: 1280/2163
[A[ATraining Step: 381  | total loss: [1m[32m0.15128[0m[0m | time: 307.740s
[2K
| Adam | epoch: 006 | loss: 0.15128 - acc: 0.9415 -- iter: 1312/2163
[A[ATraining Step: 382  | total loss: [1m[32m0.13860[0m[0m | time: 315.276s
[2K
| Adam | epoch: 006 | loss: 0.13860 - acc: 0.9473 -- iter: 1344/2163
[A[ATraining Step: 383  | total loss: [1m[32m0.12981[0m[0m | time: 322.946s
[2K
| Adam | epoch: 006 | loss: 0.12981 - acc: 0.9526 -- iter: 1376/2163
[A[ATraining Step: 384  | total loss: [1m[32m0.12303[0m[0m | time: 330.638s
[2K
| Adam | epoch: 006 | loss: 0.12303 - acc: 0.9542 -- iter: 1408/2163
[A[ATraining Step: 385  | total loss: [1m[32m0.12436[0m[0m | time: 338.300s
[2K
| Adam | epoch: 006 | loss: 0.12436 - acc: 0.9525 -- iter: 1440/2163
[A[ATraining Step: 386  | total loss: [1m[32m0.11423[0m[0m | time: 345.835s
[2K
| Adam | epoch: 006 | loss: 0.11423 - acc: 0.9573 -- iter: 1472/2163
[A[ATraining Step: 387  | total loss: [1m[32m0.10436[0m[0m | time: 353.409s
[2K
| Adam | epoch: 006 | loss: 0.10436 - acc: 0.9616 -- iter: 1504/2163
[A[ATraining Step: 388  | total loss: [1m[32m0.11299[0m[0m | time: 360.960s
[2K
| Adam | epoch: 006 | loss: 0.11299 - acc: 0.9529 -- iter: 1536/2163
[A[ATraining Step: 389  | total loss: [1m[32m0.10864[0m[0m | time: 368.497s
[2K
| Adam | epoch: 006 | loss: 0.10864 - acc: 0.9545 -- iter: 1568/2163
[A[ATraining Step: 390  | total loss: [1m[32m0.10601[0m[0m | time: 376.061s
[2K
| Adam | epoch: 006 | loss: 0.10601 - acc: 0.9559 -- iter: 1600/2163
[A[ATraining Step: 391  | total loss: [1m[32m0.10447[0m[0m | time: 383.747s
[2K
| Adam | epoch: 006 | loss: 0.10447 - acc: 0.9541 -- iter: 1632/2163
[A[ATraining Step: 392  | total loss: [1m[32m0.09891[0m[0m | time: 391.365s
[2K
| Adam | epoch: 006 | loss: 0.09891 - acc: 0.9587 -- iter: 1664/2163
[A[ATraining Step: 393  | total loss: [1m[32m0.11715[0m[0m | time: 399.070s
[2K
| Adam | epoch: 006 | loss: 0.11715 - acc: 0.9503 -- iter: 1696/2163
[A[ATraining Step: 394  | total loss: [1m[32m0.11139[0m[0m | time: 406.542s
[2K
| Adam | epoch: 006 | loss: 0.11139 - acc: 0.9521 -- iter: 1728/2163
[A[ATraining Step: 395  | total loss: [1m[32m0.11411[0m[0m | time: 414.282s
[2K
| Adam | epoch: 006 | loss: 0.11411 - acc: 0.9507 -- iter: 1760/2163
[A[ATraining Step: 396  | total loss: [1m[32m0.11168[0m[0m | time: 421.858s
[2K
| Adam | epoch: 006 | loss: 0.11168 - acc: 0.9525 -- iter: 1792/2163
[A[ATraining Step: 397  | total loss: [1m[32m0.10375[0m[0m | time: 429.524s
[2K
| Adam | epoch: 006 | loss: 0.10375 - acc: 0.9572 -- iter: 1824/2163
[A[ATraining Step: 398  | total loss: [1m[32m0.11241[0m[0m | time: 437.498s
[2K
| Adam | epoch: 006 | loss: 0.11241 - acc: 0.9490 -- iter: 1856/2163
[A[ATraining Step: 399  | total loss: [1m[32m0.10997[0m[0m | time: 445.036s
[2K
| Adam | epoch: 006 | loss: 0.10997 - acc: 0.9479 -- iter: 1888/2163
[A[ATraining Step: 400  | total loss: [1m[32m0.11515[0m[0m | time: 481.905s
[2K
| Adam | epoch: 006 | loss: 0.11515 - acc: 0.9500 | val_loss: 0.33915 - val_acc: 0.8671 -- iter: 1920/2163
--
Training Step: 401  | total loss: [1m[32m0.10854[0m[0m | time: 489.638s
[2K
| Adam | epoch: 006 | loss: 0.10854 - acc: 0.9550 -- iter: 1952/2163
[A[ATraining Step: 402  | total loss: [1m[32m0.11043[0m[0m | time: 497.169s
[2K
| Adam | epoch: 006 | loss: 0.11043 - acc: 0.9532 -- iter: 1984/2163
[A[ATraining Step: 403  | total loss: [1m[32m0.10231[0m[0m | time: 504.971s
[2K
| Adam | epoch: 006 | loss: 0.10231 - acc: 0.9579 -- iter: 2016/2163
[A[ATraining Step: 404  | total loss: [1m[32m0.09611[0m[0m | time: 512.521s
[2K
| Adam | epoch: 006 | loss: 0.09611 - acc: 0.9621 -- iter: 2048/2163
[A[ATraining Step: 405  | total loss: [1m[32m0.09009[0m[0m | time: 520.166s
[2K
| Adam | epoch: 006 | loss: 0.09009 - acc: 0.9659 -- iter: 2080/2163
[A[ATraining Step: 406  | total loss: [1m[32m0.10697[0m[0m | time: 527.744s
[2K
| Adam | epoch: 006 | loss: 0.10697 - acc: 0.9599 -- iter: 2112/2163
[A[ATraining Step: 407  | total loss: [1m[32m0.09722[0m[0m | time: 535.254s
[2K
| Adam | epoch: 006 | loss: 0.09722 - acc: 0.9639 -- iter: 2144/2163
[A[ATraining Step: 408  | total loss: [1m[32m0.08889[0m[0m | time: 572.297s
[2K
| Adam | epoch: 006 | loss: 0.08889 - acc: 0.9675 | val_loss: 0.43604 - val_acc: 0.8316 -- iter: 2163/2163
--
Training Step: 409  | total loss: [1m[32m0.08940[0m[0m | time: 7.624s
[2K
| Adam | epoch: 007 | loss: 0.08940 - acc: 0.9645 -- iter: 0032/2163
[A[ATraining Step: 410  | total loss: [1m[32m0.08471[0m[0m | time: 15.324s
[2K
| Adam | epoch: 007 | loss: 0.08471 - acc: 0.9681 -- iter: 0064/2163
[A[ATraining Step: 411  | total loss: [1m[32m0.07778[0m[0m | time: 23.027s
[2K
| Adam | epoch: 007 | loss: 0.07778 - acc: 0.9713 -- iter: 0096/2163
[A[ATraining Step: 412  | total loss: [1m[32m0.07601[0m[0m | time: 30.574s
[2K
| Adam | epoch: 007 | loss: 0.07601 - acc: 0.9710 -- iter: 0128/2163
[A[ATraining Step: 413  | total loss: [1m[32m0.11045[0m[0m | time: 35.556s
[2K
| Adam | epoch: 007 | loss: 0.11045 - acc: 0.9552 -- iter: 0160/2163
[A[ATraining Step: 414  | total loss: [1m[32m0.10883[0m[0m | time: 40.691s
[2K
| Adam | epoch: 007 | loss: 0.10883 - acc: 0.9544 -- iter: 0192/2163
[A[ATraining Step: 415  | total loss: [1m[32m0.10061[0m[0m | time: 48.255s
[2K
| Adam | epoch: 007 | loss: 0.10061 - acc: 0.9590 -- iter: 0224/2163
[A[ATraining Step: 416  | total loss: [1m[32m0.09348[0m[0m | time: 55.780s
[2K
| Adam | epoch: 007 | loss: 0.09348 - acc: 0.9631 -- iter: 0256/2163
[A[ATraining Step: 417  | total loss: [1m[32m0.09525[0m[0m | time: 63.383s
[2K
| Adam | epoch: 007 | loss: 0.09525 - acc: 0.9605 -- iter: 0288/2163
[A[ATraining Step: 418  | total loss: [1m[32m0.09620[0m[0m | time: 70.825s
[2K
| Adam | epoch: 007 | loss: 0.09620 - acc: 0.9582 -- iter: 0320/2163
[A[ATraining Step: 419  | total loss: [1m[32m0.11015[0m[0m | time: 78.488s
[2K
| Adam | epoch: 007 | loss: 0.11015 - acc: 0.9561 -- iter: 0352/2163
[A[ATraining Step: 420  | total loss: [1m[32m0.10486[0m[0m | time: 86.008s
[2K
| Adam | epoch: 007 | loss: 0.10486 - acc: 0.9574 -- iter: 0384/2163
[A[ATraining Step: 421  | total loss: [1m[32m0.10203[0m[0m | time: 93.547s
[2K
| Adam | epoch: 007 | loss: 0.10203 - acc: 0.9554 -- iter: 0416/2163
[A[ATraining Step: 422  | total loss: [1m[32m0.11975[0m[0m | time: 101.266s
[2K
| Adam | epoch: 007 | loss: 0.11975 - acc: 0.9474 -- iter: 0448/2163
[A[ATraining Step: 423  | total loss: [1m[32m0.11591[0m[0m | time: 108.952s
[2K
| Adam | epoch: 007 | loss: 0.11591 - acc: 0.9526 -- iter: 0480/2163
[A[ATraining Step: 424  | total loss: [1m[32m0.10667[0m[0m | time: 116.756s
[2K
| Adam | epoch: 007 | loss: 0.10667 - acc: 0.9574 -- iter: 0512/2163
[A[ATraining Step: 425  | total loss: [1m[32m0.10545[0m[0m | time: 124.420s
[2K
| Adam | epoch: 007 | loss: 0.10545 - acc: 0.9554 -- iter: 0544/2163
[A[ATraining Step: 426  | total loss: [1m[32m0.09932[0m[0m | time: 132.033s
[2K
| Adam | epoch: 007 | loss: 0.09932 - acc: 0.9598 -- iter: 0576/2163
[A[ATraining Step: 427  | total loss: [1m[32m0.09277[0m[0m | time: 139.505s
[2K
| Adam | epoch: 007 | loss: 0.09277 - acc: 0.9639 -- iter: 0608/2163
[A[ATraining Step: 428  | total loss: [1m[32m0.08545[0m[0m | time: 147.143s
[2K
| Adam | epoch: 007 | loss: 0.08545 - acc: 0.9675 -- iter: 0640/2163
[A[ATraining Step: 429  | total loss: [1m[32m0.08121[0m[0m | time: 154.793s
[2K
| Adam | epoch: 007 | loss: 0.08121 - acc: 0.9707 -- iter: 0672/2163
[A[ATraining Step: 430  | total loss: [1m[32m0.08386[0m[0m | time: 162.401s
[2K
| Adam | epoch: 007 | loss: 0.08386 - acc: 0.9674 -- iter: 0704/2163
[A[ATraining Step: 431  | total loss: [1m[32m0.07841[0m[0m | time: 170.168s
[2K
| Adam | epoch: 007 | loss: 0.07841 - acc: 0.9707 -- iter: 0736/2163
[A[ATraining Step: 432  | total loss: [1m[32m0.07846[0m[0m | time: 177.778s
[2K
| Adam | epoch: 007 | loss: 0.07846 - acc: 0.9673 -- iter: 0768/2163
[A[ATraining Step: 433  | total loss: [1m[32m0.08323[0m[0m | time: 185.320s
[2K
| Adam | epoch: 007 | loss: 0.08323 - acc: 0.9675 -- iter: 0800/2163
[A[ATraining Step: 434  | total loss: [1m[32m0.08500[0m[0m | time: 192.972s
[2K
| Adam | epoch: 007 | loss: 0.08500 - acc: 0.9645 -- iter: 0832/2163
[A[ATraining Step: 435  | total loss: [1m[32m0.07741[0m[0m | time: 200.683s
[2K
| Adam | epoch: 007 | loss: 0.07741 - acc: 0.9680 -- iter: 0864/2163
[A[ATraining Step: 436  | total loss: [1m[32m0.10139[0m[0m | time: 208.322s
[2K
| Adam | epoch: 007 | loss: 0.10139 - acc: 0.9650 -- iter: 0896/2163
[A[ATraining Step: 437  | total loss: [1m[32m0.09614[0m[0m | time: 216.047s
[2K
| Adam | epoch: 007 | loss: 0.09614 - acc: 0.9685 -- iter: 0928/2163
[A[ATraining Step: 438  | total loss: [1m[32m0.09486[0m[0m | time: 223.846s
[2K
| Adam | epoch: 007 | loss: 0.09486 - acc: 0.9654 -- iter: 0960/2163
[A[ATraining Step: 439  | total loss: [1m[32m0.08983[0m[0m | time: 231.441s
[2K
| Adam | epoch: 007 | loss: 0.08983 - acc: 0.9657 -- iter: 0992/2163
[A[ATraining Step: 440  | total loss: [1m[32m0.11201[0m[0m | time: 239.132s
[2K
| Adam | epoch: 007 | loss: 0.11201 - acc: 0.9504 -- iter: 1024/2163
[A[ATraining Step: 441  | total loss: [1m[32m0.10334[0m[0m | time: 246.796s
[2K
| Adam | epoch: 007 | loss: 0.10334 - acc: 0.9554 -- iter: 1056/2163
[A[ATraining Step: 442  | total loss: [1m[32m0.09683[0m[0m | time: 254.465s
[2K
| Adam | epoch: 007 | loss: 0.09683 - acc: 0.9598 -- iter: 1088/2163
[A[ATraining Step: 443  | total loss: [1m[32m0.09246[0m[0m | time: 262.035s
[2K
| Adam | epoch: 007 | loss: 0.09246 - acc: 0.9607 -- iter: 1120/2163
[A[ATraining Step: 444  | total loss: [1m[32m0.08729[0m[0m | time: 269.535s
[2K
| Adam | epoch: 007 | loss: 0.08729 - acc: 0.9646 -- iter: 1152/2163
[A[ATraining Step: 445  | total loss: [1m[32m0.08113[0m[0m | time: 277.190s
[2K
| Adam | epoch: 007 | loss: 0.08113 - acc: 0.9682 -- iter: 1184/2163
[A[ATraining Step: 446  | total loss: [1m[32m0.07501[0m[0m | time: 284.830s
[2K
| Adam | epoch: 007 | loss: 0.07501 - acc: 0.9714 -- iter: 1216/2163
[A[ATraining Step: 447  | total loss: [1m[32m0.08105[0m[0m | time: 292.525s
[2K
| Adam | epoch: 007 | loss: 0.08105 - acc: 0.9649 -- iter: 1248/2163
[A[ATraining Step: 448  | total loss: [1m[32m0.08142[0m[0m | time: 300.291s
[2K
| Adam | epoch: 007 | loss: 0.08142 - acc: 0.9621 -- iter: 1280/2163
[A[ATraining Step: 449  | total loss: [1m[32m0.08919[0m[0m | time: 307.931s
[2K
| Adam | epoch: 007 | loss: 0.08919 - acc: 0.9565 -- iter: 1312/2163
[A[ATraining Step: 450  | total loss: [1m[32m0.09914[0m[0m | time: 315.694s
[2K
| Adam | epoch: 007 | loss: 0.09914 - acc: 0.9546 -- iter: 1344/2163
[A[ATraining Step: 451  | total loss: [1m[32m0.13556[0m[0m | time: 323.211s
[2K
| Adam | epoch: 007 | loss: 0.13556 - acc: 0.9529 -- iter: 1376/2163
[A[ATraining Step: 452  | total loss: [1m[32m0.12595[0m[0m | time: 330.876s
[2K
| Adam | epoch: 007 | loss: 0.12595 - acc: 0.9576 -- iter: 1408/2163
[A[ATraining Step: 453  | total loss: [1m[32m0.11821[0m[0m | time: 338.701s
[2K
| Adam | epoch: 007 | loss: 0.11821 - acc: 0.9619 -- iter: 1440/2163
[A[ATraining Step: 454  | total loss: [1m[32m0.10928[0m[0m | time: 346.416s
[2K
| Adam | epoch: 007 | loss: 0.10928 - acc: 0.9657 -- iter: 1472/2163
[A[ATraining Step: 455  | total loss: [1m[32m0.10317[0m[0m | time: 354.201s
[2K
| Adam | epoch: 007 | loss: 0.10317 - acc: 0.9660 -- iter: 1504/2163
[A[ATraining Step: 456  | total loss: [1m[32m0.09321[0m[0m | time: 362.044s
[2K
| Adam | epoch: 007 | loss: 0.09321 - acc: 0.9694 -- iter: 1536/2163
[A[ATraining Step: 457  | total loss: [1m[32m0.09116[0m[0m | time: 369.766s
[2K
| Adam | epoch: 007 | loss: 0.09116 - acc: 0.9693 -- iter: 1568/2163
[A[ATraining Step: 458  | total loss: [1m[32m0.08429[0m[0m | time: 377.429s
[2K
| Adam | epoch: 007 | loss: 0.08429 - acc: 0.9724 -- iter: 1600/2163
[A[ATraining Step: 459  | total loss: [1m[32m0.09135[0m[0m | time: 385.119s
[2K
| Adam | epoch: 007 | loss: 0.09135 - acc: 0.9689 -- iter: 1632/2163
[A[ATraining Step: 460  | total loss: [1m[32m0.08911[0m[0m | time: 392.912s
[2K
| Adam | epoch: 007 | loss: 0.08911 - acc: 0.9720 -- iter: 1664/2163
[A[ATraining Step: 461  | total loss: [1m[32m0.08164[0m[0m | time: 400.647s
[2K
| Adam | epoch: 007 | loss: 0.08164 - acc: 0.9748 -- iter: 1696/2163
[A[ATraining Step: 462  | total loss: [1m[32m0.08039[0m[0m | time: 408.350s
[2K
| Adam | epoch: 007 | loss: 0.08039 - acc: 0.9742 -- iter: 1728/2163
[A[ATraining Step: 463  | total loss: [1m[32m0.08811[0m[0m | time: 416.081s
[2K
| Adam | epoch: 007 | loss: 0.08811 - acc: 0.9737 -- iter: 1760/2163
[A[ATraining Step: 464  | total loss: [1m[32m0.09803[0m[0m | time: 423.705s
[2K
| Adam | epoch: 007 | loss: 0.09803 - acc: 0.9700 -- iter: 1792/2163
[A[ATraining Step: 465  | total loss: [1m[32m0.09397[0m[0m | time: 431.508s
[2K
| Adam | epoch: 007 | loss: 0.09397 - acc: 0.9730 -- iter: 1824/2163
[A[ATraining Step: 466  | total loss: [1m[32m0.08545[0m[0m | time: 439.219s
[2K
| Adam | epoch: 007 | loss: 0.08545 - acc: 0.9757 -- iter: 1856/2163
[A[ATraining Step: 467  | total loss: [1m[32m0.07911[0m[0m | time: 446.923s
[2K
| Adam | epoch: 007 | loss: 0.07911 - acc: 0.9782 -- iter: 1888/2163
[A[ATraining Step: 468  | total loss: [1m[32m0.08093[0m[0m | time: 454.494s
[2K
| Adam | epoch: 007 | loss: 0.08093 - acc: 0.9772 -- iter: 1920/2163
[A[ATraining Step: 469  | total loss: [1m[32m0.07567[0m[0m | time: 462.199s
[2K
| Adam | epoch: 007 | loss: 0.07567 - acc: 0.9795 -- iter: 1952/2163
[A[ATraining Step: 470  | total loss: [1m[32m0.07546[0m[0m | time: 469.929s
[2K
| Adam | epoch: 007 | loss: 0.07546 - acc: 0.9784 -- iter: 1984/2163
[A[ATraining Step: 471  | total loss: [1m[32m0.07050[0m[0m | time: 477.520s
[2K
| Adam | epoch: 007 | loss: 0.07050 - acc: 0.9806 -- iter: 2016/2163
[A[ATraining Step: 472  | total loss: [1m[32m0.07902[0m[0m | time: 485.343s
[2K
| Adam | epoch: 007 | loss: 0.07902 - acc: 0.9763 -- iter: 2048/2163
[A[ATraining Step: 473  | total loss: [1m[32m0.07816[0m[0m | time: 492.907s
[2K
| Adam | epoch: 007 | loss: 0.07816 - acc: 0.9786 -- iter: 2080/2163
[A[ATraining Step: 474  | total loss: [1m[32m0.07369[0m[0m | time: 500.565s
[2K
| Adam | epoch: 007 | loss: 0.07369 - acc: 0.9777 -- iter: 2112/2163
[A[ATraining Step: 475  | total loss: [1m[32m0.07430[0m[0m | time: 508.183s
[2K
| Adam | epoch: 007 | loss: 0.07430 - acc: 0.9768 -- iter: 2144/2163
[A[ATraining Step: 476  | total loss: [1m[32m0.06778[0m[0m | time: 545.338s
[2K
| Adam | epoch: 007 | loss: 0.06778 - acc: 0.9791 | val_loss: 0.82091 - val_acc: 0.7459 -- iter: 2163/2163
--
Training Step: 477  | total loss: [1m[32m0.06195[0m[0m | time: 7.578s
[2K
| Adam | epoch: 008 | loss: 0.06195 - acc: 0.9812 -- iter: 0032/2163
[A[ATraining Step: 478  | total loss: [1m[32m0.06197[0m[0m | time: 15.178s
[2K
| Adam | epoch: 008 | loss: 0.06197 - acc: 0.9799 -- iter: 0064/2163
[A[ATraining Step: 479  | total loss: [1m[32m0.05678[0m[0m | time: 22.813s
[2K
| Adam | epoch: 008 | loss: 0.05678 - acc: 0.9819 -- iter: 0096/2163
[A[ATraining Step: 480  | total loss: [1m[32m0.05263[0m[0m | time: 30.360s
[2K
| Adam | epoch: 008 | loss: 0.05263 - acc: 0.9837 -- iter: 0128/2163
[A[ATraining Step: 481  | total loss: [1m[32m0.05219[0m[0m | time: 38.147s
[2K
| Adam | epoch: 008 | loss: 0.05219 - acc: 0.9854 -- iter: 0160/2163
[A[ATraining Step: 482  | total loss: [1m[32m0.04945[0m[0m | time: 43.163s
[2K
| Adam | epoch: 008 | loss: 0.04945 - acc: 0.9868 -- iter: 0192/2163
[A[ATraining Step: 483  | total loss: [1m[32m0.05754[0m[0m | time: 48.185s
[2K
| Adam | epoch: 008 | loss: 0.05754 - acc: 0.9829 -- iter: 0224/2163
[A[ATraining Step: 484  | total loss: [1m[32m0.05432[0m[0m | time: 55.841s
[2K
| Adam | epoch: 008 | loss: 0.05432 - acc: 0.9846 -- iter: 0256/2163
[A[ATraining Step: 485  | total loss: [1m[32m0.06500[0m[0m | time: 63.363s
[2K
| Adam | epoch: 008 | loss: 0.06500 - acc: 0.9799 -- iter: 0288/2163
[A[ATraining Step: 486  | total loss: [1m[32m0.06341[0m[0m | time: 71.124s
[2K
| Adam | epoch: 008 | loss: 0.06341 - acc: 0.9819 -- iter: 0320/2163
[A[ATraining Step: 487  | total loss: [1m[32m0.06199[0m[0m | time: 78.767s
[2K
| Adam | epoch: 008 | loss: 0.06199 - acc: 0.9806 -- iter: 0352/2163
[A[ATraining Step: 488  | total loss: [1m[32m0.05787[0m[0m | time: 86.289s
[2K
| Adam | epoch: 008 | loss: 0.05787 - acc: 0.9825 -- iter: 0384/2163
[A[ATraining Step: 489  | total loss: [1m[32m0.06292[0m[0m | time: 93.963s
[2K
| Adam | epoch: 008 | loss: 0.06292 - acc: 0.9780 -- iter: 0416/2163
[A[ATraining Step: 490  | total loss: [1m[32m0.05887[0m[0m | time: 101.633s
[2K
| Adam | epoch: 008 | loss: 0.05887 - acc: 0.9802 -- iter: 0448/2163
[A[ATraining Step: 491  | total loss: [1m[32m0.05365[0m[0m | time: 109.352s
[2K
| Adam | epoch: 008 | loss: 0.05365 - acc: 0.9822 -- iter: 0480/2163
[A[ATraining Step: 492  | total loss: [1m[32m0.05181[0m[0m | time: 116.837s
[2K
| Adam | epoch: 008 | loss: 0.05181 - acc: 0.9840 -- iter: 0512/2163
[A[ATraining Step: 493  | total loss: [1m[32m0.07809[0m[0m | time: 124.636s
[2K
| Adam | epoch: 008 | loss: 0.07809 - acc: 0.9762 -- iter: 0544/2163
[A[ATraining Step: 494  | total loss: [1m[32m0.07185[0m[0m | time: 132.352s
[2K
| Adam | epoch: 008 | loss: 0.07185 - acc: 0.9786 -- iter: 0576/2163
[A[ATraining Step: 495  | total loss: [1m[32m0.06651[0m[0m | time: 139.924s
[2K
| Adam | epoch: 008 | loss: 0.06651 - acc: 0.9807 -- iter: 0608/2163
[A[ATraining Step: 496  | total loss: [1m[32m0.06695[0m[0m | time: 147.541s
[2K
| Adam | epoch: 008 | loss: 0.06695 - acc: 0.9764 -- iter: 0640/2163
[A[ATraining Step: 497  | total loss: [1m[32m0.08540[0m[0m | time: 155.057s
[2K
| Adam | epoch: 008 | loss: 0.08540 - acc: 0.9756 -- iter: 0672/2163
[A[ATraining Step: 498  | total loss: [1m[32m0.08128[0m[0m | time: 163.141s
[2K
| Adam | epoch: 008 | loss: 0.08128 - acc: 0.9781 -- iter: 0704/2163
[A[ATraining Step: 499  | total loss: [1m[32m0.10450[0m[0m | time: 170.915s
[2K
| Adam | epoch: 008 | loss: 0.10450 - acc: 0.9615 -- iter: 0736/2163
[A[ATraining Step: 500  | total loss: [1m[32m0.10159[0m[0m | time: 178.505s
[2K
| Adam | epoch: 008 | loss: 0.10159 - acc: 0.9591 -- iter: 0768/2163
[A[ATraining Step: 501  | total loss: [1m[32m0.09390[0m[0m | time: 186.054s
[2K
| Adam | epoch: 008 | loss: 0.09390 - acc: 0.9632 -- iter: 0800/2163
[A[ATraining Step: 502  | total loss: [1m[32m0.08904[0m[0m | time: 193.698s
[2K
| Adam | epoch: 008 | loss: 0.08904 - acc: 0.9669 -- iter: 0832/2163
[A[ATraining Step: 503  | total loss: [1m[32m0.08849[0m[0m | time: 201.355s
[2K
| Adam | epoch: 008 | loss: 0.08849 - acc: 0.9671 -- iter: 0864/2163
[A[ATraining Step: 504  | total loss: [1m[32m0.08104[0m[0m | time: 208.974s
[2K
| Adam | epoch: 008 | loss: 0.08104 - acc: 0.9704 -- iter: 0896/2163
[A[ATraining Step: 505  | total loss: [1m[32m0.07832[0m[0m | time: 216.506s
[2K
| Adam | epoch: 008 | loss: 0.07832 - acc: 0.9702 -- iter: 0928/2163
[A[ATraining Step: 506  | total loss: [1m[32m0.09225[0m[0m | time: 224.096s
[2K
| Adam | epoch: 008 | loss: 0.09225 - acc: 0.9669 -- iter: 0960/2163
[A[ATraining Step: 507  | total loss: [1m[32m0.08680[0m[0m | time: 231.794s
[2K
| Adam | epoch: 008 | loss: 0.08680 - acc: 0.9702 -- iter: 0992/2163
[A[ATraining Step: 508  | total loss: [1m[32m0.08023[0m[0m | time: 239.471s
[2K
| Adam | epoch: 008 | loss: 0.08023 - acc: 0.9732 -- iter: 1024/2163
[A[ATraining Step: 509  | total loss: [1m[32m0.07381[0m[0m | time: 247.138s
[2K
| Adam | epoch: 008 | loss: 0.07381 - acc: 0.9759 -- iter: 1056/2163
[A[ATraining Step: 510  | total loss: [1m[32m0.08560[0m[0m | time: 254.855s
[2K
| Adam | epoch: 008 | loss: 0.08560 - acc: 0.9721 -- iter: 1088/2163
[A[ATraining Step: 511  | total loss: [1m[32m0.07789[0m[0m | time: 262.588s
[2K
| Adam | epoch: 008 | loss: 0.07789 - acc: 0.9748 -- iter: 1120/2163
[A[ATraining Step: 512  | total loss: [1m[32m0.07378[0m[0m | time: 270.256s
[2K
| Adam | epoch: 008 | loss: 0.07378 - acc: 0.9774 -- iter: 1152/2163
[A[ATraining Step: 513  | total loss: [1m[32m0.06860[0m[0m | time: 277.773s
[2K
| Adam | epoch: 008 | loss: 0.06860 - acc: 0.9796 -- iter: 1184/2163
[A[ATraining Step: 514  | total loss: [1m[32m0.07330[0m[0m | time: 285.511s
[2K
| Adam | epoch: 008 | loss: 0.07330 - acc: 0.9723 -- iter: 1216/2163
[A[ATraining Step: 515  | total loss: [1m[32m0.06815[0m[0m | time: 293.125s
[2K
| Adam | epoch: 008 | loss: 0.06815 - acc: 0.9751 -- iter: 1248/2163
[A[ATraining Step: 516  | total loss: [1m[32m0.06393[0m[0m | time: 300.766s
[2K
| Adam | epoch: 008 | loss: 0.06393 - acc: 0.9776 -- iter: 1280/2163
[A[ATraining Step: 517  | total loss: [1m[32m0.05960[0m[0m | time: 308.466s
[2K
| Adam | epoch: 008 | loss: 0.05960 - acc: 0.9798 -- iter: 1312/2163
[A[ATraining Step: 518  | total loss: [1m[32m0.05406[0m[0m | time: 316.054s
[2K
| Adam | epoch: 008 | loss: 0.05406 - acc: 0.9818 -- iter: 1344/2163
[A[ATraining Step: 519  | total loss: [1m[32m0.07638[0m[0m | time: 323.768s
[2K
| Adam | epoch: 008 | loss: 0.07638 - acc: 0.9774 -- iter: 1376/2163
[A[ATraining Step: 520  | total loss: [1m[32m0.09513[0m[0m | time: 331.397s
[2K
| Adam | epoch: 008 | loss: 0.09513 - acc: 0.9765 -- iter: 1408/2163
[A[ATraining Step: 521  | total loss: [1m[32m0.10085[0m[0m | time: 339.041s
[2K
| Adam | epoch: 008 | loss: 0.10085 - acc: 0.9757 -- iter: 1440/2163
[A[ATraining Step: 522  | total loss: [1m[32m0.10291[0m[0m | time: 346.658s
[2K
| Adam | epoch: 008 | loss: 0.10291 - acc: 0.9719 -- iter: 1472/2163
[A[ATraining Step: 523  | total loss: [1m[32m0.10639[0m[0m | time: 354.200s
[2K
| Adam | epoch: 008 | loss: 0.10639 - acc: 0.9716 -- iter: 1504/2163
[A[ATraining Step: 524  | total loss: [1m[32m0.09920[0m[0m | time: 361.727s
[2K
| Adam | epoch: 008 | loss: 0.09920 - acc: 0.9744 -- iter: 1536/2163
[A[ATraining Step: 525  | total loss: [1m[32m0.09375[0m[0m | time: 369.300s
[2K
| Adam | epoch: 008 | loss: 0.09375 - acc: 0.9739 -- iter: 1568/2163
[A[ATraining Step: 526  | total loss: [1m[32m0.10027[0m[0m | time: 377.008s
[2K
| Adam | epoch: 008 | loss: 0.10027 - acc: 0.9702 -- iter: 1600/2163
[A[ATraining Step: 527  | total loss: [1m[32m0.09157[0m[0m | time: 384.653s
[2K
| Adam | epoch: 008 | loss: 0.09157 - acc: 0.9732 -- iter: 1632/2163
[A[ATraining Step: 528  | total loss: [1m[32m0.08331[0m[0m | time: 392.325s
[2K
| Adam | epoch: 008 | loss: 0.08331 - acc: 0.9759 -- iter: 1664/2163
[A[ATraining Step: 529  | total loss: [1m[32m0.07734[0m[0m | time: 399.900s
[2K
| Adam | epoch: 008 | loss: 0.07734 - acc: 0.9783 -- iter: 1696/2163
[A[ATraining Step: 530  | total loss: [1m[32m0.08919[0m[0m | time: 407.971s
[2K
| Adam | epoch: 008 | loss: 0.08919 - acc: 0.9742 -- iter: 1728/2163
[A[ATraining Step: 531  | total loss: [1m[32m0.08104[0m[0m | time: 415.577s
[2K
| Adam | epoch: 008 | loss: 0.08104 - acc: 0.9768 -- iter: 1760/2163
[A[ATraining Step: 532  | total loss: [1m[32m0.09101[0m[0m | time: 423.260s
[2K
| Adam | epoch: 008 | loss: 0.09101 - acc: 0.9697 -- iter: 1792/2163
[A[ATraining Step: 533  | total loss: [1m[32m0.08337[0m[0m | time: 430.933s
[2K
| Adam | epoch: 008 | loss: 0.08337 - acc: 0.9728 -- iter: 1824/2163
[A[ATraining Step: 534  | total loss: [1m[32m0.08259[0m[0m | time: 438.767s
[2K
| Adam | epoch: 008 | loss: 0.08259 - acc: 0.9755 -- iter: 1856/2163
[A[ATraining Step: 535  | total loss: [1m[32m0.07643[0m[0m | time: 446.598s
[2K
| Adam | epoch: 008 | loss: 0.07643 - acc: 0.9779 -- iter: 1888/2163
[A[ATraining Step: 536  | total loss: [1m[32m0.07032[0m[0m | time: 454.229s
[2K
| Adam | epoch: 008 | loss: 0.07032 - acc: 0.9801 -- iter: 1920/2163
[A[ATraining Step: 537  | total loss: [1m[32m0.07939[0m[0m | time: 461.861s
[2K
| Adam | epoch: 008 | loss: 0.07939 - acc: 0.9790 -- iter: 1952/2163
[A[ATraining Step: 538  | total loss: [1m[32m0.07444[0m[0m | time: 469.433s
[2K
| Adam | epoch: 008 | loss: 0.07444 - acc: 0.9811 -- iter: 1984/2163
[A[ATraining Step: 539  | total loss: [1m[32m0.07389[0m[0m | time: 477.207s
[2K
| Adam | epoch: 008 | loss: 0.07389 - acc: 0.9799 -- iter: 2016/2163
[A[ATraining Step: 540  | total loss: [1m[32m0.07058[0m[0m | time: 484.714s
[2K
| Adam | epoch: 008 | loss: 0.07058 - acc: 0.9819 -- iter: 2048/2163
[A[ATraining Step: 541  | total loss: [1m[32m0.06772[0m[0m | time: 492.348s
[2K
| Adam | epoch: 008 | loss: 0.06772 - acc: 0.9806 -- iter: 2080/2163
[A[ATraining Step: 542  | total loss: [1m[32m0.07623[0m[0m | time: 500.112s
[2K
| Adam | epoch: 008 | loss: 0.07623 - acc: 0.9731 -- iter: 2112/2163
[A[ATraining Step: 543  | total loss: [1m[32m0.07012[0m[0m | time: 507.719s
[2K
| Adam | epoch: 008 | loss: 0.07012 - acc: 0.9758 -- iter: 2144/2163
[A[ATraining Step: 544  | total loss: [1m[32m0.06563[0m[0m | time: 545.089s
[2K
| Adam | epoch: 008 | loss: 0.06563 - acc: 0.9782 | val_loss: 0.30372 - val_acc: 0.9040 -- iter: 2163/2163
--
Training Step: 545  | total loss: [1m[32m0.06031[0m[0m | time: 7.653s
[2K
| Adam | epoch: 009 | loss: 0.06031 - acc: 0.9804 -- iter: 0032/2163
[A[ATraining Step: 546  | total loss: [1m[32m0.05530[0m[0m | time: 15.193s
[2K
| Adam | epoch: 009 | loss: 0.05530 - acc: 0.9824 -- iter: 0064/2163
[A[ATraining Step: 547  | total loss: [1m[32m0.05063[0m[0m | time: 22.804s
[2K
| Adam | epoch: 009 | loss: 0.05063 - acc: 0.9841 -- iter: 0096/2163
[A[ATraining Step: 548  | total loss: [1m[32m0.04667[0m[0m | time: 30.380s
[2K
| Adam | epoch: 009 | loss: 0.04667 - acc: 0.9857 -- iter: 0128/2163
[A[ATraining Step: 549  | total loss: [1m[32m0.04355[0m[0m | time: 38.018s
[2K
| Adam | epoch: 009 | loss: 0.04355 - acc: 0.9872 -- iter: 0160/2163
[A[ATraining Step: 550  | total loss: [1m[32m0.04059[0m[0m | time: 45.756s
[2K
| Adam | epoch: 009 | loss: 0.04059 - acc: 0.9884 -- iter: 0192/2163
[A[ATraining Step: 551  | total loss: [1m[32m0.03901[0m[0m | time: 50.737s
[2K
| Adam | epoch: 009 | loss: 0.03901 - acc: 0.9896 -- iter: 0224/2163
[A[ATraining Step: 552  | total loss: [1m[32m0.04009[0m[0m | time: 55.837s
[2K
| Adam | epoch: 009 | loss: 0.04009 - acc: 0.9906 -- iter: 0256/2163
[A[ATraining Step: 553  | total loss: [1m[32m0.03774[0m[0m | time: 63.456s
[2K
| Adam | epoch: 009 | loss: 0.03774 - acc: 0.9916 -- iter: 0288/2163
[A[ATraining Step: 554  | total loss: [1m[32m0.03866[0m[0m | time: 75.850s
[2K
| Adam | epoch: 009 | loss: 0.03866 - acc: 0.9893 -- iter: 0320/2163
[A[ATraining Step: 555  | total loss: [1m[32m0.03664[0m[0m | time: 87.788s
[2K
| Adam | epoch: 009 | loss: 0.03664 - acc: 0.9904 -- iter: 0352/2163
[A[ATraining Step: 556  | total loss: [1m[32m0.04148[0m[0m | time: 100.371s
[2K
| Adam | epoch: 009 | loss: 0.04148 - acc: 0.9882 -- iter: 0384/2163
[A[ATraining Step: 557  | total loss: [1m[32m0.03863[0m[0m | time: 113.273s
[2K
| Adam | epoch: 009 | loss: 0.03863 - acc: 0.9894 -- iter: 0416/2163
[A[ATraining Step: 558  | total loss: [1m[32m0.04260[0m[0m | time: 125.683s
[2K
| Adam | epoch: 009 | loss: 0.04260 - acc: 0.9873 -- iter: 0448/2163
[A[ATraining Step: 559  | total loss: [1m[32m0.03973[0m[0m | time: 138.118s
[2K
| Adam | epoch: 009 | loss: 0.03973 - acc: 0.9886 -- iter: 0480/2163
[A[ATraining Step: 560  | total loss: [1m[32m0.03998[0m[0m | time: 149.424s
[2K
| Adam | epoch: 009 | loss: 0.03998 - acc: 0.9897 -- iter: 0512/2163
[A[ATraining Step: 561  | total loss: [1m[32m0.03699[0m[0m | time: 157.158s
[2K
| Adam | epoch: 009 | loss: 0.03699 - acc: 0.9908 -- iter: 0544/2163
[A[ATraining Step: 562  | total loss: [1m[32m0.03540[0m[0m | time: 167.039s
[2K
| Adam | epoch: 009 | loss: 0.03540 - acc: 0.9917 -- iter: 0576/2163
[A[ATraining Step: 563  | total loss: [1m[32m0.03223[0m[0m | time: 174.757s
[2K
| Adam | epoch: 009 | loss: 0.03223 - acc: 0.9925 -- iter: 0608/2163
[A[ATraining Step: 564  | total loss: [1m[32m0.04839[0m[0m | time: 182.358s
[2K
| Adam | epoch: 009 | loss: 0.04839 - acc: 0.9839 -- iter: 0640/2163
[A[ATraining Step: 565  | total loss: [1m[32m0.04464[0m[0m | time: 190.020s
[2K
| Adam | epoch: 009 | loss: 0.04464 - acc: 0.9855 -- iter: 0672/2163
[A[ATraining Step: 566  | total loss: [1m[32m0.04058[0m[0m | time: 197.490s
[2K
| Adam | epoch: 009 | loss: 0.04058 - acc: 0.9869 -- iter: 0704/2163
[A[ATraining Step: 567  | total loss: [1m[32m0.03788[0m[0m | time: 208.339s
[2K
| Adam | epoch: 009 | loss: 0.03788 - acc: 0.9883 -- iter: 0736/2163
[A[ATraining Step: 568  | total loss: [1m[32m0.04938[0m[0m | time: 221.048s
[2K
| Adam | epoch: 009 | loss: 0.04938 - acc: 0.9863 -- iter: 0768/2163
[A[ATraining Step: 569  | total loss: [1m[32m0.04626[0m[0m | time: 233.945s
[2K
| Adam | epoch: 009 | loss: 0.04626 - acc: 0.9877 -- iter: 0800/2163
[A[ATraining Step: 570  | total loss: [1m[32m0.04866[0m[0m | time: 246.798s
[2K
| Adam | epoch: 009 | loss: 0.04866 - acc: 0.9858 -- iter: 0832/2163
[A[ATraining Step: 571  | total loss: [1m[32m0.05815[0m[0m | time: 259.229s
[2K
| Adam | epoch: 009 | loss: 0.05815 - acc: 0.9841 -- iter: 0864/2163
[A[ATraining Step: 572  | total loss: [1m[32m0.05960[0m[0m | time: 271.801s
[2K
| Adam | epoch: 009 | loss: 0.05960 - acc: 0.9825 -- iter: 0896/2163
[A[ATraining Step: 573  | total loss: [1m[32m0.05846[0m[0m | time: 285.110s
[2K
| Adam | epoch: 009 | loss: 0.05846 - acc: 0.9843 -- iter: 0928/2163
[A[ATraining Step: 574  | total loss: [1m[32m0.05567[0m[0m | time: 293.068s
[2K
| Adam | epoch: 009 | loss: 0.05567 - acc: 0.9827 -- iter: 0960/2163
[A[ATraining Step: 575  | total loss: [1m[32m0.05238[0m[0m | time: 300.758s
[2K
| Adam | epoch: 009 | loss: 0.05238 - acc: 0.9845 -- iter: 0992/2163
[A[ATraining Step: 576  | total loss: [1m[32m0.05040[0m[0m | time: 308.475s
[2K
| Adam | epoch: 009 | loss: 0.05040 - acc: 0.9860 -- iter: 1024/2163
[A[ATraining Step: 577  | total loss: [1m[32m0.04781[0m[0m | time: 320.612s
[2K
| Adam | epoch: 009 | loss: 0.04781 - acc: 0.9874 -- iter: 1056/2163
[A[ATraining Step: 578  | total loss: [1m[32m0.04512[0m[0m | time: 332.819s
[2K
| Adam | epoch: 009 | loss: 0.04512 - acc: 0.9887 -- iter: 1088/2163
[A[ATraining Step: 579  | total loss: [1m[32m0.05832[0m[0m | time: 345.142s
[2K
| Adam | epoch: 009 | loss: 0.05832 - acc: 0.9836 -- iter: 1120/2163
[A[ATraining Step: 580  | total loss: [1m[32m0.05940[0m[0m | time: 357.838s
[2K
| Adam | epoch: 009 | loss: 0.05940 - acc: 0.9821 -- iter: 1152/2163
[A[ATraining Step: 581  | total loss: [1m[32m0.06147[0m[0m | time: 370.605s
[2K
| Adam | epoch: 009 | loss: 0.06147 - acc: 0.9807 -- iter: 1184/2163
[A[ATraining Step: 582  | total loss: [1m[32m0.05738[0m[0m | time: 383.308s
[2K
| Adam | epoch: 009 | loss: 0.05738 - acc: 0.9827 -- iter: 1216/2163
[A[ATraining Step: 583  | total loss: [1m[32m0.05378[0m[0m | time: 394.572s
[2K
| Adam | epoch: 009 | loss: 0.05378 - acc: 0.9844 -- iter: 1248/2163
[A[ATraining Step: 584  | total loss: [1m[32m0.05499[0m[0m | time: 402.279s
[2K
| Adam | epoch: 009 | loss: 0.05499 - acc: 0.9828 -- iter: 1280/2163
[A[ATraining Step: 585  | total loss: [1m[32m0.05134[0m[0m | time: 410.013s
[2K
| Adam | epoch: 009 | loss: 0.05134 - acc: 0.9846 -- iter: 1312/2163
[A[ATraining Step: 586  | total loss: [1m[32m0.04869[0m[0m | time: 418.682s
[2K
| Adam | epoch: 009 | loss: 0.04869 - acc: 0.9861 -- iter: 1344/2163
[A[ATraining Step: 587  | total loss: [1m[32m0.05084[0m[0m | time: 431.519s
[2K
| Adam | epoch: 009 | loss: 0.05084 - acc: 0.9844 -- iter: 1376/2163
[A[ATraining Step: 588  | total loss: [1m[32m0.04980[0m[0m | time: 443.718s
[2K
| Adam | epoch: 009 | loss: 0.04980 - acc: 0.9859 -- iter: 1408/2163
[A[ATraining Step: 589  | total loss: [1m[32m0.07277[0m[0m | time: 456.747s
[2K
| Adam | epoch: 009 | loss: 0.07277 - acc: 0.9842 -- iter: 1440/2163
[A[ATraining Step: 590  | total loss: [1m[32m0.06637[0m[0m | time: 469.566s
[2K
| Adam | epoch: 009 | loss: 0.06637 - acc: 0.9858 -- iter: 1472/2163
[A[ATraining Step: 591  | total loss: [1m[32m0.06048[0m[0m | time: 482.432s
[2K
| Adam | epoch: 009 | loss: 0.06048 - acc: 0.9872 -- iter: 1504/2163
[A[ATraining Step: 592  | total loss: [1m[32m0.06201[0m[0m | time: 495.399s
[2K
| Adam | epoch: 009 | loss: 0.06201 - acc: 0.9822 -- iter: 1536/2163
[A[ATraining Step: 593  | total loss: [1m[32m0.05642[0m[0m | time: 507.377s
[2K
| Adam | epoch: 009 | loss: 0.05642 - acc: 0.9840 -- iter: 1568/2163
[A[ATraining Step: 594  | total loss: [1m[32m0.05127[0m[0m | time: 519.204s
[2K
| Adam | epoch: 009 | loss: 0.05127 - acc: 0.9856 -- iter: 1600/2163
[A[ATraining Step: 595  | total loss: [1m[32m0.04677[0m[0m | time: 532.745s
[2K
| Adam | epoch: 009 | loss: 0.04677 - acc: 0.9871 -- iter: 1632/2163
[A[ATraining Step: 596  | total loss: [1m[32m0.04569[0m[0m | time: 550.359s
[2K
| Adam | epoch: 009 | loss: 0.04569 - acc: 0.9883 -- iter: 1664/2163
[A[ATraining Step: 597  | total loss: [1m[32m0.04332[0m[0m | time: 567.905s
[2K
| Adam | epoch: 009 | loss: 0.04332 - acc: 0.9895 -- iter: 1696/2163
[A[ATraining Step: 598  | total loss: [1m[32m0.04126[0m[0m | time: 585.113s
[2K
| Adam | epoch: 009 | loss: 0.04126 - acc: 0.9906 -- iter: 1728/2163
[A[ATraining Step: 599  | total loss: [1m[32m0.03836[0m[0m | time: 602.695s
[2K
| Adam | epoch: 009 | loss: 0.03836 - acc: 0.9915 -- iter: 1760/2163
[A[ATraining Step: 600  | total loss: [1m[32m0.03606[0m[0m | time: 672.311s
[2K
| Adam | epoch: 009 | loss: 0.03606 - acc: 0.9924 | val_loss: 0.20311 - val_acc: 0.9276 -- iter: 1792/2163
--
Training Step: 601  | total loss: [1m[32m0.03613[0m[0m | time: 684.716s
[2K
| Adam | epoch: 009 | loss: 0.03613 - acc: 0.9900 -- iter: 1824/2163
[A[ATraining Step: 602  | total loss: [1m[32m0.03467[0m[0m | time: 698.742s
[2K
| Adam | epoch: 009 | loss: 0.03467 - acc: 0.9910 -- iter: 1856/2163
[A[ATraining Step: 603  | total loss: [1m[32m0.03766[0m[0m | time: 716.028s
[2K
| Adam | epoch: 009 | loss: 0.03766 - acc: 0.9888 -- iter: 1888/2163
[A[ATraining Step: 604  | total loss: [1m[32m0.03847[0m[0m | time: 733.613s
[2K
| Adam | epoch: 009 | loss: 0.03847 - acc: 0.9899 -- iter: 1920/2163
[A[ATraining Step: 605  | total loss: [1m[32m0.03499[0m[0m | time: 747.669s
[2K
| Adam | epoch: 009 | loss: 0.03499 - acc: 0.9909 -- iter: 1952/2163
[A[ATraining Step: 606  | total loss: [1m[32m0.03190[0m[0m | time: 760.643s
[2K
| Adam | epoch: 009 | loss: 0.03190 - acc: 0.9918 -- iter: 1984/2163
[A[ATraining Step: 607  | total loss: [1m[32m0.03166[0m[0m | time: 773.203s
[2K
| Adam | epoch: 009 | loss: 0.03166 - acc: 0.9926 -- iter: 2016/2163
[A[ATraining Step: 608  | total loss: [1m[32m0.03085[0m[0m | time: 788.664s
[2K
| Adam | epoch: 009 | loss: 0.03085 - acc: 0.9934 -- iter: 2048/2163
[A[ATraining Step: 609  | total loss: [1m[32m0.02846[0m[0m | time: 806.199s
[2K
| Adam | epoch: 009 | loss: 0.02846 - acc: 0.9940 -- iter: 2080/2163
[A[ATraining Step: 610  | total loss: [1m[32m0.02586[0m[0m | time: 823.995s
[2K
| Adam | epoch: 009 | loss: 0.02586 - acc: 0.9946 -- iter: 2112/2163
[A[ATraining Step: 611  | total loss: [1m[32m0.02596[0m[0m | time: 841.526s
[2K
| Adam | epoch: 009 | loss: 0.02596 - acc: 0.9920 -- iter: 2144/2163
[A[ATraining Step: 612  | total loss: [1m[32m0.02397[0m[0m | time: 909.730s
[2K
| Adam | epoch: 009 | loss: 0.02397 - acc: 0.9928 | val_loss: 0.22577 - val_acc: 0.9232 -- iter: 2163/2163
--
Training Step: 613  | total loss: [1m[32m0.03342[0m[0m | time: 17.618s
[2K
| Adam | epoch: 010 | loss: 0.03342 - acc: 0.9904 -- iter: 0032/2163
[A[ATraining Step: 614  | total loss: [1m[32m0.03106[0m[0m | time: 35.731s
[2K
| Adam | epoch: 010 | loss: 0.03106 - acc: 0.9914 -- iter: 0064/2163
[A[ATraining Step: 615  | total loss: [1m[32m0.03592[0m[0m | time: 53.443s
[2K
| Adam | epoch: 010 | loss: 0.03592 - acc: 0.9891 -- iter: 0096/2163
[A[ATraining Step: 616  | total loss: [1m[32m0.03292[0m[0m | time: 70.776s
[2K
| Adam | epoch: 010 | loss: 0.03292 - acc: 0.9902 -- iter: 0128/2163
[A[ATraining Step: 617  | total loss: [1m[32m0.03011[0m[0m | time: 86.642s
[2K
| Adam | epoch: 010 | loss: 0.03011 - acc: 0.9912 -- iter: 0160/2163
[A[ATraining Step: 618  | total loss: [1m[32m0.03586[0m[0m | time: 99.228s
[2K
| Adam | epoch: 010 | loss: 0.03586 - acc: 0.9889 -- iter: 0192/2163
[A[ATraining Step: 619  | total loss: [1m[32m0.03486[0m[0m | time: 107.832s
[2K
| Adam | epoch: 010 | loss: 0.03486 - acc: 0.9901 -- iter: 0224/2163
[A[ATraining Step: 620  | total loss: [1m[32m0.03177[0m[0m | time: 112.962s
[2K
| Adam | epoch: 010 | loss: 0.03177 - acc: 0.9910 -- iter: 0256/2163
[A[ATraining Step: 621  | total loss: [1m[32m0.02881[0m[0m | time: 118.080s
[2K
| Adam | epoch: 010 | loss: 0.02881 - acc: 0.9919 -- iter: 0288/2163
[A[ATraining Step: 622  | total loss: [1m[32m0.02611[0m[0m | time: 129.562s
[2K
| Adam | epoch: 010 | loss: 0.02611 - acc: 0.9927 -- iter: 0320/2163
[A[ATraining Step: 623  | total loss: [1m[32m0.02433[0m[0m | time: 147.333s
[2K
| Adam | epoch: 010 | loss: 0.02433 - acc: 0.9935 -- iter: 0352/2163
[A[ATraining Step: 624  | total loss: [1m[32m0.02233[0m[0m | time: 164.348s
[2K
| Adam | epoch: 010 | loss: 0.02233 - acc: 0.9941 -- iter: 0384/2163
[A[ATraining Step: 625  | total loss: [1m[32m0.02077[0m[0m | time: 182.102s
[2K
| Adam | epoch: 010 | loss: 0.02077 - acc: 0.9947 -- iter: 0416/2163
[A[ATraining Step: 626  | total loss: [1m[32m0.02555[0m[0m | time: 199.887s
[2K
| Adam | epoch: 010 | loss: 0.02555 - acc: 0.9921 -- iter: 0448/2163
[A[ATraining Step: 627  | total loss: [1m[32m0.02782[0m[0m | time: 217.449s
[2K
| Adam | epoch: 010 | loss: 0.02782 - acc: 0.9898 -- iter: 0480/2163
[A[ATraining Step: 628  | total loss: [1m[32m0.02529[0m[0m | time: 235.026s
[2K
| Adam | epoch: 010 | loss: 0.02529 - acc: 0.9908 -- iter: 0512/2163
[A[ATraining Step: 629  | total loss: [1m[32m0.02431[0m[0m | time: 251.408s
[2K
| Adam | epoch: 010 | loss: 0.02431 - acc: 0.9917 -- iter: 0544/2163
[A[ATraining Step: 630  | total loss: [1m[32m0.02201[0m[0m | time: 264.462s
[2K
| Adam | epoch: 010 | loss: 0.02201 - acc: 0.9925 -- iter: 0576/2163
[A[ATraining Step: 631  | total loss: [1m[32m0.02265[0m[0m | time: 279.029s
[2K
| Adam | epoch: 010 | loss: 0.02265 - acc: 0.9933 -- iter: 0608/2163
[A[ATraining Step: 632  | total loss: [1m[32m0.02308[0m[0m | time: 291.521s
[2K
| Adam | epoch: 010 | loss: 0.02308 - acc: 0.9908 -- iter: 0640/2163
[A[ATraining Step: 633  | total loss: [1m[32m0.02210[0m[0m | time: 304.030s
[2K
| Adam | epoch: 010 | loss: 0.02210 - acc: 0.9918 -- iter: 0672/2163
[A[ATraining Step: 634  | total loss: [1m[32m0.02187[0m[0m | time: 320.851s
[2K
| Adam | epoch: 010 | loss: 0.02187 - acc: 0.9926 -- iter: 0704/2163
[A[ATraining Step: 635  | total loss: [1m[32m0.02254[0m[0m | time: 338.746s
[2K
| Adam | epoch: 010 | loss: 0.02254 - acc: 0.9933 -- iter: 0736/2163
[A[ATraining Step: 636  | total loss: [1m[32m0.02306[0m[0m | time: 355.990s
[2K
| Adam | epoch: 010 | loss: 0.02306 - acc: 0.9940 -- iter: 0768/2163
[A[ATraining Step: 637  | total loss: [1m[32m0.02359[0m[0m | time: 373.046s
[2K
| Adam | epoch: 010 | loss: 0.02359 - acc: 0.9946 -- iter: 0800/2163
[A[ATraining Step: 638  | total loss: [1m[32m0.02228[0m[0m | time: 388.539s
[2K
| Adam | epoch: 010 | loss: 0.02228 - acc: 0.9951 -- iter: 0832/2163
[A[ATraining Step: 639  | total loss: [1m[32m0.04096[0m[0m | time: 401.243s
[2K
| Adam | epoch: 010 | loss: 0.04096 - acc: 0.9925 -- iter: 0864/2163
[A[ATraining Step: 640  | total loss: [1m[32m0.03728[0m[0m | time: 415.146s
[2K
| Adam | epoch: 010 | loss: 0.03728 - acc: 0.9932 -- iter: 0896/2163
[A[ATraining Step: 641  | total loss: [1m[32m0.03467[0m[0m | time: 432.377s
[2K
| Adam | epoch: 010 | loss: 0.03467 - acc: 0.9939 -- iter: 0928/2163
[A[ATraining Step: 642  | total loss: [1m[32m0.03143[0m[0m | time: 451.034s
[2K
| Adam | epoch: 010 | loss: 0.03143 - acc: 0.9945 -- iter: 0960/2163
[A[ATraining Step: 643  | total loss: [1m[32m0.02855[0m[0m | time: 468.123s
[2K
| Adam | epoch: 010 | loss: 0.02855 - acc: 0.9951 -- iter: 0992/2163
[A[ATraining Step: 644  | total loss: [1m[32m0.02655[0m[0m | time: 480.814s
[2K
| Adam | epoch: 010 | loss: 0.02655 - acc: 0.9956 -- iter: 1024/2163
[A[ATraining Step: 645  | total loss: [1m[32m0.02398[0m[0m | time: 493.627s
[2K
| Adam | epoch: 010 | loss: 0.02398 - acc: 0.9960 -- iter: 1056/2163
[A[ATraining Step: 646  | total loss: [1m[32m0.02177[0m[0m | time: 506.501s
[2K
| Adam | epoch: 010 | loss: 0.02177 - acc: 0.9964 -- iter: 1088/2163
[A[ATraining Step: 647  | total loss: [1m[32m0.02128[0m[0m | time: 517.278s
[2K
| Adam | epoch: 010 | loss: 0.02128 - acc: 0.9968 -- iter: 1120/2163
[A[ATraining Step: 648  | total loss: [1m[32m0.02020[0m[0m | time: 529.680s
[2K
| Adam | epoch: 010 | loss: 0.02020 - acc: 0.9971 -- iter: 1152/2163
[A[ATraining Step: 649  | total loss: [1m[32m0.02167[0m[0m | time: 538.378s
[2K
| Adam | epoch: 010 | loss: 0.02167 - acc: 0.9974 -- iter: 1184/2163
[A[ATraining Step: 650  | total loss: [1m[32m0.02012[0m[0m | time: 550.869s
[2K
| Adam | epoch: 010 | loss: 0.02012 - acc: 0.9976 -- iter: 1216/2163
[A[ATraining Step: 651  | total loss: [1m[32m0.01850[0m[0m | time: 562.928s
[2K
| Adam | epoch: 010 | loss: 0.01850 - acc: 0.9979 -- iter: 1248/2163
[A[ATraining Step: 652  | total loss: [1m[32m0.01717[0m[0m | time: 575.481s
[2K
| Adam | epoch: 010 | loss: 0.01717 - acc: 0.9981 -- iter: 1280/2163
[A[ATraining Step: 653  | total loss: [1m[32m0.02752[0m[0m | time: 587.912s
[2K
| Adam | epoch: 010 | loss: 0.02752 - acc: 0.9952 -- iter: 1312/2163
[A[ATraining Step: 654  | total loss: [1m[32m0.02875[0m[0m | time: 600.699s
[2K
| Adam | epoch: 010 | loss: 0.02875 - acc: 0.9925 -- iter: 1344/2163
[A[ATraining Step: 655  | total loss: [1m[32m0.02776[0m[0m | time: 613.148s
[2K
| Adam | epoch: 010 | loss: 0.02776 - acc: 0.9933 -- iter: 1376/2163
[A[ATraining Step: 656  | total loss: [1m[32m0.02963[0m[0m | time: 623.345s
[2K
| Adam | epoch: 010 | loss: 0.02963 - acc: 0.9908 -- iter: 1408/2163
[A[ATraining Step: 657  | total loss: [1m[32m0.02712[0m[0m | time: 631.115s
[2K
| Adam | epoch: 010 | loss: 0.02712 - acc: 0.9917 -- iter: 1440/2163
[A[ATraining Step: 658  | total loss: [1m[32m0.02459[0m[0m | time: 638.735s
[2K
| Adam | epoch: 010 | loss: 0.02459 - acc: 0.9926 -- iter: 1472/2163
[A[ATraining Step: 659  | total loss: [1m[32m0.03250[0m[0m | time: 646.346s
[2K
| Adam | epoch: 010 | loss: 0.03250 - acc: 0.9839 -- iter: 1504/2163
[A[ATraining Step: 660  | total loss: [1m[32m0.02958[0m[0m | time: 654.164s
[2K
| Adam | epoch: 010 | loss: 0.02958 - acc: 0.9855 -- iter: 1536/2163
[A[ATraining Step: 661  | total loss: [1m[32m0.02703[0m[0m | time: 666.312s
[2K
| Adam | epoch: 010 | loss: 0.02703 - acc: 0.9870 -- iter: 1568/2163
[A[ATraining Step: 662  | total loss: [1m[32m0.02983[0m[0m | time: 678.771s
[2K
| Adam | epoch: 010 | loss: 0.02983 - acc: 0.9852 -- iter: 1600/2163
[A[ATraining Step: 663  | total loss: [1m[32m0.05482[0m[0m | time: 691.038s
[2K
| Adam | epoch: 010 | loss: 0.05482 - acc: 0.9773 -- iter: 1632/2163
[A[ATraining Step: 664  | total loss: [1m[32m0.05339[0m[0m | time: 703.433s
[2K
| Adam | epoch: 010 | loss: 0.05339 - acc: 0.9764 -- iter: 1664/2163
[A[ATraining Step: 665  | total loss: [1m[32m0.04854[0m[0m | time: 716.307s
[2K
| Adam | epoch: 010 | loss: 0.04854 - acc: 0.9788 -- iter: 1696/2163
[A[ATraining Step: 666  | total loss: [1m[32m0.04518[0m[0m | time: 728.911s
[2K
| Adam | epoch: 010 | loss: 0.04518 - acc: 0.9809 -- iter: 1728/2163
[A[ATraining Step: 667  | total loss: [1m[32m0.04222[0m[0m | time: 740.125s
[2K
| Adam | epoch: 010 | loss: 0.04222 - acc: 0.9828 -- iter: 1760/2163
[A[ATraining Step: 668  | total loss: [1m[32m0.03890[0m[0m | time: 747.880s
[2K
| Adam | epoch: 010 | loss: 0.03890 - acc: 0.9845 -- iter: 1792/2163
[A[ATraining Step: 669  | total loss: [1m[32m0.03793[0m[0m | time: 755.428s
[2K
| Adam | epoch: 010 | loss: 0.03793 - acc: 0.9829 -- iter: 1824/2163
[A[ATraining Step: 670  | total loss: [1m[32m0.03985[0m[0m | time: 765.388s
[2K
| Adam | epoch: 010 | loss: 0.03985 - acc: 0.9815 -- iter: 1856/2163
[A[ATraining Step: 671  | total loss: [1m[32m0.05016[0m[0m | time: 778.160s
[2K
| Adam | epoch: 010 | loss: 0.05016 - acc: 0.9803 -- iter: 1888/2163
[A[ATraining Step: 672  | total loss: [1m[32m0.05787[0m[0m | time: 790.617s
[2K
| Adam | epoch: 010 | loss: 0.05787 - acc: 0.9760 -- iter: 1920/2163
[A[ATraining Step: 673  | total loss: [1m[32m0.06397[0m[0m | time: 803.206s
[2K
| Adam | epoch: 010 | loss: 0.06397 - acc: 0.9753 -- iter: 1952/2163
[A[ATraining Step: 674  | total loss: [1m[32m0.05790[0m[0m | time: 815.711s
[2K
| Adam | epoch: 010 | loss: 0.05790 - acc: 0.9777 -- iter: 1984/2163
[A[ATraining Step: 675  | total loss: [1m[32m0.05418[0m[0m | time: 828.592s
[2K
| Adam | epoch: 010 | loss: 0.05418 - acc: 0.9800 -- iter: 2016/2163
[A[ATraining Step: 676  | total loss: [1m[32m0.04995[0m[0m | time: 841.345s
[2K
| Adam | epoch: 010 | loss: 0.04995 - acc: 0.9820 -- iter: 2048/2163
[A[ATraining Step: 677  | total loss: [1m[32m0.04583[0m[0m | time: 849.081s
[2K
| Adam | epoch: 010 | loss: 0.04583 - acc: 0.9838 -- iter: 2080/2163
[A[ATraining Step: 678  | total loss: [1m[32m0.04239[0m[0m | time: 856.895s
[2K
| Adam | epoch: 010 | loss: 0.04239 - acc: 0.9854 -- iter: 2112/2163
[A[ATraining Step: 679  | total loss: [1m[32m0.03972[0m[0m | time: 865.085s
[2K
| Adam | epoch: 010 | loss: 0.03972 - acc: 0.9868 -- iter: 2144/2163
[A[ATraining Step: 680  | total loss: [1m[32m0.03976[0m[0m | time: 927.616s
[2K
| Adam | epoch: 010 | loss: 0.03976 - acc: 0.9882 | val_loss: 3.38855 - val_acc: 0.5318 -- iter: 2163/2163
--
Training Step: 681  | total loss: [1m[32m0.04015[0m[0m | time: 7.800s
[2K
| Adam | epoch: 011 | loss: 0.04015 - acc: 0.9862 -- iter: 0032/2163
[A[ATraining Step: 682  | total loss: [1m[32m0.03681[0m[0m | time: 15.567s
[2K
| Adam | epoch: 011 | loss: 0.03681 - acc: 0.9876 -- iter: 0064/2163
[A[ATraining Step: 683  | total loss: [1m[32m0.04232[0m[0m | time: 24.418s
[2K
| Adam | epoch: 011 | loss: 0.04232 - acc: 0.9826 -- iter: 0096/2163
[A[ATraining Step: 684  | total loss: [1m[32m0.03820[0m[0m | time: 35.568s
[2K
| Adam | epoch: 011 | loss: 0.03820 - acc: 0.9843 -- iter: 0128/2163
[A[ATraining Step: 685  | total loss: [1m[32m0.03677[0m[0m | time: 43.462s
[2K
| Adam | epoch: 011 | loss: 0.03677 - acc: 0.9859 -- iter: 0160/2163
[A[ATraining Step: 686  | total loss: [1m[32m0.03362[0m[0m | time: 51.227s
[2K
| Adam | epoch: 011 | loss: 0.03362 - acc: 0.9873 -- iter: 0192/2163
[A[ATraining Step: 687  | total loss: [1m[32m0.04494[0m[0m | time: 58.950s
[2K
| Adam | epoch: 011 | loss: 0.04494 - acc: 0.9855 -- iter: 0224/2163
[A[ATraining Step: 688  | total loss: [1m[32m0.04265[0m[0m | time: 66.663s
[2K
| Adam | epoch: 011 | loss: 0.04265 - acc: 0.9869 -- iter: 0256/2163
[A[ATraining Step: 689  | total loss: [1m[32m0.04046[0m[0m | time: 71.752s
[2K
| Adam | epoch: 011 | loss: 0.04046 - acc: 0.9882 -- iter: 0288/2163
[A[ATraining Step: 690  | total loss: [1m[32m0.04841[0m[0m | time: 76.815s
[2K
| Adam | epoch: 011 | loss: 0.04841 - acc: 0.9841 -- iter: 0320/2163
[A[ATraining Step: 691  | total loss: [1m[32m0.04412[0m[0m | time: 84.448s
[2K
| Adam | epoch: 011 | loss: 0.04412 - acc: 0.9857 -- iter: 0352/2163
[A[ATraining Step: 692  | total loss: [1m[32m0.04356[0m[0m | time: 92.112s
[2K
| Adam | epoch: 011 | loss: 0.04356 - acc: 0.9871 -- iter: 0384/2163
[A[ATraining Step: 693  | total loss: [1m[32m0.04275[0m[0m | time: 99.968s
[2K
| Adam | epoch: 011 | loss: 0.04275 - acc: 0.9884 -- iter: 0416/2163
[A[ATraining Step: 694  | total loss: [1m[32m0.04649[0m[0m | time: 107.562s
[2K
| Adam | epoch: 011 | loss: 0.04649 - acc: 0.9865 -- iter: 0448/2163
[A[ATraining Step: 695  | total loss: [1m[32m0.04212[0m[0m | time: 115.181s
[2K
| Adam | epoch: 011 | loss: 0.04212 - acc: 0.9878 -- iter: 0480/2163
[A[ATraining Step: 696  | total loss: [1m[32m0.04619[0m[0m | time: 122.976s
[2K
| Adam | epoch: 011 | loss: 0.04619 - acc: 0.9859 -- iter: 0512/2163
[A[ATraining Step: 697  | total loss: [1m[32m0.05699[0m[0m | time: 130.736s
[2K
| Adam | epoch: 011 | loss: 0.05699 - acc: 0.9811 -- iter: 0544/2163
[A[ATraining Step: 698  | total loss: [1m[32m0.05516[0m[0m | time: 138.765s
[2K
| Adam | epoch: 011 | loss: 0.05516 - acc: 0.9830 -- iter: 0576/2163
[A[ATraining Step: 699  | total loss: [1m[32m0.05147[0m[0m | time: 146.511s
[2K
| Adam | epoch: 011 | loss: 0.05147 - acc: 0.9847 -- iter: 0608/2163
[A[ATraining Step: 700  | total loss: [1m[32m0.05849[0m[0m | time: 154.357s
[2K
| Adam | epoch: 011 | loss: 0.05849 - acc: 0.9799 -- iter: 0640/2163
[A[ATraining Step: 701  | total loss: [1m[32m0.06170[0m[0m | time: 162.125s
[2K
| Adam | epoch: 011 | loss: 0.06170 - acc: 0.9788 -- iter: 0672/2163
[A[ATraining Step: 702  | total loss: [1m[32m0.06179[0m[0m | time: 169.783s
[2K
| Adam | epoch: 011 | loss: 0.06179 - acc: 0.9778 -- iter: 0704/2163
[A[ATraining Step: 703  | total loss: [1m[32m0.07636[0m[0m | time: 177.484s
[2K
| Adam | epoch: 011 | loss: 0.07636 - acc: 0.9738 -- iter: 0736/2163
[A[ATraining Step: 704  | total loss: [1m[32m0.06928[0m[0m | time: 185.390s
[2K
| Adam | epoch: 011 | loss: 0.06928 - acc: 0.9764 -- iter: 0768/2163
[A[ATraining Step: 705  | total loss: [1m[32m0.06413[0m[0m | time: 193.240s
[2K
| Adam | epoch: 011 | loss: 0.06413 - acc: 0.9788 -- iter: 0800/2163
[A[ATraining Step: 706  | total loss: [1m[32m0.05985[0m[0m | time: 200.833s
[2K
| Adam | epoch: 011 | loss: 0.05985 - acc: 0.9809 -- iter: 0832/2163
[A[ATraining Step: 707  | total loss: [1m[32m0.05437[0m[0m | time: 208.511s
[2K
| Adam | epoch: 011 | loss: 0.05437 - acc: 0.9828 -- iter: 0864/2163
[A[ATraining Step: 708  | total loss: [1m[32m0.05141[0m[0m | time: 216.180s
[2K
| Adam | epoch: 011 | loss: 0.05141 - acc: 0.9845 -- iter: 0896/2163
[A[ATraining Step: 709  | total loss: [1m[32m0.04962[0m[0m | time: 223.780s
[2K
| Adam | epoch: 011 | loss: 0.04962 - acc: 0.9829 -- iter: 0928/2163
[A[ATraining Step: 710  | total loss: [1m[32m0.04600[0m[0m | time: 231.381s
[2K
| Adam | epoch: 011 | loss: 0.04600 - acc: 0.9847 -- iter: 0960/2163
[A[ATraining Step: 711  | total loss: [1m[32m0.04283[0m[0m | time: 238.961s
[2K
| Adam | epoch: 011 | loss: 0.04283 - acc: 0.9862 -- iter: 0992/2163
[A[ATraining Step: 712  | total loss: [1m[32m0.03994[0m[0m | time: 246.606s
[2K
| Adam | epoch: 011 | loss: 0.03994 - acc: 0.9876 -- iter: 1024/2163
[A[ATraining Step: 713  | total loss: [1m[32m0.07716[0m[0m | time: 254.260s
[2K
| Adam | epoch: 011 | loss: 0.07716 - acc: 0.9763 -- iter: 1056/2163
[A[ATraining Step: 714  | total loss: [1m[32m0.07173[0m[0m | time: 261.995s
[2K
| Adam | epoch: 011 | loss: 0.07173 - acc: 0.9787 -- iter: 1088/2163
[A[ATraining Step: 715  | total loss: [1m[32m0.07758[0m[0m | time: 269.787s
[2K
| Adam | epoch: 011 | loss: 0.07758 - acc: 0.9746 -- iter: 1120/2163
[A[ATraining Step: 716  | total loss: [1m[32m0.07220[0m[0m | time: 277.344s
[2K
| Adam | epoch: 011 | loss: 0.07220 - acc: 0.9771 -- iter: 1152/2163
[A[ATraining Step: 717  | total loss: [1m[32m0.06564[0m[0m | time: 285.057s
[2K
| Adam | epoch: 011 | loss: 0.06564 - acc: 0.9794 -- iter: 1184/2163
[A[ATraining Step: 718  | total loss: [1m[32m0.06228[0m[0m | time: 292.720s
[2K
| Adam | epoch: 011 | loss: 0.06228 - acc: 0.9815 -- iter: 1216/2163
[A[ATraining Step: 719  | total loss: [1m[32m0.06196[0m[0m | time: 300.393s
[2K
| Adam | epoch: 011 | loss: 0.06196 - acc: 0.9833 -- iter: 1248/2163
[A[ATraining Step: 720  | total loss: [1m[32m0.05653[0m[0m | time: 308.202s
[2K
| Adam | epoch: 011 | loss: 0.05653 - acc: 0.9850 -- iter: 1280/2163
[A[ATraining Step: 721  | total loss: [1m[32m0.05409[0m[0m | time: 316.043s
[2K
| Adam | epoch: 011 | loss: 0.05409 - acc: 0.9865 -- iter: 1312/2163
[A[ATraining Step: 722  | total loss: [1m[32m0.05002[0m[0m | time: 323.826s
[2K
| Adam | epoch: 011 | loss: 0.05002 - acc: 0.9878 -- iter: 1344/2163
[A[ATraining Step: 723  | total loss: [1m[32m0.04576[0m[0m | time: 331.497s
[2K
| Adam | epoch: 011 | loss: 0.04576 - acc: 0.9890 -- iter: 1376/2163
[A[ATraining Step: 724  | total loss: [1m[32m0.04293[0m[0m | time: 339.192s
[2K
| Adam | epoch: 011 | loss: 0.04293 - acc: 0.9901 -- iter: 1408/2163
[A[ATraining Step: 725  | total loss: [1m[32m0.04568[0m[0m | time: 346.930s
[2K
| Adam | epoch: 011 | loss: 0.04568 - acc: 0.9880 -- iter: 1440/2163
[A[ATraining Step: 726  | total loss: [1m[32m0.05326[0m[0m | time: 354.454s
[2K
| Adam | epoch: 011 | loss: 0.05326 - acc: 0.9861 -- iter: 1472/2163
[A[ATraining Step: 727  | total loss: [1m[32m0.08562[0m[0m | time: 362.076s
[2K
| Adam | epoch: 011 | loss: 0.08562 - acc: 0.9843 -- iter: 1504/2163
[A[ATraining Step: 728  | total loss: [1m[32m0.07865[0m[0m | time: 369.813s
[2K
| Adam | epoch: 011 | loss: 0.07865 - acc: 0.9859 -- iter: 1536/2163
[A[ATraining Step: 729  | total loss: [1m[32m0.07243[0m[0m | time: 377.416s
[2K
| Adam | epoch: 011 | loss: 0.07243 - acc: 0.9873 -- iter: 1568/2163
[A[ATraining Step: 730  | total loss: [1m[32m0.06921[0m[0m | time: 385.069s
[2K
| Adam | epoch: 011 | loss: 0.06921 - acc: 0.9886 -- iter: 1600/2163
[A[ATraining Step: 731  | total loss: [1m[32m0.06389[0m[0m | time: 392.672s
[2K
| Adam | epoch: 011 | loss: 0.06389 - acc: 0.9897 -- iter: 1632/2163
[A[ATraining Step: 732  | total loss: [1m[32m0.05814[0m[0m | time: 400.428s
[2K
| Adam | epoch: 011 | loss: 0.05814 - acc: 0.9908 -- iter: 1664/2163
[A[ATraining Step: 733  | total loss: [1m[32m0.06536[0m[0m | time: 408.033s
[2K
| Adam | epoch: 011 | loss: 0.06536 - acc: 0.9854 -- iter: 1696/2163
[A[ATraining Step: 734  | total loss: [1m[32m0.05990[0m[0m | time: 415.746s
[2K
| Adam | epoch: 011 | loss: 0.05990 - acc: 0.9869 -- iter: 1728/2163
[A[ATraining Step: 735  | total loss: [1m[32m0.05417[0m[0m | time: 423.441s
[2K
| Adam | epoch: 011 | loss: 0.05417 - acc: 0.9882 -- iter: 1760/2163
[A[ATraining Step: 736  | total loss: [1m[32m0.05282[0m[0m | time: 431.303s
[2K
| Adam | epoch: 011 | loss: 0.05282 - acc: 0.9894 -- iter: 1792/2163
[A[ATraining Step: 737  | total loss: [1m[32m0.04850[0m[0m | time: 438.930s
[2K
| Adam | epoch: 011 | loss: 0.04850 - acc: 0.9904 -- iter: 1824/2163
[A[ATraining Step: 738  | total loss: [1m[32m0.04485[0m[0m | time: 446.730s
[2K
| Adam | epoch: 011 | loss: 0.04485 - acc: 0.9914 -- iter: 1856/2163
[A[ATraining Step: 739  | total loss: [1m[32m0.04884[0m[0m | time: 454.670s
[2K
| Adam | epoch: 011 | loss: 0.04884 - acc: 0.9891 -- iter: 1888/2163
[A[ATraining Step: 740  | total loss: [1m[32m0.04462[0m[0m | time: 462.464s
[2K
| Adam | epoch: 011 | loss: 0.04462 - acc: 0.9902 -- iter: 1920/2163
[A[ATraining Step: 741  | total loss: [1m[32m0.04164[0m[0m | time: 470.280s
[2K
| Adam | epoch: 011 | loss: 0.04164 - acc: 0.9912 -- iter: 1952/2163
[A[ATraining Step: 742  | total loss: [1m[32m0.03781[0m[0m | time: 477.980s
[2K
| Adam | epoch: 011 | loss: 0.03781 - acc: 0.9921 -- iter: 1984/2163
[A[ATraining Step: 743  | total loss: [1m[32m0.03484[0m[0m | time: 485.619s
[2K
| Adam | epoch: 011 | loss: 0.03484 - acc: 0.9929 -- iter: 2016/2163
[A[ATraining Step: 744  | total loss: [1m[32m0.03243[0m[0m | time: 493.550s
[2K
| Adam | epoch: 011 | loss: 0.03243 - acc: 0.9936 -- iter: 2048/2163
[A[ATraining Step: 745  | total loss: [1m[32m0.02966[0m[0m | time: 501.247s
[2K
| Adam | epoch: 011 | loss: 0.02966 - acc: 0.9942 -- iter: 2080/2163
[A[ATraining Step: 746  | total loss: [1m[32m0.03084[0m[0m | time: 508.919s
[2K
| Adam | epoch: 011 | loss: 0.03084 - acc: 0.9948 -- iter: 2112/2163
[A[ATraining Step: 747  | total loss: [1m[32m0.02989[0m[0m | time: 516.614s
[2K
| Adam | epoch: 011 | loss: 0.02989 - acc: 0.9953 -- iter: 2144/2163
[A[ATraining Step: 748  | total loss: [1m[32m0.03382[0m[0m | time: 553.990s
[2K
| Adam | epoch: 011 | loss: 0.03382 - acc: 0.9895 | val_loss: 0.21200 - val_acc: 0.9306 -- iter: 2163/2163
--
Training Step: 749  | total loss: [1m[32m0.03844[0m[0m | time: 7.713s
[2K
| Adam | epoch: 012 | loss: 0.03844 - acc: 0.9843 -- iter: 0032/2163
[A[ATraining Step: 750  | total loss: [1m[32m0.03814[0m[0m | time: 15.482s
[2K
| Adam | epoch: 012 | loss: 0.03814 - acc: 0.9859 -- iter: 0064/2163
[A[ATraining Step: 751  | total loss: [1m[32m0.03548[0m[0m | time: 23.204s
[2K
| Adam | epoch: 012 | loss: 0.03548 - acc: 0.9873 -- iter: 0096/2163
[A[ATraining Step: 752  | total loss: [1m[32m0.03292[0m[0m | time: 31.042s
[2K
| Adam | epoch: 012 | loss: 0.03292 - acc: 0.9886 -- iter: 0128/2163
[A[ATraining Step: 753  | total loss: [1m[32m0.03048[0m[0m | time: 38.728s
[2K
| Adam | epoch: 012 | loss: 0.03048 - acc: 0.9897 -- iter: 0160/2163
[A[ATraining Step: 754  | total loss: [1m[32m0.02860[0m[0m | time: 46.418s
[2K
| Adam | epoch: 012 | loss: 0.02860 - acc: 0.9908 -- iter: 0192/2163
[A[ATraining Step: 755  | total loss: [1m[32m0.02616[0m[0m | time: 54.217s
[2K
| Adam | epoch: 012 | loss: 0.02616 - acc: 0.9917 -- iter: 0224/2163
[A[ATraining Step: 756  | total loss: [1m[32m0.02815[0m[0m | time: 61.817s
[2K
| Adam | epoch: 012 | loss: 0.02815 - acc: 0.9894 -- iter: 0256/2163
[A[ATraining Step: 757  | total loss: [1m[32m0.05314[0m[0m | time: 69.500s
[2K
| Adam | epoch: 012 | loss: 0.05314 - acc: 0.9779 -- iter: 0288/2163
[A[ATraining Step: 758  | total loss: [1m[32m0.04794[0m[0m | time: 74.584s
[2K
| Adam | epoch: 012 | loss: 0.04794 - acc: 0.9802 -- iter: 0320/2163
[A[ATraining Step: 759  | total loss: [1m[32m0.04541[0m[0m | time: 79.736s
[2K
| Adam | epoch: 012 | loss: 0.04541 - acc: 0.9821 -- iter: 0352/2163
[A[ATraining Step: 760  | total loss: [1m[32m0.04218[0m[0m | time: 87.380s
[2K
| Adam | epoch: 012 | loss: 0.04218 - acc: 0.9839 -- iter: 0384/2163
[A[ATraining Step: 761  | total loss: [1m[32m0.03816[0m[0m | time: 95.170s
[2K
| Adam | epoch: 012 | loss: 0.03816 - acc: 0.9855 -- iter: 0416/2163
[A[ATraining Step: 762  | total loss: [1m[32m0.04103[0m[0m | time: 102.771s
[2K
| Adam | epoch: 012 | loss: 0.04103 - acc: 0.9839 -- iter: 0448/2163
[A[ATraining Step: 763  | total loss: [1m[32m0.03736[0m[0m | time: 110.493s
[2K
| Adam | epoch: 012 | loss: 0.03736 - acc: 0.9855 -- iter: 0480/2163
[A[ATraining Step: 764  | total loss: [1m[32m0.03454[0m[0m | time: 118.185s
[2K
| Adam | epoch: 012 | loss: 0.03454 - acc: 0.9869 -- iter: 0512/2163
[A[ATraining Step: 765  | total loss: [1m[32m0.03159[0m[0m | time: 125.808s
[2K
| Adam | epoch: 012 | loss: 0.03159 - acc: 0.9882 -- iter: 0544/2163
[A[ATraining Step: 766  | total loss: [1m[32m0.03002[0m[0m | time: 133.625s
[2K
| Adam | epoch: 012 | loss: 0.03002 - acc: 0.9894 -- iter: 0576/2163
[A[ATraining Step: 767  | total loss: [1m[32m0.02734[0m[0m | time: 141.223s
[2K
| Adam | epoch: 012 | loss: 0.02734 - acc: 0.9905 -- iter: 0608/2163
[A[ATraining Step: 768  | total loss: [1m[32m0.02617[0m[0m | time: 148.890s
[2K
| Adam | epoch: 012 | loss: 0.02617 - acc: 0.9914 -- iter: 0640/2163
[A[ATraining Step: 769  | total loss: [1m[32m0.02743[0m[0m | time: 156.706s
[2K
| Adam | epoch: 012 | loss: 0.02743 - acc: 0.9892 -- iter: 0672/2163
[A[ATraining Step: 770  | total loss: [1m[32m0.02500[0m[0m | time: 164.495s
[2K
| Adam | epoch: 012 | loss: 0.02500 - acc: 0.9902 -- iter: 0704/2163
[A[ATraining Step: 771  | total loss: [1m[32m0.03031[0m[0m | time: 172.306s
[2K
| Adam | epoch: 012 | loss: 0.03031 - acc: 0.9881 -- iter: 0736/2163
[A[ATraining Step: 772  | total loss: [1m[32m0.02809[0m[0m | time: 179.932s
[2K
| Adam | epoch: 012 | loss: 0.02809 - acc: 0.9893 -- iter: 0768/2163
[A[ATraining Step: 773  | total loss: [1m[32m0.02934[0m[0m | time: 187.672s
[2K
| Adam | epoch: 012 | loss: 0.02934 - acc: 0.9872 -- iter: 0800/2163
[A[ATraining Step: 774  | total loss: [1m[32m0.02690[0m[0m | time: 195.405s
[2K
| Adam | epoch: 012 | loss: 0.02690 - acc: 0.9885 -- iter: 0832/2163
[A[ATraining Step: 775  | total loss: [1m[32m0.02437[0m[0m | time: 203.029s
[2K
| Adam | epoch: 012 | loss: 0.02437 - acc: 0.9897 -- iter: 0864/2163
[A[ATraining Step: 776  | total loss: [1m[32m0.02259[0m[0m | time: 210.730s
[2K
| Adam | epoch: 012 | loss: 0.02259 - acc: 0.9907 -- iter: 0896/2163
[A[ATraining Step: 777  | total loss: [1m[32m0.02137[0m[0m | time: 218.605s
[2K
| Adam | epoch: 012 | loss: 0.02137 - acc: 0.9916 -- iter: 0928/2163
[A[ATraining Step: 778  | total loss: [1m[32m0.03789[0m[0m | time: 226.584s
[2K
| Adam | epoch: 012 | loss: 0.03789 - acc: 0.9862 -- iter: 0960/2163
[A[ATraining Step: 779  | total loss: [1m[32m0.03775[0m[0m | time: 234.133s
[2K
| Adam | epoch: 012 | loss: 0.03775 - acc: 0.9845 -- iter: 0992/2163
[A[ATraining Step: 780  | total loss: [1m[32m0.03408[0m[0m | time: 241.790s
[2K
| Adam | epoch: 012 | loss: 0.03408 - acc: 0.9860 -- iter: 1024/2163
[A[ATraining Step: 781  | total loss: [1m[32m0.03490[0m[0m | time: 249.578s
[2K
| Adam | epoch: 012 | loss: 0.03490 - acc: 0.9843 -- iter: 1056/2163
[A[ATraining Step: 782  | total loss: [1m[32m0.03179[0m[0m | time: 257.243s
[2K
| Adam | epoch: 012 | loss: 0.03179 - acc: 0.9859 -- iter: 1088/2163
[A[ATraining Step: 783  | total loss: [1m[32m0.02875[0m[0m | time: 264.941s
[2K
| Adam | epoch: 012 | loss: 0.02875 - acc: 0.9873 -- iter: 1120/2163
[A[ATraining Step: 784  | total loss: [1m[32m0.03142[0m[0m | time: 272.468s
[2K
| Adam | epoch: 012 | loss: 0.03142 - acc: 0.9854 -- iter: 1152/2163
[A[ATraining Step: 785  | total loss: [1m[32m0.02968[0m[0m | time: 280.214s
[2K
| Adam | epoch: 012 | loss: 0.02968 - acc: 0.9869 -- iter: 1184/2163
[A[ATraining Step: 786  | total loss: [1m[32m0.03250[0m[0m | time: 287.947s
[2K
| Adam | epoch: 012 | loss: 0.03250 - acc: 0.9851 -- iter: 1216/2163
[A[ATraining Step: 787  | total loss: [1m[32m0.03097[0m[0m | time: 295.652s
[2K
| Adam | epoch: 012 | loss: 0.03097 - acc: 0.9866 -- iter: 1248/2163
[A[ATraining Step: 788  | total loss: [1m[32m0.02994[0m[0m | time: 303.331s
[2K
| Adam | epoch: 012 | loss: 0.02994 - acc: 0.9879 -- iter: 1280/2163
[A[ATraining Step: 789  | total loss: [1m[32m0.02910[0m[0m | time: 310.873s
[2K
| Adam | epoch: 012 | loss: 0.02910 - acc: 0.9891 -- iter: 1312/2163
[A[ATraining Step: 790  | total loss: [1m[32m0.02968[0m[0m | time: 318.481s
[2K
| Adam | epoch: 012 | loss: 0.02968 - acc: 0.9902 -- iter: 1344/2163
[A[ATraining Step: 791  | total loss: [1m[32m0.02842[0m[0m | time: 326.366s
[2K
| Adam | epoch: 012 | loss: 0.02842 - acc: 0.9912 -- iter: 1376/2163
[A[ATraining Step: 792  | total loss: [1m[32m0.05533[0m[0m | time: 334.038s
[2K
| Adam | epoch: 012 | loss: 0.05533 - acc: 0.9858 -- iter: 1408/2163
[A[ATraining Step: 793  | total loss: [1m[32m0.04995[0m[0m | time: 341.859s
[2K
| Adam | epoch: 012 | loss: 0.04995 - acc: 0.9872 -- iter: 1440/2163
[A[ATraining Step: 794  | total loss: [1m[32m0.05025[0m[0m | time: 349.451s
[2K
| Adam | epoch: 012 | loss: 0.05025 - acc: 0.9854 -- iter: 1472/2163
[A[ATraining Step: 795  | total loss: [1m[32m0.04535[0m[0m | time: 356.973s
[2K
| Adam | epoch: 012 | loss: 0.04535 - acc: 0.9868 -- iter: 1504/2163
[A[ATraining Step: 796  | total loss: [1m[32m0.04376[0m[0m | time: 364.709s
[2K
| Adam | epoch: 012 | loss: 0.04376 - acc: 0.9850 -- iter: 1536/2163
[A[ATraining Step: 797  | total loss: [1m[32m0.04666[0m[0m | time: 372.435s
[2K
| Adam | epoch: 012 | loss: 0.04666 - acc: 0.9865 -- iter: 1568/2163
[A[ATraining Step: 798  | total loss: [1m[32m0.04339[0m[0m | time: 380.105s
[2K
| Adam | epoch: 012 | loss: 0.04339 - acc: 0.9879 -- iter: 1600/2163
[A[ATraining Step: 799  | total loss: [1m[32m0.03976[0m[0m | time: 387.702s
[2K
| Adam | epoch: 012 | loss: 0.03976 - acc: 0.9891 -- iter: 1632/2163
[A[ATraining Step: 800  | total loss: [1m[32m0.03770[0m[0m | time: 425.190s
[2K
| Adam | epoch: 012 | loss: 0.03770 - acc: 0.9902 | val_loss: 0.33163 - val_acc: 0.8759 -- iter: 1664/2163
--
Training Step: 801  | total loss: [1m[32m0.03460[0m[0m | time: 433.032s
[2K
| Adam | epoch: 012 | loss: 0.03460 - acc: 0.9912 -- iter: 1696/2163
[A[ATraining Step: 802  | total loss: [1m[32m0.03171[0m[0m | time: 440.725s
[2K
| Adam | epoch: 012 | loss: 0.03171 - acc: 0.9920 -- iter: 1728/2163
[A[ATraining Step: 803  | total loss: [1m[32m0.02881[0m[0m | time: 448.385s
[2K
| Adam | epoch: 012 | loss: 0.02881 - acc: 0.9928 -- iter: 1760/2163
[A[ATraining Step: 804  | total loss: [1m[32m0.02640[0m[0m | time: 456.083s
[2K
| Adam | epoch: 012 | loss: 0.02640 - acc: 0.9936 -- iter: 1792/2163
[A[ATraining Step: 805  | total loss: [1m[32m0.03289[0m[0m | time: 463.763s
[2K
| Adam | epoch: 012 | loss: 0.03289 - acc: 0.9911 -- iter: 1824/2163
[A[ATraining Step: 806  | total loss: [1m[32m0.03266[0m[0m | time: 471.504s
[2K
| Adam | epoch: 012 | loss: 0.03266 - acc: 0.9920 -- iter: 1856/2163
[A[ATraining Step: 807  | total loss: [1m[32m0.03052[0m[0m | time: 479.220s
[2K
| Adam | epoch: 012 | loss: 0.03052 - acc: 0.9928 -- iter: 1888/2163
[A[ATraining Step: 808  | total loss: [1m[32m0.03258[0m[0m | time: 487.002s
[2K
| Adam | epoch: 012 | loss: 0.03258 - acc: 0.9904 -- iter: 1920/2163
[A[ATraining Step: 809  | total loss: [1m[32m0.03214[0m[0m | time: 494.665s
[2K
| Adam | epoch: 012 | loss: 0.03214 - acc: 0.9913 -- iter: 1952/2163
[A[ATraining Step: 810  | total loss: [1m[32m0.02932[0m[0m | time: 502.210s
[2K
| Adam | epoch: 012 | loss: 0.02932 - acc: 0.9922 -- iter: 1984/2163
[A[ATraining Step: 811  | total loss: [1m[32m0.04048[0m[0m | time: 509.907s
[2K
| Adam | epoch: 012 | loss: 0.04048 - acc: 0.9805 -- iter: 2016/2163
[A[ATraining Step: 812  | total loss: [1m[32m0.03921[0m[0m | time: 517.705s
[2K
| Adam | epoch: 012 | loss: 0.03921 - acc: 0.9824 -- iter: 2048/2163
[A[ATraining Step: 813  | total loss: [1m[32m0.03629[0m[0m | time: 525.401s
[2K
| Adam | epoch: 012 | loss: 0.03629 - acc: 0.9842 -- iter: 2080/2163
[A[ATraining Step: 814  | total loss: [1m[32m0.04018[0m[0m | time: 533.080s
[2K
| Adam | epoch: 012 | loss: 0.04018 - acc: 0.9826 -- iter: 2112/2163
[A[ATraining Step: 815  | total loss: [1m[32m0.03745[0m[0m | time: 540.763s
[2K
| Adam | epoch: 012 | loss: 0.03745 - acc: 0.9844 -- iter: 2144/2163
[A[ATraining Step: 816  | total loss: [1m[32m0.04691[0m[0m | time: 578.541s
[2K
| Adam | epoch: 012 | loss: 0.04691 - acc: 0.9828 | val_loss: 1.62479 - val_acc: 0.6455 -- iter: 2163/2163
--
Training Step: 817  | total loss: [1m[32m0.04751[0m[0m | time: 7.623s
[2K
| Adam | epoch: 013 | loss: 0.04751 - acc: 0.9814 -- iter: 0032/2163
[A[ATraining Step: 818  | total loss: [1m[32m0.04389[0m[0m | time: 15.375s
[2K
| Adam | epoch: 013 | loss: 0.04389 - acc: 0.9833 -- iter: 0064/2163
[A[ATraining Step: 819  | total loss: [1m[32m0.04271[0m[0m | time: 23.179s
[2K
| Adam | epoch: 013 | loss: 0.04271 - acc: 0.9849 -- iter: 0096/2163
[A[ATraining Step: 820  | total loss: [1m[32m0.04011[0m[0m | time: 30.887s
[2K
| Adam | epoch: 013 | loss: 0.04011 - acc: 0.9864 -- iter: 0128/2163
[A[ATraining Step: 821  | total loss: [1m[32m0.03621[0m[0m | time: 38.514s
[2K
| Adam | epoch: 013 | loss: 0.03621 - acc: 0.9878 -- iter: 0160/2163
[A[ATraining Step: 822  | total loss: [1m[32m0.03650[0m[0m | time: 46.319s
[2K
| Adam | epoch: 013 | loss: 0.03650 - acc: 0.9859 -- iter: 0192/2163
[A[ATraining Step: 823  | total loss: [1m[32m0.04217[0m[0m | time: 54.179s
[2K
| Adam | epoch: 013 | loss: 0.04217 - acc: 0.9842 -- iter: 0224/2163
[A[ATraining Step: 824  | total loss: [1m[32m0.04800[0m[0m | time: 61.883s
[2K
| Adam | epoch: 013 | loss: 0.04800 - acc: 0.9826 -- iter: 0256/2163
[A[ATraining Step: 825  | total loss: [1m[32m0.04340[0m[0m | time: 69.524s
[2K
| Adam | epoch: 013 | loss: 0.04340 - acc: 0.9844 -- iter: 0288/2163
[A[ATraining Step: 826  | total loss: [1m[32m0.04057[0m[0m | time: 77.156s
[2K
| Adam | epoch: 013 | loss: 0.04057 - acc: 0.9859 -- iter: 0320/2163
[A[ATraining Step: 827  | total loss: [1m[32m0.03701[0m[0m | time: 82.202s
[2K
| Adam | epoch: 013 | loss: 0.03701 - acc: 0.9873 -- iter: 0352/2163
[A[ATraining Step: 828  | total loss: [1m[32m0.03449[0m[0m | time: 87.343s
[2K
| Adam | epoch: 013 | loss: 0.03449 - acc: 0.9886 -- iter: 0384/2163
[A[ATraining Step: 829  | total loss: [1m[32m0.03170[0m[0m | time: 95.020s
[2K
| Adam | epoch: 013 | loss: 0.03170 - acc: 0.9897 -- iter: 0416/2163
[A[ATraining Step: 830  | total loss: [1m[32m0.03789[0m[0m | time: 102.689s
[2K
| Adam | epoch: 013 | loss: 0.03789 - acc: 0.9845 -- iter: 0448/2163
[A[ATraining Step: 831  | total loss: [1m[32m0.03447[0m[0m | time: 110.277s
[2K
| Adam | epoch: 013 | loss: 0.03447 - acc: 0.9861 -- iter: 0480/2163
[A[ATraining Step: 832  | total loss: [1m[32m0.03313[0m[0m | time: 117.837s
[2K
| Adam | epoch: 013 | loss: 0.03313 - acc: 0.9875 -- iter: 0512/2163
[A[ATraining Step: 833  | total loss: [1m[32m0.05224[0m[0m | time: 125.560s
[2K
| Adam | epoch: 013 | loss: 0.05224 - acc: 0.9762 -- iter: 0544/2163
[A[ATraining Step: 834  | total loss: [1m[32m0.04733[0m[0m | time: 133.362s
[2K
| Adam | epoch: 013 | loss: 0.04733 - acc: 0.9786 -- iter: 0576/2163
[A[ATraining Step: 835  | total loss: [1m[32m0.04384[0m[0m | time: 141.068s
[2K
| Adam | epoch: 013 | loss: 0.04384 - acc: 0.9807 -- iter: 0608/2163
[A[ATraining Step: 836  | total loss: [1m[32m0.04018[0m[0m | time: 148.847s
[2K
| Adam | epoch: 013 | loss: 0.04018 - acc: 0.9827 -- iter: 0640/2163
[A[ATraining Step: 837  | total loss: [1m[32m0.04477[0m[0m | time: 156.593s
[2K
| Adam | epoch: 013 | loss: 0.04477 - acc: 0.9781 -- iter: 0672/2163
[A[ATraining Step: 838  | total loss: [1m[32m0.04083[0m[0m | time: 164.442s
[2K
| Adam | epoch: 013 | loss: 0.04083 - acc: 0.9803 -- iter: 0704/2163
[A[ATraining Step: 839  | total loss: [1m[32m0.04240[0m[0m | time: 172.045s
[2K
| Adam | epoch: 013 | loss: 0.04240 - acc: 0.9792 -- iter: 0736/2163
[A[ATraining Step: 840  | total loss: [1m[32m0.04251[0m[0m | time: 179.809s
[2K
| Adam | epoch: 013 | loss: 0.04251 - acc: 0.9813 -- iter: 0768/2163
[A[ATraining Step: 841  | total loss: [1m[32m0.06062[0m[0m | time: 187.571s
[2K
| Adam | epoch: 013 | loss: 0.06062 - acc: 0.9769 -- iter: 0800/2163
[A[ATraining Step: 842  | total loss: [1m[32m0.05541[0m[0m | time: 195.341s
[2K
| Adam | epoch: 013 | loss: 0.05541 - acc: 0.9792 -- iter: 0832/2163
[A[ATraining Step: 843  | total loss: [1m[32m0.05264[0m[0m | time: 203.156s
[2K
| Adam | epoch: 013 | loss: 0.05264 - acc: 0.9781 -- iter: 0864/2163
[A[ATraining Step: 844  | total loss: [1m[32m0.04970[0m[0m | time: 210.927s
[2K
| Adam | epoch: 013 | loss: 0.04970 - acc: 0.9803 -- iter: 0896/2163
[A[ATraining Step: 845  | total loss: [1m[32m0.04843[0m[0m | time: 218.582s
[2K
| Adam | epoch: 013 | loss: 0.04843 - acc: 0.9823 -- iter: 0928/2163
[A[ATraining Step: 846  | total loss: [1m[32m0.05878[0m[0m | time: 226.226s
[2K
| Adam | epoch: 013 | loss: 0.05878 - acc: 0.9809 -- iter: 0960/2163
[A[ATraining Step: 847  | total loss: [1m[32m0.05550[0m[0m | time: 233.997s
[2K
| Adam | epoch: 013 | loss: 0.05550 - acc: 0.9829 -- iter: 0992/2163
[A[ATraining Step: 848  | total loss: [1m[32m0.05485[0m[0m | time: 241.736s
[2K
| Adam | epoch: 013 | loss: 0.05485 - acc: 0.9814 -- iter: 1024/2163
[A[ATraining Step: 849  | total loss: [1m[32m0.05026[0m[0m | time: 249.653s
[2K
| Adam | epoch: 013 | loss: 0.05026 - acc: 0.9833 -- iter: 1056/2163
[A[ATraining Step: 850  | total loss: [1m[32m0.04557[0m[0m | time: 257.305s
[2K
| Adam | epoch: 013 | loss: 0.04557 - acc: 0.9850 -- iter: 1088/2163
[A[ATraining Step: 851  | total loss: [1m[32m0.04584[0m[0m | time: 265.226s
[2K
| Adam | epoch: 013 | loss: 0.04584 - acc: 0.9833 -- iter: 1120/2163
[A[ATraining Step: 852  | total loss: [1m[32m0.04180[0m[0m | time: 272.967s
[2K
| Adam | epoch: 013 | loss: 0.04180 - acc: 0.9850 -- iter: 1152/2163
[A[ATraining Step: 853  | total loss: [1m[32m0.03980[0m[0m | time: 280.769s
[2K
| Adam | epoch: 013 | loss: 0.03980 - acc: 0.9865 -- iter: 1184/2163
[A[ATraining Step: 854  | total loss: [1m[32m0.03599[0m[0m | time: 288.500s
[2K
| Adam | epoch: 013 | loss: 0.03599 - acc: 0.9879 -- iter: 1216/2163
[A[ATraining Step: 855  | total loss: [1m[32m0.05668[0m[0m | time: 296.201s
[2K
| Adam | epoch: 013 | loss: 0.05668 - acc: 0.9797 -- iter: 1248/2163
[A[ATraining Step: 856  | total loss: [1m[32m0.05133[0m[0m | time: 303.879s
[2K
| Adam | epoch: 013 | loss: 0.05133 - acc: 0.9817 -- iter: 1280/2163
[A[ATraining Step: 857  | total loss: [1m[32m0.04743[0m[0m | time: 311.472s
[2K
| Adam | epoch: 013 | loss: 0.04743 - acc: 0.9836 -- iter: 1312/2163
[A[ATraining Step: 858  | total loss: [1m[32m0.04305[0m[0m | time: 319.096s
[2K
| Adam | epoch: 013 | loss: 0.04305 - acc: 0.9852 -- iter: 1344/2163
[A[ATraining Step: 859  | total loss: [1m[32m0.03920[0m[0m | time: 326.913s
[2K
| Adam | epoch: 013 | loss: 0.03920 - acc: 0.9867 -- iter: 1376/2163
[A[ATraining Step: 860  | total loss: [1m[32m0.03625[0m[0m | time: 334.695s
[2K
| Adam | epoch: 013 | loss: 0.03625 - acc: 0.9880 -- iter: 1408/2163
[A[ATraining Step: 861  | total loss: [1m[32m0.03638[0m[0m | time: 342.449s
[2K
| Adam | epoch: 013 | loss: 0.03638 - acc: 0.9861 -- iter: 1440/2163
[A[ATraining Step: 862  | total loss: [1m[32m0.04078[0m[0m | time: 350.133s
[2K
| Adam | epoch: 013 | loss: 0.04078 - acc: 0.9844 -- iter: 1472/2163
[A[ATraining Step: 863  | total loss: [1m[32m0.04159[0m[0m | time: 357.929s
[2K
| Adam | epoch: 013 | loss: 0.04159 - acc: 0.9828 -- iter: 1504/2163
[A[ATraining Step: 864  | total loss: [1m[32m0.03790[0m[0m | time: 365.885s
[2K
| Adam | epoch: 013 | loss: 0.03790 - acc: 0.9845 -- iter: 1536/2163
[A[ATraining Step: 865  | total loss: [1m[32m0.03484[0m[0m | time: 373.662s
[2K
| Adam | epoch: 013 | loss: 0.03484 - acc: 0.9861 -- iter: 1568/2163
[A[ATraining Step: 866  | total loss: [1m[32m0.03564[0m[0m | time: 381.516s
[2K
| Adam | epoch: 013 | loss: 0.03564 - acc: 0.9875 -- iter: 1600/2163
[A[ATraining Step: 867  | total loss: [1m[32m0.03233[0m[0m | time: 389.176s
[2K
| Adam | epoch: 013 | loss: 0.03233 - acc: 0.9887 -- iter: 1632/2163
[A[ATraining Step: 868  | total loss: [1m[32m0.02961[0m[0m | time: 396.943s
[2K
| Adam | epoch: 013 | loss: 0.02961 - acc: 0.9898 -- iter: 1664/2163
[A[ATraining Step: 869  | total loss: [1m[32m0.03550[0m[0m | time: 404.663s
[2K
| Adam | epoch: 013 | loss: 0.03550 - acc: 0.9846 -- iter: 1696/2163
[A[ATraining Step: 870  | total loss: [1m[32m0.03771[0m[0m | time: 412.261s
[2K
| Adam | epoch: 013 | loss: 0.03771 - acc: 0.9830 -- iter: 1728/2163
[A[ATraining Step: 871  | total loss: [1m[32m0.03434[0m[0m | time: 420.041s
[2K
| Adam | epoch: 013 | loss: 0.03434 - acc: 0.9847 -- iter: 1760/2163
[A[ATraining Step: 872  | total loss: [1m[32m0.03120[0m[0m | time: 427.560s
[2K
| Adam | epoch: 013 | loss: 0.03120 - acc: 0.9862 -- iter: 1792/2163
[A[ATraining Step: 873  | total loss: [1m[32m0.03084[0m[0m | time: 435.205s
[2K
| Adam | epoch: 013 | loss: 0.03084 - acc: 0.9876 -- iter: 1824/2163
[A[ATraining Step: 874  | total loss: [1m[32m0.02799[0m[0m | time: 443.122s
[2K
| Adam | epoch: 013 | loss: 0.02799 - acc: 0.9889 -- iter: 1856/2163
[A[ATraining Step: 875  | total loss: [1m[32m0.03107[0m[0m | time: 450.931s
[2K
| Adam | epoch: 013 | loss: 0.03107 - acc: 0.9868 -- iter: 1888/2163
[A[ATraining Step: 876  | total loss: [1m[32m0.02876[0m[0m | time: 458.714s
[2K
| Adam | epoch: 013 | loss: 0.02876 - acc: 0.9882 -- iter: 1920/2163
[A[ATraining Step: 877  | total loss: [1m[32m0.02669[0m[0m | time: 466.366s
[2K
| Adam | epoch: 013 | loss: 0.02669 - acc: 0.9893 -- iter: 1952/2163
[A[ATraining Step: 878  | total loss: [1m[32m0.02544[0m[0m | time: 473.945s
[2K
| Adam | epoch: 013 | loss: 0.02544 - acc: 0.9904 -- iter: 1984/2163
[A[ATraining Step: 879  | total loss: [1m[32m0.02399[0m[0m | time: 481.709s
[2K
| Adam | epoch: 013 | loss: 0.02399 - acc: 0.9914 -- iter: 2016/2163
[A[ATraining Step: 880  | total loss: [1m[32m0.02197[0m[0m | time: 489.355s
[2K
| Adam | epoch: 013 | loss: 0.02197 - acc: 0.9922 -- iter: 2048/2163
[A[ATraining Step: 881  | total loss: [1m[32m0.01991[0m[0m | time: 497.135s
[2K
| Adam | epoch: 013 | loss: 0.01991 - acc: 0.9930 -- iter: 2080/2163
[A[ATraining Step: 882  | total loss: [1m[32m0.01823[0m[0m | time: 504.900s
[2K
| Adam | epoch: 013 | loss: 0.01823 - acc: 0.9937 -- iter: 2112/2163
[A[ATraining Step: 883  | total loss: [1m[32m0.01756[0m[0m | time: 512.722s
[2K
| Adam | epoch: 013 | loss: 0.01756 - acc: 0.9943 -- iter: 2144/2163
[A[ATraining Step: 884  | total loss: [1m[32m0.01677[0m[0m | time: 549.980s
[2K
| Adam | epoch: 013 | loss: 0.01677 - acc: 0.9949 | val_loss: 0.22877 - val_acc: 0.9247 -- iter: 2163/2163
--
Training Step: 885  | total loss: [1m[32m0.01518[0m[0m | time: 7.725s
[2K
| Adam | epoch: 014 | loss: 0.01518 - acc: 0.9954 -- iter: 0032/2163
[A[ATraining Step: 886  | total loss: [1m[32m0.01723[0m[0m | time: 15.524s
[2K
| Adam | epoch: 014 | loss: 0.01723 - acc: 0.9927 -- iter: 0064/2163
[A[ATraining Step: 887  | total loss: [1m[32m0.01840[0m[0m | time: 23.157s
[2K
| Adam | epoch: 014 | loss: 0.01840 - acc: 0.9935 -- iter: 0096/2163
[A[ATraining Step: 888  | total loss: [1m[32m0.01695[0m[0m | time: 30.812s
[2K
| Adam | epoch: 014 | loss: 0.01695 - acc: 0.9941 -- iter: 0128/2163
[A[ATraining Step: 889  | total loss: [1m[32m0.01574[0m[0m | time: 38.519s
[2K
| Adam | epoch: 014 | loss: 0.01574 - acc: 0.9947 -- iter: 0160/2163
[A[ATraining Step: 890  | total loss: [1m[32m0.01426[0m[0m | time: 46.219s
[2K
| Adam | epoch: 014 | loss: 0.01426 - acc: 0.9952 -- iter: 0192/2163
[A[ATraining Step: 891  | total loss: [1m[32m0.01295[0m[0m | time: 53.986s
[2K
| Adam | epoch: 014 | loss: 0.01295 - acc: 0.9957 -- iter: 0224/2163
[A[ATraining Step: 892  | total loss: [1m[32m0.01212[0m[0m | time: 61.619s
[2K
| Adam | epoch: 014 | loss: 0.01212 - acc: 0.9961 -- iter: 0256/2163
[A[ATraining Step: 893  | total loss: [1m[32m0.01142[0m[0m | time: 69.312s
[2K
| Adam | epoch: 014 | loss: 0.01142 - acc: 0.9965 -- iter: 0288/2163
[A[ATraining Step: 894  | total loss: [1m[32m0.01043[0m[0m | time: 76.972s
[2K
| Adam | epoch: 014 | loss: 0.01043 - acc: 0.9969 -- iter: 0320/2163
[A[ATraining Step: 895  | total loss: [1m[32m0.01212[0m[0m | time: 84.631s
[2K
| Adam | epoch: 014 | loss: 0.01212 - acc: 0.9941 -- iter: 0352/2163
[A[ATraining Step: 896  | total loss: [1m[32m0.01100[0m[0m | time: 89.843s
[2K
| Adam | epoch: 014 | loss: 0.01100 - acc: 0.9947 -- iter: 0384/2163
[A[ATraining Step: 897  | total loss: [1m[32m0.01564[0m[0m | time: 94.967s
[2K
| Adam | epoch: 014 | loss: 0.01564 - acc: 0.9952 -- iter: 0416/2163
[A[ATraining Step: 898  | total loss: [1m[32m0.01433[0m[0m | time: 102.611s
[2K
| Adam | epoch: 014 | loss: 0.01433 - acc: 0.9957 -- iter: 0448/2163
[A[ATraining Step: 899  | total loss: [1m[32m0.01304[0m[0m | time: 110.330s
[2K
| Adam | epoch: 014 | loss: 0.01304 - acc: 0.9961 -- iter: 0480/2163
[A[ATraining Step: 900  | total loss: [1m[32m0.01675[0m[0m | time: 118.063s
[2K
| Adam | epoch: 014 | loss: 0.01675 - acc: 0.9934 -- iter: 0512/2163
[A[ATraining Step: 901  | total loss: [1m[32m0.01572[0m[0m | time: 125.847s
[2K
| Adam | epoch: 014 | loss: 0.01572 - acc: 0.9940 -- iter: 0544/2163
[A[ATraining Step: 902  | total loss: [1m[32m0.01735[0m[0m | time: 133.483s
[2K
| Adam | epoch: 014 | loss: 0.01735 - acc: 0.9915 -- iter: 0576/2163
[A[ATraining Step: 903  | total loss: [1m[32m0.02522[0m[0m | time: 141.230s
[2K
| Adam | epoch: 014 | loss: 0.02522 - acc: 0.9892 -- iter: 0608/2163
[A[ATraining Step: 904  | total loss: [1m[32m0.02283[0m[0m | time: 149.152s
[2K
| Adam | epoch: 014 | loss: 0.02283 - acc: 0.9903 -- iter: 0640/2163
[A[ATraining Step: 905  | total loss: [1m[32m0.04165[0m[0m | time: 156.804s
[2K
| Adam | epoch: 014 | loss: 0.04165 - acc: 0.9850 -- iter: 0672/2163
[A[ATraining Step: 906  | total loss: [1m[32m0.03758[0m[0m | time: 164.595s
[2K
| Adam | epoch: 014 | loss: 0.03758 - acc: 0.9865 -- iter: 0704/2163
[A[ATraining Step: 907  | total loss: [1m[32m0.03469[0m[0m | time: 172.364s
[2K
| Adam | epoch: 014 | loss: 0.03469 - acc: 0.9879 -- iter: 0736/2163
[A[ATraining Step: 908  | total loss: [1m[32m0.03133[0m[0m | time: 179.939s
[2K
| Adam | epoch: 014 | loss: 0.03133 - acc: 0.9891 -- iter: 0768/2163
[A[ATraining Step: 909  | total loss: [1m[32m0.02843[0m[0m | time: 187.600s
[2K
| Adam | epoch: 014 | loss: 0.02843 - acc: 0.9902 -- iter: 0800/2163
[A[ATraining Step: 910  | total loss: [1m[32m0.04101[0m[0m | time: 195.207s
[2K
| Adam | epoch: 014 | loss: 0.04101 - acc: 0.9849 -- iter: 0832/2163
[A[ATraining Step: 911  | total loss: [1m[32m0.03994[0m[0m | time: 203.003s
[2K
| Adam | epoch: 014 | loss: 0.03994 - acc: 0.9864 -- iter: 0864/2163
[A[ATraining Step: 912  | total loss: [1m[32m0.03668[0m[0m | time: 210.624s
[2K
| Adam | epoch: 014 | loss: 0.03668 - acc: 0.9878 -- iter: 0896/2163
[A[ATraining Step: 913  | total loss: [1m[32m0.03374[0m[0m | time: 218.357s
[2K
| Adam | epoch: 014 | loss: 0.03374 - acc: 0.9890 -- iter: 0928/2163
[A[ATraining Step: 914  | total loss: [1m[32m0.03233[0m[0m | time: 226.156s
[2K
| Adam | epoch: 014 | loss: 0.03233 - acc: 0.9901 -- iter: 0960/2163
[A[ATraining Step: 915  | total loss: [1m[32m0.04420[0m[0m | time: 233.805s
[2K
| Adam | epoch: 014 | loss: 0.04420 - acc: 0.9848 -- iter: 0992/2163
[A[ATraining Step: 916  | total loss: [1m[32m0.04136[0m[0m | time: 241.500s
[2K
| Adam | epoch: 014 | loss: 0.04136 - acc: 0.9864 -- iter: 1024/2163
[A[ATraining Step: 917  | total loss: [1m[32m0.03860[0m[0m | time: 249.116s
[2K
| Adam | epoch: 014 | loss: 0.03860 - acc: 0.9877 -- iter: 1056/2163
[A[ATraining Step: 918  | total loss: [1m[32m0.03654[0m[0m | time: 256.663s
[2K
| Adam | epoch: 014 | loss: 0.03654 - acc: 0.9889 -- iter: 1088/2163
[A[ATraining Step: 919  | total loss: [1m[32m0.03670[0m[0m | time: 264.439s
[2K
| Adam | epoch: 014 | loss: 0.03670 - acc: 0.9901 -- iter: 1120/2163
[A[ATraining Step: 920  | total loss: [1m[32m0.03414[0m[0m | time: 272.095s
[2K
| Adam | epoch: 014 | loss: 0.03414 - acc: 0.9910 -- iter: 1152/2163
[A[ATraining Step: 921  | total loss: [1m[32m0.03130[0m[0m | time: 279.923s
[2K
| Adam | epoch: 014 | loss: 0.03130 - acc: 0.9919 -- iter: 1184/2163
[A[ATraining Step: 922  | total loss: [1m[32m0.06849[0m[0m | time: 287.714s
[2K
| Adam | epoch: 014 | loss: 0.06849 - acc: 0.9771 -- iter: 1216/2163
[A[ATraining Step: 923  | total loss: [1m[32m0.07167[0m[0m | time: 295.463s
[2K
| Adam | epoch: 014 | loss: 0.07167 - acc: 0.9732 -- iter: 1248/2163
[A[ATraining Step: 924  | total loss: [1m[32m0.06554[0m[0m | time: 303.072s
[2K
| Adam | epoch: 014 | loss: 0.06554 - acc: 0.9758 -- iter: 1280/2163
[A[ATraining Step: 925  | total loss: [1m[32m0.06209[0m[0m | time: 310.840s
[2K
| Adam | epoch: 014 | loss: 0.06209 - acc: 0.9783 -- iter: 1312/2163
[A[ATraining Step: 926  | total loss: [1m[32m0.05898[0m[0m | time: 318.485s
[2K
| Adam | epoch: 014 | loss: 0.05898 - acc: 0.9804 -- iter: 1344/2163
[A[ATraining Step: 927  | total loss: [1m[32m0.05391[0m[0m | time: 326.476s
[2K
| Adam | epoch: 014 | loss: 0.05391 - acc: 0.9824 -- iter: 1376/2163
[A[ATraining Step: 928  | total loss: [1m[32m0.06721[0m[0m | time: 334.135s
[2K
| Adam | epoch: 014 | loss: 0.06721 - acc: 0.9779 -- iter: 1408/2163
[A[ATraining Step: 929  | total loss: [1m[32m0.07551[0m[0m | time: 341.879s
[2K
| Adam | epoch: 014 | loss: 0.07551 - acc: 0.9739 -- iter: 1440/2163
[A[ATraining Step: 930  | total loss: [1m[32m0.06949[0m[0m | time: 349.623s
[2K
| Adam | epoch: 014 | loss: 0.06949 - acc: 0.9765 -- iter: 1472/2163
[A[ATraining Step: 931  | total loss: [1m[32m0.06348[0m[0m | time: 357.293s
[2K
| Adam | epoch: 014 | loss: 0.06348 - acc: 0.9788 -- iter: 1504/2163
[A[ATraining Step: 932  | total loss: [1m[32m0.06428[0m[0m | time: 365.023s
[2K
| Adam | epoch: 014 | loss: 0.06428 - acc: 0.9778 -- iter: 1536/2163
[A[ATraining Step: 933  | total loss: [1m[32m0.06681[0m[0m | time: 372.851s
[2K
| Adam | epoch: 014 | loss: 0.06681 - acc: 0.9769 -- iter: 1568/2163
[A[ATraining Step: 934  | total loss: [1m[32m0.13362[0m[0m | time: 380.518s
[2K
| Adam | epoch: 014 | loss: 0.13362 - acc: 0.9730 -- iter: 1600/2163
[A[ATraining Step: 935  | total loss: [1m[32m0.12544[0m[0m | time: 388.296s
[2K
| Adam | epoch: 014 | loss: 0.12544 - acc: 0.9725 -- iter: 1632/2163
[A[ATraining Step: 936  | total loss: [1m[32m0.13014[0m[0m | time: 396.148s
[2K
| Adam | epoch: 014 | loss: 0.13014 - acc: 0.9690 -- iter: 1664/2163
[A[ATraining Step: 937  | total loss: [1m[32m0.12334[0m[0m | time: 403.833s
[2K
| Adam | epoch: 014 | loss: 0.12334 - acc: 0.9690 -- iter: 1696/2163
[A[ATraining Step: 938  | total loss: [1m[32m0.11994[0m[0m | time: 411.471s
[2K
| Adam | epoch: 014 | loss: 0.11994 - acc: 0.9690 -- iter: 1728/2163
[A[ATraining Step: 939  | total loss: [1m[32m0.11264[0m[0m | time: 419.030s
[2K
| Adam | epoch: 014 | loss: 0.11264 - acc: 0.9690 -- iter: 1760/2163
[A[ATraining Step: 940  | total loss: [1m[32m0.10472[0m[0m | time: 426.820s
[2K
| Adam | epoch: 014 | loss: 0.10472 - acc: 0.9721 -- iter: 1792/2163
[A[ATraining Step: 941  | total loss: [1m[32m0.11036[0m[0m | time: 434.533s
[2K
| Adam | epoch: 014 | loss: 0.11036 - acc: 0.9686 -- iter: 1824/2163
[A[ATraining Step: 942  | total loss: [1m[32m0.11033[0m[0m | time: 442.412s
[2K
| Adam | epoch: 014 | loss: 0.11033 - acc: 0.9655 -- iter: 1856/2163
[A[ATraining Step: 943  | total loss: [1m[32m0.10351[0m[0m | time: 450.068s
[2K
| Adam | epoch: 014 | loss: 0.10351 - acc: 0.9690 -- iter: 1888/2163
[A[ATraining Step: 944  | total loss: [1m[32m0.10682[0m[0m | time: 457.808s
[2K
| Adam | epoch: 014 | loss: 0.10682 - acc: 0.9658 -- iter: 1920/2163
[A[ATraining Step: 945  | total loss: [1m[32m0.09657[0m[0m | time: 465.507s
[2K
| Adam | epoch: 014 | loss: 0.09657 - acc: 0.9692 -- iter: 1952/2163
[A[ATraining Step: 946  | total loss: [1m[32m0.09775[0m[0m | time: 473.130s
[2K
| Adam | epoch: 014 | loss: 0.09775 - acc: 0.9629 -- iter: 1984/2163
[A[ATraining Step: 947  | total loss: [1m[32m0.08902[0m[0m | time: 480.785s
[2K
| Adam | epoch: 014 | loss: 0.08902 - acc: 0.9666 -- iter: 2016/2163
[A[ATraining Step: 948  | total loss: [1m[32m0.08094[0m[0m | time: 488.417s
[2K
| Adam | epoch: 014 | loss: 0.08094 - acc: 0.9700 -- iter: 2048/2163
[A[ATraining Step: 949  | total loss: [1m[32m0.07316[0m[0m | time: 495.981s
[2K
| Adam | epoch: 014 | loss: 0.07316 - acc: 0.9730 -- iter: 2080/2163
[A[ATraining Step: 950  | total loss: [1m[32m0.08428[0m[0m | time: 503.722s
[2K
| Adam | epoch: 014 | loss: 0.08428 - acc: 0.9726 -- iter: 2112/2163
[A[ATraining Step: 951  | total loss: [1m[32m0.07631[0m[0m | time: 511.433s
[2K
| Adam | epoch: 014 | loss: 0.07631 - acc: 0.9753 -- iter: 2144/2163
[A[ATraining Step: 952  | total loss: [1m[32m0.06963[0m[0m | time: 549.137s
[2K
| Adam | epoch: 014 | loss: 0.06963 - acc: 0.9778 | val_loss: 0.30676 - val_acc: 0.9084 -- iter: 2163/2163
--
Training Step: 953  | total loss: [1m[32m0.06489[0m[0m | time: 7.587s
[2K
| Adam | epoch: 015 | loss: 0.06489 - acc: 0.9800 -- iter: 0032/2163
[A[ATraining Step: 954  | total loss: [1m[32m0.05962[0m[0m | time: 15.306s
[2K
| Adam | epoch: 015 | loss: 0.05962 - acc: 0.9820 -- iter: 0064/2163
[A[ATraining Step: 955  | total loss: [1m[32m0.05409[0m[0m | time: 23.025s
[2K
| Adam | epoch: 015 | loss: 0.05409 - acc: 0.9838 -- iter: 0096/2163
[A[ATraining Step: 956  | total loss: [1m[32m0.05029[0m[0m | time: 30.715s
[2K
| Adam | epoch: 015 | loss: 0.05029 - acc: 0.9854 -- iter: 0128/2163
[A[ATraining Step: 957  | total loss: [1m[32m0.05995[0m[0m | time: 38.388s
[2K
| Adam | epoch: 015 | loss: 0.05995 - acc: 0.9837 -- iter: 0160/2163
[A[ATraining Step: 958  | total loss: [1m[32m0.05463[0m[0m | time: 46.095s
[2K
| Adam | epoch: 015 | loss: 0.05463 - acc: 0.9854 -- iter: 0192/2163
[A[ATraining Step: 959  | total loss: [1m[32m0.04988[0m[0m | time: 53.904s
[2K
| Adam | epoch: 015 | loss: 0.04988 - acc: 0.9868 -- iter: 0224/2163
[A[ATraining Step: 960  | total loss: [1m[32m0.05162[0m[0m | time: 61.583s
[2K
| Adam | epoch: 015 | loss: 0.05162 - acc: 0.9850 -- iter: 0256/2163
[A[ATraining Step: 961  | total loss: [1m[32m0.05635[0m[0m | time: 69.343s
[2K
| Adam | epoch: 015 | loss: 0.05635 - acc: 0.9803 -- iter: 0288/2163
[A[ATraining Step: 962  | total loss: [1m[32m0.06576[0m[0m | time: 77.134s
[2K
| Adam | epoch: 015 | loss: 0.06576 - acc: 0.9760 -- iter: 0320/2163
[A[ATraining Step: 963  | total loss: [1m[32m0.06109[0m[0m | time: 84.865s
[2K
| Adam | epoch: 015 | loss: 0.06109 - acc: 0.9784 -- iter: 0352/2163
[A[ATraining Step: 964  | total loss: [1m[32m0.05554[0m[0m | time: 92.535s
[2K
| Adam | epoch: 015 | loss: 0.05554 - acc: 0.9806 -- iter: 0384/2163
[A[ATraining Step: 965  | total loss: [1m[32m0.05132[0m[0m | time: 97.860s
[2K
| Adam | epoch: 015 | loss: 0.05132 - acc: 0.9825 -- iter: 0416/2163
[A[ATraining Step: 966  | total loss: [1m[32m0.04795[0m[0m | time: 102.882s
[2K
| Adam | epoch: 015 | loss: 0.04795 - acc: 0.9843 -- iter: 0448/2163
[A[ATraining Step: 967  | total loss: [1m[32m0.04384[0m[0m | time: 110.420s
[2K
| Adam | epoch: 015 | loss: 0.04384 - acc: 0.9858 -- iter: 0480/2163
[A[ATraining Step: 968  | total loss: [1m[32m0.05796[0m[0m | time: 118.350s
[2K
| Adam | epoch: 015 | loss: 0.05796 - acc: 0.9779 -- iter: 0512/2163
[A[ATraining Step: 969  | total loss: [1m[32m0.05304[0m[0m | time: 126.077s
[2K
| Adam | epoch: 015 | loss: 0.05304 - acc: 0.9801 -- iter: 0544/2163
[A[ATraining Step: 970  | total loss: [1m[32m0.04861[0m[0m | time: 133.884s
[2K
| Adam | epoch: 015 | loss: 0.04861 - acc: 0.9821 -- iter: 0576/2163
[A[ATraining Step: 971  | total loss: [1m[32m0.04508[0m[0m | time: 141.647s
[2K
| Adam | epoch: 015 | loss: 0.04508 - acc: 0.9839 -- iter: 0608/2163
[A[ATraining Step: 972  | total loss: [1m[32m0.04096[0m[0m | time: 149.317s
[2K
| Adam | epoch: 015 | loss: 0.04096 - acc: 0.9855 -- iter: 0640/2163
[A[ATraining Step: 973  | total loss: [1m[32m0.04265[0m[0m | time: 156.990s
[2K
| Adam | epoch: 015 | loss: 0.04265 - acc: 0.9838 -- iter: 0672/2163
[A[ATraining Step: 974  | total loss: [1m[32m0.04861[0m[0m | time: 164.641s
[2K
| Adam | epoch: 015 | loss: 0.04861 - acc: 0.9823 -- iter: 0704/2163
[A[ATraining Step: 975  | total loss: [1m[32m0.04396[0m[0m | time: 172.541s
[2K
| Adam | epoch: 015 | loss: 0.04396 - acc: 0.9841 -- iter: 0736/2163
[A[ATraining Step: 976  | total loss: [1m[32m0.04073[0m[0m | time: 180.314s
[2K
| Adam | epoch: 015 | loss: 0.04073 - acc: 0.9857 -- iter: 0768/2163
[A[ATraining Step: 977  | total loss: [1m[32m0.03779[0m[0m | time: 187.978s
[2K
| Adam | epoch: 015 | loss: 0.03779 - acc: 0.9871 -- iter: 0800/2163
[A[ATraining Step: 978  | total loss: [1m[32m0.03565[0m[0m | time: 195.790s
[2K
| Adam | epoch: 015 | loss: 0.03565 - acc: 0.9884 -- iter: 0832/2163
[A[ATraining Step: 979  | total loss: [1m[32m0.03261[0m[0m | time: 203.516s
[2K
| Adam | epoch: 015 | loss: 0.03261 - acc: 0.9895 -- iter: 0864/2163
[A[ATraining Step: 980  | total loss: [1m[32m0.03526[0m[0m | time: 211.245s
[2K
| Adam | epoch: 015 | loss: 0.03526 - acc: 0.9875 -- iter: 0896/2163
[A[ATraining Step: 981  | total loss: [1m[32m0.04024[0m[0m | time: 218.912s
[2K
| Adam | epoch: 015 | loss: 0.04024 - acc: 0.9825 -- iter: 0928/2163
[A[ATraining Step: 982  | total loss: [1m[32m0.03811[0m[0m | time: 226.743s
[2K
| Adam | epoch: 015 | loss: 0.03811 - acc: 0.9842 -- iter: 0960/2163
[A[ATraining Step: 983  | total loss: [1m[32m0.03776[0m[0m | time: 234.664s
[2K
| Adam | epoch: 015 | loss: 0.03776 - acc: 0.9827 -- iter: 0992/2163
[A[ATraining Step: 984  | total loss: [1m[32m0.03565[0m[0m | time: 242.383s
[2K
| Adam | epoch: 015 | loss: 0.03565 - acc: 0.9844 -- iter: 1024/2163
[A[ATraining Step: 985  | total loss: [1m[32m0.03322[0m[0m | time: 250.121s
[2K
| Adam | epoch: 015 | loss: 0.03322 - acc: 0.9860 -- iter: 1056/2163
[A[ATraining Step: 986  | total loss: [1m[32m0.02999[0m[0m | time: 257.900s
[2K
| Adam | epoch: 015 | loss: 0.02999 - acc: 0.9874 -- iter: 1088/2163
[A[ATraining Step: 987  | total loss: [1m[32m0.02764[0m[0m | time: 265.610s
[2K
| Adam | epoch: 015 | loss: 0.02764 - acc: 0.9886 -- iter: 1120/2163
[A[ATraining Step: 988  | total loss: [1m[32m0.02681[0m[0m | time: 273.392s
[2K
| Adam | epoch: 015 | loss: 0.02681 - acc: 0.9898 -- iter: 1152/2163
[A[ATraining Step: 989  | total loss: [1m[32m0.02477[0m[0m | time: 281.274s
[2K
| Adam | epoch: 015 | loss: 0.02477 - acc: 0.9908 -- iter: 1184/2163
[A[ATraining Step: 990  | total loss: [1m[32m0.02256[0m[0m | time: 288.841s
[2K
| Adam | epoch: 015 | loss: 0.02256 - acc: 0.9917 -- iter: 1216/2163
[A[ATraining Step: 991  | total loss: [1m[32m0.02820[0m[0m | time: 296.512s
[2K
| Adam | epoch: 015 | loss: 0.02820 - acc: 0.9894 -- iter: 1248/2163
[A[ATraining Step: 992  | total loss: [1m[32m0.03894[0m[0m | time: 304.118s
[2K
| Adam | epoch: 015 | loss: 0.03894 - acc: 0.9811 -- iter: 1280/2163
[A[ATraining Step: 993  | total loss: [1m[32m0.03528[0m[0m | time: 311.838s
[2K
| Adam | epoch: 015 | loss: 0.03528 - acc: 0.9830 -- iter: 1312/2163
[A[ATraining Step: 994  | total loss: [1m[32m0.04132[0m[0m | time: 319.533s
[2K
| Adam | epoch: 015 | loss: 0.04132 - acc: 0.9816 -- iter: 1344/2163
[A[ATraining Step: 995  | total loss: [1m[32m0.04064[0m[0m | time: 327.297s
[2K
| Adam | epoch: 015 | loss: 0.04064 - acc: 0.9834 -- iter: 1376/2163
[A[ATraining Step: 996  | total loss: [1m[32m0.04051[0m[0m | time: 334.904s
[2K
| Adam | epoch: 015 | loss: 0.04051 - acc: 0.9851 -- iter: 1408/2163
[A[ATraining Step: 997  | total loss: [1m[32m0.04270[0m[0m | time: 342.607s
[2K
| Adam | epoch: 015 | loss: 0.04270 - acc: 0.9834 -- iter: 1440/2163
[A[ATraining Step: 998  | total loss: [1m[32m0.04013[0m[0m | time: 350.324s
[2K
| Adam | epoch: 015 | loss: 0.04013 - acc: 0.9851 -- iter: 1472/2163
[A[ATraining Step: 999  | total loss: [1m[32m0.04436[0m[0m | time: 358.227s
[2K
| Adam | epoch: 015 | loss: 0.04436 - acc: 0.9803 -- iter: 1504/2163
[A[ATraining Step: 1000  | total loss: [1m[32m0.04153[0m[0m | time: 395.618s
[2K
| Adam | epoch: 015 | loss: 0.04153 - acc: 0.9823 | val_loss: 0.85908 - val_acc: 0.7917 -- iter: 1536/2163
--
Training Step: 1001  | total loss: [1m[32m0.03755[0m[0m | time: 403.286s
[2K
| Adam | epoch: 015 | loss: 0.03755 - acc: 0.9841 -- iter: 1568/2163
[A[ATraining Step: 1002  | total loss: [1m[32m0.03879[0m[0m | time: 411.058s
[2K
| Adam | epoch: 015 | loss: 0.03879 - acc: 0.9825 -- iter: 1600/2163
[A[ATraining Step: 1003  | total loss: [1m[32m0.08368[0m[0m | time: 418.776s
[2K
| Adam | epoch: 015 | loss: 0.08368 - acc: 0.9812 -- iter: 1632/2163
[A[ATraining Step: 1004  | total loss: [1m[32m0.07563[0m[0m | time: 426.599s
[2K
| Adam | epoch: 015 | loss: 0.07563 - acc: 0.9830 -- iter: 1664/2163
[A[ATraining Step: 1005  | total loss: [1m[32m0.06849[0m[0m | time: 434.327s
[2K
| Adam | epoch: 015 | loss: 0.06849 - acc: 0.9847 -- iter: 1696/2163
[A[ATraining Step: 1006  | total loss: [1m[32m0.07368[0m[0m | time: 442.089s
[2K
| Adam | epoch: 015 | loss: 0.07368 - acc: 0.9831 -- iter: 1728/2163
[A[ATraining Step: 1007  | total loss: [1m[32m0.06741[0m[0m | time: 449.911s
[2K
| Adam | epoch: 015 | loss: 0.06741 - acc: 0.9848 -- iter: 1760/2163
[A[ATraining Step: 1008  | total loss: [1m[32m0.06364[0m[0m | time: 457.536s
[2K
| Adam | epoch: 015 | loss: 0.06364 - acc: 0.9863 -- iter: 1792/2163
[A[ATraining Step: 1009  | total loss: [1m[32m0.05794[0m[0m | time: 465.366s
[2K
| Adam | epoch: 015 | loss: 0.05794 - acc: 0.9877 -- iter: 1824/2163
[A[ATraining Step: 1010  | total loss: [1m[32m0.05227[0m[0m | time: 473.181s
[2K
| Adam | epoch: 015 | loss: 0.05227 - acc: 0.9889 -- iter: 1856/2163
[A[ATraining Step: 1011  | total loss: [1m[32m0.05517[0m[0m | time: 480.917s
[2K
| Adam | epoch: 015 | loss: 0.05517 - acc: 0.9869 -- iter: 1888/2163
[A[ATraining Step: 1012  | total loss: [1m[32m0.04980[0m[0m | time: 488.677s
[2K
| Adam | epoch: 015 | loss: 0.04980 - acc: 0.9882 -- iter: 1920/2163
[A[ATraining Step: 1013  | total loss: [1m[32m0.07672[0m[0m | time: 496.354s
[2K
| Adam | epoch: 015 | loss: 0.07672 - acc: 0.9832 -- iter: 1952/2163
[A[ATraining Step: 1014  | total loss: [1m[32m0.07042[0m[0m | time: 503.993s
[2K
| Adam | epoch: 015 | loss: 0.07042 - acc: 0.9848 -- iter: 1984/2163
[A[ATraining Step: 1015  | total loss: [1m[32m0.10509[0m[0m | time: 511.838s
[2K
| Adam | epoch: 015 | loss: 0.10509 - acc: 0.9707 -- iter: 2016/2163
[A[ATraining Step: 1016  | total loss: [1m[32m0.09541[0m[0m | time: 519.544s
[2K
| Adam | epoch: 015 | loss: 0.09541 - acc: 0.9737 -- iter: 2048/2163
[A[ATraining Step: 1017  | total loss: [1m[32m0.09156[0m[0m | time: 527.307s
[2K
| Adam | epoch: 015 | loss: 0.09156 - acc: 0.9700 -- iter: 2080/2163
[A[ATraining Step: 1018  | total loss: [1m[32m0.08565[0m[0m | time: 534.971s
[2K
| Adam | epoch: 015 | loss: 0.08565 - acc: 0.9730 -- iter: 2112/2163
[A[ATraining Step: 1019  | total loss: [1m[32m0.07936[0m[0m | time: 542.641s
[2K
| Adam | epoch: 015 | loss: 0.07936 - acc: 0.9757 -- iter: 2144/2163
[A[ATraining Step: 1020  | total loss: [1m[32m0.07169[0m[0m | time: 598.838s
[2K
| Adam | epoch: 015 | loss: 0.07169 - acc: 0.9782 | val_loss: 0.29101 - val_acc: 0.9099 -- iter: 2163/2163
--
Training Step: 1021  | total loss: [1m[32m0.06500[0m[0m | time: 12.828s
[2K
| Adam | epoch: 016 | loss: 0.06500 - acc: 0.9803 -- iter: 0032/2163
[A[ATraining Step: 1022  | total loss: [1m[32m0.07336[0m[0m | time: 25.045s
[2K
| Adam | epoch: 016 | loss: 0.07336 - acc: 0.9792 -- iter: 0064/2163
[A[ATraining Step: 1023  | total loss: [1m[32m0.06762[0m[0m | time: 37.913s
[2K
| Adam | epoch: 016 | loss: 0.06762 - acc: 0.9813 -- iter: 0096/2163
[A[ATraining Step: 1024  | total loss: [1m[32m0.07159[0m[0m | time: 51.066s
[2K
| Adam | epoch: 016 | loss: 0.07159 - acc: 0.9800 -- iter: 0128/2163
[A[ATraining Step: 1025  | total loss: [1m[32m0.06489[0m[0m | time: 63.798s
[2K
| Adam | epoch: 016 | loss: 0.06489 - acc: 0.9820 -- iter: 0160/2163
[A[ATraining Step: 1026  | total loss: [1m[32m0.05881[0m[0m | time: 76.151s
[2K
| Adam | epoch: 016 | loss: 0.05881 - acc: 0.9838 -- iter: 0192/2163
[A[ATraining Step: 1027  | total loss: [1m[32m0.05607[0m[0m | time: 88.396s
[2K
| Adam | epoch: 016 | loss: 0.05607 - acc: 0.9823 -- iter: 0224/2163
[A[ATraining Step: 1028  | total loss: [1m[32m0.05165[0m[0m | time: 101.325s
[2K
| Adam | epoch: 016 | loss: 0.05165 - acc: 0.9841 -- iter: 0256/2163
[A[ATraining Step: 1029  | total loss: [1m[32m0.04685[0m[0m | time: 114.018s
[2K
| Adam | epoch: 016 | loss: 0.04685 - acc: 0.9857 -- iter: 0288/2163
[A[ATraining Step: 1030  | total loss: [1m[32m0.06442[0m[0m | time: 126.676s
[2K
| Adam | epoch: 016 | loss: 0.06442 - acc: 0.9777 -- iter: 0320/2163
[A[ATraining Step: 1031  | total loss: [1m[32m0.05835[0m[0m | time: 139.068s
[2K
| Adam | epoch: 016 | loss: 0.05835 - acc: 0.9800 -- iter: 0352/2163
[A[ATraining Step: 1032  | total loss: [1m[32m0.05401[0m[0m | time: 151.896s
[2K
| Adam | epoch: 016 | loss: 0.05401 - acc: 0.9820 -- iter: 0384/2163
[A[ATraining Step: 1033  | total loss: [1m[32m0.04902[0m[0m | time: 164.307s
[2K
| Adam | epoch: 016 | loss: 0.04902 - acc: 0.9838 -- iter: 0416/2163
[A[ATraining Step: 1034  | total loss: [1m[32m0.05764[0m[0m | time: 173.130s
[2K
| Adam | epoch: 016 | loss: 0.05764 - acc: 0.9823 -- iter: 0448/2163
[A[ATraining Step: 1035  | total loss: [1m[32m0.08657[0m[0m | time: 181.685s
[2K
| Adam | epoch: 016 | loss: 0.08657 - acc: 0.9735 -- iter: 0480/2163
[A[ATraining Step: 1036  | total loss: [1m[32m0.08415[0m[0m | time: 194.203s
[2K
| Adam | epoch: 016 | loss: 0.08415 - acc: 0.9709 -- iter: 0512/2163
[A[ATraining Step: 1037  | total loss: [1m[32m0.08100[0m[0m | time: 206.771s
[2K
| Adam | epoch: 016 | loss: 0.08100 - acc: 0.9738 -- iter: 0544/2163
[A[ATraining Step: 1038  | total loss: [1m[32m0.07993[0m[0m | time: 219.272s
[2K
| Adam | epoch: 016 | loss: 0.07993 - acc: 0.9733 -- iter: 0576/2163
[A[ATraining Step: 1039  | total loss: [1m[32m0.07288[0m[0m | time: 231.710s
[2K
| Adam | epoch: 016 | loss: 0.07288 - acc: 0.9760 -- iter: 0608/2163
[A[ATraining Step: 1040  | total loss: [1m[32m0.06685[0m[0m | time: 244.330s
[2K
| Adam | epoch: 016 | loss: 0.06685 - acc: 0.9784 -- iter: 0640/2163
[A[ATraining Step: 1041  | total loss: [1m[32m0.06152[0m[0m | time: 257.307s
[2K
| Adam | epoch: 016 | loss: 0.06152 - acc: 0.9805 -- iter: 0672/2163
[A[ATraining Step: 1042  | total loss: [1m[32m0.05755[0m[0m | time: 269.991s
[2K
| Adam | epoch: 016 | loss: 0.05755 - acc: 0.9825 -- iter: 0704/2163
[A[ATraining Step: 1043  | total loss: [1m[32m0.05577[0m[0m | time: 282.948s
[2K
| Adam | epoch: 016 | loss: 0.05577 - acc: 0.9811 -- iter: 0736/2163
[A[ATraining Step: 1044  | total loss: [1m[32m0.05164[0m[0m | time: 295.852s
[2K
| Adam | epoch: 016 | loss: 0.05164 - acc: 0.9830 -- iter: 0768/2163
[A[ATraining Step: 1045  | total loss: [1m[32m0.04987[0m[0m | time: 308.608s
[2K
| Adam | epoch: 016 | loss: 0.04987 - acc: 0.9847 -- iter: 0800/2163
[A[ATraining Step: 1046  | total loss: [1m[32m0.04615[0m[0m | time: 321.257s
[2K
| Adam | epoch: 016 | loss: 0.04615 - acc: 0.9862 -- iter: 0832/2163
[A[ATraining Step: 1047  | total loss: [1m[32m0.04429[0m[0m | time: 333.891s
[2K
| Adam | epoch: 016 | loss: 0.04429 - acc: 0.9876 -- iter: 0864/2163
[A[ATraining Step: 1048  | total loss: [1m[32m0.04052[0m[0m | time: 346.324s
[2K
| Adam | epoch: 016 | loss: 0.04052 - acc: 0.9888 -- iter: 0896/2163
[A[ATraining Step: 1049  | total loss: [1m[32m0.03892[0m[0m | time: 359.093s
[2K
| Adam | epoch: 016 | loss: 0.03892 - acc: 0.9900 -- iter: 0928/2163
[A[ATraining Step: 1050  | total loss: [1m[32m0.03708[0m[0m | time: 371.644s
[2K
| Adam | epoch: 016 | loss: 0.03708 - acc: 0.9910 -- iter: 0960/2163
[A[ATraining Step: 1051  | total loss: [1m[32m0.03679[0m[0m | time: 384.446s
[2K
| Adam | epoch: 016 | loss: 0.03679 - acc: 0.9887 -- iter: 0992/2163
[A[ATraining Step: 1052  | total loss: [1m[32m0.03410[0m[0m | time: 397.163s
[2K
| Adam | epoch: 016 | loss: 0.03410 - acc: 0.9899 -- iter: 1024/2163
[A[ATraining Step: 1053  | total loss: [1m[32m0.04215[0m[0m | time: 409.583s
[2K
| Adam | epoch: 016 | loss: 0.04215 - acc: 0.9846 -- iter: 1056/2163
[A[ATraining Step: 1054  | total loss: [1m[32m0.04152[0m[0m | time: 422.922s
[2K
| Adam | epoch: 016 | loss: 0.04152 - acc: 0.9830 -- iter: 1088/2163
[A[ATraining Step: 1055  | total loss: [1m[32m0.04048[0m[0m | time: 435.472s
[2K
| Adam | epoch: 016 | loss: 0.04048 - acc: 0.9816 -- iter: 1120/2163
[A[ATraining Step: 1056  | total loss: [1m[32m0.03806[0m[0m | time: 448.308s
[2K
| Adam | epoch: 016 | loss: 0.03806 - acc: 0.9835 -- iter: 1152/2163
[A[ATraining Step: 1057  | total loss: [1m[32m0.03538[0m[0m | time: 460.826s
[2K
| Adam | epoch: 016 | loss: 0.03538 - acc: 0.9851 -- iter: 1184/2163
[A[ATraining Step: 1058  | total loss: [1m[32m0.03227[0m[0m | time: 473.482s
[2K
| Adam | epoch: 016 | loss: 0.03227 - acc: 0.9866 -- iter: 1216/2163
[A[ATraining Step: 1059  | total loss: [1m[32m0.03142[0m[0m | time: 486.263s
[2K
| Adam | epoch: 016 | loss: 0.03142 - acc: 0.9879 -- iter: 1248/2163
[A[ATraining Step: 1060  | total loss: [1m[32m0.02902[0m[0m | time: 498.888s
[2K
| Adam | epoch: 016 | loss: 0.02902 - acc: 0.9891 -- iter: 1280/2163
[A[ATraining Step: 1061  | total loss: [1m[32m0.02925[0m[0m | time: 511.654s
[2K
| Adam | epoch: 016 | loss: 0.02925 - acc: 0.9902 -- iter: 1312/2163
[A[ATraining Step: 1062  | total loss: [1m[32m0.03120[0m[0m | time: 523.878s
[2K
| Adam | epoch: 016 | loss: 0.03120 - acc: 0.9881 -- iter: 1344/2163
[A[ATraining Step: 1063  | total loss: [1m[32m0.02842[0m[0m | time: 536.367s
[2K
| Adam | epoch: 016 | loss: 0.02842 - acc: 0.9893 -- iter: 1376/2163
[A[ATraining Step: 1064  | total loss: [1m[32m0.03248[0m[0m | time: 548.882s
[2K
| Adam | epoch: 016 | loss: 0.03248 - acc: 0.9872 -- iter: 1408/2163
[A[ATraining Step: 1065  | total loss: [1m[32m0.02999[0m[0m | time: 561.797s
[2K
| Adam | epoch: 016 | loss: 0.02999 - acc: 0.9885 -- iter: 1440/2163
[A[ATraining Step: 1066  | total loss: [1m[32m0.03066[0m[0m | time: 574.572s
[2K
| Adam | epoch: 016 | loss: 0.03066 - acc: 0.9896 -- iter: 1472/2163
[A[ATraining Step: 1067  | total loss: [1m[32m0.02781[0m[0m | time: 587.099s
[2K
| Adam | epoch: 016 | loss: 0.02781 - acc: 0.9907 -- iter: 1504/2163
[A[ATraining Step: 1068  | total loss: [1m[32m0.03505[0m[0m | time: 599.830s
[2K
| Adam | epoch: 016 | loss: 0.03505 - acc: 0.9854 -- iter: 1536/2163
[A[ATraining Step: 1069  | total loss: [1m[32m0.03174[0m[0m | time: 612.865s
[2K
| Adam | epoch: 016 | loss: 0.03174 - acc: 0.9868 -- iter: 1568/2163
[A[ATraining Step: 1070  | total loss: [1m[32m0.03653[0m[0m | time: 625.528s
[2K
| Adam | epoch: 016 | loss: 0.03653 - acc: 0.9850 -- iter: 1600/2163
[A[ATraining Step: 1071  | total loss: [1m[32m0.03330[0m[0m | time: 637.997s
[2K
| Adam | epoch: 016 | loss: 0.03330 - acc: 0.9865 -- iter: 1632/2163
[A[ATraining Step: 1072  | total loss: [1m[32m0.03188[0m[0m | time: 650.507s
[2K
| Adam | epoch: 016 | loss: 0.03188 - acc: 0.9879 -- iter: 1664/2163
[A[ATraining Step: 1073  | total loss: [1m[32m0.02884[0m[0m | time: 663.095s
[2K
| Adam | epoch: 016 | loss: 0.02884 - acc: 0.9891 -- iter: 1696/2163
[A[ATraining Step: 1074  | total loss: [1m[32m0.02604[0m[0m | time: 675.716s
[2K
| Adam | epoch: 016 | loss: 0.02604 - acc: 0.9902 -- iter: 1728/2163
[A[ATraining Step: 1075  | total loss: [1m[32m0.02782[0m[0m | time: 688.623s
[2K
| Adam | epoch: 016 | loss: 0.02782 - acc: 0.9880 -- iter: 1760/2163
[A[ATraining Step: 1076  | total loss: [1m[32m0.02569[0m[0m | time: 701.726s
[2K
| Adam | epoch: 016 | loss: 0.02569 - acc: 0.9892 -- iter: 1792/2163
[A[ATraining Step: 1077  | total loss: [1m[32m0.02367[0m[0m | time: 714.637s
[2K
| Adam | epoch: 016 | loss: 0.02367 - acc: 0.9903 -- iter: 1824/2163
[A[ATraining Step: 1078  | total loss: [1m[32m0.02138[0m[0m | time: 727.114s
[2K
| Adam | epoch: 016 | loss: 0.02138 - acc: 0.9913 -- iter: 1856/2163
[A[ATraining Step: 1079  | total loss: [1m[32m0.02075[0m[0m | time: 739.434s
[2K
| Adam | epoch: 016 | loss: 0.02075 - acc: 0.9921 -- iter: 1888/2163
[A[ATraining Step: 1080  | total loss: [1m[32m0.01887[0m[0m | time: 752.143s
[2K
| Adam | epoch: 016 | loss: 0.01887 - acc: 0.9929 -- iter: 1920/2163
[A[ATraining Step: 1081  | total loss: [1m[32m0.01791[0m[0m | time: 765.150s
[2K
| Adam | epoch: 016 | loss: 0.01791 - acc: 0.9936 -- iter: 1952/2163
[A[ATraining Step: 1082  | total loss: [1m[32m0.01660[0m[0m | time: 777.677s
[2K
| Adam | epoch: 016 | loss: 0.01660 - acc: 0.9943 -- iter: 1984/2163
[A[ATraining Step: 1083  | total loss: [1m[32m0.01599[0m[0m | time: 790.523s
[2K
| Adam | epoch: 016 | loss: 0.01599 - acc: 0.9948 -- iter: 2016/2163
[A[ATraining Step: 1084  | total loss: [1m[32m0.01477[0m[0m | time: 803.653s
[2K
| Adam | epoch: 016 | loss: 0.01477 - acc: 0.9954 -- iter: 2048/2163
[A[ATraining Step: 1085  | total loss: [1m[32m0.01561[0m[0m | time: 816.324s
[2K
| Adam | epoch: 016 | loss: 0.01561 - acc: 0.9927 -- iter: 2080/2163
[A[ATraining Step: 1086  | total loss: [1m[32m0.02371[0m[0m | time: 828.897s
[2K
| Adam | epoch: 016 | loss: 0.02371 - acc: 0.9903 -- iter: 2112/2163
[A[ATraining Step: 1087  | total loss: [1m[32m0.02168[0m[0m | time: 841.511s
[2K
| Adam | epoch: 016 | loss: 0.02168 - acc: 0.9913 -- iter: 2144/2163
[A[ATraining Step: 1088  | total loss: [1m[32m0.02062[0m[0m | time: 905.690s
[2K
| Adam | epoch: 016 | loss: 0.02062 - acc: 0.9921 | val_loss: 0.16850 - val_acc: 0.9542 -- iter: 2163/2163
--
Training Step: 1089  | total loss: [1m[32m0.01863[0m[0m | time: 12.924s
[2K
| Adam | epoch: 017 | loss: 0.01863 - acc: 0.9929 -- iter: 0032/2163
[A[ATraining Step: 1090  | total loss: [1m[32m0.01681[0m[0m | time: 25.839s
[2K
| Adam | epoch: 017 | loss: 0.01681 - acc: 0.9936 -- iter: 0064/2163
[A[ATraining Step: 1091  | total loss: [1m[32m0.01552[0m[0m | time: 38.880s
[2K
| Adam | epoch: 017 | loss: 0.01552 - acc: 0.9943 -- iter: 0096/2163
[A[ATraining Step: 1092  | total loss: [1m[32m0.01405[0m[0m | time: 51.595s
[2K
| Adam | epoch: 017 | loss: 0.01405 - acc: 0.9948 -- iter: 0128/2163
[A[ATraining Step: 1093  | total loss: [1m[32m0.01273[0m[0m | time: 64.673s
[2K
| Adam | epoch: 017 | loss: 0.01273 - acc: 0.9954 -- iter: 0160/2163
[A[ATraining Step: 1094  | total loss: [1m[32m0.01558[0m[0m | time: 77.216s
[2K
| Adam | epoch: 017 | loss: 0.01558 - acc: 0.9927 -- iter: 0192/2163
[A[ATraining Step: 1095  | total loss: [1m[32m0.01675[0m[0m | time: 89.608s
[2K
| Adam | epoch: 017 | loss: 0.01675 - acc: 0.9934 -- iter: 0224/2163
[A[ATraining Step: 1096  | total loss: [1m[32m0.02500[0m[0m | time: 102.015s
[2K
| Adam | epoch: 017 | loss: 0.02500 - acc: 0.9910 -- iter: 0256/2163
[A[ATraining Step: 1097  | total loss: [1m[32m0.02351[0m[0m | time: 114.809s
[2K
| Adam | epoch: 017 | loss: 0.02351 - acc: 0.9919 -- iter: 0288/2163
[A[ATraining Step: 1098  | total loss: [1m[32m0.02158[0m[0m | time: 127.826s
[2K
| Adam | epoch: 017 | loss: 0.02158 - acc: 0.9927 -- iter: 0320/2163
[A[ATraining Step: 1099  | total loss: [1m[32m0.01958[0m[0m | time: 140.317s
[2K
| Adam | epoch: 017 | loss: 0.01958 - acc: 0.9934 -- iter: 0352/2163
[A[ATraining Step: 1100  | total loss: [1m[32m0.02080[0m[0m | time: 152.646s
[2K
| Adam | epoch: 017 | loss: 0.02080 - acc: 0.9909 -- iter: 0384/2163
[A[ATraining Step: 1101  | total loss: [1m[32m0.02182[0m[0m | time: 165.701s
[2K
| Adam | epoch: 017 | loss: 0.02182 - acc: 0.9919 -- iter: 0416/2163
[A[ATraining Step: 1102  | total loss: [1m[32m0.01972[0m[0m | time: 178.694s
[2K
| Adam | epoch: 017 | loss: 0.01972 - acc: 0.9927 -- iter: 0448/2163
[A[ATraining Step: 1103  | total loss: [1m[32m0.01797[0m[0m | time: 187.347s
[2K
| Adam | epoch: 017 | loss: 0.01797 - acc: 0.9934 -- iter: 0480/2163
[A[ATraining Step: 1104  | total loss: [1m[32m0.01971[0m[0m | time: 195.759s
[2K
| Adam | epoch: 017 | loss: 0.01971 - acc: 0.9941 -- iter: 0512/2163
[A[ATraining Step: 1105  | total loss: [1m[32m0.01952[0m[0m | time: 208.560s
[2K
| Adam | epoch: 017 | loss: 0.01952 - acc: 0.9947 -- iter: 0544/2163
[A[ATraining Step: 1106  | total loss: [1m[32m0.01846[0m[0m | time: 221.323s
[2K
| Adam | epoch: 017 | loss: 0.01846 - acc: 0.9952 -- iter: 0576/2163
[A[ATraining Step: 1107  | total loss: [1m[32m0.01696[0m[0m | time: 233.795s
[2K
| Adam | epoch: 017 | loss: 0.01696 - acc: 0.9957 -- iter: 0608/2163
[A[ATraining Step: 1108  | total loss: [1m[32m0.01632[0m[0m | time: 246.494s
[2K
| Adam | epoch: 017 | loss: 0.01632 - acc: 0.9961 -- iter: 0640/2163
[A[ATraining Step: 1109  | total loss: [1m[32m0.01518[0m[0m | time: 259.447s
[2K
| Adam | epoch: 017 | loss: 0.01518 - acc: 0.9965 -- iter: 0672/2163
[A[ATraining Step: 1110  | total loss: [1m[32m0.01466[0m[0m | time: 272.235s
[2K
| Adam | epoch: 017 | loss: 0.01466 - acc: 0.9968 -- iter: 0704/2163
[A[ATraining Step: 1111  | total loss: [1m[32m0.01770[0m[0m | time: 284.748s
[2K
| Adam | epoch: 017 | loss: 0.01770 - acc: 0.9940 -- iter: 0736/2163
[A[ATraining Step: 1112  | total loss: [1m[32m0.01614[0m[0m | time: 298.162s
[2K
| Adam | epoch: 017 | loss: 0.01614 - acc: 0.9946 -- iter: 0768/2163
[A[ATraining Step: 1113  | total loss: [1m[32m0.01485[0m[0m | time: 311.086s
[2K
| Adam | epoch: 017 | loss: 0.01485 - acc: 0.9952 -- iter: 0800/2163
[A[ATraining Step: 1114  | total loss: [1m[32m0.01358[0m[0m | time: 323.589s
[2K
| Adam | epoch: 017 | loss: 0.01358 - acc: 0.9957 -- iter: 0832/2163
[A[ATraining Step: 1115  | total loss: [1m[32m0.01236[0m[0m | time: 335.804s
[2K
| Adam | epoch: 017 | loss: 0.01236 - acc: 0.9961 -- iter: 0864/2163
[A[ATraining Step: 1116  | total loss: [1m[32m0.01142[0m[0m | time: 348.367s
[2K
| Adam | epoch: 017 | loss: 0.01142 - acc: 0.9965 -- iter: 0896/2163
[A[ATraining Step: 1117  | total loss: [1m[32m0.01348[0m[0m | time: 360.780s
[2K
| Adam | epoch: 017 | loss: 0.01348 - acc: 0.9968 -- iter: 0928/2163
[A[ATraining Step: 1118  | total loss: [1m[32m0.01229[0m[0m | time: 373.542s
[2K
| Adam | epoch: 017 | loss: 0.01229 - acc: 0.9971 -- iter: 0960/2163
[A[ATraining Step: 1119  | total loss: [1m[32m0.01127[0m[0m | time: 385.983s
[2K
| Adam | epoch: 017 | loss: 0.01127 - acc: 0.9974 -- iter: 0992/2163
[A[ATraining Step: 1120  | total loss: [1m[32m0.01038[0m[0m | time: 398.740s
[2K
| Adam | epoch: 017 | loss: 0.01038 - acc: 0.9977 -- iter: 1024/2163
[A[ATraining Step: 1121  | total loss: [1m[32m0.00990[0m[0m | time: 412.154s
[2K
| Adam | epoch: 017 | loss: 0.00990 - acc: 0.9979 -- iter: 1056/2163
[A[ATraining Step: 1122  | total loss: [1m[32m0.01403[0m[0m | time: 425.116s
[2K
| Adam | epoch: 017 | loss: 0.01403 - acc: 0.9950 -- iter: 1088/2163
[A[ATraining Step: 1123  | total loss: [1m[32m0.02322[0m[0m | time: 438.038s
[2K
| Adam | epoch: 017 | loss: 0.02322 - acc: 0.9924 -- iter: 1120/2163
[A[ATraining Step: 1124  | total loss: [1m[32m0.02235[0m[0m | time: 451.094s
[2K
| Adam | epoch: 017 | loss: 0.02235 - acc: 0.9931 -- iter: 1152/2163
[A[ATraining Step: 1125  | total loss: [1m[32m0.02039[0m[0m | time: 463.789s
[2K
| Adam | epoch: 017 | loss: 0.02039 - acc: 0.9938 -- iter: 1184/2163
[A[ATraining Step: 1126  | total loss: [1m[32m0.01863[0m[0m | time: 476.549s
[2K
| Adam | epoch: 017 | loss: 0.01863 - acc: 0.9944 -- iter: 1216/2163
[A[ATraining Step: 1127  | total loss: [1m[32m0.02369[0m[0m | time: 487.225s
[2K
| Adam | epoch: 017 | loss: 0.02369 - acc: 0.9919 -- iter: 1248/2163
[A[ATraining Step: 1128  | total loss: [1m[32m0.02145[0m[0m | time: 496.408s
[2K
| Adam | epoch: 017 | loss: 0.02145 - acc: 0.9927 -- iter: 1280/2163
[A[ATraining Step: 1129  | total loss: [1m[32m0.01938[0m[0m | time: 509.907s
[2K
| Adam | epoch: 017 | loss: 0.01938 - acc: 0.9934 -- iter: 1312/2163
[A[ATraining Step: 1130  | total loss: [1m[32m0.01818[0m[0m | time: 523.659s
[2K
| Adam | epoch: 017 | loss: 0.01818 - acc: 0.9941 -- iter: 1344/2163
[A[ATraining Step: 1131  | total loss: [1m[32m0.01658[0m[0m | time: 537.009s
[2K
| Adam | epoch: 017 | loss: 0.01658 - acc: 0.9947 -- iter: 1376/2163
[A[ATraining Step: 1132  | total loss: [1m[32m0.01555[0m[0m | time: 550.586s
[2K
| Adam | epoch: 017 | loss: 0.01555 - acc: 0.9952 -- iter: 1408/2163
[A[ATraining Step: 1133  | total loss: [1m[32m0.01526[0m[0m | time: 564.118s
[2K
| Adam | epoch: 017 | loss: 0.01526 - acc: 0.9957 -- iter: 1440/2163
[A[ATraining Step: 1134  | total loss: [1m[32m0.01413[0m[0m | time: 577.796s
[2K
| Adam | epoch: 017 | loss: 0.01413 - acc: 0.9961 -- iter: 1472/2163
[A[ATraining Step: 1135  | total loss: [1m[32m0.01298[0m[0m | time: 587.602s
[2K
| Adam | epoch: 017 | loss: 0.01298 - acc: 0.9965 -- iter: 1504/2163
[A[ATraining Step: 1136  | total loss: [1m[32m0.01506[0m[0m | time: 595.270s
[2K
| Adam | epoch: 017 | loss: 0.01506 - acc: 0.9969 -- iter: 1536/2163
[A[ATraining Step: 1137  | total loss: [1m[32m0.01961[0m[0m | time: 603.042s
[2K
| Adam | epoch: 017 | loss: 0.01961 - acc: 0.9940 -- iter: 1568/2163
[A[ATraining Step: 1138  | total loss: [1m[32m0.01881[0m[0m | time: 610.794s
[2K
| Adam | epoch: 017 | loss: 0.01881 - acc: 0.9946 -- iter: 1600/2163
[A[ATraining Step: 1139  | total loss: [1m[32m0.01740[0m[0m | time: 619.436s
[2K
| Adam | epoch: 017 | loss: 0.01740 - acc: 0.9952 -- iter: 1632/2163
[A[ATraining Step: 1140  | total loss: [1m[32m0.02559[0m[0m | time: 632.373s
[2K
| Adam | epoch: 017 | loss: 0.02559 - acc: 0.9925 -- iter: 1664/2163
[A[ATraining Step: 1141  | total loss: [1m[32m0.11554[0m[0m | time: 645.082s
[2K
| Adam | epoch: 017 | loss: 0.11554 - acc: 0.9870 -- iter: 1696/2163
[A[ATraining Step: 1142  | total loss: [1m[32m0.10473[0m[0m | time: 657.592s
[2K
| Adam | epoch: 017 | loss: 0.10473 - acc: 0.9883 -- iter: 1728/2163
[A[ATraining Step: 1143  | total loss: [1m[32m0.09460[0m[0m | time: 670.408s
[2K
| Adam | epoch: 017 | loss: 0.09460 - acc: 0.9895 -- iter: 1760/2163
[A[ATraining Step: 1144  | total loss: [1m[32m0.08527[0m[0m | time: 683.021s
[2K
| Adam | epoch: 017 | loss: 0.08527 - acc: 0.9905 -- iter: 1792/2163
[A[ATraining Step: 1145  | total loss: [1m[32m0.07746[0m[0m | time: 695.721s
[2K
| Adam | epoch: 017 | loss: 0.07746 - acc: 0.9915 -- iter: 1824/2163
[A[ATraining Step: 1146  | total loss: [1m[32m0.07154[0m[0m | time: 708.509s
[2K
| Adam | epoch: 017 | loss: 0.07154 - acc: 0.9923 -- iter: 1856/2163
[A[ATraining Step: 1147  | total loss: [1m[32m0.06483[0m[0m | time: 721.284s
[2K
| Adam | epoch: 017 | loss: 0.06483 - acc: 0.9931 -- iter: 1888/2163
[A[ATraining Step: 1148  | total loss: [1m[32m0.05915[0m[0m | time: 734.437s
[2K
| Adam | epoch: 017 | loss: 0.05915 - acc: 0.9938 -- iter: 1920/2163
[A[ATraining Step: 1149  | total loss: [1m[32m0.05471[0m[0m | time: 747.606s
[2K
| Adam | epoch: 017 | loss: 0.05471 - acc: 0.9944 -- iter: 1952/2163
[A[ATraining Step: 1150  | total loss: [1m[32m0.08012[0m[0m | time: 760.349s
[2K
| Adam | epoch: 017 | loss: 0.08012 - acc: 0.9887 -- iter: 1984/2163
[A[ATraining Step: 1151  | total loss: [1m[32m0.08072[0m[0m | time: 773.394s
[2K
| Adam | epoch: 017 | loss: 0.08072 - acc: 0.9867 -- iter: 2016/2163
[A[ATraining Step: 1152  | total loss: [1m[32m0.07358[0m[0m | time: 786.230s
[2K
| Adam | epoch: 017 | loss: 0.07358 - acc: 0.9881 -- iter: 2048/2163
[A[ATraining Step: 1153  | total loss: [1m[32m0.06715[0m[0m | time: 798.812s
[2K
| Adam | epoch: 017 | loss: 0.06715 - acc: 0.9892 -- iter: 2080/2163
[A[ATraining Step: 1154  | total loss: [1m[32m0.06104[0m[0m | time: 811.732s
[2K
| Adam | epoch: 017 | loss: 0.06104 - acc: 0.9903 -- iter: 2112/2163
[A[ATraining Step: 1155  | total loss: [1m[32m0.05606[0m[0m | time: 824.216s
[2K
| Adam | epoch: 017 | loss: 0.05606 - acc: 0.9913 -- iter: 2144/2163
[A[ATraining Step: 1156  | total loss: [1m[32m0.05085[0m[0m | time: 887.248s
[2K
| Adam | epoch: 017 | loss: 0.05085 - acc: 0.9922 | val_loss: 0.28764 - val_acc: 0.9069 -- iter: 2163/2163
--
Training Step: 1157  | total loss: [1m[32m0.04696[0m[0m | time: 12.471s
[2K
| Adam | epoch: 018 | loss: 0.04696 - acc: 0.9929 -- iter: 0032/2163
[A[ATraining Step: 1158  | total loss: [1m[32m0.05617[0m[0m | time: 25.384s
[2K
| Adam | epoch: 018 | loss: 0.05617 - acc: 0.9905 -- iter: 0064/2163
[A[ATraining Step: 1159  | total loss: [1m[32m0.05816[0m[0m | time: 38.213s
[2K
| Adam | epoch: 018 | loss: 0.05816 - acc: 0.9883 -- iter: 0096/2163
[A[ATraining Step: 1160  | total loss: [1m[32m0.06601[0m[0m | time: 50.710s
[2K
| Adam | epoch: 018 | loss: 0.06601 - acc: 0.9833 -- iter: 0128/2163
[A[ATraining Step: 1161  | total loss: [1m[32m0.06039[0m[0m | time: 63.460s
[2K
| Adam | epoch: 018 | loss: 0.06039 - acc: 0.9849 -- iter: 0160/2163
[A[ATraining Step: 1162  | total loss: [1m[32m0.06417[0m[0m | time: 76.228s
[2K
| Adam | epoch: 018 | loss: 0.06417 - acc: 0.9833 -- iter: 0192/2163
[A[ATraining Step: 1163  | total loss: [1m[32m0.05893[0m[0m | time: 89.008s
[2K
| Adam | epoch: 018 | loss: 0.05893 - acc: 0.9850 -- iter: 0224/2163
[A[ATraining Step: 1164  | total loss: [1m[32m0.05353[0m[0m | time: 101.647s
[2K
| Adam | epoch: 018 | loss: 0.05353 - acc: 0.9865 -- iter: 0256/2163
[A[ATraining Step: 1165  | total loss: [1m[32m0.04943[0m[0m | time: 114.087s
[2K
| Adam | epoch: 018 | loss: 0.04943 - acc: 0.9878 -- iter: 0288/2163
[A[ATraining Step: 1166  | total loss: [1m[32m0.04647[0m[0m | time: 126.930s
[2K
| Adam | epoch: 018 | loss: 0.04647 - acc: 0.9891 -- iter: 0320/2163
[A[ATraining Step: 1167  | total loss: [1m[32m0.04641[0m[0m | time: 139.246s
[2K
| Adam | epoch: 018 | loss: 0.04641 - acc: 0.9901 -- iter: 0352/2163
[A[ATraining Step: 1168  | total loss: [1m[32m0.04476[0m[0m | time: 151.755s
[2K
| Adam | epoch: 018 | loss: 0.04476 - acc: 0.9911 -- iter: 0384/2163
[A[ATraining Step: 1169  | total loss: [1m[32m0.04988[0m[0m | time: 164.266s
[2K
| Adam | epoch: 018 | loss: 0.04988 - acc: 0.9858 -- iter: 0416/2163
[A[ATraining Step: 1170  | total loss: [1m[32m0.04830[0m[0m | time: 177.044s
[2K
| Adam | epoch: 018 | loss: 0.04830 - acc: 0.9841 -- iter: 0448/2163
[A[ATraining Step: 1171  | total loss: [1m[32m0.04666[0m[0m | time: 189.836s
[2K
| Adam | epoch: 018 | loss: 0.04666 - acc: 0.9857 -- iter: 0480/2163
[A[ATraining Step: 1172  | total loss: [1m[32m0.04284[0m[0m | time: 198.430s
[2K
| Adam | epoch: 018 | loss: 0.04284 - acc: 0.9871 -- iter: 0512/2163
[A[ATraining Step: 1173  | total loss: [1m[32m0.03875[0m[0m | time: 207.367s
[2K
| Adam | epoch: 018 | loss: 0.03875 - acc: 0.9884 -- iter: 0544/2163
[A[ATraining Step: 1174  | total loss: [1m[32m0.03506[0m[0m | time: 219.967s
[2K
| Adam | epoch: 018 | loss: 0.03506 - acc: 0.9895 -- iter: 0576/2163
[A[ATraining Step: 1175  | total loss: [1m[32m0.03220[0m[0m | time: 232.685s
[2K
| Adam | epoch: 018 | loss: 0.03220 - acc: 0.9906 -- iter: 0608/2163
[A[ATraining Step: 1176  | total loss: [1m[32m0.03016[0m[0m | time: 245.477s
[2K
| Adam | epoch: 018 | loss: 0.03016 - acc: 0.9915 -- iter: 0640/2163
[A[ATraining Step: 1177  | total loss: [1m[32m0.02757[0m[0m | time: 258.059s
[2K
| Adam | epoch: 018 | loss: 0.02757 - acc: 0.9924 -- iter: 0672/2163
[A[ATraining Step: 1178  | total loss: [1m[32m0.02616[0m[0m | time: 270.601s
[2K
| Adam | epoch: 018 | loss: 0.02616 - acc: 0.9931 -- iter: 0704/2163
[A[ATraining Step: 1179  | total loss: [1m[32m0.02501[0m[0m | time: 283.836s
[2K
| Adam | epoch: 018 | loss: 0.02501 - acc: 0.9938 -- iter: 0736/2163
[A[ATraining Step: 1180  | total loss: [1m[32m0.02350[0m[0m | time: 296.782s
[2K
| Adam | epoch: 018 | loss: 0.02350 - acc: 0.9944 -- iter: 0768/2163
[A[ATraining Step: 1181  | total loss: [1m[32m0.02128[0m[0m | time: 309.488s
[2K
| Adam | epoch: 018 | loss: 0.02128 - acc: 0.9950 -- iter: 0800/2163
[A[ATraining Step: 1182  | total loss: [1m[32m0.02000[0m[0m | time: 322.478s
[2K
| Adam | epoch: 018 | loss: 0.02000 - acc: 0.9955 -- iter: 0832/2163
[A[ATraining Step: 1183  | total loss: [1m[32m0.02052[0m[0m | time: 335.326s
[2K
| Adam | epoch: 018 | loss: 0.02052 - acc: 0.9928 -- iter: 0864/2163
[A[ATraining Step: 1184  | total loss: [1m[32m0.01858[0m[0m | time: 347.957s
[2K
| Adam | epoch: 018 | loss: 0.01858 - acc: 0.9935 -- iter: 0896/2163
[A[ATraining Step: 1185  | total loss: [1m[32m0.01721[0m[0m | time: 360.644s
[2K
| Adam | epoch: 018 | loss: 0.01721 - acc: 0.9942 -- iter: 0928/2163
[A[ATraining Step: 1186  | total loss: [1m[32m0.01582[0m[0m | time: 373.190s
[2K
| Adam | epoch: 018 | loss: 0.01582 - acc: 0.9948 -- iter: 0960/2163
[A[ATraining Step: 1187  | total loss: [1m[32m0.01429[0m[0m | time: 385.884s
[2K
| Adam | epoch: 018 | loss: 0.01429 - acc: 0.9953 -- iter: 0992/2163
[A[ATraining Step: 1188  | total loss: [1m[32m0.01387[0m[0m | time: 398.693s
[2K
| Adam | epoch: 018 | loss: 0.01387 - acc: 0.9958 -- iter: 1024/2163
[A[ATraining Step: 1189  | total loss: [1m[32m0.01313[0m[0m | time: 411.385s
[2K
| Adam | epoch: 018 | loss: 0.01313 - acc: 0.9962 -- iter: 1056/2163
[A[ATraining Step: 1190  | total loss: [1m[32m0.01190[0m[0m | time: 423.676s
[2K
| Adam | epoch: 018 | loss: 0.01190 - acc: 0.9966 -- iter: 1088/2163
[A[ATraining Step: 1191  | total loss: [1m[32m0.01093[0m[0m | time: 436.692s
[2K
| Adam | epoch: 018 | loss: 0.01093 - acc: 0.9969 -- iter: 1120/2163
[A[ATraining Step: 1192  | total loss: [1m[32m0.01036[0m[0m | time: 449.754s
[2K
| Adam | epoch: 018 | loss: 0.01036 - acc: 0.9972 -- iter: 1152/2163
[A[ATraining Step: 1193  | total loss: [1m[32m0.01045[0m[0m | time: 462.772s
[2K
| Adam | epoch: 018 | loss: 0.01045 - acc: 0.9975 -- iter: 1184/2163
[A[ATraining Step: 1194  | total loss: [1m[32m0.00969[0m[0m | time: 476.080s
[2K
| Adam | epoch: 018 | loss: 0.00969 - acc: 0.9977 -- iter: 1216/2163
[A[ATraining Step: 1195  | total loss: [1m[32m0.00914[0m[0m | time: 489.046s
[2K
| Adam | epoch: 018 | loss: 0.00914 - acc: 0.9980 -- iter: 1248/2163
[A[ATraining Step: 1196  | total loss: [1m[32m0.01536[0m[0m | time: 501.497s
[2K
| Adam | epoch: 018 | loss: 0.01536 - acc: 0.9951 -- iter: 1280/2163
[A[ATraining Step: 1197  | total loss: [1m[32m0.01394[0m[0m | time: 514.140s
[2K
| Adam | epoch: 018 | loss: 0.01394 - acc: 0.9955 -- iter: 1312/2163
[A[ATraining Step: 1198  | total loss: [1m[32m0.01331[0m[0m | time: 527.179s
[2K
| Adam | epoch: 018 | loss: 0.01331 - acc: 0.9960 -- iter: 1344/2163
[A[ATraining Step: 1199  | total loss: [1m[32m0.01250[0m[0m | time: 540.926s
[2K
| Adam | epoch: 018 | loss: 0.01250 - acc: 0.9964 -- iter: 1376/2163
[A[ATraining Step: 1200  | total loss: [1m[32m0.01130[0m[0m | time: 609.409s
[2K
| Adam | epoch: 018 | loss: 0.01130 - acc: 0.9968 | val_loss: 0.48401 - val_acc: 0.8789 -- iter: 1408/2163
--
Training Step: 1201  | total loss: [1m[32m0.01048[0m[0m | time: 617.183s
[2K
| Adam | epoch: 018 | loss: 0.01048 - acc: 0.9971 -- iter: 1440/2163
[A[ATraining Step: 1202  | total loss: [1m[32m0.00951[0m[0m | time: 624.860s
[2K
| Adam | epoch: 018 | loss: 0.00951 - acc: 0.9974 -- iter: 1472/2163
[A[ATraining Step: 1203  | total loss: [1m[32m0.01040[0m[0m | time: 637.267s
[2K
| Adam | epoch: 018 | loss: 0.01040 - acc: 0.9976 -- iter: 1504/2163
[A[ATraining Step: 1204  | total loss: [1m[32m0.00940[0m[0m | time: 650.197s
[2K
| Adam | epoch: 018 | loss: 0.00940 - acc: 0.9979 -- iter: 1536/2163
[A[ATraining Step: 1205  | total loss: [1m[32m0.01081[0m[0m | time: 663.162s
[2K
| Adam | epoch: 018 | loss: 0.01081 - acc: 0.9981 -- iter: 1568/2163
[A[ATraining Step: 1206  | total loss: [1m[32m0.00982[0m[0m | time: 676.000s
[2K
| Adam | epoch: 018 | loss: 0.00982 - acc: 0.9983 -- iter: 1600/2163
[A[ATraining Step: 1207  | total loss: [1m[32m0.01113[0m[0m | time: 688.525s
[2K
| Adam | epoch: 018 | loss: 0.01113 - acc: 0.9953 -- iter: 1632/2163
[A[ATraining Step: 1208  | total loss: [1m[32m0.01217[0m[0m | time: 700.987s
[2K
| Adam | epoch: 018 | loss: 0.01217 - acc: 0.9958 -- iter: 1664/2163
[A[ATraining Step: 1209  | total loss: [1m[32m0.01100[0m[0m | time: 714.071s
[2K
| Adam | epoch: 018 | loss: 0.01100 - acc: 0.9962 -- iter: 1696/2163
[A[ATraining Step: 1210  | total loss: [1m[32m0.12957[0m[0m | time: 726.208s
[2K
| Adam | epoch: 018 | loss: 0.12957 - acc: 0.9872 -- iter: 1728/2163
[A[ATraining Step: 1211  | total loss: [1m[32m0.11680[0m[0m | time: 738.671s
[2K
| Adam | epoch: 018 | loss: 0.11680 - acc: 0.9885 -- iter: 1760/2163
[A[ATraining Step: 1212  | total loss: [1m[32m0.11348[0m[0m | time: 751.008s
[2K
| Adam | epoch: 018 | loss: 0.11348 - acc: 0.9865 -- iter: 1792/2163
[A[ATraining Step: 1213  | total loss: [1m[32m0.10332[0m[0m | time: 763.390s
[2K
| Adam | epoch: 018 | loss: 0.10332 - acc: 0.9879 -- iter: 1824/2163
[A[ATraining Step: 1214  | total loss: [1m[32m0.09310[0m[0m | time: 776.487s
[2K
| Adam | epoch: 018 | loss: 0.09310 - acc: 0.9891 -- iter: 1856/2163
[A[ATraining Step: 1215  | total loss: [1m[32m0.08417[0m[0m | time: 789.001s
[2K
| Adam | epoch: 018 | loss: 0.08417 - acc: 0.9902 -- iter: 1888/2163
[A[ATraining Step: 1216  | total loss: [1m[32m0.07775[0m[0m | time: 801.658s
[2K
| Adam | epoch: 018 | loss: 0.07775 - acc: 0.9912 -- iter: 1920/2163
[A[ATraining Step: 1217  | total loss: [1m[32m0.07062[0m[0m | time: 814.677s
[2K
| Adam | epoch: 018 | loss: 0.07062 - acc: 0.9920 -- iter: 1952/2163
[A[ATraining Step: 1218  | total loss: [1m[32m0.06446[0m[0m | time: 827.850s
[2K
| Adam | epoch: 018 | loss: 0.06446 - acc: 0.9928 -- iter: 1984/2163
[A[ATraining Step: 1219  | total loss: [1m[32m0.05867[0m[0m | time: 840.711s
[2K
| Adam | epoch: 018 | loss: 0.05867 - acc: 0.9936 -- iter: 2016/2163
[A[ATraining Step: 1220  | total loss: [1m[32m0.06822[0m[0m | time: 853.177s
[2K
| Adam | epoch: 018 | loss: 0.06822 - acc: 0.9848 -- iter: 2048/2163
[A[ATraining Step: 1221  | total loss: [1m[32m0.06193[0m[0m | time: 865.521s
[2K
| Adam | epoch: 018 | loss: 0.06193 - acc: 0.9863 -- iter: 2080/2163
[A[ATraining Step: 1222  | total loss: [1m[32m0.05690[0m[0m | time: 878.059s
[2K
| Adam | epoch: 018 | loss: 0.05690 - acc: 0.9877 -- iter: 2112/2163
[A[ATraining Step: 1223  | total loss: [1m[32m0.05170[0m[0m | time: 890.568s
[2K
| Adam | epoch: 018 | loss: 0.05170 - acc: 0.9889 -- iter: 2144/2163
[A[ATraining Step: 1224  | total loss: [1m[32m0.05174[0m[0m | time: 952.999s
[2K
| Adam | epoch: 018 | loss: 0.05174 - acc: 0.9869 | val_loss: 0.24233 - val_acc: 0.9306 -- iter: 2163/2163
--
Training Step: 1225  | total loss: [1m[32m0.04675[0m[0m | time: 12.319s
[2K
| Adam | epoch: 019 | loss: 0.04675 - acc: 0.9882 -- iter: 0032/2163
[A[ATraining Step: 1226  | total loss: [1m[32m0.04357[0m[0m | time: 24.636s
[2K
| Adam | epoch: 019 | loss: 0.04357 - acc: 0.9894 -- iter: 0064/2163
[A[ATraining Step: 1227  | total loss: [1m[32m0.04002[0m[0m | time: 37.061s
[2K
| Adam | epoch: 019 | loss: 0.04002 - acc: 0.9905 -- iter: 0096/2163
[A[ATraining Step: 1228  | total loss: [1m[32m0.04157[0m[0m | time: 49.412s
[2K
| Adam | epoch: 019 | loss: 0.04157 - acc: 0.9883 -- iter: 0128/2163
[A[ATraining Step: 1229  | total loss: [1m[32m0.03850[0m[0m | time: 61.521s
[2K
| Adam | epoch: 019 | loss: 0.03850 - acc: 0.9895 -- iter: 0160/2163
[A[ATraining Step: 1230  | total loss: [1m[32m0.04174[0m[0m | time: 73.762s
[2K
| Adam | epoch: 019 | loss: 0.04174 - acc: 0.9874 -- iter: 0192/2163
[A[ATraining Step: 1231  | total loss: [1m[32m0.03807[0m[0m | time: 86.267s
[2K
| Adam | epoch: 019 | loss: 0.03807 - acc: 0.9887 -- iter: 0224/2163
[A[ATraining Step: 1232  | total loss: [1m[32m0.03533[0m[0m | time: 99.115s
[2K
| Adam | epoch: 019 | loss: 0.03533 - acc: 0.9898 -- iter: 0256/2163
[A[ATraining Step: 1233  | total loss: [1m[32m0.03229[0m[0m | time: 111.927s
[2K
| Adam | epoch: 019 | loss: 0.03229 - acc: 0.9908 -- iter: 0288/2163
[A[ATraining Step: 1234  | total loss: [1m[32m0.03044[0m[0m | time: 124.865s
[2K
| Adam | epoch: 019 | loss: 0.03044 - acc: 0.9917 -- iter: 0320/2163
[A[ATraining Step: 1235  | total loss: [1m[32m0.02771[0m[0m | time: 137.975s
[2K
| Adam | epoch: 019 | loss: 0.02771 - acc: 0.9926 -- iter: 0352/2163
[A[ATraining Step: 1236  | total loss: [1m[32m0.02820[0m[0m | time: 150.823s
[2K
| Adam | epoch: 019 | loss: 0.02820 - acc: 0.9933 -- iter: 0384/2163
[A[ATraining Step: 1237  | total loss: [1m[32m0.02604[0m[0m | time: 163.278s
[2K
| Adam | epoch: 019 | loss: 0.02604 - acc: 0.9940 -- iter: 0416/2163
[A[ATraining Step: 1238  | total loss: [1m[32m0.02842[0m[0m | time: 175.636s
[2K
| Adam | epoch: 019 | loss: 0.02842 - acc: 0.9914 -- iter: 0448/2163
[A[ATraining Step: 1239  | total loss: [1m[32m0.02656[0m[0m | time: 187.944s
[2K
| Adam | epoch: 019 | loss: 0.02656 - acc: 0.9923 -- iter: 0480/2163
[A[ATraining Step: 1240  | total loss: [1m[32m0.02453[0m[0m | time: 200.565s
[2K
| Adam | epoch: 019 | loss: 0.02453 - acc: 0.9931 -- iter: 0512/2163
[A[ATraining Step: 1241  | total loss: [1m[32m0.02240[0m[0m | time: 209.171s
[2K
| Adam | epoch: 019 | loss: 0.02240 - acc: 0.9938 -- iter: 0544/2163
[A[ATraining Step: 1242  | total loss: [1m[32m0.02085[0m[0m | time: 217.460s
[2K
| Adam | epoch: 019 | loss: 0.02085 - acc: 0.9944 -- iter: 0576/2163
[A[ATraining Step: 1243  | total loss: [1m[32m0.01936[0m[0m | time: 229.824s
[2K
| Adam | epoch: 019 | loss: 0.01936 - acc: 0.9949 -- iter: 0608/2163
[A[ATraining Step: 1244  | total loss: [1m[32m0.01954[0m[0m | time: 242.778s
[2K
| Adam | epoch: 019 | loss: 0.01954 - acc: 0.9955 -- iter: 0640/2163
[A[ATraining Step: 1245  | total loss: [1m[32m0.01818[0m[0m | time: 255.589s
[2K
| Adam | epoch: 019 | loss: 0.01818 - acc: 0.9959 -- iter: 0672/2163
[A[ATraining Step: 1246  | total loss: [1m[32m0.01656[0m[0m | time: 268.005s
[2K
| Adam | epoch: 019 | loss: 0.01656 - acc: 0.9963 -- iter: 0704/2163
[A[ATraining Step: 1247  | total loss: [1m[32m0.01669[0m[0m | time: 280.380s
[2K
| Adam | epoch: 019 | loss: 0.01669 - acc: 0.9967 -- iter: 0736/2163
[A[ATraining Step: 1248  | total loss: [1m[32m0.01689[0m[0m | time: 292.562s
[2K
| Adam | epoch: 019 | loss: 0.01689 - acc: 0.9970 -- iter: 0768/2163
[A[ATraining Step: 1249  | total loss: [1m[32m0.01573[0m[0m | time: 305.002s
[2K
| Adam | epoch: 019 | loss: 0.01573 - acc: 0.9973 -- iter: 0800/2163
[A[ATraining Step: 1250  | total loss: [1m[32m0.01696[0m[0m | time: 317.568s
[2K
| Adam | epoch: 019 | loss: 0.01696 - acc: 0.9945 -- iter: 0832/2163
[A[ATraining Step: 1251  | total loss: [1m[32m0.01622[0m[0m | time: 330.290s
[2K
| Adam | epoch: 019 | loss: 0.01622 - acc: 0.9950 -- iter: 0864/2163
[A[ATraining Step: 1252  | total loss: [1m[32m0.01541[0m[0m | time: 343.204s
[2K
| Adam | epoch: 019 | loss: 0.01541 - acc: 0.9955 -- iter: 0896/2163
[A[ATraining Step: 1253  | total loss: [1m[32m0.01433[0m[0m | time: 356.574s
[2K
| Adam | epoch: 019 | loss: 0.01433 - acc: 0.9960 -- iter: 0928/2163
[A[ATraining Step: 1254  | total loss: [1m[32m0.01443[0m[0m | time: 370.347s
[2K
| Adam | epoch: 019 | loss: 0.01443 - acc: 0.9964 -- iter: 0960/2163
[A[ATraining Step: 1255  | total loss: [1m[32m0.01427[0m[0m | time: 383.987s
[2K
| Adam | epoch: 019 | loss: 0.01427 - acc: 0.9967 -- iter: 0992/2163
[A[ATraining Step: 1256  | total loss: [1m[32m0.01364[0m[0m | time: 397.838s
[2K
| Adam | epoch: 019 | loss: 0.01364 - acc: 0.9971 -- iter: 1024/2163
[A[ATraining Step: 1257  | total loss: [1m[32m0.01243[0m[0m | time: 411.583s
[2K
| Adam | epoch: 019 | loss: 0.01243 - acc: 0.9973 -- iter: 1056/2163
[A[ATraining Step: 1258  | total loss: [1m[32m0.01142[0m[0m | time: 425.105s
[2K
| Adam | epoch: 019 | loss: 0.01142 - acc: 0.9976 -- iter: 1088/2163
[A[ATraining Step: 1259  | total loss: [1m[32m0.01036[0m[0m | time: 437.279s
[2K
| Adam | epoch: 019 | loss: 0.01036 - acc: 0.9979 -- iter: 1120/2163
[A[ATraining Step: 1260  | total loss: [1m[32m0.00941[0m[0m | time: 445.061s
[2K
| Adam | epoch: 019 | loss: 0.00941 - acc: 0.9981 -- iter: 1152/2163
[A[ATraining Step: 1261  | total loss: [1m[32m0.00919[0m[0m | time: 452.994s
[2K
| Adam | epoch: 019 | loss: 0.00919 - acc: 0.9983 -- iter: 1184/2163
[A[ATraining Step: 1262  | total loss: [1m[32m0.00858[0m[0m | time: 460.849s
[2K
| Adam | epoch: 019 | loss: 0.00858 - acc: 0.9984 -- iter: 1216/2163
[A[ATraining Step: 1263  | total loss: [1m[32m0.00797[0m[0m | time: 473.318s
[2K
| Adam | epoch: 019 | loss: 0.00797 - acc: 0.9986 -- iter: 1248/2163
[A[ATraining Step: 1264  | total loss: [1m[32m0.00732[0m[0m | time: 486.147s
[2K
| Adam | epoch: 019 | loss: 0.00732 - acc: 0.9987 -- iter: 1280/2163
[A[ATraining Step: 1265  | total loss: [1m[32m0.00675[0m[0m | time: 498.807s
[2K
| Adam | epoch: 019 | loss: 0.00675 - acc: 0.9989 -- iter: 1312/2163
[A[ATraining Step: 1266  | total loss: [1m[32m0.00622[0m[0m | time: 511.533s
[2K
| Adam | epoch: 019 | loss: 0.00622 - acc: 0.9990 -- iter: 1344/2163
[A[ATraining Step: 1267  | total loss: [1m[32m0.00563[0m[0m | time: 523.789s
[2K
| Adam | epoch: 019 | loss: 0.00563 - acc: 0.9991 -- iter: 1376/2163
[A[ATraining Step: 1268  | total loss: [1m[32m0.00516[0m[0m | time: 536.279s
[2K
| Adam | epoch: 019 | loss: 0.00516 - acc: 0.9992 -- iter: 1408/2163
[A[ATraining Step: 1269  | total loss: [1m[32m0.00531[0m[0m | time: 548.870s
[2K
| Adam | epoch: 019 | loss: 0.00531 - acc: 0.9993 -- iter: 1440/2163
[A[ATraining Step: 1270  | total loss: [1m[32m0.00485[0m[0m | time: 561.352s
[2K
| Adam | epoch: 019 | loss: 0.00485 - acc: 0.9993 -- iter: 1472/2163
[A[ATraining Step: 1271  | total loss: [1m[32m0.00486[0m[0m | time: 573.906s
[2K
| Adam | epoch: 019 | loss: 0.00486 - acc: 0.9994 -- iter: 1504/2163
[A[ATraining Step: 1272  | total loss: [1m[32m0.00480[0m[0m | time: 586.196s
[2K
| Adam | epoch: 019 | loss: 0.00480 - acc: 0.9995 -- iter: 1536/2163
[A[ATraining Step: 1273  | total loss: [1m[32m0.00441[0m[0m | time: 598.434s
[2K
| Adam | epoch: 019 | loss: 0.00441 - acc: 0.9995 -- iter: 1568/2163
[A[ATraining Step: 1274  | total loss: [1m[32m0.00515[0m[0m | time: 610.869s
[2K
| Adam | epoch: 019 | loss: 0.00515 - acc: 0.9996 -- iter: 1600/2163
[A[ATraining Step: 1275  | total loss: [1m[32m0.00541[0m[0m | time: 623.720s
[2K
| Adam | epoch: 019 | loss: 0.00541 - acc: 0.9996 -- iter: 1632/2163
[A[ATraining Step: 1276  | total loss: [1m[32m0.00544[0m[0m | time: 636.216s
[2K
| Adam | epoch: 019 | loss: 0.00544 - acc: 0.9996 -- iter: 1664/2163
[A[ATraining Step: 1277  | total loss: [1m[32m0.00492[0m[0m | time: 648.838s
[2K
| Adam | epoch: 019 | loss: 0.00492 - acc: 0.9997 -- iter: 1696/2163
[A[ATraining Step: 1278  | total loss: [1m[32m0.00459[0m[0m | time: 661.373s
[2K
| Adam | epoch: 019 | loss: 0.00459 - acc: 0.9997 -- iter: 1728/2163
[A[ATraining Step: 1279  | total loss: [1m[32m0.00419[0m[0m | time: 673.871s
[2K
| Adam | epoch: 019 | loss: 0.00419 - acc: 0.9997 -- iter: 1760/2163
[A[ATraining Step: 1280  | total loss: [1m[32m0.00415[0m[0m | time: 686.393s
[2K
| Adam | epoch: 019 | loss: 0.00415 - acc: 0.9998 -- iter: 1792/2163
[A[ATraining Step: 1281  | total loss: [1m[32m0.00452[0m[0m | time: 698.951s
[2K
| Adam | epoch: 019 | loss: 0.00452 - acc: 0.9998 -- iter: 1824/2163
[A[ATraining Step: 1282  | total loss: [1m[32m0.00425[0m[0m | time: 711.634s
[2K
| Adam | epoch: 019 | loss: 0.00425 - acc: 0.9998 -- iter: 1856/2163
[A[ATraining Step: 1283  | total loss: [1m[32m0.00384[0m[0m | time: 723.744s
[2K
| Adam | epoch: 019 | loss: 0.00384 - acc: 0.9998 -- iter: 1888/2163
[A[ATraining Step: 1284  | total loss: [1m[32m0.00395[0m[0m | time: 736.166s
[2K
| Adam | epoch: 019 | loss: 0.00395 - acc: 0.9998 -- iter: 1920/2163
[A[ATraining Step: 1285  | total loss: [1m[32m0.00361[0m[0m | time: 748.415s
[2K
| Adam | epoch: 019 | loss: 0.00361 - acc: 0.9999 -- iter: 1952/2163
[A[ATraining Step: 1286  | total loss: [1m[32m0.00330[0m[0m | time: 760.693s
[2K
| Adam | epoch: 019 | loss: 0.00330 - acc: 0.9999 -- iter: 1984/2163
[A[ATraining Step: 1287  | total loss: [1m[32m0.00305[0m[0m | time: 773.027s
[2K
| Adam | epoch: 019 | loss: 0.00305 - acc: 0.9999 -- iter: 2016/2163
[A[ATraining Step: 1288  | total loss: [1m[32m0.00287[0m[0m | time: 785.323s
[2K
| Adam | epoch: 019 | loss: 0.00287 - acc: 0.9999 -- iter: 2048/2163
[A[ATraining Step: 1289  | total loss: [1m[32m0.00269[0m[0m | time: 797.623s
[2K
| Adam | epoch: 019 | loss: 0.00269 - acc: 0.9999 -- iter: 2080/2163
[A[ATraining Step: 1290  | total loss: [1m[32m0.00277[0m[0m | time: 810.125s
[2K
| Adam | epoch: 019 | loss: 0.00277 - acc: 0.9999 -- iter: 2112/2163
[A[ATraining Step: 1291  | total loss: [1m[32m0.00255[0m[0m | time: 822.276s
[2K
| Adam | epoch: 019 | loss: 0.00255 - acc: 0.9999 -- iter: 2144/2163
[A[ATraining Step: 1292  | total loss: [1m[32m0.00243[0m[0m | time: 885.814s
[2K
| Adam | epoch: 019 | loss: 0.00243 - acc: 0.9999 | val_loss: 0.18838 - val_acc: 0.9527 -- iter: 2163/2163
--
Training Step: 1293  | total loss: [1m[32m0.00226[0m[0m | time: 12.420s
[2K
| Adam | epoch: 020 | loss: 0.00226 - acc: 0.9999 -- iter: 0032/2163
[A[ATraining Step: 1294  | total loss: [1m[32m0.00245[0m[0m | time: 24.834s
[2K
| Adam | epoch: 020 | loss: 0.00245 - acc: 0.9999 -- iter: 0064/2163
[A[ATraining Step: 1295  | total loss: [1m[32m0.00243[0m[0m | time: 37.427s
[2K
| Adam | epoch: 020 | loss: 0.00243 - acc: 1.0000 -- iter: 0096/2163
[A[ATraining Step: 1296  | total loss: [1m[32m0.00228[0m[0m | time: 49.798s
[2K
| Adam | epoch: 020 | loss: 0.00228 - acc: 1.0000 -- iter: 0128/2163
[A[ATraining Step: 1297  | total loss: [1m[32m0.00254[0m[0m | time: 62.044s
[2K
| Adam | epoch: 020 | loss: 0.00254 - acc: 1.0000 -- iter: 0160/2163
[A[ATraining Step: 1298  | total loss: [1m[32m0.00254[0m[0m | time: 74.517s
[2K
| Adam | epoch: 020 | loss: 0.00254 - acc: 1.0000 -- iter: 0192/2163
[A[ATraining Step: 1299  | total loss: [1m[32m0.00294[0m[0m | time: 87.206s
[2K
| Adam | epoch: 020 | loss: 0.00294 - acc: 1.0000 -- iter: 0224/2163
[A[ATraining Step: 1300  | total loss: [1m[32m0.00273[0m[0m | time: 99.844s
[2K
| Adam | epoch: 020 | loss: 0.00273 - acc: 1.0000 -- iter: 0256/2163
[A[ATraining Step: 1301  | total loss: [1m[32m0.00251[0m[0m | time: 112.479s
[2K
| Adam | epoch: 020 | loss: 0.00251 - acc: 1.0000 -- iter: 0288/2163
[A[ATraining Step: 1302  | total loss: [1m[32m0.00234[0m[0m | time: 125.262s
[2K
| Adam | epoch: 020 | loss: 0.00234 - acc: 1.0000 -- iter: 0320/2163
[A[ATraining Step: 1303  | total loss: [1m[32m0.00238[0m[0m | time: 137.889s
[2K
| Adam | epoch: 020 | loss: 0.00238 - acc: 1.0000 -- iter: 0352/2163
[A[ATraining Step: 1304  | total loss: [1m[32m0.00216[0m[0m | time: 150.505s
[2K
| Adam | epoch: 020 | loss: 0.00216 - acc: 1.0000 -- iter: 0384/2163
[A[ATraining Step: 1305  | total loss: [1m[32m0.00196[0m[0m | time: 163.043s
[2K
| Adam | epoch: 020 | loss: 0.00196 - acc: 1.0000 -- iter: 0416/2163
[A[ATraining Step: 1306  | total loss: [1m[32m0.00186[0m[0m | time: 175.903s
[2K
| Adam | epoch: 020 | loss: 0.00186 - acc: 1.0000 -- iter: 0448/2163
[A[ATraining Step: 1307  | total loss: [1m[32m0.00174[0m[0m | time: 188.435s
[2K
| Adam | epoch: 020 | loss: 0.00174 - acc: 1.0000 -- iter: 0480/2163
[A[ATraining Step: 1308  | total loss: [1m[32m0.00162[0m[0m | time: 201.093s
[2K
| Adam | epoch: 020 | loss: 0.00162 - acc: 1.0000 -- iter: 0512/2163
[A[ATraining Step: 1309  | total loss: [1m[32m0.00162[0m[0m | time: 213.349s
[2K
| Adam | epoch: 020 | loss: 0.00162 - acc: 1.0000 -- iter: 0544/2163
[A[ATraining Step: 1310  | total loss: [1m[32m0.00147[0m[0m | time: 221.750s
[2K
| Adam | epoch: 020 | loss: 0.00147 - acc: 1.0000 -- iter: 0576/2163
[A[ATraining Step: 1311  | total loss: [1m[32m0.00306[0m[0m | time: 229.858s
[2K
| Adam | epoch: 020 | loss: 0.00306 - acc: 1.0000 -- iter: 0608/2163
[A[ATraining Step: 1312  | total loss: [1m[32m0.00357[0m[0m | time: 242.543s
[2K
| Adam | epoch: 020 | loss: 0.00357 - acc: 1.0000 -- iter: 0640/2163
[A[ATraining Step: 1313  | total loss: [1m[32m0.00326[0m[0m | time: 255.021s
[2K
| Adam | epoch: 020 | loss: 0.00326 - acc: 1.0000 -- iter: 0672/2163
[A[ATraining Step: 1314  | total loss: [1m[32m0.00304[0m[0m | time: 267.623s
[2K
| Adam | epoch: 020 | loss: 0.00304 - acc: 1.0000 -- iter: 0704/2163
[A[ATraining Step: 1315  | total loss: [1m[32m0.00302[0m[0m | time: 279.870s
[2K
| Adam | epoch: 020 | loss: 0.00302 - acc: 1.0000 -- iter: 0736/2163
[A[ATraining Step: 1316  | total loss: [1m[32m0.00276[0m[0m | time: 292.290s
[2K
| Adam | epoch: 020 | loss: 0.00276 - acc: 1.0000 -- iter: 0768/2163
[A[ATraining Step: 1317  | total loss: [1m[32m0.00250[0m[0m | time: 304.400s
[2K
| Adam | epoch: 020 | loss: 0.00250 - acc: 1.0000 -- iter: 0800/2163
[A[ATraining Step: 1318  | total loss: [1m[32m0.00227[0m[0m | time: 317.151s
[2K
| Adam | epoch: 020 | loss: 0.00227 - acc: 1.0000 -- iter: 0832/2163
[A[ATraining Step: 1319  | total loss: [1m[32m0.00213[0m[0m | time: 329.544s
[2K
| Adam | epoch: 020 | loss: 0.00213 - acc: 1.0000 -- iter: 0864/2163
[A[ATraining Step: 1320  | total loss: [1m[32m0.00195[0m[0m | time: 342.100s
[2K
| Adam | epoch: 020 | loss: 0.00195 - acc: 1.0000 -- iter: 0896/2163
[A[ATraining Step: 1321  | total loss: [1m[32m0.00186[0m[0m | time: 354.800s
[2K
| Adam | epoch: 020 | loss: 0.00186 - acc: 1.0000 -- iter: 0928/2163
[A[ATraining Step: 1322  | total loss: [1m[32m0.00173[0m[0m | time: 367.053s
[2K
| Adam | epoch: 020 | loss: 0.00173 - acc: 1.0000 -- iter: 0960/2163
[A[ATraining Step: 1323  | total loss: [1m[32m0.00180[0m[0m | time: 379.212s
[2K
| Adam | epoch: 020 | loss: 0.00180 - acc: 1.0000 -- iter: 0992/2163
[A[ATraining Step: 1324  | total loss: [1m[32m0.00244[0m[0m | time: 392.008s
[2K
| Adam | epoch: 020 | loss: 0.00244 - acc: 1.0000 -- iter: 1024/2163
[A[ATraining Step: 1325  | total loss: [1m[32m0.00225[0m[0m | time: 404.680s
[2K
| Adam | epoch: 020 | loss: 0.00225 - acc: 1.0000 -- iter: 1056/2163
[A[ATraining Step: 1326  | total loss: [1m[32m0.00218[0m[0m | time: 417.285s
[2K
| Adam | epoch: 020 | loss: 0.00218 - acc: 1.0000 -- iter: 1088/2163
[A[ATraining Step: 1327  | total loss: [1m[32m0.00207[0m[0m | time: 429.742s
[2K
| Adam | epoch: 020 | loss: 0.00207 - acc: 1.0000 -- iter: 1120/2163
[A[ATraining Step: 1328  | total loss: [1m[32m0.00192[0m[0m | time: 442.426s
[2K
| Adam | epoch: 020 | loss: 0.00192 - acc: 1.0000 -- iter: 1152/2163
[A[ATraining Step: 1329  | total loss: [1m[32m0.00319[0m[0m | time: 455.362s
[2K
| Adam | epoch: 020 | loss: 0.00319 - acc: 1.0000 -- iter: 1184/2163
[A[ATraining Step: 1330  | total loss: [1m[32m0.00292[0m[0m | time: 467.672s
[2K
| Adam | epoch: 020 | loss: 0.00292 - acc: 1.0000 -- iter: 1216/2163
[A[ATraining Step: 1331  | total loss: [1m[32m0.00265[0m[0m | time: 480.319s
[2K
| Adam | epoch: 020 | loss: 0.00265 - acc: 1.0000 -- iter: 1248/2163
[A[ATraining Step: 1332  | total loss: [1m[32m0.00261[0m[0m | time: 492.362s
[2K
| Adam | epoch: 020 | loss: 0.00261 - acc: 1.0000 -- iter: 1280/2163
[A[ATraining Step: 1333  | total loss: [1m[32m0.00237[0m[0m | time: 504.660s
[2K
| Adam | epoch: 020 | loss: 0.00237 - acc: 1.0000 -- iter: 1312/2163
[A[ATraining Step: 1334  | total loss: [1m[32m0.00218[0m[0m | time: 517.201s
[2K
| Adam | epoch: 020 | loss: 0.00218 - acc: 1.0000 -- iter: 1344/2163
[A[ATraining Step: 1335  | total loss: [1m[32m0.00205[0m[0m | time: 529.710s
[2K
| Adam | epoch: 020 | loss: 0.00205 - acc: 1.0000 -- iter: 1376/2163
[A[ATraining Step: 1336  | total loss: [1m[32m0.00300[0m[0m | time: 542.176s
[2K
| Adam | epoch: 020 | loss: 0.00300 - acc: 1.0000 -- iter: 1408/2163
[A[ATraining Step: 1337  | total loss: [1m[32m0.00273[0m[0m | time: 554.610s
[2K
| Adam | epoch: 020 | loss: 0.00273 - acc: 1.0000 -- iter: 1440/2163
[A[ATraining Step: 1338  | total loss: [1m[32m0.00269[0m[0m | time: 567.034s
[2K
| Adam | epoch: 020 | loss: 0.00269 - acc: 1.0000 -- iter: 1472/2163
[A[ATraining Step: 1339  | total loss: [1m[32m0.00260[0m[0m | time: 579.741s
[2K
| Adam | epoch: 020 | loss: 0.00260 - acc: 1.0000 -- iter: 1504/2163
[A[ATraining Step: 1340  | total loss: [1m[32m0.00237[0m[0m | time: 592.398s
[2K
| Adam | epoch: 020 | loss: 0.00237 - acc: 1.0000 -- iter: 1536/2163
[A[ATraining Step: 1341  | total loss: [1m[32m0.00225[0m[0m | time: 605.135s
[2K
| Adam | epoch: 020 | loss: 0.00225 - acc: 1.0000 -- iter: 1568/2163
[A[ATraining Step: 1342  | total loss: [1m[32m0.00231[0m[0m | time: 617.882s
[2K
| Adam | epoch: 020 | loss: 0.00231 - acc: 1.0000 -- iter: 1600/2163
[A[ATraining Step: 1343  | total loss: [1m[32m0.00222[0m[0m | time: 630.471s
[2K
| Adam | epoch: 020 | loss: 0.00222 - acc: 1.0000 -- iter: 1632/2163
[A[ATraining Step: 1344  | total loss: [1m[32m0.00202[0m[0m | time: 643.505s
[2K
| Adam | epoch: 020 | loss: 0.00202 - acc: 1.0000 -- iter: 1664/2163
[A[ATraining Step: 1345  | total loss: [1m[32m0.00184[0m[0m | time: 656.387s
[2K
| Adam | epoch: 020 | loss: 0.00184 - acc: 1.0000 -- iter: 1696/2163
[A[ATraining Step: 1346  | total loss: [1m[32m0.00256[0m[0m | time: 668.849s
[2K
| Adam | epoch: 020 | loss: 0.00256 - acc: 1.0000 -- iter: 1728/2163
[A[ATraining Step: 1347  | total loss: [1m[32m0.00233[0m[0m | time: 681.124s
[2K
| Adam | epoch: 020 | loss: 0.00233 - acc: 1.0000 -- iter: 1760/2163
[A[ATraining Step: 1348  | total loss: [1m[32m0.27075[0m[0m | time: 693.134s
[2K
| Adam | epoch: 020 | loss: 0.27075 - acc: 0.9781 -- iter: 1792/2163
[A[ATraining Step: 1349  | total loss: [1m[32m0.24376[0m[0m | time: 705.572s
[2K
| Adam | epoch: 020 | loss: 0.24376 - acc: 0.9803 -- iter: 1824/2163
[A[ATraining Step: 1350  | total loss: [1m[32m0.22052[0m[0m | time: 717.898s
[2K
| Adam | epoch: 020 | loss: 0.22052 - acc: 0.9823 -- iter: 1856/2163
[A[ATraining Step: 1351  | total loss: [1m[32m0.19859[0m[0m | time: 730.177s
[2K
| Adam | epoch: 020 | loss: 0.19859 - acc: 0.9841 -- iter: 1888/2163
[A[ATraining Step: 1352  | total loss: [1m[32m0.17880[0m[0m | time: 742.821s
[2K
| Adam | epoch: 020 | loss: 0.17880 - acc: 0.9856 -- iter: 1920/2163
[A[ATraining Step: 1353  | total loss: [1m[32m0.16761[0m[0m | time: 755.189s
[2K
| Adam | epoch: 020 | loss: 0.16761 - acc: 0.9840 -- iter: 1952/2163
[A[ATraining Step: 1354  | total loss: [1m[32m0.15102[0m[0m | time: 767.537s
[2K
| Adam | epoch: 020 | loss: 0.15102 - acc: 0.9856 -- iter: 1984/2163
[A[ATraining Step: 1355  | total loss: [1m[32m0.13603[0m[0m | time: 780.808s
[2K
| Adam | epoch: 020 | loss: 0.13603 - acc: 0.9870 -- iter: 2016/2163
[A[ATraining Step: 1356  | total loss: [1m[32m0.12549[0m[0m | time: 793.398s
[2K
| Adam | epoch: 020 | loss: 0.12549 - acc: 0.9883 -- iter: 2048/2163
[A[ATraining Step: 1357  | total loss: [1m[32m0.13709[0m[0m | time: 806.646s
[2K
| Adam | epoch: 020 | loss: 0.13709 - acc: 0.9863 -- iter: 2080/2163
[A[ATraining Step: 1358  | total loss: [1m[32m0.12481[0m[0m | time: 818.942s
[2K
| Adam | epoch: 020 | loss: 0.12481 - acc: 0.9877 -- iter: 2112/2163
[A[ATraining Step: 1359  | total loss: [1m[32m0.13317[0m[0m | time: 831.377s
[2K
| Adam | epoch: 020 | loss: 0.13317 - acc: 0.9827 -- iter: 2144/2163
[A[ATraining Step: 1360  | total loss: [1m[32m0.12020[0m[0m | time: 894.176s
[2K
| Adam | epoch: 020 | loss: 0.12020 - acc: 0.9844 | val_loss: 0.44401 - val_acc: 0.8833 -- iter: 2163/2163
--
Training Step: 1361  | total loss: [1m[32m0.10839[0m[0m | time: 12.466s
[2K
| Adam | epoch: 021 | loss: 0.10839 - acc: 0.9860 -- iter: 0032/2163
[A[ATraining Step: 1362  | total loss: [1m[32m0.09955[0m[0m | time: 24.704s
[2K
| Adam | epoch: 021 | loss: 0.09955 - acc: 0.9874 -- iter: 0064/2163
[A[ATraining Step: 1363  | total loss: [1m[32m0.09092[0m[0m | time: 37.051s
[2K
| Adam | epoch: 021 | loss: 0.09092 - acc: 0.9886 -- iter: 0096/2163
[A[ATraining Step: 1364  | total loss: [1m[32m0.08403[0m[0m | time: 49.521s
[2K
| Adam | epoch: 021 | loss: 0.08403 - acc: 0.9898 -- iter: 0128/2163
[A[ATraining Step: 1365  | total loss: [1m[32m0.07623[0m[0m | time: 61.753s
[2K
| Adam | epoch: 021 | loss: 0.07623 - acc: 0.9908 -- iter: 0160/2163
[A[ATraining Step: 1366  | total loss: [1m[32m0.06907[0m[0m | time: 74.004s
[2K
| Adam | epoch: 021 | loss: 0.06907 - acc: 0.9917 -- iter: 0192/2163
[A[ATraining Step: 1367  | total loss: [1m[32m0.06367[0m[0m | time: 86.621s
[2K
| Adam | epoch: 021 | loss: 0.06367 - acc: 0.9926 -- iter: 0224/2163
[A[ATraining Step: 1368  | total loss: [1m[32m0.05843[0m[0m | time: 99.275s
[2K
| Adam | epoch: 021 | loss: 0.05843 - acc: 0.9933 -- iter: 0256/2163
[A[ATraining Step: 1369  | total loss: [1m[32m0.05318[0m[0m | time: 111.597s
[2K
| Adam | epoch: 021 | loss: 0.05318 - acc: 0.9940 -- iter: 0288/2163
[A[ATraining Step: 1370  | total loss: [1m[32m0.04812[0m[0m | time: 124.025s
[2K
| Adam | epoch: 021 | loss: 0.04812 - acc: 0.9946 -- iter: 0320/2163
[A[ATraining Step: 1371  | total loss: [1m[32m0.04580[0m[0m | time: 136.636s
[2K
| Adam | epoch: 021 | loss: 0.04580 - acc: 0.9951 -- iter: 0352/2163
[A[ATraining Step: 1372  | total loss: [1m[32m0.04190[0m[0m | time: 150.088s
[2K
| Adam | epoch: 021 | loss: 0.04190 - acc: 0.9956 -- iter: 0384/2163
[A[ATraining Step: 1373  | total loss: [1m[32m0.03916[0m[0m | time: 162.453s
[2K
| Adam | epoch: 021 | loss: 0.03916 - acc: 0.9960 -- iter: 0416/2163
[A[ATraining Step: 1374  | total loss: [1m[32m0.03627[0m[0m | time: 176.499s
[2K
| Adam | epoch: 021 | loss: 0.03627 - acc: 0.9964 -- iter: 0448/2163
[A[ATraining Step: 1375  | total loss: [1m[32m0.03945[0m[0m | time: 189.919s
[2K
| Adam | epoch: 021 | loss: 0.03945 - acc: 0.9937 -- iter: 0480/2163
[A[ATraining Step: 1376  | total loss: [1m[32m0.03657[0m[0m | time: 203.073s
[2K
| Adam | epoch: 021 | loss: 0.03657 - acc: 0.9943 -- iter: 0512/2163
[A[ATraining Step: 1377  | total loss: [1m[32m0.03381[0m[0m | time: 216.205s
[2K
| Adam | epoch: 021 | loss: 0.03381 - acc: 0.9949 -- iter: 0544/2163
[A[ATraining Step: 1378  | total loss: [1m[32m0.03284[0m[0m | time: 228.568s
[2K
| Adam | epoch: 021 | loss: 0.03284 - acc: 0.9954 -- iter: 0576/2163
[A[ATraining Step: 1379  | total loss: [1m[32m0.03140[0m[0m | time: 233.662s
[2K
| Adam | epoch: 021 | loss: 0.03140 - acc: 0.9958 -- iter: 0608/2163
[A[ATraining Step: 1380  | total loss: [1m[32m0.02943[0m[0m | time: 238.871s
[2K
| Adam | epoch: 021 | loss: 0.02943 - acc: 0.9963 -- iter: 0640/2163
[A[ATraining Step: 1381  | total loss: [1m[32m0.02741[0m[0m | time: 246.640s
[2K
| Adam | epoch: 021 | loss: 0.02741 - acc: 0.9966 -- iter: 0672/2163
[A[ATraining Step: 1382  | total loss: [1m[32m0.02506[0m[0m | time: 256.693s
[2K
| Adam | epoch: 021 | loss: 0.02506 - acc: 0.9970 -- iter: 0704/2163
[A[ATraining Step: 1383  | total loss: [1m[32m0.02331[0m[0m | time: 269.171s
[2K
| Adam | epoch: 021 | loss: 0.02331 - acc: 0.9973 -- iter: 0736/2163
[A[ATraining Step: 1384  | total loss: [1m[32m0.02713[0m[0m | time: 281.838s
[2K
| Adam | epoch: 021 | loss: 0.02713 - acc: 0.9975 -- iter: 0768/2163
[A[ATraining Step: 1385  | total loss: [1m[32m0.02493[0m[0m | time: 294.285s
[2K
| Adam | epoch: 021 | loss: 0.02493 - acc: 0.9978 -- iter: 0800/2163
[A[ATraining Step: 1386  | total loss: [1m[32m0.02335[0m[0m | time: 307.335s
[2K
| Adam | epoch: 021 | loss: 0.02335 - acc: 0.9980 -- iter: 0832/2163
[A[ATraining Step: 1387  | total loss: [1m[32m0.02144[0m[0m | time: 319.805s
[2K
| Adam | epoch: 021 | loss: 0.02144 - acc: 0.9982 -- iter: 0864/2163
[A[ATraining Step: 1388  | total loss: [1m[32m0.01937[0m[0m | time: 332.449s
[2K
| Adam | epoch: 021 | loss: 0.01937 - acc: 0.9984 -- iter: 0896/2163
[A[ATraining Step: 1389  | total loss: [1m[32m0.01775[0m[0m | time: 345.157s
[2K
| Adam | epoch: 021 | loss: 0.01775 - acc: 0.9986 -- iter: 0928/2163
[A[ATraining Step: 1390  | total loss: [1m[32m0.01625[0m[0m | time: 358.126s
[2K
| Adam | epoch: 021 | loss: 0.01625 - acc: 0.9987 -- iter: 0960/2163
[A[ATraining Step: 1391  | total loss: [1m[32m0.01806[0m[0m | time: 370.806s
[2K
| Adam | epoch: 021 | loss: 0.01806 - acc: 0.9988 -- iter: 0992/2163
[A[ATraining Step: 1392  | total loss: [1m[32m0.01636[0m[0m | time: 384.122s
[2K
| Adam | epoch: 021 | loss: 0.01636 - acc: 0.9989 -- iter: 1024/2163
[A[ATraining Step: 1393  | total loss: [1m[32m0.02029[0m[0m | time: 397.728s
[2K
| Adam | epoch: 021 | loss: 0.02029 - acc: 0.9959 -- iter: 1056/2163
[A[ATraining Step: 1394  | total loss: [1m[32m0.01858[0m[0m | time: 411.239s
[2K
| Adam | epoch: 021 | loss: 0.01858 - acc: 0.9963 -- iter: 1088/2163
[A[ATraining Step: 1395  | total loss: [1m[32m0.01678[0m[0m | time: 424.960s
[2K
| Adam | epoch: 021 | loss: 0.01678 - acc: 0.9967 -- iter: 1120/2163
[A[ATraining Step: 1396  | total loss: [1m[32m0.01574[0m[0m | time: 438.528s
[2K
| Adam | epoch: 021 | loss: 0.01574 - acc: 0.9970 -- iter: 1152/2163
[A[ATraining Step: 1397  | total loss: [1m[32m0.01422[0m[0m | time: 451.679s
[2K
| Adam | epoch: 021 | loss: 0.01422 - acc: 0.9973 -- iter: 1184/2163
[A[ATraining Step: 1398  | total loss: [1m[32m0.01459[0m[0m | time: 462.594s
[2K
| Adam | epoch: 021 | loss: 0.01459 - acc: 0.9976 -- iter: 1216/2163
[A[ATraining Step: 1399  | total loss: [1m[32m0.01322[0m[0m | time: 470.385s
[2K
| Adam | epoch: 021 | loss: 0.01322 - acc: 0.9978 -- iter: 1248/2163
[A[ATraining Step: 1400  | total loss: [1m[32m0.01208[0m[0m | time: 533.373s
[2K
| Adam | epoch: 021 | loss: 0.01208 - acc: 0.9981 | val_loss: 0.17410 - val_acc: 0.9542 -- iter: 1280/2163
--
Training Step: 1401  | total loss: [1m[32m0.01097[0m[0m | time: 546.568s
[2K
| Adam | epoch: 021 | loss: 0.01097 - acc: 0.9982 -- iter: 1312/2163
[A[ATraining Step: 1402  | total loss: [1m[32m0.00995[0m[0m | time: 559.275s
[2K
| Adam | epoch: 021 | loss: 0.00995 - acc: 0.9984 -- iter: 1344/2163
[A[ATraining Step: 1403  | total loss: [1m[32m0.00899[0m[0m | time: 571.997s
[2K
| Adam | epoch: 021 | loss: 0.00899 - acc: 0.9986 -- iter: 1376/2163
[A[ATraining Step: 1404  | total loss: [1m[32m0.00816[0m[0m | time: 584.287s
[2K
| Adam | epoch: 021 | loss: 0.00816 - acc: 0.9987 -- iter: 1408/2163
[A[ATraining Step: 1405  | total loss: [1m[32m0.00746[0m[0m | time: 596.624s
[2K
| Adam | epoch: 021 | loss: 0.00746 - acc: 0.9988 -- iter: 1440/2163
[A[ATraining Step: 1406  | total loss: [1m[32m0.00691[0m[0m | time: 608.874s
[2K
| Adam | epoch: 021 | loss: 0.00691 - acc: 0.9990 -- iter: 1472/2163
[A[ATraining Step: 1407  | total loss: [1m[32m0.00828[0m[0m | time: 621.571s
[2K
| Adam | epoch: 021 | loss: 0.00828 - acc: 0.9991 -- iter: 1504/2163
[A[ATraining Step: 1408  | total loss: [1m[32m0.00766[0m[0m | time: 633.671s
[2K
| Adam | epoch: 021 | loss: 0.00766 - acc: 0.9992 -- iter: 1536/2163
[A[ATraining Step: 1409  | total loss: [1m[32m0.02392[0m[0m | time: 646.055s
[2K
| Adam | epoch: 021 | loss: 0.02392 - acc: 0.9930 -- iter: 1568/2163
[A[ATraining Step: 1410  | total loss: [1m[32m0.02166[0m[0m | time: 658.252s
[2K
| Adam | epoch: 021 | loss: 0.02166 - acc: 0.9937 -- iter: 1600/2163
[A[ATraining Step: 1411  | total loss: [1m[32m0.01967[0m[0m | time: 670.907s
[2K
| Adam | epoch: 021 | loss: 0.01967 - acc: 0.9943 -- iter: 1632/2163
[A[ATraining Step: 1412  | total loss: [1m[32m0.01776[0m[0m | time: 683.638s
[2K
| Adam | epoch: 021 | loss: 0.01776 - acc: 0.9949 -- iter: 1664/2163
[A[ATraining Step: 1413  | total loss: [1m[32m0.01635[0m[0m | time: 696.003s
[2K
| Adam | epoch: 021 | loss: 0.01635 - acc: 0.9954 -- iter: 1696/2163
[A[ATraining Step: 1414  | total loss: [1m[32m0.01616[0m[0m | time: 709.005s
[2K
| Adam | epoch: 021 | loss: 0.01616 - acc: 0.9959 -- iter: 1728/2163
[A[ATraining Step: 1415  | total loss: [1m[32m0.01470[0m[0m | time: 721.704s
[2K
| Adam | epoch: 021 | loss: 0.01470 - acc: 0.9963 -- iter: 1760/2163
[A[ATraining Step: 1416  | total loss: [1m[32m0.01411[0m[0m | time: 734.476s
[2K
| Adam | epoch: 021 | loss: 0.01411 - acc: 0.9966 -- iter: 1792/2163
[A[ATraining Step: 1417  | total loss: [1m[32m0.03937[0m[0m | time: 746.822s
[2K
| Adam | epoch: 021 | loss: 0.03937 - acc: 0.9939 -- iter: 1824/2163
[A[ATraining Step: 1418  | total loss: [1m[32m0.03625[0m[0m | time: 759.452s
[2K
| Adam | epoch: 021 | loss: 0.03625 - acc: 0.9945 -- iter: 1856/2163
[A[ATraining Step: 1419  | total loss: [1m[32m0.03297[0m[0m | time: 772.214s
[2K
| Adam | epoch: 021 | loss: 0.03297 - acc: 0.9950 -- iter: 1888/2163
[A[ATraining Step: 1420  | total loss: [1m[32m0.03247[0m[0m | time: 785.182s
[2K
| Adam | epoch: 021 | loss: 0.03247 - acc: 0.9955 -- iter: 1920/2163
[A[ATraining Step: 1421  | total loss: [1m[32m0.03782[0m[0m | time: 797.628s
[2K
| Adam | epoch: 021 | loss: 0.03782 - acc: 0.9928 -- iter: 1952/2163
[A[ATraining Step: 1422  | total loss: [1m[32m0.09917[0m[0m | time: 809.910s
[2K
| Adam | epoch: 021 | loss: 0.09917 - acc: 0.9811 -- iter: 1984/2163
[A[ATraining Step: 1423  | total loss: [1m[32m0.08942[0m[0m | time: 822.441s
[2K
| Adam | epoch: 021 | loss: 0.08942 - acc: 0.9830 -- iter: 2016/2163
[A[ATraining Step: 1424  | total loss: [1m[32m0.08113[0m[0m | time: 834.878s
[2K
| Adam | epoch: 021 | loss: 0.08113 - acc: 0.9847 -- iter: 2048/2163
[A[ATraining Step: 1425  | total loss: [1m[32m0.07310[0m[0m | time: 846.964s
[2K
| Adam | epoch: 021 | loss: 0.07310 - acc: 0.9862 -- iter: 2080/2163
[A[ATraining Step: 1426  | total loss: [1m[32m0.06610[0m[0m | time: 859.341s
[2K
| Adam | epoch: 021 | loss: 0.06610 - acc: 0.9876 -- iter: 2112/2163
[A[ATraining Step: 1427  | total loss: [1m[32m0.05961[0m[0m | time: 872.148s
[2K
| Adam | epoch: 021 | loss: 0.05961 - acc: 0.9888 -- iter: 2144/2163
[A[ATraining Step: 1428  | total loss: [1m[32m0.05396[0m[0m | time: 935.432s
[2K
| Adam | epoch: 021 | loss: 0.05396 - acc: 0.9899 | val_loss: 0.21743 - val_acc: 0.9261 -- iter: 2163/2163
--
Training Step: 1429  | total loss: [1m[32m0.05349[0m[0m | time: 12.878s
[2K
| Adam | epoch: 022 | loss: 0.05349 - acc: 0.9909 -- iter: 0032/2163
[A[ATraining Step: 1430  | total loss: [1m[32m0.04916[0m[0m | time: 25.464s
[2K
| Adam | epoch: 022 | loss: 0.04916 - acc: 0.9918 -- iter: 0064/2163
[A[ATraining Step: 1431  | total loss: [1m[32m0.04748[0m[0m | time: 37.719s
[2K
| Adam | epoch: 022 | loss: 0.04748 - acc: 0.9895 -- iter: 0096/2163
[A[ATraining Step: 1432  | total loss: [1m[32m0.04373[0m[0m | time: 50.481s
[2K
| Adam | epoch: 022 | loss: 0.04373 - acc: 0.9906 -- iter: 0128/2163
[A[ATraining Step: 1433  | total loss: [1m[32m0.03957[0m[0m | time: 63.034s
[2K
| Adam | epoch: 022 | loss: 0.03957 - acc: 0.9915 -- iter: 0160/2163
[A[ATraining Step: 1434  | total loss: [1m[32m0.05961[0m[0m | time: 76.168s
[2K
| Adam | epoch: 022 | loss: 0.05961 - acc: 0.9830 -- iter: 0192/2163
[A[ATraining Step: 1435  | total loss: [1m[32m0.05690[0m[0m | time: 88.855s
[2K
| Adam | epoch: 022 | loss: 0.05690 - acc: 0.9816 -- iter: 0224/2163
[A[ATraining Step: 1436  | total loss: [1m[32m0.05217[0m[0m | time: 101.713s
[2K
| Adam | epoch: 022 | loss: 0.05217 - acc: 0.9834 -- iter: 0256/2163
[A[ATraining Step: 1437  | total loss: [1m[32m0.04814[0m[0m | time: 114.375s
[2K
| Adam | epoch: 022 | loss: 0.04814 - acc: 0.9851 -- iter: 0288/2163
[A[ATraining Step: 1438  | total loss: [1m[32m0.04369[0m[0m | time: 126.739s
[2K
| Adam | epoch: 022 | loss: 0.04369 - acc: 0.9866 -- iter: 0320/2163
[A[ATraining Step: 1439  | total loss: [1m[32m0.04204[0m[0m | time: 139.164s
[2K
| Adam | epoch: 022 | loss: 0.04204 - acc: 0.9879 -- iter: 0352/2163
[A[ATraining Step: 1440  | total loss: [1m[32m0.03808[0m[0m | time: 151.838s
[2K
| Adam | epoch: 022 | loss: 0.03808 - acc: 0.9891 -- iter: 0384/2163
[A[ATraining Step: 1441  | total loss: [1m[32m0.03492[0m[0m | time: 164.143s
[2K
| Adam | epoch: 022 | loss: 0.03492 - acc: 0.9902 -- iter: 0416/2163
[A[ATraining Step: 1442  | total loss: [1m[32m0.03498[0m[0m | time: 176.254s
[2K
| Adam | epoch: 022 | loss: 0.03498 - acc: 0.9912 -- iter: 0448/2163
[A[ATraining Step: 1443  | total loss: [1m[32m0.03468[0m[0m | time: 188.533s
[2K
| Adam | epoch: 022 | loss: 0.03468 - acc: 0.9921 -- iter: 0480/2163
[A[ATraining Step: 1444  | total loss: [1m[32m0.03315[0m[0m | time: 200.892s
[2K
| Adam | epoch: 022 | loss: 0.03315 - acc: 0.9929 -- iter: 0512/2163
[A[ATraining Step: 1445  | total loss: [1m[32m0.03101[0m[0m | time: 213.755s
[2K
| Adam | epoch: 022 | loss: 0.03101 - acc: 0.9936 -- iter: 0544/2163
[A[ATraining Step: 1446  | total loss: [1m[32m0.03329[0m[0m | time: 226.385s
[2K
| Adam | epoch: 022 | loss: 0.03329 - acc: 0.9911 -- iter: 0576/2163
[A[ATraining Step: 1447  | total loss: [1m[32m0.03590[0m[0m | time: 238.699s
[2K
| Adam | epoch: 022 | loss: 0.03590 - acc: 0.9889 -- iter: 0608/2163
[A[ATraining Step: 1448  | total loss: [1m[32m0.03446[0m[0m | time: 246.991s
[2K
| Adam | epoch: 022 | loss: 0.03446 - acc: 0.9900 -- iter: 0640/2163
[A[ATraining Step: 1449  | total loss: [1m[32m0.03554[0m[0m | time: 255.376s
[2K
| Adam | epoch: 022 | loss: 0.03554 - acc: 0.9910 -- iter: 0672/2163
[A[ATraining Step: 1450  | total loss: [1m[32m0.03351[0m[0m | time: 268.090s
[2K
| Adam | epoch: 022 | loss: 0.03351 - acc: 0.9919 -- iter: 0704/2163
[A[ATraining Step: 1451  | total loss: [1m[32m0.03226[0m[0m | time: 280.408s
[2K
| Adam | epoch: 022 | loss: 0.03226 - acc: 0.9927 -- iter: 0736/2163
[A[ATraining Step: 1452  | total loss: [1m[32m0.02984[0m[0m | time: 292.805s
[2K
| Adam | epoch: 022 | loss: 0.02984 - acc: 0.9934 -- iter: 0768/2163
[A[ATraining Step: 1453  | total loss: [1m[32m0.02997[0m[0m | time: 304.976s
[2K
| Adam | epoch: 022 | loss: 0.02997 - acc: 0.9941 -- iter: 0800/2163
[A[ATraining Step: 1454  | total loss: [1m[32m0.02705[0m[0m | time: 317.118s
[2K
| Adam | epoch: 022 | loss: 0.02705 - acc: 0.9947 -- iter: 0832/2163
[A[ATraining Step: 1455  | total loss: [1m[32m0.02675[0m[0m | time: 329.553s
[2K
| Adam | epoch: 022 | loss: 0.02675 - acc: 0.9952 -- iter: 0864/2163
[A[ATraining Step: 1456  | total loss: [1m[32m0.02415[0m[0m | time: 341.700s
[2K
| Adam | epoch: 022 | loss: 0.02415 - acc: 0.9957 -- iter: 0896/2163
[A[ATraining Step: 1457  | total loss: [1m[32m0.02195[0m[0m | time: 354.187s
[2K
| Adam | epoch: 022 | loss: 0.02195 - acc: 0.9961 -- iter: 0928/2163
[A[ATraining Step: 1458  | total loss: [1m[32m0.02012[0m[0m | time: 366.435s
[2K
| Adam | epoch: 022 | loss: 0.02012 - acc: 0.9965 -- iter: 0960/2163
[A[ATraining Step: 1459  | total loss: [1m[32m0.01830[0m[0m | time: 378.902s
[2K
| Adam | epoch: 022 | loss: 0.01830 - acc: 0.9969 -- iter: 0992/2163
[A[ATraining Step: 1460  | total loss: [1m[32m0.01676[0m[0m | time: 390.989s
[2K
| Adam | epoch: 022 | loss: 0.01676 - acc: 0.9972 -- iter: 1024/2163
[A[ATraining Step: 1461  | total loss: [1m[32m0.01523[0m[0m | time: 403.384s
[2K
| Adam | epoch: 022 | loss: 0.01523 - acc: 0.9975 -- iter: 1056/2163
[A[ATraining Step: 1462  | total loss: [1m[32m0.01444[0m[0m | time: 415.791s
[2K
| Adam | epoch: 022 | loss: 0.01444 - acc: 0.9977 -- iter: 1088/2163
[A[ATraining Step: 1463  | total loss: [1m[32m0.01363[0m[0m | time: 428.704s
[2K
| Adam | epoch: 022 | loss: 0.01363 - acc: 0.9979 -- iter: 1120/2163
[A[ATraining Step: 1464  | total loss: [1m[32m0.01448[0m[0m | time: 441.470s
[2K
| Adam | epoch: 022 | loss: 0.01448 - acc: 0.9981 -- iter: 1152/2163
[A[ATraining Step: 1465  | total loss: [1m[32m0.01425[0m[0m | time: 453.877s
[2K
| Adam | epoch: 022 | loss: 0.01425 - acc: 0.9983 -- iter: 1184/2163
[A[ATraining Step: 1466  | total loss: [1m[32m0.01664[0m[0m | time: 466.672s
[2K
| Adam | epoch: 022 | loss: 0.01664 - acc: 0.9985 -- iter: 1216/2163
[A[ATraining Step: 1467  | total loss: [1m[32m0.01687[0m[0m | time: 479.359s
[2K
| Adam | epoch: 022 | loss: 0.01687 - acc: 0.9986 -- iter: 1248/2163
[A[ATraining Step: 1468  | total loss: [1m[32m0.01961[0m[0m | time: 491.792s
[2K
| Adam | epoch: 022 | loss: 0.01961 - acc: 0.9988 -- iter: 1280/2163
[A[ATraining Step: 1469  | total loss: [1m[32m0.01835[0m[0m | time: 504.530s
[2K
| Adam | epoch: 022 | loss: 0.01835 - acc: 0.9989 -- iter: 1312/2163
[A[ATraining Step: 1470  | total loss: [1m[32m0.01659[0m[0m | time: 516.986s
[2K
| Adam | epoch: 022 | loss: 0.01659 - acc: 0.9990 -- iter: 1344/2163
[A[ATraining Step: 1471  | total loss: [1m[32m0.01669[0m[0m | time: 530.204s
[2K
| Adam | epoch: 022 | loss: 0.01669 - acc: 0.9991 -- iter: 1376/2163
[A[ATraining Step: 1472  | total loss: [1m[32m0.01509[0m[0m | time: 542.652s
[2K
| Adam | epoch: 022 | loss: 0.01509 - acc: 0.9992 -- iter: 1408/2163
[A[ATraining Step: 1473  | total loss: [1m[32m0.01369[0m[0m | time: 555.217s
[2K
| Adam | epoch: 022 | loss: 0.01369 - acc: 0.9993 -- iter: 1440/2163
[A[ATraining Step: 1474  | total loss: [1m[32m0.01291[0m[0m | time: 567.866s
[2K
| Adam | epoch: 022 | loss: 0.01291 - acc: 0.9994 -- iter: 1472/2163
[A[ATraining Step: 1475  | total loss: [1m[32m0.01166[0m[0m | time: 580.342s
[2K
| Adam | epoch: 022 | loss: 0.01166 - acc: 0.9994 -- iter: 1504/2163
[A[ATraining Step: 1476  | total loss: [1m[32m0.01053[0m[0m | time: 592.805s
[2K
| Adam | epoch: 022 | loss: 0.01053 - acc: 0.9995 -- iter: 1536/2163
[A[ATraining Step: 1477  | total loss: [1m[32m0.00982[0m[0m | time: 605.351s
[2K
| Adam | epoch: 022 | loss: 0.00982 - acc: 0.9995 -- iter: 1568/2163
[A[ATraining Step: 1478  | total loss: [1m[32m0.00936[0m[0m | time: 617.673s
[2K
| Adam | epoch: 022 | loss: 0.00936 - acc: 0.9996 -- iter: 1600/2163
[A[ATraining Step: 1479  | total loss: [1m[32m0.00853[0m[0m | time: 629.895s
[2K
| Adam | epoch: 022 | loss: 0.00853 - acc: 0.9996 -- iter: 1632/2163
[A[ATraining Step: 1480  | total loss: [1m[32m0.00773[0m[0m | time: 642.132s
[2K
| Adam | epoch: 022 | loss: 0.00773 - acc: 0.9997 -- iter: 1664/2163
[A[ATraining Step: 1481  | total loss: [1m[32m0.00785[0m[0m | time: 654.886s
[2K
| Adam | epoch: 022 | loss: 0.00785 - acc: 0.9997 -- iter: 1696/2163
[A[ATraining Step: 1482  | total loss: [1m[32m0.01004[0m[0m | time: 667.142s
[2K
| Adam | epoch: 022 | loss: 0.01004 - acc: 0.9997 -- iter: 1728/2163
[A[ATraining Step: 1483  | total loss: [1m[32m0.00942[0m[0m | time: 679.650s
[2K
| Adam | epoch: 022 | loss: 0.00942 - acc: 0.9997 -- iter: 1760/2163
[A[ATraining Step: 1484  | total loss: [1m[32m0.00864[0m[0m | time: 691.980s
[2K
| Adam | epoch: 022 | loss: 0.00864 - acc: 0.9998 -- iter: 1792/2163
[A[ATraining Step: 1485  | total loss: [1m[32m0.00839[0m[0m | time: 704.519s
[2K
| Adam | epoch: 022 | loss: 0.00839 - acc: 0.9998 -- iter: 1824/2163
[A[ATraining Step: 1486  | total loss: [1m[32m0.01024[0m[0m | time: 716.933s
[2K
| Adam | epoch: 022 | loss: 0.01024 - acc: 0.9967 -- iter: 1856/2163
[A[ATraining Step: 1487  | total loss: [1m[32m0.00957[0m[0m | time: 729.217s
[2K
| Adam | epoch: 022 | loss: 0.00957 - acc: 0.9970 -- iter: 1888/2163
[A[ATraining Step: 1488  | total loss: [1m[32m0.00868[0m[0m | time: 741.597s
[2K
| Adam | epoch: 022 | loss: 0.00868 - acc: 0.9973 -- iter: 1920/2163
[A[ATraining Step: 1489  | total loss: [1m[32m0.00786[0m[0m | time: 753.857s
[2K
| Adam | epoch: 022 | loss: 0.00786 - acc: 0.9976 -- iter: 1952/2163
[A[ATraining Step: 1490  | total loss: [1m[32m0.00713[0m[0m | time: 766.110s
[2K
| Adam | epoch: 022 | loss: 0.00713 - acc: 0.9978 -- iter: 1984/2163
[A[ATraining Step: 1491  | total loss: [1m[32m0.00651[0m[0m | time: 778.810s
[2K
| Adam | epoch: 022 | loss: 0.00651 - acc: 0.9980 -- iter: 2016/2163
[A[ATraining Step: 1492  | total loss: [1m[32m0.00588[0m[0m | time: 791.494s
[2K
| Adam | epoch: 022 | loss: 0.00588 - acc: 0.9982 -- iter: 2048/2163
[A[ATraining Step: 1493  | total loss: [1m[32m0.00539[0m[0m | time: 804.273s
[2K
| Adam | epoch: 022 | loss: 0.00539 - acc: 0.9984 -- iter: 2080/2163
[A[ATraining Step: 1494  | total loss: [1m[32m0.00495[0m[0m | time: 816.560s
[2K
| Adam | epoch: 022 | loss: 0.00495 - acc: 0.9986 -- iter: 2112/2163
[A[ATraining Step: 1495  | total loss: [1m[32m0.00449[0m[0m | time: 828.730s
[2K
| Adam | epoch: 022 | loss: 0.00449 - acc: 0.9987 -- iter: 2144/2163
[A[ATraining Step: 1496  | total loss: [1m[32m0.02228[0m[0m | time: 890.726s
[2K
| Adam | epoch: 022 | loss: 0.02228 - acc: 0.9895 | val_loss: 0.46428 - val_acc: 0.8848 -- iter: 2163/2163
--
Training Step: 1497  | total loss: [1m[32m0.02010[0m[0m | time: 13.468s
[2K
| Adam | epoch: 023 | loss: 0.02010 - acc: 0.9905 -- iter: 0032/2163
[A[ATraining Step: 1498  | total loss: [1m[32m0.01812[0m[0m | time: 27.404s
[2K
| Adam | epoch: 023 | loss: 0.01812 - acc: 0.9915 -- iter: 0064/2163
[A[ATraining Step: 1499  | total loss: [1m[32m0.01634[0m[0m | time: 40.740s
[2K
| Adam | epoch: 023 | loss: 0.01634 - acc: 0.9923 -- iter: 0096/2163
[A[ATraining Step: 1500  | total loss: [1m[32m0.01516[0m[0m | time: 54.275s
[2K
| Adam | epoch: 023 | loss: 0.01516 - acc: 0.9931 -- iter: 0128/2163
[A[ATraining Step: 1501  | total loss: [1m[32m0.01384[0m[0m | time: 68.003s
[2K
| Adam | epoch: 023 | loss: 0.01384 - acc: 0.9938 -- iter: 0160/2163
[A[ATraining Step: 1502  | total loss: [1m[32m0.01288[0m[0m | time: 76.668s
[2K
| Adam | epoch: 023 | loss: 0.01288 - acc: 0.9944 -- iter: 0192/2163
[A[ATraining Step: 1503  | total loss: [1m[32m0.02060[0m[0m | time: 84.363s
[2K
| Adam | epoch: 023 | loss: 0.02060 - acc: 0.9918 -- iter: 0224/2163
[A[ATraining Step: 1504  | total loss: [1m[32m0.02082[0m[0m | time: 92.122s
[2K
| Adam | epoch: 023 | loss: 0.02082 - acc: 0.9927 -- iter: 0256/2163
[A[ATraining Step: 1505  | total loss: [1m[32m0.01986[0m[0m | time: 99.781s
[2K
| Adam | epoch: 023 | loss: 0.01986 - acc: 0.9934 -- iter: 0288/2163
[A[ATraining Step: 1506  | total loss: [1m[32m0.01811[0m[0m | time: 109.246s
[2K
| Adam | epoch: 023 | loss: 0.01811 - acc: 0.9941 -- iter: 0320/2163
[A[ATraining Step: 1507  | total loss: [1m[32m0.01679[0m[0m | time: 121.570s
[2K
| Adam | epoch: 023 | loss: 0.01679 - acc: 0.9946 -- iter: 0352/2163
[A[ATraining Step: 1508  | total loss: [1m[32m0.01518[0m[0m | time: 133.986s
[2K
| Adam | epoch: 023 | loss: 0.01518 - acc: 0.9952 -- iter: 0384/2163
[A[ATraining Step: 1509  | total loss: [1m[32m0.01413[0m[0m | time: 146.467s
[2K
| Adam | epoch: 023 | loss: 0.01413 - acc: 0.9957 -- iter: 0416/2163
[A[ATraining Step: 1510  | total loss: [1m[32m0.01305[0m[0m | time: 158.754s
[2K
| Adam | epoch: 023 | loss: 0.01305 - acc: 0.9961 -- iter: 0448/2163
[A[ATraining Step: 1511  | total loss: [1m[32m0.01214[0m[0m | time: 171.361s
[2K
| Adam | epoch: 023 | loss: 0.01214 - acc: 0.9965 -- iter: 0480/2163
[A[ATraining Step: 1512  | total loss: [1m[32m0.01098[0m[0m | time: 183.182s
[2K
| Adam | epoch: 023 | loss: 0.01098 - acc: 0.9968 -- iter: 0512/2163
[A[ATraining Step: 1513  | total loss: [1m[32m0.01030[0m[0m | time: 195.433s
[2K
| Adam | epoch: 023 | loss: 0.01030 - acc: 0.9972 -- iter: 0544/2163
[A[ATraining Step: 1514  | total loss: [1m[32m0.00938[0m[0m | time: 207.949s
[2K
| Adam | epoch: 023 | loss: 0.00938 - acc: 0.9974 -- iter: 0576/2163
[A[ATraining Step: 1515  | total loss: [1m[32m0.00921[0m[0m | time: 220.605s
[2K
| Adam | epoch: 023 | loss: 0.00921 - acc: 0.9977 -- iter: 0608/2163
[A[ATraining Step: 1516  | total loss: [1m[32m0.00847[0m[0m | time: 233.057s
[2K
| Adam | epoch: 023 | loss: 0.00847 - acc: 0.9979 -- iter: 0640/2163
[A[ATraining Step: 1517  | total loss: [1m[32m0.01686[0m[0m | time: 241.304s
[2K
| Adam | epoch: 023 | loss: 0.01686 - acc: 0.9919 -- iter: 0672/2163
[A[ATraining Step: 1518  | total loss: [1m[32m0.01531[0m[0m | time: 249.733s
[2K
| Adam | epoch: 023 | loss: 0.01531 - acc: 0.9927 -- iter: 0704/2163
[A[ATraining Step: 1519  | total loss: [1m[32m0.01411[0m[0m | time: 261.950s
[2K
| Adam | epoch: 023 | loss: 0.01411 - acc: 0.9934 -- iter: 0736/2163
[A[ATraining Step: 1520  | total loss: [1m[32m0.01285[0m[0m | time: 274.285s
[2K
| Adam | epoch: 023 | loss: 0.01285 - acc: 0.9941 -- iter: 0768/2163
[A[ATraining Step: 1521  | total loss: [1m[32m0.01168[0m[0m | time: 286.731s
[2K
| Adam | epoch: 023 | loss: 0.01168 - acc: 0.9947 -- iter: 0800/2163
[A[ATraining Step: 1522  | total loss: [1m[32m0.01248[0m[0m | time: 299.366s
[2K
| Adam | epoch: 023 | loss: 0.01248 - acc: 0.9952 -- iter: 0832/2163
[A[ATraining Step: 1523  | total loss: [1m[32m0.01171[0m[0m | time: 312.027s
[2K
| Adam | epoch: 023 | loss: 0.01171 - acc: 0.9957 -- iter: 0864/2163
[A[ATraining Step: 1524  | total loss: [1m[32m0.01084[0m[0m | time: 324.602s
[2K
| Adam | epoch: 023 | loss: 0.01084 - acc: 0.9961 -- iter: 0896/2163
[A[ATraining Step: 1525  | total loss: [1m[32m0.01001[0m[0m | time: 336.966s
[2K
| Adam | epoch: 023 | loss: 0.01001 - acc: 0.9965 -- iter: 0928/2163
[A[ATraining Step: 1526  | total loss: [1m[32m0.00910[0m[0m | time: 349.671s
[2K
| Adam | epoch: 023 | loss: 0.00910 - acc: 0.9969 -- iter: 0960/2163
[A[ATraining Step: 1527  | total loss: [1m[32m0.01058[0m[0m | time: 362.348s
[2K
| Adam | epoch: 023 | loss: 0.01058 - acc: 0.9972 -- iter: 0992/2163
[A[ATraining Step: 1528  | total loss: [1m[32m0.00957[0m[0m | time: 375.051s
[2K
| Adam | epoch: 023 | loss: 0.00957 - acc: 0.9975 -- iter: 1024/2163
[A[ATraining Step: 1529  | total loss: [1m[32m0.02377[0m[0m | time: 387.652s
[2K
| Adam | epoch: 023 | loss: 0.02377 - acc: 0.9946 -- iter: 1056/2163
[A[ATraining Step: 1530  | total loss: [1m[32m0.02142[0m[0m | time: 400.119s
[2K
| Adam | epoch: 023 | loss: 0.02142 - acc: 0.9951 -- iter: 1088/2163
[A[ATraining Step: 1531  | total loss: [1m[32m0.01934[0m[0m | time: 413.083s
[2K
| Adam | epoch: 023 | loss: 0.01934 - acc: 0.9956 -- iter: 1120/2163
[A[ATraining Step: 1532  | total loss: [1m[32m0.01752[0m[0m | time: 425.773s
[2K
| Adam | epoch: 023 | loss: 0.01752 - acc: 0.9961 -- iter: 1152/2163
[A[ATraining Step: 1533  | total loss: [1m[32m0.01585[0m[0m | time: 438.393s
[2K
| Adam | epoch: 023 | loss: 0.01585 - acc: 0.9964 -- iter: 1184/2163
[A[ATraining Step: 1534  | total loss: [1m[32m0.01437[0m[0m | time: 451.044s
[2K
| Adam | epoch: 023 | loss: 0.01437 - acc: 0.9968 -- iter: 1216/2163
[A[ATraining Step: 1535  | total loss: [1m[32m0.01500[0m[0m | time: 463.609s
[2K
| Adam | epoch: 023 | loss: 0.01500 - acc: 0.9971 -- iter: 1248/2163
[A[ATraining Step: 1536  | total loss: [1m[32m0.01362[0m[0m | time: 475.987s
[2K
| Adam | epoch: 023 | loss: 0.01362 - acc: 0.9974 -- iter: 1280/2163
[A[ATraining Step: 1537  | total loss: [1m[32m0.01233[0m[0m | time: 488.122s
[2K
| Adam | epoch: 023 | loss: 0.01233 - acc: 0.9977 -- iter: 1312/2163
[A[ATraining Step: 1538  | total loss: [1m[32m0.01117[0m[0m | time: 500.447s
[2K
| Adam | epoch: 023 | loss: 0.01117 - acc: 0.9979 -- iter: 1344/2163
[A[ATraining Step: 1539  | total loss: [1m[32m0.01012[0m[0m | time: 512.768s
[2K
| Adam | epoch: 023 | loss: 0.01012 - acc: 0.9981 -- iter: 1376/2163
[A[ATraining Step: 1540  | total loss: [1m[32m0.00952[0m[0m | time: 525.341s
[2K
| Adam | epoch: 023 | loss: 0.00952 - acc: 0.9983 -- iter: 1408/2163
[A[ATraining Step: 1541  | total loss: [1m[32m0.00876[0m[0m | time: 537.650s
[2K
| Adam | epoch: 023 | loss: 0.00876 - acc: 0.9985 -- iter: 1440/2163
[A[ATraining Step: 1542  | total loss: [1m[32m0.01017[0m[0m | time: 550.269s
[2K
| Adam | epoch: 023 | loss: 0.01017 - acc: 0.9986 -- iter: 1472/2163
[A[ATraining Step: 1543  | total loss: [1m[32m0.00977[0m[0m | time: 562.625s
[2K
| Adam | epoch: 023 | loss: 0.00977 - acc: 0.9988 -- iter: 1504/2163
[A[ATraining Step: 1544  | total loss: [1m[32m0.01729[0m[0m | time: 575.154s
[2K
| Adam | epoch: 023 | loss: 0.01729 - acc: 0.9958 -- iter: 1536/2163
[A[ATraining Step: 1545  | total loss: [1m[32m0.01573[0m[0m | time: 587.542s
[2K
| Adam | epoch: 023 | loss: 0.01573 - acc: 0.9962 -- iter: 1568/2163
[A[ATraining Step: 1546  | total loss: [1m[32m0.01424[0m[0m | time: 599.925s
[2K
| Adam | epoch: 023 | loss: 0.01424 - acc: 0.9966 -- iter: 1600/2163
[A[ATraining Step: 1547  | total loss: [1m[32m0.01289[0m[0m | time: 612.749s
[2K
| Adam | epoch: 023 | loss: 0.01289 - acc: 0.9969 -- iter: 1632/2163
[A[ATraining Step: 1548  | total loss: [1m[32m0.01214[0m[0m | time: 625.566s
[2K
| Adam | epoch: 023 | loss: 0.01214 - acc: 0.9972 -- iter: 1664/2163
[A[ATraining Step: 1549  | total loss: [1m[32m0.01095[0m[0m | time: 638.177s
[2K
| Adam | epoch: 023 | loss: 0.01095 - acc: 0.9975 -- iter: 1696/2163
[A[ATraining Step: 1550  | total loss: [1m[32m0.01006[0m[0m | time: 650.742s
[2K
| Adam | epoch: 023 | loss: 0.01006 - acc: 0.9977 -- iter: 1728/2163
[A[ATraining Step: 1551  | total loss: [1m[32m0.01126[0m[0m | time: 663.151s
[2K
| Adam | epoch: 023 | loss: 0.01126 - acc: 0.9980 -- iter: 1760/2163
[A[ATraining Step: 1552  | total loss: [1m[32m0.01018[0m[0m | time: 675.906s
[2K
| Adam | epoch: 023 | loss: 0.01018 - acc: 0.9982 -- iter: 1792/2163
[A[ATraining Step: 1553  | total loss: [1m[32m0.00944[0m[0m | time: 688.817s
[2K
| Adam | epoch: 023 | loss: 0.00944 - acc: 0.9984 -- iter: 1824/2163
[A[ATraining Step: 1554  | total loss: [1m[32m0.00862[0m[0m | time: 701.325s
[2K
| Adam | epoch: 023 | loss: 0.00862 - acc: 0.9985 -- iter: 1856/2163
[A[ATraining Step: 1555  | total loss: [1m[32m0.03506[0m[0m | time: 714.253s
[2K
| Adam | epoch: 023 | loss: 0.03506 - acc: 0.9955 -- iter: 1888/2163
[A[ATraining Step: 1556  | total loss: [1m[32m0.03181[0m[0m | time: 726.095s
[2K
| Adam | epoch: 023 | loss: 0.03181 - acc: 0.9960 -- iter: 1920/2163
[A[ATraining Step: 1557  | total loss: [1m[32m0.02881[0m[0m | time: 738.461s
[2K
| Adam | epoch: 023 | loss: 0.02881 - acc: 0.9964 -- iter: 1952/2163
[A[ATraining Step: 1558  | total loss: [1m[32m0.02612[0m[0m | time: 750.729s
[2K
| Adam | epoch: 023 | loss: 0.02612 - acc: 0.9968 -- iter: 1984/2163
[A[ATraining Step: 1559  | total loss: [1m[32m0.02536[0m[0m | time: 763.479s
[2K
| Adam | epoch: 023 | loss: 0.02536 - acc: 0.9971 -- iter: 2016/2163
[A[ATraining Step: 1560  | total loss: [1m[32m0.02429[0m[0m | time: 775.917s
[2K
| Adam | epoch: 023 | loss: 0.02429 - acc: 0.9974 -- iter: 2048/2163
[A[ATraining Step: 1561  | total loss: [1m[32m0.02192[0m[0m | time: 788.331s
[2K
| Adam | epoch: 023 | loss: 0.02192 - acc: 0.9976 -- iter: 2080/2163
[A[ATraining Step: 1562  | total loss: [1m[32m0.01992[0m[0m | time: 801.051s
[2K
| Adam | epoch: 023 | loss: 0.01992 - acc: 0.9979 -- iter: 2112/2163
[A[ATraining Step: 1563  | total loss: [1m[32m0.01902[0m[0m | time: 813.332s
[2K
| Adam | epoch: 023 | loss: 0.01902 - acc: 0.9981 -- iter: 2144/2163
[A[ATraining Step: 1564  | total loss: [1m[32m0.01770[0m[0m | time: 875.453s
[2K
| Adam | epoch: 023 | loss: 0.01770 - acc: 0.9983 | val_loss: 0.31757 - val_acc: 0.9202 -- iter: 2163/2163
--
Training Step: 1565  | total loss: [1m[32m0.01617[0m[0m | time: 13.092s
[2K
| Adam | epoch: 024 | loss: 0.01617 - acc: 0.9984 -- iter: 0032/2163
[A[ATraining Step: 1566  | total loss: [1m[32m0.01467[0m[0m | time: 25.460s
[2K
| Adam | epoch: 024 | loss: 0.01467 - acc: 0.9986 -- iter: 0064/2163
[A[ATraining Step: 1567  | total loss: [1m[32m0.04286[0m[0m | time: 38.045s
[2K
| Adam | epoch: 024 | loss: 0.04286 - acc: 0.9925 -- iter: 0096/2163
[A[ATraining Step: 1568  | total loss: [1m[32m0.04306[0m[0m | time: 50.278s
[2K
| Adam | epoch: 024 | loss: 0.04306 - acc: 0.9901 -- iter: 0128/2163
[A[ATraining Step: 1569  | total loss: [1m[32m0.03902[0m[0m | time: 62.924s
[2K
| Adam | epoch: 024 | loss: 0.03902 - acc: 0.9911 -- iter: 0160/2163
[A[ATraining Step: 1570  | total loss: [1m[32m0.03544[0m[0m | time: 75.240s
[2K
| Adam | epoch: 024 | loss: 0.03544 - acc: 0.9920 -- iter: 0192/2163
[A[ATraining Step: 1571  | total loss: [1m[32m0.03237[0m[0m | time: 87.719s
[2K
| Adam | epoch: 024 | loss: 0.03237 - acc: 0.9928 -- iter: 0224/2163
[A[ATraining Step: 1572  | total loss: [1m[32m0.02921[0m[0m | time: 100.150s
[2K
| Adam | epoch: 024 | loss: 0.02921 - acc: 0.9935 -- iter: 0256/2163
[A[ATraining Step: 1573  | total loss: [1m[32m0.02652[0m[0m | time: 112.668s
[2K
| Adam | epoch: 024 | loss: 0.02652 - acc: 0.9942 -- iter: 0288/2163
[A[ATraining Step: 1574  | total loss: [1m[32m0.02415[0m[0m | time: 125.458s
[2K
| Adam | epoch: 024 | loss: 0.02415 - acc: 0.9947 -- iter: 0320/2163
[A[ATraining Step: 1575  | total loss: [1m[32m0.02210[0m[0m | time: 138.441s
[2K
| Adam | epoch: 024 | loss: 0.02210 - acc: 0.9953 -- iter: 0352/2163
[A[ATraining Step: 1576  | total loss: [1m[32m0.01993[0m[0m | time: 150.875s
[2K
| Adam | epoch: 024 | loss: 0.01993 - acc: 0.9957 -- iter: 0384/2163
[A[ATraining Step: 1577  | total loss: [1m[32m0.01848[0m[0m | time: 164.611s
[2K
| Adam | epoch: 024 | loss: 0.01848 - acc: 0.9962 -- iter: 0416/2163
[A[ATraining Step: 1578  | total loss: [1m[32m0.01759[0m[0m | time: 177.931s
[2K
| Adam | epoch: 024 | loss: 0.01759 - acc: 0.9966 -- iter: 0448/2163
[A[ATraining Step: 1579  | total loss: [1m[32m0.01616[0m[0m | time: 191.438s
[2K
| Adam | epoch: 024 | loss: 0.01616 - acc: 0.9969 -- iter: 0480/2163
[A[ATraining Step: 1580  | total loss: [1m[32m0.01481[0m[0m | time: 204.944s
[2K
| Adam | epoch: 024 | loss: 0.01481 - acc: 0.9972 -- iter: 0512/2163
[A[ATraining Step: 1581  | total loss: [1m[32m0.01824[0m[0m | time: 218.904s
[2K
| Adam | epoch: 024 | loss: 0.01824 - acc: 0.9944 -- iter: 0544/2163
[A[ATraining Step: 1582  | total loss: [1m[32m0.02153[0m[0m | time: 232.254s
[2K
| Adam | epoch: 024 | loss: 0.02153 - acc: 0.9918 -- iter: 0576/2163
[A[ATraining Step: 1583  | total loss: [1m[32m0.02034[0m[0m | time: 243.983s
[2K
| Adam | epoch: 024 | loss: 0.02034 - acc: 0.9926 -- iter: 0608/2163
[A[ATraining Step: 1584  | total loss: [1m[32m0.02035[0m[0m | time: 251.739s
[2K
| Adam | epoch: 024 | loss: 0.02035 - acc: 0.9934 -- iter: 0640/2163
[A[ATraining Step: 1585  | total loss: [1m[32m0.01888[0m[0m | time: 264.098s
[2K
| Adam | epoch: 024 | loss: 0.01888 - acc: 0.9940 -- iter: 0672/2163
[A[ATraining Step: 1586  | total loss: [1m[32m0.01774[0m[0m | time: 272.676s
[2K
| Adam | epoch: 024 | loss: 0.01774 - acc: 0.9946 -- iter: 0704/2163
[A[ATraining Step: 1587  | total loss: [1m[32m0.01604[0m[0m | time: 281.219s
[2K
| Adam | epoch: 024 | loss: 0.01604 - acc: 0.9952 -- iter: 0736/2163
[A[ATraining Step: 1588  | total loss: [1m[32m0.01450[0m[0m | time: 293.601s
[2K
| Adam | epoch: 024 | loss: 0.01450 - acc: 0.9956 -- iter: 0768/2163
[A[ATraining Step: 1589  | total loss: [1m[32m0.01341[0m[0m | time: 306.078s
[2K
| Adam | epoch: 024 | loss: 0.01341 - acc: 0.9961 -- iter: 0800/2163
[A[ATraining Step: 1590  | total loss: [1m[32m0.01284[0m[0m | time: 318.057s
[2K
| Adam | epoch: 024 | loss: 0.01284 - acc: 0.9965 -- iter: 0832/2163
[A[ATraining Step: 1591  | total loss: [1m[32m0.01166[0m[0m | time: 330.059s
[2K
| Adam | epoch: 024 | loss: 0.01166 - acc: 0.9968 -- iter: 0864/2163
[A[ATraining Step: 1592  | total loss: [1m[32m0.01064[0m[0m | time: 342.015s
[2K
| Adam | epoch: 024 | loss: 0.01064 - acc: 0.9971 -- iter: 0896/2163
[A[ATraining Step: 1593  | total loss: [1m[32m0.00971[0m[0m | time: 354.109s
[2K
| Adam | epoch: 024 | loss: 0.00971 - acc: 0.9974 -- iter: 0928/2163
[A[ATraining Step: 1594  | total loss: [1m[32m0.00888[0m[0m | time: 366.448s
[2K
| Adam | epoch: 024 | loss: 0.00888 - acc: 0.9977 -- iter: 0960/2163
[A[ATraining Step: 1595  | total loss: [1m[32m0.00880[0m[0m | time: 379.085s
[2K
| Adam | epoch: 024 | loss: 0.00880 - acc: 0.9979 -- iter: 0992/2163
[A[ATraining Step: 1596  | total loss: [1m[32m0.01277[0m[0m | time: 391.532s
[2K
| Adam | epoch: 024 | loss: 0.01277 - acc: 0.9950 -- iter: 1024/2163
[A[ATraining Step: 1597  | total loss: [1m[32m0.01176[0m[0m | time: 404.171s
[2K
| Adam | epoch: 024 | loss: 0.01176 - acc: 0.9955 -- iter: 1056/2163
[A[ATraining Step: 1598  | total loss: [1m[32m0.01250[0m[0m | time: 416.621s
[2K
| Adam | epoch: 024 | loss: 0.01250 - acc: 0.9959 -- iter: 1088/2163
[A[ATraining Step: 1599  | total loss: [1m[32m0.01144[0m[0m | time: 428.865s
[2K
| Adam | epoch: 024 | loss: 0.01144 - acc: 0.9964 -- iter: 1120/2163
[A[ATraining Step: 1600  | total loss: [1m[32m0.01036[0m[0m | time: 491.586s
[2K
| Adam | epoch: 024 | loss: 0.01036 - acc: 0.9967 | val_loss: 0.21336 - val_acc: 0.9542 -- iter: 1152/2163
--
Training Step: 1601  | total loss: [1m[32m0.00939[0m[0m | time: 503.913s
[2K
| Adam | epoch: 024 | loss: 0.00939 - acc: 0.9970 -- iter: 1184/2163
[A[ATraining Step: 1602  | total loss: [1m[32m0.00853[0m[0m | time: 516.415s
[2K
| Adam | epoch: 024 | loss: 0.00853 - acc: 0.9973 -- iter: 1216/2163
[A[ATraining Step: 1603  | total loss: [1m[32m0.00775[0m[0m | time: 529.137s
[2K
| Adam | epoch: 024 | loss: 0.00775 - acc: 0.9976 -- iter: 1248/2163
[A[ATraining Step: 1604  | total loss: [1m[32m0.00701[0m[0m | time: 541.887s
[2K
| Adam | epoch: 024 | loss: 0.00701 - acc: 0.9978 -- iter: 1280/2163
[A[ATraining Step: 1605  | total loss: [1m[32m0.00990[0m[0m | time: 554.641s
[2K
| Adam | epoch: 024 | loss: 0.00990 - acc: 0.9949 -- iter: 1312/2163
[A[ATraining Step: 1606  | total loss: [1m[32m0.00938[0m[0m | time: 566.652s
[2K
| Adam | epoch: 024 | loss: 0.00938 - acc: 0.9954 -- iter: 1344/2163
[A[ATraining Step: 1607  | total loss: [1m[32m0.00855[0m[0m | time: 579.075s
[2K
| Adam | epoch: 024 | loss: 0.00855 - acc: 0.9959 -- iter: 1376/2163
[A[ATraining Step: 1608  | total loss: [1m[32m0.00787[0m[0m | time: 591.370s
[2K
| Adam | epoch: 024 | loss: 0.00787 - acc: 0.9963 -- iter: 1408/2163
[A[ATraining Step: 1609  | total loss: [1m[32m0.00759[0m[0m | time: 604.004s
[2K
| Adam | epoch: 024 | loss: 0.00759 - acc: 0.9967 -- iter: 1440/2163
[A[ATraining Step: 1610  | total loss: [1m[32m0.00700[0m[0m | time: 616.981s
[2K
| Adam | epoch: 024 | loss: 0.00700 - acc: 0.9970 -- iter: 1472/2163
[A[ATraining Step: 1611  | total loss: [1m[32m0.00644[0m[0m | time: 629.717s
[2K
| Adam | epoch: 024 | loss: 0.00644 - acc: 0.9973 -- iter: 1504/2163
[A[ATraining Step: 1612  | total loss: [1m[32m0.00594[0m[0m | time: 642.260s
[2K
| Adam | epoch: 024 | loss: 0.00594 - acc: 0.9976 -- iter: 1536/2163
[A[ATraining Step: 1613  | total loss: [1m[32m0.00580[0m[0m | time: 654.506s
[2K
| Adam | epoch: 024 | loss: 0.00580 - acc: 0.9978 -- iter: 1568/2163
[A[ATraining Step: 1614  | total loss: [1m[32m0.00542[0m[0m | time: 666.961s
[2K
| Adam | epoch: 024 | loss: 0.00542 - acc: 0.9980 -- iter: 1600/2163
[A[ATraining Step: 1615  | total loss: [1m[32m0.00501[0m[0m | time: 679.071s
[2K
| Adam | epoch: 024 | loss: 0.00501 - acc: 0.9982 -- iter: 1632/2163
[A[ATraining Step: 1616  | total loss: [1m[32m0.00455[0m[0m | time: 691.212s
[2K
| Adam | epoch: 024 | loss: 0.00455 - acc: 0.9984 -- iter: 1664/2163
[A[ATraining Step: 1617  | total loss: [1m[32m0.00431[0m[0m | time: 703.440s
[2K
| Adam | epoch: 024 | loss: 0.00431 - acc: 0.9986 -- iter: 1696/2163
[A[ATraining Step: 1618  | total loss: [1m[32m0.00398[0m[0m | time: 715.756s
[2K
| Adam | epoch: 024 | loss: 0.00398 - acc: 0.9987 -- iter: 1728/2163
[A[ATraining Step: 1619  | total loss: [1m[32m0.00388[0m[0m | time: 728.434s
[2K
| Adam | epoch: 024 | loss: 0.00388 - acc: 0.9988 -- iter: 1760/2163
[A[ATraining Step: 1620  | total loss: [1m[32m0.00357[0m[0m | time: 740.924s
[2K
| Adam | epoch: 024 | loss: 0.00357 - acc: 0.9990 -- iter: 1792/2163
[A[ATraining Step: 1621  | total loss: [1m[32m0.00335[0m[0m | time: 752.908s
[2K
| Adam | epoch: 024 | loss: 0.00335 - acc: 0.9991 -- iter: 1824/2163
[A[ATraining Step: 1622  | total loss: [1m[32m0.00313[0m[0m | time: 765.411s
[2K
| Adam | epoch: 024 | loss: 0.00313 - acc: 0.9992 -- iter: 1856/2163
[A[ATraining Step: 1623  | total loss: [1m[32m0.00295[0m[0m | time: 778.009s
[2K
| Adam | epoch: 024 | loss: 0.00295 - acc: 0.9992 -- iter: 1888/2163
[A[ATraining Step: 1624  | total loss: [1m[32m0.02683[0m[0m | time: 790.224s
[2K
| Adam | epoch: 024 | loss: 0.02683 - acc: 0.9962 -- iter: 1920/2163
[A[ATraining Step: 1625  | total loss: [1m[32m0.02444[0m[0m | time: 802.515s
[2K
| Adam | epoch: 024 | loss: 0.02444 - acc: 0.9966 -- iter: 1952/2163
[A[ATraining Step: 1626  | total loss: [1m[32m0.02205[0m[0m | time: 815.149s
[2K
| Adam | epoch: 024 | loss: 0.02205 - acc: 0.9969 -- iter: 1984/2163
[A[ATraining Step: 1627  | total loss: [1m[32m0.01992[0m[0m | time: 827.352s
[2K
| Adam | epoch: 024 | loss: 0.01992 - acc: 0.9972 -- iter: 2016/2163
[A[ATraining Step: 1628  | total loss: [1m[32m0.03685[0m[0m | time: 840.859s
[2K
| Adam | epoch: 024 | loss: 0.03685 - acc: 0.9913 -- iter: 2048/2163
[A[ATraining Step: 1629  | total loss: [1m[32m0.03589[0m[0m | time: 854.533s
[2K
| Adam | epoch: 024 | loss: 0.03589 - acc: 0.9921 -- iter: 2080/2163
[A[ATraining Step: 1630  | total loss: [1m[32m0.03259[0m[0m | time: 868.001s
[2K
| Adam | epoch: 024 | loss: 0.03259 - acc: 0.9929 -- iter: 2112/2163
[A[ATraining Step: 1631  | total loss: [1m[32m0.02947[0m[0m | time: 881.326s
[2K
| Adam | epoch: 024 | loss: 0.02947 - acc: 0.9936 -- iter: 2144/2163
[A[ATraining Step: 1632  | total loss: [1m[32m0.02731[0m[0m | time: 935.759s
[2K
| Adam | epoch: 024 | loss: 0.02731 - acc: 0.9943 | val_loss: 0.22253 - val_acc: 0.9483 -- iter: 2163/2163
--
Training Step: 1633  | total loss: [1m[32m0.03255[0m[0m | time: 39.250s
[2K
| Adam | epoch: 025 | loss: 0.03255 - acc: 0.9917 -- iter: 0032/2163
[A[ATraining Step: 1634  | total loss: [1m[32m0.03398[0m[0m | time: 47.012s
[2K
| Adam | epoch: 025 | loss: 0.03398 - acc: 0.9894 -- iter: 0064/2163
[A[ATraining Step: 1635  | total loss: [1m[32m0.07295[0m[0m | time: 54.813s
[2K
| Adam | epoch: 025 | loss: 0.07295 - acc: 0.9748 -- iter: 0096/2163
[A[ATraining Step: 1636  | total loss: [1m[32m0.06568[0m[0m | time: 62.610s
[2K
| Adam | epoch: 025 | loss: 0.06568 - acc: 0.9774 -- iter: 0128/2163
[A[ATraining Step: 1637  | total loss: [1m[32m0.07271[0m[0m | time: 70.217s
[2K
| Adam | epoch: 025 | loss: 0.07271 - acc: 0.9765 -- iter: 0160/2163
[A[ATraining Step: 1638  | total loss: [1m[32m0.06597[0m[0m | time: 77.995s
[2K
| Adam | epoch: 025 | loss: 0.06597 - acc: 0.9789 -- iter: 0192/2163
[A[ATraining Step: 1639  | total loss: [1m[32m0.05971[0m[0m | time: 85.748s
[2K
| Adam | epoch: 025 | loss: 0.05971 - acc: 0.9810 -- iter: 0224/2163
[A[ATraining Step: 1640  | total loss: [1m[32m0.05603[0m[0m | time: 93.427s
[2K
| Adam | epoch: 025 | loss: 0.05603 - acc: 0.9797 -- iter: 0256/2163
[A[ATraining Step: 1641  | total loss: [1m[32m0.05740[0m[0m | time: 101.237s
[2K
| Adam | epoch: 025 | loss: 0.05740 - acc: 0.9786 -- iter: 0288/2163
[A[ATraining Step: 1642  | total loss: [1m[32m0.05227[0m[0m | time: 108.945s
[2K
| Adam | epoch: 025 | loss: 0.05227 - acc: 0.9808 -- iter: 0320/2163
[A[ATraining Step: 1643  | total loss: [1m[32m0.04911[0m[0m | time: 116.660s
[2K
| Adam | epoch: 025 | loss: 0.04911 - acc: 0.9827 -- iter: 0352/2163
[A[ATraining Step: 1644  | total loss: [1m[32m0.04459[0m[0m | time: 124.360s
[2K
| Adam | epoch: 025 | loss: 0.04459 - acc: 0.9844 -- iter: 0384/2163
[A[ATraining Step: 1645  | total loss: [1m[32m0.04100[0m[0m | time: 132.029s
[2K
| Adam | epoch: 025 | loss: 0.04100 - acc: 0.9860 -- iter: 0416/2163
[A[ATraining Step: 1646  | total loss: [1m[32m0.04068[0m[0m | time: 139.881s
[2K
| Adam | epoch: 025 | loss: 0.04068 - acc: 0.9843 -- iter: 0448/2163
[A[ATraining Step: 1647  | total loss: [1m[32m0.03855[0m[0m | time: 147.680s
[2K
| Adam | epoch: 025 | loss: 0.03855 - acc: 0.9858 -- iter: 0480/2163
[A[ATraining Step: 1648  | total loss: [1m[32m0.03892[0m[0m | time: 155.399s
[2K
| Adam | epoch: 025 | loss: 0.03892 - acc: 0.9841 -- iter: 0512/2163
[A[ATraining Step: 1649  | total loss: [1m[32m0.03752[0m[0m | time: 163.260s
[2K
| Adam | epoch: 025 | loss: 0.03752 - acc: 0.9857 -- iter: 0544/2163
[A[ATraining Step: 1650  | total loss: [1m[32m0.04430[0m[0m | time: 171.133s
[2K
| Adam | epoch: 025 | loss: 0.04430 - acc: 0.9840 -- iter: 0576/2163
[A[ATraining Step: 1651  | total loss: [1m[32m0.03993[0m[0m | time: 178.869s
[2K
| Adam | epoch: 025 | loss: 0.03993 - acc: 0.9856 -- iter: 0608/2163
[A[ATraining Step: 1652  | total loss: [1m[32m0.04846[0m[0m | time: 186.612s
[2K
| Adam | epoch: 025 | loss: 0.04846 - acc: 0.9839 -- iter: 0640/2163
[A[ATraining Step: 1653  | total loss: [1m[32m0.04385[0m[0m | time: 194.355s
[2K
| Adam | epoch: 025 | loss: 0.04385 - acc: 0.9855 -- iter: 0672/2163
[A[ATraining Step: 1654  | total loss: [1m[32m0.04797[0m[0m | time: 202.004s
[2K
| Adam | epoch: 025 | loss: 0.04797 - acc: 0.9839 -- iter: 0704/2163
[A[ATraining Step: 1655  | total loss: [1m[32m0.05118[0m[0m | time: 207.117s
[2K
| Adam | epoch: 025 | loss: 0.05118 - acc: 0.9823 -- iter: 0736/2163
[A[ATraining Step: 1656  | total loss: [1m[32m0.05778[0m[0m | time: 212.347s
[2K
| Adam | epoch: 025 | loss: 0.05778 - acc: 0.9736 -- iter: 0768/2163
[A[ATraining Step: 1657  | total loss: [1m[32m0.05350[0m[0m | time: 220.142s
[2K
| Adam | epoch: 025 | loss: 0.05350 - acc: 0.9762 -- iter: 0800/2163
[A[ATraining Step: 1658  | total loss: [1m[32m0.04864[0m[0m | time: 227.957s
[2K
| Adam | epoch: 025 | loss: 0.04864 - acc: 0.9786 -- iter: 0832/2163
[A[ATraining Step: 1659  | total loss: [1m[32m0.04468[0m[0m | time: 235.707s
[2K
| Adam | epoch: 025 | loss: 0.04468 - acc: 0.9807 -- iter: 0864/2163
[A[ATraining Step: 1660  | total loss: [1m[32m0.04243[0m[0m | time: 243.483s
[2K
| Adam | epoch: 025 | loss: 0.04243 - acc: 0.9827 -- iter: 0896/2163
[A[ATraining Step: 1661  | total loss: [1m[32m0.04377[0m[0m | time: 251.088s
[2K
| Adam | epoch: 025 | loss: 0.04377 - acc: 0.9813 -- iter: 0928/2163
[A[ATraining Step: 1662  | total loss: [1m[32m0.04152[0m[0m | time: 258.932s
[2K
| Adam | epoch: 025 | loss: 0.04152 - acc: 0.9832 -- iter: 0960/2163
[A[ATraining Step: 1663  | total loss: [1m[32m0.03784[0m[0m | time: 266.772s
[2K
| Adam | epoch: 025 | loss: 0.03784 - acc: 0.9848 -- iter: 0992/2163
[A[ATraining Step: 1664  | total loss: [1m[32m0.03500[0m[0m | time: 274.497s
[2K
| Adam | epoch: 025 | loss: 0.03500 - acc: 0.9864 -- iter: 1024/2163
[A[ATraining Step: 1665  | total loss: [1m[32m0.03171[0m[0m | time: 282.231s
[2K
| Adam | epoch: 025 | loss: 0.03171 - acc: 0.9877 -- iter: 1056/2163
[A[ATraining Step: 1666  | total loss: [1m[32m0.03127[0m[0m | time: 289.701s
[2K
| Adam | epoch: 025 | loss: 0.03127 - acc: 0.9858 -- iter: 1088/2163
[A[ATraining Step: 1667  | total loss: [1m[32m0.02831[0m[0m | time: 297.453s
[2K
| Adam | epoch: 025 | loss: 0.02831 - acc: 0.9872 -- iter: 1120/2163
[A[ATraining Step: 1668  | total loss: [1m[32m0.02571[0m[0m | time: 305.244s
[2K
| Adam | epoch: 025 | loss: 0.02571 - acc: 0.9885 -- iter: 1152/2163
[A[ATraining Step: 1669  | total loss: [1m[32m0.03501[0m[0m | time: 313.085s
[2K
| Adam | epoch: 025 | loss: 0.03501 - acc: 0.9834 -- iter: 1184/2163
[A[ATraining Step: 1670  | total loss: [1m[32m0.03310[0m[0m | time: 320.901s
[2K
| Adam | epoch: 025 | loss: 0.03310 - acc: 0.9851 -- iter: 1216/2163
[A[ATraining Step: 1671  | total loss: [1m[32m0.03022[0m[0m | time: 328.555s
[2K
| Adam | epoch: 025 | loss: 0.03022 - acc: 0.9866 -- iter: 1248/2163
[A[ATraining Step: 1672  | total loss: [1m[32m0.02744[0m[0m | time: 336.190s
[2K
| Adam | epoch: 025 | loss: 0.02744 - acc: 0.9879 -- iter: 1280/2163
[A[ATraining Step: 1673  | total loss: [1m[32m0.02507[0m[0m | time: 343.909s
[2K
| Adam | epoch: 025 | loss: 0.02507 - acc: 0.9891 -- iter: 1312/2163
[A[ATraining Step: 1674  | total loss: [1m[32m0.02261[0m[0m | time: 351.579s
[2K
| Adam | epoch: 025 | loss: 0.02261 - acc: 0.9902 -- iter: 1344/2163
[A[ATraining Step: 1675  | total loss: [1m[32m0.02072[0m[0m | time: 359.264s
[2K
| Adam | epoch: 025 | loss: 0.02072 - acc: 0.9912 -- iter: 1376/2163
[A[ATraining Step: 1676  | total loss: [1m[32m0.02083[0m[0m | time: 367.032s
[2K
| Adam | epoch: 025 | loss: 0.02083 - acc: 0.9921 -- iter: 1408/2163
[A[ATraining Step: 1677  | total loss: [1m[32m0.03881[0m[0m | time: 375.184s
[2K
| Adam | epoch: 025 | loss: 0.03881 - acc: 0.9866 -- iter: 1440/2163
[A[ATraining Step: 1678  | total loss: [1m[32m0.03527[0m[0m | time: 382.920s
[2K
| Adam | epoch: 025 | loss: 0.03527 - acc: 0.9879 -- iter: 1472/2163
[A[ATraining Step: 1679  | total loss: [1m[32m0.03309[0m[0m | time: 390.811s
[2K
| Adam | epoch: 025 | loss: 0.03309 - acc: 0.9892 -- iter: 1504/2163
[A[ATraining Step: 1680  | total loss: [1m[32m0.02983[0m[0m | time: 398.609s
[2K
| Adam | epoch: 025 | loss: 0.02983 - acc: 0.9902 -- iter: 1536/2163
[A[ATraining Step: 1681  | total loss: [1m[32m0.02890[0m[0m | time: 406.312s
[2K
| Adam | epoch: 025 | loss: 0.02890 - acc: 0.9912 -- iter: 1568/2163
[A[ATraining Step: 1682  | total loss: [1m[32m0.02627[0m[0m | time: 414.256s
[2K
| Adam | epoch: 025 | loss: 0.02627 - acc: 0.9921 -- iter: 1600/2163
[A[ATraining Step: 1683  | total loss: [1m[32m0.02395[0m[0m | time: 422.168s
[2K
| Adam | epoch: 025 | loss: 0.02395 - acc: 0.9929 -- iter: 1632/2163
[A[ATraining Step: 1684  | total loss: [1m[32m0.02172[0m[0m | time: 429.882s
[2K
| Adam | epoch: 025 | loss: 0.02172 - acc: 0.9936 -- iter: 1664/2163
[A[ATraining Step: 1685  | total loss: [1m[32m0.02073[0m[0m | time: 437.683s
[2K
| Adam | epoch: 025 | loss: 0.02073 - acc: 0.9942 -- iter: 1696/2163
[A[ATraining Step: 1686  | total loss: [1m[32m0.01959[0m[0m | time: 445.463s
[2K
| Adam | epoch: 025 | loss: 0.01959 - acc: 0.9948 -- iter: 1728/2163
[A[ATraining Step: 1687  | total loss: [1m[32m0.01847[0m[0m | time: 453.207s
[2K
| Adam | epoch: 025 | loss: 0.01847 - acc: 0.9953 -- iter: 1760/2163
[A[ATraining Step: 1688  | total loss: [1m[32m0.01759[0m[0m | time: 460.927s
[2K
| Adam | epoch: 025 | loss: 0.01759 - acc: 0.9958 -- iter: 1792/2163
[A[ATraining Step: 1689  | total loss: [1m[32m0.01770[0m[0m | time: 468.725s
[2K
| Adam | epoch: 025 | loss: 0.01770 - acc: 0.9962 -- iter: 1824/2163
[A[ATraining Step: 1690  | total loss: [1m[32m0.01655[0m[0m | time: 476.478s
[2K
| Adam | epoch: 025 | loss: 0.01655 - acc: 0.9966 -- iter: 1856/2163
[A[ATraining Step: 1691  | total loss: [1m[32m0.01798[0m[0m | time: 484.288s
[2K
| Adam | epoch: 025 | loss: 0.01798 - acc: 0.9938 -- iter: 1888/2163
[A[ATraining Step: 1692  | total loss: [1m[32m0.01625[0m[0m | time: 491.939s
[2K
| Adam | epoch: 025 | loss: 0.01625 - acc: 0.9944 -- iter: 1920/2163
[A[ATraining Step: 1693  | total loss: [1m[32m0.14460[0m[0m | time: 499.538s
[2K
| Adam | epoch: 025 | loss: 0.14460 - acc: 0.9825 -- iter: 1952/2163
[A[ATraining Step: 1694  | total loss: [1m[32m0.13030[0m[0m | time: 507.196s
[2K
| Adam | epoch: 025 | loss: 0.13030 - acc: 0.9842 -- iter: 1984/2163
[A[ATraining Step: 1695  | total loss: [1m[32m0.11748[0m[0m | time: 514.859s
[2K
| Adam | epoch: 025 | loss: 0.11748 - acc: 0.9858 -- iter: 2016/2163
[A[ATraining Step: 1696  | total loss: [1m[32m0.10591[0m[0m | time: 522.700s
[2K
| Adam | epoch: 025 | loss: 0.10591 - acc: 0.9872 -- iter: 2048/2163
[A[ATraining Step: 1697  | total loss: [1m[32m0.09680[0m[0m | time: 530.283s
[2K
| Adam | epoch: 025 | loss: 0.09680 - acc: 0.9885 -- iter: 2080/2163
[A[ATraining Step: 1698  | total loss: [1m[32m0.10173[0m[0m | time: 537.983s
[2K
| Adam | epoch: 025 | loss: 0.10173 - acc: 0.9865 -- iter: 2112/2163
[A[ATraining Step: 1699  | total loss: [1m[32m0.11889[0m[0m | time: 545.572s
[2K
| Adam | epoch: 025 | loss: 0.11889 - acc: 0.9816 -- iter: 2144/2163
[A[ATraining Step: 1700  | total loss: [1m[32m0.11945[0m[0m | time: 583.271s
[2K
| Adam | epoch: 025 | loss: 0.11945 - acc: 0.9772 | val_loss: 0.61309 - val_acc: 0.8597 -- iter: 2163/2163
--
Training Step: 1701  | total loss: [1m[32m0.11297[0m[0m | time: 7.704s
[2K
| Adam | epoch: 026 | loss: 0.11297 - acc: 0.9764 -- iter: 0032/2163
[A[ATraining Step: 1702  | total loss: [1m[32m0.10322[0m[0m | time: 15.526s
[2K
| Adam | epoch: 026 | loss: 0.10322 - acc: 0.9787 -- iter: 0064/2163
[A[ATraining Step: 1703  | total loss: [1m[32m0.09363[0m[0m | time: 23.011s
[2K
| Adam | epoch: 026 | loss: 0.09363 - acc: 0.9809 -- iter: 0096/2163
[A[ATraining Step: 1704  | total loss: [1m[32m0.10880[0m[0m | time: 30.717s
[2K
| Adam | epoch: 026 | loss: 0.10880 - acc: 0.9765 -- iter: 0128/2163
[A[ATraining Step: 1705  | total loss: [1m[32m0.09858[0m[0m | time: 38.378s
[2K
| Adam | epoch: 026 | loss: 0.09858 - acc: 0.9789 -- iter: 0160/2163
[A[ATraining Step: 1706  | total loss: [1m[32m0.08969[0m[0m | time: 46.143s
[2K
| Adam | epoch: 026 | loss: 0.08969 - acc: 0.9810 -- iter: 0192/2163
[A[ATraining Step: 1707  | total loss: [1m[32m0.09106[0m[0m | time: 53.661s
[2K
| Adam | epoch: 026 | loss: 0.09106 - acc: 0.9798 -- iter: 0224/2163
[A[ATraining Step: 1708  | total loss: [1m[32m0.08618[0m[0m | time: 61.461s
[2K
| Adam | epoch: 026 | loss: 0.08618 - acc: 0.9787 -- iter: 0256/2163
[A[ATraining Step: 1709  | total loss: [1m[32m0.09510[0m[0m | time: 69.055s
[2K
| Adam | epoch: 026 | loss: 0.09510 - acc: 0.9745 -- iter: 0288/2163
[A[ATraining Step: 1710  | total loss: [1m[32m0.08720[0m[0m | time: 76.828s
[2K
| Adam | epoch: 026 | loss: 0.08720 - acc: 0.9771 -- iter: 0320/2163
[A[ATraining Step: 1711  | total loss: [1m[32m0.08287[0m[0m | time: 84.620s
[2K
| Adam | epoch: 026 | loss: 0.08287 - acc: 0.9763 -- iter: 0352/2163
[A[ATraining Step: 1712  | total loss: [1m[32m0.10621[0m[0m | time: 92.381s
[2K
| Adam | epoch: 026 | loss: 0.10621 - acc: 0.9630 -- iter: 0384/2163
[A[ATraining Step: 1713  | total loss: [1m[32m0.09693[0m[0m | time: 100.212s
[2K
| Adam | epoch: 026 | loss: 0.09693 - acc: 0.9667 -- iter: 0416/2163
[A[ATraining Step: 1714  | total loss: [1m[32m0.08742[0m[0m | time: 107.938s
[2K
| Adam | epoch: 026 | loss: 0.08742 - acc: 0.9700 -- iter: 0448/2163
[A[ATraining Step: 1715  | total loss: [1m[32m0.08332[0m[0m | time: 115.554s
[2K
| Adam | epoch: 026 | loss: 0.08332 - acc: 0.9699 -- iter: 0480/2163
[A[ATraining Step: 1716  | total loss: [1m[32m0.07662[0m[0m | time: 123.149s
[2K
| Adam | epoch: 026 | loss: 0.07662 - acc: 0.9729 -- iter: 0512/2163
[A[ATraining Step: 1717  | total loss: [1m[32m0.07115[0m[0m | time: 130.715s
[2K
| Adam | epoch: 026 | loss: 0.07115 - acc: 0.9756 -- iter: 0544/2163
[A[ATraining Step: 1718  | total loss: [1m[32m0.06810[0m[0m | time: 138.480s
[2K
| Adam | epoch: 026 | loss: 0.06810 - acc: 0.9781 -- iter: 0576/2163
[A[ATraining Step: 1719  | total loss: [1m[32m0.06262[0m[0m | time: 146.140s
[2K
| Adam | epoch: 026 | loss: 0.06262 - acc: 0.9803 -- iter: 0608/2163
[A[ATraining Step: 1720  | total loss: [1m[32m0.05696[0m[0m | time: 153.808s
[2K
| Adam | epoch: 026 | loss: 0.05696 - acc: 0.9822 -- iter: 0640/2163
[A[ATraining Step: 1721  | total loss: [1m[32m0.05374[0m[0m | time: 161.575s
[2K
| Adam | epoch: 026 | loss: 0.05374 - acc: 0.9840 -- iter: 0672/2163
[A[ATraining Step: 1722  | total loss: [1m[32m0.06374[0m[0m | time: 169.322s
[2K
| Adam | epoch: 026 | loss: 0.06374 - acc: 0.9825 -- iter: 0704/2163
[A[ATraining Step: 1723  | total loss: [1m[32m0.06004[0m[0m | time: 176.921s
[2K
| Adam | epoch: 026 | loss: 0.06004 - acc: 0.9842 -- iter: 0736/2163
[A[ATraining Step: 1724  | total loss: [1m[32m0.05706[0m[0m | time: 182.194s
[2K
| Adam | epoch: 026 | loss: 0.05706 - acc: 0.9827 -- iter: 0768/2163
[A[ATraining Step: 1725  | total loss: [1m[32m0.05154[0m[0m | time: 187.220s
[2K
| Adam | epoch: 026 | loss: 0.05154 - acc: 0.9844 -- iter: 0800/2163
[A[ATraining Step: 1726  | total loss: [1m[32m0.04656[0m[0m | time: 195.028s
[2K
| Adam | epoch: 026 | loss: 0.04656 - acc: 0.9860 -- iter: 0832/2163
[A[ATraining Step: 1727  | total loss: [1m[32m0.04401[0m[0m | time: 202.683s
[2K
| Adam | epoch: 026 | loss: 0.04401 - acc: 0.9874 -- iter: 0864/2163
[A[ATraining Step: 1728  | total loss: [1m[32m0.04316[0m[0m | time: 210.421s
[2K
| Adam | epoch: 026 | loss: 0.04316 - acc: 0.9855 -- iter: 0896/2163
[A[ATraining Step: 1729  | total loss: [1m[32m0.04724[0m[0m | time: 218.002s
[2K
| Adam | epoch: 026 | loss: 0.04724 - acc: 0.9807 -- iter: 0928/2163
[A[ATraining Step: 1730  | total loss: [1m[32m0.04733[0m[0m | time: 225.793s
[2K
| Adam | epoch: 026 | loss: 0.04733 - acc: 0.9795 -- iter: 0960/2163
[A[ATraining Step: 1731  | total loss: [1m[32m0.04598[0m[0m | time: 233.312s
[2K
| Adam | epoch: 026 | loss: 0.04598 - acc: 0.9816 -- iter: 0992/2163
[A[ATraining Step: 1732  | total loss: [1m[32m0.04228[0m[0m | time: 240.973s
[2K
| Adam | epoch: 026 | loss: 0.04228 - acc: 0.9834 -- iter: 1024/2163
[A[ATraining Step: 1733  | total loss: [1m[32m0.03834[0m[0m | time: 248.839s
[2K
| Adam | epoch: 026 | loss: 0.03834 - acc: 0.9851 -- iter: 1056/2163
[A[ATraining Step: 1734  | total loss: [1m[32m0.03488[0m[0m | time: 256.533s
[2K
| Adam | epoch: 026 | loss: 0.03488 - acc: 0.9866 -- iter: 1088/2163
[A[ATraining Step: 1735  | total loss: [1m[32m0.03167[0m[0m | time: 264.056s
[2K
| Adam | epoch: 026 | loss: 0.03167 - acc: 0.9879 -- iter: 1120/2163
[A[ATraining Step: 1736  | total loss: [1m[32m0.03000[0m[0m | time: 271.767s
[2K
| Adam | epoch: 026 | loss: 0.03000 - acc: 0.9891 -- iter: 1152/2163
[A[ATraining Step: 1737  | total loss: [1m[32m0.02720[0m[0m | time: 279.353s
[2K
| Adam | epoch: 026 | loss: 0.02720 - acc: 0.9902 -- iter: 1184/2163
[A[ATraining Step: 1738  | total loss: [1m[32m0.02652[0m[0m | time: 286.951s
[2K
| Adam | epoch: 026 | loss: 0.02652 - acc: 0.9912 -- iter: 1216/2163
[A[ATraining Step: 1739  | total loss: [1m[32m0.02419[0m[0m | time: 294.592s
[2K
| Adam | epoch: 026 | loss: 0.02419 - acc: 0.9921 -- iter: 1248/2163
[A[ATraining Step: 1740  | total loss: [1m[32m0.03937[0m[0m | time: 302.475s
[2K
| Adam | epoch: 026 | loss: 0.03937 - acc: 0.9897 -- iter: 1280/2163
[A[ATraining Step: 1741  | total loss: [1m[32m0.04352[0m[0m | time: 310.147s
[2K
| Adam | epoch: 026 | loss: 0.04352 - acc: 0.9845 -- iter: 1312/2163
[A[ATraining Step: 1742  | total loss: [1m[32m0.03960[0m[0m | time: 317.756s
[2K
| Adam | epoch: 026 | loss: 0.03960 - acc: 0.9861 -- iter: 1344/2163
[A[ATraining Step: 1743  | total loss: [1m[32m0.03814[0m[0m | time: 325.227s
[2K
| Adam | epoch: 026 | loss: 0.03814 - acc: 0.9875 -- iter: 1376/2163
[A[ATraining Step: 1744  | total loss: [1m[32m0.03485[0m[0m | time: 333.007s
[2K
| Adam | epoch: 026 | loss: 0.03485 - acc: 0.9887 -- iter: 1408/2163
[A[ATraining Step: 1745  | total loss: [1m[32m0.03207[0m[0m | time: 340.751s
[2K
| Adam | epoch: 026 | loss: 0.03207 - acc: 0.9898 -- iter: 1440/2163
[A[ATraining Step: 1746  | total loss: [1m[32m0.02910[0m[0m | time: 348.561s
[2K
| Adam | epoch: 026 | loss: 0.02910 - acc: 0.9909 -- iter: 1472/2163
[A[ATraining Step: 1747  | total loss: [1m[32m0.02695[0m[0m | time: 356.262s
[2K
| Adam | epoch: 026 | loss: 0.02695 - acc: 0.9918 -- iter: 1504/2163
[A[ATraining Step: 1748  | total loss: [1m[32m0.02567[0m[0m | time: 363.990s
[2K
| Adam | epoch: 026 | loss: 0.02567 - acc: 0.9926 -- iter: 1536/2163
[A[ATraining Step: 1749  | total loss: [1m[32m0.02614[0m[0m | time: 371.741s
[2K
| Adam | epoch: 026 | loss: 0.02614 - acc: 0.9933 -- iter: 1568/2163
[A[ATraining Step: 1750  | total loss: [1m[32m0.02378[0m[0m | time: 379.530s
[2K
| Adam | epoch: 026 | loss: 0.02378 - acc: 0.9940 -- iter: 1600/2163
[A[ATraining Step: 1751  | total loss: [1m[32m0.02298[0m[0m | time: 387.158s
[2K
| Adam | epoch: 026 | loss: 0.02298 - acc: 0.9946 -- iter: 1632/2163
[A[ATraining Step: 1752  | total loss: [1m[32m0.02298[0m[0m | time: 396.000s
[2K
| Adam | epoch: 026 | loss: 0.02298 - acc: 0.9951 -- iter: 1664/2163
[A[ATraining Step: 1753  | total loss: [1m[32m0.02101[0m[0m | time: 407.822s
[2K
| Adam | epoch: 026 | loss: 0.02101 - acc: 0.9956 -- iter: 1696/2163
[A[ATraining Step: 1754  | total loss: [1m[32m0.01910[0m[0m | time: 421.269s
[2K
| Adam | epoch: 026 | loss: 0.01910 - acc: 0.9961 -- iter: 1728/2163
[A[ATraining Step: 1755  | total loss: [1m[32m0.01895[0m[0m | time: 434.409s
[2K
| Adam | epoch: 026 | loss: 0.01895 - acc: 0.9965 -- iter: 1760/2163
[A[ATraining Step: 1756  | total loss: [1m[32m0.02006[0m[0m | time: 447.578s
[2K
| Adam | epoch: 026 | loss: 0.02006 - acc: 0.9968 -- iter: 1792/2163
[A[ATraining Step: 1757  | total loss: [1m[32m0.01817[0m[0m | time: 458.022s
[2K
| Adam | epoch: 026 | loss: 0.01817 - acc: 0.9971 -- iter: 1824/2163
[A[ATraining Step: 1758  | total loss: [1m[32m0.01662[0m[0m | time: 466.400s
[2K
| Adam | epoch: 026 | loss: 0.01662 - acc: 0.9974 -- iter: 1856/2163
[A[ATraining Step: 1759  | total loss: [1m[32m0.01666[0m[0m | time: 474.695s
[2K
| Adam | epoch: 026 | loss: 0.01666 - acc: 0.9977 -- iter: 1888/2163
[A[ATraining Step: 1760  | total loss: [1m[32m0.01513[0m[0m | time: 482.550s
[2K
| Adam | epoch: 026 | loss: 0.01513 - acc: 0.9979 -- iter: 1920/2163
[A[ATraining Step: 1761  | total loss: [1m[32m0.01481[0m[0m | time: 490.283s
[2K
| Adam | epoch: 026 | loss: 0.01481 - acc: 0.9981 -- iter: 1952/2163
[A[ATraining Step: 1762  | total loss: [1m[32m0.03791[0m[0m | time: 497.987s
[2K
| Adam | epoch: 026 | loss: 0.03791 - acc: 0.9952 -- iter: 1984/2163
[A[ATraining Step: 1763  | total loss: [1m[32m0.03752[0m[0m | time: 505.918s
[2K
| Adam | epoch: 026 | loss: 0.03752 - acc: 0.9957 -- iter: 2016/2163
[A[ATraining Step: 1764  | total loss: [1m[32m0.03401[0m[0m | time: 515.382s
[2K
| Adam | epoch: 026 | loss: 0.03401 - acc: 0.9961 -- iter: 2048/2163
[A[ATraining Step: 1765  | total loss: [1m[32m0.03131[0m[0m | time: 528.441s
[2K
| Adam | epoch: 026 | loss: 0.03131 - acc: 0.9965 -- iter: 2080/2163
[A[ATraining Step: 1766  | total loss: [1m[32m0.02931[0m[0m | time: 541.261s
[2K
| Adam | epoch: 026 | loss: 0.02931 - acc: 0.9968 -- iter: 2112/2163
[A[ATraining Step: 1767  | total loss: [1m[32m0.02649[0m[0m | time: 554.730s
[2K
| Adam | epoch: 026 | loss: 0.02649 - acc: 0.9972 -- iter: 2144/2163
[A[ATraining Step: 1768  | total loss: [1m[32m0.02573[0m[0m | time: 625.954s
[2K
| Adam | epoch: 026 | loss: 0.02573 - acc: 0.9974 | val_loss: 0.23235 - val_acc: 0.9350 -- iter: 2163/2163
--
Training Step: 1769  | total loss: [1m[32m0.02389[0m[0m | time: 13.432s
[2K
| Adam | epoch: 027 | loss: 0.02389 - acc: 0.9977 -- iter: 0032/2163
[A[ATraining Step: 1770  | total loss: [1m[32m0.02176[0m[0m | time: 22.113s
[2K
| Adam | epoch: 027 | loss: 0.02176 - acc: 0.9979 -- iter: 0064/2163
[A[ATraining Step: 1771  | total loss: [1m[32m0.03997[0m[0m | time: 31.521s
[2K
| Adam | epoch: 027 | loss: 0.03997 - acc: 0.9919 -- iter: 0096/2163
[A[ATraining Step: 1772  | total loss: [1m[32m0.03631[0m[0m | time: 45.025s
[2K
| Adam | epoch: 027 | loss: 0.03631 - acc: 0.9927 -- iter: 0128/2163
[A[ATraining Step: 1773  | total loss: [1m[32m0.03801[0m[0m | time: 68.529s
[2K
| Adam | epoch: 027 | loss: 0.03801 - acc: 0.9934 -- iter: 0160/2163
[A[ATraining Step: 1774  | total loss: [1m[32m0.03624[0m[0m | time: 85.049s
[2K
| Adam | epoch: 027 | loss: 0.03624 - acc: 0.9941 -- iter: 0192/2163
[A[ATraining Step: 1775  | total loss: [1m[32m0.03387[0m[0m | time: 103.386s
[2K
| Adam | epoch: 027 | loss: 0.03387 - acc: 0.9947 -- iter: 0224/2163
[A[ATraining Step: 1776  | total loss: [1m[32m0.03236[0m[0m | time: 116.603s
[2K
| Adam | epoch: 027 | loss: 0.03236 - acc: 0.9952 -- iter: 0256/2163
[A[ATraining Step: 1777  | total loss: [1m[32m0.02972[0m[0m | time: 127.132s
[2K
| Adam | epoch: 027 | loss: 0.02972 - acc: 0.9957 -- iter: 0288/2163
[A[ATraining Step: 1778  | total loss: [1m[32m0.03287[0m[0m | time: 138.107s
[2K
| Adam | epoch: 027 | loss: 0.03287 - acc: 0.9930 -- iter: 0320/2163
[A[ATraining Step: 1779  | total loss: [1m[32m0.02977[0m[0m | time: 151.095s
[2K
| Adam | epoch: 027 | loss: 0.02977 - acc: 0.9937 -- iter: 0352/2163
[A[ATraining Step: 1780  | total loss: [1m[32m0.03199[0m[0m | time: 170.240s
[2K
| Adam | epoch: 027 | loss: 0.03199 - acc: 0.9912 -- iter: 0384/2163
[A[ATraining Step: 1781  | total loss: [1m[32m0.02929[0m[0m | time: 187.293s
[2K
| Adam | epoch: 027 | loss: 0.02929 - acc: 0.9921 -- iter: 0416/2163
[A[ATraining Step: 1782  | total loss: [1m[32m0.02934[0m[0m | time: 201.672s
[2K
| Adam | epoch: 027 | loss: 0.02934 - acc: 0.9897 -- iter: 0448/2163
[A[ATraining Step: 1783  | total loss: [1m[32m0.02765[0m[0m | time: 215.015s
[2K
| Adam | epoch: 027 | loss: 0.02765 - acc: 0.9908 -- iter: 0480/2163
[A[ATraining Step: 1784  | total loss: [1m[32m0.02654[0m[0m | time: 226.104s
[2K
| Adam | epoch: 027 | loss: 0.02654 - acc: 0.9917 -- iter: 0512/2163
[A[ATraining Step: 1785  | total loss: [1m[32m0.02817[0m[0m | time: 239.057s
[2K
| Adam | epoch: 027 | loss: 0.02817 - acc: 0.9894 -- iter: 0544/2163
[A[ATraining Step: 1786  | total loss: [1m[32m0.02627[0m[0m | time: 255.146s
[2K
| Adam | epoch: 027 | loss: 0.02627 - acc: 0.9905 -- iter: 0576/2163
[A[ATraining Step: 1787  | total loss: [1m[32m0.03102[0m[0m | time: 273.631s
[2K
| Adam | epoch: 027 | loss: 0.03102 - acc: 0.9883 -- iter: 0608/2163
[A[ATraining Step: 1788  | total loss: [1m[32m0.02813[0m[0m | time: 290.023s
[2K
| Adam | epoch: 027 | loss: 0.02813 - acc: 0.9895 -- iter: 0640/2163
[A[ATraining Step: 1789  | total loss: [1m[32m0.02577[0m[0m | time: 301.406s
[2K
| Adam | epoch: 027 | loss: 0.02577 - acc: 0.9905 -- iter: 0672/2163
[A[ATraining Step: 1790  | total loss: [1m[32m0.02501[0m[0m | time: 315.278s
[2K
| Adam | epoch: 027 | loss: 0.02501 - acc: 0.9915 -- iter: 0704/2163
[A[ATraining Step: 1791  | total loss: [1m[32m0.02274[0m[0m | time: 328.597s
[2K
| Adam | epoch: 027 | loss: 0.02274 - acc: 0.9923 -- iter: 0736/2163
[A[ATraining Step: 1792  | total loss: [1m[32m0.02100[0m[0m | time: 342.028s
[2K
| Adam | epoch: 027 | loss: 0.02100 - acc: 0.9931 -- iter: 0768/2163
[A[ATraining Step: 1793  | total loss: [1m[32m0.01913[0m[0m | time: 354.202s
[2K
| Adam | epoch: 027 | loss: 0.01913 - acc: 0.9938 -- iter: 0800/2163
[A[ATraining Step: 1794  | total loss: [1m[32m0.01751[0m[0m | time: 366.688s
[2K
| Adam | epoch: 027 | loss: 0.01751 - acc: 0.9944 -- iter: 0832/2163
[A[ATraining Step: 1795  | total loss: [1m[32m0.01598[0m[0m | time: 382.077s
[2K
| Adam | epoch: 027 | loss: 0.01598 - acc: 0.9950 -- iter: 0864/2163
[A[ATraining Step: 1796  | total loss: [1m[32m0.01454[0m[0m | time: 394.765s
[2K
| Adam | epoch: 027 | loss: 0.01454 - acc: 0.9955 -- iter: 0896/2163
[A[ATraining Step: 1797  | total loss: [1m[32m0.02220[0m[0m | time: 406.552s
[2K
| Adam | epoch: 027 | loss: 0.02220 - acc: 0.9928 -- iter: 0928/2163
[A[ATraining Step: 1798  | total loss: [1m[32m0.02304[0m[0m | time: 419.280s
[2K
| Adam | epoch: 027 | loss: 0.02304 - acc: 0.9935 -- iter: 0960/2163
[A[ATraining Step: 1799  | total loss: [1m[32m0.02098[0m[0m | time: 432.133s
[2K
| Adam | epoch: 027 | loss: 0.02098 - acc: 0.9942 -- iter: 0992/2163
[A[ATraining Step: 1800  | total loss: [1m[32m0.01921[0m[0m | time: 511.321s
[2K
| Adam | epoch: 027 | loss: 0.01921 - acc: 0.9947 | val_loss: 0.25220 - val_acc: 0.9453 -- iter: 1024/2163
--
Training Step: 1801  | total loss: [1m[32m0.02496[0m[0m | time: 524.776s
[2K
| Adam | epoch: 027 | loss: 0.02496 - acc: 0.9890 -- iter: 1056/2163
[A[ATraining Step: 1802  | total loss: [1m[32m0.02576[0m[0m | time: 539.386s
[2K
| Adam | epoch: 027 | loss: 0.02576 - acc: 0.9870 -- iter: 1088/2163
[A[ATraining Step: 1803  | total loss: [1m[32m0.02345[0m[0m | time: 552.232s
[2K
| Adam | epoch: 027 | loss: 0.02345 - acc: 0.9883 -- iter: 1120/2163
[A[ATraining Step: 1804  | total loss: [1m[32m0.02118[0m[0m | time: 565.237s
[2K
| Adam | epoch: 027 | loss: 0.02118 - acc: 0.9895 -- iter: 1152/2163
[A[ATraining Step: 1805  | total loss: [1m[32m0.01953[0m[0m | time: 581.941s
[2K
| Adam | epoch: 027 | loss: 0.01953 - acc: 0.9905 -- iter: 1184/2163
[A[ATraining Step: 1806  | total loss: [1m[32m0.02680[0m[0m | time: 600.466s
[2K
| Adam | epoch: 027 | loss: 0.02680 - acc: 0.9883 -- iter: 1216/2163
[A[ATraining Step: 1807  | total loss: [1m[32m0.02595[0m[0m | time: 615.314s
[2K
| Adam | epoch: 027 | loss: 0.02595 - acc: 0.9895 -- iter: 1248/2163
[A[ATraining Step: 1808  | total loss: [1m[32m0.02346[0m[0m | time: 628.690s
[2K
| Adam | epoch: 027 | loss: 0.02346 - acc: 0.9906 -- iter: 1280/2163
[A[ATraining Step: 1809  | total loss: [1m[32m0.02380[0m[0m | time: 639.530s
[2K
| Adam | epoch: 027 | loss: 0.02380 - acc: 0.9884 -- iter: 1312/2163
[A[ATraining Step: 1810  | total loss: [1m[32m0.02197[0m[0m | time: 647.607s
[2K
| Adam | epoch: 027 | loss: 0.02197 - acc: 0.9895 -- iter: 1344/2163
[A[ATraining Step: 1811  | total loss: [1m[32m0.02063[0m[0m | time: 659.057s
[2K
| Adam | epoch: 027 | loss: 0.02063 - acc: 0.9906 -- iter: 1376/2163
[A[ATraining Step: 1812  | total loss: [1m[32m0.02093[0m[0m | time: 675.775s
[2K
| Adam | epoch: 027 | loss: 0.02093 - acc: 0.9884 -- iter: 1408/2163
[A[ATraining Step: 1813  | total loss: [1m[32m0.01912[0m[0m | time: 694.902s
[2K
| Adam | epoch: 027 | loss: 0.01912 - acc: 0.9896 -- iter: 1440/2163
[A[ATraining Step: 1814  | total loss: [1m[32m0.01735[0m[0m | time: 717.124s
[2K
| Adam | epoch: 027 | loss: 0.01735 - acc: 0.9906 -- iter: 1472/2163
[A[ATraining Step: 1815  | total loss: [1m[32m0.01592[0m[0m | time: 732.422s
[2K
| Adam | epoch: 027 | loss: 0.01592 - acc: 0.9915 -- iter: 1504/2163
[A[ATraining Step: 1816  | total loss: [1m[32m0.01448[0m[0m | time: 741.324s
[2K
| Adam | epoch: 027 | loss: 0.01448 - acc: 0.9924 -- iter: 1536/2163
[A[ATraining Step: 1817  | total loss: [1m[32m0.02817[0m[0m | time: 749.822s
[2K
| Adam | epoch: 027 | loss: 0.02817 - acc: 0.9900 -- iter: 1568/2163
[A[ATraining Step: 1818  | total loss: [1m[32m0.02667[0m[0m | time: 762.846s
[2K
| Adam | epoch: 027 | loss: 0.02667 - acc: 0.9910 -- iter: 1600/2163
[A[ATraining Step: 1819  | total loss: [1m[32m0.02491[0m[0m | time: 779.331s
[2K
| Adam | epoch: 027 | loss: 0.02491 - acc: 0.9919 -- iter: 1632/2163
[A[ATraining Step: 1820  | total loss: [1m[32m0.02339[0m[0m | time: 796.300s
[2K
| Adam | epoch: 027 | loss: 0.02339 - acc: 0.9927 -- iter: 1664/2163
[A[ATraining Step: 1821  | total loss: [1m[32m0.02179[0m[0m | time: 820.713s
[2K
| Adam | epoch: 027 | loss: 0.02179 - acc: 0.9935 -- iter: 1696/2163
[A[ATraining Step: 1822  | total loss: [1m[32m0.01983[0m[0m | time: 835.342s
[2K
| Adam | epoch: 027 | loss: 0.01983 - acc: 0.9941 -- iter: 1728/2163
[A[ATraining Step: 1823  | total loss: [1m[32m0.01871[0m[0m | time: 843.434s
[2K
| Adam | epoch: 027 | loss: 0.01871 - acc: 0.9947 -- iter: 1760/2163
[A[ATraining Step: 1824  | total loss: [1m[32m0.01743[0m[0m | time: 852.705s
[2K
| Adam | epoch: 027 | loss: 0.01743 - acc: 0.9952 -- iter: 1792/2163
[A[ATraining Step: 1825  | total loss: [1m[32m0.01648[0m[0m | time: 865.577s
[2K
| Adam | epoch: 027 | loss: 0.01648 - acc: 0.9957 -- iter: 1824/2163
[A[ATraining Step: 1826  | total loss: [1m[32m0.01622[0m[0m | time: 877.204s
[2K
| Adam | epoch: 027 | loss: 0.01622 - acc: 0.9961 -- iter: 1856/2163
[A[ATraining Step: 1827  | total loss: [1m[32m0.01551[0m[0m | time: 895.888s
[2K
| Adam | epoch: 027 | loss: 0.01551 - acc: 0.9965 -- iter: 1888/2163
[A[ATraining Step: 1828  | total loss: [1m[32m0.01719[0m[0m | time: 914.152s
[2K
| Adam | epoch: 027 | loss: 0.01719 - acc: 0.9969 -- iter: 1920/2163
[A[ATraining Step: 1829  | total loss: [1m[32m0.01572[0m[0m | time: 927.101s
[2K
| Adam | epoch: 027 | loss: 0.01572 - acc: 0.9972 -- iter: 1952/2163
[A[ATraining Step: 1830  | total loss: [1m[32m0.01431[0m[0m | time: 939.614s
[2K
| Adam | epoch: 027 | loss: 0.01431 - acc: 0.9975 -- iter: 1984/2163
[A[ATraining Step: 1831  | total loss: [1m[32m0.06566[0m[0m | time: 949.937s
[2K
| Adam | epoch: 027 | loss: 0.06566 - acc: 0.9915 -- iter: 2016/2163
[A[ATraining Step: 1832  | total loss: [1m[32m0.05962[0m[0m | time: 963.149s
[2K
| Adam | epoch: 027 | loss: 0.05962 - acc: 0.9923 -- iter: 2048/2163
[A[ATraining Step: 1833  | total loss: [1m[32m0.05452[0m[0m | time: 979.730s
[2K
| Adam | epoch: 027 | loss: 0.05452 - acc: 0.9931 -- iter: 2080/2163
[A[ATraining Step: 1834  | total loss: [1m[32m0.04928[0m[0m | time: 996.703s
[2K
| Adam | epoch: 027 | loss: 0.04928 - acc: 0.9938 -- iter: 2112/2163
[A[ATraining Step: 1835  | total loss: [1m[32m0.04562[0m[0m | time: 1014.410s
[2K
| Adam | epoch: 027 | loss: 0.04562 - acc: 0.9944 -- iter: 2144/2163
[A[ATraining Step: 1836  | total loss: [1m[32m0.04279[0m[0m | time: 1067.188s
[2K
| Adam | epoch: 027 | loss: 0.04279 - acc: 0.9950 | val_loss: 0.34082 - val_acc: 0.9158 -- iter: 2163/2163
--
Training Step: 1837  | total loss: [1m[32m0.04258[0m[0m | time: 17.461s
[2K
| Adam | epoch: 028 | loss: 0.04258 - acc: 0.9923 -- iter: 0032/2163
[A[ATraining Step: 1838  | total loss: [1m[32m0.05065[0m[0m | time: 28.772s
[2K
| Adam | epoch: 028 | loss: 0.05065 - acc: 0.9900 -- iter: 0064/2163
[A[ATraining Step: 1839  | total loss: [1m[32m0.04722[0m[0m | time: 36.529s
[2K
| Adam | epoch: 028 | loss: 0.04722 - acc: 0.9910 -- iter: 0096/2163
[A[ATraining Step: 1840  | total loss: [1m[32m0.04487[0m[0m | time: 45.004s
[2K
| Adam | epoch: 028 | loss: 0.04487 - acc: 0.9919 -- iter: 0128/2163
[A[ATraining Step: 1841  | total loss: [1m[32m0.04093[0m[0m | time: 59.391s
[2K
| Adam | epoch: 028 | loss: 0.04093 - acc: 0.9927 -- iter: 0160/2163
[A[ATraining Step: 1842  | total loss: [1m[32m0.03818[0m[0m | time: 77.125s
[2K
| Adam | epoch: 028 | loss: 0.03818 - acc: 0.9934 -- iter: 0192/2163
[A[ATraining Step: 1843  | total loss: [1m[32m0.03509[0m[0m | time: 95.383s
[2K
| Adam | epoch: 028 | loss: 0.03509 - acc: 0.9941 -- iter: 0224/2163
[A[ATraining Step: 1844  | total loss: [1m[32m0.03395[0m[0m | time: 113.942s
[2K
| Adam | epoch: 028 | loss: 0.03395 - acc: 0.9947 -- iter: 0256/2163
[A[ATraining Step: 1845  | total loss: [1m[32m0.03313[0m[0m | time: 131.053s
[2K
| Adam | epoch: 028 | loss: 0.03313 - acc: 0.9921 -- iter: 0288/2163
[A[ATraining Step: 1846  | total loss: [1m[32m0.03094[0m[0m | time: 139.524s
[2K
| Adam | epoch: 028 | loss: 0.03094 - acc: 0.9929 -- iter: 0320/2163
[A[ATraining Step: 1847  | total loss: [1m[32m0.02893[0m[0m | time: 147.450s
[2K
| Adam | epoch: 028 | loss: 0.02893 - acc: 0.9936 -- iter: 0352/2163
[A[ATraining Step: 1848  | total loss: [1m[32m0.02671[0m[0m | time: 155.366s
[2K
| Adam | epoch: 028 | loss: 0.02671 - acc: 0.9942 -- iter: 0384/2163
[A[ATraining Step: 1849  | total loss: [1m[32m0.02440[0m[0m | time: 168.416s
[2K
| Adam | epoch: 028 | loss: 0.02440 - acc: 0.9948 -- iter: 0416/2163
[A[ATraining Step: 1850  | total loss: [1m[32m0.02223[0m[0m | time: 183.669s
[2K
| Adam | epoch: 028 | loss: 0.02223 - acc: 0.9953 -- iter: 0448/2163
[A[ATraining Step: 1851  | total loss: [1m[32m0.02014[0m[0m | time: 196.695s
[2K
| Adam | epoch: 028 | loss: 0.02014 - acc: 0.9958 -- iter: 0480/2163
[A[ATraining Step: 1852  | total loss: [1m[32m0.01837[0m[0m | time: 209.806s
[2K
| Adam | epoch: 028 | loss: 0.01837 - acc: 0.9962 -- iter: 0512/2163
[A[ATraining Step: 1853  | total loss: [1m[32m0.01664[0m[0m | time: 217.686s
[2K
| Adam | epoch: 028 | loss: 0.01664 - acc: 0.9966 -- iter: 0544/2163
[A[ATraining Step: 1854  | total loss: [1m[32m0.01553[0m[0m | time: 225.590s
[2K
| Adam | epoch: 028 | loss: 0.01553 - acc: 0.9969 -- iter: 0576/2163
[A[ATraining Step: 1855  | total loss: [1m[32m0.01442[0m[0m | time: 234.367s
[2K
| Adam | epoch: 028 | loss: 0.01442 - acc: 0.9972 -- iter: 0608/2163
[A[ATraining Step: 1856  | total loss: [1m[32m0.01318[0m[0m | time: 246.609s
[2K
| Adam | epoch: 028 | loss: 0.01318 - acc: 0.9975 -- iter: 0640/2163
[A[ATraining Step: 1857  | total loss: [1m[32m0.01232[0m[0m | time: 258.023s
[2K
| Adam | epoch: 028 | loss: 0.01232 - acc: 0.9978 -- iter: 0672/2163
[A[ATraining Step: 1858  | total loss: [1m[32m0.02513[0m[0m | time: 270.886s
[2K
| Adam | epoch: 028 | loss: 0.02513 - acc: 0.9917 -- iter: 0704/2163
[A[ATraining Step: 1859  | total loss: [1m[32m0.03203[0m[0m | time: 283.663s
[2K
| Adam | epoch: 028 | loss: 0.03203 - acc: 0.9894 -- iter: 0736/2163
[A[ATraining Step: 1860  | total loss: [1m[32m0.04958[0m[0m | time: 291.520s
[2K
| Adam | epoch: 028 | loss: 0.04958 - acc: 0.9874 -- iter: 0768/2163
[A[ATraining Step: 1861  | total loss: [1m[32m0.04472[0m[0m | time: 299.397s
[2K
| Adam | epoch: 028 | loss: 0.04472 - acc: 0.9886 -- iter: 0800/2163
[A[ATraining Step: 1862  | total loss: [1m[32m0.04196[0m[0m | time: 304.674s
[2K
| Adam | epoch: 028 | loss: 0.04196 - acc: 0.9898 -- iter: 0832/2163
[A[ATraining Step: 1863  | total loss: [1m[32m0.03786[0m[0m | time: 309.835s
[2K
| Adam | epoch: 028 | loss: 0.03786 - acc: 0.9908 -- iter: 0864/2163
[A[ATraining Step: 1864  | total loss: [1m[32m0.03426[0m[0m | time: 317.551s
[2K
| Adam | epoch: 028 | loss: 0.03426 - acc: 0.9917 -- iter: 0896/2163
[A[ATraining Step: 1865  | total loss: [1m[32m0.03099[0m[0m | time: 329.906s
[2K
| Adam | epoch: 028 | loss: 0.03099 - acc: 0.9925 -- iter: 0928/2163
[A[ATraining Step: 1866  | total loss: [1m[32m0.02836[0m[0m | time: 342.966s
[2K
| Adam | epoch: 028 | loss: 0.02836 - acc: 0.9933 -- iter: 0960/2163
[A[ATraining Step: 1867  | total loss: [1m[32m0.02648[0m[0m | time: 354.849s
[2K
| Adam | epoch: 028 | loss: 0.02648 - acc: 0.9940 -- iter: 0992/2163
[A[ATraining Step: 1868  | total loss: [1m[32m0.02760[0m[0m | time: 368.151s
[2K
| Adam | epoch: 028 | loss: 0.02760 - acc: 0.9946 -- iter: 1024/2163
[A[ATraining Step: 1869  | total loss: [1m[32m0.02495[0m[0m | time: 376.338s
[2K
| Adam | epoch: 028 | loss: 0.02495 - acc: 0.9951 -- iter: 1056/2163
[A[ATraining Step: 1870  | total loss: [1m[32m0.03844[0m[0m | time: 384.062s
[2K
| Adam | epoch: 028 | loss: 0.03844 - acc: 0.9893 -- iter: 1088/2163
[A[ATraining Step: 1871  | total loss: [1m[32m0.03589[0m[0m | time: 392.176s
[2K
| Adam | epoch: 028 | loss: 0.03589 - acc: 0.9904 -- iter: 1120/2163
[A[ATraining Step: 1872  | total loss: [1m[32m0.03321[0m[0m | time: 404.446s
[2K
| Adam | epoch: 028 | loss: 0.03321 - acc: 0.9914 -- iter: 1152/2163
[A[ATraining Step: 1873  | total loss: [1m[32m0.03249[0m[0m | time: 417.641s
[2K
| Adam | epoch: 028 | loss: 0.03249 - acc: 0.9922 -- iter: 1184/2163
[A[ATraining Step: 1874  | total loss: [1m[32m0.02937[0m[0m | time: 430.125s
[2K
| Adam | epoch: 028 | loss: 0.02937 - acc: 0.9930 -- iter: 1216/2163
[A[ATraining Step: 1875  | total loss: [1m[32m0.02909[0m[0m | time: 442.064s
[2K
| Adam | epoch: 028 | loss: 0.02909 - acc: 0.9937 -- iter: 1248/2163
[A[ATraining Step: 1876  | total loss: [1m[32m0.03307[0m[0m | time: 450.421s
[2K
| Adam | epoch: 028 | loss: 0.03307 - acc: 0.9912 -- iter: 1280/2163
[A[ATraining Step: 1877  | total loss: [1m[32m0.03012[0m[0m | time: 458.505s
[2K
| Adam | epoch: 028 | loss: 0.03012 - acc: 0.9921 -- iter: 1312/2163
[A[ATraining Step: 1878  | total loss: [1m[32m0.03006[0m[0m | time: 466.413s
[2K
| Adam | epoch: 028 | loss: 0.03006 - acc: 0.9898 -- iter: 1344/2163
[A[ATraining Step: 1879  | total loss: [1m[32m0.03420[0m[0m | time: 478.965s
[2K
| Adam | epoch: 028 | loss: 0.03420 - acc: 0.9877 -- iter: 1376/2163
[A[ATraining Step: 1880  | total loss: [1m[32m0.03090[0m[0m | time: 492.169s
[2K
| Adam | epoch: 028 | loss: 0.03090 - acc: 0.9889 -- iter: 1408/2163
[A[ATraining Step: 1881  | total loss: [1m[32m0.02794[0m[0m | time: 504.874s
[2K
| Adam | epoch: 028 | loss: 0.02794 - acc: 0.9900 -- iter: 1440/2163
[A[ATraining Step: 1882  | total loss: [1m[32m0.02527[0m[0m | time: 517.117s
[2K
| Adam | epoch: 028 | loss: 0.02527 - acc: 0.9910 -- iter: 1472/2163
[A[ATraining Step: 1883  | total loss: [1m[32m0.02697[0m[0m | time: 527.231s
[2K
| Adam | epoch: 028 | loss: 0.02697 - acc: 0.9919 -- iter: 1504/2163
[A[ATraining Step: 1884  | total loss: [1m[32m0.02440[0m[0m | time: 535.120s
[2K
| Adam | epoch: 028 | loss: 0.02440 - acc: 0.9927 -- iter: 1536/2163
[A[ATraining Step: 1885  | total loss: [1m[32m0.02284[0m[0m | time: 542.923s
[2K
| Adam | epoch: 028 | loss: 0.02284 - acc: 0.9934 -- iter: 1568/2163
[A[ATraining Step: 1886  | total loss: [1m[32m0.02069[0m[0m | time: 550.648s
[2K
| Adam | epoch: 028 | loss: 0.02069 - acc: 0.9941 -- iter: 1600/2163
[A[ATraining Step: 1887  | total loss: [1m[32m0.01954[0m[0m | time: 562.235s
[2K
| Adam | epoch: 028 | loss: 0.01954 - acc: 0.9947 -- iter: 1632/2163
[A[ATraining Step: 1888  | total loss: [1m[32m0.01841[0m[0m | time: 575.075s
[2K
| Adam | epoch: 028 | loss: 0.01841 - acc: 0.9952 -- iter: 1664/2163
[A[ATraining Step: 1889  | total loss: [1m[32m0.01663[0m[0m | time: 588.067s
[2K
| Adam | epoch: 028 | loss: 0.01663 - acc: 0.9957 -- iter: 1696/2163
[A[ATraining Step: 1890  | total loss: [1m[32m0.01595[0m[0m | time: 600.521s
[2K
| Adam | epoch: 028 | loss: 0.01595 - acc: 0.9961 -- iter: 1728/2163
[A[ATraining Step: 1891  | total loss: [1m[32m0.02272[0m[0m | time: 611.325s
[2K
| Adam | epoch: 028 | loss: 0.02272 - acc: 0.9934 -- iter: 1760/2163
[A[ATraining Step: 1892  | total loss: [1m[32m0.02061[0m[0m | time: 619.076s
[2K
| Adam | epoch: 028 | loss: 0.02061 - acc: 0.9941 -- iter: 1792/2163
[A[ATraining Step: 1893  | total loss: [1m[32m0.01866[0m[0m | time: 627.069s
[2K
| Adam | epoch: 028 | loss: 0.01866 - acc: 0.9946 -- iter: 1824/2163
[A[ATraining Step: 1894  | total loss: [1m[32m0.02261[0m[0m | time: 636.026s
[2K
| Adam | epoch: 028 | loss: 0.02261 - acc: 0.9921 -- iter: 1856/2163
[A[ATraining Step: 1895  | total loss: [1m[32m0.02064[0m[0m | time: 648.197s
[2K
| Adam | epoch: 028 | loss: 0.02064 - acc: 0.9929 -- iter: 1888/2163
[A[ATraining Step: 1896  | total loss: [1m[32m0.01862[0m[0m | time: 660.790s
[2K
| Adam | epoch: 028 | loss: 0.01862 - acc: 0.9936 -- iter: 1920/2163
[A[ATraining Step: 1897  | total loss: [1m[32m0.02518[0m[0m | time: 673.227s
[2K
| Adam | epoch: 028 | loss: 0.02518 - acc: 0.9911 -- iter: 1952/2163
[A[ATraining Step: 1898  | total loss: [1m[32m0.02301[0m[0m | time: 685.080s
[2K
| Adam | epoch: 028 | loss: 0.02301 - acc: 0.9920 -- iter: 1984/2163
[A[ATraining Step: 1899  | total loss: [1m[32m0.02146[0m[0m | time: 692.893s
[2K
| Adam | epoch: 028 | loss: 0.02146 - acc: 0.9928 -- iter: 2016/2163
[A[ATraining Step: 1900  | total loss: [1m[32m0.06386[0m[0m | time: 700.649s
[2K
| Adam | epoch: 028 | loss: 0.06386 - acc: 0.9904 -- iter: 2048/2163
[A[ATraining Step: 1901  | total loss: [1m[32m0.05912[0m[0m | time: 710.065s
[2K
| Adam | epoch: 028 | loss: 0.05912 - acc: 0.9913 -- iter: 2080/2163
[A[ATraining Step: 1902  | total loss: [1m[32m0.05371[0m[0m | time: 722.329s
[2K
| Adam | epoch: 028 | loss: 0.05371 - acc: 0.9922 -- iter: 2112/2163
[A[ATraining Step: 1903  | total loss: [1m[32m0.04928[0m[0m | time: 734.423s
[2K
| Adam | epoch: 028 | loss: 0.04928 - acc: 0.9930 -- iter: 2144/2163
[A[ATraining Step: 1904  | total loss: [1m[32m0.04821[0m[0m | time: 782.068s
[2K
| Adam | epoch: 028 | loss: 0.04821 - acc: 0.9906 | val_loss: 0.49442 - val_acc: 0.8892 -- iter: 2163/2163
--
Training Step: 1905  | total loss: [1m[32m0.04587[0m[0m | time: 11.578s
[2K
| Adam | epoch: 029 | loss: 0.04587 - acc: 0.9915 -- iter: 0032/2163
[A[ATraining Step: 1906  | total loss: [1m[32m0.04453[0m[0m | time: 19.361s
[2K
| Adam | epoch: 029 | loss: 0.04453 - acc: 0.9892 -- iter: 0064/2163
[A[ATraining Step: 1907  | total loss: [1m[32m0.04333[0m[0m | time: 27.050s
[2K
| Adam | epoch: 029 | loss: 0.04333 - acc: 0.9872 -- iter: 0096/2163
[A[ATraining Step: 1908  | total loss: [1m[32m0.04309[0m[0m | time: 36.486s
[2K
| Adam | epoch: 029 | loss: 0.04309 - acc: 0.9853 -- iter: 0128/2163
[A[ATraining Step: 1909  | total loss: [1m[32m0.03896[0m[0m | time: 49.501s
[2K
| Adam | epoch: 029 | loss: 0.03896 - acc: 0.9868 -- iter: 0160/2163
[A[ATraining Step: 1910  | total loss: [1m[32m0.05365[0m[0m | time: 62.300s
[2K
| Adam | epoch: 029 | loss: 0.05365 - acc: 0.9819 -- iter: 0192/2163
[A[ATraining Step: 1911  | total loss: [1m[32m0.04842[0m[0m | time: 74.619s
[2K
| Adam | epoch: 029 | loss: 0.04842 - acc: 0.9837 -- iter: 0224/2163
[A[ATraining Step: 1912  | total loss: [1m[32m0.04447[0m[0m | time: 85.879s
[2K
| Adam | epoch: 029 | loss: 0.04447 - acc: 0.9853 -- iter: 0256/2163
[A[ATraining Step: 1913  | total loss: [1m[32m0.04028[0m[0m | time: 93.678s
[2K
| Adam | epoch: 029 | loss: 0.04028 - acc: 0.9868 -- iter: 0288/2163
[A[ATraining Step: 1914  | total loss: [1m[32m0.04071[0m[0m | time: 101.407s
[2K
| Adam | epoch: 029 | loss: 0.04071 - acc: 0.9850 -- iter: 0320/2163
[A[ATraining Step: 1915  | total loss: [1m[32m0.03720[0m[0m | time: 109.093s
[2K
| Adam | epoch: 029 | loss: 0.03720 - acc: 0.9865 -- iter: 0352/2163
[A[ATraining Step: 1916  | total loss: [1m[32m0.05825[0m[0m | time: 117.271s
[2K
| Adam | epoch: 029 | loss: 0.05825 - acc: 0.9847 -- iter: 0384/2163
[A[ATraining Step: 1917  | total loss: [1m[32m0.05290[0m[0m | time: 129.297s
[2K
| Adam | epoch: 029 | loss: 0.05290 - acc: 0.9862 -- iter: 0416/2163
[A[ATraining Step: 1918  | total loss: [1m[32m0.05044[0m[0m | time: 142.241s
[2K
| Adam | epoch: 029 | loss: 0.05044 - acc: 0.9876 -- iter: 0448/2163
[A[ATraining Step: 1919  | total loss: [1m[32m0.04566[0m[0m | time: 155.453s
[2K
| Adam | epoch: 029 | loss: 0.04566 - acc: 0.9889 -- iter: 0480/2163
[A[ATraining Step: 1920  | total loss: [1m[32m0.04130[0m[0m | time: 167.561s
[2K
| Adam | epoch: 029 | loss: 0.04130 - acc: 0.9900 -- iter: 0512/2163
[A[ATraining Step: 1921  | total loss: [1m[32m0.03851[0m[0m | time: 177.888s
[2K
| Adam | epoch: 029 | loss: 0.03851 - acc: 0.9910 -- iter: 0544/2163
[A[ATraining Step: 1922  | total loss: [1m[32m0.03480[0m[0m | time: 185.595s
[2K
| Adam | epoch: 029 | loss: 0.03480 - acc: 0.9919 -- iter: 0576/2163
[A[ATraining Step: 1923  | total loss: [1m[32m0.03551[0m[0m | time: 193.381s
[2K
| Adam | epoch: 029 | loss: 0.03551 - acc: 0.9896 -- iter: 0608/2163
[A[ATraining Step: 1924  | total loss: [1m[32m0.03333[0m[0m | time: 201.053s
[2K
| Adam | epoch: 029 | loss: 0.03333 - acc: 0.9906 -- iter: 0640/2163
[A[ATraining Step: 1925  | total loss: [1m[32m0.03050[0m[0m | time: 208.807s
[2K
| Adam | epoch: 029 | loss: 0.03050 - acc: 0.9915 -- iter: 0672/2163
[A[ATraining Step: 1926  | total loss: [1m[32m0.02962[0m[0m | time: 220.105s
[2K
| Adam | epoch: 029 | loss: 0.02962 - acc: 0.9924 -- iter: 0704/2163
[A[ATraining Step: 1927  | total loss: [1m[32m0.02679[0m[0m | time: 232.652s
[2K
| Adam | epoch: 029 | loss: 0.02679 - acc: 0.9932 -- iter: 0736/2163
[A[ATraining Step: 1928  | total loss: [1m[32m0.02446[0m[0m | time: 245.510s
[2K
| Adam | epoch: 029 | loss: 0.02446 - acc: 0.9938 -- iter: 0768/2163
[A[ATraining Step: 1929  | total loss: [1m[32m0.02205[0m[0m | time: 258.178s
[2K
| Adam | epoch: 029 | loss: 0.02205 - acc: 0.9945 -- iter: 0800/2163
[A[ATraining Step: 1930  | total loss: [1m[32m0.02097[0m[0m | time: 269.258s
[2K
| Adam | epoch: 029 | loss: 0.02097 - acc: 0.9950 -- iter: 0832/2163
[A[ATraining Step: 1931  | total loss: [1m[32m0.01900[0m[0m | time: 274.327s
[2K
| Adam | epoch: 029 | loss: 0.01900 - acc: 0.9955 -- iter: 0864/2163
[A[ATraining Step: 1932  | total loss: [1m[32m0.01730[0m[0m | time: 279.625s
[2K
| Adam | epoch: 029 | loss: 0.01730 - acc: 0.9960 -- iter: 0896/2163
[A[ATraining Step: 1933  | total loss: [1m[32m0.01573[0m[0m | time: 287.642s
[2K
| Adam | epoch: 029 | loss: 0.01573 - acc: 0.9964 -- iter: 0928/2163
[A[ATraining Step: 1934  | total loss: [1m[32m0.01470[0m[0m | time: 298.621s
[2K
| Adam | epoch: 029 | loss: 0.01470 - acc: 0.9967 -- iter: 0960/2163
[A[ATraining Step: 1935  | total loss: [1m[32m0.01372[0m[0m | time: 311.423s
[2K
| Adam | epoch: 029 | loss: 0.01372 - acc: 0.9971 -- iter: 0992/2163
[A[ATraining Step: 1936  | total loss: [1m[32m0.01290[0m[0m | time: 324.755s
[2K
| Adam | epoch: 029 | loss: 0.01290 - acc: 0.9973 -- iter: 1024/2163
[A[ATraining Step: 1937  | total loss: [1m[32m0.02631[0m[0m | time: 337.917s
[2K
| Adam | epoch: 029 | loss: 0.02631 - acc: 0.9945 -- iter: 1056/2163
[A[ATraining Step: 1938  | total loss: [1m[32m0.02371[0m[0m | time: 346.053s
[2K
| Adam | epoch: 029 | loss: 0.02371 - acc: 0.9950 -- iter: 1088/2163
[A[ATraining Step: 1939  | total loss: [1m[32m0.02311[0m[0m | time: 353.895s
[2K
| Adam | epoch: 029 | loss: 0.02311 - acc: 0.9955 -- iter: 1120/2163
[A[ATraining Step: 1940  | total loss: [1m[32m0.02121[0m[0m | time: 361.613s
[2K
| Adam | epoch: 029 | loss: 0.02121 - acc: 0.9960 -- iter: 1152/2163
[A[ATraining Step: 1941  | total loss: [1m[32m0.01933[0m[0m | time: 374.535s
[2K
| Adam | epoch: 029 | loss: 0.01933 - acc: 0.9964 -- iter: 1184/2163
[A[ATraining Step: 1942  | total loss: [1m[32m0.01789[0m[0m | time: 385.595s
[2K
| Adam | epoch: 029 | loss: 0.01789 - acc: 0.9967 -- iter: 1216/2163
[A[ATraining Step: 1943  | total loss: [1m[32m0.01614[0m[0m | time: 398.722s
[2K
| Adam | epoch: 029 | loss: 0.01614 - acc: 0.9971 -- iter: 1248/2163
[A[ATraining Step: 1944  | total loss: [1m[32m0.01469[0m[0m | time: 411.299s
[2K
| Adam | epoch: 029 | loss: 0.01469 - acc: 0.9974 -- iter: 1280/2163
[A[ATraining Step: 1945  | total loss: [1m[32m0.01480[0m[0m | time: 419.642s
[2K
| Adam | epoch: 029 | loss: 0.01480 - acc: 0.9976 -- iter: 1312/2163
[A[ATraining Step: 1946  | total loss: [1m[32m0.01444[0m[0m | time: 427.558s
[2K
| Adam | epoch: 029 | loss: 0.01444 - acc: 0.9979 -- iter: 1344/2163
[A[ATraining Step: 1947  | total loss: [1m[32m0.01307[0m[0m | time: 435.322s
[2K
| Adam | epoch: 029 | loss: 0.01307 - acc: 0.9981 -- iter: 1376/2163
[A[ATraining Step: 1948  | total loss: [1m[32m0.01197[0m[0m | time: 447.172s
[2K
| Adam | epoch: 029 | loss: 0.01197 - acc: 0.9983 -- iter: 1408/2163
[A[ATraining Step: 1949  | total loss: [1m[32m0.01163[0m[0m | time: 459.691s
[2K
| Adam | epoch: 029 | loss: 0.01163 - acc: 0.9984 -- iter: 1440/2163
[A[ATraining Step: 1950  | total loss: [1m[32m0.01715[0m[0m | time: 471.098s
[2K
| Adam | epoch: 029 | loss: 0.01715 - acc: 0.9955 -- iter: 1472/2163
[A[ATraining Step: 1951  | total loss: [1m[32m0.01610[0m[0m | time: 484.020s
[2K
| Adam | epoch: 029 | loss: 0.01610 - acc: 0.9959 -- iter: 1504/2163
[A[ATraining Step: 1952  | total loss: [1m[32m0.01498[0m[0m | time: 493.558s
[2K
| Adam | epoch: 029 | loss: 0.01498 - acc: 0.9963 -- iter: 1536/2163
[A[ATraining Step: 1953  | total loss: [1m[32m0.01373[0m[0m | time: 501.370s
[2K
| Adam | epoch: 029 | loss: 0.01373 - acc: 0.9967 -- iter: 1568/2163
[A[ATraining Step: 1954  | total loss: [1m[32m0.01243[0m[0m | time: 509.219s
[2K
| Adam | epoch: 029 | loss: 0.01243 - acc: 0.9970 -- iter: 1600/2163
[A[ATraining Step: 1955  | total loss: [1m[32m0.01413[0m[0m | time: 521.505s
[2K
| Adam | epoch: 029 | loss: 0.01413 - acc: 0.9973 -- iter: 1632/2163
[A[ATraining Step: 1956  | total loss: [1m[32m0.01280[0m[0m | time: 534.141s
[2K
| Adam | epoch: 029 | loss: 0.01280 - acc: 0.9976 -- iter: 1664/2163
[A[ATraining Step: 1957  | total loss: [1m[32m0.01271[0m[0m | time: 546.933s
[2K
| Adam | epoch: 029 | loss: 0.01271 - acc: 0.9978 -- iter: 1696/2163
[A[ATraining Step: 1958  | total loss: [1m[32m0.01164[0m[0m | time: 558.153s
[2K
| Adam | epoch: 029 | loss: 0.01164 - acc: 0.9981 -- iter: 1728/2163
[A[ATraining Step: 1959  | total loss: [1m[32m0.01089[0m[0m | time: 567.205s
[2K
| Adam | epoch: 029 | loss: 0.01089 - acc: 0.9982 -- iter: 1760/2163
[A[ATraining Step: 1960  | total loss: [1m[32m0.01005[0m[0m | time: 575.141s
[2K
| Adam | epoch: 029 | loss: 0.01005 - acc: 0.9984 -- iter: 1792/2163
[A[ATraining Step: 1961  | total loss: [1m[32m0.00922[0m[0m | time: 582.815s
[2K
| Adam | epoch: 029 | loss: 0.00922 - acc: 0.9986 -- iter: 1824/2163
[A[ATraining Step: 1962  | total loss: [1m[32m0.00836[0m[0m | time: 590.580s
[2K
| Adam | epoch: 029 | loss: 0.00836 - acc: 0.9987 -- iter: 1856/2163
[A[ATraining Step: 1963  | total loss: [1m[32m0.00813[0m[0m | time: 601.217s
[2K
| Adam | epoch: 029 | loss: 0.00813 - acc: 0.9988 -- iter: 1888/2163
[A[ATraining Step: 1964  | total loss: [1m[32m0.00782[0m[0m | time: 609.106s
[2K
| Adam | epoch: 029 | loss: 0.00782 - acc: 0.9990 -- iter: 1920/2163
[A[ATraining Step: 1965  | total loss: [1m[32m0.00712[0m[0m | time: 616.896s
[2K
| Adam | epoch: 029 | loss: 0.00712 - acc: 0.9991 -- iter: 1952/2163
[A[ATraining Step: 1966  | total loss: [1m[32m0.00696[0m[0m | time: 624.702s
[2K
| Adam | epoch: 029 | loss: 0.00696 - acc: 0.9992 -- iter: 1984/2163
[A[ATraining Step: 1967  | total loss: [1m[32m0.00691[0m[0m | time: 632.632s
[2K
| Adam | epoch: 029 | loss: 0.00691 - acc: 0.9992 -- iter: 2016/2163
[A[ATraining Step: 1968  | total loss: [1m[32m0.00786[0m[0m | time: 640.333s
[2K
| Adam | epoch: 029 | loss: 0.00786 - acc: 0.9993 -- iter: 2048/2163
[A[ATraining Step: 1969  | total loss: [1m[32m0.04653[0m[0m | time: 648.245s
[2K
| Adam | epoch: 029 | loss: 0.04653 - acc: 0.9931 -- iter: 2080/2163
[A[ATraining Step: 1970  | total loss: [1m[32m0.04261[0m[0m | time: 656.079s
[2K
| Adam | epoch: 029 | loss: 0.04261 - acc: 0.9938 -- iter: 2112/2163
[A[ATraining Step: 1971  | total loss: [1m[32m0.04216[0m[0m | time: 663.924s
[2K
| Adam | epoch: 029 | loss: 0.04216 - acc: 0.9913 -- iter: 2144/2163
[A[ATraining Step: 1972  | total loss: [1m[32m0.03826[0m[0m | time: 702.057s
[2K
| Adam | epoch: 029 | loss: 0.03826 - acc: 0.9922 | val_loss: 0.40513 - val_acc: 0.9010 -- iter: 2163/2163
--
Training Step: 1973  | total loss: [1m[32m0.03467[0m[0m | time: 7.987s
[2K
| Adam | epoch: 030 | loss: 0.03467 - acc: 0.9930 -- iter: 0032/2163
[A[ATraining Step: 1974  | total loss: [1m[32m0.03320[0m[0m | time: 15.768s
[2K
| Adam | epoch: 030 | loss: 0.03320 - acc: 0.9937 -- iter: 0064/2163
[A[ATraining Step: 1975  | total loss: [1m[32m0.03077[0m[0m | time: 23.460s
[2K
| Adam | epoch: 030 | loss: 0.03077 - acc: 0.9943 -- iter: 0096/2163
[A[ATraining Step: 1976  | total loss: [1m[32m0.02777[0m[0m | time: 31.198s
[2K
| Adam | epoch: 030 | loss: 0.02777 - acc: 0.9949 -- iter: 0128/2163
[A[ATraining Step: 1977  | total loss: [1m[32m0.03222[0m[0m | time: 38.942s
[2K
| Adam | epoch: 030 | loss: 0.03222 - acc: 0.9923 -- iter: 0160/2163
[A[ATraining Step: 1978  | total loss: [1m[32m0.03109[0m[0m | time: 46.652s
[2K
| Adam | epoch: 030 | loss: 0.03109 - acc: 0.9930 -- iter: 0192/2163
[A[ATraining Step: 1979  | total loss: [1m[32m0.03202[0m[0m | time: 54.491s
[2K
| Adam | epoch: 030 | loss: 0.03202 - acc: 0.9906 -- iter: 0224/2163
[A[ATraining Step: 1980  | total loss: [1m[32m0.02914[0m[0m | time: 62.370s
[2K
| Adam | epoch: 030 | loss: 0.02914 - acc: 0.9915 -- iter: 0256/2163
[A[ATraining Step: 1981  | total loss: [1m[32m0.04088[0m[0m | time: 70.004s
[2K
| Adam | epoch: 030 | loss: 0.04088 - acc: 0.9893 -- iter: 0288/2163
[A[ATraining Step: 1982  | total loss: [1m[32m0.04041[0m[0m | time: 77.871s
[2K
| Adam | epoch: 030 | loss: 0.04041 - acc: 0.9872 -- iter: 0320/2163
[A[ATraining Step: 1983  | total loss: [1m[32m0.03733[0m[0m | time: 85.619s
[2K
| Adam | epoch: 030 | loss: 0.03733 - acc: 0.9885 -- iter: 0352/2163
[A[ATraining Step: 1984  | total loss: [1m[32m0.03387[0m[0m | time: 93.597s
[2K
| Adam | epoch: 030 | loss: 0.03387 - acc: 0.9896 -- iter: 0384/2163
[A[ATraining Step: 1985  | total loss: [1m[32m0.03064[0m[0m | time: 101.574s
[2K
| Adam | epoch: 030 | loss: 0.03064 - acc: 0.9907 -- iter: 0416/2163
[A[ATraining Step: 1986  | total loss: [1m[32m0.02818[0m[0m | time: 109.361s
[2K
| Adam | epoch: 030 | loss: 0.02818 - acc: 0.9916 -- iter: 0448/2163
[A[ATraining Step: 1987  | total loss: [1m[32m0.02626[0m[0m | time: 117.286s
[2K
| Adam | epoch: 030 | loss: 0.02626 - acc: 0.9925 -- iter: 0480/2163
[A[ATraining Step: 1988  | total loss: [1m[32m0.02442[0m[0m | time: 125.077s
[2K
| Adam | epoch: 030 | loss: 0.02442 - acc: 0.9932 -- iter: 0512/2163
[A[ATraining Step: 1989  | total loss: [1m[32m0.02735[0m[0m | time: 132.869s
[2K
| Adam | epoch: 030 | loss: 0.02735 - acc: 0.9908 -- iter: 0544/2163
[A[ATraining Step: 1990  | total loss: [1m[32m0.02594[0m[0m | time: 140.757s
[2K
| Adam | epoch: 030 | loss: 0.02594 - acc: 0.9917 -- iter: 0576/2163
[A[ATraining Step: 1991  | total loss: [1m[32m0.02437[0m[0m | time: 148.626s
[2K
| Adam | epoch: 030 | loss: 0.02437 - acc: 0.9925 -- iter: 0608/2163
[A[ATraining Step: 1992  | total loss: [1m[32m0.02330[0m[0m | time: 156.496s
[2K
| Adam | epoch: 030 | loss: 0.02330 - acc: 0.9933 -- iter: 0640/2163
[A[ATraining Step: 1993  | total loss: [1m[32m0.02326[0m[0m | time: 164.490s
[2K
| Adam | epoch: 030 | loss: 0.02326 - acc: 0.9908 -- iter: 0672/2163
[A[ATraining Step: 1994  | total loss: [1m[32m0.02114[0m[0m | time: 172.315s
[2K
| Adam | epoch: 030 | loss: 0.02114 - acc: 0.9917 -- iter: 0704/2163
[A[ATraining Step: 1995  | total loss: [1m[32m0.02060[0m[0m | time: 180.011s
[2K
| Adam | epoch: 030 | loss: 0.02060 - acc: 0.9926 -- iter: 0736/2163
[A[ATraining Step: 1996  | total loss: [1m[32m0.01879[0m[0m | time: 187.822s
[2K
| Adam | epoch: 030 | loss: 0.01879 - acc: 0.9933 -- iter: 0768/2163
[A[ATraining Step: 1997  | total loss: [1m[32m0.01840[0m[0m | time: 195.695s
[2K
| Adam | epoch: 030 | loss: 0.01840 - acc: 0.9940 -- iter: 0800/2163
[A[ATraining Step: 1998  | total loss: [1m[32m0.01685[0m[0m | time: 203.488s
[2K
| Adam | epoch: 030 | loss: 0.01685 - acc: 0.9946 -- iter: 0832/2163
[A[ATraining Step: 1999  | total loss: [1m[32m0.01529[0m[0m | time: 211.591s
[2K
| Adam | epoch: 030 | loss: 0.01529 - acc: 0.9951 -- iter: 0864/2163
[A[ATraining Step: 2000  | total loss: [1m[32m0.01403[0m[0m | time: 246.891s
[2K
| Adam | epoch: 030 | loss: 0.01403 - acc: 0.9956 | val_loss: 0.84965 - val_acc: 0.8257 -- iter: 0896/2163
--
Training Step: 2001  | total loss: [1m[32m0.01271[0m[0m | time: 252.004s
[2K
| Adam | epoch: 030 | loss: 0.01271 - acc: 0.9960 -- iter: 0928/2163
[A[ATraining Step: 2002  | total loss: [1m[32m0.01151[0m[0m | time: 259.589s
[2K
| Adam | epoch: 030 | loss: 0.01151 - acc: 0.9964 -- iter: 0960/2163
[A[ATraining Step: 2003  | total loss: [1m[32m0.01275[0m[0m | time: 267.470s
[2K
| Adam | epoch: 030 | loss: 0.01275 - acc: 0.9968 -- iter: 0992/2163
[A[ATraining Step: 2004  | total loss: [1m[32m0.06604[0m[0m | time: 275.416s
[2K
| Adam | epoch: 030 | loss: 0.06604 - acc: 0.9940 -- iter: 1024/2163
[A[ATraining Step: 2005  | total loss: [1m[32m0.05969[0m[0m | time: 283.191s
[2K
| Adam | epoch: 030 | loss: 0.05969 - acc: 0.9946 -- iter: 1056/2163
[A[ATraining Step: 2006  | total loss: [1m[32m0.05397[0m[0m | time: 290.850s
[2K
| Adam | epoch: 030 | loss: 0.05397 - acc: 0.9951 -- iter: 1088/2163
[A[ATraining Step: 2007  | total loss: [1m[32m0.04859[0m[0m | time: 298.620s
[2K
| Adam | epoch: 030 | loss: 0.04859 - acc: 0.9956 -- iter: 1120/2163
[A[ATraining Step: 2008  | total loss: [1m[32m0.04400[0m[0m | time: 306.483s
[2K
| Adam | epoch: 030 | loss: 0.04400 - acc: 0.9961 -- iter: 1152/2163
[A[ATraining Step: 2009  | total loss: [1m[32m0.03985[0m[0m | time: 314.332s
[2K
| Adam | epoch: 030 | loss: 0.03985 - acc: 0.9965 -- iter: 1184/2163
[A[ATraining Step: 2010  | total loss: [1m[32m0.03599[0m[0m | time: 322.198s
[2K
| Adam | epoch: 030 | loss: 0.03599 - acc: 0.9968 -- iter: 1216/2163
[A[ATraining Step: 2011  | total loss: [1m[32m0.04327[0m[0m | time: 329.966s
[2K
| Adam | epoch: 030 | loss: 0.04327 - acc: 0.9909 -- iter: 1248/2163
[A[ATraining Step: 2012  | total loss: [1m[32m0.04124[0m[0m | time: 337.852s
[2K
| Adam | epoch: 030 | loss: 0.04124 - acc: 0.9918 -- iter: 1280/2163
[A[ATraining Step: 2013  | total loss: [1m[32m0.03786[0m[0m | time: 345.701s
[2K
| Adam | epoch: 030 | loss: 0.03786 - acc: 0.9926 -- iter: 1312/2163
[A[ATraining Step: 2014  | total loss: [1m[32m0.03438[0m[0m | time: 353.715s
[2K
| Adam | epoch: 030 | loss: 0.03438 - acc: 0.9933 -- iter: 1344/2163
[A[ATraining Step: 2015  | total loss: [1m[32m0.03102[0m[0m | time: 361.603s
[2K
| Adam | epoch: 030 | loss: 0.03102 - acc: 0.9940 -- iter: 1376/2163
[A[ATraining Step: 2016  | total loss: [1m[32m0.03149[0m[0m | time: 369.357s
[2K
| Adam | epoch: 030 | loss: 0.03149 - acc: 0.9915 -- iter: 1408/2163
[A[ATraining Step: 2017  | total loss: [1m[32m0.02878[0m[0m | time: 377.444s
[2K
| Adam | epoch: 030 | loss: 0.02878 - acc: 0.9923 -- iter: 1440/2163
[A[ATraining Step: 2018  | total loss: [1m[32m0.03003[0m[0m | time: 385.279s
[2K
| Adam | epoch: 030 | loss: 0.03003 - acc: 0.9931 -- iter: 1472/2163
[A[ATraining Step: 2019  | total loss: [1m[32m0.08533[0m[0m | time: 393.044s
[2K
| Adam | epoch: 030 | loss: 0.08533 - acc: 0.9907 -- iter: 1504/2163
[A[ATraining Step: 2020  | total loss: [1m[32m0.09297[0m[0m | time: 400.893s
[2K
| Adam | epoch: 030 | loss: 0.09297 - acc: 0.9854 -- iter: 1536/2163
[A[ATraining Step: 2021  | total loss: [1m[32m0.08425[0m[0m | time: 408.616s
[2K
| Adam | epoch: 030 | loss: 0.08425 - acc: 0.9868 -- iter: 1568/2163
[A[ATraining Step: 2022  | total loss: [1m[32m0.07590[0m[0m | time: 416.502s
[2K
| Adam | epoch: 030 | loss: 0.07590 - acc: 0.9881 -- iter: 1600/2163
[A[ATraining Step: 2023  | total loss: [1m[32m0.07069[0m[0m | time: 424.389s
[2K
| Adam | epoch: 030 | loss: 0.07069 - acc: 0.9893 -- iter: 1632/2163
[A[ATraining Step: 2024  | total loss: [1m[32m0.06381[0m[0m | time: 432.142s
[2K
| Adam | epoch: 030 | loss: 0.06381 - acc: 0.9904 -- iter: 1664/2163
[A[ATraining Step: 2025  | total loss: [1m[32m0.05850[0m[0m | time: 439.897s
[2K
| Adam | epoch: 030 | loss: 0.05850 - acc: 0.9914 -- iter: 1696/2163
[A[ATraining Step: 2026  | total loss: [1m[32m0.05764[0m[0m | time: 447.711s
[2K
| Adam | epoch: 030 | loss: 0.05764 - acc: 0.9891 -- iter: 1728/2163
[A[ATraining Step: 2027  | total loss: [1m[32m0.05566[0m[0m | time: 455.627s
[2K
| Adam | epoch: 030 | loss: 0.05566 - acc: 0.9871 -- iter: 1760/2163
[A[ATraining Step: 2028  | total loss: [1m[32m0.05109[0m[0m | time: 463.550s
[2K
| Adam | epoch: 030 | loss: 0.05109 - acc: 0.9884 -- iter: 1792/2163
[A[ATraining Step: 2029  | total loss: [1m[32m0.04649[0m[0m | time: 471.233s
[2K
| Adam | epoch: 030 | loss: 0.04649 - acc: 0.9895 -- iter: 1824/2163
[A[ATraining Step: 2030  | total loss: [1m[32m0.04254[0m[0m | time: 478.952s
[2K
| Adam | epoch: 030 | loss: 0.04254 - acc: 0.9906 -- iter: 1856/2163
[A[ATraining Step: 2031  | total loss: [1m[32m0.04191[0m[0m | time: 486.792s
[2K
| Adam | epoch: 030 | loss: 0.04191 - acc: 0.9884 -- iter: 1888/2163
[A[ATraining Step: 2032  | total loss: [1m[32m0.03797[0m[0m | time: 494.655s
[2K
| Adam | epoch: 030 | loss: 0.03797 - acc: 0.9895 -- iter: 1920/2163
[A[ATraining Step: 2033  | total loss: [1m[32m0.03495[0m[0m | time: 502.364s
[2K
| Adam | epoch: 030 | loss: 0.03495 - acc: 0.9906 -- iter: 1952/2163
[A[ATraining Step: 2034  | total loss: [1m[32m0.03159[0m[0m | time: 510.044s
[2K
| Adam | epoch: 030 | loss: 0.03159 - acc: 0.9915 -- iter: 1984/2163
[A[ATraining Step: 2035  | total loss: [1m[32m0.03348[0m[0m | time: 517.788s
[2K
| Adam | epoch: 030 | loss: 0.03348 - acc: 0.9893 -- iter: 2016/2163
[A[ATraining Step: 2036  | total loss: [1m[32m0.03031[0m[0m | time: 525.685s
[2K
| Adam | epoch: 030 | loss: 0.03031 - acc: 0.9903 -- iter: 2048/2163
[A[ATraining Step: 2037  | total loss: [1m[32m0.03011[0m[0m | time: 533.464s
[2K
| Adam | epoch: 030 | loss: 0.03011 - acc: 0.9913 -- iter: 2080/2163
[A[ATraining Step: 2038  | total loss: [1m[32m0.05260[0m[0m | time: 541.254s
[2K
| Adam | epoch: 030 | loss: 0.05260 - acc: 0.9890 -- iter: 2112/2163
[A[ATraining Step: 2039  | total loss: [1m[32m0.04781[0m[0m | time: 549.106s
[2K
| Adam | epoch: 030 | loss: 0.04781 - acc: 0.9901 -- iter: 2144/2163
[A[ATraining Step: 2040  | total loss: [1m[32m0.04359[0m[0m | time: 587.284s
[2K
| Adam | epoch: 030 | loss: 0.04359 - acc: 0.9911 | val_loss: 0.18433 - val_acc: 0.9394 -- iter: 2163/2163
--
Validation AUC:0.9845173677779717
Validation AUPRC:0.9813992231725169
Test AUC:0.9891494421711607
Test AUPRC:0.9885627520025388
BestTestF1Score	0.95	0.91	0.96	0.95	0.96	311	17	336	13	0.75
BestTestMCCScore	0.95	0.91	0.96	0.95	0.96	311	17	336	13	0.75
BestTestAccuracyScore	0.95	0.91	0.96	0.95	0.96	311	17	336	13	0.75
BestValidationF1Score	0.95	0.9	0.95	0.95	0.94	318	15	325	19	0.75
BestValidationMCC	0.95	0.9	0.95	0.95	0.94	318	15	325	19	0.75
BestValidationAccuracy	0.95	0.9	0.95	0.95	0.94	318	15	325	19	0.75
TestPredictions (Threshold:0.75)
CHEMBL3669534,TP,ACT,0.9900000095367432	CHEMBL540896,TN,INACT,0.0	CHEMBL33438,TN,INACT,0.07000000029802322	CHEMBL297473,TN,INACT,0.0	CHEMBL7442,TN,INACT,0.0	CHEMBL3114163,TN,INACT,0.0	CHEMBL240773,TN,INACT,0.0	CHEMBL291516,TN,INACT,0.019999999552965164	CHEMBL1488893,TN,INACT,0.009999999776482582	CHEMBL3634006,TP,ACT,1.0	CHEMBL160932,TN,INACT,0.12999999523162842	CHEMBL3622333,TP,ACT,1.0	CHEMBL3665724,TP,ACT,1.0	CHEMBL3667581,TP,ACT,0.9900000095367432	CHEMBL2413082,FN,ACT,0.4000000059604645	CHEMBL3704970,TP,ACT,1.0	CHEMBL416453,TN,INACT,0.0	CHEMBL3649218,TP,ACT,1.0	CHEMBL661,TN,INACT,0.009999999776482582	CHEMBL124822,TN,INACT,0.0	CHEMBL17857,TN,INACT,0.0	CHEMBL3663398,TP,ACT,1.0	CHEMBL67060,TN,INACT,0.0	CHEMBL3665703,TP,ACT,0.9900000095367432	CHEMBL1782794,TN,INACT,0.0	CHEMBL42411,TN,INACT,0.0	CHEMBL2112561,TN,INACT,0.0	CHEMBL3410305,TN,INACT,0.0	CHEMBL70728,TN,INACT,0.05000000074505806	CHEMBL3739451,TP,ACT,1.0	CHEMBL3114164,TN,INACT,0.0	CHEMBL3642146,TP,ACT,1.0	CHEMBL3665624,TP,ACT,1.0	CHEMBL2381771,TN,INACT,0.0	CHEMBL239819,FP,INACT,1.0	CHEMBL3663530,TP,ACT,1.0	CHEMBL3426135,TP,ACT,1.0	CHEMBL338045,TN,INACT,0.0	CHEMBL3663447,TP,ACT,1.0	CHEMBL2435402,TP,ACT,1.0	CHEMBL2391353,TN,INACT,0.029999999329447746	CHEMBL3649060,TP,ACT,1.0	CHEMBL438297,FP,INACT,0.9900000095367432	CHEMBL3680371,TP,ACT,1.0	CHEMBL97436,TN,INACT,0.0	CHEMBL302150,TN,INACT,0.019999999552965164	CHEMBL3646207,TP,ACT,1.0	CHEMBL3741978,TP,ACT,0.9900000095367432	CHEMBL72670,TN,INACT,0.0	CHEMBL491086,TP,ACT,1.0	CHEMBL113,TN,INACT,0.0	CHEMBL3403741,TN,INACT,0.4000000059604645	CHEMBL24759,TN,INACT,0.009999999776482582	CHEMBL3667563,FN,ACT,0.7099999785423279	CHEMBL62421,TN,INACT,0.0	CHEMBL64727,TN,INACT,0.07000000029802322	CHEMBL3649140,TP,ACT,0.9399999976158142	CHEMBL3736248,TN,INACT,0.019999999552965164	CHEMBL3327375,TN,INACT,0.0	CHEMBL3085879,TN,INACT,0.009999999776482582	CHEMBL323074,TN,INACT,0.0	CHEMBL416069,TN,INACT,0.009999999776482582	CHEMBL3669564,TP,ACT,1.0	CHEMBL3670630,TP,ACT,1.0	CHEMBL3649065,TP,ACT,1.0	CHEMBL3665737,TP,ACT,0.9900000095367432	CHEMBL446698,TN,INACT,0.550000011920929	CHEMBL309194,TN,INACT,0.009999999776482582	CHEMBL280367,TN,INACT,0.0	CHEMBL336033,TN,INACT,0.33000001311302185	CHEMBL3670512,TP,ACT,1.0	CHEMBL3659202,TP,ACT,1.0	CHEMBL294849,TN,INACT,0.0	CHEMBL129014,TN,INACT,0.0	CHEMBL3680364,TP,ACT,1.0	CHEMBL3665730,TP,ACT,1.0	CHEMBL279898,TN,INACT,0.0	CHEMBL3665640,TP,ACT,1.0	CHEMBL3663553,TP,ACT,1.0	CHEMBL3670529,TP,ACT,1.0	CHEMBL3585936,TP,ACT,1.0	CHEMBL2435403,TP,ACT,1.0	CHEMBL276819,FP,INACT,0.8299999833106995	CHEMBL2369493,TN,INACT,0.0	CHEMBL3799379,TN,INACT,0.0	CHEMBL322537,TN,INACT,0.0	CHEMBL619,TN,INACT,0.07999999821186066	CHEMBL2425783,TP,ACT,0.9300000071525574	CHEMBL3343257,FN,ACT,0.23000000417232513	CHEMBL828,TN,INACT,0.0	CHEMBL311341,TN,INACT,0.019999999552965164	CHEMBL101554,TN,INACT,0.0	CHEMBL436180,TN,INACT,0.0	CHEMBL58241,TN,INACT,0.0	CHEMBL1223631,TN,INACT,0.029999999329447746	CHEMBL3670522,TP,ACT,1.0	CHEMBL221691,TN,INACT,0.0	CHEMBL2413521,TP,ACT,0.9800000190734863	CHEMBL3665619,TP,ACT,0.9599999785423279	CHEMBL3665626,TP,ACT,0.9599999785423279	CHEMBL74515,TN,INACT,0.0	CHEMBL374602,TN,INACT,0.18000000715255737	CHEMBL91362,TN,INACT,0.1599999964237213	CHEMBL3663507,TP,ACT,0.9900000095367432	CHEMBL2398752,FP,INACT,0.8399999737739563	CHEMBL541164,TN,INACT,0.0	CHEMBL404153,TP,ACT,1.0	CHEMBL3667584,TP,ACT,1.0	CHEMBL3665649,TP,ACT,1.0	CHEMBL73133,TN,INACT,0.0	CHEMBL102452,TN,INACT,0.0	CHEMBL3669532,TP,ACT,1.0	CHEMBL608748,TN,INACT,0.0	CHEMBL3663444,TP,ACT,1.0	CHEMBL3677853,TN,INACT,0.0	CHEMBL27995,TN,INACT,0.0	CHEMBL89093,TN,INACT,0.28999999165534973	CHEMBL3652444,TP,ACT,1.0	CHEMBL3649042,TP,ACT,1.0	CHEMBL3608763,TN,INACT,0.019999999552965164	CHEMBL3290766,TN,INACT,0.029999999329447746	CHEMBL3741721,TP,ACT,1.0	CHEMBL374336,TN,INACT,0.0	CHEMBL3665440,TN,INACT,0.019999999552965164	CHEMBL3665631,TP,ACT,1.0	CHEMBL347423,TN,INACT,0.0	CHEMBL3649226,TP,ACT,0.9900000095367432	CHEMBL341825,TN,INACT,0.0	CHEMBL3143400,TN,INACT,0.009999999776482582	CHEMBL3343239,FN,ACT,0.6700000166893005	CHEMBL411,TN,INACT,0.0	CHEMBL3667551,TP,ACT,1.0	CHEMBL52741,TN,INACT,0.0	CHEMBL236442,TN,INACT,0.0	CHEMBL115853,TN,INACT,0.44999998807907104	CHEMBL3659242,TP,ACT,0.9100000262260437	CHEMBL3290984,TN,INACT,0.0	CHEMBL3704935,TP,ACT,1.0	CHEMBL99331,TN,INACT,0.0	CHEMBL3663469,TP,ACT,1.0	CHEMBL323245,TN,INACT,0.0	CHEMBL42129,TN,INACT,0.0	CHEMBL76874,TN,INACT,0.20000000298023224	CHEMBL3652450,TP,ACT,1.0	CHEMBL3659185,TP,ACT,1.0	CHEMBL3691837,TP,ACT,1.0	CHEMBL47404,TN,INACT,0.25	CHEMBL95589,TN,INACT,0.0	CHEMBL3669555,TP,ACT,1.0	CHEMBL20168,TN,INACT,0.0	CHEMBL3670521,TP,ACT,1.0	CHEMBL3099892,TP,ACT,1.0	CHEMBL133868,TN,INACT,0.0	CHEMBL88506,TN,INACT,0.0	CHEMBL110904,TN,INACT,0.029999999329447746	CHEMBL123852,TN,INACT,0.0	CHEMBL78080,TN,INACT,0.0	CHEMBL328812,TN,INACT,0.25	CHEMBL3669472,TP,ACT,1.0	CHEMBL304009,TN,INACT,0.0	CHEMBL3649107,TP,ACT,1.0	CHEMBL30026,TN,INACT,0.0	CHEMBL282126,TN,INACT,0.0	CHEMBL3622329,TP,ACT,1.0	CHEMBL539334,TN,INACT,0.019999999552965164	CHEMBL3649111,TP,ACT,1.0	CHEMBL396303,TN,INACT,0.0	CHEMBL96365,TN,INACT,0.0	CHEMBL1782798,TN,INACT,0.009999999776482582	CHEMBL3634009,TP,ACT,0.9800000190734863	CHEMBL594801,TN,INACT,0.0	CHEMBL3649121,TP,ACT,1.0	CHEMBL3394844,TP,ACT,1.0	CHEMBL104223,TN,INACT,0.46000000834465027	CHEMBL3586441,TP,ACT,0.9900000095367432	CHEMBL3669546,TP,ACT,1.0	CHEMBL184596,TP,ACT,1.0	CHEMBL328895,TN,INACT,0.009999999776482582	CHEMBL3649139,TP,ACT,0.9900000095367432	CHEMBL291293,FP,INACT,0.9700000286102295	CHEMBL646,TN,INACT,0.0	CHEMBL3290994,TN,INACT,0.0	CHEMBL107155,TN,INACT,0.019999999552965164	CHEMBL3663409,TP,ACT,1.0	CHEMBL3649094,TP,ACT,0.9900000095367432	CHEMBL3665623,TP,ACT,1.0	CHEMBL3659200,TP,ACT,1.0	CHEMBL115670,TN,INACT,0.0	CHEMBL92364,TN,INACT,0.0	CHEMBL296715,TN,INACT,0.0	CHEMBL3652465,TP,ACT,1.0	CHEMBL3646208,TP,ACT,1.0	CHEMBL3642127,TP,ACT,1.0	CHEMBL3680366,TP,ACT,1.0	CHEMBL3663481,TP,ACT,1.0	CHEMBL3665435,TN,INACT,0.029999999329447746	CHEMBL301826,TN,INACT,0.009999999776482582	CHEMBL3585948,TP,ACT,1.0	CHEMBL226694,TN,INACT,0.25	CHEMBL3649032,TP,ACT,0.9900000095367432	CHEMBL118954,TN,INACT,0.009999999776482582	CHEMBL419997,TN,INACT,0.0	CHEMBL3642148,TP,ACT,1.0	CHEMBL44262,TN,INACT,0.0	CHEMBL3735265,TN,INACT,0.0	CHEMBL3663527,TP,ACT,1.0	CHEMBL3426154,FN,ACT,0.6700000166893005	CHEMBL124751,TN,INACT,0.0	CHEMBL589,TN,INACT,0.0	CHEMBL3669031,TP,ACT,1.0	CHEMBL422407,TN,INACT,0.0	CHEMBL241082,TN,INACT,0.44999998807907104	CHEMBL3667570,TP,ACT,1.0	CHEMBL63289,TN,INACT,0.029999999329447746	CHEMBL3670603,TP,ACT,1.0	CHEMBL3670527,TP,ACT,1.0	CHEMBL3649228,TP,ACT,1.0	CHEMBL3634328,TN,INACT,0.0	CHEMBL3691851,TP,ACT,1.0	CHEMBL76860,TN,INACT,0.0	CHEMBL3260826,TP,ACT,1.0	CHEMBL2042551,TN,INACT,0.0	CHEMBL3652508,TP,ACT,0.9900000095367432	CHEMBL3669023,TP,ACT,1.0	CHEMBL3672926,TP,ACT,1.0	CHEMBL3670543,TP,ACT,1.0	CHEMBL3663404,TP,ACT,1.0	CHEMBL3680362,TP,ACT,1.0	CHEMBL3659189,TP,ACT,1.0	CHEMBL3640038,TP,ACT,1.0	CHEMBL3659208,TP,ACT,1.0	CHEMBL277079,TN,INACT,0.0	CHEMBL356923,TN,INACT,0.36000001430511475	CHEMBL3670517,TP,ACT,1.0	CHEMBL71726,TN,INACT,0.10000000149011612	CHEMBL3741853,FN,ACT,0.009999999776482582	CHEMBL3663551,TP,ACT,1.0	CHEMBL325043,TN,INACT,0.0	CHEMBL3667572,TP,ACT,0.9900000095367432	CHEMBL3260825,TP,ACT,1.0	CHEMBL3659204,TP,ACT,1.0	CHEMBL241099,TN,INACT,0.10999999940395355	CHEMBL300926,FP,INACT,0.9300000071525574	CHEMBL3670524,TP,ACT,1.0	CHEMBL74170,TN,INACT,0.0	CHEMBL89953,TN,INACT,0.0	CHEMBL286214,TN,INACT,0.03999999910593033	CHEMBL1907845,TN,INACT,0.0	CHEMBL3659193,TP,ACT,1.0	CHEMBL3426132,TP,ACT,1.0	CHEMBL3669047,TP,ACT,1.0	CHEMBL296245,TN,INACT,0.009999999776482582	CHEMBL3586323,TN,INACT,0.029999999329447746	CHEMBL68738,TN,INACT,0.07999999821186066	CHEMBL3649112,TP,ACT,0.9800000190734863	CHEMBL1158,TN,INACT,0.0	CHEMBL3642123,TP,ACT,1.0	CHEMBL3585951,TP,ACT,1.0	CHEMBL3403345,TN,INACT,0.30000001192092896	CHEMBL417358,TN,INACT,0.029999999329447746	CHEMBL104210,TN,INACT,0.0	CHEMBL3649077,TP,ACT,0.9900000095367432	CHEMBL98038,TN,INACT,0.0	CHEMBL3343258,TP,ACT,1.0	CHEMBL3704942,TP,ACT,1.0	CHEMBL2112674,TN,INACT,0.0	CHEMBL123785,TN,INACT,0.0	CHEMBL3235264,TP,ACT,1.0	CHEMBL3649095,TP,ACT,0.9900000095367432	CHEMBL3394831,TP,ACT,1.0	CHEMBL74852,TN,INACT,0.03999999910593033	CHEMBL3670623,TP,ACT,1.0	CHEMBL25373,TN,INACT,0.0	CHEMBL2413372,TP,ACT,0.8500000238418579	CHEMBL3669478,TP,ACT,1.0	CHEMBL3545367,TP,ACT,1.0	CHEMBL323723,TN,INACT,0.009999999776482582	CHEMBL74430,TN,INACT,0.0	CHEMBL64406,TN,INACT,0.0	CHEMBL3423400,TN,INACT,0.0	CHEMBL3260827,TP,ACT,1.0	CHEMBL3143394,TN,INACT,0.0	CHEMBL3585946,TP,ACT,1.0	CHEMBL51985,TN,INACT,0.029999999329447746	CHEMBL271488,TN,INACT,0.0	CHEMBL74505,TN,INACT,0.0	CHEMBL3704933,TP,ACT,1.0	CHEMBL3663429,TP,ACT,1.0	CHEMBL324685,TN,INACT,0.0	CHEMBL3670628,TP,ACT,1.0	CHEMBL408395,TN,INACT,0.019999999552965164	CHEMBL34328,TN,INACT,0.029999999329447746	CHEMBL490885,TP,ACT,1.0	CHEMBL3649075,TP,ACT,1.0	CHEMBL392401,TN,INACT,0.6600000262260437	CHEMBL3691812,TP,ACT,1.0	CHEMBL432974,TN,INACT,0.009999999776482582	CHEMBL3649196,TP,ACT,1.0	CHEMBL3426136,TP,ACT,1.0	CHEMBL3394775,TN,INACT,0.0	CHEMBL240888,FP,INACT,0.7799999713897705	CHEMBL1956200,TN,INACT,0.0	CHEMBL3670634,TP,ACT,1.0	CHEMBL334813,TN,INACT,0.10999999940395355	CHEMBL275481,TN,INACT,0.0	CHEMBL315391,TN,INACT,0.0	CHEMBL3669025,TP,ACT,1.0	CHEMBL3663422,TP,ACT,1.0	CHEMBL3652439,TP,ACT,0.9900000095367432	CHEMBL3634028,TP,ACT,1.0	CHEMBL413040,TN,INACT,0.0	CHEMBL193,TN,INACT,0.0	CHEMBL140559,TP,ACT,1.0	CHEMBL312372,TN,INACT,0.019999999552965164	CHEMBL489284,TP,ACT,1.0	CHEMBL3670585,TP,ACT,0.9900000095367432	CHEMBL3646205,TP,ACT,0.8899999856948853	CHEMBL2413517,TP,ACT,0.9800000190734863	CHEMBL3652521,TP,ACT,0.9900000095367432	CHEMBL185435,TP,ACT,1.0	CHEMBL3114144,TN,INACT,0.0	CHEMBL3659194,TP,ACT,1.0	CHEMBL3704964,TP,ACT,1.0	CHEMBL2418806,TN,INACT,0.6499999761581421	CHEMBL64784,TN,INACT,0.019999999552965164	CHEMBL3403733,TN,INACT,0.2800000011920929	CHEMBL3663492,TP,ACT,1.0	CHEMBL80438,TN,INACT,0.0	CHEMBL3649048,TP,ACT,0.9900000095367432	CHEMBL171651,TN,INACT,0.05999999865889549	CHEMBL2237158,TN,INACT,0.7099999785423279	CHEMBL185424,TP,ACT,1.0	CHEMBL3670516,TP,ACT,1.0	CHEMBL39986,TN,INACT,0.0	CHEMBL107680,TN,INACT,0.0	CHEMBL545363,TN,INACT,0.0	CHEMBL109206,TN,INACT,0.0	CHEMBL3663390,TP,ACT,0.9700000286102295	CHEMBL3663407,TP,ACT,1.0	CHEMBL461089,TN,INACT,0.0	CHEMBL277285,TN,INACT,0.009999999776482582	CHEMBL3394847,TP,ACT,0.9599999785423279	CHEMBL608814,TN,INACT,0.0	CHEMBL3634007,TP,ACT,1.0	CHEMBL295207,TN,INACT,0.009999999776482582	CHEMBL2112320,TN,INACT,0.0	CHEMBL325983,TN,INACT,0.0	CHEMBL2347599,TP,ACT,1.0	CHEMBL72738,TN,INACT,0.0	CHEMBL589973,TN,INACT,0.0	CHEMBL3426131,TP,ACT,1.0	CHEMBL413644,FP,INACT,0.9700000286102295	CHEMBL252232,FP,INACT,0.7799999713897705	CHEMBL185195,TN,INACT,0.009999999776482582	CHEMBL3423408,TN,INACT,0.0	CHEMBL3665676,TP,ACT,1.0	CHEMBL3659187,TP,ACT,1.0	CHEMBL3597962,TP,ACT,1.0	CHEMBL306907,TN,INACT,0.029999999329447746	CHEMBL602265,TN,INACT,0.009999999776482582	CHEMBL3426148,TP,ACT,0.9900000095367432	CHEMBL11592,TN,INACT,0.019999999552965164	CHEMBL3669015,FN,ACT,0.25999999046325684	CHEMBL3327368,TN,INACT,0.17000000178813934	CHEMBL3663395,TP,ACT,1.0	CHEMBL3665689,TP,ACT,1.0	CHEMBL64000,TN,INACT,0.0	CHEMBL3663526,TP,ACT,1.0	CHEMBL271232,TP,ACT,1.0	CHEMBL3649099,TP,ACT,0.9800000190734863	CHEMBL2409410,TN,INACT,0.0	CHEMBL2413373,FN,ACT,0.46000000834465027	CHEMBL241101,TN,INACT,0.25	CHEMBL111023,TN,INACT,0.019999999552965164	CHEMBL3669559,TP,ACT,1.0	CHEMBL327597,TN,INACT,0.0	CHEMBL3667604,TP,ACT,1.0	CHEMBL233535,TN,INACT,0.0	CHEMBL3290985,TN,INACT,0.0	CHEMBL165387,TN,INACT,0.0	CHEMBL552615,TN,INACT,0.0	CHEMBL1224608,TN,INACT,0.0	CHEMBL481245,TN,INACT,0.0	CHEMBL171108,TN,INACT,0.0	CHEMBL134652,TN,INACT,0.03999999910593033	CHEMBL3343253,TP,ACT,1.0	CHEMBL3639513,TP,ACT,1.0	CHEMBL260563,TN,INACT,0.0	CHEMBL384248,TN,INACT,0.05000000074505806	CHEMBL3659201,TP,ACT,1.0	CHEMBL3112596,TN,INACT,0.4099999964237213	CHEMBL292521,FP,INACT,0.8700000047683716	CHEMBL3670605,TP,ACT,1.0	CHEMBL1788233,TN,INACT,0.0	CHEMBL2111777,TN,INACT,0.009999999776482582	CHEMBL3670589,TP,ACT,1.0	CHEMBL142324,TN,INACT,0.019999999552965164	CHEMBL104,FP,INACT,0.9800000190734863	CHEMBL3634020,TP,ACT,1.0	CHEMBL494093,TN,INACT,0.09000000357627869	CHEMBL179638,TN,INACT,0.0	CHEMBL3663570,TP,ACT,1.0	CHEMBL3652484,TP,ACT,1.0	CHEMBL25976,TN,INACT,0.0	CHEMBL3704958,TP,ACT,1.0	CHEMBL3670633,TP,ACT,1.0	CHEMBL3585950,TP,ACT,1.0	CHEMBL3663449,TP,ACT,1.0	CHEMBL3669572,TP,ACT,1.0	CHEMBL3741767,TP,ACT,1.0	CHEMBL3343250,FN,ACT,0.0	CHEMBL16109,TN,INACT,0.05000000074505806	CHEMBL52438,TN,INACT,0.0	CHEMBL2443003,TN,INACT,0.0	CHEMBL363273,TP,ACT,1.0	CHEMBL3646206,TP,ACT,0.9599999785423279	CHEMBL3290975,TN,INACT,0.009999999776482582	CHEMBL3669545,TP,ACT,1.0	CHEMBL3652494,TP,ACT,1.0	CHEMBL215278,TN,INACT,0.0	CHEMBL3691845,TP,ACT,1.0	CHEMBL160396,TN,INACT,0.009999999776482582	CHEMBL141354,TN,INACT,0.25	CHEMBL3649191,TP,ACT,1.0	CHEMBL3670513,TP,ACT,1.0	CHEMBL185131,TP,ACT,1.0	CHEMBL3652442,TP,ACT,1.0	CHEMBL3665719,TP,ACT,1.0	CHEMBL3670560,TP,ACT,1.0	CHEMBL3669528,TP,ACT,1.0	CHEMBL3623075,TP,ACT,1.0	CHEMBL392149,TN,INACT,0.009999999776482582	CHEMBL3670509,TP,ACT,1.0	CHEMBL228686,TN,INACT,0.019999999552965164	CHEMBL3649062,TP,ACT,1.0	CHEMBL3649142,TP,ACT,0.9900000095367432	CHEMBL3649234,TP,ACT,1.0	CHEMBL603858,TN,INACT,0.1599999964237213	CHEMBL72084,TN,INACT,0.23999999463558197	CHEMBL303792,TN,INACT,0.0	CHEMBL344752,TN,INACT,0.0	CHEMBL3586432,TP,ACT,0.9900000095367432	CHEMBL2164367,TN,INACT,0.0	CHEMBL3739859,TP,ACT,1.0	CHEMBL3403343,FP,INACT,1.0	CHEMBL286680,TN,INACT,0.0	CHEMBL3665630,TP,ACT,1.0	CHEMBL556506,FP,INACT,0.7699999809265137	CHEMBL3652440,TP,ACT,0.9900000095367432	CHEMBL3665698,TP,ACT,1.0	CHEMBL500,TN,INACT,0.0	CHEMBL3649181,TP,ACT,0.9900000095367432	CHEMBL2094002,TN,INACT,0.0	CHEMBL1834624,TN,INACT,0.019999999552965164	CHEMBL164210,TN,INACT,0.0	CHEMBL469146,TP,ACT,1.0	CHEMBL3670570,TP,ACT,1.0	CHEMBL3663562,TP,ACT,1.0	CHEMBL3622336,TP,ACT,1.0	CHEMBL165175,TN,INACT,0.0	CHEMBL3426146,TP,ACT,1.0	CHEMBL442,FP,INACT,0.9300000071525574	CHEMBL314364,TN,INACT,0.10000000149011612	CHEMBL3622324,TP,ACT,1.0	CHEMBL312268,TN,INACT,0.03999999910593033	CHEMBL261623,TN,INACT,0.0	CHEMBL2370511,TN,INACT,0.0	CHEMBL73740,TN,INACT,0.029999999329447746	CHEMBL3659192,TP,ACT,1.0	CHEMBL3740873,TP,ACT,0.9900000095367432	CHEMBL512778,TP,ACT,0.7799999713897705	CHEMBL3326222,TN,INACT,0.0	CHEMBL3740471,FN,ACT,0.03999999910593033	CHEMBL3577342,TN,INACT,0.0	CHEMBL3739682,TP,ACT,1.0	CHEMBL3670508,TP,ACT,1.0	CHEMBL3649083,TP,ACT,0.9900000095367432	CHEMBL19808,TN,INACT,0.7200000286102295	CHEMBL527880,TN,INACT,0.0	CHEMBL554692,FP,INACT,0.7599999904632568	CHEMBL3343260,TP,ACT,1.0	CHEMBL80845,TN,INACT,0.0	CHEMBL205768,TN,INACT,0.0	CHEMBL255791,TN,INACT,0.0	CHEMBL59347,TN,INACT,0.23999999463558197	CHEMBL3649058,TP,ACT,0.9900000095367432	CHEMBL3649089,TP,ACT,1.0	CHEMBL450463,TN,INACT,0.0	CHEMBL3663413,TP,ACT,1.0	CHEMBL3663538,TP,ACT,1.0	CHEMBL3652449,TP,ACT,1.0	CHEMBL234771,TN,INACT,0.6600000262260437	CHEMBL3652457,TP,ACT,0.9900000095367432	CHEMBL3652495,TP,ACT,0.9800000190734863	CHEMBL3680367,TP,ACT,1.0	CHEMBL404557,TN,INACT,0.0	CHEMBL404053,FN,ACT,0.23999999463558197	CHEMBL273890,TN,INACT,0.0	CHEMBL266632,TN,INACT,0.0	CHEMBL3669541,TP,ACT,1.0	CHEMBL3646202,TP,ACT,0.9700000286102295	CHEMBL112770,TN,INACT,0.0	CHEMBL3663550,TP,ACT,1.0	CHEMBL490489,TP,ACT,1.0	CHEMBL324652,TN,INACT,0.0	CHEMBL413343,FP,INACT,0.9900000095367432	CHEMBL3665710,TP,ACT,1.0	CHEMBL3652477,TP,ACT,1.0	CHEMBL16565,TN,INACT,0.07000000029802322	CHEMBL3667593,TP,ACT,1.0	CHEMBL297215,TN,INACT,0.019999999552965164	CHEMBL287321,TN,INACT,0.0	CHEMBL3667567,TP,ACT,1.0	CHEMBL3670598,TP,ACT,0.9900000095367432	CHEMBL3704931,TP,ACT,1.0	CHEMBL3338850,TP,ACT,1.0	CHEMBL21509,TN,INACT,0.009999999776482582	CHEMBL3670515,TP,ACT,1.0	CHEMBL54246,TN,INACT,0.6000000238418579	CHEMBL3585944,TP,ACT,1.0	CHEMBL3652492,TP,ACT,0.9599999785423279	CHEMBL2237157,TN,INACT,0.23000000417232513	CHEMBL307175,TN,INACT,0.0	CHEMBL3652456,TP,ACT,1.0	CHEMBL312150,TN,INACT,0.14000000059604645	CHEMBL3667601,TP,ACT,1.0	CHEMBL474091,TN,INACT,0.4099999964237213	CHEMBL3649033,TP,ACT,0.9900000095367432	CHEMBL433814,TN,INACT,0.029999999329447746	CHEMBL76779,TN,INACT,0.0	CHEMBL1083658,TP,ACT,1.0	CHEMBL608330,TN,INACT,0.0	CHEMBL135361,TN,INACT,0.0	CHEMBL312750,TN,INACT,0.6800000071525574	CHEMBL3649084,TP,ACT,1.0	CHEMBL110695,TN,INACT,0.05999999865889549	CHEMBL3677851,TN,INACT,0.0	CHEMBL89688,TN,INACT,0.009999999776482582	CHEMBL537834,TN,INACT,0.0	CHEMBL3742392,TP,ACT,1.0	CHEMBL3704966,FN,ACT,0.7200000286102295	CHEMBL3426153,TP,ACT,0.8500000238418579	CHEMBL3634014,TP,ACT,1.0	CHEMBL124805,TN,INACT,0.0	CHEMBL3394848,TP,ACT,1.0	CHEMBL281232,TN,INACT,0.0	CHEMBL224380,TN,INACT,0.3799999952316284	CHEMBL3649166,TP,ACT,1.0	CHEMBL489884,TP,ACT,1.0	CHEMBL3649213,TP,ACT,1.0	CHEMBL3669536,TP,ACT,1.0	CHEMBL3663466,TP,ACT,1.0	CHEMBL3667549,TP,ACT,0.9900000095367432	CHEMBL3667552,TP,ACT,1.0	CHEMBL3646182,TP,ACT,1.0	CHEMBL3667578,TP,ACT,1.0	CHEMBL3634321,TN,INACT,0.0	CHEMBL3665691,TP,ACT,1.0	CHEMBL119291,TN,INACT,0.12999999523162842	CHEMBL3338852,TP,ACT,1.0	CHEMBL72151,TN,INACT,0.07999999821186066	CHEMBL1775009,TN,INACT,0.0	CHEMBL3649025,TP,ACT,0.9800000190734863	CHEMBL3669019,TP,ACT,1.0	CHEMBL3649127,TP,ACT,1.0	CHEMBL3659211,TP,ACT,1.0	CHEMBL3649102,TP,ACT,1.0	CHEMBL143304,TN,INACT,0.0	CHEMBL3597966,TP,ACT,1.0	CHEMBL3642131,TP,ACT,0.9900000095367432	CHEMBL3740042,TN,INACT,0.009999999776482582	CHEMBL65461,TN,INACT,0.0	CHEMBL240001,TN,INACT,0.0	CHEMBL78669,TN,INACT,0.0	CHEMBL3665699,TP,ACT,1.0	CHEMBL392521,TN,INACT,0.0	CHEMBL101162,TN,INACT,0.019999999552965164	CHEMBL3663454,TP,ACT,1.0	CHEMBL71626,FP,INACT,0.9800000190734863	CHEMBL309397,TN,INACT,0.0	CHEMBL112314,TN,INACT,0.0	CHEMBL3394836,TP,ACT,1.0	CHEMBL312374,TN,INACT,0.14000000059604645	CHEMBL3691835,TP,ACT,1.0	CHEMBL256788,FN,ACT,0.05999999865889549	CHEMBL434063,TN,INACT,0.07999999821186066	CHEMBL73791,TN,INACT,0.03999999910593033	CHEMBL3690070,TP,ACT,1.0	CHEMBL437,TN,INACT,0.009999999776482582	CHEMBL3649201,TP,ACT,0.9900000095367432	CHEMBL394642,TN,INACT,0.0	CHEMBL3704962,TP,ACT,1.0	CHEMBL499035,TN,INACT,0.0	CHEMBL3646161,TP,ACT,1.0	CHEMBL3667553,TP,ACT,1.0	CHEMBL3642128,TP,ACT,1.0	CHEMBL3667573,TP,ACT,1.0	CHEMBL237052,TN,INACT,0.0	CHEMBL2112592,TN,INACT,0.0	CHEMBL159623,TN,INACT,0.009999999776482582	CHEMBL1093724,TP,ACT,0.9800000190734863	CHEMBL305516,TN,INACT,0.0	CHEMBL3670556,TP,ACT,1.0	CHEMBL430683,TN,INACT,0.0	CHEMBL412569,TN,INACT,0.0	CHEMBL63003,TN,INACT,0.0	CHEMBL3586440,TP,ACT,1.0	CHEMBL1098507,TN,INACT,0.009999999776482582	CHEMBL3672938,TP,ACT,0.949999988079071	CHEMBL21328,TN,INACT,0.0	CHEMBL3649081,TP,ACT,1.0	CHEMBL435810,TN,INACT,0.0	CHEMBL2111825,TN,INACT,0.0	CHEMBL109593,TN,INACT,0.0	CHEMBL3649224,TP,ACT,1.0	CHEMBL272873,TN,INACT,0.0	CHEMBL3646176,TP,ACT,1.0	CHEMBL404397,TP,ACT,0.75	CHEMBL3663488,TP,ACT,1.0	CHEMBL2112318,TN,INACT,0.0	CHEMBL2113072,TN,INACT,0.0	CHEMBL418658,TN,INACT,0.0	CHEMBL3085876,TN,INACT,0.18000000715255737	CHEMBL82194,TN,INACT,0.0	CHEMBL321644,TN,INACT,0.10000000149011612	CHEMBL1098359,TN,INACT,0.6800000071525574	CHEMBL189192,TN,INACT,0.009999999776482582	CHEMBL3659238,TP,ACT,1.0	CHEMBL75141,TN,INACT,0.0	CHEMBL3649066,TP,ACT,1.0	CHEMBL438672,TN,INACT,0.0	CHEMBL296419,TN,INACT,0.6200000047683716	CHEMBL3649021,TP,ACT,1.0	CHEMBL392115,TN,INACT,0.0	CHEMBL3663577,TP,ACT,1.0	CHEMBL145584,TN,INACT,0.0	CHEMBL75002,TN,INACT,0.0	CHEMBL3649063,TP,ACT,1.0	CHEMBL332471,TN,INACT,0.0	CHEMBL3642132,TP,ACT,1.0	CHEMBL2347604,TP,ACT,1.0	CHEMBL319356,TN,INACT,0.0	CHEMBL3665678,TP,ACT,1.0	CHEMBL3740284,TP,ACT,1.0	CHEMBL15153,TN,INACT,0.009999999776482582	CHEMBL2413513,TP,ACT,1.0	CHEMBL3665648,TP,ACT,1.0	CHEMBL3403732,TN,INACT,0.03999999910593033	CHEMBL3669010,TP,ACT,1.0	CHEMBL608811,TN,INACT,0.0	CHEMBL3691829,TP,ACT,1.0	CHEMBL3669443,TP,ACT,1.0	CHEMBL133257,TN,INACT,0.05000000074505806	CHEMBL88584,TN,INACT,0.0	CHEMBL3663558,TP,ACT,0.9700000286102295	CHEMBL2413512,TP,ACT,1.0	CHEMBL3652486,TP,ACT,1.0	CHEMBL311455,TN,INACT,0.0	CHEMBL396271,TN,INACT,0.1599999964237213	CHEMBL279105,TN,INACT,0.0	CHEMBL3585957,TP,ACT,1.0	CHEMBL3649168,TP,ACT,0.9900000095367432	CHEMBL3646154,TP,ACT,0.9800000190734863	CHEMBL170026,TN,INACT,0.0	CHEMBL3669470,TP,ACT,1.0	CHEMBL140365,TN,INACT,0.0	CHEMBL449329,TN,INACT,0.009999999776482582	CHEMBL3649200,TP,ACT,0.9900000095367432	CHEMBL283535,TN,INACT,0.009999999776482582	CHEMBL600610,TN,INACT,0.20999999344348907	CHEMBL3663485,TP,ACT,0.8899999856948853	CHEMBL2113685,TN,INACT,0.0	CHEMBL291394,TN,INACT,0.0	CHEMBL17875,TN,INACT,0.20000000298023224	CHEMBL438915,TN,INACT,0.0	CHEMBL391718,TN,INACT,0.0	CHEMBL342583,TP,ACT,1.0	

