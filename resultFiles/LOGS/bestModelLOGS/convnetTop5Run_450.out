ImageNetInceptionV2 CHEMBL2007 RMSprop 0.0001 15 0 0 0.8 False True
Number of active compounds :	298
Number of inactive compounds :	298
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2007_RMSprop_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2007_RMSprop_0.0001_15_0.8/
---------------------------------
Training samples: 363
Validation samples: 114
--
Training Step: 1  | time: 43.774s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/363
[A[ATraining Step: 2  | total loss: [1m[32m0.60063[0m[0m | time: 53.727s
[2K
| RMSProp | epoch: 001 | loss: 0.60063 - acc: 0.5344 -- iter: 064/363
[A[ATraining Step: 3  | total loss: [1m[32m0.67100[0m[0m | time: 63.360s
[2K
| RMSProp | epoch: 001 | loss: 0.67100 - acc: 0.5063 -- iter: 096/363
[A[ATraining Step: 4  | total loss: [1m[32m0.67380[0m[0m | time: 73.229s
[2K
| RMSProp | epoch: 001 | loss: 0.67380 - acc: 0.5719 -- iter: 128/363
[A[ATraining Step: 5  | total loss: [1m[32m0.70009[0m[0m | time: 82.834s
[2K
| RMSProp | epoch: 001 | loss: 0.70009 - acc: 0.4788 -- iter: 160/363
[A[ATraining Step: 6  | total loss: [1m[32m0.72516[0m[0m | time: 92.784s
[2K
| RMSProp | epoch: 001 | loss: 0.72516 - acc: 0.4724 -- iter: 192/363
[A[ATraining Step: 7  | total loss: [1m[32m0.70817[0m[0m | time: 103.025s
[2K
| RMSProp | epoch: 001 | loss: 0.70817 - acc: 0.4889 -- iter: 224/363
[A[ATraining Step: 8  | total loss: [1m[32m0.69331[0m[0m | time: 112.831s
[2K
| RMSProp | epoch: 001 | loss: 0.69331 - acc: 0.5127 -- iter: 256/363
[A[ATraining Step: 9  | total loss: [1m[32m0.71164[0m[0m | time: 122.999s
[2K
| RMSProp | epoch: 001 | loss: 0.71164 - acc: 0.4895 -- iter: 288/363
[A[ATraining Step: 10  | total loss: [1m[32m0.71488[0m[0m | time: 132.932s
[2K
| RMSProp | epoch: 001 | loss: 0.71488 - acc: 0.4947 -- iter: 320/363
[A[ATraining Step: 11  | total loss: [1m[32m0.69853[0m[0m | time: 143.089s
[2K
| RMSProp | epoch: 001 | loss: 0.69853 - acc: 0.5268 -- iter: 352/363
[A[ATraining Step: 12  | total loss: [1m[32m0.69668[0m[0m | time: 161.170s
[2K
| RMSProp | epoch: 001 | loss: 0.69668 - acc: 0.5148 | val_loss: 0.74603 - val_acc: 0.4298 -- iter: 363/363
--
Training Step: 13  | total loss: [1m[32m0.73494[0m[0m | time: 4.134s
[2K
| RMSProp | epoch: 002 | loss: 0.73494 - acc: 0.4890 -- iter: 032/363
[A[ATraining Step: 14  | total loss: [1m[32m0.75208[0m[0m | time: 14.840s
[2K
| RMSProp | epoch: 002 | loss: 0.75208 - acc: 0.4005 -- iter: 064/363
[A[ATraining Step: 15  | total loss: [1m[32m0.73679[0m[0m | time: 25.081s
[2K
| RMSProp | epoch: 002 | loss: 0.73679 - acc: 0.4394 -- iter: 096/363
[A[ATraining Step: 16  | total loss: [1m[32m0.72675[0m[0m | time: 35.492s
[2K
| RMSProp | epoch: 002 | loss: 0.72675 - acc: 0.4973 -- iter: 128/363
[A[ATraining Step: 17  | total loss: [1m[32m0.70916[0m[0m | time: 45.937s
[2K
| RMSProp | epoch: 002 | loss: 0.70916 - acc: 0.5433 -- iter: 160/363
[A[ATraining Step: 18  | total loss: [1m[32m0.70213[0m[0m | time: 55.977s
[2K
| RMSProp | epoch: 002 | loss: 0.70213 - acc: 0.5391 -- iter: 192/363
[A[ATraining Step: 19  | total loss: [1m[32m0.69944[0m[0m | time: 65.967s
[2K
| RMSProp | epoch: 002 | loss: 0.69944 - acc: 0.5365 -- iter: 224/363
[A[ATraining Step: 20  | total loss: [1m[32m0.70604[0m[0m | time: 76.191s
[2K
| RMSProp | epoch: 002 | loss: 0.70604 - acc: 0.4946 -- iter: 256/363
[A[ATraining Step: 21  | total loss: [1m[32m0.70792[0m[0m | time: 86.717s
[2K
| RMSProp | epoch: 002 | loss: 0.70792 - acc: 0.4866 -- iter: 288/363
[A[ATraining Step: 22  | total loss: [1m[32m0.71082[0m[0m | time: 96.982s
[2K
| RMSProp | epoch: 002 | loss: 0.71082 - acc: 0.4906 -- iter: 320/363
[A[ATraining Step: 23  | total loss: [1m[32m0.70476[0m[0m | time: 107.498s
[2K
| RMSProp | epoch: 002 | loss: 0.70476 - acc: 0.5024 -- iter: 352/363
[A[ATraining Step: 24  | total loss: [1m[32m0.71002[0m[0m | time: 122.414s
[2K
| RMSProp | epoch: 002 | loss: 0.71002 - acc: 0.4490 | val_loss: 0.77882 - val_acc: 0.4298 -- iter: 363/363
--
Training Step: 25  | total loss: [1m[32m0.70759[0m[0m | time: 3.410s
[2K
| RMSProp | epoch: 003 | loss: 0.70759 - acc: 0.4544 -- iter: 032/363
[A[ATraining Step: 26  | total loss: [1m[32m0.72108[0m[0m | time: 6.785s
[2K
| RMSProp | epoch: 003 | loss: 0.72108 - acc: 0.4304 -- iter: 064/363
[A[ATraining Step: 27  | total loss: [1m[32m0.71824[0m[0m | time: 15.053s
[2K
| RMSProp | epoch: 003 | loss: 0.71824 - acc: 0.4833 -- iter: 096/363
[A[ATraining Step: 28  | total loss: [1m[32m0.70233[0m[0m | time: 23.253s
[2K
| RMSProp | epoch: 003 | loss: 0.70233 - acc: 0.5266 -- iter: 128/363
[A[ATraining Step: 29  | total loss: [1m[32m0.69970[0m[0m | time: 31.477s
[2K
| RMSProp | epoch: 003 | loss: 0.69970 - acc: 0.4973 -- iter: 160/363
[A[ATraining Step: 30  | total loss: [1m[32m0.68857[0m[0m | time: 39.746s
[2K
| RMSProp | epoch: 003 | loss: 0.68857 - acc: 0.5349 -- iter: 192/363
[A[ATraining Step: 31  | total loss: [1m[32m0.69429[0m[0m | time: 47.992s
[2K
| RMSProp | epoch: 003 | loss: 0.69429 - acc: 0.4764 -- iter: 224/363
[A[ATraining Step: 32  | total loss: [1m[32m0.69111[0m[0m | time: 56.217s
[2K
| RMSProp | epoch: 003 | loss: 0.69111 - acc: 0.5098 -- iter: 256/363
[A[ATraining Step: 33  | total loss: [1m[32m0.68949[0m[0m | time: 64.538s
[2K
| RMSProp | epoch: 003 | loss: 0.68949 - acc: 0.5008 -- iter: 288/363
[A[ATraining Step: 34  | total loss: [1m[32m0.69226[0m[0m | time: 72.845s
[2K
| RMSProp | epoch: 003 | loss: 0.69226 - acc: 0.5073 -- iter: 320/363
[A[ATraining Step: 35  | total loss: [1m[32m0.68992[0m[0m | time: 81.078s
[2K
| RMSProp | epoch: 003 | loss: 0.68992 - acc: 0.5123 -- iter: 352/363
[A[ATraining Step: 36  | total loss: [1m[32m0.69276[0m[0m | time: 94.800s
[2K
| RMSProp | epoch: 003 | loss: 0.69276 - acc: 0.5034 | val_loss: 0.76768 - val_acc: 0.4298 -- iter: 363/363
--
Training Step: 37  | total loss: [1m[32m0.68882[0m[0m | time: 8.317s
[2K
| RMSProp | epoch: 004 | loss: 0.68882 - acc: 0.5277 -- iter: 032/363
[A[ATraining Step: 38  | total loss: [1m[32m0.68489[0m[0m | time: 11.771s
[2K
| RMSProp | epoch: 004 | loss: 0.68489 - acc: 0.5468 -- iter: 064/363
[A[ATraining Step: 39  | total loss: [1m[32m0.69756[0m[0m | time: 15.181s
[2K
| RMSProp | epoch: 004 | loss: 0.69756 - acc: 0.5465 -- iter: 096/363
[A[ATraining Step: 40  | total loss: [1m[32m0.69591[0m[0m | time: 23.547s
[2K
| RMSProp | epoch: 004 | loss: 0.69591 - acc: 0.5463 -- iter: 128/363
[A[ATraining Step: 41  | total loss: [1m[32m0.69165[0m[0m | time: 31.814s
[2K
| RMSProp | epoch: 004 | loss: 0.69165 - acc: 0.5608 -- iter: 160/363
[A[ATraining Step: 42  | total loss: [1m[32m0.69351[0m[0m | time: 40.096s
[2K
| RMSProp | epoch: 004 | loss: 0.69351 - acc: 0.5555 -- iter: 192/363
[A[ATraining Step: 43  | total loss: [1m[32m0.69054[0m[0m | time: 48.189s
[2K
| RMSProp | epoch: 004 | loss: 0.69054 - acc: 0.5677 -- iter: 224/363
[A[ATraining Step: 44  | total loss: [1m[32m0.69707[0m[0m | time: 56.464s
[2K
| RMSProp | epoch: 004 | loss: 0.69707 - acc: 0.5344 -- iter: 256/363
[A[ATraining Step: 45  | total loss: [1m[32m0.69972[0m[0m | time: 64.905s
[2K
| RMSProp | epoch: 004 | loss: 0.69972 - acc: 0.5073 -- iter: 288/363
[A[ATraining Step: 46  | total loss: [1m[32m0.69121[0m[0m | time: 73.132s
[2K
| RMSProp | epoch: 004 | loss: 0.69121 - acc: 0.5269 -- iter: 320/363
[A[ATraining Step: 47  | total loss: [1m[32m0.68836[0m[0m | time: 81.581s
[2K
| RMSProp | epoch: 004 | loss: 0.68836 - acc: 0.5379 -- iter: 352/363
[A[ATraining Step: 48  | total loss: [1m[32m0.68675[0m[0m | time: 95.341s
[2K
| RMSProp | epoch: 004 | loss: 0.68675 - acc: 0.5519 | val_loss: 0.72178 - val_acc: 0.4298 -- iter: 363/363
--
Training Step: 49  | total loss: [1m[32m0.68294[0m[0m | time: 8.526s
[2K
| RMSProp | epoch: 005 | loss: 0.68294 - acc: 0.5585 -- iter: 032/363
[A[ATraining Step: 50  | total loss: [1m[32m0.68254[0m[0m | time: 17.037s
[2K
| RMSProp | epoch: 005 | loss: 0.68254 - acc: 0.5494 -- iter: 064/363
[A[ATraining Step: 51  | total loss: [1m[32m0.68060[0m[0m | time: 20.453s
[2K
| RMSProp | epoch: 005 | loss: 0.68060 - acc: 0.5609 -- iter: 096/363
[A[ATraining Step: 52  | total loss: [1m[32m0.68470[0m[0m | time: 23.814s
[2K
| RMSProp | epoch: 005 | loss: 0.68470 - acc: 0.5586 -- iter: 128/363
[A[ATraining Step: 53  | total loss: [1m[32m0.68348[0m[0m | time: 32.349s
[2K
| RMSProp | epoch: 005 | loss: 0.68348 - acc: 0.5567 -- iter: 160/363
[A[ATraining Step: 54  | total loss: [1m[32m0.67904[0m[0m | time: 41.010s
[2K
| RMSProp | epoch: 005 | loss: 0.67904 - acc: 0.5666 -- iter: 192/363
[A[ATraining Step: 55  | total loss: [1m[32m0.67943[0m[0m | time: 49.667s
[2K
| RMSProp | epoch: 005 | loss: 0.67943 - acc: 0.5526 -- iter: 224/363
[A[ATraining Step: 56  | total loss: [1m[32m0.67767[0m[0m | time: 58.219s
[2K
| RMSProp | epoch: 005 | loss: 0.67767 - acc: 0.5760 -- iter: 256/363
[A[ATraining Step: 57  | total loss: [1m[32m0.68389[0m[0m | time: 67.084s
[2K
| RMSProp | epoch: 005 | loss: 0.68389 - acc: 0.5655 -- iter: 288/363
[A[ATraining Step: 58  | total loss: [1m[32m0.68832[0m[0m | time: 107.582s
[2K
| RMSProp | epoch: 005 | loss: 0.68832 - acc: 0.5523 -- iter: 320/363
[A[ATraining Step: 59  | total loss: [1m[32m0.68405[0m[0m | time: 124.679s
[2K
| RMSProp | epoch: 005 | loss: 0.68405 - acc: 0.5536 -- iter: 352/363
[A[ATraining Step: 60  | total loss: [1m[32m0.67196[0m[0m | time: 193.472s
[2K
| RMSProp | epoch: 005 | loss: 0.67196 - acc: 0.5838 | val_loss: 0.70702 - val_acc: 0.4386 -- iter: 363/363
--
Training Step: 61  | total loss: [1m[32m0.67787[0m[0m | time: 46.527s
[2K
| RMSProp | epoch: 006 | loss: 0.67787 - acc: 0.5647 -- iter: 032/363
[A[ATraining Step: 62  | total loss: [1m[32m0.67909[0m[0m | time: 74.954s
[2K
| RMSProp | epoch: 006 | loss: 0.67909 - acc: 0.5564 -- iter: 064/363
[A[ATraining Step: 63  | total loss: [1m[32m0.67803[0m[0m | time: 101.727s
[2K
| RMSProp | epoch: 006 | loss: 0.67803 - acc: 0.5730 -- iter: 096/363
[A[ATraining Step: 64  | total loss: [1m[32m0.67853[0m[0m | time: 107.844s
[2K
| RMSProp | epoch: 006 | loss: 0.67853 - acc: 0.5717 -- iter: 128/363
[A[ATraining Step: 65  | total loss: [1m[32m0.68223[0m[0m | time: 115.002s
[2K
| RMSProp | epoch: 006 | loss: 0.68223 - acc: 0.5572 -- iter: 160/363
[A[ATraining Step: 66  | total loss: [1m[32m0.67690[0m[0m | time: 141.053s
[2K
| RMSProp | epoch: 006 | loss: 0.67690 - acc: 0.5779 -- iter: 192/363
[A[ATraining Step: 67  | total loss: [1m[32m0.67723[0m[0m | time: 161.422s
[2K
| RMSProp | epoch: 006 | loss: 0.67723 - acc: 0.5798 -- iter: 224/363
[A[ATraining Step: 68  | total loss: [1m[32m0.67923[0m[0m | time: 176.769s
[2K
| RMSProp | epoch: 006 | loss: 0.67923 - acc: 0.5741 -- iter: 256/363
[A[ATraining Step: 69  | total loss: [1m[32m0.67905[0m[0m | time: 194.676s
[2K
| RMSProp | epoch: 006 | loss: 0.67905 - acc: 0.5727 -- iter: 288/363
[A[ATraining Step: 70  | total loss: [1m[32m0.68209[0m[0m | time: 211.463s
[2K
| RMSProp | epoch: 006 | loss: 0.68209 - acc: 0.5499 -- iter: 320/363
[A[ATraining Step: 71  | total loss: [1m[32m0.67930[0m[0m | time: 225.836s
[2K
| RMSProp | epoch: 006 | loss: 0.67930 - acc: 0.5656 -- iter: 352/363
[A[ATraining Step: 72  | total loss: [1m[32m0.68019[0m[0m | time: 242.988s
[2K
| RMSProp | epoch: 006 | loss: 0.68019 - acc: 0.5652 | val_loss: 0.69090 - val_acc: 0.5000 -- iter: 363/363
--
Training Step: 73  | total loss: [1m[32m0.67970[0m[0m | time: 10.063s
[2K
| RMSProp | epoch: 007 | loss: 0.67970 - acc: 0.5684 -- iter: 032/363
[A[ATraining Step: 74  | total loss: [1m[32m0.67481[0m[0m | time: 37.886s
[2K
| RMSProp | epoch: 007 | loss: 0.67481 - acc: 0.5849 -- iter: 064/363
[A[ATraining Step: 75  | total loss: [1m[32m0.67253[0m[0m | time: 61.556s
[2K
| RMSProp | epoch: 007 | loss: 0.67253 - acc: 0.5825 -- iter: 096/363
[A[ATraining Step: 76  | total loss: [1m[32m0.67187[0m[0m | time: 76.137s
[2K
| RMSProp | epoch: 007 | loss: 0.67187 - acc: 0.5803 -- iter: 128/363
[A[ATraining Step: 77  | total loss: [1m[32m0.66255[0m[0m | time: 81.959s
[2K
| RMSProp | epoch: 007 | loss: 0.66255 - acc: 0.6082 -- iter: 160/363
[A[ATraining Step: 78  | total loss: [1m[32m0.66704[0m[0m | time: 88.524s
[2K
| RMSProp | epoch: 007 | loss: 0.66704 - acc: 0.5826 -- iter: 192/363
[A[ATraining Step: 79  | total loss: [1m[32m0.66135[0m[0m | time: 103.283s
[2K
| RMSProp | epoch: 007 | loss: 0.66135 - acc: 0.5976 -- iter: 224/363
[A[ATraining Step: 80  | total loss: [1m[32m0.65966[0m[0m | time: 118.905s
[2K
| RMSProp | epoch: 007 | loss: 0.65966 - acc: 0.6004 -- iter: 256/363
[A[ATraining Step: 81  | total loss: [1m[32m0.65290[0m[0m | time: 134.050s
[2K
| RMSProp | epoch: 007 | loss: 0.65290 - acc: 0.6250 -- iter: 288/363
[A[ATraining Step: 82  | total loss: [1m[32m0.65055[0m[0m | time: 148.253s
[2K
| RMSProp | epoch: 007 | loss: 0.65055 - acc: 0.6344 -- iter: 320/363
[A[ATraining Step: 83  | total loss: [1m[32m0.64512[0m[0m | time: 163.035s
[2K
| RMSProp | epoch: 007 | loss: 0.64512 - acc: 0.6522 -- iter: 352/363
[A[ATraining Step: 84  | total loss: [1m[32m0.64304[0m[0m | time: 196.263s
[2K
| RMSProp | epoch: 007 | loss: 0.64304 - acc: 0.6557 | val_loss: 0.67233 - val_acc: 0.5702 -- iter: 363/363
--
Training Step: 85  | total loss: [1m[32m0.64441[0m[0m | time: 70.922s
[2K
| RMSProp | epoch: 008 | loss: 0.64441 - acc: 0.6589 -- iter: 032/363
[A[ATraining Step: 86  | total loss: [1m[32m0.63698[0m[0m | time: 96.724s
[2K
| RMSProp | epoch: 008 | loss: 0.63698 - acc: 0.6805 -- iter: 064/363
[A[ATraining Step: 87  | total loss: [1m[32m0.63179[0m[0m | time: 114.471s
[2K
| RMSProp | epoch: 008 | loss: 0.63179 - acc: 0.6968 -- iter: 096/363
[A[ATraining Step: 88  | total loss: [1m[32m0.63146[0m[0m | time: 126.614s
[2K
| RMSProp | epoch: 008 | loss: 0.63146 - acc: 0.7021 -- iter: 128/363
[A[ATraining Step: 89  | total loss: [1m[32m0.62657[0m[0m | time: 135.393s
[2K
| RMSProp | epoch: 008 | loss: 0.62657 - acc: 0.7163 -- iter: 160/363
[A[ATraining Step: 90  | total loss: [1m[32m0.62260[0m[0m | time: 138.771s
[2K
| RMSProp | epoch: 008 | loss: 0.62260 - acc: 0.7166 -- iter: 192/363
[A[ATraining Step: 91  | total loss: [1m[32m0.61682[0m[0m | time: 142.094s
[2K
| RMSProp | epoch: 008 | loss: 0.61682 - acc: 0.7358 -- iter: 224/363
[A[ATraining Step: 92  | total loss: [1m[32m0.59916[0m[0m | time: 158.579s
[2K
| RMSProp | epoch: 008 | loss: 0.59916 - acc: 0.7622 -- iter: 256/363
[A[ATraining Step: 93  | total loss: [1m[32m0.59392[0m[0m | time: 200.770s
[2K
| RMSProp | epoch: 008 | loss: 0.59392 - acc: 0.7641 -- iter: 288/363
[A[ATraining Step: 94  | total loss: [1m[32m0.60013[0m[0m | time: 261.551s
[2K
| RMSProp | epoch: 008 | loss: 0.60013 - acc: 0.7471 -- iter: 320/363
[A[ATraining Step: 95  | total loss: [1m[32m0.59897[0m[0m | time: 290.983s
[2K
| RMSProp | epoch: 008 | loss: 0.59897 - acc: 0.7505 -- iter: 352/363
[A[ATraining Step: 96  | total loss: [1m[32m0.60372[0m[0m | time: 314.407s
[2K
| RMSProp | epoch: 008 | loss: 0.60372 - acc: 0.7411 | val_loss: 0.70854 - val_acc: 0.5702 -- iter: 363/363
--
Training Step: 97  | total loss: [1m[32m0.59766[0m[0m | time: 14.392s
[2K
| RMSProp | epoch: 009 | loss: 0.59766 - acc: 0.7451 -- iter: 032/363
[A[ATraining Step: 98  | total loss: [1m[32m0.59305[0m[0m | time: 28.216s
[2K
| RMSProp | epoch: 009 | loss: 0.59305 - acc: 0.7487 -- iter: 064/363
[A[ATraining Step: 99  | total loss: [1m[32m0.58475[0m[0m | time: 47.171s
[2K
| RMSProp | epoch: 009 | loss: 0.58475 - acc: 0.7613 -- iter: 096/363
[A[ATraining Step: 100  | total loss: [1m[32m0.57691[0m[0m | time: 62.884s
[2K
| RMSProp | epoch: 009 | loss: 0.57691 - acc: 0.7727 -- iter: 128/363
[A[ATraining Step: 101  | total loss: [1m[32m0.57151[0m[0m | time: 77.207s
[2K
| RMSProp | epoch: 009 | loss: 0.57151 - acc: 0.7829 -- iter: 160/363
[A[ATraining Step: 102  | total loss: [1m[32m0.57162[0m[0m | time: 92.628s
[2K
| RMSProp | epoch: 009 | loss: 0.57162 - acc: 0.7796 -- iter: 192/363
[A[ATraining Step: 103  | total loss: [1m[32m0.56559[0m[0m | time: 99.021s
[2K
| RMSProp | epoch: 009 | loss: 0.56559 - acc: 0.7923 -- iter: 224/363
[A[ATraining Step: 104  | total loss: [1m[32m0.56605[0m[0m | time: 104.707s
[2K
| RMSProp | epoch: 009 | loss: 0.56605 - acc: 0.7767 -- iter: 256/363
[A[ATraining Step: 105  | total loss: [1m[32m0.54841[0m[0m | time: 119.703s
[2K
| RMSProp | epoch: 009 | loss: 0.54841 - acc: 0.7990 -- iter: 288/363
[A[ATraining Step: 106  | total loss: [1m[32m0.55070[0m[0m | time: 134.704s
[2K
| RMSProp | epoch: 009 | loss: 0.55070 - acc: 0.7879 -- iter: 320/363
[A[ATraining Step: 107  | total loss: [1m[32m0.54528[0m[0m | time: 148.964s
[2K
| RMSProp | epoch: 009 | loss: 0.54528 - acc: 0.7841 -- iter: 352/363
[A[ATraining Step: 108  | total loss: [1m[32m0.53763[0m[0m | time: 165.001s
[2K
| RMSProp | epoch: 009 | loss: 0.53763 - acc: 0.7869 | val_loss: 0.73358 - val_acc: 0.5877 -- iter: 363/363
--
Training Step: 109  | total loss: [1m[32m0.53380[0m[0m | time: 54.400s
[2K
| RMSProp | epoch: 010 | loss: 0.53380 - acc: 0.7832 -- iter: 032/363
[A[ATraining Step: 110  | total loss: [1m[32m0.53375[0m[0m | time: 75.851s
[2K
| RMSProp | epoch: 010 | loss: 0.53375 - acc: 0.7768 -- iter: 064/363
[A[ATraining Step: 111  | total loss: [1m[32m0.52634[0m[0m | time: 90.184s
[2K
| RMSProp | epoch: 010 | loss: 0.52634 - acc: 0.7804 -- iter: 096/363
[A[ATraining Step: 112  | total loss: [1m[32m0.51776[0m[0m | time: 104.709s
[2K
| RMSProp | epoch: 010 | loss: 0.51776 - acc: 0.7898 -- iter: 128/363
[A[ATraining Step: 113  | total loss: [1m[32m0.51080[0m[0m | time: 118.927s
[2K
| RMSProp | epoch: 010 | loss: 0.51080 - acc: 0.7921 -- iter: 160/363
[A[ATraining Step: 114  | total loss: [1m[32m0.49676[0m[0m | time: 132.843s
[2K
| RMSProp | epoch: 010 | loss: 0.49676 - acc: 0.8004 -- iter: 192/363
[A[ATraining Step: 115  | total loss: [1m[32m0.48801[0m[0m | time: 151.359s
[2K
| RMSProp | epoch: 010 | loss: 0.48801 - acc: 0.8078 -- iter: 224/363
[A[ATraining Step: 116  | total loss: [1m[32m0.48588[0m[0m | time: 157.898s
[2K
| RMSProp | epoch: 010 | loss: 0.48588 - acc: 0.8052 -- iter: 256/363
[A[ATraining Step: 117  | total loss: [1m[32m0.48139[0m[0m | time: 164.143s
[2K
| RMSProp | epoch: 010 | loss: 0.48139 - acc: 0.8247 -- iter: 288/363
[A[ATraining Step: 118  | total loss: [1m[32m0.45451[0m[0m | time: 178.074s
[2K
| RMSProp | epoch: 010 | loss: 0.45451 - acc: 0.8422 -- iter: 320/363
[A[ATraining Step: 119  | total loss: [1m[32m0.45492[0m[0m | time: 192.674s
[2K
| RMSProp | epoch: 010 | loss: 0.45492 - acc: 0.8361 -- iter: 352/363
[A[ATraining Step: 120  | total loss: [1m[32m0.45978[0m[0m | time: 216.869s
[2K
| RMSProp | epoch: 010 | loss: 0.45978 - acc: 0.8275 | val_loss: 1.04531 - val_acc: 0.5702 -- iter: 363/363
--
Training Step: 121  | total loss: [1m[32m0.45006[0m[0m | time: 13.915s
[2K
| RMSProp | epoch: 011 | loss: 0.45006 - acc: 0.8322 -- iter: 032/363
[A[ATraining Step: 122  | total loss: [1m[32m0.44461[0m[0m | time: 22.678s
[2K
| RMSProp | epoch: 011 | loss: 0.44461 - acc: 0.8396 -- iter: 064/363
[A[ATraining Step: 123  | total loss: [1m[32m0.44308[0m[0m | time: 31.310s
[2K
| RMSProp | epoch: 011 | loss: 0.44308 - acc: 0.8369 -- iter: 096/363
[A[ATraining Step: 124  | total loss: [1m[32m0.43492[0m[0m | time: 40.064s
[2K
| RMSProp | epoch: 011 | loss: 0.43492 - acc: 0.8407 -- iter: 128/363
[A[ATraining Step: 125  | total loss: [1m[32m0.42387[0m[0m | time: 50.694s
[2K
| RMSProp | epoch: 011 | loss: 0.42387 - acc: 0.8442 -- iter: 160/363
[A[ATraining Step: 126  | total loss: [1m[32m0.42110[0m[0m | time: 64.641s
[2K
| RMSProp | epoch: 011 | loss: 0.42110 - acc: 0.8410 -- iter: 192/363
[A[ATraining Step: 127  | total loss: [1m[32m0.41919[0m[0m | time: 78.658s
[2K
| RMSProp | epoch: 011 | loss: 0.41919 - acc: 0.8413 -- iter: 224/363
[A[ATraining Step: 128  | total loss: [1m[32m0.41132[0m[0m | time: 92.415s
[2K
| RMSProp | epoch: 011 | loss: 0.41132 - acc: 0.8509 -- iter: 256/363
[A[ATraining Step: 129  | total loss: [1m[32m0.39812[0m[0m | time: 98.814s
[2K
| RMSProp | epoch: 011 | loss: 0.39812 - acc: 0.8533 -- iter: 288/363
[A[ATraining Step: 130  | total loss: [1m[32m0.40629[0m[0m | time: 104.359s
[2K
| RMSProp | epoch: 011 | loss: 0.40629 - acc: 0.8498 -- iter: 320/363
[A[ATraining Step: 131  | total loss: [1m[32m0.38164[0m[0m | time: 122.608s
[2K
| RMSProp | epoch: 011 | loss: 0.38164 - acc: 0.8648 -- iter: 352/363
[A[ATraining Step: 132  | total loss: [1m[32m0.37676[0m[0m | time: 149.707s
[2K
| RMSProp | epoch: 011 | loss: 0.37676 - acc: 0.8752 | val_loss: 0.75264 - val_acc: 0.5877 -- iter: 363/363
--
Training Step: 133  | total loss: [1m[32m0.37119[0m[0m | time: 49.609s
[2K
| RMSProp | epoch: 012 | loss: 0.37119 - acc: 0.8721 -- iter: 032/363
[A[ATraining Step: 134  | total loss: [1m[32m0.35827[0m[0m | time: 69.618s
[2K
| RMSProp | epoch: 012 | loss: 0.35827 - acc: 0.8817 -- iter: 064/363
[A[ATraining Step: 135  | total loss: [1m[32m0.34935[0m[0m | time: 83.754s
[2K
| RMSProp | epoch: 012 | loss: 0.34935 - acc: 0.8811 -- iter: 096/363
[A[ATraining Step: 136  | total loss: [1m[32m0.33783[0m[0m | time: 97.888s
[2K
| RMSProp | epoch: 012 | loss: 0.33783 - acc: 0.8898 -- iter: 128/363
[A[ATraining Step: 137  | total loss: [1m[32m0.36260[0m[0m | time: 111.640s
[2K
| RMSProp | epoch: 012 | loss: 0.36260 - acc: 0.8821 -- iter: 160/363
[A[ATraining Step: 138  | total loss: [1m[32m0.34769[0m[0m | time: 125.723s
[2K
| RMSProp | epoch: 012 | loss: 0.34769 - acc: 0.8876 -- iter: 192/363
[A[ATraining Step: 139  | total loss: [1m[32m0.33305[0m[0m | time: 139.691s
[2K
| RMSProp | epoch: 012 | loss: 0.33305 - acc: 0.8926 -- iter: 224/363
[A[ATraining Step: 140  | total loss: [1m[32m0.32056[0m[0m | time: 154.131s
[2K
| RMSProp | epoch: 012 | loss: 0.32056 - acc: 0.8971 -- iter: 256/363
[A[ATraining Step: 141  | total loss: [1m[32m0.30534[0m[0m | time: 163.719s
[2K
| RMSProp | epoch: 012 | loss: 0.30534 - acc: 0.9043 -- iter: 288/363
[A[ATraining Step: 142  | total loss: [1m[32m0.29014[0m[0m | time: 167.247s
[2K
| RMSProp | epoch: 012 | loss: 0.29014 - acc: 0.9138 -- iter: 320/363
[A[ATraining Step: 143  | total loss: [1m[32m0.28202[0m[0m | time: 170.696s
[2K
| RMSProp | epoch: 012 | loss: 0.28202 - acc: 0.9225 -- iter: 352/363
[A[ATraining Step: 144  | total loss: [1m[32m0.25872[0m[0m | time: 187.665s
[2K
| RMSProp | epoch: 012 | loss: 0.25872 - acc: 0.9302 | val_loss: 1.50404 - val_acc: 0.5702 -- iter: 363/363
--
Training Step: 145  | total loss: [1m[32m0.25172[0m[0m | time: 71.722s
[2K
| RMSProp | epoch: 013 | loss: 0.25172 - acc: 0.9309 -- iter: 032/363
[A[ATraining Step: 146  | total loss: [1m[32m0.24091[0m[0m | time: 85.377s
[2K
| RMSProp | epoch: 013 | loss: 0.24091 - acc: 0.9316 -- iter: 064/363
[A[ATraining Step: 147  | total loss: [1m[32m0.22585[0m[0m | time: 99.279s
[2K
| RMSProp | epoch: 013 | loss: 0.22585 - acc: 0.9384 -- iter: 096/363
[A[ATraining Step: 148  | total loss: [1m[32m0.22044[0m[0m | time: 113.412s
[2K
| RMSProp | epoch: 013 | loss: 0.22044 - acc: 0.9446 -- iter: 128/363
[A[ATraining Step: 149  | total loss: [1m[32m0.21623[0m[0m | time: 127.367s
[2K
| RMSProp | epoch: 013 | loss: 0.21623 - acc: 0.9408 -- iter: 160/363
[A[ATraining Step: 150  | total loss: [1m[32m0.20841[0m[0m | time: 141.242s
[2K
| RMSProp | epoch: 013 | loss: 0.20841 - acc: 0.9436 -- iter: 192/363
[A[ATraining Step: 151  | total loss: [1m[32m0.19530[0m[0m | time: 155.330s
[2K
| RMSProp | epoch: 013 | loss: 0.19530 - acc: 0.9492 -- iter: 224/363
[A[ATraining Step: 152  | total loss: [1m[32m0.17918[0m[0m | time: 169.943s
[2K
| RMSProp | epoch: 013 | loss: 0.17918 - acc: 0.9543 -- iter: 256/363
[A[ATraining Step: 153  | total loss: [1m[32m0.16964[0m[0m | time: 185.252s
[2K
| RMSProp | epoch: 013 | loss: 0.16964 - acc: 0.9589 -- iter: 288/363
[A[ATraining Step: 154  | total loss: [1m[32m0.16141[0m[0m | time: 276.497s
[2K
| RMSProp | epoch: 013 | loss: 0.16141 - acc: 0.9630 -- iter: 320/363
[A[ATraining Step: 155  | total loss: [1m[32m0.15122[0m[0m | time: 282.859s
[2K
| RMSProp | epoch: 013 | loss: 0.15122 - acc: 0.9667 -- iter: 352/363
[A[ATraining Step: 156  | total loss: [1m[32m0.14096[0m[0m | time: 298.085s
[2K
| RMSProp | epoch: 013 | loss: 0.14096 - acc: 0.9700 | val_loss: 3.43584 - val_acc: 0.5702 -- iter: 363/363
--
Training Step: 157  | total loss: [1m[32m0.13768[0m[0m | time: 10.676s
[2K
| RMSProp | epoch: 014 | loss: 0.13768 - acc: 0.9730 -- iter: 032/363
[A[ATraining Step: 158  | total loss: [1m[32m0.12887[0m[0m | time: 19.554s
[2K
| RMSProp | epoch: 014 | loss: 0.12887 - acc: 0.9757 -- iter: 064/363
[A[ATraining Step: 159  | total loss: [1m[32m0.12316[0m[0m | time: 28.529s
[2K
| RMSProp | epoch: 014 | loss: 0.12316 - acc: 0.9750 -- iter: 096/363
[A[ATraining Step: 160  | total loss: [1m[32m0.12756[0m[0m | time: 170.637s
[2K
| RMSProp | epoch: 014 | loss: 0.12756 - acc: 0.9744 -- iter: 128/363
[A[ATraining Step: 161  | total loss: [1m[32m0.11998[0m[0m | time: 213.901s
[2K
| RMSProp | epoch: 014 | loss: 0.11998 - acc: 0.9769 -- iter: 160/363
[A[ATraining Step: 162  | total loss: [1m[32m0.11164[0m[0m | time: 228.165s
[2K
| RMSProp | epoch: 014 | loss: 0.11164 - acc: 0.9793 -- iter: 192/363
[A[ATraining Step: 163  | total loss: [1m[32m0.10988[0m[0m | time: 241.749s
[2K
| RMSProp | epoch: 014 | loss: 0.10988 - acc: 0.9782 -- iter: 224/363
[A[ATraining Step: 164  | total loss: [1m[32m0.10285[0m[0m | time: 255.217s
[2K
| RMSProp | epoch: 014 | loss: 0.10285 - acc: 0.9804 -- iter: 256/363
[A[ATraining Step: 165  | total loss: [1m[32m0.09466[0m[0m | time: 269.002s
[2K
| RMSProp | epoch: 014 | loss: 0.09466 - acc: 0.9823 -- iter: 288/363
[A[ATraining Step: 166  | total loss: [1m[32m0.08766[0m[0m | time: 283.033s
[2K
| RMSProp | epoch: 014 | loss: 0.08766 - acc: 0.9841 -- iter: 320/363
[A[ATraining Step: 167  | total loss: [1m[32m0.08079[0m[0m | time: 296.953s
[2K
| RMSProp | epoch: 014 | loss: 0.08079 - acc: 0.9857 -- iter: 352/363
[A[ATraining Step: 168  | total loss: [1m[32m0.07583[0m[0m | time: 312.700s
[2K
| RMSProp | epoch: 014 | loss: 0.07583 - acc: 0.9871 | val_loss: 5.74982 - val_acc: 0.5702 -- iter: 363/363
--
Training Step: 169  | total loss: [1m[32m0.07433[0m[0m | time: 6.512s
[2K
| RMSProp | epoch: 015 | loss: 0.07433 - acc: 0.9884 -- iter: 032/363
[A[ATraining Step: 170  | total loss: [1m[32m0.11278[0m[0m | time: 20.433s
[2K
| RMSProp | epoch: 015 | loss: 0.11278 - acc: 0.9623 -- iter: 064/363
[A[ATraining Step: 171  | total loss: [1m[32m0.14136[0m[0m | time: 33.865s
[2K
| RMSProp | epoch: 015 | loss: 0.14136 - acc: 0.9567 -- iter: 096/363
[A[ATraining Step: 172  | total loss: [1m[32m0.13705[0m[0m | time: 47.922s
[2K
| RMSProp | epoch: 015 | loss: 0.13705 - acc: 0.9579 -- iter: 128/363
[A[ATraining Step: 173  | total loss: [1m[32m0.12709[0m[0m | time: 61.927s
[2K
| RMSProp | epoch: 015 | loss: 0.12709 - acc: 0.9621 -- iter: 160/363
[A[ATraining Step: 174  | total loss: [1m[32m0.11683[0m[0m | time: 76.136s
[2K
| RMSProp | epoch: 015 | loss: 0.11683 - acc: 0.9659 -- iter: 192/363
[A[ATraining Step: 175  | total loss: [1m[32m0.10819[0m[0m | time: 86.909s
[2K
| RMSProp | epoch: 015 | loss: 0.10819 - acc: 0.9693 -- iter: 224/363
[A[ATraining Step: 176  | total loss: [1m[32m0.11178[0m[0m | time: 95.464s
[2K
| RMSProp | epoch: 015 | loss: 0.11178 - acc: 0.9693 -- iter: 256/363
[A[ATraining Step: 177  | total loss: [1m[32m0.10224[0m[0m | time: 105.932s
[2K
| RMSProp | epoch: 015 | loss: 0.10224 - acc: 0.9723 -- iter: 288/363
[A[ATraining Step: 178  | total loss: [1m[32m0.09334[0m[0m | time: 119.537s
[2K
| RMSProp | epoch: 015 | loss: 0.09334 - acc: 0.9751 -- iter: 320/363
[A[ATraining Step: 179  | total loss: [1m[32m0.08624[0m[0m | time: 133.481s
[2K
| RMSProp | epoch: 015 | loss: 0.08624 - acc: 0.9776 -- iter: 352/363
[A[ATraining Step: 180  | total loss: [1m[32m0.07940[0m[0m | time: 156.613s
[2K
| RMSProp | epoch: 015 | loss: 0.07940 - acc: 0.9798 | val_loss: 0.83900 - val_acc: 0.6930 -- iter: 363/363
--
Validation AUC:0.8106750392464679
Validation AUPRC:0.8418091230853704
Test AUC:0.8790397045244691
Test AUPRC:0.9076303635762337
BestTestF1Score	0.79	0.54	0.75	0.69	0.91	52	23	34	5	0.05
BestTestMCCScore	0.82	0.65	0.82	0.82	0.82	47	10	47	10	0.18
BestTestAccuracyScore	0.82	0.65	0.82	0.82	0.82	47	10	47	10	0.18
BestValidationF1Score	0.8	0.48	0.75	0.72	0.89	58	22	27	7	0.05
BestValidationMCC	0.79	0.52	0.76	0.79	0.8	52	14	35	13	0.18
BestValidationAccuracy	0.79	0.52	0.76	0.79	0.8	52	14	35	13	0.18
TestPredictions (Threshold:0.18)
CHEMBL3808884,TP,ACT,0.6100000143051147	CHEMBL456796,TN,INACT,0.15000000596046448	CHEMBL31184,FP,INACT,0.7200000286102295	CHEMBL1331525,TN,INACT,0.009999999776482582	CHEMBL470851,TN,INACT,0.05000000074505806	CHEMBL2086750,TP,ACT,0.7900000214576721	CHEMBL497454,TN,INACT,0.009999999776482582	CHEMBL575925,TP,ACT,0.9900000095367432	CHEMBL209511,TN,INACT,0.0	CHEMBL2347053,FN,ACT,0.05000000074505806	CHEMBL3114027,TP,ACT,1.0	CHEMBL574738,FN,ACT,0.05000000074505806	CHEMBL3642839,TP,ACT,0.9800000190734863	CHEMBL522892,TP,ACT,0.3199999928474426	CHEMBL291986,TN,INACT,0.0	CHEMBL57553,TN,INACT,0.029999999329447746	CHEMBL559882,TN,INACT,0.019999999552965164	CHEMBL426047,TP,ACT,1.0	CHEMBL1956892,TN,INACT,0.10999999940395355	CHEMBL456964,TN,INACT,0.009999999776482582	CHEMBL552136,TN,INACT,0.019999999552965164	CHEMBL515051,TN,INACT,0.009999999776482582	CHEMBL3642834,TP,ACT,1.0	CHEMBL559683,TN,INACT,0.019999999552965164	CHEMBL179227,TP,ACT,1.0	CHEMBL1922210,TN,INACT,0.029999999329447746	CHEMBL328034,FP,INACT,0.7900000214576721	CHEMBL1980297,TP,ACT,1.0	CHEMBL606245,FN,ACT,0.14000000059604645	CHEMBL327820,FP,INACT,0.3499999940395355	CHEMBL50,TN,INACT,0.019999999552965164	CHEMBL1336,TP,ACT,1.0	CHEMBL132399,TN,INACT,0.019999999552965164	CHEMBL1242557,TP,ACT,1.0	CHEMBL205652,TN,INACT,0.05000000074505806	CHEMBL551936,TN,INACT,0.0	CHEMBL572881,FN,ACT,0.0	CHEMBL3780091,FN,ACT,0.03999999910593033	CHEMBL557456,TN,INACT,0.009999999776482582	CHEMBL179603,TP,ACT,1.0	CHEMBL557525,TN,INACT,0.07999999821186066	CHEMBL3642842,TP,ACT,0.9900000095367432	CHEMBL360526,TP,ACT,1.0	CHEMBL597592,TP,ACT,0.9200000166893005	CHEMBL521155,TN,INACT,0.009999999776482582	CHEMBL116423,TN,INACT,0.15000000596046448	CHEMBL490053,FP,INACT,0.7900000214576721	CHEMBL377300,TP,ACT,0.7099999785423279	CHEMBL498249,FP,INACT,0.20000000298023224	CHEMBL3764279,TP,ACT,0.9900000095367432	CHEMBL590568,TN,INACT,0.0	CHEMBL469346,TN,INACT,0.09000000357627869	CHEMBL592224,TN,INACT,0.019999999552965164	CHEMBL591050,TN,INACT,0.029999999329447746	CHEMBL103667,TP,ACT,0.9599999785423279	CHEMBL2420911,TN,INACT,0.009999999776482582	CHEMBL558601,TN,INACT,0.14000000059604645	CHEMBL71884,TN,INACT,0.0	CHEMBL606027,TN,INACT,0.0	CHEMBL428690,FN,ACT,0.0	CHEMBL520515,TN,INACT,0.0	CHEMBL178455,TP,ACT,1.0	CHEMBL490241,TN,INACT,0.009999999776482582	CHEMBL3642840,TP,ACT,0.5199999809265137	CHEMBL238617,TN,INACT,0.009999999776482582	CHEMBL3739732,TP,ACT,0.8199999928474426	CHEMBL605957,TP,ACT,1.0	CHEMBL179719,TP,ACT,1.0	CHEMBL2206278,TP,ACT,0.44999998807907104	CHEMBL3114028,TP,ACT,0.8999999761581421	CHEMBL91748,TN,INACT,0.17000000178813934	CHEMBL67655,TN,INACT,0.14000000059604645	CHEMBL498105,TP,ACT,0.9399999976158142	CHEMBL2086759,FN,ACT,0.0	CHEMBL1242471,TN,INACT,0.0	CHEMBL3746122,TP,ACT,0.9200000166893005	CHEMBL1829272,TN,INACT,0.0	CHEMBL1272182,TP,ACT,0.949999988079071	CHEMBL255863,FN,ACT,0.05000000074505806	CHEMBL2086751,TP,ACT,1.0	CHEMBL55360,TN,INACT,0.07000000029802322	CHEMBL150177,FP,INACT,0.4300000071525574	CHEMBL1172602,TN,INACT,0.029999999329447746	CHEMBL602123,TP,ACT,0.4000000059604645	CHEMBL498088,TP,ACT,1.0	CHEMBL525550,TP,ACT,0.9900000095367432	CHEMBL3114019,TP,ACT,1.0	CHEMBL91,TN,INACT,0.029999999329447746	CHEMBL1272021,TP,ACT,0.9399999976158142	CHEMBL8223,FP,INACT,0.7400000095367432	CHEMBL56731,TN,INACT,0.10000000149011612	CHEMBL1172877,TN,INACT,0.009999999776482582	CHEMBL3114024,TP,ACT,0.6399999856948853	CHEMBL332497,TN,INACT,0.019999999552965164	CHEMBL2312646,FP,INACT,0.7599999904632568	CHEMBL2010872,TP,ACT,1.0	CHEMBL3114029,TP,ACT,1.0	CHEMBL525921,TN,INACT,0.019999999552965164	CHEMBL602472,TN,INACT,0.15000000596046448	CHEMBL941,FN,ACT,0.03999999910593033	CHEMBL2087169,TP,ACT,0.25	CHEMBL3288526,TP,ACT,0.6399999856948853	CHEMBL2086753,TP,ACT,0.7300000190734863	CHEMBL426602,TP,ACT,1.0	CHEMBL369760,TP,ACT,1.0	CHEMBL1933802,FP,INACT,0.7900000214576721	CHEMBL3237943,FP,INACT,0.8799999952316284	CHEMBL2392240,TN,INACT,0.0	CHEMBL1668419,TP,ACT,0.8999999761581421	CHEMBL572878,TP,ACT,0.1899999976158142	CHEMBL1241674,FN,ACT,0.05000000074505806	CHEMBL591051,TN,INACT,0.009999999776482582	CHEMBL450786,TP,ACT,0.9399999976158142	CHEMBL524453,TP,ACT,1.0	

