CNNModel CHEMBL1974 RMSprop 0.0005 30 32 0 0.8 False True
Number of active compounds :	1244
Number of inactive compounds :	1244
---------------------------------
Run id: CNNModel_CHEMBL1974_RMSprop_0.0005_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1974_RMSprop_0.0005_30_32_0.8_True/
---------------------------------
Training samples: 1584
Validation samples: 496
--
Training Step: 1  | time: 1.364s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1584
[A[ATraining Step: 2  | total loss: [1m[32m0.62382[0m[0m | time: 2.384s
[2K
| RMSProp | epoch: 001 | loss: 0.62382 - acc: 0.5344 -- iter: 0064/1584
[A[ATraining Step: 3  | total loss: [1m[32m0.68055[0m[0m | time: 3.138s
[2K
| RMSProp | epoch: 001 | loss: 0.68055 - acc: 0.5063 -- iter: 0096/1584
[A[ATraining Step: 4  | total loss: [1m[32m0.69027[0m[0m | time: 4.029s
[2K
| RMSProp | epoch: 001 | loss: 0.69027 - acc: 0.4078 -- iter: 0128/1584
[A[ATraining Step: 5  | total loss: [1m[32m0.69233[0m[0m | time: 4.921s
[2K
| RMSProp | epoch: 001 | loss: 0.69233 - acc: 0.4284 -- iter: 0160/1584
[A[ATraining Step: 6  | total loss: [1m[32m0.69268[0m[0m | time: 5.823s
[2K
| RMSProp | epoch: 001 | loss: 0.69268 - acc: 0.6150 -- iter: 0192/1584
[A[ATraining Step: 7  | total loss: [1m[32m0.69276[0m[0m | time: 6.737s
[2K
| RMSProp | epoch: 001 | loss: 0.69276 - acc: 0.6023 -- iter: 0224/1584
[A[ATraining Step: 8  | total loss: [1m[32m0.69292[0m[0m | time: 7.639s
[2K
| RMSProp | epoch: 001 | loss: 0.69292 - acc: 0.5272 -- iter: 0256/1584
[A[ATraining Step: 9  | total loss: [1m[32m0.69305[0m[0m | time: 8.526s
[2K
| RMSProp | epoch: 001 | loss: 0.69305 - acc: 0.4797 -- iter: 0288/1584
[A[ATraining Step: 10  | total loss: [1m[32m0.69312[0m[0m | time: 9.412s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.4742 -- iter: 0320/1584
[A[ATraining Step: 11  | total loss: [1m[32m0.69327[0m[0m | time: 10.330s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.4568 -- iter: 0352/1584
[A[ATraining Step: 12  | total loss: [1m[32m0.69320[0m[0m | time: 11.234s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.5184 -- iter: 0384/1584
[A[ATraining Step: 13  | total loss: [1m[32m0.69308[0m[0m | time: 12.219s
[2K
| RMSProp | epoch: 001 | loss: 0.69308 - acc: 0.5239 -- iter: 0416/1584
[A[ATraining Step: 14  | total loss: [1m[32m0.69315[0m[0m | time: 13.184s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.5141 -- iter: 0448/1584
[A[ATraining Step: 15  | total loss: [1m[32m0.69310[0m[0m | time: 14.152s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5208 -- iter: 0480/1584
[A[ATraining Step: 16  | total loss: [1m[32m0.69318[0m[0m | time: 14.843s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4661 -- iter: 0512/1584
[A[ATraining Step: 17  | total loss: [1m[32m0.69310[0m[0m | time: 15.691s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5121 -- iter: 0544/1584
[A[ATraining Step: 18  | total loss: [1m[32m0.69306[0m[0m | time: 16.582s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5404 -- iter: 0576/1584
[A[ATraining Step: 19  | total loss: [1m[32m0.69313[0m[0m | time: 17.476s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4957 -- iter: 0608/1584
[A[ATraining Step: 20  | total loss: [1m[32m0.69316[0m[0m | time: 18.413s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4870 -- iter: 0640/1584
[A[ATraining Step: 21  | total loss: [1m[32m0.69316[0m[0m | time: 19.311s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.5007 -- iter: 0672/1584
[A[ATraining Step: 22  | total loss: [1m[32m0.69323[0m[0m | time: 20.206s
[2K
| RMSProp | epoch: 001 | loss: 0.69323 - acc: 0.4911 -- iter: 0704/1584
[A[ATraining Step: 23  | total loss: [1m[32m0.69330[0m[0m | time: 21.113s
[2K
| RMSProp | epoch: 001 | loss: 0.69330 - acc: 0.4393 -- iter: 0736/1584
[A[ATraining Step: 24  | total loss: [1m[32m0.69325[0m[0m | time: 22.002s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4564 -- iter: 0768/1584
[A[ATraining Step: 25  | total loss: [1m[32m0.69330[0m[0m | time: 22.811s
[2K
| RMSProp | epoch: 001 | loss: 0.69330 - acc: 0.4427 -- iter: 0800/1584
[A[ATraining Step: 26  | total loss: [1m[32m0.69328[0m[0m | time: 23.797s
[2K
| RMSProp | epoch: 001 | loss: 0.69328 - acc: 0.4579 -- iter: 0832/1584
[A[ATraining Step: 27  | total loss: [1m[32m0.69324[0m[0m | time: 24.767s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4526 -- iter: 0864/1584
[A[ATraining Step: 28  | total loss: [1m[32m0.69316[0m[0m | time: 25.720s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4957 -- iter: 0896/1584
[A[ATraining Step: 29  | total loss: [1m[32m0.69314[0m[0m | time: 26.471s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5044 -- iter: 0928/1584
[A[ATraining Step: 30  | total loss: [1m[32m0.69315[0m[0m | time: 27.342s
[2K
| RMSProp | epoch: 001 | loss: 0.69315 - acc: 0.5255 -- iter: 0960/1584
[A[ATraining Step: 31  | total loss: [1m[32m0.69321[0m[0m | time: 28.253s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4764 -- iter: 0992/1584
[A[ATraining Step: 32  | total loss: [1m[32m0.69318[0m[0m | time: 29.149s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4958 -- iter: 1024/1584
[A[ATraining Step: 33  | total loss: [1m[32m0.69319[0m[0m | time: 30.044s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4692 -- iter: 1056/1584
[A[ATraining Step: 34  | total loss: [1m[32m0.69321[0m[0m | time: 30.931s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4557 -- iter: 1088/1584
[A[ATraining Step: 35  | total loss: [1m[32m0.69322[0m[0m | time: 31.887s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4519 -- iter: 1120/1584
[A[ATraining Step: 36  | total loss: [1m[32m0.69321[0m[0m | time: 32.771s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4554 -- iter: 1152/1584
[A[ATraining Step: 37  | total loss: [1m[32m0.69321[0m[0m | time: 33.652s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4455 -- iter: 1184/1584
[A[ATraining Step: 38  | total loss: [1m[32m0.69321[0m[0m | time: 34.535s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4440 -- iter: 1216/1584
[A[ATraining Step: 39  | total loss: [1m[32m0.69319[0m[0m | time: 35.565s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4367 -- iter: 1248/1584
[A[ATraining Step: 40  | total loss: [1m[32m0.69320[0m[0m | time: 36.579s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4369 -- iter: 1280/1584
[A[ATraining Step: 41  | total loss: [1m[32m0.69321[0m[0m | time: 37.273s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4485 -- iter: 1312/1584
[A[ATraining Step: 42  | total loss: [1m[32m0.69320[0m[0m | time: 38.137s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4803 -- iter: 1344/1584
[A[ATraining Step: 43  | total loss: [1m[32m0.69316[0m[0m | time: 38.988s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.5113 -- iter: 1376/1584
[A[ATraining Step: 44  | total loss: [1m[32m0.69317[0m[0m | time: 39.847s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5094 -- iter: 1408/1584
[A[ATraining Step: 45  | total loss: [1m[32m0.69316[0m[0m | time: 40.714s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.5078 -- iter: 1440/1584
[A[ATraining Step: 46  | total loss: [1m[32m0.69320[0m[0m | time: 41.574s
[2K
| RMSProp | epoch: 001 | loss: 0.69320 - acc: 0.4752 -- iter: 1472/1584
[A[ATraining Step: 47  | total loss: [1m[32m0.69318[0m[0m | time: 42.473s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.4742 -- iter: 1504/1584
[A[ATraining Step: 48  | total loss: [1m[32m0.69317[0m[0m | time: 43.351s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4833 -- iter: 1536/1584
[A[ATraining Step: 49  | total loss: [1m[32m0.69308[0m[0m | time: 44.245s
[2K
| RMSProp | epoch: 001 | loss: 0.69308 - acc: 0.5057 -- iter: 1568/1584
[A[ATraining Step: 50  | total loss: [1m[32m0.69301[0m[0m | time: 47.265s
[2K
| RMSProp | epoch: 001 | loss: 0.69301 - acc: 0.5242 | val_loss: 0.69324 - val_acc: 0.4879 -- iter: 1584/1584
--
Training Step: 51  | total loss: [1m[32m0.69298[0m[0m | time: 0.454s
[2K
| RMSProp | epoch: 002 | loss: 0.69298 - acc: 0.5205 -- iter: 0032/1584
[A[ATraining Step: 52  | total loss: [1m[32m0.69301[0m[0m | time: 1.335s
[2K
| RMSProp | epoch: 002 | loss: 0.69301 - acc: 0.5174 -- iter: 0064/1584
[A[ATraining Step: 53  | total loss: [1m[32m0.69314[0m[0m | time: 2.258s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4918 -- iter: 0096/1584
[A[ATraining Step: 54  | total loss: [1m[32m0.69313[0m[0m | time: 3.185s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.4930 -- iter: 0128/1584
[A[ATraining Step: 55  | total loss: [1m[32m0.69305[0m[0m | time: 4.108s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5074 -- iter: 0160/1584
[A[ATraining Step: 56  | total loss: [1m[32m0.69304[0m[0m | time: 4.991s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5064 -- iter: 0192/1584
[A[ATraining Step: 57  | total loss: [1m[32m0.69312[0m[0m | time: 5.944s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.4925 -- iter: 0224/1584
[A[ATraining Step: 58  | total loss: [1m[32m0.69316[0m[0m | time: 6.747s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.4807 -- iter: 0256/1584
[A[ATraining Step: 59  | total loss: [1m[32m0.69322[0m[0m | time: 7.826s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4623 -- iter: 0288/1584
[A[ATraining Step: 60  | total loss: [1m[32m0.69320[0m[0m | time: 8.863s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4549 -- iter: 0320/1584
[A[ATraining Step: 61  | total loss: [1m[32m0.69319[0m[0m | time: 9.686s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4567 -- iter: 0352/1584
[A[ATraining Step: 62  | total loss: [1m[32m0.69324[0m[0m | time: 10.490s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4462 -- iter: 0384/1584
[A[ATraining Step: 63  | total loss: [1m[32m0.69323[0m[0m | time: 11.398s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4411 -- iter: 0416/1584
[A[ATraining Step: 64  | total loss: [1m[32m0.69323[0m[0m | time: 12.319s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4446 -- iter: 0448/1584
[A[ATraining Step: 65  | total loss: [1m[32m0.69321[0m[0m | time: 13.216s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4437 -- iter: 0480/1584
[A[ATraining Step: 66  | total loss: [1m[32m0.69323[0m[0m | time: 14.111s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4430 -- iter: 0512/1584
[A[ATraining Step: 67  | total loss: [1m[32m0.69324[0m[0m | time: 15.012s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4423 -- iter: 0544/1584
[A[ATraining Step: 68  | total loss: [1m[32m0.69322[0m[0m | time: 15.942s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4528 -- iter: 0576/1584
[A[ATraining Step: 69  | total loss: [1m[32m0.69320[0m[0m | time: 16.846s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4510 -- iter: 0608/1584
[A[ATraining Step: 70  | total loss: [1m[32m0.69320[0m[0m | time: 17.730s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4603 -- iter: 0640/1584
[A[ATraining Step: 71  | total loss: [1m[32m0.69317[0m[0m | time: 18.714s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4648 -- iter: 0672/1584
[A[ATraining Step: 72  | total loss: [1m[32m0.69318[0m[0m | time: 19.687s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4723 -- iter: 0704/1584
[A[ATraining Step: 73  | total loss: [1m[32m0.69322[0m[0m | time: 20.612s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.4684 -- iter: 0736/1584
[A[ATraining Step: 74  | total loss: [1m[32m0.69317[0m[0m | time: 21.351s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4856 -- iter: 0768/1584
[A[ATraining Step: 75  | total loss: [1m[32m0.69309[0m[0m | time: 22.192s
[2K
| RMSProp | epoch: 002 | loss: 0.69309 - acc: 0.5041 -- iter: 0800/1584
[A[ATraining Step: 76  | total loss: [1m[32m0.69314[0m[0m | time: 23.119s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4970 -- iter: 0832/1584
[A[ATraining Step: 77  | total loss: [1m[32m0.69323[0m[0m | time: 23.992s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4841 -- iter: 0864/1584
[A[ATraining Step: 78  | total loss: [1m[32m0.69330[0m[0m | time: 24.889s
[2K
| RMSProp | epoch: 002 | loss: 0.69330 - acc: 0.4727 -- iter: 0896/1584
[A[ATraining Step: 79  | total loss: [1m[32m0.69328[0m[0m | time: 25.751s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4722 -- iter: 0928/1584
[A[ATraining Step: 80  | total loss: [1m[32m0.69325[0m[0m | time: 26.637s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4911 -- iter: 0960/1584
[A[ATraining Step: 81  | total loss: [1m[32m0.69317[0m[0m | time: 27.498s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.5141 -- iter: 0992/1584
[A[ATraining Step: 82  | total loss: [1m[32m0.69322[0m[0m | time: 28.402s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.5064 -- iter: 1024/1584
[A[ATraining Step: 83  | total loss: [1m[32m0.69323[0m[0m | time: 29.254s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.5027 -- iter: 1056/1584
[A[ATraining Step: 84  | total loss: [1m[32m0.69324[0m[0m | time: 30.176s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4961 -- iter: 1088/1584
[A[ATraining Step: 85  | total loss: [1m[32m0.69313[0m[0m | time: 31.157s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5184 -- iter: 1120/1584
[A[ATraining Step: 86  | total loss: [1m[32m0.69304[0m[0m | time: 32.115s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5291 -- iter: 1152/1584
[A[ATraining Step: 87  | total loss: [1m[32m0.69321[0m[0m | time: 32.817s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.5137 -- iter: 1184/1584
[A[ATraining Step: 88  | total loss: [1m[32m0.69325[0m[0m | time: 33.690s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.5092 -- iter: 1216/1584
[A[ATraining Step: 89  | total loss: [1m[32m0.69329[0m[0m | time: 34.571s
[2K
| RMSProp | epoch: 002 | loss: 0.69329 - acc: 0.5020 -- iter: 1248/1584
[A[ATraining Step: 90  | total loss: [1m[32m0.69337[0m[0m | time: 35.437s
[2K
| RMSProp | epoch: 002 | loss: 0.69337 - acc: 0.4831 -- iter: 1280/1584
[A[ATraining Step: 91  | total loss: [1m[32m0.69331[0m[0m | time: 36.306s
[2K
| RMSProp | epoch: 002 | loss: 0.69331 - acc: 0.4941 -- iter: 1312/1584
[A[ATraining Step: 92  | total loss: [1m[32m0.69333[0m[0m | time: 37.186s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.4760 -- iter: 1344/1584
[A[ATraining Step: 93  | total loss: [1m[32m0.69330[0m[0m | time: 38.184s
[2K
| RMSProp | epoch: 002 | loss: 0.69330 - acc: 0.4815 -- iter: 1376/1584
[A[ATraining Step: 94  | total loss: [1m[32m0.69328[0m[0m | time: 39.093s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4802 -- iter: 1408/1584
[A[ATraining Step: 95  | total loss: [1m[32m0.69324[0m[0m | time: 39.976s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4978 -- iter: 1440/1584
[A[ATraining Step: 96  | total loss: [1m[32m0.69319[0m[0m | time: 40.815s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.5012 -- iter: 1472/1584
[A[ATraining Step: 97  | total loss: [1m[32m0.69319[0m[0m | time: 41.871s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4979 -- iter: 1504/1584
[A[ATraining Step: 98  | total loss: [1m[32m0.69312[0m[0m | time: 42.918s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5106 -- iter: 1536/1584
[A[ATraining Step: 99  | total loss: [1m[32m0.69321[0m[0m | time: 43.698s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.5002 -- iter: 1568/1584
[A[ATraining Step: 100  | total loss: [1m[32m0.69324[0m[0m | time: 46.866s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4939 | val_loss: 0.69324 - val_acc: 0.4879 -- iter: 1584/1584
--
Training Step: 101  | total loss: [1m[32m0.69319[0m[0m | time: 0.467s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5039 -- iter: 0032/1584
[A[ATraining Step: 102  | total loss: [1m[32m0.69309[0m[0m | time: 0.940s
[2K
| RMSProp | epoch: 003 | loss: 0.69309 - acc: 0.5160 -- iter: 0064/1584
[A[ATraining Step: 103  | total loss: [1m[32m0.69295[0m[0m | time: 1.843s
[2K
| RMSProp | epoch: 003 | loss: 0.69295 - acc: 0.5269 -- iter: 0096/1584
[A[ATraining Step: 104  | total loss: [1m[32m0.69286[0m[0m | time: 2.672s
[2K
| RMSProp | epoch: 003 | loss: 0.69286 - acc: 0.5305 -- iter: 0128/1584
[A[ATraining Step: 105  | total loss: [1m[32m0.69314[0m[0m | time: 3.685s
[2K
| RMSProp | epoch: 003 | loss: 0.69314 - acc: 0.5149 -- iter: 0160/1584
[A[ATraining Step: 106  | total loss: [1m[32m0.69274[0m[0m | time: 4.700s
[2K
| RMSProp | epoch: 003 | loss: 0.69274 - acc: 0.5416 -- iter: 0192/1584
[A[ATraining Step: 107  | total loss: [1m[32m0.69271[0m[0m | time: 5.631s
[2K
| RMSProp | epoch: 003 | loss: 0.69271 - acc: 0.5405 -- iter: 0224/1584
[A[ATraining Step: 108  | total loss: [1m[32m0.69282[0m[0m | time: 6.377s
[2K
| RMSProp | epoch: 003 | loss: 0.69282 - acc: 0.5333 -- iter: 0256/1584
[A[ATraining Step: 109  | total loss: [1m[32m0.69271[0m[0m | time: 7.247s
[2K
| RMSProp | epoch: 003 | loss: 0.69271 - acc: 0.5363 -- iter: 0288/1584
[A[ATraining Step: 110  | total loss: [1m[32m0.69309[0m[0m | time: 8.127s
[2K
| RMSProp | epoch: 003 | loss: 0.69309 - acc: 0.5201 -- iter: 0320/1584
[A[ATraining Step: 111  | total loss: [1m[32m0.69284[0m[0m | time: 9.013s
[2K
| RMSProp | epoch: 003 | loss: 0.69284 - acc: 0.5306 -- iter: 0352/1584
[A[ATraining Step: 112  | total loss: [1m[32m0.69323[0m[0m | time: 9.868s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.5151 -- iter: 0384/1584
[A[ATraining Step: 113  | total loss: [1m[32m0.69316[0m[0m | time: 10.792s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.5167 -- iter: 0416/1584
[A[ATraining Step: 114  | total loss: [1m[32m0.69323[0m[0m | time: 11.688s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.5119 -- iter: 0448/1584
[A[ATraining Step: 115  | total loss: [1m[32m0.69324[0m[0m | time: 12.569s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.5107 -- iter: 0480/1584
[A[ATraining Step: 116  | total loss: [1m[32m0.69304[0m[0m | time: 13.427s
[2K
| RMSProp | epoch: 003 | loss: 0.69304 - acc: 0.5190 -- iter: 0512/1584
[A[ATraining Step: 117  | total loss: [1m[32m0.69321[0m[0m | time: 14.275s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.5109 -- iter: 0544/1584
[A[ATraining Step: 118  | total loss: [1m[32m0.69329[0m[0m | time: 15.355s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.5066 -- iter: 0576/1584
[A[ATraining Step: 119  | total loss: [1m[32m0.69340[0m[0m | time: 16.380s
[2K
| RMSProp | epoch: 003 | loss: 0.69340 - acc: 0.4997 -- iter: 0608/1584
[A[ATraining Step: 120  | total loss: [1m[32m0.69316[0m[0m | time: 17.144s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.5154 -- iter: 0640/1584
[A[ATraining Step: 121  | total loss: [1m[32m0.69302[0m[0m | time: 17.988s
[2K
| RMSProp | epoch: 003 | loss: 0.69302 - acc: 0.5201 -- iter: 0672/1584
[A[ATraining Step: 122  | total loss: [1m[32m0.69288[0m[0m | time: 18.883s
[2K
| RMSProp | epoch: 003 | loss: 0.69288 - acc: 0.5243 -- iter: 0704/1584
[A[ATraining Step: 123  | total loss: [1m[32m0.69294[0m[0m | time: 19.763s
[2K
| RMSProp | epoch: 003 | loss: 0.69294 - acc: 0.5219 -- iter: 0736/1584
[A[ATraining Step: 124  | total loss: [1m[32m0.69307[0m[0m | time: 20.631s
[2K
| RMSProp | epoch: 003 | loss: 0.69307 - acc: 0.5166 -- iter: 0768/1584
[A[ATraining Step: 125  | total loss: [1m[32m0.69301[0m[0m | time: 21.591s
[2K
| RMSProp | epoch: 003 | loss: 0.69301 - acc: 0.5181 -- iter: 0800/1584
[A[ATraining Step: 126  | total loss: [1m[32m0.69254[0m[0m | time: 22.468s
[2K
| RMSProp | epoch: 003 | loss: 0.69254 - acc: 0.5350 -- iter: 0832/1584
[A[ATraining Step: 127  | total loss: [1m[32m0.69214[0m[0m | time: 23.357s
[2K
| RMSProp | epoch: 003 | loss: 0.69214 - acc: 0.5440 -- iter: 0864/1584
[A[ATraining Step: 128  | total loss: [1m[32m0.69157[0m[0m | time: 24.271s
[2K
| RMSProp | epoch: 003 | loss: 0.69157 - acc: 0.5552 -- iter: 0896/1584
[A[ATraining Step: 129  | total loss: [1m[32m0.69175[0m[0m | time: 25.095s
[2K
| RMSProp | epoch: 003 | loss: 0.69175 - acc: 0.5497 -- iter: 0928/1584
[A[ATraining Step: 130  | total loss: [1m[32m0.69155[0m[0m | time: 25.989s
[2K
| RMSProp | epoch: 003 | loss: 0.69155 - acc: 0.5510 -- iter: 0960/1584
[A[ATraining Step: 131  | total loss: [1m[32m0.69196[0m[0m | time: 26.976s
[2K
| RMSProp | epoch: 003 | loss: 0.69196 - acc: 0.5428 -- iter: 0992/1584
[A[ATraining Step: 132  | total loss: [1m[32m0.69212[0m[0m | time: 28.030s
[2K
| RMSProp | epoch: 003 | loss: 0.69212 - acc: 0.5385 -- iter: 1024/1584
[A[ATraining Step: 133  | total loss: [1m[32m0.69213[0m[0m | time: 28.748s
[2K
| RMSProp | epoch: 003 | loss: 0.69213 - acc: 0.5378 -- iter: 1056/1584
[A[ATraining Step: 134  | total loss: [1m[32m0.69204[0m[0m | time: 29.560s
[2K
| RMSProp | epoch: 003 | loss: 0.69204 - acc: 0.5371 -- iter: 1088/1584
[A[ATraining Step: 135  | total loss: [1m[32m0.69236[0m[0m | time: 30.432s
[2K
| RMSProp | epoch: 003 | loss: 0.69236 - acc: 0.5303 -- iter: 1120/1584
[A[ATraining Step: 136  | total loss: [1m[32m0.69231[0m[0m | time: 31.297s
[2K
| RMSProp | epoch: 003 | loss: 0.69231 - acc: 0.5304 -- iter: 1152/1584
[A[ATraining Step: 137  | total loss: [1m[32m0.69189[0m[0m | time: 32.224s
[2K
| RMSProp | epoch: 003 | loss: 0.69189 - acc: 0.5367 -- iter: 1184/1584
[A[ATraining Step: 138  | total loss: [1m[32m0.69187[0m[0m | time: 33.161s
[2K
| RMSProp | epoch: 003 | loss: 0.69187 - acc: 0.5362 -- iter: 1216/1584
[A[ATraining Step: 139  | total loss: [1m[32m0.69162[0m[0m | time: 34.063s
[2K
| RMSProp | epoch: 003 | loss: 0.69162 - acc: 0.5388 -- iter: 1248/1584
[A[ATraining Step: 140  | total loss: [1m[32m0.69238[0m[0m | time: 34.952s
[2K
| RMSProp | epoch: 003 | loss: 0.69238 - acc: 0.5287 -- iter: 1280/1584
[A[ATraining Step: 141  | total loss: [1m[32m0.69212[0m[0m | time: 35.810s
[2K
| RMSProp | epoch: 003 | loss: 0.69212 - acc: 0.5320 -- iter: 1312/1584
[A[ATraining Step: 142  | total loss: [1m[32m0.69201[0m[0m | time: 36.686s
[2K
| RMSProp | epoch: 003 | loss: 0.69201 - acc: 0.5320 -- iter: 1344/1584
[A[ATraining Step: 143  | total loss: [1m[32m0.69193[0m[0m | time: 37.633s
[2K
| RMSProp | epoch: 003 | loss: 0.69193 - acc: 0.5319 -- iter: 1376/1584
[A[ATraining Step: 144  | total loss: [1m[32m0.69215[0m[0m | time: 38.642s
[2K
| RMSProp | epoch: 003 | loss: 0.69215 - acc: 0.5287 -- iter: 1408/1584
[A[ATraining Step: 145  | total loss: [1m[32m0.69282[0m[0m | time: 39.664s
[2K
| RMSProp | epoch: 003 | loss: 0.69282 - acc: 0.5196 -- iter: 1440/1584
[A[ATraining Step: 146  | total loss: [1m[32m0.69333[0m[0m | time: 40.355s
[2K
| RMSProp | epoch: 003 | loss: 0.69333 - acc: 0.5083 -- iter: 1472/1584
[A[ATraining Step: 147  | total loss: [1m[32m0.69279[0m[0m | time: 41.201s
[2K
| RMSProp | epoch: 003 | loss: 0.69279 - acc: 0.5231 -- iter: 1504/1584
[A[ATraining Step: 148  | total loss: [1m[32m0.69255[0m[0m | time: 42.145s
[2K
| RMSProp | epoch: 003 | loss: 0.69255 - acc: 0.5270 -- iter: 1536/1584
[A[ATraining Step: 149  | total loss: [1m[32m0.69169[0m[0m | time: 43.043s
[2K
| RMSProp | epoch: 003 | loss: 0.69169 - acc: 0.5399 -- iter: 1568/1584
[A[ATraining Step: 150  | total loss: [1m[32m0.69283[0m[0m | time: 46.391s
[2K
| RMSProp | epoch: 003 | loss: 0.69283 - acc: 0.5266 | val_loss: 0.69378 - val_acc: 0.4879 -- iter: 1584/1584
--
Training Step: 151  | total loss: [1m[32m0.69363[0m[0m | time: 1.064s
[2K
| RMSProp | epoch: 004 | loss: 0.69363 - acc: 0.5114 -- iter: 0032/1584
[A[ATraining Step: 152  | total loss: [1m[32m0.69359[0m[0m | time: 1.637s
[2K
| RMSProp | epoch: 004 | loss: 0.69359 - acc: 0.5103 -- iter: 0064/1584
[A[ATraining Step: 153  | total loss: [1m[32m0.69333[0m[0m | time: 2.043s
[2K
| RMSProp | epoch: 004 | loss: 0.69333 - acc: 0.5155 -- iter: 0096/1584
[A[ATraining Step: 154  | total loss: [1m[32m0.69303[0m[0m | time: 2.832s
[2K
| RMSProp | epoch: 004 | loss: 0.69303 - acc: 0.5202 -- iter: 0128/1584
[A[ATraining Step: 155  | total loss: [1m[32m0.69258[0m[0m | time: 3.740s
[2K
| RMSProp | epoch: 004 | loss: 0.69258 - acc: 0.5275 -- iter: 0160/1584
[A[ATraining Step: 156  | total loss: [1m[32m0.69209[0m[0m | time: 4.643s
[2K
| RMSProp | epoch: 004 | loss: 0.69209 - acc: 0.5342 -- iter: 0192/1584
[A[ATraining Step: 157  | total loss: [1m[32m0.69300[0m[0m | time: 5.501s
[2K
| RMSProp | epoch: 004 | loss: 0.69300 - acc: 0.5214 -- iter: 0224/1584
[A[ATraining Step: 158  | total loss: [1m[32m0.69287[0m[0m | time: 6.458s
[2K
| RMSProp | epoch: 004 | loss: 0.69287 - acc: 0.5224 -- iter: 0256/1584
[A[ATraining Step: 159  | total loss: [1m[32m0.69294[0m[0m | time: 7.344s
[2K
| RMSProp | epoch: 004 | loss: 0.69294 - acc: 0.5201 -- iter: 0288/1584
[A[ATraining Step: 160  | total loss: [1m[32m0.69245[0m[0m | time: 8.299s
[2K
| RMSProp | epoch: 004 | loss: 0.69245 - acc: 0.5275 -- iter: 0320/1584
[A[ATraining Step: 161  | total loss: [1m[32m0.69323[0m[0m | time: 9.243s
[2K
| RMSProp | epoch: 004 | loss: 0.69323 - acc: 0.5154 -- iter: 0352/1584
[A[ATraining Step: 162  | total loss: [1m[32m0.69324[0m[0m | time: 10.138s
[2K
| RMSProp | epoch: 004 | loss: 0.69324 - acc: 0.5138 -- iter: 0384/1584
[A[ATraining Step: 163  | total loss: [1m[32m0.69424[0m[0m | time: 11.078s
[2K
| RMSProp | epoch: 004 | loss: 0.69424 - acc: 0.4906 -- iter: 0416/1584
[A[ATraining Step: 164  | total loss: [1m[32m0.69452[0m[0m | time: 12.108s
[2K
| RMSProp | epoch: 004 | loss: 0.69452 - acc: 0.4759 -- iter: 0448/1584
[A[ATraining Step: 165  | total loss: [1m[32m0.69462[0m[0m | time: 13.144s
[2K
| RMSProp | epoch: 004 | loss: 0.69462 - acc: 0.4595 -- iter: 0480/1584
[A[ATraining Step: 166  | total loss: [1m[32m0.69447[0m[0m | time: 13.877s
[2K
| RMSProp | epoch: 004 | loss: 0.69447 - acc: 0.4698 -- iter: 0512/1584
[A[ATraining Step: 167  | total loss: [1m[32m0.69443[0m[0m | time: 14.732s
[2K
| RMSProp | epoch: 004 | loss: 0.69443 - acc: 0.4666 -- iter: 0544/1584
[A[ATraining Step: 168  | total loss: [1m[32m0.69427[0m[0m | time: 15.648s
[2K
| RMSProp | epoch: 004 | loss: 0.69427 - acc: 0.4887 -- iter: 0576/1584
[A[ATraining Step: 169  | total loss: [1m[32m0.69417[0m[0m | time: 16.537s
[2K
| RMSProp | epoch: 004 | loss: 0.69417 - acc: 0.4867 -- iter: 0608/1584
[A[ATraining Step: 170  | total loss: [1m[32m0.69403[0m[0m | time: 17.435s
[2K
| RMSProp | epoch: 004 | loss: 0.69403 - acc: 0.4849 -- iter: 0640/1584
[A[ATraining Step: 171  | total loss: [1m[32m0.69390[0m[0m | time: 18.365s
[2K
| RMSProp | epoch: 004 | loss: 0.69390 - acc: 0.4958 -- iter: 0672/1584
[A[ATraining Step: 172  | total loss: [1m[32m0.69383[0m[0m | time: 19.295s
[2K
| RMSProp | epoch: 004 | loss: 0.69383 - acc: 0.4962 -- iter: 0704/1584
[A[ATraining Step: 173  | total loss: [1m[32m0.69395[0m[0m | time: 20.182s
[2K
| RMSProp | epoch: 004 | loss: 0.69395 - acc: 0.4841 -- iter: 0736/1584
[A[ATraining Step: 174  | total loss: [1m[32m0.69378[0m[0m | time: 21.042s
[2K
| RMSProp | epoch: 004 | loss: 0.69378 - acc: 0.4951 -- iter: 0768/1584
[A[ATraining Step: 175  | total loss: [1m[32m0.69336[0m[0m | time: 21.903s
[2K
| RMSProp | epoch: 004 | loss: 0.69336 - acc: 0.5143 -- iter: 0800/1584
[A[ATraining Step: 176  | total loss: [1m[32m0.69371[0m[0m | time: 22.988s
[2K
| RMSProp | epoch: 004 | loss: 0.69371 - acc: 0.5035 -- iter: 0832/1584
[A[ATraining Step: 177  | total loss: [1m[32m0.69359[0m[0m | time: 24.070s
[2K
| RMSProp | epoch: 004 | loss: 0.69359 - acc: 0.5063 -- iter: 0864/1584
[A[ATraining Step: 178  | total loss: [1m[32m0.69323[0m[0m | time: 24.895s
[2K
| RMSProp | epoch: 004 | loss: 0.69323 - acc: 0.5181 -- iter: 0896/1584
[A[ATraining Step: 179  | total loss: [1m[32m0.69336[0m[0m | time: 25.712s
[2K
| RMSProp | epoch: 004 | loss: 0.69336 - acc: 0.5132 -- iter: 0928/1584
[A[ATraining Step: 180  | total loss: [1m[32m0.69295[0m[0m | time: 26.566s
[2K
| RMSProp | epoch: 004 | loss: 0.69295 - acc: 0.5244 -- iter: 0960/1584
[A[ATraining Step: 181  | total loss: [1m[32m0.69253[0m[0m | time: 27.461s
[2K
| RMSProp | epoch: 004 | loss: 0.69253 - acc: 0.5313 -- iter: 0992/1584
[A[ATraining Step: 182  | total loss: [1m[32m0.69316[0m[0m | time: 28.333s
[2K
| RMSProp | epoch: 004 | loss: 0.69316 - acc: 0.5219 -- iter: 1024/1584
[A[ATraining Step: 183  | total loss: [1m[32m0.69342[0m[0m | time: 29.222s
[2K
| RMSProp | epoch: 004 | loss: 0.69342 - acc: 0.5135 -- iter: 1056/1584
[A[ATraining Step: 184  | total loss: [1m[32m0.69311[0m[0m | time: 30.108s
[2K
| RMSProp | epoch: 004 | loss: 0.69311 - acc: 0.5215 -- iter: 1088/1584
[A[ATraining Step: 185  | total loss: [1m[32m0.69285[0m[0m | time: 31.023s
[2K
| RMSProp | epoch: 004 | loss: 0.69285 - acc: 0.5256 -- iter: 1120/1584
[A[ATraining Step: 186  | total loss: [1m[32m0.69342[0m[0m | time: 31.925s
[2K
| RMSProp | epoch: 004 | loss: 0.69342 - acc: 0.5137 -- iter: 1152/1584
[A[ATraining Step: 187  | total loss: [1m[32m0.69390[0m[0m | time: 32.814s
[2K
| RMSProp | epoch: 004 | loss: 0.69390 - acc: 0.4967 -- iter: 1184/1584
[A[ATraining Step: 188  | total loss: [1m[32m0.69389[0m[0m | time: 33.651s
[2K
| RMSProp | epoch: 004 | loss: 0.69389 - acc: 0.4939 -- iter: 1216/1584
[A[ATraining Step: 189  | total loss: [1m[32m0.69392[0m[0m | time: 34.680s
[2K
| RMSProp | epoch: 004 | loss: 0.69392 - acc: 0.4851 -- iter: 1248/1584
[A[ATraining Step: 190  | total loss: [1m[32m0.69384[0m[0m | time: 35.686s
[2K
| RMSProp | epoch: 004 | loss: 0.69384 - acc: 0.4866 -- iter: 1280/1584
[A[ATraining Step: 191  | total loss: [1m[32m0.69374[0m[0m | time: 36.575s
[2K
| RMSProp | epoch: 004 | loss: 0.69374 - acc: 0.4942 -- iter: 1312/1584
[A[ATraining Step: 192  | total loss: [1m[32m0.69356[0m[0m | time: 37.317s
[2K
| RMSProp | epoch: 004 | loss: 0.69356 - acc: 0.5042 -- iter: 1344/1584
[A[ATraining Step: 193  | total loss: [1m[32m0.69369[0m[0m | time: 38.211s
[2K
| RMSProp | epoch: 004 | loss: 0.69369 - acc: 0.4975 -- iter: 1376/1584
[A[ATraining Step: 194  | total loss: [1m[32m0.69358[0m[0m | time: 39.155s
[2K
| RMSProp | epoch: 004 | loss: 0.69358 - acc: 0.5009 -- iter: 1408/1584
[A[ATraining Step: 195  | total loss: [1m[32m0.69325[0m[0m | time: 40.047s
[2K
| RMSProp | epoch: 004 | loss: 0.69325 - acc: 0.5164 -- iter: 1440/1584
[A[ATraining Step: 196  | total loss: [1m[32m0.69317[0m[0m | time: 40.932s
[2K
| RMSProp | epoch: 004 | loss: 0.69317 - acc: 0.5179 -- iter: 1472/1584
[A[ATraining Step: 197  | total loss: [1m[32m0.69339[0m[0m | time: 41.862s
[2K
| RMSProp | epoch: 004 | loss: 0.69339 - acc: 0.5099 -- iter: 1504/1584
[A[ATraining Step: 198  | total loss: [1m[32m0.69351[0m[0m | time: 42.759s
[2K
| RMSProp | epoch: 004 | loss: 0.69351 - acc: 0.5026 -- iter: 1536/1584
[A[ATraining Step: 199  | total loss: [1m[32m0.69365[0m[0m | time: 43.639s
[2K
| RMSProp | epoch: 004 | loss: 0.69365 - acc: 0.4930 -- iter: 1568/1584
[A[ATraining Step: 200  | total loss: [1m[32m0.69360[0m[0m | time: 46.911s
[2K
| RMSProp | epoch: 004 | loss: 0.69360 - acc: 0.4937 | val_loss: 0.69319 - val_acc: 0.4879 -- iter: 1584/1584
--
Training Step: 201  | total loss: [1m[32m0.69358[0m[0m | time: 0.983s
[2K
| RMSProp | epoch: 005 | loss: 0.69358 - acc: 0.4912 -- iter: 0032/1584
[A[ATraining Step: 202  | total loss: [1m[32m0.69354[0m[0m | time: 1.879s
[2K
| RMSProp | epoch: 005 | loss: 0.69354 - acc: 0.4983 -- iter: 0064/1584
[A[ATraining Step: 203  | total loss: [1m[32m0.69346[0m[0m | time: 2.346s
[2K
| RMSProp | epoch: 005 | loss: 0.69346 - acc: 0.5079 -- iter: 0096/1584
[A[ATraining Step: 204  | total loss: [1m[32m0.69386[0m[0m | time: 2.804s
[2K
| RMSProp | epoch: 005 | loss: 0.69386 - acc: 0.4821 -- iter: 0128/1584
[A[ATraining Step: 205  | total loss: [1m[32m0.69387[0m[0m | time: 3.709s
[2K
| RMSProp | epoch: 005 | loss: 0.69387 - acc: 0.4589 -- iter: 0160/1584
[A[ATraining Step: 206  | total loss: [1m[32m0.69382[0m[0m | time: 4.495s
[2K
| RMSProp | epoch: 005 | loss: 0.69382 - acc: 0.4630 -- iter: 0192/1584
[A[ATraining Step: 207  | total loss: [1m[32m0.69394[0m[0m | time: 5.493s
[2K
| RMSProp | epoch: 005 | loss: 0.69394 - acc: 0.4542 -- iter: 0224/1584
[A[ATraining Step: 208  | total loss: [1m[32m0.69388[0m[0m | time: 6.518s
[2K
| RMSProp | epoch: 005 | loss: 0.69388 - acc: 0.4556 -- iter: 0256/1584
[A[ATraining Step: 209  | total loss: [1m[32m0.69382[0m[0m | time: 7.427s
[2K
| RMSProp | epoch: 005 | loss: 0.69382 - acc: 0.4570 -- iter: 0288/1584
[A[ATraining Step: 210  | total loss: [1m[32m0.69368[0m[0m | time: 8.193s
[2K
| RMSProp | epoch: 005 | loss: 0.69368 - acc: 0.4738 -- iter: 0320/1584
[A[ATraining Step: 211  | total loss: [1m[32m0.69386[0m[0m | time: 9.126s
[2K
| RMSProp | epoch: 005 | loss: 0.69386 - acc: 0.4608 -- iter: 0352/1584
[A[ATraining Step: 212  | total loss: [1m[32m0.69379[0m[0m | time: 10.059s
[2K
| RMSProp | epoch: 005 | loss: 0.69379 - acc: 0.4616 -- iter: 0384/1584
[A[ATraining Step: 213  | total loss: [1m[32m0.69371[0m[0m | time: 10.960s
[2K
| RMSProp | epoch: 005 | loss: 0.69371 - acc: 0.4810 -- iter: 0416/1584
[A[ATraining Step: 214  | total loss: [1m[32m0.69367[0m[0m | time: 11.862s
[2K
| RMSProp | epoch: 005 | loss: 0.69367 - acc: 0.4767 -- iter: 0448/1584
[A[ATraining Step: 215  | total loss: [1m[32m0.69360[0m[0m | time: 12.819s
[2K
| RMSProp | epoch: 005 | loss: 0.69360 - acc: 0.4790 -- iter: 0480/1584
[A[ATraining Step: 216  | total loss: [1m[32m0.69356[0m[0m | time: 13.720s
[2K
| RMSProp | epoch: 005 | loss: 0.69356 - acc: 0.4780 -- iter: 0512/1584
[A[ATraining Step: 217  | total loss: [1m[32m0.69350[0m[0m | time: 14.612s
[2K
| RMSProp | epoch: 005 | loss: 0.69350 - acc: 0.4833 -- iter: 0544/1584
[A[ATraining Step: 218  | total loss: [1m[32m0.69343[0m[0m | time: 15.467s
[2K
| RMSProp | epoch: 005 | loss: 0.69343 - acc: 0.4912 -- iter: 0576/1584
[A[ATraining Step: 219  | total loss: [1m[32m0.69358[0m[0m | time: 16.409s
[2K
| RMSProp | epoch: 005 | loss: 0.69358 - acc: 0.4765 -- iter: 0608/1584
[A[ATraining Step: 220  | total loss: [1m[32m0.69354[0m[0m | time: 17.408s
[2K
| RMSProp | epoch: 005 | loss: 0.69354 - acc: 0.4820 -- iter: 0640/1584
[A[ATraining Step: 221  | total loss: [1m[32m0.69350[0m[0m | time: 18.437s
[2K
| RMSProp | epoch: 005 | loss: 0.69350 - acc: 0.4806 -- iter: 0672/1584
[A[ATraining Step: 222  | total loss: [1m[32m0.69349[0m[0m | time: 19.165s
[2K
| RMSProp | epoch: 005 | loss: 0.69349 - acc: 0.4732 -- iter: 0704/1584
[A[ATraining Step: 223  | total loss: [1m[32m0.69357[0m[0m | time: 20.022s
[2K
| RMSProp | epoch: 005 | loss: 0.69357 - acc: 0.4509 -- iter: 0736/1584
[A[ATraining Step: 224  | total loss: [1m[32m0.69355[0m[0m | time: 20.919s
[2K
| RMSProp | epoch: 005 | loss: 0.69355 - acc: 0.4527 -- iter: 0768/1584
[A[ATraining Step: 225  | total loss: [1m[32m0.69359[0m[0m | time: 21.791s
[2K
| RMSProp | epoch: 005 | loss: 0.69359 - acc: 0.4480 -- iter: 0800/1584
[A[ATraining Step: 226  | total loss: [1m[32m0.69354[0m[0m | time: 22.670s
[2K
| RMSProp | epoch: 005 | loss: 0.69354 - acc: 0.4501 -- iter: 0832/1584
[A[ATraining Step: 227  | total loss: [1m[32m0.69351[0m[0m | time: 23.543s
[2K
| RMSProp | epoch: 005 | loss: 0.69351 - acc: 0.4645 -- iter: 0864/1584
[A[ATraining Step: 228  | total loss: [1m[32m0.69345[0m[0m | time: 24.435s
[2K
| RMSProp | epoch: 005 | loss: 0.69345 - acc: 0.4711 -- iter: 0896/1584
[A[ATraining Step: 229  | total loss: [1m[32m0.69345[0m[0m | time: 25.347s
[2K
| RMSProp | epoch: 005 | loss: 0.69345 - acc: 0.4678 -- iter: 0928/1584
[A[ATraining Step: 230  | total loss: [1m[32m0.69345[0m[0m | time: 26.209s
[2K
| RMSProp | epoch: 005 | loss: 0.69345 - acc: 0.4585 -- iter: 0960/1584
[A[ATraining Step: 231  | total loss: [1m[32m0.69340[0m[0m | time: 27.042s
[2K
| RMSProp | epoch: 005 | loss: 0.69340 - acc: 0.4658 -- iter: 0992/1584
[A[ATraining Step: 232  | total loss: [1m[32m0.69344[0m[0m | time: 28.060s
[2K
| RMSProp | epoch: 005 | loss: 0.69344 - acc: 0.4598 -- iter: 1024/1584
[A[ATraining Step: 233  | total loss: [1m[32m0.69341[0m[0m | time: 29.070s
[2K
| RMSProp | epoch: 005 | loss: 0.69341 - acc: 0.4607 -- iter: 1056/1584
[A[ATraining Step: 234  | total loss: [1m[32m0.69339[0m[0m | time: 29.978s
[2K
| RMSProp | epoch: 005 | loss: 0.69339 - acc: 0.4490 -- iter: 1088/1584
[A[ATraining Step: 235  | total loss: [1m[32m0.69337[0m[0m | time: 30.703s
[2K
| RMSProp | epoch: 005 | loss: 0.69337 - acc: 0.4510 -- iter: 1120/1584
[A[ATraining Step: 236  | total loss: [1m[32m0.69335[0m[0m | time: 31.553s
[2K
| RMSProp | epoch: 005 | loss: 0.69335 - acc: 0.4559 -- iter: 1152/1584
[A[ATraining Step: 237  | total loss: [1m[32m0.69340[0m[0m | time: 32.443s
[2K
| RMSProp | epoch: 005 | loss: 0.69340 - acc: 0.4478 -- iter: 1184/1584
[A[ATraining Step: 238  | total loss: [1m[32m0.69340[0m[0m | time: 33.336s
[2K
| RMSProp | epoch: 005 | loss: 0.69340 - acc: 0.4530 -- iter: 1216/1584
[A[ATraining Step: 239  | total loss: [1m[32m0.69338[0m[0m | time: 34.224s
[2K
| RMSProp | epoch: 005 | loss: 0.69338 - acc: 0.4577 -- iter: 1248/1584
[A[ATraining Step: 240  | total loss: [1m[32m0.69341[0m[0m | time: 35.122s
[2K
| RMSProp | epoch: 005 | loss: 0.69341 - acc: 0.4494 -- iter: 1280/1584
[A[ATraining Step: 241  | total loss: [1m[32m0.69333[0m[0m | time: 36.039s
[2K
| RMSProp | epoch: 005 | loss: 0.69333 - acc: 0.4639 -- iter: 1312/1584
[A[ATraining Step: 242  | total loss: [1m[32m0.69328[0m[0m | time: 36.924s
[2K
| RMSProp | epoch: 005 | loss: 0.69328 - acc: 0.4706 -- iter: 1344/1584
[A[ATraining Step: 243  | total loss: [1m[32m0.69280[0m[0m | time: 37.800s
[2K
| RMSProp | epoch: 005 | loss: 0.69280 - acc: 0.4986 -- iter: 1376/1584
[A[ATraining Step: 244  | total loss: [1m[32m0.69308[0m[0m | time: 38.610s
[2K
| RMSProp | epoch: 005 | loss: 0.69308 - acc: 0.4956 -- iter: 1408/1584
[A[ATraining Step: 245  | total loss: [1m[32m0.69296[0m[0m | time: 39.655s
[2K
| RMSProp | epoch: 005 | loss: 0.69296 - acc: 0.4991 -- iter: 1440/1584
[A[ATraining Step: 246  | total loss: [1m[32m0.69298[0m[0m | time: 40.693s
[2K
| RMSProp | epoch: 005 | loss: 0.69298 - acc: 0.4992 -- iter: 1472/1584
[A[ATraining Step: 247  | total loss: [1m[32m0.69289[0m[0m | time: 41.599s
[2K
| RMSProp | epoch: 005 | loss: 0.69289 - acc: 0.5024 -- iter: 1504/1584
[A[ATraining Step: 248  | total loss: [1m[32m0.69235[0m[0m | time: 42.405s
[2K
| RMSProp | epoch: 005 | loss: 0.69235 - acc: 0.5147 -- iter: 1536/1584
[A[ATraining Step: 249  | total loss: [1m[32m0.69144[0m[0m | time: 43.373s
[2K
| RMSProp | epoch: 005 | loss: 0.69144 - acc: 0.5226 -- iter: 1568/1584
[A[ATraining Step: 250  | total loss: [1m[32m0.69421[0m[0m | time: 46.701s
[2K
| RMSProp | epoch: 005 | loss: 0.69421 - acc: 0.5172 | val_loss: 0.69379 - val_acc: 0.4879 -- iter: 1584/1584
--
Training Step: 251  | total loss: [1m[32m0.69538[0m[0m | time: 1.003s
[2K
| RMSProp | epoch: 006 | loss: 0.69538 - acc: 0.4999 -- iter: 0032/1584
[A[ATraining Step: 252  | total loss: [1m[32m0.69570[0m[0m | time: 1.992s
[2K
| RMSProp | epoch: 006 | loss: 0.69570 - acc: 0.4874 -- iter: 0064/1584
[A[ATraining Step: 253  | total loss: [1m[32m0.69495[0m[0m | time: 2.692s
[2K
| RMSProp | epoch: 006 | loss: 0.69495 - acc: 0.5074 -- iter: 0096/1584
[A[ATraining Step: 254  | total loss: [1m[32m0.69475[0m[0m | time: 3.116s
[2K
| RMSProp | epoch: 006 | loss: 0.69475 - acc: 0.5066 -- iter: 0128/1584
[A[ATraining Step: 255  | total loss: [1m[32m0.69415[0m[0m | time: 3.575s
[2K
| RMSProp | epoch: 006 | loss: 0.69415 - acc: 0.5185 -- iter: 0160/1584
[A[ATraining Step: 256  | total loss: [1m[32m0.69336[0m[0m | time: 4.442s
[2K
| RMSProp | epoch: 006 | loss: 0.69336 - acc: 0.5291 -- iter: 0192/1584
[A[ATraining Step: 257  | total loss: [1m[32m0.69268[0m[0m | time: 5.303s
[2K
| RMSProp | epoch: 006 | loss: 0.69268 - acc: 0.5356 -- iter: 0224/1584
[A[ATraining Step: 258  | total loss: [1m[32m0.69257[0m[0m | time: 6.197s
[2K
| RMSProp | epoch: 006 | loss: 0.69257 - acc: 0.5352 -- iter: 0256/1584
[A[ATraining Step: 259  | total loss: [1m[32m0.69214[0m[0m | time: 7.047s
[2K
| RMSProp | epoch: 006 | loss: 0.69214 - acc: 0.5379 -- iter: 0288/1584
[A[ATraining Step: 260  | total loss: [1m[32m0.69350[0m[0m | time: 7.945s
[2K
| RMSProp | epoch: 006 | loss: 0.69350 - acc: 0.5247 -- iter: 0320/1584
[A[ATraining Step: 261  | total loss: [1m[32m0.69411[0m[0m | time: 8.829s
[2K
| RMSProp | epoch: 006 | loss: 0.69411 - acc: 0.5129 -- iter: 0352/1584
[A[ATraining Step: 262  | total loss: [1m[32m0.69465[0m[0m | time: 9.762s
[2K
| RMSProp | epoch: 006 | loss: 0.69465 - acc: 0.4991 -- iter: 0384/1584
[A[ATraining Step: 263  | total loss: [1m[32m0.69471[0m[0m | time: 10.634s
[2K
| RMSProp | epoch: 006 | loss: 0.69471 - acc: 0.4929 -- iter: 0416/1584
[A[ATraining Step: 264  | total loss: [1m[32m0.69478[0m[0m | time: 11.538s
[2K
| RMSProp | epoch: 006 | loss: 0.69478 - acc: 0.4843 -- iter: 0448/1584
[A[ATraining Step: 265  | total loss: [1m[32m0.69490[0m[0m | time: 12.561s
[2K
| RMSProp | epoch: 006 | loss: 0.69490 - acc: 0.4671 -- iter: 0480/1584
[A[ATraining Step: 266  | total loss: [1m[32m0.69473[0m[0m | time: 13.608s
[2K
| RMSProp | epoch: 006 | loss: 0.69473 - acc: 0.4641 -- iter: 0512/1584
[A[ATraining Step: 267  | total loss: [1m[32m0.69454[0m[0m | time: 14.316s
[2K
| RMSProp | epoch: 006 | loss: 0.69454 - acc: 0.4708 -- iter: 0544/1584
[A[ATraining Step: 268  | total loss: [1m[32m0.69446[0m[0m | time: 15.215s
[2K
| RMSProp | epoch: 006 | loss: 0.69446 - acc: 0.4675 -- iter: 0576/1584
[A[ATraining Step: 269  | total loss: [1m[32m0.69431[0m[0m | time: 16.106s
[2K
| RMSProp | epoch: 006 | loss: 0.69431 - acc: 0.4833 -- iter: 0608/1584
[A[ATraining Step: 270  | total loss: [1m[32m0.69418[0m[0m | time: 17.017s
[2K
| RMSProp | epoch: 006 | loss: 0.69418 - acc: 0.4849 -- iter: 0640/1584
[A[ATraining Step: 271  | total loss: [1m[32m0.69402[0m[0m | time: 17.936s
[2K
| RMSProp | epoch: 006 | loss: 0.69402 - acc: 0.4927 -- iter: 0672/1584
[A[ATraining Step: 272  | total loss: [1m[32m0.69372[0m[0m | time: 18.885s
[2K
| RMSProp | epoch: 006 | loss: 0.69372 - acc: 0.5059 -- iter: 0704/1584
[A[ATraining Step: 273  | total loss: [1m[32m0.69380[0m[0m | time: 19.786s
[2K
| RMSProp | epoch: 006 | loss: 0.69380 - acc: 0.5022 -- iter: 0736/1584
[A[ATraining Step: 274  | total loss: [1m[32m0.69343[0m[0m | time: 20.656s
[2K
| RMSProp | epoch: 006 | loss: 0.69343 - acc: 0.5114 -- iter: 0768/1584
[A[ATraining Step: 275  | total loss: [1m[32m0.69288[0m[0m | time: 21.525s
[2K
| RMSProp | epoch: 006 | loss: 0.69288 - acc: 0.5196 -- iter: 0800/1584
[A[ATraining Step: 276  | total loss: [1m[32m0.69477[0m[0m | time: 22.324s
[2K
| RMSProp | epoch: 006 | loss: 0.69477 - acc: 0.5051 -- iter: 0832/1584
[A[ATraining Step: 277  | total loss: [1m[32m0.69433[0m[0m | time: 23.329s
[2K
| RMSProp | epoch: 006 | loss: 0.69433 - acc: 0.5140 -- iter: 0864/1584
[A[ATraining Step: 278  | total loss: [1m[32m0.69452[0m[0m | time: 24.309s
[2K
| RMSProp | epoch: 006 | loss: 0.69452 - acc: 0.5063 -- iter: 0896/1584
[A[ATraining Step: 279  | total loss: [1m[32m0.69394[0m[0m | time: 25.222s
[2K
| RMSProp | epoch: 006 | loss: 0.69394 - acc: 0.5182 -- iter: 0928/1584
[A[ATraining Step: 280  | total loss: [1m[32m0.69405[0m[0m | time: 25.954s
[2K
| RMSProp | epoch: 006 | loss: 0.69405 - acc: 0.5133 -- iter: 0960/1584
[A[ATraining Step: 281  | total loss: [1m[32m0.69346[0m[0m | time: 26.802s
[2K
| RMSProp | epoch: 006 | loss: 0.69346 - acc: 0.5244 -- iter: 0992/1584
[A[ATraining Step: 282  | total loss: [1m[32m0.69422[0m[0m | time: 27.690s
[2K
| RMSProp | epoch: 006 | loss: 0.69422 - acc: 0.5095 -- iter: 1024/1584
[A[ATraining Step: 283  | total loss: [1m[32m0.69415[0m[0m | time: 28.567s
[2K
| RMSProp | epoch: 006 | loss: 0.69415 - acc: 0.5085 -- iter: 1056/1584
[A[ATraining Step: 284  | total loss: [1m[32m0.69372[0m[0m | time: 29.473s
[2K
| RMSProp | epoch: 006 | loss: 0.69372 - acc: 0.5171 -- iter: 1088/1584
[A[ATraining Step: 285  | total loss: [1m[32m0.69354[0m[0m | time: 30.372s
[2K
| RMSProp | epoch: 006 | loss: 0.69354 - acc: 0.5185 -- iter: 1120/1584
[A[ATraining Step: 286  | total loss: [1m[32m0.69275[0m[0m | time: 31.271s
[2K
| RMSProp | epoch: 006 | loss: 0.69275 - acc: 0.5323 -- iter: 1152/1584
[A[ATraining Step: 287  | total loss: [1m[32m0.69309[0m[0m | time: 32.129s
[2K
| RMSProp | epoch: 006 | loss: 0.69309 - acc: 0.5259 -- iter: 1184/1584
[A[ATraining Step: 288  | total loss: [1m[32m0.69374[0m[0m | time: 32.965s
[2K
| RMSProp | epoch: 006 | loss: 0.69374 - acc: 0.5139 -- iter: 1216/1584
[A[ATraining Step: 289  | total loss: [1m[32m0.69333[0m[0m | time: 33.808s
[2K
| RMSProp | epoch: 006 | loss: 0.69333 - acc: 0.5219 -- iter: 1248/1584
[A[ATraining Step: 290  | total loss: [1m[32m0.69426[0m[0m | time: 34.898s
[2K
| RMSProp | epoch: 006 | loss: 0.69426 - acc: 0.5010 -- iter: 1280/1584
[A[ATraining Step: 291  | total loss: [1m[32m0.69421[0m[0m | time: 35.870s
[2K
| RMSProp | epoch: 006 | loss: 0.69421 - acc: 0.4978 -- iter: 1312/1584
[A[ATraining Step: 292  | total loss: [1m[32m0.69478[0m[0m | time: 36.683s
[2K
| RMSProp | epoch: 006 | loss: 0.69478 - acc: 0.4699 -- iter: 1344/1584
[A[ATraining Step: 293  | total loss: [1m[32m0.69463[0m[0m | time: 37.469s
[2K
| RMSProp | epoch: 006 | loss: 0.69463 - acc: 0.4760 -- iter: 1376/1584
[A[ATraining Step: 294  | total loss: [1m[32m0.69450[0m[0m | time: 38.396s
[2K
| RMSProp | epoch: 006 | loss: 0.69450 - acc: 0.4753 -- iter: 1408/1584
[A[ATraining Step: 295  | total loss: [1m[32m0.69427[0m[0m | time: 39.272s
[2K
| RMSProp | epoch: 006 | loss: 0.69427 - acc: 0.4965 -- iter: 1440/1584
[A[ATraining Step: 296  | total loss: [1m[32m0.69412[0m[0m | time: 40.166s
[2K
| RMSProp | epoch: 006 | loss: 0.69412 - acc: 0.5000 -- iter: 1472/1584
[A[ATraining Step: 297  | total loss: [1m[32m0.69413[0m[0m | time: 41.053s
[2K
| RMSProp | epoch: 006 | loss: 0.69413 - acc: 0.4937 -- iter: 1504/1584
[A[ATraining Step: 298  | total loss: [1m[32m0.69390[0m[0m | time: 41.970s
[2K
| RMSProp | epoch: 006 | loss: 0.69390 - acc: 0.5037 -- iter: 1536/1584
[A[ATraining Step: 299  | total loss: [1m[32m0.69358[0m[0m | time: 42.847s
[2K
| RMSProp | epoch: 006 | loss: 0.69358 - acc: 0.5159 -- iter: 1568/1584
[A[ATraining Step: 300  | total loss: [1m[32m0.69364[0m[0m | time: 46.120s
[2K
| RMSProp | epoch: 006 | loss: 0.69364 - acc: 0.5111 | val_loss: 0.69346 - val_acc: 0.4879 -- iter: 1584/1584
--
Training Step: 301  | total loss: [1m[32m0.69353[0m[0m | time: 0.857s
[2K
| RMSProp | epoch: 007 | loss: 0.69353 - acc: 0.5132 -- iter: 0032/1584
[A[ATraining Step: 302  | total loss: [1m[32m0.69366[0m[0m | time: 1.743s
[2K
| RMSProp | epoch: 007 | loss: 0.69366 - acc: 0.5056 -- iter: 0064/1584
[A[ATraining Step: 303  | total loss: [1m[32m0.69398[0m[0m | time: 2.603s
[2K
| RMSProp | epoch: 007 | loss: 0.69398 - acc: 0.4863 -- iter: 0096/1584
[A[ATraining Step: 304  | total loss: [1m[32m0.69390[0m[0m | time: 3.491s
[2K
| RMSProp | epoch: 007 | loss: 0.69390 - acc: 0.4845 -- iter: 0128/1584
[A[ATraining Step: 305  | total loss: [1m[32m0.69385[0m[0m | time: 3.962s
[2K
| RMSProp | epoch: 007 | loss: 0.69385 - acc: 0.4767 -- iter: 0160/1584
[A[ATraining Step: 306  | total loss: [1m[32m0.69376[0m[0m | time: 4.414s
[2K
| RMSProp | epoch: 007 | loss: 0.69376 - acc: 0.4978 -- iter: 0192/1584
[A[ATraining Step: 307  | total loss: [1m[32m0.69357[0m[0m | time: 5.303s
[2K
| RMSProp | epoch: 007 | loss: 0.69357 - acc: 0.5105 -- iter: 0224/1584
[A[ATraining Step: 308  | total loss: [1m[32m0.69382[0m[0m | time: 6.213s
[2K
| RMSProp | epoch: 007 | loss: 0.69382 - acc: 0.4938 -- iter: 0256/1584
[A[ATraining Step: 309  | total loss: [1m[32m0.69371[0m[0m | time: 7.069s
[2K
| RMSProp | epoch: 007 | loss: 0.69371 - acc: 0.5007 -- iter: 0288/1584
[A[ATraining Step: 310  | total loss: [1m[32m0.69366[0m[0m | time: 7.987s
[2K
| RMSProp | epoch: 007 | loss: 0.69366 - acc: 0.4975 -- iter: 0320/1584
[A[ATraining Step: 311  | total loss: [1m[32m0.69369[0m[0m | time: 9.091s
[2K
| RMSProp | epoch: 007 | loss: 0.69369 - acc: 0.4884 -- iter: 0352/1584
[A[ATraining Step: 312  | total loss: [1m[32m0.69362[0m[0m | time: 10.135s
[2K
| RMSProp | epoch: 007 | loss: 0.69362 - acc: 0.4895 -- iter: 0384/1584
[A[ATraining Step: 313  | total loss: [1m[32m0.69355[0m[0m | time: 10.881s
[2K
| RMSProp | epoch: 007 | loss: 0.69355 - acc: 0.4937 -- iter: 0416/1584
[A[ATraining Step: 314  | total loss: [1m[32m0.69354[0m[0m | time: 11.747s
[2K
| RMSProp | epoch: 007 | loss: 0.69354 - acc: 0.4850 -- iter: 0448/1584
[A[ATraining Step: 315  | total loss: [1m[32m0.69343[0m[0m | time: 12.613s
[2K
| RMSProp | epoch: 007 | loss: 0.69343 - acc: 0.4990 -- iter: 0480/1584
[A[ATraining Step: 316  | total loss: [1m[32m0.69333[0m[0m | time: 13.488s
[2K
| RMSProp | epoch: 007 | loss: 0.69333 - acc: 0.5022 -- iter: 0512/1584
[A[ATraining Step: 317  | total loss: [1m[32m0.69319[0m[0m | time: 14.356s
[2K
| RMSProp | epoch: 007 | loss: 0.69319 - acc: 0.5082 -- iter: 0544/1584
[A[ATraining Step: 318  | total loss: [1m[32m0.69364[0m[0m | time: 15.269s
[2K
| RMSProp | epoch: 007 | loss: 0.69364 - acc: 0.4949 -- iter: 0576/1584
[A[ATraining Step: 319  | total loss: [1m[32m0.69346[0m[0m | time: 16.148s
[2K
| RMSProp | epoch: 007 | loss: 0.69346 - acc: 0.5079 -- iter: 0608/1584
[A[ATraining Step: 320  | total loss: [1m[32m0.69328[0m[0m | time: 17.025s
[2K
| RMSProp | epoch: 007 | loss: 0.69328 - acc: 0.5134 -- iter: 0640/1584
[A[ATraining Step: 321  | total loss: [1m[32m0.69296[0m[0m | time: 17.907s
[2K
| RMSProp | epoch: 007 | loss: 0.69296 - acc: 0.5245 -- iter: 0672/1584
[A[ATraining Step: 322  | total loss: [1m[32m0.69254[0m[0m | time: 18.748s
[2K
| RMSProp | epoch: 007 | loss: 0.69254 - acc: 0.5315 -- iter: 0704/1584
[A[ATraining Step: 323  | total loss: [1m[32m0.69195[0m[0m | time: 19.627s
[2K
| RMSProp | epoch: 007 | loss: 0.69195 - acc: 0.5377 -- iter: 0736/1584
[A[ATraining Step: 324  | total loss: [1m[32m0.69122[0m[0m | time: 20.665s
[2K
| RMSProp | epoch: 007 | loss: 0.69122 - acc: 0.5402 -- iter: 0768/1584
[A[ATraining Step: 325  | total loss: [1m[32m0.68954[0m[0m | time: 21.631s
[2K
| RMSProp | epoch: 007 | loss: 0.68954 - acc: 0.5455 -- iter: 0800/1584
[A[ATraining Step: 326  | total loss: [1m[32m0.69969[0m[0m | time: 22.440s
[2K
| RMSProp | epoch: 007 | loss: 0.69969 - acc: 0.5347 -- iter: 0832/1584
[A[ATraining Step: 327  | total loss: [1m[32m0.69739[0m[0m | time: 23.217s
[2K
| RMSProp | epoch: 007 | loss: 0.69739 - acc: 0.5438 -- iter: 0864/1584
[A[ATraining Step: 328  | total loss: [1m[32m0.69712[0m[0m | time: 24.126s
[2K
| RMSProp | epoch: 007 | loss: 0.69712 - acc: 0.5394 -- iter: 0896/1584
[A[ATraining Step: 329  | total loss: [1m[32m0.69946[0m[0m | time: 25.019s
[2K
| RMSProp | epoch: 007 | loss: 0.69946 - acc: 0.5198 -- iter: 0928/1584
[A[ATraining Step: 330  | total loss: [1m[32m0.69705[0m[0m | time: 25.916s
[2K
| RMSProp | epoch: 007 | loss: 0.69705 - acc: 0.5366 -- iter: 0960/1584
[A[ATraining Step: 331  | total loss: [1m[32m0.69495[0m[0m | time: 26.798s
[2K
| RMSProp | epoch: 007 | loss: 0.69495 - acc: 0.5454 -- iter: 0992/1584
[A[ATraining Step: 332  | total loss: [1m[32m0.69496[0m[0m | time: 27.636s
[2K
| RMSProp | epoch: 007 | loss: 0.69496 - acc: 0.5409 -- iter: 1024/1584
[A[ATraining Step: 333  | total loss: [1m[32m0.69632[0m[0m | time: 28.494s
[2K
| RMSProp | epoch: 007 | loss: 0.69632 - acc: 0.5274 -- iter: 1056/1584
[A[ATraining Step: 334  | total loss: [1m[32m0.69739[0m[0m | time: 29.396s
[2K
| RMSProp | epoch: 007 | loss: 0.69739 - acc: 0.5122 -- iter: 1088/1584
[A[ATraining Step: 335  | total loss: [1m[32m0.69734[0m[0m | time: 30.255s
[2K
| RMSProp | epoch: 007 | loss: 0.69734 - acc: 0.5047 -- iter: 1120/1584
[A[ATraining Step: 336  | total loss: [1m[32m0.69704[0m[0m | time: 31.134s
[2K
| RMSProp | epoch: 007 | loss: 0.69704 - acc: 0.5011 -- iter: 1152/1584
[A[ATraining Step: 337  | total loss: [1m[32m0.69668[0m[0m | time: 32.136s
[2K
| RMSProp | epoch: 007 | loss: 0.69668 - acc: 0.4916 -- iter: 1184/1584
[A[ATraining Step: 338  | total loss: [1m[32m0.69624[0m[0m | time: 33.155s
[2K
| RMSProp | epoch: 007 | loss: 0.69624 - acc: 0.5050 -- iter: 1216/1584
[A[ATraining Step: 339  | total loss: [1m[32m0.69605[0m[0m | time: 33.857s
[2K
| RMSProp | epoch: 007 | loss: 0.69605 - acc: 0.4888 -- iter: 1248/1584
[A[ATraining Step: 340  | total loss: [1m[32m0.69569[0m[0m | time: 34.654s
[2K
| RMSProp | epoch: 007 | loss: 0.69569 - acc: 0.4868 -- iter: 1280/1584
[A[ATraining Step: 341  | total loss: [1m[32m0.69516[0m[0m | time: 35.583s
[2K
| RMSProp | epoch: 007 | loss: 0.69516 - acc: 0.4913 -- iter: 1312/1584
[A[ATraining Step: 342  | total loss: [1m[32m0.69471[0m[0m | time: 36.463s
[2K
| RMSProp | epoch: 007 | loss: 0.69471 - acc: 0.4921 -- iter: 1344/1584
[A[ATraining Step: 343  | total loss: [1m[32m0.69444[0m[0m | time: 37.341s
[2K
| RMSProp | epoch: 007 | loss: 0.69444 - acc: 0.4929 -- iter: 1376/1584
[A[ATraining Step: 344  | total loss: [1m[32m0.69444[0m[0m | time: 38.225s
[2K
| RMSProp | epoch: 007 | loss: 0.69444 - acc: 0.4843 -- iter: 1408/1584
[A[ATraining Step: 345  | total loss: [1m[32m0.69401[0m[0m | time: 39.139s
[2K
| RMSProp | epoch: 007 | loss: 0.69401 - acc: 0.4983 -- iter: 1440/1584
[A[ATraining Step: 346  | total loss: [1m[32m0.69224[0m[0m | time: 40.060s
[2K
| RMSProp | epoch: 007 | loss: 0.69224 - acc: 0.5235 -- iter: 1472/1584
[A[ATraining Step: 347  | total loss: [1m[32m0.69033[0m[0m | time: 40.956s
[2K
| RMSProp | epoch: 007 | loss: 0.69033 - acc: 0.5337 -- iter: 1504/1584
[A[ATraining Step: 348  | total loss: [1m[32m0.69704[0m[0m | time: 41.795s
[2K
| RMSProp | epoch: 007 | loss: 0.69704 - acc: 0.5115 -- iter: 1536/1584
[A[ATraining Step: 349  | total loss: [1m[32m0.69617[0m[0m | time: 42.667s
[2K
| RMSProp | epoch: 007 | loss: 0.69617 - acc: 0.5166 -- iter: 1568/1584
[A[ATraining Step: 350  | total loss: [1m[32m0.69638[0m[0m | time: 46.270s
[2K
| RMSProp | epoch: 007 | loss: 0.69638 - acc: 0.5056 | val_loss: 0.69174 - val_acc: 0.4879 -- iter: 1584/1584
--
Training Step: 351  | total loss: [1m[32m0.69616[0m[0m | time: 0.908s
[2K
| RMSProp | epoch: 008 | loss: 0.69616 - acc: 0.4988 -- iter: 0032/1584
[A[ATraining Step: 352  | total loss: [1m[32m0.69589[0m[0m | time: 1.782s
[2K
| RMSProp | epoch: 008 | loss: 0.69589 - acc: 0.4927 -- iter: 0064/1584
[A[ATraining Step: 353  | total loss: [1m[32m0.69576[0m[0m | time: 2.637s
[2K
| RMSProp | epoch: 008 | loss: 0.69576 - acc: 0.4871 -- iter: 0096/1584
[A[ATraining Step: 354  | total loss: [1m[32m0.69522[0m[0m | time: 3.550s
[2K
| RMSProp | epoch: 008 | loss: 0.69522 - acc: 0.5009 -- iter: 0128/1584
[A[ATraining Step: 355  | total loss: [1m[32m0.69481[0m[0m | time: 4.368s
[2K
| RMSProp | epoch: 008 | loss: 0.69481 - acc: 0.5071 -- iter: 0160/1584
[A[ATraining Step: 356  | total loss: [1m[32m0.69468[0m[0m | time: 4.918s
[2K
| RMSProp | epoch: 008 | loss: 0.69468 - acc: 0.5095 -- iter: 0192/1584
[A[ATraining Step: 357  | total loss: [1m[32m0.69439[0m[0m | time: 5.477s
[2K
| RMSProp | epoch: 008 | loss: 0.69439 - acc: 0.5086 -- iter: 0224/1584
[A[ATraining Step: 358  | total loss: [1m[32m0.69405[0m[0m | time: 6.517s
[2K
| RMSProp | epoch: 008 | loss: 0.69405 - acc: 0.5077 -- iter: 0256/1584
[A[ATraining Step: 359  | total loss: [1m[32m0.69348[0m[0m | time: 7.413s
[2K
| RMSProp | epoch: 008 | loss: 0.69348 - acc: 0.5163 -- iter: 0288/1584
[A[ATraining Step: 360  | total loss: [1m[32m0.69262[0m[0m | time: 8.162s
[2K
| RMSProp | epoch: 008 | loss: 0.69262 - acc: 0.5209 -- iter: 0320/1584
[A[ATraining Step: 361  | total loss: [1m[32m0.69115[0m[0m | time: 9.017s
[2K
| RMSProp | epoch: 008 | loss: 0.69115 - acc: 0.5313 -- iter: 0352/1584
[A[ATraining Step: 362  | total loss: [1m[32m0.68775[0m[0m | time: 9.853s
[2K
| RMSProp | epoch: 008 | loss: 0.68775 - acc: 0.5469 -- iter: 0384/1584
[A[ATraining Step: 363  | total loss: [1m[32m0.69234[0m[0m | time: 10.718s
[2K
| RMSProp | epoch: 008 | loss: 0.69234 - acc: 0.5391 -- iter: 0416/1584
[A[ATraining Step: 364  | total loss: [1m[32m0.69248[0m[0m | time: 11.597s
[2K
| RMSProp | epoch: 008 | loss: 0.69248 - acc: 0.5352 -- iter: 0448/1584
[A[ATraining Step: 365  | total loss: [1m[32m0.69186[0m[0m | time: 12.541s
[2K
| RMSProp | epoch: 008 | loss: 0.69186 - acc: 0.5348 -- iter: 0480/1584
[A[ATraining Step: 366  | total loss: [1m[32m0.69101[0m[0m | time: 13.447s
[2K
| RMSProp | epoch: 008 | loss: 0.69101 - acc: 0.5345 -- iter: 0512/1584
[A[ATraining Step: 367  | total loss: [1m[32m0.69341[0m[0m | time: 14.333s
[2K
| RMSProp | epoch: 008 | loss: 0.69341 - acc: 0.5185 -- iter: 0544/1584
[A[ATraining Step: 368  | total loss: [1m[32m0.69251[0m[0m | time: 15.187s
[2K
| RMSProp | epoch: 008 | loss: 0.69251 - acc: 0.5354 -- iter: 0576/1584
[A[ATraining Step: 369  | total loss: [1m[32m0.69151[0m[0m | time: 16.056s
[2K
| RMSProp | epoch: 008 | loss: 0.69151 - acc: 0.5381 -- iter: 0608/1584
[A[ATraining Step: 370  | total loss: [1m[32m0.69244[0m[0m | time: 17.030s
[2K
| RMSProp | epoch: 008 | loss: 0.69244 - acc: 0.5249 -- iter: 0640/1584
[A[ATraining Step: 371  | total loss: [1m[32m0.69206[0m[0m | time: 18.029s
[2K
| RMSProp | epoch: 008 | loss: 0.69206 - acc: 0.5412 -- iter: 0672/1584
[A[ATraining Step: 372  | total loss: [1m[32m0.69214[0m[0m | time: 18.921s
[2K
| RMSProp | epoch: 008 | loss: 0.69214 - acc: 0.5277 -- iter: 0704/1584
[A[ATraining Step: 373  | total loss: [1m[32m0.69143[0m[0m | time: 19.679s
[2K
| RMSProp | epoch: 008 | loss: 0.69143 - acc: 0.5437 -- iter: 0736/1584
[A[ATraining Step: 374  | total loss: [1m[32m0.69165[0m[0m | time: 20.500s
[2K
| RMSProp | epoch: 008 | loss: 0.69165 - acc: 0.5362 -- iter: 0768/1584
[A[ATraining Step: 375  | total loss: [1m[32m0.69020[0m[0m | time: 21.373s
[2K
| RMSProp | epoch: 008 | loss: 0.69020 - acc: 0.5607 -- iter: 0800/1584
[A[ATraining Step: 376  | total loss: [1m[32m0.69106[0m[0m | time: 22.275s
[2K
| RMSProp | epoch: 008 | loss: 0.69106 - acc: 0.5515 -- iter: 0832/1584
[A[ATraining Step: 377  | total loss: [1m[32m0.69152[0m[0m | time: 23.106s
[2K
| RMSProp | epoch: 008 | loss: 0.69152 - acc: 0.5432 -- iter: 0864/1584
[A[ATraining Step: 378  | total loss: [1m[32m0.69111[0m[0m | time: 23.999s
[2K
| RMSProp | epoch: 008 | loss: 0.69111 - acc: 0.5358 -- iter: 0896/1584
[A[ATraining Step: 379  | total loss: [1m[32m0.69036[0m[0m | time: 24.892s
[2K
| RMSProp | epoch: 008 | loss: 0.69036 - acc: 0.5447 -- iter: 0928/1584
[A[ATraining Step: 380  | total loss: [1m[32m0.68947[0m[0m | time: 25.737s
[2K
| RMSProp | epoch: 008 | loss: 0.68947 - acc: 0.5496 -- iter: 0960/1584
[A[ATraining Step: 381  | total loss: [1m[32m0.68967[0m[0m | time: 26.610s
[2K
| RMSProp | epoch: 008 | loss: 0.68967 - acc: 0.5446 -- iter: 0992/1584
[A[ATraining Step: 382  | total loss: [1m[32m0.68748[0m[0m | time: 27.446s
[2K
| RMSProp | epoch: 008 | loss: 0.68748 - acc: 0.5433 -- iter: 1024/1584
[A[ATraining Step: 383  | total loss: [1m[32m0.68637[0m[0m | time: 28.422s
[2K
| RMSProp | epoch: 008 | loss: 0.68637 - acc: 0.5515 -- iter: 1056/1584
[A[ATraining Step: 384  | total loss: [1m[32m0.68435[0m[0m | time: 29.430s
[2K
| RMSProp | epoch: 008 | loss: 0.68435 - acc: 0.5557 -- iter: 1088/1584
[A[ATraining Step: 385  | total loss: [1m[32m0.67575[0m[0m | time: 30.479s
[2K
| RMSProp | epoch: 008 | loss: 0.67575 - acc: 0.5689 -- iter: 1120/1584
[A[ATraining Step: 386  | total loss: [1m[32m0.68588[0m[0m | time: 31.174s
[2K
| RMSProp | epoch: 008 | loss: 0.68588 - acc: 0.5651 -- iter: 1152/1584
[A[ATraining Step: 387  | total loss: [1m[32m0.68537[0m[0m | time: 32.008s
[2K
| RMSProp | epoch: 008 | loss: 0.68537 - acc: 0.5711 -- iter: 1184/1584
[A[ATraining Step: 388  | total loss: [1m[32m0.68424[0m[0m | time: 32.896s
[2K
| RMSProp | epoch: 008 | loss: 0.68424 - acc: 0.5671 -- iter: 1216/1584
[A[ATraining Step: 389  | total loss: [1m[32m0.68340[0m[0m | time: 33.810s
[2K
| RMSProp | epoch: 008 | loss: 0.68340 - acc: 0.5698 -- iter: 1248/1584
[A[ATraining Step: 390  | total loss: [1m[32m0.68003[0m[0m | time: 34.732s
[2K
| RMSProp | epoch: 008 | loss: 0.68003 - acc: 0.5878 -- iter: 1280/1584
[A[ATraining Step: 391  | total loss: [1m[32m0.67622[0m[0m | time: 35.644s
[2K
| RMSProp | epoch: 008 | loss: 0.67622 - acc: 0.6009 -- iter: 1312/1584
[A[ATraining Step: 392  | total loss: [1m[32m0.67724[0m[0m | time: 36.541s
[2K
| RMSProp | epoch: 008 | loss: 0.67724 - acc: 0.5939 -- iter: 1344/1584
[A[ATraining Step: 393  | total loss: [1m[32m0.67960[0m[0m | time: 37.449s
[2K
| RMSProp | epoch: 008 | loss: 0.67960 - acc: 0.5845 -- iter: 1376/1584
[A[ATraining Step: 394  | total loss: [1m[32m0.67826[0m[0m | time: 38.293s
[2K
| RMSProp | epoch: 008 | loss: 0.67826 - acc: 0.5917 -- iter: 1408/1584
[A[ATraining Step: 395  | total loss: [1m[32m0.67337[0m[0m | time: 39.162s
[2K
| RMSProp | epoch: 008 | loss: 0.67337 - acc: 0.6044 -- iter: 1440/1584
[A[ATraining Step: 396  | total loss: [1m[32m0.67732[0m[0m | time: 40.187s
[2K
| RMSProp | epoch: 008 | loss: 0.67732 - acc: 0.5908 -- iter: 1472/1584
[A[ATraining Step: 397  | total loss: [1m[32m0.67343[0m[0m | time: 41.195s
[2K
| RMSProp | epoch: 008 | loss: 0.67343 - acc: 0.6036 -- iter: 1504/1584
[A[ATraining Step: 398  | total loss: [1m[32m0.67312[0m[0m | time: 41.987s
[2K
| RMSProp | epoch: 008 | loss: 0.67312 - acc: 0.6027 -- iter: 1536/1584
[A[ATraining Step: 399  | total loss: [1m[32m0.67335[0m[0m | time: 42.791s
[2K
| RMSProp | epoch: 008 | loss: 0.67335 - acc: 0.6049 -- iter: 1568/1584
[A[ATraining Step: 400  | total loss: [1m[32m0.67516[0m[0m | time: 45.992s
[2K
| RMSProp | epoch: 008 | loss: 0.67516 - acc: 0.6006 | val_loss: 0.66435 - val_acc: 0.5847 -- iter: 1584/1584
--
Training Step: 401  | total loss: [1m[32m0.67375[0m[0m | time: 0.949s
[2K
| RMSProp | epoch: 009 | loss: 0.67375 - acc: 0.6062 -- iter: 0032/1584
[A[ATraining Step: 402  | total loss: [1m[32m0.66801[0m[0m | time: 1.666s
[2K
| RMSProp | epoch: 009 | loss: 0.66801 - acc: 0.6206 -- iter: 0064/1584
[A[ATraining Step: 403  | total loss: [1m[32m0.67153[0m[0m | time: 2.578s
[2K
| RMSProp | epoch: 009 | loss: 0.67153 - acc: 0.6148 -- iter: 0096/1584
[A[ATraining Step: 404  | total loss: [1m[32m0.66832[0m[0m | time: 3.418s
[2K
| RMSProp | epoch: 009 | loss: 0.66832 - acc: 0.6252 -- iter: 0128/1584
[A[ATraining Step: 405  | total loss: [1m[32m0.66880[0m[0m | time: 4.301s
[2K
| RMSProp | epoch: 009 | loss: 0.66880 - acc: 0.6158 -- iter: 0160/1584
[A[ATraining Step: 406  | total loss: [1m[32m0.66659[0m[0m | time: 5.220s
[2K
| RMSProp | epoch: 009 | loss: 0.66659 - acc: 0.6105 -- iter: 0192/1584
[A[ATraining Step: 407  | total loss: [1m[32m0.67106[0m[0m | time: 5.682s
[2K
| RMSProp | epoch: 009 | loss: 0.67106 - acc: 0.6025 -- iter: 0224/1584
[A[ATraining Step: 408  | total loss: [1m[32m0.66602[0m[0m | time: 6.153s
[2K
| RMSProp | epoch: 009 | loss: 0.66602 - acc: 0.6235 -- iter: 0256/1584
[A[ATraining Step: 409  | total loss: [1m[32m0.65863[0m[0m | time: 7.050s
[2K
| RMSProp | epoch: 009 | loss: 0.65863 - acc: 0.6362 -- iter: 0288/1584
[A[ATraining Step: 410  | total loss: [1m[32m0.66138[0m[0m | time: 7.959s
[2K
| RMSProp | epoch: 009 | loss: 0.66138 - acc: 0.6319 -- iter: 0320/1584
[A[ATraining Step: 411  | total loss: [1m[32m0.66256[0m[0m | time: 8.813s
[2K
| RMSProp | epoch: 009 | loss: 0.66256 - acc: 0.6281 -- iter: 0352/1584
[A[ATraining Step: 412  | total loss: [1m[32m0.66175[0m[0m | time: 9.624s
[2K
| RMSProp | epoch: 009 | loss: 0.66175 - acc: 0.6309 -- iter: 0384/1584
[A[ATraining Step: 413  | total loss: [1m[32m0.66081[0m[0m | time: 10.635s
[2K
| RMSProp | epoch: 009 | loss: 0.66081 - acc: 0.6335 -- iter: 0416/1584
[A[ATraining Step: 414  | total loss: [1m[32m0.66249[0m[0m | time: 11.658s
[2K
| RMSProp | epoch: 009 | loss: 0.66249 - acc: 0.6326 -- iter: 0448/1584
[A[ATraining Step: 415  | total loss: [1m[32m0.66147[0m[0m | time: 12.544s
[2K
| RMSProp | epoch: 009 | loss: 0.66147 - acc: 0.6256 -- iter: 0480/1584
[A[ATraining Step: 416  | total loss: [1m[32m0.66069[0m[0m | time: 13.319s
[2K
| RMSProp | epoch: 009 | loss: 0.66069 - acc: 0.6224 -- iter: 0512/1584
[A[ATraining Step: 417  | total loss: [1m[32m0.65584[0m[0m | time: 14.184s
[2K
| RMSProp | epoch: 009 | loss: 0.65584 - acc: 0.6227 -- iter: 0544/1584
[A[ATraining Step: 418  | total loss: [1m[32m0.65503[0m[0m | time: 15.069s
[2K
| RMSProp | epoch: 009 | loss: 0.65503 - acc: 0.6260 -- iter: 0576/1584
[A[ATraining Step: 419  | total loss: [1m[32m0.66089[0m[0m | time: 15.951s
[2K
| RMSProp | epoch: 009 | loss: 0.66089 - acc: 0.6134 -- iter: 0608/1584
[A[ATraining Step: 420  | total loss: [1m[32m0.65997[0m[0m | time: 16.849s
[2K
| RMSProp | epoch: 009 | loss: 0.65997 - acc: 0.6146 -- iter: 0640/1584
[A[ATraining Step: 421  | total loss: [1m[32m0.67029[0m[0m | time: 17.733s
[2K
| RMSProp | epoch: 009 | loss: 0.67029 - acc: 0.5969 -- iter: 0672/1584
[A[ATraining Step: 422  | total loss: [1m[32m0.66764[0m[0m | time: 18.631s
[2K
| RMSProp | epoch: 009 | loss: 0.66764 - acc: 0.5997 -- iter: 0704/1584
[A[ATraining Step: 423  | total loss: [1m[32m0.66563[0m[0m | time: 19.494s
[2K
| RMSProp | epoch: 009 | loss: 0.66563 - acc: 0.5991 -- iter: 0736/1584
[A[ATraining Step: 424  | total loss: [1m[32m0.66448[0m[0m | time: 20.398s
[2K
| RMSProp | epoch: 009 | loss: 0.66448 - acc: 0.6048 -- iter: 0768/1584
[A[ATraining Step: 425  | total loss: [1m[32m0.66540[0m[0m | time: 21.296s
[2K
| RMSProp | epoch: 009 | loss: 0.66540 - acc: 0.5912 -- iter: 0800/1584
[A[ATraining Step: 426  | total loss: [1m[32m0.65947[0m[0m | time: 22.241s
[2K
| RMSProp | epoch: 009 | loss: 0.65947 - acc: 0.6071 -- iter: 0832/1584
[A[ATraining Step: 427  | total loss: [1m[32m0.65418[0m[0m | time: 23.228s
[2K
| RMSProp | epoch: 009 | loss: 0.65418 - acc: 0.6183 -- iter: 0864/1584
[A[ATraining Step: 428  | total loss: [1m[32m0.65141[0m[0m | time: 24.160s
[2K
| RMSProp | epoch: 009 | loss: 0.65141 - acc: 0.6221 -- iter: 0896/1584
[A[ATraining Step: 429  | total loss: [1m[32m0.65791[0m[0m | time: 24.884s
[2K
| RMSProp | epoch: 009 | loss: 0.65791 - acc: 0.6098 -- iter: 0928/1584
[A[ATraining Step: 430  | total loss: [1m[32m0.65380[0m[0m | time: 25.742s
[2K
| RMSProp | epoch: 009 | loss: 0.65380 - acc: 0.6114 -- iter: 0960/1584
[A[ATraining Step: 431  | total loss: [1m[32m0.65326[0m[0m | time: 26.591s
[2K
| RMSProp | epoch: 009 | loss: 0.65326 - acc: 0.6065 -- iter: 0992/1584
[A[ATraining Step: 432  | total loss: [1m[32m0.64816[0m[0m | time: 27.455s
[2K
| RMSProp | epoch: 009 | loss: 0.64816 - acc: 0.6146 -- iter: 1024/1584
[A[ATraining Step: 433  | total loss: [1m[32m0.65208[0m[0m | time: 28.311s
[2K
| RMSProp | epoch: 009 | loss: 0.65208 - acc: 0.6094 -- iter: 1056/1584
[A[ATraining Step: 434  | total loss: [1m[32m0.64303[0m[0m | time: 29.161s
[2K
| RMSProp | epoch: 009 | loss: 0.64303 - acc: 0.6297 -- iter: 1088/1584
[A[ATraining Step: 435  | total loss: [1m[32m0.63919[0m[0m | time: 30.050s
[2K
| RMSProp | epoch: 009 | loss: 0.63919 - acc: 0.6323 -- iter: 1120/1584
[A[ATraining Step: 436  | total loss: [1m[32m0.64328[0m[0m | time: 30.932s
[2K
| RMSProp | epoch: 009 | loss: 0.64328 - acc: 0.6254 -- iter: 1152/1584
[A[ATraining Step: 437  | total loss: [1m[32m0.63442[0m[0m | time: 31.827s
[2K
| RMSProp | epoch: 009 | loss: 0.63442 - acc: 0.6347 -- iter: 1184/1584
[A[ATraining Step: 438  | total loss: [1m[32m0.63301[0m[0m | time: 32.708s
[2K
| RMSProp | epoch: 009 | loss: 0.63301 - acc: 0.6369 -- iter: 1216/1584
[A[ATraining Step: 439  | total loss: [1m[32m0.62865[0m[0m | time: 33.593s
[2K
| RMSProp | epoch: 009 | loss: 0.62865 - acc: 0.6419 -- iter: 1248/1584
[A[ATraining Step: 440  | total loss: [1m[32m0.61881[0m[0m | time: 34.630s
[2K
| RMSProp | epoch: 009 | loss: 0.61881 - acc: 0.6527 -- iter: 1280/1584
[A[ATraining Step: 441  | total loss: [1m[32m0.61869[0m[0m | time: 35.625s
[2K
| RMSProp | epoch: 009 | loss: 0.61869 - acc: 0.6593 -- iter: 1312/1584
[A[ATraining Step: 442  | total loss: [1m[32m0.61856[0m[0m | time: 36.363s
[2K
| RMSProp | epoch: 009 | loss: 0.61856 - acc: 0.6621 -- iter: 1344/1584
[A[ATraining Step: 443  | total loss: [1m[32m0.61942[0m[0m | time: 37.210s
[2K
| RMSProp | epoch: 009 | loss: 0.61942 - acc: 0.6553 -- iter: 1376/1584
[A[ATraining Step: 444  | total loss: [1m[32m0.64011[0m[0m | time: 38.085s
[2K
| RMSProp | epoch: 009 | loss: 0.64011 - acc: 0.6241 -- iter: 1408/1584
[A[ATraining Step: 445  | total loss: [1m[32m0.63830[0m[0m | time: 38.983s
[2K
| RMSProp | epoch: 009 | loss: 0.63830 - acc: 0.6305 -- iter: 1440/1584
[A[ATraining Step: 446  | total loss: [1m[32m0.64474[0m[0m | time: 39.849s
[2K
| RMSProp | epoch: 009 | loss: 0.64474 - acc: 0.6237 -- iter: 1472/1584
[A[ATraining Step: 447  | total loss: [1m[32m0.64456[0m[0m | time: 40.740s
[2K
| RMSProp | epoch: 009 | loss: 0.64456 - acc: 0.6207 -- iter: 1504/1584
[A[ATraining Step: 448  | total loss: [1m[32m0.64163[0m[0m | time: 41.696s
[2K
| RMSProp | epoch: 009 | loss: 0.64163 - acc: 0.6242 -- iter: 1536/1584
[A[ATraining Step: 449  | total loss: [1m[32m0.63520[0m[0m | time: 42.590s
[2K
| RMSProp | epoch: 009 | loss: 0.63520 - acc: 0.6337 -- iter: 1568/1584
[A[ATraining Step: 450  | total loss: [1m[32m0.62829[0m[0m | time: 45.684s
[2K
| RMSProp | epoch: 009 | loss: 0.62829 - acc: 0.6485 | val_loss: 0.61317 - val_acc: 0.6613 -- iter: 1584/1584
--
Training Step: 451  | total loss: [1m[32m0.62570[0m[0m | time: 0.941s
[2K
| RMSProp | epoch: 010 | loss: 0.62570 - acc: 0.6461 -- iter: 0032/1584
[A[ATraining Step: 452  | total loss: [1m[32m0.61583[0m[0m | time: 1.861s
[2K
| RMSProp | epoch: 010 | loss: 0.61583 - acc: 0.6565 -- iter: 0064/1584
[A[ATraining Step: 453  | total loss: [1m[32m0.61333[0m[0m | time: 2.742s
[2K
| RMSProp | epoch: 010 | loss: 0.61333 - acc: 0.6596 -- iter: 0096/1584
[A[ATraining Step: 454  | total loss: [1m[32m0.61826[0m[0m | time: 3.644s
[2K
| RMSProp | epoch: 010 | loss: 0.61826 - acc: 0.6593 -- iter: 0128/1584
[A[ATraining Step: 455  | total loss: [1m[32m0.61791[0m[0m | time: 4.660s
[2K
| RMSProp | epoch: 010 | loss: 0.61791 - acc: 0.6590 -- iter: 0160/1584
[A[ATraining Step: 456  | total loss: [1m[32m0.62149[0m[0m | time: 5.666s
[2K
| RMSProp | epoch: 010 | loss: 0.62149 - acc: 0.6462 -- iter: 0192/1584
[A[ATraining Step: 457  | total loss: [1m[32m0.62845[0m[0m | time: 6.395s
[2K
| RMSProp | epoch: 010 | loss: 0.62845 - acc: 0.6347 -- iter: 0224/1584
[A[ATraining Step: 458  | total loss: [1m[32m0.62216[0m[0m | time: 6.823s
[2K
| RMSProp | epoch: 010 | loss: 0.62216 - acc: 0.6462 -- iter: 0256/1584
[A[ATraining Step: 459  | total loss: [1m[32m0.61504[0m[0m | time: 7.276s
[2K
| RMSProp | epoch: 010 | loss: 0.61504 - acc: 0.6566 -- iter: 0288/1584
[A[ATraining Step: 460  | total loss: [1m[32m0.60191[0m[0m | time: 8.187s
[2K
| RMSProp | epoch: 010 | loss: 0.60191 - acc: 0.6659 -- iter: 0320/1584
[A[ATraining Step: 461  | total loss: [1m[32m0.59881[0m[0m | time: 9.075s
[2K
| RMSProp | epoch: 010 | loss: 0.59881 - acc: 0.6775 -- iter: 0352/1584
[A[ATraining Step: 462  | total loss: [1m[32m0.60226[0m[0m | time: 10.002s
[2K
| RMSProp | epoch: 010 | loss: 0.60226 - acc: 0.6785 -- iter: 0384/1584
[A[ATraining Step: 463  | total loss: [1m[32m0.60242[0m[0m | time: 10.917s
[2K
| RMSProp | epoch: 010 | loss: 0.60242 - acc: 0.6794 -- iter: 0416/1584
[A[ATraining Step: 464  | total loss: [1m[32m0.59041[0m[0m | time: 11.849s
[2K
| RMSProp | epoch: 010 | loss: 0.59041 - acc: 0.6989 -- iter: 0448/1584
[A[ATraining Step: 465  | total loss: [1m[32m0.58940[0m[0m | time: 12.729s
[2K
| RMSProp | epoch: 010 | loss: 0.58940 - acc: 0.6947 -- iter: 0480/1584
[A[ATraining Step: 466  | total loss: [1m[32m0.58264[0m[0m | time: 13.626s
[2K
| RMSProp | epoch: 010 | loss: 0.58264 - acc: 0.7065 -- iter: 0512/1584
[A[ATraining Step: 467  | total loss: [1m[32m0.59542[0m[0m | time: 14.490s
[2K
| RMSProp | epoch: 010 | loss: 0.59542 - acc: 0.6952 -- iter: 0544/1584
[A[ATraining Step: 468  | total loss: [1m[32m0.60823[0m[0m | time: 15.505s
[2K
| RMSProp | epoch: 010 | loss: 0.60823 - acc: 0.6819 -- iter: 0576/1584
[A[ATraining Step: 469  | total loss: [1m[32m0.60154[0m[0m | time: 16.540s
[2K
| RMSProp | epoch: 010 | loss: 0.60154 - acc: 0.6918 -- iter: 0608/1584
[A[ATraining Step: 470  | total loss: [1m[32m0.59668[0m[0m | time: 17.475s
[2K
| RMSProp | epoch: 010 | loss: 0.59668 - acc: 0.6945 -- iter: 0640/1584
[A[ATraining Step: 471  | total loss: [1m[32m0.58808[0m[0m | time: 18.210s
[2K
| RMSProp | epoch: 010 | loss: 0.58808 - acc: 0.7001 -- iter: 0672/1584
[A[ATraining Step: 472  | total loss: [1m[32m0.59078[0m[0m | time: 19.069s
[2K
| RMSProp | epoch: 010 | loss: 0.59078 - acc: 0.6926 -- iter: 0704/1584
[A[ATraining Step: 473  | total loss: [1m[32m0.58663[0m[0m | time: 19.926s
[2K
| RMSProp | epoch: 010 | loss: 0.58663 - acc: 0.6983 -- iter: 0736/1584
[A[ATraining Step: 474  | total loss: [1m[32m0.58704[0m[0m | time: 20.756s
[2K
| RMSProp | epoch: 010 | loss: 0.58704 - acc: 0.7004 -- iter: 0768/1584
[A[ATraining Step: 475  | total loss: [1m[32m0.58669[0m[0m | time: 21.617s
[2K
| RMSProp | epoch: 010 | loss: 0.58669 - acc: 0.7022 -- iter: 0800/1584
[A[ATraining Step: 476  | total loss: [1m[32m0.57794[0m[0m | time: 22.495s
[2K
| RMSProp | epoch: 010 | loss: 0.57794 - acc: 0.7101 -- iter: 0832/1584
[A[ATraining Step: 477  | total loss: [1m[32m0.57003[0m[0m | time: 23.440s
[2K
| RMSProp | epoch: 010 | loss: 0.57003 - acc: 0.7141 -- iter: 0864/1584
[A[ATraining Step: 478  | total loss: [1m[32m0.58102[0m[0m | time: 24.360s
[2K
| RMSProp | epoch: 010 | loss: 0.58102 - acc: 0.7052 -- iter: 0896/1584
[A[ATraining Step: 479  | total loss: [1m[32m0.61468[0m[0m | time: 25.284s
[2K
| RMSProp | epoch: 010 | loss: 0.61468 - acc: 0.6784 -- iter: 0928/1584
[A[ATraining Step: 480  | total loss: [1m[32m0.60553[0m[0m | time: 26.087s
[2K
| RMSProp | epoch: 010 | loss: 0.60553 - acc: 0.6887 -- iter: 0960/1584
[A[ATraining Step: 481  | total loss: [1m[32m0.60072[0m[0m | time: 27.086s
[2K
| RMSProp | epoch: 010 | loss: 0.60072 - acc: 0.6948 -- iter: 0992/1584
[A[ATraining Step: 482  | total loss: [1m[32m0.59239[0m[0m | time: 28.126s
[2K
| RMSProp | epoch: 010 | loss: 0.59239 - acc: 0.7066 -- iter: 1024/1584
[A[ATraining Step: 483  | total loss: [1m[32m0.58950[0m[0m | time: 29.079s
[2K
| RMSProp | epoch: 010 | loss: 0.58950 - acc: 0.7078 -- iter: 1056/1584
[A[ATraining Step: 484  | total loss: [1m[32m0.57925[0m[0m | time: 29.852s
[2K
| RMSProp | epoch: 010 | loss: 0.57925 - acc: 0.7183 -- iter: 1088/1584
[A[ATraining Step: 485  | total loss: [1m[32m0.58361[0m[0m | time: 30.795s
[2K
| RMSProp | epoch: 010 | loss: 0.58361 - acc: 0.7090 -- iter: 1120/1584
[A[ATraining Step: 486  | total loss: [1m[32m0.57807[0m[0m | time: 31.710s
[2K
| RMSProp | epoch: 010 | loss: 0.57807 - acc: 0.7037 -- iter: 1152/1584
[A[ATraining Step: 487  | total loss: [1m[32m0.56837[0m[0m | time: 32.615s
[2K
| RMSProp | epoch: 010 | loss: 0.56837 - acc: 0.7083 -- iter: 1184/1584
[A[ATraining Step: 488  | total loss: [1m[32m0.58926[0m[0m | time: 33.506s
[2K
| RMSProp | epoch: 010 | loss: 0.58926 - acc: 0.6875 -- iter: 1216/1584
[A[ATraining Step: 489  | total loss: [1m[32m0.60869[0m[0m | time: 34.373s
[2K
| RMSProp | epoch: 010 | loss: 0.60869 - acc: 0.6687 -- iter: 1248/1584
[A[ATraining Step: 490  | total loss: [1m[32m0.60383[0m[0m | time: 35.234s
[2K
| RMSProp | epoch: 010 | loss: 0.60383 - acc: 0.6737 -- iter: 1280/1584
[A[ATraining Step: 491  | total loss: [1m[32m0.59627[0m[0m | time: 36.110s
[2K
| RMSProp | epoch: 010 | loss: 0.59627 - acc: 0.6876 -- iter: 1312/1584
[A[ATraining Step: 492  | total loss: [1m[32m0.60345[0m[0m | time: 36.990s
[2K
| RMSProp | epoch: 010 | loss: 0.60345 - acc: 0.6751 -- iter: 1344/1584
[A[ATraining Step: 493  | total loss: [1m[32m0.60538[0m[0m | time: 37.865s
[2K
| RMSProp | epoch: 010 | loss: 0.60538 - acc: 0.6670 -- iter: 1376/1584
[A[ATraining Step: 494  | total loss: [1m[32m0.60005[0m[0m | time: 38.898s
[2K
| RMSProp | epoch: 010 | loss: 0.60005 - acc: 0.6784 -- iter: 1408/1584
[A[ATraining Step: 495  | total loss: [1m[32m0.59348[0m[0m | time: 39.927s
[2K
| RMSProp | epoch: 010 | loss: 0.59348 - acc: 0.6918 -- iter: 1440/1584
[A[ATraining Step: 496  | total loss: [1m[32m0.58843[0m[0m | time: 40.648s
[2K
| RMSProp | epoch: 010 | loss: 0.58843 - acc: 0.6945 -- iter: 1472/1584
[A[ATraining Step: 497  | total loss: [1m[32m0.58701[0m[0m | time: 41.561s
[2K
| RMSProp | epoch: 010 | loss: 0.58701 - acc: 0.6907 -- iter: 1504/1584
[A[ATraining Step: 498  | total loss: [1m[32m0.59124[0m[0m | time: 42.436s
[2K
| RMSProp | epoch: 010 | loss: 0.59124 - acc: 0.6841 -- iter: 1536/1584
[A[ATraining Step: 499  | total loss: [1m[32m0.59130[0m[0m | time: 43.329s
[2K
| RMSProp | epoch: 010 | loss: 0.59130 - acc: 0.6844 -- iter: 1568/1584
[A[ATraining Step: 500  | total loss: [1m[32m0.57825[0m[0m | time: 46.675s
[2K
| RMSProp | epoch: 010 | loss: 0.57825 - acc: 0.6941 | val_loss: 0.72807 - val_acc: 0.5847 -- iter: 1584/1584
--
Training Step: 501  | total loss: [1m[32m0.57145[0m[0m | time: 0.997s
[2K
| RMSProp | epoch: 011 | loss: 0.57145 - acc: 0.6997 -- iter: 0032/1584
[A[ATraining Step: 502  | total loss: [1m[32m0.57860[0m[0m | time: 2.002s
[2K
| RMSProp | epoch: 011 | loss: 0.57860 - acc: 0.6954 -- iter: 0064/1584
[A[ATraining Step: 503  | total loss: [1m[32m0.56982[0m[0m | time: 3.025s
[2K
| RMSProp | epoch: 011 | loss: 0.56982 - acc: 0.7040 -- iter: 0096/1584
[A[ATraining Step: 504  | total loss: [1m[32m0.57143[0m[0m | time: 3.756s
[2K
| RMSProp | epoch: 011 | loss: 0.57143 - acc: 0.7086 -- iter: 0128/1584
[A[ATraining Step: 505  | total loss: [1m[32m0.56754[0m[0m | time: 4.614s
[2K
| RMSProp | epoch: 011 | loss: 0.56754 - acc: 0.7127 -- iter: 0160/1584
[A[ATraining Step: 506  | total loss: [1m[32m0.56187[0m[0m | time: 5.507s
[2K
| RMSProp | epoch: 011 | loss: 0.56187 - acc: 0.7164 -- iter: 0192/1584
[A[ATraining Step: 507  | total loss: [1m[32m0.56083[0m[0m | time: 6.377s
[2K
| RMSProp | epoch: 011 | loss: 0.56083 - acc: 0.7260 -- iter: 0224/1584
[A[ATraining Step: 508  | total loss: [1m[32m0.56519[0m[0m | time: 7.244s
[2K
| RMSProp | epoch: 011 | loss: 0.56519 - acc: 0.7222 -- iter: 0256/1584
[A[ATraining Step: 509  | total loss: [1m[32m0.56426[0m[0m | time: 7.691s
[2K
| RMSProp | epoch: 011 | loss: 0.56426 - acc: 0.7187 -- iter: 0288/1584
[A[ATraining Step: 510  | total loss: [1m[32m0.55171[0m[0m | time: 8.179s
[2K
| RMSProp | epoch: 011 | loss: 0.55171 - acc: 0.7281 -- iter: 0320/1584
[A[ATraining Step: 511  | total loss: [1m[32m0.52829[0m[0m | time: 9.108s
[2K
| RMSProp | epoch: 011 | loss: 0.52829 - acc: 0.7490 -- iter: 0352/1584
[A[ATraining Step: 512  | total loss: [1m[32m0.52473[0m[0m | time: 9.976s
[2K
| RMSProp | epoch: 011 | loss: 0.52473 - acc: 0.7460 -- iter: 0384/1584
[A[ATraining Step: 513  | total loss: [1m[32m0.55291[0m[0m | time: 10.863s
[2K
| RMSProp | epoch: 011 | loss: 0.55291 - acc: 0.7308 -- iter: 0416/1584
[A[ATraining Step: 514  | total loss: [1m[32m0.57353[0m[0m | time: 11.725s
[2K
| RMSProp | epoch: 011 | loss: 0.57353 - acc: 0.7171 -- iter: 0448/1584
[A[ATraining Step: 515  | total loss: [1m[32m0.57585[0m[0m | time: 12.778s
[2K
| RMSProp | epoch: 011 | loss: 0.57585 - acc: 0.7172 -- iter: 0480/1584
[A[ATraining Step: 516  | total loss: [1m[32m0.57732[0m[0m | time: 13.807s
[2K
| RMSProp | epoch: 011 | loss: 0.57732 - acc: 0.7080 -- iter: 0512/1584
[A[ATraining Step: 517  | total loss: [1m[32m0.57395[0m[0m | time: 14.722s
[2K
| RMSProp | epoch: 011 | loss: 0.57395 - acc: 0.7153 -- iter: 0544/1584
[A[ATraining Step: 518  | total loss: [1m[32m0.56860[0m[0m | time: 15.479s
[2K
| RMSProp | epoch: 011 | loss: 0.56860 - acc: 0.7188 -- iter: 0576/1584
[A[ATraining Step: 519  | total loss: [1m[32m0.57172[0m[0m | time: 16.382s
[2K
| RMSProp | epoch: 011 | loss: 0.57172 - acc: 0.7188 -- iter: 0608/1584
[A[ATraining Step: 520  | total loss: [1m[32m0.57003[0m[0m | time: 17.293s
[2K
| RMSProp | epoch: 011 | loss: 0.57003 - acc: 0.7219 -- iter: 0640/1584
[A[ATraining Step: 521  | total loss: [1m[32m0.56124[0m[0m | time: 18.242s
[2K
| RMSProp | epoch: 011 | loss: 0.56124 - acc: 0.7341 -- iter: 0672/1584
[A[ATraining Step: 522  | total loss: [1m[32m0.55794[0m[0m | time: 19.155s
[2K
| RMSProp | epoch: 011 | loss: 0.55794 - acc: 0.7419 -- iter: 0704/1584
[A[ATraining Step: 523  | total loss: [1m[32m0.54122[0m[0m | time: 20.084s
[2K
| RMSProp | epoch: 011 | loss: 0.54122 - acc: 0.7553 -- iter: 0736/1584
[A[ATraining Step: 524  | total loss: [1m[32m0.54715[0m[0m | time: 20.925s
[2K
| RMSProp | epoch: 011 | loss: 0.54715 - acc: 0.7516 -- iter: 0768/1584
[A[ATraining Step: 525  | total loss: [1m[32m0.54589[0m[0m | time: 21.841s
[2K
| RMSProp | epoch: 011 | loss: 0.54589 - acc: 0.7514 -- iter: 0800/1584
[A[ATraining Step: 526  | total loss: [1m[32m0.54905[0m[0m | time: 22.688s
[2K
| RMSProp | epoch: 011 | loss: 0.54905 - acc: 0.7482 -- iter: 0832/1584
[A[ATraining Step: 527  | total loss: [1m[32m0.55145[0m[0m | time: 23.514s
[2K
| RMSProp | epoch: 011 | loss: 0.55145 - acc: 0.7390 -- iter: 0864/1584
[A[ATraining Step: 528  | total loss: [1m[32m0.54159[0m[0m | time: 24.516s
[2K
| RMSProp | epoch: 011 | loss: 0.54159 - acc: 0.7495 -- iter: 0896/1584
[A[ATraining Step: 529  | total loss: [1m[32m0.53437[0m[0m | time: 25.543s
[2K
| RMSProp | epoch: 011 | loss: 0.53437 - acc: 0.7620 -- iter: 0928/1584
[A[ATraining Step: 530  | total loss: [1m[32m0.52717[0m[0m | time: 26.291s
[2K
| RMSProp | epoch: 011 | loss: 0.52717 - acc: 0.7671 -- iter: 0960/1584
[A[ATraining Step: 531  | total loss: [1m[32m0.52773[0m[0m | time: 27.117s
[2K
| RMSProp | epoch: 011 | loss: 0.52773 - acc: 0.7622 -- iter: 0992/1584
[A[ATraining Step: 532  | total loss: [1m[32m0.52509[0m[0m | time: 27.988s
[2K
| RMSProp | epoch: 011 | loss: 0.52509 - acc: 0.7673 -- iter: 1024/1584
[A[ATraining Step: 533  | total loss: [1m[32m0.51530[0m[0m | time: 28.869s
[2K
| RMSProp | epoch: 011 | loss: 0.51530 - acc: 0.7687 -- iter: 1056/1584
[A[ATraining Step: 534  | total loss: [1m[32m0.53341[0m[0m | time: 29.730s
[2K
| RMSProp | epoch: 011 | loss: 0.53341 - acc: 0.7574 -- iter: 1088/1584
[A[ATraining Step: 535  | total loss: [1m[32m0.52985[0m[0m | time: 30.609s
[2K
| RMSProp | epoch: 011 | loss: 0.52985 - acc: 0.7567 -- iter: 1120/1584
[A[ATraining Step: 536  | total loss: [1m[32m0.52661[0m[0m | time: 31.505s
[2K
| RMSProp | epoch: 011 | loss: 0.52661 - acc: 0.7560 -- iter: 1152/1584
[A[ATraining Step: 537  | total loss: [1m[32m0.52131[0m[0m | time: 32.379s
[2K
| RMSProp | epoch: 011 | loss: 0.52131 - acc: 0.7523 -- iter: 1184/1584
[A[ATraining Step: 538  | total loss: [1m[32m0.50999[0m[0m | time: 33.248s
[2K
| RMSProp | epoch: 011 | loss: 0.50999 - acc: 0.7614 -- iter: 1216/1584
[A[ATraining Step: 539  | total loss: [1m[32m0.50434[0m[0m | time: 34.091s
[2K
| RMSProp | epoch: 011 | loss: 0.50434 - acc: 0.7603 -- iter: 1248/1584
[A[ATraining Step: 540  | total loss: [1m[32m0.54391[0m[0m | time: 35.054s
[2K
| RMSProp | epoch: 011 | loss: 0.54391 - acc: 0.7374 -- iter: 1280/1584
[A[ATraining Step: 541  | total loss: [1m[32m0.54360[0m[0m | time: 36.041s
[2K
| RMSProp | epoch: 011 | loss: 0.54360 - acc: 0.7355 -- iter: 1312/1584
[A[ATraining Step: 542  | total loss: [1m[32m0.54332[0m[0m | time: 37.066s
[2K
| RMSProp | epoch: 011 | loss: 0.54332 - acc: 0.7370 -- iter: 1344/1584
[A[ATraining Step: 543  | total loss: [1m[32m0.52553[0m[0m | time: 37.782s
[2K
| RMSProp | epoch: 011 | loss: 0.52553 - acc: 0.7508 -- iter: 1376/1584
[A[ATraining Step: 544  | total loss: [1m[32m0.52740[0m[0m | time: 38.654s
[2K
| RMSProp | epoch: 011 | loss: 0.52740 - acc: 0.7476 -- iter: 1408/1584
[A[ATraining Step: 545  | total loss: [1m[32m0.52608[0m[0m | time: 39.699s
[2K
| RMSProp | epoch: 011 | loss: 0.52608 - acc: 0.7478 -- iter: 1440/1584
[A[ATraining Step: 546  | total loss: [1m[32m0.52924[0m[0m | time: 40.851s
[2K
| RMSProp | epoch: 011 | loss: 0.52924 - acc: 0.7418 -- iter: 1472/1584
[A[ATraining Step: 547  | total loss: [1m[32m0.51683[0m[0m | time: 41.914s
[2K
| RMSProp | epoch: 011 | loss: 0.51683 - acc: 0.7551 -- iter: 1504/1584
[A[ATraining Step: 548  | total loss: [1m[32m0.50638[0m[0m | time: 42.985s
[2K
| RMSProp | epoch: 011 | loss: 0.50638 - acc: 0.7640 -- iter: 1536/1584
[A[ATraining Step: 549  | total loss: [1m[32m0.52270[0m[0m | time: 44.144s
[2K
| RMSProp | epoch: 011 | loss: 0.52270 - acc: 0.7532 -- iter: 1568/1584
[A[ATraining Step: 550  | total loss: [1m[32m0.52774[0m[0m | time: 48.243s
[2K
| RMSProp | epoch: 011 | loss: 0.52774 - acc: 0.7466 | val_loss: 0.53626 - val_acc: 0.7500 -- iter: 1584/1584
--
Training Step: 551  | total loss: [1m[32m0.52115[0m[0m | time: 1.055s
[2K
| RMSProp | epoch: 012 | loss: 0.52115 - acc: 0.7532 -- iter: 0032/1584
[A[ATraining Step: 552  | total loss: [1m[32m0.51651[0m[0m | time: 1.944s
[2K
| RMSProp | epoch: 012 | loss: 0.51651 - acc: 0.7560 -- iter: 0064/1584
[A[ATraining Step: 553  | total loss: [1m[32m0.51283[0m[0m | time: 2.826s
[2K
| RMSProp | epoch: 012 | loss: 0.51283 - acc: 0.7554 -- iter: 0096/1584
[A[ATraining Step: 554  | total loss: [1m[32m0.51882[0m[0m | time: 3.802s
[2K
| RMSProp | epoch: 012 | loss: 0.51882 - acc: 0.7517 -- iter: 0128/1584
[A[ATraining Step: 555  | total loss: [1m[32m0.50819[0m[0m | time: 4.887s
[2K
| RMSProp | epoch: 012 | loss: 0.50819 - acc: 0.7641 -- iter: 0160/1584
[A[ATraining Step: 556  | total loss: [1m[32m0.51844[0m[0m | time: 5.974s
[2K
| RMSProp | epoch: 012 | loss: 0.51844 - acc: 0.7502 -- iter: 0192/1584
[A[ATraining Step: 557  | total loss: [1m[32m0.51514[0m[0m | time: 7.082s
[2K
| RMSProp | epoch: 012 | loss: 0.51514 - acc: 0.7533 -- iter: 0224/1584
[A[ATraining Step: 558  | total loss: [1m[32m0.50439[0m[0m | time: 8.156s
[2K
| RMSProp | epoch: 012 | loss: 0.50439 - acc: 0.7592 -- iter: 0256/1584
[A[ATraining Step: 559  | total loss: [1m[32m0.50762[0m[0m | time: 9.197s
[2K
| RMSProp | epoch: 012 | loss: 0.50762 - acc: 0.7552 -- iter: 0288/1584
[A[ATraining Step: 560  | total loss: [1m[32m0.50285[0m[0m | time: 9.711s
[2K
| RMSProp | epoch: 012 | loss: 0.50285 - acc: 0.7609 -- iter: 0320/1584
[A[ATraining Step: 561  | total loss: [1m[32m0.47853[0m[0m | time: 10.227s
[2K
| RMSProp | epoch: 012 | loss: 0.47853 - acc: 0.7723 -- iter: 0352/1584
[A[ATraining Step: 562  | total loss: [1m[32m0.45387[0m[0m | time: 11.459s
[2K
| RMSProp | epoch: 012 | loss: 0.45387 - acc: 0.7888 -- iter: 0384/1584
[A[ATraining Step: 563  | total loss: [1m[32m0.48840[0m[0m | time: 12.608s
[2K
| RMSProp | epoch: 012 | loss: 0.48840 - acc: 0.7662 -- iter: 0416/1584
[A[ATraining Step: 564  | total loss: [1m[32m0.49803[0m[0m | time: 13.780s
[2K
| RMSProp | epoch: 012 | loss: 0.49803 - acc: 0.7646 -- iter: 0448/1584
[A[ATraining Step: 565  | total loss: [1m[32m0.49710[0m[0m | time: 14.687s
[2K
| RMSProp | epoch: 012 | loss: 0.49710 - acc: 0.7662 -- iter: 0480/1584
[A[ATraining Step: 566  | total loss: [1m[32m0.50035[0m[0m | time: 15.811s
[2K
| RMSProp | epoch: 012 | loss: 0.50035 - acc: 0.7646 -- iter: 0512/1584
[A[ATraining Step: 567  | total loss: [1m[32m0.50033[0m[0m | time: 16.850s
[2K
| RMSProp | epoch: 012 | loss: 0.50033 - acc: 0.7694 -- iter: 0544/1584
[A[ATraining Step: 568  | total loss: [1m[32m0.49835[0m[0m | time: 17.980s
[2K
| RMSProp | epoch: 012 | loss: 0.49835 - acc: 0.7643 -- iter: 0576/1584
[A[ATraining Step: 569  | total loss: [1m[32m0.51349[0m[0m | time: 18.957s
[2K
| RMSProp | epoch: 012 | loss: 0.51349 - acc: 0.7473 -- iter: 0608/1584
[A[ATraining Step: 570  | total loss: [1m[32m0.49972[0m[0m | time: 19.873s
[2K
| RMSProp | epoch: 012 | loss: 0.49972 - acc: 0.7600 -- iter: 0640/1584
[A[ATraining Step: 571  | total loss: [1m[32m0.50246[0m[0m | time: 20.886s
[2K
| RMSProp | epoch: 012 | loss: 0.50246 - acc: 0.7622 -- iter: 0672/1584
[A[ATraining Step: 572  | total loss: [1m[32m0.52666[0m[0m | time: 22.041s
[2K
| RMSProp | epoch: 012 | loss: 0.52666 - acc: 0.7422 -- iter: 0704/1584
[A[ATraining Step: 573  | total loss: [1m[32m0.53257[0m[0m | time: 23.163s
[2K
| RMSProp | epoch: 012 | loss: 0.53257 - acc: 0.7305 -- iter: 0736/1584
[A[ATraining Step: 574  | total loss: [1m[32m0.52845[0m[0m | time: 24.249s
[2K
| RMSProp | epoch: 012 | loss: 0.52845 - acc: 0.7387 -- iter: 0768/1584
[A[ATraining Step: 575  | total loss: [1m[32m0.52298[0m[0m | time: 25.375s
[2K
| RMSProp | epoch: 012 | loss: 0.52298 - acc: 0.7398 -- iter: 0800/1584
[A[ATraining Step: 576  | total loss: [1m[32m0.52554[0m[0m | time: 26.639s
[2K
| RMSProp | epoch: 012 | loss: 0.52554 - acc: 0.7408 -- iter: 0832/1584
[A[ATraining Step: 577  | total loss: [1m[32m0.53638[0m[0m | time: 27.903s
[2K
| RMSProp | epoch: 012 | loss: 0.53638 - acc: 0.7418 -- iter: 0864/1584
[A[ATraining Step: 578  | total loss: [1m[32m0.53165[0m[0m | time: 28.928s
[2K
| RMSProp | epoch: 012 | loss: 0.53165 - acc: 0.7488 -- iter: 0896/1584
[A[ATraining Step: 579  | total loss: [1m[32m0.52141[0m[0m | time: 30.018s
[2K
| RMSProp | epoch: 012 | loss: 0.52141 - acc: 0.7552 -- iter: 0928/1584
[A[ATraining Step: 580  | total loss: [1m[32m0.51947[0m[0m | time: 31.147s
[2K
| RMSProp | epoch: 012 | loss: 0.51947 - acc: 0.7547 -- iter: 0960/1584
[A[ATraining Step: 581  | total loss: [1m[32m0.52712[0m[0m | time: 32.173s
[2K
| RMSProp | epoch: 012 | loss: 0.52712 - acc: 0.7417 -- iter: 0992/1584
[A[ATraining Step: 582  | total loss: [1m[32m0.52034[0m[0m | time: 33.250s
[2K
| RMSProp | epoch: 012 | loss: 0.52034 - acc: 0.7457 -- iter: 1024/1584
[A[ATraining Step: 583  | total loss: [1m[32m0.50514[0m[0m | time: 34.285s
[2K
| RMSProp | epoch: 012 | loss: 0.50514 - acc: 0.7617 -- iter: 1056/1584
[A[ATraining Step: 584  | total loss: [1m[32m0.48166[0m[0m | time: 35.504s
[2K
| RMSProp | epoch: 012 | loss: 0.48166 - acc: 0.7762 -- iter: 1088/1584
[A[ATraining Step: 585  | total loss: [1m[32m0.49043[0m[0m | time: 36.369s
[2K
| RMSProp | epoch: 012 | loss: 0.49043 - acc: 0.7611 -- iter: 1120/1584
[A[ATraining Step: 586  | total loss: [1m[32m0.48983[0m[0m | time: 37.406s
[2K
| RMSProp | epoch: 012 | loss: 0.48983 - acc: 0.7568 -- iter: 1152/1584
[A[ATraining Step: 587  | total loss: [1m[32m0.49420[0m[0m | time: 38.446s
[2K
| RMSProp | epoch: 012 | loss: 0.49420 - acc: 0.7530 -- iter: 1184/1584
[A[ATraining Step: 588  | total loss: [1m[32m0.49714[0m[0m | time: 39.420s
[2K
| RMSProp | epoch: 012 | loss: 0.49714 - acc: 0.7496 -- iter: 1216/1584
[A[ATraining Step: 589  | total loss: [1m[32m0.48184[0m[0m | time: 40.555s
[2K
| RMSProp | epoch: 012 | loss: 0.48184 - acc: 0.7621 -- iter: 1248/1584
[A[ATraining Step: 590  | total loss: [1m[32m0.47817[0m[0m | time: 41.716s
[2K
| RMSProp | epoch: 012 | loss: 0.47817 - acc: 0.7672 -- iter: 1280/1584
[A[ATraining Step: 591  | total loss: [1m[32m0.46729[0m[0m | time: 42.899s
[2K
| RMSProp | epoch: 012 | loss: 0.46729 - acc: 0.7780 -- iter: 1312/1584
[A[ATraining Step: 592  | total loss: [1m[32m0.47419[0m[0m | time: 43.896s
[2K
| RMSProp | epoch: 012 | loss: 0.47419 - acc: 0.7783 -- iter: 1344/1584
[A[ATraining Step: 593  | total loss: [1m[32m0.48810[0m[0m | time: 44.895s
[2K
| RMSProp | epoch: 012 | loss: 0.48810 - acc: 0.7692 -- iter: 1376/1584
[A[ATraining Step: 594  | total loss: [1m[32m0.47781[0m[0m | time: 45.911s
[2K
| RMSProp | epoch: 012 | loss: 0.47781 - acc: 0.7767 -- iter: 1408/1584
[A[ATraining Step: 595  | total loss: [1m[32m0.46758[0m[0m | time: 46.909s
[2K
| RMSProp | epoch: 012 | loss: 0.46758 - acc: 0.7834 -- iter: 1440/1584
[A[ATraining Step: 596  | total loss: [1m[32m0.44491[0m[0m | time: 47.936s
[2K
| RMSProp | epoch: 012 | loss: 0.44491 - acc: 0.8019 -- iter: 1472/1584
[A[ATraining Step: 597  | total loss: [1m[32m0.45045[0m[0m | time: 48.997s
[2K
| RMSProp | epoch: 012 | loss: 0.45045 - acc: 0.7998 -- iter: 1504/1584
[A[ATraining Step: 598  | total loss: [1m[32m0.45585[0m[0m | time: 50.038s
[2K
| RMSProp | epoch: 012 | loss: 0.45585 - acc: 0.7855 -- iter: 1536/1584
[A[ATraining Step: 599  | total loss: [1m[32m0.45010[0m[0m | time: 51.201s
[2K
| RMSProp | epoch: 012 | loss: 0.45010 - acc: 0.7882 -- iter: 1568/1584
[A[ATraining Step: 600  | total loss: [1m[32m0.43729[0m[0m | time: 54.743s
[2K
| RMSProp | epoch: 012 | loss: 0.43729 - acc: 0.8000 | val_loss: 0.68844 - val_acc: 0.6472 -- iter: 1584/1584
--
Training Step: 601  | total loss: [1m[32m0.44821[0m[0m | time: 1.264s
[2K
| RMSProp | epoch: 013 | loss: 0.44821 - acc: 0.7919 -- iter: 0032/1584
[A[ATraining Step: 602  | total loss: [1m[32m0.45525[0m[0m | time: 2.458s
[2K
| RMSProp | epoch: 013 | loss: 0.45525 - acc: 0.7846 -- iter: 0064/1584
[A[ATraining Step: 603  | total loss: [1m[32m0.45003[0m[0m | time: 3.656s
[2K
| RMSProp | epoch: 013 | loss: 0.45003 - acc: 0.7967 -- iter: 0096/1584
[A[ATraining Step: 604  | total loss: [1m[32m0.45313[0m[0m | time: 4.550s
[2K
| RMSProp | epoch: 013 | loss: 0.45313 - acc: 0.7889 -- iter: 0128/1584
[A[ATraining Step: 605  | total loss: [1m[32m0.44074[0m[0m | time: 5.557s
[2K
| RMSProp | epoch: 013 | loss: 0.44074 - acc: 0.7944 -- iter: 0160/1584
[A[ATraining Step: 606  | total loss: [1m[32m0.42888[0m[0m | time: 6.554s
[2K
| RMSProp | epoch: 013 | loss: 0.42888 - acc: 0.8056 -- iter: 0192/1584
[A[ATraining Step: 607  | total loss: [1m[32m0.41901[0m[0m | time: 7.644s
[2K
| RMSProp | epoch: 013 | loss: 0.41901 - acc: 0.8094 -- iter: 0224/1584
[A[ATraining Step: 608  | total loss: [1m[32m0.42320[0m[0m | time: 8.749s
[2K
| RMSProp | epoch: 013 | loss: 0.42320 - acc: 0.8128 -- iter: 0256/1584
[A[ATraining Step: 609  | total loss: [1m[32m0.42894[0m[0m | time: 9.805s
[2K
| RMSProp | epoch: 013 | loss: 0.42894 - acc: 0.8159 -- iter: 0288/1584
[A[ATraining Step: 610  | total loss: [1m[32m0.43817[0m[0m | time: 10.960s
[2K
| RMSProp | epoch: 013 | loss: 0.43817 - acc: 0.8062 -- iter: 0320/1584
[A[ATraining Step: 611  | total loss: [1m[32m0.42720[0m[0m | time: 11.456s
[2K
| RMSProp | epoch: 013 | loss: 0.42720 - acc: 0.8131 -- iter: 0352/1584
[A[ATraining Step: 612  | total loss: [1m[32m0.41252[0m[0m | time: 12.120s
[2K
| RMSProp | epoch: 013 | loss: 0.41252 - acc: 0.8193 -- iter: 0384/1584
[A[ATraining Step: 613  | total loss: [1m[32m0.38818[0m[0m | time: 13.252s
[2K
| RMSProp | epoch: 013 | loss: 0.38818 - acc: 0.8374 -- iter: 0416/1584
[A[ATraining Step: 614  | total loss: [1m[32m0.39528[0m[0m | time: 14.271s
[2K
| RMSProp | epoch: 013 | loss: 0.39528 - acc: 0.8286 -- iter: 0448/1584
[A[ATraining Step: 615  | total loss: [1m[32m0.38671[0m[0m | time: 15.182s
[2K
| RMSProp | epoch: 013 | loss: 0.38671 - acc: 0.8333 -- iter: 0480/1584
[A[ATraining Step: 616  | total loss: [1m[32m0.41029[0m[0m | time: 16.187s
[2K
| RMSProp | epoch: 013 | loss: 0.41029 - acc: 0.8249 -- iter: 0512/1584
[A[ATraining Step: 617  | total loss: [1m[32m0.40331[0m[0m | time: 17.323s
[2K
| RMSProp | epoch: 013 | loss: 0.40331 - acc: 0.8268 -- iter: 0544/1584
[A[ATraining Step: 618  | total loss: [1m[32m0.39549[0m[0m | time: 18.296s
[2K
| RMSProp | epoch: 013 | loss: 0.39549 - acc: 0.8348 -- iter: 0576/1584
[A[ATraining Step: 619  | total loss: [1m[32m0.41455[0m[0m | time: 19.289s
[2K
| RMSProp | epoch: 013 | loss: 0.41455 - acc: 0.8263 -- iter: 0608/1584
[A[ATraining Step: 620  | total loss: [1m[32m0.43249[0m[0m | time: 20.364s
[2K
| RMSProp | epoch: 013 | loss: 0.43249 - acc: 0.8155 -- iter: 0640/1584
[A[ATraining Step: 621  | total loss: [1m[32m0.42864[0m[0m | time: 21.458s
[2K
| RMSProp | epoch: 013 | loss: 0.42864 - acc: 0.8152 -- iter: 0672/1584
[A[ATraining Step: 622  | total loss: [1m[32m0.44181[0m[0m | time: 22.499s
[2K
| RMSProp | epoch: 013 | loss: 0.44181 - acc: 0.8056 -- iter: 0704/1584
[A[ATraining Step: 623  | total loss: [1m[32m0.44587[0m[0m | time: 23.571s
[2K
| RMSProp | epoch: 013 | loss: 0.44587 - acc: 0.8000 -- iter: 0736/1584
[A[ATraining Step: 624  | total loss: [1m[32m0.43522[0m[0m | time: 24.572s
[2K
| RMSProp | epoch: 013 | loss: 0.43522 - acc: 0.8075 -- iter: 0768/1584
[A[ATraining Step: 625  | total loss: [1m[32m0.42708[0m[0m | time: 25.661s
[2K
| RMSProp | epoch: 013 | loss: 0.42708 - acc: 0.8111 -- iter: 0800/1584
[A[ATraining Step: 626  | total loss: [1m[32m0.43928[0m[0m | time: 26.706s
[2K
| RMSProp | epoch: 013 | loss: 0.43928 - acc: 0.8019 -- iter: 0832/1584
[A[ATraining Step: 627  | total loss: [1m[32m0.45817[0m[0m | time: 27.846s
[2K
| RMSProp | epoch: 013 | loss: 0.45817 - acc: 0.7936 -- iter: 0864/1584
[A[ATraining Step: 628  | total loss: [1m[32m0.47948[0m[0m | time: 28.855s
[2K
| RMSProp | epoch: 013 | loss: 0.47948 - acc: 0.7799 -- iter: 0896/1584
[A[ATraining Step: 629  | total loss: [1m[32m0.46743[0m[0m | time: 29.870s
[2K
| RMSProp | epoch: 013 | loss: 0.46743 - acc: 0.7956 -- iter: 0928/1584
[A[ATraining Step: 630  | total loss: [1m[32m0.45781[0m[0m | time: 31.180s
[2K
| RMSProp | epoch: 013 | loss: 0.45781 - acc: 0.7942 -- iter: 0960/1584
[A[ATraining Step: 631  | total loss: [1m[32m0.44926[0m[0m | time: 32.234s
[2K
| RMSProp | epoch: 013 | loss: 0.44926 - acc: 0.8023 -- iter: 0992/1584
[A[ATraining Step: 632  | total loss: [1m[32m0.43084[0m[0m | time: 33.063s
[2K
| RMSProp | epoch: 013 | loss: 0.43084 - acc: 0.8158 -- iter: 1024/1584
[A[ATraining Step: 633  | total loss: [1m[32m0.41602[0m[0m | time: 33.824s
[2K
| RMSProp | epoch: 013 | loss: 0.41602 - acc: 0.8217 -- iter: 1056/1584
[A[ATraining Step: 634  | total loss: [1m[32m0.40206[0m[0m | time: 34.661s
[2K
| RMSProp | epoch: 013 | loss: 0.40206 - acc: 0.8302 -- iter: 1088/1584
[A[ATraining Step: 635  | total loss: [1m[32m0.40769[0m[0m | time: 35.551s
[2K
| RMSProp | epoch: 013 | loss: 0.40769 - acc: 0.8221 -- iter: 1120/1584
[A[ATraining Step: 636  | total loss: [1m[32m0.40273[0m[0m | time: 36.568s
[2K
| RMSProp | epoch: 013 | loss: 0.40273 - acc: 0.8243 -- iter: 1152/1584
[A[ATraining Step: 637  | total loss: [1m[32m0.39250[0m[0m | time: 37.599s
[2K
| RMSProp | epoch: 013 | loss: 0.39250 - acc: 0.8263 -- iter: 1184/1584
[A[ATraining Step: 638  | total loss: [1m[32m0.38399[0m[0m | time: 38.754s
[2K
| RMSProp | epoch: 013 | loss: 0.38399 - acc: 0.8280 -- iter: 1216/1584
[A[ATraining Step: 639  | total loss: [1m[32m0.39709[0m[0m | time: 39.849s
[2K
| RMSProp | epoch: 013 | loss: 0.39709 - acc: 0.8202 -- iter: 1248/1584
[A[ATraining Step: 640  | total loss: [1m[32m0.40096[0m[0m | time: 40.961s
[2K
| RMSProp | epoch: 013 | loss: 0.40096 - acc: 0.8132 -- iter: 1280/1584
[A[ATraining Step: 641  | total loss: [1m[32m0.39816[0m[0m | time: 42.007s
[2K
| RMSProp | epoch: 013 | loss: 0.39816 - acc: 0.8162 -- iter: 1312/1584
[A[ATraining Step: 642  | total loss: [1m[32m0.40632[0m[0m | time: 42.968s
[2K
| RMSProp | epoch: 013 | loss: 0.40632 - acc: 0.8127 -- iter: 1344/1584
[A[ATraining Step: 643  | total loss: [1m[32m0.39238[0m[0m | time: 44.101s
[2K
| RMSProp | epoch: 013 | loss: 0.39238 - acc: 0.8252 -- iter: 1376/1584
[A[ATraining Step: 644  | total loss: [1m[32m0.38367[0m[0m | time: 45.354s
[2K
| RMSProp | epoch: 013 | loss: 0.38367 - acc: 0.8333 -- iter: 1408/1584
[A[ATraining Step: 645  | total loss: [1m[32m0.38944[0m[0m | time: 46.539s
[2K
| RMSProp | epoch: 013 | loss: 0.38944 - acc: 0.8281 -- iter: 1440/1584
[A[ATraining Step: 646  | total loss: [1m[32m0.38517[0m[0m | time: 47.413s
[2K
| RMSProp | epoch: 013 | loss: 0.38517 - acc: 0.8328 -- iter: 1472/1584
[A[ATraining Step: 647  | total loss: [1m[32m0.37263[0m[0m | time: 48.379s
[2K
| RMSProp | epoch: 013 | loss: 0.37263 - acc: 0.8401 -- iter: 1504/1584
[A[ATraining Step: 648  | total loss: [1m[32m0.38269[0m[0m | time: 49.455s
[2K
| RMSProp | epoch: 013 | loss: 0.38269 - acc: 0.8405 -- iter: 1536/1584
[A[ATraining Step: 649  | total loss: [1m[32m0.36966[0m[0m | time: 50.603s
[2K
| RMSProp | epoch: 013 | loss: 0.36966 - acc: 0.8471 -- iter: 1568/1584
[A[ATraining Step: 650  | total loss: [1m[32m0.40096[0m[0m | time: 53.967s
[2K
| RMSProp | epoch: 013 | loss: 0.40096 - acc: 0.8280 | val_loss: 0.55517 - val_acc: 0.7278 -- iter: 1584/1584
--
Training Step: 651  | total loss: [1m[32m0.39535[0m[0m | time: 1.211s
[2K
| RMSProp | epoch: 014 | loss: 0.39535 - acc: 0.8296 -- iter: 0032/1584
[A[ATraining Step: 652  | total loss: [1m[32m0.40553[0m[0m | time: 2.255s
[2K
| RMSProp | epoch: 014 | loss: 0.40553 - acc: 0.8247 -- iter: 0064/1584
[A[ATraining Step: 653  | total loss: [1m[32m0.39559[0m[0m | time: 3.396s
[2K
| RMSProp | epoch: 014 | loss: 0.39559 - acc: 0.8391 -- iter: 0096/1584
[A[ATraining Step: 654  | total loss: [1m[32m0.38923[0m[0m | time: 4.589s
[2K
| RMSProp | epoch: 014 | loss: 0.38923 - acc: 0.8490 -- iter: 0128/1584
[A[ATraining Step: 655  | total loss: [1m[32m0.37080[0m[0m | time: 5.824s
[2K
| RMSProp | epoch: 014 | loss: 0.37080 - acc: 0.8547 -- iter: 0160/1584
[A[ATraining Step: 656  | total loss: [1m[32m0.37386[0m[0m | time: 6.670s
[2K
| RMSProp | epoch: 014 | loss: 0.37386 - acc: 0.8474 -- iter: 0192/1584
[A[ATraining Step: 657  | total loss: [1m[32m0.36705[0m[0m | time: 7.664s
[2K
| RMSProp | epoch: 014 | loss: 0.36705 - acc: 0.8501 -- iter: 0224/1584
[A[ATraining Step: 658  | total loss: [1m[32m0.36290[0m[0m | time: 8.703s
[2K
| RMSProp | epoch: 014 | loss: 0.36290 - acc: 0.8526 -- iter: 0256/1584
[A[ATraining Step: 659  | total loss: [1m[32m0.36316[0m[0m | time: 9.758s
[2K
| RMSProp | epoch: 014 | loss: 0.36316 - acc: 0.8517 -- iter: 0288/1584
[A[ATraining Step: 660  | total loss: [1m[32m0.36219[0m[0m | time: 10.833s
[2K
| RMSProp | epoch: 014 | loss: 0.36219 - acc: 0.8509 -- iter: 0320/1584
[A[ATraining Step: 661  | total loss: [1m[32m0.35291[0m[0m | time: 11.967s
[2K
| RMSProp | epoch: 014 | loss: 0.35291 - acc: 0.8565 -- iter: 0352/1584
[A[ATraining Step: 662  | total loss: [1m[32m0.35518[0m[0m | time: 12.439s
[2K
| RMSProp | epoch: 014 | loss: 0.35518 - acc: 0.8552 -- iter: 0384/1584
[A[ATraining Step: 663  | total loss: [1m[32m0.35647[0m[0m | time: 12.910s
[2K
| RMSProp | epoch: 014 | loss: 0.35647 - acc: 0.8509 -- iter: 0416/1584
[A[ATraining Step: 664  | total loss: [1m[32m0.33866[0m[0m | time: 13.846s
[2K
| RMSProp | epoch: 014 | loss: 0.33866 - acc: 0.8658 -- iter: 0448/1584
[A[ATraining Step: 665  | total loss: [1m[32m0.35055[0m[0m | time: 14.961s
[2K
| RMSProp | epoch: 014 | loss: 0.35055 - acc: 0.8574 -- iter: 0480/1584
[A[ATraining Step: 666  | total loss: [1m[32m0.37998[0m[0m | time: 16.020s
[2K
| RMSProp | epoch: 014 | loss: 0.37998 - acc: 0.8341 -- iter: 0512/1584
[A[ATraining Step: 667  | total loss: [1m[32m0.39282[0m[0m | time: 17.006s
[2K
| RMSProp | epoch: 014 | loss: 0.39282 - acc: 0.8226 -- iter: 0544/1584
[A[ATraining Step: 668  | total loss: [1m[32m0.40897[0m[0m | time: 18.151s
[2K
| RMSProp | epoch: 014 | loss: 0.40897 - acc: 0.8153 -- iter: 0576/1584
[A[ATraining Step: 669  | total loss: [1m[32m0.40081[0m[0m | time: 19.332s
[2K
| RMSProp | epoch: 014 | loss: 0.40081 - acc: 0.8213 -- iter: 0608/1584
[A[ATraining Step: 670  | total loss: [1m[32m0.38675[0m[0m | time: 20.462s
[2K
| RMSProp | epoch: 014 | loss: 0.38675 - acc: 0.8329 -- iter: 0640/1584
[A[ATraining Step: 671  | total loss: [1m[32m0.38273[0m[0m | time: 21.316s
[2K
| RMSProp | epoch: 014 | loss: 0.38273 - acc: 0.8309 -- iter: 0672/1584
[A[ATraining Step: 672  | total loss: [1m[32m0.37383[0m[0m | time: 22.244s
[2K
| RMSProp | epoch: 014 | loss: 0.37383 - acc: 0.8384 -- iter: 0704/1584
[A[ATraining Step: 673  | total loss: [1m[32m0.38677[0m[0m | time: 23.252s
[2K
| RMSProp | epoch: 014 | loss: 0.38677 - acc: 0.8296 -- iter: 0736/1584
[A[ATraining Step: 674  | total loss: [1m[32m0.39516[0m[0m | time: 24.279s
[2K
| RMSProp | epoch: 014 | loss: 0.39516 - acc: 0.8216 -- iter: 0768/1584
[A[ATraining Step: 675  | total loss: [1m[32m0.38066[0m[0m | time: 25.342s
[2K
| RMSProp | epoch: 014 | loss: 0.38066 - acc: 0.8238 -- iter: 0800/1584
[A[ATraining Step: 676  | total loss: [1m[32m0.37560[0m[0m | time: 26.381s
[2K
| RMSProp | epoch: 014 | loss: 0.37560 - acc: 0.8289 -- iter: 0832/1584
[A[ATraining Step: 677  | total loss: [1m[32m0.37963[0m[0m | time: 27.446s
[2K
| RMSProp | epoch: 014 | loss: 0.37963 - acc: 0.8148 -- iter: 0864/1584
[A[ATraining Step: 678  | total loss: [1m[32m0.38814[0m[0m | time: 28.578s
[2K
| RMSProp | epoch: 014 | loss: 0.38814 - acc: 0.8146 -- iter: 0896/1584
[A[ATraining Step: 679  | total loss: [1m[32m0.37738[0m[0m | time: 29.455s
[2K
| RMSProp | epoch: 014 | loss: 0.37738 - acc: 0.8237 -- iter: 0928/1584
[A[ATraining Step: 680  | total loss: [1m[32m0.37292[0m[0m | time: 30.338s
[2K
| RMSProp | epoch: 014 | loss: 0.37292 - acc: 0.8289 -- iter: 0960/1584
[A[ATraining Step: 681  | total loss: [1m[32m0.37451[0m[0m | time: 31.169s
[2K
| RMSProp | epoch: 014 | loss: 0.37451 - acc: 0.8210 -- iter: 0992/1584
[A[ATraining Step: 682  | total loss: [1m[32m0.37518[0m[0m | time: 32.170s
[2K
| RMSProp | epoch: 014 | loss: 0.37518 - acc: 0.8201 -- iter: 1024/1584
[A[ATraining Step: 683  | total loss: [1m[32m0.37434[0m[0m | time: 33.405s
[2K
| RMSProp | epoch: 014 | loss: 0.37434 - acc: 0.8162 -- iter: 1056/1584
[A[ATraining Step: 684  | total loss: [1m[32m0.37132[0m[0m | time: 34.586s
[2K
| RMSProp | epoch: 014 | loss: 0.37132 - acc: 0.8252 -- iter: 1088/1584
[A[ATraining Step: 685  | total loss: [1m[32m0.34636[0m[0m | time: 35.771s
[2K
| RMSProp | epoch: 014 | loss: 0.34636 - acc: 0.8427 -- iter: 1120/1584
[A[ATraining Step: 686  | total loss: [1m[32m0.32074[0m[0m | time: 36.638s
[2K
| RMSProp | epoch: 014 | loss: 0.32074 - acc: 0.8584 -- iter: 1152/1584
[A[ATraining Step: 687  | total loss: [1m[32m0.31247[0m[0m | time: 37.618s
[2K
| RMSProp | epoch: 014 | loss: 0.31247 - acc: 0.8601 -- iter: 1184/1584
[A[ATraining Step: 688  | total loss: [1m[32m0.32228[0m[0m | time: 38.658s
[2K
| RMSProp | epoch: 014 | loss: 0.32228 - acc: 0.8585 -- iter: 1216/1584
[A[ATraining Step: 689  | total loss: [1m[32m0.35971[0m[0m | time: 39.662s
[2K
| RMSProp | epoch: 014 | loss: 0.35971 - acc: 0.8476 -- iter: 1248/1584
[A[ATraining Step: 690  | total loss: [1m[32m0.35083[0m[0m | time: 40.716s
[2K
| RMSProp | epoch: 014 | loss: 0.35083 - acc: 0.8535 -- iter: 1280/1584
[A[ATraining Step: 691  | total loss: [1m[32m0.34004[0m[0m | time: 41.762s
[2K
| RMSProp | epoch: 014 | loss: 0.34004 - acc: 0.8619 -- iter: 1312/1584
[A[ATraining Step: 692  | total loss: [1m[32m0.34017[0m[0m | time: 42.797s
[2K
| RMSProp | epoch: 014 | loss: 0.34017 - acc: 0.8663 -- iter: 1344/1584
[A[ATraining Step: 693  | total loss: [1m[32m0.33002[0m[0m | time: 43.835s
[2K
| RMSProp | epoch: 014 | loss: 0.33002 - acc: 0.8734 -- iter: 1376/1584
[A[ATraining Step: 694  | total loss: [1m[32m0.31579[0m[0m | time: 44.885s
[2K
| RMSProp | epoch: 014 | loss: 0.31579 - acc: 0.8798 -- iter: 1408/1584
[A[ATraining Step: 695  | total loss: [1m[32m0.30492[0m[0m | time: 46.026s
[2K
| RMSProp | epoch: 014 | loss: 0.30492 - acc: 0.8856 -- iter: 1440/1584
[A[ATraining Step: 696  | total loss: [1m[32m0.29473[0m[0m | time: 46.992s
[2K
| RMSProp | epoch: 014 | loss: 0.29473 - acc: 0.8908 -- iter: 1472/1584
[A[ATraining Step: 697  | total loss: [1m[32m0.28008[0m[0m | time: 47.853s
[2K
| RMSProp | epoch: 014 | loss: 0.28008 - acc: 0.8986 -- iter: 1504/1584
[A[ATraining Step: 698  | total loss: [1m[32m0.28666[0m[0m | time: 49.012s
[2K
| RMSProp | epoch: 014 | loss: 0.28666 - acc: 0.8994 -- iter: 1536/1584
[A[ATraining Step: 699  | total loss: [1m[32m0.29116[0m[0m | time: 50.190s
[2K
| RMSProp | epoch: 014 | loss: 0.29116 - acc: 0.8938 -- iter: 1568/1584
[A[ATraining Step: 700  | total loss: [1m[32m0.30368[0m[0m | time: 53.976s
[2K
| RMSProp | epoch: 014 | loss: 0.30368 - acc: 0.8888 | val_loss: 0.52331 - val_acc: 0.7782 -- iter: 1584/1584
--
Training Step: 701  | total loss: [1m[32m0.29747[0m[0m | time: 1.050s
[2K
| RMSProp | epoch: 015 | loss: 0.29747 - acc: 0.8905 -- iter: 0032/1584
[A[ATraining Step: 702  | total loss: [1m[32m0.31889[0m[0m | time: 2.264s
[2K
| RMSProp | epoch: 015 | loss: 0.31889 - acc: 0.8827 -- iter: 0064/1584
[A[ATraining Step: 703  | total loss: [1m[32m0.32042[0m[0m | time: 3.378s
[2K
| RMSProp | epoch: 015 | loss: 0.32042 - acc: 0.8820 -- iter: 0096/1584
[A[ATraining Step: 704  | total loss: [1m[32m0.31150[0m[0m | time: 4.498s
[2K
| RMSProp | epoch: 015 | loss: 0.31150 - acc: 0.8844 -- iter: 0128/1584
[A[ATraining Step: 705  | total loss: [1m[32m0.30484[0m[0m | time: 5.512s
[2K
| RMSProp | epoch: 015 | loss: 0.30484 - acc: 0.8866 -- iter: 0160/1584
[A[ATraining Step: 706  | total loss: [1m[32m0.30828[0m[0m | time: 6.935s
[2K
| RMSProp | epoch: 015 | loss: 0.30828 - acc: 0.8854 -- iter: 0192/1584
[A[ATraining Step: 707  | total loss: [1m[32m0.30327[0m[0m | time: 7.969s
[2K
| RMSProp | epoch: 015 | loss: 0.30327 - acc: 0.8875 -- iter: 0224/1584
[A[ATraining Step: 708  | total loss: [1m[32m0.29700[0m[0m | time: 8.827s
[2K
| RMSProp | epoch: 015 | loss: 0.29700 - acc: 0.8863 -- iter: 0256/1584
[A[ATraining Step: 709  | total loss: [1m[32m0.28985[0m[0m | time: 9.577s
[2K
| RMSProp | epoch: 015 | loss: 0.28985 - acc: 0.8883 -- iter: 0288/1584
[A[ATraining Step: 710  | total loss: [1m[32m0.29264[0m[0m | time: 10.459s
[2K
| RMSProp | epoch: 015 | loss: 0.29264 - acc: 0.8838 -- iter: 0320/1584
[A[ATraining Step: 711  | total loss: [1m[32m0.29336[0m[0m | time: 11.577s
[2K
| RMSProp | epoch: 015 | loss: 0.29336 - acc: 0.8798 -- iter: 0352/1584
[A[ATraining Step: 712  | total loss: [1m[32m0.29333[0m[0m | time: 12.653s
[2K
| RMSProp | epoch: 015 | loss: 0.29333 - acc: 0.8793 -- iter: 0384/1584
[A[ATraining Step: 713  | total loss: [1m[32m0.28203[0m[0m | time: 13.283s
[2K
| RMSProp | epoch: 015 | loss: 0.28203 - acc: 0.8883 -- iter: 0416/1584
[A[ATraining Step: 714  | total loss: [1m[32m0.26107[0m[0m | time: 13.797s
[2K
| RMSProp | epoch: 015 | loss: 0.26107 - acc: 0.8994 -- iter: 0448/1584
[A[ATraining Step: 715  | total loss: [1m[32m0.23727[0m[0m | time: 14.889s
[2K
| RMSProp | epoch: 015 | loss: 0.23727 - acc: 0.9095 -- iter: 0480/1584
[A[ATraining Step: 716  | total loss: [1m[32m0.24368[0m[0m | time: 16.039s
[2K
| RMSProp | epoch: 015 | loss: 0.24368 - acc: 0.9029 -- iter: 0512/1584
[A[ATraining Step: 717  | total loss: [1m[32m0.25746[0m[0m | time: 17.249s
[2K
| RMSProp | epoch: 015 | loss: 0.25746 - acc: 0.8939 -- iter: 0544/1584
[A[ATraining Step: 718  | total loss: [1m[32m0.27810[0m[0m | time: 18.333s
[2K
| RMSProp | epoch: 015 | loss: 0.27810 - acc: 0.8857 -- iter: 0576/1584
[A[ATraining Step: 719  | total loss: [1m[32m0.29930[0m[0m | time: 19.390s
[2K
| RMSProp | epoch: 015 | loss: 0.29930 - acc: 0.8690 -- iter: 0608/1584
[A[ATraining Step: 720  | total loss: [1m[32m0.29972[0m[0m | time: 20.782s
[2K
| RMSProp | epoch: 015 | loss: 0.29972 - acc: 0.8665 -- iter: 0640/1584
[A[ATraining Step: 721  | total loss: [1m[32m0.28647[0m[0m | time: 22.170s
[2K
| RMSProp | epoch: 015 | loss: 0.28647 - acc: 0.8767 -- iter: 0672/1584
[A[ATraining Step: 722  | total loss: [1m[32m0.28412[0m[0m | time: 23.182s
[2K
| RMSProp | epoch: 015 | loss: 0.28412 - acc: 0.8766 -- iter: 0704/1584
[A[ATraining Step: 723  | total loss: [1m[32m0.28056[0m[0m | time: 24.190s
[2K
| RMSProp | epoch: 015 | loss: 0.28056 - acc: 0.8795 -- iter: 0736/1584
[A[ATraining Step: 724  | total loss: [1m[32m0.30120[0m[0m | time: 25.305s
[2K
| RMSProp | epoch: 015 | loss: 0.30120 - acc: 0.8666 -- iter: 0768/1584
[A[ATraining Step: 725  | total loss: [1m[32m0.29783[0m[0m | time: 26.241s
[2K
| RMSProp | epoch: 015 | loss: 0.29783 - acc: 0.8674 -- iter: 0800/1584
[A[ATraining Step: 726  | total loss: [1m[32m0.29646[0m[0m | time: 27.226s
[2K
| RMSProp | epoch: 015 | loss: 0.29646 - acc: 0.8682 -- iter: 0832/1584
[A[ATraining Step: 727  | total loss: [1m[32m0.29401[0m[0m | time: 28.239s
[2K
| RMSProp | epoch: 015 | loss: 0.29401 - acc: 0.8782 -- iter: 0864/1584
[A[ATraining Step: 728  | total loss: [1m[32m0.27932[0m[0m | time: 29.367s
[2K
| RMSProp | epoch: 015 | loss: 0.27932 - acc: 0.8842 -- iter: 0896/1584
[A[ATraining Step: 729  | total loss: [1m[32m0.26476[0m[0m | time: 30.483s
[2K
| RMSProp | epoch: 015 | loss: 0.26476 - acc: 0.8926 -- iter: 0928/1584
[A[ATraining Step: 730  | total loss: [1m[32m0.26459[0m[0m | time: 31.644s
[2K
| RMSProp | epoch: 015 | loss: 0.26459 - acc: 0.8877 -- iter: 0960/1584
[A[ATraining Step: 731  | total loss: [1m[32m0.28432[0m[0m | time: 32.699s
[2K
| RMSProp | epoch: 015 | loss: 0.28432 - acc: 0.8802 -- iter: 0992/1584
[A[ATraining Step: 732  | total loss: [1m[32m0.28681[0m[0m | time: 33.772s
[2K
| RMSProp | epoch: 015 | loss: 0.28681 - acc: 0.8797 -- iter: 1024/1584
[A[ATraining Step: 733  | total loss: [1m[32m0.33251[0m[0m | time: 35.030s
[2K
| RMSProp | epoch: 015 | loss: 0.33251 - acc: 0.8636 -- iter: 1056/1584
[A[ATraining Step: 734  | total loss: [1m[32m0.33155[0m[0m | time: 36.306s
[2K
| RMSProp | epoch: 015 | loss: 0.33155 - acc: 0.8679 -- iter: 1088/1584
[A[ATraining Step: 735  | total loss: [1m[32m0.33061[0m[0m | time: 37.477s
[2K
| RMSProp | epoch: 015 | loss: 0.33061 - acc: 0.8623 -- iter: 1120/1584
[A[ATraining Step: 736  | total loss: [1m[32m0.31894[0m[0m | time: 38.352s
[2K
| RMSProp | epoch: 015 | loss: 0.31894 - acc: 0.8698 -- iter: 1152/1584
[A[ATraining Step: 737  | total loss: [1m[32m0.30203[0m[0m | time: 39.324s
[2K
| RMSProp | epoch: 015 | loss: 0.30203 - acc: 0.8766 -- iter: 1184/1584
[A[ATraining Step: 738  | total loss: [1m[32m0.28582[0m[0m | time: 40.372s
[2K
| RMSProp | epoch: 015 | loss: 0.28582 - acc: 0.8858 -- iter: 1216/1584
[A[ATraining Step: 739  | total loss: [1m[32m0.27666[0m[0m | time: 41.554s
[2K
| RMSProp | epoch: 015 | loss: 0.27666 - acc: 0.8910 -- iter: 1248/1584
[A[ATraining Step: 740  | total loss: [1m[32m0.27068[0m[0m | time: 42.456s
[2K
| RMSProp | epoch: 015 | loss: 0.27068 - acc: 0.8925 -- iter: 1280/1584
[A[ATraining Step: 741  | total loss: [1m[32m0.28244[0m[0m | time: 43.367s
[2K
| RMSProp | epoch: 015 | loss: 0.28244 - acc: 0.8845 -- iter: 1312/1584
[A[ATraining Step: 742  | total loss: [1m[32m0.28789[0m[0m | time: 44.408s
[2K
| RMSProp | epoch: 015 | loss: 0.28789 - acc: 0.8836 -- iter: 1344/1584
[A[ATraining Step: 743  | total loss: [1m[32m0.27648[0m[0m | time: 45.525s
[2K
| RMSProp | epoch: 015 | loss: 0.27648 - acc: 0.8827 -- iter: 1376/1584
[A[ATraining Step: 744  | total loss: [1m[32m0.26483[0m[0m | time: 46.684s
[2K
| RMSProp | epoch: 015 | loss: 0.26483 - acc: 0.8851 -- iter: 1408/1584
[A[ATraining Step: 745  | total loss: [1m[32m0.24806[0m[0m | time: 47.689s
[2K
| RMSProp | epoch: 015 | loss: 0.24806 - acc: 0.8934 -- iter: 1440/1584
[A[ATraining Step: 746  | total loss: [1m[32m0.23347[0m[0m | time: 48.789s
[2K
| RMSProp | epoch: 015 | loss: 0.23347 - acc: 0.9010 -- iter: 1472/1584
[A[ATraining Step: 747  | total loss: [1m[32m0.22401[0m[0m | time: 50.042s
[2K
| RMSProp | epoch: 015 | loss: 0.22401 - acc: 0.9046 -- iter: 1504/1584
[A[ATraining Step: 748  | total loss: [1m[32m0.21197[0m[0m | time: 51.253s
[2K
| RMSProp | epoch: 015 | loss: 0.21197 - acc: 0.9079 -- iter: 1536/1584
[A[ATraining Step: 749  | total loss: [1m[32m0.21193[0m[0m | time: 52.332s
[2K
| RMSProp | epoch: 015 | loss: 0.21193 - acc: 0.9109 -- iter: 1568/1584
[A[ATraining Step: 750  | total loss: [1m[32m0.22335[0m[0m | time: 56.203s
[2K
| RMSProp | epoch: 015 | loss: 0.22335 - acc: 0.9073 | val_loss: 0.53140 - val_acc: 0.7520 -- iter: 1584/1584
--
Training Step: 751  | total loss: [1m[32m0.26528[0m[0m | time: 1.262s
[2K
| RMSProp | epoch: 016 | loss: 0.26528 - acc: 0.8978 -- iter: 0032/1584
[A[ATraining Step: 752  | total loss: [1m[32m0.25819[0m[0m | time: 2.174s
[2K
| RMSProp | epoch: 016 | loss: 0.25819 - acc: 0.8986 -- iter: 0064/1584
[A[ATraining Step: 753  | total loss: [1m[32m0.25367[0m[0m | time: 3.030s
[2K
| RMSProp | epoch: 016 | loss: 0.25367 - acc: 0.8994 -- iter: 0096/1584
[A[ATraining Step: 754  | total loss: [1m[32m0.24529[0m[0m | time: 3.918s
[2K
| RMSProp | epoch: 016 | loss: 0.24529 - acc: 0.9032 -- iter: 0128/1584
[A[ATraining Step: 755  | total loss: [1m[32m0.23044[0m[0m | time: 4.984s
[2K
| RMSProp | epoch: 016 | loss: 0.23044 - acc: 0.9098 -- iter: 0160/1584
[A[ATraining Step: 756  | total loss: [1m[32m0.23720[0m[0m | time: 6.097s
[2K
| RMSProp | epoch: 016 | loss: 0.23720 - acc: 0.9032 -- iter: 0192/1584
[A[ATraining Step: 757  | total loss: [1m[32m0.22579[0m[0m | time: 7.213s
[2K
| RMSProp | epoch: 016 | loss: 0.22579 - acc: 0.9097 -- iter: 0224/1584
[A[ATraining Step: 758  | total loss: [1m[32m0.22238[0m[0m | time: 8.427s
[2K
| RMSProp | epoch: 016 | loss: 0.22238 - acc: 0.9125 -- iter: 0256/1584
[A[ATraining Step: 759  | total loss: [1m[32m0.20802[0m[0m | time: 9.432s
[2K
| RMSProp | epoch: 016 | loss: 0.20802 - acc: 0.9181 -- iter: 0288/1584
[A[ATraining Step: 760  | total loss: [1m[32m0.21092[0m[0m | time: 10.340s
[2K
| RMSProp | epoch: 016 | loss: 0.21092 - acc: 0.9169 -- iter: 0320/1584
[A[ATraining Step: 761  | total loss: [1m[32m0.20122[0m[0m | time: 11.369s
[2K
| RMSProp | epoch: 016 | loss: 0.20122 - acc: 0.9190 -- iter: 0352/1584
[A[ATraining Step: 762  | total loss: [1m[32m0.21343[0m[0m | time: 12.447s
[2K
| RMSProp | epoch: 016 | loss: 0.21343 - acc: 0.9115 -- iter: 0384/1584
[A[ATraining Step: 763  | total loss: [1m[32m0.25289[0m[0m | time: 13.606s
[2K
| RMSProp | epoch: 016 | loss: 0.25289 - acc: 0.8984 -- iter: 0416/1584
[A[ATraining Step: 764  | total loss: [1m[32m0.24260[0m[0m | time: 14.108s
[2K
| RMSProp | epoch: 016 | loss: 0.24260 - acc: 0.9086 -- iter: 0448/1584
[A[ATraining Step: 765  | total loss: [1m[32m0.22379[0m[0m | time: 14.740s
[2K
| RMSProp | epoch: 016 | loss: 0.22379 - acc: 0.9177 -- iter: 0480/1584
[A[ATraining Step: 766  | total loss: [1m[32m0.20378[0m[0m | time: 15.876s
[2K
| RMSProp | epoch: 016 | loss: 0.20378 - acc: 0.9260 -- iter: 0512/1584
[A[ATraining Step: 767  | total loss: [1m[32m0.20256[0m[0m | time: 16.946s
[2K
| RMSProp | epoch: 016 | loss: 0.20256 - acc: 0.9271 -- iter: 0544/1584
[A[ATraining Step: 768  | total loss: [1m[32m0.19549[0m[0m | time: 18.060s
[2K
| RMSProp | epoch: 016 | loss: 0.19549 - acc: 0.9313 -- iter: 0576/1584
[A[ATraining Step: 769  | total loss: [1m[32m0.24359[0m[0m | time: 19.314s
[2K
| RMSProp | epoch: 016 | loss: 0.24359 - acc: 0.9163 -- iter: 0608/1584
[A[ATraining Step: 770  | total loss: [1m[32m0.24079[0m[0m | time: 20.124s
[2K
| RMSProp | epoch: 016 | loss: 0.24079 - acc: 0.9153 -- iter: 0640/1584
[A[ATraining Step: 771  | total loss: [1m[32m0.25425[0m[0m | time: 21.125s
[2K
| RMSProp | epoch: 016 | loss: 0.25425 - acc: 0.9113 -- iter: 0672/1584
[A[ATraining Step: 772  | total loss: [1m[32m0.24266[0m[0m | time: 22.166s
[2K
| RMSProp | epoch: 016 | loss: 0.24266 - acc: 0.9170 -- iter: 0704/1584
[A[ATraining Step: 773  | total loss: [1m[32m0.23342[0m[0m | time: 23.354s
[2K
| RMSProp | epoch: 016 | loss: 0.23342 - acc: 0.9222 -- iter: 0736/1584
[A[ATraining Step: 774  | total loss: [1m[32m0.23125[0m[0m | time: 24.249s
[2K
| RMSProp | epoch: 016 | loss: 0.23125 - acc: 0.9206 -- iter: 0768/1584
[A[ATraining Step: 775  | total loss: [1m[32m0.24264[0m[0m | time: 25.211s
[2K
| RMSProp | epoch: 016 | loss: 0.24264 - acc: 0.9223 -- iter: 0800/1584
[A[ATraining Step: 776  | total loss: [1m[32m0.23325[0m[0m | time: 26.241s
[2K
| RMSProp | epoch: 016 | loss: 0.23325 - acc: 0.9238 -- iter: 0832/1584
[A[ATraining Step: 777  | total loss: [1m[32m0.22796[0m[0m | time: 27.349s
[2K
| RMSProp | epoch: 016 | loss: 0.22796 - acc: 0.9252 -- iter: 0864/1584
[A[ATraining Step: 778  | total loss: [1m[32m0.22702[0m[0m | time: 28.629s
[2K
| RMSProp | epoch: 016 | loss: 0.22702 - acc: 0.9233 -- iter: 0896/1584
[A[ATraining Step: 779  | total loss: [1m[32m0.22224[0m[0m | time: 29.802s
[2K
| RMSProp | epoch: 016 | loss: 0.22224 - acc: 0.9216 -- iter: 0928/1584
[A[ATraining Step: 780  | total loss: [1m[32m0.22673[0m[0m | time: 30.922s
[2K
| RMSProp | epoch: 016 | loss: 0.22673 - acc: 0.9169 -- iter: 0960/1584
[A[ATraining Step: 781  | total loss: [1m[32m0.23142[0m[0m | time: 32.002s
[2K
| RMSProp | epoch: 016 | loss: 0.23142 - acc: 0.9127 -- iter: 0992/1584
[A[ATraining Step: 782  | total loss: [1m[32m0.23372[0m[0m | time: 33.217s
[2K
| RMSProp | epoch: 016 | loss: 0.23372 - acc: 0.9121 -- iter: 1024/1584
[A[ATraining Step: 783  | total loss: [1m[32m0.22651[0m[0m | time: 34.299s
[2K
| RMSProp | epoch: 016 | loss: 0.22651 - acc: 0.9115 -- iter: 1056/1584
[A[ATraining Step: 784  | total loss: [1m[32m0.22261[0m[0m | time: 35.288s
[2K
| RMSProp | epoch: 016 | loss: 0.22261 - acc: 0.9172 -- iter: 1088/1584
[A[ATraining Step: 785  | total loss: [1m[32m0.22523[0m[0m | time: 36.522s
[2K
| RMSProp | epoch: 016 | loss: 0.22523 - acc: 0.9161 -- iter: 1120/1584
[A[ATraining Step: 786  | total loss: [1m[32m0.22548[0m[0m | time: 37.772s
[2K
| RMSProp | epoch: 016 | loss: 0.22548 - acc: 0.9151 -- iter: 1152/1584
[A[ATraining Step: 787  | total loss: [1m[32m0.20918[0m[0m | time: 38.839s
[2K
| RMSProp | epoch: 016 | loss: 0.20918 - acc: 0.9236 -- iter: 1184/1584
[A[ATraining Step: 788  | total loss: [1m[32m0.19896[0m[0m | time: 39.554s
[2K
| RMSProp | epoch: 016 | loss: 0.19896 - acc: 0.9281 -- iter: 1216/1584
[A[ATraining Step: 789  | total loss: [1m[32m0.19791[0m[0m | time: 40.406s
[2K
| RMSProp | epoch: 016 | loss: 0.19791 - acc: 0.9259 -- iter: 1248/1584
[A[ATraining Step: 790  | total loss: [1m[32m0.20160[0m[0m | time: 41.450s
[2K
| RMSProp | epoch: 016 | loss: 0.20160 - acc: 0.9240 -- iter: 1280/1584
[A[ATraining Step: 791  | total loss: [1m[32m0.20892[0m[0m | time: 42.655s
[2K
| RMSProp | epoch: 016 | loss: 0.20892 - acc: 0.9191 -- iter: 1312/1584
[A[ATraining Step: 792  | total loss: [1m[32m0.21061[0m[0m | time: 43.733s
[2K
| RMSProp | epoch: 016 | loss: 0.21061 - acc: 0.9147 -- iter: 1344/1584
[A[ATraining Step: 793  | total loss: [1m[32m0.20831[0m[0m | time: 44.860s
[2K
| RMSProp | epoch: 016 | loss: 0.20831 - acc: 0.9170 -- iter: 1376/1584
[A[ATraining Step: 794  | total loss: [1m[32m0.20148[0m[0m | time: 46.020s
[2K
| RMSProp | epoch: 016 | loss: 0.20148 - acc: 0.9190 -- iter: 1408/1584
[A[ATraining Step: 795  | total loss: [1m[32m0.19435[0m[0m | time: 47.125s
[2K
| RMSProp | epoch: 016 | loss: 0.19435 - acc: 0.9209 -- iter: 1440/1584
[A[ATraining Step: 796  | total loss: [1m[32m0.18833[0m[0m | time: 48.432s
[2K
| RMSProp | epoch: 016 | loss: 0.18833 - acc: 0.9225 -- iter: 1472/1584
[A[ATraining Step: 797  | total loss: [1m[32m0.17790[0m[0m | time: 49.422s
[2K
| RMSProp | epoch: 016 | loss: 0.17790 - acc: 0.9271 -- iter: 1504/1584
[A[ATraining Step: 798  | total loss: [1m[32m0.16937[0m[0m | time: 50.603s
[2K
| RMSProp | epoch: 016 | loss: 0.16937 - acc: 0.9344 -- iter: 1536/1584
[A[ATraining Step: 799  | total loss: [1m[32m0.18773[0m[0m | time: 51.818s
[2K
| RMSProp | epoch: 016 | loss: 0.18773 - acc: 0.9254 -- iter: 1568/1584
[A[ATraining Step: 800  | total loss: [1m[32m0.18261[0m[0m | time: 55.587s
[2K
| RMSProp | epoch: 016 | loss: 0.18261 - acc: 0.9297 | val_loss: 0.62471 - val_acc: 0.7742 -- iter: 1584/1584
--
Training Step: 801  | total loss: [1m[32m0.19359[0m[0m | time: 1.042s
[2K
| RMSProp | epoch: 017 | loss: 0.19359 - acc: 0.9242 -- iter: 0032/1584
[A[ATraining Step: 802  | total loss: [1m[32m0.20562[0m[0m | time: 2.055s
[2K
| RMSProp | epoch: 017 | loss: 0.20562 - acc: 0.9193 -- iter: 0064/1584
[A[ATraining Step: 803  | total loss: [1m[32m0.19480[0m[0m | time: 3.030s
[2K
| RMSProp | epoch: 017 | loss: 0.19480 - acc: 0.9274 -- iter: 0096/1584
[A[ATraining Step: 804  | total loss: [1m[32m0.18665[0m[0m | time: 4.120s
[2K
| RMSProp | epoch: 017 | loss: 0.18665 - acc: 0.9346 -- iter: 0128/1584
[A[ATraining Step: 805  | total loss: [1m[32m0.17394[0m[0m | time: 5.177s
[2K
| RMSProp | epoch: 017 | loss: 0.17394 - acc: 0.9412 -- iter: 0160/1584
[A[ATraining Step: 806  | total loss: [1m[32m0.16459[0m[0m | time: 6.306s
[2K
| RMSProp | epoch: 017 | loss: 0.16459 - acc: 0.9439 -- iter: 0192/1584
[A[ATraining Step: 807  | total loss: [1m[32m0.15647[0m[0m | time: 7.343s
[2K
| RMSProp | epoch: 017 | loss: 0.15647 - acc: 0.9433 -- iter: 0224/1584
[A[ATraining Step: 808  | total loss: [1m[32m0.15886[0m[0m | time: 8.444s
[2K
| RMSProp | epoch: 017 | loss: 0.15886 - acc: 0.9396 -- iter: 0256/1584
[A[ATraining Step: 809  | total loss: [1m[32m0.18483[0m[0m | time: 9.615s
[2K
| RMSProp | epoch: 017 | loss: 0.18483 - acc: 0.9269 -- iter: 0288/1584
[A[ATraining Step: 810  | total loss: [1m[32m0.17530[0m[0m | time: 10.797s
[2K
| RMSProp | epoch: 017 | loss: 0.17530 - acc: 0.9311 -- iter: 0320/1584
[A[ATraining Step: 811  | total loss: [1m[32m0.16244[0m[0m | time: 11.840s
[2K
| RMSProp | epoch: 017 | loss: 0.16244 - acc: 0.9348 -- iter: 0352/1584
[A[ATraining Step: 812  | total loss: [1m[32m0.15012[0m[0m | time: 12.705s
[2K
| RMSProp | epoch: 017 | loss: 0.15012 - acc: 0.9413 -- iter: 0384/1584
[A[ATraining Step: 813  | total loss: [1m[32m0.15418[0m[0m | time: 13.671s
[2K
| RMSProp | epoch: 017 | loss: 0.15418 - acc: 0.9410 -- iter: 0416/1584
[A[ATraining Step: 814  | total loss: [1m[32m0.15046[0m[0m | time: 14.951s
[2K
| RMSProp | epoch: 017 | loss: 0.15046 - acc: 0.9406 -- iter: 0448/1584
[A[ATraining Step: 815  | total loss: [1m[32m0.15805[0m[0m | time: 15.421s
[2K
| RMSProp | epoch: 017 | loss: 0.15805 - acc: 0.9372 -- iter: 0480/1584
[A[ATraining Step: 816  | total loss: [1m[32m0.19710[0m[0m | time: 15.884s
[2K
| RMSProp | epoch: 017 | loss: 0.19710 - acc: 0.9185 -- iter: 0512/1584
[A[ATraining Step: 817  | total loss: [1m[32m0.18219[0m[0m | time: 16.794s
[2K
| RMSProp | epoch: 017 | loss: 0.18219 - acc: 0.9266 -- iter: 0544/1584
[A[ATraining Step: 818  | total loss: [1m[32m0.16998[0m[0m | time: 17.853s
[2K
| RMSProp | epoch: 017 | loss: 0.16998 - acc: 0.9340 -- iter: 0576/1584
[A[ATraining Step: 819  | total loss: [1m[32m0.15631[0m[0m | time: 18.995s
[2K
| RMSProp | epoch: 017 | loss: 0.15631 - acc: 0.9406 -- iter: 0608/1584
[A[ATraining Step: 820  | total loss: [1m[32m0.15198[0m[0m | time: 20.023s
[2K
| RMSProp | epoch: 017 | loss: 0.15198 - acc: 0.9403 -- iter: 0640/1584
[A[ATraining Step: 821  | total loss: [1m[32m0.15796[0m[0m | time: 21.040s
[2K
| RMSProp | epoch: 017 | loss: 0.15796 - acc: 0.9400 -- iter: 0672/1584
[A[ATraining Step: 822  | total loss: [1m[32m0.17173[0m[0m | time: 22.092s
[2K
| RMSProp | epoch: 017 | loss: 0.17173 - acc: 0.9366 -- iter: 0704/1584
[A[ATraining Step: 823  | total loss: [1m[32m0.16381[0m[0m | time: 23.236s
[2K
| RMSProp | epoch: 017 | loss: 0.16381 - acc: 0.9398 -- iter: 0736/1584
[A[ATraining Step: 824  | total loss: [1m[32m0.15083[0m[0m | time: 24.370s
[2K
| RMSProp | epoch: 017 | loss: 0.15083 - acc: 0.9458 -- iter: 0768/1584
[A[ATraining Step: 825  | total loss: [1m[32m0.14430[0m[0m | time: 25.551s
[2K
| RMSProp | epoch: 017 | loss: 0.14430 - acc: 0.9481 -- iter: 0800/1584
[A[ATraining Step: 826  | total loss: [1m[32m0.14408[0m[0m | time: 26.685s
[2K
| RMSProp | epoch: 017 | loss: 0.14408 - acc: 0.9502 -- iter: 0832/1584
[A[ATraining Step: 827  | total loss: [1m[32m0.13409[0m[0m | time: 27.604s
[2K
| RMSProp | epoch: 017 | loss: 0.13409 - acc: 0.9552 -- iter: 0864/1584
[A[ATraining Step: 828  | total loss: [1m[32m0.14086[0m[0m | time: 28.603s
[2K
| RMSProp | epoch: 017 | loss: 0.14086 - acc: 0.9534 -- iter: 0896/1584
[A[ATraining Step: 829  | total loss: [1m[32m0.18433[0m[0m | time: 29.670s
[2K
| RMSProp | epoch: 017 | loss: 0.18433 - acc: 0.9393 -- iter: 0928/1584
[A[ATraining Step: 830  | total loss: [1m[32m0.17309[0m[0m | time: 30.702s
[2K
| RMSProp | epoch: 017 | loss: 0.17309 - acc: 0.9454 -- iter: 0960/1584
[A[ATraining Step: 831  | total loss: [1m[32m0.16433[0m[0m | time: 31.858s
[2K
| RMSProp | epoch: 017 | loss: 0.16433 - acc: 0.9508 -- iter: 0992/1584
[A[ATraining Step: 832  | total loss: [1m[32m0.18140[0m[0m | time: 32.758s
[2K
| RMSProp | epoch: 017 | loss: 0.18140 - acc: 0.9433 -- iter: 1024/1584
[A[ATraining Step: 833  | total loss: [1m[32m0.17605[0m[0m | time: 33.624s
[2K
| RMSProp | epoch: 017 | loss: 0.17605 - acc: 0.9427 -- iter: 1056/1584
[A[ATraining Step: 834  | total loss: [1m[32m0.16936[0m[0m | time: 34.504s
[2K
| RMSProp | epoch: 017 | loss: 0.16936 - acc: 0.9422 -- iter: 1088/1584
[A[ATraining Step: 835  | total loss: [1m[32m0.17229[0m[0m | time: 35.560s
[2K
| RMSProp | epoch: 017 | loss: 0.17229 - acc: 0.9417 -- iter: 1120/1584
[A[ATraining Step: 836  | total loss: [1m[32m0.15793[0m[0m | time: 36.567s
[2K
| RMSProp | epoch: 017 | loss: 0.15793 - acc: 0.9475 -- iter: 1152/1584
[A[ATraining Step: 837  | total loss: [1m[32m0.14576[0m[0m | time: 37.590s
[2K
| RMSProp | epoch: 017 | loss: 0.14576 - acc: 0.9528 -- iter: 1184/1584
[A[ATraining Step: 838  | total loss: [1m[32m0.14497[0m[0m | time: 38.650s
[2K
| RMSProp | epoch: 017 | loss: 0.14497 - acc: 0.9512 -- iter: 1216/1584
[A[ATraining Step: 839  | total loss: [1m[32m0.13965[0m[0m | time: 39.829s
[2K
| RMSProp | epoch: 017 | loss: 0.13965 - acc: 0.9530 -- iter: 1248/1584
[A[ATraining Step: 840  | total loss: [1m[32m0.13011[0m[0m | time: 41.114s
[2K
| RMSProp | epoch: 017 | loss: 0.13011 - acc: 0.9577 -- iter: 1280/1584
[A[ATraining Step: 841  | total loss: [1m[32m0.12077[0m[0m | time: 42.107s
[2K
| RMSProp | epoch: 017 | loss: 0.12077 - acc: 0.9619 -- iter: 1312/1584
[A[ATraining Step: 842  | total loss: [1m[32m0.11640[0m[0m | time: 43.084s
[2K
| RMSProp | epoch: 017 | loss: 0.11640 - acc: 0.9626 -- iter: 1344/1584
[A[ATraining Step: 843  | total loss: [1m[32m0.11746[0m[0m | time: 44.087s
[2K
| RMSProp | epoch: 017 | loss: 0.11746 - acc: 0.9632 -- iter: 1376/1584
[A[ATraining Step: 844  | total loss: [1m[32m0.12563[0m[0m | time: 45.207s
[2K
| RMSProp | epoch: 017 | loss: 0.12563 - acc: 0.9638 -- iter: 1408/1584
[A[ATraining Step: 845  | total loss: [1m[32m0.12077[0m[0m | time: 46.248s
[2K
| RMSProp | epoch: 017 | loss: 0.12077 - acc: 0.9643 -- iter: 1440/1584
[A[ATraining Step: 846  | total loss: [1m[32m0.11408[0m[0m | time: 47.337s
[2K
| RMSProp | epoch: 017 | loss: 0.11408 - acc: 0.9678 -- iter: 1472/1584
[A[ATraining Step: 847  | total loss: [1m[32m0.10885[0m[0m | time: 48.418s
[2K
| RMSProp | epoch: 017 | loss: 0.10885 - acc: 0.9711 -- iter: 1504/1584
[A[ATraining Step: 848  | total loss: [1m[32m0.10639[0m[0m | time: 49.614s
[2K
| RMSProp | epoch: 017 | loss: 0.10639 - acc: 0.9708 -- iter: 1536/1584
[A[ATraining Step: 849  | total loss: [1m[32m0.09926[0m[0m | time: 50.494s
[2K
| RMSProp | epoch: 017 | loss: 0.09926 - acc: 0.9737 -- iter: 1568/1584
[A[ATraining Step: 850  | total loss: [1m[32m0.09298[0m[0m | time: 54.112s
[2K
| RMSProp | epoch: 017 | loss: 0.09298 - acc: 0.9764 | val_loss: 0.64692 - val_acc: 0.7923 -- iter: 1584/1584
--
Training Step: 851  | total loss: [1m[32m0.09802[0m[0m | time: 1.052s
[2K
| RMSProp | epoch: 018 | loss: 0.09802 - acc: 0.9694 -- iter: 0032/1584
[A[ATraining Step: 852  | total loss: [1m[32m0.09649[0m[0m | time: 2.108s
[2K
| RMSProp | epoch: 018 | loss: 0.09649 - acc: 0.9693 -- iter: 0064/1584
[A[ATraining Step: 853  | total loss: [1m[32m0.09696[0m[0m | time: 3.178s
[2K
| RMSProp | epoch: 018 | loss: 0.09696 - acc: 0.9692 -- iter: 0096/1584
[A[ATraining Step: 854  | total loss: [1m[32m0.09958[0m[0m | time: 4.248s
[2K
| RMSProp | epoch: 018 | loss: 0.09958 - acc: 0.9661 -- iter: 0128/1584
[A[ATraining Step: 855  | total loss: [1m[32m0.13276[0m[0m | time: 5.334s
[2K
| RMSProp | epoch: 018 | loss: 0.13276 - acc: 0.9601 -- iter: 0160/1584
[A[ATraining Step: 856  | total loss: [1m[32m0.13527[0m[0m | time: 6.453s
[2K
| RMSProp | epoch: 018 | loss: 0.13527 - acc: 0.9578 -- iter: 0192/1584
[A[ATraining Step: 857  | total loss: [1m[32m0.13437[0m[0m | time: 7.532s
[2K
| RMSProp | epoch: 018 | loss: 0.13437 - acc: 0.9589 -- iter: 0224/1584
[A[ATraining Step: 858  | total loss: [1m[32m0.12987[0m[0m | time: 8.745s
[2K
| RMSProp | epoch: 018 | loss: 0.12987 - acc: 0.9568 -- iter: 0256/1584
[A[ATraining Step: 859  | total loss: [1m[32m0.13334[0m[0m | time: 9.582s
[2K
| RMSProp | epoch: 018 | loss: 0.13334 - acc: 0.9580 -- iter: 0288/1584
[A[ATraining Step: 860  | total loss: [1m[32m0.12624[0m[0m | time: 10.591s
[2K
| RMSProp | epoch: 018 | loss: 0.12624 - acc: 0.9622 -- iter: 0320/1584
[A[ATraining Step: 861  | total loss: [1m[32m0.11904[0m[0m | time: 11.605s
[2K
| RMSProp | epoch: 018 | loss: 0.11904 - acc: 0.9660 -- iter: 0352/1584
[A[ATraining Step: 862  | total loss: [1m[32m0.12513[0m[0m | time: 12.546s
[2K
| RMSProp | epoch: 018 | loss: 0.12513 - acc: 0.9631 -- iter: 0384/1584
[A[ATraining Step: 863  | total loss: [1m[32m0.16542[0m[0m | time: 13.425s
[2K
| RMSProp | epoch: 018 | loss: 0.16542 - acc: 0.9387 -- iter: 0416/1584
[A[ATraining Step: 864  | total loss: [1m[32m0.15481[0m[0m | time: 14.497s
[2K
| RMSProp | epoch: 018 | loss: 0.15481 - acc: 0.9417 -- iter: 0448/1584
[A[ATraining Step: 865  | total loss: [1m[32m0.14179[0m[0m | time: 15.568s
[2K
| RMSProp | epoch: 018 | loss: 0.14179 - acc: 0.9475 -- iter: 0480/1584
[A[ATraining Step: 866  | total loss: [1m[32m0.13259[0m[0m | time: 16.088s
[2K
| RMSProp | epoch: 018 | loss: 0.13259 - acc: 0.9496 -- iter: 0512/1584
[A[ATraining Step: 867  | total loss: [1m[32m0.12346[0m[0m | time: 16.649s
[2K
| RMSProp | epoch: 018 | loss: 0.12346 - acc: 0.9547 -- iter: 0544/1584
[A[ATraining Step: 868  | total loss: [1m[32m0.11179[0m[0m | time: 17.674s
[2K
| RMSProp | epoch: 018 | loss: 0.11179 - acc: 0.9592 -- iter: 0576/1584
[A[ATraining Step: 869  | total loss: [1m[32m0.10351[0m[0m | time: 18.749s
[2K
| RMSProp | epoch: 018 | loss: 0.10351 - acc: 0.9633 -- iter: 0608/1584
[A[ATraining Step: 870  | total loss: [1m[32m0.09837[0m[0m | time: 20.010s
[2K
| RMSProp | epoch: 018 | loss: 0.09837 - acc: 0.9638 -- iter: 0640/1584
[A[ATraining Step: 871  | total loss: [1m[32m0.09137[0m[0m | time: 21.155s
[2K
| RMSProp | epoch: 018 | loss: 0.09137 - acc: 0.9675 -- iter: 0672/1584
[A[ATraining Step: 872  | total loss: [1m[32m0.08549[0m[0m | time: 22.297s
[2K
| RMSProp | epoch: 018 | loss: 0.08549 - acc: 0.9707 -- iter: 0704/1584
[A[ATraining Step: 873  | total loss: [1m[32m0.10071[0m[0m | time: 23.395s
[2K
| RMSProp | epoch: 018 | loss: 0.10071 - acc: 0.9705 -- iter: 0736/1584
[A[ATraining Step: 874  | total loss: [1m[32m0.09397[0m[0m | time: 24.546s
[2K
| RMSProp | epoch: 018 | loss: 0.09397 - acc: 0.9735 -- iter: 0768/1584
[A[ATraining Step: 875  | total loss: [1m[32m0.09534[0m[0m | time: 25.843s
[2K
| RMSProp | epoch: 018 | loss: 0.09534 - acc: 0.9699 -- iter: 0800/1584
[A[ATraining Step: 876  | total loss: [1m[32m0.08986[0m[0m | time: 27.266s
[2K
| RMSProp | epoch: 018 | loss: 0.08986 - acc: 0.9729 -- iter: 0832/1584
[A[ATraining Step: 877  | total loss: [1m[32m0.08184[0m[0m | time: 28.119s
[2K
| RMSProp | epoch: 018 | loss: 0.08184 - acc: 0.9756 -- iter: 0864/1584
[A[ATraining Step: 878  | total loss: [1m[32m0.08559[0m[0m | time: 28.964s
[2K
| RMSProp | epoch: 018 | loss: 0.08559 - acc: 0.9718 -- iter: 0896/1584
[A[ATraining Step: 879  | total loss: [1m[32m0.13368[0m[0m | time: 29.956s
[2K
| RMSProp | epoch: 018 | loss: 0.13368 - acc: 0.9590 -- iter: 0928/1584
[A[ATraining Step: 880  | total loss: [1m[32m0.12451[0m[0m | time: 31.106s
[2K
| RMSProp | epoch: 018 | loss: 0.12451 - acc: 0.9631 -- iter: 0960/1584
[A[ATraining Step: 881  | total loss: [1m[32m0.13075[0m[0m | time: 32.162s
[2K
| RMSProp | epoch: 018 | loss: 0.13075 - acc: 0.9636 -- iter: 0992/1584
[A[ATraining Step: 882  | total loss: [1m[32m0.12963[0m[0m | time: 33.201s
[2K
| RMSProp | epoch: 018 | loss: 0.12963 - acc: 0.9642 -- iter: 1024/1584
[A[ATraining Step: 883  | total loss: [1m[32m0.12611[0m[0m | time: 34.275s
[2K
| RMSProp | epoch: 018 | loss: 0.12611 - acc: 0.9646 -- iter: 1056/1584
[A[ATraining Step: 884  | total loss: [1m[32m0.13952[0m[0m | time: 35.320s
[2K
| RMSProp | epoch: 018 | loss: 0.13952 - acc: 0.9588 -- iter: 1088/1584
[A[ATraining Step: 885  | total loss: [1m[32m0.14203[0m[0m | time: 36.399s
[2K
| RMSProp | epoch: 018 | loss: 0.14203 - acc: 0.9567 -- iter: 1120/1584
[A[ATraining Step: 886  | total loss: [1m[32m0.14421[0m[0m | time: 37.460s
[2K
| RMSProp | epoch: 018 | loss: 0.14421 - acc: 0.9485 -- iter: 1152/1584
[A[ATraining Step: 887  | total loss: [1m[32m0.13208[0m[0m | time: 38.487s
[2K
| RMSProp | epoch: 018 | loss: 0.13208 - acc: 0.9536 -- iter: 1184/1584
[A[ATraining Step: 888  | total loss: [1m[32m0.12103[0m[0m | time: 39.728s
[2K
| RMSProp | epoch: 018 | loss: 0.12103 - acc: 0.9583 -- iter: 1216/1584
[A[ATraining Step: 889  | total loss: [1m[32m0.11103[0m[0m | time: 40.882s
[2K
| RMSProp | epoch: 018 | loss: 0.11103 - acc: 0.9624 -- iter: 1248/1584
[A[ATraining Step: 890  | total loss: [1m[32m0.10086[0m[0m | time: 42.089s
[2K
| RMSProp | epoch: 018 | loss: 0.10086 - acc: 0.9662 -- iter: 1280/1584
[A[ATraining Step: 891  | total loss: [1m[32m0.09366[0m[0m | time: 42.936s
[2K
| RMSProp | epoch: 018 | loss: 0.09366 - acc: 0.9696 -- iter: 1312/1584
[A[ATraining Step: 892  | total loss: [1m[32m0.09178[0m[0m | time: 44.020s
[2K
| RMSProp | epoch: 018 | loss: 0.09178 - acc: 0.9695 -- iter: 1344/1584
[A[ATraining Step: 893  | total loss: [1m[32m0.10245[0m[0m | time: 44.877s
[2K
| RMSProp | epoch: 018 | loss: 0.10245 - acc: 0.9663 -- iter: 1376/1584
[A[ATraining Step: 894  | total loss: [1m[32m0.10184[0m[0m | time: 45.771s
[2K
| RMSProp | epoch: 018 | loss: 0.10184 - acc: 0.9634 -- iter: 1408/1584
[A[ATraining Step: 895  | total loss: [1m[32m0.09295[0m[0m | time: 46.660s
[2K
| RMSProp | epoch: 018 | loss: 0.09295 - acc: 0.9671 -- iter: 1440/1584
[A[ATraining Step: 896  | total loss: [1m[32m0.08755[0m[0m | time: 47.691s
[2K
| RMSProp | epoch: 018 | loss: 0.08755 - acc: 0.9672 -- iter: 1472/1584
[A[ATraining Step: 897  | total loss: [1m[32m0.09645[0m[0m | time: 48.787s
[2K
| RMSProp | epoch: 018 | loss: 0.09645 - acc: 0.9674 -- iter: 1504/1584
[A[ATraining Step: 898  | total loss: [1m[32m0.11540[0m[0m | time: 49.888s
[2K
| RMSProp | epoch: 018 | loss: 0.11540 - acc: 0.9519 -- iter: 1536/1584
[A[ATraining Step: 899  | total loss: [1m[32m0.11392[0m[0m | time: 51.067s
[2K
| RMSProp | epoch: 018 | loss: 0.11392 - acc: 0.9505 -- iter: 1568/1584
[A[ATraining Step: 900  | total loss: [1m[32m0.12937[0m[0m | time: 55.178s
[2K
| RMSProp | epoch: 018 | loss: 0.12937 - acc: 0.9460 | val_loss: 0.63067 - val_acc: 0.7843 -- iter: 1584/1584
--
Training Step: 901  | total loss: [1m[32m0.12253[0m[0m | time: 1.024s
[2K
| RMSProp | epoch: 019 | loss: 0.12253 - acc: 0.9483 -- iter: 0032/1584
[A[ATraining Step: 902  | total loss: [1m[32m0.11455[0m[0m | time: 1.956s
[2K
| RMSProp | epoch: 019 | loss: 0.11455 - acc: 0.9535 -- iter: 0064/1584
[A[ATraining Step: 903  | total loss: [1m[32m0.10673[0m[0m | time: 2.989s
[2K
| RMSProp | epoch: 019 | loss: 0.10673 - acc: 0.9581 -- iter: 0096/1584
[A[ATraining Step: 904  | total loss: [1m[32m0.09684[0m[0m | time: 4.079s
[2K
| RMSProp | epoch: 019 | loss: 0.09684 - acc: 0.9623 -- iter: 0128/1584
[A[ATraining Step: 905  | total loss: [1m[32m0.08944[0m[0m | time: 5.210s
[2K
| RMSProp | epoch: 019 | loss: 0.08944 - acc: 0.9661 -- iter: 0160/1584
[A[ATraining Step: 906  | total loss: [1m[32m0.08696[0m[0m | time: 6.075s
[2K
| RMSProp | epoch: 019 | loss: 0.08696 - acc: 0.9664 -- iter: 0192/1584
[A[ATraining Step: 907  | total loss: [1m[32m0.09076[0m[0m | time: 6.977s
[2K
| RMSProp | epoch: 019 | loss: 0.09076 - acc: 0.9635 -- iter: 0224/1584
[A[ATraining Step: 908  | total loss: [1m[32m0.12274[0m[0m | time: 7.830s
[2K
| RMSProp | epoch: 019 | loss: 0.12274 - acc: 0.9546 -- iter: 0256/1584
[A[ATraining Step: 909  | total loss: [1m[32m0.11519[0m[0m | time: 8.998s
[2K
| RMSProp | epoch: 019 | loss: 0.11519 - acc: 0.9592 -- iter: 0288/1584
[A[ATraining Step: 910  | total loss: [1m[32m0.11276[0m[0m | time: 10.115s
[2K
| RMSProp | epoch: 019 | loss: 0.11276 - acc: 0.9601 -- iter: 0320/1584
[A[ATraining Step: 911  | total loss: [1m[32m0.11093[0m[0m | time: 11.183s
[2K
| RMSProp | epoch: 019 | loss: 0.11093 - acc: 0.9610 -- iter: 0352/1584
[A[ATraining Step: 912  | total loss: [1m[32m0.13149[0m[0m | time: 12.461s
[2K
| RMSProp | epoch: 019 | loss: 0.13149 - acc: 0.9586 -- iter: 0384/1584
[A[ATraining Step: 913  | total loss: [1m[32m0.13720[0m[0m | time: 13.748s
[2K
| RMSProp | epoch: 019 | loss: 0.13720 - acc: 0.9471 -- iter: 0416/1584
[A[ATraining Step: 914  | total loss: [1m[32m0.12870[0m[0m | time: 14.878s
[2K
| RMSProp | epoch: 019 | loss: 0.12870 - acc: 0.9524 -- iter: 0448/1584
[A[ATraining Step: 915  | total loss: [1m[32m0.11800[0m[0m | time: 15.787s
[2K
| RMSProp | epoch: 019 | loss: 0.11800 - acc: 0.9572 -- iter: 0480/1584
[A[ATraining Step: 916  | total loss: [1m[32m0.11014[0m[0m | time: 16.782s
[2K
| RMSProp | epoch: 019 | loss: 0.11014 - acc: 0.9583 -- iter: 0512/1584
[A[ATraining Step: 917  | total loss: [1m[32m0.10404[0m[0m | time: 17.411s
[2K
| RMSProp | epoch: 019 | loss: 0.10404 - acc: 0.9594 -- iter: 0544/1584
[A[ATraining Step: 918  | total loss: [1m[32m0.09612[0m[0m | time: 17.937s
[2K
| RMSProp | epoch: 019 | loss: 0.09612 - acc: 0.9634 -- iter: 0576/1584
[A[ATraining Step: 919  | total loss: [1m[32m0.08742[0m[0m | time: 19.084s
[2K
| RMSProp | epoch: 019 | loss: 0.08742 - acc: 0.9671 -- iter: 0608/1584
[A[ATraining Step: 920  | total loss: [1m[32m0.07964[0m[0m | time: 20.192s
[2K
| RMSProp | epoch: 019 | loss: 0.07964 - acc: 0.9704 -- iter: 0640/1584
[A[ATraining Step: 921  | total loss: [1m[32m0.07418[0m[0m | time: 21.232s
[2K
| RMSProp | epoch: 019 | loss: 0.07418 - acc: 0.9734 -- iter: 0672/1584
[A[ATraining Step: 922  | total loss: [1m[32m0.07600[0m[0m | time: 22.334s
[2K
| RMSProp | epoch: 019 | loss: 0.07600 - acc: 0.9698 -- iter: 0704/1584
[A[ATraining Step: 923  | total loss: [1m[32m0.09020[0m[0m | time: 23.389s
[2K
| RMSProp | epoch: 019 | loss: 0.09020 - acc: 0.9665 -- iter: 0736/1584
[A[ATraining Step: 924  | total loss: [1m[32m0.10280[0m[0m | time: 24.294s
[2K
| RMSProp | epoch: 019 | loss: 0.10280 - acc: 0.9574 -- iter: 0768/1584
[A[ATraining Step: 925  | total loss: [1m[32m0.09800[0m[0m | time: 25.154s
[2K
| RMSProp | epoch: 019 | loss: 0.09800 - acc: 0.9585 -- iter: 0800/1584
[A[ATraining Step: 926  | total loss: [1m[32m0.08956[0m[0m | time: 26.152s
[2K
| RMSProp | epoch: 019 | loss: 0.08956 - acc: 0.9627 -- iter: 0832/1584
[A[ATraining Step: 927  | total loss: [1m[32m0.08131[0m[0m | time: 27.388s
[2K
| RMSProp | epoch: 019 | loss: 0.08131 - acc: 0.9664 -- iter: 0864/1584
[A[ATraining Step: 928  | total loss: [1m[32m0.07736[0m[0m | time: 28.632s
[2K
| RMSProp | epoch: 019 | loss: 0.07736 - acc: 0.9666 -- iter: 0896/1584
[A[ATraining Step: 929  | total loss: [1m[32m0.08114[0m[0m | time: 29.738s
[2K
| RMSProp | epoch: 019 | loss: 0.08114 - acc: 0.9637 -- iter: 0928/1584
[A[ATraining Step: 930  | total loss: [1m[32m0.08636[0m[0m | time: 30.609s
[2K
| RMSProp | epoch: 019 | loss: 0.08636 - acc: 0.9642 -- iter: 0960/1584
[A[ATraining Step: 931  | total loss: [1m[32m0.08804[0m[0m | time: 31.661s
[2K
| RMSProp | epoch: 019 | loss: 0.08804 - acc: 0.9647 -- iter: 0992/1584
[A[ATraining Step: 932  | total loss: [1m[32m0.09823[0m[0m | time: 32.722s
[2K
| RMSProp | epoch: 019 | loss: 0.09823 - acc: 0.9651 -- iter: 1024/1584
[A[ATraining Step: 933  | total loss: [1m[32m0.09548[0m[0m | time: 33.733s
[2K
| RMSProp | epoch: 019 | loss: 0.09548 - acc: 0.9655 -- iter: 1056/1584
[A[ATraining Step: 934  | total loss: [1m[32m0.08781[0m[0m | time: 34.782s
[2K
| RMSProp | epoch: 019 | loss: 0.08781 - acc: 0.9689 -- iter: 1088/1584
[A[ATraining Step: 935  | total loss: [1m[32m0.08485[0m[0m | time: 35.852s
[2K
| RMSProp | epoch: 019 | loss: 0.08485 - acc: 0.9689 -- iter: 1120/1584
[A[ATraining Step: 936  | total loss: [1m[32m0.10823[0m[0m | time: 36.877s
[2K
| RMSProp | epoch: 019 | loss: 0.10823 - acc: 0.9595 -- iter: 1152/1584
[A[ATraining Step: 937  | total loss: [1m[32m0.14168[0m[0m | time: 38.021s
[2K
| RMSProp | epoch: 019 | loss: 0.14168 - acc: 0.9542 -- iter: 1184/1584
[A[ATraining Step: 938  | total loss: [1m[32m0.13019[0m[0m | time: 39.044s
[2K
| RMSProp | epoch: 019 | loss: 0.13019 - acc: 0.9588 -- iter: 1216/1584
[A[ATraining Step: 939  | total loss: [1m[32m0.13358[0m[0m | time: 40.179s
[2K
| RMSProp | epoch: 019 | loss: 0.13358 - acc: 0.9598 -- iter: 1248/1584
[A[ATraining Step: 940  | total loss: [1m[32m0.14221[0m[0m | time: 41.064s
[2K
| RMSProp | epoch: 019 | loss: 0.14221 - acc: 0.9607 -- iter: 1280/1584
[A[ATraining Step: 941  | total loss: [1m[32m0.13368[0m[0m | time: 41.960s
[2K
| RMSProp | epoch: 019 | loss: 0.13368 - acc: 0.9646 -- iter: 1312/1584
[A[ATraining Step: 942  | total loss: [1m[32m0.12185[0m[0m | time: 43.080s
[2K
| RMSProp | epoch: 019 | loss: 0.12185 - acc: 0.9681 -- iter: 1344/1584
[A[ATraining Step: 943  | total loss: [1m[32m0.11340[0m[0m | time: 44.295s
[2K
| RMSProp | epoch: 019 | loss: 0.11340 - acc: 0.9713 -- iter: 1376/1584
[A[ATraining Step: 944  | total loss: [1m[32m0.10330[0m[0m | time: 45.425s
[2K
| RMSProp | epoch: 019 | loss: 0.10330 - acc: 0.9742 -- iter: 1408/1584
[A[ATraining Step: 945  | total loss: [1m[32m0.09481[0m[0m | time: 46.330s
[2K
| RMSProp | epoch: 019 | loss: 0.09481 - acc: 0.9768 -- iter: 1440/1584
[A[ATraining Step: 946  | total loss: [1m[32m0.08657[0m[0m | time: 47.303s
[2K
| RMSProp | epoch: 019 | loss: 0.08657 - acc: 0.9791 -- iter: 1472/1584
[A[ATraining Step: 947  | total loss: [1m[32m0.07992[0m[0m | time: 48.342s
[2K
| RMSProp | epoch: 019 | loss: 0.07992 - acc: 0.9812 -- iter: 1504/1584
[A[ATraining Step: 948  | total loss: [1m[32m0.07247[0m[0m | time: 49.364s
[2K
| RMSProp | epoch: 019 | loss: 0.07247 - acc: 0.9831 -- iter: 1536/1584
[A[ATraining Step: 949  | total loss: [1m[32m0.06574[0m[0m | time: 50.480s
[2K
| RMSProp | epoch: 019 | loss: 0.06574 - acc: 0.9848 -- iter: 1568/1584
[A[ATraining Step: 950  | total loss: [1m[32m0.05974[0m[0m | time: 54.474s
[2K
| RMSProp | epoch: 019 | loss: 0.05974 - acc: 0.9863 | val_loss: 0.70198 - val_acc: 0.8044 -- iter: 1584/1584
--
Training Step: 951  | total loss: [1m[32m0.05421[0m[0m | time: 1.016s
[2K
| RMSProp | epoch: 020 | loss: 0.05421 - acc: 0.9877 -- iter: 0032/1584
[A[ATraining Step: 952  | total loss: [1m[32m0.04974[0m[0m | time: 1.716s
[2K
| RMSProp | epoch: 020 | loss: 0.04974 - acc: 0.9889 -- iter: 0064/1584
[A[ATraining Step: 953  | total loss: [1m[32m0.04563[0m[0m | time: 2.752s
[2K
| RMSProp | epoch: 020 | loss: 0.04563 - acc: 0.9900 -- iter: 0096/1584
[A[ATraining Step: 954  | total loss: [1m[32m0.04168[0m[0m | time: 3.839s
[2K
| RMSProp | epoch: 020 | loss: 0.04168 - acc: 0.9910 -- iter: 0128/1584
[A[ATraining Step: 955  | total loss: [1m[32m0.03908[0m[0m | time: 4.932s
[2K
| RMSProp | epoch: 020 | loss: 0.03908 - acc: 0.9919 -- iter: 0160/1584
[A[ATraining Step: 956  | total loss: [1m[32m0.04974[0m[0m | time: 6.006s
[2K
| RMSProp | epoch: 020 | loss: 0.04974 - acc: 0.9865 -- iter: 0192/1584
[A[ATraining Step: 957  | total loss: [1m[32m0.06387[0m[0m | time: 7.093s
[2K
| RMSProp | epoch: 020 | loss: 0.06387 - acc: 0.9753 -- iter: 0224/1584
[A[ATraining Step: 958  | total loss: [1m[32m0.06508[0m[0m | time: 8.168s
[2K
| RMSProp | epoch: 020 | loss: 0.06508 - acc: 0.9747 -- iter: 0256/1584
[A[ATraining Step: 959  | total loss: [1m[32m0.08137[0m[0m | time: 9.247s
[2K
| RMSProp | epoch: 020 | loss: 0.08137 - acc: 0.9741 -- iter: 0288/1584
[A[ATraining Step: 960  | total loss: [1m[32m0.07721[0m[0m | time: 10.430s
[2K
| RMSProp | epoch: 020 | loss: 0.07721 - acc: 0.9767 -- iter: 0320/1584
[A[ATraining Step: 961  | total loss: [1m[32m0.07095[0m[0m | time: 11.466s
[2K
| RMSProp | epoch: 020 | loss: 0.07095 - acc: 0.9790 -- iter: 0352/1584
[A[ATraining Step: 962  | total loss: [1m[32m0.06752[0m[0m | time: 12.468s
[2K
| RMSProp | epoch: 020 | loss: 0.06752 - acc: 0.9780 -- iter: 0384/1584
[A[ATraining Step: 963  | total loss: [1m[32m0.09442[0m[0m | time: 13.675s
[2K
| RMSProp | epoch: 020 | loss: 0.09442 - acc: 0.9739 -- iter: 0416/1584
[A[ATraining Step: 964  | total loss: [1m[32m0.09243[0m[0m | time: 14.868s
[2K
| RMSProp | epoch: 020 | loss: 0.09243 - acc: 0.9734 -- iter: 0448/1584
[A[ATraining Step: 965  | total loss: [1m[32m0.10210[0m[0m | time: 16.059s
[2K
| RMSProp | epoch: 020 | loss: 0.10210 - acc: 0.9729 -- iter: 0480/1584
[A[ATraining Step: 966  | total loss: [1m[32m0.09453[0m[0m | time: 17.053s
[2K
| RMSProp | epoch: 020 | loss: 0.09453 - acc: 0.9756 -- iter: 0512/1584
[A[ATraining Step: 967  | total loss: [1m[32m0.08622[0m[0m | time: 17.935s
[2K
| RMSProp | epoch: 020 | loss: 0.08622 - acc: 0.9781 -- iter: 0544/1584
[A[ATraining Step: 968  | total loss: [1m[32m0.07827[0m[0m | time: 18.420s
[2K
| RMSProp | epoch: 020 | loss: 0.07827 - acc: 0.9803 -- iter: 0576/1584
[A[ATraining Step: 969  | total loss: [1m[32m0.07149[0m[0m | time: 18.952s
[2K
| RMSProp | epoch: 020 | loss: 0.07149 - acc: 0.9822 -- iter: 0608/1584
[A[ATraining Step: 970  | total loss: [1m[32m0.06494[0m[0m | time: 20.111s
[2K
| RMSProp | epoch: 020 | loss: 0.06494 - acc: 0.9840 -- iter: 0640/1584
[A[ATraining Step: 971  | total loss: [1m[32m0.05908[0m[0m | time: 21.336s
[2K
| RMSProp | epoch: 020 | loss: 0.05908 - acc: 0.9856 -- iter: 0672/1584
[A[ATraining Step: 972  | total loss: [1m[32m0.05363[0m[0m | time: 22.603s
[2K
| RMSProp | epoch: 020 | loss: 0.05363 - acc: 0.9871 -- iter: 0704/1584
[A[ATraining Step: 973  | total loss: [1m[32m0.05112[0m[0m | time: 23.844s
[2K
| RMSProp | epoch: 020 | loss: 0.05112 - acc: 0.9884 -- iter: 0736/1584
[A[ATraining Step: 974  | total loss: [1m[32m0.06410[0m[0m | time: 25.050s
[2K
| RMSProp | epoch: 020 | loss: 0.06410 - acc: 0.9833 -- iter: 0768/1584
[A[ATraining Step: 975  | total loss: [1m[32m0.12803[0m[0m | time: 26.160s
[2K
| RMSProp | epoch: 020 | loss: 0.12803 - acc: 0.9662 -- iter: 0800/1584
[A[ATraining Step: 976  | total loss: [1m[32m0.12477[0m[0m | time: 27.210s
[2K
| RMSProp | epoch: 020 | loss: 0.12477 - acc: 0.9664 -- iter: 0832/1584
[A[ATraining Step: 977  | total loss: [1m[32m0.11358[0m[0m | time: 28.484s
[2K
| RMSProp | epoch: 020 | loss: 0.11358 - acc: 0.9698 -- iter: 0864/1584
[A[ATraining Step: 978  | total loss: [1m[32m0.11354[0m[0m | time: 29.615s
[2K
| RMSProp | epoch: 020 | loss: 0.11354 - acc: 0.9634 -- iter: 0896/1584
[A[ATraining Step: 979  | total loss: [1m[32m0.12005[0m[0m | time: 30.661s
[2K
| RMSProp | epoch: 020 | loss: 0.12005 - acc: 0.9577 -- iter: 0928/1584
[A[ATraining Step: 980  | total loss: [1m[32m0.10932[0m[0m | time: 31.635s
[2K
| RMSProp | epoch: 020 | loss: 0.10932 - acc: 0.9620 -- iter: 0960/1584
[A[ATraining Step: 981  | total loss: [1m[32m0.10215[0m[0m | time: 32.618s
[2K
| RMSProp | epoch: 020 | loss: 0.10215 - acc: 0.9658 -- iter: 0992/1584
[A[ATraining Step: 982  | total loss: [1m[32m0.09281[0m[0m | time: 33.791s
[2K
| RMSProp | epoch: 020 | loss: 0.09281 - acc: 0.9692 -- iter: 1024/1584
[A[ATraining Step: 983  | total loss: [1m[32m0.08403[0m[0m | time: 34.697s
[2K
| RMSProp | epoch: 020 | loss: 0.08403 - acc: 0.9723 -- iter: 1056/1584
[A[ATraining Step: 984  | total loss: [1m[32m0.07708[0m[0m | time: 35.588s
[2K
| RMSProp | epoch: 020 | loss: 0.07708 - acc: 0.9750 -- iter: 1088/1584
[A[ATraining Step: 985  | total loss: [1m[32m0.07022[0m[0m | time: 36.711s
[2K
| RMSProp | epoch: 020 | loss: 0.07022 - acc: 0.9775 -- iter: 1120/1584
[A[ATraining Step: 986  | total loss: [1m[32m0.06402[0m[0m | time: 37.783s
[2K
| RMSProp | epoch: 020 | loss: 0.06402 - acc: 0.9798 -- iter: 1152/1584
[A[ATraining Step: 987  | total loss: [1m[32m0.05926[0m[0m | time: 38.891s
[2K
| RMSProp | epoch: 020 | loss: 0.05926 - acc: 0.9818 -- iter: 1184/1584
[A[ATraining Step: 988  | total loss: [1m[32m0.09483[0m[0m | time: 39.964s
[2K
| RMSProp | epoch: 020 | loss: 0.09483 - acc: 0.9742 -- iter: 1216/1584
[A[ATraining Step: 989  | total loss: [1m[32m0.08920[0m[0m | time: 41.025s
[2K
| RMSProp | epoch: 020 | loss: 0.08920 - acc: 0.9737 -- iter: 1248/1584
[A[ATraining Step: 990  | total loss: [1m[32m0.08333[0m[0m | time: 42.081s
[2K
| RMSProp | epoch: 020 | loss: 0.08333 - acc: 0.9763 -- iter: 1280/1584
[A[ATraining Step: 991  | total loss: [1m[32m0.07628[0m[0m | time: 43.282s
[2K
| RMSProp | epoch: 020 | loss: 0.07628 - acc: 0.9787 -- iter: 1312/1584
[A[ATraining Step: 992  | total loss: [1m[32m0.08624[0m[0m | time: 44.400s
[2K
| RMSProp | epoch: 020 | loss: 0.08624 - acc: 0.9777 -- iter: 1344/1584
[A[ATraining Step: 993  | total loss: [1m[32m0.09182[0m[0m | time: 45.439s
[2K
| RMSProp | epoch: 020 | loss: 0.09182 - acc: 0.9737 -- iter: 1376/1584
[A[ATraining Step: 994  | total loss: [1m[32m0.11492[0m[0m | time: 46.360s
[2K
| RMSProp | epoch: 020 | loss: 0.11492 - acc: 0.9638 -- iter: 1408/1584
[A[ATraining Step: 995  | total loss: [1m[32m0.10991[0m[0m | time: 47.418s
[2K
| RMSProp | epoch: 020 | loss: 0.10991 - acc: 0.9643 -- iter: 1440/1584
[A[ATraining Step: 996  | total loss: [1m[32m0.10455[0m[0m | time: 48.471s
[2K
| RMSProp | epoch: 020 | loss: 0.10455 - acc: 0.9679 -- iter: 1472/1584
[A[ATraining Step: 997  | total loss: [1m[32m0.09853[0m[0m | time: 49.481s
[2K
| RMSProp | epoch: 020 | loss: 0.09853 - acc: 0.9680 -- iter: 1504/1584
[A[ATraining Step: 998  | total loss: [1m[32m0.10911[0m[0m | time: 50.661s
[2K
| RMSProp | epoch: 020 | loss: 0.10911 - acc: 0.9680 -- iter: 1536/1584
[A[ATraining Step: 999  | total loss: [1m[32m0.10211[0m[0m | time: 51.570s
[2K
| RMSProp | epoch: 020 | loss: 0.10211 - acc: 0.9712 -- iter: 1568/1584
[A[ATraining Step: 1000  | total loss: [1m[32m0.09604[0m[0m | time: 55.835s
[2K
| RMSProp | epoch: 020 | loss: 0.09604 - acc: 0.9710 | val_loss: 0.64193 - val_acc: 0.8165 -- iter: 1584/1584
--
Training Step: 1001  | total loss: [1m[32m0.08948[0m[0m | time: 0.765s
[2K
| RMSProp | epoch: 021 | loss: 0.08948 - acc: 0.9739 -- iter: 0032/1584
[A[ATraining Step: 1002  | total loss: [1m[32m0.08328[0m[0m | time: 1.626s
[2K
| RMSProp | epoch: 021 | loss: 0.08328 - acc: 0.9734 -- iter: 0064/1584
[A[ATraining Step: 1003  | total loss: [1m[32m0.07894[0m[0m | time: 2.488s
[2K
| RMSProp | epoch: 021 | loss: 0.07894 - acc: 0.9760 -- iter: 0096/1584
[A[ATraining Step: 1004  | total loss: [1m[32m0.07306[0m[0m | time: 3.362s
[2K
| RMSProp | epoch: 021 | loss: 0.07306 - acc: 0.9784 -- iter: 0128/1584
[A[ATraining Step: 1005  | total loss: [1m[32m0.07942[0m[0m | time: 4.217s
[2K
| RMSProp | epoch: 021 | loss: 0.07942 - acc: 0.9775 -- iter: 0160/1584
[A[ATraining Step: 1006  | total loss: [1m[32m0.09315[0m[0m | time: 5.075s
[2K
| RMSProp | epoch: 021 | loss: 0.09315 - acc: 0.9703 -- iter: 0192/1584
[A[ATraining Step: 1007  | total loss: [1m[32m0.08535[0m[0m | time: 5.922s
[2K
| RMSProp | epoch: 021 | loss: 0.08535 - acc: 0.9733 -- iter: 0224/1584
[A[ATraining Step: 1008  | total loss: [1m[32m0.07746[0m[0m | time: 6.789s
[2K
| RMSProp | epoch: 021 | loss: 0.07746 - acc: 0.9760 -- iter: 0256/1584
[A[ATraining Step: 1009  | total loss: [1m[32m0.07021[0m[0m | time: 7.602s
[2K
| RMSProp | epoch: 021 | loss: 0.07021 - acc: 0.9784 -- iter: 0288/1584
[A[ATraining Step: 1010  | total loss: [1m[32m0.06453[0m[0m | time: 8.446s
[2K
| RMSProp | epoch: 021 | loss: 0.06453 - acc: 0.9805 -- iter: 0320/1584
[A[ATraining Step: 1011  | total loss: [1m[32m0.05881[0m[0m | time: 9.483s
[2K
| RMSProp | epoch: 021 | loss: 0.05881 - acc: 0.9825 -- iter: 0352/1584
[A[ATraining Step: 1012  | total loss: [1m[32m0.05479[0m[0m | time: 10.486s
[2K
| RMSProp | epoch: 021 | loss: 0.05479 - acc: 0.9842 -- iter: 0384/1584
[A[ATraining Step: 1013  | total loss: [1m[32m0.05298[0m[0m | time: 11.203s
[2K
| RMSProp | epoch: 021 | loss: 0.05298 - acc: 0.9827 -- iter: 0416/1584
[A[ATraining Step: 1014  | total loss: [1m[32m0.07535[0m[0m | time: 11.997s
[2K
| RMSProp | epoch: 021 | loss: 0.07535 - acc: 0.9750 -- iter: 0448/1584
[A[ATraining Step: 1015  | total loss: [1m[32m0.09065[0m[0m | time: 12.860s
[2K
| RMSProp | epoch: 021 | loss: 0.09065 - acc: 0.9713 -- iter: 0480/1584
[A[ATraining Step: 1016  | total loss: [1m[32m0.08691[0m[0m | time: 13.714s
[2K
| RMSProp | epoch: 021 | loss: 0.08691 - acc: 0.9710 -- iter: 0512/1584
[A[ATraining Step: 1017  | total loss: [1m[32m0.08513[0m[0m | time: 14.546s
[2K
| RMSProp | epoch: 021 | loss: 0.08513 - acc: 0.9708 -- iter: 0544/1584
[A[ATraining Step: 1018  | total loss: [1m[32m0.08176[0m[0m | time: 15.432s
[2K
| RMSProp | epoch: 021 | loss: 0.08176 - acc: 0.9737 -- iter: 0576/1584
[A[ATraining Step: 1019  | total loss: [1m[32m0.08456[0m[0m | time: 15.899s
[2K
| RMSProp | epoch: 021 | loss: 0.08456 - acc: 0.9732 -- iter: 0608/1584
[A[ATraining Step: 1020  | total loss: [1m[32m0.07742[0m[0m | time: 16.373s
[2K
| RMSProp | epoch: 021 | loss: 0.07742 - acc: 0.9759 -- iter: 0640/1584
[A[ATraining Step: 1021  | total loss: [1m[32m0.07032[0m[0m | time: 17.279s
[2K
| RMSProp | epoch: 021 | loss: 0.07032 - acc: 0.9783 -- iter: 0672/1584
[A[ATraining Step: 1022  | total loss: [1m[32m0.06645[0m[0m | time: 18.175s
[2K
| RMSProp | epoch: 021 | loss: 0.06645 - acc: 0.9774 -- iter: 0704/1584
[A[ATraining Step: 1023  | total loss: [1m[32m0.06421[0m[0m | time: 19.110s
[2K
| RMSProp | epoch: 021 | loss: 0.06421 - acc: 0.9765 -- iter: 0736/1584
[A[ATraining Step: 1024  | total loss: [1m[32m0.05938[0m[0m | time: 19.950s
[2K
| RMSProp | epoch: 021 | loss: 0.05938 - acc: 0.9788 -- iter: 0768/1584
[A[ATraining Step: 1025  | total loss: [1m[32m0.05422[0m[0m | time: 20.949s
[2K
| RMSProp | epoch: 021 | loss: 0.05422 - acc: 0.9810 -- iter: 0800/1584
[A[ATraining Step: 1026  | total loss: [1m[32m0.04949[0m[0m | time: 21.919s
[2K
| RMSProp | epoch: 021 | loss: 0.04949 - acc: 0.9829 -- iter: 0832/1584
[A[ATraining Step: 1027  | total loss: [1m[32m0.04514[0m[0m | time: 22.701s
[2K
| RMSProp | epoch: 021 | loss: 0.04514 - acc: 0.9846 -- iter: 0864/1584
[A[ATraining Step: 1028  | total loss: [1m[32m0.04111[0m[0m | time: 23.502s
[2K
| RMSProp | epoch: 021 | loss: 0.04111 - acc: 0.9861 -- iter: 0896/1584
[A[ATraining Step: 1029  | total loss: [1m[32m0.05328[0m[0m | time: 24.385s
[2K
| RMSProp | epoch: 021 | loss: 0.05328 - acc: 0.9844 -- iter: 0928/1584
[A[ATraining Step: 1030  | total loss: [1m[32m0.05044[0m[0m | time: 25.278s
[2K
| RMSProp | epoch: 021 | loss: 0.05044 - acc: 0.9859 -- iter: 0960/1584
[A[ATraining Step: 1031  | total loss: [1m[32m0.04841[0m[0m | time: 26.173s
[2K
| RMSProp | epoch: 021 | loss: 0.04841 - acc: 0.9842 -- iter: 0992/1584
[A[ATraining Step: 1032  | total loss: [1m[32m0.05973[0m[0m | time: 27.075s
[2K
| RMSProp | epoch: 021 | loss: 0.05973 - acc: 0.9764 -- iter: 1024/1584
[A[ATraining Step: 1033  | total loss: [1m[32m0.08582[0m[0m | time: 27.934s
[2K
| RMSProp | epoch: 021 | loss: 0.08582 - acc: 0.9725 -- iter: 1056/1584
[A[ATraining Step: 1034  | total loss: [1m[32m0.09169[0m[0m | time: 28.823s
[2K
| RMSProp | epoch: 021 | loss: 0.09169 - acc: 0.9722 -- iter: 1088/1584
[A[ATraining Step: 1035  | total loss: [1m[32m0.08450[0m[0m | time: 29.693s
[2K
| RMSProp | epoch: 021 | loss: 0.08450 - acc: 0.9749 -- iter: 1120/1584
[A[ATraining Step: 1036  | total loss: [1m[32m0.07842[0m[0m | time: 30.565s
[2K
| RMSProp | epoch: 021 | loss: 0.07842 - acc: 0.9774 -- iter: 1152/1584
[A[ATraining Step: 1037  | total loss: [1m[32m0.07239[0m[0m | time: 31.410s
[2K
| RMSProp | epoch: 021 | loss: 0.07239 - acc: 0.9797 -- iter: 1184/1584
[A[ATraining Step: 1038  | total loss: [1m[32m0.06616[0m[0m | time: 32.413s
[2K
| RMSProp | epoch: 021 | loss: 0.06616 - acc: 0.9817 -- iter: 1216/1584
[A[ATraining Step: 1039  | total loss: [1m[32m0.09901[0m[0m | time: 33.403s
[2K
| RMSProp | epoch: 021 | loss: 0.09901 - acc: 0.9773 -- iter: 1248/1584
[A[ATraining Step: 1040  | total loss: [1m[32m0.09229[0m[0m | time: 34.142s
[2K
| RMSProp | epoch: 021 | loss: 0.09229 - acc: 0.9796 -- iter: 1280/1584
[A[ATraining Step: 1041  | total loss: [1m[32m0.08461[0m[0m | time: 34.923s
[2K
| RMSProp | epoch: 021 | loss: 0.08461 - acc: 0.9816 -- iter: 1312/1584
[A[ATraining Step: 1042  | total loss: [1m[32m0.07725[0m[0m | time: 35.789s
[2K
| RMSProp | epoch: 021 | loss: 0.07725 - acc: 0.9835 -- iter: 1344/1584
[A[ATraining Step: 1043  | total loss: [1m[32m0.07127[0m[0m | time: 36.672s
[2K
| RMSProp | epoch: 021 | loss: 0.07127 - acc: 0.9851 -- iter: 1376/1584
[A[ATraining Step: 1044  | total loss: [1m[32m0.06454[0m[0m | time: 37.628s
[2K
| RMSProp | epoch: 021 | loss: 0.06454 - acc: 0.9866 -- iter: 1408/1584
[A[ATraining Step: 1045  | total loss: [1m[32m0.05957[0m[0m | time: 38.543s
[2K
| RMSProp | epoch: 021 | loss: 0.05957 - acc: 0.9879 -- iter: 1440/1584
[A[ATraining Step: 1046  | total loss: [1m[32m0.05427[0m[0m | time: 39.459s
[2K
| RMSProp | epoch: 021 | loss: 0.05427 - acc: 0.9891 -- iter: 1472/1584
[A[ATraining Step: 1047  | total loss: [1m[32m0.04972[0m[0m | time: 40.325s
[2K
| RMSProp | epoch: 021 | loss: 0.04972 - acc: 0.9902 -- iter: 1504/1584
[A[ATraining Step: 1048  | total loss: [1m[32m0.04506[0m[0m | time: 41.185s
[2K
| RMSProp | epoch: 021 | loss: 0.04506 - acc: 0.9912 -- iter: 1536/1584
[A[ATraining Step: 1049  | total loss: [1m[32m0.04077[0m[0m | time: 42.019s
[2K
| RMSProp | epoch: 021 | loss: 0.04077 - acc: 0.9921 -- iter: 1568/1584
[A[ATraining Step: 1050  | total loss: [1m[32m0.03703[0m[0m | time: 45.559s
[2K
| RMSProp | epoch: 021 | loss: 0.03703 - acc: 0.9929 | val_loss: 0.78742 - val_acc: 0.8286 -- iter: 1584/1584
--
Training Step: 1051  | total loss: [1m[32m0.03363[0m[0m | time: 0.921s
[2K
| RMSProp | epoch: 022 | loss: 0.03363 - acc: 0.9936 -- iter: 0032/1584
[A[ATraining Step: 1052  | total loss: [1m[32m0.04275[0m[0m | time: 1.818s
[2K
| RMSProp | epoch: 022 | loss: 0.04275 - acc: 0.9911 -- iter: 0064/1584
[A[ATraining Step: 1053  | total loss: [1m[32m0.05188[0m[0m | time: 2.711s
[2K
| RMSProp | epoch: 022 | loss: 0.05188 - acc: 0.9795 -- iter: 0096/1584
[A[ATraining Step: 1054  | total loss: [1m[32m0.08013[0m[0m | time: 3.598s
[2K
| RMSProp | epoch: 022 | loss: 0.08013 - acc: 0.9690 -- iter: 0128/1584
[A[ATraining Step: 1055  | total loss: [1m[32m0.08068[0m[0m | time: 4.521s
[2K
| RMSProp | epoch: 022 | loss: 0.08068 - acc: 0.9690 -- iter: 0160/1584
[A[ATraining Step: 1056  | total loss: [1m[32m0.07471[0m[0m | time: 5.387s
[2K
| RMSProp | epoch: 022 | loss: 0.07471 - acc: 0.9721 -- iter: 0192/1584
[A[ATraining Step: 1057  | total loss: [1m[32m0.06777[0m[0m | time: 6.275s
[2K
| RMSProp | epoch: 022 | loss: 0.06777 - acc: 0.9749 -- iter: 0224/1584
[A[ATraining Step: 1058  | total loss: [1m[32m0.06339[0m[0m | time: 7.317s
[2K
| RMSProp | epoch: 022 | loss: 0.06339 - acc: 0.9774 -- iter: 0256/1584
[A[ATraining Step: 1059  | total loss: [1m[32m0.07084[0m[0m | time: 8.305s
[2K
| RMSProp | epoch: 022 | loss: 0.07084 - acc: 0.9765 -- iter: 0288/1584
[A[ATraining Step: 1060  | total loss: [1m[32m0.06614[0m[0m | time: 9.243s
[2K
| RMSProp | epoch: 022 | loss: 0.06614 - acc: 0.9789 -- iter: 0320/1584
[A[ATraining Step: 1061  | total loss: [1m[32m0.05989[0m[0m | time: 9.976s
[2K
| RMSProp | epoch: 022 | loss: 0.05989 - acc: 0.9810 -- iter: 0352/1584
[A[ATraining Step: 1062  | total loss: [1m[32m0.05834[0m[0m | time: 10.879s
[2K
| RMSProp | epoch: 022 | loss: 0.05834 - acc: 0.9829 -- iter: 0384/1584
[A[ATraining Step: 1063  | total loss: [1m[32m0.05356[0m[0m | time: 11.769s
[2K
| RMSProp | epoch: 022 | loss: 0.05356 - acc: 0.9846 -- iter: 0416/1584
[A[ATraining Step: 1064  | total loss: [1m[32m0.04855[0m[0m | time: 12.607s
[2K
| RMSProp | epoch: 022 | loss: 0.04855 - acc: 0.9862 -- iter: 0448/1584
[A[ATraining Step: 1065  | total loss: [1m[32m0.04408[0m[0m | time: 13.502s
[2K
| RMSProp | epoch: 022 | loss: 0.04408 - acc: 0.9875 -- iter: 0480/1584
[A[ATraining Step: 1066  | total loss: [1m[32m0.05508[0m[0m | time: 14.368s
[2K
| RMSProp | epoch: 022 | loss: 0.05508 - acc: 0.9857 -- iter: 0512/1584
[A[ATraining Step: 1067  | total loss: [1m[32m0.07255[0m[0m | time: 15.287s
[2K
| RMSProp | epoch: 022 | loss: 0.07255 - acc: 0.9777 -- iter: 0544/1584
[A[ATraining Step: 1068  | total loss: [1m[32m0.07223[0m[0m | time: 16.128s
[2K
| RMSProp | epoch: 022 | loss: 0.07223 - acc: 0.9737 -- iter: 0576/1584
[A[ATraining Step: 1069  | total loss: [1m[32m0.09256[0m[0m | time: 17.002s
[2K
| RMSProp | epoch: 022 | loss: 0.09256 - acc: 0.9670 -- iter: 0608/1584
[A[ATraining Step: 1070  | total loss: [1m[32m0.08579[0m[0m | time: 17.449s
[2K
| RMSProp | epoch: 022 | loss: 0.08579 - acc: 0.9703 -- iter: 0640/1584
[A[ATraining Step: 1071  | total loss: [1m[32m0.08660[0m[0m | time: 17.860s
[2K
| RMSProp | epoch: 022 | loss: 0.08660 - acc: 0.9670 -- iter: 0672/1584
[A[ATraining Step: 1072  | total loss: [1m[32m0.08237[0m[0m | time: 18.816s
[2K
| RMSProp | epoch: 022 | loss: 0.08237 - acc: 0.9703 -- iter: 0704/1584
[A[ATraining Step: 1073  | total loss: [1m[32m0.07614[0m[0m | time: 19.807s
[2K
| RMSProp | epoch: 022 | loss: 0.07614 - acc: 0.9733 -- iter: 0736/1584
[A[ATraining Step: 1074  | total loss: [1m[32m0.07194[0m[0m | time: 20.776s
[2K
| RMSProp | epoch: 022 | loss: 0.07194 - acc: 0.9728 -- iter: 0768/1584
[A[ATraining Step: 1075  | total loss: [1m[32m0.07461[0m[0m | time: 21.463s
[2K
| RMSProp | epoch: 022 | loss: 0.07461 - acc: 0.9661 -- iter: 0800/1584
[A[ATraining Step: 1076  | total loss: [1m[32m0.09221[0m[0m | time: 22.302s
[2K
| RMSProp | epoch: 022 | loss: 0.09221 - acc: 0.9602 -- iter: 0832/1584
[A[ATraining Step: 1077  | total loss: [1m[32m0.08698[0m[0m | time: 23.282s
[2K
| RMSProp | epoch: 022 | loss: 0.08698 - acc: 0.9610 -- iter: 0864/1584
[A[ATraining Step: 1078  | total loss: [1m[32m0.08177[0m[0m | time: 24.167s
[2K
| RMSProp | epoch: 022 | loss: 0.08177 - acc: 0.9618 -- iter: 0896/1584
[A[ATraining Step: 1079  | total loss: [1m[32m0.07654[0m[0m | time: 24.998s
[2K
| RMSProp | epoch: 022 | loss: 0.07654 - acc: 0.9656 -- iter: 0928/1584
[A[ATraining Step: 1080  | total loss: [1m[32m0.07307[0m[0m | time: 25.840s
[2K
| RMSProp | epoch: 022 | loss: 0.07307 - acc: 0.9691 -- iter: 0960/1584
[A[ATraining Step: 1081  | total loss: [1m[32m0.07057[0m[0m | time: 26.703s
[2K
| RMSProp | epoch: 022 | loss: 0.07057 - acc: 0.9721 -- iter: 0992/1584
[A[ATraining Step: 1082  | total loss: [1m[32m0.07612[0m[0m | time: 27.579s
[2K
| RMSProp | epoch: 022 | loss: 0.07612 - acc: 0.9687 -- iter: 1024/1584
[A[ATraining Step: 1083  | total loss: [1m[32m0.07066[0m[0m | time: 28.548s
[2K
| RMSProp | epoch: 022 | loss: 0.07066 - acc: 0.9718 -- iter: 1056/1584
[A[ATraining Step: 1084  | total loss: [1m[32m0.08010[0m[0m | time: 29.401s
[2K
| RMSProp | epoch: 022 | loss: 0.08010 - acc: 0.9715 -- iter: 1088/1584
[A[ATraining Step: 1085  | total loss: [1m[32m0.07527[0m[0m | time: 30.261s
[2K
| RMSProp | epoch: 022 | loss: 0.07527 - acc: 0.9744 -- iter: 1120/1584
[A[ATraining Step: 1086  | total loss: [1m[32m0.06921[0m[0m | time: 31.227s
[2K
| RMSProp | epoch: 022 | loss: 0.06921 - acc: 0.9769 -- iter: 1152/1584
[A[ATraining Step: 1087  | total loss: [1m[32m0.06451[0m[0m | time: 32.184s
[2K
| RMSProp | epoch: 022 | loss: 0.06451 - acc: 0.9792 -- iter: 1184/1584
[A[ATraining Step: 1088  | total loss: [1m[32m0.06097[0m[0m | time: 33.124s
[2K
| RMSProp | epoch: 022 | loss: 0.06097 - acc: 0.9813 -- iter: 1216/1584
[A[ATraining Step: 1089  | total loss: [1m[32m0.05594[0m[0m | time: 34.124s
[2K
| RMSProp | epoch: 022 | loss: 0.05594 - acc: 0.9832 -- iter: 1248/1584
[A[ATraining Step: 1090  | total loss: [1m[32m0.06534[0m[0m | time: 35.067s
[2K
| RMSProp | epoch: 022 | loss: 0.06534 - acc: 0.9817 -- iter: 1280/1584
[A[ATraining Step: 1091  | total loss: [1m[32m0.05956[0m[0m | time: 36.046s
[2K
| RMSProp | epoch: 022 | loss: 0.05956 - acc: 0.9836 -- iter: 1312/1584
[A[ATraining Step: 1092  | total loss: [1m[32m0.05444[0m[0m | time: 37.035s
[2K
| RMSProp | epoch: 022 | loss: 0.05444 - acc: 0.9852 -- iter: 1344/1584
[A[ATraining Step: 1093  | total loss: [1m[32m0.05005[0m[0m | time: 38.049s
[2K
| RMSProp | epoch: 022 | loss: 0.05005 - acc: 0.9867 -- iter: 1376/1584
[A[ATraining Step: 1094  | total loss: [1m[32m0.04543[0m[0m | time: 38.993s
[2K
| RMSProp | epoch: 022 | loss: 0.04543 - acc: 0.9880 -- iter: 1408/1584
[A[ATraining Step: 1095  | total loss: [1m[32m0.04160[0m[0m | time: 39.911s
[2K
| RMSProp | epoch: 022 | loss: 0.04160 - acc: 0.9892 -- iter: 1440/1584
[A[ATraining Step: 1096  | total loss: [1m[32m0.03764[0m[0m | time: 40.889s
[2K
| RMSProp | epoch: 022 | loss: 0.03764 - acc: 0.9903 -- iter: 1472/1584
[A[ATraining Step: 1097  | total loss: [1m[32m0.03869[0m[0m | time: 41.869s
[2K
| RMSProp | epoch: 022 | loss: 0.03869 - acc: 0.9881 -- iter: 1504/1584
[A[ATraining Step: 1098  | total loss: [1m[32m0.05243[0m[0m | time: 42.880s
[2K
| RMSProp | epoch: 022 | loss: 0.05243 - acc: 0.9799 -- iter: 1536/1584
[A[ATraining Step: 1099  | total loss: [1m[32m0.06432[0m[0m | time: 43.840s
[2K
| RMSProp | epoch: 022 | loss: 0.06432 - acc: 0.9788 -- iter: 1568/1584
[A[ATraining Step: 1100  | total loss: [1m[32m0.06308[0m[0m | time: 47.316s
[2K
| RMSProp | epoch: 022 | loss: 0.06308 - acc: 0.9778 | val_loss: 1.03986 - val_acc: 0.7177 -- iter: 1584/1584
--
Training Step: 1101  | total loss: [1m[32m0.09836[0m[0m | time: 0.927s
[2K
| RMSProp | epoch: 023 | loss: 0.09836 - acc: 0.9738 -- iter: 0032/1584
[A[ATraining Step: 1102  | total loss: [1m[32m0.09362[0m[0m | time: 1.872s
[2K
| RMSProp | epoch: 023 | loss: 0.09362 - acc: 0.9764 -- iter: 0064/1584
[A[ATraining Step: 1103  | total loss: [1m[32m0.08564[0m[0m | time: 2.882s
[2K
| RMSProp | epoch: 023 | loss: 0.08564 - acc: 0.9788 -- iter: 0096/1584
[A[ATraining Step: 1104  | total loss: [1m[32m0.07780[0m[0m | time: 3.834s
[2K
| RMSProp | epoch: 023 | loss: 0.07780 - acc: 0.9809 -- iter: 0128/1584
[A[ATraining Step: 1105  | total loss: [1m[32m0.07521[0m[0m | time: 4.789s
[2K
| RMSProp | epoch: 023 | loss: 0.07521 - acc: 0.9797 -- iter: 0160/1584
[A[ATraining Step: 1106  | total loss: [1m[32m0.07612[0m[0m | time: 5.740s
[2K
| RMSProp | epoch: 023 | loss: 0.07612 - acc: 0.9786 -- iter: 0192/1584
[A[ATraining Step: 1107  | total loss: [1m[32m0.08366[0m[0m | time: 6.665s
[2K
| RMSProp | epoch: 023 | loss: 0.08366 - acc: 0.9776 -- iter: 0224/1584
[A[ATraining Step: 1108  | total loss: [1m[32m0.07599[0m[0m | time: 7.647s
[2K
| RMSProp | epoch: 023 | loss: 0.07599 - acc: 0.9798 -- iter: 0256/1584
[A[ATraining Step: 1109  | total loss: [1m[32m0.07031[0m[0m | time: 8.597s
[2K
| RMSProp | epoch: 023 | loss: 0.07031 - acc: 0.9819 -- iter: 0288/1584
[A[ATraining Step: 1110  | total loss: [1m[32m0.07667[0m[0m | time: 9.576s
[2K
| RMSProp | epoch: 023 | loss: 0.07667 - acc: 0.9805 -- iter: 0320/1584
[A[ATraining Step: 1111  | total loss: [1m[32m0.07378[0m[0m | time: 10.567s
[2K
| RMSProp | epoch: 023 | loss: 0.07378 - acc: 0.9794 -- iter: 0352/1584
[A[ATraining Step: 1112  | total loss: [1m[32m0.06774[0m[0m | time: 11.518s
[2K
| RMSProp | epoch: 023 | loss: 0.06774 - acc: 0.9814 -- iter: 0384/1584
[A[ATraining Step: 1113  | total loss: [1m[32m0.06614[0m[0m | time: 12.464s
[2K
| RMSProp | epoch: 023 | loss: 0.06614 - acc: 0.9833 -- iter: 0416/1584
[A[ATraining Step: 1114  | total loss: [1m[32m0.06466[0m[0m | time: 13.401s
[2K
| RMSProp | epoch: 023 | loss: 0.06466 - acc: 0.9818 -- iter: 0448/1584
[A[ATraining Step: 1115  | total loss: [1m[32m0.06371[0m[0m | time: 14.365s
[2K
| RMSProp | epoch: 023 | loss: 0.06371 - acc: 0.9805 -- iter: 0480/1584
[A[ATraining Step: 1116  | total loss: [1m[32m0.07215[0m[0m | time: 15.275s
[2K
| RMSProp | epoch: 023 | loss: 0.07215 - acc: 0.9793 -- iter: 0512/1584
[A[ATraining Step: 1117  | total loss: [1m[32m0.06581[0m[0m | time: 16.242s
[2K
| RMSProp | epoch: 023 | loss: 0.06581 - acc: 0.9814 -- iter: 0544/1584
[A[ATraining Step: 1118  | total loss: [1m[32m0.06056[0m[0m | time: 17.214s
[2K
| RMSProp | epoch: 023 | loss: 0.06056 - acc: 0.9833 -- iter: 0576/1584
[A[ATraining Step: 1119  | total loss: [1m[32m0.05553[0m[0m | time: 18.222s
[2K
| RMSProp | epoch: 023 | loss: 0.05553 - acc: 0.9849 -- iter: 0608/1584
[A[ATraining Step: 1120  | total loss: [1m[32m0.05033[0m[0m | time: 19.224s
[2K
| RMSProp | epoch: 023 | loss: 0.05033 - acc: 0.9865 -- iter: 0640/1584
[A[ATraining Step: 1121  | total loss: [1m[32m0.04580[0m[0m | time: 19.760s
[2K
| RMSProp | epoch: 023 | loss: 0.04580 - acc: 0.9878 -- iter: 0672/1584
[A[ATraining Step: 1122  | total loss: [1m[32m0.04153[0m[0m | time: 20.272s
[2K
| RMSProp | epoch: 023 | loss: 0.04153 - acc: 0.9890 -- iter: 0704/1584
[A[ATraining Step: 1123  | total loss: [1m[32m0.03761[0m[0m | time: 21.249s
[2K
| RMSProp | epoch: 023 | loss: 0.03761 - acc: 0.9901 -- iter: 0736/1584
[A[ATraining Step: 1124  | total loss: [1m[32m0.03417[0m[0m | time: 22.248s
[2K
| RMSProp | epoch: 023 | loss: 0.03417 - acc: 0.9911 -- iter: 0768/1584
[A[ATraining Step: 1125  | total loss: [1m[32m0.03236[0m[0m | time: 23.193s
[2K
| RMSProp | epoch: 023 | loss: 0.03236 - acc: 0.9920 -- iter: 0800/1584
[A[ATraining Step: 1126  | total loss: [1m[32m0.03604[0m[0m | time: 24.219s
[2K
| RMSProp | epoch: 023 | loss: 0.03604 - acc: 0.9865 -- iter: 0832/1584
[A[ATraining Step: 1127  | total loss: [1m[32m0.04550[0m[0m | time: 25.216s
[2K
| RMSProp | epoch: 023 | loss: 0.04550 - acc: 0.9816 -- iter: 0864/1584
[A[ATraining Step: 1128  | total loss: [1m[32m0.04507[0m[0m | time: 26.223s
[2K
| RMSProp | epoch: 023 | loss: 0.04507 - acc: 0.9835 -- iter: 0896/1584
[A[ATraining Step: 1129  | total loss: [1m[32m0.04106[0m[0m | time: 27.167s
[2K
| RMSProp | epoch: 023 | loss: 0.04106 - acc: 0.9851 -- iter: 0928/1584
[A[ATraining Step: 1130  | total loss: [1m[32m0.03746[0m[0m | time: 28.184s
[2K
| RMSProp | epoch: 023 | loss: 0.03746 - acc: 0.9866 -- iter: 0960/1584
[A[ATraining Step: 1131  | total loss: [1m[32m0.05418[0m[0m | time: 29.189s
[2K
| RMSProp | epoch: 023 | loss: 0.05418 - acc: 0.9817 -- iter: 0992/1584
[A[ATraining Step: 1132  | total loss: [1m[32m0.05974[0m[0m | time: 30.191s
[2K
| RMSProp | epoch: 023 | loss: 0.05974 - acc: 0.9804 -- iter: 1024/1584
[A[ATraining Step: 1133  | total loss: [1m[32m0.06830[0m[0m | time: 31.170s
[2K
| RMSProp | epoch: 023 | loss: 0.06830 - acc: 0.9761 -- iter: 1056/1584
[A[ATraining Step: 1134  | total loss: [1m[32m0.07681[0m[0m | time: 32.159s
[2K
| RMSProp | epoch: 023 | loss: 0.07681 - acc: 0.9723 -- iter: 1088/1584
[A[ATraining Step: 1135  | total loss: [1m[32m0.07227[0m[0m | time: 33.271s
[2K
| RMSProp | epoch: 023 | loss: 0.07227 - acc: 0.9750 -- iter: 1120/1584
[A[ATraining Step: 1136  | total loss: [1m[32m0.06842[0m[0m | time: 34.267s
[2K
| RMSProp | epoch: 023 | loss: 0.06842 - acc: 0.9775 -- iter: 1152/1584
[A[ATraining Step: 1137  | total loss: [1m[32m0.06355[0m[0m | time: 35.246s
[2K
| RMSProp | epoch: 023 | loss: 0.06355 - acc: 0.9798 -- iter: 1184/1584
[A[ATraining Step: 1138  | total loss: [1m[32m0.05774[0m[0m | time: 36.225s
[2K
| RMSProp | epoch: 023 | loss: 0.05774 - acc: 0.9818 -- iter: 1216/1584
[A[ATraining Step: 1139  | total loss: [1m[32m0.05267[0m[0m | time: 37.231s
[2K
| RMSProp | epoch: 023 | loss: 0.05267 - acc: 0.9836 -- iter: 1248/1584
[A[ATraining Step: 1140  | total loss: [1m[32m0.04812[0m[0m | time: 38.223s
[2K
| RMSProp | epoch: 023 | loss: 0.04812 - acc: 0.9853 -- iter: 1280/1584
[A[ATraining Step: 1141  | total loss: [1m[32m0.07848[0m[0m | time: 39.332s
[2K
| RMSProp | epoch: 023 | loss: 0.07848 - acc: 0.9805 -- iter: 1312/1584
[A[ATraining Step: 1142  | total loss: [1m[32m0.07277[0m[0m | time: 40.314s
[2K
| RMSProp | epoch: 023 | loss: 0.07277 - acc: 0.9824 -- iter: 1344/1584
[A[ATraining Step: 1143  | total loss: [1m[32m0.06679[0m[0m | time: 41.351s
[2K
| RMSProp | epoch: 023 | loss: 0.06679 - acc: 0.9842 -- iter: 1376/1584
[A[ATraining Step: 1144  | total loss: [1m[32m0.06082[0m[0m | time: 42.330s
[2K
| RMSProp | epoch: 023 | loss: 0.06082 - acc: 0.9858 -- iter: 1408/1584
[A[ATraining Step: 1145  | total loss: [1m[32m0.06557[0m[0m | time: 43.366s
[2K
| RMSProp | epoch: 023 | loss: 0.06557 - acc: 0.9841 -- iter: 1440/1584
[A[ATraining Step: 1146  | total loss: [1m[32m0.06000[0m[0m | time: 44.337s
[2K
| RMSProp | epoch: 023 | loss: 0.06000 - acc: 0.9857 -- iter: 1472/1584
[A[ATraining Step: 1147  | total loss: [1m[32m0.06307[0m[0m | time: 45.316s
[2K
| RMSProp | epoch: 023 | loss: 0.06307 - acc: 0.9840 -- iter: 1504/1584
[A[ATraining Step: 1148  | total loss: [1m[32m0.06374[0m[0m | time: 46.317s
[2K
| RMSProp | epoch: 023 | loss: 0.06374 - acc: 0.9793 -- iter: 1536/1584
[A[ATraining Step: 1149  | total loss: [1m[32m0.06518[0m[0m | time: 47.344s
[2K
| RMSProp | epoch: 023 | loss: 0.06518 - acc: 0.9783 -- iter: 1568/1584
[A[ATraining Step: 1150  | total loss: [1m[32m0.05940[0m[0m | time: 50.487s
[2K
| RMSProp | epoch: 023 | loss: 0.05940 - acc: 0.9804 | val_loss: 0.79025 - val_acc: 0.8065 -- iter: 1584/1584
--
Training Step: 1151  | total loss: [1m[32m0.05393[0m[0m | time: 0.683s
[2K
| RMSProp | epoch: 024 | loss: 0.05393 - acc: 0.9824 -- iter: 0032/1584
[A[ATraining Step: 1152  | total loss: [1m[32m0.05087[0m[0m | time: 1.370s
[2K
| RMSProp | epoch: 024 | loss: 0.05087 - acc: 0.9842 -- iter: 0064/1584
[A[ATraining Step: 1153  | total loss: [1m[32m0.04591[0m[0m | time: 2.038s
[2K
| RMSProp | epoch: 024 | loss: 0.04591 - acc: 0.9857 -- iter: 0096/1584
[A[ATraining Step: 1154  | total loss: [1m[32m0.04196[0m[0m | time: 2.713s
[2K
| RMSProp | epoch: 024 | loss: 0.04196 - acc: 0.9872 -- iter: 0128/1584
[A[ATraining Step: 1155  | total loss: [1m[32m0.03801[0m[0m | time: 3.391s
[2K
| RMSProp | epoch: 024 | loss: 0.03801 - acc: 0.9884 -- iter: 0160/1584
[A[ATraining Step: 1156  | total loss: [1m[32m0.04495[0m[0m | time: 4.050s
[2K
| RMSProp | epoch: 024 | loss: 0.04495 - acc: 0.9865 -- iter: 0192/1584
[A[ATraining Step: 1157  | total loss: [1m[32m0.04510[0m[0m | time: 4.705s
[2K
| RMSProp | epoch: 024 | loss: 0.04510 - acc: 0.9847 -- iter: 0224/1584
[A[ATraining Step: 1158  | total loss: [1m[32m0.04084[0m[0m | time: 5.359s
[2K
| RMSProp | epoch: 024 | loss: 0.04084 - acc: 0.9862 -- iter: 0256/1584
[A[ATraining Step: 1159  | total loss: [1m[32m0.03788[0m[0m | time: 6.014s
[2K
| RMSProp | epoch: 024 | loss: 0.03788 - acc: 0.9876 -- iter: 0288/1584
[A[ATraining Step: 1160  | total loss: [1m[32m0.03476[0m[0m | time: 6.677s
[2K
| RMSProp | epoch: 024 | loss: 0.03476 - acc: 0.9889 -- iter: 0320/1584
[A[ATraining Step: 1161  | total loss: [1m[32m0.03187[0m[0m | time: 7.339s
[2K
| RMSProp | epoch: 024 | loss: 0.03187 - acc: 0.9900 -- iter: 0352/1584
[A[ATraining Step: 1162  | total loss: [1m[32m0.02927[0m[0m | time: 8.002s
[2K
| RMSProp | epoch: 024 | loss: 0.02927 - acc: 0.9910 -- iter: 0384/1584
[A[ATraining Step: 1163  | total loss: [1m[32m0.03204[0m[0m | time: 8.666s
[2K
| RMSProp | epoch: 024 | loss: 0.03204 - acc: 0.9887 -- iter: 0416/1584
[A[ATraining Step: 1164  | total loss: [1m[32m0.07830[0m[0m | time: 9.330s
[2K
| RMSProp | epoch: 024 | loss: 0.07830 - acc: 0.9742 -- iter: 0448/1584
[A[ATraining Step: 1165  | total loss: [1m[32m0.09059[0m[0m | time: 9.983s
[2K
| RMSProp | epoch: 024 | loss: 0.09059 - acc: 0.9643 -- iter: 0480/1584
[A[ATraining Step: 1166  | total loss: [1m[32m0.08341[0m[0m | time: 10.648s
[2K
| RMSProp | epoch: 024 | loss: 0.08341 - acc: 0.9679 -- iter: 0512/1584
[A[ATraining Step: 1167  | total loss: [1m[32m0.08522[0m[0m | time: 11.339s
[2K
| RMSProp | epoch: 024 | loss: 0.08522 - acc: 0.9680 -- iter: 0544/1584
[A[ATraining Step: 1168  | total loss: [1m[32m0.08740[0m[0m | time: 11.974s
[2K
| RMSProp | epoch: 024 | loss: 0.08740 - acc: 0.9649 -- iter: 0576/1584
[A[ATraining Step: 1169  | total loss: [1m[32m0.09224[0m[0m | time: 12.648s
[2K
| RMSProp | epoch: 024 | loss: 0.09224 - acc: 0.9653 -- iter: 0608/1584
[A[ATraining Step: 1170  | total loss: [1m[32m0.09167[0m[0m | time: 13.295s
[2K
| RMSProp | epoch: 024 | loss: 0.09167 - acc: 0.9625 -- iter: 0640/1584
[A[ATraining Step: 1171  | total loss: [1m[32m0.08849[0m[0m | time: 13.963s
[2K
| RMSProp | epoch: 024 | loss: 0.08849 - acc: 0.9632 -- iter: 0672/1584
[A[ATraining Step: 1172  | total loss: [1m[32m0.08175[0m[0m | time: 14.310s
[2K
| RMSProp | epoch: 024 | loss: 0.08175 - acc: 0.9668 -- iter: 0704/1584
[A[ATraining Step: 1173  | total loss: [1m[32m0.07390[0m[0m | time: 14.675s
[2K
| RMSProp | epoch: 024 | loss: 0.07390 - acc: 0.9702 -- iter: 0736/1584
[A[ATraining Step: 1174  | total loss: [1m[32m0.06661[0m[0m | time: 15.336s
[2K
| RMSProp | epoch: 024 | loss: 0.06661 - acc: 0.9731 -- iter: 0768/1584
[A[ATraining Step: 1175  | total loss: [1m[32m0.06125[0m[0m | time: 15.987s
[2K
| RMSProp | epoch: 024 | loss: 0.06125 - acc: 0.9758 -- iter: 0800/1584
[A[ATraining Step: 1176  | total loss: [1m[32m0.05767[0m[0m | time: 16.634s
[2K
| RMSProp | epoch: 024 | loss: 0.05767 - acc: 0.9782 -- iter: 0832/1584
[A[ATraining Step: 1177  | total loss: [1m[32m0.07266[0m[0m | time: 17.330s
[2K
| RMSProp | epoch: 024 | loss: 0.07266 - acc: 0.9742 -- iter: 0864/1584
[A[ATraining Step: 1178  | total loss: [1m[32m0.07720[0m[0m | time: 18.426s
[2K
| RMSProp | epoch: 024 | loss: 0.07720 - acc: 0.9736 -- iter: 0896/1584
[A[ATraining Step: 1179  | total loss: [1m[32m0.07004[0m[0m | time: 19.437s
[2K
| RMSProp | epoch: 024 | loss: 0.07004 - acc: 0.9763 -- iter: 0928/1584
[A[ATraining Step: 1180  | total loss: [1m[32m0.06391[0m[0m | time: 20.273s
[2K
| RMSProp | epoch: 024 | loss: 0.06391 - acc: 0.9786 -- iter: 0960/1584
[A[ATraining Step: 1181  | total loss: [1m[32m0.05943[0m[0m | time: 21.110s
[2K
| RMSProp | epoch: 024 | loss: 0.05943 - acc: 0.9808 -- iter: 0992/1584
[A[ATraining Step: 1182  | total loss: [1m[32m0.05411[0m[0m | time: 22.053s
[2K
| RMSProp | epoch: 024 | loss: 0.05411 - acc: 0.9827 -- iter: 1024/1584
[A[ATraining Step: 1183  | total loss: [1m[32m0.04961[0m[0m | time: 22.976s
[2K
| RMSProp | epoch: 024 | loss: 0.04961 - acc: 0.9844 -- iter: 1056/1584
[A[ATraining Step: 1184  | total loss: [1m[32m0.04660[0m[0m | time: 23.846s
[2K
| RMSProp | epoch: 024 | loss: 0.04660 - acc: 0.9860 -- iter: 1088/1584
[A[ATraining Step: 1185  | total loss: [1m[32m0.04244[0m[0m | time: 24.759s
[2K
| RMSProp | epoch: 024 | loss: 0.04244 - acc: 0.9874 -- iter: 1120/1584
[A[ATraining Step: 1186  | total loss: [1m[32m0.03866[0m[0m | time: 25.651s
[2K
| RMSProp | epoch: 024 | loss: 0.03866 - acc: 0.9886 -- iter: 1152/1584
[A[ATraining Step: 1187  | total loss: [1m[32m0.05632[0m[0m | time: 26.550s
[2K
| RMSProp | epoch: 024 | loss: 0.05632 - acc: 0.9867 -- iter: 1184/1584
[A[ATraining Step: 1188  | total loss: [1m[32m0.06152[0m[0m | time: 27.432s
[2K
| RMSProp | epoch: 024 | loss: 0.06152 - acc: 0.9849 -- iter: 1216/1584
[A[ATraining Step: 1189  | total loss: [1m[32m0.06697[0m[0m | time: 28.263s
[2K
| RMSProp | epoch: 024 | loss: 0.06697 - acc: 0.9801 -- iter: 1248/1584
[A[ATraining Step: 1190  | total loss: [1m[32m0.06606[0m[0m | time: 29.239s
[2K
| RMSProp | epoch: 024 | loss: 0.06606 - acc: 0.9790 -- iter: 1280/1584
[A[ATraining Step: 1191  | total loss: [1m[32m0.06209[0m[0m | time: 30.261s
[2K
| RMSProp | epoch: 024 | loss: 0.06209 - acc: 0.9811 -- iter: 1312/1584
[A[ATraining Step: 1192  | total loss: [1m[32m0.07080[0m[0m | time: 31.222s
[2K
| RMSProp | epoch: 024 | loss: 0.07080 - acc: 0.9799 -- iter: 1344/1584
[A[ATraining Step: 1193  | total loss: [1m[32m0.06465[0m[0m | time: 31.950s
[2K
| RMSProp | epoch: 024 | loss: 0.06465 - acc: 0.9819 -- iter: 1376/1584
[A[ATraining Step: 1194  | total loss: [1m[32m0.05898[0m[0m | time: 32.803s
[2K
| RMSProp | epoch: 024 | loss: 0.05898 - acc: 0.9837 -- iter: 1408/1584
[A[ATraining Step: 1195  | total loss: [1m[32m0.05379[0m[0m | time: 33.695s
[2K
| RMSProp | epoch: 024 | loss: 0.05379 - acc: 0.9853 -- iter: 1440/1584
[A[ATraining Step: 1196  | total loss: [1m[32m0.04899[0m[0m | time: 34.594s
[2K
| RMSProp | epoch: 024 | loss: 0.04899 - acc: 0.9868 -- iter: 1472/1584
[A[ATraining Step: 1197  | total loss: [1m[32m0.04461[0m[0m | time: 35.488s
[2K
| RMSProp | epoch: 024 | loss: 0.04461 - acc: 0.9881 -- iter: 1504/1584
[A[ATraining Step: 1198  | total loss: [1m[32m0.04071[0m[0m | time: 36.422s
[2K
| RMSProp | epoch: 024 | loss: 0.04071 - acc: 0.9893 -- iter: 1536/1584
[A[ATraining Step: 1199  | total loss: [1m[32m0.03745[0m[0m | time: 37.350s
[2K
| RMSProp | epoch: 024 | loss: 0.03745 - acc: 0.9904 -- iter: 1568/1584
[A[ATraining Step: 1200  | total loss: [1m[32m0.03400[0m[0m | time: 45.664s
[2K
| RMSProp | epoch: 024 | loss: 0.03400 - acc: 0.9913 | val_loss: 0.83635 - val_acc: 0.8266 -- iter: 1584/1584
--
Training Step: 1201  | total loss: [1m[32m0.03082[0m[0m | time: 5.397s
[2K
| RMSProp | epoch: 025 | loss: 0.03082 - acc: 0.9922 -- iter: 0032/1584
[A[ATraining Step: 1202  | total loss: [1m[32m0.02797[0m[0m | time: 23.767s
[2K
| RMSProp | epoch: 025 | loss: 0.02797 - acc: 0.9930 -- iter: 0064/1584
[A[ATraining Step: 1203  | total loss: [1m[32m0.02528[0m[0m | time: 39.620s
[2K
| RMSProp | epoch: 025 | loss: 0.02528 - acc: 0.9937 -- iter: 0096/1584
[A[ATraining Step: 1204  | total loss: [1m[32m0.03568[0m[0m | time: 53.485s
[2K
| RMSProp | epoch: 025 | loss: 0.03568 - acc: 0.9912 -- iter: 0128/1584
[A[ATraining Step: 1205  | total loss: [1m[32m0.03254[0m[0m | time: 70.995s
[2K
| RMSProp | epoch: 025 | loss: 0.03254 - acc: 0.9921 -- iter: 0160/1584
[A[ATraining Step: 1206  | total loss: [1m[32m0.03179[0m[0m | time: 95.167s
[2K
| RMSProp | epoch: 025 | loss: 0.03179 - acc: 0.9929 -- iter: 0192/1584
[A[ATraining Step: 1207  | total loss: [1m[32m0.03266[0m[0m | time: 108.842s
[2K
| RMSProp | epoch: 025 | loss: 0.03266 - acc: 0.9904 -- iter: 0224/1584
[A[ATraining Step: 1208  | total loss: [1m[32m0.06156[0m[0m | time: 126.011s
[2K
| RMSProp | epoch: 025 | loss: 0.06156 - acc: 0.9852 -- iter: 0256/1584
[A[ATraining Step: 1209  | total loss: [1m[32m0.06455[0m[0m | time: 136.657s
[2K
| RMSProp | epoch: 025 | loss: 0.06455 - acc: 0.9835 -- iter: 0288/1584
[A[ATraining Step: 1210  | total loss: [1m[32m0.05904[0m[0m | time: 139.927s
[2K
| RMSProp | epoch: 025 | loss: 0.05904 - acc: 0.9852 -- iter: 0320/1584
[A[ATraining Step: 1211  | total loss: [1m[32m0.05355[0m[0m | time: 151.416s
[2K
| RMSProp | epoch: 025 | loss: 0.05355 - acc: 0.9866 -- iter: 0352/1584
[A[ATraining Step: 1212  | total loss: [1m[32m0.04844[0m[0m | time: 159.134s
[2K
| RMSProp | epoch: 025 | loss: 0.04844 - acc: 0.9880 -- iter: 0384/1584
[A[ATraining Step: 1213  | total loss: [1m[32m0.04751[0m[0m | time: 177.065s
[2K
| RMSProp | epoch: 025 | loss: 0.04751 - acc: 0.9861 -- iter: 0416/1584
[A[ATraining Step: 1214  | total loss: [1m[32m0.05651[0m[0m | time: 201.737s
[2K
| RMSProp | epoch: 025 | loss: 0.05651 - acc: 0.9812 -- iter: 0448/1584
[A[ATraining Step: 1215  | total loss: [1m[32m0.05168[0m[0m | time: 212.534s
[2K
| RMSProp | epoch: 025 | loss: 0.05168 - acc: 0.9831 -- iter: 0480/1584
[A[ATraining Step: 1216  | total loss: [1m[32m0.07331[0m[0m | time: 223.414s
[2K
| RMSProp | epoch: 025 | loss: 0.07331 - acc: 0.9785 -- iter: 0512/1584
[A[ATraining Step: 1217  | total loss: [1m[32m0.06703[0m[0m | time: 230.245s
[2K
| RMSProp | epoch: 025 | loss: 0.06703 - acc: 0.9807 -- iter: 0544/1584
[A[ATraining Step: 1218  | total loss: [1m[32m0.06201[0m[0m | time: 236.152s
[2K
| RMSProp | epoch: 025 | loss: 0.06201 - acc: 0.9826 -- iter: 0576/1584
[A[ATraining Step: 1219  | total loss: [1m[32m0.06078[0m[0m | time: 237.297s
[2K
| RMSProp | epoch: 025 | loss: 0.06078 - acc: 0.9812 -- iter: 0608/1584
[A[ATraining Step: 1220  | total loss: [1m[32m0.05941[0m[0m | time: 238.591s
[2K
| RMSProp | epoch: 025 | loss: 0.05941 - acc: 0.9831 -- iter: 0640/1584
[A[ATraining Step: 1221  | total loss: [1m[32m0.06365[0m[0m | time: 239.897s
[2K
| RMSProp | epoch: 025 | loss: 0.06365 - acc: 0.9817 -- iter: 0672/1584
[A[ATraining Step: 1222  | total loss: [1m[32m0.06215[0m[0m | time: 241.158s
[2K
| RMSProp | epoch: 025 | loss: 0.06215 - acc: 0.9804 -- iter: 0704/1584
[A[ATraining Step: 1223  | total loss: [1m[32m0.06155[0m[0m | time: 241.878s
[2K
| RMSProp | epoch: 025 | loss: 0.06155 - acc: 0.9792 -- iter: 0736/1584
[A[ATraining Step: 1224  | total loss: [1m[32m0.06817[0m[0m | time: 242.637s
[2K
| RMSProp | epoch: 025 | loss: 0.06817 - acc: 0.9750 -- iter: 0768/1584
[A[ATraining Step: 1225  | total loss: [1m[32m0.06314[0m[0m | time: 243.941s
[2K
| RMSProp | epoch: 025 | loss: 0.06314 - acc: 0.9775 -- iter: 0800/1584
[A[ATraining Step: 1226  | total loss: [1m[32m0.05765[0m[0m | time: 245.197s
[2K
| RMSProp | epoch: 025 | loss: 0.05765 - acc: 0.9798 -- iter: 0832/1584
[A[ATraining Step: 1227  | total loss: [1m[32m0.05239[0m[0m | time: 246.266s
[2K
| RMSProp | epoch: 025 | loss: 0.05239 - acc: 0.9818 -- iter: 0864/1584
[A[ATraining Step: 1228  | total loss: [1m[32m0.04807[0m[0m | time: 247.176s
[2K
| RMSProp | epoch: 025 | loss: 0.04807 - acc: 0.9836 -- iter: 0896/1584
[A[ATraining Step: 1229  | total loss: [1m[32m0.04384[0m[0m | time: 248.455s
[2K
| RMSProp | epoch: 025 | loss: 0.04384 - acc: 0.9853 -- iter: 0928/1584
[A[ATraining Step: 1230  | total loss: [1m[32m0.03996[0m[0m | time: 249.607s
[2K
| RMSProp | epoch: 025 | loss: 0.03996 - acc: 0.9867 -- iter: 0960/1584
[A[ATraining Step: 1231  | total loss: [1m[32m0.03609[0m[0m | time: 254.147s
[2K
| RMSProp | epoch: 025 | loss: 0.03609 - acc: 0.9881 -- iter: 0992/1584
[A[ATraining Step: 1232  | total loss: [1m[32m0.03399[0m[0m | time: 268.094s
[2K
| RMSProp | epoch: 025 | loss: 0.03399 - acc: 0.9893 -- iter: 1024/1584
[A[ATraining Step: 1233  | total loss: [1m[32m0.05244[0m[0m | time: 277.921s
[2K
| RMSProp | epoch: 025 | loss: 0.05244 - acc: 0.9872 -- iter: 1056/1584
[A[ATraining Step: 1234  | total loss: [1m[32m0.08208[0m[0m | time: 291.229s
[2K
| RMSProp | epoch: 025 | loss: 0.08208 - acc: 0.9791 -- iter: 1088/1584
[A[ATraining Step: 1235  | total loss: [1m[32m0.07523[0m[0m | time: 306.047s
[2K
| RMSProp | epoch: 025 | loss: 0.07523 - acc: 0.9812 -- iter: 1120/1584
[A[ATraining Step: 1236  | total loss: [1m[32m0.07714[0m[0m | time: 343.462s
[2K
| RMSProp | epoch: 025 | loss: 0.07714 - acc: 0.9800 -- iter: 1152/1584
[A[ATraining Step: 1237  | total loss: [1m[32m0.07122[0m[0m | time: 364.196s
[2K
| RMSProp | epoch: 025 | loss: 0.07122 - acc: 0.9820 -- iter: 1184/1584
[A[ATraining Step: 1238  | total loss: [1m[32m0.06452[0m[0m | time: 386.206s
[2K
| RMSProp | epoch: 025 | loss: 0.06452 - acc: 0.9838 -- iter: 1216/1584
[A[ATraining Step: 1239  | total loss: [1m[32m0.07012[0m[0m | time: 401.466s
[2K
| RMSProp | epoch: 025 | loss: 0.07012 - acc: 0.9823 -- iter: 1248/1584
[A[ATraining Step: 1240  | total loss: [1m[32m0.07730[0m[0m | time: 412.086s
[2K
| RMSProp | epoch: 025 | loss: 0.07730 - acc: 0.9778 -- iter: 1280/1584
[A[ATraining Step: 1241  | total loss: [1m[32m0.07054[0m[0m | time: 425.190s
[2K
| RMSProp | epoch: 025 | loss: 0.07054 - acc: 0.9800 -- iter: 1312/1584
[A[ATraining Step: 1242  | total loss: [1m[32m0.08660[0m[0m | time: 450.599s
[2K
| RMSProp | epoch: 025 | loss: 0.08660 - acc: 0.9789 -- iter: 1344/1584
[A[ATraining Step: 1243  | total loss: [1m[32m0.12533[0m[0m | time: 475.290s
[2K
| RMSProp | epoch: 025 | loss: 0.12533 - acc: 0.9747 -- iter: 1376/1584
[A[ATraining Step: 1244  | total loss: [1m[32m0.12039[0m[0m | time: 500.141s
[2K
| RMSProp | epoch: 025 | loss: 0.12039 - acc: 0.9773 -- iter: 1408/1584
[A[ATraining Step: 1245  | total loss: [1m[32m0.11305[0m[0m | time: 509.628s
[2K
| RMSProp | epoch: 025 | loss: 0.11305 - acc: 0.9764 -- iter: 1440/1584
[A[ATraining Step: 1246  | total loss: [1m[32m0.10348[0m[0m | time: 534.054s
[2K
| RMSProp | epoch: 025 | loss: 0.10348 - acc: 0.9788 -- iter: 1472/1584
[A[ATraining Step: 1247  | total loss: [1m[32m0.09416[0m[0m | time: 547.454s
[2K
| RMSProp | epoch: 025 | loss: 0.09416 - acc: 0.9809 -- iter: 1504/1584
[A[ATraining Step: 1248  | total loss: [1m[32m0.08554[0m[0m | time: 548.667s
[2K
| RMSProp | epoch: 025 | loss: 0.08554 - acc: 0.9828 -- iter: 1536/1584
[A[ATraining Step: 1249  | total loss: [1m[32m0.08452[0m[0m | time: 549.863s
[2K
| RMSProp | epoch: 025 | loss: 0.08452 - acc: 0.9814 -- iter: 1568/1584
[A[ATraining Step: 1250  | total loss: [1m[32m0.07689[0m[0m | time: 555.143s
[2K
| RMSProp | epoch: 025 | loss: 0.07689 - acc: 0.9833 | val_loss: 0.74768 - val_acc: 0.8226 -- iter: 1584/1584
--
Training Step: 1251  | total loss: [1m[32m0.07021[0m[0m | time: 1.402s
[2K
| RMSProp | epoch: 026 | loss: 0.07021 - acc: 0.9849 -- iter: 0032/1584
[A[ATraining Step: 1252  | total loss: [1m[32m0.06346[0m[0m | time: 2.651s
[2K
| RMSProp | epoch: 026 | loss: 0.06346 - acc: 0.9864 -- iter: 0064/1584
[A[ATraining Step: 1253  | total loss: [1m[32m0.05750[0m[0m | time: 4.055s
[2K
| RMSProp | epoch: 026 | loss: 0.05750 - acc: 0.9878 -- iter: 0096/1584
[A[ATraining Step: 1254  | total loss: [1m[32m0.05200[0m[0m | time: 7.087s
[2K
| RMSProp | epoch: 026 | loss: 0.05200 - acc: 0.9890 -- iter: 0128/1584
[A[ATraining Step: 1255  | total loss: [1m[32m0.04700[0m[0m | time: 15.545s
[2K
| RMSProp | epoch: 026 | loss: 0.04700 - acc: 0.9901 -- iter: 0160/1584
[A[ATraining Step: 1256  | total loss: [1m[32m0.04255[0m[0m | time: 24.718s
[2K
| RMSProp | epoch: 026 | loss: 0.04255 - acc: 0.9911 -- iter: 0192/1584
[A[ATraining Step: 1257  | total loss: [1m[32m0.04371[0m[0m | time: 54.230s
[2K
| RMSProp | epoch: 026 | loss: 0.04371 - acc: 0.9889 -- iter: 0224/1584
[A[ATraining Step: 1258  | total loss: [1m[32m0.03988[0m[0m | time: 68.548s
[2K
| RMSProp | epoch: 026 | loss: 0.03988 - acc: 0.9900 -- iter: 0256/1584
[A[ATraining Step: 1259  | total loss: [1m[32m0.04148[0m[0m | time: 90.094s
[2K
| RMSProp | epoch: 026 | loss: 0.04148 - acc: 0.9879 -- iter: 0288/1584
[A[ATraining Step: 1260  | total loss: [1m[32m0.05066[0m[0m | time: 99.166s
[2K
| RMSProp | epoch: 026 | loss: 0.05066 - acc: 0.9766 -- iter: 0320/1584
[A[ATraining Step: 1261  | total loss: [1m[32m0.06578[0m[0m | time: 115.328s
[2K
| RMSProp | epoch: 026 | loss: 0.06578 - acc: 0.9727 -- iter: 0352/1584
[A[ATraining Step: 1262  | total loss: [1m[32m0.06440[0m[0m | time: 122.781s
[2K
| RMSProp | epoch: 026 | loss: 0.06440 - acc: 0.9723 -- iter: 0384/1584
[A[ATraining Step: 1263  | total loss: [1m[32m0.05952[0m[0m | time: 160.468s
[2K
| RMSProp | epoch: 026 | loss: 0.05952 - acc: 0.9750 -- iter: 0416/1584
[A[ATraining Step: 1264  | total loss: [1m[32m0.06680[0m[0m | time: 168.906s
[2K
| RMSProp | epoch: 026 | loss: 0.06680 - acc: 0.9744 -- iter: 0448/1584
[A[ATraining Step: 1265  | total loss: [1m[32m0.07359[0m[0m | time: 173.748s
[2K
| RMSProp | epoch: 026 | loss: 0.07359 - acc: 0.9739 -- iter: 0480/1584
[A[ATraining Step: 1266  | total loss: [1m[32m0.06835[0m[0m | time: 192.383s
[2K
| RMSProp | epoch: 026 | loss: 0.06835 - acc: 0.9765 -- iter: 0512/1584
[A[ATraining Step: 1267  | total loss: [1m[32m0.06207[0m[0m | time: 202.847s
[2K
| RMSProp | epoch: 026 | loss: 0.06207 - acc: 0.9788 -- iter: 0544/1584
[A[ATraining Step: 1268  | total loss: [1m[32m0.05640[0m[0m | time: 204.061s
[2K
| RMSProp | epoch: 026 | loss: 0.05640 - acc: 0.9809 -- iter: 0576/1584
[A[ATraining Step: 1269  | total loss: [1m[32m0.05119[0m[0m | time: 216.346s
[2K
| RMSProp | epoch: 026 | loss: 0.05119 - acc: 0.9828 -- iter: 0608/1584
[A[ATraining Step: 1270  | total loss: [1m[32m0.04627[0m[0m | time: 232.328s
[2K
| RMSProp | epoch: 026 | loss: 0.04627 - acc: 0.9846 -- iter: 0640/1584
[A[ATraining Step: 1271  | total loss: [1m[32m0.04187[0m[0m | time: 257.226s
[2K
| RMSProp | epoch: 026 | loss: 0.04187 - acc: 0.9861 -- iter: 0672/1584
[A[ATraining Step: 1272  | total loss: [1m[32m0.03799[0m[0m | time: 274.178s
[2K
| RMSProp | epoch: 026 | loss: 0.03799 - acc: 0.9875 -- iter: 0704/1584
[A[ATraining Step: 1273  | total loss: [1m[32m0.03442[0m[0m | time: 288.990s
[2K
| RMSProp | epoch: 026 | loss: 0.03442 - acc: 0.9887 -- iter: 0736/1584
[A[ATraining Step: 1274  | total loss: [1m[32m0.03189[0m[0m | time: 293.423s
[2K
| RMSProp | epoch: 026 | loss: 0.03189 - acc: 0.9899 -- iter: 0768/1584
[A[ATraining Step: 1275  | total loss: [1m[32m0.03138[0m[0m | time: 299.005s
[2K
| RMSProp | epoch: 026 | loss: 0.03138 - acc: 0.9909 -- iter: 0800/1584
[A[ATraining Step: 1276  | total loss: [1m[32m0.02857[0m[0m | time: 305.706s
[2K
| RMSProp | epoch: 026 | loss: 0.02857 - acc: 0.9918 -- iter: 0832/1584
[A[ATraining Step: 1277  | total loss: [1m[32m0.02720[0m[0m | time: 309.639s
[2K
| RMSProp | epoch: 026 | loss: 0.02720 - acc: 0.9926 -- iter: 0864/1584
[A[ATraining Step: 1278  | total loss: [1m[32m0.04025[0m[0m | time: 313.433s
[2K
| RMSProp | epoch: 026 | loss: 0.04025 - acc: 0.9902 -- iter: 0896/1584
[A[ATraining Step: 1279  | total loss: [1m[32m0.04678[0m[0m | time: 316.743s
[2K
| RMSProp | epoch: 026 | loss: 0.04678 - acc: 0.9881 -- iter: 0928/1584
[A[ATraining Step: 1280  | total loss: [1m[32m0.08782[0m[0m | time: 319.899s
[2K
| RMSProp | epoch: 026 | loss: 0.08782 - acc: 0.9736 -- iter: 0960/1584
[A[ATraining Step: 1281  | total loss: [1m[32m0.08006[0m[0m | time: 331.433s
[2K
| RMSProp | epoch: 026 | loss: 0.08006 - acc: 0.9763 -- iter: 0992/1584
[A[ATraining Step: 1282  | total loss: [1m[32m0.07441[0m[0m | time: 347.039s
[2K
| RMSProp | epoch: 026 | loss: 0.07441 - acc: 0.9787 -- iter: 1024/1584
[A[ATraining Step: 1283  | total loss: [1m[32m0.08035[0m[0m | time: 353.753s
[2K
| RMSProp | epoch: 026 | loss: 0.08035 - acc: 0.9745 -- iter: 1056/1584
[A[ATraining Step: 1284  | total loss: [1m[32m0.08854[0m[0m | time: 354.990s
[2K
| RMSProp | epoch: 026 | loss: 0.08854 - acc: 0.9708 -- iter: 1088/1584
[A[ATraining Step: 1285  | total loss: [1m[32m0.09328[0m[0m | time: 356.251s
[2K
| RMSProp | epoch: 026 | loss: 0.09328 - acc: 0.9675 -- iter: 1120/1584
[A[ATraining Step: 1286  | total loss: [1m[32m0.08901[0m[0m | time: 357.388s
[2K
| RMSProp | epoch: 026 | loss: 0.08901 - acc: 0.9676 -- iter: 1152/1584
[A[ATraining Step: 1287  | total loss: [1m[32m0.08961[0m[0m | time: 358.668s
[2K
| RMSProp | epoch: 026 | loss: 0.08961 - acc: 0.9677 -- iter: 1184/1584
[A[ATraining Step: 1288  | total loss: [1m[32m0.08174[0m[0m | time: 359.931s
[2K
| RMSProp | epoch: 026 | loss: 0.08174 - acc: 0.9710 -- iter: 1216/1584
[A[ATraining Step: 1289  | total loss: [1m[32m0.07495[0m[0m | time: 361.399s
[2K
| RMSProp | epoch: 026 | loss: 0.07495 - acc: 0.9739 -- iter: 1248/1584
[A[ATraining Step: 1290  | total loss: [1m[32m0.07893[0m[0m | time: 362.718s
[2K
| RMSProp | epoch: 026 | loss: 0.07893 - acc: 0.9734 -- iter: 1280/1584
[A[ATraining Step: 1291  | total loss: [1m[32m0.07263[0m[0m | time: 363.917s
[2K
| RMSProp | epoch: 026 | loss: 0.07263 - acc: 0.9760 -- iter: 1312/1584
[A[ATraining Step: 1292  | total loss: [1m[32m0.06610[0m[0m | time: 365.429s
[2K
| RMSProp | epoch: 026 | loss: 0.06610 - acc: 0.9784 -- iter: 1344/1584
[A[ATraining Step: 1293  | total loss: [1m[32m0.06119[0m[0m | time: 367.031s
[2K
| RMSProp | epoch: 026 | loss: 0.06119 - acc: 0.9806 -- iter: 1376/1584
[A[ATraining Step: 1294  | total loss: [1m[32m0.07075[0m[0m | time: 372.497s
[2K
| RMSProp | epoch: 026 | loss: 0.07075 - acc: 0.9794 -- iter: 1408/1584
[A[ATraining Step: 1295  | total loss: [1m[32m0.06928[0m[0m | time: 388.784s
[2K
| RMSProp | epoch: 026 | loss: 0.06928 - acc: 0.9783 -- iter: 1440/1584
[A[ATraining Step: 1296  | total loss: [1m[32m0.06319[0m[0m | time: 402.544s
[2K
| RMSProp | epoch: 026 | loss: 0.06319 - acc: 0.9805 -- iter: 1472/1584
[A[ATraining Step: 1297  | total loss: [1m[32m0.05938[0m[0m | time: 411.010s
[2K
| RMSProp | epoch: 026 | loss: 0.05938 - acc: 0.9824 -- iter: 1504/1584
[A[ATraining Step: 1298  | total loss: [1m[32m0.05632[0m[0m | time: 419.134s
[2K
| RMSProp | epoch: 026 | loss: 0.05632 - acc: 0.9842 -- iter: 1536/1584
[A[ATraining Step: 1299  | total loss: [1m[32m0.05198[0m[0m | time: 428.388s
[2K
| RMSProp | epoch: 026 | loss: 0.05198 - acc: 0.9858 -- iter: 1568/1584
[A[ATraining Step: 1300  | total loss: [1m[32m0.04750[0m[0m | time: 577.801s
[2K
| RMSProp | epoch: 026 | loss: 0.04750 - acc: 0.9872 | val_loss: 0.75839 - val_acc: 0.8226 -- iter: 1584/1584
--
Training Step: 1301  | total loss: [1m[32m0.04309[0m[0m | time: 2.251s
[2K
| RMSProp | epoch: 027 | loss: 0.04309 - acc: 0.9885 -- iter: 0032/1584
[A[ATraining Step: 1302  | total loss: [1m[32m0.03892[0m[0m | time: 8.563s
[2K
| RMSProp | epoch: 027 | loss: 0.03892 - acc: 0.9896 -- iter: 0064/1584
[A[ATraining Step: 1303  | total loss: [1m[32m0.03525[0m[0m | time: 9.756s
[2K
| RMSProp | epoch: 027 | loss: 0.03525 - acc: 0.9907 -- iter: 0096/1584
[A[ATraining Step: 1304  | total loss: [1m[32m0.03187[0m[0m | time: 10.823s
[2K
| RMSProp | epoch: 027 | loss: 0.03187 - acc: 0.9916 -- iter: 0128/1584
[A[ATraining Step: 1305  | total loss: [1m[32m0.02881[0m[0m | time: 12.016s
[2K
| RMSProp | epoch: 027 | loss: 0.02881 - acc: 0.9924 -- iter: 0160/1584
[A[ATraining Step: 1306  | total loss: [1m[32m0.02603[0m[0m | time: 13.284s
[2K
| RMSProp | epoch: 027 | loss: 0.02603 - acc: 0.9932 -- iter: 0192/1584
[A[ATraining Step: 1307  | total loss: [1m[32m0.02359[0m[0m | time: 14.631s
[2K
| RMSProp | epoch: 027 | loss: 0.02359 - acc: 0.9939 -- iter: 0224/1584
[A[ATraining Step: 1308  | total loss: [1m[32m0.02129[0m[0m | time: 16.085s
[2K
| RMSProp | epoch: 027 | loss: 0.02129 - acc: 0.9945 -- iter: 0256/1584
[A[ATraining Step: 1309  | total loss: [1m[32m0.02467[0m[0m | time: 17.360s
[2K
| RMSProp | epoch: 027 | loss: 0.02467 - acc: 0.9919 -- iter: 0288/1584
[A[ATraining Step: 1310  | total loss: [1m[32m0.07358[0m[0m | time: 18.785s
[2K
| RMSProp | epoch: 027 | loss: 0.07358 - acc: 0.9771 -- iter: 0320/1584
[A[ATraining Step: 1311  | total loss: [1m[32m0.08567[0m[0m | time: 20.228s
[2K
| RMSProp | epoch: 027 | loss: 0.08567 - acc: 0.9731 -- iter: 0352/1584
[A[ATraining Step: 1312  | total loss: [1m[32m0.09915[0m[0m | time: 22.011s
[2K
| RMSProp | epoch: 027 | loss: 0.09915 - acc: 0.9665 -- iter: 0384/1584
[A[ATraining Step: 1313  | total loss: [1m[32m0.09427[0m[0m | time: 37.892s
[2K
| RMSProp | epoch: 027 | loss: 0.09427 - acc: 0.9667 -- iter: 0416/1584
[A[ATraining Step: 1314  | total loss: [1m[32m0.08590[0m[0m | time: 44.602s
[2K
| RMSProp | epoch: 027 | loss: 0.08590 - acc: 0.9700 -- iter: 0448/1584
[A[ATraining Step: 1315  | total loss: [1m[32m0.07847[0m[0m | time: 62.408s
[2K
| RMSProp | epoch: 027 | loss: 0.07847 - acc: 0.9730 -- iter: 0480/1584
[A[ATraining Step: 1316  | total loss: [1m[32m0.07299[0m[0m | time: 76.789s
[2K
| RMSProp | epoch: 027 | loss: 0.07299 - acc: 0.9757 -- iter: 0512/1584
[A[ATraining Step: 1317  | total loss: [1m[32m0.07116[0m[0m | time: 81.799s
[2K
| RMSProp | epoch: 027 | loss: 0.07116 - acc: 0.9750 -- iter: 0544/1584
[A[ATraining Step: 1318  | total loss: [1m[32m0.06546[0m[0m | time: 97.989s
[2K
| RMSProp | epoch: 027 | loss: 0.06546 - acc: 0.9775 -- iter: 0576/1584
[A[ATraining Step: 1319  | total loss: [1m[32m0.05937[0m[0m | time: 108.500s
[2K
| RMSProp | epoch: 027 | loss: 0.05937 - acc: 0.9798 -- iter: 0608/1584
[A[ATraining Step: 1320  | total loss: [1m[32m0.05368[0m[0m | time: 117.636s
[2K
| RMSProp | epoch: 027 | loss: 0.05368 - acc: 0.9818 -- iter: 0640/1584
[A[ATraining Step: 1321  | total loss: [1m[32m0.04867[0m[0m | time: 125.786s
[2K
| RMSProp | epoch: 027 | loss: 0.04867 - acc: 0.9836 -- iter: 0672/1584
[A[ATraining Step: 1322  | total loss: [1m[32m0.04430[0m[0m | time: 144.225s
[2K
| RMSProp | epoch: 027 | loss: 0.04430 - acc: 0.9852 -- iter: 0704/1584
[A[ATraining Step: 1323  | total loss: [1m[32m0.04025[0m[0m | time: 151.630s
[2K
| RMSProp | epoch: 027 | loss: 0.04025 - acc: 0.9867 -- iter: 0736/1584
[A[ATraining Step: 1324  | total loss: [1m[32m0.03654[0m[0m | time: 157.585s
[2K
| RMSProp | epoch: 027 | loss: 0.03654 - acc: 0.9880 -- iter: 0768/1584
[A[ATraining Step: 1325  | total loss: [1m[32m0.03303[0m[0m | time: 158.511s
[2K
| RMSProp | epoch: 027 | loss: 0.03303 - acc: 0.9892 -- iter: 0800/1584
[A[ATraining Step: 1326  | total loss: [1m[32m0.02987[0m[0m | time: 159.174s
[2K
| RMSProp | epoch: 027 | loss: 0.02987 - acc: 0.9903 -- iter: 0832/1584
[A[ATraining Step: 1327  | total loss: [1m[32m0.02699[0m[0m | time: 160.352s
[2K
| RMSProp | epoch: 027 | loss: 0.02699 - acc: 0.9913 -- iter: 0864/1584
[A[ATraining Step: 1328  | total loss: [1m[32m0.02452[0m[0m | time: 161.434s
[2K
| RMSProp | epoch: 027 | loss: 0.02452 - acc: 0.9922 -- iter: 0896/1584
[A[ATraining Step: 1329  | total loss: [1m[32m0.02221[0m[0m | time: 162.584s
[2K
| RMSProp | epoch: 027 | loss: 0.02221 - acc: 0.9929 -- iter: 0928/1584
[A[ATraining Step: 1330  | total loss: [1m[32m0.02805[0m[0m | time: 163.874s
[2K
| RMSProp | epoch: 027 | loss: 0.02805 - acc: 0.9905 -- iter: 0960/1584
[A[ATraining Step: 1331  | total loss: [1m[32m0.04559[0m[0m | time: 165.297s
[2K
| RMSProp | epoch: 027 | loss: 0.04559 - acc: 0.9883 -- iter: 0992/1584
[A[ATraining Step: 1332  | total loss: [1m[32m0.09961[0m[0m | time: 166.718s
[2K
| RMSProp | epoch: 027 | loss: 0.09961 - acc: 0.9770 -- iter: 1024/1584
[A[ATraining Step: 1333  | total loss: [1m[32m0.09827[0m[0m | time: 167.945s
[2K
| RMSProp | epoch: 027 | loss: 0.09827 - acc: 0.9762 -- iter: 1056/1584
[A[ATraining Step: 1334  | total loss: [1m[32m0.09240[0m[0m | time: 169.184s
[2K
| RMSProp | epoch: 027 | loss: 0.09240 - acc: 0.9786 -- iter: 1088/1584
[A[ATraining Step: 1335  | total loss: [1m[32m0.08517[0m[0m | time: 170.631s
[2K
| RMSProp | epoch: 027 | loss: 0.08517 - acc: 0.9807 -- iter: 1120/1584
[A[ATraining Step: 1336  | total loss: [1m[32m0.07722[0m[0m | time: 171.944s
[2K
| RMSProp | epoch: 027 | loss: 0.07722 - acc: 0.9826 -- iter: 1152/1584
[A[ATraining Step: 1337  | total loss: [1m[32m0.07112[0m[0m | time: 173.250s
[2K
| RMSProp | epoch: 027 | loss: 0.07112 - acc: 0.9844 -- iter: 1184/1584
[A[ATraining Step: 1338  | total loss: [1m[32m0.06925[0m[0m | time: 181.877s
[2K
| RMSProp | epoch: 027 | loss: 0.06925 - acc: 0.9828 -- iter: 1216/1584
[A[ATraining Step: 1339  | total loss: [1m[32m0.08390[0m[0m | time: 195.385s
[2K
| RMSProp | epoch: 027 | loss: 0.08390 - acc: 0.9814 -- iter: 1248/1584
[A[ATraining Step: 1340  | total loss: [1m[32m0.07742[0m[0m | time: 208.549s
[2K
| RMSProp | epoch: 027 | loss: 0.07742 - acc: 0.9833 -- iter: 1280/1584
[A[ATraining Step: 1341  | total loss: [1m[32m0.07039[0m[0m | time: 218.859s
[2K
| RMSProp | epoch: 027 | loss: 0.07039 - acc: 0.9849 -- iter: 1312/1584
[A[ATraining Step: 1342  | total loss: [1m[32m0.06473[0m[0m | time: 222.364s
[2K
| RMSProp | epoch: 027 | loss: 0.06473 - acc: 0.9864 -- iter: 1344/1584
[A[ATraining Step: 1343  | total loss: [1m[32m0.05879[0m[0m | time: 230.278s
[2K
| RMSProp | epoch: 027 | loss: 0.05879 - acc: 0.9878 -- iter: 1376/1584
[A[ATraining Step: 1344  | total loss: [1m[32m0.05348[0m[0m | time: 240.160s
[2K
| RMSProp | epoch: 027 | loss: 0.05348 - acc: 0.9890 -- iter: 1408/1584
[A[ATraining Step: 1345  | total loss: [1m[32m0.10847[0m[0m | time: 245.740s
[2K
| RMSProp | epoch: 027 | loss: 0.10847 - acc: 0.9807 -- iter: 1440/1584
[A[ATraining Step: 1346  | total loss: [1m[32m0.10851[0m[0m | time: 252.500s
[2K
| RMSProp | epoch: 027 | loss: 0.10851 - acc: 0.9764 -- iter: 1472/1584
[A[ATraining Step: 1347  | total loss: [1m[32m0.10003[0m[0m | time: 268.351s
[2K
| RMSProp | epoch: 027 | loss: 0.10003 - acc: 0.9788 -- iter: 1504/1584
[A[ATraining Step: 1348  | total loss: [1m[32m0.09251[0m[0m | time: 270.587s
[2K
| RMSProp | epoch: 027 | loss: 0.09251 - acc: 0.9809 -- iter: 1536/1584
[A[ATraining Step: 1349  | total loss: [1m[32m0.08413[0m[0m | time: 271.742s
[2K
| RMSProp | epoch: 027 | loss: 0.08413 - acc: 0.9828 -- iter: 1568/1584
[A[ATraining Step: 1350  | total loss: [1m[32m0.07787[0m[0m | time: 276.871s
[2K
| RMSProp | epoch: 027 | loss: 0.07787 - acc: 0.9845 | val_loss: 0.67822 - val_acc: 0.8286 -- iter: 1584/1584
--
Training Step: 1351  | total loss: [1m[32m0.07068[0m[0m | time: 1.472s
[2K
| RMSProp | epoch: 028 | loss: 0.07068 - acc: 0.9861 -- iter: 0032/1584
[A[ATraining Step: 1352  | total loss: [1m[32m0.06774[0m[0m | time: 2.761s
[2K
| RMSProp | epoch: 028 | loss: 0.06774 - acc: 0.9843 -- iter: 0064/1584
[A[ATraining Step: 1353  | total loss: [1m[32m0.14609[0m[0m | time: 4.243s
[2K
| RMSProp | epoch: 028 | loss: 0.14609 - acc: 0.9672 -- iter: 0096/1584
[A[ATraining Step: 1354  | total loss: [1m[32m0.13352[0m[0m | time: 5.527s
[2K
| RMSProp | epoch: 028 | loss: 0.13352 - acc: 0.9704 -- iter: 0128/1584
[A[ATraining Step: 1355  | total loss: [1m[32m0.12084[0m[0m | time: 13.258s
[2K
| RMSProp | epoch: 028 | loss: 0.12084 - acc: 0.9734 -- iter: 0160/1584
[A[ATraining Step: 1356  | total loss: [1m[32m0.10923[0m[0m | time: 25.931s
[2K
| RMSProp | epoch: 028 | loss: 0.10923 - acc: 0.9761 -- iter: 0192/1584
[A[ATraining Step: 1357  | total loss: [1m[32m0.09882[0m[0m | time: 34.508s
[2K
| RMSProp | epoch: 028 | loss: 0.09882 - acc: 0.9785 -- iter: 0224/1584
[A[ATraining Step: 1358  | total loss: [1m[32m0.08947[0m[0m | time: 47.516s
[2K
| RMSProp | epoch: 028 | loss: 0.08947 - acc: 0.9806 -- iter: 0256/1584
[A[ATraining Step: 1359  | total loss: [1m[32m0.08103[0m[0m | time: 52.651s
[2K
| RMSProp | epoch: 028 | loss: 0.08103 - acc: 0.9825 -- iter: 0288/1584
[A[ATraining Step: 1360  | total loss: [1m[32m0.07539[0m[0m | time: 57.501s
[2K
| RMSProp | epoch: 028 | loss: 0.07539 - acc: 0.9843 -- iter: 0320/1584
[A[ATraining Step: 1361  | total loss: [1m[32m0.06857[0m[0m | time: 62.113s
[2K
| RMSProp | epoch: 028 | loss: 0.06857 - acc: 0.9859 -- iter: 0352/1584
[A[ATraining Step: 1362  | total loss: [1m[32m0.06202[0m[0m | time: 64.261s
[2K
| RMSProp | epoch: 028 | loss: 0.06202 - acc: 0.9873 -- iter: 0384/1584
[A[ATraining Step: 1363  | total loss: [1m[32m0.05591[0m[0m | time: 69.016s
[2K
| RMSProp | epoch: 028 | loss: 0.05591 - acc: 0.9885 -- iter: 0416/1584
[A[ATraining Step: 1364  | total loss: [1m[32m0.05171[0m[0m | time: 72.924s
[2K
| RMSProp | epoch: 028 | loss: 0.05171 - acc: 0.9897 -- iter: 0448/1584
[A[ATraining Step: 1365  | total loss: [1m[32m0.05563[0m[0m | time: 85.184s
[2K
| RMSProp | epoch: 028 | loss: 0.05563 - acc: 0.9876 -- iter: 0480/1584
[A[ATraining Step: 1366  | total loss: [1m[32m0.08168[0m[0m | time: 101.940s
[2K
| RMSProp | epoch: 028 | loss: 0.08168 - acc: 0.9857 -- iter: 0512/1584
[A[ATraining Step: 1367  | total loss: [1m[32m0.07383[0m[0m | time: 103.165s
[2K
| RMSProp | epoch: 028 | loss: 0.07383 - acc: 0.9871 -- iter: 0544/1584
[A[ATraining Step: 1368  | total loss: [1m[32m0.06705[0m[0m | time: 104.392s
[2K
| RMSProp | epoch: 028 | loss: 0.06705 - acc: 0.9884 -- iter: 0576/1584
[A[ATraining Step: 1369  | total loss: [1m[32m0.06069[0m[0m | time: 105.475s
[2K
| RMSProp | epoch: 028 | loss: 0.06069 - acc: 0.9896 -- iter: 0608/1584
[A[ATraining Step: 1370  | total loss: [1m[32m0.05501[0m[0m | time: 106.698s
[2K
| RMSProp | epoch: 028 | loss: 0.05501 - acc: 0.9906 -- iter: 0640/1584
[A[ATraining Step: 1371  | total loss: [1m[32m0.04972[0m[0m | time: 107.973s
[2K
| RMSProp | epoch: 028 | loss: 0.04972 - acc: 0.9916 -- iter: 0672/1584
[A[ATraining Step: 1372  | total loss: [1m[32m0.04493[0m[0m | time: 109.252s
[2K
| RMSProp | epoch: 028 | loss: 0.04493 - acc: 0.9924 -- iter: 0704/1584
[A[ATraining Step: 1373  | total loss: [1m[32m0.04068[0m[0m | time: 110.531s
[2K
| RMSProp | epoch: 028 | loss: 0.04068 - acc: 0.9932 -- iter: 0736/1584
[A[ATraining Step: 1374  | total loss: [1m[32m0.03677[0m[0m | time: 111.789s
[2K
| RMSProp | epoch: 028 | loss: 0.03677 - acc: 0.9939 -- iter: 0768/1584
[A[ATraining Step: 1375  | total loss: [1m[32m0.03328[0m[0m | time: 113.036s
[2K
| RMSProp | epoch: 028 | loss: 0.03328 - acc: 0.9945 -- iter: 0800/1584
[A[ATraining Step: 1376  | total loss: [1m[32m0.05884[0m[0m | time: 113.861s
[2K
| RMSProp | epoch: 028 | loss: 0.05884 - acc: 0.9919 -- iter: 0832/1584
[A[ATraining Step: 1377  | total loss: [1m[32m0.05367[0m[0m | time: 114.640s
[2K
| RMSProp | epoch: 028 | loss: 0.05367 - acc: 0.9927 -- iter: 0864/1584
[A[ATraining Step: 1378  | total loss: [1m[32m0.04854[0m[0m | time: 116.378s
[2K
| RMSProp | epoch: 028 | loss: 0.04854 - acc: 0.9934 -- iter: 0896/1584
[A[ATraining Step: 1379  | total loss: [1m[32m0.04438[0m[0m | time: 130.670s
[2K
| RMSProp | epoch: 028 | loss: 0.04438 - acc: 0.9941 -- iter: 0928/1584
[A[ATraining Step: 1380  | total loss: [1m[32m0.04131[0m[0m | time: 142.601s
[2K
| RMSProp | epoch: 028 | loss: 0.04131 - acc: 0.9947 -- iter: 0960/1584
[A[ATraining Step: 1381  | total loss: [1m[32m0.04276[0m[0m | time: 156.207s
[2K
| RMSProp | epoch: 028 | loss: 0.04276 - acc: 0.9921 -- iter: 0992/1584
[A[ATraining Step: 1382  | total loss: [1m[32m0.04548[0m[0m | time: 166.789s
[2K
| RMSProp | epoch: 028 | loss: 0.04548 - acc: 0.9898 -- iter: 1024/1584
[A[ATraining Step: 1383  | total loss: [1m[32m0.04248[0m[0m | time: 172.310s
[2K
| RMSProp | epoch: 028 | loss: 0.04248 - acc: 0.9908 -- iter: 1056/1584
[A[ATraining Step: 1384  | total loss: [1m[32m0.04067[0m[0m | time: 179.745s
[2K
| RMSProp | epoch: 028 | loss: 0.04067 - acc: 0.9917 -- iter: 1088/1584
[A[ATraining Step: 1385  | total loss: [1m[32m0.03686[0m[0m | time: 183.345s
[2K
| RMSProp | epoch: 028 | loss: 0.03686 - acc: 0.9925 -- iter: 1120/1584
[A[ATraining Step: 1386  | total loss: [1m[32m0.04242[0m[0m | time: 190.729s
[2K
| RMSProp | epoch: 028 | loss: 0.04242 - acc: 0.9870 -- iter: 1152/1584
[A[ATraining Step: 1387  | total loss: [1m[32m0.04084[0m[0m | time: 195.806s
[2K
| RMSProp | epoch: 028 | loss: 0.04084 - acc: 0.9852 -- iter: 1184/1584
[A[ATraining Step: 1388  | total loss: [1m[32m0.06877[0m[0m | time: 209.952s
[2K
| RMSProp | epoch: 028 | loss: 0.06877 - acc: 0.9773 -- iter: 1216/1584
[A[ATraining Step: 1389  | total loss: [1m[32m0.10451[0m[0m | time: 218.958s
[2K
| RMSProp | epoch: 028 | loss: 0.10451 - acc: 0.9514 -- iter: 1248/1584
[A[ATraining Step: 1390  | total loss: [1m[32m0.09498[0m[0m | time: 224.438s
[2K
| RMSProp | epoch: 028 | loss: 0.09498 - acc: 0.9563 -- iter: 1280/1584
[A[ATraining Step: 1391  | total loss: [1m[32m0.08696[0m[0m | time: 229.625s
[2K
| RMSProp | epoch: 028 | loss: 0.08696 - acc: 0.9607 -- iter: 1312/1584
[A[ATraining Step: 1392  | total loss: [1m[32m0.07859[0m[0m | time: 235.269s
[2K
| RMSProp | epoch: 028 | loss: 0.07859 - acc: 0.9646 -- iter: 1344/1584
[A[ATraining Step: 1393  | total loss: [1m[32m0.07132[0m[0m | time: 239.192s
[2K
| RMSProp | epoch: 028 | loss: 0.07132 - acc: 0.9681 -- iter: 1376/1584
[A[ATraining Step: 1394  | total loss: [1m[32m0.07803[0m[0m | time: 243.463s
[2K
| RMSProp | epoch: 028 | loss: 0.07803 - acc: 0.9682 -- iter: 1408/1584
[A[ATraining Step: 1395  | total loss: [1m[32m0.07286[0m[0m | time: 249.378s
[2K
| RMSProp | epoch: 028 | loss: 0.07286 - acc: 0.9714 -- iter: 1440/1584
[A[ATraining Step: 1396  | total loss: [1m[32m0.07774[0m[0m | time: 251.567s
[2K
| RMSProp | epoch: 028 | loss: 0.07774 - acc: 0.9711 -- iter: 1472/1584
[A[ATraining Step: 1397  | total loss: [1m[32m0.07456[0m[0m | time: 252.615s
[2K
| RMSProp | epoch: 028 | loss: 0.07456 - acc: 0.9740 -- iter: 1504/1584
[A[ATraining Step: 1398  | total loss: [1m[32m0.06784[0m[0m | time: 253.761s
[2K
| RMSProp | epoch: 028 | loss: 0.06784 - acc: 0.9766 -- iter: 1536/1584
[A[ATraining Step: 1399  | total loss: [1m[32m0.06194[0m[0m | time: 255.085s
[2K
| RMSProp | epoch: 028 | loss: 0.06194 - acc: 0.9789 -- iter: 1568/1584
[A[ATraining Step: 1400  | total loss: [1m[32m0.05602[0m[0m | time: 260.712s
[2K
| RMSProp | epoch: 028 | loss: 0.05602 - acc: 0.9811 | val_loss: 0.74552 - val_acc: 0.8206 -- iter: 1584/1584
--
Training Step: 1401  | total loss: [1m[32m0.05110[0m[0m | time: 1.452s
[2K
| RMSProp | epoch: 029 | loss: 0.05110 - acc: 0.9829 -- iter: 0032/1584
[A[ATraining Step: 1402  | total loss: [1m[32m0.04615[0m[0m | time: 3.094s
[2K
| RMSProp | epoch: 029 | loss: 0.04615 - acc: 0.9847 -- iter: 0064/1584
[A[ATraining Step: 1403  | total loss: [1m[32m0.05667[0m[0m | time: 11.918s
[2K
| RMSProp | epoch: 029 | loss: 0.05667 - acc: 0.9831 -- iter: 0096/1584
[A[ATraining Step: 1404  | total loss: [1m[32m0.06123[0m[0m | time: 27.007s
[2K
| RMSProp | epoch: 029 | loss: 0.06123 - acc: 0.9816 -- iter: 0128/1584
[A[ATraining Step: 1405  | total loss: [1m[32m0.05559[0m[0m | time: 33.696s
[2K
| RMSProp | epoch: 029 | loss: 0.05559 - acc: 0.9835 -- iter: 0160/1584
[A[ATraining Step: 1406  | total loss: [1m[32m0.05121[0m[0m | time: 38.185s
[2K
| RMSProp | epoch: 029 | loss: 0.05121 - acc: 0.9851 -- iter: 0192/1584
[A[ATraining Step: 1407  | total loss: [1m[32m0.04640[0m[0m | time: 43.395s
[2K
| RMSProp | epoch: 029 | loss: 0.04640 - acc: 0.9866 -- iter: 0224/1584
[A[ATraining Step: 1408  | total loss: [1m[32m0.04261[0m[0m | time: 51.064s
[2K
| RMSProp | epoch: 029 | loss: 0.04261 - acc: 0.9879 -- iter: 0256/1584
[A[ATraining Step: 1409  | total loss: [1m[32m0.03902[0m[0m | time: 55.945s
[2K
| RMSProp | epoch: 029 | loss: 0.03902 - acc: 0.9892 -- iter: 0288/1584
[A[ATraining Step: 1410  | total loss: [1m[32m0.03710[0m[0m | time: 64.754s
[2K
| RMSProp | epoch: 029 | loss: 0.03710 - acc: 0.9902 -- iter: 0320/1584
[A[ATraining Step: 1411  | total loss: [1m[32m0.03406[0m[0m | time: 68.762s
[2K
| RMSProp | epoch: 029 | loss: 0.03406 - acc: 0.9912 -- iter: 0352/1584
[A[ATraining Step: 1412  | total loss: [1m[32m0.03087[0m[0m | time: 70.019s
[2K
| RMSProp | epoch: 029 | loss: 0.03087 - acc: 0.9921 -- iter: 0384/1584
[A[ATraining Step: 1413  | total loss: [1m[32m0.02793[0m[0m | time: 71.069s
[2K
| RMSProp | epoch: 029 | loss: 0.02793 - acc: 0.9929 -- iter: 0416/1584
[A[ATraining Step: 1414  | total loss: [1m[32m0.04837[0m[0m | time: 72.316s
[2K
| RMSProp | epoch: 029 | loss: 0.04837 - acc: 0.9905 -- iter: 0448/1584
[A[ATraining Step: 1415  | total loss: [1m[32m0.04572[0m[0m | time: 73.590s
[2K
| RMSProp | epoch: 029 | loss: 0.04572 - acc: 0.9914 -- iter: 0480/1584
[A[ATraining Step: 1416  | total loss: [1m[32m0.06270[0m[0m | time: 74.900s
[2K
| RMSProp | epoch: 029 | loss: 0.06270 - acc: 0.9860 -- iter: 0512/1584
[A[ATraining Step: 1417  | total loss: [1m[32m0.06738[0m[0m | time: 76.313s
[2K
| RMSProp | epoch: 029 | loss: 0.06738 - acc: 0.9843 -- iter: 0544/1584
[A[ATraining Step: 1418  | total loss: [1m[32m0.06236[0m[0m | time: 77.710s
[2K
| RMSProp | epoch: 029 | loss: 0.06236 - acc: 0.9859 -- iter: 0576/1584
[A[ATraining Step: 1419  | total loss: [1m[32m0.05718[0m[0m | time: 78.971s
[2K
| RMSProp | epoch: 029 | loss: 0.05718 - acc: 0.9873 -- iter: 0608/1584
[A[ATraining Step: 1420  | total loss: [1m[32m0.05201[0m[0m | time: 80.587s
[2K
| RMSProp | epoch: 029 | loss: 0.05201 - acc: 0.9886 -- iter: 0640/1584
[A[ATraining Step: 1421  | total loss: [1m[32m0.04723[0m[0m | time: 81.791s
[2K
| RMSProp | epoch: 029 | loss: 0.04723 - acc: 0.9897 -- iter: 0672/1584
[A[ATraining Step: 1422  | total loss: [1m[32m0.04281[0m[0m | time: 83.001s
[2K
| RMSProp | epoch: 029 | loss: 0.04281 - acc: 0.9907 -- iter: 0704/1584
[A[ATraining Step: 1423  | total loss: [1m[32m0.03886[0m[0m | time: 90.195s
[2K
| RMSProp | epoch: 029 | loss: 0.03886 - acc: 0.9917 -- iter: 0736/1584
[A[ATraining Step: 1424  | total loss: [1m[32m0.03507[0m[0m | time: 102.132s
[2K
| RMSProp | epoch: 029 | loss: 0.03507 - acc: 0.9925 -- iter: 0768/1584
[A[ATraining Step: 1425  | total loss: [1m[32m0.03175[0m[0m | time: 111.350s
[2K
| RMSProp | epoch: 029 | loss: 0.03175 - acc: 0.9932 -- iter: 0800/1584
[A[ATraining Step: 1426  | total loss: [1m[32m0.02865[0m[0m | time: 115.678s
[2K
| RMSProp | epoch: 029 | loss: 0.02865 - acc: 0.9939 -- iter: 0832/1584
[A[ATraining Step: 1427  | total loss: [1m[32m0.02596[0m[0m | time: 119.431s
[2K
| RMSProp | epoch: 029 | loss: 0.02596 - acc: 0.9945 -- iter: 0864/1584
[A[ATraining Step: 1428  | total loss: [1m[32m0.02349[0m[0m | time: 121.434s
[2K
| RMSProp | epoch: 029 | loss: 0.02349 - acc: 0.9951 -- iter: 0896/1584
[A[ATraining Step: 1429  | total loss: [1m[32m0.02122[0m[0m | time: 130.892s
[2K
| RMSProp | epoch: 029 | loss: 0.02122 - acc: 0.9956 -- iter: 0928/1584
[A[ATraining Step: 1430  | total loss: [1m[32m0.01916[0m[0m | time: 148.241s
[2K
| RMSProp | epoch: 029 | loss: 0.01916 - acc: 0.9960 -- iter: 0960/1584
[A[ATraining Step: 1431  | total loss: [1m[32m0.01746[0m[0m | time: 155.672s
[2K
| RMSProp | epoch: 029 | loss: 0.01746 - acc: 0.9964 -- iter: 0992/1584
[A[ATraining Step: 1432  | total loss: [1m[32m0.01576[0m[0m | time: 166.714s
[2K
| RMSProp | epoch: 029 | loss: 0.01576 - acc: 0.9968 -- iter: 1024/1584
[A[ATraining Step: 1433  | total loss: [1m[32m0.01430[0m[0m | time: 171.009s
[2K
| RMSProp | epoch: 029 | loss: 0.01430 - acc: 0.9971 -- iter: 1056/1584
[A[ATraining Step: 1434  | total loss: [1m[32m0.02624[0m[0m | time: 174.690s
[2K
| RMSProp | epoch: 029 | loss: 0.02624 - acc: 0.9943 -- iter: 1088/1584
[A[ATraining Step: 1435  | total loss: [1m[32m0.05661[0m[0m | time: 178.968s
[2K
| RMSProp | epoch: 029 | loss: 0.05661 - acc: 0.9792 -- iter: 1120/1584
[A[ATraining Step: 1436  | total loss: [1m[32m0.08525[0m[0m | time: 179.949s
[2K
| RMSProp | epoch: 029 | loss: 0.08525 - acc: 0.9688 -- iter: 1152/1584
[A[ATraining Step: 1437  | total loss: [1m[32m0.07926[0m[0m | time: 181.065s
[2K
| RMSProp | epoch: 029 | loss: 0.07926 - acc: 0.9719 -- iter: 1184/1584
[A[ATraining Step: 1438  | total loss: [1m[32m0.07178[0m[0m | time: 182.307s
[2K
| RMSProp | epoch: 029 | loss: 0.07178 - acc: 0.9747 -- iter: 1216/1584
[A[ATraining Step: 1439  | total loss: [1m[32m0.06670[0m[0m | time: 183.564s
[2K
| RMSProp | epoch: 029 | loss: 0.06670 - acc: 0.9772 -- iter: 1248/1584
[A[ATraining Step: 1440  | total loss: [1m[32m0.06909[0m[0m | time: 184.879s
[2K
| RMSProp | epoch: 029 | loss: 0.06909 - acc: 0.9764 -- iter: 1280/1584
[A[ATraining Step: 1441  | total loss: [1m[32m0.06250[0m[0m | time: 186.238s
[2K
| RMSProp | epoch: 029 | loss: 0.06250 - acc: 0.9788 -- iter: 1312/1584
[A[ATraining Step: 1442  | total loss: [1m[32m0.05658[0m[0m | time: 187.636s
[2K
| RMSProp | epoch: 029 | loss: 0.05658 - acc: 0.9809 -- iter: 1344/1584
[A[ATraining Step: 1443  | total loss: [1m[32m0.05570[0m[0m | time: 188.926s
[2K
| RMSProp | epoch: 029 | loss: 0.05570 - acc: 0.9797 -- iter: 1376/1584
[A[ATraining Step: 1444  | total loss: [1m[32m0.06225[0m[0m | time: 190.361s
[2K
| RMSProp | epoch: 029 | loss: 0.06225 - acc: 0.9755 -- iter: 1408/1584
[A[ATraining Step: 1445  | total loss: [1m[32m0.07236[0m[0m | time: 191.780s
[2K
| RMSProp | epoch: 029 | loss: 0.07236 - acc: 0.9717 -- iter: 1440/1584
[A[ATraining Step: 1446  | total loss: [1m[32m0.06544[0m[0m | time: 193.109s
[2K
| RMSProp | epoch: 029 | loss: 0.06544 - acc: 0.9745 -- iter: 1472/1584
[A[ATraining Step: 1447  | total loss: [1m[32m0.08192[0m[0m | time: 197.705s
[2K
| RMSProp | epoch: 029 | loss: 0.08192 - acc: 0.9739 -- iter: 1504/1584
[A[ATraining Step: 1448  | total loss: [1m[32m0.09194[0m[0m | time: 201.038s
[2K
| RMSProp | epoch: 029 | loss: 0.09194 - acc: 0.9703 -- iter: 1536/1584
[A[ATraining Step: 1449  | total loss: [1m[32m0.08370[0m[0m | time: 204.167s
[2K
| RMSProp | epoch: 029 | loss: 0.08370 - acc: 0.9732 -- iter: 1568/1584
[A[ATraining Step: 1450  | total loss: [1m[32m0.07566[0m[0m | time: 208.944s
[2K
| RMSProp | epoch: 029 | loss: 0.07566 - acc: 0.9759 | val_loss: 0.69133 - val_acc: 0.8044 -- iter: 1584/1584
--
Training Step: 1451  | total loss: [1m[32m0.06882[0m[0m | time: 1.383s
[2K
| RMSProp | epoch: 030 | loss: 0.06882 - acc: 0.9783 -- iter: 0032/1584
[A[ATraining Step: 1452  | total loss: [1m[32m0.06340[0m[0m | time: 2.785s
[2K
| RMSProp | epoch: 030 | loss: 0.06340 - acc: 0.9805 -- iter: 0064/1584
[A[ATraining Step: 1453  | total loss: [1m[32m0.05827[0m[0m | time: 4.078s
[2K
| RMSProp | epoch: 030 | loss: 0.05827 - acc: 0.9824 -- iter: 0096/1584
[A[ATraining Step: 1454  | total loss: [1m[32m0.05269[0m[0m | time: 5.421s
[2K
| RMSProp | epoch: 030 | loss: 0.05269 - acc: 0.9842 -- iter: 0128/1584
[A[ATraining Step: 1455  | total loss: [1m[32m0.04790[0m[0m | time: 6.822s
[2K
| RMSProp | epoch: 030 | loss: 0.04790 - acc: 0.9858 -- iter: 0160/1584
[A[ATraining Step: 1456  | total loss: [1m[32m0.04325[0m[0m | time: 8.952s
[2K
| RMSProp | epoch: 030 | loss: 0.04325 - acc: 0.9872 -- iter: 0192/1584
[A[ATraining Step: 1457  | total loss: [1m[32m0.06054[0m[0m | time: 17.380s
[2K
| RMSProp | epoch: 030 | loss: 0.06054 - acc: 0.9854 -- iter: 0224/1584
[A[ATraining Step: 1458  | total loss: [1m[32m0.05567[0m[0m | time: 28.381s
[2K
| RMSProp | epoch: 030 | loss: 0.05567 - acc: 0.9868 -- iter: 0256/1584
[A[ATraining Step: 1459  | total loss: [1m[32m0.05066[0m[0m | time: 31.875s
[2K
| RMSProp | epoch: 030 | loss: 0.05066 - acc: 0.9881 -- iter: 0288/1584
[A[ATraining Step: 1460  | total loss: [1m[32m0.04591[0m[0m | time: 34.971s
[2K
| RMSProp | epoch: 030 | loss: 0.04591 - acc: 0.9893 -- iter: 0320/1584
[A[ATraining Step: 1461  | total loss: [1m[32m0.04183[0m[0m | time: 43.069s
[2K
| RMSProp | epoch: 030 | loss: 0.04183 - acc: 0.9904 -- iter: 0352/1584
[A[ATraining Step: 1462  | total loss: [1m[32m0.03777[0m[0m | time: 46.124s
[2K
| RMSProp | epoch: 030 | loss: 0.03777 - acc: 0.9914 -- iter: 0384/1584
[A[ATraining Step: 1463  | total loss: [1m[32m0.03423[0m[0m | time: 52.031s
[2K
| RMSProp | epoch: 030 | loss: 0.03423 - acc: 0.9922 -- iter: 0416/1584
[A[ATraining Step: 1464  | total loss: [1m[32m0.03113[0m[0m | time: 61.433s
[2K
| RMSProp | epoch: 030 | loss: 0.03113 - acc: 0.9930 -- iter: 0448/1584
[A[ATraining Step: 1465  | total loss: [1m[32m0.04854[0m[0m | time: 67.147s
[2K
| RMSProp | epoch: 030 | loss: 0.04854 - acc: 0.9906 -- iter: 0480/1584
[A[ATraining Step: 1466  | total loss: [1m[32m0.06013[0m[0m | time: 68.347s
[2K
| RMSProp | epoch: 030 | loss: 0.06013 - acc: 0.9821 -- iter: 0512/1584
[A[ATraining Step: 1467  | total loss: [1m[32m0.07017[0m[0m | time: 69.476s
[2K
| RMSProp | epoch: 030 | loss: 0.07017 - acc: 0.9777 -- iter: 0544/1584
[A[ATraining Step: 1468  | total loss: [1m[32m0.06504[0m[0m | time: 70.606s
[2K
| RMSProp | epoch: 030 | loss: 0.06504 - acc: 0.9799 -- iter: 0576/1584
[A[ATraining Step: 1469  | total loss: [1m[32m0.06313[0m[0m | time: 71.840s
[2K
| RMSProp | epoch: 030 | loss: 0.06313 - acc: 0.9788 -- iter: 0608/1584
[A[ATraining Step: 1470  | total loss: [1m[32m0.05794[0m[0m | time: 73.185s
[2K
| RMSProp | epoch: 030 | loss: 0.05794 - acc: 0.9809 -- iter: 0640/1584
[A[ATraining Step: 1471  | total loss: [1m[32m0.05501[0m[0m | time: 74.596s
[2K
| RMSProp | epoch: 030 | loss: 0.05501 - acc: 0.9828 -- iter: 0672/1584
[A[ATraining Step: 1472  | total loss: [1m[32m0.04976[0m[0m | time: 75.971s
[2K
| RMSProp | epoch: 030 | loss: 0.04976 - acc: 0.9845 -- iter: 0704/1584
[A[ATraining Step: 1473  | total loss: [1m[32m0.04512[0m[0m | time: 77.170s
[2K
| RMSProp | epoch: 030 | loss: 0.04512 - acc: 0.9861 -- iter: 0736/1584
[A[ATraining Step: 1474  | total loss: [1m[32m0.04072[0m[0m | time: 78.725s
[2K
| RMSProp | epoch: 030 | loss: 0.04072 - acc: 0.9875 -- iter: 0768/1584
[A[ATraining Step: 1475  | total loss: [1m[32m0.03678[0m[0m | time: 80.245s
[2K
| RMSProp | epoch: 030 | loss: 0.03678 - acc: 0.9887 -- iter: 0800/1584
[A[ATraining Step: 1476  | total loss: [1m[32m0.03325[0m[0m | time: 85.648s
[2K
| RMSProp | epoch: 030 | loss: 0.03325 - acc: 0.9899 -- iter: 0832/1584
[A[ATraining Step: 1477  | total loss: [1m[32m0.03343[0m[0m | time: 88.723s
[2K
| RMSProp | epoch: 030 | loss: 0.03343 - acc: 0.9877 -- iter: 0864/1584
[A[ATraining Step: 1478  | total loss: [1m[32m0.03769[0m[0m | time: 91.633s
[2K
| RMSProp | epoch: 030 | loss: 0.03769 - acc: 0.9858 -- iter: 0896/1584
[A[ATraining Step: 1479  | total loss: [1m[32m0.05764[0m[0m | time: 97.693s
[2K
| RMSProp | epoch: 030 | loss: 0.05764 - acc: 0.9810 -- iter: 0928/1584
[A[ATraining Step: 1480  | total loss: [1m[32m0.06486[0m[0m | time: 102.413s
[2K
| RMSProp | epoch: 030 | loss: 0.06486 - acc: 0.9767 -- iter: 0960/1584
[A[ATraining Step: 1481  | total loss: [1m[32m0.07413[0m[0m | time: 109.078s
[2K
| RMSProp | epoch: 030 | loss: 0.07413 - acc: 0.9759 -- iter: 0992/1584
[A[ATraining Step: 1482  | total loss: [1m[32m0.08207[0m[0m | time: 114.197s
[2K
| RMSProp | epoch: 030 | loss: 0.08207 - acc: 0.9752 -- iter: 1024/1584
[A[ATraining Step: 1483  | total loss: [1m[32m0.07689[0m[0m | time: 116.143s
[2K
| RMSProp | epoch: 030 | loss: 0.07689 - acc: 0.9776 -- iter: 1056/1584
[A[ATraining Step: 1484  | total loss: [1m[32m0.08675[0m[0m | time: 118.300s
[2K
| RMSProp | epoch: 030 | loss: 0.08675 - acc: 0.9768 -- iter: 1088/1584
[A[ATraining Step: 1485  | total loss: [1m[32m0.07931[0m[0m | time: 123.284s
[2K
| RMSProp | epoch: 030 | loss: 0.07931 - acc: 0.9791 -- iter: 1120/1584
[A[ATraining Step: 1486  | total loss: [1m[32m0.07188[0m[0m | time: 127.063s
[2K
| RMSProp | epoch: 030 | loss: 0.07188 - acc: 0.9812 -- iter: 1152/1584
[A[ATraining Step: 1487  | total loss: [1m[32m0.07800[0m[0m | time: 131.245s
[2K
| RMSProp | epoch: 030 | loss: 0.07800 - acc: 0.9768 -- iter: 1184/1584
[A[ATraining Step: 1488  | total loss: [1m[32m0.07543[0m[0m | time: 136.497s
[2K
| RMSProp | epoch: 030 | loss: 0.07543 - acc: 0.9760 -- iter: 1216/1584
[A[ATraining Step: 1489  | total loss: [1m[32m0.06900[0m[0m | time: 137.831s
[2K
| RMSProp | epoch: 030 | loss: 0.06900 - acc: 0.9784 -- iter: 1248/1584
[A[ATraining Step: 1490  | total loss: [1m[32m0.07402[0m[0m | time: 138.994s
[2K
| RMSProp | epoch: 030 | loss: 0.07402 - acc: 0.9774 -- iter: 1280/1584
[A[ATraining Step: 1491  | total loss: [1m[32m0.06746[0m[0m | time: 140.149s
[2K
| RMSProp | epoch: 030 | loss: 0.06746 - acc: 0.9797 -- iter: 1312/1584
[A[ATraining Step: 1492  | total loss: [1m[32m0.06145[0m[0m | time: 141.517s
[2K
| RMSProp | epoch: 030 | loss: 0.06145 - acc: 0.9817 -- iter: 1344/1584
[A[ATraining Step: 1493  | total loss: [1m[32m0.05636[0m[0m | time: 142.974s
[2K
| RMSProp | epoch: 030 | loss: 0.05636 - acc: 0.9835 -- iter: 1376/1584
[A[ATraining Step: 1494  | total loss: [1m[32m0.05127[0m[0m | time: 144.276s
[2K
| RMSProp | epoch: 030 | loss: 0.05127 - acc: 0.9852 -- iter: 1408/1584
[A[ATraining Step: 1495  | total loss: [1m[32m0.04682[0m[0m | time: 145.469s
[2K
| RMSProp | epoch: 030 | loss: 0.04682 - acc: 0.9867 -- iter: 1440/1584
[A[ATraining Step: 1496  | total loss: [1m[32m0.04235[0m[0m | time: 146.788s
[2K
| RMSProp | epoch: 030 | loss: 0.04235 - acc: 0.9880 -- iter: 1472/1584
[A[ATraining Step: 1497  | total loss: [1m[32m0.03842[0m[0m | time: 148.224s
[2K
| RMSProp | epoch: 030 | loss: 0.03842 - acc: 0.9892 -- iter: 1504/1584
[A[ATraining Step: 1498  | total loss: [1m[32m0.17003[0m[0m | time: 149.659s
[2K
| RMSProp | epoch: 030 | loss: 0.17003 - acc: 0.9715 -- iter: 1536/1584
[A[ATraining Step: 1499  | total loss: [1m[32m0.15911[0m[0m | time: 150.890s
[2K
| RMSProp | epoch: 030 | loss: 0.15911 - acc: 0.9744 -- iter: 1568/1584
[A[ATraining Step: 1500  | total loss: [1m[32m0.15231[0m[0m | time: 155.882s
[2K
| RMSProp | epoch: 030 | loss: 0.15231 - acc: 0.9707 | val_loss: 0.63602 - val_acc: 0.8044 -- iter: 1584/1584
--
Validation AUC:0.8862172187154292
Validation AUPRC:0.8933005747764979
Test AUC:0.885235489544655
Test AUPRC:0.9033497309160016
BestTestF1Score	0.81	0.59	0.79	0.78	0.84	218	62	176	40	0.23
BestTestMCCScore	0.81	0.59	0.79	0.78	0.84	218	62	176	40	0.23
BestTestAccuracyScore	0.81	0.59	0.79	0.78	0.84	218	62	176	40	0.23
BestValidationF1Score	0.83	0.63	0.81	0.77	0.89	227	66	176	27	0.23
BestValidationMCC	0.83	0.63	0.81	0.77	0.89	227	66	176	27	0.23
BestValidationAccuracy	0.83	0.63	0.81	0.77	0.89	227	66	176	27	0.23
TestPredictions (Threshold:0.23)
CHEMBL1095374,TP,ACT,0.47999998927116394	CHEMBL1241950,TN,INACT,0.019999999552965164	CHEMBL589064,FP,INACT,0.8299999833106995	CHEMBL210226,TP,ACT,0.9900000095367432	CHEMBL1172421,TP,ACT,0.9900000095367432	CHEMBL526932,TN,INACT,0.029999999329447746	CHEMBL85403,FP,INACT,0.41999998688697815	CHEMBL2035181,TP,ACT,1.0	CHEMBL30432,FP,INACT,0.9900000095367432	CHEMBL348834,FP,INACT,0.9300000071525574	CHEMBL1254286,TN,INACT,0.0	CHEMBL1096737,TN,INACT,0.0	CHEMBL1835867,TP,ACT,0.9800000190734863	CHEMBL2011302,FP,INACT,0.9700000286102295	CHEMBL1093099,TN,INACT,0.09000000357627869	CHEMBL1807392,TP,ACT,1.0	CHEMBL246166,TP,ACT,0.9599999785423279	CHEMBL386051,TP,ACT,0.9900000095367432	CHEMBL77085,FP,INACT,0.9300000071525574	CHEMBL3098312,TN,INACT,0.07999999821186066	CHEMBL2063332,TP,ACT,0.9900000095367432	CHEMBL3628211,TN,INACT,0.009999999776482582	CHEMBL86755,FN,ACT,0.1899999976158142	CHEMBL1807386,TP,ACT,0.9800000190734863	CHEMBL241750,TN,INACT,0.009999999776482582	CHEMBL2023116,TP,ACT,0.9900000095367432	CHEMBL291979,TN,INACT,0.0	CHEMBL3646211,TP,ACT,0.9900000095367432	CHEMBL457390,TN,INACT,0.009999999776482582	CHEMBL3421964,TN,INACT,0.2199999988079071	CHEMBL233958,TN,INACT,0.0	CHEMBL428380,TP,ACT,0.9900000095367432	CHEMBL2063329,TP,ACT,1.0	CHEMBL3687194,TP,ACT,0.9900000095367432	CHEMBL1929314,TN,INACT,0.0	CHEMBL77068,TN,INACT,0.20999999344348907	CHEMBL113996,TN,INACT,0.0	CHEMBL3815054,TP,ACT,0.9900000095367432	CHEMBL2147845,FN,ACT,0.019999999552965164	CHEMBL137828,TN,INACT,0.009999999776482582	CHEMBL2332870,TP,ACT,0.9700000286102295	CHEMBL2205426,TP,ACT,0.8199999928474426	CHEMBL77298,TN,INACT,0.0	CHEMBL1915433,TP,ACT,0.9700000286102295	CHEMBL3329398,TN,INACT,0.019999999552965164	CHEMBL323133,TN,INACT,0.009999999776482582	CHEMBL3633690,TN,INACT,0.09000000357627869	CHEMBL3401984,TP,ACT,0.9900000095367432	CHEMBL3128233,TN,INACT,0.03999999910593033	CHEMBL318461,TN,INACT,0.05999999865889549	CHEMBL322464,TN,INACT,0.019999999552965164	CHEMBL379218,FN,ACT,0.0	CHEMBL1094475,TN,INACT,0.0	CHEMBL387312,TP,ACT,0.9900000095367432	CHEMBL519590,TN,INACT,0.07999999821186066	CHEMBL14326,TN,INACT,0.11999999731779099	CHEMBL3329675,TP,ACT,1.0	CHEMBL3421974,FP,INACT,0.800000011920929	CHEMBL474015,TN,INACT,0.12999999523162842	CHEMBL1081509,TP,ACT,0.9900000095367432	CHEMBL3360681,TN,INACT,0.019999999552965164	CHEMBL1807788,FN,ACT,0.12999999523162842	CHEMBL2332845,TP,ACT,0.8899999856948853	CHEMBL223583,TP,ACT,0.9900000095367432	CHEMBL117488,TN,INACT,0.029999999329447746	CHEMBL210860,FN,ACT,0.15000000596046448	CHEMBL3680381,TP,ACT,1.0	CHEMBL271188,TN,INACT,0.07999999821186066	CHEMBL339856,TN,INACT,0.009999999776482582	CHEMBL1765783,TP,ACT,1.0	CHEMBL379367,TP,ACT,0.9800000190734863	CHEMBL1241862,TN,INACT,0.009999999776482582	CHEMBL2046726,TP,ACT,0.9700000286102295	CHEMBL457401,FP,INACT,0.6600000262260437	CHEMBL584,TN,INACT,0.0	CHEMBL1081166,TP,ACT,0.9900000095367432	CHEMBL345641,TN,INACT,0.0	CHEMBL2335379,TN,INACT,0.0	CHEMBL498520,TN,INACT,0.0	CHEMBL1242033,TN,INACT,0.09000000357627869	CHEMBL1258377,TP,ACT,0.9900000095367432	CHEMBL62965,FN,ACT,0.029999999329447746	CHEMBL3358976,FP,INACT,0.5799999833106995	CHEMBL572881,TP,ACT,0.8999999761581421	CHEMBL80810,TN,INACT,0.029999999329447746	CHEMBL3290628,TP,ACT,0.9900000095367432	CHEMBL431025,FP,INACT,0.9800000190734863	CHEMBL410504,TP,ACT,0.9900000095367432	CHEMBL215417,TN,INACT,0.019999999552965164	CHEMBL1221633,FP,INACT,0.9300000071525574	CHEMBL584710,TP,ACT,0.9900000095367432	CHEMBL597960,FN,ACT,0.029999999329447746	CHEMBL2386794,TP,ACT,0.9900000095367432	CHEMBL564575,TN,INACT,0.0	CHEMBL392111,TP,ACT,0.9900000095367432	CHEMBL208974,TP,ACT,0.9900000095367432	CHEMBL2203431,TP,ACT,0.9900000095367432	CHEMBL196363,TP,ACT,1.0	CHEMBL2158227,TP,ACT,0.7599999904632568	CHEMBL410731,TP,ACT,0.9900000095367432	CHEMBL21108,FP,INACT,0.6299999952316284	CHEMBL3629605,TN,INACT,0.0	CHEMBL726,TN,INACT,0.009999999776482582	CHEMBL1242119,TN,INACT,0.009999999776482582	CHEMBL497957,TN,INACT,0.0	CHEMBL591437,TN,INACT,0.0	CHEMBL3237451,TP,ACT,0.9900000095367432	CHEMBL2148120,TP,ACT,1.0	CHEMBL1945568,TP,ACT,1.0	CHEMBL2032274,TP,ACT,0.9900000095367432	CHEMBL69109,TN,INACT,0.0	CHEMBL2181087,TP,ACT,0.9900000095367432	CHEMBL443350,FP,INACT,0.27000001072883606	CHEMBL187007,TN,INACT,0.009999999776482582	CHEMBL334026,FP,INACT,0.30000001192092896	CHEMBL2088106,TN,INACT,0.009999999776482582	CHEMBL505610,TN,INACT,0.019999999552965164	CHEMBL313500,TN,INACT,0.029999999329447746	CHEMBL1765781,TP,ACT,1.0	CHEMBL295528,FP,INACT,0.6100000143051147	CHEMBL603469,TP,ACT,0.25999999046325684	CHEMBL3263640,TP,ACT,0.949999988079071	CHEMBL3116050,FN,ACT,0.05000000074505806	CHEMBL1241775,TN,INACT,0.0	CHEMBL1829273,TN,INACT,0.0	CHEMBL2181083,TP,ACT,1.0	CHEMBL602645,FP,INACT,0.9100000262260437	CHEMBL164,FN,ACT,0.11999999731779099	CHEMBL510168,TN,INACT,0.009999999776482582	CHEMBL404367,TP,ACT,0.9900000095367432	CHEMBL1171837,FN,ACT,0.10000000149011612	CHEMBL1910275,TN,INACT,0.05000000074505806	CHEMBL1835663,TP,ACT,0.8999999761581421	CHEMBL2181329,TP,ACT,0.9900000095367432	CHEMBL391684,TP,ACT,0.7900000214576721	CHEMBL3797839,TN,INACT,0.0	CHEMBL376077,TP,ACT,0.9900000095367432	CHEMBL522760,FP,INACT,0.9599999785423279	CHEMBL328452,TN,INACT,0.019999999552965164	CHEMBL1254545,TN,INACT,0.009999999776482582	CHEMBL31965,FN,ACT,0.0	CHEMBL629,TN,INACT,0.03999999910593033	CHEMBL488101,TN,INACT,0.14000000059604645	CHEMBL1807475,TP,ACT,1.0	CHEMBL245968,TP,ACT,0.9900000095367432	CHEMBL1947158,TP,ACT,1.0	CHEMBL1828882,TN,INACT,0.10999999940395355	CHEMBL1940267,TP,ACT,0.9800000190734863	CHEMBL3343366,TP,ACT,0.9900000095367432	CHEMBL3414599,TP,ACT,0.9900000095367432	CHEMBL1940113,TP,ACT,1.0	CHEMBL90277,TN,INACT,0.11999999731779099	CHEMBL87080,FP,INACT,0.44999998807907104	CHEMBL1910273,TN,INACT,0.11999999731779099	CHEMBL3593294,TP,ACT,0.9800000190734863	CHEMBL590962,TN,INACT,0.0	CHEMBL293731,FP,INACT,0.25999999046325684	CHEMBL300335,FP,INACT,0.8999999761581421	CHEMBL1258830,TP,ACT,0.9900000095367432	CHEMBL3322590,TP,ACT,0.7699999809265137	CHEMBL509435,TP,ACT,0.38999998569488525	CHEMBL1945567,TP,ACT,1.0	CHEMBL454192,FP,INACT,0.6299999952316284	CHEMBL3416157,FN,ACT,0.03999999910593033	CHEMBL558849,TN,INACT,0.0	CHEMBL3339360,TP,ACT,0.9900000095367432	CHEMBL223361,TP,ACT,0.9900000095367432	CHEMBL1956894,TN,INACT,0.0	CHEMBL3612498,TP,ACT,0.9900000095367432	CHEMBL3353355,TP,ACT,1.0	CHEMBL210420,FN,ACT,0.03999999910593033	CHEMBL3612496,TP,ACT,1.0	CHEMBL2180882,TP,ACT,0.28999999165534973	CHEMBL558475,TN,INACT,0.0	CHEMBL399914,FP,INACT,0.9900000095367432	CHEMBL296682,FP,INACT,0.5799999833106995	CHEMBL1828884,TN,INACT,0.10000000149011612	CHEMBL253116,TP,ACT,0.9800000190734863	CHEMBL258202,FP,INACT,0.9800000190734863	CHEMBL272183,TP,ACT,1.0	CHEMBL165751,TN,INACT,0.019999999552965164	CHEMBL2063327,TP,ACT,0.9800000190734863	CHEMBL156797,TN,INACT,0.0	CHEMBL1947162,TP,ACT,1.0	CHEMBL67747,TN,INACT,0.07999999821186066	CHEMBL3792955,TP,ACT,0.9300000071525574	CHEMBL448205,TN,INACT,0.009999999776482582	CHEMBL457180,TN,INACT,0.0	CHEMBL1257921,FN,ACT,0.03999999910593033	CHEMBL3133912,TN,INACT,0.0	CHEMBL132399,TN,INACT,0.03999999910593033	CHEMBL475051,FP,INACT,0.9599999785423279	CHEMBL1172878,TN,INACT,0.0	CHEMBL199723,TP,ACT,0.949999988079071	CHEMBL1940259,TP,ACT,1.0	CHEMBL430090,TP,ACT,0.9900000095367432	CHEMBL184231,TN,INACT,0.12999999523162842	CHEMBL2203435,TP,ACT,0.9900000095367432	CHEMBL3793804,TP,ACT,0.9900000095367432	CHEMBL3780091,FN,ACT,0.009999999776482582	CHEMBL1172697,FP,INACT,0.9700000286102295	CHEMBL1915640,FN,ACT,0.019999999552965164	CHEMBL55683,TN,INACT,0.009999999776482582	CHEMBL3813745,TP,ACT,1.0	CHEMBL3656369,TP,ACT,0.6399999856948853	CHEMBL1952141,TP,ACT,0.9900000095367432	CHEMBL1091199,TN,INACT,0.03999999910593033	CHEMBL2032276,TP,ACT,0.9900000095367432	CHEMBL114073,TN,INACT,0.07999999821186066	CHEMBL3687210,TP,ACT,0.75	CHEMBL63070,FN,ACT,0.019999999552965164	CHEMBL1172147,TN,INACT,0.05000000074505806	CHEMBL211327,FP,INACT,0.6299999952316284	CHEMBL1807480,TP,ACT,0.9599999785423279	CHEMBL55360,TN,INACT,0.10000000149011612	CHEMBL76985,TN,INACT,0.07000000029802322	CHEMBL80030,TN,INACT,0.03999999910593033	CHEMBL195437,TN,INACT,0.019999999552965164	CHEMBL1615182,TN,INACT,0.019999999552965164	CHEMBL598727,TN,INACT,0.0	CHEMBL430845,FP,INACT,0.9200000166893005	CHEMBL2181327,TP,ACT,0.9900000095367432	CHEMBL3353340,TP,ACT,0.9800000190734863	CHEMBL1668413,FP,INACT,0.949999988079071	CHEMBL602471,TN,INACT,0.0	CHEMBL551031,TN,INACT,0.0	CHEMBL180022,FN,ACT,0.10999999940395355	CHEMBL3425865,FN,ACT,0.17000000178813934	CHEMBL3353347,FN,ACT,0.009999999776482582	CHEMBL91,TN,INACT,0.019999999552965164	CHEMBL2147261,TN,INACT,0.17000000178813934	CHEMBL458248,TN,INACT,0.0	CHEMBL3401989,TP,ACT,0.9900000095367432	CHEMBL28,FN,ACT,0.05999999865889549	CHEMBL3335229,TN,INACT,0.009999999776482582	CHEMBL1821883,TN,INACT,0.0	CHEMBL1910278,FP,INACT,0.8500000238418579	CHEMBL226417,TP,ACT,0.9800000190734863	CHEMBL3699444,TP,ACT,0.9200000166893005	CHEMBL1765770,TP,ACT,0.9900000095367432	CHEMBL2063436,TP,ACT,0.9900000095367432	CHEMBL58142,TN,INACT,0.0	CHEMBL2332864,TP,ACT,0.4099999964237213	CHEMBL137653,TN,INACT,0.0	CHEMBL488646,FP,INACT,0.8199999928474426	CHEMBL3355065,TP,ACT,0.9900000095367432	CHEMBL422540,TN,INACT,0.03999999910593033	CHEMBL199996,TN,INACT,0.05000000074505806	CHEMBL3623372,TP,ACT,0.9900000095367432	CHEMBL3417185,TP,ACT,0.9800000190734863	CHEMBL3687200,TP,ACT,0.9900000095367432	CHEMBL3109339,TP,ACT,0.9800000190734863	CHEMBL2386813,TP,ACT,1.0	CHEMBL294410,FN,ACT,0.03999999910593033	CHEMBL2203434,TP,ACT,1.0	CHEMBL1915641,TP,ACT,0.9800000190734863	CHEMBL1077068,FP,INACT,0.9300000071525574	CHEMBL2063336,TP,ACT,0.9900000095367432	CHEMBL490053,TN,INACT,0.03999999910593033	CHEMBL3290626,TP,ACT,0.9800000190734863	CHEMBL603463,TN,INACT,0.2199999988079071	CHEMBL197538,FP,INACT,0.4099999964237213	CHEMBL341423,TN,INACT,0.009999999776482582	CHEMBL2407900,TP,ACT,1.0	CHEMBL1945046,TP,ACT,0.9900000095367432	CHEMBL3329670,TP,ACT,0.949999988079071	CHEMBL3361128,TN,INACT,0.20999999344348907	CHEMBL1945822,TP,ACT,1.0	CHEMBL1938402,FN,ACT,0.15000000596046448	CHEMBL3335244,TN,INACT,0.019999999552965164	CHEMBL3128228,TN,INACT,0.0	CHEMBL2147367,TN,INACT,0.0	CHEMBL3656360,TP,ACT,1.0	CHEMBL18276,TN,INACT,0.07999999821186066	CHEMBL293250,TN,INACT,0.009999999776482582	CHEMBL3098315,TN,INACT,0.05000000074505806	CHEMBL57553,TN,INACT,0.019999999552965164	CHEMBL1956885,TN,INACT,0.009999999776482582	CHEMBL1092754,FP,INACT,0.800000011920929	CHEMBL226813,TN,INACT,0.019999999552965164	CHEMBL223237,TP,ACT,0.8999999761581421	CHEMBL270070,TP,ACT,0.9700000286102295	CHEMBL1808239,TN,INACT,0.019999999552965164	CHEMBL460472,TP,ACT,0.9900000095367432	CHEMBL2035046,TP,ACT,1.0	CHEMBL1807485,TP,ACT,0.8899999856948853	CHEMBL538528,TN,INACT,0.019999999552965164	CHEMBL1173411,TP,ACT,0.9900000095367432	CHEMBL1807483,TP,ACT,0.8799999952316284	CHEMBL3353407,TN,INACT,0.0	CHEMBL513909,FN,ACT,0.0	CHEMBL3601223,TP,ACT,0.9700000286102295	CHEMBL2386807,TP,ACT,0.9900000095367432	CHEMBL1683957,TN,INACT,0.07000000029802322	CHEMBL209511,TN,INACT,0.029999999329447746	CHEMBL3800448,TN,INACT,0.0	CHEMBL1094784,TN,INACT,0.009999999776482582	CHEMBL1940109,TP,ACT,0.9900000095367432	CHEMBL430902,TN,INACT,0.009999999776482582	CHEMBL277236,TN,INACT,0.019999999552965164	CHEMBL1945171,TP,ACT,0.9900000095367432	CHEMBL1947159,TP,ACT,1.0	CHEMBL1938961,TP,ACT,0.8199999928474426	CHEMBL1929312,FP,INACT,0.25999999046325684	CHEMBL1940266,TP,ACT,1.0	CHEMBL3115492,FP,INACT,0.9599999785423279	CHEMBL3668195,FP,INACT,0.7300000190734863	CHEMBL50,FN,ACT,0.029999999329447746	CHEMBL595497,TN,INACT,0.07999999821186066	CHEMBL1230609,TP,ACT,1.0	CHEMBL3656357,TP,ACT,0.9900000095367432	CHEMBL3357176,TP,ACT,0.9599999785423279	CHEMBL3237705,TP,ACT,0.9700000286102295	CHEMBL2335722,TN,INACT,0.20999999344348907	CHEMBL379849,TN,INACT,0.05000000074505806	CHEMBL499587,TN,INACT,0.03999999910593033	CHEMBL3628817,FP,INACT,0.9800000190734863	CHEMBL3702566,TP,ACT,0.9900000095367432	CHEMBL2063434,TP,ACT,1.0	CHEMBL3322565,TP,ACT,1.0	CHEMBL2332852,TP,ACT,0.23000000417232513	CHEMBL3401990,TP,ACT,0.9900000095367432	CHEMBL605003,FN,ACT,0.0	CHEMBL1172886,TP,ACT,1.0	CHEMBL2036727,TN,INACT,0.009999999776482582	CHEMBL1172877,TN,INACT,0.0	CHEMBL3810244,FP,INACT,0.9300000071525574	CHEMBL3353406,TN,INACT,0.05000000074505806	CHEMBL3612513,TP,ACT,0.9900000095367432	CHEMBL2377475,FP,INACT,0.9599999785423279	CHEMBL2386790,TP,ACT,1.0	CHEMBL3764279,TP,ACT,0.9900000095367432	CHEMBL3687224,TP,ACT,0.949999988079071	CHEMBL499067,TN,INACT,0.0	CHEMBL1944928,TN,INACT,0.019999999552965164	CHEMBL2386793,TP,ACT,0.9900000095367432	CHEMBL808,TN,INACT,0.019999999552965164	CHEMBL1835737,TP,ACT,0.9599999785423279	CHEMBL201511,FN,ACT,0.18000000715255737	CHEMBL3676319,TN,INACT,0.009999999776482582	CHEMBL47202,TN,INACT,0.0	CHEMBL1258603,TP,ACT,0.3199999928474426	CHEMBL493169,TP,ACT,0.9800000190734863	CHEMBL1835865,TP,ACT,1.0	CHEMBL1172837,TP,ACT,0.9900000095367432	CHEMBL1990583,TP,ACT,1.0	CHEMBL605161,TN,INACT,0.019999999552965164	CHEMBL3656356,TP,ACT,0.9800000190734863	CHEMBL1835662,TP,ACT,0.9399999976158142	CHEMBL77243,TN,INACT,0.05999999865889549	CHEMBL2037200,FN,ACT,0.019999999552965164	CHEMBL604263,TP,ACT,0.9800000190734863	CHEMBL1779752,FP,INACT,0.3700000047683716	CHEMBL941,FN,ACT,0.009999999776482582	CHEMBL87325,TN,INACT,0.0	CHEMBL1952113,TP,ACT,0.9800000190734863	CHEMBL1077095,TN,INACT,0.009999999776482582	CHEMBL583418,TP,ACT,0.9900000095367432	CHEMBL1258031,TP,ACT,0.9900000095367432	CHEMBL495727,TP,ACT,0.9800000190734863	CHEMBL1173442,TP,ACT,0.9200000166893005	CHEMBL104466,FP,INACT,0.7400000095367432	CHEMBL260307,TP,ACT,0.9900000095367432	CHEMBL223304,TP,ACT,1.0	CHEMBL293251,TN,INACT,0.009999999776482582	CHEMBL3612500,TP,ACT,0.9900000095367432	CHEMBL1081167,TP,ACT,1.0	CHEMBL541988,FP,INACT,0.7099999785423279	CHEMBL450622,FP,INACT,0.7799999713897705	CHEMBL3593295,TP,ACT,0.38999998569488525	CHEMBL456760,FP,INACT,0.25999999046325684	CHEMBL515109,FP,INACT,0.9200000166893005	CHEMBL1791360,TN,INACT,0.019999999552965164	CHEMBL293913,TN,INACT,0.0	CHEMBL1765776,TP,ACT,0.9900000095367432	CHEMBL53463,TN,INACT,0.009999999776482582	CHEMBL3680385,TP,ACT,1.0	CHEMBL3357634,FN,ACT,0.03999999910593033	CHEMBL1807477,TP,ACT,0.9900000095367432	CHEMBL2147259,TN,INACT,0.0	CHEMBL589832,FP,INACT,0.8500000238418579	CHEMBL345862,TN,INACT,0.0	CHEMBL1241683,TN,INACT,0.009999999776482582	CHEMBL3656348,FN,ACT,0.019999999552965164	CHEMBL1240703,TP,ACT,0.9900000095367432	CHEMBL2337367,FP,INACT,0.4300000071525574	CHEMBL89505,TN,INACT,0.03999999910593033	CHEMBL1173150,TP,ACT,1.0	CHEMBL1081510,TP,ACT,0.9900000095367432	CHEMBL238010,TP,ACT,0.9900000095367432	CHEMBL3329399,TN,INACT,0.029999999329447746	CHEMBL481248,TN,INACT,0.0	CHEMBL3329683,TP,ACT,0.5400000214576721	CHEMBL455114,FP,INACT,0.9800000190734863	CHEMBL1076721,FN,ACT,0.009999999776482582	CHEMBL210250,TP,ACT,0.9900000095367432	CHEMBL3781795,FP,INACT,0.9800000190734863	CHEMBL207895,TP,ACT,1.0	CHEMBL1944698,TP,ACT,1.0	CHEMBL3329660,TP,ACT,0.7799999713897705	CHEMBL467321,TN,INACT,0.019999999552965164	CHEMBL1080063,TP,ACT,1.0	CHEMBL265777,FP,INACT,0.9300000071525574	CHEMBL383264,FP,INACT,0.9900000095367432	CHEMBL1774056,FN,ACT,0.03999999910593033	CHEMBL2372113,FP,INACT,0.6100000143051147	CHEMBL2011301,TN,INACT,0.0	CHEMBL574738,TP,ACT,0.9700000286102295	CHEMBL2069624,FP,INACT,0.6399999856948853	CHEMBL559683,TN,INACT,0.0	CHEMBL2382015,TN,INACT,0.0	CHEMBL591504,TN,INACT,0.0	CHEMBL425363,TN,INACT,0.20999999344348907	CHEMBL2337370,TN,INACT,0.019999999552965164	CHEMBL1807481,TP,ACT,1.0	CHEMBL498705,FP,INACT,0.7699999809265137	CHEMBL271955,TP,ACT,1.0	CHEMBL1944701,TP,ACT,1.0	CHEMBL1944870,TP,ACT,1.0	CHEMBL3417192,TP,ACT,0.9900000095367432	CHEMBL450329,TN,INACT,0.009999999776482582	CHEMBL75637,TN,INACT,0.019999999552965164	CHEMBL1230020,FN,ACT,0.0	CHEMBL3656367,TP,ACT,0.9900000095367432	CHEMBL1258149,TP,ACT,0.9900000095367432	CHEMBL1938958,TP,ACT,1.0	CHEMBL438610,FP,INACT,1.0	CHEMBL426004,TP,ACT,1.0	CHEMBL3586175,TN,INACT,0.009999999776482582	CHEMBL360190,TP,ACT,1.0	CHEMBL3355550,TP,ACT,0.9900000095367432	CHEMBL453336,TN,INACT,0.029999999329447746	CHEMBL2047244,TN,INACT,0.009999999776482582	CHEMBL3593292,TP,ACT,0.9900000095367432	CHEMBL3416149,TP,ACT,0.4000000059604645	CHEMBL3593283,TP,ACT,0.9900000095367432	CHEMBL1173541,TP,ACT,1.0	CHEMBL330863,TP,ACT,0.9900000095367432	CHEMBL2402845,FP,INACT,0.9800000190734863	CHEMBL1956892,TN,INACT,0.10000000149011612	CHEMBL154822,TN,INACT,0.0	CHEMBL403776,TP,ACT,0.6600000262260437	CHEMBL1915636,TP,ACT,0.9800000190734863	CHEMBL515432,TN,INACT,0.0	CHEMBL2311806,TP,ACT,0.9599999785423279	CHEMBL1945565,TP,ACT,0.9900000095367432	CHEMBL367113,TP,ACT,0.9900000095367432	CHEMBL76642,TN,INACT,0.05000000074505806	CHEMBL564726,TN,INACT,0.0	CHEMBL185140,TN,INACT,0.019999999552965164	CHEMBL56964,FP,INACT,0.9700000286102295	CHEMBL245966,TN,INACT,0.05999999865889549	CHEMBL2032278,TP,ACT,0.9900000095367432	CHEMBL3814055,FN,ACT,0.09000000357627869	CHEMBL3792973,TP,ACT,0.8999999761581421	CHEMBL521201,FN,ACT,0.07999999821186066	CHEMBL27085,FP,INACT,0.8999999761581421	CHEMBL207858,TP,ACT,0.9900000095367432	CHEMBL3612622,TP,ACT,0.9800000190734863	CHEMBL1807470,TP,ACT,1.0	CHEMBL403706,FN,ACT,0.18000000715255737	CHEMBL3326007,TP,ACT,0.9900000095367432	CHEMBL2047243,TN,INACT,0.019999999552965164	CHEMBL3781192,TN,INACT,0.0	CHEMBL1079354,TP,ACT,0.9900000095367432	CHEMBL557321,TN,INACT,0.0	CHEMBL2063333,TP,ACT,0.9900000095367432	CHEMBL590109,TP,ACT,0.3400000035762787	CHEMBL2403108,FN,ACT,0.0	CHEMBL376787,TP,ACT,1.0	CHEMBL3417188,TP,ACT,0.9900000095367432	CHEMBL1940268,TP,ACT,1.0	CHEMBL596808,FP,INACT,0.9900000095367432	CHEMBL398610,TP,ACT,0.3100000023841858	CHEMBL412102,TP,ACT,1.0	CHEMBL590083,FP,INACT,0.8899999856948853	CHEMBL3358993,TN,INACT,0.019999999552965164	CHEMBL370545,FN,ACT,0.009999999776482582	CHEMBL1822792,TP,ACT,0.9800000190734863	CHEMBL1779745,TN,INACT,0.0	CHEMBL210266,TP,ACT,0.9800000190734863	CHEMBL74645,TN,INACT,0.05999999865889549	CHEMBL1910892,TP,ACT,1.0	CHEMBL2047241,TN,INACT,0.0	CHEMBL104067,FN,ACT,0.019999999552965164	CHEMBL2035047,TP,ACT,1.0	CHEMBL270342,TN,INACT,0.05000000074505806	CHEMBL1938956,TP,ACT,1.0	CHEMBL491473,TP,ACT,0.7599999904632568	CHEMBL3327135,TP,ACT,0.9900000095367432	CHEMBL3793843,TP,ACT,0.9100000262260437	CHEMBL80651,TN,INACT,0.0	CHEMBL8223,FP,INACT,0.9900000095367432	CHEMBL3104852,TN,INACT,0.019999999552965164	CHEMBL3109401,TN,INACT,0.05999999865889549	CHEMBL591050,TN,INACT,0.10000000149011612	

