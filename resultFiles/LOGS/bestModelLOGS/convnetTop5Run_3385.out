CNNModel CHEMBL2828 adam 0.001 30 256 0 0.6 False True
Number of active compounds :	164
Number of inactive compounds :	164
---------------------------------
Run id: CNNModel_CHEMBL2828_adam_0.001_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2828_adam_0.001_30_256_0.6_True/
---------------------------------
Training samples: 209
Validation samples: 66
--
Training Step: 1  | time: 1.301s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/209
[A[ATraining Step: 2  | total loss: [1m[32m0.62398[0m[0m | time: 2.334s
[2K
| Adam | epoch: 001 | loss: 0.62398 - acc: 0.3094 -- iter: 064/209
[A[ATraining Step: 3  | total loss: [1m[32m0.68176[0m[0m | time: 3.382s
[2K
| Adam | epoch: 001 | loss: 0.68176 - acc: 0.3886 -- iter: 096/209
[A[ATraining Step: 4  | total loss: [1m[32m0.69134[0m[0m | time: 4.628s
[2K
| Adam | epoch: 001 | loss: 0.69134 - acc: 0.3784 -- iter: 128/209
[A[ATraining Step: 5  | total loss: [1m[32m0.69285[0m[0m | time: 5.525s
[2K
| Adam | epoch: 001 | loss: 0.69285 - acc: 0.3977 -- iter: 160/209
[A[ATraining Step: 6  | total loss: [1m[32m0.69314[0m[0m | time: 6.673s
[2K
| Adam | epoch: 001 | loss: 0.69314 - acc: 0.3831 -- iter: 192/209
[A[ATraining Step: 7  | total loss: [1m[32m0.69310[0m[0m | time: 8.523s
[2K
| Adam | epoch: 001 | loss: 0.69310 - acc: 0.4720 | val_loss: 0.69737 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 8  | total loss: [1m[32m0.69188[0m[0m | time: 0.519s
[2K
| Adam | epoch: 002 | loss: 0.69188 - acc: 0.5705 -- iter: 032/209
[A[ATraining Step: 9  | total loss: [1m[32m0.68919[0m[0m | time: 1.448s
[2K
| Adam | epoch: 002 | loss: 0.68919 - acc: 0.6110 -- iter: 064/209
[A[ATraining Step: 10  | total loss: [1m[32m0.69800[0m[0m | time: 2.330s
[2K
| Adam | epoch: 002 | loss: 0.69800 - acc: 0.5086 -- iter: 096/209
[A[ATraining Step: 11  | total loss: [1m[32m0.69389[0m[0m | time: 3.224s
[2K
| Adam | epoch: 002 | loss: 0.69389 - acc: 0.5341 -- iter: 128/209
[A[ATraining Step: 12  | total loss: [1m[32m0.69177[0m[0m | time: 4.250s
[2K
| Adam | epoch: 002 | loss: 0.69177 - acc: 0.5469 -- iter: 160/209
[A[ATraining Step: 13  | total loss: [1m[32m0.69475[0m[0m | time: 5.182s
[2K
| Adam | epoch: 002 | loss: 0.69475 - acc: 0.5134 -- iter: 192/209
[A[ATraining Step: 14  | total loss: [1m[32m0.69224[0m[0m | time: 7.101s
[2K
| Adam | epoch: 002 | loss: 0.69224 - acc: 0.5335 | val_loss: 0.70012 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 15  | total loss: [1m[32m0.69597[0m[0m | time: 0.852s
[2K
| Adam | epoch: 003 | loss: 0.69597 - acc: 0.4837 -- iter: 032/209
[A[ATraining Step: 16  | total loss: [1m[32m0.69431[0m[0m | time: 1.411s
[2K
| Adam | epoch: 003 | loss: 0.69431 - acc: 0.5008 -- iter: 064/209
[A[ATraining Step: 17  | total loss: [1m[32m0.69340[0m[0m | time: 2.314s
[2K
| Adam | epoch: 003 | loss: 0.69340 - acc: 0.5111 -- iter: 096/209
[A[ATraining Step: 18  | total loss: [1m[32m0.69245[0m[0m | time: 3.210s
[2K
| Adam | epoch: 003 | loss: 0.69245 - acc: 0.5289 -- iter: 128/209
[A[ATraining Step: 19  | total loss: [1m[32m0.69109[0m[0m | time: 4.137s
[2K
| Adam | epoch: 003 | loss: 0.69109 - acc: 0.5505 -- iter: 160/209
[A[ATraining Step: 20  | total loss: [1m[32m0.69198[0m[0m | time: 4.978s
[2K
| Adam | epoch: 003 | loss: 0.69198 - acc: 0.5343 -- iter: 192/209
[A[ATraining Step: 21  | total loss: [1m[32m0.69351[0m[0m | time: 6.953s
[2K
| Adam | epoch: 003 | loss: 0.69351 - acc: 0.5042 | val_loss: 0.69798 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 22  | total loss: [1m[32m0.69339[0m[0m | time: 1.356s
[2K
| Adam | epoch: 004 | loss: 0.69339 - acc: 0.5030 -- iter: 032/209
[A[ATraining Step: 23  | total loss: [1m[32m0.69440[0m[0m | time: 2.101s
[2K
| Adam | epoch: 004 | loss: 0.69440 - acc: 0.4840 -- iter: 064/209
[A[ATraining Step: 24  | total loss: [1m[32m0.69371[0m[0m | time: 2.566s
[2K
| Adam | epoch: 004 | loss: 0.69371 - acc: 0.4967 -- iter: 096/209
[A[ATraining Step: 25  | total loss: [1m[32m0.69333[0m[0m | time: 3.479s
[2K
| Adam | epoch: 004 | loss: 0.69333 - acc: 0.5057 -- iter: 128/209
[A[ATraining Step: 26  | total loss: [1m[32m0.69431[0m[0m | time: 4.369s
[2K
| Adam | epoch: 004 | loss: 0.69431 - acc: 0.4793 -- iter: 160/209
[A[ATraining Step: 27  | total loss: [1m[32m0.69320[0m[0m | time: 5.285s
[2K
| Adam | epoch: 004 | loss: 0.69320 - acc: 0.5088 -- iter: 192/209
[A[ATraining Step: 28  | total loss: [1m[32m0.69372[0m[0m | time: 7.239s
[2K
| Adam | epoch: 004 | loss: 0.69372 - acc: 0.4909 | val_loss: 0.69558 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 29  | total loss: [1m[32m0.69354[0m[0m | time: 1.232s
[2K
| Adam | epoch: 005 | loss: 0.69354 - acc: 0.4931 -- iter: 032/209
[A[ATraining Step: 30  | total loss: [1m[32m0.69304[0m[0m | time: 2.334s
[2K
| Adam | epoch: 005 | loss: 0.69304 - acc: 0.5096 -- iter: 064/209
[A[ATraining Step: 31  | total loss: [1m[32m0.69289[0m[0m | time: 2.811s
[2K
| Adam | epoch: 005 | loss: 0.69289 - acc: 0.5146 -- iter: 096/209
[A[ATraining Step: 32  | total loss: [1m[32m0.69214[0m[0m | time: 3.300s
[2K
| Adam | epoch: 005 | loss: 0.69214 - acc: 0.5444 -- iter: 128/209
[A[ATraining Step: 33  | total loss: [1m[32m0.69142[0m[0m | time: 4.231s
[2K
| Adam | epoch: 005 | loss: 0.69142 - acc: 0.5669 -- iter: 160/209
[A[ATraining Step: 34  | total loss: [1m[32m0.69086[0m[0m | time: 5.121s
[2K
| Adam | epoch: 005 | loss: 0.69086 - acc: 0.5794 -- iter: 192/209
[A[ATraining Step: 35  | total loss: [1m[32m0.69215[0m[0m | time: 7.095s
[2K
| Adam | epoch: 005 | loss: 0.69215 - acc: 0.5431 | val_loss: 0.69801 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 36  | total loss: [1m[32m0.69207[0m[0m | time: 1.185s
[2K
| Adam | epoch: 006 | loss: 0.69207 - acc: 0.5407 -- iter: 032/209
[A[ATraining Step: 37  | total loss: [1m[32m0.69164[0m[0m | time: 1.994s
[2K
| Adam | epoch: 006 | loss: 0.69164 - acc: 0.5451 -- iter: 064/209
[A[ATraining Step: 38  | total loss: [1m[32m0.69271[0m[0m | time: 2.916s
[2K
| Adam | epoch: 006 | loss: 0.69271 - acc: 0.5240 -- iter: 096/209
[A[ATraining Step: 39  | total loss: [1m[32m0.69383[0m[0m | time: 3.469s
[2K
| Adam | epoch: 006 | loss: 0.69383 - acc: 0.5015 -- iter: 128/209
[A[ATraining Step: 40  | total loss: [1m[32m0.69280[0m[0m | time: 3.989s
[2K
| Adam | epoch: 006 | loss: 0.69280 - acc: 0.5177 -- iter: 160/209
[A[ATraining Step: 41  | total loss: [1m[32m0.69197[0m[0m | time: 4.954s
[2K
| Adam | epoch: 006 | loss: 0.69197 - acc: 0.5307 -- iter: 192/209
[A[ATraining Step: 42  | total loss: [1m[32m0.69118[0m[0m | time: 7.047s
[2K
| Adam | epoch: 006 | loss: 0.69118 - acc: 0.5420 | val_loss: 0.69995 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 43  | total loss: [1m[32m0.69276[0m[0m | time: 1.421s
[2K
| Adam | epoch: 007 | loss: 0.69276 - acc: 0.5181 -- iter: 032/209
[A[ATraining Step: 44  | total loss: [1m[32m0.69331[0m[0m | time: 2.386s
[2K
| Adam | epoch: 007 | loss: 0.69331 - acc: 0.5095 -- iter: 064/209
[A[ATraining Step: 45  | total loss: [1m[32m0.69253[0m[0m | time: 3.279s
[2K
| Adam | epoch: 007 | loss: 0.69253 - acc: 0.5185 -- iter: 096/209
[A[ATraining Step: 46  | total loss: [1m[32m0.69273[0m[0m | time: 4.197s
[2K
| Adam | epoch: 007 | loss: 0.69273 - acc: 0.5154 -- iter: 128/209
[A[ATraining Step: 47  | total loss: [1m[32m0.69329[0m[0m | time: 4.740s
[2K
| Adam | epoch: 007 | loss: 0.69329 - acc: 0.5078 -- iter: 160/209
[A[ATraining Step: 48  | total loss: [1m[32m0.69300[0m[0m | time: 5.270s
[2K
| Adam | epoch: 007 | loss: 0.69300 - acc: 0.5113 -- iter: 192/209
[A[ATraining Step: 49  | total loss: [1m[32m0.69273[0m[0m | time: 7.324s
[2K
| Adam | epoch: 007 | loss: 0.69273 - acc: 0.5141 | val_loss: 0.70011 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 50  | total loss: [1m[32m0.69207[0m[0m | time: 1.439s
[2K
| Adam | epoch: 008 | loss: 0.69207 - acc: 0.5216 -- iter: 032/209
[A[ATraining Step: 51  | total loss: [1m[32m0.69292[0m[0m | time: 2.775s
[2K
| Adam | epoch: 008 | loss: 0.69292 - acc: 0.5088 -- iter: 064/209
[A[ATraining Step: 52  | total loss: [1m[32m0.69328[0m[0m | time: 3.831s
[2K
| Adam | epoch: 008 | loss: 0.69328 - acc: 0.5028 -- iter: 096/209
[A[ATraining Step: 53  | total loss: [1m[32m0.69293[0m[0m | time: 4.687s
[2K
| Adam | epoch: 008 | loss: 0.69293 - acc: 0.5070 -- iter: 128/209
[A[ATraining Step: 54  | total loss: [1m[32m0.69259[0m[0m | time: 5.552s
[2K
| Adam | epoch: 008 | loss: 0.69259 - acc: 0.5105 -- iter: 160/209
[A[ATraining Step: 55  | total loss: [1m[32m0.69259[0m[0m | time: 6.052s
[2K
| Adam | epoch: 008 | loss: 0.69259 - acc: 0.5090 -- iter: 192/209
[A[ATraining Step: 56  | total loss: [1m[32m0.69176[0m[0m | time: 7.571s
[2K
| Adam | epoch: 008 | loss: 0.69176 - acc: 0.5202 | val_loss: 0.70220 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 57  | total loss: [1m[32m0.69074[0m[0m | time: 1.064s
[2K
| Adam | epoch: 009 | loss: 0.69074 - acc: 0.5296 -- iter: 032/209
[A[ATraining Step: 58  | total loss: [1m[32m0.69098[0m[0m | time: 2.069s
[2K
| Adam | epoch: 009 | loss: 0.69098 - acc: 0.5255 -- iter: 064/209
[A[ATraining Step: 59  | total loss: [1m[32m0.69011[0m[0m | time: 3.137s
[2K
| Adam | epoch: 009 | loss: 0.69011 - acc: 0.5305 -- iter: 096/209
[A[ATraining Step: 60  | total loss: [1m[32m0.68958[0m[0m | time: 4.260s
[2K
| Adam | epoch: 009 | loss: 0.68958 - acc: 0.5306 -- iter: 128/209
[A[ATraining Step: 61  | total loss: [1m[32m0.69168[0m[0m | time: 5.252s
[2K
| Adam | epoch: 009 | loss: 0.69168 - acc: 0.5185 -- iter: 160/209
[A[ATraining Step: 62  | total loss: [1m[32m0.69244[0m[0m | time: 6.293s
[2K
| Adam | epoch: 009 | loss: 0.69244 - acc: 0.5121 -- iter: 192/209
[A[ATraining Step: 63  | total loss: [1m[32m0.69230[0m[0m | time: 7.883s
[2K
| Adam | epoch: 009 | loss: 0.69230 - acc: 0.5105 | val_loss: 0.69816 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 64  | total loss: [1m[32m0.69250[0m[0m | time: 0.378s
[2K
| Adam | epoch: 010 | loss: 0.69250 - acc: 0.5055 -- iter: 032/209
[A[ATraining Step: 65  | total loss: [1m[32m0.69261[0m[0m | time: 1.020s
[2K
| Adam | epoch: 010 | loss: 0.69261 - acc: 0.5012 -- iter: 064/209
[A[ATraining Step: 66  | total loss: [1m[32m0.69264[0m[0m | time: 1.689s
[2K
| Adam | epoch: 010 | loss: 0.69264 - acc: 0.4973 -- iter: 096/209
[A[ATraining Step: 67  | total loss: [1m[32m0.69242[0m[0m | time: 2.328s
[2K
| Adam | epoch: 010 | loss: 0.69242 - acc: 0.4976 -- iter: 128/209
[A[ATraining Step: 68  | total loss: [1m[32m0.69197[0m[0m | time: 3.015s
[2K
| Adam | epoch: 010 | loss: 0.69197 - acc: 0.4979 -- iter: 160/209
[A[ATraining Step: 69  | total loss: [1m[32m0.69182[0m[0m | time: 3.660s
[2K
| Adam | epoch: 010 | loss: 0.69182 - acc: 0.4908 -- iter: 192/209
[A[ATraining Step: 70  | total loss: [1m[32m0.68903[0m[0m | time: 5.307s
[2K
| Adam | epoch: 010 | loss: 0.68903 - acc: 0.5099 | val_loss: 0.71122 - val_acc: 0.4091 -- iter: 209/209
--
Training Step: 71  | total loss: [1m[32m0.68803[0m[0m | time: 0.376s
[2K
| Adam | epoch: 011 | loss: 0.68803 - acc: 0.5088 -- iter: 032/209
[A[ATraining Step: 72  | total loss: [1m[32m0.68866[0m[0m | time: 0.740s
[2K
| Adam | epoch: 011 | loss: 0.68866 - acc: 0.5045 -- iter: 064/209
[A[ATraining Step: 73  | total loss: [1m[32m0.68685[0m[0m | time: 1.403s
[2K
| Adam | epoch: 011 | loss: 0.68685 - acc: 0.5138 -- iter: 096/209
[A[ATraining Step: 74  | total loss: [1m[32m0.68846[0m[0m | time: 2.041s
[2K
| Adam | epoch: 011 | loss: 0.68846 - acc: 0.4986 -- iter: 128/209
[A[ATraining Step: 75  | total loss: [1m[32m0.68539[0m[0m | time: 2.698s
[2K
| Adam | epoch: 011 | loss: 0.68539 - acc: 0.5224 -- iter: 160/209
[A[ATraining Step: 76  | total loss: [1m[32m0.68258[0m[0m | time: 3.383s
[2K
| Adam | epoch: 011 | loss: 0.68258 - acc: 0.5502 -- iter: 192/209
[A[ATraining Step: 77  | total loss: [1m[32m0.68101[0m[0m | time: 5.026s
[2K
| Adam | epoch: 011 | loss: 0.68101 - acc: 0.5482 | val_loss: 0.69326 - val_acc: 0.5303 -- iter: 209/209
--
Training Step: 78  | total loss: [1m[32m0.67598[0m[0m | time: 0.660s
[2K
| Adam | epoch: 012 | loss: 0.67598 - acc: 0.5497 -- iter: 032/209
[A[ATraining Step: 79  | total loss: [1m[32m0.66975[0m[0m | time: 1.018s
[2K
| Adam | epoch: 012 | loss: 0.66975 - acc: 0.5704 -- iter: 064/209
[A[ATraining Step: 80  | total loss: [1m[32m0.67418[0m[0m | time: 1.373s
[2K
| Adam | epoch: 012 | loss: 0.67418 - acc: 0.5722 -- iter: 096/209
[A[ATraining Step: 81  | total loss: [1m[32m0.67584[0m[0m | time: 2.041s
[2K
| Adam | epoch: 012 | loss: 0.67584 - acc: 0.5619 -- iter: 128/209
[A[ATraining Step: 82  | total loss: [1m[32m0.67309[0m[0m | time: 3.187s
[2K
| Adam | epoch: 012 | loss: 0.67309 - acc: 0.5776 -- iter: 160/209
[A[ATraining Step: 83  | total loss: [1m[32m0.66906[0m[0m | time: 4.499s
[2K
| Adam | epoch: 012 | loss: 0.66906 - acc: 0.5886 -- iter: 192/209
[A[ATraining Step: 84  | total loss: [1m[32m0.65936[0m[0m | time: 6.829s
[2K
| Adam | epoch: 012 | loss: 0.65936 - acc: 0.5954 | val_loss: 0.74637 - val_acc: 0.5606 -- iter: 209/209
--
Training Step: 85  | total loss: [1m[32m0.65316[0m[0m | time: 0.967s
[2K
| Adam | epoch: 013 | loss: 0.65316 - acc: 0.6046 -- iter: 032/209
[A[ATraining Step: 86  | total loss: [1m[32m0.64819[0m[0m | time: 2.305s
[2K
| Adam | epoch: 013 | loss: 0.64819 - acc: 0.6223 -- iter: 064/209
[A[ATraining Step: 87  | total loss: [1m[32m0.64166[0m[0m | time: 3.072s
[2K
| Adam | epoch: 013 | loss: 0.64166 - acc: 0.6350 -- iter: 096/209
[A[ATraining Step: 88  | total loss: [1m[32m0.63028[0m[0m | time: 3.845s
[2K
| Adam | epoch: 013 | loss: 0.63028 - acc: 0.6480 -- iter: 128/209
[A[ATraining Step: 89  | total loss: [1m[32m0.60752[0m[0m | time: 4.937s
[2K
| Adam | epoch: 013 | loss: 0.60752 - acc: 0.6773 -- iter: 160/209
[A[ATraining Step: 90  | total loss: [1m[32m0.60903[0m[0m | time: 5.815s
[2K
| Adam | epoch: 013 | loss: 0.60903 - acc: 0.6783 -- iter: 192/209
[A[ATraining Step: 91  | total loss: [1m[32m0.59223[0m[0m | time: 7.788s
[2K
| Adam | epoch: 013 | loss: 0.59223 - acc: 0.6886 | val_loss: 0.67999 - val_acc: 0.6515 -- iter: 209/209
--
Training Step: 92  | total loss: [1m[32m0.58992[0m[0m | time: 1.333s
[2K
| Adam | epoch: 014 | loss: 0.58992 - acc: 0.6854 -- iter: 032/209
[A[ATraining Step: 93  | total loss: [1m[32m0.58609[0m[0m | time: 2.611s
[2K
| Adam | epoch: 014 | loss: 0.58609 - acc: 0.6825 -- iter: 064/209
[A[ATraining Step: 94  | total loss: [1m[32m0.58051[0m[0m | time: 3.580s
[2K
| Adam | epoch: 014 | loss: 0.58051 - acc: 0.6892 -- iter: 096/209
[A[ATraining Step: 95  | total loss: [1m[32m0.57253[0m[0m | time: 4.123s
[2K
| Adam | epoch: 014 | loss: 0.57253 - acc: 0.6984 -- iter: 128/209
[A[ATraining Step: 96  | total loss: [1m[32m0.57818[0m[0m | time: 4.685s
[2K
| Adam | epoch: 014 | loss: 0.57818 - acc: 0.6933 -- iter: 160/209
[A[ATraining Step: 97  | total loss: [1m[32m0.56022[0m[0m | time: 5.669s
[2K
| Adam | epoch: 014 | loss: 0.56022 - acc: 0.7122 -- iter: 192/209
[A[ATraining Step: 98  | total loss: [1m[32m0.57162[0m[0m | time: 7.721s
[2K
| Adam | epoch: 014 | loss: 0.57162 - acc: 0.6941 | val_loss: 0.57300 - val_acc: 0.7424 -- iter: 209/209
--
Training Step: 99  | total loss: [1m[32m0.56593[0m[0m | time: 1.327s
[2K
| Adam | epoch: 015 | loss: 0.56593 - acc: 0.6903 -- iter: 032/209
[A[ATraining Step: 100  | total loss: [1m[32m0.55376[0m[0m | time: 2.698s
[2K
| Adam | epoch: 015 | loss: 0.55376 - acc: 0.7025 -- iter: 064/209
[A[ATraining Step: 101  | total loss: [1m[32m0.55040[0m[0m | time: 3.562s
[2K
| Adam | epoch: 015 | loss: 0.55040 - acc: 0.7135 -- iter: 096/209
[A[ATraining Step: 102  | total loss: [1m[32m0.56371[0m[0m | time: 4.497s
[2K
| Adam | epoch: 015 | loss: 0.56371 - acc: 0.7016 -- iter: 128/209
[A[ATraining Step: 103  | total loss: [1m[32m0.55675[0m[0m | time: 5.069s
[2K
| Adam | epoch: 015 | loss: 0.55675 - acc: 0.7095 -- iter: 160/209
[A[ATraining Step: 104  | total loss: [1m[32m0.53755[0m[0m | time: 5.650s
[2K
| Adam | epoch: 015 | loss: 0.53755 - acc: 0.7386 -- iter: 192/209
[A[ATraining Step: 105  | total loss: [1m[32m0.52148[0m[0m | time: 7.592s
[2K
| Adam | epoch: 015 | loss: 0.52148 - acc: 0.7471 | val_loss: 0.59521 - val_acc: 0.7273 -- iter: 209/209
--
Training Step: 106  | total loss: [1m[32m0.50897[0m[0m | time: 1.449s
[2K
| Adam | epoch: 016 | loss: 0.50897 - acc: 0.7567 -- iter: 032/209
[A[ATraining Step: 107  | total loss: [1m[32m0.50985[0m[0m | time: 2.846s
[2K
| Adam | epoch: 016 | loss: 0.50985 - acc: 0.7561 -- iter: 064/209
[A[ATraining Step: 108  | total loss: [1m[32m0.49573[0m[0m | time: 3.986s
[2K
| Adam | epoch: 016 | loss: 0.49573 - acc: 0.7711 -- iter: 096/209
[A[ATraining Step: 109  | total loss: [1m[32m0.48091[0m[0m | time: 4.851s
[2K
| Adam | epoch: 016 | loss: 0.48091 - acc: 0.7783 -- iter: 128/209
[A[ATraining Step: 110  | total loss: [1m[32m0.46727[0m[0m | time: 5.830s
[2K
| Adam | epoch: 016 | loss: 0.46727 - acc: 0.7818 -- iter: 160/209
[A[ATraining Step: 111  | total loss: [1m[32m0.44900[0m[0m | time: 6.335s
[2K
| Adam | epoch: 016 | loss: 0.44900 - acc: 0.7911 -- iter: 192/209
[A[ATraining Step: 112  | total loss: [1m[32m0.43657[0m[0m | time: 7.922s
[2K
| Adam | epoch: 016 | loss: 0.43657 - acc: 0.8002 | val_loss: 0.59775 - val_acc: 0.7273 -- iter: 209/209
--
Training Step: 113  | total loss: [1m[32m0.41199[0m[0m | time: 1.200s
[2K
| Adam | epoch: 017 | loss: 0.41199 - acc: 0.8143 -- iter: 032/209
[A[ATraining Step: 114  | total loss: [1m[32m0.38551[0m[0m | time: 2.525s
[2K
| Adam | epoch: 017 | loss: 0.38551 - acc: 0.8329 -- iter: 064/209
[A[ATraining Step: 115  | total loss: [1m[32m0.37347[0m[0m | time: 3.806s
[2K
| Adam | epoch: 017 | loss: 0.37347 - acc: 0.8402 -- iter: 096/209
[A[ATraining Step: 116  | total loss: [1m[32m0.36731[0m[0m | time: 4.672s
[2K
| Adam | epoch: 017 | loss: 0.36731 - acc: 0.8406 -- iter: 128/209
[A[ATraining Step: 117  | total loss: [1m[32m0.34378[0m[0m | time: 5.583s
[2K
| Adam | epoch: 017 | loss: 0.34378 - acc: 0.8503 -- iter: 160/209
[A[ATraining Step: 118  | total loss: [1m[32m0.35133[0m[0m | time: 6.527s
[2K
| Adam | epoch: 017 | loss: 0.35133 - acc: 0.8496 -- iter: 192/209
[A[ATraining Step: 119  | total loss: [1m[32m0.37472[0m[0m | time: 8.041s
[2K
| Adam | epoch: 017 | loss: 0.37472 - acc: 0.8428 | val_loss: 1.16570 - val_acc: 0.6061 -- iter: 209/209
--
Training Step: 120  | total loss: [1m[32m0.44181[0m[0m | time: 0.821s
[2K
| Adam | epoch: 018 | loss: 0.44181 - acc: 0.8409 -- iter: 032/209
[A[ATraining Step: 121  | total loss: [1m[32m0.41749[0m[0m | time: 2.069s
[2K
| Adam | epoch: 018 | loss: 0.41749 - acc: 0.8509 -- iter: 064/209
[A[ATraining Step: 122  | total loss: [1m[32m0.43521[0m[0m | time: 3.338s
[2K
| Adam | epoch: 018 | loss: 0.43521 - acc: 0.8408 -- iter: 096/209
[A[ATraining Step: 123  | total loss: [1m[32m0.43319[0m[0m | time: 4.215s
[2K
| Adam | epoch: 018 | loss: 0.43319 - acc: 0.8380 -- iter: 128/209
[A[ATraining Step: 124  | total loss: [1m[32m0.41721[0m[0m | time: 5.354s
[2K
| Adam | epoch: 018 | loss: 0.41721 - acc: 0.8448 -- iter: 160/209
[A[ATraining Step: 125  | total loss: [1m[32m0.42705[0m[0m | time: 6.381s
[2K
| Adam | epoch: 018 | loss: 0.42705 - acc: 0.8322 -- iter: 192/209
[A[ATraining Step: 126  | total loss: [1m[32m0.41597[0m[0m | time: 8.435s
[2K
| Adam | epoch: 018 | loss: 0.41597 - acc: 0.8333 | val_loss: 0.80310 - val_acc: 0.6818 -- iter: 209/209
--
Training Step: 127  | total loss: [1m[32m0.39598[0m[0m | time: 0.884s
[2K
| Adam | epoch: 019 | loss: 0.39598 - acc: 0.8406 -- iter: 032/209
[A[ATraining Step: 128  | total loss: [1m[32m0.41325[0m[0m | time: 1.613s
[2K
| Adam | epoch: 019 | loss: 0.41325 - acc: 0.8389 -- iter: 064/209
[A[ATraining Step: 129  | total loss: [1m[32m0.39926[0m[0m | time: 2.918s
[2K
| Adam | epoch: 019 | loss: 0.39926 - acc: 0.8433 -- iter: 096/209
[A[ATraining Step: 130  | total loss: [1m[32m0.38978[0m[0m | time: 3.794s
[2K
| Adam | epoch: 019 | loss: 0.38978 - acc: 0.8433 -- iter: 128/209
[A[ATraining Step: 131  | total loss: [1m[32m0.36955[0m[0m | time: 4.770s
[2K
| Adam | epoch: 019 | loss: 0.36955 - acc: 0.8590 -- iter: 160/209
[A[ATraining Step: 132  | total loss: [1m[32m0.36736[0m[0m | time: 5.778s
[2K
| Adam | epoch: 019 | loss: 0.36736 - acc: 0.8637 -- iter: 192/209
[A[ATraining Step: 133  | total loss: [1m[32m0.35763[0m[0m | time: 7.817s
[2K
| Adam | epoch: 019 | loss: 0.35763 - acc: 0.8680 | val_loss: 0.57444 - val_acc: 0.7273 -- iter: 209/209
--
Training Step: 134  | total loss: [1m[32m0.34533[0m[0m | time: 1.362s
[2K
| Adam | epoch: 020 | loss: 0.34533 - acc: 0.8718 -- iter: 032/209
[A[ATraining Step: 135  | total loss: [1m[32m0.33623[0m[0m | time: 2.138s
[2K
| Adam | epoch: 020 | loss: 0.33623 - acc: 0.8752 -- iter: 064/209
[A[ATraining Step: 136  | total loss: [1m[32m0.34664[0m[0m | time: 2.765s
[2K
| Adam | epoch: 020 | loss: 0.34664 - acc: 0.8760 -- iter: 096/209
[A[ATraining Step: 137  | total loss: [1m[32m0.34847[0m[0m | time: 3.610s
[2K
| Adam | epoch: 020 | loss: 0.34847 - acc: 0.8707 -- iter: 128/209
[A[ATraining Step: 138  | total loss: [1m[32m0.32353[0m[0m | time: 4.544s
[2K
| Adam | epoch: 020 | loss: 0.32353 - acc: 0.8805 -- iter: 160/209
[A[ATraining Step: 139  | total loss: [1m[32m0.30868[0m[0m | time: 5.536s
[2K
| Adam | epoch: 020 | loss: 0.30868 - acc: 0.8893 -- iter: 192/209
[A[ATraining Step: 140  | total loss: [1m[32m0.28685[0m[0m | time: 7.578s
[2K
| Adam | epoch: 020 | loss: 0.28685 - acc: 0.9004 | val_loss: 0.62895 - val_acc: 0.7424 -- iter: 209/209
--
Training Step: 141  | total loss: [1m[32m0.27523[0m[0m | time: 1.446s
[2K
| Adam | epoch: 021 | loss: 0.27523 - acc: 0.9041 -- iter: 032/209
[A[ATraining Step: 142  | total loss: [1m[32m0.25279[0m[0m | time: 2.705s
[2K
| Adam | epoch: 021 | loss: 0.25279 - acc: 0.9137 -- iter: 064/209
[A[ATraining Step: 143  | total loss: [1m[32m0.24348[0m[0m | time: 3.450s
[2K
| Adam | epoch: 021 | loss: 0.24348 - acc: 0.9130 -- iter: 096/209
[A[ATraining Step: 144  | total loss: [1m[32m0.26697[0m[0m | time: 3.937s
[2K
| Adam | epoch: 021 | loss: 0.26697 - acc: 0.9099 -- iter: 128/209
[A[ATraining Step: 145  | total loss: [1m[32m0.24861[0m[0m | time: 4.904s
[2K
| Adam | epoch: 021 | loss: 0.24861 - acc: 0.9189 -- iter: 160/209
[A[ATraining Step: 146  | total loss: [1m[32m0.24637[0m[0m | time: 5.896s
[2K
| Adam | epoch: 021 | loss: 0.24637 - acc: 0.9145 -- iter: 192/209
[A[ATraining Step: 147  | total loss: [1m[32m0.22874[0m[0m | time: 7.922s
[2K
| Adam | epoch: 021 | loss: 0.22874 - acc: 0.9168 | val_loss: 0.79646 - val_acc: 0.7727 -- iter: 209/209
--
Training Step: 148  | total loss: [1m[32m0.21665[0m[0m | time: 1.116s
[2K
| Adam | epoch: 022 | loss: 0.21665 - acc: 0.9158 -- iter: 032/209
[A[ATraining Step: 149  | total loss: [1m[32m0.20311[0m[0m | time: 1.999s
[2K
| Adam | epoch: 022 | loss: 0.20311 - acc: 0.9211 -- iter: 064/209
[A[ATraining Step: 150  | total loss: [1m[32m0.19277[0m[0m | time: 2.937s
[2K
| Adam | epoch: 022 | loss: 0.19277 - acc: 0.9258 -- iter: 096/209
[A[ATraining Step: 151  | total loss: [1m[32m0.17706[0m[0m | time: 3.497s
[2K
| Adam | epoch: 022 | loss: 0.17706 - acc: 0.9332 -- iter: 128/209
[A[ATraining Step: 152  | total loss: [1m[32m0.16209[0m[0m | time: 4.062s
[2K
| Adam | epoch: 022 | loss: 0.16209 - acc: 0.9399 -- iter: 160/209
[A[ATraining Step: 153  | total loss: [1m[32m0.14753[0m[0m | time: 5.080s
[2K
| Adam | epoch: 022 | loss: 0.14753 - acc: 0.9459 -- iter: 192/209
[A[ATraining Step: 154  | total loss: [1m[32m0.13751[0m[0m | time: 7.182s
[2K
| Adam | epoch: 022 | loss: 0.13751 - acc: 0.9482 | val_loss: 0.90010 - val_acc: 0.7273 -- iter: 209/209
--
Training Step: 155  | total loss: [1m[32m0.12521[0m[0m | time: 1.356s
[2K
| Adam | epoch: 023 | loss: 0.12521 - acc: 0.9534 -- iter: 032/209
[A[ATraining Step: 156  | total loss: [1m[32m0.11576[0m[0m | time: 2.346s
[2K
| Adam | epoch: 023 | loss: 0.11576 - acc: 0.9580 -- iter: 064/209
[A[ATraining Step: 157  | total loss: [1m[32m0.10561[0m[0m | time: 3.309s
[2K
| Adam | epoch: 023 | loss: 0.10561 - acc: 0.9622 -- iter: 096/209
[A[ATraining Step: 158  | total loss: [1m[32m0.09721[0m[0m | time: 4.305s
[2K
| Adam | epoch: 023 | loss: 0.09721 - acc: 0.9660 -- iter: 128/209
[A[ATraining Step: 159  | total loss: [1m[32m0.09961[0m[0m | time: 4.872s
[2K
| Adam | epoch: 023 | loss: 0.09961 - acc: 0.9632 -- iter: 160/209
[A[ATraining Step: 160  | total loss: [1m[32m0.10130[0m[0m | time: 5.416s
[2K
| Adam | epoch: 023 | loss: 0.10130 - acc: 0.9610 -- iter: 192/209
[A[ATraining Step: 161  | total loss: [1m[32m0.09349[0m[0m | time: 7.438s
[2K
| Adam | epoch: 023 | loss: 0.09349 - acc: 0.9649 | val_loss: 1.09586 - val_acc: 0.7273 -- iter: 209/209
--
Training Step: 162  | total loss: [1m[32m0.09104[0m[0m | time: 1.039s
[2K
| Adam | epoch: 024 | loss: 0.09104 - acc: 0.9621 -- iter: 032/209
[A[ATraining Step: 163  | total loss: [1m[32m0.09847[0m[0m | time: 2.056s
[2K
| Adam | epoch: 024 | loss: 0.09847 - acc: 0.9565 -- iter: 064/209
[A[ATraining Step: 164  | total loss: [1m[32m0.08966[0m[0m | time: 3.082s
[2K
| Adam | epoch: 024 | loss: 0.08966 - acc: 0.9609 -- iter: 096/209
[A[ATraining Step: 165  | total loss: [1m[32m0.08175[0m[0m | time: 4.141s
[2K
| Adam | epoch: 024 | loss: 0.08175 - acc: 0.9648 -- iter: 128/209
[A[ATraining Step: 166  | total loss: [1m[32m0.07858[0m[0m | time: 5.075s
[2K
| Adam | epoch: 024 | loss: 0.07858 - acc: 0.9652 -- iter: 160/209
[A[ATraining Step: 167  | total loss: [1m[32m0.07186[0m[0m | time: 5.440s
[2K
| Adam | epoch: 024 | loss: 0.07186 - acc: 0.9687 -- iter: 192/209
[A[ATraining Step: 168  | total loss: [1m[32m0.15039[0m[0m | time: 6.819s
[2K
| Adam | epoch: 024 | loss: 0.15039 - acc: 0.9600 | val_loss: 0.87357 - val_acc: 0.7576 -- iter: 209/209
--
Training Step: 169  | total loss: [1m[32m0.13711[0m[0m | time: 0.690s
[2K
| Adam | epoch: 025 | loss: 0.13711 - acc: 0.9640 -- iter: 032/209
[A[ATraining Step: 170  | total loss: [1m[32m0.12472[0m[0m | time: 1.343s
[2K
| Adam | epoch: 025 | loss: 0.12472 - acc: 0.9676 -- iter: 064/209
[A[ATraining Step: 171  | total loss: [1m[32m0.11501[0m[0m | time: 2.001s
[2K
| Adam | epoch: 025 | loss: 0.11501 - acc: 0.9709 -- iter: 096/209
[A[ATraining Step: 172  | total loss: [1m[32m0.10837[0m[0m | time: 2.654s
[2K
| Adam | epoch: 025 | loss: 0.10837 - acc: 0.9738 -- iter: 128/209
[A[ATraining Step: 173  | total loss: [1m[32m0.10168[0m[0m | time: 3.314s
[2K
| Adam | epoch: 025 | loss: 0.10168 - acc: 0.9733 -- iter: 160/209
[A[ATraining Step: 174  | total loss: [1m[32m0.09302[0m[0m | time: 3.958s
[2K
| Adam | epoch: 025 | loss: 0.09302 - acc: 0.9760 -- iter: 192/209
[A[ATraining Step: 175  | total loss: [1m[32m0.08667[0m[0m | time: 5.331s
[2K
| Adam | epoch: 025 | loss: 0.08667 - acc: 0.9784 | val_loss: 0.85165 - val_acc: 0.7576 -- iter: 209/209
--
Training Step: 176  | total loss: [1m[32m0.08384[0m[0m | time: 0.371s
[2K
| Adam | epoch: 026 | loss: 0.08384 - acc: 0.9805 -- iter: 032/209
[A[ATraining Step: 177  | total loss: [1m[32m0.07745[0m[0m | time: 1.010s
[2K
| Adam | epoch: 026 | loss: 0.07745 - acc: 0.9825 -- iter: 064/209
[A[ATraining Step: 178  | total loss: [1m[32m0.07103[0m[0m | time: 1.648s
[2K
| Adam | epoch: 026 | loss: 0.07103 - acc: 0.9842 -- iter: 096/209
[A[ATraining Step: 179  | total loss: [1m[32m0.06569[0m[0m | time: 2.322s
[2K
| Adam | epoch: 026 | loss: 0.06569 - acc: 0.9858 -- iter: 128/209
[A[ATraining Step: 180  | total loss: [1m[32m0.06068[0m[0m | time: 2.972s
[2K
| Adam | epoch: 026 | loss: 0.06068 - acc: 0.9872 -- iter: 160/209
[A[ATraining Step: 181  | total loss: [1m[32m0.05559[0m[0m | time: 3.619s
[2K
| Adam | epoch: 026 | loss: 0.05559 - acc: 0.9885 -- iter: 192/209
[A[ATraining Step: 182  | total loss: [1m[32m0.05168[0m[0m | time: 5.281s
[2K
| Adam | epoch: 026 | loss: 0.05168 - acc: 0.9896 | val_loss: 0.84664 - val_acc: 0.7576 -- iter: 209/209
--
Training Step: 183  | total loss: [1m[32m0.04918[0m[0m | time: 0.362s
[2K
| Adam | epoch: 027 | loss: 0.04918 - acc: 0.9907 -- iter: 032/209
[A[ATraining Step: 184  | total loss: [1m[32m0.08206[0m[0m | time: 0.721s
[2K
| Adam | epoch: 027 | loss: 0.08206 - acc: 0.9857 -- iter: 064/209
[A[ATraining Step: 185  | total loss: [1m[32m0.07496[0m[0m | time: 1.964s
[2K
| Adam | epoch: 027 | loss: 0.07496 - acc: 0.9872 -- iter: 096/209
[A[ATraining Step: 186  | total loss: [1m[32m0.06816[0m[0m | time: 3.275s
[2K
| Adam | epoch: 027 | loss: 0.06816 - acc: 0.9884 -- iter: 128/209
[A[ATraining Step: 187  | total loss: [1m[32m0.06194[0m[0m | time: 4.509s
[2K
| Adam | epoch: 027 | loss: 0.06194 - acc: 0.9896 -- iter: 160/209
[A[ATraining Step: 188  | total loss: [1m[32m0.05735[0m[0m | time: 5.427s
[2K
| Adam | epoch: 027 | loss: 0.05735 - acc: 0.9906 -- iter: 192/209
[A[ATraining Step: 189  | total loss: [1m[32m0.05306[0m[0m | time: 7.389s
[2K
| Adam | epoch: 027 | loss: 0.05306 - acc: 0.9916 | val_loss: 0.92645 - val_acc: 0.7576 -- iter: 209/209
--
Training Step: 190  | total loss: [1m[32m0.04962[0m[0m | time: 1.310s
[2K
| Adam | epoch: 028 | loss: 0.04962 - acc: 0.9924 -- iter: 032/209
[A[ATraining Step: 191  | total loss: [1m[32m0.04588[0m[0m | time: 2.042s
[2K
| Adam | epoch: 028 | loss: 0.04588 - acc: 0.9932 -- iter: 064/209
[A[ATraining Step: 192  | total loss: [1m[32m0.07716[0m[0m | time: 2.798s
[2K
| Adam | epoch: 028 | loss: 0.07716 - acc: 0.9880 -- iter: 096/209
[A[ATraining Step: 193  | total loss: [1m[32m0.07031[0m[0m | time: 3.979s
[2K
| Adam | epoch: 028 | loss: 0.07031 - acc: 0.9892 -- iter: 128/209
[A[ATraining Step: 194  | total loss: [1m[32m0.07623[0m[0m | time: 4.860s
[2K
| Adam | epoch: 028 | loss: 0.07623 - acc: 0.9840 -- iter: 160/209
[A[ATraining Step: 195  | total loss: [1m[32m0.07218[0m[0m | time: 5.806s
[2K
| Adam | epoch: 028 | loss: 0.07218 - acc: 0.9856 -- iter: 192/209
[A[ATraining Step: 196  | total loss: [1m[32m0.06606[0m[0m | time: 7.769s
[2K
| Adam | epoch: 028 | loss: 0.06606 - acc: 0.9870 | val_loss: 0.95149 - val_acc: 0.7424 -- iter: 209/209
--
Training Step: 197  | total loss: [1m[32m0.06009[0m[0m | time: 1.272s
[2K
| Adam | epoch: 029 | loss: 0.06009 - acc: 0.9883 -- iter: 032/209
[A[ATraining Step: 198  | total loss: [1m[32m0.05487[0m[0m | time: 2.567s
[2K
| Adam | epoch: 029 | loss: 0.05487 - acc: 0.9895 -- iter: 064/209
[A[ATraining Step: 199  | total loss: [1m[32m0.05590[0m[0m | time: 3.371s
[2K
| Adam | epoch: 029 | loss: 0.05590 - acc: 0.9874 -- iter: 096/209
[A[ATraining Step: 200  | total loss: [1m[32m0.06954[0m[0m | time: 5.041s
[2K
| Adam | epoch: 029 | loss: 0.06954 - acc: 0.9769 | val_loss: 0.93345 - val_acc: 0.7576 -- iter: 128/209
--
Training Step: 201  | total loss: [1m[32m0.06881[0m[0m | time: 6.139s
[2K
| Adam | epoch: 029 | loss: 0.06881 - acc: 0.9792 -- iter: 160/209
[A[ATraining Step: 202  | total loss: [1m[32m0.06339[0m[0m | time: 7.291s
[2K
| Adam | epoch: 029 | loss: 0.06339 - acc: 0.9813 -- iter: 192/209
[A[ATraining Step: 203  | total loss: [1m[32m0.05811[0m[0m | time: 9.248s
[2K
| Adam | epoch: 029 | loss: 0.05811 - acc: 0.9832 | val_loss: 0.88428 - val_acc: 0.7273 -- iter: 209/209
--
Training Step: 204  | total loss: [1m[32m0.05324[0m[0m | time: 0.879s
[2K
| Adam | epoch: 030 | loss: 0.05324 - acc: 0.9849 -- iter: 032/209
[A[ATraining Step: 205  | total loss: [1m[32m0.05284[0m[0m | time: 1.837s
[2K
| Adam | epoch: 030 | loss: 0.05284 - acc: 0.9864 -- iter: 064/209
[A[ATraining Step: 206  | total loss: [1m[32m0.05123[0m[0m | time: 2.775s
[2K
| Adam | epoch: 030 | loss: 0.05123 - acc: 0.9877 -- iter: 096/209
[A[ATraining Step: 207  | total loss: [1m[32m0.04689[0m[0m | time: 3.337s
[2K
| Adam | epoch: 030 | loss: 0.04689 - acc: 0.9890 -- iter: 128/209
[A[ATraining Step: 208  | total loss: [1m[32m0.06451[0m[0m | time: 3.844s
[2K
| Adam | epoch: 030 | loss: 0.06451 - acc: 0.9842 -- iter: 160/209
[A[ATraining Step: 209  | total loss: [1m[32m0.05858[0m[0m | time: 4.939s
[2K
| Adam | epoch: 030 | loss: 0.05858 - acc: 0.9858 -- iter: 192/209
[A[ATraining Step: 210  | total loss: [1m[32m0.05372[0m[0m | time: 7.020s
[2K
| Adam | epoch: 030 | loss: 0.05372 - acc: 0.9872 | val_loss: 0.85408 - val_acc: 0.7576 -- iter: 209/209
--
Validation AUC:0.8537511870845204
Validation AUPRC:0.9133757008696548
Test AUC:0.9253456221198156
Test AUPRC:0.9193263160161615
BestTestF1Score	0.85	0.71	0.85	0.78	0.94	29	8	27	2	0.23
BestTestMCCScore	0.75	0.62	0.8	0.91	0.65	20	2	33	11	0.99
BestTestAccuracyScore	0.85	0.71	0.85	0.78	0.94	29	8	27	2	0.23
BestValidationF1Score	0.82	0.56	0.79	0.8	0.85	33	8	19	6	0.23
BestValidationMCC	0.72	0.59	0.74	1.0	0.56	22	0	27	17	0.99
BestValidationAccuracy	0.82	0.56	0.79	0.8	0.85	33	8	19	6	0.23
TestPredictions (Threshold:0.99)
CHEMBL3235555,TP,ACT,1.0	CHEMBL2392390,TN,INACT,0.0	CHEMBL232542,TN,INACT,0.029999999329447746	CHEMBL1242756,TN,INACT,0.20999999344348907	CHEMBL404941,FN,ACT,0.9599999785423279	CHEMBL1242032,TN,INACT,0.05999999865889549	CHEMBL361708,TP,ACT,0.9900000095367432	CHEMBL246166,TN,INACT,0.5400000214576721	CHEMBL1241772,TN,INACT,0.10000000149011612	CHEMBL1241863,TN,INACT,0.11999999731779099	CHEMBL1436125,TN,INACT,0.0	CHEMBL3235570,TP,ACT,1.0	CHEMBL571357,TP,ACT,0.9900000095367432	CHEMBL3780985,TN,INACT,0.36000001430511475	CHEMBL2071623,FN,ACT,0.9700000286102295	CHEMBL3235542,TP,ACT,1.0	CHEMBL3629013,TN,INACT,0.029999999329447746	CHEMBL379218,FN,ACT,0.009999999776482582	CHEMBL2392236,TN,INACT,0.0	CHEMBL1276308,TN,INACT,0.019999999552965164	CHEMBL2392388,TN,INACT,0.019999999552965164	CHEMBL3235545,TP,ACT,1.0	CHEMBL3235185,FN,ACT,0.9700000286102295	CHEMBL564235,TN,INACT,0.0	CHEMBL2071618,FN,ACT,0.949999988079071	CHEMBL3823628,TN,INACT,0.009999999776482582	CHEMBL3314274,TN,INACT,0.05000000074505806	CHEMBL3235178,FN,ACT,0.7900000214576721	CHEMBL2203555,FN,ACT,0.23000000417232513	CHEMBL556746,TN,INACT,0.0	CHEMBL2392233,TN,INACT,0.0	CHEMBL3314278,TN,INACT,0.5099999904632568	CHEMBL474208,TN,INACT,0.0	CHEMBL2392232,TN,INACT,0.0	CHEMBL3120986,FN,ACT,0.10999999940395355	CHEMBL270302,TN,INACT,0.1599999964237213	CHEMBL2203563,TP,ACT,1.0	CHEMBL390156,TN,INACT,0.0	CHEMBL2392379,TN,INACT,0.9800000190734863	CHEMBL585533,TP,ACT,0.9900000095367432	CHEMBL428647,FP,INACT,0.9900000095367432	CHEMBL3235539,TP,ACT,1.0	CHEMBL515109,FP,INACT,1.0	CHEMBL327820,TN,INACT,0.3799999952316284	CHEMBL1668417,TN,INACT,0.0	CHEMBL1668413,TN,INACT,0.0	CHEMBL233958,TN,INACT,0.03999999910593033	CHEMBL3235574,TP,ACT,0.9900000095367432	CHEMBL3235541,TP,ACT,1.0	CHEMBL2392378,TN,INACT,0.029999999329447746	CHEMBL1933551,FN,ACT,0.7900000214576721	CHEMBL2203557,TP,ACT,1.0	CHEMBL2071614,TP,ACT,1.0	CHEMBL215417,TN,INACT,0.0	CHEMBL3314279,TN,INACT,0.18000000715255737	CHEMBL3235547,TP,ACT,1.0	CHEMBL2203564,TP,ACT,0.9900000095367432	CHEMBL3235188,FN,ACT,0.6000000238418579	CHEMBL2071607,TP,ACT,0.9900000095367432	CHEMBL3235569,TP,ACT,0.9900000095367432	CHEMBL600795,TN,INACT,0.019999999552965164	CHEMBL469776,TN,INACT,0.7699999809265137	CHEMBL3235556,TP,ACT,1.0	CHEMBL3235566,TP,ACT,1.0	CHEMBL3120985,FN,ACT,0.44999998807907104	CHEMBL264406,TP,ACT,0.9900000095367432	

