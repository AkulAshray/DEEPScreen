CNNModel CHEMBL4026 adam 0.0005 30 128 0 0.8 False True
Number of active compounds :	342
Number of inactive compounds :	247
---------------------------------
Run id: CNNModel_CHEMBL4026_adam_0.0005_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4026_adam_0.0005_30_128_0.8_True/
---------------------------------
Training samples: 352
Validation samples: 111
--
Training Step: 1  | time: 1.687s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/352
[A[ATraining Step: 2  | total loss: [1m[32m0.62401[0m[0m | time: 2.815s
[2K
| Adam | epoch: 001 | loss: 0.62401 - acc: 0.3937 -- iter: 064/352
[A[ATraining Step: 3  | total loss: [1m[32m0.68298[0m[0m | time: 3.706s
[2K
| Adam | epoch: 001 | loss: 0.68298 - acc: 0.3273 -- iter: 096/352
[A[ATraining Step: 4  | total loss: [1m[32m0.69156[0m[0m | time: 4.921s
[2K
| Adam | epoch: 001 | loss: 0.69156 - acc: 0.3865 -- iter: 128/352
[A[ATraining Step: 5  | total loss: [1m[32m0.69149[0m[0m | time: 6.343s
[2K
| Adam | epoch: 001 | loss: 0.69149 - acc: 0.5733 -- iter: 160/352
[A[ATraining Step: 6  | total loss: [1m[32m0.69391[0m[0m | time: 7.790s
[2K
| Adam | epoch: 001 | loss: 0.69391 - acc: 0.4659 -- iter: 192/352
[A[ATraining Step: 7  | total loss: [1m[32m0.69115[0m[0m | time: 9.767s
[2K
| Adam | epoch: 001 | loss: 0.69115 - acc: 0.6176 -- iter: 224/352
[A[ATraining Step: 8  | total loss: [1m[32m0.69023[0m[0m | time: 13.634s
[2K
| Adam | epoch: 001 | loss: 0.69023 - acc: 0.6218 -- iter: 256/352
[A[ATraining Step: 9  | total loss: [1m[32m0.68717[0m[0m | time: 14.629s
[2K
| Adam | epoch: 001 | loss: 0.68717 - acc: 0.6400 -- iter: 288/352
[A[ATraining Step: 10  | total loss: [1m[32m0.69390[0m[0m | time: 15.582s
[2K
| Adam | epoch: 001 | loss: 0.69390 - acc: 0.5388 -- iter: 320/352
[A[ATraining Step: 11  | total loss: [1m[32m0.68795[0m[0m | time: 17.711s
[2K
| Adam | epoch: 001 | loss: 0.68795 - acc: 0.5648 | val_loss: 0.69842 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 12  | total loss: [1m[32m0.68229[0m[0m | time: 1.347s
[2K
| Adam | epoch: 002 | loss: 0.68229 - acc: 0.5919 -- iter: 032/352
[A[ATraining Step: 13  | total loss: [1m[32m0.67645[0m[0m | time: 2.654s
[2K
| Adam | epoch: 002 | loss: 0.67645 - acc: 0.6061 -- iter: 064/352
[A[ATraining Step: 14  | total loss: [1m[32m0.70337[0m[0m | time: 4.091s
[2K
| Adam | epoch: 002 | loss: 0.70337 - acc: 0.5371 -- iter: 096/352
[A[ATraining Step: 15  | total loss: [1m[32m0.70675[0m[0m | time: 5.955s
[2K
| Adam | epoch: 002 | loss: 0.70675 - acc: 0.5226 -- iter: 128/352
[A[ATraining Step: 16  | total loss: [1m[32m0.69602[0m[0m | time: 14.915s
[2K
| Adam | epoch: 002 | loss: 0.69602 - acc: 0.5493 -- iter: 160/352
[A[ATraining Step: 17  | total loss: [1m[32m0.68707[0m[0m | time: 15.936s
[2K
| Adam | epoch: 002 | loss: 0.68707 - acc: 0.5765 -- iter: 192/352
[A[ATraining Step: 18  | total loss: [1m[32m0.69145[0m[0m | time: 17.004s
[2K
| Adam | epoch: 002 | loss: 0.69145 - acc: 0.5500 -- iter: 224/352
[A[ATraining Step: 19  | total loss: [1m[32m0.69347[0m[0m | time: 18.034s
[2K
| Adam | epoch: 002 | loss: 0.69347 - acc: 0.5334 -- iter: 256/352
[A[ATraining Step: 20  | total loss: [1m[32m0.69077[0m[0m | time: 19.234s
[2K
| Adam | epoch: 002 | loss: 0.69077 - acc: 0.5427 -- iter: 288/352
[A[ATraining Step: 21  | total loss: [1m[32m0.69095[0m[0m | time: 20.286s
[2K
| Adam | epoch: 002 | loss: 0.69095 - acc: 0.5392 -- iter: 320/352
[A[ATraining Step: 22  | total loss: [1m[32m0.69109[0m[0m | time: 22.250s
[2K
| Adam | epoch: 002 | loss: 0.69109 - acc: 0.5368 | val_loss: 0.69320 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 23  | total loss: [1m[32m0.69072[0m[0m | time: 1.210s
[2K
| Adam | epoch: 003 | loss: 0.69072 - acc: 0.5352 -- iter: 032/352
[A[ATraining Step: 24  | total loss: [1m[32m0.68980[0m[0m | time: 5.774s
[2K
| Adam | epoch: 003 | loss: 0.68980 - acc: 0.5429 -- iter: 064/352
[A[ATraining Step: 25  | total loss: [1m[32m0.68936[0m[0m | time: 12.087s
[2K
| Adam | epoch: 003 | loss: 0.68936 - acc: 0.5482 -- iter: 096/352
[A[ATraining Step: 26  | total loss: [1m[32m0.69224[0m[0m | time: 13.018s
[2K
| Adam | epoch: 003 | loss: 0.69224 - acc: 0.5189 -- iter: 128/352
[A[ATraining Step: 27  | total loss: [1m[32m0.68851[0m[0m | time: 13.988s
[2K
| Adam | epoch: 003 | loss: 0.68851 - acc: 0.5623 -- iter: 160/352
[A[ATraining Step: 28  | total loss: [1m[32m0.68789[0m[0m | time: 15.025s
[2K
| Adam | epoch: 003 | loss: 0.68789 - acc: 0.5701 -- iter: 192/352
[A[ATraining Step: 29  | total loss: [1m[32m0.68662[0m[0m | time: 16.131s
[2K
| Adam | epoch: 003 | loss: 0.68662 - acc: 0.5835 -- iter: 224/352
[A[ATraining Step: 30  | total loss: [1m[32m0.68756[0m[0m | time: 17.244s
[2K
| Adam | epoch: 003 | loss: 0.68756 - acc: 0.5711 -- iter: 256/352
[A[ATraining Step: 31  | total loss: [1m[32m0.68437[0m[0m | time: 18.100s
[2K
| Adam | epoch: 003 | loss: 0.68437 - acc: 0.5980 -- iter: 288/352
[A[ATraining Step: 32  | total loss: [1m[32m0.68832[0m[0m | time: 19.526s
[2K
| Adam | epoch: 003 | loss: 0.68832 - acc: 0.5619 -- iter: 320/352
[A[ATraining Step: 33  | total loss: [1m[32m0.68716[0m[0m | time: 21.868s
[2K
| Adam | epoch: 003 | loss: 0.68716 - acc: 0.5689 | val_loss: 0.69483 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 34  | total loss: [1m[32m0.68712[0m[0m | time: 6.776s
[2K
| Adam | epoch: 004 | loss: 0.68712 - acc: 0.5675 -- iter: 032/352
[A[ATraining Step: 35  | total loss: [1m[32m0.69287[0m[0m | time: 7.732s
[2K
| Adam | epoch: 004 | loss: 0.69287 - acc: 0.5337 -- iter: 064/352
[A[ATraining Step: 36  | total loss: [1m[32m0.69039[0m[0m | time: 8.768s
[2K
| Adam | epoch: 004 | loss: 0.69039 - acc: 0.5460 -- iter: 096/352
[A[ATraining Step: 37  | total loss: [1m[32m0.68873[0m[0m | time: 9.800s
[2K
| Adam | epoch: 004 | loss: 0.68873 - acc: 0.5556 -- iter: 128/352
[A[ATraining Step: 38  | total loss: [1m[32m0.68953[0m[0m | time: 10.973s
[2K
| Adam | epoch: 004 | loss: 0.68953 - acc: 0.5508 -- iter: 160/352
[A[ATraining Step: 39  | total loss: [1m[32m0.69120[0m[0m | time: 12.000s
[2K
| Adam | epoch: 004 | loss: 0.69120 - acc: 0.5411 -- iter: 192/352
[A[ATraining Step: 40  | total loss: [1m[32m0.69537[0m[0m | time: 12.873s
[2K
| Adam | epoch: 004 | loss: 0.69537 - acc: 0.5158 -- iter: 224/352
[A[ATraining Step: 41  | total loss: [1m[32m0.69346[0m[0m | time: 14.439s
[2K
| Adam | epoch: 004 | loss: 0.69346 - acc: 0.5244 -- iter: 256/352
[A[ATraining Step: 42  | total loss: [1m[32m0.69212[0m[0m | time: 15.802s
[2K
| Adam | epoch: 004 | loss: 0.69212 - acc: 0.5312 -- iter: 288/352
[A[ATraining Step: 43  | total loss: [1m[32m0.68944[0m[0m | time: 17.079s
[2K
| Adam | epoch: 004 | loss: 0.68944 - acc: 0.5478 -- iter: 320/352
[A[ATraining Step: 44  | total loss: [1m[32m0.69072[0m[0m | time: 22.972s
[2K
| Adam | epoch: 004 | loss: 0.69072 - acc: 0.5395 | val_loss: 0.69410 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 45  | total loss: [1m[32m0.68834[0m[0m | time: 1.023s
[2K
| Adam | epoch: 005 | loss: 0.68834 - acc: 0.5540 -- iter: 032/352
[A[ATraining Step: 46  | total loss: [1m[32m0.68641[0m[0m | time: 2.051s
[2K
| Adam | epoch: 005 | loss: 0.68641 - acc: 0.5659 -- iter: 064/352
[A[ATraining Step: 47  | total loss: [1m[32m0.68628[0m[0m | time: 3.204s
[2K
| Adam | epoch: 005 | loss: 0.68628 - acc: 0.5653 -- iter: 096/352
[A[ATraining Step: 48  | total loss: [1m[32m0.68812[0m[0m | time: 4.075s
[2K
| Adam | epoch: 005 | loss: 0.68812 - acc: 0.5548 -- iter: 128/352
[A[ATraining Step: 49  | total loss: [1m[32m0.68979[0m[0m | time: 5.282s
[2K
| Adam | epoch: 005 | loss: 0.68979 - acc: 0.5462 -- iter: 160/352
[A[ATraining Step: 50  | total loss: [1m[32m0.68709[0m[0m | time: 6.702s
[2K
| Adam | epoch: 005 | loss: 0.68709 - acc: 0.5584 -- iter: 192/352
[A[ATraining Step: 51  | total loss: [1m[32m0.68979[0m[0m | time: 8.076s
[2K
| Adam | epoch: 005 | loss: 0.68979 - acc: 0.5447 -- iter: 224/352
[A[ATraining Step: 52  | total loss: [1m[32m0.68899[0m[0m | time: 8.996s
[2K
| Adam | epoch: 005 | loss: 0.68899 - acc: 0.5474 -- iter: 256/352
[A[ATraining Step: 53  | total loss: [1m[32m0.68928[0m[0m | time: 9.965s
[2K
| Adam | epoch: 005 | loss: 0.68928 - acc: 0.5450 -- iter: 288/352
[A[ATraining Step: 54  | total loss: [1m[32m0.68487[0m[0m | time: 10.922s
[2K
| Adam | epoch: 005 | loss: 0.68487 - acc: 0.5657 -- iter: 320/352
[A[ATraining Step: 55  | total loss: [1m[32m0.68379[0m[0m | time: 12.898s
[2K
| Adam | epoch: 005 | loss: 0.68379 - acc: 0.5697 | val_loss: 0.69800 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 56  | total loss: [1m[32m0.68738[0m[0m | time: 0.613s
[2K
| Adam | epoch: 006 | loss: 0.68738 - acc: 0.5555 -- iter: 032/352
[A[ATraining Step: 57  | total loss: [1m[32m0.68813[0m[0m | time: 1.264s
[2K
| Adam | epoch: 006 | loss: 0.68813 - acc: 0.5521 -- iter: 064/352
[A[ATraining Step: 58  | total loss: [1m[32m0.68765[0m[0m | time: 1.888s
[2K
| Adam | epoch: 006 | loss: 0.68765 - acc: 0.5536 -- iter: 096/352
[A[ATraining Step: 59  | total loss: [1m[32m0.69162[0m[0m | time: 2.515s
[2K
| Adam | epoch: 006 | loss: 0.69162 - acc: 0.5380 -- iter: 128/352
[A[ATraining Step: 60  | total loss: [1m[32m0.69235[0m[0m | time: 3.160s
[2K
| Adam | epoch: 006 | loss: 0.69235 - acc: 0.5329 -- iter: 160/352
[A[ATraining Step: 61  | total loss: [1m[32m0.69296[0m[0m | time: 3.788s
[2K
| Adam | epoch: 006 | loss: 0.69296 - acc: 0.5286 -- iter: 192/352
[A[ATraining Step: 62  | total loss: [1m[32m0.68998[0m[0m | time: 4.414s
[2K
| Adam | epoch: 006 | loss: 0.68998 - acc: 0.5451 -- iter: 224/352
[A[ATraining Step: 63  | total loss: [1m[32m0.69009[0m[0m | time: 5.024s
[2K
| Adam | epoch: 006 | loss: 0.69009 - acc: 0.5433 -- iter: 256/352
[A[ATraining Step: 64  | total loss: [1m[32m0.68895[0m[0m | time: 5.645s
[2K
| Adam | epoch: 006 | loss: 0.68895 - acc: 0.5496 -- iter: 288/352
[A[ATraining Step: 65  | total loss: [1m[32m0.69037[0m[0m | time: 6.349s
[2K
| Adam | epoch: 006 | loss: 0.69037 - acc: 0.5396 -- iter: 320/352
[A[ATraining Step: 66  | total loss: [1m[32m0.68882[0m[0m | time: 8.461s
[2K
| Adam | epoch: 006 | loss: 0.68882 - acc: 0.5500 | val_loss: 0.69342 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 67  | total loss: [1m[32m0.68802[0m[0m | time: 0.841s
[2K
| Adam | epoch: 007 | loss: 0.68802 - acc: 0.5553 -- iter: 032/352
[A[ATraining Step: 68  | total loss: [1m[32m0.68775[0m[0m | time: 1.506s
[2K
| Adam | epoch: 007 | loss: 0.68775 - acc: 0.5561 -- iter: 064/352
[A[ATraining Step: 69  | total loss: [1m[32m0.68810[0m[0m | time: 2.111s
[2K
| Adam | epoch: 007 | loss: 0.68810 - acc: 0.5532 -- iter: 096/352
[A[ATraining Step: 70  | total loss: [1m[32m0.68857[0m[0m | time: 2.733s
[2K
| Adam | epoch: 007 | loss: 0.68857 - acc: 0.5507 -- iter: 128/352
[A[ATraining Step: 71  | total loss: [1m[32m0.68873[0m[0m | time: 3.350s
[2K
| Adam | epoch: 007 | loss: 0.68873 - acc: 0.5485 -- iter: 160/352
[A[ATraining Step: 72  | total loss: [1m[32m0.68838[0m[0m | time: 3.966s
[2K
| Adam | epoch: 007 | loss: 0.68838 - acc: 0.5500 -- iter: 192/352
[A[ATraining Step: 73  | total loss: [1m[32m0.68805[0m[0m | time: 4.624s
[2K
| Adam | epoch: 007 | loss: 0.68805 - acc: 0.5514 -- iter: 224/352
[A[ATraining Step: 74  | total loss: [1m[32m0.68821[0m[0m | time: 5.329s
[2K
| Adam | epoch: 007 | loss: 0.68821 - acc: 0.5492 -- iter: 256/352
[A[ATraining Step: 75  | total loss: [1m[32m0.68838[0m[0m | time: 5.962s
[2K
| Adam | epoch: 007 | loss: 0.68838 - acc: 0.5473 -- iter: 288/352
[A[ATraining Step: 76  | total loss: [1m[32m0.68984[0m[0m | time: 6.580s
[2K
| Adam | epoch: 007 | loss: 0.68984 - acc: 0.5389 -- iter: 320/352
[A[ATraining Step: 77  | total loss: [1m[32m0.68864[0m[0m | time: 8.202s
[2K
| Adam | epoch: 007 | loss: 0.68864 - acc: 0.5447 | val_loss: 0.69453 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 78  | total loss: [1m[32m0.68822[0m[0m | time: 0.639s
[2K
| Adam | epoch: 008 | loss: 0.68822 - acc: 0.5465 -- iter: 032/352
[A[ATraining Step: 79  | total loss: [1m[32m0.68892[0m[0m | time: 1.319s
[2K
| Adam | epoch: 008 | loss: 0.68892 - acc: 0.5417 -- iter: 064/352
[A[ATraining Step: 80  | total loss: [1m[32m0.68732[0m[0m | time: 1.971s
[2K
| Adam | epoch: 008 | loss: 0.68732 - acc: 0.5502 -- iter: 096/352
[A[ATraining Step: 81  | total loss: [1m[32m0.68634[0m[0m | time: 2.575s
[2K
| Adam | epoch: 008 | loss: 0.68634 - acc: 0.5546 -- iter: 128/352
[A[ATraining Step: 82  | total loss: [1m[32m0.68454[0m[0m | time: 3.214s
[2K
| Adam | epoch: 008 | loss: 0.68454 - acc: 0.5617 -- iter: 160/352
[A[ATraining Step: 83  | total loss: [1m[32m0.68369[0m[0m | time: 3.819s
[2K
| Adam | epoch: 008 | loss: 0.68369 - acc: 0.5649 -- iter: 192/352
[A[ATraining Step: 84  | total loss: [1m[32m0.68623[0m[0m | time: 4.457s
[2K
| Adam | epoch: 008 | loss: 0.68623 - acc: 0.5553 -- iter: 224/352
[A[ATraining Step: 85  | total loss: [1m[32m0.68880[0m[0m | time: 5.107s
[2K
| Adam | epoch: 008 | loss: 0.68880 - acc: 0.5466 -- iter: 256/352
[A[ATraining Step: 86  | total loss: [1m[32m0.69160[0m[0m | time: 5.755s
[2K
| Adam | epoch: 008 | loss: 0.69160 - acc: 0.5357 -- iter: 288/352
[A[ATraining Step: 87  | total loss: [1m[32m0.68973[0m[0m | time: 6.361s
[2K
| Adam | epoch: 008 | loss: 0.68973 - acc: 0.5415 -- iter: 320/352
[A[ATraining Step: 88  | total loss: [1m[32m0.69186[0m[0m | time: 7.999s
[2K
| Adam | epoch: 008 | loss: 0.69186 - acc: 0.5280 | val_loss: 0.69232 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 89  | total loss: [1m[32m0.69361[0m[0m | time: 0.645s
[2K
| Adam | epoch: 009 | loss: 0.69361 - acc: 0.5158 -- iter: 032/352
[A[ATraining Step: 90  | total loss: [1m[32m0.69357[0m[0m | time: 1.254s
[2K
| Adam | epoch: 009 | loss: 0.69357 - acc: 0.5142 -- iter: 064/352
[A[ATraining Step: 91  | total loss: [1m[32m0.69262[0m[0m | time: 1.877s
[2K
| Adam | epoch: 009 | loss: 0.69262 - acc: 0.5222 -- iter: 096/352
[A[ATraining Step: 92  | total loss: [1m[32m0.69205[0m[0m | time: 2.536s
[2K
| Adam | epoch: 009 | loss: 0.69205 - acc: 0.5262 -- iter: 128/352
[A[ATraining Step: 93  | total loss: [1m[32m0.69051[0m[0m | time: 3.141s
[2K
| Adam | epoch: 009 | loss: 0.69051 - acc: 0.5486 -- iter: 160/352
[A[ATraining Step: 94  | total loss: [1m[32m0.69017[0m[0m | time: 3.809s
[2K
| Adam | epoch: 009 | loss: 0.69017 - acc: 0.5531 -- iter: 192/352
[A[ATraining Step: 95  | total loss: [1m[32m0.69041[0m[0m | time: 4.425s
[2K
| Adam | epoch: 009 | loss: 0.69041 - acc: 0.5478 -- iter: 224/352
[A[ATraining Step: 96  | total loss: [1m[32m0.68967[0m[0m | time: 5.120s
[2K
| Adam | epoch: 009 | loss: 0.68967 - acc: 0.5555 -- iter: 256/352
[A[ATraining Step: 97  | total loss: [1m[32m0.68894[0m[0m | time: 5.748s
[2K
| Adam | epoch: 009 | loss: 0.68894 - acc: 0.5625 -- iter: 288/352
[A[ATraining Step: 98  | total loss: [1m[32m0.68834[0m[0m | time: 6.369s
[2K
| Adam | epoch: 009 | loss: 0.68834 - acc: 0.5687 -- iter: 320/352
[A[ATraining Step: 99  | total loss: [1m[32m0.68866[0m[0m | time: 8.019s
[2K
| Adam | epoch: 009 | loss: 0.68866 - acc: 0.5618 | val_loss: 0.69169 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 100  | total loss: [1m[32m0.68853[0m[0m | time: 0.671s
[2K
| Adam | epoch: 010 | loss: 0.68853 - acc: 0.5588 -- iter: 032/352
[A[ATraining Step: 101  | total loss: [1m[32m0.68805[0m[0m | time: 1.286s
[2K
| Adam | epoch: 010 | loss: 0.68805 - acc: 0.5623 -- iter: 064/352
[A[ATraining Step: 102  | total loss: [1m[32m0.68906[0m[0m | time: 2.347s
[2K
| Adam | epoch: 010 | loss: 0.68906 - acc: 0.5498 -- iter: 096/352
[A[ATraining Step: 103  | total loss: [1m[32m0.68855[0m[0m | time: 3.660s
[2K
| Adam | epoch: 010 | loss: 0.68855 - acc: 0.5511 -- iter: 128/352
[A[ATraining Step: 104  | total loss: [1m[32m0.68762[0m[0m | time: 4.972s
[2K
| Adam | epoch: 010 | loss: 0.68762 - acc: 0.5553 -- iter: 160/352
[A[ATraining Step: 105  | total loss: [1m[32m0.68776[0m[0m | time: 6.085s
[2K
| Adam | epoch: 010 | loss: 0.68776 - acc: 0.5498 -- iter: 192/352
[A[ATraining Step: 106  | total loss: [1m[32m0.68561[0m[0m | time: 6.999s
[2K
| Adam | epoch: 010 | loss: 0.68561 - acc: 0.5605 -- iter: 224/352
[A[ATraining Step: 107  | total loss: [1m[32m0.68316[0m[0m | time: 7.992s
[2K
| Adam | epoch: 010 | loss: 0.68316 - acc: 0.5732 -- iter: 256/352
[A[ATraining Step: 108  | total loss: [1m[32m0.68157[0m[0m | time: 8.983s
[2K
| Adam | epoch: 010 | loss: 0.68157 - acc: 0.5752 -- iter: 288/352
[A[ATraining Step: 109  | total loss: [1m[32m0.67966[0m[0m | time: 10.125s
[2K
| Adam | epoch: 010 | loss: 0.67966 - acc: 0.5771 -- iter: 320/352
[A[ATraining Step: 110  | total loss: [1m[32m0.68207[0m[0m | time: 12.108s
[2K
| Adam | epoch: 010 | loss: 0.68207 - acc: 0.5694 | val_loss: 0.69713 - val_acc: 0.5135 -- iter: 352/352
--
Training Step: 111  | total loss: [1m[32m0.68826[0m[0m | time: 1.358s
[2K
| Adam | epoch: 011 | loss: 0.68826 - acc: 0.5531 -- iter: 032/352
[A[ATraining Step: 112  | total loss: [1m[32m0.68310[0m[0m | time: 10.264s
[2K
| Adam | epoch: 011 | loss: 0.68310 - acc: 0.5634 -- iter: 064/352
[A[ATraining Step: 113  | total loss: [1m[32m0.68073[0m[0m | time: 46.774s
[2K
| Adam | epoch: 011 | loss: 0.68073 - acc: 0.5633 -- iter: 096/352
[A[ATraining Step: 114  | total loss: [1m[32m0.67886[0m[0m | time: 47.779s
[2K
| Adam | epoch: 011 | loss: 0.67886 - acc: 0.5663 -- iter: 128/352
[A[ATraining Step: 115  | total loss: [1m[32m0.68157[0m[0m | time: 48.799s
[2K
| Adam | epoch: 011 | loss: 0.68157 - acc: 0.5534 -- iter: 160/352
[A[ATraining Step: 116  | total loss: [1m[32m0.67991[0m[0m | time: 49.798s
[2K
| Adam | epoch: 011 | loss: 0.67991 - acc: 0.5481 -- iter: 192/352
[A[ATraining Step: 117  | total loss: [1m[32m0.67804[0m[0m | time: 50.899s
[2K
| Adam | epoch: 011 | loss: 0.67804 - acc: 0.5589 -- iter: 224/352
[A[ATraining Step: 118  | total loss: [1m[32m0.67697[0m[0m | time: 52.090s
[2K
| Adam | epoch: 011 | loss: 0.67697 - acc: 0.5530 -- iter: 256/352
[A[ATraining Step: 119  | total loss: [1m[32m0.67540[0m[0m | time: 53.055s
[2K
| Adam | epoch: 011 | loss: 0.67540 - acc: 0.5540 -- iter: 288/352
[A[ATraining Step: 120  | total loss: [1m[32m0.67812[0m[0m | time: 54.377s
[2K
| Adam | epoch: 011 | loss: 0.67812 - acc: 0.5455 -- iter: 320/352
[A[ATraining Step: 121  | total loss: [1m[32m0.68030[0m[0m | time: 56.852s
[2K
| Adam | epoch: 011 | loss: 0.68030 - acc: 0.5378 | val_loss: 0.67955 - val_acc: 0.6306 -- iter: 352/352
--
Training Step: 122  | total loss: [1m[32m0.67836[0m[0m | time: 32.840s
[2K
| Adam | epoch: 012 | loss: 0.67836 - acc: 0.5371 -- iter: 032/352
[A[ATraining Step: 123  | total loss: [1m[32m0.67539[0m[0m | time: 64.363s
[2K
| Adam | epoch: 012 | loss: 0.67539 - acc: 0.5490 -- iter: 064/352
[A[ATraining Step: 124  | total loss: [1m[32m0.67228[0m[0m | time: 65.450s
[2K
| Adam | epoch: 012 | loss: 0.67228 - acc: 0.5660 -- iter: 096/352
[A[ATraining Step: 125  | total loss: [1m[32m0.66937[0m[0m | time: 66.521s
[2K
| Adam | epoch: 012 | loss: 0.66937 - acc: 0.5719 -- iter: 128/352
[A[ATraining Step: 126  | total loss: [1m[32m0.67309[0m[0m | time: 67.619s
[2K
| Adam | epoch: 012 | loss: 0.67309 - acc: 0.5710 -- iter: 160/352
[A[ATraining Step: 127  | total loss: [1m[32m0.66631[0m[0m | time: 68.855s
[2K
| Adam | epoch: 012 | loss: 0.66631 - acc: 0.5795 -- iter: 192/352
[A[ATraining Step: 128  | total loss: [1m[32m0.66005[0m[0m | time: 69.928s
[2K
| Adam | epoch: 012 | loss: 0.66005 - acc: 0.5934 -- iter: 224/352
[A[ATraining Step: 129  | total loss: [1m[32m0.65762[0m[0m | time: 70.982s
[2K
| Adam | epoch: 012 | loss: 0.65762 - acc: 0.5997 -- iter: 256/352
[A[ATraining Step: 130  | total loss: [1m[32m0.65415[0m[0m | time: 72.459s
[2K
| Adam | epoch: 012 | loss: 0.65415 - acc: 0.6085 -- iter: 288/352
[A[ATraining Step: 131  | total loss: [1m[32m0.65918[0m[0m | time: 73.841s
[2K
| Adam | epoch: 012 | loss: 0.65918 - acc: 0.5945 -- iter: 320/352
[A[ATraining Step: 132  | total loss: [1m[32m0.65735[0m[0m | time: 99.297s
[2K
| Adam | epoch: 012 | loss: 0.65735 - acc: 0.5976 | val_loss: 0.67295 - val_acc: 0.6306 -- iter: 352/352
--
Training Step: 133  | total loss: [1m[32m0.65241[0m[0m | time: 28.507s
[2K
| Adam | epoch: 013 | loss: 0.65241 - acc: 0.6003 -- iter: 032/352
[A[ATraining Step: 134  | total loss: [1m[32m0.63827[0m[0m | time: 29.535s
[2K
| Adam | epoch: 013 | loss: 0.63827 - acc: 0.6059 -- iter: 064/352
[A[ATraining Step: 135  | total loss: [1m[32m0.64323[0m[0m | time: 30.676s
[2K
| Adam | epoch: 013 | loss: 0.64323 - acc: 0.6016 -- iter: 096/352
[A[ATraining Step: 136  | total loss: [1m[32m0.63780[0m[0m | time: 31.801s
[2K
| Adam | epoch: 013 | loss: 0.63780 - acc: 0.6039 -- iter: 128/352
[A[ATraining Step: 137  | total loss: [1m[32m0.65175[0m[0m | time: 33.011s
[2K
| Adam | epoch: 013 | loss: 0.65175 - acc: 0.5935 -- iter: 160/352
[A[ATraining Step: 138  | total loss: [1m[32m0.64518[0m[0m | time: 34.122s
[2K
| Adam | epoch: 013 | loss: 0.64518 - acc: 0.6029 -- iter: 192/352
[A[ATraining Step: 139  | total loss: [1m[32m0.64039[0m[0m | time: 35.286s
[2K
| Adam | epoch: 013 | loss: 0.64039 - acc: 0.6145 -- iter: 224/352
[A[ATraining Step: 140  | total loss: [1m[32m0.64011[0m[0m | time: 36.937s
[2K
| Adam | epoch: 013 | loss: 0.64011 - acc: 0.6218 -- iter: 256/352
[A[ATraining Step: 141  | total loss: [1m[32m0.63716[0m[0m | time: 38.360s
[2K
| Adam | epoch: 013 | loss: 0.63716 - acc: 0.6284 -- iter: 288/352
[A[ATraining Step: 142  | total loss: [1m[32m0.63874[0m[0m | time: 39.429s
[2K
| Adam | epoch: 013 | loss: 0.63874 - acc: 0.6280 -- iter: 320/352
[A[ATraining Step: 143  | total loss: [1m[32m0.64320[0m[0m | time: 44.228s
[2K
| Adam | epoch: 013 | loss: 0.64320 - acc: 0.6152 | val_loss: 0.64909 - val_acc: 0.6937 -- iter: 352/352
--
Training Step: 144  | total loss: [1m[32m0.63029[0m[0m | time: 1.103s
[2K
| Adam | epoch: 014 | loss: 0.63029 - acc: 0.6381 -- iter: 032/352
[A[ATraining Step: 145  | total loss: [1m[32m0.61461[0m[0m | time: 2.629s
[2K
| Adam | epoch: 014 | loss: 0.61461 - acc: 0.6461 -- iter: 064/352
[A[ATraining Step: 146  | total loss: [1m[32m0.60816[0m[0m | time: 3.704s
[2K
| Adam | epoch: 014 | loss: 0.60816 - acc: 0.6472 -- iter: 096/352
[A[ATraining Step: 147  | total loss: [1m[32m0.62392[0m[0m | time: 4.804s
[2K
| Adam | epoch: 014 | loss: 0.62392 - acc: 0.6387 -- iter: 128/352
[A[ATraining Step: 148  | total loss: [1m[32m0.62986[0m[0m | time: 6.229s
[2K
| Adam | epoch: 014 | loss: 0.62986 - acc: 0.6311 -- iter: 160/352
[A[ATraining Step: 149  | total loss: [1m[32m0.61646[0m[0m | time: 7.681s
[2K
| Adam | epoch: 014 | loss: 0.61646 - acc: 0.6555 -- iter: 192/352
[A[ATraining Step: 150  | total loss: [1m[32m0.61190[0m[0m | time: 8.641s
[2K
| Adam | epoch: 014 | loss: 0.61190 - acc: 0.6524 -- iter: 224/352
[A[ATraining Step: 151  | total loss: [1m[32m0.60187[0m[0m | time: 20.187s
[2K
| Adam | epoch: 014 | loss: 0.60187 - acc: 0.6653 -- iter: 256/352
[A[ATraining Step: 152  | total loss: [1m[32m0.60690[0m[0m | time: 21.272s
[2K
| Adam | epoch: 014 | loss: 0.60690 - acc: 0.6581 -- iter: 288/352
[A[ATraining Step: 153  | total loss: [1m[32m0.62029[0m[0m | time: 22.325s
[2K
| Adam | epoch: 014 | loss: 0.62029 - acc: 0.6392 -- iter: 320/352
[A[ATraining Step: 154  | total loss: [1m[32m0.61367[0m[0m | time: 24.382s
[2K
| Adam | epoch: 014 | loss: 0.61367 - acc: 0.6472 | val_loss: 0.65022 - val_acc: 0.6847 -- iter: 352/352
--
Training Step: 155  | total loss: [1m[32m0.60930[0m[0m | time: 1.110s
[2K
| Adam | epoch: 015 | loss: 0.60930 - acc: 0.6668 -- iter: 032/352
[A[ATraining Step: 156  | total loss: [1m[32m0.61025[0m[0m | time: 2.613s
[2K
| Adam | epoch: 015 | loss: 0.61025 - acc: 0.6658 -- iter: 064/352
[A[ATraining Step: 157  | total loss: [1m[32m0.61027[0m[0m | time: 4.175s
[2K
| Adam | epoch: 015 | loss: 0.61027 - acc: 0.6679 -- iter: 096/352
[A[ATraining Step: 158  | total loss: [1m[32m0.61924[0m[0m | time: 5.326s
[2K
| Adam | epoch: 015 | loss: 0.61924 - acc: 0.6605 -- iter: 128/352
[A[ATraining Step: 159  | total loss: [1m[32m0.62269[0m[0m | time: 32.081s
[2K
| Adam | epoch: 015 | loss: 0.62269 - acc: 0.6601 -- iter: 160/352
[A[ATraining Step: 160  | total loss: [1m[32m0.62318[0m[0m | time: 44.431s
[2K
| Adam | epoch: 015 | loss: 0.62318 - acc: 0.6503 -- iter: 192/352
[A[ATraining Step: 161  | total loss: [1m[32m0.61855[0m[0m | time: 45.414s
[2K
| Adam | epoch: 015 | loss: 0.61855 - acc: 0.6540 -- iter: 224/352
[A[ATraining Step: 162  | total loss: [1m[32m0.61964[0m[0m | time: 46.548s
[2K
| Adam | epoch: 015 | loss: 0.61964 - acc: 0.6511 -- iter: 256/352
[A[ATraining Step: 163  | total loss: [1m[32m0.61455[0m[0m | time: 47.747s
[2K
| Adam | epoch: 015 | loss: 0.61455 - acc: 0.6610 -- iter: 288/352
[A[ATraining Step: 164  | total loss: [1m[32m0.61046[0m[0m | time: 49.040s
[2K
| Adam | epoch: 015 | loss: 0.61046 - acc: 0.6731 -- iter: 320/352
[A[ATraining Step: 165  | total loss: [1m[32m0.61422[0m[0m | time: 51.420s
[2K
| Adam | epoch: 015 | loss: 0.61422 - acc: 0.6745 | val_loss: 0.66067 - val_acc: 0.6847 -- iter: 352/352
--
Training Step: 166  | total loss: [1m[32m0.61206[0m[0m | time: 1.525s
[2K
| Adam | epoch: 016 | loss: 0.61206 - acc: 0.6695 -- iter: 032/352
[A[ATraining Step: 167  | total loss: [1m[32m0.60788[0m[0m | time: 2.768s
[2K
| Adam | epoch: 016 | loss: 0.60788 - acc: 0.6682 -- iter: 064/352
[A[ATraining Step: 168  | total loss: [1m[32m0.60633[0m[0m | time: 13.031s
[2K
| Adam | epoch: 016 | loss: 0.60633 - acc: 0.6608 -- iter: 096/352
[A[ATraining Step: 169  | total loss: [1m[32m0.60387[0m[0m | time: 46.865s
[2K
| Adam | epoch: 016 | loss: 0.60387 - acc: 0.6666 -- iter: 128/352
[A[ATraining Step: 170  | total loss: [1m[32m0.59449[0m[0m | time: 47.929s
[2K
| Adam | epoch: 016 | loss: 0.59449 - acc: 0.6718 -- iter: 160/352
[A[ATraining Step: 171  | total loss: [1m[32m0.59283[0m[0m | time: 49.150s
[2K
| Adam | epoch: 016 | loss: 0.59283 - acc: 0.6702 -- iter: 192/352
[A[ATraining Step: 172  | total loss: [1m[32m0.59588[0m[0m | time: 50.294s
[2K
| Adam | epoch: 016 | loss: 0.59588 - acc: 0.6813 -- iter: 224/352
[A[ATraining Step: 173  | total loss: [1m[32m0.59405[0m[0m | time: 51.608s
[2K
| Adam | epoch: 016 | loss: 0.59405 - acc: 0.6882 -- iter: 256/352
[A[ATraining Step: 174  | total loss: [1m[32m0.58822[0m[0m | time: 52.822s
[2K
| Adam | epoch: 016 | loss: 0.58822 - acc: 0.6975 -- iter: 288/352
[A[ATraining Step: 175  | total loss: [1m[32m0.57687[0m[0m | time: 53.792s
[2K
| Adam | epoch: 016 | loss: 0.57687 - acc: 0.7028 -- iter: 320/352
[A[ATraining Step: 176  | total loss: [1m[32m0.57619[0m[0m | time: 56.010s
[2K
| Adam | epoch: 016 | loss: 0.57619 - acc: 0.6981 | val_loss: 0.83546 - val_acc: 0.6126 -- iter: 352/352
--
Training Step: 177  | total loss: [1m[32m0.56051[0m[0m | time: 1.086s
[2K
| Adam | epoch: 017 | loss: 0.56051 - acc: 0.7095 -- iter: 032/352
[A[ATraining Step: 178  | total loss: [1m[32m0.57487[0m[0m | time: 1.767s
[2K
| Adam | epoch: 017 | loss: 0.57487 - acc: 0.7042 -- iter: 064/352
[A[ATraining Step: 179  | total loss: [1m[32m0.59993[0m[0m | time: 2.408s
[2K
| Adam | epoch: 017 | loss: 0.59993 - acc: 0.6932 -- iter: 096/352
[A[ATraining Step: 180  | total loss: [1m[32m0.58497[0m[0m | time: 3.166s
[2K
| Adam | epoch: 017 | loss: 0.58497 - acc: 0.7020 -- iter: 128/352
[A[ATraining Step: 181  | total loss: [1m[32m0.56884[0m[0m | time: 3.844s
[2K
| Adam | epoch: 017 | loss: 0.56884 - acc: 0.7130 -- iter: 160/352
[A[ATraining Step: 182  | total loss: [1m[32m0.56367[0m[0m | time: 4.483s
[2K
| Adam | epoch: 017 | loss: 0.56367 - acc: 0.7199 -- iter: 192/352
[A[ATraining Step: 183  | total loss: [1m[32m0.56338[0m[0m | time: 5.163s
[2K
| Adam | epoch: 017 | loss: 0.56338 - acc: 0.7260 -- iter: 224/352
[A[ATraining Step: 184  | total loss: [1m[32m0.56565[0m[0m | time: 5.813s
[2K
| Adam | epoch: 017 | loss: 0.56565 - acc: 0.7190 -- iter: 256/352
[A[ATraining Step: 185  | total loss: [1m[32m0.56201[0m[0m | time: 6.517s
[2K
| Adam | epoch: 017 | loss: 0.56201 - acc: 0.7221 -- iter: 288/352
[A[ATraining Step: 186  | total loss: [1m[32m0.55802[0m[0m | time: 7.190s
[2K
| Adam | epoch: 017 | loss: 0.55802 - acc: 0.7280 -- iter: 320/352
[A[ATraining Step: 187  | total loss: [1m[32m0.55182[0m[0m | time: 8.851s
[2K
| Adam | epoch: 017 | loss: 0.55182 - acc: 0.7365 | val_loss: 0.60135 - val_acc: 0.7117 -- iter: 352/352
--
Training Step: 188  | total loss: [1m[32m0.55340[0m[0m | time: 0.671s
[2K
| Adam | epoch: 018 | loss: 0.55340 - acc: 0.7441 -- iter: 032/352
[A[ATraining Step: 189  | total loss: [1m[32m0.53515[0m[0m | time: 1.347s
[2K
| Adam | epoch: 018 | loss: 0.53515 - acc: 0.7572 -- iter: 064/352
[A[ATraining Step: 190  | total loss: [1m[32m0.53228[0m[0m | time: 2.012s
[2K
| Adam | epoch: 018 | loss: 0.53228 - acc: 0.7596 -- iter: 096/352
[A[ATraining Step: 191  | total loss: [1m[32m0.53450[0m[0m | time: 2.678s
[2K
| Adam | epoch: 018 | loss: 0.53450 - acc: 0.7555 -- iter: 128/352
[A[ATraining Step: 192  | total loss: [1m[32m0.52828[0m[0m | time: 3.347s
[2K
| Adam | epoch: 018 | loss: 0.52828 - acc: 0.7612 -- iter: 160/352
[A[ATraining Step: 193  | total loss: [1m[32m0.52341[0m[0m | time: 3.991s
[2K
| Adam | epoch: 018 | loss: 0.52341 - acc: 0.7632 -- iter: 192/352
[A[ATraining Step: 194  | total loss: [1m[32m0.52112[0m[0m | time: 4.636s
[2K
| Adam | epoch: 018 | loss: 0.52112 - acc: 0.7588 -- iter: 224/352
[A[ATraining Step: 195  | total loss: [1m[32m0.51438[0m[0m | time: 5.300s
[2K
| Adam | epoch: 018 | loss: 0.51438 - acc: 0.7610 -- iter: 256/352
[A[ATraining Step: 196  | total loss: [1m[32m0.51629[0m[0m | time: 5.987s
[2K
| Adam | epoch: 018 | loss: 0.51629 - acc: 0.7537 -- iter: 288/352
[A[ATraining Step: 197  | total loss: [1m[32m0.50925[0m[0m | time: 6.648s
[2K
| Adam | epoch: 018 | loss: 0.50925 - acc: 0.7564 -- iter: 320/352
[A[ATraining Step: 198  | total loss: [1m[32m0.51313[0m[0m | time: 8.329s
[2K
| Adam | epoch: 018 | loss: 0.51313 - acc: 0.7495 | val_loss: 0.61250 - val_acc: 0.6847 -- iter: 352/352
--
Training Step: 199  | total loss: [1m[32m0.51838[0m[0m | time: 1.354s
[2K
| Adam | epoch: 019 | loss: 0.51838 - acc: 0.7402 -- iter: 032/352
[A[ATraining Step: 200  | total loss: [1m[32m0.50841[0m[0m | time: 3.333s
[2K
| Adam | epoch: 019 | loss: 0.50841 - acc: 0.7443 | val_loss: 0.73366 - val_acc: 0.5766 -- iter: 064/352
--
Training Step: 201  | total loss: [1m[32m0.49571[0m[0m | time: 4.458s
[2K
| Adam | epoch: 019 | loss: 0.49571 - acc: 0.7542 -- iter: 096/352
[A[ATraining Step: 202  | total loss: [1m[32m0.49148[0m[0m | time: 5.887s
[2K
| Adam | epoch: 019 | loss: 0.49148 - acc: 0.7569 -- iter: 128/352
[A[ATraining Step: 203  | total loss: [1m[32m0.50446[0m[0m | time: 7.041s
[2K
| Adam | epoch: 019 | loss: 0.50446 - acc: 0.7531 -- iter: 160/352
[A[ATraining Step: 204  | total loss: [1m[32m0.51082[0m[0m | time: 8.224s
[2K
| Adam | epoch: 019 | loss: 0.51082 - acc: 0.7497 -- iter: 192/352
[A[ATraining Step: 205  | total loss: [1m[32m0.50361[0m[0m | time: 9.713s
[2K
| Adam | epoch: 019 | loss: 0.50361 - acc: 0.7528 -- iter: 224/352
[A[ATraining Step: 206  | total loss: [1m[32m0.49807[0m[0m | time: 11.057s
[2K
| Adam | epoch: 019 | loss: 0.49807 - acc: 0.7557 -- iter: 256/352
[A[ATraining Step: 207  | total loss: [1m[32m0.51106[0m[0m | time: 12.049s
[2K
| Adam | epoch: 019 | loss: 0.51106 - acc: 0.7457 -- iter: 288/352
[A[ATraining Step: 208  | total loss: [1m[32m0.50452[0m[0m | time: 13.138s
[2K
| Adam | epoch: 019 | loss: 0.50452 - acc: 0.7555 -- iter: 320/352
[A[ATraining Step: 209  | total loss: [1m[32m0.49873[0m[0m | time: 15.275s
[2K
| Adam | epoch: 019 | loss: 0.49873 - acc: 0.7612 | val_loss: 0.58771 - val_acc: 0.6847 -- iter: 352/352
--
Training Step: 210  | total loss: [1m[32m0.50422[0m[0m | time: 1.153s
[2K
| Adam | epoch: 020 | loss: 0.50422 - acc: 0.7601 -- iter: 032/352
[A[ATraining Step: 211  | total loss: [1m[32m0.48563[0m[0m | time: 2.362s
[2K
| Adam | epoch: 020 | loss: 0.48563 - acc: 0.7810 -- iter: 064/352
[A[ATraining Step: 212  | total loss: [1m[32m0.47601[0m[0m | time: 3.784s
[2K
| Adam | epoch: 020 | loss: 0.47601 - acc: 0.7904 -- iter: 096/352
[A[ATraining Step: 213  | total loss: [1m[32m0.48282[0m[0m | time: 5.276s
[2K
| Adam | epoch: 020 | loss: 0.48282 - acc: 0.7801 -- iter: 128/352
[A[ATraining Step: 214  | total loss: [1m[32m0.46980[0m[0m | time: 6.226s
[2K
| Adam | epoch: 020 | loss: 0.46980 - acc: 0.7927 -- iter: 160/352
[A[ATraining Step: 215  | total loss: [1m[32m0.45466[0m[0m | time: 21.231s
[2K
| Adam | epoch: 020 | loss: 0.45466 - acc: 0.8009 -- iter: 192/352
[A[ATraining Step: 216  | total loss: [1m[32m0.44098[0m[0m | time: 22.396s
[2K
| Adam | epoch: 020 | loss: 0.44098 - acc: 0.8115 -- iter: 224/352
[A[ATraining Step: 217  | total loss: [1m[32m0.42387[0m[0m | time: 23.556s
[2K
| Adam | epoch: 020 | loss: 0.42387 - acc: 0.8272 -- iter: 256/352
[A[ATraining Step: 218  | total loss: [1m[32m0.41507[0m[0m | time: 24.618s
[2K
| Adam | epoch: 020 | loss: 0.41507 - acc: 0.8320 -- iter: 288/352
[A[ATraining Step: 219  | total loss: [1m[32m0.42853[0m[0m | time: 25.925s
[2K
| Adam | epoch: 020 | loss: 0.42853 - acc: 0.8238 -- iter: 320/352
[A[ATraining Step: 220  | total loss: [1m[32m0.45724[0m[0m | time: 28.302s
[2K
| Adam | epoch: 020 | loss: 0.45724 - acc: 0.8070 | val_loss: 0.60481 - val_acc: 0.7297 -- iter: 352/352
--
Training Step: 221  | total loss: [1m[32m0.43737[0m[0m | time: 1.431s
[2K
| Adam | epoch: 021 | loss: 0.43737 - acc: 0.8138 -- iter: 032/352
[A[ATraining Step: 222  | total loss: [1m[32m0.42143[0m[0m | time: 3.107s
[2K
| Adam | epoch: 021 | loss: 0.42143 - acc: 0.8231 -- iter: 064/352
[A[ATraining Step: 223  | total loss: [1m[32m0.40927[0m[0m | time: 36.283s
[2K
| Adam | epoch: 021 | loss: 0.40927 - acc: 0.8314 -- iter: 096/352
[A[ATraining Step: 224  | total loss: [1m[32m0.40929[0m[0m | time: 37.401s
[2K
| Adam | epoch: 021 | loss: 0.40929 - acc: 0.8326 -- iter: 128/352
[A[ATraining Step: 225  | total loss: [1m[32m0.40057[0m[0m | time: 38.625s
[2K
| Adam | epoch: 021 | loss: 0.40057 - acc: 0.8369 -- iter: 160/352
[A[ATraining Step: 226  | total loss: [1m[32m0.38398[0m[0m | time: 39.791s
[2K
| Adam | epoch: 021 | loss: 0.38398 - acc: 0.8469 -- iter: 192/352
[A[ATraining Step: 227  | total loss: [1m[32m0.36467[0m[0m | time: 40.943s
[2K
| Adam | epoch: 021 | loss: 0.36467 - acc: 0.8529 -- iter: 224/352
[A[ATraining Step: 228  | total loss: [1m[32m0.36338[0m[0m | time: 42.208s
[2K
| Adam | epoch: 021 | loss: 0.36338 - acc: 0.8551 -- iter: 256/352
[A[ATraining Step: 229  | total loss: [1m[32m0.35938[0m[0m | time: 43.323s
[2K
| Adam | epoch: 021 | loss: 0.35938 - acc: 0.8571 -- iter: 288/352
[A[ATraining Step: 230  | total loss: [1m[32m0.36079[0m[0m | time: 44.652s
[2K
| Adam | epoch: 021 | loss: 0.36079 - acc: 0.8526 -- iter: 320/352
[A[ATraining Step: 231  | total loss: [1m[32m0.37533[0m[0m | time: 47.082s
[2K
| Adam | epoch: 021 | loss: 0.37533 - acc: 0.8517 | val_loss: 0.65282 - val_acc: 0.7207 -- iter: 352/352
--
Training Step: 232  | total loss: [1m[32m0.37565[0m[0m | time: 7.516s
[2K
| Adam | epoch: 022 | loss: 0.37565 - acc: 0.8572 -- iter: 032/352
[A[ATraining Step: 233  | total loss: [1m[32m0.35715[0m[0m | time: 8.690s
[2K
| Adam | epoch: 022 | loss: 0.35715 - acc: 0.8683 -- iter: 064/352
[A[ATraining Step: 234  | total loss: [1m[32m0.34113[0m[0m | time: 9.843s
[2K
| Adam | epoch: 022 | loss: 0.34113 - acc: 0.8752 -- iter: 096/352
[A[ATraining Step: 235  | total loss: [1m[32m0.33036[0m[0m | time: 10.974s
[2K
| Adam | epoch: 022 | loss: 0.33036 - acc: 0.8815 -- iter: 128/352
[A[ATraining Step: 236  | total loss: [1m[32m0.32025[0m[0m | time: 12.178s
[2K
| Adam | epoch: 022 | loss: 0.32025 - acc: 0.8808 -- iter: 160/352
[A[ATraining Step: 237  | total loss: [1m[32m0.31901[0m[0m | time: 13.684s
[2K
| Adam | epoch: 022 | loss: 0.31901 - acc: 0.8802 -- iter: 192/352
[A[ATraining Step: 238  | total loss: [1m[32m0.32128[0m[0m | time: 14.794s
[2K
| Adam | epoch: 022 | loss: 0.32128 - acc: 0.8828 -- iter: 224/352
[A[ATraining Step: 239  | total loss: [1m[32m0.31230[0m[0m | time: 16.435s
[2K
| Adam | epoch: 022 | loss: 0.31230 - acc: 0.8852 -- iter: 256/352
[A[ATraining Step: 240  | total loss: [1m[32m0.33158[0m[0m | time: 17.787s
[2K
| Adam | epoch: 022 | loss: 0.33158 - acc: 0.8779 -- iter: 288/352
[A[ATraining Step: 241  | total loss: [1m[32m0.34173[0m[0m | time: 19.052s
[2K
| Adam | epoch: 022 | loss: 0.34173 - acc: 0.8745 -- iter: 320/352
[A[ATraining Step: 242  | total loss: [1m[32m0.33518[0m[0m | time: 21.071s
[2K
| Adam | epoch: 022 | loss: 0.33518 - acc: 0.8745 | val_loss: 0.81257 - val_acc: 0.6757 -- iter: 352/352
--
Training Step: 243  | total loss: [1m[32m0.31324[0m[0m | time: 1.084s
[2K
| Adam | epoch: 023 | loss: 0.31324 - acc: 0.8840 -- iter: 032/352
[A[ATraining Step: 244  | total loss: [1m[32m0.30366[0m[0m | time: 2.342s
[2K
| Adam | epoch: 023 | loss: 0.30366 - acc: 0.8893 -- iter: 064/352
[A[ATraining Step: 245  | total loss: [1m[32m0.31931[0m[0m | time: 3.631s
[2K
| Adam | epoch: 023 | loss: 0.31931 - acc: 0.8816 -- iter: 096/352
[A[ATraining Step: 246  | total loss: [1m[32m0.32153[0m[0m | time: 4.716s
[2K
| Adam | epoch: 023 | loss: 0.32153 - acc: 0.8779 -- iter: 128/352
[A[ATraining Step: 247  | total loss: [1m[32m0.32189[0m[0m | time: 6.246s
[2K
| Adam | epoch: 023 | loss: 0.32189 - acc: 0.8807 -- iter: 160/352
[A[ATraining Step: 248  | total loss: [1m[32m0.30389[0m[0m | time: 7.662s
[2K
| Adam | epoch: 023 | loss: 0.30389 - acc: 0.8926 -- iter: 192/352
[A[ATraining Step: 249  | total loss: [1m[32m0.29760[0m[0m | time: 8.966s
[2K
| Adam | epoch: 023 | loss: 0.29760 - acc: 0.8971 -- iter: 224/352
[A[ATraining Step: 250  | total loss: [1m[32m0.30713[0m[0m | time: 9.922s
[2K
| Adam | epoch: 023 | loss: 0.30713 - acc: 0.8855 -- iter: 256/352
[A[ATraining Step: 251  | total loss: [1m[32m0.30562[0m[0m | time: 11.076s
[2K
| Adam | epoch: 023 | loss: 0.30562 - acc: 0.8845 -- iter: 288/352
[A[ATraining Step: 252  | total loss: [1m[32m0.30394[0m[0m | time: 12.225s
[2K
| Adam | epoch: 023 | loss: 0.30394 - acc: 0.8866 -- iter: 320/352
[A[ATraining Step: 253  | total loss: [1m[32m0.29585[0m[0m | time: 14.463s
[2K
| Adam | epoch: 023 | loss: 0.29585 - acc: 0.8949 | val_loss: 0.69389 - val_acc: 0.6937 -- iter: 352/352
--
Training Step: 254  | total loss: [1m[32m0.30730[0m[0m | time: 1.123s
[2K
| Adam | epoch: 024 | loss: 0.30730 - acc: 0.8929 -- iter: 032/352
[A[ATraining Step: 255  | total loss: [1m[32m0.28984[0m[0m | time: 2.656s
[2K
| Adam | epoch: 024 | loss: 0.28984 - acc: 0.8973 -- iter: 064/352
[A[ATraining Step: 256  | total loss: [1m[32m0.27823[0m[0m | time: 4.114s
[2K
| Adam | epoch: 024 | loss: 0.27823 - acc: 0.9014 -- iter: 096/352
[A[ATraining Step: 257  | total loss: [1m[32m0.26773[0m[0m | time: 5.540s
[2K
| Adam | epoch: 024 | loss: 0.26773 - acc: 0.9018 -- iter: 128/352
[A[ATraining Step: 258  | total loss: [1m[32m0.26315[0m[0m | time: 16.553s
[2K
| Adam | epoch: 024 | loss: 0.26315 - acc: 0.9054 -- iter: 160/352
[A[ATraining Step: 259  | total loss: [1m[32m0.25576[0m[0m | time: 18.165s
[2K
| Adam | epoch: 024 | loss: 0.25576 - acc: 0.9086 -- iter: 192/352
[A[ATraining Step: 260  | total loss: [1m[32m0.24645[0m[0m | time: 19.293s
[2K
| Adam | epoch: 024 | loss: 0.24645 - acc: 0.9115 -- iter: 224/352
[A[ATraining Step: 261  | total loss: [1m[32m0.23457[0m[0m | time: 20.451s
[2K
| Adam | epoch: 024 | loss: 0.23457 - acc: 0.9141 -- iter: 256/352
[A[ATraining Step: 262  | total loss: [1m[32m0.22200[0m[0m | time: 21.563s
[2K
| Adam | epoch: 024 | loss: 0.22200 - acc: 0.9196 -- iter: 288/352
[A[ATraining Step: 263  | total loss: [1m[32m0.20938[0m[0m | time: 22.890s
[2K
| Adam | epoch: 024 | loss: 0.20938 - acc: 0.9245 -- iter: 320/352
[A[ATraining Step: 264  | total loss: [1m[32m0.19661[0m[0m | time: 25.290s
[2K
| Adam | epoch: 024 | loss: 0.19661 - acc: 0.9289 | val_loss: 0.80333 - val_acc: 0.7297 -- iter: 352/352
--
Training Step: 265  | total loss: [1m[32m0.18345[0m[0m | time: 1.438s
[2K
| Adam | epoch: 025 | loss: 0.18345 - acc: 0.9360 -- iter: 032/352
[A[ATraining Step: 266  | total loss: [1m[32m0.18933[0m[0m | time: 2.654s
[2K
| Adam | epoch: 025 | loss: 0.18933 - acc: 0.9330 -- iter: 064/352
[A[ATraining Step: 267  | total loss: [1m[32m0.18862[0m[0m | time: 3.560s
[2K
| Adam | epoch: 025 | loss: 0.18862 - acc: 0.9304 -- iter: 096/352
[A[ATraining Step: 268  | total loss: [1m[32m0.23516[0m[0m | time: 4.251s
[2K
| Adam | epoch: 025 | loss: 0.23516 - acc: 0.9248 -- iter: 128/352
[A[ATraining Step: 269  | total loss: [1m[32m0.21440[0m[0m | time: 4.933s
[2K
| Adam | epoch: 025 | loss: 0.21440 - acc: 0.9323 -- iter: 160/352
[A[ATraining Step: 270  | total loss: [1m[32m0.20395[0m[0m | time: 5.609s
[2K
| Adam | epoch: 025 | loss: 0.20395 - acc: 0.9360 -- iter: 192/352
[A[ATraining Step: 271  | total loss: [1m[32m0.20043[0m[0m | time: 6.274s
[2K
| Adam | epoch: 025 | loss: 0.20043 - acc: 0.9361 -- iter: 224/352
[A[ATraining Step: 272  | total loss: [1m[32m0.19229[0m[0m | time: 6.939s
[2K
| Adam | epoch: 025 | loss: 0.19229 - acc: 0.9425 -- iter: 256/352
[A[ATraining Step: 273  | total loss: [1m[32m0.18766[0m[0m | time: 7.666s
[2K
| Adam | epoch: 025 | loss: 0.18766 - acc: 0.9420 -- iter: 288/352
[A[ATraining Step: 274  | total loss: [1m[32m0.17667[0m[0m | time: 8.356s
[2K
| Adam | epoch: 025 | loss: 0.17667 - acc: 0.9447 -- iter: 320/352
[A[ATraining Step: 275  | total loss: [1m[32m0.18329[0m[0m | time: 10.016s
[2K
| Adam | epoch: 025 | loss: 0.18329 - acc: 0.9377 | val_loss: 0.83412 - val_acc: 0.6847 -- iter: 352/352
--
Training Step: 276  | total loss: [1m[32m0.18309[0m[0m | time: 0.665s
[2K
| Adam | epoch: 026 | loss: 0.18309 - acc: 0.9346 -- iter: 032/352
[A[ATraining Step: 277  | total loss: [1m[32m0.17261[0m[0m | time: 1.361s
[2K
| Adam | epoch: 026 | loss: 0.17261 - acc: 0.9380 -- iter: 064/352
[A[ATraining Step: 278  | total loss: [1m[32m0.16652[0m[0m | time: 2.016s
[2K
| Adam | epoch: 026 | loss: 0.16652 - acc: 0.9379 -- iter: 096/352
[A[ATraining Step: 279  | total loss: [1m[32m0.21594[0m[0m | time: 2.694s
[2K
| Adam | epoch: 026 | loss: 0.21594 - acc: 0.9192 -- iter: 128/352
[A[ATraining Step: 280  | total loss: [1m[32m0.23252[0m[0m | time: 3.373s
[2K
| Adam | epoch: 026 | loss: 0.23252 - acc: 0.9147 -- iter: 160/352
[A[ATraining Step: 281  | total loss: [1m[32m0.21527[0m[0m | time: 4.030s
[2K
| Adam | epoch: 026 | loss: 0.21527 - acc: 0.9201 -- iter: 192/352
[A[ATraining Step: 282  | total loss: [1m[32m0.20283[0m[0m | time: 4.705s
[2K
| Adam | epoch: 026 | loss: 0.20283 - acc: 0.9250 -- iter: 224/352
[A[ATraining Step: 283  | total loss: [1m[32m0.18663[0m[0m | time: 5.367s
[2K
| Adam | epoch: 026 | loss: 0.18663 - acc: 0.9325 -- iter: 256/352
[A[ATraining Step: 284  | total loss: [1m[32m0.18451[0m[0m | time: 6.067s
[2K
| Adam | epoch: 026 | loss: 0.18451 - acc: 0.9361 -- iter: 288/352
[A[ATraining Step: 285  | total loss: [1m[32m0.17508[0m[0m | time: 6.757s
[2K
| Adam | epoch: 026 | loss: 0.17508 - acc: 0.9394 -- iter: 320/352
[A[ATraining Step: 286  | total loss: [1m[32m0.18841[0m[0m | time: 8.443s
[2K
| Adam | epoch: 026 | loss: 0.18841 - acc: 0.9329 | val_loss: 0.69462 - val_acc: 0.7387 -- iter: 352/352
--
Training Step: 287  | total loss: [1m[32m0.17741[0m[0m | time: 1.492s
[2K
| Adam | epoch: 027 | loss: 0.17741 - acc: 0.9365 -- iter: 032/352
[A[ATraining Step: 288  | total loss: [1m[32m0.17389[0m[0m | time: 2.835s
[2K
| Adam | epoch: 027 | loss: 0.17389 - acc: 0.9398 -- iter: 064/352
[A[ATraining Step: 289  | total loss: [1m[32m0.17657[0m[0m | time: 11.779s
[2K
| Adam | epoch: 027 | loss: 0.17657 - acc: 0.9395 -- iter: 096/352
[A[ATraining Step: 290  | total loss: [1m[32m0.17609[0m[0m | time: 21.622s
[2K
| Adam | epoch: 027 | loss: 0.17609 - acc: 0.9331 -- iter: 128/352
[A[ATraining Step: 291  | total loss: [1m[32m0.16289[0m[0m | time: 40.883s
[2K
| Adam | epoch: 027 | loss: 0.16289 - acc: 0.9398 -- iter: 160/352
[A[ATraining Step: 292  | total loss: [1m[32m0.16972[0m[0m | time: 42.025s
[2K
| Adam | epoch: 027 | loss: 0.16972 - acc: 0.9395 -- iter: 192/352
[A[ATraining Step: 293  | total loss: [1m[32m0.16077[0m[0m | time: 43.253s
[2K
| Adam | epoch: 027 | loss: 0.16077 - acc: 0.9456 -- iter: 224/352
[A[ATraining Step: 294  | total loss: [1m[32m0.15181[0m[0m | time: 44.321s
[2K
| Adam | epoch: 027 | loss: 0.15181 - acc: 0.9510 -- iter: 256/352
[A[ATraining Step: 295  | total loss: [1m[32m0.14265[0m[0m | time: 45.714s
[2K
| Adam | epoch: 027 | loss: 0.14265 - acc: 0.9559 -- iter: 288/352
[A[ATraining Step: 296  | total loss: [1m[32m0.13362[0m[0m | time: 46.995s
[2K
| Adam | epoch: 027 | loss: 0.13362 - acc: 0.9572 -- iter: 320/352
[A[ATraining Step: 297  | total loss: [1m[32m0.12231[0m[0m | time: 49.069s
[2K
| Adam | epoch: 027 | loss: 0.12231 - acc: 0.9615 | val_loss: 0.76427 - val_acc: 0.7387 -- iter: 352/352
--
Training Step: 298  | total loss: [1m[32m0.11955[0m[0m | time: 1.428s
[2K
| Adam | epoch: 028 | loss: 0.11955 - acc: 0.9591 -- iter: 032/352
[A[ATraining Step: 299  | total loss: [1m[32m0.11457[0m[0m | time: 2.410s
[2K
| Adam | epoch: 028 | loss: 0.11457 - acc: 0.9569 -- iter: 064/352
[A[ATraining Step: 300  | total loss: [1m[32m0.10523[0m[0m | time: 3.474s
[2K
| Adam | epoch: 028 | loss: 0.10523 - acc: 0.9612 -- iter: 096/352
[A[ATraining Step: 301  | total loss: [1m[32m0.09664[0m[0m | time: 4.570s
[2K
| Adam | epoch: 028 | loss: 0.09664 - acc: 0.9651 -- iter: 128/352
[A[ATraining Step: 302  | total loss: [1m[32m0.08880[0m[0m | time: 5.805s
[2K
| Adam | epoch: 028 | loss: 0.08880 - acc: 0.9686 -- iter: 160/352
[A[ATraining Step: 303  | total loss: [1m[32m0.09995[0m[0m | time: 7.166s
[2K
| Adam | epoch: 028 | loss: 0.09995 - acc: 0.9655 -- iter: 192/352
[A[ATraining Step: 304  | total loss: [1m[32m0.12350[0m[0m | time: 8.305s
[2K
| Adam | epoch: 028 | loss: 0.12350 - acc: 0.9596 -- iter: 224/352
[A[ATraining Step: 305  | total loss: [1m[32m0.11201[0m[0m | time: 9.801s
[2K
| Adam | epoch: 028 | loss: 0.11201 - acc: 0.9636 -- iter: 256/352
[A[ATraining Step: 306  | total loss: [1m[32m0.10540[0m[0m | time: 11.202s
[2K
| Adam | epoch: 028 | loss: 0.10540 - acc: 0.9672 -- iter: 288/352
[A[ATraining Step: 307  | total loss: [1m[32m0.09734[0m[0m | time: 12.422s
[2K
| Adam | epoch: 028 | loss: 0.09734 - acc: 0.9705 -- iter: 320/352
[A[ATraining Step: 308  | total loss: [1m[32m0.09433[0m[0m | time: 14.420s
[2K
| Adam | epoch: 028 | loss: 0.09433 - acc: 0.9735 | val_loss: 0.84080 - val_acc: 0.7387 -- iter: 352/352
--
Training Step: 309  | total loss: [1m[32m0.08992[0m[0m | time: 1.239s
[2K
| Adam | epoch: 029 | loss: 0.08992 - acc: 0.9730 -- iter: 032/352
[A[ATraining Step: 310  | total loss: [1m[32m0.08376[0m[0m | time: 2.331s
[2K
| Adam | epoch: 029 | loss: 0.08376 - acc: 0.9757 -- iter: 064/352
[A[ATraining Step: 311  | total loss: [1m[32m0.07697[0m[0m | time: 3.813s
[2K
| Adam | epoch: 029 | loss: 0.07697 - acc: 0.9781 -- iter: 096/352
[A[ATraining Step: 312  | total loss: [1m[32m0.07626[0m[0m | time: 5.258s
[2K
| Adam | epoch: 029 | loss: 0.07626 - acc: 0.9772 -- iter: 128/352
[A[ATraining Step: 313  | total loss: [1m[32m0.07469[0m[0m | time: 6.720s
[2K
| Adam | epoch: 029 | loss: 0.07469 - acc: 0.9763 -- iter: 160/352
[A[ATraining Step: 314  | total loss: [1m[32m0.07467[0m[0m | time: 29.282s
[2K
| Adam | epoch: 029 | loss: 0.07467 - acc: 0.9756 -- iter: 192/352
[A[ATraining Step: 315  | total loss: [1m[32m0.06923[0m[0m | time: 57.858s
[2K
| Adam | epoch: 029 | loss: 0.06923 - acc: 0.9780 -- iter: 224/352
[A[ATraining Step: 316  | total loss: [1m[32m0.08359[0m[0m | time: 58.981s
[2K
| Adam | epoch: 029 | loss: 0.08359 - acc: 0.9771 -- iter: 256/352
[A[ATraining Step: 317  | total loss: [1m[32m0.07785[0m[0m | time: 60.223s
[2K
| Adam | epoch: 029 | loss: 0.07785 - acc: 0.9794 -- iter: 288/352
[A[ATraining Step: 318  | total loss: [1m[32m0.07276[0m[0m | time: 61.379s
[2K
| Adam | epoch: 029 | loss: 0.07276 - acc: 0.9815 -- iter: 320/352
[A[ATraining Step: 319  | total loss: [1m[32m0.06710[0m[0m | time: 63.675s
[2K
| Adam | epoch: 029 | loss: 0.06710 - acc: 0.9833 | val_loss: 0.95397 - val_acc: 0.7387 -- iter: 352/352
--
Training Step: 320  | total loss: [1m[32m0.06723[0m[0m | time: 1.534s
[2K
| Adam | epoch: 030 | loss: 0.06723 - acc: 0.9819 -- iter: 032/352
[A[ATraining Step: 321  | total loss: [1m[32m0.06188[0m[0m | time: 2.920s
[2K
| Adam | epoch: 030 | loss: 0.06188 - acc: 0.9837 -- iter: 064/352
[A[ATraining Step: 322  | total loss: [1m[32m0.05738[0m[0m | time: 4.137s
[2K
| Adam | epoch: 030 | loss: 0.05738 - acc: 0.9853 -- iter: 096/352
[A[ATraining Step: 323  | total loss: [1m[32m0.05776[0m[0m | time: 24.654s
[2K
| Adam | epoch: 030 | loss: 0.05776 - acc: 0.9836 -- iter: 128/352
[A[ATraining Step: 324  | total loss: [1m[32m0.05489[0m[0m | time: 25.802s
[2K
| Adam | epoch: 030 | loss: 0.05489 - acc: 0.9853 -- iter: 160/352
[A[ATraining Step: 325  | total loss: [1m[32m0.05146[0m[0m | time: 26.945s
[2K
| Adam | epoch: 030 | loss: 0.05146 - acc: 0.9868 -- iter: 192/352
[A[ATraining Step: 326  | total loss: [1m[32m0.04726[0m[0m | time: 28.041s
[2K
| Adam | epoch: 030 | loss: 0.04726 - acc: 0.9881 -- iter: 224/352
[A[ATraining Step: 327  | total loss: [1m[32m0.04405[0m[0m | time: 29.230s
[2K
| Adam | epoch: 030 | loss: 0.04405 - acc: 0.9893 -- iter: 256/352
[A[ATraining Step: 328  | total loss: [1m[32m0.04012[0m[0m | time: 30.574s
[2K
| Adam | epoch: 030 | loss: 0.04012 - acc: 0.9903 -- iter: 288/352
[A[ATraining Step: 329  | total loss: [1m[32m0.03697[0m[0m | time: 31.644s
[2K
| Adam | epoch: 030 | loss: 0.03697 - acc: 0.9913 -- iter: 320/352
[A[ATraining Step: 330  | total loss: [1m[32m0.03367[0m[0m | time: 34.259s
[2K
| Adam | epoch: 030 | loss: 0.03367 - acc: 0.9922 | val_loss: 1.14133 - val_acc: 0.7207 -- iter: 352/352
--
Validation AUC:0.7946718648473033
Validation AUPRC:0.7946572353756503
Test AUC:0.8271276595744681
Test AUPRC:0.8643074908260925
BestTestF1Score	0.81	0.47	0.74	0.71	0.94	60	25	22	4	0.02
BestTestMCCScore	0.78	0.54	0.77	0.85	0.72	46	8	39	18	0.93
BestTestAccuracyScore	0.78	0.54	0.77	0.85	0.72	46	8	39	18	0.93
BestValidationF1Score	0.76	0.45	0.71	0.66	0.91	52	27	27	5	0.02
BestValidationMCC	0.74	0.48	0.74	0.76	0.72	41	13	41	16	0.93
BestValidationAccuracy	0.74	0.48	0.74	0.76	0.72	41	13	41	16	0.93
TestPredictions (Threshold:0.93)
CHEMBL1510582,TP,ACT,1.0	CHEMBL372758,TP,ACT,0.9900000095367432	CHEMBL351757,TP,ACT,1.0	CHEMBL1476319,TP,ACT,1.0	CHEMBL1327627,FN,ACT,0.8100000023841858	CHEMBL3600688,TN,INACT,0.0	CHEMBL573643,TP,ACT,1.0	CHEMBL1829874,TN,INACT,0.0	CHEMBL475488,TP,ACT,1.0	CHEMBL454365,TP,ACT,1.0	CHEMBL502403,TP,ACT,1.0	CHEMBL3133492,TN,INACT,0.029999999329447746	CHEMBL408322,TN,INACT,0.0	CHEMBL2172016,TN,INACT,0.0	CHEMBL371705,FN,ACT,0.6600000262260437	CHEMBL306834,TN,INACT,0.009999999776482582	CHEMBL388529,TN,INACT,0.009999999776482582	CHEMBL2431942,FN,ACT,0.009999999776482582	CHEMBL1829868,TN,INACT,0.3499999940395355	CHEMBL609349,TN,INACT,0.07000000029802322	CHEMBL1300956,TP,ACT,1.0	CHEMBL2431970,TP,ACT,0.9700000286102295	CHEMBL575497,TP,ACT,1.0	CHEMBL3600853,TP,ACT,0.949999988079071	CHEMBL193433,FN,ACT,0.14000000059604645	CHEMBL196884,TP,ACT,0.9800000190734863	CHEMBL3133481,TN,INACT,0.1599999964237213	CHEMBL414034,TP,ACT,1.0	CHEMBL2347241,FP,INACT,1.0	CHEMBL2335514,TN,INACT,0.009999999776482582	CHEMBL2431972,TN,INACT,0.07000000029802322	CHEMBL1439622,FP,INACT,1.0	CHEMBL393817,TN,INACT,0.8500000238418579	CHEMBL1483201,TP,ACT,1.0	CHEMBL2172015,TN,INACT,0.019999999552965164	CHEMBL72311,TN,INACT,0.8899999856948853	CHEMBL197916,TN,INACT,0.5199999809265137	CHEMBL3827273,FN,ACT,0.8899999856948853	CHEMBL3696066,TN,INACT,0.15000000596046448	CHEMBL371056,FP,INACT,1.0	CHEMBL365749,TP,ACT,0.9300000071525574	CHEMBL573980,TP,ACT,1.0	CHEMBL3628241,TP,ACT,1.0	CHEMBL1687976,TN,INACT,0.0	CHEMBL1344250,TP,ACT,1.0	CHEMBL574636,TP,ACT,1.0	CHEMBL348181,FN,ACT,0.0	CHEMBL1432712,TP,ACT,0.9900000095367432	CHEMBL2335525,TN,INACT,0.009999999776482582	CHEMBL2429889,TN,INACT,0.8700000047683716	CHEMBL583725,TP,ACT,1.0	CHEMBL1442663,TP,ACT,1.0	CHEMBL1503513,TP,ACT,1.0	CHEMBL3696065,TN,INACT,0.1899999976158142	CHEMBL373124,TP,ACT,1.0	CHEMBL370208,FN,ACT,0.14000000059604645	CHEMBL573069,TP,ACT,1.0	CHEMBL1419744,TP,ACT,1.0	CHEMBL1459062,TP,ACT,1.0	CHEMBL392556,TN,INACT,0.0	CHEMBL23997,TN,INACT,0.0	CHEMBL3600744,FN,ACT,0.9200000166893005	CHEMBL2203687,FP,INACT,1.0	CHEMBL3828160,TN,INACT,0.5600000023841858	CHEMBL1607661,TP,ACT,1.0	CHEMBL234465,TN,INACT,0.699999988079071	CHEMBL1344478,TP,ACT,0.9900000095367432	CHEMBL2335521,TN,INACT,0.0	CHEMBL2031572,FP,INACT,1.0	CHEMBL3628032,TP,ACT,1.0	CHEMBL2431965,FN,ACT,0.0	CHEMBL8805,TN,INACT,0.05000000074505806	CHEMBL2431980,TP,ACT,0.9700000286102295	CHEMBL160849,TP,ACT,1.0	CHEMBL231705,TP,ACT,0.9900000095367432	CHEMBL1681826,TN,INACT,0.0	CHEMBL1501859,FN,ACT,0.15000000596046448	CHEMBL1687978,TN,INACT,0.0	CHEMBL436427,FN,ACT,0.30000001192092896	CHEMBL254219,TP,ACT,1.0	CHEMBL1380192,TP,ACT,0.9700000286102295	CHEMBL1339432,TP,ACT,0.949999988079071	CHEMBL3133483,TN,INACT,0.0	CHEMBL3827123,TP,ACT,1.0	CHEMBL2431956,FN,ACT,0.10000000149011612	CHEMBL3108909,FN,ACT,0.5899999737739563	CHEMBL503365,TP,ACT,1.0	CHEMBL372993,TP,ACT,1.0	CHEMBL194446,TP,ACT,1.0	CHEMBL1541720,FN,ACT,0.0	CHEMBL385115,TN,INACT,0.8899999856948853	CHEMBL42048,TN,INACT,0.009999999776482582	CHEMBL1488466,FN,ACT,0.8399999737739563	CHEMBL1370479,TP,ACT,1.0	CHEMBL510008,TP,ACT,1.0	CHEMBL2431969,FN,ACT,0.05999999865889549	CHEMBL3828152,FN,ACT,0.5899999737739563	CHEMBL348612,FP,INACT,0.9599999785423279	CHEMBL45615,FP,INACT,0.9900000095367432	CHEMBL2326995,TN,INACT,0.0	CHEMBL1560530,TP,ACT,1.0	CHEMBL72293,TN,INACT,0.009999999776482582	CHEMBL412549,TN,INACT,0.0	CHEMBL3287878,FP,INACT,0.9800000190734863	CHEMBL1651678,TN,INACT,0.7200000286102295	CHEMBL3133484,TN,INACT,0.0	CHEMBL1472244,TP,ACT,1.0	CHEMBL2335549,TN,INACT,0.009999999776482582	CHEMBL1425718,TP,ACT,1.0	CHEMBL2172008,TN,INACT,0.7699999809265137	CHEMBL1542483,FN,ACT,0.09000000357627869	

