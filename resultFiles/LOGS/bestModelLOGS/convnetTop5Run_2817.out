CNNModel CHEMBL3587 adam 0.001 15 128 0 0.8 False True
Number of active compounds :	613
Number of inactive compounds :	613
---------------------------------
Run id: CNNModel_CHEMBL3587_adam_0.001_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3587_adam_0.001_15_128_0.8_True/
---------------------------------
Training samples: 784
Validation samples: 245
--
Training Step: 1  | time: 0.855s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/784
[A[ATraining Step: 2  | total loss: [1m[32m0.62405[0m[0m | time: 1.480s
[2K
| Adam | epoch: 001 | loss: 0.62405 - acc: 0.3937 -- iter: 064/784
[A[ATraining Step: 3  | total loss: [1m[32m0.68080[0m[0m | time: 2.106s
[2K
| Adam | epoch: 001 | loss: 0.68080 - acc: 0.4807 -- iter: 096/784
[A[ATraining Step: 4  | total loss: [1m[32m0.69252[0m[0m | time: 2.726s
[2K
| Adam | epoch: 001 | loss: 0.69252 - acc: 0.4483 -- iter: 128/784
[A[ATraining Step: 5  | total loss: [1m[32m0.69266[0m[0m | time: 3.345s
[2K
| Adam | epoch: 001 | loss: 0.69266 - acc: 0.5274 -- iter: 160/784
[A[ATraining Step: 6  | total loss: [1m[32m0.69435[0m[0m | time: 3.990s
[2K
| Adam | epoch: 001 | loss: 0.69435 - acc: 0.4495 -- iter: 192/784
[A[ATraining Step: 7  | total loss: [1m[32m0.69330[0m[0m | time: 4.605s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.4986 -- iter: 224/784
[A[ATraining Step: 8  | total loss: [1m[32m0.69361[0m[0m | time: 5.213s
[2K
| Adam | epoch: 001 | loss: 0.69361 - acc: 0.4818 -- iter: 256/784
[A[ATraining Step: 9  | total loss: [1m[32m0.69319[0m[0m | time: 5.834s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5245 -- iter: 288/784
[A[ATraining Step: 10  | total loss: [1m[32m0.69362[0m[0m | time: 6.441s
[2K
| Adam | epoch: 001 | loss: 0.69362 - acc: 0.4654 -- iter: 320/784
[A[ATraining Step: 11  | total loss: [1m[32m0.69296[0m[0m | time: 7.050s
[2K
| Adam | epoch: 001 | loss: 0.69296 - acc: 0.5410 -- iter: 352/784
[A[ATraining Step: 12  | total loss: [1m[32m0.69275[0m[0m | time: 7.652s
[2K
| Adam | epoch: 001 | loss: 0.69275 - acc: 0.5507 -- iter: 384/784
[A[ATraining Step: 13  | total loss: [1m[32m0.69366[0m[0m | time: 8.259s
[2K
| Adam | epoch: 001 | loss: 0.69366 - acc: 0.4754 -- iter: 416/784
[A[ATraining Step: 14  | total loss: [1m[32m0.69382[0m[0m | time: 8.862s
[2K
| Adam | epoch: 001 | loss: 0.69382 - acc: 0.4599 -- iter: 448/784
[A[ATraining Step: 15  | total loss: [1m[32m0.69348[0m[0m | time: 9.504s
[2K
| Adam | epoch: 001 | loss: 0.69348 - acc: 0.4878 -- iter: 480/784
[A[ATraining Step: 16  | total loss: [1m[32m0.69343[0m[0m | time: 10.107s
[2K
| Adam | epoch: 001 | loss: 0.69343 - acc: 0.4807 -- iter: 512/784
[A[ATraining Step: 17  | total loss: [1m[32m0.69323[0m[0m | time: 10.740s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.4989 -- iter: 544/784
[A[ATraining Step: 18  | total loss: [1m[32m0.69317[0m[0m | time: 11.346s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.5101 -- iter: 576/784
[A[ATraining Step: 19  | total loss: [1m[32m0.69339[0m[0m | time: 11.967s
[2K
| Adam | epoch: 001 | loss: 0.69339 - acc: 0.4651 -- iter: 608/784
[A[ATraining Step: 20  | total loss: [1m[32m0.69334[0m[0m | time: 12.571s
[2K
| Adam | epoch: 001 | loss: 0.69334 - acc: 0.4462 -- iter: 640/784
[A[ATraining Step: 21  | total loss: [1m[32m0.69343[0m[0m | time: 13.174s
[2K
| Adam | epoch: 001 | loss: 0.69343 - acc: 0.4241 -- iter: 672/784
[A[ATraining Step: 22  | total loss: [1m[32m0.69337[0m[0m | time: 13.775s
[2K
| Adam | epoch: 001 | loss: 0.69337 - acc: 0.4375 -- iter: 704/784
[A[ATraining Step: 23  | total loss: [1m[32m0.69330[0m[0m | time: 14.403s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.4375 -- iter: 736/784
[A[ATraining Step: 24  | total loss: [1m[32m0.69332[0m[0m | time: 15.034s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.4375 -- iter: 768/784
[A[ATraining Step: 25  | total loss: [1m[32m0.69344[0m[0m | time: 16.384s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.4375 | val_loss: 0.69328 - val_acc: 0.4898 -- iter: 784/784
--
Training Step: 26  | total loss: [1m[32m0.69318[0m[0m | time: 0.337s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.4706 -- iter: 032/784
[A[ATraining Step: 27  | total loss: [1m[32m0.69301[0m[0m | time: 0.956s
[2K
| Adam | epoch: 002 | loss: 0.69301 - acc: 0.4942 -- iter: 064/784
[A[ATraining Step: 28  | total loss: [1m[32m0.69338[0m[0m | time: 1.603s
[2K
| Adam | epoch: 002 | loss: 0.69338 - acc: 0.4722 -- iter: 096/784
[A[ATraining Step: 29  | total loss: [1m[32m0.69377[0m[0m | time: 2.216s
[2K
| Adam | epoch: 002 | loss: 0.69377 - acc: 0.4486 -- iter: 128/784
[A[ATraining Step: 30  | total loss: [1m[32m0.69392[0m[0m | time: 2.830s
[2K
| Adam | epoch: 002 | loss: 0.69392 - acc: 0.4386 -- iter: 160/784
[A[ATraining Step: 31  | total loss: [1m[32m0.69365[0m[0m | time: 3.453s
[2K
| Adam | epoch: 002 | loss: 0.69365 - acc: 0.4599 -- iter: 192/784
[A[ATraining Step: 32  | total loss: [1m[32m0.69345[0m[0m | time: 4.067s
[2K
| Adam | epoch: 002 | loss: 0.69345 - acc: 0.4760 -- iter: 224/784
[A[ATraining Step: 33  | total loss: [1m[32m0.69334[0m[0m | time: 4.677s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4881 -- iter: 256/784
[A[ATraining Step: 34  | total loss: [1m[32m0.69344[0m[0m | time: 5.285s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.4773 -- iter: 288/784
[A[ATraining Step: 35  | total loss: [1m[32m0.69318[0m[0m | time: 5.888s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5082 -- iter: 320/784
[A[ATraining Step: 36  | total loss: [1m[32m0.69311[0m[0m | time: 6.499s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5129 -- iter: 352/784
[A[ATraining Step: 37  | total loss: [1m[32m0.69305[0m[0m | time: 7.108s
[2K
| Adam | epoch: 002 | loss: 0.69305 - acc: 0.5166 -- iter: 384/784
[A[ATraining Step: 38  | total loss: [1m[32m0.69303[0m[0m | time: 7.744s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5133 -- iter: 416/784
[A[ATraining Step: 39  | total loss: [1m[32m0.69322[0m[0m | time: 8.360s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.5048 -- iter: 448/784
[A[ATraining Step: 40  | total loss: [1m[32m0.69305[0m[0m | time: 8.958s
[2K
| Adam | epoch: 002 | loss: 0.69305 - acc: 0.5156 -- iter: 480/784
[A[ATraining Step: 41  | total loss: [1m[32m0.69237[0m[0m | time: 9.570s
[2K
| Adam | epoch: 002 | loss: 0.69237 - acc: 0.5472 -- iter: 512/784
[A[ATraining Step: 42  | total loss: [1m[32m0.69251[0m[0m | time: 10.213s
[2K
| Adam | epoch: 002 | loss: 0.69251 - acc: 0.5387 -- iter: 544/784
[A[ATraining Step: 43  | total loss: [1m[32m0.69339[0m[0m | time: 10.841s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.5153 -- iter: 576/784
[A[ATraining Step: 44  | total loss: [1m[32m0.69308[0m[0m | time: 11.459s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5181 -- iter: 608/784
[A[ATraining Step: 45  | total loss: [1m[32m0.69461[0m[0m | time: 12.060s
[2K
| Adam | epoch: 002 | loss: 0.69461 - acc: 0.4885 -- iter: 640/784
[A[ATraining Step: 46  | total loss: [1m[32m0.69367[0m[0m | time: 12.686s
[2K
| Adam | epoch: 002 | loss: 0.69367 - acc: 0.5112 -- iter: 672/784
[A[ATraining Step: 47  | total loss: [1m[32m0.69374[0m[0m | time: 13.332s
[2K
| Adam | epoch: 002 | loss: 0.69374 - acc: 0.5043 -- iter: 704/784
[A[ATraining Step: 48  | total loss: [1m[32m0.69364[0m[0m | time: 13.933s
[2K
| Adam | epoch: 002 | loss: 0.69364 - acc: 0.5036 -- iter: 736/784
[A[ATraining Step: 49  | total loss: [1m[32m0.69363[0m[0m | time: 14.538s
[2K
| Adam | epoch: 002 | loss: 0.69363 - acc: 0.5030 -- iter: 768/784
[A[ATraining Step: 50  | total loss: [1m[32m0.69346[0m[0m | time: 16.146s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.5074 | val_loss: 0.69348 - val_acc: 0.4898 -- iter: 784/784
--
Training Step: 51  | total loss: [1m[32m0.69328[0m[0m | time: 0.324s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.5110 -- iter: 032/784
[A[ATraining Step: 52  | total loss: [1m[32m0.69301[0m[0m | time: 0.649s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5188 -- iter: 064/784
[A[ATraining Step: 53  | total loss: [1m[32m0.69279[0m[0m | time: 1.283s
[2K
| Adam | epoch: 003 | loss: 0.69279 - acc: 0.5252 -- iter: 096/784
[A[ATraining Step: 54  | total loss: [1m[32m0.69295[0m[0m | time: 1.902s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.5170 -- iter: 128/784
[A[ATraining Step: 55  | total loss: [1m[32m0.69315[0m[0m | time: 2.520s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5101 -- iter: 160/784
[A[ATraining Step: 56  | total loss: [1m[32m0.69342[0m[0m | time: 3.134s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.4999 -- iter: 192/784
[A[ATraining Step: 57  | total loss: [1m[32m0.69342[0m[0m | time: 3.735s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.4999 -- iter: 224/784
[A[ATraining Step: 58  | total loss: [1m[32m0.69313[0m[0m | time: 4.371s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5085 -- iter: 256/784
[A[ATraining Step: 59  | total loss: [1m[32m0.69270[0m[0m | time: 4.997s
[2K
| Adam | epoch: 003 | loss: 0.69270 - acc: 0.5241 -- iter: 288/784
[A[ATraining Step: 60  | total loss: [1m[32m0.69298[0m[0m | time: 5.609s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5126 -- iter: 320/784
[A[ATraining Step: 61  | total loss: [1m[32m0.69335[0m[0m | time: 6.218s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4988 -- iter: 352/784
[A[ATraining Step: 62  | total loss: [1m[32m0.69298[0m[0m | time: 6.847s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5110 -- iter: 384/784
[A[ATraining Step: 63  | total loss: [1m[32m0.69277[0m[0m | time: 7.450s
[2K
| Adam | epoch: 003 | loss: 0.69277 - acc: 0.5175 -- iter: 416/784
[A[ATraining Step: 64  | total loss: [1m[32m0.69282[0m[0m | time: 8.050s
[2K
| Adam | epoch: 003 | loss: 0.69282 - acc: 0.5153 -- iter: 448/784
[A[ATraining Step: 65  | total loss: [1m[32m0.69296[0m[0m | time: 8.651s
[2K
| Adam | epoch: 003 | loss: 0.69296 - acc: 0.5096 -- iter: 480/784
[A[ATraining Step: 66  | total loss: [1m[32m0.69331[0m[0m | time: 9.264s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.4970 -- iter: 512/784
[A[ATraining Step: 67  | total loss: [1m[32m0.69265[0m[0m | time: 9.883s
[2K
| Adam | epoch: 003 | loss: 0.69265 - acc: 0.5199 -- iter: 544/784
[A[ATraining Step: 68  | total loss: [1m[32m0.69297[0m[0m | time: 10.501s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5101 -- iter: 576/784
[A[ATraining Step: 69  | total loss: [1m[32m0.69311[0m[0m | time: 11.111s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5053 -- iter: 608/784
[A[ATraining Step: 70  | total loss: [1m[32m0.69335[0m[0m | time: 11.723s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4975 -- iter: 640/784
[A[ATraining Step: 71  | total loss: [1m[32m0.69324[0m[0m | time: 12.334s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.5013 -- iter: 672/784
[A[ATraining Step: 72  | total loss: [1m[32m0.69343[0m[0m | time: 12.965s
[2K
| Adam | epoch: 003 | loss: 0.69343 - acc: 0.4941 -- iter: 704/784
[A[ATraining Step: 73  | total loss: [1m[32m0.69351[0m[0m | time: 13.582s
[2K
| Adam | epoch: 003 | loss: 0.69351 - acc: 0.4913 -- iter: 736/784
[A[ATraining Step: 74  | total loss: [1m[32m0.69265[0m[0m | time: 14.176s
[2K
| Adam | epoch: 003 | loss: 0.69265 - acc: 0.5231 -- iter: 768/784
[A[ATraining Step: 75  | total loss: [1m[32m0.69275[0m[0m | time: 15.766s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5206 | val_loss: 0.69356 - val_acc: 0.4898 -- iter: 784/784
--
Training Step: 76  | total loss: [1m[32m0.69289[0m[0m | time: 0.638s
[2K
| Adam | epoch: 004 | loss: 0.69289 - acc: 0.5151 -- iter: 032/784
[A[ATraining Step: 77  | total loss: [1m[32m0.69325[0m[0m | time: 0.955s
[2K
| Adam | epoch: 004 | loss: 0.69325 - acc: 0.5035 -- iter: 064/784
[A[ATraining Step: 78  | total loss: [1m[32m0.69323[0m[0m | time: 1.295s
[2K
| Adam | epoch: 004 | loss: 0.69323 - acc: 0.5032 -- iter: 096/784
[A[ATraining Step: 79  | total loss: [1m[32m0.69327[0m[0m | time: 1.902s
[2K
| Adam | epoch: 004 | loss: 0.69327 - acc: 0.5028 -- iter: 128/784
[A[ATraining Step: 80  | total loss: [1m[32m0.69330[0m[0m | time: 2.502s
[2K
| Adam | epoch: 004 | loss: 0.69330 - acc: 0.5026 -- iter: 160/784
[A[ATraining Step: 81  | total loss: [1m[32m0.69338[0m[0m | time: 3.114s
[2K
| Adam | epoch: 004 | loss: 0.69338 - acc: 0.4991 -- iter: 192/784
[A[ATraining Step: 82  | total loss: [1m[32m0.69319[0m[0m | time: 3.752s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.5055 -- iter: 224/784
[A[ATraining Step: 83  | total loss: [1m[32m0.69351[0m[0m | time: 4.366s
[2K
| Adam | epoch: 004 | loss: 0.69351 - acc: 0.4924 -- iter: 256/784
[A[ATraining Step: 84  | total loss: [1m[32m0.69359[0m[0m | time: 4.970s
[2K
| Adam | epoch: 004 | loss: 0.69359 - acc: 0.4901 -- iter: 288/784
[A[ATraining Step: 85  | total loss: [1m[32m0.69341[0m[0m | time: 5.564s
[2K
| Adam | epoch: 004 | loss: 0.69341 - acc: 0.4973 -- iter: 320/784
[A[ATraining Step: 86  | total loss: [1m[32m0.69330[0m[0m | time: 6.163s
[2K
| Adam | epoch: 004 | loss: 0.69330 - acc: 0.5007 -- iter: 352/784
[A[ATraining Step: 87  | total loss: [1m[32m0.69315[0m[0m | time: 6.768s
[2K
| Adam | epoch: 004 | loss: 0.69315 - acc: 0.5069 -- iter: 384/784
[A[ATraining Step: 88  | total loss: [1m[32m0.69322[0m[0m | time: 7.383s
[2K
| Adam | epoch: 004 | loss: 0.69322 - acc: 0.5031 -- iter: 416/784
[A[ATraining Step: 89  | total loss: [1m[32m0.69317[0m[0m | time: 7.980s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5059 -- iter: 448/784
[A[ATraining Step: 90  | total loss: [1m[32m0.69317[0m[0m | time: 8.575s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5053 -- iter: 480/784
[A[ATraining Step: 91  | total loss: [1m[32m0.69285[0m[0m | time: 9.202s
[2K
| Adam | epoch: 004 | loss: 0.69285 - acc: 0.5204 -- iter: 512/784
[A[ATraining Step: 92  | total loss: [1m[32m0.69290[0m[0m | time: 9.813s
[2K
| Adam | epoch: 004 | loss: 0.69290 - acc: 0.5184 -- iter: 544/784
[A[ATraining Step: 93  | total loss: [1m[32m0.69255[0m[0m | time: 10.437s
[2K
| Adam | epoch: 004 | loss: 0.69255 - acc: 0.5321 -- iter: 576/784
[A[ATraining Step: 94  | total loss: [1m[32m0.69296[0m[0m | time: 11.077s
[2K
| Adam | epoch: 004 | loss: 0.69296 - acc: 0.5164 -- iter: 608/784
[A[ATraining Step: 95  | total loss: [1m[32m0.69299[0m[0m | time: 11.689s
[2K
| Adam | epoch: 004 | loss: 0.69299 - acc: 0.5148 -- iter: 640/784
[A[ATraining Step: 96  | total loss: [1m[32m0.69363[0m[0m | time: 12.301s
[2K
| Adam | epoch: 004 | loss: 0.69363 - acc: 0.4946 -- iter: 672/784
[A[ATraining Step: 97  | total loss: [1m[32m0.69332[0m[0m | time: 12.903s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.5045 -- iter: 704/784
[A[ATraining Step: 98  | total loss: [1m[32m0.69328[0m[0m | time: 13.510s
[2K
| Adam | epoch: 004 | loss: 0.69328 - acc: 0.5040 -- iter: 736/784
[A[ATraining Step: 99  | total loss: [1m[32m0.69346[0m[0m | time: 14.120s
[2K
| Adam | epoch: 004 | loss: 0.69346 - acc: 0.4974 -- iter: 768/784
[A[ATraining Step: 100  | total loss: [1m[32m0.69345[0m[0m | time: 15.729s
[2K
| Adam | epoch: 004 | loss: 0.69345 - acc: 0.4976 | val_loss: 0.69340 - val_acc: 0.4898 -- iter: 784/784
--
Training Step: 101  | total loss: [1m[32m0.69374[0m[0m | time: 0.621s
[2K
| Adam | epoch: 005 | loss: 0.69374 - acc: 0.4854 -- iter: 032/784
[A[ATraining Step: 102  | total loss: [1m[32m0.69365[0m[0m | time: 1.237s
[2K
| Adam | epoch: 005 | loss: 0.69365 - acc: 0.4868 -- iter: 064/784
[A[ATraining Step: 103  | total loss: [1m[32m0.69370[0m[0m | time: 1.558s
[2K
| Adam | epoch: 005 | loss: 0.69370 - acc: 0.4850 -- iter: 096/784
[A[ATraining Step: 104  | total loss: [1m[32m0.69390[0m[0m | time: 1.875s
[2K
| Adam | epoch: 005 | loss: 0.69390 - acc: 0.4740 -- iter: 128/784
[A[ATraining Step: 105  | total loss: [1m[32m0.69399[0m[0m | time: 2.491s
[2K
| Adam | epoch: 005 | loss: 0.69399 - acc: 0.4641 -- iter: 160/784
[A[ATraining Step: 106  | total loss: [1m[32m0.69406[0m[0m | time: 3.104s
[2K
| Adam | epoch: 005 | loss: 0.69406 - acc: 0.4552 -- iter: 192/784
[A[ATraining Step: 107  | total loss: [1m[32m0.69406[0m[0m | time: 3.726s
[2K
| Adam | epoch: 005 | loss: 0.69406 - acc: 0.4472 -- iter: 224/784
[A[ATraining Step: 108  | total loss: [1m[32m0.69398[0m[0m | time: 4.356s
[2K
| Adam | epoch: 005 | loss: 0.69398 - acc: 0.4493 -- iter: 256/784
[A[ATraining Step: 109  | total loss: [1m[32m0.69384[0m[0m | time: 4.970s
[2K
| Adam | epoch: 005 | loss: 0.69384 - acc: 0.4638 -- iter: 288/784
[A[ATraining Step: 110  | total loss: [1m[32m0.69383[0m[0m | time: 5.575s
[2K
| Adam | epoch: 005 | loss: 0.69383 - acc: 0.4612 -- iter: 320/784
[A[ATraining Step: 111  | total loss: [1m[32m0.69363[0m[0m | time: 6.187s
[2K
| Adam | epoch: 005 | loss: 0.69363 - acc: 0.4744 -- iter: 352/784
[A[ATraining Step: 112  | total loss: [1m[32m0.69371[0m[0m | time: 6.811s
[2K
| Adam | epoch: 005 | loss: 0.69371 - acc: 0.4707 -- iter: 384/784
[A[ATraining Step: 113  | total loss: [1m[32m0.69364[0m[0m | time: 7.408s
[2K
| Adam | epoch: 005 | loss: 0.69364 - acc: 0.4737 -- iter: 416/784
[A[ATraining Step: 114  | total loss: [1m[32m0.69378[0m[0m | time: 8.073s
[2K
| Adam | epoch: 005 | loss: 0.69378 - acc: 0.4700 -- iter: 448/784
[A[ATraining Step: 115  | total loss: [1m[32m0.69402[0m[0m | time: 8.687s
[2K
| Adam | epoch: 005 | loss: 0.69402 - acc: 0.4605 -- iter: 480/784
[A[ATraining Step: 116  | total loss: [1m[32m0.69407[0m[0m | time: 9.292s
[2K
| Adam | epoch: 005 | loss: 0.69407 - acc: 0.4582 -- iter: 512/784
[A[ATraining Step: 117  | total loss: [1m[32m0.69381[0m[0m | time: 9.931s
[2K
| Adam | epoch: 005 | loss: 0.69381 - acc: 0.4718 -- iter: 544/784
[A[ATraining Step: 118  | total loss: [1m[32m0.69362[0m[0m | time: 10.554s
[2K
| Adam | epoch: 005 | loss: 0.69362 - acc: 0.4809 -- iter: 576/784
[A[ATraining Step: 119  | total loss: [1m[32m0.69385[0m[0m | time: 11.164s
[2K
| Adam | epoch: 005 | loss: 0.69385 - acc: 0.4671 -- iter: 608/784
[A[ATraining Step: 120  | total loss: [1m[32m0.69420[0m[0m | time: 11.767s
[2K
| Adam | epoch: 005 | loss: 0.69420 - acc: 0.4392 -- iter: 640/784
[A[ATraining Step: 121  | total loss: [1m[32m0.69411[0m[0m | time: 12.384s
[2K
| Adam | epoch: 005 | loss: 0.69411 - acc: 0.4390 -- iter: 672/784
[A[ATraining Step: 122  | total loss: [1m[32m0.69397[0m[0m | time: 13.002s
[2K
| Adam | epoch: 005 | loss: 0.69397 - acc: 0.4451 -- iter: 704/784
[A[ATraining Step: 123  | total loss: [1m[32m0.69369[0m[0m | time: 13.611s
[2K
| Adam | epoch: 005 | loss: 0.69369 - acc: 0.4537 -- iter: 736/784
[A[ATraining Step: 124  | total loss: [1m[32m0.69274[0m[0m | time: 14.222s
[2K
| Adam | epoch: 005 | loss: 0.69274 - acc: 0.4709 -- iter: 768/784
[A[ATraining Step: 125  | total loss: [1m[32m0.69340[0m[0m | time: 15.839s
[2K
| Adam | epoch: 005 | loss: 0.69340 - acc: 0.4706 | val_loss: 0.70280 - val_acc: 0.4898 -- iter: 784/784
--
Training Step: 126  | total loss: [1m[32m0.69136[0m[0m | time: 0.615s
[2K
| Adam | epoch: 006 | loss: 0.69136 - acc: 0.4861 -- iter: 032/784
[A[ATraining Step: 127  | total loss: [1m[32m0.69213[0m[0m | time: 1.198s
[2K
| Adam | epoch: 006 | loss: 0.69213 - acc: 0.4875 -- iter: 064/784
[A[ATraining Step: 128  | total loss: [1m[32m0.69200[0m[0m | time: 1.814s
[2K
| Adam | epoch: 006 | loss: 0.69200 - acc: 0.4918 -- iter: 096/784
[A[ATraining Step: 129  | total loss: [1m[32m0.69192[0m[0m | time: 2.131s
[2K
| Adam | epoch: 006 | loss: 0.69192 - acc: 0.4958 -- iter: 128/784
[A[ATraining Step: 130  | total loss: [1m[32m0.69081[0m[0m | time: 2.452s
[2K
| Adam | epoch: 006 | loss: 0.69081 - acc: 0.5025 -- iter: 160/784
[A[ATraining Step: 131  | total loss: [1m[32m0.68983[0m[0m | time: 3.060s
[2K
| Adam | epoch: 006 | loss: 0.68983 - acc: 0.5085 -- iter: 192/784
[A[ATraining Step: 132  | total loss: [1m[32m0.69011[0m[0m | time: 3.669s
[2K
| Adam | epoch: 006 | loss: 0.69011 - acc: 0.5076 -- iter: 224/784
[A[ATraining Step: 133  | total loss: [1m[32m0.69266[0m[0m | time: 4.273s
[2K
| Adam | epoch: 006 | loss: 0.69266 - acc: 0.4881 -- iter: 256/784
[A[ATraining Step: 134  | total loss: [1m[32m0.69219[0m[0m | time: 4.880s
[2K
| Adam | epoch: 006 | loss: 0.69219 - acc: 0.4924 -- iter: 288/784
[A[ATraining Step: 135  | total loss: [1m[32m0.69220[0m[0m | time: 5.490s
[2K
| Adam | epoch: 006 | loss: 0.69220 - acc: 0.4901 -- iter: 320/784
[A[ATraining Step: 136  | total loss: [1m[32m0.69222[0m[0m | time: 6.107s
[2K
| Adam | epoch: 006 | loss: 0.69222 - acc: 0.4879 -- iter: 352/784
[A[ATraining Step: 137  | total loss: [1m[32m0.69239[0m[0m | time: 6.717s
[2K
| Adam | epoch: 006 | loss: 0.69239 - acc: 0.4829 -- iter: 384/784
[A[ATraining Step: 138  | total loss: [1m[32m0.69248[0m[0m | time: 7.333s
[2K
| Adam | epoch: 006 | loss: 0.69248 - acc: 0.4815 -- iter: 416/784
[A[ATraining Step: 139  | total loss: [1m[32m0.69258[0m[0m | time: 7.925s
[2K
| Adam | epoch: 006 | loss: 0.69258 - acc: 0.4739 -- iter: 448/784
[A[ATraining Step: 140  | total loss: [1m[32m0.69263[0m[0m | time: 8.528s
[2K
| Adam | epoch: 006 | loss: 0.69263 - acc: 0.4797 -- iter: 480/784
[A[ATraining Step: 141  | total loss: [1m[32m0.69264[0m[0m | time: 9.148s
[2K
| Adam | epoch: 006 | loss: 0.69264 - acc: 0.4880 -- iter: 512/784
[A[ATraining Step: 142  | total loss: [1m[32m0.69290[0m[0m | time: 9.754s
[2K
| Adam | epoch: 006 | loss: 0.69290 - acc: 0.4767 -- iter: 544/784
[A[ATraining Step: 143  | total loss: [1m[32m0.69332[0m[0m | time: 10.356s
[2K
| Adam | epoch: 006 | loss: 0.69332 - acc: 0.4540 -- iter: 576/784
[A[ATraining Step: 144  | total loss: [1m[32m0.69323[0m[0m | time: 10.972s
[2K
| Adam | epoch: 006 | loss: 0.69323 - acc: 0.4648 -- iter: 608/784
[A[ATraining Step: 145  | total loss: [1m[32m0.69308[0m[0m | time: 11.583s
[2K
| Adam | epoch: 006 | loss: 0.69308 - acc: 0.4840 -- iter: 640/784
[A[ATraining Step: 146  | total loss: [1m[32m0.69312[0m[0m | time: 12.195s
[2K
| Adam | epoch: 006 | loss: 0.69312 - acc: 0.4825 -- iter: 672/784
[A[ATraining Step: 147  | total loss: [1m[32m0.69305[0m[0m | time: 12.794s
[2K
| Adam | epoch: 006 | loss: 0.69305 - acc: 0.4905 -- iter: 704/784
[A[ATraining Step: 148  | total loss: [1m[32m0.69324[0m[0m | time: 13.404s
[2K
| Adam | epoch: 006 | loss: 0.69324 - acc: 0.4758 -- iter: 736/784
[A[ATraining Step: 149  | total loss: [1m[32m0.69344[0m[0m | time: 14.028s
[2K
| Adam | epoch: 006 | loss: 0.69344 - acc: 0.4595 -- iter: 768/784
[A[ATraining Step: 150  | total loss: [1m[32m0.69344[0m[0m | time: 15.641s
[2K
| Adam | epoch: 006 | loss: 0.69344 - acc: 0.4604 | val_loss: 0.69311 - val_acc: 0.5102 -- iter: 784/784
--
Training Step: 151  | total loss: [1m[32m0.69346[0m[0m | time: 0.659s
[2K
| Adam | epoch: 007 | loss: 0.69346 - acc: 0.4581 -- iter: 032/784
[A[ATraining Step: 152  | total loss: [1m[32m0.69346[0m[0m | time: 1.268s
[2K
| Adam | epoch: 007 | loss: 0.69346 - acc: 0.4560 -- iter: 064/784
[A[ATraining Step: 153  | total loss: [1m[32m0.69345[0m[0m | time: 1.871s
[2K
| Adam | epoch: 007 | loss: 0.69345 - acc: 0.4542 -- iter: 096/784
[A[ATraining Step: 154  | total loss: [1m[32m0.69340[0m[0m | time: 2.470s
[2K
| Adam | epoch: 007 | loss: 0.69340 - acc: 0.4619 -- iter: 128/784
[A[ATraining Step: 155  | total loss: [1m[32m0.69336[0m[0m | time: 2.804s
[2K
| Adam | epoch: 007 | loss: 0.69336 - acc: 0.4751 -- iter: 160/784
[A[ATraining Step: 156  | total loss: [1m[32m0.69335[0m[0m | time: 3.132s
[2K
| Adam | epoch: 007 | loss: 0.69335 - acc: 0.4838 -- iter: 192/784
[A[ATraining Step: 157  | total loss: [1m[32m0.69334[0m[0m | time: 3.746s
[2K
| Adam | epoch: 007 | loss: 0.69334 - acc: 0.4917 -- iter: 224/784
[A[ATraining Step: 158  | total loss: [1m[32m0.69335[0m[0m | time: 4.364s
[2K
| Adam | epoch: 007 | loss: 0.69335 - acc: 0.4831 -- iter: 256/784
[A[ATraining Step: 159  | total loss: [1m[32m0.69342[0m[0m | time: 4.978s
[2K
| Adam | epoch: 007 | loss: 0.69342 - acc: 0.4723 -- iter: 288/784
[A[ATraining Step: 160  | total loss: [1m[32m0.69337[0m[0m | time: 5.580s
[2K
| Adam | epoch: 007 | loss: 0.69337 - acc: 0.4813 -- iter: 320/784
[A[ATraining Step: 161  | total loss: [1m[32m0.69337[0m[0m | time: 6.182s
[2K
| Adam | epoch: 007 | loss: 0.69337 - acc: 0.4801 -- iter: 352/784
[A[ATraining Step: 162  | total loss: [1m[32m0.69333[0m[0m | time: 6.790s
[2K
| Adam | epoch: 007 | loss: 0.69333 - acc: 0.4883 -- iter: 384/784
[A[ATraining Step: 163  | total loss: [1m[32m0.69329[0m[0m | time: 7.439s
[2K
| Adam | epoch: 007 | loss: 0.69329 - acc: 0.4957 -- iter: 416/784
[A[ATraining Step: 164  | total loss: [1m[32m0.69320[0m[0m | time: 8.076s
[2K
| Adam | epoch: 007 | loss: 0.69320 - acc: 0.5118 -- iter: 448/784
[A[ATraining Step: 165  | total loss: [1m[32m0.69334[0m[0m | time: 8.707s
[2K
| Adam | epoch: 007 | loss: 0.69334 - acc: 0.4919 -- iter: 480/784
[A[ATraining Step: 166  | total loss: [1m[32m0.69333[0m[0m | time: 9.314s
[2K
| Adam | epoch: 007 | loss: 0.69333 - acc: 0.4896 -- iter: 512/784
[A[ATraining Step: 167  | total loss: [1m[32m0.69333[0m[0m | time: 9.917s
[2K
| Adam | epoch: 007 | loss: 0.69333 - acc: 0.4906 -- iter: 544/784
[A[ATraining Step: 168  | total loss: [1m[32m0.69333[0m[0m | time: 10.543s
[2K
| Adam | epoch: 007 | loss: 0.69333 - acc: 0.4915 -- iter: 576/784
[A[ATraining Step: 169  | total loss: [1m[32m0.69326[0m[0m | time: 11.151s
[2K
| Adam | epoch: 007 | loss: 0.69326 - acc: 0.4986 -- iter: 608/784
[A[ATraining Step: 170  | total loss: [1m[32m0.69318[0m[0m | time: 11.761s
[2K
| Adam | epoch: 007 | loss: 0.69318 - acc: 0.5081 -- iter: 640/784
[A[ATraining Step: 171  | total loss: [1m[32m0.69322[0m[0m | time: 12.373s
[2K
| Adam | epoch: 007 | loss: 0.69322 - acc: 0.5011 -- iter: 672/784
[A[ATraining Step: 172  | total loss: [1m[32m0.69305[0m[0m | time: 12.989s
[2K
| Adam | epoch: 007 | loss: 0.69305 - acc: 0.5197 -- iter: 704/784
[A[ATraining Step: 173  | total loss: [1m[32m0.69296[0m[0m | time: 13.620s
[2K
| Adam | epoch: 007 | loss: 0.69296 - acc: 0.5271 -- iter: 736/784
[A[ATraining Step: 174  | total loss: [1m[32m0.69285[0m[0m | time: 14.223s
[2K
| Adam | epoch: 007 | loss: 0.69285 - acc: 0.5307 -- iter: 768/784
[A[ATraining Step: 175  | total loss: [1m[32m0.69328[0m[0m | time: 15.852s
[2K
| Adam | epoch: 007 | loss: 0.69328 - acc: 0.5120 | val_loss: 0.69337 - val_acc: 0.4898 -- iter: 784/784
--
Training Step: 176  | total loss: [1m[32m0.69366[0m[0m | time: 0.631s
[2K
| Adam | epoch: 008 | loss: 0.69366 - acc: 0.4952 -- iter: 032/784
[A[ATraining Step: 177  | total loss: [1m[32m0.69348[0m[0m | time: 1.231s
[2K
| Adam | epoch: 008 | loss: 0.69348 - acc: 0.5019 -- iter: 064/784
[A[ATraining Step: 178  | total loss: [1m[32m0.69351[0m[0m | time: 1.854s
[2K
| Adam | epoch: 008 | loss: 0.69351 - acc: 0.4986 -- iter: 096/784
[A[ATraining Step: 179  | total loss: [1m[32m0.69358[0m[0m | time: 2.475s
[2K
| Adam | epoch: 008 | loss: 0.69358 - acc: 0.4925 -- iter: 128/784
[A[ATraining Step: 180  | total loss: [1m[32m0.69350[0m[0m | time: 3.080s
[2K
| Adam | epoch: 008 | loss: 0.69350 - acc: 0.4963 -- iter: 160/784
[A[ATraining Step: 181  | total loss: [1m[32m0.69364[0m[0m | time: 3.401s
[2K
| Adam | epoch: 008 | loss: 0.69364 - acc: 0.4842 -- iter: 192/784
[A[ATraining Step: 182  | total loss: [1m[32m0.69354[0m[0m | time: 3.719s
[2K
| Adam | epoch: 008 | loss: 0.69354 - acc: 0.4920 -- iter: 224/784
[A[ATraining Step: 183  | total loss: [1m[32m0.69346[0m[0m | time: 4.325s
[2K
| Adam | epoch: 008 | loss: 0.69346 - acc: 0.4991 -- iter: 256/784
[A[ATraining Step: 184  | total loss: [1m[32m0.69336[0m[0m | time: 4.931s
[2K
| Adam | epoch: 008 | loss: 0.69336 - acc: 0.5086 -- iter: 288/784
[A[ATraining Step: 185  | total loss: [1m[32m0.69318[0m[0m | time: 5.549s
[2K
| Adam | epoch: 008 | loss: 0.69318 - acc: 0.5233 -- iter: 320/784
[A[ATraining Step: 186  | total loss: [1m[32m0.69329[0m[0m | time: 6.163s
[2K
| Adam | epoch: 008 | loss: 0.69329 - acc: 0.5116 -- iter: 352/784
[A[ATraining Step: 187  | total loss: [1m[32m0.69314[0m[0m | time: 6.781s
[2K
| Adam | epoch: 008 | loss: 0.69314 - acc: 0.5230 -- iter: 384/784
[A[ATraining Step: 188  | total loss: [1m[32m0.69323[0m[0m | time: 7.409s
[2K
| Adam | epoch: 008 | loss: 0.69323 - acc: 0.5144 -- iter: 416/784
[A[ATraining Step: 189  | total loss: [1m[32m0.69317[0m[0m | time: 8.056s
[2K
| Adam | epoch: 008 | loss: 0.69317 - acc: 0.5161 -- iter: 448/784
[A[ATraining Step: 190  | total loss: [1m[32m0.69322[0m[0m | time: 8.666s
[2K
| Adam | epoch: 008 | loss: 0.69322 - acc: 0.5114 -- iter: 480/784
[A[ATraining Step: 191  | total loss: [1m[32m0.69318[0m[0m | time: 9.266s
[2K
| Adam | epoch: 008 | loss: 0.69318 - acc: 0.5133 -- iter: 512/784
[A[ATraining Step: 192  | total loss: [1m[32m0.69308[0m[0m | time: 9.862s
[2K
| Adam | epoch: 008 | loss: 0.69308 - acc: 0.5183 -- iter: 544/784
[A[ATraining Step: 193  | total loss: [1m[32m0.69314[0m[0m | time: 10.463s
[2K
| Adam | epoch: 008 | loss: 0.69314 - acc: 0.5133 -- iter: 576/784
[A[ATraining Step: 194  | total loss: [1m[32m0.69297[0m[0m | time: 11.058s
[2K
| Adam | epoch: 008 | loss: 0.69297 - acc: 0.5214 -- iter: 608/784
[A[ATraining Step: 195  | total loss: [1m[32m0.69282[0m[0m | time: 11.696s
[2K
| Adam | epoch: 008 | loss: 0.69282 - acc: 0.5286 -- iter: 640/784
[A[ATraining Step: 196  | total loss: [1m[32m0.69266[0m[0m | time: 12.301s
[2K
| Adam | epoch: 008 | loss: 0.69266 - acc: 0.5351 -- iter: 672/784
[A[ATraining Step: 197  | total loss: [1m[32m0.69271[0m[0m | time: 12.924s
[2K
| Adam | epoch: 008 | loss: 0.69271 - acc: 0.5316 -- iter: 704/784
[A[ATraining Step: 198  | total loss: [1m[32m0.69294[0m[0m | time: 13.540s
[2K
| Adam | epoch: 008 | loss: 0.69294 - acc: 0.5222 -- iter: 736/784
[A[ATraining Step: 199  | total loss: [1m[32m0.69291[0m[0m | time: 14.145s
[2K
| Adam | epoch: 008 | loss: 0.69291 - acc: 0.5231 -- iter: 768/784
[A[ATraining Step: 200  | total loss: [1m[32m0.69317[0m[0m | time: 15.754s
[2K
| Adam | epoch: 008 | loss: 0.69317 - acc: 0.5145 | val_loss: 0.69351 - val_acc: 0.4898 -- iter: 784/784
--
Training Step: 201  | total loss: [1m[32m0.69327[0m[0m | time: 0.611s
[2K
| Adam | epoch: 009 | loss: 0.69327 - acc: 0.5100 -- iter: 032/784
[A[ATraining Step: 202  | total loss: [1m[32m0.69310[0m[0m | time: 1.226s
[2K
| Adam | epoch: 009 | loss: 0.69310 - acc: 0.5152 -- iter: 064/784
[A[ATraining Step: 203  | total loss: [1m[32m0.69293[0m[0m | time: 1.824s
[2K
| Adam | epoch: 009 | loss: 0.69293 - acc: 0.5199 -- iter: 096/784
[A[ATraining Step: 204  | total loss: [1m[32m0.69270[0m[0m | time: 2.429s
[2K
| Adam | epoch: 009 | loss: 0.69270 - acc: 0.5273 -- iter: 128/784
[A[ATraining Step: 205  | total loss: [1m[32m0.69275[0m[0m | time: 3.055s
[2K
| Adam | epoch: 009 | loss: 0.69275 - acc: 0.5246 -- iter: 160/784
[A[ATraining Step: 206  | total loss: [1m[32m0.69261[0m[0m | time: 3.659s
[2K
| Adam | epoch: 009 | loss: 0.69261 - acc: 0.5284 -- iter: 192/784
[A[ATraining Step: 207  | total loss: [1m[32m0.69246[0m[0m | time: 4.001s
[2K
| Adam | epoch: 009 | loss: 0.69246 - acc: 0.5318 -- iter: 224/784
[A[ATraining Step: 208  | total loss: [1m[32m0.69279[0m[0m | time: 4.319s
[2K
| Adam | epoch: 009 | loss: 0.69279 - acc: 0.5224 -- iter: 256/784
[A[ATraining Step: 209  | total loss: [1m[32m0.69311[0m[0m | time: 4.918s
[2K
| Adam | epoch: 009 | loss: 0.69311 - acc: 0.5139 -- iter: 288/784
[A[ATraining Step: 210  | total loss: [1m[32m0.69326[0m[0m | time: 5.525s
[2K
| Adam | epoch: 009 | loss: 0.69326 - acc: 0.5094 -- iter: 320/784
[A[ATraining Step: 211  | total loss: [1m[32m0.69310[0m[0m | time: 6.126s
[2K
| Adam | epoch: 009 | loss: 0.69310 - acc: 0.5116 -- iter: 352/784
[A[ATraining Step: 212  | total loss: [1m[32m0.69299[0m[0m | time: 6.754s
[2K
| Adam | epoch: 009 | loss: 0.69299 - acc: 0.5135 -- iter: 384/784
[A[ATraining Step: 213  | total loss: [1m[32m0.69256[0m[0m | time: 7.351s
[2K
| Adam | epoch: 009 | loss: 0.69256 - acc: 0.5247 -- iter: 416/784
[A[ATraining Step: 214  | total loss: [1m[32m0.69280[0m[0m | time: 7.962s
[2K
| Adam | epoch: 009 | loss: 0.69280 - acc: 0.5191 -- iter: 448/784
[A[ATraining Step: 215  | total loss: [1m[32m0.69283[0m[0m | time: 8.571s
[2K
| Adam | epoch: 009 | loss: 0.69283 - acc: 0.5172 -- iter: 480/784
[A[ATraining Step: 216  | total loss: [1m[32m0.69302[0m[0m | time: 9.181s
[2K
| Adam | epoch: 009 | loss: 0.69302 - acc: 0.5123 -- iter: 512/784
[A[ATraining Step: 217  | total loss: [1m[32m0.69398[0m[0m | time: 9.785s
[2K
| Adam | epoch: 009 | loss: 0.69398 - acc: 0.4892 -- iter: 544/784
[A[ATraining Step: 218  | total loss: [1m[32m0.69408[0m[0m | time: 10.390s
[2K
| Adam | epoch: 009 | loss: 0.69408 - acc: 0.4872 -- iter: 576/784
[A[ATraining Step: 219  | total loss: [1m[32m0.69389[0m[0m | time: 10.998s
[2K
| Adam | epoch: 009 | loss: 0.69389 - acc: 0.4916 -- iter: 608/784
[A[ATraining Step: 220  | total loss: [1m[32m0.69397[0m[0m | time: 11.619s
[2K
| Adam | epoch: 009 | loss: 0.69397 - acc: 0.4893 -- iter: 640/784
[A[ATraining Step: 221  | total loss: [1m[32m0.69368[0m[0m | time: 12.241s
[2K
| Adam | epoch: 009 | loss: 0.69368 - acc: 0.4966 -- iter: 672/784
[A[ATraining Step: 222  | total loss: [1m[32m0.69385[0m[0m | time: 12.867s
[2K
| Adam | epoch: 009 | loss: 0.69385 - acc: 0.4907 -- iter: 704/784
[A[ATraining Step: 223  | total loss: [1m[32m0.69416[0m[0m | time: 13.483s
[2K
| Adam | epoch: 009 | loss: 0.69416 - acc: 0.4791 -- iter: 736/784
[A[ATraining Step: 224  | total loss: [1m[32m0.69388[0m[0m | time: 14.111s
[2K
| Adam | epoch: 009 | loss: 0.69388 - acc: 0.4875 -- iter: 768/784
[A[ATraining Step: 225  | total loss: [1m[32m0.69382[0m[0m | time: 15.744s
[2K
| Adam | epoch: 009 | loss: 0.69382 - acc: 0.4887 | val_loss: 0.69343 - val_acc: 0.4898 -- iter: 784/784
--
Training Step: 226  | total loss: [1m[32m0.69370[0m[0m | time: 0.615s
[2K
| Adam | epoch: 010 | loss: 0.69370 - acc: 0.4930 -- iter: 032/784
[A[ATraining Step: 227  | total loss: [1m[32m0.69350[0m[0m | time: 1.224s
[2K
| Adam | epoch: 010 | loss: 0.69350 - acc: 0.4999 -- iter: 064/784
[A[ATraining Step: 228  | total loss: [1m[32m0.69375[0m[0m | time: 1.837s
[2K
| Adam | epoch: 010 | loss: 0.69375 - acc: 0.4874 -- iter: 096/784
[A[ATraining Step: 229  | total loss: [1m[32m0.69372[0m[0m | time: 2.447s
[2K
| Adam | epoch: 010 | loss: 0.69372 - acc: 0.4887 -- iter: 128/784
[A[ATraining Step: 230  | total loss: [1m[32m0.69362[0m[0m | time: 3.067s
[2K
| Adam | epoch: 010 | loss: 0.69362 - acc: 0.4929 -- iter: 160/784
[A[ATraining Step: 231  | total loss: [1m[32m0.69348[0m[0m | time: 3.679s
[2K
| Adam | epoch: 010 | loss: 0.69348 - acc: 0.4999 -- iter: 192/784
[A[ATraining Step: 232  | total loss: [1m[32m0.69346[0m[0m | time: 4.291s
[2K
| Adam | epoch: 010 | loss: 0.69346 - acc: 0.4999 -- iter: 224/784
[A[ATraining Step: 233  | total loss: [1m[32m0.69347[0m[0m | time: 4.604s
[2K
| Adam | epoch: 010 | loss: 0.69347 - acc: 0.4968 -- iter: 256/784
[A[ATraining Step: 234  | total loss: [1m[32m0.69344[0m[0m | time: 4.922s
[2K
| Adam | epoch: 010 | loss: 0.69344 - acc: 0.4971 -- iter: 288/784
[A[ATraining Step: 235  | total loss: [1m[32m0.69346[0m[0m | time: 5.546s
[2K
| Adam | epoch: 010 | loss: 0.69346 - acc: 0.4974 -- iter: 320/784
[A[ATraining Step: 236  | total loss: [1m[32m0.69323[0m[0m | time: 6.172s
[2K
| Adam | epoch: 010 | loss: 0.69323 - acc: 0.5102 -- iter: 352/784
[A[ATraining Step: 237  | total loss: [1m[32m0.69322[0m[0m | time: 6.775s
[2K
| Adam | epoch: 010 | loss: 0.69322 - acc: 0.5091 -- iter: 384/784
[A[ATraining Step: 238  | total loss: [1m[32m0.69307[0m[0m | time: 7.377s
[2K
| Adam | epoch: 010 | loss: 0.69307 - acc: 0.5176 -- iter: 416/784
[A[ATraining Step: 239  | total loss: [1m[32m0.69297[0m[0m | time: 7.997s
[2K
| Adam | epoch: 010 | loss: 0.69297 - acc: 0.5221 -- iter: 448/784
[A[ATraining Step: 240  | total loss: [1m[32m0.69319[0m[0m | time: 8.614s
[2K
| Adam | epoch: 010 | loss: 0.69319 - acc: 0.5074 -- iter: 480/784
[A[ATraining Step: 241  | total loss: [1m[32m0.69329[0m[0m | time: 9.225s
[2K
| Adam | epoch: 010 | loss: 0.69329 - acc: 0.5004 -- iter: 512/784
[A[ATraining Step: 242  | total loss: [1m[32m0.69318[0m[0m | time: 9.828s
[2K
| Adam | epoch: 010 | loss: 0.69318 - acc: 0.5066 -- iter: 544/784
[A[ATraining Step: 243  | total loss: [1m[32m0.69315[0m[0m | time: 10.454s
[2K
| Adam | epoch: 010 | loss: 0.69315 - acc: 0.5059 -- iter: 576/784
[A[ATraining Step: 244  | total loss: [1m[32m0.69306[0m[0m | time: 11.083s
[2K
| Adam | epoch: 010 | loss: 0.69306 - acc: 0.5085 -- iter: 608/784
[A[ATraining Step: 245  | total loss: [1m[32m0.69302[0m[0m | time: 11.695s
[2K
| Adam | epoch: 010 | loss: 0.69302 - acc: 0.5108 -- iter: 640/784
[A[ATraining Step: 246  | total loss: [1m[32m0.69291[0m[0m | time: 12.325s
[2K
| Adam | epoch: 010 | loss: 0.69291 - acc: 0.5159 -- iter: 672/784
[A[ATraining Step: 247  | total loss: [1m[32m0.69295[0m[0m | time: 12.949s
[2K
| Adam | epoch: 010 | loss: 0.69295 - acc: 0.5112 -- iter: 704/784
[A[ATraining Step: 248  | total loss: [1m[32m0.69311[0m[0m | time: 13.558s
[2K
| Adam | epoch: 010 | loss: 0.69311 - acc: 0.5007 -- iter: 736/784
[A[ATraining Step: 249  | total loss: [1m[32m0.69315[0m[0m | time: 14.167s
[2K
| Adam | epoch: 010 | loss: 0.69315 - acc: 0.4944 -- iter: 768/784
[A[ATraining Step: 250  | total loss: [1m[32m0.69301[0m[0m | time: 15.800s
[2K
| Adam | epoch: 010 | loss: 0.69301 - acc: 0.5168 | val_loss: 0.69236 - val_acc: 0.4898 -- iter: 784/784
--
Training Step: 251  | total loss: [1m[32m0.69286[0m[0m | time: 0.609s
[2K
| Adam | epoch: 011 | loss: 0.69286 - acc: 0.5339 -- iter: 032/784
[A[ATraining Step: 252  | total loss: [1m[32m0.69305[0m[0m | time: 1.217s
[2K
| Adam | epoch: 011 | loss: 0.69305 - acc: 0.5149 -- iter: 064/784
[A[ATraining Step: 253  | total loss: [1m[32m0.69290[0m[0m | time: 1.831s
[2K
| Adam | epoch: 011 | loss: 0.69290 - acc: 0.5165 -- iter: 096/784
[A[ATraining Step: 254  | total loss: [1m[32m0.69288[0m[0m | time: 2.461s
[2K
| Adam | epoch: 011 | loss: 0.69288 - acc: 0.5086 -- iter: 128/784
[A[ATraining Step: 255  | total loss: [1m[32m0.69261[0m[0m | time: 3.073s
[2K
| Adam | epoch: 011 | loss: 0.69261 - acc: 0.5484 -- iter: 160/784
[A[ATraining Step: 256  | total loss: [1m[32m0.69231[0m[0m | time: 3.710s
[2K
| Adam | epoch: 011 | loss: 0.69231 - acc: 0.5779 -- iter: 192/784
[A[ATraining Step: 257  | total loss: [1m[32m0.69200[0m[0m | time: 4.333s
[2K
| Adam | epoch: 011 | loss: 0.69200 - acc: 0.5764 -- iter: 224/784
[A[ATraining Step: 258  | total loss: [1m[32m0.69211[0m[0m | time: 4.942s
[2K
| Adam | epoch: 011 | loss: 0.69211 - acc: 0.5687 -- iter: 256/784
[A[ATraining Step: 259  | total loss: [1m[32m0.69174[0m[0m | time: 5.269s
[2K
| Adam | epoch: 011 | loss: 0.69174 - acc: 0.5869 -- iter: 288/784
[A[ATraining Step: 260  | total loss: [1m[32m0.69196[0m[0m | time: 5.595s
[2K
| Adam | epoch: 011 | loss: 0.69196 - acc: 0.5719 -- iter: 320/784
[A[ATraining Step: 261  | total loss: [1m[32m0.69093[0m[0m | time: 6.203s
[2K
| Adam | epoch: 011 | loss: 0.69093 - acc: 0.5772 -- iter: 352/784
[A[ATraining Step: 262  | total loss: [1m[32m0.68925[0m[0m | time: 6.820s
[2K
| Adam | epoch: 011 | loss: 0.68925 - acc: 0.5758 -- iter: 384/784
[A[ATraining Step: 263  | total loss: [1m[32m0.69239[0m[0m | time: 7.442s
[2K
| Adam | epoch: 011 | loss: 0.69239 - acc: 0.5619 -- iter: 416/784
[A[ATraining Step: 264  | total loss: [1m[32m0.69293[0m[0m | time: 8.058s
[2K
| Adam | epoch: 011 | loss: 0.69293 - acc: 0.5526 -- iter: 448/784
[A[ATraining Step: 265  | total loss: [1m[32m0.69316[0m[0m | time: 8.671s
[2K
| Adam | epoch: 011 | loss: 0.69316 - acc: 0.5349 -- iter: 480/784
[A[ATraining Step: 266  | total loss: [1m[32m0.69187[0m[0m | time: 9.281s
[2K
| Adam | epoch: 011 | loss: 0.69187 - acc: 0.5470 -- iter: 512/784
[A[ATraining Step: 267  | total loss: [1m[32m0.69155[0m[0m | time: 9.891s
[2K
| Adam | epoch: 011 | loss: 0.69155 - acc: 0.5548 -- iter: 544/784
[A[ATraining Step: 268  | total loss: [1m[32m0.69105[0m[0m | time: 10.507s
[2K
| Adam | epoch: 011 | loss: 0.69105 - acc: 0.5681 -- iter: 576/784
[A[ATraining Step: 269  | total loss: [1m[32m0.69054[0m[0m | time: 11.127s
[2K
| Adam | epoch: 011 | loss: 0.69054 - acc: 0.5831 -- iter: 608/784
[A[ATraining Step: 270  | total loss: [1m[32m0.68980[0m[0m | time: 11.745s
[2K
| Adam | epoch: 011 | loss: 0.68980 - acc: 0.6061 -- iter: 640/784
[A[ATraining Step: 271  | total loss: [1m[32m0.68868[0m[0m | time: 12.352s
[2K
| Adam | epoch: 011 | loss: 0.68868 - acc: 0.6142 -- iter: 672/784
[A[ATraining Step: 272  | total loss: [1m[32m0.68895[0m[0m | time: 12.960s
[2K
| Adam | epoch: 011 | loss: 0.68895 - acc: 0.5965 -- iter: 704/784
[A[ATraining Step: 273  | total loss: [1m[32m0.68590[0m[0m | time: 13.591s
[2K
| Adam | epoch: 011 | loss: 0.68590 - acc: 0.6056 -- iter: 736/784
[A[ATraining Step: 274  | total loss: [1m[32m0.68425[0m[0m | time: 14.220s
[2K
| Adam | epoch: 011 | loss: 0.68425 - acc: 0.6138 -- iter: 768/784
[A[ATraining Step: 275  | total loss: [1m[32m0.68079[0m[0m | time: 15.851s
[2K
| Adam | epoch: 011 | loss: 0.68079 - acc: 0.6243 | val_loss: 0.62801 - val_acc: 0.7388 -- iter: 784/784
--
Training Step: 276  | total loss: [1m[32m0.67972[0m[0m | time: 0.610s
[2K
| Adam | epoch: 012 | loss: 0.67972 - acc: 0.6213 -- iter: 032/784
[A[ATraining Step: 277  | total loss: [1m[32m0.67826[0m[0m | time: 1.222s
[2K
| Adam | epoch: 012 | loss: 0.67826 - acc: 0.6216 -- iter: 064/784
[A[ATraining Step: 278  | total loss: [1m[32m0.67111[0m[0m | time: 1.845s
[2K
| Adam | epoch: 012 | loss: 0.67111 - acc: 0.6313 -- iter: 096/784
[A[ATraining Step: 279  | total loss: [1m[32m0.67234[0m[0m | time: 2.471s
[2K
| Adam | epoch: 012 | loss: 0.67234 - acc: 0.6276 -- iter: 128/784
[A[ATraining Step: 280  | total loss: [1m[32m0.66518[0m[0m | time: 3.086s
[2K
| Adam | epoch: 012 | loss: 0.66518 - acc: 0.6336 -- iter: 160/784
[A[ATraining Step: 281  | total loss: [1m[32m0.65030[0m[0m | time: 3.696s
[2K
| Adam | epoch: 012 | loss: 0.65030 - acc: 0.6452 -- iter: 192/784
[A[ATraining Step: 282  | total loss: [1m[32m0.66572[0m[0m | time: 4.307s
[2K
| Adam | epoch: 012 | loss: 0.66572 - acc: 0.6401 -- iter: 224/784
[A[ATraining Step: 283  | total loss: [1m[32m0.65168[0m[0m | time: 4.949s
[2K
| Adam | epoch: 012 | loss: 0.65168 - acc: 0.6573 -- iter: 256/784
[A[ATraining Step: 284  | total loss: [1m[32m0.64208[0m[0m | time: 5.732s
[2K
| Adam | epoch: 012 | loss: 0.64208 - acc: 0.6728 -- iter: 288/784
[A[ATraining Step: 285  | total loss: [1m[32m0.63447[0m[0m | time: 6.150s
[2K
| Adam | epoch: 012 | loss: 0.63447 - acc: 0.6868 -- iter: 320/784
[A[ATraining Step: 286  | total loss: [1m[32m0.61512[0m[0m | time: 6.505s
[2K
| Adam | epoch: 012 | loss: 0.61512 - acc: 0.7119 -- iter: 352/784
[A[ATraining Step: 287  | total loss: [1m[32m0.59153[0m[0m | time: 7.284s
[2K
| Adam | epoch: 012 | loss: 0.59153 - acc: 0.7344 -- iter: 384/784
[A[ATraining Step: 288  | total loss: [1m[32m0.59408[0m[0m | time: 8.058s
[2K
| Adam | epoch: 012 | loss: 0.59408 - acc: 0.7266 -- iter: 416/784
[A[ATraining Step: 289  | total loss: [1m[32m0.59594[0m[0m | time: 8.814s
[2K
| Adam | epoch: 012 | loss: 0.59594 - acc: 0.7258 -- iter: 448/784
[A[ATraining Step: 290  | total loss: [1m[32m0.60389[0m[0m | time: 9.576s
[2K
| Adam | epoch: 012 | loss: 0.60389 - acc: 0.7251 -- iter: 480/784
[A[ATraining Step: 291  | total loss: [1m[32m0.59353[0m[0m | time: 10.284s
[2K
| Adam | epoch: 012 | loss: 0.59353 - acc: 0.7370 -- iter: 512/784
[A[ATraining Step: 292  | total loss: [1m[32m0.58453[0m[0m | time: 11.030s
[2K
| Adam | epoch: 012 | loss: 0.58453 - acc: 0.7352 -- iter: 544/784
[A[ATraining Step: 293  | total loss: [1m[32m0.58350[0m[0m | time: 11.637s
[2K
| Adam | epoch: 012 | loss: 0.58350 - acc: 0.7273 -- iter: 576/784
[A[ATraining Step: 294  | total loss: [1m[32m0.57735[0m[0m | time: 12.239s
[2K
| Adam | epoch: 012 | loss: 0.57735 - acc: 0.7233 -- iter: 608/784
[A[ATraining Step: 295  | total loss: [1m[32m0.56940[0m[0m | time: 12.869s
[2K
| Adam | epoch: 012 | loss: 0.56940 - acc: 0.7291 -- iter: 640/784
[A[ATraining Step: 296  | total loss: [1m[32m0.56987[0m[0m | time: 13.479s
[2K
| Adam | epoch: 012 | loss: 0.56987 - acc: 0.7249 -- iter: 672/784
[A[ATraining Step: 297  | total loss: [1m[32m0.56177[0m[0m | time: 14.100s
[2K
| Adam | epoch: 012 | loss: 0.56177 - acc: 0.7306 -- iter: 704/784
[A[ATraining Step: 298  | total loss: [1m[32m0.57054[0m[0m | time: 14.770s
[2K
| Adam | epoch: 012 | loss: 0.57054 - acc: 0.7231 -- iter: 736/784
[A[ATraining Step: 299  | total loss: [1m[32m0.55406[0m[0m | time: 15.527s
[2K
| Adam | epoch: 012 | loss: 0.55406 - acc: 0.7321 -- iter: 768/784
[A[ATraining Step: 300  | total loss: [1m[32m0.54541[0m[0m | time: 17.281s
[2K
| Adam | epoch: 012 | loss: 0.54541 - acc: 0.7370 | val_loss: 0.49798 - val_acc: 0.7714 -- iter: 784/784
--
Training Step: 301  | total loss: [1m[32m0.55429[0m[0m | time: 0.620s
[2K
| Adam | epoch: 013 | loss: 0.55429 - acc: 0.7258 -- iter: 032/784
[A[ATraining Step: 302  | total loss: [1m[32m0.53680[0m[0m | time: 1.348s
[2K
| Adam | epoch: 013 | loss: 0.53680 - acc: 0.7376 -- iter: 064/784
[A[ATraining Step: 303  | total loss: [1m[32m0.54927[0m[0m | time: 2.087s
[2K
| Adam | epoch: 013 | loss: 0.54927 - acc: 0.7357 -- iter: 096/784
[A[ATraining Step: 304  | total loss: [1m[32m0.57007[0m[0m | time: 2.863s
[2K
| Adam | epoch: 013 | loss: 0.57007 - acc: 0.7153 -- iter: 128/784
[A[ATraining Step: 305  | total loss: [1m[32m0.55791[0m[0m | time: 3.603s
[2K
| Adam | epoch: 013 | loss: 0.55791 - acc: 0.7250 -- iter: 160/784
[A[ATraining Step: 306  | total loss: [1m[32m0.54885[0m[0m | time: 4.397s
[2K
| Adam | epoch: 013 | loss: 0.54885 - acc: 0.7337 -- iter: 192/784
[A[ATraining Step: 307  | total loss: [1m[32m0.55040[0m[0m | time: 5.156s
[2K
| Adam | epoch: 013 | loss: 0.55040 - acc: 0.7260 -- iter: 224/784
[A[ATraining Step: 308  | total loss: [1m[32m0.53523[0m[0m | time: 5.918s
[2K
| Adam | epoch: 013 | loss: 0.53523 - acc: 0.7409 -- iter: 256/784
[A[ATraining Step: 309  | total loss: [1m[32m0.52695[0m[0m | time: 6.685s
[2K
| Adam | epoch: 013 | loss: 0.52695 - acc: 0.7449 -- iter: 288/784
[A[ATraining Step: 310  | total loss: [1m[32m0.50978[0m[0m | time: 7.284s
[2K
| Adam | epoch: 013 | loss: 0.50978 - acc: 0.7486 -- iter: 320/784
[A[ATraining Step: 311  | total loss: [1m[32m0.50821[0m[0m | time: 7.608s
[2K
| Adam | epoch: 013 | loss: 0.50821 - acc: 0.7487 -- iter: 352/784
[A[ATraining Step: 312  | total loss: [1m[32m0.52032[0m[0m | time: 7.925s
[2K
| Adam | epoch: 013 | loss: 0.52032 - acc: 0.7363 -- iter: 384/784
[A[ATraining Step: 313  | total loss: [1m[32m0.52115[0m[0m | time: 8.535s
[2K
| Adam | epoch: 013 | loss: 0.52115 - acc: 0.7439 -- iter: 416/784
[A[ATraining Step: 314  | total loss: [1m[32m0.53277[0m[0m | time: 9.166s
[2K
| Adam | epoch: 013 | loss: 0.53277 - acc: 0.7383 -- iter: 448/784
[A[ATraining Step: 315  | total loss: [1m[32m0.55050[0m[0m | time: 9.780s
[2K
| Adam | epoch: 013 | loss: 0.55050 - acc: 0.7301 -- iter: 480/784
[A[ATraining Step: 316  | total loss: [1m[32m0.53307[0m[0m | time: 10.399s
[2K
| Adam | epoch: 013 | loss: 0.53307 - acc: 0.7477 -- iter: 512/784
[A[ATraining Step: 317  | total loss: [1m[32m0.52345[0m[0m | time: 11.011s
[2K
| Adam | epoch: 013 | loss: 0.52345 - acc: 0.7573 -- iter: 544/784
[A[ATraining Step: 318  | total loss: [1m[32m0.51531[0m[0m | time: 11.744s
[2K
| Adam | epoch: 013 | loss: 0.51531 - acc: 0.7628 -- iter: 576/784
[A[ATraining Step: 319  | total loss: [1m[32m0.50958[0m[0m | time: 12.471s
[2K
| Adam | epoch: 013 | loss: 0.50958 - acc: 0.7647 -- iter: 608/784
[A[ATraining Step: 320  | total loss: [1m[32m0.51503[0m[0m | time: 13.242s
[2K
| Adam | epoch: 013 | loss: 0.51503 - acc: 0.7601 -- iter: 640/784
[A[ATraining Step: 321  | total loss: [1m[32m0.52557[0m[0m | time: 14.000s
[2K
| Adam | epoch: 013 | loss: 0.52557 - acc: 0.7466 -- iter: 672/784
[A[ATraining Step: 322  | total loss: [1m[32m0.51766[0m[0m | time: 14.741s
[2K
| Adam | epoch: 013 | loss: 0.51766 - acc: 0.7532 -- iter: 704/784
[A[ATraining Step: 323  | total loss: [1m[32m0.49553[0m[0m | time: 15.491s
[2K
| Adam | epoch: 013 | loss: 0.49553 - acc: 0.7685 -- iter: 736/784
[A[ATraining Step: 324  | total loss: [1m[32m0.48034[0m[0m | time: 16.268s
[2K
| Adam | epoch: 013 | loss: 0.48034 - acc: 0.7760 -- iter: 768/784
[A[ATraining Step: 325  | total loss: [1m[32m0.48306[0m[0m | time: 18.026s
[2K
| Adam | epoch: 013 | loss: 0.48306 - acc: 0.7797 | val_loss: 0.49753 - val_acc: 0.7755 -- iter: 784/784
--
Training Step: 326  | total loss: [1m[32m0.47597[0m[0m | time: 0.762s
[2K
| Adam | epoch: 014 | loss: 0.47597 - acc: 0.7861 -- iter: 032/784
[A[ATraining Step: 327  | total loss: [1m[32m0.47460[0m[0m | time: 1.461s
[2K
| Adam | epoch: 014 | loss: 0.47460 - acc: 0.7887 -- iter: 064/784
[A[ATraining Step: 328  | total loss: [1m[32m0.47839[0m[0m | time: 2.177s
[2K
| Adam | epoch: 014 | loss: 0.47839 - acc: 0.7817 -- iter: 096/784
[A[ATraining Step: 329  | total loss: [1m[32m0.48102[0m[0m | time: 2.904s
[2K
| Adam | epoch: 014 | loss: 0.48102 - acc: 0.7817 -- iter: 128/784
[A[ATraining Step: 330  | total loss: [1m[32m0.45607[0m[0m | time: 3.520s
[2K
| Adam | epoch: 014 | loss: 0.45607 - acc: 0.8004 -- iter: 160/784
[A[ATraining Step: 331  | total loss: [1m[32m0.46638[0m[0m | time: 4.126s
[2K
| Adam | epoch: 014 | loss: 0.46638 - acc: 0.7922 -- iter: 192/784
[A[ATraining Step: 332  | total loss: [1m[32m0.45770[0m[0m | time: 4.736s
[2K
| Adam | epoch: 014 | loss: 0.45770 - acc: 0.7942 -- iter: 224/784
[A[ATraining Step: 333  | total loss: [1m[32m0.45434[0m[0m | time: 5.382s
[2K
| Adam | epoch: 014 | loss: 0.45434 - acc: 0.7961 -- iter: 256/784
[A[ATraining Step: 334  | total loss: [1m[32m0.43733[0m[0m | time: 5.993s
[2K
| Adam | epoch: 014 | loss: 0.43733 - acc: 0.8102 -- iter: 288/784
[A[ATraining Step: 335  | total loss: [1m[32m0.42281[0m[0m | time: 6.583s
[2K
| Adam | epoch: 014 | loss: 0.42281 - acc: 0.8198 -- iter: 320/784
[A[ATraining Step: 336  | total loss: [1m[32m0.41758[0m[0m | time: 7.190s
[2K
| Adam | epoch: 014 | loss: 0.41758 - acc: 0.8222 -- iter: 352/784
[A[ATraining Step: 337  | total loss: [1m[32m0.40147[0m[0m | time: 7.616s
[2K
| Adam | epoch: 014 | loss: 0.40147 - acc: 0.8337 -- iter: 384/784
[A[ATraining Step: 338  | total loss: [1m[32m0.41463[0m[0m | time: 7.968s
[2K
| Adam | epoch: 014 | loss: 0.41463 - acc: 0.8254 -- iter: 416/784
[A[ATraining Step: 339  | total loss: [1m[32m0.41484[0m[0m | time: 8.741s
[2K
| Adam | epoch: 014 | loss: 0.41484 - acc: 0.8241 -- iter: 448/784
[A[ATraining Step: 340  | total loss: [1m[32m0.41995[0m[0m | time: 9.494s
[2K
| Adam | epoch: 014 | loss: 0.41995 - acc: 0.8229 -- iter: 480/784
[A[ATraining Step: 341  | total loss: [1m[32m0.45142[0m[0m | time: 10.264s
[2K
| Adam | epoch: 014 | loss: 0.45142 - acc: 0.8094 -- iter: 512/784
[A[ATraining Step: 342  | total loss: [1m[32m0.43518[0m[0m | time: 11.094s
[2K
| Adam | epoch: 014 | loss: 0.43518 - acc: 0.8191 -- iter: 544/784
[A[ATraining Step: 343  | total loss: [1m[32m0.41985[0m[0m | time: 11.862s
[2K
| Adam | epoch: 014 | loss: 0.41985 - acc: 0.8247 -- iter: 576/784
[A[ATraining Step: 344  | total loss: [1m[32m0.40666[0m[0m | time: 12.635s
[2K
| Adam | epoch: 014 | loss: 0.40666 - acc: 0.8359 -- iter: 608/784
[A[ATraining Step: 345  | total loss: [1m[32m0.41212[0m[0m | time: 13.235s
[2K
| Adam | epoch: 014 | loss: 0.41212 - acc: 0.8336 -- iter: 640/784
[A[ATraining Step: 346  | total loss: [1m[32m0.42874[0m[0m | time: 13.870s
[2K
| Adam | epoch: 014 | loss: 0.42874 - acc: 0.8159 -- iter: 672/784
[A[ATraining Step: 347  | total loss: [1m[32m0.42640[0m[0m | time: 14.483s
[2K
| Adam | epoch: 014 | loss: 0.42640 - acc: 0.8218 -- iter: 704/784
[A[ATraining Step: 348  | total loss: [1m[32m0.43313[0m[0m | time: 15.102s
[2K
| Adam | epoch: 014 | loss: 0.43313 - acc: 0.8146 -- iter: 736/784
[A[ATraining Step: 349  | total loss: [1m[32m0.42749[0m[0m | time: 15.691s
[2K
| Adam | epoch: 014 | loss: 0.42749 - acc: 0.8144 -- iter: 768/784
[A[ATraining Step: 350  | total loss: [1m[32m0.42784[0m[0m | time: 17.297s
[2K
| Adam | epoch: 014 | loss: 0.42784 - acc: 0.8142 | val_loss: 0.48192 - val_acc: 0.7714 -- iter: 784/784
--
Training Step: 351  | total loss: [1m[32m0.41500[0m[0m | time: 0.746s
[2K
| Adam | epoch: 015 | loss: 0.41500 - acc: 0.8234 -- iter: 032/784
[A[ATraining Step: 352  | total loss: [1m[32m0.42279[0m[0m | time: 1.487s
[2K
| Adam | epoch: 015 | loss: 0.42279 - acc: 0.8129 -- iter: 064/784
[A[ATraining Step: 353  | total loss: [1m[32m0.42093[0m[0m | time: 2.219s
[2K
| Adam | epoch: 015 | loss: 0.42093 - acc: 0.8129 -- iter: 096/784
[A[ATraining Step: 354  | total loss: [1m[32m0.40406[0m[0m | time: 2.835s
[2K
| Adam | epoch: 015 | loss: 0.40406 - acc: 0.8254 -- iter: 128/784
[A[ATraining Step: 355  | total loss: [1m[32m0.38464[0m[0m | time: 3.468s
[2K
| Adam | epoch: 015 | loss: 0.38464 - acc: 0.8366 -- iter: 160/784
[A[ATraining Step: 356  | total loss: [1m[32m0.41250[0m[0m | time: 4.074s
[2K
| Adam | epoch: 015 | loss: 0.41250 - acc: 0.8248 -- iter: 192/784
[A[ATraining Step: 357  | total loss: [1m[32m0.42986[0m[0m | time: 4.682s
[2K
| Adam | epoch: 015 | loss: 0.42986 - acc: 0.8142 -- iter: 224/784
[A[ATraining Step: 358  | total loss: [1m[32m0.42940[0m[0m | time: 5.279s
[2K
| Adam | epoch: 015 | loss: 0.42940 - acc: 0.8234 -- iter: 256/784
[A[ATraining Step: 359  | total loss: [1m[32m0.42633[0m[0m | time: 5.883s
[2K
| Adam | epoch: 015 | loss: 0.42633 - acc: 0.8286 -- iter: 288/784
[A[ATraining Step: 360  | total loss: [1m[32m0.41418[0m[0m | time: 6.523s
[2K
| Adam | epoch: 015 | loss: 0.41418 - acc: 0.8332 -- iter: 320/784
[A[ATraining Step: 361  | total loss: [1m[32m0.39888[0m[0m | time: 7.223s
[2K
| Adam | epoch: 015 | loss: 0.39888 - acc: 0.8374 -- iter: 352/784
[A[ATraining Step: 362  | total loss: [1m[32m0.38089[0m[0m | time: 8.019s
[2K
| Adam | epoch: 015 | loss: 0.38089 - acc: 0.8474 -- iter: 384/784
[A[ATraining Step: 363  | total loss: [1m[32m0.38220[0m[0m | time: 8.368s
[2K
| Adam | epoch: 015 | loss: 0.38220 - acc: 0.8408 -- iter: 416/784
[A[ATraining Step: 364  | total loss: [1m[32m0.36047[0m[0m | time: 8.840s
[2K
| Adam | epoch: 015 | loss: 0.36047 - acc: 0.8504 -- iter: 448/784
[A[ATraining Step: 365  | total loss: [1m[32m0.33870[0m[0m | time: 9.572s
[2K
| Adam | epoch: 015 | loss: 0.33870 - acc: 0.8592 -- iter: 480/784
[A[ATraining Step: 366  | total loss: [1m[32m0.33572[0m[0m | time: 10.292s
[2K
| Adam | epoch: 015 | loss: 0.33572 - acc: 0.8576 -- iter: 512/784
[A[ATraining Step: 367  | total loss: [1m[32m0.34561[0m[0m | time: 10.965s
[2K
| Adam | epoch: 015 | loss: 0.34561 - acc: 0.8500 -- iter: 544/784
[A[ATraining Step: 368  | total loss: [1m[32m0.32732[0m[0m | time: 11.667s
[2K
| Adam | epoch: 015 | loss: 0.32732 - acc: 0.8587 -- iter: 576/784
[A[ATraining Step: 369  | total loss: [1m[32m0.31997[0m[0m | time: 12.416s
[2K
| Adam | epoch: 015 | loss: 0.31997 - acc: 0.8635 -- iter: 608/784
[A[ATraining Step: 370  | total loss: [1m[32m0.33393[0m[0m | time: 13.034s
[2K
| Adam | epoch: 015 | loss: 0.33393 - acc: 0.8553 -- iter: 640/784
[A[ATraining Step: 371  | total loss: [1m[32m0.31558[0m[0m | time: 13.653s
[2K
| Adam | epoch: 015 | loss: 0.31558 - acc: 0.8635 -- iter: 672/784
[A[ATraining Step: 372  | total loss: [1m[32m0.30231[0m[0m | time: 14.272s
[2K
| Adam | epoch: 015 | loss: 0.30231 - acc: 0.8709 -- iter: 704/784
[A[ATraining Step: 373  | total loss: [1m[32m0.32064[0m[0m | time: 14.890s
[2K
| Adam | epoch: 015 | loss: 0.32064 - acc: 0.8650 -- iter: 736/784
[A[ATraining Step: 374  | total loss: [1m[32m0.32783[0m[0m | time: 15.510s
[2K
| Adam | epoch: 015 | loss: 0.32783 - acc: 0.8660 -- iter: 768/784
[A[ATraining Step: 375  | total loss: [1m[32m0.32409[0m[0m | time: 17.131s
[2K
| Adam | epoch: 015 | loss: 0.32409 - acc: 0.8701 | val_loss: 0.47616 - val_acc: 0.8041 -- iter: 784/784
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8709333333333333
Validation AUPRC:0.8930141317644983
Test AUC:0.8985565356856456
Test AUPRC:0.9204180771756554
BestTestF1Score	0.84	0.67	0.83	0.86	0.81	105	17	99	24	0.36
BestTestMCCScore	0.84	0.71	0.84	0.93	0.76	98	7	109	31	0.63
BestTestAccuracyScore	0.84	0.67	0.83	0.86	0.81	105	17	99	24	0.36
BestValidationF1Score	0.82	0.64	0.82	0.84	0.8	100	19	101	25	0.36
BestValidationMCC	0.8	0.65	0.82	0.89	0.73	91	11	109	34	0.63
BestValidationAccuracy	0.82	0.64	0.82	0.84	0.8	100	19	101	25	0.36
TestPredictions (Threshold:0.63)
CHEMBL3640630,TP,ACT,0.9900000095367432	CHEMBL558460,TN,INACT,0.12999999523162842	CHEMBL457047,TN,INACT,0.3199999928474426	CHEMBL201630,TP,ACT,0.9800000190734863	CHEMBL1688219,TN,INACT,0.07000000029802322	CHEMBL520025,TP,ACT,0.9300000071525574	CHEMBL100670,TN,INACT,0.11999999731779099	CHEMBL1287853,TP,ACT,0.6800000071525574	CHEMBL3746467,TP,ACT,0.9900000095367432	CHEMBL30359,TP,ACT,0.8600000143051147	CHEMBL486285,TN,INACT,0.05999999865889549	CHEMBL232542,FP,INACT,0.8700000047683716	CHEMBL266540,TN,INACT,0.2199999988079071	CHEMBL3261163,TP,ACT,0.949999988079071	CHEMBL213562,TP,ACT,0.699999988079071	CHEMBL95002,TP,ACT,0.9599999785423279	CHEMBL457180,TN,INACT,0.05000000074505806	CHEMBL214816,TP,ACT,0.9700000286102295	CHEMBL383098,FN,ACT,0.18000000715255737	CHEMBL37911,TP,ACT,0.8700000047683716	CHEMBL603494,TN,INACT,0.2199999988079071	CHEMBL557237,TN,INACT,0.23000000417232513	CHEMBL1829271,TN,INACT,0.03999999910593033	CHEMBL3402994,TP,ACT,0.9399999976158142	CHEMBL2012899,FN,ACT,0.12999999523162842	CHEMBL1767126,TN,INACT,0.05999999865889549	CHEMBL1270331,TN,INACT,0.07999999821186066	CHEMBL469776,TN,INACT,0.14000000059604645	CHEMBL288349,TP,ACT,0.8199999928474426	CHEMBL99779,TN,INACT,0.11999999731779099	CHEMBL417693,TP,ACT,0.9300000071525574	CHEMBL413636,TP,ACT,0.8899999856948853	CHEMBL490423,FN,ACT,0.029999999329447746	CHEMBL2146893,TP,ACT,0.9100000262260437	CHEMBL217414,TP,ACT,0.9599999785423279	CHEMBL2376672,TP,ACT,0.9800000190734863	CHEMBL3261153,TP,ACT,0.9399999976158142	CHEMBL197603,TN,INACT,0.10999999940395355	CHEMBL169757,TN,INACT,0.07999999821186066	CHEMBL463384,TN,INACT,0.03999999910593033	CHEMBL1908397,FN,ACT,0.12999999523162842	CHEMBL74799,TN,INACT,0.5400000214576721	CHEMBL89505,TN,INACT,0.28999999165534973	CHEMBL286371,FN,ACT,0.14000000059604645	CHEMBL37548,TP,ACT,0.9599999785423279	CHEMBL100312,FP,INACT,0.6800000071525574	CHEMBL36307,TP,ACT,0.9700000286102295	CHEMBL2146891,FN,ACT,0.6100000143051147	CHEMBL269528,TN,INACT,0.07999999821186066	CHEMBL38195,TP,ACT,0.9800000190734863	CHEMBL3640625,TP,ACT,0.9900000095367432	CHEMBL98131,TP,ACT,0.9700000286102295	CHEMBL209868,TP,ACT,0.7200000286102295	CHEMBL485238,FN,ACT,0.46000000834465027	CHEMBL209520,TP,ACT,0.8600000143051147	CHEMBL485285,FN,ACT,0.11999999731779099	CHEMBL1331627,TN,INACT,0.05000000074505806	CHEMBL1169814,TP,ACT,0.9900000095367432	CHEMBL180022,TP,ACT,0.6800000071525574	CHEMBL1230020,TP,ACT,0.9399999976158142	CHEMBL1242468,TN,INACT,0.4300000071525574	CHEMBL3640634,TP,ACT,0.9800000190734863	CHEMBL100811,TN,INACT,0.05999999865889549	CHEMBL40583,TN,INACT,0.10000000149011612	CHEMBL373834,TN,INACT,0.3400000035762787	CHEMBL284708,TP,ACT,0.9800000190734863	CHEMBL2392227,TN,INACT,0.05000000074505806	CHEMBL491434,FN,ACT,0.11999999731779099	CHEMBL377288,TP,ACT,0.9800000190734863	CHEMBL3133826,FP,INACT,0.9200000166893005	CHEMBL424897,TP,ACT,0.6899999976158142	CHEMBL37504,TP,ACT,0.9700000286102295	CHEMBL2031893,TN,INACT,0.07000000029802322	CHEMBL150,TN,INACT,0.1899999976158142	CHEMBL212474,TP,ACT,0.7799999713897705	CHEMBL3421980,TN,INACT,0.12999999523162842	CHEMBL77155,TN,INACT,0.47999998927116394	CHEMBL172973,TN,INACT,0.10999999940395355	CHEMBL37493,TP,ACT,0.9900000095367432	CHEMBL450775,TP,ACT,0.9200000166893005	CHEMBL201203,TP,ACT,0.9100000262260437	CHEMBL176815,TN,INACT,0.6200000047683716	CHEMBL3092196,TP,ACT,0.8799999952316284	CHEMBL2029525,TN,INACT,0.12999999523162842	CHEMBL1087650,TN,INACT,0.3799999952316284	CHEMBL559882,TN,INACT,0.05000000074505806	CHEMBL244488,TP,ACT,0.9900000095367432	CHEMBL56731,TN,INACT,0.09000000357627869	CHEMBL3699139,TP,ACT,0.8899999856948853	CHEMBL97463,TP,ACT,0.9800000190734863	CHEMBL490053,TN,INACT,0.029999999329447746	CHEMBL2391615,TN,INACT,0.07000000029802322	CHEMBL30597,FN,ACT,0.5799999833106995	CHEMBL535,TP,ACT,0.7200000286102295	CHEMBL430845,TN,INACT,0.5899999737739563	CHEMBL202128,TP,ACT,0.8799999952316284	CHEMBL151,TN,INACT,0.05999999865889549	CHEMBL3609569,TN,INACT,0.03999999910593033	CHEMBL285905,FN,ACT,0.4099999964237213	CHEMBL522579,TN,INACT,0.3400000035762787	CHEMBL216646,TN,INACT,0.30000001192092896	CHEMBL113996,TN,INACT,0.11999999731779099	CHEMBL113985,TN,INACT,0.23000000417232513	CHEMBL2087079,TP,ACT,0.9300000071525574	CHEMBL3644805,TP,ACT,0.9399999976158142	CHEMBL1172878,TN,INACT,0.10000000149011612	CHEMBL2376679,TP,ACT,0.8999999761581421	CHEMBL2333445,FN,ACT,0.05000000074505806	CHEMBL3261161,TP,ACT,0.9100000262260437	CHEMBL453336,FP,INACT,0.9800000190734863	CHEMBL426840,TP,ACT,0.9700000286102295	CHEMBL557050,TN,INACT,0.019999999552965164	CHEMBL91748,TN,INACT,0.33000001311302185	CHEMBL1684062,TP,ACT,0.9700000286102295	CHEMBL101052,TN,INACT,0.33000001311302185	CHEMBL1929238,TN,INACT,0.09000000357627869	CHEMBL3092186,TP,ACT,0.8899999856948853	CHEMBL240093,TN,INACT,0.03999999910593033	CHEMBL1910755,TN,INACT,0.07999999821186066	CHEMBL203257,TP,ACT,0.7200000286102295	CHEMBL456143,TN,INACT,0.03999999910593033	CHEMBL1910761,TN,INACT,0.10999999940395355	CHEMBL1652453,TN,INACT,0.07000000029802322	CHEMBL1615025,TP,ACT,0.9700000286102295	CHEMBL1910278,FP,INACT,0.8700000047683716	CHEMBL490241,TN,INACT,0.029999999329447746	CHEMBL2376676,TP,ACT,0.9599999785423279	CHEMBL2376675,FN,ACT,0.6200000047683716	CHEMBL3746569,TP,ACT,0.9900000095367432	CHEMBL1767294,TN,INACT,0.07999999821186066	CHEMBL335966,TN,INACT,0.18000000715255737	CHEMBL1171955,TN,INACT,0.05000000074505806	CHEMBL211359,TP,ACT,0.8999999761581421	CHEMBL2029520,TN,INACT,0.07999999821186066	CHEMBL563948,TN,INACT,0.029999999329447746	CHEMBL3640638,TP,ACT,0.9800000190734863	CHEMBL2163610,TN,INACT,0.3700000047683716	CHEMBL3342105,TN,INACT,0.1599999964237213	CHEMBL2392246,TN,INACT,0.029999999329447746	CHEMBL489661,TP,ACT,0.8199999928474426	CHEMBL498249,FP,INACT,0.7400000095367432	CHEMBL1331525,TN,INACT,0.07000000029802322	CHEMBL214032,TP,ACT,0.9700000286102295	CHEMBL2163608,TN,INACT,0.07000000029802322	CHEMBL2087077,FN,ACT,0.18000000715255737	CHEMBL3746142,TP,ACT,0.9800000190734863	CHEMBL287852,TP,ACT,0.9399999976158142	CHEMBL31733,TP,ACT,0.8199999928474426	CHEMBL322395,TP,ACT,0.8899999856948853	CHEMBL90277,TN,INACT,0.36000001430511475	CHEMBL2391621,TN,INACT,0.4300000071525574	CHEMBL33906,FN,ACT,0.05999999865889549	CHEMBL3086065,TP,ACT,0.8999999761581421	CHEMBL2146887,FN,ACT,0.09000000357627869	CHEMBL386469,TP,ACT,0.9800000190734863	CHEMBL201389,TP,ACT,0.9900000095367432	CHEMBL213651,FN,ACT,0.17000000178813934	CHEMBL602472,TN,INACT,0.1899999976158142	CHEMBL15887,TN,INACT,0.2199999988079071	CHEMBL94965,FN,ACT,0.27000001072883606	CHEMBL551318,TN,INACT,0.07000000029802322	CHEMBL530335,TN,INACT,0.20999999344348907	CHEMBL3746516,TP,ACT,0.9800000190734863	CHEMBL336330,TN,INACT,0.11999999731779099	CHEMBL1910757,TN,INACT,0.07000000029802322	CHEMBL2042136,FP,INACT,0.8799999952316284	CHEMBL1922121,TN,INACT,0.07000000029802322	CHEMBL2376669,FN,ACT,0.23999999463558197	CHEMBL502835,TP,ACT,0.8500000238418579	CHEMBL491435,FN,ACT,0.05999999865889549	CHEMBL1684063,TP,ACT,0.9700000286102295	CHEMBL1789941,FN,ACT,0.05000000074505806	CHEMBL271138,TN,INACT,0.10000000149011612	CHEMBL589259,TN,INACT,0.6100000143051147	CHEMBL1684067,TP,ACT,0.9599999785423279	CHEMBL289134,TP,ACT,0.699999988079071	CHEMBL217117,FN,ACT,0.38999998569488525	CHEMBL209148,TN,INACT,0.3499999940395355	CHEMBL385820,FN,ACT,0.25	CHEMBL30728,TP,ACT,0.9599999785423279	CHEMBL2376667,TP,ACT,0.9900000095367432	CHEMBL209502,FN,ACT,0.2199999988079071	CHEMBL2381116,TN,INACT,0.03999999910593033	CHEMBL202545,TP,ACT,0.9599999785423279	CHEMBL458076,TN,INACT,0.07000000029802322	CHEMBL97205,TP,ACT,0.9300000071525574	CHEMBL1612732,TN,INACT,0.10000000149011612	CHEMBL1908396,FN,ACT,0.14000000059604645	CHEMBL486302,TN,INACT,0.18000000715255737	CHEMBL1734241,TN,INACT,0.029999999329447746	CHEMBL489627,TN,INACT,0.009999999776482582	CHEMBL317281,TN,INACT,0.07000000029802322	CHEMBL356164,FN,ACT,0.25999999046325684	CHEMBL3747637,TP,ACT,0.9900000095367432	CHEMBL428647,TN,INACT,0.029999999329447746	CHEMBL3665666,TN,INACT,0.05000000074505806	CHEMBL3644818,TP,ACT,0.9700000286102295	CHEMBL3680461,TN,INACT,0.11999999731779099	CHEMBL104264,TN,INACT,0.029999999329447746	CHEMBL396487,TN,INACT,0.3400000035762787	CHEMBL2057830,FN,ACT,0.029999999329447746	CHEMBL1828883,TN,INACT,0.03999999910593033	CHEMBL285527,TN,INACT,0.11999999731779099	CHEMBL226471,TN,INACT,0.019999999552965164	CHEMBL385059,TP,ACT,0.9900000095367432	CHEMBL2376660,TP,ACT,0.8899999856948853	CHEMBL1767292,TN,INACT,0.05999999865889549	CHEMBL491635,FN,ACT,0.07999999821186066	CHEMBL1172947,TN,INACT,0.10000000149011612	CHEMBL217416,TP,ACT,0.9900000095367432	CHEMBL101558,TN,INACT,0.05999999865889549	CHEMBL3092177,TP,ACT,0.9300000071525574	CHEMBL2164716,TN,INACT,0.12999999523162842	CHEMBL35579,FN,ACT,0.3400000035762787	CHEMBL367442,TN,INACT,0.07999999821186066	CHEMBL2012906,TP,ACT,0.7200000286102295	CHEMBL102047,TN,INACT,0.2800000011920929	CHEMBL482919,TN,INACT,0.029999999329447746	CHEMBL30516,TP,ACT,0.949999988079071	CHEMBL201819,TP,ACT,0.9800000190734863	CHEMBL1688212,TN,INACT,0.3100000023841858	CHEMBL329698,TP,ACT,0.9900000095367432	CHEMBL211201,TP,ACT,0.949999988079071	CHEMBL3640632,TP,ACT,0.9800000190734863	CHEMBL284760,TP,ACT,0.8299999833106995	CHEMBL203258,FN,ACT,0.4699999988079071	CHEMBL460472,TN,INACT,0.05000000074505806	CHEMBL31143,TP,ACT,0.9300000071525574	CHEMBL265999,FN,ACT,0.2800000011920929	CHEMBL457191,TN,INACT,0.029999999329447746	CHEMBL281662,TP,ACT,0.949999988079071	CHEMBL2146888,TP,ACT,0.8399999737739563	CHEMBL3092182,TP,ACT,0.75	CHEMBL2375372,TP,ACT,0.9800000190734863	CHEMBL2177670,TN,INACT,0.1899999976158142	CHEMBL3665656,TN,INACT,0.1899999976158142	CHEMBL318485,TN,INACT,0.05999999865889549	CHEMBL2012897,TP,ACT,0.949999988079071	CHEMBL372600,TP,ACT,0.9800000190734863	CHEMBL590877,TN,INACT,0.05999999865889549	CHEMBL2348175,TN,INACT,0.029999999329447746	CHEMBL560393,TN,INACT,0.019999999552965164	CHEMBL317720,TP,ACT,0.9700000286102295	CHEMBL31497,TP,ACT,0.949999988079071	CHEMBL2012903,TP,ACT,0.8899999856948853	

