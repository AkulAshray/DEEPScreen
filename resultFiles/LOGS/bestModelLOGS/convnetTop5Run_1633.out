CNNModel CHEMBL3764 adam 0.001 15 256 0 0.8 False True
Number of active compounds :	392
Number of inactive compounds :	392
---------------------------------
Run id: CNNModel_CHEMBL3764_adam_0.001_15_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3764_adam_0.001_15_256_0.8_True/
---------------------------------
Training samples: 500
Validation samples: 157
--
Training Step: 1  | time: 1.354s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/500
[A[ATraining Step: 2  | total loss: [1m[32m0.62438[0m[0m | time: 2.442s
[2K
| Adam | epoch: 001 | loss: 0.62438 - acc: 0.3094 -- iter: 064/500
[A[ATraining Step: 3  | total loss: [1m[32m0.67995[0m[0m | time: 3.552s
[2K
| Adam | epoch: 001 | loss: 0.67995 - acc: 0.4909 -- iter: 096/500
[A[ATraining Step: 4  | total loss: [1m[32m0.68860[0m[0m | time: 4.464s
[2K
| Adam | epoch: 001 | loss: 0.68860 - acc: 0.5212 -- iter: 128/500
[A[ATraining Step: 5  | total loss: [1m[32m0.68972[0m[0m | time: 5.544s
[2K
| Adam | epoch: 001 | loss: 0.68972 - acc: 0.5281 -- iter: 160/500
[A[ATraining Step: 6  | total loss: [1m[32m0.69465[0m[0m | time: 6.591s
[2K
| Adam | epoch: 001 | loss: 0.69465 - acc: 0.5101 -- iter: 192/500
[A[ATraining Step: 7  | total loss: [1m[32m0.70025[0m[0m | time: 7.635s
[2K
| Adam | epoch: 001 | loss: 0.70025 - acc: 0.4478 -- iter: 224/500
[A[ATraining Step: 8  | total loss: [1m[32m0.69717[0m[0m | time: 8.738s
[2K
| Adam | epoch: 001 | loss: 0.69717 - acc: 0.4596 -- iter: 256/500
[A[ATraining Step: 9  | total loss: [1m[32m0.69549[0m[0m | time: 9.785s
[2K
| Adam | epoch: 001 | loss: 0.69549 - acc: 0.4644 -- iter: 288/500
[A[ATraining Step: 10  | total loss: [1m[32m0.69642[0m[0m | time: 10.902s
[2K
| Adam | epoch: 001 | loss: 0.69642 - acc: 0.3416 -- iter: 320/500
[A[ATraining Step: 11  | total loss: [1m[32m0.69451[0m[0m | time: 12.293s
[2K
| Adam | epoch: 001 | loss: 0.69451 - acc: 0.4758 -- iter: 352/500
[A[ATraining Step: 12  | total loss: [1m[32m0.69403[0m[0m | time: 13.236s
[2K
| Adam | epoch: 001 | loss: 0.69403 - acc: 0.4586 -- iter: 384/500
[A[ATraining Step: 13  | total loss: [1m[32m0.69358[0m[0m | time: 14.331s
[2K
| Adam | epoch: 001 | loss: 0.69358 - acc: 0.5031 -- iter: 416/500
[A[ATraining Step: 14  | total loss: [1m[32m0.69340[0m[0m | time: 15.341s
[2K
| Adam | epoch: 001 | loss: 0.69340 - acc: 0.5018 -- iter: 448/500
[A[ATraining Step: 15  | total loss: [1m[32m0.69348[0m[0m | time: 16.367s
[2K
| Adam | epoch: 001 | loss: 0.69348 - acc: 0.4767 -- iter: 480/500
[A[ATraining Step: 16  | total loss: [1m[32m0.69302[0m[0m | time: 18.239s
[2K
| Adam | epoch: 001 | loss: 0.69302 - acc: 0.5323 | val_loss: 0.69399 - val_acc: 0.4459 -- iter: 500/500
--
Training Step: 17  | total loss: [1m[32m0.69306[0m[0m | time: 0.650s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5207 -- iter: 032/500
[A[ATraining Step: 18  | total loss: [1m[32m0.69310[0m[0m | time: 1.593s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5135 -- iter: 064/500
[A[ATraining Step: 19  | total loss: [1m[32m0.69306[0m[0m | time: 2.619s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5090 -- iter: 096/500
[A[ATraining Step: 20  | total loss: [1m[32m0.69292[0m[0m | time: 3.723s
[2K
| Adam | epoch: 002 | loss: 0.69292 - acc: 0.5162 -- iter: 128/500
[A[ATraining Step: 21  | total loss: [1m[32m0.69346[0m[0m | time: 5.004s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.4917 -- iter: 160/500
[A[ATraining Step: 22  | total loss: [1m[32m0.69255[0m[0m | time: 14.037s
[2K
| Adam | epoch: 002 | loss: 0.69255 - acc: 0.5317 -- iter: 192/500
[A[ATraining Step: 23  | total loss: [1m[32m0.69223[0m[0m | time: 23.295s
[2K
| Adam | epoch: 002 | loss: 0.69223 - acc: 0.5407 -- iter: 224/500
[A[ATraining Step: 24  | total loss: [1m[32m0.69223[0m[0m | time: 24.563s
[2K
| Adam | epoch: 002 | loss: 0.69223 - acc: 0.5380 -- iter: 256/500
[A[ATraining Step: 25  | total loss: [1m[32m0.69157[0m[0m | time: 25.585s
[2K
| Adam | epoch: 002 | loss: 0.69157 - acc: 0.5532 -- iter: 288/500
[A[ATraining Step: 26  | total loss: [1m[32m0.69327[0m[0m | time: 26.599s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.5143 -- iter: 320/500
[A[ATraining Step: 27  | total loss: [1m[32m0.69414[0m[0m | time: 27.482s
[2K
| Adam | epoch: 002 | loss: 0.69414 - acc: 0.4946 -- iter: 352/500
[A[ATraining Step: 28  | total loss: [1m[32m0.69315[0m[0m | time: 28.636s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5115 -- iter: 384/500
[A[ATraining Step: 29  | total loss: [1m[32m0.69350[0m[0m | time: 29.691s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.5011 -- iter: 416/500
[A[ATraining Step: 30  | total loss: [1m[32m0.69219[0m[0m | time: 30.881s
[2K
| Adam | epoch: 002 | loss: 0.69219 - acc: 0.5305 -- iter: 448/500
[A[ATraining Step: 31  | total loss: [1m[32m0.69185[0m[0m | time: 32.157s
[2K
| Adam | epoch: 002 | loss: 0.69185 - acc: 0.5379 -- iter: 480/500
[A[ATraining Step: 32  | total loss: [1m[32m0.69292[0m[0m | time: 34.294s
[2K
| Adam | epoch: 002 | loss: 0.69292 - acc: 0.5153 | val_loss: 0.69637 - val_acc: 0.4459 -- iter: 500/500
--
Training Step: 33  | total loss: [1m[32m0.69228[0m[0m | time: 0.703s
[2K
| Adam | epoch: 003 | loss: 0.69228 - acc: 0.5256 -- iter: 032/500
[A[ATraining Step: 34  | total loss: [1m[32m0.69543[0m[0m | time: 1.532s
[2K
| Adam | epoch: 003 | loss: 0.69543 - acc: 0.4666 -- iter: 064/500
[A[ATraining Step: 35  | total loss: [1m[32m0.69754[0m[0m | time: 2.791s
[2K
| Adam | epoch: 003 | loss: 0.69754 - acc: 0.4212 -- iter: 096/500
[A[ATraining Step: 36  | total loss: [1m[32m0.69709[0m[0m | time: 3.820s
[2K
| Adam | epoch: 003 | loss: 0.69709 - acc: 0.4246 -- iter: 128/500
[A[ATraining Step: 37  | total loss: [1m[32m0.69553[0m[0m | time: 4.919s
[2K
| Adam | epoch: 003 | loss: 0.69553 - acc: 0.4647 -- iter: 160/500
[A[ATraining Step: 38  | total loss: [1m[32m0.69489[0m[0m | time: 5.986s
[2K
| Adam | epoch: 003 | loss: 0.69489 - acc: 0.4777 -- iter: 192/500
[A[ATraining Step: 39  | total loss: [1m[32m0.69467[0m[0m | time: 6.884s
[2K
| Adam | epoch: 003 | loss: 0.69467 - acc: 0.4760 -- iter: 224/500
[A[ATraining Step: 40  | total loss: [1m[32m0.69418[0m[0m | time: 7.549s
[2K
| Adam | epoch: 003 | loss: 0.69418 - acc: 0.4922 -- iter: 256/500
[A[ATraining Step: 41  | total loss: [1m[32m0.69443[0m[0m | time: 8.415s
[2K
| Adam | epoch: 003 | loss: 0.69443 - acc: 0.4707 -- iter: 288/500
[A[ATraining Step: 42  | total loss: [1m[32m0.69411[0m[0m | time: 9.249s
[2K
| Adam | epoch: 003 | loss: 0.69411 - acc: 0.4816 -- iter: 320/500
[A[ATraining Step: 43  | total loss: [1m[32m0.69393[0m[0m | time: 10.093s
[2K
| Adam | epoch: 003 | loss: 0.69393 - acc: 0.4848 -- iter: 352/500
[A[ATraining Step: 44  | total loss: [1m[32m0.69351[0m[0m | time: 11.091s
[2K
| Adam | epoch: 003 | loss: 0.69351 - acc: 0.5091 -- iter: 384/500
[A[ATraining Step: 45  | total loss: [1m[32m0.69324[0m[0m | time: 11.963s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.5235 -- iter: 416/500
[A[ATraining Step: 46  | total loss: [1m[32m0.69332[0m[0m | time: 12.819s
[2K
| Adam | epoch: 003 | loss: 0.69332 - acc: 0.5091 -- iter: 448/500
[A[ATraining Step: 47  | total loss: [1m[32m0.69339[0m[0m | time: 13.719s
[2K
| Adam | epoch: 003 | loss: 0.69339 - acc: 0.4974 -- iter: 480/500
[A[ATraining Step: 48  | total loss: [1m[32m0.69327[0m[0m | time: 15.582s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.5029 | val_loss: 0.69336 - val_acc: 0.4459 -- iter: 500/500
--
Training Step: 49  | total loss: [1m[32m0.69318[0m[0m | time: 0.988s
[2K
| Adam | epoch: 004 | loss: 0.69318 - acc: 0.5024 -- iter: 032/500
[A[ATraining Step: 50  | total loss: [1m[32m0.69308[0m[0m | time: 1.637s
[2K
| Adam | epoch: 004 | loss: 0.69308 - acc: 0.5069 -- iter: 064/500
[A[ATraining Step: 51  | total loss: [1m[32m0.69302[0m[0m | time: 2.080s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5058 -- iter: 096/500
[A[ATraining Step: 52  | total loss: [1m[32m0.69289[0m[0m | time: 2.842s
[2K
| Adam | epoch: 004 | loss: 0.69289 - acc: 0.5125 -- iter: 128/500
[A[ATraining Step: 53  | total loss: [1m[32m0.69290[0m[0m | time: 3.738s
[2K
| Adam | epoch: 004 | loss: 0.69290 - acc: 0.5106 -- iter: 160/500
[A[ATraining Step: 54  | total loss: [1m[32m0.69281[0m[0m | time: 4.632s
[2K
| Adam | epoch: 004 | loss: 0.69281 - acc: 0.5318 -- iter: 192/500
[A[ATraining Step: 55  | total loss: [1m[32m0.69250[0m[0m | time: 5.554s
[2K
| Adam | epoch: 004 | loss: 0.69250 - acc: 0.5540 -- iter: 224/500
[A[ATraining Step: 56  | total loss: [1m[32m0.69254[0m[0m | time: 6.404s
[2K
| Adam | epoch: 004 | loss: 0.69254 - acc: 0.5464 -- iter: 256/500
[A[ATraining Step: 57  | total loss: [1m[32m0.69244[0m[0m | time: 7.248s
[2K
| Adam | epoch: 004 | loss: 0.69244 - acc: 0.5486 -- iter: 288/500
[A[ATraining Step: 58  | total loss: [1m[32m0.69266[0m[0m | time: 8.089s
[2K
| Adam | epoch: 004 | loss: 0.69266 - acc: 0.5377 -- iter: 320/500
[A[ATraining Step: 59  | total loss: [1m[32m0.69243[0m[0m | time: 8.962s
[2K
| Adam | epoch: 004 | loss: 0.69243 - acc: 0.5411 -- iter: 352/500
[A[ATraining Step: 60  | total loss: [1m[32m0.69272[0m[0m | time: 9.785s
[2K
| Adam | epoch: 004 | loss: 0.69272 - acc: 0.5274 -- iter: 384/500
[A[ATraining Step: 61  | total loss: [1m[32m0.69294[0m[0m | time: 10.777s
[2K
| Adam | epoch: 004 | loss: 0.69294 - acc: 0.5156 -- iter: 416/500
[A[ATraining Step: 62  | total loss: [1m[32m0.69206[0m[0m | time: 11.776s
[2K
| Adam | epoch: 004 | loss: 0.69206 - acc: 0.5498 -- iter: 448/500
[A[ATraining Step: 63  | total loss: [1m[32m0.69210[0m[0m | time: 13.019s
[2K
| Adam | epoch: 004 | loss: 0.69210 - acc: 0.5514 -- iter: 480/500
[A[ATraining Step: 64  | total loss: [1m[32m0.69172[0m[0m | time: 18.636s
[2K
| Adam | epoch: 004 | loss: 0.69172 - acc: 0.5684 | val_loss: 0.68356 - val_acc: 0.5541 -- iter: 500/500
--
Training Step: 65  | total loss: [1m[32m0.69110[0m[0m | time: 1.099s
[2K
| Adam | epoch: 005 | loss: 0.69110 - acc: 0.5754 -- iter: 032/500
[A[ATraining Step: 66  | total loss: [1m[32m0.68990[0m[0m | time: 2.139s
[2K
| Adam | epoch: 005 | loss: 0.68990 - acc: 0.5662 -- iter: 064/500
[A[ATraining Step: 67  | total loss: [1m[32m0.68881[0m[0m | time: 2.802s
[2K
| Adam | epoch: 005 | loss: 0.68881 - acc: 0.5620 -- iter: 096/500
[A[ATraining Step: 68  | total loss: [1m[32m0.68868[0m[0m | time: 3.546s
[2K
| Adam | epoch: 005 | loss: 0.68868 - acc: 0.5488 -- iter: 128/500
[A[ATraining Step: 69  | total loss: [1m[32m0.68665[0m[0m | time: 4.698s
[2K
| Adam | epoch: 005 | loss: 0.68665 - acc: 0.5372 -- iter: 160/500
[A[ATraining Step: 70  | total loss: [1m[32m0.68251[0m[0m | time: 5.827s
[2K
| Adam | epoch: 005 | loss: 0.68251 - acc: 0.5582 -- iter: 192/500
[A[ATraining Step: 71  | total loss: [1m[32m0.67666[0m[0m | time: 6.933s
[2K
| Adam | epoch: 005 | loss: 0.67666 - acc: 0.5729 -- iter: 224/500
[A[ATraining Step: 72  | total loss: [1m[32m0.67962[0m[0m | time: 8.056s
[2K
| Adam | epoch: 005 | loss: 0.67962 - acc: 0.5717 -- iter: 256/500
[A[ATraining Step: 73  | total loss: [1m[32m0.67588[0m[0m | time: 9.307s
[2K
| Adam | epoch: 005 | loss: 0.67588 - acc: 0.5811 -- iter: 288/500
[A[ATraining Step: 74  | total loss: [1m[32m0.67328[0m[0m | time: 10.541s
[2K
| Adam | epoch: 005 | loss: 0.67328 - acc: 0.5825 -- iter: 320/500
[A[ATraining Step: 75  | total loss: [1m[32m0.67180[0m[0m | time: 11.572s
[2K
| Adam | epoch: 005 | loss: 0.67180 - acc: 0.5837 -- iter: 352/500
[A[ATraining Step: 76  | total loss: [1m[32m0.66494[0m[0m | time: 13.215s
[2K
| Adam | epoch: 005 | loss: 0.66494 - acc: 0.5915 -- iter: 384/500
[A[ATraining Step: 77  | total loss: [1m[32m0.67542[0m[0m | time: 15.275s
[2K
| Adam | epoch: 005 | loss: 0.67542 - acc: 0.5851 -- iter: 416/500
[A[ATraining Step: 78  | total loss: [1m[32m0.67191[0m[0m | time: 16.118s
[2K
| Adam | epoch: 005 | loss: 0.67191 - acc: 0.5827 -- iter: 448/500
[A[ATraining Step: 79  | total loss: [1m[32m0.66971[0m[0m | time: 17.100s
[2K
| Adam | epoch: 005 | loss: 0.66971 - acc: 0.5936 -- iter: 480/500
[A[ATraining Step: 80  | total loss: [1m[32m0.66893[0m[0m | time: 19.226s
[2K
| Adam | epoch: 005 | loss: 0.66893 - acc: 0.5936 | val_loss: 0.63159 - val_acc: 0.6306 -- iter: 500/500
--
Training Step: 81  | total loss: [1m[32m0.66019[0m[0m | time: 1.056s
[2K
| Adam | epoch: 006 | loss: 0.66019 - acc: 0.6126 -- iter: 032/500
[A[ATraining Step: 82  | total loss: [1m[32m0.66246[0m[0m | time: 2.145s
[2K
| Adam | epoch: 006 | loss: 0.66246 - acc: 0.6044 -- iter: 064/500
[A[ATraining Step: 83  | total loss: [1m[32m0.66227[0m[0m | time: 3.174s
[2K
| Adam | epoch: 006 | loss: 0.66227 - acc: 0.6096 -- iter: 096/500
[A[ATraining Step: 84  | total loss: [1m[32m0.63907[0m[0m | time: 3.828s
[2K
| Adam | epoch: 006 | loss: 0.63907 - acc: 0.6393 -- iter: 128/500
[A[ATraining Step: 85  | total loss: [1m[32m0.64587[0m[0m | time: 4.651s
[2K
| Adam | epoch: 006 | loss: 0.64587 - acc: 0.6454 -- iter: 160/500
[A[ATraining Step: 86  | total loss: [1m[32m0.64817[0m[0m | time: 5.921s
[2K
| Adam | epoch: 006 | loss: 0.64817 - acc: 0.6508 -- iter: 192/500
[A[ATraining Step: 87  | total loss: [1m[32m0.64325[0m[0m | time: 7.057s
[2K
| Adam | epoch: 006 | loss: 0.64325 - acc: 0.6514 -- iter: 224/500
[A[ATraining Step: 88  | total loss: [1m[32m0.64274[0m[0m | time: 8.089s
[2K
| Adam | epoch: 006 | loss: 0.64274 - acc: 0.6519 -- iter: 256/500
[A[ATraining Step: 89  | total loss: [1m[32m0.63490[0m[0m | time: 9.244s
[2K
| Adam | epoch: 006 | loss: 0.63490 - acc: 0.6617 -- iter: 288/500
[A[ATraining Step: 90  | total loss: [1m[32m0.62098[0m[0m | time: 10.352s
[2K
| Adam | epoch: 006 | loss: 0.62098 - acc: 0.6768 -- iter: 320/500
[A[ATraining Step: 91  | total loss: [1m[32m0.61302[0m[0m | time: 11.227s
[2K
| Adam | epoch: 006 | loss: 0.61302 - acc: 0.6903 -- iter: 352/500
[A[ATraining Step: 92  | total loss: [1m[32m0.59389[0m[0m | time: 12.232s
[2K
| Adam | epoch: 006 | loss: 0.59389 - acc: 0.7057 -- iter: 384/500
[A[ATraining Step: 93  | total loss: [1m[32m0.59697[0m[0m | time: 13.249s
[2K
| Adam | epoch: 006 | loss: 0.59697 - acc: 0.7039 -- iter: 416/500
[A[ATraining Step: 94  | total loss: [1m[32m0.60115[0m[0m | time: 14.375s
[2K
| Adam | epoch: 006 | loss: 0.60115 - acc: 0.7022 -- iter: 448/500
[A[ATraining Step: 95  | total loss: [1m[32m0.59298[0m[0m | time: 15.418s
[2K
| Adam | epoch: 006 | loss: 0.59298 - acc: 0.7101 -- iter: 480/500
[A[ATraining Step: 96  | total loss: [1m[32m0.58754[0m[0m | time: 17.589s
[2K
| Adam | epoch: 006 | loss: 0.58754 - acc: 0.7110 | val_loss: 0.61359 - val_acc: 0.6752 -- iter: 500/500
--
Training Step: 97  | total loss: [1m[32m0.58976[0m[0m | time: 1.150s
[2K
| Adam | epoch: 007 | loss: 0.58976 - acc: 0.7118 -- iter: 032/500
[A[ATraining Step: 98  | total loss: [1m[32m0.59415[0m[0m | time: 2.438s
[2K
| Adam | epoch: 007 | loss: 0.59415 - acc: 0.7062 -- iter: 064/500
[A[ATraining Step: 99  | total loss: [1m[32m0.60594[0m[0m | time: 3.611s
[2K
| Adam | epoch: 007 | loss: 0.60594 - acc: 0.6950 -- iter: 096/500
[A[ATraining Step: 100  | total loss: [1m[32m0.61913[0m[0m | time: 4.830s
[2K
| Adam | epoch: 007 | loss: 0.61913 - acc: 0.6848 -- iter: 128/500
[A[ATraining Step: 101  | total loss: [1m[32m0.61360[0m[0m | time: 10.692s
[2K
| Adam | epoch: 007 | loss: 0.61360 - acc: 0.6914 -- iter: 160/500
[A[ATraining Step: 102  | total loss: [1m[32m0.61428[0m[0m | time: 17.593s
[2K
| Adam | epoch: 007 | loss: 0.61428 - acc: 0.6872 -- iter: 192/500
[A[ATraining Step: 103  | total loss: [1m[32m0.61548[0m[0m | time: 35.225s
[2K
| Adam | epoch: 007 | loss: 0.61548 - acc: 0.6835 -- iter: 224/500
[A[ATraining Step: 104  | total loss: [1m[32m0.62976[0m[0m | time: 41.764s
[2K
| Adam | epoch: 007 | loss: 0.62976 - acc: 0.6620 -- iter: 256/500
[A[ATraining Step: 105  | total loss: [1m[32m0.63119[0m[0m | time: 42.877s
[2K
| Adam | epoch: 007 | loss: 0.63119 - acc: 0.6583 -- iter: 288/500
[A[ATraining Step: 106  | total loss: [1m[32m0.62791[0m[0m | time: 43.935s
[2K
| Adam | epoch: 007 | loss: 0.62791 - acc: 0.6706 -- iter: 320/500
[A[ATraining Step: 107  | total loss: [1m[32m0.62904[0m[0m | time: 44.923s
[2K
| Adam | epoch: 007 | loss: 0.62904 - acc: 0.6723 -- iter: 352/500
[A[ATraining Step: 108  | total loss: [1m[32m0.62707[0m[0m | time: 45.971s
[2K
| Adam | epoch: 007 | loss: 0.62707 - acc: 0.6769 -- iter: 384/500
[A[ATraining Step: 109  | total loss: [1m[32m0.62687[0m[0m | time: 47.155s
[2K
| Adam | epoch: 007 | loss: 0.62687 - acc: 0.6874 -- iter: 416/500
[A[ATraining Step: 110  | total loss: [1m[32m0.62381[0m[0m | time: 48.187s
[2K
| Adam | epoch: 007 | loss: 0.62381 - acc: 0.6874 -- iter: 448/500
[A[ATraining Step: 111  | total loss: [1m[32m0.61799[0m[0m | time: 49.229s
[2K
| Adam | epoch: 007 | loss: 0.61799 - acc: 0.6937 -- iter: 480/500
[A[ATraining Step: 112  | total loss: [1m[32m0.60970[0m[0m | time: 51.400s
[2K
| Adam | epoch: 007 | loss: 0.60970 - acc: 0.6993 | val_loss: 0.65568 - val_acc: 0.6369 -- iter: 500/500
--
Training Step: 113  | total loss: [1m[32m0.60727[0m[0m | time: 1.153s
[2K
| Adam | epoch: 008 | loss: 0.60727 - acc: 0.7044 -- iter: 032/500
[A[ATraining Step: 114  | total loss: [1m[32m0.60987[0m[0m | time: 2.385s
[2K
| Adam | epoch: 008 | loss: 0.60987 - acc: 0.7058 -- iter: 064/500
[A[ATraining Step: 115  | total loss: [1m[32m0.59835[0m[0m | time: 3.417s
[2K
| Adam | epoch: 008 | loss: 0.59835 - acc: 0.7102 -- iter: 096/500
[A[ATraining Step: 116  | total loss: [1m[32m0.59527[0m[0m | time: 4.404s
[2K
| Adam | epoch: 008 | loss: 0.59527 - acc: 0.7173 -- iter: 128/500
[A[ATraining Step: 117  | total loss: [1m[32m0.59272[0m[0m | time: 5.534s
[2K
| Adam | epoch: 008 | loss: 0.59272 - acc: 0.7081 -- iter: 160/500
[A[ATraining Step: 118  | total loss: [1m[32m0.58947[0m[0m | time: 6.261s
[2K
| Adam | epoch: 008 | loss: 0.58947 - acc: 0.7092 -- iter: 192/500
[A[ATraining Step: 119  | total loss: [1m[32m0.57051[0m[0m | time: 6.984s
[2K
| Adam | epoch: 008 | loss: 0.57051 - acc: 0.7182 -- iter: 224/500
[A[ATraining Step: 120  | total loss: [1m[32m0.55799[0m[0m | time: 7.865s
[2K
| Adam | epoch: 008 | loss: 0.55799 - acc: 0.7264 -- iter: 256/500
[A[ATraining Step: 121  | total loss: [1m[32m0.57548[0m[0m | time: 8.823s
[2K
| Adam | epoch: 008 | loss: 0.57548 - acc: 0.7194 -- iter: 288/500
[A[ATraining Step: 122  | total loss: [1m[32m0.55780[0m[0m | time: 9.825s
[2K
| Adam | epoch: 008 | loss: 0.55780 - acc: 0.7318 -- iter: 320/500
[A[ATraining Step: 123  | total loss: [1m[32m0.56089[0m[0m | time: 10.872s
[2K
| Adam | epoch: 008 | loss: 0.56089 - acc: 0.7337 -- iter: 352/500
[A[ATraining Step: 124  | total loss: [1m[32m0.56719[0m[0m | time: 11.953s
[2K
| Adam | epoch: 008 | loss: 0.56719 - acc: 0.7290 -- iter: 384/500
[A[ATraining Step: 125  | total loss: [1m[32m0.56959[0m[0m | time: 13.100s
[2K
| Adam | epoch: 008 | loss: 0.56959 - acc: 0.7218 -- iter: 416/500
[A[ATraining Step: 126  | total loss: [1m[32m0.57139[0m[0m | time: 14.280s
[2K
| Adam | epoch: 008 | loss: 0.57139 - acc: 0.7121 -- iter: 448/500
[A[ATraining Step: 127  | total loss: [1m[32m0.54946[0m[0m | time: 15.353s
[2K
| Adam | epoch: 008 | loss: 0.54946 - acc: 0.7377 -- iter: 480/500
[A[ATraining Step: 128  | total loss: [1m[32m0.54128[0m[0m | time: 17.342s
[2K
| Adam | epoch: 008 | loss: 0.54128 - acc: 0.7421 | val_loss: 0.57944 - val_acc: 0.6943 -- iter: 500/500
--
Training Step: 129  | total loss: [1m[32m0.53292[0m[0m | time: 1.261s
[2K
| Adam | epoch: 009 | loss: 0.53292 - acc: 0.7491 -- iter: 032/500
[A[ATraining Step: 130  | total loss: [1m[32m0.53658[0m[0m | time: 2.475s
[2K
| Adam | epoch: 009 | loss: 0.53658 - acc: 0.7398 -- iter: 064/500
[A[ATraining Step: 131  | total loss: [1m[32m0.53384[0m[0m | time: 3.663s
[2K
| Adam | epoch: 009 | loss: 0.53384 - acc: 0.7409 -- iter: 096/500
[A[ATraining Step: 132  | total loss: [1m[32m0.52558[0m[0m | time: 4.525s
[2K
| Adam | epoch: 009 | loss: 0.52558 - acc: 0.7512 -- iter: 128/500
[A[ATraining Step: 133  | total loss: [1m[32m0.52626[0m[0m | time: 5.581s
[2K
| Adam | epoch: 009 | loss: 0.52626 - acc: 0.7573 -- iter: 160/500
[A[ATraining Step: 134  | total loss: [1m[32m0.51746[0m[0m | time: 6.746s
[2K
| Adam | epoch: 009 | loss: 0.51746 - acc: 0.7659 -- iter: 192/500
[A[ATraining Step: 135  | total loss: [1m[32m0.51053[0m[0m | time: 7.471s
[2K
| Adam | epoch: 009 | loss: 0.51053 - acc: 0.7675 -- iter: 224/500
[A[ATraining Step: 136  | total loss: [1m[32m0.50451[0m[0m | time: 8.198s
[2K
| Adam | epoch: 009 | loss: 0.50451 - acc: 0.7707 -- iter: 256/500
[A[ATraining Step: 137  | total loss: [1m[32m0.49751[0m[0m | time: 9.226s
[2K
| Adam | epoch: 009 | loss: 0.49751 - acc: 0.7636 -- iter: 288/500
[A[ATraining Step: 138  | total loss: [1m[32m0.54938[0m[0m | time: 10.067s
[2K
| Adam | epoch: 009 | loss: 0.54938 - acc: 0.7373 -- iter: 320/500
[A[ATraining Step: 139  | total loss: [1m[32m0.55166[0m[0m | time: 10.939s
[2K
| Adam | epoch: 009 | loss: 0.55166 - acc: 0.7292 -- iter: 352/500
[A[ATraining Step: 140  | total loss: [1m[32m0.52801[0m[0m | time: 11.761s
[2K
| Adam | epoch: 009 | loss: 0.52801 - acc: 0.7438 -- iter: 384/500
[A[ATraining Step: 141  | total loss: [1m[32m0.52862[0m[0m | time: 12.626s
[2K
| Adam | epoch: 009 | loss: 0.52862 - acc: 0.7506 -- iter: 416/500
[A[ATraining Step: 142  | total loss: [1m[32m0.51923[0m[0m | time: 13.491s
[2K
| Adam | epoch: 009 | loss: 0.51923 - acc: 0.7568 -- iter: 448/500
[A[ATraining Step: 143  | total loss: [1m[32m0.53961[0m[0m | time: 14.332s
[2K
| Adam | epoch: 009 | loss: 0.53961 - acc: 0.7374 -- iter: 480/500
[A[ATraining Step: 144  | total loss: [1m[32m0.53639[0m[0m | time: 16.346s
[2K
| Adam | epoch: 009 | loss: 0.53639 - acc: 0.7387 | val_loss: 0.58227 - val_acc: 0.6879 -- iter: 500/500
--
Training Step: 145  | total loss: [1m[32m0.54301[0m[0m | time: 0.643s
[2K
| Adam | epoch: 010 | loss: 0.54301 - acc: 0.7335 -- iter: 032/500
[A[ATraining Step: 146  | total loss: [1m[32m0.52747[0m[0m | time: 1.423s
[2K
| Adam | epoch: 010 | loss: 0.52747 - acc: 0.7414 -- iter: 064/500
[A[ATraining Step: 147  | total loss: [1m[32m0.51880[0m[0m | time: 2.253s
[2K
| Adam | epoch: 010 | loss: 0.51880 - acc: 0.7579 -- iter: 096/500
[A[ATraining Step: 148  | total loss: [1m[32m0.51501[0m[0m | time: 3.170s
[2K
| Adam | epoch: 010 | loss: 0.51501 - acc: 0.7602 -- iter: 128/500
[A[ATraining Step: 149  | total loss: [1m[32m0.50550[0m[0m | time: 4.069s
[2K
| Adam | epoch: 010 | loss: 0.50550 - acc: 0.7623 -- iter: 160/500
[A[ATraining Step: 150  | total loss: [1m[32m0.52960[0m[0m | time: 4.996s
[2K
| Adam | epoch: 010 | loss: 0.52960 - acc: 0.7361 -- iter: 192/500
[A[ATraining Step: 151  | total loss: [1m[32m0.53147[0m[0m | time: 5.973s
[2K
| Adam | epoch: 010 | loss: 0.53147 - acc: 0.7313 -- iter: 224/500
[A[ATraining Step: 152  | total loss: [1m[32m0.52190[0m[0m | time: 6.514s
[2K
| Adam | epoch: 010 | loss: 0.52190 - acc: 0.7394 -- iter: 256/500
[A[ATraining Step: 153  | total loss: [1m[32m0.51189[0m[0m | time: 7.098s
[2K
| Adam | epoch: 010 | loss: 0.51189 - acc: 0.7504 -- iter: 288/500
[A[ATraining Step: 154  | total loss: [1m[32m0.50272[0m[0m | time: 7.912s
[2K
| Adam | epoch: 010 | loss: 0.50272 - acc: 0.7604 -- iter: 320/500
[A[ATraining Step: 155  | total loss: [1m[32m0.49990[0m[0m | time: 8.741s
[2K
| Adam | epoch: 010 | loss: 0.49990 - acc: 0.7656 -- iter: 352/500
[A[ATraining Step: 156  | total loss: [1m[32m0.49592[0m[0m | time: 9.713s
[2K
| Adam | epoch: 010 | loss: 0.49592 - acc: 0.7734 -- iter: 384/500
[A[ATraining Step: 157  | total loss: [1m[32m0.48792[0m[0m | time: 10.643s
[2K
| Adam | epoch: 010 | loss: 0.48792 - acc: 0.7805 -- iter: 416/500
[A[ATraining Step: 158  | total loss: [1m[32m0.49081[0m[0m | time: 11.356s
[2K
| Adam | epoch: 010 | loss: 0.49081 - acc: 0.7805 -- iter: 448/500
[A[ATraining Step: 159  | total loss: [1m[32m0.47607[0m[0m | time: 12.149s
[2K
| Adam | epoch: 010 | loss: 0.47607 - acc: 0.7962 -- iter: 480/500
[A[ATraining Step: 160  | total loss: [1m[32m0.46007[0m[0m | time: 14.065s
[2K
| Adam | epoch: 010 | loss: 0.46007 - acc: 0.8072 | val_loss: 0.53006 - val_acc: 0.7389 -- iter: 500/500
--
Training Step: 161  | total loss: [1m[32m0.44363[0m[0m | time: 1.211s
[2K
| Adam | epoch: 011 | loss: 0.44363 - acc: 0.8171 -- iter: 032/500
[A[ATraining Step: 162  | total loss: [1m[32m0.43883[0m[0m | time: 2.363s
[2K
| Adam | epoch: 011 | loss: 0.43883 - acc: 0.8198 -- iter: 064/500
[A[ATraining Step: 163  | total loss: [1m[32m0.42534[0m[0m | time: 3.505s
[2K
| Adam | epoch: 011 | loss: 0.42534 - acc: 0.8222 -- iter: 096/500
[A[ATraining Step: 164  | total loss: [1m[32m0.40193[0m[0m | time: 4.395s
[2K
| Adam | epoch: 011 | loss: 0.40193 - acc: 0.8337 -- iter: 128/500
[A[ATraining Step: 165  | total loss: [1m[32m0.41190[0m[0m | time: 5.443s
[2K
| Adam | epoch: 011 | loss: 0.41190 - acc: 0.8285 -- iter: 160/500
[A[ATraining Step: 166  | total loss: [1m[32m0.40667[0m[0m | time: 6.432s
[2K
| Adam | epoch: 011 | loss: 0.40667 - acc: 0.8269 -- iter: 192/500
[A[ATraining Step: 167  | total loss: [1m[32m0.42765[0m[0m | time: 7.599s
[2K
| Adam | epoch: 011 | loss: 0.42765 - acc: 0.8223 -- iter: 224/500
[A[ATraining Step: 168  | total loss: [1m[32m0.45071[0m[0m | time: 8.736s
[2K
| Adam | epoch: 011 | loss: 0.45071 - acc: 0.8088 -- iter: 256/500
[A[ATraining Step: 169  | total loss: [1m[32m0.44240[0m[0m | time: 9.480s
[2K
| Adam | epoch: 011 | loss: 0.44240 - acc: 0.8123 -- iter: 288/500
[A[ATraining Step: 170  | total loss: [1m[32m0.43272[0m[0m | time: 10.230s
[2K
| Adam | epoch: 011 | loss: 0.43272 - acc: 0.8211 -- iter: 320/500
[A[ATraining Step: 171  | total loss: [1m[32m0.42073[0m[0m | time: 11.213s
[2K
| Adam | epoch: 011 | loss: 0.42073 - acc: 0.8290 -- iter: 352/500
[A[ATraining Step: 172  | total loss: [1m[32m0.42664[0m[0m | time: 12.460s
[2K
| Adam | epoch: 011 | loss: 0.42664 - acc: 0.8273 -- iter: 384/500
[A[ATraining Step: 173  | total loss: [1m[32m0.42176[0m[0m | time: 13.508s
[2K
| Adam | epoch: 011 | loss: 0.42176 - acc: 0.8259 -- iter: 416/500
[A[ATraining Step: 174  | total loss: [1m[32m0.41218[0m[0m | time: 14.606s
[2K
| Adam | epoch: 011 | loss: 0.41218 - acc: 0.8308 -- iter: 448/500
[A[ATraining Step: 175  | total loss: [1m[32m0.41236[0m[0m | time: 15.813s
[2K
| Adam | epoch: 011 | loss: 0.41236 - acc: 0.8258 -- iter: 480/500
[A[ATraining Step: 176  | total loss: [1m[32m0.38618[0m[0m | time: 18.030s
[2K
| Adam | epoch: 011 | loss: 0.38618 - acc: 0.8432 | val_loss: 0.46341 - val_acc: 0.7707 -- iter: 500/500
--
Training Step: 177  | total loss: [1m[32m0.36767[0m[0m | time: 1.187s
[2K
| Adam | epoch: 012 | loss: 0.36767 - acc: 0.8558 -- iter: 032/500
[A[ATraining Step: 178  | total loss: [1m[32m0.36849[0m[0m | time: 2.199s
[2K
| Adam | epoch: 012 | loss: 0.36849 - acc: 0.8546 -- iter: 064/500
[A[ATraining Step: 179  | total loss: [1m[32m0.35486[0m[0m | time: 3.246s
[2K
| Adam | epoch: 012 | loss: 0.35486 - acc: 0.8629 -- iter: 096/500
[A[ATraining Step: 180  | total loss: [1m[32m0.33437[0m[0m | time: 4.471s
[2K
| Adam | epoch: 012 | loss: 0.33437 - acc: 0.8735 -- iter: 128/500
[A[ATraining Step: 181  | total loss: [1m[32m0.32331[0m[0m | time: 5.607s
[2K
| Adam | epoch: 012 | loss: 0.32331 - acc: 0.8767 -- iter: 160/500
[A[ATraining Step: 182  | total loss: [1m[32m0.31944[0m[0m | time: 6.840s
[2K
| Adam | epoch: 012 | loss: 0.31944 - acc: 0.8766 -- iter: 192/500
[A[ATraining Step: 183  | total loss: [1m[32m0.30760[0m[0m | time: 7.818s
[2K
| Adam | epoch: 012 | loss: 0.30760 - acc: 0.8827 -- iter: 224/500
[A[ATraining Step: 184  | total loss: [1m[32m0.30452[0m[0m | time: 8.928s
[2K
| Adam | epoch: 012 | loss: 0.30452 - acc: 0.8850 -- iter: 256/500
[A[ATraining Step: 185  | total loss: [1m[32m0.29721[0m[0m | time: 10.078s
[2K
| Adam | epoch: 012 | loss: 0.29721 - acc: 0.8934 -- iter: 288/500
[A[ATraining Step: 186  | total loss: [1m[32m0.27918[0m[0m | time: 10.726s
[2K
| Adam | epoch: 012 | loss: 0.27918 - acc: 0.9009 -- iter: 320/500
[A[ATraining Step: 187  | total loss: [1m[32m0.26889[0m[0m | time: 11.527s
[2K
| Adam | epoch: 012 | loss: 0.26889 - acc: 0.9058 -- iter: 352/500
[A[ATraining Step: 188  | total loss: [1m[32m0.26616[0m[0m | time: 12.685s
[2K
| Adam | epoch: 012 | loss: 0.26616 - acc: 0.9053 -- iter: 384/500
[A[ATraining Step: 189  | total loss: [1m[32m0.37165[0m[0m | time: 13.913s
[2K
| Adam | epoch: 012 | loss: 0.37165 - acc: 0.8616 -- iter: 416/500
[A[ATraining Step: 190  | total loss: [1m[32m0.35800[0m[0m | time: 14.987s
[2K
| Adam | epoch: 012 | loss: 0.35800 - acc: 0.8629 -- iter: 448/500
[A[ATraining Step: 191  | total loss: [1m[32m0.33440[0m[0m | time: 15.916s
[2K
| Adam | epoch: 012 | loss: 0.33440 - acc: 0.8704 -- iter: 480/500
[A[ATraining Step: 192  | total loss: [1m[32m0.31958[0m[0m | time: 17.991s
[2K
| Adam | epoch: 012 | loss: 0.31958 - acc: 0.8771 | val_loss: 0.42346 - val_acc: 0.8280 -- iter: 500/500
--
Training Step: 193  | total loss: [1m[32m0.33113[0m[0m | time: 1.228s
[2K
| Adam | epoch: 013 | loss: 0.33113 - acc: 0.8675 -- iter: 032/500
[A[ATraining Step: 194  | total loss: [1m[32m0.32500[0m[0m | time: 2.414s
[2K
| Adam | epoch: 013 | loss: 0.32500 - acc: 0.8683 -- iter: 064/500
[A[ATraining Step: 195  | total loss: [1m[32m0.30791[0m[0m | time: 3.515s
[2K
| Adam | epoch: 013 | loss: 0.30791 - acc: 0.8752 -- iter: 096/500
[A[ATraining Step: 196  | total loss: [1m[32m0.32613[0m[0m | time: 4.524s
[2K
| Adam | epoch: 013 | loss: 0.32613 - acc: 0.8720 -- iter: 128/500
[A[ATraining Step: 197  | total loss: [1m[32m0.36461[0m[0m | time: 5.640s
[2K
| Adam | epoch: 013 | loss: 0.36461 - acc: 0.8630 -- iter: 160/500
[A[ATraining Step: 198  | total loss: [1m[32m0.35920[0m[0m | time: 6.722s
[2K
| Adam | epoch: 013 | loss: 0.35920 - acc: 0.8673 -- iter: 192/500
[A[ATraining Step: 199  | total loss: [1m[32m0.33535[0m[0m | time: 7.904s
[2K
| Adam | epoch: 013 | loss: 0.33535 - acc: 0.8743 -- iter: 224/500
[A[ATraining Step: 200  | total loss: [1m[32m0.31815[0m[0m | time: 10.757s
[2K
| Adam | epoch: 013 | loss: 0.31815 - acc: 0.8806 | val_loss: 0.60476 - val_acc: 0.7580 -- iter: 256/500
--
Training Step: 201  | total loss: [1m[32m0.33515[0m[0m | time: 17.983s
[2K
| Adam | epoch: 013 | loss: 0.33515 - acc: 0.8582 -- iter: 288/500
[A[ATraining Step: 202  | total loss: [1m[32m0.33850[0m[0m | time: 23.379s
[2K
| Adam | epoch: 013 | loss: 0.33850 - acc: 0.8443 -- iter: 320/500
[A[ATraining Step: 203  | total loss: [1m[32m0.32533[0m[0m | time: 24.109s
[2K
| Adam | epoch: 013 | loss: 0.32533 - acc: 0.8567 -- iter: 352/500
[A[ATraining Step: 204  | total loss: [1m[32m0.31378[0m[0m | time: 24.908s
[2K
| Adam | epoch: 013 | loss: 0.31378 - acc: 0.8660 -- iter: 384/500
[A[ATraining Step: 205  | total loss: [1m[32m0.30491[0m[0m | time: 26.049s
[2K
| Adam | epoch: 013 | loss: 0.30491 - acc: 0.8744 -- iter: 416/500
[A[ATraining Step: 206  | total loss: [1m[32m0.31364[0m[0m | time: 26.961s
[2K
| Adam | epoch: 013 | loss: 0.31364 - acc: 0.8682 -- iter: 448/500
[A[ATraining Step: 207  | total loss: [1m[32m0.33899[0m[0m | time: 28.007s
[2K
| Adam | epoch: 013 | loss: 0.33899 - acc: 0.8533 -- iter: 480/500
[A[ATraining Step: 208  | total loss: [1m[32m0.32845[0m[0m | time: 30.244s
[2K
| Adam | epoch: 013 | loss: 0.32845 - acc: 0.8555 | val_loss: 0.42011 - val_acc: 0.8089 -- iter: 500/500
--
Training Step: 209  | total loss: [1m[32m0.30650[0m[0m | time: 1.107s
[2K
| Adam | epoch: 014 | loss: 0.30650 - acc: 0.8668 -- iter: 032/500
[A[ATraining Step: 210  | total loss: [1m[32m0.29244[0m[0m | time: 2.289s
[2K
| Adam | epoch: 014 | loss: 0.29244 - acc: 0.8739 -- iter: 064/500
[A[ATraining Step: 211  | total loss: [1m[32m0.30340[0m[0m | time: 3.473s
[2K
| Adam | epoch: 014 | loss: 0.30340 - acc: 0.8646 -- iter: 096/500
[A[ATraining Step: 212  | total loss: [1m[32m0.30130[0m[0m | time: 4.615s
[2K
| Adam | epoch: 014 | loss: 0.30130 - acc: 0.8625 -- iter: 128/500
[A[ATraining Step: 213  | total loss: [1m[32m0.28797[0m[0m | time: 13.114s
[2K
| Adam | epoch: 014 | loss: 0.28797 - acc: 0.8700 -- iter: 160/500
[A[ATraining Step: 214  | total loss: [1m[32m0.27461[0m[0m | time: 21.752s
[2K
| Adam | epoch: 014 | loss: 0.27461 - acc: 0.8799 -- iter: 192/500
[A[ATraining Step: 215  | total loss: [1m[32m0.26684[0m[0m | time: 26.358s
[2K
| Adam | epoch: 014 | loss: 0.26684 - acc: 0.8856 -- iter: 224/500
[A[ATraining Step: 216  | total loss: [1m[32m0.25755[0m[0m | time: 27.420s
[2K
| Adam | epoch: 014 | loss: 0.25755 - acc: 0.8877 -- iter: 256/500
[A[ATraining Step: 217  | total loss: [1m[32m0.24645[0m[0m | time: 28.469s
[2K
| Adam | epoch: 014 | loss: 0.24645 - acc: 0.8927 -- iter: 288/500
[A[ATraining Step: 218  | total loss: [1m[32m0.23245[0m[0m | time: 29.559s
[2K
| Adam | epoch: 014 | loss: 0.23245 - acc: 0.8972 -- iter: 320/500
[A[ATraining Step: 219  | total loss: [1m[32m0.21855[0m[0m | time: 30.653s
[2K
| Adam | epoch: 014 | loss: 0.21855 - acc: 0.9043 -- iter: 352/500
[A[ATraining Step: 220  | total loss: [1m[32m0.20282[0m[0m | time: 31.361s
[2K
| Adam | epoch: 014 | loss: 0.20282 - acc: 0.9108 -- iter: 384/500
[A[ATraining Step: 221  | total loss: [1m[32m0.19096[0m[0m | time: 32.152s
[2K
| Adam | epoch: 014 | loss: 0.19096 - acc: 0.9197 -- iter: 416/500
[A[ATraining Step: 222  | total loss: [1m[32m0.17800[0m[0m | time: 33.233s
[2K
| Adam | epoch: 014 | loss: 0.17800 - acc: 0.9277 -- iter: 448/500
[A[ATraining Step: 223  | total loss: [1m[32m0.21832[0m[0m | time: 34.394s
[2K
| Adam | epoch: 014 | loss: 0.21832 - acc: 0.9225 -- iter: 480/500
[A[ATraining Step: 224  | total loss: [1m[32m0.20671[0m[0m | time: 36.714s
[2K
| Adam | epoch: 014 | loss: 0.20671 - acc: 0.9240 | val_loss: 0.45441 - val_acc: 0.8153 -- iter: 500/500
--
Training Step: 225  | total loss: [1m[32m0.18984[0m[0m | time: 1.401s
[2K
| Adam | epoch: 015 | loss: 0.18984 - acc: 0.9316 -- iter: 032/500
[A[ATraining Step: 226  | total loss: [1m[32m0.18141[0m[0m | time: 2.558s
[2K
| Adam | epoch: 015 | loss: 0.18141 - acc: 0.9353 -- iter: 064/500
[A[ATraining Step: 227  | total loss: [1m[32m0.16795[0m[0m | time: 3.577s
[2K
| Adam | epoch: 015 | loss: 0.16795 - acc: 0.9418 -- iter: 096/500
[A[ATraining Step: 228  | total loss: [1m[32m0.16116[0m[0m | time: 4.742s
[2K
| Adam | epoch: 015 | loss: 0.16116 - acc: 0.9445 -- iter: 128/500
[A[ATraining Step: 229  | total loss: [1m[32m0.15114[0m[0m | time: 5.893s
[2K
| Adam | epoch: 015 | loss: 0.15114 - acc: 0.9500 -- iter: 160/500
[A[ATraining Step: 230  | total loss: [1m[32m0.14364[0m[0m | time: 7.203s
[2K
| Adam | epoch: 015 | loss: 0.14364 - acc: 0.9550 -- iter: 192/500
[A[ATraining Step: 231  | total loss: [1m[32m0.13472[0m[0m | time: 8.355s
[2K
| Adam | epoch: 015 | loss: 0.13472 - acc: 0.9595 -- iter: 224/500
[A[ATraining Step: 232  | total loss: [1m[32m0.12860[0m[0m | time: 9.538s
[2K
| Adam | epoch: 015 | loss: 0.12860 - acc: 0.9604 -- iter: 256/500
[A[ATraining Step: 233  | total loss: [1m[32m0.12090[0m[0m | time: 10.720s
[2K
| Adam | epoch: 015 | loss: 0.12090 - acc: 0.9644 -- iter: 288/500
[A[ATraining Step: 234  | total loss: [1m[32m0.12280[0m[0m | time: 11.853s
[2K
| Adam | epoch: 015 | loss: 0.12280 - acc: 0.9617 -- iter: 320/500
[A[ATraining Step: 235  | total loss: [1m[32m0.11328[0m[0m | time: 13.045s
[2K
| Adam | epoch: 015 | loss: 0.11328 - acc: 0.9655 -- iter: 352/500
[A[ATraining Step: 236  | total loss: [1m[32m0.10470[0m[0m | time: 14.373s
[2K
| Adam | epoch: 015 | loss: 0.10470 - acc: 0.9690 -- iter: 384/500
[A[ATraining Step: 237  | total loss: [1m[32m0.09631[0m[0m | time: 15.176s
[2K
| Adam | epoch: 015 | loss: 0.09631 - acc: 0.9721 -- iter: 416/500
[A[ATraining Step: 238  | total loss: [1m[32m0.08867[0m[0m | time: 16.054s
[2K
| Adam | epoch: 015 | loss: 0.08867 - acc: 0.9749 -- iter: 448/500
[A[ATraining Step: 239  | total loss: [1m[32m0.08111[0m[0m | time: 17.342s
[2K
| Adam | epoch: 015 | loss: 0.08111 - acc: 0.9774 -- iter: 480/500
[A[ATraining Step: 240  | total loss: [1m[32m0.07497[0m[0m | time: 19.527s
[2K
| Adam | epoch: 015 | loss: 0.07497 - acc: 0.9796 | val_loss: 0.52966 - val_acc: 0.8471 -- iter: 500/500
--
Validation AUC:0.9201970443349754
Validation AUPRC:0.9402618594224729
Test AUC:0.9258357676079195
Test AUPRC:0.9424073858351776
BestTestF1Score	0.86	0.71	0.85	0.84	0.87	69	13	65	10	0.25
BestTestMCCScore	0.87	0.75	0.87	0.88	0.86	68	9	69	11	0.52
BestTestAccuracyScore	0.87	0.75	0.87	0.88	0.86	68	9	69	11	0.52
BestValidationF1Score	0.86	0.69	0.85	0.88	0.84	73	10	60	14	0.25
BestValidationMCC	0.86	0.7	0.85	0.9	0.82	71	8	62	16	0.52
BestValidationAccuracy	0.86	0.7	0.85	0.9	0.82	71	8	62	16	0.52
TestPredictions (Threshold:0.52)
CHEMBL510618,TP,ACT,1.0	CHEMBL257547,FP,INACT,0.8700000047683716	CHEMBL160626,TN,INACT,0.0	CHEMBL205681,TP,ACT,1.0	CHEMBL518312,TP,ACT,0.9599999785423279	CHEMBL569688,TP,ACT,1.0	CHEMBL3315143,TP,ACT,1.0	CHEMBL42799,TN,INACT,0.0	CHEMBL516606,TP,ACT,1.0	CHEMBL205735,TP,ACT,0.7300000190734863	CHEMBL567713,TP,ACT,1.0	CHEMBL192552,FN,ACT,0.0	CHEMBL380054,TN,INACT,0.0	CHEMBL256988,TP,ACT,1.0	CHEMBL205628,FN,ACT,0.1899999976158142	CHEMBL33438,TN,INACT,0.009999999776482582	CHEMBL501794,TP,ACT,1.0	CHEMBL392401,TN,INACT,0.009999999776482582	CHEMBL332645,TN,INACT,0.009999999776482582	CHEMBL219356,TP,ACT,1.0	CHEMBL2348526,TP,ACT,0.9900000095367432	CHEMBL3665435,TN,INACT,0.0	CHEMBL1076554,TN,INACT,0.0	CHEMBL233501,TN,INACT,0.009999999776482582	CHEMBL319005,TN,INACT,0.44999998807907104	CHEMBL308924,TN,INACT,0.009999999776482582	CHEMBL1259241,TN,INACT,0.0	CHEMBL2348505,TP,ACT,1.0	CHEMBL2303762,TN,INACT,0.009999999776482582	CHEMBL1258371,TN,INACT,0.3799999952316284	CHEMBL283320,TN,INACT,0.05999999865889549	CHEMBL453067,TP,ACT,1.0	CHEMBL410825,FN,ACT,0.009999999776482582	CHEMBL3358668,TP,ACT,1.0	CHEMBL21509,FP,INACT,0.9599999785423279	CHEMBL257552,TP,ACT,1.0	CHEMBL251541,TN,INACT,0.03999999910593033	CHEMBL3315142,TP,ACT,1.0	CHEMBL80504,TN,INACT,0.0	CHEMBL274508,TP,ACT,0.9900000095367432	CHEMBL456675,TN,INACT,0.009999999776482582	CHEMBL195893,TN,INACT,0.009999999776482582	CHEMBL577518,TP,ACT,1.0	CHEMBL208512,TP,ACT,0.9800000190734863	CHEMBL264726,TP,ACT,1.0	CHEMBL218825,TP,ACT,1.0	CHEMBL1259071,TN,INACT,0.009999999776482582	CHEMBL3104462,TP,ACT,1.0	CHEMBL3315150,TP,ACT,1.0	CHEMBL204988,TP,ACT,0.9900000095367432	CHEMBL602269,TN,INACT,0.019999999552965164	CHEMBL3358672,TP,ACT,1.0	CHEMBL2348523,TP,ACT,0.9900000095367432	CHEMBL453075,FN,ACT,0.0	CHEMBL3633665,TN,INACT,0.009999999776482582	CHEMBL522381,TP,ACT,0.9800000190734863	CHEMBL3104639,TP,ACT,1.0	CHEMBL104,FP,INACT,0.9900000095367432	CHEMBL240001,FP,INACT,0.9700000286102295	CHEMBL450729,TN,INACT,0.0	CHEMBL565580,TP,ACT,1.0	CHEMBL3665439,TN,INACT,0.0	CHEMBL474708,TN,INACT,0.0	CHEMBL2348510,TP,ACT,0.9599999785423279	CHEMBL514606,TN,INACT,0.0	CHEMBL7441,TN,INACT,0.0	CHEMBL509604,TP,ACT,1.0	CHEMBL393675,TN,INACT,0.0	CHEMBL142822,TN,INACT,0.009999999776482582	CHEMBL542877,TN,INACT,0.009999999776482582	CHEMBL241082,TN,INACT,0.03999999910593033	CHEMBL258017,FN,ACT,0.12999999523162842	CHEMBL578206,FN,ACT,0.05000000074505806	CHEMBL568637,TP,ACT,1.0	CHEMBL402805,TP,ACT,1.0	CHEMBL205430,TP,ACT,0.9900000095367432	CHEMBL565416,TP,ACT,1.0	CHEMBL481129,FN,ACT,0.4000000059604645	CHEMBL361664,TP,ACT,1.0	CHEMBL257337,TP,ACT,1.0	CHEMBL21937,TN,INACT,0.05999999865889549	CHEMBL173708,TN,INACT,0.019999999552965164	CHEMBL391191,TN,INACT,0.33000001311302185	CHEMBL510201,FP,INACT,0.8999999761581421	CHEMBL384248,FP,INACT,0.9800000190734863	CHEMBL21508,FP,INACT,0.9599999785423279	CHEMBL445655,TP,ACT,1.0	CHEMBL257349,TP,ACT,0.9900000095367432	CHEMBL446717,TP,ACT,0.8899999856948853	CHEMBL193266,TP,ACT,1.0	CHEMBL206596,TP,ACT,0.9800000190734863	CHEMBL372658,TP,ACT,0.9100000262260437	CHEMBL3739820,TN,INACT,0.009999999776482582	CHEMBL57908,TN,INACT,0.0	CHEMBL2163921,TN,INACT,0.0	CHEMBL205254,TP,ACT,0.9900000095367432	CHEMBL437430,TP,ACT,0.9599999785423279	CHEMBL128360,TN,INACT,0.0	CHEMBL227378,TN,INACT,0.0	CHEMBL602474,TN,INACT,0.029999999329447746	CHEMBL566056,TP,ACT,1.0	CHEMBL291306,TN,INACT,0.009999999776482582	CHEMBL191915,TN,INACT,0.019999999552965164	CHEMBL349689,TN,INACT,0.0	CHEMBL217002,TN,INACT,0.0	CHEMBL523566,TP,ACT,1.0	CHEMBL302038,TN,INACT,0.0	CHEMBL1192069,TN,INACT,0.0	CHEMBL1478530,FP,INACT,0.9900000095367432	CHEMBL104222,TN,INACT,0.0	CHEMBL328476,TN,INACT,0.1599999964237213	CHEMBL482257,TP,ACT,0.9399999976158142	CHEMBL378235,TP,ACT,0.9900000095367432	CHEMBL3589940,TN,INACT,0.33000001311302185	CHEMBL594803,TN,INACT,0.0	CHEMBL415851,TP,ACT,1.0	CHEMBL245319,TN,INACT,0.10999999940395355	CHEMBL385281,TP,ACT,1.0	CHEMBL452808,FN,ACT,0.0	CHEMBL284965,TN,INACT,0.0	CHEMBL240021,TN,INACT,0.07999999821186066	CHEMBL3315140,TP,ACT,1.0	CHEMBL169631,TN,INACT,0.0	CHEMBL474091,FP,INACT,0.9900000095367432	CHEMBL3665443,TN,INACT,0.0	CHEMBL404557,TN,INACT,0.0	CHEMBL3315144,TP,ACT,1.0	CHEMBL377542,TN,INACT,0.0	CHEMBL204227,TP,ACT,0.949999988079071	CHEMBL206597,FN,ACT,0.20999999344348907	CHEMBL104180,TN,INACT,0.05999999865889549	CHEMBL403833,FN,ACT,0.07999999821186066	CHEMBL15936,TN,INACT,0.10999999940395355	CHEMBL2348515,TP,ACT,0.5799999833106995	CHEMBL3315139,TP,ACT,1.0	CHEMBL344752,TN,INACT,0.0	CHEMBL2348529,TP,ACT,1.0	CHEMBL3085215,TN,INACT,0.009999999776482582	CHEMBL389653,TP,ACT,1.0	CHEMBL414570,TN,INACT,0.0	CHEMBL332405,TN,INACT,0.18000000715255737	CHEMBL3290985,TN,INACT,0.019999999552965164	CHEMBL546011,TP,ACT,0.9900000095367432	CHEMBL2348514,TP,ACT,1.0	CHEMBL328925,TN,INACT,0.009999999776482582	CHEMBL207882,TP,ACT,0.9900000095367432	CHEMBL291992,TN,INACT,0.009999999776482582	CHEMBL389654,TP,ACT,1.0	CHEMBL1263,TN,INACT,0.0	CHEMBL499582,TP,ACT,0.9900000095367432	CHEMBL504097,TP,ACT,1.0	CHEMBL3590085,TN,INACT,0.03999999910593033	CHEMBL2163920,TN,INACT,0.11999999731779099	CHEMBL566433,TP,ACT,0.8899999856948853	CHEMBL572138,TP,ACT,1.0	CHEMBL382477,TP,ACT,0.8100000023841858	CHEMBL3358667,FN,ACT,0.029999999329447746	

