CNNModel CHEMBL4354 RMSprop 0.001 30 256 0 0.6 False True
Number of active compounds :	1070
Number of inactive compounds :	1070
---------------------------------
Run id: CNNModel_CHEMBL4354_RMSprop_0.001_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4354_RMSprop_0.001_30_256_0.6_True/
---------------------------------
Training samples: 1350
Validation samples: 423
--
Training Step: 1  | time: 1.187s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1350
[A[ATraining Step: 2  | total loss: [1m[32m0.62327[0m[0m | time: 2.117s
[2K
| RMSProp | epoch: 001 | loss: 0.62327 - acc: 0.5625 -- iter: 0064/1350
[A[ATraining Step: 3  | total loss: [1m[32m0.68067[0m[0m | time: 3.014s
[2K
| RMSProp | epoch: 001 | loss: 0.68067 - acc: 0.4858 -- iter: 0096/1350
[A[ATraining Step: 4  | total loss: [1m[32m0.69013[0m[0m | time: 3.865s
[2K
| RMSProp | epoch: 001 | loss: 0.69013 - acc: 0.4730 -- iter: 0128/1350
[A[ATraining Step: 5  | total loss: [1m[32m0.69269[0m[0m | time: 4.823s
[2K
| RMSProp | epoch: 001 | loss: 0.69269 - acc: 0.4268 -- iter: 0160/1350
[A[ATraining Step: 6  | total loss: [1m[32m0.69300[0m[0m | time: 5.870s
[2K
| RMSProp | epoch: 001 | loss: 0.69300 - acc: 0.4939 -- iter: 0192/1350
[A[ATraining Step: 7  | total loss: [1m[32m0.69312[0m[0m | time: 6.619s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.4976 -- iter: 0224/1350
[A[ATraining Step: 8  | total loss: [1m[32m0.69285[0m[0m | time: 7.408s
[2K
| RMSProp | epoch: 001 | loss: 0.69285 - acc: 0.5341 -- iter: 0256/1350
[A[ATraining Step: 9  | total loss: [1m[32m0.69310[0m[0m | time: 8.264s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.4995 -- iter: 0288/1350
[A[ATraining Step: 10  | total loss: [1m[32m0.69266[0m[0m | time: 9.128s
[2K
| RMSProp | epoch: 001 | loss: 0.69266 - acc: 0.5935 -- iter: 0320/1350
[A[ATraining Step: 11  | total loss: [1m[32m0.69330[0m[0m | time: 9.974s
[2K
| RMSProp | epoch: 001 | loss: 0.69330 - acc: 0.4900 -- iter: 0352/1350
[A[ATraining Step: 12  | total loss: [1m[32m0.69318[0m[0m | time: 10.831s
[2K
| RMSProp | epoch: 001 | loss: 0.69318 - acc: 0.5226 -- iter: 0384/1350
[A[ATraining Step: 13  | total loss: [1m[32m0.69376[0m[0m | time: 11.730s
[2K
| RMSProp | epoch: 001 | loss: 0.69376 - acc: 0.4058 -- iter: 0416/1350
[A[ATraining Step: 14  | total loss: [1m[32m0.69349[0m[0m | time: 12.616s
[2K
| RMSProp | epoch: 001 | loss: 0.69349 - acc: 0.4699 -- iter: 0448/1350
[A[ATraining Step: 15  | total loss: [1m[32m0.69322[0m[0m | time: 13.484s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.5061 -- iter: 0480/1350
[A[ATraining Step: 16  | total loss: [1m[32m0.69356[0m[0m | time: 14.426s
[2K
| RMSProp | epoch: 001 | loss: 0.69356 - acc: 0.4452 -- iter: 0512/1350
[A[ATraining Step: 17  | total loss: [1m[32m0.69325[0m[0m | time: 15.421s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.5212 -- iter: 0544/1350
[A[ATraining Step: 18  | total loss: [1m[32m0.69306[0m[0m | time: 16.367s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5463 -- iter: 0576/1350
[A[ATraining Step: 19  | total loss: [1m[32m0.69335[0m[0m | time: 17.031s
[2K
| RMSProp | epoch: 001 | loss: 0.69335 - acc: 0.4892 -- iter: 0608/1350
[A[ATraining Step: 20  | total loss: [1m[32m0.69327[0m[0m | time: 17.863s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.5027 -- iter: 0640/1350
[A[ATraining Step: 21  | total loss: [1m[32m0.69324[0m[0m | time: 18.753s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.5116 -- iter: 0672/1350
[A[ATraining Step: 22  | total loss: [1m[32m0.69307[0m[0m | time: 19.616s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5269 -- iter: 0704/1350
[A[ATraining Step: 23  | total loss: [1m[32m0.69297[0m[0m | time: 20.460s
[2K
| RMSProp | epoch: 001 | loss: 0.69297 - acc: 0.5372 -- iter: 0736/1350
[A[ATraining Step: 24  | total loss: [1m[32m0.69291[0m[0m | time: 21.336s
[2K
| RMSProp | epoch: 001 | loss: 0.69291 - acc: 0.5531 -- iter: 0768/1350
[A[ATraining Step: 25  | total loss: [1m[32m0.69294[0m[0m | time: 22.193s
[2K
| RMSProp | epoch: 001 | loss: 0.69294 - acc: 0.5557 -- iter: 0800/1350
[A[ATraining Step: 26  | total loss: [1m[32m0.69317[0m[0m | time: 23.034s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5244 -- iter: 0832/1350
[A[ATraining Step: 27  | total loss: [1m[32m0.69317[0m[0m | time: 23.915s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5181 -- iter: 0864/1350
[A[ATraining Step: 28  | total loss: [1m[32m0.69319[0m[0m | time: 24.811s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.5214 -- iter: 0896/1350
[A[ATraining Step: 29  | total loss: [1m[32m0.69319[0m[0m | time: 25.757s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.5238 -- iter: 0928/1350
[A[ATraining Step: 30  | total loss: [1m[32m0.69312[0m[0m | time: 26.707s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.5256 -- iter: 0960/1350
[A[ATraining Step: 31  | total loss: [1m[32m0.69327[0m[0m | time: 27.426s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.5125 -- iter: 0992/1350
[A[ATraining Step: 32  | total loss: [1m[32m0.69331[0m[0m | time: 28.256s
[2K
| RMSProp | epoch: 001 | loss: 0.69331 - acc: 0.5026 -- iter: 1024/1350
[A[ATraining Step: 33  | total loss: [1m[32m0.69309[0m[0m | time: 29.157s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5295 -- iter: 1056/1350
[A[ATraining Step: 34  | total loss: [1m[32m0.69302[0m[0m | time: 29.997s
[2K
| RMSProp | epoch: 001 | loss: 0.69302 - acc: 0.5299 -- iter: 1088/1350
[A[ATraining Step: 35  | total loss: [1m[32m0.69289[0m[0m | time: 30.889s
[2K
| RMSProp | epoch: 001 | loss: 0.69289 - acc: 0.5432 -- iter: 1120/1350
[A[ATraining Step: 36  | total loss: [1m[32m0.69327[0m[0m | time: 31.772s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.5088 -- iter: 1152/1350
[A[ATraining Step: 37  | total loss: [1m[32m0.69331[0m[0m | time: 32.623s
[2K
| RMSProp | epoch: 001 | loss: 0.69331 - acc: 0.5008 -- iter: 1184/1350
[A[ATraining Step: 38  | total loss: [1m[32m0.69350[0m[0m | time: 33.529s
[2K
| RMSProp | epoch: 001 | loss: 0.69350 - acc: 0.4762 -- iter: 1216/1350
[A[ATraining Step: 39  | total loss: [1m[32m0.69347[0m[0m | time: 34.402s
[2K
| RMSProp | epoch: 001 | loss: 0.69347 - acc: 0.4748 -- iter: 1248/1350
[A[ATraining Step: 40  | total loss: [1m[32m0.69332[0m[0m | time: 35.313s
[2K
| RMSProp | epoch: 001 | loss: 0.69332 - acc: 0.4971 -- iter: 1280/1350
[A[ATraining Step: 41  | total loss: [1m[32m0.69346[0m[0m | time: 36.329s
[2K
| RMSProp | epoch: 001 | loss: 0.69346 - acc: 0.4747 -- iter: 1312/1350
[A[ATraining Step: 42  | total loss: [1m[32m0.69348[0m[0m | time: 37.208s
[2K
| RMSProp | epoch: 001 | loss: 0.69348 - acc: 0.4736 -- iter: 1344/1350
[A[ATraining Step: 43  | total loss: [1m[32m0.69347[0m[0m | time: 39.093s
[2K
| RMSProp | epoch: 001 | loss: 0.69347 - acc: 0.4727 | val_loss: 0.69322 - val_acc: 0.4515 -- iter: 1350/1350
--
Training Step: 44  | total loss: [1m[32m0.69351[0m[0m | time: 0.219s
[2K
| RMSProp | epoch: 002 | loss: 0.69351 - acc: 0.4486 -- iter: 0032/1350
[A[ATraining Step: 45  | total loss: [1m[32m0.69334[0m[0m | time: 1.117s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4856 -- iter: 0064/1350
[A[ATraining Step: 46  | total loss: [1m[32m0.69335[0m[0m | time: 1.965s
[2K
| RMSProp | epoch: 002 | loss: 0.69335 - acc: 0.4776 -- iter: 0096/1350
[A[ATraining Step: 47  | total loss: [1m[32m0.69335[0m[0m | time: 2.817s
[2K
| RMSProp | epoch: 002 | loss: 0.69335 - acc: 0.4762 -- iter: 0128/1350
[A[ATraining Step: 48  | total loss: [1m[32m0.69334[0m[0m | time: 3.581s
[2K
| RMSProp | epoch: 002 | loss: 0.69334 - acc: 0.4649 -- iter: 0160/1350
[A[ATraining Step: 49  | total loss: [1m[32m0.69333[0m[0m | time: 4.536s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.4606 -- iter: 0192/1350
[A[ATraining Step: 50  | total loss: [1m[32m0.69333[0m[0m | time: 5.558s
[2K
| RMSProp | epoch: 002 | loss: 0.69333 - acc: 0.4667 -- iter: 0224/1350
[A[ATraining Step: 51  | total loss: [1m[32m0.69326[0m[0m | time: 6.438s
[2K
| RMSProp | epoch: 002 | loss: 0.69326 - acc: 0.5004 -- iter: 0256/1350
[A[ATraining Step: 52  | total loss: [1m[32m0.69322[0m[0m | time: 7.204s
[2K
| RMSProp | epoch: 002 | loss: 0.69322 - acc: 0.5050 -- iter: 0288/1350
[A[ATraining Step: 53  | total loss: [1m[32m0.69327[0m[0m | time: 8.038s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.4951 -- iter: 0320/1350
[A[ATraining Step: 54  | total loss: [1m[32m0.69328[0m[0m | time: 8.892s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4958 -- iter: 0352/1350
[A[ATraining Step: 55  | total loss: [1m[32m0.69326[0m[0m | time: 9.740s
[2K
| RMSProp | epoch: 002 | loss: 0.69326 - acc: 0.5053 -- iter: 0384/1350
[A[ATraining Step: 56  | total loss: [1m[32m0.69327[0m[0m | time: 10.617s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.5046 -- iter: 0416/1350
[A[ATraining Step: 57  | total loss: [1m[32m0.69323[0m[0m | time: 11.473s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.5126 -- iter: 0448/1350
[A[ATraining Step: 58  | total loss: [1m[32m0.69313[0m[0m | time: 12.380s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5322 -- iter: 0480/1350
[A[ATraining Step: 59  | total loss: [1m[32m0.69319[0m[0m | time: 13.246s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.5237 -- iter: 0512/1350
[A[ATraining Step: 60  | total loss: [1m[32m0.69326[0m[0m | time: 14.062s
[2K
| RMSProp | epoch: 002 | loss: 0.69326 - acc: 0.5123 -- iter: 0544/1350
[A[ATraining Step: 61  | total loss: [1m[32m0.69316[0m[0m | time: 14.972s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.5229 -- iter: 0576/1350
[A[ATraining Step: 62  | total loss: [1m[32m0.69318[0m[0m | time: 15.972s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.5159 -- iter: 0608/1350
[A[ATraining Step: 63  | total loss: [1m[32m0.69314[0m[0m | time: 16.865s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.5218 -- iter: 0640/1350
[A[ATraining Step: 64  | total loss: [1m[32m0.69325[0m[0m | time: 17.628s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.5113 -- iter: 0672/1350
[A[ATraining Step: 65  | total loss: [1m[32m0.69325[0m[0m | time: 18.476s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.5060 -- iter: 0704/1350
[A[ATraining Step: 66  | total loss: [1m[32m0.69328[0m[0m | time: 19.368s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.5015 -- iter: 0736/1350
[A[ATraining Step: 67  | total loss: [1m[32m0.69319[0m[0m | time: 20.183s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.5126 -- iter: 0768/1350
[A[ATraining Step: 68  | total loss: [1m[32m0.69305[0m[0m | time: 21.014s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5259 -- iter: 0800/1350
[A[ATraining Step: 69  | total loss: [1m[32m0.69303[0m[0m | time: 21.895s
[2K
| RMSProp | epoch: 002 | loss: 0.69303 - acc: 0.5265 -- iter: 0832/1350
[A[ATraining Step: 70  | total loss: [1m[32m0.69298[0m[0m | time: 22.717s
[2K
| RMSProp | epoch: 002 | loss: 0.69298 - acc: 0.5271 -- iter: 0864/1350
[A[ATraining Step: 71  | total loss: [1m[32m0.69285[0m[0m | time: 23.568s
[2K
| RMSProp | epoch: 002 | loss: 0.69285 - acc: 0.5347 -- iter: 0896/1350
[A[ATraining Step: 72  | total loss: [1m[32m0.69297[0m[0m | time: 24.380s
[2K
| RMSProp | epoch: 002 | loss: 0.69297 - acc: 0.5272 -- iter: 0928/1350
[A[ATraining Step: 73  | total loss: [1m[32m0.69258[0m[0m | time: 25.240s
[2K
| RMSProp | epoch: 002 | loss: 0.69258 - acc: 0.5451 -- iter: 0960/1350
[A[ATraining Step: 74  | total loss: [1m[32m0.69266[0m[0m | time: 26.193s
[2K
| RMSProp | epoch: 002 | loss: 0.69266 - acc: 0.5401 -- iter: 0992/1350
[A[ATraining Step: 75  | total loss: [1m[32m0.69238[0m[0m | time: 27.181s
[2K
| RMSProp | epoch: 002 | loss: 0.69238 - acc: 0.5493 -- iter: 1024/1350
[A[ATraining Step: 76  | total loss: [1m[32m0.69238[0m[0m | time: 27.871s
[2K
| RMSProp | epoch: 002 | loss: 0.69238 - acc: 0.5474 -- iter: 1056/1350
[A[ATraining Step: 77  | total loss: [1m[32m0.69280[0m[0m | time: 28.656s
[2K
| RMSProp | epoch: 002 | loss: 0.69280 - acc: 0.5324 -- iter: 1088/1350
[A[ATraining Step: 78  | total loss: [1m[32m0.69310[0m[0m | time: 29.521s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5192 -- iter: 1120/1350
[A[ATraining Step: 79  | total loss: [1m[32m0.69332[0m[0m | time: 30.375s
[2K
| RMSProp | epoch: 002 | loss: 0.69332 - acc: 0.5075 -- iter: 1152/1350
[A[ATraining Step: 80  | total loss: [1m[32m0.69347[0m[0m | time: 31.250s
[2K
| RMSProp | epoch: 002 | loss: 0.69347 - acc: 0.4972 -- iter: 1184/1350
[A[ATraining Step: 81  | total loss: [1m[32m0.69335[0m[0m | time: 32.087s
[2K
| RMSProp | epoch: 002 | loss: 0.69335 - acc: 0.5038 -- iter: 1216/1350
[A[ATraining Step: 82  | total loss: [1m[32m0.69335[0m[0m | time: 32.944s
[2K
| RMSProp | epoch: 002 | loss: 0.69335 - acc: 0.5034 -- iter: 1248/1350
[A[ATraining Step: 83  | total loss: [1m[32m0.69329[0m[0m | time: 33.813s
[2K
| RMSProp | epoch: 002 | loss: 0.69329 - acc: 0.5062 -- iter: 1280/1350
[A[ATraining Step: 84  | total loss: [1m[32m0.69323[0m[0m | time: 34.648s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.5087 -- iter: 1312/1350
[A[ATraining Step: 85  | total loss: [1m[32m0.69343[0m[0m | time: 35.486s
[2K
| RMSProp | epoch: 002 | loss: 0.69343 - acc: 0.4985 -- iter: 1344/1350
[A[ATraining Step: 86  | total loss: [1m[32m0.69357[0m[0m | time: 38.452s
[2K
| RMSProp | epoch: 002 | loss: 0.69357 - acc: 0.4861 | val_loss: 0.69360 - val_acc: 0.4704 -- iter: 1350/1350
--
Training Step: 87  | total loss: [1m[32m0.69346[0m[0m | time: 0.199s
[2K
| RMSProp | epoch: 003 | loss: 0.69346 - acc: 0.5031 -- iter: 0032/1350
[A[ATraining Step: 88  | total loss: [1m[32m0.69345[0m[0m | time: 0.402s
[2K
| RMSProp | epoch: 003 | loss: 0.69345 - acc: 0.5028 -- iter: 0064/1350
[A[ATraining Step: 89  | total loss: [1m[32m0.69340[0m[0m | time: 1.265s
[2K
| RMSProp | epoch: 003 | loss: 0.69340 - acc: 0.5025 -- iter: 0096/1350
[A[ATraining Step: 90  | total loss: [1m[32m0.69347[0m[0m | time: 2.168s
[2K
| RMSProp | epoch: 003 | loss: 0.69347 - acc: 0.4960 -- iter: 0128/1350
[A[ATraining Step: 91  | total loss: [1m[32m0.69353[0m[0m | time: 3.006s
[2K
| RMSProp | epoch: 003 | loss: 0.69353 - acc: 0.4839 -- iter: 0160/1350
[A[ATraining Step: 92  | total loss: [1m[32m0.69349[0m[0m | time: 3.837s
[2K
| RMSProp | epoch: 003 | loss: 0.69349 - acc: 0.4855 -- iter: 0192/1350
[A[ATraining Step: 93  | total loss: [1m[32m0.69343[0m[0m | time: 4.739s
[2K
| RMSProp | epoch: 003 | loss: 0.69343 - acc: 0.4995 -- iter: 0224/1350
[A[ATraining Step: 94  | total loss: [1m[32m0.69332[0m[0m | time: 5.740s
[2K
| RMSProp | epoch: 003 | loss: 0.69332 - acc: 0.5089 -- iter: 0256/1350
[A[ATraining Step: 95  | total loss: [1m[32m0.69332[0m[0m | time: 6.641s
[2K
| RMSProp | epoch: 003 | loss: 0.69332 - acc: 0.5080 -- iter: 0288/1350
[A[ATraining Step: 96  | total loss: [1m[32m0.69323[0m[0m | time: 7.360s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.5103 -- iter: 0320/1350
[A[ATraining Step: 97  | total loss: [1m[32m0.69321[0m[0m | time: 8.186s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.5093 -- iter: 0352/1350
[A[ATraining Step: 98  | total loss: [1m[32m0.69300[0m[0m | time: 9.108s
[2K
| RMSProp | epoch: 003 | loss: 0.69300 - acc: 0.5209 -- iter: 0384/1350
[A[ATraining Step: 99  | total loss: [1m[32m0.69286[0m[0m | time: 9.982s
[2K
| RMSProp | epoch: 003 | loss: 0.69286 - acc: 0.5250 -- iter: 0416/1350
[A[ATraining Step: 100  | total loss: [1m[32m0.69271[0m[0m | time: 10.814s
[2K
| RMSProp | epoch: 003 | loss: 0.69271 - acc: 0.5288 -- iter: 0448/1350
[A[ATraining Step: 101  | total loss: [1m[32m0.69266[0m[0m | time: 11.736s
[2K
| RMSProp | epoch: 003 | loss: 0.69266 - acc: 0.5290 -- iter: 0480/1350
[A[ATraining Step: 102  | total loss: [1m[32m0.69250[0m[0m | time: 12.621s
[2K
| RMSProp | epoch: 003 | loss: 0.69250 - acc: 0.5324 -- iter: 0512/1350
[A[ATraining Step: 103  | total loss: [1m[32m0.69249[0m[0m | time: 13.456s
[2K
| RMSProp | epoch: 003 | loss: 0.69249 - acc: 0.5323 -- iter: 0544/1350
[A[ATraining Step: 104  | total loss: [1m[32m0.69246[0m[0m | time: 14.284s
[2K
| RMSProp | epoch: 003 | loss: 0.69246 - acc: 0.5322 -- iter: 0576/1350
[A[ATraining Step: 105  | total loss: [1m[32m0.69244[0m[0m | time: 15.265s
[2K
| RMSProp | epoch: 003 | loss: 0.69244 - acc: 0.5321 -- iter: 0608/1350
[A[ATraining Step: 106  | total loss: [1m[32m0.69298[0m[0m | time: 16.297s
[2K
| RMSProp | epoch: 003 | loss: 0.69298 - acc: 0.5195 -- iter: 0640/1350
[A[ATraining Step: 107  | total loss: [1m[32m0.69320[0m[0m | time: 17.071s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.5113 -- iter: 0672/1350
[A[ATraining Step: 108  | total loss: [1m[32m0.69319[0m[0m | time: 17.878s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5102 -- iter: 0704/1350
[A[ATraining Step: 109  | total loss: [1m[32m0.69321[0m[0m | time: 18.755s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.5091 -- iter: 0736/1350
[A[ATraining Step: 110  | total loss: [1m[32m0.69306[0m[0m | time: 19.663s
[2K
| RMSProp | epoch: 003 | loss: 0.69306 - acc: 0.5145 -- iter: 0768/1350
[A[ATraining Step: 111  | total loss: [1m[32m0.69327[0m[0m | time: 20.485s
[2K
| RMSProp | epoch: 003 | loss: 0.69327 - acc: 0.5068 -- iter: 0800/1350
[A[ATraining Step: 112  | total loss: [1m[32m0.69311[0m[0m | time: 21.380s
[2K
| RMSProp | epoch: 003 | loss: 0.69311 - acc: 0.5124 -- iter: 0832/1350
[A[ATraining Step: 113  | total loss: [1m[32m0.69359[0m[0m | time: 22.230s
[2K
| RMSProp | epoch: 003 | loss: 0.69359 - acc: 0.4955 -- iter: 0864/1350
[A[ATraining Step: 114  | total loss: [1m[32m0.69355[0m[0m | time: 23.120s
[2K
| RMSProp | epoch: 003 | loss: 0.69355 - acc: 0.4897 -- iter: 0896/1350
[A[ATraining Step: 115  | total loss: [1m[32m0.69350[0m[0m | time: 23.956s
[2K
| RMSProp | epoch: 003 | loss: 0.69350 - acc: 0.4970 -- iter: 0928/1350
[A[ATraining Step: 116  | total loss: [1m[32m0.69359[0m[0m | time: 24.799s
[2K
| RMSProp | epoch: 003 | loss: 0.69359 - acc: 0.4879 -- iter: 0960/1350
[A[ATraining Step: 117  | total loss: [1m[32m0.69354[0m[0m | time: 25.761s
[2K
| RMSProp | epoch: 003 | loss: 0.69354 - acc: 0.4922 -- iter: 0992/1350
[A[ATraining Step: 118  | total loss: [1m[32m0.69345[0m[0m | time: 26.727s
[2K
| RMSProp | epoch: 003 | loss: 0.69345 - acc: 0.5086 -- iter: 1024/1350
[A[ATraining Step: 119  | total loss: [1m[32m0.69342[0m[0m | time: 27.418s
[2K
| RMSProp | epoch: 003 | loss: 0.69342 - acc: 0.5046 -- iter: 1056/1350
[A[ATraining Step: 120  | total loss: [1m[32m0.69339[0m[0m | time: 28.228s
[2K
| RMSProp | epoch: 003 | loss: 0.69339 - acc: 0.5073 -- iter: 1088/1350
[A[ATraining Step: 121  | total loss: [1m[32m0.69351[0m[0m | time: 29.092s
[2K
| RMSProp | epoch: 003 | loss: 0.69351 - acc: 0.4941 -- iter: 1120/1350
[A[ATraining Step: 122  | total loss: [1m[32m0.69340[0m[0m | time: 29.956s
[2K
| RMSProp | epoch: 003 | loss: 0.69340 - acc: 0.5009 -- iter: 1152/1350
[A[ATraining Step: 123  | total loss: [1m[32m0.69373[0m[0m | time: 30.792s
[2K
| RMSProp | epoch: 003 | loss: 0.69373 - acc: 0.4852 -- iter: 1184/1350
[A[ATraining Step: 124  | total loss: [1m[32m0.69363[0m[0m | time: 31.739s
[2K
| RMSProp | epoch: 003 | loss: 0.69363 - acc: 0.4961 -- iter: 1216/1350
[A[ATraining Step: 125  | total loss: [1m[32m0.69350[0m[0m | time: 32.626s
[2K
| RMSProp | epoch: 003 | loss: 0.69350 - acc: 0.5027 -- iter: 1248/1350
[A[ATraining Step: 126  | total loss: [1m[32m0.69347[0m[0m | time: 33.497s
[2K
| RMSProp | epoch: 003 | loss: 0.69347 - acc: 0.5024 -- iter: 1280/1350
[A[ATraining Step: 127  | total loss: [1m[32m0.69348[0m[0m | time: 34.344s
[2K
| RMSProp | epoch: 003 | loss: 0.69348 - acc: 0.4991 -- iter: 1312/1350
[A[ATraining Step: 128  | total loss: [1m[32m0.69333[0m[0m | time: 35.288s
[2K
| RMSProp | epoch: 003 | loss: 0.69333 - acc: 0.5054 -- iter: 1344/1350
[A[ATraining Step: 129  | total loss: [1m[32m0.69336[0m[0m | time: 38.050s
[2K
| RMSProp | epoch: 003 | loss: 0.69336 - acc: 0.5049 | val_loss: 0.69243 - val_acc: 0.5296 -- iter: 1350/1350
--
Training Step: 130  | total loss: [1m[32m0.69331[0m[0m | time: 0.839s
[2K
| RMSProp | epoch: 004 | loss: 0.69331 - acc: 0.5044 -- iter: 0032/1350
[A[ATraining Step: 131  | total loss: [1m[32m0.69312[0m[0m | time: 1.046s
[2K
| RMSProp | epoch: 004 | loss: 0.69312 - acc: 0.5102 -- iter: 0064/1350
[A[ATraining Step: 132  | total loss: [1m[32m0.69248[0m[0m | time: 1.248s
[2K
| RMSProp | epoch: 004 | loss: 0.69248 - acc: 0.5258 -- iter: 0096/1350
[A[ATraining Step: 133  | total loss: [1m[32m0.69127[0m[0m | time: 2.145s
[2K
| RMSProp | epoch: 004 | loss: 0.69127 - acc: 0.5399 -- iter: 0128/1350
[A[ATraining Step: 134  | total loss: [1m[32m0.69174[0m[0m | time: 3.105s
[2K
| RMSProp | epoch: 004 | loss: 0.69174 - acc: 0.5359 -- iter: 0160/1350
[A[ATraining Step: 135  | total loss: [1m[32m0.69213[0m[0m | time: 3.975s
[2K
| RMSProp | epoch: 004 | loss: 0.69213 - acc: 0.5323 -- iter: 0192/1350
[A[ATraining Step: 136  | total loss: [1m[32m0.69305[0m[0m | time: 4.830s
[2K
| RMSProp | epoch: 004 | loss: 0.69305 - acc: 0.5197 -- iter: 0224/1350
[A[ATraining Step: 137  | total loss: [1m[32m0.69322[0m[0m | time: 5.815s
[2K
| RMSProp | epoch: 004 | loss: 0.69322 - acc: 0.5146 -- iter: 0256/1350
[A[ATraining Step: 138  | total loss: [1m[32m0.69318[0m[0m | time: 6.820s
[2K
| RMSProp | epoch: 004 | loss: 0.69318 - acc: 0.5132 -- iter: 0288/1350
[A[ATraining Step: 139  | total loss: [1m[32m0.69320[0m[0m | time: 7.690s
[2K
| RMSProp | epoch: 004 | loss: 0.69320 - acc: 0.5119 -- iter: 0320/1350
[A[ATraining Step: 140  | total loss: [1m[32m0.69349[0m[0m | time: 8.425s
[2K
| RMSProp | epoch: 004 | loss: 0.69349 - acc: 0.4982 -- iter: 0352/1350
[A[ATraining Step: 141  | total loss: [1m[32m0.69341[0m[0m | time: 9.258s
[2K
| RMSProp | epoch: 004 | loss: 0.69341 - acc: 0.4983 -- iter: 0384/1350
[A[ATraining Step: 142  | total loss: [1m[32m0.69353[0m[0m | time: 10.078s
[2K
| RMSProp | epoch: 004 | loss: 0.69353 - acc: 0.4891 -- iter: 0416/1350
[A[ATraining Step: 143  | total loss: [1m[32m0.69357[0m[0m | time: 10.928s
[2K
| RMSProp | epoch: 004 | loss: 0.69357 - acc: 0.4871 -- iter: 0448/1350
[A[ATraining Step: 144  | total loss: [1m[32m0.69351[0m[0m | time: 11.781s
[2K
| RMSProp | epoch: 004 | loss: 0.69351 - acc: 0.4821 -- iter: 0480/1350
[A[ATraining Step: 145  | total loss: [1m[32m0.69358[0m[0m | time: 12.638s
[2K
| RMSProp | epoch: 004 | loss: 0.69358 - acc: 0.4746 -- iter: 0512/1350
[A[ATraining Step: 146  | total loss: [1m[32m0.69364[0m[0m | time: 13.495s
[2K
| RMSProp | epoch: 004 | loss: 0.69364 - acc: 0.4708 -- iter: 0544/1350
[A[ATraining Step: 147  | total loss: [1m[32m0.69365[0m[0m | time: 14.354s
[2K
| RMSProp | epoch: 004 | loss: 0.69365 - acc: 0.4550 -- iter: 0576/1350
[A[ATraining Step: 148  | total loss: [1m[32m0.69394[0m[0m | time: 15.158s
[2K
| RMSProp | epoch: 004 | loss: 0.69394 - acc: 0.4470 -- iter: 0608/1350
[A[ATraining Step: 149  | total loss: [1m[32m0.69395[0m[0m | time: 16.056s
[2K
| RMSProp | epoch: 004 | loss: 0.69395 - acc: 0.4398 -- iter: 0640/1350
[A[ATraining Step: 150  | total loss: [1m[32m0.69384[0m[0m | time: 17.043s
[2K
| RMSProp | epoch: 004 | loss: 0.69384 - acc: 0.4458 -- iter: 0672/1350
[A[ATraining Step: 151  | total loss: [1m[32m0.69378[0m[0m | time: 18.022s
[2K
| RMSProp | epoch: 004 | loss: 0.69378 - acc: 0.4512 -- iter: 0704/1350
[A[ATraining Step: 152  | total loss: [1m[32m0.69377[0m[0m | time: 18.732s
[2K
| RMSProp | epoch: 004 | loss: 0.69377 - acc: 0.4499 -- iter: 0736/1350
[A[ATraining Step: 153  | total loss: [1m[32m0.69367[0m[0m | time: 19.569s
[2K
| RMSProp | epoch: 004 | loss: 0.69367 - acc: 0.4705 -- iter: 0768/1350
[A[ATraining Step: 154  | total loss: [1m[32m0.69363[0m[0m | time: 20.403s
[2K
| RMSProp | epoch: 004 | loss: 0.69363 - acc: 0.4672 -- iter: 0800/1350
[A[ATraining Step: 155  | total loss: [1m[32m0.69352[0m[0m | time: 21.235s
[2K
| RMSProp | epoch: 004 | loss: 0.69352 - acc: 0.4767 -- iter: 0832/1350
[A[ATraining Step: 156  | total loss: [1m[32m0.69368[0m[0m | time: 22.048s
[2K
| RMSProp | epoch: 004 | loss: 0.69368 - acc: 0.4666 -- iter: 0864/1350
[A[ATraining Step: 157  | total loss: [1m[32m0.69359[0m[0m | time: 22.867s
[2K
| RMSProp | epoch: 004 | loss: 0.69359 - acc: 0.4762 -- iter: 0896/1350
[A[ATraining Step: 158  | total loss: [1m[32m0.69321[0m[0m | time: 23.804s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.4910 -- iter: 0928/1350
[A[ATraining Step: 159  | total loss: [1m[32m0.69478[0m[0m | time: 24.694s
[2K
| RMSProp | epoch: 004 | loss: 0.69478 - acc: 0.4794 -- iter: 0960/1350
[A[ATraining Step: 160  | total loss: [1m[32m0.69462[0m[0m | time: 25.552s
[2K
| RMSProp | epoch: 004 | loss: 0.69462 - acc: 0.4784 -- iter: 0992/1350
[A[ATraining Step: 161  | total loss: [1m[32m0.69449[0m[0m | time: 26.362s
[2K
| RMSProp | epoch: 004 | loss: 0.69449 - acc: 0.4805 -- iter: 1024/1350
[A[ATraining Step: 162  | total loss: [1m[32m0.69445[0m[0m | time: 27.334s
[2K
| RMSProp | epoch: 004 | loss: 0.69445 - acc: 0.4794 -- iter: 1056/1350
[A[ATraining Step: 163  | total loss: [1m[32m0.69455[0m[0m | time: 28.302s
[2K
| RMSProp | epoch: 004 | loss: 0.69455 - acc: 0.4658 -- iter: 1088/1350
[A[ATraining Step: 164  | total loss: [1m[32m0.69435[0m[0m | time: 29.014s
[2K
| RMSProp | epoch: 004 | loss: 0.69435 - acc: 0.4848 -- iter: 1120/1350
[A[ATraining Step: 165  | total loss: [1m[32m0.69436[0m[0m | time: 29.841s
[2K
| RMSProp | epoch: 004 | loss: 0.69436 - acc: 0.4801 -- iter: 1152/1350
[A[ATraining Step: 166  | total loss: [1m[32m0.69437[0m[0m | time: 30.697s
[2K
| RMSProp | epoch: 004 | loss: 0.69437 - acc: 0.4696 -- iter: 1184/1350
[A[ATraining Step: 167  | total loss: [1m[32m0.69425[0m[0m | time: 31.497s
[2K
| RMSProp | epoch: 004 | loss: 0.69425 - acc: 0.4726 -- iter: 1216/1350
[A[ATraining Step: 168  | total loss: [1m[32m0.69409[0m[0m | time: 32.361s
[2K
| RMSProp | epoch: 004 | loss: 0.69409 - acc: 0.4910 -- iter: 1248/1350
[A[ATraining Step: 169  | total loss: [1m[32m0.69393[0m[0m | time: 33.224s
[2K
| RMSProp | epoch: 004 | loss: 0.69393 - acc: 0.4981 -- iter: 1280/1350
[A[ATraining Step: 170  | total loss: [1m[32m0.69373[0m[0m | time: 34.112s
[2K
| RMSProp | epoch: 004 | loss: 0.69373 - acc: 0.5046 -- iter: 1312/1350
[A[ATraining Step: 171  | total loss: [1m[32m0.69366[0m[0m | time: 35.009s
[2K
| RMSProp | epoch: 004 | loss: 0.69366 - acc: 0.5041 -- iter: 1344/1350
[A[ATraining Step: 172  | total loss: [1m[32m0.69388[0m[0m | time: 37.677s
[2K
| RMSProp | epoch: 004 | loss: 0.69388 - acc: 0.4943 | val_loss: 0.69360 - val_acc: 0.4704 -- iter: 1350/1350
--
Training Step: 173  | total loss: [1m[32m0.69380[0m[0m | time: 0.728s
[2K
| RMSProp | epoch: 005 | loss: 0.69380 - acc: 0.4949 -- iter: 0032/1350
[A[ATraining Step: 174  | total loss: [1m[32m0.69369[0m[0m | time: 1.598s
[2K
| RMSProp | epoch: 005 | loss: 0.69369 - acc: 0.4985 -- iter: 0064/1350
[A[ATraining Step: 175  | total loss: [1m[32m0.69388[0m[0m | time: 1.800s
[2K
| RMSProp | epoch: 005 | loss: 0.69388 - acc: 0.4862 -- iter: 0096/1350
[A[ATraining Step: 176  | total loss: [1m[32m0.69401[0m[0m | time: 2.001s
[2K
| RMSProp | epoch: 005 | loss: 0.69401 - acc: 0.4542 -- iter: 0128/1350
[A[ATraining Step: 177  | total loss: [1m[32m0.69340[0m[0m | time: 2.849s
[2K
| RMSProp | epoch: 005 | loss: 0.69340 - acc: 0.4921 -- iter: 0160/1350
[A[ATraining Step: 178  | total loss: [1m[32m0.69295[0m[0m | time: 3.698s
[2K
| RMSProp | epoch: 005 | loss: 0.69295 - acc: 0.5023 -- iter: 0192/1350
[A[ATraining Step: 179  | total loss: [1m[32m0.69411[0m[0m | time: 4.550s
[2K
| RMSProp | epoch: 005 | loss: 0.69411 - acc: 0.4896 -- iter: 0224/1350
[A[ATraining Step: 180  | total loss: [1m[32m0.69418[0m[0m | time: 5.443s
[2K
| RMSProp | epoch: 005 | loss: 0.69418 - acc: 0.4844 -- iter: 0256/1350
[A[ATraining Step: 181  | total loss: [1m[32m0.69384[0m[0m | time: 6.345s
[2K
| RMSProp | epoch: 005 | loss: 0.69384 - acc: 0.4953 -- iter: 0288/1350
[A[ATraining Step: 182  | total loss: [1m[32m0.69358[0m[0m | time: 7.190s
[2K
| RMSProp | epoch: 005 | loss: 0.69358 - acc: 0.5020 -- iter: 0320/1350
[A[ATraining Step: 183  | total loss: [1m[32m0.69345[0m[0m | time: 8.046s
[2K
| RMSProp | epoch: 005 | loss: 0.69345 - acc: 0.5049 -- iter: 0352/1350
[A[ATraining Step: 184  | total loss: [1m[32m0.69321[0m[0m | time: 9.028s
[2K
| RMSProp | epoch: 005 | loss: 0.69321 - acc: 0.5107 -- iter: 0384/1350
[A[ATraining Step: 185  | total loss: [1m[32m0.69303[0m[0m | time: 9.993s
[2K
| RMSProp | epoch: 005 | loss: 0.69303 - acc: 0.5159 -- iter: 0416/1350
[A[ATraining Step: 186  | total loss: [1m[32m0.69250[0m[0m | time: 10.707s
[2K
| RMSProp | epoch: 005 | loss: 0.69250 - acc: 0.5268 -- iter: 0448/1350
[A[ATraining Step: 187  | total loss: [1m[32m0.69258[0m[0m | time: 11.524s
[2K
| RMSProp | epoch: 005 | loss: 0.69258 - acc: 0.5241 -- iter: 0480/1350
[A[ATraining Step: 188  | total loss: [1m[32m0.69177[0m[0m | time: 12.440s
[2K
| RMSProp | epoch: 005 | loss: 0.69177 - acc: 0.5373 -- iter: 0512/1350
[A[ATraining Step: 189  | total loss: [1m[32m0.69201[0m[0m | time: 13.281s
[2K
| RMSProp | epoch: 005 | loss: 0.69201 - acc: 0.5336 -- iter: 0544/1350
[A[ATraining Step: 190  | total loss: [1m[32m0.69289[0m[0m | time: 14.137s
[2K
| RMSProp | epoch: 005 | loss: 0.69289 - acc: 0.5209 -- iter: 0576/1350
[A[ATraining Step: 191  | total loss: [1m[32m0.69249[0m[0m | time: 14.953s
[2K
| RMSProp | epoch: 005 | loss: 0.69249 - acc: 0.5281 -- iter: 0608/1350
[A[ATraining Step: 192  | total loss: [1m[32m0.69181[0m[0m | time: 15.856s
[2K
| RMSProp | epoch: 005 | loss: 0.69181 - acc: 0.5378 -- iter: 0640/1350
[A[ATraining Step: 193  | total loss: [1m[32m0.69178[0m[0m | time: 16.749s
[2K
| RMSProp | epoch: 005 | loss: 0.69178 - acc: 0.5372 -- iter: 0672/1350
[A[ATraining Step: 194  | total loss: [1m[32m0.69043[0m[0m | time: 17.600s
[2K
| RMSProp | epoch: 005 | loss: 0.69043 - acc: 0.5522 -- iter: 0704/1350
[A[ATraining Step: 195  | total loss: [1m[32m0.68954[0m[0m | time: 18.490s
[2K
| RMSProp | epoch: 005 | loss: 0.68954 - acc: 0.5564 -- iter: 0736/1350
[A[ATraining Step: 196  | total loss: [1m[32m0.69627[0m[0m | time: 19.452s
[2K
| RMSProp | epoch: 005 | loss: 0.69627 - acc: 0.5445 -- iter: 0768/1350
[A[ATraining Step: 197  | total loss: [1m[32m0.69722[0m[0m | time: 20.457s
[2K
| RMSProp | epoch: 005 | loss: 0.69722 - acc: 0.5244 -- iter: 0800/1350
[A[ATraining Step: 198  | total loss: [1m[32m0.69695[0m[0m | time: 21.151s
[2K
| RMSProp | epoch: 005 | loss: 0.69695 - acc: 0.5188 -- iter: 0832/1350
[A[ATraining Step: 199  | total loss: [1m[32m0.69661[0m[0m | time: 21.965s
[2K
| RMSProp | epoch: 005 | loss: 0.69661 - acc: 0.5076 -- iter: 0864/1350
[A[ATraining Step: 200  | total loss: [1m[32m0.69386[0m[0m | time: 24.519s
[2K
| RMSProp | epoch: 005 | loss: 0.69386 - acc: 0.5224 | val_loss: 0.69498 - val_acc: 0.4704 -- iter: 0896/1350
--
Training Step: 201  | total loss: [1m[32m0.72328[0m[0m | time: 25.315s
[2K
| RMSProp | epoch: 005 | loss: 0.72328 - acc: 0.5265 -- iter: 0928/1350
[A[ATraining Step: 202  | total loss: [1m[32m0.72085[0m[0m | time: 26.367s
[2K
| RMSProp | epoch: 005 | loss: 0.72085 - acc: 0.5144 -- iter: 0960/1350
[A[ATraining Step: 203  | total loss: [1m[32m0.71769[0m[0m | time: 27.386s
[2K
| RMSProp | epoch: 005 | loss: 0.71769 - acc: 0.5255 -- iter: 0992/1350
[A[ATraining Step: 204  | total loss: [1m[32m0.71567[0m[0m | time: 28.139s
[2K
| RMSProp | epoch: 005 | loss: 0.71567 - acc: 0.5167 -- iter: 1024/1350
[A[ATraining Step: 205  | total loss: [1m[32m0.71306[0m[0m | time: 28.993s
[2K
| RMSProp | epoch: 005 | loss: 0.71306 - acc: 0.5213 -- iter: 1056/1350
[A[ATraining Step: 206  | total loss: [1m[32m0.71168[0m[0m | time: 29.783s
[2K
| RMSProp | epoch: 005 | loss: 0.71168 - acc: 0.5098 -- iter: 1088/1350
[A[ATraining Step: 207  | total loss: [1m[32m0.70963[0m[0m | time: 30.630s
[2K
| RMSProp | epoch: 005 | loss: 0.70963 - acc: 0.5119 -- iter: 1120/1350
[A[ATraining Step: 208  | total loss: [1m[32m0.70791[0m[0m | time: 31.467s
[2K
| RMSProp | epoch: 005 | loss: 0.70791 - acc: 0.5107 -- iter: 1152/1350
[A[ATraining Step: 209  | total loss: [1m[32m0.70681[0m[0m | time: 32.273s
[2K
| RMSProp | epoch: 005 | loss: 0.70681 - acc: 0.5003 -- iter: 1184/1350
[A[ATraining Step: 210  | total loss: [1m[32m0.70526[0m[0m | time: 33.140s
[2K
| RMSProp | epoch: 005 | loss: 0.70526 - acc: 0.5096 -- iter: 1216/1350
[A[ATraining Step: 211  | total loss: [1m[32m0.70460[0m[0m | time: 33.999s
[2K
| RMSProp | epoch: 005 | loss: 0.70460 - acc: 0.4930 -- iter: 1248/1350
[A[ATraining Step: 212  | total loss: [1m[32m0.70344[0m[0m | time: 34.849s
[2K
| RMSProp | epoch: 005 | loss: 0.70344 - acc: 0.4969 -- iter: 1280/1350
[A[ATraining Step: 213  | total loss: [1m[32m0.70259[0m[0m | time: 35.674s
[2K
| RMSProp | epoch: 005 | loss: 0.70259 - acc: 0.4815 -- iter: 1312/1350
[A[ATraining Step: 214  | total loss: [1m[32m0.70132[0m[0m | time: 36.556s
[2K
| RMSProp | epoch: 005 | loss: 0.70132 - acc: 0.4928 -- iter: 1344/1350
[A[ATraining Step: 215  | total loss: [1m[32m0.70060[0m[0m | time: 39.365s
[2K
| RMSProp | epoch: 005 | loss: 0.70060 - acc: 0.4904 | val_loss: 0.69263 - val_acc: 0.4704 -- iter: 1350/1350
--
Training Step: 216  | total loss: [1m[32m0.70012[0m[0m | time: 0.837s
[2K
| RMSProp | epoch: 006 | loss: 0.70012 - acc: 0.4820 -- iter: 0032/1350
[A[ATraining Step: 217  | total loss: [1m[32m0.69928[0m[0m | time: 1.694s
[2K
| RMSProp | epoch: 006 | loss: 0.69928 - acc: 0.4838 -- iter: 0064/1350
[A[ATraining Step: 218  | total loss: [1m[32m0.69849[0m[0m | time: 2.598s
[2K
| RMSProp | epoch: 006 | loss: 0.69849 - acc: 0.4948 -- iter: 0096/1350
[A[ATraining Step: 219  | total loss: [1m[32m0.69742[0m[0m | time: 2.789s
[2K
| RMSProp | epoch: 006 | loss: 0.69742 - acc: 0.5015 -- iter: 0128/1350
[A[ATraining Step: 220  | total loss: [1m[32m0.70204[0m[0m | time: 2.993s
[2K
| RMSProp | epoch: 006 | loss: 0.70204 - acc: 0.4514 -- iter: 0160/1350
[A[ATraining Step: 221  | total loss: [1m[32m0.69874[0m[0m | time: 3.864s
[2K
| RMSProp | epoch: 006 | loss: 0.69874 - acc: 0.5062 -- iter: 0192/1350
[A[ATraining Step: 222  | total loss: [1m[32m0.69868[0m[0m | time: 4.684s
[2K
| RMSProp | epoch: 006 | loss: 0.69868 - acc: 0.5025 -- iter: 0224/1350
[A[ATraining Step: 223  | total loss: [1m[32m0.69680[0m[0m | time: 5.632s
[2K
| RMSProp | epoch: 006 | loss: 0.69680 - acc: 0.5179 -- iter: 0256/1350
[A[ATraining Step: 224  | total loss: [1m[32m0.69821[0m[0m | time: 6.599s
[2K
| RMSProp | epoch: 006 | loss: 0.69821 - acc: 0.5005 -- iter: 0288/1350
[A[ATraining Step: 225  | total loss: [1m[32m0.69750[0m[0m | time: 7.505s
[2K
| RMSProp | epoch: 006 | loss: 0.69750 - acc: 0.5035 -- iter: 0320/1350
[A[ATraining Step: 226  | total loss: [1m[32m0.69658[0m[0m | time: 8.199s
[2K
| RMSProp | epoch: 006 | loss: 0.69658 - acc: 0.5094 -- iter: 0352/1350
[A[ATraining Step: 227  | total loss: [1m[32m0.69660[0m[0m | time: 9.004s
[2K
| RMSProp | epoch: 006 | loss: 0.69660 - acc: 0.5054 -- iter: 0384/1350
[A[ATraining Step: 228  | total loss: [1m[32m0.69707[0m[0m | time: 9.809s
[2K
| RMSProp | epoch: 006 | loss: 0.69707 - acc: 0.4955 -- iter: 0416/1350
[A[ATraining Step: 229  | total loss: [1m[32m0.69608[0m[0m | time: 10.653s
[2K
| RMSProp | epoch: 006 | loss: 0.69608 - acc: 0.5053 -- iter: 0448/1350
[A[ATraining Step: 230  | total loss: [1m[32m0.69559[0m[0m | time: 11.490s
[2K
| RMSProp | epoch: 006 | loss: 0.69559 - acc: 0.5079 -- iter: 0480/1350
[A[ATraining Step: 231  | total loss: [1m[32m0.69568[0m[0m | time: 12.388s
[2K
| RMSProp | epoch: 006 | loss: 0.69568 - acc: 0.5040 -- iter: 0512/1350
[A[ATraining Step: 232  | total loss: [1m[32m0.69549[0m[0m | time: 13.252s
[2K
| RMSProp | epoch: 006 | loss: 0.69549 - acc: 0.5036 -- iter: 0544/1350
[A[ATraining Step: 233  | total loss: [1m[32m0.69416[0m[0m | time: 14.111s
[2K
| RMSProp | epoch: 006 | loss: 0.69416 - acc: 0.5188 -- iter: 0576/1350
[A[ATraining Step: 234  | total loss: [1m[32m0.69578[0m[0m | time: 14.941s
[2K
| RMSProp | epoch: 006 | loss: 0.69578 - acc: 0.4982 -- iter: 0608/1350
[A[ATraining Step: 235  | total loss: [1m[32m0.69531[0m[0m | time: 15.803s
[2K
| RMSProp | epoch: 006 | loss: 0.69531 - acc: 0.5015 -- iter: 0640/1350
[A[ATraining Step: 236  | total loss: [1m[32m0.69572[0m[0m | time: 16.827s
[2K
| RMSProp | epoch: 006 | loss: 0.69572 - acc: 0.4920 -- iter: 0672/1350
[A[ATraining Step: 237  | total loss: [1m[32m0.69494[0m[0m | time: 17.818s
[2K
| RMSProp | epoch: 006 | loss: 0.69494 - acc: 0.5022 -- iter: 0704/1350
[A[ATraining Step: 238  | total loss: [1m[32m0.69355[0m[0m | time: 18.530s
[2K
| RMSProp | epoch: 006 | loss: 0.69355 - acc: 0.5207 -- iter: 0736/1350
[A[ATraining Step: 239  | total loss: [1m[32m0.69350[0m[0m | time: 19.388s
[2K
| RMSProp | epoch: 006 | loss: 0.69350 - acc: 0.5186 -- iter: 0768/1350
[A[ATraining Step: 240  | total loss: [1m[32m0.69355[0m[0m | time: 20.224s
[2K
| RMSProp | epoch: 006 | loss: 0.69355 - acc: 0.5168 -- iter: 0800/1350
[A[ATraining Step: 241  | total loss: [1m[32m0.69413[0m[0m | time: 21.038s
[2K
| RMSProp | epoch: 006 | loss: 0.69413 - acc: 0.5088 -- iter: 0832/1350
[A[ATraining Step: 242  | total loss: [1m[32m0.69347[0m[0m | time: 21.872s
[2K
| RMSProp | epoch: 006 | loss: 0.69347 - acc: 0.5173 -- iter: 0864/1350
[A[ATraining Step: 243  | total loss: [1m[32m0.69256[0m[0m | time: 22.734s
[2K
| RMSProp | epoch: 006 | loss: 0.69256 - acc: 0.5281 -- iter: 0896/1350
[A[ATraining Step: 244  | total loss: [1m[32m0.69215[0m[0m | time: 23.604s
[2K
| RMSProp | epoch: 006 | loss: 0.69215 - acc: 0.5315 -- iter: 0928/1350
[A[ATraining Step: 245  | total loss: [1m[32m0.69265[0m[0m | time: 24.468s
[2K
| RMSProp | epoch: 006 | loss: 0.69265 - acc: 0.5253 -- iter: 0960/1350
[A[ATraining Step: 246  | total loss: [1m[32m0.69330[0m[0m | time: 25.331s
[2K
| RMSProp | epoch: 006 | loss: 0.69330 - acc: 0.5165 -- iter: 0992/1350
[A[ATraining Step: 247  | total loss: [1m[32m0.69327[0m[0m | time: 26.153s
[2K
| RMSProp | epoch: 006 | loss: 0.69327 - acc: 0.5148 -- iter: 1024/1350
[A[ATraining Step: 248  | total loss: [1m[32m0.69208[0m[0m | time: 27.107s
[2K
| RMSProp | epoch: 006 | loss: 0.69208 - acc: 0.5321 -- iter: 1056/1350
[A[ATraining Step: 249  | total loss: [1m[32m0.69289[0m[0m | time: 28.076s
[2K
| RMSProp | epoch: 006 | loss: 0.69289 - acc: 0.5226 -- iter: 1088/1350
[A[ATraining Step: 250  | total loss: [1m[32m0.69324[0m[0m | time: 28.786s
[2K
| RMSProp | epoch: 006 | loss: 0.69324 - acc: 0.5173 -- iter: 1120/1350
[A[ATraining Step: 251  | total loss: [1m[32m0.69211[0m[0m | time: 29.654s
[2K
| RMSProp | epoch: 006 | loss: 0.69211 - acc: 0.5312 -- iter: 1152/1350
[A[ATraining Step: 252  | total loss: [1m[32m0.69235[0m[0m | time: 30.496s
[2K
| RMSProp | epoch: 006 | loss: 0.69235 - acc: 0.5280 -- iter: 1184/1350
[A[ATraining Step: 253  | total loss: [1m[32m0.69224[0m[0m | time: 31.361s
[2K
| RMSProp | epoch: 006 | loss: 0.69224 - acc: 0.5284 -- iter: 1216/1350
[A[ATraining Step: 254  | total loss: [1m[32m0.69355[0m[0m | time: 32.185s
[2K
| RMSProp | epoch: 006 | loss: 0.69355 - acc: 0.5130 -- iter: 1248/1350
[A[ATraining Step: 255  | total loss: [1m[32m0.69415[0m[0m | time: 33.040s
[2K
| RMSProp | epoch: 006 | loss: 0.69415 - acc: 0.5023 -- iter: 1280/1350
[A[ATraining Step: 256  | total loss: [1m[32m0.69389[0m[0m | time: 33.888s
[2K
| RMSProp | epoch: 006 | loss: 0.69389 - acc: 0.5052 -- iter: 1312/1350
[A[ATraining Step: 257  | total loss: [1m[32m0.69400[0m[0m | time: 34.772s
[2K
| RMSProp | epoch: 006 | loss: 0.69400 - acc: 0.4985 -- iter: 1344/1350
[A[ATraining Step: 258  | total loss: [1m[32m0.69354[0m[0m | time: 37.459s
[2K
| RMSProp | epoch: 006 | loss: 0.69354 - acc: 0.5236 | val_loss: 0.69151 - val_acc: 0.5296 -- iter: 1350/1350
--
Training Step: 259  | total loss: [1m[32m0.69455[0m[0m | time: 0.885s
[2K
| RMSProp | epoch: 007 | loss: 0.69455 - acc: 0.5213 -- iter: 0032/1350
[A[ATraining Step: 260  | total loss: [1m[32m0.69397[0m[0m | time: 1.811s
[2K
| RMSProp | epoch: 007 | loss: 0.69397 - acc: 0.5379 -- iter: 0064/1350
[A[ATraining Step: 261  | total loss: [1m[32m0.69371[0m[0m | time: 2.718s
[2K
| RMSProp | epoch: 007 | loss: 0.69371 - acc: 0.5341 -- iter: 0096/1350
[A[ATraining Step: 262  | total loss: [1m[32m0.69339[0m[0m | time: 3.601s
[2K
| RMSProp | epoch: 007 | loss: 0.69339 - acc: 0.5307 -- iter: 0128/1350
[A[ATraining Step: 263  | total loss: [1m[32m0.69359[0m[0m | time: 3.783s
[2K
| RMSProp | epoch: 007 | loss: 0.69359 - acc: 0.5214 -- iter: 0160/1350
[A[ATraining Step: 264  | total loss: [1m[32m0.69309[0m[0m | time: 3.969s
[2K
| RMSProp | epoch: 007 | loss: 0.69309 - acc: 0.5526 -- iter: 0192/1350
[A[ATraining Step: 265  | total loss: [1m[32m0.69241[0m[0m | time: 4.897s
[2K
| RMSProp | epoch: 007 | loss: 0.69241 - acc: 0.5640 -- iter: 0224/1350
[A[ATraining Step: 266  | total loss: [1m[32m0.69230[0m[0m | time: 5.845s
[2K
| RMSProp | epoch: 007 | loss: 0.69230 - acc: 0.5544 -- iter: 0256/1350
[A[ATraining Step: 267  | total loss: [1m[32m0.69266[0m[0m | time: 6.779s
[2K
| RMSProp | epoch: 007 | loss: 0.69266 - acc: 0.5459 -- iter: 0288/1350
[A[ATraining Step: 268  | total loss: [1m[32m0.69197[0m[0m | time: 7.538s
[2K
| RMSProp | epoch: 007 | loss: 0.69197 - acc: 0.5757 -- iter: 0320/1350
[A[ATraining Step: 269  | total loss: [1m[32m0.69104[0m[0m | time: 8.437s
[2K
| RMSProp | epoch: 007 | loss: 0.69104 - acc: 0.5806 -- iter: 0352/1350
[A[ATraining Step: 270  | total loss: [1m[32m0.69116[0m[0m | time: 9.287s
[2K
| RMSProp | epoch: 007 | loss: 0.69116 - acc: 0.5694 -- iter: 0384/1350
[A[ATraining Step: 271  | total loss: [1m[32m0.69176[0m[0m | time: 10.100s
[2K
| RMSProp | epoch: 007 | loss: 0.69176 - acc: 0.5593 -- iter: 0416/1350
[A[ATraining Step: 272  | total loss: [1m[32m0.69148[0m[0m | time: 10.971s
[2K
| RMSProp | epoch: 007 | loss: 0.69148 - acc: 0.5534 -- iter: 0448/1350
[A[ATraining Step: 273  | total loss: [1m[32m0.68970[0m[0m | time: 11.848s
[2K
| RMSProp | epoch: 007 | loss: 0.68970 - acc: 0.5543 -- iter: 0480/1350
[A[ATraining Step: 274  | total loss: [1m[32m0.70241[0m[0m | time: 12.728s
[2K
| RMSProp | epoch: 007 | loss: 0.70241 - acc: 0.5333 -- iter: 0512/1350
[A[ATraining Step: 275  | total loss: [1m[32m0.70158[0m[0m | time: 13.623s
[2K
| RMSProp | epoch: 007 | loss: 0.70158 - acc: 0.5299 -- iter: 0544/1350
[A[ATraining Step: 276  | total loss: [1m[32m0.70096[0m[0m | time: 14.511s
[2K
| RMSProp | epoch: 007 | loss: 0.70096 - acc: 0.5238 -- iter: 0576/1350
[A[ATraining Step: 277  | total loss: [1m[32m0.69946[0m[0m | time: 15.524s
[2K
| RMSProp | epoch: 007 | loss: 0.69946 - acc: 0.5277 -- iter: 0608/1350
[A[ATraining Step: 278  | total loss: [1m[32m0.69838[0m[0m | time: 16.517s
[2K
| RMSProp | epoch: 007 | loss: 0.69838 - acc: 0.5249 -- iter: 0640/1350
[A[ATraining Step: 279  | total loss: [1m[32m0.69696[0m[0m | time: 17.267s
[2K
| RMSProp | epoch: 007 | loss: 0.69696 - acc: 0.5443 -- iter: 0672/1350
[A[ATraining Step: 280  | total loss: [1m[32m0.69496[0m[0m | time: 18.080s
[2K
| RMSProp | epoch: 007 | loss: 0.69496 - acc: 0.5617 -- iter: 0704/1350
[A[ATraining Step: 281  | total loss: [1m[32m0.69289[0m[0m | time: 18.949s
[2K
| RMSProp | epoch: 007 | loss: 0.69289 - acc: 0.5743 -- iter: 0736/1350
[A[ATraining Step: 282  | total loss: [1m[32m0.69283[0m[0m | time: 19.874s
[2K
| RMSProp | epoch: 007 | loss: 0.69283 - acc: 0.5700 -- iter: 0768/1350
[A[ATraining Step: 283  | total loss: [1m[32m0.69180[0m[0m | time: 20.722s
[2K
| RMSProp | epoch: 007 | loss: 0.69180 - acc: 0.5693 -- iter: 0800/1350
[A[ATraining Step: 284  | total loss: [1m[32m0.69033[0m[0m | time: 21.592s
[2K
| RMSProp | epoch: 007 | loss: 0.69033 - acc: 0.5748 -- iter: 0832/1350
[A[ATraining Step: 285  | total loss: [1m[32m0.69028[0m[0m | time: 22.511s
[2K
| RMSProp | epoch: 007 | loss: 0.69028 - acc: 0.5736 -- iter: 0864/1350
[A[ATraining Step: 286  | total loss: [1m[32m0.69481[0m[0m | time: 23.436s
[2K
| RMSProp | epoch: 007 | loss: 0.69481 - acc: 0.5537 -- iter: 0896/1350
[A[ATraining Step: 287  | total loss: [1m[32m0.69446[0m[0m | time: 24.224s
[2K
| RMSProp | epoch: 007 | loss: 0.69446 - acc: 0.5452 -- iter: 0928/1350
[A[ATraining Step: 288  | total loss: [1m[32m0.69224[0m[0m | time: 25.184s
[2K
| RMSProp | epoch: 007 | loss: 0.69224 - acc: 0.5532 -- iter: 0960/1350
[A[ATraining Step: 289  | total loss: [1m[32m0.69039[0m[0m | time: 26.155s
[2K
| RMSProp | epoch: 007 | loss: 0.69039 - acc: 0.5635 -- iter: 0992/1350
[A[ATraining Step: 290  | total loss: [1m[32m0.68499[0m[0m | time: 27.048s
[2K
| RMSProp | epoch: 007 | loss: 0.68499 - acc: 0.5790 -- iter: 1024/1350
[A[ATraining Step: 291  | total loss: [1m[32m0.68188[0m[0m | time: 27.782s
[2K
| RMSProp | epoch: 007 | loss: 0.68188 - acc: 0.5774 -- iter: 1056/1350
[A[ATraining Step: 292  | total loss: [1m[32m0.68538[0m[0m | time: 28.623s
[2K
| RMSProp | epoch: 007 | loss: 0.68538 - acc: 0.5634 -- iter: 1088/1350
[A[ATraining Step: 293  | total loss: [1m[32m0.68622[0m[0m | time: 29.445s
[2K
| RMSProp | epoch: 007 | loss: 0.68622 - acc: 0.5571 -- iter: 1120/1350
[A[ATraining Step: 294  | total loss: [1m[32m0.68913[0m[0m | time: 30.279s
[2K
| RMSProp | epoch: 007 | loss: 0.68913 - acc: 0.5357 -- iter: 1152/1350
[A[ATraining Step: 295  | total loss: [1m[32m0.68871[0m[0m | time: 31.125s
[2K
| RMSProp | epoch: 007 | loss: 0.68871 - acc: 0.5447 -- iter: 1184/1350
[A[ATraining Step: 296  | total loss: [1m[32m0.69009[0m[0m | time: 32.028s
[2K
| RMSProp | epoch: 007 | loss: 0.69009 - acc: 0.5308 -- iter: 1216/1350
[A[ATraining Step: 297  | total loss: [1m[32m0.68886[0m[0m | time: 32.896s
[2K
| RMSProp | epoch: 007 | loss: 0.68886 - acc: 0.5340 -- iter: 1248/1350
[A[ATraining Step: 298  | total loss: [1m[32m0.70138[0m[0m | time: 33.732s
[2K
| RMSProp | epoch: 007 | loss: 0.70138 - acc: 0.5275 -- iter: 1280/1350
[A[ATraining Step: 299  | total loss: [1m[32m0.69971[0m[0m | time: 34.579s
[2K
| RMSProp | epoch: 007 | loss: 0.69971 - acc: 0.5341 -- iter: 1312/1350
[A[ATraining Step: 300  | total loss: [1m[32m0.69740[0m[0m | time: 35.535s
[2K
| RMSProp | epoch: 007 | loss: 0.69740 - acc: 0.5588 -- iter: 1344/1350
[A[ATraining Step: 301  | total loss: [1m[32m0.69505[0m[0m | time: 38.256s
[2K
| RMSProp | epoch: 007 | loss: 0.69505 - acc: 0.5686 | val_loss: 0.68263 - val_acc: 0.5556 -- iter: 1350/1350
--
Training Step: 302  | total loss: [1m[32m0.69391[0m[0m | time: 0.932s
[2K
| RMSProp | epoch: 008 | loss: 0.69391 - acc: 0.5711 -- iter: 0032/1350
[A[ATraining Step: 303  | total loss: [1m[32m0.69465[0m[0m | time: 1.826s
[2K
| RMSProp | epoch: 008 | loss: 0.69465 - acc: 0.5546 -- iter: 0064/1350
[A[ATraining Step: 304  | total loss: [1m[32m0.69157[0m[0m | time: 2.591s
[2K
| RMSProp | epoch: 008 | loss: 0.69157 - acc: 0.5773 -- iter: 0096/1350
[A[ATraining Step: 305  | total loss: [1m[32m0.69225[0m[0m | time: 3.552s
[2K
| RMSProp | epoch: 008 | loss: 0.69225 - acc: 0.5695 -- iter: 0128/1350
[A[ATraining Step: 306  | total loss: [1m[32m0.68992[0m[0m | time: 4.516s
[2K
| RMSProp | epoch: 008 | loss: 0.68992 - acc: 0.5813 -- iter: 0160/1350
[A[ATraining Step: 307  | total loss: [1m[32m0.68635[0m[0m | time: 4.737s
[2K
| RMSProp | epoch: 008 | loss: 0.68635 - acc: 0.6076 -- iter: 0192/1350
[A[ATraining Step: 308  | total loss: [1m[32m0.68171[0m[0m | time: 4.975s
[2K
| RMSProp | epoch: 008 | loss: 0.68171 - acc: 0.5968 -- iter: 0224/1350
[A[ATraining Step: 309  | total loss: [1m[32m0.67146[0m[0m | time: 5.676s
[2K
| RMSProp | epoch: 008 | loss: 0.67146 - acc: 0.6038 -- iter: 0256/1350
[A[ATraining Step: 310  | total loss: [1m[32m0.66855[0m[0m | time: 6.481s
[2K
| RMSProp | epoch: 008 | loss: 0.66855 - acc: 0.6153 -- iter: 0288/1350
[A[ATraining Step: 311  | total loss: [1m[32m0.68106[0m[0m | time: 7.315s
[2K
| RMSProp | epoch: 008 | loss: 0.68106 - acc: 0.6163 -- iter: 0320/1350
[A[ATraining Step: 312  | total loss: [1m[32m0.68307[0m[0m | time: 8.149s
[2K
| RMSProp | epoch: 008 | loss: 0.68307 - acc: 0.5984 -- iter: 0352/1350
[A[ATraining Step: 313  | total loss: [1m[32m0.67944[0m[0m | time: 8.984s
[2K
| RMSProp | epoch: 008 | loss: 0.67944 - acc: 0.5979 -- iter: 0384/1350
[A[ATraining Step: 314  | total loss: [1m[32m0.67472[0m[0m | time: 9.865s
[2K
| RMSProp | epoch: 008 | loss: 0.67472 - acc: 0.6163 -- iter: 0416/1350
[A[ATraining Step: 315  | total loss: [1m[32m0.66921[0m[0m | time: 10.734s
[2K
| RMSProp | epoch: 008 | loss: 0.66921 - acc: 0.6296 -- iter: 0448/1350
[A[ATraining Step: 316  | total loss: [1m[32m0.66631[0m[0m | time: 11.656s
[2K
| RMSProp | epoch: 008 | loss: 0.66631 - acc: 0.6292 -- iter: 0480/1350
[A[ATraining Step: 317  | total loss: [1m[32m0.66086[0m[0m | time: 12.513s
[2K
| RMSProp | epoch: 008 | loss: 0.66086 - acc: 0.6475 -- iter: 0512/1350
[A[ATraining Step: 318  | total loss: [1m[32m0.64982[0m[0m | time: 13.374s
[2K
| RMSProp | epoch: 008 | loss: 0.64982 - acc: 0.6546 -- iter: 0544/1350
[A[ATraining Step: 319  | total loss: [1m[32m0.65138[0m[0m | time: 14.324s
[2K
| RMSProp | epoch: 008 | loss: 0.65138 - acc: 0.6485 -- iter: 0576/1350
[A[ATraining Step: 320  | total loss: [1m[32m0.66250[0m[0m | time: 15.362s
[2K
| RMSProp | epoch: 008 | loss: 0.66250 - acc: 0.6368 -- iter: 0608/1350
[A[ATraining Step: 321  | total loss: [1m[32m0.66208[0m[0m | time: 16.039s
[2K
| RMSProp | epoch: 008 | loss: 0.66208 - acc: 0.6356 -- iter: 0640/1350
[A[ATraining Step: 322  | total loss: [1m[32m0.67242[0m[0m | time: 16.857s
[2K
| RMSProp | epoch: 008 | loss: 0.67242 - acc: 0.6096 -- iter: 0672/1350
[A[ATraining Step: 323  | total loss: [1m[32m0.67192[0m[0m | time: 17.739s
[2K
| RMSProp | epoch: 008 | loss: 0.67192 - acc: 0.6111 -- iter: 0704/1350
[A[ATraining Step: 324  | total loss: [1m[32m0.66592[0m[0m | time: 18.635s
[2K
| RMSProp | epoch: 008 | loss: 0.66592 - acc: 0.6312 -- iter: 0736/1350
[A[ATraining Step: 325  | total loss: [1m[32m0.66229[0m[0m | time: 19.465s
[2K
| RMSProp | epoch: 008 | loss: 0.66229 - acc: 0.6369 -- iter: 0768/1350
[A[ATraining Step: 326  | total loss: [1m[32m0.65224[0m[0m | time: 20.403s
[2K
| RMSProp | epoch: 008 | loss: 0.65224 - acc: 0.6607 -- iter: 0800/1350
[A[ATraining Step: 327  | total loss: [1m[32m0.65200[0m[0m | time: 21.306s
[2K
| RMSProp | epoch: 008 | loss: 0.65200 - acc: 0.6634 -- iter: 0832/1350
[A[ATraining Step: 328  | total loss: [1m[32m0.65749[0m[0m | time: 22.187s
[2K
| RMSProp | epoch: 008 | loss: 0.65749 - acc: 0.6502 -- iter: 0864/1350
[A[ATraining Step: 329  | total loss: [1m[32m0.65971[0m[0m | time: 23.014s
[2K
| RMSProp | epoch: 008 | loss: 0.65971 - acc: 0.6383 -- iter: 0896/1350
[A[ATraining Step: 330  | total loss: [1m[32m0.65695[0m[0m | time: 24.000s
[2K
| RMSProp | epoch: 008 | loss: 0.65695 - acc: 0.6432 -- iter: 0928/1350
[A[ATraining Step: 331  | total loss: [1m[32m0.65018[0m[0m | time: 24.954s
[2K
| RMSProp | epoch: 008 | loss: 0.65018 - acc: 0.6507 -- iter: 0960/1350
[A[ATraining Step: 332  | total loss: [1m[32m0.65397[0m[0m | time: 25.801s
[2K
| RMSProp | epoch: 008 | loss: 0.65397 - acc: 0.6419 -- iter: 0992/1350
[A[ATraining Step: 333  | total loss: [1m[32m0.64635[0m[0m | time: 26.578s
[2K
| RMSProp | epoch: 008 | loss: 0.64635 - acc: 0.6652 -- iter: 1024/1350
[A[ATraining Step: 334  | total loss: [1m[32m0.63552[0m[0m | time: 27.406s
[2K
| RMSProp | epoch: 008 | loss: 0.63552 - acc: 0.6831 -- iter: 1056/1350
[A[ATraining Step: 335  | total loss: [1m[32m0.62916[0m[0m | time: 28.254s
[2K
| RMSProp | epoch: 008 | loss: 0.62916 - acc: 0.6898 -- iter: 1088/1350
[A[ATraining Step: 336  | total loss: [1m[32m0.61752[0m[0m | time: 29.087s
[2K
| RMSProp | epoch: 008 | loss: 0.61752 - acc: 0.6989 -- iter: 1120/1350
[A[ATraining Step: 337  | total loss: [1m[32m0.63691[0m[0m | time: 29.979s
[2K
| RMSProp | epoch: 008 | loss: 0.63691 - acc: 0.6853 -- iter: 1152/1350
[A[ATraining Step: 338  | total loss: [1m[32m0.63016[0m[0m | time: 30.897s
[2K
| RMSProp | epoch: 008 | loss: 0.63016 - acc: 0.6761 -- iter: 1184/1350
[A[ATraining Step: 339  | total loss: [1m[32m0.63067[0m[0m | time: 31.742s
[2K
| RMSProp | epoch: 008 | loss: 0.63067 - acc: 0.6804 -- iter: 1216/1350
[A[ATraining Step: 340  | total loss: [1m[32m0.62584[0m[0m | time: 32.604s
[2K
| RMSProp | epoch: 008 | loss: 0.62584 - acc: 0.6873 -- iter: 1248/1350
[A[ATraining Step: 341  | total loss: [1m[32m0.61274[0m[0m | time: 33.385s
[2K
| RMSProp | epoch: 008 | loss: 0.61274 - acc: 0.6967 -- iter: 1280/1350
[A[ATraining Step: 342  | total loss: [1m[32m0.62907[0m[0m | time: 34.349s
[2K
| RMSProp | epoch: 008 | loss: 0.62907 - acc: 0.6864 -- iter: 1312/1350
[A[ATraining Step: 343  | total loss: [1m[32m0.63572[0m[0m | time: 35.309s
[2K
| RMSProp | epoch: 008 | loss: 0.63572 - acc: 0.6709 -- iter: 1344/1350
[A[ATraining Step: 344  | total loss: [1m[32m0.63625[0m[0m | time: 37.744s
[2K
| RMSProp | epoch: 008 | loss: 0.63625 - acc: 0.6695 | val_loss: 0.55130 - val_acc: 0.7187 -- iter: 1350/1350
--
Training Step: 345  | total loss: [1m[32m0.62196[0m[0m | time: 0.793s
[2K
| RMSProp | epoch: 009 | loss: 0.62196 - acc: 0.6806 -- iter: 0032/1350
[A[ATraining Step: 346  | total loss: [1m[32m0.61941[0m[0m | time: 1.813s
[2K
| RMSProp | epoch: 009 | loss: 0.61941 - acc: 0.6844 -- iter: 0064/1350
[A[ATraining Step: 347  | total loss: [1m[32m0.63992[0m[0m | time: 2.811s
[2K
| RMSProp | epoch: 009 | loss: 0.63992 - acc: 0.6660 -- iter: 0096/1350
[A[ATraining Step: 348  | total loss: [1m[32m0.63543[0m[0m | time: 3.530s
[2K
| RMSProp | epoch: 009 | loss: 0.63543 - acc: 0.6682 -- iter: 0128/1350
[A[ATraining Step: 349  | total loss: [1m[32m0.64046[0m[0m | time: 4.322s
[2K
| RMSProp | epoch: 009 | loss: 0.64046 - acc: 0.6545 -- iter: 0160/1350
[A[ATraining Step: 350  | total loss: [1m[32m0.63605[0m[0m | time: 5.127s
[2K
| RMSProp | epoch: 009 | loss: 0.63605 - acc: 0.6546 -- iter: 0192/1350
[A[ATraining Step: 351  | total loss: [1m[32m0.62929[0m[0m | time: 5.329s
[2K
| RMSProp | epoch: 009 | loss: 0.62929 - acc: 0.6611 -- iter: 0224/1350
[A[ATraining Step: 352  | total loss: [1m[32m0.61670[0m[0m | time: 5.531s
[2K
| RMSProp | epoch: 009 | loss: 0.61670 - acc: 0.6616 -- iter: 0256/1350
[A[ATraining Step: 353  | total loss: [1m[32m0.59955[0m[0m | time: 6.395s
[2K
| RMSProp | epoch: 009 | loss: 0.59955 - acc: 0.6788 -- iter: 0288/1350
[A[ATraining Step: 354  | total loss: [1m[32m0.60324[0m[0m | time: 7.195s
[2K
| RMSProp | epoch: 009 | loss: 0.60324 - acc: 0.6672 -- iter: 0320/1350
[A[ATraining Step: 355  | total loss: [1m[32m0.60645[0m[0m | time: 8.068s
[2K
| RMSProp | epoch: 009 | loss: 0.60645 - acc: 0.6661 -- iter: 0352/1350
[A[ATraining Step: 356  | total loss: [1m[32m0.59465[0m[0m | time: 8.944s
[2K
| RMSProp | epoch: 009 | loss: 0.59465 - acc: 0.6901 -- iter: 0384/1350
[A[ATraining Step: 357  | total loss: [1m[32m0.58625[0m[0m | time: 9.867s
[2K
| RMSProp | epoch: 009 | loss: 0.58625 - acc: 0.6898 -- iter: 0416/1350
[A[ATraining Step: 358  | total loss: [1m[32m0.61081[0m[0m | time: 10.741s
[2K
| RMSProp | epoch: 009 | loss: 0.61081 - acc: 0.6615 -- iter: 0448/1350
[A[ATraining Step: 359  | total loss: [1m[32m0.59861[0m[0m | time: 11.636s
[2K
| RMSProp | epoch: 009 | loss: 0.59861 - acc: 0.6672 -- iter: 0480/1350
[A[ATraining Step: 360  | total loss: [1m[32m0.59537[0m[0m | time: 12.593s
[2K
| RMSProp | epoch: 009 | loss: 0.59537 - acc: 0.6692 -- iter: 0512/1350
[A[ATraining Step: 361  | total loss: [1m[32m0.60420[0m[0m | time: 13.545s
[2K
| RMSProp | epoch: 009 | loss: 0.60420 - acc: 0.6617 -- iter: 0544/1350
[A[ATraining Step: 362  | total loss: [1m[32m0.61497[0m[0m | time: 14.212s
[2K
| RMSProp | epoch: 009 | loss: 0.61497 - acc: 0.6486 -- iter: 0576/1350
[A[ATraining Step: 363  | total loss: [1m[32m0.60942[0m[0m | time: 15.010s
[2K
| RMSProp | epoch: 009 | loss: 0.60942 - acc: 0.6588 -- iter: 0608/1350
[A[ATraining Step: 364  | total loss: [1m[32m0.60081[0m[0m | time: 15.859s
[2K
| RMSProp | epoch: 009 | loss: 0.60081 - acc: 0.6710 -- iter: 0640/1350
[A[ATraining Step: 365  | total loss: [1m[32m0.59239[0m[0m | time: 16.685s
[2K
| RMSProp | epoch: 009 | loss: 0.59239 - acc: 0.6789 -- iter: 0672/1350
[A[ATraining Step: 366  | total loss: [1m[32m0.58835[0m[0m | time: 17.578s
[2K
| RMSProp | epoch: 009 | loss: 0.58835 - acc: 0.6860 -- iter: 0704/1350
[A[ATraining Step: 367  | total loss: [1m[32m0.59331[0m[0m | time: 18.428s
[2K
| RMSProp | epoch: 009 | loss: 0.59331 - acc: 0.6768 -- iter: 0736/1350
[A[ATraining Step: 368  | total loss: [1m[32m0.60232[0m[0m | time: 19.323s
[2K
| RMSProp | epoch: 009 | loss: 0.60232 - acc: 0.6591 -- iter: 0768/1350
[A[ATraining Step: 369  | total loss: [1m[32m0.60467[0m[0m | time: 20.270s
[2K
| RMSProp | epoch: 009 | loss: 0.60467 - acc: 0.6526 -- iter: 0800/1350
[A[ATraining Step: 370  | total loss: [1m[32m0.60636[0m[0m | time: 21.135s
[2K
| RMSProp | epoch: 009 | loss: 0.60636 - acc: 0.6529 -- iter: 0832/1350
[A[ATraining Step: 371  | total loss: [1m[32m0.59687[0m[0m | time: 21.996s
[2K
| RMSProp | epoch: 009 | loss: 0.59687 - acc: 0.6627 -- iter: 0864/1350
[A[ATraining Step: 372  | total loss: [1m[32m0.59180[0m[0m | time: 22.982s
[2K
| RMSProp | epoch: 009 | loss: 0.59180 - acc: 0.6776 -- iter: 0896/1350
[A[ATraining Step: 373  | total loss: [1m[32m0.57719[0m[0m | time: 23.968s
[2K
| RMSProp | epoch: 009 | loss: 0.57719 - acc: 0.7005 -- iter: 0928/1350
[A[ATraining Step: 374  | total loss: [1m[32m0.57963[0m[0m | time: 24.660s
[2K
| RMSProp | epoch: 009 | loss: 0.57963 - acc: 0.6992 -- iter: 0960/1350
[A[ATraining Step: 375  | total loss: [1m[32m0.56864[0m[0m | time: 25.480s
[2K
| RMSProp | epoch: 009 | loss: 0.56864 - acc: 0.7074 -- iter: 0992/1350
[A[ATraining Step: 376  | total loss: [1m[32m0.57369[0m[0m | time: 26.302s
[2K
| RMSProp | epoch: 009 | loss: 0.57369 - acc: 0.7054 -- iter: 1024/1350
[A[ATraining Step: 377  | total loss: [1m[32m0.59326[0m[0m | time: 27.157s
[2K
| RMSProp | epoch: 009 | loss: 0.59326 - acc: 0.6817 -- iter: 1056/1350
[A[ATraining Step: 378  | total loss: [1m[32m0.57730[0m[0m | time: 28.071s
[2K
| RMSProp | epoch: 009 | loss: 0.57730 - acc: 0.7011 -- iter: 1088/1350
[A[ATraining Step: 379  | total loss: [1m[32m0.56957[0m[0m | time: 28.949s
[2K
| RMSProp | epoch: 009 | loss: 0.56957 - acc: 0.7060 -- iter: 1120/1350
[A[ATraining Step: 380  | total loss: [1m[32m0.56666[0m[0m | time: 29.830s
[2K
| RMSProp | epoch: 009 | loss: 0.56666 - acc: 0.7104 -- iter: 1152/1350
[A[ATraining Step: 381  | total loss: [1m[32m0.56096[0m[0m | time: 30.746s
[2K
| RMSProp | epoch: 009 | loss: 0.56096 - acc: 0.7175 -- iter: 1184/1350
[A[ATraining Step: 382  | total loss: [1m[32m0.55599[0m[0m | time: 31.594s
[2K
| RMSProp | epoch: 009 | loss: 0.55599 - acc: 0.7176 -- iter: 1216/1350
[A[ATraining Step: 383  | total loss: [1m[32m0.57107[0m[0m | time: 32.531s
[2K
| RMSProp | epoch: 009 | loss: 0.57107 - acc: 0.7021 -- iter: 1248/1350
[A[ATraining Step: 384  | total loss: [1m[32m0.57282[0m[0m | time: 33.525s
[2K
| RMSProp | epoch: 009 | loss: 0.57282 - acc: 0.7037 -- iter: 1280/1350
[A[ATraining Step: 385  | total loss: [1m[32m0.57243[0m[0m | time: 34.461s
[2K
| RMSProp | epoch: 009 | loss: 0.57243 - acc: 0.7084 -- iter: 1312/1350
[A[ATraining Step: 386  | total loss: [1m[32m0.56296[0m[0m | time: 35.214s
[2K
| RMSProp | epoch: 009 | loss: 0.56296 - acc: 0.7157 -- iter: 1344/1350
[A[ATraining Step: 387  | total loss: [1m[32m0.55814[0m[0m | time: 37.845s
[2K
| RMSProp | epoch: 009 | loss: 0.55814 - acc: 0.7128 | val_loss: 0.46978 - val_acc: 0.8132 -- iter: 1350/1350
--
Training Step: 388  | total loss: [1m[32m0.54707[0m[0m | time: 0.817s
[2K
| RMSProp | epoch: 010 | loss: 0.54707 - acc: 0.7228 -- iter: 0032/1350
[A[ATraining Step: 389  | total loss: [1m[32m0.54680[0m[0m | time: 1.681s
[2K
| RMSProp | epoch: 010 | loss: 0.54680 - acc: 0.7193 -- iter: 0064/1350
[A[ATraining Step: 390  | total loss: [1m[32m0.55213[0m[0m | time: 2.687s
[2K
| RMSProp | epoch: 010 | loss: 0.55213 - acc: 0.7192 -- iter: 0096/1350
[A[ATraining Step: 391  | total loss: [1m[32m0.62545[0m[0m | time: 3.604s
[2K
| RMSProp | epoch: 010 | loss: 0.62545 - acc: 0.6942 -- iter: 0128/1350
[A[ATraining Step: 392  | total loss: [1m[32m0.61323[0m[0m | time: 4.315s
[2K
| RMSProp | epoch: 010 | loss: 0.61323 - acc: 0.7123 -- iter: 0160/1350
[A[ATraining Step: 393  | total loss: [1m[32m0.60715[0m[0m | time: 5.154s
[2K
| RMSProp | epoch: 010 | loss: 0.60715 - acc: 0.7129 -- iter: 0192/1350
[A[ATraining Step: 394  | total loss: [1m[32m0.58822[0m[0m | time: 6.012s
[2K
| RMSProp | epoch: 010 | loss: 0.58822 - acc: 0.7291 -- iter: 0224/1350
[A[ATraining Step: 395  | total loss: [1m[32m0.57004[0m[0m | time: 6.209s
[2K
| RMSProp | epoch: 010 | loss: 0.57004 - acc: 0.7437 -- iter: 0256/1350
[A[ATraining Step: 396  | total loss: [1m[32m0.53746[0m[0m | time: 6.402s
[2K
| RMSProp | epoch: 010 | loss: 0.53746 - acc: 0.7693 -- iter: 0288/1350
[A[ATraining Step: 397  | total loss: [1m[32m0.52283[0m[0m | time: 7.256s
[2K
| RMSProp | epoch: 010 | loss: 0.52283 - acc: 0.7757 -- iter: 0320/1350
[A[ATraining Step: 398  | total loss: [1m[32m0.53505[0m[0m | time: 8.132s
[2K
| RMSProp | epoch: 010 | loss: 0.53505 - acc: 0.7732 -- iter: 0352/1350
[A[ATraining Step: 399  | total loss: [1m[32m0.52723[0m[0m | time: 9.088s
[2K
| RMSProp | epoch: 010 | loss: 0.52723 - acc: 0.7677 -- iter: 0384/1350
[A[ATraining Step: 400  | total loss: [1m[32m0.51623[0m[0m | time: 11.796s
[2K
| RMSProp | epoch: 010 | loss: 0.51623 - acc: 0.7753 | val_loss: 0.44405 - val_acc: 0.8180 -- iter: 0416/1350
--
Training Step: 401  | total loss: [1m[32m0.50996[0m[0m | time: 12.525s
[2K
| RMSProp | epoch: 010 | loss: 0.50996 - acc: 0.7728 -- iter: 0448/1350
[A[ATraining Step: 402  | total loss: [1m[32m0.49685[0m[0m | time: 13.418s
[2K
| RMSProp | epoch: 010 | loss: 0.49685 - acc: 0.7861 -- iter: 0480/1350
[A[ATraining Step: 403  | total loss: [1m[32m0.48828[0m[0m | time: 14.251s
[2K
| RMSProp | epoch: 010 | loss: 0.48828 - acc: 0.7888 -- iter: 0512/1350
[A[ATraining Step: 404  | total loss: [1m[32m0.49530[0m[0m | time: 15.060s
[2K
| RMSProp | epoch: 010 | loss: 0.49530 - acc: 0.7849 -- iter: 0544/1350
[A[ATraining Step: 405  | total loss: [1m[32m0.51559[0m[0m | time: 15.881s
[2K
| RMSProp | epoch: 010 | loss: 0.51559 - acc: 0.7627 -- iter: 0576/1350
[A[ATraining Step: 406  | total loss: [1m[32m0.50762[0m[0m | time: 16.796s
[2K
| RMSProp | epoch: 010 | loss: 0.50762 - acc: 0.7645 -- iter: 0608/1350
[A[ATraining Step: 407  | total loss: [1m[32m0.51504[0m[0m | time: 17.735s
[2K
| RMSProp | epoch: 010 | loss: 0.51504 - acc: 0.7568 -- iter: 0640/1350
[A[ATraining Step: 408  | total loss: [1m[32m0.52707[0m[0m | time: 18.610s
[2K
| RMSProp | epoch: 010 | loss: 0.52707 - acc: 0.7530 -- iter: 0672/1350
[A[ATraining Step: 409  | total loss: [1m[32m0.54099[0m[0m | time: 19.437s
[2K
| RMSProp | epoch: 010 | loss: 0.54099 - acc: 0.7340 -- iter: 0704/1350
[A[ATraining Step: 410  | total loss: [1m[32m0.54612[0m[0m | time: 20.274s
[2K
| RMSProp | epoch: 010 | loss: 0.54612 - acc: 0.7387 -- iter: 0736/1350
[A[ATraining Step: 411  | total loss: [1m[32m0.53781[0m[0m | time: 21.265s
[2K
| RMSProp | epoch: 010 | loss: 0.53781 - acc: 0.7398 -- iter: 0768/1350
[A[ATraining Step: 412  | total loss: [1m[32m0.53421[0m[0m | time: 22.216s
[2K
| RMSProp | epoch: 010 | loss: 0.53421 - acc: 0.7377 -- iter: 0800/1350
[A[ATraining Step: 413  | total loss: [1m[32m0.52462[0m[0m | time: 22.911s
[2K
| RMSProp | epoch: 010 | loss: 0.52462 - acc: 0.7452 -- iter: 0832/1350
[A[ATraining Step: 414  | total loss: [1m[32m0.50843[0m[0m | time: 23.720s
[2K
| RMSProp | epoch: 010 | loss: 0.50843 - acc: 0.7613 -- iter: 0864/1350
[A[ATraining Step: 415  | total loss: [1m[32m0.50174[0m[0m | time: 24.576s
[2K
| RMSProp | epoch: 010 | loss: 0.50174 - acc: 0.7664 -- iter: 0896/1350
[A[ATraining Step: 416  | total loss: [1m[32m0.56042[0m[0m | time: 25.420s
[2K
| RMSProp | epoch: 010 | loss: 0.56042 - acc: 0.7335 -- iter: 0928/1350
[A[ATraining Step: 417  | total loss: [1m[32m0.56353[0m[0m | time: 26.255s
[2K
| RMSProp | epoch: 010 | loss: 0.56353 - acc: 0.7227 -- iter: 0960/1350
[A[ATraining Step: 418  | total loss: [1m[32m0.55966[0m[0m | time: 27.091s
[2K
| RMSProp | epoch: 010 | loss: 0.55966 - acc: 0.7254 -- iter: 0992/1350
[A[ATraining Step: 419  | total loss: [1m[32m0.55736[0m[0m | time: 28.008s
[2K
| RMSProp | epoch: 010 | loss: 0.55736 - acc: 0.7247 -- iter: 1024/1350
[A[ATraining Step: 420  | total loss: [1m[32m0.56119[0m[0m | time: 28.870s
[2K
| RMSProp | epoch: 010 | loss: 0.56119 - acc: 0.7116 -- iter: 1056/1350
[A[ATraining Step: 421  | total loss: [1m[32m0.55545[0m[0m | time: 29.750s
[2K
| RMSProp | epoch: 010 | loss: 0.55545 - acc: 0.7124 -- iter: 1088/1350
[A[ATraining Step: 422  | total loss: [1m[32m0.54867[0m[0m | time: 30.561s
[2K
| RMSProp | epoch: 010 | loss: 0.54867 - acc: 0.7224 -- iter: 1120/1350
[A[ATraining Step: 423  | total loss: [1m[32m0.53331[0m[0m | time: 31.527s
[2K
| RMSProp | epoch: 010 | loss: 0.53331 - acc: 0.7314 -- iter: 1152/1350
[A[ATraining Step: 424  | total loss: [1m[32m0.50858[0m[0m | time: 32.533s
[2K
| RMSProp | epoch: 010 | loss: 0.50858 - acc: 0.7520 -- iter: 1184/1350
[A[ATraining Step: 425  | total loss: [1m[32m0.50566[0m[0m | time: 33.258s
[2K
| RMSProp | epoch: 010 | loss: 0.50566 - acc: 0.7580 -- iter: 1216/1350
[A[ATraining Step: 426  | total loss: [1m[32m0.49957[0m[0m | time: 34.024s
[2K
| RMSProp | epoch: 010 | loss: 0.49957 - acc: 0.7541 -- iter: 1248/1350
[A[ATraining Step: 427  | total loss: [1m[32m0.50284[0m[0m | time: 34.841s
[2K
| RMSProp | epoch: 010 | loss: 0.50284 - acc: 0.7568 -- iter: 1280/1350
[A[ATraining Step: 428  | total loss: [1m[32m0.50522[0m[0m | time: 35.727s
[2K
| RMSProp | epoch: 010 | loss: 0.50522 - acc: 0.7499 -- iter: 1312/1350
[A[ATraining Step: 429  | total loss: [1m[32m0.50029[0m[0m | time: 36.611s
[2K
| RMSProp | epoch: 010 | loss: 0.50029 - acc: 0.7593 -- iter: 1344/1350
[A[ATraining Step: 430  | total loss: [1m[32m0.48230[0m[0m | time: 39.300s
[2K
| RMSProp | epoch: 010 | loss: 0.48230 - acc: 0.7709 | val_loss: 0.65320 - val_acc: 0.6478 -- iter: 1350/1350
--
Training Step: 431  | total loss: [1m[32m0.49957[0m[0m | time: 0.727s
[2K
| RMSProp | epoch: 011 | loss: 0.49957 - acc: 0.7750 -- iter: 0032/1350
[A[ATraining Step: 432  | total loss: [1m[32m0.50802[0m[0m | time: 1.523s
[2K
| RMSProp | epoch: 011 | loss: 0.50802 - acc: 0.7694 -- iter: 0064/1350
[A[ATraining Step: 433  | total loss: [1m[32m0.52419[0m[0m | time: 2.379s
[2K
| RMSProp | epoch: 011 | loss: 0.52419 - acc: 0.7581 -- iter: 0096/1350
[A[ATraining Step: 434  | total loss: [1m[32m0.50745[0m[0m | time: 3.255s
[2K
| RMSProp | epoch: 011 | loss: 0.50745 - acc: 0.7760 -- iter: 0128/1350
[A[ATraining Step: 435  | total loss: [1m[32m0.50246[0m[0m | time: 4.095s
[2K
| RMSProp | epoch: 011 | loss: 0.50246 - acc: 0.7765 -- iter: 0160/1350
[A[ATraining Step: 436  | total loss: [1m[32m0.48892[0m[0m | time: 4.977s
[2K
| RMSProp | epoch: 011 | loss: 0.48892 - acc: 0.7864 -- iter: 0192/1350
[A[ATraining Step: 437  | total loss: [1m[32m0.47740[0m[0m | time: 5.842s
[2K
| RMSProp | epoch: 011 | loss: 0.47740 - acc: 0.7952 -- iter: 0224/1350
[A[ATraining Step: 438  | total loss: [1m[32m0.47798[0m[0m | time: 6.731s
[2K
| RMSProp | epoch: 011 | loss: 0.47798 - acc: 0.7938 -- iter: 0256/1350
[A[ATraining Step: 439  | total loss: [1m[32m0.47530[0m[0m | time: 6.947s
[2K
| RMSProp | epoch: 011 | loss: 0.47530 - acc: 0.7957 -- iter: 0288/1350
[A[ATraining Step: 440  | total loss: [1m[32m0.47187[0m[0m | time: 7.149s
[2K
| RMSProp | epoch: 011 | loss: 0.47187 - acc: 0.7828 -- iter: 0320/1350
[A[ATraining Step: 441  | total loss: [1m[32m0.46655[0m[0m | time: 7.930s
[2K
| RMSProp | epoch: 011 | loss: 0.46655 - acc: 0.7879 -- iter: 0352/1350
[A[ATraining Step: 442  | total loss: [1m[32m0.51090[0m[0m | time: 8.949s
[2K
| RMSProp | epoch: 011 | loss: 0.51090 - acc: 0.7591 -- iter: 0384/1350
[A[ATraining Step: 443  | total loss: [1m[32m0.50848[0m[0m | time: 9.935s
[2K
| RMSProp | epoch: 011 | loss: 0.50848 - acc: 0.7550 -- iter: 0416/1350
[A[ATraining Step: 444  | total loss: [1m[32m0.49618[0m[0m | time: 10.775s
[2K
| RMSProp | epoch: 011 | loss: 0.49618 - acc: 0.7639 -- iter: 0448/1350
[A[ATraining Step: 445  | total loss: [1m[32m0.48818[0m[0m | time: 11.508s
[2K
| RMSProp | epoch: 011 | loss: 0.48818 - acc: 0.7656 -- iter: 0480/1350
[A[ATraining Step: 446  | total loss: [1m[32m0.48773[0m[0m | time: 12.373s
[2K
| RMSProp | epoch: 011 | loss: 0.48773 - acc: 0.7641 -- iter: 0512/1350
[A[ATraining Step: 447  | total loss: [1m[32m0.47783[0m[0m | time: 13.246s
[2K
| RMSProp | epoch: 011 | loss: 0.47783 - acc: 0.7720 -- iter: 0544/1350
[A[ATraining Step: 448  | total loss: [1m[32m0.47620[0m[0m | time: 14.095s
[2K
| RMSProp | epoch: 011 | loss: 0.47620 - acc: 0.7792 -- iter: 0576/1350
[A[ATraining Step: 449  | total loss: [1m[32m0.47604[0m[0m | time: 14.935s
[2K
| RMSProp | epoch: 011 | loss: 0.47604 - acc: 0.7825 -- iter: 0608/1350
[A[ATraining Step: 450  | total loss: [1m[32m0.49662[0m[0m | time: 15.769s
[2K
| RMSProp | epoch: 011 | loss: 0.49662 - acc: 0.7887 -- iter: 0640/1350
[A[ATraining Step: 451  | total loss: [1m[32m0.48467[0m[0m | time: 16.633s
[2K
| RMSProp | epoch: 011 | loss: 0.48467 - acc: 0.7911 -- iter: 0672/1350
[A[ATraining Step: 452  | total loss: [1m[32m0.48418[0m[0m | time: 17.520s
[2K
| RMSProp | epoch: 011 | loss: 0.48418 - acc: 0.7901 -- iter: 0704/1350
[A[ATraining Step: 453  | total loss: [1m[32m0.47275[0m[0m | time: 18.414s
[2K
| RMSProp | epoch: 011 | loss: 0.47275 - acc: 0.7923 -- iter: 0736/1350
[A[ATraining Step: 454  | total loss: [1m[32m0.47929[0m[0m | time: 19.322s
[2K
| RMSProp | epoch: 011 | loss: 0.47929 - acc: 0.7850 -- iter: 0768/1350
[A[ATraining Step: 455  | total loss: [1m[32m0.48395[0m[0m | time: 20.219s
[2K
| RMSProp | epoch: 011 | loss: 0.48395 - acc: 0.7846 -- iter: 0800/1350
[A[ATraining Step: 456  | total loss: [1m[32m0.49093[0m[0m | time: 21.249s
[2K
| RMSProp | epoch: 011 | loss: 0.49093 - acc: 0.7843 -- iter: 0832/1350
[A[ATraining Step: 457  | total loss: [1m[32m0.48511[0m[0m | time: 22.135s
[2K
| RMSProp | epoch: 011 | loss: 0.48511 - acc: 0.7902 -- iter: 0864/1350
[A[ATraining Step: 458  | total loss: [1m[32m0.48250[0m[0m | time: 23.122s
[2K
| RMSProp | epoch: 011 | loss: 0.48250 - acc: 0.7924 -- iter: 0896/1350
[A[ATraining Step: 459  | total loss: [1m[32m0.46098[0m[0m | time: 24.053s
[2K
| RMSProp | epoch: 011 | loss: 0.46098 - acc: 0.8038 -- iter: 0928/1350
[A[ATraining Step: 460  | total loss: [1m[32m0.46087[0m[0m | time: 24.967s
[2K
| RMSProp | epoch: 011 | loss: 0.46087 - acc: 0.7984 -- iter: 0960/1350
[A[ATraining Step: 461  | total loss: [1m[32m0.46401[0m[0m | time: 25.839s
[2K
| RMSProp | epoch: 011 | loss: 0.46401 - acc: 0.7998 -- iter: 0992/1350
[A[ATraining Step: 462  | total loss: [1m[32m0.46792[0m[0m | time: 26.763s
[2K
| RMSProp | epoch: 011 | loss: 0.46792 - acc: 0.7949 -- iter: 1024/1350
[A[ATraining Step: 463  | total loss: [1m[32m0.47730[0m[0m | time: 27.733s
[2K
| RMSProp | epoch: 011 | loss: 0.47730 - acc: 0.7841 -- iter: 1056/1350
[A[ATraining Step: 464  | total loss: [1m[32m0.46640[0m[0m | time: 28.694s
[2K
| RMSProp | epoch: 011 | loss: 0.46640 - acc: 0.7932 -- iter: 1088/1350
[A[ATraining Step: 465  | total loss: [1m[32m0.46040[0m[0m | time: 29.572s
[2K
| RMSProp | epoch: 011 | loss: 0.46040 - acc: 0.7983 -- iter: 1120/1350
[A[ATraining Step: 466  | total loss: [1m[32m0.45080[0m[0m | time: 30.537s
[2K
| RMSProp | epoch: 011 | loss: 0.45080 - acc: 0.8059 -- iter: 1152/1350
[A[ATraining Step: 467  | total loss: [1m[32m0.47500[0m[0m | time: 31.489s
[2K
| RMSProp | epoch: 011 | loss: 0.47500 - acc: 0.7972 -- iter: 1184/1350
[A[ATraining Step: 468  | total loss: [1m[32m0.49753[0m[0m | time: 32.495s
[2K
| RMSProp | epoch: 011 | loss: 0.49753 - acc: 0.7800 -- iter: 1216/1350
[A[ATraining Step: 469  | total loss: [1m[32m0.49921[0m[0m | time: 33.434s
[2K
| RMSProp | epoch: 011 | loss: 0.49921 - acc: 0.7770 -- iter: 1248/1350
[A[ATraining Step: 470  | total loss: [1m[32m0.48925[0m[0m | time: 34.367s
[2K
| RMSProp | epoch: 011 | loss: 0.48925 - acc: 0.7899 -- iter: 1280/1350
[A[ATraining Step: 471  | total loss: [1m[32m0.48049[0m[0m | time: 35.291s
[2K
| RMSProp | epoch: 011 | loss: 0.48049 - acc: 0.7922 -- iter: 1312/1350
[A[ATraining Step: 472  | total loss: [1m[32m0.47079[0m[0m | time: 36.177s
[2K
| RMSProp | epoch: 011 | loss: 0.47079 - acc: 0.7973 -- iter: 1344/1350
[A[ATraining Step: 473  | total loss: [1m[32m0.45333[0m[0m | time: 39.030s
[2K
| RMSProp | epoch: 011 | loss: 0.45333 - acc: 0.8020 | val_loss: 0.97229 - val_acc: 0.4988 -- iter: 1350/1350
--
Training Step: 474  | total loss: [1m[32m0.46775[0m[0m | time: 0.914s
[2K
| RMSProp | epoch: 012 | loss: 0.46775 - acc: 0.7968 -- iter: 0032/1350
[A[ATraining Step: 475  | total loss: [1m[32m0.50797[0m[0m | time: 1.803s
[2K
| RMSProp | epoch: 012 | loss: 0.50797 - acc: 0.7765 -- iter: 0064/1350
[A[ATraining Step: 476  | total loss: [1m[32m0.50568[0m[0m | time: 2.722s
[2K
| RMSProp | epoch: 012 | loss: 0.50568 - acc: 0.7801 -- iter: 0096/1350
[A[ATraining Step: 477  | total loss: [1m[32m0.49580[0m[0m | time: 3.679s
[2K
| RMSProp | epoch: 012 | loss: 0.49580 - acc: 0.7802 -- iter: 0128/1350
[A[ATraining Step: 478  | total loss: [1m[32m0.49014[0m[0m | time: 4.636s
[2K
| RMSProp | epoch: 012 | loss: 0.49014 - acc: 0.7803 -- iter: 0160/1350
[A[ATraining Step: 479  | total loss: [1m[32m0.48876[0m[0m | time: 5.626s
[2K
| RMSProp | epoch: 012 | loss: 0.48876 - acc: 0.7835 -- iter: 0192/1350
[A[ATraining Step: 480  | total loss: [1m[32m0.47223[0m[0m | time: 6.557s
[2K
| RMSProp | epoch: 012 | loss: 0.47223 - acc: 0.7927 -- iter: 0224/1350
[A[ATraining Step: 481  | total loss: [1m[32m0.45757[0m[0m | time: 7.539s
[2K
| RMSProp | epoch: 012 | loss: 0.45757 - acc: 0.8009 -- iter: 0256/1350
[A[ATraining Step: 482  | total loss: [1m[32m0.44400[0m[0m | time: 8.479s
[2K
| RMSProp | epoch: 012 | loss: 0.44400 - acc: 0.8083 -- iter: 0288/1350
[A[ATraining Step: 483  | total loss: [1m[32m0.44985[0m[0m | time: 8.697s
[2K
| RMSProp | epoch: 012 | loss: 0.44985 - acc: 0.8056 -- iter: 0320/1350
[A[ATraining Step: 484  | total loss: [1m[32m0.44758[0m[0m | time: 8.901s
[2K
| RMSProp | epoch: 012 | loss: 0.44758 - acc: 0.7917 -- iter: 0352/1350
[A[ATraining Step: 485  | total loss: [1m[32m0.42295[0m[0m | time: 9.854s
[2K
| RMSProp | epoch: 012 | loss: 0.42295 - acc: 0.7959 -- iter: 0384/1350
[A[ATraining Step: 486  | total loss: [1m[32m0.44097[0m[0m | time: 10.768s
[2K
| RMSProp | epoch: 012 | loss: 0.44097 - acc: 0.7913 -- iter: 0416/1350
[A[ATraining Step: 487  | total loss: [1m[32m0.45538[0m[0m | time: 11.706s
[2K
| RMSProp | epoch: 012 | loss: 0.45538 - acc: 0.7715 -- iter: 0448/1350
[A[ATraining Step: 488  | total loss: [1m[32m0.44965[0m[0m | time: 12.660s
[2K
| RMSProp | epoch: 012 | loss: 0.44965 - acc: 0.7819 -- iter: 0480/1350
[A[ATraining Step: 489  | total loss: [1m[32m0.44482[0m[0m | time: 13.584s
[2K
| RMSProp | epoch: 012 | loss: 0.44482 - acc: 0.7881 -- iter: 0512/1350
[A[ATraining Step: 490  | total loss: [1m[32m0.44000[0m[0m | time: 14.555s
[2K
| RMSProp | epoch: 012 | loss: 0.44000 - acc: 0.7874 -- iter: 0544/1350
[A[ATraining Step: 491  | total loss: [1m[32m0.43847[0m[0m | time: 15.456s
[2K
| RMSProp | epoch: 012 | loss: 0.43847 - acc: 0.7805 -- iter: 0576/1350
[A[ATraining Step: 492  | total loss: [1m[32m0.43484[0m[0m | time: 16.482s
[2K
| RMSProp | epoch: 012 | loss: 0.43484 - acc: 0.7806 -- iter: 0608/1350
[A[ATraining Step: 493  | total loss: [1m[32m0.43223[0m[0m | time: 17.419s
[2K
| RMSProp | epoch: 012 | loss: 0.43223 - acc: 0.7775 -- iter: 0640/1350
[A[ATraining Step: 494  | total loss: [1m[32m0.44782[0m[0m | time: 18.334s
[2K
| RMSProp | epoch: 012 | loss: 0.44782 - acc: 0.7748 -- iter: 0672/1350
[A[ATraining Step: 495  | total loss: [1m[32m0.46041[0m[0m | time: 19.271s
[2K
| RMSProp | epoch: 012 | loss: 0.46041 - acc: 0.7661 -- iter: 0704/1350
[A[ATraining Step: 496  | total loss: [1m[32m0.48166[0m[0m | time: 20.153s
[2K
| RMSProp | epoch: 012 | loss: 0.48166 - acc: 0.7582 -- iter: 0736/1350
[A[ATraining Step: 497  | total loss: [1m[32m0.46496[0m[0m | time: 21.151s
[2K
| RMSProp | epoch: 012 | loss: 0.46496 - acc: 0.7761 -- iter: 0768/1350
[A[ATraining Step: 498  | total loss: [1m[32m0.47001[0m[0m | time: 22.061s
[2K
| RMSProp | epoch: 012 | loss: 0.47001 - acc: 0.7735 -- iter: 0800/1350
[A[ATraining Step: 499  | total loss: [1m[32m0.44814[0m[0m | time: 23.066s
[2K
| RMSProp | epoch: 012 | loss: 0.44814 - acc: 0.7868 -- iter: 0832/1350
[A[ATraining Step: 500  | total loss: [1m[32m0.44858[0m[0m | time: 24.053s
[2K
| RMSProp | epoch: 012 | loss: 0.44858 - acc: 0.7862 -- iter: 0864/1350
[A[ATraining Step: 501  | total loss: [1m[32m0.48158[0m[0m | time: 24.985s
[2K
| RMSProp | epoch: 012 | loss: 0.48158 - acc: 0.7670 -- iter: 0896/1350
[A[ATraining Step: 502  | total loss: [1m[32m0.47358[0m[0m | time: 25.878s
[2K
| RMSProp | epoch: 012 | loss: 0.47358 - acc: 0.7747 -- iter: 0928/1350
[A[ATraining Step: 503  | total loss: [1m[32m0.46116[0m[0m | time: 26.833s
[2K
| RMSProp | epoch: 012 | loss: 0.46116 - acc: 0.7847 -- iter: 0960/1350
[A[ATraining Step: 504  | total loss: [1m[32m0.45342[0m[0m | time: 27.761s
[2K
| RMSProp | epoch: 012 | loss: 0.45342 - acc: 0.7781 -- iter: 0992/1350
[A[ATraining Step: 505  | total loss: [1m[32m0.49177[0m[0m | time: 28.667s
[2K
| RMSProp | epoch: 012 | loss: 0.49177 - acc: 0.7690 -- iter: 1024/1350
[A[ATraining Step: 506  | total loss: [1m[32m0.48808[0m[0m | time: 29.589s
[2K
| RMSProp | epoch: 012 | loss: 0.48808 - acc: 0.7671 -- iter: 1056/1350
[A[ATraining Step: 507  | total loss: [1m[32m0.46735[0m[0m | time: 30.529s
[2K
| RMSProp | epoch: 012 | loss: 0.46735 - acc: 0.7810 -- iter: 1088/1350
[A[ATraining Step: 508  | total loss: [1m[32m0.47357[0m[0m | time: 31.423s
[2K
| RMSProp | epoch: 012 | loss: 0.47357 - acc: 0.7873 -- iter: 1120/1350
[A[ATraining Step: 509  | total loss: [1m[32m0.47141[0m[0m | time: 32.348s
[2K
| RMSProp | epoch: 012 | loss: 0.47141 - acc: 0.7930 -- iter: 1152/1350
[A[ATraining Step: 510  | total loss: [1m[32m0.47417[0m[0m | time: 33.308s
[2K
| RMSProp | epoch: 012 | loss: 0.47417 - acc: 0.7824 -- iter: 1184/1350
[A[ATraining Step: 511  | total loss: [1m[32m0.49738[0m[0m | time: 34.273s
[2K
| RMSProp | epoch: 012 | loss: 0.49738 - acc: 0.7698 -- iter: 1216/1350
[A[ATraining Step: 512  | total loss: [1m[32m0.49014[0m[0m | time: 35.212s
[2K
| RMSProp | epoch: 012 | loss: 0.49014 - acc: 0.7772 -- iter: 1248/1350
[A[ATraining Step: 513  | total loss: [1m[32m0.47813[0m[0m | time: 36.117s
[2K
| RMSProp | epoch: 012 | loss: 0.47813 - acc: 0.7870 -- iter: 1280/1350
[A[ATraining Step: 514  | total loss: [1m[32m0.47247[0m[0m | time: 37.110s
[2K
| RMSProp | epoch: 012 | loss: 0.47247 - acc: 0.7927 -- iter: 1312/1350
[A[ATraining Step: 515  | total loss: [1m[32m0.45990[0m[0m | time: 38.048s
[2K
| RMSProp | epoch: 012 | loss: 0.45990 - acc: 0.7978 -- iter: 1344/1350
[A[ATraining Step: 516  | total loss: [1m[32m0.45693[0m[0m | time: 40.945s
[2K
| RMSProp | epoch: 012 | loss: 0.45693 - acc: 0.7992 | val_loss: 0.38727 - val_acc: 0.8487 -- iter: 1350/1350
--
Training Step: 517  | total loss: [1m[32m0.47503[0m[0m | time: 0.914s
[2K
| RMSProp | epoch: 013 | loss: 0.47503 - acc: 0.7912 -- iter: 0032/1350
[A[ATraining Step: 518  | total loss: [1m[32m0.46493[0m[0m | time: 1.819s
[2K
| RMSProp | epoch: 013 | loss: 0.46493 - acc: 0.7933 -- iter: 0064/1350
[A[ATraining Step: 519  | total loss: [1m[32m0.44711[0m[0m | time: 2.716s
[2K
| RMSProp | epoch: 013 | loss: 0.44711 - acc: 0.8046 -- iter: 0096/1350
[A[ATraining Step: 520  | total loss: [1m[32m0.42783[0m[0m | time: 3.509s
[2K
| RMSProp | epoch: 013 | loss: 0.42783 - acc: 0.8179 -- iter: 0128/1350
[A[ATraining Step: 521  | total loss: [1m[32m0.41143[0m[0m | time: 4.113s
[2K
| RMSProp | epoch: 013 | loss: 0.41143 - acc: 0.8267 -- iter: 0160/1350
[A[ATraining Step: 522  | total loss: [1m[32m0.39666[0m[0m | time: 4.743s
[2K
| RMSProp | epoch: 013 | loss: 0.39666 - acc: 0.8316 -- iter: 0192/1350
[A[ATraining Step: 523  | total loss: [1m[32m0.40662[0m[0m | time: 5.363s
[2K
| RMSProp | epoch: 013 | loss: 0.40662 - acc: 0.8234 -- iter: 0224/1350
[A[ATraining Step: 524  | total loss: [1m[32m0.39351[0m[0m | time: 5.969s
[2K
| RMSProp | epoch: 013 | loss: 0.39351 - acc: 0.8348 -- iter: 0256/1350
[A[ATraining Step: 525  | total loss: [1m[32m0.39018[0m[0m | time: 6.575s
[2K
| RMSProp | epoch: 013 | loss: 0.39018 - acc: 0.8388 -- iter: 0288/1350
[A[ATraining Step: 526  | total loss: [1m[32m0.37037[0m[0m | time: 7.188s
[2K
| RMSProp | epoch: 013 | loss: 0.37037 - acc: 0.8487 -- iter: 0320/1350
[A[ATraining Step: 527  | total loss: [1m[32m0.36451[0m[0m | time: 7.344s
[2K
| RMSProp | epoch: 013 | loss: 0.36451 - acc: 0.8451 -- iter: 0352/1350
[A[ATraining Step: 528  | total loss: [1m[32m0.37253[0m[0m | time: 7.488s
[2K
| RMSProp | epoch: 013 | loss: 0.37253 - acc: 0.8439 -- iter: 0384/1350
[A[ATraining Step: 529  | total loss: [1m[32m0.35521[0m[0m | time: 8.096s
[2K
| RMSProp | epoch: 013 | loss: 0.35521 - acc: 0.8595 -- iter: 0416/1350
[A[ATraining Step: 530  | total loss: [1m[32m0.38243[0m[0m | time: 8.708s
[2K
| RMSProp | epoch: 013 | loss: 0.38243 - acc: 0.8454 -- iter: 0448/1350
[A[ATraining Step: 531  | total loss: [1m[32m0.45877[0m[0m | time: 9.325s
[2K
| RMSProp | epoch: 013 | loss: 0.45877 - acc: 0.8234 -- iter: 0480/1350
[A[ATraining Step: 532  | total loss: [1m[32m0.45231[0m[0m | time: 9.928s
[2K
| RMSProp | epoch: 013 | loss: 0.45231 - acc: 0.8286 -- iter: 0512/1350
[A[ATraining Step: 533  | total loss: [1m[32m0.45345[0m[0m | time: 10.525s
[2K
| RMSProp | epoch: 013 | loss: 0.45345 - acc: 0.8301 -- iter: 0544/1350
[A[ATraining Step: 534  | total loss: [1m[32m0.44839[0m[0m | time: 11.146s
[2K
| RMSProp | epoch: 013 | loss: 0.44839 - acc: 0.8314 -- iter: 0576/1350
[A[ATraining Step: 535  | total loss: [1m[32m0.43908[0m[0m | time: 11.772s
[2K
| RMSProp | epoch: 013 | loss: 0.43908 - acc: 0.8389 -- iter: 0608/1350
[A[ATraining Step: 536  | total loss: [1m[32m0.43520[0m[0m | time: 12.387s
[2K
| RMSProp | epoch: 013 | loss: 0.43520 - acc: 0.8394 -- iter: 0640/1350
[A[ATraining Step: 537  | total loss: [1m[32m0.43897[0m[0m | time: 12.991s
[2K
| RMSProp | epoch: 013 | loss: 0.43897 - acc: 0.8398 -- iter: 0672/1350
[A[ATraining Step: 538  | total loss: [1m[32m0.44529[0m[0m | time: 13.592s
[2K
| RMSProp | epoch: 013 | loss: 0.44529 - acc: 0.8340 -- iter: 0704/1350
[A[ATraining Step: 539  | total loss: [1m[32m0.42731[0m[0m | time: 14.444s
[2K
| RMSProp | epoch: 013 | loss: 0.42731 - acc: 0.8443 -- iter: 0736/1350
[A[ATraining Step: 540  | total loss: [1m[32m0.44071[0m[0m | time: 15.452s
[2K
| RMSProp | epoch: 013 | loss: 0.44071 - acc: 0.8349 -- iter: 0768/1350
[A[ATraining Step: 541  | total loss: [1m[32m0.46133[0m[0m | time: 16.377s
[2K
| RMSProp | epoch: 013 | loss: 0.46133 - acc: 0.8170 -- iter: 0800/1350
[A[ATraining Step: 542  | total loss: [1m[32m0.45648[0m[0m | time: 17.085s
[2K
| RMSProp | epoch: 013 | loss: 0.45648 - acc: 0.8166 -- iter: 0832/1350
[A[ATraining Step: 543  | total loss: [1m[32m0.48417[0m[0m | time: 17.907s
[2K
| RMSProp | epoch: 013 | loss: 0.48417 - acc: 0.8037 -- iter: 0864/1350
[A[ATraining Step: 544  | total loss: [1m[32m0.46546[0m[0m | time: 18.781s
[2K
| RMSProp | epoch: 013 | loss: 0.46546 - acc: 0.8139 -- iter: 0896/1350
[A[ATraining Step: 545  | total loss: [1m[32m0.45052[0m[0m | time: 19.685s
[2K
| RMSProp | epoch: 013 | loss: 0.45052 - acc: 0.8200 -- iter: 0928/1350
[A[ATraining Step: 546  | total loss: [1m[32m0.42595[0m[0m | time: 20.550s
[2K
| RMSProp | epoch: 013 | loss: 0.42595 - acc: 0.8318 -- iter: 0960/1350
[A[ATraining Step: 547  | total loss: [1m[32m0.40112[0m[0m | time: 21.427s
[2K
| RMSProp | epoch: 013 | loss: 0.40112 - acc: 0.8455 -- iter: 0992/1350
[A[ATraining Step: 548  | total loss: [1m[32m0.38324[0m[0m | time: 22.327s
[2K
| RMSProp | epoch: 013 | loss: 0.38324 - acc: 0.8484 -- iter: 1024/1350
[A[ATraining Step: 549  | total loss: [1m[32m0.39168[0m[0m | time: 23.237s
[2K
| RMSProp | epoch: 013 | loss: 0.39168 - acc: 0.8386 -- iter: 1056/1350
[A[ATraining Step: 550  | total loss: [1m[32m0.42140[0m[0m | time: 24.034s
[2K
| RMSProp | epoch: 013 | loss: 0.42140 - acc: 0.8235 -- iter: 1088/1350
[A[ATraining Step: 551  | total loss: [1m[32m0.42494[0m[0m | time: 24.983s
[2K
| RMSProp | epoch: 013 | loss: 0.42494 - acc: 0.8193 -- iter: 1120/1350
[A[ATraining Step: 552  | total loss: [1m[32m0.42001[0m[0m | time: 25.990s
[2K
| RMSProp | epoch: 013 | loss: 0.42001 - acc: 0.8186 -- iter: 1152/1350
[A[ATraining Step: 553  | total loss: [1m[32m0.40315[0m[0m | time: 26.844s
[2K
| RMSProp | epoch: 013 | loss: 0.40315 - acc: 0.8242 -- iter: 1184/1350
[A[ATraining Step: 554  | total loss: [1m[32m0.38839[0m[0m | time: 27.601s
[2K
| RMSProp | epoch: 013 | loss: 0.38839 - acc: 0.8356 -- iter: 1216/1350
[A[ATraining Step: 555  | total loss: [1m[32m0.38073[0m[0m | time: 28.437s
[2K
| RMSProp | epoch: 013 | loss: 0.38073 - acc: 0.8395 -- iter: 1248/1350
[A[ATraining Step: 556  | total loss: [1m[32m0.41215[0m[0m | time: 29.295s
[2K
| RMSProp | epoch: 013 | loss: 0.41215 - acc: 0.8274 -- iter: 1280/1350
[A[ATraining Step: 557  | total loss: [1m[32m0.40424[0m[0m | time: 30.113s
[2K
| RMSProp | epoch: 013 | loss: 0.40424 - acc: 0.8291 -- iter: 1312/1350
[A[ATraining Step: 558  | total loss: [1m[32m0.41299[0m[0m | time: 30.928s
[2K
| RMSProp | epoch: 013 | loss: 0.41299 - acc: 0.8274 -- iter: 1344/1350
[A[ATraining Step: 559  | total loss: [1m[32m0.40877[0m[0m | time: 33.656s
[2K
| RMSProp | epoch: 013 | loss: 0.40877 - acc: 0.8290 | val_loss: 0.42122 - val_acc: 0.8180 -- iter: 1350/1350
--
Training Step: 560  | total loss: [1m[32m0.40998[0m[0m | time: 1.023s
[2K
| RMSProp | epoch: 014 | loss: 0.40998 - acc: 0.8274 -- iter: 0032/1350
[A[ATraining Step: 561  | total loss: [1m[32m0.42217[0m[0m | time: 1.783s
[2K
| RMSProp | epoch: 014 | loss: 0.42217 - acc: 0.8259 -- iter: 0064/1350
[A[ATraining Step: 562  | total loss: [1m[32m0.42833[0m[0m | time: 2.611s
[2K
| RMSProp | epoch: 014 | loss: 0.42833 - acc: 0.8121 -- iter: 0096/1350
[A[ATraining Step: 563  | total loss: [1m[32m0.43315[0m[0m | time: 3.396s
[2K
| RMSProp | epoch: 014 | loss: 0.43315 - acc: 0.8027 -- iter: 0128/1350
[A[ATraining Step: 564  | total loss: [1m[32m0.42822[0m[0m | time: 4.241s
[2K
| RMSProp | epoch: 014 | loss: 0.42822 - acc: 0.8006 -- iter: 0160/1350
[A[ATraining Step: 565  | total loss: [1m[32m0.42332[0m[0m | time: 5.074s
[2K
| RMSProp | epoch: 014 | loss: 0.42332 - acc: 0.8080 -- iter: 0192/1350
[A[ATraining Step: 566  | total loss: [1m[32m0.41108[0m[0m | time: 5.919s
[2K
| RMSProp | epoch: 014 | loss: 0.41108 - acc: 0.8178 -- iter: 0224/1350
[A[ATraining Step: 567  | total loss: [1m[32m0.38828[0m[0m | time: 6.810s
[2K
| RMSProp | epoch: 014 | loss: 0.38828 - acc: 0.8329 -- iter: 0256/1350
[A[ATraining Step: 568  | total loss: [1m[32m0.38927[0m[0m | time: 7.722s
[2K
| RMSProp | epoch: 014 | loss: 0.38927 - acc: 0.8278 -- iter: 0288/1350
[A[ATraining Step: 569  | total loss: [1m[32m0.38253[0m[0m | time: 8.627s
[2K
| RMSProp | epoch: 014 | loss: 0.38253 - acc: 0.8294 -- iter: 0320/1350
[A[ATraining Step: 570  | total loss: [1m[32m0.37064[0m[0m | time: 9.417s
[2K
| RMSProp | epoch: 014 | loss: 0.37064 - acc: 0.8402 -- iter: 0352/1350
[A[ATraining Step: 571  | total loss: [1m[32m0.34910[0m[0m | time: 9.674s
[2K
| RMSProp | epoch: 014 | loss: 0.34910 - acc: 0.8530 -- iter: 0384/1350
[A[ATraining Step: 572  | total loss: [1m[32m0.33319[0m[0m | time: 9.902s
[2K
| RMSProp | epoch: 014 | loss: 0.33319 - acc: 0.8511 -- iter: 0416/1350
[A[ATraining Step: 573  | total loss: [1m[32m0.32378[0m[0m | time: 10.879s
[2K
| RMSProp | epoch: 014 | loss: 0.32378 - acc: 0.8493 -- iter: 0448/1350
[A[ATraining Step: 574  | total loss: [1m[32m0.36230[0m[0m | time: 11.780s
[2K
| RMSProp | epoch: 014 | loss: 0.36230 - acc: 0.8394 -- iter: 0480/1350
[A[ATraining Step: 575  | total loss: [1m[32m0.35221[0m[0m | time: 12.465s
[2K
| RMSProp | epoch: 014 | loss: 0.35221 - acc: 0.8429 -- iter: 0512/1350
[A[ATraining Step: 576  | total loss: [1m[32m0.35770[0m[0m | time: 13.258s
[2K
| RMSProp | epoch: 014 | loss: 0.35770 - acc: 0.8493 -- iter: 0544/1350
[A[ATraining Step: 577  | total loss: [1m[32m0.34943[0m[0m | time: 14.151s
[2K
| RMSProp | epoch: 014 | loss: 0.34943 - acc: 0.8550 -- iter: 0576/1350
[A[ATraining Step: 578  | total loss: [1m[32m0.34528[0m[0m | time: 14.992s
[2K
| RMSProp | epoch: 014 | loss: 0.34528 - acc: 0.8507 -- iter: 0608/1350
[A[ATraining Step: 579  | total loss: [1m[32m0.35169[0m[0m | time: 15.874s
[2K
| RMSProp | epoch: 014 | loss: 0.35169 - acc: 0.8375 -- iter: 0640/1350
[A[ATraining Step: 580  | total loss: [1m[32m0.34313[0m[0m | time: 16.750s
[2K
| RMSProp | epoch: 014 | loss: 0.34313 - acc: 0.8413 -- iter: 0672/1350
[A[ATraining Step: 581  | total loss: [1m[32m0.32854[0m[0m | time: 17.569s
[2K
| RMSProp | epoch: 014 | loss: 0.32854 - acc: 0.8478 -- iter: 0704/1350
[A[ATraining Step: 582  | total loss: [1m[32m0.31687[0m[0m | time: 18.432s
[2K
| RMSProp | epoch: 014 | loss: 0.31687 - acc: 0.8536 -- iter: 0736/1350
[A[ATraining Step: 583  | total loss: [1m[32m0.30511[0m[0m | time: 19.246s
[2K
| RMSProp | epoch: 014 | loss: 0.30511 - acc: 0.8589 -- iter: 0768/1350
[A[ATraining Step: 584  | total loss: [1m[32m0.29054[0m[0m | time: 20.155s
[2K
| RMSProp | epoch: 014 | loss: 0.29054 - acc: 0.8667 -- iter: 0800/1350
[A[ATraining Step: 585  | total loss: [1m[32m0.27157[0m[0m | time: 21.127s
[2K
| RMSProp | epoch: 014 | loss: 0.27157 - acc: 0.8769 -- iter: 0832/1350
[A[ATraining Step: 586  | total loss: [1m[32m0.28711[0m[0m | time: 22.052s
[2K
| RMSProp | epoch: 014 | loss: 0.28711 - acc: 0.8705 -- iter: 0864/1350
[A[ATraining Step: 587  | total loss: [1m[32m0.32331[0m[0m | time: 22.764s
[2K
| RMSProp | epoch: 014 | loss: 0.32331 - acc: 0.8553 -- iter: 0896/1350
[A[ATraining Step: 588  | total loss: [1m[32m0.34793[0m[0m | time: 23.610s
[2K
| RMSProp | epoch: 014 | loss: 0.34793 - acc: 0.8354 -- iter: 0928/1350
[A[ATraining Step: 589  | total loss: [1m[32m0.35388[0m[0m | time: 24.503s
[2K
| RMSProp | epoch: 014 | loss: 0.35388 - acc: 0.8394 -- iter: 0960/1350
[A[ATraining Step: 590  | total loss: [1m[32m0.34612[0m[0m | time: 25.379s
[2K
| RMSProp | epoch: 014 | loss: 0.34612 - acc: 0.8461 -- iter: 0992/1350
[A[ATraining Step: 591  | total loss: [1m[32m0.34504[0m[0m | time: 26.230s
[2K
| RMSProp | epoch: 014 | loss: 0.34504 - acc: 0.8427 -- iter: 1024/1350
[A[ATraining Step: 592  | total loss: [1m[32m0.35745[0m[0m | time: 27.089s
[2K
| RMSProp | epoch: 014 | loss: 0.35745 - acc: 0.8397 -- iter: 1056/1350
[A[ATraining Step: 593  | total loss: [1m[32m0.35142[0m[0m | time: 27.984s
[2K
| RMSProp | epoch: 014 | loss: 0.35142 - acc: 0.8432 -- iter: 1088/1350
[A[ATraining Step: 594  | total loss: [1m[32m0.33408[0m[0m | time: 28.859s
[2K
| RMSProp | epoch: 014 | loss: 0.33408 - acc: 0.8526 -- iter: 1120/1350
[A[ATraining Step: 595  | total loss: [1m[32m0.32765[0m[0m | time: 29.667s
[2K
| RMSProp | epoch: 014 | loss: 0.32765 - acc: 0.8580 -- iter: 1152/1350
[A[ATraining Step: 596  | total loss: [1m[32m0.31239[0m[0m | time: 30.632s
[2K
| RMSProp | epoch: 014 | loss: 0.31239 - acc: 0.8691 -- iter: 1184/1350
[A[ATraining Step: 597  | total loss: [1m[32m0.29598[0m[0m | time: 31.619s
[2K
| RMSProp | epoch: 014 | loss: 0.29598 - acc: 0.8759 -- iter: 1216/1350
[A[ATraining Step: 598  | total loss: [1m[32m0.29516[0m[0m | time: 32.492s
[2K
| RMSProp | epoch: 014 | loss: 0.29516 - acc: 0.8696 -- iter: 1248/1350
[A[ATraining Step: 599  | total loss: [1m[32m0.28863[0m[0m | time: 33.230s
[2K
| RMSProp | epoch: 014 | loss: 0.28863 - acc: 0.8732 -- iter: 1280/1350
[A[ATraining Step: 600  | total loss: [1m[32m0.29775[0m[0m | time: 35.819s
[2K
| RMSProp | epoch: 014 | loss: 0.29775 - acc: 0.8703 | val_loss: 0.32474 - val_acc: 0.8842 -- iter: 1312/1350
--
Training Step: 601  | total loss: [1m[32m0.35185[0m[0m | time: 36.833s
[2K
| RMSProp | epoch: 014 | loss: 0.35185 - acc: 0.8458 -- iter: 1344/1350
[A[ATraining Step: 602  | total loss: [1m[32m0.35316[0m[0m | time: 39.250s
[2K
| RMSProp | epoch: 014 | loss: 0.35316 - acc: 0.8518 | val_loss: 0.38734 - val_acc: 0.8392 -- iter: 1350/1350
--
Training Step: 603  | total loss: [1m[32m0.35509[0m[0m | time: 0.883s
[2K
| RMSProp | epoch: 015 | loss: 0.35509 - acc: 0.8479 -- iter: 0032/1350
[A[ATraining Step: 604  | total loss: [1m[32m0.35370[0m[0m | time: 1.817s
[2K
| RMSProp | epoch: 015 | loss: 0.35370 - acc: 0.8475 -- iter: 0064/1350
[A[ATraining Step: 605  | total loss: [1m[32m0.35665[0m[0m | time: 2.685s
[2K
| RMSProp | epoch: 015 | loss: 0.35665 - acc: 0.8471 -- iter: 0096/1350
[A[ATraining Step: 606  | total loss: [1m[32m0.34968[0m[0m | time: 3.504s
[2K
| RMSProp | epoch: 015 | loss: 0.34968 - acc: 0.8530 -- iter: 0128/1350
[A[ATraining Step: 607  | total loss: [1m[32m0.33308[0m[0m | time: 4.537s
[2K
| RMSProp | epoch: 015 | loss: 0.33308 - acc: 0.8646 -- iter: 0160/1350
[A[ATraining Step: 608  | total loss: [1m[32m0.31771[0m[0m | time: 5.509s
[2K
| RMSProp | epoch: 015 | loss: 0.31771 - acc: 0.8719 -- iter: 0192/1350
[A[ATraining Step: 609  | total loss: [1m[32m0.32360[0m[0m | time: 6.266s
[2K
| RMSProp | epoch: 015 | loss: 0.32360 - acc: 0.8691 -- iter: 0224/1350
[A[ATraining Step: 610  | total loss: [1m[32m0.31735[0m[0m | time: 7.054s
[2K
| RMSProp | epoch: 015 | loss: 0.31735 - acc: 0.8728 -- iter: 0256/1350
[A[ATraining Step: 611  | total loss: [1m[32m0.29814[0m[0m | time: 7.923s
[2K
| RMSProp | epoch: 015 | loss: 0.29814 - acc: 0.8855 -- iter: 0288/1350
[A[ATraining Step: 612  | total loss: [1m[32m0.29427[0m[0m | time: 8.760s
[2K
| RMSProp | epoch: 015 | loss: 0.29427 - acc: 0.8845 -- iter: 0320/1350
[A[ATraining Step: 613  | total loss: [1m[32m0.35358[0m[0m | time: 9.597s
[2K
| RMSProp | epoch: 015 | loss: 0.35358 - acc: 0.8616 -- iter: 0352/1350
[A[ATraining Step: 614  | total loss: [1m[32m0.36725[0m[0m | time: 10.441s
[2K
| RMSProp | epoch: 015 | loss: 0.36725 - acc: 0.8442 -- iter: 0384/1350
[A[ATraining Step: 615  | total loss: [1m[32m0.36808[0m[0m | time: 10.656s
[2K
| RMSProp | epoch: 015 | loss: 0.36808 - acc: 0.8410 -- iter: 0416/1350
[A[ATraining Step: 616  | total loss: [1m[32m0.36957[0m[0m | time: 10.867s
[2K
| RMSProp | epoch: 015 | loss: 0.36957 - acc: 0.8403 -- iter: 0448/1350
[A[ATraining Step: 617  | total loss: [1m[32m0.34925[0m[0m | time: 11.785s
[2K
| RMSProp | epoch: 015 | loss: 0.34925 - acc: 0.8396 -- iter: 0480/1350
[A[ATraining Step: 618  | total loss: [1m[32m0.36311[0m[0m | time: 12.658s
[2K
| RMSProp | epoch: 015 | loss: 0.36311 - acc: 0.8337 -- iter: 0512/1350
[A[ATraining Step: 619  | total loss: [1m[32m0.35595[0m[0m | time: 13.440s
[2K
| RMSProp | epoch: 015 | loss: 0.35595 - acc: 0.8379 -- iter: 0544/1350
[A[ATraining Step: 620  | total loss: [1m[32m0.35437[0m[0m | time: 14.439s
[2K
| RMSProp | epoch: 015 | loss: 0.35437 - acc: 0.8447 -- iter: 0576/1350
[A[ATraining Step: 621  | total loss: [1m[32m0.36307[0m[0m | time: 15.405s
[2K
| RMSProp | epoch: 015 | loss: 0.36307 - acc: 0.8321 -- iter: 0608/1350
[A[ATraining Step: 622  | total loss: [1m[32m0.35757[0m[0m | time: 16.237s
[2K
| RMSProp | epoch: 015 | loss: 0.35757 - acc: 0.8364 -- iter: 0640/1350
[A[ATraining Step: 623  | total loss: [1m[32m0.35464[0m[0m | time: 17.053s
[2K
| RMSProp | epoch: 015 | loss: 0.35464 - acc: 0.8371 -- iter: 0672/1350
[A[ATraining Step: 624  | total loss: [1m[32m0.34893[0m[0m | time: 17.928s
[2K
| RMSProp | epoch: 015 | loss: 0.34893 - acc: 0.8441 -- iter: 0704/1350
[A[ATraining Step: 625  | total loss: [1m[32m0.33583[0m[0m | time: 18.775s
[2K
| RMSProp | epoch: 015 | loss: 0.33583 - acc: 0.8471 -- iter: 0736/1350
[A[ATraining Step: 626  | total loss: [1m[32m0.32289[0m[0m | time: 19.649s
[2K
| RMSProp | epoch: 015 | loss: 0.32289 - acc: 0.8562 -- iter: 0768/1350
[A[ATraining Step: 627  | total loss: [1m[32m0.29795[0m[0m | time: 20.526s
[2K
| RMSProp | epoch: 015 | loss: 0.29795 - acc: 0.8706 -- iter: 0800/1350
[A[ATraining Step: 628  | total loss: [1m[32m0.28964[0m[0m | time: 21.342s
[2K
| RMSProp | epoch: 015 | loss: 0.28964 - acc: 0.8804 -- iter: 0832/1350
[A[ATraining Step: 629  | total loss: [1m[32m0.28255[0m[0m | time: 22.224s
[2K
| RMSProp | epoch: 015 | loss: 0.28255 - acc: 0.8861 -- iter: 0864/1350
[A[ATraining Step: 630  | total loss: [1m[32m0.26327[0m[0m | time: 23.056s
[2K
| RMSProp | epoch: 015 | loss: 0.26327 - acc: 0.8975 -- iter: 0896/1350
[A[ATraining Step: 631  | total loss: [1m[32m0.24681[0m[0m | time: 23.877s
[2K
| RMSProp | epoch: 015 | loss: 0.24681 - acc: 0.9046 -- iter: 0928/1350
[A[ATraining Step: 632  | total loss: [1m[32m0.22386[0m[0m | time: 24.834s
[2K
| RMSProp | epoch: 015 | loss: 0.22386 - acc: 0.9141 -- iter: 0960/1350
[A[ATraining Step: 633  | total loss: [1m[32m0.22424[0m[0m | time: 25.833s
[2K
| RMSProp | epoch: 015 | loss: 0.22424 - acc: 0.9134 -- iter: 0992/1350
[A[ATraining Step: 634  | total loss: [1m[32m0.30574[0m[0m | time: 26.597s
[2K
| RMSProp | epoch: 015 | loss: 0.30574 - acc: 0.8783 -- iter: 1024/1350
[A[ATraining Step: 635  | total loss: [1m[32m0.31077[0m[0m | time: 27.420s
[2K
| RMSProp | epoch: 015 | loss: 0.31077 - acc: 0.8779 -- iter: 1056/1350
[A[ATraining Step: 636  | total loss: [1m[32m0.29270[0m[0m | time: 28.282s
[2K
| RMSProp | epoch: 015 | loss: 0.29270 - acc: 0.8870 -- iter: 1088/1350
[A[ATraining Step: 637  | total loss: [1m[32m0.28613[0m[0m | time: 29.128s
[2K
| RMSProp | epoch: 015 | loss: 0.28613 - acc: 0.8921 -- iter: 1120/1350
[A[ATraining Step: 638  | total loss: [1m[32m0.27559[0m[0m | time: 30.010s
[2K
| RMSProp | epoch: 015 | loss: 0.27559 - acc: 0.8966 -- iter: 1152/1350
[A[ATraining Step: 639  | total loss: [1m[32m0.25891[0m[0m | time: 30.955s
[2K
| RMSProp | epoch: 015 | loss: 0.25891 - acc: 0.9038 -- iter: 1184/1350
[A[ATraining Step: 640  | total loss: [1m[32m0.24146[0m[0m | time: 31.827s
[2K
| RMSProp | epoch: 015 | loss: 0.24146 - acc: 0.9103 -- iter: 1216/1350
[A[ATraining Step: 641  | total loss: [1m[32m0.23837[0m[0m | time: 32.742s
[2K
| RMSProp | epoch: 015 | loss: 0.23837 - acc: 0.9130 -- iter: 1248/1350
[A[ATraining Step: 642  | total loss: [1m[32m0.24957[0m[0m | time: 33.556s
[2K
| RMSProp | epoch: 015 | loss: 0.24957 - acc: 0.8999 -- iter: 1280/1350
[A[ATraining Step: 643  | total loss: [1m[32m0.26667[0m[0m | time: 34.517s
[2K
| RMSProp | epoch: 015 | loss: 0.26667 - acc: 0.8942 -- iter: 1312/1350
[A[ATraining Step: 644  | total loss: [1m[32m0.26604[0m[0m | time: 35.539s
[2K
| RMSProp | epoch: 015 | loss: 0.26604 - acc: 0.8954 -- iter: 1344/1350
[A[ATraining Step: 645  | total loss: [1m[32m0.25092[0m[0m | time: 38.023s
[2K
| RMSProp | epoch: 015 | loss: 0.25092 - acc: 0.9059 | val_loss: 0.34519 - val_acc: 0.8794 -- iter: 1350/1350
--
Training Step: 646  | total loss: [1m[32m0.25703[0m[0m | time: 0.856s
[2K
| RMSProp | epoch: 016 | loss: 0.25703 - acc: 0.9091 -- iter: 0032/1350
[A[ATraining Step: 647  | total loss: [1m[32m0.26189[0m[0m | time: 1.729s
[2K
| RMSProp | epoch: 016 | loss: 0.26189 - acc: 0.9057 -- iter: 0064/1350
[A[ATraining Step: 648  | total loss: [1m[32m0.25293[0m[0m | time: 2.593s
[2K
| RMSProp | epoch: 016 | loss: 0.25293 - acc: 0.9057 -- iter: 0096/1350
[A[ATraining Step: 649  | total loss: [1m[32m0.24959[0m[0m | time: 3.465s
[2K
| RMSProp | epoch: 016 | loss: 0.24959 - acc: 0.9058 -- iter: 0128/1350
[A[ATraining Step: 650  | total loss: [1m[32m0.23711[0m[0m | time: 4.258s
[2K
| RMSProp | epoch: 016 | loss: 0.23711 - acc: 0.9089 -- iter: 0160/1350
[A[ATraining Step: 651  | total loss: [1m[32m0.22131[0m[0m | time: 5.233s
[2K
| RMSProp | epoch: 016 | loss: 0.22131 - acc: 0.9180 -- iter: 0192/1350
[A[ATraining Step: 652  | total loss: [1m[32m0.21817[0m[0m | time: 6.243s
[2K
| RMSProp | epoch: 016 | loss: 0.21817 - acc: 0.9169 -- iter: 0224/1350
[A[ATraining Step: 653  | total loss: [1m[32m0.20727[0m[0m | time: 7.026s
[2K
| RMSProp | epoch: 016 | loss: 0.20727 - acc: 0.9221 -- iter: 0256/1350
[A[ATraining Step: 654  | total loss: [1m[32m0.20194[0m[0m | time: 7.809s
[2K
| RMSProp | epoch: 016 | loss: 0.20194 - acc: 0.9205 -- iter: 0288/1350
[A[ATraining Step: 655  | total loss: [1m[32m0.29320[0m[0m | time: 8.633s
[2K
| RMSProp | epoch: 016 | loss: 0.29320 - acc: 0.8878 -- iter: 0320/1350
[A[ATraining Step: 656  | total loss: [1m[32m0.27531[0m[0m | time: 9.469s
[2K
| RMSProp | epoch: 016 | loss: 0.27531 - acc: 0.8959 -- iter: 0352/1350
[A[ATraining Step: 657  | total loss: [1m[32m0.26441[0m[0m | time: 10.326s
[2K
| RMSProp | epoch: 016 | loss: 0.26441 - acc: 0.9001 -- iter: 0384/1350
[A[ATraining Step: 658  | total loss: [1m[32m0.29809[0m[0m | time: 11.173s
[2K
| RMSProp | epoch: 016 | loss: 0.29809 - acc: 0.8882 -- iter: 0416/1350
[A[ATraining Step: 659  | total loss: [1m[32m0.28872[0m[0m | time: 11.405s
[2K
| RMSProp | epoch: 016 | loss: 0.28872 - acc: 0.8869 -- iter: 0448/1350
[A[ATraining Step: 660  | total loss: [1m[32m0.27313[0m[0m | time: 11.609s
[2K
| RMSProp | epoch: 016 | loss: 0.27313 - acc: 0.8982 -- iter: 0480/1350
[A[ATraining Step: 661  | total loss: [1m[32m0.25145[0m[0m | time: 12.435s
[2K
| RMSProp | epoch: 016 | loss: 0.25145 - acc: 0.9084 -- iter: 0512/1350
[A[ATraining Step: 662  | total loss: [1m[32m0.26845[0m[0m | time: 13.340s
[2K
| RMSProp | epoch: 016 | loss: 0.26845 - acc: 0.9019 -- iter: 0544/1350
[A[ATraining Step: 663  | total loss: [1m[32m0.27466[0m[0m | time: 14.150s
[2K
| RMSProp | epoch: 016 | loss: 0.27466 - acc: 0.8898 -- iter: 0576/1350
[A[ATraining Step: 664  | total loss: [1m[32m0.27830[0m[0m | time: 15.075s
[2K
| RMSProp | epoch: 016 | loss: 0.27830 - acc: 0.8852 -- iter: 0608/1350
[A[ATraining Step: 665  | total loss: [1m[32m0.27054[0m[0m | time: 16.017s
[2K
| RMSProp | epoch: 016 | loss: 0.27054 - acc: 0.8905 -- iter: 0640/1350
[A[ATraining Step: 666  | total loss: [1m[32m0.29717[0m[0m | time: 16.964s
[2K
| RMSProp | epoch: 016 | loss: 0.29717 - acc: 0.8827 -- iter: 0672/1350
[A[ATraining Step: 667  | total loss: [1m[32m0.31820[0m[0m | time: 17.643s
[2K
| RMSProp | epoch: 016 | loss: 0.31820 - acc: 0.8694 -- iter: 0704/1350
[A[ATraining Step: 668  | total loss: [1m[32m0.31034[0m[0m | time: 18.469s
[2K
| RMSProp | epoch: 016 | loss: 0.31034 - acc: 0.8762 -- iter: 0736/1350
[A[ATraining Step: 669  | total loss: [1m[32m0.29161[0m[0m | time: 19.325s
[2K
| RMSProp | epoch: 016 | loss: 0.29161 - acc: 0.8886 -- iter: 0768/1350
[A[ATraining Step: 670  | total loss: [1m[32m0.30114[0m[0m | time: 20.148s
[2K
| RMSProp | epoch: 016 | loss: 0.30114 - acc: 0.8841 -- iter: 0800/1350
[A[ATraining Step: 671  | total loss: [1m[32m0.30196[0m[0m | time: 20.979s
[2K
| RMSProp | epoch: 016 | loss: 0.30196 - acc: 0.8832 -- iter: 0832/1350
[A[ATraining Step: 672  | total loss: [1m[32m0.29963[0m[0m | time: 21.840s
[2K
| RMSProp | epoch: 016 | loss: 0.29963 - acc: 0.8855 -- iter: 0864/1350
[A[ATraining Step: 673  | total loss: [1m[32m0.30894[0m[0m | time: 22.720s
[2K
| RMSProp | epoch: 016 | loss: 0.30894 - acc: 0.8751 -- iter: 0896/1350
[A[ATraining Step: 674  | total loss: [1m[32m0.31164[0m[0m | time: 23.575s
[2K
| RMSProp | epoch: 016 | loss: 0.31164 - acc: 0.8782 -- iter: 0928/1350
[A[ATraining Step: 675  | total loss: [1m[32m0.29015[0m[0m | time: 24.414s
[2K
| RMSProp | epoch: 016 | loss: 0.29015 - acc: 0.8904 -- iter: 0960/1350
[A[ATraining Step: 676  | total loss: [1m[32m0.26844[0m[0m | time: 25.331s
[2K
| RMSProp | epoch: 016 | loss: 0.26844 - acc: 0.9013 -- iter: 0992/1350
[A[ATraining Step: 677  | total loss: [1m[32m0.25461[0m[0m | time: 26.306s
[2K
| RMSProp | epoch: 016 | loss: 0.25461 - acc: 0.9081 -- iter: 1024/1350
[A[ATraining Step: 678  | total loss: [1m[32m0.24581[0m[0m | time: 27.270s
[2K
| RMSProp | epoch: 016 | loss: 0.24581 - acc: 0.9079 -- iter: 1056/1350
[A[ATraining Step: 679  | total loss: [1m[32m0.26011[0m[0m | time: 27.960s
[2K
| RMSProp | epoch: 016 | loss: 0.26011 - acc: 0.9015 -- iter: 1088/1350
[A[ATraining Step: 680  | total loss: [1m[32m0.26037[0m[0m | time: 28.793s
[2K
| RMSProp | epoch: 016 | loss: 0.26037 - acc: 0.9051 -- iter: 1120/1350
[A[ATraining Step: 681  | total loss: [1m[32m0.24513[0m[0m | time: 29.611s
[2K
| RMSProp | epoch: 016 | loss: 0.24513 - acc: 0.9114 -- iter: 1152/1350
[A[ATraining Step: 682  | total loss: [1m[32m0.23891[0m[0m | time: 30.460s
[2K
| RMSProp | epoch: 016 | loss: 0.23891 - acc: 0.9078 -- iter: 1184/1350
[A[ATraining Step: 683  | total loss: [1m[32m0.22957[0m[0m | time: 31.331s
[2K
| RMSProp | epoch: 016 | loss: 0.22957 - acc: 0.9108 -- iter: 1216/1350
[A[ATraining Step: 684  | total loss: [1m[32m0.23438[0m[0m | time: 32.157s
[2K
| RMSProp | epoch: 016 | loss: 0.23438 - acc: 0.9041 -- iter: 1248/1350
[A[ATraining Step: 685  | total loss: [1m[32m0.22803[0m[0m | time: 33.099s
[2K
| RMSProp | epoch: 016 | loss: 0.22803 - acc: 0.9074 -- iter: 1280/1350
[A[ATraining Step: 686  | total loss: [1m[32m0.22496[0m[0m | time: 33.981s
[2K
| RMSProp | epoch: 016 | loss: 0.22496 - acc: 0.9073 -- iter: 1312/1350
[A[ATraining Step: 687  | total loss: [1m[32m0.20785[0m[0m | time: 34.805s
[2K
| RMSProp | epoch: 016 | loss: 0.20785 - acc: 0.9166 -- iter: 1344/1350
[A[ATraining Step: 688  | total loss: [1m[32m0.19465[0m[0m | time: 37.744s
[2K
| RMSProp | epoch: 016 | loss: 0.19465 - acc: 0.9218 | val_loss: 0.39777 - val_acc: 0.8511 -- iter: 1350/1350
--
Training Step: 689  | total loss: [1m[32m0.19391[0m[0m | time: 0.887s
[2K
| RMSProp | epoch: 017 | loss: 0.19391 - acc: 0.9234 -- iter: 0032/1350
[A[ATraining Step: 690  | total loss: [1m[32m0.19280[0m[0m | time: 1.783s
[2K
| RMSProp | epoch: 017 | loss: 0.19280 - acc: 0.9279 -- iter: 0064/1350
[A[ATraining Step: 691  | total loss: [1m[32m0.18178[0m[0m | time: 2.632s
[2K
| RMSProp | epoch: 017 | loss: 0.18178 - acc: 0.9320 -- iter: 0096/1350
[A[ATraining Step: 692  | total loss: [1m[32m0.17959[0m[0m | time: 3.462s
[2K
| RMSProp | epoch: 017 | loss: 0.17959 - acc: 0.9325 -- iter: 0128/1350
[A[ATraining Step: 693  | total loss: [1m[32m0.16868[0m[0m | time: 4.417s
[2K
| RMSProp | epoch: 017 | loss: 0.16868 - acc: 0.9362 -- iter: 0160/1350
[A[ATraining Step: 694  | total loss: [1m[32m0.16740[0m[0m | time: 5.445s
[2K
| RMSProp | epoch: 017 | loss: 0.16740 - acc: 0.9394 -- iter: 0192/1350
[A[ATraining Step: 695  | total loss: [1m[32m0.17921[0m[0m | time: 6.304s
[2K
| RMSProp | epoch: 017 | loss: 0.17921 - acc: 0.9361 -- iter: 0224/1350
[A[ATraining Step: 696  | total loss: [1m[32m0.18108[0m[0m | time: 7.038s
[2K
| RMSProp | epoch: 017 | loss: 0.18108 - acc: 0.9300 -- iter: 0256/1350
[A[ATraining Step: 697  | total loss: [1m[32m0.17201[0m[0m | time: 7.882s
[2K
| RMSProp | epoch: 017 | loss: 0.17201 - acc: 0.9307 -- iter: 0288/1350
[A[ATraining Step: 698  | total loss: [1m[32m0.16440[0m[0m | time: 8.806s
[2K
| RMSProp | epoch: 017 | loss: 0.16440 - acc: 0.9345 -- iter: 0320/1350
[A[ATraining Step: 699  | total loss: [1m[32m0.19026[0m[0m | time: 9.661s
[2K
| RMSProp | epoch: 017 | loss: 0.19026 - acc: 0.9255 -- iter: 0352/1350
[A[ATraining Step: 700  | total loss: [1m[32m0.20997[0m[0m | time: 10.531s
[2K
| RMSProp | epoch: 017 | loss: 0.20997 - acc: 0.9142 -- iter: 0384/1350
[A[ATraining Step: 701  | total loss: [1m[32m0.20343[0m[0m | time: 11.429s
[2K
| RMSProp | epoch: 017 | loss: 0.20343 - acc: 0.9196 -- iter: 0416/1350
[A[ATraining Step: 702  | total loss: [1m[32m0.19127[0m[0m | time: 12.274s
[2K
| RMSProp | epoch: 017 | loss: 0.19127 - acc: 0.9277 -- iter: 0448/1350
[A[ATraining Step: 703  | total loss: [1m[32m0.18519[0m[0m | time: 12.519s
[2K
| RMSProp | epoch: 017 | loss: 0.18519 - acc: 0.9286 -- iter: 0480/1350
[A[ATraining Step: 704  | total loss: [1m[32m0.19205[0m[0m | time: 12.740s
[2K
| RMSProp | epoch: 017 | loss: 0.19205 - acc: 0.9191 -- iter: 0512/1350
[A[ATraining Step: 705  | total loss: [1m[32m0.18626[0m[0m | time: 13.513s
[2K
| RMSProp | epoch: 017 | loss: 0.18626 - acc: 0.9272 -- iter: 0544/1350
[A[ATraining Step: 706  | total loss: [1m[32m0.25303[0m[0m | time: 14.458s
[2K
| RMSProp | epoch: 017 | loss: 0.25303 - acc: 0.9126 -- iter: 0576/1350
[A[ATraining Step: 707  | total loss: [1m[32m0.23578[0m[0m | time: 15.396s
[2K
| RMSProp | epoch: 017 | loss: 0.23578 - acc: 0.9213 -- iter: 0608/1350
[A[ATraining Step: 708  | total loss: [1m[32m0.21527[0m[0m | time: 16.298s
[2K
| RMSProp | epoch: 017 | loss: 0.21527 - acc: 0.9292 -- iter: 0640/1350
[A[ATraining Step: 709  | total loss: [1m[32m0.21901[0m[0m | time: 17.085s
[2K
| RMSProp | epoch: 017 | loss: 0.21901 - acc: 0.9300 -- iter: 0672/1350
[A[ATraining Step: 710  | total loss: [1m[32m0.20668[0m[0m | time: 17.947s
[2K
| RMSProp | epoch: 017 | loss: 0.20668 - acc: 0.9339 -- iter: 0704/1350
[A[ATraining Step: 711  | total loss: [1m[32m0.19140[0m[0m | time: 18.785s
[2K
| RMSProp | epoch: 017 | loss: 0.19140 - acc: 0.9405 -- iter: 0736/1350
[A[ATraining Step: 712  | total loss: [1m[32m0.17965[0m[0m | time: 19.609s
[2K
| RMSProp | epoch: 017 | loss: 0.17965 - acc: 0.9433 -- iter: 0768/1350
[A[ATraining Step: 713  | total loss: [1m[32m0.18084[0m[0m | time: 20.445s
[2K
| RMSProp | epoch: 017 | loss: 0.18084 - acc: 0.9459 -- iter: 0800/1350
[A[ATraining Step: 714  | total loss: [1m[32m0.18178[0m[0m | time: 21.325s
[2K
| RMSProp | epoch: 017 | loss: 0.18178 - acc: 0.9450 -- iter: 0832/1350
[A[ATraining Step: 715  | total loss: [1m[32m0.17897[0m[0m | time: 22.213s
[2K
| RMSProp | epoch: 017 | loss: 0.17897 - acc: 0.9412 -- iter: 0864/1350
[A[ATraining Step: 716  | total loss: [1m[32m0.29985[0m[0m | time: 23.085s
[2K
| RMSProp | epoch: 017 | loss: 0.29985 - acc: 0.9095 -- iter: 0896/1350
[A[ATraining Step: 717  | total loss: [1m[32m0.34183[0m[0m | time: 23.874s
[2K
| RMSProp | epoch: 017 | loss: 0.34183 - acc: 0.8686 -- iter: 0928/1350
[A[ATraining Step: 718  | total loss: [1m[32m0.34128[0m[0m | time: 24.878s
[2K
| RMSProp | epoch: 017 | loss: 0.34128 - acc: 0.8661 -- iter: 0960/1350
[A[ATraining Step: 719  | total loss: [1m[32m0.32674[0m[0m | time: 25.850s
[2K
| RMSProp | epoch: 017 | loss: 0.32674 - acc: 0.8732 -- iter: 0992/1350
[A[ATraining Step: 720  | total loss: [1m[32m0.30534[0m[0m | time: 26.694s
[2K
| RMSProp | epoch: 017 | loss: 0.30534 - acc: 0.8828 -- iter: 1024/1350
[A[ATraining Step: 721  | total loss: [1m[32m0.31325[0m[0m | time: 27.451s
[2K
| RMSProp | epoch: 017 | loss: 0.31325 - acc: 0.8820 -- iter: 1056/1350
[A[ATraining Step: 722  | total loss: [1m[32m0.31686[0m[0m | time: 28.332s
[2K
| RMSProp | epoch: 017 | loss: 0.31686 - acc: 0.8813 -- iter: 1088/1350
[A[ATraining Step: 723  | total loss: [1m[32m0.29859[0m[0m | time: 29.190s
[2K
| RMSProp | epoch: 017 | loss: 0.29859 - acc: 0.8932 -- iter: 1120/1350
[A[ATraining Step: 724  | total loss: [1m[32m0.27747[0m[0m | time: 30.045s
[2K
| RMSProp | epoch: 017 | loss: 0.27747 - acc: 0.9007 -- iter: 1152/1350
[A[ATraining Step: 725  | total loss: [1m[32m0.26418[0m[0m | time: 30.905s
[2K
| RMSProp | epoch: 017 | loss: 0.26418 - acc: 0.9075 -- iter: 1184/1350
[A[ATraining Step: 726  | total loss: [1m[32m0.24252[0m[0m | time: 31.735s
[2K
| RMSProp | epoch: 017 | loss: 0.24252 - acc: 0.9168 -- iter: 1216/1350
[A[ATraining Step: 727  | total loss: [1m[32m0.23086[0m[0m | time: 32.599s
[2K
| RMSProp | epoch: 017 | loss: 0.23086 - acc: 0.9220 -- iter: 1248/1350
[A[ATraining Step: 728  | total loss: [1m[32m0.21493[0m[0m | time: 33.443s
[2K
| RMSProp | epoch: 017 | loss: 0.21493 - acc: 0.9298 -- iter: 1280/1350
[A[ATraining Step: 729  | total loss: [1m[32m0.19899[0m[0m | time: 34.257s
[2K
| RMSProp | epoch: 017 | loss: 0.19899 - acc: 0.9368 -- iter: 1312/1350
[A[ATraining Step: 730  | total loss: [1m[32m0.19055[0m[0m | time: 35.157s
[2K
| RMSProp | epoch: 017 | loss: 0.19055 - acc: 0.9400 -- iter: 1344/1350
[A[ATraining Step: 731  | total loss: [1m[32m0.23253[0m[0m | time: 37.906s
[2K
| RMSProp | epoch: 017 | loss: 0.23253 - acc: 0.9241 | val_loss: 0.36305 - val_acc: 0.8558 -- iter: 1350/1350
--
Training Step: 732  | total loss: [1m[32m0.25292[0m[0m | time: 0.955s
[2K
| RMSProp | epoch: 018 | loss: 0.25292 - acc: 0.9161 -- iter: 0032/1350
[A[ATraining Step: 733  | total loss: [1m[32m0.27518[0m[0m | time: 1.820s
[2K
| RMSProp | epoch: 018 | loss: 0.27518 - acc: 0.9120 -- iter: 0064/1350
[A[ATraining Step: 734  | total loss: [1m[32m0.26643[0m[0m | time: 2.702s
[2K
| RMSProp | epoch: 018 | loss: 0.26643 - acc: 0.9177 -- iter: 0096/1350
[A[ATraining Step: 735  | total loss: [1m[32m0.25127[0m[0m | time: 3.476s
[2K
| RMSProp | epoch: 018 | loss: 0.25127 - acc: 0.9228 -- iter: 0128/1350
[A[ATraining Step: 736  | total loss: [1m[32m0.23632[0m[0m | time: 4.463s
[2K
| RMSProp | epoch: 018 | loss: 0.23632 - acc: 0.9274 -- iter: 0160/1350
[A[ATraining Step: 737  | total loss: [1m[32m0.25267[0m[0m | time: 5.452s
[2K
| RMSProp | epoch: 018 | loss: 0.25267 - acc: 0.9221 -- iter: 0192/1350
[A[ATraining Step: 738  | total loss: [1m[32m0.23794[0m[0m | time: 6.309s
[2K
| RMSProp | epoch: 018 | loss: 0.23794 - acc: 0.9268 -- iter: 0224/1350
[A[ATraining Step: 739  | total loss: [1m[32m0.22665[0m[0m | time: 7.082s
[2K
| RMSProp | epoch: 018 | loss: 0.22665 - acc: 0.9310 -- iter: 0256/1350
[A[ATraining Step: 740  | total loss: [1m[32m0.21264[0m[0m | time: 7.952s
[2K
| RMSProp | epoch: 018 | loss: 0.21264 - acc: 0.9348 -- iter: 0288/1350
[A[ATraining Step: 741  | total loss: [1m[32m0.21237[0m[0m | time: 8.849s
[2K
| RMSProp | epoch: 018 | loss: 0.21237 - acc: 0.9288 -- iter: 0320/1350
[A[ATraining Step: 742  | total loss: [1m[32m0.20532[0m[0m | time: 9.716s
[2K
| RMSProp | epoch: 018 | loss: 0.20532 - acc: 0.9297 -- iter: 0352/1350
[A[ATraining Step: 743  | total loss: [1m[32m0.18821[0m[0m | time: 10.601s
[2K
| RMSProp | epoch: 018 | loss: 0.18821 - acc: 0.9367 -- iter: 0384/1350
[A[ATraining Step: 744  | total loss: [1m[32m0.19242[0m[0m | time: 11.487s
[2K
| RMSProp | epoch: 018 | loss: 0.19242 - acc: 0.9336 -- iter: 0416/1350
[A[ATraining Step: 745  | total loss: [1m[32m0.19251[0m[0m | time: 12.391s
[2K
| RMSProp | epoch: 018 | loss: 0.19251 - acc: 0.9309 -- iter: 0448/1350
[A[ATraining Step: 746  | total loss: [1m[32m0.21210[0m[0m | time: 13.249s
[2K
| RMSProp | epoch: 018 | loss: 0.21210 - acc: 0.9222 -- iter: 0480/1350
[A[ATraining Step: 747  | total loss: [1m[32m0.21321[0m[0m | time: 13.423s
[2K
| RMSProp | epoch: 018 | loss: 0.21321 - acc: 0.9206 -- iter: 0512/1350
[A[ATraining Step: 748  | total loss: [1m[32m0.20482[0m[0m | time: 13.589s
[2K
| RMSProp | epoch: 018 | loss: 0.20482 - acc: 0.9285 -- iter: 0544/1350
[A[ATraining Step: 749  | total loss: [1m[32m0.18565[0m[0m | time: 14.516s
[2K
| RMSProp | epoch: 018 | loss: 0.18565 - acc: 0.9357 -- iter: 0576/1350
[A[ATraining Step: 750  | total loss: [1m[32m0.17281[0m[0m | time: 15.528s
[2K
| RMSProp | epoch: 018 | loss: 0.17281 - acc: 0.9421 -- iter: 0608/1350
[A[ATraining Step: 751  | total loss: [1m[32m0.16217[0m[0m | time: 16.436s
[2K
| RMSProp | epoch: 018 | loss: 0.16217 - acc: 0.9448 -- iter: 0640/1350
[A[ATraining Step: 752  | total loss: [1m[32m0.15130[0m[0m | time: 17.160s
[2K
| RMSProp | epoch: 018 | loss: 0.15130 - acc: 0.9472 -- iter: 0672/1350
[A[ATraining Step: 753  | total loss: [1m[32m0.14825[0m[0m | time: 18.005s
[2K
| RMSProp | epoch: 018 | loss: 0.14825 - acc: 0.9462 -- iter: 0704/1350
[A[ATraining Step: 754  | total loss: [1m[32m0.18142[0m[0m | time: 18.841s
[2K
| RMSProp | epoch: 018 | loss: 0.18142 - acc: 0.9297 -- iter: 0736/1350
[A[ATraining Step: 755  | total loss: [1m[32m0.17546[0m[0m | time: 19.673s
[2K
| RMSProp | epoch: 018 | loss: 0.17546 - acc: 0.9305 -- iter: 0768/1350
[A[ATraining Step: 756  | total loss: [1m[32m0.17185[0m[0m | time: 20.521s
[2K
| RMSProp | epoch: 018 | loss: 0.17185 - acc: 0.9312 -- iter: 0800/1350
[A[ATraining Step: 757  | total loss: [1m[32m0.15846[0m[0m | time: 21.432s
[2K
| RMSProp | epoch: 018 | loss: 0.15846 - acc: 0.9381 -- iter: 0832/1350
[A[ATraining Step: 758  | total loss: [1m[32m0.14591[0m[0m | time: 22.305s
[2K
| RMSProp | epoch: 018 | loss: 0.14591 - acc: 0.9443 -- iter: 0864/1350
[A[ATraining Step: 759  | total loss: [1m[32m0.14513[0m[0m | time: 23.177s
[2K
| RMSProp | epoch: 018 | loss: 0.14513 - acc: 0.9405 -- iter: 0896/1350
[A[ATraining Step: 760  | total loss: [1m[32m0.24822[0m[0m | time: 24.023s
[2K
| RMSProp | epoch: 018 | loss: 0.24822 - acc: 0.9027 -- iter: 0928/1350
[A[ATraining Step: 761  | total loss: [1m[32m0.22912[0m[0m | time: 24.964s
[2K
| RMSProp | epoch: 018 | loss: 0.22912 - acc: 0.9124 -- iter: 0960/1350
[A[ATraining Step: 762  | total loss: [1m[32m0.21555[0m[0m | time: 25.926s
[2K
| RMSProp | epoch: 018 | loss: 0.21555 - acc: 0.9180 -- iter: 0992/1350
[A[ATraining Step: 763  | total loss: [1m[32m0.19726[0m[0m | time: 26.832s
[2K
| RMSProp | epoch: 018 | loss: 0.19726 - acc: 0.9262 -- iter: 1024/1350
[A[ATraining Step: 764  | total loss: [1m[32m0.18374[0m[0m | time: 27.565s
[2K
| RMSProp | epoch: 018 | loss: 0.18374 - acc: 0.9305 -- iter: 1056/1350
[A[ATraining Step: 765  | total loss: [1m[32m0.18268[0m[0m | time: 28.404s
[2K
| RMSProp | epoch: 018 | loss: 0.18268 - acc: 0.9312 -- iter: 1088/1350
[A[ATraining Step: 766  | total loss: [1m[32m0.17452[0m[0m | time: 29.259s
[2K
| RMSProp | epoch: 018 | loss: 0.17452 - acc: 0.9318 -- iter: 1120/1350
[A[ATraining Step: 767  | total loss: [1m[32m0.16615[0m[0m | time: 30.126s
[2K
| RMSProp | epoch: 018 | loss: 0.16615 - acc: 0.9355 -- iter: 1152/1350
[A[ATraining Step: 768  | total loss: [1m[32m0.16550[0m[0m | time: 30.996s
[2K
| RMSProp | epoch: 018 | loss: 0.16550 - acc: 0.9326 -- iter: 1184/1350
[A[ATraining Step: 769  | total loss: [1m[32m0.16774[0m[0m | time: 31.867s
[2K
| RMSProp | epoch: 018 | loss: 0.16774 - acc: 0.9331 -- iter: 1216/1350
[A[ATraining Step: 770  | total loss: [1m[32m0.15433[0m[0m | time: 32.714s
[2K
| RMSProp | epoch: 018 | loss: 0.15433 - acc: 0.9398 -- iter: 1248/1350
[A[ATraining Step: 771  | total loss: [1m[32m0.14158[0m[0m | time: 33.625s
[2K
| RMSProp | epoch: 018 | loss: 0.14158 - acc: 0.9458 -- iter: 1280/1350
[A[ATraining Step: 772  | total loss: [1m[32m0.13078[0m[0m | time: 34.389s
[2K
| RMSProp | epoch: 018 | loss: 0.13078 - acc: 0.9512 -- iter: 1312/1350
[A[ATraining Step: 773  | total loss: [1m[32m0.11985[0m[0m | time: 35.384s
[2K
| RMSProp | epoch: 018 | loss: 0.11985 - acc: 0.9561 -- iter: 1344/1350
[A[ATraining Step: 774  | total loss: [1m[32m0.10847[0m[0m | time: 38.026s
[2K
| RMSProp | epoch: 018 | loss: 0.10847 - acc: 0.9605 | val_loss: 0.35657 - val_acc: 0.8983 -- iter: 1350/1350
--
Training Step: 775  | total loss: [1m[32m0.10972[0m[0m | time: 0.905s
[2K
| RMSProp | epoch: 019 | loss: 0.10972 - acc: 0.9582 -- iter: 0032/1350
[A[ATraining Step: 776  | total loss: [1m[32m0.09995[0m[0m | time: 1.734s
[2K
| RMSProp | epoch: 019 | loss: 0.09995 - acc: 0.9624 -- iter: 0064/1350
[A[ATraining Step: 777  | total loss: [1m[32m0.10846[0m[0m | time: 2.708s
[2K
| RMSProp | epoch: 019 | loss: 0.10846 - acc: 0.9599 -- iter: 0096/1350
[A[ATraining Step: 778  | total loss: [1m[32m0.14030[0m[0m | time: 3.690s
[2K
| RMSProp | epoch: 019 | loss: 0.14030 - acc: 0.9451 -- iter: 0128/1350
[A[ATraining Step: 779  | total loss: [1m[32m0.14874[0m[0m | time: 4.486s
[2K
| RMSProp | epoch: 019 | loss: 0.14874 - acc: 0.9444 -- iter: 0160/1350
[A[ATraining Step: 780  | total loss: [1m[32m0.13908[0m[0m | time: 5.278s
[2K
| RMSProp | epoch: 019 | loss: 0.13908 - acc: 0.9499 -- iter: 0192/1350
[A[ATraining Step: 781  | total loss: [1m[32m0.12879[0m[0m | time: 6.123s
[2K
| RMSProp | epoch: 019 | loss: 0.12879 - acc: 0.9549 -- iter: 0224/1350
[A[ATraining Step: 782  | total loss: [1m[32m0.13122[0m[0m | time: 6.932s
[2K
| RMSProp | epoch: 019 | loss: 0.13122 - acc: 0.9563 -- iter: 0256/1350
[A[ATraining Step: 783  | total loss: [1m[32m0.14236[0m[0m | time: 7.764s
[2K
| RMSProp | epoch: 019 | loss: 0.14236 - acc: 0.9544 -- iter: 0288/1350
[A[ATraining Step: 784  | total loss: [1m[32m0.13556[0m[0m | time: 8.600s
[2K
| RMSProp | epoch: 019 | loss: 0.13556 - acc: 0.9559 -- iter: 0320/1350
[A[ATraining Step: 785  | total loss: [1m[32m0.12283[0m[0m | time: 9.483s
[2K
| RMSProp | epoch: 019 | loss: 0.12283 - acc: 0.9603 -- iter: 0352/1350
[A[ATraining Step: 786  | total loss: [1m[32m0.11183[0m[0m | time: 10.360s
[2K
| RMSProp | epoch: 019 | loss: 0.11183 - acc: 0.9643 -- iter: 0384/1350
[A[ATraining Step: 787  | total loss: [1m[32m0.12391[0m[0m | time: 11.252s
[2K
| RMSProp | epoch: 019 | loss: 0.12391 - acc: 0.9616 -- iter: 0416/1350
[A[ATraining Step: 788  | total loss: [1m[32m0.11684[0m[0m | time: 12.112s
[2K
| RMSProp | epoch: 019 | loss: 0.11684 - acc: 0.9654 -- iter: 0448/1350
[A[ATraining Step: 789  | total loss: [1m[32m0.10976[0m[0m | time: 13.072s
[2K
| RMSProp | epoch: 019 | loss: 0.10976 - acc: 0.9689 -- iter: 0480/1350
[A[ATraining Step: 790  | total loss: [1m[32m0.10054[0m[0m | time: 14.062s
[2K
| RMSProp | epoch: 019 | loss: 0.10054 - acc: 0.9720 -- iter: 0512/1350
[A[ATraining Step: 791  | total loss: [1m[32m0.09191[0m[0m | time: 14.285s
[2K
| RMSProp | epoch: 019 | loss: 0.09191 - acc: 0.9748 -- iter: 0544/1350
[A[ATraining Step: 792  | total loss: [1m[32m0.08305[0m[0m | time: 14.505s
[2K
| RMSProp | epoch: 019 | loss: 0.08305 - acc: 0.9773 -- iter: 0576/1350
[A[ATraining Step: 793  | total loss: [1m[32m0.07488[0m[0m | time: 15.206s
[2K
| RMSProp | epoch: 019 | loss: 0.07488 - acc: 0.9796 -- iter: 0608/1350
[A[ATraining Step: 794  | total loss: [1m[32m0.07037[0m[0m | time: 16.019s
[2K
| RMSProp | epoch: 019 | loss: 0.07037 - acc: 0.9785 -- iter: 0640/1350
[A[ATraining Step: 795  | total loss: [1m[32m0.06690[0m[0m | time: 16.883s
[2K
| RMSProp | epoch: 019 | loss: 0.06690 - acc: 0.9775 -- iter: 0672/1350
[A[ATraining Step: 796  | total loss: [1m[32m0.07379[0m[0m | time: 17.742s
[2K
| RMSProp | epoch: 019 | loss: 0.07379 - acc: 0.9766 -- iter: 0704/1350
[A[ATraining Step: 797  | total loss: [1m[32m0.10646[0m[0m | time: 18.637s
[2K
| RMSProp | epoch: 019 | loss: 0.10646 - acc: 0.9665 -- iter: 0736/1350
[A[ATraining Step: 798  | total loss: [1m[32m0.12837[0m[0m | time: 19.523s
[2K
| RMSProp | epoch: 019 | loss: 0.12837 - acc: 0.9573 -- iter: 0768/1350
[A[ATraining Step: 799  | total loss: [1m[32m0.12253[0m[0m | time: 20.489s
[2K
| RMSProp | epoch: 019 | loss: 0.12253 - acc: 0.9616 -- iter: 0800/1350
[A[ATraining Step: 800  | total loss: [1m[32m0.11628[0m[0m | time: 23.181s
[2K
| RMSProp | epoch: 019 | loss: 0.11628 - acc: 0.9623 | val_loss: 0.54986 - val_acc: 0.8274 -- iter: 0832/1350
--
Training Step: 801  | total loss: [1m[32m0.11182[0m[0m | time: 24.105s
[2K
| RMSProp | epoch: 019 | loss: 0.11182 - acc: 0.9661 -- iter: 0864/1350
[A[ATraining Step: 802  | total loss: [1m[32m0.14541[0m[0m | time: 25.015s
[2K
| RMSProp | epoch: 019 | loss: 0.14541 - acc: 0.9570 -- iter: 0896/1350
[A[ATraining Step: 803  | total loss: [1m[32m0.17988[0m[0m | time: 25.951s
[2K
| RMSProp | epoch: 019 | loss: 0.17988 - acc: 0.9457 -- iter: 0928/1350
[A[ATraining Step: 804  | total loss: [1m[32m0.25920[0m[0m | time: 26.871s
[2K
| RMSProp | epoch: 019 | loss: 0.25920 - acc: 0.9105 -- iter: 0960/1350
[A[ATraining Step: 805  | total loss: [1m[32m0.31912[0m[0m | time: 27.813s
[2K
| RMSProp | epoch: 019 | loss: 0.31912 - acc: 0.8725 -- iter: 0992/1350
[A[ATraining Step: 806  | total loss: [1m[32m0.31987[0m[0m | time: 28.741s
[2K
| RMSProp | epoch: 019 | loss: 0.31987 - acc: 0.8728 -- iter: 1024/1350
[A[ATraining Step: 807  | total loss: [1m[32m0.31374[0m[0m | time: 29.700s
[2K
| RMSProp | epoch: 019 | loss: 0.31374 - acc: 0.8793 -- iter: 1056/1350
[A[ATraining Step: 808  | total loss: [1m[32m0.28783[0m[0m | time: 30.641s
[2K
| RMSProp | epoch: 019 | loss: 0.28783 - acc: 0.8913 -- iter: 1088/1350
[A[ATraining Step: 809  | total loss: [1m[32m0.26425[0m[0m | time: 31.532s
[2K
| RMSProp | epoch: 019 | loss: 0.26425 - acc: 0.9022 -- iter: 1120/1350
[A[ATraining Step: 810  | total loss: [1m[32m0.24140[0m[0m | time: 32.412s
[2K
| RMSProp | epoch: 019 | loss: 0.24140 - acc: 0.9120 -- iter: 1152/1350
[A[ATraining Step: 811  | total loss: [1m[32m0.21872[0m[0m | time: 33.429s
[2K
| RMSProp | epoch: 019 | loss: 0.21872 - acc: 0.9208 -- iter: 1184/1350
[A[ATraining Step: 812  | total loss: [1m[32m0.20122[0m[0m | time: 34.347s
[2K
| RMSProp | epoch: 019 | loss: 0.20122 - acc: 0.9256 -- iter: 1216/1350
[A[ATraining Step: 813  | total loss: [1m[32m0.23917[0m[0m | time: 35.268s
[2K
| RMSProp | epoch: 019 | loss: 0.23917 - acc: 0.9174 -- iter: 1248/1350
[A[ATraining Step: 814  | total loss: [1m[32m0.24329[0m[0m | time: 36.252s
[2K
| RMSProp | epoch: 019 | loss: 0.24329 - acc: 0.9132 -- iter: 1280/1350
[A[ATraining Step: 815  | total loss: [1m[32m0.22991[0m[0m | time: 37.166s
[2K
| RMSProp | epoch: 019 | loss: 0.22991 - acc: 0.9156 -- iter: 1312/1350
[A[ATraining Step: 816  | total loss: [1m[32m0.23171[0m[0m | time: 38.109s
[2K
| RMSProp | epoch: 019 | loss: 0.23171 - acc: 0.9178 -- iter: 1344/1350
[A[ATraining Step: 817  | total loss: [1m[32m0.21918[0m[0m | time: 40.972s
[2K
| RMSProp | epoch: 019 | loss: 0.21918 - acc: 0.9229 | val_loss: 0.26875 - val_acc: 0.9054 -- iter: 1350/1350
--
Training Step: 818  | total loss: [1m[32m0.20694[0m[0m | time: 0.933s
[2K
| RMSProp | epoch: 020 | loss: 0.20694 - acc: 0.9275 -- iter: 0032/1350
[A[ATraining Step: 819  | total loss: [1m[32m0.18833[0m[0m | time: 1.856s
[2K
| RMSProp | epoch: 020 | loss: 0.18833 - acc: 0.9347 -- iter: 0064/1350
[A[ATraining Step: 820  | total loss: [1m[32m0.17731[0m[0m | time: 2.781s
[2K
| RMSProp | epoch: 020 | loss: 0.17731 - acc: 0.9381 -- iter: 0096/1350
[A[ATraining Step: 821  | total loss: [1m[32m0.16593[0m[0m | time: 3.727s
[2K
| RMSProp | epoch: 020 | loss: 0.16593 - acc: 0.9412 -- iter: 0128/1350
[A[ATraining Step: 822  | total loss: [1m[32m0.15223[0m[0m | time: 4.657s
[2K
| RMSProp | epoch: 020 | loss: 0.15223 - acc: 0.9471 -- iter: 0160/1350
[A[ATraining Step: 823  | total loss: [1m[32m0.13812[0m[0m | time: 5.586s
[2K
| RMSProp | epoch: 020 | loss: 0.13812 - acc: 0.9524 -- iter: 0192/1350
[A[ATraining Step: 824  | total loss: [1m[32m0.12880[0m[0m | time: 6.492s
[2K
| RMSProp | epoch: 020 | loss: 0.12880 - acc: 0.9540 -- iter: 0224/1350
[A[ATraining Step: 825  | total loss: [1m[32m0.12190[0m[0m | time: 7.500s
[2K
| RMSProp | epoch: 020 | loss: 0.12190 - acc: 0.9555 -- iter: 0256/1350
[A[ATraining Step: 826  | total loss: [1m[32m0.12858[0m[0m | time: 8.438s
[2K
| RMSProp | epoch: 020 | loss: 0.12858 - acc: 0.9506 -- iter: 0288/1350
[A[ATraining Step: 827  | total loss: [1m[32m0.12033[0m[0m | time: 9.365s
[2K
| RMSProp | epoch: 020 | loss: 0.12033 - acc: 0.9555 -- iter: 0320/1350
[A[ATraining Step: 828  | total loss: [1m[32m0.10943[0m[0m | time: 10.315s
[2K
| RMSProp | epoch: 020 | loss: 0.10943 - acc: 0.9599 -- iter: 0352/1350
[A[ATraining Step: 829  | total loss: [1m[32m0.10398[0m[0m | time: 11.209s
[2K
| RMSProp | epoch: 020 | loss: 0.10398 - acc: 0.9577 -- iter: 0384/1350
[A[ATraining Step: 830  | total loss: [1m[32m0.09787[0m[0m | time: 12.105s
[2K
| RMSProp | epoch: 020 | loss: 0.09787 - acc: 0.9619 -- iter: 0416/1350
[A[ATraining Step: 831  | total loss: [1m[32m0.08829[0m[0m | time: 13.060s
[2K
| RMSProp | epoch: 020 | loss: 0.08829 - acc: 0.9657 -- iter: 0448/1350
[A[ATraining Step: 832  | total loss: [1m[32m0.10844[0m[0m | time: 13.978s
[2K
| RMSProp | epoch: 020 | loss: 0.10844 - acc: 0.9629 -- iter: 0480/1350
[A[ATraining Step: 833  | total loss: [1m[32m0.10373[0m[0m | time: 14.909s
[2K
| RMSProp | epoch: 020 | loss: 0.10373 - acc: 0.9635 -- iter: 0512/1350
[A[ATraining Step: 834  | total loss: [1m[32m0.10447[0m[0m | time: 15.841s
[2K
| RMSProp | epoch: 020 | loss: 0.10447 - acc: 0.9640 -- iter: 0544/1350
[A[ATraining Step: 835  | total loss: [1m[32m0.09667[0m[0m | time: 16.091s
[2K
| RMSProp | epoch: 020 | loss: 0.09667 - acc: 0.9676 -- iter: 0576/1350
[A[ATraining Step: 836  | total loss: [1m[32m0.08762[0m[0m | time: 16.300s
[2K
| RMSProp | epoch: 020 | loss: 0.08762 - acc: 0.9709 -- iter: 0608/1350
[A[ATraining Step: 837  | total loss: [1m[32m0.07913[0m[0m | time: 17.267s
[2K
| RMSProp | epoch: 020 | loss: 0.07913 - acc: 0.9738 -- iter: 0640/1350
[A[ATraining Step: 838  | total loss: [1m[32m0.07141[0m[0m | time: 18.183s
[2K
| RMSProp | epoch: 020 | loss: 0.07141 - acc: 0.9764 -- iter: 0672/1350
[A[ATraining Step: 839  | total loss: [1m[32m0.06998[0m[0m | time: 19.151s
[2K
| RMSProp | epoch: 020 | loss: 0.06998 - acc: 0.9756 -- iter: 0704/1350
[A[ATraining Step: 840  | total loss: [1m[32m0.09454[0m[0m | time: 20.065s
[2K
| RMSProp | epoch: 020 | loss: 0.09454 - acc: 0.9656 -- iter: 0736/1350
[A[ATraining Step: 841  | total loss: [1m[32m0.10791[0m[0m | time: 21.028s
[2K
| RMSProp | epoch: 020 | loss: 0.10791 - acc: 0.9628 -- iter: 0768/1350
[A[ATraining Step: 842  | total loss: [1m[32m0.10278[0m[0m | time: 21.932s
[2K
| RMSProp | epoch: 020 | loss: 0.10278 - acc: 0.9665 -- iter: 0800/1350
[A[ATraining Step: 843  | total loss: [1m[32m0.10680[0m[0m | time: 22.831s
[2K
| RMSProp | epoch: 020 | loss: 0.10680 - acc: 0.9605 -- iter: 0832/1350
[A[ATraining Step: 844  | total loss: [1m[32m0.11170[0m[0m | time: 23.733s
[2K
| RMSProp | epoch: 020 | loss: 0.11170 - acc: 0.9582 -- iter: 0864/1350
[A[ATraining Step: 845  | total loss: [1m[32m0.12213[0m[0m | time: 24.673s
[2K
| RMSProp | epoch: 020 | loss: 0.12213 - acc: 0.9530 -- iter: 0896/1350
[A[ATraining Step: 846  | total loss: [1m[32m0.12241[0m[0m | time: 25.545s
[2K
| RMSProp | epoch: 020 | loss: 0.12241 - acc: 0.9514 -- iter: 0928/1350
[A[ATraining Step: 847  | total loss: [1m[32m0.11519[0m[0m | time: 26.530s
[2K
| RMSProp | epoch: 020 | loss: 0.11519 - acc: 0.9532 -- iter: 0960/1350
[A[ATraining Step: 848  | total loss: [1m[32m0.14605[0m[0m | time: 27.434s
[2K
| RMSProp | epoch: 020 | loss: 0.14605 - acc: 0.9516 -- iter: 0992/1350
[A[ATraining Step: 849  | total loss: [1m[32m0.19501[0m[0m | time: 28.344s
[2K
| RMSProp | epoch: 020 | loss: 0.19501 - acc: 0.9377 -- iter: 1024/1350
[A[ATraining Step: 850  | total loss: [1m[32m0.18173[0m[0m | time: 29.241s
[2K
| RMSProp | epoch: 020 | loss: 0.18173 - acc: 0.9439 -- iter: 1056/1350
[A[ATraining Step: 851  | total loss: [1m[32m0.16722[0m[0m | time: 30.157s
[2K
| RMSProp | epoch: 020 | loss: 0.16722 - acc: 0.9495 -- iter: 1088/1350
[A[ATraining Step: 852  | total loss: [1m[32m0.15308[0m[0m | time: 31.059s
[2K
| RMSProp | epoch: 020 | loss: 0.15308 - acc: 0.9546 -- iter: 1120/1350
[A[ATraining Step: 853  | total loss: [1m[32m0.13924[0m[0m | time: 31.976s
[2K
| RMSProp | epoch: 020 | loss: 0.13924 - acc: 0.9591 -- iter: 1152/1350
[A[ATraining Step: 854  | total loss: [1m[32m0.12776[0m[0m | time: 32.858s
[2K
| RMSProp | epoch: 020 | loss: 0.12776 - acc: 0.9632 -- iter: 1184/1350
[A[ATraining Step: 855  | total loss: [1m[32m0.11947[0m[0m | time: 33.786s
[2K
| RMSProp | epoch: 020 | loss: 0.11947 - acc: 0.9638 -- iter: 1216/1350
[A[ATraining Step: 856  | total loss: [1m[32m0.11396[0m[0m | time: 34.733s
[2K
| RMSProp | epoch: 020 | loss: 0.11396 - acc: 0.9643 -- iter: 1248/1350
[A[ATraining Step: 857  | total loss: [1m[32m0.10746[0m[0m | time: 35.702s
[2K
| RMSProp | epoch: 020 | loss: 0.10746 - acc: 0.9647 -- iter: 1280/1350
[A[ATraining Step: 858  | total loss: [1m[32m0.11194[0m[0m | time: 36.630s
[2K
| RMSProp | epoch: 020 | loss: 0.11194 - acc: 0.9651 -- iter: 1312/1350
[A[ATraining Step: 859  | total loss: [1m[32m0.10393[0m[0m | time: 37.536s
[2K
| RMSProp | epoch: 020 | loss: 0.10393 - acc: 0.9686 -- iter: 1344/1350
[A[ATraining Step: 860  | total loss: [1m[32m0.09946[0m[0m | time: 40.477s
[2K
| RMSProp | epoch: 020 | loss: 0.09946 - acc: 0.9686 | val_loss: 0.45931 - val_acc: 0.8416 -- iter: 1350/1350
--
Training Step: 861  | total loss: [1m[32m0.11562[0m[0m | time: 0.903s
[2K
| RMSProp | epoch: 021 | loss: 0.11562 - acc: 0.9624 -- iter: 0032/1350
[A[ATraining Step: 862  | total loss: [1m[32m0.11437[0m[0m | time: 1.862s
[2K
| RMSProp | epoch: 021 | loss: 0.11437 - acc: 0.9630 -- iter: 0064/1350
[A[ATraining Step: 863  | total loss: [1m[32m0.11539[0m[0m | time: 2.781s
[2K
| RMSProp | epoch: 021 | loss: 0.11539 - acc: 0.9636 -- iter: 0096/1350
[A[ATraining Step: 864  | total loss: [1m[32m0.10537[0m[0m | time: 3.752s
[2K
| RMSProp | epoch: 021 | loss: 0.10537 - acc: 0.9672 -- iter: 0128/1350
[A[ATraining Step: 865  | total loss: [1m[32m0.09653[0m[0m | time: 4.570s
[2K
| RMSProp | epoch: 021 | loss: 0.09653 - acc: 0.9705 -- iter: 0160/1350
[A[ATraining Step: 866  | total loss: [1m[32m0.09583[0m[0m | time: 5.197s
[2K
| RMSProp | epoch: 021 | loss: 0.09583 - acc: 0.9672 -- iter: 0192/1350
[A[ATraining Step: 867  | total loss: [1m[32m0.09025[0m[0m | time: 5.811s
[2K
| RMSProp | epoch: 021 | loss: 0.09025 - acc: 0.9705 -- iter: 0224/1350
[A[ATraining Step: 868  | total loss: [1m[32m0.08178[0m[0m | time: 6.438s
[2K
| RMSProp | epoch: 021 | loss: 0.08178 - acc: 0.9734 -- iter: 0256/1350
[A[ATraining Step: 869  | total loss: [1m[32m0.07395[0m[0m | time: 7.051s
[2K
| RMSProp | epoch: 021 | loss: 0.07395 - acc: 0.9761 -- iter: 0288/1350
[A[ATraining Step: 870  | total loss: [1m[32m0.08310[0m[0m | time: 7.658s
[2K
| RMSProp | epoch: 021 | loss: 0.08310 - acc: 0.9754 -- iter: 0320/1350
[A[ATraining Step: 871  | total loss: [1m[32m0.08656[0m[0m | time: 8.270s
[2K
| RMSProp | epoch: 021 | loss: 0.08656 - acc: 0.9747 -- iter: 0352/1350
[A[ATraining Step: 872  | total loss: [1m[32m0.09308[0m[0m | time: 8.879s
[2K
| RMSProp | epoch: 021 | loss: 0.09308 - acc: 0.9741 -- iter: 0384/1350
[A[ATraining Step: 873  | total loss: [1m[32m0.08735[0m[0m | time: 9.486s
[2K
| RMSProp | epoch: 021 | loss: 0.08735 - acc: 0.9767 -- iter: 0416/1350
[A[ATraining Step: 874  | total loss: [1m[32m0.09209[0m[0m | time: 10.102s
[2K
| RMSProp | epoch: 021 | loss: 0.09209 - acc: 0.9728 -- iter: 0448/1350
[A[ATraining Step: 875  | total loss: [1m[32m0.10339[0m[0m | time: 10.689s
[2K
| RMSProp | epoch: 021 | loss: 0.10339 - acc: 0.9661 -- iter: 0480/1350
[A[ATraining Step: 876  | total loss: [1m[32m0.11595[0m[0m | time: 11.297s
[2K
| RMSProp | epoch: 021 | loss: 0.11595 - acc: 0.9601 -- iter: 0512/1350
[A[ATraining Step: 877  | total loss: [1m[32m0.11346[0m[0m | time: 11.918s
[2K
| RMSProp | epoch: 021 | loss: 0.11346 - acc: 0.9610 -- iter: 0544/1350
[A[ATraining Step: 878  | total loss: [1m[32m0.10772[0m[0m | time: 12.515s
[2K
| RMSProp | epoch: 021 | loss: 0.10772 - acc: 0.9618 -- iter: 0576/1350
[A[ATraining Step: 879  | total loss: [1m[32m0.10235[0m[0m | time: 12.657s
[2K
| RMSProp | epoch: 021 | loss: 0.10235 - acc: 0.9656 -- iter: 0608/1350
[A[ATraining Step: 880  | total loss: [1m[32m0.09491[0m[0m | time: 12.813s
[2K
| RMSProp | epoch: 021 | loss: 0.09491 - acc: 0.9690 -- iter: 0640/1350
[A[ATraining Step: 881  | total loss: [1m[32m0.08571[0m[0m | time: 13.429s
[2K
| RMSProp | epoch: 021 | loss: 0.08571 - acc: 0.9721 -- iter: 0672/1350
[A[ATraining Step: 882  | total loss: [1m[32m0.08050[0m[0m | time: 14.043s
[2K
| RMSProp | epoch: 021 | loss: 0.08050 - acc: 0.9718 -- iter: 0704/1350
[A[ATraining Step: 883  | total loss: [1m[32m0.07510[0m[0m | time: 14.646s
[2K
| RMSProp | epoch: 021 | loss: 0.07510 - acc: 0.9746 -- iter: 0736/1350
[A[ATraining Step: 884  | total loss: [1m[32m0.06874[0m[0m | time: 15.252s
[2K
| RMSProp | epoch: 021 | loss: 0.06874 - acc: 0.9772 -- iter: 0768/1350
[A[ATraining Step: 885  | total loss: [1m[32m0.07187[0m[0m | time: 15.872s
[2K
| RMSProp | epoch: 021 | loss: 0.07187 - acc: 0.9763 -- iter: 0800/1350
[A[ATraining Step: 886  | total loss: [1m[32m0.08300[0m[0m | time: 16.489s
[2K
| RMSProp | epoch: 021 | loss: 0.08300 - acc: 0.9693 -- iter: 0832/1350
[A[ATraining Step: 887  | total loss: [1m[32m0.07889[0m[0m | time: 17.100s
[2K
| RMSProp | epoch: 021 | loss: 0.07889 - acc: 0.9693 -- iter: 0864/1350
[A[ATraining Step: 888  | total loss: [1m[32m0.07578[0m[0m | time: 17.724s
[2K
| RMSProp | epoch: 021 | loss: 0.07578 - acc: 0.9692 -- iter: 0896/1350
[A[ATraining Step: 889  | total loss: [1m[32m0.08991[0m[0m | time: 18.347s
[2K
| RMSProp | epoch: 021 | loss: 0.08991 - acc: 0.9598 -- iter: 0928/1350
[A[ATraining Step: 890  | total loss: [1m[32m0.08265[0m[0m | time: 18.962s
[2K
| RMSProp | epoch: 021 | loss: 0.08265 - acc: 0.9638 -- iter: 0960/1350
[A[ATraining Step: 891  | total loss: [1m[32m0.07926[0m[0m | time: 19.589s
[2K
| RMSProp | epoch: 021 | loss: 0.07926 - acc: 0.9643 -- iter: 0992/1350
[A[ATraining Step: 892  | total loss: [1m[32m0.08498[0m[0m | time: 20.212s
[2K
| RMSProp | epoch: 021 | loss: 0.08498 - acc: 0.9647 -- iter: 1024/1350
[A[ATraining Step: 893  | total loss: [1m[32m0.10628[0m[0m | time: 20.830s
[2K
| RMSProp | epoch: 021 | loss: 0.10628 - acc: 0.9589 -- iter: 1056/1350
[A[ATraining Step: 894  | total loss: [1m[32m0.10099[0m[0m | time: 21.440s
[2K
| RMSProp | epoch: 021 | loss: 0.10099 - acc: 0.9599 -- iter: 1088/1350
[A[ATraining Step: 895  | total loss: [1m[32m0.10413[0m[0m | time: 22.045s
[2K
| RMSProp | epoch: 021 | loss: 0.10413 - acc: 0.9608 -- iter: 1120/1350
[A[ATraining Step: 896  | total loss: [1m[32m0.09596[0m[0m | time: 22.657s
[2K
| RMSProp | epoch: 021 | loss: 0.09596 - acc: 0.9647 -- iter: 1152/1350
[A[ATraining Step: 897  | total loss: [1m[32m0.10211[0m[0m | time: 23.278s
[2K
| RMSProp | epoch: 021 | loss: 0.10211 - acc: 0.9620 -- iter: 1184/1350
[A[ATraining Step: 898  | total loss: [1m[32m0.11645[0m[0m | time: 23.890s
[2K
| RMSProp | epoch: 021 | loss: 0.11645 - acc: 0.9533 -- iter: 1216/1350
[A[ATraining Step: 899  | total loss: [1m[32m0.10620[0m[0m | time: 24.495s
[2K
| RMSProp | epoch: 021 | loss: 0.10620 - acc: 0.9579 -- iter: 1248/1350
[A[ATraining Step: 900  | total loss: [1m[32m0.09958[0m[0m | time: 25.144s
[2K
| RMSProp | epoch: 021 | loss: 0.09958 - acc: 0.9590 -- iter: 1280/1350
[A[ATraining Step: 901  | total loss: [1m[32m0.09099[0m[0m | time: 25.755s
[2K
| RMSProp | epoch: 021 | loss: 0.09099 - acc: 0.9631 -- iter: 1312/1350
[A[ATraining Step: 902  | total loss: [1m[32m0.08241[0m[0m | time: 26.356s
[2K
| RMSProp | epoch: 021 | loss: 0.08241 - acc: 0.9668 -- iter: 1344/1350
[A[ATraining Step: 903  | total loss: [1m[32m0.08504[0m[0m | time: 28.323s
[2K
| RMSProp | epoch: 021 | loss: 0.08504 - acc: 0.9639 | val_loss: 0.32448 - val_acc: 0.8771 -- iter: 1350/1350
--
Training Step: 904  | total loss: [1m[32m0.18600[0m[0m | time: 0.621s
[2K
| RMSProp | epoch: 022 | loss: 0.18600 - acc: 0.9362 -- iter: 0032/1350
[A[ATraining Step: 905  | total loss: [1m[32m0.18073[0m[0m | time: 1.220s
[2K
| RMSProp | epoch: 022 | loss: 0.18073 - acc: 0.9364 -- iter: 0064/1350
[A[ATraining Step: 906  | total loss: [1m[32m0.16766[0m[0m | time: 1.830s
[2K
| RMSProp | epoch: 022 | loss: 0.16766 - acc: 0.9396 -- iter: 0096/1350
[A[ATraining Step: 907  | total loss: [1m[32m0.15229[0m[0m | time: 2.514s
[2K
| RMSProp | epoch: 022 | loss: 0.15229 - acc: 0.9456 -- iter: 0128/1350
[A[ATraining Step: 908  | total loss: [1m[32m0.13805[0m[0m | time: 3.502s
[2K
| RMSProp | epoch: 022 | loss: 0.13805 - acc: 0.9511 -- iter: 0160/1350
[A[ATraining Step: 909  | total loss: [1m[32m0.12499[0m[0m | time: 4.486s
[2K
| RMSProp | epoch: 022 | loss: 0.12499 - acc: 0.9560 -- iter: 0192/1350
[A[ATraining Step: 910  | total loss: [1m[32m0.11300[0m[0m | time: 5.248s
[2K
| RMSProp | epoch: 022 | loss: 0.11300 - acc: 0.9604 -- iter: 0224/1350
[A[ATraining Step: 911  | total loss: [1m[32m0.10222[0m[0m | time: 6.036s
[2K
| RMSProp | epoch: 022 | loss: 0.10222 - acc: 0.9643 -- iter: 0256/1350
[A[ATraining Step: 912  | total loss: [1m[32m0.09796[0m[0m | time: 6.878s
[2K
| RMSProp | epoch: 022 | loss: 0.09796 - acc: 0.9617 -- iter: 0288/1350
[A[ATraining Step: 913  | total loss: [1m[32m0.08883[0m[0m | time: 7.726s
[2K
| RMSProp | epoch: 022 | loss: 0.08883 - acc: 0.9655 -- iter: 0320/1350
[A[ATraining Step: 914  | total loss: [1m[32m0.08013[0m[0m | time: 8.583s
[2K
| RMSProp | epoch: 022 | loss: 0.08013 - acc: 0.9689 -- iter: 0352/1350
[A[ATraining Step: 915  | total loss: [1m[32m0.07369[0m[0m | time: 9.433s
[2K
| RMSProp | epoch: 022 | loss: 0.07369 - acc: 0.9720 -- iter: 0384/1350
[A[ATraining Step: 916  | total loss: [1m[32m0.06728[0m[0m | time: 10.305s
[2K
| RMSProp | epoch: 022 | loss: 0.06728 - acc: 0.9748 -- iter: 0416/1350
[A[ATraining Step: 917  | total loss: [1m[32m0.06674[0m[0m | time: 11.194s
[2K
| RMSProp | epoch: 022 | loss: 0.06674 - acc: 0.9742 -- iter: 0448/1350
[A[ATraining Step: 918  | total loss: [1m[32m0.07191[0m[0m | time: 12.088s
[2K
| RMSProp | epoch: 022 | loss: 0.07191 - acc: 0.9737 -- iter: 0480/1350
[A[ATraining Step: 919  | total loss: [1m[32m0.06639[0m[0m | time: 12.933s
[2K
| RMSProp | epoch: 022 | loss: 0.06639 - acc: 0.9763 -- iter: 0512/1350
[A[ATraining Step: 920  | total loss: [1m[32m0.06054[0m[0m | time: 13.921s
[2K
| RMSProp | epoch: 022 | loss: 0.06054 - acc: 0.9787 -- iter: 0544/1350
[A[ATraining Step: 921  | total loss: [1m[32m0.05482[0m[0m | time: 14.944s
[2K
| RMSProp | epoch: 022 | loss: 0.05482 - acc: 0.9808 -- iter: 0576/1350
[A[ATraining Step: 922  | total loss: [1m[32m0.05705[0m[0m | time: 15.649s
[2K
| RMSProp | epoch: 022 | loss: 0.05705 - acc: 0.9796 -- iter: 0608/1350
[A[ATraining Step: 923  | total loss: [1m[32m0.06853[0m[0m | time: 15.829s
[2K
| RMSProp | epoch: 022 | loss: 0.06853 - acc: 0.9754 -- iter: 0640/1350
[A[ATraining Step: 924  | total loss: [1m[32m0.06220[0m[0m | time: 16.018s
[2K
| RMSProp | epoch: 022 | loss: 0.06220 - acc: 0.9779 -- iter: 0672/1350
[A[ATraining Step: 925  | total loss: [1m[32m0.05613[0m[0m | time: 16.878s
[2K
| RMSProp | epoch: 022 | loss: 0.05613 - acc: 0.9801 -- iter: 0704/1350
[A[ATraining Step: 926  | total loss: [1m[32m0.12359[0m[0m | time: 17.761s
[2K
| RMSProp | epoch: 022 | loss: 0.12359 - acc: 0.9539 -- iter: 0736/1350
[A[ATraining Step: 927  | total loss: [1m[32m0.15117[0m[0m | time: 18.598s
[2K
| RMSProp | epoch: 022 | loss: 0.15117 - acc: 0.9460 -- iter: 0768/1350
[A[ATraining Step: 928  | total loss: [1m[32m0.16710[0m[0m | time: 19.429s
[2K
| RMSProp | epoch: 022 | loss: 0.16710 - acc: 0.9421 -- iter: 0800/1350
[A[ATraining Step: 929  | total loss: [1m[32m0.15493[0m[0m | time: 20.295s
[2K
| RMSProp | epoch: 022 | loss: 0.15493 - acc: 0.9479 -- iter: 0832/1350
[A[ATraining Step: 930  | total loss: [1m[32m0.14656[0m[0m | time: 21.261s
[2K
| RMSProp | epoch: 022 | loss: 0.14656 - acc: 0.9499 -- iter: 0864/1350
[A[ATraining Step: 931  | total loss: [1m[32m0.13316[0m[0m | time: 22.178s
[2K
| RMSProp | epoch: 022 | loss: 0.13316 - acc: 0.9550 -- iter: 0896/1350
[A[ATraining Step: 932  | total loss: [1m[32m0.12377[0m[0m | time: 22.981s
[2K
| RMSProp | epoch: 022 | loss: 0.12377 - acc: 0.9563 -- iter: 0928/1350
[A[ATraining Step: 933  | total loss: [1m[32m0.12272[0m[0m | time: 23.914s
[2K
| RMSProp | epoch: 022 | loss: 0.12272 - acc: 0.9545 -- iter: 0960/1350
[A[ATraining Step: 934  | total loss: [1m[32m0.11093[0m[0m | time: 24.897s
[2K
| RMSProp | epoch: 022 | loss: 0.11093 - acc: 0.9590 -- iter: 0992/1350
[A[ATraining Step: 935  | total loss: [1m[32m0.10419[0m[0m | time: 25.783s
[2K
| RMSProp | epoch: 022 | loss: 0.10419 - acc: 0.9600 -- iter: 1024/1350
[A[ATraining Step: 936  | total loss: [1m[32m0.15008[0m[0m | time: 26.503s
[2K
| RMSProp | epoch: 022 | loss: 0.15008 - acc: 0.9546 -- iter: 1056/1350
[A[ATraining Step: 937  | total loss: [1m[32m0.14969[0m[0m | time: 27.363s
[2K
| RMSProp | epoch: 022 | loss: 0.14969 - acc: 0.9560 -- iter: 1088/1350
[A[ATraining Step: 938  | total loss: [1m[32m0.14024[0m[0m | time: 28.209s
[2K
| RMSProp | epoch: 022 | loss: 0.14024 - acc: 0.9573 -- iter: 1120/1350
[A[ATraining Step: 939  | total loss: [1m[32m0.12959[0m[0m | time: 29.086s
[2K
| RMSProp | epoch: 022 | loss: 0.12959 - acc: 0.9616 -- iter: 1152/1350
[A[ATraining Step: 940  | total loss: [1m[32m0.11985[0m[0m | time: 29.940s
[2K
| RMSProp | epoch: 022 | loss: 0.11985 - acc: 0.9654 -- iter: 1184/1350
[A[ATraining Step: 941  | total loss: [1m[32m0.10837[0m[0m | time: 30.889s
[2K
| RMSProp | epoch: 022 | loss: 0.10837 - acc: 0.9689 -- iter: 1216/1350
[A[ATraining Step: 942  | total loss: [1m[32m0.09838[0m[0m | time: 31.813s
[2K
| RMSProp | epoch: 022 | loss: 0.09838 - acc: 0.9720 -- iter: 1248/1350
[A[ATraining Step: 943  | total loss: [1m[32m0.08897[0m[0m | time: 32.729s
[2K
| RMSProp | epoch: 022 | loss: 0.08897 - acc: 0.9748 -- iter: 1280/1350
[A[ATraining Step: 944  | total loss: [1m[32m0.08035[0m[0m | time: 33.500s
[2K
| RMSProp | epoch: 022 | loss: 0.08035 - acc: 0.9773 -- iter: 1312/1350
[A[ATraining Step: 945  | total loss: [1m[32m0.08402[0m[0m | time: 34.532s
[2K
| RMSProp | epoch: 022 | loss: 0.08402 - acc: 0.9764 -- iter: 1344/1350
[A[ATraining Step: 946  | total loss: [1m[32m0.07844[0m[0m | time: 37.115s
[2K
| RMSProp | epoch: 022 | loss: 0.07844 - acc: 0.9788 | val_loss: 0.47062 - val_acc: 0.8558 -- iter: 1350/1350
--
Training Step: 947  | total loss: [1m[32m0.07449[0m[0m | time: 0.831s
[2K
| RMSProp | epoch: 023 | loss: 0.07449 - acc: 0.9778 -- iter: 0032/1350
[A[ATraining Step: 948  | total loss: [1m[32m0.06769[0m[0m | time: 1.763s
[2K
| RMSProp | epoch: 023 | loss: 0.06769 - acc: 0.9800 -- iter: 0064/1350
[A[ATraining Step: 949  | total loss: [1m[32m0.06485[0m[0m | time: 2.654s
[2K
| RMSProp | epoch: 023 | loss: 0.06485 - acc: 0.9789 -- iter: 0096/1350
[A[ATraining Step: 950  | total loss: [1m[32m0.06014[0m[0m | time: 3.461s
[2K
| RMSProp | epoch: 023 | loss: 0.06014 - acc: 0.9810 -- iter: 0128/1350
[A[ATraining Step: 951  | total loss: [1m[32m0.07488[0m[0m | time: 4.260s
[2K
| RMSProp | epoch: 023 | loss: 0.07488 - acc: 0.9767 -- iter: 0160/1350
[A[ATraining Step: 952  | total loss: [1m[32m0.11749[0m[0m | time: 5.255s
[2K
| RMSProp | epoch: 023 | loss: 0.11749 - acc: 0.9602 -- iter: 0192/1350
[A[ATraining Step: 953  | total loss: [1m[32m0.13737[0m[0m | time: 6.195s
[2K
| RMSProp | epoch: 023 | loss: 0.13737 - acc: 0.9486 -- iter: 0224/1350
[A[ATraining Step: 954  | total loss: [1m[32m0.13988[0m[0m | time: 6.992s
[2K
| RMSProp | epoch: 023 | loss: 0.13988 - acc: 0.9475 -- iter: 0256/1350
[A[ATraining Step: 955  | total loss: [1m[32m0.15203[0m[0m | time: 7.789s
[2K
| RMSProp | epoch: 023 | loss: 0.15203 - acc: 0.9434 -- iter: 0288/1350
[A[ATraining Step: 956  | total loss: [1m[32m0.14177[0m[0m | time: 8.585s
[2K
| RMSProp | epoch: 023 | loss: 0.14177 - acc: 0.9459 -- iter: 0320/1350
[A[ATraining Step: 957  | total loss: [1m[32m0.12864[0m[0m | time: 9.416s
[2K
| RMSProp | epoch: 023 | loss: 0.12864 - acc: 0.9513 -- iter: 0352/1350
[A[ATraining Step: 958  | total loss: [1m[32m0.11710[0m[0m | time: 10.246s
[2K
| RMSProp | epoch: 023 | loss: 0.11710 - acc: 0.9562 -- iter: 0384/1350
[A[ATraining Step: 959  | total loss: [1m[32m0.11028[0m[0m | time: 11.067s
[2K
| RMSProp | epoch: 023 | loss: 0.11028 - acc: 0.9574 -- iter: 0416/1350
[A[ATraining Step: 960  | total loss: [1m[32m0.09988[0m[0m | time: 11.996s
[2K
| RMSProp | epoch: 023 | loss: 0.09988 - acc: 0.9617 -- iter: 0448/1350
[A[ATraining Step: 961  | total loss: [1m[32m0.09950[0m[0m | time: 12.908s
[2K
| RMSProp | epoch: 023 | loss: 0.09950 - acc: 0.9624 -- iter: 0480/1350
[A[ATraining Step: 962  | total loss: [1m[32m0.13423[0m[0m | time: 13.819s
[2K
| RMSProp | epoch: 023 | loss: 0.13423 - acc: 0.9537 -- iter: 0512/1350
[A[ATraining Step: 963  | total loss: [1m[32m0.14300[0m[0m | time: 14.606s
[2K
| RMSProp | epoch: 023 | loss: 0.14300 - acc: 0.9520 -- iter: 0544/1350
[A[ATraining Step: 964  | total loss: [1m[32m0.13091[0m[0m | time: 15.651s
[2K
| RMSProp | epoch: 023 | loss: 0.13091 - acc: 0.9568 -- iter: 0576/1350
[A[ATraining Step: 965  | total loss: [1m[32m0.11840[0m[0m | time: 16.610s
[2K
| RMSProp | epoch: 023 | loss: 0.11840 - acc: 0.9612 -- iter: 0608/1350
[A[ATraining Step: 966  | total loss: [1m[32m0.10697[0m[0m | time: 17.386s
[2K
| RMSProp | epoch: 023 | loss: 0.10697 - acc: 0.9650 -- iter: 0640/1350
[A[ATraining Step: 967  | total loss: [1m[32m0.09675[0m[0m | time: 17.587s
[2K
| RMSProp | epoch: 023 | loss: 0.09675 - acc: 0.9685 -- iter: 0672/1350
[A[ATraining Step: 968  | total loss: [1m[32m0.08750[0m[0m | time: 17.769s
[2K
| RMSProp | epoch: 023 | loss: 0.08750 - acc: 0.9717 -- iter: 0704/1350
[A[ATraining Step: 969  | total loss: [1m[32m0.07890[0m[0m | time: 18.620s
[2K
| RMSProp | epoch: 023 | loss: 0.07890 - acc: 0.9745 -- iter: 0736/1350
[A[ATraining Step: 970  | total loss: [1m[32m0.07280[0m[0m | time: 19.480s
[2K
| RMSProp | epoch: 023 | loss: 0.07280 - acc: 0.9771 -- iter: 0768/1350
[A[ATraining Step: 971  | total loss: [1m[32m0.06628[0m[0m | time: 20.325s
[2K
| RMSProp | epoch: 023 | loss: 0.06628 - acc: 0.9794 -- iter: 0800/1350
[A[ATraining Step: 972  | total loss: [1m[32m0.06145[0m[0m | time: 21.203s
[2K
| RMSProp | epoch: 023 | loss: 0.06145 - acc: 0.9814 -- iter: 0832/1350
[A[ATraining Step: 973  | total loss: [1m[32m0.05552[0m[0m | time: 22.101s
[2K
| RMSProp | epoch: 023 | loss: 0.05552 - acc: 0.9833 -- iter: 0864/1350
[A[ATraining Step: 974  | total loss: [1m[32m0.05113[0m[0m | time: 23.014s
[2K
| RMSProp | epoch: 023 | loss: 0.05113 - acc: 0.9849 -- iter: 0896/1350
[A[ATraining Step: 975  | total loss: [1m[32m0.04664[0m[0m | time: 23.884s
[2K
| RMSProp | epoch: 023 | loss: 0.04664 - acc: 0.9865 -- iter: 0928/1350
[A[ATraining Step: 976  | total loss: [1m[32m0.04794[0m[0m | time: 24.631s
[2K
| RMSProp | epoch: 023 | loss: 0.04794 - acc: 0.9847 -- iter: 0960/1350
[A[ATraining Step: 977  | total loss: [1m[32m0.07174[0m[0m | time: 25.582s
[2K
| RMSProp | epoch: 023 | loss: 0.07174 - acc: 0.9737 -- iter: 0992/1350
[A[ATraining Step: 978  | total loss: [1m[32m0.08841[0m[0m | time: 26.536s
[2K
| RMSProp | epoch: 023 | loss: 0.08841 - acc: 0.9638 -- iter: 1024/1350
[A[ATraining Step: 979  | total loss: [1m[32m0.08976[0m[0m | time: 27.415s
[2K
| RMSProp | epoch: 023 | loss: 0.08976 - acc: 0.9643 -- iter: 1056/1350
[A[ATraining Step: 980  | total loss: [1m[32m0.09254[0m[0m | time: 28.123s
[2K
| RMSProp | epoch: 023 | loss: 0.09254 - acc: 0.9648 -- iter: 1088/1350
[A[ATraining Step: 981  | total loss: [1m[32m0.08369[0m[0m | time: 28.937s
[2K
| RMSProp | epoch: 023 | loss: 0.08369 - acc: 0.9683 -- iter: 1120/1350
[A[ATraining Step: 982  | total loss: [1m[32m0.07787[0m[0m | time: 29.770s
[2K
| RMSProp | epoch: 023 | loss: 0.07787 - acc: 0.9715 -- iter: 1152/1350
[A[ATraining Step: 983  | total loss: [1m[32m0.07097[0m[0m | time: 30.594s
[2K
| RMSProp | epoch: 023 | loss: 0.07097 - acc: 0.9743 -- iter: 1184/1350
[A[ATraining Step: 984  | total loss: [1m[32m0.06520[0m[0m | time: 31.450s
[2K
| RMSProp | epoch: 023 | loss: 0.06520 - acc: 0.9769 -- iter: 1216/1350
[A[ATraining Step: 985  | total loss: [1m[32m0.05894[0m[0m | time: 32.328s
[2K
| RMSProp | epoch: 023 | loss: 0.05894 - acc: 0.9792 -- iter: 1248/1350
[A[ATraining Step: 986  | total loss: [1m[32m0.05321[0m[0m | time: 33.250s
[2K
| RMSProp | epoch: 023 | loss: 0.05321 - acc: 0.9813 -- iter: 1280/1350
[A[ATraining Step: 987  | total loss: [1m[32m0.04805[0m[0m | time: 34.082s
[2K
| RMSProp | epoch: 023 | loss: 0.04805 - acc: 0.9832 -- iter: 1312/1350
[A[ATraining Step: 988  | total loss: [1m[32m0.04343[0m[0m | time: 34.908s
[2K
| RMSProp | epoch: 023 | loss: 0.04343 - acc: 0.9848 -- iter: 1344/1350
[A[ATraining Step: 989  | total loss: [1m[32m0.03928[0m[0m | time: 37.849s
[2K
| RMSProp | epoch: 023 | loss: 0.03928 - acc: 0.9864 | val_loss: 0.39336 - val_acc: 0.9078 -- iter: 1350/1350
--
Training Step: 990  | total loss: [1m[32m0.03545[0m[0m | time: 0.887s
[2K
| RMSProp | epoch: 024 | loss: 0.03545 - acc: 0.9877 -- iter: 0032/1350
[A[ATraining Step: 991  | total loss: [1m[32m0.03219[0m[0m | time: 1.825s
[2K
| RMSProp | epoch: 024 | loss: 0.03219 - acc: 0.9889 -- iter: 0064/1350
[A[ATraining Step: 992  | total loss: [1m[32m0.02911[0m[0m | time: 2.701s
[2K
| RMSProp | epoch: 024 | loss: 0.02911 - acc: 0.9901 -- iter: 0096/1350
[A[ATraining Step: 993  | total loss: [1m[32m0.02750[0m[0m | time: 3.645s
[2K
| RMSProp | epoch: 024 | loss: 0.02750 - acc: 0.9910 -- iter: 0128/1350
[A[ATraining Step: 994  | total loss: [1m[32m0.02790[0m[0m | time: 4.660s
[2K
| RMSProp | epoch: 024 | loss: 0.02790 - acc: 0.9919 -- iter: 0160/1350
[A[ATraining Step: 995  | total loss: [1m[32m0.04171[0m[0m | time: 5.548s
[2K
| RMSProp | epoch: 024 | loss: 0.04171 - acc: 0.9865 -- iter: 0192/1350
[A[ATraining Step: 996  | total loss: [1m[32m0.04689[0m[0m | time: 6.259s
[2K
| RMSProp | epoch: 024 | loss: 0.04689 - acc: 0.9847 -- iter: 0224/1350
[A[ATraining Step: 997  | total loss: [1m[32m0.06067[0m[0m | time: 7.099s
[2K
| RMSProp | epoch: 024 | loss: 0.06067 - acc: 0.9800 -- iter: 0256/1350
[A[ATraining Step: 998  | total loss: [1m[32m0.06708[0m[0m | time: 8.007s
[2K
| RMSProp | epoch: 024 | loss: 0.06708 - acc: 0.9758 -- iter: 0288/1350
[A[ATraining Step: 999  | total loss: [1m[32m0.08514[0m[0m | time: 8.843s
[2K
| RMSProp | epoch: 024 | loss: 0.08514 - acc: 0.9688 -- iter: 0320/1350
[A[ATraining Step: 1000  | total loss: [1m[32m0.07746[0m[0m | time: 11.501s
[2K
| RMSProp | epoch: 024 | loss: 0.07746 - acc: 0.9719 | val_loss: 0.43363 - val_acc: 0.8818 -- iter: 0352/1350
--
Training Step: 1001  | total loss: [1m[32m0.07042[0m[0m | time: 12.364s
[2K
| RMSProp | epoch: 024 | loss: 0.07042 - acc: 0.9747 -- iter: 0384/1350
[A[ATraining Step: 1002  | total loss: [1m[32m0.06561[0m[0m | time: 13.253s
[2K
| RMSProp | epoch: 024 | loss: 0.06561 - acc: 0.9773 -- iter: 0416/1350
[A[ATraining Step: 1003  | total loss: [1m[32m0.06871[0m[0m | time: 14.225s
[2K
| RMSProp | epoch: 024 | loss: 0.06871 - acc: 0.9764 -- iter: 0448/1350
[A[ATraining Step: 1004  | total loss: [1m[32m0.08266[0m[0m | time: 15.193s
[2K
| RMSProp | epoch: 024 | loss: 0.08266 - acc: 0.9756 -- iter: 0480/1350
[A[ATraining Step: 1005  | total loss: [1m[32m0.07553[0m[0m | time: 15.876s
[2K
| RMSProp | epoch: 024 | loss: 0.07553 - acc: 0.9781 -- iter: 0512/1350
[A[ATraining Step: 1006  | total loss: [1m[32m0.06831[0m[0m | time: 16.672s
[2K
| RMSProp | epoch: 024 | loss: 0.06831 - acc: 0.9803 -- iter: 0544/1350
[A[ATraining Step: 1007  | total loss: [1m[32m0.06241[0m[0m | time: 17.495s
[2K
| RMSProp | epoch: 024 | loss: 0.06241 - acc: 0.9822 -- iter: 0576/1350
[A[ATraining Step: 1008  | total loss: [1m[32m0.06733[0m[0m | time: 18.345s
[2K
| RMSProp | epoch: 024 | loss: 0.06733 - acc: 0.9809 -- iter: 0608/1350
[A[ATraining Step: 1009  | total loss: [1m[32m0.06278[0m[0m | time: 19.152s
[2K
| RMSProp | epoch: 024 | loss: 0.06278 - acc: 0.9828 -- iter: 0640/1350
[A[ATraining Step: 1010  | total loss: [1m[32m0.06804[0m[0m | time: 20.028s
[2K
| RMSProp | epoch: 024 | loss: 0.06804 - acc: 0.9814 -- iter: 0672/1350
[A[ATraining Step: 1011  | total loss: [1m[32m0.06961[0m[0m | time: 20.242s
[2K
| RMSProp | epoch: 024 | loss: 0.06961 - acc: 0.9770 -- iter: 0704/1350
[A[ATraining Step: 1012  | total loss: [1m[32m0.06501[0m[0m | time: 20.442s
[2K
| RMSProp | epoch: 024 | loss: 0.06501 - acc: 0.9793 -- iter: 0736/1350
[A[ATraining Step: 1013  | total loss: [1m[32m0.05854[0m[0m | time: 21.317s
[2K
| RMSProp | epoch: 024 | loss: 0.05854 - acc: 0.9814 -- iter: 0768/1350
[A[ATraining Step: 1014  | total loss: [1m[32m0.05620[0m[0m | time: 22.200s
[2K
| RMSProp | epoch: 024 | loss: 0.05620 - acc: 0.9801 -- iter: 0800/1350
[A[ATraining Step: 1015  | total loss: [1m[32m0.11980[0m[0m | time: 23.029s
[2K
| RMSProp | epoch: 024 | loss: 0.11980 - acc: 0.9696 -- iter: 0832/1350
[A[ATraining Step: 1016  | total loss: [1m[32m0.11247[0m[0m | time: 23.918s
[2K
| RMSProp | epoch: 024 | loss: 0.11247 - acc: 0.9695 -- iter: 0864/1350
[A[ATraining Step: 1017  | total loss: [1m[32m0.10309[0m[0m | time: 24.922s
[2K
| RMSProp | epoch: 024 | loss: 0.10309 - acc: 0.9726 -- iter: 0896/1350
[A[ATraining Step: 1018  | total loss: [1m[32m0.09517[0m[0m | time: 25.806s
[2K
| RMSProp | epoch: 024 | loss: 0.09517 - acc: 0.9753 -- iter: 0928/1350
[A[ATraining Step: 1019  | total loss: [1m[32m0.08776[0m[0m | time: 26.529s
[2K
| RMSProp | epoch: 024 | loss: 0.08776 - acc: 0.9778 -- iter: 0960/1350
[A[ATraining Step: 1020  | total loss: [1m[32m0.08231[0m[0m | time: 27.351s
[2K
| RMSProp | epoch: 024 | loss: 0.08231 - acc: 0.9769 -- iter: 0992/1350
[A[ATraining Step: 1021  | total loss: [1m[32m0.08304[0m[0m | time: 28.178s
[2K
| RMSProp | epoch: 024 | loss: 0.08304 - acc: 0.9761 -- iter: 1024/1350
[A[ATraining Step: 1022  | total loss: [1m[32m0.07513[0m[0m | time: 28.998s
[2K
| RMSProp | epoch: 024 | loss: 0.07513 - acc: 0.9785 -- iter: 1056/1350
[A[ATraining Step: 1023  | total loss: [1m[32m0.06973[0m[0m | time: 29.808s
[2K
| RMSProp | epoch: 024 | loss: 0.06973 - acc: 0.9806 -- iter: 1088/1350
[A[ATraining Step: 1024  | total loss: [1m[32m0.09225[0m[0m | time: 30.731s
[2K
| RMSProp | epoch: 024 | loss: 0.09225 - acc: 0.9794 -- iter: 1120/1350
[A[ATraining Step: 1025  | total loss: [1m[32m0.11691[0m[0m | time: 31.627s
[2K
| RMSProp | epoch: 024 | loss: 0.11691 - acc: 0.9659 -- iter: 1152/1350
[A[ATraining Step: 1026  | total loss: [1m[32m0.11208[0m[0m | time: 32.511s
[2K
| RMSProp | epoch: 024 | loss: 0.11208 - acc: 0.9661 -- iter: 1184/1350
[A[ATraining Step: 1027  | total loss: [1m[32m0.10165[0m[0m | time: 33.332s
[2K
| RMSProp | epoch: 024 | loss: 0.10165 - acc: 0.9695 -- iter: 1216/1350
[A[ATraining Step: 1028  | total loss: [1m[32m0.09313[0m[0m | time: 34.091s
[2K
| RMSProp | epoch: 024 | loss: 0.09313 - acc: 0.9726 -- iter: 1248/1350
[A[ATraining Step: 1029  | total loss: [1m[32m0.08437[0m[0m | time: 34.808s
[2K
| RMSProp | epoch: 024 | loss: 0.08437 - acc: 0.9753 -- iter: 1280/1350
[A[ATraining Step: 1030  | total loss: [1m[32m0.07655[0m[0m | time: 35.577s
[2K
| RMSProp | epoch: 024 | loss: 0.07655 - acc: 0.9778 -- iter: 1312/1350
[A[ATraining Step: 1031  | total loss: [1m[32m0.06928[0m[0m | time: 36.308s
[2K
| RMSProp | epoch: 024 | loss: 0.06928 - acc: 0.9800 -- iter: 1344/1350
[A[ATraining Step: 1032  | total loss: [1m[32m0.06274[0m[0m | time: 38.916s
[2K
| RMSProp | epoch: 024 | loss: 0.06274 - acc: 0.9820 | val_loss: 0.34796 - val_acc: 0.9007 -- iter: 1350/1350
--
Training Step: 1033  | total loss: [1m[32m0.05669[0m[0m | time: 0.834s
[2K
| RMSProp | epoch: 025 | loss: 0.05669 - acc: 0.9838 -- iter: 0032/1350
[A[ATraining Step: 1034  | total loss: [1m[32m0.05136[0m[0m | time: 1.662s
[2K
| RMSProp | epoch: 025 | loss: 0.05136 - acc: 0.9854 -- iter: 0064/1350
[A[ATraining Step: 1035  | total loss: [1m[32m0.04630[0m[0m | time: 2.529s
[2K
| RMSProp | epoch: 025 | loss: 0.04630 - acc: 0.9869 -- iter: 0096/1350
[A[ATraining Step: 1036  | total loss: [1m[32m0.04185[0m[0m | time: 3.406s
[2K
| RMSProp | epoch: 025 | loss: 0.04185 - acc: 0.9882 -- iter: 0128/1350
[A[ATraining Step: 1037  | total loss: [1m[32m0.03853[0m[0m | time: 4.256s
[2K
| RMSProp | epoch: 025 | loss: 0.03853 - acc: 0.9894 -- iter: 0160/1350
[A[ATraining Step: 1038  | total loss: [1m[32m0.03893[0m[0m | time: 5.107s
[2K
| RMSProp | epoch: 025 | loss: 0.03893 - acc: 0.9873 -- iter: 0192/1350
[A[ATraining Step: 1039  | total loss: [1m[32m0.13864[0m[0m | time: 5.933s
[2K
| RMSProp | epoch: 025 | loss: 0.13864 - acc: 0.9636 -- iter: 0224/1350
[A[ATraining Step: 1040  | total loss: [1m[32m0.13867[0m[0m | time: 6.913s
[2K
| RMSProp | epoch: 025 | loss: 0.13867 - acc: 0.9610 -- iter: 0256/1350
[A[ATraining Step: 1041  | total loss: [1m[32m0.13226[0m[0m | time: 7.896s
[2K
| RMSProp | epoch: 025 | loss: 0.13226 - acc: 0.9618 -- iter: 0288/1350
[A[ATraining Step: 1042  | total loss: [1m[32m0.13022[0m[0m | time: 8.665s
[2K
| RMSProp | epoch: 025 | loss: 0.13022 - acc: 0.9625 -- iter: 0320/1350
[A[ATraining Step: 1043  | total loss: [1m[32m0.11860[0m[0m | time: 9.418s
[2K
| RMSProp | epoch: 025 | loss: 0.11860 - acc: 0.9662 -- iter: 0352/1350
[A[ATraining Step: 1044  | total loss: [1m[32m0.10859[0m[0m | time: 10.266s
[2K
| RMSProp | epoch: 025 | loss: 0.10859 - acc: 0.9696 -- iter: 0384/1350
[A[ATraining Step: 1045  | total loss: [1m[32m0.10103[0m[0m | time: 11.114s
[2K
| RMSProp | epoch: 025 | loss: 0.10103 - acc: 0.9695 -- iter: 0416/1350
[A[ATraining Step: 1046  | total loss: [1m[32m0.09791[0m[0m | time: 11.993s
[2K
| RMSProp | epoch: 025 | loss: 0.09791 - acc: 0.9694 -- iter: 0448/1350
[A[ATraining Step: 1047  | total loss: [1m[32m0.08907[0m[0m | time: 12.836s
[2K
| RMSProp | epoch: 025 | loss: 0.08907 - acc: 0.9725 -- iter: 0480/1350
[A[ATraining Step: 1048  | total loss: [1m[32m0.08161[0m[0m | time: 13.696s
[2K
| RMSProp | epoch: 025 | loss: 0.08161 - acc: 0.9752 -- iter: 0512/1350
[A[ATraining Step: 1049  | total loss: [1m[32m0.07388[0m[0m | time: 14.606s
[2K
| RMSProp | epoch: 025 | loss: 0.07388 - acc: 0.9777 -- iter: 0544/1350
[A[ATraining Step: 1050  | total loss: [1m[32m0.06675[0m[0m | time: 15.475s
[2K
| RMSProp | epoch: 025 | loss: 0.06675 - acc: 0.9799 -- iter: 0576/1350
[A[ATraining Step: 1051  | total loss: [1m[32m0.06020[0m[0m | time: 16.253s
[2K
| RMSProp | epoch: 025 | loss: 0.06020 - acc: 0.9819 -- iter: 0608/1350
[A[ATraining Step: 1052  | total loss: [1m[32m0.05433[0m[0m | time: 17.256s
[2K
| RMSProp | epoch: 025 | loss: 0.05433 - acc: 0.9838 -- iter: 0640/1350
[A[ATraining Step: 1053  | total loss: [1m[32m0.06545[0m[0m | time: 18.257s
[2K
| RMSProp | epoch: 025 | loss: 0.06545 - acc: 0.9823 -- iter: 0672/1350
[A[ATraining Step: 1054  | total loss: [1m[32m0.10066[0m[0m | time: 19.086s
[2K
| RMSProp | epoch: 025 | loss: 0.10066 - acc: 0.9747 -- iter: 0704/1350
[A[ATraining Step: 1055  | total loss: [1m[32m0.09162[0m[0m | time: 19.273s
[2K
| RMSProp | epoch: 025 | loss: 0.09162 - acc: 0.9772 -- iter: 0736/1350
[A[ATraining Step: 1056  | total loss: [1m[32m0.08424[0m[0m | time: 19.451s
[2K
| RMSProp | epoch: 025 | loss: 0.08424 - acc: 0.9795 -- iter: 0768/1350
[A[ATraining Step: 1057  | total loss: [1m[32m0.07588[0m[0m | time: 20.269s
[2K
| RMSProp | epoch: 025 | loss: 0.07588 - acc: 0.9815 -- iter: 0800/1350
[A[ATraining Step: 1058  | total loss: [1m[32m0.06853[0m[0m | time: 21.186s
[2K
| RMSProp | epoch: 025 | loss: 0.06853 - acc: 0.9834 -- iter: 0832/1350
[A[ATraining Step: 1059  | total loss: [1m[32m0.06217[0m[0m | time: 22.004s
[2K
| RMSProp | epoch: 025 | loss: 0.06217 - acc: 0.9850 -- iter: 0864/1350
[A[ATraining Step: 1060  | total loss: [1m[32m0.05658[0m[0m | time: 22.862s
[2K
| RMSProp | epoch: 025 | loss: 0.05658 - acc: 0.9865 -- iter: 0896/1350
[A[ATraining Step: 1061  | total loss: [1m[32m0.05156[0m[0m | time: 23.752s
[2K
| RMSProp | epoch: 025 | loss: 0.05156 - acc: 0.9879 -- iter: 0928/1350
[A[ATraining Step: 1062  | total loss: [1m[32m0.04660[0m[0m | time: 24.645s
[2K
| RMSProp | epoch: 025 | loss: 0.04660 - acc: 0.9891 -- iter: 0960/1350
[A[ATraining Step: 1063  | total loss: [1m[32m0.04204[0m[0m | time: 25.515s
[2K
| RMSProp | epoch: 025 | loss: 0.04204 - acc: 0.9902 -- iter: 0992/1350
[A[ATraining Step: 1064  | total loss: [1m[32m0.03790[0m[0m | time: 26.319s
[2K
| RMSProp | epoch: 025 | loss: 0.03790 - acc: 0.9912 -- iter: 1024/1350
[A[ATraining Step: 1065  | total loss: [1m[32m0.03415[0m[0m | time: 27.229s
[2K
| RMSProp | epoch: 025 | loss: 0.03415 - acc: 0.9920 -- iter: 1056/1350
[A[ATraining Step: 1066  | total loss: [1m[32m0.03080[0m[0m | time: 28.172s
[2K
| RMSProp | epoch: 025 | loss: 0.03080 - acc: 0.9928 -- iter: 1088/1350
[A[ATraining Step: 1067  | total loss: [1m[32m0.02785[0m[0m | time: 29.111s
[2K
| RMSProp | epoch: 025 | loss: 0.02785 - acc: 0.9936 -- iter: 1120/1350
[A[ATraining Step: 1068  | total loss: [1m[32m0.05357[0m[0m | time: 29.789s
[2K
| RMSProp | epoch: 025 | loss: 0.05357 - acc: 0.9911 -- iter: 1152/1350
[A[ATraining Step: 1069  | total loss: [1m[32m0.05669[0m[0m | time: 30.587s
[2K
| RMSProp | epoch: 025 | loss: 0.05669 - acc: 0.9888 -- iter: 1184/1350
[A[ATraining Step: 1070  | total loss: [1m[32m0.05965[0m[0m | time: 31.428s
[2K
| RMSProp | epoch: 025 | loss: 0.05965 - acc: 0.9806 -- iter: 1216/1350
[A[ATraining Step: 1071  | total loss: [1m[32m0.06165[0m[0m | time: 32.245s
[2K
| RMSProp | epoch: 025 | loss: 0.06165 - acc: 0.9794 -- iter: 1248/1350
[A[ATraining Step: 1072  | total loss: [1m[32m0.06113[0m[0m | time: 33.091s
[2K
| RMSProp | epoch: 025 | loss: 0.06113 - acc: 0.9783 -- iter: 1280/1350
[A[ATraining Step: 1073  | total loss: [1m[32m0.06682[0m[0m | time: 33.943s
[2K
| RMSProp | epoch: 025 | loss: 0.06682 - acc: 0.9743 -- iter: 1312/1350
[A[ATraining Step: 1074  | total loss: [1m[32m0.06333[0m[0m | time: 34.884s
[2K
| RMSProp | epoch: 025 | loss: 0.06333 - acc: 0.9768 -- iter: 1344/1350
[A[ATraining Step: 1075  | total loss: [1m[32m0.05824[0m[0m | time: 37.506s
[2K
| RMSProp | epoch: 025 | loss: 0.05824 - acc: 0.9791 | val_loss: 0.35920 - val_acc: 0.8983 -- iter: 1350/1350
--
Training Step: 1076  | total loss: [1m[32m0.05311[0m[0m | time: 0.942s
[2K
| RMSProp | epoch: 026 | loss: 0.05311 - acc: 0.9812 -- iter: 0032/1350
[A[ATraining Step: 1077  | total loss: [1m[32m0.04811[0m[0m | time: 1.795s
[2K
| RMSProp | epoch: 026 | loss: 0.04811 - acc: 0.9831 -- iter: 0064/1350
[A[ATraining Step: 1078  | total loss: [1m[32m0.04366[0m[0m | time: 2.654s
[2K
| RMSProp | epoch: 026 | loss: 0.04366 - acc: 0.9848 -- iter: 0096/1350
[A[ATraining Step: 1079  | total loss: [1m[32m0.04005[0m[0m | time: 3.526s
[2K
| RMSProp | epoch: 026 | loss: 0.04005 - acc: 0.9863 -- iter: 0128/1350
[A[ATraining Step: 1080  | total loss: [1m[32m0.03616[0m[0m | time: 4.482s
[2K
| RMSProp | epoch: 026 | loss: 0.03616 - acc: 0.9877 -- iter: 0160/1350
[A[ATraining Step: 1081  | total loss: [1m[32m0.03303[0m[0m | time: 5.361s
[2K
| RMSProp | epoch: 026 | loss: 0.03303 - acc: 0.9889 -- iter: 0192/1350
[A[ATraining Step: 1082  | total loss: [1m[32m0.03054[0m[0m | time: 6.138s
[2K
| RMSProp | epoch: 026 | loss: 0.03054 - acc: 0.9900 -- iter: 0224/1350
[A[ATraining Step: 1083  | total loss: [1m[32m0.02944[0m[0m | time: 7.138s
[2K
| RMSProp | epoch: 026 | loss: 0.02944 - acc: 0.9910 -- iter: 0256/1350
[A[ATraining Step: 1084  | total loss: [1m[32m0.06185[0m[0m | time: 8.132s
[2K
| RMSProp | epoch: 026 | loss: 0.06185 - acc: 0.9825 -- iter: 0288/1350
[A[ATraining Step: 1085  | total loss: [1m[32m0.12664[0m[0m | time: 8.945s
[2K
| RMSProp | epoch: 026 | loss: 0.12664 - acc: 0.9687 -- iter: 0320/1350
[A[ATraining Step: 1086  | total loss: [1m[32m0.12046[0m[0m | time: 9.716s
[2K
| RMSProp | epoch: 026 | loss: 0.12046 - acc: 0.9687 -- iter: 0352/1350
[A[ATraining Step: 1087  | total loss: [1m[32m0.10940[0m[0m | time: 10.559s
[2K
| RMSProp | epoch: 026 | loss: 0.10940 - acc: 0.9718 -- iter: 0384/1350
[A[ATraining Step: 1088  | total loss: [1m[32m0.10221[0m[0m | time: 11.393s
[2K
| RMSProp | epoch: 026 | loss: 0.10221 - acc: 0.9715 -- iter: 0416/1350
[A[ATraining Step: 1089  | total loss: [1m[32m0.09293[0m[0m | time: 12.219s
[2K
| RMSProp | epoch: 026 | loss: 0.09293 - acc: 0.9744 -- iter: 0448/1350
[A[ATraining Step: 1090  | total loss: [1m[32m0.09187[0m[0m | time: 13.082s
[2K
| RMSProp | epoch: 026 | loss: 0.09187 - acc: 0.9738 -- iter: 0480/1350
[A[ATraining Step: 1091  | total loss: [1m[32m0.08402[0m[0m | time: 14.028s
[2K
| RMSProp | epoch: 026 | loss: 0.08402 - acc: 0.9764 -- iter: 0512/1350
[A[ATraining Step: 1092  | total loss: [1m[32m0.07814[0m[0m | time: 14.873s
[2K
| RMSProp | epoch: 026 | loss: 0.07814 - acc: 0.9788 -- iter: 0544/1350
[A[ATraining Step: 1093  | total loss: [1m[32m0.07799[0m[0m | time: 15.760s
[2K
| RMSProp | epoch: 026 | loss: 0.07799 - acc: 0.9778 -- iter: 0576/1350
[A[ATraining Step: 1094  | total loss: [1m[32m0.07193[0m[0m | time: 16.564s
[2K
| RMSProp | epoch: 026 | loss: 0.07193 - acc: 0.9800 -- iter: 0608/1350
[A[ATraining Step: 1095  | total loss: [1m[32m0.06538[0m[0m | time: 17.555s
[2K
| RMSProp | epoch: 026 | loss: 0.06538 - acc: 0.9820 -- iter: 0640/1350
[A[ATraining Step: 1096  | total loss: [1m[32m0.05897[0m[0m | time: 18.556s
[2K
| RMSProp | epoch: 026 | loss: 0.05897 - acc: 0.9838 -- iter: 0672/1350
[A[ATraining Step: 1097  | total loss: [1m[32m0.05338[0m[0m | time: 19.452s
[2K
| RMSProp | epoch: 026 | loss: 0.05338 - acc: 0.9854 -- iter: 0704/1350
[A[ATraining Step: 1098  | total loss: [1m[32m0.04816[0m[0m | time: 20.194s
[2K
| RMSProp | epoch: 026 | loss: 0.04816 - acc: 0.9869 -- iter: 0736/1350
[A[ATraining Step: 1099  | total loss: [1m[32m0.04352[0m[0m | time: 20.389s
[2K
| RMSProp | epoch: 026 | loss: 0.04352 - acc: 0.9882 -- iter: 0768/1350
[A[ATraining Step: 1100  | total loss: [1m[32m0.03932[0m[0m | time: 20.584s
[2K
| RMSProp | epoch: 026 | loss: 0.03932 - acc: 0.9894 -- iter: 0800/1350
[A[ATraining Step: 1101  | total loss: [1m[32m0.03542[0m[0m | time: 21.383s
[2K
| RMSProp | epoch: 026 | loss: 0.03542 - acc: 0.9904 -- iter: 0832/1350
[A[ATraining Step: 1102  | total loss: [1m[32m0.03196[0m[0m | time: 22.327s
[2K
| RMSProp | epoch: 026 | loss: 0.03196 - acc: 0.9914 -- iter: 0864/1350
[A[ATraining Step: 1103  | total loss: [1m[32m0.02884[0m[0m | time: 23.133s
[2K
| RMSProp | epoch: 026 | loss: 0.02884 - acc: 0.9922 -- iter: 0896/1350
[A[ATraining Step: 1104  | total loss: [1m[32m0.02614[0m[0m | time: 23.994s
[2K
| RMSProp | epoch: 026 | loss: 0.02614 - acc: 0.9930 -- iter: 0928/1350
[A[ATraining Step: 1105  | total loss: [1m[32m0.02358[0m[0m | time: 24.939s
[2K
| RMSProp | epoch: 026 | loss: 0.02358 - acc: 0.9937 -- iter: 0960/1350
[A[ATraining Step: 1106  | total loss: [1m[32m0.02128[0m[0m | time: 25.877s
[2K
| RMSProp | epoch: 026 | loss: 0.02128 - acc: 0.9943 -- iter: 0992/1350
[A[ATraining Step: 1107  | total loss: [1m[32m0.01937[0m[0m | time: 26.717s
[2K
| RMSProp | epoch: 026 | loss: 0.01937 - acc: 0.9949 -- iter: 1024/1350
[A[ATraining Step: 1108  | total loss: [1m[32m0.01745[0m[0m | time: 27.552s
[2K
| RMSProp | epoch: 026 | loss: 0.01745 - acc: 0.9954 -- iter: 1056/1350
[A[ATraining Step: 1109  | total loss: [1m[32m0.01845[0m[0m | time: 28.553s
[2K
| RMSProp | epoch: 026 | loss: 0.01845 - acc: 0.9928 -- iter: 1088/1350
[A[ATraining Step: 1110  | total loss: [1m[32m0.04519[0m[0m | time: 29.527s
[2K
| RMSProp | epoch: 026 | loss: 0.04519 - acc: 0.9872 -- iter: 1120/1350
[A[ATraining Step: 1111  | total loss: [1m[32m0.14445[0m[0m | time: 30.274s
[2K
| RMSProp | epoch: 026 | loss: 0.14445 - acc: 0.9698 -- iter: 1152/1350
[A[ATraining Step: 1112  | total loss: [1m[32m0.14969[0m[0m | time: 31.095s
[2K
| RMSProp | epoch: 026 | loss: 0.14969 - acc: 0.9697 -- iter: 1184/1350
[A[ATraining Step: 1113  | total loss: [1m[32m0.13845[0m[0m | time: 31.964s
[2K
| RMSProp | epoch: 026 | loss: 0.13845 - acc: 0.9727 -- iter: 1216/1350
[A[ATraining Step: 1114  | total loss: [1m[32m0.12533[0m[0m | time: 32.796s
[2K
| RMSProp | epoch: 026 | loss: 0.12533 - acc: 0.9754 -- iter: 1248/1350
[A[ATraining Step: 1115  | total loss: [1m[32m0.11369[0m[0m | time: 33.672s
[2K
| RMSProp | epoch: 026 | loss: 0.11369 - acc: 0.9779 -- iter: 1280/1350
[A[ATraining Step: 1116  | total loss: [1m[32m0.10345[0m[0m | time: 34.545s
[2K
| RMSProp | epoch: 026 | loss: 0.10345 - acc: 0.9801 -- iter: 1312/1350
[A[ATraining Step: 1117  | total loss: [1m[32m0.09326[0m[0m | time: 35.369s
[2K
| RMSProp | epoch: 026 | loss: 0.09326 - acc: 0.9821 -- iter: 1344/1350
[A[ATraining Step: 1118  | total loss: [1m[32m0.08413[0m[0m | time: 38.013s
[2K
| RMSProp | epoch: 026 | loss: 0.08413 - acc: 0.9839 | val_loss: 0.42539 - val_acc: 0.9102 -- iter: 1350/1350
--
Training Step: 1119  | total loss: [1m[32m0.07586[0m[0m | time: 0.900s
[2K
| RMSProp | epoch: 027 | loss: 0.07586 - acc: 0.9855 -- iter: 0032/1350
[A[ATraining Step: 1120  | total loss: [1m[32m0.06889[0m[0m | time: 1.799s
[2K
| RMSProp | epoch: 027 | loss: 0.06889 - acc: 0.9869 -- iter: 0064/1350
[A[ATraining Step: 1121  | total loss: [1m[32m0.06220[0m[0m | time: 2.637s
[2K
| RMSProp | epoch: 027 | loss: 0.06220 - acc: 0.9882 -- iter: 0096/1350
[A[ATraining Step: 1122  | total loss: [1m[32m0.05602[0m[0m | time: 3.432s
[2K
| RMSProp | epoch: 027 | loss: 0.05602 - acc: 0.9894 -- iter: 0128/1350
[A[ATraining Step: 1123  | total loss: [1m[32m0.05047[0m[0m | time: 4.375s
[2K
| RMSProp | epoch: 027 | loss: 0.05047 - acc: 0.9905 -- iter: 0160/1350
[A[ATraining Step: 1124  | total loss: [1m[32m0.04552[0m[0m | time: 5.379s
[2K
| RMSProp | epoch: 027 | loss: 0.04552 - acc: 0.9914 -- iter: 0192/1350
[A[ATraining Step: 1125  | total loss: [1m[32m0.04104[0m[0m | time: 6.174s
[2K
| RMSProp | epoch: 027 | loss: 0.04104 - acc: 0.9923 -- iter: 0224/1350
[A[ATraining Step: 1126  | total loss: [1m[32m0.03698[0m[0m | time: 7.058s
[2K
| RMSProp | epoch: 027 | loss: 0.03698 - acc: 0.9931 -- iter: 0256/1350
[A[ATraining Step: 1127  | total loss: [1m[32m0.03332[0m[0m | time: 7.886s
[2K
| RMSProp | epoch: 027 | loss: 0.03332 - acc: 0.9938 -- iter: 0288/1350
[A[ATraining Step: 1128  | total loss: [1m[32m0.03002[0m[0m | time: 8.717s
[2K
| RMSProp | epoch: 027 | loss: 0.03002 - acc: 0.9944 -- iter: 0320/1350
[A[ATraining Step: 1129  | total loss: [1m[32m0.02713[0m[0m | time: 9.576s
[2K
| RMSProp | epoch: 027 | loss: 0.02713 - acc: 0.9949 -- iter: 0352/1350
[A[ATraining Step: 1130  | total loss: [1m[32m0.02447[0m[0m | time: 10.417s
[2K
| RMSProp | epoch: 027 | loss: 0.02447 - acc: 0.9954 -- iter: 0384/1350
[A[ATraining Step: 1131  | total loss: [1m[32m0.02206[0m[0m | time: 11.276s
[2K
| RMSProp | epoch: 027 | loss: 0.02206 - acc: 0.9959 -- iter: 0416/1350
[A[ATraining Step: 1132  | total loss: [1m[32m0.01997[0m[0m | time: 12.123s
[2K
| RMSProp | epoch: 027 | loss: 0.01997 - acc: 0.9963 -- iter: 0448/1350
[A[ATraining Step: 1133  | total loss: [1m[32m0.01906[0m[0m | time: 12.980s
[2K
| RMSProp | epoch: 027 | loss: 0.01906 - acc: 0.9967 -- iter: 0480/1350
[A[ATraining Step: 1134  | total loss: [1m[32m0.02831[0m[0m | time: 13.803s
[2K
| RMSProp | epoch: 027 | loss: 0.02831 - acc: 0.9939 -- iter: 0512/1350
[A[ATraining Step: 1135  | total loss: [1m[32m0.07185[0m[0m | time: 14.677s
[2K
| RMSProp | epoch: 027 | loss: 0.07185 - acc: 0.9882 -- iter: 0544/1350
[A[ATraining Step: 1136  | total loss: [1m[32m0.08580[0m[0m | time: 15.612s
[2K
| RMSProp | epoch: 027 | loss: 0.08580 - acc: 0.9800 -- iter: 0576/1350
[A[ATraining Step: 1137  | total loss: [1m[32m0.08396[0m[0m | time: 16.520s
[2K
| RMSProp | epoch: 027 | loss: 0.08396 - acc: 0.9820 -- iter: 0608/1350
[A[ATraining Step: 1138  | total loss: [1m[32m0.07648[0m[0m | time: 17.230s
[2K
| RMSProp | epoch: 027 | loss: 0.07648 - acc: 0.9838 -- iter: 0640/1350
[A[ATraining Step: 1139  | total loss: [1m[32m0.06950[0m[0m | time: 18.021s
[2K
| RMSProp | epoch: 027 | loss: 0.06950 - acc: 0.9855 -- iter: 0672/1350
[A[ATraining Step: 1140  | total loss: [1m[32m0.06386[0m[0m | time: 18.844s
[2K
| RMSProp | epoch: 027 | loss: 0.06386 - acc: 0.9869 -- iter: 0704/1350
[A[ATraining Step: 1141  | total loss: [1m[32m0.05847[0m[0m | time: 19.678s
[2K
| RMSProp | epoch: 027 | loss: 0.05847 - acc: 0.9882 -- iter: 0736/1350
[A[ATraining Step: 1142  | total loss: [1m[32m0.05325[0m[0m | time: 20.544s
[2K
| RMSProp | epoch: 027 | loss: 0.05325 - acc: 0.9894 -- iter: 0768/1350
[A[ATraining Step: 1143  | total loss: [1m[32m0.05139[0m[0m | time: 20.726s
[2K
| RMSProp | epoch: 027 | loss: 0.05139 - acc: 0.9873 -- iter: 0800/1350
[A[ATraining Step: 1144  | total loss: [1m[32m0.04628[0m[0m | time: 20.922s
[2K
| RMSProp | epoch: 027 | loss: 0.04628 - acc: 0.9886 -- iter: 0832/1350
[A[ATraining Step: 1145  | total loss: [1m[32m0.04168[0m[0m | time: 21.777s
[2K
| RMSProp | epoch: 027 | loss: 0.04168 - acc: 0.9897 -- iter: 0864/1350
[A[ATraining Step: 1146  | total loss: [1m[32m0.03758[0m[0m | time: 22.626s
[2K
| RMSProp | epoch: 027 | loss: 0.03758 - acc: 0.9908 -- iter: 0896/1350
[A[ATraining Step: 1147  | total loss: [1m[32m0.03384[0m[0m | time: 23.481s
[2K
| RMSProp | epoch: 027 | loss: 0.03384 - acc: 0.9917 -- iter: 0928/1350
[A[ATraining Step: 1148  | total loss: [1m[32m0.04636[0m[0m | time: 24.322s
[2K
| RMSProp | epoch: 027 | loss: 0.04636 - acc: 0.9863 -- iter: 0960/1350
[A[ATraining Step: 1149  | total loss: [1m[32m0.08537[0m[0m | time: 25.149s
[2K
| RMSProp | epoch: 027 | loss: 0.08537 - acc: 0.9751 -- iter: 0992/1350
[A[ATraining Step: 1150  | total loss: [1m[32m0.08101[0m[0m | time: 26.119s
[2K
| RMSProp | epoch: 027 | loss: 0.08101 - acc: 0.9776 -- iter: 1024/1350
[A[ATraining Step: 1151  | total loss: [1m[32m0.07408[0m[0m | time: 27.101s
[2K
| RMSProp | epoch: 027 | loss: 0.07408 - acc: 0.9799 -- iter: 1056/1350
[A[ATraining Step: 1152  | total loss: [1m[32m0.06858[0m[0m | time: 27.845s
[2K
| RMSProp | epoch: 027 | loss: 0.06858 - acc: 0.9819 -- iter: 1088/1350
[A[ATraining Step: 1153  | total loss: [1m[32m0.06192[0m[0m | time: 28.653s
[2K
| RMSProp | epoch: 027 | loss: 0.06192 - acc: 0.9837 -- iter: 1120/1350
[A[ATraining Step: 1154  | total loss: [1m[32m0.05623[0m[0m | time: 29.549s
[2K
| RMSProp | epoch: 027 | loss: 0.05623 - acc: 0.9853 -- iter: 1152/1350
[A[ATraining Step: 1155  | total loss: [1m[32m0.05179[0m[0m | time: 30.406s
[2K
| RMSProp | epoch: 027 | loss: 0.05179 - acc: 0.9868 -- iter: 1184/1350
[A[ATraining Step: 1156  | total loss: [1m[32m0.07158[0m[0m | time: 31.274s
[2K
| RMSProp | epoch: 027 | loss: 0.07158 - acc: 0.9850 -- iter: 1216/1350
[A[ATraining Step: 1157  | total loss: [1m[32m0.08385[0m[0m | time: 32.150s
[2K
| RMSProp | epoch: 027 | loss: 0.08385 - acc: 0.9802 -- iter: 1248/1350
[A[ATraining Step: 1158  | total loss: [1m[32m0.07592[0m[0m | time: 33.048s
[2K
| RMSProp | epoch: 027 | loss: 0.07592 - acc: 0.9822 -- iter: 1280/1350
[A[ATraining Step: 1159  | total loss: [1m[32m0.07668[0m[0m | time: 33.950s
[2K
| RMSProp | epoch: 027 | loss: 0.07668 - acc: 0.9777 -- iter: 1312/1350
[A[ATraining Step: 1160  | total loss: [1m[32m0.07412[0m[0m | time: 34.766s
[2K
| RMSProp | epoch: 027 | loss: 0.07412 - acc: 0.9768 -- iter: 1344/1350
[A[ATraining Step: 1161  | total loss: [1m[32m0.06689[0m[0m | time: 37.737s
[2K
| RMSProp | epoch: 027 | loss: 0.06689 - acc: 0.9792 | val_loss: 0.43615 - val_acc: 0.8913 -- iter: 1350/1350
--
Training Step: 1162  | total loss: [1m[32m0.06067[0m[0m | time: 0.865s
[2K
| RMSProp | epoch: 028 | loss: 0.06067 - acc: 0.9812 -- iter: 0032/1350
[A[ATraining Step: 1163  | total loss: [1m[32m0.05475[0m[0m | time: 1.702s
[2K
| RMSProp | epoch: 028 | loss: 0.05475 - acc: 0.9831 -- iter: 0064/1350
[A[ATraining Step: 1164  | total loss: [1m[32m0.04991[0m[0m | time: 2.582s
[2K
| RMSProp | epoch: 028 | loss: 0.04991 - acc: 0.9848 -- iter: 0096/1350
[A[ATraining Step: 1165  | total loss: [1m[32m0.05263[0m[0m | time: 3.502s
[2K
| RMSProp | epoch: 028 | loss: 0.05263 - acc: 0.9801 -- iter: 0128/1350
[A[ATraining Step: 1166  | total loss: [1m[32m0.06211[0m[0m | time: 4.387s
[2K
| RMSProp | epoch: 028 | loss: 0.06211 - acc: 0.9727 -- iter: 0160/1350
[A[ATraining Step: 1167  | total loss: [1m[32m0.06328[0m[0m | time: 5.197s
[2K
| RMSProp | epoch: 028 | loss: 0.06328 - acc: 0.9723 -- iter: 0192/1350
[A[ATraining Step: 1168  | total loss: [1m[32m0.07163[0m[0m | time: 6.087s
[2K
| RMSProp | epoch: 028 | loss: 0.07163 - acc: 0.9657 -- iter: 0224/1350
[A[ATraining Step: 1169  | total loss: [1m[32m0.06515[0m[0m | time: 7.066s
[2K
| RMSProp | epoch: 028 | loss: 0.06515 - acc: 0.9691 -- iter: 0256/1350
[A[ATraining Step: 1170  | total loss: [1m[32m0.05993[0m[0m | time: 7.997s
[2K
| RMSProp | epoch: 028 | loss: 0.05993 - acc: 0.9722 -- iter: 0288/1350
[A[ATraining Step: 1171  | total loss: [1m[32m0.05434[0m[0m | time: 8.729s
[2K
| RMSProp | epoch: 028 | loss: 0.05434 - acc: 0.9750 -- iter: 0320/1350
[A[ATraining Step: 1172  | total loss: [1m[32m0.05128[0m[0m | time: 9.547s
[2K
| RMSProp | epoch: 028 | loss: 0.05128 - acc: 0.9744 -- iter: 0352/1350
[A[ATraining Step: 1173  | total loss: [1m[32m0.04624[0m[0m | time: 10.425s
[2K
| RMSProp | epoch: 028 | loss: 0.04624 - acc: 0.9769 -- iter: 0384/1350
[A[ATraining Step: 1174  | total loss: [1m[32m0.04311[0m[0m | time: 11.246s
[2K
| RMSProp | epoch: 028 | loss: 0.04311 - acc: 0.9792 -- iter: 0416/1350
[A[ATraining Step: 1175  | total loss: [1m[32m0.03909[0m[0m | time: 12.075s
[2K
| RMSProp | epoch: 028 | loss: 0.03909 - acc: 0.9813 -- iter: 0448/1350
[A[ATraining Step: 1176  | total loss: [1m[32m0.03530[0m[0m | time: 12.956s
[2K
| RMSProp | epoch: 028 | loss: 0.03530 - acc: 0.9832 -- iter: 0480/1350
[A[ATraining Step: 1177  | total loss: [1m[32m0.03184[0m[0m | time: 13.831s
[2K
| RMSProp | epoch: 028 | loss: 0.03184 - acc: 0.9849 -- iter: 0512/1350
[A[ATraining Step: 1178  | total loss: [1m[32m0.02872[0m[0m | time: 14.695s
[2K
| RMSProp | epoch: 028 | loss: 0.02872 - acc: 0.9864 -- iter: 0544/1350
[A[ATraining Step: 1179  | total loss: [1m[32m0.02641[0m[0m | time: 15.519s
[2K
| RMSProp | epoch: 028 | loss: 0.02641 - acc: 0.9877 -- iter: 0576/1350
[A[ATraining Step: 1180  | total loss: [1m[32m0.02391[0m[0m | time: 16.412s
[2K
| RMSProp | epoch: 028 | loss: 0.02391 - acc: 0.9890 -- iter: 0608/1350
[A[ATraining Step: 1181  | total loss: [1m[32m0.02165[0m[0m | time: 17.369s
[2K
| RMSProp | epoch: 028 | loss: 0.02165 - acc: 0.9901 -- iter: 0640/1350
[A[ATraining Step: 1182  | total loss: [1m[32m0.02076[0m[0m | time: 18.397s
[2K
| RMSProp | epoch: 028 | loss: 0.02076 - acc: 0.9911 -- iter: 0672/1350
[A[ATraining Step: 1183  | total loss: [1m[32m0.01894[0m[0m | time: 19.074s
[2K
| RMSProp | epoch: 028 | loss: 0.01894 - acc: 0.9920 -- iter: 0704/1350
[A[ATraining Step: 1184  | total loss: [1m[32m0.02695[0m[0m | time: 19.884s
[2K
| RMSProp | epoch: 028 | loss: 0.02695 - acc: 0.9896 -- iter: 0736/1350
[A[ATraining Step: 1185  | total loss: [1m[32m0.02477[0m[0m | time: 20.782s
[2K
| RMSProp | epoch: 028 | loss: 0.02477 - acc: 0.9907 -- iter: 0768/1350
[A[ATraining Step: 1186  | total loss: [1m[32m0.02810[0m[0m | time: 21.655s
[2K
| RMSProp | epoch: 028 | loss: 0.02810 - acc: 0.9885 -- iter: 0800/1350
[A[ATraining Step: 1187  | total loss: [1m[32m0.04711[0m[0m | time: 21.861s
[2K
| RMSProp | epoch: 028 | loss: 0.04711 - acc: 0.9865 -- iter: 0832/1350
[A[ATraining Step: 1188  | total loss: [1m[32m0.05132[0m[0m | time: 22.059s
[2K
| RMSProp | epoch: 028 | loss: 0.05132 - acc: 0.9879 -- iter: 0864/1350
[A[ATraining Step: 1189  | total loss: [1m[32m0.04622[0m[0m | time: 22.890s
[2K
| RMSProp | epoch: 028 | loss: 0.04622 - acc: 0.9891 -- iter: 0896/1350
[A[ATraining Step: 1190  | total loss: [1m[32m0.06282[0m[0m | time: 23.757s
[2K
| RMSProp | epoch: 028 | loss: 0.06282 - acc: 0.9808 -- iter: 0928/1350
[A[ATraining Step: 1191  | total loss: [1m[32m0.06468[0m[0m | time: 24.635s
[2K
| RMSProp | epoch: 028 | loss: 0.06468 - acc: 0.9796 -- iter: 0960/1350
[A[ATraining Step: 1192  | total loss: [1m[32m0.07428[0m[0m | time: 25.538s
[2K
| RMSProp | epoch: 028 | loss: 0.07428 - acc: 0.9785 -- iter: 0992/1350
[A[ATraining Step: 1193  | total loss: [1m[32m0.07694[0m[0m | time: 26.329s
[2K
| RMSProp | epoch: 028 | loss: 0.07694 - acc: 0.9775 -- iter: 1024/1350
[A[ATraining Step: 1194  | total loss: [1m[32m0.07011[0m[0m | time: 27.256s
[2K
| RMSProp | epoch: 028 | loss: 0.07011 - acc: 0.9798 -- iter: 1056/1350
[A[ATraining Step: 1195  | total loss: [1m[32m0.07710[0m[0m | time: 28.211s
[2K
| RMSProp | epoch: 028 | loss: 0.07710 - acc: 0.9787 -- iter: 1088/1350
[A[ATraining Step: 1196  | total loss: [1m[32m0.07144[0m[0m | time: 29.073s
[2K
| RMSProp | epoch: 028 | loss: 0.07144 - acc: 0.9808 -- iter: 1120/1350
[A[ATraining Step: 1197  | total loss: [1m[32m0.06474[0m[0m | time: 29.812s
[2K
| RMSProp | epoch: 028 | loss: 0.06474 - acc: 0.9827 -- iter: 1152/1350
[A[ATraining Step: 1198  | total loss: [1m[32m0.06988[0m[0m | time: 30.654s
[2K
| RMSProp | epoch: 028 | loss: 0.06988 - acc: 0.9813 -- iter: 1184/1350
[A[ATraining Step: 1199  | total loss: [1m[32m0.07249[0m[0m | time: 31.488s
[2K
| RMSProp | epoch: 028 | loss: 0.07249 - acc: 0.9801 -- iter: 1216/1350
[A[ATraining Step: 1200  | total loss: [1m[32m0.06555[0m[0m | time: 34.106s
[2K
| RMSProp | epoch: 028 | loss: 0.06555 - acc: 0.9821 | val_loss: 0.39671 - val_acc: 0.9054 -- iter: 1248/1350
--
Training Step: 1201  | total loss: [1m[32m0.05951[0m[0m | time: 34.925s
[2K
| RMSProp | epoch: 028 | loss: 0.05951 - acc: 0.9839 -- iter: 1280/1350
[A[ATraining Step: 1202  | total loss: [1m[32m0.05379[0m[0m | time: 35.795s
[2K
| RMSProp | epoch: 028 | loss: 0.05379 - acc: 0.9855 -- iter: 1312/1350
[A[ATraining Step: 1203  | total loss: [1m[32m0.04874[0m[0m | time: 36.782s
[2K
| RMSProp | epoch: 028 | loss: 0.04874 - acc: 0.9869 -- iter: 1344/1350
[A[ATraining Step: 1204  | total loss: [1m[32m0.04412[0m[0m | time: 39.382s
[2K
| RMSProp | epoch: 028 | loss: 0.04412 - acc: 0.9882 | val_loss: 0.43250 - val_acc: 0.9054 -- iter: 1350/1350
--
Training Step: 1205  | total loss: [1m[32m0.03980[0m[0m | time: 0.875s
[2K
| RMSProp | epoch: 029 | loss: 0.03980 - acc: 0.9894 -- iter: 0032/1350
[A[ATraining Step: 1206  | total loss: [1m[32m0.03589[0m[0m | time: 1.717s
[2K
| RMSProp | epoch: 029 | loss: 0.03589 - acc: 0.9905 -- iter: 0064/1350
[A[ATraining Step: 1207  | total loss: [1m[32m0.03246[0m[0m | time: 2.534s
[2K
| RMSProp | epoch: 029 | loss: 0.03246 - acc: 0.9914 -- iter: 0096/1350
[A[ATraining Step: 1208  | total loss: [1m[32m0.02927[0m[0m | time: 3.355s
[2K
| RMSProp | epoch: 029 | loss: 0.02927 - acc: 0.9923 -- iter: 0128/1350
[A[ATraining Step: 1209  | total loss: [1m[32m0.02642[0m[0m | time: 4.206s
[2K
| RMSProp | epoch: 029 | loss: 0.02642 - acc: 0.9931 -- iter: 0160/1350
[A[ATraining Step: 1210  | total loss: [1m[32m0.02392[0m[0m | time: 5.188s
[2K
| RMSProp | epoch: 029 | loss: 0.02392 - acc: 0.9937 -- iter: 0192/1350
[A[ATraining Step: 1211  | total loss: [1m[32m0.02161[0m[0m | time: 6.169s
[2K
| RMSProp | epoch: 029 | loss: 0.02161 - acc: 0.9944 -- iter: 0224/1350
[A[ATraining Step: 1212  | total loss: [1m[32m0.01956[0m[0m | time: 6.889s
[2K
| RMSProp | epoch: 029 | loss: 0.01956 - acc: 0.9949 -- iter: 0256/1350
[A[ATraining Step: 1213  | total loss: [1m[32m0.01772[0m[0m | time: 7.709s
[2K
| RMSProp | epoch: 029 | loss: 0.01772 - acc: 0.9954 -- iter: 0288/1350
[A[ATraining Step: 1214  | total loss: [1m[32m0.01603[0m[0m | time: 8.543s
[2K
| RMSProp | epoch: 029 | loss: 0.01603 - acc: 0.9959 -- iter: 0320/1350
[A[ATraining Step: 1215  | total loss: [1m[32m0.01444[0m[0m | time: 9.412s
[2K
| RMSProp | epoch: 029 | loss: 0.01444 - acc: 0.9963 -- iter: 0352/1350
[A[ATraining Step: 1216  | total loss: [1m[32m0.01309[0m[0m | time: 10.249s
[2K
| RMSProp | epoch: 029 | loss: 0.01309 - acc: 0.9967 -- iter: 0384/1350
[A[ATraining Step: 1217  | total loss: [1m[32m0.01193[0m[0m | time: 11.138s
[2K
| RMSProp | epoch: 029 | loss: 0.01193 - acc: 0.9970 -- iter: 0416/1350
[A[ATraining Step: 1218  | total loss: [1m[32m0.01080[0m[0m | time: 12.063s
[2K
| RMSProp | epoch: 029 | loss: 0.01080 - acc: 0.9973 -- iter: 0448/1350
[A[ATraining Step: 1219  | total loss: [1m[32m0.00974[0m[0m | time: 12.951s
[2K
| RMSProp | epoch: 029 | loss: 0.00974 - acc: 0.9976 -- iter: 0480/1350
[A[ATraining Step: 1220  | total loss: [1m[32m0.00881[0m[0m | time: 13.796s
[2K
| RMSProp | epoch: 029 | loss: 0.00881 - acc: 0.9978 -- iter: 0512/1350
[A[ATraining Step: 1221  | total loss: [1m[32m0.00793[0m[0m | time: 14.745s
[2K
| RMSProp | epoch: 029 | loss: 0.00793 - acc: 0.9980 -- iter: 0544/1350
[A[ATraining Step: 1222  | total loss: [1m[32m0.00720[0m[0m | time: 15.700s
[2K
| RMSProp | epoch: 029 | loss: 0.00720 - acc: 0.9982 -- iter: 0576/1350
[A[ATraining Step: 1223  | total loss: [1m[32m0.00652[0m[0m | time: 16.638s
[2K
| RMSProp | epoch: 029 | loss: 0.00652 - acc: 0.9984 -- iter: 0608/1350
[A[ATraining Step: 1224  | total loss: [1m[32m0.00589[0m[0m | time: 17.358s
[2K
| RMSProp | epoch: 029 | loss: 0.00589 - acc: 0.9986 -- iter: 0640/1350
[A[ATraining Step: 1225  | total loss: [1m[32m0.00533[0m[0m | time: 18.201s
[2K
| RMSProp | epoch: 029 | loss: 0.00533 - acc: 0.9987 -- iter: 0672/1350
[A[ATraining Step: 1226  | total loss: [1m[32m0.00480[0m[0m | time: 19.060s
[2K
| RMSProp | epoch: 029 | loss: 0.00480 - acc: 0.9988 -- iter: 0704/1350
[A[ATraining Step: 1227  | total loss: [1m[32m0.00437[0m[0m | time: 19.865s
[2K
| RMSProp | epoch: 029 | loss: 0.00437 - acc: 0.9990 -- iter: 0736/1350
[A[ATraining Step: 1228  | total loss: [1m[32m0.00394[0m[0m | time: 20.694s
[2K
| RMSProp | epoch: 029 | loss: 0.00394 - acc: 0.9991 -- iter: 0768/1350
[A[ATraining Step: 1229  | total loss: [1m[32m0.00359[0m[0m | time: 21.584s
[2K
| RMSProp | epoch: 029 | loss: 0.00359 - acc: 0.9992 -- iter: 0800/1350
[A[ATraining Step: 1230  | total loss: [1m[32m0.00327[0m[0m | time: 22.549s
[2K
| RMSProp | epoch: 029 | loss: 0.00327 - acc: 0.9992 -- iter: 0832/1350
[A[ATraining Step: 1231  | total loss: [1m[32m0.00295[0m[0m | time: 22.748s
[2K
| RMSProp | epoch: 029 | loss: 0.00295 - acc: 0.9993 -- iter: 0864/1350
[A[ATraining Step: 1232  | total loss: [1m[32m0.00266[0m[0m | time: 22.963s
[2K
| RMSProp | epoch: 029 | loss: 0.00266 - acc: 0.9994 -- iter: 0896/1350
[A[ATraining Step: 1233  | total loss: [1m[32m0.00240[0m[0m | time: 23.847s
[2K
| RMSProp | epoch: 029 | loss: 0.00240 - acc: 0.9994 -- iter: 0928/1350
[A[ATraining Step: 1234  | total loss: [1m[32m0.00217[0m[0m | time: 24.736s
[2K
| RMSProp | epoch: 029 | loss: 0.00217 - acc: 0.9995 -- iter: 0960/1350
[A[ATraining Step: 1235  | total loss: [1m[32m0.00195[0m[0m | time: 25.769s
[2K
| RMSProp | epoch: 029 | loss: 0.00195 - acc: 0.9996 -- iter: 0992/1350
[A[ATraining Step: 1236  | total loss: [1m[32m0.00176[0m[0m | time: 26.719s
[2K
| RMSProp | epoch: 029 | loss: 0.00176 - acc: 0.9996 -- iter: 1024/1350
[A[ATraining Step: 1237  | total loss: [1m[32m0.00164[0m[0m | time: 27.438s
[2K
| RMSProp | epoch: 029 | loss: 0.00164 - acc: 0.9996 -- iter: 1056/1350
[A[ATraining Step: 1238  | total loss: [1m[32m0.00232[0m[0m | time: 28.242s
[2K
| RMSProp | epoch: 029 | loss: 0.00232 - acc: 0.9997 -- iter: 1088/1350
[A[ATraining Step: 1239  | total loss: [1m[32m0.00339[0m[0m | time: 29.071s
[2K
| RMSProp | epoch: 029 | loss: 0.00339 - acc: 0.9997 -- iter: 1120/1350
[A[ATraining Step: 1240  | total loss: [1m[32m0.00326[0m[0m | time: 29.937s
[2K
| RMSProp | epoch: 029 | loss: 0.00326 - acc: 0.9997 -- iter: 1152/1350
[A[ATraining Step: 1241  | total loss: [1m[32m0.00428[0m[0m | time: 30.759s
[2K
| RMSProp | epoch: 029 | loss: 0.00428 - acc: 0.9998 -- iter: 1184/1350
[A[ATraining Step: 1242  | total loss: [1m[32m0.02539[0m[0m | time: 31.584s
[2K
| RMSProp | epoch: 029 | loss: 0.02539 - acc: 0.9935 -- iter: 1216/1350
[A[ATraining Step: 1243  | total loss: [1m[32m0.02981[0m[0m | time: 32.455s
[2K
| RMSProp | epoch: 029 | loss: 0.02981 - acc: 0.9911 -- iter: 1248/1350
[A[ATraining Step: 1244  | total loss: [1m[32m0.05292[0m[0m | time: 33.345s
[2K
| RMSProp | epoch: 029 | loss: 0.05292 - acc: 0.9888 -- iter: 1280/1350
[A[ATraining Step: 1245  | total loss: [1m[32m0.07354[0m[0m | time: 34.222s
[2K
| RMSProp | epoch: 029 | loss: 0.07354 - acc: 0.9837 -- iter: 1312/1350
[A[ATraining Step: 1246  | total loss: [1m[32m0.07067[0m[0m | time: 35.034s
[2K
| RMSProp | epoch: 029 | loss: 0.07067 - acc: 0.9853 -- iter: 1344/1350
[A[ATraining Step: 1247  | total loss: [1m[32m0.06389[0m[0m | time: 38.117s
[2K
| RMSProp | epoch: 029 | loss: 0.06389 - acc: 0.9868 | val_loss: 0.35382 - val_acc: 0.9196 -- iter: 1350/1350
--
Training Step: 1248  | total loss: [1m[32m0.05808[0m[0m | time: 0.882s
[2K
| RMSProp | epoch: 030 | loss: 0.05808 - acc: 0.9881 -- iter: 0032/1350
[A[ATraining Step: 1249  | total loss: [1m[32m0.05241[0m[0m | time: 1.734s
[2K
| RMSProp | epoch: 030 | loss: 0.05241 - acc: 0.9893 -- iter: 0064/1350
[A[ATraining Step: 1250  | total loss: [1m[32m0.04731[0m[0m | time: 2.557s
[2K
| RMSProp | epoch: 030 | loss: 0.04731 - acc: 0.9904 -- iter: 0096/1350
[A[ATraining Step: 1251  | total loss: [1m[32m0.04276[0m[0m | time: 3.499s
[2K
| RMSProp | epoch: 030 | loss: 0.04276 - acc: 0.9913 -- iter: 0128/1350
[A[ATraining Step: 1252  | total loss: [1m[32m0.03855[0m[0m | time: 4.446s
[2K
| RMSProp | epoch: 030 | loss: 0.03855 - acc: 0.9922 -- iter: 0160/1350
[A[ATraining Step: 1253  | total loss: [1m[32m0.03533[0m[0m | time: 5.190s
[2K
| RMSProp | epoch: 030 | loss: 0.03533 - acc: 0.9930 -- iter: 0192/1350
[A[ATraining Step: 1254  | total loss: [1m[32m0.03186[0m[0m | time: 6.010s
[2K
| RMSProp | epoch: 030 | loss: 0.03186 - acc: 0.9937 -- iter: 0224/1350
[A[ATraining Step: 1255  | total loss: [1m[32m0.02869[0m[0m | time: 6.885s
[2K
| RMSProp | epoch: 030 | loss: 0.02869 - acc: 0.9943 -- iter: 0256/1350
[A[ATraining Step: 1256  | total loss: [1m[32m0.02586[0m[0m | time: 7.756s
[2K
| RMSProp | epoch: 030 | loss: 0.02586 - acc: 0.9949 -- iter: 0288/1350
[A[ATraining Step: 1257  | total loss: [1m[32m0.02336[0m[0m | time: 8.588s
[2K
| RMSProp | epoch: 030 | loss: 0.02336 - acc: 0.9954 -- iter: 0320/1350
[A[ATraining Step: 1258  | total loss: [1m[32m0.02117[0m[0m | time: 9.484s
[2K
| RMSProp | epoch: 030 | loss: 0.02117 - acc: 0.9959 -- iter: 0352/1350
[A[ATraining Step: 1259  | total loss: [1m[32m0.01906[0m[0m | time: 10.375s
[2K
| RMSProp | epoch: 030 | loss: 0.01906 - acc: 0.9963 -- iter: 0384/1350
[A[ATraining Step: 1260  | total loss: [1m[32m0.01719[0m[0m | time: 11.294s
[2K
| RMSProp | epoch: 030 | loss: 0.01719 - acc: 0.9966 -- iter: 0416/1350
[A[ATraining Step: 1261  | total loss: [1m[32m0.01549[0m[0m | time: 12.119s
[2K
| RMSProp | epoch: 030 | loss: 0.01549 - acc: 0.9970 -- iter: 0448/1350
[A[ATraining Step: 1262  | total loss: [1m[32m0.01406[0m[0m | time: 13.024s
[2K
| RMSProp | epoch: 030 | loss: 0.01406 - acc: 0.9973 -- iter: 0480/1350
[A[ATraining Step: 1263  | total loss: [1m[32m0.01270[0m[0m | time: 14.011s
[2K
| RMSProp | epoch: 030 | loss: 0.01270 - acc: 0.9976 -- iter: 0512/1350
[A[ATraining Step: 1264  | total loss: [1m[32m0.01148[0m[0m | time: 14.963s
[2K
| RMSProp | epoch: 030 | loss: 0.01148 - acc: 0.9978 -- iter: 0544/1350
[A[ATraining Step: 1265  | total loss: [1m[32m0.01067[0m[0m | time: 15.666s
[2K
| RMSProp | epoch: 030 | loss: 0.01067 - acc: 0.9980 -- iter: 0576/1350
[A[ATraining Step: 1266  | total loss: [1m[32m0.00990[0m[0m | time: 16.454s
[2K
| RMSProp | epoch: 030 | loss: 0.00990 - acc: 0.9982 -- iter: 0608/1350
[A[ATraining Step: 1267  | total loss: [1m[32m0.00891[0m[0m | time: 17.277s
[2K
| RMSProp | epoch: 030 | loss: 0.00891 - acc: 0.9984 -- iter: 0640/1350
[A[ATraining Step: 1268  | total loss: [1m[32m0.00804[0m[0m | time: 18.128s
[2K
| RMSProp | epoch: 030 | loss: 0.00804 - acc: 0.9986 -- iter: 0672/1350
[A[ATraining Step: 1269  | total loss: [1m[32m0.00724[0m[0m | time: 18.922s
[2K
| RMSProp | epoch: 030 | loss: 0.00724 - acc: 0.9987 -- iter: 0704/1350
[A[ATraining Step: 1270  | total loss: [1m[32m0.00654[0m[0m | time: 19.845s
[2K
| RMSProp | epoch: 030 | loss: 0.00654 - acc: 0.9988 -- iter: 0736/1350
[A[ATraining Step: 1271  | total loss: [1m[32m0.00589[0m[0m | time: 20.821s
[2K
| RMSProp | epoch: 030 | loss: 0.00589 - acc: 0.9989 -- iter: 0768/1350
[A[ATraining Step: 1272  | total loss: [1m[32m0.00532[0m[0m | time: 21.734s
[2K
| RMSProp | epoch: 030 | loss: 0.00532 - acc: 0.9991 -- iter: 0800/1350
[A[ATraining Step: 1273  | total loss: [1m[32m0.00479[0m[0m | time: 22.584s
[2K
| RMSProp | epoch: 030 | loss: 0.00479 - acc: 0.9991 -- iter: 0832/1350
[A[ATraining Step: 1274  | total loss: [1m[32m0.00433[0m[0m | time: 23.468s
[2K
| RMSProp | epoch: 030 | loss: 0.00433 - acc: 0.9992 -- iter: 0864/1350
[A[ATraining Step: 1275  | total loss: [1m[32m0.00390[0m[0m | time: 23.693s
[2K
| RMSProp | epoch: 030 | loss: 0.00390 - acc: 0.9993 -- iter: 0896/1350
[A[ATraining Step: 1276  | total loss: [1m[32m0.00354[0m[0m | time: 23.946s
[2K
| RMSProp | epoch: 030 | loss: 0.00354 - acc: 0.9994 -- iter: 0928/1350
[A[ATraining Step: 1277  | total loss: [1m[32m0.00321[0m[0m | time: 24.923s
[2K
| RMSProp | epoch: 030 | loss: 0.00321 - acc: 0.9994 -- iter: 0960/1350
[A[ATraining Step: 1278  | total loss: [1m[32m0.00293[0m[0m | time: 25.709s
[2K
| RMSProp | epoch: 030 | loss: 0.00293 - acc: 0.9995 -- iter: 0992/1350
[A[ATraining Step: 1279  | total loss: [1m[32m0.00267[0m[0m | time: 26.494s
[2K
| RMSProp | epoch: 030 | loss: 0.00267 - acc: 0.9995 -- iter: 1024/1350
[A[ATraining Step: 1280  | total loss: [1m[32m0.00241[0m[0m | time: 27.313s
[2K
| RMSProp | epoch: 030 | loss: 0.00241 - acc: 0.9996 -- iter: 1056/1350
[A[ATraining Step: 1281  | total loss: [1m[32m0.00219[0m[0m | time: 28.177s
[2K
| RMSProp | epoch: 030 | loss: 0.00219 - acc: 0.9996 -- iter: 1088/1350
[A[ATraining Step: 1282  | total loss: [1m[32m0.00202[0m[0m | time: 29.059s
[2K
| RMSProp | epoch: 030 | loss: 0.00202 - acc: 0.9997 -- iter: 1120/1350
[A[ATraining Step: 1283  | total loss: [1m[32m0.00182[0m[0m | time: 29.898s
[2K
| RMSProp | epoch: 030 | loss: 0.00182 - acc: 0.9997 -- iter: 1152/1350
[A[ATraining Step: 1284  | total loss: [1m[32m0.00165[0m[0m | time: 30.722s
[2K
| RMSProp | epoch: 030 | loss: 0.00165 - acc: 0.9997 -- iter: 1184/1350
[A[ATraining Step: 1285  | total loss: [1m[32m0.00165[0m[0m | time: 31.610s
[2K
| RMSProp | epoch: 030 | loss: 0.00165 - acc: 0.9998 -- iter: 1216/1350
[A[ATraining Step: 1286  | total loss: [1m[32m0.05942[0m[0m | time: 32.456s
[2K
| RMSProp | epoch: 030 | loss: 0.05942 - acc: 0.9904 -- iter: 1248/1350
[A[ATraining Step: 1287  | total loss: [1m[32m0.16025[0m[0m | time: 33.226s
[2K
| RMSProp | epoch: 030 | loss: 0.16025 - acc: 0.9570 -- iter: 1280/1350
[A[ATraining Step: 1288  | total loss: [1m[32m0.14992[0m[0m | time: 34.130s
[2K
| RMSProp | epoch: 030 | loss: 0.14992 - acc: 0.9582 -- iter: 1312/1350
[A[ATraining Step: 1289  | total loss: [1m[32m0.14128[0m[0m | time: 35.159s
[2K
| RMSProp | epoch: 030 | loss: 0.14128 - acc: 0.9592 -- iter: 1344/1350
[A[ATraining Step: 1290  | total loss: [1m[32m0.13217[0m[0m | time: 37.592s
[2K
| RMSProp | epoch: 030 | loss: 0.13217 - acc: 0.9602 | val_loss: 0.62036 - val_acc: 0.8865 -- iter: 1350/1350
--
Validation AUC:0.9491430366116295
Validation AUPRC:0.9461317365062437
Test AUC:0.9360171009042887
Test AUPRC:0.9419572318648769
BestTestF1Score	0.89	0.78	0.89	0.92	0.86	189	17	187	30	0.76
BestTestMCCScore	0.89	0.78	0.89	0.92	0.85	187	16	188	32	0.82
BestTestAccuracyScore	0.89	0.78	0.89	0.92	0.85	187	16	188	32	0.82
BestValidationF1Score	0.89	0.8	0.9	0.9	0.88	175	19	205	24	0.76
BestValidationMCC	0.89	0.8	0.9	0.91	0.87	173	17	207	26	0.82
BestValidationAccuracy	0.89	0.8	0.9	0.91	0.87	173	17	207	26	0.82
TestPredictions (Threshold:0.82)
CHEMBL421523,TN,INACT,0.0	CHEMBL2371361,FP,INACT,0.9900000095367432	CHEMBL344885,TP,ACT,1.0	CHEMBL1082400,FN,ACT,0.7599999904632568	CHEMBL169553,TN,INACT,0.0	CHEMBL299132,TP,ACT,0.9900000095367432	CHEMBL14036,TP,ACT,1.0	CHEMBL169670,TP,ACT,1.0	CHEMBL415406,FN,ACT,0.0	CHEMBL2113670,TP,ACT,1.0	CHEMBL78932,TP,ACT,1.0	CHEMBL407685,TP,ACT,1.0	CHEMBL48241,TP,ACT,1.0	CHEMBL227429,TN,INACT,0.0	CHEMBL344602,TN,INACT,0.0	CHEMBL312551,TN,INACT,0.10999999940395355	CHEMBL79030,TN,INACT,0.0	CHEMBL294134,FN,ACT,0.0	CHEMBL3236675,TP,ACT,1.0	CHEMBL2112592,TN,INACT,0.009999999776482582	CHEMBL87496,TN,INACT,0.05000000074505806	CHEMBL48448,TN,INACT,0.0	CHEMBL110695,TN,INACT,0.0	CHEMBL3408737,TP,ACT,1.0	CHEMBL419511,TP,ACT,1.0	CHEMBL104981,TN,INACT,0.0	CHEMBL112777,TN,INACT,0.2199999988079071	CHEMBL2370869,TP,ACT,1.0	CHEMBL404929,TP,ACT,1.0	CHEMBL2331793,TN,INACT,0.0	CHEMBL2370162,TP,ACT,0.8299999833106995	CHEMBL430833,TP,ACT,1.0	CHEMBL34328,TN,INACT,0.0	CHEMBL3633663,TN,INACT,0.33000001311302185	CHEMBL240888,TN,INACT,0.0	CHEMBL1672481,TP,ACT,1.0	CHEMBL602474,TN,INACT,0.0	CHEMBL112417,TN,INACT,0.0	CHEMBL458409,TN,INACT,0.0	CHEMBL214040,TP,ACT,1.0	CHEMBL10986,FN,ACT,0.7900000214576721	CHEMBL333357,FN,ACT,0.4000000059604645	CHEMBL102452,TN,INACT,0.0	CHEMBL269576,TN,INACT,0.0	CHEMBL2372391,TP,ACT,0.9800000190734863	CHEMBL42799,TN,INACT,0.0	CHEMBL2369126,TP,ACT,1.0	CHEMBL610002,TP,ACT,1.0	CHEMBL3577342,TN,INACT,0.7900000214576721	CHEMBL239153,TN,INACT,0.0	CHEMBL299709,TP,ACT,1.0	CHEMBL2112730,TP,ACT,1.0	CHEMBL2402936,TP,ACT,1.0	CHEMBL214285,TP,ACT,1.0	CHEMBL266845,TP,ACT,1.0	CHEMBL3403343,TN,INACT,0.0	CHEMBL384250,TP,ACT,1.0	CHEMBL3350315,TN,INACT,0.0	CHEMBL1672470,TP,ACT,1.0	CHEMBL272853,TN,INACT,0.0	CHEMBL374602,TN,INACT,0.0	CHEMBL2163921,TN,INACT,0.009999999776482582	CHEMBL3823054,TP,ACT,1.0	CHEMBL490,TN,INACT,0.0	CHEMBL286682,TN,INACT,0.12999999523162842	CHEMBL80317,TN,INACT,0.0	CHEMBL1672489,TP,ACT,1.0	CHEMBL74066,TN,INACT,0.0	CHEMBL446698,TN,INACT,0.0	CHEMBL110064,TN,INACT,0.0	CHEMBL473362,TP,ACT,1.0	CHEMBL60559,TN,INACT,0.0	CHEMBL399000,TN,INACT,0.0	CHEMBL278789,FN,ACT,0.009999999776482582	CHEMBL100810,TN,INACT,0.0	CHEMBL2372390,FN,ACT,0.009999999776482582	CHEMBL433272,TP,ACT,1.0	CHEMBL1076625,TN,INACT,0.0	CHEMBL440765,TP,ACT,1.0	CHEMBL416069,TN,INACT,0.0	CHEMBL3233014,FN,ACT,0.0	CHEMBL142295,TN,INACT,0.6600000262260437	CHEMBL611139,TP,ACT,1.0	CHEMBL14094,FN,ACT,0.0	CHEMBL196866,TN,INACT,0.0	CHEMBL290968,TP,ACT,1.0	CHEMBL418658,TN,INACT,0.0	CHEMBL2048230,TN,INACT,0.0	CHEMBL1672471,TP,ACT,1.0	CHEMBL31524,TN,INACT,0.0	CHEMBL109206,TN,INACT,0.0	CHEMBL106910,TP,ACT,1.0	CHEMBL25493,FN,ACT,0.0	CHEMBL106359,TN,INACT,0.019999999552965164	CHEMBL91231,TP,ACT,1.0	CHEMBL3410301,FP,INACT,0.9800000190734863	CHEMBL77962,FP,INACT,0.949999988079071	CHEMBL7505,TN,INACT,0.0	CHEMBL61630,TP,ACT,1.0	CHEMBL332927,TP,ACT,1.0	CHEMBL38704,TN,INACT,0.0	CHEMBL76023,TP,ACT,1.0	CHEMBL2153622,FP,INACT,0.9900000095367432	CHEMBL44463,TN,INACT,0.0	CHEMBL291293,TN,INACT,0.0	CHEMBL323517,TN,INACT,0.0	CHEMBL239819,TN,INACT,0.019999999552965164	CHEMBL3608939,FN,ACT,0.3799999952316284	CHEMBL542149,TP,ACT,1.0	CHEMBL3604302,TN,INACT,0.0	CHEMBL2158005,TN,INACT,0.0	CHEMBL214657,TP,ACT,0.9900000095367432	CHEMBL38578,TP,ACT,1.0	CHEMBL10801,TN,INACT,0.0	CHEMBL2112736,TP,ACT,1.0	CHEMBL3735265,TN,INACT,0.0	CHEMBL328236,TP,ACT,0.9900000095367432	CHEMBL2370509,TN,INACT,0.0	CHEMBL3350132,TP,ACT,1.0	CHEMBL308813,TP,ACT,1.0	CHEMBL2112732,TP,ACT,1.0	CHEMBL353502,TN,INACT,0.23000000417232513	CHEMBL3617467,TP,ACT,1.0	CHEMBL2207681,TP,ACT,1.0	CHEMBL3109772,TN,INACT,0.0	CHEMBL274875,TP,ACT,1.0	CHEMBL106259,TN,INACT,0.0	CHEMBL171108,TN,INACT,0.019999999552965164	CHEMBL323074,TN,INACT,0.0	CHEMBL386887,TP,ACT,0.9599999785423279	CHEMBL79915,TN,INACT,0.0	CHEMBL169345,FN,ACT,0.10999999940395355	CHEMBL3114145,TN,INACT,0.0	CHEMBL511691,FN,ACT,0.07999999821186066	CHEMBL545363,TN,INACT,0.0	CHEMBL3403336,TN,INACT,0.0	CHEMBL140365,TN,INACT,0.0	CHEMBL263509,TP,ACT,1.0	CHEMBL602269,TN,INACT,0.0	CHEMBL2112740,TP,ACT,1.0	CHEMBL3754081,TP,ACT,0.9599999785423279	CHEMBL412569,TN,INACT,0.5899999737739563	CHEMBL2370868,TP,ACT,1.0	CHEMBL610549,TP,ACT,1.0	CHEMBL3577343,FP,INACT,0.8899999856948853	CHEMBL78853,TN,INACT,0.0	CHEMBL2372387,TP,ACT,0.9900000095367432	CHEMBL306016,TP,ACT,0.949999988079071	CHEMBL240895,TN,INACT,0.0	CHEMBL458947,TN,INACT,0.0	CHEMBL3143400,FP,INACT,1.0	CHEMBL129198,TN,INACT,0.05000000074505806	CHEMBL42359,TN,INACT,0.0	CHEMBL319387,TN,INACT,0.0	CHEMBL152351,TP,ACT,1.0	CHEMBL2115043,FN,ACT,0.0	CHEMBL555430,FN,ACT,0.0	CHEMBL283802,TP,ACT,1.0	CHEMBL78830,TN,INACT,0.0	CHEMBL1192069,TN,INACT,0.0	CHEMBL160626,TN,INACT,0.0	CHEMBL340032,FN,ACT,0.0	CHEMBL385048,TP,ACT,1.0	CHEMBL2207679,TP,ACT,1.0	CHEMBL2370622,TP,ACT,1.0	CHEMBL2016680,TP,ACT,1.0	CHEMBL291516,TN,INACT,0.0	CHEMBL461229,TP,ACT,1.0	CHEMBL2110199,TP,ACT,1.0	CHEMBL3038177,TP,ACT,0.9900000095367432	CHEMBL112877,TN,INACT,0.0	CHEMBL385759,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.0	CHEMBL132179,TN,INACT,0.0	CHEMBL408024,TP,ACT,1.0	CHEMBL1082638,TP,ACT,1.0	CHEMBL143341,TN,INACT,0.0	CHEMBL307659,TN,INACT,0.0	CHEMBL307614,TN,INACT,0.0	CHEMBL216351,TP,ACT,1.0	CHEMBL102092,TP,ACT,1.0	CHEMBL344187,TN,INACT,0.0	CHEMBL3613280,TP,ACT,1.0	CHEMBL1797684,TP,ACT,1.0	CHEMBL191915,TN,INACT,0.0	CHEMBL514965,TN,INACT,0.0	CHEMBL124283,TP,ACT,1.0	CHEMBL61792,TN,INACT,0.0	CHEMBL3613168,TP,ACT,1.0	CHEMBL39843,TN,INACT,0.0	CHEMBL2408012,TP,ACT,1.0	CHEMBL59517,TN,INACT,0.0	CHEMBL594801,TN,INACT,0.0	CHEMBL3350741,FP,INACT,1.0	CHEMBL323245,TN,INACT,0.0	CHEMBL295076,TP,ACT,1.0	CHEMBL2369128,TP,ACT,1.0	CHEMBL70246,TN,INACT,0.3400000035762787	CHEMBL297215,TN,INACT,0.0	CHEMBL81593,TN,INACT,0.0	CHEMBL543251,TN,INACT,0.0	CHEMBL2112729,TP,ACT,1.0	CHEMBL97246,FN,ACT,0.0	CHEMBL411,TN,INACT,0.0	CHEMBL438034,TP,ACT,1.0	CHEMBL59,TN,INACT,0.0	CHEMBL1223890,TP,ACT,1.0	CHEMBL3808398,TP,ACT,1.0	CHEMBL291751,TP,ACT,1.0	CHEMBL1621896,TN,INACT,0.0	CHEMBL1672494,TP,ACT,1.0	CHEMBL22321,TP,ACT,1.0	CHEMBL3822676,TP,ACT,1.0	CHEMBL283320,TN,INACT,0.0	CHEMBL3114143,TN,INACT,0.07000000029802322	CHEMBL302468,TN,INACT,0.0	CHEMBL2372388,FN,ACT,0.0	CHEMBL104180,TN,INACT,0.0	CHEMBL3038184,TP,ACT,1.0	CHEMBL64235,TN,INACT,0.0	CHEMBL355188,TP,ACT,1.0	CHEMBL2371359,TP,ACT,0.9900000095367432	CHEMBL63114,TN,INACT,0.0	CHEMBL113,TN,INACT,0.0	CHEMBL595265,TN,INACT,0.0	CHEMBL573214,TP,ACT,1.0	CHEMBL68177,TP,ACT,1.0	CHEMBL3408518,FN,ACT,0.0	CHEMBL672,TN,INACT,0.0	CHEMBL73096,TN,INACT,0.0	CHEMBL380054,TN,INACT,0.0	CHEMBL38521,TP,ACT,0.9900000095367432	CHEMBL2371340,TP,ACT,0.9900000095367432	CHEMBL25373,TN,INACT,0.009999999776482582	CHEMBL353876,TP,ACT,1.0	CHEMBL200199,TP,ACT,1.0	CHEMBL336033,TN,INACT,0.0	CHEMBL32202,TP,ACT,1.0	CHEMBL296328,TP,ACT,1.0	CHEMBL428803,TP,ACT,1.0	CHEMBL89457,TN,INACT,0.0	CHEMBL477,TN,INACT,0.0	CHEMBL307235,TP,ACT,1.0	CHEMBL286585,TP,ACT,1.0	CHEMBL104,TN,INACT,0.0	CHEMBL414605,TN,INACT,0.0	CHEMBL352965,TP,ACT,1.0	CHEMBL3350496,TN,INACT,0.0	CHEMBL305371,TN,INACT,0.0	CHEMBL48157,TP,ACT,1.0	CHEMBL1202433,TP,ACT,0.9900000095367432	CHEMBL304714,TN,INACT,0.0	CHEMBL242077,TP,ACT,1.0	CHEMBL319005,TN,INACT,0.0	CHEMBL127463,FN,ACT,0.27000001072883606	CHEMBL149592,TN,INACT,0.0	CHEMBL19982,TP,ACT,1.0	CHEMBL55948,TP,ACT,1.0	CHEMBL609744,TP,ACT,1.0	CHEMBL2370612,TP,ACT,1.0	CHEMBL150696,TN,INACT,0.0	CHEMBL1672485,TP,ACT,1.0	CHEMBL2372075,FP,INACT,1.0	CHEMBL170399,TP,ACT,1.0	CHEMBL269119,TP,ACT,1.0	CHEMBL46399,TP,ACT,0.9900000095367432	CHEMBL305313,TN,INACT,0.0	CHEMBL64406,TN,INACT,0.0	CHEMBL414570,FP,INACT,1.0	CHEMBL432974,TN,INACT,0.0	CHEMBL3264362,TP,ACT,1.0	CHEMBL3609615,FN,ACT,0.23999999463558197	CHEMBL295651,TN,INACT,0.009999999776482582	CHEMBL1797515,TP,ACT,1.0	CHEMBL477154,TP,ACT,1.0	CHEMBL303204,TN,INACT,0.0	CHEMBL136515,TP,ACT,1.0	CHEMBL2370165,TP,ACT,1.0	CHEMBL3604300,TN,INACT,0.0	CHEMBL2368320,TP,ACT,1.0	CHEMBL444307,TN,INACT,0.0	CHEMBL49507,TP,ACT,1.0	CHEMBL3613281,TP,ACT,1.0	CHEMBL441765,FN,ACT,0.07999999821186066	CHEMBL240001,TN,INACT,0.0	CHEMBL302150,TN,INACT,0.0	CHEMBL423341,TP,ACT,1.0	CHEMBL62948,TN,INACT,0.0	CHEMBL172493,TP,ACT,1.0	CHEMBL143416,TP,ACT,0.949999988079071	CHEMBL3093783,TP,ACT,1.0	CHEMBL392888,TN,INACT,0.009999999776482582	CHEMBL105665,TP,ACT,1.0	CHEMBL50284,FN,ACT,0.0	CHEMBL330003,TN,INACT,0.009999999776482582	CHEMBL2334773,FN,ACT,0.0	CHEMBL384248,TN,INACT,0.0	CHEMBL101396,FN,ACT,0.8100000023841858	CHEMBL335936,TP,ACT,0.9900000095367432	CHEMBL73164,TN,INACT,0.0	CHEMBL351531,TN,INACT,0.0	CHEMBL2398752,FP,INACT,0.9599999785423279	CHEMBL3617471,TP,ACT,1.0	CHEMBL3665435,TN,INACT,0.0	CHEMBL276676,FP,INACT,0.9700000286102295	CHEMBL1169580,TP,ACT,1.0	CHEMBL293951,TP,ACT,1.0	CHEMBL2179261,TP,ACT,1.0	CHEMBL2397389,TN,INACT,0.0	CHEMBL164968,TN,INACT,0.009999999776482582	CHEMBL72841,TN,INACT,0.0	CHEMBL2387338,TP,ACT,1.0	CHEMBL169536,TP,ACT,1.0	CHEMBL3350137,TP,ACT,1.0	CHEMBL2370631,TP,ACT,1.0	CHEMBL56208,TP,ACT,1.0	CHEMBL49106,TP,ACT,1.0	CHEMBL3753293,FP,INACT,0.9900000095367432	CHEMBL332471,TN,INACT,0.0	CHEMBL2367916,TP,ACT,1.0	CHEMBL95001,FN,ACT,0.009999999776482582	CHEMBL219407,TP,ACT,0.9700000286102295	CHEMBL608813,TN,INACT,0.0	CHEMBL300662,TP,ACT,1.0	CHEMBL3609621,TP,ACT,0.9900000095367432	CHEMBL508030,TN,INACT,0.0	CHEMBL168223,TN,INACT,0.0	CHEMBL544276,TP,ACT,0.9900000095367432	CHEMBL439898,TP,ACT,1.0	CHEMBL538308,TP,ACT,1.0	CHEMBL634,TP,ACT,1.0	CHEMBL261623,TN,INACT,0.0	CHEMBL102160,TP,ACT,1.0	CHEMBL3218124,TN,INACT,0.0	CHEMBL1091778,TN,INACT,0.0	CHEMBL423666,TN,INACT,0.0	CHEMBL3290991,TN,INACT,0.0	CHEMBL339552,FN,ACT,0.17000000178813934	CHEMBL148843,FN,ACT,0.0	CHEMBL415339,TP,ACT,1.0	CHEMBL2207677,TP,ACT,1.0	CHEMBL170384,TP,ACT,1.0	CHEMBL279520,TN,INACT,0.0	CHEMBL114074,TN,INACT,0.0	CHEMBL383805,TN,INACT,0.0	CHEMBL19808,TN,INACT,0.0	CHEMBL33224,TN,INACT,0.0	CHEMBL408360,TP,ACT,1.0	CHEMBL283552,FN,ACT,0.4399999976158142	CHEMBL217597,TP,ACT,0.8299999833106995	CHEMBL538700,TP,ACT,1.0	CHEMBL146983,FP,INACT,0.9700000286102295	CHEMBL469046,TP,ACT,1.0	CHEMBL149611,TP,ACT,0.8799999952316284	CHEMBL425806,TP,ACT,1.0	CHEMBL415224,TP,ACT,1.0	CHEMBL39211,TP,ACT,1.0	CHEMBL2372393,TP,ACT,0.9700000286102295	CHEMBL2436719,TN,INACT,0.0	CHEMBL291394,TN,INACT,0.0	CHEMBL1223831,TP,ACT,1.0	CHEMBL384497,TP,ACT,1.0	CHEMBL3613163,TP,ACT,1.0	CHEMBL396271,TN,INACT,0.0	CHEMBL103828,TN,INACT,0.0	CHEMBL143939,TP,ACT,0.9900000095367432	CHEMBL2334776,TP,ACT,1.0	CHEMBL142811,TN,INACT,0.0	CHEMBL143761,TN,INACT,0.0	CHEMBL2370618,TP,ACT,1.0	CHEMBL452150,TN,INACT,0.0	CHEMBL130272,TP,ACT,0.9200000166893005	CHEMBL524026,FP,INACT,1.0	CHEMBL2112488,FP,INACT,1.0	CHEMBL343969,TN,INACT,0.0	CHEMBL422959,TN,INACT,0.0	CHEMBL359088,FN,ACT,0.0	CHEMBL165462,TN,INACT,0.0	CHEMBL302359,TN,INACT,0.0	CHEMBL297567,TP,ACT,1.0	CHEMBL323951,TN,INACT,0.0	CHEMBL53842,TN,INACT,0.05000000074505806	CHEMBL2436712,TN,INACT,0.0	CHEMBL88629,TN,INACT,0.0	CHEMBL166736,TN,INACT,0.0	CHEMBL344154,TN,INACT,0.0	CHEMBL3408522,FN,ACT,0.0	CHEMBL2079569,TP,ACT,0.9900000095367432	CHEMBL284965,TN,INACT,0.0	CHEMBL1927443,TN,INACT,0.0	CHEMBL293232,TN,INACT,0.0	CHEMBL40796,TN,INACT,0.009999999776482582	CHEMBL100940,TP,ACT,1.0	CHEMBL414713,TP,ACT,1.0	CHEMBL420995,TP,ACT,1.0	CHEMBL197159,TN,INACT,0.0	CHEMBL301835,TP,ACT,1.0	CHEMBL1083953,TP,ACT,1.0	CHEMBL21328,TN,INACT,0.0	CHEMBL1672486,TP,ACT,1.0	CHEMBL352827,TP,ACT,1.0	CHEMBL435898,TP,ACT,0.8700000047683716	CHEMBL1834624,FP,INACT,0.8600000143051147	CHEMBL300725,TN,INACT,0.0	CHEMBL327885,TP,ACT,1.0	CHEMBL281140,TP,ACT,1.0	CHEMBL154068,TN,INACT,0.5799999833106995	CHEMBL279430,TP,ACT,1.0	CHEMBL280958,TP,ACT,1.0	CHEMBL145584,TN,INACT,0.0	CHEMBL3290975,TN,INACT,0.0	CHEMBL412580,TP,ACT,1.0	CHEMBL131034,FN,ACT,0.009999999776482582	CHEMBL1672480,TP,ACT,1.0	CHEMBL3236672,TP,ACT,1.0	CHEMBL62115,TN,INACT,0.0	CHEMBL2111857,TP,ACT,1.0	CHEMBL168392,TP,ACT,1.0	CHEMBL2372076,TN,INACT,0.0	CHEMBL78601,TN,INACT,0.0	CHEMBL610018,TP,ACT,1.0	CHEMBL60444,TP,ACT,1.0	CHEMBL594802,TN,INACT,0.0	

