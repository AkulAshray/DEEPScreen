ImageNetInceptionV2 CHEMBL5067 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	232
Number of inactive compounds :	232
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5067_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5067_adam_0.0005_15_0.8/
---------------------------------
Training samples: 289
Validation samples: 91
--
Training Step: 1  | time: 37.861s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/289
[A[ATraining Step: 2  | total loss: [1m[32m0.63023[0m[0m | time: 48.963s
[2K
| Adam | epoch: 001 | loss: 0.63023 - acc: 0.4500 -- iter: 064/289
[A[ATraining Step: 3  | total loss: [1m[32m0.66220[0m[0m | time: 58.476s
[2K
| Adam | epoch: 001 | loss: 0.66220 - acc: 0.6443 -- iter: 096/289
[A[ATraining Step: 4  | total loss: [1m[32m0.66008[0m[0m | time: 67.865s
[2K
| Adam | epoch: 001 | loss: 0.66008 - acc: 0.6298 -- iter: 128/289
[A[ATraining Step: 5  | total loss: [1m[32m0.39728[0m[0m | time: 79.044s
[2K
| Adam | epoch: 001 | loss: 0.39728 - acc: 0.8645 -- iter: 160/289
[A[ATraining Step: 6  | total loss: [1m[32m0.45529[0m[0m | time: 88.907s
[2K
| Adam | epoch: 001 | loss: 0.45529 - acc: 0.8311 -- iter: 192/289
[A[ATraining Step: 7  | total loss: [1m[32m0.63757[0m[0m | time: 98.753s
[2K
| Adam | epoch: 001 | loss: 0.63757 - acc: 0.7262 -- iter: 224/289
[A[ATraining Step: 8  | total loss: [1m[32m0.55678[0m[0m | time: 107.660s
[2K
| Adam | epoch: 001 | loss: 0.55678 - acc: 0.7747 -- iter: 256/289
[A[ATraining Step: 9  | total loss: [1m[32m0.54449[0m[0m | time: 116.867s
[2K
| Adam | epoch: 001 | loss: 0.54449 - acc: 0.7451 -- iter: 288/289
[A[ATraining Step: 10  | total loss: [1m[32m0.51855[0m[0m | time: 127.368s
[2K
| Adam | epoch: 001 | loss: 0.51855 - acc: 0.7632 | val_loss: 4.45338 - val_acc: 0.4615 -- iter: 289/289
--
Training Step: 11  | total loss: [1m[32m0.55642[0m[0m | time: 0.640s
[2K
| Adam | epoch: 002 | loss: 0.55642 - acc: 0.8754 -- iter: 032/289
[A[ATraining Step: 12  | total loss: [1m[32m0.53424[0m[0m | time: 14.247s
[2K
| Adam | epoch: 002 | loss: 0.53424 - acc: 0.9314 -- iter: 064/289
[A[ATraining Step: 13  | total loss: [1m[32m0.43105[0m[0m | time: 25.489s
[2K
| Adam | epoch: 002 | loss: 0.43105 - acc: 0.9340 -- iter: 096/289
[A[ATraining Step: 14  | total loss: [1m[32m0.41923[0m[0m | time: 37.013s
[2K
| Adam | epoch: 002 | loss: 0.41923 - acc: 0.8843 -- iter: 128/289
[A[ATraining Step: 15  | total loss: [1m[32m0.38990[0m[0m | time: 51.529s
[2K
| Adam | epoch: 002 | loss: 0.38990 - acc: 0.8807 -- iter: 160/289
[A[ATraining Step: 16  | total loss: [1m[32m0.49270[0m[0m | time: 62.561s
[2K
| Adam | epoch: 002 | loss: 0.49270 - acc: 0.8434 -- iter: 192/289
[A[ATraining Step: 17  | total loss: [1m[32m0.40854[0m[0m | time: 76.591s
[2K
| Adam | epoch: 002 | loss: 0.40854 - acc: 0.8660 -- iter: 224/289
[A[ATraining Step: 18  | total loss: [1m[32m0.34012[0m[0m | time: 86.267s
[2K
| Adam | epoch: 002 | loss: 0.34012 - acc: 0.8908 -- iter: 256/289
[A[ATraining Step: 19  | total loss: [1m[32m0.29451[0m[0m | time: 96.662s
[2K
| Adam | epoch: 002 | loss: 0.29451 - acc: 0.8959 -- iter: 288/289
[A[ATraining Step: 20  | total loss: [1m[32m0.33833[0m[0m | time: 110.384s
[2K
| Adam | epoch: 002 | loss: 0.33833 - acc: 0.8992 | val_loss: 4.00323 - val_acc: 0.4615 -- iter: 289/289
--
Training Step: 21  | total loss: [1m[32m0.34634[0m[0m | time: 0.649s
[2K
| Adam | epoch: 003 | loss: 0.34634 - acc: 0.8820 -- iter: 032/289
[A[ATraining Step: 22  | total loss: [1m[32m0.35678[0m[0m | time: 1.244s
[2K
| Adam | epoch: 003 | loss: 0.35678 - acc: 0.9174 -- iter: 064/289
[A[ATraining Step: 23  | total loss: [1m[32m0.33903[0m[0m | time: 11.692s
[2K
| Adam | epoch: 003 | loss: 0.33903 - acc: 0.9414 -- iter: 096/289
[A[ATraining Step: 24  | total loss: [1m[32m0.29617[0m[0m | time: 23.223s
[2K
| Adam | epoch: 003 | loss: 0.29617 - acc: 0.9227 -- iter: 128/289
[A[ATraining Step: 25  | total loss: [1m[32m0.24470[0m[0m | time: 34.096s
[2K
| Adam | epoch: 003 | loss: 0.24470 - acc: 0.9353 -- iter: 160/289
[A[ATraining Step: 26  | total loss: [1m[32m0.20499[0m[0m | time: 48.137s
[2K
| Adam | epoch: 003 | loss: 0.20499 - acc: 0.9441 -- iter: 192/289
[A[ATraining Step: 27  | total loss: [1m[32m0.20833[0m[0m | time: 60.131s
[2K
| Adam | epoch: 003 | loss: 0.20833 - acc: 0.9424 -- iter: 224/289
[A[ATraining Step: 28  | total loss: [1m[32m0.18221[0m[0m | time: 70.953s
[2K
| Adam | epoch: 003 | loss: 0.18221 - acc: 0.9490 -- iter: 256/289
[A[ATraining Step: 29  | total loss: [1m[32m0.20647[0m[0m | time: 85.751s
[2K
| Adam | epoch: 003 | loss: 0.20647 - acc: 0.9386 -- iter: 288/289
[A[ATraining Step: 30  | total loss: [1m[32m0.18436[0m[0m | time: 100.908s
[2K
| Adam | epoch: 003 | loss: 0.18436 - acc: 0.9457 | val_loss: 1.52818 - val_acc: 0.5385 -- iter: 289/289
--
Training Step: 31  | total loss: [1m[32m0.19113[0m[0m | time: 42.153s
[2K
| Adam | epoch: 004 | loss: 0.19113 - acc: 0.9366 -- iter: 032/289
[A[ATraining Step: 32  | total loss: [1m[32m0.21884[0m[0m | time: 42.912s
[2K
| Adam | epoch: 004 | loss: 0.21884 - acc: 0.9298 -- iter: 064/289
[A[ATraining Step: 33  | total loss: [1m[32m0.20808[0m[0m | time: 43.679s
[2K
| Adam | epoch: 004 | loss: 0.20808 - acc: 0.9452 -- iter: 096/289
[A[ATraining Step: 34  | total loss: [1m[32m0.59417[0m[0m | time: 79.468s
[2K
| Adam | epoch: 004 | loss: 0.59417 - acc: 0.7427 -- iter: 128/289
[A[ATraining Step: 35  | total loss: [1m[32m0.52932[0m[0m | time: 99.052s
[2K
| Adam | epoch: 004 | loss: 0.52932 - acc: 0.7704 -- iter: 160/289
[A[ATraining Step: 36  | total loss: [1m[32m0.53855[0m[0m | time: 123.334s
[2K
| Adam | epoch: 004 | loss: 0.53855 - acc: 0.7918 -- iter: 192/289
[A[ATraining Step: 37  | total loss: [1m[32m0.45432[0m[0m | time: 147.632s
[2K
| Adam | epoch: 004 | loss: 0.45432 - acc: 0.8272 -- iter: 224/289
[A[ATraining Step: 38  | total loss: [1m[32m0.42984[0m[0m | time: 176.238s
[2K
| Adam | epoch: 004 | loss: 0.42984 - acc: 0.8304 -- iter: 256/289
[A[ATraining Step: 39  | total loss: [1m[32m0.40834[0m[0m | time: 204.215s
[2K
| Adam | epoch: 004 | loss: 0.40834 - acc: 0.8389 -- iter: 288/289
[A[ATraining Step: 40  | total loss: [1m[32m0.35216[0m[0m | time: 223.642s
[2K
| Adam | epoch: 004 | loss: 0.35216 - acc: 0.8633 | val_loss: 1.61428 - val_acc: 0.5824 -- iter: 289/289
--
Training Step: 41  | total loss: [1m[32m0.30301[0m[0m | time: 23.519s
[2K
| Adam | epoch: 005 | loss: 0.30301 - acc: 0.8827 -- iter: 032/289
[A[ATraining Step: 42  | total loss: [1m[32m0.26283[0m[0m | time: 40.535s
[2K
| Adam | epoch: 005 | loss: 0.26283 - acc: 0.8982 -- iter: 064/289
[A[ATraining Step: 43  | total loss: [1m[32m0.22701[0m[0m | time: 41.300s
[2K
| Adam | epoch: 005 | loss: 0.22701 - acc: 0.9161 -- iter: 096/289
[A[ATraining Step: 44  | total loss: [1m[32m0.49292[0m[0m | time: 42.061s
[2K
| Adam | epoch: 005 | loss: 0.49292 - acc: 0.7576 -- iter: 128/289
[A[ATraining Step: 45  | total loss: [1m[32m0.46179[0m[0m | time: 55.484s
[2K
| Adam | epoch: 005 | loss: 0.46179 - acc: 0.7987 -- iter: 160/289
[A[ATraining Step: 46  | total loss: [1m[32m0.40549[0m[0m | time: 66.925s
[2K
| Adam | epoch: 005 | loss: 0.40549 - acc: 0.8219 -- iter: 192/289
[A[ATraining Step: 47  | total loss: [1m[32m0.40306[0m[0m | time: 82.827s
[2K
| Adam | epoch: 005 | loss: 0.40306 - acc: 0.8357 -- iter: 224/289
[A[ATraining Step: 48  | total loss: [1m[32m0.37131[0m[0m | time: 96.760s
[2K
| Adam | epoch: 005 | loss: 0.37131 - acc: 0.8470 -- iter: 256/289
[A[ATraining Step: 49  | total loss: [1m[32m0.33645[0m[0m | time: 112.528s
[2K
| Adam | epoch: 005 | loss: 0.33645 - acc: 0.8613 -- iter: 288/289
[A[ATraining Step: 50  | total loss: [1m[32m0.30069[0m[0m | time: 135.745s
[2K
| Adam | epoch: 005 | loss: 0.30069 - acc: 0.8731 | val_loss: 3.55368 - val_acc: 0.5385 -- iter: 289/289
--
Training Step: 51  | total loss: [1m[32m0.32356[0m[0m | time: 16.335s
[2K
| Adam | epoch: 006 | loss: 0.32356 - acc: 0.8591 -- iter: 032/289
[A[ATraining Step: 52  | total loss: [1m[32m0.28381[0m[0m | time: 35.667s
[2K
| Adam | epoch: 006 | loss: 0.28381 - acc: 0.8802 -- iter: 064/289
[A[ATraining Step: 53  | total loss: [1m[32m0.28823[0m[0m | time: 48.660s
[2K
| Adam | epoch: 006 | loss: 0.28823 - acc: 0.8841 -- iter: 096/289
[A[ATraining Step: 54  | total loss: [1m[32m0.25841[0m[0m | time: 49.317s
[2K
| Adam | epoch: 006 | loss: 0.25841 - acc: 0.8964 -- iter: 128/289
[A[ATraining Step: 55  | total loss: [1m[32m0.26033[0m[0m | time: 50.035s
[2K
| Adam | epoch: 006 | loss: 0.26033 - acc: 0.9112 -- iter: 160/289
[A[ATraining Step: 56  | total loss: [1m[32m0.25594[0m[0m | time: 64.723s
[2K
| Adam | epoch: 006 | loss: 0.25594 - acc: 0.9237 -- iter: 192/289
[A[ATraining Step: 57  | total loss: [1m[32m0.22917[0m[0m | time: 82.581s
[2K
| Adam | epoch: 006 | loss: 0.22917 - acc: 0.9256 -- iter: 224/289
[A[ATraining Step: 58  | total loss: [1m[32m0.20788[0m[0m | time: 98.018s
[2K
| Adam | epoch: 006 | loss: 0.20788 - acc: 0.9315 -- iter: 256/289
[A[ATraining Step: 59  | total loss: [1m[32m0.19214[0m[0m | time: 110.026s
[2K
| Adam | epoch: 006 | loss: 0.19214 - acc: 0.9365 -- iter: 288/289
[A[ATraining Step: 60  | total loss: [1m[32m0.18404[0m[0m | time: 129.504s
[2K
| Adam | epoch: 006 | loss: 0.18404 - acc: 0.9407 | val_loss: 0.39210 - val_acc: 0.8462 -- iter: 289/289
--
Training Step: 61  | total loss: [1m[32m0.16345[0m[0m | time: 17.162s
[2K
| Adam | epoch: 007 | loss: 0.16345 - acc: 0.9485 -- iter: 032/289
[A[ATraining Step: 62  | total loss: [1m[32m0.14964[0m[0m | time: 45.165s
[2K
| Adam | epoch: 007 | loss: 0.14964 - acc: 0.9551 -- iter: 064/289
[A[ATraining Step: 63  | total loss: [1m[32m0.13544[0m[0m | time: 54.094s
[2K
| Adam | epoch: 007 | loss: 0.13544 - acc: 0.9608 -- iter: 096/289
[A[ATraining Step: 64  | total loss: [1m[32m0.12785[0m[0m | time: 62.653s
[2K
| Adam | epoch: 007 | loss: 0.12785 - acc: 0.9618 -- iter: 128/289
[A[ATraining Step: 65  | total loss: [1m[32m0.11945[0m[0m | time: 63.274s
[2K
| Adam | epoch: 007 | loss: 0.11945 - acc: 0.9665 -- iter: 160/289
[A[ATraining Step: 66  | total loss: [1m[32m0.11630[0m[0m | time: 63.862s
[2K
| Adam | epoch: 007 | loss: 0.11630 - acc: 0.9706 -- iter: 192/289
[A[ATraining Step: 67  | total loss: [1m[32m0.38642[0m[0m | time: 72.278s
[2K
| Adam | epoch: 007 | loss: 0.38642 - acc: 0.8541 -- iter: 224/289
[A[ATraining Step: 68  | total loss: [1m[32m0.34897[0m[0m | time: 80.979s
[2K
| Adam | epoch: 007 | loss: 0.34897 - acc: 0.8677 -- iter: 256/289
[A[ATraining Step: 69  | total loss: [1m[32m0.31417[0m[0m | time: 89.938s
[2K
| Adam | epoch: 007 | loss: 0.31417 - acc: 0.8795 -- iter: 288/289
[A[ATraining Step: 70  | total loss: [1m[32m0.28017[0m[0m | time: 102.645s
[2K
| Adam | epoch: 007 | loss: 0.28017 - acc: 0.8934 | val_loss: 0.38322 - val_acc: 0.8462 -- iter: 289/289
--
Training Step: 71  | total loss: [1m[32m0.24982[0m[0m | time: 10.334s
[2K
| Adam | epoch: 008 | loss: 0.24982 - acc: 0.9055 -- iter: 032/289
[A[ATraining Step: 72  | total loss: [1m[32m0.22233[0m[0m | time: 25.762s
[2K
| Adam | epoch: 008 | loss: 0.22233 - acc: 0.9162 -- iter: 064/289
[A[ATraining Step: 73  | total loss: [1m[32m0.20242[0m[0m | time: 34.627s
[2K
| Adam | epoch: 008 | loss: 0.20242 - acc: 0.9220 -- iter: 096/289
[A[ATraining Step: 74  | total loss: [1m[32m0.20557[0m[0m | time: 43.571s
[2K
| Adam | epoch: 008 | loss: 0.20557 - acc: 0.9203 -- iter: 128/289
[A[ATraining Step: 75  | total loss: [1m[32m0.20877[0m[0m | time: 52.264s
[2K
| Adam | epoch: 008 | loss: 0.20877 - acc: 0.9221 -- iter: 160/289
[A[ATraining Step: 76  | total loss: [1m[32m0.18954[0m[0m | time: 52.873s
[2K
| Adam | epoch: 008 | loss: 0.18954 - acc: 0.9305 -- iter: 192/289
[A[ATraining Step: 77  | total loss: [1m[32m0.39706[0m[0m | time: 53.461s
[2K
| Adam | epoch: 008 | loss: 0.39706 - acc: 0.8320 -- iter: 224/289
[A[ATraining Step: 78  | total loss: [1m[32m0.53095[0m[0m | time: 66.648s
[2K
| Adam | epoch: 008 | loss: 0.53095 - acc: 0.7449 -- iter: 256/289
[A[ATraining Step: 79  | total loss: [1m[32m0.47643[0m[0m | time: 75.409s
[2K
| Adam | epoch: 008 | loss: 0.47643 - acc: 0.7713 -- iter: 288/289
[A[ATraining Step: 80  | total loss: [1m[32m0.48708[0m[0m | time: 101.712s
[2K
| Adam | epoch: 008 | loss: 0.48708 - acc: 0.7723 | val_loss: 0.38450 - val_acc: 0.8791 -- iter: 289/289
--
Training Step: 81  | total loss: [1m[32m0.44358[0m[0m | time: 106.120s
[2K
| Adam | epoch: 009 | loss: 0.44358 - acc: 0.7922 -- iter: 032/289
[A[ATraining Step: 82  | total loss: [1m[32m0.41100[0m[0m | time: 174.806s
[2K
| Adam | epoch: 009 | loss: 0.41100 - acc: 0.8067 -- iter: 064/289
[A[ATraining Step: 83  | total loss: [1m[32m0.37375[0m[0m | time: 283.957s
[2K
| Adam | epoch: 009 | loss: 0.37375 - acc: 0.8260 -- iter: 096/289
[A[ATraining Step: 84  | total loss: [1m[32m0.33742[0m[0m | time: 416.054s
[2K
| Adam | epoch: 009 | loss: 0.33742 - acc: 0.8434 -- iter: 128/289
[A[ATraining Step: 85  | total loss: [1m[32m0.30586[0m[0m | time: 426.203s
[2K
| Adam | epoch: 009 | loss: 0.30586 - acc: 0.8591 -- iter: 160/289
[A[ATraining Step: 86  | total loss: [1m[32m0.28143[0m[0m | time: 435.071s
[2K
| Adam | epoch: 009 | loss: 0.28143 - acc: 0.8732 -- iter: 192/289
[A[ATraining Step: 87  | total loss: [1m[32m0.26250[0m[0m | time: 435.676s
[2K
| Adam | epoch: 009 | loss: 0.26250 - acc: 0.8827 -- iter: 224/289
[A[ATraining Step: 88  | total loss: [1m[32m0.32882[0m[0m | time: 436.277s
[2K
| Adam | epoch: 009 | loss: 0.32882 - acc: 0.7945 -- iter: 256/289
[A[ATraining Step: 89  | total loss: [1m[32m0.37865[0m[0m | time: 445.239s
[2K
| Adam | epoch: 009 | loss: 0.37865 - acc: 0.7150 -- iter: 288/289
[A[ATraining Step: 90  | total loss: [1m[32m0.34504[0m[0m | time: 458.620s
[2K
| Adam | epoch: 009 | loss: 0.34504 - acc: 0.7404 | val_loss: 2.97955 - val_acc: 0.4835 -- iter: 289/289
--
Training Step: 91  | total loss: [1m[32m0.32376[0m[0m | time: 8.834s
[2K
| Adam | epoch: 010 | loss: 0.32376 - acc: 0.7601 -- iter: 032/289
[A[ATraining Step: 92  | total loss: [1m[32m0.29260[0m[0m | time: 17.671s
[2K
| Adam | epoch: 010 | loss: 0.29260 - acc: 0.7841 -- iter: 064/289
[A[ATraining Step: 93  | total loss: [1m[32m0.26696[0m[0m | time: 26.741s
[2K
| Adam | epoch: 010 | loss: 0.26696 - acc: 0.8057 -- iter: 096/289
[A[ATraining Step: 94  | total loss: [1m[32m0.24767[0m[0m | time: 35.453s
[2K
| Adam | epoch: 010 | loss: 0.24767 - acc: 0.8220 -- iter: 128/289
[A[ATraining Step: 95  | total loss: [1m[32m0.22667[0m[0m | time: 44.181s
[2K
| Adam | epoch: 010 | loss: 0.22667 - acc: 0.8398 -- iter: 160/289
[A[ATraining Step: 96  | total loss: [1m[32m0.22464[0m[0m | time: 53.233s
[2K
| Adam | epoch: 010 | loss: 0.22464 - acc: 0.8496 -- iter: 192/289
[A[ATraining Step: 97  | total loss: [1m[32m0.20365[0m[0m | time: 61.784s
[2K
| Adam | epoch: 010 | loss: 0.20365 - acc: 0.8646 -- iter: 224/289
[A[ATraining Step: 98  | total loss: [1m[32m0.19837[0m[0m | time: 62.356s
[2K
| Adam | epoch: 010 | loss: 0.19837 - acc: 0.8719 -- iter: 256/289
[A[ATraining Step: 99  | total loss: [1m[32m0.21491[0m[0m | time: 62.944s
[2K
| Adam | epoch: 010 | loss: 0.21491 - acc: 0.8847 -- iter: 288/289
[A[ATraining Step: 100  | total loss: [1m[32m0.21606[0m[0m | time: 76.130s
[2K
| Adam | epoch: 010 | loss: 0.21606 - acc: 0.8962 | val_loss: 5.63761 - val_acc: 0.5385 -- iter: 289/289
--
Training Step: 101  | total loss: [1m[32m0.21807[0m[0m | time: 8.793s
[2K
| Adam | epoch: 011 | loss: 0.21807 - acc: 0.9004 -- iter: 032/289
[A[ATraining Step: 102  | total loss: [1m[32m0.20724[0m[0m | time: 17.769s
[2K
| Adam | epoch: 011 | loss: 0.20724 - acc: 0.9009 -- iter: 064/289
[A[ATraining Step: 103  | total loss: [1m[32m0.19065[0m[0m | time: 26.659s
[2K
| Adam | epoch: 011 | loss: 0.19065 - acc: 0.9109 -- iter: 096/289
[A[ATraining Step: 104  | total loss: [1m[32m0.17892[0m[0m | time: 35.229s
[2K
| Adam | epoch: 011 | loss: 0.17892 - acc: 0.9166 -- iter: 128/289
[A[ATraining Step: 105  | total loss: [1m[32m0.17922[0m[0m | time: 43.984s
[2K
| Adam | epoch: 011 | loss: 0.17922 - acc: 0.9219 -- iter: 160/289
[A[ATraining Step: 106  | total loss: [1m[32m0.16743[0m[0m | time: 52.896s
[2K
| Adam | epoch: 011 | loss: 0.16743 - acc: 0.9265 -- iter: 192/289
[A[ATraining Step: 107  | total loss: [1m[32m0.16692[0m[0m | time: 61.988s
[2K
| Adam | epoch: 011 | loss: 0.16692 - acc: 0.9245 -- iter: 224/289
[A[ATraining Step: 108  | total loss: [1m[32m0.15540[0m[0m | time: 70.402s
[2K
| Adam | epoch: 011 | loss: 0.15540 - acc: 0.9289 -- iter: 256/289
[A[ATraining Step: 109  | total loss: [1m[32m0.14442[0m[0m | time: 70.979s
[2K
| Adam | epoch: 011 | loss: 0.14442 - acc: 0.9360 -- iter: 288/289
[A[ATraining Step: 110  | total loss: [1m[32m0.13761[0m[0m | time: 75.788s
[2K
| Adam | epoch: 011 | loss: 0.13761 - acc: 0.9424 | val_loss: 1.48827 - val_acc: 0.7033 -- iter: 289/289
--
Training Step: 111  | total loss: [1m[32m0.13385[0m[0m | time: 8.642s
[2K
| Adam | epoch: 012 | loss: 0.13385 - acc: 0.9482 -- iter: 032/289
[A[ATraining Step: 112  | total loss: [1m[32m0.13295[0m[0m | time: 17.407s
[2K
| Adam | epoch: 012 | loss: 0.13295 - acc: 0.9503 -- iter: 064/289
[A[ATraining Step: 113  | total loss: [1m[32m0.12192[0m[0m | time: 26.157s
[2K
| Adam | epoch: 012 | loss: 0.12192 - acc: 0.9552 -- iter: 096/289
[A[ATraining Step: 114  | total loss: [1m[32m0.12214[0m[0m | time: 34.482s
[2K
| Adam | epoch: 012 | loss: 0.12214 - acc: 0.9566 -- iter: 128/289
[A[ATraining Step: 115  | total loss: [1m[32m0.12456[0m[0m | time: 43.432s
[2K
| Adam | epoch: 012 | loss: 0.12456 - acc: 0.9515 -- iter: 160/289
[A[ATraining Step: 116  | total loss: [1m[32m0.11231[0m[0m | time: 52.136s
[2K
| Adam | epoch: 012 | loss: 0.11231 - acc: 0.9564 -- iter: 192/289
[A[ATraining Step: 117  | total loss: [1m[32m0.10613[0m[0m | time: 61.083s
[2K
| Adam | epoch: 012 | loss: 0.10613 - acc: 0.9576 -- iter: 224/289
[A[ATraining Step: 118  | total loss: [1m[32m0.10745[0m[0m | time: 70.044s
[2K
| Adam | epoch: 012 | loss: 0.10745 - acc: 0.9587 -- iter: 256/289
[A[ATraining Step: 119  | total loss: [1m[32m0.10765[0m[0m | time: 78.852s
[2K
| Adam | epoch: 012 | loss: 0.10765 - acc: 0.9597 -- iter: 288/289
[A[ATraining Step: 120  | total loss: [1m[32m0.10481[0m[0m | time: 83.764s
[2K
| Adam | epoch: 012 | loss: 0.10481 - acc: 0.9606 | val_loss: 2.08608 - val_acc: 0.6703 -- iter: 289/289
--
Training Step: 121  | total loss: [1m[32m0.10361[0m[0m | time: 0.587s
[2K
| Adam | epoch: 013 | loss: 0.10361 - acc: 0.9646 -- iter: 032/289
[A[ATraining Step: 122  | total loss: [1m[32m0.10400[0m[0m | time: 9.093s
[2K
| Adam | epoch: 013 | loss: 0.10400 - acc: 0.9681 -- iter: 064/289
[A[ATraining Step: 123  | total loss: [1m[32m0.10318[0m[0m | time: 18.243s
[2K
| Adam | epoch: 013 | loss: 0.10318 - acc: 0.9682 -- iter: 096/289
[A[ATraining Step: 124  | total loss: [1m[32m0.09297[0m[0m | time: 26.695s
[2K
| Adam | epoch: 013 | loss: 0.09297 - acc: 0.9714 -- iter: 128/289
[A[ATraining Step: 125  | total loss: [1m[32m0.08696[0m[0m | time: 35.401s
[2K
| Adam | epoch: 013 | loss: 0.08696 - acc: 0.9742 -- iter: 160/289
[A[ATraining Step: 126  | total loss: [1m[32m0.10070[0m[0m | time: 44.221s
[2K
| Adam | epoch: 013 | loss: 0.10070 - acc: 0.9643 -- iter: 192/289
[A[ATraining Step: 127  | total loss: [1m[32m0.12522[0m[0m | time: 53.116s
[2K
| Adam | epoch: 013 | loss: 0.12522 - acc: 0.9585 -- iter: 224/289
[A[ATraining Step: 128  | total loss: [1m[32m0.11636[0m[0m | time: 61.876s
[2K
| Adam | epoch: 013 | loss: 0.11636 - acc: 0.9626 -- iter: 256/289
[A[ATraining Step: 129  | total loss: [1m[32m0.12562[0m[0m | time: 70.933s
[2K
| Adam | epoch: 013 | loss: 0.12562 - acc: 0.9601 -- iter: 288/289
[A[ATraining Step: 130  | total loss: [1m[32m0.12256[0m[0m | time: 83.999s
[2K
| Adam | epoch: 013 | loss: 0.12256 - acc: 0.9579 | val_loss: 1.49514 - val_acc: 0.5824 -- iter: 289/289
--
Training Step: 131  | total loss: [1m[32m0.11342[0m[0m | time: 0.593s
[2K
| Adam | epoch: 014 | loss: 0.11342 - acc: 0.9621 -- iter: 032/289
[A[ATraining Step: 132  | total loss: [1m[32m0.11030[0m[0m | time: 1.168s
[2K
| Adam | epoch: 014 | loss: 0.11030 - acc: 0.9659 -- iter: 064/289
[A[ATraining Step: 133  | total loss: [1m[32m0.10892[0m[0m | time: 17.104s
[2K
| Adam | epoch: 014 | loss: 0.10892 - acc: 0.9693 -- iter: 096/289
[A[ATraining Step: 134  | total loss: [1m[32m0.11102[0m[0m | time: 25.921s
[2K
| Adam | epoch: 014 | loss: 0.11102 - acc: 0.9692 -- iter: 128/289
[A[ATraining Step: 135  | total loss: [1m[32m0.10068[0m[0m | time: 34.689s
[2K
| Adam | epoch: 014 | loss: 0.10068 - acc: 0.9723 -- iter: 160/289
[A[ATraining Step: 136  | total loss: [1m[32m0.09222[0m[0m | time: 43.676s
[2K
| Adam | epoch: 014 | loss: 0.09222 - acc: 0.9751 -- iter: 192/289
[A[ATraining Step: 137  | total loss: [1m[32m0.08531[0m[0m | time: 52.159s
[2K
| Adam | epoch: 014 | loss: 0.08531 - acc: 0.9776 -- iter: 224/289
[A[ATraining Step: 138  | total loss: [1m[32m0.08680[0m[0m | time: 61.332s
[2K
| Adam | epoch: 014 | loss: 0.08680 - acc: 0.9767 -- iter: 256/289
[A[ATraining Step: 139  | total loss: [1m[32m0.09473[0m[0m | time: 70.157s
[2K
| Adam | epoch: 014 | loss: 0.09473 - acc: 0.9728 -- iter: 288/289
[A[ATraining Step: 140  | total loss: [1m[32m0.08946[0m[0m | time: 83.710s
[2K
| Adam | epoch: 014 | loss: 0.08946 - acc: 0.9755 | val_loss: 0.32590 - val_acc: 0.8571 -- iter: 289/289
--
Training Step: 141  | total loss: [1m[32m0.08275[0m[0m | time: 95.297s
[2K
| Adam | epoch: 015 | loss: 0.08275 - acc: 0.9779 -- iter: 032/289
[A[ATraining Step: 142  | total loss: [1m[32m0.07694[0m[0m | time: 95.869s
[2K
| Adam | epoch: 015 | loss: 0.07694 - acc: 0.9801 -- iter: 064/289
[A[ATraining Step: 143  | total loss: [1m[32m0.07942[0m[0m | time: 96.445s
[2K
| Adam | epoch: 015 | loss: 0.07942 - acc: 0.9821 -- iter: 096/289
[A[ATraining Step: 144  | total loss: [1m[32m0.31197[0m[0m | time: 224.013s
[2K
| Adam | epoch: 015 | loss: 0.31197 - acc: 0.8839 -- iter: 128/289
[A[ATraining Step: 145  | total loss: [1m[32m0.28227[0m[0m | time: 270.717s
[2K
| Adam | epoch: 015 | loss: 0.28227 - acc: 0.8955 -- iter: 160/289
[A[ATraining Step: 146  | total loss: [1m[32m0.26410[0m[0m | time: 372.990s
[2K
| Adam | epoch: 015 | loss: 0.26410 - acc: 0.9029 -- iter: 192/289
[A[ATraining Step: 147  | total loss: [1m[32m0.24255[0m[0m | time: 450.765s
[2K
| Adam | epoch: 015 | loss: 0.24255 - acc: 0.9094 -- iter: 224/289
[A[ATraining Step: 148  | total loss: [1m[32m0.22196[0m[0m | time: 507.394s
[2K
| Adam | epoch: 015 | loss: 0.22196 - acc: 0.9154 -- iter: 256/289
[A[ATraining Step: 149  | total loss: [1m[32m0.21101[0m[0m | time: 516.254s
[2K
| Adam | epoch: 015 | loss: 0.21101 - acc: 0.9207 -- iter: 288/289
[A[ATraining Step: 150  | total loss: [1m[32m0.19049[0m[0m | time: 529.643s
[2K
| Adam | epoch: 015 | loss: 0.19049 - acc: 0.9286 | val_loss: 2.52071 - val_acc: 0.7253 -- iter: 289/289
--
Validation AUC:0.9132653061224489
Validation AUPRC:0.8525525487683931
Test AUC:0.9487922705314009
Test AUPRC:0.9269937055328755
BestTestF1Score	0.85	0.7	0.84	0.76	0.98	44	14	32	1	1.0
BestTestMCCScore	0.85	0.7	0.84	0.76	0.98	44	14	32	1	1.0
BestTestAccuracyScore	0.85	0.7	0.84	0.76	0.98	44	14	32	1	1.0
BestValidationF1Score	0.82	0.64	0.8	0.71	0.95	40	16	33	2	1.0
BestValidationMCC	0.82	0.64	0.8	0.71	0.95	40	16	33	2	1.0
BestValidationAccuracy	0.82	0.64	0.8	0.71	0.95	40	16	33	2	1.0
TestPredictions (Threshold:1.0)
CHEMBL572867,TP,ACT,1.0	CHEMBL272395,TP,ACT,1.0	CHEMBL182379,TP,ACT,1.0	CHEMBL322547,TN,INACT,0.3700000047683716	CHEMBL3318839,TP,ACT,1.0	CHEMBL165012,FP,INACT,1.0	CHEMBL2042551,TN,INACT,0.029999999329447746	CHEMBL128360,FP,INACT,1.0	CHEMBL2443002,TN,INACT,0.9900000095367432	CHEMBL1256169,TP,ACT,1.0	CHEMBL602474,FP,INACT,1.0	CHEMBL574534,TP,ACT,1.0	CHEMBL272873,FP,INACT,1.0	CHEMBL552615,TN,INACT,0.9599999785423279	CHEMBL11131,TN,INACT,0.9700000286102295	CHEMBL1765631,FP,INACT,1.0	CHEMBL2207637,TP,ACT,1.0	CHEMBL164968,FP,INACT,1.0	CHEMBL210567,TP,ACT,1.0	CHEMBL430683,TN,INACT,0.5199999809265137	CHEMBL484204,TP,ACT,1.0	CHEMBL411437,TP,ACT,1.0	CHEMBL404557,TN,INACT,0.0	CHEMBL1771107,TP,ACT,1.0	CHEMBL3780633,TN,INACT,0.009999999776482582	CHEMBL1928139,TP,ACT,1.0	CHEMBL58617,TN,INACT,0.6100000143051147	CHEMBL573792,TP,ACT,1.0	CHEMBL1926700,TP,ACT,1.0	CHEMBL2370511,TN,INACT,0.949999988079071	CHEMBL211539,TP,ACT,1.0	CHEMBL2369493,FP,INACT,1.0	CHEMBL59597,TN,INACT,0.9900000095367432	CHEMBL1258495,TP,ACT,1.0	CHEMBL256492,TP,ACT,1.0	CHEMBL1928125,TP,ACT,1.0	CHEMBL21508,FP,INACT,1.0	CHEMBL227378,TN,INACT,0.0	CHEMBL379125,TP,ACT,1.0	CHEMBL48031,TN,INACT,0.0	CHEMBL1803023,TP,ACT,1.0	CHEMBL462650,TN,INACT,0.4699999988079071	CHEMBL336081,FP,INACT,1.0	CHEMBL321644,TN,INACT,0.05999999865889549	CHEMBL3317465,TP,ACT,1.0	CHEMBL197214,TP,ACT,1.0	CHEMBL211118,TP,ACT,1.0	CHEMBL1928122,TP,ACT,1.0	CHEMBL378515,TP,ACT,1.0	CHEMBL1771110,TP,ACT,1.0	CHEMBL451335,TN,INACT,0.009999999776482582	CHEMBL25856,TP,ACT,1.0	CHEMBL255163,TP,ACT,1.0	CHEMBL394292,TP,ACT,1.0	CHEMBL2111789,TN,INACT,0.9800000190734863	CHEMBL270056,TP,ACT,1.0	CHEMBL298203,TN,INACT,0.7099999785423279	CHEMBL1923416,TN,INACT,0.9900000095367432	CHEMBL89445,TN,INACT,0.9800000190734863	CHEMBL239733,TP,ACT,1.0	CHEMBL444128,TP,ACT,1.0	CHEMBL413040,TN,INACT,0.2800000011920929	CHEMBL330003,TN,INACT,0.4300000071525574	CHEMBL221640,TP,ACT,1.0	CHEMBL3780248,TN,INACT,0.25	CHEMBL1258494,TP,ACT,1.0	CHEMBL2207636,TP,ACT,1.0	CHEMBL1928136,TP,ACT,1.0	CHEMBL594376,TN,INACT,0.009999999776482582	CHEMBL44262,TN,INACT,0.019999999552965164	CHEMBL1771108,TP,ACT,1.0	CHEMBL123099,TN,INACT,0.9700000286102295	CHEMBL2207634,FN,ACT,0.9900000095367432	CHEMBL221652,TP,ACT,1.0	CHEMBL1765630,TP,ACT,1.0	CHEMBL424214,TN,INACT,0.0	CHEMBL78830,TN,INACT,0.0	CHEMBL2391353,FP,INACT,1.0	CHEMBL3633650,TN,INACT,0.029999999329447746	CHEMBL3318833,TP,ACT,1.0	CHEMBL10801,FP,INACT,1.0	CHEMBL1928129,TP,ACT,1.0	CHEMBL355851,TN,INACT,0.9900000095367432	CHEMBL42359,TN,INACT,0.0	CHEMBL2397480,TP,ACT,1.0	CHEMBL2443004,FP,INACT,1.0	CHEMBL2391356,TN,INACT,0.18000000715255737	CHEMBL574569,TP,ACT,1.0	CHEMBL21509,FP,INACT,1.0	CHEMBL59347,FP,INACT,1.0	CHEMBL379177,TP,ACT,1.0	

