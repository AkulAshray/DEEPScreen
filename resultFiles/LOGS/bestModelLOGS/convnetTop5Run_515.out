ImageNetInceptionV2 CHEMBL6007 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	194
Number of inactive compounds :	194
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL6007_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL6007_adam_0.001_15_0.8/
---------------------------------
Training samples: 248
Validation samples: 78
--
Training Step: 1  | time: 1085.874s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/248
[A[ATraining Step: 2  | total loss: [1m[32m0.61328[0m[0m | time: 1208.090s
[2K
| Adam | epoch: 001 | loss: 0.61328 - acc: 0.4781 -- iter: 064/248
[A[ATraining Step: 3  | total loss: [1m[32m0.81291[0m[0m | time: 1317.471s
[2K
| Adam | epoch: 001 | loss: 0.81291 - acc: 0.5983 -- iter: 096/248
[A[ATraining Step: 4  | total loss: [1m[32m0.94361[0m[0m | time: 1481.760s
[2K
| Adam | epoch: 001 | loss: 0.94361 - acc: 0.6183 -- iter: 128/248
[A[ATraining Step: 5  | total loss: [1m[32m0.72720[0m[0m | time: 1542.044s
[2K
| Adam | epoch: 001 | loss: 0.72720 - acc: 0.6662 -- iter: 160/248
[A[ATraining Step: 6  | total loss: [1m[32m0.71776[0m[0m | time: 1589.027s
[2K
| Adam | epoch: 001 | loss: 0.71776 - acc: 0.5795 -- iter: 192/248
[A[ATraining Step: 7  | total loss: [1m[32m0.54180[0m[0m | time: 1604.519s
[2K
| Adam | epoch: 001 | loss: 0.54180 - acc: 0.7380 -- iter: 224/248
[A[ATraining Step: 8  | total loss: [1m[32m0.57538[0m[0m | time: 1632.978s
[2K
| Adam | epoch: 001 | loss: 0.57538 - acc: 0.7448 | val_loss: 0.80733 - val_acc: 0.4487 -- iter: 248/248
--
Training Step: 9  | total loss: [1m[32m0.48482[0m[0m | time: 10.985s
[2K
| Adam | epoch: 002 | loss: 0.48482 - acc: 0.7475 -- iter: 032/248
[A[ATraining Step: 10  | total loss: [1m[32m0.35993[0m[0m | time: 24.257s
[2K
| Adam | epoch: 002 | loss: 0.35993 - acc: 0.8321 -- iter: 064/248
[A[ATraining Step: 11  | total loss: [1m[32m0.49712[0m[0m | time: 37.332s
[2K
| Adam | epoch: 002 | loss: 0.49712 - acc: 0.7488 -- iter: 096/248
[A[ATraining Step: 12  | total loss: [1m[32m0.52674[0m[0m | time: 51.629s
[2K
| Adam | epoch: 002 | loss: 0.52674 - acc: 0.7353 -- iter: 128/248
[A[ATraining Step: 13  | total loss: [1m[32m0.49504[0m[0m | time: 62.677s
[2K
| Adam | epoch: 002 | loss: 0.49504 - acc: 0.7282 -- iter: 160/248
[A[ATraining Step: 14  | total loss: [1m[32m0.42231[0m[0m | time: 73.214s
[2K
| Adam | epoch: 002 | loss: 0.42231 - acc: 0.8010 -- iter: 192/248
[A[ATraining Step: 15  | total loss: [1m[32m0.40824[0m[0m | time: 84.625s
[2K
| Adam | epoch: 002 | loss: 0.40824 - acc: 0.7933 -- iter: 224/248
[A[ATraining Step: 16  | total loss: [1m[32m0.43451[0m[0m | time: 99.932s
[2K
| Adam | epoch: 002 | loss: 0.43451 - acc: 0.7653 | val_loss: 0.68777 - val_acc: 0.5513 -- iter: 248/248
--
Training Step: 17  | total loss: [1m[32m0.41205[0m[0m | time: 8.924s
[2K
| Adam | epoch: 003 | loss: 0.41205 - acc: 0.8161 -- iter: 032/248
[A[ATraining Step: 18  | total loss: [1m[32m0.52969[0m[0m | time: 18.239s
[2K
| Adam | epoch: 003 | loss: 0.52969 - acc: 0.8076 -- iter: 064/248
[A[ATraining Step: 19  | total loss: [1m[32m0.48635[0m[0m | time: 29.578s
[2K
| Adam | epoch: 003 | loss: 0.48635 - acc: 0.8023 -- iter: 096/248
[A[ATraining Step: 20  | total loss: [1m[32m0.49803[0m[0m | time: 41.559s
[2K
| Adam | epoch: 003 | loss: 0.49803 - acc: 0.8056 -- iter: 128/248
[A[ATraining Step: 21  | total loss: [1m[32m0.47300[0m[0m | time: 53.040s
[2K
| Adam | epoch: 003 | loss: 0.47300 - acc: 0.7980 -- iter: 160/248
[A[ATraining Step: 22  | total loss: [1m[32m0.46185[0m[0m | time: 65.150s
[2K
| Adam | epoch: 003 | loss: 0.46185 - acc: 0.7930 -- iter: 192/248
[A[ATraining Step: 23  | total loss: [1m[32m0.49246[0m[0m | time: 76.867s
[2K
| Adam | epoch: 003 | loss: 0.49246 - acc: 0.7896 -- iter: 224/248
[A[ATraining Step: 24  | total loss: [1m[32m0.46177[0m[0m | time: 93.763s
[2K
| Adam | epoch: 003 | loss: 0.46177 - acc: 0.8136 | val_loss: 0.82044 - val_acc: 0.5513 -- iter: 248/248
--
Training Step: 25  | total loss: [1m[32m0.44643[0m[0m | time: 11.605s
[2K
| Adam | epoch: 004 | loss: 0.44643 - acc: 0.8304 -- iter: 032/248
[A[ATraining Step: 26  | total loss: [1m[32m0.41663[0m[0m | time: 20.912s
[2K
| Adam | epoch: 004 | loss: 0.41663 - acc: 0.8422 -- iter: 064/248
[A[ATraining Step: 27  | total loss: [1m[32m0.38769[0m[0m | time: 30.259s
[2K
| Adam | epoch: 004 | loss: 0.38769 - acc: 0.8506 -- iter: 096/248
[A[ATraining Step: 28  | total loss: [1m[32m0.34341[0m[0m | time: 42.033s
[2K
| Adam | epoch: 004 | loss: 0.34341 - acc: 0.8775 -- iter: 128/248
[A[ATraining Step: 29  | total loss: [1m[32m0.35744[0m[0m | time: 54.157s
[2K
| Adam | epoch: 004 | loss: 0.35744 - acc: 0.8693 -- iter: 160/248
[A[ATraining Step: 30  | total loss: [1m[32m0.32897[0m[0m | time: 65.777s
[2K
| Adam | epoch: 004 | loss: 0.32897 - acc: 0.8855 -- iter: 192/248
[A[ATraining Step: 31  | total loss: [1m[32m0.31664[0m[0m | time: 77.090s
[2K
| Adam | epoch: 004 | loss: 0.31664 - acc: 0.8831 -- iter: 224/248
[A[ATraining Step: 32  | total loss: [1m[32m0.30140[0m[0m | time: 94.395s
[2K
| Adam | epoch: 004 | loss: 0.30140 - acc: 0.8883 | val_loss: 0.69110 - val_acc: 0.5385 -- iter: 248/248
--
Training Step: 33  | total loss: [1m[32m0.28100[0m[0m | time: 12.037s
[2K
| Adam | epoch: 005 | loss: 0.28100 - acc: 0.8922 -- iter: 032/248
[A[ATraining Step: 34  | total loss: [1m[32m0.29000[0m[0m | time: 23.284s
[2K
| Adam | epoch: 005 | loss: 0.29000 - acc: 0.8952 -- iter: 064/248
[A[ATraining Step: 35  | total loss: [1m[32m0.27780[0m[0m | time: 32.635s
[2K
| Adam | epoch: 005 | loss: 0.27780 - acc: 0.8845 -- iter: 096/248
[A[ATraining Step: 36  | total loss: [1m[32m0.24215[0m[0m | time: 41.490s
[2K
| Adam | epoch: 005 | loss: 0.24215 - acc: 0.8996 -- iter: 128/248
[A[ATraining Step: 37  | total loss: [1m[32m0.20310[0m[0m | time: 53.669s
[2K
| Adam | epoch: 005 | loss: 0.20310 - acc: 0.9197 -- iter: 160/248
[A[ATraining Step: 38  | total loss: [1m[32m0.25103[0m[0m | time: 65.295s
[2K
| Adam | epoch: 005 | loss: 0.25103 - acc: 0.9048 -- iter: 192/248
[A[ATraining Step: 39  | total loss: [1m[32m0.24651[0m[0m | time: 77.120s
[2K
| Adam | epoch: 005 | loss: 0.24651 - acc: 0.9051 -- iter: 224/248
[A[ATraining Step: 40  | total loss: [1m[32m0.24495[0m[0m | time: 93.801s
[2K
| Adam | epoch: 005 | loss: 0.24495 - acc: 0.9112 | val_loss: 1.01907 - val_acc: 0.5513 -- iter: 248/248
--
Training Step: 41  | total loss: [1m[32m0.22739[0m[0m | time: 10.491s
[2K
| Adam | epoch: 006 | loss: 0.22739 - acc: 0.9160 -- iter: 032/248
[A[ATraining Step: 42  | total loss: [1m[32m0.26208[0m[0m | time: 19.554s
[2K
| Adam | epoch: 006 | loss: 0.26208 - acc: 0.8917 -- iter: 064/248
[A[ATraining Step: 43  | total loss: [1m[32m0.23366[0m[0m | time: 28.846s
[2K
| Adam | epoch: 006 | loss: 0.23366 - acc: 0.9053 -- iter: 096/248
[A[ATraining Step: 44  | total loss: [1m[32m0.20506[0m[0m | time: 36.246s
[2K
| Adam | epoch: 006 | loss: 0.20506 - acc: 0.9163 -- iter: 128/248
[A[ATraining Step: 45  | total loss: [1m[32m0.20368[0m[0m | time: 43.253s
[2K
| Adam | epoch: 006 | loss: 0.20368 - acc: 0.9164 -- iter: 160/248
[A[ATraining Step: 46  | total loss: [1m[32m0.17942[0m[0m | time: 52.562s
[2K
| Adam | epoch: 006 | loss: 0.17942 - acc: 0.9303 -- iter: 192/248
[A[ATraining Step: 47  | total loss: [1m[32m0.19714[0m[0m | time: 61.420s
[2K
| Adam | epoch: 006 | loss: 0.19714 - acc: 0.9264 -- iter: 224/248
[A[ATraining Step: 48  | total loss: [1m[32m0.19105[0m[0m | time: 73.958s
[2K
| Adam | epoch: 006 | loss: 0.19105 - acc: 0.9282 | val_loss: 2.21517 - val_acc: 0.5513 -- iter: 248/248
--
Training Step: 49  | total loss: [1m[32m0.22229[0m[0m | time: 9.088s
[2K
| Adam | epoch: 007 | loss: 0.22229 - acc: 0.9346 -- iter: 032/248
[A[ATraining Step: 50  | total loss: [1m[32m0.19610[0m[0m | time: 18.312s
[2K
| Adam | epoch: 007 | loss: 0.19610 - acc: 0.9447 -- iter: 064/248
[A[ATraining Step: 51  | total loss: [1m[32m0.21318[0m[0m | time: 27.384s
[2K
| Adam | epoch: 007 | loss: 0.21318 - acc: 0.9341 -- iter: 096/248
[A[ATraining Step: 52  | total loss: [1m[32m0.20373[0m[0m | time: 36.561s
[2K
| Adam | epoch: 007 | loss: 0.20373 - acc: 0.9346 -- iter: 128/248
[A[ATraining Step: 53  | total loss: [1m[32m0.18736[0m[0m | time: 43.676s
[2K
| Adam | epoch: 007 | loss: 0.18736 - acc: 0.9396 -- iter: 160/248
[A[ATraining Step: 54  | total loss: [1m[32m0.17702[0m[0m | time: 50.622s
[2K
| Adam | epoch: 007 | loss: 0.17702 - acc: 0.9424 -- iter: 192/248
[A[ATraining Step: 55  | total loss: [1m[32m0.15582[0m[0m | time: 59.980s
[2K
| Adam | epoch: 007 | loss: 0.15582 - acc: 0.9506 -- iter: 224/248
[A[ATraining Step: 56  | total loss: [1m[32m0.14372[0m[0m | time: 72.625s
[2K
| Adam | epoch: 007 | loss: 0.14372 - acc: 0.9575 | val_loss: 0.54167 - val_acc: 0.7692 -- iter: 248/248
--
Training Step: 57  | total loss: [1m[32m0.17482[0m[0m | time: 9.029s
[2K
| Adam | epoch: 008 | loss: 0.17482 - acc: 0.9418 -- iter: 032/248
[A[ATraining Step: 58  | total loss: [1m[32m0.19117[0m[0m | time: 18.120s
[2K
| Adam | epoch: 008 | loss: 0.19117 - acc: 0.9369 -- iter: 064/248
[A[ATraining Step: 59  | total loss: [1m[32m0.17134[0m[0m | time: 27.619s
[2K
| Adam | epoch: 008 | loss: 0.17134 - acc: 0.9454 -- iter: 096/248
[A[ATraining Step: 60  | total loss: [1m[32m0.16273[0m[0m | time: 36.922s
[2K
| Adam | epoch: 008 | loss: 0.16273 - acc: 0.9444 -- iter: 128/248
[A[ATraining Step: 61  | total loss: [1m[32m0.18975[0m[0m | time: 45.860s
[2K
| Adam | epoch: 008 | loss: 0.18975 - acc: 0.9394 -- iter: 160/248
[A[ATraining Step: 62  | total loss: [1m[32m0.18292[0m[0m | time: 52.970s
[2K
| Adam | epoch: 008 | loss: 0.18292 - acc: 0.9432 -- iter: 192/248
[A[ATraining Step: 63  | total loss: [1m[32m0.17258[0m[0m | time: 59.979s
[2K
| Adam | epoch: 008 | loss: 0.17258 - acc: 0.9398 -- iter: 224/248
[A[ATraining Step: 64  | total loss: [1m[32m0.15449[0m[0m | time: 72.647s
[2K
| Adam | epoch: 008 | loss: 0.15449 - acc: 0.9473 | val_loss: 3.38166 - val_acc: 0.5769 -- iter: 248/248
--
Training Step: 65  | total loss: [1m[32m0.18868[0m[0m | time: 9.160s
[2K
| Adam | epoch: 009 | loss: 0.18868 - acc: 0.9384 -- iter: 032/248
[A[ATraining Step: 66  | total loss: [1m[32m0.17195[0m[0m | time: 18.490s
[2K
| Adam | epoch: 009 | loss: 0.17195 - acc: 0.9421 -- iter: 064/248
[A[ATraining Step: 67  | total loss: [1m[32m0.18291[0m[0m | time: 27.428s
[2K
| Adam | epoch: 009 | loss: 0.18291 - acc: 0.9340 -- iter: 096/248
[A[ATraining Step: 68  | total loss: [1m[32m0.17189[0m[0m | time: 36.547s
[2K
| Adam | epoch: 009 | loss: 0.17189 - acc: 0.9382 -- iter: 128/248
[A[ATraining Step: 69  | total loss: [1m[32m0.17386[0m[0m | time: 45.667s
[2K
| Adam | epoch: 009 | loss: 0.17386 - acc: 0.9344 -- iter: 160/248
[A[ATraining Step: 70  | total loss: [1m[32m0.16205[0m[0m | time: 55.074s
[2K
| Adam | epoch: 009 | loss: 0.16205 - acc: 0.9384 -- iter: 192/248
[A[ATraining Step: 71  | total loss: [1m[32m0.14969[0m[0m | time: 62.362s
[2K
| Adam | epoch: 009 | loss: 0.14969 - acc: 0.9454 -- iter: 224/248
[A[ATraining Step: 72  | total loss: [1m[32m0.16921[0m[0m | time: 73.458s
[2K
| Adam | epoch: 009 | loss: 0.16921 - acc: 0.9375 | val_loss: 0.70202 - val_acc: 0.7308 -- iter: 248/248
--
Training Step: 73  | total loss: [1m[32m0.15941[0m[0m | time: 8.852s
[2K
| Adam | epoch: 010 | loss: 0.15941 - acc: 0.9444 -- iter: 032/248
[A[ATraining Step: 74  | total loss: [1m[32m0.17298[0m[0m | time: 18.191s
[2K
| Adam | epoch: 010 | loss: 0.17298 - acc: 0.9402 -- iter: 064/248
[A[ATraining Step: 75  | total loss: [1m[32m0.16759[0m[0m | time: 27.511s
[2K
| Adam | epoch: 010 | loss: 0.16759 - acc: 0.9433 -- iter: 096/248
[A[ATraining Step: 76  | total loss: [1m[32m0.18822[0m[0m | time: 36.612s
[2K
| Adam | epoch: 010 | loss: 0.18822 - acc: 0.9427 -- iter: 128/248
[A[ATraining Step: 77  | total loss: [1m[32m0.20737[0m[0m | time: 45.871s
[2K
| Adam | epoch: 010 | loss: 0.20737 - acc: 0.9355 -- iter: 160/248
[A[ATraining Step: 78  | total loss: [1m[32m0.20593[0m[0m | time: 55.032s
[2K
| Adam | epoch: 010 | loss: 0.20593 - acc: 0.9325 -- iter: 192/248
[A[ATraining Step: 79  | total loss: [1m[32m0.19202[0m[0m | time: 64.085s
[2K
| Adam | epoch: 010 | loss: 0.19202 - acc: 0.9362 -- iter: 224/248
[A[ATraining Step: 80  | total loss: [1m[32m0.18610[0m[0m | time: 75.086s
[2K
| Adam | epoch: 010 | loss: 0.18610 - acc: 0.9396 | val_loss: 5.27572 - val_acc: 0.5128 -- iter: 248/248
--
Training Step: 81  | total loss: [1m[32m0.18621[0m[0m | time: 7.663s
[2K
| Adam | epoch: 011 | loss: 0.18621 - acc: 0.9372 -- iter: 032/248
[A[ATraining Step: 82  | total loss: [1m[32m0.17286[0m[0m | time: 17.161s
[2K
| Adam | epoch: 011 | loss: 0.17286 - acc: 0.9435 -- iter: 064/248
[A[ATraining Step: 83  | total loss: [1m[32m0.19080[0m[0m | time: 25.871s
[2K
| Adam | epoch: 011 | loss: 0.19080 - acc: 0.9273 -- iter: 096/248
[A[ATraining Step: 84  | total loss: [1m[32m0.22231[0m[0m | time: 35.229s
[2K
| Adam | epoch: 011 | loss: 0.22231 - acc: 0.9096 -- iter: 128/248
[A[ATraining Step: 85  | total loss: [1m[32m0.20574[0m[0m | time: 44.462s
[2K
| Adam | epoch: 011 | loss: 0.20574 - acc: 0.9186 -- iter: 160/248
[A[ATraining Step: 86  | total loss: [1m[32m0.20253[0m[0m | time: 54.122s
[2K
| Adam | epoch: 011 | loss: 0.20253 - acc: 0.9205 -- iter: 192/248
[A[ATraining Step: 87  | total loss: [1m[32m0.18877[0m[0m | time: 63.202s
[2K
| Adam | epoch: 011 | loss: 0.18877 - acc: 0.9284 -- iter: 224/248
[A[ATraining Step: 88  | total loss: [1m[32m0.21207[0m[0m | time: 76.115s
[2K
| Adam | epoch: 011 | loss: 0.21207 - acc: 0.9231 | val_loss: 3.14048 - val_acc: 0.5385 -- iter: 248/248
--
Training Step: 89  | total loss: [1m[32m0.22095[0m[0m | time: 7.346s
[2K
| Adam | epoch: 012 | loss: 0.22095 - acc: 0.9214 -- iter: 032/248
[A[ATraining Step: 90  | total loss: [1m[32m0.22778[0m[0m | time: 15.008s
[2K
| Adam | epoch: 012 | loss: 0.22778 - acc: 0.9209 -- iter: 064/248
[A[ATraining Step: 91  | total loss: [1m[32m0.21684[0m[0m | time: 24.099s
[2K
| Adam | epoch: 012 | loss: 0.21684 - acc: 0.9247 -- iter: 096/248
[A[ATraining Step: 92  | total loss: [1m[32m0.21717[0m[0m | time: 33.251s
[2K
| Adam | epoch: 012 | loss: 0.21717 - acc: 0.9228 -- iter: 128/248
[A[ATraining Step: 93  | total loss: [1m[32m0.19988[0m[0m | time: 42.955s
[2K
| Adam | epoch: 012 | loss: 0.19988 - acc: 0.9306 -- iter: 160/248
[A[ATraining Step: 94  | total loss: [1m[32m0.18553[0m[0m | time: 53.036s
[2K
| Adam | epoch: 012 | loss: 0.18553 - acc: 0.9344 -- iter: 192/248
[A[ATraining Step: 95  | total loss: [1m[32m0.17998[0m[0m | time: 62.589s
[2K
| Adam | epoch: 012 | loss: 0.17998 - acc: 0.9378 -- iter: 224/248
[A[ATraining Step: 96  | total loss: [1m[32m0.18160[0m[0m | time: 75.918s
[2K
| Adam | epoch: 012 | loss: 0.18160 - acc: 0.9378 | val_loss: 1.55668 - val_acc: 0.6923 -- iter: 248/248
--
Training Step: 97  | total loss: [1m[32m0.17729[0m[0m | time: 9.387s
[2K
| Adam | epoch: 013 | loss: 0.17729 - acc: 0.9378 -- iter: 032/248
[A[ATraining Step: 98  | total loss: [1m[32m0.16426[0m[0m | time: 16.832s
[2K
| Adam | epoch: 013 | loss: 0.16426 - acc: 0.9440 -- iter: 064/248
[A[ATraining Step: 99  | total loss: [1m[32m0.15321[0m[0m | time: 24.305s
[2K
| Adam | epoch: 013 | loss: 0.15321 - acc: 0.9496 -- iter: 096/248
[A[ATraining Step: 100  | total loss: [1m[32m0.13950[0m[0m | time: 33.512s
[2K
| Adam | epoch: 013 | loss: 0.13950 - acc: 0.9546 -- iter: 128/248
[A[ATraining Step: 101  | total loss: [1m[32m0.13167[0m[0m | time: 42.974s
[2K
| Adam | epoch: 013 | loss: 0.13167 - acc: 0.9560 -- iter: 160/248
[A[ATraining Step: 102  | total loss: [1m[32m0.11992[0m[0m | time: 52.476s
[2K
| Adam | epoch: 013 | loss: 0.11992 - acc: 0.9604 -- iter: 192/248
[A[ATraining Step: 103  | total loss: [1m[32m0.11866[0m[0m | time: 61.942s
[2K
| Adam | epoch: 013 | loss: 0.11866 - acc: 0.9613 -- iter: 224/248
[A[ATraining Step: 104  | total loss: [1m[32m0.11226[0m[0m | time: 75.248s
[2K
| Adam | epoch: 013 | loss: 0.11226 - acc: 0.9620 | val_loss: 0.89940 - val_acc: 0.7821 -- iter: 248/248
--
Training Step: 105  | total loss: [1m[32m0.10403[0m[0m | time: 9.609s
[2K
| Adam | epoch: 014 | loss: 0.10403 - acc: 0.9658 -- iter: 032/248
[A[ATraining Step: 106  | total loss: [1m[32m0.09827[0m[0m | time: 19.630s
[2K
| Adam | epoch: 014 | loss: 0.09827 - acc: 0.9692 -- iter: 064/248
[A[ATraining Step: 107  | total loss: [1m[32m0.08896[0m[0m | time: 27.142s
[2K
| Adam | epoch: 014 | loss: 0.08896 - acc: 0.9723 -- iter: 096/248
[A[ATraining Step: 108  | total loss: [1m[32m0.08143[0m[0m | time: 34.446s
[2K
| Adam | epoch: 014 | loss: 0.08143 - acc: 0.9751 -- iter: 128/248
[A[ATraining Step: 109  | total loss: [1m[32m0.07496[0m[0m | time: 43.899s
[2K
| Adam | epoch: 014 | loss: 0.07496 - acc: 0.9776 -- iter: 160/248
[A[ATraining Step: 110  | total loss: [1m[32m0.07309[0m[0m | time: 53.390s
[2K
| Adam | epoch: 014 | loss: 0.07309 - acc: 0.9767 -- iter: 192/248
[A[ATraining Step: 111  | total loss: [1m[32m0.06653[0m[0m | time: 63.091s
[2K
| Adam | epoch: 014 | loss: 0.06653 - acc: 0.9790 -- iter: 224/248
[A[ATraining Step: 112  | total loss: [1m[32m0.06022[0m[0m | time: 76.851s
[2K
| Adam | epoch: 014 | loss: 0.06022 - acc: 0.9811 | val_loss: 0.96415 - val_acc: 0.7692 -- iter: 248/248
--
Training Step: 113  | total loss: [1m[32m0.05898[0m[0m | time: 9.696s
[2K
| Adam | epoch: 015 | loss: 0.05898 - acc: 0.9799 -- iter: 032/248
[A[ATraining Step: 114  | total loss: [1m[32m0.05430[0m[0m | time: 19.318s
[2K
| Adam | epoch: 015 | loss: 0.05430 - acc: 0.9819 -- iter: 064/248
[A[ATraining Step: 115  | total loss: [1m[32m0.04904[0m[0m | time: 28.418s
[2K
| Adam | epoch: 015 | loss: 0.04904 - acc: 0.9837 -- iter: 096/248
[A[ATraining Step: 116  | total loss: [1m[32m0.04510[0m[0m | time: 35.201s
[2K
| Adam | epoch: 015 | loss: 0.04510 - acc: 0.9853 -- iter: 128/248
[A[ATraining Step: 117  | total loss: [1m[32m0.05710[0m[0m | time: 42.199s
[2K
| Adam | epoch: 015 | loss: 0.05710 - acc: 0.9785 -- iter: 160/248
[A[ATraining Step: 118  | total loss: [1m[32m0.05581[0m[0m | time: 51.094s
[2K
| Adam | epoch: 015 | loss: 0.05581 - acc: 0.9806 -- iter: 192/248
[A[ATraining Step: 119  | total loss: [1m[32m0.05081[0m[0m | time: 60.171s
[2K
| Adam | epoch: 015 | loss: 0.05081 - acc: 0.9826 -- iter: 224/248
[A[ATraining Step: 120  | total loss: [1m[32m0.04638[0m[0m | time: 72.591s
[2K
| Adam | epoch: 015 | loss: 0.04638 - acc: 0.9843 | val_loss: 2.39374 - val_acc: 0.7051 -- iter: 248/248
--
Validation AUC:0.8039867109634551
Validation AUPRC:0.8497848461844184
Test AUC:0.7357001972386588
Test AUPRC:0.7315217552215064
BestTestF1Score	0.72	0.41	0.71	0.68	0.77	30	14	25	9	0.02
BestTestMCCScore	0.68	0.39	0.69	0.71	0.64	25	10	29	14	0.28
BestTestAccuracyScore	0.68	0.39	0.69	0.71	0.64	25	10	29	14	0.28
BestValidationF1Score	0.74	0.47	0.73	0.79	0.7	30	8	27	13	0.02
BestValidationMCC	0.73	0.48	0.73	0.82	0.65	28	6	29	15	0.28
BestValidationAccuracy	0.73	0.48	0.73	0.82	0.65	28	6	29	15	0.28
TestPredictions (Threshold:0.28)
CHEMBL2376848,TN,INACT,0.0	CHEMBL3697711,FP,INACT,1.0	CHEMBL151649,TP,ACT,1.0	CHEMBL3753909,TP,ACT,1.0	CHEMBL2322255,TN,INACT,0.0	CHEMBL3786037,FN,ACT,0.0	CHEMBL3299020,FN,ACT,0.009999999776482582	CHEMBL2087058,TN,INACT,0.0	CHEMBL249592,FP,INACT,0.9900000095367432	CHEMBL3298582,TP,ACT,1.0	CHEMBL406556,TN,INACT,0.0	CHEMBL3325770,TP,ACT,0.8700000047683716	CHEMBL2376845,TN,INACT,0.0	CHEMBL1084097,TP,ACT,0.9700000286102295	CHEMBL3311192,TP,ACT,1.0	CHEMBL1085943,FN,ACT,0.0	CHEMBL1083802,TN,INACT,0.0	CHEMBL2322545,TN,INACT,0.0	CHEMBL3220230,TP,ACT,0.8500000238418579	CHEMBL2376850,TN,INACT,0.0	CHEMBL210574,TN,INACT,0.0	CHEMBL3236343,FP,INACT,0.9700000286102295	CHEMBL3297778,TP,ACT,1.0	CHEMBL3697705,TP,ACT,1.0	CHEMBL2418811,TN,INACT,0.009999999776482582	CHEMBL3589911,TN,INACT,0.0	CHEMBL2312049,TN,INACT,0.0	CHEMBL3416893,TN,INACT,0.0	CHEMBL2087072,TN,INACT,0.0	CHEMBL2373178,TN,INACT,0.12999999523162842	CHEMBL3220449,FN,ACT,0.0	CHEMBL605157,TN,INACT,0.0	CHEMBL3753942,TP,ACT,0.9900000095367432	CHEMBL3787204,TP,ACT,0.699999988079071	CHEMBL3753452,FN,ACT,0.09000000357627869	CHEMBL3298585,TP,ACT,1.0	CHEMBL3298250,FN,ACT,0.029999999329447746	CHEMBL411931,FP,INACT,0.9800000190734863	CHEMBL259804,TN,INACT,0.0	CHEMBL254384,TN,INACT,0.0	CHEMBL184238,TN,INACT,0.0	CHEMBL186366,TN,INACT,0.09000000357627869	CHEMBL1084098,TP,ACT,1.0	CHEMBL3298249,FN,ACT,0.10000000149011612	CHEMBL3220450,FN,ACT,0.0	CHEMBL2430156,TN,INACT,0.03999999910593033	CHEMBL3754445,TP,ACT,1.0	CHEMBL3325765,TN,INACT,0.0	CHEMBL3786619,FN,ACT,0.009999999776482582	CHEMBL2430161,TN,INACT,0.11999999731779099	CHEMBL3298925,FP,INACT,0.9700000286102295	CHEMBL3698469,TN,INACT,0.0	CHEMBL3752891,FN,ACT,0.0	CHEMBL574688,TP,ACT,1.0	CHEMBL481246,FP,INACT,1.0	CHEMBL1939972,TP,ACT,0.9599999785423279	CHEMBL3220451,FN,ACT,0.03999999910593033	CHEMBL3298760,TP,ACT,1.0	CHEMBL210287,FP,INACT,1.0	CHEMBL3298500,TP,ACT,0.9599999785423279	CHEMBL3299019,TP,ACT,1.0	CHEMBL3297779,TP,ACT,0.36000001430511475	CHEMBL469537,FP,INACT,0.5799999833106995	CHEMBL2430157,TN,INACT,0.0	CHEMBL2376843,TN,INACT,0.0	CHEMBL3697710,TP,ACT,1.0	CHEMBL3593947,TP,ACT,1.0	CHEMBL1084638,TP,ACT,1.0	CHEMBL3298212,TP,ACT,1.0	CHEMBL2087061,FP,INACT,0.9800000190734863	CHEMBL182120,FN,ACT,0.0	CHEMBL3311188,FN,ACT,0.0	CHEMBL3355287,TN,INACT,0.0	CHEMBL3787359,FN,ACT,0.029999999329447746	CHEMBL3682291,TN,INACT,0.0	CHEMBL454280,FP,INACT,1.0	CHEMBL2151143,TP,ACT,1.0	CHEMBL261864,TN,INACT,0.0	

