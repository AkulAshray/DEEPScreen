ImageNetInceptionV2 CHEMBL2073 adam 0.0001 15 0 0 0.8 False True
Number of active compounds :	126
Number of inactive compounds :	126
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2073_adam_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2073_adam_0.0001_15_0.8/
---------------------------------
Training samples: 144
Validation samples: 45
--
Training Step: 1  | time: 1367.357s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/144
[A[ATraining Step: 2  | total loss: [1m[32m0.60736[0m[0m | time: 1781.294s
[2K
| Adam | epoch: 001 | loss: 0.60736 - acc: 0.5062 -- iter: 064/144
[A[ATraining Step: 3  | total loss: [1m[32m0.67831[0m[0m | time: 2004.997s
[2K
| Adam | epoch: 001 | loss: 0.67831 - acc: 0.5011 -- iter: 096/144
[A[ATraining Step: 4  | total loss: [1m[32m0.60104[0m[0m | time: 2077.311s
[2K
| Adam | epoch: 001 | loss: 0.60104 - acc: 0.6643 -- iter: 128/144
[A[ATraining Step: 5  | total loss: [1m[32m0.55420[0m[0m | time: 2092.461s
[2K
| Adam | epoch: 001 | loss: 0.55420 - acc: 0.7453 | val_loss: 0.69225 - val_acc: 0.5556 -- iter: 144/144
--
Training Step: 6  | total loss: [1m[32m0.53058[0m[0m | time: 6.093s
[2K
| Adam | epoch: 002 | loss: 0.53058 - acc: 0.7885 -- iter: 032/144
[A[ATraining Step: 7  | total loss: [1m[32m0.40536[0m[0m | time: 15.822s
[2K
| Adam | epoch: 002 | loss: 0.40536 - acc: 0.9154 -- iter: 064/144
[A[ATraining Step: 8  | total loss: [1m[32m0.45086[0m[0m | time: 26.271s
[2K
| Adam | epoch: 002 | loss: 0.45086 - acc: 0.8224 -- iter: 096/144
[A[ATraining Step: 9  | total loss: [1m[32m0.48520[0m[0m | time: 40.457s
[2K
| Adam | epoch: 002 | loss: 0.48520 - acc: 0.7510 -- iter: 128/144
[A[ATraining Step: 10  | total loss: [1m[32m0.38977[0m[0m | time: 72.037s
[2K
| Adam | epoch: 002 | loss: 0.38977 - acc: 0.8755 | val_loss: 0.68755 - val_acc: 0.5556 -- iter: 144/144
--
Training Step: 11  | total loss: [1m[32m0.34559[0m[0m | time: 5.724s
[2K
| Adam | epoch: 003 | loss: 0.34559 - acc: 0.8901 -- iter: 032/144
[A[ATraining Step: 12  | total loss: [1m[32m0.30605[0m[0m | time: 11.666s
[2K
| Adam | epoch: 003 | loss: 0.30605 - acc: 0.9114 -- iter: 064/144
[A[ATraining Step: 13  | total loss: [1m[32m0.24119[0m[0m | time: 20.535s
[2K
| Adam | epoch: 003 | loss: 0.24119 - acc: 0.9494 -- iter: 096/144
[A[ATraining Step: 14  | total loss: [1m[32m0.22713[0m[0m | time: 29.237s
[2K
| Adam | epoch: 003 | loss: 0.22713 - acc: 0.9445 -- iter: 128/144
[A[ATraining Step: 15  | total loss: [1m[32m0.20223[0m[0m | time: 39.628s
[2K
| Adam | epoch: 003 | loss: 0.20223 - acc: 0.9540 | val_loss: 0.69074 - val_acc: 0.5556 -- iter: 144/144
--
Training Step: 16  | total loss: [1m[32m0.15884[0m[0m | time: 8.159s
[2K
| Adam | epoch: 004 | loss: 0.15884 - acc: 0.9712 -- iter: 032/144
[A[ATraining Step: 17  | total loss: [1m[32m0.13027[0m[0m | time: 13.093s
[2K
| Adam | epoch: 004 | loss: 0.13027 - acc: 0.9816 -- iter: 064/144
[A[ATraining Step: 18  | total loss: [1m[32m0.12146[0m[0m | time: 17.912s
[2K
| Adam | epoch: 004 | loss: 0.12146 - acc: 0.9880 -- iter: 096/144
[A[ATraining Step: 19  | total loss: [1m[32m0.09973[0m[0m | time: 27.312s
[2K
| Adam | epoch: 004 | loss: 0.09973 - acc: 0.9920 -- iter: 128/144
[A[ATraining Step: 20  | total loss: [1m[32m0.07971[0m[0m | time: 37.728s
[2K
| Adam | epoch: 004 | loss: 0.07971 - acc: 0.9946 | val_loss: 0.68415 - val_acc: 0.5556 -- iter: 144/144
--
Training Step: 21  | total loss: [1m[32m0.07899[0m[0m | time: 7.918s
[2K
| Adam | epoch: 005 | loss: 0.07899 - acc: 0.9962 -- iter: 032/144
[A[ATraining Step: 22  | total loss: [1m[32m0.10710[0m[0m | time: 15.992s
[2K
| Adam | epoch: 005 | loss: 0.10710 - acc: 0.9880 -- iter: 064/144
[A[ATraining Step: 23  | total loss: [1m[32m0.08162[0m[0m | time: 20.715s
[2K
| Adam | epoch: 005 | loss: 0.08162 - acc: 0.9915 -- iter: 096/144
[A[ATraining Step: 24  | total loss: [1m[32m0.06470[0m[0m | time: 25.315s
[2K
| Adam | epoch: 005 | loss: 0.06470 - acc: 0.9939 -- iter: 128/144
[A[ATraining Step: 25  | total loss: [1m[32m0.05245[0m[0m | time: 35.434s
[2K
| Adam | epoch: 005 | loss: 0.05245 - acc: 0.9955 | val_loss: 0.67762 - val_acc: 0.5556 -- iter: 144/144
--
Training Step: 26  | total loss: [1m[32m0.04430[0m[0m | time: 8.530s
[2K
| Adam | epoch: 006 | loss: 0.04430 - acc: 0.9967 -- iter: 032/144
[A[ATraining Step: 27  | total loss: [1m[32m0.03650[0m[0m | time: 16.485s
[2K
| Adam | epoch: 006 | loss: 0.03650 - acc: 0.9976 -- iter: 064/144
[A[ATraining Step: 28  | total loss: [1m[32m0.03211[0m[0m | time: 24.642s
[2K
| Adam | epoch: 006 | loss: 0.03211 - acc: 0.9982 -- iter: 096/144
[A[ATraining Step: 29  | total loss: [1m[32m0.02643[0m[0m | time: 29.340s
[2K
| Adam | epoch: 006 | loss: 0.02643 - acc: 0.9986 -- iter: 128/144
[A[ATraining Step: 30  | total loss: [1m[32m0.02170[0m[0m | time: 36.210s
[2K
| Adam | epoch: 006 | loss: 0.02170 - acc: 0.9989 | val_loss: 0.68004 - val_acc: 0.5556 -- iter: 144/144
--
Training Step: 31  | total loss: [1m[32m0.01776[0m[0m | time: 8.120s
[2K
| Adam | epoch: 007 | loss: 0.01776 - acc: 0.9992 -- iter: 032/144
[A[ATraining Step: 32  | total loss: [1m[32m0.01466[0m[0m | time: 16.252s
[2K
| Adam | epoch: 007 | loss: 0.01466 - acc: 0.9994 -- iter: 064/144
[A[ATraining Step: 33  | total loss: [1m[32m0.01218[0m[0m | time: 24.375s
[2K
| Adam | epoch: 007 | loss: 0.01218 - acc: 0.9995 -- iter: 096/144
[A[ATraining Step: 34  | total loss: [1m[32m0.06210[0m[0m | time: 32.209s
[2K
| Adam | epoch: 007 | loss: 0.06210 - acc: 0.9929 -- iter: 128/144
[A[ATraining Step: 35  | total loss: [1m[32m0.04979[0m[0m | time: 39.173s
[2K
| Adam | epoch: 007 | loss: 0.04979 - acc: 0.9944 | val_loss: 0.64970 - val_acc: 0.5556 -- iter: 144/144
--
Training Step: 36  | total loss: [1m[32m0.04162[0m[0m | time: 4.669s
[2K
| Adam | epoch: 008 | loss: 0.04162 - acc: 0.9955 -- iter: 032/144
[A[ATraining Step: 37  | total loss: [1m[32m0.03502[0m[0m | time: 12.843s
[2K
| Adam | epoch: 008 | loss: 0.03502 - acc: 0.9964 -- iter: 064/144
[A[ATraining Step: 38  | total loss: [1m[32m0.05185[0m[0m | time: 21.143s
[2K
| Adam | epoch: 008 | loss: 0.05185 - acc: 0.9910 -- iter: 096/144
[A[ATraining Step: 39  | total loss: [1m[32m0.04316[0m[0m | time: 29.106s
[2K
| Adam | epoch: 008 | loss: 0.04316 - acc: 0.9927 -- iter: 128/144
[A[ATraining Step: 40  | total loss: [1m[32m0.03783[0m[0m | time: 39.463s
[2K
| Adam | epoch: 008 | loss: 0.03783 - acc: 0.9941 | val_loss: 0.79372 - val_acc: 0.4444 -- iter: 144/144
--
Training Step: 41  | total loss: [1m[32m0.03129[0m[0m | time: 4.922s
[2K
| Adam | epoch: 009 | loss: 0.03129 - acc: 0.9952 -- iter: 032/144
[A[ATraining Step: 42  | total loss: [1m[32m0.02737[0m[0m | time: 9.582s
[2K
| Adam | epoch: 009 | loss: 0.02737 - acc: 0.9961 -- iter: 064/144
[A[ATraining Step: 43  | total loss: [1m[32m0.02390[0m[0m | time: 17.710s
[2K
| Adam | epoch: 009 | loss: 0.02390 - acc: 0.9967 -- iter: 096/144
[A[ATraining Step: 44  | total loss: [1m[32m0.02040[0m[0m | time: 25.907s
[2K
| Adam | epoch: 009 | loss: 0.02040 - acc: 0.9973 -- iter: 128/144
[A[ATraining Step: 45  | total loss: [1m[32m0.01858[0m[0m | time: 36.220s
[2K
| Adam | epoch: 009 | loss: 0.01858 - acc: 0.9978 | val_loss: 1.22652 - val_acc: 0.4444 -- iter: 144/144
--
Training Step: 46  | total loss: [1m[32m0.05063[0m[0m | time: 8.430s
[2K
| Adam | epoch: 010 | loss: 0.05063 - acc: 0.9929 -- iter: 032/144
[A[ATraining Step: 47  | total loss: [1m[32m0.04328[0m[0m | time: 12.974s
[2K
| Adam | epoch: 010 | loss: 0.04328 - acc: 0.9941 -- iter: 064/144
[A[ATraining Step: 48  | total loss: [1m[32m0.03776[0m[0m | time: 17.612s
[2K
| Adam | epoch: 010 | loss: 0.03776 - acc: 0.9950 -- iter: 096/144
[A[ATraining Step: 49  | total loss: [1m[32m0.03280[0m[0m | time: 25.752s
[2K
| Adam | epoch: 010 | loss: 0.03280 - acc: 0.9958 -- iter: 128/144
[A[ATraining Step: 50  | total loss: [1m[32m0.04392[0m[0m | time: 36.246s
[2K
| Adam | epoch: 010 | loss: 0.04392 - acc: 0.9916 | val_loss: 1.65806 - val_acc: 0.4444 -- iter: 144/144
--
Training Step: 51  | total loss: [1m[32m0.03769[0m[0m | time: 8.478s
[2K
| Adam | epoch: 011 | loss: 0.03769 - acc: 0.9929 -- iter: 032/144
[A[ATraining Step: 52  | total loss: [1m[32m0.03242[0m[0m | time: 16.525s
[2K
| Adam | epoch: 011 | loss: 0.03242 - acc: 0.9940 -- iter: 064/144
[A[ATraining Step: 53  | total loss: [1m[32m0.02820[0m[0m | time: 21.520s
[2K
| Adam | epoch: 011 | loss: 0.02820 - acc: 0.9949 -- iter: 096/144
[A[ATraining Step: 54  | total loss: [1m[32m0.02435[0m[0m | time: 26.206s
[2K
| Adam | epoch: 011 | loss: 0.02435 - acc: 0.9956 -- iter: 128/144
[A[ATraining Step: 55  | total loss: [1m[32m0.02112[0m[0m | time: 36.614s
[2K
| Adam | epoch: 011 | loss: 0.02112 - acc: 0.9962 | val_loss: 1.62261 - val_acc: 0.4667 -- iter: 144/144
--
Training Step: 56  | total loss: [1m[32m0.01869[0m[0m | time: 8.246s
[2K
| Adam | epoch: 012 | loss: 0.01869 - acc: 0.9968 -- iter: 032/144
[A[ATraining Step: 57  | total loss: [1m[32m0.01646[0m[0m | time: 16.284s
[2K
| Adam | epoch: 012 | loss: 0.01646 - acc: 0.9972 -- iter: 064/144
[A[ATraining Step: 58  | total loss: [1m[32m0.01480[0m[0m | time: 24.352s
[2K
| Adam | epoch: 012 | loss: 0.01480 - acc: 0.9976 -- iter: 096/144
[A[ATraining Step: 59  | total loss: [1m[32m0.01331[0m[0m | time: 28.949s
[2K
| Adam | epoch: 012 | loss: 0.01331 - acc: 0.9979 -- iter: 128/144
[A[ATraining Step: 60  | total loss: [1m[32m0.01245[0m[0m | time: 35.654s
[2K
| Adam | epoch: 012 | loss: 0.01245 - acc: 0.9982 | val_loss: 0.89833 - val_acc: 0.6000 -- iter: 144/144
--
Training Step: 61  | total loss: [1m[32m0.01144[0m[0m | time: 7.994s
[2K
| Adam | epoch: 013 | loss: 0.01144 - acc: 0.9984 -- iter: 032/144
[A[ATraining Step: 62  | total loss: [1m[32m0.01022[0m[0m | time: 16.084s
[2K
| Adam | epoch: 013 | loss: 0.01022 - acc: 0.9986 -- iter: 064/144
[A[ATraining Step: 63  | total loss: [1m[32m0.00913[0m[0m | time: 24.080s
[2K
| Adam | epoch: 013 | loss: 0.00913 - acc: 0.9988 -- iter: 096/144
[A[ATraining Step: 64  | total loss: [1m[32m0.00824[0m[0m | time: 32.055s
[2K
| Adam | epoch: 013 | loss: 0.00824 - acc: 0.9990 -- iter: 128/144
[A[ATraining Step: 65  | total loss: [1m[32m0.00758[0m[0m | time: 38.759s
[2K
| Adam | epoch: 013 | loss: 0.00758 - acc: 0.9991 | val_loss: 0.54575 - val_acc: 0.7556 -- iter: 144/144
--
Training Step: 66  | total loss: [1m[32m0.00686[0m[0m | time: 4.650s
[2K
| Adam | epoch: 014 | loss: 0.00686 - acc: 0.9992 -- iter: 032/144
[A[ATraining Step: 67  | total loss: [1m[32m0.00623[0m[0m | time: 12.649s
[2K
| Adam | epoch: 014 | loss: 0.00623 - acc: 0.9993 -- iter: 064/144
[A[ATraining Step: 68  | total loss: [1m[32m0.00564[0m[0m | time: 20.566s
[2K
| Adam | epoch: 014 | loss: 0.00564 - acc: 0.9994 -- iter: 096/144
[A[ATraining Step: 69  | total loss: [1m[32m0.00513[0m[0m | time: 28.593s
[2K
| Adam | epoch: 014 | loss: 0.00513 - acc: 0.9994 -- iter: 128/144
[A[ATraining Step: 70  | total loss: [1m[32m0.00480[0m[0m | time: 38.853s
[2K
| Adam | epoch: 014 | loss: 0.00480 - acc: 0.9995 | val_loss: 0.52832 - val_acc: 0.8222 -- iter: 144/144
--
Training Step: 71  | total loss: [1m[32m0.00437[0m[0m | time: 4.919s
[2K
| Adam | epoch: 015 | loss: 0.00437 - acc: 0.9996 -- iter: 032/144
[A[ATraining Step: 72  | total loss: [1m[32m0.00421[0m[0m | time: 10.089s
[2K
| Adam | epoch: 015 | loss: 0.00421 - acc: 0.9996 -- iter: 064/144
[A[ATraining Step: 73  | total loss: [1m[32m0.00404[0m[0m | time: 18.081s
[2K
| Adam | epoch: 015 | loss: 0.00404 - acc: 0.9997 -- iter: 096/144
[A[ATraining Step: 74  | total loss: [1m[32m0.00386[0m[0m | time: 26.325s
[2K
| Adam | epoch: 015 | loss: 0.00386 - acc: 0.9997 -- iter: 128/144
[A[ATraining Step: 75  | total loss: [1m[32m0.00355[0m[0m | time: 36.322s
[2K
| Adam | epoch: 015 | loss: 0.00355 - acc: 0.9997 | val_loss: 0.58733 - val_acc: 0.7778 -- iter: 144/144
--
Validation AUC:0.86
Validation AUPRC:0.9118789389178437
Test AUC:0.9033613445378152
Test AUPRC:0.9565767973856208
BestTestF1Score	0.86	0.62	0.82	0.83	0.89	25	5	12	3	0.1
BestTestMCCScore	0.9	0.8	0.89	1.0	0.82	23	0	17	5	0.46
BestTestAccuracyScore	0.9	0.8	0.89	1.0	0.82	23	0	17	5	0.46
BestValidationF1Score	0.82	0.59	0.8	0.81	0.84	21	5	15	4	0.1
BestValidationMCC	0.82	0.67	0.82	0.95	0.72	18	1	19	7	0.46
BestValidationAccuracy	0.82	0.67	0.82	0.95	0.72	18	1	19	7	0.46
TestPredictions (Threshold:0.46)
CHEMBL55594,TP,ACT,1.0	CHEMBL2336005,TP,ACT,0.8100000023841858	CHEMBL2392223,TN,INACT,0.009999999776482582	CHEMBL1908395,TP,ACT,0.9100000262260437	CHEMBL3335362,TN,INACT,0.09000000357627869	CHEMBL3781795,TN,INACT,0.23999999463558197	CHEMBL1721885,TP,ACT,0.7200000286102295	CHEMBL2392375,TN,INACT,0.019999999552965164	CHEMBL54283,TP,ACT,1.0	CHEMBL1909651,TN,INACT,0.05999999865889549	CHEMBL59042,TP,ACT,1.0	CHEMBL52513,TP,ACT,1.0	CHEMBL1908397,FN,ACT,0.03999999910593033	CHEMBL1289926,TP,ACT,0.8399999737739563	CHEMBL1767275,TN,INACT,0.11999999731779099	CHEMBL3426225,TP,ACT,0.8199999928474426	CHEMBL605003,FN,ACT,0.1599999964237213	CHEMBL3651299,TP,ACT,0.6600000262260437	CHEMBL230614,TP,ACT,0.6299999952316284	CHEMBL469346,TN,INACT,0.11999999731779099	CHEMBL400402,TP,ACT,0.9900000095367432	CHEMBL2392366,TN,INACT,0.2199999988079071	CHEMBL572881,FN,ACT,0.009999999776482582	CHEMBL1910757,TN,INACT,0.029999999329447746	CHEMBL3318027,FN,ACT,0.07000000029802322	CHEMBL77638,TP,ACT,0.6200000047683716	CHEMBL3102933,TN,INACT,0.09000000357627869	CHEMBL3780632,TP,ACT,1.0	CHEMBL1933802,TN,INACT,0.1899999976158142	CHEMBL1922122,TN,INACT,0.03999999910593033	CHEMBL218632,TP,ACT,0.9800000190734863	CHEMBL3609656,TN,INACT,0.07000000029802322	CHEMBL300853,TP,ACT,1.0	CHEMBL249821,TP,ACT,0.699999988079071	CHEMBL215152,TP,ACT,0.8299999833106995	CHEMBL386051,TP,ACT,0.9200000166893005	CHEMBL3609567,TN,INACT,0.03999999910593033	CHEMBL1276179,TP,ACT,0.9900000095367432	CHEMBL292930,TP,ACT,1.0	CHEMBL396487,TN,INACT,0.009999999776482582	CHEMBL1933806,TN,INACT,0.03999999910593033	CHEMBL457614,FN,ACT,0.10999999940395355	CHEMBL3617738,TP,ACT,0.49000000953674316	CHEMBL131098,TN,INACT,0.09000000357627869	CHEMBL1908396,TP,ACT,0.8999999761581421	

