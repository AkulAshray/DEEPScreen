CNNModel CHEMBL5469 adam 0.001 30 256 0 0.8 False True
Number of active compounds :	193
Number of inactive compounds :	193
---------------------------------
Run id: CNNModel_CHEMBL5469_adam_0.001_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5469_adam_0.001_30_256_0.8_True/
---------------------------------
Training samples: 191
Validation samples: 60
--
Training Step: 1  | time: 0.842s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/191
[A[ATraining Step: 2  | total loss: [1m[32m0.62346[0m[0m | time: 1.493s
[2K
| Adam | epoch: 001 | loss: 0.62346 - acc: 0.5625 -- iter: 064/191
[A[ATraining Step: 3  | total loss: [1m[32m0.67779[0m[0m | time: 2.151s
[2K
| Adam | epoch: 001 | loss: 0.67779 - acc: 0.5625 -- iter: 096/191
[A[ATraining Step: 4  | total loss: [1m[32m0.69498[0m[0m | time: 2.816s
[2K
| Adam | epoch: 001 | loss: 0.69498 - acc: 0.5156 -- iter: 128/191
[A[ATraining Step: 5  | total loss: [1m[32m0.70053[0m[0m | time: 3.468s
[2K
| Adam | epoch: 001 | loss: 0.70053 - acc: 0.4615 -- iter: 160/191
[A[ATraining Step: 6  | total loss: [1m[32m0.69929[0m[0m | time: 5.149s
[2K
| Adam | epoch: 001 | loss: 0.69929 - acc: 0.4260 | val_loss: 0.69349 - val_acc: 0.4500 -- iter: 191/191
--
Training Step: 7  | total loss: [1m[32m0.69526[0m[0m | time: 0.666s
[2K
| Adam | epoch: 002 | loss: 0.69526 - acc: 0.4994 -- iter: 032/191
[A[ATraining Step: 8  | total loss: [1m[32m0.69383[0m[0m | time: 1.308s
[2K
| Adam | epoch: 002 | loss: 0.69383 - acc: 0.5270 -- iter: 064/191
[A[ATraining Step: 9  | total loss: [1m[32m0.69350[0m[0m | time: 1.964s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.5127 -- iter: 096/191
[A[ATraining Step: 10  | total loss: [1m[32m0.69268[0m[0m | time: 2.628s
[2K
| Adam | epoch: 002 | loss: 0.69268 - acc: 0.5845 -- iter: 128/191
[A[ATraining Step: 11  | total loss: [1m[32m0.69362[0m[0m | time: 3.299s
[2K
| Adam | epoch: 002 | loss: 0.69362 - acc: 0.4852 -- iter: 160/191
[A[ATraining Step: 12  | total loss: [1m[32m0.69340[0m[0m | time: 4.992s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.4919 | val_loss: 0.69364 - val_acc: 0.4500 -- iter: 191/191
--
Training Step: 13  | total loss: [1m[32m0.69356[0m[0m | time: 0.679s
[2K
| Adam | epoch: 003 | loss: 0.69356 - acc: 0.4686 -- iter: 032/191
[A[ATraining Step: 14  | total loss: [1m[32m0.69345[0m[0m | time: 1.349s
[2K
| Adam | epoch: 003 | loss: 0.69345 - acc: 0.4748 -- iter: 064/191
[A[ATraining Step: 15  | total loss: [1m[32m0.69337[0m[0m | time: 2.013s
[2K
| Adam | epoch: 003 | loss: 0.69337 - acc: 0.4784 -- iter: 096/191
[A[ATraining Step: 16  | total loss: [1m[32m0.69330[0m[0m | time: 2.691s
[2K
| Adam | epoch: 003 | loss: 0.69330 - acc: 0.4865 -- iter: 128/191
[A[ATraining Step: 17  | total loss: [1m[32m0.69329[0m[0m | time: 3.350s
[2K
| Adam | epoch: 003 | loss: 0.69329 - acc: 0.4801 -- iter: 160/191
[A[ATraining Step: 18  | total loss: [1m[32m0.69322[0m[0m | time: 5.034s
[2K
| Adam | epoch: 003 | loss: 0.69322 - acc: 0.4978 | val_loss: 0.69327 - val_acc: 0.4500 -- iter: 191/191
--
Training Step: 19  | total loss: [1m[32m0.69311[0m[0m | time: 0.663s
[2K
| Adam | epoch: 004 | loss: 0.69311 - acc: 0.5506 -- iter: 032/191
[A[ATraining Step: 20  | total loss: [1m[32m0.69323[0m[0m | time: 1.316s
[2K
| Adam | epoch: 004 | loss: 0.69323 - acc: 0.5042 -- iter: 064/191
[A[ATraining Step: 21  | total loss: [1m[32m0.69324[0m[0m | time: 1.968s
[2K
| Adam | epoch: 004 | loss: 0.69324 - acc: 0.4979 -- iter: 096/191
[A[ATraining Step: 22  | total loss: [1m[32m0.69322[0m[0m | time: 2.627s
[2K
| Adam | epoch: 004 | loss: 0.69322 - acc: 0.4937 -- iter: 128/191
[A[ATraining Step: 23  | total loss: [1m[32m0.69324[0m[0m | time: 3.272s
[2K
| Adam | epoch: 004 | loss: 0.69324 - acc: 0.4774 -- iter: 160/191
[A[ATraining Step: 24  | total loss: [1m[32m0.69331[0m[0m | time: 4.922s
[2K
| Adam | epoch: 004 | loss: 0.69331 - acc: 0.4662 | val_loss: 0.69278 - val_acc: 0.5500 -- iter: 191/191
--
Training Step: 25  | total loss: [1m[32m0.69314[0m[0m | time: 0.684s
[2K
| Adam | epoch: 005 | loss: 0.69314 - acc: 0.5095 -- iter: 032/191
[A[ATraining Step: 26  | total loss: [1m[32m0.69284[0m[0m | time: 1.328s
[2K
| Adam | epoch: 005 | loss: 0.69284 - acc: 0.5483 -- iter: 064/191
[A[ATraining Step: 27  | total loss: [1m[32m0.69325[0m[0m | time: 1.970s
[2K
| Adam | epoch: 005 | loss: 0.69325 - acc: 0.5038 -- iter: 096/191
[A[ATraining Step: 28  | total loss: [1m[32m0.69319[0m[0m | time: 2.601s
[2K
| Adam | epoch: 005 | loss: 0.69319 - acc: 0.5069 -- iter: 128/191
[A[ATraining Step: 29  | total loss: [1m[32m0.69315[0m[0m | time: 3.261s
[2K
| Adam | epoch: 005 | loss: 0.69315 - acc: 0.5091 -- iter: 160/191
[A[ATraining Step: 30  | total loss: [1m[32m0.69340[0m[0m | time: 4.898s
[2K
| Adam | epoch: 005 | loss: 0.69340 - acc: 0.4921 | val_loss: 0.69228 - val_acc: 0.5500 -- iter: 191/191
--
Training Step: 31  | total loss: [1m[32m0.69349[0m[0m | time: 0.661s
[2K
| Adam | epoch: 006 | loss: 0.69349 - acc: 0.4867 -- iter: 032/191
[A[ATraining Step: 32  | total loss: [1m[32m0.69368[0m[0m | time: 1.313s
[2K
| Adam | epoch: 006 | loss: 0.69368 - acc: 0.4757 -- iter: 064/191
[A[ATraining Step: 33  | total loss: [1m[32m0.69310[0m[0m | time: 1.993s
[2K
| Adam | epoch: 006 | loss: 0.69310 - acc: 0.5084 -- iter: 096/191
[A[ATraining Step: 34  | total loss: [1m[32m0.69278[0m[0m | time: 2.631s
[2K
| Adam | epoch: 006 | loss: 0.69278 - acc: 0.5267 -- iter: 128/191
[A[ATraining Step: 35  | total loss: [1m[32m0.69278[0m[0m | time: 3.264s
[2K
| Adam | epoch: 006 | loss: 0.69278 - acc: 0.5245 -- iter: 160/191
[A[ATraining Step: 36  | total loss: [1m[32m0.69278[0m[0m | time: 4.927s
[2K
| Adam | epoch: 006 | loss: 0.69278 - acc: 0.5228 | val_loss: 0.69199 - val_acc: 0.5500 -- iter: 191/191
--
Training Step: 37  | total loss: [1m[32m0.69331[0m[0m | time: 0.668s
[2K
| Adam | epoch: 007 | loss: 0.69331 - acc: 0.4995 -- iter: 032/191
[A[ATraining Step: 38  | total loss: [1m[32m0.69298[0m[0m | time: 1.327s
[2K
| Adam | epoch: 007 | loss: 0.69298 - acc: 0.5118 -- iter: 064/191
[A[ATraining Step: 39  | total loss: [1m[32m0.69364[0m[0m | time: 1.986s
[2K
| Adam | epoch: 007 | loss: 0.69364 - acc: 0.4856 -- iter: 096/191
[A[ATraining Step: 40  | total loss: [1m[32m0.69356[0m[0m | time: 2.657s
[2K
| Adam | epoch: 007 | loss: 0.69356 - acc: 0.4883 -- iter: 128/191
[A[ATraining Step: 41  | total loss: [1m[32m0.69312[0m[0m | time: 3.319s
[2K
| Adam | epoch: 007 | loss: 0.69312 - acc: 0.5077 -- iter: 160/191
[A[ATraining Step: 42  | total loss: [1m[32m0.69323[0m[0m | time: 4.984s
[2K
| Adam | epoch: 007 | loss: 0.69323 - acc: 0.5034 | val_loss: 0.69201 - val_acc: 0.5500 -- iter: 191/191
--
Training Step: 43  | total loss: [1m[32m0.69329[0m[0m | time: 0.653s
[2K
| Adam | epoch: 008 | loss: 0.69329 - acc: 0.4999 -- iter: 032/191
[A[ATraining Step: 44  | total loss: [1m[32m0.69314[0m[0m | time: 1.316s
[2K
| Adam | epoch: 008 | loss: 0.69314 - acc: 0.5054 -- iter: 064/191
[A[ATraining Step: 45  | total loss: [1m[32m0.69316[0m[0m | time: 1.993s
[2K
| Adam | epoch: 008 | loss: 0.69316 - acc: 0.5045 -- iter: 096/191
[A[ATraining Step: 46  | total loss: [1m[32m0.69343[0m[0m | time: 2.633s
[2K
| Adam | epoch: 008 | loss: 0.69343 - acc: 0.4933 -- iter: 128/191
[A[ATraining Step: 47  | total loss: [1m[32m0.69329[0m[0m | time: 3.327s
[2K
| Adam | epoch: 008 | loss: 0.69329 - acc: 0.4995 -- iter: 160/191
[A[ATraining Step: 48  | total loss: [1m[32m0.69371[0m[0m | time: 4.962s
[2K
| Adam | epoch: 008 | loss: 0.69371 - acc: 0.4795 | val_loss: 0.69218 - val_acc: 0.5500 -- iter: 191/191
--
Training Step: 49  | total loss: [1m[32m0.69335[0m[0m | time: 0.660s
[2K
| Adam | epoch: 009 | loss: 0.69335 - acc: 0.4955 -- iter: 032/191
[A[ATraining Step: 50  | total loss: [1m[32m0.69311[0m[0m | time: 1.314s
[2K
| Adam | epoch: 009 | loss: 0.69311 - acc: 0.5087 -- iter: 064/191
[A[ATraining Step: 51  | total loss: [1m[32m0.69272[0m[0m | time: 1.949s
[2K
| Adam | epoch: 009 | loss: 0.69272 - acc: 0.5264 -- iter: 096/191
[A[ATraining Step: 52  | total loss: [1m[32m0.69250[0m[0m | time: 2.598s
[2K
| Adam | epoch: 009 | loss: 0.69250 - acc: 0.5365 -- iter: 128/191
[A[ATraining Step: 53  | total loss: [1m[32m0.69248[0m[0m | time: 3.241s
[2K
| Adam | epoch: 009 | loss: 0.69248 - acc: 0.5357 -- iter: 160/191
[A[ATraining Step: 54  | total loss: [1m[32m0.69233[0m[0m | time: 4.900s
[2K
| Adam | epoch: 009 | loss: 0.69233 - acc: 0.5396 | val_loss: 0.69159 - val_acc: 0.5500 -- iter: 191/191
--
Training Step: 55  | total loss: [1m[32m0.69275[0m[0m | time: 0.638s
[2K
| Adam | epoch: 010 | loss: 0.69275 - acc: 0.5250 -- iter: 032/191
[A[ATraining Step: 56  | total loss: [1m[32m0.69285[0m[0m | time: 1.288s
[2K
| Adam | epoch: 010 | loss: 0.69285 - acc: 0.5193 -- iter: 064/191
[A[ATraining Step: 57  | total loss: [1m[32m0.69301[0m[0m | time: 1.941s
[2K
| Adam | epoch: 010 | loss: 0.69301 - acc: 0.5144 -- iter: 096/191
[A[ATraining Step: 58  | total loss: [1m[32m0.69337[0m[0m | time: 2.580s
[2K
| Adam | epoch: 010 | loss: 0.69337 - acc: 0.5039 -- iter: 128/191
[A[ATraining Step: 59  | total loss: [1m[32m0.69277[0m[0m | time: 3.212s
[2K
| Adam | epoch: 010 | loss: 0.69277 - acc: 0.5201 -- iter: 160/191
[A[ATraining Step: 60  | total loss: [1m[32m0.69327[0m[0m | time: 4.895s
[2K
| Adam | epoch: 010 | loss: 0.69327 - acc: 0.5051 | val_loss: 0.69138 - val_acc: 0.5500 -- iter: 191/191
--
Training Step: 61  | total loss: [1m[32m0.69310[0m[0m | time: 0.653s
[2K
| Adam | epoch: 011 | loss: 0.69310 - acc: 0.5085 -- iter: 032/191
[A[ATraining Step: 62  | total loss: [1m[32m0.69340[0m[0m | time: 1.286s
[2K
| Adam | epoch: 011 | loss: 0.69340 - acc: 0.4994 -- iter: 064/191
[A[ATraining Step: 63  | total loss: [1m[32m0.69332[0m[0m | time: 1.923s
[2K
| Adam | epoch: 011 | loss: 0.69332 - acc: 0.5015 -- iter: 096/191
[A[ATraining Step: 64  | total loss: [1m[32m0.69324[0m[0m | time: 2.567s
[2K
| Adam | epoch: 011 | loss: 0.69324 - acc: 0.5033 -- iter: 128/191
[A[ATraining Step: 65  | total loss: [1m[32m0.69312[0m[0m | time: 3.213s
[2K
| Adam | epoch: 011 | loss: 0.69312 - acc: 0.5068 -- iter: 160/191
[A[ATraining Step: 66  | total loss: [1m[32m0.69315[0m[0m | time: 4.879s
[2K
| Adam | epoch: 011 | loss: 0.69315 - acc: 0.5059 | val_loss: 0.69153 - val_acc: 0.5500 -- iter: 191/191
--
Training Step: 67  | total loss: [1m[32m0.69313[0m[0m | time: 0.671s
[2K
| Adam | epoch: 012 | loss: 0.69313 - acc: 0.5052 -- iter: 032/191
[A[ATraining Step: 68  | total loss: [1m[32m0.69324[0m[0m | time: 1.322s
[2K
| Adam | epoch: 012 | loss: 0.69324 - acc: 0.5009 -- iter: 064/191
[A[ATraining Step: 69  | total loss: [1m[32m0.69292[0m[0m | time: 1.952s
[2K
| Adam | epoch: 012 | loss: 0.69292 - acc: 0.5081 -- iter: 096/191
[A[ATraining Step: 70  | total loss: [1m[32m0.69272[0m[0m | time: 2.593s
[2K
| Adam | epoch: 012 | loss: 0.69272 - acc: 0.5128 -- iter: 128/191
[A[ATraining Step: 71  | total loss: [1m[32m0.69251[0m[0m | time: 3.250s
[2K
| Adam | epoch: 012 | loss: 0.69251 - acc: 0.5168 -- iter: 160/191
[A[ATraining Step: 72  | total loss: [1m[32m0.69269[0m[0m | time: 4.930s
[2K
| Adam | epoch: 012 | loss: 0.69269 - acc: 0.5114 | val_loss: 0.69032 - val_acc: 0.5500 -- iter: 191/191
--
Training Step: 73  | total loss: [1m[32m0.69245[0m[0m | time: 0.691s
[2K
| Adam | epoch: 013 | loss: 0.69245 - acc: 0.5136 -- iter: 032/191
[A[ATraining Step: 74  | total loss: [1m[32m0.69211[0m[0m | time: 1.342s
[2K
| Adam | epoch: 013 | loss: 0.69211 - acc: 0.5155 -- iter: 064/191
[A[ATraining Step: 75  | total loss: [1m[32m0.69207[0m[0m | time: 2.014s
[2K
| Adam | epoch: 013 | loss: 0.69207 - acc: 0.5139 -- iter: 096/191
[A[ATraining Step: 76  | total loss: [1m[32m0.69162[0m[0m | time: 2.665s
[2K
| Adam | epoch: 013 | loss: 0.69162 - acc: 0.5191 -- iter: 128/191
[A[ATraining Step: 77  | total loss: [1m[32m0.69168[0m[0m | time: 3.300s
[2K
| Adam | epoch: 013 | loss: 0.69168 - acc: 0.5119 -- iter: 160/191
[A[ATraining Step: 78  | total loss: [1m[32m0.69131[0m[0m | time: 4.953s
[2K
| Adam | epoch: 013 | loss: 0.69131 - acc: 0.5056 | val_loss: 0.68828 - val_acc: 0.5833 -- iter: 191/191
--
Training Step: 79  | total loss: [1m[32m0.69112[0m[0m | time: 0.670s
[2K
| Adam | epoch: 014 | loss: 0.69112 - acc: 0.5180 -- iter: 032/191
[A[ATraining Step: 80  | total loss: [1m[32m0.68968[0m[0m | time: 1.335s
[2K
| Adam | epoch: 014 | loss: 0.68968 - acc: 0.5385 -- iter: 064/191
[A[ATraining Step: 81  | total loss: [1m[32m0.68849[0m[0m | time: 1.996s
[2K
| Adam | epoch: 014 | loss: 0.68849 - acc: 0.5409 -- iter: 096/191
[A[ATraining Step: 82  | total loss: [1m[32m0.68789[0m[0m | time: 2.658s
[2K
| Adam | epoch: 014 | loss: 0.68789 - acc: 0.5400 -- iter: 128/191
[A[ATraining Step: 83  | total loss: [1m[32m0.68740[0m[0m | time: 3.300s
[2K
| Adam | epoch: 014 | loss: 0.68740 - acc: 0.5360 -- iter: 160/191
[A[ATraining Step: 84  | total loss: [1m[32m0.68561[0m[0m | time: 4.953s
[2K
| Adam | epoch: 014 | loss: 0.68561 - acc: 0.5404 | val_loss: 0.70580 - val_acc: 0.4500 -- iter: 191/191
--
Training Step: 85  | total loss: [1m[32m0.68435[0m[0m | time: 0.720s
[2K
| Adam | epoch: 015 | loss: 0.68435 - acc: 0.5477 -- iter: 032/191
[A[ATraining Step: 86  | total loss: [1m[32m0.68556[0m[0m | time: 1.380s
[2K
| Adam | epoch: 015 | loss: 0.68556 - acc: 0.5398 -- iter: 064/191
[A[ATraining Step: 87  | total loss: [1m[32m0.68470[0m[0m | time: 2.019s
[2K
| Adam | epoch: 015 | loss: 0.68470 - acc: 0.5421 -- iter: 096/191
[A[ATraining Step: 88  | total loss: [1m[32m0.68383[0m[0m | time: 2.688s
[2K
| Adam | epoch: 015 | loss: 0.68383 - acc: 0.5441 -- iter: 128/191
[A[ATraining Step: 89  | total loss: [1m[32m0.67772[0m[0m | time: 3.373s
[2K
| Adam | epoch: 015 | loss: 0.67772 - acc: 0.5678 -- iter: 160/191
[A[ATraining Step: 90  | total loss: [1m[32m0.67420[0m[0m | time: 5.030s
[2K
| Adam | epoch: 015 | loss: 0.67420 - acc: 0.5704 | val_loss: 0.67361 - val_acc: 0.5167 -- iter: 191/191
--
Training Step: 91  | total loss: [1m[32m0.67986[0m[0m | time: 0.654s
[2K
| Adam | epoch: 016 | loss: 0.67986 - acc: 0.5650 -- iter: 032/191
[A[ATraining Step: 92  | total loss: [1m[32m0.67624[0m[0m | time: 1.322s
[2K
| Adam | epoch: 016 | loss: 0.67624 - acc: 0.5730 -- iter: 064/191
[A[ATraining Step: 93  | total loss: [1m[32m0.67001[0m[0m | time: 1.986s
[2K
| Adam | epoch: 016 | loss: 0.67001 - acc: 0.5845 -- iter: 096/191
[A[ATraining Step: 94  | total loss: [1m[32m0.66935[0m[0m | time: 2.667s
[2K
| Adam | epoch: 016 | loss: 0.66935 - acc: 0.5854 -- iter: 128/191
[A[ATraining Step: 95  | total loss: [1m[32m0.67526[0m[0m | time: 3.326s
[2K
| Adam | epoch: 016 | loss: 0.67526 - acc: 0.5737 -- iter: 160/191
[A[ATraining Step: 96  | total loss: [1m[32m0.66913[0m[0m | time: 5.008s
[2K
| Adam | epoch: 016 | loss: 0.66913 - acc: 0.5882 | val_loss: 0.72178 - val_acc: 0.5667 -- iter: 191/191
--
Training Step: 97  | total loss: [1m[32m0.66450[0m[0m | time: 0.645s
[2K
| Adam | epoch: 017 | loss: 0.66450 - acc: 0.5950 -- iter: 032/191
[A[ATraining Step: 98  | total loss: [1m[32m0.65658[0m[0m | time: 1.296s
[2K
| Adam | epoch: 017 | loss: 0.65658 - acc: 0.6000 -- iter: 064/191
[A[ATraining Step: 99  | total loss: [1m[32m0.64760[0m[0m | time: 1.975s
[2K
| Adam | epoch: 017 | loss: 0.64760 - acc: 0.6110 -- iter: 096/191
[A[ATraining Step: 100  | total loss: [1m[32m0.64039[0m[0m | time: 2.628s
[2K
| Adam | epoch: 017 | loss: 0.64039 - acc: 0.6280 -- iter: 128/191
[A[ATraining Step: 101  | total loss: [1m[32m0.62975[0m[0m | time: 3.278s
[2K
| Adam | epoch: 017 | loss: 0.62975 - acc: 0.6465 -- iter: 160/191
[A[ATraining Step: 102  | total loss: [1m[32m0.63175[0m[0m | time: 4.938s
[2K
| Adam | epoch: 017 | loss: 0.63175 - acc: 0.6350 | val_loss: 0.71443 - val_acc: 0.5833 -- iter: 191/191
--
Training Step: 103  | total loss: [1m[32m0.63089[0m[0m | time: 0.657s
[2K
| Adam | epoch: 018 | loss: 0.63089 - acc: 0.6308 -- iter: 032/191
[A[ATraining Step: 104  | total loss: [1m[32m0.61680[0m[0m | time: 1.307s
[2K
| Adam | epoch: 018 | loss: 0.61680 - acc: 0.6459 -- iter: 064/191
[A[ATraining Step: 105  | total loss: [1m[32m0.61802[0m[0m | time: 1.950s
[2K
| Adam | epoch: 018 | loss: 0.61802 - acc: 0.6458 -- iter: 096/191
[A[ATraining Step: 106  | total loss: [1m[32m0.60901[0m[0m | time: 2.613s
[2K
| Adam | epoch: 018 | loss: 0.60901 - acc: 0.6490 -- iter: 128/191
[A[ATraining Step: 107  | total loss: [1m[32m0.59027[0m[0m | time: 3.278s
[2K
| Adam | epoch: 018 | loss: 0.59027 - acc: 0.6684 -- iter: 160/191
[A[ATraining Step: 108  | total loss: [1m[32m0.57692[0m[0m | time: 4.930s
[2K
| Adam | epoch: 018 | loss: 0.57692 - acc: 0.6797 | val_loss: 0.76851 - val_acc: 0.5333 -- iter: 191/191
--
Training Step: 109  | total loss: [1m[32m0.55364[0m[0m | time: 0.684s
[2K
| Adam | epoch: 019 | loss: 0.55364 - acc: 0.6993 -- iter: 032/191
[A[ATraining Step: 110  | total loss: [1m[32m0.55405[0m[0m | time: 1.335s
[2K
| Adam | epoch: 019 | loss: 0.55405 - acc: 0.7012 -- iter: 064/191
[A[ATraining Step: 111  | total loss: [1m[32m0.53889[0m[0m | time: 1.969s
[2K
| Adam | epoch: 019 | loss: 0.53889 - acc: 0.7092 -- iter: 096/191
[A[ATraining Step: 112  | total loss: [1m[32m0.52010[0m[0m | time: 2.622s
[2K
| Adam | epoch: 019 | loss: 0.52010 - acc: 0.7254 -- iter: 128/191
[A[ATraining Step: 113  | total loss: [1m[32m0.50206[0m[0m | time: 3.284s
[2K
| Adam | epoch: 019 | loss: 0.50206 - acc: 0.7399 -- iter: 160/191
[A[ATraining Step: 114  | total loss: [1m[32m0.49002[0m[0m | time: 4.950s
[2K
| Adam | epoch: 019 | loss: 0.49002 - acc: 0.7503 | val_loss: 0.58759 - val_acc: 0.7500 -- iter: 191/191
--
Training Step: 115  | total loss: [1m[32m0.47043[0m[0m | time: 0.655s
[2K
| Adam | epoch: 020 | loss: 0.47043 - acc: 0.7659 -- iter: 032/191
[A[ATraining Step: 116  | total loss: [1m[32m0.45050[0m[0m | time: 1.304s
[2K
| Adam | epoch: 020 | loss: 0.45050 - acc: 0.7768 -- iter: 064/191
[A[ATraining Step: 117  | total loss: [1m[32m0.43340[0m[0m | time: 1.951s
[2K
| Adam | epoch: 020 | loss: 0.43340 - acc: 0.7866 -- iter: 096/191
[A[ATraining Step: 118  | total loss: [1m[32m0.40958[0m[0m | time: 2.581s
[2K
| Adam | epoch: 020 | loss: 0.40958 - acc: 0.7986 -- iter: 128/191
[A[ATraining Step: 119  | total loss: [1m[32m0.41152[0m[0m | time: 3.238s
[2K
| Adam | epoch: 020 | loss: 0.41152 - acc: 0.8026 -- iter: 160/191
[A[ATraining Step: 120  | total loss: [1m[32m0.40680[0m[0m | time: 4.907s
[2K
| Adam | epoch: 020 | loss: 0.40680 - acc: 0.8094 | val_loss: 0.78158 - val_acc: 0.6333 -- iter: 191/191
--
Training Step: 121  | total loss: [1m[32m0.38475[0m[0m | time: 0.660s
[2K
| Adam | epoch: 021 | loss: 0.38475 - acc: 0.8191 -- iter: 032/191
[A[ATraining Step: 122  | total loss: [1m[32m0.37886[0m[0m | time: 1.319s
[2K
| Adam | epoch: 021 | loss: 0.37886 - acc: 0.8278 -- iter: 064/191
[A[ATraining Step: 123  | total loss: [1m[32m0.35203[0m[0m | time: 1.979s
[2K
| Adam | epoch: 021 | loss: 0.35203 - acc: 0.8388 -- iter: 096/191
[A[ATraining Step: 124  | total loss: [1m[32m0.35124[0m[0m | time: 2.639s
[2K
| Adam | epoch: 021 | loss: 0.35124 - acc: 0.8362 -- iter: 128/191
[A[ATraining Step: 125  | total loss: [1m[32m0.34266[0m[0m | time: 3.287s
[2K
| Adam | epoch: 021 | loss: 0.34266 - acc: 0.8401 -- iter: 160/191
[A[ATraining Step: 126  | total loss: [1m[32m0.32297[0m[0m | time: 4.924s
[2K
| Adam | epoch: 021 | loss: 0.32297 - acc: 0.8464 | val_loss: 0.78156 - val_acc: 0.6667 -- iter: 191/191
--
Training Step: 127  | total loss: [1m[32m0.30499[0m[0m | time: 0.863s
[2K
| Adam | epoch: 022 | loss: 0.30499 - acc: 0.8521 -- iter: 032/191
[A[ATraining Step: 128  | total loss: [1m[32m0.28263[0m[0m | time: 1.671s
[2K
| Adam | epoch: 022 | loss: 0.28263 - acc: 0.8669 -- iter: 064/191
[A[ATraining Step: 129  | total loss: [1m[32m0.27990[0m[0m | time: 2.520s
[2K
| Adam | epoch: 022 | loss: 0.27990 - acc: 0.8739 -- iter: 096/191
[A[ATraining Step: 130  | total loss: [1m[32m0.26446[0m[0m | time: 3.194s
[2K
| Adam | epoch: 022 | loss: 0.26446 - acc: 0.8803 -- iter: 128/191
[A[ATraining Step: 131  | total loss: [1m[32m0.24244[0m[0m | time: 3.848s
[2K
| Adam | epoch: 022 | loss: 0.24244 - acc: 0.8891 -- iter: 160/191
[A[ATraining Step: 132  | total loss: [1m[32m0.24221[0m[0m | time: 5.494s
[2K
| Adam | epoch: 022 | loss: 0.24221 - acc: 0.8908 | val_loss: 0.69363 - val_acc: 0.7000 -- iter: 191/191
--
Training Step: 133  | total loss: [1m[32m0.22813[0m[0m | time: 0.858s
[2K
| Adam | epoch: 023 | loss: 0.22813 - acc: 0.8985 -- iter: 032/191
[A[ATraining Step: 134  | total loss: [1m[32m0.21248[0m[0m | time: 1.688s
[2K
| Adam | epoch: 023 | loss: 0.21248 - acc: 0.9054 -- iter: 064/191
[A[ATraining Step: 135  | total loss: [1m[32m0.19573[0m[0m | time: 2.359s
[2K
| Adam | epoch: 023 | loss: 0.19573 - acc: 0.9149 -- iter: 096/191
[A[ATraining Step: 136  | total loss: [1m[32m0.19505[0m[0m | time: 3.017s
[2K
| Adam | epoch: 023 | loss: 0.19505 - acc: 0.9172 -- iter: 128/191
[A[ATraining Step: 137  | total loss: [1m[32m0.17701[0m[0m | time: 3.681s
[2K
| Adam | epoch: 023 | loss: 0.17701 - acc: 0.9254 -- iter: 160/191
[A[ATraining Step: 138  | total loss: [1m[32m0.17773[0m[0m | time: 5.337s
[2K
| Adam | epoch: 023 | loss: 0.17773 - acc: 0.9235 | val_loss: 0.72144 - val_acc: 0.7500 -- iter: 191/191
--
Training Step: 139  | total loss: [1m[32m0.16614[0m[0m | time: 0.650s
[2K
| Adam | epoch: 024 | loss: 0.16614 - acc: 0.9280 -- iter: 032/191
[A[ATraining Step: 140  | total loss: [1m[32m0.15157[0m[0m | time: 1.296s
[2K
| Adam | epoch: 024 | loss: 0.15157 - acc: 0.9352 -- iter: 064/191
[A[ATraining Step: 141  | total loss: [1m[32m0.14615[0m[0m | time: 1.961s
[2K
| Adam | epoch: 024 | loss: 0.14615 - acc: 0.9385 -- iter: 096/191
[A[ATraining Step: 142  | total loss: [1m[32m0.14617[0m[0m | time: 2.617s
[2K
| Adam | epoch: 024 | loss: 0.14617 - acc: 0.9415 -- iter: 128/191
[A[ATraining Step: 143  | total loss: [1m[32m0.14895[0m[0m | time: 3.270s
[2K
| Adam | epoch: 024 | loss: 0.14895 - acc: 0.9442 -- iter: 160/191
[A[ATraining Step: 144  | total loss: [1m[32m0.13814[0m[0m | time: 5.168s
[2K
| Adam | epoch: 024 | loss: 0.13814 - acc: 0.9498 | val_loss: 0.97076 - val_acc: 0.6833 -- iter: 191/191
--
Training Step: 145  | total loss: [1m[32m0.12883[0m[0m | time: 0.668s
[2K
| Adam | epoch: 025 | loss: 0.12883 - acc: 0.9517 -- iter: 032/191
[A[ATraining Step: 146  | total loss: [1m[32m0.11654[0m[0m | time: 1.292s
[2K
| Adam | epoch: 025 | loss: 0.11654 - acc: 0.9565 -- iter: 064/191
[A[ATraining Step: 147  | total loss: [1m[32m0.10754[0m[0m | time: 1.930s
[2K
| Adam | epoch: 025 | loss: 0.10754 - acc: 0.9609 -- iter: 096/191
[A[ATraining Step: 148  | total loss: [1m[32m0.09964[0m[0m | time: 2.596s
[2K
| Adam | epoch: 025 | loss: 0.09964 - acc: 0.9648 -- iter: 128/191
[A[ATraining Step: 149  | total loss: [1m[32m0.09106[0m[0m | time: 3.246s
[2K
| Adam | epoch: 025 | loss: 0.09106 - acc: 0.9683 -- iter: 160/191
[A[ATraining Step: 150  | total loss: [1m[32m0.09003[0m[0m | time: 4.923s
[2K
| Adam | epoch: 025 | loss: 0.09003 - acc: 0.9684 | val_loss: 1.35188 - val_acc: 0.6667 -- iter: 191/191
--
Training Step: 151  | total loss: [1m[32m0.08731[0m[0m | time: 0.683s
[2K
| Adam | epoch: 026 | loss: 0.08731 - acc: 0.9715 -- iter: 032/191
[A[ATraining Step: 152  | total loss: [1m[32m0.08145[0m[0m | time: 1.357s
[2K
| Adam | epoch: 026 | loss: 0.08145 - acc: 0.9744 -- iter: 064/191
[A[ATraining Step: 153  | total loss: [1m[32m0.08362[0m[0m | time: 2.013s
[2K
| Adam | epoch: 026 | loss: 0.08362 - acc: 0.9738 -- iter: 096/191
[A[ATraining Step: 154  | total loss: [1m[32m0.07662[0m[0m | time: 2.643s
[2K
| Adam | epoch: 026 | loss: 0.07662 - acc: 0.9764 -- iter: 128/191
[A[ATraining Step: 155  | total loss: [1m[32m0.07839[0m[0m | time: 3.323s
[2K
| Adam | epoch: 026 | loss: 0.07839 - acc: 0.9756 -- iter: 160/191
[A[ATraining Step: 156  | total loss: [1m[32m0.09835[0m[0m | time: 5.005s
[2K
| Adam | epoch: 026 | loss: 0.09835 - acc: 0.9718 | val_loss: 1.29500 - val_acc: 0.6500 -- iter: 191/191
--
Training Step: 157  | total loss: [1m[32m0.08888[0m[0m | time: 0.655s
[2K
| Adam | epoch: 027 | loss: 0.08888 - acc: 0.9746 -- iter: 032/191
[A[ATraining Step: 158  | total loss: [1m[32m0.08122[0m[0m | time: 1.307s
[2K
| Adam | epoch: 027 | loss: 0.08122 - acc: 0.9771 -- iter: 064/191
[A[ATraining Step: 159  | total loss: [1m[32m0.08227[0m[0m | time: 1.971s
[2K
| Adam | epoch: 027 | loss: 0.08227 - acc: 0.9763 -- iter: 096/191
[A[ATraining Step: 160  | total loss: [1m[32m0.07643[0m[0m | time: 2.620s
[2K
| Adam | epoch: 027 | loss: 0.07643 - acc: 0.9787 -- iter: 128/191
[A[ATraining Step: 161  | total loss: [1m[32m0.07002[0m[0m | time: 3.271s
[2K
| Adam | epoch: 027 | loss: 0.07002 - acc: 0.9808 -- iter: 160/191
[A[ATraining Step: 162  | total loss: [1m[32m0.06387[0m[0m | time: 5.106s
[2K
| Adam | epoch: 027 | loss: 0.06387 - acc: 0.9827 | val_loss: 1.00904 - val_acc: 0.7333 -- iter: 191/191
--
Training Step: 163  | total loss: [1m[32m0.05866[0m[0m | time: 0.674s
[2K
| Adam | epoch: 028 | loss: 0.05866 - acc: 0.9844 -- iter: 032/191
[A[ATraining Step: 164  | total loss: [1m[32m0.30404[0m[0m | time: 1.324s
[2K
| Adam | epoch: 028 | loss: 0.30404 - acc: 0.9422 -- iter: 064/191
[A[ATraining Step: 165  | total loss: [1m[32m0.29843[0m[0m | time: 2.009s
[2K
| Adam | epoch: 028 | loss: 0.29843 - acc: 0.9355 -- iter: 096/191
[A[ATraining Step: 166  | total loss: [1m[32m0.28354[0m[0m | time: 2.662s
[2K
| Adam | epoch: 028 | loss: 0.28354 - acc: 0.9357 -- iter: 128/191
[A[ATraining Step: 167  | total loss: [1m[32m0.25728[0m[0m | time: 3.463s
[2K
| Adam | epoch: 028 | loss: 0.25728 - acc: 0.9421 -- iter: 160/191
[A[ATraining Step: 168  | total loss: [1m[32m0.23275[0m[0m | time: 5.102s
[2K
| Adam | epoch: 028 | loss: 0.23275 - acc: 0.9479 | val_loss: 1.21070 - val_acc: 0.6500 -- iter: 191/191
--
Training Step: 169  | total loss: [1m[32m0.21457[0m[0m | time: 0.661s
[2K
| Adam | epoch: 029 | loss: 0.21457 - acc: 0.9531 -- iter: 032/191
[A[ATraining Step: 170  | total loss: [1m[32m0.20121[0m[0m | time: 1.323s
[2K
| Adam | epoch: 029 | loss: 0.20121 - acc: 0.9547 -- iter: 064/191
[A[ATraining Step: 171  | total loss: [1m[32m0.20915[0m[0m | time: 2.004s
[2K
| Adam | epoch: 029 | loss: 0.20915 - acc: 0.9561 -- iter: 096/191
[A[ATraining Step: 172  | total loss: [1m[32m0.18946[0m[0m | time: 2.638s
[2K
| Adam | epoch: 029 | loss: 0.18946 - acc: 0.9605 -- iter: 128/191
[A[ATraining Step: 173  | total loss: [1m[32m0.17668[0m[0m | time: 3.294s
[2K
| Adam | epoch: 029 | loss: 0.17668 - acc: 0.9613 -- iter: 160/191
[A[ATraining Step: 174  | total loss: [1m[32m0.16399[0m[0m | time: 5.156s
[2K
| Adam | epoch: 029 | loss: 0.16399 - acc: 0.9652 | val_loss: 0.82559 - val_acc: 0.6667 -- iter: 191/191
--
Training Step: 175  | total loss: [1m[32m0.14966[0m[0m | time: 0.888s
[2K
| Adam | epoch: 030 | loss: 0.14966 - acc: 0.9687 -- iter: 032/191
[A[ATraining Step: 176  | total loss: [1m[32m0.13608[0m[0m | time: 1.546s
[2K
| Adam | epoch: 030 | loss: 0.13608 - acc: 0.9718 -- iter: 064/191
[A[ATraining Step: 177  | total loss: [1m[32m0.12379[0m[0m | time: 2.208s
[2K
| Adam | epoch: 030 | loss: 0.12379 - acc: 0.9746 -- iter: 096/191
[A[ATraining Step: 178  | total loss: [1m[32m0.13888[0m[0m | time: 2.863s
[2K
| Adam | epoch: 030 | loss: 0.13888 - acc: 0.9709 -- iter: 128/191
[A[ATraining Step: 179  | total loss: [1m[32m0.12648[0m[0m | time: 3.543s
[2K
| Adam | epoch: 030 | loss: 0.12648 - acc: 0.9738 -- iter: 160/191
[A[ATraining Step: 180  | total loss: [1m[32m0.12314[0m[0m | time: 5.217s
[2K
| Adam | epoch: 030 | loss: 0.12314 - acc: 0.9733 | val_loss: 1.07275 - val_acc: 0.6833 -- iter: 191/191
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7530864197530863
Validation AUPRC:0.7516538117745846
Test AUC:0.8255555555555556
Test AUPRC:0.8503481154601993
BestTestF1Score	0.77	0.57	0.78	0.81	0.73	22	5	25	8	0.12
BestTestMCCScore	0.77	0.57	0.78	0.81	0.73	22	5	25	8	0.12
BestTestAccuracyScore	0.77	0.57	0.78	0.81	0.73	22	5	25	8	0.12
BestValidationF1Score	0.68	0.43	0.72	0.69	0.67	18	8	25	9	0.12
BestValidationMCC	0.68	0.43	0.72	0.69	0.67	18	8	25	9	0.12
BestValidationAccuracy	0.68	0.43	0.72	0.69	0.67	18	8	25	9	0.12
TestPredictions (Threshold:0.12)
CHEMBL1910760,TN,INACT,0.0	CHEMBL1996902,TP,ACT,0.1599999964237213	CHEMBL1558223,FP,INACT,0.9399999976158142	CHEMBL3675452,TN,INACT,0.0	CHEMBL3797559,TN,INACT,0.009999999776482582	CHEMBL2207437,TP,ACT,0.9900000095367432	CHEMBL1537500,TN,INACT,0.029999999329447746	CHEMBL203006,TN,INACT,0.0	CHEMBL2430359,TP,ACT,0.9900000095367432	CHEMBL550856,TN,INACT,0.0	CHEMBL3196625,FP,INACT,0.25	CHEMBL1364528,TP,ACT,0.699999988079071	CHEMBL1908397,FN,ACT,0.0	CHEMBL99699,TN,INACT,0.009999999776482582	CHEMBL2207441,TP,ACT,0.9800000190734863	CHEMBL2312652,FP,INACT,0.7300000190734863	CHEMBL1806525,TN,INACT,0.0	CHEMBL502835,TP,ACT,0.9800000190734863	CHEMBL2207430,TP,ACT,0.6800000071525574	CHEMBL316887,FP,INACT,0.20000000298023224	CHEMBL2163623,TN,INACT,0.0	CHEMBL341473,FN,ACT,0.05000000074505806	CHEMBL1347829,TP,ACT,0.25	CHEMBL570846,TP,ACT,1.0	CHEMBL488089,TP,ACT,0.9599999785423279	CHEMBL601719,FN,ACT,0.009999999776482582	CHEMBL570706,TP,ACT,0.9900000095367432	CHEMBL1240703,FN,ACT,0.10000000149011612	CHEMBL102047,TN,INACT,0.029999999329447746	CHEMBL455680,TP,ACT,0.9900000095367432	CHEMBL2348176,TN,INACT,0.0	CHEMBL261692,TP,ACT,0.25999999046325684	CHEMBL1403448,FN,ACT,0.03999999910593033	CHEMBL570643,TP,ACT,0.9700000286102295	CHEMBL452341,TP,ACT,0.6100000143051147	CHEMBL1084546,TP,ACT,0.46000000834465027	CHEMBL3665654,TN,INACT,0.009999999776482582	CHEMBL3658032,TN,INACT,0.019999999552965164	CHEMBL322640,TN,INACT,0.0	CHEMBL472212,TP,ACT,0.699999988079071	CHEMBL1313195,TP,ACT,0.5899999737739563	CHEMBL261641,FN,ACT,0.0	CHEMBL1235213,TN,INACT,0.009999999776482582	CHEMBL557237,FP,INACT,0.8500000238418579	CHEMBL1910761,TN,INACT,0.0	CHEMBL488646,TN,INACT,0.009999999776482582	CHEMBL2448536,TP,ACT,0.9900000095367432	CHEMBL1909651,TN,INACT,0.0	CHEMBL1349451,TP,ACT,0.9300000071525574	CHEMBL1390871,TN,INACT,0.07000000029802322	CHEMBL328623,TN,INACT,0.0	CHEMBL486285,TN,INACT,0.009999999776482582	CHEMBL1372905,TN,INACT,0.029999999329447746	CHEMBL1414554,TP,ACT,0.20000000298023224	CHEMBL1714669,FN,ACT,0.029999999329447746	CHEMBL100675,TN,INACT,0.0	CHEMBL1528600,FN,ACT,0.0	CHEMBL454173,TP,ACT,0.5699999928474426	CHEMBL2163611,TN,INACT,0.009999999776482582	CHEMBL513336,TN,INACT,0.05999999865889549	

