ImageNetInceptionV2 CHEMBL5331 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	200
Number of inactive compounds :	200
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL5331_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL5331_adam_0.0005_30_0.8/
---------------------------------
Training samples: 233
Validation samples: 73
--
Training Step: 1  | time: 61.304s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/233
[A[ATraining Step: 2  | total loss: [1m[32m0.65201[0m[0m | time: 81.004s
[2K
| Adam | epoch: 001 | loss: 0.65201 - acc: 0.5062 -- iter: 064/233
[A[ATraining Step: 3  | total loss: [1m[32m0.62133[0m[0m | time: 102.204s
[2K
| Adam | epoch: 001 | loss: 0.62133 - acc: 0.6034 -- iter: 096/233
[A[ATraining Step: 4  | total loss: [1m[32m0.49627[0m[0m | time: 115.961s
[2K
| Adam | epoch: 001 | loss: 0.49627 - acc: 0.7368 -- iter: 128/233
[A[ATraining Step: 5  | total loss: [1m[32m0.65822[0m[0m | time: 142.534s
[2K
| Adam | epoch: 001 | loss: 0.65822 - acc: 0.6810 -- iter: 160/233
[A[ATraining Step: 6  | total loss: [1m[32m0.76895[0m[0m | time: 156.851s
[2K
| Adam | epoch: 001 | loss: 0.76895 - acc: 0.5847 -- iter: 192/233
[A[ATraining Step: 7  | total loss: [1m[32m0.75114[0m[0m | time: 168.214s
[2K
| Adam | epoch: 001 | loss: 0.75114 - acc: 0.4776 -- iter: 224/233
[A[ATraining Step: 8  | total loss: [1m[32m0.63653[0m[0m | time: 180.764s
[2K
| Adam | epoch: 001 | loss: 0.63653 - acc: 0.6308 | val_loss: 0.77633 - val_acc: 0.4795 -- iter: 233/233
--
Training Step: 9  | total loss: [1m[32m0.59100[0m[0m | time: 3.301s
[2K
| Adam | epoch: 002 | loss: 0.59100 - acc: 0.7086 -- iter: 032/233
[A[ATraining Step: 10  | total loss: [1m[32m0.33220[0m[0m | time: 26.788s
[2K
| Adam | epoch: 002 | loss: 0.33220 - acc: 0.8543 -- iter: 064/233
[A[ATraining Step: 11  | total loss: [1m[32m0.58271[0m[0m | time: 71.407s
[2K
| Adam | epoch: 002 | loss: 0.58271 - acc: 0.7457 -- iter: 096/233
[A[ATraining Step: 12  | total loss: [1m[32m0.64846[0m[0m | time: 80.996s
[2K
| Adam | epoch: 002 | loss: 0.64846 - acc: 0.7054 -- iter: 128/233
[A[ATraining Step: 13  | total loss: [1m[32m0.54390[0m[0m | time: 91.300s
[2K
| Adam | epoch: 002 | loss: 0.54390 - acc: 0.7513 -- iter: 160/233
[A[ATraining Step: 14  | total loss: [1m[32m0.41476[0m[0m | time: 100.212s
[2K
| Adam | epoch: 002 | loss: 0.41476 - acc: 0.8019 -- iter: 192/233
[A[ATraining Step: 15  | total loss: [1m[32m0.38689[0m[0m | time: 116.727s
[2K
| Adam | epoch: 002 | loss: 0.38689 - acc: 0.8305 -- iter: 224/233
[A[ATraining Step: 16  | total loss: [1m[32m0.33611[0m[0m | time: 139.913s
[2K
| Adam | epoch: 002 | loss: 0.33611 - acc: 0.8589 | val_loss: 1.05553 - val_acc: 0.4795 -- iter: 233/233
--
Training Step: 17  | total loss: [1m[32m0.29043[0m[0m | time: 3.167s
[2K
| Adam | epoch: 003 | loss: 0.29043 - acc: 0.8872 -- iter: 032/233
[A[ATraining Step: 18  | total loss: [1m[32m0.49615[0m[0m | time: 6.355s
[2K
| Adam | epoch: 003 | loss: 0.49615 - acc: 0.7724 -- iter: 064/233
[A[ATraining Step: 19  | total loss: [1m[32m0.48617[0m[0m | time: 31.536s
[2K
| Adam | epoch: 003 | loss: 0.48617 - acc: 0.7742 -- iter: 096/233
[A[ATraining Step: 20  | total loss: [1m[32m0.41319[0m[0m | time: 46.220s
[2K
| Adam | epoch: 003 | loss: 0.41319 - acc: 0.7966 -- iter: 128/233
[A[ATraining Step: 21  | total loss: [1m[32m0.38395[0m[0m | time: 55.265s
[2K
| Adam | epoch: 003 | loss: 0.38395 - acc: 0.8112 -- iter: 160/233
[A[ATraining Step: 22  | total loss: [1m[32m0.30393[0m[0m | time: 74.901s
[2K
| Adam | epoch: 003 | loss: 0.30393 - acc: 0.8585 -- iter: 192/233
[A[ATraining Step: 23  | total loss: [1m[32m0.25544[0m[0m | time: 102.843s
[2K
| Adam | epoch: 003 | loss: 0.25544 - acc: 0.8814 -- iter: 224/233
[A[ATraining Step: 24  | total loss: [1m[32m0.22155[0m[0m | time: 115.265s
[2K
| Adam | epoch: 003 | loss: 0.22155 - acc: 0.8972 | val_loss: 1.12086 - val_acc: 0.5205 -- iter: 233/233
--
Training Step: 25  | total loss: [1m[32m0.19943[0m[0m | time: 9.127s
[2K
| Adam | epoch: 004 | loss: 0.19943 - acc: 0.8997 -- iter: 032/233
[A[ATraining Step: 26  | total loss: [1m[32m0.17684[0m[0m | time: 12.283s
[2K
| Adam | epoch: 004 | loss: 0.17684 - acc: 0.9179 -- iter: 064/233
[A[ATraining Step: 27  | total loss: [1m[32m0.14273[0m[0m | time: 15.490s
[2K
| Adam | epoch: 004 | loss: 0.14273 - acc: 0.9390 -- iter: 096/233
[A[ATraining Step: 28  | total loss: [1m[32m0.10955[0m[0m | time: 24.618s
[2K
| Adam | epoch: 004 | loss: 0.10955 - acc: 0.9543 -- iter: 128/233
[A[ATraining Step: 29  | total loss: [1m[32m0.17216[0m[0m | time: 33.697s
[2K
| Adam | epoch: 004 | loss: 0.17216 - acc: 0.9274 -- iter: 160/233
[A[ATraining Step: 30  | total loss: [1m[32m0.18279[0m[0m | time: 43.843s
[2K
| Adam | epoch: 004 | loss: 0.18279 - acc: 0.9298 -- iter: 192/233
[A[ATraining Step: 31  | total loss: [1m[32m0.23080[0m[0m | time: 59.493s
[2K
| Adam | epoch: 004 | loss: 0.23080 - acc: 0.9388 -- iter: 224/233
[A[ATraining Step: 32  | total loss: [1m[32m0.18410[0m[0m | time: 72.588s
[2K
| Adam | epoch: 004 | loss: 0.18410 - acc: 0.9526 | val_loss: 1.24086 - val_acc: 0.5205 -- iter: 233/233
--
Training Step: 33  | total loss: [1m[32m0.15062[0m[0m | time: 19.848s
[2K
| Adam | epoch: 005 | loss: 0.15062 - acc: 0.9630 -- iter: 032/233
[A[ATraining Step: 34  | total loss: [1m[32m0.17009[0m[0m | time: 29.083s
[2K
| Adam | epoch: 005 | loss: 0.17009 - acc: 0.9575 -- iter: 064/233
[A[ATraining Step: 35  | total loss: [1m[32m0.18239[0m[0m | time: 32.378s
[2K
| Adam | epoch: 005 | loss: 0.18239 - acc: 0.9599 -- iter: 096/233
[A[ATraining Step: 36  | total loss: [1m[32m0.14697[0m[0m | time: 35.469s
[2K
| Adam | epoch: 005 | loss: 0.14697 - acc: 0.9681 -- iter: 128/233
[A[ATraining Step: 37  | total loss: [1m[32m0.11903[0m[0m | time: 44.477s
[2K
| Adam | epoch: 005 | loss: 0.11903 - acc: 0.9745 -- iter: 160/233
[A[ATraining Step: 38  | total loss: [1m[32m0.13980[0m[0m | time: 53.403s
[2K
| Adam | epoch: 005 | loss: 0.13980 - acc: 0.9611 -- iter: 192/233
[A[ATraining Step: 39  | total loss: [1m[32m0.12394[0m[0m | time: 63.867s
[2K
| Adam | epoch: 005 | loss: 0.12394 - acc: 0.9626 -- iter: 224/233
[A[ATraining Step: 40  | total loss: [1m[32m0.10814[0m[0m | time: 76.432s
[2K
| Adam | epoch: 005 | loss: 0.10814 - acc: 0.9696 | val_loss: 0.89783 - val_acc: 0.5753 -- iter: 233/233
--
Training Step: 41  | total loss: [1m[32m0.10133[0m[0m | time: 16.444s
[2K
| Adam | epoch: 006 | loss: 0.10133 - acc: 0.9694 -- iter: 032/233
[A[ATraining Step: 42  | total loss: [1m[32m0.09194[0m[0m | time: 35.102s
[2K
| Adam | epoch: 006 | loss: 0.09194 - acc: 0.9749 -- iter: 064/233
[A[ATraining Step: 43  | total loss: [1m[32m0.09322[0m[0m | time: 62.127s
[2K
| Adam | epoch: 006 | loss: 0.09322 - acc: 0.9738 -- iter: 096/233
[A[ATraining Step: 44  | total loss: [1m[32m0.09503[0m[0m | time: 66.043s
[2K
| Adam | epoch: 006 | loss: 0.09503 - acc: 0.9730 -- iter: 128/233
[A[ATraining Step: 45  | total loss: [1m[32m0.07970[0m[0m | time: 70.277s
[2K
| Adam | epoch: 006 | loss: 0.07970 - acc: 0.9776 -- iter: 160/233
[A[ATraining Step: 46  | total loss: [1m[32m0.06732[0m[0m | time: 112.693s
[2K
| Adam | epoch: 006 | loss: 0.06732 - acc: 0.9813 -- iter: 192/233
[A[ATraining Step: 47  | total loss: [1m[32m0.12425[0m[0m | time: 130.289s
[2K
| Adam | epoch: 006 | loss: 0.12425 - acc: 0.9588 -- iter: 224/233
[A[ATraining Step: 48  | total loss: [1m[32m0.11617[0m[0m | time: 199.827s
[2K
| Adam | epoch: 006 | loss: 0.11617 - acc: 0.9604 | val_loss: 0.64468 - val_acc: 0.6986 -- iter: 233/233
--
Training Step: 49  | total loss: [1m[32m0.12499[0m[0m | time: 15.739s
[2K
| Adam | epoch: 007 | loss: 0.12499 - acc: 0.9617 -- iter: 032/233
[A[ATraining Step: 50  | total loss: [1m[32m0.12232[0m[0m | time: 59.443s
[2K
| Adam | epoch: 007 | loss: 0.12232 - acc: 0.9628 -- iter: 064/233
[A[ATraining Step: 51  | total loss: [1m[32m0.10555[0m[0m | time: 103.278s
[2K
| Adam | epoch: 007 | loss: 0.10555 - acc: 0.9685 -- iter: 096/233
[A[ATraining Step: 52  | total loss: [1m[32m0.09497[0m[0m | time: 114.605s
[2K
| Adam | epoch: 007 | loss: 0.09497 - acc: 0.9732 -- iter: 128/233
[A[ATraining Step: 53  | total loss: [1m[32m0.08425[0m[0m | time: 118.543s
[2K
| Adam | epoch: 007 | loss: 0.08425 - acc: 0.9772 -- iter: 160/233
[A[ATraining Step: 54  | total loss: [1m[32m0.10583[0m[0m | time: 122.301s
[2K
| Adam | epoch: 007 | loss: 0.10583 - acc: 0.9643 -- iter: 192/233
[A[ATraining Step: 55  | total loss: [1m[32m0.09722[0m[0m | time: 133.265s
[2K
| Adam | epoch: 007 | loss: 0.09722 - acc: 0.9694 -- iter: 224/233
[A[ATraining Step: 56  | total loss: [1m[32m0.09378[0m[0m | time: 150.713s
[2K
| Adam | epoch: 007 | loss: 0.09378 - acc: 0.9693 | val_loss: 0.88687 - val_acc: 0.7123 -- iter: 233/233
--
Training Step: 57  | total loss: [1m[32m0.13519[0m[0m | time: 10.997s
[2K
| Adam | epoch: 008 | loss: 0.13519 - acc: 0.9563 -- iter: 032/233
[A[ATraining Step: 58  | total loss: [1m[32m0.13931[0m[0m | time: 21.415s
[2K
| Adam | epoch: 008 | loss: 0.13931 - acc: 0.9580 -- iter: 064/233
[A[ATraining Step: 59  | total loss: [1m[32m0.12792[0m[0m | time: 47.417s
[2K
| Adam | epoch: 008 | loss: 0.12792 - acc: 0.9636 -- iter: 096/233
[A[ATraining Step: 60  | total loss: [1m[32m0.11502[0m[0m | time: 58.201s
[2K
| Adam | epoch: 008 | loss: 0.11502 - acc: 0.9684 -- iter: 128/233
[A[ATraining Step: 61  | total loss: [1m[32m0.11094[0m[0m | time: 99.677s
[2K
| Adam | epoch: 008 | loss: 0.11094 - acc: 0.9685 -- iter: 160/233
[A[ATraining Step: 62  | total loss: [1m[32m0.10410[0m[0m | time: 103.803s
[2K
| Adam | epoch: 008 | loss: 0.10410 - acc: 0.9685 -- iter: 192/233
[A[ATraining Step: 63  | total loss: [1m[32m0.09158[0m[0m | time: 108.645s
[2K
| Adam | epoch: 008 | loss: 0.09158 - acc: 0.9725 -- iter: 224/233
[A[ATraining Step: 64  | total loss: [1m[32m0.08051[0m[0m | time: 145.957s
[2K
| Adam | epoch: 008 | loss: 0.08051 - acc: 0.9759 | val_loss: 2.39802 - val_acc: 0.5890 -- iter: 233/233
--
Training Step: 65  | total loss: [1m[32m0.08440[0m[0m | time: 60.174s
[2K
| Adam | epoch: 009 | loss: 0.08440 - acc: 0.9712 -- iter: 032/233
[A[ATraining Step: 66  | total loss: [1m[32m0.08035[0m[0m | time: 87.824s
[2K
| Adam | epoch: 009 | loss: 0.08035 - acc: 0.9747 -- iter: 064/233
[A[ATraining Step: 67  | total loss: [1m[32m0.07594[0m[0m | time: 163.747s
[2K
| Adam | epoch: 009 | loss: 0.07594 - acc: 0.9777 -- iter: 096/233
[A[ATraining Step: 68  | total loss: [1m[32m0.07269[0m[0m | time: 224.022s
[2K
| Adam | epoch: 009 | loss: 0.07269 - acc: 0.9767 -- iter: 128/233
[A[ATraining Step: 69  | total loss: [1m[32m0.07060[0m[0m | time: 267.615s
[2K
| Adam | epoch: 009 | loss: 0.07060 - acc: 0.9794 -- iter: 160/233
[A[ATraining Step: 70  | total loss: [1m[32m0.10097[0m[0m | time: 283.354s
[2K
| Adam | epoch: 009 | loss: 0.10097 - acc: 0.9710 -- iter: 192/233
[A[ATraining Step: 71  | total loss: [1m[32m0.09440[0m[0m | time: 288.688s
[2K
| Adam | epoch: 009 | loss: 0.09440 - acc: 0.9743 -- iter: 224/233
[A[ATraining Step: 72  | total loss: [1m[32m0.09598[0m[0m | time: 299.847s
[2K
| Adam | epoch: 009 | loss: 0.09598 - acc: 0.9647 | val_loss: 1.24393 - val_acc: 0.6986 -- iter: 233/233
--
Training Step: 73  | total loss: [1m[32m0.09284[0m[0m | time: 51.724s
[2K
| Adam | epoch: 010 | loss: 0.09284 - acc: 0.9686 -- iter: 032/233
[A[ATraining Step: 74  | total loss: [1m[32m0.09547[0m[0m | time: 75.299s
[2K
| Adam | epoch: 010 | loss: 0.09547 - acc: 0.9686 -- iter: 064/233
[A[ATraining Step: 75  | total loss: [1m[32m0.09419[0m[0m | time: 108.793s
[2K
| Adam | epoch: 010 | loss: 0.09419 - acc: 0.9686 -- iter: 096/233
[A[ATraining Step: 76  | total loss: [1m[32m0.12214[0m[0m | time: 143.316s
[2K
| Adam | epoch: 010 | loss: 0.12214 - acc: 0.9653 -- iter: 128/233
[A[ATraining Step: 77  | total loss: [1m[32m0.11668[0m[0m | time: 160.540s
[2K
| Adam | epoch: 010 | loss: 0.11668 - acc: 0.9657 -- iter: 160/233
[A[ATraining Step: 78  | total loss: [1m[32m0.10871[0m[0m | time: 174.137s
[2K
| Adam | epoch: 010 | loss: 0.10871 - acc: 0.9692 -- iter: 192/233
[A[ATraining Step: 79  | total loss: [1m[32m0.11778[0m[0m | time: 211.079s
[2K
| Adam | epoch: 010 | loss: 0.11778 - acc: 0.9692 -- iter: 224/233
[A[ATraining Step: 80  | total loss: [1m[32m0.11283[0m[0m | time: 223.265s
[2K
| Adam | epoch: 010 | loss: 0.11283 - acc: 0.9692 | val_loss: 0.96143 - val_acc: 0.6986 -- iter: 233/233
--
Training Step: 81  | total loss: [1m[32m0.10315[0m[0m | time: 3.934s
[2K
| Adam | epoch: 011 | loss: 0.10315 - acc: 0.9723 -- iter: 032/233
[A[ATraining Step: 82  | total loss: [1m[32m0.09401[0m[0m | time: 15.552s
[2K
| Adam | epoch: 011 | loss: 0.09401 - acc: 0.9750 -- iter: 064/233
[A[ATraining Step: 83  | total loss: [1m[32m0.10873[0m[0m | time: 26.880s
[2K
| Adam | epoch: 011 | loss: 0.10873 - acc: 0.9682 -- iter: 096/233
[A[ATraining Step: 84  | total loss: [1m[32m0.10167[0m[0m | time: 37.494s
[2K
| Adam | epoch: 011 | loss: 0.10167 - acc: 0.9713 -- iter: 128/233
[A[ATraining Step: 85  | total loss: [1m[32m0.10103[0m[0m | time: 48.988s
[2K
| Adam | epoch: 011 | loss: 0.10103 - acc: 0.9711 -- iter: 160/233
[A[ATraining Step: 86  | total loss: [1m[32m0.09276[0m[0m | time: 59.851s
[2K
| Adam | epoch: 011 | loss: 0.09276 - acc: 0.9740 -- iter: 192/233
[A[ATraining Step: 87  | total loss: [1m[32m0.09304[0m[0m | time: 70.521s
[2K
| Adam | epoch: 011 | loss: 0.09304 - acc: 0.9735 -- iter: 224/233
[A[ATraining Step: 88  | total loss: [1m[32m0.08649[0m[0m | time: 86.620s
[2K
| Adam | epoch: 011 | loss: 0.08649 - acc: 0.9761 | val_loss: 2.60316 - val_acc: 0.5890 -- iter: 233/233
--
Training Step: 89  | total loss: [1m[32m0.08049[0m[0m | time: 4.223s
[2K
| Adam | epoch: 012 | loss: 0.08049 - acc: 0.9785 -- iter: 032/233
[A[ATraining Step: 90  | total loss: [1m[32m0.08610[0m[0m | time: 8.065s
[2K
| Adam | epoch: 012 | loss: 0.08610 - acc: 0.9695 -- iter: 064/233
[A[ATraining Step: 91  | total loss: [1m[32m0.08009[0m[0m | time: 19.062s
[2K
| Adam | epoch: 012 | loss: 0.08009 - acc: 0.9726 -- iter: 096/233
[A[ATraining Step: 92  | total loss: [1m[32m0.07829[0m[0m | time: 29.612s
[2K
| Adam | epoch: 012 | loss: 0.07829 - acc: 0.9722 -- iter: 128/233
[A[ATraining Step: 93  | total loss: [1m[32m0.09610[0m[0m | time: 41.670s
[2K
| Adam | epoch: 012 | loss: 0.09610 - acc: 0.9656 -- iter: 160/233
[A[ATraining Step: 94  | total loss: [1m[32m0.08997[0m[0m | time: 50.352s
[2K
| Adam | epoch: 012 | loss: 0.08997 - acc: 0.9659 -- iter: 192/233
[A[ATraining Step: 95  | total loss: [1m[32m0.08493[0m[0m | time: 58.964s
[2K
| Adam | epoch: 012 | loss: 0.08493 - acc: 0.9662 -- iter: 224/233
[A[ATraining Step: 96  | total loss: [1m[32m0.07751[0m[0m | time: 71.319s
[2K
| Adam | epoch: 012 | loss: 0.07751 - acc: 0.9696 | val_loss: 3.89111 - val_acc: 0.5479 -- iter: 233/233
--
Training Step: 97  | total loss: [1m[32m0.07399[0m[0m | time: 8.780s
[2K
| Adam | epoch: 013 | loss: 0.07399 - acc: 0.9726 -- iter: 032/233
[A[ATraining Step: 98  | total loss: [1m[32m0.08190[0m[0m | time: 11.834s
[2K
| Adam | epoch: 013 | loss: 0.08190 - acc: 0.9660 -- iter: 064/233
[A[ATraining Step: 99  | total loss: [1m[32m0.07532[0m[0m | time: 14.902s
[2K
| Adam | epoch: 013 | loss: 0.07532 - acc: 0.9694 -- iter: 096/233
[A[ATraining Step: 100  | total loss: [1m[32m0.06818[0m[0m | time: 23.711s
[2K
| Adam | epoch: 013 | loss: 0.06818 - acc: 0.9724 -- iter: 128/233
[A[ATraining Step: 101  | total loss: [1m[32m0.06205[0m[0m | time: 32.143s
[2K
| Adam | epoch: 013 | loss: 0.06205 - acc: 0.9752 -- iter: 160/233
[A[ATraining Step: 102  | total loss: [1m[32m0.06617[0m[0m | time: 40.925s
[2K
| Adam | epoch: 013 | loss: 0.06617 - acc: 0.9714 -- iter: 192/233
[A[ATraining Step: 103  | total loss: [1m[32m0.10365[0m[0m | time: 49.910s
[2K
| Adam | epoch: 013 | loss: 0.10365 - acc: 0.9680 -- iter: 224/233
[A[ATraining Step: 104  | total loss: [1m[32m0.09444[0m[0m | time: 62.408s
[2K
| Adam | epoch: 013 | loss: 0.09444 - acc: 0.9712 | val_loss: 1.41411 - val_acc: 0.6712 -- iter: 233/233
--
Training Step: 105  | total loss: [1m[32m0.08658[0m[0m | time: 8.985s
[2K
| Adam | epoch: 014 | loss: 0.08658 - acc: 0.9741 -- iter: 032/233
[A[ATraining Step: 106  | total loss: [1m[32m0.09249[0m[0m | time: 17.462s
[2K
| Adam | epoch: 014 | loss: 0.09249 - acc: 0.9705 -- iter: 064/233
[A[ATraining Step: 107  | total loss: [1m[32m0.09317[0m[0m | time: 20.506s
[2K
| Adam | epoch: 014 | loss: 0.09317 - acc: 0.9703 -- iter: 096/233
[A[ATraining Step: 108  | total loss: [1m[32m0.09419[0m[0m | time: 23.616s
[2K
| Adam | epoch: 014 | loss: 0.09419 - acc: 0.9621 -- iter: 128/233
[A[ATraining Step: 109  | total loss: [1m[32m0.08505[0m[0m | time: 32.402s
[2K
| Adam | epoch: 014 | loss: 0.08505 - acc: 0.9659 -- iter: 160/233
[A[ATraining Step: 110  | total loss: [1m[32m0.08710[0m[0m | time: 41.216s
[2K
| Adam | epoch: 014 | loss: 0.08710 - acc: 0.9662 -- iter: 192/233
[A[ATraining Step: 111  | total loss: [1m[32m0.09876[0m[0m | time: 50.111s
[2K
| Adam | epoch: 014 | loss: 0.09876 - acc: 0.9665 -- iter: 224/233
[A[ATraining Step: 112  | total loss: [1m[32m0.11716[0m[0m | time: 62.249s
[2K
| Adam | epoch: 014 | loss: 0.11716 - acc: 0.9667 | val_loss: 0.99279 - val_acc: 0.7534 -- iter: 233/233
--
Training Step: 113  | total loss: [1m[32m0.10781[0m[0m | time: 8.583s
[2K
| Adam | epoch: 015 | loss: 0.10781 - acc: 0.9700 -- iter: 032/233
[A[ATraining Step: 114  | total loss: [1m[32m0.11639[0m[0m | time: 17.297s
[2K
| Adam | epoch: 015 | loss: 0.11639 - acc: 0.9668 -- iter: 064/233
[A[ATraining Step: 115  | total loss: [1m[32m0.10975[0m[0m | time: 26.256s
[2K
| Adam | epoch: 015 | loss: 0.10975 - acc: 0.9670 -- iter: 096/233
[A[ATraining Step: 116  | total loss: [1m[32m0.10339[0m[0m | time: 29.316s
[2K
| Adam | epoch: 015 | loss: 0.10339 - acc: 0.9703 -- iter: 128/233
[A[ATraining Step: 117  | total loss: [1m[32m0.09444[0m[0m | time: 32.317s
[2K
| Adam | epoch: 015 | loss: 0.09444 - acc: 0.9732 -- iter: 160/233
[A[ATraining Step: 118  | total loss: [1m[32m0.08613[0m[0m | time: 40.992s
[2K
| Adam | epoch: 015 | loss: 0.08613 - acc: 0.9759 -- iter: 192/233
[A[ATraining Step: 119  | total loss: [1m[32m0.10301[0m[0m | time: 49.543s
[2K
| Adam | epoch: 015 | loss: 0.10301 - acc: 0.9690 -- iter: 224/233
[A[ATraining Step: 120  | total loss: [1m[32m0.09752[0m[0m | time: 62.044s
[2K
| Adam | epoch: 015 | loss: 0.09752 - acc: 0.9721 | val_loss: 1.14785 - val_acc: 0.7260 -- iter: 233/233
--
Training Step: 121  | total loss: [1m[32m0.10090[0m[0m | time: 8.735s
[2K
| Adam | epoch: 016 | loss: 0.10090 - acc: 0.9717 -- iter: 032/233
[A[ATraining Step: 122  | total loss: [1m[32m0.09219[0m[0m | time: 17.371s
[2K
| Adam | epoch: 016 | loss: 0.09219 - acc: 0.9746 -- iter: 064/233
[A[ATraining Step: 123  | total loss: [1m[32m0.09023[0m[0m | time: 26.373s
[2K
| Adam | epoch: 016 | loss: 0.09023 - acc: 0.9740 -- iter: 096/233
[A[ATraining Step: 124  | total loss: [1m[32m0.09009[0m[0m | time: 35.020s
[2K
| Adam | epoch: 016 | loss: 0.09009 - acc: 0.9735 -- iter: 128/233
[A[ATraining Step: 125  | total loss: [1m[32m0.09522[0m[0m | time: 38.105s
[2K
| Adam | epoch: 016 | loss: 0.09522 - acc: 0.9730 -- iter: 160/233
[A[ATraining Step: 126  | total loss: [1m[32m0.09673[0m[0m | time: 41.196s
[2K
| Adam | epoch: 016 | loss: 0.09673 - acc: 0.9757 -- iter: 192/233
[A[ATraining Step: 127  | total loss: [1m[32m0.09261[0m[0m | time: 49.876s
[2K
| Adam | epoch: 016 | loss: 0.09261 - acc: 0.9781 -- iter: 224/233
[A[ATraining Step: 128  | total loss: [1m[32m0.09140[0m[0m | time: 62.270s
[2K
| Adam | epoch: 016 | loss: 0.09140 - acc: 0.9772 | val_loss: 4.42488 - val_acc: 0.5753 -- iter: 233/233
--
Training Step: 129  | total loss: [1m[32m0.08417[0m[0m | time: 8.849s
[2K
| Adam | epoch: 017 | loss: 0.08417 - acc: 0.9795 -- iter: 032/233
[A[ATraining Step: 130  | total loss: [1m[32m0.10218[0m[0m | time: 17.705s
[2K
| Adam | epoch: 017 | loss: 0.10218 - acc: 0.9753 -- iter: 064/233
[A[ATraining Step: 131  | total loss: [1m[32m0.09418[0m[0m | time: 26.563s
[2K
| Adam | epoch: 017 | loss: 0.09418 - acc: 0.9777 -- iter: 096/233
[A[ATraining Step: 132  | total loss: [1m[32m0.09206[0m[0m | time: 35.231s
[2K
| Adam | epoch: 017 | loss: 0.09206 - acc: 0.9768 -- iter: 128/233
[A[ATraining Step: 133  | total loss: [1m[32m0.09916[0m[0m | time: 43.748s
[2K
| Adam | epoch: 017 | loss: 0.09916 - acc: 0.9698 -- iter: 160/233
[A[ATraining Step: 134  | total loss: [1m[32m0.09346[0m[0m | time: 46.840s
[2K
| Adam | epoch: 017 | loss: 0.09346 - acc: 0.9728 -- iter: 192/233
[A[ATraining Step: 135  | total loss: [1m[32m0.08591[0m[0m | time: 49.867s
[2K
| Adam | epoch: 017 | loss: 0.08591 - acc: 0.9755 -- iter: 224/233
[A[ATraining Step: 136  | total loss: [1m[32m0.07862[0m[0m | time: 62.613s
[2K
| Adam | epoch: 017 | loss: 0.07862 - acc: 0.9780 | val_loss: 3.17583 - val_acc: 0.6438 -- iter: 233/233
--
Training Step: 137  | total loss: [1m[32m0.10420[0m[0m | time: 8.723s
[2K
| Adam | epoch: 018 | loss: 0.10420 - acc: 0.9708 -- iter: 032/233
[A[ATraining Step: 138  | total loss: [1m[32m0.09620[0m[0m | time: 17.505s
[2K
| Adam | epoch: 018 | loss: 0.09620 - acc: 0.9737 -- iter: 064/233
[A[ATraining Step: 139  | total loss: [1m[32m0.13085[0m[0m | time: 26.221s
[2K
| Adam | epoch: 018 | loss: 0.13085 - acc: 0.9701 -- iter: 096/233
[A[ATraining Step: 140  | total loss: [1m[32m0.12771[0m[0m | time: 34.641s
[2K
| Adam | epoch: 018 | loss: 0.12771 - acc: 0.9668 -- iter: 128/233
[A[ATraining Step: 141  | total loss: [1m[32m0.11542[0m[0m | time: 43.166s
[2K
| Adam | epoch: 018 | loss: 0.11542 - acc: 0.9702 -- iter: 160/233
[A[ATraining Step: 142  | total loss: [1m[32m0.11242[0m[0m | time: 51.741s
[2K
| Adam | epoch: 018 | loss: 0.11242 - acc: 0.9700 -- iter: 192/233
[A[ATraining Step: 143  | total loss: [1m[32m0.10510[0m[0m | time: 54.739s
[2K
| Adam | epoch: 018 | loss: 0.10510 - acc: 0.9730 -- iter: 224/233
[A[ATraining Step: 144  | total loss: [1m[32m0.10090[0m[0m | time: 61.308s
[2K
| Adam | epoch: 018 | loss: 0.10090 - acc: 0.9757 | val_loss: 7.85284 - val_acc: 0.4795 -- iter: 233/233
--
Training Step: 145  | total loss: [1m[32m0.09356[0m[0m | time: 11.568s
[2K
| Adam | epoch: 019 | loss: 0.09356 - acc: 0.9781 -- iter: 032/233
[A[ATraining Step: 146  | total loss: [1m[32m0.10751[0m[0m | time: 28.916s
[2K
| Adam | epoch: 019 | loss: 0.10751 - acc: 0.9710 -- iter: 064/233
[A[ATraining Step: 147  | total loss: [1m[32m0.09948[0m[0m | time: 39.919s
[2K
| Adam | epoch: 019 | loss: 0.09948 - acc: 0.9739 -- iter: 096/233
[A[ATraining Step: 148  | total loss: [1m[32m0.11293[0m[0m | time: 50.883s
[2K
| Adam | epoch: 019 | loss: 0.11293 - acc: 0.9733 -- iter: 128/233
[A[ATraining Step: 149  | total loss: [1m[32m0.10641[0m[0m | time: 66.397s
[2K
| Adam | epoch: 019 | loss: 0.10641 - acc: 0.9729 -- iter: 160/233
[A[ATraining Step: 150  | total loss: [1m[32m0.10514[0m[0m | time: 77.377s
[2K
| Adam | epoch: 019 | loss: 0.10514 - acc: 0.9662 -- iter: 192/233
[A[ATraining Step: 151  | total loss: [1m[32m0.09980[0m[0m | time: 92.023s
[2K
| Adam | epoch: 019 | loss: 0.09980 - acc: 0.9696 -- iter: 224/233
[A[ATraining Step: 152  | total loss: [1m[32m0.09291[0m[0m | time: 100.139s
[2K
| Adam | epoch: 019 | loss: 0.09291 - acc: 0.9726 | val_loss: 1.65723 - val_acc: 0.6986 -- iter: 233/233
--
Training Step: 153  | total loss: [1m[32m0.09103[0m[0m | time: 3.813s
[2K
| Adam | epoch: 020 | loss: 0.09103 - acc: 0.9754 -- iter: 032/233
[A[ATraining Step: 154  | total loss: [1m[32m0.08465[0m[0m | time: 16.636s
[2K
| Adam | epoch: 020 | loss: 0.08465 - acc: 0.9778 -- iter: 064/233
[A[ATraining Step: 155  | total loss: [1m[32m0.07747[0m[0m | time: 29.918s
[2K
| Adam | epoch: 020 | loss: 0.07747 - acc: 0.9801 -- iter: 096/233
[A[ATraining Step: 156  | total loss: [1m[32m0.07140[0m[0m | time: 40.482s
[2K
| Adam | epoch: 020 | loss: 0.07140 - acc: 0.9820 -- iter: 128/233
[A[ATraining Step: 157  | total loss: [1m[32m0.06754[0m[0m | time: 73.920s
[2K
| Adam | epoch: 020 | loss: 0.06754 - acc: 0.9838 -- iter: 160/233
[A[ATraining Step: 158  | total loss: [1m[32m0.06154[0m[0m | time: 84.314s
[2K
| Adam | epoch: 020 | loss: 0.06154 - acc: 0.9855 -- iter: 192/233
[A[ATraining Step: 159  | total loss: [1m[32m0.05669[0m[0m | time: 95.404s
[2K
| Adam | epoch: 020 | loss: 0.05669 - acc: 0.9869 -- iter: 224/233
[A[ATraining Step: 160  | total loss: [1m[32m0.05203[0m[0m | time: 112.086s
[2K
| Adam | epoch: 020 | loss: 0.05203 - acc: 0.9882 | val_loss: 1.31588 - val_acc: 0.6986 -- iter: 233/233
--
Training Step: 161  | total loss: [1m[32m0.04966[0m[0m | time: 3.793s
[2K
| Adam | epoch: 021 | loss: 0.04966 - acc: 0.9894 -- iter: 032/233
[A[ATraining Step: 162  | total loss: [1m[32m0.04548[0m[0m | time: 7.457s
[2K
| Adam | epoch: 021 | loss: 0.04548 - acc: 0.9905 -- iter: 064/233
[A[ATraining Step: 163  | total loss: [1m[32m0.04136[0m[0m | time: 20.534s
[2K
| Adam | epoch: 021 | loss: 0.04136 - acc: 0.9914 -- iter: 096/233
[A[ATraining Step: 164  | total loss: [1m[32m0.03925[0m[0m | time: 31.650s
[2K
| Adam | epoch: 021 | loss: 0.03925 - acc: 0.9923 -- iter: 128/233
[A[ATraining Step: 165  | total loss: [1m[32m0.03610[0m[0m | time: 43.861s
[2K
| Adam | epoch: 021 | loss: 0.03610 - acc: 0.9930 -- iter: 160/233
[A[ATraining Step: 166  | total loss: [1m[32m0.06537[0m[0m | time: 58.140s
[2K
| Adam | epoch: 021 | loss: 0.06537 - acc: 0.9906 -- iter: 192/233
[A[ATraining Step: 167  | total loss: [1m[32m0.05903[0m[0m | time: 72.202s
[2K
| Adam | epoch: 021 | loss: 0.05903 - acc: 0.9916 -- iter: 224/233
[A[ATraining Step: 168  | total loss: [1m[32m0.05332[0m[0m | time: 98.038s
[2K
| Adam | epoch: 021 | loss: 0.05332 - acc: 0.9924 | val_loss: 1.16426 - val_acc: 0.7260 -- iter: 233/233
--
Training Step: 169  | total loss: [1m[32m0.06280[0m[0m | time: 11.933s
[2K
| Adam | epoch: 022 | loss: 0.06280 - acc: 0.9900 -- iter: 032/233
[A[ATraining Step: 170  | total loss: [1m[32m0.05682[0m[0m | time: 15.675s
[2K
| Adam | epoch: 022 | loss: 0.05682 - acc: 0.9910 -- iter: 064/233
[A[ATraining Step: 171  | total loss: [1m[32m0.12274[0m[0m | time: 19.427s
[2K
| Adam | epoch: 022 | loss: 0.12274 - acc: 0.9697 -- iter: 096/233
[A[ATraining Step: 172  | total loss: [1m[32m0.12890[0m[0m | time: 31.211s
[2K
| Adam | epoch: 022 | loss: 0.12890 - acc: 0.9727 -- iter: 128/233
[A[ATraining Step: 173  | total loss: [1m[32m0.11685[0m[0m | time: 41.939s
[2K
| Adam | epoch: 022 | loss: 0.11685 - acc: 0.9755 -- iter: 160/233
[A[ATraining Step: 174  | total loss: [1m[32m0.11422[0m[0m | time: 52.700s
[2K
| Adam | epoch: 022 | loss: 0.11422 - acc: 0.9748 -- iter: 192/233
[A[ATraining Step: 175  | total loss: [1m[32m0.12604[0m[0m | time: 65.155s
[2K
| Adam | epoch: 022 | loss: 0.12604 - acc: 0.9742 -- iter: 224/233
[A[ATraining Step: 176  | total loss: [1m[32m0.11612[0m[0m | time: 80.383s
[2K
| Adam | epoch: 022 | loss: 0.11612 - acc: 0.9768 | val_loss: 2.65272 - val_acc: 0.5890 -- iter: 233/233
--
Training Step: 177  | total loss: [1m[32m0.10550[0m[0m | time: 10.594s
[2K
| Adam | epoch: 023 | loss: 0.10550 - acc: 0.9791 -- iter: 032/233
[A[ATraining Step: 178  | total loss: [1m[32m0.10353[0m[0m | time: 21.454s
[2K
| Adam | epoch: 023 | loss: 0.10353 - acc: 0.9749 -- iter: 064/233
[A[ATraining Step: 179  | total loss: [1m[32m0.09689[0m[0m | time: 25.214s
[2K
| Adam | epoch: 023 | loss: 0.09689 - acc: 0.9774 -- iter: 096/233
[A[ATraining Step: 180  | total loss: [1m[32m0.09131[0m[0m | time: 28.717s
[2K
| Adam | epoch: 023 | loss: 0.09131 - acc: 0.9797 -- iter: 128/233
[A[ATraining Step: 181  | total loss: [1m[32m0.08231[0m[0m | time: 39.604s
[2K
| Adam | epoch: 023 | loss: 0.08231 - acc: 0.9817 -- iter: 160/233
[A[ATraining Step: 182  | total loss: [1m[32m0.09053[0m[0m | time: 50.485s
[2K
| Adam | epoch: 023 | loss: 0.09053 - acc: 0.9742 -- iter: 192/233
[A[ATraining Step: 183  | total loss: [1m[32m0.11184[0m[0m | time: 61.120s
[2K
| Adam | epoch: 023 | loss: 0.11184 - acc: 0.9736 -- iter: 224/233
[A[ATraining Step: 184  | total loss: [1m[32m0.12316[0m[0m | time: 77.154s
[2K
| Adam | epoch: 023 | loss: 0.12316 - acc: 0.9731 | val_loss: 1.82506 - val_acc: 0.6712 -- iter: 233/233
--
Training Step: 185  | total loss: [1m[32m0.12351[0m[0m | time: 10.413s
[2K
| Adam | epoch: 024 | loss: 0.12351 - acc: 0.9665 -- iter: 032/233
[A[ATraining Step: 186  | total loss: [1m[32m0.11408[0m[0m | time: 21.333s
[2K
| Adam | epoch: 024 | loss: 0.11408 - acc: 0.9698 -- iter: 064/233
[A[ATraining Step: 187  | total loss: [1m[32m0.10992[0m[0m | time: 31.611s
[2K
| Adam | epoch: 024 | loss: 0.10992 - acc: 0.9697 -- iter: 096/233
[A[ATraining Step: 188  | total loss: [1m[32m0.10772[0m[0m | time: 35.250s
[2K
| Adam | epoch: 024 | loss: 0.10772 - acc: 0.9696 -- iter: 128/233
[A[ATraining Step: 189  | total loss: [1m[32m0.19691[0m[0m | time: 38.955s
[2K
| Adam | epoch: 024 | loss: 0.19691 - acc: 0.9393 -- iter: 160/233
[A[ATraining Step: 190  | total loss: [1m[32m0.20217[0m[0m | time: 50.354s
[2K
| Adam | epoch: 024 | loss: 0.20217 - acc: 0.9343 -- iter: 192/233
[A[ATraining Step: 191  | total loss: [1m[32m0.18292[0m[0m | time: 62.121s
[2K
| Adam | epoch: 024 | loss: 0.18292 - acc: 0.9408 -- iter: 224/233
[A[ATraining Step: 192  | total loss: [1m[32m0.17308[0m[0m | time: 76.958s
[2K
| Adam | epoch: 024 | loss: 0.17308 - acc: 0.9436 | val_loss: 1.79522 - val_acc: 0.6438 -- iter: 233/233
--
Training Step: 193  | total loss: [1m[32m0.16885[0m[0m | time: 10.606s
[2K
| Adam | epoch: 025 | loss: 0.16885 - acc: 0.9430 -- iter: 032/233
[A[ATraining Step: 194  | total loss: [1m[32m0.16507[0m[0m | time: 20.905s
[2K
| Adam | epoch: 025 | loss: 0.16507 - acc: 0.9393 -- iter: 064/233
[A[ATraining Step: 195  | total loss: [1m[32m0.15554[0m[0m | time: 31.086s
[2K
| Adam | epoch: 025 | loss: 0.15554 - acc: 0.9454 -- iter: 096/233
[A[ATraining Step: 196  | total loss: [1m[32m0.14111[0m[0m | time: 42.987s
[2K
| Adam | epoch: 025 | loss: 0.14111 - acc: 0.9509 -- iter: 128/233
[A[ATraining Step: 197  | total loss: [1m[32m0.13047[0m[0m | time: 46.613s
[2K
| Adam | epoch: 025 | loss: 0.13047 - acc: 0.9558 -- iter: 160/233
[A[ATraining Step: 198  | total loss: [1m[32m0.11821[0m[0m | time: 50.166s
[2K
| Adam | epoch: 025 | loss: 0.11821 - acc: 0.9602 -- iter: 192/233
[A[ATraining Step: 199  | total loss: [1m[32m0.10693[0m[0m | time: 60.352s
[2K
| Adam | epoch: 025 | loss: 0.10693 - acc: 0.9642 -- iter: 224/233
[A[ATraining Step: 200  | total loss: [1m[32m0.09720[0m[0m | time: 75.201s
[2K
| Adam | epoch: 025 | loss: 0.09720 - acc: 0.9678 | val_loss: 1.49019 - val_acc: 0.6712 -- iter: 233/233
--
Training Step: 201  | total loss: [1m[32m0.08996[0m[0m | time: 10.570s
[2K
| Adam | epoch: 026 | loss: 0.08996 - acc: 0.9710 -- iter: 032/233
[A[ATraining Step: 202  | total loss: [1m[32m0.08153[0m[0m | time: 21.011s
[2K
| Adam | epoch: 026 | loss: 0.08153 - acc: 0.9739 -- iter: 064/233
[A[ATraining Step: 203  | total loss: [1m[32m0.07502[0m[0m | time: 33.186s
[2K
| Adam | epoch: 026 | loss: 0.07502 - acc: 0.9765 -- iter: 096/233
[A[ATraining Step: 204  | total loss: [1m[32m0.06923[0m[0m | time: 43.980s
[2K
| Adam | epoch: 026 | loss: 0.06923 - acc: 0.9789 -- iter: 128/233
[A[ATraining Step: 205  | total loss: [1m[32m0.06689[0m[0m | time: 54.935s
[2K
| Adam | epoch: 026 | loss: 0.06689 - acc: 0.9778 -- iter: 160/233
[A[ATraining Step: 206  | total loss: [1m[32m0.06296[0m[0m | time: 58.601s
[2K
| Adam | epoch: 026 | loss: 0.06296 - acc: 0.9801 -- iter: 192/233
[A[ATraining Step: 207  | total loss: [1m[32m0.05698[0m[0m | time: 62.662s
[2K
| Adam | epoch: 026 | loss: 0.05698 - acc: 0.9821 -- iter: 224/233
[A[ATraining Step: 208  | total loss: [1m[32m0.05150[0m[0m | time: 78.361s
[2K
| Adam | epoch: 026 | loss: 0.05150 - acc: 0.9838 | val_loss: 1.97084 - val_acc: 0.5890 -- iter: 233/233
--
Training Step: 209  | total loss: [1m[32m0.04972[0m[0m | time: 10.553s
[2K
| Adam | epoch: 027 | loss: 0.04972 - acc: 0.9823 -- iter: 032/233
[A[ATraining Step: 210  | total loss: [1m[32m0.04604[0m[0m | time: 22.651s
[2K
| Adam | epoch: 027 | loss: 0.04604 - acc: 0.9841 -- iter: 064/233
[A[ATraining Step: 211  | total loss: [1m[32m0.36145[0m[0m | time: 32.988s
[2K
| Adam | epoch: 027 | loss: 0.36145 - acc: 0.9419 -- iter: 096/233
[A[ATraining Step: 212  | total loss: [1m[32m0.32794[0m[0m | time: 43.398s
[2K
| Adam | epoch: 027 | loss: 0.32794 - acc: 0.9477 -- iter: 128/233
[A[ATraining Step: 213  | total loss: [1m[32m0.29642[0m[0m | time: 54.083s
[2K
| Adam | epoch: 027 | loss: 0.29642 - acc: 0.9530 -- iter: 160/233
[A[ATraining Step: 214  | total loss: [1m[32m0.27016[0m[0m | time: 64.552s
[2K
| Adam | epoch: 027 | loss: 0.27016 - acc: 0.9577 -- iter: 192/233
[A[ATraining Step: 215  | total loss: [1m[32m0.25525[0m[0m | time: 68.405s
[2K
| Adam | epoch: 027 | loss: 0.25525 - acc: 0.9557 -- iter: 224/233
[A[ATraining Step: 216  | total loss: [1m[32m0.27427[0m[0m | time: 76.309s
[2K
| Adam | epoch: 027 | loss: 0.27427 - acc: 0.9379 | val_loss: 1.83350 - val_acc: 0.6027 -- iter: 233/233
--
Training Step: 217  | total loss: [1m[32m0.25352[0m[0m | time: 10.676s
[2K
| Adam | epoch: 028 | loss: 0.25352 - acc: 0.9441 -- iter: 032/233
[A[ATraining Step: 218  | total loss: [1m[32m0.23732[0m[0m | time: 21.026s
[2K
| Adam | epoch: 028 | loss: 0.23732 - acc: 0.9434 -- iter: 064/233
[A[ATraining Step: 219  | total loss: [1m[32m0.23845[0m[0m | time: 31.708s
[2K
| Adam | epoch: 028 | loss: 0.23845 - acc: 0.9397 -- iter: 096/233
[A[ATraining Step: 220  | total loss: [1m[32m0.21547[0m[0m | time: 42.500s
[2K
| Adam | epoch: 028 | loss: 0.21547 - acc: 0.9457 -- iter: 128/233
[A[ATraining Step: 221  | total loss: [1m[32m0.19607[0m[0m | time: 52.935s
[2K
| Adam | epoch: 028 | loss: 0.19607 - acc: 0.9512 -- iter: 160/233
[A[ATraining Step: 222  | total loss: [1m[32m0.17847[0m[0m | time: 63.260s
[2K
| Adam | epoch: 028 | loss: 0.17847 - acc: 0.9560 -- iter: 192/233
[A[ATraining Step: 223  | total loss: [1m[32m0.16239[0m[0m | time: 75.679s
[2K
| Adam | epoch: 028 | loss: 0.16239 - acc: 0.9604 -- iter: 224/233
[A[ATraining Step: 224  | total loss: [1m[32m0.14872[0m[0m | time: 83.602s
[2K
| Adam | epoch: 028 | loss: 0.14872 - acc: 0.9644 | val_loss: 1.34094 - val_acc: 0.6575 -- iter: 233/233
--
Training Step: 225  | total loss: [1m[32m0.14660[0m[0m | time: 3.941s
[2K
| Adam | epoch: 029 | loss: 0.14660 - acc: 0.9568 -- iter: 032/233
[A[ATraining Step: 226  | total loss: [1m[32m0.13345[0m[0m | time: 14.885s
[2K
| Adam | epoch: 029 | loss: 0.13345 - acc: 0.9612 -- iter: 064/233
[A[ATraining Step: 227  | total loss: [1m[32m0.12746[0m[0m | time: 25.586s
[2K
| Adam | epoch: 029 | loss: 0.12746 - acc: 0.9619 -- iter: 096/233
[A[ATraining Step: 228  | total loss: [1m[32m0.11997[0m[0m | time: 36.361s
[2K
| Adam | epoch: 029 | loss: 0.11997 - acc: 0.9626 -- iter: 128/233
[A[ATraining Step: 229  | total loss: [1m[32m0.10966[0m[0m | time: 48.075s
[2K
| Adam | epoch: 029 | loss: 0.10966 - acc: 0.9663 -- iter: 160/233
[A[ATraining Step: 230  | total loss: [1m[32m0.10214[0m[0m | time: 58.807s
[2K
| Adam | epoch: 029 | loss: 0.10214 - acc: 0.9697 -- iter: 192/233
[A[ATraining Step: 231  | total loss: [1m[32m0.09326[0m[0m | time: 70.342s
[2K
| Adam | epoch: 029 | loss: 0.09326 - acc: 0.9727 -- iter: 224/233
[A[ATraining Step: 232  | total loss: [1m[32m0.08488[0m[0m | time: 86.473s
[2K
| Adam | epoch: 029 | loss: 0.08488 - acc: 0.9755 | val_loss: 1.91923 - val_acc: 0.6438 -- iter: 233/233
--
Training Step: 233  | total loss: [1m[32m0.07745[0m[0m | time: 3.942s
[2K
| Adam | epoch: 030 | loss: 0.07745 - acc: 0.9779 -- iter: 032/233
[A[ATraining Step: 234  | total loss: [1m[32m0.10307[0m[0m | time: 7.819s
[2K
| Adam | epoch: 030 | loss: 0.10307 - acc: 0.9690 -- iter: 064/233
[A[ATraining Step: 235  | total loss: [1m[32m0.09592[0m[0m | time: 18.033s
[2K
| Adam | epoch: 030 | loss: 0.09592 - acc: 0.9721 -- iter: 096/233
[A[ATraining Step: 236  | total loss: [1m[32m0.08720[0m[0m | time: 28.972s
[2K
| Adam | epoch: 030 | loss: 0.08720 - acc: 0.9749 -- iter: 128/233
[A[ATraining Step: 237  | total loss: [1m[32m0.08277[0m[0m | time: 39.731s
[2K
| Adam | epoch: 030 | loss: 0.08277 - acc: 0.9774 -- iter: 160/233
[A[ATraining Step: 238  | total loss: [1m[32m0.07493[0m[0m | time: 52.423s
[2K
| Adam | epoch: 030 | loss: 0.07493 - acc: 0.9797 -- iter: 192/233
[A[ATraining Step: 239  | total loss: [1m[32m0.06865[0m[0m | time: 62.683s
[2K
| Adam | epoch: 030 | loss: 0.06865 - acc: 0.9817 -- iter: 224/233
[A[ATraining Step: 240  | total loss: [1m[32m0.06405[0m[0m | time: 79.216s
[2K
| Adam | epoch: 030 | loss: 0.06405 - acc: 0.9835 | val_loss: 1.14503 - val_acc: 0.7808 -- iter: 233/233
--
Validation AUC:0.8263157894736842
Validation AUPRC:0.7736112797464729
Test AUC:0.8661654135338346
Test AUPRC:0.8081756292345308
BestTestF1Score	0.79	0.57	0.78	0.73	0.86	30	11	27	5	0.92
BestTestMCCScore	0.79	0.57	0.78	0.73	0.86	30	11	27	5	0.92
BestTestAccuracyScore	0.79	0.57	0.78	0.73	0.86	30	11	27	5	0.92
BestValidationF1Score	0.82	0.62	0.81	0.79	0.87	33	9	26	5	0.92
BestValidationMCC	0.82	0.62	0.81	0.79	0.87	33	9	26	5	0.92
BestValidationAccuracy	0.82	0.62	0.81	0.79	0.87	33	9	26	5	0.92
TestPredictions (Threshold:0.92)
CHEMBL558601,TN,INACT,0.009999999776482582	CHEMBL2036802,FN,ACT,0.9100000262260437	CHEMBL3093755,TP,ACT,1.0	CHEMBL3808931,FN,ACT,0.05000000074505806	CHEMBL2346665,TN,INACT,0.44999998807907104	CHEMBL29197,TN,INACT,0.009999999776482582	CHEMBL328164,FP,INACT,1.0	CHEMBL515356,TN,INACT,0.41999998688697815	CHEMBL606245,FP,INACT,1.0	CHEMBL228862,TN,INACT,0.009999999776482582	CHEMBL1910760,TN,INACT,0.4000000059604645	CHEMBL3356117,FP,INACT,0.9900000095367432	CHEMBL3093640,TP,ACT,1.0	CHEMBL506669,TN,INACT,0.019999999552965164	CHEMBL495758,TN,INACT,0.8999999761581421	CHEMBL2042136,FP,INACT,0.9800000190734863	CHEMBL101779,FP,INACT,0.9700000286102295	CHEMBL1910757,TN,INACT,0.30000001192092896	CHEMBL3809699,FN,ACT,0.8899999856948853	CHEMBL3092774,TP,ACT,1.0	CHEMBL3093639,TP,ACT,1.0	CHEMBL456112,TN,INACT,0.20999999344348907	CHEMBL132369,TN,INACT,0.5199999809265137	CHEMBL3093635,TP,ACT,1.0	CHEMBL489627,TN,INACT,0.0	CHEMBL549303,TN,INACT,0.0	CHEMBL574738,TP,ACT,1.0	CHEMBL2036629,TP,ACT,1.0	CHEMBL495727,TP,ACT,1.0	CHEMBL2036631,TP,ACT,0.9900000095367432	CHEMBL1908394,FN,ACT,0.6600000262260437	CHEMBL3092775,TP,ACT,1.0	CHEMBL312078,TN,INACT,0.14000000059604645	CHEMBL457401,TN,INACT,0.10000000149011612	CHEMBL367442,TN,INACT,0.029999999329447746	CHEMBL563733,TN,INACT,0.44999998807907104	CHEMBL551936,TN,INACT,0.009999999776482582	CHEMBL573578,FP,INACT,0.949999988079071	CHEMBL521201,FP,INACT,1.0	CHEMBL3810139,TP,ACT,1.0	CHEMBL3092801,TP,ACT,1.0	CHEMBL77155,TN,INACT,0.14000000059604645	CHEMBL464552,TP,ACT,0.949999988079071	CHEMBL3092784,TP,ACT,1.0	CHEMBL498249,TN,INACT,0.05999999865889549	CHEMBL3092794,TP,ACT,1.0	CHEMBL553,TP,ACT,0.9800000190734863	CHEMBL3093629,TP,ACT,1.0	CHEMBL3093645,TP,ACT,0.9900000095367432	CHEMBL100500,TN,INACT,0.8999999761581421	CHEMBL1336,TP,ACT,0.9700000286102295	CHEMBL2036796,TP,ACT,1.0	CHEMBL3092785,TP,ACT,1.0	CHEMBL558849,TN,INACT,0.27000001072883606	CHEMBL3092776,TP,ACT,0.9800000190734863	CHEMBL572878,FN,ACT,0.44999998807907104	CHEMBL3093643,TP,ACT,1.0	CHEMBL388978,TP,ACT,1.0	CHEMBL1910606,TN,INACT,0.029999999329447746	CHEMBL3093756,TP,ACT,1.0	CHEMBL3092779,TP,ACT,0.9900000095367432	CHEMBL463384,TN,INACT,0.14000000059604645	CHEMBL86795,FP,INACT,1.0	CHEMBL483081,FP,INACT,1.0	CHEMBL518732,TN,INACT,0.09000000357627869	CHEMBL2036628,TP,ACT,1.0	CHEMBL2036805,TP,ACT,1.0	CHEMBL551722,TN,INACT,0.009999999776482582	CHEMBL2312301,TP,ACT,1.0	CHEMBL2036633,TP,ACT,1.0	CHEMBL2163616,FP,INACT,0.9800000190734863	CHEMBL489344,FP,INACT,1.0	CHEMBL318461,TN,INACT,0.11999999731779099	

