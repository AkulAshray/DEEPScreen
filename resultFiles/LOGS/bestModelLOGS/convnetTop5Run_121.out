ImageNetInceptionV2 CHEMBL2622 RMSprop 0.0005 30 0 0 0.6 False True
Number of active compounds :	475
Number of inactive compounds :	475
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2622_RMSprop_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2622_RMSprop_0.0005_30_0.6/
---------------------------------
Training samples: 608
Validation samples: 190
--
Training Step: 1  | time: 536.563s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/608
[A[ATraining Step: 2  | total loss: [1m[32m0.74429[0m[0m | time: 1097.938s
[2K
| RMSProp | epoch: 001 | loss: 0.74429 - acc: 0.4781 -- iter: 064/608
[A[ATraining Step: 3  | total loss: [1m[32m0.77044[0m[0m | time: 1560.656s
[2K
| RMSProp | epoch: 001 | loss: 0.77044 - acc: 0.4705 -- iter: 096/608
[A[ATraining Step: 4  | total loss: [1m[32m0.79993[0m[0m | time: 1896.512s
[2K
| RMSProp | epoch: 001 | loss: 0.79993 - acc: 0.4457 -- iter: 128/608
[A[ATraining Step: 5  | total loss: [1m[32m0.87206[0m[0m | time: 2362.254s
[2K
| RMSProp | epoch: 001 | loss: 0.87206 - acc: 0.2886 -- iter: 160/608
[A[ATraining Step: 6  | total loss: [1m[32m0.69499[0m[0m | time: 2752.595s
[2K
| RMSProp | epoch: 001 | loss: 0.69499 - acc: 0.5049 -- iter: 192/608
[A[ATraining Step: 7  | total loss: [1m[32m0.72699[0m[0m | time: 3046.388s
[2K
| RMSProp | epoch: 001 | loss: 0.72699 - acc: 0.4832 -- iter: 224/608
[A[ATraining Step: 8  | total loss: [1m[32m0.74095[0m[0m | time: 3210.430s
[2K
| RMSProp | epoch: 001 | loss: 0.74095 - acc: 0.5102 -- iter: 256/608
[A[ATraining Step: 9  | total loss: [1m[32m0.74204[0m[0m | time: 3606.815s
[2K
| RMSProp | epoch: 001 | loss: 0.74204 - acc: 0.5048 -- iter: 288/608
[A[ATraining Step: 10  | total loss: [1m[32m0.76978[0m[0m | time: 3845.282s
[2K
| RMSProp | epoch: 001 | loss: 0.76978 - acc: 0.4555 -- iter: 320/608
[A[ATraining Step: 11  | total loss: [1m[32m0.76504[0m[0m | time: 4067.117s
[2K
| RMSProp | epoch: 001 | loss: 0.76504 - acc: 0.4914 -- iter: 352/608
[A[ATraining Step: 12  | total loss: [1m[32m0.76685[0m[0m | time: 4344.694s
[2K
| RMSProp | epoch: 001 | loss: 0.76685 - acc: 0.4531 -- iter: 384/608
[A[ATraining Step: 13  | total loss: [1m[32m0.73380[0m[0m | time: 4626.945s
[2K
| RMSProp | epoch: 001 | loss: 0.73380 - acc: 0.4866 -- iter: 416/608
[A[ATraining Step: 14  | total loss: [1m[32m0.72001[0m[0m | time: 5208.519s
[2K
| RMSProp | epoch: 001 | loss: 0.72001 - acc: 0.4665 -- iter: 448/608
[A[ATraining Step: 15  | total loss: [1m[32m0.71070[0m[0m | time: 5693.903s
[2K
| RMSProp | epoch: 001 | loss: 0.71070 - acc: 0.5163 -- iter: 480/608
[A[ATraining Step: 16  | total loss: [1m[32m0.73885[0m[0m | time: 5874.428s
[2K
| RMSProp | epoch: 001 | loss: 0.73885 - acc: 0.4164 -- iter: 512/608
[A[ATraining Step: 17  | total loss: [1m[32m0.72735[0m[0m | time: 5897.198s
[2K
| RMSProp | epoch: 001 | loss: 0.72735 - acc: 0.4803 -- iter: 544/608
[A[ATraining Step: 18  | total loss: [1m[32m0.72786[0m[0m | time: 5966.711s
[2K
| RMSProp | epoch: 001 | loss: 0.72786 - acc: 0.5087 -- iter: 576/608
[A[ATraining Step: 19  | total loss: [1m[32m0.72106[0m[0m | time: 6720.108s
[2K
| RMSProp | epoch: 001 | loss: 0.72106 - acc: 0.4746 | val_loss: 0.71992 - val_acc: 0.4947 -- iter: 608/608
--
Training Step: 20  | total loss: [1m[32m0.70753[0m[0m | time: 249.581s
[2K
| RMSProp | epoch: 002 | loss: 0.70753 - acc: 0.5028 -- iter: 032/608
[A[ATraining Step: 21  | total loss: [1m[32m0.70169[0m[0m | time: 345.547s
[2K
| RMSProp | epoch: 002 | loss: 0.70169 - acc: 0.5310 -- iter: 064/608
[A[ATraining Step: 22  | total loss: [1m[32m0.70610[0m[0m | time: 528.133s
[2K
| RMSProp | epoch: 002 | loss: 0.70610 - acc: 0.5311 -- iter: 096/608
[A[ATraining Step: 23  | total loss: [1m[32m0.69649[0m[0m | time: 537.321s
[2K
| RMSProp | epoch: 002 | loss: 0.69649 - acc: 0.5584 -- iter: 128/608
[A[ATraining Step: 24  | total loss: [1m[32m0.70345[0m[0m | time: 546.124s
[2K
| RMSProp | epoch: 002 | loss: 0.70345 - acc: 0.5595 -- iter: 160/608
[A[ATraining Step: 25  | total loss: [1m[32m0.71234[0m[0m | time: 556.754s
[2K
| RMSProp | epoch: 002 | loss: 0.71234 - acc: 0.5177 -- iter: 192/608
[A[ATraining Step: 26  | total loss: [1m[32m0.71731[0m[0m | time: 593.083s
[2K
| RMSProp | epoch: 002 | loss: 0.71731 - acc: 0.5213 -- iter: 224/608
[A[ATraining Step: 27  | total loss: [1m[32m0.71735[0m[0m | time: 769.947s
[2K
| RMSProp | epoch: 002 | loss: 0.71735 - acc: 0.4998 -- iter: 256/608
[A[ATraining Step: 28  | total loss: [1m[32m0.71471[0m[0m | time: 896.154s
[2K
| RMSProp | epoch: 002 | loss: 0.71471 - acc: 0.4920 -- iter: 288/608
[A[ATraining Step: 29  | total loss: [1m[32m0.70789[0m[0m | time: 926.056s
[2K
| RMSProp | epoch: 002 | loss: 0.70789 - acc: 0.5092 -- iter: 320/608
[A[ATraining Step: 30  | total loss: [1m[32m0.69667[0m[0m | time: 1025.960s
[2K
| RMSProp | epoch: 002 | loss: 0.69667 - acc: 0.5218 -- iter: 352/608
[A[ATraining Step: 31  | total loss: [1m[32m0.71419[0m[0m | time: 1065.016s
[2K
| RMSProp | epoch: 002 | loss: 0.71419 - acc: 0.4807 -- iter: 384/608
[A[ATraining Step: 32  | total loss: [1m[32m0.71708[0m[0m | time: 1074.017s
[2K
| RMSProp | epoch: 002 | loss: 0.71708 - acc: 0.4640 -- iter: 416/608
[A[ATraining Step: 33  | total loss: [1m[32m0.71659[0m[0m | time: 1084.848s
[2K
| RMSProp | epoch: 002 | loss: 0.71659 - acc: 0.4856 -- iter: 448/608
[A[ATraining Step: 34  | total loss: [1m[32m0.72266[0m[0m | time: 1382.149s
[2K
| RMSProp | epoch: 002 | loss: 0.72266 - acc: 0.4686 -- iter: 480/608
[A[ATraining Step: 35  | total loss: [1m[32m0.71909[0m[0m | time: 1405.085s
[2K
| RMSProp | epoch: 002 | loss: 0.71909 - acc: 0.4555 -- iter: 512/608
[A[ATraining Step: 36  | total loss: [1m[32m0.70874[0m[0m | time: 1532.116s
[2K
| RMSProp | epoch: 002 | loss: 0.70874 - acc: 0.4902 -- iter: 544/608
[A[ATraining Step: 37  | total loss: [1m[32m0.69949[0m[0m | time: 1613.988s
[2K
| RMSProp | epoch: 002 | loss: 0.69949 - acc: 0.4984 -- iter: 576/608
[A[ATraining Step: 38  | total loss: [1m[32m0.70905[0m[0m | time: 1901.436s
[2K
| RMSProp | epoch: 002 | loss: 0.70905 - acc: 0.4743 | val_loss: 0.69389 - val_acc: 0.4737 -- iter: 608/608
--
Training Step: 39  | total loss: [1m[32m0.70199[0m[0m | time: 79.240s
[2K
| RMSProp | epoch: 003 | loss: 0.70199 - acc: 0.4912 -- iter: 032/608
[A[ATraining Step: 40  | total loss: [1m[32m0.70092[0m[0m | time: 359.287s
[2K
| RMSProp | epoch: 003 | loss: 0.70092 - acc: 0.4987 -- iter: 064/608
[A[ATraining Step: 41  | total loss: [1m[32m0.68667[0m[0m | time: 503.141s
[2K
| RMSProp | epoch: 003 | loss: 0.68667 - acc: 0.5391 -- iter: 096/608
[A[ATraining Step: 42  | total loss: [1m[32m0.68150[0m[0m | time: 516.780s
[2K
| RMSProp | epoch: 003 | loss: 0.68150 - acc: 0.5546 -- iter: 128/608
[A[ATraining Step: 43  | total loss: [1m[32m0.68206[0m[0m | time: 529.690s
[2K
| RMSProp | epoch: 003 | loss: 0.68206 - acc: 0.5449 -- iter: 160/608
[A[ATraining Step: 44  | total loss: [1m[32m0.69447[0m[0m | time: 726.781s
[2K
| RMSProp | epoch: 003 | loss: 0.69447 - acc: 0.5317 -- iter: 192/608
[A[ATraining Step: 45  | total loss: [1m[32m0.68653[0m[0m | time: 795.221s
[2K
| RMSProp | epoch: 003 | loss: 0.68653 - acc: 0.5582 -- iter: 224/608
[A[ATraining Step: 46  | total loss: [1m[32m0.69041[0m[0m | time: 804.449s
[2K
| RMSProp | epoch: 003 | loss: 0.69041 - acc: 0.5537 -- iter: 256/608
[A[ATraining Step: 47  | total loss: [1m[32m0.69193[0m[0m | time: 813.843s
[2K
| RMSProp | epoch: 003 | loss: 0.69193 - acc: 0.5500 -- iter: 288/608
[A[ATraining Step: 48  | total loss: [1m[32m0.69146[0m[0m | time: 858.078s
[2K
| RMSProp | epoch: 003 | loss: 0.69146 - acc: 0.5319 -- iter: 320/608
[A[ATraining Step: 49  | total loss: [1m[32m0.69340[0m[0m | time: 986.434s
[2K
| RMSProp | epoch: 003 | loss: 0.69340 - acc: 0.5269 -- iter: 352/608
[A[ATraining Step: 50  | total loss: [1m[32m0.69387[0m[0m | time: 999.738s
[2K
| RMSProp | epoch: 003 | loss: 0.69387 - acc: 0.5518 -- iter: 384/608
[A[ATraining Step: 51  | total loss: [1m[32m0.69468[0m[0m | time: 1012.458s
[2K
| RMSProp | epoch: 003 | loss: 0.69468 - acc: 0.5439 -- iter: 416/608
[A[ATraining Step: 52  | total loss: [1m[32m0.68665[0m[0m | time: 1025.379s
[2K
| RMSProp | epoch: 003 | loss: 0.68665 - acc: 0.5561 -- iter: 448/608
[A[ATraining Step: 53  | total loss: [1m[32m0.68546[0m[0m | time: 1038.553s
[2K
| RMSProp | epoch: 003 | loss: 0.68546 - acc: 0.5662 -- iter: 480/608
[A[ATraining Step: 54  | total loss: [1m[32m0.68228[0m[0m | time: 1050.209s
[2K
| RMSProp | epoch: 003 | loss: 0.68228 - acc: 0.5702 -- iter: 512/608
[A[ATraining Step: 55  | total loss: [1m[32m0.66765[0m[0m | time: 1058.644s
[2K
| RMSProp | epoch: 003 | loss: 0.66765 - acc: 0.6048 -- iter: 544/608
[A[ATraining Step: 56  | total loss: [1m[32m0.67341[0m[0m | time: 1067.024s
[2K
| RMSProp | epoch: 003 | loss: 0.67341 - acc: 0.5901 -- iter: 576/608
[A[ATraining Step: 57  | total loss: [1m[32m0.66401[0m[0m | time: 1093.685s
[2K
| RMSProp | epoch: 003 | loss: 0.66401 - acc: 0.6122 | val_loss: 0.69700 - val_acc: 0.5000 -- iter: 608/608
--
Training Step: 58  | total loss: [1m[32m0.66704[0m[0m | time: 9.582s
[2K
| RMSProp | epoch: 004 | loss: 0.66704 - acc: 0.6140 -- iter: 032/608
[A[ATraining Step: 59  | total loss: [1m[32m0.67533[0m[0m | time: 17.988s
[2K
| RMSProp | epoch: 004 | loss: 0.67533 - acc: 0.6029 -- iter: 064/608
[A[ATraining Step: 60  | total loss: [1m[32m0.68564[0m[0m | time: 26.555s
[2K
| RMSProp | epoch: 004 | loss: 0.68564 - acc: 0.5768 -- iter: 096/608
[A[ATraining Step: 61  | total loss: [1m[32m0.67001[0m[0m | time: 36.349s
[2K
| RMSProp | epoch: 004 | loss: 0.67001 - acc: 0.6035 -- iter: 128/608
[A[ATraining Step: 62  | total loss: [1m[32m0.66504[0m[0m | time: 49.108s
[2K
| RMSProp | epoch: 004 | loss: 0.66504 - acc: 0.6023 -- iter: 160/608
[A[ATraining Step: 63  | total loss: [1m[32m0.67226[0m[0m | time: 62.206s
[2K
| RMSProp | epoch: 004 | loss: 0.67226 - acc: 0.5972 -- iter: 192/608
[A[ATraining Step: 64  | total loss: [1m[32m0.66770[0m[0m | time: 74.792s
[2K
| RMSProp | epoch: 004 | loss: 0.66770 - acc: 0.6007 -- iter: 224/608
[A[ATraining Step: 65  | total loss: [1m[32m0.66887[0m[0m | time: 87.429s
[2K
| RMSProp | epoch: 004 | loss: 0.66887 - acc: 0.5921 -- iter: 256/608
[A[ATraining Step: 66  | total loss: [1m[32m0.68522[0m[0m | time: 100.467s
[2K
| RMSProp | epoch: 004 | loss: 0.68522 - acc: 0.5619 -- iter: 288/608
[A[ATraining Step: 67  | total loss: [1m[32m0.68744[0m[0m | time: 112.326s
[2K
| RMSProp | epoch: 004 | loss: 0.68744 - acc: 0.5432 -- iter: 320/608
[A[ATraining Step: 68  | total loss: [1m[32m0.68966[0m[0m | time: 120.901s
[2K
| RMSProp | epoch: 004 | loss: 0.68966 - acc: 0.5418 -- iter: 352/608
[A[ATraining Step: 69  | total loss: [1m[32m0.68843[0m[0m | time: 129.248s
[2K
| RMSProp | epoch: 004 | loss: 0.68843 - acc: 0.5515 -- iter: 384/608
[A[ATraining Step: 70  | total loss: [1m[32m0.68748[0m[0m | time: 137.944s
[2K
| RMSProp | epoch: 004 | loss: 0.68748 - acc: 0.5492 -- iter: 416/608
[A[ATraining Step: 71  | total loss: [1m[32m0.68688[0m[0m | time: 147.730s
[2K
| RMSProp | epoch: 004 | loss: 0.68688 - acc: 0.5436 -- iter: 448/608
[A[ATraining Step: 72  | total loss: [1m[32m0.68685[0m[0m | time: 160.675s
[2K
| RMSProp | epoch: 004 | loss: 0.68685 - acc: 0.5317 -- iter: 480/608
[A[ATraining Step: 73  | total loss: [1m[32m0.68525[0m[0m | time: 173.919s
[2K
| RMSProp | epoch: 004 | loss: 0.68525 - acc: 0.5386 -- iter: 512/608
[A[ATraining Step: 74  | total loss: [1m[32m0.68393[0m[0m | time: 186.590s
[2K
| RMSProp | epoch: 004 | loss: 0.68393 - acc: 0.5378 -- iter: 544/608
[A[ATraining Step: 75  | total loss: [1m[32m0.67697[0m[0m | time: 200.034s
[2K
| RMSProp | epoch: 004 | loss: 0.67697 - acc: 0.5540 -- iter: 576/608
[A[ATraining Step: 76  | total loss: [1m[32m0.67382[0m[0m | time: 224.644s
[2K
| RMSProp | epoch: 004 | loss: 0.67382 - acc: 0.5616 | val_loss: 0.75524 - val_acc: 0.5105 -- iter: 608/608
--
Training Step: 77  | total loss: [1m[32m0.67250[0m[0m | time: 12.952s
[2K
| RMSProp | epoch: 005 | loss: 0.67250 - acc: 0.5584 -- iter: 032/608
[A[ATraining Step: 78  | total loss: [1m[32m0.67049[0m[0m | time: 26.144s
[2K
| RMSProp | epoch: 005 | loss: 0.67049 - acc: 0.5719 -- iter: 064/608
[A[ATraining Step: 79  | total loss: [1m[32m0.66433[0m[0m | time: 38.866s
[2K
| RMSProp | epoch: 005 | loss: 0.66433 - acc: 0.5839 -- iter: 096/608
[A[ATraining Step: 80  | total loss: [1m[32m0.66015[0m[0m | time: 51.900s
[2K
| RMSProp | epoch: 005 | loss: 0.66015 - acc: 0.5817 -- iter: 128/608
[A[ATraining Step: 81  | total loss: [1m[32m0.64080[0m[0m | time: 65.065s
[2K
| RMSProp | epoch: 005 | loss: 0.64080 - acc: 0.6082 -- iter: 160/608
[A[ATraining Step: 82  | total loss: [1m[32m0.64576[0m[0m | time: 74.557s
[2K
| RMSProp | epoch: 005 | loss: 0.64576 - acc: 0.5942 -- iter: 192/608
[A[ATraining Step: 83  | total loss: [1m[32m0.65664[0m[0m | time: 83.428s
[2K
| RMSProp | epoch: 005 | loss: 0.65664 - acc: 0.5817 -- iter: 224/608
[A[ATraining Step: 84  | total loss: [1m[32m0.65732[0m[0m | time: 91.787s
[2K
| RMSProp | epoch: 005 | loss: 0.65732 - acc: 0.5829 -- iter: 256/608
[A[ATraining Step: 85  | total loss: [1m[32m0.65426[0m[0m | time: 100.497s
[2K
| RMSProp | epoch: 005 | loss: 0.65426 - acc: 0.5902 -- iter: 288/608
[A[ATraining Step: 86  | total loss: [1m[32m0.64618[0m[0m | time: 112.773s
[2K
| RMSProp | epoch: 005 | loss: 0.64618 - acc: 0.5968 -- iter: 320/608
[A[ATraining Step: 87  | total loss: [1m[32m0.65867[0m[0m | time: 125.330s
[2K
| RMSProp | epoch: 005 | loss: 0.65867 - acc: 0.5965 -- iter: 352/608
[A[ATraining Step: 88  | total loss: [1m[32m0.65094[0m[0m | time: 138.452s
[2K
| RMSProp | epoch: 005 | loss: 0.65094 - acc: 0.6087 -- iter: 384/608
[A[ATraining Step: 89  | total loss: [1m[32m0.65079[0m[0m | time: 151.099s
[2K
| RMSProp | epoch: 005 | loss: 0.65079 - acc: 0.6104 -- iter: 416/608
[A[ATraining Step: 90  | total loss: [1m[32m0.65710[0m[0m | time: 163.527s
[2K
| RMSProp | epoch: 005 | loss: 0.65710 - acc: 0.6025 -- iter: 448/608
[A[ATraining Step: 91  | total loss: [1m[32m0.65839[0m[0m | time: 176.229s
[2K
| RMSProp | epoch: 005 | loss: 0.65839 - acc: 0.6016 -- iter: 480/608
[A[ATraining Step: 92  | total loss: [1m[32m0.65516[0m[0m | time: 185.053s
[2K
| RMSProp | epoch: 005 | loss: 0.65516 - acc: 0.6039 -- iter: 512/608
[A[ATraining Step: 93  | total loss: [1m[32m0.65494[0m[0m | time: 193.637s
[2K
| RMSProp | epoch: 005 | loss: 0.65494 - acc: 0.6029 -- iter: 544/608
[A[ATraining Step: 94  | total loss: [1m[32m0.64782[0m[0m | time: 202.102s
[2K
| RMSProp | epoch: 005 | loss: 0.64782 - acc: 0.6051 -- iter: 576/608
[A[ATraining Step: 95  | total loss: [1m[32m0.64993[0m[0m | time: 225.187s
[2K
| RMSProp | epoch: 005 | loss: 0.64993 - acc: 0.6040 | val_loss: 0.85715 - val_acc: 0.5526 -- iter: 608/608
--
Training Step: 96  | total loss: [1m[32m0.65438[0m[0m | time: 12.372s
[2K
| RMSProp | epoch: 006 | loss: 0.65438 - acc: 0.6030 -- iter: 032/608
[A[ATraining Step: 97  | total loss: [1m[32m0.66050[0m[0m | time: 20.957s
[2K
| RMSProp | epoch: 006 | loss: 0.66050 - acc: 0.6020 -- iter: 064/608
[A[ATraining Step: 98  | total loss: [1m[32m0.66109[0m[0m | time: 29.612s
[2K
| RMSProp | epoch: 006 | loss: 0.66109 - acc: 0.6106 -- iter: 096/608
[A[ATraining Step: 99  | total loss: [1m[32m0.65125[0m[0m | time: 41.902s
[2K
| RMSProp | epoch: 006 | loss: 0.65125 - acc: 0.6120 -- iter: 128/608
[A[ATraining Step: 100  | total loss: [1m[32m0.64264[0m[0m | time: 55.084s
[2K
| RMSProp | epoch: 006 | loss: 0.64264 - acc: 0.6258 -- iter: 160/608
[A[ATraining Step: 101  | total loss: [1m[32m0.61816[0m[0m | time: 67.646s
[2K
| RMSProp | epoch: 006 | loss: 0.61816 - acc: 0.6476 -- iter: 192/608
[A[ATraining Step: 102  | total loss: [1m[32m0.63495[0m[0m | time: 80.653s
[2K
| RMSProp | epoch: 006 | loss: 0.63495 - acc: 0.6360 -- iter: 224/608
[A[ATraining Step: 103  | total loss: [1m[32m0.64748[0m[0m | time: 93.490s
[2K
| RMSProp | epoch: 006 | loss: 0.64748 - acc: 0.6255 -- iter: 256/608
[A[ATraining Step: 104  | total loss: [1m[32m0.64613[0m[0m | time: 106.616s
[2K
| RMSProp | epoch: 006 | loss: 0.64613 - acc: 0.6286 -- iter: 288/608
[A[ATraining Step: 105  | total loss: [1m[32m0.64727[0m[0m | time: 115.078s
[2K
| RMSProp | epoch: 006 | loss: 0.64727 - acc: 0.6220 -- iter: 320/608
[A[ATraining Step: 106  | total loss: [1m[32m0.64702[0m[0m | time: 123.605s
[2K
| RMSProp | epoch: 006 | loss: 0.64702 - acc: 0.6223 -- iter: 352/608
[A[ATraining Step: 107  | total loss: [1m[32m0.65192[0m[0m | time: 134.995s
[2K
| RMSProp | epoch: 006 | loss: 0.65192 - acc: 0.6100 -- iter: 384/608
[A[ATraining Step: 108  | total loss: [1m[32m0.65239[0m[0m | time: 148.126s
[2K
| RMSProp | epoch: 006 | loss: 0.65239 - acc: 0.6053 -- iter: 416/608
[A[ATraining Step: 109  | total loss: [1m[32m0.64093[0m[0m | time: 161.312s
[2K
| RMSProp | epoch: 006 | loss: 0.64093 - acc: 0.6229 -- iter: 448/608
[A[ATraining Step: 110  | total loss: [1m[32m0.63228[0m[0m | time: 174.481s
[2K
| RMSProp | epoch: 006 | loss: 0.63228 - acc: 0.6356 -- iter: 480/608
[A[ATraining Step: 111  | total loss: [1m[32m0.63914[0m[0m | time: 187.658s
[2K
| RMSProp | epoch: 006 | loss: 0.63914 - acc: 0.6408 -- iter: 512/608
[A[ATraining Step: 112  | total loss: [1m[32m0.63293[0m[0m | time: 200.358s
[2K
| RMSProp | epoch: 006 | loss: 0.63293 - acc: 0.6392 -- iter: 544/608
[A[ATraining Step: 113  | total loss: [1m[32m0.62634[0m[0m | time: 209.555s
[2K
| RMSProp | epoch: 006 | loss: 0.62634 - acc: 0.6440 -- iter: 576/608
[A[ATraining Step: 114  | total loss: [1m[32m0.62144[0m[0m | time: 228.929s
[2K
| RMSProp | epoch: 006 | loss: 0.62144 - acc: 0.6546 | val_loss: 1.31048 - val_acc: 0.5000 -- iter: 608/608
--
Training Step: 115  | total loss: [1m[32m0.60473[0m[0m | time: 13.298s
[2K
| RMSProp | epoch: 007 | loss: 0.60473 - acc: 0.6704 -- iter: 032/608
[A[ATraining Step: 116  | total loss: [1m[32m0.61520[0m[0m | time: 26.601s
[2K
| RMSProp | epoch: 007 | loss: 0.61520 - acc: 0.6628 -- iter: 064/608
[A[ATraining Step: 117  | total loss: [1m[32m0.61808[0m[0m | time: 39.043s
[2K
| RMSProp | epoch: 007 | loss: 0.61808 - acc: 0.6527 -- iter: 096/608
[A[ATraining Step: 118  | total loss: [1m[32m0.64851[0m[0m | time: 49.622s
[2K
| RMSProp | epoch: 007 | loss: 0.64851 - acc: 0.6375 -- iter: 128/608
[A[ATraining Step: 119  | total loss: [1m[32m0.64513[0m[0m | time: 58.163s
[2K
| RMSProp | epoch: 007 | loss: 0.64513 - acc: 0.6425 -- iter: 160/608
[A[ATraining Step: 120  | total loss: [1m[32m0.63448[0m[0m | time: 66.598s
[2K
| RMSProp | epoch: 007 | loss: 0.63448 - acc: 0.6532 -- iter: 192/608
[A[ATraining Step: 121  | total loss: [1m[32m0.60288[0m[0m | time: 75.115s
[2K
| RMSProp | epoch: 007 | loss: 0.60288 - acc: 0.6785 -- iter: 224/608
[A[ATraining Step: 122  | total loss: [1m[32m0.61376[0m[0m | time: 87.166s
[2K
| RMSProp | epoch: 007 | loss: 0.61376 - acc: 0.6575 -- iter: 256/608
[A[ATraining Step: 123  | total loss: [1m[32m0.61511[0m[0m | time: 95.767s
[2K
| RMSProp | epoch: 007 | loss: 0.61511 - acc: 0.6512 -- iter: 288/608
[A[ATraining Step: 124  | total loss: [1m[32m0.61585[0m[0m | time: 104.175s
[2K
| RMSProp | epoch: 007 | loss: 0.61585 - acc: 0.6548 -- iter: 320/608
[A[ATraining Step: 125  | total loss: [1m[32m0.62142[0m[0m | time: 112.602s
[2K
| RMSProp | epoch: 007 | loss: 0.62142 - acc: 0.6518 -- iter: 352/608
[A[ATraining Step: 126  | total loss: [1m[32m0.63719[0m[0m | time: 121.014s
[2K
| RMSProp | epoch: 007 | loss: 0.63719 - acc: 0.6491 -- iter: 384/608
[A[ATraining Step: 127  | total loss: [1m[32m0.63809[0m[0m | time: 129.528s
[2K
| RMSProp | epoch: 007 | loss: 0.63809 - acc: 0.6467 -- iter: 416/608
[A[ATraining Step: 128  | total loss: [1m[32m0.64109[0m[0m | time: 138.191s
[2K
| RMSProp | epoch: 007 | loss: 0.64109 - acc: 0.6383 -- iter: 448/608
[A[ATraining Step: 129  | total loss: [1m[32m0.63155[0m[0m | time: 146.669s
[2K
| RMSProp | epoch: 007 | loss: 0.63155 - acc: 0.6401 -- iter: 480/608
[A[ATraining Step: 130  | total loss: [1m[32m0.62523[0m[0m | time: 155.251s
[2K
| RMSProp | epoch: 007 | loss: 0.62523 - acc: 0.6480 -- iter: 512/608
[A[ATraining Step: 131  | total loss: [1m[32m0.62089[0m[0m | time: 163.591s
[2K
| RMSProp | epoch: 007 | loss: 0.62089 - acc: 0.6488 -- iter: 544/608
[A[ATraining Step: 132  | total loss: [1m[32m0.61328[0m[0m | time: 171.826s
[2K
| RMSProp | epoch: 007 | loss: 0.61328 - acc: 0.6527 -- iter: 576/608
[A[ATraining Step: 133  | total loss: [1m[32m0.60299[0m[0m | time: 189.262s
[2K
| RMSProp | epoch: 007 | loss: 0.60299 - acc: 0.6561 | val_loss: 11.42408 - val_acc: 0.4947 -- iter: 608/608
--
Training Step: 134  | total loss: [1m[32m0.58510[0m[0m | time: 8.548s
[2K
| RMSProp | epoch: 008 | loss: 0.58510 - acc: 0.6687 -- iter: 032/608
[A[ATraining Step: 135  | total loss: [1m[32m0.58118[0m[0m | time: 16.891s
[2K
| RMSProp | epoch: 008 | loss: 0.58118 - acc: 0.6799 -- iter: 064/608
[A[ATraining Step: 136  | total loss: [1m[32m0.58057[0m[0m | time: 25.415s
[2K
| RMSProp | epoch: 008 | loss: 0.58057 - acc: 0.6838 -- iter: 096/608
[A[ATraining Step: 137  | total loss: [1m[32m0.58914[0m[0m | time: 33.914s
[2K
| RMSProp | epoch: 008 | loss: 0.58914 - acc: 0.6810 -- iter: 128/608
[A[ATraining Step: 138  | total loss: [1m[32m0.60767[0m[0m | time: 42.679s
[2K
| RMSProp | epoch: 008 | loss: 0.60767 - acc: 0.6598 -- iter: 160/608
[A[ATraining Step: 139  | total loss: [1m[32m0.60588[0m[0m | time: 51.256s
[2K
| RMSProp | epoch: 008 | loss: 0.60588 - acc: 0.6626 -- iter: 192/608
[A[ATraining Step: 140  | total loss: [1m[32m0.60431[0m[0m | time: 59.849s
[2K
| RMSProp | epoch: 008 | loss: 0.60431 - acc: 0.6682 -- iter: 224/608
[A[ATraining Step: 141  | total loss: [1m[32m0.57026[0m[0m | time: 68.506s
[2K
| RMSProp | epoch: 008 | loss: 0.57026 - acc: 0.6951 -- iter: 256/608
[A[ATraining Step: 142  | total loss: [1m[32m0.57422[0m[0m | time: 77.094s
[2K
| RMSProp | epoch: 008 | loss: 0.57422 - acc: 0.6912 -- iter: 288/608
[A[ATraining Step: 143  | total loss: [1m[32m0.61466[0m[0m | time: 85.533s
[2K
| RMSProp | epoch: 008 | loss: 0.61466 - acc: 0.6690 -- iter: 320/608
[A[ATraining Step: 144  | total loss: [1m[32m0.61671[0m[0m | time: 94.368s
[2K
| RMSProp | epoch: 008 | loss: 0.61671 - acc: 0.6615 -- iter: 352/608
[A[ATraining Step: 145  | total loss: [1m[32m0.63425[0m[0m | time: 102.633s
[2K
| RMSProp | epoch: 008 | loss: 0.63425 - acc: 0.6547 -- iter: 384/608
[A[ATraining Step: 146  | total loss: [1m[32m0.63454[0m[0m | time: 111.107s
[2K
| RMSProp | epoch: 008 | loss: 0.63454 - acc: 0.6517 -- iter: 416/608
[A[ATraining Step: 147  | total loss: [1m[32m0.65354[0m[0m | time: 119.539s
[2K
| RMSProp | epoch: 008 | loss: 0.65354 - acc: 0.6334 -- iter: 448/608
[A[ATraining Step: 148  | total loss: [1m[32m0.66532[0m[0m | time: 127.952s
[2K
| RMSProp | epoch: 008 | loss: 0.66532 - acc: 0.6263 -- iter: 480/608
[A[ATraining Step: 149  | total loss: [1m[32m0.65800[0m[0m | time: 136.373s
[2K
| RMSProp | epoch: 008 | loss: 0.65800 - acc: 0.6387 -- iter: 512/608
[A[ATraining Step: 150  | total loss: [1m[32m0.63712[0m[0m | time: 144.838s
[2K
| RMSProp | epoch: 008 | loss: 0.63712 - acc: 0.6498 -- iter: 544/608
[A[ATraining Step: 151  | total loss: [1m[32m0.62992[0m[0m | time: 153.447s
[2K
| RMSProp | epoch: 008 | loss: 0.62992 - acc: 0.6567 -- iter: 576/608
[A[ATraining Step: 152  | total loss: [1m[32m0.61697[0m[0m | time: 171.041s
[2K
| RMSProp | epoch: 008 | loss: 0.61697 - acc: 0.6598 | val_loss: 2.93932 - val_acc: 0.4947 -- iter: 608/608
--
Training Step: 153  | total loss: [1m[32m0.60785[0m[0m | time: 8.329s
[2K
| RMSProp | epoch: 009 | loss: 0.60785 - acc: 0.6688 -- iter: 032/608
[A[ATraining Step: 154  | total loss: [1m[32m0.58786[0m[0m | time: 16.769s
[2K
| RMSProp | epoch: 009 | loss: 0.58786 - acc: 0.6832 -- iter: 064/608
[A[ATraining Step: 155  | total loss: [1m[32m0.61497[0m[0m | time: 25.515s
[2K
| RMSProp | epoch: 009 | loss: 0.61497 - acc: 0.6836 -- iter: 096/608
[A[ATraining Step: 156  | total loss: [1m[32m0.59475[0m[0m | time: 33.986s
[2K
| RMSProp | epoch: 009 | loss: 0.59475 - acc: 0.6965 -- iter: 128/608
[A[ATraining Step: 157  | total loss: [1m[32m0.58430[0m[0m | time: 42.421s
[2K
| RMSProp | epoch: 009 | loss: 0.58430 - acc: 0.7112 -- iter: 160/608
[A[ATraining Step: 158  | total loss: [1m[32m0.56697[0m[0m | time: 51.042s
[2K
| RMSProp | epoch: 009 | loss: 0.56697 - acc: 0.7182 -- iter: 192/608
[A[ATraining Step: 159  | total loss: [1m[32m0.56047[0m[0m | time: 59.656s
[2K
| RMSProp | epoch: 009 | loss: 0.56047 - acc: 0.7214 -- iter: 224/608
[A[ATraining Step: 160  | total loss: [1m[32m0.57985[0m[0m | time: 68.139s
[2K
| RMSProp | epoch: 009 | loss: 0.57985 - acc: 0.7086 -- iter: 256/608
[A[ATraining Step: 161  | total loss: [1m[32m0.55023[0m[0m | time: 76.749s
[2K
| RMSProp | epoch: 009 | loss: 0.55023 - acc: 0.7315 -- iter: 288/608
[A[ATraining Step: 162  | total loss: [1m[32m0.56898[0m[0m | time: 85.303s
[2K
| RMSProp | epoch: 009 | loss: 0.56898 - acc: 0.7209 -- iter: 320/608
[A[ATraining Step: 163  | total loss: [1m[32m0.60011[0m[0m | time: 93.638s
[2K
| RMSProp | epoch: 009 | loss: 0.60011 - acc: 0.7019 -- iter: 352/608
[A[ATraining Step: 164  | total loss: [1m[32m0.59407[0m[0m | time: 102.068s
[2K
| RMSProp | epoch: 009 | loss: 0.59407 - acc: 0.7130 -- iter: 384/608
[A[ATraining Step: 165  | total loss: [1m[32m0.60469[0m[0m | time: 110.548s
[2K
| RMSProp | epoch: 009 | loss: 0.60469 - acc: 0.7073 -- iter: 416/608
[A[ATraining Step: 166  | total loss: [1m[32m0.59923[0m[0m | time: 118.965s
[2K
| RMSProp | epoch: 009 | loss: 0.59923 - acc: 0.7084 -- iter: 448/608
[A[ATraining Step: 167  | total loss: [1m[32m0.61157[0m[0m | time: 127.337s
[2K
| RMSProp | epoch: 009 | loss: 0.61157 - acc: 0.6939 -- iter: 480/608
[A[ATraining Step: 168  | total loss: [1m[32m0.63584[0m[0m | time: 135.842s
[2K
| RMSProp | epoch: 009 | loss: 0.63584 - acc: 0.6682 -- iter: 512/608
[A[ATraining Step: 169  | total loss: [1m[32m0.61583[0m[0m | time: 144.342s
[2K
| RMSProp | epoch: 009 | loss: 0.61583 - acc: 0.6858 -- iter: 544/608
[A[ATraining Step: 170  | total loss: [1m[32m0.61830[0m[0m | time: 152.770s
[2K
| RMSProp | epoch: 009 | loss: 0.61830 - acc: 0.6859 -- iter: 576/608
[A[ATraining Step: 171  | total loss: [1m[32m0.60399[0m[0m | time: 170.179s
[2K
| RMSProp | epoch: 009 | loss: 0.60399 - acc: 0.7017 | val_loss: 9.47353 - val_acc: 0.4947 -- iter: 608/608
--
Training Step: 172  | total loss: [1m[32m0.57606[0m[0m | time: 8.657s
[2K
| RMSProp | epoch: 010 | loss: 0.57606 - acc: 0.7159 -- iter: 032/608
[A[ATraining Step: 173  | total loss: [1m[32m0.55622[0m[0m | time: 16.927s
[2K
| RMSProp | epoch: 010 | loss: 0.55622 - acc: 0.7287 -- iter: 064/608
[A[ATraining Step: 174  | total loss: [1m[32m0.58525[0m[0m | time: 25.263s
[2K
| RMSProp | epoch: 010 | loss: 0.58525 - acc: 0.7183 -- iter: 096/608
[A[ATraining Step: 175  | total loss: [1m[32m0.58527[0m[0m | time: 33.881s
[2K
| RMSProp | epoch: 010 | loss: 0.58527 - acc: 0.7121 -- iter: 128/608
[A[ATraining Step: 176  | total loss: [1m[32m0.58586[0m[0m | time: 42.461s
[2K
| RMSProp | epoch: 010 | loss: 0.58586 - acc: 0.7097 -- iter: 160/608
[A[ATraining Step: 177  | total loss: [1m[32m0.57652[0m[0m | time: 50.971s
[2K
| RMSProp | epoch: 010 | loss: 0.57652 - acc: 0.7137 -- iter: 192/608
[A[ATraining Step: 178  | total loss: [1m[32m0.58981[0m[0m | time: 59.449s
[2K
| RMSProp | epoch: 010 | loss: 0.58981 - acc: 0.7173 -- iter: 224/608
[A[ATraining Step: 179  | total loss: [1m[32m0.58491[0m[0m | time: 67.885s
[2K
| RMSProp | epoch: 010 | loss: 0.58491 - acc: 0.7143 -- iter: 256/608
[A[ATraining Step: 180  | total loss: [1m[32m0.57334[0m[0m | time: 76.355s
[2K
| RMSProp | epoch: 010 | loss: 0.57334 - acc: 0.7242 -- iter: 288/608
[A[ATraining Step: 181  | total loss: [1m[32m0.52868[0m[0m | time: 84.888s
[2K
| RMSProp | epoch: 010 | loss: 0.52868 - acc: 0.7517 -- iter: 320/608
[A[ATraining Step: 182  | total loss: [1m[32m0.54374[0m[0m | time: 93.485s
[2K
| RMSProp | epoch: 010 | loss: 0.54374 - acc: 0.7422 -- iter: 352/608
[A[ATraining Step: 183  | total loss: [1m[32m0.53121[0m[0m | time: 101.986s
[2K
| RMSProp | epoch: 010 | loss: 0.53121 - acc: 0.7524 -- iter: 384/608
[A[ATraining Step: 184  | total loss: [1m[32m0.53344[0m[0m | time: 110.444s
[2K
| RMSProp | epoch: 010 | loss: 0.53344 - acc: 0.7521 -- iter: 416/608
[A[ATraining Step: 185  | total loss: [1m[32m0.54359[0m[0m | time: 118.843s
[2K
| RMSProp | epoch: 010 | loss: 0.54359 - acc: 0.7519 -- iter: 448/608
[A[ATraining Step: 186  | total loss: [1m[32m0.61717[0m[0m | time: 127.510s
[2K
| RMSProp | epoch: 010 | loss: 0.61717 - acc: 0.7236 -- iter: 480/608
[A[ATraining Step: 187  | total loss: [1m[32m0.62432[0m[0m | time: 135.938s
[2K
| RMSProp | epoch: 010 | loss: 0.62432 - acc: 0.6981 -- iter: 512/608
[A[ATraining Step: 188  | total loss: [1m[32m0.62379[0m[0m | time: 144.414s
[2K
| RMSProp | epoch: 010 | loss: 0.62379 - acc: 0.6970 -- iter: 544/608
[A[ATraining Step: 189  | total loss: [1m[32m0.60889[0m[0m | time: 152.780s
[2K
| RMSProp | epoch: 010 | loss: 0.60889 - acc: 0.7023 -- iter: 576/608
[A[ATraining Step: 190  | total loss: [1m[32m0.58573[0m[0m | time: 170.366s
[2K
| RMSProp | epoch: 010 | loss: 0.58573 - acc: 0.7165 | val_loss: 2.07594 - val_acc: 0.4947 -- iter: 608/608
--
Training Step: 191  | total loss: [1m[32m0.59591[0m[0m | time: 8.417s
[2K
| RMSProp | epoch: 011 | loss: 0.59591 - acc: 0.7198 -- iter: 032/608
[A[ATraining Step: 192  | total loss: [1m[32m0.61677[0m[0m | time: 17.053s
[2K
| RMSProp | epoch: 011 | loss: 0.61677 - acc: 0.7010 -- iter: 064/608
[A[ATraining Step: 193  | total loss: [1m[32m0.59166[0m[0m | time: 25.569s
[2K
| RMSProp | epoch: 011 | loss: 0.59166 - acc: 0.7184 -- iter: 096/608
[A[ATraining Step: 194  | total loss: [1m[32m0.58326[0m[0m | time: 33.895s
[2K
| RMSProp | epoch: 011 | loss: 0.58326 - acc: 0.7278 -- iter: 128/608
[A[ATraining Step: 195  | total loss: [1m[32m0.56700[0m[0m | time: 42.389s
[2K
| RMSProp | epoch: 011 | loss: 0.56700 - acc: 0.7331 -- iter: 160/608
[A[ATraining Step: 196  | total loss: [1m[32m0.54220[0m[0m | time: 51.034s
[2K
| RMSProp | epoch: 011 | loss: 0.54220 - acc: 0.7473 -- iter: 192/608
[A[ATraining Step: 197  | total loss: [1m[32m0.54723[0m[0m | time: 59.415s
[2K
| RMSProp | epoch: 011 | loss: 0.54723 - acc: 0.7507 -- iter: 224/608
[A[ATraining Step: 198  | total loss: [1m[32m0.54433[0m[0m | time: 67.879s
[2K
| RMSProp | epoch: 011 | loss: 0.54433 - acc: 0.7569 -- iter: 256/608
[A[ATraining Step: 199  | total loss: [1m[32m0.54119[0m[0m | time: 76.450s
[2K
| RMSProp | epoch: 011 | loss: 0.54119 - acc: 0.7625 -- iter: 288/608
[A[ATraining Step: 200  | total loss: [1m[32m0.53745[0m[0m | time: 93.881s
[2K
| RMSProp | epoch: 011 | loss: 0.53745 - acc: 0.7550 | val_loss: 5.15589 - val_acc: 0.4947 -- iter: 320/608
--
Training Step: 201  | total loss: [1m[32m0.49260[0m[0m | time: 102.432s
[2K
| RMSProp | epoch: 011 | loss: 0.49260 - acc: 0.7795 -- iter: 352/608
[A[ATraining Step: 202  | total loss: [1m[32m0.46721[0m[0m | time: 111.012s
[2K
| RMSProp | epoch: 011 | loss: 0.46721 - acc: 0.7953 -- iter: 384/608
[A[ATraining Step: 203  | total loss: [1m[32m0.47864[0m[0m | time: 119.446s
[2K
| RMSProp | epoch: 011 | loss: 0.47864 - acc: 0.7939 -- iter: 416/608
[A[ATraining Step: 204  | total loss: [1m[32m0.50626[0m[0m | time: 127.858s
[2K
| RMSProp | epoch: 011 | loss: 0.50626 - acc: 0.7801 -- iter: 448/608
[A[ATraining Step: 205  | total loss: [1m[32m0.50049[0m[0m | time: 136.295s
[2K
| RMSProp | epoch: 011 | loss: 0.50049 - acc: 0.7771 -- iter: 480/608
[A[ATraining Step: 206  | total loss: [1m[32m0.51515[0m[0m | time: 144.833s
[2K
| RMSProp | epoch: 011 | loss: 0.51515 - acc: 0.7713 -- iter: 512/608
[A[ATraining Step: 207  | total loss: [1m[32m0.52769[0m[0m | time: 153.437s
[2K
| RMSProp | epoch: 011 | loss: 0.52769 - acc: 0.7629 -- iter: 544/608
[A[ATraining Step: 208  | total loss: [1m[32m0.51796[0m[0m | time: 161.779s
[2K
| RMSProp | epoch: 011 | loss: 0.51796 - acc: 0.7772 -- iter: 576/608
[A[ATraining Step: 209  | total loss: [1m[32m0.51377[0m[0m | time: 178.987s
[2K
| RMSProp | epoch: 011 | loss: 0.51377 - acc: 0.7776 | val_loss: 4.11576 - val_acc: 0.4947 -- iter: 608/608
--
Training Step: 210  | total loss: [1m[32m0.48267[0m[0m | time: 8.390s
[2K
| RMSProp | epoch: 012 | loss: 0.48267 - acc: 0.7874 -- iter: 032/608
[A[ATraining Step: 211  | total loss: [1m[32m0.47151[0m[0m | time: 16.651s
[2K
| RMSProp | epoch: 012 | loss: 0.47151 - acc: 0.7867 -- iter: 064/608
[A[ATraining Step: 212  | total loss: [1m[32m0.44935[0m[0m | time: 25.007s
[2K
| RMSProp | epoch: 012 | loss: 0.44935 - acc: 0.7924 -- iter: 096/608
[A[ATraining Step: 213  | total loss: [1m[32m0.44098[0m[0m | time: 33.508s
[2K
| RMSProp | epoch: 012 | loss: 0.44098 - acc: 0.8038 -- iter: 128/608
[A[ATraining Step: 214  | total loss: [1m[32m0.42834[0m[0m | time: 42.073s
[2K
| RMSProp | epoch: 012 | loss: 0.42834 - acc: 0.8109 -- iter: 160/608
[A[ATraining Step: 215  | total loss: [1m[32m0.45889[0m[0m | time: 50.463s
[2K
| RMSProp | epoch: 012 | loss: 0.45889 - acc: 0.7986 -- iter: 192/608
[A[ATraining Step: 216  | total loss: [1m[32m0.45948[0m[0m | time: 59.073s
[2K
| RMSProp | epoch: 012 | loss: 0.45948 - acc: 0.7937 -- iter: 224/608
[A[ATraining Step: 217  | total loss: [1m[32m0.44597[0m[0m | time: 67.597s
[2K
| RMSProp | epoch: 012 | loss: 0.44597 - acc: 0.8019 -- iter: 256/608
[A[ATraining Step: 218  | total loss: [1m[32m0.44383[0m[0m | time: 75.850s
[2K
| RMSProp | epoch: 012 | loss: 0.44383 - acc: 0.8061 -- iter: 288/608
[A[ATraining Step: 219  | total loss: [1m[32m0.42885[0m[0m | time: 84.430s
[2K
| RMSProp | epoch: 012 | loss: 0.42885 - acc: 0.8161 -- iter: 320/608
[A[ATraining Step: 220  | total loss: [1m[32m0.41692[0m[0m | time: 93.033s
[2K
| RMSProp | epoch: 012 | loss: 0.41692 - acc: 0.8251 -- iter: 352/608
[A[ATraining Step: 221  | total loss: [1m[32m0.37680[0m[0m | time: 101.569s
[2K
| RMSProp | epoch: 012 | loss: 0.37680 - acc: 0.8426 -- iter: 384/608
[A[ATraining Step: 222  | total loss: [1m[32m0.35998[0m[0m | time: 109.969s
[2K
| RMSProp | epoch: 012 | loss: 0.35998 - acc: 0.8490 -- iter: 416/608
[A[ATraining Step: 223  | total loss: [1m[32m0.43297[0m[0m | time: 118.372s
[2K
| RMSProp | epoch: 012 | loss: 0.43297 - acc: 0.8422 -- iter: 448/608
[A[ATraining Step: 224  | total loss: [1m[32m0.42614[0m[0m | time: 127.120s
[2K
| RMSProp | epoch: 012 | loss: 0.42614 - acc: 0.8298 -- iter: 480/608
[A[ATraining Step: 225  | total loss: [1m[32m0.42178[0m[0m | time: 135.679s
[2K
| RMSProp | epoch: 012 | loss: 0.42178 - acc: 0.8281 -- iter: 512/608
[A[ATraining Step: 226  | total loss: [1m[32m0.40546[0m[0m | time: 144.144s
[2K
| RMSProp | epoch: 012 | loss: 0.40546 - acc: 0.8328 -- iter: 544/608
[A[ATraining Step: 227  | total loss: [1m[32m0.41231[0m[0m | time: 152.443s
[2K
| RMSProp | epoch: 012 | loss: 0.41231 - acc: 0.8308 -- iter: 576/608
[A[ATraining Step: 228  | total loss: [1m[32m0.39379[0m[0m | time: 170.090s
[2K
| RMSProp | epoch: 012 | loss: 0.39379 - acc: 0.8414 | val_loss: 0.78223 - val_acc: 0.6263 -- iter: 608/608
--
Training Step: 229  | total loss: [1m[32m0.38177[0m[0m | time: 8.497s
[2K
| RMSProp | epoch: 013 | loss: 0.38177 - acc: 0.8448 -- iter: 032/608
[A[ATraining Step: 230  | total loss: [1m[32m0.35952[0m[0m | time: 16.856s
[2K
| RMSProp | epoch: 013 | loss: 0.35952 - acc: 0.8572 -- iter: 064/608
[A[ATraining Step: 231  | total loss: [1m[32m0.34354[0m[0m | time: 25.384s
[2K
| RMSProp | epoch: 013 | loss: 0.34354 - acc: 0.8652 -- iter: 096/608
[A[ATraining Step: 232  | total loss: [1m[32m0.35827[0m[0m | time: 33.651s
[2K
| RMSProp | epoch: 013 | loss: 0.35827 - acc: 0.8631 -- iter: 128/608
[A[ATraining Step: 233  | total loss: [1m[32m0.35484[0m[0m | time: 41.985s
[2K
| RMSProp | epoch: 013 | loss: 0.35484 - acc: 0.8643 -- iter: 160/608
[A[ATraining Step: 234  | total loss: [1m[32m0.35499[0m[0m | time: 50.548s
[2K
| RMSProp | epoch: 013 | loss: 0.35499 - acc: 0.8685 -- iter: 192/608
[A[ATraining Step: 235  | total loss: [1m[32m0.33002[0m[0m | time: 59.120s
[2K
| RMSProp | epoch: 013 | loss: 0.33002 - acc: 0.8816 -- iter: 224/608
[A[ATraining Step: 236  | total loss: [1m[32m0.31448[0m[0m | time: 67.454s
[2K
| RMSProp | epoch: 013 | loss: 0.31448 - acc: 0.8903 -- iter: 256/608
[A[ATraining Step: 237  | total loss: [1m[32m0.30673[0m[0m | time: 75.604s
[2K
| RMSProp | epoch: 013 | loss: 0.30673 - acc: 0.8950 -- iter: 288/608
[A[ATraining Step: 238  | total loss: [1m[32m0.32851[0m[0m | time: 84.088s
[2K
| RMSProp | epoch: 013 | loss: 0.32851 - acc: 0.8805 -- iter: 320/608
[A[ATraining Step: 239  | total loss: [1m[32m0.34276[0m[0m | time: 92.476s
[2K
| RMSProp | epoch: 013 | loss: 0.34276 - acc: 0.8675 -- iter: 352/608
[A[ATraining Step: 240  | total loss: [1m[32m0.33111[0m[0m | time: 100.865s
[2K
| RMSProp | epoch: 013 | loss: 0.33111 - acc: 0.8682 -- iter: 384/608
[A[ATraining Step: 241  | total loss: [1m[32m0.31395[0m[0m | time: 109.235s
[2K
| RMSProp | epoch: 013 | loss: 0.31395 - acc: 0.8783 -- iter: 416/608
[A[ATraining Step: 242  | total loss: [1m[32m0.30077[0m[0m | time: 117.509s
[2K
| RMSProp | epoch: 013 | loss: 0.30077 - acc: 0.8811 -- iter: 448/608
[A[ATraining Step: 243  | total loss: [1m[32m0.30120[0m[0m | time: 126.189s
[2K
| RMSProp | epoch: 013 | loss: 0.30120 - acc: 0.8836 -- iter: 480/608
[A[ATraining Step: 244  | total loss: [1m[32m0.31411[0m[0m | time: 134.470s
[2K
| RMSProp | epoch: 013 | loss: 0.31411 - acc: 0.8796 -- iter: 512/608
[A[ATraining Step: 245  | total loss: [1m[32m0.35390[0m[0m | time: 143.056s
[2K
| RMSProp | epoch: 013 | loss: 0.35390 - acc: 0.8729 -- iter: 544/608
[A[ATraining Step: 246  | total loss: [1m[32m0.35596[0m[0m | time: 151.373s
[2K
| RMSProp | epoch: 013 | loss: 0.35596 - acc: 0.8762 -- iter: 576/608
[A[ATraining Step: 247  | total loss: [1m[32m0.34805[0m[0m | time: 168.878s
[2K
| RMSProp | epoch: 013 | loss: 0.34805 - acc: 0.8761 | val_loss: 1.35165 - val_acc: 0.5421 -- iter: 608/608
--
Training Step: 248  | total loss: [1m[32m0.34572[0m[0m | time: 8.459s
[2K
| RMSProp | epoch: 014 | loss: 0.34572 - acc: 0.8823 -- iter: 032/608
[A[ATraining Step: 249  | total loss: [1m[32m0.37201[0m[0m | time: 17.119s
[2K
| RMSProp | epoch: 014 | loss: 0.37201 - acc: 0.8722 -- iter: 064/608
[A[ATraining Step: 250  | total loss: [1m[32m0.36945[0m[0m | time: 25.651s
[2K
| RMSProp | epoch: 014 | loss: 0.36945 - acc: 0.8756 -- iter: 096/608
[A[ATraining Step: 251  | total loss: [1m[32m0.35344[0m[0m | time: 34.114s
[2K
| RMSProp | epoch: 014 | loss: 0.35344 - acc: 0.8818 -- iter: 128/608
[A[ATraining Step: 252  | total loss: [1m[32m0.35056[0m[0m | time: 42.416s
[2K
| RMSProp | epoch: 014 | loss: 0.35056 - acc: 0.8873 -- iter: 160/608
[A[ATraining Step: 253  | total loss: [1m[32m0.33710[0m[0m | time: 50.802s
[2K
| RMSProp | epoch: 014 | loss: 0.33710 - acc: 0.8923 -- iter: 192/608
[A[ATraining Step: 254  | total loss: [1m[32m0.32020[0m[0m | time: 59.454s
[2K
| RMSProp | epoch: 014 | loss: 0.32020 - acc: 0.8937 -- iter: 224/608
[A[ATraining Step: 255  | total loss: [1m[32m0.29629[0m[0m | time: 68.082s
[2K
| RMSProp | epoch: 014 | loss: 0.29629 - acc: 0.9012 -- iter: 256/608
[A[ATraining Step: 256  | total loss: [1m[32m0.28300[0m[0m | time: 76.399s
[2K
| RMSProp | epoch: 014 | loss: 0.28300 - acc: 0.9080 -- iter: 288/608
[A[ATraining Step: 257  | total loss: [1m[32m0.26245[0m[0m | time: 84.809s
[2K
| RMSProp | epoch: 014 | loss: 0.26245 - acc: 0.9141 -- iter: 320/608
[A[ATraining Step: 258  | total loss: [1m[32m0.30364[0m[0m | time: 93.179s
[2K
| RMSProp | epoch: 014 | loss: 0.30364 - acc: 0.9133 -- iter: 352/608
[A[ATraining Step: 259  | total loss: [1m[32m0.30679[0m[0m | time: 101.570s
[2K
| RMSProp | epoch: 014 | loss: 0.30679 - acc: 0.9126 -- iter: 384/608
[A[ATraining Step: 260  | total loss: [1m[32m0.29187[0m[0m | time: 109.842s
[2K
| RMSProp | epoch: 014 | loss: 0.29187 - acc: 0.9151 -- iter: 416/608
[A[ATraining Step: 261  | total loss: [1m[32m0.26772[0m[0m | time: 118.317s
[2K
| RMSProp | epoch: 014 | loss: 0.26772 - acc: 0.9236 -- iter: 448/608
[A[ATraining Step: 262  | total loss: [1m[32m0.25756[0m[0m | time: 126.895s
[2K
| RMSProp | epoch: 014 | loss: 0.25756 - acc: 0.9250 -- iter: 480/608
[A[ATraining Step: 263  | total loss: [1m[32m0.27491[0m[0m | time: 135.184s
[2K
| RMSProp | epoch: 014 | loss: 0.27491 - acc: 0.9200 -- iter: 512/608
[A[ATraining Step: 264  | total loss: [1m[32m0.25495[0m[0m | time: 143.738s
[2K
| RMSProp | epoch: 014 | loss: 0.25495 - acc: 0.9280 -- iter: 544/608
[A[ATraining Step: 265  | total loss: [1m[32m0.23908[0m[0m | time: 152.054s
[2K
| RMSProp | epoch: 014 | loss: 0.23908 - acc: 0.9289 -- iter: 576/608
[A[ATraining Step: 266  | total loss: [1m[32m0.24857[0m[0m | time: 169.309s
[2K
| RMSProp | epoch: 014 | loss: 0.24857 - acc: 0.9235 | val_loss: 2.05020 - val_acc: 0.5105 -- iter: 608/608
--
Training Step: 267  | total loss: [1m[32m0.24332[0m[0m | time: 14.687s
[2K
| RMSProp | epoch: 015 | loss: 0.24332 - acc: 0.9187 -- iter: 032/608
[A[ATraining Step: 268  | total loss: [1m[32m0.24066[0m[0m | time: 29.745s
[2K
| RMSProp | epoch: 015 | loss: 0.24066 - acc: 0.9237 -- iter: 064/608
[A[ATraining Step: 269  | total loss: [1m[32m0.22707[0m[0m | time: 44.423s
[2K
| RMSProp | epoch: 015 | loss: 0.22707 - acc: 0.9282 -- iter: 096/608
[A[ATraining Step: 270  | total loss: [1m[32m0.23110[0m[0m | time: 59.354s
[2K
| RMSProp | epoch: 015 | loss: 0.23110 - acc: 0.9260 -- iter: 128/608
[A[ATraining Step: 271  | total loss: [1m[32m0.22207[0m[0m | time: 73.639s
[2K
| RMSProp | epoch: 015 | loss: 0.22207 - acc: 0.9303 -- iter: 160/608
[A[ATraining Step: 272  | total loss: [1m[32m0.22722[0m[0m | time: 88.457s
[2K
| RMSProp | epoch: 015 | loss: 0.22722 - acc: 0.9310 -- iter: 192/608
[A[ATraining Step: 273  | total loss: [1m[32m0.23276[0m[0m | time: 103.018s
[2K
| RMSProp | epoch: 015 | loss: 0.23276 - acc: 0.9191 -- iter: 224/608
[A[ATraining Step: 274  | total loss: [1m[32m0.23083[0m[0m | time: 118.004s
[2K
| RMSProp | epoch: 015 | loss: 0.23083 - acc: 0.9241 -- iter: 256/608
[A[ATraining Step: 275  | total loss: [1m[32m0.22538[0m[0m | time: 133.325s
[2K
| RMSProp | epoch: 015 | loss: 0.22538 - acc: 0.9254 -- iter: 288/608
[A[ATraining Step: 276  | total loss: [1m[32m0.21475[0m[0m | time: 147.986s
[2K
| RMSProp | epoch: 015 | loss: 0.21475 - acc: 0.9298 -- iter: 320/608
[A[ATraining Step: 277  | total loss: [1m[32m0.22591[0m[0m | time: 163.567s
[2K
| RMSProp | epoch: 015 | loss: 0.22591 - acc: 0.9212 -- iter: 352/608
[A[ATraining Step: 278  | total loss: [1m[32m0.23128[0m[0m | time: 178.157s
[2K
| RMSProp | epoch: 015 | loss: 0.23128 - acc: 0.9197 -- iter: 384/608
[A[ATraining Step: 279  | total loss: [1m[32m0.23554[0m[0m | time: 192.961s
[2K
| RMSProp | epoch: 015 | loss: 0.23554 - acc: 0.9215 -- iter: 416/608
[A[ATraining Step: 280  | total loss: [1m[32m0.23411[0m[0m | time: 218.270s
[2K
| RMSProp | epoch: 015 | loss: 0.23411 - acc: 0.9199 -- iter: 448/608
[A[ATraining Step: 281  | total loss: [1m[32m0.21320[0m[0m | time: 232.650s
[2K
| RMSProp | epoch: 015 | loss: 0.21320 - acc: 0.9279 -- iter: 480/608
[A[ATraining Step: 282  | total loss: [1m[32m0.21082[0m[0m | time: 247.383s
[2K
| RMSProp | epoch: 015 | loss: 0.21082 - acc: 0.9289 -- iter: 512/608
[A[ATraining Step: 283  | total loss: [1m[32m0.23368[0m[0m | time: 261.899s
[2K
| RMSProp | epoch: 015 | loss: 0.23368 - acc: 0.9298 -- iter: 544/608
[A[ATraining Step: 284  | total loss: [1m[32m0.22959[0m[0m | time: 276.346s
[2K
| RMSProp | epoch: 015 | loss: 0.22959 - acc: 0.9305 -- iter: 576/608
[A[ATraining Step: 285  | total loss: [1m[32m0.23663[0m[0m | time: 307.154s
[2K
| RMSProp | epoch: 015 | loss: 0.23663 - acc: 0.9250 | val_loss: 5.14466 - val_acc: 0.4947 -- iter: 608/608
--
Training Step: 286  | total loss: [1m[32m0.22819[0m[0m | time: 13.866s
[2K
| RMSProp | epoch: 016 | loss: 0.22819 - acc: 0.9231 -- iter: 032/608
[A[ATraining Step: 287  | total loss: [1m[32m0.24225[0m[0m | time: 22.758s
[2K
| RMSProp | epoch: 016 | loss: 0.24225 - acc: 0.9152 -- iter: 064/608
[A[ATraining Step: 288  | total loss: [1m[32m0.24943[0m[0m | time: 37.523s
[2K
| RMSProp | epoch: 016 | loss: 0.24943 - acc: 0.9080 -- iter: 096/608
[A[ATraining Step: 289  | total loss: [1m[32m0.27189[0m[0m | time: 48.899s
[2K
| RMSProp | epoch: 016 | loss: 0.27189 - acc: 0.8985 -- iter: 128/608
[A[ATraining Step: 290  | total loss: [1m[32m0.27265[0m[0m | time: 57.349s
[2K
| RMSProp | epoch: 016 | loss: 0.27265 - acc: 0.8961 -- iter: 160/608
[A[ATraining Step: 291  | total loss: [1m[32m0.26215[0m[0m | time: 65.730s
[2K
| RMSProp | epoch: 016 | loss: 0.26215 - acc: 0.9034 -- iter: 192/608
[A[ATraining Step: 292  | total loss: [1m[32m0.25731[0m[0m | time: 74.480s
[2K
| RMSProp | epoch: 016 | loss: 0.25731 - acc: 0.9068 -- iter: 224/608
[A[ATraining Step: 293  | total loss: [1m[32m0.24329[0m[0m | time: 87.969s
[2K
| RMSProp | epoch: 016 | loss: 0.24329 - acc: 0.9130 -- iter: 256/608
[A[ATraining Step: 294  | total loss: [1m[32m0.22716[0m[0m | time: 102.359s
[2K
| RMSProp | epoch: 016 | loss: 0.22716 - acc: 0.9217 -- iter: 288/608
[A[ATraining Step: 295  | total loss: [1m[32m0.22024[0m[0m | time: 117.345s
[2K
| RMSProp | epoch: 016 | loss: 0.22024 - acc: 0.9264 -- iter: 320/608
[A[ATraining Step: 296  | total loss: [1m[32m0.20434[0m[0m | time: 131.885s
[2K
| RMSProp | epoch: 016 | loss: 0.20434 - acc: 0.9306 -- iter: 352/608
[A[ATraining Step: 297  | total loss: [1m[32m0.18798[0m[0m | time: 146.879s
[2K
| RMSProp | epoch: 016 | loss: 0.18798 - acc: 0.9376 -- iter: 384/608
[A[ATraining Step: 298  | total loss: [1m[32m0.22429[0m[0m | time: 180.645s
[2K
| RMSProp | epoch: 016 | loss: 0.22429 - acc: 0.9344 -- iter: 416/608
[A[ATraining Step: 299  | total loss: [1m[32m0.21075[0m[0m | time: 194.537s
[2K
| RMSProp | epoch: 016 | loss: 0.21075 - acc: 0.9379 -- iter: 448/608
[A[ATraining Step: 300  | total loss: [1m[32m0.21474[0m[0m | time: 209.014s
[2K
| RMSProp | epoch: 016 | loss: 0.21474 - acc: 0.9285 -- iter: 480/608
[A[ATraining Step: 301  | total loss: [1m[32m0.20387[0m[0m | time: 224.026s
[2K
| RMSProp | epoch: 016 | loss: 0.20387 - acc: 0.9294 -- iter: 512/608
[A[ATraining Step: 302  | total loss: [1m[32m0.19297[0m[0m | time: 238.260s
[2K
| RMSProp | epoch: 016 | loss: 0.19297 - acc: 0.9302 -- iter: 544/608
[A[ATraining Step: 303  | total loss: [1m[32m0.19479[0m[0m | time: 252.758s
[2K
| RMSProp | epoch: 016 | loss: 0.19479 - acc: 0.9247 -- iter: 576/608
[A[ATraining Step: 304  | total loss: [1m[32m0.19740[0m[0m | time: 283.550s
[2K
| RMSProp | epoch: 016 | loss: 0.19740 - acc: 0.9228 | val_loss: 0.87058 - val_acc: 0.7105 -- iter: 608/608
--
Training Step: 305  | total loss: [1m[32m0.18410[0m[0m | time: 14.829s
[2K
| RMSProp | epoch: 017 | loss: 0.18410 - acc: 0.9305 -- iter: 032/608
[A[ATraining Step: 306  | total loss: [1m[32m0.18618[0m[0m | time: 31.356s
[2K
| RMSProp | epoch: 017 | loss: 0.18618 - acc: 0.9281 -- iter: 064/608
[A[ATraining Step: 307  | total loss: [1m[32m0.20563[0m[0m | time: 45.326s
[2K
| RMSProp | epoch: 017 | loss: 0.20563 - acc: 0.9228 -- iter: 096/608
[A[ATraining Step: 308  | total loss: [1m[32m0.20535[0m[0m | time: 59.387s
[2K
| RMSProp | epoch: 017 | loss: 0.20535 - acc: 0.9211 -- iter: 128/608
[A[ATraining Step: 309  | total loss: [1m[32m0.22646[0m[0m | time: 73.687s
[2K
| RMSProp | epoch: 017 | loss: 0.22646 - acc: 0.9228 -- iter: 160/608
[A[ATraining Step: 310  | total loss: [1m[32m0.22605[0m[0m | time: 98.569s
[2K
| RMSProp | epoch: 017 | loss: 0.22605 - acc: 0.9243 -- iter: 192/608
[A[ATraining Step: 311  | total loss: [1m[32m0.22125[0m[0m | time: 112.890s
[2K
| RMSProp | epoch: 017 | loss: 0.22125 - acc: 0.9256 -- iter: 224/608
[A[ATraining Step: 312  | total loss: [1m[32m0.21235[0m[0m | time: 127.397s
[2K
| RMSProp | epoch: 017 | loss: 0.21235 - acc: 0.9268 -- iter: 256/608
[A[ATraining Step: 313  | total loss: [1m[32m0.21685[0m[0m | time: 142.414s
[2K
| RMSProp | epoch: 017 | loss: 0.21685 - acc: 0.9216 -- iter: 288/608
[A[ATraining Step: 314  | total loss: [1m[32m0.21387[0m[0m | time: 153.360s
[2K
| RMSProp | epoch: 017 | loss: 0.21387 - acc: 0.9201 -- iter: 320/608
[A[ATraining Step: 315  | total loss: [1m[32m0.19929[0m[0m | time: 161.882s
[2K
| RMSProp | epoch: 017 | loss: 0.19929 - acc: 0.9249 -- iter: 352/608
[A[ATraining Step: 316  | total loss: [1m[32m0.18128[0m[0m | time: 170.572s
[2K
| RMSProp | epoch: 017 | loss: 0.18128 - acc: 0.9324 -- iter: 384/608
[A[ATraining Step: 317  | total loss: [1m[32m0.16494[0m[0m | time: 178.742s
[2K
| RMSProp | epoch: 017 | loss: 0.16494 - acc: 0.9392 -- iter: 416/608
[A[ATraining Step: 318  | total loss: [1m[32m0.15985[0m[0m | time: 189.101s
[2K
| RMSProp | epoch: 017 | loss: 0.15985 - acc: 0.9390 -- iter: 448/608
[A[ATraining Step: 319  | total loss: [1m[32m0.16708[0m[0m | time: 202.892s
[2K
| RMSProp | epoch: 017 | loss: 0.16708 - acc: 0.9389 -- iter: 480/608
[A[ATraining Step: 320  | total loss: [1m[32m0.17575[0m[0m | time: 217.624s
[2K
| RMSProp | epoch: 017 | loss: 0.17575 - acc: 0.9356 -- iter: 512/608
[A[ATraining Step: 321  | total loss: [1m[32m0.16374[0m[0m | time: 232.542s
[2K
| RMSProp | epoch: 017 | loss: 0.16374 - acc: 0.9420 -- iter: 544/608
[A[ATraining Step: 322  | total loss: [1m[32m0.19207[0m[0m | time: 260.332s
[2K
| RMSProp | epoch: 017 | loss: 0.19207 - acc: 0.9385 -- iter: 576/608
[A[ATraining Step: 323  | total loss: [1m[32m0.20846[0m[0m | time: 290.370s
[2K
| RMSProp | epoch: 017 | loss: 0.20846 - acc: 0.9352 | val_loss: 2.40456 - val_acc: 0.4895 -- iter: 608/608
--
Training Step: 324  | total loss: [1m[32m0.21512[0m[0m | time: 13.847s
[2K
| RMSProp | epoch: 018 | loss: 0.21512 - acc: 0.9292 -- iter: 032/608
[A[ATraining Step: 325  | total loss: [1m[32m0.20911[0m[0m | time: 28.664s
[2K
| RMSProp | epoch: 018 | loss: 0.20911 - acc: 0.9269 -- iter: 064/608
[A[ATraining Step: 326  | total loss: [1m[32m0.19889[0m[0m | time: 42.956s
[2K
| RMSProp | epoch: 018 | loss: 0.19889 - acc: 0.9311 -- iter: 096/608
[A[ATraining Step: 327  | total loss: [1m[32m0.19661[0m[0m | time: 57.056s
[2K
| RMSProp | epoch: 018 | loss: 0.19661 - acc: 0.9317 -- iter: 128/608
[A[ATraining Step: 328  | total loss: [1m[32m0.18369[0m[0m | time: 71.531s
[2K
| RMSProp | epoch: 018 | loss: 0.18369 - acc: 0.9354 -- iter: 160/608
[A[ATraining Step: 329  | total loss: [1m[32m0.19401[0m[0m | time: 86.610s
[2K
| RMSProp | epoch: 018 | loss: 0.19401 - acc: 0.9357 -- iter: 192/608
[A[ATraining Step: 330  | total loss: [1m[32m0.19150[0m[0m | time: 100.539s
[2K
| RMSProp | epoch: 018 | loss: 0.19150 - acc: 0.9390 -- iter: 224/608
[A[ATraining Step: 331  | total loss: [1m[32m0.19641[0m[0m | time: 115.219s
[2K
| RMSProp | epoch: 018 | loss: 0.19641 - acc: 0.9388 -- iter: 256/608
[A[ATraining Step: 332  | total loss: [1m[32m0.18742[0m[0m | time: 133.810s
[2K
| RMSProp | epoch: 018 | loss: 0.18742 - acc: 0.9387 -- iter: 288/608
[A[ATraining Step: 333  | total loss: [1m[32m0.19540[0m[0m | time: 180.349s
[2K
| RMSProp | epoch: 018 | loss: 0.19540 - acc: 0.9354 -- iter: 320/608
[A[ATraining Step: 334  | total loss: [1m[32m0.19142[0m[0m | time: 193.897s
[2K
| RMSProp | epoch: 018 | loss: 0.19142 - acc: 0.9325 -- iter: 352/608
[A[ATraining Step: 335  | total loss: [1m[32m0.17778[0m[0m | time: 208.392s
[2K
| RMSProp | epoch: 018 | loss: 0.17778 - acc: 0.9393 -- iter: 384/608
[A[ATraining Step: 336  | total loss: [1m[32m0.17174[0m[0m | time: 223.077s
[2K
| RMSProp | epoch: 018 | loss: 0.17174 - acc: 0.9422 -- iter: 416/608
[A[ATraining Step: 337  | total loss: [1m[32m0.15956[0m[0m | time: 241.941s
[2K
| RMSProp | epoch: 018 | loss: 0.15956 - acc: 0.9449 -- iter: 448/608
[A[ATraining Step: 338  | total loss: [1m[32m0.15763[0m[0m | time: 256.035s
[2K
| RMSProp | epoch: 018 | loss: 0.15763 - acc: 0.9441 -- iter: 480/608
[A[ATraining Step: 339  | total loss: [1m[32m0.14821[0m[0m | time: 271.038s
[2K
| RMSProp | epoch: 018 | loss: 0.14821 - acc: 0.9466 -- iter: 512/608
[A[ATraining Step: 340  | total loss: [1m[32m0.14130[0m[0m | time: 283.811s
[2K
| RMSProp | epoch: 018 | loss: 0.14130 - acc: 0.9488 -- iter: 544/608
[A[ATraining Step: 341  | total loss: [1m[32m0.12966[0m[0m | time: 292.199s
[2K
| RMSProp | epoch: 018 | loss: 0.12966 - acc: 0.9539 -- iter: 576/608
[A[ATraining Step: 342  | total loss: [1m[32m0.15221[0m[0m | time: 315.523s
[2K
| RMSProp | epoch: 018 | loss: 0.15221 - acc: 0.9523 | val_loss: 1.50949 - val_acc: 0.6421 -- iter: 608/608
--
Training Step: 343  | total loss: [1m[32m0.14772[0m[0m | time: 14.559s
[2K
| RMSProp | epoch: 019 | loss: 0.14772 - acc: 0.9539 -- iter: 032/608
[A[ATraining Step: 344  | total loss: [1m[32m0.14072[0m[0m | time: 28.750s
[2K
| RMSProp | epoch: 019 | loss: 0.14072 - acc: 0.9585 -- iter: 064/608
[A[ATraining Step: 345  | total loss: [1m[32m0.13898[0m[0m | time: 42.843s
[2K
| RMSProp | epoch: 019 | loss: 0.13898 - acc: 0.9564 -- iter: 096/608
[A[ATraining Step: 346  | total loss: [1m[32m0.13934[0m[0m | time: 57.400s
[2K
| RMSProp | epoch: 019 | loss: 0.13934 - acc: 0.9545 -- iter: 128/608
[A[ATraining Step: 347  | total loss: [1m[32m0.14928[0m[0m | time: 71.972s
[2K
| RMSProp | epoch: 019 | loss: 0.14928 - acc: 0.9497 -- iter: 160/608
[A[ATraining Step: 348  | total loss: [1m[32m0.17614[0m[0m | time: 86.002s
[2K
| RMSProp | epoch: 019 | loss: 0.17614 - acc: 0.9454 -- iter: 192/608
[A[ATraining Step: 349  | total loss: [1m[32m0.17337[0m[0m | time: 99.736s
[2K
| RMSProp | epoch: 019 | loss: 0.17337 - acc: 0.9477 -- iter: 224/608
[A[ATraining Step: 350  | total loss: [1m[32m0.16529[0m[0m | time: 114.340s
[2K
| RMSProp | epoch: 019 | loss: 0.16529 - acc: 0.9467 -- iter: 256/608
[A[ATraining Step: 351  | total loss: [1m[32m0.15768[0m[0m | time: 128.735s
[2K
| RMSProp | epoch: 019 | loss: 0.15768 - acc: 0.9489 -- iter: 288/608
[A[ATraining Step: 352  | total loss: [1m[32m0.16833[0m[0m | time: 142.671s
[2K
| RMSProp | epoch: 019 | loss: 0.16833 - acc: 0.9446 -- iter: 320/608
[A[ATraining Step: 353  | total loss: [1m[32m0.18152[0m[0m | time: 156.596s
[2K
| RMSProp | epoch: 019 | loss: 0.18152 - acc: 0.9377 -- iter: 352/608
[A[ATraining Step: 354  | total loss: [1m[32m0.17400[0m[0m | time: 170.695s
[2K
| RMSProp | epoch: 019 | loss: 0.17400 - acc: 0.9408 -- iter: 384/608
[A[ATraining Step: 355  | total loss: [1m[32m0.16855[0m[0m | time: 185.201s
[2K
| RMSProp | epoch: 019 | loss: 0.16855 - acc: 0.9404 -- iter: 416/608
[A[ATraining Step: 356  | total loss: [1m[32m0.18977[0m[0m | time: 199.313s
[2K
| RMSProp | epoch: 019 | loss: 0.18977 - acc: 0.9339 -- iter: 448/608
[A[ATraining Step: 357  | total loss: [1m[32m0.18157[0m[0m | time: 213.822s
[2K
| RMSProp | epoch: 019 | loss: 0.18157 - acc: 0.9343 -- iter: 480/608
[A[ATraining Step: 358  | total loss: [1m[32m0.16676[0m[0m | time: 228.300s
[2K
| RMSProp | epoch: 019 | loss: 0.16676 - acc: 0.9408 -- iter: 512/608
[A[ATraining Step: 359  | total loss: [1m[32m0.17738[0m[0m | time: 263.656s
[2K
| RMSProp | epoch: 019 | loss: 0.17738 - acc: 0.9405 -- iter: 544/608
[A[ATraining Step: 360  | total loss: [1m[32m0.16357[0m[0m | time: 277.863s
[2K
| RMSProp | epoch: 019 | loss: 0.16357 - acc: 0.9465 -- iter: 576/608
[A[ATraining Step: 361  | total loss: [1m[32m0.14788[0m[0m | time: 308.409s
[2K
| RMSProp | epoch: 019 | loss: 0.14788 - acc: 0.9518 | val_loss: 1.77126 - val_acc: 0.5947 -- iter: 608/608
--
Training Step: 362  | total loss: [1m[32m0.14952[0m[0m | time: 8.861s
[2K
| RMSProp | epoch: 020 | loss: 0.14952 - acc: 0.9504 -- iter: 032/608
[A[ATraining Step: 363  | total loss: [1m[32m0.14912[0m[0m | time: 17.089s
[2K
| RMSProp | epoch: 020 | loss: 0.14912 - acc: 0.9491 -- iter: 064/608
[A[ATraining Step: 364  | total loss: [1m[32m0.14076[0m[0m | time: 25.681s
[2K
| RMSProp | epoch: 020 | loss: 0.14076 - acc: 0.9511 -- iter: 096/608
[A[ATraining Step: 365  | total loss: [1m[32m0.14602[0m[0m | time: 39.355s
[2K
| RMSProp | epoch: 020 | loss: 0.14602 - acc: 0.9497 -- iter: 128/608
[A[ATraining Step: 366  | total loss: [1m[32m0.17463[0m[0m | time: 61.420s
[2K
| RMSProp | epoch: 020 | loss: 0.17463 - acc: 0.9485 -- iter: 160/608
[A[ATraining Step: 367  | total loss: [1m[32m0.16356[0m[0m | time: 75.002s
[2K
| RMSProp | epoch: 020 | loss: 0.16356 - acc: 0.9505 -- iter: 192/608
[A[ATraining Step: 368  | total loss: [1m[32m0.17586[0m[0m | time: 89.565s
[2K
| RMSProp | epoch: 020 | loss: 0.17586 - acc: 0.9492 -- iter: 224/608
[A[ATraining Step: 369  | total loss: [1m[32m0.16623[0m[0m | time: 103.310s
[2K
| RMSProp | epoch: 020 | loss: 0.16623 - acc: 0.9512 -- iter: 256/608
[A[ATraining Step: 370  | total loss: [1m[32m0.15796[0m[0m | time: 117.632s
[2K
| RMSProp | epoch: 020 | loss: 0.15796 - acc: 0.9498 -- iter: 288/608
[A[ATraining Step: 371  | total loss: [1m[32m0.17718[0m[0m | time: 131.895s
[2K
| RMSProp | epoch: 020 | loss: 0.17718 - acc: 0.9423 -- iter: 320/608
[A[ATraining Step: 372  | total loss: [1m[32m0.17117[0m[0m | time: 145.964s
[2K
| RMSProp | epoch: 020 | loss: 0.17117 - acc: 0.9418 -- iter: 352/608
[A[ATraining Step: 373  | total loss: [1m[32m0.17241[0m[0m | time: 172.094s
[2K
| RMSProp | epoch: 020 | loss: 0.17241 - acc: 0.9445 -- iter: 384/608
[A[ATraining Step: 374  | total loss: [1m[32m0.18046[0m[0m | time: 187.005s
[2K
| RMSProp | epoch: 020 | loss: 0.18046 - acc: 0.9438 -- iter: 416/608
[A[ATraining Step: 375  | total loss: [1m[32m0.17907[0m[0m | time: 201.219s
[2K
| RMSProp | epoch: 020 | loss: 0.17907 - acc: 0.9401 -- iter: 448/608
[A[ATraining Step: 376  | total loss: [1m[32m0.16414[0m[0m | time: 216.175s
[2K
| RMSProp | epoch: 020 | loss: 0.16414 - acc: 0.9461 -- iter: 480/608
[A[ATraining Step: 377  | total loss: [1m[32m0.17056[0m[0m | time: 230.163s
[2K
| RMSProp | epoch: 020 | loss: 0.17056 - acc: 0.9452 -- iter: 512/608
[A[ATraining Step: 378  | total loss: [1m[32m0.16029[0m[0m | time: 244.366s
[2K
| RMSProp | epoch: 020 | loss: 0.16029 - acc: 0.9444 -- iter: 544/608
[A[ATraining Step: 379  | total loss: [1m[32m0.15246[0m[0m | time: 259.246s
[2K
| RMSProp | epoch: 020 | loss: 0.15246 - acc: 0.9500 -- iter: 576/608
[A[ATraining Step: 380  | total loss: [1m[32m0.15247[0m[0m | time: 288.436s
[2K
| RMSProp | epoch: 020 | loss: 0.15247 - acc: 0.9487 | val_loss: 2.20684 - val_acc: 0.5158 -- iter: 608/608
--
Training Step: 381  | total loss: [1m[32m0.14217[0m[0m | time: 13.676s
[2K
| RMSProp | epoch: 021 | loss: 0.14217 - acc: 0.9539 -- iter: 032/608
[A[ATraining Step: 382  | total loss: [1m[32m0.13364[0m[0m | time: 27.352s
[2K
| RMSProp | epoch: 021 | loss: 0.13364 - acc: 0.9554 -- iter: 064/608
[A[ATraining Step: 383  | total loss: [1m[32m0.15263[0m[0m | time: 41.718s
[2K
| RMSProp | epoch: 021 | loss: 0.15263 - acc: 0.9504 -- iter: 096/608
[A[ATraining Step: 384  | total loss: [1m[32m0.16043[0m[0m | time: 56.093s
[2K
| RMSProp | epoch: 021 | loss: 0.16043 - acc: 0.9491 -- iter: 128/608
[A[ATraining Step: 385  | total loss: [1m[32m0.16231[0m[0m | time: 70.189s
[2K
| RMSProp | epoch: 021 | loss: 0.16231 - acc: 0.9480 -- iter: 160/608
[A[ATraining Step: 386  | total loss: [1m[32m0.16785[0m[0m | time: 84.913s
[2K
| RMSProp | epoch: 021 | loss: 0.16785 - acc: 0.9407 -- iter: 192/608
[A[ATraining Step: 387  | total loss: [1m[32m0.16813[0m[0m | time: 97.581s
[2K
| RMSProp | epoch: 021 | loss: 0.16813 - acc: 0.9404 -- iter: 224/608
[A[ATraining Step: 388  | total loss: [1m[32m0.16316[0m[0m | time: 106.115s
[2K
| RMSProp | epoch: 021 | loss: 0.16316 - acc: 0.9401 -- iter: 256/608
[A[ATraining Step: 389  | total loss: [1m[32m0.16997[0m[0m | time: 114.640s
[2K
| RMSProp | epoch: 021 | loss: 0.16997 - acc: 0.9398 -- iter: 288/608
[A[ATraining Step: 390  | total loss: [1m[32m0.15780[0m[0m | time: 123.321s
[2K
| RMSProp | epoch: 021 | loss: 0.15780 - acc: 0.9427 -- iter: 320/608
[A[ATraining Step: 391  | total loss: [1m[32m0.14416[0m[0m | time: 136.364s
[2K
| RMSProp | epoch: 021 | loss: 0.14416 - acc: 0.9484 -- iter: 352/608
[A[ATraining Step: 392  | total loss: [1m[32m0.13276[0m[0m | time: 151.211s
[2K
| RMSProp | epoch: 021 | loss: 0.13276 - acc: 0.9536 -- iter: 384/608
[A[ATraining Step: 393  | total loss: [1m[32m0.14265[0m[0m | time: 163.563s
[2K
| RMSProp | epoch: 021 | loss: 0.14265 - acc: 0.9551 -- iter: 416/608
[A[ATraining Step: 394  | total loss: [1m[32m0.13573[0m[0m | time: 178.058s
[2K
| RMSProp | epoch: 021 | loss: 0.13573 - acc: 0.9565 -- iter: 448/608
[A[ATraining Step: 395  | total loss: [1m[32m0.15163[0m[0m | time: 191.843s
[2K
| RMSProp | epoch: 021 | loss: 0.15163 - acc: 0.9546 -- iter: 480/608
[A[ATraining Step: 396  | total loss: [1m[32m0.13769[0m[0m | time: 206.510s
[2K
| RMSProp | epoch: 021 | loss: 0.13769 - acc: 0.9591 -- iter: 512/608
[A[ATraining Step: 397  | total loss: [1m[32m0.12554[0m[0m | time: 221.237s
[2K
| RMSProp | epoch: 021 | loss: 0.12554 - acc: 0.9632 -- iter: 544/608
[A[ATraining Step: 398  | total loss: [1m[32m0.11487[0m[0m | time: 235.098s
[2K
| RMSProp | epoch: 021 | loss: 0.11487 - acc: 0.9669 -- iter: 576/608
[A[ATraining Step: 399  | total loss: [1m[32m0.12369[0m[0m | time: 264.641s
[2K
| RMSProp | epoch: 021 | loss: 0.12369 - acc: 0.9671 | val_loss: 1.69114 - val_acc: 0.5368 -- iter: 608/608
--
Training Step: 400  | total loss: [1m[32m0.13301[0m[0m | time: 31.165s
[2K
| RMSProp | epoch: 022 | loss: 0.13301 - acc: 0.9672 | val_loss: 1.20349 - val_acc: 0.6263 -- iter: 032/608
--
Training Step: 401  | total loss: [1m[32m0.12369[0m[0m | time: 45.442s
[2K
| RMSProp | epoch: 022 | loss: 0.12369 - acc: 0.9705 -- iter: 064/608
[A[ATraining Step: 402  | total loss: [1m[32m0.11744[0m[0m | time: 59.532s
[2K
| RMSProp | epoch: 022 | loss: 0.11744 - acc: 0.9703 -- iter: 096/608
[A[ATraining Step: 403  | total loss: [1m[32m0.11462[0m[0m | time: 73.706s
[2K
| RMSProp | epoch: 022 | loss: 0.11462 - acc: 0.9702 -- iter: 128/608
[A[ATraining Step: 404  | total loss: [1m[32m0.19081[0m[0m | time: 87.977s
[2K
| RMSProp | epoch: 022 | loss: 0.19081 - acc: 0.9544 -- iter: 160/608
[A[ATraining Step: 405  | total loss: [1m[32m0.17706[0m[0m | time: 123.130s
[2K
| RMSProp | epoch: 022 | loss: 0.17706 - acc: 0.9590 -- iter: 192/608
[A[ATraining Step: 406  | total loss: [1m[32m0.16299[0m[0m | time: 136.694s
[2K
| RMSProp | epoch: 022 | loss: 0.16299 - acc: 0.9600 -- iter: 224/608
[A[ATraining Step: 407  | total loss: [1m[32m0.15581[0m[0m | time: 150.536s
[2K
| RMSProp | epoch: 022 | loss: 0.15581 - acc: 0.9608 -- iter: 256/608
[A[ATraining Step: 408  | total loss: [1m[32m0.15636[0m[0m | time: 164.796s
[2K
| RMSProp | epoch: 022 | loss: 0.15636 - acc: 0.9616 -- iter: 288/608
[A[ATraining Step: 409  | total loss: [1m[32m0.14221[0m[0m | time: 180.934s
[2K
| RMSProp | epoch: 022 | loss: 0.14221 - acc: 0.9655 -- iter: 320/608
[A[ATraining Step: 410  | total loss: [1m[32m0.13193[0m[0m | time: 196.209s
[2K
| RMSProp | epoch: 022 | loss: 0.13193 - acc: 0.9689 -- iter: 352/608
[A[ATraining Step: 411  | total loss: [1m[32m0.12307[0m[0m | time: 205.918s
[2K
| RMSProp | epoch: 022 | loss: 0.12307 - acc: 0.9720 -- iter: 384/608
[A[ATraining Step: 412  | total loss: [1m[32m0.11962[0m[0m | time: 214.693s
[2K
| RMSProp | epoch: 022 | loss: 0.11962 - acc: 0.9717 -- iter: 416/608
[A[ATraining Step: 413  | total loss: [1m[32m0.11523[0m[0m | time: 224.886s
[2K
| RMSProp | epoch: 022 | loss: 0.11523 - acc: 0.9714 -- iter: 448/608
[A[ATraining Step: 414  | total loss: [1m[32m0.10929[0m[0m | time: 239.105s
[2K
| RMSProp | epoch: 022 | loss: 0.10929 - acc: 0.9711 -- iter: 480/608
[A[ATraining Step: 415  | total loss: [1m[32m0.13686[0m[0m | time: 253.467s
[2K
| RMSProp | epoch: 022 | loss: 0.13686 - acc: 0.9678 -- iter: 512/608
[A[ATraining Step: 416  | total loss: [1m[32m0.13679[0m[0m | time: 267.565s
[2K
| RMSProp | epoch: 022 | loss: 0.13679 - acc: 0.9679 -- iter: 544/608
[A[ATraining Step: 417  | total loss: [1m[32m0.12638[0m[0m | time: 279.947s
[2K
| RMSProp | epoch: 022 | loss: 0.12638 - acc: 0.9711 -- iter: 576/608
[A[ATraining Step: 418  | total loss: [1m[32m0.13391[0m[0m | time: 310.486s
[2K
| RMSProp | epoch: 022 | loss: 0.13391 - acc: 0.9677 | val_loss: 1.32834 - val_acc: 0.6263 -- iter: 608/608
--
Training Step: 419  | total loss: [1m[32m0.12946[0m[0m | time: 14.302s
[2K
| RMSProp | epoch: 023 | loss: 0.12946 - acc: 0.9678 -- iter: 032/608
[A[ATraining Step: 420  | total loss: [1m[32m0.13969[0m[0m | time: 27.902s
[2K
| RMSProp | epoch: 023 | loss: 0.13969 - acc: 0.9617 -- iter: 064/608
[A[ATraining Step: 421  | total loss: [1m[32m0.12703[0m[0m | time: 42.181s
[2K
| RMSProp | epoch: 023 | loss: 0.12703 - acc: 0.9655 -- iter: 096/608
[A[ATraining Step: 422  | total loss: [1m[32m0.12093[0m[0m | time: 56.554s
[2K
| RMSProp | epoch: 023 | loss: 0.12093 - acc: 0.9658 -- iter: 128/608
[A[ATraining Step: 423  | total loss: [1m[32m0.12517[0m[0m | time: 78.438s
[2K
| RMSProp | epoch: 023 | loss: 0.12517 - acc: 0.9661 -- iter: 160/608
[A[ATraining Step: 424  | total loss: [1m[32m0.12111[0m[0m | time: 92.608s
[2K
| RMSProp | epoch: 023 | loss: 0.12111 - acc: 0.9664 -- iter: 192/608
[A[ATraining Step: 425  | total loss: [1m[32m0.12077[0m[0m | time: 107.120s
[2K
| RMSProp | epoch: 023 | loss: 0.12077 - acc: 0.9666 -- iter: 224/608
[A[ATraining Step: 426  | total loss: [1m[32m0.12307[0m[0m | time: 121.662s
[2K
| RMSProp | epoch: 023 | loss: 0.12307 - acc: 0.9637 -- iter: 256/608
[A[ATraining Step: 427  | total loss: [1m[32m0.13187[0m[0m | time: 136.123s
[2K
| RMSProp | epoch: 023 | loss: 0.13187 - acc: 0.9580 -- iter: 288/608
[A[ATraining Step: 428  | total loss: [1m[32m0.14618[0m[0m | time: 150.523s
[2K
| RMSProp | epoch: 023 | loss: 0.14618 - acc: 0.9590 -- iter: 320/608
[A[ATraining Step: 429  | total loss: [1m[32m0.13780[0m[0m | time: 165.198s
[2K
| RMSProp | epoch: 023 | loss: 0.13780 - acc: 0.9631 -- iter: 352/608
[A[ATraining Step: 430  | total loss: [1m[32m0.16789[0m[0m | time: 193.714s
[2K
| RMSProp | epoch: 023 | loss: 0.16789 - acc: 0.9574 -- iter: 384/608
[A[ATraining Step: 431  | total loss: [1m[32m0.16091[0m[0m | time: 207.317s
[2K
| RMSProp | epoch: 023 | loss: 0.16091 - acc: 0.9555 -- iter: 416/608
[A[ATraining Step: 432  | total loss: [1m[32m0.16109[0m[0m | time: 221.482s
[2K
| RMSProp | epoch: 023 | loss: 0.16109 - acc: 0.9568 -- iter: 448/608
[A[ATraining Step: 433  | total loss: [1m[32m0.14863[0m[0m | time: 236.041s
[2K
| RMSProp | epoch: 023 | loss: 0.14863 - acc: 0.9611 -- iter: 480/608
[A[ATraining Step: 434  | total loss: [1m[32m0.14848[0m[0m | time: 252.436s
[2K
| RMSProp | epoch: 023 | loss: 0.14848 - acc: 0.9587 -- iter: 512/608
[A[ATraining Step: 435  | total loss: [1m[32m0.13961[0m[0m | time: 266.420s
[2K
| RMSProp | epoch: 023 | loss: 0.13961 - acc: 0.9597 -- iter: 544/608
[A[ATraining Step: 436  | total loss: [1m[32m0.14144[0m[0m | time: 280.304s
[2K
| RMSProp | epoch: 023 | loss: 0.14144 - acc: 0.9575 -- iter: 576/608
[A[ATraining Step: 437  | total loss: [1m[32m0.12859[0m[0m | time: 307.747s
[2K
| RMSProp | epoch: 023 | loss: 0.12859 - acc: 0.9618 | val_loss: 2.15917 - val_acc: 0.5105 -- iter: 608/608
--
Training Step: 438  | total loss: [1m[32m0.13793[0m[0m | time: 13.889s
[2K
| RMSProp | epoch: 024 | loss: 0.13793 - acc: 0.9625 -- iter: 032/608
[A[ATraining Step: 439  | total loss: [1m[32m0.13163[0m[0m | time: 28.487s
[2K
| RMSProp | epoch: 024 | loss: 0.13163 - acc: 0.9631 -- iter: 064/608
[A[ATraining Step: 440  | total loss: [1m[32m0.13365[0m[0m | time: 61.547s
[2K
| RMSProp | epoch: 024 | loss: 0.13365 - acc: 0.9637 -- iter: 096/608
[A[ATraining Step: 441  | total loss: [1m[32m0.12140[0m[0m | time: 74.164s
[2K
| RMSProp | epoch: 024 | loss: 0.12140 - acc: 0.9673 -- iter: 128/608
[A[ATraining Step: 442  | total loss: [1m[32m0.11289[0m[0m | time: 88.671s
[2K
| RMSProp | epoch: 024 | loss: 0.11289 - acc: 0.9674 -- iter: 160/608
[A[ATraining Step: 443  | total loss: [1m[32m0.11450[0m[0m | time: 102.728s
[2K
| RMSProp | epoch: 024 | loss: 0.11450 - acc: 0.9644 -- iter: 192/608
[A[ATraining Step: 444  | total loss: [1m[32m0.10712[0m[0m | time: 116.725s
[2K
| RMSProp | epoch: 024 | loss: 0.10712 - acc: 0.9680 -- iter: 224/608
[A[ATraining Step: 445  | total loss: [1m[32m0.10393[0m[0m | time: 131.080s
[2K
| RMSProp | epoch: 024 | loss: 0.10393 - acc: 0.9681 -- iter: 256/608
[A[ATraining Step: 446  | total loss: [1m[32m0.09493[0m[0m | time: 145.430s
[2K
| RMSProp | epoch: 024 | loss: 0.09493 - acc: 0.9713 -- iter: 288/608
[A[ATraining Step: 447  | total loss: [1m[32m0.10113[0m[0m | time: 159.301s
[2K
| RMSProp | epoch: 024 | loss: 0.10113 - acc: 0.9679 -- iter: 320/608
[A[ATraining Step: 448  | total loss: [1m[32m0.12403[0m[0m | time: 172.976s
[2K
| RMSProp | epoch: 024 | loss: 0.12403 - acc: 0.9649 -- iter: 352/608
[A[ATraining Step: 449  | total loss: [1m[32m0.12972[0m[0m | time: 187.359s
[2K
| RMSProp | epoch: 024 | loss: 0.12972 - acc: 0.9652 -- iter: 384/608
[A[ATraining Step: 450  | total loss: [1m[32m0.12201[0m[0m | time: 201.424s
[2K
| RMSProp | epoch: 024 | loss: 0.12201 - acc: 0.9687 -- iter: 416/608
[A[ATraining Step: 451  | total loss: [1m[32m0.12277[0m[0m | time: 215.564s
[2K
| RMSProp | epoch: 024 | loss: 0.12277 - acc: 0.9687 -- iter: 448/608
[A[ATraining Step: 452  | total loss: [1m[32m0.12076[0m[0m | time: 229.502s
[2K
| RMSProp | epoch: 024 | loss: 0.12076 - acc: 0.9687 -- iter: 480/608
[A[ATraining Step: 453  | total loss: [1m[32m0.14859[0m[0m | time: 243.189s
[2K
| RMSProp | epoch: 024 | loss: 0.14859 - acc: 0.9625 -- iter: 512/608
[A[ATraining Step: 454  | total loss: [1m[32m0.14078[0m[0m | time: 257.554s
[2K
| RMSProp | epoch: 024 | loss: 0.14078 - acc: 0.9662 -- iter: 544/608
[A[ATraining Step: 455  | total loss: [1m[32m0.13835[0m[0m | time: 271.685s
[2K
| RMSProp | epoch: 024 | loss: 0.13835 - acc: 0.9634 -- iter: 576/608
[A[ATraining Step: 456  | total loss: [1m[32m0.13712[0m[0m | time: 300.229s
[2K
| RMSProp | epoch: 024 | loss: 0.13712 - acc: 0.9639 | val_loss: 2.78803 - val_acc: 0.4947 -- iter: 608/608
--
Training Step: 457  | total loss: [1m[32m0.13522[0m[0m | time: 14.167s
[2K
| RMSProp | epoch: 025 | loss: 0.13522 - acc: 0.9644 -- iter: 032/608
[A[ATraining Step: 458  | total loss: [1m[32m0.12360[0m[0m | time: 28.388s
[2K
| RMSProp | epoch: 025 | loss: 0.12360 - acc: 0.9679 -- iter: 064/608
[A[ATraining Step: 459  | total loss: [1m[32m0.12533[0m[0m | time: 43.576s
[2K
| RMSProp | epoch: 025 | loss: 0.12533 - acc: 0.9649 -- iter: 096/608
[A[ATraining Step: 460  | total loss: [1m[32m0.12469[0m[0m | time: 54.047s
[2K
| RMSProp | epoch: 025 | loss: 0.12469 - acc: 0.9622 -- iter: 128/608
[A[ATraining Step: 461  | total loss: [1m[32m0.12291[0m[0m | time: 62.375s
[2K
| RMSProp | epoch: 025 | loss: 0.12291 - acc: 0.9628 -- iter: 160/608
[A[ATraining Step: 462  | total loss: [1m[32m0.13668[0m[0m | time: 72.914s
[2K
| RMSProp | epoch: 025 | loss: 0.13668 - acc: 0.9509 -- iter: 192/608
[A[ATraining Step: 463  | total loss: [1m[32m0.14979[0m[0m | time: 87.022s
[2K
| RMSProp | epoch: 025 | loss: 0.14979 - acc: 0.9433 -- iter: 224/608
[A[ATraining Step: 464  | total loss: [1m[32m0.13990[0m[0m | time: 101.247s
[2K
| RMSProp | epoch: 025 | loss: 0.13990 - acc: 0.9490 -- iter: 256/608
[A[ATraining Step: 465  | total loss: [1m[32m0.13668[0m[0m | time: 115.538s
[2K
| RMSProp | epoch: 025 | loss: 0.13668 - acc: 0.9510 -- iter: 288/608
[A[ATraining Step: 466  | total loss: [1m[32m0.12879[0m[0m | time: 129.497s
[2K
| RMSProp | epoch: 025 | loss: 0.12879 - acc: 0.9559 -- iter: 320/608
[A[ATraining Step: 467  | total loss: [1m[32m0.12462[0m[0m | time: 141.564s
[2K
| RMSProp | epoch: 025 | loss: 0.12462 - acc: 0.9572 -- iter: 352/608
[A[ATraining Step: 468  | total loss: [1m[32m0.20574[0m[0m | time: 155.763s
[2K
| RMSProp | epoch: 025 | loss: 0.20574 - acc: 0.9396 -- iter: 384/608
[A[ATraining Step: 469  | total loss: [1m[32m0.20543[0m[0m | time: 169.454s
[2K
| RMSProp | epoch: 025 | loss: 0.20543 - acc: 0.9362 -- iter: 416/608
[A[ATraining Step: 470  | total loss: [1m[32m0.19119[0m[0m | time: 183.694s
[2K
| RMSProp | epoch: 025 | loss: 0.19119 - acc: 0.9395 -- iter: 448/608
[A[ATraining Step: 471  | total loss: [1m[32m0.17682[0m[0m | time: 198.361s
[2K
| RMSProp | epoch: 025 | loss: 0.17682 - acc: 0.9424 -- iter: 480/608
[A[ATraining Step: 472  | total loss: [1m[32m0.15988[0m[0m | time: 212.253s
[2K
| RMSProp | epoch: 025 | loss: 0.15988 - acc: 0.9482 -- iter: 512/608
[A[ATraining Step: 473  | total loss: [1m[32m0.15133[0m[0m | time: 226.297s
[2K
| RMSProp | epoch: 025 | loss: 0.15133 - acc: 0.9502 -- iter: 544/608
[A[ATraining Step: 474  | total loss: [1m[32m0.14171[0m[0m | time: 240.173s
[2K
| RMSProp | epoch: 025 | loss: 0.14171 - acc: 0.9521 -- iter: 576/608
[A[ATraining Step: 475  | total loss: [1m[32m0.16509[0m[0m | time: 270.002s
[2K
| RMSProp | epoch: 025 | loss: 0.16509 - acc: 0.9412 | val_loss: 1.15330 - val_acc: 0.6421 -- iter: 608/608
--
Training Step: 476  | total loss: [1m[32m0.17855[0m[0m | time: 14.007s
[2K
| RMSProp | epoch: 026 | loss: 0.17855 - acc: 0.9409 -- iter: 032/608
[A[ATraining Step: 477  | total loss: [1m[32m0.16494[0m[0m | time: 28.316s
[2K
| RMSProp | epoch: 026 | loss: 0.16494 - acc: 0.9468 -- iter: 064/608
[A[ATraining Step: 478  | total loss: [1m[32m0.16993[0m[0m | time: 42.594s
[2K
| RMSProp | epoch: 026 | loss: 0.16993 - acc: 0.9427 -- iter: 096/608
[A[ATraining Step: 479  | total loss: [1m[32m0.19334[0m[0m | time: 56.803s
[2K
| RMSProp | epoch: 026 | loss: 0.19334 - acc: 0.9422 -- iter: 128/608
[A[ATraining Step: 480  | total loss: [1m[32m0.20243[0m[0m | time: 71.328s
[2K
| RMSProp | epoch: 026 | loss: 0.20243 - acc: 0.9386 -- iter: 160/608
[A[ATraining Step: 481  | total loss: [1m[32m0.18331[0m[0m | time: 85.497s
[2K
| RMSProp | epoch: 026 | loss: 0.18331 - acc: 0.9448 -- iter: 192/608
[A[ATraining Step: 482  | total loss: [1m[32m0.18159[0m[0m | time: 99.869s
[2K
| RMSProp | epoch: 026 | loss: 0.18159 - acc: 0.9378 -- iter: 224/608
[A[ATraining Step: 483  | total loss: [1m[32m0.19742[0m[0m | time: 113.881s
[2K
| RMSProp | epoch: 026 | loss: 0.19742 - acc: 0.9346 -- iter: 256/608
[A[ATraining Step: 484  | total loss: [1m[32m0.18329[0m[0m | time: 128.586s
[2K
| RMSProp | epoch: 026 | loss: 0.18329 - acc: 0.9412 -- iter: 288/608
[A[ATraining Step: 485  | total loss: [1m[32m0.17357[0m[0m | time: 137.337s
[2K
| RMSProp | epoch: 026 | loss: 0.17357 - acc: 0.9408 -- iter: 320/608
[A[ATraining Step: 486  | total loss: [1m[32m0.16175[0m[0m | time: 145.717s
[2K
| RMSProp | epoch: 026 | loss: 0.16175 - acc: 0.9436 -- iter: 352/608
[A[ATraining Step: 487  | total loss: [1m[32m0.15423[0m[0m | time: 156.864s
[2K
| RMSProp | epoch: 026 | loss: 0.15423 - acc: 0.9430 -- iter: 384/608
[A[ATraining Step: 488  | total loss: [1m[32m0.14791[0m[0m | time: 171.222s
[2K
| RMSProp | epoch: 026 | loss: 0.14791 - acc: 0.9456 -- iter: 416/608
[A[ATraining Step: 489  | total loss: [1m[32m0.14288[0m[0m | time: 185.831s
[2K
| RMSProp | epoch: 026 | loss: 0.14288 - acc: 0.9510 -- iter: 448/608
[A[ATraining Step: 490  | total loss: [1m[32m0.13149[0m[0m | time: 199.024s
[2K
| RMSProp | epoch: 026 | loss: 0.13149 - acc: 0.9559 -- iter: 480/608
[A[ATraining Step: 491  | total loss: [1m[32m0.12546[0m[0m | time: 213.059s
[2K
| RMSProp | epoch: 026 | loss: 0.12546 - acc: 0.9572 -- iter: 512/608
[A[ATraining Step: 492  | total loss: [1m[32m0.11441[0m[0m | time: 227.419s
[2K
| RMSProp | epoch: 026 | loss: 0.11441 - acc: 0.9615 -- iter: 544/608
[A[ATraining Step: 493  | total loss: [1m[32m0.12174[0m[0m | time: 239.703s
[2K
| RMSProp | epoch: 026 | loss: 0.12174 - acc: 0.9591 -- iter: 576/608
[A[ATraining Step: 494  | total loss: [1m[32m0.11286[0m[0m | time: 268.897s
[2K
| RMSProp | epoch: 026 | loss: 0.11286 - acc: 0.9632 | val_loss: 1.64378 - val_acc: 0.6053 -- iter: 608/608
--
Training Step: 495  | total loss: [1m[32m0.11069[0m[0m | time: 14.157s
[2K
| RMSProp | epoch: 027 | loss: 0.11069 - acc: 0.9606 -- iter: 032/608
[A[ATraining Step: 496  | total loss: [1m[32m0.10320[0m[0m | time: 28.398s
[2K
| RMSProp | epoch: 027 | loss: 0.10320 - acc: 0.9645 -- iter: 064/608
[A[ATraining Step: 497  | total loss: [1m[32m0.11262[0m[0m | time: 42.125s
[2K
| RMSProp | epoch: 027 | loss: 0.11262 - acc: 0.9587 -- iter: 096/608
[A[ATraining Step: 498  | total loss: [1m[32m0.10554[0m[0m | time: 55.565s
[2K
| RMSProp | epoch: 027 | loss: 0.10554 - acc: 0.9628 -- iter: 128/608
[A[ATraining Step: 499  | total loss: [1m[32m0.10736[0m[0m | time: 69.663s
[2K
| RMSProp | epoch: 027 | loss: 0.10736 - acc: 0.9634 -- iter: 160/608
[A[ATraining Step: 500  | total loss: [1m[32m0.10280[0m[0m | time: 83.515s
[2K
| RMSProp | epoch: 027 | loss: 0.10280 - acc: 0.9640 -- iter: 192/608
[A[ATraining Step: 501  | total loss: [1m[32m0.09308[0m[0m | time: 98.123s
[2K
| RMSProp | epoch: 027 | loss: 0.09308 - acc: 0.9676 -- iter: 224/608
[A[ATraining Step: 502  | total loss: [1m[32m0.11534[0m[0m | time: 111.895s
[2K
| RMSProp | epoch: 027 | loss: 0.11534 - acc: 0.9552 -- iter: 256/608
[A[ATraining Step: 503  | total loss: [1m[32m0.11150[0m[0m | time: 126.143s
[2K
| RMSProp | epoch: 027 | loss: 0.11150 - acc: 0.9565 -- iter: 288/608
[A[ATraining Step: 504  | total loss: [1m[32m0.10729[0m[0m | time: 140.254s
[2K
| RMSProp | epoch: 027 | loss: 0.10729 - acc: 0.9578 -- iter: 320/608
[A[ATraining Step: 505  | total loss: [1m[32m0.10494[0m[0m | time: 154.699s
[2K
| RMSProp | epoch: 027 | loss: 0.10494 - acc: 0.9589 -- iter: 352/608
[A[ATraining Step: 506  | total loss: [1m[32m0.12196[0m[0m | time: 168.130s
[2K
| RMSProp | epoch: 027 | loss: 0.12196 - acc: 0.9473 -- iter: 384/608
[A[ATraining Step: 507  | total loss: [1m[32m0.12718[0m[0m | time: 182.329s
[2K
| RMSProp | epoch: 027 | loss: 0.12718 - acc: 0.9464 -- iter: 416/608
[A[ATraining Step: 508  | total loss: [1m[32m0.11654[0m[0m | time: 196.584s
[2K
| RMSProp | epoch: 027 | loss: 0.11654 - acc: 0.9517 -- iter: 448/608
[A[ATraining Step: 509  | total loss: [1m[32m0.10645[0m[0m | time: 210.993s
[2K
| RMSProp | epoch: 027 | loss: 0.10645 - acc: 0.9566 -- iter: 480/608
[A[ATraining Step: 510  | total loss: [1m[32m0.10223[0m[0m | time: 222.791s
[2K
| RMSProp | epoch: 027 | loss: 0.10223 - acc: 0.9578 -- iter: 512/608
[A[ATraining Step: 511  | total loss: [1m[32m0.10393[0m[0m | time: 231.508s
[2K
| RMSProp | epoch: 027 | loss: 0.10393 - acc: 0.9589 -- iter: 544/608
[A[ATraining Step: 512  | total loss: [1m[32m0.10406[0m[0m | time: 240.114s
[2K
| RMSProp | epoch: 027 | loss: 0.10406 - acc: 0.9599 -- iter: 576/608
[A[ATraining Step: 513  | total loss: [1m[32m0.09465[0m[0m | time: 269.263s
[2K
| RMSProp | epoch: 027 | loss: 0.09465 - acc: 0.9639 | val_loss: 1.64511 - val_acc: 0.6737 -- iter: 608/608
--
Training Step: 514  | total loss: [1m[32m0.09158[0m[0m | time: 13.923s
[2K
| RMSProp | epoch: 028 | loss: 0.09158 - acc: 0.9644 -- iter: 032/608
[A[ATraining Step: 515  | total loss: [1m[32m0.09054[0m[0m | time: 27.805s
[2K
| RMSProp | epoch: 028 | loss: 0.09054 - acc: 0.9648 -- iter: 064/608
[A[ATraining Step: 516  | total loss: [1m[32m0.09180[0m[0m | time: 39.372s
[2K
| RMSProp | epoch: 028 | loss: 0.09180 - acc: 0.9621 -- iter: 096/608
[A[ATraining Step: 517  | total loss: [1m[32m0.10684[0m[0m | time: 52.817s
[2K
| RMSProp | epoch: 028 | loss: 0.10684 - acc: 0.9565 -- iter: 128/608
[A[ATraining Step: 518  | total loss: [1m[32m0.13569[0m[0m | time: 66.319s
[2K
| RMSProp | epoch: 028 | loss: 0.13569 - acc: 0.9515 -- iter: 160/608
[A[ATraining Step: 519  | total loss: [1m[32m0.15847[0m[0m | time: 80.850s
[2K
| RMSProp | epoch: 028 | loss: 0.15847 - acc: 0.9376 -- iter: 192/608
[A[ATraining Step: 520  | total loss: [1m[32m0.17145[0m[0m | time: 94.720s
[2K
| RMSProp | epoch: 028 | loss: 0.17145 - acc: 0.9376 -- iter: 224/608
[A[ATraining Step: 521  | total loss: [1m[32m0.15542[0m[0m | time: 108.413s
[2K
| RMSProp | epoch: 028 | loss: 0.15542 - acc: 0.9438 -- iter: 256/608
[A[ATraining Step: 522  | total loss: [1m[32m0.14898[0m[0m | time: 122.194s
[2K
| RMSProp | epoch: 028 | loss: 0.14898 - acc: 0.9463 -- iter: 288/608
[A[ATraining Step: 523  | total loss: [1m[32m0.14366[0m[0m | time: 136.348s
[2K
| RMSProp | epoch: 028 | loss: 0.14366 - acc: 0.9485 -- iter: 320/608
[A[ATraining Step: 524  | total loss: [1m[32m0.15391[0m[0m | time: 149.985s
[2K
| RMSProp | epoch: 028 | loss: 0.15391 - acc: 0.9443 -- iter: 352/608
[A[ATraining Step: 525  | total loss: [1m[32m0.14210[0m[0m | time: 163.252s
[2K
| RMSProp | epoch: 028 | loss: 0.14210 - acc: 0.9499 -- iter: 384/608
[A[ATraining Step: 526  | total loss: [1m[32m0.13658[0m[0m | time: 177.012s
[2K
| RMSProp | epoch: 028 | loss: 0.13658 - acc: 0.9518 -- iter: 416/608
[A[ATraining Step: 527  | total loss: [1m[32m0.13010[0m[0m | time: 190.907s
[2K
| RMSProp | epoch: 028 | loss: 0.13010 - acc: 0.9535 -- iter: 448/608
[A[ATraining Step: 528  | total loss: [1m[32m0.16580[0m[0m | time: 204.594s
[2K
| RMSProp | epoch: 028 | loss: 0.16580 - acc: 0.9487 -- iter: 480/608
[A[ATraining Step: 529  | total loss: [1m[32m0.16796[0m[0m | time: 218.654s
[2K
| RMSProp | epoch: 028 | loss: 0.16796 - acc: 0.9414 -- iter: 512/608
[A[ATraining Step: 530  | total loss: [1m[32m0.15870[0m[0m | time: 232.102s
[2K
| RMSProp | epoch: 028 | loss: 0.15870 - acc: 0.9441 -- iter: 544/608
[A[ATraining Step: 531  | total loss: [1m[32m0.15455[0m[0m | time: 246.048s
[2K
| RMSProp | epoch: 028 | loss: 0.15455 - acc: 0.9434 -- iter: 576/608
[A[ATraining Step: 532  | total loss: [1m[32m0.14329[0m[0m | time: 274.793s
[2K
| RMSProp | epoch: 028 | loss: 0.14329 - acc: 0.9491 | val_loss: 1.19504 - val_acc: 0.6632 -- iter: 608/608
--
Training Step: 533  | total loss: [1m[32m0.13726[0m[0m | time: 8.824s
[2K
| RMSProp | epoch: 029 | loss: 0.13726 - acc: 0.9511 -- iter: 032/608
[A[ATraining Step: 534  | total loss: [1m[32m0.13124[0m[0m | time: 17.372s
[2K
| RMSProp | epoch: 029 | loss: 0.13124 - acc: 0.9528 -- iter: 064/608
[A[ATraining Step: 535  | total loss: [1m[32m0.12328[0m[0m | time: 25.905s
[2K
| RMSProp | epoch: 029 | loss: 0.12328 - acc: 0.9544 -- iter: 096/608
[A[ATraining Step: 536  | total loss: [1m[32m0.11210[0m[0m | time: 36.801s
[2K
| RMSProp | epoch: 029 | loss: 0.11210 - acc: 0.9590 -- iter: 128/608
[A[ATraining Step: 537  | total loss: [1m[32m0.10849[0m[0m | time: 50.966s
[2K
| RMSProp | epoch: 029 | loss: 0.10849 - acc: 0.9600 -- iter: 160/608
[A[ATraining Step: 538  | total loss: [1m[32m0.09919[0m[0m | time: 64.758s
[2K
| RMSProp | epoch: 029 | loss: 0.09919 - acc: 0.9640 -- iter: 192/608
[A[ATraining Step: 539  | total loss: [1m[32m0.11109[0m[0m | time: 78.751s
[2K
| RMSProp | epoch: 029 | loss: 0.11109 - acc: 0.9644 -- iter: 224/608
[A[ATraining Step: 540  | total loss: [1m[32m0.11925[0m[0m | time: 92.334s
[2K
| RMSProp | epoch: 029 | loss: 0.11925 - acc: 0.9617 -- iter: 256/608
[A[ATraining Step: 541  | total loss: [1m[32m0.12731[0m[0m | time: 106.143s
[2K
| RMSProp | epoch: 029 | loss: 0.12731 - acc: 0.9624 -- iter: 288/608
[A[ATraining Step: 542  | total loss: [1m[32m0.12145[0m[0m | time: 119.920s
[2K
| RMSProp | epoch: 029 | loss: 0.12145 - acc: 0.9631 -- iter: 320/608
[A[ATraining Step: 543  | total loss: [1m[32m0.11511[0m[0m | time: 133.395s
[2K
| RMSProp | epoch: 029 | loss: 0.11511 - acc: 0.9636 -- iter: 352/608
[A[ATraining Step: 544  | total loss: [1m[32m0.14442[0m[0m | time: 145.683s
[2K
| RMSProp | epoch: 029 | loss: 0.14442 - acc: 0.9485 -- iter: 384/608
[A[ATraining Step: 545  | total loss: [1m[32m0.16268[0m[0m | time: 159.565s
[2K
| RMSProp | epoch: 029 | loss: 0.16268 - acc: 0.9443 -- iter: 416/608
[A[ATraining Step: 546  | total loss: [1m[32m0.15676[0m[0m | time: 174.037s
[2K
| RMSProp | epoch: 029 | loss: 0.15676 - acc: 0.9467 -- iter: 448/608
[A[ATraining Step: 547  | total loss: [1m[32m0.14493[0m[0m | time: 187.471s
[2K
| RMSProp | epoch: 029 | loss: 0.14493 - acc: 0.9521 -- iter: 480/608
[A[ATraining Step: 548  | total loss: [1m[32m0.24296[0m[0m | time: 200.827s
[2K
| RMSProp | epoch: 029 | loss: 0.24296 - acc: 0.9319 -- iter: 512/608
[A[ATraining Step: 549  | total loss: [1m[32m0.23859[0m[0m | time: 214.722s
[2K
| RMSProp | epoch: 029 | loss: 0.23859 - acc: 0.9356 -- iter: 544/608
[A[ATraining Step: 550  | total loss: [1m[32m0.23076[0m[0m | time: 228.627s
[2K
| RMSProp | epoch: 029 | loss: 0.23076 - acc: 0.9357 -- iter: 576/608
[A[ATraining Step: 551  | total loss: [1m[32m0.24907[0m[0m | time: 256.428s
[2K
| RMSProp | epoch: 029 | loss: 0.24907 - acc: 0.9265 | val_loss: 1.95413 - val_acc: 0.5000 -- iter: 608/608
--
Training Step: 552  | total loss: [1m[32m0.23619[0m[0m | time: 13.207s
[2K
| RMSProp | epoch: 030 | loss: 0.23619 - acc: 0.9276 -- iter: 032/608
[A[ATraining Step: 553  | total loss: [1m[32m0.22879[0m[0m | time: 27.276s
[2K
| RMSProp | epoch: 030 | loss: 0.22879 - acc: 0.9286 -- iter: 064/608
[A[ATraining Step: 554  | total loss: [1m[32m0.21074[0m[0m | time: 41.343s
[2K
| RMSProp | epoch: 030 | loss: 0.21074 - acc: 0.9358 -- iter: 096/608
[A[ATraining Step: 555  | total loss: [1m[32m0.19571[0m[0m | time: 55.150s
[2K
| RMSProp | epoch: 030 | loss: 0.19571 - acc: 0.9422 -- iter: 128/608
[A[ATraining Step: 556  | total loss: [1m[32m0.19622[0m[0m | time: 68.897s
[2K
| RMSProp | epoch: 030 | loss: 0.19622 - acc: 0.9386 -- iter: 160/608
[A[ATraining Step: 557  | total loss: [1m[32m0.19480[0m[0m | time: 82.696s
[2K
| RMSProp | epoch: 030 | loss: 0.19480 - acc: 0.9385 -- iter: 192/608
[A[ATraining Step: 558  | total loss: [1m[32m0.17847[0m[0m | time: 97.310s
[2K
| RMSProp | epoch: 030 | loss: 0.17847 - acc: 0.9446 -- iter: 224/608
[A[ATraining Step: 559  | total loss: [1m[32m0.18485[0m[0m | time: 109.148s
[2K
| RMSProp | epoch: 030 | loss: 0.18485 - acc: 0.9408 -- iter: 256/608
[A[ATraining Step: 560  | total loss: [1m[32m0.16907[0m[0m | time: 117.741s
[2K
| RMSProp | epoch: 030 | loss: 0.16907 - acc: 0.9467 -- iter: 288/608
[A[ATraining Step: 561  | total loss: [1m[32m0.15258[0m[0m | time: 127.291s
[2K
| RMSProp | epoch: 030 | loss: 0.15258 - acc: 0.9520 -- iter: 320/608
[A[ATraining Step: 562  | total loss: [1m[32m0.13912[0m[0m | time: 140.200s
[2K
| RMSProp | epoch: 030 | loss: 0.13912 - acc: 0.9568 -- iter: 352/608
[A[ATraining Step: 563  | total loss: [1m[32m0.12659[0m[0m | time: 153.600s
[2K
| RMSProp | epoch: 030 | loss: 0.12659 - acc: 0.9612 -- iter: 384/608
[A[ATraining Step: 564  | total loss: [1m[32m0.11504[0m[0m | time: 167.163s
[2K
| RMSProp | epoch: 030 | loss: 0.11504 - acc: 0.9650 -- iter: 416/608
[A[ATraining Step: 565  | total loss: [1m[32m0.12405[0m[0m | time: 180.660s
[2K
| RMSProp | epoch: 030 | loss: 0.12405 - acc: 0.9623 -- iter: 448/608
[A[ATraining Step: 566  | total loss: [1m[32m0.11819[0m[0m | time: 196.435s
[2K
| RMSProp | epoch: 030 | loss: 0.11819 - acc: 0.9629 -- iter: 480/608
[A[ATraining Step: 567  | total loss: [1m[32m0.10970[0m[0m | time: 209.787s
[2K
| RMSProp | epoch: 030 | loss: 0.10970 - acc: 0.9666 -- iter: 512/608
[A[ATraining Step: 568  | total loss: [1m[32m0.12063[0m[0m | time: 223.693s
[2K
| RMSProp | epoch: 030 | loss: 0.12063 - acc: 0.9637 -- iter: 544/608
[A[ATraining Step: 569  | total loss: [1m[32m0.10947[0m[0m | time: 237.677s
[2K
| RMSProp | epoch: 030 | loss: 0.10947 - acc: 0.9674 -- iter: 576/608
[A[ATraining Step: 570  | total loss: [1m[32m0.10551[0m[0m | time: 264.880s
[2K
| RMSProp | epoch: 030 | loss: 0.10551 - acc: 0.9675 | val_loss: 2.53345 - val_acc: 0.5316 -- iter: 608/608
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7580895390070922
Validation AUPRC:0.7555811059485298
Test AUC:0.6537552077468752
Test AUPRC:0.7351158063178106
BestTestF1Score	0.53	0.3	0.61	0.8	0.4	43	11	72	64	0.01
BestTestMCCScore	0.53	0.3	0.61	0.8	0.4	43	11	72	64	0.01
BestTestAccuracyScore	0.53	0.3	0.61	0.8	0.4	43	11	72	64	0.01
BestValidationF1Score	0.59	0.39	0.67	0.8	0.47	45	11	83	51	0.01
BestValidationMCC	0.59	0.39	0.67	0.8	0.47	45	11	83	51	0.01
BestValidationAccuracy	0.59	0.39	0.67	0.8	0.47	45	11	83	51	0.01
TestPredictions (Threshold:0.01)
CHEMBL1682205,TN,INACT,0.0	CHEMBL1946966,FP,INACT,0.029999999329447746	CHEMBL3422332,FN,ACT,0.0	CHEMBL2070001,TN,INACT,0.0	CHEMBL346845,TN,INACT,0.0	CHEMBL2010975,FP,INACT,0.11999999731779099	CHEMBL469,FN,ACT,0.0	CHEMBL2261305,TN,INACT,0.0	CHEMBL2323508,FP,INACT,0.019999999552965164	CHEMBL2261309,FN,ACT,0.0	CHEMBL2010963,FN,ACT,0.0	CHEMBL1774251,TP,ACT,0.36000001430511475	CHEMBL1081326,TN,INACT,0.0	CHEMBL2261551,TN,INACT,0.0	CHEMBL2172259,FP,INACT,0.4300000071525574	CHEMBL2334933,TN,INACT,0.0	CHEMBL2261304,FN,ACT,0.0	CHEMBL81709,TN,INACT,0.0	CHEMBL2180652,FN,ACT,0.0	CHEMBL433898,TP,ACT,0.07000000029802322	CHEMBL267744,FN,ACT,0.0	CHEMBL287999,FN,ACT,0.009999999776482582	CHEMBL85496,TN,INACT,0.0	CHEMBL2323495,TN,INACT,0.0	CHEMBL3409353,TP,ACT,0.14000000059604645	CHEMBL2180644,TP,ACT,0.029999999329447746	CHEMBL428495,TN,INACT,0.0	CHEMBL3798264,TP,ACT,0.20999999344348907	CHEMBL476731,TP,ACT,0.3499999940395355	CHEMBL2041554,TN,INACT,0.0	CHEMBL164603,TP,ACT,0.11999999731779099	CHEMBL33210,TN,INACT,0.0	CHEMBL485677,TP,ACT,0.019999999552965164	CHEMBL69688,TN,INACT,0.0	CHEMBL2323500,TN,INACT,0.0	CHEMBL38344,TN,INACT,0.009999999776482582	CHEMBL2041773,TN,INACT,0.0	CHEMBL137540,TN,INACT,0.0	CHEMBL464825,FN,ACT,0.0	CHEMBL1203655,TN,INACT,0.0	CHEMBL33261,FN,ACT,0.0	CHEMBL2172252,TN,INACT,0.0	CHEMBL1907953,FN,ACT,0.0	CHEMBL2041567,TN,INACT,0.0	CHEMBL156333,TN,INACT,0.0	CHEMBL2172116,TN,INACT,0.0	CHEMBL457815,TN,INACT,0.0	CHEMBL275007,FN,ACT,0.0	CHEMBL602309,FN,ACT,0.0	CHEMBL3409344,TP,ACT,0.10000000149011612	CHEMBL82548,TN,INACT,0.0	CHEMBL3409361,TP,ACT,0.9100000262260437	CHEMBL1632038,FN,ACT,0.0	CHEMBL3262463,TN,INACT,0.0	CHEMBL73016,TP,ACT,0.05999999865889549	CHEMBL30655,TP,ACT,0.09000000357627869	CHEMBL476730,TP,ACT,0.10999999940395355	CHEMBL3409357,TP,ACT,0.4099999964237213	CHEMBL479077,FN,ACT,0.0	CHEMBL487810,TP,ACT,0.33000001311302185	CHEMBL2297682,FN,ACT,0.0	CHEMBL2323487,FP,INACT,0.019999999552965164	CHEMBL55614,TN,INACT,0.0	CHEMBL2041157,TN,INACT,0.0	CHEMBL284990,FN,ACT,0.0	CHEMBL233930,FN,ACT,0.0	CHEMBL82425,TN,INACT,0.0	CHEMBL40681,FN,ACT,0.0	CHEMBL3422330,FN,ACT,0.0	CHEMBL10413,FN,ACT,0.0	CHEMBL3409350,FN,ACT,0.0	CHEMBL3261534,TP,ACT,0.07999999821186066	CHEMBL3409367,FN,ACT,0.009999999776482582	CHEMBL66711,FN,ACT,0.009999999776482582	CHEMBL463753,TN,INACT,0.009999999776482582	CHEMBL2261575,FN,ACT,0.0	CHEMBL2261574,FN,ACT,0.0	CHEMBL417680,FN,ACT,0.0	CHEMBL297608,TN,INACT,0.009999999776482582	CHEMBL3409359,TP,ACT,0.38999998569488525	CHEMBL565091,FN,ACT,0.0	CHEMBL2010986,FN,ACT,0.0	CHEMBL602310,TN,INACT,0.0	CHEMBL56988,TN,INACT,0.0	CHEMBL152671,TN,INACT,0.0	CHEMBL2172251,TN,INACT,0.0	CHEMBL590016,FN,ACT,0.0	CHEMBL298650,TN,INACT,0.0	CHEMBL420773,TN,INACT,0.0	CHEMBL1277476,FN,ACT,0.0	CHEMBL242419,TN,INACT,0.0	CHEMBL72637,FN,ACT,0.0	CHEMBL286613,FN,ACT,0.0	CHEMBL81106,TN,INACT,0.0	CHEMBL309684,FP,INACT,0.09000000357627869	CHEMBL1632039,TP,ACT,0.41999998688697815	CHEMBL1939278,TN,INACT,0.0	CHEMBL2010978,FN,ACT,0.0	CHEMBL1774241,TP,ACT,0.5799999833106995	CHEMBL1774249,FN,ACT,0.0	CHEMBL2010965,FN,ACT,0.0	CHEMBL2323505,TN,INACT,0.0	CHEMBL3409347,TP,ACT,0.18000000715255737	CHEMBL152672,TN,INACT,0.0	CHEMBL82242,TP,ACT,0.8600000143051147	CHEMBL2334932,TN,INACT,0.0	CHEMBL3260152,FN,ACT,0.0	CHEMBL276168,FP,INACT,0.029999999329447746	CHEMBL366350,TN,INACT,0.0	CHEMBL2041556,FP,INACT,0.019999999552965164	CHEMBL163888,FN,ACT,0.0	CHEMBL2334931,TN,INACT,0.0	CHEMBL3409351,FN,ACT,0.0	CHEMBL569146,TN,INACT,0.009999999776482582	CHEMBL3409348,TP,ACT,0.18000000715255737	CHEMBL3409369,TP,ACT,0.12999999523162842	CHEMBL1774238,FN,ACT,0.0	CHEMBL3422329,FN,ACT,0.0	CHEMBL136083,TN,INACT,0.0	CHEMBL2261559,TN,INACT,0.0	CHEMBL487417,FN,ACT,0.0	CHEMBL324907,FN,ACT,0.009999999776482582	CHEMBL1940389,TN,INACT,0.0	CHEMBL3236006,TN,INACT,0.0	CHEMBL513901,FN,ACT,0.0	CHEMBL34976,FN,ACT,0.0	CHEMBL2180648,TP,ACT,0.05999999865889549	CHEMBL78544,TN,INACT,0.0	CHEMBL3098361,TP,ACT,0.6000000238418579	CHEMBL3236009,TN,INACT,0.0	CHEMBL2010981,TN,INACT,0.0	CHEMBL182653,FN,ACT,0.009999999776482582	CHEMBL3260157,FN,ACT,0.009999999776482582	CHEMBL390320,TN,INACT,0.0	CHEMBL2261578,FN,ACT,0.0	CHEMBL2297688,TP,ACT,0.10000000149011612	CHEMBL390741,FN,ACT,0.0	CHEMBL1927014,TP,ACT,0.019999999552965164	CHEMBL1632036,TN,INACT,0.0	CHEMBL313244,FP,INACT,0.03999999910593033	CHEMBL447936,TP,ACT,0.6200000047683716	CHEMBL305251,FN,ACT,0.0	CHEMBL40666,TP,ACT,0.8799999952316284	CHEMBL63055,FN,ACT,0.0	CHEMBL516438,TP,ACT,0.03999999910593033	CHEMBL2297676,TP,ACT,0.07999999821186066	CHEMBL444802,TN,INACT,0.009999999776482582	CHEMBL276870,TP,ACT,0.4300000071525574	CHEMBL309965,TN,INACT,0.0	CHEMBL268492,TP,ACT,0.7400000095367432	CHEMBL80881,TN,INACT,0.0	CHEMBL33509,FN,ACT,0.009999999776482582	CHEMBL284616,TP,ACT,0.12999999523162842	CHEMBL1277202,TN,INACT,0.0	CHEMBL1632027,TP,ACT,0.07000000029802322	CHEMBL493921,TN,INACT,0.0	CHEMBL81625,TN,INACT,0.0	CHEMBL8798,TN,INACT,0.0	CHEMBL404313,TN,INACT,0.0	CHEMBL1085682,TN,INACT,0.0	CHEMBL342382,FN,ACT,0.0	CHEMBL1171546,TN,INACT,0.0	CHEMBL34534,FP,INACT,0.6600000262260437	CHEMBL2261306,FN,ACT,0.0	CHEMBL3609183,TP,ACT,0.07999999821186066	CHEMBL1907772,TP,ACT,0.15000000596046448	CHEMBL479233,FN,ACT,0.0	CHEMBL80087,TN,INACT,0.0	CHEMBL408,FN,ACT,0.0	CHEMBL302057,FN,ACT,0.0	CHEMBL516320,TN,INACT,0.0	CHEMBL12655,FN,ACT,0.0	CHEMBL3409365,TP,ACT,0.33000001311302185	CHEMBL34737,TP,ACT,0.029999999329447746	CHEMBL3609181,TP,ACT,0.17000000178813934	CHEMBL443463,FN,ACT,0.0	CHEMBL6246,TP,ACT,0.12999999523162842	CHEMBL1203649,TN,INACT,0.0	CHEMBL2180647,TP,ACT,0.05999999865889549	CHEMBL573524,FN,ACT,0.0	CHEMBL286858,FN,ACT,0.0	CHEMBL2172241,TN,INACT,0.0	CHEMBL2334921,TN,INACT,0.0	CHEMBL363387,TP,ACT,0.23000000417232513	CHEMBL1094044,FP,INACT,0.3700000047683716	CHEMBL135144,FN,ACT,0.009999999776482582	CHEMBL79885,TN,INACT,0.0	CHEMBL157003,TN,INACT,0.0	CHEMBL7480,FN,ACT,0.0	CHEMBL302999,FN,ACT,0.0	

