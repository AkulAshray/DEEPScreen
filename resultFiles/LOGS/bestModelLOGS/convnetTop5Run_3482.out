CNNModel CHEMBL263 adam 0.0005 15 128 0 0.6 False True
Number of active compounds :	422
Number of inactive compounds :	422
---------------------------------
Run id: CNNModel_CHEMBL263_adam_0.0005_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL263_adam_0.0005_15_128_0.6_True/
---------------------------------
Training samples: 537
Validation samples: 168
--
Training Step: 1  | time: 1.699s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/537
[A[ATraining Step: 2  | total loss: [1m[32m0.62370[0m[0m | time: 3.000s
[2K
| Adam | epoch: 001 | loss: 0.62370 - acc: 0.4781 -- iter: 064/537
[A[ATraining Step: 3  | total loss: [1m[32m0.68165[0m[0m | time: 4.203s
[2K
| Adam | epoch: 001 | loss: 0.68165 - acc: 0.4449 -- iter: 096/537
[A[ATraining Step: 4  | total loss: [1m[32m0.69056[0m[0m | time: 5.209s
[2K
| Adam | epoch: 001 | loss: 0.69056 - acc: 0.4862 -- iter: 128/537
[A[ATraining Step: 5  | total loss: [1m[32m0.69207[0m[0m | time: 6.451s
[2K
| Adam | epoch: 001 | loss: 0.69207 - acc: 0.5390 -- iter: 160/537
[A[ATraining Step: 6  | total loss: [1m[32m0.69336[0m[0m | time: 7.793s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4336 -- iter: 192/537
[A[ATraining Step: 7  | total loss: [1m[32m0.69334[0m[0m | time: 9.099s
[2K
| Adam | epoch: 001 | loss: 0.69334 - acc: 0.3984 -- iter: 224/537
[A[ATraining Step: 8  | total loss: [1m[32m0.69420[0m[0m | time: 10.179s
[2K
| Adam | epoch: 001 | loss: 0.69420 - acc: 0.3853 -- iter: 256/537
[A[ATraining Step: 9  | total loss: [1m[32m0.69315[0m[0m | time: 11.309s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.4956 -- iter: 288/537
[A[ATraining Step: 10  | total loss: [1m[32m0.69363[0m[0m | time: 12.611s
[2K
| Adam | epoch: 001 | loss: 0.69363 - acc: 0.4509 -- iter: 320/537
[A[ATraining Step: 11  | total loss: [1m[32m0.69267[0m[0m | time: 14.019s
[2K
| Adam | epoch: 001 | loss: 0.69267 - acc: 0.5630 -- iter: 352/537
[A[ATraining Step: 12  | total loss: [1m[32m0.69252[0m[0m | time: 25.214s
[2K
| Adam | epoch: 001 | loss: 0.69252 - acc: 0.5768 -- iter: 384/537
[A[ATraining Step: 13  | total loss: [1m[32m0.68975[0m[0m | time: 37.369s
[2K
| Adam | epoch: 001 | loss: 0.68975 - acc: 0.6243 -- iter: 416/537
[A[ATraining Step: 14  | total loss: [1m[32m0.69125[0m[0m | time: 44.790s
[2K
| Adam | epoch: 001 | loss: 0.69125 - acc: 0.5734 -- iter: 448/537
[A[ATraining Step: 15  | total loss: [1m[32m0.69072[0m[0m | time: 56.961s
[2K
| Adam | epoch: 001 | loss: 0.69072 - acc: 0.5569 -- iter: 480/537
[A[ATraining Step: 16  | total loss: [1m[32m0.69520[0m[0m | time: 57.997s
[2K
| Adam | epoch: 001 | loss: 0.69520 - acc: 0.5121 -- iter: 512/537
[A[ATraining Step: 17  | total loss: [1m[32m0.69812[0m[0m | time: 60.105s
[2K
| Adam | epoch: 001 | loss: 0.69812 - acc: 0.4853 | val_loss: 0.69608 - val_acc: 0.4643 -- iter: 537/537
--
Training Step: 18  | total loss: [1m[32m0.69689[0m[0m | time: 0.985s
[2K
| Adam | epoch: 002 | loss: 0.69689 - acc: 0.4834 -- iter: 032/537
[A[ATraining Step: 19  | total loss: [1m[32m0.69638[0m[0m | time: 2.165s
[2K
| Adam | epoch: 002 | loss: 0.69638 - acc: 0.4823 -- iter: 064/537
[A[ATraining Step: 20  | total loss: [1m[32m0.69437[0m[0m | time: 3.388s
[2K
| Adam | epoch: 002 | loss: 0.69437 - acc: 0.5081 -- iter: 096/537
[A[ATraining Step: 21  | total loss: [1m[32m0.69539[0m[0m | time: 4.555s
[2K
| Adam | epoch: 002 | loss: 0.69539 - acc: 0.4668 -- iter: 128/537
[A[ATraining Step: 22  | total loss: [1m[32m0.69528[0m[0m | time: 5.671s
[2K
| Adam | epoch: 002 | loss: 0.69528 - acc: 0.4580 -- iter: 160/537
[A[ATraining Step: 23  | total loss: [1m[32m0.69511[0m[0m | time: 6.742s
[2K
| Adam | epoch: 002 | loss: 0.69511 - acc: 0.4430 -- iter: 192/537
[A[ATraining Step: 24  | total loss: [1m[32m0.69441[0m[0m | time: 7.948s
[2K
| Adam | epoch: 002 | loss: 0.69441 - acc: 0.4678 -- iter: 224/537
[A[ATraining Step: 25  | total loss: [1m[32m0.69388[0m[0m | time: 9.281s
[2K
| Adam | epoch: 002 | loss: 0.69388 - acc: 0.5277 -- iter: 256/537
[A[ATraining Step: 26  | total loss: [1m[32m0.69371[0m[0m | time: 10.476s
[2K
| Adam | epoch: 002 | loss: 0.69371 - acc: 0.5038 -- iter: 288/537
[A[ATraining Step: 27  | total loss: [1m[32m0.69356[0m[0m | time: 18.785s
[2K
| Adam | epoch: 002 | loss: 0.69356 - acc: 0.4948 -- iter: 320/537
[A[ATraining Step: 28  | total loss: [1m[32m0.69350[0m[0m | time: 28.150s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.4961 -- iter: 352/537
[A[ATraining Step: 29  | total loss: [1m[32m0.69348[0m[0m | time: 29.428s
[2K
| Adam | epoch: 002 | loss: 0.69348 - acc: 0.4667 -- iter: 384/537
[A[ATraining Step: 30  | total loss: [1m[32m0.69340[0m[0m | time: 30.526s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.4671 -- iter: 416/537
[A[ATraining Step: 31  | total loss: [1m[32m0.69340[0m[0m | time: 31.617s
[2K
| Adam | epoch: 002 | loss: 0.69340 - acc: 0.4675 -- iter: 448/537
[A[ATraining Step: 32  | total loss: [1m[32m0.69333[0m[0m | time: 32.751s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4819 -- iter: 480/537
[A[ATraining Step: 33  | total loss: [1m[32m0.69330[0m[0m | time: 33.991s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.4858 -- iter: 512/537
[A[ATraining Step: 34  | total loss: [1m[32m0.69321[0m[0m | time: 36.481s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5157 | val_loss: 0.69340 - val_acc: 0.4643 -- iter: 537/537
--
Training Step: 35  | total loss: [1m[32m0.69317[0m[0m | time: 1.006s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.5124 -- iter: 032/537
[A[ATraining Step: 36  | total loss: [1m[32m0.69327[0m[0m | time: 1.832s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.4976 -- iter: 064/537
[A[ATraining Step: 37  | total loss: [1m[32m0.69335[0m[0m | time: 3.231s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4861 -- iter: 096/537
[A[ATraining Step: 38  | total loss: [1m[32m0.69325[0m[0m | time: 4.657s
[2K
| Adam | epoch: 003 | loss: 0.69325 - acc: 0.5010 -- iter: 128/537
[A[ATraining Step: 39  | total loss: [1m[32m0.69339[0m[0m | time: 19.458s
[2K
| Adam | epoch: 003 | loss: 0.69339 - acc: 0.4829 -- iter: 160/537
[A[ATraining Step: 40  | total loss: [1m[32m0.69350[0m[0m | time: 35.387s
[2K
| Adam | epoch: 003 | loss: 0.69350 - acc: 0.4685 -- iter: 192/537
[A[ATraining Step: 41  | total loss: [1m[32m0.69338[0m[0m | time: 36.950s
[2K
| Adam | epoch: 003 | loss: 0.69338 - acc: 0.4800 -- iter: 224/537
[A[ATraining Step: 42  | total loss: [1m[32m0.69341[0m[0m | time: 38.077s
[2K
| Adam | epoch: 003 | loss: 0.69341 - acc: 0.4724 -- iter: 256/537
[A[ATraining Step: 43  | total loss: [1m[32m0.69348[0m[0m | time: 39.107s
[2K
| Adam | epoch: 003 | loss: 0.69348 - acc: 0.4552 -- iter: 288/537
[A[ATraining Step: 44  | total loss: [1m[32m0.69328[0m[0m | time: 40.227s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.4954 -- iter: 320/537
[A[ATraining Step: 45  | total loss: [1m[32m0.69335[0m[0m | time: 41.352s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.4750 -- iter: 352/537
[A[ATraining Step: 46  | total loss: [1m[32m0.69330[0m[0m | time: 42.575s
[2K
| Adam | epoch: 003 | loss: 0.69330 - acc: 0.4843 -- iter: 384/537
[A[ATraining Step: 47  | total loss: [1m[32m0.69330[0m[0m | time: 43.690s
[2K
| Adam | epoch: 003 | loss: 0.69330 - acc: 0.4818 -- iter: 416/537
[A[ATraining Step: 48  | total loss: [1m[32m0.69323[0m[0m | time: 44.942s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.5048 -- iter: 448/537
[A[ATraining Step: 49  | total loss: [1m[32m0.69326[0m[0m | time: 46.262s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.4892 -- iter: 480/537
[A[ATraining Step: 50  | total loss: [1m[32m0.69320[0m[0m | time: 47.492s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.5006 -- iter: 512/537
[A[ATraining Step: 51  | total loss: [1m[32m0.69320[0m[0m | time: 50.158s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.4910 | val_loss: 0.69310 - val_acc: 0.4643 -- iter: 537/537
--
Training Step: 52  | total loss: [1m[32m0.69318[0m[0m | time: 12.526s
[2K
| Adam | epoch: 004 | loss: 0.69318 - acc: 0.4923 -- iter: 032/537
[A[ATraining Step: 53  | total loss: [1m[32m0.69313[0m[0m | time: 14.959s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.5119 -- iter: 064/537
[A[ATraining Step: 54  | total loss: [1m[32m0.69309[0m[0m | time: 24.567s
[2K
| Adam | epoch: 004 | loss: 0.69309 - acc: 0.5305 -- iter: 096/537
[A[ATraining Step: 55  | total loss: [1m[32m0.69301[0m[0m | time: 35.033s
[2K
| Adam | epoch: 004 | loss: 0.69301 - acc: 0.5461 -- iter: 128/537
[A[ATraining Step: 56  | total loss: [1m[32m0.69283[0m[0m | time: 36.211s
[2K
| Adam | epoch: 004 | loss: 0.69283 - acc: 0.5616 -- iter: 160/537
[A[ATraining Step: 57  | total loss: [1m[32m0.69276[0m[0m | time: 37.186s
[2K
| Adam | epoch: 004 | loss: 0.69276 - acc: 0.5617 -- iter: 192/537
[A[ATraining Step: 58  | total loss: [1m[32m0.69279[0m[0m | time: 38.359s
[2K
| Adam | epoch: 004 | loss: 0.69279 - acc: 0.5533 -- iter: 224/537
[A[ATraining Step: 59  | total loss: [1m[32m0.69257[0m[0m | time: 39.551s
[2K
| Adam | epoch: 004 | loss: 0.69257 - acc: 0.5546 -- iter: 256/537
[A[ATraining Step: 60  | total loss: [1m[32m0.69210[0m[0m | time: 40.731s
[2K
| Adam | epoch: 004 | loss: 0.69210 - acc: 0.5597 -- iter: 288/537
[A[ATraining Step: 61  | total loss: [1m[32m0.69171[0m[0m | time: 42.058s
[2K
| Adam | epoch: 004 | loss: 0.69171 - acc: 0.5601 -- iter: 320/537
[A[ATraining Step: 62  | total loss: [1m[32m0.69127[0m[0m | time: 43.335s
[2K
| Adam | epoch: 004 | loss: 0.69127 - acc: 0.5604 -- iter: 352/537
[A[ATraining Step: 63  | total loss: [1m[32m0.69429[0m[0m | time: 44.506s
[2K
| Adam | epoch: 004 | loss: 0.69429 - acc: 0.5369 -- iter: 384/537
[A[ATraining Step: 64  | total loss: [1m[32m0.69288[0m[0m | time: 45.595s
[2K
| Adam | epoch: 004 | loss: 0.69288 - acc: 0.5440 -- iter: 416/537
[A[ATraining Step: 65  | total loss: [1m[32m0.69311[0m[0m | time: 46.898s
[2K
| Adam | epoch: 004 | loss: 0.69311 - acc: 0.5386 -- iter: 448/537
[A[ATraining Step: 66  | total loss: [1m[32m0.69329[0m[0m | time: 48.217s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.5339 -- iter: 480/537
[A[ATraining Step: 67  | total loss: [1m[32m0.69260[0m[0m | time: 52.724s
[2K
| Adam | epoch: 004 | loss: 0.69260 - acc: 0.5373 -- iter: 512/537
[A[ATraining Step: 68  | total loss: [1m[32m0.69349[0m[0m | time: 82.078s
[2K
| Adam | epoch: 004 | loss: 0.69349 - acc: 0.5255 | val_loss: 0.69697 - val_acc: 0.4643 -- iter: 537/537
--
Training Step: 69  | total loss: [1m[32m0.69213[0m[0m | time: 1.196s
[2K
| Adam | epoch: 005 | loss: 0.69213 - acc: 0.5371 -- iter: 032/537
[A[ATraining Step: 70  | total loss: [1m[32m0.69231[0m[0m | time: 2.200s
[2K
| Adam | epoch: 005 | loss: 0.69231 - acc: 0.5329 -- iter: 064/537
[A[ATraining Step: 71  | total loss: [1m[32m0.69015[0m[0m | time: 3.042s
[2K
| Adam | epoch: 005 | loss: 0.69015 - acc: 0.5540 -- iter: 096/537
[A[ATraining Step: 72  | total loss: [1m[32m0.68980[0m[0m | time: 4.031s
[2K
| Adam | epoch: 005 | loss: 0.68980 - acc: 0.5547 -- iter: 128/537
[A[ATraining Step: 73  | total loss: [1m[32m0.68951[0m[0m | time: 5.194s
[2K
| Adam | epoch: 005 | loss: 0.68951 - acc: 0.5553 -- iter: 160/537
[A[ATraining Step: 74  | total loss: [1m[32m0.69484[0m[0m | time: 6.453s
[2K
| Adam | epoch: 005 | loss: 0.69484 - acc: 0.5184 -- iter: 192/537
[A[ATraining Step: 75  | total loss: [1m[32m0.69620[0m[0m | time: 7.627s
[2K
| Adam | epoch: 005 | loss: 0.69620 - acc: 0.5062 -- iter: 224/537
[A[ATraining Step: 76  | total loss: [1m[32m0.69629[0m[0m | time: 8.810s
[2K
| Adam | epoch: 005 | loss: 0.69629 - acc: 0.5022 -- iter: 256/537
[A[ATraining Step: 77  | total loss: [1m[32m0.69623[0m[0m | time: 9.982s
[2K
| Adam | epoch: 005 | loss: 0.69623 - acc: 0.4986 -- iter: 288/537
[A[ATraining Step: 78  | total loss: [1m[32m0.69522[0m[0m | time: 11.320s
[2K
| Adam | epoch: 005 | loss: 0.69522 - acc: 0.5086 -- iter: 320/537
[A[ATraining Step: 79  | total loss: [1m[32m0.69514[0m[0m | time: 12.769s
[2K
| Adam | epoch: 005 | loss: 0.69514 - acc: 0.5045 -- iter: 352/537
[A[ATraining Step: 80  | total loss: [1m[32m0.69514[0m[0m | time: 14.130s
[2K
| Adam | epoch: 005 | loss: 0.69514 - acc: 0.5008 -- iter: 384/537
[A[ATraining Step: 81  | total loss: [1m[32m0.69466[0m[0m | time: 24.542s
[2K
| Adam | epoch: 005 | loss: 0.69466 - acc: 0.5071 -- iter: 416/537
[A[ATraining Step: 82  | total loss: [1m[32m0.69458[0m[0m | time: 30.261s
[2K
| Adam | epoch: 005 | loss: 0.69458 - acc: 0.5032 -- iter: 448/537
[A[ATraining Step: 83  | total loss: [1m[32m0.69396[0m[0m | time: 31.416s
[2K
| Adam | epoch: 005 | loss: 0.69396 - acc: 0.5154 -- iter: 480/537
[A[ATraining Step: 84  | total loss: [1m[32m0.69369[0m[0m | time: 32.494s
[2K
| Adam | epoch: 005 | loss: 0.69369 - acc: 0.5201 -- iter: 512/537
[A[ATraining Step: 85  | total loss: [1m[32m0.69382[0m[0m | time: 35.068s
[2K
| Adam | epoch: 005 | loss: 0.69382 - acc: 0.5119 | val_loss: 0.69415 - val_acc: 0.4643 -- iter: 537/537
--
Training Step: 86  | total loss: [1m[32m0.69383[0m[0m | time: 1.292s
[2K
| Adam | epoch: 006 | loss: 0.69383 - acc: 0.5075 -- iter: 032/537
[A[ATraining Step: 87  | total loss: [1m[32m0.69364[0m[0m | time: 2.567s
[2K
| Adam | epoch: 006 | loss: 0.69364 - acc: 0.5099 -- iter: 064/537
[A[ATraining Step: 88  | total loss: [1m[32m0.69377[0m[0m | time: 3.909s
[2K
| Adam | epoch: 006 | loss: 0.69377 - acc: 0.5027 -- iter: 096/537
[A[ATraining Step: 89  | total loss: [1m[32m0.69369[0m[0m | time: 4.807s
[2K
| Adam | epoch: 006 | loss: 0.69369 - acc: 0.5024 -- iter: 128/537
[A[ATraining Step: 90  | total loss: [1m[32m0.69332[0m[0m | time: 5.864s
[2K
| Adam | epoch: 006 | loss: 0.69332 - acc: 0.5122 -- iter: 160/537
[A[ATraining Step: 91  | total loss: [1m[32m0.69305[0m[0m | time: 7.158s
[2K
| Adam | epoch: 006 | loss: 0.69305 - acc: 0.5209 -- iter: 192/537
[A[ATraining Step: 92  | total loss: [1m[32m0.69303[0m[0m | time: 8.406s
[2K
| Adam | epoch: 006 | loss: 0.69303 - acc: 0.5189 -- iter: 224/537
[A[ATraining Step: 93  | total loss: [1m[32m0.69266[0m[0m | time: 14.996s
[2K
| Adam | epoch: 006 | loss: 0.69266 - acc: 0.5295 -- iter: 256/537
[A[ATraining Step: 94  | total loss: [1m[32m0.69287[0m[0m | time: 25.611s
[2K
| Adam | epoch: 006 | loss: 0.69287 - acc: 0.5203 -- iter: 288/537
[A[ATraining Step: 95  | total loss: [1m[32m0.69259[0m[0m | time: 36.447s
[2K
| Adam | epoch: 006 | loss: 0.69259 - acc: 0.5276 -- iter: 320/537
[A[ATraining Step: 96  | total loss: [1m[32m0.69253[0m[0m | time: 43.871s
[2K
| Adam | epoch: 006 | loss: 0.69253 - acc: 0.5280 -- iter: 352/537
[A[ATraining Step: 97  | total loss: [1m[32m0.69276[0m[0m | time: 44.799s
[2K
| Adam | epoch: 006 | loss: 0.69276 - acc: 0.5189 -- iter: 384/537
[A[ATraining Step: 98  | total loss: [1m[32m0.69236[0m[0m | time: 46.061s
[2K
| Adam | epoch: 006 | loss: 0.69236 - acc: 0.5295 -- iter: 416/537
[A[ATraining Step: 99  | total loss: [1m[32m0.69263[0m[0m | time: 47.347s
[2K
| Adam | epoch: 006 | loss: 0.69263 - acc: 0.5203 -- iter: 448/537
[A[ATraining Step: 100  | total loss: [1m[32m0.69277[0m[0m | time: 48.654s
[2K
| Adam | epoch: 006 | loss: 0.69277 - acc: 0.5152 -- iter: 480/537
[A[ATraining Step: 101  | total loss: [1m[32m0.69231[0m[0m | time: 49.956s
[2K
| Adam | epoch: 006 | loss: 0.69231 - acc: 0.5262 -- iter: 512/537
[A[ATraining Step: 102  | total loss: [1m[32m0.69290[0m[0m | time: 52.607s
[2K
| Adam | epoch: 006 | loss: 0.69290 - acc: 0.5079 | val_loss: 0.69386 - val_acc: 0.4643 -- iter: 537/537
--
Training Step: 103  | total loss: [1m[32m0.69240[0m[0m | time: 1.113s
[2K
| Adam | epoch: 007 | loss: 0.69240 - acc: 0.5196 -- iter: 032/537
[A[ATraining Step: 104  | total loss: [1m[32m0.69220[0m[0m | time: 2.389s
[2K
| Adam | epoch: 007 | loss: 0.69220 - acc: 0.5239 -- iter: 064/537
[A[ATraining Step: 105  | total loss: [1m[32m0.69258[0m[0m | time: 3.733s
[2K
| Adam | epoch: 007 | loss: 0.69258 - acc: 0.5121 -- iter: 096/537
[A[ATraining Step: 106  | total loss: [1m[32m0.69242[0m[0m | time: 7.482s
[2K
| Adam | epoch: 007 | loss: 0.69242 - acc: 0.5141 -- iter: 128/537
[A[ATraining Step: 107  | total loss: [1m[32m0.69251[0m[0m | time: 12.340s
[2K
| Adam | epoch: 007 | loss: 0.69251 - acc: 0.5095 -- iter: 160/537
[A[ATraining Step: 108  | total loss: [1m[32m0.69251[0m[0m | time: 21.906s
[2K
| Adam | epoch: 007 | loss: 0.69251 - acc: 0.5066 -- iter: 192/537
[A[ATraining Step: 109  | total loss: [1m[32m0.69248[0m[0m | time: 25.424s
[2K
| Adam | epoch: 007 | loss: 0.69248 - acc: 0.5039 -- iter: 224/537
[A[ATraining Step: 110  | total loss: [1m[32m0.69183[0m[0m | time: 30.046s
[2K
| Adam | epoch: 007 | loss: 0.69183 - acc: 0.5160 -- iter: 256/537
[A[ATraining Step: 111  | total loss: [1m[32m0.69150[0m[0m | time: 31.239s
[2K
| Adam | epoch: 007 | loss: 0.69150 - acc: 0.5207 -- iter: 288/537
[A[ATraining Step: 112  | total loss: [1m[32m0.69179[0m[0m | time: 32.416s
[2K
| Adam | epoch: 007 | loss: 0.69179 - acc: 0.5124 -- iter: 320/537
[A[ATraining Step: 113  | total loss: [1m[32m0.69120[0m[0m | time: 33.609s
[2K
| Adam | epoch: 007 | loss: 0.69120 - acc: 0.5205 -- iter: 352/537
[A[ATraining Step: 114  | total loss: [1m[32m0.69003[0m[0m | time: 34.963s
[2K
| Adam | epoch: 007 | loss: 0.69003 - acc: 0.5372 -- iter: 384/537
[A[ATraining Step: 115  | total loss: [1m[32m0.69030[0m[0m | time: 36.261s
[2K
| Adam | epoch: 007 | loss: 0.69030 - acc: 0.5272 -- iter: 416/537
[A[ATraining Step: 116  | total loss: [1m[32m0.68973[0m[0m | time: 37.482s
[2K
| Adam | epoch: 007 | loss: 0.68973 - acc: 0.5308 -- iter: 448/537
[A[ATraining Step: 117  | total loss: [1m[32m0.68973[0m[0m | time: 38.921s
[2K
| Adam | epoch: 007 | loss: 0.68973 - acc: 0.5246 -- iter: 480/537
[A[ATraining Step: 118  | total loss: [1m[32m0.68973[0m[0m | time: 40.199s
[2K
| Adam | epoch: 007 | loss: 0.68973 - acc: 0.5158 -- iter: 512/537
[A[ATraining Step: 119  | total loss: [1m[32m0.68960[0m[0m | time: 42.796s
[2K
| Adam | epoch: 007 | loss: 0.68960 - acc: 0.5049 | val_loss: 0.68887 - val_acc: 0.4643 -- iter: 537/537
--
Training Step: 120  | total loss: [1m[32m0.68789[0m[0m | time: 6.034s
[2K
| Adam | epoch: 008 | loss: 0.68789 - acc: 0.5138 -- iter: 032/537
[A[ATraining Step: 121  | total loss: [1m[32m0.68869[0m[0m | time: 7.322s
[2K
| Adam | epoch: 008 | loss: 0.68869 - acc: 0.5030 -- iter: 064/537
[A[ATraining Step: 122  | total loss: [1m[32m0.68789[0m[0m | time: 8.480s
[2K
| Adam | epoch: 008 | loss: 0.68789 - acc: 0.4996 -- iter: 096/537
[A[ATraining Step: 123  | total loss: [1m[32m0.68691[0m[0m | time: 9.575s
[2K
| Adam | epoch: 008 | loss: 0.68691 - acc: 0.5090 -- iter: 128/537
[A[ATraining Step: 124  | total loss: [1m[32m0.68583[0m[0m | time: 10.862s
[2K
| Adam | epoch: 008 | loss: 0.68583 - acc: 0.5394 -- iter: 160/537
[A[ATraining Step: 125  | total loss: [1m[32m0.68390[0m[0m | time: 11.915s
[2K
| Adam | epoch: 008 | loss: 0.68390 - acc: 0.5573 -- iter: 192/537
[A[ATraining Step: 126  | total loss: [1m[32m0.67971[0m[0m | time: 13.048s
[2K
| Adam | epoch: 008 | loss: 0.67971 - acc: 0.5616 -- iter: 224/537
[A[ATraining Step: 127  | total loss: [1m[32m0.67567[0m[0m | time: 14.421s
[2K
| Adam | epoch: 008 | loss: 0.67567 - acc: 0.5654 -- iter: 256/537
[A[ATraining Step: 128  | total loss: [1m[32m0.67393[0m[0m | time: 15.742s
[2K
| Adam | epoch: 008 | loss: 0.67393 - acc: 0.5651 -- iter: 288/537
[A[ATraining Step: 129  | total loss: [1m[32m0.66043[0m[0m | time: 16.932s
[2K
| Adam | epoch: 008 | loss: 0.66043 - acc: 0.5805 -- iter: 320/537
[A[ATraining Step: 130  | total loss: [1m[32m0.66831[0m[0m | time: 18.343s
[2K
| Adam | epoch: 008 | loss: 0.66831 - acc: 0.5568 -- iter: 352/537
[A[ATraining Step: 131  | total loss: [1m[32m0.66170[0m[0m | time: 19.679s
[2K
| Adam | epoch: 008 | loss: 0.66170 - acc: 0.5793 -- iter: 384/537
[A[ATraining Step: 132  | total loss: [1m[32m0.65913[0m[0m | time: 21.010s
[2K
| Adam | epoch: 008 | loss: 0.65913 - acc: 0.5932 -- iter: 416/537
[A[ATraining Step: 133  | total loss: [1m[32m0.65292[0m[0m | time: 22.295s
[2K
| Adam | epoch: 008 | loss: 0.65292 - acc: 0.6183 -- iter: 448/537
[A[ATraining Step: 134  | total loss: [1m[32m0.64537[0m[0m | time: 23.747s
[2K
| Adam | epoch: 008 | loss: 0.64537 - acc: 0.6346 -- iter: 480/537
[A[ATraining Step: 135  | total loss: [1m[32m0.63476[0m[0m | time: 24.962s
[2K
| Adam | epoch: 008 | loss: 0.63476 - acc: 0.6461 -- iter: 512/537
[A[ATraining Step: 136  | total loss: [1m[32m0.62161[0m[0m | time: 27.693s
[2K
| Adam | epoch: 008 | loss: 0.62161 - acc: 0.6596 | val_loss: 0.48472 - val_acc: 0.8274 -- iter: 537/537
--
Training Step: 137  | total loss: [1m[32m0.60623[0m[0m | time: 1.243s
[2K
| Adam | epoch: 009 | loss: 0.60623 - acc: 0.6874 -- iter: 032/537
[A[ATraining Step: 138  | total loss: [1m[32m0.58755[0m[0m | time: 2.155s
[2K
| Adam | epoch: 009 | loss: 0.58755 - acc: 0.7093 -- iter: 064/537
[A[ATraining Step: 139  | total loss: [1m[32m0.56966[0m[0m | time: 3.061s
[2K
| Adam | epoch: 009 | loss: 0.56966 - acc: 0.7290 -- iter: 096/537
[A[ATraining Step: 140  | total loss: [1m[32m0.55428[0m[0m | time: 4.076s
[2K
| Adam | epoch: 009 | loss: 0.55428 - acc: 0.7436 -- iter: 128/537
[A[ATraining Step: 141  | total loss: [1m[32m0.53228[0m[0m | time: 4.961s
[2K
| Adam | epoch: 009 | loss: 0.53228 - acc: 0.7536 -- iter: 160/537
[A[ATraining Step: 142  | total loss: [1m[32m0.50735[0m[0m | time: 6.034s
[2K
| Adam | epoch: 009 | loss: 0.50735 - acc: 0.7689 -- iter: 192/537
[A[ATraining Step: 143  | total loss: [1m[32m0.48415[0m[0m | time: 6.933s
[2K
| Adam | epoch: 009 | loss: 0.48415 - acc: 0.7795 -- iter: 224/537
[A[ATraining Step: 144  | total loss: [1m[32m0.45624[0m[0m | time: 7.657s
[2K
| Adam | epoch: 009 | loss: 0.45624 - acc: 0.7935 -- iter: 256/537
[A[ATraining Step: 145  | total loss: [1m[32m0.42919[0m[0m | time: 8.501s
[2K
| Adam | epoch: 009 | loss: 0.42919 - acc: 0.8062 -- iter: 288/537
[A[ATraining Step: 146  | total loss: [1m[32m0.41016[0m[0m | time: 9.403s
[2K
| Adam | epoch: 009 | loss: 0.41016 - acc: 0.8193 -- iter: 320/537
[A[ATraining Step: 147  | total loss: [1m[32m0.47154[0m[0m | time: 10.434s
[2K
| Adam | epoch: 009 | loss: 0.47154 - acc: 0.8030 -- iter: 352/537
[A[ATraining Step: 148  | total loss: [1m[32m0.51565[0m[0m | time: 11.427s
[2K
| Adam | epoch: 009 | loss: 0.51565 - acc: 0.7915 -- iter: 384/537
[A[ATraining Step: 149  | total loss: [1m[32m0.50254[0m[0m | time: 12.376s
[2K
| Adam | epoch: 009 | loss: 0.50254 - acc: 0.7967 -- iter: 416/537
[A[ATraining Step: 150  | total loss: [1m[32m0.49047[0m[0m | time: 13.350s
[2K
| Adam | epoch: 009 | loss: 0.49047 - acc: 0.7983 -- iter: 448/537
[A[ATraining Step: 151  | total loss: [1m[32m0.49579[0m[0m | time: 14.294s
[2K
| Adam | epoch: 009 | loss: 0.49579 - acc: 0.7997 -- iter: 480/537
[A[ATraining Step: 152  | total loss: [1m[32m0.49501[0m[0m | time: 15.227s
[2K
| Adam | epoch: 009 | loss: 0.49501 - acc: 0.8072 -- iter: 512/537
[A[ATraining Step: 153  | total loss: [1m[32m0.46598[0m[0m | time: 17.380s
[2K
| Adam | epoch: 009 | loss: 0.46598 - acc: 0.8171 | val_loss: 0.32211 - val_acc: 0.8452 -- iter: 537/537
--
Training Step: 154  | total loss: [1m[32m0.43969[0m[0m | time: 0.803s
[2K
| Adam | epoch: 010 | loss: 0.43969 - acc: 0.8292 -- iter: 032/537
[A[ATraining Step: 155  | total loss: [1m[32m0.41737[0m[0m | time: 1.706s
[2K
| Adam | epoch: 010 | loss: 0.41737 - acc: 0.8369 -- iter: 064/537
[A[ATraining Step: 156  | total loss: [1m[32m0.39727[0m[0m | time: 3.059s
[2K
| Adam | epoch: 010 | loss: 0.39727 - acc: 0.8438 -- iter: 096/537
[A[ATraining Step: 157  | total loss: [1m[32m0.39793[0m[0m | time: 4.408s
[2K
| Adam | epoch: 010 | loss: 0.39793 - acc: 0.8469 -- iter: 128/537
[A[ATraining Step: 158  | total loss: [1m[32m0.37627[0m[0m | time: 17.117s
[2K
| Adam | epoch: 010 | loss: 0.37627 - acc: 0.8560 -- iter: 160/537
[A[ATraining Step: 159  | total loss: [1m[32m0.37737[0m[0m | time: 26.126s
[2K
| Adam | epoch: 010 | loss: 0.37737 - acc: 0.8579 -- iter: 192/537
[A[ATraining Step: 160  | total loss: [1m[32m0.36270[0m[0m | time: 34.917s
[2K
| Adam | epoch: 010 | loss: 0.36270 - acc: 0.8658 -- iter: 224/537
[A[ATraining Step: 161  | total loss: [1m[32m0.36345[0m[0m | time: 41.247s
[2K
| Adam | epoch: 010 | loss: 0.36345 - acc: 0.8636 -- iter: 256/537
[A[ATraining Step: 162  | total loss: [1m[32m0.35540[0m[0m | time: 42.214s
[2K
| Adam | epoch: 010 | loss: 0.35540 - acc: 0.8613 -- iter: 288/537
[A[ATraining Step: 163  | total loss: [1m[32m0.34714[0m[0m | time: 43.222s
[2K
| Adam | epoch: 010 | loss: 0.34714 - acc: 0.8631 -- iter: 320/537
[A[ATraining Step: 164  | total loss: [1m[32m0.32183[0m[0m | time: 44.441s
[2K
| Adam | epoch: 010 | loss: 0.32183 - acc: 0.8768 -- iter: 352/537
[A[ATraining Step: 165  | total loss: [1m[32m0.30171[0m[0m | time: 45.701s
[2K
| Adam | epoch: 010 | loss: 0.30171 - acc: 0.8860 -- iter: 384/537
[A[ATraining Step: 166  | total loss: [1m[32m0.28949[0m[0m | time: 46.974s
[2K
| Adam | epoch: 010 | loss: 0.28949 - acc: 0.8943 -- iter: 416/537
[A[ATraining Step: 167  | total loss: [1m[32m0.27958[0m[0m | time: 48.302s
[2K
| Adam | epoch: 010 | loss: 0.27958 - acc: 0.8986 -- iter: 448/537
[A[ATraining Step: 168  | total loss: [1m[32m0.27621[0m[0m | time: 49.787s
[2K
| Adam | epoch: 010 | loss: 0.27621 - acc: 0.8994 -- iter: 480/537
[A[ATraining Step: 169  | total loss: [1m[32m0.26467[0m[0m | time: 51.072s
[2K
| Adam | epoch: 010 | loss: 0.26467 - acc: 0.9001 -- iter: 512/537
[A[ATraining Step: 170  | total loss: [1m[32m0.25336[0m[0m | time: 53.907s
[2K
| Adam | epoch: 010 | loss: 0.25336 - acc: 0.9069 | val_loss: 0.31554 - val_acc: 0.8988 -- iter: 537/537
--
Training Step: 171  | total loss: [1m[32m0.23696[0m[0m | time: 14.255s
[2K
| Adam | epoch: 011 | loss: 0.23696 - acc: 0.9162 -- iter: 032/537
[A[ATraining Step: 172  | total loss: [1m[32m0.22750[0m[0m | time: 21.864s
[2K
| Adam | epoch: 011 | loss: 0.22750 - acc: 0.9184 -- iter: 064/537
[A[ATraining Step: 173  | total loss: [1m[32m0.23718[0m[0m | time: 33.897s
[2K
| Adam | epoch: 011 | loss: 0.23718 - acc: 0.9203 -- iter: 096/537
[A[ATraining Step: 174  | total loss: [1m[32m0.23647[0m[0m | time: 42.602s
[2K
| Adam | epoch: 011 | loss: 0.23647 - acc: 0.9220 -- iter: 128/537
[A[ATraining Step: 175  | total loss: [1m[32m0.23378[0m[0m | time: 49.314s
[2K
| Adam | epoch: 011 | loss: 0.23378 - acc: 0.9236 -- iter: 160/537
[A[ATraining Step: 176  | total loss: [1m[32m0.25905[0m[0m | time: 54.428s
[2K
| Adam | epoch: 011 | loss: 0.25905 - acc: 0.9124 -- iter: 192/537
[A[ATraining Step: 177  | total loss: [1m[32m0.24032[0m[0m | time: 55.649s
[2K
| Adam | epoch: 011 | loss: 0.24032 - acc: 0.9212 -- iter: 224/537
[A[ATraining Step: 178  | total loss: [1m[32m0.23380[0m[0m | time: 56.972s
[2K
| Adam | epoch: 011 | loss: 0.23380 - acc: 0.9197 -- iter: 256/537
[A[ATraining Step: 179  | total loss: [1m[32m0.24139[0m[0m | time: 58.074s
[2K
| Adam | epoch: 011 | loss: 0.24139 - acc: 0.9215 -- iter: 288/537
[A[ATraining Step: 180  | total loss: [1m[32m0.23158[0m[0m | time: 59.039s
[2K
| Adam | epoch: 011 | loss: 0.23158 - acc: 0.9253 -- iter: 320/537
[A[ATraining Step: 181  | total loss: [1m[32m0.22957[0m[0m | time: 60.390s
[2K
| Adam | epoch: 011 | loss: 0.22957 - acc: 0.9208 -- iter: 352/537
[A[ATraining Step: 182  | total loss: [1m[32m0.23485[0m[0m | time: 61.711s
[2K
| Adam | epoch: 011 | loss: 0.23485 - acc: 0.9162 -- iter: 384/537
[A[ATraining Step: 183  | total loss: [1m[32m0.22808[0m[0m | time: 63.000s
[2K
| Adam | epoch: 011 | loss: 0.22808 - acc: 0.9215 -- iter: 416/537
[A[ATraining Step: 184  | total loss: [1m[32m0.23074[0m[0m | time: 64.250s
[2K
| Adam | epoch: 011 | loss: 0.23074 - acc: 0.9200 -- iter: 448/537
[A[ATraining Step: 185  | total loss: [1m[32m0.25095[0m[0m | time: 65.488s
[2K
| Adam | epoch: 011 | loss: 0.25095 - acc: 0.9061 -- iter: 480/537
[A[ATraining Step: 186  | total loss: [1m[32m0.24370[0m[0m | time: 66.762s
[2K
| Adam | epoch: 011 | loss: 0.24370 - acc: 0.9092 -- iter: 512/537
[A[ATraining Step: 187  | total loss: [1m[32m0.22343[0m[0m | time: 69.127s
[2K
| Adam | epoch: 011 | loss: 0.22343 - acc: 0.9183 | val_loss: 0.27145 - val_acc: 0.8988 -- iter: 537/537
--
Training Step: 188  | total loss: [1m[32m0.20817[0m[0m | time: 1.330s
[2K
| Adam | epoch: 012 | loss: 0.20817 - acc: 0.9265 -- iter: 032/537
[A[ATraining Step: 189  | total loss: [1m[32m0.19189[0m[0m | time: 2.633s
[2K
| Adam | epoch: 012 | loss: 0.19189 - acc: 0.9338 -- iter: 064/537
[A[ATraining Step: 190  | total loss: [1m[32m0.18838[0m[0m | time: 4.047s
[2K
| Adam | epoch: 012 | loss: 0.18838 - acc: 0.9342 -- iter: 096/537
[A[ATraining Step: 191  | total loss: [1m[32m0.18303[0m[0m | time: 5.340s
[2K
| Adam | epoch: 012 | loss: 0.18303 - acc: 0.9376 -- iter: 128/537
[A[ATraining Step: 192  | total loss: [1m[32m0.18121[0m[0m | time: 6.512s
[2K
| Adam | epoch: 012 | loss: 0.18121 - acc: 0.9408 -- iter: 160/537
[A[ATraining Step: 193  | total loss: [1m[32m0.17701[0m[0m | time: 7.955s
[2K
| Adam | epoch: 012 | loss: 0.17701 - acc: 0.9436 -- iter: 192/537
[A[ATraining Step: 194  | total loss: [1m[32m0.17478[0m[0m | time: 9.271s
[2K
| Adam | epoch: 012 | loss: 0.17478 - acc: 0.9461 -- iter: 224/537
[A[ATraining Step: 195  | total loss: [1m[32m0.17633[0m[0m | time: 10.397s
[2K
| Adam | epoch: 012 | loss: 0.17633 - acc: 0.9452 -- iter: 256/537
[A[ATraining Step: 196  | total loss: [1m[32m0.16428[0m[0m | time: 11.847s
[2K
| Adam | epoch: 012 | loss: 0.16428 - acc: 0.9507 -- iter: 288/537
[A[ATraining Step: 197  | total loss: [1m[32m0.15181[0m[0m | time: 12.934s
[2K
| Adam | epoch: 012 | loss: 0.15181 - acc: 0.9556 -- iter: 320/537
[A[ATraining Step: 198  | total loss: [1m[32m0.14646[0m[0m | time: 13.797s
[2K
| Adam | epoch: 012 | loss: 0.14646 - acc: 0.9561 -- iter: 352/537
[A[ATraining Step: 199  | total loss: [1m[32m0.13945[0m[0m | time: 15.070s
[2K
| Adam | epoch: 012 | loss: 0.13945 - acc: 0.9565 -- iter: 384/537
[A[ATraining Step: 200  | total loss: [1m[32m0.13711[0m[0m | time: 17.626s
[2K
| Adam | epoch: 012 | loss: 0.13711 - acc: 0.9577 | val_loss: 0.27296 - val_acc: 0.9048 -- iter: 416/537
--
Training Step: 201  | total loss: [1m[32m0.14992[0m[0m | time: 19.006s
[2K
| Adam | epoch: 012 | loss: 0.14992 - acc: 0.9557 -- iter: 448/537
[A[ATraining Step: 202  | total loss: [1m[32m0.15380[0m[0m | time: 29.979s
[2K
| Adam | epoch: 012 | loss: 0.15380 - acc: 0.9570 -- iter: 480/537
[A[ATraining Step: 203  | total loss: [1m[32m0.15308[0m[0m | time: 39.347s
[2K
| Adam | epoch: 012 | loss: 0.15308 - acc: 0.9550 -- iter: 512/537
[A[ATraining Step: 204  | total loss: [1m[32m0.15711[0m[0m | time: 47.408s
[2K
| Adam | epoch: 012 | loss: 0.15711 - acc: 0.9502 | val_loss: 0.35054 - val_acc: 0.8631 -- iter: 537/537
--
Training Step: 205  | total loss: [1m[32m0.15067[0m[0m | time: 1.301s
[2K
| Adam | epoch: 013 | loss: 0.15067 - acc: 0.9520 -- iter: 032/537
[A[ATraining Step: 206  | total loss: [1m[32m0.14160[0m[0m | time: 2.486s
[2K
| Adam | epoch: 013 | loss: 0.14160 - acc: 0.9568 -- iter: 064/537
[A[ATraining Step: 207  | total loss: [1m[32m0.15463[0m[0m | time: 3.822s
[2K
| Adam | epoch: 013 | loss: 0.15463 - acc: 0.9549 -- iter: 096/537
[A[ATraining Step: 208  | total loss: [1m[32m0.15757[0m[0m | time: 5.248s
[2K
| Adam | epoch: 013 | loss: 0.15757 - acc: 0.9563 -- iter: 128/537
[A[ATraining Step: 209  | total loss: [1m[32m0.14516[0m[0m | time: 6.706s
[2K
| Adam | epoch: 013 | loss: 0.14516 - acc: 0.9606 -- iter: 160/537
[A[ATraining Step: 210  | total loss: [1m[32m0.13454[0m[0m | time: 7.933s
[2K
| Adam | epoch: 013 | loss: 0.13454 - acc: 0.9646 -- iter: 192/537
[A[ATraining Step: 211  | total loss: [1m[32m0.13400[0m[0m | time: 9.394s
[2K
| Adam | epoch: 013 | loss: 0.13400 - acc: 0.9650 -- iter: 224/537
[A[ATraining Step: 212  | total loss: [1m[32m0.12640[0m[0m | time: 10.746s
[2K
| Adam | epoch: 013 | loss: 0.12640 - acc: 0.9685 -- iter: 256/537
[A[ATraining Step: 213  | total loss: [1m[32m0.11885[0m[0m | time: 25.584s
[2K
| Adam | epoch: 013 | loss: 0.11885 - acc: 0.9716 -- iter: 288/537
[A[ATraining Step: 214  | total loss: [1m[32m0.13667[0m[0m | time: 34.660s
[2K
| Adam | epoch: 013 | loss: 0.13667 - acc: 0.9651 -- iter: 320/537
[A[ATraining Step: 215  | total loss: [1m[32m0.13236[0m[0m | time: 41.579s
[2K
| Adam | epoch: 013 | loss: 0.13236 - acc: 0.9655 -- iter: 352/537
[A[ATraining Step: 216  | total loss: [1m[32m0.12165[0m[0m | time: 47.769s
[2K
| Adam | epoch: 013 | loss: 0.12165 - acc: 0.9689 -- iter: 384/537
[A[ATraining Step: 217  | total loss: [1m[32m0.11142[0m[0m | time: 48.864s
[2K
| Adam | epoch: 013 | loss: 0.11142 - acc: 0.9720 -- iter: 416/537
[A[ATraining Step: 218  | total loss: [1m[32m0.12872[0m[0m | time: 49.908s
[2K
| Adam | epoch: 013 | loss: 0.12872 - acc: 0.9623 -- iter: 448/537
[A[ATraining Step: 219  | total loss: [1m[32m0.12600[0m[0m | time: 51.130s
[2K
| Adam | epoch: 013 | loss: 0.12600 - acc: 0.9598 -- iter: 480/537
[A[ATraining Step: 220  | total loss: [1m[32m0.14075[0m[0m | time: 52.328s
[2K
| Adam | epoch: 013 | loss: 0.14075 - acc: 0.9576 -- iter: 512/537
[A[ATraining Step: 221  | total loss: [1m[32m0.14076[0m[0m | time: 54.935s
[2K
| Adam | epoch: 013 | loss: 0.14076 - acc: 0.9587 | val_loss: 0.27125 - val_acc: 0.9167 -- iter: 537/537
--
Training Step: 222  | total loss: [1m[32m0.13661[0m[0m | time: 1.403s
[2K
| Adam | epoch: 014 | loss: 0.13661 - acc: 0.9597 -- iter: 032/537
[A[ATraining Step: 223  | total loss: [1m[32m0.12731[0m[0m | time: 2.624s
[2K
| Adam | epoch: 014 | loss: 0.12731 - acc: 0.9638 -- iter: 064/537
[A[ATraining Step: 224  | total loss: [1m[32m0.11797[0m[0m | time: 3.930s
[2K
| Adam | epoch: 014 | loss: 0.11797 - acc: 0.9674 -- iter: 096/537
[A[ATraining Step: 225  | total loss: [1m[32m0.12252[0m[0m | time: 5.990s
[2K
| Adam | epoch: 014 | loss: 0.12252 - acc: 0.9675 -- iter: 128/537
[A[ATraining Step: 226  | total loss: [1m[32m0.11929[0m[0m | time: 15.264s
[2K
| Adam | epoch: 014 | loss: 0.11929 - acc: 0.9676 -- iter: 160/537
[A[ATraining Step: 227  | total loss: [1m[32m0.10991[0m[0m | time: 23.239s
[2K
| Adam | epoch: 014 | loss: 0.10991 - acc: 0.9709 -- iter: 192/537
[A[ATraining Step: 228  | total loss: [1m[32m0.10645[0m[0m | time: 32.904s
[2K
| Adam | epoch: 014 | loss: 0.10645 - acc: 0.9707 -- iter: 224/537
[A[ATraining Step: 229  | total loss: [1m[32m0.09896[0m[0m | time: 38.652s
[2K
| Adam | epoch: 014 | loss: 0.09896 - acc: 0.9736 -- iter: 256/537
[A[ATraining Step: 230  | total loss: [1m[32m0.10498[0m[0m | time: 45.277s
[2K
| Adam | epoch: 014 | loss: 0.10498 - acc: 0.9731 -- iter: 288/537
[A[ATraining Step: 231  | total loss: [1m[32m0.09661[0m[0m | time: 58.318s
[2K
| Adam | epoch: 014 | loss: 0.09661 - acc: 0.9758 -- iter: 320/537
[A[ATraining Step: 232  | total loss: [1m[32m0.09132[0m[0m | time: 59.557s
[2K
| Adam | epoch: 014 | loss: 0.09132 - acc: 0.9751 -- iter: 352/537
[A[ATraining Step: 233  | total loss: [1m[32m0.08476[0m[0m | time: 60.555s
[2K
| Adam | epoch: 014 | loss: 0.08476 - acc: 0.9776 -- iter: 384/537
[A[ATraining Step: 234  | total loss: [1m[32m0.07861[0m[0m | time: 61.493s
[2K
| Adam | epoch: 014 | loss: 0.07861 - acc: 0.9798 -- iter: 416/537
[A[ATraining Step: 235  | total loss: [1m[32m0.07246[0m[0m | time: 62.913s
[2K
| Adam | epoch: 014 | loss: 0.07246 - acc: 0.9818 -- iter: 448/537
[A[ATraining Step: 236  | total loss: [1m[32m0.07560[0m[0m | time: 64.346s
[2K
| Adam | epoch: 014 | loss: 0.07560 - acc: 0.9805 -- iter: 480/537
[A[ATraining Step: 237  | total loss: [1m[32m0.07212[0m[0m | time: 65.429s
[2K
| Adam | epoch: 014 | loss: 0.07212 - acc: 0.9825 -- iter: 512/537
[A[ATraining Step: 238  | total loss: [1m[32m0.09495[0m[0m | time: 68.099s
[2K
| Adam | epoch: 014 | loss: 0.09495 - acc: 0.9811 | val_loss: 0.43338 - val_acc: 0.8393 -- iter: 537/537
--
Training Step: 239  | total loss: [1m[32m0.08949[0m[0m | time: 1.244s
[2K
| Adam | epoch: 015 | loss: 0.08949 - acc: 0.9799 -- iter: 032/537
[A[ATraining Step: 240  | total loss: [1m[32m0.08994[0m[0m | time: 2.602s
[2K
| Adam | epoch: 015 | loss: 0.08994 - acc: 0.9788 -- iter: 064/537
[A[ATraining Step: 241  | total loss: [1m[32m0.09076[0m[0m | time: 4.018s
[2K
| Adam | epoch: 015 | loss: 0.09076 - acc: 0.9746 -- iter: 096/537
[A[ATraining Step: 242  | total loss: [1m[32m0.08754[0m[0m | time: 5.165s
[2K
| Adam | epoch: 015 | loss: 0.08754 - acc: 0.9740 -- iter: 128/537
[A[ATraining Step: 243  | total loss: [1m[32m0.08397[0m[0m | time: 6.420s
[2K
| Adam | epoch: 015 | loss: 0.08397 - acc: 0.9735 -- iter: 160/537
[A[ATraining Step: 244  | total loss: [1m[32m0.08394[0m[0m | time: 7.713s
[2K
| Adam | epoch: 015 | loss: 0.08394 - acc: 0.9730 -- iter: 192/537
[A[ATraining Step: 245  | total loss: [1m[32m0.10149[0m[0m | time: 8.982s
[2K
| Adam | epoch: 015 | loss: 0.10149 - acc: 0.9664 -- iter: 224/537
[A[ATraining Step: 246  | total loss: [1m[32m0.12498[0m[0m | time: 10.332s
[2K
| Adam | epoch: 015 | loss: 0.12498 - acc: 0.9510 -- iter: 256/537
[A[ATraining Step: 247  | total loss: [1m[32m0.11590[0m[0m | time: 11.763s
[2K
| Adam | epoch: 015 | loss: 0.11590 - acc: 0.9559 -- iter: 288/537
[A[ATraining Step: 248  | total loss: [1m[32m0.11987[0m[0m | time: 13.041s
[2K
| Adam | epoch: 015 | loss: 0.11987 - acc: 0.9572 -- iter: 320/537
[A[ATraining Step: 249  | total loss: [1m[32m0.11116[0m[0m | time: 14.207s
[2K
| Adam | epoch: 015 | loss: 0.11116 - acc: 0.9614 -- iter: 352/537
[A[ATraining Step: 250  | total loss: [1m[32m0.12426[0m[0m | time: 15.361s
[2K
| Adam | epoch: 015 | loss: 0.12426 - acc: 0.9528 -- iter: 384/537
[A[ATraining Step: 251  | total loss: [1m[32m0.12870[0m[0m | time: 16.391s
[2K
| Adam | epoch: 015 | loss: 0.12870 - acc: 0.9481 -- iter: 416/537
[A[ATraining Step: 252  | total loss: [1m[32m0.11788[0m[0m | time: 17.527s
[2K
| Adam | epoch: 015 | loss: 0.11788 - acc: 0.9533 -- iter: 448/537
[A[ATraining Step: 253  | total loss: [1m[32m0.10984[0m[0m | time: 18.881s
[2K
| Adam | epoch: 015 | loss: 0.10984 - acc: 0.9580 -- iter: 480/537
[A[ATraining Step: 254  | total loss: [1m[32m0.12256[0m[0m | time: 20.089s
[2K
| Adam | epoch: 015 | loss: 0.12256 - acc: 0.9434 -- iter: 512/537
[A[ATraining Step: 255  | total loss: [1m[32m0.13069[0m[0m | time: 22.634s
[2K
| Adam | epoch: 015 | loss: 0.13069 - acc: 0.9397 | val_loss: 0.25372 - val_acc: 0.9167 -- iter: 537/537
--
Validation AUC:0.9656695156695156
Validation AUPRC:0.9648020588071875
Test AUC:0.9904829545454547
Test AUPRC:0.9937568285913555
BestTestF1Score	0.97	0.93	0.96	0.98	0.95	84	2	78	4	0.47
BestTestMCCScore	0.97	0.93	0.96	0.98	0.95	84	2	78	4	0.47
BestTestAccuracyScore	0.97	0.93	0.96	0.98	0.95	84	2	78	4	0.47
BestValidationF1Score	0.92	0.85	0.92	0.9	0.94	73	8	82	5	0.47
BestValidationMCC	0.92	0.85	0.92	0.9	0.94	73	8	82	5	0.47
BestValidationAccuracy	0.92	0.85	0.92	0.9	0.94	73	8	82	5	0.47
TestPredictions (Threshold:0.47)
CHEMBL298203,TN,INACT,0.009999999776482582	CHEMBL112343,TP,ACT,0.9800000190734863	CHEMBL435810,TN,INACT,0.029999999329447746	CHEMBL450463,TN,INACT,0.029999999329447746	CHEMBL168223,TN,INACT,0.019999999552965164	CHEMBL100624,TN,INACT,0.019999999552965164	CHEMBL1907665,TN,INACT,0.019999999552965164	CHEMBL2093084,TN,INACT,0.05000000074505806	CHEMBL325935,TN,INACT,0.019999999552965164	CHEMBL307752,TP,ACT,0.9900000095367432	CHEMBL86247,TP,ACT,0.9800000190734863	CHEMBL164968,TN,INACT,0.029999999329447746	CHEMBL330885,TN,INACT,0.4699999988079071	CHEMBL87884,TP,ACT,0.9800000190734863	CHEMBL353502,TN,INACT,0.009999999776482582	CHEMBL328552,FN,ACT,0.27000001072883606	CHEMBL2079781,TP,ACT,0.8999999761581421	CHEMBL21508,TN,INACT,0.009999999776482582	CHEMBL80218,TP,ACT,0.9900000095367432	CHEMBL111023,TN,INACT,0.029999999329447746	CHEMBL309397,TN,INACT,0.019999999552965164	CHEMBL77962,TN,INACT,0.019999999552965164	CHEMBL245319,TN,INACT,0.009999999776482582	CHEMBL114656,TP,ACT,0.9900000095367432	CHEMBL42799,TN,INACT,0.009999999776482582	CHEMBL3780248,TN,INACT,0.10000000149011612	CHEMBL132280,TP,ACT,0.9900000095367432	CHEMBL342287,TP,ACT,0.9800000190734863	CHEMBL276381,TP,ACT,1.0	CHEMBL432529,TP,ACT,0.9700000286102295	CHEMBL81593,TN,INACT,0.009999999776482582	CHEMBL49954,TP,ACT,0.9900000095367432	CHEMBL142822,TN,INACT,0.019999999552965164	CHEMBL301705,TP,ACT,0.9800000190734863	CHEMBL89689,TN,INACT,0.03999999910593033	CHEMBL303386,TN,INACT,0.14000000059604645	CHEMBL460470,TN,INACT,0.029999999329447746	CHEMBL325684,TP,ACT,0.9900000095367432	CHEMBL104684,TP,ACT,0.9900000095367432	CHEMBL328422,TN,INACT,0.009999999776482582	CHEMBL354126,TN,INACT,0.009999999776482582	CHEMBL309017,TN,INACT,0.10000000149011612	CHEMBL47428,TP,ACT,1.0	CHEMBL114074,TN,INACT,0.019999999552965164	CHEMBL424214,TN,INACT,0.029999999329447746	CHEMBL3218122,TN,INACT,0.019999999552965164	CHEMBL276163,FN,ACT,0.20999999344348907	CHEMBL195893,TN,INACT,0.029999999329447746	CHEMBL104,FP,INACT,0.5799999833106995	CHEMBL420028,TP,ACT,1.0	CHEMBL297358,TP,ACT,1.0	CHEMBL302261,TP,ACT,0.9900000095367432	CHEMBL432153,TP,ACT,1.0	CHEMBL308138,TP,ACT,1.0	CHEMBL2079768,TP,ACT,0.9100000262260437	CHEMBL545363,TN,INACT,0.019999999552965164	CHEMBL45814,TP,ACT,0.9800000190734863	CHEMBL241100,TN,INACT,0.009999999776482582	CHEMBL127068,TP,ACT,1.0	CHEMBL312632,TP,ACT,0.9900000095367432	CHEMBL126801,TP,ACT,1.0	CHEMBL2113072,TN,INACT,0.029999999329447746	CHEMBL10801,TN,INACT,0.03999999910593033	CHEMBL320569,TN,INACT,0.019999999552965164	CHEMBL106682,TP,ACT,0.9800000190734863	CHEMBL351183,TN,INACT,0.33000001311302185	CHEMBL70029,TP,ACT,1.0	CHEMBL86562,TP,ACT,0.9800000190734863	CHEMBL434815,TP,ACT,0.9800000190734863	CHEMBL86346,TP,ACT,1.0	CHEMBL313239,TP,ACT,0.9399999976158142	CHEMBL404557,TN,INACT,0.029999999329447746	CHEMBL171108,TN,INACT,0.019999999552965164	CHEMBL110904,TN,INACT,0.019999999552965164	CHEMBL416477,TP,ACT,0.9900000095367432	CHEMBL140495,TN,INACT,0.009999999776482582	CHEMBL332051,TP,ACT,0.9700000286102295	CHEMBL319036,FP,INACT,0.8700000047683716	CHEMBL417712,TN,INACT,0.009999999776482582	CHEMBL202861,TN,INACT,0.03999999910593033	CHEMBL310250,TN,INACT,0.009999999776482582	CHEMBL289448,TP,ACT,0.9800000190734863	CHEMBL35475,TP,ACT,0.9900000095367432	CHEMBL413040,TN,INACT,0.4399999976158142	CHEMBL297465,TP,ACT,0.8999999761581421	CHEMBL6568,TN,INACT,0.03999999910593033	CHEMBL304032,TP,ACT,1.0	CHEMBL131948,TP,ACT,0.9900000095367432	CHEMBL67764,TP,ACT,1.0	CHEMBL78399,TP,ACT,1.0	CHEMBL63937,TN,INACT,0.009999999776482582	CHEMBL421092,TP,ACT,1.0	CHEMBL359141,TN,INACT,0.019999999552965164	CHEMBL129181,TP,ACT,0.9900000095367432	CHEMBL424483,TP,ACT,0.9100000262260437	CHEMBL293232,TN,INACT,0.019999999552965164	CHEMBL80446,TP,ACT,0.9700000286102295	CHEMBL48756,TP,ACT,0.9800000190734863	CHEMBL80317,TN,INACT,0.019999999552965164	CHEMBL437659,TP,ACT,1.0	CHEMBL443005,TP,ACT,0.9800000190734863	CHEMBL45160,TN,INACT,0.009999999776482582	CHEMBL127090,TP,ACT,1.0	CHEMBL302282,TN,INACT,0.009999999776482582	CHEMBL88350,TP,ACT,1.0	CHEMBL111218,TN,INACT,0.019999999552965164	CHEMBL174463,TN,INACT,0.009999999776482582	CHEMBL104848,TN,INACT,0.009999999776482582	CHEMBL46782,TP,ACT,1.0	CHEMBL2370511,TN,INACT,0.019999999552965164	CHEMBL288967,TN,INACT,0.009999999776482582	CHEMBL315022,TP,ACT,0.9900000095367432	CHEMBL3109772,TN,INACT,0.05000000074505806	CHEMBL300487,TP,ACT,0.9399999976158142	CHEMBL3780633,TN,INACT,0.019999999552965164	CHEMBL88014,TP,ACT,0.9700000286102295	CHEMBL424629,TP,ACT,0.9399999976158142	CHEMBL88067,TP,ACT,0.9900000095367432	CHEMBL306645,TN,INACT,0.009999999776482582	CHEMBL418306,TP,ACT,0.9800000190734863	CHEMBL80161,TP,ACT,0.9700000286102295	CHEMBL145276,TP,ACT,0.9800000190734863	CHEMBL296725,TP,ACT,1.0	CHEMBL594376,TN,INACT,0.03999999910593033	CHEMBL429238,TN,INACT,0.17000000178813934	CHEMBL77783,TP,ACT,1.0	CHEMBL114625,FN,ACT,0.019999999552965164	CHEMBL67515,TP,ACT,0.9399999976158142	CHEMBL130741,FN,ACT,0.46000000834465027	CHEMBL89457,TN,INACT,0.009999999776482582	CHEMBL40317,TN,INACT,0.019999999552965164	CHEMBL128913,TP,ACT,0.9900000095367432	CHEMBL432334,TN,INACT,0.009999999776482582	CHEMBL302150,TN,INACT,0.1899999976158142	CHEMBL88506,TN,INACT,0.009999999776482582	CHEMBL333534,TP,ACT,0.9900000095367432	CHEMBL128922,TP,ACT,0.9900000095367432	CHEMBL233552,TN,INACT,0.18000000715255737	CHEMBL286537,TP,ACT,1.0	CHEMBL68919,TP,ACT,1.0	CHEMBL3633663,TN,INACT,0.17000000178813934	CHEMBL3218124,TN,INACT,0.36000001430511475	CHEMBL331394,TN,INACT,0.03999999910593033	CHEMBL421141,TP,ACT,1.0	CHEMBL37679,TP,ACT,0.9599999785423279	CHEMBL47810,TP,ACT,1.0	CHEMBL45195,TP,ACT,0.9300000071525574	CHEMBL340618,TP,ACT,1.0	CHEMBL412664,TP,ACT,0.9800000190734863	CHEMBL118553,TN,INACT,0.1599999964237213	CHEMBL309458,TP,ACT,1.0	CHEMBL77384,TP,ACT,1.0	CHEMBL336033,TN,INACT,0.07000000029802322	CHEMBL299324,TP,ACT,0.9399999976158142	CHEMBL331983,TP,ACT,0.9399999976158142	CHEMBL40250,TP,ACT,0.5699999928474426	CHEMBL85405,TP,ACT,0.9599999785423279	CHEMBL112877,TN,INACT,0.019999999552965164	CHEMBL169675,TN,INACT,0.019999999552965164	CHEMBL432974,TN,INACT,0.019999999552965164	CHEMBL322537,TN,INACT,0.019999999552965164	CHEMBL89953,TN,INACT,0.029999999329447746	CHEMBL314149,TP,ACT,1.0	CHEMBL299130,TP,ACT,0.9300000071525574	CHEMBL3633656,TN,INACT,0.019999999552965164	CHEMBL334515,TP,ACT,0.949999988079071	CHEMBL338954,TP,ACT,0.949999988079071	CHEMBL12451,TP,ACT,0.9900000095367432	

