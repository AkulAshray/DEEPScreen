CNNModel CHEMBL4145 adam 0.0005 30 256 0 0.8 False True
Number of active compounds :	109
Number of inactive compounds :	109
---------------------------------
Run id: CNNModel_CHEMBL4145_adam_0.0005_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4145_adam_0.0005_30_256_0.8_True/
---------------------------------
Training samples: 139
Validation samples: 44
--
Training Step: 1  | time: 1.862s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/139
[A[ATraining Step: 2  | total loss: [1m[32m0.62370[0m[0m | time: 3.295s
[2K
| Adam | epoch: 001 | loss: 0.62370 - acc: 0.5625 -- iter: 064/139
[A[ATraining Step: 3  | total loss: [1m[32m0.68067[0m[0m | time: 4.628s
[2K
| Adam | epoch: 001 | loss: 0.68067 - acc: 0.5114 -- iter: 096/139
[A[ATraining Step: 4  | total loss: [1m[32m0.69044[0m[0m | time: 5.664s
[2K
| Adam | epoch: 001 | loss: 0.69044 - acc: 0.4794 -- iter: 128/139
[A[ATraining Step: 5  | total loss: [1m[32m0.69253[0m[0m | time: 7.194s
[2K
| Adam | epoch: 001 | loss: 0.69253 - acc: 0.4720 | val_loss: 0.69307 - val_acc: 0.5227 -- iter: 139/139
--
Training Step: 6  | total loss: [1m[32m0.69416[0m[0m | time: 0.637s
[2K
| Adam | epoch: 002 | loss: 0.69416 - acc: 0.4023 -- iter: 032/139
[A[ATraining Step: 7  | total loss: [1m[32m0.69391[0m[0m | time: 2.130s
[2K
| Adam | epoch: 002 | loss: 0.69391 - acc: 0.3791 -- iter: 064/139
[A[ATraining Step: 8  | total loss: [1m[32m0.69347[0m[0m | time: 3.278s
[2K
| Adam | epoch: 002 | loss: 0.69347 - acc: 0.4471 -- iter: 096/139
[A[ATraining Step: 9  | total loss: [1m[32m0.69362[0m[0m | time: 4.331s
[2K
| Adam | epoch: 002 | loss: 0.69362 - acc: 0.4586 -- iter: 128/139
[A[ATraining Step: 10  | total loss: [1m[32m0.69396[0m[0m | time: 6.895s
[2K
| Adam | epoch: 002 | loss: 0.69396 - acc: 0.4480 | val_loss: 0.69353 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 11  | total loss: [1m[32m0.69318[0m[0m | time: 0.389s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.5023 -- iter: 032/139
[A[ATraining Step: 12  | total loss: [1m[32m0.69353[0m[0m | time: 0.796s
[2K
| Adam | epoch: 003 | loss: 0.69353 - acc: 0.4808 -- iter: 064/139
[A[ATraining Step: 13  | total loss: [1m[32m0.69361[0m[0m | time: 2.068s
[2K
| Adam | epoch: 003 | loss: 0.69361 - acc: 0.4695 -- iter: 096/139
[A[ATraining Step: 14  | total loss: [1m[32m0.69337[0m[0m | time: 3.395s
[2K
| Adam | epoch: 003 | loss: 0.69337 - acc: 0.4820 -- iter: 128/139
[A[ATraining Step: 15  | total loss: [1m[32m0.69291[0m[0m | time: 5.518s
[2K
| Adam | epoch: 003 | loss: 0.69291 - acc: 0.5257 | val_loss: 0.69353 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 16  | total loss: [1m[32m0.69261[0m[0m | time: 1.223s
[2K
| Adam | epoch: 004 | loss: 0.69261 - acc: 0.5512 -- iter: 032/139
[A[ATraining Step: 17  | total loss: [1m[32m0.69263[0m[0m | time: 1.784s
[2K
| Adam | epoch: 004 | loss: 0.69263 - acc: 0.5440 -- iter: 064/139
[A[ATraining Step: 18  | total loss: [1m[32m0.69313[0m[0m | time: 2.396s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.5131 -- iter: 096/139
[A[ATraining Step: 19  | total loss: [1m[32m0.69355[0m[0m | time: 3.873s
[2K
| Adam | epoch: 004 | loss: 0.69355 - acc: 0.4936 -- iter: 128/139
[A[ATraining Step: 20  | total loss: [1m[32m0.69383[0m[0m | time: 6.185s
[2K
| Adam | epoch: 004 | loss: 0.69383 - acc: 0.4755 | val_loss: 0.69361 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 21  | total loss: [1m[32m0.69333[0m[0m | time: 1.261s
[2K
| Adam | epoch: 005 | loss: 0.69333 - acc: 0.4928 -- iter: 032/139
[A[ATraining Step: 22  | total loss: [1m[32m0.69277[0m[0m | time: 2.445s
[2K
| Adam | epoch: 005 | loss: 0.69277 - acc: 0.5231 -- iter: 064/139
[A[ATraining Step: 23  | total loss: [1m[32m0.69313[0m[0m | time: 3.153s
[2K
| Adam | epoch: 005 | loss: 0.69313 - acc: 0.5073 -- iter: 096/139
[A[ATraining Step: 24  | total loss: [1m[32m0.69164[0m[0m | time: 3.748s
[2K
| Adam | epoch: 005 | loss: 0.69164 - acc: 0.5692 -- iter: 128/139
[A[ATraining Step: 25  | total loss: [1m[32m0.69018[0m[0m | time: 6.142s
[2K
| Adam | epoch: 005 | loss: 0.69018 - acc: 0.6123 | val_loss: 0.69510 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 26  | total loss: [1m[32m0.69089[0m[0m | time: 0.675s
[2K
| Adam | epoch: 006 | loss: 0.69089 - acc: 0.5826 -- iter: 032/139
[A[ATraining Step: 27  | total loss: [1m[32m0.69258[0m[0m | time: 1.338s
[2K
| Adam | epoch: 006 | loss: 0.69258 - acc: 0.5453 -- iter: 064/139
[A[ATraining Step: 28  | total loss: [1m[32m0.69260[0m[0m | time: 1.992s
[2K
| Adam | epoch: 006 | loss: 0.69260 - acc: 0.5340 -- iter: 096/139
[A[ATraining Step: 29  | total loss: [1m[32m0.69282[0m[0m | time: 2.253s
[2K
| Adam | epoch: 006 | loss: 0.69282 - acc: 0.5257 -- iter: 128/139
[A[ATraining Step: 30  | total loss: [1m[32m0.69225[0m[0m | time: 3.513s
[2K
| Adam | epoch: 006 | loss: 0.69225 - acc: 0.5304 | val_loss: 0.69662 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 31  | total loss: [1m[32m0.69164[0m[0m | time: 0.639s
[2K
| Adam | epoch: 007 | loss: 0.69164 - acc: 0.5339 -- iter: 032/139
[A[ATraining Step: 32  | total loss: [1m[32m0.69208[0m[0m | time: 2.063s
[2K
| Adam | epoch: 007 | loss: 0.69208 - acc: 0.5262 -- iter: 064/139
[A[ATraining Step: 33  | total loss: [1m[32m0.69089[0m[0m | time: 3.227s
[2K
| Adam | epoch: 007 | loss: 0.69089 - acc: 0.5342 -- iter: 096/139
[A[ATraining Step: 34  | total loss: [1m[32m0.68586[0m[0m | time: 4.060s
[2K
| Adam | epoch: 007 | loss: 0.68586 - acc: 0.5670 -- iter: 128/139
[A[ATraining Step: 35  | total loss: [1m[32m0.68767[0m[0m | time: 5.350s
[2K
| Adam | epoch: 007 | loss: 0.68767 - acc: 0.5530 | val_loss: 0.70009 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 36  | total loss: [1m[32m0.69946[0m[0m | time: 0.284s
[2K
| Adam | epoch: 008 | loss: 0.69946 - acc: 0.4957 -- iter: 032/139
[A[ATraining Step: 37  | total loss: [1m[32m0.70617[0m[0m | time: 0.950s
[2K
| Adam | epoch: 008 | loss: 0.70617 - acc: 0.4511 -- iter: 064/139
[A[ATraining Step: 38  | total loss: [1m[32m0.70369[0m[0m | time: 1.634s
[2K
| Adam | epoch: 008 | loss: 0.70369 - acc: 0.4607 -- iter: 096/139
[A[ATraining Step: 39  | total loss: [1m[32m0.70207[0m[0m | time: 2.289s
[2K
| Adam | epoch: 008 | loss: 0.70207 - acc: 0.4622 -- iter: 128/139
[A[ATraining Step: 40  | total loss: [1m[32m0.69991[0m[0m | time: 3.949s
[2K
| Adam | epoch: 008 | loss: 0.69991 - acc: 0.4810 | val_loss: 0.69367 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 41  | total loss: [1m[32m0.69790[0m[0m | time: 0.260s
[2K
| Adam | epoch: 009 | loss: 0.69790 - acc: 0.4960 -- iter: 032/139
[A[ATraining Step: 42  | total loss: [1m[32m0.69666[0m[0m | time: 0.508s
[2K
| Adam | epoch: 009 | loss: 0.69666 - acc: 0.5049 -- iter: 064/139
[A[ATraining Step: 43  | total loss: [1m[32m0.69572[0m[0m | time: 1.160s
[2K
| Adam | epoch: 009 | loss: 0.69572 - acc: 0.5120 -- iter: 096/139
[A[ATraining Step: 44  | total loss: [1m[32m0.69506[0m[0m | time: 1.817s
[2K
| Adam | epoch: 009 | loss: 0.69506 - acc: 0.5154 -- iter: 128/139
[A[ATraining Step: 45  | total loss: [1m[32m0.69504[0m[0m | time: 3.486s
[2K
| Adam | epoch: 009 | loss: 0.69504 - acc: 0.4968 | val_loss: 0.69332 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 46  | total loss: [1m[32m0.69447[0m[0m | time: 0.680s
[2K
| Adam | epoch: 010 | loss: 0.69447 - acc: 0.5078 -- iter: 032/139
[A[ATraining Step: 47  | total loss: [1m[32m0.69443[0m[0m | time: 0.964s
[2K
| Adam | epoch: 010 | loss: 0.69443 - acc: 0.4912 -- iter: 064/139
[A[ATraining Step: 48  | total loss: [1m[32m0.69400[0m[0m | time: 1.224s
[2K
| Adam | epoch: 010 | loss: 0.69400 - acc: 0.4999 -- iter: 096/139
[A[ATraining Step: 49  | total loss: [1m[32m0.69368[0m[0m | time: 1.901s
[2K
| Adam | epoch: 010 | loss: 0.69368 - acc: 0.5071 -- iter: 128/139
[A[ATraining Step: 50  | total loss: [1m[32m0.69360[0m[0m | time: 3.589s
[2K
| Adam | epoch: 010 | loss: 0.69360 - acc: 0.5011 | val_loss: 0.69320 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 51  | total loss: [1m[32m0.69325[0m[0m | time: 0.674s
[2K
| Adam | epoch: 011 | loss: 0.69325 - acc: 0.5200 -- iter: 032/139
[A[ATraining Step: 52  | total loss: [1m[32m0.69323[0m[0m | time: 1.337s
[2K
| Adam | epoch: 011 | loss: 0.69323 - acc: 0.5123 -- iter: 064/139
[A[ATraining Step: 53  | total loss: [1m[32m0.69300[0m[0m | time: 1.600s
[2K
| Adam | epoch: 011 | loss: 0.69300 - acc: 0.5197 -- iter: 096/139
[A[ATraining Step: 54  | total loss: [1m[32m0.69304[0m[0m | time: 1.837s
[2K
| Adam | epoch: 011 | loss: 0.69304 - acc: 0.5103 -- iter: 128/139
[A[ATraining Step: 55  | total loss: [1m[32m0.69304[0m[0m | time: 3.515s
[2K
| Adam | epoch: 011 | loss: 0.69304 - acc: 0.5023 | val_loss: 0.69304 - val_acc: 0.4773 -- iter: 139/139
--
Training Step: 56  | total loss: [1m[32m0.69285[0m[0m | time: 0.688s
[2K
| Adam | epoch: 012 | loss: 0.69285 - acc: 0.5108 -- iter: 032/139
[A[ATraining Step: 57  | total loss: [1m[32m0.69283[0m[0m | time: 1.347s
[2K
| Adam | epoch: 012 | loss: 0.69283 - acc: 0.5093 -- iter: 064/139
[A[ATraining Step: 58  | total loss: [1m[32m0.69261[0m[0m | time: 2.017s
[2K
| Adam | epoch: 012 | loss: 0.69261 - acc: 0.5251 -- iter: 096/139
[A[ATraining Step: 59  | total loss: [1m[32m0.69253[0m[0m | time: 2.283s
[2K
| Adam | epoch: 012 | loss: 0.69253 - acc: 0.5217 -- iter: 128/139
[A[ATraining Step: 60  | total loss: [1m[32m0.69296[0m[0m | time: 3.541s
[2K
| Adam | epoch: 012 | loss: 0.69296 - acc: 0.4767 | val_loss: 0.69263 - val_acc: 0.5682 -- iter: 139/139
--
Training Step: 61  | total loss: [1m[32m0.69318[0m[0m | time: 0.828s
[2K
| Adam | epoch: 013 | loss: 0.69318 - acc: 0.4382 -- iter: 032/139
[A[ATraining Step: 62  | total loss: [1m[32m0.69306[0m[0m | time: 1.609s
[2K
| Adam | epoch: 013 | loss: 0.69306 - acc: 0.4623 -- iter: 064/139
[A[ATraining Step: 63  | total loss: [1m[32m0.69290[0m[0m | time: 2.856s
[2K
| Adam | epoch: 013 | loss: 0.69290 - acc: 0.4908 -- iter: 096/139
[A[ATraining Step: 64  | total loss: [1m[32m0.69276[0m[0m | time: 4.265s
[2K
| Adam | epoch: 013 | loss: 0.69276 - acc: 0.5115 -- iter: 128/139
[A[ATraining Step: 65  | total loss: [1m[32m0.69256[0m[0m | time: 5.907s
[2K
| Adam | epoch: 013 | loss: 0.69256 - acc: 0.5293 | val_loss: 0.69178 - val_acc: 0.5682 -- iter: 139/139
--
Training Step: 66  | total loss: [1m[32m0.69239[0m[0m | time: 0.457s
[2K
| Adam | epoch: 014 | loss: 0.69239 - acc: 0.5313 -- iter: 032/139
[A[ATraining Step: 67  | total loss: [1m[32m0.69208[0m[0m | time: 1.602s
[2K
| Adam | epoch: 014 | loss: 0.69208 - acc: 0.5548 -- iter: 064/139
[A[ATraining Step: 68  | total loss: [1m[32m0.69211[0m[0m | time: 2.803s
[2K
| Adam | epoch: 014 | loss: 0.69211 - acc: 0.5446 -- iter: 096/139
[A[ATraining Step: 69  | total loss: [1m[32m0.69200[0m[0m | time: 4.071s
[2K
| Adam | epoch: 014 | loss: 0.69200 - acc: 0.5540 -- iter: 128/139
[A[ATraining Step: 70  | total loss: [1m[32m0.69173[0m[0m | time: 6.636s
[2K
| Adam | epoch: 014 | loss: 0.69173 - acc: 0.5766 | val_loss: 0.69160 - val_acc: 0.5455 -- iter: 139/139
--
Training Step: 71  | total loss: [1m[32m0.69145[0m[0m | time: 0.581s
[2K
| Adam | epoch: 015 | loss: 0.69145 - acc: 0.5999 -- iter: 032/139
[A[ATraining Step: 72  | total loss: [1m[32m0.69151[0m[0m | time: 1.089s
[2K
| Adam | epoch: 015 | loss: 0.69151 - acc: 0.5938 -- iter: 064/139
[A[ATraining Step: 73  | total loss: [1m[32m0.69124[0m[0m | time: 2.111s
[2K
| Adam | epoch: 015 | loss: 0.69124 - acc: 0.5985 -- iter: 096/139
[A[ATraining Step: 74  | total loss: [1m[32m0.69060[0m[0m | time: 6.834s
[2K
| Adam | epoch: 015 | loss: 0.69060 - acc: 0.6117 -- iter: 128/139
[A[ATraining Step: 75  | total loss: [1m[32m0.69024[0m[0m | time: 8.946s
[2K
| Adam | epoch: 015 | loss: 0.69024 - acc: 0.6064 | val_loss: 0.68791 - val_acc: 0.5227 -- iter: 139/139
--
Training Step: 76  | total loss: [1m[32m0.69001[0m[0m | time: 1.505s
[2K
| Adam | epoch: 016 | loss: 0.69001 - acc: 0.6017 -- iter: 032/139
[A[ATraining Step: 77  | total loss: [1m[32m0.68942[0m[0m | time: 1.867s
[2K
| Adam | epoch: 016 | loss: 0.68942 - acc: 0.5909 -- iter: 064/139
[A[ATraining Step: 78  | total loss: [1m[32m0.68988[0m[0m | time: 2.192s
[2K
| Adam | epoch: 016 | loss: 0.68988 - acc: 0.5671 -- iter: 096/139
[A[ATraining Step: 79  | total loss: [1m[32m0.68910[0m[0m | time: 3.613s
[2K
| Adam | epoch: 016 | loss: 0.68910 - acc: 0.5837 -- iter: 128/139
[A[ATraining Step: 80  | total loss: [1m[32m0.68892[0m[0m | time: 6.061s
[2K
| Adam | epoch: 016 | loss: 0.68892 - acc: 0.5847 | val_loss: 0.68984 - val_acc: 0.5227 -- iter: 139/139
--
Training Step: 81  | total loss: [1m[32m0.68840[0m[0m | time: 1.057s
[2K
| Adam | epoch: 017 | loss: 0.68840 - acc: 0.5825 -- iter: 032/139
[A[ATraining Step: 82  | total loss: [1m[32m0.68784[0m[0m | time: 2.206s
[2K
| Adam | epoch: 017 | loss: 0.68784 - acc: 0.5836 -- iter: 064/139
[A[ATraining Step: 83  | total loss: [1m[32m0.68792[0m[0m | time: 2.649s
[2K
| Adam | epoch: 017 | loss: 0.68792 - acc: 0.5815 -- iter: 096/139
[A[ATraining Step: 84  | total loss: [1m[32m0.68464[0m[0m | time: 3.062s
[2K
| Adam | epoch: 017 | loss: 0.68464 - acc: 0.6052 -- iter: 128/139
[A[ATraining Step: 85  | total loss: [1m[32m0.68062[0m[0m | time: 5.511s
[2K
| Adam | epoch: 017 | loss: 0.68062 - acc: 0.6356 | val_loss: 0.68044 - val_acc: 0.5455 -- iter: 139/139
--
Training Step: 86  | total loss: [1m[32m0.68050[0m[0m | time: 1.465s
[2K
| Adam | epoch: 018 | loss: 0.68050 - acc: 0.6251 -- iter: 032/139
[A[ATraining Step: 87  | total loss: [1m[32m0.67744[0m[0m | time: 2.832s
[2K
| Adam | epoch: 018 | loss: 0.67744 - acc: 0.6407 -- iter: 064/139
[A[ATraining Step: 88  | total loss: [1m[32m0.67311[0m[0m | time: 3.897s
[2K
| Adam | epoch: 018 | loss: 0.67311 - acc: 0.6517 -- iter: 096/139
[A[ATraining Step: 89  | total loss: [1m[32m0.67683[0m[0m | time: 4.213s
[2K
| Adam | epoch: 018 | loss: 0.67683 - acc: 0.6334 -- iter: 128/139
[A[ATraining Step: 90  | total loss: [1m[32m0.67417[0m[0m | time: 13.247s
[2K
| Adam | epoch: 018 | loss: 0.67417 - acc: 0.6337 | val_loss: 0.70813 - val_acc: 0.5000 -- iter: 139/139
--
Training Step: 91  | total loss: [1m[32m0.66359[0m[0m | time: 1.148s
[2K
| Adam | epoch: 019 | loss: 0.66359 - acc: 0.6430 -- iter: 032/139
[A[ATraining Step: 92  | total loss: [1m[32m0.67512[0m[0m | time: 2.303s
[2K
| Adam | epoch: 019 | loss: 0.67512 - acc: 0.6131 -- iter: 064/139
[A[ATraining Step: 93  | total loss: [1m[32m0.67531[0m[0m | time: 3.636s
[2K
| Adam | epoch: 019 | loss: 0.67531 - acc: 0.6049 -- iter: 096/139
[A[ATraining Step: 94  | total loss: [1m[32m0.67578[0m[0m | time: 5.013s
[2K
| Adam | epoch: 019 | loss: 0.67578 - acc: 0.5913 -- iter: 128/139
[A[ATraining Step: 95  | total loss: [1m[32m0.67226[0m[0m | time: 6.474s
[2K
| Adam | epoch: 019 | loss: 0.67226 - acc: 0.5978 | val_loss: 0.65104 - val_acc: 0.6136 -- iter: 139/139
--
Training Step: 96  | total loss: [1m[32m0.66420[0m[0m | time: 0.251s
[2K
| Adam | epoch: 020 | loss: 0.66420 - acc: 0.6107 -- iter: 032/139
[A[ATraining Step: 97  | total loss: [1m[32m0.65618[0m[0m | time: 0.937s
[2K
| Adam | epoch: 020 | loss: 0.65618 - acc: 0.6315 -- iter: 064/139
[A[ATraining Step: 98  | total loss: [1m[32m0.65285[0m[0m | time: 1.607s
[2K
| Adam | epoch: 020 | loss: 0.65285 - acc: 0.6402 -- iter: 096/139
[A[ATraining Step: 99  | total loss: [1m[32m0.64742[0m[0m | time: 2.273s
[2K
| Adam | epoch: 020 | loss: 0.64742 - acc: 0.6449 -- iter: 128/139
[A[ATraining Step: 100  | total loss: [1m[32m0.63916[0m[0m | time: 3.958s
[2K
| Adam | epoch: 020 | loss: 0.63916 - acc: 0.6492 | val_loss: 0.63053 - val_acc: 0.6136 -- iter: 139/139
--
Training Step: 101  | total loss: [1m[32m0.63623[0m[0m | time: 0.277s
[2K
| Adam | epoch: 021 | loss: 0.63623 - acc: 0.6562 -- iter: 032/139
[A[ATraining Step: 102  | total loss: [1m[32m0.61964[0m[0m | time: 0.539s
[2K
| Adam | epoch: 021 | loss: 0.61964 - acc: 0.6724 -- iter: 064/139
[A[ATraining Step: 103  | total loss: [1m[32m0.60140[0m[0m | time: 1.203s
[2K
| Adam | epoch: 021 | loss: 0.60140 - acc: 0.6869 -- iter: 096/139
[A[ATraining Step: 104  | total loss: [1m[32m0.59068[0m[0m | time: 1.884s
[2K
| Adam | epoch: 021 | loss: 0.59068 - acc: 0.6964 -- iter: 128/139
[A[ATraining Step: 105  | total loss: [1m[32m0.58775[0m[0m | time: 3.577s
[2K
| Adam | epoch: 021 | loss: 0.58775 - acc: 0.6955 | val_loss: 0.76788 - val_acc: 0.5227 -- iter: 139/139
--
Training Step: 106  | total loss: [1m[32m0.57725[0m[0m | time: 0.668s
[2K
| Adam | epoch: 022 | loss: 0.57725 - acc: 0.7041 -- iter: 032/139
[A[ATraining Step: 107  | total loss: [1m[32m0.56667[0m[0m | time: 0.932s
[2K
| Adam | epoch: 022 | loss: 0.56667 - acc: 0.7055 -- iter: 064/139
[A[ATraining Step: 108  | total loss: [1m[32m0.60005[0m[0m | time: 1.197s
[2K
| Adam | epoch: 022 | loss: 0.60005 - acc: 0.6895 -- iter: 096/139
[A[ATraining Step: 109  | total loss: [1m[32m0.59411[0m[0m | time: 1.857s
[2K
| Adam | epoch: 022 | loss: 0.59411 - acc: 0.6933 -- iter: 128/139
[A[ATraining Step: 110  | total loss: [1m[32m0.59980[0m[0m | time: 3.519s
[2K
| Adam | epoch: 022 | loss: 0.59980 - acc: 0.6927 | val_loss: 0.90214 - val_acc: 0.5682 -- iter: 139/139
--
Training Step: 111  | total loss: [1m[32m0.62499[0m[0m | time: 0.677s
[2K
| Adam | epoch: 023 | loss: 0.62499 - acc: 0.6734 -- iter: 032/139
[A[ATraining Step: 112  | total loss: [1m[32m0.65168[0m[0m | time: 1.356s
[2K
| Adam | epoch: 023 | loss: 0.65168 - acc: 0.6592 -- iter: 064/139
[A[ATraining Step: 113  | total loss: [1m[32m0.65672[0m[0m | time: 1.599s
[2K
| Adam | epoch: 023 | loss: 0.65672 - acc: 0.6652 -- iter: 096/139
[A[ATraining Step: 114  | total loss: [1m[32m0.63442[0m[0m | time: 1.858s
[2K
| Adam | epoch: 023 | loss: 0.63442 - acc: 0.6896 -- iter: 128/139
[A[ATraining Step: 115  | total loss: [1m[32m0.61841[0m[0m | time: 3.677s
[2K
| Adam | epoch: 023 | loss: 0.61841 - acc: 0.7024 | val_loss: 0.66267 - val_acc: 0.5909 -- iter: 139/139
--
Training Step: 116  | total loss: [1m[32m0.60459[0m[0m | time: 1.458s
[2K
| Adam | epoch: 024 | loss: 0.60459 - acc: 0.7041 -- iter: 032/139
[A[ATraining Step: 117  | total loss: [1m[32m0.59612[0m[0m | time: 2.889s
[2K
| Adam | epoch: 024 | loss: 0.59612 - acc: 0.7055 -- iter: 064/139
[A[ATraining Step: 118  | total loss: [1m[32m0.58780[0m[0m | time: 4.258s
[2K
| Adam | epoch: 024 | loss: 0.58780 - acc: 0.7069 -- iter: 096/139
[A[ATraining Step: 119  | total loss: [1m[32m0.58301[0m[0m | time: 4.720s
[2K
| Adam | epoch: 024 | loss: 0.58301 - acc: 0.7143 -- iter: 128/139
[A[ATraining Step: 120  | total loss: [1m[32m0.57548[0m[0m | time: 6.075s
[2K
| Adam | epoch: 024 | loss: 0.57548 - acc: 0.7247 | val_loss: 0.60009 - val_acc: 0.6818 -- iter: 139/139
--
Training Step: 121  | total loss: [1m[32m0.56835[0m[0m | time: 1.398s
[2K
| Adam | epoch: 025 | loss: 0.56835 - acc: 0.7249 -- iter: 032/139
[A[ATraining Step: 122  | total loss: [1m[32m0.55547[0m[0m | time: 2.457s
[2K
| Adam | epoch: 025 | loss: 0.55547 - acc: 0.7368 -- iter: 064/139
[A[ATraining Step: 123  | total loss: [1m[32m0.54289[0m[0m | time: 3.814s
[2K
| Adam | epoch: 025 | loss: 0.54289 - acc: 0.7506 -- iter: 096/139
[A[ATraining Step: 124  | total loss: [1m[32m0.53360[0m[0m | time: 5.297s
[2K
| Adam | epoch: 025 | loss: 0.53360 - acc: 0.7631 -- iter: 128/139
[A[ATraining Step: 125  | total loss: [1m[32m0.52037[0m[0m | time: 6.832s
[2K
| Adam | epoch: 025 | loss: 0.52037 - acc: 0.7743 | val_loss: 0.56810 - val_acc: 0.6591 -- iter: 139/139
--
Training Step: 126  | total loss: [1m[32m0.52650[0m[0m | time: 0.430s
[2K
| Adam | epoch: 026 | loss: 0.52650 - acc: 0.7787 -- iter: 032/139
[A[ATraining Step: 127  | total loss: [1m[32m0.52842[0m[0m | time: 1.588s
[2K
| Adam | epoch: 026 | loss: 0.52842 - acc: 0.7826 -- iter: 064/139
[A[ATraining Step: 128  | total loss: [1m[32m0.51013[0m[0m | time: 2.820s
[2K
| Adam | epoch: 026 | loss: 0.51013 - acc: 0.7919 -- iter: 096/139
[A[ATraining Step: 129  | total loss: [1m[32m0.49177[0m[0m | time: 4.006s
[2K
| Adam | epoch: 026 | loss: 0.49177 - acc: 0.8033 -- iter: 128/139
[A[ATraining Step: 130  | total loss: [1m[32m0.49257[0m[0m | time: 6.418s
[2K
| Adam | epoch: 026 | loss: 0.49257 - acc: 0.8011 | val_loss: 0.51763 - val_acc: 0.7500 -- iter: 139/139
--
Training Step: 131  | total loss: [1m[32m0.47013[0m[0m | time: 0.516s
[2K
| Adam | epoch: 027 | loss: 0.47013 - acc: 0.8147 -- iter: 032/139
[A[ATraining Step: 132  | total loss: [1m[32m0.44007[0m[0m | time: 0.989s
[2K
| Adam | epoch: 027 | loss: 0.44007 - acc: 0.8242 -- iter: 064/139
[A[ATraining Step: 133  | total loss: [1m[32m0.40611[0m[0m | time: 11.752s
[2K
| Adam | epoch: 027 | loss: 0.40611 - acc: 0.8417 -- iter: 096/139
[A[ATraining Step: 134  | total loss: [1m[32m0.44129[0m[0m | time: 12.715s
[2K
| Adam | epoch: 027 | loss: 0.44129 - acc: 0.8169 -- iter: 128/139
[A[ATraining Step: 135  | total loss: [1m[32m0.49887[0m[0m | time: 14.943s
[2K
| Adam | epoch: 027 | loss: 0.49887 - acc: 0.7915 | val_loss: 0.49434 - val_acc: 0.7727 -- iter: 139/139
--
Training Step: 136  | total loss: [1m[32m0.50270[0m[0m | time: 0.969s
[2K
| Adam | epoch: 028 | loss: 0.50270 - acc: 0.7842 -- iter: 032/139
[A[ATraining Step: 137  | total loss: [1m[32m0.47461[0m[0m | time: 1.504s
[2K
| Adam | epoch: 028 | loss: 0.47461 - acc: 0.7996 -- iter: 064/139
[A[ATraining Step: 138  | total loss: [1m[32m0.45172[0m[0m | time: 1.939s
[2K
| Adam | epoch: 028 | loss: 0.45172 - acc: 0.8196 -- iter: 096/139
[A[ATraining Step: 139  | total loss: [1m[32m0.44580[0m[0m | time: 2.984s
[2K
| Adam | epoch: 028 | loss: 0.44580 - acc: 0.8013 -- iter: 128/139
[A[ATraining Step: 140  | total loss: [1m[32m0.48222[0m[0m | time: 4.895s
[2K
| Adam | epoch: 028 | loss: 0.48222 - acc: 0.7805 | val_loss: 0.55336 - val_acc: 0.7045 -- iter: 139/139
--
Training Step: 141  | total loss: [1m[32m0.47173[0m[0m | time: 0.661s
[2K
| Adam | epoch: 029 | loss: 0.47173 - acc: 0.7775 -- iter: 032/139
[A[ATraining Step: 142  | total loss: [1m[32m0.45274[0m[0m | time: 1.325s
[2K
| Adam | epoch: 029 | loss: 0.45274 - acc: 0.7903 -- iter: 064/139
[A[ATraining Step: 143  | total loss: [1m[32m0.42513[0m[0m | time: 1.577s
[2K
| Adam | epoch: 029 | loss: 0.42513 - acc: 0.8082 -- iter: 096/139
[A[ATraining Step: 144  | total loss: [1m[32m0.40238[0m[0m | time: 1.824s
[2K
| Adam | epoch: 029 | loss: 0.40238 - acc: 0.8274 -- iter: 128/139
[A[ATraining Step: 145  | total loss: [1m[32m0.38438[0m[0m | time: 3.461s
[2K
| Adam | epoch: 029 | loss: 0.38438 - acc: 0.8355 | val_loss: 0.61158 - val_acc: 0.7727 -- iter: 139/139
--
Training Step: 146  | total loss: [1m[32m0.36648[0m[0m | time: 0.671s
[2K
| Adam | epoch: 030 | loss: 0.36648 - acc: 0.8426 -- iter: 032/139
[A[ATraining Step: 147  | total loss: [1m[32m0.36399[0m[0m | time: 1.351s
[2K
| Adam | epoch: 030 | loss: 0.36399 - acc: 0.8334 -- iter: 064/139
[A[ATraining Step: 148  | total loss: [1m[32m0.34747[0m[0m | time: 2.013s
[2K
| Adam | epoch: 030 | loss: 0.34747 - acc: 0.8469 -- iter: 096/139
[A[ATraining Step: 149  | total loss: [1m[32m0.33859[0m[0m | time: 2.271s
[2K
| Adam | epoch: 030 | loss: 0.33859 - acc: 0.8528 -- iter: 128/139
[A[ATraining Step: 150  | total loss: [1m[32m0.31679[0m[0m | time: 3.524s
[2K
| Adam | epoch: 030 | loss: 0.31679 - acc: 0.8675 | val_loss: 0.61788 - val_acc: 0.6818 -- iter: 139/139
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8571428571428572
Validation AUPRC:0.8310957857979506
Test AUC:0.6645833333333334
Test AUPRC:0.6455508609108386
BestTestF1Score	0.6	0.27	0.64	0.6	0.6	12	8	16	8	0.09
BestTestMCCScore	0.6	0.27	0.64	0.6	0.6	12	8	16	8	0.09
BestTestAccuracyScore	0.6	0.27	0.64	0.6	0.6	12	8	16	8	0.09
BestValidationF1Score	0.83	0.65	0.82	0.76	0.9	19	6	17	2	0.09
BestValidationMCC	0.83	0.65	0.82	0.76	0.9	19	6	17	2	0.09
BestValidationAccuracy	0.83	0.65	0.82	0.76	0.9	19	6	17	2	0.09
TestPredictions (Threshold:0.09)
CHEMBL356769,TP,ACT,0.09000000357627869	CHEMBL1173445,FN,ACT,0.03999999910593033	CHEMBL3110021,TP,ACT,0.9599999785423279	CHEMBL561209,FP,INACT,0.5299999713897705	CHEMBL3353053,TN,INACT,0.019999999552965164	CHEMBL3335300,TN,INACT,0.03999999910593033	CHEMBL1631912,FN,ACT,0.05999999865889549	CHEMBL2177582,TN,INACT,0.009999999776482582	CHEMBL512179,FP,INACT,0.49000000953674316	CHEMBL1914702,FN,ACT,0.07000000029802322	CHEMBL483254,FN,ACT,0.019999999552965164	CHEMBL1830396,TP,ACT,0.9900000095367432	CHEMBL3799265,TN,INACT,0.029999999329447746	CHEMBL3309299,TP,ACT,0.8700000047683716	CHEMBL1767043,FN,ACT,0.05000000074505806	CHEMBL2417786,TN,INACT,0.029999999329447746	CHEMBL2408778,TN,INACT,0.05000000074505806	CHEMBL1631915,TP,ACT,0.47999998927116394	CHEMBL513589,TN,INACT,0.05000000074505806	CHEMBL141885,FP,INACT,0.3100000023841858	CHEMBL609583,FN,ACT,0.03999999910593033	CHEMBL1213490,FN,ACT,0.03999999910593033	CHEMBL3309291,TP,ACT,0.9100000262260437	CHEMBL3355256,TN,INACT,0.05000000074505806	CHEMBL518821,TP,ACT,0.7900000214576721	CHEMBL256655,TN,INACT,0.05999999865889549	CHEMBL2323286,TN,INACT,0.029999999329447746	CHEMBL55895,TN,INACT,0.05000000074505806	CHEMBL3758457,TP,ACT,0.17000000178813934	CHEMBL3798925,FP,INACT,0.6100000143051147	CHEMBL1096986,FP,INACT,0.9399999976158142	CHEMBL1934897,FP,INACT,0.6000000238418579	CHEMBL3670669,TP,ACT,0.11999999731779099	CHEMBL1934903,TN,INACT,0.029999999329447746	CHEMBL3770566,FP,INACT,0.4000000059604645	CHEMBL439842,TN,INACT,0.05000000074505806	CHEMBL356066,TP,ACT,0.20000000298023224	CHEMBL1631911,FN,ACT,0.05999999865889549	CHEMBL3235790,TN,INACT,0.03999999910593033	CHEMBL472346,TN,INACT,0.03999999910593033	CHEMBL471042,TP,ACT,0.27000001072883606	CHEMBL186311,FP,INACT,0.8399999737739563	CHEMBL1631917,TP,ACT,0.9300000071525574	CHEMBL3770119,TN,INACT,0.029999999329447746	

