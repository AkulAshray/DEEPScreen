ImageNetInceptionV2 CHEMBL4501 adam 0.0005 5 0 0 0.8 False True
Number of active compounds :	693
Number of inactive compounds :	693
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4501_adam_0.0005_5_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4501_adam_0.0005_5_0.8/
---------------------------------
Training samples: 870
Validation samples: 273
--
Training Step: 1  | time: 35.800s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/870
[A[ATraining Step: 2  | total loss: [1m[32m0.64492[0m[0m | time: 43.963s
[2K
| Adam | epoch: 001 | loss: 0.64492 - acc: 0.3937 -- iter: 064/870
[A[ATraining Step: 3  | total loss: [1m[32m0.62234[0m[0m | time: 52.378s
[2K
| Adam | epoch: 001 | loss: 0.62234 - acc: 0.5318 -- iter: 096/870
[A[ATraining Step: 4  | total loss: [1m[32m0.86465[0m[0m | time: 60.793s
[2K
| Adam | epoch: 001 | loss: 0.86465 - acc: 0.6017 -- iter: 128/870
[A[ATraining Step: 5  | total loss: [1m[32m0.67362[0m[0m | time: 69.133s
[2K
| Adam | epoch: 001 | loss: 0.67362 - acc: 0.6395 -- iter: 160/870
[A[ATraining Step: 6  | total loss: [1m[32m0.75934[0m[0m | time: 78.125s
[2K
| Adam | epoch: 001 | loss: 0.75934 - acc: 0.5498 -- iter: 192/870
[A[ATraining Step: 7  | total loss: [1m[32m0.73035[0m[0m | time: 86.694s
[2K
| Adam | epoch: 001 | loss: 0.73035 - acc: 0.5574 -- iter: 224/870
[A[ATraining Step: 8  | total loss: [1m[32m0.67439[0m[0m | time: 95.135s
[2K
| Adam | epoch: 001 | loss: 0.67439 - acc: 0.5779 -- iter: 256/870
[A[ATraining Step: 9  | total loss: [1m[32m0.65181[0m[0m | time: 103.641s
[2K
| Adam | epoch: 001 | loss: 0.65181 - acc: 0.6524 -- iter: 288/870
[A[ATraining Step: 10  | total loss: [1m[32m0.75356[0m[0m | time: 112.094s
[2K
| Adam | epoch: 001 | loss: 0.75356 - acc: 0.6075 -- iter: 320/870
[A[ATraining Step: 11  | total loss: [1m[32m0.69796[0m[0m | time: 120.312s
[2K
| Adam | epoch: 001 | loss: 0.69796 - acc: 0.6454 -- iter: 352/870
[A[ATraining Step: 12  | total loss: [1m[32m0.68790[0m[0m | time: 129.707s
[2K
| Adam | epoch: 001 | loss: 0.68790 - acc: 0.6362 -- iter: 384/870
[A[ATraining Step: 13  | total loss: [1m[32m0.64229[0m[0m | time: 138.623s
[2K
| Adam | epoch: 001 | loss: 0.64229 - acc: 0.6984 -- iter: 416/870
[A[ATraining Step: 14  | total loss: [1m[32m0.60032[0m[0m | time: 147.411s
[2K
| Adam | epoch: 001 | loss: 0.60032 - acc: 0.7195 -- iter: 448/870
[A[ATraining Step: 15  | total loss: [1m[32m0.67923[0m[0m | time: 155.751s
[2K
| Adam | epoch: 001 | loss: 0.67923 - acc: 0.6581 -- iter: 480/870
[A[ATraining Step: 16  | total loss: [1m[32m0.61115[0m[0m | time: 164.002s
[2K
| Adam | epoch: 001 | loss: 0.61115 - acc: 0.7160 -- iter: 512/870
[A[ATraining Step: 17  | total loss: [1m[32m0.60059[0m[0m | time: 172.570s
[2K
| Adam | epoch: 001 | loss: 0.60059 - acc: 0.7170 -- iter: 544/870
[A[ATraining Step: 18  | total loss: [1m[32m0.62508[0m[0m | time: 180.902s
[2K
| Adam | epoch: 001 | loss: 0.62508 - acc: 0.6960 -- iter: 576/870
[A[ATraining Step: 19  | total loss: [1m[32m0.61304[0m[0m | time: 189.170s
[2K
| Adam | epoch: 001 | loss: 0.61304 - acc: 0.7140 -- iter: 608/870
[A[ATraining Step: 20  | total loss: [1m[32m0.57409[0m[0m | time: 197.393s
[2K
| Adam | epoch: 001 | loss: 0.57409 - acc: 0.7155 -- iter: 640/870
[A[ATraining Step: 21  | total loss: [1m[32m0.54243[0m[0m | time: 205.796s
[2K
| Adam | epoch: 001 | loss: 0.54243 - acc: 0.7165 -- iter: 672/870
[A[ATraining Step: 22  | total loss: [1m[32m0.56226[0m[0m | time: 214.550s
[2K
| Adam | epoch: 001 | loss: 0.56226 - acc: 0.7172 -- iter: 704/870
[A[ATraining Step: 23  | total loss: [1m[32m0.59027[0m[0m | time: 223.746s
[2K
| Adam | epoch: 001 | loss: 0.59027 - acc: 0.7176 -- iter: 736/870
[A[ATraining Step: 24  | total loss: [1m[32m0.55983[0m[0m | time: 232.151s
[2K
| Adam | epoch: 001 | loss: 0.55983 - acc: 0.7267 -- iter: 768/870
[A[ATraining Step: 25  | total loss: [1m[32m0.56736[0m[0m | time: 240.694s
[2K
| Adam | epoch: 001 | loss: 0.56736 - acc: 0.7246 -- iter: 800/870
[A[ATraining Step: 26  | total loss: [1m[32m0.54886[0m[0m | time: 249.358s
[2K
| Adam | epoch: 001 | loss: 0.54886 - acc: 0.7478 -- iter: 832/870
[A[ATraining Step: 27  | total loss: [1m[32m0.51748[0m[0m | time: 257.701s
[2K
| Adam | epoch: 001 | loss: 0.51748 - acc: 0.7725 -- iter: 864/870
[A[ATraining Step: 28  | total loss: [1m[32m0.46152[0m[0m | time: 277.955s
[2K
| Adam | epoch: 001 | loss: 0.46152 - acc: 0.7981 | val_loss: 0.94636 - val_acc: 0.5128 -- iter: 870/870
--
Training Step: 29  | total loss: [1m[32m0.57280[0m[0m | time: 2.209s
[2K
| Adam | epoch: 002 | loss: 0.57280 - acc: 0.8067 -- iter: 032/870
[A[ATraining Step: 30  | total loss: [1m[32m0.53120[0m[0m | time: 11.344s
[2K
| Adam | epoch: 002 | loss: 0.53120 - acc: 0.8130 -- iter: 064/870
[A[ATraining Step: 31  | total loss: [1m[32m0.54622[0m[0m | time: 19.818s
[2K
| Adam | epoch: 002 | loss: 0.54622 - acc: 0.7985 -- iter: 096/870
[A[ATraining Step: 32  | total loss: [1m[32m0.52308[0m[0m | time: 28.218s
[2K
| Adam | epoch: 002 | loss: 0.52308 - acc: 0.7946 -- iter: 128/870
[A[ATraining Step: 33  | total loss: [1m[32m0.49628[0m[0m | time: 37.958s
[2K
| Adam | epoch: 002 | loss: 0.49628 - acc: 0.8191 -- iter: 160/870
[A[ATraining Step: 34  | total loss: [1m[32m0.49458[0m[0m | time: 46.363s
[2K
| Adam | epoch: 002 | loss: 0.49458 - acc: 0.7842 -- iter: 192/870
[A[ATraining Step: 35  | total loss: [1m[32m0.46547[0m[0m | time: 54.701s
[2K
| Adam | epoch: 002 | loss: 0.46547 - acc: 0.8032 -- iter: 224/870
[A[ATraining Step: 36  | total loss: [1m[32m0.44770[0m[0m | time: 63.102s
[2K
| Adam | epoch: 002 | loss: 0.44770 - acc: 0.8179 -- iter: 256/870
[A[ATraining Step: 37  | total loss: [1m[32m0.46421[0m[0m | time: 71.600s
[2K
| Adam | epoch: 002 | loss: 0.46421 - acc: 0.8293 -- iter: 288/870
[A[ATraining Step: 38  | total loss: [1m[32m0.47324[0m[0m | time: 80.672s
[2K
| Adam | epoch: 002 | loss: 0.47324 - acc: 0.8138 -- iter: 320/870
[A[ATraining Step: 39  | total loss: [1m[32m0.46436[0m[0m | time: 91.103s
[2K
| Adam | epoch: 002 | loss: 0.46436 - acc: 0.8016 -- iter: 352/870
[A[ATraining Step: 40  | total loss: [1m[32m0.43881[0m[0m | time: 99.452s
[2K
| Adam | epoch: 002 | loss: 0.43881 - acc: 0.7978 -- iter: 384/870
[A[ATraining Step: 41  | total loss: [1m[32m0.47246[0m[0m | time: 107.828s
[2K
| Adam | epoch: 002 | loss: 0.47246 - acc: 0.7775 -- iter: 416/870
[A[ATraining Step: 42  | total loss: [1m[32m0.42382[0m[0m | time: 116.234s
[2K
| Adam | epoch: 002 | loss: 0.42382 - acc: 0.8063 -- iter: 448/870
[A[ATraining Step: 43  | total loss: [1m[32m0.40660[0m[0m | time: 124.423s
[2K
| Adam | epoch: 002 | loss: 0.40660 - acc: 0.8129 -- iter: 480/870
[A[ATraining Step: 44  | total loss: [1m[32m0.40276[0m[0m | time: 134.272s
[2K
| Adam | epoch: 002 | loss: 0.40276 - acc: 0.8074 -- iter: 512/870
[A[ATraining Step: 45  | total loss: [1m[32m0.39813[0m[0m | time: 142.907s
[2K
| Adam | epoch: 002 | loss: 0.39813 - acc: 0.8189 -- iter: 544/870
[A[ATraining Step: 46  | total loss: [1m[32m0.38627[0m[0m | time: 151.117s
[2K
| Adam | epoch: 002 | loss: 0.38627 - acc: 0.8283 -- iter: 576/870
[A[ATraining Step: 47  | total loss: [1m[32m0.39878[0m[0m | time: 159.405s
[2K
| Adam | epoch: 002 | loss: 0.39878 - acc: 0.8308 -- iter: 608/870
[A[ATraining Step: 48  | total loss: [1m[32m0.44880[0m[0m | time: 167.756s
[2K
| Adam | epoch: 002 | loss: 0.44880 - acc: 0.8078 -- iter: 640/870
[A[ATraining Step: 49  | total loss: [1m[32m0.44852[0m[0m | time: 177.543s
[2K
| Adam | epoch: 002 | loss: 0.44852 - acc: 0.8085 -- iter: 672/870
[A[ATraining Step: 50  | total loss: [1m[32m0.43197[0m[0m | time: 185.972s
[2K
| Adam | epoch: 002 | loss: 0.43197 - acc: 0.8140 -- iter: 704/870
[A[ATraining Step: 51  | total loss: [1m[32m0.41361[0m[0m | time: 194.376s
[2K
| Adam | epoch: 002 | loss: 0.41361 - acc: 0.8281 -- iter: 736/870
[A[ATraining Step: 52  | total loss: [1m[32m0.41499[0m[0m | time: 202.702s
[2K
| Adam | epoch: 002 | loss: 0.41499 - acc: 0.8304 -- iter: 768/870
[A[ATraining Step: 53  | total loss: [1m[32m0.40403[0m[0m | time: 211.807s
[2K
| Adam | epoch: 002 | loss: 0.40403 - acc: 0.8370 -- iter: 800/870
[A[ATraining Step: 54  | total loss: [1m[32m0.39705[0m[0m | time: 220.456s
[2K
| Adam | epoch: 002 | loss: 0.39705 - acc: 0.8380 -- iter: 832/870
[A[ATraining Step: 55  | total loss: [1m[32m0.37559[0m[0m | time: 228.668s
[2K
| Adam | epoch: 002 | loss: 0.37559 - acc: 0.8567 -- iter: 864/870
[A[ATraining Step: 56  | total loss: [1m[32m0.36539[0m[0m | time: 249.365s
[2K
| Adam | epoch: 002 | loss: 0.36539 - acc: 0.8636 | val_loss: 0.41213 - val_acc: 0.8022 -- iter: 870/870
--
Training Step: 57  | total loss: [1m[32m0.33903[0m[0m | time: 2.327s
[2K
| Adam | epoch: 003 | loss: 0.33903 - acc: 0.8739 -- iter: 032/870
[A[ATraining Step: 58  | total loss: [1m[32m0.37558[0m[0m | time: 4.521s
[2K
| Adam | epoch: 003 | loss: 0.37558 - acc: 0.8683 -- iter: 064/870
[A[ATraining Step: 59  | total loss: [1m[32m0.35939[0m[0m | time: 14.405s
[2K
| Adam | epoch: 003 | loss: 0.35939 - acc: 0.8636 -- iter: 096/870
[A[ATraining Step: 60  | total loss: [1m[32m0.33196[0m[0m | time: 23.526s
[2K
| Adam | epoch: 003 | loss: 0.33196 - acc: 0.8734 -- iter: 128/870
[A[ATraining Step: 61  | total loss: [1m[32m0.31464[0m[0m | time: 33.172s
[2K
| Adam | epoch: 003 | loss: 0.31464 - acc: 0.8818 -- iter: 160/870
[A[ATraining Step: 62  | total loss: [1m[32m0.30371[0m[0m | time: 41.457s
[2K
| Adam | epoch: 003 | loss: 0.30371 - acc: 0.8809 -- iter: 192/870
[A[ATraining Step: 63  | total loss: [1m[32m0.29599[0m[0m | time: 49.575s
[2K
| Adam | epoch: 003 | loss: 0.29599 - acc: 0.8841 -- iter: 224/870
[A[ATraining Step: 64  | total loss: [1m[32m0.31943[0m[0m | time: 58.178s
[2K
| Adam | epoch: 003 | loss: 0.31943 - acc: 0.8791 -- iter: 256/870
[A[ATraining Step: 65  | total loss: [1m[32m0.32230[0m[0m | time: 73.321s
[2K
| Adam | epoch: 003 | loss: 0.32230 - acc: 0.8786 -- iter: 288/870
[A[ATraining Step: 66  | total loss: [1m[32m0.31418[0m[0m | time: 86.572s
[2K
| Adam | epoch: 003 | loss: 0.31418 - acc: 0.8781 -- iter: 320/870
[A[ATraining Step: 67  | total loss: [1m[32m0.31573[0m[0m | time: 96.302s
[2K
| Adam | epoch: 003 | loss: 0.31573 - acc: 0.8853 -- iter: 352/870
[A[ATraining Step: 68  | total loss: [1m[32m0.30394[0m[0m | time: 107.493s
[2K
| Adam | epoch: 003 | loss: 0.30394 - acc: 0.8877 -- iter: 384/870
[A[ATraining Step: 69  | total loss: [1m[32m0.35356[0m[0m | time: 115.943s
[2K
| Adam | epoch: 003 | loss: 0.35356 - acc: 0.8680 -- iter: 416/870
[A[ATraining Step: 70  | total loss: [1m[32m0.34121[0m[0m | time: 124.374s
[2K
| Adam | epoch: 003 | loss: 0.34121 - acc: 0.8760 -- iter: 448/870
[A[ATraining Step: 71  | total loss: [1m[32m0.33573[0m[0m | time: 132.619s
[2K
| Adam | epoch: 003 | loss: 0.33573 - acc: 0.8795 -- iter: 480/870
[A[ATraining Step: 72  | total loss: [1m[32m0.34883[0m[0m | time: 141.106s
[2K
| Adam | epoch: 003 | loss: 0.34883 - acc: 0.8684 -- iter: 512/870
[A[ATraining Step: 73  | total loss: [1m[32m0.34291[0m[0m | time: 149.344s
[2K
| Adam | epoch: 003 | loss: 0.34291 - acc: 0.8726 -- iter: 544/870
[A[ATraining Step: 74  | total loss: [1m[32m0.33848[0m[0m | time: 157.592s
[2K
| Adam | epoch: 003 | loss: 0.33848 - acc: 0.8729 -- iter: 576/870
[A[ATraining Step: 75  | total loss: [1m[32m0.32039[0m[0m | time: 166.670s
[2K
| Adam | epoch: 003 | loss: 0.32039 - acc: 0.8833 -- iter: 608/870
[A[ATraining Step: 76  | total loss: [1m[32m0.31414[0m[0m | time: 175.806s
[2K
| Adam | epoch: 003 | loss: 0.31414 - acc: 0.8824 -- iter: 640/870
[A[ATraining Step: 77  | total loss: [1m[32m0.32112[0m[0m | time: 186.246s
[2K
| Adam | epoch: 003 | loss: 0.32112 - acc: 0.8816 -- iter: 672/870
[A[ATraining Step: 78  | total loss: [1m[32m0.32159[0m[0m | time: 202.888s
[2K
| Adam | epoch: 003 | loss: 0.32159 - acc: 0.8875 -- iter: 704/870
[A[ATraining Step: 79  | total loss: [1m[32m0.32064[0m[0m | time: 217.483s
[2K
| Adam | epoch: 003 | loss: 0.32064 - acc: 0.8894 -- iter: 736/870
[A[ATraining Step: 80  | total loss: [1m[32m0.32025[0m[0m | time: 225.912s
[2K
| Adam | epoch: 003 | loss: 0.32025 - acc: 0.8911 -- iter: 768/870
[A[ATraining Step: 81  | total loss: [1m[32m0.31555[0m[0m | time: 234.319s
[2K
| Adam | epoch: 003 | loss: 0.31555 - acc: 0.8895 -- iter: 800/870
[A[ATraining Step: 82  | total loss: [1m[32m0.30811[0m[0m | time: 242.588s
[2K
| Adam | epoch: 003 | loss: 0.30811 - acc: 0.8912 -- iter: 832/870
[A[ATraining Step: 83  | total loss: [1m[32m0.31465[0m[0m | time: 250.818s
[2K
| Adam | epoch: 003 | loss: 0.31465 - acc: 0.8895 -- iter: 864/870
[A[ATraining Step: 84  | total loss: [1m[32m0.30676[0m[0m | time: 271.131s
[2K
| Adam | epoch: 003 | loss: 0.30676 - acc: 0.8943 | val_loss: 0.37924 - val_acc: 0.8498 -- iter: 870/870
--
Training Step: 85  | total loss: [1m[32m0.29376[0m[0m | time: 8.227s
[2K
| Adam | epoch: 004 | loss: 0.29376 - acc: 0.8987 -- iter: 032/870
[A[ATraining Step: 86  | total loss: [1m[32m0.27258[0m[0m | time: 10.436s
[2K
| Adam | epoch: 004 | loss: 0.27258 - acc: 0.9057 -- iter: 064/870
[A[ATraining Step: 87  | total loss: [1m[32m0.25213[0m[0m | time: 12.653s
[2K
| Adam | epoch: 004 | loss: 0.25213 - acc: 0.9151 -- iter: 096/870
[A[ATraining Step: 88  | total loss: [1m[32m0.23177[0m[0m | time: 23.640s
[2K
| Adam | epoch: 004 | loss: 0.23177 - acc: 0.9236 -- iter: 128/870
[A[ATraining Step: 89  | total loss: [1m[32m0.24861[0m[0m | time: 36.332s
[2K
| Adam | epoch: 004 | loss: 0.24861 - acc: 0.9125 -- iter: 160/870
[A[ATraining Step: 90  | total loss: [1m[32m0.23944[0m[0m | time: 46.586s
[2K
| Adam | epoch: 004 | loss: 0.23944 - acc: 0.9150 -- iter: 192/870
[A[ATraining Step: 91  | total loss: [1m[32m0.24309[0m[0m | time: 54.565s
[2K
| Adam | epoch: 004 | loss: 0.24309 - acc: 0.9141 -- iter: 224/870
[A[ATraining Step: 92  | total loss: [1m[32m0.23846[0m[0m | time: 62.712s
[2K
| Adam | epoch: 004 | loss: 0.23846 - acc: 0.9102 -- iter: 256/870
[A[ATraining Step: 93  | total loss: [1m[32m0.24163[0m[0m | time: 71.032s
[2K
| Adam | epoch: 004 | loss: 0.24163 - acc: 0.9067 -- iter: 288/870
[A[ATraining Step: 94  | total loss: [1m[32m0.26820[0m[0m | time: 79.124s
[2K
| Adam | epoch: 004 | loss: 0.26820 - acc: 0.8973 -- iter: 320/870
[A[ATraining Step: 95  | total loss: [1m[32m0.28873[0m[0m | time: 87.523s
[2K
| Adam | epoch: 004 | loss: 0.28873 - acc: 0.8888 -- iter: 352/870
[A[ATraining Step: 96  | total loss: [1m[32m0.27052[0m[0m | time: 95.693s
[2K
| Adam | epoch: 004 | loss: 0.27052 - acc: 0.8968 -- iter: 384/870
[A[ATraining Step: 97  | total loss: [1m[32m0.28200[0m[0m | time: 106.043s
[2K
| Adam | epoch: 004 | loss: 0.28200 - acc: 0.8946 -- iter: 416/870
[A[ATraining Step: 98  | total loss: [1m[32m0.28549[0m[0m | time: 115.247s
[2K
| Adam | epoch: 004 | loss: 0.28549 - acc: 0.8895 -- iter: 448/870
[A[ATraining Step: 99  | total loss: [1m[32m0.27437[0m[0m | time: 123.578s
[2K
| Adam | epoch: 004 | loss: 0.27437 - acc: 0.8943 -- iter: 480/870
[A[ATraining Step: 100  | total loss: [1m[32m0.26722[0m[0m | time: 131.937s
[2K
| Adam | epoch: 004 | loss: 0.26722 - acc: 0.8955 -- iter: 512/870
[A[ATraining Step: 101  | total loss: [1m[32m0.24781[0m[0m | time: 140.182s
[2K
| Adam | epoch: 004 | loss: 0.24781 - acc: 0.9028 -- iter: 544/870
[A[ATraining Step: 102  | total loss: [1m[32m0.23706[0m[0m | time: 148.949s
[2K
| Adam | epoch: 004 | loss: 0.23706 - acc: 0.9063 -- iter: 576/870
[A[ATraining Step: 103  | total loss: [1m[32m0.21782[0m[0m | time: 157.313s
[2K
| Adam | epoch: 004 | loss: 0.21782 - acc: 0.9157 -- iter: 608/870
[A[ATraining Step: 104  | total loss: [1m[32m0.22267[0m[0m | time: 165.783s
[2K
| Adam | epoch: 004 | loss: 0.22267 - acc: 0.9179 -- iter: 640/870
[A[ATraining Step: 105  | total loss: [1m[32m0.22145[0m[0m | time: 174.738s
[2K
| Adam | epoch: 004 | loss: 0.22145 - acc: 0.9167 -- iter: 672/870
[A[ATraining Step: 106  | total loss: [1m[32m0.20441[0m[0m | time: 183.024s
[2K
| Adam | epoch: 004 | loss: 0.20441 - acc: 0.9250 -- iter: 704/870
[A[ATraining Step: 107  | total loss: [1m[32m0.19837[0m[0m | time: 191.974s
[2K
| Adam | epoch: 004 | loss: 0.19837 - acc: 0.9231 -- iter: 736/870
[A[ATraining Step: 108  | total loss: [1m[32m0.19727[0m[0m | time: 200.217s
[2K
| Adam | epoch: 004 | loss: 0.19727 - acc: 0.9246 -- iter: 768/870
[A[ATraining Step: 109  | total loss: [1m[32m0.19614[0m[0m | time: 208.771s
[2K
| Adam | epoch: 004 | loss: 0.19614 - acc: 0.9196 -- iter: 800/870
[A[ATraining Step: 110  | total loss: [1m[32m0.20416[0m[0m | time: 217.205s
[2K
| Adam | epoch: 004 | loss: 0.20416 - acc: 0.9183 -- iter: 832/870
[A[ATraining Step: 111  | total loss: [1m[32m0.19824[0m[0m | time: 229.163s
[2K
| Adam | epoch: 004 | loss: 0.19824 - acc: 0.9202 -- iter: 864/870
[A[ATraining Step: 112  | total loss: [1m[32m0.19332[0m[0m | time: 251.671s
[2K
| Adam | epoch: 004 | loss: 0.19332 - acc: 0.9251 | val_loss: 3.68826 - val_acc: 0.5128 -- iter: 870/870
--
Training Step: 113  | total loss: [1m[32m0.18818[0m[0m | time: 8.266s
[2K
| Adam | epoch: 005 | loss: 0.18818 - acc: 0.9263 -- iter: 032/870
[A[ATraining Step: 114  | total loss: [1m[32m0.21000[0m[0m | time: 17.887s
[2K
| Adam | epoch: 005 | loss: 0.21000 - acc: 0.9181 -- iter: 064/870
[A[ATraining Step: 115  | total loss: [1m[32m0.19866[0m[0m | time: 20.144s
[2K
| Adam | epoch: 005 | loss: 0.19866 - acc: 0.9231 -- iter: 096/870
[A[ATraining Step: 116  | total loss: [1m[32m0.19450[0m[0m | time: 22.317s
[2K
| Adam | epoch: 005 | loss: 0.19450 - acc: 0.9141 -- iter: 128/870
[A[ATraining Step: 117  | total loss: [1m[32m0.18064[0m[0m | time: 31.272s
[2K
| Adam | epoch: 005 | loss: 0.18064 - acc: 0.9227 -- iter: 160/870
[A[ATraining Step: 118  | total loss: [1m[32m0.17666[0m[0m | time: 39.935s
[2K
| Adam | epoch: 005 | loss: 0.17666 - acc: 0.9273 -- iter: 192/870
[A[ATraining Step: 119  | total loss: [1m[32m0.16778[0m[0m | time: 48.715s
[2K
| Adam | epoch: 005 | loss: 0.16778 - acc: 0.9315 -- iter: 224/870
[A[ATraining Step: 120  | total loss: [1m[32m0.15855[0m[0m | time: 62.573s
[2K
| Adam | epoch: 005 | loss: 0.15855 - acc: 0.9352 -- iter: 256/870
[A[ATraining Step: 121  | total loss: [1m[32m0.17088[0m[0m | time: 70.686s
[2K
| Adam | epoch: 005 | loss: 0.17088 - acc: 0.9323 -- iter: 288/870
[A[ATraining Step: 122  | total loss: [1m[32m0.18264[0m[0m | time: 80.431s
[2K
| Adam | epoch: 005 | loss: 0.18264 - acc: 0.9297 -- iter: 320/870
[A[ATraining Step: 123  | total loss: [1m[32m0.18132[0m[0m | time: 88.686s
[2K
| Adam | epoch: 005 | loss: 0.18132 - acc: 0.9305 -- iter: 352/870
[A[ATraining Step: 124  | total loss: [1m[32m0.16772[0m[0m | time: 96.972s
[2K
| Adam | epoch: 005 | loss: 0.16772 - acc: 0.9374 -- iter: 384/870
[A[ATraining Step: 125  | total loss: [1m[32m0.19107[0m[0m | time: 105.145s
[2K
| Adam | epoch: 005 | loss: 0.19107 - acc: 0.9249 -- iter: 416/870
[A[ATraining Step: 126  | total loss: [1m[32m0.20319[0m[0m | time: 114.842s
[2K
| Adam | epoch: 005 | loss: 0.20319 - acc: 0.9168 -- iter: 448/870
[A[ATraining Step: 127  | total loss: [1m[32m0.20530[0m[0m | time: 132.774s
[2K
| Adam | epoch: 005 | loss: 0.20530 - acc: 0.9189 -- iter: 480/870
[A[ATraining Step: 128  | total loss: [1m[32m0.18822[0m[0m | time: 141.084s
[2K
| Adam | epoch: 005 | loss: 0.18822 - acc: 0.9270 -- iter: 512/870
[A[ATraining Step: 129  | total loss: [1m[32m0.17501[0m[0m | time: 149.812s
[2K
| Adam | epoch: 005 | loss: 0.17501 - acc: 0.9312 -- iter: 544/870
[A[ATraining Step: 130  | total loss: [1m[32m0.16452[0m[0m | time: 159.315s
[2K
| Adam | epoch: 005 | loss: 0.16452 - acc: 0.9349 -- iter: 576/870
[A[ATraining Step: 131  | total loss: [1m[32m0.18455[0m[0m | time: 169.575s
[2K
| Adam | epoch: 005 | loss: 0.18455 - acc: 0.9289 -- iter: 608/870
[A[ATraining Step: 132  | total loss: [1m[32m0.18765[0m[0m | time: 178.982s
[2K
| Adam | epoch: 005 | loss: 0.18765 - acc: 0.9329 -- iter: 640/870
[A[ATraining Step: 133  | total loss: [1m[32m0.17741[0m[0m | time: 187.208s
[2K
| Adam | epoch: 005 | loss: 0.17741 - acc: 0.9396 -- iter: 672/870
[A[ATraining Step: 134  | total loss: [1m[32m0.18674[0m[0m | time: 195.282s
[2K
| Adam | epoch: 005 | loss: 0.18674 - acc: 0.9363 -- iter: 704/870
[A[ATraining Step: 135  | total loss: [1m[32m0.18122[0m[0m | time: 205.078s
[2K
| Adam | epoch: 005 | loss: 0.18122 - acc: 0.9364 -- iter: 736/870
[A[ATraining Step: 136  | total loss: [1m[32m0.16768[0m[0m | time: 213.041s
[2K
| Adam | epoch: 005 | loss: 0.16768 - acc: 0.9428 -- iter: 768/870
[A[ATraining Step: 137  | total loss: [1m[32m0.16527[0m[0m | time: 221.168s
[2K
| Adam | epoch: 005 | loss: 0.16527 - acc: 0.9422 -- iter: 800/870
[A[ATraining Step: 138  | total loss: [1m[32m0.16183[0m[0m | time: 229.273s
[2K
| Adam | epoch: 005 | loss: 0.16183 - acc: 0.9418 -- iter: 832/870
[A[ATraining Step: 139  | total loss: [1m[32m0.17395[0m[0m | time: 237.535s
[2K
| Adam | epoch: 005 | loss: 0.17395 - acc: 0.9445 -- iter: 864/870
[A[ATraining Step: 140  | total loss: [1m[32m0.17137[0m[0m | time: 257.816s
[2K
| Adam | epoch: 005 | loss: 0.17137 - acc: 0.9469 | val_loss: 0.98010 - val_acc: 0.7509 -- iter: 870/870
--
Validation AUC:0.9412459720730397
Validation AUPRC:0.9449173678454348
Test AUC:0.903582974137931
Test AUPRC:0.9178924052872115
BestTestF1Score	0.84	0.69	0.84	0.89	0.81	117	15	113	28	1.0
BestTestMCCScore	0.84	0.69	0.84	0.89	0.81	117	15	113	28	1.0
BestTestAccuracyScore	0.84	0.69	0.84	0.89	0.81	117	15	113	28	1.0
BestValidationF1Score	0.87	0.75	0.88	0.88	0.86	114	15	125	19	1.0
BestValidationMCC	0.87	0.75	0.88	0.88	0.86	114	15	125	19	1.0
BestValidationAccuracy	0.87	0.75	0.88	0.88	0.86	114	15	125	19	1.0
TestPredictions (Threshold:1.0)
CHEMBL3670470,TP,ACT,1.0	CHEMBL3675536,TP,ACT,1.0	CHEMBL151,TN,INACT,0.3799999952316284	CHEMBL3675408,TP,ACT,1.0	CHEMBL3670481,TP,ACT,1.0	CHEMBL318461,TN,INACT,0.05000000074505806	CHEMBL599552,TN,INACT,0.12999999523162842	CHEMBL1161235,TN,INACT,0.7300000190734863	CHEMBL3670410,TP,ACT,1.0	CHEMBL3670463,TP,ACT,1.0	CHEMBL259850,TN,INACT,0.10000000149011612	CHEMBL1242468,FP,INACT,1.0	CHEMBL2392379,TN,INACT,0.9599999785423279	CHEMBL509499,TN,INACT,0.8399999737739563	CHEMBL3675491,TP,ACT,1.0	CHEMBL3680464,TP,ACT,1.0	CHEMBL131382,TN,INACT,0.44999998807907104	CHEMBL3675432,TP,ACT,1.0	CHEMBL1767275,TN,INACT,0.8399999737739563	CHEMBL3685317,TP,ACT,1.0	CHEMBL3680461,TP,ACT,1.0	CHEMBL3675433,TP,ACT,1.0	CHEMBL285527,TN,INACT,0.6700000166893005	CHEMBL1688215,FN,ACT,0.7300000190734863	CHEMBL188434,FN,ACT,0.3199999928474426	CHEMBL3680602,TP,ACT,1.0	CHEMBL308134,TN,INACT,0.5299999713897705	CHEMBL3675463,TP,ACT,1.0	CHEMBL3675350,TP,ACT,1.0	CHEMBL3680422,TP,ACT,1.0	CHEMBL1287853,FN,ACT,0.6299999952316284	CHEMBL512658,TN,INACT,0.75	CHEMBL3353406,FP,INACT,1.0	CHEMBL1559959,TN,INACT,0.8999999761581421	CHEMBL1910755,TN,INACT,0.2800000011920929	CHEMBL3670484,TP,ACT,1.0	CHEMBL56219,TN,INACT,0.9700000286102295	CHEMBL524820,TN,INACT,0.9599999785423279	CHEMBL428647,FP,INACT,1.0	CHEMBL3675343,TP,ACT,1.0	CHEMBL3815097,TN,INACT,0.23000000417232513	CHEMBL3675504,TP,ACT,1.0	CHEMBL3675345,TP,ACT,1.0	CHEMBL3670482,TP,ACT,1.0	CHEMBL477064,TN,INACT,0.3100000023841858	CHEMBL3680469,TP,ACT,1.0	CHEMBL3680399,TP,ACT,1.0	CHEMBL3680579,TP,ACT,1.0	CHEMBL314146,TN,INACT,0.6399999856948853	CHEMBL3670485,TP,ACT,1.0	CHEMBL3670419,TP,ACT,1.0	CHEMBL3680484,FN,ACT,0.9900000095367432	CHEMBL131695,TN,INACT,0.03999999910593033	CHEMBL232542,TN,INACT,0.949999988079071	CHEMBL558849,TN,INACT,0.0	CHEMBL3675414,TP,ACT,1.0	CHEMBL549792,TN,INACT,0.5899999737739563	CHEMBL1082061,FN,ACT,0.6700000166893005	CHEMBL430902,FP,INACT,1.0	CHEMBL6291,TP,ACT,1.0	CHEMBL549303,TN,INACT,0.6499999761581421	CHEMBL3670487,TP,ACT,1.0	CHEMBL591440,TN,INACT,0.019999999552965164	CHEMBL3670444,TP,ACT,1.0	CHEMBL2177668,TN,INACT,0.5899999737739563	CHEMBL1095278,TP,ACT,1.0	CHEMBL1641789,FN,ACT,0.23999999463558197	CHEMBL3680403,TP,ACT,1.0	CHEMBL1079243,FN,ACT,0.5400000214576721	CHEMBL1089405,FP,INACT,1.0	CHEMBL589119,TN,INACT,0.9700000286102295	CHEMBL3670430,FP,INACT,1.0	CHEMBL2177686,FP,INACT,1.0	CHEMBL3421974,TN,INACT,0.4399999976158142	CHEMBL154911,TN,INACT,0.7900000214576721	CHEMBL3675438,TP,ACT,1.0	CHEMBL3421979,TN,INACT,0.4699999988079071	CHEMBL3680535,TP,ACT,1.0	CHEMBL3680439,FN,ACT,0.49000000953674316	CHEMBL3675538,TP,ACT,1.0	CHEMBL3675364,TP,ACT,1.0	CHEMBL266540,TN,INACT,0.03999999910593033	CHEMBL3675407,TP,ACT,1.0	CHEMBL329642,TN,INACT,0.6800000071525574	CHEMBL3675453,TP,ACT,1.0	CHEMBL114073,TN,INACT,0.9900000095367432	CHEMBL328164,TN,INACT,0.2800000011920929	CHEMBL1641790,FN,ACT,0.7799999713897705	CHEMBL2420909,TN,INACT,0.9399999976158142	CHEMBL3675510,TP,ACT,1.0	CHEMBL3680550,TP,ACT,1.0	CHEMBL3670465,TP,ACT,1.0	CHEMBL3675472,TP,ACT,1.0	CHEMBL3680455,TP,ACT,1.0	CHEMBL3680515,FN,ACT,0.9700000286102295	CHEMBL457180,TN,INACT,0.8999999761581421	CHEMBL3675387,TP,ACT,1.0	CHEMBL1784649,TN,INACT,0.9700000286102295	CHEMBL3675470,TP,ACT,1.0	CHEMBL201307,TN,INACT,0.4699999988079071	CHEMBL3670411,TP,ACT,1.0	CHEMBL3085242,TN,INACT,0.10999999940395355	CHEMBL3670447,TP,ACT,1.0	CHEMBL3675502,FN,ACT,0.9700000286102295	CHEMBL3745929,TN,INACT,0.11999999731779099	CHEMBL2029518,TN,INACT,0.2800000011920929	CHEMBL234944,TN,INACT,0.9100000262260437	CHEMBL3675402,TP,ACT,1.0	CHEMBL332342,FP,INACT,1.0	CHEMBL3670408,TP,ACT,1.0	CHEMBL3661094,TN,INACT,0.029999999329447746	CHEMBL3675493,TP,ACT,1.0	CHEMBL2016887,TP,ACT,1.0	CHEMBL3675420,TP,ACT,1.0	CHEMBL1829272,TN,INACT,0.18000000715255737	CHEMBL3675505,TP,ACT,1.0	CHEMBL551663,TN,INACT,0.03999999910593033	CHEMBL552136,TN,INACT,0.6100000143051147	CHEMBL3675394,TP,ACT,1.0	CHEMBL1078537,FN,ACT,0.6000000238418579	CHEMBL3628817,TN,INACT,0.9900000095367432	CHEMBL2070409,TN,INACT,0.550000011920929	CHEMBL1096271,TP,ACT,1.0	CHEMBL99687,TN,INACT,0.8100000023841858	CHEMBL558460,TN,INACT,0.9900000095367432	CHEMBL318485,TN,INACT,0.029999999329447746	CHEMBL1721885,FN,ACT,0.9900000095367432	CHEMBL515414,FN,ACT,0.9599999785423279	CHEMBL1079294,TP,ACT,1.0	CHEMBL379218,FN,ACT,0.9800000190734863	CHEMBL562198,TN,INACT,0.949999988079071	CHEMBL3680471,TP,ACT,1.0	CHEMBL3680462,TP,ACT,1.0	CHEMBL1078539,FN,ACT,0.23999999463558197	CHEMBL3675441,TP,ACT,1.0	CHEMBL300138,TP,ACT,1.0	CHEMBL2029517,TN,INACT,0.20000000298023224	CHEMBL3680596,TP,ACT,1.0	CHEMBL3675375,FP,INACT,1.0	CHEMBL223393,TN,INACT,0.9900000095367432	CHEMBL3675488,TP,ACT,1.0	CHEMBL3675540,TP,ACT,1.0	CHEMBL49120,TN,INACT,0.3199999928474426	CHEMBL314021,TN,INACT,0.019999999552965164	CHEMBL3675506,FN,ACT,0.9900000095367432	CHEMBL3680573,TP,ACT,1.0	CHEMBL3675363,TP,ACT,1.0	CHEMBL318188,TN,INACT,0.029999999329447746	CHEMBL3680575,TP,ACT,1.0	CHEMBL3675424,TP,ACT,1.0	CHEMBL3680388,TP,ACT,1.0	CHEMBL498520,TN,INACT,0.9800000190734863	CHEMBL2392240,TN,INACT,0.03999999910593033	CHEMBL3685311,FN,ACT,0.9800000190734863	CHEMBL3675395,FN,ACT,0.7699999809265137	CHEMBL61743,TN,INACT,0.019999999552965164	CHEMBL3675366,TP,ACT,1.0	CHEMBL3670472,TP,ACT,1.0	CHEMBL2348180,TN,INACT,0.9300000071525574	CHEMBL44,TN,INACT,0.09000000357627869	CHEMBL3675335,TP,ACT,1.0	CHEMBL3675410,TP,ACT,1.0	CHEMBL525530,FP,INACT,1.0	CHEMBL3680488,TP,ACT,1.0	CHEMBL3685323,FN,ACT,0.9900000095367432	CHEMBL1828876,TN,INACT,0.47999998927116394	CHEMBL3675398,TP,ACT,1.0	CHEMBL1087421,TN,INACT,0.2800000011920929	CHEMBL1078426,TP,ACT,1.0	CHEMBL1922122,TN,INACT,0.5899999737739563	CHEMBL3675383,TP,ACT,1.0	CHEMBL3675413,FN,ACT,0.8899999856948853	CHEMBL1922210,FP,INACT,1.0	CHEMBL29197,TN,INACT,0.3100000023841858	CHEMBL3680507,TP,ACT,1.0	CHEMBL88326,TN,INACT,0.9399999976158142	CHEMBL3680410,TP,ACT,1.0	CHEMBL95477,TN,INACT,0.7300000190734863	CHEMBL3680511,TP,ACT,1.0	CHEMBL188282,FP,INACT,1.0	CHEMBL3680477,FN,ACT,0.9800000190734863	CHEMBL3670409,TP,ACT,1.0	CHEMBL460472,FP,INACT,1.0	CHEMBL1079293,TP,ACT,1.0	CHEMBL1235213,TN,INACT,0.9900000095367432	CHEMBL3680508,TP,ACT,1.0	CHEMBL3675430,FN,ACT,0.9800000190734863	CHEMBL2012701,TP,ACT,1.0	CHEMBL3675389,TP,ACT,1.0	CHEMBL100312,TN,INACT,0.9599999785423279	CHEMBL295316,TN,INACT,0.44999998807907104	CHEMBL3685320,TP,ACT,1.0	CHEMBL520828,TP,ACT,1.0	CHEMBL3670464,TP,ACT,1.0	CHEMBL3670454,TP,ACT,1.0	CHEMBL1081198,TN,INACT,0.9900000095367432	CHEMBL3670434,TP,ACT,1.0	CHEMBL315701,TN,INACT,0.9300000071525574	CHEMBL3675406,TP,ACT,1.0	CHEMBL3685205,TP,ACT,1.0	CHEMBL3098326,TN,INACT,0.9100000262260437	CHEMBL3665670,TN,INACT,0.5099999904632568	CHEMBL1683951,TN,INACT,0.05000000074505806	CHEMBL3670476,TP,ACT,1.0	CHEMBL1910762,TN,INACT,0.3700000047683716	CHEMBL99779,FP,INACT,1.0	CHEMBL3670423,TP,ACT,1.0	CHEMBL3675400,TP,ACT,1.0	CHEMBL1910761,TN,INACT,0.5299999713897705	CHEMBL2392234,TN,INACT,0.05000000074505806	CHEMBL74799,TN,INACT,0.9599999785423279	CHEMBL1258663,TN,INACT,0.9900000095367432	CHEMBL2312652,TN,INACT,0.9100000262260437	CHEMBL456759,TN,INACT,0.9900000095367432	CHEMBL154260,TN,INACT,0.5299999713897705	CHEMBL3670429,TP,ACT,1.0	CHEMBL3675404,TP,ACT,1.0	CHEMBL323015,TN,INACT,0.7699999809265137	CHEMBL515674,TN,INACT,0.15000000596046448	CHEMBL3675467,TP,ACT,1.0	CHEMBL3670435,TP,ACT,1.0	CHEMBL3680416,TP,ACT,1.0	CHEMBL3335245,TN,INACT,0.3499999940395355	CHEMBL527039,TN,INACT,0.27000001072883606	CHEMBL3685293,TP,ACT,1.0	CHEMBL3675382,TP,ACT,1.0	CHEMBL3675539,TP,ACT,1.0	CHEMBL3680520,TP,ACT,1.0	CHEMBL3670424,TP,ACT,1.0	CHEMBL100485,TN,INACT,0.9900000095367432	CHEMBL327725,TN,INACT,0.10000000149011612	CHEMBL2208034,FN,ACT,0.8600000143051147	CHEMBL3675351,TP,ACT,1.0	CHEMBL591706,TN,INACT,0.07000000029802322	CHEMBL3661092,TN,INACT,0.7400000095367432	CHEMBL1688205,TN,INACT,0.11999999731779099	CHEMBL3675490,TP,ACT,1.0	CHEMBL3680499,TP,ACT,1.0	CHEMBL91748,TN,INACT,0.2199999988079071	CHEMBL1241390,TN,INACT,0.9900000095367432	CHEMBL3665654,TN,INACT,0.7300000190734863	CHEMBL520515,TN,INACT,0.14000000059604645	CHEMBL495617,TN,INACT,0.5199999809265137	CHEMBL3675342,TP,ACT,1.0	CHEMBL2392227,TN,INACT,0.019999999552965164	CHEMBL3675427,TP,ACT,1.0	CHEMBL1688204,TN,INACT,0.05000000074505806	CHEMBL482883,TN,INACT,0.9900000095367432	CHEMBL2347053,FN,ACT,0.9599999785423279	CHEMBL3675497,TP,ACT,1.0	CHEMBL23507,TN,INACT,0.25	CHEMBL3680429,TP,ACT,1.0	CHEMBL38380,TN,INACT,0.07000000029802322	CHEMBL3670501,TP,ACT,1.0	CHEMBL3675440,TP,ACT,1.0	CHEMBL2029695,TN,INACT,0.46000000834465027	CHEMBL172973,FP,INACT,1.0	CHEMBL1269497,TN,INACT,0.009999999776482582	CHEMBL541445,TN,INACT,0.28999999165534973	CHEMBL3680583,FN,ACT,0.8799999952316284	CHEMBL3680490,TP,ACT,1.0	CHEMBL233958,TN,INACT,0.9800000190734863	CHEMBL3670438,TP,ACT,1.0	CHEMBL474807,TN,INACT,0.9900000095367432	CHEMBL3670497,TP,ACT,1.0	CHEMBL1641801,FN,ACT,0.4699999988079071	CHEMBL1641792,TN,INACT,0.7699999809265137	CHEMBL2164696,TN,INACT,0.949999988079071	CHEMBL1828884,TN,INACT,0.05000000074505806	CHEMBL3675327,TP,ACT,1.0	CHEMBL1080245,FN,ACT,0.9900000095367432	CHEMBL515051,TN,INACT,0.9399999976158142	CHEMBL2337364,TN,INACT,0.5199999809265137	

