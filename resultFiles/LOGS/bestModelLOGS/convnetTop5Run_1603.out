ImageNetInceptionV2 CHEMBL307 adam 0.0001 15 0 0 0.8 False True
Number of active compounds :	206
Number of inactive compounds :	206
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL307_adam_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL307_adam_0.0001_15_0.8/
---------------------------------
Training samples: 263
Validation samples: 83
--
Training Step: 1  | time: 224.552s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/263
[A[ATraining Step: 2  | total loss: [1m[32m0.67302[0m[0m | time: 366.712s
[2K
| Adam | epoch: 001 | loss: 0.67302 - acc: 0.3094 -- iter: 064/263
[A[ATraining Step: 3  | total loss: [1m[32m0.67711[0m[0m | time: 443.578s
[2K
| Adam | epoch: 001 | loss: 0.67711 - acc: 0.4653 -- iter: 096/263
[A[ATraining Step: 4  | total loss: [1m[32m0.63499[0m[0m | time: 513.108s
[2K
| Adam | epoch: 001 | loss: 0.63499 - acc: 0.6085 -- iter: 128/263
[A[ATraining Step: 5  | total loss: [1m[32m0.63320[0m[0m | time: 571.818s
[2K
| Adam | epoch: 001 | loss: 0.63320 - acc: 0.6199 -- iter: 160/263
[A[ATraining Step: 6  | total loss: [1m[32m0.61107[0m[0m | time: 608.404s
[2K
| Adam | epoch: 001 | loss: 0.61107 - acc: 0.6433 -- iter: 192/263
[A[ATraining Step: 7  | total loss: [1m[32m0.60487[0m[0m | time: 649.735s
[2K
| Adam | epoch: 001 | loss: 0.60487 - acc: 0.6136 -- iter: 224/263
[A[ATraining Step: 8  | total loss: [1m[32m0.51476[0m[0m | time: 662.198s
[2K
| Adam | epoch: 001 | loss: 0.51476 - acc: 0.7255 -- iter: 256/263
[A[ATraining Step: 9  | total loss: [1m[32m0.47518[0m[0m | time: 677.787s
[2K
| Adam | epoch: 001 | loss: 0.47518 - acc: 0.8046 | val_loss: 1.28944 - val_acc: 0.5301 -- iter: 263/263
--
Training Step: 10  | total loss: [1m[32m0.48534[0m[0m | time: 43.795s
[2K
| Adam | epoch: 002 | loss: 0.48534 - acc: 0.8309 -- iter: 032/263
[A[ATraining Step: 11  | total loss: [1m[32m0.38493[0m[0m | time: 121.316s
[2K
| Adam | epoch: 002 | loss: 0.38493 - acc: 0.9110 -- iter: 064/263
[A[ATraining Step: 12  | total loss: [1m[32m0.43304[0m[0m | time: 201.959s
[2K
| Adam | epoch: 002 | loss: 0.43304 - acc: 0.8526 -- iter: 096/263
[A[ATraining Step: 13  | total loss: [1m[32m0.44838[0m[0m | time: 251.004s
[2K
| Adam | epoch: 002 | loss: 0.44838 - acc: 0.8354 -- iter: 128/263
[A[ATraining Step: 14  | total loss: [1m[32m0.43217[0m[0m | time: 277.252s
[2K
| Adam | epoch: 002 | loss: 0.43217 - acc: 0.8388 -- iter: 160/263
[A[ATraining Step: 15  | total loss: [1m[32m0.42325[0m[0m | time: 316.547s
[2K
| Adam | epoch: 002 | loss: 0.42325 - acc: 0.8285 -- iter: 192/263
[A[ATraining Step: 16  | total loss: [1m[32m0.41394[0m[0m | time: 332.429s
[2K
| Adam | epoch: 002 | loss: 0.41394 - acc: 0.8342 -- iter: 224/263
[A[ATraining Step: 17  | total loss: [1m[32m0.39251[0m[0m | time: 416.576s
[2K
| Adam | epoch: 002 | loss: 0.39251 - acc: 0.8489 -- iter: 256/263
[A[ATraining Step: 18  | total loss: [1m[32m0.34690[0m[0m | time: 476.637s
[2K
| Adam | epoch: 002 | loss: 0.34690 - acc: 0.8796 | val_loss: 2.65331 - val_acc: 0.5301 -- iter: 263/263
--
Training Step: 19  | total loss: [1m[32m0.28160[0m[0m | time: 4.841s
[2K
| Adam | epoch: 003 | loss: 0.28160 - acc: 0.9197 -- iter: 032/263
[A[ATraining Step: 20  | total loss: [1m[32m0.24561[0m[0m | time: 9.753s
[2K
| Adam | epoch: 003 | loss: 0.24561 - acc: 0.9455 -- iter: 064/263
[A[ATraining Step: 21  | total loss: [1m[32m0.19582[0m[0m | time: 75.306s
[2K
| Adam | epoch: 003 | loss: 0.19582 - acc: 0.9624 -- iter: 096/263
[A[ATraining Step: 22  | total loss: [1m[32m0.17588[0m[0m | time: 125.158s
[2K
| Adam | epoch: 003 | loss: 0.17588 - acc: 0.9737 -- iter: 128/263
[A[ATraining Step: 23  | total loss: [1m[32m0.17996[0m[0m | time: 160.771s
[2K
| Adam | epoch: 003 | loss: 0.17996 - acc: 0.9813 -- iter: 160/263
[A[ATraining Step: 24  | total loss: [1m[32m0.20112[0m[0m | time: 178.293s
[2K
| Adam | epoch: 003 | loss: 0.20112 - acc: 0.9602 -- iter: 192/263
[A[ATraining Step: 25  | total loss: [1m[32m0.18305[0m[0m | time: 186.934s
[2K
| Adam | epoch: 003 | loss: 0.18305 - acc: 0.9625 -- iter: 224/263
[A[ATraining Step: 26  | total loss: [1m[32m0.17314[0m[0m | time: 195.293s
[2K
| Adam | epoch: 003 | loss: 0.17314 - acc: 0.9559 -- iter: 256/263
[A[ATraining Step: 27  | total loss: [1m[32m0.15272[0m[0m | time: 223.663s
[2K
| Adam | epoch: 003 | loss: 0.15272 - acc: 0.9673 | val_loss: 2.51328 - val_acc: 0.5301 -- iter: 263/263
--
Training Step: 28  | total loss: [1m[32m0.15628[0m[0m | time: 12.511s
[2K
| Adam | epoch: 004 | loss: 0.15628 - acc: 0.9676 -- iter: 032/263
[A[ATraining Step: 29  | total loss: [1m[32m0.12716[0m[0m | time: 16.622s
[2K
| Adam | epoch: 004 | loss: 0.12716 - acc: 0.9755 -- iter: 064/263
[A[ATraining Step: 30  | total loss: [1m[32m0.11631[0m[0m | time: 20.495s
[2K
| Adam | epoch: 004 | loss: 0.11631 - acc: 0.9813 -- iter: 096/263
[A[ATraining Step: 31  | total loss: [1m[32m0.09193[0m[0m | time: 33.219s
[2K
| Adam | epoch: 004 | loss: 0.09193 - acc: 0.9856 -- iter: 128/263
[A[ATraining Step: 32  | total loss: [1m[32m0.12846[0m[0m | time: 45.711s
[2K
| Adam | epoch: 004 | loss: 0.12846 - acc: 0.9818 -- iter: 160/263
[A[ATraining Step: 33  | total loss: [1m[32m0.10840[0m[0m | time: 55.857s
[2K
| Adam | epoch: 004 | loss: 0.10840 - acc: 0.9858 -- iter: 192/263
[A[ATraining Step: 34  | total loss: [1m[32m0.11007[0m[0m | time: 64.067s
[2K
| Adam | epoch: 004 | loss: 0.11007 - acc: 0.9755 -- iter: 224/263
[A[ATraining Step: 35  | total loss: [1m[32m0.09733[0m[0m | time: 73.811s
[2K
| Adam | epoch: 004 | loss: 0.09733 - acc: 0.9806 -- iter: 256/263
[A[ATraining Step: 36  | total loss: [1m[32m0.08313[0m[0m | time: 92.296s
[2K
| Adam | epoch: 004 | loss: 0.08313 - acc: 0.9846 | val_loss: 2.53587 - val_acc: 0.5301 -- iter: 263/263
--
Training Step: 37  | total loss: [1m[32m0.09059[0m[0m | time: 12.280s
[2K
| Adam | epoch: 005 | loss: 0.09059 - acc: 0.9814 -- iter: 032/263
[A[ATraining Step: 38  | total loss: [1m[32m0.23887[0m[0m | time: 24.903s
[2K
| Adam | epoch: 005 | loss: 0.23887 - acc: 0.9545 -- iter: 064/263
[A[ATraining Step: 39  | total loss: [1m[32m0.20389[0m[0m | time: 29.063s
[2K
| Adam | epoch: 005 | loss: 0.20389 - acc: 0.9572 -- iter: 096/263
[A[ATraining Step: 40  | total loss: [1m[32m0.16747[0m[0m | time: 33.266s
[2K
| Adam | epoch: 005 | loss: 0.16747 - acc: 0.9652 -- iter: 128/263
[A[ATraining Step: 41  | total loss: [1m[32m0.13849[0m[0m | time: 46.235s
[2K
| Adam | epoch: 005 | loss: 0.13849 - acc: 0.9716 -- iter: 160/263
[A[ATraining Step: 42  | total loss: [1m[32m0.12654[0m[0m | time: 55.553s
[2K
| Adam | epoch: 005 | loss: 0.12654 - acc: 0.9655 -- iter: 192/263
[A[ATraining Step: 43  | total loss: [1m[32m0.12061[0m[0m | time: 64.331s
[2K
| Adam | epoch: 005 | loss: 0.12061 - acc: 0.9661 -- iter: 224/263
[A[ATraining Step: 44  | total loss: [1m[32m0.10931[0m[0m | time: 74.947s
[2K
| Adam | epoch: 005 | loss: 0.10931 - acc: 0.9719 -- iter: 256/263
[A[ATraining Step: 45  | total loss: [1m[32m0.10643[0m[0m | time: 93.355s
[2K
| Adam | epoch: 005 | loss: 0.10643 - acc: 0.9714 | val_loss: 0.75630 - val_acc: 0.6506 -- iter: 263/263
--
Training Step: 46  | total loss: [1m[32m0.10092[0m[0m | time: 31.952s
[2K
| Adam | epoch: 006 | loss: 0.10092 - acc: 0.9709 -- iter: 032/263
[A[ATraining Step: 47  | total loss: [1m[32m0.08836[0m[0m | time: 45.515s
[2K
| Adam | epoch: 006 | loss: 0.08836 - acc: 0.9757 -- iter: 064/263
[A[ATraining Step: 48  | total loss: [1m[32m0.11618[0m[0m | time: 56.202s
[2K
| Adam | epoch: 006 | loss: 0.11618 - acc: 0.9746 -- iter: 096/263
[A[ATraining Step: 49  | total loss: [1m[32m0.09917[0m[0m | time: 58.770s
[2K
| Adam | epoch: 006 | loss: 0.09917 - acc: 0.9786 -- iter: 128/263
[A[ATraining Step: 50  | total loss: [1m[32m0.08663[0m[0m | time: 61.479s
[2K
| Adam | epoch: 006 | loss: 0.08663 - acc: 0.9819 -- iter: 160/263
[A[ATraining Step: 51  | total loss: [1m[32m0.07448[0m[0m | time: 69.956s
[2K
| Adam | epoch: 006 | loss: 0.07448 - acc: 0.9847 -- iter: 192/263
[A[ATraining Step: 52  | total loss: [1m[32m0.06645[0m[0m | time: 78.585s
[2K
| Adam | epoch: 006 | loss: 0.06645 - acc: 0.9870 -- iter: 224/263
[A[ATraining Step: 53  | total loss: [1m[32m0.10158[0m[0m | time: 89.557s
[2K
| Adam | epoch: 006 | loss: 0.10158 - acc: 0.9797 -- iter: 256/263
[A[ATraining Step: 54  | total loss: [1m[32m0.09490[0m[0m | time: 108.606s
[2K
| Adam | epoch: 006 | loss: 0.09490 - acc: 0.9781 | val_loss: 1.87800 - val_acc: 0.5783 -- iter: 263/263
--
Training Step: 55  | total loss: [1m[32m0.08567[0m[0m | time: 12.577s
[2K
| Adam | epoch: 007 | loss: 0.08567 - acc: 0.9812 -- iter: 032/263
[A[ATraining Step: 56  | total loss: [1m[32m0.07644[0m[0m | time: 25.258s
[2K
| Adam | epoch: 007 | loss: 0.07644 - acc: 0.9839 -- iter: 064/263
[A[ATraining Step: 57  | total loss: [1m[32m0.06915[0m[0m | time: 37.899s
[2K
| Adam | epoch: 007 | loss: 0.06915 - acc: 0.9861 -- iter: 096/263
[A[ATraining Step: 58  | total loss: [1m[32m0.10932[0m[0m | time: 47.452s
[2K
| Adam | epoch: 007 | loss: 0.10932 - acc: 0.9795 -- iter: 128/263
[A[ATraining Step: 59  | total loss: [1m[32m0.09727[0m[0m | time: 50.054s
[2K
| Adam | epoch: 007 | loss: 0.09727 - acc: 0.9822 -- iter: 160/263
[A[ATraining Step: 60  | total loss: [1m[32m0.08562[0m[0m | time: 52.625s
[2K
| Adam | epoch: 007 | loss: 0.08562 - acc: 0.9846 -- iter: 192/263
[A[ATraining Step: 61  | total loss: [1m[32m0.07546[0m[0m | time: 62.410s
[2K
| Adam | epoch: 007 | loss: 0.07546 - acc: 0.9866 -- iter: 224/263
[A[ATraining Step: 62  | total loss: [1m[32m0.06814[0m[0m | time: 75.209s
[2K
| Adam | epoch: 007 | loss: 0.06814 - acc: 0.9883 -- iter: 256/263
[A[ATraining Step: 63  | total loss: [1m[32m0.06206[0m[0m | time: 93.677s
[2K
| Adam | epoch: 007 | loss: 0.06206 - acc: 0.9898 | val_loss: 2.69745 - val_acc: 0.5301 -- iter: 263/263
--
Training Step: 64  | total loss: [1m[32m0.05515[0m[0m | time: 12.099s
[2K
| Adam | epoch: 008 | loss: 0.05515 - acc: 0.9911 -- iter: 032/263
[A[ATraining Step: 65  | total loss: [1m[32m0.08000[0m[0m | time: 24.250s
[2K
| Adam | epoch: 008 | loss: 0.08000 - acc: 0.9883 -- iter: 064/263
[A[ATraining Step: 66  | total loss: [1m[32m0.09054[0m[0m | time: 36.735s
[2K
| Adam | epoch: 008 | loss: 0.09054 - acc: 0.9859 -- iter: 096/263
[A[ATraining Step: 67  | total loss: [1m[32m0.09066[0m[0m | time: 45.330s
[2K
| Adam | epoch: 008 | loss: 0.09066 - acc: 0.9839 -- iter: 128/263
[A[ATraining Step: 68  | total loss: [1m[32m0.10605[0m[0m | time: 54.054s
[2K
| Adam | epoch: 008 | loss: 0.10605 - acc: 0.9821 -- iter: 160/263
[A[ATraining Step: 69  | total loss: [1m[32m0.12039[0m[0m | time: 57.858s
[2K
| Adam | epoch: 008 | loss: 0.12039 - acc: 0.9805 -- iter: 192/263
[A[ATraining Step: 70  | total loss: [1m[32m0.13478[0m[0m | time: 61.629s
[2K
| Adam | epoch: 008 | loss: 0.13478 - acc: 0.9663 -- iter: 224/263
[A[ATraining Step: 71  | total loss: [1m[32m0.13489[0m[0m | time: 74.682s
[2K
| Adam | epoch: 008 | loss: 0.13489 - acc: 0.9701 -- iter: 256/263
[A[ATraining Step: 72  | total loss: [1m[32m0.12263[0m[0m | time: 93.692s
[2K
| Adam | epoch: 008 | loss: 0.12263 - acc: 0.9735 | val_loss: 0.45356 - val_acc: 0.7831 -- iter: 263/263
--
Training Step: 73  | total loss: [1m[32m0.11246[0m[0m | time: 12.486s
[2K
| Adam | epoch: 009 | loss: 0.11246 - acc: 0.9764 -- iter: 032/263
[A[ATraining Step: 74  | total loss: [1m[32m0.10235[0m[0m | time: 21.022s
[2K
| Adam | epoch: 009 | loss: 0.10235 - acc: 0.9790 -- iter: 064/263
[A[ATraining Step: 75  | total loss: [1m[32m0.11399[0m[0m | time: 29.519s
[2K
| Adam | epoch: 009 | loss: 0.11399 - acc: 0.9779 -- iter: 096/263
[A[ATraining Step: 76  | total loss: [1m[32m0.10743[0m[0m | time: 40.762s
[2K
| Adam | epoch: 009 | loss: 0.10743 - acc: 0.9769 -- iter: 128/263
[A[ATraining Step: 77  | total loss: [1m[32m0.10188[0m[0m | time: 53.457s
[2K
| Adam | epoch: 009 | loss: 0.10188 - acc: 0.9761 -- iter: 160/263
[A[ATraining Step: 78  | total loss: [1m[32m0.11694[0m[0m | time: 65.828s
[2K
| Adam | epoch: 009 | loss: 0.11694 - acc: 0.9753 -- iter: 192/263
[A[ATraining Step: 79  | total loss: [1m[32m0.10673[0m[0m | time: 69.894s
[2K
| Adam | epoch: 009 | loss: 0.10673 - acc: 0.9779 -- iter: 224/263
[A[ATraining Step: 80  | total loss: [1m[32m0.09846[0m[0m | time: 73.878s
[2K
| Adam | epoch: 009 | loss: 0.09846 - acc: 0.9801 -- iter: 256/263
[A[ATraining Step: 81  | total loss: [1m[32m0.08942[0m[0m | time: 93.943s
[2K
| Adam | epoch: 009 | loss: 0.08942 - acc: 0.9821 | val_loss: 1.01272 - val_acc: 0.6627 -- iter: 263/263
--
Training Step: 82  | total loss: [1m[32m0.09970[0m[0m | time: 12.404s
[2K
| Adam | epoch: 010 | loss: 0.09970 - acc: 0.9808 -- iter: 032/263
[A[ATraining Step: 83  | total loss: [1m[32m0.09161[0m[0m | time: 20.964s
[2K
| Adam | epoch: 010 | loss: 0.09161 - acc: 0.9827 -- iter: 064/263
[A[ATraining Step: 84  | total loss: [1m[32m0.08488[0m[0m | time: 29.399s
[2K
| Adam | epoch: 010 | loss: 0.08488 - acc: 0.9844 -- iter: 096/263
[A[ATraining Step: 85  | total loss: [1m[32m0.07740[0m[0m | time: 38.054s
[2K
| Adam | epoch: 010 | loss: 0.07740 - acc: 0.9860 -- iter: 128/263
[A[ATraining Step: 86  | total loss: [1m[32m0.08752[0m[0m | time: 50.094s
[2K
| Adam | epoch: 010 | loss: 0.08752 - acc: 0.9843 -- iter: 160/263
[A[ATraining Step: 87  | total loss: [1m[32m0.08001[0m[0m | time: 64.888s
[2K
| Adam | epoch: 010 | loss: 0.08001 - acc: 0.9858 -- iter: 192/263
[A[ATraining Step: 88  | total loss: [1m[32m0.11959[0m[0m | time: 78.297s
[2K
| Adam | epoch: 010 | loss: 0.11959 - acc: 0.9779 -- iter: 224/263
[A[ATraining Step: 89  | total loss: [1m[32m0.10853[0m[0m | time: 82.157s
[2K
| Adam | epoch: 010 | loss: 0.10853 - acc: 0.9801 -- iter: 256/263
[A[ATraining Step: 90  | total loss: [1m[32m0.09873[0m[0m | time: 92.496s
[2K
| Adam | epoch: 010 | loss: 0.09873 - acc: 0.9821 | val_loss: 1.12837 - val_acc: 0.6747 -- iter: 263/263
--
Training Step: 91  | total loss: [1m[32m0.08958[0m[0m | time: 13.282s
[2K
| Adam | epoch: 011 | loss: 0.08958 - acc: 0.9839 -- iter: 032/263
[A[ATraining Step: 92  | total loss: [1m[32m0.08125[0m[0m | time: 24.961s
[2K
| Adam | epoch: 011 | loss: 0.08125 - acc: 0.9855 -- iter: 064/263
[A[ATraining Step: 93  | total loss: [1m[32m0.08873[0m[0m | time: 33.616s
[2K
| Adam | epoch: 011 | loss: 0.08873 - acc: 0.9838 -- iter: 096/263
[A[ATraining Step: 94  | total loss: [1m[32m0.08112[0m[0m | time: 41.992s
[2K
| Adam | epoch: 011 | loss: 0.08112 - acc: 0.9854 -- iter: 128/263
[A[ATraining Step: 95  | total loss: [1m[32m0.07414[0m[0m | time: 50.960s
[2K
| Adam | epoch: 011 | loss: 0.07414 - acc: 0.9869 -- iter: 160/263
[A[ATraining Step: 96  | total loss: [1m[32m0.07215[0m[0m | time: 63.217s
[2K
| Adam | epoch: 011 | loss: 0.07215 - acc: 0.9851 -- iter: 192/263
[A[ATraining Step: 97  | total loss: [1m[32m0.06847[0m[0m | time: 75.944s
[2K
| Adam | epoch: 011 | loss: 0.06847 - acc: 0.9866 -- iter: 224/263
[A[ATraining Step: 98  | total loss: [1m[32m0.09114[0m[0m | time: 88.469s
[2K
| Adam | epoch: 011 | loss: 0.09114 - acc: 0.9848 -- iter: 256/263
[A[ATraining Step: 99  | total loss: [1m[32m0.08298[0m[0m | time: 98.423s
[2K
| Adam | epoch: 011 | loss: 0.08298 - acc: 0.9863 | val_loss: 2.25649 - val_acc: 0.5060 -- iter: 263/263
--
Training Step: 100  | total loss: [1m[32m0.14534[0m[0m | time: 4.267s
[2K
| Adam | epoch: 012 | loss: 0.14534 - acc: 0.9734 -- iter: 032/263
[A[ATraining Step: 101  | total loss: [1m[32m0.15486[0m[0m | time: 17.505s
[2K
| Adam | epoch: 012 | loss: 0.15486 - acc: 0.9618 -- iter: 064/263
[A[ATraining Step: 102  | total loss: [1m[32m0.14074[0m[0m | time: 26.567s
[2K
| Adam | epoch: 012 | loss: 0.14074 - acc: 0.9656 -- iter: 096/263
[A[ATraining Step: 103  | total loss: [1m[32m0.13106[0m[0m | time: 34.999s
[2K
| Adam | epoch: 012 | loss: 0.13106 - acc: 0.9690 -- iter: 128/263
[A[ATraining Step: 104  | total loss: [1m[32m0.13626[0m[0m | time: 44.982s
[2K
| Adam | epoch: 012 | loss: 0.13626 - acc: 0.9690 -- iter: 160/263
[A[ATraining Step: 105  | total loss: [1m[32m0.12414[0m[0m | time: 58.475s
[2K
| Adam | epoch: 012 | loss: 0.12414 - acc: 0.9721 -- iter: 192/263
[A[ATraining Step: 106  | total loss: [1m[32m0.13091[0m[0m | time: 71.114s
[2K
| Adam | epoch: 012 | loss: 0.13091 - acc: 0.9686 -- iter: 224/263
[A[ATraining Step: 107  | total loss: [1m[32m0.12184[0m[0m | time: 121.950s
[2K
| Adam | epoch: 012 | loss: 0.12184 - acc: 0.9718 -- iter: 256/263
[A[ATraining Step: 108  | total loss: [1m[32m0.11062[0m[0m | time: 162.246s
[2K
| Adam | epoch: 012 | loss: 0.11062 - acc: 0.9746 | val_loss: 2.48057 - val_acc: 0.5422 -- iter: 263/263
--
Training Step: 109  | total loss: [1m[32m0.10158[0m[0m | time: 4.093s
[2K
| Adam | epoch: 013 | loss: 0.10158 - acc: 0.9771 -- iter: 032/263
[A[ATraining Step: 110  | total loss: [1m[32m0.12722[0m[0m | time: 7.120s
[2K
| Adam | epoch: 013 | loss: 0.12722 - acc: 0.9651 -- iter: 064/263
[A[ATraining Step: 111  | total loss: [1m[32m0.12312[0m[0m | time: 15.709s
[2K
| Adam | epoch: 013 | loss: 0.12312 - acc: 0.9686 -- iter: 096/263
[A[ATraining Step: 112  | total loss: [1m[32m0.13782[0m[0m | time: 24.413s
[2K
| Adam | epoch: 013 | loss: 0.13782 - acc: 0.9686 -- iter: 128/263
[A[ATraining Step: 113  | total loss: [1m[32m0.12679[0m[0m | time: 33.099s
[2K
| Adam | epoch: 013 | loss: 0.12679 - acc: 0.9718 -- iter: 160/263
[A[ATraining Step: 114  | total loss: [1m[32m0.12428[0m[0m | time: 54.802s
[2K
| Adam | epoch: 013 | loss: 0.12428 - acc: 0.9715 -- iter: 192/263
[A[ATraining Step: 115  | total loss: [1m[32m0.11427[0m[0m | time: 73.974s
[2K
| Adam | epoch: 013 | loss: 0.11427 - acc: 0.9743 -- iter: 224/263
[A[ATraining Step: 116  | total loss: [1m[32m0.10694[0m[0m | time: 86.626s
[2K
| Adam | epoch: 013 | loss: 0.10694 - acc: 0.9769 -- iter: 256/263
[A[ATraining Step: 117  | total loss: [1m[32m0.11532[0m[0m | time: 105.260s
[2K
| Adam | epoch: 013 | loss: 0.11532 - acc: 0.9761 | val_loss: 3.40874 - val_acc: 0.5301 -- iter: 263/263
--
Training Step: 118  | total loss: [1m[32m0.11705[0m[0m | time: 12.502s
[2K
| Adam | epoch: 014 | loss: 0.11705 - acc: 0.9753 -- iter: 032/263
[A[ATraining Step: 119  | total loss: [1m[32m0.10615[0m[0m | time: 16.068s
[2K
| Adam | epoch: 014 | loss: 0.10615 - acc: 0.9778 -- iter: 064/263
[A[ATraining Step: 120  | total loss: [1m[32m0.09930[0m[0m | time: 18.647s
[2K
| Adam | epoch: 014 | loss: 0.09930 - acc: 0.9800 -- iter: 096/263
[A[ATraining Step: 121  | total loss: [1m[32m0.09086[0m[0m | time: 27.262s
[2K
| Adam | epoch: 014 | loss: 0.09086 - acc: 0.9820 -- iter: 128/263
[A[ATraining Step: 122  | total loss: [1m[32m0.08852[0m[0m | time: 35.656s
[2K
| Adam | epoch: 014 | loss: 0.08852 - acc: 0.9807 -- iter: 160/263
[A[ATraining Step: 123  | total loss: [1m[32m0.08278[0m[0m | time: 47.844s
[2K
| Adam | epoch: 014 | loss: 0.08278 - acc: 0.9826 -- iter: 192/263
[A[ATraining Step: 124  | total loss: [1m[32m0.07642[0m[0m | time: 60.336s
[2K
| Adam | epoch: 014 | loss: 0.07642 - acc: 0.9844 -- iter: 224/263
[A[ATraining Step: 125  | total loss: [1m[32m0.07356[0m[0m | time: 75.614s
[2K
| Adam | epoch: 014 | loss: 0.07356 - acc: 0.9828 -- iter: 256/263
[A[ATraining Step: 126  | total loss: [1m[32m0.07458[0m[0m | time: 93.813s
[2K
| Adam | epoch: 014 | loss: 0.07458 - acc: 0.9814 | val_loss: 0.44602 - val_acc: 0.7590 -- iter: 263/263
--
Training Step: 127  | total loss: [1m[32m0.09602[0m[0m | time: 16.617s
[2K
| Adam | epoch: 015 | loss: 0.09602 - acc: 0.9770 -- iter: 032/263
[A[ATraining Step: 128  | total loss: [1m[32m0.08718[0m[0m | time: 26.637s
[2K
| Adam | epoch: 015 | loss: 0.08718 - acc: 0.9793 -- iter: 064/263
[A[ATraining Step: 129  | total loss: [1m[32m0.08653[0m[0m | time: 29.178s
[2K
| Adam | epoch: 015 | loss: 0.08653 - acc: 0.9814 -- iter: 096/263
[A[ATraining Step: 130  | total loss: [1m[32m0.09447[0m[0m | time: 31.676s
[2K
| Adam | epoch: 015 | loss: 0.09447 - acc: 0.9690 -- iter: 128/263
[A[ATraining Step: 131  | total loss: [1m[32m0.08625[0m[0m | time: 40.305s
[2K
| Adam | epoch: 015 | loss: 0.08625 - acc: 0.9721 -- iter: 160/263
[A[ATraining Step: 132  | total loss: [1m[32m0.07839[0m[0m | time: 48.659s
[2K
| Adam | epoch: 015 | loss: 0.07839 - acc: 0.9749 -- iter: 192/263
[A[ATraining Step: 133  | total loss: [1m[32m0.07232[0m[0m | time: 61.845s
[2K
| Adam | epoch: 015 | loss: 0.07232 - acc: 0.9774 -- iter: 224/263
[A[ATraining Step: 134  | total loss: [1m[32m0.07049[0m[0m | time: 70.189s
[2K
| Adam | epoch: 015 | loss: 0.07049 - acc: 0.9796 -- iter: 256/263
[A[ATraining Step: 135  | total loss: [1m[32m0.06535[0m[0m | time: 82.660s
[2K
| Adam | epoch: 015 | loss: 0.06535 - acc: 0.9817 | val_loss: 1.85443 - val_acc: 0.6265 -- iter: 263/263
--
Validation AUC:0.9411421911421911
Validation AUPRC:0.9301528518745824
Test AUC:0.9243498817966903
Test AUPRC:0.9163251887709334
BestTestF1Score	0.76	0.56	0.73	0.62	0.97	35	21	26	1	1.0
BestTestMCCScore	0.76	0.56	0.73	0.62	0.97	35	21	26	1	1.0
BestTestAccuracyScore	0.76	0.56	0.73	0.62	0.97	35	21	26	1	1.0
BestValidationF1Score	0.85	0.71	0.83	0.74	1.0	39	14	30	0	1.0
BestValidationMCC	0.85	0.71	0.83	0.74	1.0	39	14	30	0	1.0
BestValidationAccuracy	0.85	0.71	0.83	0.74	1.0	39	14	30	0	1.0
TestPredictions (Threshold:1.0)
CHEMBL2398352,TN,INACT,0.9900000095367432	CHEMBL3628502,TN,INACT,0.9900000095367432	CHEMBL525720,TP,ACT,1.0	CHEMBL3676967,TP,ACT,1.0	CHEMBL2402902,TN,INACT,0.2199999988079071	CHEMBL1630291,TN,INACT,0.2199999988079071	CHEMBL3676952,TP,ACT,1.0	CHEMBL191947,TN,INACT,0.33000001311302185	CHEMBL2179522,FP,INACT,1.0	CHEMBL2179527,TP,ACT,1.0	CHEMBL1163244,FP,INACT,1.0	CHEMBL2179539,TP,ACT,1.0	CHEMBL481723,TN,INACT,0.9900000095367432	CHEMBL448,FP,INACT,1.0	CHEMBL498277,TP,ACT,1.0	CHEMBL502374,TP,ACT,1.0	CHEMBL3676954,TP,ACT,1.0	CHEMBL2441756,TN,INACT,0.949999988079071	CHEMBL2179547,TP,ACT,1.0	CHEMBL1917229,TN,INACT,0.2199999988079071	CHEMBL480797,FP,INACT,1.0	CHEMBL2179523,FP,INACT,1.0	CHEMBL3676972,TP,ACT,1.0	CHEMBL3612361,TN,INACT,0.38999998569488525	CHEMBL190851,TP,ACT,1.0	CHEMBL231592,FP,INACT,1.0	CHEMBL2381564,FP,INACT,1.0	CHEMBL385227,FP,INACT,1.0	CHEMBL463229,TP,ACT,1.0	CHEMBL3676981,TP,ACT,1.0	CHEMBL2062314,TP,ACT,1.0	CHEMBL3676971,TP,ACT,1.0	CHEMBL46,FP,INACT,1.0	CHEMBL2179543,TP,ACT,1.0	CHEMBL2179551,TP,ACT,1.0	CHEMBL124208,FP,INACT,1.0	CHEMBL1163517,FP,INACT,1.0	CHEMBL2179541,TP,ACT,1.0	CHEMBL504313,TP,ACT,1.0	CHEMBL499635,TP,ACT,1.0	CHEMBL494773,TP,ACT,1.0	CHEMBL478029,TP,ACT,1.0	CHEMBL559599,TP,ACT,1.0	CHEMBL3676951,TP,ACT,1.0	CHEMBL1947048,TN,INACT,0.07000000029802322	CHEMBL1917222,TN,INACT,0.949999988079071	CHEMBL445169,FP,INACT,1.0	CHEMBL376289,TN,INACT,0.0	CHEMBL2179517,TN,INACT,0.8999999761581421	CHEMBL481374,TN,INACT,0.05999999865889549	CHEMBL189788,FP,INACT,1.0	CHEMBL3037926,FP,INACT,1.0	CHEMBL2179966,TP,ACT,1.0	CHEMBL111864,FP,INACT,1.0	CHEMBL2323572,FP,INACT,1.0	CHEMBL2179530,TP,ACT,1.0	CHEMBL457965,FP,INACT,1.0	CHEMBL289469,FP,INACT,1.0	CHEMBL102757,TN,INACT,0.5299999713897705	CHEMBL442890,FN,ACT,0.9900000095367432	CHEMBL502029,TP,ACT,1.0	CHEMBL225853,TN,INACT,0.11999999731779099	CHEMBL503604,TP,ACT,1.0	CHEMBL479429,TN,INACT,0.699999988079071	CHEMBL445298,TP,ACT,1.0	CHEMBL558513,TP,ACT,1.0	CHEMBL480798,TN,INACT,0.5099999904632568	CHEMBL3628498,TN,INACT,0.8899999856948853	CHEMBL2179545,TP,ACT,1.0	CHEMBL508949,FP,INACT,1.0	CHEMBL3121475,TN,INACT,0.9900000095367432	CHEMBL54580,TN,INACT,0.28999999165534973	CHEMBL2381567,FP,INACT,1.0	CHEMBL457737,TP,ACT,1.0	CHEMBL1914487,TN,INACT,0.41999998688697815	CHEMBL54331,TN,INACT,0.28999999165534973	CHEMBL3676988,TP,ACT,1.0	CHEMBL3600667,TN,INACT,0.9399999976158142	CHEMBL3676989,TP,ACT,1.0	CHEMBL3600668,TN,INACT,0.6700000166893005	CHEMBL225851,TN,INACT,0.18000000715255737	CHEMBL524911,TP,ACT,1.0	CHEMBL284237,FP,INACT,1.0	

