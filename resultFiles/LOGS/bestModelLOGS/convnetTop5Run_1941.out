CNNModel CHEMBL4630 adam 0.0001 15 128 0 0.6 False True
Number of active compounds :	1671
Number of inactive compounds :	1671
---------------------------------
Run id: CNNModel_CHEMBL4630_adam_0.0001_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4630_adam_0.0001_15_128_0.6_True/
---------------------------------
Training samples: 2105
Validation samples: 658
--
Training Step: 1  | time: 1.975s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2105
[A[ATraining Step: 2  | total loss: [1m[32m0.62396[0m[0m | time: 3.423s
[2K
| Adam | epoch: 001 | loss: 0.62396 - acc: 0.2812 -- iter: 0064/2105
[A[ATraining Step: 3  | total loss: [1m[32m0.68085[0m[0m | time: 4.740s
[2K
| Adam | epoch: 001 | loss: 0.68085 - acc: 0.4347 -- iter: 0096/2105
[A[ATraining Step: 4  | total loss: [1m[32m0.68941[0m[0m | time: 5.796s
[2K
| Adam | epoch: 001 | loss: 0.68941 - acc: 0.6243 -- iter: 0128/2105
[A[ATraining Step: 5  | total loss: [1m[32m0.69071[0m[0m | time: 6.922s
[2K
| Adam | epoch: 001 | loss: 0.69071 - acc: 0.6681 -- iter: 0160/2105
[A[ATraining Step: 6  | total loss: [1m[32m0.69207[0m[0m | time: 7.972s
[2K
| Adam | epoch: 001 | loss: 0.69207 - acc: 0.5801 -- iter: 0192/2105
[A[ATraining Step: 7  | total loss: [1m[32m0.69262[0m[0m | time: 8.968s
[2K
| Adam | epoch: 001 | loss: 0.69262 - acc: 0.5320 -- iter: 0224/2105
[A[ATraining Step: 8  | total loss: [1m[32m0.69158[0m[0m | time: 10.054s
[2K
| Adam | epoch: 001 | loss: 0.69158 - acc: 0.5668 -- iter: 0256/2105
[A[ATraining Step: 9  | total loss: [1m[32m0.69167[0m[0m | time: 11.080s
[2K
| Adam | epoch: 001 | loss: 0.69167 - acc: 0.5645 -- iter: 0288/2105
[A[ATraining Step: 10  | total loss: [1m[32m0.69071[0m[0m | time: 12.127s
[2K
| Adam | epoch: 001 | loss: 0.69071 - acc: 0.5948 -- iter: 0320/2105
[A[ATraining Step: 11  | total loss: [1m[32m0.69216[0m[0m | time: 13.105s
[2K
| Adam | epoch: 001 | loss: 0.69216 - acc: 0.5499 -- iter: 0352/2105
[A[ATraining Step: 12  | total loss: [1m[32m0.69394[0m[0m | time: 14.084s
[2K
| Adam | epoch: 001 | loss: 0.69394 - acc: 0.4993 -- iter: 0384/2105
[A[ATraining Step: 13  | total loss: [1m[32m0.69345[0m[0m | time: 15.092s
[2K
| Adam | epoch: 001 | loss: 0.69345 - acc: 0.5130 -- iter: 0416/2105
[A[ATraining Step: 14  | total loss: [1m[32m0.69805[0m[0m | time: 16.151s
[2K
| Adam | epoch: 001 | loss: 0.69805 - acc: 0.4182 -- iter: 0448/2105
[A[ATraining Step: 15  | total loss: [1m[32m0.69568[0m[0m | time: 17.115s
[2K
| Adam | epoch: 001 | loss: 0.69568 - acc: 0.4624 -- iter: 0480/2105
[A[ATraining Step: 16  | total loss: [1m[32m0.69318[0m[0m | time: 18.193s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.5117 -- iter: 0512/2105
[A[ATraining Step: 17  | total loss: [1m[32m0.69521[0m[0m | time: 19.226s
[2K
| Adam | epoch: 001 | loss: 0.69521 - acc: 0.4625 -- iter: 0544/2105
[A[ATraining Step: 18  | total loss: [1m[32m0.69508[0m[0m | time: 20.024s
[2K
| Adam | epoch: 001 | loss: 0.69508 - acc: 0.4646 -- iter: 0576/2105
[A[ATraining Step: 19  | total loss: [1m[32m0.69413[0m[0m | time: 20.705s
[2K
| Adam | epoch: 001 | loss: 0.69413 - acc: 0.4868 -- iter: 0608/2105
[A[ATraining Step: 20  | total loss: [1m[32m0.69349[0m[0m | time: 21.373s
[2K
| Adam | epoch: 001 | loss: 0.69349 - acc: 0.5011 -- iter: 0640/2105
[A[ATraining Step: 21  | total loss: [1m[32m0.69419[0m[0m | time: 22.058s
[2K
| Adam | epoch: 001 | loss: 0.69419 - acc: 0.4814 -- iter: 0672/2105
[A[ATraining Step: 22  | total loss: [1m[32m0.69586[0m[0m | time: 22.774s
[2K
| Adam | epoch: 001 | loss: 0.69586 - acc: 0.4307 -- iter: 0704/2105
[A[ATraining Step: 23  | total loss: [1m[32m0.69542[0m[0m | time: 23.449s
[2K
| Adam | epoch: 001 | loss: 0.69542 - acc: 0.4418 -- iter: 0736/2105
[A[ATraining Step: 24  | total loss: [1m[32m0.69533[0m[0m | time: 24.138s
[2K
| Adam | epoch: 001 | loss: 0.69533 - acc: 0.4406 -- iter: 0768/2105
[A[ATraining Step: 25  | total loss: [1m[32m0.69524[0m[0m | time: 24.830s
[2K
| Adam | epoch: 001 | loss: 0.69524 - acc: 0.4397 -- iter: 0800/2105
[A[ATraining Step: 26  | total loss: [1m[32m0.69452[0m[0m | time: 25.568s
[2K
| Adam | epoch: 001 | loss: 0.69452 - acc: 0.4640 -- iter: 0832/2105
[A[ATraining Step: 27  | total loss: [1m[32m0.69431[0m[0m | time: 26.280s
[2K
| Adam | epoch: 001 | loss: 0.69431 - acc: 0.4652 -- iter: 0864/2105
[A[ATraining Step: 28  | total loss: [1m[32m0.69432[0m[0m | time: 26.958s
[2K
| Adam | epoch: 001 | loss: 0.69432 - acc: 0.4583 -- iter: 0896/2105
[A[ATraining Step: 29  | total loss: [1m[32m0.69402[0m[0m | time: 27.634s
[2K
| Adam | epoch: 001 | loss: 0.69402 - acc: 0.4684 -- iter: 0928/2105
[A[ATraining Step: 30  | total loss: [1m[32m0.69426[0m[0m | time: 28.312s
[2K
| Adam | epoch: 001 | loss: 0.69426 - acc: 0.4389 -- iter: 0960/2105
[A[ATraining Step: 31  | total loss: [1m[32m0.69408[0m[0m | time: 29.030s
[2K
| Adam | epoch: 001 | loss: 0.69408 - acc: 0.4458 -- iter: 0992/2105
[A[ATraining Step: 32  | total loss: [1m[32m0.69347[0m[0m | time: 29.738s
[2K
| Adam | epoch: 001 | loss: 0.69347 - acc: 0.5002 -- iter: 1024/2105
[A[ATraining Step: 33  | total loss: [1m[32m0.69348[0m[0m | time: 30.412s
[2K
| Adam | epoch: 001 | loss: 0.69348 - acc: 0.4864 -- iter: 1056/2105
[A[ATraining Step: 34  | total loss: [1m[32m0.69355[0m[0m | time: 31.101s
[2K
| Adam | epoch: 001 | loss: 0.69355 - acc: 0.4692 -- iter: 1088/2105
[A[ATraining Step: 35  | total loss: [1m[32m0.69363[0m[0m | time: 31.790s
[2K
| Adam | epoch: 001 | loss: 0.69363 - acc: 0.4495 -- iter: 1120/2105
[A[ATraining Step: 36  | total loss: [1m[32m0.69344[0m[0m | time: 32.447s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.4790 -- iter: 1152/2105
[A[ATraining Step: 37  | total loss: [1m[32m0.69350[0m[0m | time: 33.115s
[2K
| Adam | epoch: 001 | loss: 0.69350 - acc: 0.4582 -- iter: 1184/2105
[A[ATraining Step: 38  | total loss: [1m[32m0.69331[0m[0m | time: 33.744s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.4786 -- iter: 1216/2105
[A[ATraining Step: 39  | total loss: [1m[32m0.69331[0m[0m | time: 34.388s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.4767 -- iter: 1248/2105
[A[ATraining Step: 40  | total loss: [1m[32m0.69332[0m[0m | time: 35.047s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.4635 -- iter: 1280/2105
[A[ATraining Step: 41  | total loss: [1m[32m0.69332[0m[0m | time: 35.736s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.4530 -- iter: 1312/2105
[A[ATraining Step: 42  | total loss: [1m[32m0.69330[0m[0m | time: 36.440s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.4390 -- iter: 1344/2105
[A[ATraining Step: 43  | total loss: [1m[32m0.69330[0m[0m | time: 37.128s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.4222 -- iter: 1376/2105
[A[ATraining Step: 44  | total loss: [1m[32m0.69324[0m[0m | time: 37.821s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.4519 -- iter: 1408/2105
[A[ATraining Step: 45  | total loss: [1m[32m0.69326[0m[0m | time: 38.508s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.4441 -- iter: 1440/2105
[A[ATraining Step: 46  | total loss: [1m[32m0.69320[0m[0m | time: 39.187s
[2K
| Adam | epoch: 001 | loss: 0.69320 - acc: 0.4534 -- iter: 1472/2105
[A[ATraining Step: 47  | total loss: [1m[32m0.69321[0m[0m | time: 39.867s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.4610 -- iter: 1504/2105
[A[ATraining Step: 48  | total loss: [1m[32m0.69319[0m[0m | time: 40.512s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.4723 -- iter: 1536/2105
[A[ATraining Step: 49  | total loss: [1m[32m0.69302[0m[0m | time: 41.150s
[2K
| Adam | epoch: 001 | loss: 0.69302 - acc: 0.5112 -- iter: 1568/2105
[A[ATraining Step: 50  | total loss: [1m[32m0.69314[0m[0m | time: 41.801s
[2K
| Adam | epoch: 001 | loss: 0.69314 - acc: 0.4901 -- iter: 1600/2105
[A[ATraining Step: 51  | total loss: [1m[32m0.69300[0m[0m | time: 42.478s
[2K
| Adam | epoch: 001 | loss: 0.69300 - acc: 0.5107 -- iter: 1632/2105
[A[ATraining Step: 52  | total loss: [1m[32m0.69298[0m[0m | time: 43.201s
[2K
| Adam | epoch: 001 | loss: 0.69298 - acc: 0.5138 -- iter: 1664/2105
[A[ATraining Step: 53  | total loss: [1m[32m0.69296[0m[0m | time: 44.606s
[2K
| Adam | epoch: 001 | loss: 0.69296 - acc: 0.5163 -- iter: 1696/2105
[A[ATraining Step: 54  | total loss: [1m[32m0.69278[0m[0m | time: 46.157s
[2K
| Adam | epoch: 001 | loss: 0.69278 - acc: 0.5412 -- iter: 1728/2105
[A[ATraining Step: 55  | total loss: [1m[32m0.69271[0m[0m | time: 50.228s
[2K
| Adam | epoch: 001 | loss: 0.69271 - acc: 0.5442 -- iter: 1760/2105
[A[ATraining Step: 56  | total loss: [1m[32m0.69286[0m[0m | time: 54.990s
[2K
| Adam | epoch: 001 | loss: 0.69286 - acc: 0.5292 -- iter: 1792/2105
[A[ATraining Step: 57  | total loss: [1m[32m0.69295[0m[0m | time: 59.708s
[2K
| Adam | epoch: 001 | loss: 0.69295 - acc: 0.5208 -- iter: 1824/2105
[A[ATraining Step: 58  | total loss: [1m[32m0.69293[0m[0m | time: 66.626s
[2K
| Adam | epoch: 001 | loss: 0.69293 - acc: 0.5223 -- iter: 1856/2105
[A[ATraining Step: 59  | total loss: [1m[32m0.69289[0m[0m | time: 73.661s
[2K
| Adam | epoch: 001 | loss: 0.69289 - acc: 0.5235 -- iter: 1888/2105
[A[ATraining Step: 60  | total loss: [1m[32m0.69263[0m[0m | time: 80.064s
[2K
| Adam | epoch: 001 | loss: 0.69263 - acc: 0.5410 -- iter: 1920/2105
[A[ATraining Step: 61  | total loss: [1m[32m0.69290[0m[0m | time: 84.461s
[2K
| Adam | epoch: 001 | loss: 0.69290 - acc: 0.5235 -- iter: 1952/2105
[A[ATraining Step: 62  | total loss: [1m[32m0.69336[0m[0m | time: 88.076s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4963 -- iter: 1984/2105
[A[ATraining Step: 63  | total loss: [1m[32m0.69339[0m[0m | time: 89.186s
[2K
| Adam | epoch: 001 | loss: 0.69339 - acc: 0.4928 -- iter: 2016/2105
[A[ATraining Step: 64  | total loss: [1m[32m0.69323[0m[0m | time: 90.342s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.5016 -- iter: 2048/2105
[A[ATraining Step: 65  | total loss: [1m[32m0.69310[0m[0m | time: 91.592s
[2K
| Adam | epoch: 001 | loss: 0.69310 - acc: 0.5091 -- iter: 2080/2105
[A[ATraining Step: 66  | total loss: [1m[32m0.69297[0m[0m | time: 98.232s
[2K
| Adam | epoch: 001 | loss: 0.69297 - acc: 0.5156 | val_loss: 0.69337 - val_acc: 0.4894 -- iter: 2105/2105
--
Training Step: 67  | total loss: [1m[32m0.69301[0m[0m | time: 1.297s
[2K
| Adam | epoch: 002 | loss: 0.69301 - acc: 0.5113 -- iter: 0032/2105
[A[ATraining Step: 68  | total loss: [1m[32m0.69309[0m[0m | time: 2.845s
[2K
| Adam | epoch: 002 | loss: 0.69309 - acc: 0.5076 -- iter: 0064/2105
[A[ATraining Step: 69  | total loss: [1m[32m0.69307[0m[0m | time: 4.013s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5067 -- iter: 0096/2105
[A[ATraining Step: 70  | total loss: [1m[32m0.69314[0m[0m | time: 14.940s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5023 -- iter: 0128/2105
[A[ATraining Step: 71  | total loss: [1m[32m0.69335[0m[0m | time: 21.541s
[2K
| Adam | epoch: 002 | loss: 0.69335 - acc: 0.4914 -- iter: 0160/2105
[A[ATraining Step: 72  | total loss: [1m[32m0.69344[0m[0m | time: 30.584s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.4853 -- iter: 0192/2105
[A[ATraining Step: 73  | total loss: [1m[32m0.69372[0m[0m | time: 34.913s
[2K
| Adam | epoch: 002 | loss: 0.69372 - acc: 0.4696 -- iter: 0224/2105
[A[ATraining Step: 74  | total loss: [1m[32m0.69367[0m[0m | time: 44.095s
[2K
| Adam | epoch: 002 | loss: 0.69367 - acc: 0.4729 -- iter: 0256/2105
[A[ATraining Step: 75  | total loss: [1m[32m0.69355[0m[0m | time: 51.553s
[2K
| Adam | epoch: 002 | loss: 0.69355 - acc: 0.4792 -- iter: 0288/2105
[A[ATraining Step: 76  | total loss: [1m[32m0.69357[0m[0m | time: 55.762s
[2K
| Adam | epoch: 002 | loss: 0.69357 - acc: 0.4781 -- iter: 0320/2105
[A[ATraining Step: 77  | total loss: [1m[32m0.69357[0m[0m | time: 59.308s
[2K
| Adam | epoch: 002 | loss: 0.69357 - acc: 0.4771 -- iter: 0352/2105
[A[ATraining Step: 78  | total loss: [1m[32m0.69375[0m[0m | time: 60.404s
[2K
| Adam | epoch: 002 | loss: 0.69375 - acc: 0.4632 -- iter: 0384/2105
[A[ATraining Step: 79  | total loss: [1m[32m0.69385[0m[0m | time: 61.621s
[2K
| Adam | epoch: 002 | loss: 0.69385 - acc: 0.4541 -- iter: 0416/2105
[A[ATraining Step: 80  | total loss: [1m[32m0.69378[0m[0m | time: 62.972s
[2K
| Adam | epoch: 002 | loss: 0.69378 - acc: 0.4588 -- iter: 0448/2105
[A[ATraining Step: 81  | total loss: [1m[32m0.69381[0m[0m | time: 64.344s
[2K
| Adam | epoch: 002 | loss: 0.69381 - acc: 0.4534 -- iter: 0480/2105
[A[ATraining Step: 82  | total loss: [1m[32m0.69369[0m[0m | time: 65.802s
[2K
| Adam | epoch: 002 | loss: 0.69369 - acc: 0.4643 -- iter: 0512/2105
[A[ATraining Step: 83  | total loss: [1m[32m0.69371[0m[0m | time: 67.328s
[2K
| Adam | epoch: 002 | loss: 0.69371 - acc: 0.4585 -- iter: 0544/2105
[A[ATraining Step: 84  | total loss: [1m[32m0.69367[0m[0m | time: 68.877s
[2K
| Adam | epoch: 002 | loss: 0.69367 - acc: 0.4596 -- iter: 0576/2105
[A[ATraining Step: 85  | total loss: [1m[32m0.69361[0m[0m | time: 70.240s
[2K
| Adam | epoch: 002 | loss: 0.69361 - acc: 0.4636 -- iter: 0608/2105
[A[ATraining Step: 86  | total loss: [1m[32m0.69352[0m[0m | time: 71.757s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.4735 -- iter: 0640/2105
[A[ATraining Step: 87  | total loss: [1m[32m0.69352[0m[0m | time: 73.259s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.4668 -- iter: 0672/2105
[A[ATraining Step: 88  | total loss: [1m[32m0.69351[0m[0m | time: 82.259s
[2K
| Adam | epoch: 002 | loss: 0.69351 - acc: 0.4607 -- iter: 0704/2105
[A[ATraining Step: 89  | total loss: [1m[32m0.69346[0m[0m | time: 91.951s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.4678 -- iter: 0736/2105
[A[ATraining Step: 90  | total loss: [1m[32m0.69342[0m[0m | time: 93.297s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4710 -- iter: 0768/2105
[A[ATraining Step: 91  | total loss: [1m[32m0.69342[0m[0m | time: 94.714s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4583 -- iter: 0800/2105
[A[ATraining Step: 92  | total loss: [1m[32m0.69339[0m[0m | time: 96.030s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.4687 -- iter: 0832/2105
[A[ATraining Step: 93  | total loss: [1m[32m0.69337[0m[0m | time: 97.328s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4687 -- iter: 0864/2105
[A[ATraining Step: 94  | total loss: [1m[32m0.69334[0m[0m | time: 98.749s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4687 -- iter: 0896/2105
[A[ATraining Step: 95  | total loss: [1m[32m0.69334[0m[0m | time: 100.291s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4593 -- iter: 0928/2105
[A[ATraining Step: 96  | total loss: [1m[32m0.69334[0m[0m | time: 101.656s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4540 -- iter: 0960/2105
[A[ATraining Step: 97  | total loss: [1m[32m0.69331[0m[0m | time: 102.735s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4711 -- iter: 0992/2105
[A[ATraining Step: 98  | total loss: [1m[32m0.69327[0m[0m | time: 104.273s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4928 -- iter: 1024/2105
[A[ATraining Step: 99  | total loss: [1m[32m0.69324[0m[0m | time: 105.801s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4997 -- iter: 1056/2105
[A[ATraining Step: 100  | total loss: [1m[32m0.69322[0m[0m | time: 107.054s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.5060 -- iter: 1088/2105
[A[ATraining Step: 101  | total loss: [1m[32m0.69324[0m[0m | time: 112.574s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4929 -- iter: 1120/2105
[A[ATraining Step: 102  | total loss: [1m[32m0.69328[0m[0m | time: 121.727s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.4780 -- iter: 1152/2105
[A[ATraining Step: 103  | total loss: [1m[32m0.69320[0m[0m | time: 124.023s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5052 -- iter: 1184/2105
[A[ATraining Step: 104  | total loss: [1m[32m0.69322[0m[0m | time: 136.472s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4953 -- iter: 1216/2105
[A[ATraining Step: 105  | total loss: [1m[32m0.69322[0m[0m | time: 140.333s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4895 -- iter: 1248/2105
[A[ATraining Step: 106  | total loss: [1m[32m0.69324[0m[0m | time: 151.196s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4812 -- iter: 1280/2105
[A[ATraining Step: 107  | total loss: [1m[32m0.69327[0m[0m | time: 155.098s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4643 -- iter: 1312/2105
[A[ATraining Step: 108  | total loss: [1m[32m0.69325[0m[0m | time: 156.433s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4710 -- iter: 1344/2105
[A[ATraining Step: 109  | total loss: [1m[32m0.69324[0m[0m | time: 157.516s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4770 -- iter: 1376/2105
[A[ATraining Step: 110  | total loss: [1m[32m0.69324[0m[0m | time: 158.826s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4762 -- iter: 1408/2105
[A[ATraining Step: 111  | total loss: [1m[32m0.69323[0m[0m | time: 160.114s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.4661 -- iter: 1440/2105
[A[ATraining Step: 112  | total loss: [1m[32m0.69321[0m[0m | time: 161.546s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4757 -- iter: 1472/2105
[A[ATraining Step: 113  | total loss: [1m[32m0.69321[0m[0m | time: 163.009s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4813 -- iter: 1504/2105
[A[ATraining Step: 114  | total loss: [1m[32m0.69319[0m[0m | time: 164.383s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.4894 -- iter: 1536/2105
[A[ATraining Step: 115  | total loss: [1m[32m0.69326[0m[0m | time: 165.816s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4655 -- iter: 1568/2105
[A[ATraining Step: 116  | total loss: [1m[32m0.69328[0m[0m | time: 167.335s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.4564 -- iter: 1600/2105
[A[ATraining Step: 117  | total loss: [1m[32m0.69331[0m[0m | time: 168.746s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4452 -- iter: 1632/2105
[A[ATraining Step: 118  | total loss: [1m[32m0.69326[0m[0m | time: 170.115s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4663 -- iter: 1664/2105
[A[ATraining Step: 119  | total loss: [1m[32m0.69326[0m[0m | time: 174.343s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4665 -- iter: 1696/2105
[A[ATraining Step: 120  | total loss: [1m[32m0.69327[0m[0m | time: 176.472s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4605 -- iter: 1728/2105
[A[ATraining Step: 121  | total loss: [1m[32m0.69326[0m[0m | time: 178.096s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4644 -- iter: 1760/2105
[A[ATraining Step: 122  | total loss: [1m[32m0.69327[0m[0m | time: 181.152s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4586 -- iter: 1792/2105
[A[ATraining Step: 123  | total loss: [1m[32m0.69325[0m[0m | time: 182.708s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4628 -- iter: 1824/2105
[A[ATraining Step: 124  | total loss: [1m[32m0.69326[0m[0m | time: 188.348s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4602 -- iter: 1856/2105
[A[ATraining Step: 125  | total loss: [1m[32m0.69325[0m[0m | time: 192.274s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4705 -- iter: 1888/2105
[A[ATraining Step: 126  | total loss: [1m[32m0.69324[0m[0m | time: 193.580s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4734 -- iter: 1920/2105
[A[ATraining Step: 127  | total loss: [1m[32m0.69325[0m[0m | time: 195.101s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4636 -- iter: 1952/2105
[A[ATraining Step: 128  | total loss: [1m[32m0.69322[0m[0m | time: 196.613s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4828 -- iter: 1984/2105
[A[ATraining Step: 129  | total loss: [1m[32m0.69321[0m[0m | time: 198.032s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4908 -- iter: 2016/2105
[A[ATraining Step: 130  | total loss: [1m[32m0.69322[0m[0m | time: 199.649s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4823 -- iter: 2048/2105
[A[ATraining Step: 131  | total loss: [1m[32m0.69322[0m[0m | time: 201.941s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4810 -- iter: 2080/2105
[A[ATraining Step: 132  | total loss: [1m[32m0.69321[0m[0m | time: 251.279s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4891 | val_loss: 0.69315 - val_acc: 0.4894 -- iter: 2105/2105
--
Training Step: 133  | total loss: [1m[32m0.69321[0m[0m | time: 8.546s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.4777 -- iter: 0032/2105
[A[ATraining Step: 134  | total loss: [1m[32m0.69320[0m[0m | time: 9.652s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.4820 -- iter: 0064/2105
[A[ATraining Step: 135  | total loss: [1m[32m0.69319[0m[0m | time: 11.147s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.4858 -- iter: 0096/2105
[A[ATraining Step: 136  | total loss: [1m[32m0.69318[0m[0m | time: 12.572s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.4903 -- iter: 0128/2105
[A[ATraining Step: 137  | total loss: [1m[32m0.69317[0m[0m | time: 13.890s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4913 -- iter: 0160/2105
[A[ATraining Step: 138  | total loss: [1m[32m0.69319[0m[0m | time: 15.383s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.4828 -- iter: 0192/2105
[A[ATraining Step: 139  | total loss: [1m[32m0.69318[0m[0m | time: 16.775s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.4907 -- iter: 0224/2105
[A[ATraining Step: 140  | total loss: [1m[32m0.69318[0m[0m | time: 17.996s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.4917 -- iter: 0256/2105
[A[ATraining Step: 141  | total loss: [1m[32m0.69317[0m[0m | time: 19.459s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4956 -- iter: 0288/2105
[A[ATraining Step: 142  | total loss: [1m[32m0.69316[0m[0m | time: 20.865s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.4992 -- iter: 0320/2105
[A[ATraining Step: 143  | total loss: [1m[32m0.69316[0m[0m | time: 22.269s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.4993 -- iter: 0352/2105
[A[ATraining Step: 144  | total loss: [1m[32m0.69318[0m[0m | time: 23.510s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.4868 -- iter: 0384/2105
[A[ATraining Step: 145  | total loss: [1m[32m0.69319[0m[0m | time: 24.861s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.4819 -- iter: 0416/2105
[A[ATraining Step: 146  | total loss: [1m[32m0.69318[0m[0m | time: 26.351s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.4962 -- iter: 0448/2105
[A[ATraining Step: 147  | total loss: [1m[32m0.69315[0m[0m | time: 27.766s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5153 -- iter: 0480/2105
[A[ATraining Step: 148  | total loss: [1m[32m0.69313[0m[0m | time: 29.005s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5232 -- iter: 0512/2105
[A[ATraining Step: 149  | total loss: [1m[32m0.69315[0m[0m | time: 30.014s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5146 -- iter: 0544/2105
[A[ATraining Step: 150  | total loss: [1m[32m0.69319[0m[0m | time: 31.026s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5007 -- iter: 0576/2105
[A[ATraining Step: 151  | total loss: [1m[32m0.69320[0m[0m | time: 32.031s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.4943 -- iter: 0608/2105
[A[ATraining Step: 152  | total loss: [1m[32m0.69318[0m[0m | time: 32.974s
[2K
| Adam | epoch: 003 | loss: 0.69318 - acc: 0.5012 -- iter: 0640/2105
[A[ATraining Step: 153  | total loss: [1m[32m0.69317[0m[0m | time: 34.072s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4979 -- iter: 0672/2105
[A[ATraining Step: 154  | total loss: [1m[32m0.69321[0m[0m | time: 35.272s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.4856 -- iter: 0704/2105
[A[ATraining Step: 155  | total loss: [1m[32m0.69316[0m[0m | time: 36.375s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.4996 -- iter: 0736/2105
[A[ATraining Step: 156  | total loss: [1m[32m0.69315[0m[0m | time: 37.235s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.4996 -- iter: 0768/2105
[A[ATraining Step: 157  | total loss: [1m[32m0.69314[0m[0m | time: 38.198s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.4996 -- iter: 0800/2105
[A[ATraining Step: 158  | total loss: [1m[32m0.69317[0m[0m | time: 39.146s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4903 -- iter: 0832/2105
[A[ATraining Step: 159  | total loss: [1m[32m0.69316[0m[0m | time: 40.133s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.4944 -- iter: 0864/2105
[A[ATraining Step: 160  | total loss: [1m[32m0.69315[0m[0m | time: 41.156s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.5012 -- iter: 0896/2105
[A[ATraining Step: 161  | total loss: [1m[32m0.69314[0m[0m | time: 42.190s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.5042 -- iter: 0928/2105
[A[ATraining Step: 162  | total loss: [1m[32m0.69315[0m[0m | time: 43.185s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.4944 -- iter: 0960/2105
[A[ATraining Step: 163  | total loss: [1m[32m0.69313[0m[0m | time: 44.167s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5106 -- iter: 0992/2105
[A[ATraining Step: 164  | total loss: [1m[32m0.69313[0m[0m | time: 45.004s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5064 -- iter: 1024/2105
[A[ATraining Step: 165  | total loss: [1m[32m0.69314[0m[0m | time: 46.018s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.4933 -- iter: 1056/2105
[A[ATraining Step: 166  | total loss: [1m[32m0.69314[0m[0m | time: 47.155s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.4908 -- iter: 1088/2105
[A[ATraining Step: 167  | total loss: [1m[32m0.69315[0m[0m | time: 48.370s
[2K
| Adam | epoch: 003 | loss: 0.69315 - acc: 0.4949 -- iter: 1120/2105
[A[ATraining Step: 168  | total loss: [1m[32m0.69314[0m[0m | time: 49.267s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.5141 -- iter: 1152/2105
[A[ATraining Step: 169  | total loss: [1m[32m0.69313[0m[0m | time: 50.256s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5315 -- iter: 1184/2105
[A[ATraining Step: 170  | total loss: [1m[32m0.69312[0m[0m | time: 51.257s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.5408 -- iter: 1216/2105
[A[ATraining Step: 171  | total loss: [1m[32m0.69311[0m[0m | time: 52.266s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5430 -- iter: 1248/2105
[A[ATraining Step: 172  | total loss: [1m[32m0.69311[0m[0m | time: 53.256s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5449 -- iter: 1280/2105
[A[ATraining Step: 173  | total loss: [1m[32m0.69311[0m[0m | time: 54.243s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5404 -- iter: 1312/2105
[A[ATraining Step: 174  | total loss: [1m[32m0.69311[0m[0m | time: 55.195s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5270 -- iter: 1344/2105
[A[ATraining Step: 175  | total loss: [1m[32m0.69311[0m[0m | time: 56.269s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5181 -- iter: 1376/2105
[A[ATraining Step: 176  | total loss: [1m[32m0.69311[0m[0m | time: 57.340s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5163 -- iter: 1408/2105
[A[ATraining Step: 177  | total loss: [1m[32m0.69311[0m[0m | time: 58.565s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5146 -- iter: 1440/2105
[A[ATraining Step: 178  | total loss: [1m[32m0.69310[0m[0m | time: 59.776s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5225 -- iter: 1472/2105
[A[ATraining Step: 179  | total loss: [1m[32m0.69310[0m[0m | time: 60.623s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5234 -- iter: 1504/2105
[A[ATraining Step: 180  | total loss: [1m[32m0.69309[0m[0m | time: 61.536s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5180 -- iter: 1536/2105
[A[ATraining Step: 181  | total loss: [1m[32m0.69311[0m[0m | time: 62.520s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5099 -- iter: 1568/2105
[A[ATraining Step: 182  | total loss: [1m[32m0.69307[0m[0m | time: 63.486s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5183 -- iter: 1600/2105
[A[ATraining Step: 183  | total loss: [1m[32m0.69307[0m[0m | time: 64.425s
[2K
| Adam | epoch: 003 | loss: 0.69307 - acc: 0.5165 -- iter: 1632/2105
[A[ATraining Step: 184  | total loss: [1m[32m0.69305[0m[0m | time: 65.759s
[2K
| Adam | epoch: 003 | loss: 0.69305 - acc: 0.5179 -- iter: 1664/2105
[A[ATraining Step: 185  | total loss: [1m[32m0.69304[0m[0m | time: 67.223s
[2K
| Adam | epoch: 003 | loss: 0.69304 - acc: 0.5130 -- iter: 1696/2105
[A[ATraining Step: 186  | total loss: [1m[32m0.69308[0m[0m | time: 68.508s
[2K
| Adam | epoch: 003 | loss: 0.69308 - acc: 0.5055 -- iter: 1728/2105
[A[ATraining Step: 187  | total loss: [1m[32m0.69306[0m[0m | time: 69.699s
[2K
| Adam | epoch: 003 | loss: 0.69306 - acc: 0.5080 -- iter: 1760/2105
[A[ATraining Step: 188  | total loss: [1m[32m0.69310[0m[0m | time: 71.182s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.4979 -- iter: 1792/2105
[A[ATraining Step: 189  | total loss: [1m[32m0.69312[0m[0m | time: 72.639s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.4950 -- iter: 1824/2105
[A[ATraining Step: 190  | total loss: [1m[32m0.69308[0m[0m | time: 74.129s
[2K
| Adam | epoch: 003 | loss: 0.69308 - acc: 0.5080 -- iter: 1856/2105
[A[ATraining Step: 191  | total loss: [1m[32m0.69305[0m[0m | time: 75.263s
[2K
| Adam | epoch: 003 | loss: 0.69305 - acc: 0.5259 -- iter: 1888/2105
[A[ATraining Step: 192  | total loss: [1m[32m0.69305[0m[0m | time: 76.654s
[2K
| Adam | epoch: 003 | loss: 0.69305 - acc: 0.5296 -- iter: 1920/2105
[A[ATraining Step: 193  | total loss: [1m[32m0.69305[0m[0m | time: 78.050s
[2K
| Adam | epoch: 003 | loss: 0.69305 - acc: 0.5297 -- iter: 1952/2105
[A[ATraining Step: 194  | total loss: [1m[32m0.69309[0m[0m | time: 85.484s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5205 -- iter: 1984/2105
[A[ATraining Step: 195  | total loss: [1m[32m0.69313[0m[0m | time: 91.339s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5122 -- iter: 2016/2105
[A[ATraining Step: 196  | total loss: [1m[32m0.69324[0m[0m | time: 94.667s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4985 -- iter: 2048/2105
[A[ATraining Step: 197  | total loss: [1m[32m0.69322[0m[0m | time: 95.934s
[2K
| Adam | epoch: 003 | loss: 0.69322 - acc: 0.4986 -- iter: 2080/2105
[A[ATraining Step: 198  | total loss: [1m[32m0.69324[0m[0m | time: 102.891s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4925 | val_loss: 0.69311 - val_acc: 0.4894 -- iter: 2105/2105
--
Training Step: 199  | total loss: [1m[32m0.69320[0m[0m | time: 1.468s
[2K
| Adam | epoch: 004 | loss: 0.69320 - acc: 0.4995 -- iter: 0032/2105
[A[ATraining Step: 200  | total loss: [1m[32m0.69313[0m[0m | time: 31.804s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.5089 | val_loss: 0.69312 - val_acc: 0.4894 -- iter: 0064/2105
--
Training Step: 201  | total loss: [1m[32m0.69311[0m[0m | time: 35.108s
[2K
| Adam | epoch: 004 | loss: 0.69311 - acc: 0.5101 -- iter: 0096/2105
[A[ATraining Step: 202  | total loss: [1m[32m0.69310[0m[0m | time: 36.093s
[2K
| Adam | epoch: 004 | loss: 0.69310 - acc: 0.5110 -- iter: 0128/2105
[A[ATraining Step: 203  | total loss: [1m[32m0.69297[0m[0m | time: 37.116s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5287 -- iter: 0160/2105
[A[ATraining Step: 204  | total loss: [1m[32m0.69297[0m[0m | time: 38.424s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5258 -- iter: 0192/2105
[A[ATraining Step: 205  | total loss: [1m[32m0.69289[0m[0m | time: 39.886s
[2K
| Adam | epoch: 004 | loss: 0.69289 - acc: 0.5326 -- iter: 0224/2105
[A[ATraining Step: 206  | total loss: [1m[32m0.69297[0m[0m | time: 41.302s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5231 -- iter: 0256/2105
[A[ATraining Step: 207  | total loss: [1m[32m0.69289[0m[0m | time: 42.651s
[2K
| Adam | epoch: 004 | loss: 0.69289 - acc: 0.5302 -- iter: 0288/2105
[A[ATraining Step: 208  | total loss: [1m[32m0.69278[0m[0m | time: 44.165s
[2K
| Adam | epoch: 004 | loss: 0.69278 - acc: 0.5365 -- iter: 0320/2105
[A[ATraining Step: 209  | total loss: [1m[32m0.69288[0m[0m | time: 45.746s
[2K
| Adam | epoch: 004 | loss: 0.69288 - acc: 0.5298 -- iter: 0352/2105
[A[ATraining Step: 210  | total loss: [1m[32m0.69303[0m[0m | time: 49.212s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5174 -- iter: 0384/2105
[A[ATraining Step: 211  | total loss: [1m[32m0.69328[0m[0m | time: 63.928s
[2K
| Adam | epoch: 004 | loss: 0.69328 - acc: 0.5000 -- iter: 0416/2105
[A[ATraining Step: 212  | total loss: [1m[32m0.69323[0m[0m | time: 73.132s
[2K
| Adam | epoch: 004 | loss: 0.69323 - acc: 0.5032 -- iter: 0448/2105
[A[ATraining Step: 213  | total loss: [1m[32m0.69324[0m[0m | time: 80.897s
[2K
| Adam | epoch: 004 | loss: 0.69324 - acc: 0.4997 -- iter: 0480/2105
[A[ATraining Step: 214  | total loss: [1m[32m0.69304[0m[0m | time: 82.276s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5122 -- iter: 0512/2105
[A[ATraining Step: 215  | total loss: [1m[32m0.69300[0m[0m | time: 87.291s
[2K
| Adam | epoch: 004 | loss: 0.69300 - acc: 0.5141 -- iter: 0544/2105
[A[ATraining Step: 216  | total loss: [1m[32m0.69292[0m[0m | time: 88.499s
[2K
| Adam | epoch: 004 | loss: 0.69292 - acc: 0.5190 -- iter: 0576/2105
[A[ATraining Step: 217  | total loss: [1m[32m0.69297[0m[0m | time: 89.915s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5140 -- iter: 0608/2105
[A[ATraining Step: 218  | total loss: [1m[32m0.69320[0m[0m | time: 91.331s
[2K
| Adam | epoch: 004 | loss: 0.69320 - acc: 0.4969 -- iter: 0640/2105
[A[ATraining Step: 219  | total loss: [1m[32m0.69305[0m[0m | time: 92.874s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5066 -- iter: 0672/2105
[A[ATraining Step: 220  | total loss: [1m[32m0.69319[0m[0m | time: 94.131s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.4935 -- iter: 0704/2105
[A[ATraining Step: 221  | total loss: [1m[32m0.69319[0m[0m | time: 95.657s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.4910 -- iter: 0736/2105
[A[ATraining Step: 222  | total loss: [1m[32m0.69313[0m[0m | time: 97.144s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.4981 -- iter: 0768/2105
[A[ATraining Step: 223  | total loss: [1m[32m0.69314[0m[0m | time: 98.424s
[2K
| Adam | epoch: 004 | loss: 0.69314 - acc: 0.4952 -- iter: 0800/2105
[A[ATraining Step: 224  | total loss: [1m[32m0.69303[0m[0m | time: 101.378s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5051 -- iter: 0832/2105
[A[ATraining Step: 225  | total loss: [1m[32m0.69305[0m[0m | time: 107.108s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5014 -- iter: 0864/2105
[A[ATraining Step: 226  | total loss: [1m[32m0.69309[0m[0m | time: 117.044s
[2K
| Adam | epoch: 004 | loss: 0.69309 - acc: 0.4950 -- iter: 0896/2105
[A[ATraining Step: 227  | total loss: [1m[32m0.69310[0m[0m | time: 122.615s
[2K
| Adam | epoch: 004 | loss: 0.69310 - acc: 0.4893 -- iter: 0928/2105
[A[ATraining Step: 228  | total loss: [1m[32m0.69306[0m[0m | time: 123.999s
[2K
| Adam | epoch: 004 | loss: 0.69306 - acc: 0.4966 -- iter: 0960/2105
[A[ATraining Step: 229  | total loss: [1m[32m0.69304[0m[0m | time: 125.261s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5001 -- iter: 0992/2105
[A[ATraining Step: 230  | total loss: [1m[32m0.69307[0m[0m | time: 126.512s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.4938 -- iter: 1024/2105
[A[ATraining Step: 231  | total loss: [1m[32m0.69311[0m[0m | time: 127.835s
[2K
| Adam | epoch: 004 | loss: 0.69311 - acc: 0.4788 -- iter: 1056/2105
[A[ATraining Step: 232  | total loss: [1m[32m0.69313[0m[0m | time: 129.317s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.4778 -- iter: 1088/2105
[A[ATraining Step: 233  | total loss: [1m[32m0.69309[0m[0m | time: 130.703s
[2K
| Adam | epoch: 004 | loss: 0.69309 - acc: 0.4894 -- iter: 1120/2105
[A[ATraining Step: 234  | total loss: [1m[32m0.69311[0m[0m | time: 132.143s
[2K
| Adam | epoch: 004 | loss: 0.69311 - acc: 0.4905 -- iter: 1152/2105
[A[ATraining Step: 235  | total loss: [1m[32m0.69310[0m[0m | time: 133.500s
[2K
| Adam | epoch: 004 | loss: 0.69310 - acc: 0.4977 -- iter: 1184/2105
[A[ATraining Step: 236  | total loss: [1m[32m0.69309[0m[0m | time: 135.147s
[2K
| Adam | epoch: 004 | loss: 0.69309 - acc: 0.5010 -- iter: 1216/2105
[A[ATraining Step: 237  | total loss: [1m[32m0.69311[0m[0m | time: 136.714s
[2K
| Adam | epoch: 004 | loss: 0.69311 - acc: 0.4947 -- iter: 1248/2105
[A[ATraining Step: 238  | total loss: [1m[32m0.69309[0m[0m | time: 138.442s
[2K
| Adam | epoch: 004 | loss: 0.69309 - acc: 0.5077 -- iter: 1280/2105
[A[ATraining Step: 239  | total loss: [1m[32m0.69304[0m[0m | time: 145.734s
[2K
| Adam | epoch: 004 | loss: 0.69304 - acc: 0.5257 -- iter: 1312/2105
[A[ATraining Step: 240  | total loss: [1m[32m0.69302[0m[0m | time: 155.527s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5387 -- iter: 1344/2105
[A[ATraining Step: 241  | total loss: [1m[32m0.69298[0m[0m | time: 164.555s
[2K
| Adam | epoch: 004 | loss: 0.69298 - acc: 0.5474 -- iter: 1376/2105
[A[ATraining Step: 242  | total loss: [1m[32m0.69290[0m[0m | time: 170.287s
[2K
| Adam | epoch: 004 | loss: 0.69290 - acc: 0.5520 -- iter: 1408/2105
[A[ATraining Step: 243  | total loss: [1m[32m0.69285[0m[0m | time: 174.190s
[2K
| Adam | epoch: 004 | loss: 0.69285 - acc: 0.5499 -- iter: 1440/2105
[A[ATraining Step: 244  | total loss: [1m[32m0.69295[0m[0m | time: 175.567s
[2K
| Adam | epoch: 004 | loss: 0.69295 - acc: 0.5356 -- iter: 1472/2105
[A[ATraining Step: 245  | total loss: [1m[32m0.69289[0m[0m | time: 176.711s
[2K
| Adam | epoch: 004 | loss: 0.69289 - acc: 0.5351 -- iter: 1504/2105
[A[ATraining Step: 246  | total loss: [1m[32m0.69289[0m[0m | time: 178.011s
[2K
| Adam | epoch: 004 | loss: 0.69289 - acc: 0.5316 -- iter: 1536/2105
[A[ATraining Step: 247  | total loss: [1m[32m0.69284[0m[0m | time: 179.274s
[2K
| Adam | epoch: 004 | loss: 0.69284 - acc: 0.5316 -- iter: 1568/2105
[A[ATraining Step: 248  | total loss: [1m[32m0.69266[0m[0m | time: 180.775s
[2K
| Adam | epoch: 004 | loss: 0.69266 - acc: 0.5378 -- iter: 1600/2105
[A[ATraining Step: 249  | total loss: [1m[32m0.69253[0m[0m | time: 182.263s
[2K
| Adam | epoch: 004 | loss: 0.69253 - acc: 0.5403 -- iter: 1632/2105
[A[ATraining Step: 250  | total loss: [1m[32m0.69243[0m[0m | time: 183.600s
[2K
| Adam | epoch: 004 | loss: 0.69243 - acc: 0.5425 -- iter: 1664/2105
[A[ATraining Step: 251  | total loss: [1m[32m0.69261[0m[0m | time: 185.017s
[2K
| Adam | epoch: 004 | loss: 0.69261 - acc: 0.5351 -- iter: 1696/2105
[A[ATraining Step: 252  | total loss: [1m[32m0.69221[0m[0m | time: 186.417s
[2K
| Adam | epoch: 004 | loss: 0.69221 - acc: 0.5472 -- iter: 1728/2105
[A[ATraining Step: 253  | total loss: [1m[32m0.69237[0m[0m | time: 187.899s
[2K
| Adam | epoch: 004 | loss: 0.69237 - acc: 0.5394 -- iter: 1760/2105
[A[ATraining Step: 254  | total loss: [1m[32m0.69254[0m[0m | time: 189.145s
[2K
| Adam | epoch: 004 | loss: 0.69254 - acc: 0.5323 -- iter: 1792/2105
[A[ATraining Step: 255  | total loss: [1m[32m0.69207[0m[0m | time: 195.523s
[2K
| Adam | epoch: 004 | loss: 0.69207 - acc: 0.5416 -- iter: 1824/2105
[A[ATraining Step: 256  | total loss: [1m[32m0.69201[0m[0m | time: 200.278s
[2K
| Adam | epoch: 004 | loss: 0.69201 - acc: 0.5406 -- iter: 1856/2105
[A[ATraining Step: 257  | total loss: [1m[32m0.69174[0m[0m | time: 201.671s
[2K
| Adam | epoch: 004 | loss: 0.69174 - acc: 0.5427 -- iter: 1888/2105
[A[ATraining Step: 258  | total loss: [1m[32m0.69175[0m[0m | time: 203.140s
[2K
| Adam | epoch: 004 | loss: 0.69175 - acc: 0.5416 -- iter: 1920/2105
[A[ATraining Step: 259  | total loss: [1m[32m0.69249[0m[0m | time: 204.283s
[2K
| Adam | epoch: 004 | loss: 0.69249 - acc: 0.5281 -- iter: 1952/2105
[A[ATraining Step: 260  | total loss: [1m[32m0.69208[0m[0m | time: 205.674s
[2K
| Adam | epoch: 004 | loss: 0.69208 - acc: 0.5315 -- iter: 1984/2105
[A[ATraining Step: 261  | total loss: [1m[32m0.69256[0m[0m | time: 207.221s
[2K
| Adam | epoch: 004 | loss: 0.69256 - acc: 0.5221 -- iter: 2016/2105
[A[ATraining Step: 262  | total loss: [1m[32m0.69373[0m[0m | time: 208.604s
[2K
| Adam | epoch: 004 | loss: 0.69373 - acc: 0.5043 -- iter: 2048/2105
[A[ATraining Step: 263  | total loss: [1m[32m0.69324[0m[0m | time: 209.967s
[2K
| Adam | epoch: 004 | loss: 0.69324 - acc: 0.5101 -- iter: 2080/2105
[A[ATraining Step: 264  | total loss: [1m[32m0.69338[0m[0m | time: 217.002s
[2K
| Adam | epoch: 004 | loss: 0.69338 - acc: 0.5060 | val_loss: 0.69315 - val_acc: 0.4894 -- iter: 2105/2105
--
Training Step: 265  | total loss: [1m[32m0.69350[0m[0m | time: 1.058s
[2K
| Adam | epoch: 005 | loss: 0.69350 - acc: 0.5022 -- iter: 0032/2105
[A[ATraining Step: 266  | total loss: [1m[32m0.69289[0m[0m | time: 2.077s
[2K
| Adam | epoch: 005 | loss: 0.69289 - acc: 0.5145 -- iter: 0064/2105
[A[ATraining Step: 267  | total loss: [1m[32m0.69306[0m[0m | time: 2.922s
[2K
| Adam | epoch: 005 | loss: 0.69306 - acc: 0.5068 -- iter: 0096/2105
[A[ATraining Step: 268  | total loss: [1m[32m0.69324[0m[0m | time: 3.743s
[2K
| Adam | epoch: 005 | loss: 0.69324 - acc: 0.5001 -- iter: 0128/2105
[A[ATraining Step: 269  | total loss: [1m[32m0.69334[0m[0m | time: 4.772s
[2K
| Adam | epoch: 005 | loss: 0.69334 - acc: 0.4941 -- iter: 0160/2105
[A[ATraining Step: 270  | total loss: [1m[32m0.69334[0m[0m | time: 5.707s
[2K
| Adam | epoch: 005 | loss: 0.69334 - acc: 0.4916 -- iter: 0192/2105
[A[ATraining Step: 271  | total loss: [1m[32m0.69340[0m[0m | time: 6.646s
[2K
| Adam | epoch: 005 | loss: 0.69340 - acc: 0.4799 -- iter: 0224/2105
[A[ATraining Step: 272  | total loss: [1m[32m0.69330[0m[0m | time: 7.749s
[2K
| Adam | epoch: 005 | loss: 0.69330 - acc: 0.4913 -- iter: 0256/2105
[A[ATraining Step: 273  | total loss: [1m[32m0.69328[0m[0m | time: 9.032s
[2K
| Adam | epoch: 005 | loss: 0.69328 - acc: 0.4859 -- iter: 0288/2105
[A[ATraining Step: 274  | total loss: [1m[32m0.69315[0m[0m | time: 10.136s
[2K
| Adam | epoch: 005 | loss: 0.69315 - acc: 0.5030 -- iter: 0320/2105
[A[ATraining Step: 275  | total loss: [1m[32m0.69313[0m[0m | time: 11.032s
[2K
| Adam | epoch: 005 | loss: 0.69313 - acc: 0.5027 -- iter: 0352/2105
[A[ATraining Step: 276  | total loss: [1m[32m0.69309[0m[0m | time: 12.060s
[2K
| Adam | epoch: 005 | loss: 0.69309 - acc: 0.5024 -- iter: 0384/2105
[A[ATraining Step: 277  | total loss: [1m[32m0.69287[0m[0m | time: 13.052s
[2K
| Adam | epoch: 005 | loss: 0.69287 - acc: 0.5178 -- iter: 0416/2105
[A[ATraining Step: 278  | total loss: [1m[32m0.69280[0m[0m | time: 14.054s
[2K
| Adam | epoch: 005 | loss: 0.69280 - acc: 0.5191 -- iter: 0448/2105
[A[ATraining Step: 279  | total loss: [1m[32m0.69285[0m[0m | time: 15.034s
[2K
| Adam | epoch: 005 | loss: 0.69285 - acc: 0.5172 -- iter: 0480/2105
[A[ATraining Step: 280  | total loss: [1m[32m0.69302[0m[0m | time: 16.015s
[2K
| Adam | epoch: 005 | loss: 0.69302 - acc: 0.5092 -- iter: 0512/2105
[A[ATraining Step: 281  | total loss: [1m[32m0.69285[0m[0m | time: 17.016s
[2K
| Adam | epoch: 005 | loss: 0.69285 - acc: 0.5146 -- iter: 0544/2105
[A[ATraining Step: 282  | total loss: [1m[32m0.69283[0m[0m | time: 17.927s
[2K
| Adam | epoch: 005 | loss: 0.69283 - acc: 0.5131 -- iter: 0576/2105
[A[ATraining Step: 283  | total loss: [1m[32m0.69264[0m[0m | time: 19.181s
[2K
| Adam | epoch: 005 | loss: 0.69264 - acc: 0.5181 -- iter: 0608/2105
[A[ATraining Step: 284  | total loss: [1m[32m0.69237[0m[0m | time: 20.442s
[2K
| Adam | epoch: 005 | loss: 0.69237 - acc: 0.5256 -- iter: 0640/2105
[A[ATraining Step: 285  | total loss: [1m[32m0.69264[0m[0m | time: 21.338s
[2K
| Adam | epoch: 005 | loss: 0.69264 - acc: 0.5137 -- iter: 0672/2105
[A[ATraining Step: 286  | total loss: [1m[32m0.69289[0m[0m | time: 22.292s
[2K
| Adam | epoch: 005 | loss: 0.69289 - acc: 0.5029 -- iter: 0704/2105
[A[ATraining Step: 287  | total loss: [1m[32m0.69309[0m[0m | time: 23.326s
[2K
| Adam | epoch: 005 | loss: 0.69309 - acc: 0.4933 -- iter: 0736/2105
[A[ATraining Step: 288  | total loss: [1m[32m0.69288[0m[0m | time: 24.304s
[2K
| Adam | epoch: 005 | loss: 0.69288 - acc: 0.4971 -- iter: 0768/2105
[A[ATraining Step: 289  | total loss: [1m[32m0.69284[0m[0m | time: 25.301s
[2K
| Adam | epoch: 005 | loss: 0.69284 - acc: 0.4974 -- iter: 0800/2105
[A[ATraining Step: 290  | total loss: [1m[32m0.69274[0m[0m | time: 26.349s
[2K
| Adam | epoch: 005 | loss: 0.69274 - acc: 0.5070 -- iter: 0832/2105
[A[ATraining Step: 291  | total loss: [1m[32m0.69264[0m[0m | time: 27.342s
[2K
| Adam | epoch: 005 | loss: 0.69264 - acc: 0.5251 -- iter: 0864/2105
[A[ATraining Step: 292  | total loss: [1m[32m0.69262[0m[0m | time: 28.297s
[2K
| Adam | epoch: 005 | loss: 0.69262 - acc: 0.5350 -- iter: 0896/2105
[A[ATraining Step: 293  | total loss: [1m[32m0.69245[0m[0m | time: 29.246s
[2K
| Adam | epoch: 005 | loss: 0.69245 - acc: 0.5503 -- iter: 0928/2105
[A[ATraining Step: 294  | total loss: [1m[32m0.69246[0m[0m | time: 30.417s
[2K
| Adam | epoch: 005 | loss: 0.69246 - acc: 0.5515 -- iter: 0960/2105
[A[ATraining Step: 295  | total loss: [1m[32m0.69227[0m[0m | time: 31.626s
[2K
| Adam | epoch: 005 | loss: 0.69227 - acc: 0.5620 -- iter: 0992/2105
[A[ATraining Step: 296  | total loss: [1m[32m0.69225[0m[0m | time: 32.448s
[2K
| Adam | epoch: 005 | loss: 0.69225 - acc: 0.5589 -- iter: 1024/2105
[A[ATraining Step: 297  | total loss: [1m[32m0.69176[0m[0m | time: 33.423s
[2K
| Adam | epoch: 005 | loss: 0.69176 - acc: 0.5905 -- iter: 1056/2105
[A[ATraining Step: 298  | total loss: [1m[32m0.69184[0m[0m | time: 34.480s
[2K
| Adam | epoch: 005 | loss: 0.69184 - acc: 0.5783 -- iter: 1088/2105
[A[ATraining Step: 299  | total loss: [1m[32m0.69193[0m[0m | time: 35.802s
[2K
| Adam | epoch: 005 | loss: 0.69193 - acc: 0.5768 -- iter: 1120/2105
[A[ATraining Step: 300  | total loss: [1m[32m0.69166[0m[0m | time: 37.185s
[2K
| Adam | epoch: 005 | loss: 0.69166 - acc: 0.5910 -- iter: 1152/2105
[A[ATraining Step: 301  | total loss: [1m[32m0.69151[0m[0m | time: 38.467s
[2K
| Adam | epoch: 005 | loss: 0.69151 - acc: 0.5912 -- iter: 1184/2105
[A[ATraining Step: 302  | total loss: [1m[32m0.69195[0m[0m | time: 39.803s
[2K
| Adam | epoch: 005 | loss: 0.69195 - acc: 0.5665 -- iter: 1216/2105
[A[ATraining Step: 303  | total loss: [1m[32m0.69177[0m[0m | time: 41.174s
[2K
| Adam | epoch: 005 | loss: 0.69177 - acc: 0.5723 -- iter: 1248/2105
[A[ATraining Step: 304  | total loss: [1m[32m0.69151[0m[0m | time: 42.515s
[2K
| Adam | epoch: 005 | loss: 0.69151 - acc: 0.5807 -- iter: 1280/2105
[A[ATraining Step: 305  | total loss: [1m[32m0.69111[0m[0m | time: 44.045s
[2K
| Adam | epoch: 005 | loss: 0.69111 - acc: 0.5945 -- iter: 1312/2105
[A[ATraining Step: 306  | total loss: [1m[32m0.69121[0m[0m | time: 45.556s
[2K
| Adam | epoch: 005 | loss: 0.69121 - acc: 0.5820 -- iter: 1344/2105
[A[ATraining Step: 307  | total loss: [1m[32m0.69129[0m[0m | time: 46.855s
[2K
| Adam | epoch: 005 | loss: 0.69129 - acc: 0.5800 -- iter: 1376/2105
[A[ATraining Step: 308  | total loss: [1m[32m0.69162[0m[0m | time: 51.620s
[2K
| Adam | epoch: 005 | loss: 0.69162 - acc: 0.5658 -- iter: 1408/2105
[A[ATraining Step: 309  | total loss: [1m[32m0.69137[0m[0m | time: 57.471s
[2K
| Adam | epoch: 005 | loss: 0.69137 - acc: 0.5592 -- iter: 1440/2105
[A[ATraining Step: 310  | total loss: [1m[32m0.69130[0m[0m | time: 61.538s
[2K
| Adam | epoch: 005 | loss: 0.69130 - acc: 0.5470 -- iter: 1472/2105
[A[ATraining Step: 311  | total loss: [1m[32m0.69073[0m[0m | time: 63.825s
[2K
| Adam | epoch: 005 | loss: 0.69073 - acc: 0.5517 -- iter: 1504/2105
[A[ATraining Step: 312  | total loss: [1m[32m0.69029[0m[0m | time: 64.966s
[2K
| Adam | epoch: 005 | loss: 0.69029 - acc: 0.5559 -- iter: 1536/2105
[A[ATraining Step: 313  | total loss: [1m[32m0.69049[0m[0m | time: 66.329s
[2K
| Adam | epoch: 005 | loss: 0.69049 - acc: 0.5409 -- iter: 1568/2105
[A[ATraining Step: 314  | total loss: [1m[32m0.69093[0m[0m | time: 67.671s
[2K
| Adam | epoch: 005 | loss: 0.69093 - acc: 0.5275 -- iter: 1600/2105
[A[ATraining Step: 315  | total loss: [1m[32m0.69059[0m[0m | time: 69.173s
[2K
| Adam | epoch: 005 | loss: 0.69059 - acc: 0.5403 -- iter: 1632/2105
[A[ATraining Step: 316  | total loss: [1m[32m0.69045[0m[0m | time: 70.618s
[2K
| Adam | epoch: 005 | loss: 0.69045 - acc: 0.5426 -- iter: 1664/2105
[A[ATraining Step: 317  | total loss: [1m[32m0.69037[0m[0m | time: 72.081s
[2K
| Adam | epoch: 005 | loss: 0.69037 - acc: 0.5446 -- iter: 1696/2105
[A[ATraining Step: 318  | total loss: [1m[32m0.69090[0m[0m | time: 73.352s
[2K
| Adam | epoch: 005 | loss: 0.69090 - acc: 0.5307 -- iter: 1728/2105
[A[ATraining Step: 319  | total loss: [1m[32m0.69048[0m[0m | time: 75.338s
[2K
| Adam | epoch: 005 | loss: 0.69048 - acc: 0.5464 -- iter: 1760/2105
[A[ATraining Step: 320  | total loss: [1m[32m0.69026[0m[0m | time: 78.765s
[2K
| Adam | epoch: 005 | loss: 0.69026 - acc: 0.5418 -- iter: 1792/2105
[A[ATraining Step: 321  | total loss: [1m[32m0.68980[0m[0m | time: 81.038s
[2K
| Adam | epoch: 005 | loss: 0.68980 - acc: 0.5532 -- iter: 1824/2105
[A[ATraining Step: 322  | total loss: [1m[32m0.68879[0m[0m | time: 82.380s
[2K
| Adam | epoch: 005 | loss: 0.68879 - acc: 0.5729 -- iter: 1856/2105
[A[ATraining Step: 323  | total loss: [1m[32m0.68801[0m[0m | time: 83.702s
[2K
| Adam | epoch: 005 | loss: 0.68801 - acc: 0.5906 -- iter: 1888/2105
[A[ATraining Step: 324  | total loss: [1m[32m0.68909[0m[0m | time: 84.875s
[2K
| Adam | epoch: 005 | loss: 0.68909 - acc: 0.5815 -- iter: 1920/2105
[A[ATraining Step: 325  | total loss: [1m[32m0.68823[0m[0m | time: 86.156s
[2K
| Adam | epoch: 005 | loss: 0.68823 - acc: 0.5953 -- iter: 1952/2105
[A[ATraining Step: 326  | total loss: [1m[32m0.68706[0m[0m | time: 87.523s
[2K
| Adam | epoch: 005 | loss: 0.68706 - acc: 0.6014 -- iter: 1984/2105
[A[ATraining Step: 327  | total loss: [1m[32m0.68664[0m[0m | time: 89.052s
[2K
| Adam | epoch: 005 | loss: 0.68664 - acc: 0.6006 -- iter: 2016/2105
[A[ATraining Step: 328  | total loss: [1m[32m0.68597[0m[0m | time: 90.475s
[2K
| Adam | epoch: 005 | loss: 0.68597 - acc: 0.6093 -- iter: 2048/2105
[A[ATraining Step: 329  | total loss: [1m[32m0.68391[0m[0m | time: 91.795s
[2K
| Adam | epoch: 005 | loss: 0.68391 - acc: 0.6327 -- iter: 2080/2105
[A[ATraining Step: 330  | total loss: [1m[32m0.68295[0m[0m | time: 103.999s
[2K
| Adam | epoch: 005 | loss: 0.68295 - acc: 0.6382 | val_loss: 0.68225 - val_acc: 0.5790 -- iter: 2105/2105
--
Training Step: 331  | total loss: [1m[32m0.68235[0m[0m | time: 1.278s
[2K
| Adam | epoch: 006 | loss: 0.68235 - acc: 0.6431 -- iter: 0032/2105
[A[ATraining Step: 332  | total loss: [1m[32m0.68352[0m[0m | time: 2.700s
[2K
| Adam | epoch: 006 | loss: 0.68352 - acc: 0.6195 -- iter: 0064/2105
[A[ATraining Step: 333  | total loss: [1m[32m0.68416[0m[0m | time: 4.264s
[2K
| Adam | epoch: 006 | loss: 0.68416 - acc: 0.6106 -- iter: 0096/2105
[A[ATraining Step: 334  | total loss: [1m[32m0.68194[0m[0m | time: 5.380s
[2K
| Adam | epoch: 006 | loss: 0.68194 - acc: 0.6246 -- iter: 0128/2105
[A[ATraining Step: 335  | total loss: [1m[32m0.68138[0m[0m | time: 6.461s
[2K
| Adam | epoch: 006 | loss: 0.68138 - acc: 0.6221 -- iter: 0160/2105
[A[ATraining Step: 336  | total loss: [1m[32m0.68065[0m[0m | time: 8.105s
[2K
| Adam | epoch: 006 | loss: 0.68065 - acc: 0.6159 -- iter: 0192/2105
[A[ATraining Step: 337  | total loss: [1m[32m0.67768[0m[0m | time: 9.606s
[2K
| Adam | epoch: 006 | loss: 0.67768 - acc: 0.6231 -- iter: 0224/2105
[A[ATraining Step: 338  | total loss: [1m[32m0.67888[0m[0m | time: 14.153s
[2K
| Adam | epoch: 006 | loss: 0.67888 - acc: 0.6076 -- iter: 0256/2105
[A[ATraining Step: 339  | total loss: [1m[32m0.67560[0m[0m | time: 20.649s
[2K
| Adam | epoch: 006 | loss: 0.67560 - acc: 0.6125 -- iter: 0288/2105
[A[ATraining Step: 340  | total loss: [1m[32m0.67648[0m[0m | time: 23.600s
[2K
| Adam | epoch: 006 | loss: 0.67648 - acc: 0.6012 -- iter: 0320/2105
[A[ATraining Step: 341  | total loss: [1m[32m0.68577[0m[0m | time: 24.953s
[2K
| Adam | epoch: 006 | loss: 0.68577 - acc: 0.5755 -- iter: 0352/2105
[A[ATraining Step: 342  | total loss: [1m[32m0.68411[0m[0m | time: 30.822s
[2K
| Adam | epoch: 006 | loss: 0.68411 - acc: 0.5742 -- iter: 0384/2105
[A[ATraining Step: 343  | total loss: [1m[32m0.68358[0m[0m | time: 39.962s
[2K
| Adam | epoch: 006 | loss: 0.68358 - acc: 0.5605 -- iter: 0416/2105
[A[ATraining Step: 344  | total loss: [1m[32m0.68401[0m[0m | time: 45.769s
[2K
| Adam | epoch: 006 | loss: 0.68401 - acc: 0.5576 -- iter: 0448/2105
[A[ATraining Step: 345  | total loss: [1m[32m0.68158[0m[0m | time: 49.387s
[2K
| Adam | epoch: 006 | loss: 0.68158 - acc: 0.5612 -- iter: 0480/2105
[A[ATraining Step: 346  | total loss: [1m[32m0.67883[0m[0m | time: 50.635s
[2K
| Adam | epoch: 006 | loss: 0.67883 - acc: 0.5770 -- iter: 0512/2105
[A[ATraining Step: 347  | total loss: [1m[32m0.68060[0m[0m | time: 51.715s
[2K
| Adam | epoch: 006 | loss: 0.68060 - acc: 0.5724 -- iter: 0544/2105
[A[ATraining Step: 348  | total loss: [1m[32m0.68393[0m[0m | time: 52.960s
[2K
| Adam | epoch: 006 | loss: 0.68393 - acc: 0.5652 -- iter: 0576/2105
[A[ATraining Step: 349  | total loss: [1m[32m0.68305[0m[0m | time: 54.299s
[2K
| Adam | epoch: 006 | loss: 0.68305 - acc: 0.5649 -- iter: 0608/2105
[A[ATraining Step: 350  | total loss: [1m[32m0.69156[0m[0m | time: 55.757s
[2K
| Adam | epoch: 006 | loss: 0.69156 - acc: 0.5490 -- iter: 0640/2105
[A[ATraining Step: 351  | total loss: [1m[32m0.69878[0m[0m | time: 57.254s
[2K
| Adam | epoch: 006 | loss: 0.69878 - acc: 0.5285 -- iter: 0672/2105
[A[ATraining Step: 352  | total loss: [1m[32m0.69866[0m[0m | time: 58.581s
[2K
| Adam | epoch: 006 | loss: 0.69866 - acc: 0.5288 -- iter: 0704/2105
[A[ATraining Step: 353  | total loss: [1m[32m0.69454[0m[0m | time: 59.936s
[2K
| Adam | epoch: 006 | loss: 0.69454 - acc: 0.5415 -- iter: 0736/2105
[A[ATraining Step: 354  | total loss: [1m[32m0.69298[0m[0m | time: 61.440s
[2K
| Adam | epoch: 006 | loss: 0.69298 - acc: 0.5467 -- iter: 0768/2105
[A[ATraining Step: 355  | total loss: [1m[32m0.69026[0m[0m | time: 62.943s
[2K
| Adam | epoch: 006 | loss: 0.69026 - acc: 0.5608 -- iter: 0800/2105
[A[ATraining Step: 356  | total loss: [1m[32m0.68849[0m[0m | time: 77.578s
[2K
| Adam | epoch: 006 | loss: 0.68849 - acc: 0.5579 -- iter: 0832/2105
[A[ATraining Step: 357  | total loss: [1m[32m0.68645[0m[0m | time: 85.089s
[2K
| Adam | epoch: 006 | loss: 0.68645 - acc: 0.5646 -- iter: 0864/2105
[A[ATraining Step: 358  | total loss: [1m[32m0.68496[0m[0m | time: 94.770s
[2K
| Adam | epoch: 006 | loss: 0.68496 - acc: 0.5612 -- iter: 0896/2105
[A[ATraining Step: 359  | total loss: [1m[32m0.68586[0m[0m | time: 96.111s
[2K
| Adam | epoch: 006 | loss: 0.68586 - acc: 0.5489 -- iter: 0928/2105
[A[ATraining Step: 360  | total loss: [1m[32m0.68409[0m[0m | time: 97.407s
[2K
| Adam | epoch: 006 | loss: 0.68409 - acc: 0.5534 -- iter: 0960/2105
[A[ATraining Step: 361  | total loss: [1m[32m0.68466[0m[0m | time: 98.625s
[2K
| Adam | epoch: 006 | loss: 0.68466 - acc: 0.5418 -- iter: 0992/2105
[A[ATraining Step: 362  | total loss: [1m[32m0.68488[0m[0m | time: 99.926s
[2K
| Adam | epoch: 006 | loss: 0.68488 - acc: 0.5345 -- iter: 1024/2105
[A[ATraining Step: 363  | total loss: [1m[32m0.68668[0m[0m | time: 101.360s
[2K
| Adam | epoch: 006 | loss: 0.68668 - acc: 0.5279 -- iter: 1056/2105
[A[ATraining Step: 364  | total loss: [1m[32m0.68655[0m[0m | time: 102.812s
[2K
| Adam | epoch: 006 | loss: 0.68655 - acc: 0.5189 -- iter: 1088/2105
[A[ATraining Step: 365  | total loss: [1m[32m0.68326[0m[0m | time: 104.203s
[2K
| Adam | epoch: 006 | loss: 0.68326 - acc: 0.5388 -- iter: 1120/2105
[A[ATraining Step: 366  | total loss: [1m[32m0.68322[0m[0m | time: 105.593s
[2K
| Adam | epoch: 006 | loss: 0.68322 - acc: 0.5412 -- iter: 1152/2105
[A[ATraining Step: 367  | total loss: [1m[32m0.68385[0m[0m | time: 107.148s
[2K
| Adam | epoch: 006 | loss: 0.68385 - acc: 0.5340 -- iter: 1184/2105
[A[ATraining Step: 368  | total loss: [1m[32m0.68235[0m[0m | time: 108.695s
[2K
| Adam | epoch: 006 | loss: 0.68235 - acc: 0.5524 -- iter: 1216/2105
[A[ATraining Step: 369  | total loss: [1m[32m0.68059[0m[0m | time: 113.119s
[2K
| Adam | epoch: 006 | loss: 0.68059 - acc: 0.5722 -- iter: 1248/2105
[A[ATraining Step: 370  | total loss: [1m[32m0.68319[0m[0m | time: 120.652s
[2K
| Adam | epoch: 006 | loss: 0.68319 - acc: 0.5556 -- iter: 1280/2105
[A[ATraining Step: 371  | total loss: [1m[32m0.68182[0m[0m | time: 135.732s
[2K
| Adam | epoch: 006 | loss: 0.68182 - acc: 0.5688 -- iter: 1312/2105
[A[ATraining Step: 372  | total loss: [1m[32m0.68030[0m[0m | time: 140.577s
[2K
| Adam | epoch: 006 | loss: 0.68030 - acc: 0.5775 -- iter: 1344/2105
[A[ATraining Step: 373  | total loss: [1m[32m0.67854[0m[0m | time: 141.905s
[2K
| Adam | epoch: 006 | loss: 0.67854 - acc: 0.5885 -- iter: 1376/2105
[A[ATraining Step: 374  | total loss: [1m[32m0.67926[0m[0m | time: 143.531s
[2K
| Adam | epoch: 006 | loss: 0.67926 - acc: 0.5922 -- iter: 1408/2105
[A[ATraining Step: 375  | total loss: [1m[32m0.67580[0m[0m | time: 146.407s
[2K
| Adam | epoch: 006 | loss: 0.67580 - acc: 0.6173 -- iter: 1440/2105
[A[ATraining Step: 376  | total loss: [1m[32m0.67579[0m[0m | time: 149.136s
[2K
| Adam | epoch: 006 | loss: 0.67579 - acc: 0.6150 -- iter: 1472/2105
[A[ATraining Step: 377  | total loss: [1m[32m0.67780[0m[0m | time: 150.379s
[2K
| Adam | epoch: 006 | loss: 0.67780 - acc: 0.6097 -- iter: 1504/2105
[A[ATraining Step: 378  | total loss: [1m[32m0.67636[0m[0m | time: 151.672s
[2K
| Adam | epoch: 006 | loss: 0.67636 - acc: 0.6113 -- iter: 1536/2105
[A[ATraining Step: 379  | total loss: [1m[32m0.67560[0m[0m | time: 153.092s
[2K
| Adam | epoch: 006 | loss: 0.67560 - acc: 0.6095 -- iter: 1568/2105
[A[ATraining Step: 380  | total loss: [1m[32m0.67178[0m[0m | time: 154.535s
[2K
| Adam | epoch: 006 | loss: 0.67178 - acc: 0.6298 -- iter: 1600/2105
[A[ATraining Step: 381  | total loss: [1m[32m0.67064[0m[0m | time: 155.870s
[2K
| Adam | epoch: 006 | loss: 0.67064 - acc: 0.6387 -- iter: 1632/2105
[A[ATraining Step: 382  | total loss: [1m[32m0.66916[0m[0m | time: 157.408s
[2K
| Adam | epoch: 006 | loss: 0.66916 - acc: 0.6436 -- iter: 1664/2105
[A[ATraining Step: 383  | total loss: [1m[32m0.67119[0m[0m | time: 158.957s
[2K
| Adam | epoch: 006 | loss: 0.67119 - acc: 0.6292 -- iter: 1696/2105
[A[ATraining Step: 384  | total loss: [1m[32m0.66925[0m[0m | time: 160.383s
[2K
| Adam | epoch: 006 | loss: 0.66925 - acc: 0.6382 -- iter: 1728/2105
[A[ATraining Step: 385  | total loss: [1m[32m0.66620[0m[0m | time: 161.740s
[2K
| Adam | epoch: 006 | loss: 0.66620 - acc: 0.6462 -- iter: 1760/2105
[A[ATraining Step: 386  | total loss: [1m[32m0.66411[0m[0m | time: 163.056s
[2K
| Adam | epoch: 006 | loss: 0.66411 - acc: 0.6441 -- iter: 1792/2105
[A[ATraining Step: 387  | total loss: [1m[32m0.66225[0m[0m | time: 164.309s
[2K
| Adam | epoch: 006 | loss: 0.66225 - acc: 0.6516 -- iter: 1824/2105
[A[ATraining Step: 388  | total loss: [1m[32m0.66283[0m[0m | time: 165.291s
[2K
| Adam | epoch: 006 | loss: 0.66283 - acc: 0.6458 -- iter: 1856/2105
[A[ATraining Step: 389  | total loss: [1m[32m0.65797[0m[0m | time: 166.271s
[2K
| Adam | epoch: 006 | loss: 0.65797 - acc: 0.6625 -- iter: 1888/2105
[A[ATraining Step: 390  | total loss: [1m[32m0.65579[0m[0m | time: 167.345s
[2K
| Adam | epoch: 006 | loss: 0.65579 - acc: 0.6712 -- iter: 1920/2105
[A[ATraining Step: 391  | total loss: [1m[32m0.65230[0m[0m | time: 168.262s
[2K
| Adam | epoch: 006 | loss: 0.65230 - acc: 0.6853 -- iter: 1952/2105
[A[ATraining Step: 392  | total loss: [1m[32m0.65124[0m[0m | time: 169.467s
[2K
| Adam | epoch: 006 | loss: 0.65124 - acc: 0.6762 -- iter: 1984/2105
[A[ATraining Step: 393  | total loss: [1m[32m0.65290[0m[0m | time: 170.396s
[2K
| Adam | epoch: 006 | loss: 0.65290 - acc: 0.6679 -- iter: 2016/2105
[A[ATraining Step: 394  | total loss: [1m[32m0.65221[0m[0m | time: 171.402s
[2K
| Adam | epoch: 006 | loss: 0.65221 - acc: 0.6699 -- iter: 2048/2105
[A[ATraining Step: 395  | total loss: [1m[32m0.65221[0m[0m | time: 172.380s
[2K
| Adam | epoch: 006 | loss: 0.65221 - acc: 0.6685 -- iter: 2080/2105
[A[ATraining Step: 396  | total loss: [1m[32m0.64845[0m[0m | time: 177.571s
[2K
| Adam | epoch: 006 | loss: 0.64845 - acc: 0.6673 | val_loss: 0.65127 - val_acc: 0.6261 -- iter: 2105/2105
--
Training Step: 397  | total loss: [1m[32m0.65028[0m[0m | time: 1.036s
[2K
| Adam | epoch: 007 | loss: 0.65028 - acc: 0.6568 -- iter: 0032/2105
[A[ATraining Step: 398  | total loss: [1m[32m0.64778[0m[0m | time: 2.018s
[2K
| Adam | epoch: 007 | loss: 0.64778 - acc: 0.6474 -- iter: 0064/2105
[A[ATraining Step: 399  | total loss: [1m[32m0.64455[0m[0m | time: 3.003s
[2K
| Adam | epoch: 007 | loss: 0.64455 - acc: 0.6452 -- iter: 0096/2105
[A[ATraining Step: 400  | total loss: [1m[32m0.63831[0m[0m | time: 8.539s
[2K
| Adam | epoch: 007 | loss: 0.63831 - acc: 0.6525 | val_loss: 0.63987 - val_acc: 0.6641 -- iter: 0128/2105
--
Training Step: 401  | total loss: [1m[32m0.63960[0m[0m | time: 11.846s
[2K
| Adam | epoch: 007 | loss: 0.63960 - acc: 0.6529 -- iter: 0160/2105
[A[ATraining Step: 402  | total loss: [1m[32m0.63100[0m[0m | time: 13.023s
[2K
| Adam | epoch: 007 | loss: 0.63100 - acc: 0.6676 -- iter: 0192/2105
[A[ATraining Step: 403  | total loss: [1m[32m0.62351[0m[0m | time: 19.003s
[2K
| Adam | epoch: 007 | loss: 0.62351 - acc: 0.6808 -- iter: 0224/2105
[A[ATraining Step: 404  | total loss: [1m[32m0.62655[0m[0m | time: 27.623s
[2K
| Adam | epoch: 007 | loss: 0.62655 - acc: 0.6753 -- iter: 0256/2105
[A[ATraining Step: 405  | total loss: [1m[32m0.62507[0m[0m | time: 32.400s
[2K
| Adam | epoch: 007 | loss: 0.62507 - acc: 0.6734 -- iter: 0288/2105
[A[ATraining Step: 406  | total loss: [1m[32m0.61997[0m[0m | time: 36.961s
[2K
| Adam | epoch: 007 | loss: 0.61997 - acc: 0.6810 -- iter: 0320/2105
[A[ATraining Step: 407  | total loss: [1m[32m0.61793[0m[0m | time: 41.026s
[2K
| Adam | epoch: 007 | loss: 0.61793 - acc: 0.6817 -- iter: 0352/2105
[A[ATraining Step: 408  | total loss: [1m[32m0.61548[0m[0m | time: 42.045s
[2K
| Adam | epoch: 007 | loss: 0.61548 - acc: 0.6916 -- iter: 0384/2105
[A[ATraining Step: 409  | total loss: [1m[32m0.61642[0m[0m | time: 43.380s
[2K
| Adam | epoch: 007 | loss: 0.61642 - acc: 0.6912 -- iter: 0416/2105
[A[ATraining Step: 410  | total loss: [1m[32m0.61853[0m[0m | time: 44.673s
[2K
| Adam | epoch: 007 | loss: 0.61853 - acc: 0.6877 -- iter: 0448/2105
[A[ATraining Step: 411  | total loss: [1m[32m0.61454[0m[0m | time: 45.928s
[2K
| Adam | epoch: 007 | loss: 0.61454 - acc: 0.6877 -- iter: 0480/2105
[A[ATraining Step: 412  | total loss: [1m[32m0.61127[0m[0m | time: 47.260s
[2K
| Adam | epoch: 007 | loss: 0.61127 - acc: 0.6939 -- iter: 0512/2105
[A[ATraining Step: 413  | total loss: [1m[32m0.61627[0m[0m | time: 48.714s
[2K
| Adam | epoch: 007 | loss: 0.61627 - acc: 0.6808 -- iter: 0544/2105
[A[ATraining Step: 414  | total loss: [1m[32m0.62642[0m[0m | time: 50.141s
[2K
| Adam | epoch: 007 | loss: 0.62642 - acc: 0.6690 -- iter: 0576/2105
[A[ATraining Step: 415  | total loss: [1m[32m0.62892[0m[0m | time: 51.553s
[2K
| Adam | epoch: 007 | loss: 0.62892 - acc: 0.6583 -- iter: 0608/2105
[A[ATraining Step: 416  | total loss: [1m[32m0.62114[0m[0m | time: 52.997s
[2K
| Adam | epoch: 007 | loss: 0.62114 - acc: 0.6612 -- iter: 0640/2105
[A[ATraining Step: 417  | total loss: [1m[32m0.62111[0m[0m | time: 54.418s
[2K
| Adam | epoch: 007 | loss: 0.62111 - acc: 0.6607 -- iter: 0672/2105
[A[ATraining Step: 418  | total loss: [1m[32m0.61423[0m[0m | time: 55.722s
[2K
| Adam | epoch: 007 | loss: 0.61423 - acc: 0.6728 -- iter: 0704/2105
[A[ATraining Step: 419  | total loss: [1m[32m0.61073[0m[0m | time: 57.091s
[2K
| Adam | epoch: 007 | loss: 0.61073 - acc: 0.6774 -- iter: 0736/2105
[A[ATraining Step: 420  | total loss: [1m[32m0.61088[0m[0m | time: 58.216s
[2K
| Adam | epoch: 007 | loss: 0.61088 - acc: 0.6878 -- iter: 0768/2105
[A[ATraining Step: 421  | total loss: [1m[32m0.61423[0m[0m | time: 59.405s
[2K
| Adam | epoch: 007 | loss: 0.61423 - acc: 0.6815 -- iter: 0800/2105
[A[ATraining Step: 422  | total loss: [1m[32m0.62413[0m[0m | time: 60.767s
[2K
| Adam | epoch: 007 | loss: 0.62413 - acc: 0.6665 -- iter: 0832/2105
[A[ATraining Step: 423  | total loss: [1m[32m0.62339[0m[0m | time: 62.023s
[2K
| Adam | epoch: 007 | loss: 0.62339 - acc: 0.6717 -- iter: 0864/2105
[A[ATraining Step: 424  | total loss: [1m[32m0.61329[0m[0m | time: 63.410s
[2K
| Adam | epoch: 007 | loss: 0.61329 - acc: 0.6826 -- iter: 0896/2105
[A[ATraining Step: 425  | total loss: [1m[32m0.60466[0m[0m | time: 64.717s
[2K
| Adam | epoch: 007 | loss: 0.60466 - acc: 0.6988 -- iter: 0928/2105
[A[ATraining Step: 426  | total loss: [1m[32m0.60493[0m[0m | time: 65.955s
[2K
| Adam | epoch: 007 | loss: 0.60493 - acc: 0.7039 -- iter: 0960/2105
[A[ATraining Step: 427  | total loss: [1m[32m0.59954[0m[0m | time: 67.272s
[2K
| Adam | epoch: 007 | loss: 0.59954 - acc: 0.7147 -- iter: 0992/2105
[A[ATraining Step: 428  | total loss: [1m[32m0.59462[0m[0m | time: 68.469s
[2K
| Adam | epoch: 007 | loss: 0.59462 - acc: 0.7151 -- iter: 1024/2105
[A[ATraining Step: 429  | total loss: [1m[32m0.59051[0m[0m | time: 69.797s
[2K
| Adam | epoch: 007 | loss: 0.59051 - acc: 0.7186 -- iter: 1056/2105
[A[ATraining Step: 430  | total loss: [1m[32m0.58322[0m[0m | time: 71.284s
[2K
| Adam | epoch: 007 | loss: 0.58322 - acc: 0.7218 -- iter: 1088/2105
[A[ATraining Step: 431  | total loss: [1m[32m0.58122[0m[0m | time: 72.766s
[2K
| Adam | epoch: 007 | loss: 0.58122 - acc: 0.7121 -- iter: 1120/2105
[A[ATraining Step: 432  | total loss: [1m[32m0.60301[0m[0m | time: 73.835s
[2K
| Adam | epoch: 007 | loss: 0.60301 - acc: 0.6878 -- iter: 1152/2105
[A[ATraining Step: 433  | total loss: [1m[32m0.60668[0m[0m | time: 78.656s
[2K
| Adam | epoch: 007 | loss: 0.60668 - acc: 0.6846 -- iter: 1184/2105
[A[ATraining Step: 434  | total loss: [1m[32m0.60861[0m[0m | time: 84.353s
[2K
| Adam | epoch: 007 | loss: 0.60861 - acc: 0.6849 -- iter: 1216/2105
[A[ATraining Step: 435  | total loss: [1m[32m0.60836[0m[0m | time: 87.669s
[2K
| Adam | epoch: 007 | loss: 0.60836 - acc: 0.6789 -- iter: 1248/2105
[A[ATraining Step: 436  | total loss: [1m[32m0.60852[0m[0m | time: 91.898s
[2K
| Adam | epoch: 007 | loss: 0.60852 - acc: 0.6766 -- iter: 1280/2105
[A[ATraining Step: 437  | total loss: [1m[32m0.60335[0m[0m | time: 93.183s
[2K
| Adam | epoch: 007 | loss: 0.60335 - acc: 0.6871 -- iter: 1312/2105
[A[ATraining Step: 438  | total loss: [1m[32m0.60666[0m[0m | time: 94.395s
[2K
| Adam | epoch: 007 | loss: 0.60666 - acc: 0.6809 -- iter: 1344/2105
[A[ATraining Step: 439  | total loss: [1m[32m0.61297[0m[0m | time: 95.760s
[2K
| Adam | epoch: 007 | loss: 0.61297 - acc: 0.6722 -- iter: 1376/2105
[A[ATraining Step: 440  | total loss: [1m[32m0.60713[0m[0m | time: 97.093s
[2K
| Adam | epoch: 007 | loss: 0.60713 - acc: 0.6831 -- iter: 1408/2105
[A[ATraining Step: 441  | total loss: [1m[32m0.59508[0m[0m | time: 98.427s
[2K
| Adam | epoch: 007 | loss: 0.59508 - acc: 0.6992 -- iter: 1440/2105
[A[ATraining Step: 442  | total loss: [1m[32m0.59808[0m[0m | time: 99.745s
[2K
| Adam | epoch: 007 | loss: 0.59808 - acc: 0.6949 -- iter: 1472/2105
[A[ATraining Step: 443  | total loss: [1m[32m0.60702[0m[0m | time: 101.286s
[2K
| Adam | epoch: 007 | loss: 0.60702 - acc: 0.6847 -- iter: 1504/2105
[A[ATraining Step: 444  | total loss: [1m[32m0.60235[0m[0m | time: 102.931s
[2K
| Adam | epoch: 007 | loss: 0.60235 - acc: 0.6881 -- iter: 1536/2105
[A[ATraining Step: 445  | total loss: [1m[32m0.59972[0m[0m | time: 104.363s
[2K
| Adam | epoch: 007 | loss: 0.59972 - acc: 0.6881 -- iter: 1568/2105
[A[ATraining Step: 446  | total loss: [1m[32m0.59486[0m[0m | time: 105.707s
[2K
| Adam | epoch: 007 | loss: 0.59486 - acc: 0.6974 -- iter: 1600/2105
[A[ATraining Step: 447  | total loss: [1m[32m0.59163[0m[0m | time: 107.072s
[2K
| Adam | epoch: 007 | loss: 0.59163 - acc: 0.7089 -- iter: 1632/2105
[A[ATraining Step: 448  | total loss: [1m[32m0.59209[0m[0m | time: 108.406s
[2K
| Adam | epoch: 007 | loss: 0.59209 - acc: 0.7068 -- iter: 1664/2105
[A[ATraining Step: 449  | total loss: [1m[32m0.58656[0m[0m | time: 109.675s
[2K
| Adam | epoch: 007 | loss: 0.58656 - acc: 0.7173 -- iter: 1696/2105
[A[ATraining Step: 450  | total loss: [1m[32m0.57983[0m[0m | time: 110.973s
[2K
| Adam | epoch: 007 | loss: 0.57983 - acc: 0.7300 -- iter: 1728/2105
[A[ATraining Step: 451  | total loss: [1m[32m0.57655[0m[0m | time: 112.251s
[2K
| Adam | epoch: 007 | loss: 0.57655 - acc: 0.7257 -- iter: 1760/2105
[A[ATraining Step: 452  | total loss: [1m[32m0.56707[0m[0m | time: 113.685s
[2K
| Adam | epoch: 007 | loss: 0.56707 - acc: 0.7344 -- iter: 1792/2105
[A[ATraining Step: 453  | total loss: [1m[32m0.58013[0m[0m | time: 114.970s
[2K
| Adam | epoch: 007 | loss: 0.58013 - acc: 0.7203 -- iter: 1824/2105
[A[ATraining Step: 454  | total loss: [1m[32m0.57466[0m[0m | time: 116.429s
[2K
| Adam | epoch: 007 | loss: 0.57466 - acc: 0.7264 -- iter: 1856/2105
[A[ATraining Step: 455  | total loss: [1m[32m0.58147[0m[0m | time: 117.894s
[2K
| Adam | epoch: 007 | loss: 0.58147 - acc: 0.7163 -- iter: 1888/2105
[A[ATraining Step: 456  | total loss: [1m[32m0.57710[0m[0m | time: 119.239s
[2K
| Adam | epoch: 007 | loss: 0.57710 - acc: 0.7134 -- iter: 1920/2105
[A[ATraining Step: 457  | total loss: [1m[32m0.57045[0m[0m | time: 120.725s
[2K
| Adam | epoch: 007 | loss: 0.57045 - acc: 0.7233 -- iter: 1952/2105
[A[ATraining Step: 458  | total loss: [1m[32m0.56466[0m[0m | time: 122.294s
[2K
| Adam | epoch: 007 | loss: 0.56466 - acc: 0.7291 -- iter: 1984/2105
[A[ATraining Step: 459  | total loss: [1m[32m0.55838[0m[0m | time: 123.595s
[2K
| Adam | epoch: 007 | loss: 0.55838 - acc: 0.7437 -- iter: 2016/2105
[A[ATraining Step: 460  | total loss: [1m[32m0.55499[0m[0m | time: 124.983s
[2K
| Adam | epoch: 007 | loss: 0.55499 - acc: 0.7350 -- iter: 2048/2105
[A[ATraining Step: 461  | total loss: [1m[32m0.57430[0m[0m | time: 132.002s
[2K
| Adam | epoch: 007 | loss: 0.57430 - acc: 0.7208 -- iter: 2080/2105
[A[ATraining Step: 462  | total loss: [1m[32m0.56968[0m[0m | time: 143.699s
[2K
| Adam | epoch: 007 | loss: 0.56968 - acc: 0.7206 | val_loss: 0.56141 - val_acc: 0.7280 -- iter: 2105/2105
--
Training Step: 463  | total loss: [1m[32m0.55973[0m[0m | time: 1.615s
[2K
| Adam | epoch: 008 | loss: 0.55973 - acc: 0.7298 -- iter: 0032/2105
[A[ATraining Step: 464  | total loss: [1m[32m0.55375[0m[0m | time: 3.091s
[2K
| Adam | epoch: 008 | loss: 0.55375 - acc: 0.7318 -- iter: 0064/2105
[A[ATraining Step: 465  | total loss: [1m[32m0.55525[0m[0m | time: 4.505s
[2K
| Adam | epoch: 008 | loss: 0.55525 - acc: 0.7274 -- iter: 0096/2105
[A[ATraining Step: 466  | total loss: [1m[32m0.55798[0m[0m | time: 5.822s
[2K
| Adam | epoch: 008 | loss: 0.55798 - acc: 0.7265 -- iter: 0128/2105
[A[ATraining Step: 467  | total loss: [1m[32m0.55431[0m[0m | time: 7.189s
[2K
| Adam | epoch: 008 | loss: 0.55431 - acc: 0.7258 -- iter: 0160/2105
[A[ATraining Step: 468  | total loss: [1m[32m0.55031[0m[0m | time: 12.625s
[2K
| Adam | epoch: 008 | loss: 0.55031 - acc: 0.7313 -- iter: 0192/2105
[A[ATraining Step: 469  | total loss: [1m[32m0.55131[0m[0m | time: 13.602s
[2K
| Adam | epoch: 008 | loss: 0.55131 - acc: 0.7262 -- iter: 0224/2105
[A[ATraining Step: 470  | total loss: [1m[32m0.55115[0m[0m | time: 14.838s
[2K
| Adam | epoch: 008 | loss: 0.55115 - acc: 0.7256 -- iter: 0256/2105
[A[ATraining Step: 471  | total loss: [1m[32m0.55046[0m[0m | time: 16.225s
[2K
| Adam | epoch: 008 | loss: 0.55046 - acc: 0.7311 -- iter: 0288/2105
[A[ATraining Step: 472  | total loss: [1m[32m0.54957[0m[0m | time: 17.518s
[2K
| Adam | epoch: 008 | loss: 0.54957 - acc: 0.7268 -- iter: 0320/2105
[A[ATraining Step: 473  | total loss: [1m[32m0.54335[0m[0m | time: 18.810s
[2K
| Adam | epoch: 008 | loss: 0.54335 - acc: 0.7260 -- iter: 0352/2105
[A[ATraining Step: 474  | total loss: [1m[32m0.53200[0m[0m | time: 20.164s
[2K
| Adam | epoch: 008 | loss: 0.53200 - acc: 0.7409 -- iter: 0384/2105
[A[ATraining Step: 475  | total loss: [1m[32m0.51687[0m[0m | time: 21.789s
[2K
| Adam | epoch: 008 | loss: 0.51687 - acc: 0.7512 -- iter: 0416/2105
[A[ATraining Step: 476  | total loss: [1m[32m0.51940[0m[0m | time: 23.333s
[2K
| Adam | epoch: 008 | loss: 0.51940 - acc: 0.7417 -- iter: 0448/2105
[A[ATraining Step: 477  | total loss: [1m[32m0.52952[0m[0m | time: 24.641s
[2K
| Adam | epoch: 008 | loss: 0.52952 - acc: 0.7362 -- iter: 0480/2105
[A[ATraining Step: 478  | total loss: [1m[32m0.54823[0m[0m | time: 26.052s
[2K
| Adam | epoch: 008 | loss: 0.54823 - acc: 0.7189 -- iter: 0512/2105
[A[ATraining Step: 479  | total loss: [1m[32m0.54831[0m[0m | time: 27.417s
[2K
| Adam | epoch: 008 | loss: 0.54831 - acc: 0.7157 -- iter: 0544/2105
[A[ATraining Step: 480  | total loss: [1m[32m0.53808[0m[0m | time: 28.890s
[2K
| Adam | epoch: 008 | loss: 0.53808 - acc: 0.7254 -- iter: 0576/2105
[A[ATraining Step: 481  | total loss: [1m[32m0.53414[0m[0m | time: 30.210s
[2K
| Adam | epoch: 008 | loss: 0.53414 - acc: 0.7279 -- iter: 0608/2105
[A[ATraining Step: 482  | total loss: [1m[32m0.53325[0m[0m | time: 31.192s
[2K
| Adam | epoch: 008 | loss: 0.53325 - acc: 0.7301 -- iter: 0640/2105
[A[ATraining Step: 483  | total loss: [1m[32m0.53571[0m[0m | time: 32.189s
[2K
| Adam | epoch: 008 | loss: 0.53571 - acc: 0.7196 -- iter: 0672/2105
[A[ATraining Step: 484  | total loss: [1m[32m0.54936[0m[0m | time: 33.184s
[2K
| Adam | epoch: 008 | loss: 0.54936 - acc: 0.7132 -- iter: 0704/2105
[A[ATraining Step: 485  | total loss: [1m[32m0.55042[0m[0m | time: 34.190s
[2K
| Adam | epoch: 008 | loss: 0.55042 - acc: 0.7169 -- iter: 0736/2105
[A[ATraining Step: 486  | total loss: [1m[32m0.54652[0m[0m | time: 35.176s
[2K
| Adam | epoch: 008 | loss: 0.54652 - acc: 0.7234 -- iter: 0768/2105
[A[ATraining Step: 487  | total loss: [1m[32m0.53667[0m[0m | time: 36.375s
[2K
| Adam | epoch: 008 | loss: 0.53667 - acc: 0.7323 -- iter: 0800/2105
[A[ATraining Step: 488  | total loss: [1m[32m0.54342[0m[0m | time: 37.594s
[2K
| Adam | epoch: 008 | loss: 0.54342 - acc: 0.7247 -- iter: 0832/2105
[A[ATraining Step: 489  | total loss: [1m[32m0.53256[0m[0m | time: 38.467s
[2K
| Adam | epoch: 008 | loss: 0.53256 - acc: 0.7397 -- iter: 0864/2105
[A[ATraining Step: 490  | total loss: [1m[32m0.53368[0m[0m | time: 39.430s
[2K
| Adam | epoch: 008 | loss: 0.53368 - acc: 0.7345 -- iter: 0896/2105
[A[ATraining Step: 491  | total loss: [1m[32m0.53313[0m[0m | time: 40.408s
[2K
| Adam | epoch: 008 | loss: 0.53313 - acc: 0.7423 -- iter: 0928/2105
[A[ATraining Step: 492  | total loss: [1m[32m0.53695[0m[0m | time: 41.429s
[2K
| Adam | epoch: 008 | loss: 0.53695 - acc: 0.7368 -- iter: 0960/2105
[A[ATraining Step: 493  | total loss: [1m[32m0.53837[0m[0m | time: 42.422s
[2K
| Adam | epoch: 008 | loss: 0.53837 - acc: 0.7350 -- iter: 0992/2105
[A[ATraining Step: 494  | total loss: [1m[32m0.53693[0m[0m | time: 43.436s
[2K
| Adam | epoch: 008 | loss: 0.53693 - acc: 0.7334 -- iter: 1024/2105
[A[ATraining Step: 495  | total loss: [1m[32m0.52996[0m[0m | time: 44.406s
[2K
| Adam | epoch: 008 | loss: 0.52996 - acc: 0.7319 -- iter: 1056/2105
[A[ATraining Step: 496  | total loss: [1m[32m0.53315[0m[0m | time: 45.387s
[2K
| Adam | epoch: 008 | loss: 0.53315 - acc: 0.7275 -- iter: 1088/2105
[A[ATraining Step: 497  | total loss: [1m[32m0.53227[0m[0m | time: 46.376s
[2K
| Adam | epoch: 008 | loss: 0.53227 - acc: 0.7297 -- iter: 1120/2105
[A[ATraining Step: 498  | total loss: [1m[32m0.54383[0m[0m | time: 47.626s
[2K
| Adam | epoch: 008 | loss: 0.54383 - acc: 0.7193 -- iter: 1152/2105
[A[ATraining Step: 499  | total loss: [1m[32m0.54154[0m[0m | time: 48.795s
[2K
| Adam | epoch: 008 | loss: 0.54154 - acc: 0.7223 -- iter: 1184/2105
[A[ATraining Step: 500  | total loss: [1m[32m0.53444[0m[0m | time: 49.626s
[2K
| Adam | epoch: 008 | loss: 0.53444 - acc: 0.7313 -- iter: 1216/2105
[A[ATraining Step: 501  | total loss: [1m[32m0.52558[0m[0m | time: 50.601s
[2K
| Adam | epoch: 008 | loss: 0.52558 - acc: 0.7363 -- iter: 1248/2105
[A[ATraining Step: 502  | total loss: [1m[32m0.51215[0m[0m | time: 51.682s
[2K
| Adam | epoch: 008 | loss: 0.51215 - acc: 0.7565 -- iter: 1280/2105
[A[ATraining Step: 503  | total loss: [1m[32m0.51342[0m[0m | time: 52.689s
[2K
| Adam | epoch: 008 | loss: 0.51342 - acc: 0.7589 -- iter: 1312/2105
[A[ATraining Step: 504  | total loss: [1m[32m0.50111[0m[0m | time: 53.725s
[2K
| Adam | epoch: 008 | loss: 0.50111 - acc: 0.7737 -- iter: 1344/2105
[A[ATraining Step: 505  | total loss: [1m[32m0.49922[0m[0m | time: 54.766s
[2K
| Adam | epoch: 008 | loss: 0.49922 - acc: 0.7744 -- iter: 1376/2105
[A[ATraining Step: 506  | total loss: [1m[32m0.48833[0m[0m | time: 55.749s
[2K
| Adam | epoch: 008 | loss: 0.48833 - acc: 0.7814 -- iter: 1408/2105
[A[ATraining Step: 507  | total loss: [1m[32m0.48405[0m[0m | time: 56.712s
[2K
| Adam | epoch: 008 | loss: 0.48405 - acc: 0.7845 -- iter: 1440/2105
[A[ATraining Step: 508  | total loss: [1m[32m0.48585[0m[0m | time: 58.308s
[2K
| Adam | epoch: 008 | loss: 0.48585 - acc: 0.7748 -- iter: 1472/2105
[A[ATraining Step: 509  | total loss: [1m[32m0.48201[0m[0m | time: 59.807s
[2K
| Adam | epoch: 008 | loss: 0.48201 - acc: 0.7692 -- iter: 1504/2105
[A[ATraining Step: 510  | total loss: [1m[32m0.47961[0m[0m | time: 60.748s
[2K
| Adam | epoch: 008 | loss: 0.47961 - acc: 0.7766 -- iter: 1536/2105
[A[ATraining Step: 511  | total loss: [1m[32m0.46994[0m[0m | time: 71.456s
[2K
| Adam | epoch: 008 | loss: 0.46994 - acc: 0.7896 -- iter: 1568/2105
[A[ATraining Step: 512  | total loss: [1m[32m0.47663[0m[0m | time: 79.843s
[2K
| Adam | epoch: 008 | loss: 0.47663 - acc: 0.7856 -- iter: 1600/2105
[A[ATraining Step: 513  | total loss: [1m[32m0.48469[0m[0m | time: 82.938s
[2K
| Adam | epoch: 008 | loss: 0.48469 - acc: 0.7696 -- iter: 1632/2105
[A[ATraining Step: 514  | total loss: [1m[32m0.48346[0m[0m | time: 88.631s
[2K
| Adam | epoch: 008 | loss: 0.48346 - acc: 0.7707 -- iter: 1664/2105
[A[ATraining Step: 515  | total loss: [1m[32m0.48032[0m[0m | time: 93.835s
[2K
| Adam | epoch: 008 | loss: 0.48032 - acc: 0.7749 -- iter: 1696/2105
[A[ATraining Step: 516  | total loss: [1m[32m0.48247[0m[0m | time: 98.536s
[2K
| Adam | epoch: 008 | loss: 0.48247 - acc: 0.7662 -- iter: 1728/2105
[A[ATraining Step: 517  | total loss: [1m[32m0.46736[0m[0m | time: 99.628s
[2K
| Adam | epoch: 008 | loss: 0.46736 - acc: 0.7802 -- iter: 1760/2105
[A[ATraining Step: 518  | total loss: [1m[32m0.47820[0m[0m | time: 100.874s
[2K
| Adam | epoch: 008 | loss: 0.47820 - acc: 0.7647 -- iter: 1792/2105
[A[ATraining Step: 519  | total loss: [1m[32m0.48251[0m[0m | time: 102.236s
[2K
| Adam | epoch: 008 | loss: 0.48251 - acc: 0.7507 -- iter: 1824/2105
[A[ATraining Step: 520  | total loss: [1m[32m0.49139[0m[0m | time: 103.555s
[2K
| Adam | epoch: 008 | loss: 0.49139 - acc: 0.7381 -- iter: 1856/2105
[A[ATraining Step: 521  | total loss: [1m[32m0.49851[0m[0m | time: 104.844s
[2K
| Adam | epoch: 008 | loss: 0.49851 - acc: 0.7299 -- iter: 1888/2105
[A[ATraining Step: 522  | total loss: [1m[32m0.50115[0m[0m | time: 106.280s
[2K
| Adam | epoch: 008 | loss: 0.50115 - acc: 0.7288 -- iter: 1920/2105
[A[ATraining Step: 523  | total loss: [1m[32m0.49532[0m[0m | time: 107.836s
[2K
| Adam | epoch: 008 | loss: 0.49532 - acc: 0.7403 -- iter: 1952/2105
[A[ATraining Step: 524  | total loss: [1m[32m0.49009[0m[0m | time: 109.346s
[2K
| Adam | epoch: 008 | loss: 0.49009 - acc: 0.7444 -- iter: 1984/2105
[A[ATraining Step: 525  | total loss: [1m[32m0.48996[0m[0m | time: 110.846s
[2K
| Adam | epoch: 008 | loss: 0.48996 - acc: 0.7512 -- iter: 2016/2105
[A[ATraining Step: 526  | total loss: [1m[32m0.48743[0m[0m | time: 112.332s
[2K
| Adam | epoch: 008 | loss: 0.48743 - acc: 0.7480 -- iter: 2048/2105
[A[ATraining Step: 527  | total loss: [1m[32m0.49062[0m[0m | time: 119.776s
[2K
| Adam | epoch: 008 | loss: 0.49062 - acc: 0.7419 -- iter: 2080/2105
[A[ATraining Step: 528  | total loss: [1m[32m0.47875[0m[0m | time: 134.449s
[2K
| Adam | epoch: 008 | loss: 0.47875 - acc: 0.7521 | val_loss: 0.57813 - val_acc: 0.7036 -- iter: 2105/2105
--
Training Step: 529  | total loss: [1m[32m0.49266[0m[0m | time: 1.627s
[2K
| Adam | epoch: 009 | loss: 0.49266 - acc: 0.7456 -- iter: 0032/2105
[A[ATraining Step: 530  | total loss: [1m[32m0.48531[0m[0m | time: 3.075s
[2K
| Adam | epoch: 009 | loss: 0.48531 - acc: 0.7523 -- iter: 0064/2105
[A[ATraining Step: 531  | total loss: [1m[32m0.48892[0m[0m | time: 4.318s
[2K
| Adam | epoch: 009 | loss: 0.48892 - acc: 0.7583 -- iter: 0096/2105
[A[ATraining Step: 532  | total loss: [1m[32m0.49039[0m[0m | time: 5.855s
[2K
| Adam | epoch: 009 | loss: 0.49039 - acc: 0.7481 -- iter: 0128/2105
[A[ATraining Step: 533  | total loss: [1m[32m0.48361[0m[0m | time: 7.136s
[2K
| Adam | epoch: 009 | loss: 0.48361 - acc: 0.7546 -- iter: 0160/2105
[A[ATraining Step: 534  | total loss: [1m[32m0.49321[0m[0m | time: 8.405s
[2K
| Adam | epoch: 009 | loss: 0.49321 - acc: 0.7479 -- iter: 0192/2105
[A[ATraining Step: 535  | total loss: [1m[32m0.49048[0m[0m | time: 9.501s
[2K
| Adam | epoch: 009 | loss: 0.49048 - acc: 0.7481 -- iter: 0224/2105
[A[ATraining Step: 536  | total loss: [1m[32m0.49602[0m[0m | time: 10.514s
[2K
| Adam | epoch: 009 | loss: 0.49602 - acc: 0.7413 -- iter: 0256/2105
[A[ATraining Step: 537  | total loss: [1m[32m0.49865[0m[0m | time: 11.911s
[2K
| Adam | epoch: 009 | loss: 0.49865 - acc: 0.7391 -- iter: 0288/2105
[A[ATraining Step: 538  | total loss: [1m[32m0.51922[0m[0m | time: 12.986s
[2K
| Adam | epoch: 009 | loss: 0.51922 - acc: 0.7246 -- iter: 0320/2105
[A[ATraining Step: 539  | total loss: [1m[32m0.50963[0m[0m | time: 14.307s
[2K
| Adam | epoch: 009 | loss: 0.50963 - acc: 0.7334 -- iter: 0352/2105
[A[ATraining Step: 540  | total loss: [1m[32m0.50329[0m[0m | time: 15.650s
[2K
| Adam | epoch: 009 | loss: 0.50329 - acc: 0.7382 -- iter: 0384/2105
[A[ATraining Step: 541  | total loss: [1m[32m0.49921[0m[0m | time: 16.766s
[2K
| Adam | epoch: 009 | loss: 0.49921 - acc: 0.7456 -- iter: 0416/2105
[A[ATraining Step: 542  | total loss: [1m[32m0.49637[0m[0m | time: 18.099s
[2K
| Adam | epoch: 009 | loss: 0.49637 - acc: 0.7492 -- iter: 0448/2105
[A[ATraining Step: 543  | total loss: [1m[32m0.48658[0m[0m | time: 19.362s
[2K
| Adam | epoch: 009 | loss: 0.48658 - acc: 0.7586 -- iter: 0480/2105
[A[ATraining Step: 544  | total loss: [1m[32m0.47894[0m[0m | time: 20.746s
[2K
| Adam | epoch: 009 | loss: 0.47894 - acc: 0.7671 -- iter: 0512/2105
[A[ATraining Step: 545  | total loss: [1m[32m0.49836[0m[0m | time: 22.069s
[2K
| Adam | epoch: 009 | loss: 0.49836 - acc: 0.7498 -- iter: 0544/2105
[A[ATraining Step: 546  | total loss: [1m[32m0.50424[0m[0m | time: 23.617s
[2K
| Adam | epoch: 009 | loss: 0.50424 - acc: 0.7436 -- iter: 0576/2105
[A[ATraining Step: 547  | total loss: [1m[32m0.50515[0m[0m | time: 24.958s
[2K
| Adam | epoch: 009 | loss: 0.50515 - acc: 0.7380 -- iter: 0608/2105
[A[ATraining Step: 548  | total loss: [1m[32m0.49078[0m[0m | time: 26.427s
[2K
| Adam | epoch: 009 | loss: 0.49078 - acc: 0.7548 -- iter: 0640/2105
[A[ATraining Step: 549  | total loss: [1m[32m0.49715[0m[0m | time: 27.717s
[2K
| Adam | epoch: 009 | loss: 0.49715 - acc: 0.7481 -- iter: 0672/2105
[A[ATraining Step: 550  | total loss: [1m[32m0.49683[0m[0m | time: 29.050s
[2K
| Adam | epoch: 009 | loss: 0.49683 - acc: 0.7483 -- iter: 0704/2105
[A[ATraining Step: 551  | total loss: [1m[32m0.48054[0m[0m | time: 30.249s
[2K
| Adam | epoch: 009 | loss: 0.48054 - acc: 0.7609 -- iter: 0736/2105
[A[ATraining Step: 552  | total loss: [1m[32m0.47254[0m[0m | time: 31.444s
[2K
| Adam | epoch: 009 | loss: 0.47254 - acc: 0.7661 -- iter: 0768/2105
[A[ATraining Step: 553  | total loss: [1m[32m0.46583[0m[0m | time: 32.815s
[2K
| Adam | epoch: 009 | loss: 0.46583 - acc: 0.7739 -- iter: 0800/2105
[A[ATraining Step: 554  | total loss: [1m[32m0.46197[0m[0m | time: 34.269s
[2K
| Adam | epoch: 009 | loss: 0.46197 - acc: 0.7777 -- iter: 0832/2105
[A[ATraining Step: 555  | total loss: [1m[32m0.46731[0m[0m | time: 35.769s
[2K
| Adam | epoch: 009 | loss: 0.46731 - acc: 0.7718 -- iter: 0864/2105
[A[ATraining Step: 556  | total loss: [1m[32m0.45670[0m[0m | time: 37.115s
[2K
| Adam | epoch: 009 | loss: 0.45670 - acc: 0.7821 -- iter: 0896/2105
[A[ATraining Step: 557  | total loss: [1m[32m0.46702[0m[0m | time: 38.582s
[2K
| Adam | epoch: 009 | loss: 0.46702 - acc: 0.7821 -- iter: 0928/2105
[A[ATraining Step: 558  | total loss: [1m[32m0.46376[0m[0m | time: 40.153s
[2K
| Adam | epoch: 009 | loss: 0.46376 - acc: 0.7913 -- iter: 0960/2105
[A[ATraining Step: 559  | total loss: [1m[32m0.47278[0m[0m | time: 41.796s
[2K
| Adam | epoch: 009 | loss: 0.47278 - acc: 0.7841 -- iter: 0992/2105
[A[ATraining Step: 560  | total loss: [1m[32m0.46967[0m[0m | time: 50.112s
[2K
| Adam | epoch: 009 | loss: 0.46967 - acc: 0.7838 -- iter: 1024/2105
[A[ATraining Step: 561  | total loss: [1m[32m0.46043[0m[0m | time: 61.402s
[2K
| Adam | epoch: 009 | loss: 0.46043 - acc: 0.7960 -- iter: 1056/2105
[A[ATraining Step: 562  | total loss: [1m[32m0.45227[0m[0m | time: 72.821s
[2K
| Adam | epoch: 009 | loss: 0.45227 - acc: 0.7946 -- iter: 1088/2105
[A[ATraining Step: 563  | total loss: [1m[32m0.44696[0m[0m | time: 74.212s
[2K
| Adam | epoch: 009 | loss: 0.44696 - acc: 0.7964 -- iter: 1120/2105
[A[ATraining Step: 564  | total loss: [1m[32m0.45753[0m[0m | time: 75.551s
[2K
| Adam | epoch: 009 | loss: 0.45753 - acc: 0.7917 -- iter: 1152/2105
[A[ATraining Step: 565  | total loss: [1m[32m0.46752[0m[0m | time: 76.726s
[2K
| Adam | epoch: 009 | loss: 0.46752 - acc: 0.7844 -- iter: 1184/2105
[A[ATraining Step: 566  | total loss: [1m[32m0.48422[0m[0m | time: 77.999s
[2K
| Adam | epoch: 009 | loss: 0.48422 - acc: 0.7779 -- iter: 1216/2105
[A[ATraining Step: 567  | total loss: [1m[32m0.50114[0m[0m | time: 79.450s
[2K
| Adam | epoch: 009 | loss: 0.50114 - acc: 0.7626 -- iter: 1248/2105
[A[ATraining Step: 568  | total loss: [1m[32m0.49093[0m[0m | time: 80.845s
[2K
| Adam | epoch: 009 | loss: 0.49093 - acc: 0.7644 -- iter: 1280/2105
[A[ATraining Step: 569  | total loss: [1m[32m0.47941[0m[0m | time: 82.239s
[2K
| Adam | epoch: 009 | loss: 0.47941 - acc: 0.7755 -- iter: 1312/2105
[A[ATraining Step: 570  | total loss: [1m[32m0.48152[0m[0m | time: 83.585s
[2K
| Adam | epoch: 009 | loss: 0.48152 - acc: 0.7729 -- iter: 1344/2105
[A[ATraining Step: 571  | total loss: [1m[32m0.48956[0m[0m | time: 85.093s
[2K
| Adam | epoch: 009 | loss: 0.48956 - acc: 0.7675 -- iter: 1376/2105
[A[ATraining Step: 572  | total loss: [1m[32m0.49225[0m[0m | time: 86.536s
[2K
| Adam | epoch: 009 | loss: 0.49225 - acc: 0.7689 -- iter: 1408/2105
[A[ATraining Step: 573  | total loss: [1m[32m0.48602[0m[0m | time: 92.371s
[2K
| Adam | epoch: 009 | loss: 0.48602 - acc: 0.7639 -- iter: 1440/2105
[A[ATraining Step: 574  | total loss: [1m[32m0.50150[0m[0m | time: 103.252s
[2K
| Adam | epoch: 009 | loss: 0.50150 - acc: 0.7562 -- iter: 1472/2105
[A[ATraining Step: 575  | total loss: [1m[32m0.47876[0m[0m | time: 114.347s
[2K
| Adam | epoch: 009 | loss: 0.47876 - acc: 0.7744 -- iter: 1504/2105
[A[ATraining Step: 576  | total loss: [1m[32m0.46771[0m[0m | time: 115.654s
[2K
| Adam | epoch: 009 | loss: 0.46771 - acc: 0.7813 -- iter: 1536/2105
[A[ATraining Step: 577  | total loss: [1m[32m0.48044[0m[0m | time: 116.879s
[2K
| Adam | epoch: 009 | loss: 0.48044 - acc: 0.7751 -- iter: 1568/2105
[A[ATraining Step: 578  | total loss: [1m[32m0.48550[0m[0m | time: 118.115s
[2K
| Adam | epoch: 009 | loss: 0.48550 - acc: 0.7694 -- iter: 1600/2105
[A[ATraining Step: 579  | total loss: [1m[32m0.49562[0m[0m | time: 119.473s
[2K
| Adam | epoch: 009 | loss: 0.49562 - acc: 0.7644 -- iter: 1632/2105
[A[ATraining Step: 580  | total loss: [1m[32m0.49508[0m[0m | time: 120.986s
[2K
| Adam | epoch: 009 | loss: 0.49508 - acc: 0.7598 -- iter: 1664/2105
[A[ATraining Step: 581  | total loss: [1m[32m0.49100[0m[0m | time: 122.510s
[2K
| Adam | epoch: 009 | loss: 0.49100 - acc: 0.7619 -- iter: 1696/2105
[A[ATraining Step: 582  | total loss: [1m[32m0.47595[0m[0m | time: 123.848s
[2K
| Adam | epoch: 009 | loss: 0.47595 - acc: 0.7795 -- iter: 1728/2105
[A[ATraining Step: 583  | total loss: [1m[32m0.47709[0m[0m | time: 125.242s
[2K
| Adam | epoch: 009 | loss: 0.47709 - acc: 0.7765 -- iter: 1760/2105
[A[ATraining Step: 584  | total loss: [1m[32m0.47075[0m[0m | time: 126.700s
[2K
| Adam | epoch: 009 | loss: 0.47075 - acc: 0.7770 -- iter: 1792/2105
[A[ATraining Step: 585  | total loss: [1m[32m0.45981[0m[0m | time: 128.233s
[2K
| Adam | epoch: 009 | loss: 0.45981 - acc: 0.7774 -- iter: 1824/2105
[A[ATraining Step: 586  | total loss: [1m[32m0.46105[0m[0m | time: 129.699s
[2K
| Adam | epoch: 009 | loss: 0.46105 - acc: 0.7747 -- iter: 1856/2105
[A[ATraining Step: 587  | total loss: [1m[32m0.45427[0m[0m | time: 130.935s
[2K
| Adam | epoch: 009 | loss: 0.45427 - acc: 0.7910 -- iter: 1888/2105
[A[ATraining Step: 588  | total loss: [1m[32m0.45417[0m[0m | time: 132.125s
[2K
| Adam | epoch: 009 | loss: 0.45417 - acc: 0.7900 -- iter: 1920/2105
[A[ATraining Step: 589  | total loss: [1m[32m0.45106[0m[0m | time: 133.233s
[2K
| Adam | epoch: 009 | loss: 0.45106 - acc: 0.7798 -- iter: 1952/2105
[A[ATraining Step: 590  | total loss: [1m[32m0.44152[0m[0m | time: 134.010s
[2K
| Adam | epoch: 009 | loss: 0.44152 - acc: 0.7924 -- iter: 1984/2105
[A[ATraining Step: 591  | total loss: [1m[32m0.45031[0m[0m | time: 134.982s
[2K
| Adam | epoch: 009 | loss: 0.45031 - acc: 0.7882 -- iter: 2016/2105
[A[ATraining Step: 592  | total loss: [1m[32m0.46834[0m[0m | time: 136.009s
[2K
| Adam | epoch: 009 | loss: 0.46834 - acc: 0.7750 -- iter: 2048/2105
[A[ATraining Step: 593  | total loss: [1m[32m0.48980[0m[0m | time: 136.993s
[2K
| Adam | epoch: 009 | loss: 0.48980 - acc: 0.7631 -- iter: 2080/2105
[A[ATraining Step: 594  | total loss: [1m[32m0.51660[0m[0m | time: 142.076s
[2K
| Adam | epoch: 009 | loss: 0.51660 - acc: 0.7399 | val_loss: 0.49796 - val_acc: 0.7462 -- iter: 2105/2105
--
Training Step: 595  | total loss: [1m[32m0.50015[0m[0m | time: 1.012s
[2K
| Adam | epoch: 010 | loss: 0.50015 - acc: 0.7503 -- iter: 0032/2105
[A[ATraining Step: 596  | total loss: [1m[32m0.49380[0m[0m | time: 2.077s
[2K
| Adam | epoch: 010 | loss: 0.49380 - acc: 0.7534 -- iter: 0064/2105
[A[ATraining Step: 597  | total loss: [1m[32m0.49639[0m[0m | time: 3.116s
[2K
| Adam | epoch: 010 | loss: 0.49639 - acc: 0.7468 -- iter: 0096/2105
[A[ATraining Step: 598  | total loss: [1m[32m0.48634[0m[0m | time: 4.162s
[2K
| Adam | epoch: 010 | loss: 0.48634 - acc: 0.7565 -- iter: 0128/2105
[A[ATraining Step: 599  | total loss: [1m[32m0.50617[0m[0m | time: 5.185s
[2K
| Adam | epoch: 010 | loss: 0.50617 - acc: 0.7402 -- iter: 0160/2105
[A[ATraining Step: 600  | total loss: [1m[32m0.50840[0m[0m | time: 10.961s
[2K
| Adam | epoch: 010 | loss: 0.50840 - acc: 0.7287 | val_loss: 0.63104 - val_acc: 0.6459 -- iter: 0192/2105
--
Training Step: 601  | total loss: [1m[32m0.51813[0m[0m | time: 12.215s
[2K
| Adam | epoch: 010 | loss: 0.51813 - acc: 0.7183 -- iter: 0224/2105
[A[ATraining Step: 602  | total loss: [1m[32m0.51999[0m[0m | time: 13.122s
[2K
| Adam | epoch: 010 | loss: 0.51999 - acc: 0.7090 -- iter: 0256/2105
[A[ATraining Step: 603  | total loss: [1m[32m0.51130[0m[0m | time: 19.615s
[2K
| Adam | epoch: 010 | loss: 0.51130 - acc: 0.7101 -- iter: 0288/2105
[A[ATraining Step: 604  | total loss: [1m[32m0.49782[0m[0m | time: 21.434s
[2K
| Adam | epoch: 010 | loss: 0.49782 - acc: 0.7351 -- iter: 0320/2105
[A[ATraining Step: 605  | total loss: [1m[32m0.49344[0m[0m | time: 25.398s
[2K
| Adam | epoch: 010 | loss: 0.49344 - acc: 0.7303 -- iter: 0352/2105
[A[ATraining Step: 606  | total loss: [1m[32m0.49210[0m[0m | time: 26.658s
[2K
| Adam | epoch: 010 | loss: 0.49210 - acc: 0.7354 -- iter: 0384/2105
[A[ATraining Step: 607  | total loss: [1m[32m0.49679[0m[0m | time: 28.064s
[2K
| Adam | epoch: 010 | loss: 0.49679 - acc: 0.7275 -- iter: 0416/2105
[A[ATraining Step: 608  | total loss: [1m[32m0.50907[0m[0m | time: 29.570s
[2K
| Adam | epoch: 010 | loss: 0.50907 - acc: 0.7204 -- iter: 0448/2105
[A[ATraining Step: 609  | total loss: [1m[32m0.51902[0m[0m | time: 31.038s
[2K
| Adam | epoch: 010 | loss: 0.51902 - acc: 0.7265 -- iter: 0480/2105
[A[ATraining Step: 610  | total loss: [1m[32m0.53811[0m[0m | time: 32.456s
[2K
| Adam | epoch: 010 | loss: 0.53811 - acc: 0.7101 -- iter: 0512/2105
[A[ATraining Step: 611  | total loss: [1m[32m0.52912[0m[0m | time: 33.832s
[2K
| Adam | epoch: 010 | loss: 0.52912 - acc: 0.7203 -- iter: 0544/2105
[A[ATraining Step: 612  | total loss: [1m[32m0.52181[0m[0m | time: 35.226s
[2K
| Adam | epoch: 010 | loss: 0.52181 - acc: 0.7233 -- iter: 0576/2105
[A[ATraining Step: 613  | total loss: [1m[32m0.51712[0m[0m | time: 36.584s
[2K
| Adam | epoch: 010 | loss: 0.51712 - acc: 0.7291 -- iter: 0608/2105
[A[ATraining Step: 614  | total loss: [1m[32m0.50884[0m[0m | time: 38.125s
[2K
| Adam | epoch: 010 | loss: 0.50884 - acc: 0.7405 -- iter: 0640/2105
[A[ATraining Step: 615  | total loss: [1m[32m0.49875[0m[0m | time: 39.553s
[2K
| Adam | epoch: 010 | loss: 0.49875 - acc: 0.7446 -- iter: 0672/2105
[A[ATraining Step: 616  | total loss: [1m[32m0.50429[0m[0m | time: 40.931s
[2K
| Adam | epoch: 010 | loss: 0.50429 - acc: 0.7358 -- iter: 0704/2105
[A[ATraining Step: 617  | total loss: [1m[32m0.49229[0m[0m | time: 42.110s
[2K
| Adam | epoch: 010 | loss: 0.49229 - acc: 0.7435 -- iter: 0736/2105
[A[ATraining Step: 618  | total loss: [1m[32m0.49178[0m[0m | time: 43.400s
[2K
| Adam | epoch: 010 | loss: 0.49178 - acc: 0.7379 -- iter: 0768/2105
[A[ATraining Step: 619  | total loss: [1m[32m0.48371[0m[0m | time: 44.694s
[2K
| Adam | epoch: 010 | loss: 0.48371 - acc: 0.7484 -- iter: 0800/2105
[A[ATraining Step: 620  | total loss: [1m[32m0.47480[0m[0m | time: 46.064s
[2K
| Adam | epoch: 010 | loss: 0.47480 - acc: 0.7642 -- iter: 0832/2105
[A[ATraining Step: 621  | total loss: [1m[32m0.47503[0m[0m | time: 47.465s
[2K
| Adam | epoch: 010 | loss: 0.47503 - acc: 0.7597 -- iter: 0864/2105
[A[ATraining Step: 622  | total loss: [1m[32m0.46628[0m[0m | time: 49.135s
[2K
| Adam | epoch: 010 | loss: 0.46628 - acc: 0.7650 -- iter: 0896/2105
[A[ATraining Step: 623  | total loss: [1m[32m0.46403[0m[0m | time: 50.713s
[2K
| Adam | epoch: 010 | loss: 0.46403 - acc: 0.7666 -- iter: 0928/2105
[A[ATraining Step: 624  | total loss: [1m[32m0.46786[0m[0m | time: 52.182s
[2K
| Adam | epoch: 010 | loss: 0.46786 - acc: 0.7618 -- iter: 0960/2105
[A[ATraining Step: 625  | total loss: [1m[32m0.46247[0m[0m | time: 53.694s
[2K
| Adam | epoch: 010 | loss: 0.46247 - acc: 0.7700 -- iter: 0992/2105
[A[ATraining Step: 626  | total loss: [1m[32m0.44240[0m[0m | time: 55.215s
[2K
| Adam | epoch: 010 | loss: 0.44240 - acc: 0.7930 -- iter: 1024/2105
[A[ATraining Step: 627  | total loss: [1m[32m0.43881[0m[0m | time: 56.815s
[2K
| Adam | epoch: 010 | loss: 0.43881 - acc: 0.7950 -- iter: 1056/2105
[A[ATraining Step: 628  | total loss: [1m[32m0.43438[0m[0m | time: 58.080s
[2K
| Adam | epoch: 010 | loss: 0.43438 - acc: 0.7998 -- iter: 1088/2105
[A[ATraining Step: 629  | total loss: [1m[32m0.44171[0m[0m | time: 66.859s
[2K
| Adam | epoch: 010 | loss: 0.44171 - acc: 0.7886 -- iter: 1120/2105
[A[ATraining Step: 630  | total loss: [1m[32m0.42329[0m[0m | time: 77.777s
[2K
| Adam | epoch: 010 | loss: 0.42329 - acc: 0.8035 -- iter: 1152/2105
[A[ATraining Step: 631  | total loss: [1m[32m0.41962[0m[0m | time: 85.724s
[2K
| Adam | epoch: 010 | loss: 0.41962 - acc: 0.8075 -- iter: 1184/2105
[A[ATraining Step: 632  | total loss: [1m[32m0.40960[0m[0m | time: 87.031s
[2K
| Adam | epoch: 010 | loss: 0.40960 - acc: 0.8174 -- iter: 1216/2105
[A[ATraining Step: 633  | total loss: [1m[32m0.40558[0m[0m | time: 88.323s
[2K
| Adam | epoch: 010 | loss: 0.40558 - acc: 0.8200 -- iter: 1248/2105
[A[ATraining Step: 634  | total loss: [1m[32m0.39450[0m[0m | time: 89.750s
[2K
| Adam | epoch: 010 | loss: 0.39450 - acc: 0.8255 -- iter: 1280/2105
[A[ATraining Step: 635  | total loss: [1m[32m0.38829[0m[0m | time: 91.246s
[2K
| Adam | epoch: 010 | loss: 0.38829 - acc: 0.8273 -- iter: 1312/2105
[A[ATraining Step: 636  | total loss: [1m[32m0.39268[0m[0m | time: 92.630s
[2K
| Adam | epoch: 010 | loss: 0.39268 - acc: 0.8196 -- iter: 1344/2105
[A[ATraining Step: 637  | total loss: [1m[32m0.38292[0m[0m | time: 94.216s
[2K
| Adam | epoch: 010 | loss: 0.38292 - acc: 0.8283 -- iter: 1376/2105
[A[ATraining Step: 638  | total loss: [1m[32m0.39555[0m[0m | time: 95.657s
[2K
| Adam | epoch: 010 | loss: 0.39555 - acc: 0.8204 -- iter: 1408/2105
[A[ATraining Step: 639  | total loss: [1m[32m0.39045[0m[0m | time: 97.020s
[2K
| Adam | epoch: 010 | loss: 0.39045 - acc: 0.8259 -- iter: 1440/2105
[A[ATraining Step: 640  | total loss: [1m[32m0.39408[0m[0m | time: 98.499s
[2K
| Adam | epoch: 010 | loss: 0.39408 - acc: 0.8246 -- iter: 1472/2105
[A[ATraining Step: 641  | total loss: [1m[32m0.39016[0m[0m | time: 99.882s
[2K
| Adam | epoch: 010 | loss: 0.39016 - acc: 0.8234 -- iter: 1504/2105
[A[ATraining Step: 642  | total loss: [1m[32m0.38409[0m[0m | time: 101.128s
[2K
| Adam | epoch: 010 | loss: 0.38409 - acc: 0.8254 -- iter: 1536/2105
[A[ATraining Step: 643  | total loss: [1m[32m0.37655[0m[0m | time: 102.515s
[2K
| Adam | epoch: 010 | loss: 0.37655 - acc: 0.8272 -- iter: 1568/2105
[A[ATraining Step: 644  | total loss: [1m[32m0.36686[0m[0m | time: 103.801s
[2K
| Adam | epoch: 010 | loss: 0.36686 - acc: 0.8320 -- iter: 1600/2105
[A[ATraining Step: 645  | total loss: [1m[32m0.35693[0m[0m | time: 105.122s
[2K
| Adam | epoch: 010 | loss: 0.35693 - acc: 0.8426 -- iter: 1632/2105
[A[ATraining Step: 646  | total loss: [1m[32m0.35907[0m[0m | time: 106.513s
[2K
| Adam | epoch: 010 | loss: 0.35907 - acc: 0.8458 -- iter: 1664/2105
[A[ATraining Step: 647  | total loss: [1m[32m0.38500[0m[0m | time: 107.883s
[2K
| Adam | epoch: 010 | loss: 0.38500 - acc: 0.8268 -- iter: 1696/2105
[A[ATraining Step: 648  | total loss: [1m[32m0.37679[0m[0m | time: 109.478s
[2K
| Adam | epoch: 010 | loss: 0.37679 - acc: 0.8285 -- iter: 1728/2105
[A[ATraining Step: 649  | total loss: [1m[32m0.37799[0m[0m | time: 110.749s
[2K
| Adam | epoch: 010 | loss: 0.37799 - acc: 0.8269 -- iter: 1760/2105
[A[ATraining Step: 650  | total loss: [1m[32m0.36577[0m[0m | time: 112.268s
[2K
| Adam | epoch: 010 | loss: 0.36577 - acc: 0.8349 -- iter: 1792/2105
[A[ATraining Step: 651  | total loss: [1m[32m0.37086[0m[0m | time: 113.643s
[2K
| Adam | epoch: 010 | loss: 0.37086 - acc: 0.8358 -- iter: 1824/2105
[A[ATraining Step: 652  | total loss: [1m[32m0.35847[0m[0m | time: 115.168s
[2K
| Adam | epoch: 010 | loss: 0.35847 - acc: 0.8459 -- iter: 1856/2105
[A[ATraining Step: 653  | total loss: [1m[32m0.36462[0m[0m | time: 116.571s
[2K
| Adam | epoch: 010 | loss: 0.36462 - acc: 0.8426 -- iter: 1888/2105
[A[ATraining Step: 654  | total loss: [1m[32m0.36254[0m[0m | time: 118.309s
[2K
| Adam | epoch: 010 | loss: 0.36254 - acc: 0.8427 -- iter: 1920/2105
[A[ATraining Step: 655  | total loss: [1m[32m0.35964[0m[0m | time: 119.840s
[2K
| Adam | epoch: 010 | loss: 0.35964 - acc: 0.8397 -- iter: 1952/2105
[A[ATraining Step: 656  | total loss: [1m[32m0.35764[0m[0m | time: 121.647s
[2K
| Adam | epoch: 010 | loss: 0.35764 - acc: 0.8432 -- iter: 1984/2105
[A[ATraining Step: 657  | total loss: [1m[32m0.35546[0m[0m | time: 128.993s
[2K
| Adam | epoch: 010 | loss: 0.35546 - acc: 0.8464 -- iter: 2016/2105
[A[ATraining Step: 658  | total loss: [1m[32m0.35180[0m[0m | time: 135.993s
[2K
| Adam | epoch: 010 | loss: 0.35180 - acc: 0.8524 -- iter: 2048/2105
[A[ATraining Step: 659  | total loss: [1m[32m0.34292[0m[0m | time: 137.301s
[2K
| Adam | epoch: 010 | loss: 0.34292 - acc: 0.8609 -- iter: 2080/2105
[A[ATraining Step: 660  | total loss: [1m[32m0.34909[0m[0m | time: 144.708s
[2K
| Adam | epoch: 010 | loss: 0.34909 - acc: 0.8561 | val_loss: 0.47144 - val_acc: 0.7796 -- iter: 2105/2105
--
Training Step: 661  | total loss: [1m[32m0.34601[0m[0m | time: 1.462s
[2K
| Adam | epoch: 011 | loss: 0.34601 - acc: 0.8579 -- iter: 0032/2105
[A[ATraining Step: 662  | total loss: [1m[32m0.33904[0m[0m | time: 2.695s
[2K
| Adam | epoch: 011 | loss: 0.33904 - acc: 0.8659 -- iter: 0064/2105
[A[ATraining Step: 663  | total loss: [1m[32m0.33617[0m[0m | time: 18.403s
[2K
| Adam | epoch: 011 | loss: 0.33617 - acc: 0.8731 -- iter: 0096/2105
[A[ATraining Step: 664  | total loss: [1m[32m0.33196[0m[0m | time: 28.810s
[2K
| Adam | epoch: 011 | loss: 0.33196 - acc: 0.8764 -- iter: 0128/2105
[A[ATraining Step: 665  | total loss: [1m[32m0.33868[0m[0m | time: 36.024s
[2K
| Adam | epoch: 011 | loss: 0.33868 - acc: 0.8669 -- iter: 0160/2105
[A[ATraining Step: 666  | total loss: [1m[32m0.34854[0m[0m | time: 46.573s
[2K
| Adam | epoch: 011 | loss: 0.34854 - acc: 0.8614 -- iter: 0192/2105
[A[ATraining Step: 667  | total loss: [1m[32m0.34391[0m[0m | time: 48.795s
[2K
| Adam | epoch: 011 | loss: 0.34391 - acc: 0.8597 -- iter: 0224/2105
[A[ATraining Step: 668  | total loss: [1m[32m0.37313[0m[0m | time: 50.032s
[2K
| Adam | epoch: 011 | loss: 0.37313 - acc: 0.8518 -- iter: 0256/2105
[A[ATraining Step: 669  | total loss: [1m[32m0.39374[0m[0m | time: 51.115s
[2K
| Adam | epoch: 011 | loss: 0.39374 - acc: 0.8385 -- iter: 0288/2105
[A[ATraining Step: 670  | total loss: [1m[32m0.38044[0m[0m | time: 52.240s
[2K
| Adam | epoch: 011 | loss: 0.38044 - acc: 0.8467 -- iter: 0320/2105
[A[ATraining Step: 671  | total loss: [1m[32m0.36381[0m[0m | time: 53.694s
[2K
| Adam | epoch: 011 | loss: 0.36381 - acc: 0.8580 -- iter: 0352/2105
[A[ATraining Step: 672  | total loss: [1m[32m0.37074[0m[0m | time: 55.015s
[2K
| Adam | epoch: 011 | loss: 0.37074 - acc: 0.8566 -- iter: 0384/2105
[A[ATraining Step: 673  | total loss: [1m[32m0.36522[0m[0m | time: 56.494s
[2K
| Adam | epoch: 011 | loss: 0.36522 - acc: 0.8553 -- iter: 0416/2105
[A[ATraining Step: 674  | total loss: [1m[32m0.36223[0m[0m | time: 58.113s
[2K
| Adam | epoch: 011 | loss: 0.36223 - acc: 0.8604 -- iter: 0448/2105
[A[ATraining Step: 675  | total loss: [1m[32m0.35648[0m[0m | time: 59.475s
[2K
| Adam | epoch: 011 | loss: 0.35648 - acc: 0.8650 -- iter: 0480/2105
[A[ATraining Step: 676  | total loss: [1m[32m0.34516[0m[0m | time: 60.986s
[2K
| Adam | epoch: 011 | loss: 0.34516 - acc: 0.8691 -- iter: 0512/2105
[A[ATraining Step: 677  | total loss: [1m[32m0.33461[0m[0m | time: 62.440s
[2K
| Adam | epoch: 011 | loss: 0.33461 - acc: 0.8759 -- iter: 0544/2105
[A[ATraining Step: 678  | total loss: [1m[32m0.33374[0m[0m | time: 64.060s
[2K
| Adam | epoch: 011 | loss: 0.33374 - acc: 0.8790 -- iter: 0576/2105
[A[ATraining Step: 679  | total loss: [1m[32m0.32858[0m[0m | time: 65.474s
[2K
| Adam | epoch: 011 | loss: 0.32858 - acc: 0.8817 -- iter: 0608/2105
[A[ATraining Step: 680  | total loss: [1m[32m0.33489[0m[0m | time: 66.849s
[2K
| Adam | epoch: 011 | loss: 0.33489 - acc: 0.8685 -- iter: 0640/2105
[A[ATraining Step: 681  | total loss: [1m[32m0.33898[0m[0m | time: 67.975s
[2K
| Adam | epoch: 011 | loss: 0.33898 - acc: 0.8536 -- iter: 0672/2105
[A[ATraining Step: 682  | total loss: [1m[32m0.34287[0m[0m | time: 69.187s
[2K
| Adam | epoch: 011 | loss: 0.34287 - acc: 0.8557 -- iter: 0704/2105
[A[ATraining Step: 683  | total loss: [1m[32m0.35293[0m[0m | time: 70.280s
[2K
| Adam | epoch: 011 | loss: 0.35293 - acc: 0.8451 -- iter: 0736/2105
[A[ATraining Step: 684  | total loss: [1m[32m0.35637[0m[0m | time: 71.401s
[2K
| Adam | epoch: 011 | loss: 0.35637 - acc: 0.8387 -- iter: 0768/2105
[A[ATraining Step: 685  | total loss: [1m[32m0.35776[0m[0m | time: 72.420s
[2K
| Adam | epoch: 011 | loss: 0.35776 - acc: 0.8361 -- iter: 0800/2105
[A[ATraining Step: 686  | total loss: [1m[32m0.37025[0m[0m | time: 73.513s
[2K
| Adam | epoch: 011 | loss: 0.37025 - acc: 0.8338 -- iter: 0832/2105
[A[ATraining Step: 687  | total loss: [1m[32m0.36280[0m[0m | time: 74.682s
[2K
| Adam | epoch: 011 | loss: 0.36280 - acc: 0.8348 -- iter: 0864/2105
[A[ATraining Step: 688  | total loss: [1m[32m0.36113[0m[0m | time: 75.748s
[2K
| Adam | epoch: 011 | loss: 0.36113 - acc: 0.8357 -- iter: 0896/2105
[A[ATraining Step: 689  | total loss: [1m[32m0.35566[0m[0m | time: 76.945s
[2K
| Adam | epoch: 011 | loss: 0.35566 - acc: 0.8365 -- iter: 0928/2105
[A[ATraining Step: 690  | total loss: [1m[32m0.34643[0m[0m | time: 78.036s
[2K
| Adam | epoch: 011 | loss: 0.34643 - acc: 0.8434 -- iter: 0960/2105
[A[ATraining Step: 691  | total loss: [1m[32m0.34866[0m[0m | time: 79.111s
[2K
| Adam | epoch: 011 | loss: 0.34866 - acc: 0.8403 -- iter: 0992/2105
[A[ATraining Step: 692  | total loss: [1m[32m0.35085[0m[0m | time: 80.232s
[2K
| Adam | epoch: 011 | loss: 0.35085 - acc: 0.8344 -- iter: 1024/2105
[A[ATraining Step: 693  | total loss: [1m[32m0.34844[0m[0m | time: 81.366s
[2K
| Adam | epoch: 011 | loss: 0.34844 - acc: 0.8385 -- iter: 1056/2105
[A[ATraining Step: 694  | total loss: [1m[32m0.36258[0m[0m | time: 82.448s
[2K
| Adam | epoch: 011 | loss: 0.36258 - acc: 0.8296 -- iter: 1088/2105
[A[ATraining Step: 695  | total loss: [1m[32m0.35025[0m[0m | time: 83.496s
[2K
| Adam | epoch: 011 | loss: 0.35025 - acc: 0.8436 -- iter: 1120/2105
[A[ATraining Step: 696  | total loss: [1m[32m0.34190[0m[0m | time: 84.574s
[2K
| Adam | epoch: 011 | loss: 0.34190 - acc: 0.8436 -- iter: 1152/2105
[A[ATraining Step: 697  | total loss: [1m[32m0.35585[0m[0m | time: 85.731s
[2K
| Adam | epoch: 011 | loss: 0.35585 - acc: 0.8373 -- iter: 1184/2105
[A[ATraining Step: 698  | total loss: [1m[32m0.35496[0m[0m | time: 86.875s
[2K
| Adam | epoch: 011 | loss: 0.35496 - acc: 0.8442 -- iter: 1216/2105
[A[ATraining Step: 699  | total loss: [1m[32m0.37192[0m[0m | time: 87.990s
[2K
| Adam | epoch: 011 | loss: 0.37192 - acc: 0.8317 -- iter: 1248/2105
[A[ATraining Step: 700  | total loss: [1m[32m0.35933[0m[0m | time: 89.053s
[2K
| Adam | epoch: 011 | loss: 0.35933 - acc: 0.8391 -- iter: 1280/2105
[A[ATraining Step: 701  | total loss: [1m[32m0.36122[0m[0m | time: 90.171s
[2K
| Adam | epoch: 011 | loss: 0.36122 - acc: 0.8365 -- iter: 1312/2105
[A[ATraining Step: 702  | total loss: [1m[32m0.36149[0m[0m | time: 91.249s
[2K
| Adam | epoch: 011 | loss: 0.36149 - acc: 0.8403 -- iter: 1344/2105
[A[ATraining Step: 703  | total loss: [1m[32m0.35765[0m[0m | time: 92.343s
[2K
| Adam | epoch: 011 | loss: 0.35765 - acc: 0.8375 -- iter: 1376/2105
[A[ATraining Step: 704  | total loss: [1m[32m0.35986[0m[0m | time: 93.419s
[2K
| Adam | epoch: 011 | loss: 0.35986 - acc: 0.8257 -- iter: 1408/2105
[A[ATraining Step: 705  | total loss: [1m[32m0.37025[0m[0m | time: 94.217s
[2K
| Adam | epoch: 011 | loss: 0.37025 - acc: 0.8243 -- iter: 1440/2105
[A[ATraining Step: 706  | total loss: [1m[32m0.36055[0m[0m | time: 94.905s
[2K
| Adam | epoch: 011 | loss: 0.36055 - acc: 0.8357 -- iter: 1472/2105
[A[ATraining Step: 707  | total loss: [1m[32m0.35851[0m[0m | time: 95.622s
[2K
| Adam | epoch: 011 | loss: 0.35851 - acc: 0.8365 -- iter: 1504/2105
[A[ATraining Step: 708  | total loss: [1m[32m0.34938[0m[0m | time: 96.352s
[2K
| Adam | epoch: 011 | loss: 0.34938 - acc: 0.8435 -- iter: 1536/2105
[A[ATraining Step: 709  | total loss: [1m[32m0.33687[0m[0m | time: 97.059s
[2K
| Adam | epoch: 011 | loss: 0.33687 - acc: 0.8560 -- iter: 1568/2105
[A[ATraining Step: 710  | total loss: [1m[32m0.32698[0m[0m | time: 97.752s
[2K
| Adam | epoch: 011 | loss: 0.32698 - acc: 0.8579 -- iter: 1600/2105
[A[ATraining Step: 711  | total loss: [1m[32m0.33450[0m[0m | time: 98.422s
[2K
| Adam | epoch: 011 | loss: 0.33450 - acc: 0.8565 -- iter: 1632/2105
[A[ATraining Step: 712  | total loss: [1m[32m0.32007[0m[0m | time: 99.176s
[2K
| Adam | epoch: 011 | loss: 0.32007 - acc: 0.8646 -- iter: 1664/2105
[A[ATraining Step: 713  | total loss: [1m[32m0.32189[0m[0m | time: 99.891s
[2K
| Adam | epoch: 011 | loss: 0.32189 - acc: 0.8594 -- iter: 1696/2105
[A[ATraining Step: 714  | total loss: [1m[32m0.32428[0m[0m | time: 100.600s
[2K
| Adam | epoch: 011 | loss: 0.32428 - acc: 0.8578 -- iter: 1728/2105
[A[ATraining Step: 715  | total loss: [1m[32m0.32251[0m[0m | time: 101.303s
[2K
| Adam | epoch: 011 | loss: 0.32251 - acc: 0.8595 -- iter: 1760/2105
[A[ATraining Step: 716  | total loss: [1m[32m0.31888[0m[0m | time: 102.026s
[2K
| Adam | epoch: 011 | loss: 0.31888 - acc: 0.8642 -- iter: 1792/2105
[A[ATraining Step: 717  | total loss: [1m[32m0.31811[0m[0m | time: 103.204s
[2K
| Adam | epoch: 011 | loss: 0.31811 - acc: 0.8684 -- iter: 1824/2105
[A[ATraining Step: 718  | total loss: [1m[32m0.31320[0m[0m | time: 104.598s
[2K
| Adam | epoch: 011 | loss: 0.31320 - acc: 0.8659 -- iter: 1856/2105
[A[ATraining Step: 719  | total loss: [1m[32m0.32022[0m[0m | time: 106.038s
[2K
| Adam | epoch: 011 | loss: 0.32022 - acc: 0.8606 -- iter: 1888/2105
[A[ATraining Step: 720  | total loss: [1m[32m0.33500[0m[0m | time: 113.766s
[2K
| Adam | epoch: 011 | loss: 0.33500 - acc: 0.8495 -- iter: 1920/2105
[A[ATraining Step: 721  | total loss: [1m[32m0.33262[0m[0m | time: 116.594s
[2K
| Adam | epoch: 011 | loss: 0.33262 - acc: 0.8490 -- iter: 1952/2105
[A[ATraining Step: 722  | total loss: [1m[32m0.32470[0m[0m | time: 117.731s
[2K
| Adam | epoch: 011 | loss: 0.32470 - acc: 0.8547 -- iter: 1984/2105
[A[ATraining Step: 723  | total loss: [1m[32m0.31844[0m[0m | time: 119.038s
[2K
| Adam | epoch: 011 | loss: 0.31844 - acc: 0.8567 -- iter: 2016/2105
[A[ATraining Step: 724  | total loss: [1m[32m0.31347[0m[0m | time: 120.407s
[2K
| Adam | epoch: 011 | loss: 0.31347 - acc: 0.8648 -- iter: 2048/2105
[A[ATraining Step: 725  | total loss: [1m[32m0.29868[0m[0m | time: 121.718s
[2K
| Adam | epoch: 011 | loss: 0.29868 - acc: 0.8721 -- iter: 2080/2105
[A[ATraining Step: 726  | total loss: [1m[32m0.29283[0m[0m | time: 129.330s
[2K
| Adam | epoch: 011 | loss: 0.29283 - acc: 0.8817 | val_loss: 0.45196 - val_acc: 0.7994 -- iter: 2105/2105
--
Training Step: 727  | total loss: [1m[32m0.29269[0m[0m | time: 1.306s
[2K
| Adam | epoch: 012 | loss: 0.29269 - acc: 0.8811 -- iter: 0032/2105
[A[ATraining Step: 728  | total loss: [1m[32m0.30524[0m[0m | time: 2.633s
[2K
| Adam | epoch: 012 | loss: 0.30524 - acc: 0.8711 -- iter: 0064/2105
[A[ATraining Step: 729  | total loss: [1m[32m0.30446[0m[0m | time: 4.027s
[2K
| Adam | epoch: 012 | loss: 0.30446 - acc: 0.8715 -- iter: 0096/2105
[A[ATraining Step: 730  | total loss: [1m[32m0.29986[0m[0m | time: 5.649s
[2K
| Adam | epoch: 012 | loss: 0.29986 - acc: 0.8687 -- iter: 0128/2105
[A[ATraining Step: 731  | total loss: [1m[32m0.29665[0m[0m | time: 7.056s
[2K
| Adam | epoch: 012 | loss: 0.29665 - acc: 0.8693 -- iter: 0160/2105
[A[ATraining Step: 732  | total loss: [1m[32m0.30484[0m[0m | time: 8.336s
[2K
| Adam | epoch: 012 | loss: 0.30484 - acc: 0.8668 -- iter: 0192/2105
[A[ATraining Step: 733  | total loss: [1m[32m0.31225[0m[0m | time: 9.716s
[2K
| Adam | epoch: 012 | loss: 0.31225 - acc: 0.8520 -- iter: 0224/2105
[A[ATraining Step: 734  | total loss: [1m[32m0.31757[0m[0m | time: 11.211s
[2K
| Adam | epoch: 012 | loss: 0.31757 - acc: 0.8480 -- iter: 0256/2105
[A[ATraining Step: 735  | total loss: [1m[32m0.31218[0m[0m | time: 12.738s
[2K
| Adam | epoch: 012 | loss: 0.31218 - acc: 0.8538 -- iter: 0288/2105
[A[ATraining Step: 736  | total loss: [1m[32m0.32303[0m[0m | time: 15.857s
[2K
| Adam | epoch: 012 | loss: 0.32303 - acc: 0.8497 -- iter: 0320/2105
[A[ATraining Step: 737  | total loss: [1m[32m0.30973[0m[0m | time: 21.355s
[2K
| Adam | epoch: 012 | loss: 0.30973 - acc: 0.8607 -- iter: 0352/2105
[A[ATraining Step: 738  | total loss: [1m[32m0.29641[0m[0m | time: 27.230s
[2K
| Adam | epoch: 012 | loss: 0.29641 - acc: 0.8707 -- iter: 0384/2105
[A[ATraining Step: 739  | total loss: [1m[32m0.30770[0m[0m | time: 28.420s
[2K
| Adam | epoch: 012 | loss: 0.30770 - acc: 0.8648 -- iter: 0416/2105
[A[ATraining Step: 740  | total loss: [1m[32m0.32489[0m[0m | time: 29.812s
[2K
| Adam | epoch: 012 | loss: 0.32489 - acc: 0.8502 -- iter: 0448/2105
[A[ATraining Step: 741  | total loss: [1m[32m0.32747[0m[0m | time: 30.981s
[2K
| Adam | epoch: 012 | loss: 0.32747 - acc: 0.8558 -- iter: 0480/2105
[A[ATraining Step: 742  | total loss: [1m[32m0.32577[0m[0m | time: 32.181s
[2K
| Adam | epoch: 012 | loss: 0.32577 - acc: 0.8578 -- iter: 0512/2105
[A[ATraining Step: 743  | total loss: [1m[32m0.32050[0m[0m | time: 33.607s
[2K
| Adam | epoch: 012 | loss: 0.32050 - acc: 0.8595 -- iter: 0544/2105
[A[ATraining Step: 744  | total loss: [1m[32m0.32559[0m[0m | time: 35.120s
[2K
| Adam | epoch: 012 | loss: 0.32559 - acc: 0.8579 -- iter: 0576/2105
[A[ATraining Step: 745  | total loss: [1m[32m0.31700[0m[0m | time: 36.730s
[2K
| Adam | epoch: 012 | loss: 0.31700 - acc: 0.8627 -- iter: 0608/2105
[A[ATraining Step: 746  | total loss: [1m[32m0.31059[0m[0m | time: 38.057s
[2K
| Adam | epoch: 012 | loss: 0.31059 - acc: 0.8671 -- iter: 0640/2105
[A[ATraining Step: 747  | total loss: [1m[32m0.30465[0m[0m | time: 39.586s
[2K
| Adam | epoch: 012 | loss: 0.30465 - acc: 0.8679 -- iter: 0672/2105
[A[ATraining Step: 748  | total loss: [1m[32m0.30529[0m[0m | time: 41.041s
[2K
| Adam | epoch: 012 | loss: 0.30529 - acc: 0.8717 -- iter: 0704/2105
[A[ATraining Step: 749  | total loss: [1m[32m0.31770[0m[0m | time: 42.096s
[2K
| Adam | epoch: 012 | loss: 0.31770 - acc: 0.8595 -- iter: 0736/2105
[A[ATraining Step: 750  | total loss: [1m[32m0.32756[0m[0m | time: 45.394s
[2K
| Adam | epoch: 012 | loss: 0.32756 - acc: 0.8486 -- iter: 0768/2105
[A[ATraining Step: 751  | total loss: [1m[32m0.32203[0m[0m | time: 56.239s
[2K
| Adam | epoch: 012 | loss: 0.32203 - acc: 0.8481 -- iter: 0800/2105
[A[ATraining Step: 752  | total loss: [1m[32m0.32429[0m[0m | time: 60.034s
[2K
| Adam | epoch: 012 | loss: 0.32429 - acc: 0.8477 -- iter: 0832/2105
[A[ATraining Step: 753  | total loss: [1m[32m0.31575[0m[0m | time: 65.173s
[2K
| Adam | epoch: 012 | loss: 0.31575 - acc: 0.8567 -- iter: 0864/2105
[A[ATraining Step: 754  | total loss: [1m[32m0.31241[0m[0m | time: 66.522s
[2K
| Adam | epoch: 012 | loss: 0.31241 - acc: 0.8554 -- iter: 0896/2105
[A[ATraining Step: 755  | total loss: [1m[32m0.29613[0m[0m | time: 67.635s
[2K
| Adam | epoch: 012 | loss: 0.29613 - acc: 0.8667 -- iter: 0928/2105
[A[ATraining Step: 756  | total loss: [1m[32m0.29272[0m[0m | time: 68.855s
[2K
| Adam | epoch: 012 | loss: 0.29272 - acc: 0.8707 -- iter: 0960/2105
[A[ATraining Step: 757  | total loss: [1m[32m0.28612[0m[0m | time: 70.177s
[2K
| Adam | epoch: 012 | loss: 0.28612 - acc: 0.8711 -- iter: 0992/2105
[A[ATraining Step: 758  | total loss: [1m[32m0.28555[0m[0m | time: 71.701s
[2K
| Adam | epoch: 012 | loss: 0.28555 - acc: 0.8715 -- iter: 1024/2105
[A[ATraining Step: 759  | total loss: [1m[32m0.28036[0m[0m | time: 73.248s
[2K
| Adam | epoch: 012 | loss: 0.28036 - acc: 0.8718 -- iter: 1056/2105
[A[ATraining Step: 760  | total loss: [1m[32m0.27666[0m[0m | time: 74.592s
[2K
| Adam | epoch: 012 | loss: 0.27666 - acc: 0.8753 -- iter: 1088/2105
[A[ATraining Step: 761  | total loss: [1m[32m0.26370[0m[0m | time: 76.047s
[2K
| Adam | epoch: 012 | loss: 0.26370 - acc: 0.8815 -- iter: 1120/2105
[A[ATraining Step: 762  | total loss: [1m[32m0.25819[0m[0m | time: 77.454s
[2K
| Adam | epoch: 012 | loss: 0.25819 - acc: 0.8871 -- iter: 1152/2105
[A[ATraining Step: 763  | total loss: [1m[32m0.27409[0m[0m | time: 78.588s
[2K
| Adam | epoch: 012 | loss: 0.27409 - acc: 0.8828 -- iter: 1184/2105
[A[ATraining Step: 764  | total loss: [1m[32m0.27983[0m[0m | time: 79.762s
[2K
| Adam | epoch: 012 | loss: 0.27983 - acc: 0.8851 -- iter: 1216/2105
[A[ATraining Step: 765  | total loss: [1m[32m0.27474[0m[0m | time: 81.065s
[2K
| Adam | epoch: 012 | loss: 0.27474 - acc: 0.8935 -- iter: 1248/2105
[A[ATraining Step: 766  | total loss: [1m[32m0.26644[0m[0m | time: 82.594s
[2K
| Adam | epoch: 012 | loss: 0.26644 - acc: 0.8979 -- iter: 1280/2105
[A[ATraining Step: 767  | total loss: [1m[32m0.25416[0m[0m | time: 84.061s
[2K
| Adam | epoch: 012 | loss: 0.25416 - acc: 0.9050 -- iter: 1312/2105
[A[ATraining Step: 768  | total loss: [1m[32m0.25445[0m[0m | time: 85.480s
[2K
| Adam | epoch: 012 | loss: 0.25445 - acc: 0.9051 -- iter: 1344/2105
[A[ATraining Step: 769  | total loss: [1m[32m0.25858[0m[0m | time: 86.785s
[2K
| Adam | epoch: 012 | loss: 0.25858 - acc: 0.9052 -- iter: 1376/2105
[A[ATraining Step: 770  | total loss: [1m[32m0.26707[0m[0m | time: 87.908s
[2K
| Adam | epoch: 012 | loss: 0.26707 - acc: 0.8959 -- iter: 1408/2105
[A[ATraining Step: 771  | total loss: [1m[32m0.27484[0m[0m | time: 89.098s
[2K
| Adam | epoch: 012 | loss: 0.27484 - acc: 0.8876 -- iter: 1440/2105
[A[ATraining Step: 772  | total loss: [1m[32m0.29711[0m[0m | time: 90.281s
[2K
| Adam | epoch: 012 | loss: 0.29711 - acc: 0.8801 -- iter: 1472/2105
[A[ATraining Step: 773  | total loss: [1m[32m0.30715[0m[0m | time: 91.670s
[2K
| Adam | epoch: 012 | loss: 0.30715 - acc: 0.8733 -- iter: 1504/2105
[A[ATraining Step: 774  | total loss: [1m[32m0.28938[0m[0m | time: 92.979s
[2K
| Adam | epoch: 012 | loss: 0.28938 - acc: 0.8829 -- iter: 1536/2105
[A[ATraining Step: 775  | total loss: [1m[32m0.27953[0m[0m | time: 94.411s
[2K
| Adam | epoch: 012 | loss: 0.27953 - acc: 0.8852 -- iter: 1568/2105
[A[ATraining Step: 776  | total loss: [1m[32m0.28559[0m[0m | time: 95.849s
[2K
| Adam | epoch: 012 | loss: 0.28559 - acc: 0.8842 -- iter: 1600/2105
[A[ATraining Step: 777  | total loss: [1m[32m0.27637[0m[0m | time: 97.188s
[2K
| Adam | epoch: 012 | loss: 0.27637 - acc: 0.8926 -- iter: 1632/2105
[A[ATraining Step: 778  | total loss: [1m[32m0.26817[0m[0m | time: 98.504s
[2K
| Adam | epoch: 012 | loss: 0.26817 - acc: 0.9003 -- iter: 1664/2105
[A[ATraining Step: 779  | total loss: [1m[32m0.26950[0m[0m | time: 99.858s
[2K
| Adam | epoch: 012 | loss: 0.26950 - acc: 0.8977 -- iter: 1696/2105
[A[ATraining Step: 780  | total loss: [1m[32m0.26200[0m[0m | time: 101.179s
[2K
| Adam | epoch: 012 | loss: 0.26200 - acc: 0.8986 -- iter: 1728/2105
[A[ATraining Step: 781  | total loss: [1m[32m0.27257[0m[0m | time: 102.417s
[2K
| Adam | epoch: 012 | loss: 0.27257 - acc: 0.8931 -- iter: 1760/2105
[A[ATraining Step: 782  | total loss: [1m[32m0.26907[0m[0m | time: 103.782s
[2K
| Adam | epoch: 012 | loss: 0.26907 - acc: 0.8975 -- iter: 1792/2105
[A[ATraining Step: 783  | total loss: [1m[32m0.27047[0m[0m | time: 105.166s
[2K
| Adam | epoch: 012 | loss: 0.27047 - acc: 0.8984 -- iter: 1824/2105
[A[ATraining Step: 784  | total loss: [1m[32m0.25948[0m[0m | time: 106.621s
[2K
| Adam | epoch: 012 | loss: 0.25948 - acc: 0.9054 -- iter: 1856/2105
[A[ATraining Step: 785  | total loss: [1m[32m0.24860[0m[0m | time: 108.069s
[2K
| Adam | epoch: 012 | loss: 0.24860 - acc: 0.9149 -- iter: 1888/2105
[A[ATraining Step: 786  | total loss: [1m[32m0.25164[0m[0m | time: 109.314s
[2K
| Adam | epoch: 012 | loss: 0.25164 - acc: 0.9047 -- iter: 1920/2105
[A[ATraining Step: 787  | total loss: [1m[32m0.26331[0m[0m | time: 110.784s
[2K
| Adam | epoch: 012 | loss: 0.26331 - acc: 0.9017 -- iter: 1952/2105
[A[ATraining Step: 788  | total loss: [1m[32m0.26892[0m[0m | time: 112.132s
[2K
| Adam | epoch: 012 | loss: 0.26892 - acc: 0.8990 -- iter: 1984/2105
[A[ATraining Step: 789  | total loss: [1m[32m0.27182[0m[0m | time: 113.630s
[2K
| Adam | epoch: 012 | loss: 0.27182 - acc: 0.8935 -- iter: 2016/2105
[A[ATraining Step: 790  | total loss: [1m[32m0.26043[0m[0m | time: 115.037s
[2K
| Adam | epoch: 012 | loss: 0.26043 - acc: 0.8979 -- iter: 2048/2105
[A[ATraining Step: 791  | total loss: [1m[32m0.24605[0m[0m | time: 116.329s
[2K
| Adam | epoch: 012 | loss: 0.24605 - acc: 0.9050 -- iter: 2080/2105
[A[ATraining Step: 792  | total loss: [1m[32m0.23774[0m[0m | time: 121.055s
[2K
| Adam | epoch: 012 | loss: 0.23774 - acc: 0.9082 | val_loss: 0.41783 - val_acc: 0.8055 -- iter: 2105/2105
--
Training Step: 793  | total loss: [1m[32m0.24727[0m[0m | time: 1.040s
[2K
| Adam | epoch: 013 | loss: 0.24727 - acc: 0.9080 -- iter: 0032/2105
[A[ATraining Step: 794  | total loss: [1m[32m0.24711[0m[0m | time: 2.029s
[2K
| Adam | epoch: 013 | loss: 0.24711 - acc: 0.9110 -- iter: 0064/2105
[A[ATraining Step: 795  | total loss: [1m[32m0.25266[0m[0m | time: 3.078s
[2K
| Adam | epoch: 013 | loss: 0.25266 - acc: 0.9074 -- iter: 0096/2105
[A[ATraining Step: 796  | total loss: [1m[32m0.24159[0m[0m | time: 4.258s
[2K
| Adam | epoch: 013 | loss: 0.24159 - acc: 0.9166 -- iter: 0128/2105
[A[ATraining Step: 797  | total loss: [1m[32m0.23111[0m[0m | time: 5.390s
[2K
| Adam | epoch: 013 | loss: 0.23111 - acc: 0.9219 -- iter: 0160/2105
[A[ATraining Step: 798  | total loss: [1m[32m0.22710[0m[0m | time: 6.201s
[2K
| Adam | epoch: 013 | loss: 0.22710 - acc: 0.9234 -- iter: 0192/2105
[A[ATraining Step: 799  | total loss: [1m[32m0.21748[0m[0m | time: 7.190s
[2K
| Adam | epoch: 013 | loss: 0.21748 - acc: 0.9280 -- iter: 0224/2105
[A[ATraining Step: 800  | total loss: [1m[32m0.22467[0m[0m | time: 12.254s
[2K
| Adam | epoch: 013 | loss: 0.22467 - acc: 0.9195 | val_loss: 0.45019 - val_acc: 0.8070 -- iter: 0256/2105
--
Training Step: 801  | total loss: [1m[32m0.22274[0m[0m | time: 13.434s
[2K
| Adam | epoch: 013 | loss: 0.22274 - acc: 0.9182 -- iter: 0288/2105
[A[ATraining Step: 802  | total loss: [1m[32m0.21773[0m[0m | time: 14.607s
[2K
| Adam | epoch: 013 | loss: 0.21773 - acc: 0.9170 -- iter: 0320/2105
[A[ATraining Step: 803  | total loss: [1m[32m0.21812[0m[0m | time: 15.395s
[2K
| Adam | epoch: 013 | loss: 0.21812 - acc: 0.9191 -- iter: 0352/2105
[A[ATraining Step: 804  | total loss: [1m[32m0.21317[0m[0m | time: 16.051s
[2K
| Adam | epoch: 013 | loss: 0.21317 - acc: 0.9232 -- iter: 0384/2105
[A[ATraining Step: 805  | total loss: [1m[32m0.20644[0m[0m | time: 17.041s
[2K
| Adam | epoch: 013 | loss: 0.20644 - acc: 0.9268 -- iter: 0416/2105
[A[ATraining Step: 806  | total loss: [1m[32m0.21540[0m[0m | time: 18.060s
[2K
| Adam | epoch: 013 | loss: 0.21540 - acc: 0.9248 -- iter: 0448/2105
[A[ATraining Step: 807  | total loss: [1m[32m0.21351[0m[0m | time: 19.059s
[2K
| Adam | epoch: 013 | loss: 0.21351 - acc: 0.9261 -- iter: 0480/2105
[A[ATraining Step: 808  | total loss: [1m[32m0.24620[0m[0m | time: 20.046s
[2K
| Adam | epoch: 013 | loss: 0.24620 - acc: 0.9053 -- iter: 0512/2105
[A[ATraining Step: 809  | total loss: [1m[32m0.26288[0m[0m | time: 21.030s
[2K
| Adam | epoch: 013 | loss: 0.26288 - acc: 0.8960 -- iter: 0544/2105
[A[ATraining Step: 810  | total loss: [1m[32m0.25832[0m[0m | time: 22.007s
[2K
| Adam | epoch: 013 | loss: 0.25832 - acc: 0.8971 -- iter: 0576/2105
[A[ATraining Step: 811  | total loss: [1m[32m0.26483[0m[0m | time: 22.969s
[2K
| Adam | epoch: 013 | loss: 0.26483 - acc: 0.8855 -- iter: 0608/2105
[A[ATraining Step: 812  | total loss: [1m[32m0.29502[0m[0m | time: 23.999s
[2K
| Adam | epoch: 013 | loss: 0.29502 - acc: 0.8751 -- iter: 0640/2105
[A[ATraining Step: 813  | total loss: [1m[32m0.30793[0m[0m | time: 25.211s
[2K
| Adam | epoch: 013 | loss: 0.30793 - acc: 0.8719 -- iter: 0672/2105
[A[ATraining Step: 814  | total loss: [1m[32m0.32427[0m[0m | time: 26.348s
[2K
| Adam | epoch: 013 | loss: 0.32427 - acc: 0.8629 -- iter: 0704/2105
[A[ATraining Step: 815  | total loss: [1m[32m0.31296[0m[0m | time: 27.637s
[2K
| Adam | epoch: 013 | loss: 0.31296 - acc: 0.8672 -- iter: 0736/2105
[A[ATraining Step: 816  | total loss: [1m[32m0.29386[0m[0m | time: 29.157s
[2K
| Adam | epoch: 013 | loss: 0.29386 - acc: 0.8774 -- iter: 0768/2105
[A[ATraining Step: 817  | total loss: [1m[32m0.31314[0m[0m | time: 30.645s
[2K
| Adam | epoch: 013 | loss: 0.31314 - acc: 0.8615 -- iter: 0800/2105
[A[ATraining Step: 818  | total loss: [1m[32m0.31211[0m[0m | time: 32.071s
[2K
| Adam | epoch: 013 | loss: 0.31211 - acc: 0.8628 -- iter: 0832/2105
[A[ATraining Step: 819  | total loss: [1m[32m0.30365[0m[0m | time: 33.855s
[2K
| Adam | epoch: 013 | loss: 0.30365 - acc: 0.8609 -- iter: 0864/2105
[A[ATraining Step: 820  | total loss: [1m[32m0.30025[0m[0m | time: 35.327s
[2K
| Adam | epoch: 013 | loss: 0.30025 - acc: 0.8623 -- iter: 0896/2105
[A[ATraining Step: 821  | total loss: [1m[32m0.28303[0m[0m | time: 36.801s
[2K
| Adam | epoch: 013 | loss: 0.28303 - acc: 0.8699 -- iter: 0928/2105
[A[ATraining Step: 822  | total loss: [1m[32m0.27521[0m[0m | time: 38.179s
[2K
| Adam | epoch: 013 | loss: 0.27521 - acc: 0.8766 -- iter: 0960/2105
[A[ATraining Step: 823  | total loss: [1m[32m0.27472[0m[0m | time: 39.149s
[2K
| Adam | epoch: 013 | loss: 0.27472 - acc: 0.8796 -- iter: 0992/2105
[A[ATraining Step: 824  | total loss: [1m[32m0.26132[0m[0m | time: 40.217s
[2K
| Adam | epoch: 013 | loss: 0.26132 - acc: 0.8885 -- iter: 1024/2105
[A[ATraining Step: 825  | total loss: [1m[32m0.25129[0m[0m | time: 41.428s
[2K
| Adam | epoch: 013 | loss: 0.25129 - acc: 0.8965 -- iter: 1056/2105
[A[ATraining Step: 826  | total loss: [1m[32m0.24591[0m[0m | time: 42.552s
[2K
| Adam | epoch: 013 | loss: 0.24591 - acc: 0.8944 -- iter: 1088/2105
[A[ATraining Step: 827  | total loss: [1m[32m0.24988[0m[0m | time: 43.486s
[2K
| Adam | epoch: 013 | loss: 0.24988 - acc: 0.8893 -- iter: 1120/2105
[A[ATraining Step: 828  | total loss: [1m[32m0.24073[0m[0m | time: 44.465s
[2K
| Adam | epoch: 013 | loss: 0.24073 - acc: 0.8973 -- iter: 1152/2105
[A[ATraining Step: 829  | total loss: [1m[32m0.23518[0m[0m | time: 45.502s
[2K
| Adam | epoch: 013 | loss: 0.23518 - acc: 0.8950 -- iter: 1184/2105
[A[ATraining Step: 830  | total loss: [1m[32m0.23536[0m[0m | time: 46.496s
[2K
| Adam | epoch: 013 | loss: 0.23536 - acc: 0.8993 -- iter: 1216/2105
[A[ATraining Step: 831  | total loss: [1m[32m0.22620[0m[0m | time: 47.508s
[2K
| Adam | epoch: 013 | loss: 0.22620 - acc: 0.9062 -- iter: 1248/2105
[A[ATraining Step: 832  | total loss: [1m[32m0.22650[0m[0m | time: 48.544s
[2K
| Adam | epoch: 013 | loss: 0.22650 - acc: 0.9031 -- iter: 1280/2105
[A[ATraining Step: 833  | total loss: [1m[32m0.21913[0m[0m | time: 49.558s
[2K
| Adam | epoch: 013 | loss: 0.21913 - acc: 0.9097 -- iter: 1312/2105
[A[ATraining Step: 834  | total loss: [1m[32m0.23257[0m[0m | time: 50.561s
[2K
| Adam | epoch: 013 | loss: 0.23257 - acc: 0.8999 -- iter: 1344/2105
[A[ATraining Step: 835  | total loss: [1m[32m0.24208[0m[0m | time: 51.757s
[2K
| Adam | epoch: 013 | loss: 0.24208 - acc: 0.8881 -- iter: 1376/2105
[A[ATraining Step: 836  | total loss: [1m[32m0.24198[0m[0m | time: 52.952s
[2K
| Adam | epoch: 013 | loss: 0.24198 - acc: 0.8868 -- iter: 1408/2105
[A[ATraining Step: 837  | total loss: [1m[32m0.24573[0m[0m | time: 53.788s
[2K
| Adam | epoch: 013 | loss: 0.24573 - acc: 0.8856 -- iter: 1440/2105
[A[ATraining Step: 838  | total loss: [1m[32m0.24344[0m[0m | time: 54.702s
[2K
| Adam | epoch: 013 | loss: 0.24344 - acc: 0.8877 -- iter: 1472/2105
[A[ATraining Step: 839  | total loss: [1m[32m0.26015[0m[0m | time: 55.630s
[2K
| Adam | epoch: 013 | loss: 0.26015 - acc: 0.8833 -- iter: 1504/2105
[A[ATraining Step: 840  | total loss: [1m[32m0.26162[0m[0m | time: 56.619s
[2K
| Adam | epoch: 013 | loss: 0.26162 - acc: 0.8856 -- iter: 1536/2105
[A[ATraining Step: 841  | total loss: [1m[32m0.25006[0m[0m | time: 57.585s
[2K
| Adam | epoch: 013 | loss: 0.25006 - acc: 0.8908 -- iter: 1568/2105
[A[ATraining Step: 842  | total loss: [1m[32m0.23807[0m[0m | time: 58.535s
[2K
| Adam | epoch: 013 | loss: 0.23807 - acc: 0.8986 -- iter: 1600/2105
[A[ATraining Step: 843  | total loss: [1m[32m0.22902[0m[0m | time: 59.540s
[2K
| Adam | epoch: 013 | loss: 0.22902 - acc: 0.9025 -- iter: 1632/2105
[A[ATraining Step: 844  | total loss: [1m[32m0.22977[0m[0m | time: 60.485s
[2K
| Adam | epoch: 013 | loss: 0.22977 - acc: 0.9028 -- iter: 1664/2105
[A[ATraining Step: 845  | total loss: [1m[32m0.22870[0m[0m | time: 61.431s
[2K
| Adam | epoch: 013 | loss: 0.22870 - acc: 0.9000 -- iter: 1696/2105
[A[ATraining Step: 846  | total loss: [1m[32m0.24335[0m[0m | time: 62.519s
[2K
| Adam | epoch: 013 | loss: 0.24335 - acc: 0.8913 -- iter: 1728/2105
[A[ATraining Step: 847  | total loss: [1m[32m0.23147[0m[0m | time: 63.728s
[2K
| Adam | epoch: 013 | loss: 0.23147 - acc: 0.9022 -- iter: 1760/2105
[A[ATraining Step: 848  | total loss: [1m[32m0.23420[0m[0m | time: 64.878s
[2K
| Adam | epoch: 013 | loss: 0.23420 - acc: 0.9026 -- iter: 1792/2105
[A[ATraining Step: 849  | total loss: [1m[32m0.22955[0m[0m | time: 65.705s
[2K
| Adam | epoch: 013 | loss: 0.22955 - acc: 0.9092 -- iter: 1824/2105
[A[ATraining Step: 850  | total loss: [1m[32m0.22659[0m[0m | time: 66.751s
[2K
| Adam | epoch: 013 | loss: 0.22659 - acc: 0.9151 -- iter: 1856/2105
[A[ATraining Step: 851  | total loss: [1m[32m0.24650[0m[0m | time: 67.757s
[2K
| Adam | epoch: 013 | loss: 0.24650 - acc: 0.9049 -- iter: 1888/2105
[A[ATraining Step: 852  | total loss: [1m[32m0.24531[0m[0m | time: 68.757s
[2K
| Adam | epoch: 013 | loss: 0.24531 - acc: 0.9050 -- iter: 1920/2105
[A[ATraining Step: 853  | total loss: [1m[32m0.25317[0m[0m | time: 69.749s
[2K
| Adam | epoch: 013 | loss: 0.25317 - acc: 0.8958 -- iter: 1952/2105
[A[ATraining Step: 854  | total loss: [1m[32m0.24130[0m[0m | time: 70.785s
[2K
| Adam | epoch: 013 | loss: 0.24130 - acc: 0.9031 -- iter: 1984/2105
[A[ATraining Step: 855  | total loss: [1m[32m0.24044[0m[0m | time: 71.731s
[2K
| Adam | epoch: 013 | loss: 0.24044 - acc: 0.9003 -- iter: 2016/2105
[A[ATraining Step: 856  | total loss: [1m[32m0.26187[0m[0m | time: 72.652s
[2K
| Adam | epoch: 013 | loss: 0.26187 - acc: 0.8852 -- iter: 2048/2105
[A[ATraining Step: 857  | total loss: [1m[32m0.27805[0m[0m | time: 73.906s
[2K
| Adam | epoch: 013 | loss: 0.27805 - acc: 0.8717 -- iter: 2080/2105
[A[ATraining Step: 858  | total loss: [1m[32m0.27872[0m[0m | time: 78.671s
[2K
| Adam | epoch: 013 | loss: 0.27872 - acc: 0.8752 | val_loss: 0.41089 - val_acc: 0.8283 -- iter: 2105/2105
--
Training Step: 859  | total loss: [1m[32m0.27659[0m[0m | time: 1.001s
[2K
| Adam | epoch: 014 | loss: 0.27659 - acc: 0.8751 -- iter: 0032/2105
[A[ATraining Step: 860  | total loss: [1m[32m0.27103[0m[0m | time: 1.990s
[2K
| Adam | epoch: 014 | loss: 0.27103 - acc: 0.8783 -- iter: 0064/2105
[A[ATraining Step: 861  | total loss: [1m[32m0.25893[0m[0m | time: 2.931s
[2K
| Adam | epoch: 014 | loss: 0.25893 - acc: 0.8842 -- iter: 0096/2105
[A[ATraining Step: 862  | total loss: [1m[32m0.25527[0m[0m | time: 4.085s
[2K
| Adam | epoch: 014 | loss: 0.25527 - acc: 0.8864 -- iter: 0128/2105
[A[ATraining Step: 863  | total loss: [1m[32m0.28327[0m[0m | time: 5.269s
[2K
| Adam | epoch: 014 | loss: 0.28327 - acc: 0.8727 -- iter: 0160/2105
[A[ATraining Step: 864  | total loss: [1m[32m0.28768[0m[0m | time: 6.147s
[2K
| Adam | epoch: 014 | loss: 0.28768 - acc: 0.8698 -- iter: 0192/2105
[A[ATraining Step: 865  | total loss: [1m[32m0.29259[0m[0m | time: 7.038s
[2K
| Adam | epoch: 014 | loss: 0.29259 - acc: 0.8672 -- iter: 0224/2105
[A[ATraining Step: 866  | total loss: [1m[32m0.28355[0m[0m | time: 8.006s
[2K
| Adam | epoch: 014 | loss: 0.28355 - acc: 0.8743 -- iter: 0256/2105
[A[ATraining Step: 867  | total loss: [1m[32m0.27810[0m[0m | time: 8.973s
[2K
| Adam | epoch: 014 | loss: 0.27810 - acc: 0.8837 -- iter: 0288/2105
[A[ATraining Step: 868  | total loss: [1m[32m0.27152[0m[0m | time: 9.947s
[2K
| Adam | epoch: 014 | loss: 0.27152 - acc: 0.8860 -- iter: 0320/2105
[A[ATraining Step: 869  | total loss: [1m[32m0.27558[0m[0m | time: 10.973s
[2K
| Adam | epoch: 014 | loss: 0.27558 - acc: 0.8817 -- iter: 0352/2105
[A[ATraining Step: 870  | total loss: [1m[32m0.26160[0m[0m | time: 11.740s
[2K
| Adam | epoch: 014 | loss: 0.26160 - acc: 0.8873 -- iter: 0384/2105
[A[ATraining Step: 871  | total loss: [1m[32m0.27420[0m[0m | time: 12.552s
[2K
| Adam | epoch: 014 | loss: 0.27420 - acc: 0.8866 -- iter: 0416/2105
[A[ATraining Step: 872  | total loss: [1m[32m0.28180[0m[0m | time: 13.526s
[2K
| Adam | epoch: 014 | loss: 0.28180 - acc: 0.8899 -- iter: 0448/2105
[A[ATraining Step: 873  | total loss: [1m[32m0.28225[0m[0m | time: 14.568s
[2K
| Adam | epoch: 014 | loss: 0.28225 - acc: 0.8853 -- iter: 0480/2105
[A[ATraining Step: 874  | total loss: [1m[32m0.28803[0m[0m | time: 15.841s
[2K
| Adam | epoch: 014 | loss: 0.28803 - acc: 0.8874 -- iter: 0512/2105
[A[ATraining Step: 875  | total loss: [1m[32m0.27243[0m[0m | time: 16.950s
[2K
| Adam | epoch: 014 | loss: 0.27243 - acc: 0.8924 -- iter: 0544/2105
[A[ATraining Step: 876  | total loss: [1m[32m0.26813[0m[0m | time: 17.799s
[2K
| Adam | epoch: 014 | loss: 0.26813 - acc: 0.8938 -- iter: 0576/2105
[A[ATraining Step: 877  | total loss: [1m[32m0.26392[0m[0m | time: 18.778s
[2K
| Adam | epoch: 014 | loss: 0.26392 - acc: 0.8919 -- iter: 0608/2105
[A[ATraining Step: 878  | total loss: [1m[32m0.26131[0m[0m | time: 19.774s
[2K
| Adam | epoch: 014 | loss: 0.26131 - acc: 0.8965 -- iter: 0640/2105
[A[ATraining Step: 879  | total loss: [1m[32m0.25471[0m[0m | time: 20.792s
[2K
| Adam | epoch: 014 | loss: 0.25471 - acc: 0.9006 -- iter: 0672/2105
[A[ATraining Step: 880  | total loss: [1m[32m0.24973[0m[0m | time: 21.817s
[2K
| Adam | epoch: 014 | loss: 0.24973 - acc: 0.9011 -- iter: 0704/2105
[A[ATraining Step: 881  | total loss: [1m[32m0.24640[0m[0m | time: 22.816s
[2K
| Adam | epoch: 014 | loss: 0.24640 - acc: 0.9017 -- iter: 0736/2105
[A[ATraining Step: 882  | total loss: [1m[32m0.25139[0m[0m | time: 23.818s
[2K
| Adam | epoch: 014 | loss: 0.25139 - acc: 0.8990 -- iter: 0768/2105
[A[ATraining Step: 883  | total loss: [1m[32m0.24258[0m[0m | time: 24.822s
[2K
| Adam | epoch: 014 | loss: 0.24258 - acc: 0.9060 -- iter: 0800/2105
[A[ATraining Step: 884  | total loss: [1m[32m0.23677[0m[0m | time: 26.023s
[2K
| Adam | epoch: 014 | loss: 0.23677 - acc: 0.9091 -- iter: 0832/2105
[A[ATraining Step: 885  | total loss: [1m[32m0.22858[0m[0m | time: 27.234s
[2K
| Adam | epoch: 014 | loss: 0.22858 - acc: 0.9088 -- iter: 0864/2105
[A[ATraining Step: 886  | total loss: [1m[32m0.22504[0m[0m | time: 28.010s
[2K
| Adam | epoch: 014 | loss: 0.22504 - acc: 0.9086 -- iter: 0896/2105
[A[ATraining Step: 887  | total loss: [1m[32m0.22892[0m[0m | time: 28.975s
[2K
| Adam | epoch: 014 | loss: 0.22892 - acc: 0.9083 -- iter: 0928/2105
[A[ATraining Step: 888  | total loss: [1m[32m0.23573[0m[0m | time: 30.007s
[2K
| Adam | epoch: 014 | loss: 0.23573 - acc: 0.9050 -- iter: 0960/2105
[A[ATraining Step: 889  | total loss: [1m[32m0.23218[0m[0m | time: 31.052s
[2K
| Adam | epoch: 014 | loss: 0.23218 - acc: 0.9114 -- iter: 0992/2105
[A[ATraining Step: 890  | total loss: [1m[32m0.22943[0m[0m | time: 32.052s
[2K
| Adam | epoch: 014 | loss: 0.22943 - acc: 0.9140 -- iter: 1024/2105
[A[ATraining Step: 891  | total loss: [1m[32m0.21872[0m[0m | time: 33.073s
[2K
| Adam | epoch: 014 | loss: 0.21872 - acc: 0.9226 -- iter: 1056/2105
[A[ATraining Step: 892  | total loss: [1m[32m0.21332[0m[0m | time: 34.085s
[2K
| Adam | epoch: 014 | loss: 0.21332 - acc: 0.9241 -- iter: 1088/2105
[A[ATraining Step: 893  | total loss: [1m[32m0.22098[0m[0m | time: 35.151s
[2K
| Adam | epoch: 014 | loss: 0.22098 - acc: 0.9192 -- iter: 1120/2105
[A[ATraining Step: 894  | total loss: [1m[32m0.21980[0m[0m | time: 36.223s
[2K
| Adam | epoch: 014 | loss: 0.21980 - acc: 0.9179 -- iter: 1152/2105
[A[ATraining Step: 895  | total loss: [1m[32m0.21009[0m[0m | time: 37.380s
[2K
| Adam | epoch: 014 | loss: 0.21009 - acc: 0.9230 -- iter: 1184/2105
[A[ATraining Step: 896  | total loss: [1m[32m0.21105[0m[0m | time: 38.476s
[2K
| Adam | epoch: 014 | loss: 0.21105 - acc: 0.9275 -- iter: 1216/2105
[A[ATraining Step: 897  | total loss: [1m[32m0.22615[0m[0m | time: 39.255s
[2K
| Adam | epoch: 014 | loss: 0.22615 - acc: 0.9192 -- iter: 1248/2105
[A[ATraining Step: 898  | total loss: [1m[32m0.22394[0m[0m | time: 40.189s
[2K
| Adam | epoch: 014 | loss: 0.22394 - acc: 0.9210 -- iter: 1280/2105
[A[ATraining Step: 899  | total loss: [1m[32m0.21713[0m[0m | time: 41.235s
[2K
| Adam | epoch: 014 | loss: 0.21713 - acc: 0.9227 -- iter: 1312/2105
[A[ATraining Step: 900  | total loss: [1m[32m0.20476[0m[0m | time: 42.266s
[2K
| Adam | epoch: 014 | loss: 0.20476 - acc: 0.9304 -- iter: 1344/2105
[A[ATraining Step: 901  | total loss: [1m[32m0.20598[0m[0m | time: 43.307s
[2K
| Adam | epoch: 014 | loss: 0.20598 - acc: 0.9311 -- iter: 1376/2105
[A[ATraining Step: 902  | total loss: [1m[32m0.21667[0m[0m | time: 44.340s
[2K
| Adam | epoch: 014 | loss: 0.21667 - acc: 0.9224 -- iter: 1408/2105
[A[ATraining Step: 903  | total loss: [1m[32m0.23495[0m[0m | time: 45.353s
[2K
| Adam | epoch: 014 | loss: 0.23495 - acc: 0.9145 -- iter: 1440/2105
[A[ATraining Step: 904  | total loss: [1m[32m0.23419[0m[0m | time: 46.257s
[2K
| Adam | epoch: 014 | loss: 0.23419 - acc: 0.9137 -- iter: 1472/2105
[A[ATraining Step: 905  | total loss: [1m[32m0.22443[0m[0m | time: 47.486s
[2K
| Adam | epoch: 014 | loss: 0.22443 - acc: 0.9192 -- iter: 1504/2105
[A[ATraining Step: 906  | total loss: [1m[32m0.21417[0m[0m | time: 48.753s
[2K
| Adam | epoch: 014 | loss: 0.21417 - acc: 0.9241 -- iter: 1536/2105
[A[ATraining Step: 907  | total loss: [1m[32m0.21452[0m[0m | time: 49.676s
[2K
| Adam | epoch: 014 | loss: 0.21452 - acc: 0.9224 -- iter: 1568/2105
[A[ATraining Step: 908  | total loss: [1m[32m0.20683[0m[0m | time: 50.559s
[2K
| Adam | epoch: 014 | loss: 0.20683 - acc: 0.9270 -- iter: 1600/2105
[A[ATraining Step: 909  | total loss: [1m[32m0.23075[0m[0m | time: 51.639s
[2K
| Adam | epoch: 014 | loss: 0.23075 - acc: 0.9155 -- iter: 1632/2105
[A[ATraining Step: 910  | total loss: [1m[32m0.23590[0m[0m | time: 52.672s
[2K
| Adam | epoch: 014 | loss: 0.23590 - acc: 0.9146 -- iter: 1664/2105
[A[ATraining Step: 911  | total loss: [1m[32m0.22234[0m[0m | time: 53.678s
[2K
| Adam | epoch: 014 | loss: 0.22234 - acc: 0.9232 -- iter: 1696/2105
[A[ATraining Step: 912  | total loss: [1m[32m0.21264[0m[0m | time: 54.726s
[2K
| Adam | epoch: 014 | loss: 0.21264 - acc: 0.9246 -- iter: 1728/2105
[A[ATraining Step: 913  | total loss: [1m[32m0.21707[0m[0m | time: 55.717s
[2K
| Adam | epoch: 014 | loss: 0.21707 - acc: 0.9165 -- iter: 1760/2105
[A[ATraining Step: 914  | total loss: [1m[32m0.21817[0m[0m | time: 56.712s
[2K
| Adam | epoch: 014 | loss: 0.21817 - acc: 0.9124 -- iter: 1792/2105
[A[ATraining Step: 915  | total loss: [1m[32m0.21978[0m[0m | time: 57.745s
[2K
| Adam | epoch: 014 | loss: 0.21978 - acc: 0.9117 -- iter: 1824/2105
[A[ATraining Step: 916  | total loss: [1m[32m0.21691[0m[0m | time: 58.907s
[2K
| Adam | epoch: 014 | loss: 0.21691 - acc: 0.9174 -- iter: 1856/2105
[A[ATraining Step: 917  | total loss: [1m[32m0.21432[0m[0m | time: 60.089s
[2K
| Adam | epoch: 014 | loss: 0.21432 - acc: 0.9163 -- iter: 1888/2105
[A[ATraining Step: 918  | total loss: [1m[32m0.21814[0m[0m | time: 60.938s
[2K
| Adam | epoch: 014 | loss: 0.21814 - acc: 0.9153 -- iter: 1920/2105
[A[ATraining Step: 919  | total loss: [1m[32m0.20863[0m[0m | time: 61.902s
[2K
| Adam | epoch: 014 | loss: 0.20863 - acc: 0.9207 -- iter: 1952/2105
[A[ATraining Step: 920  | total loss: [1m[32m0.20034[0m[0m | time: 62.903s
[2K
| Adam | epoch: 014 | loss: 0.20034 - acc: 0.9223 -- iter: 1984/2105
[A[ATraining Step: 921  | total loss: [1m[32m0.20284[0m[0m | time: 63.989s
[2K
| Adam | epoch: 014 | loss: 0.20284 - acc: 0.9207 -- iter: 2016/2105
[A[ATraining Step: 922  | total loss: [1m[32m0.18927[0m[0m | time: 65.066s
[2K
| Adam | epoch: 014 | loss: 0.18927 - acc: 0.9287 -- iter: 2048/2105
[A[ATraining Step: 923  | total loss: [1m[32m0.18056[0m[0m | time: 66.067s
[2K
| Adam | epoch: 014 | loss: 0.18056 - acc: 0.9358 -- iter: 2080/2105
[A[ATraining Step: 924  | total loss: [1m[32m0.17524[0m[0m | time: 71.194s
[2K
| Adam | epoch: 014 | loss: 0.17524 - acc: 0.9360 | val_loss: 0.41139 - val_acc: 0.8237 -- iter: 2105/2105
--
Training Step: 925  | total loss: [1m[32m0.17933[0m[0m | time: 0.986s
[2K
| Adam | epoch: 015 | loss: 0.17933 - acc: 0.9330 -- iter: 0032/2105
[A[ATraining Step: 926  | total loss: [1m[32m0.18542[0m[0m | time: 1.983s
[2K
| Adam | epoch: 015 | loss: 0.18542 - acc: 0.9303 -- iter: 0064/2105
[A[ATraining Step: 927  | total loss: [1m[32m0.19955[0m[0m | time: 2.990s
[2K
| Adam | epoch: 015 | loss: 0.19955 - acc: 0.9279 -- iter: 0096/2105
[A[ATraining Step: 928  | total loss: [1m[32m0.19752[0m[0m | time: 4.011s
[2K
| Adam | epoch: 015 | loss: 0.19752 - acc: 0.9257 -- iter: 0128/2105
[A[ATraining Step: 929  | total loss: [1m[32m0.19819[0m[0m | time: 5.043s
[2K
| Adam | epoch: 015 | loss: 0.19819 - acc: 0.9238 -- iter: 0160/2105
[A[ATraining Step: 930  | total loss: [1m[32m0.19384[0m[0m | time: 6.043s
[2K
| Adam | epoch: 015 | loss: 0.19384 - acc: 0.9220 -- iter: 0192/2105
[A[ATraining Step: 931  | total loss: [1m[32m0.18947[0m[0m | time: 6.991s
[2K
| Adam | epoch: 015 | loss: 0.18947 - acc: 0.9236 -- iter: 0224/2105
[A[ATraining Step: 932  | total loss: [1m[32m0.18487[0m[0m | time: 8.230s
[2K
| Adam | epoch: 015 | loss: 0.18487 - acc: 0.9250 -- iter: 0256/2105
[A[ATraining Step: 933  | total loss: [1m[32m0.18355[0m[0m | time: 9.518s
[2K
| Adam | epoch: 015 | loss: 0.18355 - acc: 0.9262 -- iter: 0288/2105
[A[ATraining Step: 934  | total loss: [1m[32m0.18042[0m[0m | time: 10.427s
[2K
| Adam | epoch: 015 | loss: 0.18042 - acc: 0.9242 -- iter: 0320/2105
[A[ATraining Step: 935  | total loss: [1m[32m0.17010[0m[0m | time: 11.381s
[2K
| Adam | epoch: 015 | loss: 0.17010 - acc: 0.9287 -- iter: 0352/2105
[A[ATraining Step: 936  | total loss: [1m[32m0.17091[0m[0m | time: 12.376s
[2K
| Adam | epoch: 015 | loss: 0.17091 - acc: 0.9296 -- iter: 0384/2105
[A[ATraining Step: 937  | total loss: [1m[32m0.16798[0m[0m | time: 13.193s
[2K
| Adam | epoch: 015 | loss: 0.16798 - acc: 0.9335 -- iter: 0416/2105
[A[ATraining Step: 938  | total loss: [1m[32m0.16786[0m[0m | time: 13.983s
[2K
| Adam | epoch: 015 | loss: 0.16786 - acc: 0.9321 -- iter: 0448/2105
[A[ATraining Step: 939  | total loss: [1m[32m0.16503[0m[0m | time: 15.038s
[2K
| Adam | epoch: 015 | loss: 0.16503 - acc: 0.9349 -- iter: 0480/2105
[A[ATraining Step: 940  | total loss: [1m[32m0.15676[0m[0m | time: 16.018s
[2K
| Adam | epoch: 015 | loss: 0.15676 - acc: 0.9414 -- iter: 0512/2105
[A[ATraining Step: 941  | total loss: [1m[32m0.15193[0m[0m | time: 17.024s
[2K
| Adam | epoch: 015 | loss: 0.15193 - acc: 0.9473 -- iter: 0544/2105
[A[ATraining Step: 942  | total loss: [1m[32m0.15805[0m[0m | time: 18.038s
[2K
| Adam | epoch: 015 | loss: 0.15805 - acc: 0.9401 -- iter: 0576/2105
[A[ATraining Step: 943  | total loss: [1m[32m0.15286[0m[0m | time: 19.250s
[2K
| Adam | epoch: 015 | loss: 0.15286 - acc: 0.9461 -- iter: 0608/2105
[A[ATraining Step: 944  | total loss: [1m[32m0.15648[0m[0m | time: 20.481s
[2K
| Adam | epoch: 015 | loss: 0.15648 - acc: 0.9421 -- iter: 0640/2105
[A[ATraining Step: 945  | total loss: [1m[32m0.15532[0m[0m | time: 21.357s
[2K
| Adam | epoch: 015 | loss: 0.15532 - acc: 0.9416 -- iter: 0672/2105
[A[ATraining Step: 946  | total loss: [1m[32m0.15031[0m[0m | time: 22.255s
[2K
| Adam | epoch: 015 | loss: 0.15031 - acc: 0.9443 -- iter: 0704/2105
[A[ATraining Step: 947  | total loss: [1m[32m0.14469[0m[0m | time: 23.276s
[2K
| Adam | epoch: 015 | loss: 0.14469 - acc: 0.9468 -- iter: 0736/2105
[A[ATraining Step: 948  | total loss: [1m[32m0.14598[0m[0m | time: 24.257s
[2K
| Adam | epoch: 015 | loss: 0.14598 - acc: 0.9490 -- iter: 0768/2105
[A[ATraining Step: 949  | total loss: [1m[32m0.14487[0m[0m | time: 25.208s
[2K
| Adam | epoch: 015 | loss: 0.14487 - acc: 0.9478 -- iter: 0800/2105
[A[ATraining Step: 950  | total loss: [1m[32m0.13929[0m[0m | time: 26.261s
[2K
| Adam | epoch: 015 | loss: 0.13929 - acc: 0.9530 -- iter: 0832/2105
[A[ATraining Step: 951  | total loss: [1m[32m0.15465[0m[0m | time: 27.245s
[2K
| Adam | epoch: 015 | loss: 0.15465 - acc: 0.9515 -- iter: 0864/2105
[A[ATraining Step: 952  | total loss: [1m[32m0.15422[0m[0m | time: 28.226s
[2K
| Adam | epoch: 015 | loss: 0.15422 - acc: 0.9501 -- iter: 0896/2105
[A[ATraining Step: 953  | total loss: [1m[32m0.15299[0m[0m | time: 29.158s
[2K
| Adam | epoch: 015 | loss: 0.15299 - acc: 0.9488 -- iter: 0928/2105
[A[ATraining Step: 954  | total loss: [1m[32m0.14720[0m[0m | time: 30.154s
[2K
| Adam | epoch: 015 | loss: 0.14720 - acc: 0.9508 -- iter: 0960/2105
[A[ATraining Step: 955  | total loss: [1m[32m0.13908[0m[0m | time: 31.259s
[2K
| Adam | epoch: 015 | loss: 0.13908 - acc: 0.9557 -- iter: 0992/2105
[A[ATraining Step: 956  | total loss: [1m[32m0.13208[0m[0m | time: 32.296s
[2K
| Adam | epoch: 015 | loss: 0.13208 - acc: 0.9602 -- iter: 1024/2105
[A[ATraining Step: 957  | total loss: [1m[32m0.13054[0m[0m | time: 33.091s
[2K
| Adam | epoch: 015 | loss: 0.13054 - acc: 0.9579 -- iter: 1056/2105
[A[ATraining Step: 958  | total loss: [1m[32m0.14243[0m[0m | time: 34.076s
[2K
| Adam | epoch: 015 | loss: 0.14243 - acc: 0.9527 -- iter: 1088/2105
[A[ATraining Step: 959  | total loss: [1m[32m0.15792[0m[0m | time: 35.058s
[2K
| Adam | epoch: 015 | loss: 0.15792 - acc: 0.9418 -- iter: 1120/2105
[A[ATraining Step: 960  | total loss: [1m[32m0.15242[0m[0m | time: 36.081s
[2K
| Adam | epoch: 015 | loss: 0.15242 - acc: 0.9477 -- iter: 1152/2105
[A[ATraining Step: 961  | total loss: [1m[32m0.16681[0m[0m | time: 37.119s
[2K
| Adam | epoch: 015 | loss: 0.16681 - acc: 0.9435 -- iter: 1184/2105
[A[ATraining Step: 962  | total loss: [1m[32m0.17975[0m[0m | time: 38.173s
[2K
| Adam | epoch: 015 | loss: 0.17975 - acc: 0.9367 -- iter: 1216/2105
[A[ATraining Step: 963  | total loss: [1m[32m0.17488[0m[0m | time: 39.175s
[2K
| Adam | epoch: 015 | loss: 0.17488 - acc: 0.9399 -- iter: 1248/2105
[A[ATraining Step: 964  | total loss: [1m[32m0.16474[0m[0m | time: 40.103s
[2K
| Adam | epoch: 015 | loss: 0.16474 - acc: 0.9459 -- iter: 1280/2105
[A[ATraining Step: 965  | total loss: [1m[32m0.15679[0m[0m | time: 41.144s
[2K
| Adam | epoch: 015 | loss: 0.15679 - acc: 0.9482 -- iter: 1312/2105
[A[ATraining Step: 966  | total loss: [1m[32m0.15999[0m[0m | time: 42.378s
[2K
| Adam | epoch: 015 | loss: 0.15999 - acc: 0.9471 -- iter: 1344/2105
[A[ATraining Step: 967  | total loss: [1m[32m0.16231[0m[0m | time: 43.577s
[2K
| Adam | epoch: 015 | loss: 0.16231 - acc: 0.9461 -- iter: 1376/2105
[A[ATraining Step: 968  | total loss: [1m[32m0.15634[0m[0m | time: 44.374s
[2K
| Adam | epoch: 015 | loss: 0.15634 - acc: 0.9484 -- iter: 1408/2105
[A[ATraining Step: 969  | total loss: [1m[32m0.15751[0m[0m | time: 45.319s
[2K
| Adam | epoch: 015 | loss: 0.15751 - acc: 0.9442 -- iter: 1440/2105
[A[ATraining Step: 970  | total loss: [1m[32m0.14876[0m[0m | time: 46.340s
[2K
| Adam | epoch: 015 | loss: 0.14876 - acc: 0.9498 -- iter: 1472/2105
[A[ATraining Step: 971  | total loss: [1m[32m0.15191[0m[0m | time: 47.337s
[2K
| Adam | epoch: 015 | loss: 0.15191 - acc: 0.9454 -- iter: 1504/2105
[A[ATraining Step: 972  | total loss: [1m[32m0.16054[0m[0m | time: 48.368s
[2K
| Adam | epoch: 015 | loss: 0.16054 - acc: 0.9446 -- iter: 1536/2105
[A[ATraining Step: 973  | total loss: [1m[32m0.17659[0m[0m | time: 49.425s
[2K
| Adam | epoch: 015 | loss: 0.17659 - acc: 0.9408 -- iter: 1568/2105
[A[ATraining Step: 974  | total loss: [1m[32m0.16708[0m[0m | time: 50.471s
[2K
| Adam | epoch: 015 | loss: 0.16708 - acc: 0.9467 -- iter: 1600/2105
[A[ATraining Step: 975  | total loss: [1m[32m0.15974[0m[0m | time: 51.407s
[2K
| Adam | epoch: 015 | loss: 0.15974 - acc: 0.9520 -- iter: 1632/2105
[A[ATraining Step: 976  | total loss: [1m[32m0.15276[0m[0m | time: 52.519s
[2K
| Adam | epoch: 015 | loss: 0.15276 - acc: 0.9568 -- iter: 1664/2105
[A[ATraining Step: 977  | total loss: [1m[32m0.15119[0m[0m | time: 53.691s
[2K
| Adam | epoch: 015 | loss: 0.15119 - acc: 0.9580 -- iter: 1696/2105
[A[ATraining Step: 978  | total loss: [1m[32m0.15366[0m[0m | time: 54.734s
[2K
| Adam | epoch: 015 | loss: 0.15366 - acc: 0.9560 -- iter: 1728/2105
[A[ATraining Step: 979  | total loss: [1m[32m0.14948[0m[0m | time: 55.549s
[2K
| Adam | epoch: 015 | loss: 0.14948 - acc: 0.9573 -- iter: 1760/2105
[A[ATraining Step: 980  | total loss: [1m[32m0.13987[0m[0m | time: 56.646s
[2K
| Adam | epoch: 015 | loss: 0.13987 - acc: 0.9615 -- iter: 1792/2105
[A[ATraining Step: 981  | total loss: [1m[32m0.14250[0m[0m | time: 57.673s
[2K
| Adam | epoch: 015 | loss: 0.14250 - acc: 0.9560 -- iter: 1824/2105
[A[ATraining Step: 982  | total loss: [1m[32m0.14725[0m[0m | time: 58.674s
[2K
| Adam | epoch: 015 | loss: 0.14725 - acc: 0.9510 -- iter: 1856/2105
[A[ATraining Step: 983  | total loss: [1m[32m0.14577[0m[0m | time: 59.690s
[2K
| Adam | epoch: 015 | loss: 0.14577 - acc: 0.9497 -- iter: 1888/2105
[A[ATraining Step: 984  | total loss: [1m[32m0.14941[0m[0m | time: 60.674s
[2K
| Adam | epoch: 015 | loss: 0.14941 - acc: 0.9453 -- iter: 1920/2105
[A[ATraining Step: 985  | total loss: [1m[32m0.15303[0m[0m | time: 61.623s
[2K
| Adam | epoch: 015 | loss: 0.15303 - acc: 0.9445 -- iter: 1952/2105
[A[ATraining Step: 986  | total loss: [1m[32m0.17302[0m[0m | time: 62.582s
[2K
| Adam | epoch: 015 | loss: 0.17302 - acc: 0.9345 -- iter: 1984/2105
[A[ATraining Step: 987  | total loss: [1m[32m0.16405[0m[0m | time: 63.638s
[2K
| Adam | epoch: 015 | loss: 0.16405 - acc: 0.9379 -- iter: 2016/2105
[A[ATraining Step: 988  | total loss: [1m[32m0.17793[0m[0m | time: 64.835s
[2K
| Adam | epoch: 015 | loss: 0.17793 - acc: 0.9285 -- iter: 2048/2105
[A[ATraining Step: 989  | total loss: [1m[32m0.17429[0m[0m | time: 65.984s
[2K
| Adam | epoch: 015 | loss: 0.17429 - acc: 0.9263 -- iter: 2080/2105
[A[ATraining Step: 990  | total loss: [1m[32m0.16212[0m[0m | time: 70.689s
[2K
| Adam | epoch: 015 | loss: 0.16212 - acc: 0.9336 | val_loss: 0.45873 - val_acc: 0.8222 -- iter: 2105/2105
--
2018-08-02 00:53:50.231747: W tensorflow/core/framework/allocator.cc:101] Allocation of 5959353344 exceeds 10% of system memory.
2018-08-02 00:54:09.123678: W tensorflow/core/framework/allocator.cc:101] Allocation of 5959353344 exceeds 10% of system memory.
Validation AUC:0.90905057675244
Validation AUPRC:0.9102109571585425
Test AUC:0.9290564573498027
Test AUPRC:0.9377898240851138
BestTestF1Score	0.84	0.68	0.84	0.8	0.89	293	72	257	36	0.11
BestTestMCCScore	0.85	0.73	0.86	0.91	0.81	265	26	303	64	0.36
BestTestAccuracyScore	0.85	0.73	0.86	0.91	0.81	265	26	303	64	0.36
BestValidationF1Score	0.83	0.66	0.83	0.78	0.9	290	83	253	32	0.11
BestValidationMCC	0.82	0.66	0.83	0.85	0.79	255	45	291	67	0.36
BestValidationAccuracy	0.82	0.66	0.83	0.85	0.79	255	45	291	67	0.36
TestPredictions (Threshold:0.36)
CHEMBL2381244,TP,ACT,0.949999988079071	CHEMBL312396,TN,INACT,0.0	CHEMBL2203844,TP,ACT,0.8600000143051147	CHEMBL3353406,TN,INACT,0.05000000074505806	CHEMBL452812,TN,INACT,0.019999999552965164	CHEMBL440213,FP,INACT,0.7400000095367432	CHEMBL488835,TP,ACT,0.9100000262260437	CHEMBL304746,TN,INACT,0.05000000074505806	CHEMBL2037086,TP,ACT,0.9800000190734863	CHEMBL1928673,TP,ACT,0.3799999952316284	CHEMBL309016,TN,INACT,0.05000000074505806	CHEMBL378967,TP,ACT,0.6100000143051147	CHEMBL1371386,TN,INACT,0.009999999776482582	CHEMBL2070700,TP,ACT,1.0	CHEMBL324842,TN,INACT,0.07999999821186066	CHEMBL428566,TP,ACT,0.5299999713897705	CHEMBL1928680,FN,ACT,0.09000000357627869	CHEMBL1236798,TN,INACT,0.10000000149011612	CHEMBL1933743,TN,INACT,0.03999999910593033	CHEMBL311370,TN,INACT,0.0	CHEMBL1908397,TP,ACT,0.6299999952316284	CHEMBL249400,TP,ACT,0.6499999761581421	CHEMBL3809141,TN,INACT,0.009999999776482582	CHEMBL247201,TP,ACT,0.9800000190734863	CHEMBL1171955,TN,INACT,0.0	CHEMBL541515,TP,ACT,0.8500000238418579	CHEMBL496588,TN,INACT,0.05999999865889549	CHEMBL511280,FN,ACT,0.33000001311302185	CHEMBL315701,TN,INACT,0.0	CHEMBL3261194,TN,INACT,0.0	CHEMBL306184,TN,INACT,0.0	CHEMBL589413,TN,INACT,0.07999999821186066	CHEMBL476189,TN,INACT,0.07999999821186066	CHEMBL1209834,TN,INACT,0.0	CHEMBL3694360,TP,ACT,0.7900000214576721	CHEMBL471549,FN,ACT,0.10999999940395355	CHEMBL456760,TN,INACT,0.0	CHEMBL237285,TP,ACT,1.0	CHEMBL235605,TP,ACT,0.6299999952316284	CHEMBL1928674,TP,ACT,0.8999999761581421	CHEMBL1288248,TP,ACT,0.8999999761581421	CHEMBL1288192,FN,ACT,0.14000000059604645	CHEMBL435750,TP,ACT,1.0	CHEMBL2335070,TN,INACT,0.009999999776482582	CHEMBL249155,TP,ACT,1.0	CHEMBL1650131,FN,ACT,0.2800000011920929	CHEMBL1643254,FN,ACT,0.019999999552965164	CHEMBL349810,TN,INACT,0.0	CHEMBL452021,TP,ACT,0.9599999785423279	CHEMBL2392366,TN,INACT,0.14000000059604645	CHEMBL3408395,FN,ACT,0.029999999329447746	CHEMBL2382019,TN,INACT,0.009999999776482582	CHEMBL456113,TN,INACT,0.18000000715255737	CHEMBL607707,FN,ACT,0.03999999910593033	CHEMBL3694388,TP,ACT,0.41999998688697815	CHEMBL2312652,TN,INACT,0.25999999046325684	CHEMBL599519,TN,INACT,0.07999999821186066	CHEMBL491263,FN,ACT,0.03999999910593033	CHEMBL374412,TP,ACT,0.7799999713897705	CHEMBL1426468,TN,INACT,0.009999999776482582	CHEMBL1171125,TN,INACT,0.03999999910593033	CHEMBL323564,TN,INACT,0.17000000178813934	CHEMBL393569,TP,ACT,0.9599999785423279	CHEMBL560149,TP,ACT,0.8600000143051147	CHEMBL568789,TN,INACT,0.07999999821186066	CHEMBL1574263,TN,INACT,0.0	CHEMBL1829274,TN,INACT,0.0	CHEMBL564542,TP,ACT,0.4099999964237213	CHEMBL459442,TP,ACT,0.9800000190734863	CHEMBL3665664,TN,INACT,0.009999999776482582	CHEMBL1269497,TN,INACT,0.019999999552965164	CHEMBL2012879,TP,ACT,0.3799999952316284	CHEMBL1223167,TP,ACT,0.5199999809265137	CHEMBL1454594,TN,INACT,0.0	CHEMBL242184,TP,ACT,0.8199999928474426	CHEMBL3781543,TN,INACT,0.05999999865889549	CHEMBL3739750,TP,ACT,0.5799999833106995	CHEMBL394608,TP,ACT,0.8999999761581421	CHEMBL249075,TP,ACT,0.8299999833106995	CHEMBL460940,TP,ACT,0.41999998688697815	CHEMBL486868,TP,ACT,0.8500000238418579	CHEMBL1349172,TN,INACT,0.009999999776482582	CHEMBL207778,TP,ACT,0.9900000095367432	CHEMBL2029520,TN,INACT,0.05999999865889549	CHEMBL2425141,TN,INACT,0.07000000029802322	CHEMBL511992,TP,ACT,0.8600000143051147	CHEMBL487622,TP,ACT,0.9700000286102295	CHEMBL1688206,TN,INACT,0.009999999776482582	CHEMBL215470,TP,ACT,0.9800000190734863	CHEMBL517859,FN,ACT,0.14000000059604645	CHEMBL564596,FN,ACT,0.019999999552965164	CHEMBL77412,TN,INACT,0.23000000417232513	CHEMBL94581,TN,INACT,0.0	CHEMBL279003,TN,INACT,0.0	CHEMBL1337188,TN,INACT,0.0	CHEMBL267213,TN,INACT,0.0	CHEMBL223565,TP,ACT,0.9800000190734863	CHEMBL1739550,TP,ACT,0.7400000095367432	CHEMBL1536771,TN,INACT,0.0	CHEMBL400575,TP,ACT,1.0	CHEMBL247911,TN,INACT,0.20000000298023224	CHEMBL221735,TP,ACT,0.9599999785423279	CHEMBL559893,FN,ACT,0.0	CHEMBL2070706,TP,ACT,0.9900000095367432	CHEMBL3355476,TP,ACT,0.49000000953674316	CHEMBL1643246,TP,ACT,0.9200000166893005	CHEMBL1652453,TN,INACT,0.009999999776482582	CHEMBL2029516,TN,INACT,0.0	CHEMBL3421636,FP,INACT,0.47999998927116394	CHEMBL1643206,TP,ACT,0.8999999761581421	CHEMBL2029523,TN,INACT,0.20000000298023224	CHEMBL522916,TN,INACT,0.05999999865889549	CHEMBL241447,TP,ACT,0.9399999976158142	CHEMBL3582216,TP,ACT,0.9599999785423279	CHEMBL600828,FP,INACT,0.699999988079071	CHEMBL132006,TN,INACT,0.0	CHEMBL2420909,TN,INACT,0.0	CHEMBL1223340,TP,ACT,1.0	CHEMBL1688205,TN,INACT,0.27000001072883606	CHEMBL570313,TN,INACT,0.0	CHEMBL1555880,TN,INACT,0.23000000417232513	CHEMBL3335244,TN,INACT,0.019999999552965164	CHEMBL456759,TN,INACT,0.0	CHEMBL223311,TP,ACT,1.0	CHEMBL2437297,TN,INACT,0.009999999776482582	CHEMBL247652,TP,ACT,0.9900000095367432	CHEMBL1421889,TN,INACT,0.0	CHEMBL559683,TN,INACT,0.0	CHEMBL69863,TN,INACT,0.009999999776482582	CHEMBL1400863,TN,INACT,0.019999999552965164	CHEMBL378756,TP,ACT,0.9900000095367432	CHEMBL1270522,TN,INACT,0.14000000059604645	CHEMBL257067,TP,ACT,0.8799999952316284	CHEMBL265446,TP,ACT,0.46000000834465027	CHEMBL291986,TN,INACT,0.23000000417232513	CHEMBL202930,TP,ACT,0.8999999761581421	CHEMBL17551,TN,INACT,0.0	CHEMBL1641990,FP,INACT,0.4000000059604645	CHEMBL328627,TN,INACT,0.019999999552965164	CHEMBL1223267,FN,ACT,0.10999999940395355	CHEMBL1933754,TN,INACT,0.09000000357627869	CHEMBL1270331,TN,INACT,0.05000000074505806	CHEMBL488238,FN,ACT,0.25	CHEMBL559695,FN,ACT,0.019999999552965164	CHEMBL2013061,TP,ACT,0.7599999904632568	CHEMBL396487,TN,INACT,0.009999999776482582	CHEMBL221633,TP,ACT,0.9399999976158142	CHEMBL272479,TP,ACT,0.9900000095367432	CHEMBL1643241,FN,ACT,0.009999999776482582	CHEMBL2203846,TP,ACT,0.9599999785423279	CHEMBL240093,TN,INACT,0.0	CHEMBL1643462,TP,ACT,0.6700000166893005	CHEMBL247588,TP,ACT,0.9900000095367432	CHEMBL1170124,TN,INACT,0.3100000023841858	CHEMBL284362,FP,INACT,0.550000011920929	CHEMBL248190,TP,ACT,0.9900000095367432	CHEMBL388596,TN,INACT,0.009999999776482582	CHEMBL3694362,TP,ACT,0.44999998807907104	CHEMBL472006,TN,INACT,0.05999999865889549	CHEMBL3582231,TP,ACT,0.9900000095367432	CHEMBL248007,TP,ACT,0.9900000095367432	CHEMBL3740003,TP,ACT,0.5699999928474426	CHEMBL1928701,FN,ACT,0.25999999046325684	CHEMBL1288307,FN,ACT,0.029999999329447746	CHEMBL2425110,TN,INACT,0.0	CHEMBL1208885,TN,INACT,0.019999999552965164	CHEMBL1325688,TN,INACT,0.019999999552965164	CHEMBL596808,TN,INACT,0.009999999776482582	CHEMBL76813,TN,INACT,0.0	CHEMBL540497,FN,ACT,0.1599999964237213	CHEMBL1783554,TN,INACT,0.0	CHEMBL372247,FN,ACT,0.09000000357627869	CHEMBL565046,TP,ACT,0.6700000166893005	CHEMBL3330132,TP,ACT,0.9700000286102295	CHEMBL209388,TP,ACT,0.9700000286102295	CHEMBL1668413,TN,INACT,0.029999999329447746	CHEMBL1643245,TP,ACT,0.949999988079071	CHEMBL1288161,TP,ACT,0.8500000238418579	CHEMBL520929,FN,ACT,0.05999999865889549	CHEMBL232807,TP,ACT,0.9200000166893005	CHEMBL504547,TN,INACT,0.0	CHEMBL1933755,TN,INACT,0.07000000029802322	CHEMBL258818,TN,INACT,0.2199999988079071	CHEMBL281957,TN,INACT,0.23999999463558197	CHEMBL599581,FN,ACT,0.23000000417232513	CHEMBL247427,TP,ACT,1.0	CHEMBL3109404,TN,INACT,0.009999999776482582	CHEMBL1933074,TN,INACT,0.009999999776482582	CHEMBL2011342,TP,ACT,0.6899999976158142	CHEMBL523179,FN,ACT,0.07999999821186066	CHEMBL558925,TN,INACT,0.009999999776482582	CHEMBL1933749,TN,INACT,0.009999999776482582	CHEMBL1331627,FP,INACT,0.41999998688697815	CHEMBL595048,TN,INACT,0.009999999776482582	CHEMBL248225,TP,ACT,0.9800000190734863	CHEMBL405681,TN,INACT,0.0	CHEMBL3582185,TP,ACT,0.6499999761581421	CHEMBL3189536,TN,INACT,0.07000000029802322	CHEMBL455192,FN,ACT,0.09000000357627869	CHEMBL2070702,TP,ACT,0.8100000023841858	CHEMBL3582229,TP,ACT,0.9800000190734863	CHEMBL560413,FN,ACT,0.0	CHEMBL130871,TN,INACT,0.23000000417232513	CHEMBL466154,TN,INACT,0.009999999776482582	CHEMBL3330235,FN,ACT,0.2800000011920929	CHEMBL549661,FN,ACT,0.25999999046325684	CHEMBL139269,TN,INACT,0.019999999552965164	CHEMBL392154,TP,ACT,0.8299999833106995	CHEMBL2334715,TN,INACT,0.14000000059604645	CHEMBL395037,TP,ACT,0.9200000166893005	CHEMBL1643210,TP,ACT,0.44999998807907104	CHEMBL1288073,TP,ACT,1.0	CHEMBL3582219,TP,ACT,0.699999988079071	CHEMBL1287863,TP,ACT,0.9900000095367432	CHEMBL1223459,TP,ACT,0.9599999785423279	CHEMBL395894,TP,ACT,0.9599999785423279	CHEMBL249154,TP,ACT,1.0	CHEMBL519891,TP,ACT,0.9100000262260437	CHEMBL3694365,TP,ACT,0.949999988079071	CHEMBL1287892,TP,ACT,1.0	CHEMBL270866,TP,ACT,0.9599999785423279	CHEMBL206812,FN,ACT,0.11999999731779099	CHEMBL243500,TP,ACT,0.9200000166893005	CHEMBL1287949,TP,ACT,0.9399999976158142	CHEMBL3616869,TN,INACT,0.009999999776482582	CHEMBL1668417,TN,INACT,0.03999999910593033	CHEMBL1643255,TP,ACT,0.7400000095367432	CHEMBL555321,TN,INACT,0.009999999776482582	CHEMBL53463,TN,INACT,0.3400000035762787	CHEMBL247200,TP,ACT,0.9599999785423279	CHEMBL293731,TN,INACT,0.1599999964237213	CHEMBL1910756,TN,INACT,0.07000000029802322	CHEMBL3421974,TN,INACT,0.1599999964237213	CHEMBL336975,TN,INACT,0.019999999552965164	CHEMBL336958,TN,INACT,0.019999999552965164	CHEMBL336864,TN,INACT,0.12999999523162842	CHEMBL2393376,TN,INACT,0.009999999776482582	CHEMBL1643233,FN,ACT,0.2199999988079071	CHEMBL2037021,TP,ACT,0.9300000071525574	CHEMBL2029519,TN,INACT,0.05000000074505806	CHEMBL246842,TP,ACT,0.9399999976158142	CHEMBL503641,TN,INACT,0.05999999865889549	CHEMBL478488,TN,INACT,0.009999999776482582	CHEMBL3313935,TN,INACT,0.029999999329447746	CHEMBL1170125,TN,INACT,0.17000000178813934	CHEMBL2011329,TP,ACT,0.9800000190734863	CHEMBL1478,TN,INACT,0.029999999329447746	CHEMBL292866,TN,INACT,0.11999999731779099	CHEMBL23507,TN,INACT,0.05999999865889549	CHEMBL2322996,TN,INACT,0.009999999776482582	CHEMBL436679,TN,INACT,0.05000000074505806	CHEMBL436817,TN,INACT,0.009999999776482582	CHEMBL131229,TN,INACT,0.009999999776482582	CHEMBL248214,TP,ACT,1.0	CHEMBL2012858,TP,ACT,0.5299999713897705	CHEMBL215417,TN,INACT,0.14000000059604645	CHEMBL2381250,TP,ACT,0.5299999713897705	CHEMBL1783551,TN,INACT,0.0	CHEMBL576353,TN,INACT,0.019999999552965164	CHEMBL3359883,FN,ACT,0.23000000417232513	CHEMBL249238,FN,ACT,0.25	CHEMBL1223183,TP,ACT,0.9800000190734863	CHEMBL3612750,TN,INACT,0.3100000023841858	CHEMBL247826,TP,ACT,0.9599999785423279	CHEMBL223512,TP,ACT,0.36000001430511475	CHEMBL221554,TP,ACT,0.8899999856948853	CHEMBL255427,TP,ACT,0.9700000286102295	CHEMBL1288220,TP,ACT,0.6399999856948853	CHEMBL2409596,TN,INACT,0.03999999910593033	CHEMBL3694385,TP,ACT,0.9200000166893005	CHEMBL2336578,TN,INACT,0.0	CHEMBL3741655,TP,ACT,0.6700000166893005	CHEMBL212084,TN,INACT,0.3400000035762787	CHEMBL212646,TP,ACT,0.949999988079071	CHEMBL272267,TP,ACT,0.9399999976158142	CHEMBL1642293,TN,INACT,0.009999999776482582	CHEMBL247824,TP,ACT,0.9900000095367432	CHEMBL2041933,TP,ACT,0.8799999952316284	CHEMBL3360318,TN,INACT,0.14000000059604645	CHEMBL441811,TN,INACT,0.009999999776482582	CHEMBL250035,TP,ACT,0.8100000023841858	CHEMBL159974,TN,INACT,0.0	CHEMBL274926,FP,INACT,0.7400000095367432	CHEMBL244756,TP,ACT,0.8199999928474426	CHEMBL141238,TN,INACT,0.009999999776482582	CHEMBL1762110,FP,INACT,0.4000000059604645	CHEMBL3359892,TP,ACT,0.8799999952316284	CHEMBL250628,TP,ACT,1.0	CHEMBL1223044,TP,ACT,1.0	CHEMBL399023,TP,ACT,0.550000011920929	CHEMBL1910754,TN,INACT,0.009999999776482582	CHEMBL1401485,FP,INACT,0.5299999713897705	CHEMBL1223247,TP,ACT,0.47999998927116394	CHEMBL3582200,FN,ACT,0.05000000074505806	CHEMBL278526,TN,INACT,0.05999999865889549	CHEMBL1454635,TN,INACT,0.0	CHEMBL278071,TN,INACT,0.05999999865889549	CHEMBL1223456,TP,ACT,0.8799999952316284	CHEMBL2064381,TN,INACT,0.019999999552965164	CHEMBL316485,TN,INACT,0.019999999552965164	CHEMBL427720,TP,ACT,0.9300000071525574	CHEMBL1928693,FN,ACT,0.05999999865889549	CHEMBL1459123,TN,INACT,0.0	CHEMBL470288,TP,ACT,0.9800000190734863	CHEMBL513079,TP,ACT,0.7799999713897705	CHEMBL1734241,TN,INACT,0.0	CHEMBL245802,TP,ACT,1.0	CHEMBL602472,FP,INACT,0.7200000286102295	CHEMBL457047,TN,INACT,0.009999999776482582	CHEMBL1529808,TN,INACT,0.009999999776482582	CHEMBL212494,TP,ACT,1.0	CHEMBL248911,TP,ACT,0.9800000190734863	CHEMBL52654,TN,INACT,0.05999999865889549	CHEMBL1480110,TN,INACT,0.009999999776482582	CHEMBL238625,TP,ACT,0.6899999976158142	CHEMBL1170531,TN,INACT,0.03999999910593033	CHEMBL3665661,TN,INACT,0.019999999552965164	CHEMBL462011,TP,ACT,0.7099999785423279	CHEMBL456964,TN,INACT,0.0	CHEMBL335628,TN,INACT,0.25	CHEMBL1374352,FP,INACT,0.41999998688697815	CHEMBL1223460,TP,ACT,0.9300000071525574	CHEMBL270302,TN,INACT,0.019999999552965164	CHEMBL199973,FN,ACT,0.25	CHEMBL3115323,TN,INACT,0.10000000149011612	CHEMBL264666,TN,INACT,0.0	CHEMBL206460,TP,ACT,0.9800000190734863	CHEMBL336314,TN,INACT,0.009999999776482582	CHEMBL2375548,TN,INACT,0.019999999552965164	CHEMBL236019,TP,ACT,0.9800000190734863	CHEMBL285527,TN,INACT,0.0	CHEMBL211140,TP,ACT,0.9900000095367432	CHEMBL3680481,TN,INACT,0.009999999776482582	CHEMBL212798,TP,ACT,0.949999988079071	CHEMBL248992,FN,ACT,0.20999999344348907	CHEMBL2011296,TN,INACT,0.029999999329447746	CHEMBL1783546,TN,INACT,0.0	CHEMBL221428,TP,ACT,0.9900000095367432	CHEMBL480354,FN,ACT,0.17000000178813934	CHEMBL323015,TN,INACT,0.2199999988079071	CHEMBL1223388,TP,ACT,0.8999999761581421	CHEMBL2392241,TN,INACT,0.019999999552965164	CHEMBL1650130,FN,ACT,0.10999999940395355	CHEMBL375416,TP,ACT,0.8399999737739563	CHEMBL311449,TN,INACT,0.009999999776482582	CHEMBL2204592,TP,ACT,0.8899999856948853	CHEMBL555940,TP,ACT,0.6299999952316284	CHEMBL505538,TN,INACT,0.07999999821186066	CHEMBL2013065,TP,ACT,0.9599999785423279	CHEMBL606052,FN,ACT,0.17000000178813934	CHEMBL452791,TP,ACT,0.44999998807907104	CHEMBL1791360,TN,INACT,0.0	CHEMBL392516,TP,ACT,0.8299999833106995	CHEMBL2070715,TP,ACT,1.0	CHEMBL1439904,TN,INACT,0.0	CHEMBL7137,TN,INACT,0.05999999865889549	CHEMBL485502,TN,INACT,0.0	CHEMBL1522377,TN,INACT,0.25	CHEMBL486665,TP,ACT,0.8500000238418579	CHEMBL1928698,TP,ACT,0.4699999988079071	CHEMBL248871,TP,ACT,0.9200000166893005	CHEMBL3694374,TP,ACT,0.9900000095367432	CHEMBL3680501,TN,INACT,0.05000000074505806	CHEMBL1933747,TN,INACT,0.019999999552965164	CHEMBL341946,TN,INACT,0.009999999776482582	CHEMBL3408386,TP,ACT,0.3700000047683716	CHEMBL551025,FN,ACT,0.009999999776482582	CHEMBL538671,TP,ACT,0.9300000071525574	CHEMBL590109,FN,ACT,0.14000000059604645	CHEMBL244141,TP,ACT,0.9300000071525574	CHEMBL255816,TP,ACT,0.7300000190734863	CHEMBL1558177,TN,INACT,0.0	CHEMBL2012866,TP,ACT,0.46000000834465027	CHEMBL2322990,TN,INACT,0.0	CHEMBL591051,TN,INACT,0.009999999776482582	CHEMBL1277132,FN,ACT,0.33000001311302185	CHEMBL373897,TP,ACT,0.6000000238418579	CHEMBL1170317,TN,INACT,0.009999999776482582	CHEMBL2425158,TN,INACT,0.10999999940395355	CHEMBL336644,TN,INACT,0.0	CHEMBL489430,TN,INACT,0.0	CHEMBL233349,FP,INACT,0.5199999809265137	CHEMBL561136,TN,INACT,0.0	CHEMBL334539,TN,INACT,0.07000000029802322	CHEMBL2163627,TN,INACT,0.019999999552965164	CHEMBL1545746,TN,INACT,0.029999999329447746	CHEMBL70942,TN,INACT,0.019999999552965164	CHEMBL91,TN,INACT,0.019999999552965164	CHEMBL3629331,TN,INACT,0.0	CHEMBL212659,TP,ACT,0.9900000095367432	CHEMBL1160358,TN,INACT,0.009999999776482582	CHEMBL602471,FP,INACT,0.8199999928474426	CHEMBL496587,TN,INACT,0.009999999776482582	CHEMBL399532,TP,ACT,0.9700000286102295	CHEMBL1779744,TN,INACT,0.0	CHEMBL2336582,TN,INACT,0.009999999776482582	CHEMBL3694344,TP,ACT,0.9599999785423279	CHEMBL3359889,TP,ACT,0.9300000071525574	CHEMBL510360,TN,INACT,0.019999999552965164	CHEMBL249115,TP,ACT,0.9700000286102295	CHEMBL1392879,TN,INACT,0.0	CHEMBL214949,TN,INACT,0.1599999964237213	CHEMBL255465,FN,ACT,0.07000000029802322	CHEMBL1310505,TN,INACT,0.0	CHEMBL2012841,TP,ACT,0.9800000190734863	CHEMBL2012863,TP,ACT,1.0	CHEMBL248001,TP,ACT,0.9599999785423279	CHEMBL201638,FP,INACT,0.8299999833106995	CHEMBL399255,TP,ACT,0.9700000286102295	CHEMBL88533,TN,INACT,0.009999999776482582	CHEMBL3582220,TP,ACT,0.9399999976158142	CHEMBL2392392,TN,INACT,0.0	CHEMBL2012870,TP,ACT,0.9800000190734863	CHEMBL1643459,FN,ACT,0.019999999552965164	CHEMBL1372854,TN,INACT,0.029999999329447746	CHEMBL221603,TP,ACT,0.8199999928474426	CHEMBL249972,TP,ACT,0.9800000190734863	CHEMBL264667,TN,INACT,0.0	CHEMBL178133,TN,INACT,0.09000000357627869	CHEMBL102765,TN,INACT,0.009999999776482582	CHEMBL132369,TN,INACT,0.07999999821186066	CHEMBL1524458,TN,INACT,0.019999999552965164	CHEMBL2012871,TP,ACT,0.9800000190734863	CHEMBL460848,FN,ACT,0.12999999523162842	CHEMBL573578,TN,INACT,0.0	CHEMBL396060,FN,ACT,0.009999999776482582	CHEMBL2012864,TP,ACT,0.9399999976158142	CHEMBL1790815,FP,INACT,0.36000001430511475	CHEMBL3582228,TP,ACT,0.9900000095367432	CHEMBL552355,TP,ACT,0.8799999952316284	CHEMBL3694395,TP,ACT,0.800000011920929	CHEMBL3809985,TN,INACT,0.05999999865889549	CHEMBL3740582,FN,ACT,0.05999999865889549	CHEMBL214140,TP,ACT,0.9800000190734863	CHEMBL1683298,TN,INACT,0.05999999865889549	CHEMBL2029518,TN,INACT,0.03999999910593033	CHEMBL247459,TP,ACT,0.9800000190734863	CHEMBL3694359,TP,ACT,0.6299999952316284	CHEMBL519238,TP,ACT,0.44999998807907104	CHEMBL527039,TN,INACT,0.23999999463558197	CHEMBL2037093,TP,ACT,0.9700000286102295	CHEMBL272351,TP,ACT,0.7799999713897705	CHEMBL497454,TN,INACT,0.0	CHEMBL629,TN,INACT,0.3199999928474426	CHEMBL2409599,TN,INACT,0.019999999552965164	CHEMBL398757,TP,ACT,1.0	CHEMBL277236,TN,INACT,0.0	CHEMBL249764,TP,ACT,0.9900000095367432	CHEMBL505413,TN,INACT,0.0	CHEMBL245769,TN,INACT,0.019999999552965164	CHEMBL3359887,TP,ACT,0.9800000190734863	CHEMBL456378,FP,INACT,0.5199999809265137	CHEMBL2012874,TP,ACT,0.8799999952316284	CHEMBL540992,TP,ACT,0.6100000143051147	CHEMBL3582199,TP,ACT,0.949999988079071	CHEMBL3104854,TN,INACT,0.009999999776482582	CHEMBL22978,TN,INACT,0.0	CHEMBL1288279,FN,ACT,0.20999999344348907	CHEMBL393603,TP,ACT,0.9800000190734863	CHEMBL1643225,TP,ACT,0.550000011920929	CHEMBL377312,TP,ACT,0.6499999761581421	CHEMBL1584518,TN,INACT,0.009999999776482582	CHEMBL1790311,FP,INACT,0.4099999964237213	CHEMBL2013064,FN,ACT,0.3499999940395355	CHEMBL1643461,TP,ACT,0.7200000286102295	CHEMBL495052,FN,ACT,0.009999999776482582	CHEMBL3102933,TN,INACT,0.05000000074505806	CHEMBL236646,TP,ACT,1.0	CHEMBL550821,FN,ACT,0.03999999910593033	CHEMBL3582189,TP,ACT,0.8899999856948853	CHEMBL312078,TN,INACT,0.009999999776482582	CHEMBL460472,TN,INACT,0.03999999910593033	CHEMBL3330234,TP,ACT,0.7099999785423279	CHEMBL375097,TP,ACT,0.9800000190734863	CHEMBL1254224,TN,INACT,0.009999999776482582	CHEMBL328034,TN,INACT,0.009999999776482582	CHEMBL209511,TN,INACT,0.0	CHEMBL384293,FP,INACT,0.3700000047683716	CHEMBL541265,TN,INACT,0.009999999776482582	CHEMBL3330228,FN,ACT,0.27000001072883606	CHEMBL511991,TP,ACT,0.9200000166893005	CHEMBL115421,TN,INACT,0.10999999940395355	CHEMBL1223320,TP,ACT,0.6600000262260437	CHEMBL3408388,TP,ACT,0.4300000071525574	CHEMBL1643250,TP,ACT,0.8399999737739563	CHEMBL3694390,TP,ACT,0.9800000190734863	CHEMBL560278,TN,INACT,0.0	CHEMBL2113341,TN,INACT,0.0	CHEMBL1809197,TN,INACT,0.009999999776482582	CHEMBL33175,TN,INACT,0.2199999988079071	CHEMBL2011293,TN,INACT,0.03999999910593033	CHEMBL1223339,TP,ACT,1.0	CHEMBL21096,TN,INACT,0.009999999776482582	CHEMBL1643261,TP,ACT,0.6600000262260437	CHEMBL513154,TN,INACT,0.029999999329447746	CHEMBL249089,TN,INACT,0.0	CHEMBL3355472,FN,ACT,0.12999999523162842	CHEMBL563639,FN,ACT,0.05000000074505806	CHEMBL2392242,TN,INACT,0.03999999910593033	CHEMBL520904,TP,ACT,0.5299999713897705	CHEMBL326711,FP,INACT,0.7599999904632568	CHEMBL192161,TP,ACT,0.8399999737739563	CHEMBL3421979,TN,INACT,0.0	CHEMBL77032,FP,INACT,0.44999998807907104	CHEMBL2381609,TN,INACT,0.20000000298023224	CHEMBL2393373,TN,INACT,0.0	CHEMBL1807604,FP,INACT,0.949999988079071	CHEMBL1222992,TN,INACT,0.03999999910593033	CHEMBL2420911,FN,ACT,0.0	CHEMBL38380,TN,INACT,0.0	CHEMBL2381112,TP,ACT,0.9599999785423279	CHEMBL511410,TN,INACT,0.019999999552965164	CHEMBL234865,TP,ACT,0.9900000095367432	CHEMBL223640,TP,ACT,1.0	CHEMBL400804,TP,ACT,0.9900000095367432	CHEMBL218489,TP,ACT,0.9900000095367432	CHEMBL1947252,TP,ACT,0.3700000047683716	CHEMBL1641989,TN,INACT,0.3499999940395355	CHEMBL381028,TP,ACT,0.4099999964237213	CHEMBL2425143,TN,INACT,0.019999999552965164	CHEMBL1600661,TN,INACT,0.0	CHEMBL608533,FN,ACT,0.1599999964237213	CHEMBL1092013,TN,INACT,0.1899999976158142	CHEMBL214005,TP,ACT,0.9599999785423279	CHEMBL3661094,TN,INACT,0.14000000059604645	CHEMBL559621,TP,ACT,0.9300000071525574	CHEMBL2348170,TN,INACT,0.0	CHEMBL3261186,TN,INACT,0.0	CHEMBL451860,TN,INACT,0.009999999776482582	CHEMBL600795,TN,INACT,0.0	CHEMBL2392237,TN,INACT,0.009999999776482582	CHEMBL3694397,TP,ACT,0.7799999713897705	CHEMBL2070699,TP,ACT,0.75	CHEMBL551318,TN,INACT,0.0	CHEMBL563281,TN,INACT,0.0	CHEMBL557525,TN,INACT,0.0	CHEMBL1436125,TN,INACT,0.009999999776482582	CHEMBL29197,TN,INACT,0.009999999776482582	CHEMBL3694380,TP,ACT,0.8199999928474426	CHEMBL2348175,TN,INACT,0.0	CHEMBL1933801,TN,INACT,0.0	CHEMBL1643235,TP,ACT,0.4000000059604645	CHEMBL2023149,FP,INACT,0.75	CHEMBL486828,TP,ACT,0.8199999928474426	CHEMBL1288101,TP,ACT,0.9800000190734863	CHEMBL1171416,TN,INACT,0.0	CHEMBL2013169,TP,ACT,0.9800000190734863	CHEMBL511451,TN,INACT,0.019999999552965164	CHEMBL2029510,TN,INACT,0.019999999552965164	CHEMBL249363,TP,ACT,0.9200000166893005	CHEMBL2392246,TN,INACT,0.0	CHEMBL460079,TP,ACT,0.6200000047683716	CHEMBL3764798,FP,INACT,0.8199999928474426	CHEMBL520240,TP,ACT,0.6000000238418579	CHEMBL248002,TP,ACT,0.9599999785423279	CHEMBL395277,TP,ACT,0.8299999833106995	CHEMBL1643256,TP,ACT,0.38999998569488525	CHEMBL246166,TN,INACT,0.03999999910593033	CHEMBL3582193,TP,ACT,0.9900000095367432	CHEMBL3261188,TN,INACT,0.0	CHEMBL2011344,TP,ACT,0.9599999785423279	CHEMBL1288964,TN,INACT,0.0	CHEMBL1767294,TN,INACT,0.009999999776482582	CHEMBL3582196,TP,ACT,0.949999988079071	CHEMBL77242,TN,INACT,0.03999999910593033	CHEMBL330360,TN,INACT,0.0	CHEMBL2334723,TN,INACT,0.009999999776482582	CHEMBL246356,TN,INACT,0.029999999329447746	CHEMBL3694383,TP,ACT,0.5099999904632568	CHEMBL332342,TN,INACT,0.1899999976158142	CHEMBL3263998,TN,INACT,0.23999999463558197	CHEMBL390670,FN,ACT,0.029999999329447746	CHEMBL1223040,TP,ACT,0.8600000143051147	CHEMBL480350,FN,ACT,0.009999999776482582	CHEMBL471095,TP,ACT,0.9300000071525574	CHEMBL1231626,TP,ACT,1.0	CHEMBL600048,TN,INACT,0.009999999776482582	CHEMBL3665668,TN,INACT,0.09000000357627869	CHEMBL1643242,TP,ACT,0.44999998807907104	CHEMBL549525,TP,ACT,0.9700000286102295	CHEMBL1688208,TN,INACT,0.0	CHEMBL1223455,TP,ACT,0.5600000023841858	CHEMBL1223168,TP,ACT,0.5400000214576721	CHEMBL71884,TN,INACT,0.33000001311302185	CHEMBL1643259,TP,ACT,0.8700000047683716	CHEMBL498203,TN,INACT,0.029999999329447746	CHEMBL2088099,TN,INACT,0.3400000035762787	CHEMBL3582201,TP,ACT,0.9900000095367432	CHEMBL513379,TN,INACT,0.05999999865889549	CHEMBL219689,TP,ACT,0.9599999785423279	CHEMBL3359894,TP,ACT,0.9900000095367432	CHEMBL247199,TP,ACT,0.949999988079071	CHEMBL510668,TP,ACT,0.8799999952316284	CHEMBL2013062,TP,ACT,0.9100000262260437	CHEMBL132963,TN,INACT,0.0	CHEMBL316239,TN,INACT,0.07000000029802322	CHEMBL1973073,TN,INACT,0.33000001311302185	CHEMBL1783564,TN,INACT,0.019999999552965164	CHEMBL3408394,FN,ACT,0.009999999776482582	CHEMBL488645,TN,INACT,0.23999999463558197	CHEMBL249971,TP,ACT,1.0	CHEMBL1494345,TN,INACT,0.009999999776482582	CHEMBL1909651,TN,INACT,0.0	CHEMBL1910753,TN,INACT,0.23999999463558197	CHEMBL1458153,TN,INACT,0.0	CHEMBL3115321,TN,INACT,0.03999999910593033	CHEMBL1235213,TN,INACT,0.1899999976158142	CHEMBL247193,TP,ACT,1.0	CHEMBL488239,TP,ACT,0.9900000095367432	CHEMBL3742200,FN,ACT,0.10999999940395355	CHEMBL590521,TN,INACT,0.09000000357627869	CHEMBL236230,TP,ACT,1.0	CHEMBL311574,TN,INACT,0.0	CHEMBL1767275,TN,INACT,0.029999999329447746	CHEMBL1641619,TP,ACT,0.7099999785423279	CHEMBL2204588,TP,ACT,0.9399999976158142	CHEMBL3694345,TP,ACT,0.9800000190734863	CHEMBL130106,TN,INACT,0.009999999776482582	CHEMBL271727,TP,ACT,0.9200000166893005	CHEMBL386048,TP,ACT,1.0	CHEMBL2088110,FP,INACT,0.38999998569488525	CHEMBL484307,TN,INACT,0.03999999910593033	CHEMBL271071,TP,ACT,0.9700000286102295	CHEMBL2420584,TN,INACT,0.019999999552965164	CHEMBL1287948,TP,ACT,0.9900000095367432	CHEMBL1270399,TP,ACT,0.5799999833106995	CHEMBL1828880,TN,INACT,0.0	CHEMBL3694378,TP,ACT,0.9100000262260437	CHEMBL496996,TN,INACT,0.05000000074505806	CHEMBL205590,FN,ACT,0.2800000011920929	CHEMBL1643244,TP,ACT,0.5099999904632568	CHEMBL1762119,TN,INACT,0.019999999552965164	CHEMBL2203839,TP,ACT,0.8199999928474426	CHEMBL402093,TP,ACT,0.6899999976158142	CHEMBL1783558,TN,INACT,0.0	CHEMBL509499,TN,INACT,0.0	CHEMBL1377245,TN,INACT,0.3100000023841858	CHEMBL529217,TN,INACT,0.009999999776482582	CHEMBL334891,TN,INACT,0.0	CHEMBL433805,TN,INACT,0.0	CHEMBL40583,TN,INACT,0.019999999552965164	CHEMBL245377,FP,INACT,0.7799999713897705	CHEMBL460421,FN,ACT,0.019999999552965164	CHEMBL1643253,FN,ACT,0.17000000178813934	CHEMBL522892,TP,ACT,0.5099999904632568	CHEMBL236023,TP,ACT,0.7400000095367432	CHEMBL249429,TP,ACT,0.9300000071525574	CHEMBL247977,FN,ACT,0.029999999329447746	CHEMBL373732,TP,ACT,1.0	CHEMBL549867,FN,ACT,0.0	CHEMBL1287914,TN,INACT,0.0	CHEMBL511526,TP,ACT,0.8899999856948853	CHEMBL244142,TP,ACT,0.4699999988079071	CHEMBL262293,TN,INACT,0.0	CHEMBL256192,TP,ACT,0.9200000166893005	CHEMBL1643248,TP,ACT,0.3799999952316284	CHEMBL2177830,FP,INACT,0.9599999785423279	CHEMBL1288162,TP,ACT,0.9900000095367432	

