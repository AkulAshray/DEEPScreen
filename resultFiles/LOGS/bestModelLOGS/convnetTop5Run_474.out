ImageNetInceptionV2 CHEMBL1907 adam 0.001 30 0 0 0.6 False True
Number of active compounds :	160
Number of inactive compounds :	160
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1907_adam_0.001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1907_adam_0.001_30_0.6/
---------------------------------
Training samples: 202
Validation samples: 64
--
Training Step: 1  | time: 36.497s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/202
[A[ATraining Step: 2  | total loss: [1m[32m0.58440[0m[0m | time: 44.427s
[2K
| Adam | epoch: 001 | loss: 0.58440 - acc: 0.6187 -- iter: 064/202
[A[ATraining Step: 3  | total loss: [1m[32m0.97639[0m[0m | time: 52.157s
[2K
| Adam | epoch: 001 | loss: 0.97639 - acc: 0.5216 -- iter: 096/202
[A[ATraining Step: 4  | total loss: [1m[32m0.88506[0m[0m | time: 60.094s
[2K
| Adam | epoch: 001 | loss: 0.88506 - acc: 0.5054 -- iter: 128/202
[A[ATraining Step: 5  | total loss: [1m[32m0.77095[0m[0m | time: 67.963s
[2K
| Adam | epoch: 001 | loss: 0.77095 - acc: 0.6098 -- iter: 160/202
[A[ATraining Step: 6  | total loss: [1m[32m0.65958[0m[0m | time: 75.785s
[2K
| Adam | epoch: 001 | loss: 0.65958 - acc: 0.6598 -- iter: 192/202
[A[ATraining Step: 7  | total loss: [1m[32m0.66888[0m[0m | time: 87.413s
[2K
| Adam | epoch: 001 | loss: 0.66888 - acc: 0.6014 | val_loss: 0.75905 - val_acc: 0.4844 -- iter: 202/202
--
Training Step: 8  | total loss: [1m[32m0.72620[0m[0m | time: 3.203s
[2K
| Adam | epoch: 002 | loss: 0.72620 - acc: 0.6569 -- iter: 032/202
[A[ATraining Step: 9  | total loss: [1m[32m0.55058[0m[0m | time: 10.871s
[2K
| Adam | epoch: 002 | loss: 0.55058 - acc: 0.7856 -- iter: 064/202
[A[ATraining Step: 10  | total loss: [1m[32m0.54704[0m[0m | time: 18.600s
[2K
| Adam | epoch: 002 | loss: 0.54704 - acc: 0.7522 -- iter: 096/202
[A[ATraining Step: 11  | total loss: [1m[32m0.63405[0m[0m | time: 26.425s
[2K
| Adam | epoch: 002 | loss: 0.63405 - acc: 0.7067 -- iter: 128/202
[A[ATraining Step: 12  | total loss: [1m[32m0.61324[0m[0m | time: 34.289s
[2K
| Adam | epoch: 002 | loss: 0.61324 - acc: 0.7121 -- iter: 160/202
[A[ATraining Step: 13  | total loss: [1m[32m0.67011[0m[0m | time: 42.116s
[2K
| Adam | epoch: 002 | loss: 0.67011 - acc: 0.6346 -- iter: 192/202
[A[ATraining Step: 14  | total loss: [1m[32m0.66514[0m[0m | time: 52.799s
[2K
| Adam | epoch: 002 | loss: 0.66514 - acc: 0.6690 | val_loss: 0.73689 - val_acc: 0.5156 -- iter: 202/202
--
Training Step: 15  | total loss: [1m[32m0.64026[0m[0m | time: 3.112s
[2K
| Adam | epoch: 003 | loss: 0.64026 - acc: 0.6763 -- iter: 032/202
[A[ATraining Step: 16  | total loss: [1m[32m0.58370[0m[0m | time: 6.211s
[2K
| Adam | epoch: 003 | loss: 0.58370 - acc: 0.7227 -- iter: 064/202
[A[ATraining Step: 17  | total loss: [1m[32m0.47924[0m[0m | time: 14.049s
[2K
| Adam | epoch: 003 | loss: 0.47924 - acc: 0.7865 -- iter: 096/202
[A[ATraining Step: 18  | total loss: [1m[32m0.43921[0m[0m | time: 21.731s
[2K
| Adam | epoch: 003 | loss: 0.43921 - acc: 0.8171 -- iter: 128/202
[A[ATraining Step: 19  | total loss: [1m[32m0.43949[0m[0m | time: 29.495s
[2K
| Adam | epoch: 003 | loss: 0.43949 - acc: 0.7843 -- iter: 160/202
[A[ATraining Step: 20  | total loss: [1m[32m0.45179[0m[0m | time: 37.291s
[2K
| Adam | epoch: 003 | loss: 0.45179 - acc: 0.7833 -- iter: 192/202
[A[ATraining Step: 21  | total loss: [1m[32m0.47664[0m[0m | time: 47.922s
[2K
| Adam | epoch: 003 | loss: 0.47664 - acc: 0.7924 | val_loss: 0.72163 - val_acc: 0.4844 -- iter: 202/202
--
Training Step: 22  | total loss: [1m[32m0.46896[0m[0m | time: 7.926s
[2K
| Adam | epoch: 004 | loss: 0.46896 - acc: 0.7797 -- iter: 032/202
[A[ATraining Step: 23  | total loss: [1m[32m0.48874[0m[0m | time: 11.071s
[2K
| Adam | epoch: 004 | loss: 0.48874 - acc: 0.7529 -- iter: 064/202
[A[ATraining Step: 24  | total loss: [1m[32m0.38023[0m[0m | time: 14.174s
[2K
| Adam | epoch: 004 | loss: 0.38023 - acc: 0.8224 -- iter: 096/202
[A[ATraining Step: 25  | total loss: [1m[32m0.30591[0m[0m | time: 21.889s
[2K
| Adam | epoch: 004 | loss: 0.30591 - acc: 0.8708 -- iter: 128/202
[A[ATraining Step: 26  | total loss: [1m[32m0.31727[0m[0m | time: 29.584s
[2K
| Adam | epoch: 004 | loss: 0.31727 - acc: 0.8719 -- iter: 160/202
[A[ATraining Step: 27  | total loss: [1m[32m0.30708[0m[0m | time: 37.253s
[2K
| Adam | epoch: 004 | loss: 0.30708 - acc: 0.8808 -- iter: 192/202
[A[ATraining Step: 28  | total loss: [1m[32m0.28454[0m[0m | time: 47.845s
[2K
| Adam | epoch: 004 | loss: 0.28454 - acc: 0.8871 | val_loss: 1.60287 - val_acc: 0.4844 -- iter: 202/202
--
Training Step: 29  | total loss: [1m[32m0.33843[0m[0m | time: 7.761s
[2K
| Adam | epoch: 005 | loss: 0.33843 - acc: 0.8690 -- iter: 032/202
[A[ATraining Step: 30  | total loss: [1m[32m0.32931[0m[0m | time: 15.360s
[2K
| Adam | epoch: 005 | loss: 0.32931 - acc: 0.8630 -- iter: 064/202
[A[ATraining Step: 31  | total loss: [1m[32m0.39931[0m[0m | time: 18.486s
[2K
| Adam | epoch: 005 | loss: 0.39931 - acc: 0.8297 -- iter: 096/202
[A[ATraining Step: 32  | total loss: [1m[32m0.40185[0m[0m | time: 21.670s
[2K
| Adam | epoch: 005 | loss: 0.40185 - acc: 0.8230 -- iter: 128/202
[A[ATraining Step: 33  | total loss: [1m[32m0.32538[0m[0m | time: 29.299s
[2K
| Adam | epoch: 005 | loss: 0.32538 - acc: 0.8619 -- iter: 160/202
[A[ATraining Step: 34  | total loss: [1m[32m0.32695[0m[0m | time: 37.022s
[2K
| Adam | epoch: 005 | loss: 0.32695 - acc: 0.8647 -- iter: 192/202
[A[ATraining Step: 35  | total loss: [1m[32m0.34586[0m[0m | time: 47.755s
[2K
| Adam | epoch: 005 | loss: 0.34586 - acc: 0.8668 | val_loss: 0.81103 - val_acc: 0.4844 -- iter: 202/202
--
Training Step: 36  | total loss: [1m[32m0.34335[0m[0m | time: 7.666s
[2K
| Adam | epoch: 006 | loss: 0.34335 - acc: 0.8685 -- iter: 032/202
[A[ATraining Step: 37  | total loss: [1m[32m0.36188[0m[0m | time: 15.479s
[2K
| Adam | epoch: 006 | loss: 0.36188 - acc: 0.8511 -- iter: 064/202
[A[ATraining Step: 38  | total loss: [1m[32m0.34421[0m[0m | time: 23.210s
[2K
| Adam | epoch: 006 | loss: 0.34421 - acc: 0.8680 -- iter: 096/202
[A[ATraining Step: 39  | total loss: [1m[32m0.34352[0m[0m | time: 26.399s
[2K
| Adam | epoch: 006 | loss: 0.34352 - acc: 0.8633 -- iter: 128/202
[A[ATraining Step: 40  | total loss: [1m[32m0.29549[0m[0m | time: 29.485s
[2K
| Adam | epoch: 006 | loss: 0.29549 - acc: 0.8890 -- iter: 160/202
[A[ATraining Step: 41  | total loss: [1m[32m0.24915[0m[0m | time: 37.190s
[2K
| Adam | epoch: 006 | loss: 0.24915 - acc: 0.9094 -- iter: 192/202
[A[ATraining Step: 42  | total loss: [1m[32m0.25027[0m[0m | time: 47.807s
[2K
| Adam | epoch: 006 | loss: 0.25027 - acc: 0.8975 | val_loss: 1.20078 - val_acc: 0.5312 -- iter: 202/202
--
Training Step: 43  | total loss: [1m[32m0.26105[0m[0m | time: 7.713s
[2K
| Adam | epoch: 007 | loss: 0.26105 - acc: 0.8991 -- iter: 032/202
[A[ATraining Step: 44  | total loss: [1m[32m0.23801[0m[0m | time: 15.382s
[2K
| Adam | epoch: 007 | loss: 0.23801 - acc: 0.9111 -- iter: 064/202
[A[ATraining Step: 45  | total loss: [1m[32m0.23386[0m[0m | time: 23.119s
[2K
| Adam | epoch: 007 | loss: 0.23386 - acc: 0.9103 -- iter: 096/202
[A[ATraining Step: 46  | total loss: [1m[32m0.27155[0m[0m | time: 30.700s
[2K
| Adam | epoch: 007 | loss: 0.27155 - acc: 0.8940 -- iter: 128/202
[A[ATraining Step: 47  | total loss: [1m[32m0.24073[0m[0m | time: 33.833s
[2K
| Adam | epoch: 007 | loss: 0.24073 - acc: 0.9062 -- iter: 160/202
[A[ATraining Step: 48  | total loss: [1m[32m0.35927[0m[0m | time: 36.864s
[2K
| Adam | epoch: 007 | loss: 0.35927 - acc: 0.8731 -- iter: 192/202
[A[ATraining Step: 49  | total loss: [1m[32m0.31573[0m[0m | time: 47.463s
[2K
| Adam | epoch: 007 | loss: 0.31573 - acc: 0.8931 | val_loss: 0.98872 - val_acc: 0.5938 -- iter: 202/202
--
Training Step: 50  | total loss: [1m[32m0.35991[0m[0m | time: 7.672s
[2K
| Adam | epoch: 008 | loss: 0.35991 - acc: 0.8612 -- iter: 032/202
[A[ATraining Step: 51  | total loss: [1m[32m0.36073[0m[0m | time: 15.296s
[2K
| Adam | epoch: 008 | loss: 0.36073 - acc: 0.8586 -- iter: 064/202
[A[ATraining Step: 52  | total loss: [1m[32m0.34355[0m[0m | time: 22.852s
[2K
| Adam | epoch: 008 | loss: 0.34355 - acc: 0.8657 -- iter: 096/202
[A[ATraining Step: 53  | total loss: [1m[32m0.34840[0m[0m | time: 30.471s
[2K
| Adam | epoch: 008 | loss: 0.34840 - acc: 0.8717 -- iter: 128/202
[A[ATraining Step: 54  | total loss: [1m[32m0.31552[0m[0m | time: 38.063s
[2K
| Adam | epoch: 008 | loss: 0.31552 - acc: 0.8903 -- iter: 160/202
[A[ATraining Step: 55  | total loss: [1m[32m0.29103[0m[0m | time: 41.099s
[2K
| Adam | epoch: 008 | loss: 0.29103 - acc: 0.9015 -- iter: 192/202
[A[ATraining Step: 56  | total loss: [1m[32m0.30704[0m[0m | time: 46.889s
[2K
| Adam | epoch: 008 | loss: 0.30704 - acc: 0.9013 | val_loss: 2.38905 - val_acc: 0.5156 -- iter: 202/202
--
Training Step: 57  | total loss: [1m[32m0.27565[0m[0m | time: 7.739s
[2K
| Adam | epoch: 009 | loss: 0.27565 - acc: 0.9150 -- iter: 032/202
[A[ATraining Step: 58  | total loss: [1m[32m0.27644[0m[0m | time: 15.439s
[2K
| Adam | epoch: 009 | loss: 0.27644 - acc: 0.9053 -- iter: 064/202
[A[ATraining Step: 59  | total loss: [1m[32m0.27199[0m[0m | time: 23.144s
[2K
| Adam | epoch: 009 | loss: 0.27199 - acc: 0.9054 -- iter: 096/202
[A[ATraining Step: 60  | total loss: [1m[32m0.26545[0m[0m | time: 30.928s
[2K
| Adam | epoch: 009 | loss: 0.26545 - acc: 0.9055 -- iter: 128/202
[A[ATraining Step: 61  | total loss: [1m[32m0.24920[0m[0m | time: 38.592s
[2K
| Adam | epoch: 009 | loss: 0.24920 - acc: 0.9138 -- iter: 160/202
[A[ATraining Step: 62  | total loss: [1m[32m0.24492[0m[0m | time: 46.249s
[2K
| Adam | epoch: 009 | loss: 0.24492 - acc: 0.9128 -- iter: 192/202
[A[ATraining Step: 63  | total loss: [1m[32m0.24446[0m[0m | time: 52.114s
[2K
| Adam | epoch: 009 | loss: 0.24446 - acc: 0.9120 | val_loss: 2.51181 - val_acc: 0.5156 -- iter: 202/202
--
Training Step: 64  | total loss: [1m[32m0.25525[0m[0m | time: 3.090s
[2K
| Adam | epoch: 010 | loss: 0.25525 - acc: 0.8980 -- iter: 032/202
[A[ATraining Step: 65  | total loss: [1m[32m0.23107[0m[0m | time: 10.926s
[2K
| Adam | epoch: 010 | loss: 0.23107 - acc: 0.9105 -- iter: 064/202
[A[ATraining Step: 66  | total loss: [1m[32m0.27554[0m[0m | time: 18.637s
[2K
| Adam | epoch: 010 | loss: 0.27554 - acc: 0.8948 -- iter: 096/202
[A[ATraining Step: 67  | total loss: [1m[32m0.28674[0m[0m | time: 26.403s
[2K
| Adam | epoch: 010 | loss: 0.28674 - acc: 0.8887 -- iter: 128/202
[A[ATraining Step: 68  | total loss: [1m[32m0.27890[0m[0m | time: 33.889s
[2K
| Adam | epoch: 010 | loss: 0.27890 - acc: 0.8908 -- iter: 160/202
[A[ATraining Step: 69  | total loss: [1m[32m0.26541[0m[0m | time: 41.556s
[2K
| Adam | epoch: 010 | loss: 0.26541 - acc: 0.8926 -- iter: 192/202
[A[ATraining Step: 70  | total loss: [1m[32m0.24925[0m[0m | time: 51.992s
[2K
| Adam | epoch: 010 | loss: 0.24925 - acc: 0.9014 | val_loss: 1.19570 - val_acc: 0.6250 -- iter: 202/202
--
Training Step: 71  | total loss: [1m[32m0.24524[0m[0m | time: 3.129s
[2K
| Adam | epoch: 011 | loss: 0.24524 - acc: 0.9019 -- iter: 032/202
[A[ATraining Step: 72  | total loss: [1m[32m0.22021[0m[0m | time: 6.217s
[2K
| Adam | epoch: 011 | loss: 0.22021 - acc: 0.9130 -- iter: 064/202
[A[ATraining Step: 73  | total loss: [1m[32m0.19736[0m[0m | time: 13.985s
[2K
| Adam | epoch: 011 | loss: 0.19736 - acc: 0.9226 -- iter: 096/202
[A[ATraining Step: 74  | total loss: [1m[32m0.19701[0m[0m | time: 21.527s
[2K
| Adam | epoch: 011 | loss: 0.19701 - acc: 0.9243 -- iter: 128/202
[A[ATraining Step: 75  | total loss: [1m[32m0.19260[0m[0m | time: 29.291s
[2K
| Adam | epoch: 011 | loss: 0.19260 - acc: 0.9223 -- iter: 160/202
[A[ATraining Step: 76  | total loss: [1m[32m0.17498[0m[0m | time: 37.135s
[2K
| Adam | epoch: 011 | loss: 0.17498 - acc: 0.9306 -- iter: 192/202
[A[ATraining Step: 77  | total loss: [1m[32m0.17516[0m[0m | time: 47.586s
[2K
| Adam | epoch: 011 | loss: 0.17516 - acc: 0.9281 | val_loss: 1.40884 - val_acc: 0.5938 -- iter: 202/202
--
Training Step: 78  | total loss: [1m[32m0.16942[0m[0m | time: 7.697s
[2K
| Adam | epoch: 012 | loss: 0.16942 - acc: 0.9323 -- iter: 032/202
[A[ATraining Step: 79  | total loss: [1m[32m0.20083[0m[0m | time: 10.777s
[2K
| Adam | epoch: 012 | loss: 0.20083 - acc: 0.9135 -- iter: 064/202
[A[ATraining Step: 80  | total loss: [1m[32m0.18566[0m[0m | time: 13.783s
[2K
| Adam | epoch: 012 | loss: 0.18566 - acc: 0.9223 -- iter: 096/202
[A[ATraining Step: 81  | total loss: [1m[32m0.17349[0m[0m | time: 21.497s
[2K
| Adam | epoch: 012 | loss: 0.17349 - acc: 0.9302 -- iter: 128/202
[A[ATraining Step: 82  | total loss: [1m[32m0.16085[0m[0m | time: 29.028s
[2K
| Adam | epoch: 012 | loss: 0.16085 - acc: 0.9371 -- iter: 160/202
[A[ATraining Step: 83  | total loss: [1m[32m0.15969[0m[0m | time: 36.697s
[2K
| Adam | epoch: 012 | loss: 0.15969 - acc: 0.9341 -- iter: 192/202
[A[ATraining Step: 84  | total loss: [1m[32m0.16277[0m[0m | time: 47.093s
[2K
| Adam | epoch: 012 | loss: 0.16277 - acc: 0.9344 | val_loss: 1.22399 - val_acc: 0.6719 -- iter: 202/202
--
Training Step: 85  | total loss: [1m[32m0.15483[0m[0m | time: 7.615s
[2K
| Adam | epoch: 013 | loss: 0.15483 - acc: 0.9378 -- iter: 032/202
[A[ATraining Step: 86  | total loss: [1m[32m0.15912[0m[0m | time: 15.081s
[2K
| Adam | epoch: 013 | loss: 0.15912 - acc: 0.9347 -- iter: 064/202
[A[ATraining Step: 87  | total loss: [1m[32m0.16121[0m[0m | time: 18.157s
[2K
| Adam | epoch: 013 | loss: 0.16121 - acc: 0.9350 -- iter: 096/202
[A[ATraining Step: 88  | total loss: [1m[32m0.14630[0m[0m | time: 21.246s
[2K
| Adam | epoch: 013 | loss: 0.14630 - acc: 0.9415 -- iter: 128/202
[A[ATraining Step: 89  | total loss: [1m[32m0.13236[0m[0m | time: 28.839s
[2K
| Adam | epoch: 013 | loss: 0.13236 - acc: 0.9473 -- iter: 160/202
[A[ATraining Step: 90  | total loss: [1m[32m0.12236[0m[0m | time: 36.573s
[2K
| Adam | epoch: 013 | loss: 0.12236 - acc: 0.9526 -- iter: 192/202
[A[ATraining Step: 91  | total loss: [1m[32m0.12959[0m[0m | time: 47.012s
[2K
| Adam | epoch: 013 | loss: 0.12959 - acc: 0.9542 | val_loss: 1.20130 - val_acc: 0.7031 -- iter: 202/202
--
Training Step: 92  | total loss: [1m[32m0.12361[0m[0m | time: 7.690s
[2K
| Adam | epoch: 014 | loss: 0.12361 - acc: 0.9557 -- iter: 032/202
[A[ATraining Step: 93  | total loss: [1m[32m0.11593[0m[0m | time: 15.262s
[2K
| Adam | epoch: 014 | loss: 0.11593 - acc: 0.9570 -- iter: 064/202
[A[ATraining Step: 94  | total loss: [1m[32m0.11639[0m[0m | time: 22.851s
[2K
| Adam | epoch: 014 | loss: 0.11639 - acc: 0.9550 -- iter: 096/202
[A[ATraining Step: 95  | total loss: [1m[32m0.13776[0m[0m | time: 25.930s
[2K
| Adam | epoch: 014 | loss: 0.13776 - acc: 0.9501 -- iter: 128/202
[A[ATraining Step: 96  | total loss: [1m[32m0.12882[0m[0m | time: 29.026s
[2K
| Adam | epoch: 014 | loss: 0.12882 - acc: 0.9551 -- iter: 160/202
[A[ATraining Step: 97  | total loss: [1m[32m0.11960[0m[0m | time: 36.718s
[2K
| Adam | epoch: 014 | loss: 0.11960 - acc: 0.9596 -- iter: 192/202
[A[ATraining Step: 98  | total loss: [1m[32m0.13558[0m[0m | time: 47.208s
[2K
| Adam | epoch: 014 | loss: 0.13558 - acc: 0.9574 | val_loss: 1.03862 - val_acc: 0.6875 -- iter: 202/202
--
Training Step: 99  | total loss: [1m[32m0.14747[0m[0m | time: 7.777s
[2K
| Adam | epoch: 015 | loss: 0.14747 - acc: 0.9554 -- iter: 032/202
[A[ATraining Step: 100  | total loss: [1m[32m0.14683[0m[0m | time: 15.355s
[2K
| Adam | epoch: 015 | loss: 0.14683 - acc: 0.9567 -- iter: 064/202
[A[ATraining Step: 101  | total loss: [1m[32m0.14102[0m[0m | time: 23.009s
[2K
| Adam | epoch: 015 | loss: 0.14102 - acc: 0.9611 -- iter: 096/202
[A[ATraining Step: 102  | total loss: [1m[32m0.14395[0m[0m | time: 30.757s
[2K
| Adam | epoch: 015 | loss: 0.14395 - acc: 0.9587 -- iter: 128/202
[A[ATraining Step: 103  | total loss: [1m[32m0.14279[0m[0m | time: 33.868s
[2K
| Adam | epoch: 015 | loss: 0.14279 - acc: 0.9566 -- iter: 160/202
[A[ATraining Step: 104  | total loss: [1m[32m0.14955[0m[0m | time: 36.967s
[2K
| Adam | epoch: 015 | loss: 0.14955 - acc: 0.9509 -- iter: 192/202
[A[ATraining Step: 105  | total loss: [1m[32m0.13644[0m[0m | time: 47.455s
[2K
| Adam | epoch: 015 | loss: 0.13644 - acc: 0.9558 | val_loss: 3.35171 - val_acc: 0.5625 -- iter: 202/202
--
Training Step: 106  | total loss: [1m[32m0.14564[0m[0m | time: 7.618s
[2K
| Adam | epoch: 016 | loss: 0.14564 - acc: 0.9540 -- iter: 032/202
[A[ATraining Step: 107  | total loss: [1m[32m0.13977[0m[0m | time: 15.353s
[2K
| Adam | epoch: 016 | loss: 0.13977 - acc: 0.9555 -- iter: 064/202
[A[ATraining Step: 108  | total loss: [1m[32m0.14379[0m[0m | time: 23.212s
[2K
| Adam | epoch: 016 | loss: 0.14379 - acc: 0.9506 -- iter: 096/202
[A[ATraining Step: 109  | total loss: [1m[32m0.16656[0m[0m | time: 30.957s
[2K
| Adam | epoch: 016 | loss: 0.16656 - acc: 0.9461 -- iter: 128/202
[A[ATraining Step: 110  | total loss: [1m[32m0.15837[0m[0m | time: 38.686s
[2K
| Adam | epoch: 016 | loss: 0.15837 - acc: 0.9515 -- iter: 160/202
[A[ATraining Step: 111  | total loss: [1m[32m0.15044[0m[0m | time: 41.810s
[2K
| Adam | epoch: 016 | loss: 0.15044 - acc: 0.9532 -- iter: 192/202
[A[ATraining Step: 112  | total loss: [1m[32m0.24131[0m[0m | time: 47.696s
[2K
| Adam | epoch: 016 | loss: 0.24131 - acc: 0.9479 | val_loss: 1.18356 - val_acc: 0.5938 -- iter: 202/202
--
Training Step: 113  | total loss: [1m[32m0.24123[0m[0m | time: 7.773s
[2K
| Adam | epoch: 017 | loss: 0.24123 - acc: 0.9431 -- iter: 032/202
[A[ATraining Step: 114  | total loss: [1m[32m0.23416[0m[0m | time: 15.595s
[2K
| Adam | epoch: 017 | loss: 0.23416 - acc: 0.9363 -- iter: 064/202
[A[ATraining Step: 115  | total loss: [1m[32m0.24786[0m[0m | time: 23.090s
[2K
| Adam | epoch: 017 | loss: 0.24786 - acc: 0.9302 -- iter: 096/202
[A[ATraining Step: 116  | total loss: [1m[32m0.23372[0m[0m | time: 30.935s
[2K
| Adam | epoch: 017 | loss: 0.23372 - acc: 0.9340 -- iter: 128/202
[A[ATraining Step: 117  | total loss: [1m[32m0.27054[0m[0m | time: 38.626s
[2K
| Adam | epoch: 017 | loss: 0.27054 - acc: 0.9188 -- iter: 160/202
[A[ATraining Step: 118  | total loss: [1m[32m0.26459[0m[0m | time: 46.444s
[2K
| Adam | epoch: 017 | loss: 0.26459 - acc: 0.9206 -- iter: 192/202
[A[ATraining Step: 119  | total loss: [1m[32m0.24768[0m[0m | time: 52.297s
[2K
| Adam | epoch: 017 | loss: 0.24768 - acc: 0.9254 | val_loss: 2.41066 - val_acc: 0.5625 -- iter: 202/202
--
Training Step: 120  | total loss: [1m[32m0.24294[0m[0m | time: 3.065s
[2K
| Adam | epoch: 018 | loss: 0.24294 - acc: 0.9229 -- iter: 032/202
[A[ATraining Step: 121  | total loss: [1m[32m0.22248[0m[0m | time: 10.694s
[2K
| Adam | epoch: 018 | loss: 0.22248 - acc: 0.9306 -- iter: 064/202
[A[ATraining Step: 122  | total loss: [1m[32m0.21032[0m[0m | time: 18.362s
[2K
| Adam | epoch: 018 | loss: 0.21032 - acc: 0.9344 -- iter: 096/202
[A[ATraining Step: 123  | total loss: [1m[32m0.19635[0m[0m | time: 26.020s
[2K
| Adam | epoch: 018 | loss: 0.19635 - acc: 0.9410 -- iter: 128/202
[A[ATraining Step: 124  | total loss: [1m[32m0.19902[0m[0m | time: 33.630s
[2K
| Adam | epoch: 018 | loss: 0.19902 - acc: 0.9344 -- iter: 160/202
[A[ATraining Step: 125  | total loss: [1m[32m0.21449[0m[0m | time: 41.345s
[2K
| Adam | epoch: 018 | loss: 0.21449 - acc: 0.9253 -- iter: 192/202
[A[ATraining Step: 126  | total loss: [1m[32m0.24489[0m[0m | time: 51.785s
[2K
| Adam | epoch: 018 | loss: 0.24489 - acc: 0.9203 | val_loss: 1.84296 - val_acc: 0.5938 -- iter: 202/202
--
Training Step: 127  | total loss: [1m[32m0.22882[0m[0m | time: 3.085s
[2K
| Adam | epoch: 019 | loss: 0.22882 - acc: 0.9251 -- iter: 032/202
[A[ATraining Step: 128  | total loss: [1m[32m0.20821[0m[0m | time: 6.642s
[2K
| Adam | epoch: 019 | loss: 0.20821 - acc: 0.9326 -- iter: 064/202
[A[ATraining Step: 129  | total loss: [1m[32m0.18865[0m[0m | time: 16.444s
[2K
| Adam | epoch: 019 | loss: 0.18865 - acc: 0.9394 -- iter: 096/202
[A[ATraining Step: 130  | total loss: [1m[32m0.19137[0m[0m | time: 25.894s
[2K
| Adam | epoch: 019 | loss: 0.19137 - acc: 0.9423 -- iter: 128/202
[A[ATraining Step: 131  | total loss: [1m[32m0.18566[0m[0m | time: 35.844s
[2K
| Adam | epoch: 019 | loss: 0.18566 - acc: 0.9418 -- iter: 160/202
[A[ATraining Step: 132  | total loss: [1m[32m0.17839[0m[0m | time: 45.442s
[2K
| Adam | epoch: 019 | loss: 0.17839 - acc: 0.9445 -- iter: 192/202
[A[ATraining Step: 133  | total loss: [1m[32m0.17984[0m[0m | time: 58.620s
[2K
| Adam | epoch: 019 | loss: 0.17984 - acc: 0.9438 | val_loss: 1.40883 - val_acc: 0.5781 -- iter: 202/202
--
Training Step: 134  | total loss: [1m[32m0.16952[0m[0m | time: 9.887s
[2K
| Adam | epoch: 020 | loss: 0.16952 - acc: 0.9463 -- iter: 032/202
[A[ATraining Step: 135  | total loss: [1m[32m0.16108[0m[0m | time: 13.830s
[2K
| Adam | epoch: 020 | loss: 0.16108 - acc: 0.9485 -- iter: 064/202
[A[ATraining Step: 136  | total loss: [1m[32m0.15529[0m[0m | time: 17.674s
[2K
| Adam | epoch: 020 | loss: 0.15529 - acc: 0.9437 -- iter: 096/202
[A[ATraining Step: 137  | total loss: [1m[32m0.14274[0m[0m | time: 27.415s
[2K
| Adam | epoch: 020 | loss: 0.14274 - acc: 0.9493 -- iter: 128/202
[A[ATraining Step: 138  | total loss: [1m[32m0.13362[0m[0m | time: 37.375s
[2K
| Adam | epoch: 020 | loss: 0.13362 - acc: 0.9513 -- iter: 160/202
[A[ATraining Step: 139  | total loss: [1m[32m0.14904[0m[0m | time: 47.064s
[2K
| Adam | epoch: 020 | loss: 0.14904 - acc: 0.9436 -- iter: 192/202
[A[ATraining Step: 140  | total loss: [1m[32m0.15083[0m[0m | time: 60.275s
[2K
| Adam | epoch: 020 | loss: 0.15083 - acc: 0.9462 | val_loss: 1.30886 - val_acc: 0.7344 -- iter: 202/202
--
Training Step: 141  | total loss: [1m[32m0.15444[0m[0m | time: 9.413s
[2K
| Adam | epoch: 021 | loss: 0.15444 - acc: 0.9422 -- iter: 032/202
[A[ATraining Step: 142  | total loss: [1m[32m0.14550[0m[0m | time: 19.546s
[2K
| Adam | epoch: 021 | loss: 0.14550 - acc: 0.9448 -- iter: 064/202
[A[ATraining Step: 143  | total loss: [1m[32m0.13350[0m[0m | time: 23.847s
[2K
| Adam | epoch: 021 | loss: 0.13350 - acc: 0.9503 -- iter: 096/202
[A[ATraining Step: 144  | total loss: [1m[32m0.12301[0m[0m | time: 27.689s
[2K
| Adam | epoch: 021 | loss: 0.12301 - acc: 0.9553 -- iter: 128/202
[A[ATraining Step: 145  | total loss: [1m[32m0.11406[0m[0m | time: 37.612s
[2K
| Adam | epoch: 021 | loss: 0.11406 - acc: 0.9598 -- iter: 160/202
[A[ATraining Step: 146  | total loss: [1m[32m0.10926[0m[0m | time: 46.968s
[2K
| Adam | epoch: 021 | loss: 0.10926 - acc: 0.9607 -- iter: 192/202
[A[ATraining Step: 147  | total loss: [1m[32m0.10097[0m[0m | time: 60.341s
[2K
| Adam | epoch: 021 | loss: 0.10097 - acc: 0.9646 | val_loss: 1.98815 - val_acc: 0.6406 -- iter: 202/202
--
Training Step: 148  | total loss: [1m[32m0.09633[0m[0m | time: 9.818s
[2K
| Adam | epoch: 022 | loss: 0.09633 - acc: 0.9681 -- iter: 032/202
[A[ATraining Step: 149  | total loss: [1m[32m0.10246[0m[0m | time: 19.319s
[2K
| Adam | epoch: 022 | loss: 0.10246 - acc: 0.9651 -- iter: 064/202
[A[ATraining Step: 150  | total loss: [1m[32m0.11261[0m[0m | time: 29.194s
[2K
| Adam | epoch: 022 | loss: 0.11261 - acc: 0.9654 -- iter: 096/202
[A[ATraining Step: 151  | total loss: [1m[32m0.10302[0m[0m | time: 33.082s
[2K
| Adam | epoch: 022 | loss: 0.10302 - acc: 0.9689 -- iter: 128/202
[A[ATraining Step: 152  | total loss: [1m[32m0.09592[0m[0m | time: 36.972s
[2K
| Adam | epoch: 022 | loss: 0.09592 - acc: 0.9720 -- iter: 160/202
[A[ATraining Step: 153  | total loss: [1m[32m0.08847[0m[0m | time: 46.445s
[2K
| Adam | epoch: 022 | loss: 0.08847 - acc: 0.9748 -- iter: 192/202
[A[ATraining Step: 154  | total loss: [1m[32m0.08806[0m[0m | time: 60.370s
[2K
| Adam | epoch: 022 | loss: 0.08806 - acc: 0.9711 | val_loss: 2.20761 - val_acc: 0.6562 -- iter: 202/202
--
Training Step: 155  | total loss: [1m[32m0.08461[0m[0m | time: 9.712s
[2K
| Adam | epoch: 023 | loss: 0.08461 - acc: 0.9708 -- iter: 032/202
[A[ATraining Step: 156  | total loss: [1m[32m0.07697[0m[0m | time: 19.811s
[2K
| Adam | epoch: 023 | loss: 0.07697 - acc: 0.9738 -- iter: 064/202
[A[ATraining Step: 157  | total loss: [1m[32m0.07083[0m[0m | time: 29.810s
[2K
| Adam | epoch: 023 | loss: 0.07083 - acc: 0.9764 -- iter: 096/202
[A[ATraining Step: 158  | total loss: [1m[32m0.07941[0m[0m | time: 39.282s
[2K
| Adam | epoch: 023 | loss: 0.07941 - acc: 0.9725 -- iter: 128/202
[A[ATraining Step: 159  | total loss: [1m[32m0.07879[0m[0m | time: 43.041s
[2K
| Adam | epoch: 023 | loss: 0.07879 - acc: 0.9690 -- iter: 160/202
[A[ATraining Step: 160  | total loss: [1m[32m0.16108[0m[0m | time: 47.361s
[2K
| Adam | epoch: 023 | loss: 0.16108 - acc: 0.9621 -- iter: 192/202
[A[ATraining Step: 161  | total loss: [1m[32m0.14899[0m[0m | time: 60.620s
[2K
| Adam | epoch: 023 | loss: 0.14899 - acc: 0.9659 | val_loss: 2.47502 - val_acc: 0.5781 -- iter: 202/202
--
Training Step: 162  | total loss: [1m[32m0.14068[0m[0m | time: 9.628s
[2K
| Adam | epoch: 024 | loss: 0.14068 - acc: 0.9630 -- iter: 032/202
[A[ATraining Step: 163  | total loss: [1m[32m0.13890[0m[0m | time: 19.799s
[2K
| Adam | epoch: 024 | loss: 0.13890 - acc: 0.9605 -- iter: 064/202
[A[ATraining Step: 164  | total loss: [1m[32m0.12658[0m[0m | time: 29.372s
[2K
| Adam | epoch: 024 | loss: 0.12658 - acc: 0.9644 -- iter: 096/202
[A[ATraining Step: 165  | total loss: [1m[32m0.11667[0m[0m | time: 39.652s
[2K
| Adam | epoch: 024 | loss: 0.11667 - acc: 0.9680 -- iter: 128/202
[A[ATraining Step: 166  | total loss: [1m[32m0.11651[0m[0m | time: 49.341s
[2K
| Adam | epoch: 024 | loss: 0.11651 - acc: 0.9650 -- iter: 160/202
[A[ATraining Step: 167  | total loss: [1m[32m0.12385[0m[0m | time: 53.303s
[2K
| Adam | epoch: 024 | loss: 0.12385 - acc: 0.9653 -- iter: 192/202
[A[ATraining Step: 168  | total loss: [1m[32m0.11354[0m[0m | time: 60.701s
[2K
| Adam | epoch: 024 | loss: 0.11354 - acc: 0.9688 | val_loss: 0.99057 - val_acc: 0.7500 -- iter: 202/202
--
Training Step: 169  | total loss: [1m[32m0.10347[0m[0m | time: 9.603s
[2K
| Adam | epoch: 025 | loss: 0.10347 - acc: 0.9719 -- iter: 032/202
[A[ATraining Step: 170  | total loss: [1m[32m0.09977[0m[0m | time: 18.971s
[2K
| Adam | epoch: 025 | loss: 0.09977 - acc: 0.9716 -- iter: 064/202
[A[ATraining Step: 171  | total loss: [1m[32m0.09182[0m[0m | time: 29.128s
[2K
| Adam | epoch: 025 | loss: 0.09182 - acc: 0.9744 -- iter: 096/202
[A[ATraining Step: 172  | total loss: [1m[32m0.08846[0m[0m | time: 38.648s
[2K
| Adam | epoch: 025 | loss: 0.08846 - acc: 0.9739 -- iter: 128/202
[A[ATraining Step: 173  | total loss: [1m[32m0.08662[0m[0m | time: 48.028s
[2K
| Adam | epoch: 025 | loss: 0.08662 - acc: 0.9734 -- iter: 160/202
[A[ATraining Step: 174  | total loss: [1m[32m0.08528[0m[0m | time: 58.258s
[2K
| Adam | epoch: 025 | loss: 0.08528 - acc: 0.9729 -- iter: 192/202
[A[ATraining Step: 175  | total loss: [1m[32m0.07945[0m[0m | time: 65.850s
[2K
| Adam | epoch: 025 | loss: 0.07945 - acc: 0.9756 | val_loss: 1.51741 - val_acc: 0.6719 -- iter: 202/202
--
Training Step: 176  | total loss: [1m[32m0.12527[0m[0m | time: 3.847s
[2K
| Adam | epoch: 026 | loss: 0.12527 - acc: 0.9580 -- iter: 032/202
[A[ATraining Step: 177  | total loss: [1m[32m0.11375[0m[0m | time: 13.246s
[2K
| Adam | epoch: 026 | loss: 0.11375 - acc: 0.9622 -- iter: 064/202
[A[ATraining Step: 178  | total loss: [1m[32m0.10877[0m[0m | time: 23.451s
[2K
| Adam | epoch: 026 | loss: 0.10877 - acc: 0.9629 -- iter: 096/202
[A[ATraining Step: 179  | total loss: [1m[32m0.10846[0m[0m | time: 33.041s
[2K
| Adam | epoch: 026 | loss: 0.10846 - acc: 0.9635 -- iter: 128/202
[A[ATraining Step: 180  | total loss: [1m[32m0.10295[0m[0m | time: 42.951s
[2K
| Adam | epoch: 026 | loss: 0.10295 - acc: 0.9640 -- iter: 160/202
[A[ATraining Step: 181  | total loss: [1m[32m0.09532[0m[0m | time: 53.217s
[2K
| Adam | epoch: 026 | loss: 0.09532 - acc: 0.9676 -- iter: 192/202
[A[ATraining Step: 182  | total loss: [1m[32m0.09525[0m[0m | time: 66.645s
[2K
| Adam | epoch: 026 | loss: 0.09525 - acc: 0.9677 | val_loss: 0.93455 - val_acc: 0.7344 -- iter: 202/202
--
Training Step: 183  | total loss: [1m[32m0.08903[0m[0m | time: 3.912s
[2K
| Adam | epoch: 027 | loss: 0.08903 - acc: 0.9709 -- iter: 032/202
[A[ATraining Step: 184  | total loss: [1m[32m0.13277[0m[0m | time: 8.251s
[2K
| Adam | epoch: 027 | loss: 0.13277 - acc: 0.9639 -- iter: 064/202
[A[ATraining Step: 185  | total loss: [1m[32m0.12781[0m[0m | time: 18.125s
[2K
| Adam | epoch: 027 | loss: 0.12781 - acc: 0.9675 -- iter: 096/202
[A[ATraining Step: 186  | total loss: [1m[32m0.11622[0m[0m | time: 28.080s
[2K
| Adam | epoch: 027 | loss: 0.11622 - acc: 0.9707 -- iter: 128/202
[A[ATraining Step: 187  | total loss: [1m[32m0.10850[0m[0m | time: 38.702s
[2K
| Adam | epoch: 027 | loss: 0.10850 - acc: 0.9736 -- iter: 160/202
[A[ATraining Step: 188  | total loss: [1m[32m0.09922[0m[0m | time: 48.507s
[2K
| Adam | epoch: 027 | loss: 0.09922 - acc: 0.9763 -- iter: 192/202
[A[ATraining Step: 189  | total loss: [1m[32m0.09694[0m[0m | time: 62.101s
[2K
| Adam | epoch: 027 | loss: 0.09694 - acc: 0.9755 | val_loss: 1.19918 - val_acc: 0.6562 -- iter: 202/202
--
Training Step: 190  | total loss: [1m[32m0.09033[0m[0m | time: 10.412s
[2K
| Adam | epoch: 028 | loss: 0.09033 - acc: 0.9780 -- iter: 032/202
[A[ATraining Step: 191  | total loss: [1m[32m0.09295[0m[0m | time: 14.134s
[2K
| Adam | epoch: 028 | loss: 0.09295 - acc: 0.9771 -- iter: 064/202
[A[ATraining Step: 192  | total loss: [1m[32m0.12105[0m[0m | time: 18.075s
[2K
| Adam | epoch: 028 | loss: 0.12105 - acc: 0.9593 -- iter: 096/202
[A[ATraining Step: 193  | total loss: [1m[32m0.12005[0m[0m | time: 27.721s
[2K
| Adam | epoch: 028 | loss: 0.12005 - acc: 0.9634 -- iter: 128/202
[A[ATraining Step: 194  | total loss: [1m[32m0.11039[0m[0m | time: 38.333s
[2K
| Adam | epoch: 028 | loss: 0.11039 - acc: 0.9671 -- iter: 160/202
[A[ATraining Step: 195  | total loss: [1m[32m0.10848[0m[0m | time: 46.756s
[2K
| Adam | epoch: 028 | loss: 0.10848 - acc: 0.9641 -- iter: 192/202
[A[ATraining Step: 196  | total loss: [1m[32m0.11773[0m[0m | time: 57.339s
[2K
| Adam | epoch: 028 | loss: 0.11773 - acc: 0.9552 | val_loss: 0.85579 - val_acc: 0.7344 -- iter: 202/202
--
Training Step: 197  | total loss: [1m[32m0.10807[0m[0m | time: 7.761s
[2K
| Adam | epoch: 029 | loss: 0.10807 - acc: 0.9597 -- iter: 032/202
[A[ATraining Step: 198  | total loss: [1m[32m0.12293[0m[0m | time: 15.535s
[2K
| Adam | epoch: 029 | loss: 0.12293 - acc: 0.9606 -- iter: 064/202
[A[ATraining Step: 199  | total loss: [1m[32m0.11785[0m[0m | time: 18.527s
[2K
| Adam | epoch: 029 | loss: 0.11785 - acc: 0.9614 -- iter: 096/202
[A[ATraining Step: 200  | total loss: [1m[32m0.22648[0m[0m | time: 24.509s
[2K
| Adam | epoch: 029 | loss: 0.22648 - acc: 0.9553 | val_loss: 1.51141 - val_acc: 0.6406 -- iter: 128/202
--
Training Step: 201  | total loss: [1m[32m0.20666[0m[0m | time: 32.329s
[2K
| Adam | epoch: 029 | loss: 0.20666 - acc: 0.9597 -- iter: 160/202
[A[ATraining Step: 202  | total loss: [1m[32m0.20040[0m[0m | time: 40.060s
[2K
| Adam | epoch: 029 | loss: 0.20040 - acc: 0.9606 -- iter: 192/202
[A[ATraining Step: 203  | total loss: [1m[32m0.18685[0m[0m | time: 50.622s
[2K
| Adam | epoch: 029 | loss: 0.18685 - acc: 0.9615 | val_loss: 1.95474 - val_acc: 0.5938 -- iter: 202/202
--
Training Step: 204  | total loss: [1m[32m0.16923[0m[0m | time: 7.587s
[2K
| Adam | epoch: 030 | loss: 0.16923 - acc: 0.9653 -- iter: 032/202
[A[ATraining Step: 205  | total loss: [1m[32m0.15624[0m[0m | time: 15.263s
[2K
| Adam | epoch: 030 | loss: 0.15624 - acc: 0.9657 -- iter: 064/202
[A[ATraining Step: 206  | total loss: [1m[32m0.14677[0m[0m | time: 22.957s
[2K
| Adam | epoch: 030 | loss: 0.14677 - acc: 0.9660 -- iter: 096/202
[A[ATraining Step: 207  | total loss: [1m[32m0.13707[0m[0m | time: 26.059s
[2K
| Adam | epoch: 030 | loss: 0.13707 - acc: 0.9694 -- iter: 128/202
[A[ATraining Step: 208  | total loss: [1m[32m0.16463[0m[0m | time: 29.063s
[2K
| Adam | epoch: 030 | loss: 0.16463 - acc: 0.9624 -- iter: 160/202
[A[ATraining Step: 209  | total loss: [1m[32m0.15250[0m[0m | time: 37.029s
[2K
| Adam | epoch: 030 | loss: 0.15250 - acc: 0.9662 -- iter: 192/202
[A[ATraining Step: 210  | total loss: [1m[32m0.14351[0m[0m | time: 47.425s
[2K
| Adam | epoch: 030 | loss: 0.14351 - acc: 0.9696 | val_loss: 0.89341 - val_acc: 0.6719 -- iter: 202/202
--
Validation AUC:0.7556207233626588
Validation AUPRC:0.7472866754846079
Test AUC:0.7947947947947949
Test AUPRC:0.7821156685605994
BestTestF1Score	0.87	0.66	0.83	0.78	0.97	36	10	17	1	0.05
BestTestMCCScore	0.87	0.66	0.83	0.78	0.97	36	10	17	1	0.05
BestTestAccuracyScore	0.45	0.2	0.55	0.75	0.32	12	4	23	25	0.93
BestValidationF1Score	0.77	0.45	0.7	0.65	0.94	31	17	14	2	0.05
BestValidationMCC	0.77	0.45	0.7	0.65	0.94	31	17	14	2	0.05
BestValidationAccuracy	0.65	0.44	0.7	0.82	0.55	18	4	27	15	0.93
TestPredictions (Threshold:0.05)
CHEMBL2261077,TN,INACT,0.0	CHEMBL25915,TP,ACT,0.5199999809265137	CHEMBL3741904,TN,INACT,0.029999999329447746	CHEMBL3804959,TP,ACT,0.25999999046325684	CHEMBL3805986,TP,ACT,0.8299999833106995	CHEMBL1095254,FN,ACT,0.009999999776482582	CHEMBL1668626,TP,ACT,1.0	CHEMBL2029394,FP,INACT,0.7300000190734863	CHEMBL37281,TP,ACT,1.0	CHEMBL259019,TP,ACT,0.9599999785423279	CHEMBL470072,FP,INACT,0.10999999940395355	CHEMBL1077583,TP,ACT,0.38999998569488525	CHEMBL227343,FP,INACT,1.0	CHEMBL3805472,TP,ACT,0.9100000262260437	CHEMBL3804861,TP,ACT,0.5299999713897705	CHEMBL3805193,TP,ACT,0.9900000095367432	CHEMBL3355100,TP,ACT,0.7799999713897705	CHEMBL247189,TN,INACT,0.019999999552965164	CHEMBL495234,TN,INACT,0.0	CHEMBL226912,TP,ACT,0.9700000286102295	CHEMBL1077591,TP,ACT,0.5099999904632568	CHEMBL1099254,FP,INACT,0.949999988079071	CHEMBL1782881,TP,ACT,0.09000000357627869	CHEMBL1096255,TN,INACT,0.019999999552965164	CHEMBL3633454,TN,INACT,0.0	CHEMBL227290,TP,ACT,0.09000000357627869	CHEMBL526329,TN,INACT,0.029999999329447746	CHEMBL1235787,TP,ACT,0.10999999940395355	CHEMBL2024267,TP,ACT,0.5899999737739563	CHEMBL148482,FP,INACT,0.49000000953674316	CHEMBL85320,TP,ACT,0.46000000834465027	CHEMBL522903,TN,INACT,0.0	CHEMBL494522,FP,INACT,0.1599999964237213	CHEMBL390323,TP,ACT,0.7400000095367432	CHEMBL501326,TN,INACT,0.0	CHEMBL469483,TP,ACT,0.41999998688697815	CHEMBL313952,TN,INACT,0.0	CHEMBL1093247,TN,INACT,0.0	CHEMBL227347,TP,ACT,0.8600000143051147	CHEMBL1277810,TP,ACT,0.4000000059604645	CHEMBL3298947,TP,ACT,0.9800000190734863	CHEMBL572501,FP,INACT,0.9900000095367432	CHEMBL226863,TP,ACT,0.05999999865889549	CHEMBL2204945,TP,ACT,0.9200000166893005	CHEMBL2022235,TN,INACT,0.0	CHEMBL474325,TN,INACT,0.0	CHEMBL1782889,TP,ACT,0.23999999463558197	CHEMBL472906,TN,INACT,0.009999999776482582	CHEMBL227289,TP,ACT,0.10999999940395355	CHEMBL3355109,TP,ACT,1.0	CHEMBL3298945,TP,ACT,0.9800000190734863	CHEMBL2022227,FP,INACT,0.6200000047683716	CHEMBL1782888,TP,ACT,0.9900000095367432	CHEMBL260622,TP,ACT,0.9800000190734863	CHEMBL1077590,TP,ACT,0.17000000178813934	CHEMBL461004,TN,INACT,0.03999999910593033	CHEMBL3298942,TP,ACT,0.9800000190734863	CHEMBL3355105,TP,ACT,0.949999988079071	CHEMBL282364,TP,ACT,0.4300000071525574	CHEMBL1277718,FP,INACT,0.3700000047683716	CHEMBL502913,TN,INACT,0.0	CHEMBL3764432,TP,ACT,0.05000000074505806	CHEMBL574273,FP,INACT,0.9900000095367432	CHEMBL494976,TN,INACT,0.0	

