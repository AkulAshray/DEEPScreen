ImageNetInceptionV2 CHEMBL3869 RMSprop 0.0005 15 0 0 0.8 False True
Number of active compounds :	536
Number of inactive compounds :	536
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3869_RMSprop_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3869_RMSprop_0.0005_15_0.8/
---------------------------------
Training samples: 685
Validation samples: 215
--
Training Step: 1  | time: 197.189s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/685
[A[ATraining Step: 2  | total loss: [1m[32m0.63182[0m[0m | time: 445.328s
[2K
| RMSProp | epoch: 001 | loss: 0.63182 - acc: 0.5062 -- iter: 064/685
[A[ATraining Step: 3  | total loss: [1m[32m0.70215[0m[0m | time: 494.245s
[2K
| RMSProp | epoch: 001 | loss: 0.70215 - acc: 0.5011 -- iter: 096/685
[A[ATraining Step: 4  | total loss: [1m[32m0.67666[0m[0m | time: 521.528s
[2K
| RMSProp | epoch: 001 | loss: 0.67666 - acc: 0.5237 -- iter: 128/685
[A[ATraining Step: 5  | total loss: [1m[32m0.69655[0m[0m | time: 543.646s
[2K
| RMSProp | epoch: 001 | loss: 0.69655 - acc: 0.4857 -- iter: 160/685
[A[ATraining Step: 6  | total loss: [1m[32m0.72458[0m[0m | time: 572.800s
[2K
| RMSProp | epoch: 001 | loss: 0.72458 - acc: 0.3944 -- iter: 192/685
[A[ATraining Step: 7  | total loss: [1m[32m0.71399[0m[0m | time: 602.386s
[2K
| RMSProp | epoch: 001 | loss: 0.71399 - acc: 0.4390 -- iter: 224/685
[A[ATraining Step: 8  | total loss: [1m[32m0.72102[0m[0m | time: 628.100s
[2K
| RMSProp | epoch: 001 | loss: 0.72102 - acc: 0.4557 -- iter: 256/685
[A[ATraining Step: 9  | total loss: [1m[32m0.70851[0m[0m | time: 658.549s
[2K
| RMSProp | epoch: 001 | loss: 0.70851 - acc: 0.4957 -- iter: 288/685
[A[ATraining Step: 10  | total loss: [1m[32m0.70153[0m[0m | time: 692.832s
[2K
| RMSProp | epoch: 001 | loss: 0.70153 - acc: 0.4822 -- iter: 320/685
[A[ATraining Step: 11  | total loss: [1m[32m0.69553[0m[0m | time: 721.625s
[2K
| RMSProp | epoch: 001 | loss: 0.69553 - acc: 0.5203 -- iter: 352/685
[A[ATraining Step: 12  | total loss: [1m[32m0.69962[0m[0m | time: 754.152s
[2K
| RMSProp | epoch: 001 | loss: 0.69962 - acc: 0.4690 -- iter: 384/685
[A[ATraining Step: 13  | total loss: [1m[32m0.69643[0m[0m | time: 774.258s
[2K
| RMSProp | epoch: 001 | loss: 0.69643 - acc: 0.4823 -- iter: 416/685
[A[ATraining Step: 14  | total loss: [1m[32m0.69499[0m[0m | time: 789.747s
[2K
| RMSProp | epoch: 001 | loss: 0.69499 - acc: 0.4639 -- iter: 448/685
[A[ATraining Step: 15  | total loss: [1m[32m0.69405[0m[0m | time: 804.914s
[2K
| RMSProp | epoch: 001 | loss: 0.69405 - acc: 0.4781 -- iter: 480/685
[A[ATraining Step: 16  | total loss: [1m[32m0.68709[0m[0m | time: 826.580s
[2K
| RMSProp | epoch: 001 | loss: 0.68709 - acc: 0.5214 -- iter: 512/685
[A[ATraining Step: 17  | total loss: [1m[32m0.67908[0m[0m | time: 849.522s
[2K
| RMSProp | epoch: 001 | loss: 0.67908 - acc: 0.5587 -- iter: 544/685
[A[ATraining Step: 18  | total loss: [1m[32m0.68864[0m[0m | time: 872.123s
[2K
| RMSProp | epoch: 001 | loss: 0.68864 - acc: 0.5276 -- iter: 576/685
[A[ATraining Step: 19  | total loss: [1m[32m0.68780[0m[0m | time: 892.029s
[2K
| RMSProp | epoch: 001 | loss: 0.68780 - acc: 0.5288 -- iter: 608/685
[A[ATraining Step: 20  | total loss: [1m[32m0.69435[0m[0m | time: 911.380s
[2K
| RMSProp | epoch: 001 | loss: 0.69435 - acc: 0.5195 -- iter: 640/685
[A[ATraining Step: 21  | total loss: [1m[32m0.68923[0m[0m | time: 931.128s
[2K
| RMSProp | epoch: 001 | loss: 0.68923 - acc: 0.5329 -- iter: 672/685
[A[ATraining Step: 22  | total loss: [1m[32m0.68719[0m[0m | time: 977.593s
[2K
| RMSProp | epoch: 001 | loss: 0.68719 - acc: 0.5324 | val_loss: 0.70123 - val_acc: 0.4651 -- iter: 685/685
--
Training Step: 23  | total loss: [1m[32m0.69106[0m[0m | time: 7.134s
[2K
| RMSProp | epoch: 002 | loss: 0.69106 - acc: 0.5342 -- iter: 032/685
[A[ATraining Step: 24  | total loss: [1m[32m0.68826[0m[0m | time: 21.399s
[2K
| RMSProp | epoch: 002 | loss: 0.68826 - acc: 0.5354 -- iter: 064/685
[A[ATraining Step: 25  | total loss: [1m[32m0.68458[0m[0m | time: 35.915s
[2K
| RMSProp | epoch: 002 | loss: 0.68458 - acc: 0.5428 -- iter: 096/685
[A[ATraining Step: 26  | total loss: [1m[32m0.68808[0m[0m | time: 53.530s
[2K
| RMSProp | epoch: 002 | loss: 0.68808 - acc: 0.5232 -- iter: 128/685
[A[ATraining Step: 27  | total loss: [1m[32m0.69237[0m[0m | time: 74.561s
[2K
| RMSProp | epoch: 002 | loss: 0.69237 - acc: 0.5172 -- iter: 160/685
[A[ATraining Step: 28  | total loss: [1m[32m0.68996[0m[0m | time: 94.591s
[2K
| RMSProp | epoch: 002 | loss: 0.68996 - acc: 0.5207 -- iter: 192/685
[A[ATraining Step: 29  | total loss: [1m[32m0.69276[0m[0m | time: 109.897s
[2K
| RMSProp | epoch: 002 | loss: 0.69276 - acc: 0.4929 -- iter: 224/685
[A[ATraining Step: 30  | total loss: [1m[32m0.68989[0m[0m | time: 126.051s
[2K
| RMSProp | epoch: 002 | loss: 0.68989 - acc: 0.5168 -- iter: 256/685
[A[ATraining Step: 31  | total loss: [1m[32m0.68014[0m[0m | time: 145.901s
[2K
| RMSProp | epoch: 002 | loss: 0.68014 - acc: 0.5345 -- iter: 288/685
[A[ATraining Step: 32  | total loss: [1m[32m0.68117[0m[0m | time: 166.202s
[2K
| RMSProp | epoch: 002 | loss: 0.68117 - acc: 0.5268 -- iter: 320/685
[A[ATraining Step: 33  | total loss: [1m[32m0.68684[0m[0m | time: 186.163s
[2K
| RMSProp | epoch: 002 | loss: 0.68684 - acc: 0.5277 -- iter: 352/685
[A[ATraining Step: 34  | total loss: [1m[32m0.69585[0m[0m | time: 206.574s
[2K
| RMSProp | epoch: 002 | loss: 0.69585 - acc: 0.5084 -- iter: 384/685
[A[ATraining Step: 35  | total loss: [1m[32m0.68538[0m[0m | time: 226.027s
[2K
| RMSProp | epoch: 002 | loss: 0.68538 - acc: 0.5459 -- iter: 416/685
[A[ATraining Step: 36  | total loss: [1m[32m0.68211[0m[0m | time: 246.619s
[2K
| RMSProp | epoch: 002 | loss: 0.68211 - acc: 0.5429 -- iter: 448/685
[A[ATraining Step: 37  | total loss: [1m[32m0.67862[0m[0m | time: 266.228s
[2K
| RMSProp | epoch: 002 | loss: 0.67862 - acc: 0.5531 -- iter: 480/685
[A[ATraining Step: 38  | total loss: [1m[32m0.68423[0m[0m | time: 283.206s
[2K
| RMSProp | epoch: 002 | loss: 0.68423 - acc: 0.5366 -- iter: 512/685
[A[ATraining Step: 39  | total loss: [1m[32m0.67956[0m[0m | time: 298.588s
[2K
| RMSProp | epoch: 002 | loss: 0.67956 - acc: 0.5715 -- iter: 544/685
[A[ATraining Step: 40  | total loss: [1m[32m0.68767[0m[0m | time: 327.945s
[2K
| RMSProp | epoch: 002 | loss: 0.68767 - acc: 0.5405 -- iter: 576/685
[A[ATraining Step: 41  | total loss: [1m[32m0.68630[0m[0m | time: 349.568s
[2K
| RMSProp | epoch: 002 | loss: 0.68630 - acc: 0.5560 -- iter: 608/685
[A[ATraining Step: 42  | total loss: [1m[32m0.68043[0m[0m | time: 373.602s
[2K
| RMSProp | epoch: 002 | loss: 0.68043 - acc: 0.5853 -- iter: 640/685
[A[ATraining Step: 43  | total loss: [1m[32m0.67113[0m[0m | time: 397.232s
[2K
| RMSProp | epoch: 002 | loss: 0.67113 - acc: 0.6144 -- iter: 672/685
[A[ATraining Step: 44  | total loss: [1m[32m0.66895[0m[0m | time: 443.113s
[2K
| RMSProp | epoch: 002 | loss: 0.66895 - acc: 0.6054 | val_loss: 0.68884 - val_acc: 0.5116 -- iter: 685/685
--
Training Step: 45  | total loss: [1m[32m0.67090[0m[0m | time: 7.639s
[2K
| RMSProp | epoch: 003 | loss: 0.67090 - acc: 0.6034 -- iter: 032/685
[A[ATraining Step: 46  | total loss: [1m[32m0.66798[0m[0m | time: 15.962s
[2K
| RMSProp | epoch: 003 | loss: 0.66798 - acc: 0.6054 -- iter: 064/685
[A[ATraining Step: 47  | total loss: [1m[32m0.64572[0m[0m | time: 32.242s
[2K
| RMSProp | epoch: 003 | loss: 0.64572 - acc: 0.6574 -- iter: 096/685
[A[ATraining Step: 48  | total loss: [1m[32m0.64342[0m[0m | time: 46.831s
[2K
| RMSProp | epoch: 003 | loss: 0.64342 - acc: 0.6673 -- iter: 128/685
[A[ATraining Step: 49  | total loss: [1m[32m0.64263[0m[0m | time: 62.122s
[2K
| RMSProp | epoch: 003 | loss: 0.64263 - acc: 0.6754 -- iter: 160/685
[A[ATraining Step: 50  | total loss: [1m[32m0.64431[0m[0m | time: 81.980s
[2K
| RMSProp | epoch: 003 | loss: 0.64431 - acc: 0.6627 -- iter: 192/685
[A[ATraining Step: 51  | total loss: [1m[32m0.64598[0m[0m | time: 101.829s
[2K
| RMSProp | epoch: 003 | loss: 0.64598 - acc: 0.6665 -- iter: 224/685
[A[ATraining Step: 52  | total loss: [1m[32m0.65347[0m[0m | time: 122.777s
[2K
| RMSProp | epoch: 003 | loss: 0.65347 - acc: 0.6462 -- iter: 256/685
[A[ATraining Step: 53  | total loss: [1m[32m0.65747[0m[0m | time: 143.227s
[2K
| RMSProp | epoch: 003 | loss: 0.65747 - acc: 0.6339 -- iter: 288/685
[A[ATraining Step: 54  | total loss: [1m[32m0.65149[0m[0m | time: 162.234s
[2K
| RMSProp | epoch: 003 | loss: 0.65149 - acc: 0.6462 -- iter: 320/685
[A[ATraining Step: 55  | total loss: [1m[32m0.66443[0m[0m | time: 177.192s
[2K
| RMSProp | epoch: 003 | loss: 0.66443 - acc: 0.6253 -- iter: 352/685
[A[ATraining Step: 56  | total loss: [1m[32m0.66578[0m[0m | time: 192.310s
[2K
| RMSProp | epoch: 003 | loss: 0.66578 - acc: 0.6384 -- iter: 384/685
[A[ATraining Step: 57  | total loss: [1m[32m0.66822[0m[0m | time: 209.960s
[2K
| RMSProp | epoch: 003 | loss: 0.66822 - acc: 0.6236 -- iter: 416/685
[A[ATraining Step: 58  | total loss: [1m[32m0.66608[0m[0m | time: 230.550s
[2K
| RMSProp | epoch: 003 | loss: 0.66608 - acc: 0.6195 -- iter: 448/685
[A[ATraining Step: 59  | total loss: [1m[32m0.66517[0m[0m | time: 251.006s
[2K
| RMSProp | epoch: 003 | loss: 0.66517 - acc: 0.6119 -- iter: 480/685
[A[ATraining Step: 60  | total loss: [1m[32m0.66263[0m[0m | time: 271.206s
[2K
| RMSProp | epoch: 003 | loss: 0.66263 - acc: 0.6219 -- iter: 512/685
[A[ATraining Step: 61  | total loss: [1m[32m0.65717[0m[0m | time: 290.999s
[2K
| RMSProp | epoch: 003 | loss: 0.65717 - acc: 0.6386 -- iter: 544/685
[A[ATraining Step: 62  | total loss: [1m[32m0.65194[0m[0m | time: 311.172s
[2K
| RMSProp | epoch: 003 | loss: 0.65194 - acc: 0.6368 -- iter: 576/685
[A[ATraining Step: 63  | total loss: [1m[32m0.66305[0m[0m | time: 331.013s
[2K
| RMSProp | epoch: 003 | loss: 0.66305 - acc: 0.6116 -- iter: 608/685
[A[ATraining Step: 64  | total loss: [1m[32m0.66416[0m[0m | time: 350.081s
[2K
| RMSProp | epoch: 003 | loss: 0.66416 - acc: 0.6133 -- iter: 640/685
[A[ATraining Step: 65  | total loss: [1m[32m0.66062[0m[0m | time: 365.180s
[2K
| RMSProp | epoch: 003 | loss: 0.66062 - acc: 0.6263 -- iter: 672/685
[A[ATraining Step: 66  | total loss: [1m[32m0.65726[0m[0m | time: 406.334s
[2K
| RMSProp | epoch: 003 | loss: 0.65726 - acc: 0.6185 | val_loss: 0.69880 - val_acc: 0.4791 -- iter: 685/685
--
Training Step: 67  | total loss: [1m[32m0.65433[0m[0m | time: 20.183s
[2K
| RMSProp | epoch: 004 | loss: 0.65433 - acc: 0.6380 -- iter: 032/685
[A[ATraining Step: 68  | total loss: [1m[32m0.65047[0m[0m | time: 30.059s
[2K
| RMSProp | epoch: 004 | loss: 0.65047 - acc: 0.6365 -- iter: 064/685
[A[ATraining Step: 69  | total loss: [1m[32m0.65440[0m[0m | time: 40.534s
[2K
| RMSProp | epoch: 004 | loss: 0.65440 - acc: 0.6250 -- iter: 096/685
[A[ATraining Step: 70  | total loss: [1m[32m0.63953[0m[0m | time: 60.298s
[2K
| RMSProp | epoch: 004 | loss: 0.63953 - acc: 0.6505 -- iter: 128/685
[A[ATraining Step: 71  | total loss: [1m[32m0.64299[0m[0m | time: 80.100s
[2K
| RMSProp | epoch: 004 | loss: 0.64299 - acc: 0.6370 -- iter: 160/685
[A[ATraining Step: 72  | total loss: [1m[32m0.63792[0m[0m | time: 90.892s
[2K
| RMSProp | epoch: 004 | loss: 0.63792 - acc: 0.6497 -- iter: 192/685
[A[ATraining Step: 73  | total loss: [1m[32m0.64068[0m[0m | time: 100.475s
[2K
| RMSProp | epoch: 004 | loss: 0.64068 - acc: 0.6365 -- iter: 224/685
[A[ATraining Step: 74  | total loss: [1m[32m0.63977[0m[0m | time: 111.975s
[2K
| RMSProp | epoch: 004 | loss: 0.63977 - acc: 0.6353 -- iter: 256/685
[A[ATraining Step: 75  | total loss: [1m[32m0.63437[0m[0m | time: 128.486s
[2K
| RMSProp | epoch: 004 | loss: 0.63437 - acc: 0.6443 -- iter: 288/685
[A[ATraining Step: 76  | total loss: [1m[32m0.62436[0m[0m | time: 147.609s
[2K
| RMSProp | epoch: 004 | loss: 0.62436 - acc: 0.6556 -- iter: 320/685
[A[ATraining Step: 77  | total loss: [1m[32m0.64011[0m[0m | time: 166.373s
[2K
| RMSProp | epoch: 004 | loss: 0.64011 - acc: 0.6325 -- iter: 352/685
[A[ATraining Step: 78  | total loss: [1m[32m0.63798[0m[0m | time: 186.194s
[2K
| RMSProp | epoch: 004 | loss: 0.63798 - acc: 0.6350 -- iter: 384/685
[A[ATraining Step: 79  | total loss: [1m[32m0.64032[0m[0m | time: 206.431s
[2K
| RMSProp | epoch: 004 | loss: 0.64032 - acc: 0.6340 -- iter: 416/685
[A[ATraining Step: 80  | total loss: [1m[32m0.63459[0m[0m | time: 226.144s
[2K
| RMSProp | epoch: 004 | loss: 0.63459 - acc: 0.6331 -- iter: 448/685
[A[ATraining Step: 81  | total loss: [1m[32m0.64349[0m[0m | time: 246.161s
[2K
| RMSProp | epoch: 004 | loss: 0.64349 - acc: 0.6133 -- iter: 480/685
[A[ATraining Step: 82  | total loss: [1m[32m0.64539[0m[0m | time: 261.716s
[2K
| RMSProp | epoch: 004 | loss: 0.64539 - acc: 0.6113 -- iter: 512/685
[A[ATraining Step: 83  | total loss: [1m[32m0.64294[0m[0m | time: 276.726s
[2K
| RMSProp | epoch: 004 | loss: 0.64294 - acc: 0.6096 -- iter: 544/685
[A[ATraining Step: 84  | total loss: [1m[32m0.64275[0m[0m | time: 308.307s
[2K
| RMSProp | epoch: 004 | loss: 0.64275 - acc: 0.6080 -- iter: 576/685
[A[ATraining Step: 85  | total loss: [1m[32m0.63552[0m[0m | time: 333.568s
[2K
| RMSProp | epoch: 004 | loss: 0.63552 - acc: 0.6191 -- iter: 608/685
[A[ATraining Step: 86  | total loss: [1m[32m0.62984[0m[0m | time: 358.203s
[2K
| RMSProp | epoch: 004 | loss: 0.62984 - acc: 0.6322 -- iter: 640/685
[A[ATraining Step: 87  | total loss: [1m[32m0.62216[0m[0m | time: 380.204s
[2K
| RMSProp | epoch: 004 | loss: 0.62216 - acc: 0.6439 -- iter: 672/685
[A[ATraining Step: 88  | total loss: [1m[32m0.62721[0m[0m | time: 428.204s
[2K
| RMSProp | epoch: 004 | loss: 0.62721 - acc: 0.6327 | val_loss: 0.65148 - val_acc: 0.6233 -- iter: 685/685
--
Training Step: 89  | total loss: [1m[32m0.64056[0m[0m | time: 18.664s
[2K
| RMSProp | epoch: 005 | loss: 0.64056 - acc: 0.6132 -- iter: 032/685
[A[ATraining Step: 90  | total loss: [1m[32m0.64939[0m[0m | time: 38.396s
[2K
| RMSProp | epoch: 005 | loss: 0.64939 - acc: 0.6081 -- iter: 064/685
[A[ATraining Step: 91  | total loss: [1m[32m0.63243[0m[0m | time: 49.362s
[2K
| RMSProp | epoch: 005 | loss: 0.63243 - acc: 0.6317 -- iter: 096/685
[A[ATraining Step: 92  | total loss: [1m[32m0.63555[0m[0m | time: 59.837s
[2K
| RMSProp | epoch: 005 | loss: 0.63555 - acc: 0.6300 -- iter: 128/685
[A[ATraining Step: 93  | total loss: [1m[32m0.60792[0m[0m | time: 79.799s
[2K
| RMSProp | epoch: 005 | loss: 0.60792 - acc: 0.6593 -- iter: 160/685
[A[ATraining Step: 94  | total loss: [1m[32m0.60737[0m[0m | time: 99.880s
[2K
| RMSProp | epoch: 005 | loss: 0.60737 - acc: 0.6559 -- iter: 192/685
[A[ATraining Step: 95  | total loss: [1m[32m0.59946[0m[0m | time: 120.457s
[2K
| RMSProp | epoch: 005 | loss: 0.59946 - acc: 0.6684 -- iter: 224/685
[A[ATraining Step: 96  | total loss: [1m[32m0.59644[0m[0m | time: 136.544s
[2K
| RMSProp | epoch: 005 | loss: 0.59644 - acc: 0.6703 -- iter: 256/685
[A[ATraining Step: 97  | total loss: [1m[32m0.60994[0m[0m | time: 148.252s
[2K
| RMSProp | epoch: 005 | loss: 0.60994 - acc: 0.6658 -- iter: 288/685
[A[ATraining Step: 98  | total loss: [1m[32m0.61328[0m[0m | time: 160.360s
[2K
| RMSProp | epoch: 005 | loss: 0.61328 - acc: 0.6649 -- iter: 320/685
[A[ATraining Step: 99  | total loss: [1m[32m0.60463[0m[0m | time: 176.482s
[2K
| RMSProp | epoch: 005 | loss: 0.60463 - acc: 0.6827 -- iter: 352/685
[A[ATraining Step: 100  | total loss: [1m[32m0.59858[0m[0m | time: 195.924s
[2K
| RMSProp | epoch: 005 | loss: 0.59858 - acc: 0.6926 -- iter: 384/685
[A[ATraining Step: 101  | total loss: [1m[32m0.60826[0m[0m | time: 214.912s
[2K
| RMSProp | epoch: 005 | loss: 0.60826 - acc: 0.6765 -- iter: 416/685
[A[ATraining Step: 102  | total loss: [1m[32m0.61977[0m[0m | time: 234.610s
[2K
| RMSProp | epoch: 005 | loss: 0.61977 - acc: 0.6744 -- iter: 448/685
[A[ATraining Step: 103  | total loss: [1m[32m0.62716[0m[0m | time: 254.641s
[2K
| RMSProp | epoch: 005 | loss: 0.62716 - acc: 0.6726 -- iter: 480/685
[A[ATraining Step: 104  | total loss: [1m[32m0.63296[0m[0m | time: 274.203s
[2K
| RMSProp | epoch: 005 | loss: 0.63296 - acc: 0.6647 -- iter: 512/685
[A[ATraining Step: 105  | total loss: [1m[32m0.62767[0m[0m | time: 293.508s
[2K
| RMSProp | epoch: 005 | loss: 0.62767 - acc: 0.6639 -- iter: 544/685
[A[ATraining Step: 106  | total loss: [1m[32m0.62238[0m[0m | time: 313.298s
[2K
| RMSProp | epoch: 005 | loss: 0.62238 - acc: 0.6600 -- iter: 576/685
[A[ATraining Step: 107  | total loss: [1m[32m0.61475[0m[0m | time: 328.494s
[2K
| RMSProp | epoch: 005 | loss: 0.61475 - acc: 0.6690 -- iter: 608/685
[A[ATraining Step: 108  | total loss: [1m[32m0.60104[0m[0m | time: 343.515s
[2K
| RMSProp | epoch: 005 | loss: 0.60104 - acc: 0.6833 -- iter: 640/685
[A[ATraining Step: 109  | total loss: [1m[32m0.58873[0m[0m | time: 365.932s
[2K
| RMSProp | epoch: 005 | loss: 0.58873 - acc: 0.6994 -- iter: 672/685
[A[ATraining Step: 110  | total loss: [1m[32m0.58002[0m[0m | time: 414.643s
[2K
| RMSProp | epoch: 005 | loss: 0.58002 - acc: 0.7044 | val_loss: 1.26529 - val_acc: 0.4651 -- iter: 685/685
--
Training Step: 111  | total loss: [1m[32m0.57652[0m[0m | time: 19.829s
[2K
| RMSProp | epoch: 006 | loss: 0.57652 - acc: 0.7059 -- iter: 032/685
[A[ATraining Step: 112  | total loss: [1m[32m0.57741[0m[0m | time: 39.058s
[2K
| RMSProp | epoch: 006 | loss: 0.57741 - acc: 0.7072 -- iter: 064/685
[A[ATraining Step: 113  | total loss: [1m[32m0.57278[0m[0m | time: 57.204s
[2K
| RMSProp | epoch: 006 | loss: 0.57278 - acc: 0.7052 -- iter: 096/685
[A[ATraining Step: 114  | total loss: [1m[32m0.56863[0m[0m | time: 64.497s
[2K
| RMSProp | epoch: 006 | loss: 0.56863 - acc: 0.7066 -- iter: 128/685
[A[ATraining Step: 115  | total loss: [1m[32m0.56808[0m[0m | time: 72.490s
[2K
| RMSProp | epoch: 006 | loss: 0.56808 - acc: 0.7128 -- iter: 160/685
[A[ATraining Step: 116  | total loss: [1m[32m0.52965[0m[0m | time: 88.920s
[2K
| RMSProp | epoch: 006 | loss: 0.52965 - acc: 0.7415 -- iter: 192/685
[A[ATraining Step: 117  | total loss: [1m[32m0.56065[0m[0m | time: 108.019s
[2K
| RMSProp | epoch: 006 | loss: 0.56065 - acc: 0.7205 -- iter: 224/685
[A[ATraining Step: 118  | total loss: [1m[32m0.55976[0m[0m | time: 127.802s
[2K
| RMSProp | epoch: 006 | loss: 0.55976 - acc: 0.7172 -- iter: 256/685
[A[ATraining Step: 119  | total loss: [1m[32m0.54644[0m[0m | time: 146.975s
[2K
| RMSProp | epoch: 006 | loss: 0.54644 - acc: 0.7267 -- iter: 288/685
[A[ATraining Step: 120  | total loss: [1m[32m0.56076[0m[0m | time: 167.512s
[2K
| RMSProp | epoch: 006 | loss: 0.56076 - acc: 0.7166 -- iter: 320/685
[A[ATraining Step: 121  | total loss: [1m[32m0.56396[0m[0m | time: 177.523s
[2K
| RMSProp | epoch: 006 | loss: 0.56396 - acc: 0.7137 -- iter: 352/685
[A[ATraining Step: 122  | total loss: [1m[32m0.57546[0m[0m | time: 191.163s
[2K
| RMSProp | epoch: 006 | loss: 0.57546 - acc: 0.7017 -- iter: 384/685
[A[ATraining Step: 123  | total loss: [1m[32m0.56283[0m[0m | time: 208.042s
[2K
| RMSProp | epoch: 006 | loss: 0.56283 - acc: 0.7034 -- iter: 416/685
[A[ATraining Step: 124  | total loss: [1m[32m0.57139[0m[0m | time: 227.430s
[2K
| RMSProp | epoch: 006 | loss: 0.57139 - acc: 0.6955 -- iter: 448/685
[A[ATraining Step: 125  | total loss: [1m[32m0.57288[0m[0m | time: 245.441s
[2K
| RMSProp | epoch: 006 | loss: 0.57288 - acc: 0.6885 -- iter: 480/685
[A[ATraining Step: 126  | total loss: [1m[32m0.56971[0m[0m | time: 259.829s
[2K
| RMSProp | epoch: 006 | loss: 0.56971 - acc: 0.6978 -- iter: 512/685
[A[ATraining Step: 127  | total loss: [1m[32m0.55779[0m[0m | time: 277.473s
[2K
| RMSProp | epoch: 006 | loss: 0.55779 - acc: 0.7061 -- iter: 544/685
[A[ATraining Step: 128  | total loss: [1m[32m0.58212[0m[0m | time: 296.343s
[2K
| RMSProp | epoch: 006 | loss: 0.58212 - acc: 0.6980 -- iter: 576/685
[A[ATraining Step: 129  | total loss: [1m[32m0.57505[0m[0m | time: 315.579s
[2K
| RMSProp | epoch: 006 | loss: 0.57505 - acc: 0.7063 -- iter: 608/685
[A[ATraining Step: 130  | total loss: [1m[32m0.56873[0m[0m | time: 334.817s
[2K
| RMSProp | epoch: 006 | loss: 0.56873 - acc: 0.7138 -- iter: 640/685
[A[ATraining Step: 131  | total loss: [1m[32m0.55653[0m[0m | time: 354.995s
[2K
| RMSProp | epoch: 006 | loss: 0.55653 - acc: 0.7174 -- iter: 672/685
[A[ATraining Step: 132  | total loss: [1m[32m0.53664[0m[0m | time: 400.058s
[2K
| RMSProp | epoch: 006 | loss: 0.53664 - acc: 0.7301 | val_loss: 0.95830 - val_acc: 0.6233 -- iter: 685/685
--
Training Step: 133  | total loss: [1m[32m0.51703[0m[0m | time: 14.465s
[2K
| RMSProp | epoch: 007 | loss: 0.51703 - acc: 0.7352 -- iter: 032/685
[A[ATraining Step: 134  | total loss: [1m[32m0.48884[0m[0m | time: 31.580s
[2K
| RMSProp | epoch: 007 | loss: 0.48884 - acc: 0.7523 -- iter: 064/685
[A[ATraining Step: 135  | total loss: [1m[32m0.49780[0m[0m | time: 48.146s
[2K
| RMSProp | epoch: 007 | loss: 0.49780 - acc: 0.7552 -- iter: 096/685
[A[ATraining Step: 136  | total loss: [1m[32m0.48192[0m[0m | time: 62.016s
[2K
| RMSProp | epoch: 007 | loss: 0.48192 - acc: 0.7578 -- iter: 128/685
[A[ATraining Step: 137  | total loss: [1m[32m0.47513[0m[0m | time: 68.807s
[2K
| RMSProp | epoch: 007 | loss: 0.47513 - acc: 0.7601 -- iter: 160/685
[A[ATraining Step: 138  | total loss: [1m[32m0.49077[0m[0m | time: 75.894s
[2K
| RMSProp | epoch: 007 | loss: 0.49077 - acc: 0.7457 -- iter: 192/685
[A[ATraining Step: 139  | total loss: [1m[32m0.45221[0m[0m | time: 89.492s
[2K
| RMSProp | epoch: 007 | loss: 0.45221 - acc: 0.7711 -- iter: 224/685
[A[ATraining Step: 140  | total loss: [1m[32m0.50757[0m[0m | time: 103.683s
[2K
| RMSProp | epoch: 007 | loss: 0.50757 - acc: 0.7409 -- iter: 256/685
[A[ATraining Step: 141  | total loss: [1m[32m0.53596[0m[0m | time: 117.604s
[2K
| RMSProp | epoch: 007 | loss: 0.53596 - acc: 0.7262 -- iter: 288/685
[A[ATraining Step: 142  | total loss: [1m[32m0.52182[0m[0m | time: 131.489s
[2K
| RMSProp | epoch: 007 | loss: 0.52182 - acc: 0.7410 -- iter: 320/685
[A[ATraining Step: 143  | total loss: [1m[32m0.51462[0m[0m | time: 144.741s
[2K
| RMSProp | epoch: 007 | loss: 0.51462 - acc: 0.7482 -- iter: 352/685
[A[ATraining Step: 144  | total loss: [1m[32m0.49340[0m[0m | time: 159.090s
[2K
| RMSProp | epoch: 007 | loss: 0.49340 - acc: 0.7609 -- iter: 384/685
[A[ATraining Step: 145  | total loss: [1m[32m0.50966[0m[0m | time: 171.084s
[2K
| RMSProp | epoch: 007 | loss: 0.50966 - acc: 0.7504 -- iter: 416/685
[A[ATraining Step: 146  | total loss: [1m[32m0.53123[0m[0m | time: 179.992s
[2K
| RMSProp | epoch: 007 | loss: 0.53123 - acc: 0.7410 -- iter: 448/685
[A[ATraining Step: 147  | total loss: [1m[32m0.53440[0m[0m | time: 188.876s
[2K
| RMSProp | epoch: 007 | loss: 0.53440 - acc: 0.7450 -- iter: 480/685
[A[ATraining Step: 148  | total loss: [1m[32m0.52413[0m[0m | time: 202.701s
[2K
| RMSProp | epoch: 007 | loss: 0.52413 - acc: 0.7455 -- iter: 512/685
[A[ATraining Step: 149  | total loss: [1m[32m0.53028[0m[0m | time: 216.263s
[2K
| RMSProp | epoch: 007 | loss: 0.53028 - acc: 0.7397 -- iter: 544/685
[A[ATraining Step: 150  | total loss: [1m[32m0.54792[0m[0m | time: 230.565s
[2K
| RMSProp | epoch: 007 | loss: 0.54792 - acc: 0.7220 -- iter: 576/685
[A[ATraining Step: 151  | total loss: [1m[32m0.57872[0m[0m | time: 244.505s
[2K
| RMSProp | epoch: 007 | loss: 0.57872 - acc: 0.7154 -- iter: 608/685
[A[ATraining Step: 152  | total loss: [1m[32m0.58605[0m[0m | time: 257.953s
[2K
| RMSProp | epoch: 007 | loss: 0.58605 - acc: 0.7032 -- iter: 640/685
[A[ATraining Step: 153  | total loss: [1m[32m0.57548[0m[0m | time: 271.748s
[2K
| RMSProp | epoch: 007 | loss: 0.57548 - acc: 0.7110 -- iter: 672/685
[A[ATraining Step: 154  | total loss: [1m[32m0.54734[0m[0m | time: 302.504s
[2K
| RMSProp | epoch: 007 | loss: 0.54734 - acc: 0.7243 | val_loss: 8.27704 - val_acc: 0.5349 -- iter: 685/685
--
Training Step: 155  | total loss: [1m[32m0.54396[0m[0m | time: 14.369s
[2K
| RMSProp | epoch: 008 | loss: 0.54396 - acc: 0.7238 -- iter: 032/685
[A[ATraining Step: 156  | total loss: [1m[32m0.52965[0m[0m | time: 28.171s
[2K
| RMSProp | epoch: 008 | loss: 0.52965 - acc: 0.7358 -- iter: 064/685
[A[ATraining Step: 157  | total loss: [1m[32m0.51572[0m[0m | time: 42.234s
[2K
| RMSProp | epoch: 008 | loss: 0.51572 - acc: 0.7434 -- iter: 096/685
[A[ATraining Step: 158  | total loss: [1m[32m0.50785[0m[0m | time: 56.278s
[2K
| RMSProp | epoch: 008 | loss: 0.50785 - acc: 0.7441 -- iter: 128/685
[A[ATraining Step: 159  | total loss: [1m[32m0.49900[0m[0m | time: 70.152s
[2K
| RMSProp | epoch: 008 | loss: 0.49900 - acc: 0.7509 -- iter: 160/685
[A[ATraining Step: 160  | total loss: [1m[32m0.48417[0m[0m | time: 78.101s
[2K
| RMSProp | epoch: 008 | loss: 0.48417 - acc: 0.7633 -- iter: 192/685
[A[ATraining Step: 161  | total loss: [1m[32m0.50401[0m[0m | time: 84.734s
[2K
| RMSProp | epoch: 008 | loss: 0.50401 - acc: 0.7562 -- iter: 224/685
[A[ATraining Step: 162  | total loss: [1m[32m0.50958[0m[0m | time: 99.456s
[2K
| RMSProp | epoch: 008 | loss: 0.50958 - acc: 0.7575 -- iter: 256/685
[A[ATraining Step: 163  | total loss: [1m[32m0.52068[0m[0m | time: 113.895s
[2K
| RMSProp | epoch: 008 | loss: 0.52068 - acc: 0.7505 -- iter: 288/685
[A[ATraining Step: 164  | total loss: [1m[32m0.50792[0m[0m | time: 127.949s
[2K
| RMSProp | epoch: 008 | loss: 0.50792 - acc: 0.7599 -- iter: 320/685
[A[ATraining Step: 165  | total loss: [1m[32m0.49362[0m[0m | time: 141.984s
[2K
| RMSProp | epoch: 008 | loss: 0.49362 - acc: 0.7651 -- iter: 352/685
[A[ATraining Step: 166  | total loss: [1m[32m0.50840[0m[0m | time: 156.245s
[2K
| RMSProp | epoch: 008 | loss: 0.50840 - acc: 0.7636 -- iter: 384/685
[A[ATraining Step: 167  | total loss: [1m[32m0.51032[0m[0m | time: 171.460s
[2K
| RMSProp | epoch: 008 | loss: 0.51032 - acc: 0.7622 -- iter: 416/685
[A[ATraining Step: 168  | total loss: [1m[32m0.51386[0m[0m | time: 186.502s
[2K
| RMSProp | epoch: 008 | loss: 0.51386 - acc: 0.7641 -- iter: 448/685
[A[ATraining Step: 169  | total loss: [1m[32m0.50917[0m[0m | time: 196.233s
[2K
| RMSProp | epoch: 008 | loss: 0.50917 - acc: 0.7565 -- iter: 480/685
[A[ATraining Step: 170  | total loss: [1m[32m0.48239[0m[0m | time: 205.462s
[2K
| RMSProp | epoch: 008 | loss: 0.48239 - acc: 0.7715 -- iter: 512/685
[A[ATraining Step: 171  | total loss: [1m[32m0.49562[0m[0m | time: 216.271s
[2K
| RMSProp | epoch: 008 | loss: 0.49562 - acc: 0.7756 -- iter: 544/685
[A[ATraining Step: 172  | total loss: [1m[32m0.50355[0m[0m | time: 230.984s
[2K
| RMSProp | epoch: 008 | loss: 0.50355 - acc: 0.7730 -- iter: 576/685
[A[ATraining Step: 173  | total loss: [1m[32m0.49917[0m[0m | time: 245.911s
[2K
| RMSProp | epoch: 008 | loss: 0.49917 - acc: 0.7707 -- iter: 608/685
[A[ATraining Step: 174  | total loss: [1m[32m0.51049[0m[0m | time: 259.979s
[2K
| RMSProp | epoch: 008 | loss: 0.51049 - acc: 0.7686 -- iter: 640/685
[A[ATraining Step: 175  | total loss: [1m[32m0.49940[0m[0m | time: 274.458s
[2K
| RMSProp | epoch: 008 | loss: 0.49940 - acc: 0.7730 -- iter: 672/685
[A[ATraining Step: 176  | total loss: [1m[32m0.48192[0m[0m | time: 305.773s
[2K
| RMSProp | epoch: 008 | loss: 0.48192 - acc: 0.7801 | val_loss: 2.41976 - val_acc: 0.5349 -- iter: 685/685
--
Training Step: 177  | total loss: [1m[32m0.47487[0m[0m | time: 14.812s
[2K
| RMSProp | epoch: 009 | loss: 0.47487 - acc: 0.7833 -- iter: 032/685
[A[ATraining Step: 178  | total loss: [1m[32m0.44898[0m[0m | time: 29.309s
[2K
| RMSProp | epoch: 009 | loss: 0.44898 - acc: 0.7925 -- iter: 064/685
[A[ATraining Step: 179  | total loss: [1m[32m0.42860[0m[0m | time: 44.038s
[2K
| RMSProp | epoch: 009 | loss: 0.42860 - acc: 0.8008 -- iter: 096/685
[A[ATraining Step: 180  | total loss: [1m[32m0.41672[0m[0m | time: 58.374s
[2K
| RMSProp | epoch: 009 | loss: 0.41672 - acc: 0.8051 -- iter: 128/685
[A[ATraining Step: 181  | total loss: [1m[32m0.45614[0m[0m | time: 72.369s
[2K
| RMSProp | epoch: 009 | loss: 0.45614 - acc: 0.7902 -- iter: 160/685
[A[ATraining Step: 182  | total loss: [1m[32m0.43675[0m[0m | time: 87.228s
[2K
| RMSProp | epoch: 009 | loss: 0.43675 - acc: 0.8049 -- iter: 192/685
[A[ATraining Step: 183  | total loss: [1m[32m0.41134[0m[0m | time: 94.800s
[2K
| RMSProp | epoch: 009 | loss: 0.41134 - acc: 0.8150 -- iter: 224/685
[A[ATraining Step: 184  | total loss: [1m[32m0.40393[0m[0m | time: 102.339s
[2K
| RMSProp | epoch: 009 | loss: 0.40393 - acc: 0.8182 -- iter: 256/685
[A[ATraining Step: 185  | total loss: [1m[32m0.38824[0m[0m | time: 116.711s
[2K
| RMSProp | epoch: 009 | loss: 0.38824 - acc: 0.8286 -- iter: 288/685
[A[ATraining Step: 186  | total loss: [1m[32m0.46642[0m[0m | time: 130.950s
[2K
| RMSProp | epoch: 009 | loss: 0.46642 - acc: 0.8083 -- iter: 320/685
[A[ATraining Step: 187  | total loss: [1m[32m0.45417[0m[0m | time: 145.307s
[2K
| RMSProp | epoch: 009 | loss: 0.45417 - acc: 0.8056 -- iter: 352/685
[A[ATraining Step: 188  | total loss: [1m[32m0.42642[0m[0m | time: 159.743s
[2K
| RMSProp | epoch: 009 | loss: 0.42642 - acc: 0.8188 -- iter: 384/685
[A[ATraining Step: 189  | total loss: [1m[32m0.41492[0m[0m | time: 174.028s
[2K
| RMSProp | epoch: 009 | loss: 0.41492 - acc: 0.8244 -- iter: 416/685
[A[ATraining Step: 190  | total loss: [1m[32m0.43168[0m[0m | time: 188.236s
[2K
| RMSProp | epoch: 009 | loss: 0.43168 - acc: 0.8170 -- iter: 448/685
[A[ATraining Step: 191  | total loss: [1m[32m0.41055[0m[0m | time: 202.271s
[2K
| RMSProp | epoch: 009 | loss: 0.41055 - acc: 0.8290 -- iter: 480/685
[A[ATraining Step: 192  | total loss: [1m[32m0.41575[0m[0m | time: 217.026s
[2K
| RMSProp | epoch: 009 | loss: 0.41575 - acc: 0.8274 -- iter: 512/685
[A[ATraining Step: 193  | total loss: [1m[32m0.41038[0m[0m | time: 226.832s
[2K
| RMSProp | epoch: 009 | loss: 0.41038 - acc: 0.8259 -- iter: 544/685
[A[ATraining Step: 194  | total loss: [1m[32m0.39463[0m[0m | time: 236.191s
[2K
| RMSProp | epoch: 009 | loss: 0.39463 - acc: 0.8339 -- iter: 576/685
[A[ATraining Step: 195  | total loss: [1m[32m0.37280[0m[0m | time: 247.803s
[2K
| RMSProp | epoch: 009 | loss: 0.37280 - acc: 0.8411 -- iter: 608/685
[A[ATraining Step: 196  | total loss: [1m[32m0.41588[0m[0m | time: 262.037s
[2K
| RMSProp | epoch: 009 | loss: 0.41588 - acc: 0.8383 -- iter: 640/685
[A[ATraining Step: 197  | total loss: [1m[32m0.40265[0m[0m | time: 276.154s
[2K
| RMSProp | epoch: 009 | loss: 0.40265 - acc: 0.8388 -- iter: 672/685
[A[ATraining Step: 198  | total loss: [1m[32m0.38205[0m[0m | time: 307.916s
[2K
| RMSProp | epoch: 009 | loss: 0.38205 - acc: 0.8487 | val_loss: 2.24357 - val_acc: 0.5628 -- iter: 685/685
--
Training Step: 199  | total loss: [1m[32m0.35901[0m[0m | time: 14.867s
[2K
| RMSProp | epoch: 010 | loss: 0.35901 - acc: 0.8576 -- iter: 032/685
[A[ATraining Step: 200  | total loss: [1m[32m0.35969[0m[0m | time: 38.874s
[2K
| RMSProp | epoch: 010 | loss: 0.35969 - acc: 0.8624 | val_loss: 2.20631 - val_acc: 0.4930 -- iter: 064/685
--
Training Step: 201  | total loss: [1m[32m0.38214[0m[0m | time: 53.392s
[2K
| RMSProp | epoch: 010 | loss: 0.38214 - acc: 0.8543 -- iter: 096/685
[A[ATraining Step: 202  | total loss: [1m[32m0.36660[0m[0m | time: 68.567s
[2K
| RMSProp | epoch: 010 | loss: 0.36660 - acc: 0.8626 -- iter: 128/685
[A[ATraining Step: 203  | total loss: [1m[32m0.34745[0m[0m | time: 83.115s
[2K
| RMSProp | epoch: 010 | loss: 0.34745 - acc: 0.8701 -- iter: 160/685
[A[ATraining Step: 204  | total loss: [1m[32m0.33892[0m[0m | time: 97.357s
[2K
| RMSProp | epoch: 010 | loss: 0.33892 - acc: 0.8769 -- iter: 192/685
[A[ATraining Step: 205  | total loss: [1m[32m0.33692[0m[0m | time: 112.378s
[2K
| RMSProp | epoch: 010 | loss: 0.33692 - acc: 0.8798 -- iter: 224/685
[A[ATraining Step: 206  | total loss: [1m[32m0.34424[0m[0m | time: 119.687s
[2K
| RMSProp | epoch: 010 | loss: 0.34424 - acc: 0.8793 -- iter: 256/685
[A[ATraining Step: 207  | total loss: [1m[32m0.31832[0m[0m | time: 126.976s
[2K
| RMSProp | epoch: 010 | loss: 0.31832 - acc: 0.8914 -- iter: 288/685
[A[ATraining Step: 208  | total loss: [1m[32m0.32995[0m[0m | time: 141.312s
[2K
| RMSProp | epoch: 010 | loss: 0.32995 - acc: 0.8869 -- iter: 320/685
[A[ATraining Step: 209  | total loss: [1m[32m0.31801[0m[0m | time: 155.765s
[2K
| RMSProp | epoch: 010 | loss: 0.31801 - acc: 0.8888 -- iter: 352/685
[A[ATraining Step: 210  | total loss: [1m[32m0.30811[0m[0m | time: 171.205s
[2K
| RMSProp | epoch: 010 | loss: 0.30811 - acc: 0.8843 -- iter: 384/685
[A[ATraining Step: 211  | total loss: [1m[32m0.29319[0m[0m | time: 185.408s
[2K
| RMSProp | epoch: 010 | loss: 0.29319 - acc: 0.8865 -- iter: 416/685
[A[ATraining Step: 212  | total loss: [1m[32m0.28371[0m[0m | time: 200.073s
[2K
| RMSProp | epoch: 010 | loss: 0.28371 - acc: 0.8885 -- iter: 448/685
[A[ATraining Step: 213  | total loss: [1m[32m0.29788[0m[0m | time: 214.401s
[2K
| RMSProp | epoch: 010 | loss: 0.29788 - acc: 0.8746 -- iter: 480/685
[A[ATraining Step: 214  | total loss: [1m[32m0.32282[0m[0m | time: 228.784s
[2K
| RMSProp | epoch: 010 | loss: 0.32282 - acc: 0.8653 -- iter: 512/685
[A[ATraining Step: 215  | total loss: [1m[32m0.31190[0m[0m | time: 243.829s
[2K
| RMSProp | epoch: 010 | loss: 0.31190 - acc: 0.8663 -- iter: 544/685
[A[ATraining Step: 216  | total loss: [1m[32m0.31012[0m[0m | time: 257.744s
[2K
| RMSProp | epoch: 010 | loss: 0.31012 - acc: 0.8640 -- iter: 576/685
[A[ATraining Step: 217  | total loss: [1m[32m0.31060[0m[0m | time: 267.129s
[2K
| RMSProp | epoch: 010 | loss: 0.31060 - acc: 0.8589 -- iter: 608/685
[A[ATraining Step: 218  | total loss: [1m[32m0.29990[0m[0m | time: 276.283s
[2K
| RMSProp | epoch: 010 | loss: 0.29990 - acc: 0.8667 -- iter: 640/685
[A[ATraining Step: 219  | total loss: [1m[32m0.29526[0m[0m | time: 287.799s
[2K
| RMSProp | epoch: 010 | loss: 0.29526 - acc: 0.8707 -- iter: 672/685
[A[ATraining Step: 220  | total loss: [1m[32m0.30577[0m[0m | time: 319.535s
[2K
| RMSProp | epoch: 010 | loss: 0.30577 - acc: 0.8742 | val_loss: 3.07607 - val_acc: 0.5581 -- iter: 685/685
--
Training Step: 221  | total loss: [1m[32m0.30257[0m[0m | time: 14.993s
[2K
| RMSProp | epoch: 011 | loss: 0.30257 - acc: 0.8774 -- iter: 032/685
[A[ATraining Step: 222  | total loss: [1m[32m0.30777[0m[0m | time: 29.205s
[2K
| RMSProp | epoch: 011 | loss: 0.30777 - acc: 0.8772 -- iter: 064/685
[A[ATraining Step: 223  | total loss: [1m[32m0.29679[0m[0m | time: 42.720s
[2K
| RMSProp | epoch: 011 | loss: 0.29679 - acc: 0.8832 -- iter: 096/685
[A[ATraining Step: 224  | total loss: [1m[32m0.28798[0m[0m | time: 56.575s
[2K
| RMSProp | epoch: 011 | loss: 0.28798 - acc: 0.8793 -- iter: 128/685
[A[ATraining Step: 225  | total loss: [1m[32m0.27063[0m[0m | time: 70.981s
[2K
| RMSProp | epoch: 011 | loss: 0.27063 - acc: 0.8851 -- iter: 160/685
[A[ATraining Step: 226  | total loss: [1m[32m0.29721[0m[0m | time: 85.625s
[2K
| RMSProp | epoch: 011 | loss: 0.29721 - acc: 0.8778 -- iter: 192/685
[A[ATraining Step: 227  | total loss: [1m[32m0.28563[0m[0m | time: 99.633s
[2K
| RMSProp | epoch: 011 | loss: 0.28563 - acc: 0.8807 -- iter: 224/685
[A[ATraining Step: 228  | total loss: [1m[32m0.28298[0m[0m | time: 113.990s
[2K
| RMSProp | epoch: 011 | loss: 0.28298 - acc: 0.8864 -- iter: 256/685
[A[ATraining Step: 229  | total loss: [1m[32m0.26381[0m[0m | time: 121.786s
[2K
| RMSProp | epoch: 011 | loss: 0.26381 - acc: 0.8946 -- iter: 288/685
[A[ATraining Step: 230  | total loss: [1m[32m0.31788[0m[0m | time: 129.075s
[2K
| RMSProp | epoch: 011 | loss: 0.31788 - acc: 0.8974 -- iter: 320/685
[A[ATraining Step: 231  | total loss: [1m[32m0.29310[0m[0m | time: 143.948s
[2K
| RMSProp | epoch: 011 | loss: 0.29310 - acc: 0.9077 -- iter: 352/685
[A[ATraining Step: 232  | total loss: [1m[32m0.28530[0m[0m | time: 157.996s
[2K
| RMSProp | epoch: 011 | loss: 0.28530 - acc: 0.9138 -- iter: 384/685
[A[ATraining Step: 233  | total loss: [1m[32m0.27229[0m[0m | time: 172.243s
[2K
| RMSProp | epoch: 011 | loss: 0.27229 - acc: 0.9162 -- iter: 416/685
[A[ATraining Step: 234  | total loss: [1m[32m0.28344[0m[0m | time: 186.691s
[2K
| RMSProp | epoch: 011 | loss: 0.28344 - acc: 0.9121 -- iter: 448/685
[A[ATraining Step: 235  | total loss: [1m[32m0.26346[0m[0m | time: 200.894s
[2K
| RMSProp | epoch: 011 | loss: 0.26346 - acc: 0.9209 -- iter: 480/685
[A[ATraining Step: 236  | total loss: [1m[32m0.24590[0m[0m | time: 215.351s
[2K
| RMSProp | epoch: 011 | loss: 0.24590 - acc: 0.9256 -- iter: 512/685
[A[ATraining Step: 237  | total loss: [1m[32m0.26551[0m[0m | time: 229.654s
[2K
| RMSProp | epoch: 011 | loss: 0.26551 - acc: 0.9143 -- iter: 544/685
[A[ATraining Step: 238  | total loss: [1m[32m0.25612[0m[0m | time: 243.714s
[2K
| RMSProp | epoch: 011 | loss: 0.25612 - acc: 0.9166 -- iter: 576/685
[A[ATraining Step: 239  | total loss: [1m[32m0.27309[0m[0m | time: 257.256s
[2K
| RMSProp | epoch: 011 | loss: 0.27309 - acc: 0.9094 -- iter: 608/685
[A[ATraining Step: 240  | total loss: [1m[32m0.25594[0m[0m | time: 272.427s
[2K
| RMSProp | epoch: 011 | loss: 0.25594 - acc: 0.9153 -- iter: 640/685
[A[ATraining Step: 241  | total loss: [1m[32m0.24731[0m[0m | time: 282.092s
[2K
| RMSProp | epoch: 011 | loss: 0.24731 - acc: 0.9206 -- iter: 672/685
[A[ATraining Step: 242  | total loss: [1m[32m0.24216[0m[0m | time: 305.718s
[2K
| RMSProp | epoch: 011 | loss: 0.24216 - acc: 0.9223 | val_loss: 0.70405 - val_acc: 0.7814 -- iter: 685/685
--
Training Step: 243  | total loss: [1m[32m0.23757[0m[0m | time: 14.191s
[2K
| RMSProp | epoch: 012 | loss: 0.23757 - acc: 0.9238 -- iter: 032/685
[A[ATraining Step: 244  | total loss: [1m[32m0.27828[0m[0m | time: 28.226s
[2K
| RMSProp | epoch: 012 | loss: 0.27828 - acc: 0.9158 -- iter: 064/685
[A[ATraining Step: 245  | total loss: [1m[32m0.28159[0m[0m | time: 42.603s
[2K
| RMSProp | epoch: 012 | loss: 0.28159 - acc: 0.9118 -- iter: 096/685
[A[ATraining Step: 246  | total loss: [1m[32m0.26418[0m[0m | time: 57.140s
[2K
| RMSProp | epoch: 012 | loss: 0.26418 - acc: 0.9175 -- iter: 128/685
[A[ATraining Step: 247  | total loss: [1m[32m0.25717[0m[0m | time: 71.606s
[2K
| RMSProp | epoch: 012 | loss: 0.25717 - acc: 0.9132 -- iter: 160/685
[A[ATraining Step: 248  | total loss: [1m[32m0.25910[0m[0m | time: 85.926s
[2K
| RMSProp | epoch: 012 | loss: 0.25910 - acc: 0.9125 -- iter: 192/685
[A[ATraining Step: 249  | total loss: [1m[32m0.25432[0m[0m | time: 100.316s
[2K
| RMSProp | epoch: 012 | loss: 0.25432 - acc: 0.9150 -- iter: 224/685
[A[ATraining Step: 250  | total loss: [1m[32m0.23882[0m[0m | time: 114.724s
[2K
| RMSProp | epoch: 012 | loss: 0.23882 - acc: 0.9204 -- iter: 256/685
[A[ATraining Step: 251  | total loss: [1m[32m0.22701[0m[0m | time: 128.439s
[2K
| RMSProp | epoch: 012 | loss: 0.22701 - acc: 0.9221 -- iter: 288/685
[A[ATraining Step: 252  | total loss: [1m[32m0.21318[0m[0m | time: 135.639s
[2K
| RMSProp | epoch: 012 | loss: 0.21318 - acc: 0.9299 -- iter: 320/685
[A[ATraining Step: 253  | total loss: [1m[32m0.20947[0m[0m | time: 143.600s
[2K
| RMSProp | epoch: 012 | loss: 0.20947 - acc: 0.9215 -- iter: 352/685
[A[ATraining Step: 254  | total loss: [1m[32m0.21534[0m[0m | time: 157.644s
[2K
| RMSProp | epoch: 012 | loss: 0.21534 - acc: 0.9140 -- iter: 384/685
[A[ATraining Step: 255  | total loss: [1m[32m0.23600[0m[0m | time: 172.098s
[2K
| RMSProp | epoch: 012 | loss: 0.23600 - acc: 0.9038 -- iter: 416/685
[A[ATraining Step: 256  | total loss: [1m[32m0.22064[0m[0m | time: 186.139s
[2K
| RMSProp | epoch: 012 | loss: 0.22064 - acc: 0.9134 -- iter: 448/685
[A[ATraining Step: 257  | total loss: [1m[32m0.20723[0m[0m | time: 200.470s
[2K
| RMSProp | epoch: 012 | loss: 0.20723 - acc: 0.9190 -- iter: 480/685
[A[ATraining Step: 258  | total loss: [1m[32m0.18963[0m[0m | time: 214.658s
[2K
| RMSProp | epoch: 012 | loss: 0.18963 - acc: 0.9271 -- iter: 512/685
[A[ATraining Step: 259  | total loss: [1m[32m0.17886[0m[0m | time: 228.903s
[2K
| RMSProp | epoch: 012 | loss: 0.17886 - acc: 0.9281 -- iter: 544/685
[A[ATraining Step: 260  | total loss: [1m[32m0.22590[0m[0m | time: 243.060s
[2K
| RMSProp | epoch: 012 | loss: 0.22590 - acc: 0.9103 -- iter: 576/685
[A[ATraining Step: 261  | total loss: [1m[32m0.21518[0m[0m | time: 257.458s
[2K
| RMSProp | epoch: 012 | loss: 0.21518 - acc: 0.9099 -- iter: 608/685
[A[ATraining Step: 262  | total loss: [1m[32m0.21313[0m[0m | time: 272.186s
[2K
| RMSProp | epoch: 012 | loss: 0.21313 - acc: 0.9127 -- iter: 640/685
[A[ATraining Step: 263  | total loss: [1m[32m0.20772[0m[0m | time: 285.777s
[2K
| RMSProp | epoch: 012 | loss: 0.20772 - acc: 0.9151 -- iter: 672/685
[A[ATraining Step: 264  | total loss: [1m[32m0.23863[0m[0m | time: 305.497s
[2K
| RMSProp | epoch: 012 | loss: 0.23863 - acc: 0.9080 | val_loss: 4.95370 - val_acc: 0.5535 -- iter: 685/685
--
Training Step: 265  | total loss: [1m[32m0.22096[0m[0m | time: 14.385s
[2K
| RMSProp | epoch: 013 | loss: 0.22096 - acc: 0.9172 -- iter: 032/685
[A[ATraining Step: 266  | total loss: [1m[32m0.20944[0m[0m | time: 28.353s
[2K
| RMSProp | epoch: 013 | loss: 0.20944 - acc: 0.9224 -- iter: 064/685
[A[ATraining Step: 267  | total loss: [1m[32m0.22308[0m[0m | time: 43.073s
[2K
| RMSProp | epoch: 013 | loss: 0.22308 - acc: 0.9207 -- iter: 096/685
[A[ATraining Step: 268  | total loss: [1m[32m0.23754[0m[0m | time: 57.463s
[2K
| RMSProp | epoch: 013 | loss: 0.23754 - acc: 0.9130 -- iter: 128/685
[A[ATraining Step: 269  | total loss: [1m[32m0.22896[0m[0m | time: 72.355s
[2K
| RMSProp | epoch: 013 | loss: 0.22896 - acc: 0.9186 -- iter: 160/685
[A[ATraining Step: 270  | total loss: [1m[32m0.26231[0m[0m | time: 87.180s
[2K
| RMSProp | epoch: 013 | loss: 0.26231 - acc: 0.9080 -- iter: 192/685
[A[ATraining Step: 271  | total loss: [1m[32m0.25499[0m[0m | time: 101.149s
[2K
| RMSProp | epoch: 013 | loss: 0.25499 - acc: 0.9141 -- iter: 224/685
[A[ATraining Step: 272  | total loss: [1m[32m0.26131[0m[0m | time: 114.305s
[2K
| RMSProp | epoch: 013 | loss: 0.26131 - acc: 0.9039 -- iter: 256/685
[A[ATraining Step: 273  | total loss: [1m[32m0.24861[0m[0m | time: 128.798s
[2K
| RMSProp | epoch: 013 | loss: 0.24861 - acc: 0.9104 -- iter: 288/685
[A[ATraining Step: 274  | total loss: [1m[32m0.24225[0m[0m | time: 142.711s
[2K
| RMSProp | epoch: 013 | loss: 0.24225 - acc: 0.9100 -- iter: 320/685
[A[ATraining Step: 275  | total loss: [1m[32m0.25403[0m[0m | time: 150.406s
[2K
| RMSProp | epoch: 013 | loss: 0.25403 - acc: 0.9127 -- iter: 352/685
[A[ATraining Step: 276  | total loss: [1m[32m0.24704[0m[0m | time: 157.179s
[2K
| RMSProp | epoch: 013 | loss: 0.24704 - acc: 0.9138 -- iter: 384/685
[A[ATraining Step: 277  | total loss: [1m[32m0.22798[0m[0m | time: 171.352s
[2K
| RMSProp | epoch: 013 | loss: 0.22798 - acc: 0.9224 -- iter: 416/685
[A[ATraining Step: 278  | total loss: [1m[32m0.23322[0m[0m | time: 186.165s
[2K
| RMSProp | epoch: 013 | loss: 0.23322 - acc: 0.9177 -- iter: 448/685
[A[ATraining Step: 279  | total loss: [1m[32m0.21290[0m[0m | time: 200.517s
[2K
| RMSProp | epoch: 013 | loss: 0.21290 - acc: 0.9259 -- iter: 480/685
[A[ATraining Step: 280  | total loss: [1m[32m0.19412[0m[0m | time: 214.799s
[2K
| RMSProp | epoch: 013 | loss: 0.19412 - acc: 0.9333 -- iter: 512/685
[A[ATraining Step: 281  | total loss: [1m[32m0.17704[0m[0m | time: 229.218s
[2K
| RMSProp | epoch: 013 | loss: 0.17704 - acc: 0.9400 -- iter: 544/685
[A[ATraining Step: 282  | total loss: [1m[32m0.16304[0m[0m | time: 243.544s
[2K
| RMSProp | epoch: 013 | loss: 0.16304 - acc: 0.9429 -- iter: 576/685
[A[ATraining Step: 283  | total loss: [1m[32m0.14864[0m[0m | time: 258.147s
[2K
| RMSProp | epoch: 013 | loss: 0.14864 - acc: 0.9486 -- iter: 608/685
[A[ATraining Step: 284  | total loss: [1m[32m0.14201[0m[0m | time: 272.486s
[2K
| RMSProp | epoch: 013 | loss: 0.14201 - acc: 0.9506 -- iter: 640/685
[A[ATraining Step: 285  | total loss: [1m[32m0.13256[0m[0m | time: 286.617s
[2K
| RMSProp | epoch: 013 | loss: 0.13256 - acc: 0.9524 -- iter: 672/685
[A[ATraining Step: 286  | total loss: [1m[32m0.14040[0m[0m | time: 318.464s
[2K
| RMSProp | epoch: 013 | loss: 0.14040 - acc: 0.9509 | val_loss: 0.99308 - val_acc: 0.7070 -- iter: 685/685
--
Training Step: 287  | total loss: [1m[32m0.13957[0m[0m | time: 9.239s
[2K
| RMSProp | epoch: 014 | loss: 0.13957 - acc: 0.9464 -- iter: 032/685
[A[ATraining Step: 288  | total loss: [1m[32m0.13305[0m[0m | time: 18.901s
[2K
| RMSProp | epoch: 014 | loss: 0.13305 - acc: 0.9487 -- iter: 064/685
[A[ATraining Step: 289  | total loss: [1m[32m0.12602[0m[0m | time: 32.361s
[2K
| RMSProp | epoch: 014 | loss: 0.12602 - acc: 0.9507 -- iter: 096/685
[A[ATraining Step: 290  | total loss: [1m[32m0.14300[0m[0m | time: 46.650s
[2K
| RMSProp | epoch: 014 | loss: 0.14300 - acc: 0.9462 -- iter: 128/685
[A[ATraining Step: 291  | total loss: [1m[32m0.13794[0m[0m | time: 61.074s
[2K
| RMSProp | epoch: 014 | loss: 0.13794 - acc: 0.9454 -- iter: 160/685
[A[ATraining Step: 292  | total loss: [1m[32m0.14190[0m[0m | time: 75.645s
[2K
| RMSProp | epoch: 014 | loss: 0.14190 - acc: 0.9446 -- iter: 192/685
[A[ATraining Step: 293  | total loss: [1m[32m0.14902[0m[0m | time: 89.829s
[2K
| RMSProp | epoch: 014 | loss: 0.14902 - acc: 0.9470 -- iter: 224/685
[A[ATraining Step: 294  | total loss: [1m[32m0.14924[0m[0m | time: 103.575s
[2K
| RMSProp | epoch: 014 | loss: 0.14924 - acc: 0.9429 -- iter: 256/685
[A[ATraining Step: 295  | total loss: [1m[32m0.13747[0m[0m | time: 117.622s
[2K
| RMSProp | epoch: 014 | loss: 0.13747 - acc: 0.9486 -- iter: 288/685
[A[ATraining Step: 296  | total loss: [1m[32m0.13217[0m[0m | time: 131.837s
[2K
| RMSProp | epoch: 014 | loss: 0.13217 - acc: 0.9475 -- iter: 320/685
[A[ATraining Step: 297  | total loss: [1m[32m0.16180[0m[0m | time: 146.428s
[2K
| RMSProp | epoch: 014 | loss: 0.16180 - acc: 0.9465 -- iter: 352/685
[A[ATraining Step: 298  | total loss: [1m[32m0.15567[0m[0m | time: 152.968s
[2K
| RMSProp | epoch: 014 | loss: 0.15567 - acc: 0.9487 -- iter: 384/685
[A[ATraining Step: 299  | total loss: [1m[32m0.16003[0m[0m | time: 160.121s
[2K
| RMSProp | epoch: 014 | loss: 0.16003 - acc: 0.9462 -- iter: 416/685
[A[ATraining Step: 300  | total loss: [1m[32m0.14871[0m[0m | time: 174.189s
[2K
| RMSProp | epoch: 014 | loss: 0.14871 - acc: 0.9516 -- iter: 448/685
[A[ATraining Step: 301  | total loss: [1m[32m0.13760[0m[0m | time: 188.635s
[2K
| RMSProp | epoch: 014 | loss: 0.13760 - acc: 0.9533 -- iter: 480/685
[A[ATraining Step: 302  | total loss: [1m[32m0.15781[0m[0m | time: 202.624s
[2K
| RMSProp | epoch: 014 | loss: 0.15781 - acc: 0.9423 -- iter: 512/685
[A[ATraining Step: 303  | total loss: [1m[32m0.15192[0m[0m | time: 216.629s
[2K
| RMSProp | epoch: 014 | loss: 0.15192 - acc: 0.9481 -- iter: 544/685
[A[ATraining Step: 304  | total loss: [1m[32m0.15194[0m[0m | time: 230.967s
[2K
| RMSProp | epoch: 014 | loss: 0.15194 - acc: 0.9470 -- iter: 576/685
[A[ATraining Step: 305  | total loss: [1m[32m0.18385[0m[0m | time: 244.876s
[2K
| RMSProp | epoch: 014 | loss: 0.18385 - acc: 0.9305 -- iter: 608/685
[A[ATraining Step: 306  | total loss: [1m[32m0.17971[0m[0m | time: 259.661s
[2K
| RMSProp | epoch: 014 | loss: 0.17971 - acc: 0.9280 -- iter: 640/685
[A[ATraining Step: 307  | total loss: [1m[32m0.19687[0m[0m | time: 274.070s
[2K
| RMSProp | epoch: 014 | loss: 0.19687 - acc: 0.9259 -- iter: 672/685
[A[ATraining Step: 308  | total loss: [1m[32m0.19713[0m[0m | time: 305.786s
[2K
| RMSProp | epoch: 014 | loss: 0.19713 - acc: 0.9239 | val_loss: 2.78046 - val_acc: 0.6093 -- iter: 685/685
--
Training Step: 309  | total loss: [1m[32m0.20455[0m[0m | time: 15.050s
[2K
| RMSProp | epoch: 015 | loss: 0.20455 - acc: 0.9284 -- iter: 032/685
[A[ATraining Step: 310  | total loss: [1m[32m0.21660[0m[0m | time: 25.880s
[2K
| RMSProp | epoch: 015 | loss: 0.21660 - acc: 0.9230 -- iter: 064/685
[A[ATraining Step: 311  | total loss: [1m[32m0.20878[0m[0m | time: 35.185s
[2K
| RMSProp | epoch: 015 | loss: 0.20878 - acc: 0.9245 -- iter: 096/685
[A[ATraining Step: 312  | total loss: [1m[32m0.20406[0m[0m | time: 45.465s
[2K
| RMSProp | epoch: 015 | loss: 0.20406 - acc: 0.9227 -- iter: 128/685
[A[ATraining Step: 313  | total loss: [1m[32m0.20023[0m[0m | time: 59.597s
[2K
| RMSProp | epoch: 015 | loss: 0.20023 - acc: 0.9273 -- iter: 160/685
[A[ATraining Step: 314  | total loss: [1m[32m0.18429[0m[0m | time: 73.308s
[2K
| RMSProp | epoch: 015 | loss: 0.18429 - acc: 0.9345 -- iter: 192/685
[A[ATraining Step: 315  | total loss: [1m[32m0.16992[0m[0m | time: 88.273s
[2K
| RMSProp | epoch: 015 | loss: 0.16992 - acc: 0.9411 -- iter: 224/685
[A[ATraining Step: 316  | total loss: [1m[32m0.15918[0m[0m | time: 102.765s
[2K
| RMSProp | epoch: 015 | loss: 0.15918 - acc: 0.9439 -- iter: 256/685
[A[ATraining Step: 317  | total loss: [1m[32m0.15812[0m[0m | time: 116.977s
[2K
| RMSProp | epoch: 015 | loss: 0.15812 - acc: 0.9432 -- iter: 288/685
[A[ATraining Step: 318  | total loss: [1m[32m0.16136[0m[0m | time: 131.059s
[2K
| RMSProp | epoch: 015 | loss: 0.16136 - acc: 0.9458 -- iter: 320/685
[A[ATraining Step: 319  | total loss: [1m[32m0.14906[0m[0m | time: 144.726s
[2K
| RMSProp | epoch: 015 | loss: 0.14906 - acc: 0.9512 -- iter: 352/685
[A[ATraining Step: 320  | total loss: [1m[32m0.15789[0m[0m | time: 159.122s
[2K
| RMSProp | epoch: 015 | loss: 0.15789 - acc: 0.9530 -- iter: 384/685
[A[ATraining Step: 321  | total loss: [1m[32m0.15542[0m[0m | time: 165.868s
[2K
| RMSProp | epoch: 015 | loss: 0.15542 - acc: 0.9514 -- iter: 416/685
[A[ATraining Step: 322  | total loss: [1m[32m0.14602[0m[0m | time: 173.668s
[2K
| RMSProp | epoch: 015 | loss: 0.14602 - acc: 0.9563 -- iter: 448/685
[A[ATraining Step: 323  | total loss: [1m[32m0.13801[0m[0m | time: 187.870s
[2K
| RMSProp | epoch: 015 | loss: 0.13801 - acc: 0.9606 -- iter: 480/685
[A[ATraining Step: 324  | total loss: [1m[32m0.13089[0m[0m | time: 202.166s
[2K
| RMSProp | epoch: 015 | loss: 0.13089 - acc: 0.9615 -- iter: 512/685
[A[ATraining Step: 325  | total loss: [1m[32m0.16902[0m[0m | time: 217.147s
[2K
| RMSProp | epoch: 015 | loss: 0.16902 - acc: 0.9559 -- iter: 544/685
[A[ATraining Step: 326  | total loss: [1m[32m0.20577[0m[0m | time: 231.468s
[2K
| RMSProp | epoch: 015 | loss: 0.20577 - acc: 0.9510 -- iter: 576/685
[A[ATraining Step: 327  | total loss: [1m[32m0.19508[0m[0m | time: 246.168s
[2K
| RMSProp | epoch: 015 | loss: 0.19508 - acc: 0.9527 -- iter: 608/685
[A[ATraining Step: 328  | total loss: [1m[32m0.21084[0m[0m | time: 260.513s
[2K
| RMSProp | epoch: 015 | loss: 0.21084 - acc: 0.9481 -- iter: 640/685
[A[ATraining Step: 329  | total loss: [1m[32m0.20151[0m[0m | time: 274.969s
[2K
| RMSProp | epoch: 015 | loss: 0.20151 - acc: 0.9470 -- iter: 672/685
[A[ATraining Step: 330  | total loss: [1m[32m0.19271[0m[0m | time: 305.781s
[2K
| RMSProp | epoch: 015 | loss: 0.19271 - acc: 0.9492 | val_loss: 1.57476 - val_acc: 0.6698 -- iter: 685/685
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8298260869565218
Validation AUPRC:0.8196960258862076
Test AUC:0.8520284327323162
Test AUPRC:0.8551473914887238
BestTestF1Score	0.79	0.56	0.78	0.78	0.8	90	25	78	22	0.99
BestTestMCCScore	0.79	0.56	0.78	0.78	0.8	90	25	78	22	0.99
BestTestAccuracyScore	0.79	0.56	0.78	0.78	0.8	90	25	78	22	0.99
BestValidationF1Score	0.8	0.53	0.77	0.75	0.84	97	32	68	18	0.99
BestValidationMCC	0.8	0.53	0.77	0.75	0.84	97	32	68	18	0.99
BestValidationAccuracy	0.8	0.53	0.77	0.75	0.84	97	32	68	18	0.99
TestPredictions (Threshold:0.99)
CHEMBL295871,FP,INACT,1.0	CHEMBL3775142,TN,INACT,0.6800000071525574	CHEMBL77461,FP,INACT,1.0	CHEMBL2380387,TP,ACT,1.0	CHEMBL1939846,TP,ACT,0.9900000095367432	CHEMBL575881,FN,ACT,0.9200000166893005	CHEMBL1801430,TP,ACT,1.0	CHEMBL556645,TP,ACT,1.0	CHEMBL456774,FN,ACT,0.9399999976158142	CHEMBL146289,FN,ACT,0.9800000190734863	CHEMBL484261,TP,ACT,1.0	CHEMBL288510,TN,INACT,0.7799999713897705	CHEMBL210133,TP,ACT,1.0	CHEMBL491050,TN,INACT,0.05000000074505806	CHEMBL327617,TP,ACT,1.0	CHEMBL197842,FN,ACT,0.8799999952316284	CHEMBL2153739,TP,ACT,1.0	CHEMBL314327,FP,INACT,0.9900000095367432	CHEMBL88188,TP,ACT,1.0	CHEMBL41923,TN,INACT,0.6600000262260437	CHEMBL2409676,TN,INACT,0.949999988079071	CHEMBL98852,FP,INACT,0.9900000095367432	CHEMBL212481,TP,ACT,1.0	CHEMBL398892,TN,INACT,0.05999999865889549	CHEMBL497762,FP,INACT,1.0	CHEMBL41067,TN,INACT,0.9300000071525574	CHEMBL1927183,TN,INACT,0.6600000262260437	CHEMBL367331,TN,INACT,0.1899999976158142	CHEMBL174373,TN,INACT,0.12999999523162842	CHEMBL417697,TN,INACT,0.9300000071525574	CHEMBL236573,TP,ACT,1.0	CHEMBL121559,TN,INACT,0.6499999761581421	CHEMBL358539,TP,ACT,1.0	CHEMBL368347,TN,INACT,0.9200000166893005	CHEMBL3622792,TN,INACT,0.07999999821186066	CHEMBL123064,TN,INACT,0.8500000238418579	CHEMBL380049,TP,ACT,1.0	CHEMBL2333267,FP,INACT,0.9900000095367432	CHEMBL86390,TP,ACT,1.0	CHEMBL61538,TN,INACT,0.20000000298023224	CHEMBL19843,TP,ACT,1.0	CHEMBL361783,TP,ACT,1.0	CHEMBL315901,TP,ACT,1.0	CHEMBL104446,TN,INACT,0.9700000286102295	CHEMBL574444,TN,INACT,0.550000011920929	CHEMBL361326,TP,ACT,1.0	CHEMBL2440433,TN,INACT,0.10000000149011612	CHEMBL47076,FP,INACT,1.0	CHEMBL212205,FN,ACT,0.9599999785423279	CHEMBL556692,FP,INACT,1.0	CHEMBL253823,TN,INACT,0.05999999865889549	CHEMBL1819325,TN,INACT,0.27000001072883606	CHEMBL2151350,TN,INACT,0.8500000238418579	CHEMBL3358157,TP,ACT,0.9900000095367432	CHEMBL227501,TP,ACT,1.0	CHEMBL515439,TN,INACT,0.9200000166893005	CHEMBL1795862,FN,ACT,0.7400000095367432	CHEMBL250502,TP,ACT,1.0	CHEMBL377862,TP,ACT,1.0	CHEMBL182582,TP,ACT,1.0	CHEMBL148214,TP,ACT,0.9900000095367432	CHEMBL561036,FN,ACT,0.9800000190734863	CHEMBL97389,TN,INACT,0.10999999940395355	CHEMBL3670699,FN,ACT,0.9700000286102295	CHEMBL579067,TP,ACT,1.0	CHEMBL1939861,TN,INACT,0.9399999976158142	CHEMBL1649594,TN,INACT,0.9800000190734863	CHEMBL2409686,TP,ACT,0.9900000095367432	CHEMBL2326365,TP,ACT,1.0	CHEMBL115468,TN,INACT,0.44999998807907104	CHEMBL369524,TP,ACT,1.0	CHEMBL88520,FN,ACT,0.9800000190734863	CHEMBL252523,TN,INACT,0.23000000417232513	CHEMBL1650630,FP,INACT,1.0	CHEMBL290457,TN,INACT,0.7099999785423279	CHEMBL323874,TN,INACT,0.07000000029802322	CHEMBL95560,FP,INACT,1.0	CHEMBL2440578,TN,INACT,0.6600000262260437	CHEMBL1801052,TP,ACT,1.0	CHEMBL97057,TN,INACT,0.019999999552965164	CHEMBL508335,TP,ACT,1.0	CHEMBL199314,TN,INACT,0.05000000074505806	CHEMBL394363,TN,INACT,0.699999988079071	CHEMBL2333264,TN,INACT,0.18000000715255737	CHEMBL253372,TN,INACT,0.11999999731779099	CHEMBL491656,TN,INACT,0.9399999976158142	CHEMBL8943,TN,INACT,0.49000000953674316	CHEMBL3758580,TN,INACT,0.8299999833106995	CHEMBL182894,TP,ACT,1.0	CHEMBL324522,TN,INACT,0.019999999552965164	CHEMBL226852,TN,INACT,0.44999998807907104	CHEMBL1093689,TP,ACT,1.0	CHEMBL37147,TN,INACT,0.7099999785423279	CHEMBL194430,FP,INACT,1.0	CHEMBL288599,TN,INACT,0.7200000286102295	CHEMBL250299,TP,ACT,1.0	CHEMBL228188,TP,ACT,1.0	CHEMBL1801054,TP,ACT,1.0	CHEMBL1939844,FN,ACT,0.3199999928474426	CHEMBL415872,TN,INACT,0.949999988079071	CHEMBL3827735,TP,ACT,1.0	CHEMBL1939876,TP,ACT,0.9900000095367432	CHEMBL2409688,TP,ACT,1.0	CHEMBL2063277,TP,ACT,1.0	CHEMBL88187,TP,ACT,1.0	CHEMBL313386,TP,ACT,1.0	CHEMBL203199,TN,INACT,0.05999999865889549	CHEMBL574589,FN,ACT,0.9700000286102295	CHEMBL1766912,TP,ACT,1.0	CHEMBL388453,FN,ACT,0.8500000238418579	CHEMBL332145,TN,INACT,0.1599999964237213	CHEMBL183216,TP,ACT,1.0	CHEMBL3358151,FP,INACT,0.9900000095367432	CHEMBL466118,TP,ACT,0.9900000095367432	CHEMBL3142589,FP,INACT,0.9900000095367432	CHEMBL183713,TP,ACT,1.0	CHEMBL575946,TN,INACT,0.9599999785423279	CHEMBL117503,TN,INACT,0.8700000047683716	CHEMBL1800089,TP,ACT,1.0	CHEMBL3358158,FP,INACT,1.0	CHEMBL251423,TN,INACT,0.019999999552965164	CHEMBL475231,TN,INACT,0.9800000190734863	CHEMBL27647,TN,INACT,0.8899999856948853	CHEMBL289207,TN,INACT,0.30000001192092896	CHEMBL403649,TP,ACT,1.0	CHEMBL87786,TP,ACT,1.0	CHEMBL324891,FP,INACT,1.0	CHEMBL2048507,FP,INACT,1.0	CHEMBL2063270,TP,ACT,1.0	CHEMBL3142608,FP,INACT,0.9900000095367432	CHEMBL389020,TN,INACT,0.6100000143051147	CHEMBL1801425,TP,ACT,1.0	CHEMBL237468,TP,ACT,1.0	CHEMBL234735,TP,ACT,1.0	CHEMBL340455,TN,INACT,0.4399999976158142	CHEMBL572980,TN,INACT,0.3799999952316284	CHEMBL43152,FN,ACT,0.800000011920929	CHEMBL2380314,TP,ACT,1.0	CHEMBL2430289,FN,ACT,0.9300000071525574	CHEMBL199241,TN,INACT,0.4000000059604645	CHEMBL1957605,TP,ACT,0.9900000095367432	CHEMBL1160686,TN,INACT,0.05000000074505806	CHEMBL1939866,TN,INACT,0.8600000143051147	CHEMBL1214544,TN,INACT,0.949999988079071	CHEMBL183848,TP,ACT,1.0	CHEMBL315046,TP,ACT,1.0	CHEMBL3142588,TN,INACT,0.9800000190734863	CHEMBL2440441,FN,ACT,0.27000001072883606	CHEMBL109806,FN,ACT,0.9700000286102295	CHEMBL2337690,TP,ACT,0.9900000095367432	CHEMBL78335,FP,INACT,1.0	CHEMBL102839,TN,INACT,0.9300000071525574	CHEMBL1801393,TP,ACT,1.0	CHEMBL250093,TP,ACT,1.0	CHEMBL210084,TP,ACT,1.0	CHEMBL97510,TN,INACT,0.09000000357627869	CHEMBL432842,TP,ACT,1.0	CHEMBL38717,FP,INACT,1.0	CHEMBL1939869,TN,INACT,0.33000001311302185	CHEMBL440498,TP,ACT,1.0	CHEMBL2172745,TN,INACT,0.9200000166893005	CHEMBL126712,FP,INACT,1.0	CHEMBL573715,TP,ACT,1.0	CHEMBL2440432,TN,INACT,0.38999998569488525	CHEMBL1162966,TN,INACT,0.6200000047683716	CHEMBL252464,TP,ACT,1.0	CHEMBL379287,TP,ACT,1.0	CHEMBL269834,TN,INACT,0.9399999976158142	CHEMBL514138,FN,ACT,0.8199999928474426	CHEMBL339588,FP,INACT,0.9900000095367432	CHEMBL404715,TP,ACT,1.0	CHEMBL3827453,TP,ACT,1.0	CHEMBL109353,TP,ACT,1.0	CHEMBL277792,TP,ACT,1.0	CHEMBL123105,TN,INACT,0.6600000262260437	CHEMBL400449,TN,INACT,0.14000000059604645	CHEMBL483857,FN,ACT,0.9200000166893005	CHEMBL432770,TP,ACT,1.0	CHEMBL424130,FN,ACT,0.9599999785423279	CHEMBL502674,TP,ACT,1.0	CHEMBL422250,TP,ACT,1.0	CHEMBL1683443,TP,ACT,1.0	CHEMBL211726,TP,ACT,1.0	CHEMBL279964,FN,ACT,0.3700000047683716	CHEMBL2442885,TP,ACT,1.0	CHEMBL254038,TN,INACT,0.38999998569488525	CHEMBL95237,TP,ACT,1.0	CHEMBL253801,TN,INACT,0.15000000596046448	CHEMBL2369490,TN,INACT,0.9300000071525574	CHEMBL254821,TN,INACT,0.2199999988079071	CHEMBL3775115,TN,INACT,0.9700000286102295	CHEMBL318252,FP,INACT,1.0	CHEMBL1767010,TP,ACT,1.0	CHEMBL309067,FP,INACT,1.0	CHEMBL24398,TN,INACT,0.9800000190734863	CHEMBL2063274,TP,ACT,1.0	CHEMBL314199,TP,ACT,1.0	CHEMBL189666,TP,ACT,1.0	CHEMBL1766911,TP,ACT,1.0	CHEMBL173382,TN,INACT,0.11999999731779099	CHEMBL1766906,TP,ACT,1.0	CHEMBL2409699,TP,ACT,0.9900000095367432	CHEMBL1683453,TP,ACT,1.0	CHEMBL326489,FN,ACT,0.8700000047683716	CHEMBL1084509,TP,ACT,1.0	CHEMBL1795858,FN,ACT,0.9399999976158142	CHEMBL234530,TP,ACT,0.9900000095367432	CHEMBL409502,TN,INACT,0.17000000178813934	CHEMBL2380390,TP,ACT,1.0	CHEMBL109214,TP,ACT,1.0	CHEMBL254838,TN,INACT,0.07999999821186066	CHEMBL271235,TP,ACT,0.9900000095367432	CHEMBL122109,FP,INACT,1.0	CHEMBL252268,TP,ACT,1.0	CHEMBL234567,FP,INACT,1.0	

