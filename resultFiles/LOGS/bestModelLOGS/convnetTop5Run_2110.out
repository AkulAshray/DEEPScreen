CNNModel CHEMBL1947 adam 0.001 15 256 0 0.6 False True
Number of active compounds :	433
Number of inactive compounds :	433
---------------------------------
Run id: CNNModel_CHEMBL1947_adam_0.001_15_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1947_adam_0.001_15_256_0.6_True/
---------------------------------
Training samples: 512
Validation samples: 161
--
Training Step: 1  | time: 0.957s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/512
[A[ATraining Step: 2  | total loss: [1m[32m0.62413[0m[0m | time: 1.818s
[2K
| Adam | epoch: 001 | loss: 0.62413 - acc: 0.3656 -- iter: 064/512
[A[ATraining Step: 3  | total loss: [1m[32m0.68025[0m[0m | time: 2.644s
[2K
| Adam | epoch: 001 | loss: 0.68025 - acc: 0.5011 -- iter: 096/512
[A[ATraining Step: 4  | total loss: [1m[32m0.68654[0m[0m | time: 3.266s
[2K
| Adam | epoch: 001 | loss: 0.68654 - acc: 0.5472 -- iter: 128/512
[A[ATraining Step: 5  | total loss: [1m[32m0.72107[0m[0m | time: 3.935s
[2K
| Adam | epoch: 001 | loss: 0.72107 - acc: 0.4063 -- iter: 160/512
[A[ATraining Step: 6  | total loss: [1m[32m0.70189[0m[0m | time: 4.576s
[2K
| Adam | epoch: 001 | loss: 0.70189 - acc: 0.4866 -- iter: 192/512
[A[ATraining Step: 7  | total loss: [1m[32m0.69368[0m[0m | time: 5.197s
[2K
| Adam | epoch: 001 | loss: 0.69368 - acc: 0.5509 -- iter: 224/512
[A[ATraining Step: 8  | total loss: [1m[32m0.69330[0m[0m | time: 5.825s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.5223 -- iter: 256/512
[A[ATraining Step: 9  | total loss: [1m[32m0.69185[0m[0m | time: 6.443s
[2K
| Adam | epoch: 001 | loss: 0.69185 - acc: 0.5601 -- iter: 288/512
[A[ATraining Step: 10  | total loss: [1m[32m0.68981[0m[0m | time: 7.059s
[2K
| Adam | epoch: 001 | loss: 0.68981 - acc: 0.6238 -- iter: 320/512
[A[ATraining Step: 11  | total loss: [1m[32m0.68895[0m[0m | time: 7.961s
[2K
| Adam | epoch: 001 | loss: 0.68895 - acc: 0.6392 -- iter: 352/512
[A[ATraining Step: 12  | total loss: [1m[32m0.69211[0m[0m | time: 8.804s
[2K
| Adam | epoch: 001 | loss: 0.69211 - acc: 0.5484 -- iter: 384/512
[A[ATraining Step: 13  | total loss: [1m[32m0.69198[0m[0m | time: 9.636s
[2K
| Adam | epoch: 001 | loss: 0.69198 - acc: 0.5411 -- iter: 416/512
[A[ATraining Step: 14  | total loss: [1m[32m0.69185[0m[0m | time: 10.470s
[2K
| Adam | epoch: 001 | loss: 0.69185 - acc: 0.5370 -- iter: 448/512
[A[ATraining Step: 15  | total loss: [1m[32m0.69248[0m[0m | time: 11.239s
[2K
| Adam | epoch: 001 | loss: 0.69248 - acc: 0.5226 -- iter: 480/512
[A[ATraining Step: 16  | total loss: [1m[32m0.69075[0m[0m | time: 13.080s
[2K
| Adam | epoch: 001 | loss: 0.69075 - acc: 0.5493 | val_loss: 0.69150 - val_acc: 0.5280 -- iter: 512/512
--
Training Step: 17  | total loss: [1m[32m0.68943[0m[0m | time: 0.662s
[2K
| Adam | epoch: 002 | loss: 0.68943 - acc: 0.5653 -- iter: 032/512
[A[ATraining Step: 18  | total loss: [1m[32m0.68823[0m[0m | time: 1.273s
[2K
| Adam | epoch: 002 | loss: 0.68823 - acc: 0.5751 -- iter: 064/512
[A[ATraining Step: 19  | total loss: [1m[32m0.68799[0m[0m | time: 2.014s
[2K
| Adam | epoch: 002 | loss: 0.68799 - acc: 0.5709 -- iter: 096/512
[A[ATraining Step: 20  | total loss: [1m[32m0.68465[0m[0m | time: 2.800s
[2K
| Adam | epoch: 002 | loss: 0.68465 - acc: 0.5883 -- iter: 128/512
[A[ATraining Step: 21  | total loss: [1m[32m0.68660[0m[0m | time: 3.577s
[2K
| Adam | epoch: 002 | loss: 0.68660 - acc: 0.5706 -- iter: 160/512
[A[ATraining Step: 22  | total loss: [1m[32m0.68277[0m[0m | time: 4.370s
[2K
| Adam | epoch: 002 | loss: 0.68277 - acc: 0.5775 -- iter: 192/512
[A[ATraining Step: 23  | total loss: [1m[32m0.69078[0m[0m | time: 5.121s
[2K
| Adam | epoch: 002 | loss: 0.69078 - acc: 0.5550 -- iter: 224/512
[A[ATraining Step: 24  | total loss: [1m[32m0.68607[0m[0m | time: 5.886s
[2K
| Adam | epoch: 002 | loss: 0.68607 - acc: 0.5659 -- iter: 256/512
[A[ATraining Step: 25  | total loss: [1m[32m0.68825[0m[0m | time: 6.648s
[2K
| Adam | epoch: 002 | loss: 0.68825 - acc: 0.5565 -- iter: 288/512
[A[ATraining Step: 26  | total loss: [1m[32m0.69630[0m[0m | time: 7.397s
[2K
| Adam | epoch: 002 | loss: 0.69630 - acc: 0.5250 -- iter: 320/512
[A[ATraining Step: 27  | total loss: [1m[32m0.69374[0m[0m | time: 8.161s
[2K
| Adam | epoch: 002 | loss: 0.69374 - acc: 0.5346 -- iter: 352/512
[A[ATraining Step: 28  | total loss: [1m[32m0.69058[0m[0m | time: 8.879s
[2K
| Adam | epoch: 002 | loss: 0.69058 - acc: 0.5494 -- iter: 384/512
[A[ATraining Step: 29  | total loss: [1m[32m0.69247[0m[0m | time: 9.762s
[2K
| Adam | epoch: 002 | loss: 0.69247 - acc: 0.5298 -- iter: 416/512
[A[ATraining Step: 30  | total loss: [1m[32m0.69382[0m[0m | time: 10.385s
[2K
| Adam | epoch: 002 | loss: 0.69382 - acc: 0.5153 -- iter: 448/512
[A[ATraining Step: 31  | total loss: [1m[32m0.69323[0m[0m | time: 11.030s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.5190 -- iter: 480/512
[A[ATraining Step: 32  | total loss: [1m[32m0.69255[0m[0m | time: 12.652s
[2K
| Adam | epoch: 002 | loss: 0.69255 - acc: 0.5218 | val_loss: 0.69141 - val_acc: 0.5280 -- iter: 512/512
--
Training Step: 33  | total loss: [1m[32m0.69047[0m[0m | time: 0.851s
[2K
| Adam | epoch: 003 | loss: 0.69047 - acc: 0.5444 -- iter: 032/512
[A[ATraining Step: 34  | total loss: [1m[32m0.68892[0m[0m | time: 1.659s
[2K
| Adam | epoch: 003 | loss: 0.68892 - acc: 0.5617 -- iter: 064/512
[A[ATraining Step: 35  | total loss: [1m[32m0.68784[0m[0m | time: 2.450s
[2K
| Adam | epoch: 003 | loss: 0.68784 - acc: 0.5749 -- iter: 096/512
[A[ATraining Step: 36  | total loss: [1m[32m0.68846[0m[0m | time: 3.305s
[2K
| Adam | epoch: 003 | loss: 0.68846 - acc: 0.5660 -- iter: 128/512
[A[ATraining Step: 37  | total loss: [1m[32m0.68953[0m[0m | time: 4.092s
[2K
| Adam | epoch: 003 | loss: 0.68953 - acc: 0.5528 -- iter: 160/512
[A[ATraining Step: 38  | total loss: [1m[32m0.68929[0m[0m | time: 4.879s
[2K
| Adam | epoch: 003 | loss: 0.68929 - acc: 0.5547 -- iter: 192/512
[A[ATraining Step: 39  | total loss: [1m[32m0.68841[0m[0m | time: 5.749s
[2K
| Adam | epoch: 003 | loss: 0.68841 - acc: 0.5622 -- iter: 224/512
[A[ATraining Step: 40  | total loss: [1m[32m0.69061[0m[0m | time: 6.373s
[2K
| Adam | epoch: 003 | loss: 0.69061 - acc: 0.5388 -- iter: 256/512
[A[ATraining Step: 41  | total loss: [1m[32m0.69116[0m[0m | time: 6.984s
[2K
| Adam | epoch: 003 | loss: 0.69116 - acc: 0.5317 -- iter: 288/512
[A[ATraining Step: 42  | total loss: [1m[32m0.69043[0m[0m | time: 7.596s
[2K
| Adam | epoch: 003 | loss: 0.69043 - acc: 0.5372 -- iter: 320/512
[A[ATraining Step: 43  | total loss: [1m[32m0.69041[0m[0m | time: 8.223s
[2K
| Adam | epoch: 003 | loss: 0.69041 - acc: 0.5362 -- iter: 352/512
[A[ATraining Step: 44  | total loss: [1m[32m0.68900[0m[0m | time: 8.863s
[2K
| Adam | epoch: 003 | loss: 0.68900 - acc: 0.5461 -- iter: 384/512
[A[ATraining Step: 45  | total loss: [1m[32m0.68662[0m[0m | time: 9.505s
[2K
| Adam | epoch: 003 | loss: 0.68662 - acc: 0.5648 -- iter: 416/512
[A[ATraining Step: 46  | total loss: [1m[32m0.68788[0m[0m | time: 10.149s
[2K
| Adam | epoch: 003 | loss: 0.68788 - acc: 0.5540 -- iter: 448/512
[A[ATraining Step: 47  | total loss: [1m[32m0.68494[0m[0m | time: 10.788s
[2K
| Adam | epoch: 003 | loss: 0.68494 - acc: 0.5708 -- iter: 480/512
[A[ATraining Step: 48  | total loss: [1m[32m0.68715[0m[0m | time: 12.506s
[2K
| Adam | epoch: 003 | loss: 0.68715 - acc: 0.5544 | val_loss: 0.69060 - val_acc: 0.5280 -- iter: 512/512
--
Training Step: 49  | total loss: [1m[32m0.68304[0m[0m | time: 0.832s
[2K
| Adam | epoch: 004 | loss: 0.68304 - acc: 0.5704 -- iter: 032/512
[A[ATraining Step: 50  | total loss: [1m[32m0.68256[0m[0m | time: 1.715s
[2K
| Adam | epoch: 004 | loss: 0.68256 - acc: 0.5692 -- iter: 064/512
[A[ATraining Step: 51  | total loss: [1m[32m0.68662[0m[0m | time: 2.364s
[2K
| Adam | epoch: 004 | loss: 0.68662 - acc: 0.5539 -- iter: 096/512
[A[ATraining Step: 52  | total loss: [1m[32m0.68983[0m[0m | time: 3.009s
[2K
| Adam | epoch: 004 | loss: 0.68983 - acc: 0.5411 -- iter: 128/512
[A[ATraining Step: 53  | total loss: [1m[32m0.68798[0m[0m | time: 3.643s
[2K
| Adam | epoch: 004 | loss: 0.68798 - acc: 0.5443 -- iter: 160/512
[A[ATraining Step: 54  | total loss: [1m[32m0.69086[0m[0m | time: 4.271s
[2K
| Adam | epoch: 004 | loss: 0.69086 - acc: 0.5288 -- iter: 192/512
[A[ATraining Step: 55  | total loss: [1m[32m0.69177[0m[0m | time: 4.888s
[2K
| Adam | epoch: 004 | loss: 0.69177 - acc: 0.5247 -- iter: 224/512
[A[ATraining Step: 56  | total loss: [1m[32m0.69287[0m[0m | time: 5.534s
[2K
| Adam | epoch: 004 | loss: 0.69287 - acc: 0.5168 -- iter: 256/512
[A[ATraining Step: 57  | total loss: [1m[32m0.69064[0m[0m | time: 6.196s
[2K
| Adam | epoch: 004 | loss: 0.69064 - acc: 0.5275 -- iter: 288/512
[A[ATraining Step: 58  | total loss: [1m[32m0.69048[0m[0m | time: 6.855s
[2K
| Adam | epoch: 004 | loss: 0.69048 - acc: 0.5280 -- iter: 320/512
[A[ATraining Step: 59  | total loss: [1m[32m0.69179[0m[0m | time: 7.487s
[2K
| Adam | epoch: 004 | loss: 0.69179 - acc: 0.5158 -- iter: 352/512
[A[ATraining Step: 60  | total loss: [1m[32m0.69211[0m[0m | time: 8.142s
[2K
| Adam | epoch: 004 | loss: 0.69211 - acc: 0.5096 -- iter: 384/512
[A[ATraining Step: 61  | total loss: [1m[32m0.69077[0m[0m | time: 8.813s
[2K
| Adam | epoch: 004 | loss: 0.69077 - acc: 0.5206 -- iter: 416/512
[A[ATraining Step: 62  | total loss: [1m[32m0.69066[0m[0m | time: 9.457s
[2K
| Adam | epoch: 004 | loss: 0.69066 - acc: 0.5179 -- iter: 448/512
[A[ATraining Step: 63  | total loss: [1m[32m0.68886[0m[0m | time: 10.095s
[2K
| Adam | epoch: 004 | loss: 0.68886 - acc: 0.5315 -- iter: 480/512
[A[ATraining Step: 64  | total loss: [1m[32m0.68822[0m[0m | time: 11.914s
[2K
| Adam | epoch: 004 | loss: 0.68822 - acc: 0.5354 | val_loss: 0.68566 - val_acc: 0.5280 -- iter: 512/512
--
Training Step: 65  | total loss: [1m[32m0.68485[0m[0m | time: 0.896s
[2K
| Adam | epoch: 005 | loss: 0.68485 - acc: 0.5503 -- iter: 032/512
[A[ATraining Step: 66  | total loss: [1m[32m0.68131[0m[0m | time: 1.750s
[2K
| Adam | epoch: 005 | loss: 0.68131 - acc: 0.5594 -- iter: 064/512
[A[ATraining Step: 67  | total loss: [1m[32m0.68249[0m[0m | time: 2.403s
[2K
| Adam | epoch: 005 | loss: 0.68249 - acc: 0.5560 -- iter: 096/512
[A[ATraining Step: 68  | total loss: [1m[32m0.67311[0m[0m | time: 3.060s
[2K
| Adam | epoch: 005 | loss: 0.67311 - acc: 0.5716 -- iter: 128/512
[A[ATraining Step: 69  | total loss: [1m[32m0.66145[0m[0m | time: 3.708s
[2K
| Adam | epoch: 005 | loss: 0.66145 - acc: 0.5851 -- iter: 160/512
[A[ATraining Step: 70  | total loss: [1m[32m0.65922[0m[0m | time: 4.360s
[2K
| Adam | epoch: 005 | loss: 0.65922 - acc: 0.5897 -- iter: 192/512
[A[ATraining Step: 71  | total loss: [1m[32m0.67570[0m[0m | time: 5.029s
[2K
| Adam | epoch: 005 | loss: 0.67570 - acc: 0.5759 -- iter: 224/512
[A[ATraining Step: 72  | total loss: [1m[32m0.69239[0m[0m | time: 5.897s
[2K
| Adam | epoch: 005 | loss: 0.69239 - acc: 0.5639 -- iter: 256/512
[A[ATraining Step: 73  | total loss: [1m[32m0.68588[0m[0m | time: 6.807s
[2K
| Adam | epoch: 005 | loss: 0.68588 - acc: 0.5637 -- iter: 288/512
[A[ATraining Step: 74  | total loss: [1m[32m0.68519[0m[0m | time: 7.650s
[2K
| Adam | epoch: 005 | loss: 0.68519 - acc: 0.5499 -- iter: 320/512
[A[ATraining Step: 75  | total loss: [1m[32m0.68393[0m[0m | time: 8.506s
[2K
| Adam | epoch: 005 | loss: 0.68393 - acc: 0.5580 -- iter: 352/512
[A[ATraining Step: 76  | total loss: [1m[32m0.68330[0m[0m | time: 9.335s
[2K
| Adam | epoch: 005 | loss: 0.68330 - acc: 0.5752 -- iter: 384/512
[A[ATraining Step: 77  | total loss: [1m[32m0.68424[0m[0m | time: 10.140s
[2K
| Adam | epoch: 005 | loss: 0.68424 - acc: 0.5640 -- iter: 416/512
[A[ATraining Step: 78  | total loss: [1m[32m0.68446[0m[0m | time: 10.950s
[2K
| Adam | epoch: 005 | loss: 0.68446 - acc: 0.5736 -- iter: 448/512
[A[ATraining Step: 79  | total loss: [1m[32m0.68557[0m[0m | time: 11.756s
[2K
| Adam | epoch: 005 | loss: 0.68557 - acc: 0.5563 -- iter: 480/512
[A[ATraining Step: 80  | total loss: [1m[32m0.68561[0m[0m | time: 13.547s
[2K
| Adam | epoch: 005 | loss: 0.68561 - acc: 0.5665 | val_loss: 0.69116 - val_acc: 0.5280 -- iter: 512/512
--
Training Step: 81  | total loss: [1m[32m0.68624[0m[0m | time: 0.837s
[2K
| Adam | epoch: 006 | loss: 0.68624 - acc: 0.5630 -- iter: 032/512
[A[ATraining Step: 82  | total loss: [1m[32m0.68691[0m[0m | time: 1.701s
[2K
| Adam | epoch: 006 | loss: 0.68691 - acc: 0.5567 -- iter: 064/512
[A[ATraining Step: 83  | total loss: [1m[32m0.68727[0m[0m | time: 2.521s
[2K
| Adam | epoch: 006 | loss: 0.68727 - acc: 0.5541 -- iter: 096/512
[A[ATraining Step: 84  | total loss: [1m[32m0.68752[0m[0m | time: 3.336s
[2K
| Adam | epoch: 006 | loss: 0.68752 - acc: 0.5550 -- iter: 128/512
[A[ATraining Step: 85  | total loss: [1m[32m0.68768[0m[0m | time: 4.156s
[2K
| Adam | epoch: 006 | loss: 0.68768 - acc: 0.5557 -- iter: 160/512
[A[ATraining Step: 86  | total loss: [1m[32m0.68774[0m[0m | time: 5.002s
[2K
| Adam | epoch: 006 | loss: 0.68774 - acc: 0.5564 -- iter: 192/512
[A[ATraining Step: 87  | total loss: [1m[32m0.68703[0m[0m | time: 5.857s
[2K
| Adam | epoch: 006 | loss: 0.68703 - acc: 0.5633 -- iter: 224/512
[A[ATraining Step: 88  | total loss: [1m[32m0.68750[0m[0m | time: 6.656s
[2K
| Adam | epoch: 006 | loss: 0.68750 - acc: 0.5569 -- iter: 256/512
[A[ATraining Step: 89  | total loss: [1m[32m0.68738[0m[0m | time: 7.436s
[2K
| Adam | epoch: 006 | loss: 0.68738 - acc: 0.5512 -- iter: 288/512
[A[ATraining Step: 90  | total loss: [1m[32m0.68677[0m[0m | time: 8.352s
[2K
| Adam | epoch: 006 | loss: 0.68677 - acc: 0.5742 -- iter: 320/512
[A[ATraining Step: 91  | total loss: [1m[32m0.68627[0m[0m | time: 9.017s
[2K
| Adam | epoch: 006 | loss: 0.68627 - acc: 0.5887 -- iter: 352/512
[A[ATraining Step: 92  | total loss: [1m[32m0.68450[0m[0m | time: 9.674s
[2K
| Adam | epoch: 006 | loss: 0.68450 - acc: 0.6079 -- iter: 384/512
[A[ATraining Step: 93  | total loss: [1m[32m0.68384[0m[0m | time: 10.340s
[2K
| Adam | epoch: 006 | loss: 0.68384 - acc: 0.6222 -- iter: 416/512
[A[ATraining Step: 94  | total loss: [1m[32m0.68202[0m[0m | time: 10.998s
[2K
| Adam | epoch: 006 | loss: 0.68202 - acc: 0.6162 -- iter: 448/512
[A[ATraining Step: 95  | total loss: [1m[32m0.67976[0m[0m | time: 11.638s
[2K
| Adam | epoch: 006 | loss: 0.67976 - acc: 0.6233 -- iter: 480/512
[A[ATraining Step: 96  | total loss: [1m[32m0.67793[0m[0m | time: 13.296s
[2K
| Adam | epoch: 006 | loss: 0.67793 - acc: 0.6360 | val_loss: 0.65016 - val_acc: 0.6335 -- iter: 512/512
--
Training Step: 97  | total loss: [1m[32m0.67707[0m[0m | time: 0.654s
[2K
| Adam | epoch: 007 | loss: 0.67707 - acc: 0.6349 -- iter: 032/512
[A[ATraining Step: 98  | total loss: [1m[32m0.67173[0m[0m | time: 1.318s
[2K
| Adam | epoch: 007 | loss: 0.67173 - acc: 0.6433 -- iter: 064/512
[A[ATraining Step: 99  | total loss: [1m[32m0.66824[0m[0m | time: 1.974s
[2K
| Adam | epoch: 007 | loss: 0.66824 - acc: 0.6414 -- iter: 096/512
[A[ATraining Step: 100  | total loss: [1m[32m0.66380[0m[0m | time: 2.625s
[2K
| Adam | epoch: 007 | loss: 0.66380 - acc: 0.6523 -- iter: 128/512
[A[ATraining Step: 101  | total loss: [1m[32m0.66884[0m[0m | time: 3.272s
[2K
| Adam | epoch: 007 | loss: 0.66884 - acc: 0.6433 -- iter: 160/512
[A[ATraining Step: 102  | total loss: [1m[32m0.67653[0m[0m | time: 3.934s
[2K
| Adam | epoch: 007 | loss: 0.67653 - acc: 0.6321 -- iter: 192/512
[A[ATraining Step: 103  | total loss: [1m[32m0.67287[0m[0m | time: 4.590s
[2K
| Adam | epoch: 007 | loss: 0.67287 - acc: 0.6377 -- iter: 224/512
[A[ATraining Step: 104  | total loss: [1m[32m0.69120[0m[0m | time: 5.427s
[2K
| Adam | epoch: 007 | loss: 0.69120 - acc: 0.6239 -- iter: 256/512
[A[ATraining Step: 105  | total loss: [1m[32m0.69217[0m[0m | time: 6.261s
[2K
| Adam | epoch: 007 | loss: 0.69217 - acc: 0.6209 -- iter: 288/512
[A[ATraining Step: 106  | total loss: [1m[32m0.69367[0m[0m | time: 7.096s
[2K
| Adam | epoch: 007 | loss: 0.69367 - acc: 0.6119 -- iter: 320/512
[A[ATraining Step: 107  | total loss: [1m[32m0.69342[0m[0m | time: 7.975s
[2K
| Adam | epoch: 007 | loss: 0.69342 - acc: 0.6038 -- iter: 352/512
[A[ATraining Step: 108  | total loss: [1m[32m0.69035[0m[0m | time: 8.833s
[2K
| Adam | epoch: 007 | loss: 0.69035 - acc: 0.5966 -- iter: 384/512
[A[ATraining Step: 109  | total loss: [1m[32m0.68721[0m[0m | time: 9.682s
[2K
| Adam | epoch: 007 | loss: 0.68721 - acc: 0.6119 -- iter: 416/512
[A[ATraining Step: 110  | total loss: [1m[32m0.68308[0m[0m | time: 10.531s
[2K
| Adam | epoch: 007 | loss: 0.68308 - acc: 0.6320 -- iter: 448/512
[A[ATraining Step: 111  | total loss: [1m[32m0.68017[0m[0m | time: 11.392s
[2K
| Adam | epoch: 007 | loss: 0.68017 - acc: 0.6313 -- iter: 480/512
[A[ATraining Step: 112  | total loss: [1m[32m0.68455[0m[0m | time: 13.262s
[2K
| Adam | epoch: 007 | loss: 0.68455 - acc: 0.5932 | val_loss: 0.66634 - val_acc: 0.6087 -- iter: 512/512
--
Training Step: 113  | total loss: [1m[32m0.68170[0m[0m | time: 0.683s
[2K
| Adam | epoch: 008 | loss: 0.68170 - acc: 0.5901 -- iter: 032/512
[A[ATraining Step: 114  | total loss: [1m[32m0.67782[0m[0m | time: 1.367s
[2K
| Adam | epoch: 008 | loss: 0.67782 - acc: 0.5998 -- iter: 064/512
[A[ATraining Step: 115  | total loss: [1m[32m0.67772[0m[0m | time: 2.002s
[2K
| Adam | epoch: 008 | loss: 0.67772 - acc: 0.5930 -- iter: 096/512
[A[ATraining Step: 116  | total loss: [1m[32m0.67404[0m[0m | time: 2.646s
[2K
| Adam | epoch: 008 | loss: 0.67404 - acc: 0.6149 -- iter: 128/512
[A[ATraining Step: 117  | total loss: [1m[32m0.66958[0m[0m | time: 3.323s
[2K
| Adam | epoch: 008 | loss: 0.66958 - acc: 0.6284 -- iter: 160/512
[A[ATraining Step: 118  | total loss: [1m[32m0.66467[0m[0m | time: 3.974s
[2K
| Adam | epoch: 008 | loss: 0.66467 - acc: 0.6406 -- iter: 192/512
[A[ATraining Step: 119  | total loss: [1m[32m0.65912[0m[0m | time: 4.623s
[2K
| Adam | epoch: 008 | loss: 0.65912 - acc: 0.6484 -- iter: 224/512
[A[ATraining Step: 120  | total loss: [1m[32m0.65248[0m[0m | time: 5.785s
[2K
| Adam | epoch: 008 | loss: 0.65248 - acc: 0.6554 -- iter: 256/512
[A[ATraining Step: 121  | total loss: [1m[32m0.65029[0m[0m | time: 6.460s
[2K
| Adam | epoch: 008 | loss: 0.65029 - acc: 0.6618 -- iter: 288/512
[A[ATraining Step: 122  | total loss: [1m[32m0.64508[0m[0m | time: 7.120s
[2K
| Adam | epoch: 008 | loss: 0.64508 - acc: 0.6612 -- iter: 320/512
[A[ATraining Step: 123  | total loss: [1m[32m0.64065[0m[0m | time: 7.725s
[2K
| Adam | epoch: 008 | loss: 0.64065 - acc: 0.6732 -- iter: 352/512
[A[ATraining Step: 124  | total loss: [1m[32m0.63820[0m[0m | time: 8.347s
[2K
| Adam | epoch: 008 | loss: 0.63820 - acc: 0.6715 -- iter: 384/512
[A[ATraining Step: 125  | total loss: [1m[32m0.62668[0m[0m | time: 8.979s
[2K
| Adam | epoch: 008 | loss: 0.62668 - acc: 0.6794 -- iter: 416/512
[A[ATraining Step: 126  | total loss: [1m[32m0.61137[0m[0m | time: 9.580s
[2K
| Adam | epoch: 008 | loss: 0.61137 - acc: 0.6958 -- iter: 448/512
[A[ATraining Step: 127  | total loss: [1m[32m0.62251[0m[0m | time: 10.216s
[2K
| Adam | epoch: 008 | loss: 0.62251 - acc: 0.6919 -- iter: 480/512
[A[ATraining Step: 128  | total loss: [1m[32m0.61325[0m[0m | time: 11.826s
[2K
| Adam | epoch: 008 | loss: 0.61325 - acc: 0.6977 | val_loss: 0.55258 - val_acc: 0.7640 -- iter: 512/512
--
Training Step: 129  | total loss: [1m[32m0.60675[0m[0m | time: 0.628s
[2K
| Adam | epoch: 009 | loss: 0.60675 - acc: 0.7029 -- iter: 032/512
[A[ATraining Step: 130  | total loss: [1m[32m0.60581[0m[0m | time: 1.258s
[2K
| Adam | epoch: 009 | loss: 0.60581 - acc: 0.7076 -- iter: 064/512
[A[ATraining Step: 131  | total loss: [1m[32m0.59872[0m[0m | time: 1.908s
[2K
| Adam | epoch: 009 | loss: 0.59872 - acc: 0.7056 -- iter: 096/512
[A[ATraining Step: 132  | total loss: [1m[32m0.58858[0m[0m | time: 2.526s
[2K
| Adam | epoch: 009 | loss: 0.58858 - acc: 0.7069 -- iter: 128/512
[A[ATraining Step: 133  | total loss: [1m[32m0.56859[0m[0m | time: 3.139s
[2K
| Adam | epoch: 009 | loss: 0.56859 - acc: 0.7268 -- iter: 160/512
[A[ATraining Step: 134  | total loss: [1m[32m0.55630[0m[0m | time: 3.757s
[2K
| Adam | epoch: 009 | loss: 0.55630 - acc: 0.7385 -- iter: 192/512
[A[ATraining Step: 135  | total loss: [1m[32m0.54694[0m[0m | time: 4.394s
[2K
| Adam | epoch: 009 | loss: 0.54694 - acc: 0.7491 -- iter: 224/512
[A[ATraining Step: 136  | total loss: [1m[32m0.52706[0m[0m | time: 5.012s
[2K
| Adam | epoch: 009 | loss: 0.52706 - acc: 0.7585 -- iter: 256/512
[A[ATraining Step: 137  | total loss: [1m[32m0.50617[0m[0m | time: 5.602s
[2K
| Adam | epoch: 009 | loss: 0.50617 - acc: 0.7671 -- iter: 288/512
[A[ATraining Step: 138  | total loss: [1m[32m0.49736[0m[0m | time: 6.205s
[2K
| Adam | epoch: 009 | loss: 0.49736 - acc: 0.7685 -- iter: 320/512
[A[ATraining Step: 139  | total loss: [1m[32m0.48607[0m[0m | time: 6.819s
[2K
| Adam | epoch: 009 | loss: 0.48607 - acc: 0.7729 -- iter: 352/512
[A[ATraining Step: 140  | total loss: [1m[32m0.48827[0m[0m | time: 7.443s
[2K
| Adam | epoch: 009 | loss: 0.48827 - acc: 0.7675 -- iter: 384/512
[A[ATraining Step: 141  | total loss: [1m[32m0.48768[0m[0m | time: 8.048s
[2K
| Adam | epoch: 009 | loss: 0.48768 - acc: 0.7720 -- iter: 416/512
[A[ATraining Step: 142  | total loss: [1m[32m0.47980[0m[0m | time: 8.652s
[2K
| Adam | epoch: 009 | loss: 0.47980 - acc: 0.7760 -- iter: 448/512
[A[ATraining Step: 143  | total loss: [1m[32m0.45812[0m[0m | time: 9.262s
[2K
| Adam | epoch: 009 | loss: 0.45812 - acc: 0.7859 -- iter: 480/512
[A[ATraining Step: 144  | total loss: [1m[32m0.43326[0m[0m | time: 10.868s
[2K
| Adam | epoch: 009 | loss: 0.43326 - acc: 0.8011 | val_loss: 0.52521 - val_acc: 0.7764 -- iter: 512/512
--
Training Step: 145  | total loss: [1m[32m0.43058[0m[0m | time: 0.614s
[2K
| Adam | epoch: 010 | loss: 0.43058 - acc: 0.8022 -- iter: 032/512
[A[ATraining Step: 146  | total loss: [1m[32m0.42647[0m[0m | time: 1.230s
[2K
| Adam | epoch: 010 | loss: 0.42647 - acc: 0.8064 -- iter: 064/512
[A[ATraining Step: 147  | total loss: [1m[32m0.45077[0m[0m | time: 1.836s
[2K
| Adam | epoch: 010 | loss: 0.45077 - acc: 0.7945 -- iter: 096/512
[A[ATraining Step: 148  | total loss: [1m[32m0.43705[0m[0m | time: 2.450s
[2K
| Adam | epoch: 010 | loss: 0.43705 - acc: 0.8025 -- iter: 128/512
[A[ATraining Step: 149  | total loss: [1m[32m0.42663[0m[0m | time: 3.061s
[2K
| Adam | epoch: 010 | loss: 0.42663 - acc: 0.8098 -- iter: 160/512
[A[ATraining Step: 150  | total loss: [1m[32m0.41028[0m[0m | time: 3.696s
[2K
| Adam | epoch: 010 | loss: 0.41028 - acc: 0.8163 -- iter: 192/512
[A[ATraining Step: 151  | total loss: [1m[32m0.39771[0m[0m | time: 4.301s
[2K
| Adam | epoch: 010 | loss: 0.39771 - acc: 0.8253 -- iter: 224/512
[A[ATraining Step: 152  | total loss: [1m[32m0.38842[0m[0m | time: 4.949s
[2K
| Adam | epoch: 010 | loss: 0.38842 - acc: 0.8334 -- iter: 256/512
[A[ATraining Step: 153  | total loss: [1m[32m0.38344[0m[0m | time: 5.561s
[2K
| Adam | epoch: 010 | loss: 0.38344 - acc: 0.8376 -- iter: 288/512
[A[ATraining Step: 154  | total loss: [1m[32m0.37797[0m[0m | time: 6.159s
[2K
| Adam | epoch: 010 | loss: 0.37797 - acc: 0.8413 -- iter: 320/512
[A[ATraining Step: 155  | total loss: [1m[32m0.38303[0m[0m | time: 6.766s
[2K
| Adam | epoch: 010 | loss: 0.38303 - acc: 0.8384 -- iter: 352/512
[A[ATraining Step: 156  | total loss: [1m[32m0.39288[0m[0m | time: 7.375s
[2K
| Adam | epoch: 010 | loss: 0.39288 - acc: 0.8421 -- iter: 384/512
[A[ATraining Step: 157  | total loss: [1m[32m0.37423[0m[0m | time: 7.998s
[2K
| Adam | epoch: 010 | loss: 0.37423 - acc: 0.8547 -- iter: 416/512
[A[ATraining Step: 158  | total loss: [1m[32m0.36611[0m[0m | time: 8.614s
[2K
| Adam | epoch: 010 | loss: 0.36611 - acc: 0.8568 -- iter: 448/512
[A[ATraining Step: 159  | total loss: [1m[32m0.35487[0m[0m | time: 9.241s
[2K
| Adam | epoch: 010 | loss: 0.35487 - acc: 0.8617 -- iter: 480/512
[A[ATraining Step: 160  | total loss: [1m[32m0.33596[0m[0m | time: 10.838s
[2K
| Adam | epoch: 010 | loss: 0.33596 - acc: 0.8693 | val_loss: 0.39858 - val_acc: 0.8323 -- iter: 512/512
--
Training Step: 161  | total loss: [1m[32m0.32786[0m[0m | time: 0.615s
[2K
| Adam | epoch: 011 | loss: 0.32786 - acc: 0.8667 -- iter: 032/512
[A[ATraining Step: 162  | total loss: [1m[32m0.32528[0m[0m | time: 1.213s
[2K
| Adam | epoch: 011 | loss: 0.32528 - acc: 0.8707 -- iter: 064/512
[A[ATraining Step: 163  | total loss: [1m[32m0.30943[0m[0m | time: 1.820s
[2K
| Adam | epoch: 011 | loss: 0.30943 - acc: 0.8774 -- iter: 096/512
[A[ATraining Step: 164  | total loss: [1m[32m0.30092[0m[0m | time: 2.419s
[2K
| Adam | epoch: 011 | loss: 0.30092 - acc: 0.8803 -- iter: 128/512
[A[ATraining Step: 165  | total loss: [1m[32m0.31106[0m[0m | time: 3.030s
[2K
| Adam | epoch: 011 | loss: 0.31106 - acc: 0.8766 -- iter: 160/512
[A[ATraining Step: 166  | total loss: [1m[32m0.30170[0m[0m | time: 3.632s
[2K
| Adam | epoch: 011 | loss: 0.30170 - acc: 0.8827 -- iter: 192/512
[A[ATraining Step: 167  | total loss: [1m[32m0.29425[0m[0m | time: 4.260s
[2K
| Adam | epoch: 011 | loss: 0.29425 - acc: 0.8882 -- iter: 224/512
[A[ATraining Step: 168  | total loss: [1m[32m0.29461[0m[0m | time: 4.870s
[2K
| Adam | epoch: 011 | loss: 0.29461 - acc: 0.8837 -- iter: 256/512
[A[ATraining Step: 169  | total loss: [1m[32m0.28440[0m[0m | time: 5.481s
[2K
| Adam | epoch: 011 | loss: 0.28440 - acc: 0.8860 -- iter: 288/512
[A[ATraining Step: 170  | total loss: [1m[32m0.26409[0m[0m | time: 6.084s
[2K
| Adam | epoch: 011 | loss: 0.26409 - acc: 0.8974 -- iter: 320/512
[A[ATraining Step: 171  | total loss: [1m[32m0.24688[0m[0m | time: 6.703s
[2K
| Adam | epoch: 011 | loss: 0.24688 - acc: 0.9076 -- iter: 352/512
[A[ATraining Step: 172  | total loss: [1m[32m0.23708[0m[0m | time: 7.348s
[2K
| Adam | epoch: 011 | loss: 0.23708 - acc: 0.9138 -- iter: 384/512
[A[ATraining Step: 173  | total loss: [1m[32m0.23021[0m[0m | time: 7.982s
[2K
| Adam | epoch: 011 | loss: 0.23021 - acc: 0.9161 -- iter: 416/512
[A[ATraining Step: 174  | total loss: [1m[32m0.22341[0m[0m | time: 8.616s
[2K
| Adam | epoch: 011 | loss: 0.22341 - acc: 0.9214 -- iter: 448/512
[A[ATraining Step: 175  | total loss: [1m[32m0.24041[0m[0m | time: 9.251s
[2K
| Adam | epoch: 011 | loss: 0.24041 - acc: 0.9105 -- iter: 480/512
[A[ATraining Step: 176  | total loss: [1m[32m0.22778[0m[0m | time: 10.862s
[2K
| Adam | epoch: 011 | loss: 0.22778 - acc: 0.9132 | val_loss: 0.35767 - val_acc: 0.8447 -- iter: 512/512
--
Training Step: 177  | total loss: [1m[32m0.24478[0m[0m | time: 0.612s
[2K
| Adam | epoch: 012 | loss: 0.24478 - acc: 0.9063 -- iter: 032/512
[A[ATraining Step: 178  | total loss: [1m[32m0.23119[0m[0m | time: 1.219s
[2K
| Adam | epoch: 012 | loss: 0.23119 - acc: 0.9125 -- iter: 064/512
[A[ATraining Step: 179  | total loss: [1m[32m0.22340[0m[0m | time: 1.816s
[2K
| Adam | epoch: 012 | loss: 0.22340 - acc: 0.9150 -- iter: 096/512
[A[ATraining Step: 180  | total loss: [1m[32m0.21266[0m[0m | time: 2.432s
[2K
| Adam | epoch: 012 | loss: 0.21266 - acc: 0.9204 -- iter: 128/512
[A[ATraining Step: 181  | total loss: [1m[32m0.21282[0m[0m | time: 3.068s
[2K
| Adam | epoch: 012 | loss: 0.21282 - acc: 0.9190 -- iter: 160/512
[A[ATraining Step: 182  | total loss: [1m[32m0.20084[0m[0m | time: 3.701s
[2K
| Adam | epoch: 012 | loss: 0.20084 - acc: 0.9271 -- iter: 192/512
[A[ATraining Step: 183  | total loss: [1m[32m0.20327[0m[0m | time: 4.302s
[2K
| Adam | epoch: 012 | loss: 0.20327 - acc: 0.9250 -- iter: 224/512
[A[ATraining Step: 184  | total loss: [1m[32m0.19817[0m[0m | time: 4.914s
[2K
| Adam | epoch: 012 | loss: 0.19817 - acc: 0.9294 -- iter: 256/512
[A[ATraining Step: 185  | total loss: [1m[32m0.19856[0m[0m | time: 5.519s
[2K
| Adam | epoch: 012 | loss: 0.19856 - acc: 0.9333 -- iter: 288/512
[A[ATraining Step: 186  | total loss: [1m[32m0.19594[0m[0m | time: 6.146s
[2K
| Adam | epoch: 012 | loss: 0.19594 - acc: 0.9337 -- iter: 320/512
[A[ATraining Step: 187  | total loss: [1m[32m0.18445[0m[0m | time: 6.764s
[2K
| Adam | epoch: 012 | loss: 0.18445 - acc: 0.9404 -- iter: 352/512
[A[ATraining Step: 188  | total loss: [1m[32m0.17319[0m[0m | time: 7.364s
[2K
| Adam | epoch: 012 | loss: 0.17319 - acc: 0.9463 -- iter: 384/512
[A[ATraining Step: 189  | total loss: [1m[32m0.16349[0m[0m | time: 7.992s
[2K
| Adam | epoch: 012 | loss: 0.16349 - acc: 0.9486 -- iter: 416/512
[A[ATraining Step: 190  | total loss: [1m[32m0.15994[0m[0m | time: 8.601s
[2K
| Adam | epoch: 012 | loss: 0.15994 - acc: 0.9506 -- iter: 448/512
[A[ATraining Step: 191  | total loss: [1m[32m0.14741[0m[0m | time: 9.225s
[2K
| Adam | epoch: 012 | loss: 0.14741 - acc: 0.9555 -- iter: 480/512
[A[ATraining Step: 192  | total loss: [1m[32m0.15483[0m[0m | time: 10.835s
[2K
| Adam | epoch: 012 | loss: 0.15483 - acc: 0.9537 | val_loss: 0.38100 - val_acc: 0.8509 -- iter: 512/512
--
Training Step: 193  | total loss: [1m[32m0.15903[0m[0m | time: 0.608s
[2K
| Adam | epoch: 013 | loss: 0.15903 - acc: 0.9490 -- iter: 032/512
[A[ATraining Step: 194  | total loss: [1m[32m0.14575[0m[0m | time: 1.217s
[2K
| Adam | epoch: 013 | loss: 0.14575 - acc: 0.9541 -- iter: 064/512
[A[ATraining Step: 195  | total loss: [1m[32m0.13255[0m[0m | time: 1.818s
[2K
| Adam | epoch: 013 | loss: 0.13255 - acc: 0.9587 -- iter: 096/512
[A[ATraining Step: 196  | total loss: [1m[32m0.12144[0m[0m | time: 2.431s
[2K
| Adam | epoch: 013 | loss: 0.12144 - acc: 0.9628 -- iter: 128/512
[A[ATraining Step: 197  | total loss: [1m[32m0.12084[0m[0m | time: 3.056s
[2K
| Adam | epoch: 013 | loss: 0.12084 - acc: 0.9634 -- iter: 160/512
[A[ATraining Step: 198  | total loss: [1m[32m0.11507[0m[0m | time: 3.666s
[2K
| Adam | epoch: 013 | loss: 0.11507 - acc: 0.9639 -- iter: 192/512
[A[ATraining Step: 199  | total loss: [1m[32m0.10889[0m[0m | time: 4.277s
[2K
| Adam | epoch: 013 | loss: 0.10889 - acc: 0.9644 -- iter: 224/512
[A[ATraining Step: 200  | total loss: [1m[32m0.10132[0m[0m | time: 5.879s
[2K
| Adam | epoch: 013 | loss: 0.10132 - acc: 0.9680 | val_loss: 0.48041 - val_acc: 0.8509 -- iter: 256/512
--
Training Step: 201  | total loss: [1m[32m0.10613[0m[0m | time: 6.509s
[2K
| Adam | epoch: 013 | loss: 0.10613 - acc: 0.9618 -- iter: 288/512
[A[ATraining Step: 202  | total loss: [1m[32m0.13850[0m[0m | time: 7.124s
[2K
| Adam | epoch: 013 | loss: 0.13850 - acc: 0.9562 -- iter: 320/512
[A[ATraining Step: 203  | total loss: [1m[32m0.13797[0m[0m | time: 7.721s
[2K
| Adam | epoch: 013 | loss: 0.13797 - acc: 0.9575 -- iter: 352/512
[A[ATraining Step: 204  | total loss: [1m[32m0.14840[0m[0m | time: 8.339s
[2K
| Adam | epoch: 013 | loss: 0.14840 - acc: 0.9555 -- iter: 384/512
[A[ATraining Step: 205  | total loss: [1m[32m0.15101[0m[0m | time: 8.944s
[2K
| Adam | epoch: 013 | loss: 0.15101 - acc: 0.9537 -- iter: 416/512
[A[ATraining Step: 206  | total loss: [1m[32m0.15508[0m[0m | time: 9.538s
[2K
| Adam | epoch: 013 | loss: 0.15508 - acc: 0.9552 -- iter: 448/512
[A[ATraining Step: 207  | total loss: [1m[32m0.14919[0m[0m | time: 10.137s
[2K
| Adam | epoch: 013 | loss: 0.14919 - acc: 0.9566 -- iter: 480/512
[A[ATraining Step: 208  | total loss: [1m[32m0.13677[0m[0m | time: 11.747s
[2K
| Adam | epoch: 013 | loss: 0.13677 - acc: 0.9609 | val_loss: 0.30788 - val_acc: 0.8634 -- iter: 512/512
--
Training Step: 209  | total loss: [1m[32m0.13138[0m[0m | time: 0.649s
[2K
| Adam | epoch: 014 | loss: 0.13138 - acc: 0.9617 -- iter: 032/512
[A[ATraining Step: 210  | total loss: [1m[32m0.12583[0m[0m | time: 1.246s
[2K
| Adam | epoch: 014 | loss: 0.12583 - acc: 0.9624 -- iter: 064/512
[A[ATraining Step: 211  | total loss: [1m[32m0.11787[0m[0m | time: 1.853s
[2K
| Adam | epoch: 014 | loss: 0.11787 - acc: 0.9662 -- iter: 096/512
[A[ATraining Step: 212  | total loss: [1m[32m0.11295[0m[0m | time: 2.451s
[2K
| Adam | epoch: 014 | loss: 0.11295 - acc: 0.9664 -- iter: 128/512
[A[ATraining Step: 213  | total loss: [1m[32m0.11268[0m[0m | time: 3.078s
[2K
| Adam | epoch: 014 | loss: 0.11268 - acc: 0.9666 -- iter: 160/512
[A[ATraining Step: 214  | total loss: [1m[32m0.10844[0m[0m | time: 3.679s
[2K
| Adam | epoch: 014 | loss: 0.10844 - acc: 0.9669 -- iter: 192/512
[A[ATraining Step: 215  | total loss: [1m[32m0.11022[0m[0m | time: 4.318s
[2K
| Adam | epoch: 014 | loss: 0.11022 - acc: 0.9639 -- iter: 224/512
[A[ATraining Step: 216  | total loss: [1m[32m0.11603[0m[0m | time: 4.927s
[2K
| Adam | epoch: 014 | loss: 0.11603 - acc: 0.9613 -- iter: 256/512
[A[ATraining Step: 217  | total loss: [1m[32m0.11068[0m[0m | time: 5.531s
[2K
| Adam | epoch: 014 | loss: 0.11068 - acc: 0.9620 -- iter: 288/512
[A[ATraining Step: 218  | total loss: [1m[32m0.10272[0m[0m | time: 6.143s
[2K
| Adam | epoch: 014 | loss: 0.10272 - acc: 0.9658 -- iter: 320/512
[A[ATraining Step: 219  | total loss: [1m[32m0.09464[0m[0m | time: 6.730s
[2K
| Adam | epoch: 014 | loss: 0.09464 - acc: 0.9692 -- iter: 352/512
[A[ATraining Step: 220  | total loss: [1m[32m0.10764[0m[0m | time: 7.341s
[2K
| Adam | epoch: 014 | loss: 0.10764 - acc: 0.9629 -- iter: 384/512
[A[ATraining Step: 221  | total loss: [1m[32m0.09956[0m[0m | time: 7.944s
[2K
| Adam | epoch: 014 | loss: 0.09956 - acc: 0.9666 -- iter: 416/512
[A[ATraining Step: 222  | total loss: [1m[32m0.09149[0m[0m | time: 8.566s
[2K
| Adam | epoch: 014 | loss: 0.09149 - acc: 0.9700 -- iter: 448/512
[A[ATraining Step: 223  | total loss: [1m[32m0.10246[0m[0m | time: 9.182s
[2K
| Adam | epoch: 014 | loss: 0.10246 - acc: 0.9667 -- iter: 480/512
[A[ATraining Step: 224  | total loss: [1m[32m0.10162[0m[0m | time: 10.980s
[2K
| Adam | epoch: 014 | loss: 0.10162 - acc: 0.9638 | val_loss: 0.38158 - val_acc: 0.8882 -- iter: 512/512
--
Training Step: 225  | total loss: [1m[32m0.09359[0m[0m | time: 0.615s
[2K
| Adam | epoch: 015 | loss: 0.09359 - acc: 0.9674 -- iter: 032/512
[A[ATraining Step: 226  | total loss: [1m[32m0.08495[0m[0m | time: 1.222s
[2K
| Adam | epoch: 015 | loss: 0.08495 - acc: 0.9707 -- iter: 064/512
[A[ATraining Step: 227  | total loss: [1m[32m0.07849[0m[0m | time: 1.832s
[2K
| Adam | epoch: 015 | loss: 0.07849 - acc: 0.9736 -- iter: 096/512
[A[ATraining Step: 228  | total loss: [1m[32m0.07203[0m[0m | time: 2.440s
[2K
| Adam | epoch: 015 | loss: 0.07203 - acc: 0.9763 -- iter: 128/512
[A[ATraining Step: 229  | total loss: [1m[32m0.08188[0m[0m | time: 3.058s
[2K
| Adam | epoch: 015 | loss: 0.08188 - acc: 0.9755 -- iter: 160/512
[A[ATraining Step: 230  | total loss: [1m[32m0.07535[0m[0m | time: 3.667s
[2K
| Adam | epoch: 015 | loss: 0.07535 - acc: 0.9780 -- iter: 192/512
[A[ATraining Step: 231  | total loss: [1m[32m0.06882[0m[0m | time: 4.295s
[2K
| Adam | epoch: 015 | loss: 0.06882 - acc: 0.9802 -- iter: 224/512
[A[ATraining Step: 232  | total loss: [1m[32m0.07068[0m[0m | time: 4.901s
[2K
| Adam | epoch: 015 | loss: 0.07068 - acc: 0.9790 -- iter: 256/512
[A[ATraining Step: 233  | total loss: [1m[32m0.06522[0m[0m | time: 5.510s
[2K
| Adam | epoch: 015 | loss: 0.06522 - acc: 0.9811 -- iter: 288/512
[A[ATraining Step: 234  | total loss: [1m[32m0.07383[0m[0m | time: 6.109s
[2K
| Adam | epoch: 015 | loss: 0.07383 - acc: 0.9799 -- iter: 320/512
[A[ATraining Step: 235  | total loss: [1m[32m0.08839[0m[0m | time: 6.724s
[2K
| Adam | epoch: 015 | loss: 0.08839 - acc: 0.9756 -- iter: 352/512
[A[ATraining Step: 236  | total loss: [1m[32m0.08418[0m[0m | time: 7.332s
[2K
| Adam | epoch: 015 | loss: 0.08418 - acc: 0.9750 -- iter: 384/512
[A[ATraining Step: 237  | total loss: [1m[32m0.07710[0m[0m | time: 7.937s
[2K
| Adam | epoch: 015 | loss: 0.07710 - acc: 0.9775 -- iter: 416/512
[A[ATraining Step: 238  | total loss: [1m[32m0.07094[0m[0m | time: 8.539s
[2K
| Adam | epoch: 015 | loss: 0.07094 - acc: 0.9797 -- iter: 448/512
[A[ATraining Step: 239  | total loss: [1m[32m0.06634[0m[0m | time: 9.152s
[2K
| Adam | epoch: 015 | loss: 0.06634 - acc: 0.9817 -- iter: 480/512
[A[ATraining Step: 240  | total loss: [1m[32m0.06092[0m[0m | time: 10.762s
[2K
| Adam | epoch: 015 | loss: 0.06092 - acc: 0.9836 | val_loss: 0.36929 - val_acc: 0.8820 -- iter: 512/512
--
Validation AUC:0.9489164086687307
Validation AUPRC:0.9490049653090045
Test AUC:0.9735866543095459
Test AUPRC:0.9698869734417372
BestTestF1Score	0.89	0.8	0.9	0.93	0.86	67	5	78	11	0.27
BestTestMCCScore	0.89	0.8	0.9	0.93	0.86	67	5	78	11	0.27
BestTestAccuracyScore	0.89	0.8	0.9	0.93	0.86	67	5	78	11	0.27
BestValidationF1Score	0.9	0.82	0.91	0.94	0.86	65	4	81	11	0.27
BestValidationMCC	0.9	0.82	0.91	0.94	0.86	65	4	81	11	0.27
BestValidationAccuracy	0.9	0.82	0.91	0.94	0.86	65	4	81	11	0.27
TestPredictions (Threshold:0.27)
CHEMBL549557,TP,ACT,0.9700000286102295	CHEMBL124819,TP,ACT,0.9900000095367432	CHEMBL3360841,TN,INACT,0.029999999329447746	CHEMBL203777,TP,ACT,1.0	CHEMBL3109602,TN,INACT,0.009999999776482582	CHEMBL41036,TP,ACT,1.0	CHEMBL440975,TP,ACT,0.9900000095367432	CHEMBL160703,FN,ACT,0.2199999988079071	CHEMBL236339,TN,INACT,0.05000000074505806	CHEMBL2312271,TP,ACT,1.0	CHEMBL556270,TP,ACT,0.9800000190734863	CHEMBL1642353,TN,INACT,0.0	CHEMBL485928,TP,ACT,1.0	CHEMBL550441,TN,INACT,0.0	CHEMBL442082,TP,ACT,0.4399999976158142	CHEMBL465800,TN,INACT,0.0	CHEMBL1327417,TN,INACT,0.0	CHEMBL3397343,TP,ACT,1.0	CHEMBL235164,TP,ACT,1.0	CHEMBL1808555,TN,INACT,0.0	CHEMBL250308,FN,ACT,0.1899999976158142	CHEMBL1560288,FP,INACT,0.49000000953674316	CHEMBL1539235,TN,INACT,0.019999999552965164	CHEMBL202336,FN,ACT,0.05999999865889549	CHEMBL85322,TN,INACT,0.0	CHEMBL195855,FN,ACT,0.07000000029802322	CHEMBL82293,TN,INACT,0.019999999552965164	CHEMBL550846,TP,ACT,0.9900000095367432	CHEMBL413699,TP,ACT,0.699999988079071	CHEMBL519215,TP,ACT,1.0	CHEMBL552310,TN,INACT,0.0	CHEMBL2204691,TN,INACT,0.0	CHEMBL2035878,TP,ACT,0.9900000095367432	CHEMBL1392628,TN,INACT,0.009999999776482582	CHEMBL569845,TP,ACT,0.9800000190734863	CHEMBL1365170,TN,INACT,0.0	CHEMBL236134,FP,INACT,0.9700000286102295	CHEMBL193615,TP,ACT,0.9900000095367432	CHEMBL40738,TP,ACT,0.9700000286102295	CHEMBL553624,TP,ACT,0.9800000190734863	CHEMBL119111,TN,INACT,0.009999999776482582	CHEMBL3397333,FN,ACT,0.1599999964237213	CHEMBL1818099,TN,INACT,0.11999999731779099	CHEMBL112087,TP,ACT,0.5799999833106995	CHEMBL249895,TP,ACT,0.6399999856948853	CHEMBL3261326,TP,ACT,0.9900000095367432	CHEMBL3261325,TP,ACT,1.0	CHEMBL2335811,TN,INACT,0.029999999329447746	CHEMBL3126373,FN,ACT,0.05000000074505806	CHEMBL562250,FP,INACT,0.9800000190734863	CHEMBL442243,TP,ACT,0.9900000095367432	CHEMBL2159606,TN,INACT,0.0	CHEMBL1504516,TN,INACT,0.019999999552965164	CHEMBL551965,TP,ACT,0.9800000190734863	CHEMBL2035876,TP,ACT,1.0	CHEMBL2070870,TN,INACT,0.0	CHEMBL552392,TP,ACT,0.9700000286102295	CHEMBL3261319,TP,ACT,0.9800000190734863	CHEMBL555749,TP,ACT,0.9900000095367432	CHEMBL1349382,TN,INACT,0.009999999776482582	CHEMBL2312280,TP,ACT,1.0	CHEMBL1479248,TN,INACT,0.0	CHEMBL251090,TP,ACT,0.9800000190734863	CHEMBL396304,TP,ACT,1.0	CHEMBL1328182,TN,INACT,0.12999999523162842	CHEMBL237822,TN,INACT,0.05999999865889549	CHEMBL550094,TP,ACT,0.9700000286102295	CHEMBL2070854,TN,INACT,0.019999999552965164	CHEMBL561050,TP,ACT,0.9399999976158142	CHEMBL3109606,TN,INACT,0.009999999776482582	CHEMBL3138035,TN,INACT,0.019999999552965164	CHEMBL551248,TN,INACT,0.0	CHEMBL3613431,FP,INACT,0.8100000023841858	CHEMBL563943,TP,ACT,1.0	CHEMBL563816,TP,ACT,1.0	CHEMBL206426,TN,INACT,0.0	CHEMBL2011543,TN,INACT,0.029999999329447746	CHEMBL240331,TN,INACT,0.0	CHEMBL3397336,TP,ACT,0.9900000095367432	CHEMBL572348,TP,ACT,0.9399999976158142	CHEMBL2312265,TP,ACT,1.0	CHEMBL458899,TN,INACT,0.019999999552965164	CHEMBL107789,TN,INACT,0.0	CHEMBL3263237,TN,INACT,0.0	CHEMBL2348881,TN,INACT,0.019999999552965164	CHEMBL396086,TP,ACT,0.9800000190734863	CHEMBL495123,TN,INACT,0.07999999821186066	CHEMBL550758,TP,ACT,0.9399999976158142	CHEMBL3397548,TN,INACT,0.0	CHEMBL2011540,TN,INACT,0.009999999776482582	CHEMBL192490,TP,ACT,0.9300000071525574	CHEMBL395602,TP,ACT,0.4300000071525574	CHEMBL549889,TP,ACT,0.9900000095367432	CHEMBL559718,TP,ACT,0.9700000286102295	CHEMBL2070875,TN,INACT,0.009999999776482582	CHEMBL3752848,TN,INACT,0.0	CHEMBL1612543,TN,INACT,0.0	CHEMBL590586,TN,INACT,0.009999999776482582	CHEMBL550752,TP,ACT,0.9800000190734863	CHEMBL550760,TP,ACT,0.9800000190734863	CHEMBL2348903,TN,INACT,0.019999999552965164	CHEMBL1345363,TN,INACT,0.009999999776482582	CHEMBL3109600,TN,INACT,0.029999999329447746	CHEMBL1496995,TN,INACT,0.009999999776482582	CHEMBL1976046,TN,INACT,0.0	CHEMBL572341,TP,ACT,1.0	CHEMBL2348879,TN,INACT,0.0	CHEMBL3764510,FP,INACT,0.38999998569488525	CHEMBL488991,TN,INACT,0.0	CHEMBL483035,TN,INACT,0.019999999552965164	CHEMBL217221,TP,ACT,0.44999998807907104	CHEMBL1471055,TN,INACT,0.03999999910593033	CHEMBL560568,TP,ACT,0.9800000190734863	CHEMBL552158,TP,ACT,0.9399999976158142	CHEMBL1808552,TN,INACT,0.0	CHEMBL2381203,TN,INACT,0.029999999329447746	CHEMBL358546,TN,INACT,0.0	CHEMBL2312279,FN,ACT,0.05999999865889549	CHEMBL340490,TP,ACT,0.9800000190734863	CHEMBL2312276,FN,ACT,0.2199999988079071	CHEMBL111077,TN,INACT,0.019999999552965164	CHEMBL394678,TN,INACT,0.0	CHEMBL492046,TN,INACT,0.0	CHEMBL124145,TP,ACT,0.9800000190734863	CHEMBL2348872,TN,INACT,0.0	CHEMBL194242,TP,ACT,0.6399999856948853	CHEMBL118617,TN,INACT,0.0	CHEMBL3623105,TN,INACT,0.0	CHEMBL3397344,TP,ACT,0.9900000095367432	CHEMBL1449293,TN,INACT,0.019999999552965164	CHEMBL2070878,TN,INACT,0.0	CHEMBL552105,TP,ACT,0.9800000190734863	CHEMBL550845,TP,ACT,0.9700000286102295	CHEMBL1535180,TN,INACT,0.0	CHEMBL1424125,TN,INACT,0.0	CHEMBL325405,FN,ACT,0.019999999552965164	CHEMBL482593,TN,INACT,0.0	CHEMBL683,TN,INACT,0.009999999776482582	CHEMBL1524916,TN,INACT,0.05000000074505806	CHEMBL196642,TP,ACT,1.0	CHEMBL562173,TP,ACT,1.0	CHEMBL46403,TN,INACT,0.019999999552965164	CHEMBL3397340,TP,ACT,0.9900000095367432	CHEMBL457,TN,INACT,0.009999999776482582	CHEMBL3397913,TN,INACT,0.019999999552965164	CHEMBL333798,TP,ACT,0.27000001072883606	CHEMBL1559172,TN,INACT,0.1899999976158142	CHEMBL163228,TP,ACT,0.9900000095367432	CHEMBL3753560,TN,INACT,0.0	CHEMBL3261318,TP,ACT,0.9900000095367432	CHEMBL2325060,TN,INACT,0.019999999552965164	CHEMBL2386488,TN,INACT,0.029999999329447746	CHEMBL236500,TP,ACT,0.9900000095367432	CHEMBL371245,TP,ACT,0.949999988079071	CHEMBL330814,FN,ACT,0.029999999329447746	CHEMBL551450,TP,ACT,0.9800000190734863	CHEMBL561051,TP,ACT,0.9800000190734863	CHEMBL3623106,TN,INACT,0.019999999552965164	CHEMBL1971613,TN,INACT,0.0	CHEMBL2381198,TN,INACT,0.009999999776482582	CHEMBL2035883,FN,ACT,0.07000000029802322	

