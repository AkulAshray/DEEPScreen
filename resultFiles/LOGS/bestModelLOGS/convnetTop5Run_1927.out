CNNModel CHEMBL245 adam 0.0005 15 256 0 0.6 False True
Number of active compounds :	1291
Number of inactive compounds :	1291
---------------------------------
Run id: CNNModel_CHEMBL245_adam_0.0005_15_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL245_adam_0.0005_15_256_0.6_True/
---------------------------------
Training samples: 1592
Validation samples: 498
--
Training Step: 1  | time: 1.011s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1592
[A[ATraining Step: 2  | total loss: [1m[32m0.62386[0m[0m | time: 1.822s
[2K
| Adam | epoch: 001 | loss: 0.62386 - acc: 0.4219 -- iter: 0064/1592
[A[ATraining Step: 3  | total loss: [1m[32m0.68108[0m[0m | time: 2.548s
[2K
| Adam | epoch: 001 | loss: 0.68108 - acc: 0.3580 -- iter: 0096/1592
[A[ATraining Step: 4  | total loss: [1m[32m0.69035[0m[0m | time: 3.303s
[2K
| Adam | epoch: 001 | loss: 0.69035 - acc: 0.4411 -- iter: 0128/1592
[A[ATraining Step: 5  | total loss: [1m[32m0.69268[0m[0m | time: 4.105s
[2K
| Adam | epoch: 001 | loss: 0.69268 - acc: 0.4602 -- iter: 0160/1592
[A[ATraining Step: 6  | total loss: [1m[32m0.69241[0m[0m | time: 4.883s
[2K
| Adam | epoch: 001 | loss: 0.69241 - acc: 0.5260 -- iter: 0192/1592
[A[ATraining Step: 7  | total loss: [1m[32m0.69370[0m[0m | time: 5.759s
[2K
| Adam | epoch: 001 | loss: 0.69370 - acc: 0.4916 -- iter: 0224/1592
[A[ATraining Step: 8  | total loss: [1m[32m0.69467[0m[0m | time: 6.967s
[2K
| Adam | epoch: 001 | loss: 0.69467 - acc: 0.4436 -- iter: 0256/1592
[A[ATraining Step: 9  | total loss: [1m[32m0.69485[0m[0m | time: 8.232s
[2K
| Adam | epoch: 001 | loss: 0.69485 - acc: 0.4238 -- iter: 0288/1592
[A[ATraining Step: 10  | total loss: [1m[32m0.69400[0m[0m | time: 9.534s
[2K
| Adam | epoch: 001 | loss: 0.69400 - acc: 0.4932 -- iter: 0320/1592
[A[ATraining Step: 11  | total loss: [1m[32m0.69355[0m[0m | time: 13.563s
[2K
| Adam | epoch: 001 | loss: 0.69355 - acc: 0.4816 -- iter: 0352/1592
[A[ATraining Step: 12  | total loss: [1m[32m0.69332[0m[0m | time: 30.762s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.4899 -- iter: 0384/1592
[A[ATraining Step: 13  | total loss: [1m[32m0.69333[0m[0m | time: 31.877s
[2K
| Adam | epoch: 001 | loss: 0.69333 - acc: 0.4674 -- iter: 0416/1592
[A[ATraining Step: 14  | total loss: [1m[32m0.69352[0m[0m | time: 32.974s
[2K
| Adam | epoch: 001 | loss: 0.69352 - acc: 0.4296 -- iter: 0448/1592
[A[ATraining Step: 15  | total loss: [1m[32m0.69325[0m[0m | time: 34.049s
[2K
| Adam | epoch: 001 | loss: 0.69325 - acc: 0.4938 -- iter: 0480/1592
[A[ATraining Step: 16  | total loss: [1m[32m0.69331[0m[0m | time: 35.179s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.4727 -- iter: 0512/1592
[A[ATraining Step: 17  | total loss: [1m[32m0.69332[0m[0m | time: 36.458s
[2K
| Adam | epoch: 001 | loss: 0.69332 - acc: 0.4488 -- iter: 0544/1592
[A[ATraining Step: 18  | total loss: [1m[32m0.69327[0m[0m | time: 37.635s
[2K
| Adam | epoch: 001 | loss: 0.69327 - acc: 0.4773 -- iter: 0576/1592
[A[ATraining Step: 19  | total loss: [1m[32m0.69307[0m[0m | time: 38.598s
[2K
| Adam | epoch: 001 | loss: 0.69307 - acc: 0.5370 -- iter: 0608/1592
[A[ATraining Step: 20  | total loss: [1m[32m0.69319[0m[0m | time: 39.865s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5150 -- iter: 0640/1592
[A[ATraining Step: 21  | total loss: [1m[32m0.69318[0m[0m | time: 41.095s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.5104 -- iter: 0672/1592
[A[ATraining Step: 22  | total loss: [1m[32m0.69277[0m[0m | time: 42.160s
[2K
| Adam | epoch: 001 | loss: 0.69277 - acc: 0.5541 -- iter: 0704/1592
[A[ATraining Step: 23  | total loss: [1m[32m0.69313[0m[0m | time: 49.145s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.5203 -- iter: 0736/1592
[A[ATraining Step: 24  | total loss: [1m[32m0.69321[0m[0m | time: 59.442s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.5146 -- iter: 0768/1592
[A[ATraining Step: 25  | total loss: [1m[32m0.69262[0m[0m | time: 60.508s
[2K
| Adam | epoch: 001 | loss: 0.69262 - acc: 0.5447 -- iter: 0800/1592
[A[ATraining Step: 26  | total loss: [1m[32m0.69244[0m[0m | time: 61.674s
[2K
| Adam | epoch: 001 | loss: 0.69244 - acc: 0.5494 -- iter: 0832/1592
[A[ATraining Step: 27  | total loss: [1m[32m0.69265[0m[0m | time: 62.869s
[2K
| Adam | epoch: 001 | loss: 0.69265 - acc: 0.5367 -- iter: 0864/1592
[A[ATraining Step: 28  | total loss: [1m[32m0.69253[0m[0m | time: 64.080s
[2K
| Adam | epoch: 001 | loss: 0.69253 - acc: 0.5353 -- iter: 0896/1592
[A[ATraining Step: 29  | total loss: [1m[32m0.69339[0m[0m | time: 65.385s
[2K
| Adam | epoch: 001 | loss: 0.69339 - acc: 0.5115 -- iter: 0928/1592
[A[ATraining Step: 30  | total loss: [1m[32m0.69437[0m[0m | time: 66.457s
[2K
| Adam | epoch: 001 | loss: 0.69437 - acc: 0.4866 -- iter: 0960/1592
[A[ATraining Step: 31  | total loss: [1m[32m0.69355[0m[0m | time: 67.444s
[2K
| Adam | epoch: 001 | loss: 0.69355 - acc: 0.5041 -- iter: 0992/1592
[A[ATraining Step: 32  | total loss: [1m[32m0.69317[0m[0m | time: 68.664s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.5102 -- iter: 1024/1592
[A[ATraining Step: 33  | total loss: [1m[32m0.69370[0m[0m | time: 69.818s
[2K
| Adam | epoch: 001 | loss: 0.69370 - acc: 0.4943 -- iter: 1056/1592
[A[ATraining Step: 34  | total loss: [1m[32m0.69380[0m[0m | time: 71.317s
[2K
| Adam | epoch: 001 | loss: 0.69380 - acc: 0.4888 -- iter: 1088/1592
[A[ATraining Step: 35  | total loss: [1m[32m0.69374[0m[0m | time: 74.633s
[2K
| Adam | epoch: 001 | loss: 0.69374 - acc: 0.4911 -- iter: 1120/1592
[A[ATraining Step: 36  | total loss: [1m[32m0.69348[0m[0m | time: 85.675s
[2K
| Adam | epoch: 001 | loss: 0.69348 - acc: 0.4993 -- iter: 1152/1592
[A[ATraining Step: 37  | total loss: [1m[32m0.69313[0m[0m | time: 86.728s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.5120 -- iter: 1184/1592
[A[ATraining Step: 38  | total loss: [1m[32m0.69313[0m[0m | time: 87.756s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.5096 -- iter: 1216/1592
[A[ATraining Step: 39  | total loss: [1m[32m0.69316[0m[0m | time: 88.864s
[2K
| Adam | epoch: 001 | loss: 0.69316 - acc: 0.5078 -- iter: 1248/1592
[A[ATraining Step: 40  | total loss: [1m[32m0.69272[0m[0m | time: 89.976s
[2K
| Adam | epoch: 001 | loss: 0.69272 - acc: 0.5239 -- iter: 1280/1592
[A[ATraining Step: 41  | total loss: [1m[32m0.69280[0m[0m | time: 91.288s
[2K
| Adam | epoch: 001 | loss: 0.69280 - acc: 0.5195 -- iter: 1312/1592
[A[ATraining Step: 42  | total loss: [1m[32m0.69270[0m[0m | time: 92.473s
[2K
| Adam | epoch: 001 | loss: 0.69270 - acc: 0.5216 -- iter: 1344/1592
[A[ATraining Step: 43  | total loss: [1m[32m0.69313[0m[0m | time: 93.410s
[2K
| Adam | epoch: 001 | loss: 0.69313 - acc: 0.5068 -- iter: 1376/1592
[A[ATraining Step: 44  | total loss: [1m[32m0.69298[0m[0m | time: 94.683s
[2K
| Adam | epoch: 001 | loss: 0.69298 - acc: 0.5110 -- iter: 1408/1592
[A[ATraining Step: 45  | total loss: [1m[32m0.69303[0m[0m | time: 95.882s
[2K
| Adam | epoch: 001 | loss: 0.69303 - acc: 0.5091 -- iter: 1440/1592
[A[ATraining Step: 46  | total loss: [1m[32m0.69336[0m[0m | time: 97.080s
[2K
| Adam | epoch: 001 | loss: 0.69336 - acc: 0.4972 -- iter: 1472/1592
[A[ATraining Step: 47  | total loss: [1m[32m0.69304[0m[0m | time: 106.691s
[2K
| Adam | epoch: 001 | loss: 0.69304 - acc: 0.5079 -- iter: 1504/1592
[A[ATraining Step: 48  | total loss: [1m[32m0.69295[0m[0m | time: 107.744s
[2K
| Adam | epoch: 001 | loss: 0.69295 - acc: 0.5116 -- iter: 1536/1592
[A[ATraining Step: 49  | total loss: [1m[32m0.69315[0m[0m | time: 108.887s
[2K
| Adam | epoch: 001 | loss: 0.69315 - acc: 0.5049 -- iter: 1568/1592
[A[ATraining Step: 50  | total loss: [1m[32m0.69248[0m[0m | time: 113.270s
[2K
| Adam | epoch: 001 | loss: 0.69248 - acc: 0.5284 | val_loss: 0.69365 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 51  | total loss: [1m[32m0.69243[0m[0m | time: 0.877s
[2K
| Adam | epoch: 002 | loss: 0.69243 - acc: 0.5304 -- iter: 0032/1592
[A[ATraining Step: 52  | total loss: [1m[32m0.69238[0m[0m | time: 2.058s
[2K
| Adam | epoch: 002 | loss: 0.69238 - acc: 0.5321 -- iter: 0064/1592
[A[ATraining Step: 53  | total loss: [1m[32m0.69205[0m[0m | time: 3.393s
[2K
| Adam | epoch: 002 | loss: 0.69205 - acc: 0.5412 -- iter: 0096/1592
[A[ATraining Step: 54  | total loss: [1m[32m0.69207[0m[0m | time: 4.662s
[2K
| Adam | epoch: 002 | loss: 0.69207 - acc: 0.5397 -- iter: 0128/1592
[A[ATraining Step: 55  | total loss: [1m[32m0.69137[0m[0m | time: 22.119s
[2K
| Adam | epoch: 002 | loss: 0.69137 - acc: 0.5564 -- iter: 0160/1592
[A[ATraining Step: 56  | total loss: [1m[32m0.69166[0m[0m | time: 23.203s
[2K
| Adam | epoch: 002 | loss: 0.69166 - acc: 0.5485 -- iter: 0192/1592
[A[ATraining Step: 57  | total loss: [1m[32m0.69126[0m[0m | time: 24.382s
[2K
| Adam | epoch: 002 | loss: 0.69126 - acc: 0.5547 -- iter: 0224/1592
[A[ATraining Step: 58  | total loss: [1m[32m0.69263[0m[0m | time: 25.517s
[2K
| Adam | epoch: 002 | loss: 0.69263 - acc: 0.5302 -- iter: 0256/1592
[A[ATraining Step: 59  | total loss: [1m[32m0.69327[0m[0m | time: 26.787s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.5178 -- iter: 0288/1592
[A[ATraining Step: 60  | total loss: [1m[32m0.69332[0m[0m | time: 28.006s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.5154 -- iter: 0320/1592
[A[ATraining Step: 61  | total loss: [1m[32m0.69501[0m[0m | time: 29.167s
[2K
| Adam | epoch: 002 | loss: 0.69501 - acc: 0.4849 -- iter: 0352/1592
[A[ATraining Step: 62  | total loss: [1m[32m0.69480[0m[0m | time: 30.334s
[2K
| Adam | epoch: 002 | loss: 0.69480 - acc: 0.4868 -- iter: 0384/1592
[A[ATraining Step: 63  | total loss: [1m[32m0.69423[0m[0m | time: 31.599s
[2K
| Adam | epoch: 002 | loss: 0.69423 - acc: 0.4964 -- iter: 0416/1592
[A[ATraining Step: 64  | total loss: [1m[32m0.69376[0m[0m | time: 32.852s
[2K
| Adam | epoch: 002 | loss: 0.69376 - acc: 0.5047 -- iter: 0448/1592
[A[ATraining Step: 65  | total loss: [1m[32m0.69404[0m[0m | time: 44.675s
[2K
| Adam | epoch: 002 | loss: 0.69404 - acc: 0.4964 -- iter: 0480/1592
[A[ATraining Step: 66  | total loss: [1m[32m0.69427[0m[0m | time: 45.727s
[2K
| Adam | epoch: 002 | loss: 0.69427 - acc: 0.4892 -- iter: 0512/1592
[A[ATraining Step: 67  | total loss: [1m[32m0.69343[0m[0m | time: 46.866s
[2K
| Adam | epoch: 002 | loss: 0.69343 - acc: 0.5093 -- iter: 0544/1592
[A[ATraining Step: 68  | total loss: [1m[32m0.69326[0m[0m | time: 48.038s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.5119 -- iter: 0576/1592
[A[ATraining Step: 69  | total loss: [1m[32m0.69326[0m[0m | time: 49.119s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.5105 -- iter: 0608/1592
[A[ATraining Step: 70  | total loss: [1m[32m0.69313[0m[0m | time: 50.296s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.5129 -- iter: 0640/1592
[A[ATraining Step: 71  | total loss: [1m[32m0.69303[0m[0m | time: 51.610s
[2K
| Adam | epoch: 002 | loss: 0.69303 - acc: 0.5150 -- iter: 0672/1592
[A[ATraining Step: 72  | total loss: [1m[32m0.69359[0m[0m | time: 52.735s
[2K
| Adam | epoch: 002 | loss: 0.69359 - acc: 0.4992 -- iter: 0704/1592
[A[ATraining Step: 73  | total loss: [1m[32m0.69405[0m[0m | time: 54.043s
[2K
| Adam | epoch: 002 | loss: 0.69405 - acc: 0.4854 -- iter: 0736/1592
[A[ATraining Step: 74  | total loss: [1m[32m0.69417[0m[0m | time: 55.279s
[2K
| Adam | epoch: 002 | loss: 0.69417 - acc: 0.4802 -- iter: 0768/1592
[A[ATraining Step: 75  | total loss: [1m[32m0.69324[0m[0m | time: 56.423s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.5094 -- iter: 0800/1592
[A[ATraining Step: 76  | total loss: [1m[32m0.69335[0m[0m | time: 65.573s
[2K
| Adam | epoch: 002 | loss: 0.69335 - acc: 0.5051 -- iter: 0832/1592
[A[ATraining Step: 77  | total loss: [1m[32m0.69334[0m[0m | time: 84.075s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.5045 -- iter: 0864/1592
[A[ATraining Step: 78  | total loss: [1m[32m0.69364[0m[0m | time: 85.159s
[2K
| Adam | epoch: 002 | loss: 0.69364 - acc: 0.4942 -- iter: 0896/1592
[A[ATraining Step: 79  | total loss: [1m[32m0.69350[0m[0m | time: 86.297s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.4981 -- iter: 0928/1592
[A[ATraining Step: 80  | total loss: [1m[32m0.69366[0m[0m | time: 87.438s
[2K
| Adam | epoch: 002 | loss: 0.69366 - acc: 0.4919 -- iter: 0960/1592
[A[ATraining Step: 81  | total loss: [1m[32m0.69371[0m[0m | time: 88.545s
[2K
| Adam | epoch: 002 | loss: 0.69371 - acc: 0.4895 -- iter: 0992/1592
[A[ATraining Step: 82  | total loss: [1m[32m0.69358[0m[0m | time: 89.909s
[2K
| Adam | epoch: 002 | loss: 0.69358 - acc: 0.4937 -- iter: 1024/1592
[A[ATraining Step: 83  | total loss: [1m[32m0.69332[0m[0m | time: 91.075s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.5037 -- iter: 1056/1592
[A[ATraining Step: 84  | total loss: [1m[32m0.69331[0m[0m | time: 92.276s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.5033 -- iter: 1088/1592
[A[ATraining Step: 85  | total loss: [1m[32m0.69324[0m[0m | time: 93.473s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.5061 -- iter: 1120/1592
[A[ATraining Step: 86  | total loss: [1m[32m0.69300[0m[0m | time: 94.727s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5149 -- iter: 1152/1592
[A[ATraining Step: 87  | total loss: [1m[32m0.69310[0m[0m | time: 96.386s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5103 -- iter: 1184/1592
[A[ATraining Step: 88  | total loss: [1m[32m0.69304[0m[0m | time: 97.295s
[2K
| Adam | epoch: 002 | loss: 0.69304 - acc: 0.5124 -- iter: 1216/1592
[A[ATraining Step: 89  | total loss: [1m[32m0.69291[0m[0m | time: 98.409s
[2K
| Adam | epoch: 002 | loss: 0.69291 - acc: 0.5174 -- iter: 1248/1592
[A[ATraining Step: 90  | total loss: [1m[32m0.69311[0m[0m | time: 99.582s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5094 -- iter: 1280/1592
[A[ATraining Step: 91  | total loss: [1m[32m0.69315[0m[0m | time: 100.737s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5085 -- iter: 1312/1592
[A[ATraining Step: 92  | total loss: [1m[32m0.69307[0m[0m | time: 101.949s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5107 -- iter: 1344/1592
[A[ATraining Step: 93  | total loss: [1m[32m0.69300[0m[0m | time: 103.298s
[2K
| Adam | epoch: 002 | loss: 0.69300 - acc: 0.5128 -- iter: 1376/1592
[A[ATraining Step: 94  | total loss: [1m[32m0.69285[0m[0m | time: 104.375s
[2K
| Adam | epoch: 002 | loss: 0.69285 - acc: 0.5178 -- iter: 1408/1592
[A[ATraining Step: 95  | total loss: [1m[32m0.69245[0m[0m | time: 105.402s
[2K
| Adam | epoch: 002 | loss: 0.69245 - acc: 0.5316 -- iter: 1440/1592
[A[ATraining Step: 96  | total loss: [1m[32m0.69227[0m[0m | time: 106.582s
[2K
| Adam | epoch: 002 | loss: 0.69227 - acc: 0.5378 -- iter: 1472/1592
[A[ATraining Step: 97  | total loss: [1m[32m0.69246[0m[0m | time: 107.857s
[2K
| Adam | epoch: 002 | loss: 0.69246 - acc: 0.5309 -- iter: 1504/1592
[A[ATraining Step: 98  | total loss: [1m[32m0.69223[0m[0m | time: 115.664s
[2K
| Adam | epoch: 002 | loss: 0.69223 - acc: 0.5372 -- iter: 1536/1592
[A[ATraining Step: 99  | total loss: [1m[32m0.69267[0m[0m | time: 116.706s
[2K
| Adam | epoch: 002 | loss: 0.69267 - acc: 0.5241 -- iter: 1568/1592
[A[ATraining Step: 100  | total loss: [1m[32m0.69228[0m[0m | time: 120.978s
[2K
| Adam | epoch: 002 | loss: 0.69228 - acc: 0.5342 | val_loss: 0.69380 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 101  | total loss: [1m[32m0.69239[0m[0m | time: 1.029s
[2K
| Adam | epoch: 003 | loss: 0.69239 - acc: 0.5308 -- iter: 0032/1592
[A[ATraining Step: 102  | total loss: [1m[32m0.69201[0m[0m | time: 1.891s
[2K
| Adam | epoch: 003 | loss: 0.69201 - acc: 0.5402 -- iter: 0064/1592
[A[ATraining Step: 103  | total loss: [1m[32m0.69164[0m[0m | time: 3.001s
[2K
| Adam | epoch: 003 | loss: 0.69164 - acc: 0.5487 -- iter: 0096/1592
[A[ATraining Step: 104  | total loss: [1m[32m0.69234[0m[0m | time: 4.204s
[2K
| Adam | epoch: 003 | loss: 0.69234 - acc: 0.5313 -- iter: 0128/1592
[A[ATraining Step: 105  | total loss: [1m[32m0.69275[0m[0m | time: 5.390s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5219 -- iter: 0160/1592
[A[ATraining Step: 106  | total loss: [1m[32m0.69309[0m[0m | time: 9.246s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5135 -- iter: 0192/1592
[A[ATraining Step: 107  | total loss: [1m[32m0.69228[0m[0m | time: 36.359s
[2K
| Adam | epoch: 003 | loss: 0.69228 - acc: 0.5309 -- iter: 0224/1592
[A[ATraining Step: 108  | total loss: [1m[32m0.69224[0m[0m | time: 52.121s
[2K
| Adam | epoch: 003 | loss: 0.69224 - acc: 0.5309 -- iter: 0256/1592
[A[ATraining Step: 109  | total loss: [1m[32m0.69220[0m[0m | time: 53.289s
[2K
| Adam | epoch: 003 | loss: 0.69220 - acc: 0.5310 -- iter: 0288/1592
[A[ATraining Step: 110  | total loss: [1m[32m0.69202[0m[0m | time: 54.382s
[2K
| Adam | epoch: 003 | loss: 0.69202 - acc: 0.5341 -- iter: 0320/1592
[A[ATraining Step: 111  | total loss: [1m[32m0.69202[0m[0m | time: 55.479s
[2K
| Adam | epoch: 003 | loss: 0.69202 - acc: 0.5338 -- iter: 0352/1592
[A[ATraining Step: 112  | total loss: [1m[32m0.69218[0m[0m | time: 56.739s
[2K
| Adam | epoch: 003 | loss: 0.69218 - acc: 0.5304 -- iter: 0384/1592
[A[ATraining Step: 113  | total loss: [1m[32m0.69179[0m[0m | time: 58.259s
[2K
| Adam | epoch: 003 | loss: 0.69179 - acc: 0.5368 -- iter: 0416/1592
[A[ATraining Step: 114  | total loss: [1m[32m0.69179[0m[0m | time: 59.411s
[2K
| Adam | epoch: 003 | loss: 0.69179 - acc: 0.5362 -- iter: 0448/1592
[A[ATraining Step: 115  | total loss: [1m[32m0.69177[0m[0m | time: 60.449s
[2K
| Adam | epoch: 003 | loss: 0.69177 - acc: 0.5357 -- iter: 0480/1592
[A[ATraining Step: 116  | total loss: [1m[32m0.69232[0m[0m | time: 61.552s
[2K
| Adam | epoch: 003 | loss: 0.69232 - acc: 0.5259 -- iter: 0512/1592
[A[ATraining Step: 117  | total loss: [1m[32m0.69204[0m[0m | time: 62.765s
[2K
| Adam | epoch: 003 | loss: 0.69204 - acc: 0.5296 -- iter: 0544/1592
[A[ATraining Step: 118  | total loss: [1m[32m0.69181[0m[0m | time: 68.946s
[2K
| Adam | epoch: 003 | loss: 0.69181 - acc: 0.5329 -- iter: 0576/1592
[A[ATraining Step: 119  | total loss: [1m[32m0.69343[0m[0m | time: 78.725s
[2K
| Adam | epoch: 003 | loss: 0.69343 - acc: 0.5077 -- iter: 0608/1592
[A[ATraining Step: 120  | total loss: [1m[32m0.69287[0m[0m | time: 79.851s
[2K
| Adam | epoch: 003 | loss: 0.69287 - acc: 0.5163 -- iter: 0640/1592
[A[ATraining Step: 121  | total loss: [1m[32m0.69274[0m[0m | time: 81.020s
[2K
| Adam | epoch: 003 | loss: 0.69274 - acc: 0.5178 -- iter: 0672/1592
[A[ATraining Step: 122  | total loss: [1m[32m0.69282[0m[0m | time: 82.156s
[2K
| Adam | epoch: 003 | loss: 0.69282 - acc: 0.5160 -- iter: 0704/1592
[A[ATraining Step: 123  | total loss: [1m[32m0.69292[0m[0m | time: 83.404s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5144 -- iter: 0736/1592
[A[ATraining Step: 124  | total loss: [1m[32m0.69297[0m[0m | time: 84.784s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5130 -- iter: 0768/1592
[A[ATraining Step: 125  | total loss: [1m[32m0.69262[0m[0m | time: 85.753s
[2K
| Adam | epoch: 003 | loss: 0.69262 - acc: 0.5179 -- iter: 0800/1592
[A[ATraining Step: 126  | total loss: [1m[32m0.69272[0m[0m | time: 86.918s
[2K
| Adam | epoch: 003 | loss: 0.69272 - acc: 0.5161 -- iter: 0832/1592
[A[ATraining Step: 127  | total loss: [1m[32m0.69296[0m[0m | time: 88.046s
[2K
| Adam | epoch: 003 | loss: 0.69296 - acc: 0.5114 -- iter: 0864/1592
[A[ATraining Step: 128  | total loss: [1m[32m0.69320[0m[0m | time: 89.245s
[2K
| Adam | epoch: 003 | loss: 0.69320 - acc: 0.5071 -- iter: 0896/1592
[A[ATraining Step: 129  | total loss: [1m[32m0.69358[0m[0m | time: 93.184s
[2K
| Adam | epoch: 003 | loss: 0.69358 - acc: 0.5002 -- iter: 0928/1592
[A[ATraining Step: 130  | total loss: [1m[32m0.69336[0m[0m | time: 126.305s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.5033 -- iter: 0960/1592
[A[ATraining Step: 131  | total loss: [1m[32m0.69413[0m[0m | time: 127.427s
[2K
| Adam | epoch: 003 | loss: 0.69413 - acc: 0.4904 -- iter: 0992/1592
[A[ATraining Step: 132  | total loss: [1m[32m0.69443[0m[0m | time: 128.688s
[2K
| Adam | epoch: 003 | loss: 0.69443 - acc: 0.4852 -- iter: 1024/1592
[A[ATraining Step: 133  | total loss: [1m[32m0.69468[0m[0m | time: 129.899s
[2K
| Adam | epoch: 003 | loss: 0.69468 - acc: 0.4804 -- iter: 1056/1592
[A[ATraining Step: 134  | total loss: [1m[32m0.69438[0m[0m | time: 131.029s
[2K
| Adam | epoch: 003 | loss: 0.69438 - acc: 0.4855 -- iter: 1088/1592
[A[ATraining Step: 135  | total loss: [1m[32m0.69354[0m[0m | time: 132.364s
[2K
| Adam | epoch: 003 | loss: 0.69354 - acc: 0.5026 -- iter: 1120/1592
[A[ATraining Step: 136  | total loss: [1m[32m0.69352[0m[0m | time: 133.716s
[2K
| Adam | epoch: 003 | loss: 0.69352 - acc: 0.5023 -- iter: 1152/1592
[A[ATraining Step: 137  | total loss: [1m[32m0.69394[0m[0m | time: 134.917s
[2K
| Adam | epoch: 003 | loss: 0.69394 - acc: 0.4927 -- iter: 1184/1592
[A[ATraining Step: 138  | total loss: [1m[32m0.69434[0m[0m | time: 136.160s
[2K
| Adam | epoch: 003 | loss: 0.69434 - acc: 0.4840 -- iter: 1216/1592
[A[ATraining Step: 139  | total loss: [1m[32m0.69411[0m[0m | time: 137.369s
[2K
| Adam | epoch: 003 | loss: 0.69411 - acc: 0.4888 -- iter: 1248/1592
[A[ATraining Step: 140  | total loss: [1m[32m0.69417[0m[0m | time: 138.719s
[2K
| Adam | epoch: 003 | loss: 0.69417 - acc: 0.4868 -- iter: 1280/1592
[A[ATraining Step: 141  | total loss: [1m[32m0.69420[0m[0m | time: 144.469s
[2K
| Adam | epoch: 003 | loss: 0.69420 - acc: 0.4850 -- iter: 1312/1592
[A[ATraining Step: 142  | total loss: [1m[32m0.69349[0m[0m | time: 145.461s
[2K
| Adam | epoch: 003 | loss: 0.69349 - acc: 0.5021 -- iter: 1344/1592
[A[ATraining Step: 143  | total loss: [1m[32m0.69347[0m[0m | time: 146.574s
[2K
| Adam | epoch: 003 | loss: 0.69347 - acc: 0.5019 -- iter: 1376/1592
[A[ATraining Step: 144  | total loss: [1m[32m0.69309[0m[0m | time: 147.826s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5111 -- iter: 1408/1592
[A[ATraining Step: 145  | total loss: [1m[32m0.69300[0m[0m | time: 148.978s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5131 -- iter: 1440/1592
[A[ATraining Step: 146  | total loss: [1m[32m0.69267[0m[0m | time: 150.246s
[2K
| Adam | epoch: 003 | loss: 0.69267 - acc: 0.5212 -- iter: 1472/1592
[A[ATraining Step: 147  | total loss: [1m[32m0.69240[0m[0m | time: 151.606s
[2K
| Adam | epoch: 003 | loss: 0.69240 - acc: 0.5284 -- iter: 1504/1592
[A[ATraining Step: 148  | total loss: [1m[32m0.69251[0m[0m | time: 152.680s
[2K
| Adam | epoch: 003 | loss: 0.69251 - acc: 0.5256 -- iter: 1536/1592
[A[ATraining Step: 149  | total loss: [1m[32m0.69260[0m[0m | time: 153.863s
[2K
| Adam | epoch: 003 | loss: 0.69260 - acc: 0.5230 -- iter: 1568/1592
[A[ATraining Step: 150  | total loss: [1m[32m0.69249[0m[0m | time: 177.367s
[2K
| Adam | epoch: 003 | loss: 0.69249 - acc: 0.5238 | val_loss: 0.69392 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 151  | total loss: [1m[32m0.69300[0m[0m | time: 1.135s
[2K
| Adam | epoch: 004 | loss: 0.69300 - acc: 0.5121 -- iter: 0032/1592
[A[ATraining Step: 152  | total loss: [1m[32m0.69306[0m[0m | time: 2.119s
[2K
| Adam | epoch: 004 | loss: 0.69306 - acc: 0.5109 -- iter: 0064/1592
[A[ATraining Step: 153  | total loss: [1m[32m0.69271[0m[0m | time: 3.148s
[2K
| Adam | epoch: 004 | loss: 0.69271 - acc: 0.5181 -- iter: 0096/1592
[A[ATraining Step: 154  | total loss: [1m[32m0.69243[0m[0m | time: 4.506s
[2K
| Adam | epoch: 004 | loss: 0.69243 - acc: 0.5246 -- iter: 0128/1592
[A[ATraining Step: 155  | total loss: [1m[32m0.69326[0m[0m | time: 5.837s
[2K
| Adam | epoch: 004 | loss: 0.69326 - acc: 0.5066 -- iter: 0160/1592
[A[ATraining Step: 156  | total loss: [1m[32m0.69356[0m[0m | time: 6.939s
[2K
| Adam | epoch: 004 | loss: 0.69356 - acc: 0.4996 -- iter: 0192/1592
[A[ATraining Step: 157  | total loss: [1m[32m0.69317[0m[0m | time: 8.057s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5091 -- iter: 0224/1592
[A[ATraining Step: 158  | total loss: [1m[32m0.69307[0m[0m | time: 9.795s
[2K
| Adam | epoch: 004 | loss: 0.69307 - acc: 0.5113 -- iter: 0256/1592
[A[ATraining Step: 159  | total loss: [1m[32m0.69343[0m[0m | time: 37.111s
[2K
| Adam | epoch: 004 | loss: 0.69343 - acc: 0.5008 -- iter: 0288/1592
[A[ATraining Step: 160  | total loss: [1m[32m0.69319[0m[0m | time: 38.220s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.5069 -- iter: 0320/1592
[A[ATraining Step: 161  | total loss: [1m[32m0.69315[0m[0m | time: 39.408s
[2K
| Adam | epoch: 004 | loss: 0.69315 - acc: 0.5094 -- iter: 0352/1592
[A[ATraining Step: 162  | total loss: [1m[32m0.69299[0m[0m | time: 40.587s
[2K
| Adam | epoch: 004 | loss: 0.69299 - acc: 0.5147 -- iter: 0384/1592
[A[ATraining Step: 163  | total loss: [1m[32m0.69342[0m[0m | time: 41.896s
[2K
| Adam | epoch: 004 | loss: 0.69342 - acc: 0.5007 -- iter: 0416/1592
[A[ATraining Step: 164  | total loss: [1m[32m0.69323[0m[0m | time: 43.196s
[2K
| Adam | epoch: 004 | loss: 0.69323 - acc: 0.5069 -- iter: 0448/1592
[A[ATraining Step: 165  | total loss: [1m[32m0.69272[0m[0m | time: 44.253s
[2K
| Adam | epoch: 004 | loss: 0.69272 - acc: 0.5250 -- iter: 0480/1592
[A[ATraining Step: 166  | total loss: [1m[32m0.69225[0m[0m | time: 45.494s
[2K
| Adam | epoch: 004 | loss: 0.69225 - acc: 0.5381 -- iter: 0512/1592
[A[ATraining Step: 167  | total loss: [1m[32m0.69170[0m[0m | time: 46.798s
[2K
| Adam | epoch: 004 | loss: 0.69170 - acc: 0.5499 -- iter: 0544/1592
[A[ATraining Step: 168  | total loss: [1m[32m0.69110[0m[0m | time: 48.031s
[2K
| Adam | epoch: 004 | loss: 0.69110 - acc: 0.5605 -- iter: 0576/1592
[A[ATraining Step: 169  | total loss: [1m[32m0.69185[0m[0m | time: 57.713s
[2K
| Adam | epoch: 004 | loss: 0.69185 - acc: 0.5451 -- iter: 0608/1592
[A[ATraining Step: 170  | total loss: [1m[32m0.69218[0m[0m | time: 58.855s
[2K
| Adam | epoch: 004 | loss: 0.69218 - acc: 0.5375 -- iter: 0640/1592
[A[ATraining Step: 171  | total loss: [1m[32m0.69130[0m[0m | time: 59.988s
[2K
| Adam | epoch: 004 | loss: 0.69130 - acc: 0.5525 -- iter: 0672/1592
[A[ATraining Step: 172  | total loss: [1m[32m0.69171[0m[0m | time: 61.087s
[2K
| Adam | epoch: 004 | loss: 0.69171 - acc: 0.5441 -- iter: 0704/1592
[A[ATraining Step: 173  | total loss: [1m[32m0.69228[0m[0m | time: 62.300s
[2K
| Adam | epoch: 004 | loss: 0.69228 - acc: 0.5334 -- iter: 0736/1592
[A[ATraining Step: 174  | total loss: [1m[32m0.69241[0m[0m | time: 63.597s
[2K
| Adam | epoch: 004 | loss: 0.69241 - acc: 0.5301 -- iter: 0768/1592
[A[ATraining Step: 175  | total loss: [1m[32m0.69253[0m[0m | time: 64.717s
[2K
| Adam | epoch: 004 | loss: 0.69253 - acc: 0.5271 -- iter: 0800/1592
[A[ATraining Step: 176  | total loss: [1m[32m0.69188[0m[0m | time: 65.860s
[2K
| Adam | epoch: 004 | loss: 0.69188 - acc: 0.5369 -- iter: 0832/1592
[A[ATraining Step: 177  | total loss: [1m[32m0.69083[0m[0m | time: 67.170s
[2K
| Adam | epoch: 004 | loss: 0.69083 - acc: 0.5519 -- iter: 0864/1592
[A[ATraining Step: 178  | total loss: [1m[32m0.69176[0m[0m | time: 68.525s
[2K
| Adam | epoch: 004 | loss: 0.69176 - acc: 0.5374 -- iter: 0896/1592
[A[ATraining Step: 179  | total loss: [1m[32m0.69131[0m[0m | time: 82.601s
[2K
| Adam | epoch: 004 | loss: 0.69131 - acc: 0.5430 -- iter: 0928/1592
[A[ATraining Step: 180  | total loss: [1m[32m0.69158[0m[0m | time: 83.619s
[2K
| Adam | epoch: 004 | loss: 0.69158 - acc: 0.5387 -- iter: 0960/1592
[A[ATraining Step: 181  | total loss: [1m[32m0.69233[0m[0m | time: 84.693s
[2K
| Adam | epoch: 004 | loss: 0.69233 - acc: 0.5286 -- iter: 0992/1592
[A[ATraining Step: 182  | total loss: [1m[32m0.69251[0m[0m | time: 85.803s
[2K
| Adam | epoch: 004 | loss: 0.69251 - acc: 0.5257 -- iter: 1024/1592
[A[ATraining Step: 183  | total loss: [1m[32m0.69239[0m[0m | time: 87.022s
[2K
| Adam | epoch: 004 | loss: 0.69239 - acc: 0.5263 -- iter: 1056/1592
[A[ATraining Step: 184  | total loss: [1m[32m0.69206[0m[0m | time: 88.455s
[2K
| Adam | epoch: 004 | loss: 0.69206 - acc: 0.5299 -- iter: 1088/1592
[A[ATraining Step: 185  | total loss: [1m[32m0.69198[0m[0m | time: 89.824s
[2K
| Adam | epoch: 004 | loss: 0.69198 - acc: 0.5300 -- iter: 1120/1592
[A[ATraining Step: 186  | total loss: [1m[32m0.69219[0m[0m | time: 90.949s
[2K
| Adam | epoch: 004 | loss: 0.69219 - acc: 0.5270 -- iter: 1152/1592
[A[ATraining Step: 187  | total loss: [1m[32m0.69190[0m[0m | time: 92.302s
[2K
| Adam | epoch: 004 | loss: 0.69190 - acc: 0.5306 -- iter: 1184/1592
[A[ATraining Step: 188  | total loss: [1m[32m0.69289[0m[0m | time: 93.529s
[2K
| Adam | epoch: 004 | loss: 0.69289 - acc: 0.5181 -- iter: 1216/1592
[A[ATraining Step: 189  | total loss: [1m[32m0.69303[0m[0m | time: 102.322s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5163 -- iter: 1248/1592
[A[ATraining Step: 190  | total loss: [1m[32m0.69385[0m[0m | time: 103.276s
[2K
| Adam | epoch: 004 | loss: 0.69385 - acc: 0.5053 -- iter: 1280/1592
[A[ATraining Step: 191  | total loss: [1m[32m0.69386[0m[0m | time: 104.407s
[2K
| Adam | epoch: 004 | loss: 0.69386 - acc: 0.5048 -- iter: 1312/1592
[A[ATraining Step: 192  | total loss: [1m[32m0.69482[0m[0m | time: 105.604s
[2K
| Adam | epoch: 004 | loss: 0.69482 - acc: 0.4918 -- iter: 1344/1592
[A[ATraining Step: 193  | total loss: [1m[32m0.69426[0m[0m | time: 106.664s
[2K
| Adam | epoch: 004 | loss: 0.69426 - acc: 0.4989 -- iter: 1376/1592
[A[ATraining Step: 194  | total loss: [1m[32m0.69378[0m[0m | time: 107.934s
[2K
| Adam | epoch: 004 | loss: 0.69378 - acc: 0.5052 -- iter: 1408/1592
[A[ATraining Step: 195  | total loss: [1m[32m0.69420[0m[0m | time: 109.103s
[2K
| Adam | epoch: 004 | loss: 0.69420 - acc: 0.4985 -- iter: 1440/1592
[A[ATraining Step: 196  | total loss: [1m[32m0.69389[0m[0m | time: 110.436s
[2K
| Adam | epoch: 004 | loss: 0.69389 - acc: 0.5017 -- iter: 1472/1592
[A[ATraining Step: 197  | total loss: [1m[32m0.69388[0m[0m | time: 111.652s
[2K
| Adam | epoch: 004 | loss: 0.69388 - acc: 0.5016 -- iter: 1504/1592
[A[ATraining Step: 198  | total loss: [1m[32m0.69305[0m[0m | time: 112.802s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5139 -- iter: 1536/1592
[A[ATraining Step: 199  | total loss: [1m[32m0.69206[0m[0m | time: 113.998s
[2K
| Adam | epoch: 004 | loss: 0.69206 - acc: 0.5281 -- iter: 1568/1592
[A[ATraining Step: 200  | total loss: [1m[32m0.69263[0m[0m | time: 142.505s
[2K
| Adam | epoch: 004 | loss: 0.69263 - acc: 0.5191 | val_loss: 0.69451 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 201  | total loss: [1m[32m0.69316[0m[0m | time: 1.364s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.5109 -- iter: 0032/1592
[A[ATraining Step: 202  | total loss: [1m[32m0.69258[0m[0m | time: 2.710s
[2K
| Adam | epoch: 005 | loss: 0.69258 - acc: 0.5192 -- iter: 0064/1592
[A[ATraining Step: 203  | total loss: [1m[32m0.69268[0m[0m | time: 3.582s
[2K
| Adam | epoch: 005 | loss: 0.69268 - acc: 0.5173 -- iter: 0096/1592
[A[ATraining Step: 204  | total loss: [1m[32m0.69275[0m[0m | time: 4.471s
[2K
| Adam | epoch: 005 | loss: 0.69275 - acc: 0.5156 -- iter: 0128/1592
[A[ATraining Step: 205  | total loss: [1m[32m0.69284[0m[0m | time: 5.762s
[2K
| Adam | epoch: 005 | loss: 0.69284 - acc: 0.5140 -- iter: 0160/1592
[A[ATraining Step: 206  | total loss: [1m[32m0.69314[0m[0m | time: 6.855s
[2K
| Adam | epoch: 005 | loss: 0.69314 - acc: 0.5095 -- iter: 0192/1592
[A[ATraining Step: 207  | total loss: [1m[32m0.69193[0m[0m | time: 7.889s
[2K
| Adam | epoch: 005 | loss: 0.69193 - acc: 0.5273 -- iter: 0224/1592
[A[ATraining Step: 208  | total loss: [1m[32m0.69191[0m[0m | time: 8.981s
[2K
| Adam | epoch: 005 | loss: 0.69191 - acc: 0.5277 -- iter: 0256/1592
[A[ATraining Step: 209  | total loss: [1m[32m0.69233[0m[0m | time: 10.069s
[2K
| Adam | epoch: 005 | loss: 0.69233 - acc: 0.5218 -- iter: 0288/1592
[A[ATraining Step: 210  | total loss: [1m[32m0.69202[0m[0m | time: 11.254s
[2K
| Adam | epoch: 005 | loss: 0.69202 - acc: 0.5259 -- iter: 0320/1592
[A[ATraining Step: 211  | total loss: [1m[32m0.69173[0m[0m | time: 12.384s
[2K
| Adam | epoch: 005 | loss: 0.69173 - acc: 0.5295 -- iter: 0352/1592
[A[ATraining Step: 212  | total loss: [1m[32m0.69101[0m[0m | time: 13.669s
[2K
| Adam | epoch: 005 | loss: 0.69101 - acc: 0.5391 -- iter: 0384/1592
[A[ATraining Step: 213  | total loss: [1m[32m0.69322[0m[0m | time: 14.901s
[2K
| Adam | epoch: 005 | loss: 0.69322 - acc: 0.5102 -- iter: 0416/1592
[A[ATraining Step: 214  | total loss: [1m[32m0.69308[0m[0m | time: 15.918s
[2K
| Adam | epoch: 005 | loss: 0.69308 - acc: 0.5123 -- iter: 0448/1592
[A[ATraining Step: 215  | total loss: [1m[32m0.69291[0m[0m | time: 17.145s
[2K
| Adam | epoch: 005 | loss: 0.69291 - acc: 0.5142 -- iter: 0480/1592
[A[ATraining Step: 216  | total loss: [1m[32m0.69277[0m[0m | time: 18.458s
[2K
| Adam | epoch: 005 | loss: 0.69277 - acc: 0.5159 -- iter: 0512/1592
[A[ATraining Step: 217  | total loss: [1m[32m0.69355[0m[0m | time: 19.650s
[2K
| Adam | epoch: 005 | loss: 0.69355 - acc: 0.5049 -- iter: 0544/1592
[A[ATraining Step: 218  | total loss: [1m[32m0.69291[0m[0m | time: 21.177s
[2K
| Adam | epoch: 005 | loss: 0.69291 - acc: 0.5138 -- iter: 0576/1592
[A[ATraining Step: 219  | total loss: [1m[32m0.69321[0m[0m | time: 22.396s
[2K
| Adam | epoch: 005 | loss: 0.69321 - acc: 0.5093 -- iter: 0608/1592
[A[ATraining Step: 220  | total loss: [1m[32m0.69198[0m[0m | time: 23.601s
[2K
| Adam | epoch: 005 | loss: 0.69198 - acc: 0.5271 -- iter: 0640/1592
[A[ATraining Step: 221  | total loss: [1m[32m0.69192[0m[0m | time: 24.769s
[2K
| Adam | epoch: 005 | loss: 0.69192 - acc: 0.5275 -- iter: 0672/1592
[A[ATraining Step: 222  | total loss: [1m[32m0.69209[0m[0m | time: 25.954s
[2K
| Adam | epoch: 005 | loss: 0.69209 - acc: 0.5248 -- iter: 0704/1592
[A[ATraining Step: 223  | total loss: [1m[32m0.69136[0m[0m | time: 27.265s
[2K
| Adam | epoch: 005 | loss: 0.69136 - acc: 0.5348 -- iter: 0736/1592
[A[ATraining Step: 224  | total loss: [1m[32m0.69206[0m[0m | time: 28.365s
[2K
| Adam | epoch: 005 | loss: 0.69206 - acc: 0.5251 -- iter: 0768/1592
[A[ATraining Step: 225  | total loss: [1m[32m0.69225[0m[0m | time: 29.611s
[2K
| Adam | epoch: 005 | loss: 0.69225 - acc: 0.5226 -- iter: 0800/1592
[A[ATraining Step: 226  | total loss: [1m[32m0.69334[0m[0m | time: 30.952s
[2K
| Adam | epoch: 005 | loss: 0.69334 - acc: 0.5078 -- iter: 0832/1592
[A[ATraining Step: 227  | total loss: [1m[32m0.69340[0m[0m | time: 32.069s
[2K
| Adam | epoch: 005 | loss: 0.69340 - acc: 0.5070 -- iter: 0864/1592
[A[ATraining Step: 228  | total loss: [1m[32m0.69368[0m[0m | time: 37.355s
[2K
| Adam | epoch: 005 | loss: 0.69368 - acc: 0.5032 -- iter: 0896/1592
[A[ATraining Step: 229  | total loss: [1m[32m0.69346[0m[0m | time: 51.736s
[2K
| Adam | epoch: 005 | loss: 0.69346 - acc: 0.5060 -- iter: 0928/1592
[A[ATraining Step: 230  | total loss: [1m[32m0.69346[0m[0m | time: 52.964s
[2K
| Adam | epoch: 005 | loss: 0.69346 - acc: 0.5054 -- iter: 0960/1592
[A[ATraining Step: 231  | total loss: [1m[32m0.69324[0m[0m | time: 54.143s
[2K
| Adam | epoch: 005 | loss: 0.69324 - acc: 0.5080 -- iter: 0992/1592
[A[ATraining Step: 232  | total loss: [1m[32m0.69307[0m[0m | time: 55.283s
[2K
| Adam | epoch: 005 | loss: 0.69307 - acc: 0.5103 -- iter: 1024/1592
[A[ATraining Step: 233  | total loss: [1m[32m0.69272[0m[0m | time: 56.534s
[2K
| Adam | epoch: 005 | loss: 0.69272 - acc: 0.5155 -- iter: 1056/1592
[A[ATraining Step: 234  | total loss: [1m[32m0.69220[0m[0m | time: 57.925s
[2K
| Adam | epoch: 005 | loss: 0.69220 - acc: 0.5234 -- iter: 1088/1592
[A[ATraining Step: 235  | total loss: [1m[32m0.69361[0m[0m | time: 58.932s
[2K
| Adam | epoch: 005 | loss: 0.69361 - acc: 0.5023 -- iter: 1120/1592
[A[ATraining Step: 236  | total loss: [1m[32m0.69325[0m[0m | time: 60.216s
[2K
| Adam | epoch: 005 | loss: 0.69325 - acc: 0.5083 -- iter: 1152/1592
[A[ATraining Step: 237  | total loss: [1m[32m0.69370[0m[0m | time: 61.587s
[2K
| Adam | epoch: 005 | loss: 0.69370 - acc: 0.5012 -- iter: 1184/1592
[A[ATraining Step: 238  | total loss: [1m[32m0.69447[0m[0m | time: 62.856s
[2K
| Adam | epoch: 005 | loss: 0.69447 - acc: 0.4886 -- iter: 1216/1592
[A[ATraining Step: 239  | total loss: [1m[32m0.69416[0m[0m | time: 63.718s
[2K
| Adam | epoch: 005 | loss: 0.69416 - acc: 0.4929 -- iter: 1248/1592
[A[ATraining Step: 240  | total loss: [1m[32m0.69483[0m[0m | time: 64.957s
[2K
| Adam | epoch: 005 | loss: 0.69483 - acc: 0.4811 -- iter: 1280/1592
[A[ATraining Step: 241  | total loss: [1m[32m0.69450[0m[0m | time: 66.017s
[2K
| Adam | epoch: 005 | loss: 0.69450 - acc: 0.4861 -- iter: 1312/1592
[A[ATraining Step: 242  | total loss: [1m[32m0.69355[0m[0m | time: 67.095s
[2K
| Adam | epoch: 005 | loss: 0.69355 - acc: 0.5031 -- iter: 1344/1592
[A[ATraining Step: 243  | total loss: [1m[32m0.69339[0m[0m | time: 68.208s
[2K
| Adam | epoch: 005 | loss: 0.69339 - acc: 0.5059 -- iter: 1376/1592
[A[ATraining Step: 244  | total loss: [1m[32m0.69323[0m[0m | time: 69.522s
[2K
| Adam | epoch: 005 | loss: 0.69323 - acc: 0.5085 -- iter: 1408/1592
[A[ATraining Step: 245  | total loss: [1m[32m0.69361[0m[0m | time: 70.612s
[2K
| Adam | epoch: 005 | loss: 0.69361 - acc: 0.5014 -- iter: 1440/1592
[A[ATraining Step: 246  | total loss: [1m[32m0.69442[0m[0m | time: 71.850s
[2K
| Adam | epoch: 005 | loss: 0.69442 - acc: 0.4856 -- iter: 1472/1592
[A[ATraining Step: 247  | total loss: [1m[32m0.69385[0m[0m | time: 73.175s
[2K
| Adam | epoch: 005 | loss: 0.69385 - acc: 0.4964 -- iter: 1504/1592
[A[ATraining Step: 248  | total loss: [1m[32m0.69412[0m[0m | time: 74.313s
[2K
| Adam | epoch: 005 | loss: 0.69412 - acc: 0.4905 -- iter: 1536/1592
[A[ATraining Step: 249  | total loss: [1m[32m0.69388[0m[0m | time: 77.253s
[2K
| Adam | epoch: 005 | loss: 0.69388 - acc: 0.4946 -- iter: 1568/1592
[A[ATraining Step: 250  | total loss: [1m[32m0.69385[0m[0m | time: 81.872s
[2K
| Adam | epoch: 005 | loss: 0.69385 - acc: 0.4951 | val_loss: 0.69393 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 251  | total loss: [1m[32m0.69322[0m[0m | time: 1.093s
[2K
| Adam | epoch: 006 | loss: 0.69322 - acc: 0.5081 -- iter: 0032/1592
[A[ATraining Step: 252  | total loss: [1m[32m0.69349[0m[0m | time: 2.478s
[2K
| Adam | epoch: 006 | loss: 0.69349 - acc: 0.5011 -- iter: 0064/1592
[A[ATraining Step: 253  | total loss: [1m[32m0.69361[0m[0m | time: 3.798s
[2K
| Adam | epoch: 006 | loss: 0.69361 - acc: 0.4978 -- iter: 0096/1592
[A[ATraining Step: 254  | total loss: [1m[32m0.69292[0m[0m | time: 10.000s
[2K
| Adam | epoch: 006 | loss: 0.69292 - acc: 0.5137 -- iter: 0128/1592
[A[ATraining Step: 255  | total loss: [1m[32m0.69277[0m[0m | time: 19.300s
[2K
| Adam | epoch: 006 | loss: 0.69277 - acc: 0.5165 -- iter: 0160/1592
[A[ATraining Step: 256  | total loss: [1m[32m0.69267[0m[0m | time: 20.314s
[2K
| Adam | epoch: 006 | loss: 0.69267 - acc: 0.5190 -- iter: 0192/1592
[A[ATraining Step: 257  | total loss: [1m[32m0.69260[0m[0m | time: 21.574s
[2K
| Adam | epoch: 006 | loss: 0.69260 - acc: 0.5202 -- iter: 0224/1592
[A[ATraining Step: 258  | total loss: [1m[32m0.69269[0m[0m | time: 22.630s
[2K
| Adam | epoch: 006 | loss: 0.69269 - acc: 0.5182 -- iter: 0256/1592
[A[ATraining Step: 259  | total loss: [1m[32m0.69369[0m[0m | time: 23.811s
[2K
| Adam | epoch: 006 | loss: 0.69369 - acc: 0.4945 -- iter: 0288/1592
[A[ATraining Step: 260  | total loss: [1m[32m0.69353[0m[0m | time: 25.309s
[2K
| Adam | epoch: 006 | loss: 0.69353 - acc: 0.4982 -- iter: 0320/1592
[A[ATraining Step: 261  | total loss: [1m[32m0.69298[0m[0m | time: 26.438s
[2K
| Adam | epoch: 006 | loss: 0.69298 - acc: 0.5109 -- iter: 0352/1592
[A[ATraining Step: 262  | total loss: [1m[32m0.69293[0m[0m | time: 27.718s
[2K
| Adam | epoch: 006 | loss: 0.69293 - acc: 0.5129 -- iter: 0384/1592
[A[ATraining Step: 263  | total loss: [1m[32m0.69246[0m[0m | time: 29.148s
[2K
| Adam | epoch: 006 | loss: 0.69246 - acc: 0.5241 -- iter: 0416/1592
[A[ATraining Step: 264  | total loss: [1m[32m0.69272[0m[0m | time: 30.428s
[2K
| Adam | epoch: 006 | loss: 0.69272 - acc: 0.5186 -- iter: 0448/1592
[A[ATraining Step: 265  | total loss: [1m[32m0.69252[0m[0m | time: 31.577s
[2K
| Adam | epoch: 006 | loss: 0.69252 - acc: 0.5230 -- iter: 0480/1592
[A[ATraining Step: 266  | total loss: [1m[32m0.69219[0m[0m | time: 32.802s
[2K
| Adam | epoch: 006 | loss: 0.69219 - acc: 0.5300 -- iter: 0512/1592
[A[ATraining Step: 267  | total loss: [1m[32m0.69244[0m[0m | time: 33.918s
[2K
| Adam | epoch: 006 | loss: 0.69244 - acc: 0.5239 -- iter: 0544/1592
[A[ATraining Step: 268  | total loss: [1m[32m0.69210[0m[0m | time: 35.181s
[2K
| Adam | epoch: 006 | loss: 0.69210 - acc: 0.5309 -- iter: 0576/1592
[A[ATraining Step: 269  | total loss: [1m[32m0.69175[0m[0m | time: 36.354s
[2K
| Adam | epoch: 006 | loss: 0.69175 - acc: 0.5372 -- iter: 0608/1592
[A[ATraining Step: 270  | total loss: [1m[32m0.69195[0m[0m | time: 37.710s
[2K
| Adam | epoch: 006 | loss: 0.69195 - acc: 0.5335 -- iter: 0640/1592
[A[ATraining Step: 271  | total loss: [1m[32m0.69142[0m[0m | time: 38.832s
[2K
| Adam | epoch: 006 | loss: 0.69142 - acc: 0.5426 -- iter: 0672/1592
[A[ATraining Step: 272  | total loss: [1m[32m0.69131[0m[0m | time: 40.225s
[2K
| Adam | epoch: 006 | loss: 0.69131 - acc: 0.5446 -- iter: 0704/1592
[A[ATraining Step: 273  | total loss: [1m[32m0.69069[0m[0m | time: 41.624s
[2K
| Adam | epoch: 006 | loss: 0.69069 - acc: 0.5558 -- iter: 0736/1592
[A[ATraining Step: 274  | total loss: [1m[32m0.69012[0m[0m | time: 43.406s
[2K
| Adam | epoch: 006 | loss: 0.69012 - acc: 0.5658 -- iter: 0768/1592
[A[ATraining Step: 275  | total loss: [1m[32m0.69066[0m[0m | time: 44.378s
[2K
| Adam | epoch: 006 | loss: 0.69066 - acc: 0.5561 -- iter: 0800/1592
[A[ATraining Step: 276  | total loss: [1m[32m0.69159[0m[0m | time: 45.827s
[2K
| Adam | epoch: 006 | loss: 0.69159 - acc: 0.5411 -- iter: 0832/1592
[A[ATraining Step: 277  | total loss: [1m[32m0.69159[0m[0m | time: 47.166s
[2K
| Adam | epoch: 006 | loss: 0.69159 - acc: 0.5401 -- iter: 0864/1592
[A[ATraining Step: 278  | total loss: [1m[32m0.69246[0m[0m | time: 48.250s
[2K
| Adam | epoch: 006 | loss: 0.69246 - acc: 0.5267 -- iter: 0896/1592
[A[ATraining Step: 279  | total loss: [1m[32m0.69300[0m[0m | time: 49.516s
[2K
| Adam | epoch: 006 | loss: 0.69300 - acc: 0.5178 -- iter: 0928/1592
[A[ATraining Step: 280  | total loss: [1m[32m0.69328[0m[0m | time: 50.950s
[2K
| Adam | epoch: 006 | loss: 0.69328 - acc: 0.5129 -- iter: 0960/1592
[A[ATraining Step: 281  | total loss: [1m[32m0.69334[0m[0m | time: 52.077s
[2K
| Adam | epoch: 006 | loss: 0.69334 - acc: 0.5116 -- iter: 0992/1592
[A[ATraining Step: 282  | total loss: [1m[32m0.69400[0m[0m | time: 53.235s
[2K
| Adam | epoch: 006 | loss: 0.69400 - acc: 0.5011 -- iter: 1024/1592
[A[ATraining Step: 283  | total loss: [1m[32m0.69332[0m[0m | time: 54.462s
[2K
| Adam | epoch: 006 | loss: 0.69332 - acc: 0.5104 -- iter: 1056/1592
[A[ATraining Step: 284  | total loss: [1m[32m0.69256[0m[0m | time: 55.631s
[2K
| Adam | epoch: 006 | loss: 0.69256 - acc: 0.5218 -- iter: 1088/1592
[A[ATraining Step: 285  | total loss: [1m[32m0.69202[0m[0m | time: 56.760s
[2K
| Adam | epoch: 006 | loss: 0.69202 - acc: 0.5290 -- iter: 1120/1592
[A[ATraining Step: 286  | total loss: [1m[32m0.69261[0m[0m | time: 57.875s
[2K
| Adam | epoch: 006 | loss: 0.69261 - acc: 0.5199 -- iter: 1152/1592
[A[ATraining Step: 287  | total loss: [1m[32m0.69331[0m[0m | time: 59.003s
[2K
| Adam | epoch: 006 | loss: 0.69331 - acc: 0.5085 -- iter: 1184/1592
[A[ATraining Step: 288  | total loss: [1m[32m0.69275[0m[0m | time: 60.129s
[2K
| Adam | epoch: 006 | loss: 0.69275 - acc: 0.5170 -- iter: 1216/1592
[A[ATraining Step: 289  | total loss: [1m[32m0.69305[0m[0m | time: 61.409s
[2K
| Adam | epoch: 006 | loss: 0.69305 - acc: 0.5122 -- iter: 1248/1592
[A[ATraining Step: 290  | total loss: [1m[32m0.69185[0m[0m | time: 62.714s
[2K
| Adam | epoch: 006 | loss: 0.69185 - acc: 0.5297 -- iter: 1280/1592
[A[ATraining Step: 291  | total loss: [1m[32m0.69309[0m[0m | time: 63.794s
[2K
| Adam | epoch: 006 | loss: 0.69309 - acc: 0.5111 -- iter: 1312/1592
[A[ATraining Step: 292  | total loss: [1m[32m0.69237[0m[0m | time: 65.098s
[2K
| Adam | epoch: 006 | loss: 0.69237 - acc: 0.5225 -- iter: 1344/1592
[A[ATraining Step: 293  | total loss: [1m[32m0.69190[0m[0m | time: 66.457s
[2K
| Adam | epoch: 006 | loss: 0.69190 - acc: 0.5296 -- iter: 1376/1592
[A[ATraining Step: 294  | total loss: [1m[32m0.69226[0m[0m | time: 67.628s
[2K
| Adam | epoch: 006 | loss: 0.69226 - acc: 0.5236 -- iter: 1408/1592
[A[ATraining Step: 295  | total loss: [1m[32m0.69200[0m[0m | time: 68.715s
[2K
| Adam | epoch: 006 | loss: 0.69200 - acc: 0.5274 -- iter: 1440/1592
[A[ATraining Step: 296  | total loss: [1m[32m0.69279[0m[0m | time: 69.826s
[2K
| Adam | epoch: 006 | loss: 0.69279 - acc: 0.5153 -- iter: 1472/1592
[A[ATraining Step: 297  | total loss: [1m[32m0.69333[0m[0m | time: 70.913s
[2K
| Adam | epoch: 006 | loss: 0.69333 - acc: 0.5075 -- iter: 1504/1592
[A[ATraining Step: 298  | total loss: [1m[32m0.69271[0m[0m | time: 72.094s
[2K
| Adam | epoch: 006 | loss: 0.69271 - acc: 0.5162 -- iter: 1536/1592
[A[ATraining Step: 299  | total loss: [1m[32m0.69200[0m[0m | time: 73.670s
[2K
| Adam | epoch: 006 | loss: 0.69200 - acc: 0.5270 -- iter: 1568/1592
[A[ATraining Step: 300  | total loss: [1m[32m0.69129[0m[0m | time: 78.116s
[2K
| Adam | epoch: 006 | loss: 0.69129 - acc: 0.5368 | val_loss: 0.69465 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 301  | total loss: [1m[32m0.69090[0m[0m | time: 8.939s
[2K
| Adam | epoch: 007 | loss: 0.69090 - acc: 0.5425 -- iter: 0032/1592
[A[ATraining Step: 302  | total loss: [1m[32m0.69160[0m[0m | time: 10.184s
[2K
| Adam | epoch: 007 | loss: 0.69160 - acc: 0.5320 -- iter: 0064/1592
[A[ATraining Step: 303  | total loss: [1m[32m0.69159[0m[0m | time: 11.345s
[2K
| Adam | epoch: 007 | loss: 0.69159 - acc: 0.5320 -- iter: 0096/1592
[A[ATraining Step: 304  | total loss: [1m[32m0.69161[0m[0m | time: 12.557s
[2K
| Adam | epoch: 007 | loss: 0.69161 - acc: 0.5319 -- iter: 0128/1592
[A[ATraining Step: 305  | total loss: [1m[32m0.69134[0m[0m | time: 13.503s
[2K
| Adam | epoch: 007 | loss: 0.69134 - acc: 0.5349 -- iter: 0160/1592
[A[ATraining Step: 306  | total loss: [1m[32m0.69256[0m[0m | time: 14.516s
[2K
| Adam | epoch: 007 | loss: 0.69256 - acc: 0.5189 -- iter: 0192/1592
[A[ATraining Step: 307  | total loss: [1m[32m0.69362[0m[0m | time: 15.696s
[2K
| Adam | epoch: 007 | loss: 0.69362 - acc: 0.5046 -- iter: 0224/1592
[A[ATraining Step: 308  | total loss: [1m[32m0.69339[0m[0m | time: 16.957s
[2K
| Adam | epoch: 007 | loss: 0.69339 - acc: 0.5072 -- iter: 0256/1592
[A[ATraining Step: 309  | total loss: [1m[32m0.69296[0m[0m | time: 18.163s
[2K
| Adam | epoch: 007 | loss: 0.69296 - acc: 0.5128 -- iter: 0288/1592
[A[ATraining Step: 310  | total loss: [1m[32m0.69394[0m[0m | time: 19.514s
[2K
| Adam | epoch: 007 | loss: 0.69394 - acc: 0.4990 -- iter: 0320/1592
[A[ATraining Step: 311  | total loss: [1m[32m0.69323[0m[0m | time: 25.787s
[2K
| Adam | epoch: 007 | loss: 0.69323 - acc: 0.5085 -- iter: 0352/1592
[A[ATraining Step: 312  | total loss: [1m[32m0.69240[0m[0m | time: 33.044s
[2K
| Adam | epoch: 007 | loss: 0.69240 - acc: 0.5201 -- iter: 0384/1592
[A[ATraining Step: 313  | total loss: [1m[32m0.69347[0m[0m | time: 34.260s
[2K
| Adam | epoch: 007 | loss: 0.69347 - acc: 0.5056 -- iter: 0416/1592
[A[ATraining Step: 314  | total loss: [1m[32m0.69372[0m[0m | time: 35.449s
[2K
| Adam | epoch: 007 | loss: 0.69372 - acc: 0.5019 -- iter: 0448/1592
[A[ATraining Step: 315  | total loss: [1m[32m0.69392[0m[0m | time: 36.637s
[2K
| Adam | epoch: 007 | loss: 0.69392 - acc: 0.4986 -- iter: 0480/1592
[A[ATraining Step: 316  | total loss: [1m[32m0.69389[0m[0m | time: 38.031s
[2K
| Adam | epoch: 007 | loss: 0.69389 - acc: 0.4987 -- iter: 0512/1592
[A[ATraining Step: 317  | total loss: [1m[32m0.69278[0m[0m | time: 39.414s
[2K
| Adam | epoch: 007 | loss: 0.69278 - acc: 0.5145 -- iter: 0544/1592
[A[ATraining Step: 318  | total loss: [1m[32m0.69207[0m[0m | time: 40.334s
[2K
| Adam | epoch: 007 | loss: 0.69207 - acc: 0.5255 -- iter: 0576/1592
[A[ATraining Step: 319  | total loss: [1m[32m0.69223[0m[0m | time: 41.445s
[2K
| Adam | epoch: 007 | loss: 0.69223 - acc: 0.5230 -- iter: 0608/1592
[A[ATraining Step: 320  | total loss: [1m[32m0.69306[0m[0m | time: 42.685s
[2K
| Adam | epoch: 007 | loss: 0.69306 - acc: 0.5113 -- iter: 0640/1592
[A[ATraining Step: 321  | total loss: [1m[32m0.69310[0m[0m | time: 44.008s
[2K
| Adam | epoch: 007 | loss: 0.69310 - acc: 0.5102 -- iter: 0672/1592
[A[ATraining Step: 322  | total loss: [1m[32m0.69319[0m[0m | time: 45.370s
[2K
| Adam | epoch: 007 | loss: 0.69319 - acc: 0.5092 -- iter: 0704/1592
[A[ATraining Step: 323  | total loss: [1m[32m0.69305[0m[0m | time: 46.623s
[2K
| Adam | epoch: 007 | loss: 0.69305 - acc: 0.5114 -- iter: 0736/1592
[A[ATraining Step: 324  | total loss: [1m[32m0.69270[0m[0m | time: 48.006s
[2K
| Adam | epoch: 007 | loss: 0.69270 - acc: 0.5165 -- iter: 0768/1592
[A[ATraining Step: 325  | total loss: [1m[32m0.69299[0m[0m | time: 49.314s
[2K
| Adam | epoch: 007 | loss: 0.69299 - acc: 0.5117 -- iter: 0800/1592
[A[ATraining Step: 326  | total loss: [1m[32m0.69246[0m[0m | time: 50.561s
[2K
| Adam | epoch: 007 | loss: 0.69246 - acc: 0.5199 -- iter: 0832/1592
[A[ATraining Step: 327  | total loss: [1m[32m0.69237[0m[0m | time: 51.806s
[2K
| Adam | epoch: 007 | loss: 0.69237 - acc: 0.5210 -- iter: 0864/1592
[A[ATraining Step: 328  | total loss: [1m[32m0.69187[0m[0m | time: 53.133s
[2K
| Adam | epoch: 007 | loss: 0.69187 - acc: 0.5283 -- iter: 0896/1592
[A[ATraining Step: 329  | total loss: [1m[32m0.69102[0m[0m | time: 54.428s
[2K
| Adam | epoch: 007 | loss: 0.69102 - acc: 0.5411 -- iter: 0928/1592
[A[ATraining Step: 330  | total loss: [1m[32m0.69066[0m[0m | time: 55.792s
[2K
| Adam | epoch: 007 | loss: 0.69066 - acc: 0.5464 -- iter: 0960/1592
[A[ATraining Step: 331  | total loss: [1m[32m0.69121[0m[0m | time: 56.974s
[2K
| Adam | epoch: 007 | loss: 0.69121 - acc: 0.5386 -- iter: 0992/1592
[A[ATraining Step: 332  | total loss: [1m[32m0.69142[0m[0m | time: 58.316s
[2K
| Adam | epoch: 007 | loss: 0.69142 - acc: 0.5348 -- iter: 1024/1592
[A[ATraining Step: 333  | total loss: [1m[32m0.69100[0m[0m | time: 59.609s
[2K
| Adam | epoch: 007 | loss: 0.69100 - acc: 0.5407 -- iter: 1056/1592
[A[ATraining Step: 334  | total loss: [1m[32m0.69082[0m[0m | time: 60.863s
[2K
| Adam | epoch: 007 | loss: 0.69082 - acc: 0.5428 -- iter: 1088/1592
[A[ATraining Step: 335  | total loss: [1m[32m0.69135[0m[0m | time: 61.978s
[2K
| Adam | epoch: 007 | loss: 0.69135 - acc: 0.5354 -- iter: 1120/1592
[A[ATraining Step: 336  | total loss: [1m[32m0.69138[0m[0m | time: 63.046s
[2K
| Adam | epoch: 007 | loss: 0.69138 - acc: 0.5350 -- iter: 1152/1592
[A[ATraining Step: 337  | total loss: [1m[32m0.69163[0m[0m | time: 63.857s
[2K
| Adam | epoch: 007 | loss: 0.69163 - acc: 0.5315 -- iter: 1184/1592
[A[ATraining Step: 338  | total loss: [1m[32m0.69132[0m[0m | time: 64.549s
[2K
| Adam | epoch: 007 | loss: 0.69132 - acc: 0.5346 -- iter: 1216/1592
[A[ATraining Step: 339  | total loss: [1m[32m0.69056[0m[0m | time: 65.251s
[2K
| Adam | epoch: 007 | loss: 0.69056 - acc: 0.5436 -- iter: 1248/1592
[A[ATraining Step: 340  | total loss: [1m[32m0.69115[0m[0m | time: 66.060s
[2K
| Adam | epoch: 007 | loss: 0.69115 - acc: 0.5362 -- iter: 1280/1592
[A[ATraining Step: 341  | total loss: [1m[32m0.69169[0m[0m | time: 66.872s
[2K
| Adam | epoch: 007 | loss: 0.69169 - acc: 0.5294 -- iter: 1312/1592
[A[ATraining Step: 342  | total loss: [1m[32m0.69330[0m[0m | time: 67.697s
[2K
| Adam | epoch: 007 | loss: 0.69330 - acc: 0.5109 -- iter: 1344/1592
[A[ATraining Step: 343  | total loss: [1m[32m0.69311[0m[0m | time: 68.443s
[2K
| Adam | epoch: 007 | loss: 0.69311 - acc: 0.5129 -- iter: 1376/1592
[A[ATraining Step: 344  | total loss: [1m[32m0.69215[0m[0m | time: 69.245s
[2K
| Adam | epoch: 007 | loss: 0.69215 - acc: 0.5241 -- iter: 1408/1592
[A[ATraining Step: 345  | total loss: [1m[32m0.69255[0m[0m | time: 70.058s
[2K
| Adam | epoch: 007 | loss: 0.69255 - acc: 0.5186 -- iter: 1440/1592
[A[ATraining Step: 346  | total loss: [1m[32m0.69215[0m[0m | time: 70.842s
[2K
| Adam | epoch: 007 | loss: 0.69215 - acc: 0.5230 -- iter: 1472/1592
[A[ATraining Step: 347  | total loss: [1m[32m0.69236[0m[0m | time: 71.634s
[2K
| Adam | epoch: 007 | loss: 0.69236 - acc: 0.5207 -- iter: 1504/1592
[A[ATraining Step: 348  | total loss: [1m[32m0.69227[0m[0m | time: 72.457s
[2K
| Adam | epoch: 007 | loss: 0.69227 - acc: 0.5217 -- iter: 1536/1592
[A[ATraining Step: 349  | total loss: [1m[32m0.69275[0m[0m | time: 73.181s
[2K
| Adam | epoch: 007 | loss: 0.69275 - acc: 0.5164 -- iter: 1568/1592
[A[ATraining Step: 350  | total loss: [1m[32m0.69364[0m[0m | time: 76.466s
[2K
| Adam | epoch: 007 | loss: 0.69364 - acc: 0.5054 | val_loss: 0.69498 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 351  | total loss: [1m[32m0.69420[0m[0m | time: 0.824s
[2K
| Adam | epoch: 008 | loss: 0.69420 - acc: 0.4986 -- iter: 0032/1592
[A[ATraining Step: 352  | total loss: [1m[32m0.69332[0m[0m | time: 1.609s
[2K
| Adam | epoch: 008 | loss: 0.69332 - acc: 0.5081 -- iter: 0064/1592
[A[ATraining Step: 353  | total loss: [1m[32m0.69285[0m[0m | time: 2.381s
[2K
| Adam | epoch: 008 | loss: 0.69285 - acc: 0.5136 -- iter: 0096/1592
[A[ATraining Step: 354  | total loss: [1m[32m0.69295[0m[0m | time: 3.173s
[2K
| Adam | epoch: 008 | loss: 0.69295 - acc: 0.5122 -- iter: 0128/1592
[A[ATraining Step: 355  | total loss: [1m[32m0.69359[0m[0m | time: 3.965s
[2K
| Adam | epoch: 008 | loss: 0.69359 - acc: 0.5047 -- iter: 0160/1592
[A[ATraining Step: 356  | total loss: [1m[32m0.69365[0m[0m | time: 4.592s
[2K
| Adam | epoch: 008 | loss: 0.69365 - acc: 0.5043 -- iter: 0192/1592
[A[ATraining Step: 357  | total loss: [1m[32m0.69430[0m[0m | time: 5.201s
[2K
| Adam | epoch: 008 | loss: 0.69430 - acc: 0.4955 -- iter: 0224/1592
[A[ATraining Step: 358  | total loss: [1m[32m0.69490[0m[0m | time: 6.363s
[2K
| Adam | epoch: 008 | loss: 0.69490 - acc: 0.4876 -- iter: 0256/1592
[A[ATraining Step: 359  | total loss: [1m[32m0.69501[0m[0m | time: 7.172s
[2K
| Adam | epoch: 008 | loss: 0.69501 - acc: 0.4857 -- iter: 0288/1592
[A[ATraining Step: 360  | total loss: [1m[32m0.69508[0m[0m | time: 7.831s
[2K
| Adam | epoch: 008 | loss: 0.69508 - acc: 0.4840 -- iter: 0320/1592
[A[ATraining Step: 361  | total loss: [1m[32m0.69386[0m[0m | time: 8.740s
[2K
| Adam | epoch: 008 | loss: 0.69386 - acc: 0.5013 -- iter: 0352/1592
[A[ATraining Step: 362  | total loss: [1m[32m0.69321[0m[0m | time: 9.557s
[2K
| Adam | epoch: 008 | loss: 0.69321 - acc: 0.5105 -- iter: 0384/1592
[A[ATraining Step: 363  | total loss: [1m[32m0.69329[0m[0m | time: 10.336s
[2K
| Adam | epoch: 008 | loss: 0.69329 - acc: 0.5095 -- iter: 0416/1592
[A[ATraining Step: 364  | total loss: [1m[32m0.69331[0m[0m | time: 11.110s
[2K
| Adam | epoch: 008 | loss: 0.69331 - acc: 0.5085 -- iter: 0448/1592
[A[ATraining Step: 365  | total loss: [1m[32m0.69399[0m[0m | time: 11.917s
[2K
| Adam | epoch: 008 | loss: 0.69399 - acc: 0.4983 -- iter: 0480/1592
[A[ATraining Step: 366  | total loss: [1m[32m0.69373[0m[0m | time: 13.255s
[2K
| Adam | epoch: 008 | loss: 0.69373 - acc: 0.5016 -- iter: 0512/1592
[A[ATraining Step: 367  | total loss: [1m[32m0.69394[0m[0m | time: 14.538s
[2K
| Adam | epoch: 008 | loss: 0.69394 - acc: 0.4983 -- iter: 0544/1592
[A[ATraining Step: 368  | total loss: [1m[32m0.69353[0m[0m | time: 15.791s
[2K
| Adam | epoch: 008 | loss: 0.69353 - acc: 0.5047 -- iter: 0576/1592
[A[ATraining Step: 369  | total loss: [1m[32m0.69355[0m[0m | time: 17.092s
[2K
| Adam | epoch: 008 | loss: 0.69355 - acc: 0.5042 -- iter: 0608/1592
[A[ATraining Step: 370  | total loss: [1m[32m0.69280[0m[0m | time: 18.239s
[2K
| Adam | epoch: 008 | loss: 0.69280 - acc: 0.5163 -- iter: 0640/1592
[A[ATraining Step: 371  | total loss: [1m[32m0.69345[0m[0m | time: 19.447s
[2K
| Adam | epoch: 008 | loss: 0.69345 - acc: 0.5053 -- iter: 0672/1592
[A[ATraining Step: 372  | total loss: [1m[32m0.69346[0m[0m | time: 20.632s
[2K
| Adam | epoch: 008 | loss: 0.69346 - acc: 0.5048 -- iter: 0704/1592
[A[ATraining Step: 373  | total loss: [1m[32m0.69347[0m[0m | time: 22.056s
[2K
| Adam | epoch: 008 | loss: 0.69347 - acc: 0.5043 -- iter: 0736/1592
[A[ATraining Step: 374  | total loss: [1m[32m0.69329[0m[0m | time: 23.407s
[2K
| Adam | epoch: 008 | loss: 0.69329 - acc: 0.5070 -- iter: 0768/1592
[A[ATraining Step: 375  | total loss: [1m[32m0.69330[0m[0m | time: 24.504s
[2K
| Adam | epoch: 008 | loss: 0.69330 - acc: 0.5063 -- iter: 0800/1592
[A[ATraining Step: 376  | total loss: [1m[32m0.69259[0m[0m | time: 25.913s
[2K
| Adam | epoch: 008 | loss: 0.69259 - acc: 0.5182 -- iter: 0832/1592
[A[ATraining Step: 377  | total loss: [1m[32m0.69234[0m[0m | time: 27.240s
[2K
| Adam | epoch: 008 | loss: 0.69234 - acc: 0.5226 -- iter: 0864/1592
[A[ATraining Step: 378  | total loss: [1m[32m0.69174[0m[0m | time: 28.526s
[2K
| Adam | epoch: 008 | loss: 0.69174 - acc: 0.5328 -- iter: 0896/1592
[A[ATraining Step: 379  | total loss: [1m[32m0.69246[0m[0m | time: 44.002s
[2K
| Adam | epoch: 008 | loss: 0.69246 - acc: 0.5202 -- iter: 0928/1592
[A[ATraining Step: 380  | total loss: [1m[32m0.69182[0m[0m | time: 45.119s
[2K
| Adam | epoch: 008 | loss: 0.69182 - acc: 0.5307 -- iter: 0960/1592
[A[ATraining Step: 381  | total loss: [1m[32m0.69254[0m[0m | time: 46.298s
[2K
| Adam | epoch: 008 | loss: 0.69254 - acc: 0.5182 -- iter: 0992/1592
[A[ATraining Step: 382  | total loss: [1m[32m0.69323[0m[0m | time: 47.368s
[2K
| Adam | epoch: 008 | loss: 0.69323 - acc: 0.5070 -- iter: 1024/1592
[A[ATraining Step: 383  | total loss: [1m[32m0.69363[0m[0m | time: 48.551s
[2K
| Adam | epoch: 008 | loss: 0.69363 - acc: 0.5001 -- iter: 1056/1592
[A[ATraining Step: 384  | total loss: [1m[32m0.69341[0m[0m | time: 49.975s
[2K
| Adam | epoch: 008 | loss: 0.69341 - acc: 0.5032 -- iter: 1088/1592
[A[ATraining Step: 385  | total loss: [1m[32m0.69292[0m[0m | time: 51.145s
[2K
| Adam | epoch: 008 | loss: 0.69292 - acc: 0.5122 -- iter: 1120/1592
[A[ATraining Step: 386  | total loss: [1m[32m0.69229[0m[0m | time: 52.457s
[2K
| Adam | epoch: 008 | loss: 0.69229 - acc: 0.5235 -- iter: 1152/1592
[A[ATraining Step: 387  | total loss: [1m[32m0.69187[0m[0m | time: 53.751s
[2K
| Adam | epoch: 008 | loss: 0.69187 - acc: 0.5305 -- iter: 1184/1592
[A[ATraining Step: 388  | total loss: [1m[32m0.69275[0m[0m | time: 55.029s
[2K
| Adam | epoch: 008 | loss: 0.69275 - acc: 0.5150 -- iter: 1216/1592
[A[ATraining Step: 389  | total loss: [1m[32m0.69285[0m[0m | time: 56.476s
[2K
| Adam | epoch: 008 | loss: 0.69285 - acc: 0.5135 -- iter: 1248/1592
[A[ATraining Step: 390  | total loss: [1m[32m0.69275[0m[0m | time: 57.537s
[2K
| Adam | epoch: 008 | loss: 0.69275 - acc: 0.5153 -- iter: 1280/1592
[A[ATraining Step: 391  | total loss: [1m[32m0.69265[0m[0m | time: 58.695s
[2K
| Adam | epoch: 008 | loss: 0.69265 - acc: 0.5169 -- iter: 1312/1592
[A[ATraining Step: 392  | total loss: [1m[32m0.69258[0m[0m | time: 59.837s
[2K
| Adam | epoch: 008 | loss: 0.69258 - acc: 0.5183 -- iter: 1344/1592
[A[ATraining Step: 393  | total loss: [1m[32m0.69213[0m[0m | time: 61.296s
[2K
| Adam | epoch: 008 | loss: 0.69213 - acc: 0.5258 -- iter: 1376/1592
[A[ATraining Step: 394  | total loss: [1m[32m0.69268[0m[0m | time: 62.663s
[2K
| Adam | epoch: 008 | loss: 0.69268 - acc: 0.5170 -- iter: 1408/1592
[A[ATraining Step: 395  | total loss: [1m[32m0.69317[0m[0m | time: 63.728s
[2K
| Adam | epoch: 008 | loss: 0.69317 - acc: 0.5091 -- iter: 1440/1592
[A[ATraining Step: 396  | total loss: [1m[32m0.69265[0m[0m | time: 65.039s
[2K
| Adam | epoch: 008 | loss: 0.69265 - acc: 0.5175 -- iter: 1472/1592
[A[ATraining Step: 397  | total loss: [1m[32m0.69328[0m[0m | time: 66.311s
[2K
| Adam | epoch: 008 | loss: 0.69328 - acc: 0.5064 -- iter: 1504/1592
[A[ATraining Step: 398  | total loss: [1m[32m0.69294[0m[0m | time: 67.515s
[2K
| Adam | epoch: 008 | loss: 0.69294 - acc: 0.5120 -- iter: 1536/1592
[A[ATraining Step: 399  | total loss: [1m[32m0.69261[0m[0m | time: 75.069s
[2K
| Adam | epoch: 008 | loss: 0.69261 - acc: 0.5171 -- iter: 1568/1592
[A[ATraining Step: 400  | total loss: [1m[32m0.69325[0m[0m | time: 79.323s
[2K
| Adam | epoch: 008 | loss: 0.69325 - acc: 0.5060 | val_loss: 0.69426 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 401  | total loss: [1m[32m0.69306[0m[0m | time: 1.183s
[2K
| Adam | epoch: 009 | loss: 0.69306 - acc: 0.5085 -- iter: 0032/1592
[A[ATraining Step: 402  | total loss: [1m[32m0.69314[0m[0m | time: 2.429s
[2K
| Adam | epoch: 009 | loss: 0.69314 - acc: 0.5077 -- iter: 0064/1592
[A[ATraining Step: 403  | total loss: [1m[32m0.69336[0m[0m | time: 3.632s
[2K
| Adam | epoch: 009 | loss: 0.69336 - acc: 0.5038 -- iter: 0096/1592
[A[ATraining Step: 404  | total loss: [1m[32m0.69303[0m[0m | time: 4.879s
[2K
| Adam | epoch: 009 | loss: 0.69303 - acc: 0.5096 -- iter: 0128/1592
[A[ATraining Step: 405  | total loss: [1m[32m0.69413[0m[0m | time: 6.405s
[2K
| Adam | epoch: 009 | loss: 0.69413 - acc: 0.4899 -- iter: 0160/1592
[A[ATraining Step: 406  | total loss: [1m[32m0.69403[0m[0m | time: 7.597s
[2K
| Adam | epoch: 009 | loss: 0.69403 - acc: 0.4909 -- iter: 0192/1592
[A[ATraining Step: 407  | total loss: [1m[32m0.69364[0m[0m | time: 8.507s
[2K
| Adam | epoch: 009 | loss: 0.69364 - acc: 0.4981 -- iter: 0224/1592
[A[ATraining Step: 408  | total loss: [1m[32m0.69323[0m[0m | time: 9.465s
[2K
| Adam | epoch: 009 | loss: 0.69323 - acc: 0.5066 -- iter: 0256/1592
[A[ATraining Step: 409  | total loss: [1m[32m0.69285[0m[0m | time: 10.639s
[2K
| Adam | epoch: 009 | loss: 0.69285 - acc: 0.5143 -- iter: 0288/1592
[A[ATraining Step: 410  | total loss: [1m[32m0.69356[0m[0m | time: 12.004s
[2K
| Adam | epoch: 009 | loss: 0.69356 - acc: 0.5004 -- iter: 0320/1592
[A[ATraining Step: 411  | total loss: [1m[32m0.69370[0m[0m | time: 13.195s
[2K
| Adam | epoch: 009 | loss: 0.69370 - acc: 0.4972 -- iter: 0352/1592
[A[ATraining Step: 412  | total loss: [1m[32m0.69319[0m[0m | time: 14.419s
[2K
| Adam | epoch: 009 | loss: 0.69319 - acc: 0.5069 -- iter: 0384/1592
[A[ATraining Step: 413  | total loss: [1m[32m0.69280[0m[0m | time: 15.786s
[2K
| Adam | epoch: 009 | loss: 0.69280 - acc: 0.5155 -- iter: 0416/1592
[A[ATraining Step: 414  | total loss: [1m[32m0.69212[0m[0m | time: 17.090s
[2K
| Adam | epoch: 009 | loss: 0.69212 - acc: 0.5296 -- iter: 0448/1592
[A[ATraining Step: 415  | total loss: [1m[32m0.69193[0m[0m | time: 18.053s
[2K
| Adam | epoch: 009 | loss: 0.69193 - acc: 0.5329 -- iter: 0480/1592
[A[ATraining Step: 416  | total loss: [1m[32m0.69205[0m[0m | time: 19.238s
[2K
| Adam | epoch: 009 | loss: 0.69205 - acc: 0.5296 -- iter: 0512/1592
[A[ATraining Step: 417  | total loss: [1m[32m0.69240[0m[0m | time: 20.389s
[2K
| Adam | epoch: 009 | loss: 0.69240 - acc: 0.5235 -- iter: 0544/1592
[A[ATraining Step: 418  | total loss: [1m[32m0.69182[0m[0m | time: 21.515s
[2K
| Adam | epoch: 009 | loss: 0.69182 - acc: 0.5337 -- iter: 0576/1592
[A[ATraining Step: 419  | total loss: [1m[32m0.69131[0m[0m | time: 22.854s
[2K
| Adam | epoch: 009 | loss: 0.69131 - acc: 0.5428 -- iter: 0608/1592
[A[ATraining Step: 420  | total loss: [1m[32m0.69175[0m[0m | time: 24.177s
[2K
| Adam | epoch: 009 | loss: 0.69175 - acc: 0.5354 -- iter: 0640/1592
[A[ATraining Step: 421  | total loss: [1m[32m0.69177[0m[0m | time: 25.239s
[2K
| Adam | epoch: 009 | loss: 0.69177 - acc: 0.5350 -- iter: 0672/1592
[A[ATraining Step: 422  | total loss: [1m[32m0.69119[0m[0m | time: 26.333s
[2K
| Adam | epoch: 009 | loss: 0.69119 - acc: 0.5440 -- iter: 0704/1592
[A[ATraining Step: 423  | total loss: [1m[32m0.69201[0m[0m | time: 27.667s
[2K
| Adam | epoch: 009 | loss: 0.69201 - acc: 0.5302 -- iter: 0736/1592
[A[ATraining Step: 424  | total loss: [1m[32m0.69198[0m[0m | time: 28.848s
[2K
| Adam | epoch: 009 | loss: 0.69198 - acc: 0.5303 -- iter: 0768/1592
[A[ATraining Step: 425  | total loss: [1m[32m0.69210[0m[0m | time: 29.984s
[2K
| Adam | epoch: 009 | loss: 0.69210 - acc: 0.5273 -- iter: 0800/1592
[A[ATraining Step: 426  | total loss: [1m[32m0.69306[0m[0m | time: 31.108s
[2K
| Adam | epoch: 009 | loss: 0.69306 - acc: 0.5121 -- iter: 0832/1592
[A[ATraining Step: 427  | total loss: [1m[32m0.69374[0m[0m | time: 32.315s
[2K
| Adam | epoch: 009 | loss: 0.69374 - acc: 0.5015 -- iter: 0864/1592
[A[ATraining Step: 428  | total loss: [1m[32m0.69356[0m[0m | time: 33.563s
[2K
| Adam | epoch: 009 | loss: 0.69356 - acc: 0.5045 -- iter: 0896/1592
[A[ATraining Step: 429  | total loss: [1m[32m0.69354[0m[0m | time: 34.940s
[2K
| Adam | epoch: 009 | loss: 0.69354 - acc: 0.5040 -- iter: 0928/1592
[A[ATraining Step: 430  | total loss: [1m[32m0.69224[0m[0m | time: 36.175s
[2K
| Adam | epoch: 009 | loss: 0.69224 - acc: 0.5255 -- iter: 0960/1592
[A[ATraining Step: 431  | total loss: [1m[32m0.69100[0m[0m | time: 37.229s
[2K
| Adam | epoch: 009 | loss: 0.69100 - acc: 0.5448 -- iter: 0992/1592
[A[ATraining Step: 432  | total loss: [1m[32m0.69023[0m[0m | time: 38.559s
[2K
| Adam | epoch: 009 | loss: 0.69023 - acc: 0.5560 -- iter: 1024/1592
[A[ATraining Step: 433  | total loss: [1m[32m0.69035[0m[0m | time: 39.949s
[2K
| Adam | epoch: 009 | loss: 0.69035 - acc: 0.5535 -- iter: 1056/1592
[A[ATraining Step: 434  | total loss: [1m[32m0.69089[0m[0m | time: 41.023s
[2K
| Adam | epoch: 009 | loss: 0.69089 - acc: 0.5450 -- iter: 1088/1592
[A[ATraining Step: 435  | total loss: [1m[32m0.69072[0m[0m | time: 42.033s
[2K
| Adam | epoch: 009 | loss: 0.69072 - acc: 0.5468 -- iter: 1120/1592
[A[ATraining Step: 436  | total loss: [1m[32m0.69121[0m[0m | time: 43.062s
[2K
| Adam | epoch: 009 | loss: 0.69121 - acc: 0.5390 -- iter: 1152/1592
[A[ATraining Step: 437  | total loss: [1m[32m0.69122[0m[0m | time: 44.213s
[2K
| Adam | epoch: 009 | loss: 0.69122 - acc: 0.5382 -- iter: 1184/1592
[A[ATraining Step: 438  | total loss: [1m[32m0.69175[0m[0m | time: 45.490s
[2K
| Adam | epoch: 009 | loss: 0.69175 - acc: 0.5312 -- iter: 1216/1592
[A[ATraining Step: 439  | total loss: [1m[32m0.69264[0m[0m | time: 46.935s
[2K
| Adam | epoch: 009 | loss: 0.69264 - acc: 0.5187 -- iter: 1248/1592
[A[ATraining Step: 440  | total loss: [1m[32m0.69349[0m[0m | time: 48.144s
[2K
| Adam | epoch: 009 | loss: 0.69349 - acc: 0.5075 -- iter: 1280/1592
[A[ATraining Step: 441  | total loss: [1m[32m0.69447[0m[0m | time: 49.128s
[2K
| Adam | epoch: 009 | loss: 0.69447 - acc: 0.4942 -- iter: 1312/1592
[A[ATraining Step: 442  | total loss: [1m[32m0.69463[0m[0m | time: 50.443s
[2K
| Adam | epoch: 009 | loss: 0.69463 - acc: 0.4917 -- iter: 1344/1592
[A[ATraining Step: 443  | total loss: [1m[32m0.69523[0m[0m | time: 51.810s
[2K
| Adam | epoch: 009 | loss: 0.69523 - acc: 0.4832 -- iter: 1376/1592
[A[ATraining Step: 444  | total loss: [1m[32m0.69507[0m[0m | time: 52.985s
[2K
| Adam | epoch: 009 | loss: 0.69507 - acc: 0.4848 -- iter: 1408/1592
[A[ATraining Step: 445  | total loss: [1m[32m0.69539[0m[0m | time: 54.085s
[2K
| Adam | epoch: 009 | loss: 0.69539 - acc: 0.4801 -- iter: 1440/1592
[A[ATraining Step: 446  | total loss: [1m[32m0.69521[0m[0m | time: 55.183s
[2K
| Adam | epoch: 009 | loss: 0.69521 - acc: 0.4821 -- iter: 1472/1592
[A[ATraining Step: 447  | total loss: [1m[32m0.69402[0m[0m | time: 56.400s
[2K
| Adam | epoch: 009 | loss: 0.69402 - acc: 0.4995 -- iter: 1504/1592
[A[ATraining Step: 448  | total loss: [1m[32m0.69357[0m[0m | time: 57.549s
[2K
| Adam | epoch: 009 | loss: 0.69357 - acc: 0.5058 -- iter: 1536/1592
[A[ATraining Step: 449  | total loss: [1m[32m0.69341[0m[0m | time: 58.774s
[2K
| Adam | epoch: 009 | loss: 0.69341 - acc: 0.5084 -- iter: 1568/1592
[A[ATraining Step: 450  | total loss: [1m[32m0.69455[0m[0m | time: 63.747s
[2K
| Adam | epoch: 009 | loss: 0.69455 - acc: 0.4888 | val_loss: 0.69417 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 451  | total loss: [1m[32m0.69521[0m[0m | time: 1.061s
[2K
| Adam | epoch: 010 | loss: 0.69521 - acc: 0.4774 -- iter: 0032/1592
[A[ATraining Step: 452  | total loss: [1m[32m0.69418[0m[0m | time: 2.337s
[2K
| Adam | epoch: 010 | loss: 0.69418 - acc: 0.4953 -- iter: 0064/1592
[A[ATraining Step: 453  | total loss: [1m[32m0.69495[0m[0m | time: 3.517s
[2K
| Adam | epoch: 010 | loss: 0.69495 - acc: 0.4801 -- iter: 0096/1592
[A[ATraining Step: 454  | total loss: [1m[32m0.69480[0m[0m | time: 4.815s
[2K
| Adam | epoch: 010 | loss: 0.69480 - acc: 0.4821 -- iter: 0128/1592
[A[ATraining Step: 455  | total loss: [1m[32m0.69404[0m[0m | time: 6.287s
[2K
| Adam | epoch: 010 | loss: 0.69404 - acc: 0.4964 -- iter: 0160/1592
[A[ATraining Step: 456  | total loss: [1m[32m0.69400[0m[0m | time: 7.456s
[2K
| Adam | epoch: 010 | loss: 0.69400 - acc: 0.4968 -- iter: 0192/1592
[A[ATraining Step: 457  | total loss: [1m[32m0.69376[0m[0m | time: 8.726s
[2K
| Adam | epoch: 010 | loss: 0.69376 - acc: 0.5002 -- iter: 0224/1592
[A[ATraining Step: 458  | total loss: [1m[32m0.69318[0m[0m | time: 9.663s
[2K
| Adam | epoch: 010 | loss: 0.69318 - acc: 0.5127 -- iter: 0256/1592
[A[ATraining Step: 459  | total loss: [1m[32m0.69304[0m[0m | time: 10.592s
[2K
| Adam | epoch: 010 | loss: 0.69304 - acc: 0.5156 -- iter: 0288/1592
[A[ATraining Step: 460  | total loss: [1m[32m0.69288[0m[0m | time: 11.830s
[2K
| Adam | epoch: 010 | loss: 0.69288 - acc: 0.5182 -- iter: 0320/1592
[A[ATraining Step: 461  | total loss: [1m[32m0.69323[0m[0m | time: 12.922s
[2K
| Adam | epoch: 010 | loss: 0.69323 - acc: 0.5101 -- iter: 0352/1592
[A[ATraining Step: 462  | total loss: [1m[32m0.69354[0m[0m | time: 14.103s
[2K
| Adam | epoch: 010 | loss: 0.69354 - acc: 0.5029 -- iter: 0384/1592
[A[ATraining Step: 463  | total loss: [1m[32m0.69309[0m[0m | time: 15.229s
[2K
| Adam | epoch: 010 | loss: 0.69309 - acc: 0.5120 -- iter: 0416/1592
[A[ATraining Step: 464  | total loss: [1m[32m0.69256[0m[0m | time: 16.540s
[2K
| Adam | epoch: 010 | loss: 0.69256 - acc: 0.5233 -- iter: 0448/1592
[A[ATraining Step: 465  | total loss: [1m[32m0.69234[0m[0m | time: 17.982s
[2K
| Adam | epoch: 010 | loss: 0.69234 - acc: 0.5272 -- iter: 0480/1592
[A[ATraining Step: 466  | total loss: [1m[32m0.69271[0m[0m | time: 19.183s
[2K
| Adam | epoch: 010 | loss: 0.69271 - acc: 0.5182 -- iter: 0512/1592
[A[ATraining Step: 467  | total loss: [1m[32m0.69214[0m[0m | time: 20.293s
[2K
| Adam | epoch: 010 | loss: 0.69214 - acc: 0.5289 -- iter: 0544/1592
[A[ATraining Step: 468  | total loss: [1m[32m0.69178[0m[0m | time: 21.481s
[2K
| Adam | epoch: 010 | loss: 0.69178 - acc: 0.5354 -- iter: 0576/1592
[A[ATraining Step: 469  | total loss: [1m[32m0.69209[0m[0m | time: 22.816s
[2K
| Adam | epoch: 010 | loss: 0.69209 - acc: 0.5287 -- iter: 0608/1592
[A[ATraining Step: 470  | total loss: [1m[32m0.69204[0m[0m | time: 24.138s
[2K
| Adam | epoch: 010 | loss: 0.69204 - acc: 0.5290 -- iter: 0640/1592
[A[ATraining Step: 471  | total loss: [1m[32m0.69190[0m[0m | time: 25.262s
[2K
| Adam | epoch: 010 | loss: 0.69190 - acc: 0.5292 -- iter: 0672/1592
[A[ATraining Step: 472  | total loss: [1m[32m0.69168[0m[0m | time: 26.362s
[2K
| Adam | epoch: 010 | loss: 0.69168 - acc: 0.5325 -- iter: 0704/1592
[A[ATraining Step: 473  | total loss: [1m[32m0.69201[0m[0m | time: 27.495s
[2K
| Adam | epoch: 010 | loss: 0.69201 - acc: 0.5230 -- iter: 0736/1592
[A[ATraining Step: 474  | total loss: [1m[32m0.69208[0m[0m | time: 28.697s
[2K
| Adam | epoch: 010 | loss: 0.69208 - acc: 0.5207 -- iter: 0768/1592
[A[ATraining Step: 475  | total loss: [1m[32m0.69192[0m[0m | time: 30.077s
[2K
| Adam | epoch: 010 | loss: 0.69192 - acc: 0.5218 -- iter: 0800/1592
[A[ATraining Step: 476  | total loss: [1m[32m0.69183[0m[0m | time: 31.256s
[2K
| Adam | epoch: 010 | loss: 0.69183 - acc: 0.5258 -- iter: 0832/1592
[A[ATraining Step: 477  | total loss: [1m[32m0.69128[0m[0m | time: 32.351s
[2K
| Adam | epoch: 010 | loss: 0.69128 - acc: 0.5326 -- iter: 0864/1592
[A[ATraining Step: 478  | total loss: [1m[32m0.69103[0m[0m | time: 33.734s
[2K
| Adam | epoch: 010 | loss: 0.69103 - acc: 0.5356 -- iter: 0896/1592
[A[ATraining Step: 479  | total loss: [1m[32m0.69130[0m[0m | time: 35.027s
[2K
| Adam | epoch: 010 | loss: 0.69130 - acc: 0.5289 -- iter: 0928/1592
[A[ATraining Step: 480  | total loss: [1m[32m0.69134[0m[0m | time: 36.019s
[2K
| Adam | epoch: 010 | loss: 0.69134 - acc: 0.5229 -- iter: 0960/1592
[A[ATraining Step: 481  | total loss: [1m[32m0.69125[0m[0m | time: 43.878s
[2K
| Adam | epoch: 010 | loss: 0.69125 - acc: 0.5175 -- iter: 0992/1592
[A[ATraining Step: 482  | total loss: [1m[32m0.69062[0m[0m | time: 44.933s
[2K
| Adam | epoch: 010 | loss: 0.69062 - acc: 0.5314 -- iter: 1024/1592
[A[ATraining Step: 483  | total loss: [1m[32m0.68947[0m[0m | time: 46.050s
[2K
| Adam | epoch: 010 | loss: 0.68947 - acc: 0.5470 -- iter: 1056/1592
[A[ATraining Step: 484  | total loss: [1m[32m0.69019[0m[0m | time: 47.179s
[2K
| Adam | epoch: 010 | loss: 0.69019 - acc: 0.5329 -- iter: 1088/1592
[A[ATraining Step: 485  | total loss: [1m[32m0.68969[0m[0m | time: 48.339s
[2K
| Adam | epoch: 010 | loss: 0.68969 - acc: 0.5296 -- iter: 1120/1592
[A[ATraining Step: 486  | total loss: [1m[32m0.68911[0m[0m | time: 49.510s
[2K
| Adam | epoch: 010 | loss: 0.68911 - acc: 0.5360 -- iter: 1152/1592
[A[ATraining Step: 487  | total loss: [1m[32m0.68915[0m[0m | time: 50.758s
[2K
| Adam | epoch: 010 | loss: 0.68915 - acc: 0.5418 -- iter: 1184/1592
[A[ATraining Step: 488  | total loss: [1m[32m0.68938[0m[0m | time: 51.824s
[2K
| Adam | epoch: 010 | loss: 0.68938 - acc: 0.5470 -- iter: 1216/1592
[A[ATraining Step: 489  | total loss: [1m[32m0.68869[0m[0m | time: 53.222s
[2K
| Adam | epoch: 010 | loss: 0.68869 - acc: 0.5548 -- iter: 1248/1592
[A[ATraining Step: 490  | total loss: [1m[32m0.69063[0m[0m | time: 54.514s
[2K
| Adam | epoch: 010 | loss: 0.69063 - acc: 0.5368 -- iter: 1280/1592
[A[ATraining Step: 491  | total loss: [1m[32m0.69179[0m[0m | time: 55.748s
[2K
| Adam | epoch: 010 | loss: 0.69179 - acc: 0.5269 -- iter: 1312/1592
[A[ATraining Step: 492  | total loss: [1m[32m0.69285[0m[0m | time: 73.150s
[2K
| Adam | epoch: 010 | loss: 0.69285 - acc: 0.5180 -- iter: 1344/1592
[A[ATraining Step: 493  | total loss: [1m[32m0.69329[0m[0m | time: 74.273s
[2K
| Adam | epoch: 010 | loss: 0.69329 - acc: 0.5130 -- iter: 1376/1592
[A[ATraining Step: 494  | total loss: [1m[32m0.69314[0m[0m | time: 75.426s
[2K
| Adam | epoch: 010 | loss: 0.69314 - acc: 0.5149 -- iter: 1408/1592
[A[ATraining Step: 495  | total loss: [1m[32m0.69287[0m[0m | time: 76.547s
[2K
| Adam | epoch: 010 | loss: 0.69287 - acc: 0.5165 -- iter: 1440/1592
[A[ATraining Step: 496  | total loss: [1m[32m0.69287[0m[0m | time: 77.832s
[2K
| Adam | epoch: 010 | loss: 0.69287 - acc: 0.5148 -- iter: 1472/1592
[A[ATraining Step: 497  | total loss: [1m[32m0.69221[0m[0m | time: 79.183s
[2K
| Adam | epoch: 010 | loss: 0.69221 - acc: 0.5227 -- iter: 1504/1592
[A[ATraining Step: 498  | total loss: [1m[32m0.69161[0m[0m | time: 80.255s
[2K
| Adam | epoch: 010 | loss: 0.69161 - acc: 0.5298 -- iter: 1536/1592
[A[ATraining Step: 499  | total loss: [1m[32m0.69203[0m[0m | time: 81.472s
[2K
| Adam | epoch: 010 | loss: 0.69203 - acc: 0.5237 -- iter: 1568/1592
[A[ATraining Step: 500  | total loss: [1m[32m0.69071[0m[0m | time: 85.846s
[2K
| Adam | epoch: 010 | loss: 0.69071 - acc: 0.5370 | val_loss: 0.69556 - val_acc: 0.4880 -- iter: 1592/1592
--
Training Step: 501  | total loss: [1m[32m0.69067[0m[0m | time: 1.172s
[2K
| Adam | epoch: 011 | loss: 0.69067 - acc: 0.5364 -- iter: 0032/1592
[A[ATraining Step: 502  | total loss: [1m[32m0.69065[0m[0m | time: 2.771s
[2K
| Adam | epoch: 011 | loss: 0.69065 - acc: 0.5359 -- iter: 0064/1592
[A[ATraining Step: 503  | total loss: [1m[32m0.68939[0m[0m | time: 3.862s
[2K
| Adam | epoch: 011 | loss: 0.68939 - acc: 0.5448 -- iter: 0096/1592
[A[ATraining Step: 504  | total loss: [1m[32m0.68790[0m[0m | time: 5.136s
[2K
| Adam | epoch: 011 | loss: 0.68790 - acc: 0.5528 -- iter: 0128/1592
[A[ATraining Step: 505  | total loss: [1m[32m0.68832[0m[0m | time: 6.359s
[2K
| Adam | epoch: 011 | loss: 0.68832 - acc: 0.5507 -- iter: 0160/1592
[A[ATraining Step: 506  | total loss: [1m[32m0.68601[0m[0m | time: 7.643s
[2K
| Adam | epoch: 011 | loss: 0.68601 - acc: 0.5581 -- iter: 0192/1592
[A[ATraining Step: 507  | total loss: [1m[32m0.69363[0m[0m | time: 12.555s
[2K
| Adam | epoch: 011 | loss: 0.69363 - acc: 0.5429 -- iter: 0224/1592
[A[ATraining Step: 508  | total loss: [1m[32m0.69935[0m[0m | time: 14.687s
[2K
| Adam | epoch: 011 | loss: 0.69935 - acc: 0.5230 -- iter: 0256/1592
[A[ATraining Step: 509  | total loss: [1m[32m0.69803[0m[0m | time: 15.582s
[2K
| Adam | epoch: 011 | loss: 0.69803 - acc: 0.5238 -- iter: 0288/1592
[A[ATraining Step: 510  | total loss: [1m[32m0.69772[0m[0m | time: 16.460s
[2K
| Adam | epoch: 011 | loss: 0.69772 - acc: 0.5173 -- iter: 0320/1592
[A[ATraining Step: 511  | total loss: [1m[32m0.69737[0m[0m | time: 17.643s
[2K
| Adam | epoch: 011 | loss: 0.69737 - acc: 0.5114 -- iter: 0352/1592
[A[ATraining Step: 512  | total loss: [1m[32m0.69658[0m[0m | time: 18.779s
[2K
| Adam | epoch: 011 | loss: 0.69658 - acc: 0.5196 -- iter: 0384/1592
[A[ATraining Step: 513  | total loss: [1m[32m0.69521[0m[0m | time: 20.109s
[2K
| Adam | epoch: 011 | loss: 0.69521 - acc: 0.5239 -- iter: 0416/1592
[A[ATraining Step: 514  | total loss: [1m[32m0.69630[0m[0m | time: 21.164s
[2K
| Adam | epoch: 011 | loss: 0.69630 - acc: 0.5184 -- iter: 0448/1592
[A[ATraining Step: 515  | total loss: [1m[32m0.69679[0m[0m | time: 22.261s
[2K
| Adam | epoch: 011 | loss: 0.69679 - acc: 0.5134 -- iter: 0480/1592
[A[ATraining Step: 516  | total loss: [1m[32m0.69498[0m[0m | time: 23.501s
[2K
| Adam | epoch: 011 | loss: 0.69498 - acc: 0.5215 -- iter: 0512/1592
[A[ATraining Step: 517  | total loss: [1m[32m0.69445[0m[0m | time: 24.910s
[2K
| Adam | epoch: 011 | loss: 0.69445 - acc: 0.5131 -- iter: 0544/1592
[A[ATraining Step: 518  | total loss: [1m[32m0.69366[0m[0m | time: 26.268s
[2K
| Adam | epoch: 011 | loss: 0.69366 - acc: 0.5149 -- iter: 0576/1592
[A[ATraining Step: 519  | total loss: [1m[32m0.69340[0m[0m | time: 27.309s
[2K
| Adam | epoch: 011 | loss: 0.69340 - acc: 0.5165 -- iter: 0608/1592
[A[ATraining Step: 520  | total loss: [1m[32m0.69414[0m[0m | time: 28.320s
[2K
| Adam | epoch: 011 | loss: 0.69414 - acc: 0.4992 -- iter: 0640/1592
[A[ATraining Step: 521  | total loss: [1m[32m0.69426[0m[0m | time: 29.414s
[2K
| Adam | epoch: 011 | loss: 0.69426 - acc: 0.4931 -- iter: 0672/1592
[A[ATraining Step: 522  | total loss: [1m[32m0.69404[0m[0m | time: 30.486s
[2K
| Adam | epoch: 011 | loss: 0.69404 - acc: 0.4906 -- iter: 0704/1592
[A[ATraining Step: 523  | total loss: [1m[32m0.69337[0m[0m | time: 31.660s
[2K
| Adam | epoch: 011 | loss: 0.69337 - acc: 0.5041 -- iter: 0736/1592
[A[ATraining Step: 524  | total loss: [1m[32m0.69340[0m[0m | time: 33.042s
[2K
| Adam | epoch: 011 | loss: 0.69340 - acc: 0.5005 -- iter: 0768/1592
[A[ATraining Step: 525  | total loss: [1m[32m0.69262[0m[0m | time: 34.180s
[2K
| Adam | epoch: 011 | loss: 0.69262 - acc: 0.5067 -- iter: 0800/1592
[A[ATraining Step: 526  | total loss: [1m[32m0.69206[0m[0m | time: 35.454s
[2K
| Adam | epoch: 011 | loss: 0.69206 - acc: 0.5123 -- iter: 0832/1592
[A[ATraining Step: 527  | total loss: [1m[32m0.69291[0m[0m | time: 36.912s
[2K
| Adam | epoch: 011 | loss: 0.69291 - acc: 0.5048 -- iter: 0864/1592
[A[ATraining Step: 528  | total loss: [1m[32m0.69297[0m[0m | time: 38.008s
[2K
| Adam | epoch: 011 | loss: 0.69297 - acc: 0.5012 -- iter: 0896/1592
[A[ATraining Step: 529  | total loss: [1m[32m0.69216[0m[0m | time: 58.682s
[2K
| Adam | epoch: 011 | loss: 0.69216 - acc: 0.5074 -- iter: 0928/1592
[A[ATraining Step: 530  | total loss: [1m[32m0.69152[0m[0m | time: 63.819s
[2K
| Adam | epoch: 011 | loss: 0.69152 - acc: 0.5316 -- iter: 0960/1592
[A[ATraining Step: 531  | total loss: [1m[32m0.69067[0m[0m | time: 65.034s
[2K
| Adam | epoch: 011 | loss: 0.69067 - acc: 0.5472 -- iter: 0992/1592
[A[ATraining Step: 532  | total loss: [1m[32m0.68963[0m[0m | time: 66.350s
[2K
| Adam | epoch: 011 | loss: 0.68963 - acc: 0.5644 -- iter: 1024/1592
[A[ATraining Step: 533  | total loss: [1m[32m0.68897[0m[0m | time: 67.722s
[2K
| Adam | epoch: 011 | loss: 0.68897 - acc: 0.5673 -- iter: 1056/1592
[A[ATraining Step: 534  | total loss: [1m[32m0.68899[0m[0m | time: 68.953s
[2K
| Adam | epoch: 011 | loss: 0.68899 - acc: 0.5543 -- iter: 1088/1592
[A[ATraining Step: 535  | total loss: [1m[32m0.68791[0m[0m | time: 70.103s
[2K
| Adam | epoch: 011 | loss: 0.68791 - acc: 0.5583 -- iter: 1120/1592
[A[ATraining Step: 536  | total loss: [1m[32m0.68489[0m[0m | time: 71.188s
[2K
| Adam | epoch: 011 | loss: 0.68489 - acc: 0.5899 -- iter: 1152/1592
[A[ATraining Step: 537  | total loss: [1m[32m0.68404[0m[0m | time: 72.523s
[2K
| Adam | epoch: 011 | loss: 0.68404 - acc: 0.5966 -- iter: 1184/1592
[A[ATraining Step: 538  | total loss: [1m[32m0.68372[0m[0m | time: 73.856s
[2K
| Adam | epoch: 011 | loss: 0.68372 - acc: 0.5838 -- iter: 1216/1592
[A[ATraining Step: 539  | total loss: [1m[32m0.68037[0m[0m | time: 74.976s
[2K
| Adam | epoch: 011 | loss: 0.68037 - acc: 0.5910 -- iter: 1248/1592
[A[ATraining Step: 540  | total loss: [1m[32m0.67686[0m[0m | time: 76.131s
[2K
| Adam | epoch: 011 | loss: 0.67686 - acc: 0.5913 -- iter: 1280/1592
[A[ATraining Step: 541  | total loss: [1m[32m0.68086[0m[0m | time: 77.246s
[2K
| Adam | epoch: 011 | loss: 0.68086 - acc: 0.5728 -- iter: 1312/1592
[A[ATraining Step: 542  | total loss: [1m[32m0.67886[0m[0m | time: 78.397s
[2K
| Adam | epoch: 011 | loss: 0.67886 - acc: 0.5749 -- iter: 1344/1592
[A[ATraining Step: 543  | total loss: [1m[32m0.67222[0m[0m | time: 79.592s
[2K
| Adam | epoch: 011 | loss: 0.67222 - acc: 0.5862 -- iter: 1376/1592
[A[ATraining Step: 544  | total loss: [1m[32m0.67067[0m[0m | time: 80.956s
[2K
| Adam | epoch: 011 | loss: 0.67067 - acc: 0.5807 -- iter: 1408/1592
[A[ATraining Step: 545  | total loss: [1m[32m0.67083[0m[0m | time: 82.093s
[2K
| Adam | epoch: 011 | loss: 0.67083 - acc: 0.5851 -- iter: 1440/1592
[A[ATraining Step: 546  | total loss: [1m[32m0.67191[0m[0m | time: 83.355s
[2K
| Adam | epoch: 011 | loss: 0.67191 - acc: 0.5891 -- iter: 1472/1592
[A[ATraining Step: 547  | total loss: [1m[32m0.67236[0m[0m | time: 84.711s
[2K
| Adam | epoch: 011 | loss: 0.67236 - acc: 0.5833 -- iter: 1504/1592
[A[ATraining Step: 548  | total loss: [1m[32m0.66808[0m[0m | time: 85.950s
[2K
| Adam | epoch: 011 | loss: 0.66808 - acc: 0.5812 -- iter: 1536/1592
[A[ATraining Step: 549  | total loss: [1m[32m0.66756[0m[0m | time: 87.128s
[2K
| Adam | epoch: 011 | loss: 0.66756 - acc: 0.5981 -- iter: 1568/1592
[A[ATraining Step: 550  | total loss: [1m[32m0.66464[0m[0m | time: 91.866s
[2K
| Adam | epoch: 011 | loss: 0.66464 - acc: 0.6133 | val_loss: 0.64743 - val_acc: 0.5643 -- iter: 1592/1592
--
Training Step: 551  | total loss: [1m[32m0.66082[0m[0m | time: 1.105s
[2K
| Adam | epoch: 012 | loss: 0.66082 - acc: 0.6270 -- iter: 0032/1592
[A[ATraining Step: 552  | total loss: [1m[32m0.65129[0m[0m | time: 2.281s
[2K
| Adam | epoch: 012 | loss: 0.65129 - acc: 0.6393 -- iter: 0064/1592
[A[ATraining Step: 553  | total loss: [1m[32m0.65485[0m[0m | time: 3.451s
[2K
| Adam | epoch: 012 | loss: 0.65485 - acc: 0.6347 -- iter: 0096/1592
[A[ATraining Step: 554  | total loss: [1m[32m0.65935[0m[0m | time: 4.747s
[2K
| Adam | epoch: 012 | loss: 0.65935 - acc: 0.6212 -- iter: 0128/1592
[A[ATraining Step: 555  | total loss: [1m[32m0.65145[0m[0m | time: 5.965s
[2K
| Adam | epoch: 012 | loss: 0.65145 - acc: 0.6341 -- iter: 0160/1592
[A[ATraining Step: 556  | total loss: [1m[32m0.65515[0m[0m | time: 7.338s
[2K
| Adam | epoch: 012 | loss: 0.65515 - acc: 0.6238 -- iter: 0192/1592
[A[ATraining Step: 557  | total loss: [1m[32m0.65939[0m[0m | time: 8.660s
[2K
| Adam | epoch: 012 | loss: 0.65939 - acc: 0.6114 -- iter: 0224/1592
[A[ATraining Step: 558  | total loss: [1m[32m0.65560[0m[0m | time: 10.054s
[2K
| Adam | epoch: 012 | loss: 0.65560 - acc: 0.6222 -- iter: 0256/1592
[A[ATraining Step: 559  | total loss: [1m[32m0.65218[0m[0m | time: 11.371s
[2K
| Adam | epoch: 012 | loss: 0.65218 - acc: 0.6256 -- iter: 0288/1592
[A[ATraining Step: 560  | total loss: [1m[32m0.64785[0m[0m | time: 12.244s
[2K
| Adam | epoch: 012 | loss: 0.64785 - acc: 0.6318 -- iter: 0320/1592
[A[ATraining Step: 561  | total loss: [1m[32m0.64419[0m[0m | time: 62.781s
[2K
| Adam | epoch: 012 | loss: 0.64419 - acc: 0.6353 -- iter: 0352/1592
[A[ATraining Step: 562  | total loss: [1m[32m0.63882[0m[0m | time: 81.120s
[2K
| Adam | epoch: 012 | loss: 0.63882 - acc: 0.6384 -- iter: 0384/1592
[A[ATraining Step: 563  | total loss: [1m[32m0.63068[0m[0m | time: 82.229s
[2K
| Adam | epoch: 012 | loss: 0.63068 - acc: 0.6433 -- iter: 0416/1592
[A[ATraining Step: 564  | total loss: [1m[32m0.63102[0m[0m | time: 83.943s
[2K
| Adam | epoch: 012 | loss: 0.63102 - acc: 0.6415 -- iter: 0448/1592
[A[ATraining Step: 565  | total loss: [1m[32m0.62549[0m[0m | time: 88.721s
[2K
| Adam | epoch: 012 | loss: 0.62549 - acc: 0.6555 -- iter: 0480/1592
[A[ATraining Step: 566  | total loss: [1m[32m0.62692[0m[0m | time: 89.789s
[2K
| Adam | epoch: 012 | loss: 0.62692 - acc: 0.6555 -- iter: 0512/1592
[A[ATraining Step: 567  | total loss: [1m[32m0.62257[0m[0m | time: 90.941s
[2K
| Adam | epoch: 012 | loss: 0.62257 - acc: 0.6587 -- iter: 0544/1592
[A[ATraining Step: 568  | total loss: [1m[32m0.62427[0m[0m | time: 92.092s
[2K
| Adam | epoch: 012 | loss: 0.62427 - acc: 0.6522 -- iter: 0576/1592
[A[ATraining Step: 569  | total loss: [1m[32m0.63718[0m[0m | time: 93.007s
[2K
| Adam | epoch: 012 | loss: 0.63718 - acc: 0.6433 -- iter: 0608/1592
[A[ATraining Step: 570  | total loss: [1m[32m0.64067[0m[0m | time: 94.294s
[2K
| Adam | epoch: 012 | loss: 0.64067 - acc: 0.6352 -- iter: 0640/1592
[A[ATraining Step: 571  | total loss: [1m[32m0.63644[0m[0m | time: 95.444s
[2K
| Adam | epoch: 012 | loss: 0.63644 - acc: 0.6373 -- iter: 0672/1592
[A[ATraining Step: 572  | total loss: [1m[32m0.62906[0m[0m | time: 96.415s
[2K
| Adam | epoch: 012 | loss: 0.62906 - acc: 0.6392 -- iter: 0704/1592
[A[ATraining Step: 573  | total loss: [1m[32m0.62030[0m[0m | time: 97.406s
[2K
| Adam | epoch: 012 | loss: 0.62030 - acc: 0.6471 -- iter: 0736/1592
[A[ATraining Step: 574  | total loss: [1m[32m0.61266[0m[0m | time: 98.496s
[2K
| Adam | epoch: 012 | loss: 0.61266 - acc: 0.6574 -- iter: 0768/1592
[A[ATraining Step: 575  | total loss: [1m[32m0.61429[0m[0m | time: 99.520s
[2K
| Adam | epoch: 012 | loss: 0.61429 - acc: 0.6542 -- iter: 0800/1592
[A[ATraining Step: 576  | total loss: [1m[32m0.61278[0m[0m | time: 100.706s
[2K
| Adam | epoch: 012 | loss: 0.61278 - acc: 0.6544 -- iter: 0832/1592
[A[ATraining Step: 577  | total loss: [1m[32m0.60496[0m[0m | time: 101.773s
[2K
| Adam | epoch: 012 | loss: 0.60496 - acc: 0.6640 -- iter: 0864/1592
[A[ATraining Step: 578  | total loss: [1m[32m0.59563[0m[0m | time: 102.702s
[2K
| Adam | epoch: 012 | loss: 0.59563 - acc: 0.6726 -- iter: 0896/1592
[A[ATraining Step: 579  | total loss: [1m[32m0.58820[0m[0m | time: 103.944s
[2K
| Adam | epoch: 012 | loss: 0.58820 - acc: 0.6772 -- iter: 0928/1592
[A[ATraining Step: 580  | total loss: [1m[32m0.58650[0m[0m | time: 105.194s
[2K
| Adam | epoch: 012 | loss: 0.58650 - acc: 0.6720 -- iter: 0960/1592
[A[ATraining Step: 581  | total loss: [1m[32m0.57314[0m[0m | time: 106.066s
[2K
| Adam | epoch: 012 | loss: 0.57314 - acc: 0.6891 -- iter: 0992/1592
[A[ATraining Step: 582  | total loss: [1m[32m0.57067[0m[0m | time: 107.081s
[2K
| Adam | epoch: 012 | loss: 0.57067 - acc: 0.6952 -- iter: 1024/1592
[A[ATraining Step: 583  | total loss: [1m[32m0.56103[0m[0m | time: 108.088s
[2K
| Adam | epoch: 012 | loss: 0.56103 - acc: 0.7070 -- iter: 1056/1592
[A[ATraining Step: 584  | total loss: [1m[32m0.56717[0m[0m | time: 109.038s
[2K
| Adam | epoch: 012 | loss: 0.56717 - acc: 0.7113 -- iter: 1088/1592
[A[ATraining Step: 585  | total loss: [1m[32m0.55558[0m[0m | time: 110.278s
[2K
| Adam | epoch: 012 | loss: 0.55558 - acc: 0.7183 -- iter: 1120/1592
[A[ATraining Step: 586  | total loss: [1m[32m0.54067[0m[0m | time: 111.345s
[2K
| Adam | epoch: 012 | loss: 0.54067 - acc: 0.7246 -- iter: 1152/1592
[A[ATraining Step: 587  | total loss: [1m[32m0.52656[0m[0m | time: 112.350s
[2K
| Adam | epoch: 012 | loss: 0.52656 - acc: 0.7427 -- iter: 1184/1592
[A[ATraining Step: 588  | total loss: [1m[32m0.54194[0m[0m | time: 113.588s
[2K
| Adam | epoch: 012 | loss: 0.54194 - acc: 0.7278 -- iter: 1216/1592
[A[ATraining Step: 589  | total loss: [1m[32m0.51988[0m[0m | time: 114.723s
[2K
| Adam | epoch: 012 | loss: 0.51988 - acc: 0.7457 -- iter: 1248/1592
[A[ATraining Step: 590  | total loss: [1m[32m0.50745[0m[0m | time: 115.661s
[2K
| Adam | epoch: 012 | loss: 0.50745 - acc: 0.7586 -- iter: 1280/1592
[A[ATraining Step: 591  | total loss: [1m[32m0.50666[0m[0m | time: 116.612s
[2K
| Adam | epoch: 012 | loss: 0.50666 - acc: 0.7640 -- iter: 1312/1592
[A[ATraining Step: 592  | total loss: [1m[32m0.52425[0m[0m | time: 117.674s
[2K
| Adam | epoch: 012 | loss: 0.52425 - acc: 0.7501 -- iter: 1344/1592
[A[ATraining Step: 593  | total loss: [1m[32m0.53626[0m[0m | time: 118.721s
[2K
| Adam | epoch: 012 | loss: 0.53626 - acc: 0.7345 -- iter: 1376/1592
[A[ATraining Step: 594  | total loss: [1m[32m0.52663[0m[0m | time: 119.856s
[2K
| Adam | epoch: 012 | loss: 0.52663 - acc: 0.7423 -- iter: 1408/1592
[A[ATraining Step: 595  | total loss: [1m[32m0.53138[0m[0m | time: 120.855s
[2K
| Adam | epoch: 012 | loss: 0.53138 - acc: 0.7337 -- iter: 1440/1592
[A[ATraining Step: 596  | total loss: [1m[32m0.52272[0m[0m | time: 121.930s
[2K
| Adam | epoch: 012 | loss: 0.52272 - acc: 0.7384 -- iter: 1472/1592
[A[ATraining Step: 597  | total loss: [1m[32m0.53019[0m[0m | time: 123.118s
[2K
| Adam | epoch: 012 | loss: 0.53019 - acc: 0.7271 -- iter: 1504/1592
[A[ATraining Step: 598  | total loss: [1m[32m0.52068[0m[0m | time: 124.198s
[2K
| Adam | epoch: 012 | loss: 0.52068 - acc: 0.7231 -- iter: 1536/1592
[A[ATraining Step: 599  | total loss: [1m[32m0.54317[0m[0m | time: 125.171s
[2K
| Adam | epoch: 012 | loss: 0.54317 - acc: 0.7071 -- iter: 1568/1592
[A[ATraining Step: 600  | total loss: [1m[32m0.54044[0m[0m | time: 129.446s
[2K
| Adam | epoch: 012 | loss: 0.54044 - acc: 0.7082 | val_loss: 0.56159 - val_acc: 0.7108 -- iter: 1592/1592
--
Training Step: 601  | total loss: [1m[32m0.54161[0m[0m | time: 1.264s
[2K
| Adam | epoch: 013 | loss: 0.54161 - acc: 0.7155 -- iter: 0032/1592
[A[ATraining Step: 602  | total loss: [1m[32m0.53070[0m[0m | time: 2.309s
[2K
| Adam | epoch: 013 | loss: 0.53070 - acc: 0.7252 -- iter: 0064/1592
[A[ATraining Step: 603  | total loss: [1m[32m0.53727[0m[0m | time: 3.232s
[2K
| Adam | epoch: 013 | loss: 0.53727 - acc: 0.7183 -- iter: 0096/1592
[A[ATraining Step: 604  | total loss: [1m[32m0.53661[0m[0m | time: 4.238s
[2K
| Adam | epoch: 013 | loss: 0.53661 - acc: 0.7059 -- iter: 0128/1592
[A[ATraining Step: 605  | total loss: [1m[32m0.54122[0m[0m | time: 5.311s
[2K
| Adam | epoch: 013 | loss: 0.54122 - acc: 0.7040 -- iter: 0160/1592
[A[ATraining Step: 606  | total loss: [1m[32m0.53254[0m[0m | time: 6.568s
[2K
| Adam | epoch: 013 | loss: 0.53254 - acc: 0.7180 -- iter: 0192/1592
[A[ATraining Step: 607  | total loss: [1m[32m0.52254[0m[0m | time: 7.650s
[2K
| Adam | epoch: 013 | loss: 0.52254 - acc: 0.7243 -- iter: 0224/1592
[A[ATraining Step: 608  | total loss: [1m[32m0.51955[0m[0m | time: 8.606s
[2K
| Adam | epoch: 013 | loss: 0.51955 - acc: 0.7269 -- iter: 0256/1592
[A[ATraining Step: 609  | total loss: [1m[32m0.51560[0m[0m | time: 9.832s
[2K
| Adam | epoch: 013 | loss: 0.51560 - acc: 0.7292 -- iter: 0288/1592
[A[ATraining Step: 610  | total loss: [1m[32m0.51737[0m[0m | time: 10.969s
[2K
| Adam | epoch: 013 | loss: 0.51737 - acc: 0.7250 -- iter: 0320/1592
[A[ATraining Step: 611  | total loss: [1m[32m0.52447[0m[0m | time: 11.732s
[2K
| Adam | epoch: 013 | loss: 0.52447 - acc: 0.7213 -- iter: 0352/1592
[A[ATraining Step: 612  | total loss: [1m[32m0.51430[0m[0m | time: 12.493s
[2K
| Adam | epoch: 013 | loss: 0.51430 - acc: 0.7367 -- iter: 0384/1592
[A[ATraining Step: 613  | total loss: [1m[32m0.50155[0m[0m | time: 13.544s
[2K
| Adam | epoch: 013 | loss: 0.50155 - acc: 0.7547 -- iter: 0416/1592
[A[ATraining Step: 614  | total loss: [1m[32m0.51003[0m[0m | time: 14.625s
[2K
| Adam | epoch: 013 | loss: 0.51003 - acc: 0.7417 -- iter: 0448/1592
[A[ATraining Step: 615  | total loss: [1m[32m0.50754[0m[0m | time: 15.782s
[2K
| Adam | epoch: 013 | loss: 0.50754 - acc: 0.7519 -- iter: 0480/1592
[A[ATraining Step: 616  | total loss: [1m[32m0.51247[0m[0m | time: 16.954s
[2K
| Adam | epoch: 013 | loss: 0.51247 - acc: 0.7517 -- iter: 0512/1592
[A[ATraining Step: 617  | total loss: [1m[32m0.51465[0m[0m | time: 17.772s
[2K
| Adam | epoch: 013 | loss: 0.51465 - acc: 0.7484 -- iter: 0544/1592
[A[ATraining Step: 618  | total loss: [1m[32m0.52176[0m[0m | time: 18.884s
[2K
| Adam | epoch: 013 | loss: 0.52176 - acc: 0.7329 -- iter: 0576/1592
[A[ATraining Step: 619  | total loss: [1m[32m0.52846[0m[0m | time: 20.072s
[2K
| Adam | epoch: 013 | loss: 0.52846 - acc: 0.7222 -- iter: 0608/1592
[A[ATraining Step: 620  | total loss: [1m[32m0.52728[0m[0m | time: 21.076s
[2K
| Adam | epoch: 013 | loss: 0.52728 - acc: 0.7156 -- iter: 0640/1592
[A[ATraining Step: 621  | total loss: [1m[32m0.52770[0m[0m | time: 22.019s
[2K
| Adam | epoch: 013 | loss: 0.52770 - acc: 0.7190 -- iter: 0672/1592
[A[ATraining Step: 622  | total loss: [1m[32m0.54206[0m[0m | time: 23.006s
[2K
| Adam | epoch: 013 | loss: 0.54206 - acc: 0.7127 -- iter: 0704/1592
[A[ATraining Step: 623  | total loss: [1m[32m0.55248[0m[0m | time: 24.049s
[2K
| Adam | epoch: 013 | loss: 0.55248 - acc: 0.7102 -- iter: 0736/1592
[A[ATraining Step: 624  | total loss: [1m[32m0.56761[0m[0m | time: 25.183s
[2K
| Adam | epoch: 013 | loss: 0.56761 - acc: 0.7017 -- iter: 0768/1592
[A[ATraining Step: 625  | total loss: [1m[32m0.57185[0m[0m | time: 26.289s
[2K
| Adam | epoch: 013 | loss: 0.57185 - acc: 0.6971 -- iter: 0800/1592
[A[ATraining Step: 626  | total loss: [1m[32m0.55397[0m[0m | time: 27.216s
[2K
| Adam | epoch: 013 | loss: 0.55397 - acc: 0.7118 -- iter: 0832/1592
[A[ATraining Step: 627  | total loss: [1m[32m0.55551[0m[0m | time: 28.511s
[2K
| Adam | epoch: 013 | loss: 0.55551 - acc: 0.7094 -- iter: 0864/1592
[A[ATraining Step: 628  | total loss: [1m[32m0.53477[0m[0m | time: 29.704s
[2K
| Adam | epoch: 013 | loss: 0.53477 - acc: 0.7228 -- iter: 0896/1592
[A[ATraining Step: 629  | total loss: [1m[32m0.53742[0m[0m | time: 30.663s
[2K
| Adam | epoch: 013 | loss: 0.53742 - acc: 0.7130 -- iter: 0928/1592
[A[ATraining Step: 630  | total loss: [1m[32m0.52683[0m[0m | time: 31.708s
[2K
| Adam | epoch: 013 | loss: 0.52683 - acc: 0.7199 -- iter: 0960/1592
[A[ATraining Step: 631  | total loss: [1m[32m0.52197[0m[0m | time: 32.764s
[2K
| Adam | epoch: 013 | loss: 0.52197 - acc: 0.7229 -- iter: 0992/1592
[A[ATraining Step: 632  | total loss: [1m[32m0.50900[0m[0m | time: 33.785s
[2K
| Adam | epoch: 013 | loss: 0.50900 - acc: 0.7412 -- iter: 1024/1592
[A[ATraining Step: 633  | total loss: [1m[32m0.50251[0m[0m | time: 35.013s
[2K
| Adam | epoch: 013 | loss: 0.50251 - acc: 0.7515 -- iter: 1056/1592
[A[ATraining Step: 634  | total loss: [1m[32m0.49675[0m[0m | time: 36.054s
[2K
| Adam | epoch: 013 | loss: 0.49675 - acc: 0.7576 -- iter: 1088/1592
[A[ATraining Step: 635  | total loss: [1m[32m0.50072[0m[0m | time: 37.099s
[2K
| Adam | epoch: 013 | loss: 0.50072 - acc: 0.7537 -- iter: 1120/1592
[A[ATraining Step: 636  | total loss: [1m[32m0.48228[0m[0m | time: 38.354s
[2K
| Adam | epoch: 013 | loss: 0.48228 - acc: 0.7689 -- iter: 1152/1592
[A[ATraining Step: 637  | total loss: [1m[32m0.46998[0m[0m | time: 39.472s
[2K
| Adam | epoch: 013 | loss: 0.46998 - acc: 0.7827 -- iter: 1184/1592
[A[ATraining Step: 638  | total loss: [1m[32m0.47373[0m[0m | time: 40.321s
[2K
| Adam | epoch: 013 | loss: 0.47373 - acc: 0.7794 -- iter: 1216/1592
[A[ATraining Step: 639  | total loss: [1m[32m0.46738[0m[0m | time: 41.329s
[2K
| Adam | epoch: 013 | loss: 0.46738 - acc: 0.7733 -- iter: 1248/1592
[A[ATraining Step: 640  | total loss: [1m[32m0.46357[0m[0m | time: 42.355s
[2K
| Adam | epoch: 013 | loss: 0.46357 - acc: 0.7804 -- iter: 1280/1592
[A[ATraining Step: 641  | total loss: [1m[32m0.45268[0m[0m | time: 43.367s
[2K
| Adam | epoch: 013 | loss: 0.45268 - acc: 0.7898 -- iter: 1312/1592
[A[ATraining Step: 642  | total loss: [1m[32m0.45741[0m[0m | time: 44.523s
[2K
| Adam | epoch: 013 | loss: 0.45741 - acc: 0.7859 -- iter: 1344/1592
[A[ATraining Step: 643  | total loss: [1m[32m0.46037[0m[0m | time: 45.632s
[2K
| Adam | epoch: 013 | loss: 0.46037 - acc: 0.7854 -- iter: 1376/1592
[A[ATraining Step: 644  | total loss: [1m[32m0.46200[0m[0m | time: 46.713s
[2K
| Adam | epoch: 013 | loss: 0.46200 - acc: 0.7881 -- iter: 1408/1592
[A[ATraining Step: 645  | total loss: [1m[32m0.45381[0m[0m | time: 47.766s
[2K
| Adam | epoch: 013 | loss: 0.45381 - acc: 0.7999 -- iter: 1440/1592
[A[ATraining Step: 646  | total loss: [1m[32m0.44536[0m[0m | time: 48.960s
[2K
| Adam | epoch: 013 | loss: 0.44536 - acc: 0.8012 -- iter: 1472/1592
[A[ATraining Step: 647  | total loss: [1m[32m0.44230[0m[0m | time: 50.047s
[2K
| Adam | epoch: 013 | loss: 0.44230 - acc: 0.8023 -- iter: 1504/1592
[A[ATraining Step: 648  | total loss: [1m[32m0.45139[0m[0m | time: 51.206s
[2K
| Adam | epoch: 013 | loss: 0.45139 - acc: 0.7908 -- iter: 1536/1592
[A[ATraining Step: 649  | total loss: [1m[32m0.44465[0m[0m | time: 52.342s
[2K
| Adam | epoch: 013 | loss: 0.44465 - acc: 0.7992 -- iter: 1568/1592
[A[ATraining Step: 650  | total loss: [1m[32m0.44019[0m[0m | time: 56.621s
[2K
| Adam | epoch: 013 | loss: 0.44019 - acc: 0.7974 | val_loss: 0.46783 - val_acc: 0.7831 -- iter: 1592/1592
--
Training Step: 651  | total loss: [1m[32m0.44744[0m[0m | time: 1.131s
[2K
| Adam | epoch: 014 | loss: 0.44744 - acc: 0.7896 -- iter: 0032/1592
[A[ATraining Step: 652  | total loss: [1m[32m0.43177[0m[0m | time: 2.135s
[2K
| Adam | epoch: 014 | loss: 0.43177 - acc: 0.8044 -- iter: 0064/1592
[A[ATraining Step: 653  | total loss: [1m[32m0.42282[0m[0m | time: 3.108s
[2K
| Adam | epoch: 014 | loss: 0.42282 - acc: 0.8083 -- iter: 0096/1592
[A[ATraining Step: 654  | total loss: [1m[32m0.41477[0m[0m | time: 3.779s
[2K
| Adam | epoch: 014 | loss: 0.41477 - acc: 0.8119 -- iter: 0128/1592
[A[ATraining Step: 655  | total loss: [1m[32m0.40582[0m[0m | time: 4.421s
[2K
| Adam | epoch: 014 | loss: 0.40582 - acc: 0.8213 -- iter: 0160/1592
[A[ATraining Step: 656  | total loss: [1m[32m0.39921[0m[0m | time: 5.103s
[2K
| Adam | epoch: 014 | loss: 0.39921 - acc: 0.8298 -- iter: 0192/1592
[A[ATraining Step: 657  | total loss: [1m[32m0.39035[0m[0m | time: 5.813s
[2K
| Adam | epoch: 014 | loss: 0.39035 - acc: 0.8374 -- iter: 0224/1592
[A[ATraining Step: 658  | total loss: [1m[32m0.40166[0m[0m | time: 6.493s
[2K
| Adam | epoch: 014 | loss: 0.40166 - acc: 0.8224 -- iter: 0256/1592
[A[ATraining Step: 659  | total loss: [1m[32m0.39638[0m[0m | time: 7.141s
[2K
| Adam | epoch: 014 | loss: 0.39638 - acc: 0.8246 -- iter: 0288/1592
[A[ATraining Step: 660  | total loss: [1m[32m0.37557[0m[0m | time: 7.836s
[2K
| Adam | epoch: 014 | loss: 0.37557 - acc: 0.8359 -- iter: 0320/1592
[A[ATraining Step: 661  | total loss: [1m[32m0.37733[0m[0m | time: 8.460s
[2K
| Adam | epoch: 014 | loss: 0.37733 - acc: 0.8335 -- iter: 0352/1592
[A[ATraining Step: 662  | total loss: [1m[32m0.36277[0m[0m | time: 8.913s
[2K
| Adam | epoch: 014 | loss: 0.36277 - acc: 0.8439 -- iter: 0384/1592
[A[ATraining Step: 663  | total loss: [1m[32m0.37114[0m[0m | time: 9.410s
[2K
| Adam | epoch: 014 | loss: 0.37114 - acc: 0.8429 -- iter: 0416/1592
[A[ATraining Step: 664  | total loss: [1m[32m0.37362[0m[0m | time: 10.057s
[2K
| Adam | epoch: 014 | loss: 0.37362 - acc: 0.8377 -- iter: 0448/1592
[A[ATraining Step: 665  | total loss: [1m[32m0.36773[0m[0m | time: 10.726s
[2K
| Adam | epoch: 014 | loss: 0.36773 - acc: 0.8352 -- iter: 0480/1592
[A[ATraining Step: 666  | total loss: [1m[32m0.36000[0m[0m | time: 11.393s
[2K
| Adam | epoch: 014 | loss: 0.36000 - acc: 0.8423 -- iter: 0512/1592
[A[ATraining Step: 667  | total loss: [1m[32m0.36228[0m[0m | time: 12.113s
[2K
| Adam | epoch: 014 | loss: 0.36228 - acc: 0.8425 -- iter: 0544/1592
[A[ATraining Step: 668  | total loss: [1m[32m0.36614[0m[0m | time: 12.754s
[2K
| Adam | epoch: 014 | loss: 0.36614 - acc: 0.8426 -- iter: 0576/1592
[A[ATraining Step: 669  | total loss: [1m[32m0.36702[0m[0m | time: 13.411s
[2K
| Adam | epoch: 014 | loss: 0.36702 - acc: 0.8365 -- iter: 0608/1592
[A[ATraining Step: 670  | total loss: [1m[32m0.34687[0m[0m | time: 14.070s
[2K
| Adam | epoch: 014 | loss: 0.34687 - acc: 0.8528 -- iter: 0640/1592
[A[ATraining Step: 671  | total loss: [1m[32m0.35027[0m[0m | time: 14.765s
[2K
| Adam | epoch: 014 | loss: 0.35027 - acc: 0.8519 -- iter: 0672/1592
[A[ATraining Step: 672  | total loss: [1m[32m0.34710[0m[0m | time: 15.422s
[2K
| Adam | epoch: 014 | loss: 0.34710 - acc: 0.8542 -- iter: 0704/1592
[A[ATraining Step: 673  | total loss: [1m[32m0.36435[0m[0m | time: 16.079s
[2K
| Adam | epoch: 014 | loss: 0.36435 - acc: 0.8532 -- iter: 0736/1592
[A[ATraining Step: 674  | total loss: [1m[32m0.34463[0m[0m | time: 16.753s
[2K
| Adam | epoch: 014 | loss: 0.34463 - acc: 0.8647 -- iter: 0768/1592
[A[ATraining Step: 675  | total loss: [1m[32m0.34328[0m[0m | time: 17.423s
[2K
| Adam | epoch: 014 | loss: 0.34328 - acc: 0.8595 -- iter: 0800/1592
[A[ATraining Step: 676  | total loss: [1m[32m0.34065[0m[0m | time: 18.139s
[2K
| Adam | epoch: 014 | loss: 0.34065 - acc: 0.8611 -- iter: 0832/1592
[A[ATraining Step: 677  | total loss: [1m[32m0.33542[0m[0m | time: 18.811s
[2K
| Adam | epoch: 014 | loss: 0.33542 - acc: 0.8593 -- iter: 0864/1592
[A[ATraining Step: 678  | total loss: [1m[32m0.33981[0m[0m | time: 19.458s
[2K
| Adam | epoch: 014 | loss: 0.33981 - acc: 0.8609 -- iter: 0896/1592
[A[ATraining Step: 679  | total loss: [1m[32m0.33542[0m[0m | time: 20.114s
[2K
| Adam | epoch: 014 | loss: 0.33542 - acc: 0.8623 -- iter: 0928/1592
[A[ATraining Step: 680  | total loss: [1m[32m0.34225[0m[0m | time: 20.817s
[2K
| Adam | epoch: 014 | loss: 0.34225 - acc: 0.8542 -- iter: 0960/1592
[A[ATraining Step: 681  | total loss: [1m[32m0.35411[0m[0m | time: 21.892s
[2K
| Adam | epoch: 014 | loss: 0.35411 - acc: 0.8375 -- iter: 0992/1592
[A[ATraining Step: 682  | total loss: [1m[32m0.34660[0m[0m | time: 23.128s
[2K
| Adam | epoch: 014 | loss: 0.34660 - acc: 0.8444 -- iter: 1024/1592
[A[ATraining Step: 683  | total loss: [1m[32m0.33477[0m[0m | time: 24.173s
[2K
| Adam | epoch: 014 | loss: 0.33477 - acc: 0.8537 -- iter: 1056/1592
[A[ATraining Step: 684  | total loss: [1m[32m0.33454[0m[0m | time: 25.111s
[2K
| Adam | epoch: 014 | loss: 0.33454 - acc: 0.8558 -- iter: 1088/1592
[A[ATraining Step: 685  | total loss: [1m[32m0.32318[0m[0m | time: 26.189s
[2K
| Adam | epoch: 014 | loss: 0.32318 - acc: 0.8609 -- iter: 1120/1592
[A[ATraining Step: 686  | total loss: [1m[32m0.31412[0m[0m | time: 27.285s
[2K
| Adam | epoch: 014 | loss: 0.31412 - acc: 0.8685 -- iter: 1152/1592
[A[ATraining Step: 687  | total loss: [1m[32m0.31219[0m[0m | time: 28.505s
[2K
| Adam | epoch: 014 | loss: 0.31219 - acc: 0.8661 -- iter: 1184/1592
[A[ATraining Step: 688  | total loss: [1m[32m0.29822[0m[0m | time: 29.591s
[2K
| Adam | epoch: 014 | loss: 0.29822 - acc: 0.8763 -- iter: 1216/1592
[A[ATraining Step: 689  | total loss: [1m[32m0.29638[0m[0m | time: 30.516s
[2K
| Adam | epoch: 014 | loss: 0.29638 - acc: 0.8793 -- iter: 1248/1592
[A[ATraining Step: 690  | total loss: [1m[32m0.27862[0m[0m | time: 31.717s
[2K
| Adam | epoch: 014 | loss: 0.27862 - acc: 0.8883 -- iter: 1280/1592
[A[ATraining Step: 691  | total loss: [1m[32m0.29255[0m[0m | time: 32.853s
[2K
| Adam | epoch: 014 | loss: 0.29255 - acc: 0.8838 -- iter: 1312/1592
[A[ATraining Step: 692  | total loss: [1m[32m0.28079[0m[0m | time: 33.753s
[2K
| Adam | epoch: 014 | loss: 0.28079 - acc: 0.8892 -- iter: 1344/1592
[A[ATraining Step: 693  | total loss: [1m[32m0.27322[0m[0m | time: 34.795s
[2K
| Adam | epoch: 014 | loss: 0.27322 - acc: 0.8940 -- iter: 1376/1592
[A[ATraining Step: 694  | total loss: [1m[32m0.27236[0m[0m | time: 35.793s
[2K
| Adam | epoch: 014 | loss: 0.27236 - acc: 0.8921 -- iter: 1408/1592
[A[ATraining Step: 695  | total loss: [1m[32m0.26813[0m[0m | time: 36.818s
[2K
| Adam | epoch: 014 | loss: 0.26813 - acc: 0.8967 -- iter: 1440/1592
[A[ATraining Step: 696  | total loss: [1m[32m0.29524[0m[0m | time: 37.993s
[2K
| Adam | epoch: 014 | loss: 0.29524 - acc: 0.8882 -- iter: 1472/1592
[A[ATraining Step: 697  | total loss: [1m[32m0.29596[0m[0m | time: 39.104s
[2K
| Adam | epoch: 014 | loss: 0.29596 - acc: 0.8838 -- iter: 1504/1592
[A[ATraining Step: 698  | total loss: [1m[32m0.29880[0m[0m | time: 40.102s
[2K
| Adam | epoch: 014 | loss: 0.29880 - acc: 0.8767 -- iter: 1536/1592
[A[ATraining Step: 699  | total loss: [1m[32m0.29500[0m[0m | time: 41.313s
[2K
| Adam | epoch: 014 | loss: 0.29500 - acc: 0.8765 -- iter: 1568/1592
[A[ATraining Step: 700  | total loss: [1m[32m0.29910[0m[0m | time: 45.344s
[2K
| Adam | epoch: 014 | loss: 0.29910 - acc: 0.8795 | val_loss: 0.39893 - val_acc: 0.8514 -- iter: 1592/1592
--
Training Step: 701  | total loss: [1m[32m0.28833[0m[0m | time: 0.981s
[2K
| Adam | epoch: 015 | loss: 0.28833 - acc: 0.8821 -- iter: 0032/1592
[A[ATraining Step: 702  | total loss: [1m[32m0.27543[0m[0m | time: 2.151s
[2K
| Adam | epoch: 015 | loss: 0.27543 - acc: 0.8908 -- iter: 0064/1592
[A[ATraining Step: 703  | total loss: [1m[32m0.25987[0m[0m | time: 3.437s
[2K
| Adam | epoch: 015 | loss: 0.25987 - acc: 0.8986 -- iter: 0096/1592
[A[ATraining Step: 704  | total loss: [1m[32m0.25566[0m[0m | time: 4.491s
[2K
| Adam | epoch: 015 | loss: 0.25566 - acc: 0.8931 -- iter: 0128/1592
[A[ATraining Step: 705  | total loss: [1m[32m0.24664[0m[0m | time: 5.560s
[2K
| Adam | epoch: 015 | loss: 0.24664 - acc: 0.9007 -- iter: 0160/1592
[A[ATraining Step: 706  | total loss: [1m[32m0.24531[0m[0m | time: 6.601s
[2K
| Adam | epoch: 015 | loss: 0.24531 - acc: 0.9012 -- iter: 0192/1592
[A[ATraining Step: 707  | total loss: [1m[32m0.24266[0m[0m | time: 7.628s
[2K
| Adam | epoch: 015 | loss: 0.24266 - acc: 0.9017 -- iter: 0224/1592
[A[ATraining Step: 708  | total loss: [1m[32m0.24205[0m[0m | time: 8.744s
[2K
| Adam | epoch: 015 | loss: 0.24205 - acc: 0.9022 -- iter: 0256/1592
[A[ATraining Step: 709  | total loss: [1m[32m0.23890[0m[0m | time: 9.862s
[2K
| Adam | epoch: 015 | loss: 0.23890 - acc: 0.8995 -- iter: 0288/1592
[A[ATraining Step: 710  | total loss: [1m[32m0.22073[0m[0m | time: 10.709s
[2K
| Adam | epoch: 015 | loss: 0.22073 - acc: 0.9095 -- iter: 0320/1592
[A[ATraining Step: 711  | total loss: [1m[32m0.23047[0m[0m | time: 11.935s
[2K
| Adam | epoch: 015 | loss: 0.23047 - acc: 0.9061 -- iter: 0352/1592
[A[ATraining Step: 712  | total loss: [1m[32m0.23050[0m[0m | time: 13.115s
[2K
| Adam | epoch: 015 | loss: 0.23050 - acc: 0.9061 -- iter: 0384/1592
[A[ATraining Step: 713  | total loss: [1m[32m0.23006[0m[0m | time: 13.836s
[2K
| Adam | epoch: 015 | loss: 0.23006 - acc: 0.9092 -- iter: 0416/1592
[A[ATraining Step: 714  | total loss: [1m[32m0.23047[0m[0m | time: 14.532s
[2K
| Adam | epoch: 015 | loss: 0.23047 - acc: 0.9100 -- iter: 0448/1592
[A[ATraining Step: 715  | total loss: [1m[32m0.22644[0m[0m | time: 15.567s
[2K
| Adam | epoch: 015 | loss: 0.22644 - acc: 0.9148 -- iter: 0480/1592
[A[ATraining Step: 716  | total loss: [1m[32m0.23609[0m[0m | time: 16.537s
[2K
| Adam | epoch: 015 | loss: 0.23609 - acc: 0.9077 -- iter: 0512/1592
[A[ATraining Step: 717  | total loss: [1m[32m0.21963[0m[0m | time: 17.619s
[2K
| Adam | epoch: 015 | loss: 0.21963 - acc: 0.9169 -- iter: 0544/1592
[A[ATraining Step: 718  | total loss: [1m[32m0.22232[0m[0m | time: 18.835s
[2K
| Adam | epoch: 015 | loss: 0.22232 - acc: 0.9127 -- iter: 0576/1592
[A[ATraining Step: 719  | total loss: [1m[32m0.24379[0m[0m | time: 19.806s
[2K
| Adam | epoch: 015 | loss: 0.24379 - acc: 0.9027 -- iter: 0608/1592
[A[ATraining Step: 720  | total loss: [1m[32m0.25239[0m[0m | time: 20.893s
[2K
| Adam | epoch: 015 | loss: 0.25239 - acc: 0.8999 -- iter: 0640/1592
[A[ATraining Step: 721  | total loss: [1m[32m0.25355[0m[0m | time: 22.134s
[2K
| Adam | epoch: 015 | loss: 0.25355 - acc: 0.8974 -- iter: 0672/1592
[A[ATraining Step: 722  | total loss: [1m[32m0.27882[0m[0m | time: 23.236s
[2K
| Adam | epoch: 015 | loss: 0.27882 - acc: 0.8858 -- iter: 0704/1592
[A[ATraining Step: 723  | total loss: [1m[32m0.30787[0m[0m | time: 24.166s
[2K
| Adam | epoch: 015 | loss: 0.30787 - acc: 0.8691 -- iter: 0736/1592
[A[ATraining Step: 724  | total loss: [1m[32m0.31007[0m[0m | time: 25.200s
[2K
| Adam | epoch: 015 | loss: 0.31007 - acc: 0.8697 -- iter: 0768/1592
[A[ATraining Step: 725  | total loss: [1m[32m0.30403[0m[0m | time: 26.168s
[2K
| Adam | epoch: 015 | loss: 0.30403 - acc: 0.8734 -- iter: 0800/1592
[A[ATraining Step: 726  | total loss: [1m[32m0.29017[0m[0m | time: 27.312s
[2K
| Adam | epoch: 015 | loss: 0.29017 - acc: 0.8798 -- iter: 0832/1592
[A[ATraining Step: 727  | total loss: [1m[32m0.30461[0m[0m | time: 28.550s
[2K
| Adam | epoch: 015 | loss: 0.30461 - acc: 0.8762 -- iter: 0864/1592
[A[ATraining Step: 728  | total loss: [1m[32m0.29624[0m[0m | time: 29.552s
[2K
| Adam | epoch: 015 | loss: 0.29624 - acc: 0.8823 -- iter: 0896/1592
[A[ATraining Step: 729  | total loss: [1m[32m0.29016[0m[0m | time: 30.795s
[2K
| Adam | epoch: 015 | loss: 0.29016 - acc: 0.8847 -- iter: 0928/1592
[A[ATraining Step: 730  | total loss: [1m[32m0.29235[0m[0m | time: 31.998s
[2K
| Adam | epoch: 015 | loss: 0.29235 - acc: 0.8837 -- iter: 0960/1592
[A[ATraining Step: 731  | total loss: [1m[32m0.27596[0m[0m | time: 32.972s
[2K
| Adam | epoch: 015 | loss: 0.27596 - acc: 0.8922 -- iter: 0992/1592
[A[ATraining Step: 732  | total loss: [1m[32m0.27283[0m[0m | time: 33.951s
[2K
| Adam | epoch: 015 | loss: 0.27283 - acc: 0.8936 -- iter: 1024/1592
[A[ATraining Step: 733  | total loss: [1m[32m0.30417[0m[0m | time: 35.009s
[2K
| Adam | epoch: 015 | loss: 0.30417 - acc: 0.8855 -- iter: 1056/1592
[A[ATraining Step: 734  | total loss: [1m[32m0.30082[0m[0m | time: 36.069s
[2K
| Adam | epoch: 015 | loss: 0.30082 - acc: 0.8845 -- iter: 1088/1592
[A[ATraining Step: 735  | total loss: [1m[32m0.28344[0m[0m | time: 37.162s
[2K
| Adam | epoch: 015 | loss: 0.28344 - acc: 0.8929 -- iter: 1120/1592
[A[ATraining Step: 736  | total loss: [1m[32m0.27885[0m[0m | time: 38.325s
[2K
| Adam | epoch: 015 | loss: 0.27885 - acc: 0.8974 -- iter: 1152/1592
[A[ATraining Step: 737  | total loss: [1m[32m0.26523[0m[0m | time: 39.270s
[2K
| Adam | epoch: 015 | loss: 0.26523 - acc: 0.9014 -- iter: 1184/1592
[A[ATraining Step: 738  | total loss: [1m[32m0.26432[0m[0m | time: 40.554s
[2K
| Adam | epoch: 015 | loss: 0.26432 - acc: 0.9019 -- iter: 1216/1592
[A[ATraining Step: 739  | total loss: [1m[32m0.25532[0m[0m | time: 41.792s
[2K
| Adam | epoch: 015 | loss: 0.25532 - acc: 0.9054 -- iter: 1248/1592
[A[ATraining Step: 740  | total loss: [1m[32m0.24445[0m[0m | time: 42.833s
[2K
| Adam | epoch: 015 | loss: 0.24445 - acc: 0.9118 -- iter: 1280/1592
[A[ATraining Step: 741  | total loss: [1m[32m0.23338[0m[0m | time: 43.866s
[2K
| Adam | epoch: 015 | loss: 0.23338 - acc: 0.9175 -- iter: 1312/1592
[A[ATraining Step: 742  | total loss: [1m[32m0.22885[0m[0m | time: 44.914s
[2K
| Adam | epoch: 015 | loss: 0.22885 - acc: 0.9163 -- iter: 1344/1592
[A[ATraining Step: 743  | total loss: [1m[32m0.23231[0m[0m | time: 46.007s
[2K
| Adam | epoch: 015 | loss: 0.23231 - acc: 0.9122 -- iter: 1376/1592
[A[ATraining Step: 744  | total loss: [1m[32m0.22865[0m[0m | time: 47.217s
[2K
| Adam | epoch: 015 | loss: 0.22865 - acc: 0.9147 -- iter: 1408/1592
[A[ATraining Step: 745  | total loss: [1m[32m0.22898[0m[0m | time: 48.201s
[2K
| Adam | epoch: 015 | loss: 0.22898 - acc: 0.9108 -- iter: 1440/1592
[A[ATraining Step: 746  | total loss: [1m[32m0.23046[0m[0m | time: 49.321s
[2K
| Adam | epoch: 015 | loss: 0.23046 - acc: 0.9103 -- iter: 1472/1592
[A[ATraining Step: 747  | total loss: [1m[32m0.21758[0m[0m | time: 50.508s
[2K
| Adam | epoch: 015 | loss: 0.21758 - acc: 0.9162 -- iter: 1504/1592
[A[ATraining Step: 748  | total loss: [1m[32m0.20892[0m[0m | time: 51.554s
[2K
| Adam | epoch: 015 | loss: 0.20892 - acc: 0.9183 -- iter: 1536/1592
[A[ATraining Step: 749  | total loss: [1m[32m0.20883[0m[0m | time: 52.538s
[2K
| Adam | epoch: 015 | loss: 0.20883 - acc: 0.9140 -- iter: 1568/1592
[A[ATraining Step: 750  | total loss: [1m[32m0.19615[0m[0m | time: 56.530s
[2K
| Adam | epoch: 015 | loss: 0.19615 - acc: 0.9194 | val_loss: 0.41255 - val_acc: 0.8434 -- iter: 1592/1592
--
Validation AUC:0.9092068102961349
Validation AUPRC:0.9272203432343221
Test AUC:0.9148731775836737
Test AUPRC:0.926832643573066
BestTestF1Score	0.85	0.71	0.86	0.87	0.83	201	31	226	40	0.55
BestTestMCCScore	0.85	0.71	0.85	0.87	0.83	199	31	226	42	0.57
BestTestAccuracyScore	0.85	0.71	0.85	0.87	0.83	199	31	226	42	0.57
BestValidationF1Score	0.85	0.7	0.85	0.88	0.82	209	28	215	46	0.55
BestValidationMCC	0.85	0.71	0.85	0.89	0.81	206	25	218	49	0.57
BestValidationAccuracy	0.85	0.71	0.85	0.89	0.81	206	25	218	49	0.57
TestPredictions (Threshold:0.57)
CHEMBL551731,TP,ACT,1.0	CHEMBL3633656,TN,INACT,0.1899999976158142	CHEMBL3087361,TP,ACT,0.9900000095367432	CHEMBL58617,TN,INACT,0.009999999776482582	CHEMBL3114165,TN,INACT,0.4399999976158142	CHEMBL2381764,TN,INACT,0.009999999776482582	CHEMBL226348,TN,INACT,0.07000000029802322	CHEMBL1921912,FN,ACT,0.07999999821186066	CHEMBL381623,TP,ACT,0.9900000095367432	CHEMBL32688,TN,INACT,0.009999999776482582	CHEMBL3645321,TP,ACT,1.0	CHEMBL3645279,TP,ACT,0.6100000143051147	CHEMBL160396,TN,INACT,0.019999999552965164	CHEMBL1082365,TP,ACT,0.9900000095367432	CHEMBL2314499,TN,INACT,0.03999999910593033	CHEMBL284965,TN,INACT,0.009999999776482582	CHEMBL3087955,TP,ACT,1.0	CHEMBL320228,TN,INACT,0.05000000074505806	CHEMBL54266,TN,INACT,0.009999999776482582	CHEMBL199821,TP,ACT,0.8199999928474426	CHEMBL3084413,TP,ACT,0.8899999856948853	CHEMBL1683935,TP,ACT,0.9900000095367432	CHEMBL589,TN,INACT,0.009999999776482582	CHEMBL296419,FN,ACT,0.5600000023841858	CHEMBL354678,TP,ACT,0.9900000095367432	CHEMBL418386,TN,INACT,0.07000000029802322	CHEMBL467346,TN,INACT,0.07000000029802322	CHEMBL3087371,TP,ACT,1.0	CHEMBL103828,TN,INACT,0.019999999552965164	CHEMBL1921930,TP,ACT,1.0	CHEMBL7154,TN,INACT,0.10000000149011612	CHEMBL2425377,TN,INACT,0.029999999329447746	CHEMBL221713,TP,ACT,0.699999988079071	CHEMBL1201353,FN,ACT,0.009999999776482582	CHEMBL1258223,TP,ACT,0.8100000023841858	CHEMBL233200,TP,ACT,0.949999988079071	CHEMBL3121474,TN,INACT,0.019999999552965164	CHEMBL296395,TN,INACT,0.009999999776482582	CHEMBL2372525,TN,INACT,0.36000001430511475	CHEMBL118,FP,INACT,0.6800000071525574	CHEMBL177031,TN,INACT,0.009999999776482582	CHEMBL85996,TP,ACT,0.8500000238418579	CHEMBL280534,TN,INACT,0.03999999910593033	CHEMBL2262482,TN,INACT,0.05999999865889549	CHEMBL110018,TN,INACT,0.019999999552965164	CHEMBL44463,TN,INACT,0.009999999776482582	CHEMBL1779038,TP,ACT,0.7699999809265137	CHEMBL116601,TP,ACT,0.9800000190734863	CHEMBL2203713,FN,ACT,0.10000000149011612	CHEMBL3354075,TP,ACT,0.6100000143051147	CHEMBL11671,TN,INACT,0.009999999776482582	CHEMBL3219052,TP,ACT,0.6700000166893005	CHEMBL2112961,FN,ACT,0.30000001192092896	CHEMBL411,TN,INACT,0.10000000149011612	CHEMBL574602,TN,INACT,0.009999999776482582	CHEMBL1187846,TP,ACT,0.9200000166893005	CHEMBL59597,TN,INACT,0.029999999329447746	CHEMBL375073,TP,ACT,1.0	CHEMBL89738,FP,INACT,0.7099999785423279	CHEMBL1620339,TN,INACT,0.09000000357627869	CHEMBL96042,TP,ACT,0.9599999785423279	CHEMBL3645346,TP,ACT,1.0	CHEMBL603858,FP,INACT,0.800000011920929	CHEMBL15499,TN,INACT,0.05000000074505806	CHEMBL1779135,TP,ACT,0.9700000286102295	CHEMBL81895,TN,INACT,0.009999999776482582	CHEMBL61120,TN,INACT,0.009999999776482582	CHEMBL2391352,TN,INACT,0.019999999552965164	CHEMBL200209,TP,ACT,1.0	CHEMBL396761,TP,ACT,0.7699999809265137	CHEMBL222425,TP,ACT,0.9700000286102295	CHEMBL440085,FN,ACT,0.5	CHEMBL355560,TP,ACT,0.8799999952316284	CHEMBL41948,TN,INACT,0.019999999552965164	CHEMBL114478,TN,INACT,0.029999999329447746	CHEMBL374336,TN,INACT,0.15000000596046448	CHEMBL1922054,TP,ACT,0.8399999737739563	CHEMBL341825,TN,INACT,0.23000000417232513	CHEMBL387632,TN,INACT,0.029999999329447746	CHEMBL3426699,TP,ACT,0.9900000095367432	CHEMBL564747,TP,ACT,0.949999988079071	CHEMBL2381771,TN,INACT,0.1899999976158142	CHEMBL313738,TP,ACT,0.6100000143051147	CHEMBL27763,TN,INACT,0.41999998688697815	CHEMBL65461,TN,INACT,0.05999999865889549	CHEMBL338310,TN,INACT,0.4000000059604645	CHEMBL118553,FP,INACT,0.9800000190734863	CHEMBL2021989,TN,INACT,0.009999999776482582	CHEMBL1084850,FN,ACT,0.28999999165534973	CHEMBL2216805,TN,INACT,0.07000000029802322	CHEMBL564226,TP,ACT,0.9100000262260437	CHEMBL241279,TN,INACT,0.029999999329447746	CHEMBL304036,TP,ACT,0.949999988079071	CHEMBL2432041,TP,ACT,0.8199999928474426	CHEMBL208280,TP,ACT,1.0	CHEMBL319534,TN,INACT,0.3199999928474426	CHEMBL63790,TN,INACT,0.029999999329447746	CHEMBL200693,TP,ACT,0.9900000095367432	CHEMBL440120,TN,INACT,0.029999999329447746	CHEMBL515170,TN,INACT,0.20000000298023224	CHEMBL3645345,TP,ACT,1.0	CHEMBL84165,TN,INACT,0.05000000074505806	CHEMBL104804,TP,ACT,0.9599999785423279	CHEMBL434765,TP,ACT,0.9900000095367432	CHEMBL281232,TN,INACT,0.05000000074505806	CHEMBL1170027,FP,INACT,0.5799999833106995	CHEMBL381333,TP,ACT,0.9900000095367432	CHEMBL306462,FN,ACT,0.12999999523162842	CHEMBL3645327,FN,ACT,0.009999999776482582	CHEMBL3645299,TP,ACT,1.0	CHEMBL16231,TN,INACT,0.009999999776482582	CHEMBL2112313,FN,ACT,0.11999999731779099	CHEMBL3645336,TP,ACT,1.0	CHEMBL305660,TP,ACT,0.7799999713897705	CHEMBL150743,FP,INACT,0.9599999785423279	CHEMBL3426705,TP,ACT,0.9900000095367432	CHEMBL212141,TP,ACT,0.9700000286102295	CHEMBL1644484,TN,INACT,0.2199999988079071	CHEMBL229442,TN,INACT,0.009999999776482582	CHEMBL551063,TP,ACT,1.0	CHEMBL273890,TN,INACT,0.5400000214576721	CHEMBL71933,TP,ACT,0.9900000095367432	CHEMBL62660,TN,INACT,0.019999999552965164	CHEMBL284887,TN,INACT,0.1599999964237213	CHEMBL1910846,TP,ACT,0.9900000095367432	CHEMBL1924036,FN,ACT,0.5199999809265137	CHEMBL308243,TN,INACT,0.029999999329447746	CHEMBL262198,TP,ACT,0.9900000095367432	CHEMBL168815,FN,ACT,0.25	CHEMBL428561,FP,INACT,0.9599999785423279	CHEMBL387825,TN,INACT,0.019999999552965164	CHEMBL17045,TP,ACT,0.9200000166893005	CHEMBL174632,TN,INACT,0.009999999776482582	CHEMBL3426700,TP,ACT,0.9800000190734863	CHEMBL53662,TN,INACT,0.029999999329447746	CHEMBL63390,TN,INACT,0.5400000214576721	CHEMBL358193,TP,ACT,0.9599999785423279	CHEMBL2206393,TN,INACT,0.25	CHEMBL2111829,TN,INACT,0.15000000596046448	CHEMBL102452,TN,INACT,0.009999999776482582	CHEMBL101525,TN,INACT,0.12999999523162842	CHEMBL379483,TP,ACT,0.9200000166893005	CHEMBL415879,FP,INACT,0.6700000166893005	CHEMBL2323443,TN,INACT,0.3499999940395355	CHEMBL39986,TN,INACT,0.3700000047683716	CHEMBL246585,FP,INACT,0.6600000262260437	CHEMBL3039518,TP,ACT,0.9800000190734863	CHEMBL3401644,FN,ACT,0.38999998569488525	CHEMBL299231,TN,INACT,0.20000000298023224	CHEMBL205840,TP,ACT,0.9900000095367432	CHEMBL2062861,TN,INACT,0.009999999776482582	CHEMBL1788237,TN,INACT,0.029999999329447746	CHEMBL52800,TN,INACT,0.1599999964237213	CHEMBL1921932,TP,ACT,1.0	CHEMBL558766,TN,INACT,0.12999999523162842	CHEMBL2114058,TN,INACT,0.019999999552965164	CHEMBL262303,TP,ACT,0.9200000166893005	CHEMBL494510,TN,INACT,0.4000000059604645	CHEMBL106570,TN,INACT,0.009999999776482582	CHEMBL475496,TN,INACT,0.3499999940395355	CHEMBL40317,TN,INACT,0.019999999552965164	CHEMBL556390,TP,ACT,1.0	CHEMBL1437,TN,INACT,0.019999999552965164	CHEMBL3109772,TN,INACT,0.12999999523162842	CHEMBL562642,TP,ACT,0.9599999785423279	CHEMBL146291,TP,ACT,0.8100000023841858	CHEMBL1242950,FN,ACT,0.009999999776482582	CHEMBL2178724,TN,INACT,0.10000000149011612	CHEMBL167032,TN,INACT,0.009999999776482582	CHEMBL467375,TN,INACT,0.009999999776482582	CHEMBL292293,TN,INACT,0.3499999940395355	CHEMBL1921922,TP,ACT,1.0	CHEMBL229616,TN,INACT,0.019999999552965164	CHEMBL3629534,FN,ACT,0.23999999463558197	CHEMBL1559151,TN,INACT,0.009999999776482582	CHEMBL3087364,TP,ACT,1.0	CHEMBL205976,TP,ACT,1.0	CHEMBL1683938,TP,ACT,0.9900000095367432	CHEMBL404557,TN,INACT,0.30000001192092896	CHEMBL259662,TN,INACT,0.019999999552965164	CHEMBL134652,TN,INACT,0.009999999776482582	CHEMBL1319488,TN,INACT,0.10000000149011612	CHEMBL3219048,TP,ACT,0.6700000166893005	CHEMBL1202151,FP,INACT,0.7200000286102295	CHEMBL385328,TP,ACT,1.0	CHEMBL3290991,TN,INACT,0.009999999776482582	CHEMBL390298,FP,INACT,0.5899999737739563	CHEMBL1924041,TP,ACT,1.0	CHEMBL371734,TP,ACT,0.9900000095367432	CHEMBL3741290,TN,INACT,0.009999999776482582	CHEMBL292725,TN,INACT,0.019999999552965164	CHEMBL550920,TN,INACT,0.009999999776482582	CHEMBL1922055,TP,ACT,0.699999988079071	CHEMBL3753849,TN,INACT,0.25	CHEMBL62948,TN,INACT,0.009999999776482582	CHEMBL1123,TP,ACT,0.7099999785423279	CHEMBL174463,FP,INACT,0.8199999928474426	CHEMBL295651,TN,INACT,0.09000000357627869	CHEMBL416747,TN,INACT,0.03999999910593033	CHEMBL98038,TN,INACT,0.20000000298023224	CHEMBL438822,TP,ACT,1.0	CHEMBL105160,FN,ACT,0.10000000149011612	CHEMBL392186,FN,ACT,0.20000000298023224	CHEMBL50831,TN,INACT,0.019999999552965164	CHEMBL1836645,TP,ACT,1.0	CHEMBL380054,TN,INACT,0.019999999552965164	CHEMBL207098,TP,ACT,0.9900000095367432	CHEMBL545506,TN,INACT,0.019999999552965164	CHEMBL2443000,TN,INACT,0.09000000357627869	CHEMBL2237151,TN,INACT,0.5099999904632568	CHEMBL520212,TN,INACT,0.029999999329447746	CHEMBL458416,TN,INACT,0.07999999821186066	CHEMBL1259241,TN,INACT,0.009999999776482582	CHEMBL277537,TN,INACT,0.05000000074505806	CHEMBL1683915,TP,ACT,1.0	CHEMBL1683916,TP,ACT,1.0	CHEMBL3645351,TP,ACT,0.75	CHEMBL127551,TN,INACT,0.38999998569488525	CHEMBL3666066,FN,ACT,0.10000000149011612	CHEMBL3426701,TP,ACT,1.0	CHEMBL417654,TN,INACT,0.1599999964237213	CHEMBL134,TN,INACT,0.49000000953674316	CHEMBL74342,TN,INACT,0.27000001072883606	CHEMBL559106,TP,ACT,0.9900000095367432	CHEMBL3423407,TN,INACT,0.17000000178813934	CHEMBL3645294,TP,ACT,1.0	CHEMBL599548,TN,INACT,0.17000000178813934	CHEMBL3264204,TN,INACT,0.05999999865889549	CHEMBL3394775,FP,INACT,0.7200000286102295	CHEMBL234257,TP,ACT,0.8199999928474426	CHEMBL558364,TN,INACT,0.10999999940395355	CHEMBL385245,FP,INACT,0.9399999976158142	CHEMBL3403345,FP,INACT,0.8399999737739563	CHEMBL3087366,TP,ACT,1.0	CHEMBL293879,TN,INACT,0.009999999776482582	CHEMBL3091668,TP,ACT,0.9900000095367432	CHEMBL2335158,FN,ACT,0.05999999865889549	CHEMBL3238444,TN,INACT,0.009999999776482582	CHEMBL1683926,TP,ACT,1.0	CHEMBL39879,FP,INACT,0.800000011920929	CHEMBL3645313,TP,ACT,1.0	CHEMBL608151,FN,ACT,0.3199999928474426	CHEMBL3403340,TN,INACT,0.25999999046325684	CHEMBL195893,TN,INACT,0.03999999910593033	CHEMBL1743758,TN,INACT,0.05999999865889549	CHEMBL553602,TN,INACT,0.09000000357627869	CHEMBL405117,TP,ACT,0.9599999785423279	CHEMBL3645309,TP,ACT,1.0	CHEMBL234099,TP,ACT,0.949999988079071	CHEMBL3219033,TP,ACT,1.0	CHEMBL214122,TN,INACT,0.07000000029802322	CHEMBL3629539,TP,ACT,0.8299999833106995	CHEMBL185948,TN,INACT,0.15000000596046448	CHEMBL438915,FP,INACT,0.9300000071525574	CHEMBL2051756,FP,INACT,0.7799999713897705	CHEMBL395110,TP,ACT,0.9800000190734863	CHEMBL233201,TP,ACT,0.9900000095367432	CHEMBL222259,TP,ACT,1.0	CHEMBL299097,TN,INACT,0.15000000596046448	CHEMBL1076554,TN,INACT,0.09000000357627869	CHEMBL328512,TN,INACT,0.029999999329447746	CHEMBL418658,TN,INACT,0.009999999776482582	CHEMBL340755,TN,INACT,0.09000000357627869	CHEMBL2370511,TN,INACT,0.029999999329447746	CHEMBL58228,FN,ACT,0.05999999865889549	CHEMBL124173,TP,ACT,0.8399999737739563	CHEMBL269280,TP,ACT,0.7900000214576721	CHEMBL356305,TP,ACT,0.9800000190734863	CHEMBL95986,TN,INACT,0.009999999776482582	CHEMBL223724,TP,ACT,0.9599999785423279	CHEMBL37150,TN,INACT,0.05999999865889549	CHEMBL1289432,TP,ACT,0.9300000071525574	CHEMBL279289,FP,INACT,0.699999988079071	CHEMBL269004,TN,INACT,0.009999999776482582	CHEMBL98350,FP,INACT,0.8999999761581421	CHEMBL240023,TN,INACT,0.07000000029802322	CHEMBL1779045,TP,ACT,0.949999988079071	CHEMBL1643900,TP,ACT,0.6899999976158142	CHEMBL544961,TN,INACT,0.05000000074505806	CHEMBL234258,TP,ACT,0.9599999785423279	CHEMBL404888,TN,INACT,0.07000000029802322	CHEMBL1289866,TP,ACT,0.7200000286102295	CHEMBL1490,TP,ACT,0.9800000190734863	CHEMBL119985,TN,INACT,0.07999999821186066	CHEMBL1201207,FN,ACT,0.05999999865889549	CHEMBL1098606,TN,INACT,0.019999999552965164	CHEMBL16639,TN,INACT,0.029999999329447746	CHEMBL168145,TP,ACT,0.9900000095367432	CHEMBL343659,TP,ACT,0.7599999904632568	CHEMBL1290294,FN,ACT,0.05999999865889549	CHEMBL2110892,TP,ACT,0.9800000190734863	CHEMBL279520,TN,INACT,0.20999999344348907	CHEMBL481415,TN,INACT,0.05999999865889549	CHEMBL200566,TP,ACT,0.9300000071525574	CHEMBL330142,TN,INACT,0.019999999552965164	CHEMBL121476,TP,ACT,0.9200000166893005	CHEMBL45665,TN,INACT,0.05000000074505806	CHEMBL575066,FP,INACT,0.6399999856948853	CHEMBL1289544,TP,ACT,0.8999999761581421	CHEMBL45305,TN,INACT,0.009999999776482582	CHEMBL284137,TP,ACT,0.9900000095367432	CHEMBL308924,TN,INACT,0.05000000074505806	CHEMBL206714,TP,ACT,0.8700000047683716	CHEMBL261320,TN,INACT,0.23999999463558197	CHEMBL593864,TN,INACT,0.019999999552965164	CHEMBL3645312,TP,ACT,1.0	CHEMBL73917,TN,INACT,0.03999999910593033	CHEMBL105593,TP,ACT,0.9300000071525574	CHEMBL86150,TN,INACT,0.019999999552965164	CHEMBL41818,TN,INACT,0.019999999552965164	CHEMBL239866,FN,ACT,0.3199999928474426	CHEMBL86012,TP,ACT,0.9900000095367432	CHEMBL105268,TN,INACT,0.019999999552965164	CHEMBL3084650,TP,ACT,0.9800000190734863	CHEMBL127604,TN,INACT,0.3799999952316284	CHEMBL2205812,FN,ACT,0.17000000178813934	CHEMBL1922050,TP,ACT,0.9900000095367432	CHEMBL392401,TN,INACT,0.019999999552965164	CHEMBL120135,TP,ACT,0.8700000047683716	CHEMBL146249,TP,ACT,0.9900000095367432	CHEMBL200319,TP,ACT,1.0	CHEMBL478834,TP,ACT,0.8500000238418579	CHEMBL549784,TP,ACT,1.0	CHEMBL331516,TP,ACT,0.9800000190734863	CHEMBL321674,TN,INACT,0.019999999552965164	CHEMBL1773267,TP,ACT,0.8899999856948853	CHEMBL208335,TP,ACT,0.9900000095367432	CHEMBL61231,TN,INACT,0.009999999776482582	CHEMBL71765,TN,INACT,0.029999999329447746	CHEMBL341447,FN,ACT,0.009999999776482582	CHEMBL291516,TN,INACT,0.029999999329447746	CHEMBL1921944,TP,ACT,0.9800000190734863	CHEMBL257958,FP,INACT,0.6899999976158142	CHEMBL297335,TN,INACT,0.4699999988079071	CHEMBL64559,TN,INACT,0.3499999940395355	CHEMBL19576,TN,INACT,0.009999999776482582	CHEMBL549638,TN,INACT,0.019999999552965164	CHEMBL324712,TP,ACT,0.9700000286102295	CHEMBL50722,TN,INACT,0.009999999776482582	CHEMBL1250,TN,INACT,0.03999999910593033	CHEMBL356923,TN,INACT,0.38999998569488525	CHEMBL305558,TN,INACT,0.009999999776482582	CHEMBL319005,TN,INACT,0.009999999776482582	CHEMBL505197,FN,ACT,0.46000000834465027	CHEMBL1085507,TP,ACT,0.949999988079071	CHEMBL3360993,TN,INACT,0.009999999776482582	CHEMBL3219051,TP,ACT,1.0	CHEMBL3088081,TP,ACT,1.0	CHEMBL104210,FN,ACT,0.20999999344348907	CHEMBL62808,TN,INACT,0.019999999552965164	CHEMBL499519,TP,ACT,0.8199999928474426	CHEMBL304595,FP,INACT,0.7900000214576721	CHEMBL245137,TP,ACT,0.949999988079071	CHEMBL648,TP,ACT,0.9200000166893005	CHEMBL3087377,TP,ACT,1.0	CHEMBL37736,TN,INACT,0.1899999976158142	CHEMBL63421,TN,INACT,0.009999999776482582	CHEMBL426890,TP,ACT,0.7200000286102295	CHEMBL221660,TP,ACT,1.0	CHEMBL374099,TP,ACT,0.949999988079071	CHEMBL3114143,TN,INACT,0.23999999463558197	CHEMBL410531,FP,INACT,0.8700000047683716	CHEMBL205737,FN,ACT,0.11999999731779099	CHEMBL412642,TN,INACT,0.11999999731779099	CHEMBL264676,TP,ACT,0.9200000166893005	CHEMBL1082036,TN,INACT,0.029999999329447746	CHEMBL315127,TP,ACT,0.9300000071525574	CHEMBL52396,TN,INACT,0.009999999776482582	CHEMBL1779047,TP,ACT,0.8299999833106995	CHEMBL2322893,TN,INACT,0.009999999776482582	CHEMBL212631,TN,INACT,0.11999999731779099	CHEMBL1921933,TP,ACT,0.9900000095367432	CHEMBL438243,FN,ACT,0.3199999928474426	CHEMBL576707,TP,ACT,0.8700000047683716	CHEMBL3091664,TP,ACT,1.0	CHEMBL64406,TN,INACT,0.019999999552965164	CHEMBL129198,TN,INACT,0.07999999821186066	CHEMBL508011,FP,INACT,0.8799999952316284	CHEMBL293033,TN,INACT,0.009999999776482582	CHEMBL549986,TP,ACT,1.0	CHEMBL513390,TN,INACT,0.5099999904632568	CHEMBL70539,TN,INACT,0.009999999776482582	CHEMBL377241,FN,ACT,0.019999999552965164	CHEMBL280220,TP,ACT,0.9800000190734863	CHEMBL569307,TP,ACT,1.0	CHEMBL494569,TN,INACT,0.03999999910593033	CHEMBL2443010,TN,INACT,0.05999999865889549	CHEMBL82754,FN,ACT,0.5299999713897705	CHEMBL3764306,TN,INACT,0.11999999731779099	CHEMBL2042406,TP,ACT,1.0	CHEMBL26505,TP,ACT,1.0	CHEMBL391977,TP,ACT,0.9200000166893005	CHEMBL440864,TN,INACT,0.009999999776482582	CHEMBL3629357,TP,ACT,0.8799999952316284	CHEMBL69452,FN,ACT,0.09000000357627869	CHEMBL293577,TN,INACT,0.019999999552965164	CHEMBL1921942,TP,ACT,1.0	CHEMBL2070835,TN,INACT,0.2800000011920929	CHEMBL38033,TN,INACT,0.4099999964237213	CHEMBL2432048,TP,ACT,0.6499999761581421	CHEMBL1182657,TP,ACT,0.9900000095367432	CHEMBL373256,TP,ACT,0.8799999952316284	CHEMBL436814,FN,ACT,0.5699999928474426	CHEMBL3403343,FP,INACT,0.7599999904632568	CHEMBL3645296,TP,ACT,0.9800000190734863	CHEMBL42411,TN,INACT,0.5099999904632568	CHEMBL413040,TN,INACT,0.5400000214576721	CHEMBL2114064,TP,ACT,0.949999988079071	CHEMBL41457,TN,INACT,0.009999999776482582	CHEMBL3670826,TP,ACT,0.9900000095367432	CHEMBL96998,TN,INACT,0.009999999776482582	CHEMBL446698,FP,INACT,0.9599999785423279	CHEMBL954,FN,ACT,0.03999999910593033	CHEMBL553666,FP,INACT,0.6100000143051147	CHEMBL395571,TP,ACT,0.9800000190734863	CHEMBL3629532,TP,ACT,0.9399999976158142	CHEMBL173629,TN,INACT,0.0	CHEMBL3401645,TP,ACT,0.9900000095367432	CHEMBL401798,TN,INACT,0.5400000214576721	CHEMBL3645339,TP,ACT,1.0	CHEMBL1773198,FN,ACT,0.46000000834465027	CHEMBL2062860,TN,INACT,0.009999999776482582	CHEMBL3403336,FP,INACT,0.7699999809265137	CHEMBL490,FN,ACT,0.009999999776482582	CHEMBL493979,TP,ACT,1.0	CHEMBL1482157,TN,INACT,0.009999999776482582	CHEMBL144247,TN,INACT,0.3100000023841858	CHEMBL3645340,TP,ACT,1.0	CHEMBL42065,TN,INACT,0.36000001430511475	CHEMBL214898,TP,ACT,0.9700000286102295	CHEMBL434388,TP,ACT,0.8399999737739563	CHEMBL3403733,TN,INACT,0.019999999552965164	CHEMBL3401652,TP,ACT,1.0	CHEMBL135335,FP,INACT,0.7599999904632568	CHEMBL1085985,TP,ACT,0.9900000095367432	CHEMBL128714,TN,INACT,0.009999999776482582	CHEMBL3629533,FN,ACT,0.23999999463558197	CHEMBL279453,TP,ACT,0.9800000190734863	CHEMBL410061,TP,ACT,0.9900000095367432	CHEMBL99291,TN,INACT,0.009999999776482582	CHEMBL3426690,TP,ACT,1.0	CHEMBL3087961,TP,ACT,1.0	CHEMBL3426693,TP,ACT,0.9900000095367432	CHEMBL538991,TN,INACT,0.029999999329447746	CHEMBL24369,TP,ACT,0.9399999976158142	CHEMBL56275,TP,ACT,0.8899999856948853	CHEMBL512542,TN,INACT,0.029999999329447746	CHEMBL174259,TN,INACT,0.12999999523162842	CHEMBL2205817,TP,ACT,0.8799999952316284	CHEMBL238825,FN,ACT,0.019999999552965164	CHEMBL3423400,TN,INACT,0.4099999964237213	CHEMBL234253,TP,ACT,0.9399999976158142	CHEMBL3645324,TP,ACT,0.949999988079071	CHEMBL1924029,TP,ACT,0.9200000166893005	CHEMBL1836647,FN,ACT,0.2199999988079071	CHEMBL2443001,TN,INACT,0.05999999865889549	CHEMBL556798,TP,ACT,0.7900000214576721	CHEMBL1924039,TP,ACT,1.0	CHEMBL540359,FN,ACT,0.009999999776482582	CHEMBL1779137,TP,ACT,0.949999988079071	CHEMBL324936,TP,ACT,0.7799999713897705	CHEMBL66400,TP,ACT,0.9100000262260437	CHEMBL223188,FN,ACT,0.10000000149011612	CHEMBL1683909,TP,ACT,1.0	CHEMBL2377269,TP,ACT,0.8100000023841858	CHEMBL549332,TN,INACT,0.019999999552965164	CHEMBL84919,TN,INACT,0.009999999776482582	CHEMBL388177,TN,INACT,0.03999999910593033	CHEMBL321644,TN,INACT,0.49000000953674316	CHEMBL3219035,TP,ACT,1.0	CHEMBL1779034,TP,ACT,1.0	CHEMBL3335535,TN,INACT,0.009999999776482582	CHEMBL2030626,TP,ACT,0.6200000047683716	CHEMBL302447,TN,INACT,0.05999999865889549	CHEMBL3087946,TP,ACT,1.0	CHEMBL290715,TN,INACT,0.14000000059604645	CHEMBL11414,TN,INACT,0.009999999776482582	CHEMBL328812,TN,INACT,0.03999999910593033	CHEMBL222449,TP,ACT,0.7300000190734863	CHEMBL85460,TN,INACT,0.009999999776482582	CHEMBL137486,FP,INACT,0.9300000071525574	CHEMBL229400,TN,INACT,0.009999999776482582	CHEMBL2178953,TN,INACT,0.03999999910593033	CHEMBL106219,TP,ACT,0.8199999928474426	CHEMBL42586,TN,INACT,0.07000000029802322	CHEMBL302145,TP,ACT,0.9900000095367432	CHEMBL222387,TP,ACT,0.5799999833106995	CHEMBL120080,TP,ACT,0.9399999976158142	CHEMBL3403728,TN,INACT,0.07000000029802322	CHEMBL349689,TN,INACT,0.009999999776482582	CHEMBL1200633,TP,ACT,0.9399999976158142	CHEMBL543251,TN,INACT,0.009999999776482582	CHEMBL549577,TP,ACT,1.0	CHEMBL150365,TN,INACT,0.3100000023841858	CHEMBL148129,TP,ACT,0.8899999856948853	CHEMBL2093082,TN,INACT,0.05999999865889549	CHEMBL105383,TN,INACT,0.019999999552965164	CHEMBL3645288,TP,ACT,0.9900000095367432	

