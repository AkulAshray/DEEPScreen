ImageNetInceptionV2 CHEMBL3815 adam 0.0005 30 0 0 0.6 False True
Number of active compounds :	183
Number of inactive compounds :	122
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3815_adam_0.0005_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3815_adam_0.0005_30_0.6/
---------------------------------
Training samples: 192
Validation samples: 61
--
Training Step: 1  | time: 35.023s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/192
[A[ATraining Step: 2  | total loss: [1m[32m0.59376[0m[0m | time: 43.114s
[2K
| Adam | epoch: 001 | loss: 0.59376 - acc: 0.5906 -- iter: 064/192
[A[ATraining Step: 3  | total loss: [1m[32m0.48982[0m[0m | time: 51.014s
[2K
| Adam | epoch: 001 | loss: 0.48982 - acc: 0.7722 -- iter: 096/192
[A[ATraining Step: 4  | total loss: [1m[32m0.58744[0m[0m | time: 58.930s
[2K
| Adam | epoch: 001 | loss: 0.58744 - acc: 0.6618 -- iter: 128/192
[A[ATraining Step: 5  | total loss: [1m[32m0.65608[0m[0m | time: 66.949s
[2K
| Adam | epoch: 001 | loss: 0.65608 - acc: 0.6580 -- iter: 160/192
[A[ATraining Step: 6  | total loss: [1m[32m0.67202[0m[0m | time: 93.587s
[2K
| Adam | epoch: 001 | loss: 0.67202 - acc: 0.6769 | val_loss: 1.17962 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 7  | total loss: [1m[32m0.64262[0m[0m | time: 8.004s
[2K
| Adam | epoch: 002 | loss: 0.64262 - acc: 0.6833 -- iter: 032/192
[A[ATraining Step: 8  | total loss: [1m[32m0.53205[0m[0m | time: 16.067s
[2K
| Adam | epoch: 002 | loss: 0.53205 - acc: 0.7911 -- iter: 064/192
[A[ATraining Step: 9  | total loss: [1m[32m0.70339[0m[0m | time: 24.007s
[2K
| Adam | epoch: 002 | loss: 0.70339 - acc: 0.6535 -- iter: 096/192
[A[ATraining Step: 10  | total loss: [1m[32m0.58667[0m[0m | time: 31.991s
[2K
| Adam | epoch: 002 | loss: 0.58667 - acc: 0.7018 -- iter: 128/192
[A[ATraining Step: 11  | total loss: [1m[32m0.51218[0m[0m | time: 43.113s
[2K
| Adam | epoch: 002 | loss: 0.51218 - acc: 0.7690 -- iter: 160/192
[A[ATraining Step: 12  | total loss: [1m[32m0.46200[0m[0m | time: 60.107s
[2K
| Adam | epoch: 002 | loss: 0.46200 - acc: 0.7745 | val_loss: 0.93295 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 13  | total loss: [1m[32m0.43634[0m[0m | time: 8.070s
[2K
| Adam | epoch: 003 | loss: 0.43634 - acc: 0.7640 -- iter: 032/192
[A[ATraining Step: 14  | total loss: [1m[32m0.48474[0m[0m | time: 15.986s
[2K
| Adam | epoch: 003 | loss: 0.48474 - acc: 0.7071 -- iter: 064/192
[A[ATraining Step: 15  | total loss: [1m[32m0.41326[0m[0m | time: 24.313s
[2K
| Adam | epoch: 003 | loss: 0.41326 - acc: 0.7484 -- iter: 096/192
[A[ATraining Step: 16  | total loss: [1m[32m0.42070[0m[0m | time: 35.018s
[2K
| Adam | epoch: 003 | loss: 0.42070 - acc: 0.7607 -- iter: 128/192
[A[ATraining Step: 17  | total loss: [1m[32m0.34066[0m[0m | time: 47.513s
[2K
| Adam | epoch: 003 | loss: 0.34066 - acc: 0.8356 -- iter: 160/192
[A[ATraining Step: 18  | total loss: [1m[32m0.30298[0m[0m | time: 64.141s
[2K
| Adam | epoch: 003 | loss: 0.30298 - acc: 0.8601 | val_loss: 1.30942 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 19  | total loss: [1m[32m0.29140[0m[0m | time: 9.409s
[2K
| Adam | epoch: 004 | loss: 0.29140 - acc: 0.8650 -- iter: 032/192
[A[ATraining Step: 20  | total loss: [1m[32m0.34790[0m[0m | time: 26.606s
[2K
| Adam | epoch: 004 | loss: 0.34790 - acc: 0.8381 -- iter: 064/192
[A[ATraining Step: 21  | total loss: [1m[32m0.29564[0m[0m | time: 37.388s
[2K
| Adam | epoch: 004 | loss: 0.29564 - acc: 0.8690 -- iter: 096/192
[A[ATraining Step: 22  | total loss: [1m[32m0.22381[0m[0m | time: 49.956s
[2K
| Adam | epoch: 004 | loss: 0.22381 - acc: 0.9083 -- iter: 128/192
[A[ATraining Step: 23  | total loss: [1m[32m0.23401[0m[0m | time: 74.479s
[2K
| Adam | epoch: 004 | loss: 0.23401 - acc: 0.8986 -- iter: 160/192
[A[ATraining Step: 24  | total loss: [1m[32m0.19042[0m[0m | time: 90.970s
[2K
| Adam | epoch: 004 | loss: 0.19042 - acc: 0.9271 | val_loss: 2.55284 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 25  | total loss: [1m[32m0.14892[0m[0m | time: 74.280s
[2K
| Adam | epoch: 005 | loss: 0.14892 - acc: 0.9470 -- iter: 032/192
[A[ATraining Step: 26  | total loss: [1m[32m0.18830[0m[0m | time: 115.547s
[2K
| Adam | epoch: 005 | loss: 0.18830 - acc: 0.9197 -- iter: 064/192
[A[ATraining Step: 27  | total loss: [1m[32m0.15210[0m[0m | time: 237.317s
[2K
| Adam | epoch: 005 | loss: 0.15210 - acc: 0.9403 -- iter: 096/192
[A[ATraining Step: 28  | total loss: [1m[32m0.18038[0m[0m | time: 251.475s
[2K
| Adam | epoch: 005 | loss: 0.18038 - acc: 0.9396 -- iter: 128/192
[A[ATraining Step: 29  | total loss: [1m[32m0.16528[0m[0m | time: 263.283s
[2K
| Adam | epoch: 005 | loss: 0.16528 - acc: 0.9467 -- iter: 160/192
[A[ATraining Step: 30  | total loss: [1m[32m0.13244[0m[0m | time: 281.085s
[2K
| Adam | epoch: 005 | loss: 0.13244 - acc: 0.9593 | val_loss: 0.72411 - val_acc: 0.4426 -- iter: 192/192
--
Training Step: 31  | total loss: [1m[32m0.10444[0m[0m | time: 9.483s
[2K
| Adam | epoch: 006 | loss: 0.10444 - acc: 0.9687 -- iter: 032/192
[A[ATraining Step: 32  | total loss: [1m[32m0.10025[0m[0m | time: 18.615s
[2K
| Adam | epoch: 006 | loss: 0.10025 - acc: 0.9687 -- iter: 064/192
[A[ATraining Step: 33  | total loss: [1m[32m0.09592[0m[0m | time: 191.793s
[2K
| Adam | epoch: 006 | loss: 0.09592 - acc: 0.9756 -- iter: 096/192
[A[ATraining Step: 34  | total loss: [1m[32m0.08045[0m[0m | time: 262.828s
[2K
| Adam | epoch: 006 | loss: 0.08045 - acc: 0.9808 -- iter: 128/192
[A[ATraining Step: 35  | total loss: [1m[32m0.07143[0m[0m | time: 328.313s
[2K
| Adam | epoch: 006 | loss: 0.07143 - acc: 0.9848 -- iter: 160/192
[A[ATraining Step: 36  | total loss: [1m[32m0.06037[0m[0m | time: 388.228s
[2K
| Adam | epoch: 006 | loss: 0.06037 - acc: 0.9879 | val_loss: 1.26261 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 37  | total loss: [1m[32m0.06751[0m[0m | time: 16.565s
[2K
| Adam | epoch: 007 | loss: 0.06751 - acc: 0.9841 -- iter: 032/192
[A[ATraining Step: 38  | total loss: [1m[32m0.08332[0m[0m | time: 44.887s
[2K
| Adam | epoch: 007 | loss: 0.08332 - acc: 0.9811 -- iter: 064/192
[A[ATraining Step: 39  | total loss: [1m[32m0.07989[0m[0m | time: 58.006s
[2K
| Adam | epoch: 007 | loss: 0.07989 - acc: 0.9847 -- iter: 096/192
[A[ATraining Step: 40  | total loss: [1m[32m0.11681[0m[0m | time: 70.786s
[2K
| Adam | epoch: 007 | loss: 0.11681 - acc: 0.9641 -- iter: 128/192
[A[ATraining Step: 41  | total loss: [1m[32m0.10097[0m[0m | time: 85.800s
[2K
| Adam | epoch: 007 | loss: 0.10097 - acc: 0.9707 -- iter: 160/192
[A[ATraining Step: 42  | total loss: [1m[32m0.08919[0m[0m | time: 108.758s
[2K
| Adam | epoch: 007 | loss: 0.08919 - acc: 0.9760 | val_loss: 1.09771 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 43  | total loss: [1m[32m0.07628[0m[0m | time: 19.953s
[2K
| Adam | epoch: 008 | loss: 0.07628 - acc: 0.9802 -- iter: 032/192
[A[ATraining Step: 44  | total loss: [1m[32m0.07496[0m[0m | time: 50.984s
[2K
| Adam | epoch: 008 | loss: 0.07496 - acc: 0.9782 -- iter: 064/192
[A[ATraining Step: 45  | total loss: [1m[32m0.08861[0m[0m | time: 69.015s
[2K
| Adam | epoch: 008 | loss: 0.08861 - acc: 0.9713 -- iter: 096/192
[A[ATraining Step: 46  | total loss: [1m[32m0.08779[0m[0m | time: 81.854s
[2K
| Adam | epoch: 008 | loss: 0.08779 - acc: 0.9709 -- iter: 128/192
[A[ATraining Step: 47  | total loss: [1m[32m0.09426[0m[0m | time: 90.165s
[2K
| Adam | epoch: 008 | loss: 0.09426 - acc: 0.9654 -- iter: 160/192
[A[ATraining Step: 48  | total loss: [1m[32m0.08021[0m[0m | time: 104.267s
[2K
| Adam | epoch: 008 | loss: 0.08021 - acc: 0.9710 | val_loss: 0.90883 - val_acc: 0.5902 -- iter: 192/192
--
Training Step: 49  | total loss: [1m[32m0.15031[0m[0m | time: 15.947s
[2K
| Adam | epoch: 009 | loss: 0.15031 - acc: 0.9706 -- iter: 032/192
[A[ATraining Step: 50  | total loss: [1m[32m0.16034[0m[0m | time: 28.395s
[2K
| Adam | epoch: 009 | loss: 0.16034 - acc: 0.9703 -- iter: 064/192
[A[ATraining Step: 51  | total loss: [1m[32m0.16729[0m[0m | time: 41.578s
[2K
| Adam | epoch: 009 | loss: 0.16729 - acc: 0.9701 -- iter: 096/192
[A[ATraining Step: 52  | total loss: [1m[32m0.16149[0m[0m | time: 55.898s
[2K
| Adam | epoch: 009 | loss: 0.16149 - acc: 0.9699 -- iter: 128/192
[A[ATraining Step: 53  | total loss: [1m[32m0.14670[0m[0m | time: 78.016s
[2K
| Adam | epoch: 009 | loss: 0.14670 - acc: 0.9743 -- iter: 160/192
[A[ATraining Step: 54  | total loss: [1m[32m0.12923[0m[0m | time: 98.987s
[2K
| Adam | epoch: 009 | loss: 0.12923 - acc: 0.9781 | val_loss: 2.95359 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 55  | total loss: [1m[32m0.11974[0m[0m | time: 13.233s
[2K
| Adam | epoch: 010 | loss: 0.11974 - acc: 0.9812 -- iter: 032/192
[A[ATraining Step: 56  | total loss: [1m[32m0.11804[0m[0m | time: 26.654s
[2K
| Adam | epoch: 010 | loss: 0.11804 - acc: 0.9794 -- iter: 064/192
[A[ATraining Step: 57  | total loss: [1m[32m0.10958[0m[0m | time: 42.342s
[2K
| Adam | epoch: 010 | loss: 0.10958 - acc: 0.9823 -- iter: 096/192
[A[ATraining Step: 58  | total loss: [1m[32m0.12310[0m[0m | time: 113.950s
[2K
| Adam | epoch: 010 | loss: 0.12310 - acc: 0.9804 -- iter: 128/192
[A[ATraining Step: 59  | total loss: [1m[32m0.24152[0m[0m | time: 141.770s
[2K
| Adam | epoch: 010 | loss: 0.24152 - acc: 0.9495 -- iter: 160/192
[A[ATraining Step: 60  | total loss: [1m[32m0.21177[0m[0m | time: 161.529s
[2K
| Adam | epoch: 010 | loss: 0.21177 - acc: 0.9562 | val_loss: 2.13590 - val_acc: 0.5902 -- iter: 192/192
--
Training Step: 61  | total loss: [1m[32m0.19189[0m[0m | time: 12.728s
[2K
| Adam | epoch: 011 | loss: 0.19189 - acc: 0.9619 -- iter: 032/192
[A[ATraining Step: 62  | total loss: [1m[32m0.17323[0m[0m | time: 27.078s
[2K
| Adam | epoch: 011 | loss: 0.17323 - acc: 0.9668 -- iter: 064/192
[A[ATraining Step: 63  | total loss: [1m[32m0.15745[0m[0m | time: 47.595s
[2K
| Adam | epoch: 011 | loss: 0.15745 - acc: 0.9710 -- iter: 096/192
[A[ATraining Step: 64  | total loss: [1m[32m0.14121[0m[0m | time: 63.099s
[2K
| Adam | epoch: 011 | loss: 0.14121 - acc: 0.9746 -- iter: 128/192
[A[ATraining Step: 65  | total loss: [1m[32m0.13313[0m[0m | time: 75.444s
[2K
| Adam | epoch: 011 | loss: 0.13313 - acc: 0.9739 -- iter: 160/192
[A[ATraining Step: 66  | total loss: [1m[32m0.17331[0m[0m | time: 93.849s
[2K
| Adam | epoch: 011 | loss: 0.17331 - acc: 0.9657 | val_loss: 2.25082 - val_acc: 0.4754 -- iter: 192/192
--
Training Step: 67  | total loss: [1m[32m0.15667[0m[0m | time: 25.853s
[2K
| Adam | epoch: 012 | loss: 0.15667 - acc: 0.9698 -- iter: 032/192
[A[ATraining Step: 68  | total loss: [1m[32m0.14654[0m[0m | time: 69.693s
[2K
| Adam | epoch: 012 | loss: 0.14654 - acc: 0.9697 -- iter: 064/192
[A[ATraining Step: 69  | total loss: [1m[32m0.13196[0m[0m | time: 79.562s
[2K
| Adam | epoch: 012 | loss: 0.13196 - acc: 0.9732 -- iter: 096/192
[A[ATraining Step: 70  | total loss: [1m[32m0.12223[0m[0m | time: 88.141s
[2K
| Adam | epoch: 012 | loss: 0.12223 - acc: 0.9763 -- iter: 128/192
[A[ATraining Step: 71  | total loss: [1m[32m0.11005[0m[0m | time: 96.788s
[2K
| Adam | epoch: 012 | loss: 0.11005 - acc: 0.9790 -- iter: 160/192
[A[ATraining Step: 72  | total loss: [1m[32m0.11370[0m[0m | time: 116.245s
[2K
| Adam | epoch: 012 | loss: 0.11370 - acc: 0.9743 | val_loss: 0.78497 - val_acc: 0.7705 -- iter: 192/192
--
Training Step: 73  | total loss: [1m[32m0.18868[0m[0m | time: 11.637s
[2K
| Adam | epoch: 013 | loss: 0.18868 - acc: 0.9564 -- iter: 032/192
[A[ATraining Step: 74  | total loss: [1m[32m0.17291[0m[0m | time: 24.520s
[2K
| Adam | epoch: 013 | loss: 0.17291 - acc: 0.9611 -- iter: 064/192
[A[ATraining Step: 75  | total loss: [1m[32m0.15784[0m[0m | time: 37.266s
[2K
| Adam | epoch: 013 | loss: 0.15784 - acc: 0.9654 -- iter: 096/192
[A[ATraining Step: 76  | total loss: [1m[32m0.15330[0m[0m | time: 52.697s
[2K
| Adam | epoch: 013 | loss: 0.15330 - acc: 0.9624 -- iter: 128/192
[A[ATraining Step: 77  | total loss: [1m[32m0.17247[0m[0m | time: 62.831s
[2K
| Adam | epoch: 013 | loss: 0.17247 - acc: 0.9531 -- iter: 160/192
[A[ATraining Step: 78  | total loss: [1m[32m0.17456[0m[0m | time: 73.768s
[2K
| Adam | epoch: 013 | loss: 0.17456 - acc: 0.9515 | val_loss: 0.68051 - val_acc: 0.7705 -- iter: 192/192
--
Training Step: 79  | total loss: [1m[32m0.16563[0m[0m | time: 12.836s
[2K
| Adam | epoch: 014 | loss: 0.16563 - acc: 0.9533 -- iter: 032/192
[A[ATraining Step: 80  | total loss: [1m[32m0.15671[0m[0m | time: 25.930s
[2K
| Adam | epoch: 014 | loss: 0.15671 - acc: 0.9581 -- iter: 064/192
[A[ATraining Step: 81  | total loss: [1m[32m0.14810[0m[0m | time: 38.359s
[2K
| Adam | epoch: 014 | loss: 0.14810 - acc: 0.9591 -- iter: 096/192
[A[ATraining Step: 82  | total loss: [1m[32m0.13690[0m[0m | time: 49.935s
[2K
| Adam | epoch: 014 | loss: 0.13690 - acc: 0.9632 -- iter: 128/192
[A[ATraining Step: 83  | total loss: [1m[32m0.12889[0m[0m | time: 62.671s
[2K
| Adam | epoch: 014 | loss: 0.12889 - acc: 0.9669 -- iter: 160/192
[A[ATraining Step: 84  | total loss: [1m[32m0.12214[0m[0m | time: 79.372s
[2K
| Adam | epoch: 014 | loss: 0.12214 - acc: 0.9702 | val_loss: 0.66737 - val_acc: 0.7705 -- iter: 192/192
--
Training Step: 85  | total loss: [1m[32m0.11327[0m[0m | time: 8.309s
[2K
| Adam | epoch: 015 | loss: 0.11327 - acc: 0.9732 -- iter: 032/192
[A[ATraining Step: 86  | total loss: [1m[32m0.10478[0m[0m | time: 20.194s
[2K
| Adam | epoch: 015 | loss: 0.10478 - acc: 0.9759 -- iter: 064/192
[A[ATraining Step: 87  | total loss: [1m[32m0.27941[0m[0m | time: 32.634s
[2K
| Adam | epoch: 015 | loss: 0.27941 - acc: 0.9439 -- iter: 096/192
[A[ATraining Step: 88  | total loss: [1m[32m0.25536[0m[0m | time: 45.233s
[2K
| Adam | epoch: 015 | loss: 0.25536 - acc: 0.9495 -- iter: 128/192
[A[ATraining Step: 89  | total loss: [1m[32m0.26317[0m[0m | time: 58.024s
[2K
| Adam | epoch: 015 | loss: 0.26317 - acc: 0.9421 -- iter: 160/192
[A[ATraining Step: 90  | total loss: [1m[32m0.24722[0m[0m | time: 75.202s
[2K
| Adam | epoch: 015 | loss: 0.24722 - acc: 0.9447 | val_loss: 0.74716 - val_acc: 0.7869 -- iter: 192/192
--
Training Step: 91  | total loss: [1m[32m0.23466[0m[0m | time: 8.303s
[2K
| Adam | epoch: 016 | loss: 0.23466 - acc: 0.9440 -- iter: 032/192
[A[ATraining Step: 92  | total loss: [1m[32m0.21520[0m[0m | time: 16.391s
[2K
| Adam | epoch: 016 | loss: 0.21520 - acc: 0.9496 -- iter: 064/192
[A[ATraining Step: 93  | total loss: [1m[32m0.20375[0m[0m | time: 28.117s
[2K
| Adam | epoch: 016 | loss: 0.20375 - acc: 0.9515 -- iter: 096/192
[A[ATraining Step: 94  | total loss: [1m[32m0.19869[0m[0m | time: 40.663s
[2K
| Adam | epoch: 016 | loss: 0.19869 - acc: 0.9532 -- iter: 128/192
[A[ATraining Step: 95  | total loss: [1m[32m0.18729[0m[0m | time: 53.590s
[2K
| Adam | epoch: 016 | loss: 0.18729 - acc: 0.9548 -- iter: 160/192
[A[ATraining Step: 96  | total loss: [1m[32m0.17375[0m[0m | time: 71.050s
[2K
| Adam | epoch: 016 | loss: 0.17375 - acc: 0.9593 | val_loss: 1.15511 - val_acc: 0.6557 -- iter: 192/192
--
Training Step: 97  | total loss: [1m[32m0.16143[0m[0m | time: 11.383s
[2K
| Adam | epoch: 017 | loss: 0.16143 - acc: 0.9634 -- iter: 032/192
[A[ATraining Step: 98  | total loss: [1m[32m0.15160[0m[0m | time: 22.300s
[2K
| Adam | epoch: 017 | loss: 0.15160 - acc: 0.9639 -- iter: 064/192
[A[ATraining Step: 99  | total loss: [1m[32m0.13983[0m[0m | time: 30.716s
[2K
| Adam | epoch: 017 | loss: 0.13983 - acc: 0.9675 -- iter: 096/192
[A[ATraining Step: 100  | total loss: [1m[32m0.13801[0m[0m | time: 38.746s
[2K
| Adam | epoch: 017 | loss: 0.13801 - acc: 0.9677 -- iter: 128/192
[A[ATraining Step: 101  | total loss: [1m[32m0.22656[0m[0m | time: 49.363s
[2K
| Adam | epoch: 017 | loss: 0.22656 - acc: 0.9521 -- iter: 160/192
[A[ATraining Step: 102  | total loss: [1m[32m0.20770[0m[0m | time: 66.968s
[2K
| Adam | epoch: 017 | loss: 0.20770 - acc: 0.9569 | val_loss: 1.01334 - val_acc: 0.6721 -- iter: 192/192
--
Training Step: 103  | total loss: [1m[32m0.19445[0m[0m | time: 12.206s
[2K
| Adam | epoch: 018 | loss: 0.19445 - acc: 0.9581 -- iter: 032/192
[A[ATraining Step: 104  | total loss: [1m[32m0.18276[0m[0m | time: 24.780s
[2K
| Adam | epoch: 018 | loss: 0.18276 - acc: 0.9623 -- iter: 064/192
[A[ATraining Step: 105  | total loss: [1m[32m0.17231[0m[0m | time: 37.027s
[2K
| Adam | epoch: 018 | loss: 0.17231 - acc: 0.9629 -- iter: 096/192
[A[ATraining Step: 106  | total loss: [1m[32m0.16072[0m[0m | time: 49.102s
[2K
| Adam | epoch: 018 | loss: 0.16072 - acc: 0.9666 -- iter: 128/192
[A[ATraining Step: 107  | total loss: [1m[32m0.17478[0m[0m | time: 58.591s
[2K
| Adam | epoch: 018 | loss: 0.17478 - acc: 0.9606 -- iter: 160/192
[A[ATraining Step: 108  | total loss: [1m[32m0.25159[0m[0m | time: 69.753s
[2K
| Adam | epoch: 018 | loss: 0.25159 - acc: 0.9427 | val_loss: 0.67109 - val_acc: 0.7377 -- iter: 192/192
--
Training Step: 109  | total loss: [1m[32m0.23488[0m[0m | time: 12.587s
[2K
| Adam | epoch: 019 | loss: 0.23488 - acc: 0.9484 -- iter: 032/192
[A[ATraining Step: 110  | total loss: [1m[32m0.21805[0m[0m | time: 25.358s
[2K
| Adam | epoch: 019 | loss: 0.21805 - acc: 0.9536 -- iter: 064/192
[A[ATraining Step: 111  | total loss: [1m[32m0.20005[0m[0m | time: 37.847s
[2K
| Adam | epoch: 019 | loss: 0.20005 - acc: 0.9582 -- iter: 096/192
[A[ATraining Step: 112  | total loss: [1m[32m0.18554[0m[0m | time: 50.366s
[2K
| Adam | epoch: 019 | loss: 0.18554 - acc: 0.9624 -- iter: 128/192
[A[ATraining Step: 113  | total loss: [1m[32m0.17012[0m[0m | time: 63.047s
[2K
| Adam | epoch: 019 | loss: 0.17012 - acc: 0.9661 -- iter: 160/192
[A[ATraining Step: 114  | total loss: [1m[32m0.15639[0m[0m | time: 79.849s
[2K
| Adam | epoch: 019 | loss: 0.15639 - acc: 0.9695 | val_loss: 0.94584 - val_acc: 0.7049 -- iter: 192/192
--
Training Step: 115  | total loss: [1m[32m0.15996[0m[0m | time: 8.236s
[2K
| Adam | epoch: 020 | loss: 0.15996 - acc: 0.9695 -- iter: 032/192
[A[ATraining Step: 116  | total loss: [1m[32m0.14603[0m[0m | time: 16.315s
[2K
| Adam | epoch: 020 | loss: 0.14603 - acc: 0.9725 -- iter: 064/192
[A[ATraining Step: 117  | total loss: [1m[32m0.13615[0m[0m | time: 25.740s
[2K
| Adam | epoch: 020 | loss: 0.13615 - acc: 0.9753 -- iter: 096/192
[A[ATraining Step: 118  | total loss: [1m[32m0.12473[0m[0m | time: 37.444s
[2K
| Adam | epoch: 020 | loss: 0.12473 - acc: 0.9777 -- iter: 128/192
[A[ATraining Step: 119  | total loss: [1m[32m0.12150[0m[0m | time: 50.133s
[2K
| Adam | epoch: 020 | loss: 0.12150 - acc: 0.9737 -- iter: 160/192
[A[ATraining Step: 120  | total loss: [1m[32m0.11359[0m[0m | time: 67.572s
[2K
| Adam | epoch: 020 | loss: 0.11359 - acc: 0.9763 | val_loss: 0.96304 - val_acc: 0.7049 -- iter: 192/192
--
Training Step: 121  | total loss: [1m[32m0.10480[0m[0m | time: 12.570s
[2K
| Adam | epoch: 021 | loss: 0.10480 - acc: 0.9787 -- iter: 032/192
[A[ATraining Step: 122  | total loss: [1m[32m0.09555[0m[0m | time: 25.788s
[2K
| Adam | epoch: 021 | loss: 0.09555 - acc: 0.9808 -- iter: 064/192
[A[ATraining Step: 123  | total loss: [1m[32m0.08692[0m[0m | time: 34.192s
[2K
| Adam | epoch: 021 | loss: 0.08692 - acc: 0.9828 -- iter: 096/192
[A[ATraining Step: 124  | total loss: [1m[32m0.08123[0m[0m | time: 42.346s
[2K
| Adam | epoch: 021 | loss: 0.08123 - acc: 0.9845 -- iter: 128/192
[A[ATraining Step: 125  | total loss: [1m[32m0.07403[0m[0m | time: 51.879s
[2K
| Adam | epoch: 021 | loss: 0.07403 - acc: 0.9860 -- iter: 160/192
[A[ATraining Step: 126  | total loss: [1m[32m0.06745[0m[0m | time: 67.460s
[2K
| Adam | epoch: 021 | loss: 0.06745 - acc: 0.9874 | val_loss: 0.93088 - val_acc: 0.7705 -- iter: 192/192
--
Training Step: 127  | total loss: [1m[32m0.06136[0m[0m | time: 12.538s
[2K
| Adam | epoch: 022 | loss: 0.06136 - acc: 0.9887 -- iter: 032/192
[A[ATraining Step: 128  | total loss: [1m[32m0.05884[0m[0m | time: 24.700s
[2K
| Adam | epoch: 022 | loss: 0.05884 - acc: 0.9898 -- iter: 064/192
[A[ATraining Step: 129  | total loss: [1m[32m0.07798[0m[0m | time: 36.868s
[2K
| Adam | epoch: 022 | loss: 0.07798 - acc: 0.9877 -- iter: 096/192
[A[ATraining Step: 130  | total loss: [1m[32m0.07243[0m[0m | time: 49.421s
[2K
| Adam | epoch: 022 | loss: 0.07243 - acc: 0.9889 -- iter: 128/192
[A[ATraining Step: 131  | total loss: [1m[32m0.06625[0m[0m | time: 60.321s
[2K
| Adam | epoch: 022 | loss: 0.06625 - acc: 0.9900 -- iter: 160/192
[A[ATraining Step: 132  | total loss: [1m[32m0.06002[0m[0m | time: 71.353s
[2K
| Adam | epoch: 022 | loss: 0.06002 - acc: 0.9910 | val_loss: 1.58631 - val_acc: 0.6885 -- iter: 192/192
--
Training Step: 133  | total loss: [1m[32m0.05507[0m[0m | time: 11.595s
[2K
| Adam | epoch: 023 | loss: 0.05507 - acc: 0.9919 -- iter: 032/192
[A[ATraining Step: 134  | total loss: [1m[32m0.05001[0m[0m | time: 23.042s
[2K
| Adam | epoch: 023 | loss: 0.05001 - acc: 0.9927 -- iter: 064/192
[A[ATraining Step: 135  | total loss: [1m[32m0.04533[0m[0m | time: 35.826s
[2K
| Adam | epoch: 023 | loss: 0.04533 - acc: 0.9935 -- iter: 096/192
[A[ATraining Step: 136  | total loss: [1m[32m0.21854[0m[0m | time: 48.653s
[2K
| Adam | epoch: 023 | loss: 0.21854 - acc: 0.9629 -- iter: 128/192
[A[ATraining Step: 137  | total loss: [1m[32m0.19851[0m[0m | time: 61.051s
[2K
| Adam | epoch: 023 | loss: 0.19851 - acc: 0.9666 -- iter: 160/192
[A[ATraining Step: 138  | total loss: [1m[32m0.20366[0m[0m | time: 77.986s
[2K
| Adam | epoch: 023 | loss: 0.20366 - acc: 0.9668 | val_loss: 1.24393 - val_acc: 0.7541 -- iter: 192/192
--
Training Step: 139  | total loss: [1m[32m0.18379[0m[0m | time: 8.219s
[2K
| Adam | epoch: 024 | loss: 0.18379 - acc: 0.9701 -- iter: 032/192
[A[ATraining Step: 140  | total loss: [1m[32m0.16838[0m[0m | time: 16.271s
[2K
| Adam | epoch: 024 | loss: 0.16838 - acc: 0.9731 -- iter: 064/192
[A[ATraining Step: 141  | total loss: [1m[32m0.15354[0m[0m | time: 29.934s
[2K
| Adam | epoch: 024 | loss: 0.15354 - acc: 0.9758 -- iter: 096/192
[A[ATraining Step: 142  | total loss: [1m[32m0.14457[0m[0m | time: 38.211s
[2K
| Adam | epoch: 024 | loss: 0.14457 - acc: 0.9751 -- iter: 128/192
[A[ATraining Step: 143  | total loss: [1m[32m0.28111[0m[0m | time: 46.334s
[2K
| Adam | epoch: 024 | loss: 0.28111 - acc: 0.9495 -- iter: 160/192
[A[ATraining Step: 144  | total loss: [1m[32m0.25555[0m[0m | time: 57.403s
[2K
| Adam | epoch: 024 | loss: 0.25555 - acc: 0.9545 | val_loss: 0.84796 - val_acc: 0.7377 -- iter: 192/192
--
Training Step: 145  | total loss: [1m[32m0.23741[0m[0m | time: 8.275s
[2K
| Adam | epoch: 025 | loss: 0.23741 - acc: 0.9591 -- iter: 032/192
[A[ATraining Step: 146  | total loss: [1m[32m0.21783[0m[0m | time: 16.413s
[2K
| Adam | epoch: 025 | loss: 0.21783 - acc: 0.9632 -- iter: 064/192
[A[ATraining Step: 147  | total loss: [1m[32m0.21408[0m[0m | time: 24.643s
[2K
| Adam | epoch: 025 | loss: 0.21408 - acc: 0.9575 -- iter: 096/192
[A[ATraining Step: 148  | total loss: [1m[32m0.20094[0m[0m | time: 32.827s
[2K
| Adam | epoch: 025 | loss: 0.20094 - acc: 0.9586 -- iter: 128/192
[A[ATraining Step: 149  | total loss: [1m[32m0.19708[0m[0m | time: 41.017s
[2K
| Adam | epoch: 025 | loss: 0.19708 - acc: 0.9596 -- iter: 160/192
[A[ATraining Step: 150  | total loss: [1m[32m0.20467[0m[0m | time: 51.963s
[2K
| Adam | epoch: 025 | loss: 0.20467 - acc: 0.9574 | val_loss: 1.42217 - val_acc: 0.5574 -- iter: 192/192
--
Training Step: 151  | total loss: [1m[32m0.18852[0m[0m | time: 8.087s
[2K
| Adam | epoch: 026 | loss: 0.18852 - acc: 0.9617 -- iter: 032/192
[A[ATraining Step: 152  | total loss: [1m[32m0.18386[0m[0m | time: 16.230s
[2K
| Adam | epoch: 026 | loss: 0.18386 - acc: 0.9592 -- iter: 064/192
[A[ATraining Step: 153  | total loss: [1m[32m0.17237[0m[0m | time: 24.722s
[2K
| Adam | epoch: 026 | loss: 0.17237 - acc: 0.9633 -- iter: 096/192
[A[ATraining Step: 154  | total loss: [1m[32m0.15822[0m[0m | time: 33.102s
[2K
| Adam | epoch: 026 | loss: 0.15822 - acc: 0.9670 -- iter: 128/192
[A[ATraining Step: 155  | total loss: [1m[32m0.14461[0m[0m | time: 41.254s
[2K
| Adam | epoch: 026 | loss: 0.14461 - acc: 0.9703 -- iter: 160/192
[A[ATraining Step: 156  | total loss: [1m[32m0.13583[0m[0m | time: 52.207s
[2K
| Adam | epoch: 026 | loss: 0.13583 - acc: 0.9733 | val_loss: 0.72122 - val_acc: 0.7213 -- iter: 192/192
--
Training Step: 157  | total loss: [1m[32m0.15044[0m[0m | time: 8.132s
[2K
| Adam | epoch: 027 | loss: 0.15044 - acc: 0.9728 -- iter: 032/192
[A[ATraining Step: 158  | total loss: [1m[32m0.13924[0m[0m | time: 16.397s
[2K
| Adam | epoch: 027 | loss: 0.13924 - acc: 0.9755 -- iter: 064/192
[A[ATraining Step: 159  | total loss: [1m[32m0.12770[0m[0m | time: 24.496s
[2K
| Adam | epoch: 027 | loss: 0.12770 - acc: 0.9780 -- iter: 096/192
[A[ATraining Step: 160  | total loss: [1m[32m0.11740[0m[0m | time: 32.536s
[2K
| Adam | epoch: 027 | loss: 0.11740 - acc: 0.9802 -- iter: 128/192
[A[ATraining Step: 161  | total loss: [1m[32m0.10750[0m[0m | time: 40.751s
[2K
| Adam | epoch: 027 | loss: 0.10750 - acc: 0.9822 -- iter: 160/192
[A[ATraining Step: 162  | total loss: [1m[32m0.09848[0m[0m | time: 51.749s
[2K
| Adam | epoch: 027 | loss: 0.09848 - acc: 0.9839 | val_loss: 0.91493 - val_acc: 0.7049 -- iter: 192/192
--
Training Step: 163  | total loss: [1m[32m0.09354[0m[0m | time: 8.016s
[2K
| Adam | epoch: 028 | loss: 0.09354 - acc: 0.9855 -- iter: 032/192
[A[ATraining Step: 164  | total loss: [1m[32m0.09380[0m[0m | time: 16.077s
[2K
| Adam | epoch: 028 | loss: 0.09380 - acc: 0.9839 -- iter: 064/192
[A[ATraining Step: 165  | total loss: [1m[32m0.08548[0m[0m | time: 24.196s
[2K
| Adam | epoch: 028 | loss: 0.08548 - acc: 0.9855 -- iter: 096/192
[A[ATraining Step: 166  | total loss: [1m[32m0.07798[0m[0m | time: 32.276s
[2K
| Adam | epoch: 028 | loss: 0.07798 - acc: 0.9869 -- iter: 128/192
[A[ATraining Step: 167  | total loss: [1m[32m0.08127[0m[0m | time: 40.413s
[2K
| Adam | epoch: 028 | loss: 0.08127 - acc: 0.9789 -- iter: 160/192
[A[ATraining Step: 168  | total loss: [1m[32m0.07654[0m[0m | time: 51.597s
[2K
| Adam | epoch: 028 | loss: 0.07654 - acc: 0.9810 | val_loss: 0.80264 - val_acc: 0.7541 -- iter: 192/192
--
Training Step: 169  | total loss: [1m[32m0.07062[0m[0m | time: 8.189s
[2K
| Adam | epoch: 029 | loss: 0.07062 - acc: 0.9829 -- iter: 032/192
[A[ATraining Step: 170  | total loss: [1m[32m0.06454[0m[0m | time: 16.601s
[2K
| Adam | epoch: 029 | loss: 0.06454 - acc: 0.9846 -- iter: 064/192
[A[ATraining Step: 171  | total loss: [1m[32m0.08159[0m[0m | time: 24.711s
[2K
| Adam | epoch: 029 | loss: 0.08159 - acc: 0.9830 -- iter: 096/192
[A[ATraining Step: 172  | total loss: [1m[32m0.07765[0m[0m | time: 32.941s
[2K
| Adam | epoch: 029 | loss: 0.07765 - acc: 0.9816 -- iter: 128/192
[A[ATraining Step: 173  | total loss: [1m[32m0.07067[0m[0m | time: 41.376s
[2K
| Adam | epoch: 029 | loss: 0.07067 - acc: 0.9834 -- iter: 160/192
[A[ATraining Step: 174  | total loss: [1m[32m0.06490[0m[0m | time: 52.568s
[2K
| Adam | epoch: 029 | loss: 0.06490 - acc: 0.9851 | val_loss: 1.07065 - val_acc: 0.7049 -- iter: 192/192
--
Training Step: 175  | total loss: [1m[32m0.05977[0m[0m | time: 8.196s
[2K
| Adam | epoch: 030 | loss: 0.05977 - acc: 0.9866 -- iter: 032/192
[A[ATraining Step: 176  | total loss: [1m[32m0.05503[0m[0m | time: 16.179s
[2K
| Adam | epoch: 030 | loss: 0.05503 - acc: 0.9879 -- iter: 064/192
[A[ATraining Step: 177  | total loss: [1m[32m0.05072[0m[0m | time: 24.348s
[2K
| Adam | epoch: 030 | loss: 0.05072 - acc: 0.9891 -- iter: 096/192
[A[ATraining Step: 178  | total loss: [1m[32m0.06567[0m[0m | time: 32.502s
[2K
| Adam | epoch: 030 | loss: 0.06567 - acc: 0.9840 -- iter: 128/192
[A[ATraining Step: 179  | total loss: [1m[32m0.06012[0m[0m | time: 40.806s
[2K
| Adam | epoch: 030 | loss: 0.06012 - acc: 0.9856 -- iter: 160/192
[A[ATraining Step: 180  | total loss: [1m[32m0.06484[0m[0m | time: 51.870s
[2K
| Adam | epoch: 030 | loss: 0.06484 - acc: 0.9839 | val_loss: 0.99349 - val_acc: 0.7377 -- iter: 192/192
--
Validation AUC:0.7901098901098901
Validation AUPRC:0.8488909748687136
Test AUC:0.8411111111111111
Test AUPRC:0.9000558711866671
BestTestF1Score	0.75	0.56	0.75	0.92	0.64	23	2	23	13	0.86
BestTestMCCScore	0.75	0.56	0.75	0.92	0.64	23	2	23	13	0.86
BestTestAccuracyScore	0.75	0.56	0.75	0.92	0.64	23	2	23	13	0.86
BestValidationF1Score	0.77	0.57	0.77	0.89	0.69	24	3	23	11	0.86
BestValidationMCC	0.77	0.57	0.77	0.89	0.69	24	3	23	11	0.86
BestValidationAccuracy	0.77	0.57	0.77	0.89	0.69	24	3	23	11	0.86
TestPredictions (Threshold:0.86)
CHEMBL416786,TN,INACT,0.019999999552965164	CHEMBL55300,TN,INACT,0.009999999776482582	CHEMBL325949,TN,INACT,0.0	CHEMBL130431,TP,ACT,0.9900000095367432	CHEMBL322662,TP,ACT,0.9900000095367432	CHEMBL87843,TP,ACT,0.9800000190734863	CHEMBL2057959,TP,ACT,1.0	CHEMBL134086,TP,ACT,0.9900000095367432	CHEMBL100446,TN,INACT,0.0	CHEMBL449115,TN,INACT,0.0	CHEMBL134015,FN,ACT,0.7699999809265137	CHEMBL334230,TP,ACT,1.0	CHEMBL160176,FN,ACT,0.41999998688697815	CHEMBL40583,TN,INACT,0.03999999910593033	CHEMBL159021,FN,ACT,0.20999999344348907	CHEMBL1819562,TP,ACT,0.8999999761581421	CHEMBL434963,TP,ACT,1.0	CHEMBL160240,FN,ACT,0.12999999523162842	CHEMBL293731,TN,INACT,0.03999999910593033	CHEMBL397143,TN,INACT,0.30000001192092896	CHEMBL310898,TP,ACT,1.0	CHEMBL17637,FP,INACT,0.949999988079071	CHEMBL69863,TN,INACT,0.09000000357627869	CHEMBL1819580,FN,ACT,0.11999999731779099	CHEMBL318301,FN,ACT,0.3700000047683716	CHEMBL57067,TP,ACT,1.0	CHEMBL457077,TN,INACT,0.009999999776482582	CHEMBL538528,TN,INACT,0.0	CHEMBL313525,TP,ACT,0.8799999952316284	CHEMBL2057962,TP,ACT,0.8999999761581421	CHEMBL116727,TP,ACT,1.0	CHEMBL303399,TN,INACT,0.12999999523162842	CHEMBL287202,TP,ACT,0.9900000095367432	CHEMBL494914,TN,INACT,0.7200000286102295	CHEMBL467321,TN,INACT,0.03999999910593033	CHEMBL431028,TP,ACT,1.0	CHEMBL58761,TP,ACT,1.0	CHEMBL3234111,FN,ACT,0.14000000059604645	CHEMBL100912,FN,ACT,0.009999999776482582	CHEMBL84629,FN,ACT,0.12999999523162842	CHEMBL103617,FP,INACT,0.9599999785423279	CHEMBL115421,TN,INACT,0.0	CHEMBL1160231,TN,INACT,0.019999999552965164	CHEMBL410840,TN,INACT,0.33000001311302185	CHEMBL82015,TP,ACT,0.8799999952316284	CHEMBL405681,TN,INACT,0.4099999964237213	CHEMBL159974,TN,INACT,0.6000000238418579	CHEMBL87671,FN,ACT,0.11999999731779099	CHEMBL196363,TN,INACT,0.8399999737739563	CHEMBL337731,FN,ACT,0.05000000074505806	CHEMBL2057632,TP,ACT,0.9700000286102295	CHEMBL1161371,TP,ACT,0.8600000143051147	CHEMBL337434,TP,ACT,0.9900000095367432	CHEMBL131335,TP,ACT,1.0	CHEMBL130767,TP,ACT,1.0	CHEMBL84961,TP,ACT,0.9700000286102295	CHEMBL420416,FN,ACT,0.019999999552965164	CHEMBL293484,TN,INACT,0.0	CHEMBL87312,FN,ACT,0.009999999776482582	CHEMBL443350,TN,INACT,0.27000001072883606	CHEMBL55667,TN,INACT,0.0	

