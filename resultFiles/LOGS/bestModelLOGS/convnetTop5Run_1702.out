ImageNetInceptionV2 CHEMBL3776 adam 0.0001 15 0 0 0.8 False True
Number of active compounds :	228
Number of inactive compounds :	157
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3776_adam_0.0001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3776_adam_0.0001_15_0.8/
---------------------------------
Training samples: 246
Validation samples: 77
--
Training Step: 1  | time: 40.724s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/246
[A[ATraining Step: 2  | total loss: [1m[32m0.59162[0m[0m | time: 49.583s
[2K
| Adam | epoch: 001 | loss: 0.59162 - acc: 0.4781 -- iter: 064/246
[A[ATraining Step: 3  | total loss: [1m[32m0.62382[0m[0m | time: 58.949s
[2K
| Adam | epoch: 001 | loss: 0.62382 - acc: 0.5727 -- iter: 096/246
[A[ATraining Step: 4  | total loss: [1m[32m0.60580[0m[0m | time: 67.407s
[2K
| Adam | epoch: 001 | loss: 0.60580 - acc: 0.6354 -- iter: 128/246
[A[ATraining Step: 5  | total loss: [1m[32m0.49422[0m[0m | time: 75.902s
[2K
| Adam | epoch: 001 | loss: 0.49422 - acc: 0.7580 -- iter: 160/246
[A[ATraining Step: 6  | total loss: [1m[32m0.71980[0m[0m | time: 85.417s
[2K
| Adam | epoch: 001 | loss: 0.71980 - acc: 0.7127 -- iter: 192/246
[A[ATraining Step: 7  | total loss: [1m[32m0.58706[0m[0m | time: 93.736s
[2K
| Adam | epoch: 001 | loss: 0.58706 - acc: 0.7351 -- iter: 224/246
[A[ATraining Step: 8  | total loss: [1m[32m0.54326[0m[0m | time: 111.081s
[2K
| Adam | epoch: 001 | loss: 0.54326 - acc: 0.7962 | val_loss: 1.77947 - val_acc: 0.3247 -- iter: 246/246
--
Training Step: 9  | total loss: [1m[32m0.53945[0m[0m | time: 6.201s
[2K
| Adam | epoch: 002 | loss: 0.53945 - acc: 0.7838 -- iter: 032/246
[A[ATraining Step: 10  | total loss: [1m[32m0.45363[0m[0m | time: 15.912s
[2K
| Adam | epoch: 002 | loss: 0.45363 - acc: 0.8464 -- iter: 064/246
[A[ATraining Step: 11  | total loss: [1m[32m0.42454[0m[0m | time: 24.114s
[2K
| Adam | epoch: 002 | loss: 0.42454 - acc: 0.8748 -- iter: 096/246
[A[ATraining Step: 12  | total loss: [1m[32m0.51182[0m[0m | time: 33.648s
[2K
| Adam | epoch: 002 | loss: 0.51182 - acc: 0.7905 -- iter: 128/246
[A[ATraining Step: 13  | total loss: [1m[32m0.44092[0m[0m | time: 42.096s
[2K
| Adam | epoch: 002 | loss: 0.44092 - acc: 0.8401 -- iter: 160/246
[A[ATraining Step: 14  | total loss: [1m[32m0.39892[0m[0m | time: 51.755s
[2K
| Adam | epoch: 002 | loss: 0.39892 - acc: 0.8799 -- iter: 192/246
[A[ATraining Step: 15  | total loss: [1m[32m0.35039[0m[0m | time: 60.489s
[2K
| Adam | epoch: 002 | loss: 0.35039 - acc: 0.9147 -- iter: 224/246
[A[ATraining Step: 16  | total loss: [1m[32m0.35101[0m[0m | time: 73.485s
[2K
| Adam | epoch: 002 | loss: 0.35101 - acc: 0.9350 | val_loss: 1.66775 - val_acc: 0.3247 -- iter: 246/246
--
Training Step: 17  | total loss: [1m[32m0.32224[0m[0m | time: 6.927s
[2K
| Adam | epoch: 003 | loss: 0.32224 - acc: 0.9471 -- iter: 032/246
[A[ATraining Step: 18  | total loss: [1m[32m0.31307[0m[0m | time: 13.792s
[2K
| Adam | epoch: 003 | loss: 0.31307 - acc: 0.9340 -- iter: 064/246
[A[ATraining Step: 19  | total loss: [1m[32m0.28619[0m[0m | time: 22.230s
[2K
| Adam | epoch: 003 | loss: 0.28619 - acc: 0.9257 -- iter: 096/246
[A[ATraining Step: 20  | total loss: [1m[32m0.25555[0m[0m | time: 30.045s
[2K
| Adam | epoch: 003 | loss: 0.25555 - acc: 0.9395 -- iter: 128/246
[A[ATraining Step: 21  | total loss: [1m[32m0.25314[0m[0m | time: 37.789s
[2K
| Adam | epoch: 003 | loss: 0.25314 - acc: 0.9486 -- iter: 160/246
[A[ATraining Step: 22  | total loss: [1m[32m0.21726[0m[0m | time: 45.671s
[2K
| Adam | epoch: 003 | loss: 0.21726 - acc: 0.9546 -- iter: 192/246
[A[ATraining Step: 23  | total loss: [1m[32m0.19674[0m[0m | time: 53.521s
[2K
| Adam | epoch: 003 | loss: 0.19674 - acc: 0.9587 -- iter: 224/246
[A[ATraining Step: 24  | total loss: [1m[32m0.16068[0m[0m | time: 64.763s
[2K
| Adam | epoch: 003 | loss: 0.16068 - acc: 0.9703 | val_loss: 1.69091 - val_acc: 0.3247 -- iter: 246/246
--
Training Step: 25  | total loss: [1m[32m0.13491[0m[0m | time: 7.941s
[2K
| Adam | epoch: 004 | loss: 0.13491 - acc: 0.9784 -- iter: 032/246
[A[ATraining Step: 26  | total loss: [1m[32m0.12579[0m[0m | time: 13.769s
[2K
| Adam | epoch: 004 | loss: 0.12579 - acc: 0.9841 -- iter: 064/246
[A[ATraining Step: 27  | total loss: [1m[32m0.11915[0m[0m | time: 19.666s
[2K
| Adam | epoch: 004 | loss: 0.11915 - acc: 0.9765 -- iter: 096/246
[A[ATraining Step: 28  | total loss: [1m[32m0.10026[0m[0m | time: 27.447s
[2K
| Adam | epoch: 004 | loss: 0.10026 - acc: 0.9824 -- iter: 128/246
[A[ATraining Step: 29  | total loss: [1m[32m0.08841[0m[0m | time: 35.308s
[2K
| Adam | epoch: 004 | loss: 0.08841 - acc: 0.9791 -- iter: 160/246
[A[ATraining Step: 30  | total loss: [1m[32m0.10202[0m[0m | time: 42.995s
[2K
| Adam | epoch: 004 | loss: 0.10202 - acc: 0.9766 -- iter: 192/246
[A[ATraining Step: 31  | total loss: [1m[32m0.08411[0m[0m | time: 50.814s
[2K
| Adam | epoch: 004 | loss: 0.08411 - acc: 0.9820 -- iter: 224/246
[A[ATraining Step: 32  | total loss: [1m[32m0.08664[0m[0m | time: 62.142s
[2K
| Adam | epoch: 004 | loss: 0.08664 - acc: 0.9861 | val_loss: 2.05303 - val_acc: 0.3247 -- iter: 246/246
--
Training Step: 33  | total loss: [1m[32m0.07052[0m[0m | time: 7.990s
[2K
| Adam | epoch: 005 | loss: 0.07052 - acc: 0.9891 -- iter: 032/246
[A[ATraining Step: 34  | total loss: [1m[32m0.06184[0m[0m | time: 15.865s
[2K
| Adam | epoch: 005 | loss: 0.06184 - acc: 0.9915 -- iter: 064/246
[A[ATraining Step: 35  | total loss: [1m[32m0.05083[0m[0m | time: 21.790s
[2K
| Adam | epoch: 005 | loss: 0.05083 - acc: 0.9932 -- iter: 096/246
[A[ATraining Step: 36  | total loss: [1m[32m0.04278[0m[0m | time: 27.570s
[2K
| Adam | epoch: 005 | loss: 0.04278 - acc: 0.9946 -- iter: 128/246
[A[ATraining Step: 37  | total loss: [1m[32m0.03600[0m[0m | time: 35.408s
[2K
| Adam | epoch: 005 | loss: 0.03600 - acc: 0.9957 -- iter: 160/246
[A[ATraining Step: 38  | total loss: [1m[32m0.03432[0m[0m | time: 43.124s
[2K
| Adam | epoch: 005 | loss: 0.03432 - acc: 0.9965 -- iter: 192/246
[A[ATraining Step: 39  | total loss: [1m[32m0.02872[0m[0m | time: 51.060s
[2K
| Adam | epoch: 005 | loss: 0.02872 - acc: 0.9972 -- iter: 224/246
[A[ATraining Step: 40  | total loss: [1m[32m0.02452[0m[0m | time: 62.232s
[2K
| Adam | epoch: 005 | loss: 0.02452 - acc: 0.9977 | val_loss: 3.25829 - val_acc: 0.3247 -- iter: 246/246
--
Training Step: 41  | total loss: [1m[32m0.02291[0m[0m | time: 16.145s
[2K
| Adam | epoch: 006 | loss: 0.02291 - acc: 0.9981 -- iter: 032/246
[A[ATraining Step: 42  | total loss: [1m[32m0.01981[0m[0m | time: 27.634s
[2K
| Adam | epoch: 006 | loss: 0.01981 - acc: 0.9985 -- iter: 064/246
[A[ATraining Step: 43  | total loss: [1m[32m0.01694[0m[0m | time: 42.287s
[2K
| Adam | epoch: 006 | loss: 0.01694 - acc: 0.9987 -- iter: 096/246
[A[ATraining Step: 44  | total loss: [1m[32m0.01800[0m[0m | time: 52.194s
[2K
| Adam | epoch: 006 | loss: 0.01800 - acc: 0.9990 -- iter: 128/246
[A[ATraining Step: 45  | total loss: [1m[32m0.01544[0m[0m | time: 63.410s
[2K
| Adam | epoch: 006 | loss: 0.01544 - acc: 0.9991 -- iter: 160/246
[A[ATraining Step: 46  | total loss: [1m[32m0.01331[0m[0m | time: 119.251s
[2K
| Adam | epoch: 006 | loss: 0.01331 - acc: 0.9993 -- iter: 192/246
[A[ATraining Step: 47  | total loss: [1m[32m0.01160[0m[0m | time: 152.122s
[2K
| Adam | epoch: 006 | loss: 0.01160 - acc: 0.9994 -- iter: 224/246
[A[ATraining Step: 48  | total loss: [1m[32m0.01031[0m[0m | time: 193.663s
[2K
| Adam | epoch: 006 | loss: 0.01031 - acc: 0.9995 | val_loss: 3.25563 - val_acc: 0.3247 -- iter: 246/246
--
Training Step: 49  | total loss: [1m[32m0.08641[0m[0m | time: 12.518s
[2K
| Adam | epoch: 007 | loss: 0.08641 - acc: 0.9897 -- iter: 032/246
[A[ATraining Step: 50  | total loss: [1m[32m0.07377[0m[0m | time: 24.980s
[2K
| Adam | epoch: 007 | loss: 0.07377 - acc: 0.9913 -- iter: 064/246
[A[ATraining Step: 51  | total loss: [1m[32m0.06296[0m[0m | time: 34.171s
[2K
| Adam | epoch: 007 | loss: 0.06296 - acc: 0.9926 -- iter: 096/246
[A[ATraining Step: 52  | total loss: [1m[32m0.05576[0m[0m | time: 43.561s
[2K
| Adam | epoch: 007 | loss: 0.05576 - acc: 0.9937 -- iter: 128/246
[A[ATraining Step: 53  | total loss: [1m[32m0.06689[0m[0m | time: 51.862s
[2K
| Adam | epoch: 007 | loss: 0.06689 - acc: 0.9901 -- iter: 160/246
[A[ATraining Step: 54  | total loss: [1m[32m0.05775[0m[0m | time: 57.849s
[2K
| Adam | epoch: 007 | loss: 0.05775 - acc: 0.9915 -- iter: 192/246
[A[ATraining Step: 55  | total loss: [1m[32m0.04996[0m[0m | time: 65.642s
[2K
| Adam | epoch: 007 | loss: 0.04996 - acc: 0.9927 -- iter: 224/246
[A[ATraining Step: 56  | total loss: [1m[32m0.04649[0m[0m | time: 77.009s
[2K
| Adam | epoch: 007 | loss: 0.04649 - acc: 0.9893 | val_loss: 0.60856 - val_acc: 0.6883 -- iter: 246/246
--
Training Step: 57  | total loss: [1m[32m0.04085[0m[0m | time: 12.749s
[2K
| Adam | epoch: 008 | loss: 0.04085 - acc: 0.9908 -- iter: 032/246
[A[ATraining Step: 58  | total loss: [1m[32m0.03579[0m[0m | time: 25.558s
[2K
| Adam | epoch: 008 | loss: 0.03579 - acc: 0.9921 -- iter: 064/246
[A[ATraining Step: 59  | total loss: [1m[32m0.03161[0m[0m | time: 38.261s
[2K
| Adam | epoch: 008 | loss: 0.03161 - acc: 0.9931 -- iter: 096/246
[A[ATraining Step: 60  | total loss: [1m[32m0.02774[0m[0m | time: 50.778s
[2K
| Adam | epoch: 008 | loss: 0.02774 - acc: 0.9940 -- iter: 128/246
[A[ATraining Step: 61  | total loss: [1m[32m0.02492[0m[0m | time: 63.444s
[2K
| Adam | epoch: 008 | loss: 0.02492 - acc: 0.9948 -- iter: 160/246
[A[ATraining Step: 62  | total loss: [1m[32m0.02240[0m[0m | time: 73.338s
[2K
| Adam | epoch: 008 | loss: 0.02240 - acc: 0.9955 -- iter: 192/246
[A[ATraining Step: 63  | total loss: [1m[32m0.02047[0m[0m | time: 82.563s
[2K
| Adam | epoch: 008 | loss: 0.02047 - acc: 0.9961 -- iter: 224/246
[A[ATraining Step: 64  | total loss: [1m[32m0.01860[0m[0m | time: 101.920s
[2K
| Adam | epoch: 008 | loss: 0.01860 - acc: 0.9966 | val_loss: 0.50898 - val_acc: 0.8182 -- iter: 246/246
--
Training Step: 65  | total loss: [1m[32m0.01662[0m[0m | time: 10.613s
[2K
| Adam | epoch: 009 | loss: 0.01662 - acc: 0.9970 -- iter: 032/246
[A[ATraining Step: 66  | total loss: [1m[32m0.01479[0m[0m | time: 23.945s
[2K
| Adam | epoch: 009 | loss: 0.01479 - acc: 0.9973 -- iter: 064/246
[A[ATraining Step: 67  | total loss: [1m[32m0.06816[0m[0m | time: 39.091s
[2K
| Adam | epoch: 009 | loss: 0.06816 - acc: 0.9902 -- iter: 096/246
[A[ATraining Step: 68  | total loss: [1m[32m0.06030[0m[0m | time: 54.277s
[2K
| Adam | epoch: 009 | loss: 0.06030 - acc: 0.9913 -- iter: 128/246
[A[ATraining Step: 69  | total loss: [1m[32m0.05373[0m[0m | time: 69.131s
[2K
| Adam | epoch: 009 | loss: 0.05373 - acc: 0.9923 -- iter: 160/246
[A[ATraining Step: 70  | total loss: [1m[32m0.04781[0m[0m | time: 84.036s
[2K
| Adam | epoch: 009 | loss: 0.04781 - acc: 0.9932 -- iter: 192/246
[A[ATraining Step: 71  | total loss: [1m[32m0.04486[0m[0m | time: 95.024s
[2K
| Adam | epoch: 009 | loss: 0.04486 - acc: 0.9940 -- iter: 224/246
[A[ATraining Step: 72  | total loss: [1m[32m0.04012[0m[0m | time: 113.096s
[2K
| Adam | epoch: 009 | loss: 0.04012 - acc: 0.9947 | val_loss: 1.25837 - val_acc: 0.5844 -- iter: 246/246
--
Training Step: 73  | total loss: [1m[32m0.03595[0m[0m | time: 16.013s
[2K
| Adam | epoch: 010 | loss: 0.03595 - acc: 0.9953 -- iter: 032/246
[A[ATraining Step: 74  | total loss: [1m[32m0.03231[0m[0m | time: 31.327s
[2K
| Adam | epoch: 010 | loss: 0.03231 - acc: 0.9958 -- iter: 064/246
[A[ATraining Step: 75  | total loss: [1m[32m0.02917[0m[0m | time: 46.474s
[2K
| Adam | epoch: 010 | loss: 0.02917 - acc: 0.9962 -- iter: 096/246
[A[ATraining Step: 76  | total loss: [1m[32m0.04988[0m[0m | time: 61.292s
[2K
| Adam | epoch: 010 | loss: 0.04988 - acc: 0.9933 -- iter: 128/246
[A[ATraining Step: 77  | total loss: [1m[32m0.04580[0m[0m | time: 70.552s
[2K
| Adam | epoch: 010 | loss: 0.04580 - acc: 0.9940 -- iter: 160/246
[A[ATraining Step: 78  | total loss: [1m[32m0.04148[0m[0m | time: 80.503s
[2K
| Adam | epoch: 010 | loss: 0.04148 - acc: 0.9946 -- iter: 192/246
[A[ATraining Step: 79  | total loss: [1m[32m0.04157[0m[0m | time: 92.595s
[2K
| Adam | epoch: 010 | loss: 0.04157 - acc: 0.9952 -- iter: 224/246
[A[ATraining Step: 80  | total loss: [1m[32m0.03791[0m[0m | time: 108.990s
[2K
| Adam | epoch: 010 | loss: 0.03791 - acc: 0.9957 | val_loss: 0.39583 - val_acc: 0.8182 -- iter: 246/246
--
Training Step: 81  | total loss: [1m[32m0.03714[0m[0m | time: 11.784s
[2K
| Adam | epoch: 011 | loss: 0.03714 - acc: 0.9961 -- iter: 032/246
[A[ATraining Step: 82  | total loss: [1m[32m0.03525[0m[0m | time: 25.255s
[2K
| Adam | epoch: 011 | loss: 0.03525 - acc: 0.9965 -- iter: 064/246
[A[ATraining Step: 83  | total loss: [1m[32m0.03210[0m[0m | time: 37.913s
[2K
| Adam | epoch: 011 | loss: 0.03210 - acc: 0.9969 -- iter: 096/246
[A[ATraining Step: 84  | total loss: [1m[32m0.05680[0m[0m | time: 50.840s
[2K
| Adam | epoch: 011 | loss: 0.05680 - acc: 0.9940 -- iter: 128/246
[A[ATraining Step: 85  | total loss: [1m[32m0.21181[0m[0m | time: 63.336s
[2K
| Adam | epoch: 011 | loss: 0.21181 - acc: 0.9696 -- iter: 160/246
[A[ATraining Step: 86  | total loss: [1m[32m0.19182[0m[0m | time: 76.004s
[2K
| Adam | epoch: 011 | loss: 0.19182 - acc: 0.9727 -- iter: 192/246
[A[ATraining Step: 87  | total loss: [1m[32m0.17312[0m[0m | time: 88.505s
[2K
| Adam | epoch: 011 | loss: 0.17312 - acc: 0.9754 -- iter: 224/246
[A[ATraining Step: 88  | total loss: [1m[32m0.15684[0m[0m | time: 106.864s
[2K
| Adam | epoch: 011 | loss: 0.15684 - acc: 0.9779 | val_loss: 1.63519 - val_acc: 0.6883 -- iter: 246/246
--
Training Step: 89  | total loss: [1m[32m0.14815[0m[0m | time: 5.854s
[2K
| Adam | epoch: 012 | loss: 0.14815 - acc: 0.9770 -- iter: 032/246
[A[ATraining Step: 90  | total loss: [1m[32m0.13403[0m[0m | time: 14.000s
[2K
| Adam | epoch: 012 | loss: 0.13403 - acc: 0.9793 -- iter: 064/246
[A[ATraining Step: 91  | total loss: [1m[32m0.12120[0m[0m | time: 26.444s
[2K
| Adam | epoch: 012 | loss: 0.12120 - acc: 0.9813 -- iter: 096/246
[A[ATraining Step: 92  | total loss: [1m[32m0.11261[0m[0m | time: 37.572s
[2K
| Adam | epoch: 012 | loss: 0.11261 - acc: 0.9801 -- iter: 128/246
[A[ATraining Step: 93  | total loss: [1m[32m0.10984[0m[0m | time: 49.579s
[2K
| Adam | epoch: 012 | loss: 0.10984 - acc: 0.9789 -- iter: 160/246
[A[ATraining Step: 94  | total loss: [1m[32m0.09962[0m[0m | time: 62.220s
[2K
| Adam | epoch: 012 | loss: 0.09962 - acc: 0.9810 -- iter: 192/246
[A[ATraining Step: 95  | total loss: [1m[32m0.09062[0m[0m | time: 74.854s
[2K
| Adam | epoch: 012 | loss: 0.09062 - acc: 0.9829 -- iter: 224/246
[A[ATraining Step: 96  | total loss: [1m[32m0.08562[0m[0m | time: 93.738s
[2K
| Adam | epoch: 012 | loss: 0.08562 - acc: 0.9815 | val_loss: 1.56704 - val_acc: 0.4805 -- iter: 246/246
--
Training Step: 97  | total loss: [1m[32m0.07828[0m[0m | time: 12.359s
[2K
| Adam | epoch: 013 | loss: 0.07828 - acc: 0.9834 -- iter: 032/246
[A[ATraining Step: 98  | total loss: [1m[32m0.07608[0m[0m | time: 21.980s
[2K
| Adam | epoch: 013 | loss: 0.07608 - acc: 0.9819 -- iter: 064/246
[A[ATraining Step: 99  | total loss: [1m[32m0.07056[0m[0m | time: 31.481s
[2K
| Adam | epoch: 013 | loss: 0.07056 - acc: 0.9837 -- iter: 096/246
[A[ATraining Step: 100  | total loss: [1m[32m0.06482[0m[0m | time: 42.644s
[2K
| Adam | epoch: 013 | loss: 0.06482 - acc: 0.9853 -- iter: 128/246
[A[ATraining Step: 101  | total loss: [1m[32m0.06668[0m[0m | time: 50.511s
[2K
| Adam | epoch: 013 | loss: 0.06668 - acc: 0.9837 -- iter: 160/246
[A[ATraining Step: 102  | total loss: [1m[32m0.07176[0m[0m | time: 58.448s
[2K
| Adam | epoch: 013 | loss: 0.07176 - acc: 0.9822 -- iter: 192/246
[A[ATraining Step: 103  | total loss: [1m[32m0.06658[0m[0m | time: 66.214s
[2K
| Adam | epoch: 013 | loss: 0.06658 - acc: 0.9840 -- iter: 224/246
[A[ATraining Step: 104  | total loss: [1m[32m0.06958[0m[0m | time: 78.487s
[2K
| Adam | epoch: 013 | loss: 0.06958 - acc: 0.9825 | val_loss: 0.41142 - val_acc: 0.8182 -- iter: 246/246
--
Training Step: 105  | total loss: [1m[32m0.06421[0m[0m | time: 10.584s
[2K
| Adam | epoch: 014 | loss: 0.06421 - acc: 0.9842 -- iter: 032/246
[A[ATraining Step: 106  | total loss: [1m[32m0.05907[0m[0m | time: 23.067s
[2K
| Adam | epoch: 014 | loss: 0.05907 - acc: 0.9858 -- iter: 064/246
[A[ATraining Step: 107  | total loss: [1m[32m0.05500[0m[0m | time: 32.662s
[2K
| Adam | epoch: 014 | loss: 0.05500 - acc: 0.9872 -- iter: 096/246
[A[ATraining Step: 108  | total loss: [1m[32m0.05447[0m[0m | time: 41.869s
[2K
| Adam | epoch: 014 | loss: 0.05447 - acc: 0.9885 -- iter: 128/246
[A[ATraining Step: 109  | total loss: [1m[32m0.05043[0m[0m | time: 54.288s
[2K
| Adam | epoch: 014 | loss: 0.05043 - acc: 0.9896 -- iter: 160/246
[A[ATraining Step: 110  | total loss: [1m[32m0.04779[0m[0m | time: 66.889s
[2K
| Adam | epoch: 014 | loss: 0.04779 - acc: 0.9907 -- iter: 192/246
[A[ATraining Step: 111  | total loss: [1m[32m0.04437[0m[0m | time: 79.366s
[2K
| Adam | epoch: 014 | loss: 0.04437 - acc: 0.9916 -- iter: 224/246
[A[ATraining Step: 112  | total loss: [1m[32m0.04076[0m[0m | time: 97.459s
[2K
| Adam | epoch: 014 | loss: 0.04076 - acc: 0.9924 | val_loss: 1.99254 - val_acc: 0.4286 -- iter: 246/246
--
Training Step: 113  | total loss: [1m[32m0.03763[0m[0m | time: 8.056s
[2K
| Adam | epoch: 015 | loss: 0.03763 - acc: 0.9932 -- iter: 032/246
[A[ATraining Step: 114  | total loss: [1m[32m0.03509[0m[0m | time: 15.892s
[2K
| Adam | epoch: 015 | loss: 0.03509 - acc: 0.9939 -- iter: 064/246
[A[ATraining Step: 115  | total loss: [1m[32m0.03221[0m[0m | time: 23.770s
[2K
| Adam | epoch: 015 | loss: 0.03221 - acc: 0.9945 -- iter: 096/246
[A[ATraining Step: 116  | total loss: [1m[32m0.03124[0m[0m | time: 29.528s
[2K
| Adam | epoch: 015 | loss: 0.03124 - acc: 0.9950 -- iter: 128/246
[A[ATraining Step: 117  | total loss: [1m[32m0.03043[0m[0m | time: 36.852s
[2K
| Adam | epoch: 015 | loss: 0.03043 - acc: 0.9955 -- iter: 160/246
[A[ATraining Step: 118  | total loss: [1m[32m0.02814[0m[0m | time: 49.180s
[2K
| Adam | epoch: 015 | loss: 0.02814 - acc: 0.9960 -- iter: 192/246
[A[ATraining Step: 119  | total loss: [1m[32m0.02596[0m[0m | time: 61.552s
[2K
| Adam | epoch: 015 | loss: 0.02596 - acc: 0.9964 -- iter: 224/246
[A[ATraining Step: 120  | total loss: [1m[32m0.02414[0m[0m | time: 79.555s
[2K
| Adam | epoch: 015 | loss: 0.02414 - acc: 0.9967 | val_loss: 2.20051 - val_acc: 0.7143 -- iter: 246/246
--
Validation AUC:0.8588461538461538
Validation AUPRC:0.917626532620625
Test AUC:0.8604488078541375
Test AUPRC:0.8602259190314796
BestTestF1Score	0.83	0.51	0.75	0.71	0.98	45	18	13	1	1.0
BestTestMCCScore	0.83	0.51	0.75	0.71	0.98	45	18	13	1	1.0
BestTestAccuracyScore	0.83	0.51	0.75	0.71	0.98	45	18	13	1	1.0
BestValidationF1Score	0.85	0.46	0.78	0.78	0.94	49	14	11	3	1.0
BestValidationMCC	0.85	0.46	0.78	0.78	0.94	49	14	11	3	1.0
BestValidationAccuracy	0.85	0.46	0.78	0.78	0.94	49	14	11	3	1.0
TestPredictions (Threshold:1.0)
CHEMBL365747,FP,INACT,1.0	CHEMBL6484,TN,INACT,0.4399999976158142	CHEMBL2011680,FP,INACT,1.0	CHEMBL359643,TP,ACT,1.0	CHEMBL248310,TP,ACT,1.0	CHEMBL567134,FP,INACT,1.0	CHEMBL100578,FP,INACT,1.0	CHEMBL3806289,TN,INACT,0.8899999856948853	CHEMBL182295,TP,ACT,1.0	CHEMBL30983,TN,INACT,0.4000000059604645	CHEMBL148162,TP,ACT,1.0	CHEMBL400366,FP,INACT,1.0	CHEMBL103592,TP,ACT,1.0	CHEMBL2181109,TN,INACT,0.8399999737739563	CHEMBL321074,TP,ACT,1.0	CHEMBL200819,TP,ACT,1.0	CHEMBL567341,FP,INACT,1.0	CHEMBL304368,TP,ACT,1.0	CHEMBL2391855,TN,INACT,0.9900000095367432	CHEMBL361397,TP,ACT,1.0	CHEMBL194183,TN,INACT,0.5	CHEMBL198743,TP,ACT,1.0	CHEMBL221870,TP,ACT,1.0	CHEMBL213952,TP,ACT,1.0	CHEMBL100927,FP,INACT,1.0	CHEMBL429646,TP,ACT,1.0	CHEMBL180646,TP,ACT,1.0	CHEMBL3359187,FP,INACT,1.0	CHEMBL360956,TP,ACT,1.0	CHEMBL242937,TP,ACT,1.0	CHEMBL268772,TP,ACT,1.0	CHEMBL354612,TP,ACT,1.0	CHEMBL1241864,FP,INACT,1.0	CHEMBL441118,TP,ACT,1.0	CHEMBL3121475,TN,INACT,0.75	CHEMBL567893,TP,ACT,1.0	CHEMBL381624,TP,ACT,1.0	CHEMBL358725,FN,ACT,0.9800000190734863	CHEMBL2391860,FP,INACT,1.0	CHEMBL1241358,TN,INACT,0.9599999785423279	CHEMBL213965,TP,ACT,1.0	CHEMBL212870,TP,ACT,1.0	CHEMBL380780,TP,ACT,1.0	CHEMBL441854,TP,ACT,1.0	CHEMBL447233,TP,ACT,1.0	CHEMBL199264,TP,ACT,1.0	CHEMBL242511,TP,ACT,1.0	CHEMBL180669,TP,ACT,1.0	CHEMBL203709,TP,ACT,1.0	CHEMBL182078,TP,ACT,1.0	CHEMBL357191,TP,ACT,1.0	CHEMBL2391776,TN,INACT,0.9399999976158142	CHEMBL2041041,FP,INACT,1.0	CHEMBL182103,TP,ACT,1.0	CHEMBL422,FP,INACT,1.0	CHEMBL2041036,FP,INACT,1.0	CHEMBL1835320,TN,INACT,0.9599999785423279	CHEMBL149307,FP,INACT,1.0	CHEMBL242938,TP,ACT,1.0	CHEMBL2391981,FP,INACT,1.0	CHEMBL214226,TP,ACT,1.0	CHEMBL424789,TP,ACT,1.0	CHEMBL360046,TP,ACT,1.0	CHEMBL2324341,TP,ACT,1.0	CHEMBL195568,TN,INACT,0.9300000071525574	CHEMBL362213,TP,ACT,1.0	CHEMBL204245,FP,INACT,1.0	CHEMBL101835,TP,ACT,1.0	CHEMBL417149,TP,ACT,1.0	CHEMBL81038,TP,ACT,1.0	CHEMBL420458,TP,ACT,1.0	CHEMBL185356,TP,ACT,1.0	CHEMBL183379,TP,ACT,1.0	CHEMBL1223039,FP,INACT,1.0	CHEMBL1603488,TN,INACT,0.9900000095367432	CHEMBL1835404,TN,INACT,0.0	CHEMBL2391863,FP,INACT,1.0	

