ImageNetInceptionV2 CHEMBL2564 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	361
Number of inactive compounds :	241
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2564_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2564_adam_0.001_15_0.6/
---------------------------------
Training samples: 384
Validation samples: 121
--
Training Step: 1  | time: 47.456s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/384
[A[ATraining Step: 2  | total loss: [1m[32m0.61037[0m[0m | time: 75.695s
[2K
| Adam | epoch: 001 | loss: 0.61037 - acc: 0.4500 -- iter: 064/384
[A[ATraining Step: 3  | total loss: [1m[32m0.71556[0m[0m | time: 111.340s
[2K
| Adam | epoch: 001 | loss: 0.71556 - acc: 0.6443 -- iter: 096/384
[A[ATraining Step: 4  | total loss: [1m[32m0.63805[0m[0m | time: 138.599s
[2K
| Adam | epoch: 001 | loss: 0.63805 - acc: 0.5830 -- iter: 128/384
[A[ATraining Step: 5  | total loss: [1m[32m0.66566[0m[0m | time: 161.192s
[2K
| Adam | epoch: 001 | loss: 0.66566 - acc: 0.5688 -- iter: 160/384
[A[ATraining Step: 6  | total loss: [1m[32m0.56842[0m[0m | time: 172.005s
[2K
| Adam | epoch: 001 | loss: 0.56842 - acc: 0.6853 -- iter: 192/384
[A[ATraining Step: 7  | total loss: [1m[32m0.53688[0m[0m | time: 182.902s
[2K
| Adam | epoch: 001 | loss: 0.53688 - acc: 0.6866 -- iter: 224/384
[A[ATraining Step: 8  | total loss: [1m[32m0.58016[0m[0m | time: 194.884s
[2K
| Adam | epoch: 001 | loss: 0.58016 - acc: 0.7047 -- iter: 256/384
[A[ATraining Step: 9  | total loss: [1m[32m0.50994[0m[0m | time: 234.565s
[2K
| Adam | epoch: 001 | loss: 0.50994 - acc: 0.7618 -- iter: 288/384
[A[ATraining Step: 10  | total loss: [1m[32m0.55529[0m[0m | time: 265.566s
[2K
| Adam | epoch: 001 | loss: 0.55529 - acc: 0.7246 -- iter: 320/384
[A[ATraining Step: 11  | total loss: [1m[32m0.46740[0m[0m | time: 298.212s
[2K
| Adam | epoch: 001 | loss: 0.46740 - acc: 0.7959 -- iter: 352/384
[A[ATraining Step: 12  | total loss: [1m[32m0.47057[0m[0m | time: 355.351s
[2K
| Adam | epoch: 001 | loss: 0.47057 - acc: 0.7893 | val_loss: 4.04559 - val_acc: 0.5702 -- iter: 384/384
--
Training Step: 13  | total loss: [1m[32m0.44315[0m[0m | time: 8.761s
[2K
| Adam | epoch: 002 | loss: 0.44315 - acc: 0.7858 -- iter: 032/384
[A[ATraining Step: 14  | total loss: [1m[32m0.37689[0m[0m | time: 21.777s
[2K
| Adam | epoch: 002 | loss: 0.37689 - acc: 0.8351 -- iter: 064/384
[A[ATraining Step: 15  | total loss: [1m[32m0.34900[0m[0m | time: 31.158s
[2K
| Adam | epoch: 002 | loss: 0.34900 - acc: 0.8507 -- iter: 096/384
[A[ATraining Step: 16  | total loss: [1m[32m0.44515[0m[0m | time: 39.508s
[2K
| Adam | epoch: 002 | loss: 0.44515 - acc: 0.7778 -- iter: 128/384
[A[ATraining Step: 17  | total loss: [1m[32m0.51365[0m[0m | time: 48.075s
[2K
| Adam | epoch: 002 | loss: 0.51365 - acc: 0.7453 -- iter: 160/384
[A[ATraining Step: 18  | total loss: [1m[32m0.45078[0m[0m | time: 57.193s
[2K
| Adam | epoch: 002 | loss: 0.45078 - acc: 0.7794 -- iter: 192/384
[A[ATraining Step: 19  | total loss: [1m[32m0.42855[0m[0m | time: 66.814s
[2K
| Adam | epoch: 002 | loss: 0.42855 - acc: 0.8008 -- iter: 224/384
[A[ATraining Step: 20  | total loss: [1m[32m0.37756[0m[0m | time: 75.078s
[2K
| Adam | epoch: 002 | loss: 0.37756 - acc: 0.8146 -- iter: 256/384
[A[ATraining Step: 21  | total loss: [1m[32m0.32920[0m[0m | time: 94.748s
[2K
| Adam | epoch: 002 | loss: 0.32920 - acc: 0.8334 -- iter: 288/384
[A[ATraining Step: 22  | total loss: [1m[32m0.28047[0m[0m | time: 103.082s
[2K
| Adam | epoch: 002 | loss: 0.28047 - acc: 0.8646 -- iter: 320/384
[A[ATraining Step: 23  | total loss: [1m[32m0.33330[0m[0m | time: 111.484s
[2K
| Adam | epoch: 002 | loss: 0.33330 - acc: 0.8495 -- iter: 352/384
[A[ATraining Step: 24  | total loss: [1m[32m0.31100[0m[0m | time: 131.926s
[2K
| Adam | epoch: 002 | loss: 0.31100 - acc: 0.8742 | val_loss: 7.13103 - val_acc: 0.5702 -- iter: 384/384
--
Training Step: 25  | total loss: [1m[32m0.26014[0m[0m | time: 8.358s
[2K
| Adam | epoch: 003 | loss: 0.26014 - acc: 0.9000 -- iter: 032/384
[A[ATraining Step: 26  | total loss: [1m[32m0.25205[0m[0m | time: 21.755s
[2K
| Adam | epoch: 003 | loss: 0.25205 - acc: 0.8851 -- iter: 064/384
[A[ATraining Step: 27  | total loss: [1m[32m0.22888[0m[0m | time: 30.498s
[2K
| Adam | epoch: 003 | loss: 0.22888 - acc: 0.9066 -- iter: 096/384
[A[ATraining Step: 28  | total loss: [1m[32m0.32288[0m[0m | time: 38.758s
[2K
| Adam | epoch: 003 | loss: 0.32288 - acc: 0.8909 -- iter: 128/384
[A[ATraining Step: 29  | total loss: [1m[32m0.40167[0m[0m | time: 47.978s
[2K
| Adam | epoch: 003 | loss: 0.40167 - acc: 0.8642 -- iter: 160/384
[A[ATraining Step: 30  | total loss: [1m[32m0.40428[0m[0m | time: 56.504s
[2K
| Adam | epoch: 003 | loss: 0.40428 - acc: 0.8742 -- iter: 192/384
[A[ATraining Step: 31  | total loss: [1m[32m0.37696[0m[0m | time: 64.788s
[2K
| Adam | epoch: 003 | loss: 0.37696 - acc: 0.8816 -- iter: 224/384
[A[ATraining Step: 32  | total loss: [1m[32m0.34857[0m[0m | time: 73.100s
[2K
| Adam | epoch: 003 | loss: 0.34857 - acc: 0.8871 -- iter: 256/384
[A[ATraining Step: 33  | total loss: [1m[32m0.33344[0m[0m | time: 81.507s
[2K
| Adam | epoch: 003 | loss: 0.33344 - acc: 0.8845 -- iter: 288/384
[A[ATraining Step: 34  | total loss: [1m[32m0.29884[0m[0m | time: 90.037s
[2K
| Adam | epoch: 003 | loss: 0.29884 - acc: 0.9092 -- iter: 320/384
[A[ATraining Step: 35  | total loss: [1m[32m0.30425[0m[0m | time: 98.627s
[2K
| Adam | epoch: 003 | loss: 0.30425 - acc: 0.9021 -- iter: 352/384
[A[ATraining Step: 36  | total loss: [1m[32m0.28858[0m[0m | time: 112.337s
[2K
| Adam | epoch: 003 | loss: 0.28858 - acc: 0.8965 | val_loss: 2.72689 - val_acc: 0.5372 -- iter: 384/384
--
Training Step: 37  | total loss: [1m[32m0.25871[0m[0m | time: 8.872s
[2K
| Adam | epoch: 004 | loss: 0.25871 - acc: 0.9110 -- iter: 032/384
[A[ATraining Step: 38  | total loss: [1m[32m0.22688[0m[0m | time: 17.351s
[2K
| Adam | epoch: 004 | loss: 0.22688 - acc: 0.9223 -- iter: 064/384
[A[ATraining Step: 39  | total loss: [1m[32m0.20889[0m[0m | time: 25.492s
[2K
| Adam | epoch: 004 | loss: 0.20889 - acc: 0.9312 -- iter: 096/384
[A[ATraining Step: 40  | total loss: [1m[32m0.18720[0m[0m | time: 33.625s
[2K
| Adam | epoch: 004 | loss: 0.18720 - acc: 0.9441 -- iter: 128/384
[A[ATraining Step: 41  | total loss: [1m[32m0.22004[0m[0m | time: 42.131s
[2K
| Adam | epoch: 004 | loss: 0.22004 - acc: 0.9314 -- iter: 160/384
[A[ATraining Step: 42  | total loss: [1m[32m0.19241[0m[0m | time: 53.969s
[2K
| Adam | epoch: 004 | loss: 0.19241 - acc: 0.9437 -- iter: 192/384
[A[ATraining Step: 43  | total loss: [1m[32m0.19536[0m[0m | time: 62.413s
[2K
| Adam | epoch: 004 | loss: 0.19536 - acc: 0.9316 -- iter: 224/384
[A[ATraining Step: 44  | total loss: [1m[32m0.18155[0m[0m | time: 70.601s
[2K
| Adam | epoch: 004 | loss: 0.18155 - acc: 0.9380 -- iter: 256/384
[A[ATraining Step: 45  | total loss: [1m[32m0.18703[0m[0m | time: 78.908s
[2K
| Adam | epoch: 004 | loss: 0.18703 - acc: 0.9326 -- iter: 288/384
[A[ATraining Step: 46  | total loss: [1m[32m0.18463[0m[0m | time: 87.217s
[2K
| Adam | epoch: 004 | loss: 0.18463 - acc: 0.9335 -- iter: 320/384
[A[ATraining Step: 47  | total loss: [1m[32m0.17236[0m[0m | time: 95.444s
[2K
| Adam | epoch: 004 | loss: 0.17236 - acc: 0.9341 -- iter: 352/384
[A[ATraining Step: 48  | total loss: [1m[32m0.16575[0m[0m | time: 109.013s
[2K
| Adam | epoch: 004 | loss: 0.16575 - acc: 0.9347 | val_loss: 7.29195 - val_acc: 0.4298 -- iter: 384/384
--
Training Step: 49  | total loss: [1m[32m0.15542[0m[0m | time: 8.233s
[2K
| Adam | epoch: 005 | loss: 0.15542 - acc: 0.9351 -- iter: 032/384
[A[ATraining Step: 50  | total loss: [1m[32m0.17001[0m[0m | time: 16.467s
[2K
| Adam | epoch: 005 | loss: 0.17001 - acc: 0.9306 -- iter: 064/384
[A[ATraining Step: 51  | total loss: [1m[32m0.15945[0m[0m | time: 24.697s
[2K
| Adam | epoch: 005 | loss: 0.15945 - acc: 0.9317 -- iter: 096/384
[A[ATraining Step: 52  | total loss: [1m[32m0.15097[0m[0m | time: 32.951s
[2K
| Adam | epoch: 005 | loss: 0.15097 - acc: 0.9326 -- iter: 128/384
[A[ATraining Step: 53  | total loss: [1m[32m0.13755[0m[0m | time: 41.372s
[2K
| Adam | epoch: 005 | loss: 0.13755 - acc: 0.9379 -- iter: 160/384
[A[ATraining Step: 54  | total loss: [1m[32m0.17274[0m[0m | time: 49.600s
[2K
| Adam | epoch: 005 | loss: 0.17274 - acc: 0.9333 -- iter: 192/384
[A[ATraining Step: 55  | total loss: [1m[32m0.17140[0m[0m | time: 57.698s
[2K
| Adam | epoch: 005 | loss: 0.17140 - acc: 0.9339 -- iter: 224/384
[A[ATraining Step: 56  | total loss: [1m[32m0.22094[0m[0m | time: 65.987s
[2K
| Adam | epoch: 005 | loss: 0.22094 - acc: 0.9168 -- iter: 256/384
[A[ATraining Step: 57  | total loss: [1m[32m0.21865[0m[0m | time: 74.427s
[2K
| Adam | epoch: 005 | loss: 0.21865 - acc: 0.9240 -- iter: 288/384
[A[ATraining Step: 58  | total loss: [1m[32m0.22404[0m[0m | time: 83.063s
[2K
| Adam | epoch: 005 | loss: 0.22404 - acc: 0.9173 -- iter: 320/384
[A[ATraining Step: 59  | total loss: [1m[32m0.28115[0m[0m | time: 91.506s
[2K
| Adam | epoch: 005 | loss: 0.28115 - acc: 0.8991 -- iter: 352/384
[A[ATraining Step: 60  | total loss: [1m[32m0.25229[0m[0m | time: 105.064s
[2K
| Adam | epoch: 005 | loss: 0.25229 - acc: 0.9083 | val_loss: 4.90540 - val_acc: 0.4298 -- iter: 384/384
--
Training Step: 61  | total loss: [1m[32m0.23064[0m[0m | time: 8.178s
[2K
| Adam | epoch: 006 | loss: 0.23064 - acc: 0.9162 -- iter: 032/384
[A[ATraining Step: 62  | total loss: [1m[32m0.22487[0m[0m | time: 16.536s
[2K
| Adam | epoch: 006 | loss: 0.22487 - acc: 0.9149 -- iter: 064/384
[A[ATraining Step: 63  | total loss: [1m[32m0.22546[0m[0m | time: 24.849s
[2K
| Adam | epoch: 006 | loss: 0.22546 - acc: 0.9178 -- iter: 096/384
[A[ATraining Step: 64  | total loss: [1m[32m0.22416[0m[0m | time: 33.183s
[2K
| Adam | epoch: 006 | loss: 0.22416 - acc: 0.9163 -- iter: 128/384
[A[ATraining Step: 65  | total loss: [1m[32m0.20243[0m[0m | time: 41.652s
[2K
| Adam | epoch: 006 | loss: 0.20243 - acc: 0.9266 -- iter: 160/384
[A[ATraining Step: 66  | total loss: [1m[32m0.18261[0m[0m | time: 50.090s
[2K
| Adam | epoch: 006 | loss: 0.18261 - acc: 0.9356 -- iter: 192/384
[A[ATraining Step: 67  | total loss: [1m[32m0.17871[0m[0m | time: 58.246s
[2K
| Adam | epoch: 006 | loss: 0.17871 - acc: 0.9320 -- iter: 224/384
[A[ATraining Step: 68  | total loss: [1m[32m0.18640[0m[0m | time: 66.553s
[2K
| Adam | epoch: 006 | loss: 0.18640 - acc: 0.9290 -- iter: 256/384
[A[ATraining Step: 69  | total loss: [1m[32m0.18322[0m[0m | time: 74.611s
[2K
| Adam | epoch: 006 | loss: 0.18322 - acc: 0.9300 -- iter: 288/384
[A[ATraining Step: 70  | total loss: [1m[32m0.18908[0m[0m | time: 82.858s
[2K
| Adam | epoch: 006 | loss: 0.18908 - acc: 0.9308 -- iter: 320/384
[A[ATraining Step: 71  | total loss: [1m[32m0.17351[0m[0m | time: 91.021s
[2K
| Adam | epoch: 006 | loss: 0.17351 - acc: 0.9387 -- iter: 352/384
[A[ATraining Step: 72  | total loss: [1m[32m0.16880[0m[0m | time: 104.898s
[2K
| Adam | epoch: 006 | loss: 0.16880 - acc: 0.9421 | val_loss: 0.47391 - val_acc: 0.8099 -- iter: 384/384
--
Training Step: 73  | total loss: [1m[32m0.15572[0m[0m | time: 8.285s
[2K
| Adam | epoch: 007 | loss: 0.15572 - acc: 0.9485 -- iter: 032/384
[A[ATraining Step: 74  | total loss: [1m[32m0.14336[0m[0m | time: 16.419s
[2K
| Adam | epoch: 007 | loss: 0.14336 - acc: 0.9542 -- iter: 064/384
[A[ATraining Step: 75  | total loss: [1m[32m0.13674[0m[0m | time: 24.645s
[2K
| Adam | epoch: 007 | loss: 0.13674 - acc: 0.9558 -- iter: 096/384
[A[ATraining Step: 76  | total loss: [1m[32m0.12599[0m[0m | time: 32.984s
[2K
| Adam | epoch: 007 | loss: 0.12599 - acc: 0.9605 -- iter: 128/384
[A[ATraining Step: 77  | total loss: [1m[32m0.12662[0m[0m | time: 41.176s
[2K
| Adam | epoch: 007 | loss: 0.12662 - acc: 0.9581 -- iter: 160/384
[A[ATraining Step: 78  | total loss: [1m[32m0.12205[0m[0m | time: 49.472s
[2K
| Adam | epoch: 007 | loss: 0.12205 - acc: 0.9592 -- iter: 192/384
[A[ATraining Step: 79  | total loss: [1m[32m0.11475[0m[0m | time: 57.787s
[2K
| Adam | epoch: 007 | loss: 0.11475 - acc: 0.9634 -- iter: 224/384
[A[ATraining Step: 80  | total loss: [1m[32m0.11346[0m[0m | time: 66.066s
[2K
| Adam | epoch: 007 | loss: 0.11346 - acc: 0.9608 -- iter: 256/384
[A[ATraining Step: 81  | total loss: [1m[32m0.11986[0m[0m | time: 74.391s
[2K
| Adam | epoch: 007 | loss: 0.11986 - acc: 0.9584 -- iter: 288/384
[A[ATraining Step: 82  | total loss: [1m[32m0.11384[0m[0m | time: 82.493s
[2K
| Adam | epoch: 007 | loss: 0.11384 - acc: 0.9594 -- iter: 320/384
[A[ATraining Step: 83  | total loss: [1m[32m0.10414[0m[0m | time: 90.756s
[2K
| Adam | epoch: 007 | loss: 0.10414 - acc: 0.9635 -- iter: 352/384
[A[ATraining Step: 84  | total loss: [1m[32m0.10472[0m[0m | time: 104.105s
[2K
| Adam | epoch: 007 | loss: 0.10472 - acc: 0.9578 | val_loss: 0.75903 - val_acc: 0.8430 -- iter: 384/384
--
Training Step: 85  | total loss: [1m[32m0.17670[0m[0m | time: 8.093s
[2K
| Adam | epoch: 008 | loss: 0.17670 - acc: 0.9557 -- iter: 032/384
[A[ATraining Step: 86  | total loss: [1m[32m0.16043[0m[0m | time: 16.401s
[2K
| Adam | epoch: 008 | loss: 0.16043 - acc: 0.9602 -- iter: 064/384
[A[ATraining Step: 87  | total loss: [1m[32m0.16217[0m[0m | time: 24.783s
[2K
| Adam | epoch: 008 | loss: 0.16217 - acc: 0.9548 -- iter: 096/384
[A[ATraining Step: 88  | total loss: [1m[32m0.15772[0m[0m | time: 32.961s
[2K
| Adam | epoch: 008 | loss: 0.15772 - acc: 0.9562 -- iter: 128/384
[A[ATraining Step: 89  | total loss: [1m[32m0.16126[0m[0m | time: 41.107s
[2K
| Adam | epoch: 008 | loss: 0.16126 - acc: 0.9543 -- iter: 160/384
[A[ATraining Step: 90  | total loss: [1m[32m0.15062[0m[0m | time: 49.448s
[2K
| Adam | epoch: 008 | loss: 0.15062 - acc: 0.9558 -- iter: 192/384
[A[ATraining Step: 91  | total loss: [1m[32m0.14346[0m[0m | time: 57.794s
[2K
| Adam | epoch: 008 | loss: 0.14346 - acc: 0.9571 -- iter: 224/384
[A[ATraining Step: 92  | total loss: [1m[32m0.13374[0m[0m | time: 65.895s
[2K
| Adam | epoch: 008 | loss: 0.13374 - acc: 0.9613 -- iter: 256/384
[A[ATraining Step: 93  | total loss: [1m[32m0.14402[0m[0m | time: 74.158s
[2K
| Adam | epoch: 008 | loss: 0.14402 - acc: 0.9558 -- iter: 288/384
[A[ATraining Step: 94  | total loss: [1m[32m0.13950[0m[0m | time: 82.382s
[2K
| Adam | epoch: 008 | loss: 0.13950 - acc: 0.9540 -- iter: 320/384
[A[ATraining Step: 95  | total loss: [1m[32m0.13710[0m[0m | time: 90.669s
[2K
| Adam | epoch: 008 | loss: 0.13710 - acc: 0.9555 -- iter: 352/384
[A[ATraining Step: 96  | total loss: [1m[32m0.16505[0m[0m | time: 104.394s
[2K
| Adam | epoch: 008 | loss: 0.16505 - acc: 0.9412 | val_loss: 0.59591 - val_acc: 0.8264 -- iter: 384/384
--
Training Step: 97  | total loss: [1m[32m0.16470[0m[0m | time: 8.266s
[2K
| Adam | epoch: 009 | loss: 0.16470 - acc: 0.9408 -- iter: 032/384
[A[ATraining Step: 98  | total loss: [1m[32m0.17859[0m[0m | time: 16.527s
[2K
| Adam | epoch: 009 | loss: 0.17859 - acc: 0.9342 -- iter: 064/384
[A[ATraining Step: 99  | total loss: [1m[32m0.16944[0m[0m | time: 24.801s
[2K
| Adam | epoch: 009 | loss: 0.16944 - acc: 0.9377 -- iter: 096/384
[A[ATraining Step: 100  | total loss: [1m[32m0.15645[0m[0m | time: 32.839s
[2K
| Adam | epoch: 009 | loss: 0.15645 - acc: 0.9439 -- iter: 128/384
[A[ATraining Step: 101  | total loss: [1m[32m0.15401[0m[0m | time: 41.126s
[2K
| Adam | epoch: 009 | loss: 0.15401 - acc: 0.9433 -- iter: 160/384
[A[ATraining Step: 102  | total loss: [1m[32m0.14427[0m[0m | time: 49.323s
[2K
| Adam | epoch: 009 | loss: 0.14427 - acc: 0.9489 -- iter: 192/384
[A[ATraining Step: 103  | total loss: [1m[32m0.14206[0m[0m | time: 57.623s
[2K
| Adam | epoch: 009 | loss: 0.14206 - acc: 0.9478 -- iter: 224/384
[A[ATraining Step: 104  | total loss: [1m[32m0.13494[0m[0m | time: 65.835s
[2K
| Adam | epoch: 009 | loss: 0.13494 - acc: 0.9499 -- iter: 256/384
[A[ATraining Step: 105  | total loss: [1m[32m0.12425[0m[0m | time: 74.121s
[2K
| Adam | epoch: 009 | loss: 0.12425 - acc: 0.9549 -- iter: 288/384
[A[ATraining Step: 106  | total loss: [1m[32m0.12832[0m[0m | time: 82.458s
[2K
| Adam | epoch: 009 | loss: 0.12832 - acc: 0.9500 -- iter: 320/384
[A[ATraining Step: 107  | total loss: [1m[32m0.13983[0m[0m | time: 90.760s
[2K
| Adam | epoch: 009 | loss: 0.13983 - acc: 0.9457 -- iter: 352/384
[A[ATraining Step: 108  | total loss: [1m[32m0.12828[0m[0m | time: 104.210s
[2K
| Adam | epoch: 009 | loss: 0.12828 - acc: 0.9511 | val_loss: 0.81820 - val_acc: 0.7686 -- iter: 384/384
--
Training Step: 109  | total loss: [1m[32m0.12275[0m[0m | time: 8.453s
[2K
| Adam | epoch: 010 | loss: 0.12275 - acc: 0.9529 -- iter: 032/384
[A[ATraining Step: 110  | total loss: [1m[32m0.12463[0m[0m | time: 16.756s
[2K
| Adam | epoch: 010 | loss: 0.12463 - acc: 0.9544 -- iter: 064/384
[A[ATraining Step: 111  | total loss: [1m[32m0.12210[0m[0m | time: 24.872s
[2K
| Adam | epoch: 010 | loss: 0.12210 - acc: 0.9528 -- iter: 096/384
[A[ATraining Step: 112  | total loss: [1m[32m0.11330[0m[0m | time: 33.126s
[2K
| Adam | epoch: 010 | loss: 0.11330 - acc: 0.9575 -- iter: 128/384
[A[ATraining Step: 113  | total loss: [1m[32m0.10447[0m[0m | time: 41.362s
[2K
| Adam | epoch: 010 | loss: 0.10447 - acc: 0.9617 -- iter: 160/384
[A[ATraining Step: 114  | total loss: [1m[32m0.09567[0m[0m | time: 49.489s
[2K
| Adam | epoch: 010 | loss: 0.09567 - acc: 0.9656 -- iter: 192/384
[A[ATraining Step: 115  | total loss: [1m[32m0.08723[0m[0m | time: 57.433s
[2K
| Adam | epoch: 010 | loss: 0.08723 - acc: 0.9690 -- iter: 224/384
[A[ATraining Step: 116  | total loss: [1m[32m0.10985[0m[0m | time: 65.683s
[2K
| Adam | epoch: 010 | loss: 0.10985 - acc: 0.9627 -- iter: 256/384
[A[ATraining Step: 117  | total loss: [1m[32m0.11415[0m[0m | time: 73.920s
[2K
| Adam | epoch: 010 | loss: 0.11415 - acc: 0.9602 -- iter: 288/384
[A[ATraining Step: 118  | total loss: [1m[32m0.10462[0m[0m | time: 82.109s
[2K
| Adam | epoch: 010 | loss: 0.10462 - acc: 0.9642 -- iter: 320/384
[A[ATraining Step: 119  | total loss: [1m[32m0.10091[0m[0m | time: 90.070s
[2K
| Adam | epoch: 010 | loss: 0.10091 - acc: 0.9646 -- iter: 352/384
[A[ATraining Step: 120  | total loss: [1m[32m0.09435[0m[0m | time: 103.781s
[2K
| Adam | epoch: 010 | loss: 0.09435 - acc: 0.9682 | val_loss: 0.74977 - val_acc: 0.8182 -- iter: 384/384
--
Training Step: 121  | total loss: [1m[32m0.08745[0m[0m | time: 8.303s
[2K
| Adam | epoch: 011 | loss: 0.08745 - acc: 0.9714 -- iter: 032/384
[A[ATraining Step: 122  | total loss: [1m[32m0.08553[0m[0m | time: 16.500s
[2K
| Adam | epoch: 011 | loss: 0.08553 - acc: 0.9711 -- iter: 064/384
[A[ATraining Step: 123  | total loss: [1m[32m0.07782[0m[0m | time: 24.879s
[2K
| Adam | epoch: 011 | loss: 0.07782 - acc: 0.9740 -- iter: 096/384
[A[ATraining Step: 124  | total loss: [1m[32m0.11633[0m[0m | time: 33.100s
[2K
| Adam | epoch: 011 | loss: 0.11633 - acc: 0.9703 -- iter: 128/384
[A[ATraining Step: 125  | total loss: [1m[32m0.10747[0m[0m | time: 41.400s
[2K
| Adam | epoch: 011 | loss: 0.10747 - acc: 0.9733 -- iter: 160/384
[A[ATraining Step: 126  | total loss: [1m[32m0.09869[0m[0m | time: 49.608s
[2K
| Adam | epoch: 011 | loss: 0.09869 - acc: 0.9760 -- iter: 192/384
[A[ATraining Step: 127  | total loss: [1m[32m0.09600[0m[0m | time: 57.897s
[2K
| Adam | epoch: 011 | loss: 0.09600 - acc: 0.9753 -- iter: 224/384
[A[ATraining Step: 128  | total loss: [1m[32m0.11033[0m[0m | time: 65.958s
[2K
| Adam | epoch: 011 | loss: 0.11033 - acc: 0.9652 -- iter: 256/384
[A[ATraining Step: 129  | total loss: [1m[32m0.11545[0m[0m | time: 74.366s
[2K
| Adam | epoch: 011 | loss: 0.11545 - acc: 0.9656 -- iter: 288/384
[A[ATraining Step: 130  | total loss: [1m[32m0.10776[0m[0m | time: 82.599s
[2K
| Adam | epoch: 011 | loss: 0.10776 - acc: 0.9659 -- iter: 320/384
[A[ATraining Step: 131  | total loss: [1m[32m0.10058[0m[0m | time: 92.173s
[2K
| Adam | epoch: 011 | loss: 0.10058 - acc: 0.9693 -- iter: 352/384
[A[ATraining Step: 132  | total loss: [1m[32m0.11989[0m[0m | time: 105.908s
[2K
| Adam | epoch: 011 | loss: 0.11989 - acc: 0.9630 | val_loss: 3.74873 - val_acc: 0.5785 -- iter: 384/384
--
Training Step: 133  | total loss: [1m[32m0.10918[0m[0m | time: 12.794s
[2K
| Adam | epoch: 012 | loss: 0.10918 - acc: 0.9667 -- iter: 032/384
[A[ATraining Step: 134  | total loss: [1m[32m0.11449[0m[0m | time: 21.155s
[2K
| Adam | epoch: 012 | loss: 0.11449 - acc: 0.9607 -- iter: 064/384
[A[ATraining Step: 135  | total loss: [1m[32m0.10697[0m[0m | time: 29.320s
[2K
| Adam | epoch: 012 | loss: 0.10697 - acc: 0.9646 -- iter: 096/384
[A[ATraining Step: 136  | total loss: [1m[32m0.09962[0m[0m | time: 37.487s
[2K
| Adam | epoch: 012 | loss: 0.09962 - acc: 0.9681 -- iter: 128/384
[A[ATraining Step: 137  | total loss: [1m[32m0.10728[0m[0m | time: 45.612s
[2K
| Adam | epoch: 012 | loss: 0.10728 - acc: 0.9682 -- iter: 160/384
[A[ATraining Step: 138  | total loss: [1m[32m0.11570[0m[0m | time: 53.857s
[2K
| Adam | epoch: 012 | loss: 0.11570 - acc: 0.9651 -- iter: 192/384
[A[ATraining Step: 139  | total loss: [1m[32m0.10675[0m[0m | time: 62.008s
[2K
| Adam | epoch: 012 | loss: 0.10675 - acc: 0.9686 -- iter: 224/384
[A[ATraining Step: 140  | total loss: [1m[32m0.09785[0m[0m | time: 70.073s
[2K
| Adam | epoch: 012 | loss: 0.09785 - acc: 0.9718 -- iter: 256/384
[A[ATraining Step: 141  | total loss: [1m[32m0.09611[0m[0m | time: 78.070s
[2K
| Adam | epoch: 012 | loss: 0.09611 - acc: 0.9746 -- iter: 288/384
[A[ATraining Step: 142  | total loss: [1m[32m0.09322[0m[0m | time: 86.197s
[2K
| Adam | epoch: 012 | loss: 0.09322 - acc: 0.9740 -- iter: 320/384
[A[ATraining Step: 143  | total loss: [1m[32m0.08709[0m[0m | time: 94.359s
[2K
| Adam | epoch: 012 | loss: 0.08709 - acc: 0.9735 -- iter: 352/384
[A[ATraining Step: 144  | total loss: [1m[32m0.07964[0m[0m | time: 107.966s
[2K
| Adam | epoch: 012 | loss: 0.07964 - acc: 0.9761 | val_loss: 0.98372 - val_acc: 0.7521 -- iter: 384/384
--
Training Step: 145  | total loss: [1m[32m0.07693[0m[0m | time: 8.190s
[2K
| Adam | epoch: 013 | loss: 0.07693 - acc: 0.9754 -- iter: 032/384
[A[ATraining Step: 146  | total loss: [1m[32m0.07729[0m[0m | time: 16.281s
[2K
| Adam | epoch: 013 | loss: 0.07729 - acc: 0.9747 -- iter: 064/384
[A[ATraining Step: 147  | total loss: [1m[32m0.07319[0m[0m | time: 24.743s
[2K
| Adam | epoch: 013 | loss: 0.07319 - acc: 0.9772 -- iter: 096/384
[A[ATraining Step: 148  | total loss: [1m[32m0.06640[0m[0m | time: 32.863s
[2K
| Adam | epoch: 013 | loss: 0.06640 - acc: 0.9795 -- iter: 128/384
[A[ATraining Step: 149  | total loss: [1m[32m0.07475[0m[0m | time: 40.957s
[2K
| Adam | epoch: 013 | loss: 0.07475 - acc: 0.9691 -- iter: 160/384
[A[ATraining Step: 150  | total loss: [1m[32m0.09158[0m[0m | time: 49.316s
[2K
| Adam | epoch: 013 | loss: 0.09158 - acc: 0.9690 -- iter: 192/384
[A[ATraining Step: 151  | total loss: [1m[32m0.09136[0m[0m | time: 57.605s
[2K
| Adam | epoch: 013 | loss: 0.09136 - acc: 0.9690 -- iter: 224/384
[A[ATraining Step: 152  | total loss: [1m[32m0.08317[0m[0m | time: 65.775s
[2K
| Adam | epoch: 013 | loss: 0.08317 - acc: 0.9721 -- iter: 256/384
[A[ATraining Step: 153  | total loss: [1m[32m0.08838[0m[0m | time: 74.030s
[2K
| Adam | epoch: 013 | loss: 0.08838 - acc: 0.9718 -- iter: 288/384
[A[ATraining Step: 154  | total loss: [1m[32m0.08033[0m[0m | time: 82.392s
[2K
| Adam | epoch: 013 | loss: 0.08033 - acc: 0.9746 -- iter: 320/384
[A[ATraining Step: 155  | total loss: [1m[32m0.07865[0m[0m | time: 90.911s
[2K
| Adam | epoch: 013 | loss: 0.07865 - acc: 0.9740 -- iter: 352/384
[A[ATraining Step: 156  | total loss: [1m[32m0.07785[0m[0m | time: 104.419s
[2K
| Adam | epoch: 013 | loss: 0.07785 - acc: 0.9704 | val_loss: 5.42918 - val_acc: 0.4380 -- iter: 384/384
--
Training Step: 157  | total loss: [1m[32m0.07072[0m[0m | time: 8.290s
[2K
| Adam | epoch: 014 | loss: 0.07072 - acc: 0.9733 -- iter: 032/384
[A[ATraining Step: 158  | total loss: [1m[32m0.08099[0m[0m | time: 16.501s
[2K
| Adam | epoch: 014 | loss: 0.08099 - acc: 0.9697 -- iter: 064/384
[A[ATraining Step: 159  | total loss: [1m[32m0.08017[0m[0m | time: 24.761s
[2K
| Adam | epoch: 014 | loss: 0.08017 - acc: 0.9696 -- iter: 096/384
[A[ATraining Step: 160  | total loss: [1m[32m0.07344[0m[0m | time: 33.109s
[2K
| Adam | epoch: 014 | loss: 0.07344 - acc: 0.9727 -- iter: 128/384
[A[ATraining Step: 161  | total loss: [1m[32m0.06891[0m[0m | time: 41.472s
[2K
| Adam | epoch: 014 | loss: 0.06891 - acc: 0.9723 -- iter: 160/384
[A[ATraining Step: 162  | total loss: [1m[32m0.07617[0m[0m | time: 49.785s
[2K
| Adam | epoch: 014 | loss: 0.07617 - acc: 0.9657 -- iter: 192/384
[A[ATraining Step: 163  | total loss: [1m[32m0.10474[0m[0m | time: 58.159s
[2K
| Adam | epoch: 014 | loss: 0.10474 - acc: 0.9629 -- iter: 224/384
[A[ATraining Step: 164  | total loss: [1m[32m0.09829[0m[0m | time: 66.470s
[2K
| Adam | epoch: 014 | loss: 0.09829 - acc: 0.9666 -- iter: 256/384
[A[ATraining Step: 165  | total loss: [1m[32m0.09782[0m[0m | time: 74.720s
[2K
| Adam | epoch: 014 | loss: 0.09782 - acc: 0.9637 -- iter: 288/384
[A[ATraining Step: 166  | total loss: [1m[32m0.10897[0m[0m | time: 83.116s
[2K
| Adam | epoch: 014 | loss: 0.10897 - acc: 0.9611 -- iter: 320/384
[A[ATraining Step: 167  | total loss: [1m[32m0.10166[0m[0m | time: 91.363s
[2K
| Adam | epoch: 014 | loss: 0.10166 - acc: 0.9649 -- iter: 352/384
[A[ATraining Step: 168  | total loss: [1m[32m0.09501[0m[0m | time: 104.790s
[2K
| Adam | epoch: 014 | loss: 0.09501 - acc: 0.9685 | val_loss: 0.88992 - val_acc: 0.7851 -- iter: 384/384
--
Training Step: 169  | total loss: [1m[32m0.08625[0m[0m | time: 8.206s
[2K
| Adam | epoch: 015 | loss: 0.08625 - acc: 0.9716 -- iter: 032/384
[A[ATraining Step: 170  | total loss: [1m[32m0.07862[0m[0m | time: 16.447s
[2K
| Adam | epoch: 015 | loss: 0.07862 - acc: 0.9744 -- iter: 064/384
[A[ATraining Step: 171  | total loss: [1m[32m0.08847[0m[0m | time: 24.720s
[2K
| Adam | epoch: 015 | loss: 0.08847 - acc: 0.9676 -- iter: 096/384
[A[ATraining Step: 172  | total loss: [1m[32m0.08467[0m[0m | time: 32.938s
[2K
| Adam | epoch: 015 | loss: 0.08467 - acc: 0.9709 -- iter: 128/384
[A[ATraining Step: 173  | total loss: [1m[32m0.08029[0m[0m | time: 41.029s
[2K
| Adam | epoch: 015 | loss: 0.08029 - acc: 0.9738 -- iter: 160/384
[A[ATraining Step: 174  | total loss: [1m[32m0.07722[0m[0m | time: 49.308s
[2K
| Adam | epoch: 015 | loss: 0.07722 - acc: 0.9764 -- iter: 192/384
[A[ATraining Step: 175  | total loss: [1m[32m0.07037[0m[0m | time: 57.583s
[2K
| Adam | epoch: 015 | loss: 0.07037 - acc: 0.9788 -- iter: 224/384
[A[ATraining Step: 176  | total loss: [1m[32m0.08147[0m[0m | time: 65.827s
[2K
| Adam | epoch: 015 | loss: 0.08147 - acc: 0.9778 -- iter: 256/384
[A[ATraining Step: 177  | total loss: [1m[32m0.07746[0m[0m | time: 74.083s
[2K
| Adam | epoch: 015 | loss: 0.07746 - acc: 0.9800 -- iter: 288/384
[A[ATraining Step: 178  | total loss: [1m[32m0.07901[0m[0m | time: 82.461s
[2K
| Adam | epoch: 015 | loss: 0.07901 - acc: 0.9757 -- iter: 320/384
[A[ATraining Step: 179  | total loss: [1m[32m0.07267[0m[0m | time: 90.497s
[2K
| Adam | epoch: 015 | loss: 0.07267 - acc: 0.9782 -- iter: 352/384
[A[ATraining Step: 180  | total loss: [1m[32m0.08608[0m[0m | time: 103.866s
[2K
| Adam | epoch: 015 | loss: 0.08608 - acc: 0.9741 | val_loss: 0.61840 - val_acc: 0.8512 -- iter: 384/384
--
Validation AUC:0.8977146042363434
Validation AUPRC:0.9112958407437202
Test AUC:0.9360881542699724
Test AUPRC:0.9248941606807832
BestTestF1Score	0.9	0.77	0.88	0.84	0.97	64	12	43	2	0.5
BestTestMCCScore	0.9	0.77	0.88	0.84	0.97	64	12	43	2	0.5
BestTestAccuracyScore	0.9	0.77	0.88	0.84	0.97	64	12	43	2	0.5
BestValidationF1Score	0.88	0.7	0.85	0.82	0.94	65	14	38	4	0.5
BestValidationMCC	0.88	0.7	0.85	0.82	0.94	65	14	38	4	0.5
BestValidationAccuracy	0.88	0.7	0.85	0.82	0.94	65	14	38	4	0.5
TestPredictions (Threshold:0.5)
CHEMBL1672290,TP,ACT,0.8799999952316284	CHEMBL611036,TN,INACT,0.029999999329447746	CHEMBL2440632,TP,ACT,1.0	CHEMBL392420,TN,INACT,0.0	CHEMBL3660244,TP,ACT,0.9900000095367432	CHEMBL2440619,TP,ACT,0.9900000095367432	CHEMBL2440692,TN,INACT,0.009999999776482582	CHEMBL1738726,FP,INACT,0.9100000262260437	CHEMBL3314816,TP,ACT,0.9800000190734863	CHEMBL3403145,TP,ACT,1.0	CHEMBL1258854,TP,ACT,0.9599999785423279	CHEMBL35111,TN,INACT,0.0	CHEMBL2440603,TP,ACT,1.0	CHEMBL2408581,FP,INACT,0.9900000095367432	CHEMBL3642985,TP,ACT,1.0	CHEMBL2440618,TP,ACT,1.0	CHEMBL2431184,TP,ACT,0.9200000166893005	CHEMBL3401178,TP,ACT,1.0	CHEMBL3633656,TN,INACT,0.4399999976158142	CHEMBL1257473,TP,ACT,1.0	CHEMBL302402,FP,INACT,0.7900000214576721	CHEMBL3645571,TP,ACT,0.9800000190734863	CHEMBL211801,FN,ACT,0.4000000059604645	CHEMBL379515,TP,ACT,1.0	CHEMBL63927,FP,INACT,0.6800000071525574	CHEMBL3337660,TN,INACT,0.019999999552965164	CHEMBL3597603,TP,ACT,0.9599999785423279	CHEMBL3765437,TP,ACT,1.0	CHEMBL2385880,FP,INACT,1.0	CHEMBL2431154,TP,ACT,1.0	CHEMBL422505,TN,INACT,0.0	CHEMBL1257593,TP,ACT,0.9900000095367432	CHEMBL2440637,TP,ACT,0.9900000095367432	CHEMBL299291,TN,INACT,0.0	CHEMBL334842,TN,INACT,0.0	CHEMBL1258740,TP,ACT,1.0	CHEMBL1779883,FP,INACT,1.0	CHEMBL58027,TN,INACT,0.0	CHEMBL2440661,TP,ACT,1.0	CHEMBL3403100,TP,ACT,1.0	CHEMBL303415,FP,INACT,0.6299999952316284	CHEMBL2089183,TP,ACT,0.9100000262260437	CHEMBL1784601,TP,ACT,1.0	CHEMBL398724,TN,INACT,0.03999999910593033	CHEMBL154535,TN,INACT,0.0	CHEMBL2426077,TN,INACT,0.0	CHEMBL181696,TP,ACT,1.0	CHEMBL3298284,TP,ACT,1.0	CHEMBL3403093,TP,ACT,1.0	CHEMBL2426089,TN,INACT,0.009999999776482582	CHEMBL3310763,TP,ACT,1.0	CHEMBL2111523,TN,INACT,0.0	CHEMBL1209403,TP,ACT,0.9900000095367432	CHEMBL227853,TP,ACT,0.9700000286102295	CHEMBL2115152,TN,INACT,0.019999999552965164	CHEMBL2426066,TN,INACT,0.0	CHEMBL50041,TN,INACT,0.15000000596046448	CHEMBL112451,TN,INACT,0.0	CHEMBL3401204,TP,ACT,1.0	CHEMBL3403137,TP,ACT,0.9700000286102295	CHEMBL42148,FP,INACT,0.5099999904632568	CHEMBL1209203,TP,ACT,0.9900000095367432	CHEMBL231986,TP,ACT,0.7400000095367432	CHEMBL1258738,TP,ACT,1.0	CHEMBL114027,TN,INACT,0.0	CHEMBL1258736,TP,ACT,1.0	CHEMBL3694789,TP,ACT,0.9800000190734863	CHEMBL3633650,FP,INACT,0.9300000071525574	CHEMBL3643012,TP,ACT,0.9900000095367432	CHEMBL198310,TN,INACT,0.0	CHEMBL1779856,FP,INACT,0.949999988079071	CHEMBL372809,TP,ACT,0.9900000095367432	CHEMBL2440633,TP,ACT,1.0	CHEMBL360990,TP,ACT,0.5699999928474426	CHEMBL231157,TN,INACT,0.0	CHEMBL59299,TN,INACT,0.14000000059604645	CHEMBL2151790,TP,ACT,0.9900000095367432	CHEMBL3617649,TP,ACT,1.0	CHEMBL154678,TN,INACT,0.0	CHEMBL2408169,TP,ACT,1.0	CHEMBL186703,TP,ACT,1.0	CHEMBL377935,TP,ACT,0.6899999976158142	CHEMBL208927,TP,ACT,0.9900000095367432	CHEMBL3643052,TP,ACT,0.7300000190734863	CHEMBL40157,TN,INACT,0.0	CHEMBL522507,TP,ACT,0.75	CHEMBL324694,TN,INACT,0.0	CHEMBL2426097,TN,INACT,0.009999999776482582	CHEMBL112213,TN,INACT,0.0	CHEMBL113571,TN,INACT,0.0	CHEMBL3786026,TN,INACT,0.0	CHEMBL2426102,TN,INACT,0.36000001430511475	CHEMBL480169,TN,INACT,0.0	CHEMBL2151808,TP,ACT,1.0	CHEMBL3633655,FP,INACT,0.9700000286102295	CHEMBL2426076,TN,INACT,0.0	CHEMBL3403122,TP,ACT,1.0	CHEMBL1672279,TP,ACT,0.9900000095367432	CHEMBL69869,FP,INACT,1.0	CHEMBL2426094,TN,INACT,0.009999999776482582	CHEMBL3643028,TP,ACT,0.9900000095367432	CHEMBL297283,TN,INACT,0.0	CHEMBL2151817,TP,ACT,0.9900000095367432	CHEMBL1258511,TP,ACT,0.9900000095367432	CHEMBL2208405,FN,ACT,0.23999999463558197	CHEMBL1209400,TP,ACT,0.9900000095367432	CHEMBL323713,TN,INACT,0.0	CHEMBL2426098,TN,INACT,0.009999999776482582	CHEMBL178058,TN,INACT,0.05000000074505806	CHEMBL2426099,TN,INACT,0.019999999552965164	CHEMBL368858,TN,INACT,0.0	CHEMBL3660239,TP,ACT,1.0	CHEMBL493570,TP,ACT,0.9900000095367432	CHEMBL2408565,TP,ACT,0.75	CHEMBL610939,TN,INACT,0.0	CHEMBL3314854,TP,ACT,1.0	CHEMBL3642987,TP,ACT,0.9599999785423279	CHEMBL3422873,TN,INACT,0.4300000071525574	CHEMBL3617644,TP,ACT,1.0	CHEMBL421402,TN,INACT,0.0	CHEMBL2208415,TP,ACT,0.9700000286102295	

