CNNModel CHEMBL2265 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	235
Number of inactive compounds :	235
---------------------------------
Run id: CNNModel_CHEMBL2265_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2265_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 291
Validation samples: 91
--
Training Step: 1  | time: 0.812s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/291
[A[ATraining Step: 2  | total loss: [1m[32m0.62387[0m[0m | time: 1.415s
[2K
| Adam | epoch: 001 | loss: 0.62387 - acc: 0.3937 -- iter: 064/291
[A[ATraining Step: 3  | total loss: [1m[32m0.68057[0m[0m | time: 2.037s
[2K
| Adam | epoch: 001 | loss: 0.68057 - acc: 0.4551 -- iter: 096/291
[A[ATraining Step: 4  | total loss: [1m[32m0.69027[0m[0m | time: 2.640s
[2K
| Adam | epoch: 001 | loss: 0.69027 - acc: 0.4888 -- iter: 128/291
[A[ATraining Step: 5  | total loss: [1m[32m0.69193[0m[0m | time: 3.244s
[2K
| Adam | epoch: 001 | loss: 0.69193 - acc: 0.5182 -- iter: 160/291
[A[ATraining Step: 6  | total loss: [1m[32m0.69454[0m[0m | time: 3.842s
[2K
| Adam | epoch: 001 | loss: 0.69454 - acc: 0.4663 -- iter: 192/291
[A[ATraining Step: 7  | total loss: [1m[32m0.69458[0m[0m | time: 4.459s
[2K
| Adam | epoch: 001 | loss: 0.69458 - acc: 0.4678 -- iter: 224/291
[A[ATraining Step: 8  | total loss: [1m[32m0.69447[0m[0m | time: 5.091s
[2K
| Adam | epoch: 001 | loss: 0.69447 - acc: 0.4507 -- iter: 256/291
[A[ATraining Step: 9  | total loss: [1m[32m0.69384[0m[0m | time: 5.694s
[2K
| Adam | epoch: 001 | loss: 0.69384 - acc: 0.4437 -- iter: 288/291
[A[ATraining Step: 10  | total loss: [1m[32m0.69330[0m[0m | time: 6.809s
[2K
| Adam | epoch: 001 | loss: 0.69330 - acc: 0.4875 | val_loss: 0.69208 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 11  | total loss: [1m[32m0.69226[0m[0m | time: 0.102s
[2K
| Adam | epoch: 002 | loss: 0.69226 - acc: 0.5724 -- iter: 032/291
[A[ATraining Step: 12  | total loss: [1m[32m0.69089[0m[0m | time: 0.712s
[2K
| Adam | epoch: 002 | loss: 0.69089 - acc: 0.6148 -- iter: 064/291
[A[ATraining Step: 13  | total loss: [1m[32m0.69045[0m[0m | time: 1.331s
[2K
| Adam | epoch: 002 | loss: 0.69045 - acc: 0.6058 -- iter: 096/291
[A[ATraining Step: 14  | total loss: [1m[32m0.69354[0m[0m | time: 1.955s
[2K
| Adam | epoch: 002 | loss: 0.69354 - acc: 0.5369 -- iter: 128/291
[A[ATraining Step: 15  | total loss: [1m[32m0.69178[0m[0m | time: 2.574s
[2K
| Adam | epoch: 002 | loss: 0.69178 - acc: 0.5469 -- iter: 160/291
[A[ATraining Step: 16  | total loss: [1m[32m0.69025[0m[0m | time: 3.185s
[2K
| Adam | epoch: 002 | loss: 0.69025 - acc: 0.5528 -- iter: 192/291
[A[ATraining Step: 17  | total loss: [1m[32m0.68573[0m[0m | time: 3.819s
[2K
| Adam | epoch: 002 | loss: 0.68573 - acc: 0.5788 -- iter: 224/291
[A[ATraining Step: 18  | total loss: [1m[32m0.69554[0m[0m | time: 4.451s
[2K
| Adam | epoch: 002 | loss: 0.69554 - acc: 0.5299 -- iter: 256/291
[A[ATraining Step: 19  | total loss: [1m[32m0.70780[0m[0m | time: 5.045s
[2K
| Adam | epoch: 002 | loss: 0.70780 - acc: 0.4678 -- iter: 288/291
[A[ATraining Step: 20  | total loss: [1m[32m0.70427[0m[0m | time: 6.656s
[2K
| Adam | epoch: 002 | loss: 0.70427 - acc: 0.4782 | val_loss: 0.68991 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 21  | total loss: [1m[32m0.70010[0m[0m | time: 0.097s
[2K
| Adam | epoch: 003 | loss: 0.70010 - acc: 0.4946 -- iter: 032/291
[A[ATraining Step: 22  | total loss: [1m[32m0.69371[0m[0m | time: 0.195s
[2K
| Adam | epoch: 003 | loss: 0.69371 - acc: 0.5463 -- iter: 064/291
[A[ATraining Step: 23  | total loss: [1m[32m0.68993[0m[0m | time: 0.822s
[2K
| Adam | epoch: 003 | loss: 0.68993 - acc: 0.5812 -- iter: 096/291
[A[ATraining Step: 24  | total loss: [1m[32m0.69493[0m[0m | time: 1.430s
[2K
| Adam | epoch: 003 | loss: 0.69493 - acc: 0.5056 -- iter: 128/291
[A[ATraining Step: 25  | total loss: [1m[32m0.69283[0m[0m | time: 2.064s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5297 -- iter: 160/291
[A[ATraining Step: 26  | total loss: [1m[32m0.69055[0m[0m | time: 2.674s
[2K
| Adam | epoch: 003 | loss: 0.69055 - acc: 0.5632 -- iter: 192/291
[A[ATraining Step: 27  | total loss: [1m[32m0.69135[0m[0m | time: 3.286s
[2K
| Adam | epoch: 003 | loss: 0.69135 - acc: 0.5469 -- iter: 224/291
[A[ATraining Step: 28  | total loss: [1m[32m0.69098[0m[0m | time: 3.893s
[2K
| Adam | epoch: 003 | loss: 0.69098 - acc: 0.5508 -- iter: 256/291
[A[ATraining Step: 29  | total loss: [1m[32m0.69242[0m[0m | time: 4.496s
[2K
| Adam | epoch: 003 | loss: 0.69242 - acc: 0.5233 -- iter: 288/291
[A[ATraining Step: 30  | total loss: [1m[32m0.69360[0m[0m | time: 6.109s
[2K
| Adam | epoch: 003 | loss: 0.69360 - acc: 0.5029 | val_loss: 0.69086 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 31  | total loss: [1m[32m0.69248[0m[0m | time: 0.643s
[2K
| Adam | epoch: 004 | loss: 0.69248 - acc: 0.5239 -- iter: 032/291
[A[ATraining Step: 32  | total loss: [1m[32m0.69267[0m[0m | time: 0.731s
[2K
| Adam | epoch: 004 | loss: 0.69267 - acc: 0.5185 -- iter: 064/291
[A[ATraining Step: 33  | total loss: [1m[32m0.69112[0m[0m | time: 0.817s
[2K
| Adam | epoch: 004 | loss: 0.69112 - acc: 0.5510 -- iter: 096/291
[A[ATraining Step: 34  | total loss: [1m[32m0.68604[0m[0m | time: 1.425s
[2K
| Adam | epoch: 004 | loss: 0.68604 - acc: 0.6472 -- iter: 128/291
[A[ATraining Step: 35  | total loss: [1m[32m0.68473[0m[0m | time: 2.052s
[2K
| Adam | epoch: 004 | loss: 0.68473 - acc: 0.6622 -- iter: 160/291
[A[ATraining Step: 36  | total loss: [1m[32m0.68653[0m[0m | time: 2.666s
[2K
| Adam | epoch: 004 | loss: 0.68653 - acc: 0.6290 -- iter: 192/291
[A[ATraining Step: 37  | total loss: [1m[32m0.68702[0m[0m | time: 3.269s
[2K
| Adam | epoch: 004 | loss: 0.68702 - acc: 0.6157 -- iter: 224/291
[A[ATraining Step: 38  | total loss: [1m[32m0.68656[0m[0m | time: 3.877s
[2K
| Adam | epoch: 004 | loss: 0.68656 - acc: 0.6114 -- iter: 256/291
[A[ATraining Step: 39  | total loss: [1m[32m0.68463[0m[0m | time: 4.483s
[2K
| Adam | epoch: 004 | loss: 0.68463 - acc: 0.6200 -- iter: 288/291
[A[ATraining Step: 40  | total loss: [1m[32m0.68584[0m[0m | time: 6.105s
[2K
| Adam | epoch: 004 | loss: 0.68584 - acc: 0.6034 | val_loss: 0.68835 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 41  | total loss: [1m[32m0.68890[0m[0m | time: 0.615s
[2K
| Adam | epoch: 005 | loss: 0.68890 - acc: 0.5786 -- iter: 032/291
[A[ATraining Step: 42  | total loss: [1m[32m0.69760[0m[0m | time: 1.211s
[2K
| Adam | epoch: 005 | loss: 0.69760 - acc: 0.5251 -- iter: 064/291
[A[ATraining Step: 43  | total loss: [1m[32m0.70473[0m[0m | time: 1.301s
[2K
| Adam | epoch: 005 | loss: 0.70473 - acc: 0.4766 -- iter: 096/291
[A[ATraining Step: 44  | total loss: [1m[32m0.69130[0m[0m | time: 1.383s
[2K
| Adam | epoch: 005 | loss: 0.69130 - acc: 0.5672 -- iter: 128/291
[A[ATraining Step: 45  | total loss: [1m[32m0.68868[0m[0m | time: 2.008s
[2K
| Adam | epoch: 005 | loss: 0.68868 - acc: 0.5841 -- iter: 160/291
[A[ATraining Step: 46  | total loss: [1m[32m0.68907[0m[0m | time: 2.606s
[2K
| Adam | epoch: 005 | loss: 0.68907 - acc: 0.5753 -- iter: 192/291
[A[ATraining Step: 47  | total loss: [1m[32m0.68813[0m[0m | time: 3.207s
[2K
| Adam | epoch: 005 | loss: 0.68813 - acc: 0.5783 -- iter: 224/291
[A[ATraining Step: 48  | total loss: [1m[32m0.69008[0m[0m | time: 3.814s
[2K
| Adam | epoch: 005 | loss: 0.69008 - acc: 0.5607 -- iter: 256/291
[A[ATraining Step: 49  | total loss: [1m[32m0.69319[0m[0m | time: 4.425s
[2K
| Adam | epoch: 005 | loss: 0.69319 - acc: 0.5363 -- iter: 288/291
[A[ATraining Step: 50  | total loss: [1m[32m0.69652[0m[0m | time: 6.052s
[2K
| Adam | epoch: 005 | loss: 0.69652 - acc: 0.5113 | val_loss: 0.68882 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 51  | total loss: [1m[32m0.69515[0m[0m | time: 0.619s
[2K
| Adam | epoch: 006 | loss: 0.69515 - acc: 0.5191 -- iter: 032/291
[A[ATraining Step: 52  | total loss: [1m[32m0.69507[0m[0m | time: 1.217s
[2K
| Adam | epoch: 006 | loss: 0.69507 - acc: 0.5162 -- iter: 064/291
[A[ATraining Step: 53  | total loss: [1m[32m0.69551[0m[0m | time: 1.804s
[2K
| Adam | epoch: 006 | loss: 0.69551 - acc: 0.5092 -- iter: 096/291
[A[ATraining Step: 54  | total loss: [1m[32m0.69241[0m[0m | time: 1.890s
[2K
| Adam | epoch: 006 | loss: 0.69241 - acc: 0.5351 -- iter: 128/291
[A[ATraining Step: 55  | total loss: [1m[32m0.69017[0m[0m | time: 1.972s
[2K
| Adam | epoch: 006 | loss: 0.69017 - acc: 0.5539 -- iter: 160/291
[A[ATraining Step: 56  | total loss: [1m[32m0.68832[0m[0m | time: 2.564s
[2K
| Adam | epoch: 006 | loss: 0.68832 - acc: 0.5698 -- iter: 192/291
[A[ATraining Step: 57  | total loss: [1m[32m0.68920[0m[0m | time: 3.180s
[2K
| Adam | epoch: 006 | loss: 0.68920 - acc: 0.5601 -- iter: 224/291
[A[ATraining Step: 58  | total loss: [1m[32m0.68988[0m[0m | time: 3.779s
[2K
| Adam | epoch: 006 | loss: 0.68988 - acc: 0.5519 -- iter: 256/291
[A[ATraining Step: 59  | total loss: [1m[32m0.69157[0m[0m | time: 4.393s
[2K
| Adam | epoch: 006 | loss: 0.69157 - acc: 0.5365 -- iter: 288/291
[A[ATraining Step: 60  | total loss: [1m[32m0.69234[0m[0m | time: 5.997s
[2K
| Adam | epoch: 006 | loss: 0.69234 - acc: 0.5276 | val_loss: 0.68890 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 61  | total loss: [1m[32m0.69026[0m[0m | time: 0.605s
[2K
| Adam | epoch: 007 | loss: 0.69026 - acc: 0.5443 -- iter: 032/291
[A[ATraining Step: 62  | total loss: [1m[32m0.68995[0m[0m | time: 1.202s
[2K
| Adam | epoch: 007 | loss: 0.68995 - acc: 0.5467 -- iter: 064/291
[A[ATraining Step: 63  | total loss: [1m[32m0.68902[0m[0m | time: 1.813s
[2K
| Adam | epoch: 007 | loss: 0.68902 - acc: 0.5526 -- iter: 096/291
[A[ATraining Step: 64  | total loss: [1m[32m0.68842[0m[0m | time: 2.424s
[2K
| Adam | epoch: 007 | loss: 0.68842 - acc: 0.5578 -- iter: 128/291
[A[ATraining Step: 65  | total loss: [1m[32m0.69271[0m[0m | time: 2.508s
[2K
| Adam | epoch: 007 | loss: 0.69271 - acc: 0.5237 -- iter: 160/291
[A[ATraining Step: 66  | total loss: [1m[32m0.69052[0m[0m | time: 2.594s
[2K
| Adam | epoch: 007 | loss: 0.69052 - acc: 0.5411 -- iter: 192/291
[A[ATraining Step: 67  | total loss: [1m[32m0.68849[0m[0m | time: 3.198s
[2K
| Adam | epoch: 007 | loss: 0.68849 - acc: 0.5562 -- iter: 224/291
[A[ATraining Step: 68  | total loss: [1m[32m0.69119[0m[0m | time: 3.800s
[2K
| Adam | epoch: 007 | loss: 0.69119 - acc: 0.5347 -- iter: 256/291
[A[ATraining Step: 69  | total loss: [1m[32m0.69110[0m[0m | time: 4.397s
[2K
| Adam | epoch: 007 | loss: 0.69110 - acc: 0.5343 -- iter: 288/291
[A[ATraining Step: 70  | total loss: [1m[32m0.69147[0m[0m | time: 6.001s
[2K
| Adam | epoch: 007 | loss: 0.69147 - acc: 0.5303 | val_loss: 0.68853 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 71  | total loss: [1m[32m0.69231[0m[0m | time: 0.624s
[2K
| Adam | epoch: 008 | loss: 0.69231 - acc: 0.5233 -- iter: 032/291
[A[ATraining Step: 72  | total loss: [1m[32m0.68983[0m[0m | time: 1.238s
[2K
| Adam | epoch: 008 | loss: 0.68983 - acc: 0.5418 -- iter: 064/291
[A[ATraining Step: 73  | total loss: [1m[32m0.69131[0m[0m | time: 1.840s
[2K
| Adam | epoch: 008 | loss: 0.69131 - acc: 0.5302 -- iter: 096/291
[A[ATraining Step: 74  | total loss: [1m[32m0.69123[0m[0m | time: 2.433s
[2K
| Adam | epoch: 008 | loss: 0.69123 - acc: 0.5303 -- iter: 128/291
[A[ATraining Step: 75  | total loss: [1m[32m0.69335[0m[0m | time: 3.039s
[2K
| Adam | epoch: 008 | loss: 0.69335 - acc: 0.5135 -- iter: 160/291
[A[ATraining Step: 76  | total loss: [1m[32m0.69106[0m[0m | time: 3.124s
[2K
| Adam | epoch: 008 | loss: 0.69106 - acc: 0.5321 -- iter: 192/291
[A[ATraining Step: 77  | total loss: [1m[32m0.68922[0m[0m | time: 3.212s
[2K
| Adam | epoch: 008 | loss: 0.68922 - acc: 0.5464 -- iter: 224/291
[A[ATraining Step: 78  | total loss: [1m[32m0.68325[0m[0m | time: 3.807s
[2K
| Adam | epoch: 008 | loss: 0.68325 - acc: 0.5938 -- iter: 256/291
[A[ATraining Step: 79  | total loss: [1m[32m0.68540[0m[0m | time: 4.391s
[2K
| Adam | epoch: 008 | loss: 0.68540 - acc: 0.5777 -- iter: 288/291
[A[ATraining Step: 80  | total loss: [1m[32m0.68637[0m[0m | time: 5.998s
[2K
| Adam | epoch: 008 | loss: 0.68637 - acc: 0.5697 | val_loss: 0.68775 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 81  | total loss: [1m[32m0.68567[0m[0m | time: 0.609s
[2K
| Adam | epoch: 009 | loss: 0.68567 - acc: 0.5722 -- iter: 032/291
[A[ATraining Step: 82  | total loss: [1m[32m0.68676[0m[0m | time: 1.219s
[2K
| Adam | epoch: 009 | loss: 0.68676 - acc: 0.5649 -- iter: 064/291
[A[ATraining Step: 83  | total loss: [1m[32m0.68829[0m[0m | time: 1.829s
[2K
| Adam | epoch: 009 | loss: 0.68829 - acc: 0.5553 -- iter: 096/291
[A[ATraining Step: 84  | total loss: [1m[32m0.68936[0m[0m | time: 2.456s
[2K
| Adam | epoch: 009 | loss: 0.68936 - acc: 0.5498 -- iter: 128/291
[A[ATraining Step: 85  | total loss: [1m[32m0.68890[0m[0m | time: 3.083s
[2K
| Adam | epoch: 009 | loss: 0.68890 - acc: 0.5511 -- iter: 160/291
[A[ATraining Step: 86  | total loss: [1m[32m0.69166[0m[0m | time: 3.685s
[2K
| Adam | epoch: 009 | loss: 0.69166 - acc: 0.5366 -- iter: 192/291
[A[ATraining Step: 87  | total loss: [1m[32m0.69028[0m[0m | time: 3.770s
[2K
| Adam | epoch: 009 | loss: 0.69028 - acc: 0.5423 -- iter: 224/291
[A[ATraining Step: 88  | total loss: [1m[32m0.68138[0m[0m | time: 3.853s
[2K
| Adam | epoch: 009 | loss: 0.68138 - acc: 0.5881 -- iter: 256/291
[A[ATraining Step: 89  | total loss: [1m[32m0.68652[0m[0m | time: 4.457s
[2K
| Adam | epoch: 009 | loss: 0.68652 - acc: 0.5626 -- iter: 288/291
[A[ATraining Step: 90  | total loss: [1m[32m0.68767[0m[0m | time: 6.063s
[2K
| Adam | epoch: 009 | loss: 0.68767 - acc: 0.5563 | val_loss: 0.68743 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 91  | total loss: [1m[32m0.68736[0m[0m | time: 0.605s
[2K
| Adam | epoch: 010 | loss: 0.68736 - acc: 0.5570 -- iter: 032/291
[A[ATraining Step: 92  | total loss: [1m[32m0.69009[0m[0m | time: 1.217s
[2K
| Adam | epoch: 010 | loss: 0.69009 - acc: 0.5450 -- iter: 064/291
[A[ATraining Step: 93  | total loss: [1m[32m0.68948[0m[0m | time: 1.854s
[2K
| Adam | epoch: 010 | loss: 0.68948 - acc: 0.5468 -- iter: 096/291
[A[ATraining Step: 94  | total loss: [1m[32m0.69022[0m[0m | time: 2.463s
[2K
| Adam | epoch: 010 | loss: 0.69022 - acc: 0.5421 -- iter: 128/291
[A[ATraining Step: 95  | total loss: [1m[32m0.69352[0m[0m | time: 3.065s
[2K
| Adam | epoch: 010 | loss: 0.69352 - acc: 0.5254 -- iter: 160/291
[A[ATraining Step: 96  | total loss: [1m[32m0.69376[0m[0m | time: 3.673s
[2K
| Adam | epoch: 010 | loss: 0.69376 - acc: 0.5228 -- iter: 192/291
[A[ATraining Step: 97  | total loss: [1m[32m0.69334[0m[0m | time: 4.274s
[2K
| Adam | epoch: 010 | loss: 0.69334 - acc: 0.5237 -- iter: 224/291
[A[ATraining Step: 98  | total loss: [1m[32m0.69118[0m[0m | time: 4.370s
[2K
| Adam | epoch: 010 | loss: 0.69118 - acc: 0.5369 -- iter: 256/291
[A[ATraining Step: 99  | total loss: [1m[32m0.69382[0m[0m | time: 4.454s
[2K
| Adam | epoch: 010 | loss: 0.69382 - acc: 0.5166 -- iter: 288/291
[A[ATraining Step: 100  | total loss: [1m[32m0.69208[0m[0m | time: 6.051s
[2K
| Adam | epoch: 010 | loss: 0.69208 - acc: 0.5316 | val_loss: 0.68816 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 101  | total loss: [1m[32m0.69324[0m[0m | time: 0.621s
[2K
| Adam | epoch: 011 | loss: 0.69324 - acc: 0.5190 -- iter: 032/291
[A[ATraining Step: 102  | total loss: [1m[32m0.69196[0m[0m | time: 1.217s
[2K
| Adam | epoch: 011 | loss: 0.69196 - acc: 0.5296 -- iter: 064/291
[A[ATraining Step: 103  | total loss: [1m[32m0.69233[0m[0m | time: 1.816s
[2K
| Adam | epoch: 011 | loss: 0.69233 - acc: 0.5236 -- iter: 096/291
[A[ATraining Step: 104  | total loss: [1m[32m0.69177[0m[0m | time: 2.439s
[2K
| Adam | epoch: 011 | loss: 0.69177 - acc: 0.5274 -- iter: 128/291
[A[ATraining Step: 105  | total loss: [1m[32m0.69170[0m[0m | time: 3.054s
[2K
| Adam | epoch: 011 | loss: 0.69170 - acc: 0.5247 -- iter: 160/291
[A[ATraining Step: 106  | total loss: [1m[32m0.69114[0m[0m | time: 3.661s
[2K
| Adam | epoch: 011 | loss: 0.69114 - acc: 0.5285 -- iter: 192/291
[A[ATraining Step: 107  | total loss: [1m[32m0.69019[0m[0m | time: 4.295s
[2K
| Adam | epoch: 011 | loss: 0.69019 - acc: 0.5381 -- iter: 224/291
[A[ATraining Step: 108  | total loss: [1m[32m0.69027[0m[0m | time: 4.915s
[2K
| Adam | epoch: 011 | loss: 0.69027 - acc: 0.5343 -- iter: 256/291
[A[ATraining Step: 109  | total loss: [1m[32m0.69168[0m[0m | time: 5.000s
[2K
| Adam | epoch: 011 | loss: 0.69168 - acc: 0.5153 -- iter: 288/291
[A[ATraining Step: 110  | total loss: [1m[32m0.69065[0m[0m | time: 6.088s
[2K
| Adam | epoch: 011 | loss: 0.69065 - acc: 0.5304 | val_loss: 0.68712 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 111  | total loss: [1m[32m0.68998[0m[0m | time: 0.600s
[2K
| Adam | epoch: 012 | loss: 0.68998 - acc: 0.5440 -- iter: 032/291
[A[ATraining Step: 112  | total loss: [1m[32m0.68909[0m[0m | time: 1.205s
[2K
| Adam | epoch: 012 | loss: 0.68909 - acc: 0.5521 -- iter: 064/291
[A[ATraining Step: 113  | total loss: [1m[32m0.68787[0m[0m | time: 1.816s
[2K
| Adam | epoch: 012 | loss: 0.68787 - acc: 0.5625 -- iter: 096/291
[A[ATraining Step: 114  | total loss: [1m[32m0.68783[0m[0m | time: 2.434s
[2K
| Adam | epoch: 012 | loss: 0.68783 - acc: 0.5594 -- iter: 128/291
[A[ATraining Step: 115  | total loss: [1m[32m0.68757[0m[0m | time: 3.060s
[2K
| Adam | epoch: 012 | loss: 0.68757 - acc: 0.5597 -- iter: 160/291
[A[ATraining Step: 116  | total loss: [1m[32m0.68875[0m[0m | time: 3.664s
[2K
| Adam | epoch: 012 | loss: 0.68875 - acc: 0.5475 -- iter: 192/291
[A[ATraining Step: 117  | total loss: [1m[32m0.69039[0m[0m | time: 4.264s
[2K
| Adam | epoch: 012 | loss: 0.69039 - acc: 0.5334 -- iter: 224/291
[A[ATraining Step: 118  | total loss: [1m[32m0.69163[0m[0m | time: 4.873s
[2K
| Adam | epoch: 012 | loss: 0.69163 - acc: 0.5207 -- iter: 256/291
[A[ATraining Step: 119  | total loss: [1m[32m0.69231[0m[0m | time: 5.478s
[2K
| Adam | epoch: 012 | loss: 0.69231 - acc: 0.5123 -- iter: 288/291
[A[ATraining Step: 120  | total loss: [1m[32m0.69163[0m[0m | time: 6.569s
[2K
| Adam | epoch: 012 | loss: 0.69163 - acc: 0.5142 | val_loss: 0.68533 - val_acc: 0.5495 -- iter: 291/291
--
Training Step: 121  | total loss: [1m[32m0.69006[0m[0m | time: 0.096s
[2K
| Adam | epoch: 013 | loss: 0.69006 - acc: 0.5295 -- iter: 032/291
[A[ATraining Step: 122  | total loss: [1m[32m0.68874[0m[0m | time: 0.706s
[2K
| Adam | epoch: 013 | loss: 0.68874 - acc: 0.5432 -- iter: 064/291
[A[ATraining Step: 123  | total loss: [1m[32m0.68843[0m[0m | time: 1.344s
[2K
| Adam | epoch: 013 | loss: 0.68843 - acc: 0.5420 -- iter: 096/291
[A[ATraining Step: 124  | total loss: [1m[32m0.68862[0m[0m | time: 1.952s
[2K
| Adam | epoch: 013 | loss: 0.68862 - acc: 0.5347 -- iter: 128/291
[A[ATraining Step: 125  | total loss: [1m[32m0.68888[0m[0m | time: 2.573s
[2K
| Adam | epoch: 013 | loss: 0.68888 - acc: 0.5281 -- iter: 160/291
[A[ATraining Step: 126  | total loss: [1m[32m0.68712[0m[0m | time: 3.181s
[2K
| Adam | epoch: 013 | loss: 0.68712 - acc: 0.5409 -- iter: 192/291
[A[ATraining Step: 127  | total loss: [1m[32m0.68701[0m[0m | time: 3.793s
[2K
| Adam | epoch: 013 | loss: 0.68701 - acc: 0.5368 -- iter: 224/291
[A[ATraining Step: 128  | total loss: [1m[32m0.68623[0m[0m | time: 4.389s
[2K
| Adam | epoch: 013 | loss: 0.68623 - acc: 0.5331 -- iter: 256/291
[A[ATraining Step: 129  | total loss: [1m[32m0.68682[0m[0m | time: 4.995s
[2K
| Adam | epoch: 013 | loss: 0.68682 - acc: 0.5267 -- iter: 288/291
[A[ATraining Step: 130  | total loss: [1m[32m0.68555[0m[0m | time: 6.611s
[2K
| Adam | epoch: 013 | loss: 0.68555 - acc: 0.5365 | val_loss: 0.67540 - val_acc: 0.6813 -- iter: 291/291
--
Training Step: 131  | total loss: [1m[32m0.68433[0m[0m | time: 0.096s
[2K
| Adam | epoch: 014 | loss: 0.68433 - acc: 0.5579 -- iter: 032/291
[A[ATraining Step: 132  | total loss: [1m[32m0.68185[0m[0m | time: 0.190s
[2K
| Adam | epoch: 014 | loss: 0.68185 - acc: 0.6021 -- iter: 064/291
[A[ATraining Step: 133  | total loss: [1m[32m0.67145[0m[0m | time: 0.789s
[2K
| Adam | epoch: 014 | loss: 0.67145 - acc: 0.6419 -- iter: 096/291
[A[ATraining Step: 134  | total loss: [1m[32m0.67387[0m[0m | time: 1.390s
[2K
| Adam | epoch: 014 | loss: 0.67387 - acc: 0.6246 -- iter: 128/291
[A[ATraining Step: 135  | total loss: [1m[32m0.67449[0m[0m | time: 2.016s
[2K
| Adam | epoch: 014 | loss: 0.67449 - acc: 0.6152 -- iter: 160/291
[A[ATraining Step: 136  | total loss: [1m[32m0.67854[0m[0m | time: 2.625s
[2K
| Adam | epoch: 014 | loss: 0.67854 - acc: 0.6037 -- iter: 192/291
[A[ATraining Step: 137  | total loss: [1m[32m0.68103[0m[0m | time: 3.226s
[2K
| Adam | epoch: 014 | loss: 0.68103 - acc: 0.5933 -- iter: 224/291
[A[ATraining Step: 138  | total loss: [1m[32m0.68878[0m[0m | time: 3.822s
[2K
| Adam | epoch: 014 | loss: 0.68878 - acc: 0.5715 -- iter: 256/291
[A[ATraining Step: 139  | total loss: [1m[32m0.68946[0m[0m | time: 4.416s
[2K
| Adam | epoch: 014 | loss: 0.68946 - acc: 0.5612 -- iter: 288/291
[A[ATraining Step: 140  | total loss: [1m[32m0.68687[0m[0m | time: 6.041s
[2K
| Adam | epoch: 014 | loss: 0.68687 - acc: 0.5645 | val_loss: 0.67769 - val_acc: 0.6593 -- iter: 291/291
--
Training Step: 141  | total loss: [1m[32m0.68600[0m[0m | time: 0.607s
[2K
| Adam | epoch: 015 | loss: 0.68600 - acc: 0.5612 -- iter: 032/291
[A[ATraining Step: 142  | total loss: [1m[32m0.68497[0m[0m | time: 0.705s
[2K
| Adam | epoch: 015 | loss: 0.68497 - acc: 0.5769 -- iter: 064/291
[A[ATraining Step: 143  | total loss: [1m[32m0.68143[0m[0m | time: 0.788s
[2K
| Adam | epoch: 015 | loss: 0.68143 - acc: 0.5859 -- iter: 096/291
[A[ATraining Step: 144  | total loss: [1m[32m0.68199[0m[0m | time: 1.404s
[2K
| Adam | epoch: 015 | loss: 0.68199 - acc: 0.5606 -- iter: 128/291
[A[ATraining Step: 145  | total loss: [1m[32m0.68109[0m[0m | time: 2.004s
[2K
| Adam | epoch: 015 | loss: 0.68109 - acc: 0.5671 -- iter: 160/291
[A[ATraining Step: 146  | total loss: [1m[32m0.68053[0m[0m | time: 2.618s
[2K
| Adam | epoch: 015 | loss: 0.68053 - acc: 0.5697 -- iter: 192/291
[A[ATraining Step: 147  | total loss: [1m[32m0.67665[0m[0m | time: 3.216s
[2K
| Adam | epoch: 015 | loss: 0.67665 - acc: 0.5784 -- iter: 224/291
[A[ATraining Step: 148  | total loss: [1m[32m0.67369[0m[0m | time: 3.819s
[2K
| Adam | epoch: 015 | loss: 0.67369 - acc: 0.5831 -- iter: 256/291
[A[ATraining Step: 149  | total loss: [1m[32m0.67274[0m[0m | time: 4.442s
[2K
| Adam | epoch: 015 | loss: 0.67274 - acc: 0.5841 -- iter: 288/291
[A[ATraining Step: 150  | total loss: [1m[32m0.66906[0m[0m | time: 6.042s
[2K
| Adam | epoch: 015 | loss: 0.66906 - acc: 0.6007 | val_loss: 0.64982 - val_acc: 0.6923 -- iter: 291/291
--
Training Step: 151  | total loss: [1m[32m0.66927[0m[0m | time: 0.617s
[2K
| Adam | epoch: 016 | loss: 0.66927 - acc: 0.5938 -- iter: 032/291
[A[ATraining Step: 152  | total loss: [1m[32m0.66552[0m[0m | time: 1.242s
[2K
| Adam | epoch: 016 | loss: 0.66552 - acc: 0.6125 -- iter: 064/291
[A[ATraining Step: 153  | total loss: [1m[32m0.66182[0m[0m | time: 1.325s
[2K
| Adam | epoch: 016 | loss: 0.66182 - acc: 0.6200 -- iter: 096/291
[A[ATraining Step: 154  | total loss: [1m[32m0.65073[0m[0m | time: 1.412s
[2K
| Adam | epoch: 016 | loss: 0.65073 - acc: 0.6580 -- iter: 128/291
[A[ATraining Step: 155  | total loss: [1m[32m0.64175[0m[0m | time: 2.026s
[2K
| Adam | epoch: 016 | loss: 0.64175 - acc: 0.6589 -- iter: 160/291
[A[ATraining Step: 156  | total loss: [1m[32m0.64500[0m[0m | time: 2.649s
[2K
| Adam | epoch: 016 | loss: 0.64500 - acc: 0.6461 -- iter: 192/291
[A[ATraining Step: 157  | total loss: [1m[32m0.64823[0m[0m | time: 3.251s
[2K
| Adam | epoch: 016 | loss: 0.64823 - acc: 0.6503 -- iter: 224/291
[A[ATraining Step: 158  | total loss: [1m[32m0.64150[0m[0m | time: 3.855s
[2K
| Adam | epoch: 016 | loss: 0.64150 - acc: 0.6540 -- iter: 256/291
[A[ATraining Step: 159  | total loss: [1m[32m0.62903[0m[0m | time: 4.457s
[2K
| Adam | epoch: 016 | loss: 0.62903 - acc: 0.6605 -- iter: 288/291
[A[ATraining Step: 160  | total loss: [1m[32m0.62884[0m[0m | time: 6.086s
[2K
| Adam | epoch: 016 | loss: 0.62884 - acc: 0.6569 | val_loss: 0.57429 - val_acc: 0.7033 -- iter: 291/291
--
Training Step: 161  | total loss: [1m[32m0.61201[0m[0m | time: 0.634s
[2K
| Adam | epoch: 017 | loss: 0.61201 - acc: 0.6787 -- iter: 032/291
[A[ATraining Step: 162  | total loss: [1m[32m0.60250[0m[0m | time: 1.258s
[2K
| Adam | epoch: 017 | loss: 0.60250 - acc: 0.6858 -- iter: 064/291
[A[ATraining Step: 163  | total loss: [1m[32m0.58850[0m[0m | time: 1.866s
[2K
| Adam | epoch: 017 | loss: 0.58850 - acc: 0.6923 -- iter: 096/291
[A[ATraining Step: 164  | total loss: [1m[32m0.57658[0m[0m | time: 1.953s
[2K
| Adam | epoch: 017 | loss: 0.57658 - acc: 0.7012 -- iter: 128/291
[A[ATraining Step: 165  | total loss: [1m[32m0.53899[0m[0m | time: 2.037s
[2K
| Adam | epoch: 017 | loss: 0.53899 - acc: 0.7310 -- iter: 160/291
[A[ATraining Step: 166  | total loss: [1m[32m0.67233[0m[0m | time: 2.633s
[2K
| Adam | epoch: 017 | loss: 0.67233 - acc: 0.6913 -- iter: 192/291
[A[ATraining Step: 167  | total loss: [1m[32m0.68606[0m[0m | time: 3.242s
[2K
| Adam | epoch: 017 | loss: 0.68606 - acc: 0.6753 -- iter: 224/291
[A[ATraining Step: 168  | total loss: [1m[32m0.66295[0m[0m | time: 3.841s
[2K
| Adam | epoch: 017 | loss: 0.66295 - acc: 0.6890 -- iter: 256/291
[A[ATraining Step: 169  | total loss: [1m[32m0.63033[0m[0m | time: 4.459s
[2K
| Adam | epoch: 017 | loss: 0.63033 - acc: 0.7076 -- iter: 288/291
[A[ATraining Step: 170  | total loss: [1m[32m0.62076[0m[0m | time: 6.054s
[2K
| Adam | epoch: 017 | loss: 0.62076 - acc: 0.7118 | val_loss: 0.53347 - val_acc: 0.7253 -- iter: 291/291
--
Training Step: 171  | total loss: [1m[32m0.60764[0m[0m | time: 0.624s
[2K
| Adam | epoch: 018 | loss: 0.60764 - acc: 0.7157 -- iter: 032/291
[A[ATraining Step: 172  | total loss: [1m[32m0.59511[0m[0m | time: 1.237s
[2K
| Adam | epoch: 018 | loss: 0.59511 - acc: 0.7191 -- iter: 064/291
[A[ATraining Step: 173  | total loss: [1m[32m0.58615[0m[0m | time: 1.868s
[2K
| Adam | epoch: 018 | loss: 0.58615 - acc: 0.7222 -- iter: 096/291
[A[ATraining Step: 174  | total loss: [1m[32m0.57535[0m[0m | time: 2.477s
[2K
| Adam | epoch: 018 | loss: 0.57535 - acc: 0.7343 -- iter: 128/291
[A[ATraining Step: 175  | total loss: [1m[32m0.56233[0m[0m | time: 2.565s
[2K
| Adam | epoch: 018 | loss: 0.56233 - acc: 0.7390 -- iter: 160/291
[A[ATraining Step: 176  | total loss: [1m[32m0.56676[0m[0m | time: 2.669s
[2K
| Adam | epoch: 018 | loss: 0.56676 - acc: 0.7318 -- iter: 192/291
[A[ATraining Step: 177  | total loss: [1m[32m0.53618[0m[0m | time: 3.273s
[2K
| Adam | epoch: 018 | loss: 0.53618 - acc: 0.7586 -- iter: 224/291
[A[ATraining Step: 178  | total loss: [1m[32m0.53170[0m[0m | time: 3.890s
[2K
| Adam | epoch: 018 | loss: 0.53170 - acc: 0.7578 -- iter: 256/291
[A[ATraining Step: 179  | total loss: [1m[32m0.51587[0m[0m | time: 4.491s
[2K
| Adam | epoch: 018 | loss: 0.51587 - acc: 0.7695 -- iter: 288/291
[A[ATraining Step: 180  | total loss: [1m[32m0.49656[0m[0m | time: 6.093s
[2K
| Adam | epoch: 018 | loss: 0.49656 - acc: 0.7832 | val_loss: 0.57127 - val_acc: 0.6813 -- iter: 291/291
--
Training Step: 181  | total loss: [1m[32m0.48294[0m[0m | time: 0.643s
[2K
| Adam | epoch: 019 | loss: 0.48294 - acc: 0.7923 -- iter: 032/291
[A[ATraining Step: 182  | total loss: [1m[32m0.47226[0m[0m | time: 1.254s
[2K
| Adam | epoch: 019 | loss: 0.47226 - acc: 0.7912 -- iter: 064/291
[A[ATraining Step: 183  | total loss: [1m[32m0.48056[0m[0m | time: 1.855s
[2K
| Adam | epoch: 019 | loss: 0.48056 - acc: 0.7871 -- iter: 096/291
[A[ATraining Step: 184  | total loss: [1m[32m0.46689[0m[0m | time: 2.466s
[2K
| Adam | epoch: 019 | loss: 0.46689 - acc: 0.7928 -- iter: 128/291
[A[ATraining Step: 185  | total loss: [1m[32m0.45620[0m[0m | time: 3.068s
[2K
| Adam | epoch: 019 | loss: 0.45620 - acc: 0.7979 -- iter: 160/291
[A[ATraining Step: 186  | total loss: [1m[32m0.46528[0m[0m | time: 3.164s
[2K
| Adam | epoch: 019 | loss: 0.46528 - acc: 0.7900 -- iter: 192/291
[A[ATraining Step: 187  | total loss: [1m[32m0.43639[0m[0m | time: 3.249s
[2K
| Adam | epoch: 019 | loss: 0.43639 - acc: 0.8110 -- iter: 224/291
[A[ATraining Step: 188  | total loss: [1m[32m0.40700[0m[0m | time: 3.858s
[2K
| Adam | epoch: 019 | loss: 0.40700 - acc: 0.8299 -- iter: 256/291
[A[ATraining Step: 189  | total loss: [1m[32m0.40320[0m[0m | time: 4.459s
[2K
| Adam | epoch: 019 | loss: 0.40320 - acc: 0.8375 -- iter: 288/291
[A[ATraining Step: 190  | total loss: [1m[32m0.39066[0m[0m | time: 6.064s
[2K
| Adam | epoch: 019 | loss: 0.39066 - acc: 0.8444 | val_loss: 0.50904 - val_acc: 0.7692 -- iter: 291/291
--
Training Step: 191  | total loss: [1m[32m0.39201[0m[0m | time: 0.644s
[2K
| Adam | epoch: 020 | loss: 0.39201 - acc: 0.8381 -- iter: 032/291
[A[ATraining Step: 192  | total loss: [1m[32m0.38003[0m[0m | time: 1.252s
[2K
| Adam | epoch: 020 | loss: 0.38003 - acc: 0.8480 -- iter: 064/291
[A[ATraining Step: 193  | total loss: [1m[32m0.38092[0m[0m | time: 1.889s
[2K
| Adam | epoch: 020 | loss: 0.38092 - acc: 0.8476 -- iter: 096/291
[A[ATraining Step: 194  | total loss: [1m[32m0.37774[0m[0m | time: 2.504s
[2K
| Adam | epoch: 020 | loss: 0.37774 - acc: 0.8441 -- iter: 128/291
[A[ATraining Step: 195  | total loss: [1m[32m0.38128[0m[0m | time: 3.103s
[2K
| Adam | epoch: 020 | loss: 0.38128 - acc: 0.8440 -- iter: 160/291
[A[ATraining Step: 196  | total loss: [1m[32m0.35923[0m[0m | time: 3.702s
[2K
| Adam | epoch: 020 | loss: 0.35923 - acc: 0.8565 -- iter: 192/291
[A[ATraining Step: 197  | total loss: [1m[32m0.34331[0m[0m | time: 3.789s
[2K
| Adam | epoch: 020 | loss: 0.34331 - acc: 0.8646 -- iter: 224/291
[A[ATraining Step: 198  | total loss: [1m[32m0.36739[0m[0m | time: 3.876s
[2K
| Adam | epoch: 020 | loss: 0.36739 - acc: 0.8448 -- iter: 256/291
[A[ATraining Step: 199  | total loss: [1m[32m0.44211[0m[0m | time: 4.491s
[2K
| Adam | epoch: 020 | loss: 0.44211 - acc: 0.7937 -- iter: 288/291
[A[ATraining Step: 200  | total loss: [1m[32m0.43107[0m[0m | time: 6.089s
[2K
| Adam | epoch: 020 | loss: 0.43107 - acc: 0.7956 | val_loss: 0.52815 - val_acc: 0.7692 -- iter: 291/291
--
Training Step: 201  | total loss: [1m[32m0.41795[0m[0m | time: 0.617s
[2K
| Adam | epoch: 021 | loss: 0.41795 - acc: 0.8066 -- iter: 032/291
[A[ATraining Step: 202  | total loss: [1m[32m0.38803[0m[0m | time: 1.234s
[2K
| Adam | epoch: 021 | loss: 0.38803 - acc: 0.8228 -- iter: 064/291
[A[ATraining Step: 203  | total loss: [1m[32m0.37301[0m[0m | time: 1.845s
[2K
| Adam | epoch: 021 | loss: 0.37301 - acc: 0.8343 -- iter: 096/291
[A[ATraining Step: 204  | total loss: [1m[32m0.36806[0m[0m | time: 2.484s
[2K
| Adam | epoch: 021 | loss: 0.36806 - acc: 0.8384 -- iter: 128/291
[A[ATraining Step: 205  | total loss: [1m[32m0.36969[0m[0m | time: 3.103s
[2K
| Adam | epoch: 021 | loss: 0.36969 - acc: 0.8389 -- iter: 160/291
[A[ATraining Step: 206  | total loss: [1m[32m0.36274[0m[0m | time: 3.719s
[2K
| Adam | epoch: 021 | loss: 0.36274 - acc: 0.8394 -- iter: 192/291
[A[ATraining Step: 207  | total loss: [1m[32m0.36761[0m[0m | time: 4.312s
[2K
| Adam | epoch: 021 | loss: 0.36761 - acc: 0.8367 -- iter: 224/291
[A[ATraining Step: 208  | total loss: [1m[32m0.38425[0m[0m | time: 4.398s
[2K
| Adam | epoch: 021 | loss: 0.38425 - acc: 0.8280 -- iter: 256/291
[A[ATraining Step: 209  | total loss: [1m[32m0.35897[0m[0m | time: 4.483s
[2K
| Adam | epoch: 021 | loss: 0.35897 - acc: 0.8452 -- iter: 288/291
[A[ATraining Step: 210  | total loss: [1m[32m0.32771[0m[0m | time: 6.084s
[2K
| Adam | epoch: 021 | loss: 0.32771 - acc: 0.8607 | val_loss: 1.03561 - val_acc: 0.6264 -- iter: 291/291
--
Training Step: 211  | total loss: [1m[32m0.37874[0m[0m | time: 0.616s
[2K
| Adam | epoch: 022 | loss: 0.37874 - acc: 0.8309 -- iter: 032/291
[A[ATraining Step: 212  | total loss: [1m[32m0.41193[0m[0m | time: 1.225s
[2K
| Adam | epoch: 022 | loss: 0.41193 - acc: 0.8134 -- iter: 064/291
[A[ATraining Step: 213  | total loss: [1m[32m0.39639[0m[0m | time: 1.833s
[2K
| Adam | epoch: 022 | loss: 0.39639 - acc: 0.8196 -- iter: 096/291
[A[ATraining Step: 214  | total loss: [1m[32m0.38159[0m[0m | time: 2.453s
[2K
| Adam | epoch: 022 | loss: 0.38159 - acc: 0.8314 -- iter: 128/291
[A[ATraining Step: 215  | total loss: [1m[32m0.38646[0m[0m | time: 3.080s
[2K
| Adam | epoch: 022 | loss: 0.38646 - acc: 0.8295 -- iter: 160/291
[A[ATraining Step: 216  | total loss: [1m[32m0.39830[0m[0m | time: 3.679s
[2K
| Adam | epoch: 022 | loss: 0.39830 - acc: 0.8215 -- iter: 192/291
[A[ATraining Step: 217  | total loss: [1m[32m0.38811[0m[0m | time: 4.281s
[2K
| Adam | epoch: 022 | loss: 0.38811 - acc: 0.8269 -- iter: 224/291
[A[ATraining Step: 218  | total loss: [1m[32m0.38996[0m[0m | time: 4.890s
[2K
| Adam | epoch: 022 | loss: 0.38996 - acc: 0.8254 -- iter: 256/291
[A[ATraining Step: 219  | total loss: [1m[32m0.38895[0m[0m | time: 4.974s
[2K
| Adam | epoch: 022 | loss: 0.38895 - acc: 0.8210 -- iter: 288/291
[A[ATraining Step: 220  | total loss: [1m[32m0.37089[0m[0m | time: 6.063s
[2K
| Adam | epoch: 022 | loss: 0.37089 - acc: 0.8389 | val_loss: 0.84118 - val_acc: 0.6484 -- iter: 291/291
--
Training Step: 221  | total loss: [1m[32m0.37710[0m[0m | time: 0.863s
[2K
| Adam | epoch: 023 | loss: 0.37710 - acc: 0.8217 -- iter: 032/291
[A[ATraining Step: 222  | total loss: [1m[32m0.39642[0m[0m | time: 1.805s
[2K
| Adam | epoch: 023 | loss: 0.39642 - acc: 0.7958 -- iter: 064/291
[A[ATraining Step: 223  | total loss: [1m[32m0.42786[0m[0m | time: 2.754s
[2K
| Adam | epoch: 023 | loss: 0.42786 - acc: 0.7818 -- iter: 096/291
[A[ATraining Step: 224  | total loss: [1m[32m0.44471[0m[0m | time: 3.715s
[2K
| Adam | epoch: 023 | loss: 0.44471 - acc: 0.7786 -- iter: 128/291
[A[ATraining Step: 225  | total loss: [1m[32m0.44101[0m[0m | time: 4.770s
[2K
| Adam | epoch: 023 | loss: 0.44101 - acc: 0.7820 -- iter: 160/291
[A[ATraining Step: 226  | total loss: [1m[32m0.41795[0m[0m | time: 5.859s
[2K
| Adam | epoch: 023 | loss: 0.41795 - acc: 0.7945 -- iter: 192/291
[A[ATraining Step: 227  | total loss: [1m[32m0.38725[0m[0m | time: 6.756s
[2K
| Adam | epoch: 023 | loss: 0.38725 - acc: 0.8119 -- iter: 224/291
[A[ATraining Step: 228  | total loss: [1m[32m0.38251[0m[0m | time: 7.361s
[2K
| Adam | epoch: 023 | loss: 0.38251 - acc: 0.8151 -- iter: 256/291
[A[ATraining Step: 229  | total loss: [1m[32m0.37914[0m[0m | time: 8.075s
[2K
| Adam | epoch: 023 | loss: 0.37914 - acc: 0.8148 -- iter: 288/291
[A[ATraining Step: 230  | total loss: [1m[32m0.36983[0m[0m | time: 9.247s
[2K
| Adam | epoch: 023 | loss: 0.36983 - acc: 0.8240 | val_loss: 0.46576 - val_acc: 0.7363 -- iter: 291/291
--
Training Step: 231  | total loss: [1m[32m0.36155[0m[0m | time: 0.173s
[2K
| Adam | epoch: 024 | loss: 0.36155 - acc: 0.8082 -- iter: 032/291
[A[ATraining Step: 232  | total loss: [1m[32m0.38509[0m[0m | time: 1.387s
[2K
| Adam | epoch: 024 | loss: 0.38509 - acc: 0.7941 -- iter: 064/291
[A[ATraining Step: 233  | total loss: [1m[32m0.39125[0m[0m | time: 2.316s
[2K
| Adam | epoch: 024 | loss: 0.39125 - acc: 0.7928 -- iter: 096/291
[A[ATraining Step: 234  | total loss: [1m[32m0.37950[0m[0m | time: 3.272s
[2K
| Adam | epoch: 024 | loss: 0.37950 - acc: 0.8010 -- iter: 128/291
[A[ATraining Step: 235  | total loss: [1m[32m0.35526[0m[0m | time: 4.344s
[2K
| Adam | epoch: 024 | loss: 0.35526 - acc: 0.8209 -- iter: 160/291
[A[ATraining Step: 236  | total loss: [1m[32m0.33961[0m[0m | time: 5.413s
[2K
| Adam | epoch: 024 | loss: 0.33961 - acc: 0.8326 -- iter: 192/291
[A[ATraining Step: 237  | total loss: [1m[32m0.31507[0m[0m | time: 6.331s
[2K
| Adam | epoch: 024 | loss: 0.31507 - acc: 0.8493 -- iter: 224/291
[A[ATraining Step: 238  | total loss: [1m[32m0.30400[0m[0m | time: 7.274s
[2K
| Adam | epoch: 024 | loss: 0.30400 - acc: 0.8581 -- iter: 256/291
[A[ATraining Step: 239  | total loss: [1m[32m0.30441[0m[0m | time: 8.262s
[2K
| Adam | epoch: 024 | loss: 0.30441 - acc: 0.8629 -- iter: 288/291
[A[ATraining Step: 240  | total loss: [1m[32m0.28895[0m[0m | time: 10.247s
[2K
| Adam | epoch: 024 | loss: 0.28895 - acc: 0.8704 | val_loss: 0.47960 - val_acc: 0.7912 -- iter: 291/291
--
Training Step: 241  | total loss: [1m[32m0.28145[0m[0m | time: 0.154s
[2K
| Adam | epoch: 025 | loss: 0.28145 - acc: 0.8740 -- iter: 032/291
[A[ATraining Step: 242  | total loss: [1m[32m0.26289[0m[0m | time: 0.309s
[2K
| Adam | epoch: 025 | loss: 0.26289 - acc: 0.8866 -- iter: 064/291
[A[ATraining Step: 243  | total loss: [1m[32m0.31867[0m[0m | time: 1.316s
[2K
| Adam | epoch: 025 | loss: 0.31867 - acc: 0.8646 -- iter: 096/291
[A[ATraining Step: 244  | total loss: [1m[32m0.30772[0m[0m | time: 2.474s
[2K
| Adam | epoch: 025 | loss: 0.30772 - acc: 0.8656 -- iter: 128/291
[A[ATraining Step: 245  | total loss: [1m[32m0.29376[0m[0m | time: 3.372s
[2K
| Adam | epoch: 025 | loss: 0.29376 - acc: 0.8697 -- iter: 160/291
[A[ATraining Step: 246  | total loss: [1m[32m0.27131[0m[0m | time: 4.297s
[2K
| Adam | epoch: 025 | loss: 0.27131 - acc: 0.8827 -- iter: 192/291
[A[ATraining Step: 247  | total loss: [1m[32m0.25265[0m[0m | time: 5.465s
[2K
| Adam | epoch: 025 | loss: 0.25265 - acc: 0.8913 -- iter: 224/291
[A[ATraining Step: 248  | total loss: [1m[32m0.23937[0m[0m | time: 6.500s
[2K
| Adam | epoch: 025 | loss: 0.23937 - acc: 0.8959 -- iter: 256/291
[A[ATraining Step: 249  | total loss: [1m[32m0.23664[0m[0m | time: 7.512s
[2K
| Adam | epoch: 025 | loss: 0.23664 - acc: 0.9001 -- iter: 288/291
[A[ATraining Step: 250  | total loss: [1m[32m0.22875[0m[0m | time: 9.399s
[2K
| Adam | epoch: 025 | loss: 0.22875 - acc: 0.9070 | val_loss: 0.48939 - val_acc: 0.7912 -- iter: 291/291
--
Training Step: 251  | total loss: [1m[32m0.22344[0m[0m | time: 1.136s
[2K
| Adam | epoch: 026 | loss: 0.22344 - acc: 0.9069 -- iter: 032/291
[A[ATraining Step: 252  | total loss: [1m[32m0.21927[0m[0m | time: 1.290s
[2K
| Adam | epoch: 026 | loss: 0.21927 - acc: 0.9100 -- iter: 064/291
[A[ATraining Step: 253  | total loss: [1m[32m0.19999[0m[0m | time: 1.443s
[2K
| Adam | epoch: 026 | loss: 0.19999 - acc: 0.9190 -- iter: 096/291
[A[ATraining Step: 254  | total loss: [1m[32m0.18097[0m[0m | time: 2.499s
[2K
| Adam | epoch: 026 | loss: 0.18097 - acc: 0.9271 -- iter: 128/291
[A[ATraining Step: 255  | total loss: [1m[32m0.17554[0m[0m | time: 3.528s
[2K
| Adam | epoch: 026 | loss: 0.17554 - acc: 0.9281 -- iter: 160/291
[A[ATraining Step: 256  | total loss: [1m[32m0.16888[0m[0m | time: 4.417s
[2K
| Adam | epoch: 026 | loss: 0.16888 - acc: 0.9322 -- iter: 192/291
[A[ATraining Step: 257  | total loss: [1m[32m0.16676[0m[0m | time: 5.364s
[2K
| Adam | epoch: 026 | loss: 0.16676 - acc: 0.9327 -- iter: 224/291
[A[ATraining Step: 258  | total loss: [1m[32m0.15304[0m[0m | time: 6.295s
[2K
| Adam | epoch: 026 | loss: 0.15304 - acc: 0.9394 -- iter: 256/291
[A[ATraining Step: 259  | total loss: [1m[32m0.14648[0m[0m | time: 7.313s
[2K
| Adam | epoch: 026 | loss: 0.14648 - acc: 0.9424 -- iter: 288/291
[A[ATraining Step: 260  | total loss: [1m[32m0.14335[0m[0m | time: 9.396s
[2K
| Adam | epoch: 026 | loss: 0.14335 - acc: 0.9450 | val_loss: 0.55543 - val_acc: 0.8132 -- iter: 291/291
--
Training Step: 261  | total loss: [1m[32m0.13919[0m[0m | time: 1.145s
[2K
| Adam | epoch: 027 | loss: 0.13919 - acc: 0.9474 -- iter: 032/291
[A[ATraining Step: 262  | total loss: [1m[32m0.13389[0m[0m | time: 2.292s
[2K
| Adam | epoch: 027 | loss: 0.13389 - acc: 0.9495 -- iter: 064/291
[A[ATraining Step: 263  | total loss: [1m[32m0.13359[0m[0m | time: 2.440s
[2K
| Adam | epoch: 027 | loss: 0.13359 - acc: 0.9483 -- iter: 096/291
[A[ATraining Step: 264  | total loss: [1m[32m0.12123[0m[0m | time: 2.610s
[2K
| Adam | epoch: 027 | loss: 0.12123 - acc: 0.9535 -- iter: 128/291
[A[ATraining Step: 265  | total loss: [1m[32m0.32724[0m[0m | time: 3.825s
[2K
| Adam | epoch: 027 | loss: 0.32724 - acc: 0.9248 -- iter: 160/291
[A[ATraining Step: 266  | total loss: [1m[32m0.33491[0m[0m | time: 4.974s
[2K
| Adam | epoch: 027 | loss: 0.33491 - acc: 0.9136 -- iter: 192/291
[A[ATraining Step: 267  | total loss: [1m[32m0.31000[0m[0m | time: 6.005s
[2K
| Adam | epoch: 027 | loss: 0.31000 - acc: 0.9222 -- iter: 224/291
[A[ATraining Step: 268  | total loss: [1m[32m0.28800[0m[0m | time: 6.999s
[2K
| Adam | epoch: 027 | loss: 0.28800 - acc: 0.9269 -- iter: 256/291
[A[ATraining Step: 269  | total loss: [1m[32m0.27003[0m[0m | time: 8.079s
[2K
| Adam | epoch: 027 | loss: 0.27003 - acc: 0.9279 -- iter: 288/291
[A[ATraining Step: 270  | total loss: [1m[32m0.24928[0m[0m | time: 10.002s
[2K
| Adam | epoch: 027 | loss: 0.24928 - acc: 0.9351 | val_loss: 0.81334 - val_acc: 0.7253 -- iter: 291/291
--
Training Step: 271  | total loss: [1m[32m0.22964[0m[0m | time: 0.760s
[2K
| Adam | epoch: 028 | loss: 0.22964 - acc: 0.9416 -- iter: 032/291
[A[ATraining Step: 272  | total loss: [1m[32m0.22969[0m[0m | time: 1.473s
[2K
| Adam | epoch: 028 | loss: 0.22969 - acc: 0.9381 -- iter: 064/291
[A[ATraining Step: 273  | total loss: [1m[32m0.23091[0m[0m | time: 2.224s
[2K
| Adam | epoch: 028 | loss: 0.23091 - acc: 0.9349 -- iter: 096/291
[A[ATraining Step: 274  | total loss: [1m[32m0.22128[0m[0m | time: 2.318s
[2K
| Adam | epoch: 028 | loss: 0.22128 - acc: 0.9383 -- iter: 128/291
[A[ATraining Step: 275  | total loss: [1m[32m0.20000[0m[0m | time: 2.414s
[2K
| Adam | epoch: 028 | loss: 0.20000 - acc: 0.9445 -- iter: 160/291
[A[ATraining Step: 276  | total loss: [1m[32m0.18136[0m[0m | time: 3.139s
[2K
| Adam | epoch: 028 | loss: 0.18136 - acc: 0.9500 -- iter: 192/291
[A[ATraining Step: 277  | total loss: [1m[32m0.16898[0m[0m | time: 3.879s
[2K
| Adam | epoch: 028 | loss: 0.16898 - acc: 0.9519 -- iter: 224/291
[A[ATraining Step: 278  | total loss: [1m[32m0.16531[0m[0m | time: 4.597s
[2K
| Adam | epoch: 028 | loss: 0.16531 - acc: 0.9536 -- iter: 256/291
[A[ATraining Step: 279  | total loss: [1m[32m0.16075[0m[0m | time: 5.329s
[2K
| Adam | epoch: 028 | loss: 0.16075 - acc: 0.9582 -- iter: 288/291
[A[ATraining Step: 280  | total loss: [1m[32m0.16409[0m[0m | time: 7.118s
[2K
| Adam | epoch: 028 | loss: 0.16409 - acc: 0.9499 | val_loss: 0.57281 - val_acc: 0.7912 -- iter: 291/291
--
Training Step: 281  | total loss: [1m[32m0.15753[0m[0m | time: 0.981s
[2K
| Adam | epoch: 029 | loss: 0.15753 - acc: 0.9518 -- iter: 032/291
[A[ATraining Step: 282  | total loss: [1m[32m0.14721[0m[0m | time: 1.796s
[2K
| Adam | epoch: 029 | loss: 0.14721 - acc: 0.9566 -- iter: 064/291
[A[ATraining Step: 283  | total loss: [1m[32m0.14329[0m[0m | time: 2.560s
[2K
| Adam | epoch: 029 | loss: 0.14329 - acc: 0.9578 -- iter: 096/291
[A[ATraining Step: 284  | total loss: [1m[32m0.14307[0m[0m | time: 3.271s
[2K
| Adam | epoch: 029 | loss: 0.14307 - acc: 0.9589 -- iter: 128/291
[A[ATraining Step: 285  | total loss: [1m[32m0.15107[0m[0m | time: 3.449s
[2K
| Adam | epoch: 029 | loss: 0.15107 - acc: 0.9568 -- iter: 160/291
[A[ATraining Step: 286  | total loss: [1m[32m0.26015[0m[0m | time: 3.552s
[2K
| Adam | epoch: 029 | loss: 0.26015 - acc: 0.9278 -- iter: 192/291
[A[ATraining Step: 287  | total loss: [1m[32m0.41978[0m[0m | time: 4.283s
[2K
| Adam | epoch: 029 | loss: 0.41978 - acc: 0.8683 -- iter: 224/291
[A[ATraining Step: 288  | total loss: [1m[32m0.38231[0m[0m | time: 5.022s
[2K
| Adam | epoch: 029 | loss: 0.38231 - acc: 0.8815 -- iter: 256/291
[A[ATraining Step: 289  | total loss: [1m[32m0.35724[0m[0m | time: 5.748s
[2K
| Adam | epoch: 029 | loss: 0.35724 - acc: 0.8902 -- iter: 288/291
[A[ATraining Step: 290  | total loss: [1m[32m0.33394[0m[0m | time: 7.500s
[2K
| Adam | epoch: 029 | loss: 0.33394 - acc: 0.8949 | val_loss: 0.59094 - val_acc: 0.7473 -- iter: 291/291
--
Training Step: 291  | total loss: [1m[32m0.31740[0m[0m | time: 0.749s
[2K
| Adam | epoch: 030 | loss: 0.31740 - acc: 0.8992 -- iter: 032/291
[A[ATraining Step: 292  | total loss: [1m[32m0.30789[0m[0m | time: 1.482s
[2K
| Adam | epoch: 030 | loss: 0.30789 - acc: 0.8968 -- iter: 064/291
[A[ATraining Step: 293  | total loss: [1m[32m0.29060[0m[0m | time: 2.222s
[2K
| Adam | epoch: 030 | loss: 0.29060 - acc: 0.9040 -- iter: 096/291
[A[ATraining Step: 294  | total loss: [1m[32m0.27911[0m[0m | time: 2.942s
[2K
| Adam | epoch: 030 | loss: 0.27911 - acc: 0.9073 -- iter: 128/291
[A[ATraining Step: 295  | total loss: [1m[32m0.26002[0m[0m | time: 3.659s
[2K
| Adam | epoch: 030 | loss: 0.26002 - acc: 0.9135 -- iter: 160/291
[A[ATraining Step: 296  | total loss: [1m[32m0.24736[0m[0m | time: 3.750s
[2K
| Adam | epoch: 030 | loss: 0.24736 - acc: 0.9190 -- iter: 192/291
[A[ATraining Step: 297  | total loss: [1m[32m0.27178[0m[0m | time: 3.842s
[2K
| Adam | epoch: 030 | loss: 0.27178 - acc: 0.8938 -- iter: 224/291
[A[ATraining Step: 298  | total loss: [1m[32m0.30205[0m[0m | time: 4.618s
[2K
| Adam | epoch: 030 | loss: 0.30205 - acc: 0.8377 -- iter: 256/291
[A[ATraining Step: 299  | total loss: [1m[32m0.28237[0m[0m | time: 5.399s
[2K
| Adam | epoch: 030 | loss: 0.28237 - acc: 0.8508 -- iter: 288/291
[A[ATraining Step: 300  | total loss: [1m[32m0.28062[0m[0m | time: 7.203s
[2K
| Adam | epoch: 030 | loss: 0.28062 - acc: 0.8564 | val_loss: 0.52024 - val_acc: 0.7912 -- iter: 291/291
--
Validation AUC:0.8736585365853659
Validation AUPRC:0.8991902585905164
Test AUC:0.9521739130434782
Test AUPRC:0.9570637023586511
BestTestF1Score	0.88	0.74	0.87	0.83	0.93	43	9	36	3	0.12
BestTestMCCScore	0.84	0.73	0.86	0.95	0.76	35	2	43	11	0.87
BestTestAccuracyScore	0.89	0.78	0.89	0.91	0.87	40	4	41	6	0.63
BestValidationF1Score	0.83	0.58	0.79	0.76	0.9	45	14	27	5	0.12
BestValidationMCC	0.78	0.61	0.79	0.92	0.68	34	3	38	16	0.87
BestValidationAccuracy	0.81	0.61	0.8	0.86	0.76	38	6	35	12	0.63
TestPredictions (Threshold:0.87)
CHEMBL468188,TP,ACT,0.9900000095367432	CHEMBL192180,TP,ACT,1.0	CHEMBL226938,TP,ACT,0.9900000095367432	CHEMBL468221,TP,ACT,1.0	CHEMBL376201,FN,ACT,0.07999999821186066	CHEMBL2296115,TN,INACT,0.009999999776482582	CHEMBL230006,TN,INACT,0.33000001311302185	CHEMBL3133247,TN,INACT,0.05999999865889549	CHEMBL366907,TP,ACT,0.9900000095367432	CHEMBL3753231,TN,INACT,0.009999999776482582	CHEMBL2334729,TN,INACT,0.029999999329447746	CHEMBL2375944,TN,INACT,0.029999999329447746	CHEMBL3612621,TN,INACT,0.07999999821186066	CHEMBL192592,FN,ACT,0.8399999737739563	CHEMBL3132866,TN,INACT,0.029999999329447746	CHEMBL3628624,TN,INACT,0.019999999552965164	CHEMBL513787,TP,ACT,1.0	CHEMBL3288094,TN,INACT,0.09000000357627869	CHEMBL510996,TP,ACT,0.8700000047683716	CHEMBL460808,FP,INACT,0.949999988079071	CHEMBL1922540,TN,INACT,0.10999999940395355	CHEMBL3133306,TN,INACT,0.019999999552965164	CHEMBL236340,TP,ACT,0.9800000190734863	CHEMBL463556,TP,ACT,0.949999988079071	CHEMBL272830,TP,ACT,0.9700000286102295	CHEMBL1629786,TN,INACT,0.10000000149011612	CHEMBL2323352,TN,INACT,0.009999999776482582	CHEMBL292454,TP,ACT,0.9100000262260437	CHEMBL220556,FN,ACT,0.8299999833106995	CHEMBL3794413,TN,INACT,0.41999998688697815	CHEMBL2043059,TN,INACT,0.03999999910593033	CHEMBL192474,TP,ACT,0.9900000095367432	CHEMBL3754339,TN,INACT,0.05000000074505806	CHEMBL3753018,TN,INACT,0.03999999910593033	CHEMBL468189,TP,ACT,0.9900000095367432	CHEMBL3286948,TN,INACT,0.019999999552965164	CHEMBL512948,TN,INACT,0.05999999865889549	CHEMBL93675,TP,ACT,0.9800000190734863	CHEMBL192258,TP,ACT,1.0	CHEMBL1812859,TP,ACT,0.949999988079071	CHEMBL464002,TP,ACT,0.9599999785423279	CHEMBL192627,TP,ACT,0.9599999785423279	CHEMBL362705,TN,INACT,0.07000000029802322	CHEMBL1084211,TN,INACT,0.05000000074505806	CHEMBL511533,TN,INACT,0.09000000357627869	CHEMBL3104330,TN,INACT,0.019999999552965164	CHEMBL477371,TP,ACT,1.0	CHEMBL329187,TP,ACT,0.9200000166893005	CHEMBL406659,FN,ACT,0.8199999928474426	CHEMBL366959,TP,ACT,0.9700000286102295	CHEMBL373606,TP,ACT,0.9900000095367432	CHEMBL1812858,TP,ACT,0.9700000286102295	CHEMBL3617384,TN,INACT,0.019999999552965164	CHEMBL3617368,TN,INACT,0.019999999552965164	CHEMBL1812862,FN,ACT,0.5899999737739563	CHEMBL3752331,TN,INACT,0.029999999329447746	CHEMBL3770816,TN,INACT,0.029999999329447746	CHEMBL1629792,TN,INACT,0.019999999552965164	CHEMBL373781,FN,ACT,0.03999999910593033	CHEMBL1797185,FP,INACT,0.9300000071525574	CHEMBL2334736,TN,INACT,0.019999999552965164	CHEMBL3612817,TN,INACT,0.029999999329447746	CHEMBL182206,TP,ACT,0.9100000262260437	CHEMBL3235943,TN,INACT,0.20999999344348907	CHEMBL422064,FN,ACT,0.10000000149011612	CHEMBL2323351,TN,INACT,0.009999999776482582	CHEMBL39412,FN,ACT,0.1599999964237213	CHEMBL3286943,TN,INACT,0.019999999552965164	CHEMBL270375,TP,ACT,0.949999988079071	CHEMBL1956553,TN,INACT,0.11999999731779099	CHEMBL467817,TP,ACT,0.9399999976158142	CHEMBL182199,TP,ACT,1.0	CHEMBL374895,FN,ACT,0.7599999904632568	CHEMBL220770,TP,ACT,0.9900000095367432	CHEMBL467450,TP,ACT,0.9800000190734863	CHEMBL178115,TP,ACT,0.9900000095367432	CHEMBL1812855,FN,ACT,0.7699999809265137	CHEMBL220125,TP,ACT,1.0	CHEMBL3612818,TN,INACT,0.8600000143051147	CHEMBL1629793,TN,INACT,0.029999999329447746	CHEMBL3235938,TN,INACT,0.8299999833106995	CHEMBL226990,TP,ACT,0.9399999976158142	CHEMBL376417,TP,ACT,0.9900000095367432	CHEMBL476511,FN,ACT,0.5099999904632568	CHEMBL3323387,TN,INACT,0.05999999865889549	CHEMBL3771191,TN,INACT,0.029999999329447746	CHEMBL1812857,TP,ACT,0.9599999785423279	CHEMBL3323373,TN,INACT,0.5799999833106995	CHEMBL1254269,TN,INACT,0.5699999928474426	CHEMBL1914930,TN,INACT,0.11999999731779099	CHEMBL448922,TP,ACT,1.0	

