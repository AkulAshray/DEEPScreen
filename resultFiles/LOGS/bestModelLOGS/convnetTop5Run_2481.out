CNNModel CHEMBL1980 adam 0.001 30 128 0 0.6 False True
Number of active compounds :	298
Number of inactive compounds :	298
---------------------------------
Run id: CNNModel_CHEMBL1980_adam_0.001_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1980_adam_0.001_30_128_0.6_True/
---------------------------------
Training samples: 334
Validation samples: 105
--
Training Step: 1  | time: 0.779s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/334
[A[ATraining Step: 2  | total loss: [1m[32m0.62224[0m[0m | time: 1.384s
[2K
| Adam | epoch: 001 | loss: 0.62224 - acc: 0.5906 -- iter: 064/334
[A[ATraining Step: 3  | total loss: [1m[32m0.67403[0m[0m | time: 2.005s
[2K
| Adam | epoch: 001 | loss: 0.67403 - acc: 0.5676 -- iter: 096/334
[A[ATraining Step: 4  | total loss: [1m[32m0.72383[0m[0m | time: 2.621s
[2K
| Adam | epoch: 001 | loss: 0.72383 - acc: 0.5169 -- iter: 128/334
[A[ATraining Step: 5  | total loss: [1m[32m0.69741[0m[0m | time: 3.290s
[2K
| Adam | epoch: 001 | loss: 0.69741 - acc: 0.5485 -- iter: 160/334
[A[ATraining Step: 6  | total loss: [1m[32m0.68291[0m[0m | time: 3.938s
[2K
| Adam | epoch: 001 | loss: 0.68291 - acc: 0.6579 -- iter: 192/334
[A[ATraining Step: 7  | total loss: [1m[32m0.68359[0m[0m | time: 4.564s
[2K
| Adam | epoch: 001 | loss: 0.68359 - acc: 0.6382 -- iter: 224/334
[A[ATraining Step: 8  | total loss: [1m[32m0.68846[0m[0m | time: 5.177s
[2K
| Adam | epoch: 001 | loss: 0.68846 - acc: 0.5780 -- iter: 256/334
[A[ATraining Step: 9  | total loss: [1m[32m0.69364[0m[0m | time: 5.802s
[2K
| Adam | epoch: 001 | loss: 0.69364 - acc: 0.5036 -- iter: 288/334
[A[ATraining Step: 10  | total loss: [1m[32m0.69128[0m[0m | time: 6.424s
[2K
| Adam | epoch: 001 | loss: 0.69128 - acc: 0.5331 -- iter: 320/334
[A[ATraining Step: 11  | total loss: [1m[32m0.68727[0m[0m | time: 7.763s
[2K
| Adam | epoch: 001 | loss: 0.68727 - acc: 0.5914 | val_loss: 0.69032 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 12  | total loss: [1m[32m0.68544[0m[0m | time: 0.304s
[2K
| Adam | epoch: 002 | loss: 0.68544 - acc: 0.6146 -- iter: 032/334
[A[ATraining Step: 13  | total loss: [1m[32m0.68438[0m[0m | time: 0.930s
[2K
| Adam | epoch: 002 | loss: 0.68438 - acc: 0.6267 -- iter: 064/334
[A[ATraining Step: 14  | total loss: [1m[32m0.69057[0m[0m | time: 1.551s
[2K
| Adam | epoch: 002 | loss: 0.69057 - acc: 0.5621 -- iter: 096/334
[A[ATraining Step: 15  | total loss: [1m[32m0.68453[0m[0m | time: 2.573s
[2K
| Adam | epoch: 002 | loss: 0.68453 - acc: 0.5989 -- iter: 128/334
[A[ATraining Step: 16  | total loss: [1m[32m0.69228[0m[0m | time: 3.667s
[2K
| Adam | epoch: 002 | loss: 0.69228 - acc: 0.5384 -- iter: 160/334
[A[ATraining Step: 17  | total loss: [1m[32m0.68874[0m[0m | time: 4.877s
[2K
| Adam | epoch: 002 | loss: 0.68874 - acc: 0.5583 -- iter: 192/334
[A[ATraining Step: 18  | total loss: [1m[32m0.68945[0m[0m | time: 5.753s
[2K
| Adam | epoch: 002 | loss: 0.68945 - acc: 0.5490 -- iter: 224/334
[A[ATraining Step: 19  | total loss: [1m[32m0.68828[0m[0m | time: 6.675s
[2K
| Adam | epoch: 002 | loss: 0.68828 - acc: 0.5535 -- iter: 256/334
[A[ATraining Step: 20  | total loss: [1m[32m0.67921[0m[0m | time: 7.602s
[2K
| Adam | epoch: 002 | loss: 0.67921 - acc: 0.5965 -- iter: 288/334
[A[ATraining Step: 21  | total loss: [1m[32m0.68128[0m[0m | time: 8.561s
[2K
| Adam | epoch: 002 | loss: 0.68128 - acc: 0.5860 -- iter: 320/334
[A[ATraining Step: 22  | total loss: [1m[32m0.68256[0m[0m | time: 10.552s
[2K
| Adam | epoch: 002 | loss: 0.68256 - acc: 0.5789 | val_loss: 0.69853 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 23  | total loss: [1m[32m0.67720[0m[0m | time: 0.535s
[2K
| Adam | epoch: 003 | loss: 0.67720 - acc: 0.5923 -- iter: 032/334
[A[ATraining Step: 24  | total loss: [1m[32m0.69706[0m[0m | time: 0.909s
[2K
| Adam | epoch: 003 | loss: 0.69706 - acc: 0.5463 -- iter: 064/334
[A[ATraining Step: 25  | total loss: [1m[32m0.70816[0m[0m | time: 1.830s
[2K
| Adam | epoch: 003 | loss: 0.70816 - acc: 0.5142 -- iter: 096/334
[A[ATraining Step: 26  | total loss: [1m[32m0.69541[0m[0m | time: 2.759s
[2K
| Adam | epoch: 003 | loss: 0.69541 - acc: 0.5518 -- iter: 128/334
[A[ATraining Step: 27  | total loss: [1m[32m0.69098[0m[0m | time: 3.660s
[2K
| Adam | epoch: 003 | loss: 0.69098 - acc: 0.5626 -- iter: 160/334
[A[ATraining Step: 28  | total loss: [1m[32m0.68639[0m[0m | time: 4.672s
[2K
| Adam | epoch: 003 | loss: 0.68639 - acc: 0.5782 -- iter: 192/334
[A[ATraining Step: 29  | total loss: [1m[32m0.69206[0m[0m | time: 5.809s
[2K
| Adam | epoch: 003 | loss: 0.69206 - acc: 0.5440 -- iter: 224/334
[A[ATraining Step: 30  | total loss: [1m[32m0.68937[0m[0m | time: 6.715s
[2K
| Adam | epoch: 003 | loss: 0.68937 - acc: 0.5558 -- iter: 256/334
[A[ATraining Step: 31  | total loss: [1m[32m0.68762[0m[0m | time: 7.705s
[2K
| Adam | epoch: 003 | loss: 0.68762 - acc: 0.5645 -- iter: 288/334
[A[ATraining Step: 32  | total loss: [1m[32m0.68848[0m[0m | time: 8.785s
[2K
| Adam | epoch: 003 | loss: 0.68848 - acc: 0.5570 -- iter: 320/334
[A[ATraining Step: 33  | total loss: [1m[32m0.68911[0m[0m | time: 10.936s
[2K
| Adam | epoch: 003 | loss: 0.68911 - acc: 0.5514 | val_loss: 0.68963 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 34  | total loss: [1m[32m0.68580[0m[0m | time: 1.129s
[2K
| Adam | epoch: 004 | loss: 0.68580 - acc: 0.5738 -- iter: 032/334
[A[ATraining Step: 35  | total loss: [1m[32m0.68769[0m[0m | time: 1.566s
[2K
| Adam | epoch: 004 | loss: 0.68769 - acc: 0.5584 -- iter: 064/334
[A[ATraining Step: 36  | total loss: [1m[32m0.68350[0m[0m | time: 1.923s
[2K
| Adam | epoch: 004 | loss: 0.68350 - acc: 0.5903 -- iter: 096/334
[A[ATraining Step: 37  | total loss: [1m[32m0.68004[0m[0m | time: 3.005s
[2K
| Adam | epoch: 004 | loss: 0.68004 - acc: 0.6151 -- iter: 128/334
[A[ATraining Step: 38  | total loss: [1m[32m0.67846[0m[0m | time: 4.112s
[2K
| Adam | epoch: 004 | loss: 0.67846 - acc: 0.6231 -- iter: 160/334
[A[ATraining Step: 39  | total loss: [1m[32m0.67992[0m[0m | time: 5.219s
[2K
| Adam | epoch: 004 | loss: 0.67992 - acc: 0.6115 -- iter: 192/334
[A[ATraining Step: 40  | total loss: [1m[32m0.67772[0m[0m | time: 6.064s
[2K
| Adam | epoch: 004 | loss: 0.67772 - acc: 0.6199 -- iter: 224/334
[A[ATraining Step: 41  | total loss: [1m[32m0.68386[0m[0m | time: 7.028s
[2K
| Adam | epoch: 004 | loss: 0.68386 - acc: 0.5864 -- iter: 256/334
[A[ATraining Step: 42  | total loss: [1m[32m0.68390[0m[0m | time: 7.980s
[2K
| Adam | epoch: 004 | loss: 0.68390 - acc: 0.5821 -- iter: 288/334
[A[ATraining Step: 43  | total loss: [1m[32m0.68142[0m[0m | time: 8.954s
[2K
| Adam | epoch: 004 | loss: 0.68142 - acc: 0.5897 -- iter: 320/334
[A[ATraining Step: 44  | total loss: [1m[32m0.68223[0m[0m | time: 11.011s
[2K
| Adam | epoch: 004 | loss: 0.68223 - acc: 0.5850 | val_loss: 0.69123 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 45  | total loss: [1m[32m0.68598[0m[0m | time: 0.653s
[2K
| Adam | epoch: 005 | loss: 0.68598 - acc: 0.5705 -- iter: 032/334
[A[ATraining Step: 46  | total loss: [1m[32m0.68236[0m[0m | time: 1.266s
[2K
| Adam | epoch: 005 | loss: 0.68236 - acc: 0.5796 -- iter: 064/334
[A[ATraining Step: 47  | total loss: [1m[32m0.68296[0m[0m | time: 1.553s
[2K
| Adam | epoch: 005 | loss: 0.68296 - acc: 0.5768 -- iter: 096/334
[A[ATraining Step: 48  | total loss: [1m[32m0.68315[0m[0m | time: 1.843s
[2K
| Adam | epoch: 005 | loss: 0.68315 - acc: 0.5760 -- iter: 128/334
[A[ATraining Step: 49  | total loss: [1m[32m0.68298[0m[0m | time: 2.434s
[2K
| Adam | epoch: 005 | loss: 0.68298 - acc: 0.5752 -- iter: 160/334
[A[ATraining Step: 50  | total loss: [1m[32m0.67804[0m[0m | time: 3.041s
[2K
| Adam | epoch: 005 | loss: 0.67804 - acc: 0.5878 -- iter: 192/334
[A[ATraining Step: 51  | total loss: [1m[32m0.67937[0m[0m | time: 3.660s
[2K
| Adam | epoch: 005 | loss: 0.67937 - acc: 0.5839 -- iter: 224/334
[A[ATraining Step: 52  | total loss: [1m[32m0.68247[0m[0m | time: 4.267s
[2K
| Adam | epoch: 005 | loss: 0.68247 - acc: 0.5760 -- iter: 256/334
[A[ATraining Step: 53  | total loss: [1m[32m0.67428[0m[0m | time: 4.877s
[2K
| Adam | epoch: 005 | loss: 0.67428 - acc: 0.5971 -- iter: 288/334
[A[ATraining Step: 54  | total loss: [1m[32m0.67447[0m[0m | time: 5.475s
[2K
| Adam | epoch: 005 | loss: 0.67447 - acc: 0.5966 -- iter: 320/334
[A[ATraining Step: 55  | total loss: [1m[32m0.67475[0m[0m | time: 7.083s
[2K
| Adam | epoch: 005 | loss: 0.67475 - acc: 0.5962 | val_loss: 0.69772 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 56  | total loss: [1m[32m0.68112[0m[0m | time: 0.642s
[2K
| Adam | epoch: 006 | loss: 0.68112 - acc: 0.5827 -- iter: 032/334
[A[ATraining Step: 57  | total loss: [1m[32m0.68217[0m[0m | time: 1.277s
[2K
| Adam | epoch: 006 | loss: 0.68217 - acc: 0.5799 -- iter: 064/334
[A[ATraining Step: 58  | total loss: [1m[32m0.68428[0m[0m | time: 1.965s
[2K
| Adam | epoch: 006 | loss: 0.68428 - acc: 0.5732 -- iter: 096/334
[A[ATraining Step: 59  | total loss: [1m[32m0.68674[0m[0m | time: 2.256s
[2K
| Adam | epoch: 006 | loss: 0.68674 - acc: 0.5634 -- iter: 128/334
[A[ATraining Step: 60  | total loss: [1m[32m0.68108[0m[0m | time: 2.548s
[2K
| Adam | epoch: 006 | loss: 0.68108 - acc: 0.5834 -- iter: 160/334
[A[ATraining Step: 61  | total loss: [1m[32m0.67631[0m[0m | time: 3.166s
[2K
| Adam | epoch: 006 | loss: 0.67631 - acc: 0.6005 -- iter: 192/334
[A[ATraining Step: 62  | total loss: [1m[32m0.67851[0m[0m | time: 3.789s
[2K
| Adam | epoch: 006 | loss: 0.67851 - acc: 0.5916 -- iter: 224/334
[A[ATraining Step: 63  | total loss: [1m[32m0.67730[0m[0m | time: 4.413s
[2K
| Adam | epoch: 006 | loss: 0.67730 - acc: 0.5958 -- iter: 256/334
[A[ATraining Step: 64  | total loss: [1m[32m0.67514[0m[0m | time: 5.022s
[2K
| Adam | epoch: 006 | loss: 0.67514 - acc: 0.6034 -- iter: 288/334
[A[ATraining Step: 65  | total loss: [1m[32m0.67311[0m[0m | time: 5.645s
[2K
| Adam | epoch: 006 | loss: 0.67311 - acc: 0.6099 -- iter: 320/334
[A[ATraining Step: 66  | total loss: [1m[32m0.68033[0m[0m | time: 7.277s
[2K
| Adam | epoch: 006 | loss: 0.68033 - acc: 0.5851 | val_loss: 0.69091 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 67  | total loss: [1m[32m0.68075[0m[0m | time: 0.620s
[2K
| Adam | epoch: 007 | loss: 0.68075 - acc: 0.5824 -- iter: 032/334
[A[ATraining Step: 68  | total loss: [1m[32m0.68335[0m[0m | time: 1.232s
[2K
| Adam | epoch: 007 | loss: 0.68335 - acc: 0.5726 -- iter: 064/334
[A[ATraining Step: 69  | total loss: [1m[32m0.68052[0m[0m | time: 1.847s
[2K
| Adam | epoch: 007 | loss: 0.68052 - acc: 0.5824 -- iter: 096/334
[A[ATraining Step: 70  | total loss: [1m[32m0.67793[0m[0m | time: 2.453s
[2K
| Adam | epoch: 007 | loss: 0.67793 - acc: 0.5909 -- iter: 128/334
[A[ATraining Step: 71  | total loss: [1m[32m0.67746[0m[0m | time: 2.739s
[2K
| Adam | epoch: 007 | loss: 0.67746 - acc: 0.5913 -- iter: 160/334
[A[ATraining Step: 72  | total loss: [1m[32m0.67522[0m[0m | time: 3.018s
[2K
| Adam | epoch: 007 | loss: 0.67522 - acc: 0.5971 -- iter: 192/334
[A[ATraining Step: 73  | total loss: [1m[32m0.67311[0m[0m | time: 3.675s
[2K
| Adam | epoch: 007 | loss: 0.67311 - acc: 0.6021 -- iter: 224/334
[A[ATraining Step: 74  | total loss: [1m[32m0.67554[0m[0m | time: 4.334s
[2K
| Adam | epoch: 007 | loss: 0.67554 - acc: 0.5944 -- iter: 256/334
[A[ATraining Step: 75  | total loss: [1m[32m0.68004[0m[0m | time: 4.975s
[2K
| Adam | epoch: 007 | loss: 0.68004 - acc: 0.5841 -- iter: 288/334
[A[ATraining Step: 76  | total loss: [1m[32m0.67253[0m[0m | time: 5.671s
[2K
| Adam | epoch: 007 | loss: 0.67253 - acc: 0.6019 -- iter: 320/334
[A[ATraining Step: 77  | total loss: [1m[32m0.68145[0m[0m | time: 7.614s
[2K
| Adam | epoch: 007 | loss: 0.68145 - acc: 0.5812 | val_loss: 0.69571 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 78  | total loss: [1m[32m0.67409[0m[0m | time: 0.961s
[2K
| Adam | epoch: 008 | loss: 0.67409 - acc: 0.5989 -- iter: 032/334
[A[ATraining Step: 79  | total loss: [1m[32m0.67012[0m[0m | time: 2.060s
[2K
| Adam | epoch: 008 | loss: 0.67012 - acc: 0.6080 -- iter: 064/334
[A[ATraining Step: 80  | total loss: [1m[32m0.67629[0m[0m | time: 3.013s
[2K
| Adam | epoch: 008 | loss: 0.67629 - acc: 0.5938 -- iter: 096/334
[A[ATraining Step: 81  | total loss: [1m[32m0.67960[0m[0m | time: 3.973s
[2K
| Adam | epoch: 008 | loss: 0.67960 - acc: 0.5843 -- iter: 128/334
[A[ATraining Step: 82  | total loss: [1m[32m0.67990[0m[0m | time: 4.982s
[2K
| Adam | epoch: 008 | loss: 0.67990 - acc: 0.5821 -- iter: 160/334
[A[ATraining Step: 83  | total loss: [1m[32m0.67772[0m[0m | time: 5.477s
[2K
| Adam | epoch: 008 | loss: 0.67772 - acc: 0.5864 -- iter: 192/334
[A[ATraining Step: 84  | total loss: [1m[32m0.68470[0m[0m | time: 6.042s
[2K
| Adam | epoch: 008 | loss: 0.68470 - acc: 0.5635 -- iter: 224/334
[A[ATraining Step: 85  | total loss: [1m[32m0.68992[0m[0m | time: 7.059s
[2K
| Adam | epoch: 008 | loss: 0.68992 - acc: 0.5428 -- iter: 256/334
[A[ATraining Step: 86  | total loss: [1m[32m0.68948[0m[0m | time: 8.048s
[2K
| Adam | epoch: 008 | loss: 0.68948 - acc: 0.5448 -- iter: 288/334
[A[ATraining Step: 87  | total loss: [1m[32m0.68954[0m[0m | time: 9.019s
[2K
| Adam | epoch: 008 | loss: 0.68954 - acc: 0.5435 -- iter: 320/334
[A[ATraining Step: 88  | total loss: [1m[32m0.68768[0m[0m | time: 11.030s
[2K
| Adam | epoch: 008 | loss: 0.68768 - acc: 0.5579 | val_loss: 0.68945 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 89  | total loss: [1m[32m0.68659[0m[0m | time: 0.965s
[2K
| Adam | epoch: 009 | loss: 0.68659 - acc: 0.5646 -- iter: 032/334
[A[ATraining Step: 90  | total loss: [1m[32m0.68602[0m[0m | time: 1.887s
[2K
| Adam | epoch: 009 | loss: 0.68602 - acc: 0.5675 -- iter: 064/334
[A[ATraining Step: 91  | total loss: [1m[32m0.68776[0m[0m | time: 2.805s
[2K
| Adam | epoch: 009 | loss: 0.68776 - acc: 0.5576 -- iter: 096/334
[A[ATraining Step: 92  | total loss: [1m[32m0.68982[0m[0m | time: 3.897s
[2K
| Adam | epoch: 009 | loss: 0.68982 - acc: 0.5456 -- iter: 128/334
[A[ATraining Step: 93  | total loss: [1m[32m0.68804[0m[0m | time: 4.907s
[2K
| Adam | epoch: 009 | loss: 0.68804 - acc: 0.5567 -- iter: 160/334
[A[ATraining Step: 94  | total loss: [1m[32m0.68657[0m[0m | time: 5.752s
[2K
| Adam | epoch: 009 | loss: 0.68657 - acc: 0.5666 -- iter: 192/334
[A[ATraining Step: 95  | total loss: [1m[32m0.68553[0m[0m | time: 6.332s
[2K
| Adam | epoch: 009 | loss: 0.68553 - acc: 0.5725 -- iter: 224/334
[A[ATraining Step: 96  | total loss: [1m[32m0.68293[0m[0m | time: 6.820s
[2K
| Adam | epoch: 009 | loss: 0.68293 - acc: 0.5866 -- iter: 256/334
[A[ATraining Step: 97  | total loss: [1m[32m0.68019[0m[0m | time: 7.949s
[2K
| Adam | epoch: 009 | loss: 0.68019 - acc: 0.5994 -- iter: 288/334
[A[ATraining Step: 98  | total loss: [1m[32m0.68222[0m[0m | time: 8.992s
[2K
| Adam | epoch: 009 | loss: 0.68222 - acc: 0.5895 -- iter: 320/334
[A[ATraining Step: 99  | total loss: [1m[32m0.68598[0m[0m | time: 10.895s
[2K
| Adam | epoch: 009 | loss: 0.68598 - acc: 0.5743 | val_loss: 0.69044 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 100  | total loss: [1m[32m0.68763[0m[0m | time: 0.986s
[2K
| Adam | epoch: 010 | loss: 0.68763 - acc: 0.5668 -- iter: 032/334
[A[ATraining Step: 101  | total loss: [1m[32m0.68744[0m[0m | time: 1.682s
[2K
| Adam | epoch: 010 | loss: 0.68744 - acc: 0.5664 -- iter: 064/334
[A[ATraining Step: 102  | total loss: [1m[32m0.68806[0m[0m | time: 2.294s
[2K
| Adam | epoch: 010 | loss: 0.68806 - acc: 0.5629 -- iter: 096/334
[A[ATraining Step: 103  | total loss: [1m[32m0.68697[0m[0m | time: 2.905s
[2K
| Adam | epoch: 010 | loss: 0.68697 - acc: 0.5660 -- iter: 128/334
[A[ATraining Step: 104  | total loss: [1m[32m0.68690[0m[0m | time: 3.528s
[2K
| Adam | epoch: 010 | loss: 0.68690 - acc: 0.5656 -- iter: 160/334
[A[ATraining Step: 105  | total loss: [1m[32m0.68464[0m[0m | time: 4.145s
[2K
| Adam | epoch: 010 | loss: 0.68464 - acc: 0.5747 -- iter: 192/334
[A[ATraining Step: 106  | total loss: [1m[32m0.68690[0m[0m | time: 4.774s
[2K
| Adam | epoch: 010 | loss: 0.68690 - acc: 0.5641 -- iter: 224/334
[A[ATraining Step: 107  | total loss: [1m[32m0.68599[0m[0m | time: 5.070s
[2K
| Adam | epoch: 010 | loss: 0.68599 - acc: 0.5671 -- iter: 256/334
[A[ATraining Step: 108  | total loss: [1m[32m0.68243[0m[0m | time: 5.357s
[2K
| Adam | epoch: 010 | loss: 0.68243 - acc: 0.5818 -- iter: 288/334
[A[ATraining Step: 109  | total loss: [1m[32m0.67894[0m[0m | time: 5.984s
[2K
| Adam | epoch: 010 | loss: 0.67894 - acc: 0.5950 -- iter: 320/334
[A[ATraining Step: 110  | total loss: [1m[32m0.67699[0m[0m | time: 7.597s
[2K
| Adam | epoch: 010 | loss: 0.67699 - acc: 0.6012 | val_loss: 0.69505 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 111  | total loss: [1m[32m0.67806[0m[0m | time: 0.633s
[2K
| Adam | epoch: 011 | loss: 0.67806 - acc: 0.5973 -- iter: 032/334
[A[ATraining Step: 112  | total loss: [1m[32m0.67548[0m[0m | time: 1.239s
[2K
| Adam | epoch: 011 | loss: 0.67548 - acc: 0.6032 -- iter: 064/334
[A[ATraining Step: 113  | total loss: [1m[32m0.67991[0m[0m | time: 1.912s
[2K
| Adam | epoch: 011 | loss: 0.67991 - acc: 0.5929 -- iter: 096/334
[A[ATraining Step: 114  | total loss: [1m[32m0.68546[0m[0m | time: 2.639s
[2K
| Adam | epoch: 011 | loss: 0.68546 - acc: 0.5805 -- iter: 128/334
[A[ATraining Step: 115  | total loss: [1m[32m0.68427[0m[0m | time: 3.247s
[2K
| Adam | epoch: 011 | loss: 0.68427 - acc: 0.5818 -- iter: 160/334
[A[ATraining Step: 116  | total loss: [1m[32m0.68221[0m[0m | time: 3.861s
[2K
| Adam | epoch: 011 | loss: 0.68221 - acc: 0.5861 -- iter: 192/334
[A[ATraining Step: 117  | total loss: [1m[32m0.68042[0m[0m | time: 4.470s
[2K
| Adam | epoch: 011 | loss: 0.68042 - acc: 0.5900 -- iter: 224/334
[A[ATraining Step: 118  | total loss: [1m[32m0.67973[0m[0m | time: 5.095s
[2K
| Adam | epoch: 011 | loss: 0.67973 - acc: 0.5904 -- iter: 256/334
[A[ATraining Step: 119  | total loss: [1m[32m0.67918[0m[0m | time: 5.390s
[2K
| Adam | epoch: 011 | loss: 0.67918 - acc: 0.5907 -- iter: 288/334
[A[ATraining Step: 120  | total loss: [1m[32m0.68129[0m[0m | time: 5.696s
[2K
| Adam | epoch: 011 | loss: 0.68129 - acc: 0.5816 -- iter: 320/334
[A[ATraining Step: 121  | total loss: [1m[32m0.68295[0m[0m | time: 7.332s
[2K
| Adam | epoch: 011 | loss: 0.68295 - acc: 0.5735 | val_loss: 0.68838 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 122  | total loss: [1m[32m0.68351[0m[0m | time: 1.096s
[2K
| Adam | epoch: 012 | loss: 0.68351 - acc: 0.5693 -- iter: 032/334
[A[ATraining Step: 123  | total loss: [1m[32m0.68249[0m[0m | time: 2.060s
[2K
| Adam | epoch: 012 | loss: 0.68249 - acc: 0.5717 -- iter: 064/334
[A[ATraining Step: 124  | total loss: [1m[32m0.68271[0m[0m | time: 3.008s
[2K
| Adam | epoch: 012 | loss: 0.68271 - acc: 0.5708 -- iter: 096/334
[A[ATraining Step: 125  | total loss: [1m[32m0.67967[0m[0m | time: 3.938s
[2K
| Adam | epoch: 012 | loss: 0.67967 - acc: 0.5793 -- iter: 128/334
[A[ATraining Step: 126  | total loss: [1m[32m0.67952[0m[0m | time: 4.898s
[2K
| Adam | epoch: 012 | loss: 0.67952 - acc: 0.5776 -- iter: 160/334
[A[ATraining Step: 127  | total loss: [1m[32m0.68250[0m[0m | time: 5.913s
[2K
| Adam | epoch: 012 | loss: 0.68250 - acc: 0.5668 -- iter: 192/334
[A[ATraining Step: 128  | total loss: [1m[32m0.68078[0m[0m | time: 6.931s
[2K
| Adam | epoch: 012 | loss: 0.68078 - acc: 0.5695 -- iter: 224/334
[A[ATraining Step: 129  | total loss: [1m[32m0.68188[0m[0m | time: 7.857s
[2K
| Adam | epoch: 012 | loss: 0.68188 - acc: 0.5594 -- iter: 256/334
[A[ATraining Step: 130  | total loss: [1m[32m0.68161[0m[0m | time: 8.876s
[2K
| Adam | epoch: 012 | loss: 0.68161 - acc: 0.5566 -- iter: 288/334
[A[ATraining Step: 131  | total loss: [1m[32m0.68156[0m[0m | time: 9.421s
[2K
| Adam | epoch: 012 | loss: 0.68156 - acc: 0.5540 -- iter: 320/334
[A[ATraining Step: 132  | total loss: [1m[32m0.67700[0m[0m | time: 10.960s
[2K
| Adam | epoch: 012 | loss: 0.67700 - acc: 0.5701 | val_loss: 0.73503 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 133  | total loss: [1m[32m0.66691[0m[0m | time: 0.917s
[2K
| Adam | epoch: 013 | loss: 0.66691 - acc: 0.5916 -- iter: 032/334
[A[ATraining Step: 134  | total loss: [1m[32m0.66333[0m[0m | time: 1.933s
[2K
| Adam | epoch: 013 | loss: 0.66333 - acc: 0.5981 -- iter: 064/334
[A[ATraining Step: 135  | total loss: [1m[32m0.66253[0m[0m | time: 3.005s
[2K
| Adam | epoch: 013 | loss: 0.66253 - acc: 0.6039 -- iter: 096/334
[A[ATraining Step: 136  | total loss: [1m[32m0.66941[0m[0m | time: 4.142s
[2K
| Adam | epoch: 013 | loss: 0.66941 - acc: 0.6029 -- iter: 128/334
[A[ATraining Step: 137  | total loss: [1m[32m0.67270[0m[0m | time: 4.984s
[2K
| Adam | epoch: 013 | loss: 0.67270 - acc: 0.6020 -- iter: 160/334
[A[ATraining Step: 138  | total loss: [1m[32m0.68047[0m[0m | time: 5.929s
[2K
| Adam | epoch: 013 | loss: 0.68047 - acc: 0.5887 -- iter: 192/334
[A[ATraining Step: 139  | total loss: [1m[32m0.67575[0m[0m | time: 6.842s
[2K
| Adam | epoch: 013 | loss: 0.67575 - acc: 0.5985 -- iter: 224/334
[A[ATraining Step: 140  | total loss: [1m[32m0.67857[0m[0m | time: 7.835s
[2K
| Adam | epoch: 013 | loss: 0.67857 - acc: 0.5887 -- iter: 256/334
[A[ATraining Step: 141  | total loss: [1m[32m0.67915[0m[0m | time: 8.887s
[2K
| Adam | epoch: 013 | loss: 0.67915 - acc: 0.5861 -- iter: 288/334
[A[ATraining Step: 142  | total loss: [1m[32m0.67884[0m[0m | time: 9.970s
[2K
| Adam | epoch: 013 | loss: 0.67884 - acc: 0.5868 -- iter: 320/334
[A[ATraining Step: 143  | total loss: [1m[32m0.68144[0m[0m | time: 11.353s
[2K
| Adam | epoch: 013 | loss: 0.68144 - acc: 0.5750 | val_loss: 0.68917 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 144  | total loss: [1m[32m0.68016[0m[0m | time: 0.291s
[2K
| Adam | epoch: 014 | loss: 0.68016 - acc: 0.5818 -- iter: 032/334
[A[ATraining Step: 145  | total loss: [1m[32m0.67928[0m[0m | time: 0.916s
[2K
| Adam | epoch: 014 | loss: 0.67928 - acc: 0.5879 -- iter: 064/334
[A[ATraining Step: 146  | total loss: [1m[32m0.67944[0m[0m | time: 1.549s
[2K
| Adam | epoch: 014 | loss: 0.67944 - acc: 0.5885 -- iter: 096/334
[A[ATraining Step: 147  | total loss: [1m[32m0.67841[0m[0m | time: 2.164s
[2K
| Adam | epoch: 014 | loss: 0.67841 - acc: 0.5953 -- iter: 128/334
[A[ATraining Step: 148  | total loss: [1m[32m0.67976[0m[0m | time: 2.765s
[2K
| Adam | epoch: 014 | loss: 0.67976 - acc: 0.5889 -- iter: 160/334
[A[ATraining Step: 149  | total loss: [1m[32m0.67983[0m[0m | time: 3.377s
[2K
| Adam | epoch: 014 | loss: 0.67983 - acc: 0.5894 -- iter: 192/334
[A[ATraining Step: 150  | total loss: [1m[32m0.67923[0m[0m | time: 3.999s
[2K
| Adam | epoch: 014 | loss: 0.67923 - acc: 0.5929 -- iter: 224/334
[A[ATraining Step: 151  | total loss: [1m[32m0.68045[0m[0m | time: 4.597s
[2K
| Adam | epoch: 014 | loss: 0.68045 - acc: 0.5868 -- iter: 256/334
[A[ATraining Step: 152  | total loss: [1m[32m0.68206[0m[0m | time: 5.186s
[2K
| Adam | epoch: 014 | loss: 0.68206 - acc: 0.5781 -- iter: 288/334
[A[ATraining Step: 153  | total loss: [1m[32m0.68061[0m[0m | time: 5.793s
[2K
| Adam | epoch: 014 | loss: 0.68061 - acc: 0.5859 -- iter: 320/334
[A[ATraining Step: 154  | total loss: [1m[32m0.67994[0m[0m | time: 7.401s
[2K
| Adam | epoch: 014 | loss: 0.67994 - acc: 0.5898 | val_loss: 0.68940 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 155  | total loss: [1m[32m0.68234[0m[0m | time: 0.313s
[2K
| Adam | epoch: 015 | loss: 0.68234 - acc: 0.5777 -- iter: 032/334
[A[ATraining Step: 156  | total loss: [1m[32m0.68094[0m[0m | time: 0.612s
[2K
| Adam | epoch: 015 | loss: 0.68094 - acc: 0.5842 -- iter: 064/334
[A[ATraining Step: 157  | total loss: [1m[32m0.67987[0m[0m | time: 1.212s
[2K
| Adam | epoch: 015 | loss: 0.67987 - acc: 0.5901 -- iter: 096/334
[A[ATraining Step: 158  | total loss: [1m[32m0.67974[0m[0m | time: 1.848s
[2K
| Adam | epoch: 015 | loss: 0.67974 - acc: 0.5904 -- iter: 128/334
[A[ATraining Step: 159  | total loss: [1m[32m0.67948[0m[0m | time: 2.490s
[2K
| Adam | epoch: 015 | loss: 0.67948 - acc: 0.5908 -- iter: 160/334
[A[ATraining Step: 160  | total loss: [1m[32m0.67797[0m[0m | time: 3.100s
[2K
| Adam | epoch: 015 | loss: 0.67797 - acc: 0.5973 -- iter: 192/334
[A[ATraining Step: 161  | total loss: [1m[32m0.67871[0m[0m | time: 3.711s
[2K
| Adam | epoch: 015 | loss: 0.67871 - acc: 0.5938 -- iter: 224/334
[A[ATraining Step: 162  | total loss: [1m[32m0.67785[0m[0m | time: 4.332s
[2K
| Adam | epoch: 015 | loss: 0.67785 - acc: 0.5970 -- iter: 256/334
[A[ATraining Step: 163  | total loss: [1m[32m0.67333[0m[0m | time: 5.000s
[2K
| Adam | epoch: 015 | loss: 0.67333 - acc: 0.6154 -- iter: 288/334
[A[ATraining Step: 164  | total loss: [1m[32m0.67615[0m[0m | time: 5.620s
[2K
| Adam | epoch: 015 | loss: 0.67615 - acc: 0.6038 -- iter: 320/334
[A[ATraining Step: 165  | total loss: [1m[32m0.67775[0m[0m | time: 7.249s
[2K
| Adam | epoch: 015 | loss: 0.67775 - acc: 0.5966 | val_loss: 0.69073 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 166  | total loss: [1m[32m0.67948[0m[0m | time: 0.683s
[2K
| Adam | epoch: 016 | loss: 0.67948 - acc: 0.5901 -- iter: 032/334
[A[ATraining Step: 167  | total loss: [1m[32m0.67925[0m[0m | time: 1.189s
[2K
| Adam | epoch: 016 | loss: 0.67925 - acc: 0.5904 -- iter: 064/334
[A[ATraining Step: 168  | total loss: [1m[32m0.67561[0m[0m | time: 1.684s
[2K
| Adam | epoch: 016 | loss: 0.67561 - acc: 0.6028 -- iter: 096/334
[A[ATraining Step: 169  | total loss: [1m[32m0.67206[0m[0m | time: 2.677s
[2K
| Adam | epoch: 016 | loss: 0.67206 - acc: 0.6140 -- iter: 128/334
[A[ATraining Step: 170  | total loss: [1m[32m0.67328[0m[0m | time: 3.786s
[2K
| Adam | epoch: 016 | loss: 0.67328 - acc: 0.6088 -- iter: 160/334
[A[ATraining Step: 171  | total loss: [1m[32m0.68190[0m[0m | time: 4.894s
[2K
| Adam | epoch: 016 | loss: 0.68190 - acc: 0.5823 -- iter: 192/334
[A[ATraining Step: 172  | total loss: [1m[32m0.68548[0m[0m | time: 5.549s
[2K
| Adam | epoch: 016 | loss: 0.68548 - acc: 0.5710 -- iter: 224/334
[A[ATraining Step: 173  | total loss: [1m[32m0.68437[0m[0m | time: 6.178s
[2K
| Adam | epoch: 016 | loss: 0.68437 - acc: 0.5732 -- iter: 256/334
[A[ATraining Step: 174  | total loss: [1m[32m0.68527[0m[0m | time: 6.799s
[2K
| Adam | epoch: 016 | loss: 0.68527 - acc: 0.5690 -- iter: 288/334
[A[ATraining Step: 175  | total loss: [1m[32m0.68248[0m[0m | time: 7.405s
[2K
| Adam | epoch: 016 | loss: 0.68248 - acc: 0.5778 -- iter: 320/334
[A[ATraining Step: 176  | total loss: [1m[32m0.67919[0m[0m | time: 9.012s
[2K
| Adam | epoch: 016 | loss: 0.67919 - acc: 0.5887 | val_loss: 0.69041 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 177  | total loss: [1m[32m0.67875[0m[0m | time: 0.712s
[2K
| Adam | epoch: 017 | loss: 0.67875 - acc: 0.5892 -- iter: 032/334
[A[ATraining Step: 178  | total loss: [1m[32m0.67838[0m[0m | time: 1.341s
[2K
| Adam | epoch: 017 | loss: 0.67838 - acc: 0.5897 -- iter: 064/334
[A[ATraining Step: 179  | total loss: [1m[32m0.67783[0m[0m | time: 1.629s
[2K
| Adam | epoch: 017 | loss: 0.67783 - acc: 0.5901 -- iter: 096/334
[A[ATraining Step: 180  | total loss: [1m[32m0.67805[0m[0m | time: 1.936s
[2K
| Adam | epoch: 017 | loss: 0.67805 - acc: 0.5882 -- iter: 128/334
[A[ATraining Step: 181  | total loss: [1m[32m0.67830[0m[0m | time: 2.563s
[2K
| Adam | epoch: 017 | loss: 0.67830 - acc: 0.5865 -- iter: 160/334
[A[ATraining Step: 182  | total loss: [1m[32m0.67965[0m[0m | time: 3.199s
[2K
| Adam | epoch: 017 | loss: 0.67965 - acc: 0.5810 -- iter: 192/334
[A[ATraining Step: 183  | total loss: [1m[32m0.68206[0m[0m | time: 3.815s
[2K
| Adam | epoch: 017 | loss: 0.68206 - acc: 0.5729 -- iter: 224/334
[A[ATraining Step: 184  | total loss: [1m[32m0.68289[0m[0m | time: 4.438s
[2K
| Adam | epoch: 017 | loss: 0.68289 - acc: 0.5687 -- iter: 256/334
[A[ATraining Step: 185  | total loss: [1m[32m0.68294[0m[0m | time: 5.070s
[2K
| Adam | epoch: 017 | loss: 0.68294 - acc: 0.5681 -- iter: 288/334
[A[ATraining Step: 186  | total loss: [1m[32m0.68207[0m[0m | time: 5.682s
[2K
| Adam | epoch: 017 | loss: 0.68207 - acc: 0.5707 -- iter: 320/334
[A[ATraining Step: 187  | total loss: [1m[32m0.68107[0m[0m | time: 7.303s
[2K
| Adam | epoch: 017 | loss: 0.68107 - acc: 0.5730 | val_loss: 0.68914 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 188  | total loss: [1m[32m0.68087[0m[0m | time: 0.612s
[2K
| Adam | epoch: 018 | loss: 0.68087 - acc: 0.5719 -- iter: 032/334
[A[ATraining Step: 189  | total loss: [1m[32m0.68066[0m[0m | time: 1.220s
[2K
| Adam | epoch: 018 | loss: 0.68066 - acc: 0.5710 -- iter: 064/334
[A[ATraining Step: 190  | total loss: [1m[32m0.67622[0m[0m | time: 1.827s
[2K
| Adam | epoch: 018 | loss: 0.67622 - acc: 0.5826 -- iter: 096/334
[A[ATraining Step: 191  | total loss: [1m[32m0.67743[0m[0m | time: 2.123s
[2K
| Adam | epoch: 018 | loss: 0.67743 - acc: 0.5775 -- iter: 128/334
[A[ATraining Step: 192  | total loss: [1m[32m0.67213[0m[0m | time: 2.414s
[2K
| Adam | epoch: 018 | loss: 0.67213 - acc: 0.5912 -- iter: 160/334
[A[ATraining Step: 193  | total loss: [1m[32m0.66666[0m[0m | time: 3.027s
[2K
| Adam | epoch: 018 | loss: 0.66666 - acc: 0.6035 -- iter: 192/334
[A[ATraining Step: 194  | total loss: [1m[32m0.67325[0m[0m | time: 3.634s
[2K
| Adam | epoch: 018 | loss: 0.67325 - acc: 0.5900 -- iter: 224/334
[A[ATraining Step: 195  | total loss: [1m[32m0.67328[0m[0m | time: 4.249s
[2K
| Adam | epoch: 018 | loss: 0.67328 - acc: 0.5904 -- iter: 256/334
[A[ATraining Step: 196  | total loss: [1m[32m0.67129[0m[0m | time: 4.896s
[2K
| Adam | epoch: 018 | loss: 0.67129 - acc: 0.5939 -- iter: 288/334
[A[ATraining Step: 197  | total loss: [1m[32m0.67376[0m[0m | time: 5.503s
[2K
| Adam | epoch: 018 | loss: 0.67376 - acc: 0.5876 -- iter: 320/334
[A[ATraining Step: 198  | total loss: [1m[32m0.67225[0m[0m | time: 7.119s
[2K
| Adam | epoch: 018 | loss: 0.67225 - acc: 0.5851 | val_loss: 0.68563 - val_acc: 0.5429 -- iter: 334/334
--
Training Step: 199  | total loss: [1m[32m0.67020[0m[0m | time: 0.605s
[2K
| Adam | epoch: 019 | loss: 0.67020 - acc: 0.5860 -- iter: 032/334
[A[ATraining Step: 200  | total loss: [1m[32m0.67185[0m[0m | time: 2.234s
[2K
| Adam | epoch: 019 | loss: 0.67185 - acc: 0.5805 | val_loss: 0.68426 - val_acc: 0.5429 -- iter: 064/334
--
Training Step: 201  | total loss: [1m[32m0.66989[0m[0m | time: 2.869s
[2K
| Adam | epoch: 019 | loss: 0.66989 - acc: 0.5818 -- iter: 096/334
[A[ATraining Step: 202  | total loss: [1m[32m0.65773[0m[0m | time: 3.498s
[2K
| Adam | epoch: 019 | loss: 0.65773 - acc: 0.5986 -- iter: 128/334
[A[ATraining Step: 203  | total loss: [1m[32m0.65831[0m[0m | time: 3.780s
[2K
| Adam | epoch: 019 | loss: 0.65831 - acc: 0.5919 -- iter: 160/334
[A[ATraining Step: 204  | total loss: [1m[32m0.66140[0m[0m | time: 4.062s
[2K
| Adam | epoch: 019 | loss: 0.66140 - acc: 0.5898 -- iter: 192/334
[A[ATraining Step: 205  | total loss: [1m[32m0.66199[0m[0m | time: 4.685s
[2K
| Adam | epoch: 019 | loss: 0.66199 - acc: 0.5880 -- iter: 224/334
[A[ATraining Step: 206  | total loss: [1m[32m0.66183[0m[0m | time: 5.287s
[2K
| Adam | epoch: 019 | loss: 0.66183 - acc: 0.5948 -- iter: 256/334
[A[ATraining Step: 207  | total loss: [1m[32m0.66518[0m[0m | time: 5.946s
[2K
| Adam | epoch: 019 | loss: 0.66518 - acc: 0.6010 -- iter: 288/334
[A[ATraining Step: 208  | total loss: [1m[32m0.66430[0m[0m | time: 6.557s
[2K
| Adam | epoch: 019 | loss: 0.66430 - acc: 0.6034 -- iter: 320/334
[A[ATraining Step: 209  | total loss: [1m[32m0.66191[0m[0m | time: 8.163s
[2K
| Adam | epoch: 019 | loss: 0.66191 - acc: 0.6024 | val_loss: 0.66241 - val_acc: 0.6381 -- iter: 334/334
--
Training Step: 210  | total loss: [1m[32m0.65483[0m[0m | time: 0.620s
[2K
| Adam | epoch: 020 | loss: 0.65483 - acc: 0.6109 -- iter: 032/334
[A[ATraining Step: 211  | total loss: [1m[32m0.65669[0m[0m | time: 1.232s
[2K
| Adam | epoch: 020 | loss: 0.65669 - acc: 0.6061 -- iter: 064/334
[A[ATraining Step: 212  | total loss: [1m[32m0.64024[0m[0m | time: 1.854s
[2K
| Adam | epoch: 020 | loss: 0.64024 - acc: 0.6361 -- iter: 096/334
[A[ATraining Step: 213  | total loss: [1m[32m0.63455[0m[0m | time: 2.465s
[2K
| Adam | epoch: 020 | loss: 0.63455 - acc: 0.6381 -- iter: 128/334
[A[ATraining Step: 214  | total loss: [1m[32m0.62576[0m[0m | time: 3.104s
[2K
| Adam | epoch: 020 | loss: 0.62576 - acc: 0.6524 -- iter: 160/334
[A[ATraining Step: 215  | total loss: [1m[32m0.62081[0m[0m | time: 3.396s
[2K
| Adam | epoch: 020 | loss: 0.62081 - acc: 0.6559 -- iter: 192/334
[A[ATraining Step: 216  | total loss: [1m[32m0.60390[0m[0m | time: 3.696s
[2K
| Adam | epoch: 020 | loss: 0.60390 - acc: 0.6761 -- iter: 224/334
[A[ATraining Step: 217  | total loss: [1m[32m0.58944[0m[0m | time: 4.318s
[2K
| Adam | epoch: 020 | loss: 0.58944 - acc: 0.6870 -- iter: 256/334
[A[ATraining Step: 218  | total loss: [1m[32m0.61535[0m[0m | time: 4.927s
[2K
| Adam | epoch: 020 | loss: 0.61535 - acc: 0.6808 -- iter: 288/334
[A[ATraining Step: 219  | total loss: [1m[32m0.59246[0m[0m | time: 5.550s
[2K
| Adam | epoch: 020 | loss: 0.59246 - acc: 0.7002 -- iter: 320/334
[A[ATraining Step: 220  | total loss: [1m[32m0.59193[0m[0m | time: 7.166s
[2K
| Adam | epoch: 020 | loss: 0.59193 - acc: 0.6990 | val_loss: 0.59305 - val_acc: 0.6476 -- iter: 334/334
--
Training Step: 221  | total loss: [1m[32m0.58387[0m[0m | time: 0.650s
[2K
| Adam | epoch: 021 | loss: 0.58387 - acc: 0.7103 -- iter: 032/334
[A[ATraining Step: 222  | total loss: [1m[32m0.58033[0m[0m | time: 1.272s
[2K
| Adam | epoch: 021 | loss: 0.58033 - acc: 0.7112 -- iter: 064/334
[A[ATraining Step: 223  | total loss: [1m[32m0.58152[0m[0m | time: 1.893s
[2K
| Adam | epoch: 021 | loss: 0.58152 - acc: 0.7088 -- iter: 096/334
[A[ATraining Step: 224  | total loss: [1m[32m0.57367[0m[0m | time: 2.492s
[2K
| Adam | epoch: 021 | loss: 0.57367 - acc: 0.7192 -- iter: 128/334
[A[ATraining Step: 225  | total loss: [1m[32m0.56211[0m[0m | time: 3.106s
[2K
| Adam | epoch: 021 | loss: 0.56211 - acc: 0.7285 -- iter: 160/334
[A[ATraining Step: 226  | total loss: [1m[32m0.55625[0m[0m | time: 3.724s
[2K
| Adam | epoch: 021 | loss: 0.55625 - acc: 0.7338 -- iter: 192/334
[A[ATraining Step: 227  | total loss: [1m[32m0.55119[0m[0m | time: 4.010s
[2K
| Adam | epoch: 021 | loss: 0.55119 - acc: 0.7323 -- iter: 224/334
[A[ATraining Step: 228  | total loss: [1m[32m0.53099[0m[0m | time: 4.296s
[2K
| Adam | epoch: 021 | loss: 0.53099 - acc: 0.7519 -- iter: 256/334
[A[ATraining Step: 229  | total loss: [1m[32m0.50745[0m[0m | time: 4.916s
[2K
| Adam | epoch: 021 | loss: 0.50745 - acc: 0.7696 -- iter: 288/334
[A[ATraining Step: 230  | total loss: [1m[32m0.51116[0m[0m | time: 5.533s
[2K
| Adam | epoch: 021 | loss: 0.51116 - acc: 0.7645 -- iter: 320/334
[A[ATraining Step: 231  | total loss: [1m[32m0.50941[0m[0m | time: 7.148s
[2K
| Adam | epoch: 021 | loss: 0.50941 - acc: 0.7662 | val_loss: 0.63446 - val_acc: 0.6762 -- iter: 334/334
--
Training Step: 232  | total loss: [1m[32m0.49605[0m[0m | time: 0.620s
[2K
| Adam | epoch: 022 | loss: 0.49605 - acc: 0.7770 -- iter: 032/334
[A[ATraining Step: 233  | total loss: [1m[32m0.49411[0m[0m | time: 1.257s
[2K
| Adam | epoch: 022 | loss: 0.49411 - acc: 0.7743 -- iter: 064/334
[A[ATraining Step: 234  | total loss: [1m[32m0.47592[0m[0m | time: 1.919s
[2K
| Adam | epoch: 022 | loss: 0.47592 - acc: 0.7844 -- iter: 096/334
[A[ATraining Step: 235  | total loss: [1m[32m0.45620[0m[0m | time: 2.551s
[2K
| Adam | epoch: 022 | loss: 0.45620 - acc: 0.7935 -- iter: 128/334
[A[ATraining Step: 236  | total loss: [1m[32m0.46311[0m[0m | time: 3.174s
[2K
| Adam | epoch: 022 | loss: 0.46311 - acc: 0.7922 -- iter: 160/334
[A[ATraining Step: 237  | total loss: [1m[32m0.46641[0m[0m | time: 3.779s
[2K
| Adam | epoch: 022 | loss: 0.46641 - acc: 0.7943 -- iter: 192/334
[A[ATraining Step: 238  | total loss: [1m[32m0.46438[0m[0m | time: 4.377s
[2K
| Adam | epoch: 022 | loss: 0.46438 - acc: 0.7867 -- iter: 224/334
[A[ATraining Step: 239  | total loss: [1m[32m0.48565[0m[0m | time: 4.667s
[2K
| Adam | epoch: 022 | loss: 0.48565 - acc: 0.7737 -- iter: 256/334
[A[ATraining Step: 240  | total loss: [1m[32m0.47956[0m[0m | time: 4.969s
[2K
| Adam | epoch: 022 | loss: 0.47956 - acc: 0.7749 -- iter: 288/334
[A[ATraining Step: 241  | total loss: [1m[32m0.45709[0m[0m | time: 5.586s
[2K
| Adam | epoch: 022 | loss: 0.45709 - acc: 0.7974 -- iter: 320/334
[A[ATraining Step: 242  | total loss: [1m[32m0.45133[0m[0m | time: 7.276s
[2K
| Adam | epoch: 022 | loss: 0.45133 - acc: 0.8020 | val_loss: 0.62908 - val_acc: 0.6762 -- iter: 334/334
--
Training Step: 243  | total loss: [1m[32m0.45107[0m[0m | time: 0.611s
[2K
| Adam | epoch: 023 | loss: 0.45107 - acc: 0.7968 -- iter: 032/334
[A[ATraining Step: 244  | total loss: [1m[32m0.46415[0m[0m | time: 1.223s
[2K
| Adam | epoch: 023 | loss: 0.46415 - acc: 0.7859 -- iter: 064/334
[A[ATraining Step: 245  | total loss: [1m[32m0.45363[0m[0m | time: 1.835s
[2K
| Adam | epoch: 023 | loss: 0.45363 - acc: 0.7948 -- iter: 096/334
[A[ATraining Step: 246  | total loss: [1m[32m0.44643[0m[0m | time: 2.446s
[2K
| Adam | epoch: 023 | loss: 0.44643 - acc: 0.7966 -- iter: 128/334
[A[ATraining Step: 247  | total loss: [1m[32m0.44845[0m[0m | time: 3.039s
[2K
| Adam | epoch: 023 | loss: 0.44845 - acc: 0.7950 -- iter: 160/334
[A[ATraining Step: 248  | total loss: [1m[32m0.43115[0m[0m | time: 3.653s
[2K
| Adam | epoch: 023 | loss: 0.43115 - acc: 0.8093 -- iter: 192/334
[A[ATraining Step: 249  | total loss: [1m[32m0.42992[0m[0m | time: 4.256s
[2K
| Adam | epoch: 023 | loss: 0.42992 - acc: 0.8065 -- iter: 224/334
[A[ATraining Step: 250  | total loss: [1m[32m0.41879[0m[0m | time: 4.873s
[2K
| Adam | epoch: 023 | loss: 0.41879 - acc: 0.8102 -- iter: 256/334
[A[ATraining Step: 251  | total loss: [1m[32m0.41474[0m[0m | time: 5.161s
[2K
| Adam | epoch: 023 | loss: 0.41474 - acc: 0.8136 -- iter: 288/334
[A[ATraining Step: 252  | total loss: [1m[32m0.41696[0m[0m | time: 5.444s
[2K
| Adam | epoch: 023 | loss: 0.41696 - acc: 0.8108 -- iter: 320/334
[A[ATraining Step: 253  | total loss: [1m[32m0.40399[0m[0m | time: 7.086s
[2K
| Adam | epoch: 023 | loss: 0.40399 - acc: 0.8226 | val_loss: 0.57510 - val_acc: 0.7143 -- iter: 334/334
--
Training Step: 254  | total loss: [1m[32m0.39093[0m[0m | time: 0.636s
[2K
| Adam | epoch: 024 | loss: 0.39093 - acc: 0.8341 -- iter: 032/334
[A[ATraining Step: 255  | total loss: [1m[32m0.38049[0m[0m | time: 1.248s
[2K
| Adam | epoch: 024 | loss: 0.38049 - acc: 0.8381 -- iter: 064/334
[A[ATraining Step: 256  | total loss: [1m[32m0.39536[0m[0m | time: 1.846s
[2K
| Adam | epoch: 024 | loss: 0.39536 - acc: 0.8293 -- iter: 096/334
[A[ATraining Step: 257  | total loss: [1m[32m0.39576[0m[0m | time: 2.448s
[2K
| Adam | epoch: 024 | loss: 0.39576 - acc: 0.8276 -- iter: 128/334
[A[ATraining Step: 258  | total loss: [1m[32m0.38443[0m[0m | time: 3.063s
[2K
| Adam | epoch: 024 | loss: 0.38443 - acc: 0.8355 -- iter: 160/334
[A[ATraining Step: 259  | total loss: [1m[32m0.36253[0m[0m | time: 3.708s
[2K
| Adam | epoch: 024 | loss: 0.36253 - acc: 0.8457 -- iter: 192/334
[A[ATraining Step: 260  | total loss: [1m[32m0.35520[0m[0m | time: 4.311s
[2K
| Adam | epoch: 024 | loss: 0.35520 - acc: 0.8455 -- iter: 224/334
[A[ATraining Step: 261  | total loss: [1m[32m0.33876[0m[0m | time: 4.914s
[2K
| Adam | epoch: 024 | loss: 0.33876 - acc: 0.8578 -- iter: 256/334
[A[ATraining Step: 262  | total loss: [1m[32m0.33051[0m[0m | time: 5.516s
[2K
| Adam | epoch: 024 | loss: 0.33051 - acc: 0.8596 -- iter: 288/334
[A[ATraining Step: 263  | total loss: [1m[32m0.32371[0m[0m | time: 5.817s
[2K
| Adam | epoch: 024 | loss: 0.32371 - acc: 0.8642 -- iter: 320/334
[A[ATraining Step: 264  | total loss: [1m[32m0.30554[0m[0m | time: 7.105s
[2K
| Adam | epoch: 024 | loss: 0.30554 - acc: 0.8707 | val_loss: 0.60559 - val_acc: 0.7524 -- iter: 334/334
--
Training Step: 265  | total loss: [1m[32m0.28715[0m[0m | time: 0.631s
[2K
| Adam | epoch: 025 | loss: 0.28715 - acc: 0.8764 -- iter: 032/334
[A[ATraining Step: 266  | total loss: [1m[32m0.30419[0m[0m | time: 1.242s
[2K
| Adam | epoch: 025 | loss: 0.30419 - acc: 0.8701 -- iter: 064/334
[A[ATraining Step: 267  | total loss: [1m[32m0.30129[0m[0m | time: 1.846s
[2K
| Adam | epoch: 025 | loss: 0.30129 - acc: 0.8705 -- iter: 096/334
[A[ATraining Step: 268  | total loss: [1m[32m0.29190[0m[0m | time: 2.465s
[2K
| Adam | epoch: 025 | loss: 0.29190 - acc: 0.8804 -- iter: 128/334
[A[ATraining Step: 269  | total loss: [1m[32m0.29900[0m[0m | time: 3.067s
[2K
| Adam | epoch: 025 | loss: 0.29900 - acc: 0.8767 -- iter: 160/334
[A[ATraining Step: 270  | total loss: [1m[32m0.28294[0m[0m | time: 3.680s
[2K
| Adam | epoch: 025 | loss: 0.28294 - acc: 0.8859 -- iter: 192/334
[A[ATraining Step: 271  | total loss: [1m[32m0.27131[0m[0m | time: 4.286s
[2K
| Adam | epoch: 025 | loss: 0.27131 - acc: 0.8942 -- iter: 224/334
[A[ATraining Step: 272  | total loss: [1m[32m0.26259[0m[0m | time: 4.887s
[2K
| Adam | epoch: 025 | loss: 0.26259 - acc: 0.8954 -- iter: 256/334
[A[ATraining Step: 273  | total loss: [1m[32m0.24514[0m[0m | time: 5.492s
[2K
| Adam | epoch: 025 | loss: 0.24514 - acc: 0.9027 -- iter: 288/334
[A[ATraining Step: 274  | total loss: [1m[32m0.23171[0m[0m | time: 6.114s
[2K
| Adam | epoch: 025 | loss: 0.23171 - acc: 0.9093 -- iter: 320/334
[A[ATraining Step: 275  | total loss: [1m[32m0.22817[0m[0m | time: 7.408s
[2K
| Adam | epoch: 025 | loss: 0.22817 - acc: 0.9122 | val_loss: 0.43332 - val_acc: 0.8190 -- iter: 334/334
--
Training Step: 276  | total loss: [1m[32m0.21803[0m[0m | time: 0.295s
[2K
| Adam | epoch: 026 | loss: 0.21803 - acc: 0.9138 -- iter: 032/334
[A[ATraining Step: 277  | total loss: [1m[32m0.20242[0m[0m | time: 0.899s
[2K
| Adam | epoch: 026 | loss: 0.20242 - acc: 0.9224 -- iter: 064/334
[A[ATraining Step: 278  | total loss: [1m[32m0.20010[0m[0m | time: 1.530s
[2K
| Adam | epoch: 026 | loss: 0.20010 - acc: 0.9208 -- iter: 096/334
[A[ATraining Step: 279  | total loss: [1m[32m0.18352[0m[0m | time: 2.151s
[2K
| Adam | epoch: 026 | loss: 0.18352 - acc: 0.9287 -- iter: 128/334
[A[ATraining Step: 280  | total loss: [1m[32m0.19421[0m[0m | time: 2.759s
[2K
| Adam | epoch: 026 | loss: 0.19421 - acc: 0.9327 -- iter: 160/334
[A[ATraining Step: 281  | total loss: [1m[32m0.18945[0m[0m | time: 3.362s
[2K
| Adam | epoch: 026 | loss: 0.18945 - acc: 0.9269 -- iter: 192/334
[A[ATraining Step: 282  | total loss: [1m[32m0.18934[0m[0m | time: 3.962s
[2K
| Adam | epoch: 026 | loss: 0.18934 - acc: 0.9311 -- iter: 224/334
[A[ATraining Step: 283  | total loss: [1m[32m0.17750[0m[0m | time: 4.570s
[2K
| Adam | epoch: 026 | loss: 0.17750 - acc: 0.9380 -- iter: 256/334
[A[ATraining Step: 284  | total loss: [1m[32m0.17722[0m[0m | time: 5.179s
[2K
| Adam | epoch: 026 | loss: 0.17722 - acc: 0.9380 -- iter: 288/334
[A[ATraining Step: 285  | total loss: [1m[32m0.16740[0m[0m | time: 5.784s
[2K
| Adam | epoch: 026 | loss: 0.16740 - acc: 0.9410 -- iter: 320/334
[A[ATraining Step: 286  | total loss: [1m[32m0.15430[0m[0m | time: 7.392s
[2K
| Adam | epoch: 026 | loss: 0.15430 - acc: 0.9469 | val_loss: 0.47902 - val_acc: 0.8381 -- iter: 334/334
--
Training Step: 287  | total loss: [1m[32m0.17130[0m[0m | time: 0.301s
[2K
| Adam | epoch: 027 | loss: 0.17130 - acc: 0.9397 -- iter: 032/334
[A[ATraining Step: 288  | total loss: [1m[32m0.16174[0m[0m | time: 0.585s
[2K
| Adam | epoch: 027 | loss: 0.16174 - acc: 0.9386 -- iter: 064/334
[A[ATraining Step: 289  | total loss: [1m[32m0.14820[0m[0m | time: 1.190s
[2K
| Adam | epoch: 027 | loss: 0.14820 - acc: 0.9448 -- iter: 096/334
[A[ATraining Step: 290  | total loss: [1m[32m0.13548[0m[0m | time: 1.805s
[2K
| Adam | epoch: 027 | loss: 0.13548 - acc: 0.9503 -- iter: 128/334
[A[ATraining Step: 291  | total loss: [1m[32m0.15495[0m[0m | time: 2.434s
[2K
| Adam | epoch: 027 | loss: 0.15495 - acc: 0.9459 -- iter: 160/334
[A[ATraining Step: 292  | total loss: [1m[32m0.18586[0m[0m | time: 3.035s
[2K
| Adam | epoch: 027 | loss: 0.18586 - acc: 0.9419 -- iter: 192/334
[A[ATraining Step: 293  | total loss: [1m[32m0.18609[0m[0m | time: 3.653s
[2K
| Adam | epoch: 027 | loss: 0.18609 - acc: 0.9384 -- iter: 224/334
[A[ATraining Step: 294  | total loss: [1m[32m0.17030[0m[0m | time: 4.263s
[2K
| Adam | epoch: 027 | loss: 0.17030 - acc: 0.9445 -- iter: 256/334
[A[ATraining Step: 295  | total loss: [1m[32m0.18691[0m[0m | time: 4.864s
[2K
| Adam | epoch: 027 | loss: 0.18691 - acc: 0.9407 -- iter: 288/334
[A[ATraining Step: 296  | total loss: [1m[32m0.19031[0m[0m | time: 5.460s
[2K
| Adam | epoch: 027 | loss: 0.19031 - acc: 0.9372 -- iter: 320/334
[A[ATraining Step: 297  | total loss: [1m[32m0.20141[0m[0m | time: 7.079s
[2K
| Adam | epoch: 027 | loss: 0.20141 - acc: 0.9279 | val_loss: 0.38803 - val_acc: 0.8190 -- iter: 334/334
--
Training Step: 298  | total loss: [1m[32m0.18838[0m[0m | time: 0.620s
[2K
| Adam | epoch: 028 | loss: 0.18838 - acc: 0.9351 -- iter: 032/334
[A[ATraining Step: 299  | total loss: [1m[32m0.17344[0m[0m | time: 0.922s
[2K
| Adam | epoch: 028 | loss: 0.17344 - acc: 0.9416 -- iter: 064/334
[A[ATraining Step: 300  | total loss: [1m[32m0.17922[0m[0m | time: 1.205s
[2K
| Adam | epoch: 028 | loss: 0.17922 - acc: 0.9403 -- iter: 096/334
[A[ATraining Step: 301  | total loss: [1m[32m0.17054[0m[0m | time: 1.831s
[2K
| Adam | epoch: 028 | loss: 0.17054 - acc: 0.9463 -- iter: 128/334
[A[ATraining Step: 302  | total loss: [1m[32m0.16612[0m[0m | time: 2.436s
[2K
| Adam | epoch: 028 | loss: 0.16612 - acc: 0.9454 -- iter: 160/334
[A[ATraining Step: 303  | total loss: [1m[32m0.15319[0m[0m | time: 3.034s
[2K
| Adam | epoch: 028 | loss: 0.15319 - acc: 0.9508 -- iter: 192/334
[A[ATraining Step: 304  | total loss: [1m[32m0.14262[0m[0m | time: 3.634s
[2K
| Adam | epoch: 028 | loss: 0.14262 - acc: 0.9558 -- iter: 224/334
[A[ATraining Step: 305  | total loss: [1m[32m0.13091[0m[0m | time: 4.237s
[2K
| Adam | epoch: 028 | loss: 0.13091 - acc: 0.9602 -- iter: 256/334
[A[ATraining Step: 306  | total loss: [1m[32m0.12455[0m[0m | time: 4.828s
[2K
| Adam | epoch: 028 | loss: 0.12455 - acc: 0.9610 -- iter: 288/334
[A[ATraining Step: 307  | total loss: [1m[32m0.12549[0m[0m | time: 5.447s
[2K
| Adam | epoch: 028 | loss: 0.12549 - acc: 0.9587 -- iter: 320/334
[A[ATraining Step: 308  | total loss: [1m[32m0.11754[0m[0m | time: 7.058s
[2K
| Adam | epoch: 028 | loss: 0.11754 - acc: 0.9628 | val_loss: 0.64706 - val_acc: 0.8000 -- iter: 334/334
--
Training Step: 309  | total loss: [1m[32m0.12782[0m[0m | time: 0.634s
[2K
| Adam | epoch: 029 | loss: 0.12782 - acc: 0.9603 -- iter: 032/334
[A[ATraining Step: 310  | total loss: [1m[32m0.12375[0m[0m | time: 1.248s
[2K
| Adam | epoch: 029 | loss: 0.12375 - acc: 0.9611 -- iter: 064/334
[A[ATraining Step: 311  | total loss: [1m[32m0.13595[0m[0m | time: 1.551s
[2K
| Adam | epoch: 029 | loss: 0.13595 - acc: 0.9588 -- iter: 096/334
[A[ATraining Step: 312  | total loss: [1m[32m0.12520[0m[0m | time: 1.847s
[2K
| Adam | epoch: 029 | loss: 0.12520 - acc: 0.9629 -- iter: 128/334
[A[ATraining Step: 313  | total loss: [1m[32m0.11665[0m[0m | time: 2.450s
[2K
| Adam | epoch: 029 | loss: 0.11665 - acc: 0.9666 -- iter: 160/334
[A[ATraining Step: 314  | total loss: [1m[32m0.11143[0m[0m | time: 3.042s
[2K
| Adam | epoch: 029 | loss: 0.11143 - acc: 0.9668 -- iter: 192/334
[A[ATraining Step: 315  | total loss: [1m[32m0.10842[0m[0m | time: 3.819s
[2K
| Adam | epoch: 029 | loss: 0.10842 - acc: 0.9670 -- iter: 224/334
[A[ATraining Step: 316  | total loss: [1m[32m0.15154[0m[0m | time: 4.443s
[2K
| Adam | epoch: 029 | loss: 0.15154 - acc: 0.9609 -- iter: 256/334
[A[ATraining Step: 317  | total loss: [1m[32m0.13969[0m[0m | time: 5.098s
[2K
| Adam | epoch: 029 | loss: 0.13969 - acc: 0.9648 -- iter: 288/334
[A[ATraining Step: 318  | total loss: [1m[32m0.14036[0m[0m | time: 5.701s
[2K
| Adam | epoch: 029 | loss: 0.14036 - acc: 0.9652 -- iter: 320/334
[A[ATraining Step: 319  | total loss: [1m[32m0.14341[0m[0m | time: 7.315s
[2K
| Adam | epoch: 029 | loss: 0.14341 - acc: 0.9625 | val_loss: 0.44781 - val_acc: 0.8286 -- iter: 334/334
--
Training Step: 320  | total loss: [1m[32m0.13249[0m[0m | time: 0.604s
[2K
| Adam | epoch: 030 | loss: 0.13249 - acc: 0.9662 -- iter: 032/334
[A[ATraining Step: 321  | total loss: [1m[32m0.12484[0m[0m | time: 1.218s
[2K
| Adam | epoch: 030 | loss: 0.12484 - acc: 0.9665 -- iter: 064/334
[A[ATraining Step: 322  | total loss: [1m[32m0.11781[0m[0m | time: 1.820s
[2K
| Adam | epoch: 030 | loss: 0.11781 - acc: 0.9667 -- iter: 096/334
[A[ATraining Step: 323  | total loss: [1m[32m0.10859[0m[0m | time: 2.125s
[2K
| Adam | epoch: 030 | loss: 0.10859 - acc: 0.9700 -- iter: 128/334
[A[ATraining Step: 324  | total loss: [1m[32m0.09922[0m[0m | time: 2.411s
[2K
| Adam | epoch: 030 | loss: 0.09922 - acc: 0.9730 -- iter: 160/334
[A[ATraining Step: 325  | total loss: [1m[32m0.09080[0m[0m | time: 3.030s
[2K
| Adam | epoch: 030 | loss: 0.09080 - acc: 0.9757 -- iter: 192/334
[A[ATraining Step: 326  | total loss: [1m[32m0.08683[0m[0m | time: 3.644s
[2K
| Adam | epoch: 030 | loss: 0.08683 - acc: 0.9750 -- iter: 224/334
[A[ATraining Step: 327  | total loss: [1m[32m0.09280[0m[0m | time: 4.236s
[2K
| Adam | epoch: 030 | loss: 0.09280 - acc: 0.9713 -- iter: 256/334
[A[ATraining Step: 328  | total loss: [1m[32m0.10855[0m[0m | time: 4.848s
[2K
| Adam | epoch: 030 | loss: 0.10855 - acc: 0.9679 -- iter: 288/334
[A[ATraining Step: 329  | total loss: [1m[32m0.10494[0m[0m | time: 5.456s
[2K
| Adam | epoch: 030 | loss: 0.10494 - acc: 0.9680 -- iter: 320/334
[A[ATraining Step: 330  | total loss: [1m[32m0.09612[0m[0m | time: 7.050s
[2K
| Adam | epoch: 030 | loss: 0.09612 - acc: 0.9712 | val_loss: 0.46931 - val_acc: 0.8381 -- iter: 334/334
--
Validation AUC:0.9060672514619883
Validation AUPRC:0.9004237041400304
Test AUC:0.9055555555555556
Test AUPRC:0.8865623978641943
BestTestF1Score	0.77	0.61	0.81	0.8	0.73	33	8	52	12	0.69
BestTestMCCScore	0.79	0.65	0.83	0.85	0.73	33	6	54	12	0.85
BestTestAccuracyScore	0.79	0.65	0.83	0.85	0.73	33	6	54	12	0.85
BestValidationF1Score	0.83	0.72	0.86	0.9	0.77	37	4	53	11	0.69
BestValidationMCC	0.82	0.72	0.86	0.95	0.73	35	2	55	13	0.85
BestValidationAccuracy	0.82	0.72	0.86	0.95	0.73	35	2	55	13	0.85
TestPredictions (Threshold:0.85)
CHEMBL3809853,TP,ACT,1.0	CHEMBL3113257,TN,INACT,0.009999999776482582	CHEMBL3808631,FN,ACT,0.5	CHEMBL3632691,TP,ACT,0.9200000166893005	CHEMBL522211,TN,INACT,0.30000001192092896	CHEMBL2018453,TN,INACT,0.009999999776482582	CHEMBL518689,TN,INACT,0.0	CHEMBL3657943,TP,ACT,0.9800000190734863	CHEMBL498932,TN,INACT,0.03999999910593033	CHEMBL473499,TN,INACT,0.0	CHEMBL3337583,FN,ACT,0.05999999865889549	CHEMBL3221247,TN,INACT,0.0	CHEMBL558900,TN,INACT,0.7900000214576721	CHEMBL2325264,TN,INACT,0.0	CHEMBL320332,FN,ACT,0.28999999165534973	CHEMBL3808737,TP,ACT,0.9900000095367432	CHEMBL3797461,TP,ACT,0.9800000190734863	CHEMBL3654182,FN,ACT,0.46000000834465027	CHEMBL2380905,TN,INACT,0.009999999776482582	CHEMBL2381003,TN,INACT,0.0	CHEMBL3687593,TN,INACT,0.23000000417232513	CHEMBL108782,TP,ACT,0.9900000095367432	CHEMBL426096,TN,INACT,0.019999999552965164	CHEMBL3337601,FN,ACT,0.6499999761581421	CHEMBL3260892,TN,INACT,0.0	CHEMBL40078,TN,INACT,0.0	CHEMBL3416934,TP,ACT,0.9399999976158142	CHEMBL3262807,FP,INACT,0.9100000262260437	CHEMBL2380903,TN,INACT,0.0	CHEMBL372177,TN,INACT,0.009999999776482582	CHEMBL3221241,TN,INACT,0.029999999329447746	CHEMBL2147306,TP,ACT,1.0	CHEMBL2262244,TN,INACT,0.11999999731779099	CHEMBL552193,TN,INACT,0.019999999552965164	CHEMBL2262232,TN,INACT,0.029999999329447746	CHEMBL3589894,FN,ACT,0.0	CHEMBL3809904,TP,ACT,1.0	CHEMBL3808867,TP,ACT,0.9800000190734863	CHEMBL3657934,TP,ACT,0.9900000095367432	CHEMBL37379,TN,INACT,0.009999999776482582	CHEMBL3687605,TN,INACT,0.07000000029802322	CHEMBL2164384,FN,ACT,0.05999999865889549	CHEMBL2409401,TN,INACT,0.0	CHEMBL3657998,TP,ACT,0.9900000095367432	CHEMBL2262250,TN,INACT,0.009999999776482582	CHEMBL2381037,TN,INACT,0.009999999776482582	CHEMBL521211,FN,ACT,0.03999999910593033	CHEMBL2069408,TP,ACT,0.9900000095367432	CHEMBL2262231,TN,INACT,0.009999999776482582	CHEMBL2069423,TP,ACT,1.0	CHEMBL3657965,FP,INACT,0.9900000095367432	CHEMBL2069404,TP,ACT,0.9700000286102295	CHEMBL3085866,TN,INACT,0.029999999329447746	CHEMBL2164389,TP,ACT,0.9900000095367432	CHEMBL2324978,TN,INACT,0.17000000178813934	CHEMBL3262797,TN,INACT,0.009999999776482582	CHEMBL698,TP,ACT,0.9900000095367432	CHEMBL3657930,TP,ACT,0.9599999785423279	CHEMBL1797402,FN,ACT,0.029999999329447746	CHEMBL3337591,FN,ACT,0.009999999776482582	CHEMBL3634333,TN,INACT,0.7400000095367432	CHEMBL3085869,TN,INACT,0.019999999552965164	CHEMBL2325260,TN,INACT,0.009999999776482582	CHEMBL3337597,TP,ACT,0.9800000190734863	CHEMBL3127394,TN,INACT,0.0	CHEMBL3236329,TN,INACT,0.019999999552965164	CHEMBL3589892,FP,INACT,0.9599999785423279	CHEMBL3337596,FN,ACT,0.3400000035762787	CHEMBL3085868,TN,INACT,0.0	CHEMBL2069421,TP,ACT,1.0	CHEMBL3687594,TP,ACT,0.9800000190734863	CHEMBL3798460,FP,INACT,0.8999999761581421	CHEMBL594891,FP,INACT,0.9399999976158142	CHEMBL3800461,TP,ACT,0.9700000286102295	CHEMBL3262796,TN,INACT,0.4000000059604645	CHEMBL2147211,TP,ACT,1.0	CHEMBL400960,TN,INACT,0.029999999329447746	CHEMBL147507,TN,INACT,0.0	CHEMBL2381042,TN,INACT,0.009999999776482582	CHEMBL210829,TN,INACT,0.009999999776482582	CHEMBL2069420,TP,ACT,0.9900000095367432	CHEMBL3261115,TN,INACT,0.0	CHEMBL2325262,TN,INACT,0.0	CHEMBL3113255,TN,INACT,0.33000001311302185	CHEMBL2069413,TP,ACT,0.9900000095367432	CHEMBL2381043,TN,INACT,0.009999999776482582	CHEMBL108361,TP,ACT,1.0	CHEMBL3126834,TN,INACT,0.009999999776482582	CHEMBL3808917,TP,ACT,0.9900000095367432	CHEMBL3617065,TP,ACT,0.8700000047683716	CHEMBL3662090,TP,ACT,0.9800000190734863	CHEMBL3810153,TP,ACT,1.0	CHEMBL2409410,TN,INACT,0.019999999552965164	CHEMBL105782,TN,INACT,0.12999999523162842	CHEMBL2069417,TN,INACT,0.4000000059604645	CHEMBL114903,TN,INACT,0.0	CHEMBL23,TN,INACT,0.009999999776482582	CHEMBL2164383,FN,ACT,0.09000000357627869	CHEMBL3113246,TN,INACT,0.009999999776482582	CHEMBL3800069,TP,ACT,0.8500000238418579	CHEMBL3682649,TP,ACT,0.8899999856948853	CHEMBL3236343,FP,INACT,0.9800000190734863	CHEMBL2324980,TN,INACT,0.009999999776482582	CHEMBL3416930,TP,ACT,0.9700000286102295	CHEMBL3113263,TN,INACT,0.0	

