ImageNetInceptionV2 CHEMBL4600 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	186
Number of inactive compounds :	186
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4600_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4600_adam_0.0005_15_0.8/
---------------------------------
Training samples: 237
Validation samples: 75
--
Training Step: 1  | time: 69.855s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/237
[A[ATraining Step: 2  | total loss: [1m[32m0.60228[0m[0m | time: 82.656s
[2K
| Adam | epoch: 001 | loss: 0.60228 - acc: 0.5625 -- iter: 064/237
[A[ATraining Step: 3  | total loss: [1m[32m0.78151[0m[0m | time: 95.012s
[2K
| Adam | epoch: 001 | loss: 0.78151 - acc: 0.5881 -- iter: 096/237
[A[ATraining Step: 4  | total loss: [1m[32m0.61682[0m[0m | time: 107.460s
[2K
| Adam | epoch: 001 | loss: 0.61682 - acc: 0.7095 -- iter: 128/237
[A[ATraining Step: 5  | total loss: [1m[32m0.57497[0m[0m | time: 119.759s
[2K
| Adam | epoch: 001 | loss: 0.57497 - acc: 0.7592 -- iter: 160/237
[A[ATraining Step: 6  | total loss: [1m[32m0.45970[0m[0m | time: 138.898s
[2K
| Adam | epoch: 001 | loss: 0.45970 - acc: 0.8537 -- iter: 192/237
[A[ATraining Step: 7  | total loss: [1m[32m0.42051[0m[0m | time: 151.252s
[2K
| Adam | epoch: 001 | loss: 0.42051 - acc: 0.8665 -- iter: 224/237
[A[ATraining Step: 8  | total loss: [1m[32m0.41071[0m[0m | time: 174.512s
[2K
| Adam | epoch: 001 | loss: 0.41071 - acc: 0.8361 | val_loss: 1.08084 - val_acc: 0.4667 -- iter: 237/237
--
Training Step: 9  | total loss: [1m[32m0.24364[0m[0m | time: 6.118s
[2K
| Adam | epoch: 002 | loss: 0.24364 - acc: 0.9229 -- iter: 032/237
[A[ATraining Step: 10  | total loss: [1m[32m0.13442[0m[0m | time: 18.022s
[2K
| Adam | epoch: 002 | loss: 0.13442 - acc: 0.9614 -- iter: 064/237
[A[ATraining Step: 11  | total loss: [1m[32m0.35950[0m[0m | time: 29.984s
[2K
| Adam | epoch: 002 | loss: 0.35950 - acc: 0.8317 -- iter: 096/237
[A[ATraining Step: 12  | total loss: [1m[32m0.45625[0m[0m | time: 42.070s
[2K
| Adam | epoch: 002 | loss: 0.45625 - acc: 0.8371 -- iter: 128/237
[A[ATraining Step: 13  | total loss: [1m[32m0.88491[0m[0m | time: 54.358s
[2K
| Adam | epoch: 002 | loss: 0.88491 - acc: 0.7730 -- iter: 160/237
[A[ATraining Step: 14  | total loss: [1m[32m0.64484[0m[0m | time: 66.735s
[2K
| Adam | epoch: 002 | loss: 0.64484 - acc: 0.8019 -- iter: 192/237
[A[ATraining Step: 15  | total loss: [1m[32m0.63382[0m[0m | time: 78.808s
[2K
| Adam | epoch: 002 | loss: 0.63382 - acc: 0.7449 -- iter: 224/237
[A[ATraining Step: 16  | total loss: [1m[32m0.44656[0m[0m | time: 96.711s
[2K
| Adam | epoch: 002 | loss: 0.44656 - acc: 0.8406 | val_loss: 1.99472 - val_acc: 0.4667 -- iter: 237/237
--
Training Step: 17  | total loss: [1m[32m0.35690[0m[0m | time: 6.180s
[2K
| Adam | epoch: 003 | loss: 0.35690 - acc: 0.8755 -- iter: 032/237
[A[ATraining Step: 18  | total loss: [1m[32m0.30869[0m[0m | time: 12.142s
[2K
| Adam | epoch: 003 | loss: 0.30869 - acc: 0.9186 -- iter: 064/237
[A[ATraining Step: 19  | total loss: [1m[32m0.23557[0m[0m | time: 24.276s
[2K
| Adam | epoch: 003 | loss: 0.23557 - acc: 0.9457 -- iter: 096/237
[A[ATraining Step: 20  | total loss: [1m[32m0.26604[0m[0m | time: 37.009s
[2K
| Adam | epoch: 003 | loss: 0.26604 - acc: 0.9129 -- iter: 128/237
[A[ATraining Step: 21  | total loss: [1m[32m0.32124[0m[0m | time: 49.747s
[2K
| Adam | epoch: 003 | loss: 0.32124 - acc: 0.8915 -- iter: 160/237
[A[ATraining Step: 22  | total loss: [1m[32m0.32899[0m[0m | time: 62.702s
[2K
| Adam | epoch: 003 | loss: 0.32899 - acc: 0.8959 -- iter: 192/237
[A[ATraining Step: 23  | total loss: [1m[32m0.28152[0m[0m | time: 74.221s
[2K
| Adam | epoch: 003 | loss: 0.28152 - acc: 0.8989 -- iter: 224/237
[A[ATraining Step: 24  | total loss: [1m[32m0.29603[0m[0m | time: 85.493s
[2K
| Adam | epoch: 003 | loss: 0.29603 - acc: 0.8746 | val_loss: 5.10129 - val_acc: 0.4667 -- iter: 237/237
--
Training Step: 25  | total loss: [1m[32m0.26287[0m[0m | time: 12.201s
[2K
| Adam | epoch: 004 | loss: 0.26287 - acc: 0.8832 -- iter: 032/237
[A[ATraining Step: 26  | total loss: [1m[32m0.22684[0m[0m | time: 18.233s
[2K
| Adam | epoch: 004 | loss: 0.22684 - acc: 0.8976 -- iter: 064/237
[A[ATraining Step: 27  | total loss: [1m[32m0.21627[0m[0m | time: 24.419s
[2K
| Adam | epoch: 004 | loss: 0.21627 - acc: 0.9042 -- iter: 096/237
[A[ATraining Step: 28  | total loss: [1m[32m0.18001[0m[0m | time: 36.504s
[2K
| Adam | epoch: 004 | loss: 0.18001 - acc: 0.9281 -- iter: 128/237
[A[ATraining Step: 29  | total loss: [1m[32m0.15907[0m[0m | time: 48.465s
[2K
| Adam | epoch: 004 | loss: 0.15907 - acc: 0.9456 -- iter: 160/237
[A[ATraining Step: 30  | total loss: [1m[32m0.14343[0m[0m | time: 60.136s
[2K
| Adam | epoch: 004 | loss: 0.14343 - acc: 0.9511 -- iter: 192/237
[A[ATraining Step: 31  | total loss: [1m[32m0.12061[0m[0m | time: 71.246s
[2K
| Adam | epoch: 004 | loss: 0.12061 - acc: 0.9624 -- iter: 224/237
[A[ATraining Step: 32  | total loss: [1m[32m0.10675[0m[0m | time: 88.332s
[2K
| Adam | epoch: 004 | loss: 0.10675 - acc: 0.9638 | val_loss: 4.21051 - val_acc: 0.4667 -- iter: 237/237
--
Training Step: 33  | total loss: [1m[32m0.09016[0m[0m | time: 11.904s
[2K
| Adam | epoch: 005 | loss: 0.09016 - acc: 0.9718 -- iter: 032/237
[A[ATraining Step: 34  | total loss: [1m[32m0.08140[0m[0m | time: 23.906s
[2K
| Adam | epoch: 005 | loss: 0.08140 - acc: 0.9778 -- iter: 064/237
[A[ATraining Step: 35  | total loss: [1m[32m0.11754[0m[0m | time: 29.893s
[2K
| Adam | epoch: 005 | loss: 0.11754 - acc: 0.9563 -- iter: 096/237
[A[ATraining Step: 36  | total loss: [1m[32m0.13576[0m[0m | time: 36.259s
[2K
| Adam | epoch: 005 | loss: 0.13576 - acc: 0.9338 -- iter: 128/237
[A[ATraining Step: 37  | total loss: [1m[32m0.12093[0m[0m | time: 48.069s
[2K
| Adam | epoch: 005 | loss: 0.12093 - acc: 0.9470 -- iter: 160/237
[A[ATraining Step: 38  | total loss: [1m[32m0.15839[0m[0m | time: 60.444s
[2K
| Adam | epoch: 005 | loss: 0.15839 - acc: 0.9451 -- iter: 192/237
[A[ATraining Step: 39  | total loss: [1m[32m0.17080[0m[0m | time: 72.667s
[2K
| Adam | epoch: 005 | loss: 0.17080 - acc: 0.9437 -- iter: 224/237
[A[ATraining Step: 40  | total loss: [1m[32m0.14073[0m[0m | time: 90.142s
[2K
| Adam | epoch: 005 | loss: 0.14073 - acc: 0.9542 | val_loss: 6.11635 - val_acc: 0.4667 -- iter: 237/237
--
Training Step: 41  | total loss: [1m[32m0.13188[0m[0m | time: 11.718s
[2K
| Adam | epoch: 006 | loss: 0.13188 - acc: 0.9569 -- iter: 032/237
[A[ATraining Step: 42  | total loss: [1m[32m0.12944[0m[0m | time: 49.433s
[2K
| Adam | epoch: 006 | loss: 0.12944 - acc: 0.9534 -- iter: 064/237
[A[ATraining Step: 43  | total loss: [1m[32m0.12613[0m[0m | time: 97.707s
[2K
| Adam | epoch: 006 | loss: 0.12613 - acc: 0.9561 -- iter: 096/237
[A[ATraining Step: 44  | total loss: [1m[32m0.10819[0m[0m | time: 103.635s
[2K
| Adam | epoch: 006 | loss: 0.10819 - acc: 0.9637 -- iter: 128/237
[A[ATraining Step: 45  | total loss: [1m[32m0.11299[0m[0m | time: 109.722s
[2K
| Adam | epoch: 006 | loss: 0.11299 - acc: 0.9699 -- iter: 160/237
[A[ATraining Step: 46  | total loss: [1m[32m0.10299[0m[0m | time: 129.940s
[2K
| Adam | epoch: 006 | loss: 0.10299 - acc: 0.9749 -- iter: 192/237
[A[ATraining Step: 47  | total loss: [1m[32m0.09559[0m[0m | time: 161.809s
[2K
| Adam | epoch: 006 | loss: 0.09559 - acc: 0.9739 -- iter: 224/237
[A[ATraining Step: 48  | total loss: [1m[32m0.08771[0m[0m | time: 179.323s
[2K
| Adam | epoch: 006 | loss: 0.08771 - acc: 0.9781 | val_loss: 3.05810 - val_acc: 0.4667 -- iter: 237/237
--
Training Step: 49  | total loss: [1m[32m0.20396[0m[0m | time: 12.630s
[2K
| Adam | epoch: 007 | loss: 0.20396 - acc: 0.9569 -- iter: 032/237
[A[ATraining Step: 50  | total loss: [1m[32m0.17914[0m[0m | time: 25.317s
[2K
| Adam | epoch: 007 | loss: 0.17914 - acc: 0.9587 -- iter: 064/237
[A[ATraining Step: 51  | total loss: [1m[32m0.16236[0m[0m | time: 36.753s
[2K
| Adam | epoch: 007 | loss: 0.16236 - acc: 0.9602 -- iter: 096/237
[A[ATraining Step: 52  | total loss: [1m[32m0.14038[0m[0m | time: 44.447s
[2K
| Adam | epoch: 007 | loss: 0.14038 - acc: 0.9662 -- iter: 128/237
[A[ATraining Step: 53  | total loss: [1m[32m0.12453[0m[0m | time: 49.161s
[2K
| Adam | epoch: 007 | loss: 0.12453 - acc: 0.9712 -- iter: 160/237
[A[ATraining Step: 54  | total loss: [1m[32m0.11836[0m[0m | time: 55.034s
[2K
| Adam | epoch: 007 | loss: 0.11836 - acc: 0.9754 -- iter: 192/237
[A[ATraining Step: 55  | total loss: [1m[32m0.10299[0m[0m | time: 66.750s
[2K
| Adam | epoch: 007 | loss: 0.10299 - acc: 0.9789 -- iter: 224/237
[A[ATraining Step: 56  | total loss: [1m[32m0.10276[0m[0m | time: 84.078s
[2K
| Adam | epoch: 007 | loss: 0.10276 - acc: 0.9775 | val_loss: 2.46724 - val_acc: 0.4667 -- iter: 237/237
--
Training Step: 57  | total loss: [1m[32m0.09729[0m[0m | time: 11.730s
[2K
| Adam | epoch: 008 | loss: 0.09729 - acc: 0.9763 -- iter: 032/237
[A[ATraining Step: 58  | total loss: [1m[32m0.08863[0m[0m | time: 24.125s
[2K
| Adam | epoch: 008 | loss: 0.08863 - acc: 0.9795 -- iter: 064/237
[A[ATraining Step: 59  | total loss: [1m[32m0.09544[0m[0m | time: 36.016s
[2K
| Adam | epoch: 008 | loss: 0.09544 - acc: 0.9739 -- iter: 096/237
[A[ATraining Step: 60  | total loss: [1m[32m0.10594[0m[0m | time: 48.213s
[2K
| Adam | epoch: 008 | loss: 0.10594 - acc: 0.9690 -- iter: 128/237
[A[ATraining Step: 61  | total loss: [1m[32m0.09986[0m[0m | time: 60.085s
[2K
| Adam | epoch: 008 | loss: 0.09986 - acc: 0.9690 -- iter: 160/237
[A[ATraining Step: 62  | total loss: [1m[32m0.08978[0m[0m | time: 66.452s
[2K
| Adam | epoch: 008 | loss: 0.08978 - acc: 0.9730 -- iter: 192/237
[A[ATraining Step: 63  | total loss: [1m[32m0.10976[0m[0m | time: 72.125s
[2K
| Adam | epoch: 008 | loss: 0.10976 - acc: 0.9569 -- iter: 224/237
[A[ATraining Step: 64  | total loss: [1m[32m0.09830[0m[0m | time: 89.426s
[2K
| Adam | epoch: 008 | loss: 0.09830 - acc: 0.9623 | val_loss: 8.03715 - val_acc: 0.5333 -- iter: 237/237
--
Training Step: 65  | total loss: [1m[32m0.09644[0m[0m | time: 11.991s
[2K
| Adam | epoch: 009 | loss: 0.09644 - acc: 0.9631 -- iter: 032/237
[A[ATraining Step: 66  | total loss: [1m[32m0.08798[0m[0m | time: 24.033s
[2K
| Adam | epoch: 009 | loss: 0.08798 - acc: 0.9676 -- iter: 064/237
[A[ATraining Step: 67  | total loss: [1m[32m0.07979[0m[0m | time: 36.179s
[2K
| Adam | epoch: 009 | loss: 0.07979 - acc: 0.9715 -- iter: 096/237
[A[ATraining Step: 68  | total loss: [1m[32m0.07150[0m[0m | time: 48.248s
[2K
| Adam | epoch: 009 | loss: 0.07150 - acc: 0.9749 -- iter: 128/237
[A[ATraining Step: 69  | total loss: [1m[32m0.06724[0m[0m | time: 60.323s
[2K
| Adam | epoch: 009 | loss: 0.06724 - acc: 0.9778 -- iter: 160/237
[A[ATraining Step: 70  | total loss: [1m[32m0.08756[0m[0m | time: 72.210s
[2K
| Adam | epoch: 009 | loss: 0.08756 - acc: 0.9731 -- iter: 192/237
[A[ATraining Step: 71  | total loss: [1m[32m0.10802[0m[0m | time: 78.375s
[2K
| Adam | epoch: 009 | loss: 0.10802 - acc: 0.9620 -- iter: 224/237
[A[ATraining Step: 72  | total loss: [1m[32m0.10744[0m[0m | time: 90.154s
[2K
| Adam | epoch: 009 | loss: 0.10744 - acc: 0.9576 | val_loss: 0.65639 - val_acc: 0.8133 -- iter: 237/237
--
Training Step: 73  | total loss: [1m[32m0.09705[0m[0m | time: 11.928s
[2K
| Adam | epoch: 010 | loss: 0.09705 - acc: 0.9623 -- iter: 032/237
[A[ATraining Step: 74  | total loss: [1m[32m0.09507[0m[0m | time: 23.994s
[2K
| Adam | epoch: 010 | loss: 0.09507 - acc: 0.9630 -- iter: 064/237
[A[ATraining Step: 75  | total loss: [1m[32m0.08769[0m[0m | time: 36.251s
[2K
| Adam | epoch: 010 | loss: 0.08769 - acc: 0.9670 -- iter: 096/237
[A[ATraining Step: 76  | total loss: [1m[32m0.13033[0m[0m | time: 48.244s
[2K
| Adam | epoch: 010 | loss: 0.13033 - acc: 0.9639 -- iter: 128/237
[A[ATraining Step: 77  | total loss: [1m[32m0.11893[0m[0m | time: 60.608s
[2K
| Adam | epoch: 010 | loss: 0.11893 - acc: 0.9677 -- iter: 160/237
[A[ATraining Step: 78  | total loss: [1m[32m0.10782[0m[0m | time: 72.561s
[2K
| Adam | epoch: 010 | loss: 0.10782 - acc: 0.9711 -- iter: 192/237
[A[ATraining Step: 79  | total loss: [1m[32m0.11315[0m[0m | time: 84.313s
[2K
| Adam | epoch: 010 | loss: 0.11315 - acc: 0.9676 -- iter: 224/237
[A[ATraining Step: 80  | total loss: [1m[32m0.10315[0m[0m | time: 95.852s
[2K
| Adam | epoch: 010 | loss: 0.10315 - acc: 0.9709 | val_loss: 1.45763 - val_acc: 0.6133 -- iter: 237/237
--
Training Step: 81  | total loss: [1m[32m0.09502[0m[0m | time: 6.693s
[2K
| Adam | epoch: 011 | loss: 0.09502 - acc: 0.9738 -- iter: 032/237
[A[ATraining Step: 82  | total loss: [1m[32m0.08649[0m[0m | time: 19.925s
[2K
| Adam | epoch: 011 | loss: 0.08649 - acc: 0.9765 -- iter: 064/237
[A[ATraining Step: 83  | total loss: [1m[32m0.08033[0m[0m | time: 33.059s
[2K
| Adam | epoch: 011 | loss: 0.08033 - acc: 0.9788 -- iter: 096/237
[A[ATraining Step: 84  | total loss: [1m[32m0.07430[0m[0m | time: 43.626s
[2K
| Adam | epoch: 011 | loss: 0.07430 - acc: 0.9809 -- iter: 128/237
[A[ATraining Step: 85  | total loss: [1m[32m0.09074[0m[0m | time: 51.486s
[2K
| Adam | epoch: 011 | loss: 0.09074 - acc: 0.9797 -- iter: 160/237
[A[ATraining Step: 86  | total loss: [1m[32m0.08238[0m[0m | time: 59.271s
[2K
| Adam | epoch: 011 | loss: 0.08238 - acc: 0.9817 -- iter: 192/237
[A[ATraining Step: 87  | total loss: [1m[32m0.07536[0m[0m | time: 69.136s
[2K
| Adam | epoch: 011 | loss: 0.07536 - acc: 0.9836 -- iter: 224/237
[A[ATraining Step: 88  | total loss: [1m[32m0.06832[0m[0m | time: 86.629s
[2K
| Adam | epoch: 011 | loss: 0.06832 - acc: 0.9852 | val_loss: 1.18215 - val_acc: 0.7600 -- iter: 237/237
--
Training Step: 89  | total loss: [1m[32m0.06189[0m[0m | time: 6.347s
[2K
| Adam | epoch: 012 | loss: 0.06189 - acc: 0.9867 -- iter: 032/237
[A[ATraining Step: 90  | total loss: [1m[32m0.05637[0m[0m | time: 12.829s
[2K
| Adam | epoch: 012 | loss: 0.05637 - acc: 0.9880 -- iter: 064/237
[A[ATraining Step: 91  | total loss: [1m[32m0.05123[0m[0m | time: 24.931s
[2K
| Adam | epoch: 012 | loss: 0.05123 - acc: 0.9892 -- iter: 096/237
[A[ATraining Step: 92  | total loss: [1m[32m0.04670[0m[0m | time: 36.002s
[2K
| Adam | epoch: 012 | loss: 0.04670 - acc: 0.9903 -- iter: 128/237
[A[ATraining Step: 93  | total loss: [1m[32m0.04335[0m[0m | time: 47.230s
[2K
| Adam | epoch: 012 | loss: 0.04335 - acc: 0.9913 -- iter: 160/237
[A[ATraining Step: 94  | total loss: [1m[32m0.05908[0m[0m | time: 59.165s
[2K
| Adam | epoch: 012 | loss: 0.05908 - acc: 0.9890 -- iter: 192/237
[A[ATraining Step: 95  | total loss: [1m[32m0.05431[0m[0m | time: 71.236s
[2K
| Adam | epoch: 012 | loss: 0.05431 - acc: 0.9901 -- iter: 224/237
[A[ATraining Step: 96  | total loss: [1m[32m0.05066[0m[0m | time: 88.550s
[2K
| Adam | epoch: 012 | loss: 0.05066 - acc: 0.9911 | val_loss: 0.71880 - val_acc: 0.7467 -- iter: 237/237
--
Training Step: 97  | total loss: [1m[32m0.04624[0m[0m | time: 12.208s
[2K
| Adam | epoch: 013 | loss: 0.04624 - acc: 0.9920 -- iter: 032/237
[A[ATraining Step: 98  | total loss: [1m[32m0.05078[0m[0m | time: 18.253s
[2K
| Adam | epoch: 013 | loss: 0.05078 - acc: 0.9897 -- iter: 064/237
[A[ATraining Step: 99  | total loss: [1m[32m0.04648[0m[0m | time: 24.812s
[2K
| Adam | epoch: 013 | loss: 0.04648 - acc: 0.9907 -- iter: 096/237
[A[ATraining Step: 100  | total loss: [1m[32m0.04211[0m[0m | time: 36.951s
[2K
| Adam | epoch: 013 | loss: 0.04211 - acc: 0.9916 -- iter: 128/237
[A[ATraining Step: 101  | total loss: [1m[32m0.04151[0m[0m | time: 49.037s
[2K
| Adam | epoch: 013 | loss: 0.04151 - acc: 0.9925 -- iter: 160/237
[A[ATraining Step: 102  | total loss: [1m[32m0.03804[0m[0m | time: 60.993s
[2K
| Adam | epoch: 013 | loss: 0.03804 - acc: 0.9932 -- iter: 192/237
[A[ATraining Step: 103  | total loss: [1m[32m0.05927[0m[0m | time: 72.964s
[2K
| Adam | epoch: 013 | loss: 0.05927 - acc: 0.9908 -- iter: 224/237
[A[ATraining Step: 104  | total loss: [1m[32m0.05439[0m[0m | time: 90.530s
[2K
| Adam | epoch: 013 | loss: 0.05439 - acc: 0.9917 | val_loss: 0.96260 - val_acc: 0.7467 -- iter: 237/237
--
Training Step: 105  | total loss: [1m[32m0.04962[0m[0m | time: 12.183s
[2K
| Adam | epoch: 014 | loss: 0.04962 - acc: 0.9925 -- iter: 032/237
[A[ATraining Step: 106  | total loss: [1m[32m0.05005[0m[0m | time: 24.035s
[2K
| Adam | epoch: 014 | loss: 0.05005 - acc: 0.9901 -- iter: 064/237
[A[ATraining Step: 107  | total loss: [1m[32m0.04707[0m[0m | time: 29.950s
[2K
| Adam | epoch: 014 | loss: 0.04707 - acc: 0.9911 -- iter: 096/237
[A[ATraining Step: 108  | total loss: [1m[32m0.04461[0m[0m | time: 36.353s
[2K
| Adam | epoch: 014 | loss: 0.04461 - acc: 0.9920 -- iter: 128/237
[A[ATraining Step: 109  | total loss: [1m[32m0.04143[0m[0m | time: 48.603s
[2K
| Adam | epoch: 014 | loss: 0.04143 - acc: 0.9928 -- iter: 160/237
[A[ATraining Step: 110  | total loss: [1m[32m0.04371[0m[0m | time: 60.800s
[2K
| Adam | epoch: 014 | loss: 0.04371 - acc: 0.9904 -- iter: 192/237
[A[ATraining Step: 111  | total loss: [1m[32m0.04414[0m[0m | time: 72.993s
[2K
| Adam | epoch: 014 | loss: 0.04414 - acc: 0.9882 -- iter: 224/237
[A[ATraining Step: 112  | total loss: [1m[32m0.06903[0m[0m | time: 90.280s
[2K
| Adam | epoch: 014 | loss: 0.06903 - acc: 0.9832 | val_loss: 1.57121 - val_acc: 0.6667 -- iter: 237/237
--
Training Step: 113  | total loss: [1m[32m0.06553[0m[0m | time: 12.018s
[2K
| Adam | epoch: 015 | loss: 0.06553 - acc: 0.9817 -- iter: 032/237
[A[ATraining Step: 114  | total loss: [1m[32m0.06131[0m[0m | time: 24.121s
[2K
| Adam | epoch: 015 | loss: 0.06131 - acc: 0.9836 -- iter: 064/237
[A[ATraining Step: 115  | total loss: [1m[32m0.05701[0m[0m | time: 35.910s
[2K
| Adam | epoch: 015 | loss: 0.05701 - acc: 0.9852 -- iter: 096/237
[A[ATraining Step: 116  | total loss: [1m[32m0.05179[0m[0m | time: 41.986s
[2K
| Adam | epoch: 015 | loss: 0.05179 - acc: 0.9867 -- iter: 128/237
[A[ATraining Step: 117  | total loss: [1m[32m0.04755[0m[0m | time: 48.075s
[2K
| Adam | epoch: 015 | loss: 0.04755 - acc: 0.9880 -- iter: 160/237
[A[ATraining Step: 118  | total loss: [1m[32m0.04347[0m[0m | time: 60.174s
[2K
| Adam | epoch: 015 | loss: 0.04347 - acc: 0.9892 -- iter: 192/237
[A[ATraining Step: 119  | total loss: [1m[32m0.04008[0m[0m | time: 72.088s
[2K
| Adam | epoch: 015 | loss: 0.04008 - acc: 0.9903 -- iter: 224/237
[A[ATraining Step: 120  | total loss: [1m[32m0.03721[0m[0m | time: 89.627s
[2K
| Adam | epoch: 015 | loss: 0.03721 - acc: 0.9913 | val_loss: 1.09424 - val_acc: 0.8133 -- iter: 237/237
--
Validation AUC:0.8721428571428572
Validation AUPRC:0.9080581602804974
Test AUC:0.8911111111111111
Test AUPRC:0.8259641311496378
BestTestF1Score	0.81	0.72	0.87	0.92	0.73	22	2	43	8	0.94
BestTestMCCScore	0.81	0.72	0.87	0.92	0.73	22	2	43	8	0.94
BestTestAccuracyScore	0.81	0.72	0.87	0.92	0.73	22	2	43	8	0.94
BestValidationF1Score	0.82	0.68	0.83	0.94	0.72	29	2	33	11	0.94
BestValidationMCC	0.82	0.68	0.83	0.94	0.72	29	2	33	11	0.94
BestValidationAccuracy	0.82	0.68	0.83	0.94	0.72	29	2	33	11	0.94
TestPredictions (Threshold:0.94)
CHEMBL527039,TN,INACT,0.0	CHEMBL2392233,TN,INACT,0.0	CHEMBL2392379,TN,INACT,0.0	CHEMBL388978,FN,ACT,0.4399999976158142	CHEMBL3817984,TP,ACT,0.9900000095367432	CHEMBL77262,TN,INACT,0.4399999976158142	CHEMBL561136,TN,INACT,0.0	CHEMBL3822836,TP,ACT,1.0	CHEMBL518732,TN,INACT,0.0	CHEMBL3770588,TP,ACT,1.0	CHEMBL2403062,FN,ACT,0.2800000011920929	CHEMBL1331525,TN,INACT,0.0	CHEMBL504550,FP,INACT,1.0	CHEMBL469776,TN,INACT,0.05999999865889549	CHEMBL486487,TN,INACT,0.0	CHEMBL1287914,TN,INACT,0.0	CHEMBL120127,TN,INACT,0.0	CHEMBL2403066,TP,ACT,0.9700000286102295	CHEMBL457390,TN,INACT,0.0	CHEMBL2403065,TP,ACT,0.9599999785423279	CHEMBL489627,TN,INACT,0.0	CHEMBL515674,TN,INACT,0.0	CHEMBL120317,TN,INACT,0.0	CHEMBL603469,FN,ACT,0.0	CHEMBL523938,TN,INACT,0.019999999552965164	CHEMBL458076,TN,INACT,0.0	CHEMBL1910606,TN,INACT,0.0	CHEMBL3596927,TP,ACT,1.0	CHEMBL3421968,TN,INACT,0.019999999552965164	CHEMBL3580970,TP,ACT,0.9800000190734863	CHEMBL3594181,FN,ACT,0.0	CHEMBL3769981,TP,ACT,1.0	CHEMBL408244,TN,INACT,0.009999999776482582	CHEMBL3824075,TP,ACT,0.9900000095367432	CHEMBL457191,TN,INACT,0.0	CHEMBL498705,TN,INACT,0.46000000834465027	CHEMBL1801932,TN,INACT,0.009999999776482582	CHEMBL1922121,TN,INACT,0.8799999952316284	CHEMBL3596909,TP,ACT,1.0	CHEMBL3596910,TP,ACT,1.0	CHEMBL3770363,TP,ACT,1.0	CHEMBL332342,TN,INACT,0.9399999976158142	CHEMBL3594178,TP,ACT,0.9900000095367432	CHEMBL3596913,TP,ACT,1.0	CHEMBL515051,TN,INACT,0.0	CHEMBL3580976,FN,ACT,0.8899999856948853	CHEMBL3594174,TP,ACT,1.0	CHEMBL2403059,FN,ACT,0.9399999976158142	CHEMBL3609656,TN,INACT,0.0	CHEMBL488646,TN,INACT,0.0	CHEMBL2164696,TN,INACT,0.0	CHEMBL2403078,TP,ACT,1.0	CHEMBL2392390,TN,INACT,0.05999999865889549	CHEMBL396487,TN,INACT,0.0	CHEMBL3580953,FN,ACT,0.15000000596046448	CHEMBL457179,TN,INACT,0.25999999046325684	CHEMBL1922210,FP,INACT,0.9599999785423279	CHEMBL512658,TN,INACT,0.0	CHEMBL3596899,TP,ACT,1.0	CHEMBL469770,TN,INACT,0.0	CHEMBL1909651,TN,INACT,0.3499999940395355	CHEMBL230761,TN,INACT,0.0	CHEMBL3593825,FN,ACT,0.009999999776482582	CHEMBL3819633,TP,ACT,1.0	CHEMBL456112,TN,INACT,0.009999999776482582	CHEMBL3769478,TP,ACT,1.0	CHEMBL1910602,TN,INACT,0.28999999165534973	CHEMBL3597013,TP,ACT,1.0	CHEMBL498249,TN,INACT,0.23000000417232513	CHEMBL498248,TN,INACT,0.0	CHEMBL3596919,TP,ACT,1.0	CHEMBL2403080,TP,ACT,1.0	CHEMBL606245,TN,INACT,0.0	CHEMBL101779,TN,INACT,0.27000001072883606	CHEMBL48614,TN,INACT,0.009999999776482582	

