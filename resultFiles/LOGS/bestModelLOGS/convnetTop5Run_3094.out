ImageNetInceptionV2 CHEMBL1787 adam 0.001 5 0 0 0.8 False True
Number of active compounds :	392
Number of inactive compounds :	361
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1787_adam_0.001_5_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1787_adam_0.001_5_0.8/
---------------------------------
Training samples: 481
Validation samples: 151
--
Training Step: 1  | time: 37.830s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/481
[A[ATraining Step: 2  | total loss: [1m[32m0.64490[0m[0m | time: 46.466s
[2K
| Adam | epoch: 001 | loss: 0.64490 - acc: 0.3937 -- iter: 064/481
[A[ATraining Step: 3  | total loss: [1m[32m0.72533[0m[0m | time: 55.207s
[2K
| Adam | epoch: 001 | loss: 0.72533 - acc: 0.5063 -- iter: 096/481
[A[ATraining Step: 4  | total loss: [1m[32m0.59483[0m[0m | time: 63.766s
[2K
| Adam | epoch: 001 | loss: 0.59483 - acc: 0.6656 -- iter: 128/481
[A[ATraining Step: 5  | total loss: [1m[32m0.52091[0m[0m | time: 72.344s
[2K
| Adam | epoch: 001 | loss: 0.52091 - acc: 0.7240 -- iter: 160/481
[A[ATraining Step: 6  | total loss: [1m[32m0.29000[0m[0m | time: 81.111s
[2K
| Adam | epoch: 001 | loss: 0.29000 - acc: 0.8613 -- iter: 192/481
[A[ATraining Step: 7  | total loss: [1m[32m0.59488[0m[0m | time: 89.889s
[2K
| Adam | epoch: 001 | loss: 0.59488 - acc: 0.7945 -- iter: 224/481
[A[ATraining Step: 8  | total loss: [1m[32m0.40222[0m[0m | time: 98.598s
[2K
| Adam | epoch: 001 | loss: 0.40222 - acc: 0.8398 -- iter: 256/481
[A[ATraining Step: 9  | total loss: [1m[32m0.29334[0m[0m | time: 107.474s
[2K
| Adam | epoch: 001 | loss: 0.29334 - acc: 0.8915 -- iter: 288/481
[A[ATraining Step: 10  | total loss: [1m[32m0.37900[0m[0m | time: 116.296s
[2K
| Adam | epoch: 001 | loss: 0.37900 - acc: 0.8676 -- iter: 320/481
[A[ATraining Step: 11  | total loss: [1m[32m0.24792[0m[0m | time: 125.072s
[2K
| Adam | epoch: 001 | loss: 0.24792 - acc: 0.9007 -- iter: 352/481
[A[ATraining Step: 12  | total loss: [1m[32m0.19175[0m[0m | time: 133.922s
[2K
| Adam | epoch: 001 | loss: 0.19175 - acc: 0.9173 -- iter: 384/481
[A[ATraining Step: 13  | total loss: [1m[32m0.25195[0m[0m | time: 142.641s
[2K
| Adam | epoch: 001 | loss: 0.25195 - acc: 0.8456 -- iter: 416/481
[A[ATraining Step: 14  | total loss: [1m[32m0.44718[0m[0m | time: 151.477s
[2K
| Adam | epoch: 001 | loss: 0.44718 - acc: 0.8448 -- iter: 448/481
[A[ATraining Step: 15  | total loss: [1m[32m0.33066[0m[0m | time: 160.319s
[2K
| Adam | epoch: 001 | loss: 0.33066 - acc: 0.8566 -- iter: 480/481
[A[ATraining Step: 16  | total loss: [1m[32m0.28384[0m[0m | time: 173.516s
[2K
| Adam | epoch: 001 | loss: 0.28384 - acc: 0.8752 | val_loss: 0.93765 - val_acc: 0.5497 -- iter: 481/481
--
Training Step: 17  | total loss: [1m[32m0.53063[0m[0m | time: 0.609s
[2K
| Adam | epoch: 002 | loss: 0.53063 - acc: 0.5602 -- iter: 032/481
[A[ATraining Step: 18  | total loss: [1m[32m0.61948[0m[0m | time: 9.500s
[2K
| Adam | epoch: 002 | loss: 0.61948 - acc: 0.3663 -- iter: 064/481
[A[ATraining Step: 19  | total loss: [1m[32m0.52590[0m[0m | time: 18.201s
[2K
| Adam | epoch: 002 | loss: 0.52590 - acc: 0.5358 -- iter: 096/481
[A[ATraining Step: 20  | total loss: [1m[32m0.39058[0m[0m | time: 27.144s
[2K
| Adam | epoch: 002 | loss: 0.39058 - acc: 0.6649 -- iter: 128/481
[A[ATraining Step: 21  | total loss: [1m[32m0.33769[0m[0m | time: 36.326s
[2K
| Adam | epoch: 002 | loss: 0.33769 - acc: 0.7301 -- iter: 160/481
[A[ATraining Step: 22  | total loss: [1m[32m0.34970[0m[0m | time: 45.315s
[2K
| Adam | epoch: 002 | loss: 0.34970 - acc: 0.7642 -- iter: 192/481
[A[ATraining Step: 23  | total loss: [1m[32m0.32638[0m[0m | time: 54.237s
[2K
| Adam | epoch: 002 | loss: 0.32638 - acc: 0.8145 -- iter: 224/481
[A[ATraining Step: 24  | total loss: [1m[32m0.32353[0m[0m | time: 63.111s
[2K
| Adam | epoch: 002 | loss: 0.32353 - acc: 0.8403 -- iter: 256/481
[A[ATraining Step: 25  | total loss: [1m[32m0.26693[0m[0m | time: 72.047s
[2K
| Adam | epoch: 002 | loss: 0.26693 - acc: 0.8753 -- iter: 288/481
[A[ATraining Step: 26  | total loss: [1m[32m0.28230[0m[0m | time: 80.994s
[2K
| Adam | epoch: 002 | loss: 0.28230 - acc: 0.8918 -- iter: 320/481
[A[ATraining Step: 27  | total loss: [1m[32m0.25951[0m[0m | time: 89.798s
[2K
| Adam | epoch: 002 | loss: 0.25951 - acc: 0.9036 -- iter: 352/481
[A[ATraining Step: 28  | total loss: [1m[32m0.19880[0m[0m | time: 98.634s
[2K
| Adam | epoch: 002 | loss: 0.19880 - acc: 0.9277 -- iter: 384/481
[A[ATraining Step: 29  | total loss: [1m[32m0.19756[0m[0m | time: 107.560s
[2K
| Adam | epoch: 002 | loss: 0.19756 - acc: 0.9377 -- iter: 416/481
[A[ATraining Step: 30  | total loss: [1m[32m0.21785[0m[0m | time: 116.631s
[2K
| Adam | epoch: 002 | loss: 0.21785 - acc: 0.9302 -- iter: 448/481
[A[ATraining Step: 31  | total loss: [1m[32m0.18732[0m[0m | time: 125.435s
[2K
| Adam | epoch: 002 | loss: 0.18732 - acc: 0.9391 -- iter: 480/481
[A[ATraining Step: 32  | total loss: [1m[32m0.23342[0m[0m | time: 141.160s
[2K
| Adam | epoch: 002 | loss: 0.23342 - acc: 0.9247 | val_loss: 3.22997 - val_acc: 0.4503 -- iter: 481/481
--
Training Step: 33  | total loss: [1m[32m0.21180[0m[0m | time: 1.175s
[2K
| Adam | epoch: 003 | loss: 0.21180 - acc: 0.9275 -- iter: 032/481
[A[ATraining Step: 34  | total loss: [1m[32m0.35426[0m[0m | time: 2.391s
[2K
| Adam | epoch: 003 | loss: 0.35426 - acc: 0.7287 -- iter: 064/481
[A[ATraining Step: 35  | total loss: [1m[32m0.41169[0m[0m | time: 18.397s
[2K
| Adam | epoch: 003 | loss: 0.41169 - acc: 0.7855 -- iter: 096/481
[A[ATraining Step: 36  | total loss: [1m[32m0.38224[0m[0m | time: 33.827s
[2K
| Adam | epoch: 003 | loss: 0.38224 - acc: 0.8102 -- iter: 128/481
[A[ATraining Step: 37  | total loss: [1m[32m0.33309[0m[0m | time: 49.022s
[2K
| Adam | epoch: 003 | loss: 0.33309 - acc: 0.8419 -- iter: 160/481
[A[ATraining Step: 38  | total loss: [1m[32m0.34494[0m[0m | time: 63.770s
[2K
| Adam | epoch: 003 | loss: 0.34494 - acc: 0.8362 -- iter: 192/481
[A[ATraining Step: 39  | total loss: [1m[32m0.28622[0m[0m | time: 75.868s
[2K
| Adam | epoch: 003 | loss: 0.28622 - acc: 0.8675 -- iter: 224/481
[A[ATraining Step: 40  | total loss: [1m[32m0.26353[0m[0m | time: 86.391s
[2K
| Adam | epoch: 003 | loss: 0.26353 - acc: 0.8807 -- iter: 256/481
[A[ATraining Step: 41  | total loss: [1m[32m0.24277[0m[0m | time: 95.869s
[2K
| Adam | epoch: 003 | loss: 0.24277 - acc: 0.8911 -- iter: 288/481
[A[ATraining Step: 42  | total loss: [1m[32m0.20787[0m[0m | time: 105.041s
[2K
| Adam | epoch: 003 | loss: 0.20787 - acc: 0.9107 -- iter: 320/481
[A[ATraining Step: 43  | total loss: [1m[32m0.20115[0m[0m | time: 114.078s
[2K
| Adam | epoch: 003 | loss: 0.20115 - acc: 0.9154 -- iter: 352/481
[A[ATraining Step: 44  | total loss: [1m[32m0.17867[0m[0m | time: 123.266s
[2K
| Adam | epoch: 003 | loss: 0.17867 - acc: 0.9301 -- iter: 384/481
[A[ATraining Step: 45  | total loss: [1m[32m0.15633[0m[0m | time: 135.107s
[2K
| Adam | epoch: 003 | loss: 0.15633 - acc: 0.9419 -- iter: 416/481
[A[ATraining Step: 46  | total loss: [1m[32m0.13223[0m[0m | time: 151.150s
[2K
| Adam | epoch: 003 | loss: 0.13223 - acc: 0.9516 -- iter: 448/481
[A[ATraining Step: 47  | total loss: [1m[32m0.15153[0m[0m | time: 167.540s
[2K
| Adam | epoch: 003 | loss: 0.15153 - acc: 0.9493 -- iter: 480/481
[A[ATraining Step: 48  | total loss: [1m[32m0.13914[0m[0m | time: 199.832s
[2K
| Adam | epoch: 003 | loss: 0.13914 - acc: 0.9524 | val_loss: 1.95496 - val_acc: 0.5364 -- iter: 481/481
--
Training Step: 49  | total loss: [1m[32m0.13537[0m[0m | time: 9.046s
[2K
| Adam | epoch: 004 | loss: 0.13537 - acc: 0.9501 -- iter: 032/481
[A[ATraining Step: 50  | total loss: [1m[32m0.13715[0m[0m | time: 9.635s
[2K
| Adam | epoch: 004 | loss: 0.13715 - acc: 0.9530 -- iter: 064/481
[A[ATraining Step: 51  | total loss: [1m[32m0.27342[0m[0m | time: 10.218s
[2K
| Adam | epoch: 004 | loss: 0.27342 - acc: 0.8076 -- iter: 096/481
[A[ATraining Step: 52  | total loss: [1m[32m0.35445[0m[0m | time: 19.647s
[2K
| Adam | epoch: 004 | loss: 0.35445 - acc: 0.6865 -- iter: 128/481
[A[ATraining Step: 53  | total loss: [1m[32m0.39717[0m[0m | time: 70.166s
[2K
| Adam | epoch: 004 | loss: 0.39717 - acc: 0.7189 -- iter: 160/481
[A[ATraining Step: 54  | total loss: [1m[32m0.35384[0m[0m | time: 122.735s
[2K
| Adam | epoch: 004 | loss: 0.35384 - acc: 0.7552 -- iter: 192/481
[A[ATraining Step: 55  | total loss: [1m[32m0.31730[0m[0m | time: 189.928s
[2K
| Adam | epoch: 004 | loss: 0.31730 - acc: 0.7857 -- iter: 224/481
[A[ATraining Step: 56  | total loss: [1m[32m0.27805[0m[0m | time: 248.851s
[2K
| Adam | epoch: 004 | loss: 0.27805 - acc: 0.8114 -- iter: 256/481
[A[ATraining Step: 57  | total loss: [1m[32m0.24322[0m[0m | time: 282.282s
[2K
| Adam | epoch: 004 | loss: 0.24322 - acc: 0.8375 -- iter: 288/481
[A[ATraining Step: 58  | total loss: [1m[32m0.21273[0m[0m | time: 307.135s
[2K
| Adam | epoch: 004 | loss: 0.21273 - acc: 0.8597 -- iter: 320/481
[A[ATraining Step: 59  | total loss: [1m[32m0.18857[0m[0m | time: 321.960s
[2K
| Adam | epoch: 004 | loss: 0.18857 - acc: 0.8785 -- iter: 352/481
[A[ATraining Step: 60  | total loss: [1m[32m0.20402[0m[0m | time: 331.839s
[2K
| Adam | epoch: 004 | loss: 0.20402 - acc: 0.8822 -- iter: 384/481
[A[ATraining Step: 61  | total loss: [1m[32m0.18069[0m[0m | time: 342.366s
[2K
| Adam | epoch: 004 | loss: 0.18069 - acc: 0.8976 -- iter: 416/481
[A[ATraining Step: 62  | total loss: [1m[32m0.16408[0m[0m | time: 356.041s
[2K
| Adam | epoch: 004 | loss: 0.16408 - acc: 0.9067 -- iter: 448/481
[A[ATraining Step: 63  | total loss: [1m[32m0.15246[0m[0m | time: 372.603s
[2K
| Adam | epoch: 004 | loss: 0.15246 - acc: 0.9146 -- iter: 480/481
[A[ATraining Step: 64  | total loss: [1m[32m0.13894[0m[0m | time: 405.936s
[2K
| Adam | epoch: 004 | loss: 0.13894 - acc: 0.9214 | val_loss: 3.18309 - val_acc: 0.4702 -- iter: 481/481
--
Training Step: 65  | total loss: [1m[32m0.12538[0m[0m | time: 14.223s
[2K
| Adam | epoch: 005 | loss: 0.12538 - acc: 0.9310 -- iter: 032/481
[A[ATraining Step: 66  | total loss: [1m[32m0.11414[0m[0m | time: 24.681s
[2K
| Adam | epoch: 005 | loss: 0.11414 - acc: 0.9394 -- iter: 064/481
[A[ATraining Step: 67  | total loss: [1m[32m0.10270[0m[0m | time: 25.274s
[2K
| Adam | epoch: 005 | loss: 0.10270 - acc: 0.9467 -- iter: 096/481
[A[ATraining Step: 68  | total loss: [1m[32m0.13376[0m[0m | time: 25.860s
[2K
| Adam | epoch: 005 | loss: 0.13376 - acc: 0.9530 -- iter: 128/481
[A[ATraining Step: 69  | total loss: [1m[32m0.14362[0m[0m | time: 36.580s
[2K
| Adam | epoch: 005 | loss: 0.14362 - acc: 0.9585 -- iter: 160/481
[A[ATraining Step: 70  | total loss: [1m[32m0.13087[0m[0m | time: 86.925s
[2K
| Adam | epoch: 005 | loss: 0.13087 - acc: 0.9633 -- iter: 192/481
[A[ATraining Step: 71  | total loss: [1m[32m0.13334[0m[0m | time: 139.801s
[2K
| Adam | epoch: 005 | loss: 0.13334 - acc: 0.9604 -- iter: 224/481
[A[ATraining Step: 72  | total loss: [1m[32m0.11925[0m[0m | time: 162.424s
[2K
| Adam | epoch: 005 | loss: 0.11925 - acc: 0.9648 -- iter: 256/481
[A[ATraining Step: 73  | total loss: [1m[32m0.10809[0m[0m | time: 204.702s
[2K
| Adam | epoch: 005 | loss: 0.10809 - acc: 0.9687 -- iter: 288/481
[A[ATraining Step: 74  | total loss: [1m[32m0.09782[0m[0m | time: 247.796s
[2K
| Adam | epoch: 005 | loss: 0.09782 - acc: 0.9722 -- iter: 320/481
[A[ATraining Step: 75  | total loss: [1m[32m0.09797[0m[0m | time: 267.919s
[2K
| Adam | epoch: 005 | loss: 0.09797 - acc: 0.9718 -- iter: 352/481
[A[ATraining Step: 76  | total loss: [1m[32m0.09202[0m[0m | time: 281.680s
[2K
| Adam | epoch: 005 | loss: 0.09202 - acc: 0.9748 -- iter: 384/481
[A[ATraining Step: 77  | total loss: [1m[32m0.08366[0m[0m | time: 292.386s
[2K
| Adam | epoch: 005 | loss: 0.08366 - acc: 0.9775 -- iter: 416/481
[A[ATraining Step: 78  | total loss: [1m[32m0.07574[0m[0m | time: 306.561s
[2K
| Adam | epoch: 005 | loss: 0.07574 - acc: 0.9798 -- iter: 448/481
[A[ATraining Step: 79  | total loss: [1m[32m0.07473[0m[0m | time: 323.392s
[2K
| Adam | epoch: 005 | loss: 0.07473 - acc: 0.9787 -- iter: 480/481
[A[ATraining Step: 80  | total loss: [1m[32m0.07904[0m[0m | time: 354.978s
[2K
| Adam | epoch: 005 | loss: 0.07904 - acc: 0.9745 | val_loss: 0.18483 - val_acc: 0.9868 -- iter: 481/481
--
Validation AUC:0.9836109142452162
Validation AUPRC:0.9716650750489148
Test AUC:0.9637834036568214
Test AUPRC:0.9286522123688938
BestTestF1Score	0.95	0.91	0.95	0.95	0.96	69	4	75	3	0.57
BestTestMCCScore	0.95	0.91	0.95	0.95	0.96	69	4	75	3	0.57
BestTestAccuracyScore	0.95	0.91	0.95	0.95	0.96	69	4	75	3	0.57
BestValidationF1Score	0.99	0.97	0.99	0.99	0.99	82	1	67	1	0.57
BestValidationMCC	0.99	0.97	0.99	0.99	0.99	82	1	67	1	0.57
BestValidationAccuracy	0.99	0.97	0.99	0.99	0.99	82	1	67	1	0.57
TestPredictions (Threshold:0.57)
CHEMBL2206487,TN,INACT,0.2800000011920929	CHEMBL536765,TN,INACT,0.009999999776482582	CHEMBL3093902,TN,INACT,0.12999999523162842	CHEMBL399189,TN,INACT,0.15000000596046448	CHEMBL585290,TN,INACT,0.019999999552965164	CHEMBL183500,TP,ACT,0.9800000190734863	CHEMBL557187,TN,INACT,0.05000000074505806	CHEMBL135313,TP,ACT,1.0	CHEMBL364093,TN,INACT,0.09000000357627869	CHEMBL216178,TN,INACT,0.10000000149011612	CHEMBL111407,TP,ACT,1.0	CHEMBL245970,TN,INACT,0.1899999976158142	CHEMBL125855,TP,ACT,1.0	CHEMBL400278,TN,INACT,0.20000000298023224	CHEMBL371588,TN,INACT,0.07000000029802322	CHEMBL1683141,TN,INACT,0.07000000029802322	CHEMBL56518,FN,ACT,0.1599999964237213	CHEMBL36772,FN,ACT,0.23000000417232513	CHEMBL183820,TP,ACT,0.8700000047683716	CHEMBL80160,TP,ACT,1.0	CHEMBL16700,TP,ACT,1.0	CHEMBL430617,TP,ACT,1.0	CHEMBL248682,TP,ACT,0.9700000286102295	CHEMBL1683116,TN,INACT,0.029999999329447746	CHEMBL3735917,TN,INACT,0.05000000074505806	CHEMBL568111,TN,INACT,0.10000000149011612	CHEMBL190788,TN,INACT,0.05000000074505806	CHEMBL203736,TN,INACT,0.25999999046325684	CHEMBL3735149,FP,INACT,1.0	CHEMBL1395713,TN,INACT,0.27000001072883606	CHEMBL1683119,TN,INACT,0.019999999552965164	CHEMBL3806310,TN,INACT,0.10000000149011612	CHEMBL17506,TP,ACT,0.9700000286102295	CHEMBL557447,TN,INACT,0.019999999552965164	CHEMBL3805751,TN,INACT,0.05999999865889549	CHEMBL135014,TP,ACT,1.0	CHEMBL3706583,TP,ACT,1.0	CHEMBL118446,TP,ACT,1.0	CHEMBL3805346,TN,INACT,0.3799999952316284	CHEMBL24291,TP,ACT,1.0	CHEMBL307181,TP,ACT,1.0	CHEMBL3805353,TN,INACT,0.019999999552965164	CHEMBL238114,TN,INACT,0.4699999988079071	CHEMBL188643,TN,INACT,0.12999999523162842	CHEMBL14220,FP,INACT,1.0	CHEMBL282037,TP,ACT,1.0	CHEMBL192980,TN,INACT,0.2199999988079071	CHEMBL192365,TN,INACT,0.019999999552965164	CHEMBL323033,TP,ACT,0.9900000095367432	CHEMBL401304,TN,INACT,0.27000001072883606	CHEMBL16690,TP,ACT,1.0	CHEMBL3093900,TN,INACT,0.019999999552965164	CHEMBL243231,TN,INACT,0.09000000357627869	CHEMBL155094,TP,ACT,0.9399999976158142	CHEMBL400752,TN,INACT,0.17000000178813934	CHEMBL556494,TN,INACT,0.05999999865889549	CHEMBL88032,TP,ACT,1.0	CHEMBL333684,TP,ACT,0.9900000095367432	CHEMBL3706585,TP,ACT,1.0	CHEMBL76648,TP,ACT,1.0	CHEMBL2063028,TN,INACT,0.4399999976158142	CHEMBL274238,TP,ACT,1.0	CHEMBL155568,TP,ACT,0.8999999761581421	CHEMBL24193,TP,ACT,1.0	CHEMBL134114,TP,ACT,1.0	CHEMBL37880,FN,ACT,0.5	CHEMBL125257,TP,ACT,1.0	CHEMBL76192,TP,ACT,1.0	CHEMBL2425076,TN,INACT,0.17000000178813934	CHEMBL287906,TP,ACT,0.9300000071525574	CHEMBL322592,TP,ACT,1.0	CHEMBL1814744,TN,INACT,0.09000000357627869	CHEMBL279745,TP,ACT,0.6100000143051147	CHEMBL323788,TP,ACT,1.0	CHEMBL108612,TP,ACT,1.0	CHEMBL231294,TN,INACT,0.1899999976158142	CHEMBL419602,TP,ACT,1.0	CHEMBL279417,TP,ACT,1.0	CHEMBL278490,TP,ACT,0.9900000095367432	CHEMBL3127980,TN,INACT,0.36000001430511475	CHEMBL311818,TP,ACT,1.0	CHEMBL16743,TP,ACT,1.0	CHEMBL333183,TP,ACT,1.0	CHEMBL3735843,TN,INACT,0.11999999731779099	CHEMBL1683140,TN,INACT,0.019999999552965164	CHEMBL395696,TN,INACT,0.17000000178813934	CHEMBL3804950,TN,INACT,0.03999999910593033	CHEMBL426649,TN,INACT,0.05999999865889549	CHEMBL585129,TN,INACT,0.029999999329447746	CHEMBL109232,TP,ACT,1.0	CHEMBL216643,TN,INACT,0.10999999940395355	CHEMBL1683108,TN,INACT,0.019999999552965164	CHEMBL3330064,TN,INACT,0.1599999964237213	CHEMBL537400,TN,INACT,0.09000000357627869	CHEMBL437965,TN,INACT,0.12999999523162842	CHEMBL83418,TN,INACT,0.5400000214576721	CHEMBL3805696,TN,INACT,0.05000000074505806	CHEMBL230495,TN,INACT,0.12999999523162842	CHEMBL276320,TP,ACT,1.0	CHEMBL372486,TN,INACT,0.019999999552965164	CHEMBL124849,TP,ACT,1.0	CHEMBL3806239,TN,INACT,0.07000000029802322	CHEMBL3112967,TN,INACT,0.4099999964237213	CHEMBL370755,TN,INACT,0.05000000074505806	CHEMBL167774,TP,ACT,1.0	CHEMBL1683142,TN,INACT,0.05000000074505806	CHEMBL76998,TP,ACT,1.0	CHEMBL400722,TN,INACT,0.15000000596046448	CHEMBL277224,TP,ACT,1.0	CHEMBL439804,TP,ACT,1.0	CHEMBL1682984,TN,INACT,0.25	CHEMBL559011,TN,INACT,0.019999999552965164	CHEMBL1683145,TN,INACT,0.009999999776482582	CHEMBL1383750,TN,INACT,0.10000000149011612	CHEMBL365780,TN,INACT,0.3400000035762787	CHEMBL110058,TP,ACT,1.0	CHEMBL99615,TP,ACT,1.0	CHEMBL539611,TN,INACT,0.2199999988079071	CHEMBL452805,TN,INACT,0.15000000596046448	CHEMBL169621,FP,INACT,0.9900000095367432	CHEMBL3804854,TN,INACT,0.07999999821186066	CHEMBL111476,TP,ACT,1.0	CHEMBL107654,TP,ACT,1.0	CHEMBL118943,TP,ACT,1.0	CHEMBL537000,TN,INACT,0.009999999776482582	CHEMBL17193,TP,ACT,1.0	CHEMBL242813,TN,INACT,0.029999999329447746	CHEMBL307626,TP,ACT,1.0	CHEMBL420020,TP,ACT,1.0	CHEMBL17194,TP,ACT,0.9800000190734863	CHEMBL3735852,TN,INACT,0.15000000596046448	CHEMBL1683131,TN,INACT,0.029999999329447746	CHEMBL24464,TP,ACT,1.0	CHEMBL122359,TP,ACT,0.7200000286102295	CHEMBL110398,TP,ACT,1.0	CHEMBL355567,FP,INACT,1.0	CHEMBL1462031,TN,INACT,0.17000000178813934	CHEMBL78064,TP,ACT,0.9900000095367432	CHEMBL1683139,TN,INACT,0.03999999910593033	CHEMBL325572,TP,ACT,1.0	CHEMBL388475,TN,INACT,0.03999999910593033	CHEMBL445627,TP,ACT,1.0	CHEMBL109089,TP,ACT,1.0	CHEMBL566419,TN,INACT,0.03999999910593033	CHEMBL25193,TP,ACT,1.0	CHEMBL122290,TP,ACT,1.0	CHEMBL77650,TP,ACT,0.8899999856948853	CHEMBL314953,TP,ACT,1.0	CHEMBL394836,TN,INACT,0.05000000074505806	CHEMBL182945,TP,ACT,0.6499999761581421	CHEMBL88494,TP,ACT,1.0	

