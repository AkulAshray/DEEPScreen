ImageNetInceptionV2 CHEMBL4653 adam 0.001 30 0 0 0.6 False True
Number of active compounds :	188
Number of inactive compounds :	188
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4653_adam_0.001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4653_adam_0.001_30_0.6/
---------------------------------
Training samples: 236
Validation samples: 75
--
Training Step: 1  | time: 61.834s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/236
[A[ATraining Step: 2  | total loss: [1m[32m0.62215[0m[0m | time: 73.895s
[2K
| Adam | epoch: 001 | loss: 0.62215 - acc: 0.4500 -- iter: 064/236
[A[ATraining Step: 3  | total loss: [1m[32m0.75162[0m[0m | time: 86.171s
[2K
| Adam | epoch: 001 | loss: 0.75162 - acc: 0.5676 -- iter: 096/236
[A[ATraining Step: 4  | total loss: [1m[32m0.55113[0m[0m | time: 98.027s
[2K
| Adam | epoch: 001 | loss: 0.55113 - acc: 0.6575 -- iter: 128/236
[A[ATraining Step: 5  | total loss: [1m[32m1.03302[0m[0m | time: 110.174s
[2K
| Adam | epoch: 001 | loss: 1.03302 - acc: 0.6566 -- iter: 160/236
[A[ATraining Step: 6  | total loss: [1m[32m0.83041[0m[0m | time: 121.903s
[2K
| Adam | epoch: 001 | loss: 0.83041 - acc: 0.6765 -- iter: 192/236
[A[ATraining Step: 7  | total loss: [1m[32m0.65746[0m[0m | time: 133.617s
[2K
| Adam | epoch: 001 | loss: 0.65746 - acc: 0.7581 -- iter: 224/236
[A[ATraining Step: 8  | total loss: [1m[32m0.58932[0m[0m | time: 156.062s
[2K
| Adam | epoch: 001 | loss: 0.58932 - acc: 0.7711 | val_loss: 0.66254 - val_acc: 0.6400 -- iter: 236/236
--
Training Step: 9  | total loss: [1m[32m0.60790[0m[0m | time: 3.564s
[2K
| Adam | epoch: 002 | loss: 0.60790 - acc: 0.7599 -- iter: 032/236
[A[ATraining Step: 10  | total loss: [1m[32m0.42893[0m[0m | time: 11.460s
[2K
| Adam | epoch: 002 | loss: 0.42893 - acc: 0.8383 -- iter: 064/236
[A[ATraining Step: 11  | total loss: [1m[32m0.47250[0m[0m | time: 19.449s
[2K
| Adam | epoch: 002 | loss: 0.47250 - acc: 0.7965 -- iter: 096/236
[A[ATraining Step: 12  | total loss: [1m[32m0.59114[0m[0m | time: 30.865s
[2K
| Adam | epoch: 002 | loss: 0.59114 - acc: 0.7615 -- iter: 128/236
[A[ATraining Step: 13  | total loss: [1m[32m0.56546[0m[0m | time: 42.497s
[2K
| Adam | epoch: 002 | loss: 0.56546 - acc: 0.7700 -- iter: 160/236
[A[ATraining Step: 14  | total loss: [1m[32m0.44678[0m[0m | time: 54.483s
[2K
| Adam | epoch: 002 | loss: 0.44678 - acc: 0.8513 -- iter: 192/236
[A[ATraining Step: 15  | total loss: [1m[32m0.40727[0m[0m | time: 66.274s
[2K
| Adam | epoch: 002 | loss: 0.40727 - acc: 0.8606 -- iter: 224/236
[A[ATraining Step: 16  | total loss: [1m[32m0.40100[0m[0m | time: 83.822s
[2K
| Adam | epoch: 002 | loss: 0.40100 - acc: 0.8543 | val_loss: 1.13718 - val_acc: 0.3600 -- iter: 236/236
--
Training Step: 17  | total loss: [1m[32m0.36994[0m[0m | time: 5.896s
[2K
| Adam | epoch: 003 | loss: 0.36994 - acc: 0.8505 -- iter: 032/236
[A[ATraining Step: 18  | total loss: [1m[32m0.32790[0m[0m | time: 11.272s
[2K
| Adam | epoch: 003 | loss: 0.32790 - acc: 0.8734 -- iter: 064/236
[A[ATraining Step: 19  | total loss: [1m[32m0.24979[0m[0m | time: 23.408s
[2K
| Adam | epoch: 003 | loss: 0.24979 - acc: 0.9156 -- iter: 096/236
[A[ATraining Step: 20  | total loss: [1m[32m0.31139[0m[0m | time: 35.349s
[2K
| Adam | epoch: 003 | loss: 0.31139 - acc: 0.9126 -- iter: 128/236
[A[ATraining Step: 21  | total loss: [1m[32m0.35636[0m[0m | time: 47.176s
[2K
| Adam | epoch: 003 | loss: 0.35636 - acc: 0.8621 -- iter: 160/236
[A[ATraining Step: 22  | total loss: [1m[32m0.37297[0m[0m | time: 59.075s
[2K
| Adam | epoch: 003 | loss: 0.37297 - acc: 0.8472 -- iter: 192/236
[A[ATraining Step: 23  | total loss: [1m[32m0.33808[0m[0m | time: 71.072s
[2K
| Adam | epoch: 003 | loss: 0.33808 - acc: 0.8644 -- iter: 224/236
[A[ATraining Step: 24  | total loss: [1m[32m0.27392[0m[0m | time: 88.507s
[2K
| Adam | epoch: 003 | loss: 0.27392 - acc: 0.8937 | val_loss: 1.79806 - val_acc: 0.3600 -- iter: 236/236
--
Training Step: 25  | total loss: [1m[32m0.26292[0m[0m | time: 12.691s
[2K
| Adam | epoch: 004 | loss: 0.26292 - acc: 0.8971 -- iter: 032/236
[A[ATraining Step: 26  | total loss: [1m[32m0.33152[0m[0m | time: 16.285s
[2K
| Adam | epoch: 004 | loss: 0.33152 - acc: 0.8747 -- iter: 064/236
[A[ATraining Step: 27  | total loss: [1m[32m0.29173[0m[0m | time: 19.849s
[2K
| Adam | epoch: 004 | loss: 0.29173 - acc: 0.8641 -- iter: 096/236
[A[ATraining Step: 28  | total loss: [1m[32m0.22818[0m[0m | time: 27.811s
[2K
| Adam | epoch: 004 | loss: 0.22818 - acc: 0.8981 -- iter: 128/236
[A[ATraining Step: 29  | total loss: [1m[32m0.27065[0m[0m | time: 35.689s
[2K
| Adam | epoch: 004 | loss: 0.27065 - acc: 0.9001 -- iter: 160/236
[A[ATraining Step: 30  | total loss: [1m[32m0.27245[0m[0m | time: 46.958s
[2K
| Adam | epoch: 004 | loss: 0.27245 - acc: 0.8941 -- iter: 192/236
[A[ATraining Step: 31  | total loss: [1m[32m0.28003[0m[0m | time: 59.144s
[2K
| Adam | epoch: 004 | loss: 0.28003 - acc: 0.8969 -- iter: 224/236
[A[ATraining Step: 32  | total loss: [1m[32m0.29001[0m[0m | time: 77.416s
[2K
| Adam | epoch: 004 | loss: 0.29001 - acc: 0.8779 | val_loss: 1.14975 - val_acc: 0.3333 -- iter: 236/236
--
Training Step: 33  | total loss: [1m[32m0.26932[0m[0m | time: 12.226s
[2K
| Adam | epoch: 005 | loss: 0.26932 - acc: 0.8841 -- iter: 032/236
[A[ATraining Step: 34  | total loss: [1m[32m0.23565[0m[0m | time: 24.296s
[2K
| Adam | epoch: 005 | loss: 0.23565 - acc: 0.9090 -- iter: 064/236
[A[ATraining Step: 35  | total loss: [1m[32m0.23397[0m[0m | time: 29.748s
[2K
| Adam | epoch: 005 | loss: 0.23397 - acc: 0.9019 -- iter: 096/236
[A[ATraining Step: 36  | total loss: [1m[32m0.21447[0m[0m | time: 35.800s
[2K
| Adam | epoch: 005 | loss: 0.21447 - acc: 0.9049 -- iter: 128/236
[A[ATraining Step: 37  | total loss: [1m[32m0.18370[0m[0m | time: 47.845s
[2K
| Adam | epoch: 005 | loss: 0.18370 - acc: 0.9239 -- iter: 160/236
[A[ATraining Step: 38  | total loss: [1m[32m0.18008[0m[0m | time: 59.558s
[2K
| Adam | epoch: 005 | loss: 0.18008 - acc: 0.9266 -- iter: 192/236
[A[ATraining Step: 39  | total loss: [1m[32m0.18460[0m[0m | time: 71.300s
[2K
| Adam | epoch: 005 | loss: 0.18460 - acc: 0.9227 -- iter: 224/236
[A[ATraining Step: 40  | total loss: [1m[32m0.21162[0m[0m | time: 88.744s
[2K
| Adam | epoch: 005 | loss: 0.21162 - acc: 0.9196 | val_loss: 1.81385 - val_acc: 0.6533 -- iter: 236/236
--
Training Step: 41  | total loss: [1m[32m0.19544[0m[0m | time: 11.507s
[2K
| Adam | epoch: 006 | loss: 0.19544 - acc: 0.9286 -- iter: 032/236
[A[ATraining Step: 42  | total loss: [1m[32m0.22516[0m[0m | time: 19.307s
[2K
| Adam | epoch: 006 | loss: 0.22516 - acc: 0.9246 -- iter: 064/236
[A[ATraining Step: 43  | total loss: [1m[32m0.19002[0m[0m | time: 27.178s
[2K
| Adam | epoch: 006 | loss: 0.19002 - acc: 0.9379 -- iter: 096/236
[A[ATraining Step: 44  | total loss: [1m[32m0.16535[0m[0m | time: 30.743s
[2K
| Adam | epoch: 006 | loss: 0.16535 - acc: 0.9487 -- iter: 128/236
[A[ATraining Step: 45  | total loss: [1m[32m0.15072[0m[0m | time: 36.027s
[2K
| Adam | epoch: 006 | loss: 0.15072 - acc: 0.9574 -- iter: 160/236
[A[ATraining Step: 46  | total loss: [1m[32m0.13273[0m[0m | time: 47.999s
[2K
| Adam | epoch: 006 | loss: 0.13273 - acc: 0.9645 -- iter: 192/236
[A[ATraining Step: 47  | total loss: [1m[32m0.11823[0m[0m | time: 60.194s
[2K
| Adam | epoch: 006 | loss: 0.11823 - acc: 0.9703 -- iter: 224/236
[A[ATraining Step: 48  | total loss: [1m[32m0.11930[0m[0m | time: 77.760s
[2K
| Adam | epoch: 006 | loss: 0.11930 - acc: 0.9650 | val_loss: 0.84874 - val_acc: 0.7600 -- iter: 236/236
--
Training Step: 49  | total loss: [1m[32m0.22114[0m[0m | time: 11.604s
[2K
| Adam | epoch: 007 | loss: 0.22114 - acc: 0.9459 -- iter: 032/236
[A[ATraining Step: 50  | total loss: [1m[32m0.19171[0m[0m | time: 23.424s
[2K
| Adam | epoch: 007 | loss: 0.19171 - acc: 0.9543 -- iter: 064/236
[A[ATraining Step: 51  | total loss: [1m[32m0.17336[0m[0m | time: 35.313s
[2K
| Adam | epoch: 007 | loss: 0.17336 - acc: 0.9565 -- iter: 096/236
[A[ATraining Step: 52  | total loss: [1m[32m0.15388[0m[0m | time: 48.844s
[2K
| Adam | epoch: 007 | loss: 0.15388 - acc: 0.9630 -- iter: 128/236
[A[ATraining Step: 53  | total loss: [1m[32m0.13969[0m[0m | time: 54.464s
[2K
| Adam | epoch: 007 | loss: 0.13969 - acc: 0.9685 -- iter: 160/236
[A[ATraining Step: 54  | total loss: [1m[32m0.12802[0m[0m | time: 60.157s
[2K
| Adam | epoch: 007 | loss: 0.12802 - acc: 0.9730 -- iter: 192/236
[A[ATraining Step: 55  | total loss: [1m[32m0.11118[0m[0m | time: 72.783s
[2K
| Adam | epoch: 007 | loss: 0.11118 - acc: 0.9769 -- iter: 224/236
[A[ATraining Step: 56  | total loss: [1m[32m0.12910[0m[0m | time: 90.395s
[2K
| Adam | epoch: 007 | loss: 0.12910 - acc: 0.9714 | val_loss: 0.68905 - val_acc: 0.7467 -- iter: 236/236
--
Training Step: 57  | total loss: [1m[32m0.15804[0m[0m | time: 8.645s
[2K
| Adam | epoch: 008 | loss: 0.15804 - acc: 0.9623 -- iter: 032/236
[A[ATraining Step: 58  | total loss: [1m[32m0.17108[0m[0m | time: 16.427s
[2K
| Adam | epoch: 008 | loss: 0.17108 - acc: 0.9504 -- iter: 064/236
[A[ATraining Step: 59  | total loss: [1m[32m0.15056[0m[0m | time: 24.309s
[2K
| Adam | epoch: 008 | loss: 0.15056 - acc: 0.9571 -- iter: 096/236
[A[ATraining Step: 60  | total loss: [1m[32m0.15212[0m[0m | time: 35.645s
[2K
| Adam | epoch: 008 | loss: 0.15212 - acc: 0.9545 -- iter: 128/236
[A[ATraining Step: 61  | total loss: [1m[32m0.13475[0m[0m | time: 48.042s
[2K
| Adam | epoch: 008 | loss: 0.13475 - acc: 0.9604 -- iter: 160/236
[A[ATraining Step: 62  | total loss: [1m[32m0.12507[0m[0m | time: 53.773s
[2K
| Adam | epoch: 008 | loss: 0.12507 - acc: 0.9615 -- iter: 192/236
[A[ATraining Step: 63  | total loss: [1m[32m0.11029[0m[0m | time: 59.485s
[2K
| Adam | epoch: 008 | loss: 0.11029 - acc: 0.9664 -- iter: 224/236
[A[ATraining Step: 64  | total loss: [1m[32m0.09773[0m[0m | time: 77.159s
[2K
| Adam | epoch: 008 | loss: 0.09773 - acc: 0.9706 | val_loss: 0.97711 - val_acc: 0.7200 -- iter: 236/236
--
Training Step: 65  | total loss: [1m[32m0.09342[0m[0m | time: 12.059s
[2K
| Adam | epoch: 009 | loss: 0.09342 - acc: 0.9742 -- iter: 032/236
[A[ATraining Step: 66  | total loss: [1m[32m0.09973[0m[0m | time: 24.151s
[2K
| Adam | epoch: 009 | loss: 0.09973 - acc: 0.9735 -- iter: 064/236
[A[ATraining Step: 67  | total loss: [1m[32m0.13999[0m[0m | time: 36.152s
[2K
| Adam | epoch: 009 | loss: 0.13999 - acc: 0.9655 -- iter: 096/236
[A[ATraining Step: 68  | total loss: [1m[32m0.12803[0m[0m | time: 48.104s
[2K
| Adam | epoch: 009 | loss: 0.12803 - acc: 0.9696 -- iter: 128/236
[A[ATraining Step: 69  | total loss: [1m[32m0.12887[0m[0m | time: 60.492s
[2K
| Adam | epoch: 009 | loss: 0.12887 - acc: 0.9658 -- iter: 160/236
[A[ATraining Step: 70  | total loss: [1m[32m0.12344[0m[0m | time: 72.674s
[2K
| Adam | epoch: 009 | loss: 0.12344 - acc: 0.9698 -- iter: 192/236
[A[ATraining Step: 71  | total loss: [1m[32m0.12631[0m[0m | time: 78.301s
[2K
| Adam | epoch: 009 | loss: 0.12631 - acc: 0.9696 -- iter: 224/236
[A[ATraining Step: 72  | total loss: [1m[32m0.12844[0m[0m | time: 89.633s
[2K
| Adam | epoch: 009 | loss: 0.12844 - acc: 0.9637 | val_loss: 1.49459 - val_acc: 0.6533 -- iter: 236/236
--
Training Step: 73  | total loss: [1m[32m0.11769[0m[0m | time: 12.752s
[2K
| Adam | epoch: 010 | loss: 0.11769 - acc: 0.9677 -- iter: 032/236
[A[ATraining Step: 74  | total loss: [1m[32m0.10980[0m[0m | time: 21.253s
[2K
| Adam | epoch: 010 | loss: 0.10980 - acc: 0.9713 -- iter: 064/236
[A[ATraining Step: 75  | total loss: [1m[32m0.11366[0m[0m | time: 29.045s
[2K
| Adam | epoch: 010 | loss: 0.11366 - acc: 0.9642 -- iter: 096/236
[A[ATraining Step: 76  | total loss: [1m[32m0.13828[0m[0m | time: 36.882s
[2K
| Adam | epoch: 010 | loss: 0.13828 - acc: 0.9613 -- iter: 128/236
[A[ATraining Step: 77  | total loss: [1m[32m0.13672[0m[0m | time: 44.809s
[2K
| Adam | epoch: 010 | loss: 0.13672 - acc: 0.9621 -- iter: 160/236
[A[ATraining Step: 78  | total loss: [1m[32m0.13008[0m[0m | time: 53.586s
[2K
| Adam | epoch: 010 | loss: 0.13008 - acc: 0.9661 -- iter: 192/236
[A[ATraining Step: 79  | total loss: [1m[32m0.11883[0m[0m | time: 65.417s
[2K
| Adam | epoch: 010 | loss: 0.11883 - acc: 0.9696 -- iter: 224/236
[A[ATraining Step: 80  | total loss: [1m[32m0.10833[0m[0m | time: 76.548s
[2K
| Adam | epoch: 010 | loss: 0.10833 - acc: 0.9727 | val_loss: 0.70708 - val_acc: 0.8000 -- iter: 236/236
--
Training Step: 81  | total loss: [1m[32m0.10056[0m[0m | time: 5.823s
[2K
| Adam | epoch: 011 | loss: 0.10056 - acc: 0.9755 -- iter: 032/236
[A[ATraining Step: 82  | total loss: [1m[32m0.09223[0m[0m | time: 18.090s
[2K
| Adam | epoch: 011 | loss: 0.09223 - acc: 0.9779 -- iter: 064/236
[A[ATraining Step: 83  | total loss: [1m[32m0.09391[0m[0m | time: 30.240s
[2K
| Adam | epoch: 011 | loss: 0.09391 - acc: 0.9770 -- iter: 096/236
[A[ATraining Step: 84  | total loss: [1m[32m0.10180[0m[0m | time: 42.326s
[2K
| Adam | epoch: 011 | loss: 0.10180 - acc: 0.9731 -- iter: 128/236
[A[ATraining Step: 85  | total loss: [1m[32m0.11906[0m[0m | time: 54.570s
[2K
| Adam | epoch: 011 | loss: 0.11906 - acc: 0.9695 -- iter: 160/236
[A[ATraining Step: 86  | total loss: [1m[32m0.11633[0m[0m | time: 66.651s
[2K
| Adam | epoch: 011 | loss: 0.11633 - acc: 0.9694 -- iter: 192/236
[A[ATraining Step: 87  | total loss: [1m[32m0.10988[0m[0m | time: 78.745s
[2K
| Adam | epoch: 011 | loss: 0.10988 - acc: 0.9694 -- iter: 224/236
[A[ATraining Step: 88  | total loss: [1m[32m0.10939[0m[0m | time: 96.163s
[2K
| Adam | epoch: 011 | loss: 0.10939 - acc: 0.9662 | val_loss: 0.59556 - val_acc: 0.8400 -- iter: 236/236
--
Training Step: 89  | total loss: [1m[32m0.10536[0m[0m | time: 3.584s
[2K
| Adam | epoch: 012 | loss: 0.10536 - acc: 0.9664 -- iter: 032/236
[A[ATraining Step: 90  | total loss: [1m[32m0.09754[0m[0m | time: 7.128s
[2K
| Adam | epoch: 012 | loss: 0.09754 - acc: 0.9698 -- iter: 064/236
[A[ATraining Step: 91  | total loss: [1m[32m0.08848[0m[0m | time: 14.848s
[2K
| Adam | epoch: 012 | loss: 0.08848 - acc: 0.9728 -- iter: 096/236
[A[ATraining Step: 92  | total loss: [1m[32m0.08277[0m[0m | time: 22.612s
[2K
| Adam | epoch: 012 | loss: 0.08277 - acc: 0.9755 -- iter: 128/236
[A[ATraining Step: 93  | total loss: [1m[32m0.07705[0m[0m | time: 30.456s
[2K
| Adam | epoch: 012 | loss: 0.07705 - acc: 0.9780 -- iter: 160/236
[A[ATraining Step: 94  | total loss: [1m[32m0.10000[0m[0m | time: 41.375s
[2K
| Adam | epoch: 012 | loss: 0.10000 - acc: 0.9739 -- iter: 192/236
[A[ATraining Step: 95  | total loss: [1m[32m0.10005[0m[0m | time: 53.284s
[2K
| Adam | epoch: 012 | loss: 0.10005 - acc: 0.9703 -- iter: 224/236
[A[ATraining Step: 96  | total loss: [1m[32m0.09502[0m[0m | time: 71.056s
[2K
| Adam | epoch: 012 | loss: 0.09502 - acc: 0.9733 | val_loss: 1.38911 - val_acc: 0.7333 -- iter: 236/236
--
Training Step: 97  | total loss: [1m[32m0.09617[0m[0m | time: 12.064s
[2K
| Adam | epoch: 013 | loss: 0.09617 - acc: 0.9697 -- iter: 032/236
[A[ATraining Step: 98  | total loss: [1m[32m0.09025[0m[0m | time: 17.963s
[2K
| Adam | epoch: 013 | loss: 0.09025 - acc: 0.9727 -- iter: 064/236
[A[ATraining Step: 99  | total loss: [1m[32m0.08698[0m[0m | time: 23.727s
[2K
| Adam | epoch: 013 | loss: 0.08698 - acc: 0.9754 -- iter: 096/236
[A[ATraining Step: 100  | total loss: [1m[32m0.07997[0m[0m | time: 35.552s
[2K
| Adam | epoch: 013 | loss: 0.07997 - acc: 0.9779 -- iter: 128/236
[A[ATraining Step: 101  | total loss: [1m[32m0.07689[0m[0m | time: 47.817s
[2K
| Adam | epoch: 013 | loss: 0.07689 - acc: 0.9770 -- iter: 160/236
[A[ATraining Step: 102  | total loss: [1m[32m0.07215[0m[0m | time: 59.742s
[2K
| Adam | epoch: 013 | loss: 0.07215 - acc: 0.9793 -- iter: 192/236
[A[ATraining Step: 103  | total loss: [1m[32m0.09967[0m[0m | time: 71.877s
[2K
| Adam | epoch: 013 | loss: 0.09967 - acc: 0.9782 -- iter: 224/236
[A[ATraining Step: 104  | total loss: [1m[32m0.09089[0m[0m | time: 89.500s
[2K
| Adam | epoch: 013 | loss: 0.09089 - acc: 0.9804 | val_loss: 1.70354 - val_acc: 0.6400 -- iter: 236/236
--
Training Step: 105  | total loss: [1m[32m0.08246[0m[0m | time: 11.854s
[2K
| Adam | epoch: 014 | loss: 0.08246 - acc: 0.9824 -- iter: 032/236
[A[ATraining Step: 106  | total loss: [1m[32m0.07673[0m[0m | time: 24.763s
[2K
| Adam | epoch: 014 | loss: 0.07673 - acc: 0.9841 -- iter: 064/236
[A[ATraining Step: 107  | total loss: [1m[32m0.07041[0m[0m | time: 29.394s
[2K
| Adam | epoch: 014 | loss: 0.07041 - acc: 0.9857 -- iter: 096/236
[A[ATraining Step: 108  | total loss: [1m[32m0.06527[0m[0m | time: 32.904s
[2K
| Adam | epoch: 014 | loss: 0.06527 - acc: 0.9871 -- iter: 128/236
[A[ATraining Step: 109  | total loss: [1m[32m0.06044[0m[0m | time: 40.848s
[2K
| Adam | epoch: 014 | loss: 0.06044 - acc: 0.9884 -- iter: 160/236
[A[ATraining Step: 110  | total loss: [1m[32m0.08370[0m[0m | time: 48.821s
[2K
| Adam | epoch: 014 | loss: 0.08370 - acc: 0.9771 -- iter: 192/236
[A[ATraining Step: 111  | total loss: [1m[32m0.07564[0m[0m | time: 60.939s
[2K
| Adam | epoch: 014 | loss: 0.07564 - acc: 0.9794 -- iter: 224/236
[A[ATraining Step: 112  | total loss: [1m[32m0.09739[0m[0m | time: 78.185s
[2K
| Adam | epoch: 014 | loss: 0.09739 - acc: 0.9752 | val_loss: 5.62192 - val_acc: 0.3600 -- iter: 236/236
--
Training Step: 113  | total loss: [1m[32m0.08811[0m[0m | time: 7.833s
[2K
| Adam | epoch: 015 | loss: 0.08811 - acc: 0.9777 -- iter: 032/236
[A[ATraining Step: 114  | total loss: [1m[32m0.08244[0m[0m | time: 19.017s
[2K
| Adam | epoch: 015 | loss: 0.08244 - acc: 0.9799 -- iter: 064/236
[A[ATraining Step: 115  | total loss: [1m[32m0.07607[0m[0m | time: 30.985s
[2K
| Adam | epoch: 015 | loss: 0.07607 - acc: 0.9819 -- iter: 096/236
[A[ATraining Step: 116  | total loss: [1m[32m0.06935[0m[0m | time: 36.913s
[2K
| Adam | epoch: 015 | loss: 0.06935 - acc: 0.9837 -- iter: 128/236
[A[ATraining Step: 117  | total loss: [1m[32m0.06482[0m[0m | time: 42.482s
[2K
| Adam | epoch: 015 | loss: 0.06482 - acc: 0.9854 -- iter: 160/236
[A[ATraining Step: 118  | total loss: [1m[32m0.05969[0m[0m | time: 54.804s
[2K
| Adam | epoch: 015 | loss: 0.05969 - acc: 0.9868 -- iter: 192/236
[A[ATraining Step: 119  | total loss: [1m[32m0.07306[0m[0m | time: 66.748s
[2K
| Adam | epoch: 015 | loss: 0.07306 - acc: 0.9788 -- iter: 224/236
[A[ATraining Step: 120  | total loss: [1m[32m0.07247[0m[0m | time: 84.506s
[2K
| Adam | epoch: 015 | loss: 0.07247 - acc: 0.9778 | val_loss: 1.03441 - val_acc: 0.7733 -- iter: 236/236
--
Training Step: 121  | total loss: [1m[32m0.10462[0m[0m | time: 12.194s
[2K
| Adam | epoch: 016 | loss: 0.10462 - acc: 0.9769 -- iter: 032/236
[A[ATraining Step: 122  | total loss: [1m[32m0.10078[0m[0m | time: 24.467s
[2K
| Adam | epoch: 016 | loss: 0.10078 - acc: 0.9760 -- iter: 064/236
[A[ATraining Step: 123  | total loss: [1m[32m0.09410[0m[0m | time: 36.459s
[2K
| Adam | epoch: 016 | loss: 0.09410 - acc: 0.9784 -- iter: 096/236
[A[ATraining Step: 124  | total loss: [1m[32m0.08987[0m[0m | time: 48.291s
[2K
| Adam | epoch: 016 | loss: 0.08987 - acc: 0.9775 -- iter: 128/236
[A[ATraining Step: 125  | total loss: [1m[32m0.08384[0m[0m | time: 53.839s
[2K
| Adam | epoch: 016 | loss: 0.08384 - acc: 0.9797 -- iter: 160/236
[A[ATraining Step: 126  | total loss: [1m[32m0.10540[0m[0m | time: 59.925s
[2K
| Adam | epoch: 016 | loss: 0.10540 - acc: 0.9568 -- iter: 192/236
[A[ATraining Step: 127  | total loss: [1m[32m0.09793[0m[0m | time: 71.680s
[2K
| Adam | epoch: 016 | loss: 0.09793 - acc: 0.9611 -- iter: 224/236
[A[ATraining Step: 128  | total loss: [1m[32m0.09156[0m[0m | time: 82.977s
[2K
| Adam | epoch: 016 | loss: 0.09156 - acc: 0.9618 | val_loss: 9.00584 - val_acc: 0.3600 -- iter: 236/236
--
Training Step: 129  | total loss: [1m[32m0.08334[0m[0m | time: 11.917s
[2K
| Adam | epoch: 017 | loss: 0.08334 - acc: 0.9657 -- iter: 032/236
[A[ATraining Step: 130  | total loss: [1m[32m0.09985[0m[0m | time: 23.735s
[2K
| Adam | epoch: 017 | loss: 0.09985 - acc: 0.9597 -- iter: 064/236
[A[ATraining Step: 131  | total loss: [1m[32m0.09528[0m[0m | time: 35.959s
[2K
| Adam | epoch: 017 | loss: 0.09528 - acc: 0.9637 -- iter: 096/236
[A[ATraining Step: 132  | total loss: [1m[32m0.08811[0m[0m | time: 48.432s
[2K
| Adam | epoch: 017 | loss: 0.08811 - acc: 0.9674 -- iter: 128/236
[A[ATraining Step: 133  | total loss: [1m[32m0.08166[0m[0m | time: 60.327s
[2K
| Adam | epoch: 017 | loss: 0.08166 - acc: 0.9706 -- iter: 160/236
[A[ATraining Step: 134  | total loss: [1m[32m0.07491[0m[0m | time: 66.463s
[2K
| Adam | epoch: 017 | loss: 0.07491 - acc: 0.9736 -- iter: 192/236
[A[ATraining Step: 135  | total loss: [1m[32m0.06754[0m[0m | time: 71.896s
[2K
| Adam | epoch: 017 | loss: 0.06754 - acc: 0.9762 -- iter: 224/236
[A[ATraining Step: 136  | total loss: [1m[32m0.06089[0m[0m | time: 90.037s
[2K
| Adam | epoch: 017 | loss: 0.06089 - acc: 0.9786 | val_loss: 4.27962 - val_acc: 0.4267 -- iter: 236/236
--
Training Step: 137  | total loss: [1m[32m0.07605[0m[0m | time: 12.283s
[2K
| Adam | epoch: 018 | loss: 0.07605 - acc: 0.9714 -- iter: 032/236
[A[ATraining Step: 138  | total loss: [1m[32m0.07850[0m[0m | time: 24.173s
[2K
| Adam | epoch: 018 | loss: 0.07850 - acc: 0.9680 -- iter: 064/236
[A[ATraining Step: 139  | total loss: [1m[32m0.07466[0m[0m | time: 36.319s
[2K
| Adam | epoch: 018 | loss: 0.07466 - acc: 0.9681 -- iter: 096/236
[A[ATraining Step: 140  | total loss: [1m[32m0.06833[0m[0m | time: 48.486s
[2K
| Adam | epoch: 018 | loss: 0.06833 - acc: 0.9712 -- iter: 128/236
[A[ATraining Step: 141  | total loss: [1m[32m0.06209[0m[0m | time: 60.768s
[2K
| Adam | epoch: 018 | loss: 0.06209 - acc: 0.9741 -- iter: 160/236
[A[ATraining Step: 142  | total loss: [1m[32m0.07773[0m[0m | time: 73.282s
[2K
| Adam | epoch: 018 | loss: 0.07773 - acc: 0.9705 -- iter: 192/236
[A[ATraining Step: 143  | total loss: [1m[32m0.08162[0m[0m | time: 79.307s
[2K
| Adam | epoch: 018 | loss: 0.08162 - acc: 0.9703 -- iter: 224/236
[A[ATraining Step: 144  | total loss: [1m[32m0.07386[0m[0m | time: 86.362s
[2K
| Adam | epoch: 018 | loss: 0.07386 - acc: 0.9733 | val_loss: 1.14890 - val_acc: 0.7600 -- iter: 236/236
--
Training Step: 145  | total loss: [1m[32m0.06721[0m[0m | time: 12.053s
[2K
| Adam | epoch: 019 | loss: 0.06721 - acc: 0.9759 -- iter: 032/236
[A[ATraining Step: 146  | total loss: [1m[32m0.09604[0m[0m | time: 24.066s
[2K
| Adam | epoch: 019 | loss: 0.09604 - acc: 0.9690 -- iter: 064/236
[A[ATraining Step: 147  | total loss: [1m[32m0.09994[0m[0m | time: 35.592s
[2K
| Adam | epoch: 019 | loss: 0.09994 - acc: 0.9627 -- iter: 096/236
[A[ATraining Step: 148  | total loss: [1m[32m0.09457[0m[0m | time: 47.377s
[2K
| Adam | epoch: 019 | loss: 0.09457 - acc: 0.9664 -- iter: 128/236
[A[ATraining Step: 149  | total loss: [1m[32m0.08621[0m[0m | time: 59.550s
[2K
| Adam | epoch: 019 | loss: 0.08621 - acc: 0.9698 -- iter: 160/236
[A[ATraining Step: 150  | total loss: [1m[32m0.07831[0m[0m | time: 71.636s
[2K
| Adam | epoch: 019 | loss: 0.07831 - acc: 0.9728 -- iter: 192/236
[A[ATraining Step: 151  | total loss: [1m[32m0.08392[0m[0m | time: 83.747s
[2K
| Adam | epoch: 019 | loss: 0.08392 - acc: 0.9693 -- iter: 224/236
[A[ATraining Step: 152  | total loss: [1m[32m0.07785[0m[0m | time: 95.323s
[2K
| Adam | epoch: 019 | loss: 0.07785 - acc: 0.9723 | val_loss: 0.75245 - val_acc: 0.8133 -- iter: 236/236
--
Training Step: 153  | total loss: [1m[32m0.07048[0m[0m | time: 5.897s
[2K
| Adam | epoch: 020 | loss: 0.07048 - acc: 0.9751 -- iter: 032/236
[A[ATraining Step: 154  | total loss: [1m[32m0.06377[0m[0m | time: 18.134s
[2K
| Adam | epoch: 020 | loss: 0.06377 - acc: 0.9776 -- iter: 064/236
[A[ATraining Step: 155  | total loss: [1m[32m0.06787[0m[0m | time: 30.548s
[2K
| Adam | epoch: 020 | loss: 0.06787 - acc: 0.9767 -- iter: 096/236
[A[ATraining Step: 156  | total loss: [1m[32m0.06199[0m[0m | time: 43.672s
[2K
| Adam | epoch: 020 | loss: 0.06199 - acc: 0.9790 -- iter: 128/236
[A[ATraining Step: 157  | total loss: [1m[32m0.13426[0m[0m | time: 56.371s
[2K
| Adam | epoch: 020 | loss: 0.13426 - acc: 0.9718 -- iter: 160/236
[A[ATraining Step: 158  | total loss: [1m[32m0.12406[0m[0m | time: 69.548s
[2K
| Adam | epoch: 020 | loss: 0.12406 - acc: 0.9746 -- iter: 192/236
[A[ATraining Step: 159  | total loss: [1m[32m0.11235[0m[0m | time: 82.447s
[2K
| Adam | epoch: 020 | loss: 0.11235 - acc: 0.9771 -- iter: 224/236
[A[ATraining Step: 160  | total loss: [1m[32m0.10427[0m[0m | time: 94.246s
[2K
| Adam | epoch: 020 | loss: 0.10427 - acc: 0.9763 | val_loss: 0.66028 - val_acc: 0.8267 -- iter: 236/236
--
Training Step: 161  | total loss: [1m[32m0.09699[0m[0m | time: 8.835s
[2K
| Adam | epoch: 021 | loss: 0.09699 - acc: 0.9755 -- iter: 032/236
[A[ATraining Step: 162  | total loss: [1m[32m0.08792[0m[0m | time: 17.383s
[2K
| Adam | epoch: 021 | loss: 0.08792 - acc: 0.9780 -- iter: 064/236
[A[ATraining Step: 163  | total loss: [1m[32m0.07965[0m[0m | time: 41.256s
[2K
| Adam | epoch: 021 | loss: 0.07965 - acc: 0.9802 -- iter: 096/236
[A[ATraining Step: 164  | total loss: [1m[32m0.07234[0m[0m | time: 62.968s
[2K
| Adam | epoch: 021 | loss: 0.07234 - acc: 0.9822 -- iter: 128/236
[A[ATraining Step: 165  | total loss: [1m[32m0.06635[0m[0m | time: 83.115s
[2K
| Adam | epoch: 021 | loss: 0.06635 - acc: 0.9839 -- iter: 160/236
[A[ATraining Step: 166  | total loss: [1m[32m0.06415[0m[0m | time: 100.179s
[2K
| Adam | epoch: 021 | loss: 0.06415 - acc: 0.9824 -- iter: 192/236
[A[ATraining Step: 167  | total loss: [1m[32m0.06263[0m[0m | time: 119.136s
[2K
| Adam | epoch: 021 | loss: 0.06263 - acc: 0.9811 -- iter: 224/236
[A[ATraining Step: 168  | total loss: [1m[32m0.05718[0m[0m | time: 146.588s
[2K
| Adam | epoch: 021 | loss: 0.05718 - acc: 0.9830 | val_loss: 0.50806 - val_acc: 0.8667 -- iter: 236/236
--
Training Step: 169  | total loss: [1m[32m0.05294[0m[0m | time: 34.796s
[2K
| Adam | epoch: 022 | loss: 0.05294 - acc: 0.9847 -- iter: 032/236
[A[ATraining Step: 170  | total loss: [1m[32m0.05923[0m[0m | time: 43.772s
[2K
| Adam | epoch: 022 | loss: 0.05923 - acc: 0.9831 -- iter: 064/236
[A[ATraining Step: 171  | total loss: [1m[32m0.05432[0m[0m | time: 52.454s
[2K
| Adam | epoch: 022 | loss: 0.05432 - acc: 0.9848 -- iter: 096/236
[A[ATraining Step: 172  | total loss: [1m[32m0.04967[0m[0m | time: 81.671s
[2K
| Adam | epoch: 022 | loss: 0.04967 - acc: 0.9863 -- iter: 128/236
[A[ATraining Step: 173  | total loss: [1m[32m0.04554[0m[0m | time: 101.245s
[2K
| Adam | epoch: 022 | loss: 0.04554 - acc: 0.9877 -- iter: 160/236
[A[ATraining Step: 174  | total loss: [1m[32m0.04203[0m[0m | time: 118.966s
[2K
| Adam | epoch: 022 | loss: 0.04203 - acc: 0.9889 -- iter: 192/236
[A[ATraining Step: 175  | total loss: [1m[32m0.05496[0m[0m | time: 138.038s
[2K
| Adam | epoch: 022 | loss: 0.05496 - acc: 0.9869 -- iter: 224/236
[A[ATraining Step: 176  | total loss: [1m[32m0.05051[0m[0m | time: 164.812s
[2K
| Adam | epoch: 022 | loss: 0.05051 - acc: 0.9882 | val_loss: 0.98870 - val_acc: 0.7733 -- iter: 236/236
--
Training Step: 177  | total loss: [1m[32m0.04765[0m[0m | time: 78.351s
[2K
| Adam | epoch: 023 | loss: 0.04765 - acc: 0.9894 -- iter: 032/236
[A[ATraining Step: 178  | total loss: [1m[32m0.04325[0m[0m | time: 114.608s
[2K
| Adam | epoch: 023 | loss: 0.04325 - acc: 0.9904 -- iter: 064/236
[A[ATraining Step: 179  | total loss: [1m[32m0.04227[0m[0m | time: 122.872s
[2K
| Adam | epoch: 023 | loss: 0.04227 - acc: 0.9914 -- iter: 096/236
[A[ATraining Step: 180  | total loss: [1m[32m0.04390[0m[0m | time: 131.679s
[2K
| Adam | epoch: 023 | loss: 0.04390 - acc: 0.9923 -- iter: 128/236
[A[ATraining Step: 181  | total loss: [1m[32m0.04218[0m[0m | time: 175.575s
[2K
| Adam | epoch: 023 | loss: 0.04218 - acc: 0.9930 -- iter: 160/236
[A[ATraining Step: 182  | total loss: [1m[32m0.03926[0m[0m | time: 207.617s
[2K
| Adam | epoch: 023 | loss: 0.03926 - acc: 0.9937 -- iter: 192/236
[A[ATraining Step: 183  | total loss: [1m[32m0.03568[0m[0m | time: 225.321s
[2K
| Adam | epoch: 023 | loss: 0.03568 - acc: 0.9944 -- iter: 224/236
[A[ATraining Step: 184  | total loss: [1m[32m0.05612[0m[0m | time: 251.845s
[2K
| Adam | epoch: 023 | loss: 0.05612 - acc: 0.9918 | val_loss: 0.50643 - val_acc: 0.8800 -- iter: 236/236
--
Training Step: 185  | total loss: [1m[32m0.05248[0m[0m | time: 16.957s
[2K
| Adam | epoch: 024 | loss: 0.05248 - acc: 0.9926 -- iter: 032/236
[A[ATraining Step: 186  | total loss: [1m[32m0.04811[0m[0m | time: 34.082s
[2K
| Adam | epoch: 024 | loss: 0.04811 - acc: 0.9934 -- iter: 064/236
[A[ATraining Step: 187  | total loss: [1m[32m0.04365[0m[0m | time: 51.582s
[2K
| Adam | epoch: 024 | loss: 0.04365 - acc: 0.9940 -- iter: 096/236
[A[ATraining Step: 188  | total loss: [1m[32m0.03963[0m[0m | time: 60.425s
[2K
| Adam | epoch: 024 | loss: 0.03963 - acc: 0.9946 -- iter: 128/236
[A[ATraining Step: 189  | total loss: [1m[32m0.03615[0m[0m | time: 68.509s
[2K
| Adam | epoch: 024 | loss: 0.03615 - acc: 0.9952 -- iter: 160/236
[A[ATraining Step: 190  | total loss: [1m[32m0.03279[0m[0m | time: 85.925s
[2K
| Adam | epoch: 024 | loss: 0.03279 - acc: 0.9956 -- iter: 192/236
[A[ATraining Step: 191  | total loss: [1m[32m0.03155[0m[0m | time: 103.467s
[2K
| Adam | epoch: 024 | loss: 0.03155 - acc: 0.9961 -- iter: 224/236
[A[ATraining Step: 192  | total loss: [1m[32m0.02866[0m[0m | time: 129.087s
[2K
| Adam | epoch: 024 | loss: 0.02866 - acc: 0.9965 | val_loss: 1.21259 - val_acc: 0.7333 -- iter: 236/236
--
Training Step: 193  | total loss: [1m[32m0.04008[0m[0m | time: 13.115s
[2K
| Adam | epoch: 025 | loss: 0.04008 - acc: 0.9937 -- iter: 032/236
[A[ATraining Step: 194  | total loss: [1m[32m0.04149[0m[0m | time: 28.784s
[2K
| Adam | epoch: 025 | loss: 0.04149 - acc: 0.9912 -- iter: 064/236
[A[ATraining Step: 195  | total loss: [1m[32m0.03768[0m[0m | time: 46.185s
[2K
| Adam | epoch: 025 | loss: 0.03768 - acc: 0.9921 -- iter: 096/236
[A[ATraining Step: 196  | total loss: [1m[32m0.03808[0m[0m | time: 64.106s
[2K
| Adam | epoch: 025 | loss: 0.03808 - acc: 0.9929 -- iter: 128/236
[A[ATraining Step: 197  | total loss: [1m[32m0.03470[0m[0m | time: 73.064s
[2K
| Adam | epoch: 025 | loss: 0.03470 - acc: 0.9936 -- iter: 160/236
[A[ATraining Step: 198  | total loss: [1m[32m0.03313[0m[0m | time: 81.927s
[2K
| Adam | epoch: 025 | loss: 0.03313 - acc: 0.9942 -- iter: 192/236
[A[ATraining Step: 199  | total loss: [1m[32m0.03096[0m[0m | time: 100.250s
[2K
| Adam | epoch: 025 | loss: 0.03096 - acc: 0.9948 -- iter: 224/236
[A[ATraining Step: 200  | total loss: [1m[32m0.04868[0m[0m | time: 126.236s
[2K
| Adam | epoch: 025 | loss: 0.04868 - acc: 0.9922 | val_loss: 3.54960 - val_acc: 0.4267 -- iter: 236/236
--
Training Step: 201  | total loss: [1m[32m0.04439[0m[0m | time: 15.415s
[2K
| Adam | epoch: 026 | loss: 0.04439 - acc: 0.9930 -- iter: 032/236
[A[ATraining Step: 202  | total loss: [1m[32m0.04141[0m[0m | time: 29.712s
[2K
| Adam | epoch: 026 | loss: 0.04141 - acc: 0.9937 -- iter: 064/236
[A[ATraining Step: 203  | total loss: [1m[32m0.03925[0m[0m | time: 47.164s
[2K
| Adam | epoch: 026 | loss: 0.03925 - acc: 0.9943 -- iter: 096/236
[A[ATraining Step: 204  | total loss: [1m[32m0.03801[0m[0m | time: 65.369s
[2K
| Adam | epoch: 026 | loss: 0.03801 - acc: 0.9949 -- iter: 128/236
[A[ATraining Step: 205  | total loss: [1m[32m0.04061[0m[0m | time: 81.976s
[2K
| Adam | epoch: 026 | loss: 0.04061 - acc: 0.9923 -- iter: 160/236
[A[ATraining Step: 206  | total loss: [1m[32m0.03696[0m[0m | time: 87.905s
[2K
| Adam | epoch: 026 | loss: 0.03696 - acc: 0.9930 -- iter: 192/236
[A[ATraining Step: 207  | total loss: [1m[32m0.03363[0m[0m | time: 93.751s
[2K
| Adam | epoch: 026 | loss: 0.03363 - acc: 0.9937 -- iter: 224/236
[A[ATraining Step: 208  | total loss: [1m[32m0.03077[0m[0m | time: 111.764s
[2K
| Adam | epoch: 026 | loss: 0.03077 - acc: 0.9944 | val_loss: 2.65563 - val_acc: 0.5200 -- iter: 236/236
--
Training Step: 209  | total loss: [1m[32m0.03781[0m[0m | time: 17.291s
[2K
| Adam | epoch: 027 | loss: 0.03781 - acc: 0.9887 -- iter: 032/236
[A[ATraining Step: 210  | total loss: [1m[32m0.03564[0m[0m | time: 30.264s
[2K
| Adam | epoch: 027 | loss: 0.03564 - acc: 0.9898 -- iter: 064/236
[A[ATraining Step: 211  | total loss: [1m[32m0.07302[0m[0m | time: 44.200s
[2K
| Adam | epoch: 027 | loss: 0.07302 - acc: 0.9846 -- iter: 096/236
[A[ATraining Step: 212  | total loss: [1m[32m0.06687[0m[0m | time: 61.356s
[2K
| Adam | epoch: 027 | loss: 0.06687 - acc: 0.9861 -- iter: 128/236
[A[ATraining Step: 213  | total loss: [1m[32m0.06035[0m[0m | time: 78.492s
[2K
| Adam | epoch: 027 | loss: 0.06035 - acc: 0.9875 -- iter: 160/236
[A[ATraining Step: 214  | total loss: [1m[32m0.05530[0m[0m | time: 96.214s
[2K
| Adam | epoch: 027 | loss: 0.05530 - acc: 0.9888 -- iter: 192/236
[A[ATraining Step: 215  | total loss: [1m[32m0.05078[0m[0m | time: 104.357s
[2K
| Adam | epoch: 027 | loss: 0.05078 - acc: 0.9899 -- iter: 224/236
[A[ATraining Step: 216  | total loss: [1m[32m0.12674[0m[0m | time: 120.934s
[2K
| Adam | epoch: 027 | loss: 0.12674 - acc: 0.9742 | val_loss: 4.09128 - val_acc: 0.3600 -- iter: 236/236
--
Training Step: 217  | total loss: [1m[32m0.16303[0m[0m | time: 17.423s
[2K
| Adam | epoch: 028 | loss: 0.16303 - acc: 0.9685 -- iter: 032/236
[A[ATraining Step: 218  | total loss: [1m[32m0.16483[0m[0m | time: 34.878s
[2K
| Adam | epoch: 028 | loss: 0.16483 - acc: 0.9622 -- iter: 064/236
[A[ATraining Step: 219  | total loss: [1m[32m0.15662[0m[0m | time: 52.847s
[2K
| Adam | epoch: 028 | loss: 0.15662 - acc: 0.9598 -- iter: 096/236
[A[ATraining Step: 220  | total loss: [1m[32m0.16083[0m[0m | time: 70.833s
[2K
| Adam | epoch: 028 | loss: 0.16083 - acc: 0.9575 -- iter: 128/236
[A[ATraining Step: 221  | total loss: [1m[32m0.15382[0m[0m | time: 88.523s
[2K
| Adam | epoch: 028 | loss: 0.15382 - acc: 0.9587 -- iter: 160/236
[A[ATraining Step: 222  | total loss: [1m[32m0.15303[0m[0m | time: 106.247s
[2K
| Adam | epoch: 028 | loss: 0.15303 - acc: 0.9566 -- iter: 192/236
[A[ATraining Step: 223  | total loss: [1m[32m0.15488[0m[0m | time: 123.740s
[2K
| Adam | epoch: 028 | loss: 0.15488 - acc: 0.9515 -- iter: 224/236
[A[ATraining Step: 224  | total loss: [1m[32m0.14796[0m[0m | time: 140.467s
[2K
| Adam | epoch: 028 | loss: 0.14796 - acc: 0.9532 | val_loss: 5.89771 - val_acc: 0.3600 -- iter: 236/236
--
Training Step: 225  | total loss: [1m[32m0.19457[0m[0m | time: 8.758s
[2K
| Adam | epoch: 029 | loss: 0.19457 - acc: 0.9329 -- iter: 032/236
[A[ATraining Step: 226  | total loss: [1m[32m0.19361[0m[0m | time: 26.003s
[2K
| Adam | epoch: 029 | loss: 0.19361 - acc: 0.9396 -- iter: 064/236
[A[ATraining Step: 227  | total loss: [1m[32m0.17845[0m[0m | time: 43.068s
[2K
| Adam | epoch: 029 | loss: 0.17845 - acc: 0.9457 -- iter: 096/236
[A[ATraining Step: 228  | total loss: [1m[32m0.18895[0m[0m | time: 55.760s
[2K
| Adam | epoch: 029 | loss: 0.18895 - acc: 0.9386 -- iter: 128/236
[A[ATraining Step: 229  | total loss: [1m[32m0.18560[0m[0m | time: 69.547s
[2K
| Adam | epoch: 029 | loss: 0.18560 - acc: 0.9416 -- iter: 160/236
[A[ATraining Step: 230  | total loss: [1m[32m0.18263[0m[0m | time: 86.561s
[2K
| Adam | epoch: 029 | loss: 0.18263 - acc: 0.9412 -- iter: 192/236
[A[ATraining Step: 231  | total loss: [1m[32m0.16887[0m[0m | time: 103.933s
[2K
| Adam | epoch: 029 | loss: 0.16887 - acc: 0.9440 -- iter: 224/236
[A[ATraining Step: 232  | total loss: [1m[32m0.15931[0m[0m | time: 129.139s
[2K
| Adam | epoch: 029 | loss: 0.15931 - acc: 0.9464 | val_loss: 1.45560 - val_acc: 0.7067 -- iter: 236/236
--
Training Step: 233  | total loss: [1m[32m0.14478[0m[0m | time: 8.872s
[2K
| Adam | epoch: 030 | loss: 0.14478 - acc: 0.9518 -- iter: 032/236
[A[ATraining Step: 234  | total loss: [1m[32m0.13037[0m[0m | time: 17.357s
[2K
| Adam | epoch: 030 | loss: 0.13037 - acc: 0.9566 -- iter: 064/236
[A[ATraining Step: 235  | total loss: [1m[32m0.11746[0m[0m | time: 34.829s
[2K
| Adam | epoch: 030 | loss: 0.11746 - acc: 0.9610 -- iter: 096/236
[A[ATraining Step: 236  | total loss: [1m[32m0.10630[0m[0m | time: 52.492s
[2K
| Adam | epoch: 030 | loss: 0.10630 - acc: 0.9649 -- iter: 128/236
[A[ATraining Step: 237  | total loss: [1m[32m0.12483[0m[0m | time: 69.652s
[2K
| Adam | epoch: 030 | loss: 0.12483 - acc: 0.9527 -- iter: 160/236
[A[ATraining Step: 238  | total loss: [1m[32m0.11400[0m[0m | time: 86.626s
[2K
| Adam | epoch: 030 | loss: 0.11400 - acc: 0.9575 -- iter: 192/236
[A[ATraining Step: 239  | total loss: [1m[32m0.11349[0m[0m | time: 103.891s
[2K
| Adam | epoch: 030 | loss: 0.11349 - acc: 0.9586 -- iter: 224/236
[A[ATraining Step: 240  | total loss: [1m[32m0.10336[0m[0m | time: 128.975s
[2K
| Adam | epoch: 030 | loss: 0.10336 - acc: 0.9627 | val_loss: 1.29034 - val_acc: 0.7600 -- iter: 236/236
--
Validation AUC:0.9382716049382717
Validation AUPRC:0.9733975686879576
Test AUC:0.8795093795093795
Test AUPRC:0.9072606226827145
BestTestF1Score	0.84	0.62	0.81	0.79	0.9	38	10	23	4	1.0
BestTestMCCScore	0.84	0.62	0.81	0.79	0.9	38	10	23	4	1.0
BestTestAccuracyScore	0.84	0.62	0.81	0.79	0.9	38	10	23	4	1.0
BestValidationF1Score	0.91	0.74	0.88	0.9	0.92	44	5	22	4	1.0
BestValidationMCC	0.91	0.74	0.88	0.9	0.92	44	5	22	4	1.0
BestValidationAccuracy	0.91	0.74	0.88	0.9	0.92	44	5	22	4	1.0
TestPredictions (Threshold:1.0)
CHEMBL216426,TP,ACT,1.0	CHEMBL2147702,TP,ACT,1.0	CHEMBL2147711,TP,ACT,1.0	CHEMBL238515,TP,ACT,1.0	CHEMBL557575,TP,ACT,1.0	CHEMBL443622,TN,INACT,0.7900000214576721	CHEMBL361863,TN,INACT,0.4099999964237213	CHEMBL371143,TP,ACT,1.0	CHEMBL554880,TN,INACT,0.029999999329447746	CHEMBL3704836,FP,INACT,1.0	CHEMBL2147777,TP,ACT,1.0	CHEMBL2147703,TP,ACT,1.0	CHEMBL258101,TP,ACT,1.0	CHEMBL223114,TP,ACT,1.0	CHEMBL77539,FN,ACT,0.9900000095367432	CHEMBL556754,TP,ACT,1.0	CHEMBL241253,TP,ACT,1.0	CHEMBL584698,TN,INACT,0.949999988079071	CHEMBL352402,TN,INACT,0.8399999737739563	CHEMBL178401,FP,INACT,1.0	CHEMBL239565,TP,ACT,1.0	CHEMBL184140,TP,ACT,1.0	CHEMBL192882,TP,ACT,1.0	CHEMBL399610,TP,ACT,1.0	CHEMBL1812729,TN,INACT,0.0	CHEMBL386895,TN,INACT,0.0	CHEMBL241673,TP,ACT,1.0	CHEMBL1087094,FP,INACT,1.0	CHEMBL362297,TP,ACT,1.0	CHEMBL8260,TN,INACT,0.6800000071525574	CHEMBL75589,FP,INACT,1.0	CHEMBL2147715,TP,ACT,1.0	CHEMBL2147706,TP,ACT,1.0	CHEMBL195271,TN,INACT,0.20000000298023224	CHEMBL384382,FP,INACT,1.0	CHEMBL386325,TP,ACT,1.0	CHEMBL153037,TN,INACT,0.0	CHEMBL381626,FN,ACT,0.0	CHEMBL365291,FN,ACT,0.8500000238418579	CHEMBL169812,TN,INACT,0.5699999928474426	CHEMBL271870,TP,ACT,1.0	CHEMBL534918,TP,ACT,1.0	CHEMBL1161919,TP,ACT,1.0	CHEMBL256691,TP,ACT,1.0	CHEMBL3800113,FP,INACT,1.0	CHEMBL536486,TP,ACT,1.0	CHEMBL585290,TN,INACT,0.949999988079071	CHEMBL65463,TN,INACT,0.5400000214576721	CHEMBL9561,FP,INACT,1.0	CHEMBL387260,TP,ACT,1.0	CHEMBL3233549,TN,INACT,0.4399999976158142	CHEMBL328694,TN,INACT,0.949999988079071	CHEMBL402645,TP,ACT,1.0	CHEMBL567727,FP,INACT,1.0	CHEMBL146995,FP,INACT,1.0	CHEMBL1812910,FP,INACT,1.0	CHEMBL2048503,TN,INACT,0.949999988079071	CHEMBL511659,TN,INACT,0.05000000074505806	CHEMBL226771,TP,ACT,1.0	CHEMBL195335,TP,ACT,1.0	CHEMBL539939,TP,ACT,1.0	CHEMBL241464,TP,ACT,1.0	CHEMBL3665967,TP,ACT,1.0	CHEMBL404159,TP,ACT,1.0	CHEMBL2425078,TN,INACT,0.0	CHEMBL437964,TN,INACT,0.0	CHEMBL1724888,TN,INACT,0.8299999833106995	CHEMBL376562,TP,ACT,1.0	CHEMBL371585,TP,ACT,1.0	CHEMBL328197,TN,INACT,0.9200000166893005	CHEMBL88474,TN,INACT,0.9399999976158142	CHEMBL2058758,TP,ACT,1.0	CHEMBL2058756,TP,ACT,1.0	CHEMBL17347,TN,INACT,0.15000000596046448	CHEMBL379522,FN,ACT,0.0	

