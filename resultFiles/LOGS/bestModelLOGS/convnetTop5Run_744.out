ImageNetInceptionV2 CHEMBL308 RMSprop 0.001 15 0 0 0.6 False True
Number of active compounds :	918
Number of inactive compounds :	918
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL308_RMSprop_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL308_RMSprop_0.001_15_0.6/
---------------------------------
Training samples: 1145
Validation samples: 358
--
Training Step: 1  | time: 169.673s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1145
[A[ATraining Step: 2  | total loss: [1m[32m0.59128[0m[0m | time: 313.186s
[2K
| RMSProp | epoch: 001 | loss: 0.59128 - acc: 0.5344 -- iter: 0064/1145
[A[ATraining Step: 3  | total loss: [1m[32m0.68174[0m[0m | time: 429.206s
[2K
| RMSProp | epoch: 001 | loss: 0.68174 - acc: 0.5318 -- iter: 0096/1145
[A[ATraining Step: 4  | total loss: [1m[32m0.76423[0m[0m | time: 526.012s
[2K
| RMSProp | epoch: 001 | loss: 0.76423 - acc: 0.4142 -- iter: 0128/1145
[A[ATraining Step: 5  | total loss: [1m[32m0.71288[0m[0m | time: 641.450s
[2K
| RMSProp | epoch: 001 | loss: 0.71288 - acc: 0.4520 -- iter: 0160/1145
[A[ATraining Step: 6  | total loss: [1m[32m0.71301[0m[0m | time: 668.538s
[2K
| RMSProp | epoch: 001 | loss: 0.71301 - acc: 0.5029 -- iter: 0192/1145
[A[ATraining Step: 7  | total loss: [1m[32m0.69788[0m[0m | time: 832.258s
[2K
| RMSProp | epoch: 001 | loss: 0.69788 - acc: 0.5199 -- iter: 0224/1145
[A[ATraining Step: 8  | total loss: [1m[32m0.72526[0m[0m | time: 1040.567s
[2K
| RMSProp | epoch: 001 | loss: 0.72526 - acc: 0.4736 -- iter: 0256/1145
[A[ATraining Step: 9  | total loss: [1m[32m0.70895[0m[0m | time: 1083.902s
[2K
| RMSProp | epoch: 001 | loss: 0.70895 - acc: 0.5372 -- iter: 0288/1145
[A[ATraining Step: 10  | total loss: [1m[32m0.70656[0m[0m | time: 1093.642s
[2K
| RMSProp | epoch: 001 | loss: 0.70656 - acc: 0.5498 -- iter: 0320/1145
[A[ATraining Step: 11  | total loss: [1m[32m0.70239[0m[0m | time: 1101.659s
[2K
| RMSProp | epoch: 001 | loss: 0.70239 - acc: 0.5262 -- iter: 0352/1145
[A[ATraining Step: 12  | total loss: [1m[32m0.69836[0m[0m | time: 1109.945s
[2K
| RMSProp | epoch: 001 | loss: 0.69836 - acc: 0.5566 -- iter: 0384/1145
[A[ATraining Step: 13  | total loss: [1m[32m0.71126[0m[0m | time: 1118.106s
[2K
| RMSProp | epoch: 001 | loss: 0.71126 - acc: 0.5591 -- iter: 0416/1145
[A[ATraining Step: 14  | total loss: [1m[32m0.73363[0m[0m | time: 1126.369s
[2K
| RMSProp | epoch: 001 | loss: 0.73363 - acc: 0.5349 -- iter: 0448/1145
[A[ATraining Step: 15  | total loss: [1m[32m0.72449[0m[0m | time: 1134.273s
[2K
| RMSProp | epoch: 001 | loss: 0.72449 - acc: 0.5213 -- iter: 0480/1145
[A[ATraining Step: 16  | total loss: [1m[32m0.71063[0m[0m | time: 1142.597s
[2K
| RMSProp | epoch: 001 | loss: 0.71063 - acc: 0.5250 -- iter: 0512/1145
[A[ATraining Step: 17  | total loss: [1m[32m0.70467[0m[0m | time: 1150.738s
[2K
| RMSProp | epoch: 001 | loss: 0.70467 - acc: 0.5385 -- iter: 0544/1145
[A[ATraining Step: 18  | total loss: [1m[32m0.69541[0m[0m | time: 1158.695s
[2K
| RMSProp | epoch: 001 | loss: 0.69541 - acc: 0.5035 -- iter: 0576/1145
[A[ATraining Step: 19  | total loss: [1m[32m0.68421[0m[0m | time: 1166.870s
[2K
| RMSProp | epoch: 001 | loss: 0.68421 - acc: 0.5753 -- iter: 0608/1145
[A[ATraining Step: 20  | total loss: [1m[32m0.71435[0m[0m | time: 1175.066s
[2K
| RMSProp | epoch: 001 | loss: 0.71435 - acc: 0.5310 -- iter: 0640/1145
[A[ATraining Step: 21  | total loss: [1m[32m0.70751[0m[0m | time: 1182.848s
[2K
| RMSProp | epoch: 001 | loss: 0.70751 - acc: 0.5117 -- iter: 0672/1145
[A[ATraining Step: 22  | total loss: [1m[32m0.70450[0m[0m | time: 1191.019s
[2K
| RMSProp | epoch: 001 | loss: 0.70450 - acc: 0.5082 -- iter: 0704/1145
[A[ATraining Step: 23  | total loss: [1m[32m0.69795[0m[0m | time: 1200.783s
[2K
| RMSProp | epoch: 001 | loss: 0.69795 - acc: 0.5421 -- iter: 0736/1145
[A[ATraining Step: 24  | total loss: [1m[32m0.71248[0m[0m | time: 1209.168s
[2K
| RMSProp | epoch: 001 | loss: 0.71248 - acc: 0.5478 -- iter: 0768/1145
[A[ATraining Step: 25  | total loss: [1m[32m0.72286[0m[0m | time: 1217.325s
[2K
| RMSProp | epoch: 001 | loss: 0.72286 - acc: 0.5007 -- iter: 0800/1145
[A[ATraining Step: 26  | total loss: [1m[32m0.74139[0m[0m | time: 1225.294s
[2K
| RMSProp | epoch: 001 | loss: 0.74139 - acc: 0.4840 -- iter: 0832/1145
[A[ATraining Step: 27  | total loss: [1m[32m0.75761[0m[0m | time: 1233.867s
[2K
| RMSProp | epoch: 001 | loss: 0.75761 - acc: 0.4479 -- iter: 0864/1145
[A[ATraining Step: 28  | total loss: [1m[32m0.74748[0m[0m | time: 1241.882s
[2K
| RMSProp | epoch: 001 | loss: 0.74748 - acc: 0.4531 -- iter: 0896/1145
[A[ATraining Step: 29  | total loss: [1m[32m0.73663[0m[0m | time: 1249.886s
[2K
| RMSProp | epoch: 001 | loss: 0.73663 - acc: 0.4417 -- iter: 0928/1145
[A[ATraining Step: 30  | total loss: [1m[32m0.73062[0m[0m | time: 1271.471s
[2K
| RMSProp | epoch: 001 | loss: 0.73062 - acc: 0.4481 -- iter: 0960/1145
[A[ATraining Step: 31  | total loss: [1m[32m0.72800[0m[0m | time: 1279.715s
[2K
| RMSProp | epoch: 001 | loss: 0.72800 - acc: 0.4673 -- iter: 0992/1145
[A[ATraining Step: 32  | total loss: [1m[32m0.71692[0m[0m | time: 1287.795s
[2K
| RMSProp | epoch: 001 | loss: 0.71692 - acc: 0.4887 -- iter: 1024/1145
[A[ATraining Step: 33  | total loss: [1m[32m0.71388[0m[0m | time: 1295.769s
[2K
| RMSProp | epoch: 001 | loss: 0.71388 - acc: 0.4981 -- iter: 1056/1145
[A[ATraining Step: 34  | total loss: [1m[32m0.71583[0m[0m | time: 1304.011s
[2K
| RMSProp | epoch: 001 | loss: 0.71583 - acc: 0.4717 -- iter: 1088/1145
[A[ATraining Step: 35  | total loss: [1m[32m0.70627[0m[0m | time: 1311.893s
[2K
| RMSProp | epoch: 001 | loss: 0.70627 - acc: 0.4972 -- iter: 1120/1145
[A[ATraining Step: 36  | total loss: [1m[32m0.71256[0m[0m | time: 1340.101s
[2K
| RMSProp | epoch: 001 | loss: 0.71256 - acc: 0.5042 | val_loss: 0.70012 - val_acc: 0.4972 -- iter: 1145/1145
--
Training Step: 37  | total loss: [1m[32m0.71828[0m[0m | time: 6.659s
[2K
| RMSProp | epoch: 002 | loss: 0.71828 - acc: 0.4994 -- iter: 0032/1145
[A[ATraining Step: 38  | total loss: [1m[32m0.70053[0m[0m | time: 14.959s
[2K
| RMSProp | epoch: 002 | loss: 0.70053 - acc: 0.5190 -- iter: 0064/1145
[A[ATraining Step: 39  | total loss: [1m[32m0.69956[0m[0m | time: 23.127s
[2K
| RMSProp | epoch: 002 | loss: 0.69956 - acc: 0.5334 -- iter: 0096/1145
[A[ATraining Step: 40  | total loss: [1m[32m0.69171[0m[0m | time: 30.958s
[2K
| RMSProp | epoch: 002 | loss: 0.69171 - acc: 0.5447 -- iter: 0128/1145
[A[ATraining Step: 41  | total loss: [1m[32m0.68336[0m[0m | time: 39.066s
[2K
| RMSProp | epoch: 002 | loss: 0.68336 - acc: 0.5594 -- iter: 0160/1145
[A[ATraining Step: 42  | total loss: [1m[32m0.67948[0m[0m | time: 47.211s
[2K
| RMSProp | epoch: 002 | loss: 0.67948 - acc: 0.5600 -- iter: 0192/1145
[A[ATraining Step: 43  | total loss: [1m[32m0.68304[0m[0m | time: 55.175s
[2K
| RMSProp | epoch: 002 | loss: 0.68304 - acc: 0.5659 -- iter: 0224/1145
[A[ATraining Step: 44  | total loss: [1m[32m0.69305[0m[0m | time: 63.505s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5491 -- iter: 0256/1145
[A[ATraining Step: 45  | total loss: [1m[32m0.69302[0m[0m | time: 71.468s
[2K
| RMSProp | epoch: 002 | loss: 0.69302 - acc: 0.5355 -- iter: 0288/1145
[A[ATraining Step: 46  | total loss: [1m[32m0.69745[0m[0m | time: 79.610s
[2K
| RMSProp | epoch: 002 | loss: 0.69745 - acc: 0.5244 -- iter: 0320/1145
[A[ATraining Step: 47  | total loss: [1m[32m0.68890[0m[0m | time: 87.824s
[2K
| RMSProp | epoch: 002 | loss: 0.68890 - acc: 0.5562 -- iter: 0352/1145
[A[ATraining Step: 48  | total loss: [1m[32m0.70578[0m[0m | time: 96.070s
[2K
| RMSProp | epoch: 002 | loss: 0.70578 - acc: 0.5471 -- iter: 0384/1145
[A[ATraining Step: 49  | total loss: [1m[32m0.69836[0m[0m | time: 104.180s
[2K
| RMSProp | epoch: 002 | loss: 0.69836 - acc: 0.5594 -- iter: 0416/1145
[A[ATraining Step: 50  | total loss: [1m[32m0.69716[0m[0m | time: 112.263s
[2K
| RMSProp | epoch: 002 | loss: 0.69716 - acc: 0.5599 -- iter: 0448/1145
[A[ATraining Step: 51  | total loss: [1m[32m0.69645[0m[0m | time: 120.400s
[2K
| RMSProp | epoch: 002 | loss: 0.69645 - acc: 0.5603 -- iter: 0480/1145
[A[ATraining Step: 52  | total loss: [1m[32m0.68686[0m[0m | time: 128.573s
[2K
| RMSProp | epoch: 002 | loss: 0.68686 - acc: 0.5747 -- iter: 0512/1145
[A[ATraining Step: 53  | total loss: [1m[32m0.69108[0m[0m | time: 136.930s
[2K
| RMSProp | epoch: 002 | loss: 0.69108 - acc: 0.5591 -- iter: 0544/1145
[A[ATraining Step: 54  | total loss: [1m[32m0.69679[0m[0m | time: 145.087s
[2K
| RMSProp | epoch: 002 | loss: 0.69679 - acc: 0.5414 -- iter: 0576/1145
[A[ATraining Step: 55  | total loss: [1m[32m0.72292[0m[0m | time: 153.983s
[2K
| RMSProp | epoch: 002 | loss: 0.72292 - acc: 0.5087 -- iter: 0608/1145
[A[ATraining Step: 56  | total loss: [1m[32m0.73961[0m[0m | time: 162.079s
[2K
| RMSProp | epoch: 002 | loss: 0.73961 - acc: 0.4899 -- iter: 0640/1145
[A[ATraining Step: 57  | total loss: [1m[32m0.73938[0m[0m | time: 170.215s
[2K
| RMSProp | epoch: 002 | loss: 0.73938 - acc: 0.4827 -- iter: 0672/1145
[A[ATraining Step: 58  | total loss: [1m[32m0.73704[0m[0m | time: 187.852s
[2K
| RMSProp | epoch: 002 | loss: 0.73704 - acc: 0.4765 -- iter: 0704/1145
[A[ATraining Step: 59  | total loss: [1m[32m0.73273[0m[0m | time: 196.139s
[2K
| RMSProp | epoch: 002 | loss: 0.73273 - acc: 0.4671 -- iter: 0736/1145
[A[ATraining Step: 60  | total loss: [1m[32m0.72394[0m[0m | time: 204.308s
[2K
| RMSProp | epoch: 002 | loss: 0.72394 - acc: 0.4921 -- iter: 0768/1145
[A[ATraining Step: 61  | total loss: [1m[32m0.72417[0m[0m | time: 212.407s
[2K
| RMSProp | epoch: 002 | loss: 0.72417 - acc: 0.4891 -- iter: 0800/1145
[A[ATraining Step: 62  | total loss: [1m[32m0.73334[0m[0m | time: 220.515s
[2K
| RMSProp | epoch: 002 | loss: 0.73334 - acc: 0.4784 -- iter: 0832/1145
[A[ATraining Step: 63  | total loss: [1m[32m0.72804[0m[0m | time: 228.832s
[2K
| RMSProp | epoch: 002 | loss: 0.72804 - acc: 0.4970 -- iter: 0864/1145
[A[ATraining Step: 64  | total loss: [1m[32m0.72498[0m[0m | time: 236.969s
[2K
| RMSProp | epoch: 002 | loss: 0.72498 - acc: 0.5013 -- iter: 0896/1145
[A[ATraining Step: 65  | total loss: [1m[32m0.73908[0m[0m | time: 245.183s
[2K
| RMSProp | epoch: 002 | loss: 0.73908 - acc: 0.4973 -- iter: 0928/1145
[A[ATraining Step: 66  | total loss: [1m[32m0.72944[0m[0m | time: 253.511s
[2K
| RMSProp | epoch: 002 | loss: 0.72944 - acc: 0.5128 -- iter: 0960/1145
[A[ATraining Step: 67  | total loss: [1m[32m0.73970[0m[0m | time: 262.081s
[2K
| RMSProp | epoch: 002 | loss: 0.73970 - acc: 0.4963 -- iter: 0992/1145
[A[ATraining Step: 68  | total loss: [1m[32m0.72842[0m[0m | time: 273.818s
[2K
| RMSProp | epoch: 002 | loss: 0.72842 - acc: 0.5078 -- iter: 1024/1145
[A[ATraining Step: 69  | total loss: [1m[32m0.72753[0m[0m | time: 282.246s
[2K
| RMSProp | epoch: 002 | loss: 0.72753 - acc: 0.5069 -- iter: 1056/1145
[A[ATraining Step: 70  | total loss: [1m[32m0.72429[0m[0m | time: 290.380s
[2K
| RMSProp | epoch: 002 | loss: 0.72429 - acc: 0.5169 -- iter: 1088/1145
[A[ATraining Step: 71  | total loss: [1m[32m0.72519[0m[0m | time: 298.910s
[2K
| RMSProp | epoch: 002 | loss: 0.72519 - acc: 0.5079 -- iter: 1120/1145
[A[ATraining Step: 72  | total loss: [1m[32m0.72588[0m[0m | time: 323.021s
[2K
| RMSProp | epoch: 002 | loss: 0.72588 - acc: 0.5035 | val_loss: 1.28409 - val_acc: 0.4972 -- iter: 1145/1145
--
Training Step: 73  | total loss: [1m[32m0.72188[0m[0m | time: 6.624s
[2K
| RMSProp | epoch: 003 | loss: 0.72188 - acc: 0.5100 -- iter: 0032/1145
[A[ATraining Step: 74  | total loss: [1m[32m0.71224[0m[0m | time: 13.144s
[2K
| RMSProp | epoch: 003 | loss: 0.71224 - acc: 0.5287 -- iter: 0064/1145
[A[ATraining Step: 75  | total loss: [1m[32m0.69082[0m[0m | time: 21.365s
[2K
| RMSProp | epoch: 003 | loss: 0.69082 - acc: 0.5624 -- iter: 0096/1145
[A[ATraining Step: 76  | total loss: [1m[32m0.68383[0m[0m | time: 29.418s
[2K
| RMSProp | epoch: 003 | loss: 0.68383 - acc: 0.5658 -- iter: 0128/1145
[A[ATraining Step: 77  | total loss: [1m[32m0.68755[0m[0m | time: 37.414s
[2K
| RMSProp | epoch: 003 | loss: 0.68755 - acc: 0.5654 -- iter: 0160/1145
[A[ATraining Step: 78  | total loss: [1m[32m0.70746[0m[0m | time: 46.450s
[2K
| RMSProp | epoch: 003 | loss: 0.70746 - acc: 0.5553 -- iter: 0192/1145
[A[ATraining Step: 79  | total loss: [1m[32m0.70189[0m[0m | time: 54.227s
[2K
| RMSProp | epoch: 003 | loss: 0.70189 - acc: 0.5593 -- iter: 0224/1145
[A[ATraining Step: 80  | total loss: [1m[32m0.69871[0m[0m | time: 62.277s
[2K
| RMSProp | epoch: 003 | loss: 0.69871 - acc: 0.5628 -- iter: 0256/1145
[A[ATraining Step: 81  | total loss: [1m[32m0.69443[0m[0m | time: 70.378s
[2K
| RMSProp | epoch: 003 | loss: 0.69443 - acc: 0.5786 -- iter: 0288/1145
[A[ATraining Step: 82  | total loss: [1m[32m0.69503[0m[0m | time: 78.571s
[2K
| RMSProp | epoch: 003 | loss: 0.69503 - acc: 0.5645 -- iter: 0320/1145
[A[ATraining Step: 83  | total loss: [1m[32m0.69540[0m[0m | time: 86.791s
[2K
| RMSProp | epoch: 003 | loss: 0.69540 - acc: 0.5674 -- iter: 0352/1145
[A[ATraining Step: 84  | total loss: [1m[32m0.69605[0m[0m | time: 94.854s
[2K
| RMSProp | epoch: 003 | loss: 0.69605 - acc: 0.5669 -- iter: 0384/1145
[A[ATraining Step: 85  | total loss: [1m[32m0.69955[0m[0m | time: 110.959s
[2K
| RMSProp | epoch: 003 | loss: 0.69955 - acc: 0.5602 -- iter: 0416/1145
[A[ATraining Step: 86  | total loss: [1m[32m0.69779[0m[0m | time: 119.104s
[2K
| RMSProp | epoch: 003 | loss: 0.69779 - acc: 0.5667 -- iter: 0448/1145
[A[ATraining Step: 87  | total loss: [1m[32m0.70128[0m[0m | time: 127.675s
[2K
| RMSProp | epoch: 003 | loss: 0.70128 - acc: 0.5632 -- iter: 0480/1145
[A[ATraining Step: 88  | total loss: [1m[32m0.71050[0m[0m | time: 135.796s
[2K
| RMSProp | epoch: 003 | loss: 0.71050 - acc: 0.5568 -- iter: 0512/1145
[A[ATraining Step: 89  | total loss: [1m[32m0.70717[0m[0m | time: 143.818s
[2K
| RMSProp | epoch: 003 | loss: 0.70717 - acc: 0.5637 -- iter: 0544/1145
[A[ATraining Step: 90  | total loss: [1m[32m0.70187[0m[0m | time: 151.529s
[2K
| RMSProp | epoch: 003 | loss: 0.70187 - acc: 0.5729 -- iter: 0576/1145
[A[ATraining Step: 91  | total loss: [1m[32m0.70262[0m[0m | time: 159.512s
[2K
| RMSProp | epoch: 003 | loss: 0.70262 - acc: 0.5688 -- iter: 0608/1145
[A[ATraining Step: 92  | total loss: [1m[32m0.70354[0m[0m | time: 167.596s
[2K
| RMSProp | epoch: 003 | loss: 0.70354 - acc: 0.5681 -- iter: 0640/1145
[A[ATraining Step: 93  | total loss: [1m[32m0.69639[0m[0m | time: 175.608s
[2K
| RMSProp | epoch: 003 | loss: 0.69639 - acc: 0.5769 -- iter: 0672/1145
[A[ATraining Step: 94  | total loss: [1m[32m0.70622[0m[0m | time: 183.621s
[2K
| RMSProp | epoch: 003 | loss: 0.70622 - acc: 0.5567 -- iter: 0704/1145
[A[ATraining Step: 95  | total loss: [1m[32m0.74229[0m[0m | time: 192.016s
[2K
| RMSProp | epoch: 003 | loss: 0.74229 - acc: 0.5354 -- iter: 0736/1145
[A[ATraining Step: 96  | total loss: [1m[32m0.73826[0m[0m | time: 199.834s
[2K
| RMSProp | epoch: 003 | loss: 0.73826 - acc: 0.5413 -- iter: 0768/1145
[A[ATraining Step: 97  | total loss: [1m[32m0.72239[0m[0m | time: 207.943s
[2K
| RMSProp | epoch: 003 | loss: 0.72239 - acc: 0.5528 -- iter: 0800/1145
[A[ATraining Step: 98  | total loss: [1m[32m0.72408[0m[0m | time: 215.869s
[2K
| RMSProp | epoch: 003 | loss: 0.72408 - acc: 0.5537 -- iter: 0832/1145
[A[ATraining Step: 99  | total loss: [1m[32m0.73446[0m[0m | time: 224.610s
[2K
| RMSProp | epoch: 003 | loss: 0.73446 - acc: 0.5359 -- iter: 0864/1145
[A[ATraining Step: 100  | total loss: [1m[32m0.72888[0m[0m | time: 238.964s
[2K
| RMSProp | epoch: 003 | loss: 0.72888 - acc: 0.5417 -- iter: 0896/1145
[A[ATraining Step: 101  | total loss: [1m[32m0.74088[0m[0m | time: 247.027s
[2K
| RMSProp | epoch: 003 | loss: 0.74088 - acc: 0.5406 -- iter: 0928/1145
[A[ATraining Step: 102  | total loss: [1m[32m0.72953[0m[0m | time: 255.098s
[2K
| RMSProp | epoch: 003 | loss: 0.72953 - acc: 0.5522 -- iter: 0960/1145
[A[ATraining Step: 103  | total loss: [1m[32m0.76191[0m[0m | time: 267.105s
[2K
| RMSProp | epoch: 003 | loss: 0.76191 - acc: 0.5470 -- iter: 0992/1145
[A[ATraining Step: 104  | total loss: [1m[32m0.73790[0m[0m | time: 275.262s
[2K
| RMSProp | epoch: 003 | loss: 0.73790 - acc: 0.5641 -- iter: 1024/1145
[A[ATraining Step: 105  | total loss: [1m[32m0.73143[0m[0m | time: 283.425s
[2K
| RMSProp | epoch: 003 | loss: 0.73143 - acc: 0.5702 -- iter: 1056/1145
[A[ATraining Step: 106  | total loss: [1m[32m0.75370[0m[0m | time: 291.806s
[2K
| RMSProp | epoch: 003 | loss: 0.75370 - acc: 0.5663 -- iter: 1088/1145
[A[ATraining Step: 107  | total loss: [1m[32m0.79512[0m[0m | time: 299.918s
[2K
| RMSProp | epoch: 003 | loss: 0.79512 - acc: 0.5503 -- iter: 1120/1145
[A[ATraining Step: 108  | total loss: [1m[32m0.78051[0m[0m | time: 335.732s
[2K
| RMSProp | epoch: 003 | loss: 0.78051 - acc: 0.5547 | val_loss: 4.55174 - val_acc: 0.5028 -- iter: 1145/1145
--
Training Step: 109  | total loss: [1m[32m0.77066[0m[0m | time: 8.162s
[2K
| RMSProp | epoch: 004 | loss: 0.77066 - acc: 0.5554 -- iter: 0032/1145
[A[ATraining Step: 110  | total loss: [1m[32m0.79414[0m[0m | time: 14.715s
[2K
| RMSProp | epoch: 004 | loss: 0.79414 - acc: 0.5437 -- iter: 0064/1145
[A[ATraining Step: 111  | total loss: [1m[32m0.78498[0m[0m | time: 21.350s
[2K
| RMSProp | epoch: 004 | loss: 0.78498 - acc: 0.5493 -- iter: 0096/1145
[A[ATraining Step: 112  | total loss: [1m[32m0.75170[0m[0m | time: 29.516s
[2K
| RMSProp | epoch: 004 | loss: 0.75170 - acc: 0.5784 -- iter: 0128/1145
[A[ATraining Step: 113  | total loss: [1m[32m0.73818[0m[0m | time: 38.193s
[2K
| RMSProp | epoch: 004 | loss: 0.73818 - acc: 0.5861 -- iter: 0160/1145
[A[ATraining Step: 114  | total loss: [1m[32m0.73205[0m[0m | time: 46.378s
[2K
| RMSProp | epoch: 004 | loss: 0.73205 - acc: 0.5900 -- iter: 0192/1145
[A[ATraining Step: 115  | total loss: [1m[32m0.72445[0m[0m | time: 55.646s
[2K
| RMSProp | epoch: 004 | loss: 0.72445 - acc: 0.5967 -- iter: 0224/1145
[A[ATraining Step: 116  | total loss: [1m[32m0.72640[0m[0m | time: 63.757s
[2K
| RMSProp | epoch: 004 | loss: 0.72640 - acc: 0.5995 -- iter: 0256/1145
[A[ATraining Step: 117  | total loss: [1m[32m0.71877[0m[0m | time: 71.872s
[2K
| RMSProp | epoch: 004 | loss: 0.71877 - acc: 0.5958 -- iter: 0288/1145
[A[ATraining Step: 118  | total loss: [1m[32m0.71886[0m[0m | time: 80.721s
[2K
| RMSProp | epoch: 004 | loss: 0.71886 - acc: 0.5893 -- iter: 0320/1145
[A[ATraining Step: 119  | total loss: [1m[32m0.72479[0m[0m | time: 88.557s
[2K
| RMSProp | epoch: 004 | loss: 0.72479 - acc: 0.5742 -- iter: 0352/1145
[A[ATraining Step: 120  | total loss: [1m[32m0.71778[0m[0m | time: 96.535s
[2K
| RMSProp | epoch: 004 | loss: 0.71778 - acc: 0.5824 -- iter: 0384/1145
[A[ATraining Step: 121  | total loss: [1m[32m0.70929[0m[0m | time: 113.186s
[2K
| RMSProp | epoch: 004 | loss: 0.70929 - acc: 0.5898 -- iter: 0416/1145
[A[ATraining Step: 122  | total loss: [1m[32m0.72307[0m[0m | time: 127.811s
[2K
| RMSProp | epoch: 004 | loss: 0.72307 - acc: 0.5870 -- iter: 0448/1145
[A[ATraining Step: 123  | total loss: [1m[32m0.72734[0m[0m | time: 135.812s
[2K
| RMSProp | epoch: 004 | loss: 0.72734 - acc: 0.5846 -- iter: 0480/1145
[A[ATraining Step: 124  | total loss: [1m[32m0.72221[0m[0m | time: 143.851s
[2K
| RMSProp | epoch: 004 | loss: 0.72221 - acc: 0.5824 -- iter: 0512/1145
[A[ATraining Step: 125  | total loss: [1m[32m0.72254[0m[0m | time: 152.275s
[2K
| RMSProp | epoch: 004 | loss: 0.72254 - acc: 0.5773 -- iter: 0544/1145
[A[ATraining Step: 126  | total loss: [1m[32m0.72514[0m[0m | time: 160.405s
[2K
| RMSProp | epoch: 004 | loss: 0.72514 - acc: 0.5758 -- iter: 0576/1145
[A[ATraining Step: 127  | total loss: [1m[32m0.71890[0m[0m | time: 170.422s
[2K
| RMSProp | epoch: 004 | loss: 0.71890 - acc: 0.5807 -- iter: 0608/1145
[A[ATraining Step: 128  | total loss: [1m[32m0.72199[0m[0m | time: 178.565s
[2K
| RMSProp | epoch: 004 | loss: 0.72199 - acc: 0.5758 -- iter: 0640/1145
[A[ATraining Step: 129  | total loss: [1m[32m0.70938[0m[0m | time: 187.789s
[2K
| RMSProp | epoch: 004 | loss: 0.70938 - acc: 0.5838 -- iter: 0672/1145
[A[ATraining Step: 130  | total loss: [1m[32m0.71280[0m[0m | time: 200.851s
[2K
| RMSProp | epoch: 004 | loss: 0.71280 - acc: 0.5879 -- iter: 0704/1145
[A[ATraining Step: 131  | total loss: [1m[32m0.71794[0m[0m | time: 208.911s
[2K
| RMSProp | epoch: 004 | loss: 0.71794 - acc: 0.5760 -- iter: 0736/1145
[A[ATraining Step: 132  | total loss: [1m[32m0.71750[0m[0m | time: 216.993s
[2K
| RMSProp | epoch: 004 | loss: 0.71750 - acc: 0.5747 -- iter: 0768/1145
[A[ATraining Step: 133  | total loss: [1m[32m0.71705[0m[0m | time: 224.981s
[2K
| RMSProp | epoch: 004 | loss: 0.71705 - acc: 0.5703 -- iter: 0800/1145
[A[ATraining Step: 134  | total loss: [1m[32m0.71778[0m[0m | time: 233.155s
[2K
| RMSProp | epoch: 004 | loss: 0.71778 - acc: 0.5695 -- iter: 0832/1145
[A[ATraining Step: 135  | total loss: [1m[32m0.71588[0m[0m | time: 243.208s
[2K
| RMSProp | epoch: 004 | loss: 0.71588 - acc: 0.5688 -- iter: 0864/1145
[A[ATraining Step: 136  | total loss: [1m[32m0.70501[0m[0m | time: 254.306s
[2K
| RMSProp | epoch: 004 | loss: 0.70501 - acc: 0.5838 -- iter: 0896/1145
[A[ATraining Step: 137  | total loss: [1m[32m0.69052[0m[0m | time: 262.439s
[2K
| RMSProp | epoch: 004 | loss: 0.69052 - acc: 0.6004 -- iter: 0928/1145
[A[ATraining Step: 138  | total loss: [1m[32m0.67983[0m[0m | time: 295.118s
[2K
| RMSProp | epoch: 004 | loss: 0.67983 - acc: 0.6123 -- iter: 0960/1145
[A[ATraining Step: 139  | total loss: [1m[32m0.66911[0m[0m | time: 311.984s
[2K
| RMSProp | epoch: 004 | loss: 0.66911 - acc: 0.6167 -- iter: 0992/1145
[A[ATraining Step: 140  | total loss: [1m[32m0.68189[0m[0m | time: 320.240s
[2K
| RMSProp | epoch: 004 | loss: 0.68189 - acc: 0.6050 -- iter: 1024/1145
[A[ATraining Step: 141  | total loss: [1m[32m0.67648[0m[0m | time: 328.356s
[2K
| RMSProp | epoch: 004 | loss: 0.67648 - acc: 0.6039 -- iter: 1056/1145
[A[ATraining Step: 142  | total loss: [1m[32m0.69068[0m[0m | time: 336.268s
[2K
| RMSProp | epoch: 004 | loss: 0.69068 - acc: 0.5935 -- iter: 1088/1145
[A[ATraining Step: 143  | total loss: [1m[32m0.73773[0m[0m | time: 344.746s
[2K
| RMSProp | epoch: 004 | loss: 0.73773 - acc: 0.5748 -- iter: 1120/1145
[A[ATraining Step: 144  | total loss: [1m[32m0.72576[0m[0m | time: 368.871s
[2K
| RMSProp | epoch: 004 | loss: 0.72576 - acc: 0.5673 | val_loss: 7.42227 - val_acc: 0.4972 -- iter: 1145/1145
--
Training Step: 145  | total loss: [1m[32m0.70042[0m[0m | time: 8.079s
[2K
| RMSProp | epoch: 005 | loss: 0.70042 - acc: 0.5887 -- iter: 0032/1145
[A[ATraining Step: 146  | total loss: [1m[32m0.72496[0m[0m | time: 16.331s
[2K
| RMSProp | epoch: 005 | loss: 0.72496 - acc: 0.5798 -- iter: 0064/1145
[A[ATraining Step: 147  | total loss: [1m[32m0.72337[0m[0m | time: 22.706s
[2K
| RMSProp | epoch: 005 | loss: 0.72337 - acc: 0.5718 -- iter: 0096/1145
[A[ATraining Step: 148  | total loss: [1m[32m0.70581[0m[0m | time: 29.179s
[2K
| RMSProp | epoch: 005 | loss: 0.70581 - acc: 0.5827 -- iter: 0128/1145
[A[ATraining Step: 149  | total loss: [1m[32m0.67682[0m[0m | time: 37.340s
[2K
| RMSProp | epoch: 005 | loss: 0.67682 - acc: 0.6044 -- iter: 0160/1145
[A[ATraining Step: 150  | total loss: [1m[32m0.71174[0m[0m | time: 46.337s
[2K
| RMSProp | epoch: 005 | loss: 0.71174 - acc: 0.5877 -- iter: 0192/1145
[A[ATraining Step: 151  | total loss: [1m[32m0.71886[0m[0m | time: 54.769s
[2K
| RMSProp | epoch: 005 | loss: 0.71886 - acc: 0.5852 -- iter: 0224/1145
[A[ATraining Step: 152  | total loss: [1m[32m0.72002[0m[0m | time: 62.603s
[2K
| RMSProp | epoch: 005 | loss: 0.72002 - acc: 0.5767 -- iter: 0256/1145
[A[ATraining Step: 153  | total loss: [1m[32m0.71316[0m[0m | time: 70.643s
[2K
| RMSProp | epoch: 005 | loss: 0.71316 - acc: 0.5784 -- iter: 0288/1145
[A[ATraining Step: 154  | total loss: [1m[32m0.68882[0m[0m | time: 78.686s
[2K
| RMSProp | epoch: 005 | loss: 0.68882 - acc: 0.5955 -- iter: 0320/1145
[A[ATraining Step: 155  | total loss: [1m[32m0.69836[0m[0m | time: 86.896s
[2K
| RMSProp | epoch: 005 | loss: 0.69836 - acc: 0.6016 -- iter: 0352/1145
[A[ATraining Step: 156  | total loss: [1m[32m0.69873[0m[0m | time: 95.125s
[2K
| RMSProp | epoch: 005 | loss: 0.69873 - acc: 0.6008 -- iter: 0384/1145
[A[ATraining Step: 157  | total loss: [1m[32m0.70275[0m[0m | time: 103.134s
[2K
| RMSProp | epoch: 005 | loss: 0.70275 - acc: 0.6064 -- iter: 0416/1145
[A[ATraining Step: 158  | total loss: [1m[32m0.69298[0m[0m | time: 111.334s
[2K
| RMSProp | epoch: 005 | loss: 0.69298 - acc: 0.6114 -- iter: 0448/1145
[A[ATraining Step: 159  | total loss: [1m[32m0.69871[0m[0m | time: 119.720s
[2K
| RMSProp | epoch: 005 | loss: 0.69871 - acc: 0.6065 -- iter: 0480/1145
[A[ATraining Step: 160  | total loss: [1m[32m0.70514[0m[0m | time: 127.747s
[2K
| RMSProp | epoch: 005 | loss: 0.70514 - acc: 0.5833 -- iter: 0512/1145
[A[ATraining Step: 161  | total loss: [1m[32m0.71538[0m[0m | time: 135.874s
[2K
| RMSProp | epoch: 005 | loss: 0.71538 - acc: 0.5687 -- iter: 0544/1145
[A[ATraining Step: 162  | total loss: [1m[32m0.69767[0m[0m | time: 143.892s
[2K
| RMSProp | epoch: 005 | loss: 0.69767 - acc: 0.5869 -- iter: 0576/1145
[A[ATraining Step: 163  | total loss: [1m[32m0.68900[0m[0m | time: 151.843s
[2K
| RMSProp | epoch: 005 | loss: 0.68900 - acc: 0.5938 -- iter: 0608/1145
[A[ATraining Step: 164  | total loss: [1m[32m0.70267[0m[0m | time: 159.789s
[2K
| RMSProp | epoch: 005 | loss: 0.70267 - acc: 0.5938 -- iter: 0640/1145
[A[ATraining Step: 165  | total loss: [1m[32m0.69389[0m[0m | time: 168.049s
[2K
| RMSProp | epoch: 005 | loss: 0.69389 - acc: 0.6000 -- iter: 0672/1145
[A[ATraining Step: 166  | total loss: [1m[32m0.68944[0m[0m | time: 176.232s
[2K
| RMSProp | epoch: 005 | loss: 0.68944 - acc: 0.5994 -- iter: 0704/1145
[A[ATraining Step: 167  | total loss: [1m[32m0.69861[0m[0m | time: 188.093s
[2K
| RMSProp | epoch: 005 | loss: 0.69861 - acc: 0.6082 -- iter: 0736/1145
[A[ATraining Step: 168  | total loss: [1m[32m0.70268[0m[0m | time: 196.648s
[2K
| RMSProp | epoch: 005 | loss: 0.70268 - acc: 0.6036 -- iter: 0768/1145
[A[ATraining Step: 169  | total loss: [1m[32m0.70325[0m[0m | time: 204.701s
[2K
| RMSProp | epoch: 005 | loss: 0.70325 - acc: 0.5995 -- iter: 0800/1145
[A[ATraining Step: 170  | total loss: [1m[32m0.71063[0m[0m | time: 212.795s
[2K
| RMSProp | epoch: 005 | loss: 0.71063 - acc: 0.5833 -- iter: 0832/1145
[A[ATraining Step: 171  | total loss: [1m[32m0.71360[0m[0m | time: 220.899s
[2K
| RMSProp | epoch: 005 | loss: 0.71360 - acc: 0.5875 -- iter: 0864/1145
[A[ATraining Step: 172  | total loss: [1m[32m0.71523[0m[0m | time: 229.127s
[2K
| RMSProp | epoch: 005 | loss: 0.71523 - acc: 0.5881 -- iter: 0896/1145
[A[ATraining Step: 173  | total loss: [1m[32m0.71910[0m[0m | time: 237.153s
[2K
| RMSProp | epoch: 005 | loss: 0.71910 - acc: 0.5981 -- iter: 0928/1145
[A[ATraining Step: 174  | total loss: [1m[32m0.71020[0m[0m | time: 245.181s
[2K
| RMSProp | epoch: 005 | loss: 0.71020 - acc: 0.6039 -- iter: 0960/1145
[A[ATraining Step: 175  | total loss: [1m[32m0.71439[0m[0m | time: 253.497s
[2K
| RMSProp | epoch: 005 | loss: 0.71439 - acc: 0.5997 -- iter: 0992/1145
[A[ATraining Step: 176  | total loss: [1m[32m0.70092[0m[0m | time: 261.715s
[2K
| RMSProp | epoch: 005 | loss: 0.70092 - acc: 0.6054 -- iter: 1024/1145
[A[ATraining Step: 177  | total loss: [1m[32m0.67817[0m[0m | time: 269.746s
[2K
| RMSProp | epoch: 005 | loss: 0.67817 - acc: 0.6261 -- iter: 1056/1145
[A[ATraining Step: 178  | total loss: [1m[32m0.68506[0m[0m | time: 277.948s
[2K
| RMSProp | epoch: 005 | loss: 0.68506 - acc: 0.6229 -- iter: 1088/1145
[A[ATraining Step: 179  | total loss: [1m[32m0.67426[0m[0m | time: 286.150s
[2K
| RMSProp | epoch: 005 | loss: 0.67426 - acc: 0.6293 -- iter: 1120/1145
[A[ATraining Step: 180  | total loss: [1m[32m0.66063[0m[0m | time: 322.078s
[2K
| RMSProp | epoch: 005 | loss: 0.66063 - acc: 0.6508 | val_loss: 0.91196 - val_acc: 0.5223 -- iter: 1145/1145
--
Training Step: 181  | total loss: [1m[32m0.63014[0m[0m | time: 8.060s
[2K
| RMSProp | epoch: 006 | loss: 0.63014 - acc: 0.6732 -- iter: 0032/1145
[A[ATraining Step: 182  | total loss: [1m[32m0.63432[0m[0m | time: 16.167s
[2K
| RMSProp | epoch: 006 | loss: 0.63432 - acc: 0.6746 -- iter: 0064/1145
[A[ATraining Step: 183  | total loss: [1m[32m0.63087[0m[0m | time: 30.475s
[2K
| RMSProp | epoch: 006 | loss: 0.63087 - acc: 0.6759 -- iter: 0096/1145
[A[ATraining Step: 184  | total loss: [1m[32m0.62309[0m[0m | time: 37.109s
[2K
| RMSProp | epoch: 006 | loss: 0.62309 - acc: 0.6802 -- iter: 0128/1145
[A[ATraining Step: 185  | total loss: [1m[32m0.62329[0m[0m | time: 43.653s
[2K
| RMSProp | epoch: 006 | loss: 0.62329 - acc: 0.6842 -- iter: 0160/1145
[A[ATraining Step: 186  | total loss: [1m[32m0.59201[0m[0m | time: 52.945s
[2K
| RMSProp | epoch: 006 | loss: 0.59201 - acc: 0.7038 -- iter: 0192/1145
[A[ATraining Step: 187  | total loss: [1m[32m0.57604[0m[0m | time: 61.026s
[2K
| RMSProp | epoch: 006 | loss: 0.57604 - acc: 0.7146 -- iter: 0224/1145
[A[ATraining Step: 188  | total loss: [1m[32m0.58579[0m[0m | time: 69.291s
[2K
| RMSProp | epoch: 006 | loss: 0.58579 - acc: 0.7150 -- iter: 0256/1145
[A[ATraining Step: 189  | total loss: [1m[32m0.59593[0m[0m | time: 77.685s
[2K
| RMSProp | epoch: 006 | loss: 0.59593 - acc: 0.7092 -- iter: 0288/1145
[A[ATraining Step: 190  | total loss: [1m[32m0.64262[0m[0m | time: 85.786s
[2K
| RMSProp | epoch: 006 | loss: 0.64262 - acc: 0.6820 -- iter: 0320/1145
[A[ATraining Step: 191  | total loss: [1m[32m0.63267[0m[0m | time: 93.967s
[2K
| RMSProp | epoch: 006 | loss: 0.63267 - acc: 0.6919 -- iter: 0352/1145
[A[ATraining Step: 192  | total loss: [1m[32m0.63242[0m[0m | time: 108.737s
[2K
| RMSProp | epoch: 006 | loss: 0.63242 - acc: 0.7009 -- iter: 0384/1145
[A[ATraining Step: 193  | total loss: [1m[32m0.60987[0m[0m | time: 116.949s
[2K
| RMSProp | epoch: 006 | loss: 0.60987 - acc: 0.7151 -- iter: 0416/1145
[A[ATraining Step: 194  | total loss: [1m[32m0.61534[0m[0m | time: 133.911s
[2K
| RMSProp | epoch: 006 | loss: 0.61534 - acc: 0.7093 -- iter: 0448/1145
[A[ATraining Step: 195  | total loss: [1m[32m0.60755[0m[0m | time: 145.056s
[2K
| RMSProp | epoch: 006 | loss: 0.60755 - acc: 0.7071 -- iter: 0480/1145
[A[ATraining Step: 196  | total loss: [1m[32m0.60570[0m[0m | time: 153.308s
[2K
| RMSProp | epoch: 006 | loss: 0.60570 - acc: 0.7082 -- iter: 0512/1145
[A[ATraining Step: 197  | total loss: [1m[32m0.59277[0m[0m | time: 161.502s
[2K
| RMSProp | epoch: 006 | loss: 0.59277 - acc: 0.7155 -- iter: 0544/1145
[A[ATraining Step: 198  | total loss: [1m[32m0.58656[0m[0m | time: 169.662s
[2K
| RMSProp | epoch: 006 | loss: 0.58656 - acc: 0.7190 -- iter: 0576/1145
[A[ATraining Step: 199  | total loss: [1m[32m0.58646[0m[0m | time: 177.858s
[2K
| RMSProp | epoch: 006 | loss: 0.58646 - acc: 0.7127 -- iter: 0608/1145
[A[ATraining Step: 200  | total loss: [1m[32m0.58160[0m[0m | time: 205.054s
[2K
| RMSProp | epoch: 006 | loss: 0.58160 - acc: 0.7164 | val_loss: 0.64197 - val_acc: 0.6480 -- iter: 0640/1145
--
Training Step: 201  | total loss: [1m[32m0.60966[0m[0m | time: 214.303s
[2K
| RMSProp | epoch: 006 | loss: 0.60966 - acc: 0.7042 -- iter: 0672/1145
[A[ATraining Step: 202  | total loss: [1m[32m0.61915[0m[0m | time: 223.106s
[2K
| RMSProp | epoch: 006 | loss: 0.61915 - acc: 0.6900 -- iter: 0704/1145
[A[ATraining Step: 203  | total loss: [1m[32m0.64291[0m[0m | time: 231.414s
[2K
| RMSProp | epoch: 006 | loss: 0.64291 - acc: 0.6804 -- iter: 0736/1145
[A[ATraining Step: 204  | total loss: [1m[32m0.64144[0m[0m | time: 243.862s
[2K
| RMSProp | epoch: 006 | loss: 0.64144 - acc: 0.6748 -- iter: 0768/1145
[A[ATraining Step: 205  | total loss: [1m[32m0.63928[0m[0m | time: 257.015s
[2K
| RMSProp | epoch: 006 | loss: 0.63928 - acc: 0.6667 -- iter: 0800/1145
[A[ATraining Step: 206  | total loss: [1m[32m0.63863[0m[0m | time: 265.032s
[2K
| RMSProp | epoch: 006 | loss: 0.63863 - acc: 0.6688 -- iter: 0832/1145
[A[ATraining Step: 207  | total loss: [1m[32m0.62373[0m[0m | time: 276.928s
[2K
| RMSProp | epoch: 006 | loss: 0.62373 - acc: 0.6832 -- iter: 0864/1145
[A[ATraining Step: 208  | total loss: [1m[32m0.61430[0m[0m | time: 286.160s
[2K
| RMSProp | epoch: 006 | loss: 0.61430 - acc: 0.6867 -- iter: 0896/1145
[A[ATraining Step: 209  | total loss: [1m[32m0.60109[0m[0m | time: 294.296s
[2K
| RMSProp | epoch: 006 | loss: 0.60109 - acc: 0.6962 -- iter: 0928/1145
[A[ATraining Step: 210  | total loss: [1m[32m0.59562[0m[0m | time: 303.579s
[2K
| RMSProp | epoch: 006 | loss: 0.59562 - acc: 0.6953 -- iter: 0960/1145
[A[ATraining Step: 211  | total loss: [1m[32m0.59405[0m[0m | time: 312.271s
[2K
| RMSProp | epoch: 006 | loss: 0.59405 - acc: 0.7008 -- iter: 0992/1145
[A[ATraining Step: 212  | total loss: [1m[32m0.60051[0m[0m | time: 320.332s
[2K
| RMSProp | epoch: 006 | loss: 0.60051 - acc: 0.6932 -- iter: 1024/1145
[A[ATraining Step: 213  | total loss: [1m[32m0.59418[0m[0m | time: 338.992s
[2K
| RMSProp | epoch: 006 | loss: 0.59418 - acc: 0.6958 -- iter: 1056/1145
[A[ATraining Step: 214  | total loss: [1m[32m0.58630[0m[0m | time: 347.244s
[2K
| RMSProp | epoch: 006 | loss: 0.58630 - acc: 0.7012 -- iter: 1088/1145
[A[ATraining Step: 215  | total loss: [1m[32m0.60601[0m[0m | time: 355.401s
[2K
| RMSProp | epoch: 006 | loss: 0.60601 - acc: 0.6811 -- iter: 1120/1145
[A[ATraining Step: 216  | total loss: [1m[32m0.61741[0m[0m | time: 379.314s
[2K
| RMSProp | epoch: 006 | loss: 0.61741 - acc: 0.6786 | val_loss: 0.88661 - val_acc: 0.5307 -- iter: 1145/1145
--
Training Step: 217  | total loss: [1m[32m0.61960[0m[0m | time: 14.506s
[2K
| RMSProp | epoch: 007 | loss: 0.61960 - acc: 0.6764 -- iter: 0032/1145
[A[ATraining Step: 218  | total loss: [1m[32m0.61540[0m[0m | time: 23.132s
[2K
| RMSProp | epoch: 007 | loss: 0.61540 - acc: 0.6837 -- iter: 0064/1145
[A[ATraining Step: 219  | total loss: [1m[32m0.61162[0m[0m | time: 31.403s
[2K
| RMSProp | epoch: 007 | loss: 0.61162 - acc: 0.6841 -- iter: 0096/1145
[A[ATraining Step: 220  | total loss: [1m[32m0.61151[0m[0m | time: 40.625s
[2K
| RMSProp | epoch: 007 | loss: 0.61151 - acc: 0.6782 -- iter: 0128/1145
[A[ATraining Step: 221  | total loss: [1m[32m0.61724[0m[0m | time: 47.351s
[2K
| RMSProp | epoch: 007 | loss: 0.61724 - acc: 0.6854 -- iter: 0160/1145
[A[ATraining Step: 222  | total loss: [1m[32m0.60969[0m[0m | time: 53.972s
[2K
| RMSProp | epoch: 007 | loss: 0.60969 - acc: 0.6888 -- iter: 0192/1145
[A[ATraining Step: 223  | total loss: [1m[32m0.58861[0m[0m | time: 63.571s
[2K
| RMSProp | epoch: 007 | loss: 0.58861 - acc: 0.7079 -- iter: 0224/1145
[A[ATraining Step: 224  | total loss: [1m[32m0.60609[0m[0m | time: 71.839s
[2K
| RMSProp | epoch: 007 | loss: 0.60609 - acc: 0.6997 -- iter: 0256/1145
[A[ATraining Step: 225  | total loss: [1m[32m0.60608[0m[0m | time: 86.395s
[2K
| RMSProp | epoch: 007 | loss: 0.60608 - acc: 0.7016 -- iter: 0288/1145
[A[ATraining Step: 226  | total loss: [1m[32m0.59825[0m[0m | time: 94.827s
[2K
| RMSProp | epoch: 007 | loss: 0.59825 - acc: 0.7064 -- iter: 0320/1145
[A[ATraining Step: 227  | total loss: [1m[32m0.58209[0m[0m | time: 103.030s
[2K
| RMSProp | epoch: 007 | loss: 0.58209 - acc: 0.7139 -- iter: 0352/1145
[A[ATraining Step: 228  | total loss: [1m[32m0.58053[0m[0m | time: 111.223s
[2K
| RMSProp | epoch: 007 | loss: 0.58053 - acc: 0.7113 -- iter: 0384/1145
[A[ATraining Step: 229  | total loss: [1m[32m0.56621[0m[0m | time: 125.385s
[2K
| RMSProp | epoch: 007 | loss: 0.56621 - acc: 0.7151 -- iter: 0416/1145
[A[ATraining Step: 230  | total loss: [1m[32m0.55808[0m[0m | time: 147.632s
[2K
| RMSProp | epoch: 007 | loss: 0.55808 - acc: 0.7217 -- iter: 0448/1145
[A[ATraining Step: 231  | total loss: [1m[32m0.55815[0m[0m | time: 178.420s
[2K
| RMSProp | epoch: 007 | loss: 0.55815 - acc: 0.7183 -- iter: 0480/1145
[A[ATraining Step: 232  | total loss: [1m[32m0.55919[0m[0m | time: 200.202s
[2K
| RMSProp | epoch: 007 | loss: 0.55919 - acc: 0.7215 -- iter: 0512/1145
[A[ATraining Step: 233  | total loss: [1m[32m0.54230[0m[0m | time: 208.389s
[2K
| RMSProp | epoch: 007 | loss: 0.54230 - acc: 0.7306 -- iter: 0544/1145
[A[ATraining Step: 234  | total loss: [1m[32m0.54741[0m[0m | time: 216.568s
[2K
| RMSProp | epoch: 007 | loss: 0.54741 - acc: 0.7232 -- iter: 0576/1145
[A[ATraining Step: 235  | total loss: [1m[32m0.54584[0m[0m | time: 241.195s
[2K
| RMSProp | epoch: 007 | loss: 0.54584 - acc: 0.7290 -- iter: 0608/1145
[A[ATraining Step: 236  | total loss: [1m[32m0.56333[0m[0m | time: 249.293s
[2K
| RMSProp | epoch: 007 | loss: 0.56333 - acc: 0.7154 -- iter: 0640/1145
[A[ATraining Step: 237  | total loss: [1m[32m0.55701[0m[0m | time: 257.429s
[2K
| RMSProp | epoch: 007 | loss: 0.55701 - acc: 0.7189 -- iter: 0672/1145
[A[ATraining Step: 238  | total loss: [1m[32m0.55676[0m[0m | time: 265.571s
[2K
| RMSProp | epoch: 007 | loss: 0.55676 - acc: 0.7283 -- iter: 0704/1145
[A[ATraining Step: 239  | total loss: [1m[32m0.57069[0m[0m | time: 274.057s
[2K
| RMSProp | epoch: 007 | loss: 0.57069 - acc: 0.7148 -- iter: 0736/1145
[A[ATraining Step: 240  | total loss: [1m[32m0.57073[0m[0m | time: 288.829s
[2K
| RMSProp | epoch: 007 | loss: 0.57073 - acc: 0.7090 -- iter: 0768/1145
[A[ATraining Step: 241  | total loss: [1m[32m0.57122[0m[0m | time: 297.092s
[2K
| RMSProp | epoch: 007 | loss: 0.57122 - acc: 0.7162 -- iter: 0800/1145
[A[ATraining Step: 242  | total loss: [1m[32m0.57325[0m[0m | time: 320.632s
[2K
| RMSProp | epoch: 007 | loss: 0.57325 - acc: 0.7196 -- iter: 0832/1145
[A[ATraining Step: 243  | total loss: [1m[32m0.56759[0m[0m | time: 328.768s
[2K
| RMSProp | epoch: 007 | loss: 0.56759 - acc: 0.7164 -- iter: 0864/1145
[A[ATraining Step: 244  | total loss: [1m[32m0.57239[0m[0m | time: 358.061s
[2K
| RMSProp | epoch: 007 | loss: 0.57239 - acc: 0.7135 -- iter: 0896/1145
[A[ATraining Step: 245  | total loss: [1m[32m0.58851[0m[0m | time: 369.090s
[2K
| RMSProp | epoch: 007 | loss: 0.58851 - acc: 0.7109 -- iter: 0928/1145
[A[ATraining Step: 246  | total loss: [1m[32m0.58049[0m[0m | time: 377.490s
[2K
| RMSProp | epoch: 007 | loss: 0.58049 - acc: 0.7085 -- iter: 0960/1145
[A[ATraining Step: 247  | total loss: [1m[32m0.58133[0m[0m | time: 385.726s
[2K
| RMSProp | epoch: 007 | loss: 0.58133 - acc: 0.7064 -- iter: 0992/1145
[A[ATraining Step: 248  | total loss: [1m[32m0.59617[0m[0m | time: 393.852s
[2K
| RMSProp | epoch: 007 | loss: 0.59617 - acc: 0.6952 -- iter: 1024/1145
[A[ATraining Step: 249  | total loss: [1m[32m0.60514[0m[0m | time: 416.149s
[2K
| RMSProp | epoch: 007 | loss: 0.60514 - acc: 0.6913 -- iter: 1056/1145
[A[ATraining Step: 250  | total loss: [1m[32m0.60680[0m[0m | time: 424.142s
[2K
| RMSProp | epoch: 007 | loss: 0.60680 - acc: 0.6940 -- iter: 1088/1145
[A[ATraining Step: 251  | total loss: [1m[32m0.58905[0m[0m | time: 432.320s
[2K
| RMSProp | epoch: 007 | loss: 0.58905 - acc: 0.7027 -- iter: 1120/1145
[A[ATraining Step: 252  | total loss: [1m[32m0.58040[0m[0m | time: 456.312s
[2K
| RMSProp | epoch: 007 | loss: 0.58040 - acc: 0.7075 | val_loss: 0.89137 - val_acc: 0.5754 -- iter: 1145/1145
--
Training Step: 253  | total loss: [1m[32m0.56989[0m[0m | time: 8.214s
[2K
| RMSProp | epoch: 008 | loss: 0.56989 - acc: 0.7148 -- iter: 0032/1145
[A[ATraining Step: 254  | total loss: [1m[32m0.55618[0m[0m | time: 16.185s
[2K
| RMSProp | epoch: 008 | loss: 0.55618 - acc: 0.7152 -- iter: 0064/1145
[A[ATraining Step: 255  | total loss: [1m[32m0.55513[0m[0m | time: 24.280s
[2K
| RMSProp | epoch: 008 | loss: 0.55513 - acc: 0.7218 -- iter: 0096/1145
[A[ATraining Step: 256  | total loss: [1m[32m0.55558[0m[0m | time: 33.582s
[2K
| RMSProp | epoch: 008 | loss: 0.55558 - acc: 0.7215 -- iter: 0128/1145
[A[ATraining Step: 257  | total loss: [1m[32m0.54388[0m[0m | time: 41.907s
[2K
| RMSProp | epoch: 008 | loss: 0.54388 - acc: 0.7275 -- iter: 0160/1145
[A[ATraining Step: 258  | total loss: [1m[32m0.54326[0m[0m | time: 48.964s
[2K
| RMSProp | epoch: 008 | loss: 0.54326 - acc: 0.7266 -- iter: 0192/1145
[A[ATraining Step: 259  | total loss: [1m[32m0.54239[0m[0m | time: 55.599s
[2K
| RMSProp | epoch: 008 | loss: 0.54239 - acc: 0.7300 -- iter: 0224/1145
[A[ATraining Step: 260  | total loss: [1m[32m0.51472[0m[0m | time: 63.631s
[2K
| RMSProp | epoch: 008 | loss: 0.51472 - acc: 0.7530 -- iter: 0256/1145
[A[ATraining Step: 261  | total loss: [1m[32m0.51934[0m[0m | time: 74.400s
[2K
| RMSProp | epoch: 008 | loss: 0.51934 - acc: 0.7558 -- iter: 0288/1145
[A[ATraining Step: 262  | total loss: [1m[32m0.51068[0m[0m | time: 82.440s
[2K
| RMSProp | epoch: 008 | loss: 0.51068 - acc: 0.7583 -- iter: 0320/1145
[A[ATraining Step: 263  | total loss: [1m[32m0.51787[0m[0m | time: 93.079s
[2K
| RMSProp | epoch: 008 | loss: 0.51787 - acc: 0.7544 -- iter: 0352/1145
[A[ATraining Step: 264  | total loss: [1m[32m0.49820[0m[0m | time: 101.350s
[2K
| RMSProp | epoch: 008 | loss: 0.49820 - acc: 0.7664 -- iter: 0384/1145
[A[ATraining Step: 265  | total loss: [1m[32m0.54298[0m[0m | time: 110.284s
[2K
| RMSProp | epoch: 008 | loss: 0.54298 - acc: 0.7617 -- iter: 0416/1145
[A[ATraining Step: 266  | total loss: [1m[32m0.54063[0m[0m | time: 118.417s
[2K
| RMSProp | epoch: 008 | loss: 0.54063 - acc: 0.7574 -- iter: 0448/1145
[A[ATraining Step: 267  | total loss: [1m[32m0.53070[0m[0m | time: 126.565s
[2K
| RMSProp | epoch: 008 | loss: 0.53070 - acc: 0.7598 -- iter: 0480/1145
[A[ATraining Step: 268  | total loss: [1m[32m0.52520[0m[0m | time: 134.775s
[2K
| RMSProp | epoch: 008 | loss: 0.52520 - acc: 0.7619 -- iter: 0512/1145
[A[ATraining Step: 269  | total loss: [1m[32m0.53601[0m[0m | time: 147.713s
[2K
| RMSProp | epoch: 008 | loss: 0.53601 - acc: 0.7607 -- iter: 0544/1145
[A[ATraining Step: 270  | total loss: [1m[32m0.52938[0m[0m | time: 155.835s
[2K
| RMSProp | epoch: 008 | loss: 0.52938 - acc: 0.7597 -- iter: 0576/1145
[A[ATraining Step: 271  | total loss: [1m[32m0.50458[0m[0m | time: 171.933s
[2K
| RMSProp | epoch: 008 | loss: 0.50458 - acc: 0.7712 -- iter: 0608/1145
[A[ATraining Step: 272  | total loss: [1m[32m0.50145[0m[0m | time: 180.097s
[2K
| RMSProp | epoch: 008 | loss: 0.50145 - acc: 0.7784 -- iter: 0640/1145
[A[ATraining Step: 273  | total loss: [1m[32m0.51030[0m[0m | time: 188.240s
[2K
| RMSProp | epoch: 008 | loss: 0.51030 - acc: 0.7725 -- iter: 0672/1145
[A[ATraining Step: 274  | total loss: [1m[32m0.47940[0m[0m | time: 196.276s
[2K
| RMSProp | epoch: 008 | loss: 0.47940 - acc: 0.7890 -- iter: 0704/1145
[A[ATraining Step: 275  | total loss: [1m[32m0.47507[0m[0m | time: 204.485s
[2K
| RMSProp | epoch: 008 | loss: 0.47507 - acc: 0.7882 -- iter: 0736/1145
[A[ATraining Step: 276  | total loss: [1m[32m0.48807[0m[0m | time: 212.638s
[2K
| RMSProp | epoch: 008 | loss: 0.48807 - acc: 0.7938 -- iter: 0768/1145
[A[ATraining Step: 277  | total loss: [1m[32m0.50273[0m[0m | time: 220.711s
[2K
| RMSProp | epoch: 008 | loss: 0.50273 - acc: 0.7800 -- iter: 0800/1145
[A[ATraining Step: 278  | total loss: [1m[32m0.51230[0m[0m | time: 228.878s
[2K
| RMSProp | epoch: 008 | loss: 0.51230 - acc: 0.7833 -- iter: 0832/1145
[A[ATraining Step: 279  | total loss: [1m[32m0.50465[0m[0m | time: 237.094s
[2K
| RMSProp | epoch: 008 | loss: 0.50465 - acc: 0.7799 -- iter: 0864/1145
[A[ATraining Step: 280  | total loss: [1m[32m0.51642[0m[0m | time: 245.487s
[2K
| RMSProp | epoch: 008 | loss: 0.51642 - acc: 0.7769 -- iter: 0896/1145
[A[ATraining Step: 281  | total loss: [1m[32m0.50788[0m[0m | time: 256.411s
[2K
| RMSProp | epoch: 008 | loss: 0.50788 - acc: 0.7805 -- iter: 0928/1145
[A[ATraining Step: 282  | total loss: [1m[32m0.48693[0m[0m | time: 264.442s
[2K
| RMSProp | epoch: 008 | loss: 0.48693 - acc: 0.7931 -- iter: 0960/1145
[A[ATraining Step: 283  | total loss: [1m[32m0.50813[0m[0m | time: 272.641s
[2K
| RMSProp | epoch: 008 | loss: 0.50813 - acc: 0.7794 -- iter: 0992/1145
[A[ATraining Step: 284  | total loss: [1m[32m0.51637[0m[0m | time: 287.625s
[2K
| RMSProp | epoch: 008 | loss: 0.51637 - acc: 0.7827 -- iter: 1024/1145
[A[ATraining Step: 285  | total loss: [1m[32m0.52266[0m[0m | time: 295.870s
[2K
| RMSProp | epoch: 008 | loss: 0.52266 - acc: 0.7763 -- iter: 1056/1145
[A[ATraining Step: 286  | total loss: [1m[32m0.53763[0m[0m | time: 303.814s
[2K
| RMSProp | epoch: 008 | loss: 0.53763 - acc: 0.7643 -- iter: 1088/1145
[A[ATraining Step: 287  | total loss: [1m[32m0.53443[0m[0m | time: 312.122s
[2K
| RMSProp | epoch: 008 | loss: 0.53443 - acc: 0.7597 -- iter: 1120/1145
[A[ATraining Step: 288  | total loss: [1m[32m0.55822[0m[0m | time: 336.199s
[2K
| RMSProp | epoch: 008 | loss: 0.55822 - acc: 0.7338 | val_loss: 0.70104 - val_acc: 0.6564 -- iter: 1145/1145
--
Training Step: 289  | total loss: [1m[32m0.53958[0m[0m | time: 8.246s
[2K
| RMSProp | epoch: 009 | loss: 0.53958 - acc: 0.7510 -- iter: 0032/1145
[A[ATraining Step: 290  | total loss: [1m[32m0.51862[0m[0m | time: 16.331s
[2K
| RMSProp | epoch: 009 | loss: 0.51862 - acc: 0.7572 -- iter: 0064/1145
[A[ATraining Step: 291  | total loss: [1m[32m0.51443[0m[0m | time: 24.327s
[2K
| RMSProp | epoch: 009 | loss: 0.51443 - acc: 0.7502 -- iter: 0096/1145
[A[ATraining Step: 292  | total loss: [1m[32m0.50903[0m[0m | time: 32.467s
[2K
| RMSProp | epoch: 009 | loss: 0.50903 - acc: 0.7502 -- iter: 0128/1145
[A[ATraining Step: 293  | total loss: [1m[32m0.50637[0m[0m | time: 40.464s
[2K
| RMSProp | epoch: 009 | loss: 0.50637 - acc: 0.7533 -- iter: 0160/1145
[A[ATraining Step: 294  | total loss: [1m[32m0.50591[0m[0m | time: 48.310s
[2K
| RMSProp | epoch: 009 | loss: 0.50591 - acc: 0.7498 -- iter: 0192/1145
[A[ATraining Step: 295  | total loss: [1m[32m0.51225[0m[0m | time: 54.915s
[2K
| RMSProp | epoch: 009 | loss: 0.51225 - acc: 0.7436 -- iter: 0224/1145
[A[ATraining Step: 296  | total loss: [1m[32m0.52859[0m[0m | time: 61.522s
[2K
| RMSProp | epoch: 009 | loss: 0.52859 - acc: 0.7332 -- iter: 0256/1145
[A[ATraining Step: 297  | total loss: [1m[32m0.50843[0m[0m | time: 69.768s
[2K
| RMSProp | epoch: 009 | loss: 0.50843 - acc: 0.7439 -- iter: 0288/1145
[A[ATraining Step: 298  | total loss: [1m[32m0.49002[0m[0m | time: 77.882s
[2K
| RMSProp | epoch: 009 | loss: 0.49002 - acc: 0.7570 -- iter: 0320/1145
[A[ATraining Step: 299  | total loss: [1m[32m0.50084[0m[0m | time: 86.294s
[2K
| RMSProp | epoch: 009 | loss: 0.50084 - acc: 0.7532 -- iter: 0352/1145
[A[ATraining Step: 300  | total loss: [1m[32m0.51788[0m[0m | time: 94.585s
[2K
| RMSProp | epoch: 009 | loss: 0.51788 - acc: 0.7466 -- iter: 0384/1145
[A[ATraining Step: 301  | total loss: [1m[32m0.49821[0m[0m | time: 103.196s
[2K
| RMSProp | epoch: 009 | loss: 0.49821 - acc: 0.7595 -- iter: 0416/1145
[A[ATraining Step: 302  | total loss: [1m[32m0.49388[0m[0m | time: 111.392s
[2K
| RMSProp | epoch: 009 | loss: 0.49388 - acc: 0.7648 -- iter: 0448/1145
[A[ATraining Step: 303  | total loss: [1m[32m0.48250[0m[0m | time: 119.690s
[2K
| RMSProp | epoch: 009 | loss: 0.48250 - acc: 0.7758 -- iter: 0480/1145
[A[ATraining Step: 304  | total loss: [1m[32m0.46650[0m[0m | time: 128.119s
[2K
| RMSProp | epoch: 009 | loss: 0.46650 - acc: 0.7857 -- iter: 0512/1145
[A[ATraining Step: 305  | total loss: [1m[32m0.45544[0m[0m | time: 136.089s
[2K
| RMSProp | epoch: 009 | loss: 0.45544 - acc: 0.7946 -- iter: 0544/1145
[A[ATraining Step: 306  | total loss: [1m[32m0.44393[0m[0m | time: 144.064s
[2K
| RMSProp | epoch: 009 | loss: 0.44393 - acc: 0.7964 -- iter: 0576/1145
[A[ATraining Step: 307  | total loss: [1m[32m0.44036[0m[0m | time: 152.048s
[2K
| RMSProp | epoch: 009 | loss: 0.44036 - acc: 0.7980 -- iter: 0608/1145
[A[ATraining Step: 308  | total loss: [1m[32m0.43454[0m[0m | time: 160.117s
[2K
| RMSProp | epoch: 009 | loss: 0.43454 - acc: 0.7995 -- iter: 0640/1145
[A[ATraining Step: 309  | total loss: [1m[32m0.42267[0m[0m | time: 168.123s
[2K
| RMSProp | epoch: 009 | loss: 0.42267 - acc: 0.8008 -- iter: 0672/1145
[A[ATraining Step: 310  | total loss: [1m[32m0.42193[0m[0m | time: 176.207s
[2K
| RMSProp | epoch: 009 | loss: 0.42193 - acc: 0.7895 -- iter: 0704/1145
[A[ATraining Step: 311  | total loss: [1m[32m0.43612[0m[0m | time: 184.212s
[2K
| RMSProp | epoch: 009 | loss: 0.43612 - acc: 0.7918 -- iter: 0736/1145
[A[ATraining Step: 312  | total loss: [1m[32m0.44426[0m[0m | time: 192.490s
[2K
| RMSProp | epoch: 009 | loss: 0.44426 - acc: 0.7907 -- iter: 0768/1145
[A[ATraining Step: 313  | total loss: [1m[32m0.43515[0m[0m | time: 200.622s
[2K
| RMSProp | epoch: 009 | loss: 0.43515 - acc: 0.7929 -- iter: 0800/1145
[A[ATraining Step: 314  | total loss: [1m[32m0.45523[0m[0m | time: 227.861s
[2K
| RMSProp | epoch: 009 | loss: 0.45523 - acc: 0.7761 -- iter: 0832/1145
[A[ATraining Step: 315  | total loss: [1m[32m0.46255[0m[0m | time: 235.863s
[2K
| RMSProp | epoch: 009 | loss: 0.46255 - acc: 0.7829 -- iter: 0864/1145
[A[ATraining Step: 316  | total loss: [1m[32m0.45185[0m[0m | time: 243.792s
[2K
| RMSProp | epoch: 009 | loss: 0.45185 - acc: 0.7858 -- iter: 0896/1145
[A[ATraining Step: 317  | total loss: [1m[32m0.45074[0m[0m | time: 251.869s
[2K
| RMSProp | epoch: 009 | loss: 0.45074 - acc: 0.7822 -- iter: 0928/1145
[A[ATraining Step: 318  | total loss: [1m[32m0.46474[0m[0m | time: 261.693s
[2K
| RMSProp | epoch: 009 | loss: 0.46474 - acc: 0.7728 -- iter: 0960/1145
[A[ATraining Step: 319  | total loss: [1m[32m0.48541[0m[0m | time: 269.862s
[2K
| RMSProp | epoch: 009 | loss: 0.48541 - acc: 0.7736 -- iter: 0992/1145
[A[ATraining Step: 320  | total loss: [1m[32m0.46654[0m[0m | time: 277.939s
[2K
| RMSProp | epoch: 009 | loss: 0.46654 - acc: 0.7838 -- iter: 1024/1145
[A[ATraining Step: 321  | total loss: [1m[32m0.45520[0m[0m | time: 286.234s
[2K
| RMSProp | epoch: 009 | loss: 0.45520 - acc: 0.7929 -- iter: 1056/1145
[A[ATraining Step: 322  | total loss: [1m[32m0.46316[0m[0m | time: 294.062s
[2K
| RMSProp | epoch: 009 | loss: 0.46316 - acc: 0.7886 -- iter: 1088/1145
[A[ATraining Step: 323  | total loss: [1m[32m0.44531[0m[0m | time: 302.156s
[2K
| RMSProp | epoch: 009 | loss: 0.44531 - acc: 0.8004 -- iter: 1120/1145
[A[ATraining Step: 324  | total loss: [1m[32m0.44253[0m[0m | time: 326.328s
[2K
| RMSProp | epoch: 009 | loss: 0.44253 - acc: 0.8016 | val_loss: 0.73035 - val_acc: 0.6844 -- iter: 1145/1145
--
Training Step: 325  | total loss: [1m[32m0.46153[0m[0m | time: 8.167s
[2K
| RMSProp | epoch: 010 | loss: 0.46153 - acc: 0.7995 -- iter: 0032/1145
[A[ATraining Step: 326  | total loss: [1m[32m0.45353[0m[0m | time: 16.144s
[2K
| RMSProp | epoch: 010 | loss: 0.45353 - acc: 0.8008 -- iter: 0064/1145
[A[ATraining Step: 327  | total loss: [1m[32m0.45129[0m[0m | time: 24.283s
[2K
| RMSProp | epoch: 010 | loss: 0.45129 - acc: 0.7926 -- iter: 0096/1145
[A[ATraining Step: 328  | total loss: [1m[32m0.46249[0m[0m | time: 32.255s
[2K
| RMSProp | epoch: 010 | loss: 0.46249 - acc: 0.7884 -- iter: 0128/1145
[A[ATraining Step: 329  | total loss: [1m[32m0.46774[0m[0m | time: 40.323s
[2K
| RMSProp | epoch: 010 | loss: 0.46774 - acc: 0.7877 -- iter: 0160/1145
[A[ATraining Step: 330  | total loss: [1m[32m0.47683[0m[0m | time: 48.439s
[2K
| RMSProp | epoch: 010 | loss: 0.47683 - acc: 0.7808 -- iter: 0192/1145
[A[ATraining Step: 331  | total loss: [1m[32m0.47487[0m[0m | time: 60.452s
[2K
| RMSProp | epoch: 010 | loss: 0.47487 - acc: 0.7839 -- iter: 0224/1145
[A[ATraining Step: 332  | total loss: [1m[32m0.46363[0m[0m | time: 67.035s
[2K
| RMSProp | epoch: 010 | loss: 0.46363 - acc: 0.7868 -- iter: 0256/1145
[A[ATraining Step: 333  | total loss: [1m[32m0.46567[0m[0m | time: 73.709s
[2K
| RMSProp | epoch: 010 | loss: 0.46567 - acc: 0.7881 -- iter: 0288/1145
[A[ATraining Step: 334  | total loss: [1m[32m0.43822[0m[0m | time: 82.095s
[2K
| RMSProp | epoch: 010 | loss: 0.43822 - acc: 0.8053 -- iter: 0320/1145
[A[ATraining Step: 335  | total loss: [1m[32m0.42562[0m[0m | time: 90.085s
[2K
| RMSProp | epoch: 010 | loss: 0.42562 - acc: 0.8091 -- iter: 0352/1145
[A[ATraining Step: 336  | total loss: [1m[32m0.42273[0m[0m | time: 98.191s
[2K
| RMSProp | epoch: 010 | loss: 0.42273 - acc: 0.8126 -- iter: 0384/1145
[A[ATraining Step: 337  | total loss: [1m[32m0.41966[0m[0m | time: 106.507s
[2K
| RMSProp | epoch: 010 | loss: 0.41966 - acc: 0.8095 -- iter: 0416/1145
[A[ATraining Step: 338  | total loss: [1m[32m0.42393[0m[0m | time: 115.232s
[2K
| RMSProp | epoch: 010 | loss: 0.42393 - acc: 0.8129 -- iter: 0448/1145
[A[ATraining Step: 339  | total loss: [1m[32m0.42709[0m[0m | time: 123.477s
[2K
| RMSProp | epoch: 010 | loss: 0.42709 - acc: 0.8160 -- iter: 0480/1145
[A[ATraining Step: 340  | total loss: [1m[32m0.42408[0m[0m | time: 131.603s
[2K
| RMSProp | epoch: 010 | loss: 0.42408 - acc: 0.8125 -- iter: 0512/1145
[A[ATraining Step: 341  | total loss: [1m[32m0.41441[0m[0m | time: 139.694s
[2K
| RMSProp | epoch: 010 | loss: 0.41441 - acc: 0.8156 -- iter: 0544/1145
[A[ATraining Step: 342  | total loss: [1m[32m0.39469[0m[0m | time: 149.447s
[2K
| RMSProp | epoch: 010 | loss: 0.39469 - acc: 0.8278 -- iter: 0576/1145
[A[ATraining Step: 343  | total loss: [1m[32m0.40013[0m[0m | time: 180.484s
[2K
| RMSProp | epoch: 010 | loss: 0.40013 - acc: 0.8232 -- iter: 0608/1145
[A[ATraining Step: 344  | total loss: [1m[32m0.41295[0m[0m | time: 188.661s
[2K
| RMSProp | epoch: 010 | loss: 0.41295 - acc: 0.8190 -- iter: 0640/1145
[A[ATraining Step: 345  | total loss: [1m[32m0.41196[0m[0m | time: 201.098s
[2K
| RMSProp | epoch: 010 | loss: 0.41196 - acc: 0.8183 -- iter: 0672/1145
[A[ATraining Step: 346  | total loss: [1m[32m0.42665[0m[0m | time: 209.386s
[2K
| RMSProp | epoch: 010 | loss: 0.42665 - acc: 0.8115 -- iter: 0704/1145
[A[ATraining Step: 347  | total loss: [1m[32m0.42312[0m[0m | time: 217.545s
[2K
| RMSProp | epoch: 010 | loss: 0.42312 - acc: 0.8085 -- iter: 0736/1145
[A[ATraining Step: 348  | total loss: [1m[32m0.40679[0m[0m | time: 267.016s
[2K
| RMSProp | epoch: 010 | loss: 0.40679 - acc: 0.8182 -- iter: 0768/1145
[A[ATraining Step: 349  | total loss: [1m[32m0.40822[0m[0m | time: 275.072s
[2K
| RMSProp | epoch: 010 | loss: 0.40822 - acc: 0.8114 -- iter: 0800/1145
[A[ATraining Step: 350  | total loss: [1m[32m0.43392[0m[0m | time: 283.289s
[2K
| RMSProp | epoch: 010 | loss: 0.43392 - acc: 0.8053 -- iter: 0832/1145
[A[ATraining Step: 351  | total loss: [1m[32m0.42626[0m[0m | time: 291.702s
[2K
| RMSProp | epoch: 010 | loss: 0.42626 - acc: 0.8154 -- iter: 0864/1145
[A[ATraining Step: 352  | total loss: [1m[32m0.41643[0m[0m | time: 300.760s
[2K
| RMSProp | epoch: 010 | loss: 0.41643 - acc: 0.8182 -- iter: 0896/1145
[A[ATraining Step: 353  | total loss: [1m[32m0.44830[0m[0m | time: 308.832s
[2K
| RMSProp | epoch: 010 | loss: 0.44830 - acc: 0.8020 -- iter: 0928/1145
[A[ATraining Step: 354  | total loss: [1m[32m0.43839[0m[0m | time: 317.444s
[2K
| RMSProp | epoch: 010 | loss: 0.43839 - acc: 0.8093 -- iter: 0960/1145
[A[ATraining Step: 355  | total loss: [1m[32m0.41673[0m[0m | time: 350.381s
[2K
| RMSProp | epoch: 010 | loss: 0.41673 - acc: 0.8253 -- iter: 0992/1145
[A[ATraining Step: 356  | total loss: [1m[32m0.40678[0m[0m | time: 358.505s
[2K
| RMSProp | epoch: 010 | loss: 0.40678 - acc: 0.8271 -- iter: 1024/1145
[A[ATraining Step: 357  | total loss: [1m[32m0.41440[0m[0m | time: 366.567s
[2K
| RMSProp | epoch: 010 | loss: 0.41440 - acc: 0.8225 -- iter: 1056/1145
[A[ATraining Step: 358  | total loss: [1m[32m0.42156[0m[0m | time: 374.784s
[2K
| RMSProp | epoch: 010 | loss: 0.42156 - acc: 0.8121 -- iter: 1088/1145
[A[ATraining Step: 359  | total loss: [1m[32m0.43656[0m[0m | time: 386.770s
[2K
| RMSProp | epoch: 010 | loss: 0.43656 - acc: 0.7997 -- iter: 1120/1145
[A[ATraining Step: 360  | total loss: [1m[32m0.44801[0m[0m | time: 414.027s
[2K
| RMSProp | epoch: 010 | loss: 0.44801 - acc: 0.8041 | val_loss: 0.92066 - val_acc: 0.5866 -- iter: 1145/1145
--
Training Step: 361  | total loss: [1m[32m0.44185[0m[0m | time: 8.335s
[2K
| RMSProp | epoch: 011 | loss: 0.44185 - acc: 0.8081 -- iter: 0032/1145
[A[ATraining Step: 362  | total loss: [1m[32m0.42397[0m[0m | time: 25.347s
[2K
| RMSProp | epoch: 011 | loss: 0.42397 - acc: 0.8179 -- iter: 0064/1145
[A[ATraining Step: 363  | total loss: [1m[32m0.41204[0m[0m | time: 33.486s
[2K
| RMSProp | epoch: 011 | loss: 0.41204 - acc: 0.8205 -- iter: 0096/1145
[A[ATraining Step: 364  | total loss: [1m[32m0.41046[0m[0m | time: 43.168s
[2K
| RMSProp | epoch: 011 | loss: 0.41046 - acc: 0.8259 -- iter: 0128/1145
[A[ATraining Step: 365  | total loss: [1m[32m0.44626[0m[0m | time: 57.452s
[2K
| RMSProp | epoch: 011 | loss: 0.44626 - acc: 0.8152 -- iter: 0160/1145
[A[ATraining Step: 366  | total loss: [1m[32m0.44795[0m[0m | time: 69.083s
[2K
| RMSProp | epoch: 011 | loss: 0.44795 - acc: 0.8024 -- iter: 0192/1145
[A[ATraining Step: 367  | total loss: [1m[32m0.45502[0m[0m | time: 77.303s
[2K
| RMSProp | epoch: 011 | loss: 0.45502 - acc: 0.7972 -- iter: 0224/1145
[A[ATraining Step: 368  | total loss: [1m[32m0.45554[0m[0m | time: 89.044s
[2K
| RMSProp | epoch: 011 | loss: 0.45554 - acc: 0.8018 -- iter: 0256/1145
[A[ATraining Step: 369  | total loss: [1m[32m0.43414[0m[0m | time: 95.599s
[2K
| RMSProp | epoch: 011 | loss: 0.43414 - acc: 0.8123 -- iter: 0288/1145
[A[ATraining Step: 370  | total loss: [1m[32m0.42111[0m[0m | time: 102.246s
[2K
| RMSProp | epoch: 011 | loss: 0.42111 - acc: 0.8191 -- iter: 0320/1145
[A[ATraining Step: 371  | total loss: [1m[32m0.39256[0m[0m | time: 110.515s
[2K
| RMSProp | epoch: 011 | loss: 0.39256 - acc: 0.8331 -- iter: 0352/1145
[A[ATraining Step: 372  | total loss: [1m[32m0.39351[0m[0m | time: 118.924s
[2K
| RMSProp | epoch: 011 | loss: 0.39351 - acc: 0.8280 -- iter: 0384/1145
[A[ATraining Step: 373  | total loss: [1m[32m0.38672[0m[0m | time: 127.279s
[2K
| RMSProp | epoch: 011 | loss: 0.38672 - acc: 0.8295 -- iter: 0416/1145
[A[ATraining Step: 374  | total loss: [1m[32m0.36797[0m[0m | time: 135.353s
[2K
| RMSProp | epoch: 011 | loss: 0.36797 - acc: 0.8403 -- iter: 0448/1145
[A[ATraining Step: 375  | total loss: [1m[32m0.36929[0m[0m | time: 155.519s
[2K
| RMSProp | epoch: 011 | loss: 0.36929 - acc: 0.8438 -- iter: 0480/1145
[A[ATraining Step: 376  | total loss: [1m[32m0.35974[0m[0m | time: 163.485s
[2K
| RMSProp | epoch: 011 | loss: 0.35974 - acc: 0.8500 -- iter: 0512/1145
[A[ATraining Step: 377  | total loss: [1m[32m0.35085[0m[0m | time: 172.465s
[2K
| RMSProp | epoch: 011 | loss: 0.35085 - acc: 0.8494 -- iter: 0544/1145
[A[ATraining Step: 378  | total loss: [1m[32m0.34221[0m[0m | time: 180.551s
[2K
| RMSProp | epoch: 011 | loss: 0.34221 - acc: 0.8520 -- iter: 0576/1145
[A[ATraining Step: 379  | total loss: [1m[32m0.33919[0m[0m | time: 188.684s
[2K
| RMSProp | epoch: 011 | loss: 0.33919 - acc: 0.8574 -- iter: 0608/1145
[A[ATraining Step: 380  | total loss: [1m[32m0.33926[0m[0m | time: 218.750s
[2K
| RMSProp | epoch: 011 | loss: 0.33926 - acc: 0.8623 -- iter: 0640/1145
[A[ATraining Step: 381  | total loss: [1m[32m0.36457[0m[0m | time: 226.867s
[2K
| RMSProp | epoch: 011 | loss: 0.36457 - acc: 0.8479 -- iter: 0672/1145
[A[ATraining Step: 382  | total loss: [1m[32m0.37653[0m[0m | time: 234.938s
[2K
| RMSProp | epoch: 011 | loss: 0.37653 - acc: 0.8413 -- iter: 0704/1145
[A[ATraining Step: 383  | total loss: [1m[32m0.37446[0m[0m | time: 243.059s
[2K
| RMSProp | epoch: 011 | loss: 0.37446 - acc: 0.8415 -- iter: 0736/1145
[A[ATraining Step: 384  | total loss: [1m[32m0.36894[0m[0m | time: 251.487s
[2K
| RMSProp | epoch: 011 | loss: 0.36894 - acc: 0.8417 -- iter: 0768/1145
[A[ATraining Step: 385  | total loss: [1m[32m0.35193[0m[0m | time: 270.378s
[2K
| RMSProp | epoch: 011 | loss: 0.35193 - acc: 0.8513 -- iter: 0800/1145
[A[ATraining Step: 386  | total loss: [1m[32m0.36285[0m[0m | time: 278.477s
[2K
| RMSProp | epoch: 011 | loss: 0.36285 - acc: 0.8474 -- iter: 0832/1145
[A[ATraining Step: 387  | total loss: [1m[32m0.37857[0m[0m | time: 286.449s
[2K
| RMSProp | epoch: 011 | loss: 0.37857 - acc: 0.8471 -- iter: 0864/1145
[A[ATraining Step: 388  | total loss: [1m[32m0.37575[0m[0m | time: 298.384s
[2K
| RMSProp | epoch: 011 | loss: 0.37575 - acc: 0.8436 -- iter: 0896/1145
[A[ATraining Step: 389  | total loss: [1m[32m0.37348[0m[0m | time: 308.194s
[2K
| RMSProp | epoch: 011 | loss: 0.37348 - acc: 0.8405 -- iter: 0928/1145
[A[ATraining Step: 390  | total loss: [1m[32m0.39367[0m[0m | time: 316.153s
[2K
| RMSProp | epoch: 011 | loss: 0.39367 - acc: 0.8346 -- iter: 0960/1145
[A[ATraining Step: 391  | total loss: [1m[32m0.39234[0m[0m | time: 324.490s
[2K
| RMSProp | epoch: 011 | loss: 0.39234 - acc: 0.8417 -- iter: 0992/1145
[A[ATraining Step: 392  | total loss: [1m[32m0.38914[0m[0m | time: 332.836s
[2K
| RMSProp | epoch: 011 | loss: 0.38914 - acc: 0.8482 -- iter: 1024/1145
[A[ATraining Step: 393  | total loss: [1m[32m0.37302[0m[0m | time: 341.335s
[2K
| RMSProp | epoch: 011 | loss: 0.37302 - acc: 0.8509 -- iter: 1056/1145
[A[ATraining Step: 394  | total loss: [1m[32m0.36159[0m[0m | time: 349.477s
[2K
| RMSProp | epoch: 011 | loss: 0.36159 - acc: 0.8502 -- iter: 1088/1145
[A[ATraining Step: 395  | total loss: [1m[32m0.36176[0m[0m | time: 357.585s
[2K
| RMSProp | epoch: 011 | loss: 0.36176 - acc: 0.8495 -- iter: 1120/1145
[A[ATraining Step: 396  | total loss: [1m[32m0.35603[0m[0m | time: 381.620s
[2K
| RMSProp | epoch: 011 | loss: 0.35603 - acc: 0.8521 | val_loss: 0.58824 - val_acc: 0.7430 -- iter: 1145/1145
--
Training Step: 397  | total loss: [1m[32m0.39568[0m[0m | time: 8.052s
[2K
| RMSProp | epoch: 012 | loss: 0.39568 - acc: 0.8450 -- iter: 0032/1145
[A[ATraining Step: 398  | total loss: [1m[32m0.39388[0m[0m | time: 16.326s
[2K
| RMSProp | epoch: 012 | loss: 0.39388 - acc: 0.8417 -- iter: 0064/1145
[A[ATraining Step: 399  | total loss: [1m[32m0.38693[0m[0m | time: 24.382s
[2K
| RMSProp | epoch: 012 | loss: 0.38693 - acc: 0.8419 -- iter: 0096/1145
[A[ATraining Step: 400  | total loss: [1m[32m0.39301[0m[0m | time: 48.123s
[2K
| RMSProp | epoch: 012 | loss: 0.39301 - acc: 0.8327 | val_loss: 1.93772 - val_acc: 0.5056 -- iter: 0128/1145
--
Training Step: 401  | total loss: [1m[32m0.39662[0m[0m | time: 65.469s
[2K
| RMSProp | epoch: 012 | loss: 0.39662 - acc: 0.8307 -- iter: 0160/1145
[A[ATraining Step: 402  | total loss: [1m[32m0.38775[0m[0m | time: 74.563s
[2K
| RMSProp | epoch: 012 | loss: 0.38775 - acc: 0.8383 -- iter: 0192/1145
[A[ATraining Step: 403  | total loss: [1m[32m0.41021[0m[0m | time: 82.860s
[2K
| RMSProp | epoch: 012 | loss: 0.41021 - acc: 0.8326 -- iter: 0224/1145
[A[ATraining Step: 404  | total loss: [1m[32m0.41001[0m[0m | time: 90.828s
[2K
| RMSProp | epoch: 012 | loss: 0.41001 - acc: 0.8243 -- iter: 0256/1145
[A[ATraining Step: 405  | total loss: [1m[32m0.42042[0m[0m | time: 98.995s
[2K
| RMSProp | epoch: 012 | loss: 0.42042 - acc: 0.8263 -- iter: 0288/1145
[A[ATraining Step: 406  | total loss: [1m[32m0.43440[0m[0m | time: 105.824s
[2K
| RMSProp | epoch: 012 | loss: 0.43440 - acc: 0.8155 -- iter: 0320/1145
[A[ATraining Step: 407  | total loss: [1m[32m0.42453[0m[0m | time: 112.347s
[2K
| RMSProp | epoch: 012 | loss: 0.42453 - acc: 0.8180 -- iter: 0352/1145
[A[ATraining Step: 408  | total loss: [1m[32m0.39221[0m[0m | time: 121.675s
[2K
| RMSProp | epoch: 012 | loss: 0.39221 - acc: 0.8362 -- iter: 0384/1145
[A[ATraining Step: 409  | total loss: [1m[32m0.37443[0m[0m | time: 149.030s
[2K
| RMSProp | epoch: 012 | loss: 0.37443 - acc: 0.8463 -- iter: 0416/1145
[A[ATraining Step: 410  | total loss: [1m[32m0.38332[0m[0m | time: 156.991s
[2K
| RMSProp | epoch: 012 | loss: 0.38332 - acc: 0.8429 -- iter: 0448/1145
[A[ATraining Step: 411  | total loss: [1m[32m0.36550[0m[0m | time: 165.196s
[2K
| RMSProp | epoch: 012 | loss: 0.36550 - acc: 0.8492 -- iter: 0480/1145
[A[ATraining Step: 412  | total loss: [1m[32m0.36601[0m[0m | time: 173.386s
[2K
| RMSProp | epoch: 012 | loss: 0.36601 - acc: 0.8456 -- iter: 0512/1145
[A[ATraining Step: 413  | total loss: [1m[32m0.37666[0m[0m | time: 181.389s
[2K
| RMSProp | epoch: 012 | loss: 0.37666 - acc: 0.8423 -- iter: 0544/1145
[A[ATraining Step: 414  | total loss: [1m[32m0.36100[0m[0m | time: 195.243s
[2K
| RMSProp | epoch: 012 | loss: 0.36100 - acc: 0.8455 -- iter: 0576/1145
[A[ATraining Step: 415  | total loss: [1m[32m0.35808[0m[0m | time: 203.352s
[2K
| RMSProp | epoch: 012 | loss: 0.35808 - acc: 0.8516 -- iter: 0608/1145
[A[ATraining Step: 416  | total loss: [1m[32m0.34176[0m[0m | time: 211.389s
[2K
| RMSProp | epoch: 012 | loss: 0.34176 - acc: 0.8571 -- iter: 0640/1145
[A[ATraining Step: 417  | total loss: [1m[32m0.32260[0m[0m | time: 232.624s
[2K
| RMSProp | epoch: 012 | loss: 0.32260 - acc: 0.8682 -- iter: 0672/1145
[A[ATraining Step: 418  | total loss: [1m[32m0.32138[0m[0m | time: 241.745s
[2K
| RMSProp | epoch: 012 | loss: 0.32138 - acc: 0.8689 -- iter: 0704/1145
[A[ATraining Step: 419  | total loss: [1m[32m0.32168[0m[0m | time: 249.846s
[2K
| RMSProp | epoch: 012 | loss: 0.32168 - acc: 0.8664 -- iter: 0736/1145
[A[ATraining Step: 420  | total loss: [1m[32m0.31552[0m[0m | time: 258.101s
[2K
| RMSProp | epoch: 012 | loss: 0.31552 - acc: 0.8704 -- iter: 0768/1145
[A[ATraining Step: 421  | total loss: [1m[32m0.30670[0m[0m | time: 272.005s
[2K
| RMSProp | epoch: 012 | loss: 0.30670 - acc: 0.8708 -- iter: 0800/1145
[A[ATraining Step: 422  | total loss: [1m[32m0.29102[0m[0m | time: 280.015s
[2K
| RMSProp | epoch: 012 | loss: 0.29102 - acc: 0.8775 -- iter: 0832/1145
[A[ATraining Step: 423  | total loss: [1m[32m0.28590[0m[0m | time: 288.052s
[2K
| RMSProp | epoch: 012 | loss: 0.28590 - acc: 0.8835 -- iter: 0864/1145
[A[ATraining Step: 424  | total loss: [1m[32m0.29465[0m[0m | time: 296.855s
[2K
| RMSProp | epoch: 012 | loss: 0.29465 - acc: 0.8733 -- iter: 0896/1145
[A[ATraining Step: 425  | total loss: [1m[32m0.30595[0m[0m | time: 304.864s
[2K
| RMSProp | epoch: 012 | loss: 0.30595 - acc: 0.8703 -- iter: 0928/1145
[A[ATraining Step: 426  | total loss: [1m[32m0.30259[0m[0m | time: 312.714s
[2K
| RMSProp | epoch: 012 | loss: 0.30259 - acc: 0.8770 -- iter: 0960/1145
[A[ATraining Step: 427  | total loss: [1m[32m0.32481[0m[0m | time: 331.742s
[2K
| RMSProp | epoch: 012 | loss: 0.32481 - acc: 0.8706 -- iter: 0992/1145
[A[ATraining Step: 428  | total loss: [1m[32m0.32681[0m[0m | time: 339.735s
[2K
| RMSProp | epoch: 012 | loss: 0.32681 - acc: 0.8679 -- iter: 1024/1145
[A[ATraining Step: 429  | total loss: [1m[32m0.32439[0m[0m | time: 348.306s
[2K
| RMSProp | epoch: 012 | loss: 0.32439 - acc: 0.8624 -- iter: 1056/1145
[A[ATraining Step: 430  | total loss: [1m[32m0.32696[0m[0m | time: 362.107s
[2K
| RMSProp | epoch: 012 | loss: 0.32696 - acc: 0.8605 -- iter: 1088/1145
[A[ATraining Step: 431  | total loss: [1m[32m0.34169[0m[0m | time: 383.617s
[2K
| RMSProp | epoch: 012 | loss: 0.34169 - acc: 0.8588 -- iter: 1120/1145
[A[ATraining Step: 432  | total loss: [1m[32m0.32559[0m[0m | time: 407.649s
[2K
| RMSProp | epoch: 012 | loss: 0.32559 - acc: 0.8636 | val_loss: 0.90927 - val_acc: 0.6788 -- iter: 1145/1145
--
Training Step: 433  | total loss: [1m[32m0.32061[0m[0m | time: 14.322s
[2K
| RMSProp | epoch: 013 | loss: 0.32061 - acc: 0.8678 -- iter: 0032/1145
[A[ATraining Step: 434  | total loss: [1m[32m0.30932[0m[0m | time: 23.023s
[2K
| RMSProp | epoch: 013 | loss: 0.30932 - acc: 0.8748 -- iter: 0064/1145
[A[ATraining Step: 435  | total loss: [1m[32m0.31027[0m[0m | time: 54.746s
[2K
| RMSProp | epoch: 013 | loss: 0.31027 - acc: 0.8686 -- iter: 0096/1145
[A[ATraining Step: 436  | total loss: [1m[32m0.29963[0m[0m | time: 82.993s
[2K
| RMSProp | epoch: 013 | loss: 0.29963 - acc: 0.8755 -- iter: 0128/1145
[A[ATraining Step: 437  | total loss: [1m[32m0.30575[0m[0m | time: 91.162s
[2K
| RMSProp | epoch: 013 | loss: 0.30575 - acc: 0.8692 -- iter: 0160/1145
[A[ATraining Step: 438  | total loss: [1m[32m0.29342[0m[0m | time: 99.463s
[2K
| RMSProp | epoch: 013 | loss: 0.29342 - acc: 0.8791 -- iter: 0192/1145
[A[ATraining Step: 439  | total loss: [1m[32m0.28837[0m[0m | time: 110.845s
[2K
| RMSProp | epoch: 013 | loss: 0.28837 - acc: 0.8818 -- iter: 0224/1145
[A[ATraining Step: 440  | total loss: [1m[32m0.29343[0m[0m | time: 119.556s
[2K
| RMSProp | epoch: 013 | loss: 0.29343 - acc: 0.8718 -- iter: 0256/1145
[A[ATraining Step: 441  | total loss: [1m[32m0.31863[0m[0m | time: 128.614s
[2K
| RMSProp | epoch: 013 | loss: 0.31863 - acc: 0.8627 -- iter: 0288/1145
[A[ATraining Step: 442  | total loss: [1m[32m0.32104[0m[0m | time: 143.352s
[2K
| RMSProp | epoch: 013 | loss: 0.32104 - acc: 0.8546 -- iter: 0320/1145
[A[ATraining Step: 443  | total loss: [1m[32m0.31444[0m[0m | time: 150.069s
[2K
| RMSProp | epoch: 013 | loss: 0.31444 - acc: 0.8597 -- iter: 0352/1145
[A[ATraining Step: 444  | total loss: [1m[32m0.31921[0m[0m | time: 156.906s
[2K
| RMSProp | epoch: 013 | loss: 0.31921 - acc: 0.8618 -- iter: 0384/1145
[A[ATraining Step: 445  | total loss: [1m[32m0.29944[0m[0m | time: 172.341s
[2K
| RMSProp | epoch: 013 | loss: 0.29944 - acc: 0.8716 -- iter: 0416/1145
[A[ATraining Step: 446  | total loss: [1m[32m0.29960[0m[0m | time: 181.067s
[2K
| RMSProp | epoch: 013 | loss: 0.29960 - acc: 0.8782 -- iter: 0448/1145
[A[ATraining Step: 447  | total loss: [1m[32m0.29979[0m[0m | time: 189.245s
[2K
| RMSProp | epoch: 013 | loss: 0.29979 - acc: 0.8747 -- iter: 0480/1145
[A[ATraining Step: 448  | total loss: [1m[32m0.28638[0m[0m | time: 197.477s
[2K
| RMSProp | epoch: 013 | loss: 0.28638 - acc: 0.8779 -- iter: 0512/1145
[A[ATraining Step: 449  | total loss: [1m[32m0.31107[0m[0m | time: 214.739s
[2K
| RMSProp | epoch: 013 | loss: 0.31107 - acc: 0.8620 -- iter: 0544/1145
[A[ATraining Step: 450  | total loss: [1m[32m0.31893[0m[0m | time: 222.702s
[2K
| RMSProp | epoch: 013 | loss: 0.31893 - acc: 0.8602 -- iter: 0576/1145
[A[ATraining Step: 451  | total loss: [1m[32m0.31401[0m[0m | time: 230.684s
[2K
| RMSProp | epoch: 013 | loss: 0.31401 - acc: 0.8585 -- iter: 0608/1145
[A[ATraining Step: 452  | total loss: [1m[32m0.29301[0m[0m | time: 240.507s
[2K
| RMSProp | epoch: 013 | loss: 0.29301 - acc: 0.8695 -- iter: 0640/1145
[A[ATraining Step: 453  | total loss: [1m[32m0.27651[0m[0m | time: 248.763s
[2K
| RMSProp | epoch: 013 | loss: 0.27651 - acc: 0.8763 -- iter: 0672/1145
[A[ATraining Step: 454  | total loss: [1m[32m0.26453[0m[0m | time: 257.054s
[2K
| RMSProp | epoch: 013 | loss: 0.26453 - acc: 0.8856 -- iter: 0704/1145
[A[ATraining Step: 455  | total loss: [1m[32m0.24727[0m[0m | time: 269.436s
[2K
| RMSProp | epoch: 013 | loss: 0.24727 - acc: 0.8970 -- iter: 0736/1145
[A[ATraining Step: 456  | total loss: [1m[32m0.25215[0m[0m | time: 277.639s
[2K
| RMSProp | epoch: 013 | loss: 0.25215 - acc: 0.8948 -- iter: 0768/1145
[A[ATraining Step: 457  | total loss: [1m[32m0.24625[0m[0m | time: 285.738s
[2K
| RMSProp | epoch: 013 | loss: 0.24625 - acc: 0.8960 -- iter: 0800/1145
[A[ATraining Step: 458  | total loss: [1m[32m0.23884[0m[0m | time: 294.025s
[2K
| RMSProp | epoch: 013 | loss: 0.23884 - acc: 0.9032 -- iter: 0832/1145
[A[ATraining Step: 459  | total loss: [1m[32m0.25538[0m[0m | time: 302.247s
[2K
| RMSProp | epoch: 013 | loss: 0.25538 - acc: 0.9004 -- iter: 0864/1145
[A[ATraining Step: 460  | total loss: [1m[32m0.25635[0m[0m | time: 311.248s
[2K
| RMSProp | epoch: 013 | loss: 0.25635 - acc: 0.8979 -- iter: 0896/1145
[A[ATraining Step: 461  | total loss: [1m[32m0.25859[0m[0m | time: 319.381s
[2K
| RMSProp | epoch: 013 | loss: 0.25859 - acc: 0.8987 -- iter: 0928/1145
[A[ATraining Step: 462  | total loss: [1m[32m0.25861[0m[0m | time: 327.484s
[2K
| RMSProp | epoch: 013 | loss: 0.25861 - acc: 0.8963 -- iter: 0960/1145
[A[ATraining Step: 463  | total loss: [1m[32m0.28121[0m[0m | time: 335.424s
[2K
| RMSProp | epoch: 013 | loss: 0.28121 - acc: 0.8848 -- iter: 0992/1145
[A[ATraining Step: 464  | total loss: [1m[32m0.32494[0m[0m | time: 343.606s
[2K
| RMSProp | epoch: 013 | loss: 0.32494 - acc: 0.8651 -- iter: 1024/1145
[A[ATraining Step: 465  | total loss: [1m[32m0.31836[0m[0m | time: 351.703s
[2K
| RMSProp | epoch: 013 | loss: 0.31836 - acc: 0.8598 -- iter: 1056/1145
[A[ATraining Step: 466  | total loss: [1m[32m0.33961[0m[0m | time: 359.696s
[2K
| RMSProp | epoch: 013 | loss: 0.33961 - acc: 0.8582 -- iter: 1088/1145
[A[ATraining Step: 467  | total loss: [1m[32m0.32264[0m[0m | time: 367.819s
[2K
| RMSProp | epoch: 013 | loss: 0.32264 - acc: 0.8662 -- iter: 1120/1145
[A[ATraining Step: 468  | total loss: [1m[32m0.30779[0m[0m | time: 391.763s
[2K
| RMSProp | epoch: 013 | loss: 0.30779 - acc: 0.8733 | val_loss: 2.91734 - val_acc: 0.5028 -- iter: 1145/1145
--
Training Step: 469  | total loss: [1m[32m0.29800[0m[0m | time: 9.339s
[2K
| RMSProp | epoch: 014 | loss: 0.29800 - acc: 0.8735 -- iter: 0032/1145
[A[ATraining Step: 470  | total loss: [1m[32m0.28670[0m[0m | time: 17.476s
[2K
| RMSProp | epoch: 014 | loss: 0.28670 - acc: 0.8767 -- iter: 0064/1145
[A[ATraining Step: 471  | total loss: [1m[32m0.27436[0m[0m | time: 25.451s
[2K
| RMSProp | epoch: 014 | loss: 0.27436 - acc: 0.8797 -- iter: 0096/1145
[A[ATraining Step: 472  | total loss: [1m[32m0.26871[0m[0m | time: 60.997s
[2K
| RMSProp | epoch: 014 | loss: 0.26871 - acc: 0.8792 -- iter: 0128/1145
[A[ATraining Step: 473  | total loss: [1m[32m0.25181[0m[0m | time: 69.310s
[2K
| RMSProp | epoch: 014 | loss: 0.25181 - acc: 0.8882 -- iter: 0160/1145
[A[ATraining Step: 474  | total loss: [1m[32m0.28228[0m[0m | time: 77.558s
[2K
| RMSProp | epoch: 014 | loss: 0.28228 - acc: 0.8744 -- iter: 0192/1145
[A[ATraining Step: 475  | total loss: [1m[32m0.26852[0m[0m | time: 85.487s
[2K
| RMSProp | epoch: 014 | loss: 0.26852 - acc: 0.8838 -- iter: 0224/1145
[A[ATraining Step: 476  | total loss: [1m[32m0.27040[0m[0m | time: 93.473s
[2K
| RMSProp | epoch: 014 | loss: 0.27040 - acc: 0.8892 -- iter: 0256/1145
[A[ATraining Step: 477  | total loss: [1m[32m0.27462[0m[0m | time: 101.497s
[2K
| RMSProp | epoch: 014 | loss: 0.27462 - acc: 0.8846 -- iter: 0288/1145
[A[ATraining Step: 478  | total loss: [1m[32m0.28173[0m[0m | time: 109.422s
[2K
| RMSProp | epoch: 014 | loss: 0.28173 - acc: 0.8868 -- iter: 0320/1145
[A[ATraining Step: 479  | total loss: [1m[32m0.27153[0m[0m | time: 117.513s
[2K
| RMSProp | epoch: 014 | loss: 0.27153 - acc: 0.8887 -- iter: 0352/1145
[A[ATraining Step: 480  | total loss: [1m[32m0.26561[0m[0m | time: 124.230s
[2K
| RMSProp | epoch: 014 | loss: 0.26561 - acc: 0.8905 -- iter: 0384/1145
[A[ATraining Step: 481  | total loss: [1m[32m0.30600[0m[0m | time: 131.061s
[2K
| RMSProp | epoch: 014 | loss: 0.30600 - acc: 0.8814 -- iter: 0416/1145
[A[ATraining Step: 482  | total loss: [1m[32m0.28494[0m[0m | time: 139.089s
[2K
| RMSProp | epoch: 014 | loss: 0.28494 - acc: 0.8893 -- iter: 0448/1145
[A[ATraining Step: 483  | total loss: [1m[32m0.26866[0m[0m | time: 148.623s
[2K
| RMSProp | epoch: 014 | loss: 0.26866 - acc: 0.8941 -- iter: 0480/1145
[A[ATraining Step: 484  | total loss: [1m[32m0.25740[0m[0m | time: 165.073s
[2K
| RMSProp | epoch: 014 | loss: 0.25740 - acc: 0.8985 -- iter: 0512/1145
[A[ATraining Step: 485  | total loss: [1m[32m0.29129[0m[0m | time: 173.290s
[2K
| RMSProp | epoch: 014 | loss: 0.29129 - acc: 0.8867 -- iter: 0544/1145
[A[ATraining Step: 486  | total loss: [1m[32m0.29156[0m[0m | time: 181.390s
[2K
| RMSProp | epoch: 014 | loss: 0.29156 - acc: 0.8856 -- iter: 0576/1145
[A[ATraining Step: 487  | total loss: [1m[32m0.27298[0m[0m | time: 190.104s
[2K
| RMSProp | epoch: 014 | loss: 0.27298 - acc: 0.8970 -- iter: 0608/1145
[A[ATraining Step: 488  | total loss: [1m[32m0.27799[0m[0m | time: 198.267s
[2K
| RMSProp | epoch: 014 | loss: 0.27799 - acc: 0.9011 -- iter: 0640/1145
[A[ATraining Step: 489  | total loss: [1m[32m0.27784[0m[0m | time: 206.092s
[2K
| RMSProp | epoch: 014 | loss: 0.27784 - acc: 0.9016 -- iter: 0672/1145
[A[ATraining Step: 490  | total loss: [1m[32m0.26432[0m[0m | time: 214.234s
[2K
| RMSProp | epoch: 014 | loss: 0.26432 - acc: 0.9052 -- iter: 0704/1145
[A[ATraining Step: 491  | total loss: [1m[32m0.27493[0m[0m | time: 222.237s
[2K
| RMSProp | epoch: 014 | loss: 0.27493 - acc: 0.8990 -- iter: 0736/1145
[A[ATraining Step: 492  | total loss: [1m[32m0.27889[0m[0m | time: 230.298s
[2K
| RMSProp | epoch: 014 | loss: 0.27889 - acc: 0.8997 -- iter: 0768/1145
[A[ATraining Step: 493  | total loss: [1m[32m0.26017[0m[0m | time: 238.427s
[2K
| RMSProp | epoch: 014 | loss: 0.26017 - acc: 0.9066 -- iter: 0800/1145
[A[ATraining Step: 494  | total loss: [1m[32m0.26204[0m[0m | time: 246.757s
[2K
| RMSProp | epoch: 014 | loss: 0.26204 - acc: 0.9066 -- iter: 0832/1145
[A[ATraining Step: 495  | total loss: [1m[32m0.25200[0m[0m | time: 254.892s
[2K
| RMSProp | epoch: 014 | loss: 0.25200 - acc: 0.9128 -- iter: 0864/1145
[A[ATraining Step: 496  | total loss: [1m[32m0.24331[0m[0m | time: 263.046s
[2K
| RMSProp | epoch: 014 | loss: 0.24331 - acc: 0.9122 -- iter: 0896/1145
[A[ATraining Step: 497  | total loss: [1m[32m0.22859[0m[0m | time: 271.101s
[2K
| RMSProp | epoch: 014 | loss: 0.22859 - acc: 0.9178 -- iter: 0928/1145
[A[ATraining Step: 498  | total loss: [1m[32m0.22531[0m[0m | time: 279.269s
[2K
| RMSProp | epoch: 014 | loss: 0.22531 - acc: 0.9198 -- iter: 0960/1145
[A[ATraining Step: 499  | total loss: [1m[32m0.21661[0m[0m | time: 293.401s
[2K
| RMSProp | epoch: 014 | loss: 0.21661 - acc: 0.9216 -- iter: 0992/1145
[A[ATraining Step: 500  | total loss: [1m[32m0.22417[0m[0m | time: 301.741s
[2K
| RMSProp | epoch: 014 | loss: 0.22417 - acc: 0.9169 -- iter: 1024/1145
[A[ATraining Step: 501  | total loss: [1m[32m0.22907[0m[0m | time: 309.526s
[2K
| RMSProp | epoch: 014 | loss: 0.22907 - acc: 0.9190 -- iter: 1056/1145
[A[ATraining Step: 502  | total loss: [1m[32m0.22442[0m[0m | time: 328.941s
[2K
| RMSProp | epoch: 014 | loss: 0.22442 - acc: 0.9239 -- iter: 1088/1145
[A[ATraining Step: 503  | total loss: [1m[32m0.21852[0m[0m | time: 336.759s
[2K
| RMSProp | epoch: 014 | loss: 0.21852 - acc: 0.9253 -- iter: 1120/1145
[A[ATraining Step: 504  | total loss: [1m[32m0.20964[0m[0m | time: 360.760s
[2K
| RMSProp | epoch: 014 | loss: 0.20964 - acc: 0.9296 | val_loss: 0.83284 - val_acc: 0.7291 -- iter: 1145/1145
--
Training Step: 505  | total loss: [1m[32m0.19664[0m[0m | time: 8.022s
[2K
| RMSProp | epoch: 015 | loss: 0.19664 - acc: 0.9367 -- iter: 0032/1145
[A[ATraining Step: 506  | total loss: [1m[32m0.18952[0m[0m | time: 16.140s
[2K
| RMSProp | epoch: 015 | loss: 0.18952 - acc: 0.9368 -- iter: 0064/1145
[A[ATraining Step: 507  | total loss: [1m[32m0.20609[0m[0m | time: 24.165s
[2K
| RMSProp | epoch: 015 | loss: 0.20609 - acc: 0.9306 -- iter: 0096/1145
[A[ATraining Step: 508  | total loss: [1m[32m0.22877[0m[0m | time: 32.305s
[2K
| RMSProp | epoch: 015 | loss: 0.22877 - acc: 0.9250 -- iter: 0128/1145
[A[ATraining Step: 509  | total loss: [1m[32m0.22713[0m[0m | time: 40.415s
[2K
| RMSProp | epoch: 015 | loss: 0.22713 - acc: 0.9200 -- iter: 0160/1145
[A[ATraining Step: 510  | total loss: [1m[32m0.25892[0m[0m | time: 48.462s
[2K
| RMSProp | epoch: 015 | loss: 0.25892 - acc: 0.9155 -- iter: 0192/1145
[A[ATraining Step: 511  | total loss: [1m[32m0.26079[0m[0m | time: 56.665s
[2K
| RMSProp | epoch: 015 | loss: 0.26079 - acc: 0.9177 -- iter: 0224/1145
[A[ATraining Step: 512  | total loss: [1m[32m0.25399[0m[0m | time: 66.534s
[2K
| RMSProp | epoch: 015 | loss: 0.25399 - acc: 0.9197 -- iter: 0256/1145
[A[ATraining Step: 513  | total loss: [1m[32m0.26510[0m[0m | time: 76.779s
[2K
| RMSProp | epoch: 015 | loss: 0.26510 - acc: 0.9090 -- iter: 0288/1145
[A[ATraining Step: 514  | total loss: [1m[32m0.30473[0m[0m | time: 85.009s
[2K
| RMSProp | epoch: 015 | loss: 0.30473 - acc: 0.8993 -- iter: 0320/1145
[A[ATraining Step: 515  | total loss: [1m[32m0.30515[0m[0m | time: 93.066s
[2K
| RMSProp | epoch: 015 | loss: 0.30515 - acc: 0.8938 -- iter: 0352/1145
[A[ATraining Step: 516  | total loss: [1m[32m0.29065[0m[0m | time: 101.106s
[2K
| RMSProp | epoch: 015 | loss: 0.29065 - acc: 0.8950 -- iter: 0384/1145
[A[ATraining Step: 517  | total loss: [1m[32m0.29474[0m[0m | time: 108.002s
[2K
| RMSProp | epoch: 015 | loss: 0.29474 - acc: 0.8930 -- iter: 0416/1145
[A[ATraining Step: 518  | total loss: [1m[32m0.29115[0m[0m | time: 114.709s
[2K
| RMSProp | epoch: 015 | loss: 0.29115 - acc: 0.8877 -- iter: 0448/1145
[A[ATraining Step: 519  | total loss: [1m[32m0.26563[0m[0m | time: 122.868s
[2K
| RMSProp | epoch: 015 | loss: 0.26563 - acc: 0.8989 -- iter: 0480/1145
[A[ATraining Step: 520  | total loss: [1m[32m0.25360[0m[0m | time: 131.121s
[2K
| RMSProp | epoch: 015 | loss: 0.25360 - acc: 0.8997 -- iter: 0512/1145
[A[ATraining Step: 521  | total loss: [1m[32m0.26043[0m[0m | time: 139.120s
[2K
| RMSProp | epoch: 015 | loss: 0.26043 - acc: 0.8972 -- iter: 0544/1145
[A[ATraining Step: 522  | total loss: [1m[32m0.25811[0m[0m | time: 155.502s
[2K
| RMSProp | epoch: 015 | loss: 0.25811 - acc: 0.8919 -- iter: 0576/1145
[A[ATraining Step: 523  | total loss: [1m[32m0.25874[0m[0m | time: 163.709s
[2K
| RMSProp | epoch: 015 | loss: 0.25874 - acc: 0.8964 -- iter: 0608/1145
[A[ATraining Step: 524  | total loss: [1m[32m0.24958[0m[0m | time: 172.004s
[2K
| RMSProp | epoch: 015 | loss: 0.24958 - acc: 0.8974 -- iter: 0640/1145
[A[ATraining Step: 525  | total loss: [1m[32m0.23993[0m[0m | time: 185.796s
[2K
| RMSProp | epoch: 015 | loss: 0.23993 - acc: 0.9014 -- iter: 0672/1145
[A[ATraining Step: 526  | total loss: [1m[32m0.22875[0m[0m | time: 193.902s
[2K
| RMSProp | epoch: 015 | loss: 0.22875 - acc: 0.9050 -- iter: 0704/1145
[A[ATraining Step: 527  | total loss: [1m[32m0.21399[0m[0m | time: 203.426s
[2K
| RMSProp | epoch: 015 | loss: 0.21399 - acc: 0.9145 -- iter: 0736/1145
[A[ATraining Step: 528  | total loss: [1m[32m0.19871[0m[0m | time: 211.880s
[2K
| RMSProp | epoch: 015 | loss: 0.19871 - acc: 0.9231 -- iter: 0768/1145
[A[ATraining Step: 529  | total loss: [1m[32m0.18916[0m[0m | time: 220.107s
[2K
| RMSProp | epoch: 015 | loss: 0.18916 - acc: 0.9276 -- iter: 0800/1145
[A[ATraining Step: 530  | total loss: [1m[32m0.18289[0m[0m | time: 228.179s
[2K
| RMSProp | epoch: 015 | loss: 0.18289 - acc: 0.9286 -- iter: 0832/1145
[A[ATraining Step: 531  | total loss: [1m[32m0.17602[0m[0m | time: 236.405s
[2K
| RMSProp | epoch: 015 | loss: 0.17602 - acc: 0.9295 -- iter: 0864/1145
[A[ATraining Step: 532  | total loss: [1m[32m0.17188[0m[0m | time: 244.381s
[2K
| RMSProp | epoch: 015 | loss: 0.17188 - acc: 0.9272 -- iter: 0896/1145
[A[ATraining Step: 533  | total loss: [1m[32m0.18639[0m[0m | time: 252.806s
[2K
| RMSProp | epoch: 015 | loss: 0.18639 - acc: 0.9220 -- iter: 0928/1145
[A[ATraining Step: 534  | total loss: [1m[32m0.17846[0m[0m | time: 261.106s
[2K
| RMSProp | epoch: 015 | loss: 0.17846 - acc: 0.9235 -- iter: 0960/1145
[A[ATraining Step: 535  | total loss: [1m[32m0.17277[0m[0m | time: 269.086s
[2K
| RMSProp | epoch: 015 | loss: 0.17277 - acc: 0.9249 -- iter: 0992/1145
[A[ATraining Step: 536  | total loss: [1m[32m0.16781[0m[0m | time: 277.344s
[2K
| RMSProp | epoch: 015 | loss: 0.16781 - acc: 0.9262 -- iter: 1024/1145
[A[ATraining Step: 537  | total loss: [1m[32m0.17013[0m[0m | time: 285.461s
[2K
| RMSProp | epoch: 015 | loss: 0.17013 - acc: 0.9273 -- iter: 1056/1145
[A[ATraining Step: 538  | total loss: [1m[32m0.16193[0m[0m | time: 293.658s
[2K
| RMSProp | epoch: 015 | loss: 0.16193 - acc: 0.9283 -- iter: 1088/1145
[A[ATraining Step: 539  | total loss: [1m[32m0.19643[0m[0m | time: 301.730s
[2K
| RMSProp | epoch: 015 | loss: 0.19643 - acc: 0.9199 -- iter: 1120/1145
[A[ATraining Step: 540  | total loss: [1m[32m0.18170[0m[0m | time: 325.740s
[2K
| RMSProp | epoch: 015 | loss: 0.18170 - acc: 0.9279 | val_loss: 1.51807 - val_acc: 0.6369 -- iter: 1145/1145
--
Validation AUC:0.7833645443196006
Validation AUPRC:0.7836773061091614
Test AUC:0.821519975031211
Test AUPRC:0.8087934876739795
BestTestF1Score	0.74	0.46	0.73	0.72	0.76	135	53	127	43	0.97
BestTestMCCScore	0.77	0.58	0.79	0.84	0.71	126	24	156	52	1.0
BestTestAccuracyScore	0.77	0.58	0.79	0.84	0.71	126	24	156	52	1.0
BestValidationF1Score	0.73	0.46	0.73	0.73	0.72	129	48	132	49	0.97
BestValidationMCC	0.72	0.5	0.75	0.8	0.65	116	29	151	62	1.0
BestValidationAccuracy	0.72	0.5	0.75	0.8	0.65	116	29	151	62	1.0
TestPredictions (Threshold:1.0)
CHEMBL1240760,TP,ACT,1.0	CHEMBL1401485,TN,INACT,0.9900000095367432	CHEMBL2029902,TP,ACT,1.0	CHEMBL99687,TN,INACT,0.5299999713897705	CHEMBL1910602,TN,INACT,0.6499999761581421	CHEMBL497866,TN,INACT,0.019999999552965164	CHEMBL1922205,TN,INACT,0.2800000011920929	CHEMBL194721,TP,ACT,1.0	CHEMBL1093745,TN,INACT,0.029999999329447746	CHEMBL1241661,TP,ACT,1.0	CHEMBL1933802,TN,INACT,0.029999999329447746	CHEMBL2403084,TP,ACT,1.0	CHEMBL1242367,TN,INACT,0.9800000190734863	CHEMBL411425,TP,ACT,1.0	CHEMBL300389,TP,ACT,1.0	CHEMBL2163623,TN,INACT,0.9800000190734863	CHEMBL1091083,TN,INACT,0.6100000143051147	CHEMBL332765,TP,ACT,1.0	CHEMBL2112682,TP,ACT,1.0	CHEMBL520104,TN,INACT,0.7599999904632568	CHEMBL404939,TN,INACT,0.019999999552965164	CHEMBL525530,TN,INACT,0.009999999776482582	CHEMBL1092754,TP,ACT,1.0	CHEMBL458076,TN,INACT,0.3499999940395355	CHEMBL133498,FN,ACT,0.12999999523162842	CHEMBL1241849,TP,ACT,1.0	CHEMBL3798762,TP,ACT,1.0	CHEMBL233152,FN,ACT,0.8999999761581421	CHEMBL456797,TN,INACT,0.009999999776482582	CHEMBL453130,TP,ACT,1.0	CHEMBL512649,TN,INACT,0.9300000071525574	CHEMBL1325688,TN,INACT,0.9900000095367432	CHEMBL3086109,TN,INACT,0.20000000298023224	CHEMBL2391127,TN,INACT,0.9900000095367432	CHEMBL256558,TP,ACT,1.0	CHEMBL122245,TP,ACT,1.0	CHEMBL271952,TP,ACT,1.0	CHEMBL408244,TN,INACT,0.25999999046325684	CHEMBL2062563,TN,INACT,0.9900000095367432	CHEMBL194032,FN,ACT,0.46000000834465027	CHEMBL3648096,TP,ACT,1.0	CHEMBL456964,TN,INACT,0.9200000166893005	CHEMBL130280,TP,ACT,1.0	CHEMBL254979,FN,ACT,0.9900000095367432	CHEMBL2087024,FP,INACT,1.0	CHEMBL249094,TP,ACT,1.0	CHEMBL3648105,TP,ACT,1.0	CHEMBL468125,TN,INACT,0.9800000190734863	CHEMBL272668,TP,ACT,1.0	CHEMBL2042136,FP,INACT,1.0	CHEMBL1957101,TN,INACT,0.03999999910593033	CHEMBL336351,TP,ACT,1.0	CHEMBL194540,TP,ACT,1.0	CHEMBL249095,FN,ACT,0.9399999976158142	CHEMBL457177,TP,ACT,1.0	CHEMBL1922121,TN,INACT,0.14000000059604645	CHEMBL522891,TP,ACT,1.0	CHEMBL1242973,FN,ACT,0.8899999856948853	CHEMBL2402948,FN,ACT,0.9800000190734863	CHEMBL271843,TP,ACT,1.0	CHEMBL1561032,TN,INACT,0.029999999329447746	CHEMBL51709,FN,ACT,0.03999999910593033	CHEMBL403233,FP,INACT,1.0	CHEMBL190805,TP,ACT,1.0	CHEMBL2207939,TN,INACT,0.1599999964237213	CHEMBL405042,TP,ACT,1.0	CHEMBL1801612,TN,INACT,0.9200000166893005	CHEMBL2426383,TP,ACT,1.0	CHEMBL2403098,TP,ACT,1.0	CHEMBL210765,FN,ACT,0.9599999785423279	CHEMBL2435287,TN,INACT,0.550000011920929	CHEMBL233205,FN,ACT,0.10999999940395355	CHEMBL174773,TP,ACT,1.0	CHEMBL177138,TP,ACT,1.0	CHEMBL1234085,TP,ACT,1.0	CHEMBL271953,FN,ACT,0.8899999856948853	CHEMBL1310505,TN,INACT,0.12999999523162842	CHEMBL1288069,TN,INACT,0.5699999928474426	CHEMBL1439904,TN,INACT,0.7900000214576721	CHEMBL220169,TN,INACT,0.6399999856948853	CHEMBL1496523,TN,INACT,0.03999999910593033	CHEMBL552339,TP,ACT,1.0	CHEMBL1087421,TN,INACT,0.09000000357627869	CHEMBL234699,FN,ACT,0.6000000238418579	CHEMBL214329,FN,ACT,0.27000001072883606	CHEMBL1377449,TN,INACT,0.9900000095367432	CHEMBL1213923,TN,INACT,0.9800000190734863	CHEMBL3691684,TP,ACT,1.0	CHEMBL3797574,FN,ACT,0.05000000074505806	CHEMBL504547,TN,INACT,0.6100000143051147	CHEMBL2391119,TN,INACT,0.7300000190734863	CHEMBL3314286,TN,INACT,0.019999999552965164	CHEMBL1423507,TN,INACT,0.9800000190734863	CHEMBL233349,TN,INACT,0.9300000071525574	CHEMBL382607,TP,ACT,1.0	CHEMBL1480110,TN,INACT,0.949999988079071	CHEMBL1454594,TN,INACT,0.9900000095367432	CHEMBL3216893,FN,ACT,0.9800000190734863	CHEMBL23317,TP,ACT,1.0	CHEMBL107530,FN,ACT,0.949999988079071	CHEMBL3648109,TP,ACT,1.0	CHEMBL2403085,TP,ACT,1.0	CHEMBL522563,FN,ACT,0.949999988079071	CHEMBL126077,TP,ACT,1.0	CHEMBL1379970,TN,INACT,0.9800000190734863	CHEMBL1288214,FP,INACT,1.0	CHEMBL490240,FN,ACT,0.09000000357627869	CHEMBL392776,TP,ACT,1.0	CHEMBL1800452,TP,ACT,1.0	CHEMBL3216659,TP,ACT,1.0	CHEMBL3648121,TP,ACT,1.0	CHEMBL409690,TP,ACT,1.0	CHEMBL517154,TN,INACT,0.029999999329447746	CHEMBL486302,TN,INACT,0.9100000262260437	CHEMBL133214,TN,INACT,0.9900000095367432	CHEMBL2029903,TP,ACT,1.0	CHEMBL3199093,TN,INACT,0.4000000059604645	CHEMBL1800458,TP,ACT,1.0	CHEMBL120941,FP,INACT,1.0	CHEMBL86795,TN,INACT,0.07000000029802322	CHEMBL1643142,TN,INACT,0.9900000095367432	CHEMBL328623,TN,INACT,0.1599999964237213	CHEMBL1452914,TN,INACT,0.03999999910593033	CHEMBL1800447,TP,ACT,1.0	CHEMBL560393,TN,INACT,0.0	CHEMBL1213922,TN,INACT,0.9900000095367432	CHEMBL1432163,TN,INACT,0.019999999552965164	CHEMBL195423,TP,ACT,1.0	CHEMBL1505364,TN,INACT,0.9900000095367432	CHEMBL3648083,TP,ACT,1.0	CHEMBL273060,TP,ACT,1.0	CHEMBL3648093,TP,ACT,1.0	CHEMBL119982,FN,ACT,0.8299999833106995	CHEMBL1275916,TN,INACT,0.7400000095367432	CHEMBL1570276,TN,INACT,0.05000000074505806	CHEMBL1288895,TN,INACT,0.9599999785423279	CHEMBL3658034,FN,ACT,0.8700000047683716	CHEMBL363590,TP,ACT,1.0	CHEMBL202684,TN,INACT,0.8199999928474426	CHEMBL2338334,TN,INACT,0.20999999344348907	CHEMBL561136,TN,INACT,0.009999999776482582	CHEMBL1922213,TN,INACT,0.05999999865889549	CHEMBL1094167,TN,INACT,0.9900000095367432	CHEMBL1784660,TN,INACT,0.0	CHEMBL335069,TP,ACT,1.0	CHEMBL602472,TN,INACT,0.2800000011920929	CHEMBL3109939,TN,INACT,0.949999988079071	CHEMBL1767275,TN,INACT,0.009999999776482582	CHEMBL314397,TP,ACT,1.0	CHEMBL3628247,TN,INACT,0.25999999046325684	CHEMBL171975,TP,ACT,1.0	CHEMBL372464,TP,ACT,1.0	CHEMBL150261,TP,ACT,1.0	CHEMBL391437,FN,ACT,0.5899999737739563	CHEMBL435330,TP,ACT,1.0	CHEMBL190201,TN,INACT,0.09000000357627869	CHEMBL1349172,TN,INACT,0.8500000238418579	CHEMBL2158845,FN,ACT,0.8999999761581421	CHEMBL23525,TP,ACT,1.0	CHEMBL431634,FN,ACT,0.9599999785423279	CHEMBL3125820,TN,INACT,0.49000000953674316	CHEMBL223360,TP,ACT,1.0	CHEMBL3356125,TN,INACT,0.9900000095367432	CHEMBL3691621,TP,ACT,1.0	CHEMBL490241,TN,INACT,0.9800000190734863	CHEMBL370485,TP,ACT,1.0	CHEMBL2012410,TP,ACT,1.0	CHEMBL3654250,TP,ACT,1.0	CHEMBL534909,TP,ACT,1.0	CHEMBL1425417,FP,INACT,1.0	CHEMBL2163610,FP,INACT,1.0	CHEMBL489039,TP,ACT,1.0	CHEMBL1681993,TN,INACT,0.8899999856948853	CHEMBL259040,TN,INACT,0.7699999809265137	CHEMBL2403083,TP,ACT,1.0	CHEMBL1522377,TN,INACT,0.8199999928474426	CHEMBL511394,TP,ACT,1.0	CHEMBL236487,TN,INACT,0.009999999776482582	CHEMBL494685,TP,ACT,1.0	CHEMBL2392241,TN,INACT,0.009999999776482582	CHEMBL368278,TP,ACT,1.0	CHEMBL2071607,TN,INACT,0.6000000238418579	CHEMBL1964249,FN,ACT,0.05999999865889549	CHEMBL3109964,TN,INACT,0.7799999713897705	CHEMBL2348165,TN,INACT,0.029999999329447746	CHEMBL2403094,TP,ACT,1.0	CHEMBL2420584,FP,INACT,1.0	CHEMBL1933806,TN,INACT,0.8500000238418579	CHEMBL2112679,TP,ACT,1.0	CHEMBL402157,TP,ACT,1.0	CHEMBL3644032,FN,ACT,0.9100000262260437	CHEMBL1337355,FP,INACT,1.0	CHEMBL519113,TN,INACT,0.6499999761581421	CHEMBL3085251,TP,ACT,1.0	CHEMBL2012413,TP,ACT,1.0	CHEMBL233455,FN,ACT,0.5199999809265137	CHEMBL409450,FN,ACT,0.9900000095367432	CHEMBL1582724,TN,INACT,0.8199999928474426	CHEMBL1490940,TN,INACT,0.5199999809265137	CHEMBL101558,TN,INACT,0.11999999731779099	CHEMBL160333,TN,INACT,0.03999999910593033	CHEMBL1170748,TN,INACT,0.8500000238418579	CHEMBL2402945,TP,ACT,1.0	CHEMBL557321,TN,INACT,0.41999998688697815	CHEMBL3691620,TP,ACT,1.0	CHEMBL234275,TP,ACT,1.0	CHEMBL1525902,TN,INACT,0.019999999552965164	CHEMBL523923,TP,ACT,1.0	CHEMBL364935,TP,ACT,1.0	CHEMBL213713,FN,ACT,0.6800000071525574	CHEMBL2348167,TN,INACT,0.17000000178813934	CHEMBL488645,TN,INACT,0.8600000143051147	CHEMBL331906,TP,ACT,1.0	CHEMBL1569232,TN,INACT,0.41999998688697815	CHEMBL2207941,TN,INACT,0.9399999976158142	CHEMBL2392366,TN,INACT,0.5899999737739563	CHEMBL233213,FN,ACT,0.3700000047683716	CHEMBL1800217,FN,ACT,0.33000001311302185	CHEMBL551936,TN,INACT,0.23999999463558197	CHEMBL1454635,TN,INACT,0.05999999865889549	CHEMBL1372916,FP,INACT,1.0	CHEMBL3216892,TP,ACT,1.0	CHEMBL199299,FN,ACT,0.8799999952316284	CHEMBL1358988,FP,INACT,1.0	CHEMBL482883,TN,INACT,0.9200000166893005	CHEMBL523714,TP,ACT,1.0	CHEMBL3648126,TP,ACT,1.0	CHEMBL366734,TP,ACT,1.0	CHEMBL508541,FN,ACT,0.1899999976158142	CHEMBL2059859,TN,INACT,0.2800000011920929	CHEMBL1288966,TN,INACT,0.20000000298023224	CHEMBL3644020,FN,ACT,0.9599999785423279	CHEMBL269827,TP,ACT,1.0	CHEMBL572922,TN,INACT,0.699999988079071	CHEMBL1540545,TN,INACT,0.029999999329447746	CHEMBL3085235,TP,ACT,1.0	CHEMBL1599919,TN,INACT,0.949999988079071	CHEMBL421578,FN,ACT,0.9700000286102295	CHEMBL234451,TP,ACT,1.0	CHEMBL1801932,TN,INACT,0.9700000286102295	CHEMBL478832,TP,ACT,1.0	CHEMBL209280,FN,ACT,0.7200000286102295	CHEMBL286491,FN,ACT,0.9399999976158142	CHEMBL1278098,TN,INACT,0.9900000095367432	CHEMBL1359999,TN,INACT,0.3400000035762787	CHEMBL105350,TN,INACT,0.05000000074505806	CHEMBL486487,TN,INACT,0.5099999904632568	CHEMBL489245,FN,ACT,0.8899999856948853	CHEMBL1448,FP,INACT,1.0	CHEMBL1973716,FP,INACT,1.0	CHEMBL234626,TP,ACT,1.0	CHEMBL1806525,TN,INACT,0.9399999976158142	CHEMBL367691,TP,ACT,1.0	CHEMBL171891,TP,ACT,1.0	CHEMBL1957095,TN,INACT,0.11999999731779099	CHEMBL347681,FP,INACT,1.0	CHEMBL3120991,TN,INACT,0.9399999976158142	CHEMBL1276446,TP,ACT,1.0	CHEMBL1767294,FP,INACT,1.0	CHEMBL1241662,FN,ACT,0.029999999329447746	CHEMBL1964258,TP,ACT,1.0	CHEMBL2392233,TN,INACT,0.009999999776482582	CHEMBL1089722,TN,INACT,0.6700000166893005	CHEMBL335938,TN,INACT,0.6200000047683716	CHEMBL414651,TP,ACT,1.0	CHEMBL1170125,TN,INACT,0.9700000286102295	CHEMBL3673435,FN,ACT,0.8999999761581421	CHEMBL1643237,TN,INACT,0.9800000190734863	CHEMBL1800219,FN,ACT,0.9800000190734863	CHEMBL486540,TN,INACT,0.23999999463558197	CHEMBL1650055,TN,INACT,0.9700000286102295	CHEMBL103055,FN,ACT,0.9599999785423279	CHEMBL1235213,FP,INACT,1.0	CHEMBL1525418,TN,INACT,0.9900000095367432	CHEMBL271183,TP,ACT,1.0	CHEMBL265448,TN,INACT,0.0	CHEMBL2012399,TP,ACT,1.0	CHEMBL272387,TP,ACT,1.0	CHEMBL400749,TP,ACT,1.0	CHEMBL496569,TP,ACT,1.0	CHEMBL130597,TP,ACT,1.0	CHEMBL2031893,TN,INACT,0.029999999329447746	CHEMBL549303,TN,INACT,0.03999999910593033	CHEMBL318208,TP,ACT,1.0	CHEMBL14762,FN,ACT,0.699999988079071	CHEMBL367442,TN,INACT,0.03999999910593033	CHEMBL1345922,FP,INACT,1.0	CHEMBL411490,TP,ACT,1.0	CHEMBL495758,TN,INACT,0.10999999940395355	CHEMBL2392239,TN,INACT,0.18000000715255737	CHEMBL1243071,TP,ACT,1.0	CHEMBL445757,TN,INACT,0.9900000095367432	CHEMBL272833,TP,ACT,1.0	CHEMBL3823680,FP,INACT,1.0	CHEMBL77002,TN,INACT,0.14000000059604645	CHEMBL478488,TN,INACT,0.8999999761581421	CHEMBL529669,FN,ACT,0.6800000071525574	CHEMBL490251,TN,INACT,0.6299999952316284	CHEMBL2037089,TN,INACT,0.9800000190734863	CHEMBL1207227,FN,ACT,0.6899999976158142	CHEMBL3398595,TN,INACT,0.27000001072883606	CHEMBL518383,FN,ACT,0.8100000023841858	CHEMBL1454264,TN,INACT,0.949999988079071	CHEMBL559683,TN,INACT,0.03999999910593033	CHEMBL403605,TP,ACT,1.0	CHEMBL411491,TP,ACT,1.0	CHEMBL213525,TN,INACT,0.949999988079071	CHEMBL1301070,FP,INACT,1.0	CHEMBL98554,TP,ACT,1.0	CHEMBL451532,TN,INACT,0.9800000190734863	CHEMBL3648103,TP,ACT,1.0	CHEMBL445813,TP,ACT,1.0	CHEMBL101801,FN,ACT,0.9800000190734863	CHEMBL2012411,TP,ACT,1.0	CHEMBL236277,TN,INACT,0.9900000095367432	CHEMBL102871,FN,ACT,0.9100000262260437	CHEMBL233454,FN,ACT,0.20999999344348907	CHEMBL1319281,TN,INACT,0.9200000166893005	CHEMBL3085242,FP,INACT,1.0	CHEMBL24484,TP,ACT,1.0	CHEMBL1644617,TN,INACT,0.8600000143051147	CHEMBL523694,TP,ACT,1.0	CHEMBL1762119,TN,INACT,0.8199999928474426	CHEMBL3644021,TP,ACT,1.0	CHEMBL429478,TP,ACT,1.0	CHEMBL1287888,TN,INACT,0.5	CHEMBL1222474,TN,INACT,0.949999988079071	CHEMBL234065,TP,ACT,1.0	CHEMBL3648094,TP,ACT,1.0	CHEMBL1494965,TN,INACT,0.009999999776482582	CHEMBL395839,TN,INACT,0.8899999856948853	CHEMBL2012400,FN,ACT,0.9700000286102295	CHEMBL291324,FN,ACT,0.03999999910593033	CHEMBL319709,FP,INACT,1.0	CHEMBL1172464,TN,INACT,0.009999999776482582	CHEMBL3691683,TP,ACT,1.0	CHEMBL204311,TN,INACT,0.23999999463558197	CHEMBL3609568,TN,INACT,0.6600000262260437	CHEMBL214025,TP,ACT,1.0	CHEMBL1170728,TN,INACT,0.05999999865889549	CHEMBL3421968,FP,INACT,1.0	CHEMBL590109,TP,ACT,1.0	CHEMBL450161,TN,INACT,0.6200000047683716	CHEMBL1555880,TN,INACT,0.25	CHEMBL556836,TP,ACT,1.0	CHEMBL385190,TP,ACT,1.0	CHEMBL2012409,TP,ACT,1.0	CHEMBL2158866,FP,INACT,1.0	CHEMBL2420909,TN,INACT,0.9399999976158142	CHEMBL1910755,FP,INACT,1.0	CHEMBL456113,TN,INACT,0.7200000286102295	CHEMBL366642,TP,ACT,1.0	CHEMBL2071610,TN,INACT,0.3400000035762787	CHEMBL2112683,TP,ACT,1.0	CHEMBL1243039,FN,ACT,0.9800000190734863	CHEMBL1800465,FN,ACT,0.7900000214576721	CHEMBL2334796,TN,INACT,0.03999999910593033	CHEMBL2348176,TN,INACT,0.029999999329447746	

