CNNModel CHEMBL4111 RMSprop 0.001 30 256 0 0.8 False True
Number of active compounds :	244
Number of inactive compounds :	244
---------------------------------
Run id: CNNModel_CHEMBL4111_RMSprop_0.001_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4111_RMSprop_0.001_30_256_0.8_True/
---------------------------------
Training samples: 288
Validation samples: 90
--
Training Step: 1  | time: 0.796s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/288
[A[ATraining Step: 2  | total loss: [1m[32m0.62379[0m[0m | time: 1.398s
[2K
| RMSProp | epoch: 001 | loss: 0.62379 - acc: 0.4500 -- iter: 064/288
[A[ATraining Step: 3  | total loss: [1m[32m0.68059[0m[0m | time: 2.013s
[2K
| RMSProp | epoch: 001 | loss: 0.68059 - acc: 0.4142 -- iter: 096/288
[A[ATraining Step: 4  | total loss: [1m[32m0.69010[0m[0m | time: 2.702s
[2K
| RMSProp | epoch: 001 | loss: 0.69010 - acc: 0.4317 -- iter: 128/288
[A[ATraining Step: 5  | total loss: [1m[32m0.69226[0m[0m | time: 3.308s
[2K
| RMSProp | epoch: 001 | loss: 0.69226 - acc: 0.4141 -- iter: 160/288
[A[ATraining Step: 6  | total loss: [1m[32m0.69283[0m[0m | time: 3.990s
[2K
| RMSProp | epoch: 001 | loss: 0.69283 - acc: 0.4291 -- iter: 192/288
[A[ATraining Step: 7  | total loss: [1m[32m0.69299[0m[0m | time: 4.616s
[2K
| RMSProp | epoch: 001 | loss: 0.69299 - acc: 0.5092 -- iter: 224/288
[A[ATraining Step: 8  | total loss: [1m[32m0.69307[0m[0m | time: 5.238s
[2K
| RMSProp | epoch: 001 | loss: 0.69307 - acc: 0.5392 -- iter: 256/288
[A[ATraining Step: 9  | total loss: [1m[32m0.69313[0m[0m | time: 6.887s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5350 | val_loss: 0.69320 - val_acc: 0.4333 -- iter: 288/288
--
Training Step: 10  | total loss: [1m[32m0.69323[0m[0m | time: 0.627s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4706 -- iter: 032/288
[A[ATraining Step: 11  | total loss: [1m[32m0.69324[0m[0m | time: 1.226s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4253 -- iter: 064/288
[A[ATraining Step: 12  | total loss: [1m[32m0.69317[0m[0m | time: 1.841s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4589 -- iter: 096/288
[A[ATraining Step: 13  | total loss: [1m[32m0.69319[0m[0m | time: 2.470s
[2K
| RMSProp | epoch: 002 | loss: 0.69319 - acc: 0.4497 -- iter: 128/288
[A[ATraining Step: 14  | total loss: [1m[32m0.69316[0m[0m | time: 3.067s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.4447 -- iter: 160/288
[A[ATraining Step: 15  | total loss: [1m[32m0.69313[0m[0m | time: 3.675s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.4786 -- iter: 192/288
[A[ATraining Step: 16  | total loss: [1m[32m0.69315[0m[0m | time: 4.264s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4749 -- iter: 224/288
[A[ATraining Step: 17  | total loss: [1m[32m0.69317[0m[0m | time: 4.879s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4839 -- iter: 256/288
[A[ATraining Step: 18  | total loss: [1m[32m0.69315[0m[0m | time: 6.507s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4895 | val_loss: 0.69319 - val_acc: 0.4333 -- iter: 288/288
--
Training Step: 19  | total loss: [1m[32m0.69317[0m[0m | time: 0.694s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.5034 -- iter: 032/288
[A[ATraining Step: 20  | total loss: [1m[32m0.69316[0m[0m | time: 1.302s
[2K
| RMSProp | epoch: 003 | loss: 0.69316 - acc: 0.5124 -- iter: 064/288
[A[ATraining Step: 21  | total loss: [1m[32m0.69314[0m[0m | time: 1.885s
[2K
| RMSProp | epoch: 003 | loss: 0.69314 - acc: 0.5085 -- iter: 096/288
[A[ATraining Step: 22  | total loss: [1m[32m0.69313[0m[0m | time: 2.493s
[2K
| RMSProp | epoch: 003 | loss: 0.69313 - acc: 0.5528 -- iter: 128/288
[A[ATraining Step: 23  | total loss: [1m[32m0.69315[0m[0m | time: 3.265s
[2K
| RMSProp | epoch: 003 | loss: 0.69315 - acc: 0.5375 -- iter: 160/288
[A[ATraining Step: 24  | total loss: [1m[32m0.69311[0m[0m | time: 3.874s
[2K
| RMSProp | epoch: 003 | loss: 0.69311 - acc: 0.5533 -- iter: 192/288
[A[ATraining Step: 25  | total loss: [1m[32m0.69314[0m[0m | time: 4.494s
[2K
| RMSProp | epoch: 003 | loss: 0.69314 - acc: 0.5388 -- iter: 224/288
[A[ATraining Step: 26  | total loss: [1m[32m0.69318[0m[0m | time: 5.103s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.5120 -- iter: 256/288
[A[ATraining Step: 27  | total loss: [1m[32m0.69320[0m[0m | time: 6.695s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.4767 | val_loss: 0.69315 - val_acc: 0.4333 -- iter: 288/288
--
Training Step: 28  | total loss: [1m[32m0.69322[0m[0m | time: 0.631s
[2K
| RMSProp | epoch: 004 | loss: 0.69322 - acc: 0.4669 -- iter: 032/288
[A[ATraining Step: 29  | total loss: [1m[32m0.69321[0m[0m | time: 1.237s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.4522 -- iter: 064/288
[A[ATraining Step: 30  | total loss: [1m[32m0.69319[0m[0m | time: 1.856s
[2K
| RMSProp | epoch: 004 | loss: 0.69319 - acc: 0.4635 -- iter: 096/288
[A[ATraining Step: 31  | total loss: [1m[32m0.69318[0m[0m | time: 2.449s
[2K
| RMSProp | epoch: 004 | loss: 0.69318 - acc: 0.4503 -- iter: 128/288
[A[ATraining Step: 32  | total loss: [1m[32m0.69316[0m[0m | time: 3.048s
[2K
| RMSProp | epoch: 004 | loss: 0.69316 - acc: 0.4685 -- iter: 160/288
[A[ATraining Step: 33  | total loss: [1m[32m0.69316[0m[0m | time: 3.733s
[2K
| RMSProp | epoch: 004 | loss: 0.69316 - acc: 0.4617 -- iter: 192/288
[A[ATraining Step: 34  | total loss: [1m[32m0.69315[0m[0m | time: 4.337s
[2K
| RMSProp | epoch: 004 | loss: 0.69315 - acc: 0.4900 -- iter: 224/288
[A[ATraining Step: 35  | total loss: [1m[32m0.69316[0m[0m | time: 5.023s
[2K
| RMSProp | epoch: 004 | loss: 0.69316 - acc: 0.4725 -- iter: 256/288
[A[ATraining Step: 36  | total loss: [1m[32m0.69314[0m[0m | time: 6.623s
[2K
| RMSProp | epoch: 004 | loss: 0.69314 - acc: 0.4781 | val_loss: 0.69298 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 37  | total loss: [1m[32m0.69312[0m[0m | time: 0.604s
[2K
| RMSProp | epoch: 005 | loss: 0.69312 - acc: 0.4825 -- iter: 032/288
[A[ATraining Step: 38  | total loss: [1m[32m0.69318[0m[0m | time: 1.245s
[2K
| RMSProp | epoch: 005 | loss: 0.69318 - acc: 0.4737 -- iter: 064/288
[A[ATraining Step: 39  | total loss: [1m[32m0.69322[0m[0m | time: 1.862s
[2K
| RMSProp | epoch: 005 | loss: 0.69322 - acc: 0.4608 -- iter: 096/288
[A[ATraining Step: 40  | total loss: [1m[32m0.69322[0m[0m | time: 2.483s
[2K
| RMSProp | epoch: 005 | loss: 0.69322 - acc: 0.4623 -- iter: 128/288
[A[ATraining Step: 41  | total loss: [1m[32m0.69321[0m[0m | time: 3.084s
[2K
| RMSProp | epoch: 005 | loss: 0.69321 - acc: 0.4692 -- iter: 160/288
[A[ATraining Step: 42  | total loss: [1m[32m0.69319[0m[0m | time: 3.681s
[2K
| RMSProp | epoch: 005 | loss: 0.69319 - acc: 0.4860 -- iter: 192/288
[A[ATraining Step: 43  | total loss: [1m[32m0.69313[0m[0m | time: 4.308s
[2K
| RMSProp | epoch: 005 | loss: 0.69313 - acc: 0.5216 -- iter: 224/288
[A[ATraining Step: 44  | total loss: [1m[32m0.69305[0m[0m | time: 4.924s
[2K
| RMSProp | epoch: 005 | loss: 0.69305 - acc: 0.5340 -- iter: 256/288
[A[ATraining Step: 45  | total loss: [1m[32m0.69313[0m[0m | time: 6.523s
[2K
| RMSProp | epoch: 005 | loss: 0.69313 - acc: 0.5177 | val_loss: 0.69286 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 46  | total loss: [1m[32m0.69314[0m[0m | time: 0.617s
[2K
| RMSProp | epoch: 006 | loss: 0.69314 - acc: 0.5095 -- iter: 032/288
[A[ATraining Step: 47  | total loss: [1m[32m0.69310[0m[0m | time: 1.230s
[2K
| RMSProp | epoch: 006 | loss: 0.69310 - acc: 0.5182 -- iter: 064/288
[A[ATraining Step: 48  | total loss: [1m[32m0.69316[0m[0m | time: 1.881s
[2K
| RMSProp | epoch: 006 | loss: 0.69316 - acc: 0.5002 -- iter: 096/288
[A[ATraining Step: 49  | total loss: [1m[32m0.69304[0m[0m | time: 2.490s
[2K
| RMSProp | epoch: 006 | loss: 0.69304 - acc: 0.5298 -- iter: 128/288
[A[ATraining Step: 50  | total loss: [1m[32m0.69318[0m[0m | time: 3.080s
[2K
| RMSProp | epoch: 006 | loss: 0.69318 - acc: 0.5106 -- iter: 160/288
[A[ATraining Step: 51  | total loss: [1m[32m0.69326[0m[0m | time: 3.679s
[2K
| RMSProp | epoch: 006 | loss: 0.69326 - acc: 0.4947 -- iter: 192/288
[A[ATraining Step: 52  | total loss: [1m[32m0.69328[0m[0m | time: 4.287s
[2K
| RMSProp | epoch: 006 | loss: 0.69328 - acc: 0.4861 -- iter: 224/288
[A[ATraining Step: 53  | total loss: [1m[32m0.69325[0m[0m | time: 4.891s
[2K
| RMSProp | epoch: 006 | loss: 0.69325 - acc: 0.5020 -- iter: 256/288
[A[ATraining Step: 54  | total loss: [1m[32m0.69322[0m[0m | time: 6.499s
[2K
| RMSProp | epoch: 006 | loss: 0.69322 - acc: 0.5108 | val_loss: 0.69277 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 55  | total loss: [1m[32m0.69318[0m[0m | time: 0.598s
[2K
| RMSProp | epoch: 007 | loss: 0.69318 - acc: 0.5137 -- iter: 032/288
[A[ATraining Step: 56  | total loss: [1m[32m0.69314[0m[0m | time: 1.230s
[2K
| RMSProp | epoch: 007 | loss: 0.69314 - acc: 0.5162 -- iter: 064/288
[A[ATraining Step: 57  | total loss: [1m[32m0.69317[0m[0m | time: 1.830s
[2K
| RMSProp | epoch: 007 | loss: 0.69317 - acc: 0.5096 -- iter: 096/288
[A[ATraining Step: 58  | total loss: [1m[32m0.69307[0m[0m | time: 2.433s
[2K
| RMSProp | epoch: 007 | loss: 0.69307 - acc: 0.5253 -- iter: 128/288
[A[ATraining Step: 59  | total loss: [1m[32m0.69309[0m[0m | time: 3.033s
[2K
| RMSProp | epoch: 007 | loss: 0.69309 - acc: 0.5219 -- iter: 160/288
[A[ATraining Step: 60  | total loss: [1m[32m0.69307[0m[0m | time: 3.642s
[2K
| RMSProp | epoch: 007 | loss: 0.69307 - acc: 0.5232 -- iter: 192/288
[A[ATraining Step: 61  | total loss: [1m[32m0.69304[0m[0m | time: 4.277s
[2K
| RMSProp | epoch: 007 | loss: 0.69304 - acc: 0.5242 -- iter: 224/288
[A[ATraining Step: 62  | total loss: [1m[32m0.69317[0m[0m | time: 4.883s
[2K
| RMSProp | epoch: 007 | loss: 0.69317 - acc: 0.5091 -- iter: 256/288
[A[ATraining Step: 63  | total loss: [1m[32m0.69319[0m[0m | time: 6.487s
[2K
| RMSProp | epoch: 007 | loss: 0.69319 - acc: 0.5039 | val_loss: 0.69258 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 64  | total loss: [1m[32m0.69314[0m[0m | time: 0.596s
[2K
| RMSProp | epoch: 008 | loss: 0.69314 - acc: 0.5113 -- iter: 032/288
[A[ATraining Step: 65  | total loss: [1m[32m0.69321[0m[0m | time: 1.232s
[2K
| RMSProp | epoch: 008 | loss: 0.69321 - acc: 0.5022 -- iter: 064/288
[A[ATraining Step: 66  | total loss: [1m[32m0.69316[0m[0m | time: 1.865s
[2K
| RMSProp | epoch: 008 | loss: 0.69316 - acc: 0.5095 -- iter: 096/288
[A[ATraining Step: 67  | total loss: [1m[32m0.69317[0m[0m | time: 2.471s
[2K
| RMSProp | epoch: 008 | loss: 0.69317 - acc: 0.5084 -- iter: 128/288
[A[ATraining Step: 68  | total loss: [1m[32m0.69310[0m[0m | time: 3.070s
[2K
| RMSProp | epoch: 008 | loss: 0.69310 - acc: 0.5148 -- iter: 160/288
[A[ATraining Step: 69  | total loss: [1m[32m0.69298[0m[0m | time: 3.682s
[2K
| RMSProp | epoch: 008 | loss: 0.69298 - acc: 0.5240 -- iter: 192/288
[A[ATraining Step: 70  | total loss: [1m[32m0.69325[0m[0m | time: 4.290s
[2K
| RMSProp | epoch: 008 | loss: 0.69325 - acc: 0.5032 -- iter: 224/288
[A[ATraining Step: 71  | total loss: [1m[32m0.69338[0m[0m | time: 4.909s
[2K
| RMSProp | epoch: 008 | loss: 0.69338 - acc: 0.4850 -- iter: 256/288
[A[ATraining Step: 72  | total loss: [1m[32m0.69331[0m[0m | time: 6.537s
[2K
| RMSProp | epoch: 008 | loss: 0.69331 - acc: 0.5008 | val_loss: 0.69264 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 73  | total loss: [1m[32m0.69328[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 009 | loss: 0.69328 - acc: 0.5007 -- iter: 032/288
[A[ATraining Step: 74  | total loss: [1m[32m0.69323[0m[0m | time: 1.223s
[2K
| RMSProp | epoch: 009 | loss: 0.69323 - acc: 0.5041 -- iter: 064/288
[A[ATraining Step: 75  | total loss: [1m[32m0.69326[0m[0m | time: 1.830s
[2K
| RMSProp | epoch: 009 | loss: 0.69326 - acc: 0.5002 -- iter: 096/288
[A[ATraining Step: 76  | total loss: [1m[32m0.69333[0m[0m | time: 2.443s
[2K
| RMSProp | epoch: 009 | loss: 0.69333 - acc: 0.4868 -- iter: 128/288
[A[ATraining Step: 77  | total loss: [1m[32m0.69329[0m[0m | time: 3.042s
[2K
| RMSProp | epoch: 009 | loss: 0.69329 - acc: 0.4981 -- iter: 160/288
[A[ATraining Step: 78  | total loss: [1m[32m0.69333[0m[0m | time: 3.644s
[2K
| RMSProp | epoch: 009 | loss: 0.69333 - acc: 0.4885 -- iter: 192/288
[A[ATraining Step: 79  | total loss: [1m[32m0.69331[0m[0m | time: 4.278s
[2K
| RMSProp | epoch: 009 | loss: 0.69331 - acc: 0.4865 -- iter: 224/288
[A[ATraining Step: 80  | total loss: [1m[32m0.69327[0m[0m | time: 4.908s
[2K
| RMSProp | epoch: 009 | loss: 0.69327 - acc: 0.4942 -- iter: 256/288
[A[ATraining Step: 81  | total loss: [1m[32m0.69324[0m[0m | time: 6.512s
[2K
| RMSProp | epoch: 009 | loss: 0.69324 - acc: 0.4980 | val_loss: 0.69268 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 82  | total loss: [1m[32m0.69320[0m[0m | time: 0.602s
[2K
| RMSProp | epoch: 010 | loss: 0.69320 - acc: 0.5013 -- iter: 032/288
[A[ATraining Step: 83  | total loss: [1m[32m0.69310[0m[0m | time: 1.210s
[2K
| RMSProp | epoch: 010 | loss: 0.69310 - acc: 0.5106 -- iter: 064/288
[A[ATraining Step: 84  | total loss: [1m[32m0.69308[0m[0m | time: 1.830s
[2K
| RMSProp | epoch: 010 | loss: 0.69308 - acc: 0.5126 -- iter: 096/288
[A[ATraining Step: 85  | total loss: [1m[32m0.69296[0m[0m | time: 2.423s
[2K
| RMSProp | epoch: 010 | loss: 0.69296 - acc: 0.5207 -- iter: 128/288
[A[ATraining Step: 86  | total loss: [1m[32m0.69292[0m[0m | time: 3.047s
[2K
| RMSProp | epoch: 010 | loss: 0.69292 - acc: 0.5218 -- iter: 160/288
[A[ATraining Step: 87  | total loss: [1m[32m0.69317[0m[0m | time: 3.642s
[2K
| RMSProp | epoch: 010 | loss: 0.69317 - acc: 0.5071 -- iter: 192/288
[A[ATraining Step: 88  | total loss: [1m[32m0.69307[0m[0m | time: 4.235s
[2K
| RMSProp | epoch: 010 | loss: 0.69307 - acc: 0.5158 -- iter: 224/288
[A[ATraining Step: 89  | total loss: [1m[32m0.69313[0m[0m | time: 4.830s
[2K
| RMSProp | epoch: 010 | loss: 0.69313 - acc: 0.5111 -- iter: 256/288
[A[ATraining Step: 90  | total loss: [1m[32m0.69312[0m[0m | time: 6.436s
[2K
| RMSProp | epoch: 010 | loss: 0.69312 - acc: 0.5100 | val_loss: 0.69222 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 91  | total loss: [1m[32m0.69311[0m[0m | time: 0.619s
[2K
| RMSProp | epoch: 011 | loss: 0.69311 - acc: 0.5090 -- iter: 032/288
[A[ATraining Step: 92  | total loss: [1m[32m0.69303[0m[0m | time: 1.220s
[2K
| RMSProp | epoch: 011 | loss: 0.69303 - acc: 0.5143 -- iter: 064/288
[A[ATraining Step: 93  | total loss: [1m[32m0.69287[0m[0m | time: 1.823s
[2K
| RMSProp | epoch: 011 | loss: 0.69287 - acc: 0.5223 -- iter: 096/288
[A[ATraining Step: 94  | total loss: [1m[32m0.69275[0m[0m | time: 2.424s
[2K
| RMSProp | epoch: 011 | loss: 0.69275 - acc: 0.5263 -- iter: 128/288
[A[ATraining Step: 95  | total loss: [1m[32m0.69278[0m[0m | time: 3.023s
[2K
| RMSProp | epoch: 011 | loss: 0.69278 - acc: 0.5237 -- iter: 160/288
[A[ATraining Step: 96  | total loss: [1m[32m0.69282[0m[0m | time: 3.632s
[2K
| RMSProp | epoch: 011 | loss: 0.69282 - acc: 0.5213 -- iter: 192/288
[A[ATraining Step: 97  | total loss: [1m[32m0.69330[0m[0m | time: 4.244s
[2K
| RMSProp | epoch: 011 | loss: 0.69330 - acc: 0.5004 -- iter: 224/288
[A[ATraining Step: 98  | total loss: [1m[32m0.69335[0m[0m | time: 4.845s
[2K
| RMSProp | epoch: 011 | loss: 0.69335 - acc: 0.4941 -- iter: 256/288
[A[ATraining Step: 99  | total loss: [1m[32m0.69328[0m[0m | time: 6.443s
[2K
| RMSProp | epoch: 011 | loss: 0.69328 - acc: 0.5010 | val_loss: 0.69270 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 100  | total loss: [1m[32m0.69332[0m[0m | time: 0.602s
[2K
| RMSProp | epoch: 012 | loss: 0.69332 - acc: 0.4946 -- iter: 032/288
[A[ATraining Step: 101  | total loss: [1m[32m0.69332[0m[0m | time: 1.208s
[2K
| RMSProp | epoch: 012 | loss: 0.69332 - acc: 0.4889 -- iter: 064/288
[A[ATraining Step: 102  | total loss: [1m[32m0.69331[0m[0m | time: 1.817s
[2K
| RMSProp | epoch: 012 | loss: 0.69331 - acc: 0.4775 -- iter: 096/288
[A[ATraining Step: 103  | total loss: [1m[32m0.69328[0m[0m | time: 2.429s
[2K
| RMSProp | epoch: 012 | loss: 0.69328 - acc: 0.4829 -- iter: 128/288
[A[ATraining Step: 104  | total loss: [1m[32m0.69322[0m[0m | time: 3.025s
[2K
| RMSProp | epoch: 012 | loss: 0.69322 - acc: 0.4940 -- iter: 160/288
[A[ATraining Step: 105  | total loss: [1m[32m0.69328[0m[0m | time: 3.635s
[2K
| RMSProp | epoch: 012 | loss: 0.69328 - acc: 0.4883 -- iter: 192/288
[A[ATraining Step: 106  | total loss: [1m[32m0.69328[0m[0m | time: 4.238s
[2K
| RMSProp | epoch: 012 | loss: 0.69328 - acc: 0.4832 -- iter: 224/288
[A[ATraining Step: 107  | total loss: [1m[32m0.69327[0m[0m | time: 4.834s
[2K
| RMSProp | epoch: 012 | loss: 0.69327 - acc: 0.4755 -- iter: 256/288
[A[ATraining Step: 108  | total loss: [1m[32m0.69329[0m[0m | time: 6.446s
[2K
| RMSProp | epoch: 012 | loss: 0.69329 - acc: 0.4749 | val_loss: 0.69197 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 109  | total loss: [1m[32m0.69320[0m[0m | time: 0.604s
[2K
| RMSProp | epoch: 013 | loss: 0.69320 - acc: 0.4805 -- iter: 032/288
[A[ATraining Step: 110  | total loss: [1m[32m0.69323[0m[0m | time: 1.210s
[2K
| RMSProp | epoch: 013 | loss: 0.69323 - acc: 0.4793 -- iter: 064/288
[A[ATraining Step: 111  | total loss: [1m[32m0.69323[0m[0m | time: 1.821s
[2K
| RMSProp | epoch: 013 | loss: 0.69323 - acc: 0.4783 -- iter: 096/288
[A[ATraining Step: 112  | total loss: [1m[32m0.69312[0m[0m | time: 2.419s
[2K
| RMSProp | epoch: 013 | loss: 0.69312 - acc: 0.4898 -- iter: 128/288
[A[ATraining Step: 113  | total loss: [1m[32m0.69292[0m[0m | time: 3.019s
[2K
| RMSProp | epoch: 013 | loss: 0.69292 - acc: 0.5002 -- iter: 160/288
[A[ATraining Step: 114  | total loss: [1m[32m0.69285[0m[0m | time: 3.641s
[2K
| RMSProp | epoch: 013 | loss: 0.69285 - acc: 0.5033 -- iter: 192/288
[A[ATraining Step: 115  | total loss: [1m[32m0.69302[0m[0m | time: 4.252s
[2K
| RMSProp | epoch: 013 | loss: 0.69302 - acc: 0.4967 -- iter: 224/288
[A[ATraining Step: 116  | total loss: [1m[32m0.69307[0m[0m | time: 4.875s
[2K
| RMSProp | epoch: 013 | loss: 0.69307 - acc: 0.4939 -- iter: 256/288
[A[ATraining Step: 117  | total loss: [1m[32m0.69305[0m[0m | time: 6.473s
[2K
| RMSProp | epoch: 013 | loss: 0.69305 - acc: 0.4945 | val_loss: 0.69296 - val_acc: 0.4333 -- iter: 288/288
--
Training Step: 118  | total loss: [1m[32m0.69311[0m[0m | time: 0.635s
[2K
| RMSProp | epoch: 014 | loss: 0.69311 - acc: 0.4888 -- iter: 032/288
[A[ATraining Step: 119  | total loss: [1m[32m0.69312[0m[0m | time: 1.238s
[2K
| RMSProp | epoch: 014 | loss: 0.69312 - acc: 0.4868 -- iter: 064/288
[A[ATraining Step: 120  | total loss: [1m[32m0.69325[0m[0m | time: 1.873s
[2K
| RMSProp | epoch: 014 | loss: 0.69325 - acc: 0.4788 -- iter: 096/288
[A[ATraining Step: 121  | total loss: [1m[32m0.69317[0m[0m | time: 2.473s
[2K
| RMSProp | epoch: 014 | loss: 0.69317 - acc: 0.4903 -- iter: 128/288
[A[ATraining Step: 122  | total loss: [1m[32m0.69302[0m[0m | time: 3.077s
[2K
| RMSProp | epoch: 014 | loss: 0.69302 - acc: 0.4975 -- iter: 160/288
[A[ATraining Step: 123  | total loss: [1m[32m0.69272[0m[0m | time: 3.675s
[2K
| RMSProp | epoch: 014 | loss: 0.69272 - acc: 0.5071 -- iter: 192/288
[A[ATraining Step: 124  | total loss: [1m[32m0.69322[0m[0m | time: 4.276s
[2K
| RMSProp | epoch: 014 | loss: 0.69322 - acc: 0.4970 -- iter: 224/288
[A[ATraining Step: 125  | total loss: [1m[32m0.69337[0m[0m | time: 4.872s
[2K
| RMSProp | epoch: 014 | loss: 0.69337 - acc: 0.4848 -- iter: 256/288
[A[ATraining Step: 126  | total loss: [1m[32m0.69316[0m[0m | time: 6.566s
[2K
| RMSProp | epoch: 014 | loss: 0.69316 - acc: 0.4957 | val_loss: 0.69107 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 127  | total loss: [1m[32m0.69314[0m[0m | time: 0.603s
[2K
| RMSProp | epoch: 015 | loss: 0.69314 - acc: 0.4961 -- iter: 032/288
[A[ATraining Step: 128  | total loss: [1m[32m0.69290[0m[0m | time: 1.218s
[2K
| RMSProp | epoch: 015 | loss: 0.69290 - acc: 0.5059 -- iter: 064/288
[A[ATraining Step: 129  | total loss: [1m[32m0.69325[0m[0m | time: 1.820s
[2K
| RMSProp | epoch: 015 | loss: 0.69325 - acc: 0.4959 -- iter: 096/288
[A[ATraining Step: 130  | total loss: [1m[32m0.69316[0m[0m | time: 2.435s
[2K
| RMSProp | epoch: 015 | loss: 0.69316 - acc: 0.5307 -- iter: 128/288
[A[ATraining Step: 131  | total loss: [1m[32m0.69297[0m[0m | time: 3.035s
[2K
| RMSProp | epoch: 015 | loss: 0.69297 - acc: 0.5339 -- iter: 160/288
[A[ATraining Step: 132  | total loss: [1m[32m0.69296[0m[0m | time: 3.646s
[2K
| RMSProp | epoch: 015 | loss: 0.69296 - acc: 0.5305 -- iter: 192/288
[A[ATraining Step: 133  | total loss: [1m[32m0.69286[0m[0m | time: 4.247s
[2K
| RMSProp | epoch: 015 | loss: 0.69286 - acc: 0.5306 -- iter: 224/288
[A[ATraining Step: 134  | total loss: [1m[32m0.69246[0m[0m | time: 4.868s
[2K
| RMSProp | epoch: 015 | loss: 0.69246 - acc: 0.5400 -- iter: 256/288
[A[ATraining Step: 135  | total loss: [1m[32m0.69364[0m[0m | time: 6.473s
[2K
| RMSProp | epoch: 015 | loss: 0.69364 - acc: 0.5204 | val_loss: 0.69236 - val_acc: 0.7667 -- iter: 288/288
--
Training Step: 136  | total loss: [1m[32m0.69392[0m[0m | time: 0.645s
[2K
| RMSProp | epoch: 016 | loss: 0.69392 - acc: 0.5059 -- iter: 032/288
[A[ATraining Step: 137  | total loss: [1m[32m0.69375[0m[0m | time: 1.251s
[2K
| RMSProp | epoch: 016 | loss: 0.69375 - acc: 0.5365 -- iter: 064/288
[A[ATraining Step: 138  | total loss: [1m[32m0.69323[0m[0m | time: 1.850s
[2K
| RMSProp | epoch: 016 | loss: 0.69323 - acc: 0.5454 -- iter: 096/288
[A[ATraining Step: 139  | total loss: [1m[32m0.69351[0m[0m | time: 2.450s
[2K
| RMSProp | epoch: 016 | loss: 0.69351 - acc: 0.5346 -- iter: 128/288
[A[ATraining Step: 140  | total loss: [1m[32m0.69368[0m[0m | time: 3.068s
[2K
| RMSProp | epoch: 016 | loss: 0.69368 - acc: 0.5218 -- iter: 160/288
[A[ATraining Step: 141  | total loss: [1m[32m0.69350[0m[0m | time: 3.675s
[2K
| RMSProp | epoch: 016 | loss: 0.69350 - acc: 0.5477 -- iter: 192/288
[A[ATraining Step: 142  | total loss: [1m[32m0.69344[0m[0m | time: 4.302s
[2K
| RMSProp | epoch: 016 | loss: 0.69344 - acc: 0.5398 -- iter: 224/288
[A[ATraining Step: 143  | total loss: [1m[32m0.69330[0m[0m | time: 4.936s
[2K
| RMSProp | epoch: 016 | loss: 0.69330 - acc: 0.5389 -- iter: 256/288
[A[ATraining Step: 144  | total loss: [1m[32m0.69302[0m[0m | time: 6.570s
[2K
| RMSProp | epoch: 016 | loss: 0.69302 - acc: 0.5413 | val_loss: 0.69060 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 145  | total loss: [1m[32m0.69358[0m[0m | time: 0.603s
[2K
| RMSProp | epoch: 017 | loss: 0.69358 - acc: 0.5278 -- iter: 032/288
[A[ATraining Step: 146  | total loss: [1m[32m0.69330[0m[0m | time: 1.226s
[2K
| RMSProp | epoch: 017 | loss: 0.69330 - acc: 0.5313 -- iter: 064/288
[A[ATraining Step: 147  | total loss: [1m[32m0.69344[0m[0m | time: 1.826s
[2K
| RMSProp | epoch: 017 | loss: 0.69344 - acc: 0.5219 -- iter: 096/288
[A[ATraining Step: 148  | total loss: [1m[32m0.69324[0m[0m | time: 2.430s
[2K
| RMSProp | epoch: 017 | loss: 0.69324 - acc: 0.5260 -- iter: 128/288
[A[ATraining Step: 149  | total loss: [1m[32m0.69278[0m[0m | time: 3.031s
[2K
| RMSProp | epoch: 017 | loss: 0.69278 - acc: 0.5327 -- iter: 160/288
[A[ATraining Step: 150  | total loss: [1m[32m0.69307[0m[0m | time: 3.652s
[2K
| RMSProp | epoch: 017 | loss: 0.69307 - acc: 0.5263 -- iter: 192/288
[A[ATraining Step: 151  | total loss: [1m[32m0.69306[0m[0m | time: 4.249s
[2K
| RMSProp | epoch: 017 | loss: 0.69306 - acc: 0.5206 -- iter: 224/288
[A[ATraining Step: 152  | total loss: [1m[32m0.69271[0m[0m | time: 4.864s
[2K
| RMSProp | epoch: 017 | loss: 0.69271 - acc: 0.5310 -- iter: 256/288
[A[ATraining Step: 153  | total loss: [1m[32m0.69267[0m[0m | time: 6.488s
[2K
| RMSProp | epoch: 017 | loss: 0.69267 - acc: 0.5217 | val_loss: 0.69054 - val_acc: 0.5667 -- iter: 288/288
--
Training Step: 154  | total loss: [1m[32m0.69353[0m[0m | time: 0.650s
[2K
| RMSProp | epoch: 018 | loss: 0.69353 - acc: 0.5070 -- iter: 032/288
[A[ATraining Step: 155  | total loss: [1m[32m0.69324[0m[0m | time: 1.262s
[2K
| RMSProp | epoch: 018 | loss: 0.69324 - acc: 0.5125 -- iter: 064/288
[A[ATraining Step: 156  | total loss: [1m[32m0.69286[0m[0m | time: 1.870s
[2K
| RMSProp | epoch: 018 | loss: 0.69286 - acc: 0.5269 -- iter: 096/288
[A[ATraining Step: 157  | total loss: [1m[32m0.69241[0m[0m | time: 2.469s
[2K
| RMSProp | epoch: 018 | loss: 0.69241 - acc: 0.5492 -- iter: 128/288
[A[ATraining Step: 158  | total loss: [1m[32m0.69196[0m[0m | time: 3.072s
[2K
| RMSProp | epoch: 018 | loss: 0.69196 - acc: 0.5474 -- iter: 160/288
[A[ATraining Step: 159  | total loss: [1m[32m0.69343[0m[0m | time: 3.686s
[2K
| RMSProp | epoch: 018 | loss: 0.69343 - acc: 0.5364 -- iter: 192/288
[A[ATraining Step: 160  | total loss: [1m[32m0.69326[0m[0m | time: 4.288s
[2K
| RMSProp | epoch: 018 | loss: 0.69326 - acc: 0.5328 -- iter: 224/288
[A[ATraining Step: 161  | total loss: [1m[32m0.69273[0m[0m | time: 4.901s
[2K
| RMSProp | epoch: 018 | loss: 0.69273 - acc: 0.5389 -- iter: 256/288
[A[ATraining Step: 162  | total loss: [1m[32m0.69174[0m[0m | time: 6.506s
[2K
| RMSProp | epoch: 018 | loss: 0.69174 - acc: 0.5631 | val_loss: 0.69663 - val_acc: 0.4333 -- iter: 288/288
--
Training Step: 163  | total loss: [1m[32m0.69041[0m[0m | time: 0.607s
[2K
| RMSProp | epoch: 019 | loss: 0.69041 - acc: 0.5631 -- iter: 032/288
[A[ATraining Step: 164  | total loss: [1m[32m0.68886[0m[0m | time: 1.206s
[2K
| RMSProp | epoch: 019 | loss: 0.68886 - acc: 0.5630 -- iter: 064/288
[A[ATraining Step: 165  | total loss: [1m[32m0.68399[0m[0m | time: 1.809s
[2K
| RMSProp | epoch: 019 | loss: 0.68399 - acc: 0.5911 -- iter: 096/288
[A[ATraining Step: 166  | total loss: [1m[32m0.75277[0m[0m | time: 2.407s
[2K
| RMSProp | epoch: 019 | loss: 0.75277 - acc: 0.5726 -- iter: 128/288
[A[ATraining Step: 167  | total loss: [1m[32m0.74545[0m[0m | time: 3.009s
[2K
| RMSProp | epoch: 019 | loss: 0.74545 - acc: 0.5716 -- iter: 160/288
[A[ATraining Step: 168  | total loss: [1m[32m0.73813[0m[0m | time: 3.613s
[2K
| RMSProp | epoch: 019 | loss: 0.73813 - acc: 0.5769 -- iter: 192/288
[A[ATraining Step: 169  | total loss: [1m[32m0.72974[0m[0m | time: 4.217s
[2K
| RMSProp | epoch: 019 | loss: 0.72974 - acc: 0.5849 -- iter: 224/288
[A[ATraining Step: 170  | total loss: [1m[32m0.71913[0m[0m | time: 4.813s
[2K
| RMSProp | epoch: 019 | loss: 0.71913 - acc: 0.6076 -- iter: 256/288
[A[ATraining Step: 171  | total loss: [1m[32m0.71654[0m[0m | time: 6.422s
[2K
| RMSProp | epoch: 019 | loss: 0.71654 - acc: 0.6062 | val_loss: 0.60642 - val_acc: 0.7333 -- iter: 288/288
--
Training Step: 172  | total loss: [1m[32m0.71023[0m[0m | time: 0.593s
[2K
| RMSProp | epoch: 020 | loss: 0.71023 - acc: 0.6300 -- iter: 032/288
[A[ATraining Step: 173  | total loss: [1m[32m0.69989[0m[0m | time: 1.190s
[2K
| RMSProp | epoch: 020 | loss: 0.69989 - acc: 0.6420 -- iter: 064/288
[A[ATraining Step: 174  | total loss: [1m[32m0.69187[0m[0m | time: 1.789s
[2K
| RMSProp | epoch: 020 | loss: 0.69187 - acc: 0.6465 -- iter: 096/288
[A[ATraining Step: 175  | total loss: [1m[32m0.68113[0m[0m | time: 2.390s
[2K
| RMSProp | epoch: 020 | loss: 0.68113 - acc: 0.6413 -- iter: 128/288
[A[ATraining Step: 176  | total loss: [1m[32m0.67422[0m[0m | time: 2.994s
[2K
| RMSProp | epoch: 020 | loss: 0.67422 - acc: 0.6521 -- iter: 160/288
[A[ATraining Step: 177  | total loss: [1m[32m0.65410[0m[0m | time: 3.586s
[2K
| RMSProp | epoch: 020 | loss: 0.65410 - acc: 0.6807 -- iter: 192/288
[A[ATraining Step: 178  | total loss: [1m[32m0.65050[0m[0m | time: 4.190s
[2K
| RMSProp | epoch: 020 | loss: 0.65050 - acc: 0.6845 -- iter: 224/288
[A[ATraining Step: 179  | total loss: [1m[32m0.65966[0m[0m | time: 4.836s
[2K
| RMSProp | epoch: 020 | loss: 0.65966 - acc: 0.6629 -- iter: 256/288
[A[ATraining Step: 180  | total loss: [1m[32m0.65457[0m[0m | time: 6.440s
[2K
| RMSProp | epoch: 020 | loss: 0.65457 - acc: 0.6716 | val_loss: 0.42350 - val_acc: 0.8556 -- iter: 288/288
--
Training Step: 181  | total loss: [1m[32m0.64081[0m[0m | time: 0.656s
[2K
| RMSProp | epoch: 021 | loss: 0.64081 - acc: 0.6920 -- iter: 032/288
[A[ATraining Step: 182  | total loss: [1m[32m0.62497[0m[0m | time: 1.266s
[2K
| RMSProp | epoch: 021 | loss: 0.62497 - acc: 0.6915 -- iter: 064/288
[A[ATraining Step: 183  | total loss: [1m[32m0.61575[0m[0m | time: 1.867s
[2K
| RMSProp | epoch: 021 | loss: 0.61575 - acc: 0.7036 -- iter: 096/288
[A[ATraining Step: 184  | total loss: [1m[32m0.60052[0m[0m | time: 2.471s
[2K
| RMSProp | epoch: 021 | loss: 0.60052 - acc: 0.7114 -- iter: 128/288
[A[ATraining Step: 185  | total loss: [1m[32m0.59063[0m[0m | time: 3.082s
[2K
| RMSProp | epoch: 021 | loss: 0.59063 - acc: 0.7215 -- iter: 160/288
[A[ATraining Step: 186  | total loss: [1m[32m0.56709[0m[0m | time: 3.691s
[2K
| RMSProp | epoch: 021 | loss: 0.56709 - acc: 0.7306 -- iter: 192/288
[A[ATraining Step: 187  | total loss: [1m[32m0.55022[0m[0m | time: 4.292s
[2K
| RMSProp | epoch: 021 | loss: 0.55022 - acc: 0.7419 -- iter: 224/288
[A[ATraining Step: 188  | total loss: [1m[32m0.53882[0m[0m | time: 4.903s
[2K
| RMSProp | epoch: 021 | loss: 0.53882 - acc: 0.7490 -- iter: 256/288
[A[ATraining Step: 189  | total loss: [1m[32m0.51682[0m[0m | time: 6.505s
[2K
| RMSProp | epoch: 021 | loss: 0.51682 - acc: 0.7616 | val_loss: 0.83233 - val_acc: 0.4889 -- iter: 288/288
--
Training Step: 190  | total loss: [1m[32m0.50744[0m[0m | time: 0.605s
[2K
| RMSProp | epoch: 022 | loss: 0.50744 - acc: 0.7667 -- iter: 032/288
[A[ATraining Step: 191  | total loss: [1m[32m0.52038[0m[0m | time: 1.214s
[2K
| RMSProp | epoch: 022 | loss: 0.52038 - acc: 0.7494 -- iter: 064/288
[A[ATraining Step: 192  | total loss: [1m[32m0.51634[0m[0m | time: 1.822s
[2K
| RMSProp | epoch: 022 | loss: 0.51634 - acc: 0.7557 -- iter: 096/288
[A[ATraining Step: 193  | total loss: [1m[32m0.50376[0m[0m | time: 2.423s
[2K
| RMSProp | epoch: 022 | loss: 0.50376 - acc: 0.7614 -- iter: 128/288
[A[ATraining Step: 194  | total loss: [1m[32m0.47857[0m[0m | time: 3.035s
[2K
| RMSProp | epoch: 022 | loss: 0.47857 - acc: 0.7790 -- iter: 160/288
[A[ATraining Step: 195  | total loss: [1m[32m0.47091[0m[0m | time: 3.648s
[2K
| RMSProp | epoch: 022 | loss: 0.47091 - acc: 0.7792 -- iter: 192/288
[A[ATraining Step: 196  | total loss: [1m[32m0.45885[0m[0m | time: 4.249s
[2K
| RMSProp | epoch: 022 | loss: 0.45885 - acc: 0.7825 -- iter: 224/288
[A[ATraining Step: 197  | total loss: [1m[32m0.45008[0m[0m | time: 4.854s
[2K
| RMSProp | epoch: 022 | loss: 0.45008 - acc: 0.7918 -- iter: 256/288
[A[ATraining Step: 198  | total loss: [1m[32m0.45305[0m[0m | time: 6.454s
[2K
| RMSProp | epoch: 022 | loss: 0.45305 - acc: 0.8001 | val_loss: 0.29320 - val_acc: 0.9000 -- iter: 288/288
--
Training Step: 199  | total loss: [1m[32m0.44972[0m[0m | time: 0.622s
[2K
| RMSProp | epoch: 023 | loss: 0.44972 - acc: 0.8013 -- iter: 032/288
[A[ATraining Step: 200  | total loss: [1m[32m0.43950[0m[0m | time: 2.274s
[2K
| RMSProp | epoch: 023 | loss: 0.43950 - acc: 0.8118 | val_loss: 0.33250 - val_acc: 0.8444 -- iter: 064/288
--
Training Step: 201  | total loss: [1m[32m0.42197[0m[0m | time: 2.882s
[2K
| RMSProp | epoch: 023 | loss: 0.42197 - acc: 0.8181 -- iter: 096/288
[A[ATraining Step: 202  | total loss: [1m[32m0.39905[0m[0m | time: 3.476s
[2K
| RMSProp | epoch: 023 | loss: 0.39905 - acc: 0.8301 -- iter: 128/288
[A[ATraining Step: 203  | total loss: [1m[32m0.39360[0m[0m | time: 4.075s
[2K
| RMSProp | epoch: 023 | loss: 0.39360 - acc: 0.8315 -- iter: 160/288
[A[ATraining Step: 204  | total loss: [1m[32m0.38450[0m[0m | time: 4.716s
[2K
| RMSProp | epoch: 023 | loss: 0.38450 - acc: 0.8327 -- iter: 192/288
[A[ATraining Step: 205  | total loss: [1m[32m0.37699[0m[0m | time: 5.334s
[2K
| RMSProp | epoch: 023 | loss: 0.37699 - acc: 0.8338 -- iter: 224/288
[A[ATraining Step: 206  | total loss: [1m[32m0.36023[0m[0m | time: 5.940s
[2K
| RMSProp | epoch: 023 | loss: 0.36023 - acc: 0.8442 -- iter: 256/288
[A[ATraining Step: 207  | total loss: [1m[32m0.35693[0m[0m | time: 7.658s
[2K
| RMSProp | epoch: 023 | loss: 0.35693 - acc: 0.8410 | val_loss: 0.28102 - val_acc: 0.9000 -- iter: 288/288
--
Training Step: 208  | total loss: [1m[32m0.35446[0m[0m | time: 0.610s
[2K
| RMSProp | epoch: 024 | loss: 0.35446 - acc: 0.8506 -- iter: 032/288
[A[ATraining Step: 209  | total loss: [1m[32m0.33834[0m[0m | time: 1.215s
[2K
| RMSProp | epoch: 024 | loss: 0.33834 - acc: 0.8625 -- iter: 064/288
[A[ATraining Step: 210  | total loss: [1m[32m0.33633[0m[0m | time: 1.830s
[2K
| RMSProp | epoch: 024 | loss: 0.33633 - acc: 0.8606 -- iter: 096/288
[A[ATraining Step: 211  | total loss: [1m[32m0.32674[0m[0m | time: 2.442s
[2K
| RMSProp | epoch: 024 | loss: 0.32674 - acc: 0.8652 -- iter: 128/288
[A[ATraining Step: 212  | total loss: [1m[32m0.32077[0m[0m | time: 3.039s
[2K
| RMSProp | epoch: 024 | loss: 0.32077 - acc: 0.8693 -- iter: 160/288
[A[ATraining Step: 213  | total loss: [1m[32m0.30743[0m[0m | time: 3.630s
[2K
| RMSProp | epoch: 024 | loss: 0.30743 - acc: 0.8730 -- iter: 192/288
[A[ATraining Step: 214  | total loss: [1m[32m0.29970[0m[0m | time: 4.248s
[2K
| RMSProp | epoch: 024 | loss: 0.29970 - acc: 0.8794 -- iter: 224/288
[A[ATraining Step: 215  | total loss: [1m[32m0.28854[0m[0m | time: 4.846s
[2K
| RMSProp | epoch: 024 | loss: 0.28854 - acc: 0.8852 -- iter: 256/288
[A[ATraining Step: 216  | total loss: [1m[32m0.28315[0m[0m | time: 6.459s
[2K
| RMSProp | epoch: 024 | loss: 0.28315 - acc: 0.8842 | val_loss: 0.40244 - val_acc: 0.8444 -- iter: 288/288
--
Training Step: 217  | total loss: [1m[32m0.30441[0m[0m | time: 0.610s
[2K
| RMSProp | epoch: 025 | loss: 0.30441 - acc: 0.8770 -- iter: 032/288
[A[ATraining Step: 218  | total loss: [1m[32m0.31306[0m[0m | time: 1.239s
[2K
| RMSProp | epoch: 025 | loss: 0.31306 - acc: 0.8737 -- iter: 064/288
[A[ATraining Step: 219  | total loss: [1m[32m0.30292[0m[0m | time: 1.850s
[2K
| RMSProp | epoch: 025 | loss: 0.30292 - acc: 0.8801 -- iter: 096/288
[A[ATraining Step: 220  | total loss: [1m[32m0.29318[0m[0m | time: 2.455s
[2K
| RMSProp | epoch: 025 | loss: 0.29318 - acc: 0.8827 -- iter: 128/288
[A[ATraining Step: 221  | total loss: [1m[32m0.28466[0m[0m | time: 3.174s
[2K
| RMSProp | epoch: 025 | loss: 0.28466 - acc: 0.8913 -- iter: 160/288
[A[ATraining Step: 222  | total loss: [1m[32m0.27095[0m[0m | time: 3.809s
[2K
| RMSProp | epoch: 025 | loss: 0.27095 - acc: 0.8959 -- iter: 192/288
[A[ATraining Step: 223  | total loss: [1m[32m0.25006[0m[0m | time: 4.410s
[2K
| RMSProp | epoch: 025 | loss: 0.25006 - acc: 0.9063 -- iter: 224/288
[A[ATraining Step: 224  | total loss: [1m[32m0.26438[0m[0m | time: 5.019s
[2K
| RMSProp | epoch: 025 | loss: 0.26438 - acc: 0.9032 -- iter: 256/288
[A[ATraining Step: 225  | total loss: [1m[32m0.25503[0m[0m | time: 6.672s
[2K
| RMSProp | epoch: 025 | loss: 0.25503 - acc: 0.9066 | val_loss: 0.18580 - val_acc: 0.9333 -- iter: 288/288
--
Training Step: 226  | total loss: [1m[32m0.24311[0m[0m | time: 0.687s
[2K
| RMSProp | epoch: 026 | loss: 0.24311 - acc: 0.9128 -- iter: 032/288
[A[ATraining Step: 227  | total loss: [1m[32m0.22512[0m[0m | time: 1.298s
[2K
| RMSProp | epoch: 026 | loss: 0.22512 - acc: 0.9184 -- iter: 064/288
[A[ATraining Step: 228  | total loss: [1m[32m0.22970[0m[0m | time: 1.923s
[2K
| RMSProp | epoch: 026 | loss: 0.22970 - acc: 0.9172 -- iter: 096/288
[A[ATraining Step: 229  | total loss: [1m[32m0.21683[0m[0m | time: 2.559s
[2K
| RMSProp | epoch: 026 | loss: 0.21683 - acc: 0.9192 -- iter: 128/288
[A[ATraining Step: 230  | total loss: [1m[32m0.20929[0m[0m | time: 3.161s
[2K
| RMSProp | epoch: 026 | loss: 0.20929 - acc: 0.9242 -- iter: 160/288
[A[ATraining Step: 231  | total loss: [1m[32m0.20685[0m[0m | time: 3.762s
[2K
| RMSProp | epoch: 026 | loss: 0.20685 - acc: 0.9255 -- iter: 192/288
[A[ATraining Step: 232  | total loss: [1m[32m0.20894[0m[0m | time: 4.349s
[2K
| RMSProp | epoch: 026 | loss: 0.20894 - acc: 0.9205 -- iter: 224/288
[A[ATraining Step: 233  | total loss: [1m[32m0.19527[0m[0m | time: 4.956s
[2K
| RMSProp | epoch: 026 | loss: 0.19527 - acc: 0.9253 -- iter: 256/288
[A[ATraining Step: 234  | total loss: [1m[32m0.19530[0m[0m | time: 6.576s
[2K
| RMSProp | epoch: 026 | loss: 0.19530 - acc: 0.9265 | val_loss: 0.16967 - val_acc: 0.9333 -- iter: 288/288
--
Training Step: 235  | total loss: [1m[32m0.18415[0m[0m | time: 0.603s
[2K
| RMSProp | epoch: 027 | loss: 0.18415 - acc: 0.9339 -- iter: 032/288
[A[ATraining Step: 236  | total loss: [1m[32m0.19339[0m[0m | time: 1.213s
[2K
| RMSProp | epoch: 027 | loss: 0.19339 - acc: 0.9311 -- iter: 064/288
[A[ATraining Step: 237  | total loss: [1m[32m0.19164[0m[0m | time: 1.826s
[2K
| RMSProp | epoch: 027 | loss: 0.19164 - acc: 0.9349 -- iter: 096/288
[A[ATraining Step: 238  | total loss: [1m[32m0.20201[0m[0m | time: 2.434s
[2K
| RMSProp | epoch: 027 | loss: 0.20201 - acc: 0.9320 -- iter: 128/288
[A[ATraining Step: 239  | total loss: [1m[32m0.19429[0m[0m | time: 3.036s
[2K
| RMSProp | epoch: 027 | loss: 0.19429 - acc: 0.9388 -- iter: 160/288
[A[ATraining Step: 240  | total loss: [1m[32m0.18338[0m[0m | time: 3.644s
[2K
| RMSProp | epoch: 027 | loss: 0.18338 - acc: 0.9418 -- iter: 192/288
[A[ATraining Step: 241  | total loss: [1m[32m0.17090[0m[0m | time: 4.260s
[2K
| RMSProp | epoch: 027 | loss: 0.17090 - acc: 0.9476 -- iter: 224/288
[A[ATraining Step: 242  | total loss: [1m[32m0.16175[0m[0m | time: 4.898s
[2K
| RMSProp | epoch: 027 | loss: 0.16175 - acc: 0.9497 -- iter: 256/288
[A[ATraining Step: 243  | total loss: [1m[32m0.15157[0m[0m | time: 6.525s
[2K
| RMSProp | epoch: 027 | loss: 0.15157 - acc: 0.9548 | val_loss: 0.46313 - val_acc: 0.8333 -- iter: 288/288
--
Training Step: 244  | total loss: [1m[32m0.14910[0m[0m | time: 0.603s
[2K
| RMSProp | epoch: 028 | loss: 0.14910 - acc: 0.9530 -- iter: 032/288
[A[ATraining Step: 245  | total loss: [1m[32m0.16581[0m[0m | time: 1.206s
[2K
| RMSProp | epoch: 028 | loss: 0.16581 - acc: 0.9421 -- iter: 064/288
[A[ATraining Step: 246  | total loss: [1m[32m0.20509[0m[0m | time: 1.799s
[2K
| RMSProp | epoch: 028 | loss: 0.20509 - acc: 0.9166 -- iter: 096/288
[A[ATraining Step: 247  | total loss: [1m[32m0.19860[0m[0m | time: 2.403s
[2K
| RMSProp | epoch: 028 | loss: 0.19860 - acc: 0.9219 -- iter: 128/288
[A[ATraining Step: 248  | total loss: [1m[32m0.20229[0m[0m | time: 2.997s
[2K
| RMSProp | epoch: 028 | loss: 0.20229 - acc: 0.9234 -- iter: 160/288
[A[ATraining Step: 249  | total loss: [1m[32m0.19031[0m[0m | time: 3.614s
[2K
| RMSProp | epoch: 028 | loss: 0.19031 - acc: 0.9311 -- iter: 192/288
[A[ATraining Step: 250  | total loss: [1m[32m0.17506[0m[0m | time: 4.216s
[2K
| RMSProp | epoch: 028 | loss: 0.17506 - acc: 0.9380 -- iter: 224/288
[A[ATraining Step: 251  | total loss: [1m[32m0.15955[0m[0m | time: 4.835s
[2K
| RMSProp | epoch: 028 | loss: 0.15955 - acc: 0.9442 -- iter: 256/288
[A[ATraining Step: 252  | total loss: [1m[32m0.14628[0m[0m | time: 6.452s
[2K
| RMSProp | epoch: 028 | loss: 0.14628 - acc: 0.9498 | val_loss: 0.20599 - val_acc: 0.9222 -- iter: 288/288
--
Training Step: 253  | total loss: [1m[32m0.13288[0m[0m | time: 0.617s
[2K
| RMSProp | epoch: 029 | loss: 0.13288 - acc: 0.9548 -- iter: 032/288
[A[ATraining Step: 254  | total loss: [1m[32m0.12520[0m[0m | time: 1.215s
[2K
| RMSProp | epoch: 029 | loss: 0.12520 - acc: 0.9531 -- iter: 064/288
[A[ATraining Step: 255  | total loss: [1m[32m0.13928[0m[0m | time: 1.814s
[2K
| RMSProp | epoch: 029 | loss: 0.13928 - acc: 0.9484 -- iter: 096/288
[A[ATraining Step: 256  | total loss: [1m[32m0.13108[0m[0m | time: 2.400s
[2K
| RMSProp | epoch: 029 | loss: 0.13108 - acc: 0.9535 -- iter: 128/288
[A[ATraining Step: 257  | total loss: [1m[32m0.12366[0m[0m | time: 3.072s
[2K
| RMSProp | epoch: 029 | loss: 0.12366 - acc: 0.9582 -- iter: 160/288
[A[ATraining Step: 258  | total loss: [1m[32m0.12288[0m[0m | time: 3.688s
[2K
| RMSProp | epoch: 029 | loss: 0.12288 - acc: 0.9592 -- iter: 192/288
[A[ATraining Step: 259  | total loss: [1m[32m0.11913[0m[0m | time: 4.291s
[2K
| RMSProp | epoch: 029 | loss: 0.11913 - acc: 0.9571 -- iter: 224/288
[A[ATraining Step: 260  | total loss: [1m[32m0.11714[0m[0m | time: 4.888s
[2K
| RMSProp | epoch: 029 | loss: 0.11714 - acc: 0.9582 -- iter: 256/288
[A[ATraining Step: 261  | total loss: [1m[32m0.10712[0m[0m | time: 6.497s
[2K
| RMSProp | epoch: 029 | loss: 0.10712 - acc: 0.9624 | val_loss: 0.20795 - val_acc: 0.9222 -- iter: 288/288
--
Training Step: 262  | total loss: [1m[32m0.09770[0m[0m | time: 0.598s
[2K
| RMSProp | epoch: 030 | loss: 0.09770 - acc: 0.9662 -- iter: 032/288
[A[ATraining Step: 263  | total loss: [1m[32m0.08996[0m[0m | time: 1.199s
[2K
| RMSProp | epoch: 030 | loss: 0.08996 - acc: 0.9696 -- iter: 064/288
[A[ATraining Step: 264  | total loss: [1m[32m0.08240[0m[0m | time: 1.813s
[2K
| RMSProp | epoch: 030 | loss: 0.08240 - acc: 0.9726 -- iter: 096/288
[A[ATraining Step: 265  | total loss: [1m[32m0.07498[0m[0m | time: 2.423s
[2K
| RMSProp | epoch: 030 | loss: 0.07498 - acc: 0.9753 -- iter: 128/288
[A[ATraining Step: 266  | total loss: [1m[32m0.06812[0m[0m | time: 3.032s
[2K
| RMSProp | epoch: 030 | loss: 0.06812 - acc: 0.9778 -- iter: 160/288
[A[ATraining Step: 267  | total loss: [1m[32m0.06313[0m[0m | time: 3.649s
[2K
| RMSProp | epoch: 030 | loss: 0.06313 - acc: 0.9800 -- iter: 192/288
[A[ATraining Step: 268  | total loss: [1m[32m0.09586[0m[0m | time: 4.253s
[2K
| RMSProp | epoch: 030 | loss: 0.09586 - acc: 0.9789 -- iter: 224/288
[A[ATraining Step: 269  | total loss: [1m[32m0.09328[0m[0m | time: 4.857s
[2K
| RMSProp | epoch: 030 | loss: 0.09328 - acc: 0.9810 -- iter: 256/288
[A[ATraining Step: 270  | total loss: [1m[32m0.08465[0m[0m | time: 6.458s
[2K
| RMSProp | epoch: 030 | loss: 0.08465 - acc: 0.9829 | val_loss: 0.25776 - val_acc: 0.9000 -- iter: 288/288
--
Validation AUC:0.9834087481146304
Validation AUPRC:0.9893205599385356
Test AUC:0.9980158730158729
Test AUPRC:0.9983163265306123
BestTestF1Score	0.98	0.96	0.98	1.0	0.96	46	0	42	2	0.99
BestTestMCCScore	0.98	0.96	0.98	1.0	0.96	46	0	42	2	0.99
BestTestAccuracyScore	0.98	0.96	0.98	1.0	0.96	46	0	42	2	0.99
BestValidationF1Score	0.95	0.89	0.94	1.0	0.9	46	0	39	5	0.99
BestValidationMCC	0.95	0.89	0.94	1.0	0.9	46	0	39	5	0.99
BestValidationAccuracy	0.95	0.89	0.94	1.0	0.9	46	0	39	5	0.99
TestPredictions (Threshold:0.99)
CHEMBL114074,TN,INACT,0.0	CHEMBL593443,TN,INACT,0.009999999776482582	CHEMBL130517,TP,ACT,1.0	CHEMBL325935,TN,INACT,0.0	CHEMBL1916635,TN,INACT,0.9700000286102295	CHEMBL515170,TN,INACT,0.0	CHEMBL3217072,TP,ACT,0.9900000095367432	CHEMBL1258999,TN,INACT,0.05999999865889549	CHEMBL131517,TP,ACT,1.0	CHEMBL40796,TN,INACT,0.009999999776482582	CHEMBL98458,TP,ACT,1.0	CHEMBL298612,TN,INACT,0.019999999552965164	CHEMBL539324,TP,ACT,0.9900000095367432	CHEMBL603858,TN,INACT,0.9800000190734863	CHEMBL555555,TP,ACT,1.0	CHEMBL1983100,TN,INACT,0.009999999776482582	CHEMBL342016,FN,ACT,0.9700000286102295	CHEMBL45875,TN,INACT,0.0	CHEMBL80532,TN,INACT,0.009999999776482582	CHEMBL288079,TP,ACT,1.0	CHEMBL241514,TN,INACT,0.0	CHEMBL320254,TN,INACT,0.0	CHEMBL113320,TP,ACT,1.0	CHEMBL311781,TN,INACT,0.009999999776482582	CHEMBL543657,TP,ACT,1.0	CHEMBL297473,TN,INACT,0.0	CHEMBL9666,TN,INACT,0.0	CHEMBL3633665,TN,INACT,0.0	CHEMBL342195,TP,ACT,1.0	CHEMBL543188,TP,ACT,1.0	CHEMBL324586,TN,INACT,0.0	CHEMBL1180343,TN,INACT,0.0	CHEMBL321644,TN,INACT,0.8799999952316284	CHEMBL394642,TN,INACT,0.27000001072883606	CHEMBL555556,TP,ACT,1.0	CHEMBL154558,TP,ACT,1.0	CHEMBL154823,TP,ACT,1.0	CHEMBL130452,TP,ACT,1.0	CHEMBL298463,TP,ACT,1.0	CHEMBL227429,TN,INACT,0.009999999776482582	CHEMBL330003,TN,INACT,0.07000000029802322	CHEMBL544135,TP,ACT,1.0	CHEMBL89203,TN,INACT,0.0	CHEMBL2391356,TN,INACT,0.03999999910593033	CHEMBL154682,TP,ACT,1.0	CHEMBL538732,TP,ACT,1.0	CHEMBL154188,TP,ACT,1.0	CHEMBL113169,TP,ACT,1.0	CHEMBL59597,TN,INACT,0.009999999776482582	CHEMBL559195,TP,ACT,1.0	CHEMBL3142595,TP,ACT,1.0	CHEMBL174463,TN,INACT,0.009999999776482582	CHEMBL357530,TP,ACT,1.0	CHEMBL453,TN,INACT,0.0	CHEMBL267094,TN,INACT,0.009999999776482582	CHEMBL540840,TP,ACT,1.0	CHEMBL153890,TP,ACT,1.0	CHEMBL309397,TN,INACT,0.0	CHEMBL43661,TN,INACT,0.5299999713897705	CHEMBL152158,TP,ACT,1.0	CHEMBL148967,TN,INACT,0.0	CHEMBL11629,TN,INACT,0.6299999952316284	CHEMBL553293,TP,ACT,1.0	CHEMBL98460,TP,ACT,1.0	CHEMBL154633,TP,ACT,1.0	CHEMBL544134,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.009999999776482582	CHEMBL89689,TN,INACT,0.0	CHEMBL424268,TP,ACT,1.0	CHEMBL142015,TP,ACT,1.0	CHEMBL461088,TN,INACT,0.009999999776482582	CHEMBL422794,TP,ACT,1.0	CHEMBL154122,TP,ACT,1.0	CHEMBL556816,TP,ACT,1.0	CHEMBL539800,TP,ACT,1.0	CHEMBL552986,TP,ACT,1.0	CHEMBL154130,FN,ACT,0.9599999785423279	CHEMBL329758,TP,ACT,1.0	CHEMBL44557,TP,ACT,1.0	CHEMBL333832,TP,ACT,1.0	CHEMBL295651,TN,INACT,0.5600000023841858	CHEMBL48031,TN,INACT,0.009999999776482582	CHEMBL346718,TP,ACT,0.9900000095367432	CHEMBL553155,TN,INACT,0.8899999856948853	CHEMBL544720,TP,ACT,1.0	CHEMBL553843,TP,ACT,1.0	CHEMBL542479,TP,ACT,1.0	CHEMBL430683,TN,INACT,0.0	CHEMBL319036,TN,INACT,0.029999999329447746	CHEMBL133339,TP,ACT,1.0	

