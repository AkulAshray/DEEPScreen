CNNModel CHEMBL2047 adam 0.001 15 32 0 0.8 False True
Number of active compounds :	500
Number of inactive compounds :	500
---------------------------------
Run id: CNNModel_CHEMBL2047_adam_0.001_15_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2047_adam_0.001_15_32_0.8_True/
---------------------------------
Training samples: 628
Validation samples: 197
--
Training Step: 1  | time: 0.779s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/628
[A[ATraining Step: 2  | total loss: [1m[32m0.62408[0m[0m | time: 1.371s
[2K
| Adam | epoch: 001 | loss: 0.62408 - acc: 0.3937 -- iter: 064/628
[A[ATraining Step: 3  | total loss: [1m[32m0.68261[0m[0m | time: 1.973s
[2K
| Adam | epoch: 001 | loss: 0.68261 - acc: 0.4295 -- iter: 096/628
[A[ATraining Step: 4  | total loss: [1m[32m0.68980[0m[0m | time: 2.569s
[2K
| Adam | epoch: 001 | loss: 0.68980 - acc: 0.5293 -- iter: 128/628
[A[ATraining Step: 5  | total loss: [1m[32m0.69171[0m[0m | time: 3.174s
[2K
| Adam | epoch: 001 | loss: 0.69171 - acc: 0.5306 -- iter: 160/628
[A[ATraining Step: 6  | total loss: [1m[32m0.69466[0m[0m | time: 3.793s
[2K
| Adam | epoch: 001 | loss: 0.69466 - acc: 0.4708 -- iter: 192/628
[A[ATraining Step: 7  | total loss: [1m[32m0.69369[0m[0m | time: 4.421s
[2K
| Adam | epoch: 001 | loss: 0.69369 - acc: 0.4883 -- iter: 224/628
[A[ATraining Step: 8  | total loss: [1m[32m0.69105[0m[0m | time: 5.074s
[2K
| Adam | epoch: 001 | loss: 0.69105 - acc: 0.5828 -- iter: 256/628
[A[ATraining Step: 9  | total loss: [1m[32m0.69104[0m[0m | time: 5.704s
[2K
| Adam | epoch: 001 | loss: 0.69104 - acc: 0.5720 -- iter: 288/628
[A[ATraining Step: 10  | total loss: [1m[32m0.69071[0m[0m | time: 6.313s
[2K
| Adam | epoch: 001 | loss: 0.69071 - acc: 0.5673 -- iter: 320/628
[A[ATraining Step: 11  | total loss: [1m[32m0.69100[0m[0m | time: 6.937s
[2K
| Adam | epoch: 001 | loss: 0.69100 - acc: 0.5502 -- iter: 352/628
[A[ATraining Step: 12  | total loss: [1m[32m0.68941[0m[0m | time: 7.552s
[2K
| Adam | epoch: 001 | loss: 0.68941 - acc: 0.5557 -- iter: 384/628
[A[ATraining Step: 13  | total loss: [1m[32m0.69537[0m[0m | time: 8.167s
[2K
| Adam | epoch: 001 | loss: 0.69537 - acc: 0.5185 -- iter: 416/628
[A[ATraining Step: 14  | total loss: [1m[32m0.70583[0m[0m | time: 8.776s
[2K
| Adam | epoch: 001 | loss: 0.70583 - acc: 0.4470 -- iter: 448/628
[A[ATraining Step: 15  | total loss: [1m[32m0.70241[0m[0m | time: 9.397s
[2K
| Adam | epoch: 001 | loss: 0.70241 - acc: 0.4555 -- iter: 480/628
[A[ATraining Step: 16  | total loss: [1m[32m0.69934[0m[0m | time: 10.008s
[2K
| Adam | epoch: 001 | loss: 0.69934 - acc: 0.4722 -- iter: 512/628
[A[ATraining Step: 17  | total loss: [1m[32m0.69717[0m[0m | time: 10.610s
[2K
| Adam | epoch: 001 | loss: 0.69717 - acc: 0.4822 -- iter: 544/628
[A[ATraining Step: 18  | total loss: [1m[32m0.69524[0m[0m | time: 11.222s
[2K
| Adam | epoch: 001 | loss: 0.69524 - acc: 0.4992 -- iter: 576/628
[A[ATraining Step: 19  | total loss: [1m[32m0.69465[0m[0m | time: 11.833s
[2K
| Adam | epoch: 001 | loss: 0.69465 - acc: 0.4995 -- iter: 608/628
[A[ATraining Step: 20  | total loss: [1m[32m0.69381[0m[0m | time: 13.244s
[2K
| Adam | epoch: 001 | loss: 0.69381 - acc: 0.5097 | val_loss: 0.69356 - val_acc: 0.4924 -- iter: 628/628
--
Training Step: 21  | total loss: [1m[32m0.69310[0m[0m | time: 0.402s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5222 -- iter: 032/628
[A[ATraining Step: 22  | total loss: [1m[32m0.69266[0m[0m | time: 1.009s
[2K
| Adam | epoch: 002 | loss: 0.69266 - acc: 0.5305 -- iter: 064/628
[A[ATraining Step: 23  | total loss: [1m[32m0.69221[0m[0m | time: 1.646s
[2K
| Adam | epoch: 002 | loss: 0.69221 - acc: 0.5398 -- iter: 096/628
[A[ATraining Step: 24  | total loss: [1m[32m0.69315[0m[0m | time: 2.245s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5110 -- iter: 128/628
[A[ATraining Step: 25  | total loss: [1m[32m0.69161[0m[0m | time: 2.853s
[2K
| Adam | epoch: 002 | loss: 0.69161 - acc: 0.5506 -- iter: 160/628
[A[ATraining Step: 26  | total loss: [1m[32m0.69374[0m[0m | time: 3.461s
[2K
| Adam | epoch: 002 | loss: 0.69374 - acc: 0.4959 -- iter: 192/628
[A[ATraining Step: 27  | total loss: [1m[32m0.69370[0m[0m | time: 4.077s
[2K
| Adam | epoch: 002 | loss: 0.69370 - acc: 0.4969 -- iter: 224/628
[A[ATraining Step: 28  | total loss: [1m[32m0.69269[0m[0m | time: 4.682s
[2K
| Adam | epoch: 002 | loss: 0.69269 - acc: 0.5211 -- iter: 256/628
[A[ATraining Step: 29  | total loss: [1m[32m0.69401[0m[0m | time: 5.286s
[2K
| Adam | epoch: 002 | loss: 0.69401 - acc: 0.4856 -- iter: 288/628
[A[ATraining Step: 30  | total loss: [1m[32m0.69308[0m[0m | time: 5.870s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5112 -- iter: 320/628
[A[ATraining Step: 31  | total loss: [1m[32m0.69259[0m[0m | time: 6.482s
[2K
| Adam | epoch: 002 | loss: 0.69259 - acc: 0.5230 -- iter: 352/628
[A[ATraining Step: 32  | total loss: [1m[32m0.69248[0m[0m | time: 7.081s
[2K
| Adam | epoch: 002 | loss: 0.69248 - acc: 0.5249 -- iter: 384/628
[A[ATraining Step: 33  | total loss: [1m[32m0.69209[0m[0m | time: 7.710s
[2K
| Adam | epoch: 002 | loss: 0.69209 - acc: 0.5331 -- iter: 416/628
[A[ATraining Step: 34  | total loss: [1m[32m0.69127[0m[0m | time: 8.325s
[2K
| Adam | epoch: 002 | loss: 0.69127 - acc: 0.5528 -- iter: 448/628
[A[ATraining Step: 35  | total loss: [1m[32m0.69259[0m[0m | time: 8.930s
[2K
| Adam | epoch: 002 | loss: 0.69259 - acc: 0.5222 -- iter: 480/628
[A[ATraining Step: 36  | total loss: [1m[32m0.69251[0m[0m | time: 9.532s
[2K
| Adam | epoch: 002 | loss: 0.69251 - acc: 0.5240 -- iter: 512/628
[A[ATraining Step: 37  | total loss: [1m[32m0.69357[0m[0m | time: 10.127s
[2K
| Adam | epoch: 002 | loss: 0.69357 - acc: 0.5005 -- iter: 544/628
[A[ATraining Step: 38  | total loss: [1m[32m0.69325[0m[0m | time: 10.726s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.5065 -- iter: 576/628
[A[ATraining Step: 39  | total loss: [1m[32m0.69194[0m[0m | time: 11.336s
[2K
| Adam | epoch: 002 | loss: 0.69194 - acc: 0.5352 -- iter: 608/628
[A[ATraining Step: 40  | total loss: [1m[32m0.69223[0m[0m | time: 12.943s
[2K
| Adam | epoch: 002 | loss: 0.69223 - acc: 0.5286 | val_loss: 0.69382 - val_acc: 0.4924 -- iter: 628/628
--
Training Step: 41  | total loss: [1m[32m0.69334[0m[0m | time: 0.384s
[2K
| Adam | epoch: 003 | loss: 0.69334 - acc: 0.5061 -- iter: 032/628
[A[ATraining Step: 42  | total loss: [1m[32m0.69336[0m[0m | time: 0.761s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.5050 -- iter: 064/628
[A[ATraining Step: 43  | total loss: [1m[32m0.69335[0m[0m | time: 1.367s
[2K
| Adam | epoch: 003 | loss: 0.69335 - acc: 0.5041 -- iter: 096/628
[A[ATraining Step: 44  | total loss: [1m[32m0.69421[0m[0m | time: 1.971s
[2K
| Adam | epoch: 003 | loss: 0.69421 - acc: 0.4872 -- iter: 128/628
[A[ATraining Step: 45  | total loss: [1m[32m0.69461[0m[0m | time: 2.595s
[2K
| Adam | epoch: 003 | loss: 0.69461 - acc: 0.4787 -- iter: 160/628
[A[ATraining Step: 46  | total loss: [1m[32m0.69419[0m[0m | time: 3.205s
[2K
| Adam | epoch: 003 | loss: 0.69419 - acc: 0.4875 -- iter: 192/628
[A[ATraining Step: 47  | total loss: [1m[32m0.69387[0m[0m | time: 3.808s
[2K
| Adam | epoch: 003 | loss: 0.69387 - acc: 0.4947 -- iter: 224/628
[A[ATraining Step: 48  | total loss: [1m[32m0.69381[0m[0m | time: 4.411s
[2K
| Adam | epoch: 003 | loss: 0.69381 - acc: 0.4955 -- iter: 256/628
[A[ATraining Step: 49  | total loss: [1m[32m0.69392[0m[0m | time: 5.014s
[2K
| Adam | epoch: 003 | loss: 0.69392 - acc: 0.4913 -- iter: 288/628
[A[ATraining Step: 50  | total loss: [1m[32m0.69331[0m[0m | time: 5.632s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.5072 -- iter: 320/628
[A[ATraining Step: 51  | total loss: [1m[32m0.69348[0m[0m | time: 6.226s
[2K
| Adam | epoch: 003 | loss: 0.69348 - acc: 0.5013 -- iter: 352/628
[A[ATraining Step: 52  | total loss: [1m[32m0.69381[0m[0m | time: 6.832s
[2K
| Adam | epoch: 003 | loss: 0.69381 - acc: 0.4918 -- iter: 384/628
[A[ATraining Step: 53  | total loss: [1m[32m0.69358[0m[0m | time: 7.447s
[2K
| Adam | epoch: 003 | loss: 0.69358 - acc: 0.4976 -- iter: 416/628
[A[ATraining Step: 54  | total loss: [1m[32m0.69336[0m[0m | time: 8.062s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.5025 -- iter: 448/628
[A[ATraining Step: 55  | total loss: [1m[32m0.69361[0m[0m | time: 8.660s
[2K
| Adam | epoch: 003 | loss: 0.69361 - acc: 0.4932 -- iter: 480/628
[A[ATraining Step: 56  | total loss: [1m[32m0.69367[0m[0m | time: 9.265s
[2K
| Adam | epoch: 003 | loss: 0.69367 - acc: 0.4897 -- iter: 512/628
[A[ATraining Step: 57  | total loss: [1m[32m0.69352[0m[0m | time: 9.881s
[2K
| Adam | epoch: 003 | loss: 0.69352 - acc: 0.4955 -- iter: 544/628
[A[ATraining Step: 58  | total loss: [1m[32m0.69340[0m[0m | time: 10.462s
[2K
| Adam | epoch: 003 | loss: 0.69340 - acc: 0.5004 -- iter: 576/628
[A[ATraining Step: 59  | total loss: [1m[32m0.69348[0m[0m | time: 11.055s
[2K
| Adam | epoch: 003 | loss: 0.69348 - acc: 0.4961 -- iter: 608/628
[A[ATraining Step: 60  | total loss: [1m[32m0.69297[0m[0m | time: 12.689s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5173 | val_loss: 0.69336 - val_acc: 0.4924 -- iter: 628/628
--
Training Step: 61  | total loss: [1m[32m0.69259[0m[0m | time: 0.591s
[2K
| Adam | epoch: 004 | loss: 0.69259 - acc: 0.5314 -- iter: 032/628
[A[ATraining Step: 62  | total loss: [1m[32m0.69308[0m[0m | time: 0.964s
[2K
| Adam | epoch: 004 | loss: 0.69308 - acc: 0.5113 -- iter: 064/628
[A[ATraining Step: 63  | total loss: [1m[32m0.69309[0m[0m | time: 1.367s
[2K
| Adam | epoch: 004 | loss: 0.69309 - acc: 0.5098 -- iter: 096/628
[A[ATraining Step: 64  | total loss: [1m[32m0.69309[0m[0m | time: 2.002s
[2K
| Adam | epoch: 004 | loss: 0.69309 - acc: 0.5086 -- iter: 128/628
[A[ATraining Step: 65  | total loss: [1m[32m0.69320[0m[0m | time: 2.594s
[2K
| Adam | epoch: 004 | loss: 0.69320 - acc: 0.5037 -- iter: 160/628
[A[ATraining Step: 66  | total loss: [1m[32m0.69299[0m[0m | time: 3.195s
[2K
| Adam | epoch: 004 | loss: 0.69299 - acc: 0.5108 -- iter: 192/628
[A[ATraining Step: 67  | total loss: [1m[32m0.69288[0m[0m | time: 3.796s
[2K
| Adam | epoch: 004 | loss: 0.69288 - acc: 0.5133 -- iter: 224/628
[A[ATraining Step: 68  | total loss: [1m[32m0.69278[0m[0m | time: 4.392s
[2K
| Adam | epoch: 004 | loss: 0.69278 - acc: 0.5154 -- iter: 256/628
[A[ATraining Step: 69  | total loss: [1m[32m0.69309[0m[0m | time: 5.001s
[2K
| Adam | epoch: 004 | loss: 0.69309 - acc: 0.5063 -- iter: 288/628
[A[ATraining Step: 70  | total loss: [1m[32m0.69245[0m[0m | time: 5.615s
[2K
| Adam | epoch: 004 | loss: 0.69245 - acc: 0.5200 -- iter: 320/628
[A[ATraining Step: 71  | total loss: [1m[32m0.69293[0m[0m | time: 6.258s
[2K
| Adam | epoch: 004 | loss: 0.69293 - acc: 0.5070 -- iter: 352/628
[A[ATraining Step: 72  | total loss: [1m[32m0.69314[0m[0m | time: 6.860s
[2K
| Adam | epoch: 004 | loss: 0.69314 - acc: 0.4992 -- iter: 384/628
[A[ATraining Step: 73  | total loss: [1m[32m0.69333[0m[0m | time: 7.472s
[2K
| Adam | epoch: 004 | loss: 0.69333 - acc: 0.4924 -- iter: 416/628
[A[ATraining Step: 74  | total loss: [1m[32m0.69318[0m[0m | time: 8.075s
[2K
| Adam | epoch: 004 | loss: 0.69318 - acc: 0.4932 -- iter: 448/628
[A[ATraining Step: 75  | total loss: [1m[32m0.69278[0m[0m | time: 8.687s
[2K
| Adam | epoch: 004 | loss: 0.69278 - acc: 0.5041 -- iter: 480/628
[A[ATraining Step: 76  | total loss: [1m[32m0.69267[0m[0m | time: 9.300s
[2K
| Adam | epoch: 004 | loss: 0.69267 - acc: 0.5037 -- iter: 512/628
[A[ATraining Step: 77  | total loss: [1m[32m0.69172[0m[0m | time: 9.940s
[2K
| Adam | epoch: 004 | loss: 0.69172 - acc: 0.5132 -- iter: 544/628
[A[ATraining Step: 78  | total loss: [1m[32m0.69175[0m[0m | time: 10.552s
[2K
| Adam | epoch: 004 | loss: 0.69175 - acc: 0.5118 -- iter: 576/628
[A[ATraining Step: 79  | total loss: [1m[32m0.69106[0m[0m | time: 11.164s
[2K
| Adam | epoch: 004 | loss: 0.69106 - acc: 0.5138 -- iter: 608/628
[A[ATraining Step: 80  | total loss: [1m[32m0.69403[0m[0m | time: 12.761s
[2K
| Adam | epoch: 004 | loss: 0.69403 - acc: 0.4964 | val_loss: 0.68646 - val_acc: 0.4924 -- iter: 628/628
--
Training Step: 81  | total loss: [1m[32m0.69382[0m[0m | time: 0.605s
[2K
| Adam | epoch: 005 | loss: 0.69382 - acc: 0.4936 -- iter: 032/628
[A[ATraining Step: 82  | total loss: [1m[32m0.69283[0m[0m | time: 1.219s
[2K
| Adam | epoch: 005 | loss: 0.69283 - acc: 0.5005 -- iter: 064/628
[A[ATraining Step: 83  | total loss: [1m[32m0.69272[0m[0m | time: 1.616s
[2K
| Adam | epoch: 005 | loss: 0.69272 - acc: 0.4911 -- iter: 096/628
[A[ATraining Step: 84  | total loss: [1m[32m0.69263[0m[0m | time: 2.023s
[2K
| Adam | epoch: 005 | loss: 0.69263 - acc: 0.4820 -- iter: 128/628
[A[ATraining Step: 85  | total loss: [1m[32m0.69256[0m[0m | time: 2.616s
[2K
| Adam | epoch: 005 | loss: 0.69256 - acc: 0.4738 -- iter: 160/628
[A[ATraining Step: 86  | total loss: [1m[32m0.69247[0m[0m | time: 3.207s
[2K
| Adam | epoch: 005 | loss: 0.69247 - acc: 0.4764 -- iter: 192/628
[A[ATraining Step: 87  | total loss: [1m[32m0.69206[0m[0m | time: 3.812s
[2K
| Adam | epoch: 005 | loss: 0.69206 - acc: 0.4819 -- iter: 224/628
[A[ATraining Step: 88  | total loss: [1m[32m0.69116[0m[0m | time: 4.411s
[2K
| Adam | epoch: 005 | loss: 0.69116 - acc: 0.4962 -- iter: 256/628
[A[ATraining Step: 89  | total loss: [1m[32m0.68964[0m[0m | time: 5.021s
[2K
| Adam | epoch: 005 | loss: 0.68964 - acc: 0.5153 -- iter: 288/628
[A[ATraining Step: 90  | total loss: [1m[32m0.69076[0m[0m | time: 5.611s
[2K
| Adam | epoch: 005 | loss: 0.69076 - acc: 0.5013 -- iter: 320/628
[A[ATraining Step: 91  | total loss: [1m[32m0.68962[0m[0m | time: 6.226s
[2K
| Adam | epoch: 005 | loss: 0.68962 - acc: 0.5074 -- iter: 352/628
[A[ATraining Step: 92  | total loss: [1m[32m0.68811[0m[0m | time: 6.817s
[2K
| Adam | epoch: 005 | loss: 0.68811 - acc: 0.5067 -- iter: 384/628
[A[ATraining Step: 93  | total loss: [1m[32m0.68798[0m[0m | time: 7.417s
[2K
| Adam | epoch: 005 | loss: 0.68798 - acc: 0.5060 -- iter: 416/628
[A[ATraining Step: 94  | total loss: [1m[32m0.68413[0m[0m | time: 8.021s
[2K
| Adam | epoch: 005 | loss: 0.68413 - acc: 0.5148 -- iter: 448/628
[A[ATraining Step: 95  | total loss: [1m[32m0.68280[0m[0m | time: 8.640s
[2K
| Adam | epoch: 005 | loss: 0.68280 - acc: 0.5164 -- iter: 480/628
[A[ATraining Step: 96  | total loss: [1m[32m0.67822[0m[0m | time: 9.246s
[2K
| Adam | epoch: 005 | loss: 0.67822 - acc: 0.5242 -- iter: 512/628
[A[ATraining Step: 97  | total loss: [1m[32m0.68030[0m[0m | time: 9.843s
[2K
| Adam | epoch: 005 | loss: 0.68030 - acc: 0.5124 -- iter: 544/628
[A[ATraining Step: 98  | total loss: [1m[32m0.67611[0m[0m | time: 10.433s
[2K
| Adam | epoch: 005 | loss: 0.67611 - acc: 0.5518 -- iter: 576/628
[A[ATraining Step: 99  | total loss: [1m[32m0.67290[0m[0m | time: 11.035s
[2K
| Adam | epoch: 005 | loss: 0.67290 - acc: 0.5591 -- iter: 608/628
[A[ATraining Step: 100  | total loss: [1m[32m0.66911[0m[0m | time: 12.642s
[2K
| Adam | epoch: 005 | loss: 0.66911 - acc: 0.5751 | val_loss: 0.64483 - val_acc: 0.5990 -- iter: 628/628
--
Training Step: 101  | total loss: [1m[32m0.66332[0m[0m | time: 0.606s
[2K
| Adam | epoch: 006 | loss: 0.66332 - acc: 0.5832 -- iter: 032/628
[A[ATraining Step: 102  | total loss: [1m[32m0.66072[0m[0m | time: 1.210s
[2K
| Adam | epoch: 006 | loss: 0.66072 - acc: 0.5717 -- iter: 064/628
[A[ATraining Step: 103  | total loss: [1m[32m0.65292[0m[0m | time: 1.816s
[2K
| Adam | epoch: 006 | loss: 0.65292 - acc: 0.5989 -- iter: 096/628
[A[ATraining Step: 104  | total loss: [1m[32m0.64586[0m[0m | time: 2.202s
[2K
| Adam | epoch: 006 | loss: 0.64586 - acc: 0.6047 -- iter: 128/628
[A[ATraining Step: 105  | total loss: [1m[32m0.64428[0m[0m | time: 2.583s
[2K
| Adam | epoch: 006 | loss: 0.64428 - acc: 0.5942 -- iter: 160/628
[A[ATraining Step: 106  | total loss: [1m[32m0.64317[0m[0m | time: 3.177s
[2K
| Adam | epoch: 006 | loss: 0.64317 - acc: 0.5848 -- iter: 192/628
[A[ATraining Step: 107  | total loss: [1m[32m0.63946[0m[0m | time: 3.778s
[2K
| Adam | epoch: 006 | loss: 0.63946 - acc: 0.6013 -- iter: 224/628
[A[ATraining Step: 108  | total loss: [1m[32m0.63983[0m[0m | time: 4.382s
[2K
| Adam | epoch: 006 | loss: 0.63983 - acc: 0.6068 -- iter: 256/628
[A[ATraining Step: 109  | total loss: [1m[32m0.64067[0m[0m | time: 5.017s
[2K
| Adam | epoch: 006 | loss: 0.64067 - acc: 0.6117 -- iter: 288/628
[A[ATraining Step: 110  | total loss: [1m[32m0.64648[0m[0m | time: 5.609s
[2K
| Adam | epoch: 006 | loss: 0.64648 - acc: 0.6037 -- iter: 320/628
[A[ATraining Step: 111  | total loss: [1m[32m0.64069[0m[0m | time: 6.235s
[2K
| Adam | epoch: 006 | loss: 0.64069 - acc: 0.6152 -- iter: 352/628
[A[ATraining Step: 112  | total loss: [1m[32m0.64042[0m[0m | time: 6.840s
[2K
| Adam | epoch: 006 | loss: 0.64042 - acc: 0.6256 -- iter: 384/628
[A[ATraining Step: 113  | total loss: [1m[32m0.64032[0m[0m | time: 7.432s
[2K
| Adam | epoch: 006 | loss: 0.64032 - acc: 0.6224 -- iter: 416/628
[A[ATraining Step: 114  | total loss: [1m[32m0.62448[0m[0m | time: 8.041s
[2K
| Adam | epoch: 006 | loss: 0.62448 - acc: 0.6445 -- iter: 448/628
[A[ATraining Step: 115  | total loss: [1m[32m0.61921[0m[0m | time: 8.650s
[2K
| Adam | epoch: 006 | loss: 0.61921 - acc: 0.6519 -- iter: 480/628
[A[ATraining Step: 116  | total loss: [1m[32m0.60956[0m[0m | time: 9.244s
[2K
| Adam | epoch: 006 | loss: 0.60956 - acc: 0.6649 -- iter: 512/628
[A[ATraining Step: 117  | total loss: [1m[32m0.59428[0m[0m | time: 9.840s
[2K
| Adam | epoch: 006 | loss: 0.59428 - acc: 0.6796 -- iter: 544/628
[A[ATraining Step: 118  | total loss: [1m[32m0.57129[0m[0m | time: 10.441s
[2K
| Adam | epoch: 006 | loss: 0.57129 - acc: 0.7023 -- iter: 576/628
[A[ATraining Step: 119  | total loss: [1m[32m0.58247[0m[0m | time: 11.053s
[2K
| Adam | epoch: 006 | loss: 0.58247 - acc: 0.6977 -- iter: 608/628
[A[ATraining Step: 120  | total loss: [1m[32m0.57395[0m[0m | time: 12.680s
[2K
| Adam | epoch: 006 | loss: 0.57395 - acc: 0.7060 | val_loss: 0.65122 - val_acc: 0.6599 -- iter: 628/628
--
Training Step: 121  | total loss: [1m[32m0.58232[0m[0m | time: 0.616s
[2K
| Adam | epoch: 007 | loss: 0.58232 - acc: 0.6979 -- iter: 032/628
[A[ATraining Step: 122  | total loss: [1m[32m0.61928[0m[0m | time: 1.210s
[2K
| Adam | epoch: 007 | loss: 0.61928 - acc: 0.6719 -- iter: 064/628
[A[ATraining Step: 123  | total loss: [1m[32m0.61971[0m[0m | time: 1.826s
[2K
| Adam | epoch: 007 | loss: 0.61971 - acc: 0.6703 -- iter: 096/628
[A[ATraining Step: 124  | total loss: [1m[32m0.61531[0m[0m | time: 2.408s
[2K
| Adam | epoch: 007 | loss: 0.61531 - acc: 0.6689 -- iter: 128/628
[A[ATraining Step: 125  | total loss: [1m[32m0.63329[0m[0m | time: 2.793s
[2K
| Adam | epoch: 007 | loss: 0.63329 - acc: 0.6583 -- iter: 160/628
[A[ATraining Step: 126  | total loss: [1m[32m0.65255[0m[0m | time: 3.190s
[2K
| Adam | epoch: 007 | loss: 0.65255 - acc: 0.6475 -- iter: 192/628
[A[ATraining Step: 127  | total loss: [1m[32m0.65171[0m[0m | time: 3.791s
[2K
| Adam | epoch: 007 | loss: 0.65171 - acc: 0.6427 -- iter: 224/628
[A[ATraining Step: 128  | total loss: [1m[32m0.63507[0m[0m | time: 4.411s
[2K
| Adam | epoch: 007 | loss: 0.63507 - acc: 0.6597 -- iter: 256/628
[A[ATraining Step: 129  | total loss: [1m[32m0.61771[0m[0m | time: 5.016s
[2K
| Adam | epoch: 007 | loss: 0.61771 - acc: 0.6750 -- iter: 288/628
[A[ATraining Step: 130  | total loss: [1m[32m0.61906[0m[0m | time: 5.631s
[2K
| Adam | epoch: 007 | loss: 0.61906 - acc: 0.6700 -- iter: 320/628
[A[ATraining Step: 131  | total loss: [1m[32m0.61799[0m[0m | time: 6.222s
[2K
| Adam | epoch: 007 | loss: 0.61799 - acc: 0.6717 -- iter: 352/628
[A[ATraining Step: 132  | total loss: [1m[32m0.60993[0m[0m | time: 6.819s
[2K
| Adam | epoch: 007 | loss: 0.60993 - acc: 0.6733 -- iter: 384/628
[A[ATraining Step: 133  | total loss: [1m[32m0.60015[0m[0m | time: 7.420s
[2K
| Adam | epoch: 007 | loss: 0.60015 - acc: 0.6872 -- iter: 416/628
[A[ATraining Step: 134  | total loss: [1m[32m0.58418[0m[0m | time: 8.064s
[2K
| Adam | epoch: 007 | loss: 0.58418 - acc: 0.7029 -- iter: 448/628
[A[ATraining Step: 135  | total loss: [1m[32m0.57468[0m[0m | time: 8.669s
[2K
| Adam | epoch: 007 | loss: 0.57468 - acc: 0.7107 -- iter: 480/628
[A[ATraining Step: 136  | total loss: [1m[32m0.57869[0m[0m | time: 9.278s
[2K
| Adam | epoch: 007 | loss: 0.57869 - acc: 0.7178 -- iter: 512/628
[A[ATraining Step: 137  | total loss: [1m[32m0.56889[0m[0m | time: 9.911s
[2K
| Adam | epoch: 007 | loss: 0.56889 - acc: 0.7241 -- iter: 544/628
[A[ATraining Step: 138  | total loss: [1m[32m0.55797[0m[0m | time: 10.530s
[2K
| Adam | epoch: 007 | loss: 0.55797 - acc: 0.7330 -- iter: 576/628
[A[ATraining Step: 139  | total loss: [1m[32m0.55141[0m[0m | time: 11.136s
[2K
| Adam | epoch: 007 | loss: 0.55141 - acc: 0.7347 -- iter: 608/628
[A[ATraining Step: 140  | total loss: [1m[32m0.54383[0m[0m | time: 12.751s
[2K
| Adam | epoch: 007 | loss: 0.54383 - acc: 0.7393 | val_loss: 0.44199 - val_acc: 0.8020 -- iter: 628/628
--
Training Step: 141  | total loss: [1m[32m0.53411[0m[0m | time: 0.611s
[2K
| Adam | epoch: 008 | loss: 0.53411 - acc: 0.7498 -- iter: 032/628
[A[ATraining Step: 142  | total loss: [1m[32m0.53331[0m[0m | time: 1.205s
[2K
| Adam | epoch: 008 | loss: 0.53331 - acc: 0.7529 -- iter: 064/628
[A[ATraining Step: 143  | total loss: [1m[32m0.52285[0m[0m | time: 1.816s
[2K
| Adam | epoch: 008 | loss: 0.52285 - acc: 0.7651 -- iter: 096/628
[A[ATraining Step: 144  | total loss: [1m[32m0.51293[0m[0m | time: 2.443s
[2K
| Adam | epoch: 008 | loss: 0.51293 - acc: 0.7761 -- iter: 128/628
[A[ATraining Step: 145  | total loss: [1m[32m0.52205[0m[0m | time: 3.039s
[2K
| Adam | epoch: 008 | loss: 0.52205 - acc: 0.7641 -- iter: 160/628
[A[ATraining Step: 146  | total loss: [1m[32m0.56277[0m[0m | time: 3.424s
[2K
| Adam | epoch: 008 | loss: 0.56277 - acc: 0.7346 -- iter: 192/628
[A[ATraining Step: 147  | total loss: [1m[32m0.57861[0m[0m | time: 3.800s
[2K
| Adam | epoch: 008 | loss: 0.57861 - acc: 0.7261 -- iter: 224/628
[A[ATraining Step: 148  | total loss: [1m[32m0.58685[0m[0m | time: 4.397s
[2K
| Adam | epoch: 008 | loss: 0.58685 - acc: 0.7135 -- iter: 256/628
[A[ATraining Step: 149  | total loss: [1m[32m0.57597[0m[0m | time: 4.992s
[2K
| Adam | epoch: 008 | loss: 0.57597 - acc: 0.7172 -- iter: 288/628
[A[ATraining Step: 150  | total loss: [1m[32m0.56650[0m[0m | time: 5.602s
[2K
| Adam | epoch: 008 | loss: 0.56650 - acc: 0.7236 -- iter: 320/628
[A[ATraining Step: 151  | total loss: [1m[32m0.58120[0m[0m | time: 6.191s
[2K
| Adam | epoch: 008 | loss: 0.58120 - acc: 0.7075 -- iter: 352/628
[A[ATraining Step: 152  | total loss: [1m[32m0.57108[0m[0m | time: 6.793s
[2K
| Adam | epoch: 008 | loss: 0.57108 - acc: 0.7117 -- iter: 384/628
[A[ATraining Step: 153  | total loss: [1m[32m0.55737[0m[0m | time: 7.391s
[2K
| Adam | epoch: 008 | loss: 0.55737 - acc: 0.7249 -- iter: 416/628
[A[ATraining Step: 154  | total loss: [1m[32m0.55151[0m[0m | time: 7.988s
[2K
| Adam | epoch: 008 | loss: 0.55151 - acc: 0.7337 -- iter: 448/628
[A[ATraining Step: 155  | total loss: [1m[32m0.54232[0m[0m | time: 8.581s
[2K
| Adam | epoch: 008 | loss: 0.54232 - acc: 0.7384 -- iter: 480/628
[A[ATraining Step: 156  | total loss: [1m[32m0.52712[0m[0m | time: 9.185s
[2K
| Adam | epoch: 008 | loss: 0.52712 - acc: 0.7458 -- iter: 512/628
[A[ATraining Step: 157  | total loss: [1m[32m0.52556[0m[0m | time: 9.782s
[2K
| Adam | epoch: 008 | loss: 0.52556 - acc: 0.7525 -- iter: 544/628
[A[ATraining Step: 158  | total loss: [1m[32m0.51352[0m[0m | time: 10.392s
[2K
| Adam | epoch: 008 | loss: 0.51352 - acc: 0.7616 -- iter: 576/628
[A[ATraining Step: 159  | total loss: [1m[32m0.49957[0m[0m | time: 10.987s
[2K
| Adam | epoch: 008 | loss: 0.49957 - acc: 0.7761 -- iter: 608/628
[A[ATraining Step: 160  | total loss: [1m[32m0.50268[0m[0m | time: 12.593s
[2K
| Adam | epoch: 008 | loss: 0.50268 - acc: 0.7704 | val_loss: 0.39393 - val_acc: 0.8426 -- iter: 628/628
--
Training Step: 161  | total loss: [1m[32m0.49107[0m[0m | time: 0.630s
[2K
| Adam | epoch: 009 | loss: 0.49107 - acc: 0.7808 -- iter: 032/628
[A[ATraining Step: 162  | total loss: [1m[32m0.48561[0m[0m | time: 1.236s
[2K
| Adam | epoch: 009 | loss: 0.48561 - acc: 0.7871 -- iter: 064/628
[A[ATraining Step: 163  | total loss: [1m[32m0.47609[0m[0m | time: 1.836s
[2K
| Adam | epoch: 009 | loss: 0.47609 - acc: 0.7928 -- iter: 096/628
[A[ATraining Step: 164  | total loss: [1m[32m0.46866[0m[0m | time: 2.455s
[2K
| Adam | epoch: 009 | loss: 0.46866 - acc: 0.7916 -- iter: 128/628
[A[ATraining Step: 165  | total loss: [1m[32m0.46673[0m[0m | time: 3.046s
[2K
| Adam | epoch: 009 | loss: 0.46673 - acc: 0.7906 -- iter: 160/628
[A[ATraining Step: 166  | total loss: [1m[32m0.46895[0m[0m | time: 3.643s
[2K
| Adam | epoch: 009 | loss: 0.46895 - acc: 0.7928 -- iter: 192/628
[A[ATraining Step: 167  | total loss: [1m[32m0.46099[0m[0m | time: 4.032s
[2K
| Adam | epoch: 009 | loss: 0.46099 - acc: 0.7948 -- iter: 224/628
[A[ATraining Step: 168  | total loss: [1m[32m0.45530[0m[0m | time: 4.418s
[2K
| Adam | epoch: 009 | loss: 0.45530 - acc: 0.7953 -- iter: 256/628
[A[ATraining Step: 169  | total loss: [1m[32m0.45071[0m[0m | time: 5.015s
[2K
| Adam | epoch: 009 | loss: 0.45071 - acc: 0.8007 -- iter: 288/628
[A[ATraining Step: 170  | total loss: [1m[32m0.43425[0m[0m | time: 5.608s
[2K
| Adam | epoch: 009 | loss: 0.43425 - acc: 0.8144 -- iter: 320/628
[A[ATraining Step: 171  | total loss: [1m[32m0.44153[0m[0m | time: 6.209s
[2K
| Adam | epoch: 009 | loss: 0.44153 - acc: 0.8080 -- iter: 352/628
[A[ATraining Step: 172  | total loss: [1m[32m0.44947[0m[0m | time: 6.793s
[2K
| Adam | epoch: 009 | loss: 0.44947 - acc: 0.8022 -- iter: 384/628
[A[ATraining Step: 173  | total loss: [1m[32m0.44971[0m[0m | time: 7.389s
[2K
| Adam | epoch: 009 | loss: 0.44971 - acc: 0.8001 -- iter: 416/628
[A[ATraining Step: 174  | total loss: [1m[32m0.42738[0m[0m | time: 7.982s
[2K
| Adam | epoch: 009 | loss: 0.42738 - acc: 0.8107 -- iter: 448/628
[A[ATraining Step: 175  | total loss: [1m[32m0.43906[0m[0m | time: 8.570s
[2K
| Adam | epoch: 009 | loss: 0.43906 - acc: 0.7953 -- iter: 480/628
[A[ATraining Step: 176  | total loss: [1m[32m0.42965[0m[0m | time: 9.166s
[2K
| Adam | epoch: 009 | loss: 0.42965 - acc: 0.7970 -- iter: 512/628
[A[ATraining Step: 177  | total loss: [1m[32m0.42446[0m[0m | time: 9.763s
[2K
| Adam | epoch: 009 | loss: 0.42446 - acc: 0.8017 -- iter: 544/628
[A[ATraining Step: 178  | total loss: [1m[32m0.42851[0m[0m | time: 10.391s
[2K
| Adam | epoch: 009 | loss: 0.42851 - acc: 0.8059 -- iter: 576/628
[A[ATraining Step: 179  | total loss: [1m[32m0.40758[0m[0m | time: 10.974s
[2K
| Adam | epoch: 009 | loss: 0.40758 - acc: 0.8222 -- iter: 608/628
[A[ATraining Step: 180  | total loss: [1m[32m0.39299[0m[0m | time: 12.577s
[2K
| Adam | epoch: 009 | loss: 0.39299 - acc: 0.8306 | val_loss: 0.36008 - val_acc: 0.8376 -- iter: 628/628
--
Training Step: 181  | total loss: [1m[32m0.41073[0m[0m | time: 0.617s
[2K
| Adam | epoch: 010 | loss: 0.41073 - acc: 0.8194 -- iter: 032/628
[A[ATraining Step: 182  | total loss: [1m[32m0.39934[0m[0m | time: 1.219s
[2K
| Adam | epoch: 010 | loss: 0.39934 - acc: 0.8218 -- iter: 064/628
[A[ATraining Step: 183  | total loss: [1m[32m0.39239[0m[0m | time: 1.839s
[2K
| Adam | epoch: 010 | loss: 0.39239 - acc: 0.8334 -- iter: 096/628
[A[ATraining Step: 184  | total loss: [1m[32m0.39134[0m[0m | time: 2.445s
[2K
| Adam | epoch: 010 | loss: 0.39134 - acc: 0.8376 -- iter: 128/628
[A[ATraining Step: 185  | total loss: [1m[32m0.37561[0m[0m | time: 3.061s
[2K
| Adam | epoch: 010 | loss: 0.37561 - acc: 0.8507 -- iter: 160/628
[A[ATraining Step: 186  | total loss: [1m[32m0.37246[0m[0m | time: 3.655s
[2K
| Adam | epoch: 010 | loss: 0.37246 - acc: 0.8562 -- iter: 192/628
[A[ATraining Step: 187  | total loss: [1m[32m0.38796[0m[0m | time: 4.257s
[2K
| Adam | epoch: 010 | loss: 0.38796 - acc: 0.8519 -- iter: 224/628
[A[ATraining Step: 188  | total loss: [1m[32m0.36226[0m[0m | time: 4.653s
[2K
| Adam | epoch: 010 | loss: 0.36226 - acc: 0.8635 -- iter: 256/628
[A[ATraining Step: 189  | total loss: [1m[32m0.35704[0m[0m | time: 5.047s
[2K
| Adam | epoch: 010 | loss: 0.35704 - acc: 0.8672 -- iter: 288/628
[A[ATraining Step: 190  | total loss: [1m[32m0.34969[0m[0m | time: 5.644s
[2K
| Adam | epoch: 010 | loss: 0.34969 - acc: 0.8705 -- iter: 320/628
[A[ATraining Step: 191  | total loss: [1m[32m0.34891[0m[0m | time: 6.257s
[2K
| Adam | epoch: 010 | loss: 0.34891 - acc: 0.8709 -- iter: 352/628
[A[ATraining Step: 192  | total loss: [1m[32m0.34244[0m[0m | time: 6.857s
[2K
| Adam | epoch: 010 | loss: 0.34244 - acc: 0.8745 -- iter: 384/628
[A[ATraining Step: 193  | total loss: [1m[32m0.35773[0m[0m | time: 7.458s
[2K
| Adam | epoch: 010 | loss: 0.35773 - acc: 0.8683 -- iter: 416/628
[A[ATraining Step: 194  | total loss: [1m[32m0.36527[0m[0m | time: 8.058s
[2K
| Adam | epoch: 010 | loss: 0.36527 - acc: 0.8658 -- iter: 448/628
[A[ATraining Step: 195  | total loss: [1m[32m0.36003[0m[0m | time: 8.656s
[2K
| Adam | epoch: 010 | loss: 0.36003 - acc: 0.8699 -- iter: 480/628
[A[ATraining Step: 196  | total loss: [1m[32m0.34698[0m[0m | time: 9.266s
[2K
| Adam | epoch: 010 | loss: 0.34698 - acc: 0.8797 -- iter: 512/628
[A[ATraining Step: 197  | total loss: [1m[32m0.36805[0m[0m | time: 9.884s
[2K
| Adam | epoch: 010 | loss: 0.36805 - acc: 0.8699 -- iter: 544/628
[A[ATraining Step: 198  | total loss: [1m[32m0.37289[0m[0m | time: 10.482s
[2K
| Adam | epoch: 010 | loss: 0.37289 - acc: 0.8642 -- iter: 576/628
[A[ATraining Step: 199  | total loss: [1m[32m0.37143[0m[0m | time: 11.078s
[2K
| Adam | epoch: 010 | loss: 0.37143 - acc: 0.8652 -- iter: 608/628
[A[ATraining Step: 200  | total loss: [1m[32m0.34733[0m[0m | time: 12.718s
[2K
| Adam | epoch: 010 | loss: 0.34733 - acc: 0.8787 | val_loss: 0.38682 - val_acc: 0.8274 -- iter: 628/628
--
Training Step: 201  | total loss: [1m[32m0.34879[0m[0m | time: 0.618s
[2K
| Adam | epoch: 011 | loss: 0.34879 - acc: 0.8752 -- iter: 032/628
[A[ATraining Step: 202  | total loss: [1m[32m0.34405[0m[0m | time: 1.228s
[2K
| Adam | epoch: 011 | loss: 0.34405 - acc: 0.8752 -- iter: 064/628
[A[ATraining Step: 203  | total loss: [1m[32m0.34685[0m[0m | time: 1.817s
[2K
| Adam | epoch: 011 | loss: 0.34685 - acc: 0.8752 -- iter: 096/628
[A[ATraining Step: 204  | total loss: [1m[32m0.33551[0m[0m | time: 2.437s
[2K
| Adam | epoch: 011 | loss: 0.33551 - acc: 0.8783 -- iter: 128/628
[A[ATraining Step: 205  | total loss: [1m[32m0.34410[0m[0m | time: 3.054s
[2K
| Adam | epoch: 011 | loss: 0.34410 - acc: 0.8748 -- iter: 160/628
[A[ATraining Step: 206  | total loss: [1m[32m0.34623[0m[0m | time: 3.670s
[2K
| Adam | epoch: 011 | loss: 0.34623 - acc: 0.8748 -- iter: 192/628
[A[ATraining Step: 207  | total loss: [1m[32m0.33938[0m[0m | time: 4.302s
[2K
| Adam | epoch: 011 | loss: 0.33938 - acc: 0.8780 -- iter: 224/628
[A[ATraining Step: 208  | total loss: [1m[32m0.34640[0m[0m | time: 4.901s
[2K
| Adam | epoch: 011 | loss: 0.34640 - acc: 0.8714 -- iter: 256/628
[A[ATraining Step: 209  | total loss: [1m[32m0.34934[0m[0m | time: 5.281s
[2K
| Adam | epoch: 011 | loss: 0.34934 - acc: 0.8624 -- iter: 288/628
[A[ATraining Step: 210  | total loss: [1m[32m0.33358[0m[0m | time: 5.664s
[2K
| Adam | epoch: 011 | loss: 0.33358 - acc: 0.8662 -- iter: 320/628
[A[ATraining Step: 211  | total loss: [1m[32m0.31687[0m[0m | time: 6.261s
[2K
| Adam | epoch: 011 | loss: 0.31687 - acc: 0.8796 -- iter: 352/628
[A[ATraining Step: 212  | total loss: [1m[32m0.32320[0m[0m | time: 6.848s
[2K
| Adam | epoch: 011 | loss: 0.32320 - acc: 0.8791 -- iter: 384/628
[A[ATraining Step: 213  | total loss: [1m[32m0.33152[0m[0m | time: 7.459s
[2K
| Adam | epoch: 011 | loss: 0.33152 - acc: 0.8756 -- iter: 416/628
[A[ATraining Step: 214  | total loss: [1m[32m0.32509[0m[0m | time: 8.071s
[2K
| Adam | epoch: 011 | loss: 0.32509 - acc: 0.8786 -- iter: 448/628
[A[ATraining Step: 215  | total loss: [1m[32m0.32311[0m[0m | time: 8.667s
[2K
| Adam | epoch: 011 | loss: 0.32311 - acc: 0.8814 -- iter: 480/628
[A[ATraining Step: 216  | total loss: [1m[32m0.33241[0m[0m | time: 9.289s
[2K
| Adam | epoch: 011 | loss: 0.33241 - acc: 0.8714 -- iter: 512/628
[A[ATraining Step: 217  | total loss: [1m[32m0.32795[0m[0m | time: 9.903s
[2K
| Adam | epoch: 011 | loss: 0.32795 - acc: 0.8749 -- iter: 544/628
[A[ATraining Step: 218  | total loss: [1m[32m0.33634[0m[0m | time: 10.499s
[2K
| Adam | epoch: 011 | loss: 0.33634 - acc: 0.8780 -- iter: 576/628
[A[ATraining Step: 219  | total loss: [1m[32m0.32037[0m[0m | time: 11.090s
[2K
| Adam | epoch: 011 | loss: 0.32037 - acc: 0.8840 -- iter: 608/628
[A[ATraining Step: 220  | total loss: [1m[32m0.34401[0m[0m | time: 12.679s
[2K
| Adam | epoch: 011 | loss: 0.34401 - acc: 0.8737 | val_loss: 0.31724 - val_acc: 0.8680 -- iter: 628/628
--
Training Step: 221  | total loss: [1m[32m0.33412[0m[0m | time: 0.605s
[2K
| Adam | epoch: 012 | loss: 0.33412 - acc: 0.8801 -- iter: 032/628
[A[ATraining Step: 222  | total loss: [1m[32m0.32598[0m[0m | time: 1.209s
[2K
| Adam | epoch: 012 | loss: 0.32598 - acc: 0.8827 -- iter: 064/628
[A[ATraining Step: 223  | total loss: [1m[32m0.32849[0m[0m | time: 1.817s
[2K
| Adam | epoch: 012 | loss: 0.32849 - acc: 0.8819 -- iter: 096/628
[A[ATraining Step: 224  | total loss: [1m[32m0.32442[0m[0m | time: 2.426s
[2K
| Adam | epoch: 012 | loss: 0.32442 - acc: 0.8812 -- iter: 128/628
[A[ATraining Step: 225  | total loss: [1m[32m0.30893[0m[0m | time: 3.035s
[2K
| Adam | epoch: 012 | loss: 0.30893 - acc: 0.8869 -- iter: 160/628
[A[ATraining Step: 226  | total loss: [1m[32m0.31058[0m[0m | time: 3.635s
[2K
| Adam | epoch: 012 | loss: 0.31058 - acc: 0.8857 -- iter: 192/628
[A[ATraining Step: 227  | total loss: [1m[32m0.29644[0m[0m | time: 4.241s
[2K
| Adam | epoch: 012 | loss: 0.29644 - acc: 0.8940 -- iter: 224/628
[A[ATraining Step: 228  | total loss: [1m[32m0.30351[0m[0m | time: 4.833s
[2K
| Adam | epoch: 012 | loss: 0.30351 - acc: 0.8827 -- iter: 256/628
[A[ATraining Step: 229  | total loss: [1m[32m0.29096[0m[0m | time: 5.419s
[2K
| Adam | epoch: 012 | loss: 0.29096 - acc: 0.8882 -- iter: 288/628
[A[ATraining Step: 230  | total loss: [1m[32m0.28664[0m[0m | time: 5.819s
[2K
| Adam | epoch: 012 | loss: 0.28664 - acc: 0.8931 -- iter: 320/628
[A[ATraining Step: 231  | total loss: [1m[32m0.29978[0m[0m | time: 6.227s
[2K
| Adam | epoch: 012 | loss: 0.29978 - acc: 0.8888 -- iter: 352/628
[A[ATraining Step: 232  | total loss: [1m[32m0.30654[0m[0m | time: 6.851s
[2K
| Adam | epoch: 012 | loss: 0.30654 - acc: 0.8849 -- iter: 384/628
[A[ATraining Step: 233  | total loss: [1m[32m0.29131[0m[0m | time: 7.453s
[2K
| Adam | epoch: 012 | loss: 0.29131 - acc: 0.8902 -- iter: 416/628
[A[ATraining Step: 234  | total loss: [1m[32m0.28699[0m[0m | time: 8.064s
[2K
| Adam | epoch: 012 | loss: 0.28699 - acc: 0.8949 -- iter: 448/628
[A[ATraining Step: 235  | total loss: [1m[32m0.28379[0m[0m | time: 8.659s
[2K
| Adam | epoch: 012 | loss: 0.28379 - acc: 0.8992 -- iter: 480/628
[A[ATraining Step: 236  | total loss: [1m[32m0.29806[0m[0m | time: 9.256s
[2K
| Adam | epoch: 012 | loss: 0.29806 - acc: 0.8905 -- iter: 512/628
[A[ATraining Step: 237  | total loss: [1m[32m0.29724[0m[0m | time: 9.859s
[2K
| Adam | epoch: 012 | loss: 0.29724 - acc: 0.8890 -- iter: 544/628
[A[ATraining Step: 238  | total loss: [1m[32m0.30366[0m[0m | time: 10.467s
[2K
| Adam | epoch: 012 | loss: 0.30366 - acc: 0.8876 -- iter: 576/628
[A[ATraining Step: 239  | total loss: [1m[32m0.28998[0m[0m | time: 11.060s
[2K
| Adam | epoch: 012 | loss: 0.28998 - acc: 0.8894 -- iter: 608/628
[A[ATraining Step: 240  | total loss: [1m[32m0.28432[0m[0m | time: 12.659s
[2K
| Adam | epoch: 012 | loss: 0.28432 - acc: 0.8942 | val_loss: 0.38792 - val_acc: 0.8477 -- iter: 628/628
--
Training Step: 241  | total loss: [1m[32m0.27512[0m[0m | time: 0.597s
[2K
| Adam | epoch: 013 | loss: 0.27512 - acc: 0.8986 -- iter: 032/628
[A[ATraining Step: 242  | total loss: [1m[32m0.25997[0m[0m | time: 1.190s
[2K
| Adam | epoch: 013 | loss: 0.25997 - acc: 0.9056 -- iter: 064/628
[A[ATraining Step: 243  | total loss: [1m[32m0.25248[0m[0m | time: 1.797s
[2K
| Adam | epoch: 013 | loss: 0.25248 - acc: 0.9088 -- iter: 096/628
[A[ATraining Step: 244  | total loss: [1m[32m0.25963[0m[0m | time: 2.372s
[2K
| Adam | epoch: 013 | loss: 0.25963 - acc: 0.9054 -- iter: 128/628
[A[ATraining Step: 245  | total loss: [1m[32m0.24683[0m[0m | time: 2.988s
[2K
| Adam | epoch: 013 | loss: 0.24683 - acc: 0.9117 -- iter: 160/628
[A[ATraining Step: 246  | total loss: [1m[32m0.26050[0m[0m | time: 3.583s
[2K
| Adam | epoch: 013 | loss: 0.26050 - acc: 0.9081 -- iter: 192/628
[A[ATraining Step: 247  | total loss: [1m[32m0.24527[0m[0m | time: 4.197s
[2K
| Adam | epoch: 013 | loss: 0.24527 - acc: 0.9141 -- iter: 224/628
[A[ATraining Step: 248  | total loss: [1m[32m0.23721[0m[0m | time: 4.790s
[2K
| Adam | epoch: 013 | loss: 0.23721 - acc: 0.9133 -- iter: 256/628
[A[ATraining Step: 249  | total loss: [1m[32m0.24053[0m[0m | time: 5.402s
[2K
| Adam | epoch: 013 | loss: 0.24053 - acc: 0.9095 -- iter: 288/628
[A[ATraining Step: 250  | total loss: [1m[32m0.24261[0m[0m | time: 6.005s
[2K
| Adam | epoch: 013 | loss: 0.24261 - acc: 0.9092 -- iter: 320/628
[A[ATraining Step: 251  | total loss: [1m[32m0.23620[0m[0m | time: 6.382s
[2K
| Adam | epoch: 013 | loss: 0.23620 - acc: 0.9120 -- iter: 352/628
[A[ATraining Step: 252  | total loss: [1m[32m0.23866[0m[0m | time: 6.777s
[2K
| Adam | epoch: 013 | loss: 0.23866 - acc: 0.9108 -- iter: 384/628
[A[ATraining Step: 253  | total loss: [1m[32m0.23692[0m[0m | time: 7.385s
[2K
| Adam | epoch: 013 | loss: 0.23692 - acc: 0.9147 -- iter: 416/628
[A[ATraining Step: 254  | total loss: [1m[32m0.23075[0m[0m | time: 7.995s
[2K
| Adam | epoch: 013 | loss: 0.23075 - acc: 0.9170 -- iter: 448/628
[A[ATraining Step: 255  | total loss: [1m[32m0.23298[0m[0m | time: 8.589s
[2K
| Adam | epoch: 013 | loss: 0.23298 - acc: 0.9128 -- iter: 480/628
[A[ATraining Step: 256  | total loss: [1m[32m0.22960[0m[0m | time: 9.187s
[2K
| Adam | epoch: 013 | loss: 0.22960 - acc: 0.9122 -- iter: 512/628
[A[ATraining Step: 257  | total loss: [1m[32m0.21666[0m[0m | time: 9.790s
[2K
| Adam | epoch: 013 | loss: 0.21666 - acc: 0.9178 -- iter: 544/628
[A[ATraining Step: 258  | total loss: [1m[32m0.21492[0m[0m | time: 10.396s
[2K
| Adam | epoch: 013 | loss: 0.21492 - acc: 0.9167 -- iter: 576/628
[A[ATraining Step: 259  | total loss: [1m[32m0.21706[0m[0m | time: 11.013s
[2K
| Adam | epoch: 013 | loss: 0.21706 - acc: 0.9156 -- iter: 608/628
[A[ATraining Step: 260  | total loss: [1m[32m0.20801[0m[0m | time: 12.631s
[2K
| Adam | epoch: 013 | loss: 0.20801 - acc: 0.9178 | val_loss: 0.35881 - val_acc: 0.8782 -- iter: 628/628
--
Training Step: 261  | total loss: [1m[32m0.21683[0m[0m | time: 0.610s
[2K
| Adam | epoch: 014 | loss: 0.21683 - acc: 0.9135 -- iter: 032/628
[A[ATraining Step: 262  | total loss: [1m[32m0.20777[0m[0m | time: 1.213s
[2K
| Adam | epoch: 014 | loss: 0.20777 - acc: 0.9190 -- iter: 064/628
[A[ATraining Step: 263  | total loss: [1m[32m0.22517[0m[0m | time: 1.796s
[2K
| Adam | epoch: 014 | loss: 0.22517 - acc: 0.9115 -- iter: 096/628
[A[ATraining Step: 264  | total loss: [1m[32m0.22120[0m[0m | time: 2.398s
[2K
| Adam | epoch: 014 | loss: 0.22120 - acc: 0.9141 -- iter: 128/628
[A[ATraining Step: 265  | total loss: [1m[32m0.21136[0m[0m | time: 2.985s
[2K
| Adam | epoch: 014 | loss: 0.21136 - acc: 0.9196 -- iter: 160/628
[A[ATraining Step: 266  | total loss: [1m[32m0.20132[0m[0m | time: 3.598s
[2K
| Adam | epoch: 014 | loss: 0.20132 - acc: 0.9245 -- iter: 192/628
[A[ATraining Step: 267  | total loss: [1m[32m0.21712[0m[0m | time: 4.195s
[2K
| Adam | epoch: 014 | loss: 0.21712 - acc: 0.9164 -- iter: 224/628
[A[ATraining Step: 268  | total loss: [1m[32m0.20146[0m[0m | time: 4.791s
[2K
| Adam | epoch: 014 | loss: 0.20146 - acc: 0.9248 -- iter: 256/628
[A[ATraining Step: 269  | total loss: [1m[32m0.20740[0m[0m | time: 5.405s
[2K
| Adam | epoch: 014 | loss: 0.20740 - acc: 0.9229 -- iter: 288/628
[A[ATraining Step: 270  | total loss: [1m[32m0.20021[0m[0m | time: 6.011s
[2K
| Adam | epoch: 014 | loss: 0.20021 - acc: 0.9275 -- iter: 320/628
[A[ATraining Step: 271  | total loss: [1m[32m0.19940[0m[0m | time: 6.610s
[2K
| Adam | epoch: 014 | loss: 0.19940 - acc: 0.9285 -- iter: 352/628
[A[ATraining Step: 272  | total loss: [1m[32m0.20049[0m[0m | time: 7.011s
[2K
| Adam | epoch: 014 | loss: 0.20049 - acc: 0.9294 -- iter: 384/628
[A[ATraining Step: 273  | total loss: [1m[32m0.19120[0m[0m | time: 7.388s
[2K
| Adam | epoch: 014 | loss: 0.19120 - acc: 0.9315 -- iter: 416/628
[A[ATraining Step: 274  | total loss: [1m[32m0.18069[0m[0m | time: 7.979s
[2K
| Adam | epoch: 014 | loss: 0.18069 - acc: 0.9383 -- iter: 448/628
[A[ATraining Step: 275  | total loss: [1m[32m0.18917[0m[0m | time: 8.582s
[2K
| Adam | epoch: 014 | loss: 0.18917 - acc: 0.9320 -- iter: 480/628
[A[ATraining Step: 276  | total loss: [1m[32m0.20101[0m[0m | time: 9.184s
[2K
| Adam | epoch: 014 | loss: 0.20101 - acc: 0.9263 -- iter: 512/628
[A[ATraining Step: 277  | total loss: [1m[32m0.19396[0m[0m | time: 9.803s
[2K
| Adam | epoch: 014 | loss: 0.19396 - acc: 0.9274 -- iter: 544/628
[A[ATraining Step: 278  | total loss: [1m[32m0.17860[0m[0m | time: 10.406s
[2K
| Adam | epoch: 014 | loss: 0.17860 - acc: 0.9347 -- iter: 576/628
[A[ATraining Step: 279  | total loss: [1m[32m0.18523[0m[0m | time: 11.019s
[2K
| Adam | epoch: 014 | loss: 0.18523 - acc: 0.9318 -- iter: 608/628
[A[ATraining Step: 280  | total loss: [1m[32m0.19036[0m[0m | time: 12.625s
[2K
| Adam | epoch: 014 | loss: 0.19036 - acc: 0.9324 | val_loss: 0.47248 - val_acc: 0.8223 -- iter: 628/628
--
Training Step: 281  | total loss: [1m[32m0.18884[0m[0m | time: 0.593s
[2K
| Adam | epoch: 015 | loss: 0.18884 - acc: 0.9360 -- iter: 032/628
[A[ATraining Step: 282  | total loss: [1m[32m0.19175[0m[0m | time: 1.230s
[2K
| Adam | epoch: 015 | loss: 0.19175 - acc: 0.9331 -- iter: 064/628
[A[ATraining Step: 283  | total loss: [1m[32m0.19433[0m[0m | time: 1.839s
[2K
| Adam | epoch: 015 | loss: 0.19433 - acc: 0.9335 -- iter: 096/628
[A[ATraining Step: 284  | total loss: [1m[32m0.18789[0m[0m | time: 2.457s
[2K
| Adam | epoch: 015 | loss: 0.18789 - acc: 0.9370 -- iter: 128/628
[A[ATraining Step: 285  | total loss: [1m[32m0.18050[0m[0m | time: 3.047s
[2K
| Adam | epoch: 015 | loss: 0.18050 - acc: 0.9371 -- iter: 160/628
[A[ATraining Step: 286  | total loss: [1m[32m0.17488[0m[0m | time: 3.687s
[2K
| Adam | epoch: 015 | loss: 0.17488 - acc: 0.9402 -- iter: 192/628
[A[ATraining Step: 287  | total loss: [1m[32m0.17096[0m[0m | time: 4.282s
[2K
| Adam | epoch: 015 | loss: 0.17096 - acc: 0.9431 -- iter: 224/628
[A[ATraining Step: 288  | total loss: [1m[32m0.18032[0m[0m | time: 4.879s
[2K
| Adam | epoch: 015 | loss: 0.18032 - acc: 0.9394 -- iter: 256/628
[A[ATraining Step: 289  | total loss: [1m[32m0.17735[0m[0m | time: 5.480s
[2K
| Adam | epoch: 015 | loss: 0.17735 - acc: 0.9423 -- iter: 288/628
[A[ATraining Step: 290  | total loss: [1m[32m0.17667[0m[0m | time: 6.078s
[2K
| Adam | epoch: 015 | loss: 0.17667 - acc: 0.9450 -- iter: 320/628
[A[ATraining Step: 291  | total loss: [1m[32m0.17406[0m[0m | time: 6.682s
[2K
| Adam | epoch: 015 | loss: 0.17406 - acc: 0.9411 -- iter: 352/628
[A[ATraining Step: 292  | total loss: [1m[32m0.16564[0m[0m | time: 7.291s
[2K
| Adam | epoch: 015 | loss: 0.16564 - acc: 0.9439 -- iter: 384/628
[A[ATraining Step: 293  | total loss: [1m[32m0.18011[0m[0m | time: 7.683s
[2K
| Adam | epoch: 015 | loss: 0.18011 - acc: 0.9401 -- iter: 416/628
[A[ATraining Step: 294  | total loss: [1m[32m0.16718[0m[0m | time: 8.069s
[2K
| Adam | epoch: 015 | loss: 0.16718 - acc: 0.9461 -- iter: 448/628
[A[ATraining Step: 295  | total loss: [1m[32m0.15478[0m[0m | time: 8.667s
[2K
| Adam | epoch: 015 | loss: 0.15478 - acc: 0.9515 -- iter: 480/628
[A[ATraining Step: 296  | total loss: [1m[32m0.15858[0m[0m | time: 9.262s
[2K
| Adam | epoch: 015 | loss: 0.15858 - acc: 0.9501 -- iter: 512/628
[A[ATraining Step: 297  | total loss: [1m[32m0.14640[0m[0m | time: 9.857s
[2K
| Adam | epoch: 015 | loss: 0.14640 - acc: 0.9551 -- iter: 544/628
[A[ATraining Step: 298  | total loss: [1m[32m0.15013[0m[0m | time: 10.469s
[2K
| Adam | epoch: 015 | loss: 0.15013 - acc: 0.9533 -- iter: 576/628
[A[ATraining Step: 299  | total loss: [1m[32m0.14376[0m[0m | time: 11.088s
[2K
| Adam | epoch: 015 | loss: 0.14376 - acc: 0.9549 -- iter: 608/628
[A[ATraining Step: 300  | total loss: [1m[32m0.13751[0m[0m | time: 12.686s
[2K
| Adam | epoch: 015 | loss: 0.13751 - acc: 0.9563 | val_loss: 0.41890 - val_acc: 0.8426 -- iter: 628/628
--
Validation AUC:0.9206185567010309
Validation AUPRC:0.9330397182371899
Test AUC:0.9152418682235196
Test AUPRC:0.9454505444583027
BestTestF1Score	0.87	0.72	0.86	0.91	0.83	90	9	79	19	0.63
BestTestMCCScore	0.84	0.72	0.84	0.98	0.73	80	2	86	29	0.91
BestTestAccuracyScore	0.87	0.75	0.87	0.96	0.8	87	4	84	22	0.81
BestValidationF1Score	0.86	0.73	0.86	0.86	0.86	83	13	87	14	0.63
BestValidationMCC	0.84	0.74	0.86	0.96	0.75	73	3	97	24	0.91
BestValidationAccuracy	0.86	0.74	0.87	0.91	0.81	79	8	92	18	0.81
TestPredictions (Threshold:0.91)
CHEMBL3335667,TP,ACT,0.9800000190734863	CHEMBL556311,TP,ACT,1.0	CHEMBL3264643,TP,ACT,0.9900000095367432	CHEMBL3613431,TN,INACT,0.14000000059604645	CHEMBL1642349,TN,INACT,0.550000011920929	CHEMBL2037325,TP,ACT,1.0	CHEMBL191984,TP,ACT,1.0	CHEMBL3393178,TP,ACT,0.9800000190734863	CHEMBL3114111,TP,ACT,1.0	CHEMBL1541779,TN,INACT,0.029999999329447746	CHEMBL1835049,TP,ACT,1.0	CHEMBL487611,TN,INACT,0.03999999910593033	CHEMBL1535180,TN,INACT,0.029999999329447746	CHEMBL1380966,TN,INACT,0.029999999329447746	CHEMBL1578278,TN,INACT,0.029999999329447746	CHEMBL191379,TP,ACT,1.0	CHEMBL1668249,TP,ACT,1.0	CHEMBL2037326,TP,ACT,1.0	CHEMBL1976046,TN,INACT,0.07000000029802322	CHEMBL394913,TN,INACT,0.10000000149011612	CHEMBL3335648,FN,ACT,0.8799999952316284	CHEMBL2381208,TN,INACT,0.03999999910593033	CHEMBL426273,TP,ACT,1.0	CHEMBL2070838,TN,INACT,0.05000000074505806	CHEMBL3138037,TN,INACT,0.8899999856948853	CHEMBL1505049,TN,INACT,0.05999999865889549	CHEMBL3262947,FN,ACT,0.8600000143051147	CHEMBL467060,TP,ACT,0.9800000190734863	CHEMBL3335653,FN,ACT,0.8700000047683716	CHEMBL3263246,FN,ACT,0.38999998569488525	CHEMBL3109606,TN,INACT,0.7799999713897705	CHEMBL236496,TN,INACT,0.27000001072883606	CHEMBL3357420,TP,ACT,1.0	CHEMBL3335649,FN,ACT,0.75	CHEMBL391479,TN,INACT,0.23999999463558197	CHEMBL2348891,TN,INACT,0.7900000214576721	CHEMBL3823213,TP,ACT,1.0	CHEMBL3613413,FN,ACT,0.5899999737739563	CHEMBL1209171,TP,ACT,1.0	CHEMBL319606,TP,ACT,0.9900000095367432	CHEMBL1612543,TN,INACT,0.019999999552965164	CHEMBL45281,FN,ACT,0.029999999329447746	CHEMBL3109602,TN,INACT,0.4000000059604645	CHEMBL2325057,TN,INACT,0.07000000029802322	CHEMBL190553,TP,ACT,1.0	CHEMBL1325233,TN,INACT,0.019999999552965164	CHEMBL241106,FN,ACT,0.11999999731779099	CHEMBL2070868,TN,INACT,0.10000000149011612	CHEMBL3393183,TP,ACT,0.9399999976158142	CHEMBL46403,TN,INACT,0.019999999552965164	CHEMBL1375737,TN,INACT,0.03999999910593033	CHEMBL364810,TP,ACT,1.0	CHEMBL1370919,TN,INACT,0.6700000166893005	CHEMBL2064742,TN,INACT,0.10000000149011612	CHEMBL3822597,TP,ACT,1.0	CHEMBL370054,TN,INACT,0.03999999910593033	CHEMBL468734,TP,ACT,1.0	CHEMBL3264636,TP,ACT,0.9800000190734863	CHEMBL1559172,TN,INACT,0.10999999940395355	CHEMBL466318,TP,ACT,1.0	CHEMBL1668247,TP,ACT,1.0	CHEMBL466831,TP,ACT,1.0	CHEMBL1496995,TN,INACT,0.05999999865889549	CHEMBL2204685,TN,INACT,0.019999999552965164	CHEMBL2158166,FN,ACT,0.03999999910593033	CHEMBL1330946,TN,INACT,0.029999999329447746	CHEMBL1086742,TN,INACT,0.7599999904632568	CHEMBL2070862,TN,INACT,0.6299999952316284	CHEMBL1450165,TN,INACT,0.07999999821186066	CHEMBL3335651,TP,ACT,0.9100000262260437	CHEMBL2037312,TP,ACT,0.9900000095367432	CHEMBL3613417,TP,ACT,0.9700000286102295	CHEMBL425555,TP,ACT,1.0	CHEMBL564917,TP,ACT,1.0	CHEMBL1209173,TP,ACT,0.9399999976158142	CHEMBL2382120,TN,INACT,0.07000000029802322	CHEMBL189155,TP,ACT,1.0	CHEMBL364289,TP,ACT,0.9300000071525574	CHEMBL1597933,TN,INACT,0.03999999910593033	CHEMBL3138092,FN,ACT,0.009999999776482582	CHEMBL325172,FP,INACT,1.0	CHEMBL437481,TP,ACT,1.0	CHEMBL466026,TP,ACT,1.0	CHEMBL523368,TP,ACT,1.0	CHEMBL1668254,TP,ACT,1.0	CHEMBL492047,TN,INACT,0.019999999552965164	CHEMBL3824077,TP,ACT,1.0	CHEMBL1331729,TN,INACT,0.07000000029802322	CHEMBL435492,TP,ACT,1.0	CHEMBL3264647,FN,ACT,0.8600000143051147	CHEMBL482642,TN,INACT,0.03999999910593033	CHEMBL3335654,FN,ACT,0.8600000143051147	CHEMBL107789,TN,INACT,0.05999999865889549	CHEMBL402063,TN,INACT,0.05999999865889549	CHEMBL1434961,TN,INACT,0.029999999329447746	CHEMBL2070863,TN,INACT,0.14000000059604645	CHEMBL3589975,FN,ACT,0.05000000074505806	CHEMBL3114116,FN,ACT,0.03999999910593033	CHEMBL1578407,TN,INACT,0.2800000011920929	CHEMBL375927,TN,INACT,0.05999999865889549	CHEMBL2335811,TN,INACT,0.5	CHEMBL3814453,FN,ACT,0.36000001430511475	CHEMBL101381,TP,ACT,1.0	CHEMBL1084746,TN,INACT,0.05999999865889549	CHEMBL192174,TP,ACT,0.9700000286102295	CHEMBL193148,TP,ACT,1.0	CHEMBL3109612,TN,INACT,0.05999999865889549	CHEMBL3617309,FN,ACT,0.2199999988079071	CHEMBL2011539,TN,INACT,0.03999999910593033	CHEMBL2037329,FN,ACT,0.27000001072883606	CHEMBL3822803,TP,ACT,1.0	CHEMBL466315,TP,ACT,1.0	CHEMBL551185,TN,INACT,0.03999999910593033	CHEMBL1390729,TN,INACT,0.05000000074505806	CHEMBL3746388,TP,ACT,0.9900000095367432	CHEMBL1552,FN,ACT,0.8299999833106995	CHEMBL2037188,TP,ACT,1.0	CHEMBL552157,TN,INACT,0.6200000047683716	CHEMBL3264646,TP,ACT,0.9800000190734863	CHEMBL192852,TP,ACT,0.9700000286102295	CHEMBL3617295,TP,ACT,0.9599999785423279	CHEMBL551248,TN,INACT,0.03999999910593033	CHEMBL3589972,FN,ACT,0.5299999713897705	CHEMBL21241,FN,ACT,0.03999999910593033	CHEMBL1505467,FP,INACT,0.9200000166893005	CHEMBL3824337,TP,ACT,1.0	CHEMBL3357415,FN,ACT,0.8100000023841858	CHEMBL3264645,TP,ACT,0.9599999785423279	CHEMBL466620,TP,ACT,1.0	CHEMBL1834967,TP,ACT,0.9800000190734863	CHEMBL236134,TN,INACT,0.03999999910593033	CHEMBL510862,FN,ACT,0.7599999904632568	CHEMBL1668260,TP,ACT,1.0	CHEMBL466451,TP,ACT,1.0	CHEMBL511389,TP,ACT,0.9900000095367432	CHEMBL1461254,TN,INACT,0.8799999952316284	CHEMBL1322274,TN,INACT,0.03999999910593033	CHEMBL1971613,TN,INACT,0.029999999329447746	CHEMBL192769,TP,ACT,1.0	CHEMBL3335645,TP,ACT,1.0	CHEMBL3754461,TN,INACT,0.5699999928474426	CHEMBL300629,TN,INACT,0.03999999910593033	CHEMBL191097,TP,ACT,1.0	CHEMBL560648,TN,INACT,0.019999999552965164	CHEMBL3823564,TP,ACT,1.0	CHEMBL590351,TN,INACT,0.029999999329447746	CHEMBL1445192,TN,INACT,0.2199999988079071	CHEMBL492963,TP,ACT,1.0	CHEMBL119030,TN,INACT,0.029999999329447746	CHEMBL2037186,TP,ACT,1.0	CHEMBL1350226,TN,INACT,0.05999999865889549	CHEMBL2070849,TN,INACT,0.10000000149011612	CHEMBL2381195,TN,INACT,0.029999999329447746	CHEMBL1642346,FN,ACT,0.5299999713897705	CHEMBL3752362,TN,INACT,0.03999999910593033	CHEMBL1320239,TN,INACT,0.029999999329447746	CHEMBL2070865,TN,INACT,0.07999999821186066	CHEMBL560147,TP,ACT,1.0	CHEMBL1672448,TP,ACT,1.0	CHEMBL558267,TP,ACT,1.0	CHEMBL123,TN,INACT,0.05000000074505806	CHEMBL1956357,TN,INACT,0.029999999329447746	CHEMBL1450791,TN,INACT,0.03999999910593033	CHEMBL562011,TP,ACT,1.0	CHEMBL3822755,TP,ACT,1.0	CHEMBL3746619,TN,INACT,0.7799999713897705	CHEMBL579197,TP,ACT,0.9800000190734863	CHEMBL3335625,TP,ACT,0.949999988079071	CHEMBL3114120,FN,ACT,0.019999999552965164	CHEMBL1464837,TN,INACT,0.03999999910593033	CHEMBL394678,TN,INACT,0.03999999910593033	CHEMBL3617297,FN,ACT,0.10999999940395355	CHEMBL1834968,TP,ACT,0.9599999785423279	CHEMBL3264932,TN,INACT,0.03999999910593033	CHEMBL1310309,TN,INACT,0.14000000059604645	CHEMBL3264987,FN,ACT,0.05000000074505806	CHEMBL364915,TP,ACT,1.0	CHEMBL477940,TN,INACT,0.33000001311302185	CHEMBL191236,FN,ACT,0.6499999761581421	CHEMBL1471055,TN,INACT,0.07000000029802322	CHEMBL558662,TP,ACT,1.0	CHEMBL364746,TP,ACT,1.0	CHEMBL3621225,TN,INACT,0.03999999910593033	CHEMBL3823070,TP,ACT,1.0	CHEMBL1478,FN,ACT,0.14000000059604645	CHEMBL203122,TN,INACT,0.05000000074505806	CHEMBL1299357,TN,INACT,0.03999999910593033	CHEMBL1970117,TN,INACT,0.05000000074505806	CHEMBL1468124,TN,INACT,0.5199999809265137	CHEMBL427080,TN,INACT,0.019999999552965164	CHEMBL190421,TP,ACT,1.0	CHEMBL3260994,FN,ACT,0.18000000715255737	CHEMBL584897,TP,ACT,0.9900000095367432	CHEMBL558724,TP,ACT,1.0	CHEMBL489597,TN,INACT,0.05999999865889549	CHEMBL103394,TP,ACT,1.0	CHEMBL189432,TP,ACT,1.0	

