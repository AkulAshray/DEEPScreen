CNNModel CHEMBL5080 adam 0.001 30 32 0 0.6 False True
Number of active compounds :	342
Number of inactive compounds :	228
---------------------------------
Run id: CNNModel_CHEMBL5080_adam_0.001_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5080_adam_0.001_30_32_0.6_True/
---------------------------------
Training samples: 309
Validation samples: 97
--
Training Step: 1  | time: 0.770s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/309
[A[ATraining Step: 2  | total loss: [1m[32m0.62363[0m[0m | time: 1.380s
[2K
| Adam | epoch: 001 | loss: 0.62363 - acc: 0.4500 -- iter: 064/309
[A[ATraining Step: 3  | total loss: [1m[32m0.68045[0m[0m | time: 1.994s
[2K
| Adam | epoch: 001 | loss: 0.68045 - acc: 0.5676 -- iter: 096/309
[A[ATraining Step: 4  | total loss: [1m[32m0.67826[0m[0m | time: 2.601s
[2K
| Adam | epoch: 001 | loss: 0.67826 - acc: 0.6341 -- iter: 128/309
[A[ATraining Step: 5  | total loss: [1m[32m0.66786[0m[0m | time: 3.209s
[2K
| Adam | epoch: 001 | loss: 0.66786 - acc: 0.6278 -- iter: 160/309
[A[ATraining Step: 6  | total loss: [1m[32m0.69962[0m[0m | time: 3.840s
[2K
| Adam | epoch: 001 | loss: 0.69962 - acc: 0.6260 -- iter: 192/309
[A[ATraining Step: 7  | total loss: [1m[32m0.73436[0m[0m | time: 4.455s
[2K
| Adam | epoch: 001 | loss: 0.73436 - acc: 0.5316 -- iter: 224/309
[A[ATraining Step: 8  | total loss: [1m[32m0.67461[0m[0m | time: 5.079s
[2K
| Adam | epoch: 001 | loss: 0.67461 - acc: 0.6896 -- iter: 256/309
[A[ATraining Step: 9  | total loss: [1m[32m0.69046[0m[0m | time: 5.711s
[2K
| Adam | epoch: 001 | loss: 0.69046 - acc: 0.5561 -- iter: 288/309
[A[ATraining Step: 10  | total loss: [1m[32m0.69013[0m[0m | time: 7.177s
[2K
| Adam | epoch: 001 | loss: 0.69013 - acc: 0.5593 | val_loss: 0.69011 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 11  | total loss: [1m[32m0.69569[0m[0m | time: 0.433s
[2K
| Adam | epoch: 002 | loss: 0.69569 - acc: 0.4748 -- iter: 032/309
[A[ATraining Step: 12  | total loss: [1m[32m0.69239[0m[0m | time: 1.056s
[2K
| Adam | epoch: 002 | loss: 0.69239 - acc: 0.5397 -- iter: 064/309
[A[ATraining Step: 13  | total loss: [1m[32m0.69274[0m[0m | time: 1.667s
[2K
| Adam | epoch: 002 | loss: 0.69274 - acc: 0.5227 -- iter: 096/309
[A[ATraining Step: 14  | total loss: [1m[32m0.69117[0m[0m | time: 2.279s
[2K
| Adam | epoch: 002 | loss: 0.69117 - acc: 0.5773 -- iter: 128/309
[A[ATraining Step: 15  | total loss: [1m[32m0.69130[0m[0m | time: 2.907s
[2K
| Adam | epoch: 002 | loss: 0.69130 - acc: 0.5715 -- iter: 160/309
[A[ATraining Step: 16  | total loss: [1m[32m0.68962[0m[0m | time: 3.526s
[2K
| Adam | epoch: 002 | loss: 0.68962 - acc: 0.6267 -- iter: 192/309
[A[ATraining Step: 17  | total loss: [1m[32m0.69058[0m[0m | time: 4.147s
[2K
| Adam | epoch: 002 | loss: 0.69058 - acc: 0.5924 -- iter: 224/309
[A[ATraining Step: 18  | total loss: [1m[32m0.69190[0m[0m | time: 4.790s
[2K
| Adam | epoch: 002 | loss: 0.69190 - acc: 0.5496 -- iter: 256/309
[A[ATraining Step: 19  | total loss: [1m[32m0.68957[0m[0m | time: 5.404s
[2K
| Adam | epoch: 002 | loss: 0.68957 - acc: 0.6060 -- iter: 288/309
[A[ATraining Step: 20  | total loss: [1m[32m0.69123[0m[0m | time: 7.021s
[2K
| Adam | epoch: 002 | loss: 0.69123 - acc: 0.5619 | val_loss: 0.68966 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 21  | total loss: [1m[32m0.69095[0m[0m | time: 0.423s
[2K
| Adam | epoch: 003 | loss: 0.69095 - acc: 0.5621 -- iter: 032/309
[A[ATraining Step: 22  | total loss: [1m[32m0.68998[0m[0m | time: 0.829s
[2K
| Adam | epoch: 003 | loss: 0.68998 - acc: 0.5792 -- iter: 064/309
[A[ATraining Step: 23  | total loss: [1m[32m0.69145[0m[0m | time: 1.441s
[2K
| Adam | epoch: 003 | loss: 0.69145 - acc: 0.5493 -- iter: 096/309
[A[ATraining Step: 24  | total loss: [1m[32m0.69059[0m[0m | time: 2.072s
[2K
| Adam | epoch: 003 | loss: 0.69059 - acc: 0.5618 -- iter: 128/309
[A[ATraining Step: 25  | total loss: [1m[32m0.68989[0m[0m | time: 2.675s
[2K
| Adam | epoch: 003 | loss: 0.68989 - acc: 0.5705 -- iter: 160/309
[A[ATraining Step: 26  | total loss: [1m[32m0.68819[0m[0m | time: 3.312s
[2K
| Adam | epoch: 003 | loss: 0.68819 - acc: 0.5932 -- iter: 192/309
[A[ATraining Step: 27  | total loss: [1m[32m0.69081[0m[0m | time: 3.932s
[2K
| Adam | epoch: 003 | loss: 0.69081 - acc: 0.5532 -- iter: 224/309
[A[ATraining Step: 28  | total loss: [1m[32m0.68800[0m[0m | time: 4.543s
[2K
| Adam | epoch: 003 | loss: 0.68800 - acc: 0.5867 -- iter: 256/309
[A[ATraining Step: 29  | total loss: [1m[32m0.68762[0m[0m | time: 5.179s
[2K
| Adam | epoch: 003 | loss: 0.68762 - acc: 0.5884 -- iter: 288/309
[A[ATraining Step: 30  | total loss: [1m[32m0.68525[0m[0m | time: 6.811s
[2K
| Adam | epoch: 003 | loss: 0.68525 - acc: 0.6119 | val_loss: 0.68616 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 31  | total loss: [1m[32m0.68679[0m[0m | time: 0.617s
[2K
| Adam | epoch: 004 | loss: 0.68679 - acc: 0.5933 -- iter: 032/309
[A[ATraining Step: 32  | total loss: [1m[32m0.68865[0m[0m | time: 1.043s
[2K
| Adam | epoch: 004 | loss: 0.68865 - acc: 0.5723 -- iter: 064/309
[A[ATraining Step: 33  | total loss: [1m[32m0.69086[0m[0m | time: 1.456s
[2K
| Adam | epoch: 004 | loss: 0.69086 - acc: 0.5512 -- iter: 096/309
[A[ATraining Step: 34  | total loss: [1m[32m0.69117[0m[0m | time: 2.063s
[2K
| Adam | epoch: 004 | loss: 0.69117 - acc: 0.5453 -- iter: 128/309
[A[ATraining Step: 35  | total loss: [1m[32m0.69032[0m[0m | time: 2.672s
[2K
| Adam | epoch: 004 | loss: 0.69032 - acc: 0.5489 -- iter: 160/309
[A[ATraining Step: 36  | total loss: [1m[32m0.68539[0m[0m | time: 3.286s
[2K
| Adam | epoch: 004 | loss: 0.68539 - acc: 0.5837 -- iter: 192/309
[A[ATraining Step: 37  | total loss: [1m[32m0.68467[0m[0m | time: 3.922s
[2K
| Adam | epoch: 004 | loss: 0.68467 - acc: 0.5857 -- iter: 224/309
[A[ATraining Step: 38  | total loss: [1m[32m0.68391[0m[0m | time: 4.521s
[2K
| Adam | epoch: 004 | loss: 0.68391 - acc: 0.5873 -- iter: 256/309
[A[ATraining Step: 39  | total loss: [1m[32m0.68546[0m[0m | time: 5.129s
[2K
| Adam | epoch: 004 | loss: 0.68546 - acc: 0.5765 -- iter: 288/309
[A[ATraining Step: 40  | total loss: [1m[32m0.68654[0m[0m | time: 6.735s
[2K
| Adam | epoch: 004 | loss: 0.68654 - acc: 0.5680 | val_loss: 0.68236 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 41  | total loss: [1m[32m0.68884[0m[0m | time: 0.618s
[2K
| Adam | epoch: 005 | loss: 0.68884 - acc: 0.5555 -- iter: 032/309
[A[ATraining Step: 42  | total loss: [1m[32m0.68581[0m[0m | time: 1.242s
[2K
| Adam | epoch: 005 | loss: 0.68581 - acc: 0.5680 -- iter: 064/309
[A[ATraining Step: 43  | total loss: [1m[32m0.68449[0m[0m | time: 1.658s
[2K
| Adam | epoch: 005 | loss: 0.68449 - acc: 0.5726 -- iter: 096/309
[A[ATraining Step: 44  | total loss: [1m[32m0.68654[0m[0m | time: 2.070s
[2K
| Adam | epoch: 005 | loss: 0.68654 - acc: 0.5641 -- iter: 128/309
[A[ATraining Step: 45  | total loss: [1m[32m0.67766[0m[0m | time: 2.673s
[2K
| Adam | epoch: 005 | loss: 0.67766 - acc: 0.5977 -- iter: 160/309
[A[ATraining Step: 46  | total loss: [1m[32m0.66942[0m[0m | time: 3.311s
[2K
| Adam | epoch: 005 | loss: 0.66942 - acc: 0.6231 -- iter: 192/309
[A[ATraining Step: 47  | total loss: [1m[32m0.67422[0m[0m | time: 3.974s
[2K
| Adam | epoch: 005 | loss: 0.67422 - acc: 0.6081 -- iter: 224/309
[A[ATraining Step: 48  | total loss: [1m[32m0.67844[0m[0m | time: 4.612s
[2K
| Adam | epoch: 005 | loss: 0.67844 - acc: 0.5957 -- iter: 256/309
[A[ATraining Step: 49  | total loss: [1m[32m0.66869[0m[0m | time: 5.248s
[2K
| Adam | epoch: 005 | loss: 0.66869 - acc: 0.6152 -- iter: 288/309
[A[ATraining Step: 50  | total loss: [1m[32m0.67854[0m[0m | time: 6.866s
[2K
| Adam | epoch: 005 | loss: 0.67854 - acc: 0.5973 | val_loss: 0.68360 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 51  | total loss: [1m[32m0.68838[0m[0m | time: 0.610s
[2K
| Adam | epoch: 006 | loss: 0.68838 - acc: 0.5777 -- iter: 032/309
[A[ATraining Step: 52  | total loss: [1m[32m0.68700[0m[0m | time: 1.217s
[2K
| Adam | epoch: 006 | loss: 0.68700 - acc: 0.5801 -- iter: 064/309
[A[ATraining Step: 53  | total loss: [1m[32m0.68727[0m[0m | time: 1.843s
[2K
| Adam | epoch: 006 | loss: 0.68727 - acc: 0.5775 -- iter: 096/309
[A[ATraining Step: 54  | total loss: [1m[32m0.69305[0m[0m | time: 2.272s
[2K
| Adam | epoch: 006 | loss: 0.69305 - acc: 0.5572 -- iter: 128/309
[A[ATraining Step: 55  | total loss: [1m[32m0.68375[0m[0m | time: 2.681s
[2K
| Adam | epoch: 006 | loss: 0.68375 - acc: 0.5864 -- iter: 160/309
[A[ATraining Step: 56  | total loss: [1m[32m0.68845[0m[0m | time: 3.304s
[2K
| Adam | epoch: 006 | loss: 0.68845 - acc: 0.5642 -- iter: 192/309
[A[ATraining Step: 57  | total loss: [1m[32m0.68589[0m[0m | time: 3.947s
[2K
| Adam | epoch: 006 | loss: 0.68589 - acc: 0.5726 -- iter: 224/309
[A[ATraining Step: 58  | total loss: [1m[32m0.68209[0m[0m | time: 4.591s
[2K
| Adam | epoch: 006 | loss: 0.68209 - acc: 0.5883 -- iter: 256/309
[A[ATraining Step: 59  | total loss: [1m[32m0.67989[0m[0m | time: 5.199s
[2K
| Adam | epoch: 006 | loss: 0.67989 - acc: 0.5974 -- iter: 288/309
[A[ATraining Step: 60  | total loss: [1m[32m0.68229[0m[0m | time: 6.813s
[2K
| Adam | epoch: 006 | loss: 0.68229 - acc: 0.5845 | val_loss: 0.68257 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 61  | total loss: [1m[32m0.68349[0m[0m | time: 0.618s
[2K
| Adam | epoch: 007 | loss: 0.68349 - acc: 0.5776 -- iter: 032/309
[A[ATraining Step: 62  | total loss: [1m[32m0.68369[0m[0m | time: 1.219s
[2K
| Adam | epoch: 007 | loss: 0.68369 - acc: 0.5756 -- iter: 064/309
[A[ATraining Step: 63  | total loss: [1m[32m0.68394[0m[0m | time: 1.838s
[2K
| Adam | epoch: 007 | loss: 0.68394 - acc: 0.5740 -- iter: 096/309
[A[ATraining Step: 64  | total loss: [1m[32m0.68183[0m[0m | time: 2.457s
[2K
| Adam | epoch: 007 | loss: 0.68183 - acc: 0.5843 -- iter: 128/309
[A[ATraining Step: 65  | total loss: [1m[32m0.68308[0m[0m | time: 2.881s
[2K
| Adam | epoch: 007 | loss: 0.68308 - acc: 0.5777 -- iter: 160/309
[A[ATraining Step: 66  | total loss: [1m[32m0.68652[0m[0m | time: 3.332s
[2K
| Adam | epoch: 007 | loss: 0.68652 - acc: 0.5596 -- iter: 192/309
[A[ATraining Step: 67  | total loss: [1m[32m0.68274[0m[0m | time: 3.945s
[2K
| Adam | epoch: 007 | loss: 0.68274 - acc: 0.5781 -- iter: 224/309
[A[ATraining Step: 68  | total loss: [1m[32m0.67999[0m[0m | time: 4.561s
[2K
| Adam | epoch: 007 | loss: 0.67999 - acc: 0.5911 -- iter: 256/309
[A[ATraining Step: 69  | total loss: [1m[32m0.68057[0m[0m | time: 5.193s
[2K
| Adam | epoch: 007 | loss: 0.68057 - acc: 0.5878 -- iter: 288/309
[A[ATraining Step: 70  | total loss: [1m[32m0.67972[0m[0m | time: 6.796s
[2K
| Adam | epoch: 007 | loss: 0.67972 - acc: 0.5921 | val_loss: 0.68185 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 71  | total loss: [1m[32m0.67870[0m[0m | time: 0.597s
[2K
| Adam | epoch: 008 | loss: 0.67870 - acc: 0.5958 -- iter: 032/309
[A[ATraining Step: 72  | total loss: [1m[32m0.67940[0m[0m | time: 1.211s
[2K
| Adam | epoch: 008 | loss: 0.67940 - acc: 0.5921 -- iter: 064/309
[A[ATraining Step: 73  | total loss: [1m[32m0.68099[0m[0m | time: 1.811s
[2K
| Adam | epoch: 008 | loss: 0.68099 - acc: 0.5853 -- iter: 096/309
[A[ATraining Step: 74  | total loss: [1m[32m0.68308[0m[0m | time: 2.448s
[2K
| Adam | epoch: 008 | loss: 0.68308 - acc: 0.5759 -- iter: 128/309
[A[ATraining Step: 75  | total loss: [1m[32m0.68341[0m[0m | time: 3.091s
[2K
| Adam | epoch: 008 | loss: 0.68341 - acc: 0.5745 -- iter: 160/309
[A[ATraining Step: 76  | total loss: [1m[32m0.68623[0m[0m | time: 3.511s
[2K
| Adam | epoch: 008 | loss: 0.68623 - acc: 0.5632 -- iter: 192/309
[A[ATraining Step: 77  | total loss: [1m[32m0.68203[0m[0m | time: 3.937s
[2K
| Adam | epoch: 008 | loss: 0.68203 - acc: 0.5792 -- iter: 224/309
[A[ATraining Step: 78  | total loss: [1m[32m0.68330[0m[0m | time: 4.559s
[2K
| Adam | epoch: 008 | loss: 0.68330 - acc: 0.5734 -- iter: 256/309
[A[ATraining Step: 79  | total loss: [1m[32m0.68166[0m[0m | time: 5.169s
[2K
| Adam | epoch: 008 | loss: 0.68166 - acc: 0.5787 -- iter: 288/309
[A[ATraining Step: 80  | total loss: [1m[32m0.68299[0m[0m | time: 6.823s
[2K
| Adam | epoch: 008 | loss: 0.68299 - acc: 0.5739 | val_loss: 0.68107 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 81  | total loss: [1m[32m0.67979[0m[0m | time: 0.617s
[2K
| Adam | epoch: 009 | loss: 0.67979 - acc: 0.5853 -- iter: 032/309
[A[ATraining Step: 82  | total loss: [1m[32m0.68291[0m[0m | time: 1.226s
[2K
| Adam | epoch: 009 | loss: 0.68291 - acc: 0.5737 -- iter: 064/309
[A[ATraining Step: 83  | total loss: [1m[32m0.68139[0m[0m | time: 1.854s
[2K
| Adam | epoch: 009 | loss: 0.68139 - acc: 0.5788 -- iter: 096/309
[A[ATraining Step: 84  | total loss: [1m[32m0.68353[0m[0m | time: 2.460s
[2K
| Adam | epoch: 009 | loss: 0.68353 - acc: 0.5709 -- iter: 128/309
[A[ATraining Step: 85  | total loss: [1m[32m0.68387[0m[0m | time: 3.073s
[2K
| Adam | epoch: 009 | loss: 0.68387 - acc: 0.5701 -- iter: 160/309
[A[ATraining Step: 86  | total loss: [1m[32m0.68150[0m[0m | time: 3.693s
[2K
| Adam | epoch: 009 | loss: 0.68150 - acc: 0.5787 -- iter: 192/309
[A[ATraining Step: 87  | total loss: [1m[32m0.68095[0m[0m | time: 4.102s
[2K
| Adam | epoch: 009 | loss: 0.68095 - acc: 0.5802 -- iter: 224/309
[A[ATraining Step: 88  | total loss: [1m[32m0.68242[0m[0m | time: 4.523s
[2K
| Adam | epoch: 009 | loss: 0.68242 - acc: 0.5746 -- iter: 256/309
[A[ATraining Step: 89  | total loss: [1m[32m0.68120[0m[0m | time: 5.148s
[2K
| Adam | epoch: 009 | loss: 0.68120 - acc: 0.5790 -- iter: 288/309
[A[ATraining Step: 90  | total loss: [1m[32m0.68177[0m[0m | time: 6.755s
[2K
| Adam | epoch: 009 | loss: 0.68177 - acc: 0.5774 | val_loss: 0.68049 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 91  | total loss: [1m[32m0.68397[0m[0m | time: 0.612s
[2K
| Adam | epoch: 010 | loss: 0.68397 - acc: 0.5696 -- iter: 032/309
[A[ATraining Step: 92  | total loss: [1m[32m0.68331[0m[0m | time: 1.233s
[2K
| Adam | epoch: 010 | loss: 0.68331 - acc: 0.5720 -- iter: 064/309
[A[ATraining Step: 93  | total loss: [1m[32m0.68157[0m[0m | time: 1.853s
[2K
| Adam | epoch: 010 | loss: 0.68157 - acc: 0.5773 -- iter: 096/309
[A[ATraining Step: 94  | total loss: [1m[32m0.68568[0m[0m | time: 2.480s
[2K
| Adam | epoch: 010 | loss: 0.68568 - acc: 0.5634 -- iter: 128/309
[A[ATraining Step: 95  | total loss: [1m[32m0.68470[0m[0m | time: 3.112s
[2K
| Adam | epoch: 010 | loss: 0.68470 - acc: 0.5664 -- iter: 160/309
[A[ATraining Step: 96  | total loss: [1m[32m0.68097[0m[0m | time: 3.721s
[2K
| Adam | epoch: 010 | loss: 0.68097 - acc: 0.5785 -- iter: 192/309
[A[ATraining Step: 97  | total loss: [1m[32m0.68139[0m[0m | time: 4.337s
[2K
| Adam | epoch: 010 | loss: 0.68139 - acc: 0.5769 -- iter: 224/309
[A[ATraining Step: 98  | total loss: [1m[32m0.67974[0m[0m | time: 4.753s
[2K
| Adam | epoch: 010 | loss: 0.67974 - acc: 0.5817 -- iter: 256/309
[A[ATraining Step: 99  | total loss: [1m[32m0.67839[0m[0m | time: 5.177s
[2K
| Adam | epoch: 010 | loss: 0.67839 - acc: 0.5854 -- iter: 288/309
[A[ATraining Step: 100  | total loss: [1m[32m0.68019[0m[0m | time: 6.790s
[2K
| Adam | epoch: 010 | loss: 0.68019 - acc: 0.5793 | val_loss: 0.67909 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 101  | total loss: [1m[32m0.68074[0m[0m | time: 0.590s
[2K
| Adam | epoch: 011 | loss: 0.68074 - acc: 0.5776 -- iter: 032/309
[A[ATraining Step: 102  | total loss: [1m[32m0.68402[0m[0m | time: 1.190s
[2K
| Adam | epoch: 011 | loss: 0.68402 - acc: 0.5667 -- iter: 064/309
[A[ATraining Step: 103  | total loss: [1m[32m0.68712[0m[0m | time: 1.808s
[2K
| Adam | epoch: 011 | loss: 0.68712 - acc: 0.5569 -- iter: 096/309
[A[ATraining Step: 104  | total loss: [1m[32m0.68670[0m[0m | time: 2.426s
[2K
| Adam | epoch: 011 | loss: 0.68670 - acc: 0.5575 -- iter: 128/309
[A[ATraining Step: 105  | total loss: [1m[32m0.68372[0m[0m | time: 3.037s
[2K
| Adam | epoch: 011 | loss: 0.68372 - acc: 0.5674 -- iter: 160/309
[A[ATraining Step: 106  | total loss: [1m[32m0.68114[0m[0m | time: 3.660s
[2K
| Adam | epoch: 011 | loss: 0.68114 - acc: 0.5762 -- iter: 192/309
[A[ATraining Step: 107  | total loss: [1m[32m0.67950[0m[0m | time: 4.297s
[2K
| Adam | epoch: 011 | loss: 0.67950 - acc: 0.5811 -- iter: 224/309
[A[ATraining Step: 108  | total loss: [1m[32m0.67795[0m[0m | time: 4.918s
[2K
| Adam | epoch: 011 | loss: 0.67795 - acc: 0.5855 -- iter: 256/309
[A[ATraining Step: 109  | total loss: [1m[32m0.67599[0m[0m | time: 5.356s
[2K
| Adam | epoch: 011 | loss: 0.67599 - acc: 0.5895 -- iter: 288/309
[A[ATraining Step: 110  | total loss: [1m[32m0.67776[0m[0m | time: 6.814s
[2K
| Adam | epoch: 011 | loss: 0.67776 - acc: 0.5829 | val_loss: 0.67492 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 111  | total loss: [1m[32m0.67938[0m[0m | time: 0.631s
[2K
| Adam | epoch: 012 | loss: 0.67938 - acc: 0.5770 -- iter: 032/309
[A[ATraining Step: 112  | total loss: [1m[32m0.67715[0m[0m | time: 1.247s
[2K
| Adam | epoch: 012 | loss: 0.67715 - acc: 0.5818 -- iter: 064/309
[A[ATraining Step: 113  | total loss: [1m[32m0.66934[0m[0m | time: 1.882s
[2K
| Adam | epoch: 012 | loss: 0.66934 - acc: 0.6017 -- iter: 096/309
[A[ATraining Step: 114  | total loss: [1m[32m0.66750[0m[0m | time: 2.489s
[2K
| Adam | epoch: 012 | loss: 0.66750 - acc: 0.6041 -- iter: 128/309
[A[ATraining Step: 115  | total loss: [1m[32m0.67272[0m[0m | time: 3.116s
[2K
| Adam | epoch: 012 | loss: 0.67272 - acc: 0.5937 -- iter: 160/309
[A[ATraining Step: 116  | total loss: [1m[32m0.67809[0m[0m | time: 3.726s
[2K
| Adam | epoch: 012 | loss: 0.67809 - acc: 0.5812 -- iter: 192/309
[A[ATraining Step: 117  | total loss: [1m[32m0.67778[0m[0m | time: 4.336s
[2K
| Adam | epoch: 012 | loss: 0.67778 - acc: 0.5793 -- iter: 224/309
[A[ATraining Step: 118  | total loss: [1m[32m0.67486[0m[0m | time: 4.944s
[2K
| Adam | epoch: 012 | loss: 0.67486 - acc: 0.5839 -- iter: 256/309
[A[ATraining Step: 119  | total loss: [1m[32m0.67551[0m[0m | time: 5.582s
[2K
| Adam | epoch: 012 | loss: 0.67551 - acc: 0.5786 -- iter: 288/309
[A[ATraining Step: 120  | total loss: [1m[32m0.67599[0m[0m | time: 7.011s
[2K
| Adam | epoch: 012 | loss: 0.67599 - acc: 0.5739 | val_loss: 0.66184 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 121  | total loss: [1m[32m0.67545[0m[0m | time: 0.475s
[2K
| Adam | epoch: 013 | loss: 0.67545 - acc: 0.5689 -- iter: 032/309
[A[ATraining Step: 122  | total loss: [1m[32m0.67755[0m[0m | time: 1.108s
[2K
| Adam | epoch: 013 | loss: 0.67755 - acc: 0.5596 -- iter: 064/309
[A[ATraining Step: 123  | total loss: [1m[32m0.67748[0m[0m | time: 1.707s
[2K
| Adam | epoch: 013 | loss: 0.67748 - acc: 0.5536 -- iter: 096/309
[A[ATraining Step: 124  | total loss: [1m[32m0.66966[0m[0m | time: 2.331s
[2K
| Adam | epoch: 013 | loss: 0.66966 - acc: 0.5670 -- iter: 128/309
[A[ATraining Step: 125  | total loss: [1m[32m0.66839[0m[0m | time: 2.926s
[2K
| Adam | epoch: 013 | loss: 0.66839 - acc: 0.5634 -- iter: 160/309
[A[ATraining Step: 126  | total loss: [1m[32m0.66682[0m[0m | time: 3.554s
[2K
| Adam | epoch: 013 | loss: 0.66682 - acc: 0.5634 -- iter: 192/309
[A[ATraining Step: 127  | total loss: [1m[32m0.65804[0m[0m | time: 4.172s
[2K
| Adam | epoch: 013 | loss: 0.65804 - acc: 0.5758 -- iter: 224/309
[A[ATraining Step: 128  | total loss: [1m[32m0.65626[0m[0m | time: 4.781s
[2K
| Adam | epoch: 013 | loss: 0.65626 - acc: 0.5713 -- iter: 256/309
[A[ATraining Step: 129  | total loss: [1m[32m0.66177[0m[0m | time: 5.392s
[2K
| Adam | epoch: 013 | loss: 0.66177 - acc: 0.5517 -- iter: 288/309
[A[ATraining Step: 130  | total loss: [1m[32m0.65326[0m[0m | time: 7.045s
[2K
| Adam | epoch: 013 | loss: 0.65326 - acc: 0.5684 | val_loss: 0.57703 - val_acc: 0.5773 -- iter: 309/309
--
Training Step: 131  | total loss: [1m[32m0.64643[0m[0m | time: 0.441s
[2K
| Adam | epoch: 014 | loss: 0.64643 - acc: 0.5803 -- iter: 032/309
[A[ATraining Step: 132  | total loss: [1m[32m0.64272[0m[0m | time: 0.864s
[2K
| Adam | epoch: 014 | loss: 0.64272 - acc: 0.5699 -- iter: 064/309
[A[ATraining Step: 133  | total loss: [1m[32m0.64241[0m[0m | time: 1.468s
[2K
| Adam | epoch: 014 | loss: 0.64241 - acc: 0.5558 -- iter: 096/309
[A[ATraining Step: 134  | total loss: [1m[32m0.61566[0m[0m | time: 2.136s
[2K
| Adam | epoch: 014 | loss: 0.61566 - acc: 0.5814 -- iter: 128/309
[A[ATraining Step: 135  | total loss: [1m[32m0.61923[0m[0m | time: 2.761s
[2K
| Adam | epoch: 014 | loss: 0.61923 - acc: 0.5764 -- iter: 160/309
[A[ATraining Step: 136  | total loss: [1m[32m0.59583[0m[0m | time: 3.365s
[2K
| Adam | epoch: 014 | loss: 0.59583 - acc: 0.5938 -- iter: 192/309
[A[ATraining Step: 137  | total loss: [1m[32m0.59078[0m[0m | time: 3.973s
[2K
| Adam | epoch: 014 | loss: 0.59078 - acc: 0.6094 -- iter: 224/309
[A[ATraining Step: 138  | total loss: [1m[32m0.57962[0m[0m | time: 4.636s
[2K
| Adam | epoch: 014 | loss: 0.57962 - acc: 0.6266 -- iter: 256/309
[A[ATraining Step: 139  | total loss: [1m[32m0.57294[0m[0m | time: 5.251s
[2K
| Adam | epoch: 014 | loss: 0.57294 - acc: 0.6420 -- iter: 288/309
[A[ATraining Step: 140  | total loss: [1m[32m0.56667[0m[0m | time: 6.878s
[2K
| Adam | epoch: 014 | loss: 0.56667 - acc: 0.6622 | val_loss: 0.47148 - val_acc: 0.8041 -- iter: 309/309
--
Training Step: 141  | total loss: [1m[32m0.56289[0m[0m | time: 0.615s
[2K
| Adam | epoch: 015 | loss: 0.56289 - acc: 0.6616 -- iter: 032/309
[A[ATraining Step: 142  | total loss: [1m[32m0.55642[0m[0m | time: 1.065s
[2K
| Adam | epoch: 015 | loss: 0.55642 - acc: 0.6673 -- iter: 064/309
[A[ATraining Step: 143  | total loss: [1m[32m0.55039[0m[0m | time: 1.472s
[2K
| Adam | epoch: 015 | loss: 0.55039 - acc: 0.6768 -- iter: 096/309
[A[ATraining Step: 144  | total loss: [1m[32m0.58074[0m[0m | time: 2.109s
[2K
| Adam | epoch: 015 | loss: 0.58074 - acc: 0.6520 -- iter: 128/309
[A[ATraining Step: 145  | total loss: [1m[32m0.57189[0m[0m | time: 2.733s
[2K
| Adam | epoch: 015 | loss: 0.57189 - acc: 0.6618 -- iter: 160/309
[A[ATraining Step: 146  | total loss: [1m[32m0.55575[0m[0m | time: 3.342s
[2K
| Adam | epoch: 015 | loss: 0.55575 - acc: 0.6800 -- iter: 192/309
[A[ATraining Step: 147  | total loss: [1m[32m0.54242[0m[0m | time: 3.949s
[2K
| Adam | epoch: 015 | loss: 0.54242 - acc: 0.6963 -- iter: 224/309
[A[ATraining Step: 148  | total loss: [1m[32m0.53632[0m[0m | time: 4.563s
[2K
| Adam | epoch: 015 | loss: 0.53632 - acc: 0.6923 -- iter: 256/309
[A[ATraining Step: 149  | total loss: [1m[32m0.53689[0m[0m | time: 5.194s
[2K
| Adam | epoch: 015 | loss: 0.53689 - acc: 0.6950 -- iter: 288/309
[A[ATraining Step: 150  | total loss: [1m[32m0.54156[0m[0m | time: 6.809s
[2K
| Adam | epoch: 015 | loss: 0.54156 - acc: 0.6942 | val_loss: 0.49058 - val_acc: 0.8144 -- iter: 309/309
--
Training Step: 151  | total loss: [1m[32m0.52496[0m[0m | time: 0.616s
[2K
| Adam | epoch: 016 | loss: 0.52496 - acc: 0.7061 -- iter: 032/309
[A[ATraining Step: 152  | total loss: [1m[32m0.51893[0m[0m | time: 1.237s
[2K
| Adam | epoch: 016 | loss: 0.51893 - acc: 0.7198 -- iter: 064/309
[A[ATraining Step: 153  | total loss: [1m[32m0.51816[0m[0m | time: 1.655s
[2K
| Adam | epoch: 016 | loss: 0.51816 - acc: 0.7197 -- iter: 096/309
[A[ATraining Step: 154  | total loss: [1m[32m0.50695[0m[0m | time: 2.071s
[2K
| Adam | epoch: 016 | loss: 0.50695 - acc: 0.7287 -- iter: 128/309
[A[ATraining Step: 155  | total loss: [1m[32m0.50179[0m[0m | time: 2.683s
[2K
| Adam | epoch: 016 | loss: 0.50179 - acc: 0.7415 -- iter: 160/309
[A[ATraining Step: 156  | total loss: [1m[32m0.50206[0m[0m | time: 3.318s
[2K
| Adam | epoch: 016 | loss: 0.50206 - acc: 0.7549 -- iter: 192/309
[A[ATraining Step: 157  | total loss: [1m[32m0.49238[0m[0m | time: 3.941s
[2K
| Adam | epoch: 016 | loss: 0.49238 - acc: 0.7638 -- iter: 224/309
[A[ATraining Step: 158  | total loss: [1m[32m0.48091[0m[0m | time: 4.541s
[2K
| Adam | epoch: 016 | loss: 0.48091 - acc: 0.7718 -- iter: 256/309
[A[ATraining Step: 159  | total loss: [1m[32m0.47905[0m[0m | time: 5.161s
[2K
| Adam | epoch: 016 | loss: 0.47905 - acc: 0.7790 -- iter: 288/309
[A[ATraining Step: 160  | total loss: [1m[32m0.46721[0m[0m | time: 6.773s
[2K
| Adam | epoch: 016 | loss: 0.46721 - acc: 0.7792 | val_loss: 0.42637 - val_acc: 0.8351 -- iter: 309/309
--
Training Step: 161  | total loss: [1m[32m0.45796[0m[0m | time: 0.605s
[2K
| Adam | epoch: 017 | loss: 0.45796 - acc: 0.7825 -- iter: 032/309
[A[ATraining Step: 162  | total loss: [1m[32m0.45436[0m[0m | time: 1.226s
[2K
| Adam | epoch: 017 | loss: 0.45436 - acc: 0.7855 -- iter: 064/309
[A[ATraining Step: 163  | total loss: [1m[32m0.44562[0m[0m | time: 1.829s
[2K
| Adam | epoch: 017 | loss: 0.44562 - acc: 0.7945 -- iter: 096/309
[A[ATraining Step: 164  | total loss: [1m[32m0.45670[0m[0m | time: 2.267s
[2K
| Adam | epoch: 017 | loss: 0.45670 - acc: 0.7838 -- iter: 128/309
[A[ATraining Step: 165  | total loss: [1m[32m0.45212[0m[0m | time: 2.694s
[2K
| Adam | epoch: 017 | loss: 0.45212 - acc: 0.7864 -- iter: 160/309
[A[ATraining Step: 166  | total loss: [1m[32m0.45032[0m[0m | time: 3.326s
[2K
| Adam | epoch: 017 | loss: 0.45032 - acc: 0.7887 -- iter: 192/309
[A[ATraining Step: 167  | total loss: [1m[32m0.43490[0m[0m | time: 3.964s
[2K
| Adam | epoch: 017 | loss: 0.43490 - acc: 0.8004 -- iter: 224/309
[A[ATraining Step: 168  | total loss: [1m[32m0.42308[0m[0m | time: 4.575s
[2K
| Adam | epoch: 017 | loss: 0.42308 - acc: 0.8016 -- iter: 256/309
[A[ATraining Step: 169  | total loss: [1m[32m0.44241[0m[0m | time: 5.202s
[2K
| Adam | epoch: 017 | loss: 0.44241 - acc: 0.7933 -- iter: 288/309
[A[ATraining Step: 170  | total loss: [1m[32m0.44571[0m[0m | time: 6.811s
[2K
| Adam | epoch: 017 | loss: 0.44571 - acc: 0.7984 | val_loss: 0.40384 - val_acc: 0.8454 -- iter: 309/309
--
Training Step: 171  | total loss: [1m[32m0.43857[0m[0m | time: 0.610s
[2K
| Adam | epoch: 018 | loss: 0.43857 - acc: 0.8029 -- iter: 032/309
[A[ATraining Step: 172  | total loss: [1m[32m0.42686[0m[0m | time: 1.215s
[2K
| Adam | epoch: 018 | loss: 0.42686 - acc: 0.8133 -- iter: 064/309
[A[ATraining Step: 173  | total loss: [1m[32m0.42429[0m[0m | time: 1.835s
[2K
| Adam | epoch: 018 | loss: 0.42429 - acc: 0.8226 -- iter: 096/309
[A[ATraining Step: 174  | total loss: [1m[32m0.42561[0m[0m | time: 2.437s
[2K
| Adam | epoch: 018 | loss: 0.42561 - acc: 0.8247 -- iter: 128/309
[A[ATraining Step: 175  | total loss: [1m[32m0.43550[0m[0m | time: 2.868s
[2K
| Adam | epoch: 018 | loss: 0.43550 - acc: 0.8078 -- iter: 160/309
[A[ATraining Step: 176  | total loss: [1m[32m0.43506[0m[0m | time: 3.283s
[2K
| Adam | epoch: 018 | loss: 0.43506 - acc: 0.8080 -- iter: 192/309
[A[ATraining Step: 177  | total loss: [1m[32m0.42427[0m[0m | time: 3.906s
[2K
| Adam | epoch: 018 | loss: 0.42427 - acc: 0.8129 -- iter: 224/309
[A[ATraining Step: 178  | total loss: [1m[32m0.42058[0m[0m | time: 4.537s
[2K
| Adam | epoch: 018 | loss: 0.42058 - acc: 0.8129 -- iter: 256/309
[A[ATraining Step: 179  | total loss: [1m[32m0.41842[0m[0m | time: 5.154s
[2K
| Adam | epoch: 018 | loss: 0.41842 - acc: 0.8160 -- iter: 288/309
[A[ATraining Step: 180  | total loss: [1m[32m0.41166[0m[0m | time: 6.777s
[2K
| Adam | epoch: 018 | loss: 0.41166 - acc: 0.8219 | val_loss: 0.45404 - val_acc: 0.7526 -- iter: 309/309
--
Training Step: 181  | total loss: [1m[32m0.43379[0m[0m | time: 0.603s
[2K
| Adam | epoch: 019 | loss: 0.43379 - acc: 0.8022 -- iter: 032/309
[A[ATraining Step: 182  | total loss: [1m[32m0.42254[0m[0m | time: 1.203s
[2K
| Adam | epoch: 019 | loss: 0.42254 - acc: 0.8095 -- iter: 064/309
[A[ATraining Step: 183  | total loss: [1m[32m0.40225[0m[0m | time: 1.839s
[2K
| Adam | epoch: 019 | loss: 0.40225 - acc: 0.8223 -- iter: 096/309
[A[ATraining Step: 184  | total loss: [1m[32m0.40846[0m[0m | time: 2.456s
[2K
| Adam | epoch: 019 | loss: 0.40846 - acc: 0.8150 -- iter: 128/309
[A[ATraining Step: 185  | total loss: [1m[32m0.38752[0m[0m | time: 3.053s
[2K
| Adam | epoch: 019 | loss: 0.38752 - acc: 0.8304 -- iter: 160/309
[A[ATraining Step: 186  | total loss: [1m[32m0.38657[0m[0m | time: 3.481s
[2K
| Adam | epoch: 019 | loss: 0.38657 - acc: 0.8349 -- iter: 192/309
[A[ATraining Step: 187  | total loss: [1m[32m0.37280[0m[0m | time: 3.904s
[2K
| Adam | epoch: 019 | loss: 0.37280 - acc: 0.8419 -- iter: 224/309
[A[ATraining Step: 188  | total loss: [1m[32m0.37253[0m[0m | time: 4.513s
[2K
| Adam | epoch: 019 | loss: 0.37253 - acc: 0.8386 -- iter: 256/309
[A[ATraining Step: 189  | total loss: [1m[32m0.36467[0m[0m | time: 5.119s
[2K
| Adam | epoch: 019 | loss: 0.36467 - acc: 0.8423 -- iter: 288/309
[A[ATraining Step: 190  | total loss: [1m[32m0.35450[0m[0m | time: 6.763s
[2K
| Adam | epoch: 019 | loss: 0.35450 - acc: 0.8487 | val_loss: 0.45246 - val_acc: 0.7732 -- iter: 309/309
--
Training Step: 191  | total loss: [1m[32m0.35699[0m[0m | time: 0.615s
[2K
| Adam | epoch: 020 | loss: 0.35699 - acc: 0.8513 -- iter: 032/309
[A[ATraining Step: 192  | total loss: [1m[32m0.35646[0m[0m | time: 1.221s
[2K
| Adam | epoch: 020 | loss: 0.35646 - acc: 0.8505 -- iter: 064/309
[A[ATraining Step: 193  | total loss: [1m[32m0.36647[0m[0m | time: 1.843s
[2K
| Adam | epoch: 020 | loss: 0.36647 - acc: 0.8436 -- iter: 096/309
[A[ATraining Step: 194  | total loss: [1m[32m0.35583[0m[0m | time: 2.476s
[2K
| Adam | epoch: 020 | loss: 0.35583 - acc: 0.8468 -- iter: 128/309
[A[ATraining Step: 195  | total loss: [1m[32m0.35472[0m[0m | time: 3.090s
[2K
| Adam | epoch: 020 | loss: 0.35472 - acc: 0.8465 -- iter: 160/309
[A[ATraining Step: 196  | total loss: [1m[32m0.35239[0m[0m | time: 3.700s
[2K
| Adam | epoch: 020 | loss: 0.35239 - acc: 0.8524 -- iter: 192/309
[A[ATraining Step: 197  | total loss: [1m[32m0.34976[0m[0m | time: 4.120s
[2K
| Adam | epoch: 020 | loss: 0.34976 - acc: 0.8484 -- iter: 224/309
[A[ATraining Step: 198  | total loss: [1m[32m0.33387[0m[0m | time: 4.544s
[2K
| Adam | epoch: 020 | loss: 0.33387 - acc: 0.8588 -- iter: 256/309
[A[ATraining Step: 199  | total loss: [1m[32m0.37453[0m[0m | time: 5.161s
[2K
| Adam | epoch: 020 | loss: 0.37453 - acc: 0.8587 -- iter: 288/309
[A[ATraining Step: 200  | total loss: [1m[32m0.36969[0m[0m | time: 6.770s
[2K
| Adam | epoch: 020 | loss: 0.36969 - acc: 0.8572 | val_loss: 0.41935 - val_acc: 0.7835 -- iter: 309/309
--
Training Step: 201  | total loss: [1m[32m0.35202[0m[0m | time: 0.630s
[2K
| Adam | epoch: 021 | loss: 0.35202 - acc: 0.8652 -- iter: 032/309
[A[ATraining Step: 202  | total loss: [1m[32m0.35353[0m[0m | time: 1.239s
[2K
| Adam | epoch: 021 | loss: 0.35353 - acc: 0.8662 -- iter: 064/309
[A[ATraining Step: 203  | total loss: [1m[32m0.33017[0m[0m | time: 1.869s
[2K
| Adam | epoch: 021 | loss: 0.33017 - acc: 0.8796 -- iter: 096/309
[A[ATraining Step: 204  | total loss: [1m[32m0.33119[0m[0m | time: 2.481s
[2K
| Adam | epoch: 021 | loss: 0.33119 - acc: 0.8729 -- iter: 128/309
[A[ATraining Step: 205  | total loss: [1m[32m0.33829[0m[0m | time: 3.121s
[2K
| Adam | epoch: 021 | loss: 0.33829 - acc: 0.8668 -- iter: 160/309
[A[ATraining Step: 206  | total loss: [1m[32m0.32773[0m[0m | time: 3.743s
[2K
| Adam | epoch: 021 | loss: 0.32773 - acc: 0.8739 -- iter: 192/309
[A[ATraining Step: 207  | total loss: [1m[32m0.32340[0m[0m | time: 4.358s
[2K
| Adam | epoch: 021 | loss: 0.32340 - acc: 0.8771 -- iter: 224/309
[A[ATraining Step: 208  | total loss: [1m[32m0.31137[0m[0m | time: 4.771s
[2K
| Adam | epoch: 021 | loss: 0.31137 - acc: 0.8832 -- iter: 256/309
[A[ATraining Step: 209  | total loss: [1m[32m0.30366[0m[0m | time: 5.200s
[2K
| Adam | epoch: 021 | loss: 0.30366 - acc: 0.8758 -- iter: 288/309
[A[ATraining Step: 210  | total loss: [1m[32m0.30229[0m[0m | time: 6.835s
[2K
| Adam | epoch: 021 | loss: 0.30229 - acc: 0.8787 | val_loss: 0.42888 - val_acc: 0.8557 -- iter: 309/309
--
Training Step: 211  | total loss: [1m[32m0.29513[0m[0m | time: 0.634s
[2K
| Adam | epoch: 022 | loss: 0.29513 - acc: 0.8815 -- iter: 032/309
[A[ATraining Step: 212  | total loss: [1m[32m0.30759[0m[0m | time: 1.271s
[2K
| Adam | epoch: 022 | loss: 0.30759 - acc: 0.8746 -- iter: 064/309
[A[ATraining Step: 213  | total loss: [1m[32m0.31370[0m[0m | time: 2.027s
[2K
| Adam | epoch: 022 | loss: 0.31370 - acc: 0.8684 -- iter: 096/309
[A[ATraining Step: 214  | total loss: [1m[32m0.32464[0m[0m | time: 2.765s
[2K
| Adam | epoch: 022 | loss: 0.32464 - acc: 0.8628 -- iter: 128/309
[A[ATraining Step: 215  | total loss: [1m[32m0.30779[0m[0m | time: 3.517s
[2K
| Adam | epoch: 022 | loss: 0.30779 - acc: 0.8765 -- iter: 160/309
[A[ATraining Step: 216  | total loss: [1m[32m0.30117[0m[0m | time: 4.258s
[2K
| Adam | epoch: 022 | loss: 0.30117 - acc: 0.8763 -- iter: 192/309
[A[ATraining Step: 217  | total loss: [1m[32m0.29838[0m[0m | time: 4.995s
[2K
| Adam | epoch: 022 | loss: 0.29838 - acc: 0.8762 -- iter: 224/309
[A[ATraining Step: 218  | total loss: [1m[32m0.29312[0m[0m | time: 5.752s
[2K
| Adam | epoch: 022 | loss: 0.29312 - acc: 0.8855 -- iter: 256/309
[A[ATraining Step: 219  | total loss: [1m[32m0.27337[0m[0m | time: 6.290s
[2K
| Adam | epoch: 022 | loss: 0.27337 - acc: 0.8969 -- iter: 288/309
[A[ATraining Step: 220  | total loss: [1m[32m0.26544[0m[0m | time: 7.754s
[2K
| Adam | epoch: 022 | loss: 0.26544 - acc: 0.9025 | val_loss: 0.40543 - val_acc: 0.8351 -- iter: 309/309
--
Training Step: 221  | total loss: [1m[32m0.26814[0m[0m | time: 0.737s
[2K
| Adam | epoch: 023 | loss: 0.26814 - acc: 0.8979 -- iter: 032/309
[A[ATraining Step: 222  | total loss: [1m[32m0.26578[0m[0m | time: 1.462s
[2K
| Adam | epoch: 023 | loss: 0.26578 - acc: 0.8956 -- iter: 064/309
[A[ATraining Step: 223  | total loss: [1m[32m0.25589[0m[0m | time: 2.187s
[2K
| Adam | epoch: 023 | loss: 0.25589 - acc: 0.9029 -- iter: 096/309
[A[ATraining Step: 224  | total loss: [1m[32m0.25826[0m[0m | time: 2.918s
[2K
| Adam | epoch: 023 | loss: 0.25826 - acc: 0.9002 -- iter: 128/309
[A[ATraining Step: 225  | total loss: [1m[32m0.25143[0m[0m | time: 3.631s
[2K
| Adam | epoch: 023 | loss: 0.25143 - acc: 0.9039 -- iter: 160/309
[A[ATraining Step: 226  | total loss: [1m[32m0.24216[0m[0m | time: 4.357s
[2K
| Adam | epoch: 023 | loss: 0.24216 - acc: 0.9072 -- iter: 192/309
[A[ATraining Step: 227  | total loss: [1m[32m0.24208[0m[0m | time: 5.139s
[2K
| Adam | epoch: 023 | loss: 0.24208 - acc: 0.9071 -- iter: 224/309
[A[ATraining Step: 228  | total loss: [1m[32m0.23005[0m[0m | time: 5.971s
[2K
| Adam | epoch: 023 | loss: 0.23005 - acc: 0.9133 -- iter: 256/309
[A[ATraining Step: 229  | total loss: [1m[32m0.23558[0m[0m | time: 6.614s
[2K
| Adam | epoch: 023 | loss: 0.23558 - acc: 0.9095 -- iter: 288/309
[A[ATraining Step: 230  | total loss: [1m[32m0.23358[0m[0m | time: 8.031s
[2K
| Adam | epoch: 023 | loss: 0.23358 - acc: 0.9092 | val_loss: 0.33215 - val_acc: 0.8247 -- iter: 309/309
--
Training Step: 231  | total loss: [1m[32m0.22739[0m[0m | time: 0.577s
[2K
| Adam | epoch: 024 | loss: 0.22739 - acc: 0.9087 -- iter: 032/309
[A[ATraining Step: 232  | total loss: [1m[32m0.23156[0m[0m | time: 1.328s
[2K
| Adam | epoch: 024 | loss: 0.23156 - acc: 0.9083 -- iter: 064/309
[A[ATraining Step: 233  | total loss: [1m[32m0.23420[0m[0m | time: 2.048s
[2K
| Adam | epoch: 024 | loss: 0.23420 - acc: 0.9050 -- iter: 096/309
[A[ATraining Step: 234  | total loss: [1m[32m0.21958[0m[0m | time: 2.778s
[2K
| Adam | epoch: 024 | loss: 0.21958 - acc: 0.9145 -- iter: 128/309
[A[ATraining Step: 235  | total loss: [1m[32m0.21263[0m[0m | time: 3.528s
[2K
| Adam | epoch: 024 | loss: 0.21263 - acc: 0.9199 -- iter: 160/309
[A[ATraining Step: 236  | total loss: [1m[32m0.19924[0m[0m | time: 4.275s
[2K
| Adam | epoch: 024 | loss: 0.19924 - acc: 0.9279 -- iter: 192/309
[A[ATraining Step: 237  | total loss: [1m[32m0.19726[0m[0m | time: 5.022s
[2K
| Adam | epoch: 024 | loss: 0.19726 - acc: 0.9289 -- iter: 224/309
[A[ATraining Step: 238  | total loss: [1m[32m0.18410[0m[0m | time: 5.737s
[2K
| Adam | epoch: 024 | loss: 0.18410 - acc: 0.9360 -- iter: 256/309
[A[ATraining Step: 239  | total loss: [1m[32m0.16975[0m[0m | time: 6.475s
[2K
| Adam | epoch: 024 | loss: 0.16975 - acc: 0.9424 -- iter: 288/309
[A[ATraining Step: 240  | total loss: [1m[32m0.16926[0m[0m | time: 8.254s
[2K
| Adam | epoch: 024 | loss: 0.16926 - acc: 0.9388 | val_loss: 0.50296 - val_acc: 0.8247 -- iter: 309/309
--
Training Step: 241  | total loss: [1m[32m0.17540[0m[0m | time: 0.434s
[2K
| Adam | epoch: 025 | loss: 0.17540 - acc: 0.9387 -- iter: 032/309
[A[ATraining Step: 242  | total loss: [1m[32m0.16650[0m[0m | time: 0.855s
[2K
| Adam | epoch: 025 | loss: 0.16650 - acc: 0.9448 -- iter: 064/309
[A[ATraining Step: 243  | total loss: [1m[32m0.16549[0m[0m | time: 1.529s
[2K
| Adam | epoch: 025 | loss: 0.16549 - acc: 0.9408 -- iter: 096/309
[A[ATraining Step: 244  | total loss: [1m[32m0.15115[0m[0m | time: 2.237s
[2K
| Adam | epoch: 025 | loss: 0.15115 - acc: 0.9467 -- iter: 128/309
[A[ATraining Step: 245  | total loss: [1m[32m0.13849[0m[0m | time: 2.969s
[2K
| Adam | epoch: 025 | loss: 0.13849 - acc: 0.9520 -- iter: 160/309
[A[ATraining Step: 246  | total loss: [1m[32m0.14463[0m[0m | time: 3.740s
[2K
| Adam | epoch: 025 | loss: 0.14463 - acc: 0.9506 -- iter: 192/309
[A[ATraining Step: 247  | total loss: [1m[32m0.14377[0m[0m | time: 4.544s
[2K
| Adam | epoch: 025 | loss: 0.14377 - acc: 0.9493 -- iter: 224/309
[A[ATraining Step: 248  | total loss: [1m[32m0.13477[0m[0m | time: 5.291s
[2K
| Adam | epoch: 025 | loss: 0.13477 - acc: 0.9512 -- iter: 256/309
[A[ATraining Step: 249  | total loss: [1m[32m0.12363[0m[0m | time: 6.024s
[2K
| Adam | epoch: 025 | loss: 0.12363 - acc: 0.9561 -- iter: 288/309
[A[ATraining Step: 250  | total loss: [1m[32m0.11527[0m[0m | time: 7.796s
[2K
| Adam | epoch: 025 | loss: 0.11527 - acc: 0.9605 | val_loss: 0.37779 - val_acc: 0.8557 -- iter: 309/309
--
Training Step: 251  | total loss: [1m[32m0.11662[0m[0m | time: 0.800s
[2K
| Adam | epoch: 026 | loss: 0.11662 - acc: 0.9613 -- iter: 032/309
[A[ATraining Step: 252  | total loss: [1m[32m0.10916[0m[0m | time: 1.300s
[2K
| Adam | epoch: 026 | loss: 0.10916 - acc: 0.9652 -- iter: 064/309
[A[ATraining Step: 253  | total loss: [1m[32m0.10070[0m[0m | time: 1.809s
[2K
| Adam | epoch: 026 | loss: 0.10070 - acc: 0.9687 -- iter: 096/309
[A[ATraining Step: 254  | total loss: [1m[32m0.12657[0m[0m | time: 2.562s
[2K
| Adam | epoch: 026 | loss: 0.12657 - acc: 0.9623 -- iter: 128/309
[A[ATraining Step: 255  | total loss: [1m[32m0.11591[0m[0m | time: 3.295s
[2K
| Adam | epoch: 026 | loss: 0.11591 - acc: 0.9660 -- iter: 160/309
[A[ATraining Step: 256  | total loss: [1m[32m0.10639[0m[0m | time: 4.124s
[2K
| Adam | epoch: 026 | loss: 0.10639 - acc: 0.9694 -- iter: 192/309
[A[ATraining Step: 257  | total loss: [1m[32m0.09668[0m[0m | time: 4.839s
[2K
| Adam | epoch: 026 | loss: 0.09668 - acc: 0.9725 -- iter: 224/309
[A[ATraining Step: 258  | total loss: [1m[32m0.09805[0m[0m | time: 5.453s
[2K
| Adam | epoch: 026 | loss: 0.09805 - acc: 0.9721 -- iter: 256/309
[A[ATraining Step: 259  | total loss: [1m[32m0.09229[0m[0m | time: 6.056s
[2K
| Adam | epoch: 026 | loss: 0.09229 - acc: 0.9749 -- iter: 288/309
[A[ATraining Step: 260  | total loss: [1m[32m0.08565[0m[0m | time: 7.687s
[2K
| Adam | epoch: 026 | loss: 0.08565 - acc: 0.9774 | val_loss: 0.71978 - val_acc: 0.7835 -- iter: 309/309
--
Training Step: 261  | total loss: [1m[32m0.08056[0m[0m | time: 0.758s
[2K
| Adam | epoch: 027 | loss: 0.08056 - acc: 0.9797 -- iter: 032/309
[A[ATraining Step: 262  | total loss: [1m[32m0.09121[0m[0m | time: 1.483s
[2K
| Adam | epoch: 027 | loss: 0.09121 - acc: 0.9692 -- iter: 064/309
[A[ATraining Step: 263  | total loss: [1m[32m0.08305[0m[0m | time: 1.985s
[2K
| Adam | epoch: 027 | loss: 0.08305 - acc: 0.9723 -- iter: 096/309
[A[ATraining Step: 264  | total loss: [1m[32m0.07524[0m[0m | time: 2.550s
[2K
| Adam | epoch: 027 | loss: 0.07524 - acc: 0.9751 -- iter: 128/309
[A[ATraining Step: 265  | total loss: [1m[32m0.10167[0m[0m | time: 3.301s
[2K
| Adam | epoch: 027 | loss: 0.10167 - acc: 0.9728 -- iter: 160/309
[A[ATraining Step: 266  | total loss: [1m[32m0.10826[0m[0m | time: 4.049s
[2K
| Adam | epoch: 027 | loss: 0.10826 - acc: 0.9693 -- iter: 192/309
[A[ATraining Step: 267  | total loss: [1m[32m0.11323[0m[0m | time: 4.768s
[2K
| Adam | epoch: 027 | loss: 0.11323 - acc: 0.9630 -- iter: 224/309
[A[ATraining Step: 268  | total loss: [1m[32m0.10427[0m[0m | time: 5.513s
[2K
| Adam | epoch: 027 | loss: 0.10427 - acc: 0.9667 -- iter: 256/309
[A[ATraining Step: 269  | total loss: [1m[32m0.09493[0m[0m | time: 6.261s
[2K
| Adam | epoch: 027 | loss: 0.09493 - acc: 0.9700 -- iter: 288/309
[A[ATraining Step: 270  | total loss: [1m[32m0.09260[0m[0m | time: 8.034s
[2K
| Adam | epoch: 027 | loss: 0.09260 - acc: 0.9699 | val_loss: 0.84964 - val_acc: 0.7732 -- iter: 309/309
--
Training Step: 271  | total loss: [1m[32m0.09056[0m[0m | time: 0.625s
[2K
| Adam | epoch: 028 | loss: 0.09056 - acc: 0.9729 -- iter: 032/309
[A[ATraining Step: 272  | total loss: [1m[32m0.09038[0m[0m | time: 1.237s
[2K
| Adam | epoch: 028 | loss: 0.09038 - acc: 0.9725 -- iter: 064/309
[A[ATraining Step: 273  | total loss: [1m[32m0.08589[0m[0m | time: 1.859s
[2K
| Adam | epoch: 028 | loss: 0.08589 - acc: 0.9721 -- iter: 096/309
[A[ATraining Step: 274  | total loss: [1m[32m0.07808[0m[0m | time: 2.380s
[2K
| Adam | epoch: 028 | loss: 0.07808 - acc: 0.9749 -- iter: 128/309
[A[ATraining Step: 275  | total loss: [1m[32m0.07402[0m[0m | time: 2.878s
[2K
| Adam | epoch: 028 | loss: 0.07402 - acc: 0.9774 -- iter: 160/309
[A[ATraining Step: 276  | total loss: [1m[32m0.09692[0m[0m | time: 3.664s
[2K
| Adam | epoch: 028 | loss: 0.09692 - acc: 0.9749 -- iter: 192/309
[A[ATraining Step: 277  | total loss: [1m[32m0.10664[0m[0m | time: 4.467s
[2K
| Adam | epoch: 028 | loss: 0.10664 - acc: 0.9712 -- iter: 224/309
[A[ATraining Step: 278  | total loss: [1m[32m0.09929[0m[0m | time: 5.236s
[2K
| Adam | epoch: 028 | loss: 0.09929 - acc: 0.9740 -- iter: 256/309
[A[ATraining Step: 279  | total loss: [1m[32m0.09719[0m[0m | time: 6.004s
[2K
| Adam | epoch: 028 | loss: 0.09719 - acc: 0.9704 -- iter: 288/309
[A[ATraining Step: 280  | total loss: [1m[32m0.09035[0m[0m | time: 7.784s
[2K
| Adam | epoch: 028 | loss: 0.09035 - acc: 0.9734 | val_loss: 0.64019 - val_acc: 0.7629 -- iter: 309/309
--
Training Step: 281  | total loss: [1m[32m0.08446[0m[0m | time: 0.771s
[2K
| Adam | epoch: 029 | loss: 0.08446 - acc: 0.9760 -- iter: 032/309
[A[ATraining Step: 282  | total loss: [1m[32m0.07834[0m[0m | time: 1.528s
[2K
| Adam | epoch: 029 | loss: 0.07834 - acc: 0.9784 -- iter: 064/309
[A[ATraining Step: 283  | total loss: [1m[32m0.07392[0m[0m | time: 2.294s
[2K
| Adam | epoch: 029 | loss: 0.07392 - acc: 0.9806 -- iter: 096/309
[A[ATraining Step: 284  | total loss: [1m[32m0.07260[0m[0m | time: 3.040s
[2K
| Adam | epoch: 029 | loss: 0.07260 - acc: 0.9794 -- iter: 128/309
[A[ATraining Step: 285  | total loss: [1m[32m0.06860[0m[0m | time: 3.526s
[2K
| Adam | epoch: 029 | loss: 0.06860 - acc: 0.9815 -- iter: 160/309
[A[ATraining Step: 286  | total loss: [1m[32m0.06317[0m[0m | time: 4.078s
[2K
| Adam | epoch: 029 | loss: 0.06317 - acc: 0.9833 -- iter: 192/309
[A[ATraining Step: 287  | total loss: [1m[32m0.07679[0m[0m | time: 4.992s
[2K
| Adam | epoch: 029 | loss: 0.07679 - acc: 0.9802 -- iter: 224/309
[A[ATraining Step: 288  | total loss: [1m[32m0.07094[0m[0m | time: 5.630s
[2K
| Adam | epoch: 029 | loss: 0.07094 - acc: 0.9822 -- iter: 256/309
[A[ATraining Step: 289  | total loss: [1m[32m0.06533[0m[0m | time: 6.253s
[2K
| Adam | epoch: 029 | loss: 0.06533 - acc: 0.9840 -- iter: 288/309
[A[ATraining Step: 290  | total loss: [1m[32m0.06380[0m[0m | time: 7.917s
[2K
| Adam | epoch: 029 | loss: 0.06380 - acc: 0.9856 | val_loss: 0.49354 - val_acc: 0.8144 -- iter: 309/309
--
Training Step: 291  | total loss: [1m[32m0.05852[0m[0m | time: 0.760s
[2K
| Adam | epoch: 030 | loss: 0.05852 - acc: 0.9870 -- iter: 032/309
[A[ATraining Step: 292  | total loss: [1m[32m0.07840[0m[0m | time: 1.545s
[2K
| Adam | epoch: 030 | loss: 0.07840 - acc: 0.9821 -- iter: 064/309
[A[ATraining Step: 293  | total loss: [1m[32m0.07957[0m[0m | time: 2.299s
[2K
| Adam | epoch: 030 | loss: 0.07957 - acc: 0.9807 -- iter: 096/309
[A[ATraining Step: 294  | total loss: [1m[32m0.07539[0m[0m | time: 3.098s
[2K
| Adam | epoch: 030 | loss: 0.07539 - acc: 0.9827 -- iter: 128/309
[A[ATraining Step: 295  | total loss: [1m[32m0.07840[0m[0m | time: 3.884s
[2K
| Adam | epoch: 030 | loss: 0.07840 - acc: 0.9781 -- iter: 160/309
[A[ATraining Step: 296  | total loss: [1m[32m0.07708[0m[0m | time: 4.471s
[2K
| Adam | epoch: 030 | loss: 0.07708 - acc: 0.9772 -- iter: 192/309
[A[ATraining Step: 297  | total loss: [1m[32m0.07048[0m[0m | time: 4.987s
[2K
| Adam | epoch: 030 | loss: 0.07048 - acc: 0.9795 -- iter: 224/309
[A[ATraining Step: 298  | total loss: [1m[32m0.08850[0m[0m | time: 5.741s
[2K
| Adam | epoch: 030 | loss: 0.08850 - acc: 0.9768 -- iter: 256/309
[A[ATraining Step: 299  | total loss: [1m[32m0.08066[0m[0m | time: 6.506s
[2K
| Adam | epoch: 030 | loss: 0.08066 - acc: 0.9791 -- iter: 288/309
[A[ATraining Step: 300  | total loss: [1m[32m0.08276[0m[0m | time: 8.237s
[2K
| Adam | epoch: 030 | loss: 0.08276 - acc: 0.9749 | val_loss: 0.34201 - val_acc: 0.8763 -- iter: 309/309
--
Validation AUC:0.9525261324041812
Validation AUPRC:0.9608498472447665
Test AUC:0.948849104859335
Test AUPRC:0.9537038023161
BestTestF1Score	0.92	0.86	0.93	0.93	0.91	42	3	48	4	0.73
BestTestMCCScore	0.92	0.86	0.93	0.93	0.91	42	3	48	4	0.73
BestTestAccuracyScore	0.92	0.86	0.93	0.93	0.91	42	3	48	4	0.73
BestValidationF1Score	0.92	0.81	0.91	0.93	0.91	51	4	37	5	0.73
BestValidationMCC	0.92	0.81	0.91	0.93	0.91	51	4	37	5	0.73
BestValidationAccuracy	0.92	0.81	0.91	0.93	0.91	51	4	37	5	0.73
TestPredictions (Threshold:0.73)
CHEMBL3827193,FP,INACT,1.0	CHEMBL3677541,TP,ACT,1.0	CHEMBL1374573,TN,INACT,0.23999999463558197	CHEMBL1952305,TP,ACT,0.9700000286102295	CHEMBL3699449,TP,ACT,1.0	CHEMBL3682451,TP,ACT,1.0	CHEMBL3677610,TP,ACT,1.0	CHEMBL466198,TP,ACT,0.9800000190734863	CHEMBL1784260,TN,INACT,0.029999999329447746	CHEMBL1424468,TN,INACT,0.05999999865889549	CHEMBL2022680,TN,INACT,0.3100000023841858	CHEMBL1535728,TN,INACT,0.009999999776482582	CHEMBL2017114,TN,INACT,0.009999999776482582	CHEMBL3677561,TP,ACT,1.0	CHEMBL3098275,TN,INACT,0.36000001430511475	CHEMBL3680970,TP,ACT,1.0	CHEMBL3093308,TP,ACT,1.0	CHEMBL3677545,TP,ACT,1.0	CHEMBL1597933,TN,INACT,0.029999999329447746	CHEMBL3677611,TP,ACT,1.0	CHEMBL9352,TN,INACT,0.009999999776482582	CHEMBL3680961,TP,ACT,1.0	CHEMBL254196,TN,INACT,0.009999999776482582	CHEMBL202996,TN,INACT,0.029999999329447746	CHEMBL447111,TN,INACT,0.029999999329447746	CHEMBL3677539,TP,ACT,1.0	CHEMBL1460126,TN,INACT,0.009999999776482582	CHEMBL3677484,TP,ACT,1.0	CHEMBL3422850,TN,INACT,0.029999999329447746	CHEMBL240157,TN,INACT,0.03999999910593033	CHEMBL3677602,TP,ACT,1.0	CHEMBL3682448,TP,ACT,1.0	CHEMBL3677575,TP,ACT,1.0	CHEMBL3682468,TP,ACT,1.0	CHEMBL1439181,TN,INACT,0.009999999776482582	CHEMBL206764,TN,INACT,0.009999999776482582	CHEMBL1329455,TN,INACT,0.17000000178813934	CHEMBL3682484,TP,ACT,1.0	CHEMBL1466928,TN,INACT,0.05000000074505806	CHEMBL1487772,TN,INACT,0.05999999865889549	CHEMBL3677557,TP,ACT,1.0	CHEMBL3682469,TP,ACT,1.0	CHEMBL494252,TN,INACT,0.019999999552965164	CHEMBL1511524,TN,INACT,0.07000000029802322	CHEMBL3699450,FN,ACT,0.009999999776482582	CHEMBL3672613,TP,ACT,1.0	CHEMBL3696224,FN,ACT,0.05000000074505806	CHEMBL74022,TN,INACT,0.029999999329447746	CHEMBL3609152,TN,INACT,0.0	CHEMBL1393131,TN,INACT,0.05000000074505806	CHEMBL1482875,TN,INACT,0.009999999776482582	CHEMBL3207314,TN,INACT,0.25	CHEMBL3677614,TP,ACT,1.0	CHEMBL1550695,FP,INACT,0.8299999833106995	CHEMBL3677459,TP,ACT,1.0	CHEMBL3686720,TP,ACT,1.0	CHEMBL3677583,TP,ACT,1.0	CHEMBL1559853,TN,INACT,0.09000000357627869	CHEMBL1340020,TN,INACT,0.5299999713897705	CHEMBL3682463,TP,ACT,1.0	CHEMBL463804,TN,INACT,0.009999999776482582	CHEMBL1952296,TP,ACT,0.9900000095367432	CHEMBL3696230,FN,ACT,0.1899999976158142	CHEMBL3196534,TN,INACT,0.009999999776482582	CHEMBL3677587,TP,ACT,1.0	CHEMBL3195623,TN,INACT,0.28999999165534973	CHEMBL3677556,TP,ACT,1.0	CHEMBL1519669,TN,INACT,0.47999998927116394	CHEMBL3092450,TP,ACT,0.7400000095367432	CHEMBL468281,TP,ACT,0.8700000047683716	CHEMBL3677584,TP,ACT,0.9800000190734863	CHEMBL3093303,TP,ACT,0.9700000286102295	CHEMBL3682487,TP,ACT,0.9900000095367432	CHEMBL3827286,TN,INACT,0.0	CHEMBL1491602,TN,INACT,0.0	CHEMBL1519384,TN,INACT,0.009999999776482582	CHEMBL3677564,TP,ACT,1.0	CHEMBL1464837,TN,INACT,0.10000000149011612	CHEMBL425231,TN,INACT,0.009999999776482582	CHEMBL1452992,TN,INACT,0.009999999776482582	CHEMBL3622365,TN,INACT,0.09000000357627869	CHEMBL1548616,TN,INACT,0.46000000834465027	CHEMBL1472407,TN,INACT,0.20000000298023224	CHEMBL3680958,TP,ACT,0.9900000095367432	CHEMBL1347829,TN,INACT,0.009999999776482582	CHEMBL3682482,TP,ACT,1.0	CHEMBL3677636,TP,ACT,1.0	CHEMBL3696226,FN,ACT,0.03999999910593033	CHEMBL3125288,TN,INACT,0.3199999928474426	CHEMBL3682486,TP,ACT,1.0	CHEMBL15841,TN,INACT,0.029999999329447746	CHEMBL3677570,TP,ACT,1.0	CHEMBL382698,TN,INACT,0.009999999776482582	CHEMBL1346307,TN,INACT,0.05000000074505806	CHEMBL3680955,TP,ACT,1.0	CHEMBL1541552,FP,INACT,0.949999988079071	CHEMBL3609151,TN,INACT,0.4300000071525574	

