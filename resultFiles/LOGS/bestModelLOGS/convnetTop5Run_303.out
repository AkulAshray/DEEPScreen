ImageNetInceptionV2 CHEMBL6154 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	248
Number of inactive compounds :	248
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL6154_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL6154_adam_0.001_15_0.8/
---------------------------------
Training samples: 313
Validation samples: 98
--
Training Step: 1  | time: 76.655s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/313
[A[ATraining Step: 2  | total loss: [1m[32m0.59384[0m[0m | time: 100.556s
[2K
| Adam | epoch: 001 | loss: 0.59384 - acc: 0.5344 -- iter: 064/313
[A[ATraining Step: 3  | total loss: [1m[32m0.85043[0m[0m | time: 110.917s
[2K
| Adam | epoch: 001 | loss: 0.85043 - acc: 0.5574 -- iter: 096/313
[A[ATraining Step: 4  | total loss: [1m[32m0.73884[0m[0m | time: 118.920s
[2K
| Adam | epoch: 001 | loss: 0.73884 - acc: 0.5612 -- iter: 128/313
[A[ATraining Step: 5  | total loss: [1m[32m0.56211[0m[0m | time: 126.980s
[2K
| Adam | epoch: 001 | loss: 0.56211 - acc: 0.7352 -- iter: 160/313
[A[ATraining Step: 6  | total loss: [1m[32m0.66440[0m[0m | time: 139.004s
[2K
| Adam | epoch: 001 | loss: 0.66440 - acc: 0.6844 -- iter: 192/313
[A[ATraining Step: 7  | total loss: [1m[32m0.87136[0m[0m | time: 162.936s
[2K
| Adam | epoch: 001 | loss: 0.87136 - acc: 0.5738 -- iter: 224/313
[A[ATraining Step: 8  | total loss: [1m[32m0.74743[0m[0m | time: 193.814s
[2K
| Adam | epoch: 001 | loss: 0.74743 - acc: 0.5674 -- iter: 256/313
[A[ATraining Step: 9  | total loss: [1m[32m0.66908[0m[0m | time: 213.702s
[2K
| Adam | epoch: 001 | loss: 0.66908 - acc: 0.6806 -- iter: 288/313
[A[ATraining Step: 10  | total loss: [1m[32m0.67946[0m[0m | time: 250.794s
[2K
| Adam | epoch: 001 | loss: 0.67946 - acc: 0.6684 | val_loss: 0.71472 - val_acc: 0.4796 -- iter: 313/313
--
Training Step: 11  | total loss: [1m[32m0.65959[0m[0m | time: 11.864s
[2K
| Adam | epoch: 002 | loss: 0.65959 - acc: 0.6550 -- iter: 032/313
[A[ATraining Step: 12  | total loss: [1m[32m0.58230[0m[0m | time: 28.650s
[2K
| Adam | epoch: 002 | loss: 0.58230 - acc: 0.7022 -- iter: 064/313
[A[ATraining Step: 13  | total loss: [1m[32m0.57466[0m[0m | time: 48.324s
[2K
| Adam | epoch: 002 | loss: 0.57466 - acc: 0.6959 -- iter: 096/313
[A[ATraining Step: 14  | total loss: [1m[32m0.57477[0m[0m | time: 65.433s
[2K
| Adam | epoch: 002 | loss: 0.57477 - acc: 0.6797 -- iter: 128/313
[A[ATraining Step: 15  | total loss: [1m[32m0.52272[0m[0m | time: 82.553s
[2K
| Adam | epoch: 002 | loss: 0.52272 - acc: 0.7317 -- iter: 160/313
[A[ATraining Step: 16  | total loss: [1m[32m0.48778[0m[0m | time: 98.643s
[2K
| Adam | epoch: 002 | loss: 0.48778 - acc: 0.7385 -- iter: 192/313
[A[ATraining Step: 17  | total loss: [1m[32m0.46863[0m[0m | time: 111.994s
[2K
| Adam | epoch: 002 | loss: 0.46863 - acc: 0.7989 -- iter: 224/313
[A[ATraining Step: 18  | total loss: [1m[32m0.48269[0m[0m | time: 119.918s
[2K
| Adam | epoch: 002 | loss: 0.48269 - acc: 0.7820 -- iter: 256/313
[A[ATraining Step: 19  | total loss: [1m[32m0.50415[0m[0m | time: 127.752s
[2K
| Adam | epoch: 002 | loss: 0.50415 - acc: 0.7505 -- iter: 288/313
[A[ATraining Step: 20  | total loss: [1m[32m0.47478[0m[0m | time: 150.848s
[2K
| Adam | epoch: 002 | loss: 0.47478 - acc: 0.7704 | val_loss: 1.08824 - val_acc: 0.4796 -- iter: 313/313
--
Training Step: 21  | total loss: [1m[32m0.49298[0m[0m | time: 14.089s
[2K
| Adam | epoch: 003 | loss: 0.49298 - acc: 0.7447 -- iter: 032/313
[A[ATraining Step: 22  | total loss: [1m[32m0.44847[0m[0m | time: 28.235s
[2K
| Adam | epoch: 003 | loss: 0.44847 - acc: 0.7853 -- iter: 064/313
[A[ATraining Step: 23  | total loss: [1m[32m0.42349[0m[0m | time: 45.487s
[2K
| Adam | epoch: 003 | loss: 0.42349 - acc: 0.8128 -- iter: 096/313
[A[ATraining Step: 24  | total loss: [1m[32m0.39682[0m[0m | time: 62.218s
[2K
| Adam | epoch: 003 | loss: 0.39682 - acc: 0.8391 -- iter: 128/313
[A[ATraining Step: 25  | total loss: [1m[32m0.37905[0m[0m | time: 73.428s
[2K
| Adam | epoch: 003 | loss: 0.37905 - acc: 0.8574 -- iter: 160/313
[A[ATraining Step: 26  | total loss: [1m[32m0.36996[0m[0m | time: 81.546s
[2K
| Adam | epoch: 003 | loss: 0.36996 - acc: 0.8538 -- iter: 192/313
[A[ATraining Step: 27  | total loss: [1m[32m0.38625[0m[0m | time: 90.479s
[2K
| Adam | epoch: 003 | loss: 0.38625 - acc: 0.8271 -- iter: 224/313
[A[ATraining Step: 28  | total loss: [1m[32m0.37060[0m[0m | time: 104.238s
[2K
| Adam | epoch: 003 | loss: 0.37060 - acc: 0.8313 -- iter: 256/313
[A[ATraining Step: 29  | total loss: [1m[32m0.38563[0m[0m | time: 121.493s
[2K
| Adam | epoch: 003 | loss: 0.38563 - acc: 0.8191 -- iter: 288/313
[A[ATraining Step: 30  | total loss: [1m[32m0.39995[0m[0m | time: 152.789s
[2K
| Adam | epoch: 003 | loss: 0.39995 - acc: 0.7953 | val_loss: 1.32196 - val_acc: 0.4796 -- iter: 313/313
--
Training Step: 31  | total loss: [1m[32m0.38184[0m[0m | time: 12.795s
[2K
| Adam | epoch: 004 | loss: 0.38184 - acc: 0.8137 -- iter: 032/313
[A[ATraining Step: 32  | total loss: [1m[32m0.34218[0m[0m | time: 21.523s
[2K
| Adam | epoch: 004 | loss: 0.34218 - acc: 0.8486 -- iter: 064/313
[A[ATraining Step: 33  | total loss: [1m[32m0.31463[0m[0m | time: 30.654s
[2K
| Adam | epoch: 004 | loss: 0.31463 - acc: 0.8731 -- iter: 096/313
[A[ATraining Step: 34  | total loss: [1m[32m0.29665[0m[0m | time: 42.556s
[2K
| Adam | epoch: 004 | loss: 0.29665 - acc: 0.8831 -- iter: 128/313
[A[ATraining Step: 35  | total loss: [1m[32m0.26032[0m[0m | time: 59.693s
[2K
| Adam | epoch: 004 | loss: 0.26032 - acc: 0.9010 -- iter: 160/313
[A[ATraining Step: 36  | total loss: [1m[32m0.23321[0m[0m | time: 77.902s
[2K
| Adam | epoch: 004 | loss: 0.23321 - acc: 0.9085 -- iter: 192/313
[A[ATraining Step: 37  | total loss: [1m[32m0.21067[0m[0m | time: 97.399s
[2K
| Adam | epoch: 004 | loss: 0.21067 - acc: 0.9205 -- iter: 224/313
[A[ATraining Step: 38  | total loss: [1m[32m0.18563[0m[0m | time: 124.183s
[2K
| Adam | epoch: 004 | loss: 0.18563 - acc: 0.9300 -- iter: 256/313
[A[ATraining Step: 39  | total loss: [1m[32m0.19761[0m[0m | time: 135.921s
[2K
| Adam | epoch: 004 | loss: 0.19761 - acc: 0.9314 -- iter: 288/313
[A[ATraining Step: 40  | total loss: [1m[32m0.17465[0m[0m | time: 155.721s
[2K
| Adam | epoch: 004 | loss: 0.17465 - acc: 0.9384 | val_loss: 1.50415 - val_acc: 0.4796 -- iter: 313/313
--
Training Step: 41  | total loss: [1m[32m0.19257[0m[0m | time: 12.592s
[2K
| Adam | epoch: 005 | loss: 0.19257 - acc: 0.9325 -- iter: 032/313
[A[ATraining Step: 42  | total loss: [1m[32m0.21079[0m[0m | time: 27.826s
[2K
| Adam | epoch: 005 | loss: 0.21079 - acc: 0.9222 -- iter: 064/313
[A[ATraining Step: 43  | total loss: [1m[32m0.22530[0m[0m | time: 42.326s
[2K
| Adam | epoch: 005 | loss: 0.22530 - acc: 0.9194 -- iter: 096/313
[A[ATraining Step: 44  | total loss: [1m[32m0.20411[0m[0m | time: 55.854s
[2K
| Adam | epoch: 005 | loss: 0.20411 - acc: 0.9264 -- iter: 128/313
[A[ATraining Step: 45  | total loss: [1m[32m0.21421[0m[0m | time: 68.403s
[2K
| Adam | epoch: 005 | loss: 0.21421 - acc: 0.9185 -- iter: 160/313
[A[ATraining Step: 46  | total loss: [1m[32m0.24640[0m[0m | time: 82.455s
[2K
| Adam | epoch: 005 | loss: 0.24640 - acc: 0.8904 -- iter: 192/313
[A[ATraining Step: 47  | total loss: [1m[32m0.22273[0m[0m | time: 99.360s
[2K
| Adam | epoch: 005 | loss: 0.22273 - acc: 0.8981 -- iter: 224/313
[A[ATraining Step: 48  | total loss: [1m[32m0.20444[0m[0m | time: 115.740s
[2K
| Adam | epoch: 005 | loss: 0.20444 - acc: 0.9095 -- iter: 256/313
[A[ATraining Step: 49  | total loss: [1m[32m0.20562[0m[0m | time: 129.813s
[2K
| Adam | epoch: 005 | loss: 0.20562 - acc: 0.9188 -- iter: 288/313
[A[ATraining Step: 50  | total loss: [1m[32m0.20093[0m[0m | time: 149.673s
[2K
| Adam | epoch: 005 | loss: 0.20093 - acc: 0.9266 | val_loss: 0.84069 - val_acc: 0.8571 -- iter: 313/313
--
Training Step: 51  | total loss: [1m[32m0.22430[0m[0m | time: 17.144s
[2K
| Adam | epoch: 006 | loss: 0.22430 - acc: 0.9092 -- iter: 032/313
[A[ATraining Step: 52  | total loss: [1m[32m0.22654[0m[0m | time: 34.725s
[2K
| Adam | epoch: 006 | loss: 0.22654 - acc: 0.9041 -- iter: 064/313
[A[ATraining Step: 53  | total loss: [1m[32m0.22771[0m[0m | time: 51.676s
[2K
| Adam | epoch: 006 | loss: 0.22771 - acc: 0.8998 -- iter: 096/313
[A[ATraining Step: 54  | total loss: [1m[32m0.20757[0m[0m | time: 65.016s
[2K
| Adam | epoch: 006 | loss: 0.20757 - acc: 0.9098 -- iter: 128/313
[A[ATraining Step: 55  | total loss: [1m[32m0.20285[0m[0m | time: 78.573s
[2K
| Adam | epoch: 006 | loss: 0.20285 - acc: 0.9112 -- iter: 160/313
[A[ATraining Step: 56  | total loss: [1m[32m0.23638[0m[0m | time: 91.020s
[2K
| Adam | epoch: 006 | loss: 0.23638 - acc: 0.9068 -- iter: 192/313
[A[ATraining Step: 57  | total loss: [1m[32m0.21985[0m[0m | time: 99.217s
[2K
| Adam | epoch: 006 | loss: 0.21985 - acc: 0.9111 -- iter: 224/313
[A[ATraining Step: 58  | total loss: [1m[32m0.19806[0m[0m | time: 109.562s
[2K
| Adam | epoch: 006 | loss: 0.19806 - acc: 0.9232 -- iter: 256/313
[A[ATraining Step: 59  | total loss: [1m[32m0.19203[0m[0m | time: 125.457s
[2K
| Adam | epoch: 006 | loss: 0.19203 - acc: 0.9251 -- iter: 288/313
[A[ATraining Step: 60  | total loss: [1m[32m0.17427[0m[0m | time: 153.608s
[2K
| Adam | epoch: 006 | loss: 0.17427 - acc: 0.9350 | val_loss: 2.52333 - val_acc: 0.4796 -- iter: 313/313
--
Training Step: 61  | total loss: [1m[32m0.15536[0m[0m | time: 17.032s
[2K
| Adam | epoch: 007 | loss: 0.15536 - acc: 0.9435 -- iter: 032/313
[A[ATraining Step: 62  | total loss: [1m[32m0.14893[0m[0m | time: 29.893s
[2K
| Adam | epoch: 007 | loss: 0.14893 - acc: 0.9427 -- iter: 064/313
[A[ATraining Step: 63  | total loss: [1m[32m0.13610[0m[0m | time: 37.855s
[2K
| Adam | epoch: 007 | loss: 0.13610 - acc: 0.9500 -- iter: 096/313
[A[ATraining Step: 64  | total loss: [1m[32m0.13322[0m[0m | time: 47.199s
[2K
| Adam | epoch: 007 | loss: 0.13322 - acc: 0.9523 -- iter: 128/313
[A[ATraining Step: 65  | total loss: [1m[32m0.13489[0m[0m | time: 59.045s
[2K
| Adam | epoch: 007 | loss: 0.13489 - acc: 0.9544 -- iter: 160/313
[A[ATraining Step: 66  | total loss: [1m[32m0.13013[0m[0m | time: 73.079s
[2K
| Adam | epoch: 007 | loss: 0.13013 - acc: 0.9551 -- iter: 192/313
[A[ATraining Step: 67  | total loss: [1m[32m0.11732[0m[0m | time: 91.753s
[2K
| Adam | epoch: 007 | loss: 0.11732 - acc: 0.9604 -- iter: 224/313
[A[ATraining Step: 68  | total loss: [1m[32m0.12563[0m[0m | time: 114.487s
[2K
| Adam | epoch: 007 | loss: 0.12563 - acc: 0.9614 -- iter: 256/313
[A[ATraining Step: 69  | total loss: [1m[32m0.13084[0m[0m | time: 136.276s
[2K
| Adam | epoch: 007 | loss: 0.13084 - acc: 0.9623 -- iter: 288/313
[A[ATraining Step: 70  | total loss: [1m[32m0.14093[0m[0m | time: 161.448s
[2K
| Adam | epoch: 007 | loss: 0.14093 - acc: 0.9558 | val_loss: 1.07188 - val_acc: 0.7551 -- iter: 313/313
--
Training Step: 71  | total loss: [1m[32m0.13387[0m[0m | time: 9.305s
[2K
| Adam | epoch: 008 | loss: 0.13387 - acc: 0.9573 -- iter: 032/313
[A[ATraining Step: 72  | total loss: [1m[32m0.14634[0m[0m | time: 24.089s
[2K
| Adam | epoch: 008 | loss: 0.14634 - acc: 0.9480 -- iter: 064/313
[A[ATraining Step: 73  | total loss: [1m[32m0.15445[0m[0m | time: 35.874s
[2K
| Adam | epoch: 008 | loss: 0.15445 - acc: 0.9469 -- iter: 096/313
[A[ATraining Step: 74  | total loss: [1m[32m0.14121[0m[0m | time: 48.519s
[2K
| Adam | epoch: 008 | loss: 0.14121 - acc: 0.9527 -- iter: 128/313
[A[ATraining Step: 75  | total loss: [1m[32m0.12977[0m[0m | time: 60.577s
[2K
| Adam | epoch: 008 | loss: 0.12977 - acc: 0.9578 -- iter: 160/313
[A[ATraining Step: 76  | total loss: [1m[32m0.12130[0m[0m | time: 71.055s
[2K
| Adam | epoch: 008 | loss: 0.12130 - acc: 0.9623 -- iter: 192/313
[A[ATraining Step: 77  | total loss: [1m[32m0.13359[0m[0m | time: 81.665s
[2K
| Adam | epoch: 008 | loss: 0.13359 - acc: 0.9536 -- iter: 224/313
[A[ATraining Step: 78  | total loss: [1m[32m0.29736[0m[0m | time: 94.454s
[2K
| Adam | epoch: 008 | loss: 0.29736 - acc: 0.9208 -- iter: 256/313
[A[ATraining Step: 79  | total loss: [1m[32m0.27165[0m[0m | time: 102.433s
[2K
| Adam | epoch: 008 | loss: 0.27165 - acc: 0.9258 -- iter: 288/313
[A[ATraining Step: 80  | total loss: [1m[32m0.26260[0m[0m | time: 114.821s
[2K
| Adam | epoch: 008 | loss: 0.26260 - acc: 0.9238 | val_loss: 11.83756 - val_acc: 0.4796 -- iter: 313/313
--
Training Step: 81  | total loss: [1m[32m0.24533[0m[0m | time: 12.031s
[2K
| Adam | epoch: 009 | loss: 0.24533 - acc: 0.9283 -- iter: 032/313
[A[ATraining Step: 82  | total loss: [1m[32m0.23443[0m[0m | time: 24.490s
[2K
| Adam | epoch: 009 | loss: 0.23443 - acc: 0.9292 -- iter: 064/313
[A[ATraining Step: 83  | total loss: [1m[32m0.22732[0m[0m | time: 36.613s
[2K
| Adam | epoch: 009 | loss: 0.22732 - acc: 0.9269 -- iter: 096/313
[A[ATraining Step: 84  | total loss: [1m[32m0.23204[0m[0m | time: 49.200s
[2K
| Adam | epoch: 009 | loss: 0.23204 - acc: 0.9217 -- iter: 128/313
[A[ATraining Step: 85  | total loss: [1m[32m0.21562[0m[0m | time: 58.163s
[2K
| Adam | epoch: 009 | loss: 0.21562 - acc: 0.9296 -- iter: 160/313
[A[ATraining Step: 86  | total loss: [1m[32m0.23342[0m[0m | time: 66.084s
[2K
| Adam | epoch: 009 | loss: 0.23342 - acc: 0.9304 -- iter: 192/313
[A[ATraining Step: 87  | total loss: [1m[32m0.22111[0m[0m | time: 72.697s
[2K
| Adam | epoch: 009 | loss: 0.22111 - acc: 0.9342 -- iter: 224/313
[A[ATraining Step: 88  | total loss: [1m[32m0.20788[0m[0m | time: 79.130s
[2K
| Adam | epoch: 009 | loss: 0.20788 - acc: 0.9408 -- iter: 256/313
[A[ATraining Step: 89  | total loss: [1m[32m0.20443[0m[0m | time: 87.767s
[2K
| Adam | epoch: 009 | loss: 0.20443 - acc: 0.9387 -- iter: 288/313
[A[ATraining Step: 90  | total loss: [1m[32m0.20219[0m[0m | time: 107.220s
[2K
| Adam | epoch: 009 | loss: 0.20219 - acc: 0.9386 | val_loss: 0.58688 - val_acc: 0.8571 -- iter: 313/313
--
Training Step: 91  | total loss: [1m[32m0.18824[0m[0m | time: 12.035s
[2K
| Adam | epoch: 010 | loss: 0.18824 - acc: 0.9447 -- iter: 032/313
[A[ATraining Step: 92  | total loss: [1m[32m0.17435[0m[0m | time: 24.671s
[2K
| Adam | epoch: 010 | loss: 0.17435 - acc: 0.9503 -- iter: 064/313
[A[ATraining Step: 93  | total loss: [1m[32m0.17056[0m[0m | time: 34.278s
[2K
| Adam | epoch: 010 | loss: 0.17056 - acc: 0.9521 -- iter: 096/313
[A[ATraining Step: 94  | total loss: [1m[32m0.15746[0m[0m | time: 42.416s
[2K
| Adam | epoch: 010 | loss: 0.15746 - acc: 0.9569 -- iter: 128/313
[A[ATraining Step: 95  | total loss: [1m[32m0.15595[0m[0m | time: 50.371s
[2K
| Adam | epoch: 010 | loss: 0.15595 - acc: 0.9550 -- iter: 160/313
[A[ATraining Step: 96  | total loss: [1m[32m0.15156[0m[0m | time: 62.236s
[2K
| Adam | epoch: 010 | loss: 0.15156 - acc: 0.9563 -- iter: 192/313
[A[ATraining Step: 97  | total loss: [1m[32m0.14108[0m[0m | time: 74.328s
[2K
| Adam | epoch: 010 | loss: 0.14108 - acc: 0.9607 -- iter: 224/313
[A[ATraining Step: 98  | total loss: [1m[32m0.13318[0m[0m | time: 84.444s
[2K
| Adam | epoch: 010 | loss: 0.13318 - acc: 0.9615 -- iter: 256/313
[A[ATraining Step: 99  | total loss: [1m[32m0.12760[0m[0m | time: 94.802s
[2K
| Adam | epoch: 010 | loss: 0.12760 - acc: 0.9614 -- iter: 288/313
[A[ATraining Step: 100  | total loss: [1m[32m0.11592[0m[0m | time: 113.499s
[2K
| Adam | epoch: 010 | loss: 0.11592 - acc: 0.9652 | val_loss: 1.90767 - val_acc: 0.6531 -- iter: 313/313
--
Training Step: 101  | total loss: [1m[32m0.10733[0m[0m | time: 7.736s
[2K
| Adam | epoch: 011 | loss: 0.10733 - acc: 0.9687 -- iter: 032/313
[A[ATraining Step: 102  | total loss: [1m[32m0.10001[0m[0m | time: 15.578s
[2K
| Adam | epoch: 011 | loss: 0.10001 - acc: 0.9718 -- iter: 064/313
[A[ATraining Step: 103  | total loss: [1m[32m0.09400[0m[0m | time: 24.341s
[2K
| Adam | epoch: 011 | loss: 0.09400 - acc: 0.9715 -- iter: 096/313
[A[ATraining Step: 104  | total loss: [1m[32m0.08488[0m[0m | time: 35.321s
[2K
| Adam | epoch: 011 | loss: 0.08488 - acc: 0.9744 -- iter: 128/313
[A[ATraining Step: 105  | total loss: [1m[32m0.07998[0m[0m | time: 43.050s
[2K
| Adam | epoch: 011 | loss: 0.07998 - acc: 0.9769 -- iter: 160/313
[A[ATraining Step: 106  | total loss: [1m[32m0.07659[0m[0m | time: 50.981s
[2K
| Adam | epoch: 011 | loss: 0.07659 - acc: 0.9761 -- iter: 192/313
[A[ATraining Step: 107  | total loss: [1m[32m0.07236[0m[0m | time: 58.781s
[2K
| Adam | epoch: 011 | loss: 0.07236 - acc: 0.9785 -- iter: 224/313
[A[ATraining Step: 108  | total loss: [1m[32m0.07276[0m[0m | time: 66.694s
[2K
| Adam | epoch: 011 | loss: 0.07276 - acc: 0.9744 -- iter: 256/313
[A[ATraining Step: 109  | total loss: [1m[32m0.07161[0m[0m | time: 73.193s
[2K
| Adam | epoch: 011 | loss: 0.07161 - acc: 0.9738 -- iter: 288/313
[A[ATraining Step: 110  | total loss: [1m[32m0.07328[0m[0m | time: 84.097s
[2K
| Adam | epoch: 011 | loss: 0.07328 - acc: 0.9725 | val_loss: 2.30342 - val_acc: 0.6327 -- iter: 313/313
--
Training Step: 111  | total loss: [1m[32m0.06611[0m[0m | time: 7.800s
[2K
| Adam | epoch: 012 | loss: 0.06611 - acc: 0.9752 -- iter: 032/313
[A[ATraining Step: 112  | total loss: [1m[32m0.05995[0m[0m | time: 15.568s
[2K
| Adam | epoch: 012 | loss: 0.05995 - acc: 0.9777 -- iter: 064/313
[A[ATraining Step: 113  | total loss: [1m[32m0.05453[0m[0m | time: 23.532s
[2K
| Adam | epoch: 012 | loss: 0.05453 - acc: 0.9799 -- iter: 096/313
[A[ATraining Step: 114  | total loss: [1m[32m0.05542[0m[0m | time: 31.392s
[2K
| Adam | epoch: 012 | loss: 0.05542 - acc: 0.9757 -- iter: 128/313
[A[ATraining Step: 115  | total loss: [1m[32m0.05226[0m[0m | time: 39.157s
[2K
| Adam | epoch: 012 | loss: 0.05226 - acc: 0.9781 -- iter: 160/313
[A[ATraining Step: 116  | total loss: [1m[32m0.06230[0m[0m | time: 47.295s
[2K
| Adam | epoch: 012 | loss: 0.06230 - acc: 0.9772 -- iter: 192/313
[A[ATraining Step: 117  | total loss: [1m[32m0.09064[0m[0m | time: 55.083s
[2K
| Adam | epoch: 012 | loss: 0.09064 - acc: 0.9701 -- iter: 224/313
[A[ATraining Step: 118  | total loss: [1m[32m0.10976[0m[0m | time: 63.030s
[2K
| Adam | epoch: 012 | loss: 0.10976 - acc: 0.9668 -- iter: 256/313
[A[ATraining Step: 119  | total loss: [1m[32m0.10287[0m[0m | time: 70.712s
[2K
| Adam | epoch: 012 | loss: 0.10287 - acc: 0.9670 -- iter: 288/313
[A[ATraining Step: 120  | total loss: [1m[32m0.09303[0m[0m | time: 81.688s
[2K
| Adam | epoch: 012 | loss: 0.09303 - acc: 0.9703 | val_loss: 7.91805 - val_acc: 0.5000 -- iter: 313/313
--
Training Step: 121  | total loss: [1m[32m0.08850[0m[0m | time: 6.531s
[2K
| Adam | epoch: 013 | loss: 0.08850 - acc: 0.9733 -- iter: 032/313
[A[ATraining Step: 122  | total loss: [1m[32m0.13295[0m[0m | time: 14.316s
[2K
| Adam | epoch: 013 | loss: 0.13295 - acc: 0.9680 -- iter: 064/313
[A[ATraining Step: 123  | total loss: [1m[32m0.12061[0m[0m | time: 22.214s
[2K
| Adam | epoch: 013 | loss: 0.12061 - acc: 0.9712 -- iter: 096/313
[A[ATraining Step: 124  | total loss: [1m[32m0.11174[0m[0m | time: 30.045s
[2K
| Adam | epoch: 013 | loss: 0.11174 - acc: 0.9740 -- iter: 128/313
[A[ATraining Step: 125  | total loss: [1m[32m0.13409[0m[0m | time: 37.929s
[2K
| Adam | epoch: 013 | loss: 0.13409 - acc: 0.9641 -- iter: 160/313
[A[ATraining Step: 126  | total loss: [1m[32m0.15470[0m[0m | time: 45.844s
[2K
| Adam | epoch: 013 | loss: 0.15470 - acc: 0.9615 -- iter: 192/313
[A[ATraining Step: 127  | total loss: [1m[32m0.14244[0m[0m | time: 53.719s
[2K
| Adam | epoch: 013 | loss: 0.14244 - acc: 0.9653 -- iter: 224/313
[A[ATraining Step: 128  | total loss: [1m[32m0.15937[0m[0m | time: 61.674s
[2K
| Adam | epoch: 013 | loss: 0.15937 - acc: 0.9594 -- iter: 256/313
[A[ATraining Step: 129  | total loss: [1m[32m0.16570[0m[0m | time: 69.721s
[2K
| Adam | epoch: 013 | loss: 0.16570 - acc: 0.9541 -- iter: 288/313
[A[ATraining Step: 130  | total loss: [1m[32m0.16080[0m[0m | time: 82.009s
[2K
| Adam | epoch: 013 | loss: 0.16080 - acc: 0.9556 | val_loss: 5.20513 - val_acc: 0.5000 -- iter: 313/313
--
Training Step: 131  | total loss: [1m[32m0.16877[0m[0m | time: 6.578s
[2K
| Adam | epoch: 014 | loss: 0.16877 - acc: 0.9475 -- iter: 032/313
[A[ATraining Step: 132  | total loss: [1m[32m0.15605[0m[0m | time: 13.187s
[2K
| Adam | epoch: 014 | loss: 0.15605 - acc: 0.9528 -- iter: 064/313
[A[ATraining Step: 133  | total loss: [1m[32m0.14526[0m[0m | time: 21.071s
[2K
| Adam | epoch: 014 | loss: 0.14526 - acc: 0.9575 -- iter: 096/313
[A[ATraining Step: 134  | total loss: [1m[32m0.13378[0m[0m | time: 28.884s
[2K
| Adam | epoch: 014 | loss: 0.13378 - acc: 0.9617 -- iter: 128/313
[A[ATraining Step: 135  | total loss: [1m[32m0.12442[0m[0m | time: 36.893s
[2K
| Adam | epoch: 014 | loss: 0.12442 - acc: 0.9656 -- iter: 160/313
[A[ATraining Step: 136  | total loss: [1m[32m0.11390[0m[0m | time: 44.564s
[2K
| Adam | epoch: 014 | loss: 0.11390 - acc: 0.9690 -- iter: 192/313
[A[ATraining Step: 137  | total loss: [1m[32m0.10800[0m[0m | time: 52.393s
[2K
| Adam | epoch: 014 | loss: 0.10800 - acc: 0.9690 -- iter: 224/313
[A[ATraining Step: 138  | total loss: [1m[32m0.10126[0m[0m | time: 60.368s
[2K
| Adam | epoch: 014 | loss: 0.10126 - acc: 0.9721 -- iter: 256/313
[A[ATraining Step: 139  | total loss: [1m[32m0.11434[0m[0m | time: 68.254s
[2K
| Adam | epoch: 014 | loss: 0.11434 - acc: 0.9592 -- iter: 288/313
[A[ATraining Step: 140  | total loss: [1m[32m0.11186[0m[0m | time: 80.369s
[2K
| Adam | epoch: 014 | loss: 0.11186 - acc: 0.9602 | val_loss: 0.36677 - val_acc: 0.8571 -- iter: 313/313
--
Training Step: 141  | total loss: [1m[32m0.10479[0m[0m | time: 7.882s
[2K
| Adam | epoch: 015 | loss: 0.10479 - acc: 0.9642 -- iter: 032/313
[A[ATraining Step: 142  | total loss: [1m[32m0.09796[0m[0m | time: 14.386s
[2K
| Adam | epoch: 015 | loss: 0.09796 - acc: 0.9678 -- iter: 064/313
[A[ATraining Step: 143  | total loss: [1m[32m0.09575[0m[0m | time: 20.872s
[2K
| Adam | epoch: 015 | loss: 0.09575 - acc: 0.9670 -- iter: 096/313
[A[ATraining Step: 144  | total loss: [1m[32m0.12066[0m[0m | time: 28.560s
[2K
| Adam | epoch: 015 | loss: 0.12066 - acc: 0.9623 -- iter: 128/313
[A[ATraining Step: 145  | total loss: [1m[32m0.12148[0m[0m | time: 36.456s
[2K
| Adam | epoch: 015 | loss: 0.12148 - acc: 0.9598 -- iter: 160/313
[A[ATraining Step: 146  | total loss: [1m[32m0.11369[0m[0m | time: 44.450s
[2K
| Adam | epoch: 015 | loss: 0.11369 - acc: 0.9638 -- iter: 192/313
[A[ATraining Step: 147  | total loss: [1m[32m0.10352[0m[0m | time: 52.338s
[2K
| Adam | epoch: 015 | loss: 0.10352 - acc: 0.9674 -- iter: 224/313
[A[ATraining Step: 148  | total loss: [1m[32m0.10400[0m[0m | time: 60.293s
[2K
| Adam | epoch: 015 | loss: 0.10400 - acc: 0.9676 -- iter: 256/313
[A[ATraining Step: 149  | total loss: [1m[32m0.09550[0m[0m | time: 68.028s
[2K
| Adam | epoch: 015 | loss: 0.09550 - acc: 0.9708 -- iter: 288/313
[A[ATraining Step: 150  | total loss: [1m[32m0.08898[0m[0m | time: 80.329s
[2K
| Adam | epoch: 015 | loss: 0.08898 - acc: 0.9737 | val_loss: 0.36997 - val_acc: 0.8776 -- iter: 313/313
--
Validation AUC:0.9570296203587818
Validation AUPRC:0.9685291820418855
Test AUC:0.9
Test AUPRC:0.867776780989097
BestTestF1Score	0.85	0.7	0.85	0.82	0.88	42	9	41	6	0.63
BestTestMCCScore	0.86	0.74	0.87	0.89	0.83	40	5	45	8	0.93
BestTestAccuracyScore	0.86	0.74	0.87	0.89	0.83	40	5	45	8	0.93
BestValidationF1Score	0.9	0.8	0.9	0.89	0.92	47	6	41	4	0.63
BestValidationMCC	0.89	0.81	0.9	0.98	0.82	42	1	46	9	0.93
BestValidationAccuracy	0.89	0.81	0.9	0.98	0.82	42	1	46	9	0.93
TestPredictions (Threshold:0.93)
CHEMBL3594135,FP,INACT,1.0	CHEMBL2419693,TP,ACT,0.9900000095367432	CHEMBL3612653,TN,INACT,0.20000000298023224	CHEMBL2431867,TP,ACT,1.0	CHEMBL2322250,TN,INACT,0.019999999552965164	CHEMBL53738,TP,ACT,1.0	CHEMBL2407992,TN,INACT,0.0	CHEMBL3804939,TP,ACT,1.0	CHEMBL1215434,TN,INACT,0.0	CHEMBL3108871,FN,ACT,0.0	CHEMBL3594124,TP,ACT,0.9599999785423279	CHEMBL2430157,TN,INACT,0.0	CHEMBL372303,FN,ACT,0.009999999776482582	CHEMBL186141,TN,INACT,0.7300000190734863	CHEMBL3577701,TP,ACT,1.0	CHEMBL2425809,TP,ACT,1.0	CHEMBL2425797,TP,ACT,1.0	CHEMBL1900376,FN,ACT,0.0	CHEMBL2376863,TN,INACT,0.009999999776482582	CHEMBL2385995,TN,INACT,0.0	CHEMBL3359443,TN,INACT,0.23000000417232513	CHEMBL2386173,TN,INACT,0.0	CHEMBL3099716,TP,ACT,1.0	CHEMBL1949851,TN,INACT,0.0	CHEMBL340481,TP,ACT,1.0	CHEMBL2419696,FN,ACT,0.7599999904632568	CHEMBL168212,TN,INACT,0.3100000023841858	CHEMBL2425811,TP,ACT,0.9900000095367432	CHEMBL3682291,TN,INACT,0.6499999761581421	CHEMBL3698469,TN,INACT,0.019999999552965164	CHEMBL3289124,TN,INACT,0.0	CHEMBL182120,TN,INACT,0.0	CHEMBL2386181,TN,INACT,0.009999999776482582	CHEMBL1257010,TP,ACT,1.0	CHEMBL275638,TP,ACT,1.0	CHEMBL2425804,TP,ACT,0.949999988079071	CHEMBL3753510,FN,ACT,0.8100000023841858	CHEMBL3805393,TP,ACT,0.9300000071525574	CHEMBL336859,TN,INACT,0.25999999046325684	CHEMBL3594137,TP,ACT,1.0	CHEMBL1724183,TP,ACT,1.0	CHEMBL3325769,TN,INACT,0.0	CHEMBL353789,TN,INACT,0.7400000095367432	CHEMBL3098938,TP,ACT,1.0	CHEMBL2425789,TP,ACT,1.0	CHEMBL1446237,TP,ACT,1.0	CHEMBL2312052,TN,INACT,0.8899999856948853	CHEMBL1892778,FP,INACT,1.0	CHEMBL2312049,FP,INACT,0.9700000286102295	CHEMBL2425792,TP,ACT,1.0	CHEMBL338088,TP,ACT,1.0	CHEMBL2087069,TN,INACT,0.029999999329447746	CHEMBL3814530,TN,INACT,0.0	CHEMBL408340,TN,INACT,0.03999999910593033	CHEMBL2376860,TN,INACT,0.0	CHEMBL1319888,TP,ACT,1.0	CHEMBL2386004,TN,INACT,0.0	CHEMBL1949842,TN,INACT,0.0	CHEMBL410485,TN,INACT,0.5199999809265137	CHEMBL2419900,TP,ACT,1.0	CHEMBL346886,TP,ACT,1.0	CHEMBL3289109,TP,ACT,1.0	CHEMBL2417574,TP,ACT,1.0	CHEMBL265438,FP,INACT,0.9599999785423279	CHEMBL2430156,TN,INACT,0.009999999776482582	CHEMBL125759,TN,INACT,0.0	CHEMBL551775,FN,ACT,0.019999999552965164	CHEMBL1364326,TP,ACT,1.0	CHEMBL2386175,TN,INACT,0.029999999329447746	CHEMBL2425813,TP,ACT,1.0	CHEMBL1173055,FN,ACT,0.17000000178813934	CHEMBL1714359,TP,ACT,0.9599999785423279	CHEMBL2425791,FN,ACT,0.009999999776482582	CHEMBL3594128,TP,ACT,1.0	CHEMBL2376848,TN,INACT,0.0	CHEMBL3593717,TP,ACT,1.0	CHEMBL2419699,TP,ACT,0.9700000286102295	CHEMBL2419889,TP,ACT,1.0	CHEMBL2312057,FP,INACT,0.9700000286102295	CHEMBL210208,TN,INACT,0.0	CHEMBL2425796,TP,ACT,1.0	CHEMBL3359448,TN,INACT,0.019999999552965164	CHEMBL2408035,TN,INACT,0.0	CHEMBL2322255,TN,INACT,0.2199999988079071	CHEMBL115114,TN,INACT,0.0	CHEMBL3815132,TN,INACT,0.0	CHEMBL2419698,TP,ACT,0.9700000286102295	CHEMBL2322558,TN,INACT,0.0	CHEMBL2376850,TN,INACT,0.0	CHEMBL1949848,TN,INACT,0.0	CHEMBL1813880,TN,INACT,0.0	CHEMBL341142,TP,ACT,1.0	CHEMBL151728,TP,ACT,0.9399999976158142	CHEMBL3827963,TP,ACT,0.9900000095367432	CHEMBL3109647,TP,ACT,0.9900000095367432	CHEMBL605157,TN,INACT,0.0	CHEMBL3813917,TN,INACT,0.3100000023841858	CHEMBL2322545,TN,INACT,0.009999999776482582	

