ImageNetInceptionV2 CHEMBL1860 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	295
Number of inactive compounds :	295
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1860_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1860_adam_0.0005_15_0.8/
---------------------------------
Training samples: 366
Validation samples: 115
--
Training Step: 1  | time: 58.430s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/366
[A[ATraining Step: 2  | total loss: [1m[32m0.68750[0m[0m | time: 67.104s
[2K
| Adam | epoch: 001 | loss: 0.68750 - acc: 0.4219 -- iter: 064/366
[A[ATraining Step: 3  | total loss: [1m[32m1.04884[0m[0m | time: 75.958s
[2K
| Adam | epoch: 001 | loss: 1.04884 - acc: 0.3580 -- iter: 096/366
[A[ATraining Step: 4  | total loss: [1m[32m0.77301[0m[0m | time: 105.030s
[2K
| Adam | epoch: 001 | loss: 0.77301 - acc: 0.5114 -- iter: 128/366
[A[ATraining Step: 5  | total loss: [1m[32m0.80510[0m[0m | time: 130.302s
[2K
| Adam | epoch: 001 | loss: 0.80510 - acc: 0.4170 -- iter: 160/366
[A[ATraining Step: 6  | total loss: [1m[32m0.70805[0m[0m | time: 143.717s
[2K
| Adam | epoch: 001 | loss: 0.70805 - acc: 0.5507 -- iter: 192/366
[A[ATraining Step: 7  | total loss: [1m[32m0.69665[0m[0m | time: 157.404s
[2K
| Adam | epoch: 001 | loss: 0.69665 - acc: 0.6140 -- iter: 224/366
[A[ATraining Step: 8  | total loss: [1m[32m0.61316[0m[0m | time: 171.635s
[2K
| Adam | epoch: 001 | loss: 0.61316 - acc: 0.6729 -- iter: 256/366
[A[ATraining Step: 9  | total loss: [1m[32m0.63754[0m[0m | time: 185.447s
[2K
| Adam | epoch: 001 | loss: 0.63754 - acc: 0.6310 -- iter: 288/366
[A[ATraining Step: 10  | total loss: [1m[32m0.53910[0m[0m | time: 199.107s
[2K
| Adam | epoch: 001 | loss: 0.53910 - acc: 0.7061 -- iter: 320/366
[A[ATraining Step: 11  | total loss: [1m[32m0.54061[0m[0m | time: 212.996s
[2K
| Adam | epoch: 001 | loss: 0.54061 - acc: 0.7121 -- iter: 352/366
[A[ATraining Step: 12  | total loss: [1m[32m0.61451[0m[0m | time: 229.830s
[2K
| Adam | epoch: 001 | loss: 0.61451 - acc: 0.6588 | val_loss: 0.91004 - val_acc: 0.5826 -- iter: 366/366
--
Training Step: 13  | total loss: [1m[32m0.55876[0m[0m | time: 7.404s
[2K
| Adam | epoch: 002 | loss: 0.55876 - acc: 0.6826 -- iter: 032/366
[A[ATraining Step: 14  | total loss: [1m[32m0.40352[0m[0m | time: 21.431s
[2K
| Adam | epoch: 002 | loss: 0.40352 - acc: 0.8124 -- iter: 064/366
[A[ATraining Step: 15  | total loss: [1m[32m0.45650[0m[0m | time: 35.456s
[2K
| Adam | epoch: 002 | loss: 0.45650 - acc: 0.7758 -- iter: 096/366
[A[ATraining Step: 16  | total loss: [1m[32m0.59461[0m[0m | time: 49.777s
[2K
| Adam | epoch: 002 | loss: 0.59461 - acc: 0.7192 -- iter: 128/366
[A[ATraining Step: 17  | total loss: [1m[32m0.55102[0m[0m | time: 62.778s
[2K
| Adam | epoch: 002 | loss: 0.55102 - acc: 0.7416 -- iter: 160/366
[A[ATraining Step: 18  | total loss: [1m[32m0.54185[0m[0m | time: 71.527s
[2K
| Adam | epoch: 002 | loss: 0.54185 - acc: 0.7553 -- iter: 192/366
[A[ATraining Step: 19  | total loss: [1m[32m0.49430[0m[0m | time: 80.230s
[2K
| Adam | epoch: 002 | loss: 0.49430 - acc: 0.7744 -- iter: 224/366
[A[ATraining Step: 20  | total loss: [1m[32m0.45833[0m[0m | time: 89.652s
[2K
| Adam | epoch: 002 | loss: 0.45833 - acc: 0.8368 -- iter: 256/366
[A[ATraining Step: 21  | total loss: [1m[32m0.39159[0m[0m | time: 104.852s
[2K
| Adam | epoch: 002 | loss: 0.39159 - acc: 0.8875 -- iter: 288/366
[A[ATraining Step: 22  | total loss: [1m[32m0.34686[0m[0m | time: 120.239s
[2K
| Adam | epoch: 002 | loss: 0.34686 - acc: 0.8837 -- iter: 320/366
[A[ATraining Step: 23  | total loss: [1m[32m0.33394[0m[0m | time: 153.531s
[2K
| Adam | epoch: 002 | loss: 0.33394 - acc: 0.8721 -- iter: 352/366
[A[ATraining Step: 24  | total loss: [1m[32m0.27372[0m[0m | time: 178.907s
[2K
| Adam | epoch: 002 | loss: 0.27372 - acc: 0.8993 | val_loss: 0.72190 - val_acc: 0.6000 -- iter: 366/366
--
Training Step: 25  | total loss: [1m[32m0.28977[0m[0m | time: 4.090s
[2K
| Adam | epoch: 003 | loss: 0.28977 - acc: 0.8927 -- iter: 032/366
[A[ATraining Step: 26  | total loss: [1m[32m0.24289[0m[0m | time: 8.261s
[2K
| Adam | epoch: 003 | loss: 0.24289 - acc: 0.9211 -- iter: 064/366
[A[ATraining Step: 27  | total loss: [1m[32m0.18741[0m[0m | time: 17.034s
[2K
| Adam | epoch: 003 | loss: 0.18741 - acc: 0.9414 -- iter: 096/366
[A[ATraining Step: 28  | total loss: [1m[32m0.32682[0m[0m | time: 25.712s
[2K
| Adam | epoch: 003 | loss: 0.32682 - acc: 0.8857 -- iter: 128/366
[A[ATraining Step: 29  | total loss: [1m[32m0.34835[0m[0m | time: 34.514s
[2K
| Adam | epoch: 003 | loss: 0.34835 - acc: 0.8755 -- iter: 160/366
[A[ATraining Step: 30  | total loss: [1m[32m0.28348[0m[0m | time: 62.941s
[2K
| Adam | epoch: 003 | loss: 0.28348 - acc: 0.9050 -- iter: 192/366
[A[ATraining Step: 31  | total loss: [1m[32m0.28196[0m[0m | time: 78.290s
[2K
| Adam | epoch: 003 | loss: 0.28196 - acc: 0.9053 -- iter: 224/366
[A[ATraining Step: 32  | total loss: [1m[32m0.28382[0m[0m | time: 92.174s
[2K
| Adam | epoch: 003 | loss: 0.28382 - acc: 0.9125 -- iter: 256/366
[A[ATraining Step: 33  | total loss: [1m[32m0.27868[0m[0m | time: 106.334s
[2K
| Adam | epoch: 003 | loss: 0.27868 - acc: 0.9043 -- iter: 288/366
[A[ATraining Step: 34  | total loss: [1m[32m0.37012[0m[0m | time: 119.694s
[2K
| Adam | epoch: 003 | loss: 0.37012 - acc: 0.8779 -- iter: 320/366
[A[ATraining Step: 35  | total loss: [1m[32m0.33790[0m[0m | time: 133.879s
[2K
| Adam | epoch: 003 | loss: 0.33790 - acc: 0.8904 -- iter: 352/366
[A[ATraining Step: 36  | total loss: [1m[32m0.31768[0m[0m | time: 156.141s
[2K
| Adam | epoch: 003 | loss: 0.31768 - acc: 0.8745 | val_loss: 0.99903 - val_acc: 0.5304 -- iter: 366/366
--
Training Step: 37  | total loss: [1m[32m0.30992[0m[0m | time: 8.767s
[2K
| Adam | epoch: 004 | loss: 0.30992 - acc: 0.8621 -- iter: 032/366
[A[ATraining Step: 38  | total loss: [1m[32m0.31269[0m[0m | time: 12.790s
[2K
| Adam | epoch: 004 | loss: 0.31269 - acc: 0.8585 -- iter: 064/366
[A[ATraining Step: 39  | total loss: [1m[32m0.30270[0m[0m | time: 17.943s
[2K
| Adam | epoch: 004 | loss: 0.30270 - acc: 0.8582 -- iter: 096/366
[A[ATraining Step: 40  | total loss: [1m[32m0.26061[0m[0m | time: 31.566s
[2K
| Adam | epoch: 004 | loss: 0.26061 - acc: 0.8848 -- iter: 128/366
[A[ATraining Step: 41  | total loss: [1m[32m0.24677[0m[0m | time: 45.259s
[2K
| Adam | epoch: 004 | loss: 0.24677 - acc: 0.9002 -- iter: 160/366
[A[ATraining Step: 42  | total loss: [1m[32m0.26000[0m[0m | time: 59.901s
[2K
| Adam | epoch: 004 | loss: 0.26000 - acc: 0.8957 -- iter: 192/366
[A[ATraining Step: 43  | total loss: [1m[32m0.25825[0m[0m | time: 74.120s
[2K
| Adam | epoch: 004 | loss: 0.25825 - acc: 0.8976 -- iter: 224/366
[A[ATraining Step: 44  | total loss: [1m[32m0.25358[0m[0m | time: 87.872s
[2K
| Adam | epoch: 004 | loss: 0.25358 - acc: 0.8991 -- iter: 256/366
[A[ATraining Step: 45  | total loss: [1m[32m0.23794[0m[0m | time: 101.830s
[2K
| Adam | epoch: 004 | loss: 0.23794 - acc: 0.9109 -- iter: 288/366
[A[ATraining Step: 46  | total loss: [1m[32m0.25527[0m[0m | time: 115.756s
[2K
| Adam | epoch: 004 | loss: 0.25527 - acc: 0.9049 -- iter: 320/366
[A[ATraining Step: 47  | total loss: [1m[32m0.24257[0m[0m | time: 129.410s
[2K
| Adam | epoch: 004 | loss: 0.24257 - acc: 0.9051 -- iter: 352/366
[A[ATraining Step: 48  | total loss: [1m[32m0.21130[0m[0m | time: 143.477s
[2K
| Adam | epoch: 004 | loss: 0.21130 - acc: 0.9154 | val_loss: 1.39246 - val_acc: 0.5826 -- iter: 366/366
--
Training Step: 49  | total loss: [1m[32m0.19375[0m[0m | time: 14.141s
[2K
| Adam | epoch: 005 | loss: 0.19375 - acc: 0.9287 -- iter: 032/366
[A[ATraining Step: 50  | total loss: [1m[32m0.21038[0m[0m | time: 28.453s
[2K
| Adam | epoch: 005 | loss: 0.21038 - acc: 0.9155 -- iter: 064/366
[A[ATraining Step: 51  | total loss: [1m[32m0.18795[0m[0m | time: 36.210s
[2K
| Adam | epoch: 005 | loss: 0.18795 - acc: 0.9284 -- iter: 096/366
[A[ATraining Step: 52  | total loss: [1m[32m0.17143[0m[0m | time: 43.326s
[2K
| Adam | epoch: 005 | loss: 0.17143 - acc: 0.9392 -- iter: 128/366
[A[ATraining Step: 53  | total loss: [1m[32m0.14850[0m[0m | time: 57.093s
[2K
| Adam | epoch: 005 | loss: 0.14850 - acc: 0.9481 -- iter: 160/366
[A[ATraining Step: 54  | total loss: [1m[32m0.18169[0m[0m | time: 70.850s
[2K
| Adam | epoch: 005 | loss: 0.18169 - acc: 0.9466 -- iter: 192/366
[A[ATraining Step: 55  | total loss: [1m[32m0.18966[0m[0m | time: 82.141s
[2K
| Adam | epoch: 005 | loss: 0.18966 - acc: 0.9498 -- iter: 224/366
[A[ATraining Step: 56  | total loss: [1m[32m0.18316[0m[0m | time: 90.785s
[2K
| Adam | epoch: 005 | loss: 0.18316 - acc: 0.9524 -- iter: 256/366
[A[ATraining Step: 57  | total loss: [1m[32m0.17604[0m[0m | time: 99.409s
[2K
| Adam | epoch: 005 | loss: 0.17604 - acc: 0.9504 -- iter: 288/366
[A[ATraining Step: 58  | total loss: [1m[32m0.16744[0m[0m | time: 108.057s
[2K
| Adam | epoch: 005 | loss: 0.16744 - acc: 0.9443 -- iter: 320/366
[A[ATraining Step: 59  | total loss: [1m[32m0.16655[0m[0m | time: 118.225s
[2K
| Adam | epoch: 005 | loss: 0.16655 - acc: 0.9392 -- iter: 352/366
[A[ATraining Step: 60  | total loss: [1m[32m0.15505[0m[0m | time: 141.225s
[2K
| Adam | epoch: 005 | loss: 0.15505 - acc: 0.9431 | val_loss: 2.50027 - val_acc: 0.4348 -- iter: 366/366
--
Training Step: 61  | total loss: [1m[32m0.14059[0m[0m | time: 19.004s
[2K
| Adam | epoch: 006 | loss: 0.14059 - acc: 0.9506 -- iter: 032/366
[A[ATraining Step: 62  | total loss: [1m[32m0.14824[0m[0m | time: 42.304s
[2K
| Adam | epoch: 006 | loss: 0.14824 - acc: 0.9408 -- iter: 064/366
[A[ATraining Step: 63  | total loss: [1m[32m0.13111[0m[0m | time: 59.867s
[2K
| Adam | epoch: 006 | loss: 0.13111 - acc: 0.9483 -- iter: 096/366
[A[ATraining Step: 64  | total loss: [1m[32m0.11887[0m[0m | time: 66.968s
[2K
| Adam | epoch: 006 | loss: 0.11887 - acc: 0.9548 -- iter: 128/366
[A[ATraining Step: 65  | total loss: [1m[32m0.11038[0m[0m | time: 71.014s
[2K
| Adam | epoch: 006 | loss: 0.11038 - acc: 0.9604 -- iter: 160/366
[A[ATraining Step: 66  | total loss: [1m[32m0.09973[0m[0m | time: 79.537s
[2K
| Adam | epoch: 006 | loss: 0.09973 - acc: 0.9652 -- iter: 192/366
[A[ATraining Step: 67  | total loss: [1m[32m0.09012[0m[0m | time: 88.324s
[2K
| Adam | epoch: 006 | loss: 0.09012 - acc: 0.9694 -- iter: 224/366
[A[ATraining Step: 68  | total loss: [1m[32m0.08304[0m[0m | time: 98.287s
[2K
| Adam | epoch: 006 | loss: 0.08304 - acc: 0.9730 -- iter: 256/366
[A[ATraining Step: 69  | total loss: [1m[32m0.07889[0m[0m | time: 112.310s
[2K
| Adam | epoch: 006 | loss: 0.07889 - acc: 0.9725 -- iter: 288/366
[A[ATraining Step: 70  | total loss: [1m[32m0.09088[0m[0m | time: 126.495s
[2K
| Adam | epoch: 006 | loss: 0.09088 - acc: 0.9649 -- iter: 320/366
[A[ATraining Step: 71  | total loss: [1m[32m0.08358[0m[0m | time: 140.800s
[2K
| Adam | epoch: 006 | loss: 0.08358 - acc: 0.9689 -- iter: 352/366
[A[ATraining Step: 72  | total loss: [1m[32m0.07979[0m[0m | time: 164.419s
[2K
| Adam | epoch: 006 | loss: 0.07979 - acc: 0.9688 | val_loss: 2.24484 - val_acc: 0.5043 -- iter: 366/366
--
Training Step: 73  | total loss: [1m[32m0.07341[0m[0m | time: 11.940s
[2K
| Adam | epoch: 007 | loss: 0.07341 - acc: 0.9723 -- iter: 032/366
[A[ATraining Step: 74  | total loss: [1m[32m0.06699[0m[0m | time: 20.517s
[2K
| Adam | epoch: 007 | loss: 0.06699 - acc: 0.9753 -- iter: 064/366
[A[ATraining Step: 75  | total loss: [1m[32m0.08628[0m[0m | time: 29.187s
[2K
| Adam | epoch: 007 | loss: 0.08628 - acc: 0.9712 -- iter: 096/366
[A[ATraining Step: 76  | total loss: [1m[32m0.07940[0m[0m | time: 46.568s
[2K
| Adam | epoch: 007 | loss: 0.07940 - acc: 0.9743 -- iter: 128/366
[A[ATraining Step: 77  | total loss: [1m[32m0.08489[0m[0m | time: 54.063s
[2K
| Adam | epoch: 007 | loss: 0.08489 - acc: 0.9737 -- iter: 160/366
[A[ATraining Step: 78  | total loss: [1m[32m0.07755[0m[0m | time: 61.245s
[2K
| Adam | epoch: 007 | loss: 0.07755 - acc: 0.9765 -- iter: 192/366
[A[ATraining Step: 79  | total loss: [1m[32m0.07030[0m[0m | time: 74.799s
[2K
| Adam | epoch: 007 | loss: 0.07030 - acc: 0.9789 -- iter: 224/366
[A[ATraining Step: 80  | total loss: [1m[32m0.06573[0m[0m | time: 88.734s
[2K
| Adam | epoch: 007 | loss: 0.06573 - acc: 0.9811 -- iter: 256/366
[A[ATraining Step: 81  | total loss: [1m[32m0.06932[0m[0m | time: 102.625s
[2K
| Adam | epoch: 007 | loss: 0.06932 - acc: 0.9798 -- iter: 288/366
[A[ATraining Step: 82  | total loss: [1m[32m0.06630[0m[0m | time: 117.252s
[2K
| Adam | epoch: 007 | loss: 0.06630 - acc: 0.9818 -- iter: 320/366
[A[ATraining Step: 83  | total loss: [1m[32m0.06465[0m[0m | time: 130.933s
[2K
| Adam | epoch: 007 | loss: 0.06465 - acc: 0.9837 -- iter: 352/366
[A[ATraining Step: 84  | total loss: [1m[32m0.06564[0m[0m | time: 150.729s
[2K
| Adam | epoch: 007 | loss: 0.06564 - acc: 0.9822 | val_loss: 0.94608 - val_acc: 0.7826 -- iter: 366/366
--
Training Step: 85  | total loss: [1m[32m0.09729[0m[0m | time: 13.997s
[2K
| Adam | epoch: 008 | loss: 0.09729 - acc: 0.9746 -- iter: 032/366
[A[ATraining Step: 86  | total loss: [1m[32m0.08961[0m[0m | time: 28.181s
[2K
| Adam | epoch: 008 | loss: 0.08961 - acc: 0.9771 -- iter: 064/366
[A[ATraining Step: 87  | total loss: [1m[32m0.08220[0m[0m | time: 41.796s
[2K
| Adam | epoch: 008 | loss: 0.08220 - acc: 0.9794 -- iter: 096/366
[A[ATraining Step: 88  | total loss: [1m[32m0.08418[0m[0m | time: 55.807s
[2K
| Adam | epoch: 008 | loss: 0.08418 - acc: 0.9752 -- iter: 128/366
[A[ATraining Step: 89  | total loss: [1m[32m0.08012[0m[0m | time: 69.809s
[2K
| Adam | epoch: 008 | loss: 0.08012 - acc: 0.9777 -- iter: 160/366
[A[ATraining Step: 90  | total loss: [1m[32m0.08270[0m[0m | time: 77.389s
[2K
| Adam | epoch: 008 | loss: 0.08270 - acc: 0.9768 -- iter: 192/366
[A[ATraining Step: 91  | total loss: [1m[32m0.09206[0m[0m | time: 81.946s
[2K
| Adam | epoch: 008 | loss: 0.09206 - acc: 0.9720 -- iter: 224/366
[A[ATraining Step: 92  | total loss: [1m[32m0.08344[0m[0m | time: 90.622s
[2K
| Adam | epoch: 008 | loss: 0.08344 - acc: 0.9748 -- iter: 256/366
[A[ATraining Step: 93  | total loss: [1m[32m0.07751[0m[0m | time: 99.251s
[2K
| Adam | epoch: 008 | loss: 0.07751 - acc: 0.9773 -- iter: 288/366
[A[ATraining Step: 94  | total loss: [1m[32m0.14385[0m[0m | time: 112.352s
[2K
| Adam | epoch: 008 | loss: 0.14385 - acc: 0.9639 -- iter: 320/366
[A[ATraining Step: 95  | total loss: [1m[32m0.13743[0m[0m | time: 126.983s
[2K
| Adam | epoch: 008 | loss: 0.13743 - acc: 0.9644 -- iter: 352/366
[A[ATraining Step: 96  | total loss: [1m[32m0.12752[0m[0m | time: 167.198s
[2K
| Adam | epoch: 008 | loss: 0.12752 - acc: 0.9680 | val_loss: 0.41272 - val_acc: 0.8348 -- iter: 366/366
--
Training Step: 97  | total loss: [1m[32m0.11671[0m[0m | time: 11.180s
[2K
| Adam | epoch: 009 | loss: 0.11671 - acc: 0.9712 -- iter: 032/366
[A[ATraining Step: 98  | total loss: [1m[32m0.11098[0m[0m | time: 19.618s
[2K
| Adam | epoch: 009 | loss: 0.11098 - acc: 0.9709 -- iter: 064/366
[A[ATraining Step: 99  | total loss: [1m[32m0.10109[0m[0m | time: 28.389s
[2K
| Adam | epoch: 009 | loss: 0.10109 - acc: 0.9738 -- iter: 096/366
[A[ATraining Step: 100  | total loss: [1m[32m0.09177[0m[0m | time: 37.048s
[2K
| Adam | epoch: 009 | loss: 0.09177 - acc: 0.9765 -- iter: 128/366
[A[ATraining Step: 101  | total loss: [1m[32m0.08325[0m[0m | time: 49.523s
[2K
| Adam | epoch: 009 | loss: 0.08325 - acc: 0.9788 -- iter: 160/366
[A[ATraining Step: 102  | total loss: [1m[32m0.07892[0m[0m | time: 59.085s
[2K
| Adam | epoch: 009 | loss: 0.07892 - acc: 0.9809 -- iter: 192/366
[A[ATraining Step: 103  | total loss: [1m[32m0.08855[0m[0m | time: 63.258s
[2K
| Adam | epoch: 009 | loss: 0.08855 - acc: 0.9766 -- iter: 224/366
[A[ATraining Step: 104  | total loss: [1m[32m0.08175[0m[0m | time: 67.396s
[2K
| Adam | epoch: 009 | loss: 0.08175 - acc: 0.9789 -- iter: 256/366
[A[ATraining Step: 105  | total loss: [1m[32m0.07456[0m[0m | time: 75.812s
[2K
| Adam | epoch: 009 | loss: 0.07456 - acc: 0.9810 -- iter: 288/366
[A[ATraining Step: 106  | total loss: [1m[32m0.07185[0m[0m | time: 83.991s
[2K
| Adam | epoch: 009 | loss: 0.07185 - acc: 0.9798 -- iter: 320/366
[A[ATraining Step: 107  | total loss: [1m[32m0.06566[0m[0m | time: 92.310s
[2K
| Adam | epoch: 009 | loss: 0.06566 - acc: 0.9818 -- iter: 352/366
[A[ATraining Step: 108  | total loss: [1m[32m0.05963[0m[0m | time: 105.788s
[2K
| Adam | epoch: 009 | loss: 0.05963 - acc: 0.9836 | val_loss: 0.62598 - val_acc: 0.7913 -- iter: 366/366
--
Training Step: 109  | total loss: [1m[32m0.05656[0m[0m | time: 8.499s
[2K
| Adam | epoch: 010 | loss: 0.05656 - acc: 0.9853 -- iter: 032/366
[A[ATraining Step: 110  | total loss: [1m[32m0.05857[0m[0m | time: 16.693s
[2K
| Adam | epoch: 010 | loss: 0.05857 - acc: 0.9836 -- iter: 064/366
[A[ATraining Step: 111  | total loss: [1m[32m0.06722[0m[0m | time: 24.858s
[2K
| Adam | epoch: 010 | loss: 0.06722 - acc: 0.9821 -- iter: 096/366
[A[ATraining Step: 112  | total loss: [1m[32m0.06068[0m[0m | time: 33.035s
[2K
| Adam | epoch: 010 | loss: 0.06068 - acc: 0.9839 -- iter: 128/366
[A[ATraining Step: 113  | total loss: [1m[32m0.06457[0m[0m | time: 41.223s
[2K
| Adam | epoch: 010 | loss: 0.06457 - acc: 0.9824 -- iter: 160/366
[A[ATraining Step: 114  | total loss: [1m[32m0.06304[0m[0m | time: 49.475s
[2K
| Adam | epoch: 010 | loss: 0.06304 - acc: 0.9810 -- iter: 192/366
[A[ATraining Step: 115  | total loss: [1m[32m0.06130[0m[0m | time: 57.643s
[2K
| Adam | epoch: 010 | loss: 0.06130 - acc: 0.9798 -- iter: 224/366
[A[ATraining Step: 116  | total loss: [1m[32m0.05832[0m[0m | time: 61.654s
[2K
| Adam | epoch: 010 | loss: 0.05832 - acc: 0.9818 -- iter: 256/366
[A[ATraining Step: 117  | total loss: [1m[32m0.06948[0m[0m | time: 65.801s
[2K
| Adam | epoch: 010 | loss: 0.06948 - acc: 0.9765 -- iter: 288/366
[A[ATraining Step: 118  | total loss: [1m[32m0.06418[0m[0m | time: 73.993s
[2K
| Adam | epoch: 010 | loss: 0.06418 - acc: 0.9789 -- iter: 320/366
[A[ATraining Step: 119  | total loss: [1m[32m0.06158[0m[0m | time: 82.053s
[2K
| Adam | epoch: 010 | loss: 0.06158 - acc: 0.9810 -- iter: 352/366
[A[ATraining Step: 120  | total loss: [1m[32m0.06085[0m[0m | time: 95.427s
[2K
| Adam | epoch: 010 | loss: 0.06085 - acc: 0.9797 | val_loss: 1.57710 - val_acc: 0.7478 -- iter: 366/366
--
Training Step: 121  | total loss: [1m[32m0.06235[0m[0m | time: 8.119s
[2K
| Adam | epoch: 011 | loss: 0.06235 - acc: 0.9755 -- iter: 032/366
[A[ATraining Step: 122  | total loss: [1m[32m0.07028[0m[0m | time: 16.186s
[2K
| Adam | epoch: 011 | loss: 0.07028 - acc: 0.9748 -- iter: 064/366
[A[ATraining Step: 123  | total loss: [1m[32m0.10309[0m[0m | time: 24.170s
[2K
| Adam | epoch: 011 | loss: 0.10309 - acc: 0.9742 -- iter: 096/366
[A[ATraining Step: 124  | total loss: [1m[32m0.22749[0m[0m | time: 32.164s
[2K
| Adam | epoch: 011 | loss: 0.22749 - acc: 0.9581 -- iter: 128/366
[A[ATraining Step: 125  | total loss: [1m[32m0.23116[0m[0m | time: 40.190s
[2K
| Adam | epoch: 011 | loss: 0.23116 - acc: 0.9529 -- iter: 160/366
[A[ATraining Step: 126  | total loss: [1m[32m0.21408[0m[0m | time: 48.201s
[2K
| Adam | epoch: 011 | loss: 0.21408 - acc: 0.9545 -- iter: 192/366
[A[ATraining Step: 127  | total loss: [1m[32m0.19903[0m[0m | time: 56.343s
[2K
| Adam | epoch: 011 | loss: 0.19903 - acc: 0.9559 -- iter: 224/366
[A[ATraining Step: 128  | total loss: [1m[32m0.18191[0m[0m | time: 64.398s
[2K
| Adam | epoch: 011 | loss: 0.18191 - acc: 0.9603 -- iter: 256/366
[A[ATraining Step: 129  | total loss: [1m[32m0.16726[0m[0m | time: 68.413s
[2K
| Adam | epoch: 011 | loss: 0.16726 - acc: 0.9643 -- iter: 288/366
[A[ATraining Step: 130  | total loss: [1m[32m0.15238[0m[0m | time: 72.582s
[2K
| Adam | epoch: 011 | loss: 0.15238 - acc: 0.9678 -- iter: 320/366
[A[ATraining Step: 131  | total loss: [1m[32m0.13841[0m[0m | time: 80.704s
[2K
| Adam | epoch: 011 | loss: 0.13841 - acc: 0.9711 -- iter: 352/366
[A[ATraining Step: 132  | total loss: [1m[32m0.12560[0m[0m | time: 93.950s
[2K
| Adam | epoch: 011 | loss: 0.12560 - acc: 0.9740 | val_loss: 0.65439 - val_acc: 0.8348 -- iter: 366/366
--
Training Step: 133  | total loss: [1m[32m0.12621[0m[0m | time: 8.176s
[2K
| Adam | epoch: 012 | loss: 0.12621 - acc: 0.9703 -- iter: 032/366
[A[ATraining Step: 134  | total loss: [1m[32m0.11695[0m[0m | time: 16.256s
[2K
| Adam | epoch: 012 | loss: 0.11695 - acc: 0.9733 -- iter: 064/366
[A[ATraining Step: 135  | total loss: [1m[32m0.11015[0m[0m | time: 24.288s
[2K
| Adam | epoch: 012 | loss: 0.11015 - acc: 0.9728 -- iter: 096/366
[A[ATraining Step: 136  | total loss: [1m[32m0.10916[0m[0m | time: 32.190s
[2K
| Adam | epoch: 012 | loss: 0.10916 - acc: 0.9693 -- iter: 128/366
[A[ATraining Step: 137  | total loss: [1m[32m0.10430[0m[0m | time: 40.136s
[2K
| Adam | epoch: 012 | loss: 0.10430 - acc: 0.9692 -- iter: 160/366
[A[ATraining Step: 138  | total loss: [1m[32m0.09781[0m[0m | time: 48.241s
[2K
| Adam | epoch: 012 | loss: 0.09781 - acc: 0.9723 -- iter: 192/366
[A[ATraining Step: 139  | total loss: [1m[32m0.08968[0m[0m | time: 56.331s
[2K
| Adam | epoch: 012 | loss: 0.08968 - acc: 0.9751 -- iter: 224/366
[A[ATraining Step: 140  | total loss: [1m[32m0.08918[0m[0m | time: 64.540s
[2K
| Adam | epoch: 012 | loss: 0.08918 - acc: 0.9713 -- iter: 256/366
[A[ATraining Step: 141  | total loss: [1m[32m0.10885[0m[0m | time: 72.599s
[2K
| Adam | epoch: 012 | loss: 0.10885 - acc: 0.9648 -- iter: 288/366
[A[ATraining Step: 142  | total loss: [1m[32m0.10807[0m[0m | time: 76.699s
[2K
| Adam | epoch: 012 | loss: 0.10807 - acc: 0.9590 -- iter: 320/366
[A[ATraining Step: 143  | total loss: [1m[32m0.09761[0m[0m | time: 80.761s
[2K
| Adam | epoch: 012 | loss: 0.09761 - acc: 0.9631 -- iter: 352/366
[A[ATraining Step: 144  | total loss: [1m[32m0.08837[0m[0m | time: 94.203s
[2K
| Adam | epoch: 012 | loss: 0.08837 - acc: 0.9668 | val_loss: 3.51891 - val_acc: 0.4435 -- iter: 366/366
--
Training Step: 145  | total loss: [1m[32m0.08530[0m[0m | time: 8.168s
[2K
| Adam | epoch: 013 | loss: 0.08530 - acc: 0.9701 -- iter: 032/366
[A[ATraining Step: 146  | total loss: [1m[32m0.08871[0m[0m | time: 16.175s
[2K
| Adam | epoch: 013 | loss: 0.08871 - acc: 0.9699 -- iter: 064/366
[A[ATraining Step: 147  | total loss: [1m[32m0.09122[0m[0m | time: 24.499s
[2K
| Adam | epoch: 013 | loss: 0.09122 - acc: 0.9667 -- iter: 096/366
[A[ATraining Step: 148  | total loss: [1m[32m0.08479[0m[0m | time: 32.432s
[2K
| Adam | epoch: 013 | loss: 0.08479 - acc: 0.9700 -- iter: 128/366
[A[ATraining Step: 149  | total loss: [1m[32m0.08044[0m[0m | time: 40.414s
[2K
| Adam | epoch: 013 | loss: 0.08044 - acc: 0.9730 -- iter: 160/366
[A[ATraining Step: 150  | total loss: [1m[32m0.11516[0m[0m | time: 48.547s
[2K
| Adam | epoch: 013 | loss: 0.11516 - acc: 0.9664 -- iter: 192/366
[A[ATraining Step: 151  | total loss: [1m[32m0.12233[0m[0m | time: 56.519s
[2K
| Adam | epoch: 013 | loss: 0.12233 - acc: 0.9572 -- iter: 224/366
[A[ATraining Step: 152  | total loss: [1m[32m0.11752[0m[0m | time: 64.490s
[2K
| Adam | epoch: 013 | loss: 0.11752 - acc: 0.9615 -- iter: 256/366
[A[ATraining Step: 153  | total loss: [1m[32m0.12602[0m[0m | time: 72.558s
[2K
| Adam | epoch: 013 | loss: 0.12602 - acc: 0.9591 -- iter: 288/366
[A[ATraining Step: 154  | total loss: [1m[32m0.12113[0m[0m | time: 80.595s
[2K
| Adam | epoch: 013 | loss: 0.12113 - acc: 0.9601 -- iter: 320/366
[A[ATraining Step: 155  | total loss: [1m[32m0.11119[0m[0m | time: 84.647s
[2K
| Adam | epoch: 013 | loss: 0.11119 - acc: 0.9641 -- iter: 352/366
[A[ATraining Step: 156  | total loss: [1m[32m0.11687[0m[0m | time: 93.795s
[2K
| Adam | epoch: 013 | loss: 0.11687 - acc: 0.9605 | val_loss: 5.91440 - val_acc: 0.4174 -- iter: 366/366
--
Training Step: 157  | total loss: [1m[32m0.10907[0m[0m | time: 8.318s
[2K
| Adam | epoch: 014 | loss: 0.10907 - acc: 0.9645 -- iter: 032/366
[A[ATraining Step: 158  | total loss: [1m[32m0.10897[0m[0m | time: 16.375s
[2K
| Adam | epoch: 014 | loss: 0.10897 - acc: 0.9649 -- iter: 064/366
[A[ATraining Step: 159  | total loss: [1m[32m0.10154[0m[0m | time: 24.486s
[2K
| Adam | epoch: 014 | loss: 0.10154 - acc: 0.9684 -- iter: 096/366
[A[ATraining Step: 160  | total loss: [1m[32m0.10455[0m[0m | time: 32.530s
[2K
| Adam | epoch: 014 | loss: 0.10455 - acc: 0.9684 -- iter: 128/366
[A[ATraining Step: 161  | total loss: [1m[32m0.11140[0m[0m | time: 40.470s
[2K
| Adam | epoch: 014 | loss: 0.11140 - acc: 0.9653 -- iter: 160/366
[A[ATraining Step: 162  | total loss: [1m[32m0.12261[0m[0m | time: 48.717s
[2K
| Adam | epoch: 014 | loss: 0.12261 - acc: 0.9626 -- iter: 192/366
[A[ATraining Step: 163  | total loss: [1m[32m0.11103[0m[0m | time: 56.795s
[2K
| Adam | epoch: 014 | loss: 0.11103 - acc: 0.9663 -- iter: 224/366
[A[ATraining Step: 164  | total loss: [1m[32m0.10353[0m[0m | time: 64.923s
[2K
| Adam | epoch: 014 | loss: 0.10353 - acc: 0.9697 -- iter: 256/366
[A[ATraining Step: 165  | total loss: [1m[32m0.09708[0m[0m | time: 73.023s
[2K
| Adam | epoch: 014 | loss: 0.09708 - acc: 0.9727 -- iter: 288/366
[A[ATraining Step: 166  | total loss: [1m[32m0.09778[0m[0m | time: 81.032s
[2K
| Adam | epoch: 014 | loss: 0.09778 - acc: 0.9692 -- iter: 320/366
[A[ATraining Step: 167  | total loss: [1m[32m0.09440[0m[0m | time: 88.987s
[2K
| Adam | epoch: 014 | loss: 0.09440 - acc: 0.9691 -- iter: 352/366
[A[ATraining Step: 168  | total loss: [1m[32m0.08710[0m[0m | time: 98.175s
[2K
| Adam | epoch: 014 | loss: 0.08710 - acc: 0.9722 | val_loss: 0.88134 - val_acc: 0.7217 -- iter: 366/366
--
Training Step: 169  | total loss: [1m[32m0.08901[0m[0m | time: 4.060s
[2K
| Adam | epoch: 015 | loss: 0.08901 - acc: 0.9679 -- iter: 032/366
[A[ATraining Step: 170  | total loss: [1m[32m0.08073[0m[0m | time: 12.105s
[2K
| Adam | epoch: 015 | loss: 0.08073 - acc: 0.9711 -- iter: 064/366
[A[ATraining Step: 171  | total loss: [1m[32m0.07471[0m[0m | time: 20.049s
[2K
| Adam | epoch: 015 | loss: 0.07471 - acc: 0.9740 -- iter: 096/366
[A[ATraining Step: 172  | total loss: [1m[32m0.07369[0m[0m | time: 28.034s
[2K
| Adam | epoch: 015 | loss: 0.07369 - acc: 0.9766 -- iter: 128/366
[A[ATraining Step: 173  | total loss: [1m[32m0.06804[0m[0m | time: 36.127s
[2K
| Adam | epoch: 015 | loss: 0.06804 - acc: 0.9789 -- iter: 160/366
[A[ATraining Step: 174  | total loss: [1m[32m0.06351[0m[0m | time: 44.109s
[2K
| Adam | epoch: 015 | loss: 0.06351 - acc: 0.9810 -- iter: 192/366
[A[ATraining Step: 175  | total loss: [1m[32m0.05838[0m[0m | time: 52.214s
[2K
| Adam | epoch: 015 | loss: 0.05838 - acc: 0.9829 -- iter: 224/366
[A[ATraining Step: 176  | total loss: [1m[32m0.10474[0m[0m | time: 60.202s
[2K
| Adam | epoch: 015 | loss: 0.10474 - acc: 0.9784 -- iter: 256/366
[A[ATraining Step: 177  | total loss: [1m[32m0.09662[0m[0m | time: 68.168s
[2K
| Adam | epoch: 015 | loss: 0.09662 - acc: 0.9805 -- iter: 288/366
[A[ATraining Step: 178  | total loss: [1m[32m0.09130[0m[0m | time: 76.090s
[2K
| Adam | epoch: 015 | loss: 0.09130 - acc: 0.9825 -- iter: 320/366
[A[ATraining Step: 179  | total loss: [1m[32m0.08536[0m[0m | time: 84.091s
[2K
| Adam | epoch: 015 | loss: 0.08536 - acc: 0.9842 -- iter: 352/366
[A[ATraining Step: 180  | total loss: [1m[32m0.08017[0m[0m | time: 97.326s
[2K
| Adam | epoch: 015 | loss: 0.08017 - acc: 0.9827 | val_loss: 1.52869 - val_acc: 0.6435 -- iter: 366/366
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9406094527363185
Validation AUPRC:0.9621009429176881
Test AUC:0.9470659407138535
Test AUPRC:0.9402247003376388
BestTestF1Score	0.88	0.76	0.88	0.89	0.86	50	6	51	8	0.01
BestTestMCCScore	0.88	0.76	0.88	0.89	0.86	50	6	51	8	0.01
BestTestAccuracyScore	0.88	0.76	0.88	0.89	0.86	50	6	51	8	0.01
BestValidationF1Score	0.86	0.73	0.85	0.98	0.76	51	1	47	16	0.01
BestValidationMCC	0.86	0.73	0.85	0.98	0.76	51	1	47	16	0.01
BestValidationAccuracy	0.86	0.73	0.85	0.98	0.76	51	1	47	16	0.01
TestPredictions (Threshold:0.01)
CHEMBL2348869,TP,ACT,0.10999999940395355	CHEMBL235609,TP,ACT,0.1899999976158142	CHEMBL457528,TP,ACT,0.9700000286102295	CHEMBL3753560,TN,INACT,0.0	CHEMBL3138037,TN,INACT,0.0	CHEMBL573966,TN,INACT,0.0	CHEMBL442243,TP,ACT,0.9599999785423279	CHEMBL2381212,TN,INACT,0.0	CHEMBL3613431,FP,INACT,0.03999999910593033	CHEMBL2403499,TN,INACT,0.0	CHEMBL40738,TP,ACT,0.5699999928474426	CHEMBL3398424,TN,INACT,0.0	CHEMBL86271,TP,ACT,0.9900000095367432	CHEMBL1299837,TN,INACT,0.0	CHEMBL1331729,TN,INACT,0.0	CHEMBL402063,TN,INACT,0.0	CHEMBL236132,TP,ACT,0.3400000035762787	CHEMBL2312279,FN,ACT,0.0	CHEMBL550094,TP,ACT,0.8999999761581421	CHEMBL3397548,TN,INACT,0.0	CHEMBL3261332,TP,ACT,0.11999999731779099	CHEMBL2348881,TN,INACT,0.0	CHEMBL391479,TN,INACT,0.0	CHEMBL2403509,FP,INACT,0.019999999552965164	CHEMBL1461683,TN,INACT,0.0	CHEMBL1447311,TN,INACT,0.0	CHEMBL2204691,TN,INACT,0.0	CHEMBL1642349,TN,INACT,0.0	CHEMBL425366,FN,ACT,0.0	CHEMBL3354989,TN,INACT,0.0	CHEMBL395872,TN,INACT,0.0	CHEMBL250307,TP,ACT,0.8399999737739563	CHEMBL1424125,TN,INACT,0.0	CHEMBL263630,TP,ACT,0.9800000190734863	CHEMBL3126368,TP,ACT,0.27000001072883606	CHEMBL1370919,TN,INACT,0.0	CHEMBL3261322,TP,ACT,0.9800000190734863	CHEMBL2312280,TP,ACT,0.6399999856948853	CHEMBL364368,FN,ACT,0.0	CHEMBL2386485,TN,INACT,0.0	CHEMBL202521,TP,ACT,0.5799999833106995	CHEMBL3397333,FN,ACT,0.009999999776482582	CHEMBL1577661,TN,INACT,0.0	CHEMBL555749,TP,ACT,0.05000000074505806	CHEMBL555726,FP,INACT,0.3199999928474426	CHEMBL520857,TP,ACT,0.8600000143051147	CHEMBL551450,TP,ACT,0.03999999910593033	CHEMBL2403501,TN,INACT,0.0	CHEMBL393201,TP,ACT,0.7200000286102295	CHEMBL15770,TN,INACT,0.0	CHEMBL1464539,TN,INACT,0.0	CHEMBL425939,TP,ACT,0.30000001192092896	CHEMBL394644,TP,ACT,0.019999999552965164	CHEMBL596544,TN,INACT,0.0	CHEMBL253521,TN,INACT,0.0	CHEMBL401392,TP,ACT,0.6100000143051147	CHEMBL560311,TP,ACT,0.5899999737739563	CHEMBL2325060,TN,INACT,0.0	CHEMBL1541779,FP,INACT,0.019999999552965164	CHEMBL551185,FP,INACT,0.6399999856948853	CHEMBL2312272,TP,ACT,0.699999988079071	CHEMBL69091,TN,INACT,0.0	CHEMBL192142,TP,ACT,0.03999999910593033	CHEMBL235788,TP,ACT,0.41999998688697815	CHEMBL596350,TP,ACT,0.9900000095367432	CHEMBL396873,TN,INACT,0.0	CHEMBL2348870,TN,INACT,0.0	CHEMBL361362,TN,INACT,0.009999999776482582	CHEMBL291053,TP,ACT,0.28999999165534973	CHEMBL2381198,TN,INACT,0.0	CHEMBL193615,TP,ACT,0.07000000029802322	CHEMBL3263232,TN,INACT,0.0	CHEMBL1546374,TN,INACT,0.0	CHEMBL491820,FP,INACT,0.8299999833106995	CHEMBL1164770,TN,INACT,0.0	CHEMBL1375737,TN,INACT,0.0	CHEMBL41036,TP,ACT,0.9599999785423279	CHEMBL235816,TP,ACT,0.019999999552965164	CHEMBL485939,FN,ACT,0.009999999776482582	CHEMBL3261336,TP,ACT,0.5799999833106995	CHEMBL1349382,TN,INACT,0.0	CHEMBL3261324,TP,ACT,0.9900000095367432	CHEMBL2348867,TN,INACT,0.0	CHEMBL505084,TP,ACT,0.550000011920929	CHEMBL549418,TN,INACT,0.0	CHEMBL1956370,TN,INACT,0.0	CHEMBL3397338,TP,ACT,0.8799999952316284	CHEMBL557,TP,ACT,0.5600000023841858	CHEMBL3397343,TP,ACT,0.05999999865889549	CHEMBL561245,TP,ACT,0.10999999940395355	CHEMBL1956358,TN,INACT,0.0	CHEMBL477940,TN,INACT,0.0	CHEMBL270781,TN,INACT,0.0	CHEMBL3261325,TP,ACT,0.9700000286102295	CHEMBL192639,FN,ACT,0.0	CHEMBL3126377,FN,ACT,0.0	CHEMBL402714,FN,ACT,0.009999999776482582	CHEMBL457529,TP,ACT,0.949999988079071	CHEMBL235608,TP,ACT,0.8199999928474426	CHEMBL46882,TP,ACT,0.8999999761581421	CHEMBL198875,TP,ACT,0.029999999329447746	CHEMBL1391342,TN,INACT,0.0	CHEMBL192346,TN,INACT,0.0	CHEMBL160703,TP,ACT,0.03999999910593033	CHEMBL236438,TP,ACT,0.3700000047683716	CHEMBL1506123,TN,INACT,0.0	CHEMBL1342384,TN,INACT,0.0	CHEMBL2381203,TN,INACT,0.0	CHEMBL402713,TP,ACT,0.41999998688697815	CHEMBL512383,TP,ACT,0.9700000286102295	CHEMBL237611,TN,INACT,0.0	CHEMBL485928,TP,ACT,0.9300000071525574	CHEMBL3261334,TP,ACT,0.9100000262260437	CHEMBL557905,TP,ACT,0.3700000047683716	CHEMBL1257895,TN,INACT,0.0	

