CNNModel CHEMBL4471 RMSprop 0.0005 30 128 0 0.6 False True
Number of active compounds :	419
Number of inactive compounds :	419
---------------------------------
Run id: CNNModel_CHEMBL4471_RMSprop_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4471_RMSprop_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 399
Validation samples: 125
--
Training Step: 1  | time: 0.768s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/399
[A[ATraining Step: 2  | total loss: [1m[32m0.62365[0m[0m | time: 1.380s
[2K
| RMSProp | epoch: 001 | loss: 0.62365 - acc: 0.5625 -- iter: 064/399
[A[ATraining Step: 3  | total loss: [1m[32m0.68046[0m[0m | time: 1.982s
[2K
| RMSProp | epoch: 001 | loss: 0.68046 - acc: 0.6136 -- iter: 096/399
[A[ATraining Step: 4  | total loss: [1m[32m0.68989[0m[0m | time: 2.594s
[2K
| RMSProp | epoch: 001 | loss: 0.68989 - acc: 0.5987 -- iter: 128/399
[A[ATraining Step: 5  | total loss: [1m[32m0.69208[0m[0m | time: 3.212s
[2K
| RMSProp | epoch: 001 | loss: 0.69208 - acc: 0.5953 -- iter: 160/399
[A[ATraining Step: 6  | total loss: [1m[32m0.69276[0m[0m | time: 3.825s
[2K
| RMSProp | epoch: 001 | loss: 0.69276 - acc: 0.5340 -- iter: 192/399
[A[ATraining Step: 7  | total loss: [1m[32m0.69276[0m[0m | time: 4.436s
[2K
| RMSProp | epoch: 001 | loss: 0.69276 - acc: 0.6636 -- iter: 224/399
[A[ATraining Step: 8  | total loss: [1m[32m0.69273[0m[0m | time: 5.069s
[2K
| RMSProp | epoch: 001 | loss: 0.69273 - acc: 0.6067 -- iter: 256/399
[A[ATraining Step: 9  | total loss: [1m[32m0.69289[0m[0m | time: 5.680s
[2K
| RMSProp | epoch: 001 | loss: 0.69289 - acc: 0.5171 -- iter: 288/399
[A[ATraining Step: 10  | total loss: [1m[32m0.69284[0m[0m | time: 6.312s
[2K
| RMSProp | epoch: 001 | loss: 0.69284 - acc: 0.4929 -- iter: 320/399
[A[ATraining Step: 11  | total loss: [1m[32m0.69292[0m[0m | time: 6.940s
[2K
| RMSProp | epoch: 001 | loss: 0.69292 - acc: 0.5259 -- iter: 352/399
[A[ATraining Step: 12  | total loss: [1m[32m0.69288[0m[0m | time: 7.567s
[2K
| RMSProp | epoch: 001 | loss: 0.69288 - acc: 0.5846 -- iter: 384/399
[A[ATraining Step: 13  | total loss: [1m[32m0.69290[0m[0m | time: 8.921s
[2K
| RMSProp | epoch: 001 | loss: 0.69290 - acc: 0.5751 | val_loss: 0.69324 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 14  | total loss: [1m[32m0.69302[0m[0m | time: 0.306s
[2K
| RMSProp | epoch: 002 | loss: 0.69302 - acc: 0.5580 -- iter: 032/399
[A[ATraining Step: 15  | total loss: [1m[32m0.69304[0m[0m | time: 0.905s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5744 -- iter: 064/399
[A[ATraining Step: 16  | total loss: [1m[32m0.69269[0m[0m | time: 1.519s
[2K
| RMSProp | epoch: 002 | loss: 0.69269 - acc: 0.6754 -- iter: 096/399
[A[ATraining Step: 17  | total loss: [1m[32m0.69263[0m[0m | time: 2.135s
[2K
| RMSProp | epoch: 002 | loss: 0.69263 - acc: 0.6685 -- iter: 128/399
[A[ATraining Step: 18  | total loss: [1m[32m0.69276[0m[0m | time: 2.779s
[2K
| RMSProp | epoch: 002 | loss: 0.69276 - acc: 0.6318 -- iter: 160/399
[A[ATraining Step: 19  | total loss: [1m[32m0.69254[0m[0m | time: 3.388s
[2K
| RMSProp | epoch: 002 | loss: 0.69254 - acc: 0.6608 -- iter: 192/399
[A[ATraining Step: 20  | total loss: [1m[32m0.69263[0m[0m | time: 3.995s
[2K
| RMSProp | epoch: 002 | loss: 0.69263 - acc: 0.6192 -- iter: 224/399
[A[ATraining Step: 21  | total loss: [1m[32m0.69270[0m[0m | time: 4.610s
[2K
| RMSProp | epoch: 002 | loss: 0.69270 - acc: 0.6016 -- iter: 256/399
[A[ATraining Step: 22  | total loss: [1m[32m0.69283[0m[0m | time: 5.245s
[2K
| RMSProp | epoch: 002 | loss: 0.69283 - acc: 0.5711 -- iter: 288/399
[A[ATraining Step: 23  | total loss: [1m[32m0.69304[0m[0m | time: 5.861s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5323 -- iter: 320/399
[A[ATraining Step: 24  | total loss: [1m[32m0.69277[0m[0m | time: 6.471s
[2K
| RMSProp | epoch: 002 | loss: 0.69277 - acc: 0.5760 -- iter: 352/399
[A[ATraining Step: 25  | total loss: [1m[32m0.69292[0m[0m | time: 7.098s
[2K
| RMSProp | epoch: 002 | loss: 0.69292 - acc: 0.5382 -- iter: 384/399
[A[ATraining Step: 26  | total loss: [1m[32m0.69272[0m[0m | time: 8.721s
[2K
| RMSProp | epoch: 002 | loss: 0.69272 - acc: 0.5694 | val_loss: 0.69340 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 27  | total loss: [1m[32m0.69255[0m[0m | time: 0.325s
[2K
| RMSProp | epoch: 003 | loss: 0.69255 - acc: 0.5918 -- iter: 032/399
[A[ATraining Step: 28  | total loss: [1m[32m0.69233[0m[0m | time: 0.631s
[2K
| RMSProp | epoch: 003 | loss: 0.69233 - acc: 0.6105 -- iter: 064/399
[A[ATraining Step: 29  | total loss: [1m[32m0.69212[0m[0m | time: 1.237s
[2K
| RMSProp | epoch: 003 | loss: 0.69212 - acc: 0.6242 -- iter: 096/399
[A[ATraining Step: 30  | total loss: [1m[32m0.69202[0m[0m | time: 1.844s
[2K
| RMSProp | epoch: 003 | loss: 0.69202 - acc: 0.6392 -- iter: 128/399
[A[ATraining Step: 31  | total loss: [1m[32m0.69214[0m[0m | time: 2.457s
[2K
| RMSProp | epoch: 003 | loss: 0.69214 - acc: 0.6215 -- iter: 160/399
[A[ATraining Step: 32  | total loss: [1m[32m0.69231[0m[0m | time: 3.068s
[2K
| RMSProp | epoch: 003 | loss: 0.69231 - acc: 0.6012 -- iter: 192/399
[A[ATraining Step: 33  | total loss: [1m[32m0.69248[0m[0m | time: 3.677s
[2K
| RMSProp | epoch: 003 | loss: 0.69248 - acc: 0.5790 -- iter: 224/399
[A[ATraining Step: 34  | total loss: [1m[32m0.69232[0m[0m | time: 4.285s
[2K
| RMSProp | epoch: 003 | loss: 0.69232 - acc: 0.5955 -- iter: 256/399
[A[ATraining Step: 35  | total loss: [1m[32m0.69211[0m[0m | time: 4.916s
[2K
| RMSProp | epoch: 003 | loss: 0.69211 - acc: 0.6148 -- iter: 288/399
[A[ATraining Step: 36  | total loss: [1m[32m0.69231[0m[0m | time: 5.499s
[2K
| RMSProp | epoch: 003 | loss: 0.69231 - acc: 0.5913 -- iter: 320/399
[A[ATraining Step: 37  | total loss: [1m[32m0.69210[0m[0m | time: 6.100s
[2K
| RMSProp | epoch: 003 | loss: 0.69210 - acc: 0.6043 -- iter: 352/399
[A[ATraining Step: 38  | total loss: [1m[32m0.69206[0m[0m | time: 6.695s
[2K
| RMSProp | epoch: 003 | loss: 0.69206 - acc: 0.6022 -- iter: 384/399
[A[ATraining Step: 39  | total loss: [1m[32m0.69163[0m[0m | time: 8.313s
[2K
| RMSProp | epoch: 003 | loss: 0.69163 - acc: 0.6305 | val_loss: 0.69370 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 40  | total loss: [1m[32m0.69218[0m[0m | time: 0.614s
[2K
| RMSProp | epoch: 004 | loss: 0.69218 - acc: 0.5885 -- iter: 032/399
[A[ATraining Step: 41  | total loss: [1m[32m0.69162[0m[0m | time: 0.917s
[2K
| RMSProp | epoch: 004 | loss: 0.69162 - acc: 0.6239 -- iter: 064/399
[A[ATraining Step: 42  | total loss: [1m[32m0.69158[0m[0m | time: 1.218s
[2K
| RMSProp | epoch: 004 | loss: 0.69158 - acc: 0.6196 -- iter: 096/399
[A[ATraining Step: 43  | total loss: [1m[32m0.69155[0m[0m | time: 1.814s
[2K
| RMSProp | epoch: 004 | loss: 0.69155 - acc: 0.6161 -- iter: 128/399
[A[ATraining Step: 44  | total loss: [1m[32m0.69171[0m[0m | time: 2.417s
[2K
| RMSProp | epoch: 004 | loss: 0.69171 - acc: 0.6014 -- iter: 160/399
[A[ATraining Step: 45  | total loss: [1m[32m0.69168[0m[0m | time: 3.039s
[2K
| RMSProp | epoch: 004 | loss: 0.69168 - acc: 0.6001 -- iter: 192/399
[A[ATraining Step: 46  | total loss: [1m[32m0.69124[0m[0m | time: 3.638s
[2K
| RMSProp | epoch: 004 | loss: 0.69124 - acc: 0.6199 -- iter: 224/399
[A[ATraining Step: 47  | total loss: [1m[32m0.69093[0m[0m | time: 4.237s
[2K
| RMSProp | epoch: 004 | loss: 0.69093 - acc: 0.6310 -- iter: 256/399
[A[ATraining Step: 48  | total loss: [1m[32m0.69120[0m[0m | time: 4.879s
[2K
| RMSProp | epoch: 004 | loss: 0.69120 - acc: 0.6149 -- iter: 288/399
[A[ATraining Step: 49  | total loss: [1m[32m0.69118[0m[0m | time: 5.483s
[2K
| RMSProp | epoch: 004 | loss: 0.69118 - acc: 0.6116 -- iter: 320/399
[A[ATraining Step: 50  | total loss: [1m[32m0.69161[0m[0m | time: 6.086s
[2K
| RMSProp | epoch: 004 | loss: 0.69161 - acc: 0.5894 -- iter: 352/399
[A[ATraining Step: 51  | total loss: [1m[32m0.69150[0m[0m | time: 6.677s
[2K
| RMSProp | epoch: 004 | loss: 0.69150 - acc: 0.5901 -- iter: 384/399
[A[ATraining Step: 52  | total loss: [1m[32m0.69219[0m[0m | time: 8.266s
[2K
| RMSProp | epoch: 004 | loss: 0.69219 - acc: 0.5578 | val_loss: 0.69402 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 53  | total loss: [1m[32m0.69225[0m[0m | time: 0.612s
[2K
| RMSProp | epoch: 005 | loss: 0.69225 - acc: 0.5539 -- iter: 032/399
[A[ATraining Step: 54  | total loss: [1m[32m0.69210[0m[0m | time: 1.230s
[2K
| RMSProp | epoch: 005 | loss: 0.69210 - acc: 0.5597 -- iter: 064/399
[A[ATraining Step: 55  | total loss: [1m[32m0.69181[0m[0m | time: 1.531s
[2K
| RMSProp | epoch: 005 | loss: 0.69181 - acc: 0.5690 -- iter: 096/399
[A[ATraining Step: 56  | total loss: [1m[32m0.69145[0m[0m | time: 1.858s
[2K
| RMSProp | epoch: 005 | loss: 0.69145 - acc: 0.5827 -- iter: 128/399
[A[ATraining Step: 57  | total loss: [1m[32m0.69109[0m[0m | time: 2.465s
[2K
| RMSProp | epoch: 005 | loss: 0.69109 - acc: 0.5944 -- iter: 160/399
[A[ATraining Step: 58  | total loss: [1m[32m0.69090[0m[0m | time: 3.078s
[2K
| RMSProp | epoch: 005 | loss: 0.69090 - acc: 0.5985 -- iter: 192/399
[A[ATraining Step: 59  | total loss: [1m[32m0.68994[0m[0m | time: 3.715s
[2K
| RMSProp | epoch: 005 | loss: 0.68994 - acc: 0.6273 -- iter: 224/399
[A[ATraining Step: 60  | total loss: [1m[32m0.68980[0m[0m | time: 4.339s
[2K
| RMSProp | epoch: 005 | loss: 0.68980 - acc: 0.6270 -- iter: 256/399
[A[ATraining Step: 61  | total loss: [1m[32m0.68968[0m[0m | time: 4.952s
[2K
| RMSProp | epoch: 005 | loss: 0.68968 - acc: 0.6267 -- iter: 288/399
[A[ATraining Step: 62  | total loss: [1m[32m0.69001[0m[0m | time: 5.566s
[2K
| RMSProp | epoch: 005 | loss: 0.69001 - acc: 0.6144 -- iter: 320/399
[A[ATraining Step: 63  | total loss: [1m[32m0.68956[0m[0m | time: 6.168s
[2K
| RMSProp | epoch: 005 | loss: 0.68956 - acc: 0.6237 -- iter: 352/399
[A[ATraining Step: 64  | total loss: [1m[32m0.68989[0m[0m | time: 6.765s
[2K
| RMSProp | epoch: 005 | loss: 0.68989 - acc: 0.6122 -- iter: 384/399
[A[ATraining Step: 65  | total loss: [1m[32m0.68959[0m[0m | time: 8.375s
[2K
| RMSProp | epoch: 005 | loss: 0.68959 - acc: 0.6176 | val_loss: 0.69488 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 66  | total loss: [1m[32m0.68959[0m[0m | time: 0.606s
[2K
| RMSProp | epoch: 006 | loss: 0.68959 - acc: 0.6147 -- iter: 032/399
[A[ATraining Step: 67  | total loss: [1m[32m0.68988[0m[0m | time: 1.258s
[2K
| RMSProp | epoch: 006 | loss: 0.68988 - acc: 0.6047 -- iter: 064/399
[A[ATraining Step: 68  | total loss: [1m[32m0.68970[0m[0m | time: 1.876s
[2K
| RMSProp | epoch: 006 | loss: 0.68970 - acc: 0.6071 -- iter: 096/399
[A[ATraining Step: 69  | total loss: [1m[32m0.69012[0m[0m | time: 2.183s
[2K
| RMSProp | epoch: 006 | loss: 0.69012 - acc: 0.5946 -- iter: 128/399
[A[ATraining Step: 70  | total loss: [1m[32m0.69066[0m[0m | time: 2.489s
[2K
| RMSProp | epoch: 006 | loss: 0.69066 - acc: 0.5798 -- iter: 160/399
[A[ATraining Step: 71  | total loss: [1m[32m0.69117[0m[0m | time: 3.087s
[2K
| RMSProp | epoch: 006 | loss: 0.69117 - acc: 0.5669 -- iter: 192/399
[A[ATraining Step: 72  | total loss: [1m[32m0.69036[0m[0m | time: 3.695s
[2K
| RMSProp | epoch: 006 | loss: 0.69036 - acc: 0.5840 -- iter: 224/399
[A[ATraining Step: 73  | total loss: [1m[32m0.69024[0m[0m | time: 4.316s
[2K
| RMSProp | epoch: 006 | loss: 0.69024 - acc: 0.5851 -- iter: 256/399
[A[ATraining Step: 74  | total loss: [1m[32m0.69009[0m[0m | time: 4.914s
[2K
| RMSProp | epoch: 006 | loss: 0.69009 - acc: 0.5860 -- iter: 288/399
[A[ATraining Step: 75  | total loss: [1m[32m0.68963[0m[0m | time: 5.524s
[2K
| RMSProp | epoch: 006 | loss: 0.68963 - acc: 0.5936 -- iter: 320/399
[A[ATraining Step: 76  | total loss: [1m[32m0.68864[0m[0m | time: 6.124s
[2K
| RMSProp | epoch: 006 | loss: 0.68864 - acc: 0.6104 -- iter: 352/399
[A[ATraining Step: 77  | total loss: [1m[32m0.68824[0m[0m | time: 6.744s
[2K
| RMSProp | epoch: 006 | loss: 0.68824 - acc: 0.6153 -- iter: 384/399
[A[ATraining Step: 78  | total loss: [1m[32m0.68896[0m[0m | time: 8.409s
[2K
| RMSProp | epoch: 006 | loss: 0.68896 - acc: 0.5999 | val_loss: 0.69578 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 79  | total loss: [1m[32m0.68868[0m[0m | time: 0.607s
[2K
| RMSProp | epoch: 007 | loss: 0.68868 - acc: 0.6025 -- iter: 032/399
[A[ATraining Step: 80  | total loss: [1m[32m0.68802[0m[0m | time: 1.213s
[2K
| RMSProp | epoch: 007 | loss: 0.68802 - acc: 0.6112 -- iter: 064/399
[A[ATraining Step: 81  | total loss: [1m[32m0.68756[0m[0m | time: 1.831s
[2K
| RMSProp | epoch: 007 | loss: 0.68756 - acc: 0.6158 -- iter: 096/399
[A[ATraining Step: 82  | total loss: [1m[32m0.68796[0m[0m | time: 2.444s
[2K
| RMSProp | epoch: 007 | loss: 0.68796 - acc: 0.6073 -- iter: 128/399
[A[ATraining Step: 83  | total loss: [1m[32m0.68855[0m[0m | time: 2.764s
[2K
| RMSProp | epoch: 007 | loss: 0.68855 - acc: 0.5966 -- iter: 160/399
[A[ATraining Step: 84  | total loss: [1m[32m0.68974[0m[0m | time: 3.098s
[2K
| RMSProp | epoch: 007 | loss: 0.68974 - acc: 0.5769 -- iter: 192/399
[A[ATraining Step: 85  | total loss: [1m[32m0.69079[0m[0m | time: 3.696s
[2K
| RMSProp | epoch: 007 | loss: 0.69079 - acc: 0.5592 -- iter: 224/399
[A[ATraining Step: 86  | total loss: [1m[32m0.68993[0m[0m | time: 4.337s
[2K
| RMSProp | epoch: 007 | loss: 0.68993 - acc: 0.5721 -- iter: 256/399
[A[ATraining Step: 87  | total loss: [1m[32m0.68970[0m[0m | time: 4.961s
[2K
| RMSProp | epoch: 007 | loss: 0.68970 - acc: 0.5742 -- iter: 288/399
[A[ATraining Step: 88  | total loss: [1m[32m0.68993[0m[0m | time: 5.571s
[2K
| RMSProp | epoch: 007 | loss: 0.68993 - acc: 0.5699 -- iter: 320/399
[A[ATraining Step: 89  | total loss: [1m[32m0.68864[0m[0m | time: 6.181s
[2K
| RMSProp | epoch: 007 | loss: 0.68864 - acc: 0.5879 -- iter: 352/399
[A[ATraining Step: 90  | total loss: [1m[32m0.68753[0m[0m | time: 6.778s
[2K
| RMSProp | epoch: 007 | loss: 0.68753 - acc: 0.6010 -- iter: 384/399
[A[ATraining Step: 91  | total loss: [1m[32m0.68794[0m[0m | time: 8.393s
[2K
| RMSProp | epoch: 007 | loss: 0.68794 - acc: 0.5940 | val_loss: 0.69702 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 92  | total loss: [1m[32m0.68780[0m[0m | time: 0.611s
[2K
| RMSProp | epoch: 008 | loss: 0.68780 - acc: 0.5940 -- iter: 032/399
[A[ATraining Step: 93  | total loss: [1m[32m0.68790[0m[0m | time: 1.226s
[2K
| RMSProp | epoch: 008 | loss: 0.68790 - acc: 0.5909 -- iter: 064/399
[A[ATraining Step: 94  | total loss: [1m[32m0.68851[0m[0m | time: 1.830s
[2K
| RMSProp | epoch: 008 | loss: 0.68851 - acc: 0.5818 -- iter: 096/399
[A[ATraining Step: 95  | total loss: [1m[32m0.68829[0m[0m | time: 2.455s
[2K
| RMSProp | epoch: 008 | loss: 0.68829 - acc: 0.5830 -- iter: 128/399
[A[ATraining Step: 96  | total loss: [1m[32m0.68752[0m[0m | time: 3.066s
[2K
| RMSProp | epoch: 008 | loss: 0.68752 - acc: 0.5903 -- iter: 160/399
[A[ATraining Step: 97  | total loss: [1m[32m0.68706[0m[0m | time: 3.370s
[2K
| RMSProp | epoch: 008 | loss: 0.68706 - acc: 0.5938 -- iter: 192/399
[A[ATraining Step: 98  | total loss: [1m[32m0.68748[0m[0m | time: 3.676s
[2K
| RMSProp | epoch: 008 | loss: 0.68748 - acc: 0.5877 -- iter: 224/399
[A[ATraining Step: 99  | total loss: [1m[32m0.68773[0m[0m | time: 4.282s
[2K
| RMSProp | epoch: 008 | loss: 0.68773 - acc: 0.5823 -- iter: 256/399
[A[ATraining Step: 100  | total loss: [1m[32m0.68748[0m[0m | time: 4.891s
[2K
| RMSProp | epoch: 008 | loss: 0.68748 - acc: 0.5834 -- iter: 288/399
[A[ATraining Step: 101  | total loss: [1m[32m0.68633[0m[0m | time: 5.505s
[2K
| RMSProp | epoch: 008 | loss: 0.68633 - acc: 0.5938 -- iter: 320/399
[A[ATraining Step: 102  | total loss: [1m[32m0.68548[0m[0m | time: 6.125s
[2K
| RMSProp | epoch: 008 | loss: 0.68548 - acc: 0.6001 -- iter: 352/399
[A[ATraining Step: 103  | total loss: [1m[32m0.68785[0m[0m | time: 6.723s
[2K
| RMSProp | epoch: 008 | loss: 0.68785 - acc: 0.5776 -- iter: 384/399
[A[ATraining Step: 104  | total loss: [1m[32m0.68752[0m[0m | time: 8.326s
[2K
| RMSProp | epoch: 008 | loss: 0.68752 - acc: 0.5792 | val_loss: 0.69962 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 105  | total loss: [1m[32m0.68583[0m[0m | time: 0.603s
[2K
| RMSProp | epoch: 009 | loss: 0.68583 - acc: 0.5931 -- iter: 032/399
[A[ATraining Step: 106  | total loss: [1m[32m0.68479[0m[0m | time: 1.196s
[2K
| RMSProp | epoch: 009 | loss: 0.68479 - acc: 0.5995 -- iter: 064/399
[A[ATraining Step: 107  | total loss: [1m[32m0.68418[0m[0m | time: 1.795s
[2K
| RMSProp | epoch: 009 | loss: 0.68418 - acc: 0.6020 -- iter: 096/399
[A[ATraining Step: 108  | total loss: [1m[32m0.68581[0m[0m | time: 2.411s
[2K
| RMSProp | epoch: 009 | loss: 0.68581 - acc: 0.5887 -- iter: 128/399
[A[ATraining Step: 109  | total loss: [1m[32m0.68432[0m[0m | time: 3.017s
[2K
| RMSProp | epoch: 009 | loss: 0.68432 - acc: 0.5986 -- iter: 160/399
[A[ATraining Step: 110  | total loss: [1m[32m0.68318[0m[0m | time: 3.647s
[2K
| RMSProp | epoch: 009 | loss: 0.68318 - acc: 0.6043 -- iter: 192/399
[A[ATraining Step: 111  | total loss: [1m[32m0.68294[0m[0m | time: 3.953s
[2K
| RMSProp | epoch: 009 | loss: 0.68294 - acc: 0.6033 -- iter: 224/399
[A[ATraining Step: 112  | total loss: [1m[32m0.68142[0m[0m | time: 4.260s
[2K
| RMSProp | epoch: 009 | loss: 0.68142 - acc: 0.6096 -- iter: 256/399
[A[ATraining Step: 113  | total loss: [1m[32m0.67975[0m[0m | time: 4.872s
[2K
| RMSProp | epoch: 009 | loss: 0.67975 - acc: 0.6153 -- iter: 288/399
[A[ATraining Step: 114  | total loss: [1m[32m0.68037[0m[0m | time: 5.482s
[2K
| RMSProp | epoch: 009 | loss: 0.68037 - acc: 0.6100 -- iter: 320/399
[A[ATraining Step: 115  | total loss: [1m[32m0.68013[0m[0m | time: 6.116s
[2K
| RMSProp | epoch: 009 | loss: 0.68013 - acc: 0.6084 -- iter: 352/399
[A[ATraining Step: 116  | total loss: [1m[32m0.67923[0m[0m | time: 6.747s
[2K
| RMSProp | epoch: 009 | loss: 0.67923 - acc: 0.6101 -- iter: 384/399
[A[ATraining Step: 117  | total loss: [1m[32m0.67983[0m[0m | time: 8.348s
[2K
| RMSProp | epoch: 009 | loss: 0.67983 - acc: 0.6053 | val_loss: 0.71750 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 118  | total loss: [1m[32m0.67798[0m[0m | time: 0.601s
[2K
| RMSProp | epoch: 010 | loss: 0.67798 - acc: 0.6104 -- iter: 032/399
[A[ATraining Step: 119  | total loss: [1m[32m0.67386[0m[0m | time: 1.204s
[2K
| RMSProp | epoch: 010 | loss: 0.67386 - acc: 0.6212 -- iter: 064/399
[A[ATraining Step: 120  | total loss: [1m[32m0.67535[0m[0m | time: 1.828s
[2K
| RMSProp | epoch: 010 | loss: 0.67535 - acc: 0.6154 -- iter: 096/399
[A[ATraining Step: 121  | total loss: [1m[32m0.67779[0m[0m | time: 2.443s
[2K
| RMSProp | epoch: 010 | loss: 0.67779 - acc: 0.6070 -- iter: 128/399
[A[ATraining Step: 122  | total loss: [1m[32m0.68058[0m[0m | time: 3.051s
[2K
| RMSProp | epoch: 010 | loss: 0.68058 - acc: 0.5963 -- iter: 160/399
[A[ATraining Step: 123  | total loss: [1m[32m0.67934[0m[0m | time: 3.638s
[2K
| RMSProp | epoch: 010 | loss: 0.67934 - acc: 0.5991 -- iter: 192/399
[A[ATraining Step: 124  | total loss: [1m[32m0.68005[0m[0m | time: 4.239s
[2K
| RMSProp | epoch: 010 | loss: 0.68005 - acc: 0.5955 -- iter: 224/399
[A[ATraining Step: 125  | total loss: [1m[32m0.67636[0m[0m | time: 4.538s
[2K
| RMSProp | epoch: 010 | loss: 0.67636 - acc: 0.6078 -- iter: 256/399
[A[ATraining Step: 126  | total loss: [1m[32m0.67067[0m[0m | time: 4.840s
[2K
| RMSProp | epoch: 010 | loss: 0.67067 - acc: 0.6204 -- iter: 288/399
[A[ATraining Step: 127  | total loss: [1m[32m0.66319[0m[0m | time: 5.478s
[2K
| RMSProp | epoch: 010 | loss: 0.66319 - acc: 0.6316 -- iter: 320/399
[A[ATraining Step: 128  | total loss: [1m[32m0.67385[0m[0m | time: 6.094s
[2K
| RMSProp | epoch: 010 | loss: 0.67385 - acc: 0.6216 -- iter: 352/399
[A[ATraining Step: 129  | total loss: [1m[32m0.67087[0m[0m | time: 6.711s
[2K
| RMSProp | epoch: 010 | loss: 0.67087 - acc: 0.6282 -- iter: 384/399
[A[ATraining Step: 130  | total loss: [1m[32m0.66740[0m[0m | time: 8.312s
[2K
| RMSProp | epoch: 010 | loss: 0.66740 - acc: 0.6341 | val_loss: 0.73685 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 131  | total loss: [1m[32m0.66857[0m[0m | time: 0.604s
[2K
| RMSProp | epoch: 011 | loss: 0.66857 - acc: 0.6301 -- iter: 032/399
[A[ATraining Step: 132  | total loss: [1m[32m0.66932[0m[0m | time: 1.207s
[2K
| RMSProp | epoch: 011 | loss: 0.66932 - acc: 0.6265 -- iter: 064/399
[A[ATraining Step: 133  | total loss: [1m[32m0.67130[0m[0m | time: 1.823s
[2K
| RMSProp | epoch: 011 | loss: 0.67130 - acc: 0.6201 -- iter: 096/399
[A[ATraining Step: 134  | total loss: [1m[32m0.67427[0m[0m | time: 2.413s
[2K
| RMSProp | epoch: 011 | loss: 0.67427 - acc: 0.6112 -- iter: 128/399
[A[ATraining Step: 135  | total loss: [1m[32m0.67448[0m[0m | time: 3.007s
[2K
| RMSProp | epoch: 011 | loss: 0.67448 - acc: 0.6094 -- iter: 160/399
[A[ATraining Step: 136  | total loss: [1m[32m0.67569[0m[0m | time: 3.632s
[2K
| RMSProp | epoch: 011 | loss: 0.67569 - acc: 0.6047 -- iter: 192/399
[A[ATraining Step: 137  | total loss: [1m[32m0.67467[0m[0m | time: 4.237s
[2K
| RMSProp | epoch: 011 | loss: 0.67467 - acc: 0.6068 -- iter: 224/399
[A[ATraining Step: 138  | total loss: [1m[32m0.67255[0m[0m | time: 4.843s
[2K
| RMSProp | epoch: 011 | loss: 0.67255 - acc: 0.6117 -- iter: 256/399
[A[ATraining Step: 139  | total loss: [1m[32m0.67411[0m[0m | time: 5.145s
[2K
| RMSProp | epoch: 011 | loss: 0.67411 - acc: 0.6068 -- iter: 288/399
[A[ATraining Step: 140  | total loss: [1m[32m0.67638[0m[0m | time: 5.461s
[2K
| RMSProp | epoch: 011 | loss: 0.67638 - acc: 0.5994 -- iter: 320/399
[A[ATraining Step: 141  | total loss: [1m[32m0.67804[0m[0m | time: 6.067s
[2K
| RMSProp | epoch: 011 | loss: 0.67804 - acc: 0.5928 -- iter: 352/399
[A[ATraining Step: 142  | total loss: [1m[32m0.67716[0m[0m | time: 6.677s
[2K
| RMSProp | epoch: 011 | loss: 0.67716 - acc: 0.5961 -- iter: 384/399
[A[ATraining Step: 143  | total loss: [1m[32m0.67596[0m[0m | time: 8.296s
[2K
| RMSProp | epoch: 011 | loss: 0.67596 - acc: 0.5989 | val_loss: 0.72405 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 144  | total loss: [1m[32m0.67596[0m[0m | time: 0.672s
[2K
| RMSProp | epoch: 012 | loss: 0.67596 - acc: 0.5984 -- iter: 032/399
[A[ATraining Step: 145  | total loss: [1m[32m0.67335[0m[0m | time: 1.301s
[2K
| RMSProp | epoch: 012 | loss: 0.67335 - acc: 0.6042 -- iter: 064/399
[A[ATraining Step: 146  | total loss: [1m[32m0.66762[0m[0m | time: 1.910s
[2K
| RMSProp | epoch: 012 | loss: 0.66762 - acc: 0.6157 -- iter: 096/399
[A[ATraining Step: 147  | total loss: [1m[32m0.67157[0m[0m | time: 2.510s
[2K
| RMSProp | epoch: 012 | loss: 0.67157 - acc: 0.6135 -- iter: 128/399
[A[ATraining Step: 148  | total loss: [1m[32m0.67090[0m[0m | time: 3.090s
[2K
| RMSProp | epoch: 012 | loss: 0.67090 - acc: 0.6146 -- iter: 160/399
[A[ATraining Step: 149  | total loss: [1m[32m0.67734[0m[0m | time: 3.698s
[2K
| RMSProp | epoch: 012 | loss: 0.67734 - acc: 0.5969 -- iter: 192/399
[A[ATraining Step: 150  | total loss: [1m[32m0.67739[0m[0m | time: 4.280s
[2K
| RMSProp | epoch: 012 | loss: 0.67739 - acc: 0.5966 -- iter: 224/399
[A[ATraining Step: 151  | total loss: [1m[32m0.67592[0m[0m | time: 4.910s
[2K
| RMSProp | epoch: 012 | loss: 0.67592 - acc: 0.6026 -- iter: 256/399
[A[ATraining Step: 152  | total loss: [1m[32m0.67410[0m[0m | time: 5.516s
[2K
| RMSProp | epoch: 012 | loss: 0.67410 - acc: 0.6079 -- iter: 288/399
[A[ATraining Step: 153  | total loss: [1m[32m0.67566[0m[0m | time: 5.831s
[2K
| RMSProp | epoch: 012 | loss: 0.67566 - acc: 0.6034 -- iter: 320/399
[A[ATraining Step: 154  | total loss: [1m[32m0.66451[0m[0m | time: 6.142s
[2K
| RMSProp | epoch: 012 | loss: 0.66451 - acc: 0.6364 -- iter: 352/399
[A[ATraining Step: 155  | total loss: [1m[32m0.64014[0m[0m | time: 6.778s
[2K
| RMSProp | epoch: 012 | loss: 0.64014 - acc: 0.6661 -- iter: 384/399
[A[ATraining Step: 156  | total loss: [1m[32m0.70754[0m[0m | time: 8.380s
[2K
| RMSProp | epoch: 012 | loss: 0.70754 - acc: 0.6526 | val_loss: 0.73509 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 157  | total loss: [1m[32m0.71157[0m[0m | time: 0.610s
[2K
| RMSProp | epoch: 013 | loss: 0.71157 - acc: 0.6342 -- iter: 032/399
[A[ATraining Step: 158  | total loss: [1m[32m0.71343[0m[0m | time: 1.209s
[2K
| RMSProp | epoch: 013 | loss: 0.71343 - acc: 0.6177 -- iter: 064/399
[A[ATraining Step: 159  | total loss: [1m[32m0.70721[0m[0m | time: 1.812s
[2K
| RMSProp | epoch: 013 | loss: 0.70721 - acc: 0.6215 -- iter: 096/399
[A[ATraining Step: 160  | total loss: [1m[32m0.70661[0m[0m | time: 2.410s
[2K
| RMSProp | epoch: 013 | loss: 0.70661 - acc: 0.6125 -- iter: 128/399
[A[ATraining Step: 161  | total loss: [1m[32m0.70349[0m[0m | time: 3.052s
[2K
| RMSProp | epoch: 013 | loss: 0.70349 - acc: 0.6106 -- iter: 160/399
[A[ATraining Step: 162  | total loss: [1m[32m0.69598[0m[0m | time: 3.650s
[2K
| RMSProp | epoch: 013 | loss: 0.69598 - acc: 0.6214 -- iter: 192/399
[A[ATraining Step: 163  | total loss: [1m[32m0.69125[0m[0m | time: 4.272s
[2K
| RMSProp | epoch: 013 | loss: 0.69125 - acc: 0.6249 -- iter: 224/399
[A[ATraining Step: 164  | total loss: [1m[32m0.68827[0m[0m | time: 4.887s
[2K
| RMSProp | epoch: 013 | loss: 0.68827 - acc: 0.6249 -- iter: 256/399
[A[ATraining Step: 165  | total loss: [1m[32m0.69160[0m[0m | time: 5.492s
[2K
| RMSProp | epoch: 013 | loss: 0.69160 - acc: 0.6124 -- iter: 288/399
[A[ATraining Step: 166  | total loss: [1m[32m0.68507[0m[0m | time: 6.106s
[2K
| RMSProp | epoch: 013 | loss: 0.68507 - acc: 0.6231 -- iter: 320/399
[A[ATraining Step: 167  | total loss: [1m[32m0.68132[0m[0m | time: 6.410s
[2K
| RMSProp | epoch: 013 | loss: 0.68132 - acc: 0.6264 -- iter: 352/399
[A[ATraining Step: 168  | total loss: [1m[32m0.67015[0m[0m | time: 6.723s
[2K
| RMSProp | epoch: 013 | loss: 0.67015 - acc: 0.6437 -- iter: 384/399
[A[ATraining Step: 169  | total loss: [1m[32m0.65713[0m[0m | time: 8.337s
[2K
| RMSProp | epoch: 013 | loss: 0.65713 - acc: 0.6594 | val_loss: 0.74459 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 170  | total loss: [1m[32m0.66935[0m[0m | time: 0.613s
[2K
| RMSProp | epoch: 014 | loss: 0.66935 - acc: 0.6466 -- iter: 032/399
[A[ATraining Step: 171  | total loss: [1m[32m0.67354[0m[0m | time: 1.247s
[2K
| RMSProp | epoch: 014 | loss: 0.67354 - acc: 0.6350 -- iter: 064/399
[A[ATraining Step: 172  | total loss: [1m[32m0.67364[0m[0m | time: 1.849s
[2K
| RMSProp | epoch: 014 | loss: 0.67364 - acc: 0.6309 -- iter: 096/399
[A[ATraining Step: 173  | total loss: [1m[32m0.67651[0m[0m | time: 2.465s
[2K
| RMSProp | epoch: 014 | loss: 0.67651 - acc: 0.6209 -- iter: 128/399
[A[ATraining Step: 174  | total loss: [1m[32m0.67397[0m[0m | time: 3.089s
[2K
| RMSProp | epoch: 014 | loss: 0.67397 - acc: 0.6245 -- iter: 160/399
[A[ATraining Step: 175  | total loss: [1m[32m0.67679[0m[0m | time: 3.694s
[2K
| RMSProp | epoch: 014 | loss: 0.67679 - acc: 0.6151 -- iter: 192/399
[A[ATraining Step: 176  | total loss: [1m[32m0.67116[0m[0m | time: 4.292s
[2K
| RMSProp | epoch: 014 | loss: 0.67116 - acc: 0.6286 -- iter: 224/399
[A[ATraining Step: 177  | total loss: [1m[32m0.67438[0m[0m | time: 4.913s
[2K
| RMSProp | epoch: 014 | loss: 0.67438 - acc: 0.6189 -- iter: 256/399
[A[ATraining Step: 178  | total loss: [1m[32m0.67704[0m[0m | time: 5.523s
[2K
| RMSProp | epoch: 014 | loss: 0.67704 - acc: 0.6101 -- iter: 288/399
[A[ATraining Step: 179  | total loss: [1m[32m0.67899[0m[0m | time: 6.127s
[2K
| RMSProp | epoch: 014 | loss: 0.67899 - acc: 0.6022 -- iter: 320/399
[A[ATraining Step: 180  | total loss: [1m[32m0.67292[0m[0m | time: 6.769s
[2K
| RMSProp | epoch: 014 | loss: 0.67292 - acc: 0.6201 -- iter: 352/399
[A[ATraining Step: 181  | total loss: [1m[32m0.67596[0m[0m | time: 7.096s
[2K
| RMSProp | epoch: 014 | loss: 0.67596 - acc: 0.6113 -- iter: 384/399
[A[ATraining Step: 182  | total loss: [1m[32m0.67825[0m[0m | time: 8.406s
[2K
| RMSProp | epoch: 014 | loss: 0.67825 - acc: 0.6035 | val_loss: 0.71215 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 183  | total loss: [1m[32m0.67987[0m[0m | time: 0.606s
[2K
| RMSProp | epoch: 015 | loss: 0.67987 - acc: 0.5964 -- iter: 032/399
[A[ATraining Step: 184  | total loss: [1m[32m0.68050[0m[0m | time: 1.195s
[2K
| RMSProp | epoch: 015 | loss: 0.68050 - acc: 0.5931 -- iter: 064/399
[A[ATraining Step: 185  | total loss: [1m[32m0.68010[0m[0m | time: 1.801s
[2K
| RMSProp | epoch: 015 | loss: 0.68010 - acc: 0.5931 -- iter: 096/399
[A[ATraining Step: 186  | total loss: [1m[32m0.68049[0m[0m | time: 2.440s
[2K
| RMSProp | epoch: 015 | loss: 0.68049 - acc: 0.5901 -- iter: 128/399
[A[ATraining Step: 187  | total loss: [1m[32m0.68008[0m[0m | time: 3.064s
[2K
| RMSProp | epoch: 015 | loss: 0.68008 - acc: 0.5904 -- iter: 160/399
[A[ATraining Step: 188  | total loss: [1m[32m0.67969[0m[0m | time: 3.678s
[2K
| RMSProp | epoch: 015 | loss: 0.67969 - acc: 0.5908 -- iter: 192/399
[A[ATraining Step: 189  | total loss: [1m[32m0.67919[0m[0m | time: 4.286s
[2K
| RMSProp | epoch: 015 | loss: 0.67919 - acc: 0.5911 -- iter: 224/399
[A[ATraining Step: 190  | total loss: [1m[32m0.67557[0m[0m | time: 4.885s
[2K
| RMSProp | epoch: 015 | loss: 0.67557 - acc: 0.6007 -- iter: 256/399
[A[ATraining Step: 191  | total loss: [1m[32m0.66986[0m[0m | time: 5.510s
[2K
| RMSProp | epoch: 015 | loss: 0.66986 - acc: 0.6125 -- iter: 288/399
[A[ATraining Step: 192  | total loss: [1m[32m0.66489[0m[0m | time: 6.110s
[2K
| RMSProp | epoch: 015 | loss: 0.66489 - acc: 0.6200 -- iter: 320/399
[A[ATraining Step: 193  | total loss: [1m[32m0.66780[0m[0m | time: 6.726s
[2K
| RMSProp | epoch: 015 | loss: 0.66780 - acc: 0.6174 -- iter: 352/399
[A[ATraining Step: 194  | total loss: [1m[32m0.66338[0m[0m | time: 7.342s
[2K
| RMSProp | epoch: 015 | loss: 0.66338 - acc: 0.6275 -- iter: 384/399
[A[ATraining Step: 195  | total loss: [1m[32m0.65702[0m[0m | time: 8.648s
[2K
| RMSProp | epoch: 015 | loss: 0.65702 - acc: 0.6366 | val_loss: 0.77539 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 196  | total loss: [1m[32m0.65474[0m[0m | time: 0.311s
[2K
| RMSProp | epoch: 016 | loss: 0.65474 - acc: 0.6396 -- iter: 032/399
[A[ATraining Step: 197  | total loss: [1m[32m0.65250[0m[0m | time: 0.931s
[2K
| RMSProp | epoch: 016 | loss: 0.65250 - acc: 0.6423 -- iter: 064/399
[A[ATraining Step: 198  | total loss: [1m[32m0.65384[0m[0m | time: 1.539s
[2K
| RMSProp | epoch: 016 | loss: 0.65384 - acc: 0.6406 -- iter: 096/399
[A[ATraining Step: 199  | total loss: [1m[32m0.65593[0m[0m | time: 2.163s
[2K
| RMSProp | epoch: 016 | loss: 0.65593 - acc: 0.6359 -- iter: 128/399
[A[ATraining Step: 200  | total loss: [1m[32m0.65918[0m[0m | time: 3.764s
[2K
| RMSProp | epoch: 016 | loss: 0.65918 - acc: 0.6286 | val_loss: 0.70429 - val_acc: 0.4640 -- iter: 160/399
--
Training Step: 201  | total loss: [1m[32m0.66389[0m[0m | time: 4.372s
[2K
| RMSProp | epoch: 016 | loss: 0.66389 - acc: 0.6157 -- iter: 192/399
[A[ATraining Step: 202  | total loss: [1m[32m0.66542[0m[0m | time: 4.993s
[2K
| RMSProp | epoch: 016 | loss: 0.66542 - acc: 0.6135 -- iter: 224/399
[A[ATraining Step: 203  | total loss: [1m[32m0.66453[0m[0m | time: 5.596s
[2K
| RMSProp | epoch: 016 | loss: 0.66453 - acc: 0.6178 -- iter: 256/399
[A[ATraining Step: 204  | total loss: [1m[32m0.66940[0m[0m | time: 6.219s
[2K
| RMSProp | epoch: 016 | loss: 0.66940 - acc: 0.6060 -- iter: 288/399
[A[ATraining Step: 205  | total loss: [1m[32m0.67327[0m[0m | time: 6.839s
[2K
| RMSProp | epoch: 016 | loss: 0.67327 - acc: 0.5923 -- iter: 320/399
[A[ATraining Step: 206  | total loss: [1m[32m0.67264[0m[0m | time: 7.442s
[2K
| RMSProp | epoch: 016 | loss: 0.67264 - acc: 0.5987 -- iter: 352/399
[A[ATraining Step: 207  | total loss: [1m[32m0.66946[0m[0m | time: 8.039s
[2K
| RMSProp | epoch: 016 | loss: 0.66946 - acc: 0.6107 -- iter: 384/399
[A[ATraining Step: 208  | total loss: [1m[32m0.67368[0m[0m | time: 9.643s
[2K
| RMSProp | epoch: 016 | loss: 0.67368 - acc: 0.5996 | val_loss: 0.72174 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 209  | total loss: [1m[32m0.67151[0m[0m | time: 0.324s
[2K
| RMSProp | epoch: 017 | loss: 0.67151 - acc: 0.6084 -- iter: 032/399
[A[ATraining Step: 210  | total loss: [1m[32m0.67627[0m[0m | time: 0.644s
[2K
| RMSProp | epoch: 017 | loss: 0.67627 - acc: 0.5942 -- iter: 064/399
[A[ATraining Step: 211  | total loss: [1m[32m0.67937[0m[0m | time: 1.238s
[2K
| RMSProp | epoch: 017 | loss: 0.67937 - acc: 0.5815 -- iter: 096/399
[A[ATraining Step: 212  | total loss: [1m[32m0.68032[0m[0m | time: 1.829s
[2K
| RMSProp | epoch: 017 | loss: 0.68032 - acc: 0.5765 -- iter: 128/399
[A[ATraining Step: 213  | total loss: [1m[32m0.68012[0m[0m | time: 2.434s
[2K
| RMSProp | epoch: 017 | loss: 0.68012 - acc: 0.5782 -- iter: 160/399
[A[ATraining Step: 214  | total loss: [1m[32m0.67799[0m[0m | time: 3.032s
[2K
| RMSProp | epoch: 017 | loss: 0.67799 - acc: 0.5860 -- iter: 192/399
[A[ATraining Step: 215  | total loss: [1m[32m0.68206[0m[0m | time: 3.638s
[2K
| RMSProp | epoch: 017 | loss: 0.68206 - acc: 0.5711 -- iter: 224/399
[A[ATraining Step: 216  | total loss: [1m[32m0.67971[0m[0m | time: 4.236s
[2K
| RMSProp | epoch: 017 | loss: 0.67971 - acc: 0.5828 -- iter: 256/399
[A[ATraining Step: 217  | total loss: [1m[32m0.67679[0m[0m | time: 4.842s
[2K
| RMSProp | epoch: 017 | loss: 0.67679 - acc: 0.5933 -- iter: 288/399
[A[ATraining Step: 218  | total loss: [1m[32m0.67769[0m[0m | time: 5.420s
[2K
| RMSProp | epoch: 017 | loss: 0.67769 - acc: 0.5902 -- iter: 320/399
[A[ATraining Step: 219  | total loss: [1m[32m0.67695[0m[0m | time: 6.047s
[2K
| RMSProp | epoch: 017 | loss: 0.67695 - acc: 0.5905 -- iter: 352/399
[A[ATraining Step: 220  | total loss: [1m[32m0.67554[0m[0m | time: 6.661s
[2K
| RMSProp | epoch: 017 | loss: 0.67554 - acc: 0.5940 -- iter: 384/399
[A[ATraining Step: 221  | total loss: [1m[32m0.67504[0m[0m | time: 8.287s
[2K
| RMSProp | epoch: 017 | loss: 0.67504 - acc: 0.5940 | val_loss: 0.73435 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 222  | total loss: [1m[32m0.67361[0m[0m | time: 0.599s
[2K
| RMSProp | epoch: 018 | loss: 0.67361 - acc: 0.5971 -- iter: 032/399
[A[ATraining Step: 223  | total loss: [1m[32m0.67021[0m[0m | time: 0.899s
[2K
| RMSProp | epoch: 018 | loss: 0.67021 - acc: 0.6030 -- iter: 064/399
[A[ATraining Step: 224  | total loss: [1m[32m0.67569[0m[0m | time: 1.211s
[2K
| RMSProp | epoch: 018 | loss: 0.67569 - acc: 0.5960 -- iter: 096/399
[A[ATraining Step: 225  | total loss: [1m[32m0.67672[0m[0m | time: 1.819s
[2K
| RMSProp | epoch: 018 | loss: 0.67672 - acc: 0.5897 -- iter: 128/399
[A[ATraining Step: 226  | total loss: [1m[32m0.67773[0m[0m | time: 2.407s
[2K
| RMSProp | epoch: 018 | loss: 0.67773 - acc: 0.5839 -- iter: 160/399
[A[ATraining Step: 227  | total loss: [1m[32m0.67808[0m[0m | time: 3.018s
[2K
| RMSProp | epoch: 018 | loss: 0.67808 - acc: 0.5786 -- iter: 192/399
[A[ATraining Step: 228  | total loss: [1m[32m0.67447[0m[0m | time: 3.622s
[2K
| RMSProp | epoch: 018 | loss: 0.67447 - acc: 0.5926 -- iter: 224/399
[A[ATraining Step: 229  | total loss: [1m[32m0.67112[0m[0m | time: 4.229s
[2K
| RMSProp | epoch: 018 | loss: 0.67112 - acc: 0.5990 -- iter: 256/399
[A[ATraining Step: 230  | total loss: [1m[32m0.66724[0m[0m | time: 4.833s
[2K
| RMSProp | epoch: 018 | loss: 0.66724 - acc: 0.6047 -- iter: 288/399
[A[ATraining Step: 231  | total loss: [1m[32m0.67393[0m[0m | time: 5.450s
[2K
| RMSProp | epoch: 018 | loss: 0.67393 - acc: 0.5943 -- iter: 320/399
[A[ATraining Step: 232  | total loss: [1m[32m0.67316[0m[0m | time: 6.065s
[2K
| RMSProp | epoch: 018 | loss: 0.67316 - acc: 0.5973 -- iter: 352/399
[A[ATraining Step: 233  | total loss: [1m[32m0.67398[0m[0m | time: 6.663s
[2K
| RMSProp | epoch: 018 | loss: 0.67398 - acc: 0.5938 -- iter: 384/399
[A[ATraining Step: 234  | total loss: [1m[32m0.67222[0m[0m | time: 8.269s
[2K
| RMSProp | epoch: 018 | loss: 0.67222 - acc: 0.5970 | val_loss: 0.71371 - val_acc: 0.4640 -- iter: 399/399
--
Training Step: 235  | total loss: [1m[32m0.66987[0m[0m | time: 0.630s
[2K
| RMSProp | epoch: 019 | loss: 0.66987 - acc: 0.5998 -- iter: 032/399
[A[ATraining Step: 236  | total loss: [1m[32m0.67469[0m[0m | time: 1.233s
[2K
| RMSProp | epoch: 019 | loss: 0.67469 - acc: 0.5867 -- iter: 064/399
[A[ATraining Step: 237  | total loss: [1m[32m0.67501[0m[0m | time: 1.568s
[2K
| RMSProp | epoch: 019 | loss: 0.67501 - acc: 0.6061 -- iter: 096/399
[A[ATraining Step: 238  | total loss: [1m[32m0.68112[0m[0m | time: 1.874s
[2K
| RMSProp | epoch: 019 | loss: 0.68112 - acc: 0.5788 -- iter: 128/399
[A[ATraining Step: 239  | total loss: [1m[32m0.68362[0m[0m | time: 2.474s
[2K
| RMSProp | epoch: 019 | loss: 0.68362 - acc: 0.5543 -- iter: 160/399
[A[ATraining Step: 240  | total loss: [1m[32m0.68325[0m[0m | time: 3.091s
[2K
| RMSProp | epoch: 019 | loss: 0.68325 - acc: 0.5551 -- iter: 192/399
[A[ATraining Step: 241  | total loss: [1m[32m0.68174[0m[0m | time: 3.701s
[2K
| RMSProp | epoch: 019 | loss: 0.68174 - acc: 0.5559 -- iter: 224/399
[A[ATraining Step: 242  | total loss: [1m[32m0.67962[0m[0m | time: 4.321s
[2K
| RMSProp | epoch: 019 | loss: 0.67962 - acc: 0.5628 -- iter: 256/399
[A[ATraining Step: 243  | total loss: [1m[32m0.67592[0m[0m | time: 4.925s
[2K
| RMSProp | epoch: 019 | loss: 0.67592 - acc: 0.5690 -- iter: 288/399
[A[ATraining Step: 244  | total loss: [1m[32m0.67314[0m[0m | time: 5.532s
[2K
| RMSProp | epoch: 019 | loss: 0.67314 - acc: 0.5715 -- iter: 320/399
[A[ATraining Step: 245  | total loss: [1m[32m0.66706[0m[0m | time: 6.136s
[2K
| RMSProp | epoch: 019 | loss: 0.66706 - acc: 0.5799 -- iter: 352/399
[A[ATraining Step: 246  | total loss: [1m[32m0.65920[0m[0m | time: 6.731s
[2K
| RMSProp | epoch: 019 | loss: 0.65920 - acc: 0.5907 -- iter: 384/399
[A[ATraining Step: 247  | total loss: [1m[32m0.65953[0m[0m | time: 8.343s
[2K
| RMSProp | epoch: 019 | loss: 0.65953 - acc: 0.5941 | val_loss: 0.68272 - val_acc: 0.5920 -- iter: 399/399
--
Training Step: 248  | total loss: [1m[32m0.65782[0m[0m | time: 0.630s
[2K
| RMSProp | epoch: 020 | loss: 0.65782 - acc: 0.5941 -- iter: 032/399
[A[ATraining Step: 249  | total loss: [1m[32m0.65053[0m[0m | time: 1.232s
[2K
| RMSProp | epoch: 020 | loss: 0.65053 - acc: 0.6159 -- iter: 064/399
[A[ATraining Step: 250  | total loss: [1m[32m0.67154[0m[0m | time: 1.834s
[2K
| RMSProp | epoch: 020 | loss: 0.67154 - acc: 0.6106 -- iter: 096/399
[A[ATraining Step: 251  | total loss: [1m[32m0.67215[0m[0m | time: 2.139s
[2K
| RMSProp | epoch: 020 | loss: 0.67215 - acc: 0.6089 -- iter: 128/399
[A[ATraining Step: 252  | total loss: [1m[32m0.66377[0m[0m | time: 2.450s
[2K
| RMSProp | epoch: 020 | loss: 0.66377 - acc: 0.6347 -- iter: 160/399
[A[ATraining Step: 253  | total loss: [1m[32m0.64868[0m[0m | time: 3.051s
[2K
| RMSProp | epoch: 020 | loss: 0.64868 - acc: 0.6579 -- iter: 192/399
[A[ATraining Step: 254  | total loss: [1m[32m0.65443[0m[0m | time: 3.666s
[2K
| RMSProp | epoch: 020 | loss: 0.65443 - acc: 0.6483 -- iter: 224/399
[A[ATraining Step: 255  | total loss: [1m[32m0.66095[0m[0m | time: 4.265s
[2K
| RMSProp | epoch: 020 | loss: 0.66095 - acc: 0.6335 -- iter: 256/399
[A[ATraining Step: 256  | total loss: [1m[32m0.65268[0m[0m | time: 4.875s
[2K
| RMSProp | epoch: 020 | loss: 0.65268 - acc: 0.6483 -- iter: 288/399
[A[ATraining Step: 257  | total loss: [1m[32m0.65566[0m[0m | time: 5.484s
[2K
| RMSProp | epoch: 020 | loss: 0.65566 - acc: 0.6366 -- iter: 320/399
[A[ATraining Step: 258  | total loss: [1m[32m0.65865[0m[0m | time: 6.090s
[2K
| RMSProp | epoch: 020 | loss: 0.65865 - acc: 0.6229 -- iter: 352/399
[A[ATraining Step: 259  | total loss: [1m[32m0.65841[0m[0m | time: 6.689s
[2K
| RMSProp | epoch: 020 | loss: 0.65841 - acc: 0.6231 -- iter: 384/399
[A[ATraining Step: 260  | total loss: [1m[32m0.65441[0m[0m | time: 8.299s
[2K
| RMSProp | epoch: 020 | loss: 0.65441 - acc: 0.6389 | val_loss: 0.72250 - val_acc: 0.5280 -- iter: 399/399
--
Training Step: 261  | total loss: [1m[32m0.64561[0m[0m | time: 0.612s
[2K
| RMSProp | epoch: 021 | loss: 0.64561 - acc: 0.6375 -- iter: 032/399
[A[ATraining Step: 262  | total loss: [1m[32m0.64049[0m[0m | time: 1.208s
[2K
| RMSProp | epoch: 021 | loss: 0.64049 - acc: 0.6425 -- iter: 064/399
[A[ATraining Step: 263  | total loss: [1m[32m0.63129[0m[0m | time: 1.851s
[2K
| RMSProp | epoch: 021 | loss: 0.63129 - acc: 0.6595 -- iter: 096/399
[A[ATraining Step: 264  | total loss: [1m[32m0.62884[0m[0m | time: 2.450s
[2K
| RMSProp | epoch: 021 | loss: 0.62884 - acc: 0.6561 -- iter: 128/399
[A[ATraining Step: 265  | total loss: [1m[32m0.63010[0m[0m | time: 2.750s
[2K
| RMSProp | epoch: 021 | loss: 0.63010 - acc: 0.6624 -- iter: 160/399
[A[ATraining Step: 266  | total loss: [1m[32m0.61706[0m[0m | time: 3.067s
[2K
| RMSProp | epoch: 021 | loss: 0.61706 - acc: 0.6828 -- iter: 192/399
[A[ATraining Step: 267  | total loss: [1m[32m0.59806[0m[0m | time: 3.664s
[2K
| RMSProp | epoch: 021 | loss: 0.59806 - acc: 0.6945 -- iter: 224/399
[A[ATraining Step: 268  | total loss: [1m[32m0.59980[0m[0m | time: 4.261s
[2K
| RMSProp | epoch: 021 | loss: 0.59980 - acc: 0.7032 -- iter: 256/399
[A[ATraining Step: 269  | total loss: [1m[32m0.62461[0m[0m | time: 4.890s
[2K
| RMSProp | epoch: 021 | loss: 0.62461 - acc: 0.6735 -- iter: 288/399
[A[ATraining Step: 270  | total loss: [1m[32m0.62077[0m[0m | time: 5.496s
[2K
| RMSProp | epoch: 021 | loss: 0.62077 - acc: 0.6749 -- iter: 320/399
[A[ATraining Step: 271  | total loss: [1m[32m0.63277[0m[0m | time: 6.106s
[2K
| RMSProp | epoch: 021 | loss: 0.63277 - acc: 0.6605 -- iter: 352/399
[A[ATraining Step: 272  | total loss: [1m[32m0.63635[0m[0m | time: 6.712s
[2K
| RMSProp | epoch: 021 | loss: 0.63635 - acc: 0.6570 -- iter: 384/399
[A[ATraining Step: 273  | total loss: [1m[32m0.63300[0m[0m | time: 8.324s
[2K
| RMSProp | epoch: 021 | loss: 0.63300 - acc: 0.6663 | val_loss: 0.68399 - val_acc: 0.6080 -- iter: 399/399
--
Training Step: 274  | total loss: [1m[32m0.63059[0m[0m | time: 0.601s
[2K
| RMSProp | epoch: 022 | loss: 0.63059 - acc: 0.6746 -- iter: 032/399
[A[ATraining Step: 275  | total loss: [1m[32m0.62788[0m[0m | time: 1.215s
[2K
| RMSProp | epoch: 022 | loss: 0.62788 - acc: 0.6666 -- iter: 064/399
[A[ATraining Step: 276  | total loss: [1m[32m0.62305[0m[0m | time: 1.821s
[2K
| RMSProp | epoch: 022 | loss: 0.62305 - acc: 0.6749 -- iter: 096/399
[A[ATraining Step: 277  | total loss: [1m[32m0.63120[0m[0m | time: 2.422s
[2K
| RMSProp | epoch: 022 | loss: 0.63120 - acc: 0.6730 -- iter: 128/399
[A[ATraining Step: 278  | total loss: [1m[32m0.62919[0m[0m | time: 3.010s
[2K
| RMSProp | epoch: 022 | loss: 0.62919 - acc: 0.6714 -- iter: 160/399
[A[ATraining Step: 279  | total loss: [1m[32m0.63259[0m[0m | time: 3.325s
[2K
| RMSProp | epoch: 022 | loss: 0.63259 - acc: 0.6573 -- iter: 192/399
[A[ATraining Step: 280  | total loss: [1m[32m0.62537[0m[0m | time: 3.650s
[2K
| RMSProp | epoch: 022 | loss: 0.62537 - acc: 0.6716 -- iter: 224/399
[A[ATraining Step: 281  | total loss: [1m[32m0.61413[0m[0m | time: 4.283s
[2K
| RMSProp | epoch: 022 | loss: 0.61413 - acc: 0.6845 -- iter: 256/399
[A[ATraining Step: 282  | total loss: [1m[32m0.60523[0m[0m | time: 4.896s
[2K
| RMSProp | epoch: 022 | loss: 0.60523 - acc: 0.6941 -- iter: 288/399
[A[ATraining Step: 283  | total loss: [1m[32m0.60804[0m[0m | time: 5.497s
[2K
| RMSProp | epoch: 022 | loss: 0.60804 - acc: 0.6872 -- iter: 320/399
[A[ATraining Step: 284  | total loss: [1m[32m0.60571[0m[0m | time: 6.111s
[2K
| RMSProp | epoch: 022 | loss: 0.60571 - acc: 0.6841 -- iter: 352/399
[A[ATraining Step: 285  | total loss: [1m[32m0.59281[0m[0m | time: 6.718s
[2K
| RMSProp | epoch: 022 | loss: 0.59281 - acc: 0.7032 -- iter: 384/399
[A[ATraining Step: 286  | total loss: [1m[32m0.59830[0m[0m | time: 8.330s
[2K
| RMSProp | epoch: 022 | loss: 0.59830 - acc: 0.6954 | val_loss: 0.64744 - val_acc: 0.6400 -- iter: 399/399
--
Training Step: 287  | total loss: [1m[32m0.59937[0m[0m | time: 0.624s
[2K
| RMSProp | epoch: 023 | loss: 0.59937 - acc: 0.6946 -- iter: 032/399
[A[ATraining Step: 288  | total loss: [1m[32m0.59925[0m[0m | time: 1.225s
[2K
| RMSProp | epoch: 023 | loss: 0.59925 - acc: 0.6876 -- iter: 064/399
[A[ATraining Step: 289  | total loss: [1m[32m0.59406[0m[0m | time: 1.825s
[2K
| RMSProp | epoch: 023 | loss: 0.59406 - acc: 0.6939 -- iter: 096/399
[A[ATraining Step: 290  | total loss: [1m[32m0.59497[0m[0m | time: 2.472s
[2K
| RMSProp | epoch: 023 | loss: 0.59497 - acc: 0.6901 -- iter: 128/399
[A[ATraining Step: 291  | total loss: [1m[32m0.59434[0m[0m | time: 3.073s
[2K
| RMSProp | epoch: 023 | loss: 0.59434 - acc: 0.6930 -- iter: 160/399
[A[ATraining Step: 292  | total loss: [1m[32m0.58886[0m[0m | time: 3.710s
[2K
| RMSProp | epoch: 023 | loss: 0.58886 - acc: 0.6956 -- iter: 192/399
[A[ATraining Step: 293  | total loss: [1m[32m0.57957[0m[0m | time: 4.020s
[2K
| RMSProp | epoch: 023 | loss: 0.57957 - acc: 0.7072 -- iter: 224/399
[A[ATraining Step: 294  | total loss: [1m[32m0.58508[0m[0m | time: 4.318s
[2K
| RMSProp | epoch: 023 | loss: 0.58508 - acc: 0.7032 -- iter: 256/399
[A[ATraining Step: 295  | total loss: [1m[32m0.58096[0m[0m | time: 4.912s
[2K
| RMSProp | epoch: 023 | loss: 0.58096 - acc: 0.7129 -- iter: 288/399
[A[ATraining Step: 296  | total loss: [1m[32m0.58032[0m[0m | time: 5.539s
[2K
| RMSProp | epoch: 023 | loss: 0.58032 - acc: 0.7135 -- iter: 320/399
[A[ATraining Step: 297  | total loss: [1m[32m0.58250[0m[0m | time: 6.142s
[2K
| RMSProp | epoch: 023 | loss: 0.58250 - acc: 0.7109 -- iter: 352/399
[A[ATraining Step: 298  | total loss: [1m[32m0.56950[0m[0m | time: 6.743s
[2K
| RMSProp | epoch: 023 | loss: 0.56950 - acc: 0.7210 -- iter: 384/399
[A[ATraining Step: 299  | total loss: [1m[32m0.57176[0m[0m | time: 8.362s
[2K
| RMSProp | epoch: 023 | loss: 0.57176 - acc: 0.7208 | val_loss: 0.72301 - val_acc: 0.5360 -- iter: 399/399
--
Training Step: 300  | total loss: [1m[32m0.57535[0m[0m | time: 0.605s
[2K
| RMSProp | epoch: 024 | loss: 0.57535 - acc: 0.7237 -- iter: 032/399
[A[ATraining Step: 301  | total loss: [1m[32m0.57847[0m[0m | time: 1.225s
[2K
| RMSProp | epoch: 024 | loss: 0.57847 - acc: 0.7170 -- iter: 064/399
[A[ATraining Step: 302  | total loss: [1m[32m0.58154[0m[0m | time: 1.843s
[2K
| RMSProp | epoch: 024 | loss: 0.58154 - acc: 0.7140 -- iter: 096/399
[A[ATraining Step: 303  | total loss: [1m[32m0.57837[0m[0m | time: 2.439s
[2K
| RMSProp | epoch: 024 | loss: 0.57837 - acc: 0.7114 -- iter: 128/399
[A[ATraining Step: 304  | total loss: [1m[32m0.57367[0m[0m | time: 3.048s
[2K
| RMSProp | epoch: 024 | loss: 0.57367 - acc: 0.7121 -- iter: 160/399
[A[ATraining Step: 305  | total loss: [1m[32m0.56670[0m[0m | time: 3.658s
[2K
| RMSProp | epoch: 024 | loss: 0.56670 - acc: 0.7159 -- iter: 192/399
[A[ATraining Step: 306  | total loss: [1m[32m0.55279[0m[0m | time: 4.291s
[2K
| RMSProp | epoch: 024 | loss: 0.55279 - acc: 0.7287 -- iter: 224/399
[A[ATraining Step: 307  | total loss: [1m[32m0.56399[0m[0m | time: 4.592s
[2K
| RMSProp | epoch: 024 | loss: 0.56399 - acc: 0.7183 -- iter: 256/399
[A[ATraining Step: 308  | total loss: [1m[32m0.59427[0m[0m | time: 4.890s
[2K
| RMSProp | epoch: 024 | loss: 0.59427 - acc: 0.6665 -- iter: 288/399
[A[ATraining Step: 309  | total loss: [1m[32m0.57081[0m[0m | time: 5.497s
[2K
| RMSProp | epoch: 024 | loss: 0.57081 - acc: 0.6865 -- iter: 320/399
[A[ATraining Step: 310  | total loss: [1m[32m0.56872[0m[0m | time: 6.094s
[2K
| RMSProp | epoch: 024 | loss: 0.56872 - acc: 0.6897 -- iter: 352/399
[A[ATraining Step: 311  | total loss: [1m[32m0.56203[0m[0m | time: 6.695s
[2K
| RMSProp | epoch: 024 | loss: 0.56203 - acc: 0.6989 -- iter: 384/399
[A[ATraining Step: 312  | total loss: [1m[32m0.55424[0m[0m | time: 8.304s
[2K
| RMSProp | epoch: 024 | loss: 0.55424 - acc: 0.7071 | val_loss: 0.61149 - val_acc: 0.6880 -- iter: 399/399
--
Training Step: 313  | total loss: [1m[32m0.53824[0m[0m | time: 0.625s
[2K
| RMSProp | epoch: 025 | loss: 0.53824 - acc: 0.7239 -- iter: 032/399
[A[ATraining Step: 314  | total loss: [1m[32m0.52471[0m[0m | time: 1.234s
[2K
| RMSProp | epoch: 025 | loss: 0.52471 - acc: 0.7390 -- iter: 064/399
[A[ATraining Step: 315  | total loss: [1m[32m0.53218[0m[0m | time: 1.838s
[2K
| RMSProp | epoch: 025 | loss: 0.53218 - acc: 0.7245 -- iter: 096/399
[A[ATraining Step: 316  | total loss: [1m[32m0.53095[0m[0m | time: 2.444s
[2K
| RMSProp | epoch: 025 | loss: 0.53095 - acc: 0.7270 -- iter: 128/399
[A[ATraining Step: 317  | total loss: [1m[32m0.52791[0m[0m | time: 3.065s
[2K
| RMSProp | epoch: 025 | loss: 0.52791 - acc: 0.7231 -- iter: 160/399
[A[ATraining Step: 318  | total loss: [1m[32m0.54061[0m[0m | time: 3.677s
[2K
| RMSProp | epoch: 025 | loss: 0.54061 - acc: 0.7039 -- iter: 192/399
[A[ATraining Step: 319  | total loss: [1m[32m0.53976[0m[0m | time: 4.278s
[2K
| RMSProp | epoch: 025 | loss: 0.53976 - acc: 0.7054 -- iter: 224/399
[A[ATraining Step: 320  | total loss: [1m[32m0.53266[0m[0m | time: 4.894s
[2K
| RMSProp | epoch: 025 | loss: 0.53266 - acc: 0.7192 -- iter: 256/399
[A[ATraining Step: 321  | total loss: [1m[32m0.52396[0m[0m | time: 5.212s
[2K
| RMSProp | epoch: 025 | loss: 0.52396 - acc: 0.7254 -- iter: 288/399
[A[ATraining Step: 322  | total loss: [1m[32m0.53302[0m[0m | time: 5.523s
[2K
| RMSProp | epoch: 025 | loss: 0.53302 - acc: 0.7195 -- iter: 320/399
[A[ATraining Step: 323  | total loss: [1m[32m0.53460[0m[0m | time: 6.133s
[2K
| RMSProp | epoch: 025 | loss: 0.53460 - acc: 0.7076 -- iter: 352/399
[A[ATraining Step: 324  | total loss: [1m[32m0.52520[0m[0m | time: 6.729s
[2K
| RMSProp | epoch: 025 | loss: 0.52520 - acc: 0.7150 -- iter: 384/399
[A[ATraining Step: 325  | total loss: [1m[32m0.52702[0m[0m | time: 8.347s
[2K
| RMSProp | epoch: 025 | loss: 0.52702 - acc: 0.7185 | val_loss: 0.57276 - val_acc: 0.7040 -- iter: 399/399
--
Training Step: 326  | total loss: [1m[32m0.51887[0m[0m | time: 0.624s
[2K
| RMSProp | epoch: 026 | loss: 0.51887 - acc: 0.7247 -- iter: 032/399
[A[ATraining Step: 327  | total loss: [1m[32m0.51746[0m[0m | time: 1.228s
[2K
| RMSProp | epoch: 026 | loss: 0.51746 - acc: 0.7241 -- iter: 064/399
[A[ATraining Step: 328  | total loss: [1m[32m0.52718[0m[0m | time: 1.834s
[2K
| RMSProp | epoch: 026 | loss: 0.52718 - acc: 0.7142 -- iter: 096/399
[A[ATraining Step: 329  | total loss: [1m[32m0.53771[0m[0m | time: 2.446s
[2K
| RMSProp | epoch: 026 | loss: 0.53771 - acc: 0.7084 -- iter: 128/399
[A[ATraining Step: 330  | total loss: [1m[32m0.53697[0m[0m | time: 3.050s
[2K
| RMSProp | epoch: 026 | loss: 0.53697 - acc: 0.7063 -- iter: 160/399
[A[ATraining Step: 331  | total loss: [1m[32m0.52727[0m[0m | time: 3.664s
[2K
| RMSProp | epoch: 026 | loss: 0.52727 - acc: 0.7232 -- iter: 192/399
[A[ATraining Step: 332  | total loss: [1m[32m0.51776[0m[0m | time: 4.299s
[2K
| RMSProp | epoch: 026 | loss: 0.51776 - acc: 0.7321 -- iter: 224/399
[A[ATraining Step: 333  | total loss: [1m[32m0.51241[0m[0m | time: 4.908s
[2K
| RMSProp | epoch: 026 | loss: 0.51241 - acc: 0.7339 -- iter: 256/399
[A[ATraining Step: 334  | total loss: [1m[32m0.49857[0m[0m | time: 5.533s
[2K
| RMSProp | epoch: 026 | loss: 0.49857 - acc: 0.7449 -- iter: 288/399
[A[ATraining Step: 335  | total loss: [1m[32m0.49117[0m[0m | time: 5.839s
[2K
| RMSProp | epoch: 026 | loss: 0.49117 - acc: 0.7454 -- iter: 320/399
[A[ATraining Step: 336  | total loss: [1m[32m0.51643[0m[0m | time: 6.139s
[2K
| RMSProp | epoch: 026 | loss: 0.51643 - acc: 0.7309 -- iter: 352/399
[A[ATraining Step: 337  | total loss: [1m[32m0.51055[0m[0m | time: 6.746s
[2K
| RMSProp | epoch: 026 | loss: 0.51055 - acc: 0.7311 -- iter: 384/399
[A[ATraining Step: 338  | total loss: [1m[32m0.51561[0m[0m | time: 8.353s
[2K
| RMSProp | epoch: 026 | loss: 0.51561 - acc: 0.7268 | val_loss: 0.76930 - val_acc: 0.5680 -- iter: 399/399
--
Training Step: 339  | total loss: [1m[32m0.51250[0m[0m | time: 0.619s
[2K
| RMSProp | epoch: 027 | loss: 0.51250 - acc: 0.7353 -- iter: 032/399
[A[ATraining Step: 340  | total loss: [1m[32m0.50549[0m[0m | time: 1.228s
[2K
| RMSProp | epoch: 027 | loss: 0.50549 - acc: 0.7368 -- iter: 064/399
[A[ATraining Step: 341  | total loss: [1m[32m0.48986[0m[0m | time: 1.842s
[2K
| RMSProp | epoch: 027 | loss: 0.48986 - acc: 0.7537 -- iter: 096/399
[A[ATraining Step: 342  | total loss: [1m[32m0.47125[0m[0m | time: 2.450s
[2K
| RMSProp | epoch: 027 | loss: 0.47125 - acc: 0.7721 -- iter: 128/399
[A[ATraining Step: 343  | total loss: [1m[32m0.46951[0m[0m | time: 3.051s
[2K
| RMSProp | epoch: 027 | loss: 0.46951 - acc: 0.7699 -- iter: 160/399
[A[ATraining Step: 344  | total loss: [1m[32m0.47652[0m[0m | time: 3.665s
[2K
| RMSProp | epoch: 027 | loss: 0.47652 - acc: 0.7679 -- iter: 192/399
[A[ATraining Step: 345  | total loss: [1m[32m0.47894[0m[0m | time: 4.261s
[2K
| RMSProp | epoch: 027 | loss: 0.47894 - acc: 0.7692 -- iter: 224/399
[A[ATraining Step: 346  | total loss: [1m[32m0.46954[0m[0m | time: 4.892s
[2K
| RMSProp | epoch: 027 | loss: 0.46954 - acc: 0.7861 -- iter: 256/399
[A[ATraining Step: 347  | total loss: [1m[32m0.45979[0m[0m | time: 5.491s
[2K
| RMSProp | epoch: 027 | loss: 0.45979 - acc: 0.7887 -- iter: 288/399
[A[ATraining Step: 348  | total loss: [1m[32m0.45970[0m[0m | time: 6.103s
[2K
| RMSProp | epoch: 027 | loss: 0.45970 - acc: 0.7911 -- iter: 320/399
[A[ATraining Step: 349  | total loss: [1m[32m0.48363[0m[0m | time: 6.413s
[2K
| RMSProp | epoch: 027 | loss: 0.48363 - acc: 0.7807 -- iter: 352/399
[A[ATraining Step: 350  | total loss: [1m[32m0.47909[0m[0m | time: 6.719s
[2K
| RMSProp | epoch: 027 | loss: 0.47909 - acc: 0.7960 -- iter: 384/399
[A[ATraining Step: 351  | total loss: [1m[32m0.46190[0m[0m | time: 8.331s
[2K
| RMSProp | epoch: 027 | loss: 0.46190 - acc: 0.8031 | val_loss: 0.67074 - val_acc: 0.6560 -- iter: 399/399
--
Training Step: 352  | total loss: [1m[32m0.44548[0m[0m | time: 0.620s
[2K
| RMSProp | epoch: 028 | loss: 0.44548 - acc: 0.8165 -- iter: 032/399
[A[ATraining Step: 353  | total loss: [1m[32m0.42968[0m[0m | time: 1.215s
[2K
| RMSProp | epoch: 028 | loss: 0.42968 - acc: 0.8224 -- iter: 064/399
[A[ATraining Step: 354  | total loss: [1m[32m0.42362[0m[0m | time: 1.828s
[2K
| RMSProp | epoch: 028 | loss: 0.42362 - acc: 0.8276 -- iter: 096/399
[A[ATraining Step: 355  | total loss: [1m[32m0.42410[0m[0m | time: 2.448s
[2K
| RMSProp | epoch: 028 | loss: 0.42410 - acc: 0.8167 -- iter: 128/399
[A[ATraining Step: 356  | total loss: [1m[32m0.42404[0m[0m | time: 3.051s
[2K
| RMSProp | epoch: 028 | loss: 0.42404 - acc: 0.8194 -- iter: 160/399
[A[ATraining Step: 357  | total loss: [1m[32m0.43042[0m[0m | time: 3.668s
[2K
| RMSProp | epoch: 028 | loss: 0.43042 - acc: 0.8125 -- iter: 192/399
[A[ATraining Step: 358  | total loss: [1m[32m0.42260[0m[0m | time: 4.287s
[2K
| RMSProp | epoch: 028 | loss: 0.42260 - acc: 0.8250 -- iter: 224/399
[A[ATraining Step: 359  | total loss: [1m[32m0.41705[0m[0m | time: 4.896s
[2K
| RMSProp | epoch: 028 | loss: 0.41705 - acc: 0.8269 -- iter: 256/399
[A[ATraining Step: 360  | total loss: [1m[32m0.39576[0m[0m | time: 5.513s
[2K
| RMSProp | epoch: 028 | loss: 0.39576 - acc: 0.8411 -- iter: 288/399
[A[ATraining Step: 361  | total loss: [1m[32m0.38547[0m[0m | time: 6.114s
[2K
| RMSProp | epoch: 028 | loss: 0.38547 - acc: 0.8476 -- iter: 320/399
[A[ATraining Step: 362  | total loss: [1m[32m0.36984[0m[0m | time: 6.736s
[2K
| RMSProp | epoch: 028 | loss: 0.36984 - acc: 0.8534 -- iter: 352/399
[A[ATraining Step: 363  | total loss: [1m[32m0.36498[0m[0m | time: 7.039s
[2K
| RMSProp | epoch: 028 | loss: 0.36498 - acc: 0.8587 -- iter: 384/399
[A[ATraining Step: 364  | total loss: [1m[32m0.34461[0m[0m | time: 8.364s
[2K
| RMSProp | epoch: 028 | loss: 0.34461 - acc: 0.8662 | val_loss: 0.71310 - val_acc: 0.6720 -- iter: 399/399
--
Training Step: 365  | total loss: [1m[32m0.32705[0m[0m | time: 0.638s
[2K
| RMSProp | epoch: 029 | loss: 0.32705 - acc: 0.8729 -- iter: 032/399
[A[ATraining Step: 366  | total loss: [1m[32m0.32141[0m[0m | time: 1.243s
[2K
| RMSProp | epoch: 029 | loss: 0.32141 - acc: 0.8731 -- iter: 064/399
[A[ATraining Step: 367  | total loss: [1m[32m0.31996[0m[0m | time: 1.856s
[2K
| RMSProp | epoch: 029 | loss: 0.31996 - acc: 0.8733 -- iter: 096/399
[A[ATraining Step: 368  | total loss: [1m[32m0.32667[0m[0m | time: 2.458s
[2K
| RMSProp | epoch: 029 | loss: 0.32667 - acc: 0.8672 -- iter: 128/399
[A[ATraining Step: 369  | total loss: [1m[32m0.36089[0m[0m | time: 3.053s
[2K
| RMSProp | epoch: 029 | loss: 0.36089 - acc: 0.8461 -- iter: 160/399
[A[ATraining Step: 370  | total loss: [1m[32m0.37869[0m[0m | time: 3.655s
[2K
| RMSProp | epoch: 029 | loss: 0.37869 - acc: 0.8303 -- iter: 192/399
[A[ATraining Step: 371  | total loss: [1m[32m0.38024[0m[0m | time: 4.268s
[2K
| RMSProp | epoch: 029 | loss: 0.38024 - acc: 0.8285 -- iter: 224/399
[A[ATraining Step: 372  | total loss: [1m[32m0.37510[0m[0m | time: 4.877s
[2K
| RMSProp | epoch: 029 | loss: 0.37510 - acc: 0.8331 -- iter: 256/399
[A[ATraining Step: 373  | total loss: [1m[32m0.36719[0m[0m | time: 5.487s
[2K
| RMSProp | epoch: 029 | loss: 0.36719 - acc: 0.8373 -- iter: 288/399
[A[ATraining Step: 374  | total loss: [1m[32m0.34783[0m[0m | time: 6.086s
[2K
| RMSProp | epoch: 029 | loss: 0.34783 - acc: 0.8536 -- iter: 320/399
[A[ATraining Step: 375  | total loss: [1m[32m0.32990[0m[0m | time: 6.692s
[2K
| RMSProp | epoch: 029 | loss: 0.32990 - acc: 0.8682 -- iter: 352/399
[A[ATraining Step: 376  | total loss: [1m[32m0.31922[0m[0m | time: 7.307s
[2K
| RMSProp | epoch: 029 | loss: 0.31922 - acc: 0.8752 -- iter: 384/399
[A[ATraining Step: 377  | total loss: [1m[32m0.33312[0m[0m | time: 8.617s
[2K
| RMSProp | epoch: 029 | loss: 0.33312 - acc: 0.8626 | val_loss: 0.63776 - val_acc: 0.6320 -- iter: 399/399
--
Training Step: 378  | total loss: [1m[32m0.34972[0m[0m | time: 0.312s
[2K
| RMSProp | epoch: 030 | loss: 0.34972 - acc: 0.8430 -- iter: 032/399
[A[ATraining Step: 379  | total loss: [1m[32m0.35282[0m[0m | time: 0.912s
[2K
| RMSProp | epoch: 030 | loss: 0.35282 - acc: 0.8321 -- iter: 064/399
[A[ATraining Step: 380  | total loss: [1m[32m0.35440[0m[0m | time: 1.536s
[2K
| RMSProp | epoch: 030 | loss: 0.35440 - acc: 0.8332 -- iter: 096/399
[A[ATraining Step: 381  | total loss: [1m[32m0.33580[0m[0m | time: 2.152s
[2K
| RMSProp | epoch: 030 | loss: 0.33580 - acc: 0.8499 -- iter: 128/399
[A[ATraining Step: 382  | total loss: [1m[32m0.32314[0m[0m | time: 2.769s
[2K
| RMSProp | epoch: 030 | loss: 0.32314 - acc: 0.8587 -- iter: 160/399
[A[ATraining Step: 383  | total loss: [1m[32m0.30281[0m[0m | time: 3.405s
[2K
| RMSProp | epoch: 030 | loss: 0.30281 - acc: 0.8697 -- iter: 192/399
[A[ATraining Step: 384  | total loss: [1m[32m0.29744[0m[0m | time: 4.003s
[2K
| RMSProp | epoch: 030 | loss: 0.29744 - acc: 0.8702 -- iter: 224/399
[A[ATraining Step: 385  | total loss: [1m[32m0.30811[0m[0m | time: 4.625s
[2K
| RMSProp | epoch: 030 | loss: 0.30811 - acc: 0.8676 -- iter: 256/399
[A[ATraining Step: 386  | total loss: [1m[32m0.31367[0m[0m | time: 5.224s
[2K
| RMSProp | epoch: 030 | loss: 0.31367 - acc: 0.8652 -- iter: 288/399
[A[ATraining Step: 387  | total loss: [1m[32m0.31191[0m[0m | time: 5.841s
[2K
| RMSProp | epoch: 030 | loss: 0.31191 - acc: 0.8693 -- iter: 320/399
[A[ATraining Step: 388  | total loss: [1m[32m0.30349[0m[0m | time: 6.438s
[2K
| RMSProp | epoch: 030 | loss: 0.30349 - acc: 0.8761 -- iter: 352/399
[A[ATraining Step: 389  | total loss: [1m[32m0.28433[0m[0m | time: 7.078s
[2K
| RMSProp | epoch: 030 | loss: 0.28433 - acc: 0.8885 -- iter: 384/399
[A[ATraining Step: 390  | total loss: [1m[32m0.27624[0m[0m | time: 8.682s
[2K
| RMSProp | epoch: 030 | loss: 0.27624 - acc: 0.8872 | val_loss: 0.64807 - val_acc: 0.6800 -- iter: 399/399
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8445702521873393
Validation AUPRC:0.8509268243759991
Test AUC:0.8696876600102406
Test AUPRC:0.8960118615012151
BestTestF1Score	0.77	0.51	0.75	0.72	0.83	52	20	42	11	0.14
BestTestMCCScore	0.77	0.51	0.75	0.72	0.83	52	20	42	11	0.14
BestTestAccuracyScore	0.77	0.51	0.75	0.72	0.83	52	20	42	11	0.14
BestValidationF1Score	0.8	0.55	0.78	0.77	0.84	56	17	41	11	0.14
BestValidationMCC	0.8	0.55	0.78	0.77	0.84	56	17	41	11	0.14
BestValidationAccuracy	0.8	0.55	0.78	0.77	0.84	56	17	41	11	0.14
TestPredictions (Threshold:0.14)
CHEMBL1927664,TN,INACT,0.05000000074505806	CHEMBL26458,TP,ACT,0.7799999713897705	CHEMBL424164,TP,ACT,0.8399999737739563	CHEMBL342482,TP,ACT,0.8700000047683716	CHEMBL3219075,TP,ACT,0.8100000023841858	CHEMBL2441049,TP,ACT,0.15000000596046448	CHEMBL1161247,TP,ACT,0.9399999976158142	CHEMBL104731,TP,ACT,0.9300000071525574	CHEMBL145517,TP,ACT,0.9200000166893005	CHEMBL2372731,TN,INACT,0.03999999910593033	CHEMBL2372737,TN,INACT,0.029999999329447746	CHEMBL100187,FN,ACT,0.07999999821186066	CHEMBL3251191,TP,ACT,0.5199999809265137	CHEMBL107282,TP,ACT,0.8299999833106995	CHEMBL283688,TP,ACT,0.8600000143051147	CHEMBL165909,TP,ACT,0.75	CHEMBL318352,TP,ACT,0.8399999737739563	CHEMBL564165,TN,INACT,0.029999999329447746	CHEMBL3343300,FN,ACT,0.12999999523162842	CHEMBL3408421,TN,INACT,0.03999999910593033	CHEMBL19626,TN,INACT,0.05999999865889549	CHEMBL179189,TN,INACT,0.07000000029802322	CHEMBL140066,FN,ACT,0.029999999329447746	CHEMBL509562,TP,ACT,0.15000000596046448	CHEMBL1335846,TN,INACT,0.03999999910593033	CHEMBL26340,TP,ACT,0.6399999856948853	CHEMBL23332,FN,ACT,0.11999999731779099	CHEMBL24713,TN,INACT,0.03999999910593033	CHEMBL350114,FP,INACT,0.5199999809265137	CHEMBL1289860,TN,INACT,0.029999999329447746	CHEMBL208464,TN,INACT,0.09000000357627869	CHEMBL145630,TP,ACT,0.9300000071525574	CHEMBL497067,TN,INACT,0.019999999552965164	CHEMBL103102,FP,INACT,0.1899999976158142	CHEMBL104815,TP,ACT,0.9599999785423279	CHEMBL2159294,TN,INACT,0.029999999329447746	CHEMBL358387,TN,INACT,0.05000000074505806	CHEMBL3109168,TN,INACT,0.10999999940395355	CHEMBL107429,TP,ACT,0.9399999976158142	CHEMBL24749,FN,ACT,0.03999999910593033	CHEMBL3244501,FN,ACT,0.05000000074505806	CHEMBL435213,TN,INACT,0.019999999552965164	CHEMBL3277932,TP,ACT,0.4099999964237213	CHEMBL348443,TP,ACT,0.6200000047683716	CHEMBL356711,TP,ACT,0.5600000023841858	CHEMBL254647,FP,INACT,0.25	CHEMBL292235,TN,INACT,0.03999999910593033	CHEMBL321510,TN,INACT,0.019999999552965164	CHEMBL417998,TN,INACT,0.029999999329447746	CHEMBL280162,FP,INACT,0.1899999976158142	CHEMBL3219090,TP,ACT,0.7300000190734863	CHEMBL1824558,FP,INACT,0.15000000596046448	CHEMBL422147,TP,ACT,0.8600000143051147	CHEMBL239127,FN,ACT,0.09000000357627869	CHEMBL310760,FP,INACT,0.5099999904632568	CHEMBL146492,TP,ACT,0.5099999904632568	CHEMBL3780039,FP,INACT,0.1599999964237213	CHEMBL3219078,TP,ACT,0.9100000262260437	CHEMBL96428,TN,INACT,0.029999999329447746	CHEMBL2159392,TN,INACT,0.07999999821186066	CHEMBL2372514,FP,INACT,0.30000001192092896	CHEMBL435423,TP,ACT,0.18000000715255737	CHEMBL484615,TN,INACT,0.019999999552965164	CHEMBL342542,TP,ACT,0.3499999940395355	CHEMBL24654,TP,ACT,0.5400000214576721	CHEMBL349653,FP,INACT,0.15000000596046448	CHEMBL165781,TP,ACT,0.800000011920929	CHEMBL107743,FN,ACT,0.05000000074505806	CHEMBL268367,TP,ACT,0.5899999737739563	CHEMBL2047998,FP,INACT,0.6399999856948853	CHEMBL104872,TP,ACT,0.8199999928474426	CHEMBL80844,TN,INACT,0.03999999910593033	CHEMBL109044,TN,INACT,0.10999999940395355	CHEMBL64708,TN,INACT,0.03999999910593033	CHEMBL357635,TP,ACT,0.5099999904632568	CHEMBL2159305,FP,INACT,0.4699999988079071	CHEMBL263977,TN,INACT,0.029999999329447746	CHEMBL2182019,TN,INACT,0.10000000149011612	CHEMBL433179,TN,INACT,0.029999999329447746	CHEMBL526504,TN,INACT,0.019999999552965164	CHEMBL382408,FN,ACT,0.11999999731779099	CHEMBL342826,TP,ACT,0.7799999713897705	CHEMBL111432,TN,INACT,0.07999999821186066	CHEMBL1812021,FP,INACT,0.3400000035762787	CHEMBL212401,FP,INACT,0.4300000071525574	CHEMBL329730,FN,ACT,0.03999999910593033	CHEMBL101067,TN,INACT,0.07000000029802322	CHEMBL112240,TN,INACT,0.029999999329447746	CHEMBL154985,TP,ACT,0.4699999988079071	CHEMBL1907778,FP,INACT,0.36000001430511475	CHEMBL504391,TN,INACT,0.009999999776482582	CHEMBL2159301,FP,INACT,0.25	CHEMBL262213,FP,INACT,0.699999988079071	CHEMBL349986,TP,ACT,0.9200000166893005	CHEMBL145206,TP,ACT,0.9399999976158142	CHEMBL26060,TP,ACT,0.6899999976158142	CHEMBL19152,FP,INACT,0.3100000023841858	CHEMBL101261,TP,ACT,0.6899999976158142	CHEMBL102552,TP,ACT,0.38999998569488525	CHEMBL2418042,TN,INACT,0.05999999865889549	CHEMBL24559,TP,ACT,0.7900000214576721	CHEMBL101707,TP,ACT,0.6700000166893005	CHEMBL512935,TN,INACT,0.05999999865889549	CHEMBL391804,TN,INACT,0.019999999552965164	CHEMBL3277920,TP,ACT,0.2800000011920929	CHEMBL26161,TP,ACT,0.7799999713897705	CHEMBL2441030,FP,INACT,0.23999999463558197	CHEMBL280994,TP,ACT,0.8100000023841858	CHEMBL311482,FP,INACT,0.44999998807907104	CHEMBL279367,TN,INACT,0.12999999523162842	CHEMBL3219088,FN,ACT,0.05999999865889549	CHEMBL1449269,TN,INACT,0.029999999329447746	CHEMBL109251,TN,INACT,0.07999999821186066	CHEMBL101559,TP,ACT,0.3199999928474426	CHEMBL257867,TN,INACT,0.03999999910593033	CHEMBL297220,TN,INACT,0.10000000149011612	CHEMBL26117,TP,ACT,0.6800000071525574	CHEMBL423555,TP,ACT,0.7300000190734863	CHEMBL24125,TP,ACT,0.7099999785423279	CHEMBL3343299,TP,ACT,0.15000000596046448	CHEMBL403278,FP,INACT,0.1599999964237213	CHEMBL347371,TP,ACT,0.9300000071525574	CHEMBL429152,TN,INACT,0.05999999865889549	CHEMBL357920,TP,ACT,0.75	CHEMBL26043,TP,ACT,0.38999998569488525	

