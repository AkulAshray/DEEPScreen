CNNModel CHEMBL2590 adam 0.0005 30 32 0 0.6 False True
Number of active compounds :	393
Number of inactive compounds :	393
---------------------------------
Run id: CNNModel_CHEMBL2590_adam_0.0005_30_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2590_adam_0.0005_30_32_0.6_True/
---------------------------------
Training samples: 488
Validation samples: 153
--
Training Step: 1  | time: 1.287s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/488
[A[ATraining Step: 2  | total loss: [1m[32m0.62418[0m[0m | time: 2.201s
[2K
| Adam | epoch: 001 | loss: 0.62418 - acc: 0.4219 -- iter: 064/488
[A[ATraining Step: 3  | total loss: [1m[32m0.68052[0m[0m | time: 3.224s
[2K
| Adam | epoch: 001 | loss: 0.68052 - acc: 0.4858 -- iter: 096/488
[A[ATraining Step: 4  | total loss: [1m[32m0.69035[0m[0m | time: 4.470s
[2K
| Adam | epoch: 001 | loss: 0.69035 - acc: 0.4730 -- iter: 128/488
[A[ATraining Step: 5  | total loss: [1m[32m0.69236[0m[0m | time: 5.602s
[2K
| Adam | epoch: 001 | loss: 0.69236 - acc: 0.4268 -- iter: 160/488
[A[ATraining Step: 6  | total loss: [1m[32m0.69260[0m[0m | time: 6.584s
[2K
| Adam | epoch: 001 | loss: 0.69260 - acc: 0.5341 -- iter: 192/488
[A[ATraining Step: 7  | total loss: [1m[32m0.69181[0m[0m | time: 7.591s
[2K
| Adam | epoch: 001 | loss: 0.69181 - acc: 0.5699 -- iter: 224/488
[A[ATraining Step: 8  | total loss: [1m[32m0.68895[0m[0m | time: 8.515s
[2K
| Adam | epoch: 001 | loss: 0.68895 - acc: 0.6009 -- iter: 256/488
[A[ATraining Step: 9  | total loss: [1m[32m0.68715[0m[0m | time: 9.878s
[2K
| Adam | epoch: 001 | loss: 0.68715 - acc: 0.5971 -- iter: 288/488
[A[ATraining Step: 10  | total loss: [1m[32m0.69497[0m[0m | time: 11.409s
[2K
| Adam | epoch: 001 | loss: 0.69497 - acc: 0.5329 -- iter: 320/488
[A[ATraining Step: 11  | total loss: [1m[32m0.69586[0m[0m | time: 12.623s
[2K
| Adam | epoch: 001 | loss: 0.69586 - acc: 0.5173 -- iter: 352/488
[A[ATraining Step: 12  | total loss: [1m[32m0.69390[0m[0m | time: 13.542s
[2K
| Adam | epoch: 001 | loss: 0.69390 - acc: 0.5236 -- iter: 384/488
[A[ATraining Step: 13  | total loss: [1m[32m0.70496[0m[0m | time: 14.563s
[2K
| Adam | epoch: 001 | loss: 0.70496 - acc: 0.4331 -- iter: 416/488
[A[ATraining Step: 14  | total loss: [1m[32m0.70178[0m[0m | time: 16.107s
[2K
| Adam | epoch: 001 | loss: 0.70178 - acc: 0.4477 -- iter: 448/488
[A[ATraining Step: 15  | total loss: [1m[32m0.69876[0m[0m | time: 18.113s
[2K
| Adam | epoch: 001 | loss: 0.69876 - acc: 0.4682 -- iter: 480/488
[A[ATraining Step: 16  | total loss: [1m[32m0.69642[0m[0m | time: 21.558s
[2K
| Adam | epoch: 001 | loss: 0.69642 - acc: 0.4918 | val_loss: 0.69340 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 17  | total loss: [1m[32m0.69668[0m[0m | time: 0.416s
[2K
| Adam | epoch: 002 | loss: 0.69668 - acc: 0.4498 -- iter: 032/488
[A[ATraining Step: 18  | total loss: [1m[32m0.69638[0m[0m | time: 1.608s
[2K
| Adam | epoch: 002 | loss: 0.69638 - acc: 0.4239 -- iter: 064/488
[A[ATraining Step: 19  | total loss: [1m[32m0.69481[0m[0m | time: 2.884s
[2K
| Adam | epoch: 002 | loss: 0.69481 - acc: 0.4909 -- iter: 096/488
[A[ATraining Step: 20  | total loss: [1m[32m0.69483[0m[0m | time: 4.128s
[2K
| Adam | epoch: 002 | loss: 0.69483 - acc: 0.4436 -- iter: 128/488
[A[ATraining Step: 21  | total loss: [1m[32m0.69417[0m[0m | time: 5.422s
[2K
| Adam | epoch: 002 | loss: 0.69417 - acc: 0.4805 -- iter: 160/488
[A[ATraining Step: 22  | total loss: [1m[32m0.69401[0m[0m | time: 6.847s
[2K
| Adam | epoch: 002 | loss: 0.69401 - acc: 0.4489 -- iter: 192/488
[A[ATraining Step: 23  | total loss: [1m[32m0.69379[0m[0m | time: 8.146s
[2K
| Adam | epoch: 002 | loss: 0.69379 - acc: 0.4274 -- iter: 224/488
[A[ATraining Step: 24  | total loss: [1m[32m0.69369[0m[0m | time: 9.163s
[2K
| Adam | epoch: 002 | loss: 0.69369 - acc: 0.3951 -- iter: 256/488
[A[ATraining Step: 25  | total loss: [1m[32m0.69354[0m[0m | time: 10.481s
[2K
| Adam | epoch: 002 | loss: 0.69354 - acc: 0.4067 -- iter: 288/488
[A[ATraining Step: 26  | total loss: [1m[32m0.69343[0m[0m | time: 11.863s
[2K
| Adam | epoch: 002 | loss: 0.69343 - acc: 0.4479 -- iter: 320/488
[A[ATraining Step: 27  | total loss: [1m[32m0.69342[0m[0m | time: 13.303s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4372 -- iter: 352/488
[A[ATraining Step: 28  | total loss: [1m[32m0.69333[0m[0m | time: 14.998s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4685 -- iter: 384/488
[A[ATraining Step: 29  | total loss: [1m[32m0.69325[0m[0m | time: 16.185s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4838 -- iter: 416/488
[A[ATraining Step: 30  | total loss: [1m[32m0.69332[0m[0m | time: 17.413s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4506 -- iter: 448/488
[A[ATraining Step: 31  | total loss: [1m[32m0.69330[0m[0m | time: 18.602s
[2K
| Adam | epoch: 002 | loss: 0.69330 - acc: 0.4332 -- iter: 480/488
[A[ATraining Step: 32  | total loss: [1m[32m0.69332[0m[0m | time: 21.088s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4130 | val_loss: 0.69316 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 33  | total loss: [1m[32m0.69330[0m[0m | time: 0.392s
[2K
| Adam | epoch: 003 | loss: 0.69330 - acc: 0.4116 -- iter: 032/488
[A[ATraining Step: 34  | total loss: [1m[32m0.69324[0m[0m | time: 0.729s
[2K
| Adam | epoch: 003 | loss: 0.69324 - acc: 0.4305 -- iter: 064/488
[A[ATraining Step: 35  | total loss: [1m[32m0.69306[0m[0m | time: 1.959s
[2K
| Adam | epoch: 003 | loss: 0.69306 - acc: 0.4712 -- iter: 096/488
[A[ATraining Step: 36  | total loss: [1m[32m0.69291[0m[0m | time: 3.241s
[2K
| Adam | epoch: 003 | loss: 0.69291 - acc: 0.5027 -- iter: 128/488
[A[ATraining Step: 37  | total loss: [1m[32m0.69290[0m[0m | time: 4.415s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5084 -- iter: 160/488
[A[ATraining Step: 38  | total loss: [1m[32m0.69265[0m[0m | time: 5.422s
[2K
| Adam | epoch: 003 | loss: 0.69265 - acc: 0.5312 -- iter: 192/488
[A[ATraining Step: 39  | total loss: [1m[32m0.69257[0m[0m | time: 6.483s
[2K
| Adam | epoch: 003 | loss: 0.69257 - acc: 0.5372 -- iter: 224/488
[A[ATraining Step: 40  | total loss: [1m[32m0.69268[0m[0m | time: 7.695s
[2K
| Adam | epoch: 003 | loss: 0.69268 - acc: 0.5302 -- iter: 256/488
[A[ATraining Step: 41  | total loss: [1m[32m0.69314[0m[0m | time: 8.928s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.5075 -- iter: 288/488
[A[ATraining Step: 42  | total loss: [1m[32m0.69264[0m[0m | time: 10.129s
[2K
| Adam | epoch: 003 | loss: 0.69264 - acc: 0.5286 -- iter: 320/488
[A[ATraining Step: 43  | total loss: [1m[32m0.69288[0m[0m | time: 11.213s
[2K
| Adam | epoch: 003 | loss: 0.69288 - acc: 0.5180 -- iter: 352/488
[A[ATraining Step: 44  | total loss: [1m[32m0.69340[0m[0m | time: 12.395s
[2K
| Adam | epoch: 003 | loss: 0.69340 - acc: 0.4987 -- iter: 384/488
[A[ATraining Step: 45  | total loss: [1m[32m0.69352[0m[0m | time: 13.513s
[2K
| Adam | epoch: 003 | loss: 0.69352 - acc: 0.4936 -- iter: 416/488
[A[ATraining Step: 46  | total loss: [1m[32m0.69406[0m[0m | time: 14.779s
[2K
| Adam | epoch: 003 | loss: 0.69406 - acc: 0.4738 -- iter: 448/488
[A[ATraining Step: 47  | total loss: [1m[32m0.69341[0m[0m | time: 16.051s
[2K
| Adam | epoch: 003 | loss: 0.69341 - acc: 0.4986 -- iter: 480/488
[A[ATraining Step: 48  | total loss: [1m[32m0.69339[0m[0m | time: 18.682s
[2K
| Adam | epoch: 003 | loss: 0.69339 - acc: 0.4988 | val_loss: 0.69349 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 49  | total loss: [1m[32m0.69364[0m[0m | time: 1.298s
[2K
| Adam | epoch: 004 | loss: 0.69364 - acc: 0.4891 -- iter: 032/488
[A[ATraining Step: 50  | total loss: [1m[32m0.69332[0m[0m | time: 1.657s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.5005 -- iter: 064/488
[A[ATraining Step: 51  | total loss: [1m[32m0.69329[0m[0m | time: 2.039s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.5004 -- iter: 096/488
[A[ATraining Step: 52  | total loss: [1m[32m0.69329[0m[0m | time: 3.393s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.5004 -- iter: 128/488
[A[ATraining Step: 53  | total loss: [1m[32m0.69279[0m[0m | time: 4.534s
[2K
| Adam | epoch: 004 | loss: 0.69279 - acc: 0.5188 -- iter: 160/488
[A[ATraining Step: 54  | total loss: [1m[32m0.69272[0m[0m | time: 5.777s
[2K
| Adam | epoch: 004 | loss: 0.69272 - acc: 0.5206 -- iter: 192/488
[A[ATraining Step: 55  | total loss: [1m[32m0.69229[0m[0m | time: 7.057s
[2K
| Adam | epoch: 004 | loss: 0.69229 - acc: 0.5355 -- iter: 224/488
[A[ATraining Step: 56  | total loss: [1m[32m0.69242[0m[0m | time: 8.258s
[2K
| Adam | epoch: 004 | loss: 0.69242 - acc: 0.5305 -- iter: 256/488
[A[ATraining Step: 57  | total loss: [1m[32m0.69226[0m[0m | time: 9.495s
[2K
| Adam | epoch: 004 | loss: 0.69226 - acc: 0.5349 -- iter: 288/488
[A[ATraining Step: 58  | total loss: [1m[32m0.69210[0m[0m | time: 10.767s
[2K
| Adam | epoch: 004 | loss: 0.69210 - acc: 0.5387 -- iter: 320/488
[A[ATraining Step: 59  | total loss: [1m[32m0.69270[0m[0m | time: 11.983s
[2K
| Adam | epoch: 004 | loss: 0.69270 - acc: 0.5209 -- iter: 352/488
[A[ATraining Step: 60  | total loss: [1m[32m0.69264[0m[0m | time: 12.929s
[2K
| Adam | epoch: 004 | loss: 0.69264 - acc: 0.5223 -- iter: 384/488
[A[ATraining Step: 61  | total loss: [1m[32m0.69212[0m[0m | time: 13.739s
[2K
| Adam | epoch: 004 | loss: 0.69212 - acc: 0.5357 -- iter: 416/488
[A[ATraining Step: 62  | total loss: [1m[32m0.69288[0m[0m | time: 14.680s
[2K
| Adam | epoch: 004 | loss: 0.69288 - acc: 0.5150 -- iter: 448/488
[A[ATraining Step: 63  | total loss: [1m[32m0.69277[0m[0m | time: 15.618s
[2K
| Adam | epoch: 004 | loss: 0.69277 - acc: 0.5171 -- iter: 480/488
[A[ATraining Step: 64  | total loss: [1m[32m0.69297[0m[0m | time: 17.598s
[2K
| Adam | epoch: 004 | loss: 0.69297 - acc: 0.5110 | val_loss: 0.69374 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 65  | total loss: [1m[32m0.69331[0m[0m | time: 0.962s
[2K
| Adam | epoch: 005 | loss: 0.69331 - acc: 0.5020 -- iter: 032/488
[A[ATraining Step: 66  | total loss: [1m[32m0.69346[0m[0m | time: 1.863s
[2K
| Adam | epoch: 005 | loss: 0.69346 - acc: 0.4979 -- iter: 064/488
[A[ATraining Step: 67  | total loss: [1m[32m0.69317[0m[0m | time: 2.058s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.5057 -- iter: 096/488
[A[ATraining Step: 68  | total loss: [1m[32m0.69200[0m[0m | time: 2.288s
[2K
| Adam | epoch: 005 | loss: 0.69200 - acc: 0.5346 -- iter: 128/488
[A[ATraining Step: 69  | total loss: [1m[32m0.69098[0m[0m | time: 3.347s
[2K
| Adam | epoch: 005 | loss: 0.69098 - acc: 0.5598 -- iter: 160/488
[A[ATraining Step: 70  | total loss: [1m[32m0.69140[0m[0m | time: 4.543s
[2K
| Adam | epoch: 005 | loss: 0.69140 - acc: 0.5493 -- iter: 192/488
[A[ATraining Step: 71  | total loss: [1m[32m0.69166[0m[0m | time: 5.302s
[2K
| Adam | epoch: 005 | loss: 0.69166 - acc: 0.5437 -- iter: 224/488
[A[ATraining Step: 72  | total loss: [1m[32m0.69201[0m[0m | time: 6.048s
[2K
| Adam | epoch: 005 | loss: 0.69201 - acc: 0.5352 -- iter: 256/488
[A[ATraining Step: 73  | total loss: [1m[32m0.69184[0m[0m | time: 6.898s
[2K
| Adam | epoch: 005 | loss: 0.69184 - acc: 0.5383 -- iter: 288/488
[A[ATraining Step: 74  | total loss: [1m[32m0.69128[0m[0m | time: 7.731s
[2K
| Adam | epoch: 005 | loss: 0.69128 - acc: 0.5478 -- iter: 320/488
[A[ATraining Step: 75  | total loss: [1m[32m0.69172[0m[0m | time: 8.690s
[2K
| Adam | epoch: 005 | loss: 0.69172 - acc: 0.5392 -- iter: 352/488
[A[ATraining Step: 76  | total loss: [1m[32m0.69192[0m[0m | time: 9.643s
[2K
| Adam | epoch: 005 | loss: 0.69192 - acc: 0.5350 -- iter: 384/488
[A[ATraining Step: 77  | total loss: [1m[32m0.69230[0m[0m | time: 10.594s
[2K
| Adam | epoch: 005 | loss: 0.69230 - acc: 0.5280 -- iter: 416/488
[A[ATraining Step: 78  | total loss: [1m[32m0.69285[0m[0m | time: 11.424s
[2K
| Adam | epoch: 005 | loss: 0.69285 - acc: 0.5185 -- iter: 448/488
[A[ATraining Step: 79  | total loss: [1m[32m0.69275[0m[0m | time: 12.329s
[2K
| Adam | epoch: 005 | loss: 0.69275 - acc: 0.5198 -- iter: 480/488
[A[ATraining Step: 80  | total loss: [1m[32m0.69326[0m[0m | time: 14.426s
[2K
| Adam | epoch: 005 | loss: 0.69326 - acc: 0.5114 | val_loss: 0.69420 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 81  | total loss: [1m[32m0.69252[0m[0m | time: 1.100s
[2K
| Adam | epoch: 006 | loss: 0.69252 - acc: 0.5229 -- iter: 032/488
[A[ATraining Step: 82  | total loss: [1m[32m0.69168[0m[0m | time: 2.289s
[2K
| Adam | epoch: 006 | loss: 0.69168 - acc: 0.5362 -- iter: 064/488
[A[ATraining Step: 83  | total loss: [1m[32m0.69243[0m[0m | time: 3.709s
[2K
| Adam | epoch: 006 | loss: 0.69243 - acc: 0.5232 -- iter: 096/488
[A[ATraining Step: 84  | total loss: [1m[32m0.69257[0m[0m | time: 4.143s
[2K
| Adam | epoch: 006 | loss: 0.69257 - acc: 0.5209 -- iter: 128/488
[A[ATraining Step: 85  | total loss: [1m[32m0.69186[0m[0m | time: 4.616s
[2K
| Adam | epoch: 006 | loss: 0.69186 - acc: 0.5313 -- iter: 160/488
[A[ATraining Step: 86  | total loss: [1m[32m0.69122[0m[0m | time: 5.906s
[2K
| Adam | epoch: 006 | loss: 0.69122 - acc: 0.5407 -- iter: 192/488
[A[ATraining Step: 87  | total loss: [1m[32m0.69083[0m[0m | time: 7.111s
[2K
| Adam | epoch: 006 | loss: 0.69083 - acc: 0.5460 -- iter: 224/488
[A[ATraining Step: 88  | total loss: [1m[32m0.69112[0m[0m | time: 8.313s
[2K
| Adam | epoch: 006 | loss: 0.69112 - acc: 0.5414 -- iter: 256/488
[A[ATraining Step: 89  | total loss: [1m[32m0.69049[0m[0m | time: 9.591s
[2K
| Adam | epoch: 006 | loss: 0.69049 - acc: 0.5498 -- iter: 288/488
[A[ATraining Step: 90  | total loss: [1m[32m0.69287[0m[0m | time: 10.812s
[2K
| Adam | epoch: 006 | loss: 0.69287 - acc: 0.5198 -- iter: 320/488
[A[ATraining Step: 91  | total loss: [1m[32m0.69151[0m[0m | time: 12.052s
[2K
| Adam | epoch: 006 | loss: 0.69151 - acc: 0.5366 -- iter: 352/488
[A[ATraining Step: 92  | total loss: [1m[32m0.69129[0m[0m | time: 13.378s
[2K
| Adam | epoch: 006 | loss: 0.69129 - acc: 0.5391 -- iter: 384/488
[A[ATraining Step: 93  | total loss: [1m[32m0.69202[0m[0m | time: 14.723s
[2K
| Adam | epoch: 006 | loss: 0.69202 - acc: 0.5290 -- iter: 416/488
[A[ATraining Step: 94  | total loss: [1m[32m0.69169[0m[0m | time: 15.909s
[2K
| Adam | epoch: 006 | loss: 0.69169 - acc: 0.5323 -- iter: 448/488
[A[ATraining Step: 95  | total loss: [1m[32m0.69218[0m[0m | time: 17.250s
[2K
| Adam | epoch: 006 | loss: 0.69218 - acc: 0.5260 -- iter: 480/488
[A[ATraining Step: 96  | total loss: [1m[32m0.69080[0m[0m | time: 19.917s
[2K
| Adam | epoch: 006 | loss: 0.69080 - acc: 0.5421 | val_loss: 0.69489 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 97  | total loss: [1m[32m0.69221[0m[0m | time: 1.093s
[2K
| Adam | epoch: 007 | loss: 0.69221 - acc: 0.5254 -- iter: 032/488
[A[ATraining Step: 98  | total loss: [1m[32m0.69210[0m[0m | time: 2.282s
[2K
| Adam | epoch: 007 | loss: 0.69210 - acc: 0.5260 -- iter: 064/488
[A[ATraining Step: 99  | total loss: [1m[32m0.69230[0m[0m | time: 3.415s
[2K
| Adam | epoch: 007 | loss: 0.69230 - acc: 0.5234 -- iter: 096/488
[A[ATraining Step: 100  | total loss: [1m[32m0.69141[0m[0m | time: 4.489s
[2K
| Adam | epoch: 007 | loss: 0.69141 - acc: 0.5336 -- iter: 128/488
[A[ATraining Step: 101  | total loss: [1m[32m0.69305[0m[0m | time: 4.764s
[2K
| Adam | epoch: 007 | loss: 0.69305 - acc: 0.5146 -- iter: 160/488
[A[ATraining Step: 102  | total loss: [1m[32m0.69424[0m[0m | time: 5.166s
[2K
| Adam | epoch: 007 | loss: 0.69424 - acc: 0.5006 -- iter: 192/488
[A[ATraining Step: 103  | total loss: [1m[32m0.69527[0m[0m | time: 6.308s
[2K
| Adam | epoch: 007 | loss: 0.69527 - acc: 0.4881 -- iter: 224/488
[A[ATraining Step: 104  | total loss: [1m[32m0.69565[0m[0m | time: 7.697s
[2K
| Adam | epoch: 007 | loss: 0.69565 - acc: 0.4830 -- iter: 256/488
[A[ATraining Step: 105  | total loss: [1m[32m0.69478[0m[0m | time: 8.903s
[2K
| Adam | epoch: 007 | loss: 0.69478 - acc: 0.4941 -- iter: 288/488
[A[ATraining Step: 106  | total loss: [1m[32m0.69403[0m[0m | time: 10.162s
[2K
| Adam | epoch: 007 | loss: 0.69403 - acc: 0.5040 -- iter: 320/488
[A[ATraining Step: 107  | total loss: [1m[32m0.69248[0m[0m | time: 11.487s
[2K
| Adam | epoch: 007 | loss: 0.69248 - acc: 0.5255 -- iter: 352/488
[A[ATraining Step: 108  | total loss: [1m[32m0.69234[0m[0m | time: 13.035s
[2K
| Adam | epoch: 007 | loss: 0.69234 - acc: 0.5261 -- iter: 384/488
[A[ATraining Step: 109  | total loss: [1m[32m0.69226[0m[0m | time: 14.617s
[2K
| Adam | epoch: 007 | loss: 0.69226 - acc: 0.5266 -- iter: 416/488
[A[ATraining Step: 110  | total loss: [1m[32m0.69334[0m[0m | time: 15.812s
[2K
| Adam | epoch: 007 | loss: 0.69334 - acc: 0.5114 -- iter: 448/488
[A[ATraining Step: 111  | total loss: [1m[32m0.69362[0m[0m | time: 17.025s
[2K
| Adam | epoch: 007 | loss: 0.69362 - acc: 0.5072 -- iter: 480/488
[A[ATraining Step: 112  | total loss: [1m[32m0.69383[0m[0m | time: 19.252s
[2K
| Adam | epoch: 007 | loss: 0.69383 - acc: 0.5033 | val_loss: 0.69434 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 113  | total loss: [1m[32m0.69363[0m[0m | time: 1.428s
[2K
| Adam | epoch: 008 | loss: 0.69363 - acc: 0.5061 -- iter: 032/488
[A[ATraining Step: 114  | total loss: [1m[32m0.69447[0m[0m | time: 2.657s
[2K
| Adam | epoch: 008 | loss: 0.69447 - acc: 0.4930 -- iter: 064/488
[A[ATraining Step: 115  | total loss: [1m[32m0.69362[0m[0m | time: 3.931s
[2K
| Adam | epoch: 008 | loss: 0.69362 - acc: 0.5062 -- iter: 096/488
[A[ATraining Step: 116  | total loss: [1m[32m0.69441[0m[0m | time: 4.925s
[2K
| Adam | epoch: 008 | loss: 0.69441 - acc: 0.4931 -- iter: 128/488
[A[ATraining Step: 117  | total loss: [1m[32m0.69434[0m[0m | time: 6.097s
[2K
| Adam | epoch: 008 | loss: 0.69434 - acc: 0.4938 -- iter: 160/488
[A[ATraining Step: 118  | total loss: [1m[32m0.69370[0m[0m | time: 6.427s
[2K
| Adam | epoch: 008 | loss: 0.69370 - acc: 0.5038 -- iter: 192/488
[A[ATraining Step: 119  | total loss: [1m[32m0.69375[0m[0m | time: 6.815s
[2K
| Adam | epoch: 008 | loss: 0.69375 - acc: 0.5034 -- iter: 224/488
[A[ATraining Step: 120  | total loss: [1m[32m0.69380[0m[0m | time: 8.031s
[2K
| Adam | epoch: 008 | loss: 0.69380 - acc: 0.5031 -- iter: 256/488
[A[ATraining Step: 121  | total loss: [1m[32m0.69293[0m[0m | time: 9.146s
[2K
| Adam | epoch: 008 | loss: 0.69293 - acc: 0.5184 -- iter: 288/488
[A[ATraining Step: 122  | total loss: [1m[32m0.69351[0m[0m | time: 10.337s
[2K
| Adam | epoch: 008 | loss: 0.69351 - acc: 0.5072 -- iter: 320/488
[A[ATraining Step: 123  | total loss: [1m[32m0.69280[0m[0m | time: 11.496s
[2K
| Adam | epoch: 008 | loss: 0.69280 - acc: 0.5189 -- iter: 352/488
[A[ATraining Step: 124  | total loss: [1m[32m0.69357[0m[0m | time: 12.547s
[2K
| Adam | epoch: 008 | loss: 0.69357 - acc: 0.5046 -- iter: 384/488
[A[ATraining Step: 125  | total loss: [1m[32m0.69235[0m[0m | time: 13.794s
[2K
| Adam | epoch: 008 | loss: 0.69235 - acc: 0.5260 -- iter: 416/488
[A[ATraining Step: 126  | total loss: [1m[32m0.69209[0m[0m | time: 14.975s
[2K
| Adam | epoch: 008 | loss: 0.69209 - acc: 0.5296 -- iter: 448/488
[A[ATraining Step: 127  | total loss: [1m[32m0.69313[0m[0m | time: 16.108s
[2K
| Adam | epoch: 008 | loss: 0.69313 - acc: 0.5110 -- iter: 480/488
[A[ATraining Step: 128  | total loss: [1m[32m0.69261[0m[0m | time: 18.574s
[2K
| Adam | epoch: 008 | loss: 0.69261 - acc: 0.5193 | val_loss: 0.69411 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 129  | total loss: [1m[32m0.69271[0m[0m | time: 1.272s
[2K
| Adam | epoch: 009 | loss: 0.69271 - acc: 0.5174 -- iter: 032/488
[A[ATraining Step: 130  | total loss: [1m[32m0.69245[0m[0m | time: 2.187s
[2K
| Adam | epoch: 009 | loss: 0.69245 - acc: 0.5219 -- iter: 064/488
[A[ATraining Step: 131  | total loss: [1m[32m0.69275[0m[0m | time: 2.798s
[2K
| Adam | epoch: 009 | loss: 0.69275 - acc: 0.5166 -- iter: 096/488
[A[ATraining Step: 132  | total loss: [1m[32m0.69321[0m[0m | time: 3.424s
[2K
| Adam | epoch: 009 | loss: 0.69321 - acc: 0.5087 -- iter: 128/488
[A[ATraining Step: 133  | total loss: [1m[32m0.69342[0m[0m | time: 4.048s
[2K
| Adam | epoch: 009 | loss: 0.69342 - acc: 0.5047 -- iter: 160/488
[A[ATraining Step: 134  | total loss: [1m[32m0.69323[0m[0m | time: 4.897s
[2K
| Adam | epoch: 009 | loss: 0.69323 - acc: 0.5073 -- iter: 192/488
[A[ATraining Step: 135  | total loss: [1m[32m0.69361[0m[0m | time: 5.122s
[2K
| Adam | epoch: 009 | loss: 0.69361 - acc: 0.5004 -- iter: 224/488
[A[ATraining Step: 136  | total loss: [1m[32m0.69297[0m[0m | time: 5.301s
[2K
| Adam | epoch: 009 | loss: 0.69297 - acc: 0.5128 -- iter: 256/488
[A[ATraining Step: 137  | total loss: [1m[32m0.69240[0m[0m | time: 6.174s
[2K
| Adam | epoch: 009 | loss: 0.69240 - acc: 0.5240 -- iter: 288/488
[A[ATraining Step: 138  | total loss: [1m[32m0.69217[0m[0m | time: 7.105s
[2K
| Adam | epoch: 009 | loss: 0.69217 - acc: 0.5279 -- iter: 320/488
[A[ATraining Step: 139  | total loss: [1m[32m0.69212[0m[0m | time: 7.948s
[2K
| Adam | epoch: 009 | loss: 0.69212 - acc: 0.5282 -- iter: 352/488
[A[ATraining Step: 140  | total loss: [1m[32m0.69262[0m[0m | time: 8.851s
[2K
| Adam | epoch: 009 | loss: 0.69262 - acc: 0.5191 -- iter: 384/488
[A[ATraining Step: 141  | total loss: [1m[32m0.69306[0m[0m | time: 9.737s
[2K
| Adam | epoch: 009 | loss: 0.69306 - acc: 0.5110 -- iter: 416/488
[A[ATraining Step: 142  | total loss: [1m[32m0.69312[0m[0m | time: 10.691s
[2K
| Adam | epoch: 009 | loss: 0.69312 - acc: 0.5099 -- iter: 448/488
[A[ATraining Step: 143  | total loss: [1m[32m0.69345[0m[0m | time: 11.597s
[2K
| Adam | epoch: 009 | loss: 0.69345 - acc: 0.5026 -- iter: 480/488
[A[ATraining Step: 144  | total loss: [1m[32m0.69366[0m[0m | time: 13.340s
[2K
| Adam | epoch: 009 | loss: 0.69366 - acc: 0.4993 | val_loss: 0.69404 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 145  | total loss: [1m[32m0.69381[0m[0m | time: 0.938s
[2K
| Adam | epoch: 010 | loss: 0.69381 - acc: 0.4962 -- iter: 032/488
[A[ATraining Step: 146  | total loss: [1m[32m0.69381[0m[0m | time: 1.872s
[2K
| Adam | epoch: 010 | loss: 0.69381 - acc: 0.4966 -- iter: 064/488
[A[ATraining Step: 147  | total loss: [1m[32m0.69323[0m[0m | time: 2.726s
[2K
| Adam | epoch: 010 | loss: 0.69323 - acc: 0.5063 -- iter: 096/488
[A[ATraining Step: 148  | total loss: [1m[32m0.69278[0m[0m | time: 3.713s
[2K
| Adam | epoch: 010 | loss: 0.69278 - acc: 0.5150 -- iter: 128/488
[A[ATraining Step: 149  | total loss: [1m[32m0.69218[0m[0m | time: 4.544s
[2K
| Adam | epoch: 010 | loss: 0.69218 - acc: 0.5260 -- iter: 160/488
[A[ATraining Step: 150  | total loss: [1m[32m0.69230[0m[0m | time: 5.496s
[2K
| Adam | epoch: 010 | loss: 0.69230 - acc: 0.5234 -- iter: 192/488
[A[ATraining Step: 151  | total loss: [1m[32m0.69294[0m[0m | time: 6.519s
[2K
| Adam | epoch: 010 | loss: 0.69294 - acc: 0.5117 -- iter: 224/488
[A[ATraining Step: 152  | total loss: [1m[32m0.69236[0m[0m | time: 6.825s
[2K
| Adam | epoch: 010 | loss: 0.69236 - acc: 0.5230 -- iter: 256/488
[A[ATraining Step: 153  | total loss: [1m[32m0.69180[0m[0m | time: 7.154s
[2K
| Adam | epoch: 010 | loss: 0.69180 - acc: 0.5332 -- iter: 288/488
[A[ATraining Step: 154  | total loss: [1m[32m0.69125[0m[0m | time: 8.546s
[2K
| Adam | epoch: 010 | loss: 0.69125 - acc: 0.5424 -- iter: 320/488
[A[ATraining Step: 155  | total loss: [1m[32m0.69111[0m[0m | time: 9.962s
[2K
| Adam | epoch: 010 | loss: 0.69111 - acc: 0.5444 -- iter: 352/488
[A[ATraining Step: 156  | total loss: [1m[32m0.69059[0m[0m | time: 11.592s
[2K
| Adam | epoch: 010 | loss: 0.69059 - acc: 0.5525 -- iter: 384/488
[A[ATraining Step: 157  | total loss: [1m[32m0.69033[0m[0m | time: 12.707s
[2K
| Adam | epoch: 010 | loss: 0.69033 - acc: 0.5566 -- iter: 416/488
[A[ATraining Step: 158  | total loss: [1m[32m0.69067[0m[0m | time: 13.912s
[2K
| Adam | epoch: 010 | loss: 0.69067 - acc: 0.5509 -- iter: 448/488
[A[ATraining Step: 159  | total loss: [1m[32m0.69200[0m[0m | time: 15.227s
[2K
| Adam | epoch: 010 | loss: 0.69200 - acc: 0.5302 -- iter: 480/488
[A[ATraining Step: 160  | total loss: [1m[32m0.69196[0m[0m | time: 17.680s
[2K
| Adam | epoch: 010 | loss: 0.69196 - acc: 0.5303 | val_loss: 0.69440 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 161  | total loss: [1m[32m0.69174[0m[0m | time: 1.281s
[2K
| Adam | epoch: 011 | loss: 0.69174 - acc: 0.5335 -- iter: 032/488
[A[ATraining Step: 162  | total loss: [1m[32m0.69086[0m[0m | time: 2.595s
[2K
| Adam | epoch: 011 | loss: 0.69086 - acc: 0.5458 -- iter: 064/488
[A[ATraining Step: 163  | total loss: [1m[32m0.69027[0m[0m | time: 4.061s
[2K
| Adam | epoch: 011 | loss: 0.69027 - acc: 0.5537 -- iter: 096/488
[A[ATraining Step: 164  | total loss: [1m[32m0.68996[0m[0m | time: 5.520s
[2K
| Adam | epoch: 011 | loss: 0.68996 - acc: 0.5577 -- iter: 128/488
[A[ATraining Step: 165  | total loss: [1m[32m0.69253[0m[0m | time: 6.642s
[2K
| Adam | epoch: 011 | loss: 0.69253 - acc: 0.5238 -- iter: 160/488
[A[ATraining Step: 166  | total loss: [1m[32m0.69218[0m[0m | time: 7.776s
[2K
| Adam | epoch: 011 | loss: 0.69218 - acc: 0.5277 -- iter: 192/488
[A[ATraining Step: 167  | total loss: [1m[32m0.69380[0m[0m | time: 9.097s
[2K
| Adam | epoch: 011 | loss: 0.69380 - acc: 0.5062 -- iter: 224/488
[A[ATraining Step: 168  | total loss: [1m[32m0.69305[0m[0m | time: 10.159s
[2K
| Adam | epoch: 011 | loss: 0.69305 - acc: 0.5149 -- iter: 256/488
[A[ATraining Step: 169  | total loss: [1m[32m0.69312[0m[0m | time: 10.453s
[2K
| Adam | epoch: 011 | loss: 0.69312 - acc: 0.5134 -- iter: 288/488
[A[ATraining Step: 170  | total loss: [1m[32m0.69225[0m[0m | time: 10.755s
[2K
| Adam | epoch: 011 | loss: 0.69225 - acc: 0.5246 -- iter: 320/488
[A[ATraining Step: 171  | total loss: [1m[32m0.69142[0m[0m | time: 12.550s
[2K
| Adam | epoch: 011 | loss: 0.69142 - acc: 0.5346 -- iter: 352/488
[A[ATraining Step: 172  | total loss: [1m[32m0.69167[0m[0m | time: 13.787s
[2K
| Adam | epoch: 011 | loss: 0.69167 - acc: 0.5312 -- iter: 384/488
[A[ATraining Step: 173  | total loss: [1m[32m0.69208[0m[0m | time: 14.885s
[2K
| Adam | epoch: 011 | loss: 0.69208 - acc: 0.5249 -- iter: 416/488
[A[ATraining Step: 174  | total loss: [1m[32m0.69151[0m[0m | time: 15.835s
[2K
| Adam | epoch: 011 | loss: 0.69151 - acc: 0.5318 -- iter: 448/488
[A[ATraining Step: 175  | total loss: [1m[32m0.69222[0m[0m | time: 17.014s
[2K
| Adam | epoch: 011 | loss: 0.69222 - acc: 0.5224 -- iter: 480/488
[A[ATraining Step: 176  | total loss: [1m[32m0.69243[0m[0m | time: 19.371s
[2K
| Adam | epoch: 011 | loss: 0.69243 - acc: 0.5201 | val_loss: 0.69471 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 177  | total loss: [1m[32m0.69231[0m[0m | time: 1.027s
[2K
| Adam | epoch: 012 | loss: 0.69231 - acc: 0.5213 -- iter: 032/488
[A[ATraining Step: 178  | total loss: [1m[32m0.69196[0m[0m | time: 2.061s
[2K
| Adam | epoch: 012 | loss: 0.69196 - acc: 0.5254 -- iter: 064/488
[A[ATraining Step: 179  | total loss: [1m[32m0.69337[0m[0m | time: 3.099s
[2K
| Adam | epoch: 012 | loss: 0.69337 - acc: 0.5072 -- iter: 096/488
[A[ATraining Step: 180  | total loss: [1m[32m0.69339[0m[0m | time: 4.228s
[2K
| Adam | epoch: 012 | loss: 0.69339 - acc: 0.5065 -- iter: 128/488
[A[ATraining Step: 181  | total loss: [1m[32m0.69393[0m[0m | time: 5.391s
[2K
| Adam | epoch: 012 | loss: 0.69393 - acc: 0.4996 -- iter: 160/488
[A[ATraining Step: 182  | total loss: [1m[32m0.69394[0m[0m | time: 6.469s
[2K
| Adam | epoch: 012 | loss: 0.69394 - acc: 0.4996 -- iter: 192/488
[A[ATraining Step: 183  | total loss: [1m[32m0.69418[0m[0m | time: 7.455s
[2K
| Adam | epoch: 012 | loss: 0.69418 - acc: 0.4965 -- iter: 224/488
[A[ATraining Step: 184  | total loss: [1m[32m0.69342[0m[0m | time: 8.580s
[2K
| Adam | epoch: 012 | loss: 0.69342 - acc: 0.5063 -- iter: 256/488
[A[ATraining Step: 185  | total loss: [1m[32m0.69207[0m[0m | time: 9.847s
[2K
| Adam | epoch: 012 | loss: 0.69207 - acc: 0.5244 -- iter: 288/488
[A[ATraining Step: 186  | total loss: [1m[32m0.69177[0m[0m | time: 10.276s
[2K
| Adam | epoch: 012 | loss: 0.69177 - acc: 0.5282 -- iter: 320/488
[A[ATraining Step: 187  | total loss: [1m[32m0.69108[0m[0m | time: 10.680s
[2K
| Adam | epoch: 012 | loss: 0.69108 - acc: 0.5379 -- iter: 352/488
[A[ATraining Step: 188  | total loss: [1m[32m0.69040[0m[0m | time: 11.761s
[2K
| Adam | epoch: 012 | loss: 0.69040 - acc: 0.5466 -- iter: 384/488
[A[ATraining Step: 189  | total loss: [1m[32m0.69174[0m[0m | time: 12.813s
[2K
| Adam | epoch: 012 | loss: 0.69174 - acc: 0.5294 -- iter: 416/488
[A[ATraining Step: 190  | total loss: [1m[32m0.69321[0m[0m | time: 13.901s
[2K
| Adam | epoch: 012 | loss: 0.69321 - acc: 0.5109 -- iter: 448/488
[A[ATraining Step: 191  | total loss: [1m[32m0.69276[0m[0m | time: 15.006s
[2K
| Adam | epoch: 012 | loss: 0.69276 - acc: 0.5160 -- iter: 480/488
[A[ATraining Step: 192  | total loss: [1m[32m0.69262[0m[0m | time: 17.212s
[2K
| Adam | epoch: 012 | loss: 0.69262 - acc: 0.5176 | val_loss: 0.69464 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 193  | total loss: [1m[32m0.69279[0m[0m | time: 1.256s
[2K
| Adam | epoch: 013 | loss: 0.69279 - acc: 0.5158 -- iter: 032/488
[A[ATraining Step: 194  | total loss: [1m[32m0.69339[0m[0m | time: 2.448s
[2K
| Adam | epoch: 013 | loss: 0.69339 - acc: 0.5080 -- iter: 064/488
[A[ATraining Step: 195  | total loss: [1m[32m0.69297[0m[0m | time: 3.567s
[2K
| Adam | epoch: 013 | loss: 0.69297 - acc: 0.5134 -- iter: 096/488
[A[ATraining Step: 196  | total loss: [1m[32m0.69236[0m[0m | time: 4.446s
[2K
| Adam | epoch: 013 | loss: 0.69236 - acc: 0.5215 -- iter: 128/488
[A[ATraining Step: 197  | total loss: [1m[32m0.69017[0m[0m | time: 5.307s
[2K
| Adam | epoch: 013 | loss: 0.69017 - acc: 0.5506 -- iter: 160/488
[A[ATraining Step: 198  | total loss: [1m[32m0.68983[0m[0m | time: 6.499s
[2K
| Adam | epoch: 013 | loss: 0.68983 - acc: 0.5549 -- iter: 192/488
[A[ATraining Step: 199  | total loss: [1m[32m0.68971[0m[0m | time: 7.593s
[2K
| Adam | epoch: 013 | loss: 0.68971 - acc: 0.5556 -- iter: 224/488
[A[ATraining Step: 200  | total loss: [1m[32m0.69142[0m[0m | time: 9.651s
[2K
| Adam | epoch: 013 | loss: 0.69142 - acc: 0.5345 | val_loss: 0.69483 - val_acc: 0.4902 -- iter: 256/488
--
Training Step: 201  | total loss: [1m[32m0.69247[0m[0m | time: 10.412s
[2K
| Adam | epoch: 013 | loss: 0.69247 - acc: 0.5216 -- iter: 288/488
[A[ATraining Step: 202  | total loss: [1m[32m0.69206[0m[0m | time: 11.154s
[2K
| Adam | epoch: 013 | loss: 0.69206 - acc: 0.5257 -- iter: 320/488
[A[ATraining Step: 203  | total loss: [1m[32m0.69198[0m[0m | time: 11.360s
[2K
| Adam | epoch: 013 | loss: 0.69198 - acc: 0.5263 -- iter: 352/488
[A[ATraining Step: 204  | total loss: [1m[32m0.69217[0m[0m | time: 11.550s
[2K
| Adam | epoch: 013 | loss: 0.69217 - acc: 0.5236 -- iter: 384/488
[A[ATraining Step: 205  | total loss: [1m[32m0.69231[0m[0m | time: 12.385s
[2K
| Adam | epoch: 013 | loss: 0.69231 - acc: 0.5213 -- iter: 416/488
[A[ATraining Step: 206  | total loss: [1m[32m0.69193[0m[0m | time: 13.160s
[2K
| Adam | epoch: 013 | loss: 0.69193 - acc: 0.5254 -- iter: 448/488
[A[ATraining Step: 207  | total loss: [1m[32m0.69294[0m[0m | time: 13.956s
[2K
| Adam | epoch: 013 | loss: 0.69294 - acc: 0.5135 -- iter: 480/488
[A[ATraining Step: 208  | total loss: [1m[32m0.69275[0m[0m | time: 15.711s
[2K
| Adam | epoch: 013 | loss: 0.69275 - acc: 0.5153 | val_loss: 0.69481 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 209  | total loss: [1m[32m0.69365[0m[0m | time: 0.803s
[2K
| Adam | epoch: 014 | loss: 0.69365 - acc: 0.5044 -- iter: 032/488
[A[ATraining Step: 210  | total loss: [1m[32m0.69268[0m[0m | time: 1.586s
[2K
| Adam | epoch: 014 | loss: 0.69268 - acc: 0.5164 -- iter: 064/488
[A[ATraining Step: 211  | total loss: [1m[32m0.69178[0m[0m | time: 2.350s
[2K
| Adam | epoch: 014 | loss: 0.69178 - acc: 0.5273 -- iter: 096/488
[A[ATraining Step: 212  | total loss: [1m[32m0.69250[0m[0m | time: 3.110s
[2K
| Adam | epoch: 014 | loss: 0.69250 - acc: 0.5183 -- iter: 128/488
[A[ATraining Step: 213  | total loss: [1m[32m0.69263[0m[0m | time: 3.854s
[2K
| Adam | epoch: 014 | loss: 0.69263 - acc: 0.5165 -- iter: 160/488
[A[ATraining Step: 214  | total loss: [1m[32m0.69354[0m[0m | time: 4.613s
[2K
| Adam | epoch: 014 | loss: 0.69354 - acc: 0.5055 -- iter: 192/488
[A[ATraining Step: 215  | total loss: [1m[32m0.69252[0m[0m | time: 5.320s
[2K
| Adam | epoch: 014 | loss: 0.69252 - acc: 0.5174 -- iter: 224/488
[A[ATraining Step: 216  | total loss: [1m[32m0.69266[0m[0m | time: 6.076s
[2K
| Adam | epoch: 014 | loss: 0.69266 - acc: 0.5157 -- iter: 256/488
[A[ATraining Step: 217  | total loss: [1m[32m0.69249[0m[0m | time: 6.819s
[2K
| Adam | epoch: 014 | loss: 0.69249 - acc: 0.5172 -- iter: 288/488
[A[ATraining Step: 218  | total loss: [1m[32m0.69184[0m[0m | time: 7.571s
[2K
| Adam | epoch: 014 | loss: 0.69184 - acc: 0.5249 -- iter: 320/488
[A[ATraining Step: 219  | total loss: [1m[32m0.69226[0m[0m | time: 8.327s
[2K
| Adam | epoch: 014 | loss: 0.69226 - acc: 0.5193 -- iter: 352/488
[A[ATraining Step: 220  | total loss: [1m[32m0.69217[0m[0m | time: 8.519s
[2K
| Adam | epoch: 014 | loss: 0.69217 - acc: 0.5205 -- iter: 384/488
[A[ATraining Step: 221  | total loss: [1m[32m0.69335[0m[0m | time: 8.737s
[2K
| Adam | epoch: 014 | loss: 0.69335 - acc: 0.5059 -- iter: 416/488
[A[ATraining Step: 222  | total loss: [1m[32m0.69440[0m[0m | time: 9.532s
[2K
| Adam | epoch: 014 | loss: 0.69440 - acc: 0.4928 -- iter: 448/488
[A[ATraining Step: 223  | total loss: [1m[32m0.69412[0m[0m | time: 10.540s
[2K
| Adam | epoch: 014 | loss: 0.69412 - acc: 0.4967 -- iter: 480/488
[A[ATraining Step: 224  | total loss: [1m[32m0.69488[0m[0m | time: 12.596s
[2K
| Adam | epoch: 014 | loss: 0.69488 - acc: 0.4876 | val_loss: 0.69453 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 225  | total loss: [1m[32m0.69499[0m[0m | time: 1.175s
[2K
| Adam | epoch: 015 | loss: 0.69499 - acc: 0.4857 -- iter: 032/488
[A[ATraining Step: 226  | total loss: [1m[32m0.69365[0m[0m | time: 2.423s
[2K
| Adam | epoch: 015 | loss: 0.69365 - acc: 0.5028 -- iter: 064/488
[A[ATraining Step: 227  | total loss: [1m[32m0.69326[0m[0m | time: 3.828s
[2K
| Adam | epoch: 015 | loss: 0.69326 - acc: 0.5088 -- iter: 096/488
[A[ATraining Step: 228  | total loss: [1m[32m0.69376[0m[0m | time: 4.998s
[2K
| Adam | epoch: 015 | loss: 0.69376 - acc: 0.5016 -- iter: 128/488
[A[ATraining Step: 229  | total loss: [1m[32m0.69262[0m[0m | time: 6.151s
[2K
| Adam | epoch: 015 | loss: 0.69262 - acc: 0.5171 -- iter: 160/488
[A[ATraining Step: 230  | total loss: [1m[32m0.69251[0m[0m | time: 7.170s
[2K
| Adam | epoch: 015 | loss: 0.69251 - acc: 0.5185 -- iter: 192/488
[A[ATraining Step: 231  | total loss: [1m[32m0.69447[0m[0m | time: 8.235s
[2K
| Adam | epoch: 015 | loss: 0.69447 - acc: 0.4917 -- iter: 224/488
[A[ATraining Step: 232  | total loss: [1m[32m0.69462[0m[0m | time: 9.262s
[2K
| Adam | epoch: 015 | loss: 0.69462 - acc: 0.4894 -- iter: 256/488
[A[ATraining Step: 233  | total loss: [1m[32m0.69390[0m[0m | time: 10.547s
[2K
| Adam | epoch: 015 | loss: 0.69390 - acc: 0.4998 -- iter: 288/488
[A[ATraining Step: 234  | total loss: [1m[32m0.69389[0m[0m | time: 11.716s
[2K
| Adam | epoch: 015 | loss: 0.69389 - acc: 0.4998 -- iter: 320/488
[A[ATraining Step: 235  | total loss: [1m[32m0.69405[0m[0m | time: 12.685s
[2K
| Adam | epoch: 015 | loss: 0.69405 - acc: 0.4967 -- iter: 352/488
[A[ATraining Step: 236  | total loss: [1m[32m0.69422[0m[0m | time: 13.889s
[2K
| Adam | epoch: 015 | loss: 0.69422 - acc: 0.4939 -- iter: 384/488
[A[ATraining Step: 237  | total loss: [1m[32m0.69336[0m[0m | time: 14.217s
[2K
| Adam | epoch: 015 | loss: 0.69336 - acc: 0.5070 -- iter: 416/488
[A[ATraining Step: 238  | total loss: [1m[32m0.69091[0m[0m | time: 14.556s
[2K
| Adam | epoch: 015 | loss: 0.69091 - acc: 0.5438 -- iter: 448/488
[A[ATraining Step: 239  | total loss: [1m[32m0.68870[0m[0m | time: 15.835s
[2K
| Adam | epoch: 015 | loss: 0.68870 - acc: 0.5769 -- iter: 480/488
[A[ATraining Step: 240  | total loss: [1m[32m0.68764[0m[0m | time: 18.166s
[2K
| Adam | epoch: 015 | loss: 0.68764 - acc: 0.5911 | val_loss: 0.69470 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 241  | total loss: [1m[32m0.68873[0m[0m | time: 1.006s
[2K
| Adam | epoch: 016 | loss: 0.68873 - acc: 0.5758 -- iter: 032/488
[A[ATraining Step: 242  | total loss: [1m[32m0.68949[0m[0m | time: 2.157s
[2K
| Adam | epoch: 016 | loss: 0.68949 - acc: 0.5651 -- iter: 064/488
[A[ATraining Step: 243  | total loss: [1m[32m0.68911[0m[0m | time: 3.444s
[2K
| Adam | epoch: 016 | loss: 0.68911 - acc: 0.5679 -- iter: 096/488
[A[ATraining Step: 244  | total loss: [1m[32m0.68987[0m[0m | time: 4.468s
[2K
| Adam | epoch: 016 | loss: 0.68987 - acc: 0.5580 -- iter: 128/488
[A[ATraining Step: 245  | total loss: [1m[32m0.68880[0m[0m | time: 5.548s
[2K
| Adam | epoch: 016 | loss: 0.68880 - acc: 0.5678 -- iter: 160/488
[A[ATraining Step: 246  | total loss: [1m[32m0.69000[0m[0m | time: 6.750s
[2K
| Adam | epoch: 016 | loss: 0.69000 - acc: 0.5548 -- iter: 192/488
[A[ATraining Step: 247  | total loss: [1m[32m0.68936[0m[0m | time: 8.214s
[2K
| Adam | epoch: 016 | loss: 0.68936 - acc: 0.5587 -- iter: 224/488
[A[ATraining Step: 248  | total loss: [1m[32m0.68993[0m[0m | time: 9.483s
[2K
| Adam | epoch: 016 | loss: 0.68993 - acc: 0.5528 -- iter: 256/488
[A[ATraining Step: 249  | total loss: [1m[32m0.69117[0m[0m | time: 10.549s
[2K
| Adam | epoch: 016 | loss: 0.69117 - acc: 0.5413 -- iter: 288/488
[A[ATraining Step: 250  | total loss: [1m[32m0.69339[0m[0m | time: 11.700s
[2K
| Adam | epoch: 016 | loss: 0.69339 - acc: 0.5215 -- iter: 320/488
[A[ATraining Step: 251  | total loss: [1m[32m0.69377[0m[0m | time: 12.921s
[2K
| Adam | epoch: 016 | loss: 0.69377 - acc: 0.5163 -- iter: 352/488
[A[ATraining Step: 252  | total loss: [1m[32m0.69342[0m[0m | time: 14.264s
[2K
| Adam | epoch: 016 | loss: 0.69342 - acc: 0.5178 -- iter: 384/488
[A[ATraining Step: 253  | total loss: [1m[32m0.69351[0m[0m | time: 15.672s
[2K
| Adam | epoch: 016 | loss: 0.69351 - acc: 0.5160 -- iter: 416/488
[A[ATraining Step: 254  | total loss: [1m[32m0.69267[0m[0m | time: 15.981s
[2K
| Adam | epoch: 016 | loss: 0.69267 - acc: 0.5238 -- iter: 448/488
[A[ATraining Step: 255  | total loss: [1m[32m0.69389[0m[0m | time: 16.289s
[2K
| Adam | epoch: 016 | loss: 0.69389 - acc: 0.5089 -- iter: 480/488
[A[ATraining Step: 256  | total loss: [1m[32m0.69506[0m[0m | time: 18.321s
[2K
| Adam | epoch: 016 | loss: 0.69506 - acc: 0.4955 | val_loss: 0.69474 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 257  | total loss: [1m[32m0.69493[0m[0m | time: 1.259s
[2K
| Adam | epoch: 017 | loss: 0.69493 - acc: 0.4959 -- iter: 032/488
[A[ATraining Step: 258  | total loss: [1m[32m0.69459[0m[0m | time: 2.191s
[2K
| Adam | epoch: 017 | loss: 0.69459 - acc: 0.4995 -- iter: 064/488
[A[ATraining Step: 259  | total loss: [1m[32m0.69502[0m[0m | time: 3.303s
[2K
| Adam | epoch: 017 | loss: 0.69502 - acc: 0.4933 -- iter: 096/488
[A[ATraining Step: 260  | total loss: [1m[32m0.69368[0m[0m | time: 4.361s
[2K
| Adam | epoch: 017 | loss: 0.69368 - acc: 0.5096 -- iter: 128/488
[A[ATraining Step: 261  | total loss: [1m[32m0.69396[0m[0m | time: 5.466s
[2K
| Adam | epoch: 017 | loss: 0.69396 - acc: 0.5055 -- iter: 160/488
[A[ATraining Step: 262  | total loss: [1m[32m0.69419[0m[0m | time: 6.570s
[2K
| Adam | epoch: 017 | loss: 0.69419 - acc: 0.5018 -- iter: 192/488
[A[ATraining Step: 263  | total loss: [1m[32m0.69490[0m[0m | time: 7.776s
[2K
| Adam | epoch: 017 | loss: 0.69490 - acc: 0.4923 -- iter: 224/488
[A[ATraining Step: 264  | total loss: [1m[32m0.69409[0m[0m | time: 9.001s
[2K
| Adam | epoch: 017 | loss: 0.69409 - acc: 0.5024 -- iter: 256/488
[A[ATraining Step: 265  | total loss: [1m[32m0.69360[0m[0m | time: 10.000s
[2K
| Adam | epoch: 017 | loss: 0.69360 - acc: 0.5084 -- iter: 288/488
[A[ATraining Step: 266  | total loss: [1m[32m0.69317[0m[0m | time: 11.209s
[2K
| Adam | epoch: 017 | loss: 0.69317 - acc: 0.5138 -- iter: 320/488
[A[ATraining Step: 267  | total loss: [1m[32m0.69277[0m[0m | time: 12.306s
[2K
| Adam | epoch: 017 | loss: 0.69277 - acc: 0.5187 -- iter: 352/488
[A[ATraining Step: 268  | total loss: [1m[32m0.69331[0m[0m | time: 13.344s
[2K
| Adam | epoch: 017 | loss: 0.69331 - acc: 0.5106 -- iter: 384/488
[A[ATraining Step: 269  | total loss: [1m[32m0.69312[0m[0m | time: 14.090s
[2K
| Adam | epoch: 017 | loss: 0.69312 - acc: 0.5126 -- iter: 416/488
[A[ATraining Step: 270  | total loss: [1m[32m0.69287[0m[0m | time: 14.858s
[2K
| Adam | epoch: 017 | loss: 0.69287 - acc: 0.5145 -- iter: 448/488
[A[ATraining Step: 271  | total loss: [1m[32m0.69314[0m[0m | time: 15.071s
[2K
| Adam | epoch: 017 | loss: 0.69314 - acc: 0.5099 -- iter: 480/488
[A[ATraining Step: 272  | total loss: [1m[32m0.69312[0m[0m | time: 16.303s
[2K
| Adam | epoch: 017 | loss: 0.69312 - acc: 0.5089 | val_loss: 0.69407 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 273  | total loss: [1m[32m0.69314[0m[0m | time: 0.773s
[2K
| Adam | epoch: 018 | loss: 0.69314 - acc: 0.5080 -- iter: 032/488
[A[ATraining Step: 274  | total loss: [1m[32m0.69224[0m[0m | time: 1.539s
[2K
| Adam | epoch: 018 | loss: 0.69224 - acc: 0.5197 -- iter: 064/488
[A[ATraining Step: 275  | total loss: [1m[32m0.69279[0m[0m | time: 2.304s
[2K
| Adam | epoch: 018 | loss: 0.69279 - acc: 0.5115 -- iter: 096/488
[A[ATraining Step: 276  | total loss: [1m[32m0.69169[0m[0m | time: 3.123s
[2K
| Adam | epoch: 018 | loss: 0.69169 - acc: 0.5260 -- iter: 128/488
[A[ATraining Step: 277  | total loss: [1m[32m0.69208[0m[0m | time: 3.918s
[2K
| Adam | epoch: 018 | loss: 0.69208 - acc: 0.5203 -- iter: 160/488
[A[ATraining Step: 278  | total loss: [1m[32m0.69220[0m[0m | time: 4.686s
[2K
| Adam | epoch: 018 | loss: 0.69220 - acc: 0.5182 -- iter: 192/488
[A[ATraining Step: 279  | total loss: [1m[32m0.69299[0m[0m | time: 5.431s
[2K
| Adam | epoch: 018 | loss: 0.69299 - acc: 0.5070 -- iter: 224/488
[A[ATraining Step: 280  | total loss: [1m[32m0.69340[0m[0m | time: 6.176s
[2K
| Adam | epoch: 018 | loss: 0.69340 - acc: 0.5001 -- iter: 256/488
[A[ATraining Step: 281  | total loss: [1m[32m0.69256[0m[0m | time: 6.949s
[2K
| Adam | epoch: 018 | loss: 0.69256 - acc: 0.5126 -- iter: 288/488
[A[ATraining Step: 282  | total loss: [1m[32m0.69273[0m[0m | time: 7.711s
[2K
| Adam | epoch: 018 | loss: 0.69273 - acc: 0.5082 -- iter: 320/488
[A[ATraining Step: 283  | total loss: [1m[32m0.69203[0m[0m | time: 8.462s
[2K
| Adam | epoch: 018 | loss: 0.69203 - acc: 0.5167 -- iter: 352/488
[A[ATraining Step: 284  | total loss: [1m[32m0.69208[0m[0m | time: 9.178s
[2K
| Adam | epoch: 018 | loss: 0.69208 - acc: 0.5151 -- iter: 384/488
[A[ATraining Step: 285  | total loss: [1m[32m0.69163[0m[0m | time: 9.996s
[2K
| Adam | epoch: 018 | loss: 0.69163 - acc: 0.5198 -- iter: 416/488
[A[ATraining Step: 286  | total loss: [1m[32m0.69285[0m[0m | time: 10.736s
[2K
| Adam | epoch: 018 | loss: 0.69285 - acc: 0.5053 -- iter: 448/488
[A[ATraining Step: 287  | total loss: [1m[32m0.69206[0m[0m | time: 11.502s
[2K
| Adam | epoch: 018 | loss: 0.69206 - acc: 0.5111 -- iter: 480/488
[A[ATraining Step: 288  | total loss: [1m[32m0.69186[0m[0m | time: 12.706s
[2K
| Adam | epoch: 018 | loss: 0.69186 - acc: 0.5099 | val_loss: 0.68902 - val_acc: 0.4902 -- iter: 488/488
--
Training Step: 289  | total loss: [1m[32m0.69175[0m[0m | time: 0.224s
[2K
| Adam | epoch: 019 | loss: 0.69175 - acc: 0.5090 -- iter: 032/488
[A[ATraining Step: 290  | total loss: [1m[32m0.69129[0m[0m | time: 0.944s
[2K
| Adam | epoch: 019 | loss: 0.69129 - acc: 0.5081 -- iter: 064/488
[A[ATraining Step: 291  | total loss: [1m[32m0.68963[0m[0m | time: 1.866s
[2K
| Adam | epoch: 019 | loss: 0.68963 - acc: 0.5198 -- iter: 096/488
[A[ATraining Step: 292  | total loss: [1m[32m0.68942[0m[0m | time: 2.855s
[2K
| Adam | epoch: 019 | loss: 0.68942 - acc: 0.5178 -- iter: 128/488
[A[ATraining Step: 293  | total loss: [1m[32m0.69223[0m[0m | time: 3.798s
[2K
| Adam | epoch: 019 | loss: 0.69223 - acc: 0.5004 -- iter: 160/488
[A[ATraining Step: 294  | total loss: [1m[32m0.69002[0m[0m | time: 4.821s
[2K
| Adam | epoch: 019 | loss: 0.69002 - acc: 0.5128 -- iter: 192/488
[A[ATraining Step: 295  | total loss: [1m[32m0.68700[0m[0m | time: 5.766s
[2K
| Adam | epoch: 019 | loss: 0.68700 - acc: 0.5209 -- iter: 224/488
[A[ATraining Step: 296  | total loss: [1m[32m0.68571[0m[0m | time: 6.755s
[2K
| Adam | epoch: 019 | loss: 0.68571 - acc: 0.5251 -- iter: 256/488
[A[ATraining Step: 297  | total loss: [1m[32m0.68293[0m[0m | time: 7.682s
[2K
| Adam | epoch: 019 | loss: 0.68293 - acc: 0.5320 -- iter: 288/488
[A[ATraining Step: 298  | total loss: [1m[32m0.68037[0m[0m | time: 8.734s
[2K
| Adam | epoch: 019 | loss: 0.68037 - acc: 0.5444 -- iter: 320/488
[A[ATraining Step: 299  | total loss: [1m[32m0.68091[0m[0m | time: 9.649s
[2K
| Adam | epoch: 019 | loss: 0.68091 - acc: 0.5462 -- iter: 352/488
[A[ATraining Step: 300  | total loss: [1m[32m0.68033[0m[0m | time: 10.578s
[2K
| Adam | epoch: 019 | loss: 0.68033 - acc: 0.5509 -- iter: 384/488
[A[ATraining Step: 301  | total loss: [1m[32m0.68119[0m[0m | time: 11.569s
[2K
| Adam | epoch: 019 | loss: 0.68119 - acc: 0.5521 -- iter: 416/488
[A[ATraining Step: 302  | total loss: [1m[32m0.67471[0m[0m | time: 12.568s
[2K
| Adam | epoch: 019 | loss: 0.67471 - acc: 0.5781 -- iter: 448/488
[A[ATraining Step: 303  | total loss: [1m[32m0.67119[0m[0m | time: 13.714s
[2K
| Adam | epoch: 019 | loss: 0.67119 - acc: 0.5891 -- iter: 480/488
[A[ATraining Step: 304  | total loss: [1m[32m0.66653[0m[0m | time: 16.006s
[2K
| Adam | epoch: 019 | loss: 0.66653 - acc: 0.5895 | val_loss: 0.62026 - val_acc: 0.6471 -- iter: 488/488
--
Training Step: 305  | total loss: [1m[32m0.67443[0m[0m | time: 0.301s
[2K
| Adam | epoch: 020 | loss: 0.67443 - acc: 0.5837 -- iter: 032/488
[A[ATraining Step: 306  | total loss: [1m[32m0.65984[0m[0m | time: 0.565s
[2K
| Adam | epoch: 020 | loss: 0.65984 - acc: 0.6003 -- iter: 064/488
[A[ATraining Step: 307  | total loss: [1m[32m0.64097[0m[0m | time: 1.602s
[2K
| Adam | epoch: 020 | loss: 0.64097 - acc: 0.6153 -- iter: 096/488
[A[ATraining Step: 308  | total loss: [1m[32m0.65422[0m[0m | time: 2.871s
[2K
| Adam | epoch: 020 | loss: 0.65422 - acc: 0.6069 -- iter: 128/488
[A[ATraining Step: 309  | total loss: [1m[32m0.65309[0m[0m | time: 4.294s
[2K
| Adam | epoch: 020 | loss: 0.65309 - acc: 0.6087 -- iter: 160/488
[A[ATraining Step: 310  | total loss: [1m[32m0.65331[0m[0m | time: 5.660s
[2K
| Adam | epoch: 020 | loss: 0.65331 - acc: 0.6072 -- iter: 192/488
[A[ATraining Step: 311  | total loss: [1m[32m0.65050[0m[0m | time: 6.575s
[2K
| Adam | epoch: 020 | loss: 0.65050 - acc: 0.6152 -- iter: 224/488
[A[ATraining Step: 312  | total loss: [1m[32m0.65123[0m[0m | time: 7.645s
[2K
| Adam | epoch: 020 | loss: 0.65123 - acc: 0.6193 -- iter: 256/488
[A[ATraining Step: 313  | total loss: [1m[32m0.65493[0m[0m | time: 8.793s
[2K
| Adam | epoch: 020 | loss: 0.65493 - acc: 0.6168 -- iter: 288/488
[A[ATraining Step: 314  | total loss: [1m[32m0.65817[0m[0m | time: 9.853s
[2K
| Adam | epoch: 020 | loss: 0.65817 - acc: 0.6145 -- iter: 320/488
[A[ATraining Step: 315  | total loss: [1m[32m0.65693[0m[0m | time: 10.823s
[2K
| Adam | epoch: 020 | loss: 0.65693 - acc: 0.6155 -- iter: 352/488
[A[ATraining Step: 316  | total loss: [1m[32m0.65162[0m[0m | time: 11.840s
[2K
| Adam | epoch: 020 | loss: 0.65162 - acc: 0.6290 -- iter: 384/488
[A[ATraining Step: 317  | total loss: [1m[32m0.65634[0m[0m | time: 12.899s
[2K
| Adam | epoch: 020 | loss: 0.65634 - acc: 0.6255 -- iter: 416/488
[A[ATraining Step: 318  | total loss: [1m[32m0.65570[0m[0m | time: 13.971s
[2K
| Adam | epoch: 020 | loss: 0.65570 - acc: 0.6192 -- iter: 448/488
[A[ATraining Step: 319  | total loss: [1m[32m0.65306[0m[0m | time: 15.085s
[2K
| Adam | epoch: 020 | loss: 0.65306 - acc: 0.6104 -- iter: 480/488
[A[ATraining Step: 320  | total loss: [1m[32m0.65937[0m[0m | time: 17.330s
[2K
| Adam | epoch: 020 | loss: 0.65937 - acc: 0.5931 | val_loss: 0.64288 - val_acc: 0.5948 -- iter: 488/488
--
Training Step: 321  | total loss: [1m[32m0.65435[0m[0m | time: 1.146s
[2K
| Adam | epoch: 021 | loss: 0.65435 - acc: 0.5994 -- iter: 032/488
[A[ATraining Step: 322  | total loss: [1m[32m0.64842[0m[0m | time: 1.502s
[2K
| Adam | epoch: 021 | loss: 0.64842 - acc: 0.6238 -- iter: 064/488
[A[ATraining Step: 323  | total loss: [1m[32m0.65232[0m[0m | time: 1.878s
[2K
| Adam | epoch: 021 | loss: 0.65232 - acc: 0.6490 -- iter: 096/488
[A[ATraining Step: 324  | total loss: [1m[32m0.65496[0m[0m | time: 3.251s
[2K
| Adam | epoch: 021 | loss: 0.65496 - acc: 0.6716 -- iter: 128/488
[A[ATraining Step: 325  | total loss: [1m[32m0.65195[0m[0m | time: 4.131s
[2K
| Adam | epoch: 021 | loss: 0.65195 - acc: 0.6732 -- iter: 160/488
[A[ATraining Step: 326  | total loss: [1m[32m0.64953[0m[0m | time: 5.186s
[2K
| Adam | epoch: 021 | loss: 0.64953 - acc: 0.6777 -- iter: 192/488
[A[ATraining Step: 327  | total loss: [1m[32m0.64616[0m[0m | time: 6.273s
[2K
| Adam | epoch: 021 | loss: 0.64616 - acc: 0.6818 -- iter: 224/488
[A[ATraining Step: 328  | total loss: [1m[32m0.64265[0m[0m | time: 7.311s
[2K
| Adam | epoch: 021 | loss: 0.64265 - acc: 0.6855 -- iter: 256/488
[A[ATraining Step: 329  | total loss: [1m[32m0.64551[0m[0m | time: 8.404s
[2K
| Adam | epoch: 021 | loss: 0.64551 - acc: 0.6763 -- iter: 288/488
[A[ATraining Step: 330  | total loss: [1m[32m0.64438[0m[0m | time: 9.658s
[2K
| Adam | epoch: 021 | loss: 0.64438 - acc: 0.6743 -- iter: 320/488
[A[ATraining Step: 331  | total loss: [1m[32m0.63938[0m[0m | time: 10.846s
[2K
| Adam | epoch: 021 | loss: 0.63938 - acc: 0.6819 -- iter: 352/488
[A[ATraining Step: 332  | total loss: [1m[32m0.63664[0m[0m | time: 11.716s
[2K
| Adam | epoch: 021 | loss: 0.63664 - acc: 0.6825 -- iter: 384/488
[A[ATraining Step: 333  | total loss: [1m[32m0.63738[0m[0m | time: 12.895s
[2K
| Adam | epoch: 021 | loss: 0.63738 - acc: 0.6767 -- iter: 416/488
[A[ATraining Step: 334  | total loss: [1m[32m0.63671[0m[0m | time: 14.099s
[2K
| Adam | epoch: 021 | loss: 0.63671 - acc: 0.6747 -- iter: 448/488
[A[ATraining Step: 335  | total loss: [1m[32m0.64149[0m[0m | time: 15.062s
[2K
| Adam | epoch: 021 | loss: 0.64149 - acc: 0.6666 -- iter: 480/488
[A[ATraining Step: 336  | total loss: [1m[32m0.62615[0m[0m | time: 16.851s
[2K
| Adam | epoch: 021 | loss: 0.62615 - acc: 0.6843 | val_loss: 0.59036 - val_acc: 0.6667 -- iter: 488/488
--
Training Step: 337  | total loss: [1m[32m0.62126[0m[0m | time: 0.762s
[2K
| Adam | epoch: 022 | loss: 0.62126 - acc: 0.6846 -- iter: 032/488
[A[ATraining Step: 338  | total loss: [1m[32m0.61459[0m[0m | time: 1.498s
[2K
| Adam | epoch: 022 | loss: 0.61459 - acc: 0.6943 -- iter: 064/488
[A[ATraining Step: 339  | total loss: [1m[32m0.60888[0m[0m | time: 1.735s
[2K
| Adam | epoch: 022 | loss: 0.60888 - acc: 0.6936 -- iter: 096/488
[A[ATraining Step: 340  | total loss: [1m[32m0.61349[0m[0m | time: 1.934s
[2K
| Adam | epoch: 022 | loss: 0.61349 - acc: 0.6867 -- iter: 128/488
[A[ATraining Step: 341  | total loss: [1m[32m0.61515[0m[0m | time: 2.674s
[2K
| Adam | epoch: 022 | loss: 0.61515 - acc: 0.6931 -- iter: 160/488
[A[ATraining Step: 342  | total loss: [1m[32m0.61837[0m[0m | time: 3.649s
[2K
| Adam | epoch: 022 | loss: 0.61837 - acc: 0.6894 -- iter: 192/488
[A[ATraining Step: 343  | total loss: [1m[32m0.62085[0m[0m | time: 4.825s
[2K
| Adam | epoch: 022 | loss: 0.62085 - acc: 0.6829 -- iter: 224/488
[A[ATraining Step: 344  | total loss: [1m[32m0.61255[0m[0m | time: 5.687s
[2K
| Adam | epoch: 022 | loss: 0.61255 - acc: 0.6865 -- iter: 256/488
[A[ATraining Step: 345  | total loss: [1m[32m0.62106[0m[0m | time: 6.317s
[2K
| Adam | epoch: 022 | loss: 0.62106 - acc: 0.6710 -- iter: 288/488
[A[ATraining Step: 346  | total loss: [1m[32m0.60844[0m[0m | time: 6.918s
[2K
| Adam | epoch: 022 | loss: 0.60844 - acc: 0.6914 -- iter: 320/488
[A[ATraining Step: 347  | total loss: [1m[32m0.60402[0m[0m | time: 7.667s
[2K
| Adam | epoch: 022 | loss: 0.60402 - acc: 0.6973 -- iter: 352/488
[A[ATraining Step: 348  | total loss: [1m[32m0.60236[0m[0m | time: 8.413s
[2K
| Adam | epoch: 022 | loss: 0.60236 - acc: 0.6963 -- iter: 384/488
[A[ATraining Step: 349  | total loss: [1m[32m0.59349[0m[0m | time: 9.148s
[2K
| Adam | epoch: 022 | loss: 0.59349 - acc: 0.6985 -- iter: 416/488
[A[ATraining Step: 350  | total loss: [1m[32m0.59366[0m[0m | time: 9.849s
[2K
| Adam | epoch: 022 | loss: 0.59366 - acc: 0.6912 -- iter: 448/488
[A[ATraining Step: 351  | total loss: [1m[32m0.60820[0m[0m | time: 10.574s
[2K
| Adam | epoch: 022 | loss: 0.60820 - acc: 0.6846 -- iter: 480/488
[A[ATraining Step: 352  | total loss: [1m[32m0.59799[0m[0m | time: 12.321s
[2K
| Adam | epoch: 022 | loss: 0.59799 - acc: 0.6974 | val_loss: 0.59946 - val_acc: 0.6471 -- iter: 488/488
--
Training Step: 353  | total loss: [1m[32m0.60103[0m[0m | time: 0.797s
[2K
| Adam | epoch: 023 | loss: 0.60103 - acc: 0.6901 -- iter: 032/488
[A[ATraining Step: 354  | total loss: [1m[32m0.60329[0m[0m | time: 1.572s
[2K
| Adam | epoch: 023 | loss: 0.60329 - acc: 0.6805 -- iter: 064/488
[A[ATraining Step: 355  | total loss: [1m[32m0.59517[0m[0m | time: 2.312s
[2K
| Adam | epoch: 023 | loss: 0.59517 - acc: 0.6843 -- iter: 096/488
[A[ATraining Step: 356  | total loss: [1m[32m0.59249[0m[0m | time: 2.527s
[2K
| Adam | epoch: 023 | loss: 0.59249 - acc: 0.6753 -- iter: 128/488
[A[ATraining Step: 357  | total loss: [1m[32m0.57042[0m[0m | time: 2.729s
[2K
| Adam | epoch: 023 | loss: 0.57042 - acc: 0.6827 -- iter: 160/488
[A[ATraining Step: 358  | total loss: [1m[32m0.54723[0m[0m | time: 3.457s
[2K
| Adam | epoch: 023 | loss: 0.54723 - acc: 0.7020 -- iter: 192/488
[A[ATraining Step: 359  | total loss: [1m[32m0.57526[0m[0m | time: 4.194s
[2K
| Adam | epoch: 023 | loss: 0.57526 - acc: 0.6786 -- iter: 224/488
[A[ATraining Step: 360  | total loss: [1m[32m0.59757[0m[0m | time: 4.936s
[2K
| Adam | epoch: 023 | loss: 0.59757 - acc: 0.6576 -- iter: 256/488
[A[ATraining Step: 361  | total loss: [1m[32m0.59822[0m[0m | time: 5.673s
[2K
| Adam | epoch: 023 | loss: 0.59822 - acc: 0.6606 -- iter: 288/488
[A[ATraining Step: 362  | total loss: [1m[32m0.59549[0m[0m | time: 6.600s
[2K
| Adam | epoch: 023 | loss: 0.59549 - acc: 0.6633 -- iter: 320/488
[A[ATraining Step: 363  | total loss: [1m[32m0.61674[0m[0m | time: 7.752s
[2K
| Adam | epoch: 023 | loss: 0.61674 - acc: 0.6407 -- iter: 352/488
[A[ATraining Step: 364  | total loss: [1m[32m0.61793[0m[0m | time: 8.966s
[2K
| Adam | epoch: 023 | loss: 0.61793 - acc: 0.6360 -- iter: 384/488
[A[ATraining Step: 365  | total loss: [1m[32m0.62027[0m[0m | time: 10.371s
[2K
| Adam | epoch: 023 | loss: 0.62027 - acc: 0.6349 -- iter: 416/488
[A[ATraining Step: 366  | total loss: [1m[32m0.61851[0m[0m | time: 11.349s
[2K
| Adam | epoch: 023 | loss: 0.61851 - acc: 0.6371 -- iter: 448/488
[A[ATraining Step: 367  | total loss: [1m[32m0.61242[0m[0m | time: 12.407s
[2K
| Adam | epoch: 023 | loss: 0.61242 - acc: 0.6546 -- iter: 480/488
[A[ATraining Step: 368  | total loss: [1m[32m0.61454[0m[0m | time: 14.537s
[2K
| Adam | epoch: 023 | loss: 0.61454 - acc: 0.6548 | val_loss: 0.65080 - val_acc: 0.5490 -- iter: 488/488
--
Training Step: 369  | total loss: [1m[32m0.61375[0m[0m | time: 0.965s
[2K
| Adam | epoch: 024 | loss: 0.61375 - acc: 0.6518 -- iter: 032/488
[A[ATraining Step: 370  | total loss: [1m[32m0.60730[0m[0m | time: 1.989s
[2K
| Adam | epoch: 024 | loss: 0.60730 - acc: 0.6460 -- iter: 064/488
[A[ATraining Step: 371  | total loss: [1m[32m0.60958[0m[0m | time: 2.906s
[2K
| Adam | epoch: 024 | loss: 0.60958 - acc: 0.6376 -- iter: 096/488
[A[ATraining Step: 372  | total loss: [1m[32m0.60747[0m[0m | time: 4.094s
[2K
| Adam | epoch: 024 | loss: 0.60747 - acc: 0.6426 -- iter: 128/488
[A[ATraining Step: 373  | total loss: [1m[32m0.60461[0m[0m | time: 4.483s
[2K
| Adam | epoch: 024 | loss: 0.60461 - acc: 0.6502 -- iter: 160/488
[A[ATraining Step: 374  | total loss: [1m[32m0.59368[0m[0m | time: 4.844s
[2K
| Adam | epoch: 024 | loss: 0.59368 - acc: 0.6602 -- iter: 192/488
[A[ATraining Step: 375  | total loss: [1m[32m0.57890[0m[0m | time: 5.977s
[2K
| Adam | epoch: 024 | loss: 0.57890 - acc: 0.6817 -- iter: 224/488
[A[ATraining Step: 376  | total loss: [1m[32m0.59659[0m[0m | time: 6.817s
[2K
| Adam | epoch: 024 | loss: 0.59659 - acc: 0.6635 -- iter: 256/488
[A[ATraining Step: 377  | total loss: [1m[32m0.60290[0m[0m | time: 7.793s
[2K
| Adam | epoch: 024 | loss: 0.60290 - acc: 0.6597 -- iter: 288/488
[A[ATraining Step: 378  | total loss: [1m[32m0.62847[0m[0m | time: 8.782s
[2K
| Adam | epoch: 024 | loss: 0.62847 - acc: 0.6281 -- iter: 320/488
[A[ATraining Step: 379  | total loss: [1m[32m0.62524[0m[0m | time: 9.756s
[2K
| Adam | epoch: 024 | loss: 0.62524 - acc: 0.6278 -- iter: 352/488
[A[ATraining Step: 380  | total loss: [1m[32m0.62352[0m[0m | time: 10.791s
[2K
| Adam | epoch: 024 | loss: 0.62352 - acc: 0.6337 -- iter: 384/488
[A[ATraining Step: 381  | total loss: [1m[32m0.61609[0m[0m | time: 11.759s
[2K
| Adam | epoch: 024 | loss: 0.61609 - acc: 0.6454 -- iter: 416/488
[A[ATraining Step: 382  | total loss: [1m[32m0.61438[0m[0m | time: 12.876s
[2K
| Adam | epoch: 024 | loss: 0.61438 - acc: 0.6402 -- iter: 448/488
[A[ATraining Step: 383  | total loss: [1m[32m0.61815[0m[0m | time: 14.102s
[2K
| Adam | epoch: 024 | loss: 0.61815 - acc: 0.6387 -- iter: 480/488
[A[ATraining Step: 384  | total loss: [1m[32m0.61508[0m[0m | time: 16.410s
[2K
| Adam | epoch: 024 | loss: 0.61508 - acc: 0.6373 | val_loss: 0.56065 - val_acc: 0.7647 -- iter: 488/488
--
Training Step: 385  | total loss: [1m[32m0.61018[0m[0m | time: 1.057s
[2K
| Adam | epoch: 025 | loss: 0.61018 - acc: 0.6423 -- iter: 032/488
[A[ATraining Step: 386  | total loss: [1m[32m0.60485[0m[0m | time: 2.207s
[2K
| Adam | epoch: 025 | loss: 0.60485 - acc: 0.6437 -- iter: 064/488
[A[ATraining Step: 387  | total loss: [1m[32m0.60164[0m[0m | time: 3.472s
[2K
| Adam | epoch: 025 | loss: 0.60164 - acc: 0.6544 -- iter: 096/488
[A[ATraining Step: 388  | total loss: [1m[32m0.59551[0m[0m | time: 4.917s
[2K
| Adam | epoch: 025 | loss: 0.59551 - acc: 0.6608 -- iter: 128/488
[A[ATraining Step: 389  | total loss: [1m[32m0.59287[0m[0m | time: 6.028s
[2K
| Adam | epoch: 025 | loss: 0.59287 - acc: 0.6635 -- iter: 160/488
[A[ATraining Step: 390  | total loss: [1m[32m0.58296[0m[0m | time: 6.282s
[2K
| Adam | epoch: 025 | loss: 0.58296 - acc: 0.6752 -- iter: 192/488
[A[ATraining Step: 391  | total loss: [1m[32m0.61537[0m[0m | time: 6.584s
[2K
| Adam | epoch: 025 | loss: 0.61537 - acc: 0.6452 -- iter: 224/488
[A[ATraining Step: 392  | total loss: [1m[32m0.63738[0m[0m | time: 7.711s
[2K
| Adam | epoch: 025 | loss: 0.63738 - acc: 0.6182 -- iter: 256/488
[A[ATraining Step: 393  | total loss: [1m[32m0.62820[0m[0m | time: 8.769s
[2K
| Adam | epoch: 025 | loss: 0.62820 - acc: 0.6283 -- iter: 288/488
[A[ATraining Step: 394  | total loss: [1m[32m0.62588[0m[0m | time: 9.926s
[2K
| Adam | epoch: 025 | loss: 0.62588 - acc: 0.6404 -- iter: 320/488
[A[ATraining Step: 395  | total loss: [1m[32m0.63187[0m[0m | time: 11.047s
[2K
| Adam | epoch: 025 | loss: 0.63187 - acc: 0.6264 -- iter: 352/488
[A[ATraining Step: 396  | total loss: [1m[32m0.63156[0m[0m | time: 12.202s
[2K
| Adam | epoch: 025 | loss: 0.63156 - acc: 0.6262 -- iter: 384/488
[A[ATraining Step: 397  | total loss: [1m[32m0.61666[0m[0m | time: 13.289s
[2K
| Adam | epoch: 025 | loss: 0.61666 - acc: 0.6511 -- iter: 416/488
[A[ATraining Step: 398  | total loss: [1m[32m0.61188[0m[0m | time: 14.489s
[2K
| Adam | epoch: 025 | loss: 0.61188 - acc: 0.6548 -- iter: 448/488
[A[ATraining Step: 399  | total loss: [1m[32m0.60825[0m[0m | time: 15.679s
[2K
| Adam | epoch: 025 | loss: 0.60825 - acc: 0.6549 -- iter: 480/488
[A[ATraining Step: 400  | total loss: [1m[32m0.60515[0m[0m | time: 17.774s
[2K
| Adam | epoch: 025 | loss: 0.60515 - acc: 0.6707 | val_loss: 0.56397 - val_acc: 0.7124 -- iter: 488/488
--
Training Step: 401  | total loss: [1m[32m0.59010[0m[0m | time: 0.780s
[2K
| Adam | epoch: 026 | loss: 0.59010 - acc: 0.6911 -- iter: 032/488
[A[ATraining Step: 402  | total loss: [1m[32m0.58563[0m[0m | time: 1.524s
[2K
| Adam | epoch: 026 | loss: 0.58563 - acc: 0.7001 -- iter: 064/488
[A[ATraining Step: 403  | total loss: [1m[32m0.58282[0m[0m | time: 2.299s
[2K
| Adam | epoch: 026 | loss: 0.58282 - acc: 0.7020 -- iter: 096/488
[A[ATraining Step: 404  | total loss: [1m[32m0.57816[0m[0m | time: 3.012s
[2K
| Adam | epoch: 026 | loss: 0.57816 - acc: 0.7068 -- iter: 128/488
[A[ATraining Step: 405  | total loss: [1m[32m0.57242[0m[0m | time: 3.758s
[2K
| Adam | epoch: 026 | loss: 0.57242 - acc: 0.7111 -- iter: 160/488
[A[ATraining Step: 406  | total loss: [1m[32m0.56876[0m[0m | time: 4.563s
[2K
| Adam | epoch: 026 | loss: 0.56876 - acc: 0.7244 -- iter: 192/488
[A[ATraining Step: 407  | total loss: [1m[32m0.56467[0m[0m | time: 4.783s
[2K
| Adam | epoch: 026 | loss: 0.56467 - acc: 0.7238 -- iter: 224/488
[A[ATraining Step: 408  | total loss: [1m[32m0.55916[0m[0m | time: 4.957s
[2K
| Adam | epoch: 026 | loss: 0.55916 - acc: 0.7389 -- iter: 256/488
[A[ATraining Step: 409  | total loss: [1m[32m0.55143[0m[0m | time: 5.733s
[2K
| Adam | epoch: 026 | loss: 0.55143 - acc: 0.7525 -- iter: 288/488
[A[ATraining Step: 410  | total loss: [1m[32m0.54565[0m[0m | time: 6.646s
[2K
| Adam | epoch: 026 | loss: 0.54565 - acc: 0.7648 -- iter: 320/488
[A[ATraining Step: 411  | total loss: [1m[32m0.53858[0m[0m | time: 7.485s
[2K
| Adam | epoch: 026 | loss: 0.53858 - acc: 0.7633 -- iter: 352/488
[A[ATraining Step: 412  | total loss: [1m[32m0.53205[0m[0m | time: 8.279s
[2K
| Adam | epoch: 026 | loss: 0.53205 - acc: 0.7620 -- iter: 384/488
[A[ATraining Step: 413  | total loss: [1m[32m0.51905[0m[0m | time: 9.071s
[2K
| Adam | epoch: 026 | loss: 0.51905 - acc: 0.7701 -- iter: 416/488
[A[ATraining Step: 414  | total loss: [1m[32m0.51464[0m[0m | time: 9.789s
[2K
| Adam | epoch: 026 | loss: 0.51464 - acc: 0.7744 -- iter: 448/488
[A[ATraining Step: 415  | total loss: [1m[32m0.51989[0m[0m | time: 10.603s
[2K
| Adam | epoch: 026 | loss: 0.51989 - acc: 0.7626 -- iter: 480/488
[A[ATraining Step: 416  | total loss: [1m[32m0.51170[0m[0m | time: 12.370s
[2K
| Adam | epoch: 026 | loss: 0.51170 - acc: 0.7676 | val_loss: 0.58440 - val_acc: 0.7320 -- iter: 488/488
--
Training Step: 417  | total loss: [1m[32m0.51028[0m[0m | time: 0.749s
[2K
| Adam | epoch: 027 | loss: 0.51028 - acc: 0.7564 -- iter: 032/488
[A[ATraining Step: 418  | total loss: [1m[32m0.51653[0m[0m | time: 1.473s
[2K
| Adam | epoch: 027 | loss: 0.51653 - acc: 0.7464 -- iter: 064/488
[A[ATraining Step: 419  | total loss: [1m[32m0.51711[0m[0m | time: 2.246s
[2K
| Adam | epoch: 027 | loss: 0.51711 - acc: 0.7499 -- iter: 096/488
[A[ATraining Step: 420  | total loss: [1m[32m0.52599[0m[0m | time: 2.980s
[2K
| Adam | epoch: 027 | loss: 0.52599 - acc: 0.7499 -- iter: 128/488
[A[ATraining Step: 421  | total loss: [1m[32m0.52487[0m[0m | time: 3.739s
[2K
| Adam | epoch: 027 | loss: 0.52487 - acc: 0.7562 -- iter: 160/488
[A[ATraining Step: 422  | total loss: [1m[32m0.53957[0m[0m | time: 4.486s
[2K
| Adam | epoch: 027 | loss: 0.53957 - acc: 0.7493 -- iter: 192/488
[A[ATraining Step: 423  | total loss: [1m[32m0.52941[0m[0m | time: 5.203s
[2K
| Adam | epoch: 027 | loss: 0.52941 - acc: 0.7525 -- iter: 224/488
[A[ATraining Step: 424  | total loss: [1m[32m0.53154[0m[0m | time: 5.405s
[2K
| Adam | epoch: 027 | loss: 0.53154 - acc: 0.7522 -- iter: 256/488
[A[ATraining Step: 425  | total loss: [1m[32m0.53930[0m[0m | time: 5.713s
[2K
| Adam | epoch: 027 | loss: 0.53930 - acc: 0.7395 -- iter: 288/488
[A[ATraining Step: 426  | total loss: [1m[32m0.54024[0m[0m | time: 6.493s
[2K
| Adam | epoch: 027 | loss: 0.54024 - acc: 0.7406 -- iter: 320/488
[A[ATraining Step: 427  | total loss: [1m[32m0.56367[0m[0m | time: 7.660s
[2K
| Adam | epoch: 027 | loss: 0.56367 - acc: 0.7321 -- iter: 352/488
[A[ATraining Step: 428  | total loss: [1m[32m0.54080[0m[0m | time: 8.711s
[2K
| Adam | epoch: 027 | loss: 0.54080 - acc: 0.7527 -- iter: 384/488
[A[ATraining Step: 429  | total loss: [1m[32m0.54048[0m[0m | time: 9.335s
[2K
| Adam | epoch: 027 | loss: 0.54048 - acc: 0.7430 -- iter: 416/488
[A[ATraining Step: 430  | total loss: [1m[32m0.52004[0m[0m | time: 9.939s
[2K
| Adam | epoch: 027 | loss: 0.52004 - acc: 0.7562 -- iter: 448/488
[A[ATraining Step: 431  | total loss: [1m[32m0.52684[0m[0m | time: 10.568s
[2K
| Adam | epoch: 027 | loss: 0.52684 - acc: 0.7525 -- iter: 480/488
[A[ATraining Step: 432  | total loss: [1m[32m0.52092[0m[0m | time: 12.346s
[2K
| Adam | epoch: 027 | loss: 0.52092 - acc: 0.7585 | val_loss: 0.51631 - val_acc: 0.7255 -- iter: 488/488
--
Training Step: 433  | total loss: [1m[32m0.51128[0m[0m | time: 1.182s
[2K
| Adam | epoch: 028 | loss: 0.51128 - acc: 0.7670 -- iter: 032/488
[A[ATraining Step: 434  | total loss: [1m[32m0.51777[0m[0m | time: 2.512s
[2K
| Adam | epoch: 028 | loss: 0.51777 - acc: 0.7591 -- iter: 064/488
[A[ATraining Step: 435  | total loss: [1m[32m0.52180[0m[0m | time: 3.813s
[2K
| Adam | epoch: 028 | loss: 0.52180 - acc: 0.7550 -- iter: 096/488
[A[ATraining Step: 436  | total loss: [1m[32m0.51823[0m[0m | time: 4.789s
[2K
| Adam | epoch: 028 | loss: 0.51823 - acc: 0.7576 -- iter: 128/488
[A[ATraining Step: 437  | total loss: [1m[32m0.50807[0m[0m | time: 5.875s
[2K
| Adam | epoch: 028 | loss: 0.50807 - acc: 0.7631 -- iter: 160/488
[A[ATraining Step: 438  | total loss: [1m[32m0.50775[0m[0m | time: 6.912s
[2K
| Adam | epoch: 028 | loss: 0.50775 - acc: 0.7649 -- iter: 192/488
[A[ATraining Step: 439  | total loss: [1m[32m0.51373[0m[0m | time: 7.960s
[2K
| Adam | epoch: 028 | loss: 0.51373 - acc: 0.7666 -- iter: 224/488
[A[ATraining Step: 440  | total loss: [1m[32m0.51965[0m[0m | time: 9.068s
[2K
| Adam | epoch: 028 | loss: 0.51965 - acc: 0.7524 -- iter: 256/488
[A[ATraining Step: 441  | total loss: [1m[32m0.52044[0m[0m | time: 9.396s
[2K
| Adam | epoch: 028 | loss: 0.52044 - acc: 0.7491 -- iter: 288/488
[A[ATraining Step: 442  | total loss: [1m[32m0.50178[0m[0m | time: 9.768s
[2K
| Adam | epoch: 028 | loss: 0.50178 - acc: 0.7616 -- iter: 320/488
[A[ATraining Step: 443  | total loss: [1m[32m0.48282[0m[0m | time: 10.987s
[2K
| Adam | epoch: 028 | loss: 0.48282 - acc: 0.7730 -- iter: 352/488
[A[ATraining Step: 444  | total loss: [1m[32m0.49905[0m[0m | time: 12.020s
[2K
| Adam | epoch: 028 | loss: 0.49905 - acc: 0.7613 -- iter: 384/488
[A[ATraining Step: 445  | total loss: [1m[32m0.50105[0m[0m | time: 13.047s
[2K
| Adam | epoch: 028 | loss: 0.50105 - acc: 0.7602 -- iter: 416/488
[A[ATraining Step: 446  | total loss: [1m[32m0.51558[0m[0m | time: 14.233s
[2K
| Adam | epoch: 028 | loss: 0.51558 - acc: 0.7498 -- iter: 448/488
[A[ATraining Step: 447  | total loss: [1m[32m0.50880[0m[0m | time: 15.571s
[2K
| Adam | epoch: 028 | loss: 0.50880 - acc: 0.7592 -- iter: 480/488
[A[ATraining Step: 448  | total loss: [1m[32m0.49311[0m[0m | time: 17.888s
[2K
| Adam | epoch: 028 | loss: 0.49311 - acc: 0.7708 | val_loss: 0.56562 - val_acc: 0.7190 -- iter: 488/488
--
Training Step: 449  | total loss: [1m[32m0.48559[0m[0m | time: 1.292s
[2K
| Adam | epoch: 029 | loss: 0.48559 - acc: 0.7749 -- iter: 032/488
[A[ATraining Step: 450  | total loss: [1m[32m0.48025[0m[0m | time: 2.388s
[2K
| Adam | epoch: 029 | loss: 0.48025 - acc: 0.7818 -- iter: 064/488
[A[ATraining Step: 451  | total loss: [1m[32m0.48562[0m[0m | time: 3.346s
[2K
| Adam | epoch: 029 | loss: 0.48562 - acc: 0.7724 -- iter: 096/488
[A[ATraining Step: 452  | total loss: [1m[32m0.48386[0m[0m | time: 4.351s
[2K
| Adam | epoch: 029 | loss: 0.48386 - acc: 0.7639 -- iter: 128/488
[A[ATraining Step: 453  | total loss: [1m[32m0.46797[0m[0m | time: 5.255s
[2K
| Adam | epoch: 029 | loss: 0.46797 - acc: 0.7781 -- iter: 160/488
[A[ATraining Step: 454  | total loss: [1m[32m0.47028[0m[0m | time: 6.214s
[2K
| Adam | epoch: 029 | loss: 0.47028 - acc: 0.7784 -- iter: 192/488
[A[ATraining Step: 455  | total loss: [1m[32m0.48525[0m[0m | time: 7.232s
[2K
| Adam | epoch: 029 | loss: 0.48525 - acc: 0.7694 -- iter: 224/488
[A[ATraining Step: 456  | total loss: [1m[32m0.47771[0m[0m | time: 8.178s
[2K
| Adam | epoch: 029 | loss: 0.47771 - acc: 0.7737 -- iter: 256/488
[A[ATraining Step: 457  | total loss: [1m[32m0.47950[0m[0m | time: 9.126s
[2K
| Adam | epoch: 029 | loss: 0.47950 - acc: 0.7682 -- iter: 288/488
[A[ATraining Step: 458  | total loss: [1m[32m0.47576[0m[0m | time: 9.422s
[2K
| Adam | epoch: 029 | loss: 0.47576 - acc: 0.7695 -- iter: 320/488
[A[ATraining Step: 459  | total loss: [1m[32m0.48233[0m[0m | time: 9.742s
[2K
| Adam | epoch: 029 | loss: 0.48233 - acc: 0.7675 -- iter: 352/488
[A[ATraining Step: 460  | total loss: [1m[32m0.48377[0m[0m | time: 10.744s
[2K
| Adam | epoch: 029 | loss: 0.48377 - acc: 0.7658 -- iter: 384/488
[A[ATraining Step: 461  | total loss: [1m[32m0.48351[0m[0m | time: 11.710s
[2K
| Adam | epoch: 029 | loss: 0.48351 - acc: 0.7673 -- iter: 416/488
[A[ATraining Step: 462  | total loss: [1m[32m0.46380[0m[0m | time: 12.720s
[2K
| Adam | epoch: 029 | loss: 0.46380 - acc: 0.7843 -- iter: 448/488
[A[ATraining Step: 463  | total loss: [1m[32m0.46598[0m[0m | time: 13.840s
[2K
| Adam | epoch: 029 | loss: 0.46598 - acc: 0.7840 -- iter: 480/488
[A[ATraining Step: 464  | total loss: [1m[32m0.46739[0m[0m | time: 15.943s
[2K
| Adam | epoch: 029 | loss: 0.46739 - acc: 0.7806 | val_loss: 0.48237 - val_acc: 0.7190 -- iter: 488/488
--
Training Step: 465  | total loss: [1m[32m0.45839[0m[0m | time: 1.083s
[2K
| Adam | epoch: 030 | loss: 0.45839 - acc: 0.7869 -- iter: 032/488
[A[ATraining Step: 466  | total loss: [1m[32m0.45200[0m[0m | time: 2.243s
[2K
| Adam | epoch: 030 | loss: 0.45200 - acc: 0.7895 -- iter: 064/488
[A[ATraining Step: 467  | total loss: [1m[32m0.44539[0m[0m | time: 3.370s
[2K
| Adam | epoch: 030 | loss: 0.44539 - acc: 0.8012 -- iter: 096/488
[A[ATraining Step: 468  | total loss: [1m[32m0.45046[0m[0m | time: 4.553s
[2K
| Adam | epoch: 030 | loss: 0.45046 - acc: 0.7992 -- iter: 128/488
[A[ATraining Step: 469  | total loss: [1m[32m0.45077[0m[0m | time: 5.803s
[2K
| Adam | epoch: 030 | loss: 0.45077 - acc: 0.8005 -- iter: 160/488
[A[ATraining Step: 470  | total loss: [1m[32m0.43865[0m[0m | time: 6.825s
[2K
| Adam | epoch: 030 | loss: 0.43865 - acc: 0.8142 -- iter: 192/488
[A[ATraining Step: 471  | total loss: [1m[32m0.43874[0m[0m | time: 7.886s
[2K
| Adam | epoch: 030 | loss: 0.43874 - acc: 0.8203 -- iter: 224/488
[A[ATraining Step: 472  | total loss: [1m[32m0.43651[0m[0m | time: 9.044s
[2K
| Adam | epoch: 030 | loss: 0.43651 - acc: 0.8101 -- iter: 256/488
[A[ATraining Step: 473  | total loss: [1m[32m0.44079[0m[0m | time: 10.130s
[2K
| Adam | epoch: 030 | loss: 0.44079 - acc: 0.8072 -- iter: 288/488
[A[ATraining Step: 474  | total loss: [1m[32m0.44516[0m[0m | time: 10.955s
[2K
| Adam | epoch: 030 | loss: 0.44516 - acc: 0.8015 -- iter: 320/488
[A[ATraining Step: 475  | total loss: [1m[32m0.45255[0m[0m | time: 11.134s
[2K
| Adam | epoch: 030 | loss: 0.45255 - acc: 0.7964 -- iter: 352/488
[A[ATraining Step: 476  | total loss: [1m[32m0.43491[0m[0m | time: 11.410s
[2K
| Adam | epoch: 030 | loss: 0.43491 - acc: 0.8042 -- iter: 384/488
[A[ATraining Step: 477  | total loss: [1m[32m0.41779[0m[0m | time: 12.137s
[2K
| Adam | epoch: 030 | loss: 0.41779 - acc: 0.8238 -- iter: 416/488
[A[ATraining Step: 478  | total loss: [1m[32m0.42277[0m[0m | time: 12.853s
[2K
| Adam | epoch: 030 | loss: 0.42277 - acc: 0.8258 -- iter: 448/488
[A[ATraining Step: 479  | total loss: [1m[32m0.40143[0m[0m | time: 13.614s
[2K
| Adam | epoch: 030 | loss: 0.40143 - acc: 0.8370 -- iter: 480/488
[A[ATraining Step: 480  | total loss: [1m[32m0.41244[0m[0m | time: 15.365s
[2K
| Adam | epoch: 030 | loss: 0.41244 - acc: 0.8252 | val_loss: 0.47355 - val_acc: 0.7451 -- iter: 488/488
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8550427350427351
Validation AUPRC:0.8753277675661604
Test AUC:0.8446534308603274
Test AUPRC:0.7959659416200514
BestTestF1Score	0.76	0.54	0.74	0.63	0.94	62	36	51	4	0.17
BestTestMCCScore	0.65	0.52	0.76	0.85	0.53	35	6	81	31	0.77
BestTestAccuracyScore	0.65	0.5	0.75	0.83	0.53	35	7	80	31	0.73
BestValidationF1Score	0.78	0.51	0.73	0.66	0.96	75	39	36	3	0.17
BestValidationMCC	0.72	0.6	0.77	0.96	0.58	45	2	73	33	0.77
BestValidationAccuracy	0.74	0.59	0.78	0.92	0.62	48	4	71	30	0.73
TestPredictions (Threshold:0.77)
CHEMBL474325,TN,INACT,0.3700000047683716	CHEMBL1643407,TN,INACT,0.12999999523162842	CHEMBL2420377,TN,INACT,0.20000000298023224	CHEMBL2414234,FN,ACT,0.44999998807907104	CHEMBL488992,TN,INACT,0.20999999344348907	CHEMBL3355101,FN,ACT,0.10999999940395355	CHEMBL3597443,TP,ACT,0.9200000166893005	CHEMBL3597449,TP,ACT,0.9100000262260437	CHEMBL1213732,TN,INACT,0.07000000029802322	CHEMBL151900,TN,INACT,0.18000000715255737	CHEMBL470072,TN,INACT,0.09000000357627869	CHEMBL2036143,TN,INACT,0.4000000059604645	CHEMBL3355104,FN,ACT,0.1899999976158142	CHEMBL598542,TN,INACT,0.10000000149011612	CHEMBL290419,FN,ACT,0.47999998927116394	CHEMBL523828,TN,INACT,0.09000000357627869	CHEMBL1819322,TN,INACT,0.07999999821186066	CHEMBL494919,TN,INACT,0.07999999821186066	CHEMBL1095233,FN,ACT,0.3199999928474426	CHEMBL3414595,TN,INACT,0.10000000149011612	CHEMBL3596210,TP,ACT,0.9599999785423279	CHEMBL245394,TN,INACT,0.3100000023841858	CHEMBL245916,TN,INACT,0.029999999329447746	CHEMBL327844,TP,ACT,0.9399999976158142	CHEMBL2369772,TN,INACT,0.5600000023841858	CHEMBL3416721,TN,INACT,0.3400000035762787	CHEMBL1213668,TN,INACT,0.5	CHEMBL3804861,FN,ACT,0.49000000953674316	CHEMBL2205653,TP,ACT,0.8999999761581421	CHEMBL2420380,TN,INACT,0.30000001192092896	CHEMBL2179975,TP,ACT,0.8299999833106995	CHEMBL1821981,FN,ACT,0.47999998927116394	CHEMBL449526,TN,INACT,0.5099999904632568	CHEMBL3805587,TN,INACT,0.1599999964237213	CHEMBL1830648,TN,INACT,0.5099999904632568	CHEMBL3805495,FN,ACT,0.019999999552965164	CHEMBL3416730,TN,INACT,0.05999999865889549	CHEMBL498745,TN,INACT,0.07000000029802322	CHEMBL245398,TN,INACT,0.10999999940395355	CHEMBL594961,TN,INACT,0.03999999910593033	CHEMBL583058,TN,INACT,0.44999998807907104	CHEMBL3765787,TP,ACT,0.8899999856948853	CHEMBL498743,TN,INACT,0.05999999865889549	CHEMBL1159952,TP,ACT,0.9100000262260437	CHEMBL1093883,FN,ACT,0.6000000238418579	CHEMBL3764156,TP,ACT,0.8500000238418579	CHEMBL26989,TN,INACT,0.7099999785423279	CHEMBL1098915,TN,INACT,0.05999999865889549	CHEMBL1159927,TP,ACT,0.9300000071525574	CHEMBL522494,TN,INACT,0.6100000143051147	CHEMBL597935,TN,INACT,0.05999999865889549	CHEMBL3261758,TN,INACT,0.009999999776482582	CHEMBL3805338,TP,ACT,0.9599999785423279	CHEMBL481704,TN,INACT,0.009999999776482582	CHEMBL1159809,FN,ACT,0.5	CHEMBL3597452,TP,ACT,0.949999988079071	CHEMBL3805251,FP,INACT,0.9399999976158142	CHEMBL194009,TN,INACT,0.5299999713897705	CHEMBL510287,TN,INACT,0.11999999731779099	CHEMBL1214590,TN,INACT,0.11999999731779099	CHEMBL597128,FN,ACT,0.05000000074505806	CHEMBL523871,TN,INACT,0.41999998688697815	CHEMBL497922,TN,INACT,0.07999999821186066	CHEMBL85320,TP,ACT,0.8399999737739563	CHEMBL3764011,TP,ACT,0.8500000238418579	CHEMBL3765067,FN,ACT,0.27000001072883606	CHEMBL357586,TP,ACT,0.8799999952316284	CHEMBL469484,TN,INACT,0.03999999910593033	CHEMBL1819447,TN,INACT,0.11999999731779099	CHEMBL2180996,FN,ACT,0.5299999713897705	CHEMBL2204953,FN,ACT,0.6299999952316284	CHEMBL37846,FN,ACT,0.4300000071525574	CHEMBL461004,TN,INACT,0.49000000953674316	CHEMBL273851,FP,INACT,0.9300000071525574	CHEMBL2204945,TP,ACT,0.800000011920929	CHEMBL597332,TP,ACT,0.800000011920929	CHEMBL3125967,TN,INACT,0.6000000238418579	CHEMBL3261746,TN,INACT,0.1899999976158142	CHEMBL1159919,TP,ACT,0.9399999976158142	CHEMBL521626,TN,INACT,0.05999999865889549	CHEMBL70599,TN,INACT,0.1599999964237213	CHEMBL3806100,TN,INACT,0.6600000262260437	CHEMBL3261763,TN,INACT,0.07000000029802322	CHEMBL146922,FN,ACT,0.46000000834465027	CHEMBL1159923,TP,ACT,0.9300000071525574	CHEMBL2414235,FN,ACT,0.5199999809265137	CHEMBL1089899,TN,INACT,0.09000000357627869	CHEMBL101147,FN,ACT,0.30000001192092896	CHEMBL1159954,TP,ACT,0.9700000286102295	CHEMBL2261078,TN,INACT,0.5400000214576721	CHEMBL3597458,TP,ACT,0.8899999856948853	CHEMBL29292,FN,ACT,0.550000011920929	CHEMBL309130,TN,INACT,0.17000000178813934	CHEMBL3416719,TN,INACT,0.029999999329447746	CHEMBL1161304,FN,ACT,0.28999999165534973	CHEMBL375268,FP,INACT,0.8100000023841858	CHEMBL3597450,FN,ACT,0.4300000071525574	CHEMBL572501,TN,INACT,0.11999999731779099	CHEMBL2332515,FN,ACT,0.3100000023841858	CHEMBL1159811,FN,ACT,0.6299999952316284	CHEMBL1159928,TP,ACT,0.949999988079071	CHEMBL591441,FN,ACT,0.18000000715255737	CHEMBL1159953,TP,ACT,0.9399999976158142	CHEMBL523373,TN,INACT,0.029999999329447746	CHEMBL223711,FN,ACT,0.10999999940395355	CHEMBL523279,TN,INACT,0.03999999910593033	CHEMBL476657,TN,INACT,0.05000000074505806	CHEMBL3741904,TN,INACT,0.11999999731779099	CHEMBL478079,TN,INACT,0.07000000029802322	CHEMBL573583,TN,INACT,0.7699999809265137	CHEMBL103306,TP,ACT,0.8999999761581421	CHEMBL2036148,FN,ACT,0.6800000071525574	CHEMBL3740862,FP,INACT,0.9200000166893005	CHEMBL247392,TN,INACT,0.09000000357627869	CHEMBL575053,TN,INACT,0.05999999865889549	CHEMBL1941142,TP,ACT,0.8299999833106995	CHEMBL2204943,TP,ACT,0.8700000047683716	CHEMBL355858,FP,INACT,0.9399999976158142	CHEMBL1821983,TP,ACT,0.9399999976158142	CHEMBL219611,FN,ACT,0.5400000214576721	CHEMBL1090217,FN,ACT,0.3700000047683716	CHEMBL246179,TN,INACT,0.019999999552965164	CHEMBL290357,TP,ACT,0.8500000238418579	CHEMBL2204949,FN,ACT,0.25999999046325684	CHEMBL317189,FN,ACT,0.41999998688697815	CHEMBL2022235,TN,INACT,0.03999999910593033	CHEMBL3597442,TP,ACT,0.9100000262260437	CHEMBL593542,TN,INACT,0.3700000047683716	CHEMBL3416589,TN,INACT,0.019999999552965164	CHEMBL597106,TN,INACT,0.1599999964237213	CHEMBL478078,TN,INACT,0.07000000029802322	CHEMBL500851,FN,ACT,0.5600000023841858	CHEMBL2420378,TN,INACT,0.20999999344348907	CHEMBL3597461,TP,ACT,0.9800000190734863	CHEMBL151999,FP,INACT,0.8999999761581421	CHEMBL472727,TN,INACT,0.3400000035762787	CHEMBL3337721,TN,INACT,0.12999999523162842	CHEMBL3764200,TP,ACT,0.8100000023841858	CHEMBL539640,TN,INACT,0.6000000238418579	CHEMBL1099253,TN,INACT,0.07999999821186066	CHEMBL3763665,TP,ACT,0.8399999737739563	CHEMBL457656,TN,INACT,0.23999999463558197	CHEMBL246780,TN,INACT,0.019999999552965164	CHEMBL395354,TN,INACT,0.03999999910593033	CHEMBL2420381,TN,INACT,0.05000000074505806	CHEMBL1159934,TP,ACT,0.9700000286102295	CHEMBL476639,TN,INACT,0.07000000029802322	CHEMBL3765179,TP,ACT,0.9300000071525574	CHEMBL246178,TN,INACT,0.17000000178813934	CHEMBL2070003,TN,INACT,0.12999999523162842	CHEMBL1819445,TN,INACT,0.03999999910593033	CHEMBL2332519,TP,ACT,0.8500000238418579	CHEMBL2179981,TN,INACT,0.15000000596046448	

