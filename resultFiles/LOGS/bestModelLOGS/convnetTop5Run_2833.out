ImageNetInceptionV2 CHEMBL2695 RMSprop 0.001 15 0 0 0.6 False True
Number of active compounds :	1043
Number of inactive compounds :	1043
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2695_RMSprop_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2695_RMSprop_0.001_15_0.6/
---------------------------------
Training samples: 1292
Validation samples: 405
--
Training Step: 1  | time: 79.472s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1292
[A[ATraining Step: 2  | total loss: [1m[32m0.64645[0m[0m | time: 107.317s
[2K
| RMSProp | epoch: 001 | loss: 0.64645 - acc: 0.4781 -- iter: 0064/1292
[A[ATraining Step: 3  | total loss: [1m[32m0.69580[0m[0m | time: 131.899s
[2K
| RMSProp | epoch: 001 | loss: 0.69580 - acc: 0.4960 -- iter: 0096/1292
[A[ATraining Step: 4  | total loss: [1m[32m0.75032[0m[0m | time: 151.115s
[2K
| RMSProp | epoch: 001 | loss: 0.75032 - acc: 0.4521 -- iter: 0128/1292
[A[ATraining Step: 5  | total loss: [1m[32m0.72682[0m[0m | time: 185.106s
[2K
| RMSProp | epoch: 001 | loss: 0.72682 - acc: 0.5718 -- iter: 0160/1292
[A[ATraining Step: 6  | total loss: [1m[32m0.71116[0m[0m | time: 198.457s
[2K
| RMSProp | epoch: 001 | loss: 0.71116 - acc: 0.5457 -- iter: 0192/1292
[A[ATraining Step: 7  | total loss: [1m[32m0.69310[0m[0m | time: 210.875s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5558 -- iter: 0224/1292
[A[ATraining Step: 8  | total loss: [1m[32m0.70625[0m[0m | time: 223.352s
[2K
| RMSProp | epoch: 001 | loss: 0.70625 - acc: 0.5068 -- iter: 0256/1292
[A[ATraining Step: 9  | total loss: [1m[32m0.68813[0m[0m | time: 235.427s
[2K
| RMSProp | epoch: 001 | loss: 0.68813 - acc: 0.5694 -- iter: 0288/1292
[A[ATraining Step: 10  | total loss: [1m[32m0.70373[0m[0m | time: 251.685s
[2K
| RMSProp | epoch: 001 | loss: 0.70373 - acc: 0.5503 -- iter: 0320/1292
[A[ATraining Step: 11  | total loss: [1m[32m0.71883[0m[0m | time: 265.508s
[2K
| RMSProp | epoch: 001 | loss: 0.71883 - acc: 0.5265 -- iter: 0352/1292
[A[ATraining Step: 12  | total loss: [1m[32m0.71145[0m[0m | time: 277.674s
[2K
| RMSProp | epoch: 001 | loss: 0.71145 - acc: 0.5146 -- iter: 0384/1292
[A[ATraining Step: 13  | total loss: [1m[32m0.70035[0m[0m | time: 290.050s
[2K
| RMSProp | epoch: 001 | loss: 0.70035 - acc: 0.5217 -- iter: 0416/1292
[A[ATraining Step: 14  | total loss: [1m[32m0.69418[0m[0m | time: 302.240s
[2K
| RMSProp | epoch: 001 | loss: 0.69418 - acc: 0.5384 -- iter: 0448/1292
[A[ATraining Step: 15  | total loss: [1m[32m0.71140[0m[0m | time: 314.546s
[2K
| RMSProp | epoch: 001 | loss: 0.71140 - acc: 0.4989 -- iter: 0480/1292
[A[ATraining Step: 16  | total loss: [1m[32m0.69476[0m[0m | time: 326.632s
[2K
| RMSProp | epoch: 001 | loss: 0.69476 - acc: 0.5110 -- iter: 0512/1292
[A[ATraining Step: 17  | total loss: [1m[32m0.72550[0m[0m | time: 337.487s
[2K
| RMSProp | epoch: 001 | loss: 0.72550 - acc: 0.4733 -- iter: 0544/1292
[A[ATraining Step: 18  | total loss: [1m[32m0.73923[0m[0m | time: 349.676s
[2K
| RMSProp | epoch: 001 | loss: 0.73923 - acc: 0.4609 -- iter: 0576/1292
[A[ATraining Step: 19  | total loss: [1m[32m0.75359[0m[0m | time: 366.264s
[2K
| RMSProp | epoch: 001 | loss: 0.75359 - acc: 0.4531 -- iter: 0608/1292
[A[ATraining Step: 20  | total loss: [1m[32m0.73803[0m[0m | time: 378.729s
[2K
| RMSProp | epoch: 001 | loss: 0.73803 - acc: 0.4481 -- iter: 0640/1292
[A[ATraining Step: 21  | total loss: [1m[32m0.72859[0m[0m | time: 391.256s
[2K
| RMSProp | epoch: 001 | loss: 0.72859 - acc: 0.4933 -- iter: 0672/1292
[A[ATraining Step: 22  | total loss: [1m[32m0.70854[0m[0m | time: 403.749s
[2K
| RMSProp | epoch: 001 | loss: 0.70854 - acc: 0.5234 -- iter: 0704/1292
[A[ATraining Step: 23  | total loss: [1m[32m0.69927[0m[0m | time: 415.750s
[2K
| RMSProp | epoch: 001 | loss: 0.69927 - acc: 0.5348 -- iter: 0736/1292
[A[ATraining Step: 24  | total loss: [1m[32m0.69103[0m[0m | time: 428.115s
[2K
| RMSProp | epoch: 001 | loss: 0.69103 - acc: 0.5338 -- iter: 0768/1292
[A[ATraining Step: 25  | total loss: [1m[32m0.68486[0m[0m | time: 437.017s
[2K
| RMSProp | epoch: 001 | loss: 0.68486 - acc: 0.5331 -- iter: 0800/1292
[A[ATraining Step: 26  | total loss: [1m[32m0.67869[0m[0m | time: 446.006s
[2K
| RMSProp | epoch: 001 | loss: 0.67869 - acc: 0.5574 -- iter: 0832/1292
[A[ATraining Step: 27  | total loss: [1m[32m0.67055[0m[0m | time: 457.064s
[2K
| RMSProp | epoch: 001 | loss: 0.67055 - acc: 0.5909 -- iter: 0864/1292
[A[ATraining Step: 28  | total loss: [1m[32m0.66544[0m[0m | time: 469.395s
[2K
| RMSProp | epoch: 001 | loss: 0.66544 - acc: 0.5994 -- iter: 0896/1292
[A[ATraining Step: 29  | total loss: [1m[32m0.70506[0m[0m | time: 481.101s
[2K
| RMSProp | epoch: 001 | loss: 0.70506 - acc: 0.5372 -- iter: 0928/1292
[A[ATraining Step: 30  | total loss: [1m[32m0.70368[0m[0m | time: 494.728s
[2K
| RMSProp | epoch: 001 | loss: 0.70368 - acc: 0.5210 -- iter: 0960/1292
[A[ATraining Step: 31  | total loss: [1m[32m0.69787[0m[0m | time: 507.449s
[2K
| RMSProp | epoch: 001 | loss: 0.69787 - acc: 0.5234 -- iter: 0992/1292
[A[ATraining Step: 32  | total loss: [1m[32m0.70210[0m[0m | time: 519.795s
[2K
| RMSProp | epoch: 001 | loss: 0.70210 - acc: 0.5040 -- iter: 1024/1292
[A[ATraining Step: 33  | total loss: [1m[32m0.70149[0m[0m | time: 532.524s
[2K
| RMSProp | epoch: 001 | loss: 0.70149 - acc: 0.5032 -- iter: 1056/1292
[A[ATraining Step: 34  | total loss: [1m[32m0.68047[0m[0m | time: 544.632s
[2K
| RMSProp | epoch: 001 | loss: 0.68047 - acc: 0.5694 -- iter: 1088/1292
[A[ATraining Step: 35  | total loss: [1m[32m0.68200[0m[0m | time: 556.760s
[2K
| RMSProp | epoch: 001 | loss: 0.68200 - acc: 0.5811 -- iter: 1120/1292
[A[ATraining Step: 36  | total loss: [1m[32m0.68474[0m[0m | time: 575.293s
[2K
| RMSProp | epoch: 001 | loss: 0.68474 - acc: 0.5965 -- iter: 1152/1292
[A[ATraining Step: 37  | total loss: [1m[32m0.68409[0m[0m | time: 596.634s
[2K
| RMSProp | epoch: 001 | loss: 0.68409 - acc: 0.5897 -- iter: 1184/1292
[A[ATraining Step: 38  | total loss: [1m[32m0.67761[0m[0m | time: 609.007s
[2K
| RMSProp | epoch: 001 | loss: 0.67761 - acc: 0.5966 -- iter: 1216/1292
[A[ATraining Step: 39  | total loss: [1m[32m0.67476[0m[0m | time: 621.492s
[2K
| RMSProp | epoch: 001 | loss: 0.67476 - acc: 0.6200 -- iter: 1248/1292
[A[ATraining Step: 40  | total loss: [1m[32m0.68347[0m[0m | time: 632.951s
[2K
| RMSProp | epoch: 001 | loss: 0.68347 - acc: 0.5916 -- iter: 1280/1292
[A[ATraining Step: 41  | total loss: [1m[32m0.67984[0m[0m | time: 676.226s
[2K
| RMSProp | epoch: 001 | loss: 0.67984 - acc: 0.5863 | val_loss: 0.69472 - val_acc: 0.4889 -- iter: 1292/1292
--
Training Step: 42  | total loss: [1m[32m0.67714[0m[0m | time: 3.764s
[2K
| RMSProp | epoch: 002 | loss: 0.67714 - acc: 0.6007 -- iter: 0032/1292
[A[ATraining Step: 43  | total loss: [1m[32m0.66856[0m[0m | time: 12.374s
[2K
| RMSProp | epoch: 002 | loss: 0.66856 - acc: 0.5977 -- iter: 0064/1292
[A[ATraining Step: 44  | total loss: [1m[32m0.67729[0m[0m | time: 24.476s
[2K
| RMSProp | epoch: 002 | loss: 0.67729 - acc: 0.5808 -- iter: 0096/1292
[A[ATraining Step: 45  | total loss: [1m[32m0.67982[0m[0m | time: 36.906s
[2K
| RMSProp | epoch: 002 | loss: 0.67982 - acc: 0.5777 -- iter: 0128/1292
[A[ATraining Step: 46  | total loss: [1m[32m0.70216[0m[0m | time: 49.771s
[2K
| RMSProp | epoch: 002 | loss: 0.70216 - acc: 0.5647 -- iter: 0160/1292
[A[ATraining Step: 47  | total loss: [1m[32m0.69826[0m[0m | time: 62.460s
[2K
| RMSProp | epoch: 002 | loss: 0.69826 - acc: 0.5695 -- iter: 0192/1292
[A[ATraining Step: 48  | total loss: [1m[32m0.69578[0m[0m | time: 74.901s
[2K
| RMSProp | epoch: 002 | loss: 0.69578 - acc: 0.5683 -- iter: 0224/1292
[A[ATraining Step: 49  | total loss: [1m[32m0.68989[0m[0m | time: 86.890s
[2K
| RMSProp | epoch: 002 | loss: 0.68989 - acc: 0.5674 -- iter: 0256/1292
[A[ATraining Step: 50  | total loss: [1m[32m0.69837[0m[0m | time: 117.557s
[2K
| RMSProp | epoch: 002 | loss: 0.69837 - acc: 0.5570 -- iter: 0288/1292
[A[ATraining Step: 51  | total loss: [1m[32m0.70604[0m[0m | time: 130.179s
[2K
| RMSProp | epoch: 002 | loss: 0.70604 - acc: 0.5387 -- iter: 0320/1292
[A[ATraining Step: 52  | total loss: [1m[32m0.70340[0m[0m | time: 142.828s
[2K
| RMSProp | epoch: 002 | loss: 0.70340 - acc: 0.5423 -- iter: 0352/1292
[A[ATraining Step: 53  | total loss: [1m[32m0.69131[0m[0m | time: 155.396s
[2K
| RMSProp | epoch: 002 | loss: 0.69131 - acc: 0.5591 -- iter: 0384/1292
[A[ATraining Step: 54  | total loss: [1m[32m0.71720[0m[0m | time: 168.138s
[2K
| RMSProp | epoch: 002 | loss: 0.71720 - acc: 0.5279 -- iter: 0416/1292
[A[ATraining Step: 55  | total loss: [1m[32m0.70400[0m[0m | time: 180.766s
[2K
| RMSProp | epoch: 002 | loss: 0.70400 - acc: 0.5551 -- iter: 0448/1292
[A[ATraining Step: 56  | total loss: [1m[32m0.69794[0m[0m | time: 193.061s
[2K
| RMSProp | epoch: 002 | loss: 0.69794 - acc: 0.5606 -- iter: 0480/1292
[A[ATraining Step: 57  | total loss: [1m[32m0.69534[0m[0m | time: 219.357s
[2K
| RMSProp | epoch: 002 | loss: 0.69534 - acc: 0.5435 -- iter: 0512/1292
[A[ATraining Step: 58  | total loss: [1m[32m0.68101[0m[0m | time: 229.490s
[2K
| RMSProp | epoch: 002 | loss: 0.68101 - acc: 0.5717 -- iter: 0544/1292
[A[ATraining Step: 59  | total loss: [1m[32m0.67466[0m[0m | time: 260.725s
[2K
| RMSProp | epoch: 002 | loss: 0.67466 - acc: 0.5830 -- iter: 0576/1292
[A[ATraining Step: 60  | total loss: [1m[32m0.68055[0m[0m | time: 279.163s
[2K
| RMSProp | epoch: 002 | loss: 0.68055 - acc: 0.5803 -- iter: 0608/1292
[A[ATraining Step: 61  | total loss: [1m[32m0.68592[0m[0m | time: 291.397s
[2K
| RMSProp | epoch: 002 | loss: 0.68592 - acc: 0.5739 -- iter: 0640/1292
[A[ATraining Step: 62  | total loss: [1m[32m0.68501[0m[0m | time: 303.875s
[2K
| RMSProp | epoch: 002 | loss: 0.68501 - acc: 0.5684 -- iter: 0672/1292
[A[ATraining Step: 63  | total loss: [1m[32m0.68488[0m[0m | time: 314.431s
[2K
| RMSProp | epoch: 002 | loss: 0.68488 - acc: 0.5637 -- iter: 0704/1292
[A[ATraining Step: 64  | total loss: [1m[32m0.68523[0m[0m | time: 323.367s
[2K
| RMSProp | epoch: 002 | loss: 0.68523 - acc: 0.5792 -- iter: 0736/1292
[A[ATraining Step: 65  | total loss: [1m[32m0.68273[0m[0m | time: 332.206s
[2K
| RMSProp | epoch: 002 | loss: 0.68273 - acc: 0.5887 -- iter: 0768/1292
[A[ATraining Step: 66  | total loss: [1m[32m0.67595[0m[0m | time: 340.987s
[2K
| RMSProp | epoch: 002 | loss: 0.67595 - acc: 0.5969 -- iter: 0800/1292
[A[ATraining Step: 67  | total loss: [1m[32m0.68684[0m[0m | time: 355.369s
[2K
| RMSProp | epoch: 002 | loss: 0.68684 - acc: 0.5928 -- iter: 0832/1292
[A[ATraining Step: 68  | total loss: [1m[32m0.70303[0m[0m | time: 368.948s
[2K
| RMSProp | epoch: 002 | loss: 0.70303 - acc: 0.5707 -- iter: 0864/1292
[A[ATraining Step: 69  | total loss: [1m[32m0.70378[0m[0m | time: 377.458s
[2K
| RMSProp | epoch: 002 | loss: 0.70378 - acc: 0.5697 -- iter: 0896/1292
[A[ATraining Step: 70  | total loss: [1m[32m0.69496[0m[0m | time: 385.615s
[2K
| RMSProp | epoch: 002 | loss: 0.69496 - acc: 0.5833 -- iter: 0928/1292
[A[ATraining Step: 71  | total loss: [1m[32m0.70816[0m[0m | time: 393.616s
[2K
| RMSProp | epoch: 002 | loss: 0.70816 - acc: 0.5703 -- iter: 0960/1292
[A[ATraining Step: 72  | total loss: [1m[32m0.70127[0m[0m | time: 401.883s
[2K
| RMSProp | epoch: 002 | loss: 0.70127 - acc: 0.5764 -- iter: 0992/1292
[A[ATraining Step: 73  | total loss: [1m[32m0.68832[0m[0m | time: 410.037s
[2K
| RMSProp | epoch: 002 | loss: 0.68832 - acc: 0.5818 -- iter: 1024/1292
[A[ATraining Step: 74  | total loss: [1m[32m0.68462[0m[0m | time: 418.017s
[2K
| RMSProp | epoch: 002 | loss: 0.68462 - acc: 0.5831 -- iter: 1056/1292
[A[ATraining Step: 75  | total loss: [1m[32m0.67182[0m[0m | time: 426.074s
[2K
| RMSProp | epoch: 002 | loss: 0.67182 - acc: 0.5911 -- iter: 1088/1292
[A[ATraining Step: 76  | total loss: [1m[32m0.66438[0m[0m | time: 433.968s
[2K
| RMSProp | epoch: 002 | loss: 0.66438 - acc: 0.6014 -- iter: 1120/1292
[A[ATraining Step: 77  | total loss: [1m[32m0.66627[0m[0m | time: 442.226s
[2K
| RMSProp | epoch: 002 | loss: 0.66627 - acc: 0.6072 -- iter: 1152/1292
[A[ATraining Step: 78  | total loss: [1m[32m0.66208[0m[0m | time: 450.225s
[2K
| RMSProp | epoch: 002 | loss: 0.66208 - acc: 0.5993 -- iter: 1184/1292
[A[ATraining Step: 79  | total loss: [1m[32m0.65112[0m[0m | time: 458.261s
[2K
| RMSProp | epoch: 002 | loss: 0.65112 - acc: 0.6116 -- iter: 1216/1292
[A[ATraining Step: 80  | total loss: [1m[32m0.64050[0m[0m | time: 466.365s
[2K
| RMSProp | epoch: 002 | loss: 0.64050 - acc: 0.6290 -- iter: 1248/1292
[A[ATraining Step: 81  | total loss: [1m[32m0.62977[0m[0m | time: 474.561s
[2K
| RMSProp | epoch: 002 | loss: 0.62977 - acc: 0.6412 -- iter: 1280/1292
[A[ATraining Step: 82  | total loss: [1m[32m0.61703[0m[0m | time: 500.477s
[2K
| RMSProp | epoch: 002 | loss: 0.61703 - acc: 0.6552 | val_loss: 3.56532 - val_acc: 0.5136 -- iter: 1292/1292
--
Training Step: 83  | total loss: [1m[32m0.60060[0m[0m | time: 3.675s
[2K
| RMSProp | epoch: 003 | loss: 0.60060 - acc: 0.6678 -- iter: 0032/1292
[A[ATraining Step: 84  | total loss: [1m[32m0.59330[0m[0m | time: 7.289s
[2K
| RMSProp | epoch: 003 | loss: 0.59330 - acc: 0.6677 -- iter: 0064/1292
[A[ATraining Step: 85  | total loss: [1m[32m0.55609[0m[0m | time: 15.366s
[2K
| RMSProp | epoch: 003 | loss: 0.55609 - acc: 0.7009 -- iter: 0096/1292
[A[ATraining Step: 86  | total loss: [1m[32m0.55084[0m[0m | time: 23.730s
[2K
| RMSProp | epoch: 003 | loss: 0.55084 - acc: 0.7121 -- iter: 0128/1292
[A[ATraining Step: 87  | total loss: [1m[32m0.56005[0m[0m | time: 32.051s
[2K
| RMSProp | epoch: 003 | loss: 0.56005 - acc: 0.7221 -- iter: 0160/1292
[A[ATraining Step: 88  | total loss: [1m[32m0.58533[0m[0m | time: 40.588s
[2K
| RMSProp | epoch: 003 | loss: 0.58533 - acc: 0.6999 -- iter: 0192/1292
[A[ATraining Step: 89  | total loss: [1m[32m0.60518[0m[0m | time: 48.714s
[2K
| RMSProp | epoch: 003 | loss: 0.60518 - acc: 0.6924 -- iter: 0224/1292
[A[ATraining Step: 90  | total loss: [1m[32m0.62876[0m[0m | time: 57.073s
[2K
| RMSProp | epoch: 003 | loss: 0.62876 - acc: 0.6732 -- iter: 0256/1292
[A[ATraining Step: 91  | total loss: [1m[32m0.63825[0m[0m | time: 65.268s
[2K
| RMSProp | epoch: 003 | loss: 0.63825 - acc: 0.6621 -- iter: 0288/1292
[A[ATraining Step: 92  | total loss: [1m[32m0.64156[0m[0m | time: 73.358s
[2K
| RMSProp | epoch: 003 | loss: 0.64156 - acc: 0.6647 -- iter: 0320/1292
[A[ATraining Step: 93  | total loss: [1m[32m0.65233[0m[0m | time: 81.562s
[2K
| RMSProp | epoch: 003 | loss: 0.65233 - acc: 0.6638 -- iter: 0352/1292
[A[ATraining Step: 94  | total loss: [1m[32m0.65262[0m[0m | time: 89.838s
[2K
| RMSProp | epoch: 003 | loss: 0.65262 - acc: 0.6506 -- iter: 0384/1292
[A[ATraining Step: 95  | total loss: [1m[32m0.65226[0m[0m | time: 98.118s
[2K
| RMSProp | epoch: 003 | loss: 0.65226 - acc: 0.6449 -- iter: 0416/1292
[A[ATraining Step: 96  | total loss: [1m[32m0.64763[0m[0m | time: 106.330s
[2K
| RMSProp | epoch: 003 | loss: 0.64763 - acc: 0.6523 -- iter: 0448/1292
[A[ATraining Step: 97  | total loss: [1m[32m0.64210[0m[0m | time: 114.699s
[2K
| RMSProp | epoch: 003 | loss: 0.64210 - acc: 0.6620 -- iter: 0480/1292
[A[ATraining Step: 98  | total loss: [1m[32m0.61439[0m[0m | time: 122.863s
[2K
| RMSProp | epoch: 003 | loss: 0.61439 - acc: 0.6833 -- iter: 0512/1292
[A[ATraining Step: 99  | total loss: [1m[32m0.60420[0m[0m | time: 131.122s
[2K
| RMSProp | epoch: 003 | loss: 0.60420 - acc: 0.6900 -- iter: 0544/1292
[A[ATraining Step: 100  | total loss: [1m[32m0.63855[0m[0m | time: 139.325s
[2K
| RMSProp | epoch: 003 | loss: 0.63855 - acc: 0.6679 -- iter: 0576/1292
[A[ATraining Step: 101  | total loss: [1m[32m0.61850[0m[0m | time: 147.582s
[2K
| RMSProp | epoch: 003 | loss: 0.61850 - acc: 0.6823 -- iter: 0608/1292
[A[ATraining Step: 102  | total loss: [1m[32m0.61538[0m[0m | time: 155.838s
[2K
| RMSProp | epoch: 003 | loss: 0.61538 - acc: 0.6891 -- iter: 0640/1292
[A[ATraining Step: 103  | total loss: [1m[32m0.61342[0m[0m | time: 163.922s
[2K
| RMSProp | epoch: 003 | loss: 0.61342 - acc: 0.6858 -- iter: 0672/1292
[A[ATraining Step: 104  | total loss: [1m[32m0.62278[0m[0m | time: 172.112s
[2K
| RMSProp | epoch: 003 | loss: 0.62278 - acc: 0.6766 -- iter: 0704/1292
[A[ATraining Step: 105  | total loss: [1m[32m0.63927[0m[0m | time: 180.208s
[2K
| RMSProp | epoch: 003 | loss: 0.63927 - acc: 0.6652 -- iter: 0736/1292
[A[ATraining Step: 106  | total loss: [1m[32m0.63754[0m[0m | time: 188.445s
[2K
| RMSProp | epoch: 003 | loss: 0.63754 - acc: 0.6581 -- iter: 0768/1292
[A[ATraining Step: 107  | total loss: [1m[32m0.63815[0m[0m | time: 196.477s
[2K
| RMSProp | epoch: 003 | loss: 0.63815 - acc: 0.6704 -- iter: 0800/1292
[A[ATraining Step: 108  | total loss: [1m[32m0.63004[0m[0m | time: 204.799s
[2K
| RMSProp | epoch: 003 | loss: 0.63004 - acc: 0.6815 -- iter: 0832/1292
[A[ATraining Step: 109  | total loss: [1m[32m0.61709[0m[0m | time: 213.151s
[2K
| RMSProp | epoch: 003 | loss: 0.61709 - acc: 0.6883 -- iter: 0864/1292
[A[ATraining Step: 110  | total loss: [1m[32m0.60610[0m[0m | time: 221.319s
[2K
| RMSProp | epoch: 003 | loss: 0.60610 - acc: 0.6945 -- iter: 0896/1292
[A[ATraining Step: 111  | total loss: [1m[32m0.60674[0m[0m | time: 229.598s
[2K
| RMSProp | epoch: 003 | loss: 0.60674 - acc: 0.6969 -- iter: 0928/1292
[A[ATraining Step: 112  | total loss: [1m[32m0.62876[0m[0m | time: 237.827s
[2K
| RMSProp | epoch: 003 | loss: 0.62876 - acc: 0.6772 -- iter: 0960/1292
[A[ATraining Step: 113  | total loss: [1m[32m0.62565[0m[0m | time: 245.983s
[2K
| RMSProp | epoch: 003 | loss: 0.62565 - acc: 0.6751 -- iter: 0992/1292
[A[ATraining Step: 114  | total loss: [1m[32m0.61381[0m[0m | time: 254.228s
[2K
| RMSProp | epoch: 003 | loss: 0.61381 - acc: 0.6764 -- iter: 1024/1292
[A[ATraining Step: 115  | total loss: [1m[32m0.61631[0m[0m | time: 262.183s
[2K
| RMSProp | epoch: 003 | loss: 0.61631 - acc: 0.6775 -- iter: 1056/1292
[A[ATraining Step: 116  | total loss: [1m[32m0.62030[0m[0m | time: 270.298s
[2K
| RMSProp | epoch: 003 | loss: 0.62030 - acc: 0.6754 -- iter: 1088/1292
[A[ATraining Step: 117  | total loss: [1m[32m0.63900[0m[0m | time: 278.568s
[2K
| RMSProp | epoch: 003 | loss: 0.63900 - acc: 0.6578 -- iter: 1120/1292
[A[ATraining Step: 118  | total loss: [1m[32m0.65262[0m[0m | time: 286.771s
[2K
| RMSProp | epoch: 003 | loss: 0.65262 - acc: 0.6514 -- iter: 1152/1292
[A[ATraining Step: 119  | total loss: [1m[32m0.68472[0m[0m | time: 295.085s
[2K
| RMSProp | epoch: 003 | loss: 0.68472 - acc: 0.6425 -- iter: 1184/1292
[A[ATraining Step: 120  | total loss: [1m[32m0.67498[0m[0m | time: 303.218s
[2K
| RMSProp | epoch: 003 | loss: 0.67498 - acc: 0.6533 -- iter: 1216/1292
[A[ATraining Step: 121  | total loss: [1m[32m0.66327[0m[0m | time: 311.434s
[2K
| RMSProp | epoch: 003 | loss: 0.66327 - acc: 0.6567 -- iter: 1248/1292
[A[ATraining Step: 122  | total loss: [1m[32m0.64696[0m[0m | time: 319.457s
[2K
| RMSProp | epoch: 003 | loss: 0.64696 - acc: 0.6754 -- iter: 1280/1292
[A[ATraining Step: 123  | total loss: [1m[32m0.63304[0m[0m | time: 345.449s
[2K
| RMSProp | epoch: 003 | loss: 0.63304 - acc: 0.6829 | val_loss: 0.73220 - val_acc: 0.6765 -- iter: 1292/1292
--
Training Step: 124  | total loss: [1m[32m0.63927[0m[0m | time: 8.205s
[2K
| RMSProp | epoch: 004 | loss: 0.63927 - acc: 0.6802 -- iter: 0032/1292
[A[ATraining Step: 125  | total loss: [1m[32m0.65595[0m[0m | time: 11.832s
[2K
| RMSProp | epoch: 004 | loss: 0.65595 - acc: 0.6716 -- iter: 0064/1292
[A[ATraining Step: 126  | total loss: [1m[32m0.70079[0m[0m | time: 15.391s
[2K
| RMSProp | epoch: 004 | loss: 0.70079 - acc: 0.6544 -- iter: 0096/1292
[A[ATraining Step: 127  | total loss: [1m[32m0.67587[0m[0m | time: 23.455s
[2K
| RMSProp | epoch: 004 | loss: 0.67587 - acc: 0.6890 -- iter: 0128/1292
[A[ATraining Step: 128  | total loss: [1m[32m0.65672[0m[0m | time: 31.676s
[2K
| RMSProp | epoch: 004 | loss: 0.65672 - acc: 0.6951 -- iter: 0160/1292
[A[ATraining Step: 129  | total loss: [1m[32m0.65472[0m[0m | time: 39.962s
[2K
| RMSProp | epoch: 004 | loss: 0.65472 - acc: 0.6912 -- iter: 0192/1292
[A[ATraining Step: 130  | total loss: [1m[32m0.66399[0m[0m | time: 48.206s
[2K
| RMSProp | epoch: 004 | loss: 0.66399 - acc: 0.6783 -- iter: 0224/1292
[A[ATraining Step: 131  | total loss: [1m[32m0.64323[0m[0m | time: 56.414s
[2K
| RMSProp | epoch: 004 | loss: 0.64323 - acc: 0.6886 -- iter: 0256/1292
[A[ATraining Step: 132  | total loss: [1m[32m0.63291[0m[0m | time: 64.651s
[2K
| RMSProp | epoch: 004 | loss: 0.63291 - acc: 0.6947 -- iter: 0288/1292
[A[ATraining Step: 133  | total loss: [1m[32m0.63633[0m[0m | time: 72.690s
[2K
| RMSProp | epoch: 004 | loss: 0.63633 - acc: 0.6940 -- iter: 0320/1292
[A[ATraining Step: 134  | total loss: [1m[32m0.60736[0m[0m | time: 80.944s
[2K
| RMSProp | epoch: 004 | loss: 0.60736 - acc: 0.7090 -- iter: 0352/1292
[A[ATraining Step: 135  | total loss: [1m[32m0.57965[0m[0m | time: 89.165s
[2K
| RMSProp | epoch: 004 | loss: 0.57965 - acc: 0.7225 -- iter: 0384/1292
[A[ATraining Step: 136  | total loss: [1m[32m0.58386[0m[0m | time: 97.327s
[2K
| RMSProp | epoch: 004 | loss: 0.58386 - acc: 0.7190 -- iter: 0416/1292
[A[ATraining Step: 137  | total loss: [1m[32m0.58280[0m[0m | time: 105.648s
[2K
| RMSProp | epoch: 004 | loss: 0.58280 - acc: 0.7252 -- iter: 0448/1292
[A[ATraining Step: 138  | total loss: [1m[32m0.59144[0m[0m | time: 113.724s
[2K
| RMSProp | epoch: 004 | loss: 0.59144 - acc: 0.7183 -- iter: 0480/1292
[A[ATraining Step: 139  | total loss: [1m[32m0.58339[0m[0m | time: 121.777s
[2K
| RMSProp | epoch: 004 | loss: 0.58339 - acc: 0.7152 -- iter: 0512/1292
[A[ATraining Step: 140  | total loss: [1m[32m0.58014[0m[0m | time: 129.911s
[2K
| RMSProp | epoch: 004 | loss: 0.58014 - acc: 0.7187 -- iter: 0544/1292
[A[ATraining Step: 141  | total loss: [1m[32m0.56995[0m[0m | time: 138.004s
[2K
| RMSProp | epoch: 004 | loss: 0.56995 - acc: 0.7218 -- iter: 0576/1292
[A[ATraining Step: 142  | total loss: [1m[32m0.54643[0m[0m | time: 146.256s
[2K
| RMSProp | epoch: 004 | loss: 0.54643 - acc: 0.7371 -- iter: 0608/1292
[A[ATraining Step: 143  | total loss: [1m[32m0.56873[0m[0m | time: 154.379s
[2K
| RMSProp | epoch: 004 | loss: 0.56873 - acc: 0.7291 -- iter: 0640/1292
[A[ATraining Step: 144  | total loss: [1m[32m0.56793[0m[0m | time: 162.677s
[2K
| RMSProp | epoch: 004 | loss: 0.56793 - acc: 0.7280 -- iter: 0672/1292
[A[ATraining Step: 145  | total loss: [1m[32m0.55533[0m[0m | time: 170.613s
[2K
| RMSProp | epoch: 004 | loss: 0.55533 - acc: 0.7427 -- iter: 0704/1292
[A[ATraining Step: 146  | total loss: [1m[32m0.55390[0m[0m | time: 178.810s
[2K
| RMSProp | epoch: 004 | loss: 0.55390 - acc: 0.7403 -- iter: 0736/1292
[A[ATraining Step: 147  | total loss: [1m[32m0.55199[0m[0m | time: 186.835s
[2K
| RMSProp | epoch: 004 | loss: 0.55199 - acc: 0.7382 -- iter: 0768/1292
[A[ATraining Step: 148  | total loss: [1m[32m0.53510[0m[0m | time: 195.064s
[2K
| RMSProp | epoch: 004 | loss: 0.53510 - acc: 0.7456 -- iter: 0800/1292
[A[ATraining Step: 149  | total loss: [1m[32m0.53082[0m[0m | time: 203.162s
[2K
| RMSProp | epoch: 004 | loss: 0.53082 - acc: 0.7523 -- iter: 0832/1292
[A[ATraining Step: 150  | total loss: [1m[32m0.51169[0m[0m | time: 211.337s
[2K
| RMSProp | epoch: 004 | loss: 0.51169 - acc: 0.7583 -- iter: 0864/1292
[A[ATraining Step: 151  | total loss: [1m[32m0.53414[0m[0m | time: 219.511s
[2K
| RMSProp | epoch: 004 | loss: 0.53414 - acc: 0.7481 -- iter: 0896/1292
[A[ATraining Step: 152  | total loss: [1m[32m0.52472[0m[0m | time: 227.700s
[2K
| RMSProp | epoch: 004 | loss: 0.52472 - acc: 0.7545 -- iter: 0928/1292
[A[ATraining Step: 153  | total loss: [1m[32m0.56256[0m[0m | time: 235.960s
[2K
| RMSProp | epoch: 004 | loss: 0.56256 - acc: 0.7478 -- iter: 0960/1292
[A[ATraining Step: 154  | total loss: [1m[32m0.59322[0m[0m | time: 244.451s
[2K
| RMSProp | epoch: 004 | loss: 0.59322 - acc: 0.7262 -- iter: 0992/1292
[A[ATraining Step: 155  | total loss: [1m[32m0.57366[0m[0m | time: 252.681s
[2K
| RMSProp | epoch: 004 | loss: 0.57366 - acc: 0.7379 -- iter: 1024/1292
[A[ATraining Step: 156  | total loss: [1m[32m0.56948[0m[0m | time: 260.932s
[2K
| RMSProp | epoch: 004 | loss: 0.56948 - acc: 0.7423 -- iter: 1056/1292
[A[ATraining Step: 157  | total loss: [1m[32m0.56765[0m[0m | time: 269.284s
[2K
| RMSProp | epoch: 004 | loss: 0.56765 - acc: 0.7399 -- iter: 1088/1292
[A[ATraining Step: 158  | total loss: [1m[32m0.55668[0m[0m | time: 277.677s
[2K
| RMSProp | epoch: 004 | loss: 0.55668 - acc: 0.7409 -- iter: 1120/1292
[A[ATraining Step: 159  | total loss: [1m[32m0.55425[0m[0m | time: 285.708s
[2K
| RMSProp | epoch: 004 | loss: 0.55425 - acc: 0.7356 -- iter: 1152/1292
[A[ATraining Step: 160  | total loss: [1m[32m0.54925[0m[0m | time: 293.945s
[2K
| RMSProp | epoch: 004 | loss: 0.54925 - acc: 0.7308 -- iter: 1184/1292
[A[ATraining Step: 161  | total loss: [1m[32m0.53038[0m[0m | time: 302.050s
[2K
| RMSProp | epoch: 004 | loss: 0.53038 - acc: 0.7421 -- iter: 1216/1292
[A[ATraining Step: 162  | total loss: [1m[32m0.55799[0m[0m | time: 310.064s
[2K
| RMSProp | epoch: 004 | loss: 0.55799 - acc: 0.7272 -- iter: 1248/1292
[A[ATraining Step: 163  | total loss: [1m[32m0.57442[0m[0m | time: 318.175s
[2K
| RMSProp | epoch: 004 | loss: 0.57442 - acc: 0.7139 -- iter: 1280/1292
[A[ATraining Step: 164  | total loss: [1m[32m0.59116[0m[0m | time: 344.018s
[2K
| RMSProp | epoch: 004 | loss: 0.59116 - acc: 0.7081 | val_loss: 3.91503 - val_acc: 0.5136 -- iter: 1292/1292
--
Training Step: 165  | total loss: [1m[32m0.58526[0m[0m | time: 8.041s
[2K
| RMSProp | epoch: 005 | loss: 0.58526 - acc: 0.7248 -- iter: 0032/1292
[A[ATraining Step: 166  | total loss: [1m[32m0.58215[0m[0m | time: 16.306s
[2K
| RMSProp | epoch: 005 | loss: 0.58215 - acc: 0.7148 -- iter: 0064/1292
[A[ATraining Step: 167  | total loss: [1m[32m0.59895[0m[0m | time: 19.869s
[2K
| RMSProp | epoch: 005 | loss: 0.59895 - acc: 0.7058 -- iter: 0096/1292
[A[ATraining Step: 168  | total loss: [1m[32m0.56910[0m[0m | time: 23.394s
[2K
| RMSProp | epoch: 005 | loss: 0.56910 - acc: 0.7103 -- iter: 0128/1292
[A[ATraining Step: 169  | total loss: [1m[32m0.52836[0m[0m | time: 31.600s
[2K
| RMSProp | epoch: 005 | loss: 0.52836 - acc: 0.7392 -- iter: 0160/1292
[A[ATraining Step: 170  | total loss: [1m[32m0.52502[0m[0m | time: 39.799s
[2K
| RMSProp | epoch: 005 | loss: 0.52502 - acc: 0.7403 -- iter: 0192/1292
[A[ATraining Step: 171  | total loss: [1m[32m0.53107[0m[0m | time: 47.990s
[2K
| RMSProp | epoch: 005 | loss: 0.53107 - acc: 0.7413 -- iter: 0224/1292
[A[ATraining Step: 172  | total loss: [1m[32m0.56944[0m[0m | time: 56.209s
[2K
| RMSProp | epoch: 005 | loss: 0.56944 - acc: 0.7328 -- iter: 0256/1292
[A[ATraining Step: 173  | total loss: [1m[32m0.57180[0m[0m | time: 64.459s
[2K
| RMSProp | epoch: 005 | loss: 0.57180 - acc: 0.7189 -- iter: 0288/1292
[A[ATraining Step: 174  | total loss: [1m[32m0.54541[0m[0m | time: 72.443s
[2K
| RMSProp | epoch: 005 | loss: 0.54541 - acc: 0.7314 -- iter: 0320/1292
[A[ATraining Step: 175  | total loss: [1m[32m0.53076[0m[0m | time: 80.691s
[2K
| RMSProp | epoch: 005 | loss: 0.53076 - acc: 0.7364 -- iter: 0352/1292
[A[ATraining Step: 176  | total loss: [1m[32m0.52649[0m[0m | time: 88.891s
[2K
| RMSProp | epoch: 005 | loss: 0.52649 - acc: 0.7471 -- iter: 0384/1292
[A[ATraining Step: 177  | total loss: [1m[32m0.51066[0m[0m | time: 97.160s
[2K
| RMSProp | epoch: 005 | loss: 0.51066 - acc: 0.7536 -- iter: 0416/1292
[A[ATraining Step: 178  | total loss: [1m[32m0.50945[0m[0m | time: 105.269s
[2K
| RMSProp | epoch: 005 | loss: 0.50945 - acc: 0.7595 -- iter: 0448/1292
[A[ATraining Step: 179  | total loss: [1m[32m0.52093[0m[0m | time: 113.412s
[2K
| RMSProp | epoch: 005 | loss: 0.52093 - acc: 0.7586 -- iter: 0480/1292
[A[ATraining Step: 180  | total loss: [1m[32m0.51825[0m[0m | time: 121.529s
[2K
| RMSProp | epoch: 005 | loss: 0.51825 - acc: 0.7577 -- iter: 0512/1292
[A[ATraining Step: 181  | total loss: [1m[32m0.52228[0m[0m | time: 129.741s
[2K
| RMSProp | epoch: 005 | loss: 0.52228 - acc: 0.7601 -- iter: 0544/1292
[A[ATraining Step: 182  | total loss: [1m[32m0.49289[0m[0m | time: 137.964s
[2K
| RMSProp | epoch: 005 | loss: 0.49289 - acc: 0.7747 -- iter: 0576/1292
[A[ATraining Step: 183  | total loss: [1m[32m0.48427[0m[0m | time: 146.177s
[2K
| RMSProp | epoch: 005 | loss: 0.48427 - acc: 0.7785 -- iter: 0608/1292
[A[ATraining Step: 184  | total loss: [1m[32m0.47167[0m[0m | time: 154.243s
[2K
| RMSProp | epoch: 005 | loss: 0.47167 - acc: 0.7819 -- iter: 0640/1292
[A[ATraining Step: 185  | total loss: [1m[32m0.48997[0m[0m | time: 162.265s
[2K
| RMSProp | epoch: 005 | loss: 0.48997 - acc: 0.7724 -- iter: 0672/1292
[A[ATraining Step: 186  | total loss: [1m[32m0.47642[0m[0m | time: 170.500s
[2K
| RMSProp | epoch: 005 | loss: 0.47642 - acc: 0.7827 -- iter: 0704/1292
[A[ATraining Step: 187  | total loss: [1m[32m0.46670[0m[0m | time: 178.708s
[2K
| RMSProp | epoch: 005 | loss: 0.46670 - acc: 0.7857 -- iter: 0736/1292
[A[ATraining Step: 188  | total loss: [1m[32m0.51252[0m[0m | time: 186.861s
[2K
| RMSProp | epoch: 005 | loss: 0.51252 - acc: 0.7634 -- iter: 0768/1292
[A[ATraining Step: 189  | total loss: [1m[32m0.53838[0m[0m | time: 194.971s
[2K
| RMSProp | epoch: 005 | loss: 0.53838 - acc: 0.7526 -- iter: 0800/1292
[A[ATraining Step: 190  | total loss: [1m[32m0.53959[0m[0m | time: 202.870s
[2K
| RMSProp | epoch: 005 | loss: 0.53959 - acc: 0.7493 -- iter: 0832/1292
[A[ATraining Step: 191  | total loss: [1m[32m0.53120[0m[0m | time: 211.091s
[2K
| RMSProp | epoch: 005 | loss: 0.53120 - acc: 0.7525 -- iter: 0864/1292
[A[ATraining Step: 192  | total loss: [1m[32m0.52897[0m[0m | time: 219.364s
[2K
| RMSProp | epoch: 005 | loss: 0.52897 - acc: 0.7491 -- iter: 0896/1292
[A[ATraining Step: 193  | total loss: [1m[32m0.51659[0m[0m | time: 227.766s
[2K
| RMSProp | epoch: 005 | loss: 0.51659 - acc: 0.7585 -- iter: 0928/1292
[A[ATraining Step: 194  | total loss: [1m[32m0.54325[0m[0m | time: 235.895s
[2K
| RMSProp | epoch: 005 | loss: 0.54325 - acc: 0.7483 -- iter: 0960/1292
[A[ATraining Step: 195  | total loss: [1m[32m0.53913[0m[0m | time: 244.273s
[2K
| RMSProp | epoch: 005 | loss: 0.53913 - acc: 0.7454 -- iter: 0992/1292
[A[ATraining Step: 196  | total loss: [1m[32m0.53971[0m[0m | time: 252.376s
[2K
| RMSProp | epoch: 005 | loss: 0.53971 - acc: 0.7458 -- iter: 1024/1292
[A[ATraining Step: 197  | total loss: [1m[32m0.53125[0m[0m | time: 261.012s
[2K
| RMSProp | epoch: 005 | loss: 0.53125 - acc: 0.7556 -- iter: 1056/1292
[A[ATraining Step: 198  | total loss: [1m[32m0.51462[0m[0m | time: 269.469s
[2K
| RMSProp | epoch: 005 | loss: 0.51462 - acc: 0.7676 -- iter: 1088/1292
[A[ATraining Step: 199  | total loss: [1m[32m0.50129[0m[0m | time: 277.973s
[2K
| RMSProp | epoch: 005 | loss: 0.50129 - acc: 0.7752 -- iter: 1120/1292
[A[ATraining Step: 200  | total loss: [1m[32m0.49408[0m[0m | time: 304.368s
[2K
| RMSProp | epoch: 005 | loss: 0.49408 - acc: 0.7758 | val_loss: 7.19656 - val_acc: 0.5136 -- iter: 1152/1292
--
Training Step: 201  | total loss: [1m[32m0.48434[0m[0m | time: 345.440s
[2K
| RMSProp | epoch: 005 | loss: 0.48434 - acc: 0.7763 -- iter: 1184/1292
[A[ATraining Step: 202  | total loss: [1m[32m0.47146[0m[0m | time: 382.072s
[2K
| RMSProp | epoch: 005 | loss: 0.47146 - acc: 0.7862 -- iter: 1216/1292
[A[ATraining Step: 203  | total loss: [1m[32m0.45978[0m[0m | time: 403.505s
[2K
| RMSProp | epoch: 005 | loss: 0.45978 - acc: 0.7888 -- iter: 1248/1292
[A[ATraining Step: 204  | total loss: [1m[32m0.45666[0m[0m | time: 419.987s
[2K
| RMSProp | epoch: 005 | loss: 0.45666 - acc: 0.7881 -- iter: 1280/1292
[A[ATraining Step: 205  | total loss: [1m[32m0.42446[0m[0m | time: 468.743s
[2K
| RMSProp | epoch: 005 | loss: 0.42446 - acc: 0.8061 | val_loss: 4.96698 - val_acc: 0.5136 -- iter: 1292/1292
--
Training Step: 206  | total loss: [1m[32m0.41533[0m[0m | time: 10.868s
[2K
| RMSProp | epoch: 006 | loss: 0.41533 - acc: 0.8099 -- iter: 0032/1292
[A[ATraining Step: 207  | total loss: [1m[32m0.46048[0m[0m | time: 22.540s
[2K
| RMSProp | epoch: 006 | loss: 0.46048 - acc: 0.7883 -- iter: 0064/1292
[A[ATraining Step: 208  | total loss: [1m[32m0.47591[0m[0m | time: 31.853s
[2K
| RMSProp | epoch: 006 | loss: 0.47591 - acc: 0.7813 -- iter: 0096/1292
[A[ATraining Step: 209  | total loss: [1m[32m0.48174[0m[0m | time: 35.446s
[2K
| RMSProp | epoch: 006 | loss: 0.48174 - acc: 0.7719 -- iter: 0128/1292
[A[ATraining Step: 210  | total loss: [1m[32m0.47921[0m[0m | time: 39.134s
[2K
| RMSProp | epoch: 006 | loss: 0.47921 - acc: 0.7781 -- iter: 0160/1292
[A[ATraining Step: 211  | total loss: [1m[32m0.44293[0m[0m | time: 47.877s
[2K
| RMSProp | epoch: 006 | loss: 0.44293 - acc: 0.8003 -- iter: 0192/1292
[A[ATraining Step: 212  | total loss: [1m[32m0.45898[0m[0m | time: 56.374s
[2K
| RMSProp | epoch: 006 | loss: 0.45898 - acc: 0.8015 -- iter: 0224/1292
[A[ATraining Step: 213  | total loss: [1m[32m0.44849[0m[0m | time: 67.887s
[2K
| RMSProp | epoch: 006 | loss: 0.44849 - acc: 0.8026 -- iter: 0256/1292
[A[ATraining Step: 214  | total loss: [1m[32m0.43885[0m[0m | time: 154.739s
[2K
| RMSProp | epoch: 006 | loss: 0.43885 - acc: 0.8161 -- iter: 0288/1292
[A[ATraining Step: 215  | total loss: [1m[32m0.43939[0m[0m | time: 245.988s
[2K
| RMSProp | epoch: 006 | loss: 0.43939 - acc: 0.8157 -- iter: 0320/1292
[A[ATraining Step: 216  | total loss: [1m[32m0.43173[0m[0m | time: 276.847s
[2K
| RMSProp | epoch: 006 | loss: 0.43173 - acc: 0.8185 -- iter: 0352/1292
[A[ATraining Step: 217  | total loss: [1m[32m0.48167[0m[0m | time: 291.694s
[2K
| RMSProp | epoch: 006 | loss: 0.48167 - acc: 0.8054 -- iter: 0384/1292
[A[ATraining Step: 218  | total loss: [1m[32m0.46240[0m[0m | time: 310.930s
[2K
| RMSProp | epoch: 006 | loss: 0.46240 - acc: 0.8124 -- iter: 0416/1292
[A[ATraining Step: 219  | total loss: [1m[32m0.45299[0m[0m | time: 332.186s
[2K
| RMSProp | epoch: 006 | loss: 0.45299 - acc: 0.8155 -- iter: 0448/1292
[A[ATraining Step: 220  | total loss: [1m[32m0.45025[0m[0m | time: 399.985s
[2K
| RMSProp | epoch: 006 | loss: 0.45025 - acc: 0.8183 -- iter: 0480/1292
[A[ATraining Step: 221  | total loss: [1m[32m0.45483[0m[0m | time: 467.600s
[2K
| RMSProp | epoch: 006 | loss: 0.45483 - acc: 0.8146 -- iter: 0512/1292
[A[ATraining Step: 222  | total loss: [1m[32m0.46595[0m[0m | time: 599.536s
[2K
| RMSProp | epoch: 006 | loss: 0.46595 - acc: 0.7988 -- iter: 0544/1292
[A[ATraining Step: 223  | total loss: [1m[32m0.45844[0m[0m | time: 648.848s
[2K
| RMSProp | epoch: 006 | loss: 0.45844 - acc: 0.8033 -- iter: 0576/1292
[A[ATraining Step: 224  | total loss: [1m[32m0.44417[0m[0m | time: 687.125s
[2K
| RMSProp | epoch: 006 | loss: 0.44417 - acc: 0.8105 -- iter: 0608/1292
[A[ATraining Step: 225  | total loss: [1m[32m0.41830[0m[0m | time: 714.009s
[2K
| RMSProp | epoch: 006 | loss: 0.41830 - acc: 0.8263 -- iter: 0640/1292
[A[ATraining Step: 226  | total loss: [1m[32m0.42196[0m[0m | time: 729.484s
[2K
| RMSProp | epoch: 006 | loss: 0.42196 - acc: 0.8249 -- iter: 0672/1292
[A[ATraining Step: 227  | total loss: [1m[32m0.40648[0m[0m | time: 751.543s
[2K
| RMSProp | epoch: 006 | loss: 0.40648 - acc: 0.8362 -- iter: 0704/1292
[A[ATraining Step: 228  | total loss: [1m[32m0.39477[0m[0m | time: 777.867s
[2K
| RMSProp | epoch: 006 | loss: 0.39477 - acc: 0.8432 -- iter: 0736/1292
[A[ATraining Step: 229  | total loss: [1m[32m0.38617[0m[0m | time: 827.505s
[2K
| RMSProp | epoch: 006 | loss: 0.38617 - acc: 0.8495 -- iter: 0768/1292
[A[ATraining Step: 230  | total loss: [1m[32m0.38445[0m[0m | time: 909.495s
[2K
| RMSProp | epoch: 006 | loss: 0.38445 - acc: 0.8458 -- iter: 0800/1292
[A[ATraining Step: 231  | total loss: [1m[32m0.38422[0m[0m | time: 979.509s
[2K
| RMSProp | epoch: 006 | loss: 0.38422 - acc: 0.8425 -- iter: 0832/1292
[A[ATraining Step: 232  | total loss: [1m[32m0.40168[0m[0m | time: 1050.516s
[2K
| RMSProp | epoch: 006 | loss: 0.40168 - acc: 0.8332 -- iter: 0864/1292
[A[ATraining Step: 233  | total loss: [1m[32m0.41220[0m[0m | time: 1103.651s
[2K
| RMSProp | epoch: 006 | loss: 0.41220 - acc: 0.8280 -- iter: 0896/1292
[A[ATraining Step: 234  | total loss: [1m[32m0.41183[0m[0m | time: 1167.147s
[2K
| RMSProp | epoch: 006 | loss: 0.41183 - acc: 0.8265 -- iter: 0928/1292
[A[ATraining Step: 235  | total loss: [1m[32m0.40760[0m[0m | time: 1184.323s
[2K
| RMSProp | epoch: 006 | loss: 0.40760 - acc: 0.8251 -- iter: 0960/1292
[A[ATraining Step: 236  | total loss: [1m[32m0.43232[0m[0m | time: 1198.986s
[2K
| RMSProp | epoch: 006 | loss: 0.43232 - acc: 0.8144 -- iter: 0992/1292
[A[ATraining Step: 237  | total loss: [1m[32m0.43884[0m[0m | time: 1212.623s
[2K
| RMSProp | epoch: 006 | loss: 0.43884 - acc: 0.8111 -- iter: 1024/1292
[A[ATraining Step: 238  | total loss: [1m[32m0.42963[0m[0m | time: 1228.204s
[2K
| RMSProp | epoch: 006 | loss: 0.42963 - acc: 0.8113 -- iter: 1056/1292
[A[ATraining Step: 239  | total loss: [1m[32m0.43120[0m[0m | time: 1252.290s
[2K
| RMSProp | epoch: 006 | loss: 0.43120 - acc: 0.8051 -- iter: 1088/1292
[A[ATraining Step: 240  | total loss: [1m[32m0.42157[0m[0m | time: 1267.415s
[2K
| RMSProp | epoch: 006 | loss: 0.42157 - acc: 0.8184 -- iter: 1120/1292
[A[ATraining Step: 241  | total loss: [1m[32m0.43451[0m[0m | time: 1281.099s
[2K
| RMSProp | epoch: 006 | loss: 0.43451 - acc: 0.8053 -- iter: 1152/1292
[A[ATraining Step: 242  | total loss: [1m[32m0.45946[0m[0m | time: 1302.853s
[2K
| RMSProp | epoch: 006 | loss: 0.45946 - acc: 0.7873 -- iter: 1184/1292
[A[ATraining Step: 243  | total loss: [1m[32m0.46870[0m[0m | time: 1325.921s
[2K
| RMSProp | epoch: 006 | loss: 0.46870 - acc: 0.7835 -- iter: 1216/1292
[A[ATraining Step: 244  | total loss: [1m[32m0.46840[0m[0m | time: 1343.918s
[2K
| RMSProp | epoch: 006 | loss: 0.46840 - acc: 0.7802 -- iter: 1248/1292
[A[ATraining Step: 245  | total loss: [1m[32m0.45937[0m[0m | time: 1378.175s
[2K
| RMSProp | epoch: 006 | loss: 0.45937 - acc: 0.7834 -- iter: 1280/1292
[A[ATraining Step: 246  | total loss: [1m[32m0.43783[0m[0m | time: 1459.331s
[2K
| RMSProp | epoch: 006 | loss: 0.43783 - acc: 0.7926 | val_loss: 0.92488 - val_acc: 0.6568 -- iter: 1292/1292
--
Training Step: 247  | total loss: [1m[32m0.42308[0m[0m | time: 19.785s
[2K
| RMSProp | epoch: 007 | loss: 0.42308 - acc: 0.8008 -- iter: 0032/1292
[A[ATraining Step: 248  | total loss: [1m[32m0.43493[0m[0m | time: 39.041s
[2K
| RMSProp | epoch: 007 | loss: 0.43493 - acc: 0.7989 -- iter: 0064/1292
[A[ATraining Step: 249  | total loss: [1m[32m0.43593[0m[0m | time: 52.824s
[2K
| RMSProp | epoch: 007 | loss: 0.43593 - acc: 0.7971 -- iter: 0096/1292
[A[ATraining Step: 250  | total loss: [1m[32m0.42933[0m[0m | time: 68.248s
[2K
| RMSProp | epoch: 007 | loss: 0.42933 - acc: 0.7986 -- iter: 0128/1292
[A[ATraining Step: 251  | total loss: [1m[32m0.41854[0m[0m | time: 75.883s
[2K
| RMSProp | epoch: 007 | loss: 0.41854 - acc: 0.8031 -- iter: 0160/1292
[A[ATraining Step: 252  | total loss: [1m[32m0.41326[0m[0m | time: 82.315s
[2K
| RMSProp | epoch: 007 | loss: 0.41326 - acc: 0.8062 -- iter: 0192/1292
[A[ATraining Step: 253  | total loss: [1m[32m0.38084[0m[0m | time: 96.887s
[2K
| RMSProp | epoch: 007 | loss: 0.38084 - acc: 0.8255 -- iter: 0224/1292
[A[ATraining Step: 254  | total loss: [1m[32m0.38938[0m[0m | time: 115.621s
[2K
| RMSProp | epoch: 007 | loss: 0.38938 - acc: 0.8149 -- iter: 0256/1292
[A[ATraining Step: 255  | total loss: [1m[32m0.38913[0m[0m | time: 134.413s
[2K
| RMSProp | epoch: 007 | loss: 0.38913 - acc: 0.8178 -- iter: 0288/1292
[A[ATraining Step: 256  | total loss: [1m[32m0.37139[0m[0m | time: 152.124s
[2K
| RMSProp | epoch: 007 | loss: 0.37139 - acc: 0.8266 -- iter: 0320/1292
[A[ATraining Step: 257  | total loss: [1m[32m0.42450[0m[0m | time: 170.860s
[2K
| RMSProp | epoch: 007 | loss: 0.42450 - acc: 0.8189 -- iter: 0352/1292
[A[ATraining Step: 258  | total loss: [1m[32m0.43535[0m[0m | time: 189.987s
[2K
| RMSProp | epoch: 007 | loss: 0.43535 - acc: 0.8089 -- iter: 0384/1292
[A[ATraining Step: 259  | total loss: [1m[32m0.42984[0m[0m | time: 208.609s
[2K
| RMSProp | epoch: 007 | loss: 0.42984 - acc: 0.8030 -- iter: 0416/1292
[A[ATraining Step: 260  | total loss: [1m[32m0.42796[0m[0m | time: 227.972s
[2K
| RMSProp | epoch: 007 | loss: 0.42796 - acc: 0.8071 -- iter: 0448/1292
[A[ATraining Step: 261  | total loss: [1m[32m0.42537[0m[0m | time: 248.908s
[2K
| RMSProp | epoch: 007 | loss: 0.42537 - acc: 0.8076 -- iter: 0480/1292
[A[ATraining Step: 262  | total loss: [1m[32m0.41504[0m[0m | time: 268.209s
[2K
| RMSProp | epoch: 007 | loss: 0.41504 - acc: 0.8175 -- iter: 0512/1292
[A[ATraining Step: 263  | total loss: [1m[32m0.39861[0m[0m | time: 287.100s
[2K
| RMSProp | epoch: 007 | loss: 0.39861 - acc: 0.8264 -- iter: 0544/1292
[A[ATraining Step: 264  | total loss: [1m[32m0.38196[0m[0m | time: 305.536s
[2K
| RMSProp | epoch: 007 | loss: 0.38196 - acc: 0.8312 -- iter: 0576/1292
[A[ATraining Step: 265  | total loss: [1m[32m0.36632[0m[0m | time: 326.599s
[2K
| RMSProp | epoch: 007 | loss: 0.36632 - acc: 0.8419 -- iter: 0608/1292
[A[ATraining Step: 266  | total loss: [1m[32m0.35660[0m[0m | time: 341.711s
[2K
| RMSProp | epoch: 007 | loss: 0.35660 - acc: 0.8483 -- iter: 0640/1292
[A[ATraining Step: 267  | total loss: [1m[32m0.34589[0m[0m | time: 350.718s
[2K
| RMSProp | epoch: 007 | loss: 0.34589 - acc: 0.8541 -- iter: 0672/1292
[A[ATraining Step: 268  | total loss: [1m[32m0.36364[0m[0m | time: 361.155s
[2K
| RMSProp | epoch: 007 | loss: 0.36364 - acc: 0.8499 -- iter: 0704/1292
[A[ATraining Step: 269  | total loss: [1m[32m0.38526[0m[0m | time: 378.320s
[2K
| RMSProp | epoch: 007 | loss: 0.38526 - acc: 0.8462 -- iter: 0736/1292
[A[ATraining Step: 270  | total loss: [1m[32m0.37709[0m[0m | time: 398.557s
[2K
| RMSProp | epoch: 007 | loss: 0.37709 - acc: 0.8491 -- iter: 0768/1292
[A[ATraining Step: 271  | total loss: [1m[32m0.38853[0m[0m | time: 412.060s
[2K
| RMSProp | epoch: 007 | loss: 0.38853 - acc: 0.8454 -- iter: 0800/1292
[A[ATraining Step: 272  | total loss: [1m[32m0.36503[0m[0m | time: 424.933s
[2K
| RMSProp | epoch: 007 | loss: 0.36503 - acc: 0.8546 -- iter: 0832/1292
[A[ATraining Step: 273  | total loss: [1m[32m0.36577[0m[0m | time: 437.487s
[2K
| RMSProp | epoch: 007 | loss: 0.36577 - acc: 0.8535 -- iter: 0864/1292
[A[ATraining Step: 274  | total loss: [1m[32m0.36193[0m[0m | time: 451.286s
[2K
| RMSProp | epoch: 007 | loss: 0.36193 - acc: 0.8557 -- iter: 0896/1292
[A[ATraining Step: 275  | total loss: [1m[32m0.35915[0m[0m | time: 465.022s
[2K
| RMSProp | epoch: 007 | loss: 0.35915 - acc: 0.8576 -- iter: 0928/1292
[A[ATraining Step: 276  | total loss: [1m[32m0.34152[0m[0m | time: 479.370s
[2K
| RMSProp | epoch: 007 | loss: 0.34152 - acc: 0.8656 -- iter: 0960/1292
[A[ATraining Step: 277  | total loss: [1m[32m0.33255[0m[0m | time: 492.493s
[2K
| RMSProp | epoch: 007 | loss: 0.33255 - acc: 0.8697 -- iter: 0992/1292
[A[ATraining Step: 278  | total loss: [1m[32m0.34935[0m[0m | time: 505.820s
[2K
| RMSProp | epoch: 007 | loss: 0.34935 - acc: 0.8640 -- iter: 1024/1292
[A[ATraining Step: 279  | total loss: [1m[32m0.36209[0m[0m | time: 519.730s
[2K
| RMSProp | epoch: 007 | loss: 0.36209 - acc: 0.8557 -- iter: 1056/1292
[A[ATraining Step: 280  | total loss: [1m[32m0.34587[0m[0m | time: 533.290s
[2K
| RMSProp | epoch: 007 | loss: 0.34587 - acc: 0.8670 -- iter: 1088/1292
[A[ATraining Step: 281  | total loss: [1m[32m0.32637[0m[0m | time: 546.835s
[2K
| RMSProp | epoch: 007 | loss: 0.32637 - acc: 0.8772 -- iter: 1120/1292
[A[ATraining Step: 282  | total loss: [1m[32m0.34350[0m[0m | time: 555.577s
[2K
| RMSProp | epoch: 007 | loss: 0.34350 - acc: 0.8707 -- iter: 1152/1292
[A[ATraining Step: 283  | total loss: [1m[32m0.33168[0m[0m | time: 564.218s
[2K
| RMSProp | epoch: 007 | loss: 0.33168 - acc: 0.8711 -- iter: 1184/1292
[A[ATraining Step: 284  | total loss: [1m[32m0.35412[0m[0m | time: 573.168s
[2K
| RMSProp | epoch: 007 | loss: 0.35412 - acc: 0.8621 -- iter: 1216/1292
[A[ATraining Step: 285  | total loss: [1m[32m0.36219[0m[0m | time: 583.335s
[2K
| RMSProp | epoch: 007 | loss: 0.36219 - acc: 0.8603 -- iter: 1248/1292
[A[ATraining Step: 286  | total loss: [1m[32m0.38058[0m[0m | time: 596.827s
[2K
| RMSProp | epoch: 007 | loss: 0.38058 - acc: 0.8524 -- iter: 1280/1292
[A[ATraining Step: 287  | total loss: [1m[32m0.40361[0m[0m | time: 641.440s
[2K
| RMSProp | epoch: 007 | loss: 0.40361 - acc: 0.8390 | val_loss: 0.41682 - val_acc: 0.8444 -- iter: 1292/1292
--
Training Step: 288  | total loss: [1m[32m0.39954[0m[0m | time: 13.812s
[2K
| RMSProp | epoch: 008 | loss: 0.39954 - acc: 0.8364 -- iter: 0032/1292
[A[ATraining Step: 289  | total loss: [1m[32m0.39372[0m[0m | time: 26.945s
[2K
| RMSProp | epoch: 008 | loss: 0.39372 - acc: 0.8371 -- iter: 0064/1292
[A[ATraining Step: 290  | total loss: [1m[32m0.38217[0m[0m | time: 40.184s
[2K
| RMSProp | epoch: 008 | loss: 0.38217 - acc: 0.8409 -- iter: 0096/1292
[A[ATraining Step: 291  | total loss: [1m[32m0.38466[0m[0m | time: 53.007s
[2K
| RMSProp | epoch: 008 | loss: 0.38466 - acc: 0.8443 -- iter: 0128/1292
[A[ATraining Step: 292  | total loss: [1m[32m0.38549[0m[0m | time: 66.579s
[2K
| RMSProp | epoch: 008 | loss: 0.38549 - acc: 0.8349 -- iter: 0160/1292
[A[ATraining Step: 293  | total loss: [1m[32m0.39420[0m[0m | time: 71.595s
[2K
| RMSProp | epoch: 008 | loss: 0.39420 - acc: 0.8295 -- iter: 0192/1292
[A[ATraining Step: 294  | total loss: [1m[32m0.40453[0m[0m | time: 75.431s
[2K
| RMSProp | epoch: 008 | loss: 0.40453 - acc: 0.8299 -- iter: 0224/1292
[A[ATraining Step: 295  | total loss: [1m[32m0.37328[0m[0m | time: 84.155s
[2K
| RMSProp | epoch: 008 | loss: 0.37328 - acc: 0.8469 -- iter: 0256/1292
[A[ATraining Step: 296  | total loss: [1m[32m0.37762[0m[0m | time: 93.179s
[2K
| RMSProp | epoch: 008 | loss: 0.37762 - acc: 0.8466 -- iter: 0288/1292
[A[ATraining Step: 297  | total loss: [1m[32m0.36559[0m[0m | time: 106.015s
[2K
| RMSProp | epoch: 008 | loss: 0.36559 - acc: 0.8526 -- iter: 0320/1292
[A[ATraining Step: 298  | total loss: [1m[32m0.36732[0m[0m | time: 119.467s
[2K
| RMSProp | epoch: 008 | loss: 0.36732 - acc: 0.8517 -- iter: 0352/1292
[A[ATraining Step: 299  | total loss: [1m[32m0.36597[0m[0m | time: 132.552s
[2K
| RMSProp | epoch: 008 | loss: 0.36597 - acc: 0.8509 -- iter: 0384/1292
[A[ATraining Step: 300  | total loss: [1m[32m0.34518[0m[0m | time: 145.265s
[2K
| RMSProp | epoch: 008 | loss: 0.34518 - acc: 0.8595 -- iter: 0416/1292
[A[ATraining Step: 301  | total loss: [1m[32m0.32806[0m[0m | time: 158.540s
[2K
| RMSProp | epoch: 008 | loss: 0.32806 - acc: 0.8673 -- iter: 0448/1292
[A[ATraining Step: 302  | total loss: [1m[32m0.34013[0m[0m | time: 171.688s
[2K
| RMSProp | epoch: 008 | loss: 0.34013 - acc: 0.8681 -- iter: 0480/1292
[A[ATraining Step: 303  | total loss: [1m[32m0.33972[0m[0m | time: 184.729s
[2K
| RMSProp | epoch: 008 | loss: 0.33972 - acc: 0.8657 -- iter: 0512/1292
[A[ATraining Step: 304  | total loss: [1m[32m0.33854[0m[0m | time: 198.081s
[2K
| RMSProp | epoch: 008 | loss: 0.33854 - acc: 0.8697 -- iter: 0544/1292
[A[ATraining Step: 305  | total loss: [1m[32m0.34669[0m[0m | time: 211.574s
[2K
| RMSProp | epoch: 008 | loss: 0.34669 - acc: 0.8671 -- iter: 0576/1292
[A[ATraining Step: 306  | total loss: [1m[32m0.36011[0m[0m | time: 224.857s
[2K
| RMSProp | epoch: 008 | loss: 0.36011 - acc: 0.8554 -- iter: 0608/1292
[A[ATraining Step: 307  | total loss: [1m[32m0.36131[0m[0m | time: 237.982s
[2K
| RMSProp | epoch: 008 | loss: 0.36131 - acc: 0.8511 -- iter: 0640/1292
[A[ATraining Step: 308  | total loss: [1m[32m0.35596[0m[0m | time: 251.731s
[2K
| RMSProp | epoch: 008 | loss: 0.35596 - acc: 0.8535 -- iter: 0672/1292
[A[ATraining Step: 309  | total loss: [1m[32m0.35491[0m[0m | time: 265.372s
[2K
| RMSProp | epoch: 008 | loss: 0.35491 - acc: 0.8494 -- iter: 0704/1292
[A[ATraining Step: 310  | total loss: [1m[32m0.35063[0m[0m | time: 275.928s
[2K
| RMSProp | epoch: 008 | loss: 0.35063 - acc: 0.8582 -- iter: 0736/1292
[A[ATraining Step: 311  | total loss: [1m[32m0.33772[0m[0m | time: 284.592s
[2K
| RMSProp | epoch: 008 | loss: 0.33772 - acc: 0.8661 -- iter: 0768/1292
[A[ATraining Step: 312  | total loss: [1m[32m0.32380[0m[0m | time: 293.085s
[2K
| RMSProp | epoch: 008 | loss: 0.32380 - acc: 0.8733 -- iter: 0800/1292
[A[ATraining Step: 313  | total loss: [1m[32m0.30819[0m[0m | time: 301.729s
[2K
| RMSProp | epoch: 008 | loss: 0.30819 - acc: 0.8828 -- iter: 0832/1292
[A[ATraining Step: 314  | total loss: [1m[32m0.30784[0m[0m | time: 315.326s
[2K
| RMSProp | epoch: 008 | loss: 0.30784 - acc: 0.8789 -- iter: 0864/1292
[A[ATraining Step: 315  | total loss: [1m[32m0.29830[0m[0m | time: 328.860s
[2K
| RMSProp | epoch: 008 | loss: 0.29830 - acc: 0.8848 -- iter: 0896/1292
[A[ATraining Step: 316  | total loss: [1m[32m0.28539[0m[0m | time: 341.715s
[2K
| RMSProp | epoch: 008 | loss: 0.28539 - acc: 0.8901 -- iter: 0928/1292
[A[ATraining Step: 317  | total loss: [1m[32m0.28203[0m[0m | time: 355.105s
[2K
| RMSProp | epoch: 008 | loss: 0.28203 - acc: 0.8885 -- iter: 0960/1292
[A[ATraining Step: 318  | total loss: [1m[32m0.26677[0m[0m | time: 368.437s
[2K
| RMSProp | epoch: 008 | loss: 0.26677 - acc: 0.8934 -- iter: 0992/1292
[A[ATraining Step: 319  | total loss: [1m[32m0.25932[0m[0m | time: 381.755s
[2K
| RMSProp | epoch: 008 | loss: 0.25932 - acc: 0.8947 -- iter: 1024/1292
[A[ATraining Step: 320  | total loss: [1m[32m0.26891[0m[0m | time: 394.959s
[2K
| RMSProp | epoch: 008 | loss: 0.26891 - acc: 0.8896 -- iter: 1056/1292
[A[ATraining Step: 321  | total loss: [1m[32m0.28188[0m[0m | time: 408.562s
[2K
| RMSProp | epoch: 008 | loss: 0.28188 - acc: 0.8850 -- iter: 1088/1292
[A[ATraining Step: 322  | total loss: [1m[32m0.27201[0m[0m | time: 422.749s
[2K
| RMSProp | epoch: 008 | loss: 0.27201 - acc: 0.8903 -- iter: 1120/1292
[A[ATraining Step: 323  | total loss: [1m[32m0.26749[0m[0m | time: 435.775s
[2K
| RMSProp | epoch: 008 | loss: 0.26749 - acc: 0.8919 -- iter: 1152/1292
[A[ATraining Step: 324  | total loss: [1m[32m0.26477[0m[0m | time: 449.006s
[2K
| RMSProp | epoch: 008 | loss: 0.26477 - acc: 0.8933 -- iter: 1184/1292
[A[ATraining Step: 325  | total loss: [1m[32m0.25284[0m[0m | time: 461.927s
[2K
| RMSProp | epoch: 008 | loss: 0.25284 - acc: 0.8977 -- iter: 1216/1292
[A[ATraining Step: 326  | total loss: [1m[32m0.25295[0m[0m | time: 475.334s
[2K
| RMSProp | epoch: 008 | loss: 0.25295 - acc: 0.8986 -- iter: 1248/1292
[A[ATraining Step: 327  | total loss: [1m[32m0.25749[0m[0m | time: 484.917s
[2K
| RMSProp | epoch: 008 | loss: 0.25749 - acc: 0.8962 -- iter: 1280/1292
[A[ATraining Step: 328  | total loss: [1m[32m0.26188[0m[0m | time: 513.783s
[2K
| RMSProp | epoch: 008 | loss: 0.26188 - acc: 0.8941 | val_loss: 0.99308 - val_acc: 0.7383 -- iter: 1292/1292
--
Training Step: 329  | total loss: [1m[32m0.26215[0m[0m | time: 13.427s
[2K
| RMSProp | epoch: 009 | loss: 0.26215 - acc: 0.8922 -- iter: 0032/1292
[A[ATraining Step: 330  | total loss: [1m[32m0.25813[0m[0m | time: 26.649s
[2K
| RMSProp | epoch: 009 | loss: 0.25813 - acc: 0.8936 -- iter: 0064/1292
[A[ATraining Step: 331  | total loss: [1m[32m0.26079[0m[0m | time: 39.616s
[2K
| RMSProp | epoch: 009 | loss: 0.26079 - acc: 0.8886 -- iter: 0096/1292
[A[ATraining Step: 332  | total loss: [1m[32m0.26064[0m[0m | time: 52.359s
[2K
| RMSProp | epoch: 009 | loss: 0.26064 - acc: 0.8873 -- iter: 0128/1292
[A[ATraining Step: 333  | total loss: [1m[32m0.24632[0m[0m | time: 65.526s
[2K
| RMSProp | epoch: 009 | loss: 0.24632 - acc: 0.8954 -- iter: 0160/1292
[A[ATraining Step: 334  | total loss: [1m[32m0.24837[0m[0m | time: 78.549s
[2K
| RMSProp | epoch: 009 | loss: 0.24837 - acc: 0.8902 -- iter: 0192/1292
[A[ATraining Step: 335  | total loss: [1m[32m0.23708[0m[0m | time: 84.746s
[2K
| RMSProp | epoch: 009 | loss: 0.23708 - acc: 0.8981 -- iter: 0224/1292
[A[ATraining Step: 336  | total loss: [1m[32m0.23681[0m[0m | time: 91.039s
[2K
| RMSProp | epoch: 009 | loss: 0.23681 - acc: 0.8833 -- iter: 0256/1292
[A[ATraining Step: 337  | total loss: [1m[32m0.21800[0m[0m | time: 104.180s
[2K
| RMSProp | epoch: 009 | loss: 0.21800 - acc: 0.8950 -- iter: 0288/1292
[A[ATraining Step: 338  | total loss: [1m[32m0.25896[0m[0m | time: 117.617s
[2K
| RMSProp | epoch: 009 | loss: 0.25896 - acc: 0.8930 -- iter: 0320/1292
[A[ATraining Step: 339  | total loss: [1m[32m0.26059[0m[0m | time: 131.207s
[2K
| RMSProp | epoch: 009 | loss: 0.26059 - acc: 0.8912 -- iter: 0352/1292
[A[ATraining Step: 340  | total loss: [1m[32m0.27794[0m[0m | time: 144.037s
[2K
| RMSProp | epoch: 009 | loss: 0.27794 - acc: 0.8833 -- iter: 0384/1292
[A[ATraining Step: 341  | total loss: [1m[32m0.30708[0m[0m | time: 152.537s
[2K
| RMSProp | epoch: 009 | loss: 0.30708 - acc: 0.8793 -- iter: 0416/1292
[A[ATraining Step: 342  | total loss: [1m[32m0.31744[0m[0m | time: 161.220s
[2K
| RMSProp | epoch: 009 | loss: 0.31744 - acc: 0.8664 -- iter: 0448/1292
[A[ATraining Step: 343  | total loss: [1m[32m0.31208[0m[0m | time: 174.698s
[2K
| RMSProp | epoch: 009 | loss: 0.31208 - acc: 0.8735 -- iter: 0480/1292
[A[ATraining Step: 344  | total loss: [1m[32m0.30970[0m[0m | time: 188.238s
[2K
| RMSProp | epoch: 009 | loss: 0.30970 - acc: 0.8768 -- iter: 0512/1292
[A[ATraining Step: 345  | total loss: [1m[32m0.30920[0m[0m | time: 201.355s
[2K
| RMSProp | epoch: 009 | loss: 0.30920 - acc: 0.8766 -- iter: 0544/1292
[A[ATraining Step: 346  | total loss: [1m[32m0.29106[0m[0m | time: 214.071s
[2K
| RMSProp | epoch: 009 | loss: 0.29106 - acc: 0.8858 -- iter: 0576/1292
[A[ATraining Step: 347  | total loss: [1m[32m0.28700[0m[0m | time: 226.958s
[2K
| RMSProp | epoch: 009 | loss: 0.28700 - acc: 0.8879 -- iter: 0608/1292
[A[ATraining Step: 348  | total loss: [1m[32m0.30018[0m[0m | time: 240.264s
[2K
| RMSProp | epoch: 009 | loss: 0.30018 - acc: 0.8835 -- iter: 0640/1292
[A[ATraining Step: 349  | total loss: [1m[32m0.30242[0m[0m | time: 253.681s
[2K
| RMSProp | epoch: 009 | loss: 0.30242 - acc: 0.8826 -- iter: 0672/1292
[A[ATraining Step: 350  | total loss: [1m[32m0.28034[0m[0m | time: 267.029s
[2K
| RMSProp | epoch: 009 | loss: 0.28034 - acc: 0.8943 -- iter: 0704/1292
[A[ATraining Step: 351  | total loss: [1m[32m0.27010[0m[0m | time: 280.496s
[2K
| RMSProp | epoch: 009 | loss: 0.27010 - acc: 0.8987 -- iter: 0736/1292
[A[ATraining Step: 352  | total loss: [1m[32m0.25602[0m[0m | time: 293.713s
[2K
| RMSProp | epoch: 009 | loss: 0.25602 - acc: 0.9057 -- iter: 0768/1292
[A[ATraining Step: 353  | total loss: [1m[32m0.23778[0m[0m | time: 307.390s
[2K
| RMSProp | epoch: 009 | loss: 0.23778 - acc: 0.9151 -- iter: 0800/1292
[A[ATraining Step: 354  | total loss: [1m[32m0.22929[0m[0m | time: 320.346s
[2K
| RMSProp | epoch: 009 | loss: 0.22929 - acc: 0.9173 -- iter: 0832/1292
[A[ATraining Step: 355  | total loss: [1m[32m0.22178[0m[0m | time: 333.448s
[2K
| RMSProp | epoch: 009 | loss: 0.22178 - acc: 0.9194 -- iter: 0864/1292
[A[ATraining Step: 356  | total loss: [1m[32m0.20933[0m[0m | time: 344.340s
[2K
| RMSProp | epoch: 009 | loss: 0.20933 - acc: 0.9243 -- iter: 0896/1292
[A[ATraining Step: 357  | total loss: [1m[32m0.19715[0m[0m | time: 352.954s
[2K
| RMSProp | epoch: 009 | loss: 0.19715 - acc: 0.9287 -- iter: 0928/1292
[A[ATraining Step: 358  | total loss: [1m[32m0.19088[0m[0m | time: 361.683s
[2K
| RMSProp | epoch: 009 | loss: 0.19088 - acc: 0.9327 -- iter: 0960/1292
[A[ATraining Step: 359  | total loss: [1m[32m0.21073[0m[0m | time: 373.752s
[2K
| RMSProp | epoch: 009 | loss: 0.21073 - acc: 0.9270 -- iter: 0992/1292
[A[ATraining Step: 360  | total loss: [1m[32m0.19873[0m[0m | time: 387.409s
[2K
| RMSProp | epoch: 009 | loss: 0.19873 - acc: 0.9311 -- iter: 1024/1292
[A[ATraining Step: 361  | total loss: [1m[32m0.18622[0m[0m | time: 400.586s
[2K
| RMSProp | epoch: 009 | loss: 0.18622 - acc: 0.9349 -- iter: 1056/1292
[A[ATraining Step: 362  | total loss: [1m[32m0.17390[0m[0m | time: 414.272s
[2K
| RMSProp | epoch: 009 | loss: 0.17390 - acc: 0.9383 -- iter: 1088/1292
[A[ATraining Step: 363  | total loss: [1m[32m0.21080[0m[0m | time: 427.543s
[2K
| RMSProp | epoch: 009 | loss: 0.21080 - acc: 0.9257 -- iter: 1120/1292
[A[ATraining Step: 364  | total loss: [1m[32m0.21724[0m[0m | time: 440.449s
[2K
| RMSProp | epoch: 009 | loss: 0.21724 - acc: 0.9269 -- iter: 1152/1292
[A[ATraining Step: 365  | total loss: [1m[32m0.22888[0m[0m | time: 453.922s
[2K
| RMSProp | epoch: 009 | loss: 0.22888 - acc: 0.9186 -- iter: 1184/1292
[A[ATraining Step: 366  | total loss: [1m[32m0.25350[0m[0m | time: 467.374s
[2K
| RMSProp | epoch: 009 | loss: 0.25350 - acc: 0.9017 -- iter: 1216/1292
[A[ATraining Step: 367  | total loss: [1m[32m0.24794[0m[0m | time: 480.634s
[2K
| RMSProp | epoch: 009 | loss: 0.24794 - acc: 0.9053 -- iter: 1248/1292
[A[ATraining Step: 368  | total loss: [1m[32m0.26798[0m[0m | time: 494.452s
[2K
| RMSProp | epoch: 009 | loss: 0.26798 - acc: 0.8898 -- iter: 1280/1292
[A[ATraining Step: 369  | total loss: [1m[32m0.28828[0m[0m | time: 538.656s
[2K
| RMSProp | epoch: 009 | loss: 0.28828 - acc: 0.8820 | val_loss: 2.24084 - val_acc: 0.5580 -- iter: 1292/1292
--
Training Step: 370  | total loss: [1m[32m0.29682[0m[0m | time: 9.726s
[2K
| RMSProp | epoch: 010 | loss: 0.29682 - acc: 0.8813 -- iter: 0032/1292
[A[ATraining Step: 371  | total loss: [1m[32m0.29003[0m[0m | time: 22.948s
[2K
| RMSProp | epoch: 010 | loss: 0.29003 - acc: 0.8838 -- iter: 0064/1292
[A[ATraining Step: 372  | total loss: [1m[32m0.28655[0m[0m | time: 36.240s
[2K
| RMSProp | epoch: 010 | loss: 0.28655 - acc: 0.8892 -- iter: 0096/1292
[A[ATraining Step: 373  | total loss: [1m[32m0.28224[0m[0m | time: 49.524s
[2K
| RMSProp | epoch: 010 | loss: 0.28224 - acc: 0.8878 -- iter: 0128/1292
[A[ATraining Step: 374  | total loss: [1m[32m0.27965[0m[0m | time: 62.349s
[2K
| RMSProp | epoch: 010 | loss: 0.27965 - acc: 0.8896 -- iter: 0160/1292
[A[ATraining Step: 375  | total loss: [1m[32m0.26524[0m[0m | time: 75.679s
[2K
| RMSProp | epoch: 010 | loss: 0.26524 - acc: 0.8975 -- iter: 0192/1292
[A[ATraining Step: 376  | total loss: [1m[32m0.26758[0m[0m | time: 89.426s
[2K
| RMSProp | epoch: 010 | loss: 0.26758 - acc: 0.8953 -- iter: 0224/1292
[A[ATraining Step: 377  | total loss: [1m[32m0.25776[0m[0m | time: 95.508s
[2K
| RMSProp | epoch: 010 | loss: 0.25776 - acc: 0.8995 -- iter: 0256/1292
[A[ATraining Step: 378  | total loss: [1m[32m0.26687[0m[0m | time: 101.788s
[2K
| RMSProp | epoch: 010 | loss: 0.26687 - acc: 0.8929 -- iter: 0288/1292
[A[ATraining Step: 379  | total loss: [1m[32m0.24313[0m[0m | time: 115.481s
[2K
| RMSProp | epoch: 010 | loss: 0.24313 - acc: 0.9036 -- iter: 0320/1292
[A[ATraining Step: 380  | total loss: [1m[32m0.22901[0m[0m | time: 128.561s
[2K
| RMSProp | epoch: 010 | loss: 0.22901 - acc: 0.9101 -- iter: 0352/1292
[A[ATraining Step: 381  | total loss: [1m[32m0.21199[0m[0m | time: 141.568s
[2K
| RMSProp | epoch: 010 | loss: 0.21199 - acc: 0.9191 -- iter: 0384/1292
[A[ATraining Step: 382  | total loss: [1m[32m0.22308[0m[0m | time: 154.673s
[2K
| RMSProp | epoch: 010 | loss: 0.22308 - acc: 0.9178 -- iter: 0416/1292
[A[ATraining Step: 383  | total loss: [1m[32m0.23337[0m[0m | time: 167.885s
[2K
| RMSProp | epoch: 010 | loss: 0.23337 - acc: 0.9167 -- iter: 0448/1292
[A[ATraining Step: 384  | total loss: [1m[32m0.24299[0m[0m | time: 181.634s
[2K
| RMSProp | epoch: 010 | loss: 0.24299 - acc: 0.9125 -- iter: 0480/1292
[A[ATraining Step: 385  | total loss: [1m[32m0.23464[0m[0m | time: 190.421s
[2K
| RMSProp | epoch: 010 | loss: 0.23464 - acc: 0.9181 -- iter: 0512/1292
[A[ATraining Step: 386  | total loss: [1m[32m0.22594[0m[0m | time: 199.152s
[2K
| RMSProp | epoch: 010 | loss: 0.22594 - acc: 0.9201 -- iter: 0544/1292
[A[ATraining Step: 387  | total loss: [1m[32m0.22045[0m[0m | time: 209.578s
[2K
| RMSProp | epoch: 010 | loss: 0.22045 - acc: 0.9218 -- iter: 0576/1292
[A[ATraining Step: 388  | total loss: [1m[32m0.25417[0m[0m | time: 222.691s
[2K
| RMSProp | epoch: 010 | loss: 0.25417 - acc: 0.9234 -- iter: 0608/1292
[A[ATraining Step: 389  | total loss: [1m[32m0.24059[0m[0m | time: 235.870s
[2K
| RMSProp | epoch: 010 | loss: 0.24059 - acc: 0.9279 -- iter: 0640/1292
[A[ATraining Step: 390  | total loss: [1m[32m0.23965[0m[0m | time: 249.690s
[2K
| RMSProp | epoch: 010 | loss: 0.23965 - acc: 0.9257 -- iter: 0672/1292
[A[ATraining Step: 391  | total loss: [1m[32m0.22517[0m[0m | time: 262.471s
[2K
| RMSProp | epoch: 010 | loss: 0.22517 - acc: 0.9269 -- iter: 0704/1292
[A[ATraining Step: 392  | total loss: [1m[32m0.22719[0m[0m | time: 276.078s
[2K
| RMSProp | epoch: 010 | loss: 0.22719 - acc: 0.9249 -- iter: 0736/1292
[A[ATraining Step: 393  | total loss: [1m[32m0.21737[0m[0m | time: 289.516s
[2K
| RMSProp | epoch: 010 | loss: 0.21737 - acc: 0.9261 -- iter: 0768/1292
[A[ATraining Step: 394  | total loss: [1m[32m0.21554[0m[0m | time: 303.121s
[2K
| RMSProp | epoch: 010 | loss: 0.21554 - acc: 0.9241 -- iter: 0800/1292
[A[ATraining Step: 395  | total loss: [1m[32m0.21441[0m[0m | time: 316.228s
[2K
| RMSProp | epoch: 010 | loss: 0.21441 - acc: 0.9223 -- iter: 0832/1292
[A[ATraining Step: 396  | total loss: [1m[32m0.21109[0m[0m | time: 328.902s
[2K
| RMSProp | epoch: 010 | loss: 0.21109 - acc: 0.9239 -- iter: 0864/1292
[A[ATraining Step: 397  | total loss: [1m[32m0.20160[0m[0m | time: 342.096s
[2K
| RMSProp | epoch: 010 | loss: 0.20160 - acc: 0.9283 -- iter: 0896/1292
[A[ATraining Step: 398  | total loss: [1m[32m0.18673[0m[0m | time: 354.896s
[2K
| RMSProp | epoch: 010 | loss: 0.18673 - acc: 0.9355 -- iter: 0928/1292
[A[ATraining Step: 399  | total loss: [1m[32m0.18676[0m[0m | time: 367.894s
[2K
| RMSProp | epoch: 010 | loss: 0.18676 - acc: 0.9357 -- iter: 0960/1292
[A[ATraining Step: 400  | total loss: [1m[32m0.18088[0m[0m | time: 400.643s
[2K
| RMSProp | epoch: 010 | loss: 0.18088 - acc: 0.9390 | val_loss: 0.38876 - val_acc: 0.8642 -- iter: 0992/1292
--
Training Step: 401  | total loss: [1m[32m0.18181[0m[0m | time: 413.894s
[2K
| RMSProp | epoch: 010 | loss: 0.18181 - acc: 0.9389 -- iter: 1024/1292
[A[ATraining Step: 402  | total loss: [1m[32m0.18661[0m[0m | time: 427.568s
[2K
| RMSProp | epoch: 010 | loss: 0.18661 - acc: 0.9356 -- iter: 1056/1292
[A[ATraining Step: 403  | total loss: [1m[32m0.19511[0m[0m | time: 441.003s
[2K
| RMSProp | epoch: 010 | loss: 0.19511 - acc: 0.9264 -- iter: 1088/1292
[A[ATraining Step: 404  | total loss: [1m[32m0.20046[0m[0m | time: 454.934s
[2K
| RMSProp | epoch: 010 | loss: 0.20046 - acc: 0.9275 -- iter: 1120/1292
[A[ATraining Step: 405  | total loss: [1m[32m0.19801[0m[0m | time: 468.502s
[2K
| RMSProp | epoch: 010 | loss: 0.19801 - acc: 0.9285 -- iter: 1152/1292
[A[ATraining Step: 406  | total loss: [1m[32m0.18274[0m[0m | time: 481.655s
[2K
| RMSProp | epoch: 010 | loss: 0.18274 - acc: 0.9357 -- iter: 1184/1292
[A[ATraining Step: 407  | total loss: [1m[32m0.18785[0m[0m | time: 494.308s
[2K
| RMSProp | epoch: 010 | loss: 0.18785 - acc: 0.9359 -- iter: 1216/1292
[A[ATraining Step: 408  | total loss: [1m[32m0.25834[0m[0m | time: 507.335s
[2K
| RMSProp | epoch: 010 | loss: 0.25834 - acc: 0.9110 -- iter: 1248/1292
[A[ATraining Step: 409  | total loss: [1m[32m0.27621[0m[0m | time: 520.428s
[2K
| RMSProp | epoch: 010 | loss: 0.27621 - acc: 0.9043 -- iter: 1280/1292
[A[ATraining Step: 410  | total loss: [1m[32m0.26226[0m[0m | time: 558.371s
[2K
| RMSProp | epoch: 010 | loss: 0.26226 - acc: 0.9076 | val_loss: 0.41658 - val_acc: 0.8642 -- iter: 1292/1292
--
Training Step: 411  | total loss: [1m[32m0.25394[0m[0m | time: 12.676s
[2K
| RMSProp | epoch: 011 | loss: 0.25394 - acc: 0.9106 -- iter: 0032/1292
[A[ATraining Step: 412  | total loss: [1m[32m0.24500[0m[0m | time: 25.505s
[2K
| RMSProp | epoch: 011 | loss: 0.24500 - acc: 0.9102 -- iter: 0064/1292
[A[ATraining Step: 413  | total loss: [1m[32m0.22640[0m[0m | time: 38.733s
[2K
| RMSProp | epoch: 011 | loss: 0.22640 - acc: 0.9191 -- iter: 0096/1292
[A[ATraining Step: 414  | total loss: [1m[32m0.20838[0m[0m | time: 52.028s
[2K
| RMSProp | epoch: 011 | loss: 0.20838 - acc: 0.9272 -- iter: 0128/1292
[A[ATraining Step: 415  | total loss: [1m[32m0.20077[0m[0m | time: 65.225s
[2K
| RMSProp | epoch: 011 | loss: 0.20077 - acc: 0.9283 -- iter: 0160/1292
[A[ATraining Step: 416  | total loss: [1m[32m0.21267[0m[0m | time: 78.611s
[2K
| RMSProp | epoch: 011 | loss: 0.21267 - acc: 0.9261 -- iter: 0192/1292
[A[ATraining Step: 417  | total loss: [1m[32m0.20098[0m[0m | time: 92.841s
[2K
| RMSProp | epoch: 011 | loss: 0.20098 - acc: 0.9303 -- iter: 0224/1292
[A[ATraining Step: 418  | total loss: [1m[32m0.22920[0m[0m | time: 106.687s
[2K
| RMSProp | epoch: 011 | loss: 0.22920 - acc: 0.9123 -- iter: 0256/1292
[A[ATraining Step: 419  | total loss: [1m[32m0.23600[0m[0m | time: 112.213s
[2K
| RMSProp | epoch: 011 | loss: 0.23600 - acc: 0.9054 -- iter: 0288/1292
[A[ATraining Step: 420  | total loss: [1m[32m0.27017[0m[0m | time: 118.494s
[2K
| RMSProp | epoch: 011 | loss: 0.27017 - acc: 0.8982 -- iter: 0320/1292
[A[ATraining Step: 421  | total loss: [1m[32m0.24856[0m[0m | time: 131.783s
[2K
| RMSProp | epoch: 011 | loss: 0.24856 - acc: 0.9084 -- iter: 0352/1292
[A[ATraining Step: 422  | total loss: [1m[32m0.24538[0m[0m | time: 145.207s
[2K
| RMSProp | epoch: 011 | loss: 0.24538 - acc: 0.9113 -- iter: 0384/1292
[A[ATraining Step: 423  | total loss: [1m[32m0.24325[0m[0m | time: 158.840s
[2K
| RMSProp | epoch: 011 | loss: 0.24325 - acc: 0.9139 -- iter: 0416/1292
[A[ATraining Step: 424  | total loss: [1m[32m0.24650[0m[0m | time: 168.206s
[2K
| RMSProp | epoch: 011 | loss: 0.24650 - acc: 0.9100 -- iter: 0448/1292
[A[ATraining Step: 425  | total loss: [1m[32m0.23563[0m[0m | time: 176.544s
[2K
| RMSProp | epoch: 011 | loss: 0.23563 - acc: 0.9159 -- iter: 0480/1292
[A[ATraining Step: 426  | total loss: [1m[32m0.23159[0m[0m | time: 185.126s
[2K
| RMSProp | epoch: 011 | loss: 0.23159 - acc: 0.9181 -- iter: 0512/1292
[A[ATraining Step: 427  | total loss: [1m[32m0.23768[0m[0m | time: 194.604s
[2K
| RMSProp | epoch: 011 | loss: 0.23768 - acc: 0.9106 -- iter: 0544/1292
[A[ATraining Step: 428  | total loss: [1m[32m0.23379[0m[0m | time: 207.353s
[2K
| RMSProp | epoch: 011 | loss: 0.23379 - acc: 0.9133 -- iter: 0576/1292
[A[ATraining Step: 429  | total loss: [1m[32m0.23471[0m[0m | time: 220.225s
[2K
| RMSProp | epoch: 011 | loss: 0.23471 - acc: 0.9157 -- iter: 0608/1292
[A[ATraining Step: 430  | total loss: [1m[32m0.32597[0m[0m | time: 233.731s
[2K
| RMSProp | epoch: 011 | loss: 0.32597 - acc: 0.8960 -- iter: 0640/1292
[A[ATraining Step: 431  | total loss: [1m[32m0.31712[0m[0m | time: 247.685s
[2K
| RMSProp | epoch: 011 | loss: 0.31712 - acc: 0.9002 -- iter: 0672/1292
[A[ATraining Step: 432  | total loss: [1m[32m0.30103[0m[0m | time: 257.054s
[2K
| RMSProp | epoch: 011 | loss: 0.30103 - acc: 0.9070 -- iter: 0704/1292
[A[ATraining Step: 433  | total loss: [1m[32m0.28156[0m[0m | time: 269.012s
[2K
| RMSProp | epoch: 011 | loss: 0.28156 - acc: 0.9163 -- iter: 0736/1292
[A[ATraining Step: 434  | total loss: [1m[32m0.28016[0m[0m | time: 281.825s
[2K
| RMSProp | epoch: 011 | loss: 0.28016 - acc: 0.9153 -- iter: 0768/1292
[A[ATraining Step: 435  | total loss: [1m[32m0.28116[0m[0m | time: 294.831s
[2K
| RMSProp | epoch: 011 | loss: 0.28116 - acc: 0.9175 -- iter: 0800/1292
[A[ATraining Step: 436  | total loss: [1m[32m0.26557[0m[0m | time: 308.599s
[2K
| RMSProp | epoch: 011 | loss: 0.26557 - acc: 0.9227 -- iter: 0832/1292
[A[ATraining Step: 437  | total loss: [1m[32m0.26403[0m[0m | time: 322.434s
[2K
| RMSProp | epoch: 011 | loss: 0.26403 - acc: 0.9179 -- iter: 0864/1292
[A[ATraining Step: 438  | total loss: [1m[32m0.24816[0m[0m | time: 335.140s
[2K
| RMSProp | epoch: 011 | loss: 0.24816 - acc: 0.9261 -- iter: 0896/1292
[A[ATraining Step: 439  | total loss: [1m[32m0.27050[0m[0m | time: 348.125s
[2K
| RMSProp | epoch: 011 | loss: 0.27050 - acc: 0.9116 -- iter: 0928/1292
[A[ATraining Step: 440  | total loss: [1m[32m0.27603[0m[0m | time: 361.152s
[2K
| RMSProp | epoch: 011 | loss: 0.27603 - acc: 0.9048 -- iter: 0960/1292
[A[ATraining Step: 441  | total loss: [1m[32m0.26779[0m[0m | time: 374.622s
[2K
| RMSProp | epoch: 011 | loss: 0.26779 - acc: 0.9081 -- iter: 0992/1292
[A[ATraining Step: 442  | total loss: [1m[32m0.24904[0m[0m | time: 388.365s
[2K
| RMSProp | epoch: 011 | loss: 0.24904 - acc: 0.9142 -- iter: 1024/1292
[A[ATraining Step: 443  | total loss: [1m[32m0.23471[0m[0m | time: 397.182s
[2K
| RMSProp | epoch: 011 | loss: 0.23471 - acc: 0.9165 -- iter: 1056/1292
[A[ATraining Step: 444  | total loss: [1m[32m0.22784[0m[0m | time: 405.754s
[2K
| RMSProp | epoch: 011 | loss: 0.22784 - acc: 0.9186 -- iter: 1088/1292
[A[ATraining Step: 445  | total loss: [1m[32m0.22598[0m[0m | time: 414.403s
[2K
| RMSProp | epoch: 011 | loss: 0.22598 - acc: 0.9174 -- iter: 1120/1292
[A[ATraining Step: 446  | total loss: [1m[32m0.21215[0m[0m | time: 427.158s
[2K
| RMSProp | epoch: 011 | loss: 0.21215 - acc: 0.9225 -- iter: 1152/1292
[A[ATraining Step: 447  | total loss: [1m[32m0.21797[0m[0m | time: 440.193s
[2K
| RMSProp | epoch: 011 | loss: 0.21797 - acc: 0.9209 -- iter: 1184/1292
[A[ATraining Step: 448  | total loss: [1m[32m0.20505[0m[0m | time: 448.600s
[2K
| RMSProp | epoch: 011 | loss: 0.20505 - acc: 0.9288 -- iter: 1216/1292
[A[ATraining Step: 449  | total loss: [1m[32m0.19624[0m[0m | time: 457.308s
[2K
| RMSProp | epoch: 011 | loss: 0.19624 - acc: 0.9328 -- iter: 1248/1292
[A[ATraining Step: 450  | total loss: [1m[32m0.18926[0m[0m | time: 465.985s
[2K
| RMSProp | epoch: 011 | loss: 0.18926 - acc: 0.9333 -- iter: 1280/1292
[A[ATraining Step: 451  | total loss: [1m[32m0.18845[0m[0m | time: 493.216s
[2K
| RMSProp | epoch: 011 | loss: 0.18845 - acc: 0.9337 | val_loss: 1.30684 - val_acc: 0.6321 -- iter: 1292/1292
--
Training Step: 452  | total loss: [1m[32m0.17968[0m[0m | time: 8.496s
[2K
| RMSProp | epoch: 012 | loss: 0.17968 - acc: 0.9403 -- iter: 0032/1292
[A[ATraining Step: 453  | total loss: [1m[32m0.16376[0m[0m | time: 17.111s
[2K
| RMSProp | epoch: 012 | loss: 0.16376 - acc: 0.9463 -- iter: 0064/1292
[A[ATraining Step: 454  | total loss: [1m[32m0.15060[0m[0m | time: 25.398s
[2K
| RMSProp | epoch: 012 | loss: 0.15060 - acc: 0.9517 -- iter: 0096/1292
[A[ATraining Step: 455  | total loss: [1m[32m0.14044[0m[0m | time: 33.920s
[2K
| RMSProp | epoch: 012 | loss: 0.14044 - acc: 0.9534 -- iter: 0128/1292
[A[ATraining Step: 456  | total loss: [1m[32m0.16104[0m[0m | time: 42.206s
[2K
| RMSProp | epoch: 012 | loss: 0.16104 - acc: 0.9455 -- iter: 0160/1292
[A[ATraining Step: 457  | total loss: [1m[32m0.18396[0m[0m | time: 50.517s
[2K
| RMSProp | epoch: 012 | loss: 0.18396 - acc: 0.9385 -- iter: 0192/1292
[A[ATraining Step: 458  | total loss: [1m[32m0.17431[0m[0m | time: 59.058s
[2K
| RMSProp | epoch: 012 | loss: 0.17431 - acc: 0.9415 -- iter: 0224/1292
[A[ATraining Step: 459  | total loss: [1m[32m0.16711[0m[0m | time: 67.527s
[2K
| RMSProp | epoch: 012 | loss: 0.16711 - acc: 0.9411 -- iter: 0256/1292
[A[ATraining Step: 460  | total loss: [1m[32m0.15954[0m[0m | time: 75.855s
[2K
| RMSProp | epoch: 012 | loss: 0.15954 - acc: 0.9439 -- iter: 0288/1292
[A[ATraining Step: 461  | total loss: [1m[32m0.15443[0m[0m | time: 79.547s
[2K
| RMSProp | epoch: 012 | loss: 0.15443 - acc: 0.9432 -- iter: 0320/1292
[A[ATraining Step: 462  | total loss: [1m[32m0.19213[0m[0m | time: 83.331s
[2K
| RMSProp | epoch: 012 | loss: 0.19213 - acc: 0.9239 -- iter: 0352/1292
[A[ATraining Step: 463  | total loss: [1m[32m0.19119[0m[0m | time: 91.780s
[2K
| RMSProp | epoch: 012 | loss: 0.19119 - acc: 0.9232 -- iter: 0384/1292
[A[ATraining Step: 464  | total loss: [1m[32m0.24823[0m[0m | time: 100.340s
[2K
| RMSProp | epoch: 012 | loss: 0.24823 - acc: 0.8965 -- iter: 0416/1292
[A[ATraining Step: 465  | total loss: [1m[32m0.24278[0m[0m | time: 108.917s
[2K
| RMSProp | epoch: 012 | loss: 0.24278 - acc: 0.8975 -- iter: 0448/1292
[A[ATraining Step: 466  | total loss: [1m[32m0.23009[0m[0m | time: 117.352s
[2K
| RMSProp | epoch: 012 | loss: 0.23009 - acc: 0.9015 -- iter: 0480/1292
[A[ATraining Step: 467  | total loss: [1m[32m0.24864[0m[0m | time: 125.850s
[2K
| RMSProp | epoch: 012 | loss: 0.24864 - acc: 0.8926 -- iter: 0512/1292
[A[ATraining Step: 468  | total loss: [1m[32m0.23021[0m[0m | time: 134.320s
[2K
| RMSProp | epoch: 012 | loss: 0.23021 - acc: 0.9033 -- iter: 0544/1292
[A[ATraining Step: 469  | total loss: [1m[32m0.24519[0m[0m | time: 142.837s
[2K
| RMSProp | epoch: 012 | loss: 0.24519 - acc: 0.8974 -- iter: 0576/1292
[A[ATraining Step: 470  | total loss: [1m[32m0.25348[0m[0m | time: 151.317s
[2K
| RMSProp | epoch: 012 | loss: 0.25348 - acc: 0.8889 -- iter: 0608/1292
[A[ATraining Step: 471  | total loss: [1m[32m0.25034[0m[0m | time: 159.678s
[2K
| RMSProp | epoch: 012 | loss: 0.25034 - acc: 0.8937 -- iter: 0640/1292
[A[ATraining Step: 472  | total loss: [1m[32m0.24946[0m[0m | time: 168.263s
[2K
| RMSProp | epoch: 012 | loss: 0.24946 - acc: 0.8981 -- iter: 0672/1292
[A[ATraining Step: 473  | total loss: [1m[32m0.27355[0m[0m | time: 176.719s
[2K
| RMSProp | epoch: 012 | loss: 0.27355 - acc: 0.8896 -- iter: 0704/1292
[A[ATraining Step: 474  | total loss: [1m[32m0.27748[0m[0m | time: 185.279s
[2K
| RMSProp | epoch: 012 | loss: 0.27748 - acc: 0.8818 -- iter: 0736/1292
[A[ATraining Step: 475  | total loss: [1m[32m0.26678[0m[0m | time: 193.651s
[2K
| RMSProp | epoch: 012 | loss: 0.26678 - acc: 0.8905 -- iter: 0768/1292
[A[ATraining Step: 476  | total loss: [1m[32m0.26709[0m[0m | time: 202.030s
[2K
| RMSProp | epoch: 012 | loss: 0.26709 - acc: 0.8890 -- iter: 0800/1292
[A[ATraining Step: 477  | total loss: [1m[32m0.26017[0m[0m | time: 210.383s
[2K
| RMSProp | epoch: 012 | loss: 0.26017 - acc: 0.8876 -- iter: 0832/1292
[A[ATraining Step: 478  | total loss: [1m[32m0.25553[0m[0m | time: 218.947s
[2K
| RMSProp | epoch: 012 | loss: 0.25553 - acc: 0.8895 -- iter: 0864/1292
[A[ATraining Step: 479  | total loss: [1m[32m0.24807[0m[0m | time: 227.628s
[2K
| RMSProp | epoch: 012 | loss: 0.24807 - acc: 0.8974 -- iter: 0896/1292
[A[ATraining Step: 480  | total loss: [1m[32m0.23083[0m[0m | time: 236.029s
[2K
| RMSProp | epoch: 012 | loss: 0.23083 - acc: 0.9076 -- iter: 0928/1292
[A[ATraining Step: 481  | total loss: [1m[32m0.21311[0m[0m | time: 244.624s
[2K
| RMSProp | epoch: 012 | loss: 0.21311 - acc: 0.9169 -- iter: 0960/1292
[A[ATraining Step: 482  | total loss: [1m[32m0.20340[0m[0m | time: 253.318s
[2K
| RMSProp | epoch: 012 | loss: 0.20340 - acc: 0.9221 -- iter: 0992/1292
[A[ATraining Step: 483  | total loss: [1m[32m0.20347[0m[0m | time: 261.740s
[2K
| RMSProp | epoch: 012 | loss: 0.20347 - acc: 0.9205 -- iter: 1024/1292
[A[ATraining Step: 484  | total loss: [1m[32m0.19468[0m[0m | time: 270.149s
[2K
| RMSProp | epoch: 012 | loss: 0.19468 - acc: 0.9191 -- iter: 1056/1292
[A[ATraining Step: 485  | total loss: [1m[32m0.18331[0m[0m | time: 278.614s
[2K
| RMSProp | epoch: 012 | loss: 0.18331 - acc: 0.9240 -- iter: 1088/1292
[A[ATraining Step: 486  | total loss: [1m[32m0.19450[0m[0m | time: 287.165s
[2K
| RMSProp | epoch: 012 | loss: 0.19450 - acc: 0.9223 -- iter: 1120/1292
[A[ATraining Step: 487  | total loss: [1m[32m0.17697[0m[0m | time: 295.590s
[2K
| RMSProp | epoch: 012 | loss: 0.17697 - acc: 0.9300 -- iter: 1152/1292
[A[ATraining Step: 488  | total loss: [1m[32m0.17110[0m[0m | time: 304.007s
[2K
| RMSProp | epoch: 012 | loss: 0.17110 - acc: 0.9339 -- iter: 1184/1292
[A[ATraining Step: 489  | total loss: [1m[32m0.16019[0m[0m | time: 312.361s
[2K
| RMSProp | epoch: 012 | loss: 0.16019 - acc: 0.9374 -- iter: 1216/1292
[A[ATraining Step: 490  | total loss: [1m[32m0.14717[0m[0m | time: 320.839s
[2K
| RMSProp | epoch: 012 | loss: 0.14717 - acc: 0.9436 -- iter: 1248/1292
[A[ATraining Step: 491  | total loss: [1m[32m0.16674[0m[0m | time: 329.347s
[2K
| RMSProp | epoch: 012 | loss: 0.16674 - acc: 0.9368 -- iter: 1280/1292
[A[ATraining Step: 492  | total loss: [1m[32m0.16144[0m[0m | time: 356.524s
[2K
| RMSProp | epoch: 012 | loss: 0.16144 - acc: 0.9400 | val_loss: 0.63353 - val_acc: 0.7605 -- iter: 1292/1292
--
Training Step: 493  | total loss: [1m[32m0.16746[0m[0m | time: 8.458s
[2K
| RMSProp | epoch: 013 | loss: 0.16746 - acc: 0.9366 -- iter: 0032/1292
[A[ATraining Step: 494  | total loss: [1m[32m0.15923[0m[0m | time: 17.070s
[2K
| RMSProp | epoch: 013 | loss: 0.15923 - acc: 0.9398 -- iter: 0064/1292
[A[ATraining Step: 495  | total loss: [1m[32m0.16300[0m[0m | time: 25.495s
[2K
| RMSProp | epoch: 013 | loss: 0.16300 - acc: 0.9396 -- iter: 0096/1292
[A[ATraining Step: 496  | total loss: [1m[32m0.15133[0m[0m | time: 33.967s
[2K
| RMSProp | epoch: 013 | loss: 0.15133 - acc: 0.9456 -- iter: 0128/1292
[A[ATraining Step: 497  | total loss: [1m[32m0.13801[0m[0m | time: 42.431s
[2K
| RMSProp | epoch: 013 | loss: 0.13801 - acc: 0.9511 -- iter: 0160/1292
[A[ATraining Step: 498  | total loss: [1m[32m0.14136[0m[0m | time: 50.872s
[2K
| RMSProp | epoch: 013 | loss: 0.14136 - acc: 0.9497 -- iter: 0192/1292
[A[ATraining Step: 499  | total loss: [1m[32m0.14028[0m[0m | time: 59.331s
[2K
| RMSProp | epoch: 013 | loss: 0.14028 - acc: 0.9516 -- iter: 0224/1292
[A[ATraining Step: 500  | total loss: [1m[32m0.14987[0m[0m | time: 67.735s
[2K
| RMSProp | epoch: 013 | loss: 0.14987 - acc: 0.9502 -- iter: 0256/1292
[A[ATraining Step: 501  | total loss: [1m[32m0.13932[0m[0m | time: 76.160s
[2K
| RMSProp | epoch: 013 | loss: 0.13932 - acc: 0.9552 -- iter: 0288/1292
[A[ATraining Step: 502  | total loss: [1m[32m0.15524[0m[0m | time: 84.456s
[2K
| RMSProp | epoch: 013 | loss: 0.15524 - acc: 0.9440 -- iter: 0320/1292
[A[ATraining Step: 503  | total loss: [1m[32m0.15383[0m[0m | time: 88.227s
[2K
| RMSProp | epoch: 013 | loss: 0.15383 - acc: 0.9465 -- iter: 0352/1292
[A[ATraining Step: 504  | total loss: [1m[32m0.15878[0m[0m | time: 91.945s
[2K
| RMSProp | epoch: 013 | loss: 0.15878 - acc: 0.9435 -- iter: 0384/1292
[A[ATraining Step: 505  | total loss: [1m[32m0.14442[0m[0m | time: 100.493s
[2K
| RMSProp | epoch: 013 | loss: 0.14442 - acc: 0.9492 -- iter: 0416/1292
[A[ATraining Step: 506  | total loss: [1m[32m0.13782[0m[0m | time: 108.914s
[2K
| RMSProp | epoch: 013 | loss: 0.13782 - acc: 0.9511 -- iter: 0448/1292
[A[ATraining Step: 507  | total loss: [1m[32m0.13772[0m[0m | time: 117.262s
[2K
| RMSProp | epoch: 013 | loss: 0.13772 - acc: 0.9498 -- iter: 0480/1292
[A[ATraining Step: 508  | total loss: [1m[32m0.14934[0m[0m | time: 125.758s
[2K
| RMSProp | epoch: 013 | loss: 0.14934 - acc: 0.9423 -- iter: 0512/1292
[A[ATraining Step: 509  | total loss: [1m[32m0.13686[0m[0m | time: 134.129s
[2K
| RMSProp | epoch: 013 | loss: 0.13686 - acc: 0.9481 -- iter: 0544/1292
[A[ATraining Step: 510  | total loss: [1m[32m0.14855[0m[0m | time: 142.448s
[2K
| RMSProp | epoch: 013 | loss: 0.14855 - acc: 0.9439 -- iter: 0576/1292
[A[ATraining Step: 511  | total loss: [1m[32m0.16543[0m[0m | time: 150.785s
[2K
| RMSProp | epoch: 013 | loss: 0.16543 - acc: 0.9339 -- iter: 0608/1292
[A[ATraining Step: 512  | total loss: [1m[32m0.16859[0m[0m | time: 159.397s
[2K
| RMSProp | epoch: 013 | loss: 0.16859 - acc: 0.9311 -- iter: 0640/1292
[A[ATraining Step: 513  | total loss: [1m[32m0.16293[0m[0m | time: 167.887s
[2K
| RMSProp | epoch: 013 | loss: 0.16293 - acc: 0.9349 -- iter: 0672/1292
[A[ATraining Step: 514  | total loss: [1m[32m0.17552[0m[0m | time: 176.532s
[2K
| RMSProp | epoch: 013 | loss: 0.17552 - acc: 0.9320 -- iter: 0704/1292
[A[ATraining Step: 515  | total loss: [1m[32m0.16126[0m[0m | time: 185.072s
[2K
| RMSProp | epoch: 013 | loss: 0.16126 - acc: 0.9388 -- iter: 0736/1292
[A[ATraining Step: 516  | total loss: [1m[32m0.15130[0m[0m | time: 193.629s
[2K
| RMSProp | epoch: 013 | loss: 0.15130 - acc: 0.9418 -- iter: 0768/1292
[A[ATraining Step: 517  | total loss: [1m[32m0.13971[0m[0m | time: 202.055s
[2K
| RMSProp | epoch: 013 | loss: 0.13971 - acc: 0.9476 -- iter: 0800/1292
[A[ATraining Step: 518  | total loss: [1m[32m0.14973[0m[0m | time: 210.556s
[2K
| RMSProp | epoch: 013 | loss: 0.14973 - acc: 0.9466 -- iter: 0832/1292
[A[ATraining Step: 519  | total loss: [1m[32m0.13926[0m[0m | time: 218.980s
[2K
| RMSProp | epoch: 013 | loss: 0.13926 - acc: 0.9519 -- iter: 0864/1292
[A[ATraining Step: 520  | total loss: [1m[32m0.13110[0m[0m | time: 227.719s
[2K
| RMSProp | epoch: 013 | loss: 0.13110 - acc: 0.9568 -- iter: 0896/1292
[A[ATraining Step: 521  | total loss: [1m[32m0.12137[0m[0m | time: 236.275s
[2K
| RMSProp | epoch: 013 | loss: 0.12137 - acc: 0.9611 -- iter: 0928/1292
[A[ATraining Step: 522  | total loss: [1m[32m0.11887[0m[0m | time: 244.772s
[2K
| RMSProp | epoch: 013 | loss: 0.11887 - acc: 0.9618 -- iter: 0960/1292
[A[ATraining Step: 523  | total loss: [1m[32m0.11015[0m[0m | time: 253.240s
[2K
| RMSProp | epoch: 013 | loss: 0.11015 - acc: 0.9657 -- iter: 0992/1292
[A[ATraining Step: 524  | total loss: [1m[32m0.10491[0m[0m | time: 261.789s
[2K
| RMSProp | epoch: 013 | loss: 0.10491 - acc: 0.9660 -- iter: 1024/1292
[A[ATraining Step: 525  | total loss: [1m[32m0.09679[0m[0m | time: 270.427s
[2K
| RMSProp | epoch: 013 | loss: 0.09679 - acc: 0.9694 -- iter: 1056/1292
[A[ATraining Step: 526  | total loss: [1m[32m0.08996[0m[0m | time: 278.892s
[2K
| RMSProp | epoch: 013 | loss: 0.08996 - acc: 0.9724 -- iter: 1088/1292
[A[ATraining Step: 527  | total loss: [1m[32m0.09224[0m[0m | time: 287.306s
[2K
| RMSProp | epoch: 013 | loss: 0.09224 - acc: 0.9689 -- iter: 1120/1292
[A[ATraining Step: 528  | total loss: [1m[32m0.10083[0m[0m | time: 295.925s
[2K
| RMSProp | epoch: 013 | loss: 0.10083 - acc: 0.9627 -- iter: 1152/1292
[A[ATraining Step: 529  | total loss: [1m[32m0.09398[0m[0m | time: 304.327s
[2K
| RMSProp | epoch: 013 | loss: 0.09398 - acc: 0.9633 -- iter: 1184/1292
[A[ATraining Step: 530  | total loss: [1m[32m0.08647[0m[0m | time: 312.758s
[2K
| RMSProp | epoch: 013 | loss: 0.08647 - acc: 0.9670 -- iter: 1216/1292
[A[ATraining Step: 531  | total loss: [1m[32m0.09008[0m[0m | time: 321.257s
[2K
| RMSProp | epoch: 013 | loss: 0.09008 - acc: 0.9671 -- iter: 1248/1292
[A[ATraining Step: 532  | total loss: [1m[32m0.11940[0m[0m | time: 329.628s
[2K
| RMSProp | epoch: 013 | loss: 0.11940 - acc: 0.9610 -- iter: 1280/1292
[A[ATraining Step: 533  | total loss: [1m[32m0.12976[0m[0m | time: 357.367s
[2K
| RMSProp | epoch: 013 | loss: 0.12976 - acc: 0.9587 | val_loss: 0.34652 - val_acc: 0.8765 -- iter: 1292/1292
--
Training Step: 534  | total loss: [1m[32m0.13544[0m[0m | time: 8.573s
[2K
| RMSProp | epoch: 014 | loss: 0.13544 - acc: 0.9534 -- iter: 0032/1292
[A[ATraining Step: 535  | total loss: [1m[32m0.14148[0m[0m | time: 16.940s
[2K
| RMSProp | epoch: 014 | loss: 0.14148 - acc: 0.9519 -- iter: 0064/1292
[A[ATraining Step: 536  | total loss: [1m[32m0.14979[0m[0m | time: 25.667s
[2K
| RMSProp | epoch: 014 | loss: 0.14979 - acc: 0.9504 -- iter: 0096/1292
[A[ATraining Step: 537  | total loss: [1m[32m0.13790[0m[0m | time: 34.330s
[2K
| RMSProp | epoch: 014 | loss: 0.13790 - acc: 0.9554 -- iter: 0128/1292
[A[ATraining Step: 538  | total loss: [1m[32m0.12967[0m[0m | time: 42.868s
[2K
| RMSProp | epoch: 014 | loss: 0.12967 - acc: 0.9598 -- iter: 0160/1292
[A[ATraining Step: 539  | total loss: [1m[32m0.12646[0m[0m | time: 50.968s
[2K
| RMSProp | epoch: 014 | loss: 0.12646 - acc: 0.9576 -- iter: 0192/1292
[A[ATraining Step: 540  | total loss: [1m[32m0.11869[0m[0m | time: 59.640s
[2K
| RMSProp | epoch: 014 | loss: 0.11869 - acc: 0.9587 -- iter: 0224/1292
[A[ATraining Step: 541  | total loss: [1m[32m0.11657[0m[0m | time: 68.131s
[2K
| RMSProp | epoch: 014 | loss: 0.11657 - acc: 0.9597 -- iter: 0256/1292
[A[ATraining Step: 542  | total loss: [1m[32m0.11541[0m[0m | time: 76.575s
[2K
| RMSProp | epoch: 014 | loss: 0.11541 - acc: 0.9575 -- iter: 0288/1292
[A[ATraining Step: 543  | total loss: [1m[32m0.12662[0m[0m | time: 85.045s
[2K
| RMSProp | epoch: 014 | loss: 0.12662 - acc: 0.9555 -- iter: 0320/1292
[A[ATraining Step: 544  | total loss: [1m[32m0.12052[0m[0m | time: 93.715s
[2K
| RMSProp | epoch: 014 | loss: 0.12052 - acc: 0.9568 -- iter: 0352/1292
[A[ATraining Step: 545  | total loss: [1m[32m0.14291[0m[0m | time: 97.432s
[2K
| RMSProp | epoch: 014 | loss: 0.14291 - acc: 0.9518 -- iter: 0384/1292
[A[ATraining Step: 546  | total loss: [1m[32m0.15539[0m[0m | time: 101.117s
[2K
| RMSProp | epoch: 014 | loss: 0.15539 - acc: 0.9483 -- iter: 0416/1292
[A[ATraining Step: 547  | total loss: [1m[32m0.14551[0m[0m | time: 109.581s
[2K
| RMSProp | epoch: 014 | loss: 0.14551 - acc: 0.9534 -- iter: 0448/1292
[A[ATraining Step: 548  | total loss: [1m[32m0.15242[0m[0m | time: 118.208s
[2K
| RMSProp | epoch: 014 | loss: 0.15242 - acc: 0.9518 -- iter: 0480/1292
[A[ATraining Step: 549  | total loss: [1m[32m0.16107[0m[0m | time: 126.603s
[2K
| RMSProp | epoch: 014 | loss: 0.16107 - acc: 0.9442 -- iter: 0512/1292
[A[ATraining Step: 550  | total loss: [1m[32m0.16432[0m[0m | time: 135.359s
[2K
| RMSProp | epoch: 014 | loss: 0.16432 - acc: 0.9466 -- iter: 0544/1292
[A[ATraining Step: 551  | total loss: [1m[32m0.16136[0m[0m | time: 143.964s
[2K
| RMSProp | epoch: 014 | loss: 0.16136 - acc: 0.9457 -- iter: 0576/1292
[A[ATraining Step: 552  | total loss: [1m[32m0.15038[0m[0m | time: 152.509s
[2K
| RMSProp | epoch: 014 | loss: 0.15038 - acc: 0.9511 -- iter: 0608/1292
[A[ATraining Step: 553  | total loss: [1m[32m0.13853[0m[0m | time: 161.107s
[2K
| RMSProp | epoch: 014 | loss: 0.13853 - acc: 0.9560 -- iter: 0640/1292
[A[ATraining Step: 554  | total loss: [1m[32m0.13507[0m[0m | time: 169.567s
[2K
| RMSProp | epoch: 014 | loss: 0.13507 - acc: 0.9573 -- iter: 0672/1292
[A[ATraining Step: 555  | total loss: [1m[32m0.13468[0m[0m | time: 177.929s
[2K
| RMSProp | epoch: 014 | loss: 0.13468 - acc: 0.9584 -- iter: 0704/1292
[A[ATraining Step: 556  | total loss: [1m[32m0.14962[0m[0m | time: 186.399s
[2K
| RMSProp | epoch: 014 | loss: 0.14962 - acc: 0.9595 -- iter: 0736/1292
[A[ATraining Step: 557  | total loss: [1m[32m0.14661[0m[0m | time: 195.029s
[2K
| RMSProp | epoch: 014 | loss: 0.14661 - acc: 0.9573 -- iter: 0768/1292
[A[ATraining Step: 558  | total loss: [1m[32m0.14104[0m[0m | time: 203.560s
[2K
| RMSProp | epoch: 014 | loss: 0.14104 - acc: 0.9584 -- iter: 0800/1292
[A[ATraining Step: 559  | total loss: [1m[32m0.13025[0m[0m | time: 212.178s
[2K
| RMSProp | epoch: 014 | loss: 0.13025 - acc: 0.9626 -- iter: 0832/1292
[A[ATraining Step: 560  | total loss: [1m[32m0.12115[0m[0m | time: 220.615s
[2K
| RMSProp | epoch: 014 | loss: 0.12115 - acc: 0.9663 -- iter: 0864/1292
[A[ATraining Step: 561  | total loss: [1m[32m0.11691[0m[0m | time: 228.869s
[2K
| RMSProp | epoch: 014 | loss: 0.11691 - acc: 0.9634 -- iter: 0896/1292
[A[ATraining Step: 562  | total loss: [1m[32m0.10690[0m[0m | time: 237.336s
[2K
| RMSProp | epoch: 014 | loss: 0.10690 - acc: 0.9671 -- iter: 0928/1292
[A[ATraining Step: 563  | total loss: [1m[32m0.09893[0m[0m | time: 245.707s
[2K
| RMSProp | epoch: 014 | loss: 0.09893 - acc: 0.9704 -- iter: 0960/1292
[A[ATraining Step: 564  | total loss: [1m[32m0.09285[0m[0m | time: 254.011s
[2K
| RMSProp | epoch: 014 | loss: 0.09285 - acc: 0.9733 -- iter: 0992/1292
[A[ATraining Step: 565  | total loss: [1m[32m0.08985[0m[0m | time: 262.366s
[2K
| RMSProp | epoch: 014 | loss: 0.08985 - acc: 0.9729 -- iter: 1024/1292
[A[ATraining Step: 566  | total loss: [1m[32m0.08413[0m[0m | time: 270.818s
[2K
| RMSProp | epoch: 014 | loss: 0.08413 - acc: 0.9756 -- iter: 1056/1292
[A[ATraining Step: 567  | total loss: [1m[32m0.07670[0m[0m | time: 279.340s
[2K
| RMSProp | epoch: 014 | loss: 0.07670 - acc: 0.9780 -- iter: 1088/1292
[A[ATraining Step: 568  | total loss: [1m[32m0.07146[0m[0m | time: 287.751s
[2K
| RMSProp | epoch: 014 | loss: 0.07146 - acc: 0.9802 -- iter: 1120/1292
[A[ATraining Step: 569  | total loss: [1m[32m0.06518[0m[0m | time: 296.101s
[2K
| RMSProp | epoch: 014 | loss: 0.06518 - acc: 0.9822 -- iter: 1152/1292
[A[ATraining Step: 570  | total loss: [1m[32m0.06360[0m[0m | time: 304.536s
[2K
| RMSProp | epoch: 014 | loss: 0.06360 - acc: 0.9840 -- iter: 1184/1292
[A[ATraining Step: 571  | total loss: [1m[32m0.06016[0m[0m | time: 312.953s
[2K
| RMSProp | epoch: 014 | loss: 0.06016 - acc: 0.9856 -- iter: 1216/1292
[A[ATraining Step: 572  | total loss: [1m[32m0.08048[0m[0m | time: 321.581s
[2K
| RMSProp | epoch: 014 | loss: 0.08048 - acc: 0.9839 -- iter: 1248/1292
[A[ATraining Step: 573  | total loss: [1m[32m0.09123[0m[0m | time: 330.045s
[2K
| RMSProp | epoch: 014 | loss: 0.09123 - acc: 0.9730 -- iter: 1280/1292
[A[ATraining Step: 574  | total loss: [1m[32m0.09173[0m[0m | time: 357.386s
[2K
| RMSProp | epoch: 014 | loss: 0.09173 - acc: 0.9726 | val_loss: 0.46316 - val_acc: 0.8222 -- iter: 1292/1292
--
Training Step: 575  | total loss: [1m[32m0.09298[0m[0m | time: 8.710s
[2K
| RMSProp | epoch: 015 | loss: 0.09298 - acc: 0.9722 -- iter: 0032/1292
[A[ATraining Step: 576  | total loss: [1m[32m0.08713[0m[0m | time: 17.648s
[2K
| RMSProp | epoch: 015 | loss: 0.08713 - acc: 0.9750 -- iter: 0064/1292
[A[ATraining Step: 577  | total loss: [1m[32m0.08496[0m[0m | time: 26.168s
[2K
| RMSProp | epoch: 015 | loss: 0.08496 - acc: 0.9744 -- iter: 0096/1292
[A[ATraining Step: 578  | total loss: [1m[32m0.08146[0m[0m | time: 34.604s
[2K
| RMSProp | epoch: 015 | loss: 0.08146 - acc: 0.9738 -- iter: 0128/1292
[A[ATraining Step: 579  | total loss: [1m[32m0.08347[0m[0m | time: 43.021s
[2K
| RMSProp | epoch: 015 | loss: 0.08347 - acc: 0.9733 -- iter: 0160/1292
[A[ATraining Step: 580  | total loss: [1m[32m0.07665[0m[0m | time: 51.365s
[2K
| RMSProp | epoch: 015 | loss: 0.07665 - acc: 0.9760 -- iter: 0192/1292
[A[ATraining Step: 581  | total loss: [1m[32m0.07392[0m[0m | time: 59.691s
[2K
| RMSProp | epoch: 015 | loss: 0.07392 - acc: 0.9752 -- iter: 0224/1292
[A[ATraining Step: 582  | total loss: [1m[32m0.08002[0m[0m | time: 68.320s
[2K
| RMSProp | epoch: 015 | loss: 0.08002 - acc: 0.9746 -- iter: 0256/1292
[A[ATraining Step: 583  | total loss: [1m[32m0.08840[0m[0m | time: 76.979s
[2K
| RMSProp | epoch: 015 | loss: 0.08840 - acc: 0.9740 -- iter: 0288/1292
[A[ATraining Step: 584  | total loss: [1m[32m0.09195[0m[0m | time: 85.629s
[2K
| RMSProp | epoch: 015 | loss: 0.09195 - acc: 0.9735 -- iter: 0320/1292
[A[ATraining Step: 585  | total loss: [1m[32m0.10758[0m[0m | time: 94.083s
[2K
| RMSProp | epoch: 015 | loss: 0.10758 - acc: 0.9668 -- iter: 0352/1292
[A[ATraining Step: 586  | total loss: [1m[32m0.12538[0m[0m | time: 102.490s
[2K
| RMSProp | epoch: 015 | loss: 0.12538 - acc: 0.9576 -- iter: 0384/1292
[A[ATraining Step: 587  | total loss: [1m[32m0.11631[0m[0m | time: 106.252s
[2K
| RMSProp | epoch: 015 | loss: 0.11631 - acc: 0.9618 -- iter: 0416/1292
[A[ATraining Step: 588  | total loss: [1m[32m0.10627[0m[0m | time: 109.944s
[2K
| RMSProp | epoch: 015 | loss: 0.10627 - acc: 0.9656 -- iter: 0448/1292
[A[ATraining Step: 589  | total loss: [1m[32m0.09600[0m[0m | time: 118.554s
[2K
| RMSProp | epoch: 015 | loss: 0.09600 - acc: 0.9691 -- iter: 0480/1292
[A[ATraining Step: 590  | total loss: [1m[32m0.10024[0m[0m | time: 127.011s
[2K
| RMSProp | epoch: 015 | loss: 0.10024 - acc: 0.9659 -- iter: 0512/1292
[A[ATraining Step: 591  | total loss: [1m[32m0.09306[0m[0m | time: 135.708s
[2K
| RMSProp | epoch: 015 | loss: 0.09306 - acc: 0.9693 -- iter: 0544/1292
[A[ATraining Step: 592  | total loss: [1m[32m0.11854[0m[0m | time: 144.161s
[2K
| RMSProp | epoch: 015 | loss: 0.11854 - acc: 0.9568 -- iter: 0576/1292
[A[ATraining Step: 593  | total loss: [1m[32m0.13312[0m[0m | time: 152.493s
[2K
| RMSProp | epoch: 015 | loss: 0.13312 - acc: 0.9517 -- iter: 0608/1292
[A[ATraining Step: 594  | total loss: [1m[32m0.12597[0m[0m | time: 161.044s
[2K
| RMSProp | epoch: 015 | loss: 0.12597 - acc: 0.9534 -- iter: 0640/1292
[A[ATraining Step: 595  | total loss: [1m[32m0.15458[0m[0m | time: 169.635s
[2K
| RMSProp | epoch: 015 | loss: 0.15458 - acc: 0.9487 -- iter: 0672/1292
[A[ATraining Step: 596  | total loss: [1m[32m0.15399[0m[0m | time: 177.925s
[2K
| RMSProp | epoch: 015 | loss: 0.15399 - acc: 0.9476 -- iter: 0704/1292
[A[ATraining Step: 597  | total loss: [1m[32m0.14361[0m[0m | time: 186.304s
[2K
| RMSProp | epoch: 015 | loss: 0.14361 - acc: 0.9528 -- iter: 0736/1292
[A[ATraining Step: 598  | total loss: [1m[32m0.16572[0m[0m | time: 194.634s
[2K
| RMSProp | epoch: 015 | loss: 0.16572 - acc: 0.9513 -- iter: 0768/1292
[A[ATraining Step: 599  | total loss: [1m[32m0.15897[0m[0m | time: 203.082s
[2K
| RMSProp | epoch: 015 | loss: 0.15897 - acc: 0.9530 -- iter: 0800/1292
[A[ATraining Step: 600  | total loss: [1m[32m0.14437[0m[0m | time: 230.384s
[2K
| RMSProp | epoch: 015 | loss: 0.14437 - acc: 0.9577 | val_loss: 0.69147 - val_acc: 0.7901 -- iter: 0832/1292
--
Training Step: 601  | total loss: [1m[32m0.13185[0m[0m | time: 238.950s
[2K
| RMSProp | epoch: 015 | loss: 0.13185 - acc: 0.9620 -- iter: 0864/1292
[A[ATraining Step: 602  | total loss: [1m[32m0.12550[0m[0m | time: 247.591s
[2K
| RMSProp | epoch: 015 | loss: 0.12550 - acc: 0.9626 -- iter: 0896/1292
[A[ATraining Step: 603  | total loss: [1m[32m0.11593[0m[0m | time: 256.351s
[2K
| RMSProp | epoch: 015 | loss: 0.11593 - acc: 0.9664 -- iter: 0928/1292
[A[ATraining Step: 604  | total loss: [1m[32m0.11625[0m[0m | time: 264.773s
[2K
| RMSProp | epoch: 015 | loss: 0.11625 - acc: 0.9635 -- iter: 0960/1292
[A[ATraining Step: 605  | total loss: [1m[32m0.10976[0m[0m | time: 273.177s
[2K
| RMSProp | epoch: 015 | loss: 0.10976 - acc: 0.9640 -- iter: 0992/1292
[A[ATraining Step: 606  | total loss: [1m[32m0.10408[0m[0m | time: 281.487s
[2K
| RMSProp | epoch: 015 | loss: 0.10408 - acc: 0.9676 -- iter: 1024/1292
[A[ATraining Step: 607  | total loss: [1m[32m0.09644[0m[0m | time: 289.944s
[2K
| RMSProp | epoch: 015 | loss: 0.09644 - acc: 0.9709 -- iter: 1056/1292
[A[ATraining Step: 608  | total loss: [1m[32m0.12193[0m[0m | time: 298.316s
[2K
| RMSProp | epoch: 015 | loss: 0.12193 - acc: 0.9613 -- iter: 1088/1292
[A[ATraining Step: 609  | total loss: [1m[32m0.12638[0m[0m | time: 306.732s
[2K
| RMSProp | epoch: 015 | loss: 0.12638 - acc: 0.9589 -- iter: 1120/1292
[A[ATraining Step: 610  | total loss: [1m[32m0.11509[0m[0m | time: 315.423s
[2K
| RMSProp | epoch: 015 | loss: 0.11509 - acc: 0.9630 -- iter: 1152/1292
[A[ATraining Step: 611  | total loss: [1m[32m0.11298[0m[0m | time: 323.932s
[2K
| RMSProp | epoch: 015 | loss: 0.11298 - acc: 0.9636 -- iter: 1184/1292
[A[ATraining Step: 612  | total loss: [1m[32m0.10447[0m[0m | time: 332.266s
[2K
| RMSProp | epoch: 015 | loss: 0.10447 - acc: 0.9672 -- iter: 1216/1292
[A[ATraining Step: 613  | total loss: [1m[32m0.10837[0m[0m | time: 340.832s
[2K
| RMSProp | epoch: 015 | loss: 0.10837 - acc: 0.9642 -- iter: 1248/1292
[A[ATraining Step: 614  | total loss: [1m[32m0.09850[0m[0m | time: 349.174s
[2K
| RMSProp | epoch: 015 | loss: 0.09850 - acc: 0.9678 -- iter: 1280/1292
[A[ATraining Step: 615  | total loss: [1m[32m0.09185[0m[0m | time: 376.483s
[2K
| RMSProp | epoch: 015 | loss: 0.09185 - acc: 0.9710 | val_loss: 0.44941 - val_acc: 0.8765 -- iter: 1292/1292
--
Validation AUC:0.9446017180788755
Validation AUPRC:0.9558835051069352
Test AUC:0.9442248572683355
Test AUPRC:0.9558224664545788
BestTestF1Score	0.87	0.76	0.88	0.92	0.83	171	14	184	36	0.3
BestTestMCCScore	0.85	0.74	0.86	0.96	0.76	157	6	192	50	0.57
BestTestAccuracyScore	0.87	0.77	0.88	0.94	0.82	169	11	187	38	0.37
BestValidationF1Score	0.88	0.77	0.88	0.93	0.84	175	14	183	33	0.3
BestValidationMCC	0.87	0.78	0.88	0.97	0.8	166	6	191	42	0.57
BestValidationAccuracy	0.88	0.77	0.88	0.94	0.83	172	11	186	36	0.37
TestPredictions (Threshold:0.57)
CHEMBL1956891,TN,INACT,0.0	CHEMBL380312,TP,ACT,1.0	CHEMBL482919,TN,INACT,0.0	CHEMBL3657265,TP,ACT,1.0	CHEMBL3657340,TP,ACT,1.0	CHEMBL7699,TN,INACT,0.0	CHEMBL1242118,TN,INACT,0.0	CHEMBL77243,TN,INACT,0.0	CHEMBL3665907,FN,ACT,0.5	CHEMBL3642313,TP,ACT,0.9900000095367432	CHEMBL3645074,TP,ACT,1.0	CHEMBL3665668,TN,INACT,0.0	CHEMBL206927,TP,ACT,1.0	CHEMBL3644980,TP,ACT,1.0	CHEMBL3657268,TP,ACT,1.0	CHEMBL76642,TN,INACT,0.0	CHEMBL430845,TN,INACT,0.0	CHEMBL3665870,TP,ACT,1.0	CHEMBL1668418,TN,INACT,0.0	CHEMBL3658032,TN,INACT,0.019999999552965164	CHEMBL3689070,TP,ACT,1.0	CHEMBL3657357,TP,ACT,0.9900000095367432	CHEMBL2385543,TN,INACT,0.009999999776482582	CHEMBL2029513,TN,INACT,0.3199999928474426	CHEMBL1172877,TN,INACT,0.0	CHEMBL3237941,TN,INACT,0.03999999910593033	CHEMBL1929314,TN,INACT,0.009999999776482582	CHEMBL3657252,TP,ACT,1.0	CHEMBL3642329,TP,ACT,0.8700000047683716	CHEMBL559069,TN,INACT,0.0	CHEMBL1269497,TN,INACT,0.0	CHEMBL3680492,TN,INACT,0.27000001072883606	CHEMBL3642396,TP,ACT,1.0	CHEMBL3692193,FN,ACT,0.550000011920929	CHEMBL178133,TN,INACT,0.12999999523162842	CHEMBL3237855,TN,INACT,0.029999999329447746	CHEMBL2425140,TN,INACT,0.0	CHEMBL2283258,TN,INACT,0.0	CHEMBL550855,TN,INACT,0.019999999552965164	CHEMBL3104855,FN,ACT,0.0	CHEMBL3642381,TP,ACT,1.0	CHEMBL3237851,TN,INACT,0.38999998569488525	CHEMBL3661424,TP,ACT,1.0	CHEMBL2337362,TN,INACT,0.0	CHEMBL460472,TN,INACT,0.03999999910593033	CHEMBL3665917,FN,ACT,0.029999999329447746	CHEMBL1688210,TN,INACT,0.0	CHEMBL3665869,TP,ACT,0.6499999761581421	CHEMBL3645099,TP,ACT,1.0	CHEMBL3642316,TP,ACT,1.0	CHEMBL1095776,TN,INACT,0.2800000011920929	CHEMBL726,TN,INACT,0.0	CHEMBL93464,TN,INACT,0.0	CHEMBL2333443,TP,ACT,0.7300000190734863	CHEMBL1910760,TN,INACT,0.009999999776482582	CHEMBL3288854,FN,ACT,0.05000000074505806	CHEMBL264667,TN,INACT,0.0	CHEMBL3645065,TP,ACT,1.0	CHEMBL2036871,TN,INACT,0.03999999910593033	CHEMBL488446,TP,ACT,1.0	CHEMBL1779261,TN,INACT,0.0	CHEMBL2337368,TN,INACT,0.0	CHEMBL2335019,TN,INACT,0.1899999976158142	CHEMBL208419,TP,ACT,0.6600000262260437	CHEMBL541988,TN,INACT,0.009999999776482582	CHEMBL1821889,TN,INACT,0.0	CHEMBL556874,TN,INACT,0.0	CHEMBL457401,TN,INACT,0.009999999776482582	CHEMBL3675452,TN,INACT,0.0	CHEMBL3781620,TP,ACT,1.0	CHEMBL1242661,TN,INACT,0.009999999776482582	CHEMBL3781339,TP,ACT,1.0	CHEMBL1221415,TN,INACT,0.009999999776482582	CHEMBL564235,TN,INACT,0.0	CHEMBL3645011,TP,ACT,1.0	CHEMBL1910762,TN,INACT,0.03999999910593033	CHEMBL3665937,TP,ACT,1.0	CHEMBL3642289,TP,ACT,1.0	CHEMBL3645026,FN,ACT,0.07000000029802322	CHEMBL141238,TN,INACT,0.019999999552965164	CHEMBL3642319,TP,ACT,0.8199999928474426	CHEMBL3642296,TP,ACT,0.9599999785423279	CHEMBL3692182,FN,ACT,0.009999999776482582	CHEMBL3645107,TP,ACT,0.9900000095367432	CHEMBL1095130,TN,INACT,0.0	CHEMBL3261189,FP,INACT,0.9900000095367432	CHEMBL601719,FN,ACT,0.0	CHEMBL388978,TP,ACT,0.9900000095367432	CHEMBL3780912,TN,INACT,0.0	CHEMBL3657400,TP,ACT,1.0	CHEMBL2029515,TN,INACT,0.019999999552965164	CHEMBL557050,TN,INACT,0.0	CHEMBL3657325,TP,ACT,1.0	CHEMBL1767294,TN,INACT,0.0	CHEMBL2315578,FN,ACT,0.019999999552965164	CHEMBL208468,FN,ACT,0.10000000149011612	CHEMBL3672511,TN,INACT,0.20999999344348907	CHEMBL3645028,FN,ACT,0.1599999964237213	CHEMBL1241299,TN,INACT,0.0	CHEMBL120564,TN,INACT,0.0	CHEMBL3644993,TP,ACT,1.0	CHEMBL3642315,TP,ACT,1.0	CHEMBL3639561,TP,ACT,0.9200000166893005	CHEMBL3645010,TP,ACT,1.0	CHEMBL2393379,TP,ACT,0.9399999976158142	CHEMBL2062802,TP,ACT,0.9900000095367432	CHEMBL3642363,TP,ACT,1.0	CHEMBL3657299,TP,ACT,1.0	CHEMBL2207440,FN,ACT,0.07000000029802322	CHEMBL3781538,TN,INACT,0.0	CHEMBL3657245,TP,ACT,1.0	CHEMBL435054,TN,INACT,0.0	CHEMBL3342105,TN,INACT,0.0	CHEMBL3642342,FN,ACT,0.0	CHEMBL3657347,TP,ACT,1.0	CHEMBL3657394,FN,ACT,0.30000001192092896	CHEMBL3393289,TP,ACT,1.0	CHEMBL2409583,FP,INACT,0.9900000095367432	CHEMBL1933806,TN,INACT,0.0	CHEMBL3642338,TP,ACT,1.0	CHEMBL3609568,FP,INACT,0.9900000095367432	CHEMBL512658,TN,INACT,0.0	CHEMBL3645100,TP,ACT,1.0	CHEMBL3798556,TN,INACT,0.009999999776482582	CHEMBL477064,TN,INACT,0.0	CHEMBL469346,TN,INACT,0.0	CHEMBL1916951,TN,INACT,0.0	CHEMBL208042,TP,ACT,1.0	CHEMBL240093,TN,INACT,0.0	CHEMBL312078,TN,INACT,0.019999999552965164	CHEMBL2315580,TP,ACT,1.0	CHEMBL3657354,TP,ACT,0.9900000095367432	CHEMBL3665901,TP,ACT,1.0	CHEMBL1230609,FN,ACT,0.019999999552965164	CHEMBL3779977,FN,ACT,0.0	CHEMBL3353409,TN,INACT,0.2199999988079071	CHEMBL3642349,TP,ACT,0.9300000071525574	CHEMBL76905,TN,INACT,0.0	CHEMBL3645098,TP,ACT,1.0	CHEMBL1172697,TN,INACT,0.0	CHEMBL2029522,TN,INACT,0.0	CHEMBL514409,FN,ACT,0.07999999821186066	CHEMBL3780915,TP,ACT,0.9100000262260437	CHEMBL77298,TN,INACT,0.0	CHEMBL1688219,TN,INACT,0.009999999776482582	CHEMBL2392242,TN,INACT,0.0	CHEMBL3642254,TP,ACT,0.9800000190734863	CHEMBL2036727,TN,INACT,0.009999999776482582	CHEMBL155607,TN,INACT,0.0	CHEMBL3657378,TP,ACT,1.0	CHEMBL1922122,TN,INACT,0.0	CHEMBL2335377,TN,INACT,0.019999999552965164	CHEMBL489344,TN,INACT,0.09000000357627869	CHEMBL1908395,FN,ACT,0.009999999776482582	CHEMBL3645108,TP,ACT,0.9900000095367432	CHEMBL3642280,FN,ACT,0.4099999964237213	CHEMBL3657381,TP,ACT,1.0	CHEMBL3393272,FN,ACT,0.4699999988079071	CHEMBL1910373,TN,INACT,0.0	CHEMBL3645088,TP,ACT,1.0	CHEMBL3657370,TP,ACT,1.0	CHEMBL293250,TN,INACT,0.009999999776482582	CHEMBL2062800,TP,ACT,1.0	CHEMBL111443,TN,INACT,0.0	CHEMBL3691629,TN,INACT,0.009999999776482582	CHEMBL543600,TN,INACT,0.009999999776482582	CHEMBL3661459,TP,ACT,1.0	CHEMBL3692184,FN,ACT,0.009999999776482582	CHEMBL3657405,TP,ACT,1.0	CHEMBL3393273,FN,ACT,0.0	CHEMBL208368,TP,ACT,1.0	CHEMBL208939,FN,ACT,0.4099999964237213	CHEMBL2315561,TP,ACT,1.0	CHEMBL3261194,FP,INACT,0.6600000262260437	CHEMBL3645064,TP,ACT,1.0	CHEMBL1241862,TN,INACT,0.0	CHEMBL3645068,TP,ACT,1.0	CHEMBL3642408,FN,ACT,0.009999999776482582	CHEMBL3657360,TP,ACT,1.0	CHEMBL3661433,TP,ACT,0.9900000095367432	CHEMBL136289,TN,INACT,0.0	CHEMBL114073,TN,INACT,0.009999999776482582	CHEMBL379969,TP,ACT,0.6000000238418579	CHEMBL3657274,TP,ACT,1.0	CHEMBL173478,TN,INACT,0.019999999552965164	CHEMBL552136,TN,INACT,0.0	CHEMBL489627,TN,INACT,0.0	CHEMBL2337369,TN,INACT,0.0	CHEMBL487229,TP,ACT,1.0	CHEMBL1257912,FN,ACT,0.0	CHEMBL2086738,TN,INACT,0.0	CHEMBL324439,TN,INACT,0.0	CHEMBL457047,TN,INACT,0.0	CHEMBL3642334,FN,ACT,0.4699999988079071	CHEMBL550608,TN,INACT,0.009999999776482582	CHEMBL3680464,TN,INACT,0.009999999776482582	CHEMBL246167,TN,INACT,0.05999999865889549	CHEMBL3642376,TP,ACT,1.0	CHEMBL3657362,TP,ACT,0.9800000190734863	CHEMBL3661426,TP,ACT,0.7599999904632568	CHEMBL79808,TN,INACT,0.0	CHEMBL3645063,TP,ACT,1.0	CHEMBL3799956,TN,INACT,0.0	CHEMBL3665656,TN,INACT,0.009999999776482582	CHEMBL3645047,TP,ACT,1.0	CHEMBL151,TN,INACT,0.009999999776482582	CHEMBL3642421,FN,ACT,0.10999999940395355	CHEMBL1241679,TN,INACT,0.0	CHEMBL3657291,TP,ACT,1.0	CHEMBL74645,TN,INACT,0.0	CHEMBL209148,FP,INACT,0.8299999833106995	CHEMBL3657351,TP,ACT,1.0	CHEMBL2392366,TN,INACT,0.0	CHEMBL3657287,TP,ACT,1.0	CHEMBL3421979,TN,INACT,0.0	CHEMBL122721,TN,INACT,0.0	CHEMBL558601,TN,INACT,0.0	CHEMBL44,TN,INACT,0.0	CHEMBL1171273,TN,INACT,0.0	CHEMBL295316,TN,INACT,0.009999999776482582	CHEMBL3657388,TP,ACT,1.0	CHEMBL1241583,TN,INACT,0.0	CHEMBL1222565,TN,INACT,0.0	CHEMBL3657341,TP,ACT,1.0	CHEMBL445420,TN,INACT,0.0	CHEMBL568729,FN,ACT,0.5099999904632568	CHEMBL3823628,TN,INACT,0.09000000357627869	CHEMBL3642343,TP,ACT,1.0	CHEMBL2392379,TN,INACT,0.0	CHEMBL3665880,TP,ACT,1.0	CHEMBL2062811,TP,ACT,1.0	CHEMBL309937,TN,INACT,0.0	CHEMBL380515,TP,ACT,1.0	CHEMBL3393282,TP,ACT,1.0	CHEMBL3393285,FN,ACT,0.0	CHEMBL3665882,TP,ACT,0.9900000095367432	CHEMBL2392246,TN,INACT,0.009999999776482582	CHEMBL3657284,TP,ACT,0.9900000095367432	CHEMBL2312645,TN,INACT,0.0	CHEMBL3692173,TP,ACT,0.9800000190734863	CHEMBL3657310,TP,ACT,1.0	CHEMBL316887,TN,INACT,0.0	CHEMBL3645095,TP,ACT,1.0	CHEMBL3665866,TP,ACT,1.0	CHEMBL3545110,TN,INACT,0.029999999329447746	CHEMBL2372113,TN,INACT,0.4000000059604645	CHEMBL2409581,FN,ACT,0.41999998688697815	CHEMBL474015,TN,INACT,0.0	CHEMBL3623844,TN,INACT,0.0	CHEMBL2036866,TP,ACT,0.9900000095367432	CHEMBL3642317,TP,ACT,1.0	CHEMBL279035,TN,INACT,0.07000000029802322	CHEMBL472212,TP,ACT,1.0	CHEMBL1094475,TN,INACT,0.0	CHEMBL3657308,TP,ACT,1.0	CHEMBL470314,FN,ACT,0.0	CHEMBL1830266,TN,INACT,0.0	CHEMBL3645043,TP,ACT,1.0	CHEMBL131098,TN,INACT,0.0	CHEMBL1288067,TN,INACT,0.0	CHEMBL2409586,FN,ACT,0.009999999776482582	CHEMBL2393371,FN,ACT,0.0	CHEMBL1891423,TN,INACT,0.009999999776482582	CHEMBL334032,TN,INACT,0.009999999776482582	CHEMBL456797,TN,INACT,0.0	CHEMBL3609567,TN,INACT,0.0	CHEMBL603469,TP,ACT,1.0	CHEMBL1929304,TN,INACT,0.0	CHEMBL2392235,TN,INACT,0.0	CHEMBL3645073,TP,ACT,1.0	CHEMBL498249,TN,INACT,0.0	CHEMBL3692169,TP,ACT,1.0	CHEMBL3393286,TP,ACT,1.0	CHEMBL550856,TN,INACT,0.0	CHEMBL3665908,TP,ACT,1.0	CHEMBL3642294,TP,ACT,1.0	CHEMBL207499,FN,ACT,0.47999998927116394	CHEMBL3657353,TP,ACT,1.0	CHEMBL3661454,TP,ACT,1.0	CHEMBL2425141,TN,INACT,0.05000000074505806	CHEMBL1242844,TN,INACT,0.0	CHEMBL1929306,TN,INACT,0.0	CHEMBL1910759,TN,INACT,0.0	CHEMBL558849,TN,INACT,0.0	CHEMBL2163623,TN,INACT,0.009999999776482582	CHEMBL1801932,TN,INACT,0.0	CHEMBL264666,TN,INACT,0.0	CHEMBL3657363,TP,ACT,1.0	CHEMBL2062801,TP,ACT,1.0	CHEMBL3642393,TP,ACT,0.9900000095367432	CHEMBL2392234,TN,INACT,0.0	CHEMBL497454,TN,INACT,0.0	CHEMBL3661451,TP,ACT,1.0	CHEMBL563733,TN,INACT,0.0	CHEMBL3645066,TP,ACT,1.0	CHEMBL3642323,TP,ACT,1.0	CHEMBL3645092,TP,ACT,0.9800000190734863	CHEMBL3642387,TP,ACT,1.0	CHEMBL101558,TN,INACT,0.0	CHEMBL360190,FN,ACT,0.029999999329447746	CHEMBL2163610,TN,INACT,0.0	CHEMBL102136,TN,INACT,0.0	CHEMBL1910278,TN,INACT,0.0	CHEMBL3661092,TN,INACT,0.009999999776482582	CHEMBL291313,TN,INACT,0.009999999776482582	CHEMBL590568,TN,INACT,0.0	CHEMBL1929555,TN,INACT,0.0	CHEMBL518905,FN,ACT,0.019999999552965164	CHEMBL2409592,TP,ACT,1.0	CHEMBL3661421,TP,ACT,1.0	CHEMBL208384,FN,ACT,0.41999998688697815	CHEMBL3642327,TP,ACT,0.8600000143051147	CHEMBL3661423,TP,ACT,1.0	CHEMBL3237858,TN,INACT,0.029999999329447746	CHEMBL3645017,TP,ACT,1.0	CHEMBL469776,TN,INACT,0.0	CHEMBL103667,FN,ACT,0.029999999329447746	CHEMBL380683,TP,ACT,0.7599999904632568	CHEMBL1688208,TN,INACT,0.0	CHEMBL205942,FN,ACT,0.4699999988079071	CHEMBL3657253,TP,ACT,1.0	CHEMBL180022,FN,ACT,0.07999999821186066	CHEMBL3665913,TP,ACT,1.0	CHEMBL3780752,TP,ACT,0.9700000286102295	CHEMBL14326,TN,INACT,0.029999999329447746	CHEMBL2029691,TN,INACT,0.0	CHEMBL2414545,TP,ACT,1.0	CHEMBL3657279,TP,ACT,1.0	CHEMBL3133911,TN,INACT,0.4300000071525574	CHEMBL3665934,TP,ACT,1.0	CHEMBL3657276,FN,ACT,0.009999999776482582	CHEMBL3645041,TP,ACT,1.0	CHEMBL348146,TN,INACT,0.0	CHEMBL1240703,TP,ACT,0.9399999976158142	CHEMBL3665902,TP,ACT,0.7900000214576721	CHEMBL518060,TP,ACT,0.9700000286102295	CHEMBL8223,TN,INACT,0.4699999988079071	CHEMBL549303,TN,INACT,0.0	CHEMBL483234,TN,INACT,0.0	CHEMBL464552,FN,ACT,0.0	CHEMBL3657366,TP,ACT,1.0	CHEMBL1934345,TP,ACT,1.0	CHEMBL3692205,TP,ACT,0.9200000166893005	CHEMBL3665911,TP,ACT,0.9800000190734863	CHEMBL487246,TP,ACT,1.0	CHEMBL3645087,TP,ACT,1.0	CHEMBL3657350,TP,ACT,1.0	CHEMBL335938,TN,INACT,0.0	CHEMBL515258,FP,INACT,0.7200000286102295	CHEMBL564726,TN,INACT,0.0	CHEMBL2333445,FN,ACT,0.009999999776482582	CHEMBL2409579,FN,ACT,0.4000000059604645	CHEMBL554,TN,INACT,0.5699999928474426	CHEMBL337454,TN,INACT,0.0	CHEMBL209511,TN,INACT,0.009999999776482582	CHEMBL3261182,FN,ACT,0.11999999731779099	CHEMBL2029523,TN,INACT,0.0	CHEMBL1171912,TN,INACT,0.0	CHEMBL2426288,TN,INACT,0.36000001430511475	CHEMBL245966,TN,INACT,0.0	CHEMBL3645103,TP,ACT,0.9100000262260437	CHEMBL1910755,TN,INACT,0.0	CHEMBL131653,TN,INACT,0.0	CHEMBL1257164,TN,INACT,0.009999999776482582	CHEMBL3644956,TP,ACT,1.0	CHEMBL3661447,TP,ACT,1.0	CHEMBL2409605,TP,ACT,0.9100000262260437	CHEMBL3353407,TN,INACT,0.17000000178813934	CHEMBL2337366,TN,INACT,0.009999999776482582	CHEMBL1641997,TN,INACT,0.0	CHEMBL299763,TN,INACT,0.0	CHEMBL2315579,TP,ACT,1.0	CHEMBL570369,FN,ACT,0.23999999463558197	CHEMBL3657257,TP,ACT,1.0	CHEMBL2393384,TP,ACT,0.8500000238418579	CHEMBL233349,TN,INACT,0.0	CHEMBL3661422,TP,ACT,1.0	CHEMBL3665940,TP,ACT,1.0	CHEMBL3692195,TP,ACT,1.0	CHEMBL499587,TN,INACT,0.3400000035762787	CHEMBL230761,TN,INACT,0.0	CHEMBL206978,FN,ACT,0.33000001311302185	CHEMBL1173398,TN,INACT,0.0	CHEMBL2393383,FN,ACT,0.03999999910593033	CHEMBL133213,TN,INACT,0.0	CHEMBL2207427,TP,ACT,0.9900000095367432	CHEMBL3657380,TP,ACT,1.0	CHEMBL205588,TP,ACT,1.0	CHEMBL3642337,TP,ACT,0.7599999904632568	CHEMBL2062804,TP,ACT,1.0	CHEMBL1973716,TN,INACT,0.019999999552965164	CHEMBL1828880,TN,INACT,0.0	CHEMBL1934334,TP,ACT,1.0	CHEMBL3642253,TP,ACT,1.0	CHEMBL382809,FN,ACT,0.009999999776482582	CHEMBL383263,TP,ACT,1.0	CHEMBL379118,FN,ACT,0.03999999910593033	CHEMBL3325480,TN,INACT,0.019999999552965164	CHEMBL2426377,TN,INACT,0.15000000596046448	CHEMBL3661456,TP,ACT,1.0	CHEMBL3645077,TP,ACT,1.0	CHEMBL495617,TN,INACT,0.009999999776482582	CHEMBL1909651,TN,INACT,0.009999999776482582	CHEMBL77732,TN,INACT,0.0	CHEMBL1683952,TN,INACT,0.0	

