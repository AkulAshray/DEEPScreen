CNNModel CHEMBL3358 RMSprop 0.0005 30 256 0 0.6 False True
Number of active compounds :	589
Number of inactive compounds :	589
---------------------------------
Run id: CNNModel_CHEMBL3358_RMSprop_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3358_RMSprop_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 748
Validation samples: 234
--
Training Step: 1  | time: 1.679s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/748
[A[ATraining Step: 2  | total loss: [1m[32m0.62405[0m[0m | time: 2.992s
[2K
| RMSProp | epoch: 001 | loss: 0.62405 - acc: 0.4219 -- iter: 064/748
[A[ATraining Step: 3  | total loss: [1m[32m0.68069[0m[0m | time: 4.219s
[2K
| RMSProp | epoch: 001 | loss: 0.68069 - acc: 0.4602 -- iter: 096/748
[A[ATraining Step: 4  | total loss: [1m[32m0.68958[0m[0m | time: 5.320s
[2K
| RMSProp | epoch: 001 | loss: 0.68958 - acc: 0.6072 -- iter: 128/748
[A[ATraining Step: 5  | total loss: [1m[32m0.69166[0m[0m | time: 6.535s
[2K
| RMSProp | epoch: 001 | loss: 0.69166 - acc: 0.5979 -- iter: 160/748
[A[ATraining Step: 6  | total loss: [1m[32m0.69296[0m[0m | time: 7.800s
[2K
| RMSProp | epoch: 001 | loss: 0.69296 - acc: 0.4948 -- iter: 192/748
[A[ATraining Step: 7  | total loss: [1m[32m0.69259[0m[0m | time: 8.854s
[2K
| RMSProp | epoch: 001 | loss: 0.69259 - acc: 0.6104 -- iter: 224/748
[A[ATraining Step: 8  | total loss: [1m[32m0.69263[0m[0m | time: 9.736s
[2K
| RMSProp | epoch: 001 | loss: 0.69263 - acc: 0.6362 -- iter: 256/748
[A[ATraining Step: 9  | total loss: [1m[32m0.69308[0m[0m | time: 10.753s
[2K
| RMSProp | epoch: 001 | loss: 0.69308 - acc: 0.5310 -- iter: 288/748
[A[ATraining Step: 10  | total loss: [1m[32m0.69288[0m[0m | time: 11.934s
[2K
| RMSProp | epoch: 001 | loss: 0.69288 - acc: 0.5780 -- iter: 320/748
[A[ATraining Step: 11  | total loss: [1m[32m0.69344[0m[0m | time: 13.165s
[2K
| RMSProp | epoch: 001 | loss: 0.69344 - acc: 0.4670 -- iter: 352/748
[A[ATraining Step: 12  | total loss: [1m[32m0.69370[0m[0m | time: 14.211s
[2K
| RMSProp | epoch: 001 | loss: 0.69370 - acc: 0.4116 -- iter: 384/748
[A[ATraining Step: 13  | total loss: [1m[32m0.69362[0m[0m | time: 15.355s
[2K
| RMSProp | epoch: 001 | loss: 0.69362 - acc: 0.4361 -- iter: 416/748
[A[ATraining Step: 14  | total loss: [1m[32m0.69344[0m[0m | time: 16.599s
[2K
| RMSProp | epoch: 001 | loss: 0.69344 - acc: 0.4750 -- iter: 448/748
[A[ATraining Step: 15  | total loss: [1m[32m0.69351[0m[0m | time: 17.619s
[2K
| RMSProp | epoch: 001 | loss: 0.69351 - acc: 0.4359 -- iter: 480/748
[A[ATraining Step: 16  | total loss: [1m[32m0.69324[0m[0m | time: 18.710s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.4834 -- iter: 512/748
[A[ATraining Step: 17  | total loss: [1m[32m0.69334[0m[0m | time: 19.820s
[2K
| RMSProp | epoch: 001 | loss: 0.69334 - acc: 0.4556 -- iter: 544/748
[A[ATraining Step: 18  | total loss: [1m[32m0.69338[0m[0m | time: 20.874s
[2K
| RMSProp | epoch: 001 | loss: 0.69338 - acc: 0.4493 -- iter: 576/748
[A[ATraining Step: 19  | total loss: [1m[32m0.69310[0m[0m | time: 21.911s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5183 -- iter: 608/748
[A[ATraining Step: 20  | total loss: [1m[32m0.69326[0m[0m | time: 23.036s
[2K
| RMSProp | epoch: 001 | loss: 0.69326 - acc: 0.4823 -- iter: 640/748
[A[ATraining Step: 21  | total loss: [1m[32m0.69304[0m[0m | time: 24.116s
[2K
| RMSProp | epoch: 001 | loss: 0.69304 - acc: 0.5169 -- iter: 672/748
[A[ATraining Step: 22  | total loss: [1m[32m0.69310[0m[0m | time: 25.220s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.5024 -- iter: 704/748
[A[ATraining Step: 23  | total loss: [1m[32m0.69314[0m[0m | time: 26.261s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.5017 -- iter: 736/748
[A[ATraining Step: 24  | total loss: [1m[32m0.69313[0m[0m | time: 27.600s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.5012 | val_loss: 0.69312 - val_acc: 0.5085 -- iter: 748/748
--
Training Step: 25  | total loss: [1m[32m0.69328[0m[0m | time: 0.338s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4782 -- iter: 032/748
[A[ATraining Step: 26  | total loss: [1m[32m0.69321[0m[0m | time: 1.209s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4840 -- iter: 064/748
[A[ATraining Step: 27  | total loss: [1m[32m0.69312[0m[0m | time: 1.933s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5042 -- iter: 096/748
[A[ATraining Step: 28  | total loss: [1m[32m0.69325[0m[0m | time: 2.724s
[2K
| RMSProp | epoch: 002 | loss: 0.69325 - acc: 0.4875 -- iter: 128/748
[A[ATraining Step: 29  | total loss: [1m[32m0.69307[0m[0m | time: 3.522s
[2K
| RMSProp | epoch: 002 | loss: 0.69307 - acc: 0.5285 -- iter: 160/748
[A[ATraining Step: 30  | total loss: [1m[32m0.69316[0m[0m | time: 4.350s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.5070 -- iter: 192/748
[A[ATraining Step: 31  | total loss: [1m[32m0.69330[0m[0m | time: 5.183s
[2K
| RMSProp | epoch: 002 | loss: 0.69330 - acc: 0.4765 -- iter: 224/748
[A[ATraining Step: 32  | total loss: [1m[32m0.69340[0m[0m | time: 6.105s
[2K
| RMSProp | epoch: 002 | loss: 0.69340 - acc: 0.4466 -- iter: 256/748
[A[ATraining Step: 33  | total loss: [1m[32m0.69321[0m[0m | time: 7.096s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4858 -- iter: 288/748
[A[ATraining Step: 34  | total loss: [1m[32m0.69320[0m[0m | time: 7.865s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4821 -- iter: 320/748
[A[ATraining Step: 35  | total loss: [1m[32m0.69324[0m[0m | time: 8.623s
[2K
| RMSProp | epoch: 002 | loss: 0.69324 - acc: 0.4793 -- iter: 352/748
[A[ATraining Step: 36  | total loss: [1m[32m0.69326[0m[0m | time: 9.470s
[2K
| RMSProp | epoch: 002 | loss: 0.69326 - acc: 0.4772 -- iter: 384/748
[A[ATraining Step: 37  | total loss: [1m[32m0.69320[0m[0m | time: 10.346s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4880 -- iter: 416/748
[A[ATraining Step: 38  | total loss: [1m[32m0.69314[0m[0m | time: 11.166s
[2K
| RMSProp | epoch: 002 | loss: 0.69314 - acc: 0.4842 -- iter: 448/748
[A[ATraining Step: 39  | total loss: [1m[32m0.69323[0m[0m | time: 12.031s
[2K
| RMSProp | epoch: 002 | loss: 0.69323 - acc: 0.4454 -- iter: 480/748
[A[ATraining Step: 40  | total loss: [1m[32m0.69320[0m[0m | time: 12.879s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4790 -- iter: 512/748
[A[ATraining Step: 41  | total loss: [1m[32m0.69310[0m[0m | time: 13.785s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5116 -- iter: 544/748
[A[ATraining Step: 42  | total loss: [1m[32m0.69305[0m[0m | time: 14.650s
[2K
| RMSProp | epoch: 002 | loss: 0.69305 - acc: 0.5264 -- iter: 576/748
[A[ATraining Step: 43  | total loss: [1m[32m0.69308[0m[0m | time: 15.483s
[2K
| RMSProp | epoch: 002 | loss: 0.69308 - acc: 0.5272 -- iter: 608/748
[A[ATraining Step: 44  | total loss: [1m[32m0.69312[0m[0m | time: 16.245s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5171 -- iter: 640/748
[A[ATraining Step: 45  | total loss: [1m[32m0.69315[0m[0m | time: 17.222s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.4930 -- iter: 672/748
[A[ATraining Step: 46  | total loss: [1m[32m0.69313[0m[0m | time: 18.253s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5046 -- iter: 704/748
[A[ATraining Step: 47  | total loss: [1m[32m0.69311[0m[0m | time: 19.077s
[2K
| RMSProp | epoch: 002 | loss: 0.69311 - acc: 0.5089 -- iter: 736/748
[A[ATraining Step: 48  | total loss: [1m[32m0.69317[0m[0m | time: 21.280s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4924 | val_loss: 0.69312 - val_acc: 0.5085 -- iter: 748/748
--
Training Step: 49  | total loss: [1m[32m0.69315[0m[0m | time: 0.495s
[2K
| RMSProp | epoch: 003 | loss: 0.69315 - acc: 0.5035 -- iter: 032/748
[A[ATraining Step: 50  | total loss: [1m[32m0.69320[0m[0m | time: 0.979s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.4900 -- iter: 064/748
[A[ATraining Step: 51  | total loss: [1m[32m0.69321[0m[0m | time: 2.343s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4661 -- iter: 096/748
[A[ATraining Step: 52  | total loss: [1m[32m0.69322[0m[0m | time: 6.490s
[2K
| RMSProp | epoch: 003 | loss: 0.69322 - acc: 0.4525 -- iter: 128/748
[A[ATraining Step: 53  | total loss: [1m[32m0.69318[0m[0m | time: 12.294s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.4687 -- iter: 160/748
[A[ATraining Step: 54  | total loss: [1m[32m0.69317[0m[0m | time: 13.408s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.4642 -- iter: 192/748
[A[ATraining Step: 55  | total loss: [1m[32m0.69323[0m[0m | time: 14.470s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4514 -- iter: 224/748
[A[ATraining Step: 56  | total loss: [1m[32m0.69319[0m[0m | time: 15.709s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.4846 -- iter: 256/748
[A[ATraining Step: 57  | total loss: [1m[32m0.69317[0m[0m | time: 16.947s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.4954 -- iter: 288/748
[A[ATraining Step: 58  | total loss: [1m[32m0.69329[0m[0m | time: 18.094s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.4790 -- iter: 320/748
[A[ATraining Step: 59  | total loss: [1m[32m0.69326[0m[0m | time: 19.233s
[2K
| RMSProp | epoch: 003 | loss: 0.69326 - acc: 0.4902 -- iter: 352/748
[A[ATraining Step: 60  | total loss: [1m[32m0.69325[0m[0m | time: 20.481s
[2K
| RMSProp | epoch: 003 | loss: 0.69325 - acc: 0.4874 -- iter: 384/748
[A[ATraining Step: 61  | total loss: [1m[32m0.69324[0m[0m | time: 21.611s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.4890 -- iter: 416/748
[A[ATraining Step: 62  | total loss: [1m[32m0.69323[0m[0m | time: 22.734s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4904 -- iter: 448/748
[A[ATraining Step: 63  | total loss: [1m[32m0.69321[0m[0m | time: 23.988s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4916 -- iter: 480/748
[A[ATraining Step: 64  | total loss: [1m[32m0.69324[0m[0m | time: 25.242s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.4771 -- iter: 512/748
[A[ATraining Step: 65  | total loss: [1m[32m0.69324[0m[0m | time: 27.687s
[2K
| RMSProp | epoch: 003 | loss: 0.69324 - acc: 0.4606 -- iter: 544/748
[A[ATraining Step: 66  | total loss: [1m[32m0.69322[0m[0m | time: 29.954s
[2K
| RMSProp | epoch: 003 | loss: 0.69322 - acc: 0.4578 -- iter: 576/748
[A[ATraining Step: 67  | total loss: [1m[32m0.69323[0m[0m | time: 30.980s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4629 -- iter: 608/748
[A[ATraining Step: 68  | total loss: [1m[32m0.69320[0m[0m | time: 32.080s
[2K
| RMSProp | epoch: 003 | loss: 0.69320 - acc: 0.4710 -- iter: 640/748
[A[ATraining Step: 69  | total loss: [1m[32m0.69325[0m[0m | time: 33.284s
[2K
| RMSProp | epoch: 003 | loss: 0.69325 - acc: 0.4707 -- iter: 672/748
[A[ATraining Step: 70  | total loss: [1m[32m0.69323[0m[0m | time: 34.510s
[2K
| RMSProp | epoch: 003 | loss: 0.69323 - acc: 0.4813 -- iter: 704/748
[A[ATraining Step: 71  | total loss: [1m[32m0.69319[0m[0m | time: 35.753s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.4941 -- iter: 736/748
[A[ATraining Step: 72  | total loss: [1m[32m0.69321[0m[0m | time: 38.496s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4948 | val_loss: 0.69313 - val_acc: 0.5085 -- iter: 748/748
--
Training Step: 73  | total loss: [1m[32m0.69321[0m[0m | time: 1.116s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.4954 -- iter: 032/748
[A[ATraining Step: 74  | total loss: [1m[32m0.69322[0m[0m | time: 1.589s
[2K
| RMSProp | epoch: 004 | loss: 0.69322 - acc: 0.4924 -- iter: 064/748
[A[ATraining Step: 75  | total loss: [1m[32m0.69321[0m[0m | time: 2.110s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.4842 -- iter: 096/748
[A[ATraining Step: 76  | total loss: [1m[32m0.69321[0m[0m | time: 3.362s
[2K
| RMSProp | epoch: 004 | loss: 0.69321 - acc: 0.4770 -- iter: 128/748
[A[ATraining Step: 77  | total loss: [1m[32m0.69318[0m[0m | time: 5.158s
[2K
| RMSProp | epoch: 004 | loss: 0.69318 - acc: 0.4860 -- iter: 160/748
[A[ATraining Step: 78  | total loss: [1m[32m0.69325[0m[0m | time: 7.377s
[2K
| RMSProp | epoch: 004 | loss: 0.69325 - acc: 0.4777 -- iter: 192/748
[A[ATraining Step: 79  | total loss: [1m[32m0.69327[0m[0m | time: 8.454s
[2K
| RMSProp | epoch: 004 | loss: 0.69327 - acc: 0.4735 -- iter: 224/748
[A[ATraining Step: 80  | total loss: [1m[32m0.69324[0m[0m | time: 9.552s
[2K
| RMSProp | epoch: 004 | loss: 0.69324 - acc: 0.4794 -- iter: 256/748
[A[ATraining Step: 81  | total loss: [1m[32m0.69323[0m[0m | time: 10.850s
[2K
| RMSProp | epoch: 004 | loss: 0.69323 - acc: 0.4847 -- iter: 288/748
[A[ATraining Step: 82  | total loss: [1m[32m0.69320[0m[0m | time: 12.082s
[2K
| RMSProp | epoch: 004 | loss: 0.69320 - acc: 0.4925 -- iter: 320/748
[A[ATraining Step: 83  | total loss: [1m[32m0.69331[0m[0m | time: 13.294s
[2K
| RMSProp | epoch: 004 | loss: 0.69331 - acc: 0.4776 -- iter: 352/748
[A[ATraining Step: 84  | total loss: [1m[32m0.69328[0m[0m | time: 14.573s
[2K
| RMSProp | epoch: 004 | loss: 0.69328 - acc: 0.4798 -- iter: 384/748
[A[ATraining Step: 85  | total loss: [1m[32m0.69328[0m[0m | time: 15.912s
[2K
| RMSProp | epoch: 004 | loss: 0.69328 - acc: 0.4850 -- iter: 416/748
[A[ATraining Step: 86  | total loss: [1m[32m0.69332[0m[0m | time: 17.085s
[2K
| RMSProp | epoch: 004 | loss: 0.69332 - acc: 0.4740 -- iter: 448/748
[A[ATraining Step: 87  | total loss: [1m[32m0.69334[0m[0m | time: 18.290s
[2K
| RMSProp | epoch: 004 | loss: 0.69334 - acc: 0.4547 -- iter: 480/748
[A[ATraining Step: 88  | total loss: [1m[32m0.69331[0m[0m | time: 19.659s
[2K
| RMSProp | epoch: 004 | loss: 0.69331 - acc: 0.4655 -- iter: 512/748
[A[ATraining Step: 89  | total loss: [1m[32m0.69327[0m[0m | time: 20.964s
[2K
| RMSProp | epoch: 004 | loss: 0.69327 - acc: 0.4814 -- iter: 544/748
[A[ATraining Step: 90  | total loss: [1m[32m0.69335[0m[0m | time: 25.495s
[2K
| RMSProp | epoch: 004 | loss: 0.69335 - acc: 0.4614 -- iter: 576/748
[A[ATraining Step: 91  | total loss: [1m[32m0.69337[0m[0m | time: 30.983s
[2K
| RMSProp | epoch: 004 | loss: 0.69337 - acc: 0.4528 -- iter: 608/748
[A[ATraining Step: 92  | total loss: [1m[32m0.69334[0m[0m | time: 38.116s
[2K
| RMSProp | epoch: 004 | loss: 0.69334 - acc: 0.4544 -- iter: 640/748
[A[ATraining Step: 93  | total loss: [1m[32m0.69333[0m[0m | time: 39.388s
[2K
| RMSProp | epoch: 004 | loss: 0.69333 - acc: 0.4558 -- iter: 672/748
[A[ATraining Step: 94  | total loss: [1m[32m0.69331[0m[0m | time: 40.648s
[2K
| RMSProp | epoch: 004 | loss: 0.69331 - acc: 0.4634 -- iter: 704/748
[A[ATraining Step: 95  | total loss: [1m[32m0.69331[0m[0m | time: 41.673s
[2K
| RMSProp | epoch: 004 | loss: 0.69331 - acc: 0.4670 -- iter: 736/748
[A[ATraining Step: 96  | total loss: [1m[32m0.69331[0m[0m | time: 43.972s
[2K
| RMSProp | epoch: 004 | loss: 0.69331 - acc: 0.4703 | val_loss: 0.69311 - val_acc: 0.5085 -- iter: 748/748
--
Training Step: 97  | total loss: [1m[32m0.69331[0m[0m | time: 0.990s
[2K
| RMSProp | epoch: 005 | loss: 0.69331 - acc: 0.4702 -- iter: 032/748
[A[ATraining Step: 98  | total loss: [1m[32m0.69326[0m[0m | time: 1.859s
[2K
| RMSProp | epoch: 005 | loss: 0.69326 - acc: 0.4763 -- iter: 064/748
[A[ATraining Step: 99  | total loss: [1m[32m0.69330[0m[0m | time: 2.329s
[2K
| RMSProp | epoch: 005 | loss: 0.69330 - acc: 0.4755 -- iter: 096/748
[A[ATraining Step: 100  | total loss: [1m[32m0.69336[0m[0m | time: 2.791s
[2K
| RMSProp | epoch: 005 | loss: 0.69336 - acc: 0.4613 -- iter: 128/748
[A[ATraining Step: 101  | total loss: [1m[32m0.69314[0m[0m | time: 3.756s
[2K
| RMSProp | epoch: 005 | loss: 0.69314 - acc: 0.4902 -- iter: 160/748
[A[ATraining Step: 102  | total loss: [1m[32m0.69321[0m[0m | time: 4.622s
[2K
| RMSProp | epoch: 005 | loss: 0.69321 - acc: 0.4880 -- iter: 192/748
[A[ATraining Step: 103  | total loss: [1m[32m0.69331[0m[0m | time: 5.546s
[2K
| RMSProp | epoch: 005 | loss: 0.69331 - acc: 0.4830 -- iter: 224/748
[A[ATraining Step: 104  | total loss: [1m[32m0.69318[0m[0m | time: 6.457s
[2K
| RMSProp | epoch: 005 | loss: 0.69318 - acc: 0.4941 -- iter: 256/748
[A[ATraining Step: 105  | total loss: [1m[32m0.69329[0m[0m | time: 7.369s
[2K
| RMSProp | epoch: 005 | loss: 0.69329 - acc: 0.4884 -- iter: 288/748
[A[ATraining Step: 106  | total loss: [1m[32m0.69319[0m[0m | time: 8.334s
[2K
| RMSProp | epoch: 005 | loss: 0.69319 - acc: 0.4958 -- iter: 320/748
[A[ATraining Step: 107  | total loss: [1m[32m0.69325[0m[0m | time: 9.403s
[2K
| RMSProp | epoch: 005 | loss: 0.69325 - acc: 0.4931 -- iter: 352/748
[A[ATraining Step: 108  | total loss: [1m[32m0.69330[0m[0m | time: 10.400s
[2K
| RMSProp | epoch: 005 | loss: 0.69330 - acc: 0.4907 -- iter: 384/748
[A[ATraining Step: 109  | total loss: [1m[32m0.69338[0m[0m | time: 11.402s
[2K
| RMSProp | epoch: 005 | loss: 0.69338 - acc: 0.4853 -- iter: 416/748
[A[ATraining Step: 110  | total loss: [1m[32m0.69335[0m[0m | time: 12.467s
[2K
| RMSProp | epoch: 005 | loss: 0.69335 - acc: 0.4868 -- iter: 448/748
[A[ATraining Step: 111  | total loss: [1m[32m0.69306[0m[0m | time: 13.309s
[2K
| RMSProp | epoch: 005 | loss: 0.69306 - acc: 0.5163 -- iter: 480/748
[A[ATraining Step: 112  | total loss: [1m[32m0.69353[0m[0m | time: 14.057s
[2K
| RMSProp | epoch: 005 | loss: 0.69353 - acc: 0.4959 -- iter: 512/748
[A[ATraining Step: 113  | total loss: [1m[32m0.69356[0m[0m | time: 14.939s
[2K
| RMSProp | epoch: 005 | loss: 0.69356 - acc: 0.4932 -- iter: 544/748
[A[ATraining Step: 114  | total loss: [1m[32m0.69349[0m[0m | time: 15.877s
[2K
| RMSProp | epoch: 005 | loss: 0.69349 - acc: 0.4939 -- iter: 576/748
[A[ATraining Step: 115  | total loss: [1m[32m0.69340[0m[0m | time: 16.770s
[2K
| RMSProp | epoch: 005 | loss: 0.69340 - acc: 0.4976 -- iter: 608/748
[A[ATraining Step: 116  | total loss: [1m[32m0.69345[0m[0m | time: 17.724s
[2K
| RMSProp | epoch: 005 | loss: 0.69345 - acc: 0.4916 -- iter: 640/748
[A[ATraining Step: 117  | total loss: [1m[32m0.69333[0m[0m | time: 18.661s
[2K
| RMSProp | epoch: 005 | loss: 0.69333 - acc: 0.4987 -- iter: 672/748
[A[ATraining Step: 118  | total loss: [1m[32m0.69335[0m[0m | time: 19.523s
[2K
| RMSProp | epoch: 005 | loss: 0.69335 - acc: 0.4957 -- iter: 704/748
[A[ATraining Step: 119  | total loss: [1m[32m0.69333[0m[0m | time: 20.425s
[2K
| RMSProp | epoch: 005 | loss: 0.69333 - acc: 0.4961 -- iter: 736/748
[A[ATraining Step: 120  | total loss: [1m[32m0.69339[0m[0m | time: 22.491s
[2K
| RMSProp | epoch: 005 | loss: 0.69339 - acc: 0.4903 | val_loss: 0.69324 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 121  | total loss: [1m[32m0.69333[0m[0m | time: 0.914s
[2K
| RMSProp | epoch: 006 | loss: 0.69333 - acc: 0.4975 -- iter: 032/748
[A[ATraining Step: 122  | total loss: [1m[32m0.69323[0m[0m | time: 1.691s
[2K
| RMSProp | epoch: 006 | loss: 0.69323 - acc: 0.5071 -- iter: 064/748
[A[ATraining Step: 123  | total loss: [1m[32m0.69321[0m[0m | time: 2.536s
[2K
| RMSProp | epoch: 006 | loss: 0.69321 - acc: 0.5064 -- iter: 096/748
[A[ATraining Step: 124  | total loss: [1m[32m0.69317[0m[0m | time: 2.877s
[2K
| RMSProp | epoch: 006 | loss: 0.69317 - acc: 0.5058 -- iter: 128/748
[A[ATraining Step: 125  | total loss: [1m[32m0.69330[0m[0m | time: 3.220s
[2K
| RMSProp | epoch: 006 | loss: 0.69330 - acc: 0.4968 -- iter: 160/748
[A[ATraining Step: 126  | total loss: [1m[32m0.69339[0m[0m | time: 4.086s
[2K
| RMSProp | epoch: 006 | loss: 0.69339 - acc: 0.4888 -- iter: 192/748
[A[ATraining Step: 127  | total loss: [1m[32m0.69336[0m[0m | time: 5.047s
[2K
| RMSProp | epoch: 006 | loss: 0.69336 - acc: 0.5056 -- iter: 224/748
[A[ATraining Step: 128  | total loss: [1m[32m0.69331[0m[0m | time: 5.929s
[2K
| RMSProp | epoch: 006 | loss: 0.69331 - acc: 0.5081 -- iter: 256/748
[A[ATraining Step: 129  | total loss: [1m[32m0.69323[0m[0m | time: 6.929s
[2K
| RMSProp | epoch: 006 | loss: 0.69323 - acc: 0.5136 -- iter: 288/748
[A[ATraining Step: 130  | total loss: [1m[32m0.69334[0m[0m | time: 8.020s
[2K
| RMSProp | epoch: 006 | loss: 0.69334 - acc: 0.5060 -- iter: 320/748
[A[ATraining Step: 131  | total loss: [1m[32m0.69327[0m[0m | time: 9.278s
[2K
| RMSProp | epoch: 006 | loss: 0.69327 - acc: 0.5116 -- iter: 352/748
[A[ATraining Step: 132  | total loss: [1m[32m0.69310[0m[0m | time: 10.307s
[2K
| RMSProp | epoch: 006 | loss: 0.69310 - acc: 0.5198 -- iter: 384/748
[A[ATraining Step: 133  | total loss: [1m[32m0.69325[0m[0m | time: 11.546s
[2K
| RMSProp | epoch: 006 | loss: 0.69325 - acc: 0.5116 -- iter: 416/748
[A[ATraining Step: 134  | total loss: [1m[32m0.69337[0m[0m | time: 12.815s
[2K
| RMSProp | epoch: 006 | loss: 0.69337 - acc: 0.5042 -- iter: 448/748
[A[ATraining Step: 135  | total loss: [1m[32m0.69330[0m[0m | time: 14.084s
[2K
| RMSProp | epoch: 006 | loss: 0.69330 - acc: 0.5069 -- iter: 480/748
[A[ATraining Step: 136  | total loss: [1m[32m0.69325[0m[0m | time: 15.022s
[2K
| RMSProp | epoch: 006 | loss: 0.69325 - acc: 0.5093 -- iter: 512/748
[A[ATraining Step: 137  | total loss: [1m[32m0.69346[0m[0m | time: 16.125s
[2K
| RMSProp | epoch: 006 | loss: 0.69346 - acc: 0.4959 -- iter: 544/748
[A[ATraining Step: 138  | total loss: [1m[32m0.69342[0m[0m | time: 17.328s
[2K
| RMSProp | epoch: 006 | loss: 0.69342 - acc: 0.4994 -- iter: 576/748
[A[ATraining Step: 139  | total loss: [1m[32m0.69339[0m[0m | time: 18.641s
[2K
| RMSProp | epoch: 006 | loss: 0.69339 - acc: 0.5026 -- iter: 608/748
[A[ATraining Step: 140  | total loss: [1m[32m0.69335[0m[0m | time: 21.226s
[2K
| RMSProp | epoch: 006 | loss: 0.69335 - acc: 0.5024 -- iter: 640/748
[A[ATraining Step: 141  | total loss: [1m[32m0.69332[0m[0m | time: 25.896s
[2K
| RMSProp | epoch: 006 | loss: 0.69332 - acc: 0.5021 -- iter: 672/748
[A[ATraining Step: 142  | total loss: [1m[32m0.69340[0m[0m | time: 27.066s
[2K
| RMSProp | epoch: 006 | loss: 0.69340 - acc: 0.4894 -- iter: 704/748
[A[ATraining Step: 143  | total loss: [1m[32m0.69332[0m[0m | time: 28.284s
[2K
| RMSProp | epoch: 006 | loss: 0.69332 - acc: 0.4936 -- iter: 736/748
[A[ATraining Step: 144  | total loss: [1m[32m0.69321[0m[0m | time: 31.362s
[2K
| RMSProp | epoch: 006 | loss: 0.69321 - acc: 0.5036 | val_loss: 0.69359 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 145  | total loss: [1m[32m0.69300[0m[0m | time: 1.381s
[2K
| RMSProp | epoch: 007 | loss: 0.69300 - acc: 0.5126 -- iter: 032/748
[A[ATraining Step: 146  | total loss: [1m[32m0.69311[0m[0m | time: 2.593s
[2K
| RMSProp | epoch: 007 | loss: 0.69311 - acc: 0.5082 -- iter: 064/748
[A[ATraining Step: 147  | total loss: [1m[32m0.69354[0m[0m | time: 3.620s
[2K
| RMSProp | epoch: 007 | loss: 0.69354 - acc: 0.4918 -- iter: 096/748
[A[ATraining Step: 148  | total loss: [1m[32m0.69340[0m[0m | time: 4.872s
[2K
| RMSProp | epoch: 007 | loss: 0.69340 - acc: 0.5051 -- iter: 128/748
[A[ATraining Step: 149  | total loss: [1m[32m0.69337[0m[0m | time: 5.414s
[2K
| RMSProp | epoch: 007 | loss: 0.69337 - acc: 0.5046 -- iter: 160/748
[A[ATraining Step: 150  | total loss: [1m[32m0.69301[0m[0m | time: 5.976s
[2K
| RMSProp | epoch: 007 | loss: 0.69301 - acc: 0.5208 -- iter: 192/748
[A[ATraining Step: 151  | total loss: [1m[32m0.69242[0m[0m | time: 9.823s
[2K
| RMSProp | epoch: 007 | loss: 0.69242 - acc: 0.5354 -- iter: 224/748
[A[ATraining Step: 152  | total loss: [1m[32m0.69194[0m[0m | time: 13.199s
[2K
| RMSProp | epoch: 007 | loss: 0.69194 - acc: 0.5412 -- iter: 256/748
[A[ATraining Step: 153  | total loss: [1m[32m0.69272[0m[0m | time: 14.274s
[2K
| RMSProp | epoch: 007 | loss: 0.69272 - acc: 0.5309 -- iter: 288/748
[A[ATraining Step: 154  | total loss: [1m[32m0.69295[0m[0m | time: 15.450s
[2K
| RMSProp | epoch: 007 | loss: 0.69295 - acc: 0.5246 -- iter: 320/748
[A[ATraining Step: 155  | total loss: [1m[32m0.69309[0m[0m | time: 16.585s
[2K
| RMSProp | epoch: 007 | loss: 0.69309 - acc: 0.5191 -- iter: 352/748
[A[ATraining Step: 156  | total loss: [1m[32m0.69347[0m[0m | time: 17.881s
[2K
| RMSProp | epoch: 007 | loss: 0.69347 - acc: 0.5078 -- iter: 384/748
[A[ATraining Step: 157  | total loss: [1m[32m0.69346[0m[0m | time: 19.303s
[2K
| RMSProp | epoch: 007 | loss: 0.69346 - acc: 0.5070 -- iter: 416/748
[A[ATraining Step: 158  | total loss: [1m[32m0.69372[0m[0m | time: 20.723s
[2K
| RMSProp | epoch: 007 | loss: 0.69372 - acc: 0.4938 -- iter: 448/748
[A[ATraining Step: 159  | total loss: [1m[32m0.69368[0m[0m | time: 21.917s
[2K
| RMSProp | epoch: 007 | loss: 0.69368 - acc: 0.4913 -- iter: 480/748
[A[ATraining Step: 160  | total loss: [1m[32m0.69363[0m[0m | time: 23.003s
[2K
| RMSProp | epoch: 007 | loss: 0.69363 - acc: 0.4953 -- iter: 512/748
[A[ATraining Step: 161  | total loss: [1m[32m0.69356[0m[0m | time: 24.282s
[2K
| RMSProp | epoch: 007 | loss: 0.69356 - acc: 0.4958 -- iter: 544/748
[A[ATraining Step: 162  | total loss: [1m[32m0.69353[0m[0m | time: 25.539s
[2K
| RMSProp | epoch: 007 | loss: 0.69353 - acc: 0.4993 -- iter: 576/748
[A[ATraining Step: 163  | total loss: [1m[32m0.69351[0m[0m | time: 29.704s
[2K
| RMSProp | epoch: 007 | loss: 0.69351 - acc: 0.4994 -- iter: 608/748
[A[ATraining Step: 164  | total loss: [1m[32m0.69355[0m[0m | time: 32.909s
[2K
| RMSProp | epoch: 007 | loss: 0.69355 - acc: 0.4901 -- iter: 640/748
[A[ATraining Step: 165  | total loss: [1m[32m0.69364[0m[0m | time: 34.117s
[2K
| RMSProp | epoch: 007 | loss: 0.69364 - acc: 0.4817 -- iter: 672/748
[A[ATraining Step: 166  | total loss: [1m[32m0.69360[0m[0m | time: 35.339s
[2K
| RMSProp | epoch: 007 | loss: 0.69360 - acc: 0.4804 -- iter: 704/748
[A[ATraining Step: 167  | total loss: [1m[32m0.69347[0m[0m | time: 36.497s
[2K
| RMSProp | epoch: 007 | loss: 0.69347 - acc: 0.4917 -- iter: 736/748
[A[ATraining Step: 168  | total loss: [1m[32m0.69340[0m[0m | time: 39.729s
[2K
| RMSProp | epoch: 007 | loss: 0.69340 - acc: 0.4957 | val_loss: 0.69364 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 169  | total loss: [1m[32m0.69318[0m[0m | time: 1.152s
[2K
| RMSProp | epoch: 008 | loss: 0.69318 - acc: 0.5055 -- iter: 032/748
[A[ATraining Step: 170  | total loss: [1m[32m0.69274[0m[0m | time: 2.183s
[2K
| RMSProp | epoch: 008 | loss: 0.69274 - acc: 0.5174 -- iter: 064/748
[A[ATraining Step: 171  | total loss: [1m[32m0.69242[0m[0m | time: 3.527s
[2K
| RMSProp | epoch: 008 | loss: 0.69242 - acc: 0.5219 -- iter: 096/748
[A[ATraining Step: 172  | total loss: [1m[32m0.69257[0m[0m | time: 4.853s
[2K
| RMSProp | epoch: 008 | loss: 0.69257 - acc: 0.5197 -- iter: 128/748
[A[ATraining Step: 173  | total loss: [1m[32m0.69322[0m[0m | time: 6.045s
[2K
| RMSProp | epoch: 008 | loss: 0.69322 - acc: 0.5115 -- iter: 160/748
[A[ATraining Step: 174  | total loss: [1m[32m0.69345[0m[0m | time: 7.004s
[2K
| RMSProp | epoch: 008 | loss: 0.69345 - acc: 0.5041 -- iter: 192/748
[A[ATraining Step: 175  | total loss: [1m[32m0.69384[0m[0m | time: 9.384s
[2K
| RMSProp | epoch: 008 | loss: 0.69384 - acc: 0.4870 -- iter: 224/748
[A[ATraining Step: 176  | total loss: [1m[32m0.69390[0m[0m | time: 11.830s
[2K
| RMSProp | epoch: 008 | loss: 0.69390 - acc: 0.4717 -- iter: 256/748
[A[ATraining Step: 177  | total loss: [1m[32m0.69377[0m[0m | time: 12.956s
[2K
| RMSProp | epoch: 008 | loss: 0.69377 - acc: 0.4808 -- iter: 288/748
[A[ATraining Step: 178  | total loss: [1m[32m0.69384[0m[0m | time: 14.202s
[2K
| RMSProp | epoch: 008 | loss: 0.69384 - acc: 0.4796 -- iter: 320/748
[A[ATraining Step: 179  | total loss: [1m[32m0.69367[0m[0m | time: 15.488s
[2K
| RMSProp | epoch: 008 | loss: 0.69367 - acc: 0.4910 -- iter: 352/748
[A[ATraining Step: 180  | total loss: [1m[32m0.69308[0m[0m | time: 16.742s
[2K
| RMSProp | epoch: 008 | loss: 0.69308 - acc: 0.5075 -- iter: 384/748
[A[ATraining Step: 181  | total loss: [1m[32m0.69507[0m[0m | time: 17.890s
[2K
| RMSProp | epoch: 008 | loss: 0.69507 - acc: 0.4911 -- iter: 416/748
[A[ATraining Step: 182  | total loss: [1m[32m0.69485[0m[0m | time: 19.109s
[2K
| RMSProp | epoch: 008 | loss: 0.69485 - acc: 0.4920 -- iter: 448/748
[A[ATraining Step: 183  | total loss: [1m[32m0.69462[0m[0m | time: 20.256s
[2K
| RMSProp | epoch: 008 | loss: 0.69462 - acc: 0.4991 -- iter: 480/748
[A[ATraining Step: 184  | total loss: [1m[32m0.69439[0m[0m | time: 21.552s
[2K
| RMSProp | epoch: 008 | loss: 0.69439 - acc: 0.5023 -- iter: 512/748
[A[ATraining Step: 185  | total loss: [1m[32m0.69420[0m[0m | time: 22.775s
[2K
| RMSProp | epoch: 008 | loss: 0.69420 - acc: 0.5052 -- iter: 544/748
[A[ATraining Step: 186  | total loss: [1m[32m0.69401[0m[0m | time: 24.012s
[2K
| RMSProp | epoch: 008 | loss: 0.69401 - acc: 0.5078 -- iter: 576/748
[A[ATraining Step: 187  | total loss: [1m[32m0.69392[0m[0m | time: 25.027s
[2K
| RMSProp | epoch: 008 | loss: 0.69392 - acc: 0.5070 -- iter: 608/748
[A[ATraining Step: 188  | total loss: [1m[32m0.69424[0m[0m | time: 25.880s
[2K
| RMSProp | epoch: 008 | loss: 0.69424 - acc: 0.4938 -- iter: 640/748
[A[ATraining Step: 189  | total loss: [1m[32m0.69414[0m[0m | time: 26.829s
[2K
| RMSProp | epoch: 008 | loss: 0.69414 - acc: 0.4944 -- iter: 672/748
[A[ATraining Step: 190  | total loss: [1m[32m0.69411[0m[0m | time: 27.738s
[2K
| RMSProp | epoch: 008 | loss: 0.69411 - acc: 0.4887 -- iter: 704/748
[A[ATraining Step: 191  | total loss: [1m[32m0.69398[0m[0m | time: 28.571s
[2K
| RMSProp | epoch: 008 | loss: 0.69398 - acc: 0.4992 -- iter: 736/748
[A[ATraining Step: 192  | total loss: [1m[32m0.69392[0m[0m | time: 30.900s
[2K
| RMSProp | epoch: 008 | loss: 0.69392 - acc: 0.4962 | val_loss: 0.69300 - val_acc: 0.5085 -- iter: 748/748
--
Training Step: 193  | total loss: [1m[32m0.69372[0m[0m | time: 0.723s
[2K
| RMSProp | epoch: 009 | loss: 0.69372 - acc: 0.5059 -- iter: 032/748
[A[ATraining Step: 194  | total loss: [1m[32m0.69365[0m[0m | time: 1.565s
[2K
| RMSProp | epoch: 009 | loss: 0.69365 - acc: 0.5053 -- iter: 064/748
[A[ATraining Step: 195  | total loss: [1m[32m0.69372[0m[0m | time: 2.407s
[2K
| RMSProp | epoch: 009 | loss: 0.69372 - acc: 0.5017 -- iter: 096/748
[A[ATraining Step: 196  | total loss: [1m[32m0.69379[0m[0m | time: 3.384s
[2K
| RMSProp | epoch: 009 | loss: 0.69379 - acc: 0.4921 -- iter: 128/748
[A[ATraining Step: 197  | total loss: [1m[32m0.69369[0m[0m | time: 4.280s
[2K
| RMSProp | epoch: 009 | loss: 0.69369 - acc: 0.4961 -- iter: 160/748
[A[ATraining Step: 198  | total loss: [1m[32m0.69373[0m[0m | time: 5.211s
[2K
| RMSProp | epoch: 009 | loss: 0.69373 - acc: 0.4839 -- iter: 192/748
[A[ATraining Step: 199  | total loss: [1m[32m0.69363[0m[0m | time: 5.594s
[2K
| RMSProp | epoch: 009 | loss: 0.69363 - acc: 0.4981 -- iter: 224/748
[A[ATraining Step: 200  | total loss: [1m[32m0.69395[0m[0m | time: 7.161s
[2K
| RMSProp | epoch: 009 | loss: 0.69395 - acc: 0.4732 | val_loss: 0.69302 - val_acc: 0.5085 -- iter: 256/748
--
Training Step: 201  | total loss: [1m[32m0.69382[0m[0m | time: 8.057s
[2K
| RMSProp | epoch: 009 | loss: 0.69382 - acc: 0.4926 -- iter: 288/748
[A[ATraining Step: 202  | total loss: [1m[32m0.69377[0m[0m | time: 8.899s
[2K
| RMSProp | epoch: 009 | loss: 0.69377 - acc: 0.4933 -- iter: 320/748
[A[ATraining Step: 203  | total loss: [1m[32m0.69383[0m[0m | time: 9.865s
[2K
| RMSProp | epoch: 009 | loss: 0.69383 - acc: 0.4846 -- iter: 352/748
[A[ATraining Step: 204  | total loss: [1m[32m0.69378[0m[0m | time: 10.838s
[2K
| RMSProp | epoch: 009 | loss: 0.69378 - acc: 0.4830 -- iter: 384/748
[A[ATraining Step: 205  | total loss: [1m[32m0.69366[0m[0m | time: 11.818s
[2K
| RMSProp | epoch: 009 | loss: 0.69366 - acc: 0.4941 -- iter: 416/748
[A[ATraining Step: 206  | total loss: [1m[32m0.69351[0m[0m | time: 12.841s
[2K
| RMSProp | epoch: 009 | loss: 0.69351 - acc: 0.5041 -- iter: 448/748
[A[ATraining Step: 207  | total loss: [1m[32m0.69327[0m[0m | time: 13.771s
[2K
| RMSProp | epoch: 009 | loss: 0.69327 - acc: 0.5130 -- iter: 480/748
[A[ATraining Step: 208  | total loss: [1m[32m0.69328[0m[0m | time: 14.744s
[2K
| RMSProp | epoch: 009 | loss: 0.69328 - acc: 0.5117 -- iter: 512/748
[A[ATraining Step: 209  | total loss: [1m[32m0.69338[0m[0m | time: 15.711s
[2K
| RMSProp | epoch: 009 | loss: 0.69338 - acc: 0.5074 -- iter: 544/748
[A[ATraining Step: 210  | total loss: [1m[32m0.69347[0m[0m | time: 16.623s
[2K
| RMSProp | epoch: 009 | loss: 0.69347 - acc: 0.5004 -- iter: 576/748
[A[ATraining Step: 211  | total loss: [1m[32m0.69339[0m[0m | time: 17.528s
[2K
| RMSProp | epoch: 009 | loss: 0.69339 - acc: 0.5035 -- iter: 608/748
[A[ATraining Step: 212  | total loss: [1m[32m0.69341[0m[0m | time: 18.496s
[2K
| RMSProp | epoch: 009 | loss: 0.69341 - acc: 0.5000 -- iter: 640/748
[A[ATraining Step: 213  | total loss: [1m[32m0.69339[0m[0m | time: 19.160s
[2K
| RMSProp | epoch: 009 | loss: 0.69339 - acc: 0.5000 -- iter: 672/748
[A[ATraining Step: 214  | total loss: [1m[32m0.69350[0m[0m | time: 19.777s
[2K
| RMSProp | epoch: 009 | loss: 0.69350 - acc: 0.4907 -- iter: 704/748
[A[ATraining Step: 215  | total loss: [1m[32m0.69346[0m[0m | time: 20.387s
[2K
| RMSProp | epoch: 009 | loss: 0.69346 - acc: 0.4947 -- iter: 736/748
[A[ATraining Step: 216  | total loss: [1m[32m0.69341[0m[0m | time: 22.051s
[2K
| RMSProp | epoch: 009 | loss: 0.69341 - acc: 0.4952 | val_loss: 0.69298 - val_acc: 0.5085 -- iter: 748/748
--
Training Step: 217  | total loss: [1m[32m0.69328[0m[0m | time: 0.650s
[2K
| RMSProp | epoch: 010 | loss: 0.69328 - acc: 0.5113 -- iter: 032/748
[A[ATraining Step: 218  | total loss: [1m[32m0.69305[0m[0m | time: 1.275s
[2K
| RMSProp | epoch: 010 | loss: 0.69305 - acc: 0.5196 -- iter: 064/748
[A[ATraining Step: 219  | total loss: [1m[32m0.69379[0m[0m | time: 1.890s
[2K
| RMSProp | epoch: 010 | loss: 0.69379 - acc: 0.5020 -- iter: 096/748
[A[ATraining Step: 220  | total loss: [1m[32m0.69368[0m[0m | time: 2.856s
[2K
| RMSProp | epoch: 010 | loss: 0.69368 - acc: 0.5049 -- iter: 128/748
[A[ATraining Step: 221  | total loss: [1m[32m0.69327[0m[0m | time: 3.919s
[2K
| RMSProp | epoch: 010 | loss: 0.69327 - acc: 0.5263 -- iter: 160/748
[A[ATraining Step: 222  | total loss: [1m[32m0.69326[0m[0m | time: 4.710s
[2K
| RMSProp | epoch: 010 | loss: 0.69326 - acc: 0.5237 -- iter: 192/748
[A[ATraining Step: 223  | total loss: [1m[32m0.69314[0m[0m | time: 5.675s
[2K
| RMSProp | epoch: 010 | loss: 0.69314 - acc: 0.5244 -- iter: 224/748
[A[ATraining Step: 224  | total loss: [1m[32m0.69327[0m[0m | time: 6.055s
[2K
| RMSProp | epoch: 010 | loss: 0.69327 - acc: 0.5189 -- iter: 256/748
[A[ATraining Step: 225  | total loss: [1m[32m0.69393[0m[0m | time: 6.467s
[2K
| RMSProp | epoch: 010 | loss: 0.69393 - acc: 0.4920 -- iter: 288/748
[A[ATraining Step: 226  | total loss: [1m[32m0.69408[0m[0m | time: 7.459s
[2K
| RMSProp | epoch: 010 | loss: 0.69408 - acc: 0.4678 -- iter: 320/748
[A[ATraining Step: 227  | total loss: [1m[32m0.69371[0m[0m | time: 8.408s
[2K
| RMSProp | epoch: 010 | loss: 0.69371 - acc: 0.4898 -- iter: 352/748
[A[ATraining Step: 228  | total loss: [1m[32m0.69459[0m[0m | time: 9.439s
[2K
| RMSProp | epoch: 010 | loss: 0.69459 - acc: 0.4814 -- iter: 384/748
[A[ATraining Step: 229  | total loss: [1m[32m0.69441[0m[0m | time: 10.341s
[2K
| RMSProp | epoch: 010 | loss: 0.69441 - acc: 0.4864 -- iter: 416/748
[A[ATraining Step: 230  | total loss: [1m[32m0.69404[0m[0m | time: 11.265s
[2K
| RMSProp | epoch: 010 | loss: 0.69404 - acc: 0.5034 -- iter: 448/748
[A[ATraining Step: 231  | total loss: [1m[32m0.69440[0m[0m | time: 12.220s
[2K
| RMSProp | epoch: 010 | loss: 0.69440 - acc: 0.4905 -- iter: 480/748
[A[ATraining Step: 232  | total loss: [1m[32m0.69422[0m[0m | time: 13.235s
[2K
| RMSProp | epoch: 010 | loss: 0.69422 - acc: 0.4946 -- iter: 512/748
[A[ATraining Step: 233  | total loss: [1m[32m0.69424[0m[0m | time: 14.257s
[2K
| RMSProp | epoch: 010 | loss: 0.69424 - acc: 0.4889 -- iter: 544/748
[A[ATraining Step: 234  | total loss: [1m[32m0.69407[0m[0m | time: 15.495s
[2K
| RMSProp | epoch: 010 | loss: 0.69407 - acc: 0.4963 -- iter: 576/748
[A[ATraining Step: 235  | total loss: [1m[32m0.69393[0m[0m | time: 16.542s
[2K
| RMSProp | epoch: 010 | loss: 0.69393 - acc: 0.4998 -- iter: 608/748
[A[ATraining Step: 236  | total loss: [1m[32m0.69361[0m[0m | time: 19.846s
[2K
| RMSProp | epoch: 010 | loss: 0.69361 - acc: 0.5123 -- iter: 640/748
[A[ATraining Step: 237  | total loss: [1m[32m0.69409[0m[0m | time: 22.227s
[2K
| RMSProp | epoch: 010 | loss: 0.69409 - acc: 0.4954 -- iter: 672/748
[A[ATraining Step: 238  | total loss: [1m[32m0.69404[0m[0m | time: 29.780s
[2K
| RMSProp | epoch: 010 | loss: 0.69404 - acc: 0.4928 -- iter: 704/748
[A[ATraining Step: 239  | total loss: [1m[32m0.69396[0m[0m | time: 30.995s
[2K
| RMSProp | epoch: 010 | loss: 0.69396 - acc: 0.4935 -- iter: 736/748
[A[ATraining Step: 240  | total loss: [1m[32m0.69378[0m[0m | time: 33.575s
[2K
| RMSProp | epoch: 010 | loss: 0.69378 - acc: 0.5035 | val_loss: 0.69337 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 241  | total loss: [1m[32m0.69367[0m[0m | time: 1.247s
[2K
| RMSProp | epoch: 011 | loss: 0.69367 - acc: 0.5063 -- iter: 032/748
[A[ATraining Step: 242  | total loss: [1m[32m0.69399[0m[0m | time: 2.597s
[2K
| RMSProp | epoch: 011 | loss: 0.69399 - acc: 0.4869 -- iter: 064/748
[A[ATraining Step: 243  | total loss: [1m[32m0.69394[0m[0m | time: 3.945s
[2K
| RMSProp | epoch: 011 | loss: 0.69394 - acc: 0.4851 -- iter: 096/748
[A[ATraining Step: 244  | total loss: [1m[32m0.69384[0m[0m | time: 5.029s
[2K
| RMSProp | epoch: 011 | loss: 0.69384 - acc: 0.4928 -- iter: 128/748
[A[ATraining Step: 245  | total loss: [1m[32m0.69381[0m[0m | time: 6.305s
[2K
| RMSProp | epoch: 011 | loss: 0.69381 - acc: 0.4873 -- iter: 160/748
[A[ATraining Step: 246  | total loss: [1m[32m0.69374[0m[0m | time: 7.546s
[2K
| RMSProp | epoch: 011 | loss: 0.69374 - acc: 0.4886 -- iter: 192/748
[A[ATraining Step: 247  | total loss: [1m[32m0.69359[0m[0m | time: 8.765s
[2K
| RMSProp | epoch: 011 | loss: 0.69359 - acc: 0.5147 -- iter: 224/748
[A[ATraining Step: 248  | total loss: [1m[32m0.69315[0m[0m | time: 9.878s
[2K
| RMSProp | epoch: 011 | loss: 0.69315 - acc: 0.5351 -- iter: 256/748
[A[ATraining Step: 249  | total loss: [1m[32m0.69325[0m[0m | time: 10.219s
[2K
| RMSProp | epoch: 011 | loss: 0.69325 - acc: 0.5285 -- iter: 288/748
[A[ATraining Step: 250  | total loss: [1m[32m0.69321[0m[0m | time: 10.593s
[2K
| RMSProp | epoch: 011 | loss: 0.69321 - acc: 0.5256 -- iter: 320/748
[A[ATraining Step: 251  | total loss: [1m[32m0.69321[0m[0m | time: 11.928s
[2K
| RMSProp | epoch: 011 | loss: 0.69321 - acc: 0.5231 -- iter: 352/748
[A[ATraining Step: 252  | total loss: [1m[32m0.69360[0m[0m | time: 13.217s
[2K
| RMSProp | epoch: 011 | loss: 0.69360 - acc: 0.5083 -- iter: 384/748
[A[ATraining Step: 253  | total loss: [1m[32m0.69355[0m[0m | time: 14.497s
[2K
| RMSProp | epoch: 011 | loss: 0.69355 - acc: 0.5074 -- iter: 416/748
[A[ATraining Step: 254  | total loss: [1m[32m0.69370[0m[0m | time: 15.590s
[2K
| RMSProp | epoch: 011 | loss: 0.69370 - acc: 0.4942 -- iter: 448/748
[A[ATraining Step: 255  | total loss: [1m[32m0.69368[0m[0m | time: 16.845s
[2K
| RMSProp | epoch: 011 | loss: 0.69368 - acc: 0.4916 -- iter: 480/748
[A[ATraining Step: 256  | total loss: [1m[32m0.69363[0m[0m | time: 18.141s
[2K
| RMSProp | epoch: 011 | loss: 0.69363 - acc: 0.4925 -- iter: 512/748
[A[ATraining Step: 257  | total loss: [1m[32m0.69363[0m[0m | time: 19.275s
[2K
| RMSProp | epoch: 011 | loss: 0.69363 - acc: 0.4870 -- iter: 544/748
[A[ATraining Step: 258  | total loss: [1m[32m0.69359[0m[0m | time: 20.500s
[2K
| RMSProp | epoch: 011 | loss: 0.69359 - acc: 0.4789 -- iter: 576/748
[A[ATraining Step: 259  | total loss: [1m[32m0.69363[0m[0m | time: 21.850s
[2K
| RMSProp | epoch: 011 | loss: 0.69363 - acc: 0.4591 -- iter: 608/748
[A[ATraining Step: 260  | total loss: [1m[32m0.69354[0m[0m | time: 23.204s
[2K
| RMSProp | epoch: 011 | loss: 0.69354 - acc: 0.4664 -- iter: 640/748
[A[ATraining Step: 261  | total loss: [1m[32m0.69352[0m[0m | time: 27.219s
[2K
| RMSProp | epoch: 011 | loss: 0.69352 - acc: 0.4697 -- iter: 672/748
[A[ATraining Step: 262  | total loss: [1m[32m0.69354[0m[0m | time: 33.679s
[2K
| RMSProp | epoch: 011 | loss: 0.69354 - acc: 0.4696 -- iter: 704/748
[A[ATraining Step: 263  | total loss: [1m[32m0.69358[0m[0m | time: 45.856s
[2K
| RMSProp | epoch: 011 | loss: 0.69358 - acc: 0.4664 -- iter: 736/748
[A[ATraining Step: 264  | total loss: [1m[32m0.69354[0m[0m | time: 50.443s
[2K
| RMSProp | epoch: 011 | loss: 0.69354 - acc: 0.4666 | val_loss: 0.69328 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 265  | total loss: [1m[32m0.69348[0m[0m | time: 1.074s
[2K
| RMSProp | epoch: 012 | loss: 0.69348 - acc: 0.4731 -- iter: 032/748
[A[ATraining Step: 266  | total loss: [1m[32m0.69344[0m[0m | time: 2.359s
[2K
| RMSProp | epoch: 012 | loss: 0.69344 - acc: 0.4758 -- iter: 064/748
[A[ATraining Step: 267  | total loss: [1m[32m0.69349[0m[0m | time: 3.705s
[2K
| RMSProp | epoch: 012 | loss: 0.69349 - acc: 0.4720 -- iter: 096/748
[A[ATraining Step: 268  | total loss: [1m[32m0.69343[0m[0m | time: 5.018s
[2K
| RMSProp | epoch: 012 | loss: 0.69343 - acc: 0.4873 -- iter: 128/748
[A[ATraining Step: 269  | total loss: [1m[32m0.69336[0m[0m | time: 6.297s
[2K
| RMSProp | epoch: 012 | loss: 0.69336 - acc: 0.4917 -- iter: 160/748
[A[ATraining Step: 270  | total loss: [1m[32m0.69330[0m[0m | time: 7.509s
[2K
| RMSProp | epoch: 012 | loss: 0.69330 - acc: 0.4956 -- iter: 192/748
[A[ATraining Step: 271  | total loss: [1m[32m0.69323[0m[0m | time: 8.766s
[2K
| RMSProp | epoch: 012 | loss: 0.69323 - acc: 0.4992 -- iter: 224/748
[A[ATraining Step: 272  | total loss: [1m[32m0.69323[0m[0m | time: 9.958s
[2K
| RMSProp | epoch: 012 | loss: 0.69323 - acc: 0.4993 -- iter: 256/748
[A[ATraining Step: 273  | total loss: [1m[32m0.69315[0m[0m | time: 11.021s
[2K
| RMSProp | epoch: 012 | loss: 0.69315 - acc: 0.5025 -- iter: 288/748
[A[ATraining Step: 274  | total loss: [1m[32m0.69314[0m[0m | time: 11.378s
[2K
| RMSProp | epoch: 012 | loss: 0.69314 - acc: 0.5022 -- iter: 320/748
[A[ATraining Step: 275  | total loss: [1m[32m0.69343[0m[0m | time: 11.706s
[2K
| RMSProp | epoch: 012 | loss: 0.69343 - acc: 0.4937 -- iter: 352/748
[A[ATraining Step: 276  | total loss: [1m[32m0.69351[0m[0m | time: 12.696s
[2K
| RMSProp | epoch: 012 | loss: 0.69351 - acc: 0.4860 -- iter: 384/748
[A[ATraining Step: 277  | total loss: [1m[32m0.69349[0m[0m | time: 13.638s
[2K
| RMSProp | epoch: 012 | loss: 0.69349 - acc: 0.4811 -- iter: 416/748
[A[ATraining Step: 278  | total loss: [1m[32m0.69341[0m[0m | time: 14.587s
[2K
| RMSProp | epoch: 012 | loss: 0.69341 - acc: 0.5049 -- iter: 448/748
[A[ATraining Step: 279  | total loss: [1m[32m0.69326[0m[0m | time: 15.482s
[2K
| RMSProp | epoch: 012 | loss: 0.69326 - acc: 0.5138 -- iter: 480/748
[A[ATraining Step: 280  | total loss: [1m[32m0.69310[0m[0m | time: 16.440s
[2K
| RMSProp | epoch: 012 | loss: 0.69310 - acc: 0.5186 -- iter: 512/748
[A[ATraining Step: 281  | total loss: [1m[32m0.69283[0m[0m | time: 17.352s
[2K
| RMSProp | epoch: 012 | loss: 0.69283 - acc: 0.5230 -- iter: 544/748
[A[ATraining Step: 282  | total loss: [1m[32m0.69197[0m[0m | time: 18.243s
[2K
| RMSProp | epoch: 012 | loss: 0.69197 - acc: 0.5301 -- iter: 576/748
[A[ATraining Step: 283  | total loss: [1m[32m0.69285[0m[0m | time: 19.169s
[2K
| RMSProp | epoch: 012 | loss: 0.69285 - acc: 0.5302 -- iter: 608/748
[A[ATraining Step: 284  | total loss: [1m[32m0.69263[0m[0m | time: 20.132s
[2K
| RMSProp | epoch: 012 | loss: 0.69263 - acc: 0.5303 -- iter: 640/748
[A[ATraining Step: 285  | total loss: [1m[32m0.69086[0m[0m | time: 21.016s
[2K
| RMSProp | epoch: 012 | loss: 0.69086 - acc: 0.5460 -- iter: 672/748
[A[ATraining Step: 286  | total loss: [1m[32m0.69758[0m[0m | time: 21.858s
[2K
| RMSProp | epoch: 012 | loss: 0.69758 - acc: 0.5196 -- iter: 704/748
[A[ATraining Step: 287  | total loss: [1m[32m0.69697[0m[0m | time: 22.716s
[2K
| RMSProp | epoch: 012 | loss: 0.69697 - acc: 0.5207 -- iter: 736/748
[A[ATraining Step: 288  | total loss: [1m[32m0.69667[0m[0m | time: 24.714s
[2K
| RMSProp | epoch: 012 | loss: 0.69667 - acc: 0.5187 | val_loss: 0.69298 - val_acc: 0.5085 -- iter: 748/748
--
Training Step: 289  | total loss: [1m[32m0.69730[0m[0m | time: 0.918s
[2K
| RMSProp | epoch: 013 | loss: 0.69730 - acc: 0.5012 -- iter: 032/748
[A[ATraining Step: 290  | total loss: [1m[32m0.69719[0m[0m | time: 1.798s
[2K
| RMSProp | epoch: 013 | loss: 0.69719 - acc: 0.4917 -- iter: 064/748
[A[ATraining Step: 291  | total loss: [1m[32m0.69686[0m[0m | time: 2.664s
[2K
| RMSProp | epoch: 013 | loss: 0.69686 - acc: 0.4894 -- iter: 096/748
[A[ATraining Step: 292  | total loss: [1m[32m0.69663[0m[0m | time: 3.628s
[2K
| RMSProp | epoch: 013 | loss: 0.69663 - acc: 0.4779 -- iter: 128/748
[A[ATraining Step: 293  | total loss: [1m[32m0.69627[0m[0m | time: 4.428s
[2K
| RMSProp | epoch: 013 | loss: 0.69627 - acc: 0.4833 -- iter: 160/748
[A[ATraining Step: 294  | total loss: [1m[32m0.69593[0m[0m | time: 5.223s
[2K
| RMSProp | epoch: 013 | loss: 0.69593 - acc: 0.4881 -- iter: 192/748
[A[ATraining Step: 295  | total loss: [1m[32m0.69546[0m[0m | time: 6.091s
[2K
| RMSProp | epoch: 013 | loss: 0.69546 - acc: 0.5049 -- iter: 224/748
[A[ATraining Step: 296  | total loss: [1m[32m0.69551[0m[0m | time: 6.900s
[2K
| RMSProp | epoch: 013 | loss: 0.69551 - acc: 0.4981 -- iter: 256/748
[A[ATraining Step: 297  | total loss: [1m[32m0.69549[0m[0m | time: 7.950s
[2K
| RMSProp | epoch: 013 | loss: 0.69549 - acc: 0.4890 -- iter: 288/748
[A[ATraining Step: 298  | total loss: [1m[32m0.69540[0m[0m | time: 9.390s
[2K
| RMSProp | epoch: 013 | loss: 0.69540 - acc: 0.4744 -- iter: 320/748
[A[ATraining Step: 299  | total loss: [1m[32m0.69524[0m[0m | time: 9.923s
[2K
| RMSProp | epoch: 013 | loss: 0.69524 - acc: 0.4676 -- iter: 352/748
[A[ATraining Step: 300  | total loss: [1m[32m0.69495[0m[0m | time: 10.484s
[2K
| RMSProp | epoch: 013 | loss: 0.69495 - acc: 0.4959 -- iter: 384/748
[A[ATraining Step: 301  | total loss: [1m[32m0.69425[0m[0m | time: 14.814s
[2K
| RMSProp | epoch: 013 | loss: 0.69425 - acc: 0.5213 -- iter: 416/748
[A[ATraining Step: 302  | total loss: [1m[32m0.69489[0m[0m | time: 17.174s
[2K
| RMSProp | epoch: 013 | loss: 0.69489 - acc: 0.5066 -- iter: 448/748
[A[ATraining Step: 303  | total loss: [1m[32m0.69464[0m[0m | time: 18.158s
[2K
| RMSProp | epoch: 013 | loss: 0.69464 - acc: 0.5091 -- iter: 480/748
[A[ATraining Step: 304  | total loss: [1m[32m0.69460[0m[0m | time: 19.409s
[2K
| RMSProp | epoch: 013 | loss: 0.69460 - acc: 0.5051 -- iter: 512/748
[A[ATraining Step: 305  | total loss: [1m[32m0.69440[0m[0m | time: 20.568s
[2K
| RMSProp | epoch: 013 | loss: 0.69440 - acc: 0.5077 -- iter: 544/748
[A[ATraining Step: 306  | total loss: [1m[32m0.69445[0m[0m | time: 21.723s
[2K
| RMSProp | epoch: 013 | loss: 0.69445 - acc: 0.5007 -- iter: 576/748
[A[ATraining Step: 307  | total loss: [1m[32m0.69413[0m[0m | time: 22.936s
[2K
| RMSProp | epoch: 013 | loss: 0.69413 - acc: 0.5100 -- iter: 608/748
[A[ATraining Step: 308  | total loss: [1m[32m0.69405[0m[0m | time: 24.325s
[2K
| RMSProp | epoch: 013 | loss: 0.69405 - acc: 0.5090 -- iter: 640/748
[A[ATraining Step: 309  | total loss: [1m[32m0.69389[0m[0m | time: 25.607s
[2K
| RMSProp | epoch: 013 | loss: 0.69389 - acc: 0.5112 -- iter: 672/748
[A[ATraining Step: 310  | total loss: [1m[32m0.69383[0m[0m | time: 26.799s
[2K
| RMSProp | epoch: 013 | loss: 0.69383 - acc: 0.5101 -- iter: 704/748
[A[ATraining Step: 311  | total loss: [1m[32m0.69364[0m[0m | time: 28.051s
[2K
| RMSProp | epoch: 013 | loss: 0.69364 - acc: 0.5122 -- iter: 736/748
[A[ATraining Step: 312  | total loss: [1m[32m0.69371[0m[0m | time: 30.863s
[2K
| RMSProp | epoch: 013 | loss: 0.69371 - acc: 0.5079 | val_loss: 0.69335 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 313  | total loss: [1m[32m0.69383[0m[0m | time: 1.358s
[2K
| RMSProp | epoch: 014 | loss: 0.69383 - acc: 0.5008 -- iter: 032/748
[A[ATraining Step: 314  | total loss: [1m[32m0.69390[0m[0m | time: 2.489s
[2K
| RMSProp | epoch: 014 | loss: 0.69390 - acc: 0.4945 -- iter: 064/748
[A[ATraining Step: 315  | total loss: [1m[32m0.69388[0m[0m | time: 3.561s
[2K
| RMSProp | epoch: 014 | loss: 0.69388 - acc: 0.4919 -- iter: 096/748
[A[ATraining Step: 316  | total loss: [1m[32m0.69377[0m[0m | time: 4.788s
[2K
| RMSProp | epoch: 014 | loss: 0.69377 - acc: 0.4958 -- iter: 128/748
[A[ATraining Step: 317  | total loss: [1m[32m0.69362[0m[0m | time: 5.961s
[2K
| RMSProp | epoch: 014 | loss: 0.69362 - acc: 0.5025 -- iter: 160/748
[A[ATraining Step: 318  | total loss: [1m[32m0.69402[0m[0m | time: 7.046s
[2K
| RMSProp | epoch: 014 | loss: 0.69402 - acc: 0.4773 -- iter: 192/748
[A[ATraining Step: 319  | total loss: [1m[32m0.69393[0m[0m | time: 8.277s
[2K
| RMSProp | epoch: 014 | loss: 0.69393 - acc: 0.4733 -- iter: 224/748
[A[ATraining Step: 320  | total loss: [1m[32m0.69382[0m[0m | time: 9.421s
[2K
| RMSProp | epoch: 014 | loss: 0.69382 - acc: 0.4791 -- iter: 256/748
[A[ATraining Step: 321  | total loss: [1m[32m0.69365[0m[0m | time: 10.711s
[2K
| RMSProp | epoch: 014 | loss: 0.69365 - acc: 0.4905 -- iter: 288/748
[A[ATraining Step: 322  | total loss: [1m[32m0.69333[0m[0m | time: 11.906s
[2K
| RMSProp | epoch: 014 | loss: 0.69333 - acc: 0.5071 -- iter: 320/748
[A[ATraining Step: 323  | total loss: [1m[32m0.69352[0m[0m | time: 13.134s
[2K
| RMSProp | epoch: 014 | loss: 0.69352 - acc: 0.5002 -- iter: 352/748
[A[ATraining Step: 324  | total loss: [1m[32m0.69355[0m[0m | time: 13.635s
[2K
| RMSProp | epoch: 014 | loss: 0.69355 - acc: 0.4970 -- iter: 384/748
[A[ATraining Step: 325  | total loss: [1m[32m0.69355[0m[0m | time: 14.130s
[2K
| RMSProp | epoch: 014 | loss: 0.69355 - acc: 0.4973 -- iter: 416/748
[A[ATraining Step: 326  | total loss: [1m[32m0.69349[0m[0m | time: 15.426s
[2K
| RMSProp | epoch: 014 | loss: 0.69349 - acc: 0.4976 -- iter: 448/748
[A[ATraining Step: 327  | total loss: [1m[32m0.69349[0m[0m | time: 24.032s
[2K
| RMSProp | epoch: 014 | loss: 0.69349 - acc: 0.4978 -- iter: 480/748
[A[ATraining Step: 328  | total loss: [1m[32m0.69368[0m[0m | time: 27.038s
[2K
| RMSProp | epoch: 014 | loss: 0.69368 - acc: 0.4855 -- iter: 512/748
[A[ATraining Step: 329  | total loss: [1m[32m0.69365[0m[0m | time: 28.196s
[2K
| RMSProp | epoch: 014 | loss: 0.69365 - acc: 0.4839 -- iter: 544/748
[A[ATraining Step: 330  | total loss: [1m[32m0.69356[0m[0m | time: 29.284s
[2K
| RMSProp | epoch: 014 | loss: 0.69356 - acc: 0.4886 -- iter: 576/748
[A[ATraining Step: 331  | total loss: [1m[32m0.69358[0m[0m | time: 30.493s
[2K
| RMSProp | epoch: 014 | loss: 0.69358 - acc: 0.4835 -- iter: 608/748
[A[ATraining Step: 332  | total loss: [1m[32m0.69350[0m[0m | time: 31.761s
[2K
| RMSProp | epoch: 014 | loss: 0.69350 - acc: 0.4976 -- iter: 640/748
[A[ATraining Step: 333  | total loss: [1m[32m0.69343[0m[0m | time: 32.923s
[2K
| RMSProp | epoch: 014 | loss: 0.69343 - acc: 0.5010 -- iter: 672/748
[A[ATraining Step: 334  | total loss: [1m[32m0.69339[0m[0m | time: 34.204s
[2K
| RMSProp | epoch: 014 | loss: 0.69339 - acc: 0.5009 -- iter: 704/748
[A[ATraining Step: 335  | total loss: [1m[32m0.69349[0m[0m | time: 35.329s
[2K
| RMSProp | epoch: 014 | loss: 0.69349 - acc: 0.4914 -- iter: 736/748
[A[ATraining Step: 336  | total loss: [1m[32m0.69345[0m[0m | time: 38.483s
[2K
| RMSProp | epoch: 014 | loss: 0.69345 - acc: 0.4954 | val_loss: 0.69316 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 337  | total loss: [1m[32m0.69348[0m[0m | time: 1.175s
[2K
| RMSProp | epoch: 015 | loss: 0.69348 - acc: 0.4865 -- iter: 032/748
[A[ATraining Step: 338  | total loss: [1m[32m0.69343[0m[0m | time: 2.092s
[2K
| RMSProp | epoch: 015 | loss: 0.69343 - acc: 0.4972 -- iter: 064/748
[A[ATraining Step: 339  | total loss: [1m[32m0.69336[0m[0m | time: 3.395s
[2K
| RMSProp | epoch: 015 | loss: 0.69336 - acc: 0.5038 -- iter: 096/748
[A[ATraining Step: 340  | total loss: [1m[32m0.69331[0m[0m | time: 4.754s
[2K
| RMSProp | epoch: 015 | loss: 0.69331 - acc: 0.5065 -- iter: 128/748
[A[ATraining Step: 341  | total loss: [1m[32m0.69331[0m[0m | time: 6.100s
[2K
| RMSProp | epoch: 015 | loss: 0.69331 - acc: 0.5059 -- iter: 160/748
[A[ATraining Step: 342  | total loss: [1m[32m0.69349[0m[0m | time: 7.173s
[2K
| RMSProp | epoch: 015 | loss: 0.69349 - acc: 0.4928 -- iter: 192/748
[A[ATraining Step: 343  | total loss: [1m[32m0.69343[0m[0m | time: 8.459s
[2K
| RMSProp | epoch: 015 | loss: 0.69343 - acc: 0.4966 -- iter: 224/748
[A[ATraining Step: 344  | total loss: [1m[32m0.69341[0m[0m | time: 9.810s
[2K
| RMSProp | epoch: 015 | loss: 0.69341 - acc: 0.4970 -- iter: 256/748
[A[ATraining Step: 345  | total loss: [1m[32m0.69339[0m[0m | time: 11.023s
[2K
| RMSProp | epoch: 015 | loss: 0.69339 - acc: 0.4973 -- iter: 288/748
[A[ATraining Step: 346  | total loss: [1m[32m0.69330[0m[0m | time: 12.176s
[2K
| RMSProp | epoch: 015 | loss: 0.69330 - acc: 0.5069 -- iter: 320/748
[A[ATraining Step: 347  | total loss: [1m[32m0.69338[0m[0m | time: 13.559s
[2K
| RMSProp | epoch: 015 | loss: 0.69338 - acc: 0.5000 -- iter: 352/748
[A[ATraining Step: 348  | total loss: [1m[32m0.69330[0m[0m | time: 14.677s
[2K
| RMSProp | epoch: 015 | loss: 0.69330 - acc: 0.5062 -- iter: 384/748
[A[ATraining Step: 349  | total loss: [1m[32m0.69326[0m[0m | time: 15.045s
[2K
| RMSProp | epoch: 015 | loss: 0.69326 - acc: 0.5087 -- iter: 416/748
[A[ATraining Step: 350  | total loss: [1m[32m0.69314[0m[0m | time: 15.411s
[2K
| RMSProp | epoch: 015 | loss: 0.69314 - acc: 0.5162 -- iter: 448/748
[A[ATraining Step: 351  | total loss: [1m[32m0.69294[0m[0m | time: 16.251s
[2K
| RMSProp | epoch: 015 | loss: 0.69294 - acc: 0.5229 -- iter: 480/748
[A[ATraining Step: 352  | total loss: [1m[32m0.69306[0m[0m | time: 17.161s
[2K
| RMSProp | epoch: 015 | loss: 0.69306 - acc: 0.5175 -- iter: 512/748
[A[ATraining Step: 353  | total loss: [1m[32m0.69307[0m[0m | time: 18.148s
[2K
| RMSProp | epoch: 015 | loss: 0.69307 - acc: 0.5157 -- iter: 544/748
[A[ATraining Step: 354  | total loss: [1m[32m0.69279[0m[0m | time: 19.179s
[2K
| RMSProp | epoch: 015 | loss: 0.69279 - acc: 0.5267 -- iter: 576/748
[A[ATraining Step: 355  | total loss: [1m[32m0.69319[0m[0m | time: 20.100s
[2K
| RMSProp | epoch: 015 | loss: 0.69319 - acc: 0.5146 -- iter: 608/748
[A[ATraining Step: 356  | total loss: [1m[32m0.69341[0m[0m | time: 20.800s
[2K
| RMSProp | epoch: 015 | loss: 0.69341 - acc: 0.5038 -- iter: 640/748
[A[ATraining Step: 357  | total loss: [1m[32m0.69332[0m[0m | time: 21.711s
[2K
| RMSProp | epoch: 015 | loss: 0.69332 - acc: 0.5097 -- iter: 672/748
[A[ATraining Step: 358  | total loss: [1m[32m0.69350[0m[0m | time: 22.724s
[2K
| RMSProp | epoch: 015 | loss: 0.69350 - acc: 0.4993 -- iter: 704/748
[A[ATraining Step: 359  | total loss: [1m[32m0.69337[0m[0m | time: 23.619s
[2K
| RMSProp | epoch: 015 | loss: 0.69337 - acc: 0.5088 -- iter: 736/748
[A[ATraining Step: 360  | total loss: [1m[32m0.69322[0m[0m | time: 25.964s
[2K
| RMSProp | epoch: 015 | loss: 0.69322 - acc: 0.5141 | val_loss: 0.69334 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 361  | total loss: [1m[32m0.69340[0m[0m | time: 0.948s
[2K
| RMSProp | epoch: 016 | loss: 0.69340 - acc: 0.5065 -- iter: 032/748
[A[ATraining Step: 362  | total loss: [1m[32m0.69349[0m[0m | time: 1.855s
[2K
| RMSProp | epoch: 016 | loss: 0.69349 - acc: 0.4996 -- iter: 064/748
[A[ATraining Step: 363  | total loss: [1m[32m0.69343[0m[0m | time: 2.853s
[2K
| RMSProp | epoch: 016 | loss: 0.69343 - acc: 0.5027 -- iter: 096/748
[A[ATraining Step: 364  | total loss: [1m[32m0.69344[0m[0m | time: 3.830s
[2K
| RMSProp | epoch: 016 | loss: 0.69344 - acc: 0.4993 -- iter: 128/748
[A[ATraining Step: 365  | total loss: [1m[32m0.69333[0m[0m | time: 4.663s
[2K
| RMSProp | epoch: 016 | loss: 0.69333 - acc: 0.5088 -- iter: 160/748
[A[ATraining Step: 366  | total loss: [1m[32m0.69358[0m[0m | time: 5.491s
[2K
| RMSProp | epoch: 016 | loss: 0.69358 - acc: 0.4954 -- iter: 192/748
[A[ATraining Step: 367  | total loss: [1m[32m0.69360[0m[0m | time: 6.397s
[2K
| RMSProp | epoch: 016 | loss: 0.69360 - acc: 0.4896 -- iter: 224/748
[A[ATraining Step: 368  | total loss: [1m[32m0.69347[0m[0m | time: 7.324s
[2K
| RMSProp | epoch: 016 | loss: 0.69347 - acc: 0.5032 -- iter: 256/748
[A[ATraining Step: 369  | total loss: [1m[32m0.69342[0m[0m | time: 8.383s
[2K
| RMSProp | epoch: 016 | loss: 0.69342 - acc: 0.5060 -- iter: 288/748
[A[ATraining Step: 370  | total loss: [1m[32m0.69345[0m[0m | time: 9.635s
[2K
| RMSProp | epoch: 016 | loss: 0.69345 - acc: 0.5022 -- iter: 320/748
[A[ATraining Step: 371  | total loss: [1m[32m0.69350[0m[0m | time: 10.970s
[2K
| RMSProp | epoch: 016 | loss: 0.69350 - acc: 0.4958 -- iter: 352/748
[A[ATraining Step: 372  | total loss: [1m[32m0.69342[0m[0m | time: 20.189s
[2K
| RMSProp | epoch: 016 | loss: 0.69342 - acc: 0.5024 -- iter: 384/748
[A[ATraining Step: 373  | total loss: [1m[32m0.69334[0m[0m | time: 25.859s
[2K
| RMSProp | epoch: 016 | loss: 0.69334 - acc: 0.5053 -- iter: 416/748
[A[ATraining Step: 374  | total loss: [1m[32m0.69341[0m[0m | time: 26.470s
[2K
| RMSProp | epoch: 016 | loss: 0.69341 - acc: 0.4985 -- iter: 448/748
[A[ATraining Step: 375  | total loss: [1m[32m0.69311[0m[0m | time: 26.946s
[2K
| RMSProp | epoch: 016 | loss: 0.69311 - acc: 0.5237 -- iter: 480/748
[A[ATraining Step: 376  | total loss: [1m[32m0.69257[0m[0m | time: 28.220s
[2K
| RMSProp | epoch: 016 | loss: 0.69257 - acc: 0.5463 -- iter: 512/748
[A[ATraining Step: 377  | total loss: [1m[32m0.69319[0m[0m | time: 29.422s
[2K
| RMSProp | epoch: 016 | loss: 0.69319 - acc: 0.5261 -- iter: 544/748
[A[ATraining Step: 378  | total loss: [1m[32m0.69302[0m[0m | time: 30.590s
[2K
| RMSProp | epoch: 016 | loss: 0.69302 - acc: 0.5297 -- iter: 576/748
[A[ATraining Step: 379  | total loss: [1m[32m0.69306[0m[0m | time: 31.789s
[2K
| RMSProp | epoch: 016 | loss: 0.69306 - acc: 0.5267 -- iter: 608/748
[A[ATraining Step: 380  | total loss: [1m[32m0.69306[0m[0m | time: 33.177s
[2K
| RMSProp | epoch: 016 | loss: 0.69306 - acc: 0.5241 -- iter: 640/748
[A[ATraining Step: 381  | total loss: [1m[32m0.69324[0m[0m | time: 34.361s
[2K
| RMSProp | epoch: 016 | loss: 0.69324 - acc: 0.5154 -- iter: 672/748
[A[ATraining Step: 382  | total loss: [1m[32m0.69339[0m[0m | time: 35.562s
[2K
| RMSProp | epoch: 016 | loss: 0.69339 - acc: 0.5076 -- iter: 704/748
[A[ATraining Step: 383  | total loss: [1m[32m0.69343[0m[0m | time: 36.766s
[2K
| RMSProp | epoch: 016 | loss: 0.69343 - acc: 0.5037 -- iter: 736/748
[A[ATraining Step: 384  | total loss: [1m[32m0.69310[0m[0m | time: 39.823s
[2K
| RMSProp | epoch: 016 | loss: 0.69310 - acc: 0.5190 | val_loss: 0.69341 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 385  | total loss: [1m[32m0.69328[0m[0m | time: 4.935s
[2K
| RMSProp | epoch: 017 | loss: 0.69328 - acc: 0.5108 -- iter: 032/748
[A[ATraining Step: 386  | total loss: [1m[32m0.69335[0m[0m | time: 6.298s
[2K
| RMSProp | epoch: 017 | loss: 0.69335 - acc: 0.5066 -- iter: 064/748
[A[ATraining Step: 387  | total loss: [1m[32m0.69354[0m[0m | time: 7.507s
[2K
| RMSProp | epoch: 017 | loss: 0.69354 - acc: 0.4966 -- iter: 096/748
[A[ATraining Step: 388  | total loss: [1m[32m0.69360[0m[0m | time: 8.810s
[2K
| RMSProp | epoch: 017 | loss: 0.69360 - acc: 0.4907 -- iter: 128/748
[A[ATraining Step: 389  | total loss: [1m[32m0.69364[0m[0m | time: 9.833s
[2K
| RMSProp | epoch: 017 | loss: 0.69364 - acc: 0.4854 -- iter: 160/748
[A[ATraining Step: 390  | total loss: [1m[32m0.69351[0m[0m | time: 11.095s
[2K
| RMSProp | epoch: 017 | loss: 0.69351 - acc: 0.4962 -- iter: 192/748
[A[ATraining Step: 391  | total loss: [1m[32m0.69329[0m[0m | time: 12.429s
[2K
| RMSProp | epoch: 017 | loss: 0.69329 - acc: 0.5091 -- iter: 224/748
[A[ATraining Step: 392  | total loss: [1m[32m0.69327[0m[0m | time: 13.686s
[2K
| RMSProp | epoch: 017 | loss: 0.69327 - acc: 0.5082 -- iter: 256/748
[A[ATraining Step: 393  | total loss: [1m[32m0.69344[0m[0m | time: 14.910s
[2K
| RMSProp | epoch: 017 | loss: 0.69344 - acc: 0.4980 -- iter: 288/748
[A[ATraining Step: 394  | total loss: [1m[32m0.69338[0m[0m | time: 16.152s
[2K
| RMSProp | epoch: 017 | loss: 0.69338 - acc: 0.5013 -- iter: 320/748
[A[ATraining Step: 395  | total loss: [1m[32m0.69346[0m[0m | time: 17.545s
[2K
| RMSProp | epoch: 017 | loss: 0.69346 - acc: 0.4949 -- iter: 352/748
[A[ATraining Step: 396  | total loss: [1m[32m0.69341[0m[0m | time: 18.689s
[2K
| RMSProp | epoch: 017 | loss: 0.69341 - acc: 0.4954 -- iter: 384/748
[A[ATraining Step: 397  | total loss: [1m[32m0.69338[0m[0m | time: 19.845s
[2K
| RMSProp | epoch: 017 | loss: 0.69338 - acc: 0.4959 -- iter: 416/748
[A[ATraining Step: 398  | total loss: [1m[32m0.69325[0m[0m | time: 21.002s
[2K
| RMSProp | epoch: 017 | loss: 0.69325 - acc: 0.5057 -- iter: 448/748
[A[ATraining Step: 399  | total loss: [1m[32m0.69320[0m[0m | time: 21.528s
[2K
| RMSProp | epoch: 017 | loss: 0.69320 - acc: 0.5082 -- iter: 480/748
[A[ATraining Step: 400  | total loss: [1m[32m0.69318[0m[0m | time: 23.739s
[2K
| RMSProp | epoch: 017 | loss: 0.69318 - acc: 0.5074 | val_loss: 0.69334 - val_acc: 0.4915 -- iter: 512/748
--
Training Step: 401  | total loss: [1m[32m0.69319[0m[0m | time: 24.884s
[2K
| RMSProp | epoch: 017 | loss: 0.69319 - acc: 0.5067 -- iter: 544/748
[A[ATraining Step: 402  | total loss: [1m[32m0.69318[0m[0m | time: 25.873s
[2K
| RMSProp | epoch: 017 | loss: 0.69318 - acc: 0.5060 -- iter: 576/748
[A[ATraining Step: 403  | total loss: [1m[32m0.69340[0m[0m | time: 27.016s
[2K
| RMSProp | epoch: 017 | loss: 0.69340 - acc: 0.4929 -- iter: 608/748
[A[ATraining Step: 404  | total loss: [1m[32m0.69328[0m[0m | time: 28.161s
[2K
| RMSProp | epoch: 017 | loss: 0.69328 - acc: 0.5030 -- iter: 640/748
[A[ATraining Step: 405  | total loss: [1m[32m0.69323[0m[0m | time: 29.334s
[2K
| RMSProp | epoch: 017 | loss: 0.69323 - acc: 0.5058 -- iter: 672/748
[A[ATraining Step: 406  | total loss: [1m[32m0.69339[0m[0m | time: 30.569s
[2K
| RMSProp | epoch: 017 | loss: 0.69339 - acc: 0.4959 -- iter: 704/748
[A[ATraining Step: 407  | total loss: [1m[32m0.69328[0m[0m | time: 31.670s
[2K
| RMSProp | epoch: 017 | loss: 0.69328 - acc: 0.5025 -- iter: 736/748
[A[ATraining Step: 408  | total loss: [1m[32m0.69325[0m[0m | time: 34.898s
[2K
| RMSProp | epoch: 017 | loss: 0.69325 - acc: 0.5023 | val_loss: 0.69324 - val_acc: 0.4915 -- iter: 748/748
--
Training Step: 409  | total loss: [1m[32m0.69340[0m[0m | time: 1.280s
[2K
| RMSProp | epoch: 018 | loss: 0.69340 - acc: 0.4927 -- iter: 032/748
[A[ATraining Step: 410  | total loss: [1m[32m0.69329[0m[0m | time: 2.565s
[2K
| RMSProp | epoch: 018 | loss: 0.69329 - acc: 0.5028 -- iter: 064/748
[A[ATraining Step: 411  | total loss: [1m[32m0.69313[0m[0m | time: 3.841s
[2K
| RMSProp | epoch: 018 | loss: 0.69313 - acc: 0.5119 -- iter: 096/748
[A[ATraining Step: 412  | total loss: [1m[32m0.69313[0m[0m | time: 4.980s
[2K
| RMSProp | epoch: 018 | loss: 0.69313 - acc: 0.5107 -- iter: 128/748
[A[ATraining Step: 413  | total loss: [1m[32m0.69319[0m[0m | time: 6.106s
[2K
| RMSProp | epoch: 018 | loss: 0.69319 - acc: 0.5065 -- iter: 160/748
[A[ATraining Step: 414  | total loss: [1m[32m0.69316[0m[0m | time: 7.394s
[2K
| RMSProp | epoch: 018 | loss: 0.69316 - acc: 0.5090 -- iter: 192/748
[A[ATraining Step: 415  | total loss: [1m[32m0.69323[0m[0m | time: 8.745s
[2K
| RMSProp | epoch: 018 | loss: 0.69323 - acc: 0.5049 -- iter: 224/748
[A[ATraining Step: 416  | total loss: [1m[32m0.69313[0m[0m | time: 9.975s
[2K
| RMSProp | epoch: 018 | loss: 0.69313 - acc: 0.5107 -- iter: 256/748
[A[ATraining Step: 417  | total loss: [1m[32m0.69334[0m[0m | time: 11.144s
[2K
| RMSProp | epoch: 018 | loss: 0.69334 - acc: 0.5003 -- iter: 288/748
[A[ATraining Step: 418  | total loss: [1m[32m0.69337[0m[0m | time: 12.416s
[2K
| RMSProp | epoch: 018 | loss: 0.69337 - acc: 0.4971 -- iter: 320/748
[A[ATraining Step: 419  | total loss: [1m[32m0.69342[0m[0m | time: 13.592s
[2K
| RMSProp | epoch: 018 | loss: 0.69342 - acc: 0.4911 -- iter: 352/748
[A[ATraining Step: 420  | total loss: [1m[32m0.69327[0m[0m | time: 14.782s
[2K
| RMSProp | epoch: 018 | loss: 0.69327 - acc: 0.5077 -- iter: 384/748
[A[ATraining Step: 421  | total loss: [1m[32m0.69331[0m[0m | time: 15.770s
[2K
| RMSProp | epoch: 018 | loss: 0.69331 - acc: 0.5038 -- iter: 416/748
[A[ATraining Step: 422  | total loss: [1m[32m0.69326[0m[0m | time: 16.653s
[2K
| RMSProp | epoch: 018 | loss: 0.69326 - acc: 0.5065 -- iter: 448/748
[A[ATraining Step: 423  | total loss: [1m[32m0.69314[0m[0m | time: 17.556s
[2K
| RMSProp | epoch: 018 | loss: 0.69314 - acc: 0.5121 -- iter: 480/748
[A[ATraining Step: 424  | total loss: [1m[32m0.69347[0m[0m | time: 17.961s
[2K
| RMSProp | epoch: 018 | loss: 0.69347 - acc: 0.4953 -- iter: 512/748
[A[ATraining Step: 425  | total loss: [1m[32m0.69368[0m[0m | time: 18.406s
[2K
| RMSProp | epoch: 018 | loss: 0.69368 - acc: 0.4707 -- iter: 544/748
[A[ATraining Step: 426  | total loss: [1m[32m0.69363[0m[0m | time: 19.505s
[2K
| RMSProp | epoch: 018 | loss: 0.69363 - acc: 0.4653 -- iter: 576/748
[A[ATraining Step: 427  | total loss: [1m[32m0.69361[0m[0m | time: 20.318s
[2K
| RMSProp | epoch: 018 | loss: 0.69361 - acc: 0.4657 -- iter: 608/748
[A[ATraining Step: 428  | total loss: [1m[32m0.69348[0m[0m | time: 21.248s
[2K
| RMSProp | epoch: 018 | loss: 0.69348 - acc: 0.4847 -- iter: 640/748
[A[ATraining Step: 429  | total loss: [1m[32m0.69341[0m[0m | time: 22.185s
[2K
| RMSProp | epoch: 018 | loss: 0.69341 - acc: 0.4894 -- iter: 672/748
[A[ATraining Step: 430  | total loss: [1m[32m0.69358[0m[0m | time: 23.158s
[2K
| RMSProp | epoch: 018 | loss: 0.69358 - acc: 0.4780 -- iter: 704/748
[A[ATraining Step: 431  | total loss: [1m[32m0.69348[0m[0m | time: 24.147s
[2K
| RMSProp | epoch: 018 | loss: 0.69348 - acc: 0.4864 -- iter: 736/748
[A[ATraining Step: 432  | total loss: [1m[32m0.69343[0m[0m | time: 26.298s
[2K
| RMSProp | epoch: 018 | loss: 0.69343 - acc: 0.4878 | val_loss: 0.69310 - val_acc: 0.5085 -- iter: 748/748
--
Training Step: 433  | total loss: [1m[32m0.69352[0m[0m | time: 0.960s
[2K
| RMSProp | epoch: 019 | loss: 0.69352 - acc: 0.4796 -- iter: 032/748
[A[ATraining Step: 434  | total loss: [1m[32m0.69346[0m[0m | time: 1.776s
[2K
| RMSProp | epoch: 019 | loss: 0.69346 - acc: 0.4817 -- iter: 064/748
[A[ATraining Step: 435  | total loss: [1m[32m0.69345[0m[0m | time: 2.768s
[2K
| RMSProp | epoch: 019 | loss: 0.69345 - acc: 0.4772 -- iter: 096/748
[A[ATraining Step: 436  | total loss: [1m[32m0.69340[0m[0m | time: 3.846s
[2K
| RMSProp | epoch: 019 | loss: 0.69340 - acc: 0.4826 -- iter: 128/748
[A[ATraining Step: 437  | total loss: [1m[32m0.69334[0m[0m | time: 4.809s
[2K
| RMSProp | epoch: 019 | loss: 0.69334 - acc: 0.4875 -- iter: 160/748
[A[ATraining Step: 438  | total loss: [1m[32m0.69341[0m[0m | time: 5.787s
[2K
| RMSProp | epoch: 019 | loss: 0.69341 - acc: 0.4794 -- iter: 192/748
[A[ATraining Step: 439  | total loss: [1m[32m0.69341[0m[0m | time: 6.746s
[2K
| RMSProp | epoch: 019 | loss: 0.69341 - acc: 0.4783 -- iter: 224/748
[A[ATraining Step: 440  | total loss: [1m[32m0.69340[0m[0m | time: 7.749s
[2K
| RMSProp | epoch: 019 | loss: 0.69340 - acc: 0.4680 -- iter: 256/748
[A[ATraining Step: 441  | total loss: [1m[32m0.69337[0m[0m | time: 8.780s
[2K
| RMSProp | epoch: 019 | loss: 0.69337 - acc: 0.4743 -- iter: 288/748
[A[ATraining Step: 442  | total loss: [1m[32m0.69338[0m[0m | time: 9.906s
[2K
| RMSProp | epoch: 019 | loss: 0.69338 - acc: 0.4706 -- iter: 320/748
[A[ATraining Step: 443  | total loss: [1m[32m0.69337[0m[0m | time: 11.296s
[2K
| RMSProp | epoch: 019 | loss: 0.69337 - acc: 0.4642 -- iter: 352/748
[A[ATraining Step: 444  | total loss: [1m[32m0.69334[0m[0m | time: 12.645s
[2K
| RMSProp | epoch: 019 | loss: 0.69334 - acc: 0.4709 -- iter: 384/748
[A[ATraining Step: 445  | total loss: [1m[32m0.69333[0m[0m | time: 13.742s
[2K
| RMSProp | epoch: 019 | loss: 0.69333 - acc: 0.4707 -- iter: 416/748
[A[ATraining Step: 446  | total loss: [1m[32m0.69329[0m[0m | time: 14.559s
[2K
| RMSProp | epoch: 019 | loss: 0.69329 - acc: 0.4767 -- iter: 448/748
[A[ATraining Step: 447  | total loss: [1m[32m0.69319[0m[0m | time: 15.408s
[2K
| RMSProp | epoch: 019 | loss: 0.69319 - acc: 0.4884 -- iter: 480/748
[A[ATraining Step: 448  | total loss: [1m[32m0.69304[0m[0m | time: 16.453s
[2K
| RMSProp | epoch: 019 | loss: 0.69304 - acc: 0.4990 -- iter: 512/748
[A[ATraining Step: 449  | total loss: [1m[32m0.69322[0m[0m | time: 16.875s
[2K
| RMSProp | epoch: 019 | loss: 0.69322 - acc: 0.4928 -- iter: 544/748
[A[ATraining Step: 450  | total loss: [1m[32m0.69288[0m[0m | time: 17.292s
[2K
| RMSProp | epoch: 019 | loss: 0.69288 - acc: 0.5185 -- iter: 576/748
[A[ATraining Step: 451  | total loss: [1m[32m0.69214[0m[0m | time: 18.224s
[2K
| RMSProp | epoch: 019 | loss: 0.69214 - acc: 0.5417 -- iter: 608/748
[A[ATraining Step: 452  | total loss: [1m[32m0.69353[0m[0m | time: 19.442s
[2K
| RMSProp | epoch: 019 | loss: 0.69353 - acc: 0.5188 -- iter: 640/748
[A[ATraining Step: 453  | total loss: [1m[32m0.69342[0m[0m | time: 20.467s
[2K
| RMSProp | epoch: 019 | loss: 0.69342 - acc: 0.5200 -- iter: 672/748
[A[ATraining Step: 454  | total loss: [1m[32m0.69367[0m[0m | time: 21.320s
[2K
| RMSProp | epoch: 019 | loss: 0.69367 - acc: 0.5086 -- iter: 704/748
[A[ATraining Step: 455  | total loss: [1m[32m0.69393[0m[0m | time: 22.551s
[2K
| RMSProp | epoch: 019 | loss: 0.69393 - acc: 0.4953 -- iter: 736/748
[A[ATraining Step: 456  | total loss: [1m[32m0.69392[0m[0m | time: 31.593s
[2K
| RMSProp | epoch: 019 | loss: 0.69392 - acc: 0.4895 | val_loss: 0.69297 - val_acc: 0.5085 -- iter: 748/748
--
Training Step: 457  | total loss: [1m[32m0.69380[0m[0m | time: 0.971s
[2K
| RMSProp | epoch: 020 | loss: 0.69380 - acc: 0.4937 -- iter: 032/748
[A[ATraining Step: 458  | total loss: [1m[32m0.69374[0m[0m | time: 1.956s
[2K
| RMSProp | epoch: 020 | loss: 0.69374 - acc: 0.4912 -- iter: 064/748
[A[ATraining Step: 459  | total loss: [1m[32m0.69379[0m[0m | time: 2.946s
[2K
| RMSProp | epoch: 020 | loss: 0.69379 - acc: 0.4796 -- iter: 096/748
[A[ATraining Step: 460  | total loss: [1m[32m0.69372[0m[0m | time: 3.984s
[2K
| RMSProp | epoch: 020 | loss: 0.69372 - acc: 0.4879 -- iter: 128/748
[A[ATraining Step: 461  | total loss: [1m[32m0.69347[0m[0m | time: 5.155s
[2K
| RMSProp | epoch: 020 | loss: 0.69347 - acc: 0.5078 -- iter: 160/748
[A[ATraining Step: 462  | total loss: [1m[32m0.69357[0m[0m | time: 6.476s
[2K
| RMSProp | epoch: 020 | loss: 0.69357 - acc: 0.5008 -- iter: 192/748
[A[ATraining Step: 463  | total loss: [1m[32m0.69341[0m[0m | time: 7.916s
[2K
| RMSProp | epoch: 020 | loss: 0.69341 - acc: 0.5070 -- iter: 224/748
[A[ATraining Step: 464  | total loss: [1m[32m0.69330[0m[0m | time: 9.294s
[2K
| RMSProp | epoch: 020 | loss: 0.69330 - acc: 0.5094 -- iter: 256/748
[A[ATraining Step: 465  | total loss: [1m[32m0.69314[0m[0m | time: 12.324s
[2K
| RMSProp | epoch: 020 | loss: 0.69314 - acc: 0.5147 -- iter: 288/748
[A[ATraining Step: 466  | total loss: [1m[32m0.69323[0m[0m | time: 24.883s
[2K
| RMSProp | epoch: 020 | loss: 0.69323 - acc: 0.5101 -- iter: 320/748
[A[ATraining Step: 467  | total loss: [1m[32m0.69355[0m[0m | time: 28.081s
[2K
| RMSProp | epoch: 020 | loss: 0.69355 - acc: 0.4966 -- iter: 352/748
[A[ATraining Step: 468  | total loss: [1m[32m0.69333[0m[0m | time: 29.182s
[2K
| RMSProp | epoch: 020 | loss: 0.69333 - acc: 0.5094 -- iter: 384/748
[A[ATraining Step: 469  | total loss: [1m[32m0.69336[0m[0m | time: 30.367s
[2K
| RMSProp | epoch: 020 | loss: 0.69336 - acc: 0.5054 -- iter: 416/748
[A[ATraining Step: 470  | total loss: [1m[32m0.69318[0m[0m | time: 31.586s
[2K
| RMSProp | epoch: 020 | loss: 0.69318 - acc: 0.5111 -- iter: 448/748
[A[ATraining Step: 471  | total loss: [1m[32m0.69282[0m[0m | time: 32.908s
[2K
| RMSProp | epoch: 020 | loss: 0.69282 - acc: 0.5225 -- iter: 480/748
[A[ATraining Step: 472  | total loss: [1m[32m0.69268[0m[0m | time: 34.187s
[2K
| RMSProp | epoch: 020 | loss: 0.69268 - acc: 0.5233 -- iter: 512/748
[A[ATraining Step: 473  | total loss: [1m[32m0.69253[0m[0m | time: 35.608s
[2K
| RMSProp | epoch: 020 | loss: 0.69253 - acc: 0.5241 -- iter: 544/748
[A[ATraining Step: 474  | total loss: [1m[32m0.69305[0m[0m | time: 36.095s
[2K
| RMSProp | epoch: 020 | loss: 0.69305 - acc: 0.5124 -- iter: 576/748
[A[ATraining Step: 475  | total loss: [1m[32m0.69344[0m[0m | time: 36.617s
[2K
| RMSProp | epoch: 020 | loss: 0.69344 - acc: 0.4944 -- iter: 608/748
[A[ATraining Step: 476  | total loss: [1m[32m0.69350[0m[0m | time: 37.776s
[2K
| RMSProp | epoch: 020 | loss: 0.69350 - acc: 0.4783 -- iter: 640/748
[A[ATraining Step: 477  | total loss: [1m[32m0.69342[0m[0m | time: 38.999s
[2K
| RMSProp | epoch: 020 | loss: 0.69342 - acc: 0.4805 -- iter: 672/748
[A[ATraining Step: 478  | total loss: [1m[32m0.69332[0m[0m | time: 40.018s
[2K
| RMSProp | epoch: 020 | loss: 0.69332 - acc: 0.5012 -- iter: 704/748
[A[ATraining Step: 479  | total loss: [1m[32m0.69316[0m[0m | time: 41.279s
[2K
| RMSProp | epoch: 020 | loss: 0.69316 - acc: 0.5073 -- iter: 736/748
[A[ATraining Step: 480  | total loss: [1m[32m0.69345[0m[0m | time: 44.325s
[2K
| RMSProp | epoch: 020 | loss: 0.69345 - acc: 0.4972 | val_loss: 0.69225 - val_acc: 0.5556 -- iter: 748/748
--
Training Step: 481  | total loss: [1m[32m0.69333[0m[0m | time: 1.229s
[2K
| RMSProp | epoch: 021 | loss: 0.69333 - acc: 0.4975 -- iter: 032/748
[A[ATraining Step: 482  | total loss: [1m[32m0.69326[0m[0m | time: 2.461s
[2K
| RMSProp | epoch: 021 | loss: 0.69326 - acc: 0.4978 -- iter: 064/748
[A[ATraining Step: 483  | total loss: [1m[32m0.69301[0m[0m | time: 3.643s
[2K
| RMSProp | epoch: 021 | loss: 0.69301 - acc: 0.5230 -- iter: 096/748
[A[ATraining Step: 484  | total loss: [1m[32m0.69302[0m[0m | time: 4.867s
[2K
| RMSProp | epoch: 021 | loss: 0.69302 - acc: 0.5176 -- iter: 128/748
[A[ATraining Step: 485  | total loss: [1m[32m0.69304[0m[0m | time: 6.124s
[2K
| RMSProp | epoch: 021 | loss: 0.69304 - acc: 0.5127 -- iter: 160/748
[A[ATraining Step: 486  | total loss: [1m[32m0.69257[0m[0m | time: 7.387s
[2K
| RMSProp | epoch: 021 | loss: 0.69257 - acc: 0.5239 -- iter: 192/748
[A[ATraining Step: 487  | total loss: [1m[32m0.69264[0m[0m | time: 8.597s
[2K
| RMSProp | epoch: 021 | loss: 0.69264 - acc: 0.5215 -- iter: 224/748
[A[ATraining Step: 488  | total loss: [1m[32m0.69315[0m[0m | time: 9.760s
[2K
| RMSProp | epoch: 021 | loss: 0.69315 - acc: 0.5100 -- iter: 256/748
[A[ATraining Step: 489  | total loss: [1m[32m0.69297[0m[0m | time: 10.980s
[2K
| RMSProp | epoch: 021 | loss: 0.69297 - acc: 0.5246 -- iter: 288/748
[A[ATraining Step: 490  | total loss: [1m[32m0.69282[0m[0m | time: 12.247s
[2K
| RMSProp | epoch: 021 | loss: 0.69282 - acc: 0.5253 -- iter: 320/748
[A[ATraining Step: 491  | total loss: [1m[32m0.69231[0m[0m | time: 13.208s
[2K
| RMSProp | epoch: 021 | loss: 0.69231 - acc: 0.5478 -- iter: 352/748
[A[ATraining Step: 492  | total loss: [1m[32m0.69298[0m[0m | time: 14.152s
[2K
| RMSProp | epoch: 021 | loss: 0.69298 - acc: 0.5336 -- iter: 384/748
[A[ATraining Step: 493  | total loss: [1m[32m0.69247[0m[0m | time: 15.033s
[2K
| RMSProp | epoch: 021 | loss: 0.69247 - acc: 0.5615 -- iter: 416/748
[A[ATraining Step: 494  | total loss: [1m[32m0.69253[0m[0m | time: 15.955s
[2K
| RMSProp | epoch: 021 | loss: 0.69253 - acc: 0.5491 -- iter: 448/748
[A[ATraining Step: 495  | total loss: [1m[32m0.69241[0m[0m | time: 16.879s
[2K
| RMSProp | epoch: 021 | loss: 0.69241 - acc: 0.5411 -- iter: 480/748
[A[ATraining Step: 496  | total loss: [1m[32m0.69155[0m[0m | time: 17.757s
[2K
| RMSProp | epoch: 021 | loss: 0.69155 - acc: 0.5495 -- iter: 512/748
[A[ATraining Step: 497  | total loss: [1m[32m0.69177[0m[0m | time: 18.596s
[2K
| RMSProp | epoch: 021 | loss: 0.69177 - acc: 0.5414 -- iter: 544/748
[A[ATraining Step: 498  | total loss: [1m[32m0.69115[0m[0m | time: 19.633s
[2K
| RMSProp | epoch: 021 | loss: 0.69115 - acc: 0.5497 -- iter: 576/748
[A[ATraining Step: 499  | total loss: [1m[32m0.69015[0m[0m | time: 20.067s
[2K
| RMSProp | epoch: 021 | loss: 0.69015 - acc: 0.5666 -- iter: 608/748
[A[ATraining Step: 500  | total loss: [1m[32m0.69021[0m[0m | time: 20.478s
[2K
| RMSProp | epoch: 021 | loss: 0.69021 - acc: 0.5600 -- iter: 640/748
[A[ATraining Step: 501  | total loss: [1m[32m0.68891[0m[0m | time: 21.347s
[2K
| RMSProp | epoch: 021 | loss: 0.68891 - acc: 0.5623 -- iter: 672/748
[A[ATraining Step: 502  | total loss: [1m[32m0.68566[0m[0m | time: 22.167s
[2K
| RMSProp | epoch: 021 | loss: 0.68566 - acc: 0.5686 -- iter: 704/748
[A[ATraining Step: 503  | total loss: [1m[32m0.69091[0m[0m | time: 23.105s
[2K
| RMSProp | epoch: 021 | loss: 0.69091 - acc: 0.5586 -- iter: 736/748
[A[ATraining Step: 504  | total loss: [1m[32m0.68977[0m[0m | time: 25.235s
[2K
| RMSProp | epoch: 021 | loss: 0.68977 - acc: 0.5746 | val_loss: 0.68339 - val_acc: 0.5299 -- iter: 748/748
--
Training Step: 505  | total loss: [1m[32m0.68846[0m[0m | time: 1.021s
[2K
| RMSProp | epoch: 022 | loss: 0.68846 - acc: 0.5890 -- iter: 032/748
[A[ATraining Step: 506  | total loss: [1m[32m0.68889[0m[0m | time: 1.980s
[2K
| RMSProp | epoch: 022 | loss: 0.68889 - acc: 0.5833 -- iter: 064/748
[A[ATraining Step: 507  | total loss: [1m[32m0.68741[0m[0m | time: 2.930s
[2K
| RMSProp | epoch: 022 | loss: 0.68741 - acc: 0.5968 -- iter: 096/748
[A[ATraining Step: 508  | total loss: [1m[32m0.68832[0m[0m | time: 3.771s
[2K
| RMSProp | epoch: 022 | loss: 0.68832 - acc: 0.5934 -- iter: 128/748
[A[ATraining Step: 509  | total loss: [1m[32m0.68576[0m[0m | time: 4.888s
[2K
| RMSProp | epoch: 022 | loss: 0.68576 - acc: 0.6028 -- iter: 160/748
[A[ATraining Step: 510  | total loss: [1m[32m0.68194[0m[0m | time: 5.943s
[2K
| RMSProp | epoch: 022 | loss: 0.68194 - acc: 0.6050 -- iter: 192/748
[A[ATraining Step: 511  | total loss: [1m[32m0.68594[0m[0m | time: 6.766s
[2K
| RMSProp | epoch: 022 | loss: 0.68594 - acc: 0.5883 -- iter: 224/748
[A[ATraining Step: 512  | total loss: [1m[32m0.68688[0m[0m | time: 7.974s
[2K
| RMSProp | epoch: 022 | loss: 0.68688 - acc: 0.5732 -- iter: 256/748
[A[ATraining Step: 513  | total loss: [1m[32m0.68638[0m[0m | time: 9.379s
[2K
| RMSProp | epoch: 022 | loss: 0.68638 - acc: 0.5721 -- iter: 288/748
[A[ATraining Step: 514  | total loss: [1m[32m0.68466[0m[0m | time: 10.553s
[2K
| RMSProp | epoch: 022 | loss: 0.68466 - acc: 0.5837 -- iter: 320/748
[A[ATraining Step: 515  | total loss: [1m[32m0.68305[0m[0m | time: 12.415s
[2K
| RMSProp | epoch: 022 | loss: 0.68305 - acc: 0.5753 -- iter: 352/748
[A[ATraining Step: 516  | total loss: [1m[32m0.68082[0m[0m | time: 13.628s
[2K
| RMSProp | epoch: 022 | loss: 0.68082 - acc: 0.5865 -- iter: 384/748
[A[ATraining Step: 517  | total loss: [1m[32m0.67618[0m[0m | time: 14.938s
[2K
| RMSProp | epoch: 022 | loss: 0.67618 - acc: 0.6029 -- iter: 416/748
[A[ATraining Step: 518  | total loss: [1m[32m0.67432[0m[0m | time: 16.226s
[2K
| RMSProp | epoch: 022 | loss: 0.67432 - acc: 0.6019 -- iter: 448/748
[A[ATraining Step: 519  | total loss: [1m[32m0.66692[0m[0m | time: 17.473s
[2K
| RMSProp | epoch: 022 | loss: 0.66692 - acc: 0.6168 -- iter: 480/748
[A[ATraining Step: 520  | total loss: [1m[32m0.68423[0m[0m | time: 18.800s
[2K
| RMSProp | epoch: 022 | loss: 0.68423 - acc: 0.5988 -- iter: 512/748
[A[ATraining Step: 521  | total loss: [1m[32m0.68180[0m[0m | time: 20.129s
[2K
| RMSProp | epoch: 022 | loss: 0.68180 - acc: 0.6139 -- iter: 544/748
[A[ATraining Step: 522  | total loss: [1m[32m0.68097[0m[0m | time: 21.171s
[2K
| RMSProp | epoch: 022 | loss: 0.68097 - acc: 0.6150 -- iter: 576/748
[A[ATraining Step: 523  | total loss: [1m[32m0.67767[0m[0m | time: 22.208s
[2K
| RMSProp | epoch: 022 | loss: 0.67767 - acc: 0.6129 -- iter: 608/748
[A[ATraining Step: 524  | total loss: [1m[32m0.67506[0m[0m | time: 22.710s
[2K
| RMSProp | epoch: 022 | loss: 0.67506 - acc: 0.6141 -- iter: 640/748
[A[ATraining Step: 525  | total loss: [1m[32m0.67120[0m[0m | time: 23.302s
[2K
| RMSProp | epoch: 022 | loss: 0.67120 - acc: 0.6277 -- iter: 672/748
[A[ATraining Step: 526  | total loss: [1m[32m0.66063[0m[0m | time: 24.614s
[2K
| RMSProp | epoch: 022 | loss: 0.66063 - acc: 0.6483 -- iter: 704/748
[A[ATraining Step: 527  | total loss: [1m[32m0.66023[0m[0m | time: 26.683s
[2K
| RMSProp | epoch: 022 | loss: 0.66023 - acc: 0.6428 -- iter: 736/748
[A[ATraining Step: 528  | total loss: [1m[32m0.66387[0m[0m | time: 31.380s
[2K
| RMSProp | epoch: 022 | loss: 0.66387 - acc: 0.6348 | val_loss: 0.67613 - val_acc: 0.5598 -- iter: 748/748
--
Training Step: 529  | total loss: [1m[32m0.65872[0m[0m | time: 1.264s
[2K
| RMSProp | epoch: 023 | loss: 0.65872 - acc: 0.6369 -- iter: 032/748
[A[ATraining Step: 530  | total loss: [1m[32m0.65967[0m[0m | time: 2.511s
[2K
| RMSProp | epoch: 023 | loss: 0.65967 - acc: 0.6295 -- iter: 064/748
[A[ATraining Step: 531  | total loss: [1m[32m0.65700[0m[0m | time: 3.729s
[2K
| RMSProp | epoch: 023 | loss: 0.65700 - acc: 0.6322 -- iter: 096/748
[A[ATraining Step: 532  | total loss: [1m[32m0.65248[0m[0m | time: 4.938s
[2K
| RMSProp | epoch: 023 | loss: 0.65248 - acc: 0.6377 -- iter: 128/748
[A[ATraining Step: 533  | total loss: [1m[32m0.65299[0m[0m | time: 6.073s
[2K
| RMSProp | epoch: 023 | loss: 0.65299 - acc: 0.6333 -- iter: 160/748
[A[ATraining Step: 534  | total loss: [1m[32m0.65289[0m[0m | time: 7.362s
[2K
| RMSProp | epoch: 023 | loss: 0.65289 - acc: 0.6294 -- iter: 192/748
[A[ATraining Step: 535  | total loss: [1m[32m0.65250[0m[0m | time: 8.745s
[2K
| RMSProp | epoch: 023 | loss: 0.65250 - acc: 0.6195 -- iter: 224/748
[A[ATraining Step: 536  | total loss: [1m[32m0.65293[0m[0m | time: 10.699s
[2K
| RMSProp | epoch: 023 | loss: 0.65293 - acc: 0.6170 -- iter: 256/748
[A[ATraining Step: 537  | total loss: [1m[32m0.64259[0m[0m | time: 19.552s
[2K
| RMSProp | epoch: 023 | loss: 0.64259 - acc: 0.6303 -- iter: 288/748
[A[ATraining Step: 538  | total loss: [1m[32m0.64052[0m[0m | time: 22.640s
[2K
| RMSProp | epoch: 023 | loss: 0.64052 - acc: 0.6360 -- iter: 320/748
[A[ATraining Step: 539  | total loss: [1m[32m0.64040[0m[0m | time: 23.675s
[2K
| RMSProp | epoch: 023 | loss: 0.64040 - acc: 0.6349 -- iter: 352/748
[A[ATraining Step: 540  | total loss: [1m[32m0.63875[0m[0m | time: 24.894s
[2K
| RMSProp | epoch: 023 | loss: 0.63875 - acc: 0.6339 -- iter: 384/748
[A[ATraining Step: 541  | total loss: [1m[32m0.63385[0m[0m | time: 26.126s
[2K
| RMSProp | epoch: 023 | loss: 0.63385 - acc: 0.6455 -- iter: 416/748
[A[ATraining Step: 542  | total loss: [1m[32m0.62296[0m[0m | time: 27.474s
[2K
| RMSProp | epoch: 023 | loss: 0.62296 - acc: 0.6591 -- iter: 448/748
[A[ATraining Step: 543  | total loss: [1m[32m0.62233[0m[0m | time: 28.818s
[2K
| RMSProp | epoch: 023 | loss: 0.62233 - acc: 0.6588 -- iter: 480/748
[A[ATraining Step: 544  | total loss: [1m[32m0.62160[0m[0m | time: 30.266s
[2K
| RMSProp | epoch: 023 | loss: 0.62160 - acc: 0.6585 -- iter: 512/748
[A[ATraining Step: 545  | total loss: [1m[32m0.61598[0m[0m | time: 31.655s
[2K
| RMSProp | epoch: 023 | loss: 0.61598 - acc: 0.6646 -- iter: 544/748
[A[ATraining Step: 546  | total loss: [1m[32m0.60536[0m[0m | time: 32.830s
[2K
| RMSProp | epoch: 023 | loss: 0.60536 - acc: 0.6856 -- iter: 576/748
[A[ATraining Step: 547  | total loss: [1m[32m0.62099[0m[0m | time: 34.123s
[2K
| RMSProp | epoch: 023 | loss: 0.62099 - acc: 0.6670 -- iter: 608/748
[A[ATraining Step: 548  | total loss: [1m[32m0.61381[0m[0m | time: 35.344s
[2K
| RMSProp | epoch: 023 | loss: 0.61381 - acc: 0.6722 -- iter: 640/748
[A[ATraining Step: 549  | total loss: [1m[32m0.60915[0m[0m | time: 35.907s
[2K
| RMSProp | epoch: 023 | loss: 0.60915 - acc: 0.6737 -- iter: 672/748
[A[ATraining Step: 550  | total loss: [1m[32m0.60905[0m[0m | time: 36.439s
[2K
| RMSProp | epoch: 023 | loss: 0.60905 - acc: 0.6730 -- iter: 704/748
[A[ATraining Step: 551  | total loss: [1m[32m0.60042[0m[0m | time: 40.814s
[2K
| RMSProp | epoch: 023 | loss: 0.60042 - acc: 0.6724 -- iter: 736/748
[A[ATraining Step: 552  | total loss: [1m[32m0.59796[0m[0m | time: 43.948s
[2K
| RMSProp | epoch: 023 | loss: 0.59796 - acc: 0.6739 | val_loss: 0.71926 - val_acc: 0.5470 -- iter: 748/748
--
Training Step: 553  | total loss: [1m[32m0.60591[0m[0m | time: 1.294s
[2K
| RMSProp | epoch: 024 | loss: 0.60591 - acc: 0.6659 -- iter: 032/748
[A[ATraining Step: 554  | total loss: [1m[32m0.61237[0m[0m | time: 2.555s
[2K
| RMSProp | epoch: 024 | loss: 0.61237 - acc: 0.6649 -- iter: 064/748
[A[ATraining Step: 555  | total loss: [1m[32m0.61479[0m[0m | time: 4.014s
[2K
| RMSProp | epoch: 024 | loss: 0.61479 - acc: 0.6609 -- iter: 096/748
[A[ATraining Step: 556  | total loss: [1m[32m0.61269[0m[0m | time: 5.358s
[2K
| RMSProp | epoch: 024 | loss: 0.61269 - acc: 0.6605 -- iter: 128/748
[A[ATraining Step: 557  | total loss: [1m[32m0.61284[0m[0m | time: 6.709s
[2K
| RMSProp | epoch: 024 | loss: 0.61284 - acc: 0.6538 -- iter: 160/748
[A[ATraining Step: 558  | total loss: [1m[32m0.60426[0m[0m | time: 7.927s
[2K
| RMSProp | epoch: 024 | loss: 0.60426 - acc: 0.6603 -- iter: 192/748
[A[ATraining Step: 559  | total loss: [1m[32m0.60801[0m[0m | time: 8.787s
[2K
| RMSProp | epoch: 024 | loss: 0.60801 - acc: 0.6599 -- iter: 224/748
[A[ATraining Step: 560  | total loss: [1m[32m0.60496[0m[0m | time: 9.841s
[2K
| RMSProp | epoch: 024 | loss: 0.60496 - acc: 0.6720 -- iter: 256/748
[A[ATraining Step: 561  | total loss: [1m[32m0.60399[0m[0m | time: 11.123s
[2K
| RMSProp | epoch: 024 | loss: 0.60399 - acc: 0.6704 -- iter: 288/748
[A[ATraining Step: 562  | total loss: [1m[32m0.60843[0m[0m | time: 12.327s
[2K
| RMSProp | epoch: 024 | loss: 0.60843 - acc: 0.6753 -- iter: 320/748
[A[ATraining Step: 563  | total loss: [1m[32m0.60701[0m[0m | time: 13.617s
[2K
| RMSProp | epoch: 024 | loss: 0.60701 - acc: 0.6765 -- iter: 352/748
[A[ATraining Step: 564  | total loss: [1m[32m0.60565[0m[0m | time: 14.916s
[2K
| RMSProp | epoch: 024 | loss: 0.60565 - acc: 0.6807 -- iter: 384/748
[A[ATraining Step: 565  | total loss: [1m[32m0.59297[0m[0m | time: 16.257s
[2K
| RMSProp | epoch: 024 | loss: 0.59297 - acc: 0.6939 -- iter: 416/748
[A[ATraining Step: 566  | total loss: [1m[32m0.60814[0m[0m | time: 17.549s
[2K
| RMSProp | epoch: 024 | loss: 0.60814 - acc: 0.6870 -- iter: 448/748
[A[ATraining Step: 567  | total loss: [1m[32m0.61475[0m[0m | time: 18.602s
[2K
| RMSProp | epoch: 024 | loss: 0.61475 - acc: 0.6808 -- iter: 480/748
[A[ATraining Step: 568  | total loss: [1m[32m0.61874[0m[0m | time: 19.516s
[2K
| RMSProp | epoch: 024 | loss: 0.61874 - acc: 0.6690 -- iter: 512/748
[A[ATraining Step: 569  | total loss: [1m[32m0.60873[0m[0m | time: 20.579s
[2K
| RMSProp | epoch: 024 | loss: 0.60873 - acc: 0.6802 -- iter: 544/748
[A[ATraining Step: 570  | total loss: [1m[32m0.59913[0m[0m | time: 21.689s
[2K
| RMSProp | epoch: 024 | loss: 0.59913 - acc: 0.6966 -- iter: 576/748
[A[ATraining Step: 571  | total loss: [1m[32m0.58904[0m[0m | time: 22.510s
[2K
| RMSProp | epoch: 024 | loss: 0.58904 - acc: 0.7082 -- iter: 608/748
[A[ATraining Step: 572  | total loss: [1m[32m0.60134[0m[0m | time: 23.372s
[2K
| RMSProp | epoch: 024 | loss: 0.60134 - acc: 0.6873 -- iter: 640/748
[A[ATraining Step: 573  | total loss: [1m[32m0.59200[0m[0m | time: 24.338s
[2K
| RMSProp | epoch: 024 | loss: 0.59200 - acc: 0.6967 -- iter: 672/748
[A[ATraining Step: 574  | total loss: [1m[32m0.59076[0m[0m | time: 24.741s
[2K
| RMSProp | epoch: 024 | loss: 0.59076 - acc: 0.6896 -- iter: 704/748
[A[ATraining Step: 575  | total loss: [1m[32m0.58494[0m[0m | time: 25.119s
[2K
| RMSProp | epoch: 024 | loss: 0.58494 - acc: 0.6956 -- iter: 736/748
[A[ATraining Step: 576  | total loss: [1m[32m0.57028[0m[0m | time: 27.253s
[2K
| RMSProp | epoch: 024 | loss: 0.57028 - acc: 0.7094 | val_loss: 0.62448 - val_acc: 0.6581 -- iter: 748/748
--
Training Step: 577  | total loss: [1m[32m0.57646[0m[0m | time: 0.983s
[2K
| RMSProp | epoch: 025 | loss: 0.57646 - acc: 0.7072 -- iter: 032/748
[A[ATraining Step: 578  | total loss: [1m[32m0.57157[0m[0m | time: 1.895s
[2K
| RMSProp | epoch: 025 | loss: 0.57157 - acc: 0.7115 -- iter: 064/748
[A[ATraining Step: 579  | total loss: [1m[32m0.57508[0m[0m | time: 2.756s
[2K
| RMSProp | epoch: 025 | loss: 0.57508 - acc: 0.7059 -- iter: 096/748
[A[ATraining Step: 580  | total loss: [1m[32m0.56461[0m[0m | time: 3.770s
[2K
| RMSProp | epoch: 025 | loss: 0.56461 - acc: 0.7229 -- iter: 128/748
[A[ATraining Step: 581  | total loss: [1m[32m0.56562[0m[0m | time: 4.859s
[2K
| RMSProp | epoch: 025 | loss: 0.56562 - acc: 0.7256 -- iter: 160/748
[A[ATraining Step: 582  | total loss: [1m[32m0.56757[0m[0m | time: 5.758s
[2K
| RMSProp | epoch: 025 | loss: 0.56757 - acc: 0.7249 -- iter: 192/748
[A[ATraining Step: 583  | total loss: [1m[32m0.56259[0m[0m | time: 6.622s
[2K
| RMSProp | epoch: 025 | loss: 0.56259 - acc: 0.7243 -- iter: 224/748
[A[ATraining Step: 584  | total loss: [1m[32m0.59128[0m[0m | time: 7.565s
[2K
| RMSProp | epoch: 025 | loss: 0.59128 - acc: 0.7112 -- iter: 256/748
[A[ATraining Step: 585  | total loss: [1m[32m0.58860[0m[0m | time: 8.579s
[2K
| RMSProp | epoch: 025 | loss: 0.58860 - acc: 0.7120 -- iter: 288/748
[A[ATraining Step: 586  | total loss: [1m[32m0.58079[0m[0m | time: 9.491s
[2K
| RMSProp | epoch: 025 | loss: 0.58079 - acc: 0.7252 -- iter: 320/748
[A[ATraining Step: 587  | total loss: [1m[32m0.57464[0m[0m | time: 10.562s
[2K
| RMSProp | epoch: 025 | loss: 0.57464 - acc: 0.7183 -- iter: 352/748
[A[ATraining Step: 588  | total loss: [1m[32m0.57738[0m[0m | time: 11.795s
[2K
| RMSProp | epoch: 025 | loss: 0.57738 - acc: 0.7152 -- iter: 384/748
[A[ATraining Step: 589  | total loss: [1m[32m0.57631[0m[0m | time: 13.025s
[2K
| RMSProp | epoch: 025 | loss: 0.57631 - acc: 0.7187 -- iter: 416/748
[A[ATraining Step: 590  | total loss: [1m[32m0.57948[0m[0m | time: 14.022s
[2K
| RMSProp | epoch: 025 | loss: 0.57948 - acc: 0.7093 -- iter: 448/748
[A[ATraining Step: 591  | total loss: [1m[32m0.56243[0m[0m | time: 15.191s
[2K
| RMSProp | epoch: 025 | loss: 0.56243 - acc: 0.7259 -- iter: 480/748
[A[ATraining Step: 592  | total loss: [1m[32m0.56235[0m[0m | time: 16.529s
[2K
| RMSProp | epoch: 025 | loss: 0.56235 - acc: 0.7252 -- iter: 512/748
[A[ATraining Step: 593  | total loss: [1m[32m0.56321[0m[0m | time: 17.929s
[2K
| RMSProp | epoch: 025 | loss: 0.56321 - acc: 0.7276 -- iter: 544/748
[A[ATraining Step: 594  | total loss: [1m[32m0.55531[0m[0m | time: 19.098s
[2K
| RMSProp | epoch: 025 | loss: 0.55531 - acc: 0.7299 -- iter: 576/748
[A[ATraining Step: 595  | total loss: [1m[32m0.55594[0m[0m | time: 20.267s
[2K
| RMSProp | epoch: 025 | loss: 0.55594 - acc: 0.7256 -- iter: 608/748
[A[ATraining Step: 596  | total loss: [1m[32m0.55116[0m[0m | time: 21.633s
[2K
| RMSProp | epoch: 025 | loss: 0.55116 - acc: 0.7312 -- iter: 640/748
[A[ATraining Step: 597  | total loss: [1m[32m0.54860[0m[0m | time: 22.916s
[2K
| RMSProp | epoch: 025 | loss: 0.54860 - acc: 0.7268 -- iter: 672/748
[A[ATraining Step: 598  | total loss: [1m[32m0.54527[0m[0m | time: 25.031s
[2K
| RMSProp | epoch: 025 | loss: 0.54527 - acc: 0.7229 -- iter: 704/748
[A[ATraining Step: 599  | total loss: [1m[32m0.54835[0m[0m | time: 25.549s
[2K
| RMSProp | epoch: 025 | loss: 0.54835 - acc: 0.7162 -- iter: 736/748
[A[ATraining Step: 600  | total loss: [1m[32m0.54229[0m[0m | time: 27.943s
[2K
| RMSProp | epoch: 025 | loss: 0.54229 - acc: 0.7363 | val_loss: 0.59583 - val_acc: 0.6624 -- iter: 748/748
--
Training Step: 601  | total loss: [1m[32m0.52743[0m[0m | time: 1.210s
[2K
| RMSProp | epoch: 026 | loss: 0.52743 - acc: 0.7460 -- iter: 032/748
[A[ATraining Step: 602  | total loss: [1m[32m0.52986[0m[0m | time: 2.425s
[2K
| RMSProp | epoch: 026 | loss: 0.52986 - acc: 0.7526 -- iter: 064/748
[A[ATraining Step: 603  | total loss: [1m[32m0.52405[0m[0m | time: 3.719s
[2K
| RMSProp | epoch: 026 | loss: 0.52405 - acc: 0.7524 -- iter: 096/748
[A[ATraining Step: 604  | total loss: [1m[32m0.51977[0m[0m | time: 4.969s
[2K
| RMSProp | epoch: 026 | loss: 0.51977 - acc: 0.7521 -- iter: 128/748
[A[ATraining Step: 605  | total loss: [1m[32m0.53327[0m[0m | time: 6.344s
[2K
| RMSProp | epoch: 026 | loss: 0.53327 - acc: 0.7457 -- iter: 160/748
[A[ATraining Step: 606  | total loss: [1m[32m0.54016[0m[0m | time: 7.753s
[2K
| RMSProp | epoch: 026 | loss: 0.54016 - acc: 0.7399 -- iter: 192/748
[A[ATraining Step: 607  | total loss: [1m[32m0.54524[0m[0m | time: 9.980s
[2K
| RMSProp | epoch: 026 | loss: 0.54524 - acc: 0.7346 -- iter: 224/748
[A[ATraining Step: 608  | total loss: [1m[32m0.53808[0m[0m | time: 13.206s
[2K
| RMSProp | epoch: 026 | loss: 0.53808 - acc: 0.7424 -- iter: 256/748
[A[ATraining Step: 609  | total loss: [1m[32m0.54672[0m[0m | time: 18.069s
[2K
| RMSProp | epoch: 026 | loss: 0.54672 - acc: 0.7369 -- iter: 288/748
[A[ATraining Step: 610  | total loss: [1m[32m0.54945[0m[0m | time: 26.733s
[2K
| RMSProp | epoch: 026 | loss: 0.54945 - acc: 0.7382 -- iter: 320/748
[A[ATraining Step: 611  | total loss: [1m[32m0.54729[0m[0m | time: 27.848s
[2K
| RMSProp | epoch: 026 | loss: 0.54729 - acc: 0.7363 -- iter: 352/748
[A[ATraining Step: 612  | total loss: [1m[32m0.54032[0m[0m | time: 29.103s
[2K
| RMSProp | epoch: 026 | loss: 0.54032 - acc: 0.7408 -- iter: 384/748
[A[ATraining Step: 613  | total loss: [1m[32m0.53470[0m[0m | time: 30.411s
[2K
| RMSProp | epoch: 026 | loss: 0.53470 - acc: 0.7386 -- iter: 416/748
[A[ATraining Step: 614  | total loss: [1m[32m0.54201[0m[0m | time: 31.552s
[2K
| RMSProp | epoch: 026 | loss: 0.54201 - acc: 0.7272 -- iter: 448/748
[A[ATraining Step: 615  | total loss: [1m[32m0.56480[0m[0m | time: 32.752s
[2K
| RMSProp | epoch: 026 | loss: 0.56480 - acc: 0.7045 -- iter: 480/748
[A[ATraining Step: 616  | total loss: [1m[32m0.55737[0m[0m | time: 34.129s
[2K
| RMSProp | epoch: 026 | loss: 0.55737 - acc: 0.7090 -- iter: 512/748
[A[ATraining Step: 617  | total loss: [1m[32m0.54341[0m[0m | time: 35.343s
[2K
| RMSProp | epoch: 026 | loss: 0.54341 - acc: 0.7194 -- iter: 544/748
[A[ATraining Step: 618  | total loss: [1m[32m0.54617[0m[0m | time: 36.692s
[2K
| RMSProp | epoch: 026 | loss: 0.54617 - acc: 0.7193 -- iter: 576/748
[A[ATraining Step: 619  | total loss: [1m[32m0.54364[0m[0m | time: 37.992s
[2K
| RMSProp | epoch: 026 | loss: 0.54364 - acc: 0.7224 -- iter: 608/748
[A[ATraining Step: 620  | total loss: [1m[32m0.53161[0m[0m | time: 39.285s
[2K
| RMSProp | epoch: 026 | loss: 0.53161 - acc: 0.7377 -- iter: 640/748
[A[ATraining Step: 621  | total loss: [1m[32m0.52054[0m[0m | time: 42.507s
[2K
| RMSProp | epoch: 026 | loss: 0.52054 - acc: 0.7514 -- iter: 672/748
[A[ATraining Step: 622  | total loss: [1m[32m0.51344[0m[0m | time: 43.683s
[2K
| RMSProp | epoch: 026 | loss: 0.51344 - acc: 0.7544 -- iter: 704/748
[A[ATraining Step: 623  | total loss: [1m[32m0.51740[0m[0m | time: 44.857s
[2K
| RMSProp | epoch: 026 | loss: 0.51740 - acc: 0.7508 -- iter: 736/748
[A[ATraining Step: 624  | total loss: [1m[32m0.51132[0m[0m | time: 47.278s
[2K
| RMSProp | epoch: 026 | loss: 0.51132 - acc: 0.7507 | val_loss: 0.63253 - val_acc: 0.6410 -- iter: 748/748
--
Training Step: 625  | total loss: [1m[32m0.49970[0m[0m | time: 0.538s
[2K
| RMSProp | epoch: 027 | loss: 0.49970 - acc: 0.7423 -- iter: 032/748
[A[ATraining Step: 626  | total loss: [1m[32m0.47837[0m[0m | time: 1.736s
[2K
| RMSProp | epoch: 027 | loss: 0.47837 - acc: 0.7598 -- iter: 064/748
[A[ATraining Step: 627  | total loss: [1m[32m0.47452[0m[0m | time: 2.826s
[2K
| RMSProp | epoch: 027 | loss: 0.47452 - acc: 0.7650 -- iter: 096/748
[A[ATraining Step: 628  | total loss: [1m[32m0.47362[0m[0m | time: 3.933s
[2K
| RMSProp | epoch: 027 | loss: 0.47362 - acc: 0.7698 -- iter: 128/748
[A[ATraining Step: 629  | total loss: [1m[32m0.46532[0m[0m | time: 5.236s
[2K
| RMSProp | epoch: 027 | loss: 0.46532 - acc: 0.7709 -- iter: 160/748
[A[ATraining Step: 630  | total loss: [1m[32m0.49248[0m[0m | time: 6.494s
[2K
| RMSProp | epoch: 027 | loss: 0.49248 - acc: 0.7563 -- iter: 192/748
[A[ATraining Step: 631  | total loss: [1m[32m0.48264[0m[0m | time: 7.828s
[2K
| RMSProp | epoch: 027 | loss: 0.48264 - acc: 0.7620 -- iter: 224/748
[A[ATraining Step: 632  | total loss: [1m[32m0.47945[0m[0m | time: 10.177s
[2K
| RMSProp | epoch: 027 | loss: 0.47945 - acc: 0.7701 -- iter: 256/748
[A[ATraining Step: 633  | total loss: [1m[32m0.49339[0m[0m | time: 11.287s
[2K
| RMSProp | epoch: 027 | loss: 0.49339 - acc: 0.7525 -- iter: 288/748
[A[ATraining Step: 634  | total loss: [1m[32m0.49650[0m[0m | time: 12.612s
[2K
| RMSProp | epoch: 027 | loss: 0.49650 - acc: 0.7522 -- iter: 320/748
[A[ATraining Step: 635  | total loss: [1m[32m0.48711[0m[0m | time: 13.908s
[2K
| RMSProp | epoch: 027 | loss: 0.48711 - acc: 0.7583 -- iter: 352/748
[A[ATraining Step: 636  | total loss: [1m[32m0.48888[0m[0m | time: 15.136s
[2K
| RMSProp | epoch: 027 | loss: 0.48888 - acc: 0.7574 -- iter: 384/748
[A[ATraining Step: 637  | total loss: [1m[32m0.49451[0m[0m | time: 16.439s
[2K
| RMSProp | epoch: 027 | loss: 0.49451 - acc: 0.7567 -- iter: 416/748
[A[ATraining Step: 638  | total loss: [1m[32m0.48530[0m[0m | time: 17.745s
[2K
| RMSProp | epoch: 027 | loss: 0.48530 - acc: 0.7654 -- iter: 448/748
[A[ATraining Step: 639  | total loss: [1m[32m0.47167[0m[0m | time: 18.994s
[2K
| RMSProp | epoch: 027 | loss: 0.47167 - acc: 0.7732 -- iter: 480/748
[A[ATraining Step: 640  | total loss: [1m[32m0.47643[0m[0m | time: 20.109s
[2K
| RMSProp | epoch: 027 | loss: 0.47643 - acc: 0.7647 -- iter: 512/748
[A[ATraining Step: 641  | total loss: [1m[32m0.47093[0m[0m | time: 21.485s
[2K
| RMSProp | epoch: 027 | loss: 0.47093 - acc: 0.7694 -- iter: 544/748
[A[ATraining Step: 642  | total loss: [1m[32m0.47170[0m[0m | time: 22.775s
[2K
| RMSProp | epoch: 027 | loss: 0.47170 - acc: 0.7706 -- iter: 576/748
[A[ATraining Step: 643  | total loss: [1m[32m0.48984[0m[0m | time: 23.954s
[2K
| RMSProp | epoch: 027 | loss: 0.48984 - acc: 0.7717 -- iter: 608/748
[A[ATraining Step: 644  | total loss: [1m[32m0.47134[0m[0m | time: 24.917s
[2K
| RMSProp | epoch: 027 | loss: 0.47134 - acc: 0.7883 -- iter: 640/748
[A[ATraining Step: 645  | total loss: [1m[32m0.45364[0m[0m | time: 25.838s
[2K
| RMSProp | epoch: 027 | loss: 0.45364 - acc: 0.8063 -- iter: 672/748
[A[ATraining Step: 646  | total loss: [1m[32m0.44433[0m[0m | time: 26.802s
[2K
| RMSProp | epoch: 027 | loss: 0.44433 - acc: 0.8132 -- iter: 704/748
[A[ATraining Step: 647  | total loss: [1m[32m0.44167[0m[0m | time: 27.747s
[2K
| RMSProp | epoch: 027 | loss: 0.44167 - acc: 0.8100 -- iter: 736/748
[A[ATraining Step: 648  | total loss: [1m[32m0.45015[0m[0m | time: 29.964s
[2K
| RMSProp | epoch: 027 | loss: 0.45015 - acc: 0.7915 | val_loss: 0.74259 - val_acc: 0.6197 -- iter: 748/748
--
Training Step: 649  | total loss: [1m[32m0.46503[0m[0m | time: 0.412s
[2K
| RMSProp | epoch: 028 | loss: 0.46503 - acc: 0.7748 -- iter: 032/748
[A[ATraining Step: 650  | total loss: [1m[32m0.47477[0m[0m | time: 0.877s
[2K
| RMSProp | epoch: 028 | loss: 0.47477 - acc: 0.7807 -- iter: 064/748
[A[ATraining Step: 651  | total loss: [1m[32m0.46045[0m[0m | time: 1.879s
[2K
| RMSProp | epoch: 028 | loss: 0.46045 - acc: 0.7860 -- iter: 096/748
[A[ATraining Step: 652  | total loss: [1m[32m0.46527[0m[0m | time: 2.924s
[2K
| RMSProp | epoch: 028 | loss: 0.46527 - acc: 0.7855 -- iter: 128/748
[A[ATraining Step: 653  | total loss: [1m[32m0.46673[0m[0m | time: 4.024s
[2K
| RMSProp | epoch: 028 | loss: 0.46673 - acc: 0.7851 -- iter: 160/748
[A[ATraining Step: 654  | total loss: [1m[32m0.45802[0m[0m | time: 5.078s
[2K
| RMSProp | epoch: 028 | loss: 0.45802 - acc: 0.7909 -- iter: 192/748
[A[ATraining Step: 655  | total loss: [1m[32m0.47605[0m[0m | time: 6.059s
[2K
| RMSProp | epoch: 028 | loss: 0.47605 - acc: 0.7775 -- iter: 224/748
[A[ATraining Step: 656  | total loss: [1m[32m0.50002[0m[0m | time: 7.058s
[2K
| RMSProp | epoch: 028 | loss: 0.50002 - acc: 0.7591 -- iter: 256/748
[A[ATraining Step: 657  | total loss: [1m[32m0.48940[0m[0m | time: 8.008s
[2K
| RMSProp | epoch: 028 | loss: 0.48940 - acc: 0.7738 -- iter: 288/748
[A[ATraining Step: 658  | total loss: [1m[32m0.47457[0m[0m | time: 8.798s
[2K
| RMSProp | epoch: 028 | loss: 0.47457 - acc: 0.7902 -- iter: 320/748
[A[ATraining Step: 659  | total loss: [1m[32m0.47861[0m[0m | time: 9.505s
[2K
| RMSProp | epoch: 028 | loss: 0.47861 - acc: 0.7862 -- iter: 352/748
[A[ATraining Step: 660  | total loss: [1m[32m0.46209[0m[0m | time: 10.211s
[2K
| RMSProp | epoch: 028 | loss: 0.46209 - acc: 0.7950 -- iter: 384/748
[A[ATraining Step: 661  | total loss: [1m[32m0.44343[0m[0m | time: 10.890s
[2K
| RMSProp | epoch: 028 | loss: 0.44343 - acc: 0.8062 -- iter: 416/748
[A[ATraining Step: 662  | total loss: [1m[32m0.43325[0m[0m | time: 11.577s
[2K
| RMSProp | epoch: 028 | loss: 0.43325 - acc: 0.8099 -- iter: 448/748
[A[ATraining Step: 663  | total loss: [1m[32m0.43181[0m[0m | time: 12.247s
[2K
| RMSProp | epoch: 028 | loss: 0.43181 - acc: 0.8102 -- iter: 480/748
[A[ATraining Step: 664  | total loss: [1m[32m0.45992[0m[0m | time: 12.959s
[2K
| RMSProp | epoch: 028 | loss: 0.45992 - acc: 0.7917 -- iter: 512/748
[A[ATraining Step: 665  | total loss: [1m[32m0.44658[0m[0m | time: 13.614s
[2K
| RMSProp | epoch: 028 | loss: 0.44658 - acc: 0.8000 -- iter: 544/748
[A[ATraining Step: 666  | total loss: [1m[32m0.44801[0m[0m | time: 14.434s
[2K
| RMSProp | epoch: 028 | loss: 0.44801 - acc: 0.8012 -- iter: 576/748
[A[ATraining Step: 667  | total loss: [1m[32m0.46112[0m[0m | time: 15.438s
[2K
| RMSProp | epoch: 028 | loss: 0.46112 - acc: 0.7930 -- iter: 608/748
[A[ATraining Step: 668  | total loss: [1m[32m0.45288[0m[0m | time: 16.273s
[2K
| RMSProp | epoch: 028 | loss: 0.45288 - acc: 0.7949 -- iter: 640/748
[A[ATraining Step: 669  | total loss: [1m[32m0.45522[0m[0m | time: 17.152s
[2K
| RMSProp | epoch: 028 | loss: 0.45522 - acc: 0.7936 -- iter: 672/748
[A[ATraining Step: 670  | total loss: [1m[32m0.44192[0m[0m | time: 18.074s
[2K
| RMSProp | epoch: 028 | loss: 0.44192 - acc: 0.8048 -- iter: 704/748
[A[ATraining Step: 671  | total loss: [1m[32m0.43877[0m[0m | time: 19.235s
[2K
| RMSProp | epoch: 028 | loss: 0.43877 - acc: 0.8025 -- iter: 736/748
[A[ATraining Step: 672  | total loss: [1m[32m0.43101[0m[0m | time: 21.670s
[2K
| RMSProp | epoch: 028 | loss: 0.43101 - acc: 0.8129 | val_loss: 0.57145 - val_acc: 0.7137 -- iter: 748/748
--
Training Step: 673  | total loss: [1m[32m0.43076[0m[0m | time: 1.021s
[2K
| RMSProp | epoch: 029 | loss: 0.43076 - acc: 0.8097 -- iter: 032/748
[A[ATraining Step: 674  | total loss: [1m[32m0.42213[0m[0m | time: 1.397s
[2K
| RMSProp | epoch: 029 | loss: 0.42213 - acc: 0.8194 -- iter: 064/748
[A[ATraining Step: 675  | total loss: [1m[32m0.42736[0m[0m | time: 1.766s
[2K
| RMSProp | epoch: 029 | loss: 0.42736 - acc: 0.8124 -- iter: 096/748
[A[ATraining Step: 676  | total loss: [1m[32m0.41963[0m[0m | time: 2.864s
[2K
| RMSProp | epoch: 029 | loss: 0.41963 - acc: 0.8145 -- iter: 128/748
[A[ATraining Step: 677  | total loss: [1m[32m0.41567[0m[0m | time: 3.902s
[2K
| RMSProp | epoch: 029 | loss: 0.41567 - acc: 0.8174 -- iter: 160/748
[A[ATraining Step: 678  | total loss: [1m[32m0.40965[0m[0m | time: 5.219s
[2K
| RMSProp | epoch: 029 | loss: 0.40965 - acc: 0.8169 -- iter: 192/748
[A[ATraining Step: 679  | total loss: [1m[32m0.39947[0m[0m | time: 6.445s
[2K
| RMSProp | epoch: 029 | loss: 0.39947 - acc: 0.8290 -- iter: 224/748
[A[ATraining Step: 680  | total loss: [1m[32m0.39385[0m[0m | time: 7.465s
[2K
| RMSProp | epoch: 029 | loss: 0.39385 - acc: 0.8273 -- iter: 256/748
[A[ATraining Step: 681  | total loss: [1m[32m0.37835[0m[0m | time: 18.861s
[2K
| RMSProp | epoch: 029 | loss: 0.37835 - acc: 0.8384 -- iter: 288/748
[A[ATraining Step: 682  | total loss: [1m[32m0.37666[0m[0m | time: 20.001s
[2K
| RMSProp | epoch: 029 | loss: 0.37666 - acc: 0.8389 -- iter: 320/748
[A[ATraining Step: 683  | total loss: [1m[32m0.41125[0m[0m | time: 21.235s
[2K
| RMSProp | epoch: 029 | loss: 0.41125 - acc: 0.8144 -- iter: 352/748
[A[ATraining Step: 684  | total loss: [1m[32m0.41609[0m[0m | time: 22.369s
[2K
| RMSProp | epoch: 029 | loss: 0.41609 - acc: 0.8111 -- iter: 384/748
[A[ATraining Step: 685  | total loss: [1m[32m0.41584[0m[0m | time: 23.643s
[2K
| RMSProp | epoch: 029 | loss: 0.41584 - acc: 0.8175 -- iter: 416/748
[A[ATraining Step: 686  | total loss: [1m[32m0.40065[0m[0m | time: 24.978s
[2K
| RMSProp | epoch: 029 | loss: 0.40065 - acc: 0.8263 -- iter: 448/748
[A[ATraining Step: 687  | total loss: [1m[32m0.39810[0m[0m | time: 26.321s
[2K
| RMSProp | epoch: 029 | loss: 0.39810 - acc: 0.8250 -- iter: 480/748
[A[ATraining Step: 688  | total loss: [1m[32m0.40581[0m[0m | time: 27.483s
[2K
| RMSProp | epoch: 029 | loss: 0.40581 - acc: 0.8237 -- iter: 512/748
[A[ATraining Step: 689  | total loss: [1m[32m0.39431[0m[0m | time: 28.924s
[2K
| RMSProp | epoch: 029 | loss: 0.39431 - acc: 0.8288 -- iter: 544/748
[A[ATraining Step: 690  | total loss: [1m[32m0.37975[0m[0m | time: 30.299s
[2K
| RMSProp | epoch: 029 | loss: 0.37975 - acc: 0.8335 -- iter: 576/748
[A[ATraining Step: 691  | total loss: [1m[32m0.36842[0m[0m | time: 31.694s
[2K
| RMSProp | epoch: 029 | loss: 0.36842 - acc: 0.8407 -- iter: 608/748
[A[ATraining Step: 692  | total loss: [1m[32m0.36524[0m[0m | time: 33.855s
[2K
| RMSProp | epoch: 029 | loss: 0.36524 - acc: 0.8410 -- iter: 640/748
[A[ATraining Step: 693  | total loss: [1m[32m0.40707[0m[0m | time: 36.789s
[2K
| RMSProp | epoch: 029 | loss: 0.40707 - acc: 0.8226 -- iter: 672/748
[A[ATraining Step: 694  | total loss: [1m[32m0.40482[0m[0m | time: 37.977s
[2K
| RMSProp | epoch: 029 | loss: 0.40482 - acc: 0.8309 -- iter: 704/748
[A[ATraining Step: 695  | total loss: [1m[32m0.41204[0m[0m | time: 39.120s
[2K
| RMSProp | epoch: 029 | loss: 0.41204 - acc: 0.8166 -- iter: 736/748
[A[ATraining Step: 696  | total loss: [1m[32m0.43381[0m[0m | time: 41.879s
[2K
| RMSProp | epoch: 029 | loss: 0.43381 - acc: 0.8037 | val_loss: 0.54946 - val_acc: 0.7265 -- iter: 748/748
--
Training Step: 697  | total loss: [1m[32m0.42138[0m[0m | time: 1.454s
[2K
| RMSProp | epoch: 030 | loss: 0.42138 - acc: 0.8139 -- iter: 032/748
[A[ATraining Step: 698  | total loss: [1m[32m0.39658[0m[0m | time: 2.672s
[2K
| RMSProp | epoch: 030 | loss: 0.39658 - acc: 0.8294 -- iter: 064/748
[A[ATraining Step: 699  | total loss: [1m[32m0.37707[0m[0m | time: 3.159s
[2K
| RMSProp | epoch: 030 | loss: 0.37707 - acc: 0.8402 -- iter: 096/748
[A[ATraining Step: 700  | total loss: [1m[32m0.37387[0m[0m | time: 3.697s
[2K
| RMSProp | epoch: 030 | loss: 0.37387 - acc: 0.8395 -- iter: 128/748
[A[ATraining Step: 701  | total loss: [1m[32m0.34732[0m[0m | time: 5.154s
[2K
| RMSProp | epoch: 030 | loss: 0.34732 - acc: 0.8556 -- iter: 160/748
[A[ATraining Step: 702  | total loss: [1m[32m0.35637[0m[0m | time: 6.612s
[2K
| RMSProp | epoch: 030 | loss: 0.35637 - acc: 0.8544 -- iter: 192/748
[A[ATraining Step: 703  | total loss: [1m[32m0.40010[0m[0m | time: 8.548s
[2K
| RMSProp | epoch: 030 | loss: 0.40010 - acc: 0.8315 -- iter: 224/748
[A[ATraining Step: 704  | total loss: [1m[32m0.38894[0m[0m | time: 18.009s
[2K
| RMSProp | epoch: 030 | loss: 0.38894 - acc: 0.8389 -- iter: 256/748
[A[ATraining Step: 705  | total loss: [1m[32m0.38283[0m[0m | time: 19.197s
[2K
| RMSProp | epoch: 030 | loss: 0.38283 - acc: 0.8457 -- iter: 288/748
[A[ATraining Step: 706  | total loss: [1m[32m0.37574[0m[0m | time: 20.507s
[2K
| RMSProp | epoch: 030 | loss: 0.37574 - acc: 0.8455 -- iter: 320/748
[A[ATraining Step: 707  | total loss: [1m[32m0.36552[0m[0m | time: 21.677s
[2K
| RMSProp | epoch: 030 | loss: 0.36552 - acc: 0.8516 -- iter: 352/748
[A[ATraining Step: 708  | total loss: [1m[32m0.39192[0m[0m | time: 22.774s
[2K
| RMSProp | epoch: 030 | loss: 0.39192 - acc: 0.8320 -- iter: 384/748
[A[ATraining Step: 709  | total loss: [1m[32m0.38594[0m[0m | time: 23.983s
[2K
| RMSProp | epoch: 030 | loss: 0.38594 - acc: 0.8363 -- iter: 416/748
[A[ATraining Step: 710  | total loss: [1m[32m0.36853[0m[0m | time: 25.336s
[2K
| RMSProp | epoch: 030 | loss: 0.36853 - acc: 0.8464 -- iter: 448/748
[A[ATraining Step: 711  | total loss: [1m[32m0.38710[0m[0m | time: 26.675s
[2K
| RMSProp | epoch: 030 | loss: 0.38710 - acc: 0.8337 -- iter: 480/748
[A[ATraining Step: 712  | total loss: [1m[32m0.37016[0m[0m | time: 27.895s
[2K
| RMSProp | epoch: 030 | loss: 0.37016 - acc: 0.8409 -- iter: 512/748
[A[ATraining Step: 713  | total loss: [1m[32m0.36045[0m[0m | time: 29.232s
[2K
| RMSProp | epoch: 030 | loss: 0.36045 - acc: 0.8412 -- iter: 544/748
[A[ATraining Step: 714  | total loss: [1m[32m0.34371[0m[0m | time: 30.533s
[2K
| RMSProp | epoch: 030 | loss: 0.34371 - acc: 0.8508 -- iter: 576/748
[A[ATraining Step: 715  | total loss: [1m[32m0.32713[0m[0m | time: 31.830s
[2K
| RMSProp | epoch: 030 | loss: 0.32713 - acc: 0.8626 -- iter: 608/748
[A[ATraining Step: 716  | total loss: [1m[32m0.32375[0m[0m | time: 32.744s
[2K
| RMSProp | epoch: 030 | loss: 0.32375 - acc: 0.8639 -- iter: 640/748
[A[ATraining Step: 717  | total loss: [1m[32m0.31895[0m[0m | time: 33.725s
[2K
| RMSProp | epoch: 030 | loss: 0.31895 - acc: 0.8650 -- iter: 672/748
[A[ATraining Step: 718  | total loss: [1m[32m0.32889[0m[0m | time: 34.857s
[2K
| RMSProp | epoch: 030 | loss: 0.32889 - acc: 0.8629 -- iter: 704/748
[A[ATraining Step: 719  | total loss: [1m[32m0.31723[0m[0m | time: 35.907s
[2K
| RMSProp | epoch: 030 | loss: 0.31723 - acc: 0.8734 -- iter: 736/748
[A[ATraining Step: 720  | total loss: [1m[32m0.31146[0m[0m | time: 37.843s
[2K
| RMSProp | epoch: 030 | loss: 0.31146 - acc: 0.8767 | val_loss: 0.57649 - val_acc: 0.7521 -- iter: 748/748
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8193642674461088
Validation AUPRC:0.8094514959858604
Test AUC:0.8449736995908825
Test AUPRC:0.8429779653263867
BestTestF1Score	0.77	0.54	0.77	0.76	0.78	91	29	89	25	0.44
BestTestMCCScore	0.77	0.54	0.77	0.76	0.78	91	29	89	25	0.44
BestTestAccuracyScore	0.76	0.51	0.76	0.75	0.76	88	29	89	28	0.47
BestValidationF1Score	0.77	0.53	0.76	0.75	0.79	91	31	88	24	0.44
BestValidationMCC	0.77	0.53	0.76	0.75	0.79	91	31	88	24	0.44
BestValidationAccuracy	0.77	0.53	0.76	0.75	0.78	90	30	89	25	0.47
TestPredictions (Threshold:0.44)
CHEMBL2048228,TP,ACT,0.8999999761581421	CHEMBL82995,FN,ACT,0.11999999731779099	CHEMBL301088,TP,ACT,0.9800000190734863	CHEMBL454379,FN,ACT,0.23999999463558197	CHEMBL145044,FP,INACT,0.6800000071525574	CHEMBL328113,FN,ACT,0.3100000023841858	CHEMBL3651587,TN,INACT,0.019999999552965164	CHEMBL3651594,TN,INACT,0.019999999552965164	CHEMBL1830820,TN,INACT,0.17000000178813934	CHEMBL239935,TN,INACT,0.2199999988079071	CHEMBL2324524,TP,ACT,0.9700000286102295	CHEMBL1079383,TN,INACT,0.15000000596046448	CHEMBL187043,FP,INACT,0.5199999809265137	CHEMBL2324534,FN,ACT,0.36000001430511475	CHEMBL489080,TN,INACT,0.23999999463558197	CHEMBL574191,TP,ACT,0.44999998807907104	CHEMBL220495,TN,INACT,0.11999999731779099	CHEMBL2420694,TN,INACT,0.05999999865889549	CHEMBL390405,TN,INACT,0.30000001192092896	CHEMBL3586575,TP,ACT,0.9300000071525574	CHEMBL2324222,TP,ACT,0.5099999904632568	CHEMBL3394506,TN,INACT,0.03999999910593033	CHEMBL1381098,FP,INACT,0.9800000190734863	CHEMBL155863,TN,INACT,0.3499999940395355	CHEMBL447882,TP,ACT,0.9599999785423279	CHEMBL2420787,TN,INACT,0.03999999910593033	CHEMBL2324230,TP,ACT,0.8700000047683716	CHEMBL1193327,FP,INACT,0.5799999833106995	CHEMBL53798,TP,ACT,0.949999988079071	CHEMBL3605353,TN,INACT,0.12999999523162842	CHEMBL63691,TP,ACT,0.9800000190734863	CHEMBL66679,TP,ACT,0.9200000166893005	CHEMBL1835327,TN,INACT,0.27000001072883606	CHEMBL315245,TP,ACT,0.9200000166893005	CHEMBL452092,TN,INACT,0.15000000596046448	CHEMBL54760,TP,ACT,0.9599999785423279	CHEMBL372047,TP,ACT,0.9800000190734863	CHEMBL496279,TN,INACT,0.019999999552965164	CHEMBL1950705,TN,INACT,0.11999999731779099	CHEMBL3651126,TN,INACT,0.1599999964237213	CHEMBL1085949,TN,INACT,0.2800000011920929	CHEMBL150819,FN,ACT,0.1599999964237213	CHEMBL572768,FN,ACT,0.33000001311302185	CHEMBL598188,TN,INACT,0.20999999344348907	CHEMBL1253700,TN,INACT,0.019999999552965164	CHEMBL3651598,TN,INACT,0.07000000029802322	CHEMBL54424,TP,ACT,0.9599999785423279	CHEMBL972,FN,ACT,0.05000000074505806	CHEMBL3261200,TN,INACT,0.4399999976158142	CHEMBL472218,TN,INACT,0.03999999910593033	CHEMBL555641,TN,INACT,0.14000000059604645	CHEMBL356714,TP,ACT,0.949999988079071	CHEMBL298491,TP,ACT,0.7300000190734863	CHEMBL590369,FN,ACT,0.28999999165534973	CHEMBL203842,TP,ACT,0.7900000214576721	CHEMBL2332190,FP,INACT,0.6700000166893005	CHEMBL1830148,TN,INACT,0.05999999865889549	CHEMBL1642682,TN,INACT,0.029999999329447746	CHEMBL3134337,TN,INACT,0.09000000357627869	CHEMBL2324529,TP,ACT,0.9800000190734863	CHEMBL333148,TN,INACT,0.27000001072883606	CHEMBL462229,FP,INACT,0.6800000071525574	CHEMBL3764407,TN,INACT,0.1599999964237213	CHEMBL1760719,TP,ACT,0.8799999952316284	CHEMBL449920,TP,ACT,0.8600000143051147	CHEMBL544715,TN,INACT,0.18000000715255737	CHEMBL471839,TP,ACT,0.8399999737739563	CHEMBL575734,FP,INACT,0.7200000286102295	CHEMBL193045,TP,ACT,0.9800000190734863	CHEMBL2391738,TN,INACT,0.12999999523162842	CHEMBL439746,TP,ACT,0.8799999952316284	CHEMBL577614,TN,INACT,0.4099999964237213	CHEMBL127653,FP,INACT,0.9700000286102295	CHEMBL543413,FN,ACT,0.2800000011920929	CHEMBL16988,FN,ACT,0.09000000357627869	CHEMBL66023,TP,ACT,0.9599999785423279	CHEMBL3297786,FP,INACT,0.5699999928474426	CHEMBL454170,TN,INACT,0.1599999964237213	CHEMBL291388,TP,ACT,0.9900000095367432	CHEMBL223001,TP,ACT,0.5	CHEMBL2048226,TP,ACT,0.6700000166893005	CHEMBL598587,TN,INACT,0.17000000178813934	CHEMBL277760,FN,ACT,0.11999999731779099	CHEMBL575735,FP,INACT,0.6100000143051147	CHEMBL491469,TN,INACT,0.12999999523162842	CHEMBL46898,TP,ACT,0.6899999976158142	CHEMBL1929423,TP,ACT,0.75	CHEMBL3134340,TN,INACT,0.3799999952316284	CHEMBL598373,TN,INACT,0.07999999821186066	CHEMBL2336280,TP,ACT,0.8399999737739563	CHEMBL3415793,TP,ACT,0.9900000095367432	CHEMBL126419,TP,ACT,0.9200000166893005	CHEMBL144926,TN,INACT,0.14000000059604645	CHEMBL3415789,TP,ACT,0.9300000071525574	CHEMBL3134363,TN,INACT,0.3199999928474426	CHEMBL3134353,TN,INACT,0.25	CHEMBL255822,TN,INACT,0.1599999964237213	CHEMBL390050,FP,INACT,0.6899999976158142	CHEMBL2420790,TN,INACT,0.07000000029802322	CHEMBL57110,TP,ACT,0.9200000166893005	CHEMBL2207496,TP,ACT,0.6200000047683716	CHEMBL1830146,TN,INACT,0.029999999329447746	CHEMBL145792,TP,ACT,0.9700000286102295	CHEMBL3134349,TN,INACT,0.029999999329447746	CHEMBL502371,TN,INACT,0.10999999940395355	CHEMBL596340,TP,ACT,0.9300000071525574	CHEMBL186576,FP,INACT,0.8899999856948853	CHEMBL887,TP,ACT,0.7099999785423279	CHEMBL277140,FN,ACT,0.15000000596046448	CHEMBL598189,FP,INACT,0.8600000143051147	CHEMBL498683,TN,INACT,0.03999999910593033	CHEMBL151559,TP,ACT,0.5199999809265137	CHEMBL2088311,TN,INACT,0.03999999910593033	CHEMBL2204771,TN,INACT,0.17000000178813934	CHEMBL2022924,TP,ACT,0.6700000166893005	CHEMBL297730,TP,ACT,0.9399999976158142	CHEMBL3219617,TN,INACT,0.09000000357627869	CHEMBL1830819,TN,INACT,0.36000001430511475	CHEMBL1927684,TN,INACT,0.11999999731779099	CHEMBL598586,FN,ACT,0.09000000357627869	CHEMBL1243245,TN,INACT,0.009999999776482582	CHEMBL3415785,TP,ACT,0.75	CHEMBL1830796,FP,INACT,0.5899999737739563	CHEMBL487049,TN,INACT,0.3499999940395355	CHEMBL81099,TP,ACT,0.9800000190734863	CHEMBL604171,TP,ACT,0.9599999785423279	CHEMBL84517,TP,ACT,0.9300000071525574	CHEMBL1760716,TP,ACT,0.9700000286102295	CHEMBL3415800,TP,ACT,0.9800000190734863	CHEMBL16648,TN,INACT,0.05000000074505806	CHEMBL193309,TP,ACT,0.9800000190734863	CHEMBL146873,TP,ACT,0.949999988079071	CHEMBL3402200,TN,INACT,0.1599999964237213	CHEMBL31557,TP,ACT,0.8899999856948853	CHEMBL573986,TN,INACT,0.4300000071525574	CHEMBL185425,TN,INACT,0.10999999940395355	CHEMBL500683,FP,INACT,0.6499999761581421	CHEMBL282734,TP,ACT,0.8199999928474426	CHEMBL454159,TN,INACT,0.10999999940395355	CHEMBL573300,TP,ACT,0.5299999713897705	CHEMBL55927,TP,ACT,0.8899999856948853	CHEMBL90144,TP,ACT,0.6299999952316284	CHEMBL63481,TP,ACT,0.9300000071525574	CHEMBL2333933,TN,INACT,0.4099999964237213	CHEMBL81195,TP,ACT,0.9800000190734863	CHEMBL124867,TN,INACT,0.25	CHEMBL16642,TP,ACT,0.4699999988079071	CHEMBL3651141,TN,INACT,0.18000000715255737	CHEMBL373323,TP,ACT,0.6700000166893005	CHEMBL114475,TN,INACT,0.029999999329447746	CHEMBL3127978,TN,INACT,0.10000000149011612	CHEMBL2058407,FP,INACT,0.8799999952316284	CHEMBL335326,TN,INACT,0.05999999865889549	CHEMBL590,TN,INACT,0.11999999731779099	CHEMBL3319257,FN,ACT,0.3700000047683716	CHEMBL18669,TP,ACT,0.6600000262260437	CHEMBL2420784,TN,INACT,0.20999999344348907	CHEMBL960,FP,INACT,0.9700000286102295	CHEMBL83711,TP,ACT,0.9800000190734863	CHEMBL80053,TP,ACT,0.9700000286102295	CHEMBL1760714,TP,ACT,0.9700000286102295	CHEMBL189630,TP,ACT,0.9700000286102295	CHEMBL359392,TP,ACT,0.8199999928474426	CHEMBL2324232,TP,ACT,0.9599999785423279	CHEMBL1929419,FP,INACT,0.7599999904632568	CHEMBL242835,TN,INACT,0.029999999329447746	CHEMBL508259,TN,INACT,0.15000000596046448	CHEMBL185138,FP,INACT,0.6899999976158142	CHEMBL1929422,FN,ACT,0.27000001072883606	CHEMBL3734880,FP,INACT,0.7300000190734863	CHEMBL151225,TP,ACT,0.7799999713897705	CHEMBL55947,TP,ACT,0.9300000071525574	CHEMBL365132,TP,ACT,0.8799999952316284	CHEMBL3359943,TP,ACT,0.6700000166893005	CHEMBL156994,TN,INACT,0.25	CHEMBL3299043,TN,INACT,0.20999999344348907	CHEMBL235156,TN,INACT,0.20999999344348907	CHEMBL257990,FN,ACT,0.12999999523162842	CHEMBL303825,TP,ACT,0.8700000047683716	CHEMBL1243026,TN,INACT,0.10999999940395355	CHEMBL187178,FP,INACT,0.6700000166893005	CHEMBL422830,TP,ACT,0.9900000095367432	CHEMBL1200904,FN,ACT,0.14000000059604645	CHEMBL326827,FP,INACT,0.6800000071525574	CHEMBL430099,FN,ACT,0.4099999964237213	CHEMBL124461,FN,ACT,0.3499999940395355	CHEMBL592160,TP,ACT,0.4699999988079071	CHEMBL92401,TP,ACT,0.5600000023841858	CHEMBL3660740,TN,INACT,0.4099999964237213	CHEMBL16278,FN,ACT,0.4000000059604645	CHEMBL301087,TP,ACT,0.9700000286102295	CHEMBL53617,TP,ACT,0.47999998927116394	CHEMBL9514,TN,INACT,0.4300000071525574	CHEMBL126133,FP,INACT,0.6200000047683716	CHEMBL506,FP,INACT,0.8500000238418579	CHEMBL145503,FN,ACT,0.25999999046325684	CHEMBL499266,TN,INACT,0.18000000715255737	CHEMBL147412,TP,ACT,0.6399999856948853	CHEMBL146544,FN,ACT,0.23000000417232513	CHEMBL3415796,TP,ACT,0.949999988079071	CHEMBL347503,TP,ACT,0.8700000047683716	CHEMBL1760720,TP,ACT,0.9100000262260437	CHEMBL1830140,TN,INACT,0.11999999731779099	CHEMBL416859,FN,ACT,0.3499999940395355	CHEMBL127880,TN,INACT,0.03999999910593033	CHEMBL126,FP,INACT,0.75	CHEMBL6467,TP,ACT,0.9700000286102295	CHEMBL594029,TP,ACT,0.8700000047683716	CHEMBL303050,FN,ACT,0.3400000035762787	CHEMBL212661,TP,ACT,0.9599999785423279	CHEMBL3134361,TN,INACT,0.4399999976158142	CHEMBL145111,TN,INACT,0.4000000059604645	CHEMBL3415615,TP,ACT,0.9800000190734863	CHEMBL192944,FP,INACT,0.9599999785423279	CHEMBL1830833,TN,INACT,0.05000000074505806	CHEMBL3655326,TN,INACT,0.019999999552965164	CHEMBL313427,TP,ACT,0.9599999785423279	CHEMBL3094008,TP,ACT,0.7699999809265137	CHEMBL65156,TP,ACT,0.9700000286102295	CHEMBL416467,TP,ACT,0.7400000095367432	CHEMBL3655328,TN,INACT,0.029999999329447746	CHEMBL3629473,TN,INACT,0.07000000029802322	CHEMBL1196025,TN,INACT,0.2800000011920929	CHEMBL1823802,FP,INACT,0.550000011920929	CHEMBL1814644,TN,INACT,0.07000000029802322	CHEMBL67463,TP,ACT,0.9700000286102295	CHEMBL2430702,TN,INACT,0.20999999344348907	CHEMBL83927,TP,ACT,0.949999988079071	CHEMBL518827,FP,INACT,0.7400000095367432	CHEMBL555506,FP,INACT,0.8299999833106995	CHEMBL3394512,TN,INACT,0.03999999910593033	CHEMBL3586577,FN,ACT,0.3100000023841858	CHEMBL3577041,TP,ACT,0.9300000071525574	CHEMBL3297792,TN,INACT,0.10000000149011612	

