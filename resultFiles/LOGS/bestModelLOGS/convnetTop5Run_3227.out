ImageNetInceptionV2 CHEMBL2487 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	171
Number of inactive compounds :	114
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2487_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2487_adam_0.0005_15_0.8/
---------------------------------
Training samples: 180
Validation samples: 57
--
Training Step: 1  | time: 169.359s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/180
[A[ATraining Step: 2  | total loss: [1m[32m0.61210[0m[0m | time: 226.347s
[2K
| Adam | epoch: 001 | loss: 0.61210 - acc: 0.5344 -- iter: 064/180
[A[ATraining Step: 3  | total loss: [1m[32m0.57772[0m[0m | time: 317.037s
[2K
| Adam | epoch: 001 | loss: 0.57772 - acc: 0.6852 -- iter: 096/180
[A[ATraining Step: 4  | total loss: [1m[32m0.68960[0m[0m | time: 409.279s
[2K
| Adam | epoch: 001 | loss: 0.68960 - acc: 0.6635 -- iter: 128/180
[A[ATraining Step: 5  | total loss: [1m[32m0.61370[0m[0m | time: 484.953s
[2K
| Adam | epoch: 001 | loss: 0.61370 - acc: 0.7234 -- iter: 160/180
[A[ATraining Step: 6  | total loss: [1m[32m0.72451[0m[0m | time: 512.621s
[2K
| Adam | epoch: 001 | loss: 0.72451 - acc: 0.6400 | val_loss: 0.69301 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 7  | total loss: [1m[32m0.69338[0m[0m | time: 8.044s
[2K
| Adam | epoch: 002 | loss: 0.69338 - acc: 0.5860 -- iter: 032/180
[A[ATraining Step: 8  | total loss: [1m[32m0.47542[0m[0m | time: 76.934s
[2K
| Adam | epoch: 002 | loss: 0.47542 - acc: 0.7626 -- iter: 064/180
[A[ATraining Step: 9  | total loss: [1m[32m0.68027[0m[0m | time: 117.708s
[2K
| Adam | epoch: 002 | loss: 0.68027 - acc: 0.5574 -- iter: 096/180
[A[ATraining Step: 10  | total loss: [1m[32m0.71729[0m[0m | time: 129.290s
[2K
| Adam | epoch: 002 | loss: 0.71729 - acc: 0.5600 -- iter: 128/180
[A[ATraining Step: 11  | total loss: [1m[32m0.56669[0m[0m | time: 143.532s
[2K
| Adam | epoch: 002 | loss: 0.56669 - acc: 0.6944 -- iter: 160/180
[A[ATraining Step: 12  | total loss: [1m[32m0.53173[0m[0m | time: 158.722s
[2K
| Adam | epoch: 002 | loss: 0.53173 - acc: 0.7475 | val_loss: 0.73684 - val_acc: 0.4912 -- iter: 180/180
--
Training Step: 13  | total loss: [1m[32m0.44879[0m[0m | time: 7.875s
[2K
| Adam | epoch: 003 | loss: 0.44879 - acc: 0.8156 -- iter: 032/180
[A[ATraining Step: 14  | total loss: [1m[32m0.35720[0m[0m | time: 16.019s
[2K
| Adam | epoch: 003 | loss: 0.35720 - acc: 0.8910 -- iter: 064/180
[A[ATraining Step: 15  | total loss: [1m[32m0.24891[0m[0m | time: 27.489s
[2K
| Adam | epoch: 003 | loss: 0.24891 - acc: 0.9337 -- iter: 096/180
[A[ATraining Step: 16  | total loss: [1m[32m0.30722[0m[0m | time: 61.484s
[2K
| Adam | epoch: 003 | loss: 0.30722 - acc: 0.8999 -- iter: 128/180
[A[ATraining Step: 17  | total loss: [1m[32m0.30180[0m[0m | time: 72.717s
[2K
| Adam | epoch: 003 | loss: 0.30180 - acc: 0.9022 -- iter: 160/180
[A[ATraining Step: 18  | total loss: [1m[32m0.23762[0m[0m | time: 87.744s
[2K
| Adam | epoch: 003 | loss: 0.23762 - acc: 0.9252 | val_loss: 0.72676 - val_acc: 0.4912 -- iter: 180/180
--
Training Step: 19  | total loss: [1m[32m0.27576[0m[0m | time: 8.148s
[2K
| Adam | epoch: 004 | loss: 0.27576 - acc: 0.9189 -- iter: 032/180
[A[ATraining Step: 20  | total loss: [1m[32m0.27560[0m[0m | time: 13.617s
[2K
| Adam | epoch: 004 | loss: 0.27560 - acc: 0.9048 -- iter: 064/180
[A[ATraining Step: 21  | total loss: [1m[32m0.27783[0m[0m | time: 19.960s
[2K
| Adam | epoch: 004 | loss: 0.27783 - acc: 0.9033 -- iter: 096/180
[A[ATraining Step: 22  | total loss: [1m[32m0.21060[0m[0m | time: 30.555s
[2K
| Adam | epoch: 004 | loss: 0.21060 - acc: 0.9323 -- iter: 128/180
[A[ATraining Step: 23  | total loss: [1m[32m0.21972[0m[0m | time: 42.806s
[2K
| Adam | epoch: 004 | loss: 0.21972 - acc: 0.9066 -- iter: 160/180
[A[ATraining Step: 24  | total loss: [1m[32m0.33843[0m[0m | time: 57.445s
[2K
| Adam | epoch: 004 | loss: 0.33843 - acc: 0.8977 | val_loss: 1.03466 - val_acc: 0.4912 -- iter: 180/180
--
Training Step: 25  | total loss: [1m[32m0.29354[0m[0m | time: 12.106s
[2K
| Adam | epoch: 005 | loss: 0.29354 - acc: 0.9086 -- iter: 032/180
[A[ATraining Step: 26  | total loss: [1m[32m0.25713[0m[0m | time: 24.666s
[2K
| Adam | epoch: 005 | loss: 0.25713 - acc: 0.9080 -- iter: 064/180
[A[ATraining Step: 27  | total loss: [1m[32m0.22328[0m[0m | time: 32.498s
[2K
| Adam | epoch: 005 | loss: 0.22328 - acc: 0.9236 -- iter: 096/180
[A[ATraining Step: 28  | total loss: [1m[32m0.22899[0m[0m | time: 40.556s
[2K
| Adam | epoch: 005 | loss: 0.22899 - acc: 0.9302 -- iter: 128/180
[A[ATraining Step: 29  | total loss: [1m[32m0.18626[0m[0m | time: 52.812s
[2K
| Adam | epoch: 005 | loss: 0.18626 - acc: 0.9472 -- iter: 160/180
[A[ATraining Step: 30  | total loss: [1m[32m0.15995[0m[0m | time: 69.553s
[2K
| Adam | epoch: 005 | loss: 0.15995 - acc: 0.9597 | val_loss: 0.78593 - val_acc: 0.4912 -- iter: 180/180
--
Training Step: 31  | total loss: [1m[32m0.14143[0m[0m | time: 11.181s
[2K
| Adam | epoch: 006 | loss: 0.14143 - acc: 0.9690 -- iter: 032/180
[A[ATraining Step: 32  | total loss: [1m[32m0.11785[0m[0m | time: 23.017s
[2K
| Adam | epoch: 006 | loss: 0.11785 - acc: 0.9760 -- iter: 064/180
[A[ATraining Step: 33  | total loss: [1m[32m0.12068[0m[0m | time: 34.700s
[2K
| Adam | epoch: 006 | loss: 0.12068 - acc: 0.9675 -- iter: 096/180
[A[ATraining Step: 34  | total loss: [1m[32m0.14533[0m[0m | time: 42.148s
[2K
| Adam | epoch: 006 | loss: 0.14533 - acc: 0.9611 -- iter: 128/180
[A[ATraining Step: 35  | total loss: [1m[32m0.12970[0m[0m | time: 49.903s
[2K
| Adam | epoch: 006 | loss: 0.12970 - acc: 0.9692 -- iter: 160/180
[A[ATraining Step: 36  | total loss: [1m[32m0.10777[0m[0m | time: 66.759s
[2K
| Adam | epoch: 006 | loss: 0.10777 - acc: 0.9755 | val_loss: 1.35830 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 37  | total loss: [1m[32m0.09532[0m[0m | time: 10.870s
[2K
| Adam | epoch: 007 | loss: 0.09532 - acc: 0.9742 -- iter: 032/180
[A[ATraining Step: 38  | total loss: [1m[32m0.15310[0m[0m | time: 31.723s
[2K
| Adam | epoch: 007 | loss: 0.15310 - acc: 0.9731 -- iter: 064/180
[A[ATraining Step: 39  | total loss: [1m[32m0.13868[0m[0m | time: 42.603s
[2K
| Adam | epoch: 007 | loss: 0.13868 - acc: 0.9723 -- iter: 096/180
[A[ATraining Step: 40  | total loss: [1m[32m0.12390[0m[0m | time: 54.053s
[2K
| Adam | epoch: 007 | loss: 0.12390 - acc: 0.9716 -- iter: 128/180
[A[ATraining Step: 41  | total loss: [1m[32m0.10694[0m[0m | time: 62.615s
[2K
| Adam | epoch: 007 | loss: 0.10694 - acc: 0.9768 -- iter: 160/180
[A[ATraining Step: 42  | total loss: [1m[32m0.13410[0m[0m | time: 72.212s
[2K
| Adam | epoch: 007 | loss: 0.13410 - acc: 0.9630 | val_loss: 1.93598 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 43  | total loss: [1m[32m0.12480[0m[0m | time: 10.785s
[2K
| Adam | epoch: 008 | loss: 0.12480 - acc: 0.9607 -- iter: 032/180
[A[ATraining Step: 44  | total loss: [1m[32m0.10960[0m[0m | time: 21.682s
[2K
| Adam | epoch: 008 | loss: 0.10960 - acc: 0.9675 -- iter: 064/180
[A[ATraining Step: 45  | total loss: [1m[32m0.09435[0m[0m | time: 33.642s
[2K
| Adam | epoch: 008 | loss: 0.09435 - acc: 0.9730 -- iter: 096/180
[A[ATraining Step: 46  | total loss: [1m[32m0.08267[0m[0m | time: 45.993s
[2K
| Adam | epoch: 008 | loss: 0.08267 - acc: 0.9775 -- iter: 128/180
[A[ATraining Step: 47  | total loss: [1m[32m0.08807[0m[0m | time: 59.940s
[2K
| Adam | epoch: 008 | loss: 0.08807 - acc: 0.9761 -- iter: 160/180
[A[ATraining Step: 48  | total loss: [1m[32m0.07536[0m[0m | time: 71.398s
[2K
| Adam | epoch: 008 | loss: 0.07536 - acc: 0.9799 | val_loss: 2.64151 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 49  | total loss: [1m[32m0.06704[0m[0m | time: 8.002s
[2K
| Adam | epoch: 009 | loss: 0.06704 - acc: 0.9831 -- iter: 032/180
[A[ATraining Step: 50  | total loss: [1m[32m0.05847[0m[0m | time: 19.274s
[2K
| Adam | epoch: 009 | loss: 0.05847 - acc: 0.9857 -- iter: 064/180
[A[ATraining Step: 51  | total loss: [1m[32m0.05221[0m[0m | time: 30.447s
[2K
| Adam | epoch: 009 | loss: 0.05221 - acc: 0.9879 -- iter: 096/180
[A[ATraining Step: 52  | total loss: [1m[32m0.21529[0m[0m | time: 41.770s
[2K
| Adam | epoch: 009 | loss: 0.21529 - acc: 0.9663 -- iter: 128/180
[A[ATraining Step: 53  | total loss: [1m[32m0.18486[0m[0m | time: 52.821s
[2K
| Adam | epoch: 009 | loss: 0.18486 - acc: 0.9713 -- iter: 160/180
[A[ATraining Step: 54  | total loss: [1m[32m0.17460[0m[0m | time: 68.289s
[2K
| Adam | epoch: 009 | loss: 0.17460 - acc: 0.9664 | val_loss: 2.31143 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 55  | total loss: [1m[32m0.15293[0m[0m | time: 7.434s
[2K
| Adam | epoch: 010 | loss: 0.15293 - acc: 0.9712 -- iter: 032/180
[A[ATraining Step: 56  | total loss: [1m[32m0.16252[0m[0m | time: 15.264s
[2K
| Adam | epoch: 010 | loss: 0.16252 - acc: 0.9682 -- iter: 064/180
[A[ATraining Step: 57  | total loss: [1m[32m0.14444[0m[0m | time: 27.021s
[2K
| Adam | epoch: 010 | loss: 0.14444 - acc: 0.9726 -- iter: 096/180
[A[ATraining Step: 58  | total loss: [1m[32m0.15549[0m[0m | time: 39.242s
[2K
| Adam | epoch: 010 | loss: 0.15549 - acc: 0.9678 -- iter: 128/180
[A[ATraining Step: 59  | total loss: [1m[32m0.17461[0m[0m | time: 51.793s
[2K
| Adam | epoch: 010 | loss: 0.17461 - acc: 0.9637 -- iter: 160/180
[A[ATraining Step: 60  | total loss: [1m[32m0.15837[0m[0m | time: 66.763s
[2K
| Adam | epoch: 010 | loss: 0.15837 - acc: 0.9685 | val_loss: 0.77528 - val_acc: 0.6316 -- iter: 180/180
--
Training Step: 61  | total loss: [1m[32m0.14996[0m[0m | time: 8.003s
[2K
| Adam | epoch: 011 | loss: 0.14996 - acc: 0.9686 -- iter: 032/180
[A[ATraining Step: 62  | total loss: [1m[32m0.14796[0m[0m | time: 13.542s
[2K
| Adam | epoch: 011 | loss: 0.14796 - acc: 0.9686 -- iter: 064/180
[A[ATraining Step: 63  | total loss: [1m[32m0.13603[0m[0m | time: 18.976s
[2K
| Adam | epoch: 011 | loss: 0.13603 - acc: 0.9726 -- iter: 096/180
[A[ATraining Step: 64  | total loss: [1m[32m0.12247[0m[0m | time: 39.634s
[2K
| Adam | epoch: 011 | loss: 0.12247 - acc: 0.9760 -- iter: 128/180
[A[ATraining Step: 65  | total loss: [1m[32m0.11252[0m[0m | time: 50.842s
[2K
| Adam | epoch: 011 | loss: 0.11252 - acc: 0.9790 -- iter: 160/180
[A[ATraining Step: 66  | total loss: [1m[32m0.10256[0m[0m | time: 65.211s
[2K
| Adam | epoch: 011 | loss: 0.10256 - acc: 0.9815 | val_loss: 0.47564 - val_acc: 0.8070 -- iter: 180/180
--
Training Step: 67  | total loss: [1m[32m0.09386[0m[0m | time: 11.455s
[2K
| Adam | epoch: 012 | loss: 0.09386 - acc: 0.9837 -- iter: 032/180
[A[ATraining Step: 68  | total loss: [1m[32m0.08382[0m[0m | time: 22.769s
[2K
| Adam | epoch: 012 | loss: 0.08382 - acc: 0.9857 -- iter: 064/180
[A[ATraining Step: 69  | total loss: [1m[32m0.07667[0m[0m | time: 30.142s
[2K
| Adam | epoch: 012 | loss: 0.07667 - acc: 0.9873 -- iter: 096/180
[A[ATraining Step: 70  | total loss: [1m[32m0.07110[0m[0m | time: 38.039s
[2K
| Adam | epoch: 012 | loss: 0.07110 - acc: 0.9888 -- iter: 128/180
[A[ATraining Step: 71  | total loss: [1m[32m0.06351[0m[0m | time: 49.575s
[2K
| Adam | epoch: 012 | loss: 0.06351 - acc: 0.9901 -- iter: 160/180
[A[ATraining Step: 72  | total loss: [1m[32m0.05792[0m[0m | time: 64.509s
[2K
| Adam | epoch: 012 | loss: 0.05792 - acc: 0.9912 | val_loss: 4.28480 - val_acc: 0.5263 -- iter: 180/180
--
Training Step: 73  | total loss: [1m[32m0.06303[0m[0m | time: 11.709s
[2K
| Adam | epoch: 013 | loss: 0.06303 - acc: 0.9887 -- iter: 032/180
[A[ATraining Step: 74  | total loss: [1m[32m0.06632[0m[0m | time: 22.839s
[2K
| Adam | epoch: 013 | loss: 0.06632 - acc: 0.9865 -- iter: 064/180
[A[ATraining Step: 75  | total loss: [1m[32m0.06035[0m[0m | time: 33.976s
[2K
| Adam | epoch: 013 | loss: 0.06035 - acc: 0.9880 -- iter: 096/180
[A[ATraining Step: 76  | total loss: [1m[32m0.05459[0m[0m | time: 41.840s
[2K
| Adam | epoch: 013 | loss: 0.05459 - acc: 0.9893 -- iter: 128/180
[A[ATraining Step: 77  | total loss: [1m[32m0.05046[0m[0m | time: 49.357s
[2K
| Adam | epoch: 013 | loss: 0.05046 - acc: 0.9904 -- iter: 160/180
[A[ATraining Step: 78  | total loss: [1m[32m0.04632[0m[0m | time: 64.397s
[2K
| Adam | epoch: 013 | loss: 0.04632 - acc: 0.9914 | val_loss: 4.04325 - val_acc: 0.5088 -- iter: 180/180
--
Training Step: 79  | total loss: [1m[32m0.06909[0m[0m | time: 14.104s
[2K
| Adam | epoch: 014 | loss: 0.06909 - acc: 0.9891 -- iter: 032/180
[A[ATraining Step: 80  | total loss: [1m[32m0.06343[0m[0m | time: 31.045s
[2K
| Adam | epoch: 014 | loss: 0.06343 - acc: 0.9902 -- iter: 064/180
[A[ATraining Step: 81  | total loss: [1m[32m0.08315[0m[0m | time: 49.059s
[2K
| Adam | epoch: 014 | loss: 0.08315 - acc: 0.9880 -- iter: 096/180
[A[ATraining Step: 82  | total loss: [1m[32m0.07735[0m[0m | time: 61.366s
[2K
| Adam | epoch: 014 | loss: 0.07735 - acc: 0.9892 -- iter: 128/180
[A[ATraining Step: 83  | total loss: [1m[32m0.07220[0m[0m | time: 68.064s
[2K
| Adam | epoch: 014 | loss: 0.07220 - acc: 0.9903 -- iter: 160/180
[A[ATraining Step: 84  | total loss: [1m[32m0.07055[0m[0m | time: 78.896s
[2K
| Adam | epoch: 014 | loss: 0.07055 - acc: 0.9863 | val_loss: 1.50117 - val_acc: 0.6140 -- iter: 180/180
--
Training Step: 85  | total loss: [1m[32m0.06438[0m[0m | time: 51.284s
[2K
| Adam | epoch: 015 | loss: 0.06438 - acc: 0.9876 -- iter: 032/180
[A[ATraining Step: 86  | total loss: [1m[32m0.08244[0m[0m | time: 61.394s
[2K
| Adam | epoch: 015 | loss: 0.08244 - acc: 0.9764 -- iter: 064/180
[A[ATraining Step: 87  | total loss: [1m[32m0.09571[0m[0m | time: 70.748s
[2K
| Adam | epoch: 015 | loss: 0.09571 - acc: 0.9756 -- iter: 096/180
[A[ATraining Step: 88  | total loss: [1m[32m0.08738[0m[0m | time: 80.344s
[2K
| Adam | epoch: 015 | loss: 0.08738 - acc: 0.9780 -- iter: 128/180
[A[ATraining Step: 89  | total loss: [1m[32m0.07900[0m[0m | time: 90.256s
[2K
| Adam | epoch: 015 | loss: 0.07900 - acc: 0.9802 -- iter: 160/180
[A[ATraining Step: 90  | total loss: [1m[32m0.07455[0m[0m | time: 100.383s
[2K
| Adam | epoch: 015 | loss: 0.07455 - acc: 0.9822 | val_loss: 1.07726 - val_acc: 0.6842 -- iter: 180/180
--
Validation AUC:0.8177339901477833
Validation AUPRC:0.7860351534237183
Test AUC:0.8081841432225063
Test AUPRC:0.8560588492517344
BestTestF1Score	0.81	0.48	0.75	0.75	0.88	30	10	13	4	0.87
BestTestMCCScore	0.81	0.48	0.75	0.75	0.88	30	10	13	4	0.87
BestTestAccuracyScore	0.81	0.48	0.75	0.75	0.88	30	10	13	4	0.87
BestValidationF1Score	0.82	0.62	0.79	0.71	0.96	27	11	18	1	0.87
BestValidationMCC	0.82	0.62	0.79	0.71	0.96	27	11	18	1	0.87
BestValidationAccuracy	0.82	0.62	0.79	0.71	0.96	27	11	18	1	0.87
TestPredictions (Threshold:0.87)
CHEMBL3667027,TP,ACT,0.9900000095367432	CHEMBL3667025,TP,ACT,0.9900000095367432	CHEMBL93334,TP,ACT,0.9300000071525574	CHEMBL75183,TP,ACT,1.0	CHEMBL3326709,FP,INACT,0.9300000071525574	CHEMBL490806,TP,ACT,1.0	CHEMBL7889,TN,INACT,0.009999999776482582	CHEMBL3799950,TP,ACT,1.0	CHEMBL392059,TP,ACT,1.0	CHEMBL3799558,TP,ACT,0.9900000095367432	CHEMBL491406,TP,ACT,1.0	CHEMBL497,TN,INACT,0.7200000286102295	CHEMBL3692695,FN,ACT,0.8500000238418579	CHEMBL3672729,TP,ACT,1.0	CHEMBL360341,TN,INACT,0.44999998807907104	CHEMBL16117,TN,INACT,0.800000011920929	CHEMBL95,FN,ACT,0.0	CHEMBL2381402,FP,INACT,1.0	CHEMBL3672730,FN,ACT,0.6899999976158142	CHEMBL1744461,TP,ACT,0.949999988079071	CHEMBL204829,TP,ACT,1.0	CHEMBL2177588,TN,INACT,0.6200000047683716	CHEMBL2178342,TN,INACT,0.6100000143051147	CHEMBL292910,FN,ACT,0.7699999809265137	CHEMBL1527194,FP,INACT,0.9900000095367432	CHEMBL3218562,TN,INACT,0.20999999344348907	CHEMBL1836142,TN,INACT,0.25999999046325684	CHEMBL3781419,TN,INACT,0.6299999952316284	CHEMBL2059391,TP,ACT,0.9800000190734863	CHEMBL1084944,TP,ACT,1.0	CHEMBL425304,TP,ACT,0.9900000095367432	CHEMBL2414840,FP,INACT,0.9800000190734863	CHEMBL177126,TP,ACT,0.9800000190734863	CHEMBL3235503,FP,INACT,1.0	CHEMBL2414851,FP,INACT,0.9300000071525574	CHEMBL183815,TN,INACT,0.029999999329447746	CHEMBL3099500,FP,INACT,0.9700000286102295	CHEMBL3814909,TP,ACT,0.9300000071525574	CHEMBL3594079,TP,ACT,0.9700000286102295	CHEMBL55401,TP,ACT,1.0	CHEMBL3667034,TP,ACT,0.9800000190734863	CHEMBL92801,TP,ACT,1.0	CHEMBL3653684,TP,ACT,0.9700000286102295	CHEMBL390478,TP,ACT,1.0	CHEMBL1077196,TP,ACT,1.0	CHEMBL204010,TP,ACT,1.0	CHEMBL28626,TN,INACT,0.12999999523162842	CHEMBL205332,TP,ACT,0.9800000190734863	CHEMBL3617543,TN,INACT,0.0	CHEMBL472346,FP,INACT,0.9800000190734863	CHEMBL1089186,TP,ACT,0.9900000095367432	CHEMBL391205,TP,ACT,1.0	CHEMBL324842,FP,INACT,1.0	CHEMBL3740688,FP,INACT,0.949999988079071	CHEMBL248133,TP,ACT,0.9900000095367432	CHEMBL3667028,TP,ACT,1.0	CHEMBL3235463,TN,INACT,0.7699999809265137	

