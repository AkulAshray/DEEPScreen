CNNModel CHEMBL2028 RMSprop 0.001 15 128 0 0.8 False True
Number of active compounds :	718
Number of inactive compounds :	718
---------------------------------
Run id: CNNModel_CHEMBL2028_RMSprop_0.001_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2028_RMSprop_0.001_15_128_0.8_True/
---------------------------------
Training samples: 824
Validation samples: 258
--
Training Step: 1  | time: 1.179s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/824
[A[ATraining Step: 2  | total loss: [1m[32m0.62378[0m[0m | time: 2.123s
[2K
| RMSProp | epoch: 001 | loss: 0.62378 - acc: 0.5062 -- iter: 064/824
[A[ATraining Step: 3  | total loss: [1m[32m0.68055[0m[0m | time: 2.979s
[2K
| RMSProp | epoch: 001 | loss: 0.68055 - acc: 0.4500 -- iter: 096/824
[A[ATraining Step: 4  | total loss: [1m[32m0.68998[0m[0m | time: 3.913s
[2K
| RMSProp | epoch: 001 | loss: 0.68998 - acc: 0.5109 -- iter: 128/824
[A[ATraining Step: 5  | total loss: [1m[32m0.69214[0m[0m | time: 4.835s
[2K
| RMSProp | epoch: 001 | loss: 0.69214 - acc: 0.5683 -- iter: 160/824
[A[ATraining Step: 6  | total loss: [1m[32m0.69288[0m[0m | time: 5.736s
[2K
| RMSProp | epoch: 001 | loss: 0.69288 - acc: 0.4239 -- iter: 192/824
[A[ATraining Step: 7  | total loss: [1m[32m0.69299[0m[0m | time: 6.579s
[2K
| RMSProp | epoch: 001 | loss: 0.69299 - acc: 0.5258 -- iter: 224/824
[A[ATraining Step: 8  | total loss: [1m[32m0.69313[0m[0m | time: 7.503s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4586 -- iter: 256/824
[A[ATraining Step: 9  | total loss: [1m[32m0.69321[0m[0m | time: 8.357s
[2K
| RMSProp | epoch: 001 | loss: 0.69321 - acc: 0.4474 -- iter: 288/824
[A[ATraining Step: 10  | total loss: [1m[32m0.69311[0m[0m | time: 9.179s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5050 -- iter: 320/824
[A[ATraining Step: 11  | total loss: [1m[32m0.69316[0m[0m | time: 10.036s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4434 -- iter: 352/824
[A[ATraining Step: 12  | total loss: [1m[32m0.69310[0m[0m | time: 10.936s
[2K
| RMSProp | epoch: 001 | loss: 0.69310 - acc: 0.4829 -- iter: 384/824
[A[ATraining Step: 13  | total loss: [1m[32m0.69316[0m[0m | time: 11.789s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4769 -- iter: 416/824
[A[ATraining Step: 14  | total loss: [1m[32m0.69317[0m[0m | time: 12.938s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.4608 -- iter: 448/824
[A[ATraining Step: 15  | total loss: [1m[32m0.69314[0m[0m | time: 13.922s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.4761 -- iter: 480/824
[A[ATraining Step: 16  | total loss: [1m[32m0.69313[0m[0m | time: 14.723s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4616 -- iter: 512/824
[A[ATraining Step: 17  | total loss: [1m[32m0.69313[0m[0m | time: 15.608s
[2K
| RMSProp | epoch: 001 | loss: 0.69313 - acc: 0.4754 -- iter: 544/824
[A[ATraining Step: 18  | total loss: [1m[32m0.69309[0m[0m | time: 16.534s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5164 -- iter: 576/824
[A[ATraining Step: 19  | total loss: [1m[32m0.69309[0m[0m | time: 17.409s
[2K
| RMSProp | epoch: 001 | loss: 0.69309 - acc: 0.5213 -- iter: 608/824
[A[ATraining Step: 20  | total loss: [1m[32m0.69316[0m[0m | time: 18.288s
[2K
| RMSProp | epoch: 001 | loss: 0.69316 - acc: 0.4944 -- iter: 640/824
[A[ATraining Step: 21  | total loss: [1m[32m0.69308[0m[0m | time: 19.144s
[2K
| RMSProp | epoch: 001 | loss: 0.69308 - acc: 0.5252 -- iter: 672/824
[A[ATraining Step: 22  | total loss: [1m[32m0.69306[0m[0m | time: 19.946s
[2K
| RMSProp | epoch: 001 | loss: 0.69306 - acc: 0.5364 -- iter: 704/824
[A[ATraining Step: 23  | total loss: [1m[32m0.69311[0m[0m | time: 20.790s
[2K
| RMSProp | epoch: 001 | loss: 0.69311 - acc: 0.5168 -- iter: 736/824
[A[ATraining Step: 24  | total loss: [1m[32m0.69308[0m[0m | time: 21.715s
[2K
| RMSProp | epoch: 001 | loss: 0.69308 - acc: 0.5384 -- iter: 768/824
[A[ATraining Step: 25  | total loss: [1m[32m0.69317[0m[0m | time: 22.576s
[2K
| RMSProp | epoch: 001 | loss: 0.69317 - acc: 0.5365 -- iter: 800/824
[A[ATraining Step: 26  | total loss: [1m[32m0.69324[0m[0m | time: 24.632s
[2K
| RMSProp | epoch: 001 | loss: 0.69324 - acc: 0.5185 | val_loss: 0.69311 - val_acc: 0.5078 -- iter: 824/824
--
Training Step: 27  | total loss: [1m[32m0.69318[0m[0m | time: 0.626s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.5245 -- iter: 032/824
[A[ATraining Step: 28  | total loss: [1m[32m0.69315[0m[0m | time: 1.530s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5288 -- iter: 064/824
[A[ATraining Step: 29  | total loss: [1m[32m0.69300[0m[0m | time: 2.437s
[2K
| RMSProp | epoch: 002 | loss: 0.69300 - acc: 0.5598 -- iter: 096/824
[A[ATraining Step: 30  | total loss: [1m[32m0.69303[0m[0m | time: 3.282s
[2K
| RMSProp | epoch: 002 | loss: 0.69303 - acc: 0.5456 -- iter: 128/824
[A[ATraining Step: 31  | total loss: [1m[32m0.69301[0m[0m | time: 4.190s
[2K
| RMSProp | epoch: 002 | loss: 0.69301 - acc: 0.5423 -- iter: 160/824
[A[ATraining Step: 32  | total loss: [1m[32m0.69294[0m[0m | time: 5.060s
[2K
| RMSProp | epoch: 002 | loss: 0.69294 - acc: 0.5469 -- iter: 192/824
[A[ATraining Step: 33  | total loss: [1m[32m0.69321[0m[0m | time: 5.893s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.5023 -- iter: 224/824
[A[ATraining Step: 34  | total loss: [1m[32m0.69327[0m[0m | time: 6.815s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.4817 -- iter: 256/824
[A[ATraining Step: 35  | total loss: [1m[32m0.69316[0m[0m | time: 7.721s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.5051 -- iter: 288/824
[A[ATraining Step: 36  | total loss: [1m[32m0.69308[0m[0m | time: 8.620s
[2K
| RMSProp | epoch: 002 | loss: 0.69308 - acc: 0.5169 -- iter: 320/824
[A[ATraining Step: 37  | total loss: [1m[32m0.69303[0m[0m | time: 9.488s
[2K
| RMSProp | epoch: 002 | loss: 0.69303 - acc: 0.5260 -- iter: 352/824
[A[ATraining Step: 38  | total loss: [1m[32m0.69300[0m[0m | time: 10.383s
[2K
| RMSProp | epoch: 002 | loss: 0.69300 - acc: 0.5331 -- iter: 384/824
[A[ATraining Step: 39  | total loss: [1m[32m0.69293[0m[0m | time: 11.257s
[2K
| RMSProp | epoch: 002 | loss: 0.69293 - acc: 0.5447 -- iter: 416/824
[A[ATraining Step: 40  | total loss: [1m[32m0.69288[0m[0m | time: 12.177s
[2K
| RMSProp | epoch: 002 | loss: 0.69288 - acc: 0.5422 -- iter: 448/824
[A[ATraining Step: 41  | total loss: [1m[32m0.69284[0m[0m | time: 13.132s
[2K
| RMSProp | epoch: 002 | loss: 0.69284 - acc: 0.5402 -- iter: 480/824
[A[ATraining Step: 42  | total loss: [1m[32m0.69260[0m[0m | time: 14.027s
[2K
| RMSProp | epoch: 002 | loss: 0.69260 - acc: 0.5611 -- iter: 512/824
[A[ATraining Step: 43  | total loss: [1m[32m0.69269[0m[0m | time: 14.873s
[2K
| RMSProp | epoch: 002 | loss: 0.69269 - acc: 0.5503 -- iter: 544/824
[A[ATraining Step: 44  | total loss: [1m[32m0.69254[0m[0m | time: 15.821s
[2K
| RMSProp | epoch: 002 | loss: 0.69254 - acc: 0.5578 -- iter: 576/824
[A[ATraining Step: 45  | total loss: [1m[32m0.69255[0m[0m | time: 16.987s
[2K
| RMSProp | epoch: 002 | loss: 0.69255 - acc: 0.5533 -- iter: 608/824
[A[ATraining Step: 46  | total loss: [1m[32m0.69239[0m[0m | time: 17.653s
[2K
| RMSProp | epoch: 002 | loss: 0.69239 - acc: 0.5601 -- iter: 640/824
[A[ATraining Step: 47  | total loss: [1m[32m0.69294[0m[0m | time: 18.519s
[2K
| RMSProp | epoch: 002 | loss: 0.69294 - acc: 0.5247 -- iter: 672/824
[A[ATraining Step: 48  | total loss: [1m[32m0.69317[0m[0m | time: 19.438s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.5056 -- iter: 704/824
[A[ATraining Step: 49  | total loss: [1m[32m0.69327[0m[0m | time: 20.347s
[2K
| RMSProp | epoch: 002 | loss: 0.69327 - acc: 0.4998 -- iter: 736/824
[A[ATraining Step: 50  | total loss: [1m[32m0.69335[0m[0m | time: 21.266s
[2K
| RMSProp | epoch: 002 | loss: 0.69335 - acc: 0.4901 -- iter: 768/824
[A[ATraining Step: 51  | total loss: [1m[32m0.69332[0m[0m | time: 22.243s
[2K
| RMSProp | epoch: 002 | loss: 0.69332 - acc: 0.4964 -- iter: 800/824
[A[ATraining Step: 52  | total loss: [1m[32m0.69328[0m[0m | time: 24.448s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.4969 | val_loss: 0.69306 - val_acc: 0.5078 -- iter: 824/824
--
Training Step: 53  | total loss: [1m[32m0.69334[0m[0m | time: 0.650s
[2K
| RMSProp | epoch: 003 | loss: 0.69334 - acc: 0.4882 -- iter: 032/824
[A[ATraining Step: 54  | total loss: [1m[32m0.69315[0m[0m | time: 1.346s
[2K
| RMSProp | epoch: 003 | loss: 0.69315 - acc: 0.5141 -- iter: 064/824
[A[ATraining Step: 55  | total loss: [1m[32m0.69282[0m[0m | time: 2.210s
[2K
| RMSProp | epoch: 003 | loss: 0.69282 - acc: 0.5359 -- iter: 096/824
[A[ATraining Step: 56  | total loss: [1m[32m0.69252[0m[0m | time: 3.084s
[2K
| RMSProp | epoch: 003 | loss: 0.69252 - acc: 0.5528 -- iter: 128/824
[A[ATraining Step: 57  | total loss: [1m[32m0.69234[0m[0m | time: 3.928s
[2K
| RMSProp | epoch: 003 | loss: 0.69234 - acc: 0.5585 -- iter: 160/824
[A[ATraining Step: 58  | total loss: [1m[32m0.69230[0m[0m | time: 4.765s
[2K
| RMSProp | epoch: 003 | loss: 0.69230 - acc: 0.5590 -- iter: 192/824
[A[ATraining Step: 59  | total loss: [1m[32m0.69233[0m[0m | time: 5.649s
[2K
| RMSProp | epoch: 003 | loss: 0.69233 - acc: 0.5553 -- iter: 224/824
[A[ATraining Step: 60  | total loss: [1m[32m0.69234[0m[0m | time: 6.515s
[2K
| RMSProp | epoch: 003 | loss: 0.69234 - acc: 0.5521 -- iter: 256/824
[A[ATraining Step: 61  | total loss: [1m[32m0.69262[0m[0m | time: 7.343s
[2K
| RMSProp | epoch: 003 | loss: 0.69262 - acc: 0.5372 -- iter: 288/824
[A[ATraining Step: 62  | total loss: [1m[32m0.69287[0m[0m | time: 8.168s
[2K
| RMSProp | epoch: 003 | loss: 0.69287 - acc: 0.5243 -- iter: 320/824
[A[ATraining Step: 63  | total loss: [1m[32m0.69232[0m[0m | time: 9.071s
[2K
| RMSProp | epoch: 003 | loss: 0.69232 - acc: 0.5490 -- iter: 352/824
[A[ATraining Step: 64  | total loss: [1m[32m0.69208[0m[0m | time: 9.916s
[2K
| RMSProp | epoch: 003 | loss: 0.69208 - acc: 0.5546 -- iter: 384/824
[A[ATraining Step: 65  | total loss: [1m[32m0.69212[0m[0m | time: 10.759s
[2K
| RMSProp | epoch: 003 | loss: 0.69212 - acc: 0.5517 -- iter: 416/824
[A[ATraining Step: 66  | total loss: [1m[32m0.69201[0m[0m | time: 11.597s
[2K
| RMSProp | epoch: 003 | loss: 0.69201 - acc: 0.5530 -- iter: 448/824
[A[ATraining Step: 67  | total loss: [1m[32m0.69228[0m[0m | time: 12.459s
[2K
| RMSProp | epoch: 003 | loss: 0.69228 - acc: 0.5429 -- iter: 480/824
[A[ATraining Step: 68  | total loss: [1m[32m0.69239[0m[0m | time: 13.290s
[2K
| RMSProp | epoch: 003 | loss: 0.69239 - acc: 0.5378 -- iter: 512/824
[A[ATraining Step: 69  | total loss: [1m[32m0.69204[0m[0m | time: 14.151s
[2K
| RMSProp | epoch: 003 | loss: 0.69204 - acc: 0.5480 -- iter: 544/824
[A[ATraining Step: 70  | total loss: [1m[32m0.69255[0m[0m | time: 15.008s
[2K
| RMSProp | epoch: 003 | loss: 0.69255 - acc: 0.5317 -- iter: 576/824
[A[ATraining Step: 71  | total loss: [1m[32m0.69231[0m[0m | time: 15.881s
[2K
| RMSProp | epoch: 003 | loss: 0.69231 - acc: 0.5387 -- iter: 608/824
[A[ATraining Step: 72  | total loss: [1m[32m0.69240[0m[0m | time: 16.766s
[2K
| RMSProp | epoch: 003 | loss: 0.69240 - acc: 0.5344 -- iter: 640/824
[A[ATraining Step: 73  | total loss: [1m[32m0.69249[0m[0m | time: 17.591s
[2K
| RMSProp | epoch: 003 | loss: 0.69249 - acc: 0.5306 -- iter: 672/824
[A[ATraining Step: 74  | total loss: [1m[32m0.69258[0m[0m | time: 18.444s
[2K
| RMSProp | epoch: 003 | loss: 0.69258 - acc: 0.5272 -- iter: 704/824
[A[ATraining Step: 75  | total loss: [1m[32m0.69268[0m[0m | time: 19.434s
[2K
| RMSProp | epoch: 003 | loss: 0.69268 - acc: 0.5243 -- iter: 736/824
[A[ATraining Step: 76  | total loss: [1m[32m0.69238[0m[0m | time: 20.527s
[2K
| RMSProp | epoch: 003 | loss: 0.69238 - acc: 0.5317 -- iter: 768/824
[A[ATraining Step: 77  | total loss: [1m[32m0.69261[0m[0m | time: 21.314s
[2K
| RMSProp | epoch: 003 | loss: 0.69261 - acc: 0.5250 -- iter: 800/824
[A[ATraining Step: 78  | total loss: [1m[32m0.69257[0m[0m | time: 23.475s
[2K
| RMSProp | epoch: 003 | loss: 0.69257 - acc: 0.5257 | val_loss: 0.69293 - val_acc: 0.5078 -- iter: 824/824
--
Training Step: 79  | total loss: [1m[32m0.69287[0m[0m | time: 0.873s
[2K
| RMSProp | epoch: 004 | loss: 0.69287 - acc: 0.5166 -- iter: 032/824
[A[ATraining Step: 80  | total loss: [1m[32m0.69260[0m[0m | time: 1.526s
[2K
| RMSProp | epoch: 004 | loss: 0.69260 - acc: 0.5245 -- iter: 064/824
[A[ATraining Step: 81  | total loss: [1m[32m0.69249[0m[0m | time: 2.222s
[2K
| RMSProp | epoch: 004 | loss: 0.69249 - acc: 0.5262 -- iter: 096/824
[A[ATraining Step: 82  | total loss: [1m[32m0.69239[0m[0m | time: 3.086s
[2K
| RMSProp | epoch: 004 | loss: 0.69239 - acc: 0.5277 -- iter: 128/824
[A[ATraining Step: 83  | total loss: [1m[32m0.69295[0m[0m | time: 3.971s
[2K
| RMSProp | epoch: 004 | loss: 0.69295 - acc: 0.5125 -- iter: 160/824
[A[ATraining Step: 84  | total loss: [1m[32m0.69268[0m[0m | time: 4.782s
[2K
| RMSProp | epoch: 004 | loss: 0.69268 - acc: 0.5206 -- iter: 192/824
[A[ATraining Step: 85  | total loss: [1m[32m0.69260[0m[0m | time: 5.678s
[2K
| RMSProp | epoch: 004 | loss: 0.69260 - acc: 0.5217 -- iter: 224/824
[A[ATraining Step: 86  | total loss: [1m[32m0.69241[0m[0m | time: 6.568s
[2K
| RMSProp | epoch: 004 | loss: 0.69241 - acc: 0.5257 -- iter: 256/824
[A[ATraining Step: 87  | total loss: [1m[32m0.69237[0m[0m | time: 7.471s
[2K
| RMSProp | epoch: 004 | loss: 0.69237 - acc: 0.5263 -- iter: 288/824
[A[ATraining Step: 88  | total loss: [1m[32m0.69191[0m[0m | time: 8.376s
[2K
| RMSProp | epoch: 004 | loss: 0.69191 - acc: 0.5362 -- iter: 320/824
[A[ATraining Step: 89  | total loss: [1m[32m0.69171[0m[0m | time: 9.235s
[2K
| RMSProp | epoch: 004 | loss: 0.69171 - acc: 0.5388 -- iter: 352/824
[A[ATraining Step: 90  | total loss: [1m[32m0.69139[0m[0m | time: 10.092s
[2K
| RMSProp | epoch: 004 | loss: 0.69139 - acc: 0.5443 -- iter: 384/824
[A[ATraining Step: 91  | total loss: [1m[32m0.69193[0m[0m | time: 11.018s
[2K
| RMSProp | epoch: 004 | loss: 0.69193 - acc: 0.5336 -- iter: 416/824
[A[ATraining Step: 92  | total loss: [1m[32m0.69188[0m[0m | time: 11.872s
[2K
| RMSProp | epoch: 004 | loss: 0.69188 - acc: 0.5334 -- iter: 448/824
[A[ATraining Step: 93  | total loss: [1m[32m0.69167[0m[0m | time: 12.824s
[2K
| RMSProp | epoch: 004 | loss: 0.69167 - acc: 0.5363 -- iter: 480/824
[A[ATraining Step: 94  | total loss: [1m[32m0.69260[0m[0m | time: 13.748s
[2K
| RMSProp | epoch: 004 | loss: 0.69260 - acc: 0.5202 -- iter: 512/824
[A[ATraining Step: 95  | total loss: [1m[32m0.69210[0m[0m | time: 14.685s
[2K
| RMSProp | epoch: 004 | loss: 0.69210 - acc: 0.5306 -- iter: 544/824
[A[ATraining Step: 96  | total loss: [1m[32m0.69187[0m[0m | time: 15.595s
[2K
| RMSProp | epoch: 004 | loss: 0.69187 - acc: 0.5338 -- iter: 576/824
[A[ATraining Step: 97  | total loss: [1m[32m0.69184[0m[0m | time: 16.486s
[2K
| RMSProp | epoch: 004 | loss: 0.69184 - acc: 0.5336 -- iter: 608/824
[A[ATraining Step: 98  | total loss: [1m[32m0.69216[0m[0m | time: 17.369s
[2K
| RMSProp | epoch: 004 | loss: 0.69216 - acc: 0.5271 -- iter: 640/824
[A[ATraining Step: 99  | total loss: [1m[32m0.69175[0m[0m | time: 18.254s
[2K
| RMSProp | epoch: 004 | loss: 0.69175 - acc: 0.5338 -- iter: 672/824
[A[ATraining Step: 100  | total loss: [1m[32m0.69153[0m[0m | time: 19.123s
[2K
| RMSProp | epoch: 004 | loss: 0.69153 - acc: 0.5366 -- iter: 704/824
[A[ATraining Step: 101  | total loss: [1m[32m0.69239[0m[0m | time: 19.983s
[2K
| RMSProp | epoch: 004 | loss: 0.69239 - acc: 0.5236 -- iter: 736/824
[A[ATraining Step: 102  | total loss: [1m[32m0.69215[0m[0m | time: 20.843s
[2K
| RMSProp | epoch: 004 | loss: 0.69215 - acc: 0.5275 -- iter: 768/824
[A[ATraining Step: 103  | total loss: [1m[32m0.69147[0m[0m | time: 21.746s
[2K
| RMSProp | epoch: 004 | loss: 0.69147 - acc: 0.5372 -- iter: 800/824
[A[ATraining Step: 104  | total loss: [1m[32m0.69233[0m[0m | time: 24.127s
[2K
| RMSProp | epoch: 004 | loss: 0.69233 - acc: 0.5241 | val_loss: 0.69295 - val_acc: 0.5078 -- iter: 824/824
--
Training Step: 105  | total loss: [1m[32m0.69189[0m[0m | time: 0.831s
[2K
| RMSProp | epoch: 005 | loss: 0.69189 - acc: 0.5311 -- iter: 032/824
[A[ATraining Step: 106  | total loss: [1m[32m0.69137[0m[0m | time: 1.716s
[2K
| RMSProp | epoch: 005 | loss: 0.69137 - acc: 0.5374 -- iter: 064/824
[A[ATraining Step: 107  | total loss: [1m[32m0.69184[0m[0m | time: 2.361s
[2K
| RMSProp | epoch: 005 | loss: 0.69184 - acc: 0.5305 -- iter: 096/824
[A[ATraining Step: 108  | total loss: [1m[32m0.69141[0m[0m | time: 2.940s
[2K
| RMSProp | epoch: 005 | loss: 0.69141 - acc: 0.5358 -- iter: 128/824
[A[ATraining Step: 109  | total loss: [1m[32m0.69098[0m[0m | time: 3.878s
[2K
| RMSProp | epoch: 005 | loss: 0.69098 - acc: 0.5405 -- iter: 160/824
[A[ATraining Step: 110  | total loss: [1m[32m0.69210[0m[0m | time: 4.772s
[2K
| RMSProp | epoch: 005 | loss: 0.69210 - acc: 0.5271 -- iter: 192/824
[A[ATraining Step: 111  | total loss: [1m[32m0.69243[0m[0m | time: 5.663s
[2K
| RMSProp | epoch: 005 | loss: 0.69243 - acc: 0.5213 -- iter: 224/824
[A[ATraining Step: 112  | total loss: [1m[32m0.69194[0m[0m | time: 6.584s
[2K
| RMSProp | epoch: 005 | loss: 0.69194 - acc: 0.5285 -- iter: 256/824
[A[ATraining Step: 113  | total loss: [1m[32m0.69204[0m[0m | time: 7.496s
[2K
| RMSProp | epoch: 005 | loss: 0.69204 - acc: 0.5257 -- iter: 288/824
[A[ATraining Step: 114  | total loss: [1m[32m0.69172[0m[0m | time: 8.418s
[2K
| RMSProp | epoch: 005 | loss: 0.69172 - acc: 0.5294 -- iter: 320/824
[A[ATraining Step: 115  | total loss: [1m[32m0.69216[0m[0m | time: 9.315s
[2K
| RMSProp | epoch: 005 | loss: 0.69216 - acc: 0.5233 -- iter: 352/824
[A[ATraining Step: 116  | total loss: [1m[32m0.69273[0m[0m | time: 10.218s
[2K
| RMSProp | epoch: 005 | loss: 0.69273 - acc: 0.5147 -- iter: 384/824
[A[ATraining Step: 117  | total loss: [1m[32m0.69243[0m[0m | time: 11.106s
[2K
| RMSProp | epoch: 005 | loss: 0.69243 - acc: 0.5195 -- iter: 416/824
[A[ATraining Step: 118  | total loss: [1m[32m0.69256[0m[0m | time: 12.001s
[2K
| RMSProp | epoch: 005 | loss: 0.69256 - acc: 0.5175 -- iter: 448/824
[A[ATraining Step: 119  | total loss: [1m[32m0.69241[0m[0m | time: 12.881s
[2K
| RMSProp | epoch: 005 | loss: 0.69241 - acc: 0.5189 -- iter: 480/824
[A[ATraining Step: 120  | total loss: [1m[32m0.69161[0m[0m | time: 13.737s
[2K
| RMSProp | epoch: 005 | loss: 0.69161 - acc: 0.5295 -- iter: 512/824
[A[ATraining Step: 121  | total loss: [1m[32m0.69123[0m[0m | time: 14.578s
[2K
| RMSProp | epoch: 005 | loss: 0.69123 - acc: 0.5328 -- iter: 544/824
[A[ATraining Step: 122  | total loss: [1m[32m0.69152[0m[0m | time: 15.447s
[2K
| RMSProp | epoch: 005 | loss: 0.69152 - acc: 0.5295 -- iter: 576/824
[A[ATraining Step: 123  | total loss: [1m[32m0.69291[0m[0m | time: 16.292s
[2K
| RMSProp | epoch: 005 | loss: 0.69291 - acc: 0.5141 -- iter: 608/824
[A[ATraining Step: 124  | total loss: [1m[32m0.69139[0m[0m | time: 17.215s
[2K
| RMSProp | epoch: 005 | loss: 0.69139 - acc: 0.5408 -- iter: 640/824
[A[ATraining Step: 125  | total loss: [1m[32m0.69288[0m[0m | time: 18.101s
[2K
| RMSProp | epoch: 005 | loss: 0.69288 - acc: 0.5242 -- iter: 672/824
[A[ATraining Step: 126  | total loss: [1m[32m0.69225[0m[0m | time: 18.965s
[2K
| RMSProp | epoch: 005 | loss: 0.69225 - acc: 0.5312 -- iter: 704/824
[A[ATraining Step: 127  | total loss: [1m[32m0.69180[0m[0m | time: 19.858s
[2K
| RMSProp | epoch: 005 | loss: 0.69180 - acc: 0.5343 -- iter: 736/824
[A[ATraining Step: 128  | total loss: [1m[32m0.69099[0m[0m | time: 20.707s
[2K
| RMSProp | epoch: 005 | loss: 0.69099 - acc: 0.5403 -- iter: 768/824
[A[ATraining Step: 129  | total loss: [1m[32m0.69128[0m[0m | time: 21.566s
[2K
| RMSProp | epoch: 005 | loss: 0.69128 - acc: 0.5362 -- iter: 800/824
[A[ATraining Step: 130  | total loss: [1m[32m0.69116[0m[0m | time: 23.708s
[2K
| RMSProp | epoch: 005 | loss: 0.69116 - acc: 0.5357 | val_loss: 0.69265 - val_acc: 0.5078 -- iter: 824/824
--
Training Step: 131  | total loss: [1m[32m0.69179[0m[0m | time: 0.897s
[2K
| RMSProp | epoch: 006 | loss: 0.69179 - acc: 0.5290 -- iter: 032/824
[A[ATraining Step: 132  | total loss: [1m[32m0.69231[0m[0m | time: 1.768s
[2K
| RMSProp | epoch: 006 | loss: 0.69231 - acc: 0.5230 -- iter: 064/824
[A[ATraining Step: 133  | total loss: [1m[32m0.69173[0m[0m | time: 2.622s
[2K
| RMSProp | epoch: 006 | loss: 0.69173 - acc: 0.5301 -- iter: 096/824
[A[ATraining Step: 134  | total loss: [1m[32m0.69189[0m[0m | time: 3.526s
[2K
| RMSProp | epoch: 006 | loss: 0.69189 - acc: 0.5271 -- iter: 128/824
[A[ATraining Step: 135  | total loss: [1m[32m0.69274[0m[0m | time: 4.448s
[2K
| RMSProp | epoch: 006 | loss: 0.69274 - acc: 0.5160 -- iter: 160/824
[A[ATraining Step: 136  | total loss: [1m[32m0.69321[0m[0m | time: 5.318s
[2K
| RMSProp | epoch: 006 | loss: 0.69321 - acc: 0.5061 -- iter: 192/824
[A[ATraining Step: 137  | total loss: [1m[32m0.69272[0m[0m | time: 6.144s
[2K
| RMSProp | epoch: 006 | loss: 0.69272 - acc: 0.5180 -- iter: 224/824
[A[ATraining Step: 138  | total loss: [1m[32m0.69165[0m[0m | time: 6.964s
[2K
| RMSProp | epoch: 006 | loss: 0.69165 - acc: 0.5287 -- iter: 256/824
[A[ATraining Step: 139  | total loss: [1m[32m0.69110[0m[0m | time: 7.886s
[2K
| RMSProp | epoch: 006 | loss: 0.69110 - acc: 0.5321 -- iter: 288/824
[A[ATraining Step: 140  | total loss: [1m[32m0.68695[0m[0m | time: 8.783s
[2K
| RMSProp | epoch: 006 | loss: 0.68695 - acc: 0.5539 -- iter: 320/824
[A[ATraining Step: 141  | total loss: [1m[32m0.69533[0m[0m | time: 9.671s
[2K
| RMSProp | epoch: 006 | loss: 0.69533 - acc: 0.5485 -- iter: 352/824
[A[ATraining Step: 142  | total loss: [1m[32m0.69537[0m[0m | time: 10.619s
[2K
| RMSProp | epoch: 006 | loss: 0.69537 - acc: 0.5405 -- iter: 384/824
[A[ATraining Step: 143  | total loss: [1m[32m0.69536[0m[0m | time: 11.485s
[2K
| RMSProp | epoch: 006 | loss: 0.69536 - acc: 0.5333 -- iter: 416/824
[A[ATraining Step: 144  | total loss: [1m[32m0.69527[0m[0m | time: 12.422s
[2K
| RMSProp | epoch: 006 | loss: 0.69527 - acc: 0.5269 -- iter: 448/824
[A[ATraining Step: 145  | total loss: [1m[32m0.69447[0m[0m | time: 13.334s
[2K
| RMSProp | epoch: 006 | loss: 0.69447 - acc: 0.5336 -- iter: 480/824
[A[ATraining Step: 146  | total loss: [1m[32m0.69347[0m[0m | time: 14.215s
[2K
| RMSProp | epoch: 006 | loss: 0.69347 - acc: 0.5396 -- iter: 512/824
[A[ATraining Step: 147  | total loss: [1m[32m0.69345[0m[0m | time: 15.058s
[2K
| RMSProp | epoch: 006 | loss: 0.69345 - acc: 0.5356 -- iter: 544/824
[A[ATraining Step: 148  | total loss: [1m[32m0.69339[0m[0m | time: 15.923s
[2K
| RMSProp | epoch: 006 | loss: 0.69339 - acc: 0.5321 -- iter: 576/824
[A[ATraining Step: 149  | total loss: [1m[32m0.69443[0m[0m | time: 16.818s
[2K
| RMSProp | epoch: 006 | loss: 0.69443 - acc: 0.5132 -- iter: 608/824
[A[ATraining Step: 150  | total loss: [1m[32m0.69417[0m[0m | time: 17.699s
[2K
| RMSProp | epoch: 006 | loss: 0.69417 - acc: 0.5182 -- iter: 640/824
[A[ATraining Step: 151  | total loss: [1m[32m0.69409[0m[0m | time: 18.594s
[2K
| RMSProp | epoch: 006 | loss: 0.69409 - acc: 0.5163 -- iter: 672/824
[A[ATraining Step: 152  | total loss: [1m[32m0.69403[0m[0m | time: 19.473s
[2K
| RMSProp | epoch: 006 | loss: 0.69403 - acc: 0.5147 -- iter: 704/824
[A[ATraining Step: 153  | total loss: [1m[32m0.69369[0m[0m | time: 20.342s
[2K
| RMSProp | epoch: 006 | loss: 0.69369 - acc: 0.5195 -- iter: 736/824
[A[ATraining Step: 154  | total loss: [1m[32m0.69334[0m[0m | time: 21.204s
[2K
| RMSProp | epoch: 006 | loss: 0.69334 - acc: 0.5238 -- iter: 768/824
[A[ATraining Step: 155  | total loss: [1m[32m0.69225[0m[0m | time: 22.072s
[2K
| RMSProp | epoch: 006 | loss: 0.69225 - acc: 0.5370 -- iter: 800/824
[A[ATraining Step: 156  | total loss: [1m[32m0.69328[0m[0m | time: 24.247s
[2K
| RMSProp | epoch: 006 | loss: 0.69328 - acc: 0.5240 | val_loss: 0.69174 - val_acc: 0.5078 -- iter: 824/824
--
Training Step: 157  | total loss: [1m[32m0.69284[0m[0m | time: 0.947s
[2K
| RMSProp | epoch: 007 | loss: 0.69284 - acc: 0.5278 -- iter: 032/824
[A[ATraining Step: 158  | total loss: [1m[32m0.69276[0m[0m | time: 1.913s
[2K
| RMSProp | epoch: 007 | loss: 0.69276 - acc: 0.5250 -- iter: 064/824
[A[ATraining Step: 159  | total loss: [1m[32m0.69303[0m[0m | time: 2.805s
[2K
| RMSProp | epoch: 007 | loss: 0.69303 - acc: 0.5163 -- iter: 096/824
[A[ATraining Step: 160  | total loss: [1m[32m0.69319[0m[0m | time: 3.698s
[2K
| RMSProp | epoch: 007 | loss: 0.69319 - acc: 0.5053 -- iter: 128/824
[A[ATraining Step: 161  | total loss: [1m[32m0.69200[0m[0m | time: 4.349s
[2K
| RMSProp | epoch: 007 | loss: 0.69200 - acc: 0.5172 -- iter: 160/824
[A[ATraining Step: 162  | total loss: [1m[32m0.69125[0m[0m | time: 4.999s
[2K
| RMSProp | epoch: 007 | loss: 0.69125 - acc: 0.5197 -- iter: 192/824
[A[ATraining Step: 163  | total loss: [1m[32m0.69041[0m[0m | time: 5.899s
[2K
| RMSProp | epoch: 007 | loss: 0.69041 - acc: 0.5219 -- iter: 224/824
[A[ATraining Step: 164  | total loss: [1m[32m0.68693[0m[0m | time: 6.819s
[2K
| RMSProp | epoch: 007 | loss: 0.68693 - acc: 0.5353 -- iter: 256/824
[A[ATraining Step: 165  | total loss: [1m[32m0.70109[0m[0m | time: 8.176s
[2K
| RMSProp | epoch: 007 | loss: 0.70109 - acc: 0.5318 -- iter: 288/824
[A[ATraining Step: 166  | total loss: [1m[32m0.69929[0m[0m | time: 9.105s
[2K
| RMSProp | epoch: 007 | loss: 0.69929 - acc: 0.5411 -- iter: 320/824
[A[ATraining Step: 167  | total loss: [1m[32m0.69970[0m[0m | time: 9.984s
[2K
| RMSProp | epoch: 007 | loss: 0.69970 - acc: 0.5245 -- iter: 352/824
[A[ATraining Step: 168  | total loss: [1m[32m0.69738[0m[0m | time: 10.857s
[2K
| RMSProp | epoch: 007 | loss: 0.69738 - acc: 0.5470 -- iter: 384/824
[A[ATraining Step: 169  | total loss: [1m[32m0.69755[0m[0m | time: 11.778s
[2K
| RMSProp | epoch: 007 | loss: 0.69755 - acc: 0.5361 -- iter: 416/824
[A[ATraining Step: 170  | total loss: [1m[32m0.69591[0m[0m | time: 12.648s
[2K
| RMSProp | epoch: 007 | loss: 0.69591 - acc: 0.5419 -- iter: 448/824
[A[ATraining Step: 171  | total loss: [1m[32m0.69458[0m[0m | time: 13.588s
[2K
| RMSProp | epoch: 007 | loss: 0.69458 - acc: 0.5439 -- iter: 480/824
[A[ATraining Step: 172  | total loss: [1m[32m0.69349[0m[0m | time: 14.510s
[2K
| RMSProp | epoch: 007 | loss: 0.69349 - acc: 0.5427 -- iter: 512/824
[A[ATraining Step: 173  | total loss: [1m[32m0.69364[0m[0m | time: 15.354s
[2K
| RMSProp | epoch: 007 | loss: 0.69364 - acc: 0.5290 -- iter: 544/824
[A[ATraining Step: 174  | total loss: [1m[32m0.69217[0m[0m | time: 16.253s
[2K
| RMSProp | epoch: 007 | loss: 0.69217 - acc: 0.5449 -- iter: 576/824
[A[ATraining Step: 175  | total loss: [1m[32m0.68965[0m[0m | time: 17.146s
[2K
| RMSProp | epoch: 007 | loss: 0.68965 - acc: 0.5529 -- iter: 608/824
[A[ATraining Step: 176  | total loss: [1m[32m0.69201[0m[0m | time: 18.209s
[2K
| RMSProp | epoch: 007 | loss: 0.69201 - acc: 0.5320 -- iter: 640/824
[A[ATraining Step: 177  | total loss: [1m[32m0.69228[0m[0m | time: 19.459s
[2K
| RMSProp | epoch: 007 | loss: 0.69228 - acc: 0.5131 -- iter: 672/824
[A[ATraining Step: 178  | total loss: [1m[32m0.69021[0m[0m | time: 20.370s
[2K
| RMSProp | epoch: 007 | loss: 0.69021 - acc: 0.5462 -- iter: 704/824
[A[ATraining Step: 179  | total loss: [1m[32m0.68812[0m[0m | time: 21.273s
[2K
| RMSProp | epoch: 007 | loss: 0.68812 - acc: 0.5447 -- iter: 736/824
[A[ATraining Step: 180  | total loss: [1m[32m0.68459[0m[0m | time: 22.148s
[2K
| RMSProp | epoch: 007 | loss: 0.68459 - acc: 0.5559 -- iter: 768/824
[A[ATraining Step: 181  | total loss: [1m[32m0.67941[0m[0m | time: 23.066s
[2K
| RMSProp | epoch: 007 | loss: 0.67941 - acc: 0.5659 -- iter: 800/824
[A[ATraining Step: 182  | total loss: [1m[32m0.69927[0m[0m | time: 25.200s
[2K
| RMSProp | epoch: 007 | loss: 0.69927 - acc: 0.5531 | val_loss: 0.69170 - val_acc: 0.5078 -- iter: 824/824
--
Training Step: 183  | total loss: [1m[32m0.69876[0m[0m | time: 0.884s
[2K
| RMSProp | epoch: 008 | loss: 0.69876 - acc: 0.5353 -- iter: 032/824
[A[ATraining Step: 184  | total loss: [1m[32m0.69813[0m[0m | time: 1.750s
[2K
| RMSProp | epoch: 008 | loss: 0.69813 - acc: 0.5317 -- iter: 064/824
[A[ATraining Step: 185  | total loss: [1m[32m0.69711[0m[0m | time: 2.653s
[2K
| RMSProp | epoch: 008 | loss: 0.69711 - acc: 0.5348 -- iter: 096/824
[A[ATraining Step: 186  | total loss: [1m[32m0.69598[0m[0m | time: 3.531s
[2K
| RMSProp | epoch: 008 | loss: 0.69598 - acc: 0.5345 -- iter: 128/824
[A[ATraining Step: 187  | total loss: [1m[32m0.69436[0m[0m | time: 4.414s
[2K
| RMSProp | epoch: 008 | loss: 0.69436 - acc: 0.5341 -- iter: 160/824
[A[ATraining Step: 188  | total loss: [1m[32m0.69318[0m[0m | time: 5.109s
[2K
| RMSProp | epoch: 008 | loss: 0.69318 - acc: 0.5276 -- iter: 192/824
[A[ATraining Step: 189  | total loss: [1m[32m0.69257[0m[0m | time: 5.754s
[2K
| RMSProp | epoch: 008 | loss: 0.69257 - acc: 0.5248 -- iter: 224/824
[A[ATraining Step: 190  | total loss: [1m[32m0.68911[0m[0m | time: 6.624s
[2K
| RMSProp | epoch: 008 | loss: 0.68911 - acc: 0.5265 -- iter: 256/824
[A[ATraining Step: 191  | total loss: [1m[32m0.68126[0m[0m | time: 7.576s
[2K
| RMSProp | epoch: 008 | loss: 0.68126 - acc: 0.5645 -- iter: 288/824
[A[ATraining Step: 192  | total loss: [1m[32m0.66524[0m[0m | time: 8.518s
[2K
| RMSProp | epoch: 008 | loss: 0.66524 - acc: 0.5893 -- iter: 320/824
[A[ATraining Step: 193  | total loss: [1m[32m0.64540[0m[0m | time: 9.514s
[2K
| RMSProp | epoch: 008 | loss: 0.64540 - acc: 0.6116 -- iter: 352/824
[A[ATraining Step: 194  | total loss: [1m[32m0.62752[0m[0m | time: 10.363s
[2K
| RMSProp | epoch: 008 | loss: 0.62752 - acc: 0.6223 -- iter: 384/824
[A[ATraining Step: 195  | total loss: [1m[32m0.82732[0m[0m | time: 11.245s
[2K
| RMSProp | epoch: 008 | loss: 0.82732 - acc: 0.5945 -- iter: 416/824
[A[ATraining Step: 196  | total loss: [1m[32m0.81315[0m[0m | time: 12.199s
[2K
| RMSProp | epoch: 008 | loss: 0.81315 - acc: 0.5913 -- iter: 448/824
[A[ATraining Step: 197  | total loss: [1m[32m0.80466[0m[0m | time: 13.367s
[2K
| RMSProp | epoch: 008 | loss: 0.80466 - acc: 0.5728 -- iter: 480/824
[A[ATraining Step: 198  | total loss: [1m[32m0.79339[0m[0m | time: 14.215s
[2K
| RMSProp | epoch: 008 | loss: 0.79339 - acc: 0.5655 -- iter: 512/824
[A[ATraining Step: 199  | total loss: [1m[32m0.78242[0m[0m | time: 15.055s
[2K
| RMSProp | epoch: 008 | loss: 0.78242 - acc: 0.5621 -- iter: 544/824
[A[ATraining Step: 200  | total loss: [1m[32m0.77129[0m[0m | time: 17.151s
[2K
| RMSProp | epoch: 008 | loss: 0.77129 - acc: 0.5809 | val_loss: 0.67625 - val_acc: 0.6783 -- iter: 576/824
--
Training Step: 201  | total loss: [1m[32m0.76686[0m[0m | time: 18.050s
[2K
| RMSProp | epoch: 008 | loss: 0.76686 - acc: 0.5634 -- iter: 608/824
[A[ATraining Step: 202  | total loss: [1m[32m0.75671[0m[0m | time: 18.952s
[2K
| RMSProp | epoch: 008 | loss: 0.75671 - acc: 0.5946 -- iter: 640/824
[A[ATraining Step: 203  | total loss: [1m[32m0.74519[0m[0m | time: 19.844s
[2K
| RMSProp | epoch: 008 | loss: 0.74519 - acc: 0.5945 -- iter: 672/824
[A[ATraining Step: 204  | total loss: [1m[32m0.72651[0m[0m | time: 20.695s
[2K
| RMSProp | epoch: 008 | loss: 0.72651 - acc: 0.6163 -- iter: 704/824
[A[ATraining Step: 205  | total loss: [1m[32m0.71571[0m[0m | time: 21.639s
[2K
| RMSProp | epoch: 008 | loss: 0.71571 - acc: 0.6172 -- iter: 736/824
[A[ATraining Step: 206  | total loss: [1m[32m0.71118[0m[0m | time: 22.547s
[2K
| RMSProp | epoch: 008 | loss: 0.71118 - acc: 0.6117 -- iter: 768/824
[A[ATraining Step: 207  | total loss: [1m[32m0.69675[0m[0m | time: 23.479s
[2K
| RMSProp | epoch: 008 | loss: 0.69675 - acc: 0.6255 -- iter: 800/824
[A[ATraining Step: 208  | total loss: [1m[32m0.68653[0m[0m | time: 25.727s
[2K
| RMSProp | epoch: 008 | loss: 0.68653 - acc: 0.6286 | val_loss: 0.65864 - val_acc: 0.6279 -- iter: 824/824
--
Training Step: 209  | total loss: [1m[32m0.71249[0m[0m | time: 0.926s
[2K
| RMSProp | epoch: 009 | loss: 0.71249 - acc: 0.6095 -- iter: 032/824
[A[ATraining Step: 210  | total loss: [1m[32m0.70142[0m[0m | time: 1.896s
[2K
| RMSProp | epoch: 009 | loss: 0.70142 - acc: 0.6267 -- iter: 064/824
[A[ATraining Step: 211  | total loss: [1m[32m0.68910[0m[0m | time: 2.834s
[2K
| RMSProp | epoch: 009 | loss: 0.68910 - acc: 0.6452 -- iter: 096/824
[A[ATraining Step: 212  | total loss: [1m[32m0.67302[0m[0m | time: 3.708s
[2K
| RMSProp | epoch: 009 | loss: 0.67302 - acc: 0.6588 -- iter: 128/824
[A[ATraining Step: 213  | total loss: [1m[32m0.65419[0m[0m | time: 4.645s
[2K
| RMSProp | epoch: 009 | loss: 0.65419 - acc: 0.6773 -- iter: 160/824
[A[ATraining Step: 214  | total loss: [1m[32m0.62385[0m[0m | time: 5.492s
[2K
| RMSProp | epoch: 009 | loss: 0.62385 - acc: 0.6940 -- iter: 192/824
[A[ATraining Step: 215  | total loss: [1m[32m0.59857[0m[0m | time: 6.181s
[2K
| RMSProp | epoch: 009 | loss: 0.59857 - acc: 0.7090 -- iter: 224/824
[A[ATraining Step: 216  | total loss: [1m[32m0.69656[0m[0m | time: 6.861s
[2K
| RMSProp | epoch: 009 | loss: 0.69656 - acc: 0.6797 -- iter: 256/824
[A[ATraining Step: 217  | total loss: [1m[32m0.67516[0m[0m | time: 7.729s
[2K
| RMSProp | epoch: 009 | loss: 0.67516 - acc: 0.6909 -- iter: 288/824
[A[ATraining Step: 218  | total loss: [1m[32m0.66349[0m[0m | time: 8.646s
[2K
| RMSProp | epoch: 009 | loss: 0.66349 - acc: 0.6937 -- iter: 320/824
[A[ATraining Step: 219  | total loss: [1m[32m0.63883[0m[0m | time: 9.514s
[2K
| RMSProp | epoch: 009 | loss: 0.63883 - acc: 0.6993 -- iter: 352/824
[A[ATraining Step: 220  | total loss: [1m[32m0.60364[0m[0m | time: 10.380s
[2K
| RMSProp | epoch: 009 | loss: 0.60364 - acc: 0.7231 -- iter: 384/824
[A[ATraining Step: 221  | total loss: [1m[32m0.58741[0m[0m | time: 11.250s
[2K
| RMSProp | epoch: 009 | loss: 0.58741 - acc: 0.7290 -- iter: 416/824
[A[ATraining Step: 222  | total loss: [1m[32m0.60167[0m[0m | time: 12.134s
[2K
| RMSProp | epoch: 009 | loss: 0.60167 - acc: 0.7217 -- iter: 448/824
[A[ATraining Step: 223  | total loss: [1m[32m0.59784[0m[0m | time: 12.996s
[2K
| RMSProp | epoch: 009 | loss: 0.59784 - acc: 0.7120 -- iter: 480/824
[A[ATraining Step: 224  | total loss: [1m[32m0.58733[0m[0m | time: 13.853s
[2K
| RMSProp | epoch: 009 | loss: 0.58733 - acc: 0.7221 -- iter: 512/824
[A[ATraining Step: 225  | total loss: [1m[32m0.57186[0m[0m | time: 15.153s
[2K
| RMSProp | epoch: 009 | loss: 0.57186 - acc: 0.7311 -- iter: 544/824
[A[ATraining Step: 226  | total loss: [1m[32m0.56513[0m[0m | time: 15.943s
[2K
| RMSProp | epoch: 009 | loss: 0.56513 - acc: 0.7299 -- iter: 576/824
[A[ATraining Step: 227  | total loss: [1m[32m0.53916[0m[0m | time: 16.861s
[2K
| RMSProp | epoch: 009 | loss: 0.53916 - acc: 0.7506 -- iter: 608/824
[A[ATraining Step: 228  | total loss: [1m[32m0.51530[0m[0m | time: 17.748s
[2K
| RMSProp | epoch: 009 | loss: 0.51530 - acc: 0.7662 -- iter: 640/824
[A[ATraining Step: 229  | total loss: [1m[32m0.51413[0m[0m | time: 18.602s
[2K
| RMSProp | epoch: 009 | loss: 0.51413 - acc: 0.7677 -- iter: 672/824
[A[ATraining Step: 230  | total loss: [1m[32m0.50791[0m[0m | time: 19.467s
[2K
| RMSProp | epoch: 009 | loss: 0.50791 - acc: 0.7722 -- iter: 704/824
[A[ATraining Step: 231  | total loss: [1m[32m0.49773[0m[0m | time: 20.380s
[2K
| RMSProp | epoch: 009 | loss: 0.49773 - acc: 0.7825 -- iter: 736/824
[A[ATraining Step: 232  | total loss: [1m[32m0.49412[0m[0m | time: 21.249s
[2K
| RMSProp | epoch: 009 | loss: 0.49412 - acc: 0.7792 -- iter: 768/824
[A[ATraining Step: 233  | total loss: [1m[32m0.47801[0m[0m | time: 22.150s
[2K
| RMSProp | epoch: 009 | loss: 0.47801 - acc: 0.7857 -- iter: 800/824
[A[ATraining Step: 234  | total loss: [1m[32m0.48952[0m[0m | time: 24.315s
[2K
| RMSProp | epoch: 009 | loss: 0.48952 - acc: 0.7852 | val_loss: 0.49063 - val_acc: 0.7442 -- iter: 824/824
--
Training Step: 235  | total loss: [1m[32m0.49367[0m[0m | time: 0.890s
[2K
| RMSProp | epoch: 010 | loss: 0.49367 - acc: 0.7786 -- iter: 032/824
[A[ATraining Step: 236  | total loss: [1m[32m0.48481[0m[0m | time: 1.743s
[2K
| RMSProp | epoch: 010 | loss: 0.48481 - acc: 0.7820 -- iter: 064/824
[A[ATraining Step: 237  | total loss: [1m[32m0.49334[0m[0m | time: 2.613s
[2K
| RMSProp | epoch: 010 | loss: 0.49334 - acc: 0.7725 -- iter: 096/824
[A[ATraining Step: 238  | total loss: [1m[32m0.48622[0m[0m | time: 3.484s
[2K
| RMSProp | epoch: 010 | loss: 0.48622 - acc: 0.7828 -- iter: 128/824
[A[ATraining Step: 239  | total loss: [1m[32m0.47217[0m[0m | time: 4.369s
[2K
| RMSProp | epoch: 010 | loss: 0.47217 - acc: 0.7951 -- iter: 160/824
[A[ATraining Step: 240  | total loss: [1m[32m0.45874[0m[0m | time: 5.246s
[2K
| RMSProp | epoch: 010 | loss: 0.45874 - acc: 0.8031 -- iter: 192/824
[A[ATraining Step: 241  | total loss: [1m[32m0.46470[0m[0m | time: 6.142s
[2K
| RMSProp | epoch: 010 | loss: 0.46470 - acc: 0.7978 -- iter: 224/824
[A[ATraining Step: 242  | total loss: [1m[32m0.47522[0m[0m | time: 6.877s
[2K
| RMSProp | epoch: 010 | loss: 0.47522 - acc: 0.7961 -- iter: 256/824
[A[ATraining Step: 243  | total loss: [1m[32m0.45958[0m[0m | time: 7.566s
[2K
| RMSProp | epoch: 010 | loss: 0.45958 - acc: 0.8124 -- iter: 288/824
[A[ATraining Step: 244  | total loss: [1m[32m0.43672[0m[0m | time: 8.470s
[2K
| RMSProp | epoch: 010 | loss: 0.43672 - acc: 0.8270 -- iter: 320/824
[A[ATraining Step: 245  | total loss: [1m[32m0.43830[0m[0m | time: 9.339s
[2K
| RMSProp | epoch: 010 | loss: 0.43830 - acc: 0.8224 -- iter: 352/824
[A[ATraining Step: 246  | total loss: [1m[32m0.45131[0m[0m | time: 10.170s
[2K
| RMSProp | epoch: 010 | loss: 0.45131 - acc: 0.8120 -- iter: 384/824
[A[ATraining Step: 247  | total loss: [1m[32m0.43781[0m[0m | time: 11.089s
[2K
| RMSProp | epoch: 010 | loss: 0.43781 - acc: 0.8183 -- iter: 416/824
[A[ATraining Step: 248  | total loss: [1m[32m0.41954[0m[0m | time: 11.989s
[2K
| RMSProp | epoch: 010 | loss: 0.41954 - acc: 0.8334 -- iter: 448/824
[A[ATraining Step: 249  | total loss: [1m[32m0.42821[0m[0m | time: 12.857s
[2K
| RMSProp | epoch: 010 | loss: 0.42821 - acc: 0.8282 -- iter: 480/824
[A[ATraining Step: 250  | total loss: [1m[32m0.42846[0m[0m | time: 13.792s
[2K
| RMSProp | epoch: 010 | loss: 0.42846 - acc: 0.8266 -- iter: 512/824
[A[ATraining Step: 251  | total loss: [1m[32m0.42567[0m[0m | time: 14.667s
[2K
| RMSProp | epoch: 010 | loss: 0.42567 - acc: 0.8252 -- iter: 544/824
[A[ATraining Step: 252  | total loss: [1m[32m0.43406[0m[0m | time: 15.522s
[2K
| RMSProp | epoch: 010 | loss: 0.43406 - acc: 0.8177 -- iter: 576/824
[A[ATraining Step: 253  | total loss: [1m[32m0.43341[0m[0m | time: 16.426s
[2K
| RMSProp | epoch: 010 | loss: 0.43341 - acc: 0.8203 -- iter: 608/824
[A[ATraining Step: 254  | total loss: [1m[32m0.43115[0m[0m | time: 17.326s
[2K
| RMSProp | epoch: 010 | loss: 0.43115 - acc: 0.8195 -- iter: 640/824
[A[ATraining Step: 255  | total loss: [1m[32m0.43668[0m[0m | time: 18.370s
[2K
| RMSProp | epoch: 010 | loss: 0.43668 - acc: 0.8094 -- iter: 672/824
[A[ATraining Step: 256  | total loss: [1m[32m0.43470[0m[0m | time: 19.489s
[2K
| RMSProp | epoch: 010 | loss: 0.43470 - acc: 0.8097 -- iter: 704/824
[A[ATraining Step: 257  | total loss: [1m[32m0.43475[0m[0m | time: 20.406s
[2K
| RMSProp | epoch: 010 | loss: 0.43475 - acc: 0.8069 -- iter: 736/824
[A[ATraining Step: 258  | total loss: [1m[32m0.43034[0m[0m | time: 21.350s
[2K
| RMSProp | epoch: 010 | loss: 0.43034 - acc: 0.8074 -- iter: 768/824
[A[ATraining Step: 259  | total loss: [1m[32m0.41781[0m[0m | time: 22.321s
[2K
| RMSProp | epoch: 010 | loss: 0.41781 - acc: 0.8111 -- iter: 800/824
[A[ATraining Step: 260  | total loss: [1m[32m0.41599[0m[0m | time: 24.475s
[2K
| RMSProp | epoch: 010 | loss: 0.41599 - acc: 0.8143 | val_loss: 0.42382 - val_acc: 0.8023 -- iter: 824/824
--
Training Step: 261  | total loss: [1m[32m0.41581[0m[0m | time: 0.942s
[2K
| RMSProp | epoch: 011 | loss: 0.41581 - acc: 0.8110 -- iter: 032/824
[A[ATraining Step: 262  | total loss: [1m[32m0.40482[0m[0m | time: 1.798s
[2K
| RMSProp | epoch: 011 | loss: 0.40482 - acc: 0.8206 -- iter: 064/824
[A[ATraining Step: 263  | total loss: [1m[32m0.42738[0m[0m | time: 2.677s
[2K
| RMSProp | epoch: 011 | loss: 0.42738 - acc: 0.8041 -- iter: 096/824
[A[ATraining Step: 264  | total loss: [1m[32m0.43306[0m[0m | time: 3.560s
[2K
| RMSProp | epoch: 011 | loss: 0.43306 - acc: 0.8018 -- iter: 128/824
[A[ATraining Step: 265  | total loss: [1m[32m0.44911[0m[0m | time: 4.469s
[2K
| RMSProp | epoch: 011 | loss: 0.44911 - acc: 0.7935 -- iter: 160/824
[A[ATraining Step: 266  | total loss: [1m[32m0.44289[0m[0m | time: 5.365s
[2K
| RMSProp | epoch: 011 | loss: 0.44289 - acc: 0.8017 -- iter: 192/824
[A[ATraining Step: 267  | total loss: [1m[32m0.42097[0m[0m | time: 6.210s
[2K
| RMSProp | epoch: 011 | loss: 0.42097 - acc: 0.8121 -- iter: 224/824
[A[ATraining Step: 268  | total loss: [1m[32m0.41404[0m[0m | time: 7.027s
[2K
| RMSProp | epoch: 011 | loss: 0.41404 - acc: 0.8153 -- iter: 256/824
[A[ATraining Step: 269  | total loss: [1m[32m0.43377[0m[0m | time: 7.696s
[2K
| RMSProp | epoch: 011 | loss: 0.43377 - acc: 0.8119 -- iter: 288/824
[A[ATraining Step: 270  | total loss: [1m[32m0.46123[0m[0m | time: 8.372s
[2K
| RMSProp | epoch: 011 | loss: 0.46123 - acc: 0.7932 -- iter: 320/824
[A[ATraining Step: 271  | total loss: [1m[32m0.45461[0m[0m | time: 9.309s
[2K
| RMSProp | epoch: 011 | loss: 0.45461 - acc: 0.8055 -- iter: 352/824
[A[ATraining Step: 272  | total loss: [1m[32m0.45263[0m[0m | time: 10.270s
[2K
| RMSProp | epoch: 011 | loss: 0.45263 - acc: 0.8031 -- iter: 384/824
[A[ATraining Step: 273  | total loss: [1m[32m0.44455[0m[0m | time: 11.247s
[2K
| RMSProp | epoch: 011 | loss: 0.44455 - acc: 0.8072 -- iter: 416/824
[A[ATraining Step: 274  | total loss: [1m[32m0.42086[0m[0m | time: 12.129s
[2K
| RMSProp | epoch: 011 | loss: 0.42086 - acc: 0.8233 -- iter: 448/824
[A[ATraining Step: 275  | total loss: [1m[32m0.42365[0m[0m | time: 12.971s
[2K
| RMSProp | epoch: 011 | loss: 0.42365 - acc: 0.8223 -- iter: 480/824
[A[ATraining Step: 276  | total loss: [1m[32m0.39863[0m[0m | time: 13.841s
[2K
| RMSProp | epoch: 011 | loss: 0.39863 - acc: 0.8338 -- iter: 512/824
[A[ATraining Step: 277  | total loss: [1m[32m0.37759[0m[0m | time: 14.712s
[2K
| RMSProp | epoch: 011 | loss: 0.37759 - acc: 0.8473 -- iter: 544/824
[A[ATraining Step: 278  | total loss: [1m[32m0.36281[0m[0m | time: 15.622s
[2K
| RMSProp | epoch: 011 | loss: 0.36281 - acc: 0.8532 -- iter: 576/824
[A[ATraining Step: 279  | total loss: [1m[32m0.43635[0m[0m | time: 16.599s
[2K
| RMSProp | epoch: 011 | loss: 0.43635 - acc: 0.8304 -- iter: 608/824
[A[ATraining Step: 280  | total loss: [1m[32m0.42521[0m[0m | time: 17.480s
[2K
| RMSProp | epoch: 011 | loss: 0.42521 - acc: 0.8317 -- iter: 640/824
[A[ATraining Step: 281  | total loss: [1m[32m0.42181[0m[0m | time: 18.364s
[2K
| RMSProp | epoch: 011 | loss: 0.42181 - acc: 0.8329 -- iter: 672/824
[A[ATraining Step: 282  | total loss: [1m[32m0.41210[0m[0m | time: 19.182s
[2K
| RMSProp | epoch: 011 | loss: 0.41210 - acc: 0.8402 -- iter: 704/824
[A[ATraining Step: 283  | total loss: [1m[32m0.40862[0m[0m | time: 20.041s
[2K
| RMSProp | epoch: 011 | loss: 0.40862 - acc: 0.8375 -- iter: 736/824
[A[ATraining Step: 284  | total loss: [1m[32m0.41034[0m[0m | time: 21.090s
[2K
| RMSProp | epoch: 011 | loss: 0.41034 - acc: 0.8318 -- iter: 768/824
[A[ATraining Step: 285  | total loss: [1m[32m0.39804[0m[0m | time: 22.176s
[2K
| RMSProp | epoch: 011 | loss: 0.39804 - acc: 0.8424 -- iter: 800/824
[A[ATraining Step: 286  | total loss: [1m[32m0.37821[0m[0m | time: 24.354s
[2K
| RMSProp | epoch: 011 | loss: 0.37821 - acc: 0.8488 | val_loss: 0.38077 - val_acc: 0.8566 -- iter: 824/824
--
Training Step: 287  | total loss: [1m[32m0.36934[0m[0m | time: 0.864s
[2K
| RMSProp | epoch: 012 | loss: 0.36934 - acc: 0.8483 -- iter: 032/824
[A[ATraining Step: 288  | total loss: [1m[32m0.36644[0m[0m | time: 1.705s
[2K
| RMSProp | epoch: 012 | loss: 0.36644 - acc: 0.8541 -- iter: 064/824
[A[ATraining Step: 289  | total loss: [1m[32m0.37569[0m[0m | time: 2.564s
[2K
| RMSProp | epoch: 012 | loss: 0.37569 - acc: 0.8530 -- iter: 096/824
[A[ATraining Step: 290  | total loss: [1m[32m0.37514[0m[0m | time: 3.438s
[2K
| RMSProp | epoch: 012 | loss: 0.37514 - acc: 0.8521 -- iter: 128/824
[A[ATraining Step: 291  | total loss: [1m[32m0.36693[0m[0m | time: 4.327s
[2K
| RMSProp | epoch: 012 | loss: 0.36693 - acc: 0.8544 -- iter: 160/824
[A[ATraining Step: 292  | total loss: [1m[32m0.36986[0m[0m | time: 5.197s
[2K
| RMSProp | epoch: 012 | loss: 0.36986 - acc: 0.8596 -- iter: 192/824
[A[ATraining Step: 293  | total loss: [1m[32m0.35103[0m[0m | time: 6.075s
[2K
| RMSProp | epoch: 012 | loss: 0.35103 - acc: 0.8705 -- iter: 224/824
[A[ATraining Step: 294  | total loss: [1m[32m0.34343[0m[0m | time: 7.021s
[2K
| RMSProp | epoch: 012 | loss: 0.34343 - acc: 0.8678 -- iter: 256/824
[A[ATraining Step: 295  | total loss: [1m[32m0.34080[0m[0m | time: 7.871s
[2K
| RMSProp | epoch: 012 | loss: 0.34080 - acc: 0.8748 -- iter: 288/824
[A[ATraining Step: 296  | total loss: [1m[32m0.36511[0m[0m | time: 8.554s
[2K
| RMSProp | epoch: 012 | loss: 0.36511 - acc: 0.8592 -- iter: 320/824
[A[ATraining Step: 297  | total loss: [1m[32m0.40135[0m[0m | time: 9.217s
[2K
| RMSProp | epoch: 012 | loss: 0.40135 - acc: 0.8358 -- iter: 352/824
[A[ATraining Step: 298  | total loss: [1m[32m0.38932[0m[0m | time: 10.127s
[2K
| RMSProp | epoch: 012 | loss: 0.38932 - acc: 0.8439 -- iter: 384/824
[A[ATraining Step: 299  | total loss: [1m[32m0.38135[0m[0m | time: 11.028s
[2K
| RMSProp | epoch: 012 | loss: 0.38135 - acc: 0.8470 -- iter: 416/824
[A[ATraining Step: 300  | total loss: [1m[32m0.37243[0m[0m | time: 11.852s
[2K
| RMSProp | epoch: 012 | loss: 0.37243 - acc: 0.8529 -- iter: 448/824
[A[ATraining Step: 301  | total loss: [1m[32m0.37082[0m[0m | time: 12.711s
[2K
| RMSProp | epoch: 012 | loss: 0.37082 - acc: 0.8520 -- iter: 480/824
[A[ATraining Step: 302  | total loss: [1m[32m0.35888[0m[0m | time: 13.569s
[2K
| RMSProp | epoch: 012 | loss: 0.35888 - acc: 0.8574 -- iter: 512/824
[A[ATraining Step: 303  | total loss: [1m[32m0.37542[0m[0m | time: 14.406s
[2K
| RMSProp | epoch: 012 | loss: 0.37542 - acc: 0.8435 -- iter: 544/824
[A[ATraining Step: 304  | total loss: [1m[32m0.36660[0m[0m | time: 15.260s
[2K
| RMSProp | epoch: 012 | loss: 0.36660 - acc: 0.8498 -- iter: 576/824
[A[ATraining Step: 305  | total loss: [1m[32m0.35982[0m[0m | time: 16.111s
[2K
| RMSProp | epoch: 012 | loss: 0.35982 - acc: 0.8555 -- iter: 608/824
[A[ATraining Step: 306  | total loss: [1m[32m0.34126[0m[0m | time: 17.034s
[2K
| RMSProp | epoch: 012 | loss: 0.34126 - acc: 0.8668 -- iter: 640/824
[A[ATraining Step: 307  | total loss: [1m[32m0.33696[0m[0m | time: 17.932s
[2K
| RMSProp | epoch: 012 | loss: 0.33696 - acc: 0.8645 -- iter: 672/824
[A[ATraining Step: 308  | total loss: [1m[32m0.32795[0m[0m | time: 18.838s
[2K
| RMSProp | epoch: 012 | loss: 0.32795 - acc: 0.8655 -- iter: 704/824
[A[ATraining Step: 309  | total loss: [1m[32m0.34945[0m[0m | time: 19.759s
[2K
| RMSProp | epoch: 012 | loss: 0.34945 - acc: 0.8540 -- iter: 736/824
[A[ATraining Step: 310  | total loss: [1m[32m0.34641[0m[0m | time: 20.636s
[2K
| RMSProp | epoch: 012 | loss: 0.34641 - acc: 0.8592 -- iter: 768/824
[A[ATraining Step: 311  | total loss: [1m[32m0.34715[0m[0m | time: 21.524s
[2K
| RMSProp | epoch: 012 | loss: 0.34715 - acc: 0.8577 -- iter: 800/824
[A[ATraining Step: 312  | total loss: [1m[32m0.34872[0m[0m | time: 23.693s
[2K
| RMSProp | epoch: 012 | loss: 0.34872 - acc: 0.8594 | val_loss: 0.34668 - val_acc: 0.8372 -- iter: 824/824
--
Training Step: 313  | total loss: [1m[32m0.33419[0m[0m | time: 1.332s
[2K
| RMSProp | epoch: 013 | loss: 0.33419 - acc: 0.8641 -- iter: 032/824
[A[ATraining Step: 314  | total loss: [1m[32m0.32867[0m[0m | time: 2.148s
[2K
| RMSProp | epoch: 013 | loss: 0.32867 - acc: 0.8683 -- iter: 064/824
[A[ATraining Step: 315  | total loss: [1m[32m0.32644[0m[0m | time: 3.087s
[2K
| RMSProp | epoch: 013 | loss: 0.32644 - acc: 0.8627 -- iter: 096/824
[A[ATraining Step: 316  | total loss: [1m[32m0.34339[0m[0m | time: 4.041s
[2K
| RMSProp | epoch: 013 | loss: 0.34339 - acc: 0.8577 -- iter: 128/824
[A[ATraining Step: 317  | total loss: [1m[32m0.33862[0m[0m | time: 4.911s
[2K
| RMSProp | epoch: 013 | loss: 0.33862 - acc: 0.8563 -- iter: 160/824
[A[ATraining Step: 318  | total loss: [1m[32m0.34001[0m[0m | time: 5.781s
[2K
| RMSProp | epoch: 013 | loss: 0.34001 - acc: 0.8550 -- iter: 192/824
[A[ATraining Step: 319  | total loss: [1m[32m0.36543[0m[0m | time: 6.662s
[2K
| RMSProp | epoch: 013 | loss: 0.36543 - acc: 0.8539 -- iter: 224/824
[A[ATraining Step: 320  | total loss: [1m[32m0.35493[0m[0m | time: 7.535s
[2K
| RMSProp | epoch: 013 | loss: 0.35493 - acc: 0.8623 -- iter: 256/824
[A[ATraining Step: 321  | total loss: [1m[32m0.36177[0m[0m | time: 8.428s
[2K
| RMSProp | epoch: 013 | loss: 0.36177 - acc: 0.8542 -- iter: 288/824
[A[ATraining Step: 322  | total loss: [1m[32m0.35027[0m[0m | time: 9.319s
[2K
| RMSProp | epoch: 013 | loss: 0.35027 - acc: 0.8625 -- iter: 320/824
[A[ATraining Step: 323  | total loss: [1m[32m0.33892[0m[0m | time: 9.931s
[2K
| RMSProp | epoch: 013 | loss: 0.33892 - acc: 0.8700 -- iter: 352/824
[A[ATraining Step: 324  | total loss: [1m[32m0.32259[0m[0m | time: 10.626s
[2K
| RMSProp | epoch: 013 | loss: 0.32259 - acc: 0.8788 -- iter: 384/824
[A[ATraining Step: 325  | total loss: [1m[32m0.30308[0m[0m | time: 11.489s
[2K
| RMSProp | epoch: 013 | loss: 0.30308 - acc: 0.8868 -- iter: 416/824
[A[ATraining Step: 326  | total loss: [1m[32m0.29564[0m[0m | time: 12.325s
[2K
| RMSProp | epoch: 013 | loss: 0.29564 - acc: 0.8919 -- iter: 448/824
[A[ATraining Step: 327  | total loss: [1m[32m0.28575[0m[0m | time: 13.162s
[2K
| RMSProp | epoch: 013 | loss: 0.28575 - acc: 0.8964 -- iter: 480/824
[A[ATraining Step: 328  | total loss: [1m[32m0.27003[0m[0m | time: 14.046s
[2K
| RMSProp | epoch: 013 | loss: 0.27003 - acc: 0.9005 -- iter: 512/824
[A[ATraining Step: 329  | total loss: [1m[32m0.34774[0m[0m | time: 14.951s
[2K
| RMSProp | epoch: 013 | loss: 0.34774 - acc: 0.8792 -- iter: 544/824
[A[ATraining Step: 330  | total loss: [1m[32m0.35230[0m[0m | time: 15.802s
[2K
| RMSProp | epoch: 013 | loss: 0.35230 - acc: 0.8757 -- iter: 576/824
[A[ATraining Step: 331  | total loss: [1m[32m0.34579[0m[0m | time: 16.626s
[2K
| RMSProp | epoch: 013 | loss: 0.34579 - acc: 0.8819 -- iter: 608/824
[A[ATraining Step: 332  | total loss: [1m[32m0.33373[0m[0m | time: 17.471s
[2K
| RMSProp | epoch: 013 | loss: 0.33373 - acc: 0.8843 -- iter: 640/824
[A[ATraining Step: 333  | total loss: [1m[32m0.34478[0m[0m | time: 18.362s
[2K
| RMSProp | epoch: 013 | loss: 0.34478 - acc: 0.8771 -- iter: 672/824
[A[ATraining Step: 334  | total loss: [1m[32m0.32948[0m[0m | time: 19.168s
[2K
| RMSProp | epoch: 013 | loss: 0.32948 - acc: 0.8832 -- iter: 704/824
[A[ATraining Step: 335  | total loss: [1m[32m0.31756[0m[0m | time: 20.009s
[2K
| RMSProp | epoch: 013 | loss: 0.31756 - acc: 0.8886 -- iter: 736/824
[A[ATraining Step: 336  | total loss: [1m[32m0.30745[0m[0m | time: 20.920s
[2K
| RMSProp | epoch: 013 | loss: 0.30745 - acc: 0.8935 -- iter: 768/824
[A[ATraining Step: 337  | total loss: [1m[32m0.29168[0m[0m | time: 21.812s
[2K
| RMSProp | epoch: 013 | loss: 0.29168 - acc: 0.8979 -- iter: 800/824
[A[ATraining Step: 338  | total loss: [1m[32m0.34365[0m[0m | time: 23.984s
[2K
| RMSProp | epoch: 013 | loss: 0.34365 - acc: 0.8800 | val_loss: 0.30710 - val_acc: 0.8605 -- iter: 824/824
--
Training Step: 339  | total loss: [1m[32m0.35562[0m[0m | time: 0.837s
[2K
| RMSProp | epoch: 014 | loss: 0.35562 - acc: 0.8701 -- iter: 032/824
[A[ATraining Step: 340  | total loss: [1m[32m0.34575[0m[0m | time: 1.691s
[2K
| RMSProp | epoch: 014 | loss: 0.34575 - acc: 0.8706 -- iter: 064/824
[A[ATraining Step: 341  | total loss: [1m[32m0.33438[0m[0m | time: 2.616s
[2K
| RMSProp | epoch: 014 | loss: 0.33438 - acc: 0.8773 -- iter: 096/824
[A[ATraining Step: 342  | total loss: [1m[32m0.32810[0m[0m | time: 3.509s
[2K
| RMSProp | epoch: 014 | loss: 0.32810 - acc: 0.8739 -- iter: 128/824
[A[ATraining Step: 343  | total loss: [1m[32m0.34940[0m[0m | time: 4.523s
[2K
| RMSProp | epoch: 014 | loss: 0.34940 - acc: 0.8615 -- iter: 160/824
[A[ATraining Step: 344  | total loss: [1m[32m0.37524[0m[0m | time: 5.701s
[2K
| RMSProp | epoch: 014 | loss: 0.37524 - acc: 0.8504 -- iter: 192/824
[A[ATraining Step: 345  | total loss: [1m[32m0.37306[0m[0m | time: 6.570s
[2K
| RMSProp | epoch: 014 | loss: 0.37306 - acc: 0.8528 -- iter: 224/824
[A[ATraining Step: 346  | total loss: [1m[32m0.35878[0m[0m | time: 7.375s
[2K
| RMSProp | epoch: 014 | loss: 0.35878 - acc: 0.8613 -- iter: 256/824
[A[ATraining Step: 347  | total loss: [1m[32m0.33339[0m[0m | time: 8.223s
[2K
| RMSProp | epoch: 014 | loss: 0.33339 - acc: 0.8752 -- iter: 288/824
[A[ATraining Step: 348  | total loss: [1m[32m0.32848[0m[0m | time: 9.086s
[2K
| RMSProp | epoch: 014 | loss: 0.32848 - acc: 0.8752 -- iter: 320/824
[A[ATraining Step: 349  | total loss: [1m[32m0.31685[0m[0m | time: 9.934s
[2K
| RMSProp | epoch: 014 | loss: 0.31685 - acc: 0.8751 -- iter: 352/824
[A[ATraining Step: 350  | total loss: [1m[32m0.31578[0m[0m | time: 10.571s
[2K
| RMSProp | epoch: 014 | loss: 0.31578 - acc: 0.8720 -- iter: 384/824
[A[ATraining Step: 351  | total loss: [1m[32m0.31309[0m[0m | time: 11.151s
[2K
| RMSProp | epoch: 014 | loss: 0.31309 - acc: 0.8723 -- iter: 416/824
[A[ATraining Step: 352  | total loss: [1m[32m0.29891[0m[0m | time: 12.042s
[2K
| RMSProp | epoch: 014 | loss: 0.29891 - acc: 0.8767 -- iter: 448/824
[A[ATraining Step: 353  | total loss: [1m[32m0.28459[0m[0m | time: 12.921s
[2K
| RMSProp | epoch: 014 | loss: 0.28459 - acc: 0.8828 -- iter: 480/824
[A[ATraining Step: 354  | total loss: [1m[32m0.29513[0m[0m | time: 13.800s
[2K
| RMSProp | epoch: 014 | loss: 0.29513 - acc: 0.8727 -- iter: 512/824
[A[ATraining Step: 355  | total loss: [1m[32m0.30398[0m[0m | time: 14.626s
[2K
| RMSProp | epoch: 014 | loss: 0.30398 - acc: 0.8698 -- iter: 544/824
[A[ATraining Step: 356  | total loss: [1m[32m0.30411[0m[0m | time: 15.511s
[2K
| RMSProp | epoch: 014 | loss: 0.30411 - acc: 0.8703 -- iter: 576/824
[A[ATraining Step: 357  | total loss: [1m[32m0.29454[0m[0m | time: 16.394s
[2K
| RMSProp | epoch: 014 | loss: 0.29454 - acc: 0.8801 -- iter: 608/824
[A[ATraining Step: 358  | total loss: [1m[32m0.28788[0m[0m | time: 17.235s
[2K
| RMSProp | epoch: 014 | loss: 0.28788 - acc: 0.8827 -- iter: 640/824
[A[ATraining Step: 359  | total loss: [1m[32m0.27067[0m[0m | time: 18.051s
[2K
| RMSProp | epoch: 014 | loss: 0.27067 - acc: 0.8913 -- iter: 672/824
[A[ATraining Step: 360  | total loss: [1m[32m0.28187[0m[0m | time: 18.908s
[2K
| RMSProp | epoch: 014 | loss: 0.28187 - acc: 0.8866 -- iter: 704/824
[A[ATraining Step: 361  | total loss: [1m[32m0.28093[0m[0m | time: 19.711s
[2K
| RMSProp | epoch: 014 | loss: 0.28093 - acc: 0.8917 -- iter: 736/824
[A[ATraining Step: 362  | total loss: [1m[32m0.28879[0m[0m | time: 20.552s
[2K
| RMSProp | epoch: 014 | loss: 0.28879 - acc: 0.8900 -- iter: 768/824
[A[ATraining Step: 363  | total loss: [1m[32m0.31208[0m[0m | time: 21.391s
[2K
| RMSProp | epoch: 014 | loss: 0.31208 - acc: 0.8823 -- iter: 800/824
[A[ATraining Step: 364  | total loss: [1m[32m0.30869[0m[0m | time: 23.481s
[2K
| RMSProp | epoch: 014 | loss: 0.30869 - acc: 0.8878 | val_loss: 0.31098 - val_acc: 0.8643 -- iter: 824/824
--
Training Step: 365  | total loss: [1m[32m0.28979[0m[0m | time: 0.854s
[2K
| RMSProp | epoch: 015 | loss: 0.28979 - acc: 0.8990 -- iter: 032/824
[A[ATraining Step: 366  | total loss: [1m[32m0.27055[0m[0m | time: 1.770s
[2K
| RMSProp | epoch: 015 | loss: 0.27055 - acc: 0.9060 -- iter: 064/824
[A[ATraining Step: 367  | total loss: [1m[32m0.26482[0m[0m | time: 2.640s
[2K
| RMSProp | epoch: 015 | loss: 0.26482 - acc: 0.9060 -- iter: 096/824
[A[ATraining Step: 368  | total loss: [1m[32m0.26546[0m[0m | time: 3.535s
[2K
| RMSProp | epoch: 015 | loss: 0.26546 - acc: 0.9060 -- iter: 128/824
[A[ATraining Step: 369  | total loss: [1m[32m0.27119[0m[0m | time: 4.454s
[2K
| RMSProp | epoch: 015 | loss: 0.27119 - acc: 0.8967 -- iter: 160/824
[A[ATraining Step: 370  | total loss: [1m[32m0.32543[0m[0m | time: 5.347s
[2K
| RMSProp | epoch: 015 | loss: 0.32543 - acc: 0.8851 -- iter: 192/824
[A[ATraining Step: 371  | total loss: [1m[32m0.32910[0m[0m | time: 6.250s
[2K
| RMSProp | epoch: 015 | loss: 0.32910 - acc: 0.8779 -- iter: 224/824
[A[ATraining Step: 372  | total loss: [1m[32m0.31317[0m[0m | time: 7.082s
[2K
| RMSProp | epoch: 015 | loss: 0.31317 - acc: 0.8870 -- iter: 256/824
[A[ATraining Step: 373  | total loss: [1m[32m0.29796[0m[0m | time: 7.988s
[2K
| RMSProp | epoch: 015 | loss: 0.29796 - acc: 0.8951 -- iter: 288/824
[A[ATraining Step: 374  | total loss: [1m[32m0.29271[0m[0m | time: 8.967s
[2K
| RMSProp | epoch: 015 | loss: 0.29271 - acc: 0.8963 -- iter: 320/824
[A[ATraining Step: 375  | total loss: [1m[32m0.28709[0m[0m | time: 10.162s
[2K
| RMSProp | epoch: 015 | loss: 0.28709 - acc: 0.8910 -- iter: 352/824
[A[ATraining Step: 376  | total loss: [1m[32m0.30572[0m[0m | time: 11.012s
[2K
| RMSProp | epoch: 015 | loss: 0.30572 - acc: 0.8832 -- iter: 384/824
[A[ATraining Step: 377  | total loss: [1m[32m0.29863[0m[0m | time: 11.644s
[2K
| RMSProp | epoch: 015 | loss: 0.29863 - acc: 0.8886 -- iter: 416/824
[A[ATraining Step: 378  | total loss: [1m[32m0.31236[0m[0m | time: 12.319s
[2K
| RMSProp | epoch: 015 | loss: 0.31236 - acc: 0.8831 -- iter: 448/824
[A[ATraining Step: 379  | total loss: [1m[32m0.31250[0m[0m | time: 13.223s
[2K
| RMSProp | epoch: 015 | loss: 0.31250 - acc: 0.8739 -- iter: 480/824
[A[ATraining Step: 380  | total loss: [1m[32m0.30153[0m[0m | time: 14.080s
[2K
| RMSProp | epoch: 015 | loss: 0.30153 - acc: 0.8772 -- iter: 512/824
[A[ATraining Step: 381  | total loss: [1m[32m0.28715[0m[0m | time: 14.964s
[2K
| RMSProp | epoch: 015 | loss: 0.28715 - acc: 0.8863 -- iter: 544/824
[A[ATraining Step: 382  | total loss: [1m[32m0.28277[0m[0m | time: 15.821s
[2K
| RMSProp | epoch: 015 | loss: 0.28277 - acc: 0.8852 -- iter: 576/824
[A[ATraining Step: 383  | total loss: [1m[32m0.27331[0m[0m | time: 16.661s
[2K
| RMSProp | epoch: 015 | loss: 0.27331 - acc: 0.8904 -- iter: 608/824
[A[ATraining Step: 384  | total loss: [1m[32m0.27279[0m[0m | time: 17.518s
[2K
| RMSProp | epoch: 015 | loss: 0.27279 - acc: 0.8857 -- iter: 640/824
[A[ATraining Step: 385  | total loss: [1m[32m0.26665[0m[0m | time: 18.421s
[2K
| RMSProp | epoch: 015 | loss: 0.26665 - acc: 0.8878 -- iter: 672/824
[A[ATraining Step: 386  | total loss: [1m[32m0.25947[0m[0m | time: 19.245s
[2K
| RMSProp | epoch: 015 | loss: 0.25947 - acc: 0.8928 -- iter: 704/824
[A[ATraining Step: 387  | total loss: [1m[32m0.25176[0m[0m | time: 20.100s
[2K
| RMSProp | epoch: 015 | loss: 0.25176 - acc: 0.8941 -- iter: 736/824
[A[ATraining Step: 388  | total loss: [1m[32m0.26293[0m[0m | time: 20.955s
[2K
| RMSProp | epoch: 015 | loss: 0.26293 - acc: 0.8891 -- iter: 768/824
[A[ATraining Step: 389  | total loss: [1m[32m0.27766[0m[0m | time: 21.899s
[2K
| RMSProp | epoch: 015 | loss: 0.27766 - acc: 0.8845 -- iter: 800/824
[A[ATraining Step: 390  | total loss: [1m[32m0.25995[0m[0m | time: 24.063s
[2K
| RMSProp | epoch: 015 | loss: 0.25995 - acc: 0.8930 | val_loss: 0.31233 - val_acc: 0.8682 -- iter: 824/824
--
Validation AUC:0.9538378313397848
Validation AUPRC:0.9589953420714228
Test AUC:0.9676057187669663
Test AUPRC:0.976710933195595
BestTestF1Score	0.92	0.83	0.91	0.91	0.93	127	12	109	10	0.58
BestTestMCCScore	0.92	0.83	0.91	0.91	0.93	127	12	109	10	0.58
BestTestAccuracyScore	0.92	0.83	0.91	0.91	0.93	127	12	109	10	0.58
BestValidationF1Score	0.89	0.77	0.88	0.86	0.92	120	19	108	11	0.58
BestValidationMCC	0.89	0.77	0.88	0.86	0.92	120	19	108	11	0.58
BestValidationAccuracy	0.89	0.77	0.88	0.86	0.92	120	19	108	11	0.58
TestPredictions (Threshold:0.58)
CHEMBL300926,FP,INACT,0.5899999737739563	CHEMBL103828,TN,INACT,0.009999999776482582	CHEMBL2367842,TP,ACT,0.9900000095367432	CHEMBL344154,TN,INACT,0.07000000029802322	CHEMBL3350904,TP,ACT,1.0	CHEMBL175698,FP,INACT,0.8199999928474426	CHEMBL3774986,TP,ACT,0.9900000095367432	CHEMBL408987,TP,ACT,1.0	CHEMBL3665439,TN,INACT,0.44999998807907104	CHEMBL3238444,TN,INACT,0.009999999776482582	CHEMBL3582308,FN,ACT,0.3199999928474426	CHEMBL421523,TN,INACT,0.05000000074505806	CHEMBL3605788,FN,ACT,0.3499999940395355	CHEMBL58241,TN,INACT,0.0	CHEMBL3774771,TP,ACT,1.0	CHEMBL48031,FP,INACT,0.8600000143051147	CHEMBL553666,TN,INACT,0.009999999776482582	CHEMBL413373,TP,ACT,0.9900000095367432	CHEMBL173778,TP,ACT,0.9900000095367432	CHEMBL3349518,TP,ACT,1.0	CHEMBL477,TN,INACT,0.07999999821186066	CHEMBL79030,TN,INACT,0.029999999329447746	CHEMBL102390,TN,INACT,0.009999999776482582	CHEMBL428799,TP,ACT,0.9900000095367432	CHEMBL173059,TN,INACT,0.019999999552965164	CHEMBL3349674,TP,ACT,1.0	CHEMBL504462,TP,ACT,1.0	CHEMBL3582319,TP,ACT,1.0	CHEMBL500477,TP,ACT,1.0	CHEMBL1923416,TN,INACT,0.009999999776482582	CHEMBL233957,TN,INACT,0.20999999344348907	CHEMBL553672,TP,ACT,0.9599999785423279	CHEMBL343158,TN,INACT,0.07000000029802322	CHEMBL140984,TN,INACT,0.07999999821186066	CHEMBL216789,TP,ACT,1.0	CHEMBL78080,TN,INACT,0.019999999552965164	CHEMBL76576,TN,INACT,0.03999999910593033	CHEMBL267014,TN,INACT,0.03999999910593033	CHEMBL3349610,TP,ACT,1.0	CHEMBL3582343,TP,ACT,0.9900000095367432	CHEMBL15675,TN,INACT,0.05000000074505806	CHEMBL415201,TP,ACT,1.0	CHEMBL554692,TN,INACT,0.18000000715255737	CHEMBL3393999,TN,INACT,0.17000000178813934	CHEMBL559022,TP,ACT,1.0	CHEMBL3144280,TP,ACT,0.9300000071525574	CHEMBL3335537,TN,INACT,0.009999999776482582	CHEMBL2376800,TN,INACT,0.029999999329447746	CHEMBL1223230,TP,ACT,1.0	CHEMBL3287622,FN,ACT,0.14000000059604645	CHEMBL385745,TP,ACT,1.0	CHEMBL3775037,FN,ACT,0.05999999865889549	CHEMBL3775031,TP,ACT,0.9900000095367432	CHEMBL109478,TN,INACT,0.019999999552965164	CHEMBL384607,TP,ACT,1.0	CHEMBL70246,TN,INACT,0.019999999552965164	CHEMBL3323080,TP,ACT,1.0	CHEMBL543251,TN,INACT,0.009999999776482582	CHEMBL3287634,TP,ACT,0.7200000286102295	CHEMBL1824055,TP,ACT,1.0	CHEMBL556506,TN,INACT,0.09000000357627869	CHEMBL299538,TN,INACT,0.1599999964237213	CHEMBL554976,TP,ACT,1.0	CHEMBL476240,TP,ACT,0.9599999785423279	CHEMBL2370166,TP,ACT,0.9900000095367432	CHEMBL3323078,TP,ACT,0.9900000095367432	CHEMBL3582328,TP,ACT,1.0	CHEMBL21328,TN,INACT,0.20999999344348907	CHEMBL1087113,TP,ACT,0.8799999952316284	CHEMBL406373,TP,ACT,1.0	CHEMBL3098601,TP,ACT,1.0	CHEMBL2112415,TP,ACT,0.9399999976158142	CHEMBL435810,TN,INACT,0.25999999046325684	CHEMBL296927,TN,INACT,0.10999999940395355	CHEMBL502511,TP,ACT,1.0	CHEMBL1076720,TP,ACT,0.8600000143051147	CHEMBL284965,TN,INACT,0.009999999776482582	CHEMBL68738,TN,INACT,0.019999999552965164	CHEMBL473763,FN,ACT,0.05000000074505806	CHEMBL275481,TN,INACT,0.28999999165534973	CHEMBL282618,TP,ACT,0.9800000190734863	CHEMBL3350892,TP,ACT,1.0	CHEMBL552615,TN,INACT,0.009999999776482582	CHEMBL3775418,TP,ACT,1.0	CHEMBL407195,TP,ACT,1.0	CHEMBL3217760,TP,ACT,0.7799999713897705	CHEMBL3775630,TP,ACT,1.0	CHEMBL1098359,TN,INACT,0.03999999910593033	CHEMBL3323087,TP,ACT,1.0	CHEMBL505704,TP,ACT,1.0	CHEMBL2069506,TP,ACT,1.0	CHEMBL3287652,FN,ACT,0.07000000029802322	CHEMBL1202952,TP,ACT,0.9900000095367432	CHEMBL561262,TN,INACT,0.029999999329447746	CHEMBL452150,TN,INACT,0.019999999552965164	CHEMBL168541,TN,INACT,0.029999999329447746	CHEMBL2370168,TP,ACT,0.9900000095367432	CHEMBL432974,TN,INACT,0.019999999552965164	CHEMBL325935,TN,INACT,0.009999999776482582	CHEMBL563462,TP,ACT,0.9900000095367432	CHEMBL455435,TP,ACT,1.0	CHEMBL3349611,TP,ACT,0.9900000095367432	CHEMBL3349672,TP,ACT,1.0	CHEMBL3665436,TN,INACT,0.029999999329447746	CHEMBL1082178,TP,ACT,0.8899999856948853	CHEMBL148967,FP,INACT,0.6000000238418579	CHEMBL3582327,TP,ACT,1.0	CHEMBL448026,TP,ACT,0.8500000238418579	CHEMBL3582326,TP,ACT,1.0	CHEMBL241080,FP,INACT,0.8299999833106995	CHEMBL297173,TN,INACT,0.05000000074505806	CHEMBL73392,TN,INACT,0.029999999329447746	CHEMBL3122127,TP,ACT,0.9900000095367432	CHEMBL2369734,TP,ACT,1.0	CHEMBL67109,TN,INACT,0.3499999940395355	CHEMBL511086,TP,ACT,1.0	CHEMBL147238,TN,INACT,0.10999999940395355	CHEMBL3350880,TP,ACT,1.0	CHEMBL1081442,TP,ACT,0.9100000262260437	CHEMBL228738,TN,INACT,0.11999999731779099	CHEMBL3287617,TP,ACT,0.9100000262260437	CHEMBL367716,TP,ACT,0.9200000166893005	CHEMBL143539,TN,INACT,0.009999999776482582	CHEMBL510693,TP,ACT,1.0	CHEMBL80505,TN,INACT,0.05000000074505806	CHEMBL1086988,TP,ACT,0.8700000047683716	CHEMBL2079559,TP,ACT,1.0	CHEMBL2367839,TP,ACT,0.9900000095367432	CHEMBL3775050,TP,ACT,1.0	CHEMBL53842,TN,INACT,0.009999999776482582	CHEMBL309194,TN,INACT,0.009999999776482582	CHEMBL2371051,TP,ACT,1.0	CHEMBL143761,TN,INACT,0.009999999776482582	CHEMBL3774903,TP,ACT,1.0	CHEMBL251835,TP,ACT,0.6200000047683716	CHEMBL411556,TP,ACT,1.0	CHEMBL404505,TN,INACT,0.23999999463558197	CHEMBL2312347,TN,INACT,0.3400000035762787	CHEMBL140006,TN,INACT,0.009999999776482582	CHEMBL42799,TN,INACT,0.12999999523162842	CHEMBL332645,TN,INACT,0.10000000149011612	CHEMBL453938,TP,ACT,0.8700000047683716	CHEMBL48024,TN,INACT,0.3400000035762787	CHEMBL2369761,TP,ACT,1.0	CHEMBL3605802,TP,ACT,0.9100000262260437	CHEMBL3582334,TP,ACT,1.0	CHEMBL1765670,TN,INACT,0.28999999165534973	CHEMBL3582320,TP,ACT,1.0	CHEMBL2367841,TP,ACT,1.0	CHEMBL3287630,FN,ACT,0.3400000035762787	CHEMBL62421,TN,INACT,0.0	CHEMBL3605805,TP,ACT,0.9399999976158142	CHEMBL415359,TP,ACT,1.0	CHEMBL3287631,TP,ACT,0.8799999952316284	CHEMBL45456,FP,INACT,0.7900000214576721	CHEMBL504930,TP,ACT,0.9399999976158142	CHEMBL296908,TN,INACT,0.07999999821186066	CHEMBL404888,TN,INACT,0.03999999910593033	CHEMBL336081,TN,INACT,0.17000000178813934	CHEMBL1223228,TP,ACT,0.9900000095367432	CHEMBL2062854,TN,INACT,0.009999999776482582	CHEMBL2042400,TN,INACT,0.029999999329447746	CHEMBL73096,TN,INACT,0.33000001311302185	CHEMBL141354,TN,INACT,0.07000000029802322	CHEMBL129198,TN,INACT,0.009999999776482582	CHEMBL359141,TN,INACT,0.4699999988079071	CHEMBL405421,TP,ACT,1.0	CHEMBL385746,TP,ACT,1.0	CHEMBL3605812,TP,ACT,0.9599999785423279	CHEMBL311695,TP,ACT,1.0	CHEMBL296245,TN,INACT,0.4699999988079071	CHEMBL169889,TN,INACT,0.009999999776482582	CHEMBL78137,TN,INACT,0.18000000715255737	CHEMBL396271,TN,INACT,0.25	CHEMBL34328,TN,INACT,0.009999999776482582	CHEMBL404866,TN,INACT,0.029999999329447746	CHEMBL335971,TN,INACT,0.0	CHEMBL3350037,TP,ACT,1.0	CHEMBL39843,TN,INACT,0.029999999329447746	CHEMBL434674,TN,INACT,0.20000000298023224	CHEMBL3122129,TP,ACT,0.9399999976158142	CHEMBL2367843,TP,ACT,1.0	CHEMBL2311547,TN,INACT,0.009999999776482582	CHEMBL1076623,TP,ACT,0.9300000071525574	CHEMBL414165,FP,INACT,0.9900000095367432	CHEMBL165462,TN,INACT,0.009999999776482582	CHEMBL419617,TN,INACT,0.3499999940395355	CHEMBL453412,TP,ACT,0.9399999976158142	CHEMBL2112223,TP,ACT,0.7900000214576721	CHEMBL3218124,FN,ACT,0.029999999329447746	CHEMBL140620,TN,INACT,0.029999999329447746	CHEMBL2079626,TP,ACT,1.0	CHEMBL3774909,TP,ACT,1.0	CHEMBL461709,TN,INACT,0.09000000357627869	CHEMBL1478530,TN,INACT,0.3700000047683716	CHEMBL503596,TP,ACT,1.0	CHEMBL2372959,TP,ACT,0.9900000095367432	CHEMBL233721,FP,INACT,0.7900000214576721	CHEMBL440618,TP,ACT,1.0	CHEMBL2204937,TP,ACT,1.0	CHEMBL327626,TN,INACT,0.019999999552965164	CHEMBL324652,FP,INACT,0.8299999833106995	CHEMBL1081441,TP,ACT,0.9100000262260437	CHEMBL353088,TN,INACT,0.05999999865889549	CHEMBL302282,TN,INACT,0.029999999329447746	CHEMBL2372603,TP,ACT,1.0	CHEMBL414598,TP,ACT,1.0	CHEMBL9666,TN,INACT,0.10999999940395355	CHEMBL3605787,TP,ACT,0.9200000166893005	CHEMBL3350354,TP,ACT,0.9900000095367432	CHEMBL2069505,TP,ACT,1.0	CHEMBL414386,TP,ACT,1.0	CHEMBL466609,TP,ACT,0.9599999785423279	CHEMBL1076621,FN,ACT,0.09000000357627869	CHEMBL7505,TN,INACT,0.009999999776482582	CHEMBL633,TN,INACT,0.05999999865889549	CHEMBL2369756,TP,ACT,1.0	CHEMBL3582314,TP,ACT,1.0	CHEMBL3350911,TP,ACT,1.0	CHEMBL171108,TN,INACT,0.029999999329447746	CHEMBL3582309,TP,ACT,1.0	CHEMBL104377,TN,INACT,0.0	CHEMBL502077,TP,ACT,0.9800000190734863	CHEMBL306645,FP,INACT,0.9200000166893005	CHEMBL408338,TP,ACT,0.9900000095367432	CHEMBL594803,TN,INACT,0.03999999910593033	CHEMBL307659,TN,INACT,0.019999999552965164	CHEMBL461089,TN,INACT,0.019999999552965164	CHEMBL3582332,TP,ACT,1.0	CHEMBL3775055,TP,ACT,1.0	CHEMBL429166,TP,ACT,1.0	CHEMBL322678,TN,INACT,0.0	CHEMBL3647688,TP,ACT,0.9900000095367432	CHEMBL3350912,TP,ACT,1.0	CHEMBL452074,TP,ACT,1.0	CHEMBL3349617,TP,ACT,1.0	CHEMBL78853,TN,INACT,0.029999999329447746	CHEMBL1223631,TN,INACT,0.11999999731779099	CHEMBL505128,TP,ACT,1.0	CHEMBL208311,FP,INACT,0.9200000166893005	CHEMBL294349,TN,INACT,0.0	CHEMBL408787,TP,ACT,1.0	CHEMBL3582330,TP,ACT,1.0	CHEMBL104172,TN,INACT,0.029999999329447746	CHEMBL461988,FN,ACT,0.03999999910593033	CHEMBL2112488,FP,INACT,0.7599999904632568	CHEMBL166089,TN,INACT,0.14000000059604645	CHEMBL2372604,TP,ACT,1.0	CHEMBL143304,TN,INACT,0.09000000357627869	CHEMBL1983100,TN,INACT,0.15000000596046448	CHEMBL44463,TN,INACT,0.1599999964237213	CHEMBL1076686,TP,ACT,0.9200000166893005	CHEMBL357077,TN,INACT,0.019999999552965164	CHEMBL66789,TN,INACT,0.07000000029802322	CHEMBL1824056,TP,ACT,1.0	CHEMBL323175,TN,INACT,0.07000000029802322	CHEMBL286800,TN,INACT,0.009999999776482582	CHEMBL156814,TN,INACT,0.20000000298023224	

