CNNModel CHEMBL5669 adam 0.0005 30 128 0 0.8 False True
Number of active compounds :	236
Number of inactive compounds :	170
---------------------------------
Run id: CNNModel_CHEMBL5669_adam_0.0005_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5669_adam_0.0005_30_128_0.8_True/
---------------------------------
Training samples: 249
Validation samples: 78
--
Training Step: 1  | time: 1.692s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/249
[A[ATraining Step: 2  | total loss: [1m[32m0.62333[0m[0m | time: 3.170s
[2K
| Adam | epoch: 001 | loss: 0.62333 - acc: 0.6187 -- iter: 064/249
[A[ATraining Step: 3  | total loss: [1m[32m0.68072[0m[0m | time: 4.638s
[2K
| Adam | epoch: 001 | loss: 0.68072 - acc: 0.5216 -- iter: 096/249
[A[ATraining Step: 4  | total loss: [1m[32m0.68090[0m[0m | time: 5.828s
[2K
| Adam | epoch: 001 | loss: 0.68090 - acc: 0.6929 -- iter: 128/249
[A[ATraining Step: 5  | total loss: [1m[32m0.68927[0m[0m | time: 7.028s
[2K
| Adam | epoch: 001 | loss: 0.68927 - acc: 0.5810 -- iter: 160/249
[A[ATraining Step: 6  | total loss: [1m[32m0.68913[0m[0m | time: 8.300s
[2K
| Adam | epoch: 001 | loss: 0.68913 - acc: 0.5490 -- iter: 192/249
[A[ATraining Step: 7  | total loss: [1m[32m0.66643[0m[0m | time: 9.476s
[2K
| Adam | epoch: 001 | loss: 0.66643 - acc: 0.6321 -- iter: 224/249
[A[ATraining Step: 8  | total loss: [1m[32m0.68800[0m[0m | time: 11.502s
[2K
| Adam | epoch: 001 | loss: 0.68800 - acc: 0.5754 | val_loss: 0.70359 - val_acc: 0.5256 -- iter: 249/249
--
Training Step: 9  | total loss: [1m[32m0.69038[0m[0m | time: 1.096s
[2K
| Adam | epoch: 002 | loss: 0.69038 - acc: 0.5672 -- iter: 032/249
[A[ATraining Step: 10  | total loss: [1m[32m0.68785[0m[0m | time: 2.248s
[2K
| Adam | epoch: 002 | loss: 0.68785 - acc: 0.5636 -- iter: 064/249
[A[ATraining Step: 11  | total loss: [1m[32m0.69673[0m[0m | time: 3.848s
[2K
| Adam | epoch: 002 | loss: 0.69673 - acc: 0.5335 -- iter: 096/249
[A[ATraining Step: 12  | total loss: [1m[32m0.69444[0m[0m | time: 5.419s
[2K
| Adam | epoch: 002 | loss: 0.69444 - acc: 0.5325 -- iter: 128/249
[A[ATraining Step: 13  | total loss: [1m[32m0.69396[0m[0m | time: 6.618s
[2K
| Adam | epoch: 002 | loss: 0.69396 - acc: 0.5320 -- iter: 160/249
[A[ATraining Step: 14  | total loss: [1m[32m0.69113[0m[0m | time: 7.731s
[2K
| Adam | epoch: 002 | loss: 0.69113 - acc: 0.5444 -- iter: 192/249
[A[ATraining Step: 15  | total loss: [1m[32m0.68984[0m[0m | time: 8.916s
[2K
| Adam | epoch: 002 | loss: 0.68984 - acc: 0.5515 -- iter: 224/249
[A[ATraining Step: 16  | total loss: [1m[32m0.68739[0m[0m | time: 11.196s
[2K
| Adam | epoch: 002 | loss: 0.68739 - acc: 0.5791 | val_loss: 0.69176 - val_acc: 0.5256 -- iter: 249/249
--
Training Step: 17  | total loss: [1m[32m0.68888[0m[0m | time: 1.065s
[2K
| Adam | epoch: 003 | loss: 0.68888 - acc: 0.5619 -- iter: 032/249
[A[ATraining Step: 18  | total loss: [1m[32m0.69000[0m[0m | time: 2.162s
[2K
| Adam | epoch: 003 | loss: 0.69000 - acc: 0.5474 -- iter: 064/249
[A[ATraining Step: 19  | total loss: [1m[32m0.69090[0m[0m | time: 3.509s
[2K
| Adam | epoch: 003 | loss: 0.69090 - acc: 0.5382 -- iter: 096/249
[A[ATraining Step: 20  | total loss: [1m[32m0.68969[0m[0m | time: 5.056s
[2K
| Adam | epoch: 003 | loss: 0.68969 - acc: 0.5561 -- iter: 128/249
[A[ATraining Step: 21  | total loss: [1m[32m0.68662[0m[0m | time: 6.697s
[2K
| Adam | epoch: 003 | loss: 0.68662 - acc: 0.5969 -- iter: 160/249
[A[ATraining Step: 22  | total loss: [1m[32m0.68656[0m[0m | time: 14.818s
[2K
| Adam | epoch: 003 | loss: 0.68656 - acc: 0.5959 -- iter: 192/249
[A[ATraining Step: 23  | total loss: [1m[32m0.68781[0m[0m | time: 21.857s
[2K
| Adam | epoch: 003 | loss: 0.68781 - acc: 0.5772 -- iter: 224/249
[A[ATraining Step: 24  | total loss: [1m[32m0.68592[0m[0m | time: 55.440s
[2K
| Adam | epoch: 003 | loss: 0.68592 - acc: 0.5906 | val_loss: 0.69189 - val_acc: 0.5256 -- iter: 249/249
--
Training Step: 25  | total loss: [1m[32m0.68390[0m[0m | time: 1.074s
[2K
| Adam | epoch: 004 | loss: 0.68390 - acc: 0.6000 -- iter: 032/249
[A[ATraining Step: 26  | total loss: [1m[32m0.69016[0m[0m | time: 1.919s
[2K
| Adam | epoch: 004 | loss: 0.69016 - acc: 0.5570 -- iter: 064/249
[A[ATraining Step: 27  | total loss: [1m[32m0.69077[0m[0m | time: 2.991s
[2K
| Adam | epoch: 004 | loss: 0.69077 - acc: 0.5475 -- iter: 096/249
[A[ATraining Step: 28  | total loss: [1m[32m0.69110[0m[0m | time: 4.200s
[2K
| Adam | epoch: 004 | loss: 0.69110 - acc: 0.5406 -- iter: 128/249
[A[ATraining Step: 29  | total loss: [1m[32m0.68864[0m[0m | time: 5.385s
[2K
| Adam | epoch: 004 | loss: 0.68864 - acc: 0.5535 -- iter: 160/249
[A[ATraining Step: 30  | total loss: [1m[32m0.68181[0m[0m | time: 6.617s
[2K
| Adam | epoch: 004 | loss: 0.68181 - acc: 0.5853 -- iter: 192/249
[A[ATraining Step: 31  | total loss: [1m[32m0.68110[0m[0m | time: 7.964s
[2K
| Adam | epoch: 004 | loss: 0.68110 - acc: 0.5872 -- iter: 224/249
[A[ATraining Step: 32  | total loss: [1m[32m0.67542[0m[0m | time: 10.321s
[2K
| Adam | epoch: 004 | loss: 0.67542 - acc: 0.6028 | val_loss: 0.70447 - val_acc: 0.5256 -- iter: 249/249
--
Training Step: 33  | total loss: [1m[32m0.67935[0m[0m | time: 1.295s
[2K
| Adam | epoch: 005 | loss: 0.67935 - acc: 0.5871 -- iter: 032/249
[A[ATraining Step: 34  | total loss: [1m[32m0.68706[0m[0m | time: 2.687s
[2K
| Adam | epoch: 005 | loss: 0.68706 - acc: 0.5684 -- iter: 064/249
[A[ATraining Step: 35  | total loss: [1m[32m0.69039[0m[0m | time: 3.766s
[2K
| Adam | epoch: 005 | loss: 0.69039 - acc: 0.5606 -- iter: 096/249
[A[ATraining Step: 36  | total loss: [1m[32m0.68027[0m[0m | time: 4.796s
[2K
| Adam | epoch: 005 | loss: 0.68027 - acc: 0.5850 -- iter: 128/249
[A[ATraining Step: 37  | total loss: [1m[32m0.67304[0m[0m | time: 6.234s
[2K
| Adam | epoch: 005 | loss: 0.67304 - acc: 0.6040 -- iter: 160/249
[A[ATraining Step: 38  | total loss: [1m[32m0.67526[0m[0m | time: 7.831s
[2K
| Adam | epoch: 005 | loss: 0.67526 - acc: 0.5959 -- iter: 192/249
[A[ATraining Step: 39  | total loss: [1m[32m0.67525[0m[0m | time: 9.333s
[2K
| Adam | epoch: 005 | loss: 0.67525 - acc: 0.5955 -- iter: 224/249
[A[ATraining Step: 40  | total loss: [1m[32m0.67253[0m[0m | time: 11.331s
[2K
| Adam | epoch: 005 | loss: 0.67253 - acc: 0.6010 | val_loss: 0.70441 - val_acc: 0.5256 -- iter: 249/249
--
Training Step: 41  | total loss: [1m[32m0.67231[0m[0m | time: 1.128s
[2K
| Adam | epoch: 006 | loss: 0.67231 - acc: 0.5997 -- iter: 032/249
[A[ATraining Step: 42  | total loss: [1m[32m0.67229[0m[0m | time: 2.292s
[2K
| Adam | epoch: 006 | loss: 0.67229 - acc: 0.5986 -- iter: 064/249
[A[ATraining Step: 43  | total loss: [1m[32m0.68515[0m[0m | time: 3.359s
[2K
| Adam | epoch: 006 | loss: 0.68515 - acc: 0.5702 -- iter: 096/249
[A[ATraining Step: 44  | total loss: [1m[32m0.68534[0m[0m | time: 4.061s
[2K
| Adam | epoch: 006 | loss: 0.68534 - acc: 0.5689 -- iter: 128/249
[A[ATraining Step: 45  | total loss: [1m[32m0.67495[0m[0m | time: 4.937s
[2K
| Adam | epoch: 006 | loss: 0.67495 - acc: 0.6013 -- iter: 160/249
[A[ATraining Step: 46  | total loss: [1m[32m0.66673[0m[0m | time: 5.910s
[2K
| Adam | epoch: 006 | loss: 0.66673 - acc: 0.6278 -- iter: 192/249
[A[ATraining Step: 47  | total loss: [1m[32m0.66575[0m[0m | time: 6.720s
[2K
| Adam | epoch: 006 | loss: 0.66575 - acc: 0.6273 -- iter: 224/249
[A[ATraining Step: 48  | total loss: [1m[32m0.67480[0m[0m | time: 8.675s
[2K
| Adam | epoch: 006 | loss: 0.67480 - acc: 0.6018 | val_loss: 0.69814 - val_acc: 0.5256 -- iter: 249/249
--
Training Step: 49  | total loss: [1m[32m0.67438[0m[0m | time: 0.941s
[2K
| Adam | epoch: 007 | loss: 0.67438 - acc: 0.6006 -- iter: 032/249
[A[ATraining Step: 50  | total loss: [1m[32m0.68140[0m[0m | time: 1.862s
[2K
| Adam | epoch: 007 | loss: 0.68140 - acc: 0.5801 -- iter: 064/249
[A[ATraining Step: 51  | total loss: [1m[32m0.67484[0m[0m | time: 2.898s
[2K
| Adam | epoch: 007 | loss: 0.67484 - acc: 0.5965 -- iter: 096/249
[A[ATraining Step: 52  | total loss: [1m[32m0.66740[0m[0m | time: 3.683s
[2K
| Adam | epoch: 007 | loss: 0.66740 - acc: 0.6148 -- iter: 128/249
[A[ATraining Step: 53  | total loss: [1m[32m0.66793[0m[0m | time: 4.336s
[2K
| Adam | epoch: 007 | loss: 0.66793 - acc: 0.6117 -- iter: 160/249
[A[ATraining Step: 54  | total loss: [1m[32m0.66982[0m[0m | time: 5.036s
[2K
| Adam | epoch: 007 | loss: 0.66982 - acc: 0.6042 -- iter: 192/249
[A[ATraining Step: 55  | total loss: [1m[32m0.67179[0m[0m | time: 5.999s
[2K
| Adam | epoch: 007 | loss: 0.67179 - acc: 0.5979 -- iter: 224/249
[A[ATraining Step: 56  | total loss: [1m[32m0.67304[0m[0m | time: 8.028s
[2K
| Adam | epoch: 007 | loss: 0.67304 - acc: 0.5929 | val_loss: 0.69306 - val_acc: 0.5256 -- iter: 249/249
--
Training Step: 57  | total loss: [1m[32m0.68154[0m[0m | time: 1.810s
[2K
| Adam | epoch: 008 | loss: 0.68154 - acc: 0.5714 -- iter: 032/249
[A[ATraining Step: 58  | total loss: [1m[32m0.68143[0m[0m | time: 3.515s
[2K
| Adam | epoch: 008 | loss: 0.68143 - acc: 0.5702 -- iter: 064/249
[A[ATraining Step: 59  | total loss: [1m[32m0.68101[0m[0m | time: 5.132s
[2K
| Adam | epoch: 008 | loss: 0.68101 - acc: 0.5692 -- iter: 096/249
[A[ATraining Step: 60  | total loss: [1m[32m0.68235[0m[0m | time: 6.363s
[2K
| Adam | epoch: 008 | loss: 0.68235 - acc: 0.5600 -- iter: 128/249
[A[ATraining Step: 61  | total loss: [1m[32m0.67839[0m[0m | time: 14.423s
[2K
| Adam | epoch: 008 | loss: 0.67839 - acc: 0.5766 -- iter: 160/249
[A[ATraining Step: 62  | total loss: [1m[32m0.67501[0m[0m | time: 15.351s
[2K
| Adam | epoch: 008 | loss: 0.67501 - acc: 0.5909 -- iter: 192/249
[A[ATraining Step: 63  | total loss: [1m[32m0.67662[0m[0m | time: 16.467s
[2K
| Adam | epoch: 008 | loss: 0.67662 - acc: 0.5819 -- iter: 224/249
[A[ATraining Step: 64  | total loss: [1m[32m0.67826[0m[0m | time: 18.895s
[2K
| Adam | epoch: 008 | loss: 0.67826 - acc: 0.5742 | val_loss: 0.68404 - val_acc: 0.5256 -- iter: 249/249
--
Training Step: 65  | total loss: [1m[32m0.67775[0m[0m | time: 1.328s
[2K
| Adam | epoch: 009 | loss: 0.67775 - acc: 0.5727 -- iter: 032/249
[A[ATraining Step: 66  | total loss: [1m[32m0.67823[0m[0m | time: 2.795s
[2K
| Adam | epoch: 009 | loss: 0.67823 - acc: 0.5677 -- iter: 064/249
[A[ATraining Step: 67  | total loss: [1m[32m0.67892[0m[0m | time: 4.169s
[2K
| Adam | epoch: 009 | loss: 0.67892 - acc: 0.5633 -- iter: 096/249
[A[ATraining Step: 68  | total loss: [1m[32m0.67937[0m[0m | time: 5.395s
[2K
| Adam | epoch: 009 | loss: 0.67937 - acc: 0.5558 -- iter: 128/249
[A[ATraining Step: 69  | total loss: [1m[32m0.67795[0m[0m | time: 6.755s
[2K
| Adam | epoch: 009 | loss: 0.67795 - acc: 0.5566 -- iter: 160/249
[A[ATraining Step: 70  | total loss: [1m[32m0.67895[0m[0m | time: 8.128s
[2K
| Adam | epoch: 009 | loss: 0.67895 - acc: 0.5501 -- iter: 192/249
[A[ATraining Step: 71  | total loss: [1m[32m0.67504[0m[0m | time: 9.335s
[2K
| Adam | epoch: 009 | loss: 0.67504 - acc: 0.5586 -- iter: 224/249
[A[ATraining Step: 72  | total loss: [1m[32m0.67720[0m[0m | time: 11.551s
[2K
| Adam | epoch: 009 | loss: 0.67720 - acc: 0.5498 | val_loss: 0.67223 - val_acc: 0.5256 -- iter: 249/249
--
Training Step: 73  | total loss: [1m[32m0.67877[0m[0m | time: 1.109s
[2K
| Adam | epoch: 010 | loss: 0.67877 - acc: 0.5420 -- iter: 032/249
[A[ATraining Step: 74  | total loss: [1m[32m0.67441[0m[0m | time: 2.234s
[2K
| Adam | epoch: 010 | loss: 0.67441 - acc: 0.5580 -- iter: 064/249
[A[ATraining Step: 75  | total loss: [1m[32m0.66670[0m[0m | time: 3.286s
[2K
| Adam | epoch: 010 | loss: 0.66670 - acc: 0.5754 -- iter: 096/249
[A[ATraining Step: 76  | total loss: [1m[32m0.66526[0m[0m | time: 4.361s
[2K
| Adam | epoch: 010 | loss: 0.66526 - acc: 0.5740 -- iter: 128/249
[A[ATraining Step: 77  | total loss: [1m[32m0.66510[0m[0m | time: 5.329s
[2K
| Adam | epoch: 010 | loss: 0.66510 - acc: 0.5728 -- iter: 160/249
[A[ATraining Step: 78  | total loss: [1m[32m0.65638[0m[0m | time: 6.396s
[2K
| Adam | epoch: 010 | loss: 0.65638 - acc: 0.5848 -- iter: 192/249
[A[ATraining Step: 79  | total loss: [1m[32m0.66379[0m[0m | time: 7.454s
[2K
| Adam | epoch: 010 | loss: 0.66379 - acc: 0.5696 -- iter: 224/249
[A[ATraining Step: 80  | total loss: [1m[32m0.66042[0m[0m | time: 9.273s
[2K
| Adam | epoch: 010 | loss: 0.66042 - acc: 0.5688 | val_loss: 0.65301 - val_acc: 0.6538 -- iter: 249/249
--
Training Step: 81  | total loss: [1m[32m0.65918[0m[0m | time: 1.000s
[2K
| Adam | epoch: 011 | loss: 0.65918 - acc: 0.5639 -- iter: 032/249
[A[ATraining Step: 82  | total loss: [1m[32m0.65856[0m[0m | time: 2.402s
[2K
| Adam | epoch: 011 | loss: 0.65856 - acc: 0.5675 -- iter: 064/249
[A[ATraining Step: 83  | total loss: [1m[32m0.65598[0m[0m | time: 3.773s
[2K
| Adam | epoch: 011 | loss: 0.65598 - acc: 0.5764 -- iter: 096/249
[A[ATraining Step: 84  | total loss: [1m[32m0.65288[0m[0m | time: 4.758s
[2K
| Adam | epoch: 011 | loss: 0.65288 - acc: 0.5938 -- iter: 128/249
[A[ATraining Step: 85  | total loss: [1m[32m0.65221[0m[0m | time: 5.827s
[2K
| Adam | epoch: 011 | loss: 0.65221 - acc: 0.6000 -- iter: 160/249
[A[ATraining Step: 86  | total loss: [1m[32m0.65280[0m[0m | time: 7.059s
[2K
| Adam | epoch: 011 | loss: 0.65280 - acc: 0.6025 -- iter: 192/249
[A[ATraining Step: 87  | total loss: [1m[32m0.64665[0m[0m | time: 8.080s
[2K
| Adam | epoch: 011 | loss: 0.64665 - acc: 0.6173 -- iter: 224/249
[A[ATraining Step: 88  | total loss: [1m[32m0.63542[0m[0m | time: 10.170s
[2K
| Adam | epoch: 011 | loss: 0.63542 - acc: 0.6337 | val_loss: 0.65048 - val_acc: 0.6282 -- iter: 249/249
--
Training Step: 89  | total loss: [1m[32m0.62414[0m[0m | time: 0.954s
[2K
| Adam | epoch: 012 | loss: 0.62414 - acc: 0.6484 -- iter: 032/249
[A[ATraining Step: 90  | total loss: [1m[32m0.62097[0m[0m | time: 1.829s
[2K
| Adam | epoch: 012 | loss: 0.62097 - acc: 0.6476 -- iter: 064/249
[A[ATraining Step: 91  | total loss: [1m[32m0.61269[0m[0m | time: 2.909s
[2K
| Adam | epoch: 012 | loss: 0.61269 - acc: 0.6588 -- iter: 096/249
[A[ATraining Step: 92  | total loss: [1m[32m0.60592[0m[0m | time: 4.244s
[2K
| Adam | epoch: 012 | loss: 0.60592 - acc: 0.6711 -- iter: 128/249
[A[ATraining Step: 93  | total loss: [1m[32m0.59559[0m[0m | time: 5.503s
[2K
| Adam | epoch: 012 | loss: 0.59559 - acc: 0.6790 -- iter: 160/249
[A[ATraining Step: 94  | total loss: [1m[32m0.58685[0m[0m | time: 6.887s
[2K
| Adam | epoch: 012 | loss: 0.58685 - acc: 0.6892 -- iter: 192/249
[A[ATraining Step: 95  | total loss: [1m[32m0.56961[0m[0m | time: 7.821s
[2K
| Adam | epoch: 012 | loss: 0.56961 - acc: 0.7046 -- iter: 224/249
[A[ATraining Step: 96  | total loss: [1m[32m0.58973[0m[0m | time: 9.829s
[2K
| Adam | epoch: 012 | loss: 0.58973 - acc: 0.6935 | val_loss: 0.54854 - val_acc: 0.7308 -- iter: 249/249
--
Training Step: 97  | total loss: [1m[32m0.57079[0m[0m | time: 1.027s
[2K
| Adam | epoch: 013 | loss: 0.57079 - acc: 0.7117 -- iter: 032/249
[A[ATraining Step: 98  | total loss: [1m[32m0.55687[0m[0m | time: 1.863s
[2K
| Adam | epoch: 013 | loss: 0.55687 - acc: 0.7155 -- iter: 064/249
[A[ATraining Step: 99  | total loss: [1m[32m0.54913[0m[0m | time: 2.681s
[2K
| Adam | epoch: 013 | loss: 0.54913 - acc: 0.7160 -- iter: 096/249
[A[ATraining Step: 100  | total loss: [1m[32m0.54051[0m[0m | time: 3.801s
[2K
| Adam | epoch: 013 | loss: 0.54051 - acc: 0.7204 -- iter: 128/249
[A[ATraining Step: 101  | total loss: [1m[32m0.53425[0m[0m | time: 4.818s
[2K
| Adam | epoch: 013 | loss: 0.53425 - acc: 0.7265 -- iter: 160/249
[A[ATraining Step: 102  | total loss: [1m[32m0.52500[0m[0m | time: 5.834s
[2K
| Adam | epoch: 013 | loss: 0.52500 - acc: 0.7319 -- iter: 192/249
[A[ATraining Step: 103  | total loss: [1m[32m0.52394[0m[0m | time: 7.001s
[2K
| Adam | epoch: 013 | loss: 0.52394 - acc: 0.7337 -- iter: 224/249
[A[ATraining Step: 104  | total loss: [1m[32m0.50947[0m[0m | time: 9.337s
[2K
| Adam | epoch: 013 | loss: 0.50947 - acc: 0.7447 | val_loss: 0.72998 - val_acc: 0.6282 -- iter: 249/249
--
Training Step: 105  | total loss: [1m[32m0.53065[0m[0m | time: 0.852s
[2K
| Adam | epoch: 014 | loss: 0.53065 - acc: 0.7296 -- iter: 032/249
[A[ATraining Step: 106  | total loss: [1m[32m0.53919[0m[0m | time: 1.820s
[2K
| Adam | epoch: 014 | loss: 0.53919 - acc: 0.7192 -- iter: 064/249
[A[ATraining Step: 107  | total loss: [1m[32m0.52988[0m[0m | time: 2.638s
[2K
| Adam | epoch: 014 | loss: 0.52988 - acc: 0.7316 -- iter: 096/249
[A[ATraining Step: 108  | total loss: [1m[32m0.54758[0m[0m | time: 3.423s
[2K
| Adam | epoch: 014 | loss: 0.54758 - acc: 0.7145 -- iter: 128/249
[A[ATraining Step: 109  | total loss: [1m[32m0.58782[0m[0m | time: 4.537s
[2K
| Adam | epoch: 014 | loss: 0.58782 - acc: 0.6790 -- iter: 160/249
[A[ATraining Step: 110  | total loss: [1m[32m0.58960[0m[0m | time: 5.612s
[2K
| Adam | epoch: 014 | loss: 0.58960 - acc: 0.6799 -- iter: 192/249
[A[ATraining Step: 111  | total loss: [1m[32m0.56795[0m[0m | time: 6.609s
[2K
| Adam | epoch: 014 | loss: 0.56795 - acc: 0.6994 -- iter: 224/249
[A[ATraining Step: 112  | total loss: [1m[32m0.55725[0m[0m | time: 8.684s
[2K
| Adam | epoch: 014 | loss: 0.55725 - acc: 0.7138 | val_loss: 0.64210 - val_acc: 0.6795 -- iter: 249/249
--
Training Step: 113  | total loss: [1m[32m0.53311[0m[0m | time: 1.010s
[2K
| Adam | epoch: 015 | loss: 0.53311 - acc: 0.7299 -- iter: 032/249
[A[ATraining Step: 114  | total loss: [1m[32m0.54450[0m[0m | time: 2.402s
[2K
| Adam | epoch: 015 | loss: 0.54450 - acc: 0.7163 -- iter: 064/249
[A[ATraining Step: 115  | total loss: [1m[32m0.54062[0m[0m | time: 3.837s
[2K
| Adam | epoch: 015 | loss: 0.54062 - acc: 0.7134 -- iter: 096/249
[A[ATraining Step: 116  | total loss: [1m[32m0.52176[0m[0m | time: 4.989s
[2K
| Adam | epoch: 015 | loss: 0.52176 - acc: 0.7327 -- iter: 128/249
[A[ATraining Step: 117  | total loss: [1m[32m0.51344[0m[0m | time: 10.949s
[2K
| Adam | epoch: 015 | loss: 0.51344 - acc: 0.7434 -- iter: 160/249
[A[ATraining Step: 118  | total loss: [1m[32m0.50428[0m[0m | time: 11.967s
[2K
| Adam | epoch: 015 | loss: 0.50428 - acc: 0.7611 -- iter: 192/249
[A[ATraining Step: 119  | total loss: [1m[32m0.48561[0m[0m | time: 12.960s
[2K
| Adam | epoch: 015 | loss: 0.48561 - acc: 0.7819 -- iter: 224/249
[A[ATraining Step: 120  | total loss: [1m[32m0.46865[0m[0m | time: 15.013s
[2K
| Adam | epoch: 015 | loss: 0.46865 - acc: 0.7943 | val_loss: 0.53569 - val_acc: 0.7564 -- iter: 249/249
--
Training Step: 121  | total loss: [1m[32m0.45602[0m[0m | time: 1.415s
[2K
| Adam | epoch: 016 | loss: 0.45602 - acc: 0.8024 -- iter: 032/249
[A[ATraining Step: 122  | total loss: [1m[32m0.45228[0m[0m | time: 2.642s
[2K
| Adam | epoch: 016 | loss: 0.45228 - acc: 0.8003 -- iter: 064/249
[A[ATraining Step: 123  | total loss: [1m[32m0.42417[0m[0m | time: 3.677s
[2K
| Adam | epoch: 016 | loss: 0.42417 - acc: 0.8140 -- iter: 096/249
[A[ATraining Step: 124  | total loss: [1m[32m0.40391[0m[0m | time: 4.758s
[2K
| Adam | epoch: 016 | loss: 0.40391 - acc: 0.8295 -- iter: 128/249
[A[ATraining Step: 125  | total loss: [1m[32m0.39366[0m[0m | time: 5.577s
[2K
| Adam | epoch: 016 | loss: 0.39366 - acc: 0.8371 -- iter: 160/249
[A[ATraining Step: 126  | total loss: [1m[32m0.38851[0m[0m | time: 6.763s
[2K
| Adam | epoch: 016 | loss: 0.38851 - acc: 0.8414 -- iter: 192/249
[A[ATraining Step: 127  | total loss: [1m[32m0.37808[0m[0m | time: 8.103s
[2K
| Adam | epoch: 016 | loss: 0.37808 - acc: 0.8373 -- iter: 224/249
[A[ATraining Step: 128  | total loss: [1m[32m0.39729[0m[0m | time: 10.035s
[2K
| Adam | epoch: 016 | loss: 0.39729 - acc: 0.8223 | val_loss: 0.40257 - val_acc: 0.8462 -- iter: 249/249
--
Training Step: 129  | total loss: [1m[32m0.39274[0m[0m | time: 1.045s
[2K
| Adam | epoch: 017 | loss: 0.39274 - acc: 0.8276 -- iter: 032/249
[A[ATraining Step: 130  | total loss: [1m[32m0.39564[0m[0m | time: 2.165s
[2K
| Adam | epoch: 017 | loss: 0.39564 - acc: 0.8292 -- iter: 064/249
[A[ATraining Step: 131  | total loss: [1m[32m0.38050[0m[0m | time: 3.142s
[2K
| Adam | epoch: 017 | loss: 0.38050 - acc: 0.8369 -- iter: 096/249
[A[ATraining Step: 132  | total loss: [1m[32m0.36462[0m[0m | time: 4.131s
[2K
| Adam | epoch: 017 | loss: 0.36462 - acc: 0.8470 -- iter: 128/249
[A[ATraining Step: 133  | total loss: [1m[32m0.34770[0m[0m | time: 5.300s
[2K
| Adam | epoch: 017 | loss: 0.34770 - acc: 0.8560 -- iter: 160/249
[A[ATraining Step: 134  | total loss: [1m[32m0.33475[0m[0m | time: 6.376s
[2K
| Adam | epoch: 017 | loss: 0.33475 - acc: 0.8610 -- iter: 192/249
[A[ATraining Step: 135  | total loss: [1m[32m0.31718[0m[0m | time: 7.317s
[2K
| Adam | epoch: 017 | loss: 0.31718 - acc: 0.8749 -- iter: 224/249
[A[ATraining Step: 136  | total loss: [1m[32m0.29970[0m[0m | time: 9.309s
[2K
| Adam | epoch: 017 | loss: 0.29970 - acc: 0.8874 | val_loss: 0.40931 - val_acc: 0.8718 -- iter: 249/249
--
Training Step: 137  | total loss: [1m[32m0.28862[0m[0m | time: 1.135s
[2K
| Adam | epoch: 018 | loss: 0.28862 - acc: 0.8924 -- iter: 032/249
[A[ATraining Step: 138  | total loss: [1m[32m0.28204[0m[0m | time: 2.201s
[2K
| Adam | epoch: 018 | loss: 0.28204 - acc: 0.8907 -- iter: 064/249
[A[ATraining Step: 139  | total loss: [1m[32m0.27598[0m[0m | time: 3.251s
[2K
| Adam | epoch: 018 | loss: 0.27598 - acc: 0.8954 -- iter: 096/249
[A[ATraining Step: 140  | total loss: [1m[32m0.25633[0m[0m | time: 4.405s
[2K
| Adam | epoch: 018 | loss: 0.25633 - acc: 0.9058 -- iter: 128/249
[A[ATraining Step: 141  | total loss: [1m[32m0.24917[0m[0m | time: 5.505s
[2K
| Adam | epoch: 018 | loss: 0.24917 - acc: 0.9059 -- iter: 160/249
[A[ATraining Step: 142  | total loss: [1m[32m0.24883[0m[0m | time: 6.680s
[2K
| Adam | epoch: 018 | loss: 0.24883 - acc: 0.9090 -- iter: 192/249
[A[ATraining Step: 143  | total loss: [1m[32m0.25291[0m[0m | time: 7.635s
[2K
| Adam | epoch: 018 | loss: 0.25291 - acc: 0.9088 -- iter: 224/249
[A[ATraining Step: 144  | total loss: [1m[32m0.26992[0m[0m | time: 9.483s
[2K
| Adam | epoch: 018 | loss: 0.26992 - acc: 0.8939 | val_loss: 0.38883 - val_acc: 0.8718 -- iter: 249/249
--
Training Step: 145  | total loss: [1m[32m0.27894[0m[0m | time: 0.836s
[2K
| Adam | epoch: 019 | loss: 0.27894 - acc: 0.8805 -- iter: 032/249
[A[ATraining Step: 146  | total loss: [1m[32m0.26408[0m[0m | time: 1.645s
[2K
| Adam | epoch: 019 | loss: 0.26408 - acc: 0.8862 -- iter: 064/249
[A[ATraining Step: 147  | total loss: [1m[32m0.24811[0m[0m | time: 2.421s
[2K
| Adam | epoch: 019 | loss: 0.24811 - acc: 0.8945 -- iter: 096/249
[A[ATraining Step: 148  | total loss: [1m[32m0.25255[0m[0m | time: 3.183s
[2K
| Adam | epoch: 019 | loss: 0.25255 - acc: 0.8925 -- iter: 128/249
[A[ATraining Step: 149  | total loss: [1m[32m0.24399[0m[0m | time: 3.929s
[2K
| Adam | epoch: 019 | loss: 0.24399 - acc: 0.8970 -- iter: 160/249
[A[ATraining Step: 150  | total loss: [1m[32m0.23400[0m[0m | time: 4.697s
[2K
| Adam | epoch: 019 | loss: 0.23400 - acc: 0.9042 -- iter: 192/249
[A[ATraining Step: 151  | total loss: [1m[32m0.21990[0m[0m | time: 5.499s
[2K
| Adam | epoch: 019 | loss: 0.21990 - acc: 0.9106 -- iter: 224/249
[A[ATraining Step: 152  | total loss: [1m[32m0.22198[0m[0m | time: 7.110s
[2K
| Adam | epoch: 019 | loss: 0.22198 - acc: 0.9071 | val_loss: 0.37605 - val_acc: 0.8974 -- iter: 249/249
--
Training Step: 153  | total loss: [1m[32m0.21393[0m[0m | time: 0.626s
[2K
| Adam | epoch: 020 | loss: 0.21393 - acc: 0.9124 -- iter: 032/249
[A[ATraining Step: 154  | total loss: [1m[32m0.20559[0m[0m | time: 1.420s
[2K
| Adam | epoch: 020 | loss: 0.20559 - acc: 0.9131 -- iter: 064/249
[A[ATraining Step: 155  | total loss: [1m[32m0.19381[0m[0m | time: 2.219s
[2K
| Adam | epoch: 020 | loss: 0.19381 - acc: 0.9218 -- iter: 096/249
[A[ATraining Step: 156  | total loss: [1m[32m0.18455[0m[0m | time: 2.964s
[2K
| Adam | epoch: 020 | loss: 0.18455 - acc: 0.9265 -- iter: 128/249
[A[ATraining Step: 157  | total loss: [1m[32m0.18101[0m[0m | time: 3.734s
[2K
| Adam | epoch: 020 | loss: 0.18101 - acc: 0.9307 -- iter: 160/249
[A[ATraining Step: 158  | total loss: [1m[32m0.16652[0m[0m | time: 4.508s
[2K
| Adam | epoch: 020 | loss: 0.16652 - acc: 0.9377 -- iter: 192/249
[A[ATraining Step: 159  | total loss: [1m[32m0.18074[0m[0m | time: 5.249s
[2K
| Adam | epoch: 020 | loss: 0.18074 - acc: 0.9314 -- iter: 224/249
[A[ATraining Step: 160  | total loss: [1m[32m0.18941[0m[0m | time: 7.085s
[2K
| Adam | epoch: 020 | loss: 0.18941 - acc: 0.9258 | val_loss: 0.37721 - val_acc: 0.8974 -- iter: 249/249
--
Training Step: 161  | total loss: [1m[32m0.17296[0m[0m | time: 0.647s
[2K
| Adam | epoch: 021 | loss: 0.17296 - acc: 0.9332 -- iter: 032/249
[A[ATraining Step: 162  | total loss: [1m[32m0.16237[0m[0m | time: 1.301s
[2K
| Adam | epoch: 021 | loss: 0.16237 - acc: 0.9399 -- iter: 064/249
[A[ATraining Step: 163  | total loss: [1m[32m0.15453[0m[0m | time: 2.074s
[2K
| Adam | epoch: 021 | loss: 0.15453 - acc: 0.9459 -- iter: 096/249
[A[ATraining Step: 164  | total loss: [1m[32m0.14781[0m[0m | time: 2.868s
[2K
| Adam | epoch: 021 | loss: 0.14781 - acc: 0.9513 -- iter: 128/249
[A[ATraining Step: 165  | total loss: [1m[32m0.14392[0m[0m | time: 3.653s
[2K
| Adam | epoch: 021 | loss: 0.14392 - acc: 0.9499 -- iter: 160/249
[A[ATraining Step: 166  | total loss: [1m[32m0.14345[0m[0m | time: 4.392s
[2K
| Adam | epoch: 021 | loss: 0.14345 - acc: 0.9455 -- iter: 192/249
[A[ATraining Step: 167  | total loss: [1m[32m0.13152[0m[0m | time: 5.750s
[2K
| Adam | epoch: 021 | loss: 0.13152 - acc: 0.9510 -- iter: 224/249
[A[ATraining Step: 168  | total loss: [1m[32m0.12633[0m[0m | time: 8.101s
[2K
| Adam | epoch: 021 | loss: 0.12633 - acc: 0.9528 | val_loss: 0.36202 - val_acc: 0.8846 -- iter: 249/249
--
Training Step: 169  | total loss: [1m[32m0.11890[0m[0m | time: 0.886s
[2K
| Adam | epoch: 022 | loss: 0.11890 - acc: 0.9575 -- iter: 032/249
[A[ATraining Step: 170  | total loss: [1m[32m0.12641[0m[0m | time: 1.696s
[2K
| Adam | epoch: 022 | loss: 0.12641 - acc: 0.9555 -- iter: 064/249
[A[ATraining Step: 171  | total loss: [1m[32m0.12335[0m[0m | time: 2.551s
[2K
| Adam | epoch: 022 | loss: 0.12335 - acc: 0.9559 -- iter: 096/249
[A[ATraining Step: 172  | total loss: [1m[32m0.11362[0m[0m | time: 3.609s
[2K
| Adam | epoch: 022 | loss: 0.11362 - acc: 0.9603 -- iter: 128/249
[A[ATraining Step: 173  | total loss: [1m[32m0.10457[0m[0m | time: 4.733s
[2K
| Adam | epoch: 022 | loss: 0.10457 - acc: 0.9643 -- iter: 160/249
[A[ATraining Step: 174  | total loss: [1m[32m0.10441[0m[0m | time: 5.924s
[2K
| Adam | epoch: 022 | loss: 0.10441 - acc: 0.9616 -- iter: 192/249
[A[ATraining Step: 175  | total loss: [1m[32m0.11701[0m[0m | time: 7.004s
[2K
| Adam | epoch: 022 | loss: 0.11701 - acc: 0.9623 -- iter: 224/249
[A[ATraining Step: 176  | total loss: [1m[32m0.10780[0m[0m | time: 9.164s
[2K
| Adam | epoch: 022 | loss: 0.10780 - acc: 0.9661 | val_loss: 0.43627 - val_acc: 0.8846 -- iter: 249/249
--
Training Step: 177  | total loss: [1m[32m0.10830[0m[0m | time: 1.165s
[2K
| Adam | epoch: 023 | loss: 0.10830 - acc: 0.9632 -- iter: 032/249
[A[ATraining Step: 178  | total loss: [1m[32m0.10388[0m[0m | time: 2.549s
[2K
| Adam | epoch: 023 | loss: 0.10388 - acc: 0.9638 -- iter: 064/249
[A[ATraining Step: 179  | total loss: [1m[32m0.09724[0m[0m | time: 3.703s
[2K
| Adam | epoch: 023 | loss: 0.09724 - acc: 0.9674 -- iter: 096/249
[A[ATraining Step: 180  | total loss: [1m[32m0.09093[0m[0m | time: 4.649s
[2K
| Adam | epoch: 023 | loss: 0.09093 - acc: 0.9707 -- iter: 128/249
[A[ATraining Step: 181  | total loss: [1m[32m0.08450[0m[0m | time: 5.555s
[2K
| Adam | epoch: 023 | loss: 0.08450 - acc: 0.9736 -- iter: 160/249
[A[ATraining Step: 182  | total loss: [1m[32m0.07902[0m[0m | time: 6.589s
[2K
| Adam | epoch: 023 | loss: 0.07902 - acc: 0.9762 -- iter: 192/249
[A[ATraining Step: 183  | total loss: [1m[32m0.07267[0m[0m | time: 7.932s
[2K
| Adam | epoch: 023 | loss: 0.07267 - acc: 0.9786 -- iter: 224/249
[A[ATraining Step: 184  | total loss: [1m[32m0.09173[0m[0m | time: 10.314s
[2K
| Adam | epoch: 023 | loss: 0.09173 - acc: 0.9776 | val_loss: 0.38932 - val_acc: 0.9231 -- iter: 249/249
--
Training Step: 185  | total loss: [1m[32m0.08535[0m[0m | time: 1.065s
[2K
| Adam | epoch: 024 | loss: 0.08535 - acc: 0.9799 -- iter: 032/249
[A[ATraining Step: 186  | total loss: [1m[32m0.07758[0m[0m | time: 2.232s
[2K
| Adam | epoch: 024 | loss: 0.07758 - acc: 0.9819 -- iter: 064/249
[A[ATraining Step: 187  | total loss: [1m[32m0.07151[0m[0m | time: 3.432s
[2K
| Adam | epoch: 024 | loss: 0.07151 - acc: 0.9837 -- iter: 096/249
[A[ATraining Step: 188  | total loss: [1m[32m0.06760[0m[0m | time: 4.262s
[2K
| Adam | epoch: 024 | loss: 0.06760 - acc: 0.9853 -- iter: 128/249
[A[ATraining Step: 189  | total loss: [1m[32m0.06200[0m[0m | time: 5.147s
[2K
| Adam | epoch: 024 | loss: 0.06200 - acc: 0.9868 -- iter: 160/249
[A[ATraining Step: 190  | total loss: [1m[32m0.05710[0m[0m | time: 6.606s
[2K
| Adam | epoch: 024 | loss: 0.05710 - acc: 0.9881 -- iter: 192/249
[A[ATraining Step: 191  | total loss: [1m[32m0.05333[0m[0m | time: 7.941s
[2K
| Adam | epoch: 024 | loss: 0.05333 - acc: 0.9893 -- iter: 224/249
[A[ATraining Step: 192  | total loss: [1m[32m0.05156[0m[0m | time: 16.231s
[2K
| Adam | epoch: 024 | loss: 0.05156 - acc: 0.9872 | val_loss: 0.54858 - val_acc: 0.8462 -- iter: 249/249
--
Training Step: 193  | total loss: [1m[32m0.06480[0m[0m | time: 1.049s
[2K
| Adam | epoch: 025 | loss: 0.06480 - acc: 0.9854 -- iter: 032/249
[A[ATraining Step: 194  | total loss: [1m[32m0.06053[0m[0m | time: 2.085s
[2K
| Adam | epoch: 025 | loss: 0.06053 - acc: 0.9869 -- iter: 064/249
[A[ATraining Step: 195  | total loss: [1m[32m0.05618[0m[0m | time: 3.157s
[2K
| Adam | epoch: 025 | loss: 0.05618 - acc: 0.9882 -- iter: 096/249
[A[ATraining Step: 196  | total loss: [1m[32m0.05605[0m[0m | time: 4.344s
[2K
| Adam | epoch: 025 | loss: 0.05605 - acc: 0.9862 -- iter: 128/249
[A[ATraining Step: 197  | total loss: [1m[32m0.05240[0m[0m | time: 5.246s
[2K
| Adam | epoch: 025 | loss: 0.05240 - acc: 0.9876 -- iter: 160/249
[A[ATraining Step: 198  | total loss: [1m[32m0.05040[0m[0m | time: 6.194s
[2K
| Adam | epoch: 025 | loss: 0.05040 - acc: 0.9888 -- iter: 192/249
[A[ATraining Step: 199  | total loss: [1m[32m0.04741[0m[0m | time: 7.314s
[2K
| Adam | epoch: 025 | loss: 0.04741 - acc: 0.9900 -- iter: 224/249
[A[ATraining Step: 200  | total loss: [1m[32m0.04381[0m[0m | time: 9.663s
[2K
| Adam | epoch: 025 | loss: 0.04381 - acc: 0.9910 | val_loss: 0.51557 - val_acc: 0.8590 -- iter: 249/249
--
Training Step: 201  | total loss: [1m[32m0.04001[0m[0m | time: 1.046s
[2K
| Adam | epoch: 026 | loss: 0.04001 - acc: 0.9919 -- iter: 032/249
[A[ATraining Step: 202  | total loss: [1m[32m0.12443[0m[0m | time: 2.101s
[2K
| Adam | epoch: 026 | loss: 0.12443 - acc: 0.9771 -- iter: 064/249
[A[ATraining Step: 203  | total loss: [1m[32m0.11340[0m[0m | time: 3.200s
[2K
| Adam | epoch: 026 | loss: 0.11340 - acc: 0.9794 -- iter: 096/249
[A[ATraining Step: 204  | total loss: [1m[32m0.10342[0m[0m | time: 4.399s
[2K
| Adam | epoch: 026 | loss: 0.10342 - acc: 0.9814 -- iter: 128/249
[A[ATraining Step: 205  | total loss: [1m[32m0.09608[0m[0m | time: 5.492s
[2K
| Adam | epoch: 026 | loss: 0.09608 - acc: 0.9833 -- iter: 160/249
[A[ATraining Step: 206  | total loss: [1m[32m0.08862[0m[0m | time: 6.327s
[2K
| Adam | epoch: 026 | loss: 0.08862 - acc: 0.9849 -- iter: 192/249
[A[ATraining Step: 207  | total loss: [1m[32m0.08150[0m[0m | time: 7.051s
[2K
| Adam | epoch: 026 | loss: 0.08150 - acc: 0.9865 -- iter: 224/249
[A[ATraining Step: 208  | total loss: [1m[32m0.07547[0m[0m | time: 9.498s
[2K
| Adam | epoch: 026 | loss: 0.07547 - acc: 0.9878 | val_loss: 0.35934 - val_acc: 0.9231 -- iter: 249/249
--
Training Step: 209  | total loss: [1m[32m0.06919[0m[0m | time: 8.216s
[2K
| Adam | epoch: 027 | loss: 0.06919 - acc: 0.9890 -- iter: 032/249
[A[ATraining Step: 210  | total loss: [1m[32m0.06406[0m[0m | time: 9.179s
[2K
| Adam | epoch: 027 | loss: 0.06406 - acc: 0.9901 -- iter: 064/249
[A[ATraining Step: 211  | total loss: [1m[32m0.07208[0m[0m | time: 10.207s
[2K
| Adam | epoch: 027 | loss: 0.07208 - acc: 0.9880 -- iter: 096/249
[A[ATraining Step: 212  | total loss: [1m[32m0.06715[0m[0m | time: 11.240s
[2K
| Adam | epoch: 027 | loss: 0.06715 - acc: 0.9892 -- iter: 128/249
[A[ATraining Step: 213  | total loss: [1m[32m0.06230[0m[0m | time: 12.317s
[2K
| Adam | epoch: 027 | loss: 0.06230 - acc: 0.9903 -- iter: 160/249
[A[ATraining Step: 214  | total loss: [1m[32m0.05721[0m[0m | time: 13.456s
[2K
| Adam | epoch: 027 | loss: 0.05721 - acc: 0.9912 -- iter: 192/249
[A[ATraining Step: 215  | total loss: [1m[32m0.05320[0m[0m | time: 14.656s
[2K
| Adam | epoch: 027 | loss: 0.05320 - acc: 0.9921 -- iter: 224/249
[A[ATraining Step: 216  | total loss: [1m[32m0.04950[0m[0m | time: 16.793s
[2K
| Adam | epoch: 027 | loss: 0.04950 - acc: 0.9929 | val_loss: 0.32950 - val_acc: 0.9231 -- iter: 249/249
--
Training Step: 217  | total loss: [1m[32m0.04605[0m[0m | time: 1.326s
[2K
| Adam | epoch: 028 | loss: 0.04605 - acc: 0.9936 -- iter: 032/249
[A[ATraining Step: 218  | total loss: [1m[32m0.05152[0m[0m | time: 2.607s
[2K
| Adam | epoch: 028 | loss: 0.05152 - acc: 0.9911 -- iter: 064/249
[A[ATraining Step: 219  | total loss: [1m[32m0.04732[0m[0m | time: 3.562s
[2K
| Adam | epoch: 028 | loss: 0.04732 - acc: 0.9920 -- iter: 096/249
[A[ATraining Step: 220  | total loss: [1m[32m0.08211[0m[0m | time: 4.561s
[2K
| Adam | epoch: 028 | loss: 0.08211 - acc: 0.9866 -- iter: 128/249
[A[ATraining Step: 221  | total loss: [1m[32m0.07790[0m[0m | time: 5.558s
[2K
| Adam | epoch: 028 | loss: 0.07790 - acc: 0.9879 -- iter: 160/249
[A[ATraining Step: 222  | total loss: [1m[32m0.07207[0m[0m | time: 6.587s
[2K
| Adam | epoch: 028 | loss: 0.07207 - acc: 0.9891 -- iter: 192/249
[A[ATraining Step: 223  | total loss: [1m[32m0.06641[0m[0m | time: 7.595s
[2K
| Adam | epoch: 028 | loss: 0.06641 - acc: 0.9902 -- iter: 224/249
[A[ATraining Step: 224  | total loss: [1m[32m0.06089[0m[0m | time: 9.432s
[2K
| Adam | epoch: 028 | loss: 0.06089 - acc: 0.9912 | val_loss: 0.35020 - val_acc: 0.9231 -- iter: 249/249
--
Training Step: 225  | total loss: [1m[32m0.05957[0m[0m | time: 0.926s
[2K
| Adam | epoch: 029 | loss: 0.05957 - acc: 0.9881 -- iter: 032/249
[A[ATraining Step: 226  | total loss: [1m[32m0.05568[0m[0m | time: 2.043s
[2K
| Adam | epoch: 029 | loss: 0.05568 - acc: 0.9893 -- iter: 064/249
[A[ATraining Step: 227  | total loss: [1m[32m0.05186[0m[0m | time: 3.316s
[2K
| Adam | epoch: 029 | loss: 0.05186 - acc: 0.9903 -- iter: 096/249
[A[ATraining Step: 228  | total loss: [1m[32m0.04806[0m[0m | time: 4.760s
[2K
| Adam | epoch: 029 | loss: 0.04806 - acc: 0.9913 -- iter: 128/249
[A[ATraining Step: 229  | total loss: [1m[32m0.08095[0m[0m | time: 5.844s
[2K
| Adam | epoch: 029 | loss: 0.08095 - acc: 0.9859 -- iter: 160/249
[A[ATraining Step: 230  | total loss: [1m[32m0.07656[0m[0m | time: 6.938s
[2K
| Adam | epoch: 029 | loss: 0.07656 - acc: 0.9873 -- iter: 192/249
[A[ATraining Step: 231  | total loss: [1m[32m0.07028[0m[0m | time: 8.009s
[2K
| Adam | epoch: 029 | loss: 0.07028 - acc: 0.9886 -- iter: 224/249
[A[ATraining Step: 232  | total loss: [1m[32m0.06449[0m[0m | time: 10.124s
[2K
| Adam | epoch: 029 | loss: 0.06449 - acc: 0.9897 | val_loss: 0.34633 - val_acc: 0.9231 -- iter: 249/249
--
Training Step: 233  | total loss: [1m[32m0.06337[0m[0m | time: 1.069s
[2K
| Adam | epoch: 030 | loss: 0.06337 - acc: 0.9908 -- iter: 032/249
[A[ATraining Step: 234  | total loss: [1m[32m0.05847[0m[0m | time: 2.022s
[2K
| Adam | epoch: 030 | loss: 0.05847 - acc: 0.9917 -- iter: 064/249
[A[ATraining Step: 235  | total loss: [1m[32m0.05394[0m[0m | time: 3.043s
[2K
| Adam | epoch: 030 | loss: 0.05394 - acc: 0.9925 -- iter: 096/249
[A[ATraining Step: 236  | total loss: [1m[32m0.05140[0m[0m | time: 4.119s
[2K
| Adam | epoch: 030 | loss: 0.05140 - acc: 0.9933 -- iter: 128/249
[A[ATraining Step: 237  | total loss: [1m[32m0.04738[0m[0m | time: 5.478s
[2K
| Adam | epoch: 030 | loss: 0.04738 - acc: 0.9939 -- iter: 160/249
[A[ATraining Step: 238  | total loss: [1m[32m0.06672[0m[0m | time: 6.662s
[2K
| Adam | epoch: 030 | loss: 0.06672 - acc: 0.9883 -- iter: 192/249
[A[ATraining Step: 239  | total loss: [1m[32m0.07160[0m[0m | time: 7.665s
[2K
| Adam | epoch: 030 | loss: 0.07160 - acc: 0.9832 -- iter: 224/249
[A[ATraining Step: 240  | total loss: [1m[32m0.08692[0m[0m | time: 9.645s
[2K
| Adam | epoch: 030 | loss: 0.08692 - acc: 0.9724 | val_loss: 0.35075 - val_acc: 0.9103 -- iter: 249/249
--
Validation AUC:0.932762030323006
Validation AUPRC:0.9183590319405308
Test AUC:0.94006734006734
Test AUPRC:0.9460911888734689
BestTestF1Score	0.92	0.82	0.91	0.95	0.89	40	2	31	5	0.49
BestTestMCCScore	0.92	0.82	0.91	0.95	0.89	40	2	31	5	0.49
BestTestAccuracyScore	0.92	0.82	0.91	0.95	0.89	40	2	31	5	0.49
BestValidationF1Score	0.93	0.85	0.92	0.91	0.95	39	4	33	2	0.49
BestValidationMCC	0.93	0.85	0.92	0.91	0.95	39	4	33	2	0.49
BestValidationAccuracy	0.93	0.85	0.92	0.91	0.95	39	4	33	2	0.49
TestPredictions (Threshold:0.49)
CHEMBL436774,FN,ACT,0.009999999776482582	CHEMBL3104435,TP,ACT,0.9800000190734863	CHEMBL374864,TN,INACT,0.0	CHEMBL77242,TN,INACT,0.009999999776482582	CHEMBL3104620,TP,ACT,0.9900000095367432	CHEMBL242459,FN,ACT,0.05000000074505806	CHEMBL1632453,TN,INACT,0.1899999976158142	CHEMBL1079061,TP,ACT,0.8899999856948853	CHEMBL3114597,TP,ACT,1.0	CHEMBL1594316,TN,INACT,0.10000000149011612	CHEMBL561379,TP,ACT,1.0	CHEMBL1672130,TP,ACT,0.9900000095367432	CHEMBL436455,TN,INACT,0.009999999776482582	CHEMBL78444,TN,INACT,0.03999999910593033	CHEMBL3402236,TN,INACT,0.019999999552965164	CHEMBL578782,FN,ACT,0.019999999552965164	CHEMBL358672,TN,INACT,0.019999999552965164	CHEMBL3233609,TN,INACT,0.25999999046325684	CHEMBL608263,TP,ACT,0.8399999737739563	CHEMBL1079246,TP,ACT,0.9900000095367432	CHEMBL346611,TN,INACT,0.009999999776482582	CHEMBL2436577,TP,ACT,0.9800000190734863	CHEMBL1668934,TP,ACT,0.9900000095367432	CHEMBL562822,TP,ACT,1.0	CHEMBL1080974,TP,ACT,0.9599999785423279	CHEMBL560740,TP,ACT,0.8199999928474426	CHEMBL2436563,TP,ACT,0.9900000095367432	CHEMBL395080,FP,INACT,1.0	CHEMBL597990,TN,INACT,0.12999999523162842	CHEMBL563732,TP,ACT,1.0	CHEMBL450929,TN,INACT,0.009999999776482582	CHEMBL555347,TP,ACT,0.9800000190734863	CHEMBL80651,TN,INACT,0.009999999776482582	CHEMBL3102876,TP,ACT,1.0	CHEMBL3401639,FN,ACT,0.25999999046325684	CHEMBL565941,TP,ACT,0.8799999952316284	CHEMBL2392692,TP,ACT,0.9700000286102295	CHEMBL3114609,TP,ACT,1.0	CHEMBL50,TN,INACT,0.3100000023841858	CHEMBL3661407,TN,INACT,0.009999999776482582	CHEMBL576449,TP,ACT,0.8899999856948853	CHEMBL1668413,TN,INACT,0.009999999776482582	CHEMBL3781192,TN,INACT,0.009999999776482582	CHEMBL550648,TP,ACT,0.9900000095367432	CHEMBL417950,FP,INACT,0.9800000190734863	CHEMBL219595,TN,INACT,0.009999999776482582	CHEMBL497828,TP,ACT,0.9900000095367432	CHEMBL566648,TP,ACT,0.9700000286102295	CHEMBL552381,FN,ACT,0.4000000059604645	CHEMBL552382,TP,ACT,1.0	CHEMBL2436590,TP,ACT,0.9900000095367432	CHEMBL567703,TP,ACT,1.0	CHEMBL551338,TP,ACT,1.0	CHEMBL3236509,TN,INACT,0.0	CHEMBL80810,TN,INACT,0.009999999776482582	CHEMBL1077963,TP,ACT,1.0	CHEMBL3642239,TN,INACT,0.0	CHEMBL577696,TP,ACT,0.9100000262260437	CHEMBL3634697,TN,INACT,0.0	CHEMBL552402,TP,ACT,0.9800000190734863	CHEMBL3327077,TP,ACT,0.9900000095367432	CHEMBL40275,TN,INACT,0.0	CHEMBL150573,TN,INACT,0.009999999776482582	CHEMBL3634702,TN,INACT,0.0	CHEMBL76202,TN,INACT,0.0	CHEMBL66499,TN,INACT,0.019999999552965164	CHEMBL1078715,TP,ACT,0.7400000095367432	CHEMBL1079290,TP,ACT,1.0	CHEMBL387334,TN,INACT,0.009999999776482582	CHEMBL2021563,TP,ACT,0.9900000095367432	CHEMBL311318,TN,INACT,0.07000000029802322	CHEMBL568231,TP,ACT,0.8299999833106995	CHEMBL3114591,TP,ACT,1.0	CHEMBL3236510,TN,INACT,0.0	CHEMBL3402237,TN,INACT,0.019999999552965164	CHEMBL3114590,TP,ACT,1.0	CHEMBL567109,TP,ACT,0.9300000071525574	CHEMBL552061,TP,ACT,0.9200000166893005	

