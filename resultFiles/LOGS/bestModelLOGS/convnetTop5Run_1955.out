CNNModel CHEMBL3768 adam 0.001 15 128 0 0.8 False True
Number of active compounds :	286
Number of inactive compounds :	191
---------------------------------
Run id: CNNModel_CHEMBL3768_adam_0.001_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3768_adam_0.001_15_128_0.8_True/
---------------------------------
Training samples: 297
Validation samples: 94
--
Training Step: 1  | time: 0.882s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/297
[A[ATraining Step: 2  | total loss: [1m[32m0.62359[0m[0m | time: 1.570s
[2K
| Adam | epoch: 001 | loss: 0.62359 - acc: 0.5062 -- iter: 064/297
[A[ATraining Step: 3  | total loss: [1m[32m0.67864[0m[0m | time: 2.222s
[2K
| Adam | epoch: 001 | loss: 0.67864 - acc: 0.5523 -- iter: 096/297
[A[ATraining Step: 4  | total loss: [1m[32m0.67817[0m[0m | time: 2.872s
[2K
| Adam | epoch: 001 | loss: 0.67817 - acc: 0.5834 -- iter: 128/297
[A[ATraining Step: 5  | total loss: [1m[32m0.66988[0m[0m | time: 3.571s
[2K
| Adam | epoch: 001 | loss: 0.66988 - acc: 0.6122 -- iter: 160/297
[A[ATraining Step: 6  | total loss: [1m[32m0.67368[0m[0m | time: 4.243s
[2K
| Adam | epoch: 001 | loss: 0.67368 - acc: 0.6003 -- iter: 192/297
[A[ATraining Step: 7  | total loss: [1m[32m0.66287[0m[0m | time: 4.897s
[2K
| Adam | epoch: 001 | loss: 0.66287 - acc: 0.6339 -- iter: 224/297
[A[ATraining Step: 8  | total loss: [1m[32m0.68736[0m[0m | time: 5.555s
[2K
| Adam | epoch: 001 | loss: 0.68736 - acc: 0.5586 -- iter: 256/297
[A[ATraining Step: 9  | total loss: [1m[32m0.69995[0m[0m | time: 6.249s
[2K
| Adam | epoch: 001 | loss: 0.69995 - acc: 0.5110 -- iter: 288/297
[A[ATraining Step: 10  | total loss: [1m[32m0.69042[0m[0m | time: 7.520s
[2K
| Adam | epoch: 001 | loss: 0.69042 - acc: 0.5524 | val_loss: 0.68116 - val_acc: 0.6702 -- iter: 297/297
--
Training Step: 11  | total loss: [1m[32m0.69541[0m[0m | time: 0.234s
[2K
| Adam | epoch: 002 | loss: 0.69541 - acc: 0.5013 -- iter: 032/297
[A[ATraining Step: 12  | total loss: [1m[32m0.68867[0m[0m | time: 0.877s
[2K
| Adam | epoch: 002 | loss: 0.68867 - acc: 0.5757 -- iter: 064/297
[A[ATraining Step: 13  | total loss: [1m[32m0.69080[0m[0m | time: 1.546s
[2K
| Adam | epoch: 002 | loss: 0.69080 - acc: 0.5433 -- iter: 096/297
[A[ATraining Step: 14  | total loss: [1m[32m0.69183[0m[0m | time: 2.208s
[2K
| Adam | epoch: 002 | loss: 0.69183 - acc: 0.5256 -- iter: 128/297
[A[ATraining Step: 15  | total loss: [1m[32m0.69231[0m[0m | time: 2.873s
[2K
| Adam | epoch: 002 | loss: 0.69231 - acc: 0.5156 -- iter: 160/297
[A[ATraining Step: 16  | total loss: [1m[32m0.69329[0m[0m | time: 3.525s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4980 -- iter: 192/297
[A[ATraining Step: 17  | total loss: [1m[32m0.69272[0m[0m | time: 4.211s
[2K
| Adam | epoch: 002 | loss: 0.69272 - acc: 0.5100 -- iter: 224/297
[A[ATraining Step: 18  | total loss: [1m[32m0.69154[0m[0m | time: 4.893s
[2K
| Adam | epoch: 002 | loss: 0.69154 - acc: 0.5390 -- iter: 256/297
[A[ATraining Step: 19  | total loss: [1m[32m0.69079[0m[0m | time: 5.562s
[2K
| Adam | epoch: 002 | loss: 0.69079 - acc: 0.5572 -- iter: 288/297
[A[ATraining Step: 20  | total loss: [1m[32m0.68671[0m[0m | time: 7.262s
[2K
| Adam | epoch: 002 | loss: 0.68671 - acc: 0.6393 | val_loss: 0.67931 - val_acc: 0.6702 -- iter: 297/297
--
Training Step: 21  | total loss: [1m[32m0.68684[0m[0m | time: 0.238s
[2K
| Adam | epoch: 003 | loss: 0.68684 - acc: 0.6252 -- iter: 032/297
[A[ATraining Step: 22  | total loss: [1m[32m0.68448[0m[0m | time: 0.469s
[2K
| Adam | epoch: 003 | loss: 0.68448 - acc: 0.6376 -- iter: 064/297
[A[ATraining Step: 23  | total loss: [1m[32m0.69296[0m[0m | time: 1.151s
[2K
| Adam | epoch: 003 | loss: 0.69296 - acc: 0.5493 -- iter: 096/297
[A[ATraining Step: 24  | total loss: [1m[32m0.68960[0m[0m | time: 1.870s
[2K
| Adam | epoch: 003 | loss: 0.68960 - acc: 0.5618 -- iter: 128/297
[A[ATraining Step: 25  | total loss: [1m[32m0.68715[0m[0m | time: 2.600s
[2K
| Adam | epoch: 003 | loss: 0.68715 - acc: 0.5705 -- iter: 160/297
[A[ATraining Step: 26  | total loss: [1m[32m0.69172[0m[0m | time: 3.311s
[2K
| Adam | epoch: 003 | loss: 0.69172 - acc: 0.5353 -- iter: 192/297
[A[ATraining Step: 27  | total loss: [1m[32m0.69058[0m[0m | time: 3.998s
[2K
| Adam | epoch: 003 | loss: 0.69058 - acc: 0.5343 -- iter: 224/297
[A[ATraining Step: 28  | total loss: [1m[32m0.68848[0m[0m | time: 4.688s
[2K
| Adam | epoch: 003 | loss: 0.68848 - acc: 0.5413 -- iter: 256/297
[A[ATraining Step: 29  | total loss: [1m[32m0.68302[0m[0m | time: 5.369s
[2K
| Adam | epoch: 003 | loss: 0.68302 - acc: 0.5617 -- iter: 288/297
[A[ATraining Step: 30  | total loss: [1m[32m0.68014[0m[0m | time: 7.071s
[2K
| Adam | epoch: 003 | loss: 0.68014 - acc: 0.5693 | val_loss: 0.62047 - val_acc: 0.6702 -- iter: 297/297
--
Training Step: 31  | total loss: [1m[32m0.66837[0m[0m | time: 0.692s
[2K
| Adam | epoch: 004 | loss: 0.66837 - acc: 0.5966 -- iter: 032/297
[A[ATraining Step: 32  | total loss: [1m[32m0.67544[0m[0m | time: 0.920s
[2K
| Adam | epoch: 004 | loss: 0.67544 - acc: 0.5889 -- iter: 064/297
[A[ATraining Step: 33  | total loss: [1m[32m0.71077[0m[0m | time: 1.143s
[2K
| Adam | epoch: 004 | loss: 0.71077 - acc: 0.5328 -- iter: 096/297
[A[ATraining Step: 34  | total loss: [1m[32m0.72363[0m[0m | time: 1.811s
[2K
| Adam | epoch: 004 | loss: 0.72363 - acc: 0.4901 -- iter: 128/297
[A[ATraining Step: 35  | total loss: [1m[32m0.71121[0m[0m | time: 2.474s
[2K
| Adam | epoch: 004 | loss: 0.71121 - acc: 0.5183 -- iter: 160/297
[A[ATraining Step: 36  | total loss: [1m[32m0.70705[0m[0m | time: 3.110s
[2K
| Adam | epoch: 004 | loss: 0.70705 - acc: 0.5146 -- iter: 192/297
[A[ATraining Step: 37  | total loss: [1m[32m0.70226[0m[0m | time: 3.751s
[2K
| Adam | epoch: 004 | loss: 0.70226 - acc: 0.5304 -- iter: 224/297
[A[ATraining Step: 38  | total loss: [1m[32m0.70022[0m[0m | time: 4.402s
[2K
| Adam | epoch: 004 | loss: 0.70022 - acc: 0.5244 -- iter: 256/297
[A[ATraining Step: 39  | total loss: [1m[32m0.69718[0m[0m | time: 5.051s
[2K
| Adam | epoch: 004 | loss: 0.69718 - acc: 0.5437 -- iter: 288/297
[A[ATraining Step: 40  | total loss: [1m[32m0.69506[0m[0m | time: 6.744s
[2K
| Adam | epoch: 004 | loss: 0.69506 - acc: 0.5589 | val_loss: 0.68427 - val_acc: 0.6702 -- iter: 297/297
--
Training Step: 41  | total loss: [1m[32m0.69432[0m[0m | time: 0.667s
[2K
| Adam | epoch: 005 | loss: 0.69432 - acc: 0.5539 -- iter: 032/297
[A[ATraining Step: 42  | total loss: [1m[32m0.69263[0m[0m | time: 1.281s
[2K
| Adam | epoch: 005 | loss: 0.69263 - acc: 0.5723 -- iter: 064/297
[A[ATraining Step: 43  | total loss: [1m[32m0.69274[0m[0m | time: 1.503s
[2K
| Adam | epoch: 005 | loss: 0.69274 - acc: 0.5595 -- iter: 096/297
[A[ATraining Step: 44  | total loss: [1m[32m0.69338[0m[0m | time: 1.722s
[2K
| Adam | epoch: 005 | loss: 0.69338 - acc: 0.5396 -- iter: 128/297
[A[ATraining Step: 45  | total loss: [1m[32m0.69284[0m[0m | time: 2.360s
[2K
| Adam | epoch: 005 | loss: 0.69284 - acc: 0.5423 -- iter: 160/297
[A[ATraining Step: 46  | total loss: [1m[32m0.69238[0m[0m | time: 2.994s
[2K
| Adam | epoch: 005 | loss: 0.69238 - acc: 0.5457 -- iter: 192/297
[A[ATraining Step: 47  | total loss: [1m[32m0.69245[0m[0m | time: 3.686s
[2K
| Adam | epoch: 005 | loss: 0.69245 - acc: 0.5382 -- iter: 224/297
[A[ATraining Step: 48  | total loss: [1m[32m0.69041[0m[0m | time: 4.339s
[2K
| Adam | epoch: 005 | loss: 0.69041 - acc: 0.5722 -- iter: 256/297
[A[ATraining Step: 49  | total loss: [1m[32m0.69002[0m[0m | time: 4.972s
[2K
| Adam | epoch: 005 | loss: 0.69002 - acc: 0.5756 -- iter: 288/297
[A[ATraining Step: 50  | total loss: [1m[32m0.69144[0m[0m | time: 6.620s
[2K
| Adam | epoch: 005 | loss: 0.69144 - acc: 0.5494 | val_loss: 0.68159 - val_acc: 0.6702 -- iter: 297/297
--
Training Step: 51  | total loss: [1m[32m0.68983[0m[0m | time: 0.675s
[2K
| Adam | epoch: 006 | loss: 0.68983 - acc: 0.5704 -- iter: 032/297
[A[ATraining Step: 52  | total loss: [1m[32m0.69007[0m[0m | time: 1.354s
[2K
| Adam | epoch: 006 | loss: 0.69007 - acc: 0.5646 -- iter: 064/297
[A[ATraining Step: 53  | total loss: [1m[32m0.68849[0m[0m | time: 2.035s
[2K
| Adam | epoch: 006 | loss: 0.68849 - acc: 0.5827 -- iter: 096/297
[A[ATraining Step: 54  | total loss: [1m[32m0.69038[0m[0m | time: 2.252s
[2K
| Adam | epoch: 006 | loss: 0.69038 - acc: 0.5571 -- iter: 128/297
[A[ATraining Step: 55  | total loss: [1m[32m0.68990[0m[0m | time: 2.487s
[2K
| Adam | epoch: 006 | loss: 0.68990 - acc: 0.5569 -- iter: 160/297
[A[ATraining Step: 56  | total loss: [1m[32m0.69117[0m[0m | time: 3.142s
[2K
| Adam | epoch: 006 | loss: 0.69117 - acc: 0.5411 -- iter: 192/297
[A[ATraining Step: 57  | total loss: [1m[32m0.69104[0m[0m | time: 3.821s
[2K
| Adam | epoch: 006 | loss: 0.69104 - acc: 0.5397 -- iter: 224/297
[A[ATraining Step: 58  | total loss: [1m[32m0.69032[0m[0m | time: 4.454s
[2K
| Adam | epoch: 006 | loss: 0.69032 - acc: 0.5428 -- iter: 256/297
[A[ATraining Step: 59  | total loss: [1m[32m0.69073[0m[0m | time: 5.119s
[2K
| Adam | epoch: 006 | loss: 0.69073 - acc: 0.5329 -- iter: 288/297
[A[ATraining Step: 60  | total loss: [1m[32m0.68639[0m[0m | time: 6.781s
[2K
| Adam | epoch: 006 | loss: 0.68639 - acc: 0.5699 | val_loss: 0.66336 - val_acc: 0.6702 -- iter: 297/297
--
Training Step: 61  | total loss: [1m[32m0.68578[0m[0m | time: 0.661s
[2K
| Adam | epoch: 007 | loss: 0.68578 - acc: 0.5730 -- iter: 032/297
[A[ATraining Step: 62  | total loss: [1m[32m0.68850[0m[0m | time: 1.357s
[2K
| Adam | epoch: 007 | loss: 0.68850 - acc: 0.5515 -- iter: 064/297
[A[ATraining Step: 63  | total loss: [1m[32m0.68441[0m[0m | time: 2.047s
[2K
| Adam | epoch: 007 | loss: 0.68441 - acc: 0.5688 -- iter: 096/297
[A[ATraining Step: 64  | total loss: [1m[32m0.68439[0m[0m | time: 2.725s
[2K
| Adam | epoch: 007 | loss: 0.68439 - acc: 0.5641 -- iter: 128/297
[A[ATraining Step: 65  | total loss: [1m[32m0.68395[0m[0m | time: 2.941s
[2K
| Adam | epoch: 007 | loss: 0.68395 - acc: 0.5639 -- iter: 160/297
[A[ATraining Step: 66  | total loss: [1m[32m0.68923[0m[0m | time: 3.164s
[2K
| Adam | epoch: 007 | loss: 0.68923 - acc: 0.5494 -- iter: 192/297
[A[ATraining Step: 67  | total loss: [1m[32m0.68759[0m[0m | time: 3.855s
[2K
| Adam | epoch: 007 | loss: 0.68759 - acc: 0.5501 -- iter: 224/297
[A[ATraining Step: 68  | total loss: [1m[32m0.68252[0m[0m | time: 4.528s
[2K
| Adam | epoch: 007 | loss: 0.68252 - acc: 0.5590 -- iter: 256/297
[A[ATraining Step: 69  | total loss: [1m[32m0.67782[0m[0m | time: 5.187s
[2K
| Adam | epoch: 007 | loss: 0.67782 - acc: 0.5703 -- iter: 288/297
[A[ATraining Step: 70  | total loss: [1m[32m0.68263[0m[0m | time: 6.850s
[2K
| Adam | epoch: 007 | loss: 0.68263 - acc: 0.5550 | val_loss: 0.63249 - val_acc: 0.6702 -- iter: 297/297
--
Training Step: 71  | total loss: [1m[32m0.68524[0m[0m | time: 0.646s
[2K
| Adam | epoch: 008 | loss: 0.68524 - acc: 0.5416 -- iter: 032/297
[A[ATraining Step: 72  | total loss: [1m[32m0.67990[0m[0m | time: 1.296s
[2K
| Adam | epoch: 008 | loss: 0.67990 - acc: 0.5510 -- iter: 064/297
[A[ATraining Step: 73  | total loss: [1m[32m0.68014[0m[0m | time: 1.936s
[2K
| Adam | epoch: 008 | loss: 0.68014 - acc: 0.5453 -- iter: 096/297
[A[ATraining Step: 74  | total loss: [1m[32m0.67551[0m[0m | time: 2.590s
[2K
| Adam | epoch: 008 | loss: 0.67551 - acc: 0.5541 -- iter: 128/297
[A[ATraining Step: 75  | total loss: [1m[32m0.67228[0m[0m | time: 3.260s
[2K
| Adam | epoch: 008 | loss: 0.67228 - acc: 0.5550 -- iter: 160/297
[A[ATraining Step: 76  | total loss: [1m[32m0.66460[0m[0m | time: 3.498s
[2K
| Adam | epoch: 008 | loss: 0.66460 - acc: 0.5658 -- iter: 192/297
[A[ATraining Step: 77  | total loss: [1m[32m0.66211[0m[0m | time: 3.732s
[2K
| Adam | epoch: 008 | loss: 0.66211 - acc: 0.5648 -- iter: 224/297
[A[ATraining Step: 78  | total loss: [1m[32m0.64037[0m[0m | time: 4.379s
[2K
| Adam | epoch: 008 | loss: 0.64037 - acc: 0.5870 -- iter: 256/297
[A[ATraining Step: 79  | total loss: [1m[32m0.64266[0m[0m | time: 5.054s
[2K
| Adam | epoch: 008 | loss: 0.64266 - acc: 0.5877 -- iter: 288/297
[A[ATraining Step: 80  | total loss: [1m[32m0.63492[0m[0m | time: 6.692s
[2K
| Adam | epoch: 008 | loss: 0.63492 - acc: 0.5884 | val_loss: 0.62330 - val_acc: 0.7021 -- iter: 297/297
--
Training Step: 81  | total loss: [1m[32m0.63482[0m[0m | time: 0.660s
[2K
| Adam | epoch: 009 | loss: 0.63482 - acc: 0.6079 -- iter: 032/297
[A[ATraining Step: 82  | total loss: [1m[32m0.63249[0m[0m | time: 1.284s
[2K
| Adam | epoch: 009 | loss: 0.63249 - acc: 0.6283 -- iter: 064/297
[A[ATraining Step: 83  | total loss: [1m[32m0.62810[0m[0m | time: 1.927s
[2K
| Adam | epoch: 009 | loss: 0.62810 - acc: 0.6405 -- iter: 096/297
[A[ATraining Step: 84  | total loss: [1m[32m0.63743[0m[0m | time: 2.586s
[2K
| Adam | epoch: 009 | loss: 0.63743 - acc: 0.6358 -- iter: 128/297
[A[ATraining Step: 85  | total loss: [1m[32m0.63107[0m[0m | time: 3.223s
[2K
| Adam | epoch: 009 | loss: 0.63107 - acc: 0.6379 -- iter: 160/297
[A[ATraining Step: 86  | total loss: [1m[32m0.62650[0m[0m | time: 3.872s
[2K
| Adam | epoch: 009 | loss: 0.62650 - acc: 0.6491 -- iter: 192/297
[A[ATraining Step: 87  | total loss: [1m[32m0.62190[0m[0m | time: 4.083s
[2K
| Adam | epoch: 009 | loss: 0.62190 - acc: 0.6529 -- iter: 224/297
[A[ATraining Step: 88  | total loss: [1m[32m0.59050[0m[0m | time: 4.291s
[2K
| Adam | epoch: 009 | loss: 0.59050 - acc: 0.6654 -- iter: 256/297
[A[ATraining Step: 89  | total loss: [1m[32m0.58032[0m[0m | time: 4.944s
[2K
| Adam | epoch: 009 | loss: 0.58032 - acc: 0.6766 -- iter: 288/297
[A[ATraining Step: 90  | total loss: [1m[32m0.58083[0m[0m | time: 6.579s
[2K
| Adam | epoch: 009 | loss: 0.58083 - acc: 0.6809 | val_loss: 0.55028 - val_acc: 0.7447 -- iter: 297/297
--
Training Step: 91  | total loss: [1m[32m0.56530[0m[0m | time: 0.650s
[2K
| Adam | epoch: 010 | loss: 0.56530 - acc: 0.6909 -- iter: 032/297
[A[ATraining Step: 92  | total loss: [1m[32m0.55686[0m[0m | time: 1.285s
[2K
| Adam | epoch: 010 | loss: 0.55686 - acc: 0.7062 -- iter: 064/297
[A[ATraining Step: 93  | total loss: [1m[32m0.54981[0m[0m | time: 1.911s
[2K
| Adam | epoch: 010 | loss: 0.54981 - acc: 0.7199 -- iter: 096/297
[A[ATraining Step: 94  | total loss: [1m[32m0.53720[0m[0m | time: 2.565s
[2K
| Adam | epoch: 010 | loss: 0.53720 - acc: 0.7261 -- iter: 128/297
[A[ATraining Step: 95  | total loss: [1m[32m0.57867[0m[0m | time: 3.191s
[2K
| Adam | epoch: 010 | loss: 0.57867 - acc: 0.7097 -- iter: 160/297
[A[ATraining Step: 96  | total loss: [1m[32m0.56722[0m[0m | time: 3.814s
[2K
| Adam | epoch: 010 | loss: 0.56722 - acc: 0.7169 -- iter: 192/297
[A[ATraining Step: 97  | total loss: [1m[32m0.54934[0m[0m | time: 4.465s
[2K
| Adam | epoch: 010 | loss: 0.54934 - acc: 0.7358 -- iter: 224/297
[A[ATraining Step: 98  | total loss: [1m[32m0.54269[0m[0m | time: 4.691s
[2K
| Adam | epoch: 010 | loss: 0.54269 - acc: 0.7341 -- iter: 256/297
[A[ATraining Step: 99  | total loss: [1m[32m0.58751[0m[0m | time: 4.894s
[2K
| Adam | epoch: 010 | loss: 0.58751 - acc: 0.6940 -- iter: 288/297
[A[ATraining Step: 100  | total loss: [1m[32m0.58781[0m[0m | time: 6.547s
[2K
| Adam | epoch: 010 | loss: 0.58781 - acc: 0.6913 | val_loss: 0.47517 - val_acc: 0.7979 -- iter: 297/297
--
Training Step: 101  | total loss: [1m[32m0.57213[0m[0m | time: 0.652s
[2K
| Adam | epoch: 011 | loss: 0.57213 - acc: 0.7034 -- iter: 032/297
[A[ATraining Step: 102  | total loss: [1m[32m0.56453[0m[0m | time: 1.328s
[2K
| Adam | epoch: 011 | loss: 0.56453 - acc: 0.7112 -- iter: 064/297
[A[ATraining Step: 103  | total loss: [1m[32m0.60332[0m[0m | time: 1.996s
[2K
| Adam | epoch: 011 | loss: 0.60332 - acc: 0.6869 -- iter: 096/297
[A[ATraining Step: 104  | total loss: [1m[32m0.60733[0m[0m | time: 2.672s
[2K
| Adam | epoch: 011 | loss: 0.60733 - acc: 0.6745 -- iter: 128/297
[A[ATraining Step: 105  | total loss: [1m[32m0.59425[0m[0m | time: 3.345s
[2K
| Adam | epoch: 011 | loss: 0.59425 - acc: 0.6758 -- iter: 160/297
[A[ATraining Step: 106  | total loss: [1m[32m0.57821[0m[0m | time: 4.000s
[2K
| Adam | epoch: 011 | loss: 0.57821 - acc: 0.6957 -- iter: 192/297
[A[ATraining Step: 107  | total loss: [1m[32m0.57185[0m[0m | time: 4.653s
[2K
| Adam | epoch: 011 | loss: 0.57185 - acc: 0.7074 -- iter: 224/297
[A[ATraining Step: 108  | total loss: [1m[32m0.56023[0m[0m | time: 5.321s
[2K
| Adam | epoch: 011 | loss: 0.56023 - acc: 0.7179 -- iter: 256/297
[A[ATraining Step: 109  | total loss: [1m[32m0.55269[0m[0m | time: 5.567s
[2K
| Adam | epoch: 011 | loss: 0.55269 - acc: 0.7367 -- iter: 288/297
[A[ATraining Step: 110  | total loss: [1m[32m0.53927[0m[0m | time: 6.812s
[2K
| Adam | epoch: 011 | loss: 0.53927 - acc: 0.7520 | val_loss: 0.51999 - val_acc: 0.7872 -- iter: 297/297
--
Training Step: 111  | total loss: [1m[32m0.53544[0m[0m | time: 0.625s
[2K
| Adam | epoch: 012 | loss: 0.53544 - acc: 0.7657 -- iter: 032/297
[A[ATraining Step: 112  | total loss: [1m[32m0.51860[0m[0m | time: 1.248s
[2K
| Adam | epoch: 012 | loss: 0.51860 - acc: 0.7797 -- iter: 064/297
[A[ATraining Step: 113  | total loss: [1m[32m0.49679[0m[0m | time: 1.921s
[2K
| Adam | epoch: 012 | loss: 0.49679 - acc: 0.7924 -- iter: 096/297
[A[ATraining Step: 114  | total loss: [1m[32m0.48995[0m[0m | time: 2.564s
[2K
| Adam | epoch: 012 | loss: 0.48995 - acc: 0.7881 -- iter: 128/297
[A[ATraining Step: 115  | total loss: [1m[32m0.50591[0m[0m | time: 3.234s
[2K
| Adam | epoch: 012 | loss: 0.50591 - acc: 0.7812 -- iter: 160/297
[A[ATraining Step: 116  | total loss: [1m[32m0.47809[0m[0m | time: 3.915s
[2K
| Adam | epoch: 012 | loss: 0.47809 - acc: 0.7968 -- iter: 192/297
[A[ATraining Step: 117  | total loss: [1m[32m0.47661[0m[0m | time: 4.553s
[2K
| Adam | epoch: 012 | loss: 0.47661 - acc: 0.7953 -- iter: 224/297
[A[ATraining Step: 118  | total loss: [1m[32m0.46896[0m[0m | time: 5.205s
[2K
| Adam | epoch: 012 | loss: 0.46896 - acc: 0.8032 -- iter: 256/297
[A[ATraining Step: 119  | total loss: [1m[32m0.44631[0m[0m | time: 5.876s
[2K
| Adam | epoch: 012 | loss: 0.44631 - acc: 0.8104 -- iter: 288/297
[A[ATraining Step: 120  | total loss: [1m[32m0.43634[0m[0m | time: 7.121s
[2K
| Adam | epoch: 012 | loss: 0.43634 - acc: 0.8106 | val_loss: 0.44787 - val_acc: 0.7872 -- iter: 297/297
--
Training Step: 121  | total loss: [1m[32m0.43046[0m[0m | time: 0.229s
[2K
| Adam | epoch: 013 | loss: 0.43046 - acc: 0.8073 -- iter: 032/297
[A[ATraining Step: 122  | total loss: [1m[32m0.44238[0m[0m | time: 0.857s
[2K
| Adam | epoch: 013 | loss: 0.44238 - acc: 0.8044 -- iter: 064/297
[A[ATraining Step: 123  | total loss: [1m[32m0.41774[0m[0m | time: 1.496s
[2K
| Adam | epoch: 013 | loss: 0.41774 - acc: 0.8208 -- iter: 096/297
[A[ATraining Step: 124  | total loss: [1m[32m0.39774[0m[0m | time: 2.172s
[2K
| Adam | epoch: 013 | loss: 0.39774 - acc: 0.8325 -- iter: 128/297
[A[ATraining Step: 125  | total loss: [1m[32m0.37299[0m[0m | time: 2.810s
[2K
| Adam | epoch: 013 | loss: 0.37299 - acc: 0.8461 -- iter: 160/297
[A[ATraining Step: 126  | total loss: [1m[32m0.36338[0m[0m | time: 3.456s
[2K
| Adam | epoch: 013 | loss: 0.36338 - acc: 0.8459 -- iter: 192/297
[A[ATraining Step: 127  | total loss: [1m[32m0.35018[0m[0m | time: 4.109s
[2K
| Adam | epoch: 013 | loss: 0.35018 - acc: 0.8519 -- iter: 224/297
[A[ATraining Step: 128  | total loss: [1m[32m0.32895[0m[0m | time: 4.724s
[2K
| Adam | epoch: 013 | loss: 0.32895 - acc: 0.8636 -- iter: 256/297
[A[ATraining Step: 129  | total loss: [1m[32m0.34228[0m[0m | time: 5.362s
[2K
| Adam | epoch: 013 | loss: 0.34228 - acc: 0.8522 -- iter: 288/297
[A[ATraining Step: 130  | total loss: [1m[32m0.33277[0m[0m | time: 7.006s
[2K
| Adam | epoch: 013 | loss: 0.33277 - acc: 0.8545 | val_loss: 0.82436 - val_acc: 0.6170 -- iter: 297/297
--
Training Step: 131  | total loss: [1m[32m0.32103[0m[0m | time: 0.233s
[2K
| Adam | epoch: 014 | loss: 0.32103 - acc: 0.8628 -- iter: 032/297
[A[ATraining Step: 132  | total loss: [1m[32m0.32300[0m[0m | time: 0.449s
[2K
| Adam | epoch: 014 | loss: 0.32300 - acc: 0.8654 -- iter: 064/297
[A[ATraining Step: 133  | total loss: [1m[32m0.32605[0m[0m | time: 1.089s
[2K
| Adam | epoch: 014 | loss: 0.32605 - acc: 0.8567 -- iter: 096/297
[A[ATraining Step: 134  | total loss: [1m[32m0.30546[0m[0m | time: 1.777s
[2K
| Adam | epoch: 014 | loss: 0.30546 - acc: 0.8710 -- iter: 128/297
[A[ATraining Step: 135  | total loss: [1m[32m0.28739[0m[0m | time: 2.470s
[2K
| Adam | epoch: 014 | loss: 0.28739 - acc: 0.8808 -- iter: 160/297
[A[ATraining Step: 136  | total loss: [1m[32m0.26699[0m[0m | time: 3.119s
[2K
| Adam | epoch: 014 | loss: 0.26699 - acc: 0.8896 -- iter: 192/297
[A[ATraining Step: 137  | total loss: [1m[32m0.27493[0m[0m | time: 3.812s
[2K
| Adam | epoch: 014 | loss: 0.27493 - acc: 0.8850 -- iter: 224/297
[A[ATraining Step: 138  | total loss: [1m[32m0.25833[0m[0m | time: 4.454s
[2K
| Adam | epoch: 014 | loss: 0.25833 - acc: 0.8902 -- iter: 256/297
[A[ATraining Step: 139  | total loss: [1m[32m0.25286[0m[0m | time: 5.130s
[2K
| Adam | epoch: 014 | loss: 0.25286 - acc: 0.8918 -- iter: 288/297
[A[ATraining Step: 140  | total loss: [1m[32m0.25827[0m[0m | time: 6.811s
[2K
| Adam | epoch: 014 | loss: 0.25827 - acc: 0.8902 | val_loss: 0.52244 - val_acc: 0.8085 -- iter: 297/297
--
Training Step: 141  | total loss: [1m[32m0.24998[0m[0m | time: 0.677s
[2K
| Adam | epoch: 015 | loss: 0.24998 - acc: 0.8949 -- iter: 032/297
[A[ATraining Step: 142  | total loss: [1m[32m0.24370[0m[0m | time: 0.902s
[2K
| Adam | epoch: 015 | loss: 0.24370 - acc: 0.8960 -- iter: 064/297
[A[ATraining Step: 143  | total loss: [1m[32m0.24492[0m[0m | time: 1.132s
[2K
| Adam | epoch: 015 | loss: 0.24492 - acc: 0.8953 -- iter: 096/297
[A[ATraining Step: 144  | total loss: [1m[32m0.27215[0m[0m | time: 1.823s
[2K
| Adam | epoch: 015 | loss: 0.27215 - acc: 0.8947 -- iter: 128/297
[A[ATraining Step: 145  | total loss: [1m[32m0.25671[0m[0m | time: 2.470s
[2K
| Adam | epoch: 015 | loss: 0.25671 - acc: 0.9021 -- iter: 160/297
[A[ATraining Step: 146  | total loss: [1m[32m0.24012[0m[0m | time: 3.113s
[2K
| Adam | epoch: 015 | loss: 0.24012 - acc: 0.9119 -- iter: 192/297
[A[ATraining Step: 147  | total loss: [1m[32m0.23321[0m[0m | time: 3.788s
[2K
| Adam | epoch: 015 | loss: 0.23321 - acc: 0.9144 -- iter: 224/297
[A[ATraining Step: 148  | total loss: [1m[32m0.22934[0m[0m | time: 4.435s
[2K
| Adam | epoch: 015 | loss: 0.22934 - acc: 0.9136 -- iter: 256/297
[A[ATraining Step: 149  | total loss: [1m[32m0.21690[0m[0m | time: 5.149s
[2K
| Adam | epoch: 015 | loss: 0.21690 - acc: 0.9191 -- iter: 288/297
[A[ATraining Step: 150  | total loss: [1m[32m0.20432[0m[0m | time: 6.812s
[2K
| Adam | epoch: 015 | loss: 0.20432 - acc: 0.9272 | val_loss: 0.36739 - val_acc: 0.8617 -- iter: 297/297
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8914490527393752
Validation AUPRC:0.9302359914829199
Test AUC:0.9520581113801452
Test AUPRC:0.9542089593369312
BestTestF1Score	0.96	0.89	0.95	0.94	0.98	58	4	31	1	0.4
BestTestMCCScore	0.96	0.89	0.95	0.94	0.98	58	4	31	1	0.4
BestTestAccuracyScore	0.94	0.84	0.93	0.93	0.95	56	4	31	3	0.58
BestValidationF1Score	0.91	0.71	0.87	0.86	0.97	61	10	21	2	0.4
BestValidationMCC	0.91	0.71	0.87	0.86	0.97	61	10	21	2	0.4
BestValidationAccuracy	0.91	0.7	0.87	0.88	0.94	59	8	23	4	0.58
TestPredictions (Threshold:0.4)
CHEMBL310602,TP,ACT,0.949999988079071	CHEMBL86290,TP,ACT,0.8899999856948853	CHEMBL2114403,TP,ACT,0.9700000286102295	CHEMBL313198,TP,ACT,0.9700000286102295	CHEMBL501385,TN,INACT,0.019999999552965164	CHEMBL1934904,TN,INACT,0.03999999910593033	CHEMBL58315,FP,INACT,0.9399999976158142	CHEMBL63317,TP,ACT,0.8299999833106995	CHEMBL26814,TN,INACT,0.0	CHEMBL280203,TP,ACT,0.8500000238418579	CHEMBL2148012,TN,INACT,0.019999999552965164	CHEMBL315601,TP,ACT,0.9399999976158142	CHEMBL1159938,TP,ACT,0.9300000071525574	CHEMBL315255,TP,ACT,0.9200000166893005	CHEMBL314215,TP,ACT,0.8899999856948853	CHEMBL25341,TN,INACT,0.009999999776482582	CHEMBL1767029,TN,INACT,0.12999999523162842	CHEMBL3633449,TN,INACT,0.019999999552965164	CHEMBL1794011,TP,ACT,0.8899999856948853	CHEMBL2407720,TN,INACT,0.019999999552965164	CHEMBL83704,TP,ACT,0.949999988079071	CHEMBL108084,TN,INACT,0.019999999552965164	CHEMBL1651626,TN,INACT,0.18000000715255737	CHEMBL55583,TP,ACT,0.9599999785423279	CHEMBL1645621,TN,INACT,0.03999999910593033	CHEMBL3621760,TN,INACT,0.019999999552965164	CHEMBL1939276,TN,INACT,0.3499999940395355	CHEMBL47289,TP,ACT,0.7099999785423279	CHEMBL1934897,TN,INACT,0.009999999776482582	CHEMBL2372437,FN,ACT,0.38999998569488525	CHEMBL1159945,TP,ACT,0.9399999976158142	CHEMBL315037,TP,ACT,0.9800000190734863	CHEMBL356858,TP,ACT,0.8899999856948853	CHEMBL310199,TP,ACT,0.9700000286102295	CHEMBL1159925,TP,ACT,0.8600000143051147	CHEMBL2148015,TN,INACT,0.009999999776482582	CHEMBL1159942,TP,ACT,0.949999988079071	CHEMBL289518,TP,ACT,0.9399999976158142	CHEMBL421702,TP,ACT,0.9700000286102295	CHEMBL1171228,TN,INACT,0.029999999329447746	CHEMBL145,TN,INACT,0.009999999776482582	CHEMBL2024268,TN,INACT,0.009999999776482582	CHEMBL147285,TP,ACT,0.8799999952316284	CHEMBL1159922,TP,ACT,0.9700000286102295	CHEMBL2414741,TN,INACT,0.029999999329447746	CHEMBL3527525,TN,INACT,0.05999999865889549	CHEMBL314063,TP,ACT,0.9599999785423279	CHEMBL151631,TP,ACT,0.9100000262260437	CHEMBL290610,TP,ACT,0.9300000071525574	CHEMBL282158,TN,INACT,0.019999999552965164	CHEMBL20182,TP,ACT,0.7599999904632568	CHEMBL3605506,TN,INACT,0.05999999865889549	CHEMBL1159921,TP,ACT,0.949999988079071	CHEMBL37276,TP,ACT,0.9200000166893005	CHEMBL312653,TN,INACT,0.3799999952316284	CHEMBL148777,TP,ACT,0.550000011920929	CHEMBL285204,TP,ACT,0.9300000071525574	CHEMBL1159923,TP,ACT,0.9100000262260437	CHEMBL3221954,TN,INACT,0.30000001192092896	CHEMBL16779,TP,ACT,0.9399999976158142	CHEMBL1159917,TP,ACT,0.949999988079071	CHEMBL35643,TP,ACT,0.9800000190734863	CHEMBL2177696,TN,INACT,0.009999999776482582	CHEMBL316172,TP,ACT,0.5899999737739563	CHEMBL1934892,TN,INACT,0.009999999776482582	CHEMBL288814,TP,ACT,0.9300000071525574	CHEMBL1159950,TP,ACT,0.9300000071525574	CHEMBL2147953,TN,INACT,0.009999999776482582	CHEMBL3605493,TN,INACT,0.019999999552965164	CHEMBL2147945,FP,INACT,0.6899999976158142	CHEMBL295104,TP,ACT,0.8100000023841858	CHEMBL2147944,FP,INACT,0.7699999809265137	CHEMBL283315,TP,ACT,0.9200000166893005	CHEMBL367174,TP,ACT,0.9599999785423279	CHEMBL2159763,TN,INACT,0.009999999776482582	CHEMBL350633,TP,ACT,0.9700000286102295	CHEMBL53678,TP,ACT,0.9399999976158142	CHEMBL1907791,TP,ACT,0.7200000286102295	CHEMBL304939,TP,ACT,0.7599999904632568	CHEMBL2159635,TN,INACT,0.009999999776482582	CHEMBL20574,TP,ACT,0.9300000071525574	CHEMBL79592,TP,ACT,0.8700000047683716	CHEMBL418738,TP,ACT,0.9300000071525574	CHEMBL1159936,TP,ACT,0.9100000262260437	CHEMBL1934893,TN,INACT,0.029999999329447746	CHEMBL66967,TP,ACT,0.8399999737739563	CHEMBL19573,TP,ACT,0.75	CHEMBL2370089,FP,INACT,0.9700000286102295	CHEMBL86778,TP,ACT,0.9800000190734863	CHEMBL282664,TP,ACT,0.9800000190734863	CHEMBL283741,TP,ACT,0.7599999904632568	CHEMBL59762,TP,ACT,0.5600000023841858	CHEMBL310200,TP,ACT,0.9700000286102295	CHEMBL302837,TP,ACT,0.9800000190734863	

