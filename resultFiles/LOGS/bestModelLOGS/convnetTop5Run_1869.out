CNNModel CHEMBL3155 adam 0.0001 30 32 0 0.8 False True
Number of active compounds :	1593
Number of inactive compounds :	1593
---------------------------------
Run id: CNNModel_CHEMBL3155_adam_0.0001_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3155_adam_0.0001_30_32_0.8_True/
---------------------------------
Training samples: 2015
Validation samples: 630
--
Training Step: 1  | time: 0.780s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2015
[A[ATraining Step: 2  | total loss: [1m[32m0.62376[0m[0m | time: 1.366s
[2K
| Adam | epoch: 001 | loss: 0.62376 - acc: 0.5062 -- iter: 0064/2015
[A[ATraining Step: 3  | total loss: [1m[32m0.68044[0m[0m | time: 1.998s
[2K
| Adam | epoch: 001 | loss: 0.68044 - acc: 0.6034 -- iter: 0096/2015
[A[ATraining Step: 4  | total loss: [1m[32m0.68968[0m[0m | time: 2.610s
[2K
| Adam | epoch: 001 | loss: 0.68968 - acc: 0.5493 -- iter: 0128/2015
[A[ATraining Step: 5  | total loss: [1m[32m0.69160[0m[0m | time: 3.239s
[2K
| Adam | epoch: 001 | loss: 0.69160 - acc: 0.5801 -- iter: 0160/2015
[A[ATraining Step: 6  | total loss: [1m[32m0.69241[0m[0m | time: 3.876s
[2K
| Adam | epoch: 001 | loss: 0.69241 - acc: 0.5286 -- iter: 0192/2015
[A[ATraining Step: 7  | total loss: [1m[32m0.69411[0m[0m | time: 4.539s
[2K
| Adam | epoch: 001 | loss: 0.69411 - acc: 0.4364 -- iter: 0224/2015
[A[ATraining Step: 8  | total loss: [1m[32m0.69427[0m[0m | time: 5.150s
[2K
| Adam | epoch: 001 | loss: 0.69427 - acc: 0.4195 -- iter: 0256/2015
[A[ATraining Step: 9  | total loss: [1m[32m0.69377[0m[0m | time: 5.763s
[2K
| Adam | epoch: 001 | loss: 0.69377 - acc: 0.4621 -- iter: 0288/2015
[A[ATraining Step: 10  | total loss: [1m[32m0.69250[0m[0m | time: 6.380s
[2K
| Adam | epoch: 001 | loss: 0.69250 - acc: 0.5592 -- iter: 0320/2015
[A[ATraining Step: 11  | total loss: [1m[32m0.69222[0m[0m | time: 7.006s
[2K
| Adam | epoch: 001 | loss: 0.69222 - acc: 0.5904 -- iter: 0352/2015
[A[ATraining Step: 12  | total loss: [1m[32m0.69302[0m[0m | time: 7.654s
[2K
| Adam | epoch: 001 | loss: 0.69302 - acc: 0.5075 -- iter: 0384/2015
[A[ATraining Step: 13  | total loss: [1m[32m0.69312[0m[0m | time: 8.273s
[2K
| Adam | epoch: 001 | loss: 0.69312 - acc: 0.5043 -- iter: 0416/2015
[A[ATraining Step: 14  | total loss: [1m[32m0.69295[0m[0m | time: 8.882s
[2K
| Adam | epoch: 001 | loss: 0.69295 - acc: 0.5153 -- iter: 0448/2015
[A[ATraining Step: 15  | total loss: [1m[32m0.69321[0m[0m | time: 9.526s
[2K
| Adam | epoch: 001 | loss: 0.69321 - acc: 0.4849 -- iter: 0480/2015
[A[ATraining Step: 16  | total loss: [1m[32m0.69374[0m[0m | time: 10.148s
[2K
| Adam | epoch: 001 | loss: 0.69374 - acc: 0.4554 -- iter: 0512/2015
[A[ATraining Step: 17  | total loss: [1m[32m0.69372[0m[0m | time: 10.769s
[2K
| Adam | epoch: 001 | loss: 0.69372 - acc: 0.4489 -- iter: 0544/2015
[A[ATraining Step: 18  | total loss: [1m[32m0.69343[0m[0m | time: 11.381s
[2K
| Adam | epoch: 001 | loss: 0.69343 - acc: 0.4558 -- iter: 0576/2015
[A[ATraining Step: 19  | total loss: [1m[32m0.69322[0m[0m | time: 12.001s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.4914 -- iter: 0608/2015
[A[ATraining Step: 20  | total loss: [1m[32m0.69311[0m[0m | time: 12.600s
[2K
| Adam | epoch: 001 | loss: 0.69311 - acc: 0.5142 -- iter: 0640/2015
[A[ATraining Step: 21  | total loss: [1m[32m0.69301[0m[0m | time: 13.245s
[2K
| Adam | epoch: 001 | loss: 0.69301 - acc: 0.5486 -- iter: 0672/2015
[A[ATraining Step: 22  | total loss: [1m[32m0.69294[0m[0m | time: 13.861s
[2K
| Adam | epoch: 001 | loss: 0.69294 - acc: 0.5622 -- iter: 0704/2015
[A[ATraining Step: 23  | total loss: [1m[32m0.69311[0m[0m | time: 14.474s
[2K
| Adam | epoch: 001 | loss: 0.69311 - acc: 0.4987 -- iter: 0736/2015
[A[ATraining Step: 24  | total loss: [1m[32m0.69284[0m[0m | time: 15.115s
[2K
| Adam | epoch: 001 | loss: 0.69284 - acc: 0.5518 -- iter: 0768/2015
[A[ATraining Step: 25  | total loss: [1m[32m0.69283[0m[0m | time: 15.738s
[2K
| Adam | epoch: 001 | loss: 0.69283 - acc: 0.5292 -- iter: 0800/2015
[A[ATraining Step: 26  | total loss: [1m[32m0.69299[0m[0m | time: 16.357s
[2K
| Adam | epoch: 001 | loss: 0.69299 - acc: 0.5132 -- iter: 0832/2015
[A[ATraining Step: 27  | total loss: [1m[32m0.69281[0m[0m | time: 16.976s
[2K
| Adam | epoch: 001 | loss: 0.69281 - acc: 0.5178 -- iter: 0864/2015
[A[ATraining Step: 28  | total loss: [1m[32m0.69269[0m[0m | time: 17.583s
[2K
| Adam | epoch: 001 | loss: 0.69269 - acc: 0.5368 -- iter: 0896/2015
[A[ATraining Step: 29  | total loss: [1m[32m0.69286[0m[0m | time: 18.190s
[2K
| Adam | epoch: 001 | loss: 0.69286 - acc: 0.5279 -- iter: 0928/2015
[A[ATraining Step: 30  | total loss: [1m[32m0.69288[0m[0m | time: 18.794s
[2K
| Adam | epoch: 001 | loss: 0.69288 - acc: 0.5213 -- iter: 0960/2015
[A[ATraining Step: 31  | total loss: [1m[32m0.69244[0m[0m | time: 19.406s
[2K
| Adam | epoch: 001 | loss: 0.69244 - acc: 0.5380 -- iter: 0992/2015
[A[ATraining Step: 32  | total loss: [1m[32m0.69202[0m[0m | time: 20.030s
[2K
| Adam | epoch: 001 | loss: 0.69202 - acc: 0.5576 -- iter: 1024/2015
[A[ATraining Step: 33  | total loss: [1m[32m0.69207[0m[0m | time: 20.653s
[2K
| Adam | epoch: 001 | loss: 0.69207 - acc: 0.5449 -- iter: 1056/2015
[A[ATraining Step: 34  | total loss: [1m[32m0.69274[0m[0m | time: 21.263s
[2K
| Adam | epoch: 001 | loss: 0.69274 - acc: 0.5152 -- iter: 1088/2015
[A[ATraining Step: 35  | total loss: [1m[32m0.69252[0m[0m | time: 21.867s
[2K
| Adam | epoch: 001 | loss: 0.69252 - acc: 0.5186 -- iter: 1120/2015
[A[ATraining Step: 36  | total loss: [1m[32m0.69293[0m[0m | time: 22.501s
[2K
| Adam | epoch: 001 | loss: 0.69293 - acc: 0.5020 -- iter: 1152/2015
[A[ATraining Step: 37  | total loss: [1m[32m0.69299[0m[0m | time: 23.108s
[2K
| Adam | epoch: 001 | loss: 0.69299 - acc: 0.4953 -- iter: 1184/2015
[A[ATraining Step: 38  | total loss: [1m[32m0.69273[0m[0m | time: 23.758s
[2K
| Adam | epoch: 001 | loss: 0.69273 - acc: 0.5024 -- iter: 1216/2015
[A[ATraining Step: 39  | total loss: [1m[32m0.69232[0m[0m | time: 24.374s
[2K
| Adam | epoch: 001 | loss: 0.69232 - acc: 0.5139 -- iter: 1248/2015
[A[ATraining Step: 40  | total loss: [1m[32m0.69211[0m[0m | time: 24.987s
[2K
| Adam | epoch: 001 | loss: 0.69211 - acc: 0.5171 -- iter: 1280/2015
[A[ATraining Step: 41  | total loss: [1m[32m0.69192[0m[0m | time: 25.630s
[2K
| Adam | epoch: 001 | loss: 0.69192 - acc: 0.5255 -- iter: 1312/2015
[A[ATraining Step: 42  | total loss: [1m[32m0.69184[0m[0m | time: 26.239s
[2K
| Adam | epoch: 001 | loss: 0.69184 - acc: 0.5265 -- iter: 1344/2015
[A[ATraining Step: 43  | total loss: [1m[32m0.69219[0m[0m | time: 26.848s
[2K
| Adam | epoch: 001 | loss: 0.69219 - acc: 0.5108 -- iter: 1376/2015
[A[ATraining Step: 44  | total loss: [1m[32m0.69176[0m[0m | time: 27.483s
[2K
| Adam | epoch: 001 | loss: 0.69176 - acc: 0.5197 -- iter: 1408/2015
[A[ATraining Step: 45  | total loss: [1m[32m0.69179[0m[0m | time: 28.107s
[2K
| Adam | epoch: 001 | loss: 0.69179 - acc: 0.5164 -- iter: 1440/2015
[A[ATraining Step: 46  | total loss: [1m[32m0.69177[0m[0m | time: 28.728s
[2K
| Adam | epoch: 001 | loss: 0.69177 - acc: 0.5189 -- iter: 1472/2015
[A[ATraining Step: 47  | total loss: [1m[32m0.69138[0m[0m | time: 29.332s
[2K
| Adam | epoch: 001 | loss: 0.69138 - acc: 0.5209 -- iter: 1504/2015
[A[ATraining Step: 48  | total loss: [1m[32m0.69206[0m[0m | time: 29.942s
[2K
| Adam | epoch: 001 | loss: 0.69206 - acc: 0.5025 -- iter: 1536/2015
[A[ATraining Step: 49  | total loss: [1m[32m0.69213[0m[0m | time: 30.548s
[2K
| Adam | epoch: 001 | loss: 0.69213 - acc: 0.5021 -- iter: 1568/2015
[A[ATraining Step: 50  | total loss: [1m[32m0.69258[0m[0m | time: 31.153s
[2K
| Adam | epoch: 001 | loss: 0.69258 - acc: 0.4824 -- iter: 1600/2015
[A[ATraining Step: 51  | total loss: [1m[32m0.69160[0m[0m | time: 31.759s
[2K
| Adam | epoch: 001 | loss: 0.69160 - acc: 0.5137 -- iter: 1632/2015
[A[ATraining Step: 52  | total loss: [1m[32m0.69032[0m[0m | time: 32.363s
[2K
| Adam | epoch: 001 | loss: 0.69032 - acc: 0.5350 -- iter: 1664/2015
[A[ATraining Step: 53  | total loss: [1m[32m0.68992[0m[0m | time: 32.971s
[2K
| Adam | epoch: 001 | loss: 0.68992 - acc: 0.5391 -- iter: 1696/2015
[A[ATraining Step: 54  | total loss: [1m[32m0.69007[0m[0m | time: 33.592s
[2K
| Adam | epoch: 001 | loss: 0.69007 - acc: 0.5243 -- iter: 1728/2015
[A[ATraining Step: 55  | total loss: [1m[32m0.68887[0m[0m | time: 34.203s
[2K
| Adam | epoch: 001 | loss: 0.68887 - acc: 0.5477 -- iter: 1760/2015
[A[ATraining Step: 56  | total loss: [1m[32m0.69000[0m[0m | time: 34.788s
[2K
| Adam | epoch: 001 | loss: 0.69000 - acc: 0.5278 -- iter: 1792/2015
[A[ATraining Step: 57  | total loss: [1m[32m0.68725[0m[0m | time: 35.392s
[2K
| Adam | epoch: 001 | loss: 0.68725 - acc: 0.5585 -- iter: 1824/2015
[A[ATraining Step: 58  | total loss: [1m[32m0.68617[0m[0m | time: 35.989s
[2K
| Adam | epoch: 001 | loss: 0.68617 - acc: 0.5676 -- iter: 1856/2015
[A[ATraining Step: 59  | total loss: [1m[32m0.68592[0m[0m | time: 36.610s
[2K
| Adam | epoch: 001 | loss: 0.68592 - acc: 0.5669 -- iter: 1888/2015
[A[ATraining Step: 60  | total loss: [1m[32m0.68906[0m[0m | time: 37.214s
[2K
| Adam | epoch: 001 | loss: 0.68906 - acc: 0.5457 -- iter: 1920/2015
[A[ATraining Step: 61  | total loss: [1m[32m0.68768[0m[0m | time: 37.835s
[2K
| Adam | epoch: 001 | loss: 0.68768 - acc: 0.5519 -- iter: 1952/2015
[A[ATraining Step: 62  | total loss: [1m[32m0.68985[0m[0m | time: 38.443s
[2K
| Adam | epoch: 001 | loss: 0.68985 - acc: 0.5372 -- iter: 1984/2015
[A[ATraining Step: 63  | total loss: [1m[32m0.69196[0m[0m | time: 41.102s
[2K
| Adam | epoch: 001 | loss: 0.69196 - acc: 0.5206 | val_loss: 0.69219 - val_acc: 0.4921 -- iter: 2015/2015
--
Training Step: 64  | total loss: [1m[32m0.69103[0m[0m | time: 0.621s
[2K
| Adam | epoch: 002 | loss: 0.69103 - acc: 0.5241 -- iter: 0032/2015
[A[ATraining Step: 65  | total loss: [1m[32m0.69028[0m[0m | time: 1.233s
[2K
| Adam | epoch: 002 | loss: 0.69028 - acc: 0.5271 -- iter: 0064/2015
[A[ATraining Step: 66  | total loss: [1m[32m0.69373[0m[0m | time: 1.871s
[2K
| Adam | epoch: 002 | loss: 0.69373 - acc: 0.4934 -- iter: 0096/2015
[A[ATraining Step: 67  | total loss: [1m[32m0.69259[0m[0m | time: 2.521s
[2K
| Adam | epoch: 002 | loss: 0.69259 - acc: 0.5054 -- iter: 0128/2015
[A[ATraining Step: 68  | total loss: [1m[32m0.69122[0m[0m | time: 3.131s
[2K
| Adam | epoch: 002 | loss: 0.69122 - acc: 0.5122 -- iter: 0160/2015
[A[ATraining Step: 69  | total loss: [1m[32m0.69109[0m[0m | time: 3.744s
[2K
| Adam | epoch: 002 | loss: 0.69109 - acc: 0.5035 -- iter: 0192/2015
[A[ATraining Step: 70  | total loss: [1m[32m0.69089[0m[0m | time: 4.361s
[2K
| Adam | epoch: 002 | loss: 0.69089 - acc: 0.4995 -- iter: 0224/2015
[A[ATraining Step: 71  | total loss: [1m[32m0.69041[0m[0m | time: 4.976s
[2K
| Adam | epoch: 002 | loss: 0.69041 - acc: 0.5244 -- iter: 0256/2015
[A[ATraining Step: 72  | total loss: [1m[32m0.68961[0m[0m | time: 5.586s
[2K
| Adam | epoch: 002 | loss: 0.68961 - acc: 0.5463 -- iter: 0288/2015
[A[ATraining Step: 73  | total loss: [1m[32m0.68886[0m[0m | time: 6.209s
[2K
| Adam | epoch: 002 | loss: 0.68886 - acc: 0.5759 -- iter: 0320/2015
[A[ATraining Step: 74  | total loss: [1m[32m0.68828[0m[0m | time: 6.827s
[2K
| Adam | epoch: 002 | loss: 0.68828 - acc: 0.5950 -- iter: 0352/2015
[A[ATraining Step: 75  | total loss: [1m[32m0.68764[0m[0m | time: 7.438s
[2K
| Adam | epoch: 002 | loss: 0.68764 - acc: 0.6050 -- iter: 0384/2015
[A[ATraining Step: 76  | total loss: [1m[32m0.68723[0m[0m | time: 8.034s
[2K
| Adam | epoch: 002 | loss: 0.68723 - acc: 0.6172 -- iter: 0416/2015
[A[ATraining Step: 77  | total loss: [1m[32m0.68674[0m[0m | time: 8.645s
[2K
| Adam | epoch: 002 | loss: 0.68674 - acc: 0.6246 -- iter: 0448/2015
[A[ATraining Step: 78  | total loss: [1m[32m0.68669[0m[0m | time: 9.253s
[2K
| Adam | epoch: 002 | loss: 0.68669 - acc: 0.6214 -- iter: 0480/2015
[A[ATraining Step: 79  | total loss: [1m[32m0.68646[0m[0m | time: 9.865s
[2K
| Adam | epoch: 002 | loss: 0.68646 - acc: 0.6218 -- iter: 0512/2015
[A[ATraining Step: 80  | total loss: [1m[32m0.68631[0m[0m | time: 10.471s
[2K
| Adam | epoch: 002 | loss: 0.68631 - acc: 0.6221 -- iter: 0544/2015
[A[ATraining Step: 81  | total loss: [1m[32m0.68496[0m[0m | time: 11.087s
[2K
| Adam | epoch: 002 | loss: 0.68496 - acc: 0.6350 -- iter: 0576/2015
[A[ATraining Step: 82  | total loss: [1m[32m0.68375[0m[0m | time: 11.712s
[2K
| Adam | epoch: 002 | loss: 0.68375 - acc: 0.6403 -- iter: 0608/2015
[A[ATraining Step: 83  | total loss: [1m[32m0.68298[0m[0m | time: 12.313s
[2K
| Adam | epoch: 002 | loss: 0.68298 - acc: 0.6294 -- iter: 0640/2015
[A[ATraining Step: 84  | total loss: [1m[32m0.68310[0m[0m | time: 12.918s
[2K
| Adam | epoch: 002 | loss: 0.68310 - acc: 0.6164 -- iter: 0672/2015
[A[ATraining Step: 85  | total loss: [1m[32m0.68491[0m[0m | time: 13.526s
[2K
| Adam | epoch: 002 | loss: 0.68491 - acc: 0.5986 -- iter: 0704/2015
[A[ATraining Step: 86  | total loss: [1m[32m0.68265[0m[0m | time: 14.146s
[2K
| Adam | epoch: 002 | loss: 0.68265 - acc: 0.5981 -- iter: 0736/2015
[A[ATraining Step: 87  | total loss: [1m[32m0.68427[0m[0m | time: 14.757s
[2K
| Adam | epoch: 002 | loss: 0.68427 - acc: 0.5820 -- iter: 0768/2015
[A[ATraining Step: 88  | total loss: [1m[32m0.68543[0m[0m | time: 15.378s
[2K
| Adam | epoch: 002 | loss: 0.68543 - acc: 0.5707 -- iter: 0800/2015
[A[ATraining Step: 89  | total loss: [1m[32m0.68601[0m[0m | time: 15.984s
[2K
| Adam | epoch: 002 | loss: 0.68601 - acc: 0.5574 -- iter: 0832/2015
[A[ATraining Step: 90  | total loss: [1m[32m0.68672[0m[0m | time: 16.623s
[2K
| Adam | epoch: 002 | loss: 0.68672 - acc: 0.5579 -- iter: 0864/2015
[A[ATraining Step: 91  | total loss: [1m[32m0.68660[0m[0m | time: 17.226s
[2K
| Adam | epoch: 002 | loss: 0.68660 - acc: 0.5677 -- iter: 0896/2015
[A[ATraining Step: 92  | total loss: [1m[32m0.68551[0m[0m | time: 17.832s
[2K
| Adam | epoch: 002 | loss: 0.68551 - acc: 0.5703 -- iter: 0928/2015
[A[ATraining Step: 93  | total loss: [1m[32m0.68195[0m[0m | time: 18.441s
[2K
| Adam | epoch: 002 | loss: 0.68195 - acc: 0.5977 -- iter: 0960/2015
[A[ATraining Step: 94  | total loss: [1m[32m0.68050[0m[0m | time: 19.056s
[2K
| Adam | epoch: 002 | loss: 0.68050 - acc: 0.6098 -- iter: 0992/2015
[A[ATraining Step: 95  | total loss: [1m[32m0.67778[0m[0m | time: 19.664s
[2K
| Adam | epoch: 002 | loss: 0.67778 - acc: 0.6238 -- iter: 1024/2015
[A[ATraining Step: 96  | total loss: [1m[32m0.67848[0m[0m | time: 20.283s
[2K
| Adam | epoch: 002 | loss: 0.67848 - acc: 0.6145 -- iter: 1056/2015
[A[ATraining Step: 97  | total loss: [1m[32m0.67962[0m[0m | time: 20.886s
[2K
| Adam | epoch: 002 | loss: 0.67962 - acc: 0.6062 -- iter: 1088/2015
[A[ATraining Step: 98  | total loss: [1m[32m0.67999[0m[0m | time: 21.493s
[2K
| Adam | epoch: 002 | loss: 0.67999 - acc: 0.6050 -- iter: 1120/2015
[A[ATraining Step: 99  | total loss: [1m[32m0.67971[0m[0m | time: 22.098s
[2K
| Adam | epoch: 002 | loss: 0.67971 - acc: 0.6007 -- iter: 1152/2015
[A[ATraining Step: 100  | total loss: [1m[32m0.67842[0m[0m | time: 22.719s
[2K
| Adam | epoch: 002 | loss: 0.67842 - acc: 0.6031 -- iter: 1184/2015
[A[ATraining Step: 101  | total loss: [1m[32m0.67798[0m[0m | time: 23.354s
[2K
| Adam | epoch: 002 | loss: 0.67798 - acc: 0.5991 -- iter: 1216/2015
[A[ATraining Step: 102  | total loss: [1m[32m0.67729[0m[0m | time: 23.974s
[2K
| Adam | epoch: 002 | loss: 0.67729 - acc: 0.5985 -- iter: 1248/2015
[A[ATraining Step: 103  | total loss: [1m[32m0.67583[0m[0m | time: 24.604s
[2K
| Adam | epoch: 002 | loss: 0.67583 - acc: 0.5949 -- iter: 1280/2015
[A[ATraining Step: 104  | total loss: [1m[32m0.67668[0m[0m | time: 25.196s
[2K
| Adam | epoch: 002 | loss: 0.67668 - acc: 0.5855 -- iter: 1312/2015
[A[ATraining Step: 105  | total loss: [1m[32m0.67301[0m[0m | time: 25.799s
[2K
| Adam | epoch: 002 | loss: 0.67301 - acc: 0.5832 -- iter: 1344/2015
[A[ATraining Step: 106  | total loss: [1m[32m0.67603[0m[0m | time: 26.415s
[2K
| Adam | epoch: 002 | loss: 0.67603 - acc: 0.5686 -- iter: 1376/2015
[A[ATraining Step: 107  | total loss: [1m[32m0.67574[0m[0m | time: 27.030s
[2K
| Adam | epoch: 002 | loss: 0.67574 - acc: 0.5711 -- iter: 1408/2015
[A[ATraining Step: 108  | total loss: [1m[32m0.67407[0m[0m | time: 27.637s
[2K
| Adam | epoch: 002 | loss: 0.67407 - acc: 0.5827 -- iter: 1440/2015
[A[ATraining Step: 109  | total loss: [1m[32m0.66890[0m[0m | time: 28.280s
[2K
| Adam | epoch: 002 | loss: 0.66890 - acc: 0.6026 -- iter: 1472/2015
[A[ATraining Step: 110  | total loss: [1m[32m0.67005[0m[0m | time: 28.894s
[2K
| Adam | epoch: 002 | loss: 0.67005 - acc: 0.5986 -- iter: 1504/2015
[A[ATraining Step: 111  | total loss: [1m[32m0.66620[0m[0m | time: 29.515s
[2K
| Adam | epoch: 002 | loss: 0.66620 - acc: 0.6137 -- iter: 1536/2015
[A[ATraining Step: 112  | total loss: [1m[32m0.66675[0m[0m | time: 30.119s
[2K
| Adam | epoch: 002 | loss: 0.66675 - acc: 0.6055 -- iter: 1568/2015
[A[ATraining Step: 113  | total loss: [1m[32m0.66652[0m[0m | time: 30.740s
[2K
| Adam | epoch: 002 | loss: 0.66652 - acc: 0.6106 -- iter: 1600/2015
[A[ATraining Step: 114  | total loss: [1m[32m0.66398[0m[0m | time: 31.345s
[2K
| Adam | epoch: 002 | loss: 0.66398 - acc: 0.6183 -- iter: 1632/2015
[A[ATraining Step: 115  | total loss: [1m[32m0.66260[0m[0m | time: 31.952s
[2K
| Adam | epoch: 002 | loss: 0.66260 - acc: 0.6158 -- iter: 1664/2015
[A[ATraining Step: 116  | total loss: [1m[32m0.66048[0m[0m | time: 32.573s
[2K
| Adam | epoch: 002 | loss: 0.66048 - acc: 0.6230 -- iter: 1696/2015
[A[ATraining Step: 117  | total loss: [1m[32m0.65934[0m[0m | time: 33.190s
[2K
| Adam | epoch: 002 | loss: 0.65934 - acc: 0.6200 -- iter: 1728/2015
[A[ATraining Step: 118  | total loss: [1m[32m0.65316[0m[0m | time: 33.810s
[2K
| Adam | epoch: 002 | loss: 0.65316 - acc: 0.6362 -- iter: 1760/2015
[A[ATraining Step: 119  | total loss: [1m[32m0.65153[0m[0m | time: 34.425s
[2K
| Adam | epoch: 002 | loss: 0.65153 - acc: 0.6351 -- iter: 1792/2015
[A[ATraining Step: 120  | total loss: [1m[32m0.64984[0m[0m | time: 35.032s
[2K
| Adam | epoch: 002 | loss: 0.64984 - acc: 0.6434 -- iter: 1824/2015
[A[ATraining Step: 121  | total loss: [1m[32m0.64273[0m[0m | time: 35.620s
[2K
| Adam | epoch: 002 | loss: 0.64273 - acc: 0.6572 -- iter: 1856/2015
[A[ATraining Step: 122  | total loss: [1m[32m0.64741[0m[0m | time: 36.219s
[2K
| Adam | epoch: 002 | loss: 0.64741 - acc: 0.6509 -- iter: 1888/2015
[A[ATraining Step: 123  | total loss: [1m[32m0.64812[0m[0m | time: 36.834s
[2K
| Adam | epoch: 002 | loss: 0.64812 - acc: 0.6483 -- iter: 1920/2015
[A[ATraining Step: 124  | total loss: [1m[32m0.65456[0m[0m | time: 37.462s
[2K
| Adam | epoch: 002 | loss: 0.65456 - acc: 0.6334 -- iter: 1952/2015
[A[ATraining Step: 125  | total loss: [1m[32m0.65217[0m[0m | time: 38.068s
[2K
| Adam | epoch: 002 | loss: 0.65217 - acc: 0.6326 -- iter: 1984/2015
[A[ATraining Step: 126  | total loss: [1m[32m0.65422[0m[0m | time: 40.730s
[2K
| Adam | epoch: 002 | loss: 0.65422 - acc: 0.6412 | val_loss: 0.64537 - val_acc: 0.6492 -- iter: 2015/2015
--
Training Step: 127  | total loss: [1m[32m0.66464[0m[0m | time: 0.600s
[2K
| Adam | epoch: 003 | loss: 0.66464 - acc: 0.6271 -- iter: 0032/2015
[A[ATraining Step: 128  | total loss: [1m[32m0.65950[0m[0m | time: 1.191s
[2K
| Adam | epoch: 003 | loss: 0.65950 - acc: 0.6354 -- iter: 0064/2015
[A[ATraining Step: 129  | total loss: [1m[32m0.65461[0m[0m | time: 1.802s
[2K
| Adam | epoch: 003 | loss: 0.65461 - acc: 0.6460 -- iter: 0096/2015
[A[ATraining Step: 130  | total loss: [1m[32m0.64737[0m[0m | time: 2.403s
[2K
| Adam | epoch: 003 | loss: 0.64737 - acc: 0.6595 -- iter: 0128/2015
[A[ATraining Step: 131  | total loss: [1m[32m0.63933[0m[0m | time: 3.014s
[2K
| Adam | epoch: 003 | loss: 0.63933 - acc: 0.6686 -- iter: 0160/2015
[A[ATraining Step: 132  | total loss: [1m[32m0.62963[0m[0m | time: 3.622s
[2K
| Adam | epoch: 003 | loss: 0.62963 - acc: 0.6798 -- iter: 0192/2015
[A[ATraining Step: 133  | total loss: [1m[32m0.63259[0m[0m | time: 4.229s
[2K
| Adam | epoch: 003 | loss: 0.63259 - acc: 0.6712 -- iter: 0224/2015
[A[ATraining Step: 134  | total loss: [1m[32m0.63640[0m[0m | time: 4.828s
[2K
| Adam | epoch: 003 | loss: 0.63640 - acc: 0.6635 -- iter: 0256/2015
[A[ATraining Step: 135  | total loss: [1m[32m0.62963[0m[0m | time: 5.457s
[2K
| Adam | epoch: 003 | loss: 0.62963 - acc: 0.6721 -- iter: 0288/2015
[A[ATraining Step: 136  | total loss: [1m[32m0.63043[0m[0m | time: 6.068s
[2K
| Adam | epoch: 003 | loss: 0.63043 - acc: 0.6706 -- iter: 0320/2015
[A[ATraining Step: 137  | total loss: [1m[32m0.62499[0m[0m | time: 6.673s
[2K
| Adam | epoch: 003 | loss: 0.62499 - acc: 0.6754 -- iter: 0352/2015
[A[ATraining Step: 138  | total loss: [1m[32m0.62133[0m[0m | time: 7.276s
[2K
| Adam | epoch: 003 | loss: 0.62133 - acc: 0.6735 -- iter: 0384/2015
[A[ATraining Step: 139  | total loss: [1m[32m0.61654[0m[0m | time: 7.898s
[2K
| Adam | epoch: 003 | loss: 0.61654 - acc: 0.6749 -- iter: 0416/2015
[A[ATraining Step: 140  | total loss: [1m[32m0.60227[0m[0m | time: 8.506s
[2K
| Adam | epoch: 003 | loss: 0.60227 - acc: 0.6949 -- iter: 0448/2015
[A[ATraining Step: 141  | total loss: [1m[32m0.59567[0m[0m | time: 9.117s
[2K
| Adam | epoch: 003 | loss: 0.59567 - acc: 0.7035 -- iter: 0480/2015
[A[ATraining Step: 142  | total loss: [1m[32m0.60397[0m[0m | time: 9.724s
[2K
| Adam | epoch: 003 | loss: 0.60397 - acc: 0.7019 -- iter: 0512/2015
[A[ATraining Step: 143  | total loss: [1m[32m0.60311[0m[0m | time: 10.336s
[2K
| Adam | epoch: 003 | loss: 0.60311 - acc: 0.7005 -- iter: 0544/2015
[A[ATraining Step: 144  | total loss: [1m[32m0.59279[0m[0m | time: 10.952s
[2K
| Adam | epoch: 003 | loss: 0.59279 - acc: 0.7054 -- iter: 0576/2015
[A[ATraining Step: 145  | total loss: [1m[32m0.58720[0m[0m | time: 11.561s
[2K
| Adam | epoch: 003 | loss: 0.58720 - acc: 0.7193 -- iter: 0608/2015
[A[ATraining Step: 146  | total loss: [1m[32m0.58781[0m[0m | time: 12.154s
[2K
| Adam | epoch: 003 | loss: 0.58781 - acc: 0.7161 -- iter: 0640/2015
[A[ATraining Step: 147  | total loss: [1m[32m0.58681[0m[0m | time: 12.755s
[2K
| Adam | epoch: 003 | loss: 0.58681 - acc: 0.7132 -- iter: 0672/2015
[A[ATraining Step: 148  | total loss: [1m[32m0.60089[0m[0m | time: 13.355s
[2K
| Adam | epoch: 003 | loss: 0.60089 - acc: 0.7013 -- iter: 0704/2015
[A[ATraining Step: 149  | total loss: [1m[32m0.60494[0m[0m | time: 13.962s
[2K
| Adam | epoch: 003 | loss: 0.60494 - acc: 0.6999 -- iter: 0736/2015
[A[ATraining Step: 150  | total loss: [1m[32m0.59933[0m[0m | time: 14.595s
[2K
| Adam | epoch: 003 | loss: 0.59933 - acc: 0.7049 -- iter: 0768/2015
[A[ATraining Step: 151  | total loss: [1m[32m0.60242[0m[0m | time: 15.201s
[2K
| Adam | epoch: 003 | loss: 0.60242 - acc: 0.7032 -- iter: 0800/2015
[A[ATraining Step: 152  | total loss: [1m[32m0.60491[0m[0m | time: 15.803s
[2K
| Adam | epoch: 003 | loss: 0.60491 - acc: 0.6985 -- iter: 0832/2015
[A[ATraining Step: 153  | total loss: [1m[32m0.60106[0m[0m | time: 16.431s
[2K
| Adam | epoch: 003 | loss: 0.60106 - acc: 0.7036 -- iter: 0864/2015
[A[ATraining Step: 154  | total loss: [1m[32m0.59949[0m[0m | time: 17.054s
[2K
| Adam | epoch: 003 | loss: 0.59949 - acc: 0.7020 -- iter: 0896/2015
[A[ATraining Step: 155  | total loss: [1m[32m0.58582[0m[0m | time: 17.664s
[2K
| Adam | epoch: 003 | loss: 0.58582 - acc: 0.7193 -- iter: 0928/2015
[A[ATraining Step: 156  | total loss: [1m[32m0.58526[0m[0m | time: 18.282s
[2K
| Adam | epoch: 003 | loss: 0.58526 - acc: 0.7161 -- iter: 0960/2015
[A[ATraining Step: 157  | total loss: [1m[32m0.58592[0m[0m | time: 18.890s
[2K
| Adam | epoch: 003 | loss: 0.58592 - acc: 0.7164 -- iter: 0992/2015
[A[ATraining Step: 158  | total loss: [1m[32m0.57308[0m[0m | time: 19.488s
[2K
| Adam | epoch: 003 | loss: 0.57308 - acc: 0.7229 -- iter: 1024/2015
[A[ATraining Step: 159  | total loss: [1m[32m0.57192[0m[0m | time: 20.118s
[2K
| Adam | epoch: 003 | loss: 0.57192 - acc: 0.7131 -- iter: 1056/2015
[A[ATraining Step: 160  | total loss: [1m[32m0.57915[0m[0m | time: 20.731s
[2K
| Adam | epoch: 003 | loss: 0.57915 - acc: 0.7012 -- iter: 1088/2015
[A[ATraining Step: 161  | total loss: [1m[32m0.58179[0m[0m | time: 21.340s
[2K
| Adam | epoch: 003 | loss: 0.58179 - acc: 0.6998 -- iter: 1120/2015
[A[ATraining Step: 162  | total loss: [1m[32m0.59821[0m[0m | time: 21.975s
[2K
| Adam | epoch: 003 | loss: 0.59821 - acc: 0.6892 -- iter: 1152/2015
[A[ATraining Step: 163  | total loss: [1m[32m0.60227[0m[0m | time: 22.581s
[2K
| Adam | epoch: 003 | loss: 0.60227 - acc: 0.6890 -- iter: 1184/2015
[A[ATraining Step: 164  | total loss: [1m[32m0.59475[0m[0m | time: 23.188s
[2K
| Adam | epoch: 003 | loss: 0.59475 - acc: 0.6920 -- iter: 1216/2015
[A[ATraining Step: 165  | total loss: [1m[32m0.58796[0m[0m | time: 23.792s
[2K
| Adam | epoch: 003 | loss: 0.58796 - acc: 0.6978 -- iter: 1248/2015
[A[ATraining Step: 166  | total loss: [1m[32m0.57986[0m[0m | time: 24.404s
[2K
| Adam | epoch: 003 | loss: 0.57986 - acc: 0.7061 -- iter: 1280/2015
[A[ATraining Step: 167  | total loss: [1m[32m0.57229[0m[0m | time: 25.011s
[2K
| Adam | epoch: 003 | loss: 0.57229 - acc: 0.7168 -- iter: 1312/2015
[A[ATraining Step: 168  | total loss: [1m[32m0.57703[0m[0m | time: 25.626s
[2K
| Adam | epoch: 003 | loss: 0.57703 - acc: 0.7076 -- iter: 1344/2015
[A[ATraining Step: 169  | total loss: [1m[32m0.57471[0m[0m | time: 26.234s
[2K
| Adam | epoch: 003 | loss: 0.57471 - acc: 0.7150 -- iter: 1376/2015
[A[ATraining Step: 170  | total loss: [1m[32m0.58063[0m[0m | time: 26.849s
[2K
| Adam | epoch: 003 | loss: 0.58063 - acc: 0.7028 -- iter: 1408/2015
[A[ATraining Step: 171  | total loss: [1m[32m0.57562[0m[0m | time: 27.450s
[2K
| Adam | epoch: 003 | loss: 0.57562 - acc: 0.7044 -- iter: 1440/2015
[A[ATraining Step: 172  | total loss: [1m[32m0.56299[0m[0m | time: 28.050s
[2K
| Adam | epoch: 003 | loss: 0.56299 - acc: 0.7152 -- iter: 1472/2015
[A[ATraining Step: 173  | total loss: [1m[32m0.56278[0m[0m | time: 28.655s
[2K
| Adam | epoch: 003 | loss: 0.56278 - acc: 0.7156 -- iter: 1504/2015
[A[ATraining Step: 174  | total loss: [1m[32m0.56605[0m[0m | time: 29.271s
[2K
| Adam | epoch: 003 | loss: 0.56605 - acc: 0.7097 -- iter: 1536/2015
[A[ATraining Step: 175  | total loss: [1m[32m0.57287[0m[0m | time: 29.878s
[2K
| Adam | epoch: 003 | loss: 0.57287 - acc: 0.7012 -- iter: 1568/2015
[A[ATraining Step: 176  | total loss: [1m[32m0.57665[0m[0m | time: 30.484s
[2K
| Adam | epoch: 003 | loss: 0.57665 - acc: 0.6967 -- iter: 1600/2015
[A[ATraining Step: 177  | total loss: [1m[32m0.58092[0m[0m | time: 31.091s
[2K
| Adam | epoch: 003 | loss: 0.58092 - acc: 0.6958 -- iter: 1632/2015
[A[ATraining Step: 178  | total loss: [1m[32m0.57841[0m[0m | time: 31.701s
[2K
| Adam | epoch: 003 | loss: 0.57841 - acc: 0.6981 -- iter: 1664/2015
[A[ATraining Step: 179  | total loss: [1m[32m0.57205[0m[0m | time: 32.310s
[2K
| Adam | epoch: 003 | loss: 0.57205 - acc: 0.6970 -- iter: 1696/2015
[A[ATraining Step: 180  | total loss: [1m[32m0.57652[0m[0m | time: 32.903s
[2K
| Adam | epoch: 003 | loss: 0.57652 - acc: 0.6961 -- iter: 1728/2015
[A[ATraining Step: 181  | total loss: [1m[32m0.57523[0m[0m | time: 33.510s
[2K
| Adam | epoch: 003 | loss: 0.57523 - acc: 0.7108 -- iter: 1760/2015
[A[ATraining Step: 182  | total loss: [1m[32m0.57376[0m[0m | time: 34.120s
[2K
| Adam | epoch: 003 | loss: 0.57376 - acc: 0.7179 -- iter: 1792/2015
[A[ATraining Step: 183  | total loss: [1m[32m0.57943[0m[0m | time: 34.711s
[2K
| Adam | epoch: 003 | loss: 0.57943 - acc: 0.7180 -- iter: 1824/2015
[A[ATraining Step: 184  | total loss: [1m[32m0.58265[0m[0m | time: 35.324s
[2K
| Adam | epoch: 003 | loss: 0.58265 - acc: 0.7149 -- iter: 1856/2015
[A[ATraining Step: 185  | total loss: [1m[32m0.57023[0m[0m | time: 35.929s
[2K
| Adam | epoch: 003 | loss: 0.57023 - acc: 0.7278 -- iter: 1888/2015
[A[ATraining Step: 186  | total loss: [1m[32m0.57223[0m[0m | time: 36.531s
[2K
| Adam | epoch: 003 | loss: 0.57223 - acc: 0.7238 -- iter: 1920/2015
[A[ATraining Step: 187  | total loss: [1m[32m0.56819[0m[0m | time: 37.166s
[2K
| Adam | epoch: 003 | loss: 0.56819 - acc: 0.7233 -- iter: 1952/2015
[A[ATraining Step: 188  | total loss: [1m[32m0.56992[0m[0m | time: 37.770s
[2K
| Adam | epoch: 003 | loss: 0.56992 - acc: 0.7134 -- iter: 1984/2015
[A[ATraining Step: 189  | total loss: [1m[32m0.58509[0m[0m | time: 40.436s
[2K
| Adam | epoch: 003 | loss: 0.58509 - acc: 0.6983 | val_loss: 0.59684 - val_acc: 0.7016 -- iter: 2015/2015
--
Training Step: 190  | total loss: [1m[32m0.57839[0m[0m | time: 0.606s
[2K
| Adam | epoch: 004 | loss: 0.57839 - acc: 0.7035 -- iter: 0032/2015
[A[ATraining Step: 191  | total loss: [1m[32m0.58021[0m[0m | time: 1.185s
[2K
| Adam | epoch: 004 | loss: 0.58021 - acc: 0.7050 -- iter: 0064/2015
[A[ATraining Step: 192  | total loss: [1m[32m0.57441[0m[0m | time: 1.771s
[2K
| Adam | epoch: 004 | loss: 0.57441 - acc: 0.7120 -- iter: 0096/2015
[A[ATraining Step: 193  | total loss: [1m[32m0.56903[0m[0m | time: 2.371s
[2K
| Adam | epoch: 004 | loss: 0.56903 - acc: 0.7117 -- iter: 0128/2015
[A[ATraining Step: 194  | total loss: [1m[32m0.55756[0m[0m | time: 2.996s
[2K
| Adam | epoch: 004 | loss: 0.55756 - acc: 0.7281 -- iter: 0160/2015
[A[ATraining Step: 195  | total loss: [1m[32m0.57494[0m[0m | time: 3.626s
[2K
| Adam | epoch: 004 | loss: 0.57494 - acc: 0.7177 -- iter: 0192/2015
[A[ATraining Step: 196  | total loss: [1m[32m0.56891[0m[0m | time: 4.216s
[2K
| Adam | epoch: 004 | loss: 0.56891 - acc: 0.7178 -- iter: 0224/2015
[A[ATraining Step: 197  | total loss: [1m[32m0.56975[0m[0m | time: 4.820s
[2K
| Adam | epoch: 004 | loss: 0.56975 - acc: 0.7148 -- iter: 0256/2015
[A[ATraining Step: 198  | total loss: [1m[32m0.55977[0m[0m | time: 5.423s
[2K
| Adam | epoch: 004 | loss: 0.55977 - acc: 0.7246 -- iter: 0288/2015
[A[ATraining Step: 199  | total loss: [1m[32m0.56766[0m[0m | time: 6.037s
[2K
| Adam | epoch: 004 | loss: 0.56766 - acc: 0.7146 -- iter: 0320/2015
[A[ATraining Step: 200  | total loss: [1m[32m0.57106[0m[0m | time: 8.627s
[2K
| Adam | epoch: 004 | loss: 0.57106 - acc: 0.7119 | val_loss: 0.60107 - val_acc: 0.6619 -- iter: 0352/2015
--
Training Step: 201  | total loss: [1m[32m0.56962[0m[0m | time: 9.226s
[2K
| Adam | epoch: 004 | loss: 0.56962 - acc: 0.7063 -- iter: 0384/2015
[A[ATraining Step: 202  | total loss: [1m[32m0.57188[0m[0m | time: 9.825s
[2K
| Adam | epoch: 004 | loss: 0.57188 - acc: 0.7045 -- iter: 0416/2015
[A[ATraining Step: 203  | total loss: [1m[32m0.57283[0m[0m | time: 10.444s
[2K
| Adam | epoch: 004 | loss: 0.57283 - acc: 0.7028 -- iter: 0448/2015
[A[ATraining Step: 204  | total loss: [1m[32m0.58617[0m[0m | time: 11.046s
[2K
| Adam | epoch: 004 | loss: 0.58617 - acc: 0.6887 -- iter: 0480/2015
[A[ATraining Step: 205  | total loss: [1m[32m0.57937[0m[0m | time: 11.639s
[2K
| Adam | epoch: 004 | loss: 0.57937 - acc: 0.6917 -- iter: 0512/2015
[A[ATraining Step: 206  | total loss: [1m[32m0.58095[0m[0m | time: 12.248s
[2K
| Adam | epoch: 004 | loss: 0.58095 - acc: 0.6913 -- iter: 0544/2015
[A[ATraining Step: 207  | total loss: [1m[32m0.57407[0m[0m | time: 12.844s
[2K
| Adam | epoch: 004 | loss: 0.57407 - acc: 0.6972 -- iter: 0576/2015
[A[ATraining Step: 208  | total loss: [1m[32m0.57581[0m[0m | time: 13.443s
[2K
| Adam | epoch: 004 | loss: 0.57581 - acc: 0.6962 -- iter: 0608/2015
[A[ATraining Step: 209  | total loss: [1m[32m0.57108[0m[0m | time: 14.049s
[2K
| Adam | epoch: 004 | loss: 0.57108 - acc: 0.6985 -- iter: 0640/2015
[A[ATraining Step: 210  | total loss: [1m[32m0.58622[0m[0m | time: 14.644s
[2K
| Adam | epoch: 004 | loss: 0.58622 - acc: 0.6817 -- iter: 0672/2015
[A[ATraining Step: 211  | total loss: [1m[32m0.58660[0m[0m | time: 15.253s
[2K
| Adam | epoch: 004 | loss: 0.58660 - acc: 0.6792 -- iter: 0704/2015
[A[ATraining Step: 212  | total loss: [1m[32m0.59557[0m[0m | time: 15.874s
[2K
| Adam | epoch: 004 | loss: 0.59557 - acc: 0.6644 -- iter: 0736/2015
[A[ATraining Step: 213  | total loss: [1m[32m0.60352[0m[0m | time: 16.477s
[2K
| Adam | epoch: 004 | loss: 0.60352 - acc: 0.6667 -- iter: 0768/2015
[A[ATraining Step: 214  | total loss: [1m[32m0.60954[0m[0m | time: 17.080s
[2K
| Adam | epoch: 004 | loss: 0.60954 - acc: 0.6625 -- iter: 0800/2015
[A[ATraining Step: 215  | total loss: [1m[32m0.61734[0m[0m | time: 17.684s
[2K
| Adam | epoch: 004 | loss: 0.61734 - acc: 0.6619 -- iter: 0832/2015
[A[ATraining Step: 216  | total loss: [1m[32m0.59801[0m[0m | time: 18.294s
[2K
| Adam | epoch: 004 | loss: 0.59801 - acc: 0.6832 -- iter: 0864/2015
[A[ATraining Step: 217  | total loss: [1m[32m0.59245[0m[0m | time: 18.892s
[2K
| Adam | epoch: 004 | loss: 0.59245 - acc: 0.6836 -- iter: 0896/2015
[A[ATraining Step: 218  | total loss: [1m[32m0.59588[0m[0m | time: 19.503s
[2K
| Adam | epoch: 004 | loss: 0.59588 - acc: 0.6840 -- iter: 0928/2015
[A[ATraining Step: 219  | total loss: [1m[32m0.58824[0m[0m | time: 20.101s
[2K
| Adam | epoch: 004 | loss: 0.58824 - acc: 0.6938 -- iter: 0960/2015
[A[ATraining Step: 220  | total loss: [1m[32m0.58667[0m[0m | time: 20.699s
[2K
| Adam | epoch: 004 | loss: 0.58667 - acc: 0.6963 -- iter: 0992/2015
[A[ATraining Step: 221  | total loss: [1m[32m0.58008[0m[0m | time: 21.327s
[2K
| Adam | epoch: 004 | loss: 0.58008 - acc: 0.7016 -- iter: 1024/2015
[A[ATraining Step: 222  | total loss: [1m[32m0.58047[0m[0m | time: 21.937s
[2K
| Adam | epoch: 004 | loss: 0.58047 - acc: 0.7002 -- iter: 1056/2015
[A[ATraining Step: 223  | total loss: [1m[32m0.58639[0m[0m | time: 22.556s
[2K
| Adam | epoch: 004 | loss: 0.58639 - acc: 0.6989 -- iter: 1088/2015
[A[ATraining Step: 224  | total loss: [1m[32m0.58268[0m[0m | time: 23.179s
[2K
| Adam | epoch: 004 | loss: 0.58268 - acc: 0.7009 -- iter: 1120/2015
[A[ATraining Step: 225  | total loss: [1m[32m0.57298[0m[0m | time: 23.791s
[2K
| Adam | epoch: 004 | loss: 0.57298 - acc: 0.7121 -- iter: 1152/2015
[A[ATraining Step: 226  | total loss: [1m[32m0.57890[0m[0m | time: 24.398s
[2K
| Adam | epoch: 004 | loss: 0.57890 - acc: 0.7096 -- iter: 1184/2015
[A[ATraining Step: 227  | total loss: [1m[32m0.56381[0m[0m | time: 25.001s
[2K
| Adam | epoch: 004 | loss: 0.56381 - acc: 0.7230 -- iter: 1216/2015
[A[ATraining Step: 228  | total loss: [1m[32m0.55454[0m[0m | time: 25.599s
[2K
| Adam | epoch: 004 | loss: 0.55454 - acc: 0.7320 -- iter: 1248/2015
[A[ATraining Step: 229  | total loss: [1m[32m0.56269[0m[0m | time: 26.206s
[2K
| Adam | epoch: 004 | loss: 0.56269 - acc: 0.7275 -- iter: 1280/2015
[A[ATraining Step: 230  | total loss: [1m[32m0.56044[0m[0m | time: 26.810s
[2K
| Adam | epoch: 004 | loss: 0.56044 - acc: 0.7298 -- iter: 1312/2015
[A[ATraining Step: 231  | total loss: [1m[32m0.56025[0m[0m | time: 27.413s
[2K
| Adam | epoch: 004 | loss: 0.56025 - acc: 0.7318 -- iter: 1344/2015
[A[ATraining Step: 232  | total loss: [1m[32m0.56588[0m[0m | time: 28.024s
[2K
| Adam | epoch: 004 | loss: 0.56588 - acc: 0.7242 -- iter: 1376/2015
[A[ATraining Step: 233  | total loss: [1m[32m0.57117[0m[0m | time: 28.647s
[2K
| Adam | epoch: 004 | loss: 0.57117 - acc: 0.7174 -- iter: 1408/2015
[A[ATraining Step: 234  | total loss: [1m[32m0.56790[0m[0m | time: 29.268s
[2K
| Adam | epoch: 004 | loss: 0.56790 - acc: 0.7113 -- iter: 1440/2015
[A[ATraining Step: 235  | total loss: [1m[32m0.57176[0m[0m | time: 29.865s
[2K
| Adam | epoch: 004 | loss: 0.57176 - acc: 0.6964 -- iter: 1472/2015
[A[ATraining Step: 236  | total loss: [1m[32m0.57150[0m[0m | time: 30.477s
[2K
| Adam | epoch: 004 | loss: 0.57150 - acc: 0.6893 -- iter: 1504/2015
[A[ATraining Step: 237  | total loss: [1m[32m0.56537[0m[0m | time: 31.102s
[2K
| Adam | epoch: 004 | loss: 0.56537 - acc: 0.6985 -- iter: 1536/2015
[A[ATraining Step: 238  | total loss: [1m[32m0.57296[0m[0m | time: 31.706s
[2K
| Adam | epoch: 004 | loss: 0.57296 - acc: 0.6911 -- iter: 1568/2015
[A[ATraining Step: 239  | total loss: [1m[32m0.56997[0m[0m | time: 32.333s
[2K
| Adam | epoch: 004 | loss: 0.56997 - acc: 0.7033 -- iter: 1600/2015
[A[ATraining Step: 240  | total loss: [1m[32m0.57190[0m[0m | time: 32.919s
[2K
| Adam | epoch: 004 | loss: 0.57190 - acc: 0.7048 -- iter: 1632/2015
[A[ATraining Step: 241  | total loss: [1m[32m0.56572[0m[0m | time: 33.523s
[2K
| Adam | epoch: 004 | loss: 0.56572 - acc: 0.7125 -- iter: 1664/2015
[A[ATraining Step: 242  | total loss: [1m[32m0.55935[0m[0m | time: 34.137s
[2K
| Adam | epoch: 004 | loss: 0.55935 - acc: 0.7256 -- iter: 1696/2015
[A[ATraining Step: 243  | total loss: [1m[32m0.56243[0m[0m | time: 34.744s
[2K
| Adam | epoch: 004 | loss: 0.56243 - acc: 0.7280 -- iter: 1728/2015
[A[ATraining Step: 244  | total loss: [1m[32m0.55942[0m[0m | time: 35.347s
[2K
| Adam | epoch: 004 | loss: 0.55942 - acc: 0.7302 -- iter: 1760/2015
[A[ATraining Step: 245  | total loss: [1m[32m0.55619[0m[0m | time: 35.957s
[2K
| Adam | epoch: 004 | loss: 0.55619 - acc: 0.7385 -- iter: 1792/2015
[A[ATraining Step: 246  | total loss: [1m[32m0.55629[0m[0m | time: 36.570s
[2K
| Adam | epoch: 004 | loss: 0.55629 - acc: 0.7396 -- iter: 1824/2015
[A[ATraining Step: 247  | total loss: [1m[32m0.55736[0m[0m | time: 37.184s
[2K
| Adam | epoch: 004 | loss: 0.55736 - acc: 0.7407 -- iter: 1856/2015
[A[ATraining Step: 248  | total loss: [1m[32m0.56356[0m[0m | time: 37.800s
[2K
| Adam | epoch: 004 | loss: 0.56356 - acc: 0.7291 -- iter: 1888/2015
[A[ATraining Step: 249  | total loss: [1m[32m0.56295[0m[0m | time: 38.404s
[2K
| Adam | epoch: 004 | loss: 0.56295 - acc: 0.7249 -- iter: 1920/2015
[A[ATraining Step: 250  | total loss: [1m[32m0.56152[0m[0m | time: 39.002s
[2K
| Adam | epoch: 004 | loss: 0.56152 - acc: 0.7243 -- iter: 1952/2015
[A[ATraining Step: 251  | total loss: [1m[32m0.57387[0m[0m | time: 39.598s
[2K
| Adam | epoch: 004 | loss: 0.57387 - acc: 0.7144 -- iter: 1984/2015
[A[ATraining Step: 252  | total loss: [1m[32m0.56372[0m[0m | time: 42.200s
[2K
| Adam | epoch: 004 | loss: 0.56372 - acc: 0.7242 | val_loss: 0.55278 - val_acc: 0.7159 -- iter: 2015/2015
--
Training Step: 253  | total loss: [1m[32m0.56654[0m[0m | time: 0.603s
[2K
| Adam | epoch: 005 | loss: 0.56654 - acc: 0.7236 -- iter: 0032/2015
[A[ATraining Step: 254  | total loss: [1m[32m0.55883[0m[0m | time: 1.204s
[2K
| Adam | epoch: 005 | loss: 0.55883 - acc: 0.7325 -- iter: 0064/2015
[A[ATraining Step: 255  | total loss: [1m[32m0.55515[0m[0m | time: 1.791s
[2K
| Adam | epoch: 005 | loss: 0.55515 - acc: 0.7374 -- iter: 0096/2015
[A[ATraining Step: 256  | total loss: [1m[32m0.55330[0m[0m | time: 2.398s
[2K
| Adam | epoch: 005 | loss: 0.55330 - acc: 0.7411 -- iter: 0128/2015
[A[ATraining Step: 257  | total loss: [1m[32m0.55217[0m[0m | time: 2.998s
[2K
| Adam | epoch: 005 | loss: 0.55217 - acc: 0.7444 -- iter: 0160/2015
[A[ATraining Step: 258  | total loss: [1m[32m0.54878[0m[0m | time: 3.619s
[2K
| Adam | epoch: 005 | loss: 0.54878 - acc: 0.7418 -- iter: 0192/2015
[A[ATraining Step: 259  | total loss: [1m[32m0.55754[0m[0m | time: 4.227s
[2K
| Adam | epoch: 005 | loss: 0.55754 - acc: 0.7270 -- iter: 0224/2015
[A[ATraining Step: 260  | total loss: [1m[32m0.55281[0m[0m | time: 4.844s
[2K
| Adam | epoch: 005 | loss: 0.55281 - acc: 0.7293 -- iter: 0256/2015
[A[ATraining Step: 261  | total loss: [1m[32m0.56347[0m[0m | time: 5.453s
[2K
| Adam | epoch: 005 | loss: 0.56347 - acc: 0.7189 -- iter: 0288/2015
[A[ATraining Step: 262  | total loss: [1m[32m0.55874[0m[0m | time: 6.053s
[2K
| Adam | epoch: 005 | loss: 0.55874 - acc: 0.7282 -- iter: 0320/2015
[A[ATraining Step: 263  | total loss: [1m[32m0.56090[0m[0m | time: 6.689s
[2K
| Adam | epoch: 005 | loss: 0.56090 - acc: 0.7242 -- iter: 0352/2015
[A[ATraining Step: 264  | total loss: [1m[32m0.56190[0m[0m | time: 7.305s
[2K
| Adam | epoch: 005 | loss: 0.56190 - acc: 0.7205 -- iter: 0384/2015
[A[ATraining Step: 265  | total loss: [1m[32m0.55366[0m[0m | time: 7.936s
[2K
| Adam | epoch: 005 | loss: 0.55366 - acc: 0.7235 -- iter: 0416/2015
[A[ATraining Step: 266  | total loss: [1m[32m0.54955[0m[0m | time: 8.534s
[2K
| Adam | epoch: 005 | loss: 0.54955 - acc: 0.7230 -- iter: 0448/2015
[A[ATraining Step: 267  | total loss: [1m[32m0.55125[0m[0m | time: 9.166s
[2K
| Adam | epoch: 005 | loss: 0.55125 - acc: 0.7226 -- iter: 0480/2015
[A[ATraining Step: 268  | total loss: [1m[32m0.54658[0m[0m | time: 9.784s
[2K
| Adam | epoch: 005 | loss: 0.54658 - acc: 0.7316 -- iter: 0512/2015
[A[ATraining Step: 269  | total loss: [1m[32m0.55843[0m[0m | time: 10.385s
[2K
| Adam | epoch: 005 | loss: 0.55843 - acc: 0.7178 -- iter: 0544/2015
[A[ATraining Step: 270  | total loss: [1m[32m0.55568[0m[0m | time: 10.985s
[2K
| Adam | epoch: 005 | loss: 0.55568 - acc: 0.7210 -- iter: 0576/2015
[A[ATraining Step: 271  | total loss: [1m[32m0.55717[0m[0m | time: 11.594s
[2K
| Adam | epoch: 005 | loss: 0.55717 - acc: 0.7270 -- iter: 0608/2015
[A[ATraining Step: 272  | total loss: [1m[32m0.54380[0m[0m | time: 12.213s
[2K
| Adam | epoch: 005 | loss: 0.54380 - acc: 0.7324 -- iter: 0640/2015
[A[ATraining Step: 273  | total loss: [1m[32m0.54180[0m[0m | time: 12.810s
[2K
| Adam | epoch: 005 | loss: 0.54180 - acc: 0.7405 -- iter: 0672/2015
[A[ATraining Step: 274  | total loss: [1m[32m0.54308[0m[0m | time: 13.430s
[2K
| Adam | epoch: 005 | loss: 0.54308 - acc: 0.7414 -- iter: 0704/2015
[A[ATraining Step: 275  | total loss: [1m[32m0.53935[0m[0m | time: 14.035s
[2K
| Adam | epoch: 005 | loss: 0.53935 - acc: 0.7454 -- iter: 0736/2015
[A[ATraining Step: 276  | total loss: [1m[32m0.54302[0m[0m | time: 14.688s
[2K
| Adam | epoch: 005 | loss: 0.54302 - acc: 0.7396 -- iter: 0768/2015
[A[ATraining Step: 277  | total loss: [1m[32m0.53594[0m[0m | time: 15.312s
[2K
| Adam | epoch: 005 | loss: 0.53594 - acc: 0.7438 -- iter: 0800/2015
[A[ATraining Step: 278  | total loss: [1m[32m0.53306[0m[0m | time: 15.924s
[2K
| Adam | epoch: 005 | loss: 0.53306 - acc: 0.7413 -- iter: 0832/2015
[A[ATraining Step: 279  | total loss: [1m[32m0.53122[0m[0m | time: 16.541s
[2K
| Adam | epoch: 005 | loss: 0.53122 - acc: 0.7453 -- iter: 0864/2015
[A[ATraining Step: 280  | total loss: [1m[32m0.52206[0m[0m | time: 17.160s
[2K
| Adam | epoch: 005 | loss: 0.52206 - acc: 0.7520 -- iter: 0896/2015
[A[ATraining Step: 281  | total loss: [1m[32m0.51353[0m[0m | time: 17.772s
[2K
| Adam | epoch: 005 | loss: 0.51353 - acc: 0.7612 -- iter: 0928/2015
[A[ATraining Step: 282  | total loss: [1m[32m0.51027[0m[0m | time: 18.374s
[2K
| Adam | epoch: 005 | loss: 0.51027 - acc: 0.7600 -- iter: 0960/2015
[A[ATraining Step: 283  | total loss: [1m[32m0.50765[0m[0m | time: 18.989s
[2K
| Adam | epoch: 005 | loss: 0.50765 - acc: 0.7590 -- iter: 0992/2015
[A[ATraining Step: 284  | total loss: [1m[32m0.50172[0m[0m | time: 19.602s
[2K
| Adam | epoch: 005 | loss: 0.50172 - acc: 0.7644 -- iter: 1024/2015
[A[ATraining Step: 285  | total loss: [1m[32m0.50647[0m[0m | time: 20.197s
[2K
| Adam | epoch: 005 | loss: 0.50647 - acc: 0.7536 -- iter: 1056/2015
[A[ATraining Step: 286  | total loss: [1m[32m0.50199[0m[0m | time: 20.804s
[2K
| Adam | epoch: 005 | loss: 0.50199 - acc: 0.7532 -- iter: 1088/2015
[A[ATraining Step: 287  | total loss: [1m[32m0.50235[0m[0m | time: 21.408s
[2K
| Adam | epoch: 005 | loss: 0.50235 - acc: 0.7529 -- iter: 1120/2015
[A[ATraining Step: 288  | total loss: [1m[32m0.51047[0m[0m | time: 22.012s
[2K
| Adam | epoch: 005 | loss: 0.51047 - acc: 0.7526 -- iter: 1152/2015
[A[ATraining Step: 289  | total loss: [1m[32m0.51346[0m[0m | time: 22.610s
[2K
| Adam | epoch: 005 | loss: 0.51346 - acc: 0.7523 -- iter: 1184/2015
[A[ATraining Step: 290  | total loss: [1m[32m0.49959[0m[0m | time: 23.223s
[2K
| Adam | epoch: 005 | loss: 0.49959 - acc: 0.7646 -- iter: 1216/2015
[A[ATraining Step: 291  | total loss: [1m[32m0.48753[0m[0m | time: 23.818s
[2K
| Adam | epoch: 005 | loss: 0.48753 - acc: 0.7756 -- iter: 1248/2015
[A[ATraining Step: 292  | total loss: [1m[32m0.47661[0m[0m | time: 24.443s
[2K
| Adam | epoch: 005 | loss: 0.47661 - acc: 0.7887 -- iter: 1280/2015
[A[ATraining Step: 293  | total loss: [1m[32m0.47724[0m[0m | time: 25.048s
[2K
| Adam | epoch: 005 | loss: 0.47724 - acc: 0.7911 -- iter: 1312/2015
[A[ATraining Step: 294  | total loss: [1m[32m0.49433[0m[0m | time: 25.654s
[2K
| Adam | epoch: 005 | loss: 0.49433 - acc: 0.7776 -- iter: 1344/2015
[A[ATraining Step: 295  | total loss: [1m[32m0.49956[0m[0m | time: 26.261s
[2K
| Adam | epoch: 005 | loss: 0.49956 - acc: 0.7780 -- iter: 1376/2015
[A[ATraining Step: 296  | total loss: [1m[32m0.50490[0m[0m | time: 26.847s
[2K
| Adam | epoch: 005 | loss: 0.50490 - acc: 0.7720 -- iter: 1408/2015
[A[ATraining Step: 297  | total loss: [1m[32m0.49899[0m[0m | time: 27.499s
[2K
| Adam | epoch: 005 | loss: 0.49899 - acc: 0.7698 -- iter: 1440/2015
[A[ATraining Step: 298  | total loss: [1m[32m0.50107[0m[0m | time: 28.094s
[2K
| Adam | epoch: 005 | loss: 0.50107 - acc: 0.7647 -- iter: 1472/2015
[A[ATraining Step: 299  | total loss: [1m[32m0.49139[0m[0m | time: 28.712s
[2K
| Adam | epoch: 005 | loss: 0.49139 - acc: 0.7726 -- iter: 1504/2015
[A[ATraining Step: 300  | total loss: [1m[32m0.48889[0m[0m | time: 29.334s
[2K
| Adam | epoch: 005 | loss: 0.48889 - acc: 0.7735 -- iter: 1536/2015
[A[ATraining Step: 301  | total loss: [1m[32m0.48261[0m[0m | time: 29.945s
[2K
| Adam | epoch: 005 | loss: 0.48261 - acc: 0.7805 -- iter: 1568/2015
[A[ATraining Step: 302  | total loss: [1m[32m0.49837[0m[0m | time: 30.551s
[2K
| Adam | epoch: 005 | loss: 0.49837 - acc: 0.7681 -- iter: 1600/2015
[A[ATraining Step: 303  | total loss: [1m[32m0.49657[0m[0m | time: 31.158s
[2K
| Adam | epoch: 005 | loss: 0.49657 - acc: 0.7632 -- iter: 1632/2015
[A[ATraining Step: 304  | total loss: [1m[32m0.50184[0m[0m | time: 31.767s
[2K
| Adam | epoch: 005 | loss: 0.50184 - acc: 0.7618 -- iter: 1664/2015
[A[ATraining Step: 305  | total loss: [1m[32m0.49771[0m[0m | time: 32.366s
[2K
| Adam | epoch: 005 | loss: 0.49771 - acc: 0.7607 -- iter: 1696/2015
[A[ATraining Step: 306  | total loss: [1m[32m0.48347[0m[0m | time: 32.949s
[2K
| Adam | epoch: 005 | loss: 0.48347 - acc: 0.7752 -- iter: 1728/2015
[A[ATraining Step: 307  | total loss: [1m[32m0.49223[0m[0m | time: 33.544s
[2K
| Adam | epoch: 005 | loss: 0.49223 - acc: 0.7664 -- iter: 1760/2015
[A[ATraining Step: 308  | total loss: [1m[32m0.49898[0m[0m | time: 34.143s
[2K
| Adam | epoch: 005 | loss: 0.49898 - acc: 0.7679 -- iter: 1792/2015
[A[ATraining Step: 309  | total loss: [1m[32m0.51574[0m[0m | time: 34.741s
[2K
| Adam | epoch: 005 | loss: 0.51574 - acc: 0.7536 -- iter: 1824/2015
[A[ATraining Step: 310  | total loss: [1m[32m0.52098[0m[0m | time: 35.336s
[2K
| Adam | epoch: 005 | loss: 0.52098 - acc: 0.7439 -- iter: 1856/2015
[A[ATraining Step: 311  | total loss: [1m[32m0.51214[0m[0m | time: 35.947s
[2K
| Adam | epoch: 005 | loss: 0.51214 - acc: 0.7539 -- iter: 1888/2015
[A[ATraining Step: 312  | total loss: [1m[32m0.51617[0m[0m | time: 36.560s
[2K
| Adam | epoch: 005 | loss: 0.51617 - acc: 0.7472 -- iter: 1920/2015
[A[ATraining Step: 313  | total loss: [1m[32m0.51877[0m[0m | time: 37.162s
[2K
| Adam | epoch: 005 | loss: 0.51877 - acc: 0.7444 -- iter: 1952/2015
[A[ATraining Step: 314  | total loss: [1m[32m0.51895[0m[0m | time: 37.782s
[2K
| Adam | epoch: 005 | loss: 0.51895 - acc: 0.7481 -- iter: 1984/2015
[A[ATraining Step: 315  | total loss: [1m[32m0.54226[0m[0m | time: 40.376s
[2K
| Adam | epoch: 005 | loss: 0.54226 - acc: 0.7233 | val_loss: 0.52515 - val_acc: 0.7270 -- iter: 2015/2015
--
Training Step: 316  | total loss: [1m[32m0.53014[0m[0m | time: 0.622s
[2K
| Adam | epoch: 006 | loss: 0.53014 - acc: 0.7291 -- iter: 0032/2015
[A[ATraining Step: 317  | total loss: [1m[32m0.53732[0m[0m | time: 1.235s
[2K
| Adam | epoch: 006 | loss: 0.53732 - acc: 0.7218 -- iter: 0064/2015
[A[ATraining Step: 318  | total loss: [1m[32m0.52883[0m[0m | time: 1.847s
[2K
| Adam | epoch: 006 | loss: 0.52883 - acc: 0.7277 -- iter: 0096/2015
[A[ATraining Step: 319  | total loss: [1m[32m0.51716[0m[0m | time: 2.495s
[2K
| Adam | epoch: 006 | loss: 0.51716 - acc: 0.7362 -- iter: 0128/2015
[A[ATraining Step: 320  | total loss: [1m[32m0.51241[0m[0m | time: 3.074s
[2K
| Adam | epoch: 006 | loss: 0.51241 - acc: 0.7368 -- iter: 0160/2015
[A[ATraining Step: 321  | total loss: [1m[32m0.50815[0m[0m | time: 3.685s
[2K
| Adam | epoch: 006 | loss: 0.50815 - acc: 0.7373 -- iter: 0192/2015
[A[ATraining Step: 322  | total loss: [1m[32m0.51076[0m[0m | time: 4.301s
[2K
| Adam | epoch: 006 | loss: 0.51076 - acc: 0.7448 -- iter: 0224/2015
[A[ATraining Step: 323  | total loss: [1m[32m0.50706[0m[0m | time: 4.897s
[2K
| Adam | epoch: 006 | loss: 0.50706 - acc: 0.7485 -- iter: 0256/2015
[A[ATraining Step: 324  | total loss: [1m[32m0.50064[0m[0m | time: 5.486s
[2K
| Adam | epoch: 006 | loss: 0.50064 - acc: 0.7517 -- iter: 0288/2015
[A[ATraining Step: 325  | total loss: [1m[32m0.49841[0m[0m | time: 6.107s
[2K
| Adam | epoch: 006 | loss: 0.49841 - acc: 0.7547 -- iter: 0320/2015
[A[ATraining Step: 326  | total loss: [1m[32m0.49999[0m[0m | time: 6.736s
[2K
| Adam | epoch: 006 | loss: 0.49999 - acc: 0.7542 -- iter: 0352/2015
[A[ATraining Step: 327  | total loss: [1m[32m0.49738[0m[0m | time: 7.340s
[2K
| Adam | epoch: 006 | loss: 0.49738 - acc: 0.7538 -- iter: 0384/2015
[A[ATraining Step: 328  | total loss: [1m[32m0.50541[0m[0m | time: 7.943s
[2K
| Adam | epoch: 006 | loss: 0.50541 - acc: 0.7440 -- iter: 0416/2015
[A[ATraining Step: 329  | total loss: [1m[32m0.50545[0m[0m | time: 8.551s
[2K
| Adam | epoch: 006 | loss: 0.50545 - acc: 0.7478 -- iter: 0448/2015
[A[ATraining Step: 330  | total loss: [1m[32m0.49674[0m[0m | time: 9.156s
[2K
| Adam | epoch: 006 | loss: 0.49674 - acc: 0.7605 -- iter: 0480/2015
[A[ATraining Step: 331  | total loss: [1m[32m0.50159[0m[0m | time: 9.781s
[2K
| Adam | epoch: 006 | loss: 0.50159 - acc: 0.7563 -- iter: 0512/2015
[A[ATraining Step: 332  | total loss: [1m[32m0.51552[0m[0m | time: 10.384s
[2K
| Adam | epoch: 006 | loss: 0.51552 - acc: 0.7463 -- iter: 0544/2015
[A[ATraining Step: 333  | total loss: [1m[32m0.50616[0m[0m | time: 10.978s
[2K
| Adam | epoch: 006 | loss: 0.50616 - acc: 0.7529 -- iter: 0576/2015
[A[ATraining Step: 334  | total loss: [1m[32m0.50428[0m[0m | time: 11.585s
[2K
| Adam | epoch: 006 | loss: 0.50428 - acc: 0.7526 -- iter: 0608/2015
[A[ATraining Step: 335  | total loss: [1m[32m0.50548[0m[0m | time: 12.191s
[2K
| Adam | epoch: 006 | loss: 0.50548 - acc: 0.7524 -- iter: 0640/2015
[A[ATraining Step: 336  | total loss: [1m[32m0.49601[0m[0m | time: 12.811s
[2K
| Adam | epoch: 006 | loss: 0.49601 - acc: 0.7615 -- iter: 0672/2015
[A[ATraining Step: 337  | total loss: [1m[32m0.50480[0m[0m | time: 13.425s
[2K
| Adam | epoch: 006 | loss: 0.50480 - acc: 0.7572 -- iter: 0704/2015
[A[ATraining Step: 338  | total loss: [1m[32m0.50265[0m[0m | time: 14.047s
[2K
| Adam | epoch: 006 | loss: 0.50265 - acc: 0.7596 -- iter: 0736/2015
[A[ATraining Step: 339  | total loss: [1m[32m0.49717[0m[0m | time: 14.629s
[2K
| Adam | epoch: 006 | loss: 0.49717 - acc: 0.7555 -- iter: 0768/2015
[A[ATraining Step: 340  | total loss: [1m[32m0.48938[0m[0m | time: 15.234s
[2K
| Adam | epoch: 006 | loss: 0.48938 - acc: 0.7675 -- iter: 0800/2015
[A[ATraining Step: 341  | total loss: [1m[32m0.49319[0m[0m | time: 15.848s
[2K
| Adam | epoch: 006 | loss: 0.49319 - acc: 0.7626 -- iter: 0832/2015
[A[ATraining Step: 342  | total loss: [1m[32m0.49354[0m[0m | time: 16.478s
[2K
| Adam | epoch: 006 | loss: 0.49354 - acc: 0.7645 -- iter: 0864/2015
[A[ATraining Step: 343  | total loss: [1m[32m0.50877[0m[0m | time: 17.099s
[2K
| Adam | epoch: 006 | loss: 0.50877 - acc: 0.7537 -- iter: 0896/2015
[A[ATraining Step: 344  | total loss: [1m[32m0.51311[0m[0m | time: 17.694s
[2K
| Adam | epoch: 006 | loss: 0.51311 - acc: 0.7470 -- iter: 0928/2015
[A[ATraining Step: 345  | total loss: [1m[32m0.50922[0m[0m | time: 18.298s
[2K
| Adam | epoch: 006 | loss: 0.50922 - acc: 0.7536 -- iter: 0960/2015
[A[ATraining Step: 346  | total loss: [1m[32m0.50695[0m[0m | time: 18.895s
[2K
| Adam | epoch: 006 | loss: 0.50695 - acc: 0.7501 -- iter: 0992/2015
[A[ATraining Step: 347  | total loss: [1m[32m0.49577[0m[0m | time: 19.493s
[2K
| Adam | epoch: 006 | loss: 0.49577 - acc: 0.7595 -- iter: 1024/2015
[A[ATraining Step: 348  | total loss: [1m[32m0.50241[0m[0m | time: 20.084s
[2K
| Adam | epoch: 006 | loss: 0.50241 - acc: 0.7523 -- iter: 1056/2015
[A[ATraining Step: 349  | total loss: [1m[32m0.48840[0m[0m | time: 20.687s
[2K
| Adam | epoch: 006 | loss: 0.48840 - acc: 0.7645 -- iter: 1088/2015
[A[ATraining Step: 350  | total loss: [1m[32m0.49303[0m[0m | time: 21.288s
[2K
| Adam | epoch: 006 | loss: 0.49303 - acc: 0.7600 -- iter: 1120/2015
[A[ATraining Step: 351  | total loss: [1m[32m0.49705[0m[0m | time: 21.886s
[2K
| Adam | epoch: 006 | loss: 0.49705 - acc: 0.7496 -- iter: 1152/2015
[A[ATraining Step: 352  | total loss: [1m[32m0.51532[0m[0m | time: 22.488s
[2K
| Adam | epoch: 006 | loss: 0.51532 - acc: 0.7371 -- iter: 1184/2015
[A[ATraining Step: 353  | total loss: [1m[32m0.51720[0m[0m | time: 23.129s
[2K
| Adam | epoch: 006 | loss: 0.51720 - acc: 0.7415 -- iter: 1216/2015
[A[ATraining Step: 354  | total loss: [1m[32m0.51132[0m[0m | time: 23.728s
[2K
| Adam | epoch: 006 | loss: 0.51132 - acc: 0.7455 -- iter: 1248/2015
[A[ATraining Step: 355  | total loss: [1m[32m0.50828[0m[0m | time: 24.336s
[2K
| Adam | epoch: 006 | loss: 0.50828 - acc: 0.7522 -- iter: 1280/2015
[A[ATraining Step: 356  | total loss: [1m[32m0.50639[0m[0m | time: 24.936s
[2K
| Adam | epoch: 006 | loss: 0.50639 - acc: 0.7582 -- iter: 1312/2015
[A[ATraining Step: 357  | total loss: [1m[32m0.49945[0m[0m | time: 25.544s
[2K
| Adam | epoch: 006 | loss: 0.49945 - acc: 0.7637 -- iter: 1344/2015
[A[ATraining Step: 358  | total loss: [1m[32m0.50120[0m[0m | time: 26.131s
[2K
| Adam | epoch: 006 | loss: 0.50120 - acc: 0.7561 -- iter: 1376/2015
[A[ATraining Step: 359  | total loss: [1m[32m0.50476[0m[0m | time: 26.733s
[2K
| Adam | epoch: 006 | loss: 0.50476 - acc: 0.7554 -- iter: 1408/2015
[A[ATraining Step: 360  | total loss: [1m[32m0.50259[0m[0m | time: 27.370s
[2K
| Adam | epoch: 006 | loss: 0.50259 - acc: 0.7612 -- iter: 1440/2015
[A[ATraining Step: 361  | total loss: [1m[32m0.51989[0m[0m | time: 27.990s
[2K
| Adam | epoch: 006 | loss: 0.51989 - acc: 0.7507 -- iter: 1472/2015
[A[ATraining Step: 362  | total loss: [1m[32m0.52123[0m[0m | time: 28.579s
[2K
| Adam | epoch: 006 | loss: 0.52123 - acc: 0.7475 -- iter: 1504/2015
[A[ATraining Step: 363  | total loss: [1m[32m0.51649[0m[0m | time: 29.181s
[2K
| Adam | epoch: 006 | loss: 0.51649 - acc: 0.7540 -- iter: 1536/2015
[A[ATraining Step: 364  | total loss: [1m[32m0.50674[0m[0m | time: 29.776s
[2K
| Adam | epoch: 006 | loss: 0.50674 - acc: 0.7630 -- iter: 1568/2015
[A[ATraining Step: 365  | total loss: [1m[32m0.49826[0m[0m | time: 30.376s
[2K
| Adam | epoch: 006 | loss: 0.49826 - acc: 0.7679 -- iter: 1600/2015
[A[ATraining Step: 366  | total loss: [1m[32m0.50425[0m[0m | time: 31.014s
[2K
| Adam | epoch: 006 | loss: 0.50425 - acc: 0.7567 -- iter: 1632/2015
[A[ATraining Step: 367  | total loss: [1m[32m0.49864[0m[0m | time: 31.615s
[2K
| Adam | epoch: 006 | loss: 0.49864 - acc: 0.7623 -- iter: 1664/2015
[A[ATraining Step: 368  | total loss: [1m[32m0.51254[0m[0m | time: 32.227s
[2K
| Adam | epoch: 006 | loss: 0.51254 - acc: 0.7517 -- iter: 1696/2015
[A[ATraining Step: 369  | total loss: [1m[32m0.51969[0m[0m | time: 32.851s
[2K
| Adam | epoch: 006 | loss: 0.51969 - acc: 0.7422 -- iter: 1728/2015
[A[ATraining Step: 370  | total loss: [1m[32m0.52650[0m[0m | time: 33.459s
[2K
| Adam | epoch: 006 | loss: 0.52650 - acc: 0.7367 -- iter: 1760/2015
[A[ATraining Step: 371  | total loss: [1m[32m0.53789[0m[0m | time: 34.070s
[2K
| Adam | epoch: 006 | loss: 0.53789 - acc: 0.7318 -- iter: 1792/2015
[A[ATraining Step: 372  | total loss: [1m[32m0.53502[0m[0m | time: 34.659s
[2K
| Adam | epoch: 006 | loss: 0.53502 - acc: 0.7336 -- iter: 1824/2015
[A[ATraining Step: 373  | total loss: [1m[32m0.53373[0m[0m | time: 35.258s
[2K
| Adam | epoch: 006 | loss: 0.53373 - acc: 0.7352 -- iter: 1856/2015
[A[ATraining Step: 374  | total loss: [1m[32m0.52856[0m[0m | time: 35.863s
[2K
| Adam | epoch: 006 | loss: 0.52856 - acc: 0.7430 -- iter: 1888/2015
[A[ATraining Step: 375  | total loss: [1m[32m0.51972[0m[0m | time: 36.460s
[2K
| Adam | epoch: 006 | loss: 0.51972 - acc: 0.7530 -- iter: 1920/2015
[A[ATraining Step: 376  | total loss: [1m[32m0.51573[0m[0m | time: 37.060s
[2K
| Adam | epoch: 006 | loss: 0.51573 - acc: 0.7621 -- iter: 1952/2015
[A[ATraining Step: 377  | total loss: [1m[32m0.50821[0m[0m | time: 37.659s
[2K
| Adam | epoch: 006 | loss: 0.50821 - acc: 0.7672 -- iter: 1984/2015
[A[ATraining Step: 378  | total loss: [1m[32m0.50570[0m[0m | time: 40.239s
[2K
| Adam | epoch: 006 | loss: 0.50570 - acc: 0.7686 | val_loss: 0.50368 - val_acc: 0.7603 -- iter: 2015/2015
--
Training Step: 379  | total loss: [1m[32m0.50088[0m[0m | time: 0.616s
[2K
| Adam | epoch: 007 | loss: 0.50088 - acc: 0.7698 -- iter: 0032/2015
[A[ATraining Step: 380  | total loss: [1m[32m0.50005[0m[0m | time: 1.230s
[2K
| Adam | epoch: 007 | loss: 0.50005 - acc: 0.7678 -- iter: 0064/2015
[A[ATraining Step: 381  | total loss: [1m[32m0.49103[0m[0m | time: 1.840s
[2K
| Adam | epoch: 007 | loss: 0.49103 - acc: 0.7723 -- iter: 0096/2015
[A[ATraining Step: 382  | total loss: [1m[32m0.48852[0m[0m | time: 2.443s
[2K
| Adam | epoch: 007 | loss: 0.48852 - acc: 0.7732 -- iter: 0128/2015
[A[ATraining Step: 383  | total loss: [1m[32m0.48841[0m[0m | time: 3.035s
[2K
| Adam | epoch: 007 | loss: 0.48841 - acc: 0.7803 -- iter: 0160/2015
[A[ATraining Step: 384  | total loss: [1m[32m0.48330[0m[0m | time: 3.636s
[2K
| Adam | epoch: 007 | loss: 0.48330 - acc: 0.7829 -- iter: 0192/2015
[A[ATraining Step: 385  | total loss: [1m[32m0.47791[0m[0m | time: 4.257s
[2K
| Adam | epoch: 007 | loss: 0.47791 - acc: 0.7852 -- iter: 0224/2015
[A[ATraining Step: 386  | total loss: [1m[32m0.48386[0m[0m | time: 4.862s
[2K
| Adam | epoch: 007 | loss: 0.48386 - acc: 0.7723 -- iter: 0256/2015
[A[ATraining Step: 387  | total loss: [1m[32m0.49416[0m[0m | time: 5.468s
[2K
| Adam | epoch: 007 | loss: 0.49416 - acc: 0.7639 -- iter: 0288/2015
[A[ATraining Step: 388  | total loss: [1m[32m0.49606[0m[0m | time: 6.080s
[2K
| Adam | epoch: 007 | loss: 0.49606 - acc: 0.7656 -- iter: 0320/2015
[A[ATraining Step: 389  | total loss: [1m[32m0.48972[0m[0m | time: 6.710s
[2K
| Adam | epoch: 007 | loss: 0.48972 - acc: 0.7734 -- iter: 0352/2015
[A[ATraining Step: 390  | total loss: [1m[32m0.48539[0m[0m | time: 7.317s
[2K
| Adam | epoch: 007 | loss: 0.48539 - acc: 0.7804 -- iter: 0384/2015
[A[ATraining Step: 391  | total loss: [1m[32m0.49105[0m[0m | time: 7.920s
[2K
| Adam | epoch: 007 | loss: 0.49105 - acc: 0.7743 -- iter: 0416/2015
[A[ATraining Step: 392  | total loss: [1m[32m0.49552[0m[0m | time: 8.521s
[2K
| Adam | epoch: 007 | loss: 0.49552 - acc: 0.7718 -- iter: 0448/2015
[A[ATraining Step: 393  | total loss: [1m[32m0.49581[0m[0m | time: 9.121s
[2K
| Adam | epoch: 007 | loss: 0.49581 - acc: 0.7665 -- iter: 0480/2015
[A[ATraining Step: 394  | total loss: [1m[32m0.49693[0m[0m | time: 9.739s
[2K
| Adam | epoch: 007 | loss: 0.49693 - acc: 0.7618 -- iter: 0512/2015
[A[ATraining Step: 395  | total loss: [1m[32m0.48962[0m[0m | time: 10.332s
[2K
| Adam | epoch: 007 | loss: 0.48962 - acc: 0.7668 -- iter: 0544/2015
[A[ATraining Step: 396  | total loss: [1m[32m0.47225[0m[0m | time: 10.931s
[2K
| Adam | epoch: 007 | loss: 0.47225 - acc: 0.7870 -- iter: 0576/2015
[A[ATraining Step: 397  | total loss: [1m[32m0.47274[0m[0m | time: 11.532s
[2K
| Adam | epoch: 007 | loss: 0.47274 - acc: 0.7864 -- iter: 0608/2015
[A[ATraining Step: 398  | total loss: [1m[32m0.46437[0m[0m | time: 12.135s
[2K
| Adam | epoch: 007 | loss: 0.46437 - acc: 0.7922 -- iter: 0640/2015
[A[ATraining Step: 399  | total loss: [1m[32m0.47464[0m[0m | time: 12.741s
[2K
| Adam | epoch: 007 | loss: 0.47464 - acc: 0.7817 -- iter: 0672/2015
[A[ATraining Step: 400  | total loss: [1m[32m0.49196[0m[0m | time: 15.318s
[2K
| Adam | epoch: 007 | loss: 0.49196 - acc: 0.7692 | val_loss: 0.49804 - val_acc: 0.7635 -- iter: 0704/2015
--
Training Step: 401  | total loss: [1m[32m0.49325[0m[0m | time: 15.930s
[2K
| Adam | epoch: 007 | loss: 0.49325 - acc: 0.7735 -- iter: 0736/2015
[A[ATraining Step: 402  | total loss: [1m[32m0.47660[0m[0m | time: 16.529s
[2K
| Adam | epoch: 007 | loss: 0.47660 - acc: 0.7899 -- iter: 0768/2015
[A[ATraining Step: 403  | total loss: [1m[32m0.47821[0m[0m | time: 17.136s
[2K
| Adam | epoch: 007 | loss: 0.47821 - acc: 0.7890 -- iter: 0800/2015
[A[ATraining Step: 404  | total loss: [1m[32m0.45951[0m[0m | time: 17.754s
[2K
| Adam | epoch: 007 | loss: 0.45951 - acc: 0.8039 -- iter: 0832/2015
[A[ATraining Step: 405  | total loss: [1m[32m0.45508[0m[0m | time: 18.365s
[2K
| Adam | epoch: 007 | loss: 0.45508 - acc: 0.8016 -- iter: 0864/2015
[A[ATraining Step: 406  | total loss: [1m[32m0.47280[0m[0m | time: 18.975s
[2K
| Adam | epoch: 007 | loss: 0.47280 - acc: 0.7933 -- iter: 0896/2015
[A[ATraining Step: 407  | total loss: [1m[32m0.47123[0m[0m | time: 19.591s
[2K
| Adam | epoch: 007 | loss: 0.47123 - acc: 0.7921 -- iter: 0928/2015
[A[ATraining Step: 408  | total loss: [1m[32m0.47576[0m[0m | time: 20.218s
[2K
| Adam | epoch: 007 | loss: 0.47576 - acc: 0.7879 -- iter: 0960/2015
[A[ATraining Step: 409  | total loss: [1m[32m0.45809[0m[0m | time: 20.817s
[2K
| Adam | epoch: 007 | loss: 0.45809 - acc: 0.8029 -- iter: 0992/2015
[A[ATraining Step: 410  | total loss: [1m[32m0.45464[0m[0m | time: 21.421s
[2K
| Adam | epoch: 007 | loss: 0.45464 - acc: 0.8038 -- iter: 1024/2015
[A[ATraining Step: 411  | total loss: [1m[32m0.45290[0m[0m | time: 22.025s
[2K
| Adam | epoch: 007 | loss: 0.45290 - acc: 0.8047 -- iter: 1056/2015
[A[ATraining Step: 412  | total loss: [1m[32m0.44187[0m[0m | time: 22.622s
[2K
| Adam | epoch: 007 | loss: 0.44187 - acc: 0.8055 -- iter: 1088/2015
[A[ATraining Step: 413  | total loss: [1m[32m0.43578[0m[0m | time: 23.249s
[2K
| Adam | epoch: 007 | loss: 0.43578 - acc: 0.8093 -- iter: 1120/2015
[A[ATraining Step: 414  | total loss: [1m[32m0.44054[0m[0m | time: 23.852s
[2K
| Adam | epoch: 007 | loss: 0.44054 - acc: 0.8096 -- iter: 1152/2015
[A[ATraining Step: 415  | total loss: [1m[32m0.44539[0m[0m | time: 24.446s
[2K
| Adam | epoch: 007 | loss: 0.44539 - acc: 0.8037 -- iter: 1184/2015
[A[ATraining Step: 416  | total loss: [1m[32m0.45921[0m[0m | time: 25.047s
[2K
| Adam | epoch: 007 | loss: 0.45921 - acc: 0.7920 -- iter: 1216/2015
[A[ATraining Step: 417  | total loss: [1m[32m0.46681[0m[0m | time: 25.669s
[2K
| Adam | epoch: 007 | loss: 0.46681 - acc: 0.7847 -- iter: 1248/2015
[A[ATraining Step: 418  | total loss: [1m[32m0.46689[0m[0m | time: 26.298s
[2K
| Adam | epoch: 007 | loss: 0.46689 - acc: 0.7875 -- iter: 1280/2015
[A[ATraining Step: 419  | total loss: [1m[32m0.48319[0m[0m | time: 26.926s
[2K
| Adam | epoch: 007 | loss: 0.48319 - acc: 0.7775 -- iter: 1312/2015
[A[ATraining Step: 420  | total loss: [1m[32m0.49583[0m[0m | time: 27.534s
[2K
| Adam | epoch: 007 | loss: 0.49583 - acc: 0.7747 -- iter: 1344/2015
[A[ATraining Step: 421  | total loss: [1m[32m0.48561[0m[0m | time: 28.135s
[2K
| Adam | epoch: 007 | loss: 0.48561 - acc: 0.7848 -- iter: 1376/2015
[A[ATraining Step: 422  | total loss: [1m[32m0.49154[0m[0m | time: 28.751s
[2K
| Adam | epoch: 007 | loss: 0.49154 - acc: 0.7844 -- iter: 1408/2015
[A[ATraining Step: 423  | total loss: [1m[32m0.48875[0m[0m | time: 29.357s
[2K
| Adam | epoch: 007 | loss: 0.48875 - acc: 0.7779 -- iter: 1440/2015
[A[ATraining Step: 424  | total loss: [1m[32m0.49859[0m[0m | time: 29.983s
[2K
| Adam | epoch: 007 | loss: 0.49859 - acc: 0.7626 -- iter: 1472/2015
[A[ATraining Step: 425  | total loss: [1m[32m0.49749[0m[0m | time: 30.586s
[2K
| Adam | epoch: 007 | loss: 0.49749 - acc: 0.7644 -- iter: 1504/2015
[A[ATraining Step: 426  | total loss: [1m[32m0.49441[0m[0m | time: 31.204s
[2K
| Adam | epoch: 007 | loss: 0.49441 - acc: 0.7692 -- iter: 1536/2015
[A[ATraining Step: 427  | total loss: [1m[32m0.50403[0m[0m | time: 31.808s
[2K
| Adam | epoch: 007 | loss: 0.50403 - acc: 0.7673 -- iter: 1568/2015
[A[ATraining Step: 428  | total loss: [1m[32m0.48804[0m[0m | time: 32.412s
[2K
| Adam | epoch: 007 | loss: 0.48804 - acc: 0.7843 -- iter: 1600/2015
[A[ATraining Step: 429  | total loss: [1m[32m0.47928[0m[0m | time: 33.015s
[2K
| Adam | epoch: 007 | loss: 0.47928 - acc: 0.7903 -- iter: 1632/2015
[A[ATraining Step: 430  | total loss: [1m[32m0.47996[0m[0m | time: 33.618s
[2K
| Adam | epoch: 007 | loss: 0.47996 - acc: 0.7925 -- iter: 1664/2015
[A[ATraining Step: 431  | total loss: [1m[32m0.48166[0m[0m | time: 34.240s
[2K
| Adam | epoch: 007 | loss: 0.48166 - acc: 0.7914 -- iter: 1696/2015
[A[ATraining Step: 432  | total loss: [1m[32m0.47269[0m[0m | time: 34.842s
[2K
| Adam | epoch: 007 | loss: 0.47269 - acc: 0.7935 -- iter: 1728/2015
[A[ATraining Step: 433  | total loss: [1m[32m0.47524[0m[0m | time: 35.449s
[2K
| Adam | epoch: 007 | loss: 0.47524 - acc: 0.7891 -- iter: 1760/2015
[A[ATraining Step: 434  | total loss: [1m[32m0.47103[0m[0m | time: 36.068s
[2K
| Adam | epoch: 007 | loss: 0.47103 - acc: 0.7915 -- iter: 1792/2015
[A[ATraining Step: 435  | total loss: [1m[32m0.47818[0m[0m | time: 36.665s
[2K
| Adam | epoch: 007 | loss: 0.47818 - acc: 0.7873 -- iter: 1824/2015
[A[ATraining Step: 436  | total loss: [1m[32m0.46538[0m[0m | time: 37.276s
[2K
| Adam | epoch: 007 | loss: 0.46538 - acc: 0.7961 -- iter: 1856/2015
[A[ATraining Step: 437  | total loss: [1m[32m0.47056[0m[0m | time: 37.882s
[2K
| Adam | epoch: 007 | loss: 0.47056 - acc: 0.7915 -- iter: 1888/2015
[A[ATraining Step: 438  | total loss: [1m[32m0.45416[0m[0m | time: 38.503s
[2K
| Adam | epoch: 007 | loss: 0.45416 - acc: 0.8061 -- iter: 1920/2015
[A[ATraining Step: 439  | total loss: [1m[32m0.45044[0m[0m | time: 39.101s
[2K
| Adam | epoch: 007 | loss: 0.45044 - acc: 0.8036 -- iter: 1952/2015
[A[ATraining Step: 440  | total loss: [1m[32m0.44510[0m[0m | time: 39.699s
[2K
| Adam | epoch: 007 | loss: 0.44510 - acc: 0.8107 -- iter: 1984/2015
[A[ATraining Step: 441  | total loss: [1m[32m0.45377[0m[0m | time: 42.283s
[2K
| Adam | epoch: 007 | loss: 0.45377 - acc: 0.8015 | val_loss: 0.49636 - val_acc: 0.7635 -- iter: 2015/2015
--
Training Step: 442  | total loss: [1m[32m0.45008[0m[0m | time: 0.646s
[2K
| Adam | epoch: 008 | loss: 0.45008 - acc: 0.8058 -- iter: 0032/2015
[A[ATraining Step: 443  | total loss: [1m[32m0.45536[0m[0m | time: 1.263s
[2K
| Adam | epoch: 008 | loss: 0.45536 - acc: 0.8033 -- iter: 0064/2015
[A[ATraining Step: 444  | total loss: [1m[32m0.45149[0m[0m | time: 1.859s
[2K
| Adam | epoch: 008 | loss: 0.45149 - acc: 0.8042 -- iter: 0096/2015
[A[ATraining Step: 445  | total loss: [1m[32m0.45310[0m[0m | time: 2.482s
[2K
| Adam | epoch: 008 | loss: 0.45310 - acc: 0.8051 -- iter: 0128/2015
[A[ATraining Step: 446  | total loss: [1m[32m0.45539[0m[0m | time: 3.081s
[2K
| Adam | epoch: 008 | loss: 0.45539 - acc: 0.8058 -- iter: 0160/2015
[A[ATraining Step: 447  | total loss: [1m[32m0.46676[0m[0m | time: 3.664s
[2K
| Adam | epoch: 008 | loss: 0.46676 - acc: 0.7971 -- iter: 0192/2015
[A[ATraining Step: 448  | total loss: [1m[32m0.47870[0m[0m | time: 4.249s
[2K
| Adam | epoch: 008 | loss: 0.47870 - acc: 0.7851 -- iter: 0224/2015
[A[ATraining Step: 449  | total loss: [1m[32m0.48668[0m[0m | time: 4.872s
[2K
| Adam | epoch: 008 | loss: 0.48668 - acc: 0.7776 -- iter: 0256/2015
[A[ATraining Step: 450  | total loss: [1m[32m0.48490[0m[0m | time: 5.471s
[2K
| Adam | epoch: 008 | loss: 0.48490 - acc: 0.7811 -- iter: 0288/2015
[A[ATraining Step: 451  | total loss: [1m[32m0.47878[0m[0m | time: 6.085s
[2K
| Adam | epoch: 008 | loss: 0.47878 - acc: 0.7811 -- iter: 0320/2015
[A[ATraining Step: 452  | total loss: [1m[32m0.48082[0m[0m | time: 6.697s
[2K
| Adam | epoch: 008 | loss: 0.48082 - acc: 0.7811 -- iter: 0352/2015
[A[ATraining Step: 453  | total loss: [1m[32m0.47677[0m[0m | time: 7.307s
[2K
| Adam | epoch: 008 | loss: 0.47677 - acc: 0.7842 -- iter: 0384/2015
[A[ATraining Step: 454  | total loss: [1m[32m0.47524[0m[0m | time: 7.904s
[2K
| Adam | epoch: 008 | loss: 0.47524 - acc: 0.7871 -- iter: 0416/2015
[A[ATraining Step: 455  | total loss: [1m[32m0.47126[0m[0m | time: 8.507s
[2K
| Adam | epoch: 008 | loss: 0.47126 - acc: 0.7865 -- iter: 0448/2015
[A[ATraining Step: 456  | total loss: [1m[32m0.46639[0m[0m | time: 9.104s
[2K
| Adam | epoch: 008 | loss: 0.46639 - acc: 0.7891 -- iter: 0480/2015
[A[ATraining Step: 457  | total loss: [1m[32m0.46383[0m[0m | time: 9.704s
[2K
| Adam | epoch: 008 | loss: 0.46383 - acc: 0.7914 -- iter: 0512/2015
[A[ATraining Step: 458  | total loss: [1m[32m0.45879[0m[0m | time: 10.298s
[2K
| Adam | epoch: 008 | loss: 0.45879 - acc: 0.7967 -- iter: 0544/2015
[A[ATraining Step: 459  | total loss: [1m[32m0.45139[0m[0m | time: 10.914s
[2K
| Adam | epoch: 008 | loss: 0.45139 - acc: 0.8014 -- iter: 0576/2015
[A[ATraining Step: 460  | total loss: [1m[32m0.44342[0m[0m | time: 11.552s
[2K
| Adam | epoch: 008 | loss: 0.44342 - acc: 0.8087 -- iter: 0608/2015
[A[ATraining Step: 461  | total loss: [1m[32m0.43611[0m[0m | time: 12.147s
[2K
| Adam | epoch: 008 | loss: 0.43611 - acc: 0.8122 -- iter: 0640/2015
[A[ATraining Step: 462  | total loss: [1m[32m0.44945[0m[0m | time: 12.758s
[2K
| Adam | epoch: 008 | loss: 0.44945 - acc: 0.8029 -- iter: 0672/2015
[A[ATraining Step: 463  | total loss: [1m[32m0.45100[0m[0m | time: 13.378s
[2K
| Adam | epoch: 008 | loss: 0.45100 - acc: 0.7976 -- iter: 0704/2015
[A[ATraining Step: 464  | total loss: [1m[32m0.45110[0m[0m | time: 13.984s
[2K
| Adam | epoch: 008 | loss: 0.45110 - acc: 0.7960 -- iter: 0736/2015
[A[ATraining Step: 465  | total loss: [1m[32m0.45021[0m[0m | time: 14.597s
[2K
| Adam | epoch: 008 | loss: 0.45021 - acc: 0.8007 -- iter: 0768/2015
[A[ATraining Step: 466  | total loss: [1m[32m0.44410[0m[0m | time: 15.202s
[2K
| Adam | epoch: 008 | loss: 0.44410 - acc: 0.8019 -- iter: 0800/2015
[A[ATraining Step: 467  | total loss: [1m[32m0.43016[0m[0m | time: 15.813s
[2K
| Adam | epoch: 008 | loss: 0.43016 - acc: 0.8124 -- iter: 0832/2015
[A[ATraining Step: 468  | total loss: [1m[32m0.41777[0m[0m | time: 16.435s
[2K
| Adam | epoch: 008 | loss: 0.41777 - acc: 0.8249 -- iter: 0864/2015
[A[ATraining Step: 469  | total loss: [1m[32m0.41028[0m[0m | time: 17.028s
[2K
| Adam | epoch: 008 | loss: 0.41028 - acc: 0.8299 -- iter: 0896/2015
[A[ATraining Step: 470  | total loss: [1m[32m0.40253[0m[0m | time: 17.631s
[2K
| Adam | epoch: 008 | loss: 0.40253 - acc: 0.8344 -- iter: 0928/2015
[A[ATraining Step: 471  | total loss: [1m[32m0.41204[0m[0m | time: 18.234s
[2K
| Adam | epoch: 008 | loss: 0.41204 - acc: 0.8260 -- iter: 0960/2015
[A[ATraining Step: 472  | total loss: [1m[32m0.44091[0m[0m | time: 18.843s
[2K
| Adam | epoch: 008 | loss: 0.44091 - acc: 0.8027 -- iter: 0992/2015
[A[ATraining Step: 473  | total loss: [1m[32m0.44485[0m[0m | time: 19.486s
[2K
| Adam | epoch: 008 | loss: 0.44485 - acc: 0.7943 -- iter: 1024/2015
[A[ATraining Step: 474  | total loss: [1m[32m0.46392[0m[0m | time: 20.084s
[2K
| Adam | epoch: 008 | loss: 0.46392 - acc: 0.7774 -- iter: 1056/2015
[A[ATraining Step: 475  | total loss: [1m[32m0.46805[0m[0m | time: 20.702s
[2K
| Adam | epoch: 008 | loss: 0.46805 - acc: 0.7778 -- iter: 1088/2015
[A[ATraining Step: 476  | total loss: [1m[32m0.46015[0m[0m | time: 21.297s
[2K
| Adam | epoch: 008 | loss: 0.46015 - acc: 0.7844 -- iter: 1120/2015
[A[ATraining Step: 477  | total loss: [1m[32m0.44842[0m[0m | time: 21.893s
[2K
| Adam | epoch: 008 | loss: 0.44842 - acc: 0.7966 -- iter: 1152/2015
[A[ATraining Step: 478  | total loss: [1m[32m0.46011[0m[0m | time: 22.500s
[2K
| Adam | epoch: 008 | loss: 0.46011 - acc: 0.7857 -- iter: 1184/2015
[A[ATraining Step: 479  | total loss: [1m[32m0.45519[0m[0m | time: 23.113s
[2K
| Adam | epoch: 008 | loss: 0.45519 - acc: 0.7852 -- iter: 1216/2015
[A[ATraining Step: 480  | total loss: [1m[32m0.47837[0m[0m | time: 23.717s
[2K
| Adam | epoch: 008 | loss: 0.47837 - acc: 0.7723 -- iter: 1248/2015
[A[ATraining Step: 481  | total loss: [1m[32m0.50396[0m[0m | time: 24.315s
[2K
| Adam | epoch: 008 | loss: 0.50396 - acc: 0.7607 -- iter: 1280/2015
[A[ATraining Step: 482  | total loss: [1m[32m0.49019[0m[0m | time: 24.910s
[2K
| Adam | epoch: 008 | loss: 0.49019 - acc: 0.7690 -- iter: 1312/2015
[A[ATraining Step: 483  | total loss: [1m[32m0.48861[0m[0m | time: 25.546s
[2K
| Adam | epoch: 008 | loss: 0.48861 - acc: 0.7671 -- iter: 1344/2015
[A[ATraining Step: 484  | total loss: [1m[32m0.47656[0m[0m | time: 26.147s
[2K
| Adam | epoch: 008 | loss: 0.47656 - acc: 0.7717 -- iter: 1376/2015
[A[ATraining Step: 485  | total loss: [1m[32m0.46759[0m[0m | time: 26.762s
[2K
| Adam | epoch: 008 | loss: 0.46759 - acc: 0.7820 -- iter: 1408/2015
[A[ATraining Step: 486  | total loss: [1m[32m0.46467[0m[0m | time: 27.359s
[2K
| Adam | epoch: 008 | loss: 0.46467 - acc: 0.7850 -- iter: 1440/2015
[A[ATraining Step: 487  | total loss: [1m[32m0.46329[0m[0m | time: 27.967s
[2K
| Adam | epoch: 008 | loss: 0.46329 - acc: 0.7847 -- iter: 1472/2015
[A[ATraining Step: 488  | total loss: [1m[32m0.45655[0m[0m | time: 28.587s
[2K
| Adam | epoch: 008 | loss: 0.45655 - acc: 0.7937 -- iter: 1504/2015
[A[ATraining Step: 489  | total loss: [1m[32m0.45846[0m[0m | time: 29.200s
[2K
| Adam | epoch: 008 | loss: 0.45846 - acc: 0.7893 -- iter: 1536/2015
[A[ATraining Step: 490  | total loss: [1m[32m0.45835[0m[0m | time: 29.825s
[2K
| Adam | epoch: 008 | loss: 0.45835 - acc: 0.7854 -- iter: 1568/2015
[A[ATraining Step: 491  | total loss: [1m[32m0.45596[0m[0m | time: 30.439s
[2K
| Adam | epoch: 008 | loss: 0.45596 - acc: 0.7912 -- iter: 1600/2015
[A[ATraining Step: 492  | total loss: [1m[32m0.43918[0m[0m | time: 31.033s
[2K
| Adam | epoch: 008 | loss: 0.43918 - acc: 0.8090 -- iter: 1632/2015
[A[ATraining Step: 493  | total loss: [1m[32m0.44396[0m[0m | time: 31.655s
[2K
| Adam | epoch: 008 | loss: 0.44396 - acc: 0.8062 -- iter: 1664/2015
[A[ATraining Step: 494  | total loss: [1m[32m0.42950[0m[0m | time: 32.251s
[2K
| Adam | epoch: 008 | loss: 0.42950 - acc: 0.8193 -- iter: 1696/2015
[A[ATraining Step: 495  | total loss: [1m[32m0.43090[0m[0m | time: 32.861s
[2K
| Adam | epoch: 008 | loss: 0.43090 - acc: 0.8218 -- iter: 1728/2015
[A[ATraining Step: 496  | total loss: [1m[32m0.42350[0m[0m | time: 33.464s
[2K
| Adam | epoch: 008 | loss: 0.42350 - acc: 0.8271 -- iter: 1760/2015
[A[ATraining Step: 497  | total loss: [1m[32m0.41347[0m[0m | time: 34.064s
[2K
| Adam | epoch: 008 | loss: 0.41347 - acc: 0.8350 -- iter: 1792/2015
[A[ATraining Step: 498  | total loss: [1m[32m0.41437[0m[0m | time: 34.662s
[2K
| Adam | epoch: 008 | loss: 0.41437 - acc: 0.8359 -- iter: 1824/2015
[A[ATraining Step: 499  | total loss: [1m[32m0.40416[0m[0m | time: 35.256s
[2K
| Adam | epoch: 008 | loss: 0.40416 - acc: 0.8429 -- iter: 1856/2015
[A[ATraining Step: 500  | total loss: [1m[32m0.41649[0m[0m | time: 35.856s
[2K
| Adam | epoch: 008 | loss: 0.41649 - acc: 0.8243 -- iter: 1888/2015
[A[ATraining Step: 501  | total loss: [1m[32m0.40979[0m[0m | time: 36.461s
[2K
| Adam | epoch: 008 | loss: 0.40979 - acc: 0.8293 -- iter: 1920/2015
[A[ATraining Step: 502  | total loss: [1m[32m0.41928[0m[0m | time: 37.053s
[2K
| Adam | epoch: 008 | loss: 0.41928 - acc: 0.8214 -- iter: 1952/2015
[A[ATraining Step: 503  | total loss: [1m[32m0.42522[0m[0m | time: 37.652s
[2K
| Adam | epoch: 008 | loss: 0.42522 - acc: 0.8143 -- iter: 1984/2015
[A[ATraining Step: 504  | total loss: [1m[32m0.41616[0m[0m | time: 40.235s
[2K
| Adam | epoch: 008 | loss: 0.41616 - acc: 0.8172 | val_loss: 0.49353 - val_acc: 0.7762 -- iter: 2015/2015
--
Training Step: 505  | total loss: [1m[32m0.42135[0m[0m | time: 0.611s
[2K
| Adam | epoch: 009 | loss: 0.42135 - acc: 0.8105 -- iter: 0032/2015
[A[ATraining Step: 506  | total loss: [1m[32m0.41084[0m[0m | time: 1.219s
[2K
| Adam | epoch: 009 | loss: 0.41084 - acc: 0.8201 -- iter: 0064/2015
[A[ATraining Step: 507  | total loss: [1m[32m0.40312[0m[0m | time: 1.826s
[2K
| Adam | epoch: 009 | loss: 0.40312 - acc: 0.8256 -- iter: 0096/2015
[A[ATraining Step: 508  | total loss: [1m[32m0.41510[0m[0m | time: 2.426s
[2K
| Adam | epoch: 009 | loss: 0.41510 - acc: 0.8211 -- iter: 0128/2015
[A[ATraining Step: 509  | total loss: [1m[32m0.42060[0m[0m | time: 3.028s
[2K
| Adam | epoch: 009 | loss: 0.42060 - acc: 0.8203 -- iter: 0160/2015
[A[ATraining Step: 510  | total loss: [1m[32m0.42797[0m[0m | time: 3.625s
[2K
| Adam | epoch: 009 | loss: 0.42797 - acc: 0.8164 -- iter: 0192/2015
[A[ATraining Step: 511  | total loss: [1m[32m0.43427[0m[0m | time: 4.211s
[2K
| Adam | epoch: 009 | loss: 0.43427 - acc: 0.8129 -- iter: 0224/2015
[A[ATraining Step: 512  | total loss: [1m[32m0.44620[0m[0m | time: 4.793s
[2K
| Adam | epoch: 009 | loss: 0.44620 - acc: 0.8090 -- iter: 0256/2015
[A[ATraining Step: 513  | total loss: [1m[32m0.45646[0m[0m | time: 5.411s
[2K
| Adam | epoch: 009 | loss: 0.45646 - acc: 0.8055 -- iter: 0288/2015
[A[ATraining Step: 514  | total loss: [1m[32m0.44025[0m[0m | time: 6.014s
[2K
| Adam | epoch: 009 | loss: 0.44025 - acc: 0.8187 -- iter: 0320/2015
[A[ATraining Step: 515  | total loss: [1m[32m0.42138[0m[0m | time: 6.636s
[2K
| Adam | epoch: 009 | loss: 0.42138 - acc: 0.8275 -- iter: 0352/2015
[A[ATraining Step: 516  | total loss: [1m[32m0.41931[0m[0m | time: 7.256s
[2K
| Adam | epoch: 009 | loss: 0.41931 - acc: 0.8260 -- iter: 0384/2015
[A[ATraining Step: 517  | total loss: [1m[32m0.40850[0m[0m | time: 7.873s
[2K
| Adam | epoch: 009 | loss: 0.40850 - acc: 0.8309 -- iter: 0416/2015
[A[ATraining Step: 518  | total loss: [1m[32m0.39620[0m[0m | time: 8.513s
[2K
| Adam | epoch: 009 | loss: 0.39620 - acc: 0.8384 -- iter: 0448/2015
[A[ATraining Step: 519  | total loss: [1m[32m0.40616[0m[0m | time: 9.123s
[2K
| Adam | epoch: 009 | loss: 0.40616 - acc: 0.8358 -- iter: 0480/2015
[A[ATraining Step: 520  | total loss: [1m[32m0.42850[0m[0m | time: 9.747s
[2K
| Adam | epoch: 009 | loss: 0.42850 - acc: 0.8179 -- iter: 0512/2015
[A[ATraining Step: 521  | total loss: [1m[32m0.43570[0m[0m | time: 10.352s
[2K
| Adam | epoch: 009 | loss: 0.43570 - acc: 0.8111 -- iter: 0544/2015
[A[ATraining Step: 522  | total loss: [1m[32m0.43296[0m[0m | time: 10.950s
[2K
| Adam | epoch: 009 | loss: 0.43296 - acc: 0.8206 -- iter: 0576/2015
[A[ATraining Step: 523  | total loss: [1m[32m0.42182[0m[0m | time: 11.543s
[2K
| Adam | epoch: 009 | loss: 0.42182 - acc: 0.8260 -- iter: 0608/2015
[A[ATraining Step: 524  | total loss: [1m[32m0.42284[0m[0m | time: 12.139s
[2K
| Adam | epoch: 009 | loss: 0.42284 - acc: 0.8247 -- iter: 0640/2015
[A[ATraining Step: 525  | total loss: [1m[32m0.42677[0m[0m | time: 12.761s
[2K
| Adam | epoch: 009 | loss: 0.42677 - acc: 0.8203 -- iter: 0672/2015
[A[ATraining Step: 526  | total loss: [1m[32m0.43240[0m[0m | time: 13.374s
[2K
| Adam | epoch: 009 | loss: 0.43240 - acc: 0.8133 -- iter: 0704/2015
[A[ATraining Step: 527  | total loss: [1m[32m0.43887[0m[0m | time: 13.980s
[2K
| Adam | epoch: 009 | loss: 0.43887 - acc: 0.8038 -- iter: 0736/2015
[A[ATraining Step: 528  | total loss: [1m[32m0.43632[0m[0m | time: 14.589s
[2K
| Adam | epoch: 009 | loss: 0.43632 - acc: 0.8047 -- iter: 0768/2015
[A[ATraining Step: 529  | total loss: [1m[32m0.43755[0m[0m | time: 15.186s
[2K
| Adam | epoch: 009 | loss: 0.43755 - acc: 0.8055 -- iter: 0800/2015
[A[ATraining Step: 530  | total loss: [1m[32m0.45845[0m[0m | time: 15.807s
[2K
| Adam | epoch: 009 | loss: 0.45845 - acc: 0.7843 -- iter: 0832/2015
[A[ATraining Step: 531  | total loss: [1m[32m0.45224[0m[0m | time: 16.406s
[2K
| Adam | epoch: 009 | loss: 0.45224 - acc: 0.7903 -- iter: 0864/2015
[A[ATraining Step: 532  | total loss: [1m[32m0.44155[0m[0m | time: 17.040s
[2K
| Adam | epoch: 009 | loss: 0.44155 - acc: 0.7956 -- iter: 0896/2015
[A[ATraining Step: 533  | total loss: [1m[32m0.43202[0m[0m | time: 17.660s
[2K
| Adam | epoch: 009 | loss: 0.43202 - acc: 0.7973 -- iter: 0928/2015
[A[ATraining Step: 534  | total loss: [1m[32m0.43699[0m[0m | time: 18.259s
[2K
| Adam | epoch: 009 | loss: 0.43699 - acc: 0.7988 -- iter: 0960/2015
[A[ATraining Step: 535  | total loss: [1m[32m0.44065[0m[0m | time: 18.874s
[2K
| Adam | epoch: 009 | loss: 0.44065 - acc: 0.7971 -- iter: 0992/2015
[A[ATraining Step: 536  | total loss: [1m[32m0.44181[0m[0m | time: 19.484s
[2K
| Adam | epoch: 009 | loss: 0.44181 - acc: 0.7955 -- iter: 1024/2015
[A[ATraining Step: 537  | total loss: [1m[32m0.43313[0m[0m | time: 20.091s
[2K
| Adam | epoch: 009 | loss: 0.43313 - acc: 0.8003 -- iter: 1056/2015
[A[ATraining Step: 538  | total loss: [1m[32m0.43900[0m[0m | time: 20.712s
[2K
| Adam | epoch: 009 | loss: 0.43900 - acc: 0.7953 -- iter: 1088/2015
[A[ATraining Step: 539  | total loss: [1m[32m0.43222[0m[0m | time: 21.319s
[2K
| Adam | epoch: 009 | loss: 0.43222 - acc: 0.7970 -- iter: 1120/2015
[A[ATraining Step: 540  | total loss: [1m[32m0.43301[0m[0m | time: 21.927s
[2K
| Adam | epoch: 009 | loss: 0.43301 - acc: 0.8017 -- iter: 1152/2015
[A[ATraining Step: 541  | total loss: [1m[32m0.43680[0m[0m | time: 22.542s
[2K
| Adam | epoch: 009 | loss: 0.43680 - acc: 0.7965 -- iter: 1184/2015
[A[ATraining Step: 542  | total loss: [1m[32m0.43732[0m[0m | time: 23.141s
[2K
| Adam | epoch: 009 | loss: 0.43732 - acc: 0.7981 -- iter: 1216/2015
[A[ATraining Step: 543  | total loss: [1m[32m0.44878[0m[0m | time: 23.749s
[2K
| Adam | epoch: 009 | loss: 0.44878 - acc: 0.7933 -- iter: 1248/2015
[A[ATraining Step: 544  | total loss: [1m[32m0.45084[0m[0m | time: 24.347s
[2K
| Adam | epoch: 009 | loss: 0.45084 - acc: 0.7952 -- iter: 1280/2015
[A[ATraining Step: 545  | total loss: [1m[32m0.44400[0m[0m | time: 24.950s
[2K
| Adam | epoch: 009 | loss: 0.44400 - acc: 0.7969 -- iter: 1312/2015
[A[ATraining Step: 546  | total loss: [1m[32m0.42756[0m[0m | time: 25.558s
[2K
| Adam | epoch: 009 | loss: 0.42756 - acc: 0.8141 -- iter: 1344/2015
[A[ATraining Step: 547  | total loss: [1m[32m0.42041[0m[0m | time: 26.196s
[2K
| Adam | epoch: 009 | loss: 0.42041 - acc: 0.8202 -- iter: 1376/2015
[A[ATraining Step: 548  | total loss: [1m[32m0.41252[0m[0m | time: 26.806s
[2K
| Adam | epoch: 009 | loss: 0.41252 - acc: 0.8257 -- iter: 1408/2015
[A[ATraining Step: 549  | total loss: [1m[32m0.39970[0m[0m | time: 27.418s
[2K
| Adam | epoch: 009 | loss: 0.39970 - acc: 0.8337 -- iter: 1440/2015
[A[ATraining Step: 550  | total loss: [1m[32m0.41505[0m[0m | time: 28.023s
[2K
| Adam | epoch: 009 | loss: 0.41505 - acc: 0.8191 -- iter: 1472/2015
[A[ATraining Step: 551  | total loss: [1m[32m0.41605[0m[0m | time: 28.623s
[2K
| Adam | epoch: 009 | loss: 0.41605 - acc: 0.8185 -- iter: 1504/2015
[A[ATraining Step: 552  | total loss: [1m[32m0.41150[0m[0m | time: 29.234s
[2K
| Adam | epoch: 009 | loss: 0.41150 - acc: 0.8272 -- iter: 1536/2015
[A[ATraining Step: 553  | total loss: [1m[32m0.40462[0m[0m | time: 29.842s
[2K
| Adam | epoch: 009 | loss: 0.40462 - acc: 0.8320 -- iter: 1568/2015
[A[ATraining Step: 554  | total loss: [1m[32m0.39714[0m[0m | time: 30.476s
[2K
| Adam | epoch: 009 | loss: 0.39714 - acc: 0.8363 -- iter: 1600/2015
[A[ATraining Step: 555  | total loss: [1m[32m0.39010[0m[0m | time: 31.112s
[2K
| Adam | epoch: 009 | loss: 0.39010 - acc: 0.8433 -- iter: 1632/2015
[A[ATraining Step: 556  | total loss: [1m[32m0.39581[0m[0m | time: 31.712s
[2K
| Adam | epoch: 009 | loss: 0.39581 - acc: 0.8434 -- iter: 1664/2015
[A[ATraining Step: 557  | total loss: [1m[32m0.40587[0m[0m | time: 32.315s
[2K
| Adam | epoch: 009 | loss: 0.40587 - acc: 0.8340 -- iter: 1696/2015
[A[ATraining Step: 558  | total loss: [1m[32m0.40712[0m[0m | time: 32.934s
[2K
| Adam | epoch: 009 | loss: 0.40712 - acc: 0.8350 -- iter: 1728/2015
[A[ATraining Step: 559  | total loss: [1m[32m0.39178[0m[0m | time: 33.533s
[2K
| Adam | epoch: 009 | loss: 0.39178 - acc: 0.8452 -- iter: 1760/2015
[A[ATraining Step: 560  | total loss: [1m[32m0.40462[0m[0m | time: 34.138s
[2K
| Adam | epoch: 009 | loss: 0.40462 - acc: 0.8388 -- iter: 1792/2015
[A[ATraining Step: 561  | total loss: [1m[32m0.40133[0m[0m | time: 34.746s
[2K
| Adam | epoch: 009 | loss: 0.40133 - acc: 0.8362 -- iter: 1824/2015
[A[ATraining Step: 562  | total loss: [1m[32m0.39620[0m[0m | time: 35.351s
[2K
| Adam | epoch: 009 | loss: 0.39620 - acc: 0.8370 -- iter: 1856/2015
[A[ATraining Step: 563  | total loss: [1m[32m0.40738[0m[0m | time: 35.966s
[2K
| Adam | epoch: 009 | loss: 0.40738 - acc: 0.8345 -- iter: 1888/2015
[A[ATraining Step: 564  | total loss: [1m[32m0.40337[0m[0m | time: 36.583s
[2K
| Adam | epoch: 009 | loss: 0.40337 - acc: 0.8354 -- iter: 1920/2015
[A[ATraining Step: 565  | total loss: [1m[32m0.40896[0m[0m | time: 37.220s
[2K
| Adam | epoch: 009 | loss: 0.40896 - acc: 0.8331 -- iter: 1952/2015
[A[ATraining Step: 566  | total loss: [1m[32m0.41602[0m[0m | time: 37.831s
[2K
| Adam | epoch: 009 | loss: 0.41602 - acc: 0.8280 -- iter: 1984/2015
[A[ATraining Step: 567  | total loss: [1m[32m0.45667[0m[0m | time: 40.459s
[2K
| Adam | epoch: 009 | loss: 0.45667 - acc: 0.8014 | val_loss: 0.49809 - val_acc: 0.7683 -- iter: 2015/2015
--
Training Step: 568  | total loss: [1m[32m0.44134[0m[0m | time: 0.623s
[2K
| Adam | epoch: 010 | loss: 0.44134 - acc: 0.8119 -- iter: 0032/2015
[A[ATraining Step: 569  | total loss: [1m[32m0.43512[0m[0m | time: 1.228s
[2K
| Adam | epoch: 010 | loss: 0.43512 - acc: 0.8182 -- iter: 0064/2015
[A[ATraining Step: 570  | total loss: [1m[32m0.42250[0m[0m | time: 1.825s
[2K
| Adam | epoch: 010 | loss: 0.42250 - acc: 0.8239 -- iter: 0096/2015
[A[ATraining Step: 571  | total loss: [1m[32m0.40963[0m[0m | time: 2.426s
[2K
| Adam | epoch: 010 | loss: 0.40963 - acc: 0.8321 -- iter: 0128/2015
[A[ATraining Step: 572  | total loss: [1m[32m0.40339[0m[0m | time: 3.040s
[2K
| Adam | epoch: 010 | loss: 0.40339 - acc: 0.8302 -- iter: 0160/2015
[A[ATraining Step: 573  | total loss: [1m[32m0.41009[0m[0m | time: 3.642s
[2K
| Adam | epoch: 010 | loss: 0.41009 - acc: 0.8253 -- iter: 0192/2015
[A[ATraining Step: 574  | total loss: [1m[32m0.42859[0m[0m | time: 4.241s
[2K
| Adam | epoch: 010 | loss: 0.42859 - acc: 0.8146 -- iter: 0224/2015
[A[ATraining Step: 575  | total loss: [1m[32m0.42623[0m[0m | time: 4.829s
[2K
| Adam | epoch: 010 | loss: 0.42623 - acc: 0.8144 -- iter: 0256/2015
[A[ATraining Step: 576  | total loss: [1m[32m0.42401[0m[0m | time: 5.454s
[2K
| Adam | epoch: 010 | loss: 0.42401 - acc: 0.8168 -- iter: 0288/2015
[A[ATraining Step: 577  | total loss: [1m[32m0.42181[0m[0m | time: 6.071s
[2K
| Adam | epoch: 010 | loss: 0.42181 - acc: 0.8190 -- iter: 0320/2015
[A[ATraining Step: 578  | total loss: [1m[32m0.40535[0m[0m | time: 6.699s
[2K
| Adam | epoch: 010 | loss: 0.40535 - acc: 0.8309 -- iter: 0352/2015
[A[ATraining Step: 579  | total loss: [1m[32m0.40398[0m[0m | time: 7.317s
[2K
| Adam | epoch: 010 | loss: 0.40398 - acc: 0.8259 -- iter: 0384/2015
[A[ATraining Step: 580  | total loss: [1m[32m0.39818[0m[0m | time: 7.923s
[2K
| Adam | epoch: 010 | loss: 0.39818 - acc: 0.8308 -- iter: 0416/2015
[A[ATraining Step: 581  | total loss: [1m[32m0.41358[0m[0m | time: 8.538s
[2K
| Adam | epoch: 010 | loss: 0.41358 - acc: 0.8196 -- iter: 0448/2015
[A[ATraining Step: 582  | total loss: [1m[32m0.41374[0m[0m | time: 9.147s
[2K
| Adam | epoch: 010 | loss: 0.41374 - acc: 0.8158 -- iter: 0480/2015
[A[ATraining Step: 583  | total loss: [1m[32m0.42514[0m[0m | time: 9.764s
[2K
| Adam | epoch: 010 | loss: 0.42514 - acc: 0.8123 -- iter: 0512/2015
[A[ATraining Step: 584  | total loss: [1m[32m0.41616[0m[0m | time: 10.371s
[2K
| Adam | epoch: 010 | loss: 0.41616 - acc: 0.8186 -- iter: 0544/2015
[A[ATraining Step: 585  | total loss: [1m[32m0.39541[0m[0m | time: 10.975s
[2K
| Adam | epoch: 010 | loss: 0.39541 - acc: 0.8336 -- iter: 0576/2015
[A[ATraining Step: 586  | total loss: [1m[32m0.39830[0m[0m | time: 11.589s
[2K
| Adam | epoch: 010 | loss: 0.39830 - acc: 0.8315 -- iter: 0608/2015
[A[ATraining Step: 587  | total loss: [1m[32m0.38360[0m[0m | time: 12.216s
[2K
| Adam | epoch: 010 | loss: 0.38360 - acc: 0.8421 -- iter: 0640/2015
[A[ATraining Step: 588  | total loss: [1m[32m0.38768[0m[0m | time: 12.836s
[2K
| Adam | epoch: 010 | loss: 0.38768 - acc: 0.8360 -- iter: 0672/2015
[A[ATraining Step: 589  | total loss: [1m[32m0.39939[0m[0m | time: 13.439s
[2K
| Adam | epoch: 010 | loss: 0.39939 - acc: 0.8305 -- iter: 0704/2015
[A[ATraining Step: 590  | total loss: [1m[32m0.40162[0m[0m | time: 14.058s
[2K
| Adam | epoch: 010 | loss: 0.40162 - acc: 0.8287 -- iter: 0736/2015
[A[ATraining Step: 591  | total loss: [1m[32m0.40440[0m[0m | time: 14.665s
[2K
| Adam | epoch: 010 | loss: 0.40440 - acc: 0.8240 -- iter: 0768/2015
[A[ATraining Step: 592  | total loss: [1m[32m0.39795[0m[0m | time: 15.273s
[2K
| Adam | epoch: 010 | loss: 0.39795 - acc: 0.8291 -- iter: 0800/2015
[A[ATraining Step: 593  | total loss: [1m[32m0.40806[0m[0m | time: 15.893s
[2K
| Adam | epoch: 010 | loss: 0.40806 - acc: 0.8243 -- iter: 0832/2015
[A[ATraining Step: 594  | total loss: [1m[32m0.42693[0m[0m | time: 16.500s
[2K
| Adam | epoch: 010 | loss: 0.42693 - acc: 0.8044 -- iter: 0864/2015
[A[ATraining Step: 595  | total loss: [1m[32m0.41424[0m[0m | time: 17.096s
[2K
| Adam | epoch: 010 | loss: 0.41424 - acc: 0.8083 -- iter: 0896/2015
[A[ATraining Step: 596  | total loss: [1m[32m0.41870[0m[0m | time: 17.705s
[2K
| Adam | epoch: 010 | loss: 0.41870 - acc: 0.8087 -- iter: 0928/2015
[A[ATraining Step: 597  | total loss: [1m[32m0.42976[0m[0m | time: 18.308s
[2K
| Adam | epoch: 010 | loss: 0.42976 - acc: 0.8029 -- iter: 0960/2015
[A[ATraining Step: 598  | total loss: [1m[32m0.41574[0m[0m | time: 18.928s
[2K
| Adam | epoch: 010 | loss: 0.41574 - acc: 0.8101 -- iter: 0992/2015
[A[ATraining Step: 599  | total loss: [1m[32m0.40729[0m[0m | time: 19.528s
[2K
| Adam | epoch: 010 | loss: 0.40729 - acc: 0.8166 -- iter: 1024/2015
[A[ATraining Step: 600  | total loss: [1m[32m0.41159[0m[0m | time: 22.119s
[2K
| Adam | epoch: 010 | loss: 0.41159 - acc: 0.8193 | val_loss: 0.53285 - val_acc: 0.7603 -- iter: 1056/2015
--
Training Step: 601  | total loss: [1m[32m0.43485[0m[0m | time: 22.748s
[2K
| Adam | epoch: 010 | loss: 0.43485 - acc: 0.7999 -- iter: 1088/2015
[A[ATraining Step: 602  | total loss: [1m[32m0.46399[0m[0m | time: 23.354s
[2K
| Adam | epoch: 010 | loss: 0.46399 - acc: 0.7792 -- iter: 1120/2015
[A[ATraining Step: 603  | total loss: [1m[32m0.44440[0m[0m | time: 23.952s
[2K
| Adam | epoch: 010 | loss: 0.44440 - acc: 0.7951 -- iter: 1152/2015
[A[ATraining Step: 604  | total loss: [1m[32m0.44785[0m[0m | time: 24.561s
[2K
| Adam | epoch: 010 | loss: 0.44785 - acc: 0.7937 -- iter: 1184/2015
[A[ATraining Step: 605  | total loss: [1m[32m0.46363[0m[0m | time: 25.173s
[2K
| Adam | epoch: 010 | loss: 0.46363 - acc: 0.7893 -- iter: 1216/2015
[A[ATraining Step: 606  | total loss: [1m[32m0.45238[0m[0m | time: 25.769s
[2K
| Adam | epoch: 010 | loss: 0.45238 - acc: 0.7948 -- iter: 1248/2015
[A[ATraining Step: 607  | total loss: [1m[32m0.44077[0m[0m | time: 26.374s
[2K
| Adam | epoch: 010 | loss: 0.44077 - acc: 0.8028 -- iter: 1280/2015
[A[ATraining Step: 608  | total loss: [1m[32m0.44740[0m[0m | time: 26.993s
[2K
| Adam | epoch: 010 | loss: 0.44740 - acc: 0.8038 -- iter: 1312/2015
[A[ATraining Step: 609  | total loss: [1m[32m0.44827[0m[0m | time: 27.595s
[2K
| Adam | epoch: 010 | loss: 0.44827 - acc: 0.8109 -- iter: 1344/2015
[A[ATraining Step: 610  | total loss: [1m[32m0.43940[0m[0m | time: 28.228s
[2K
| Adam | epoch: 010 | loss: 0.43940 - acc: 0.8173 -- iter: 1376/2015
[A[ATraining Step: 611  | total loss: [1m[32m0.43542[0m[0m | time: 28.858s
[2K
| Adam | epoch: 010 | loss: 0.43542 - acc: 0.8199 -- iter: 1408/2015
[A[ATraining Step: 612  | total loss: [1m[32m0.42578[0m[0m | time: 29.495s
[2K
| Adam | epoch: 010 | loss: 0.42578 - acc: 0.8286 -- iter: 1440/2015
[A[ATraining Step: 613  | total loss: [1m[32m0.42967[0m[0m | time: 30.092s
[2K
| Adam | epoch: 010 | loss: 0.42967 - acc: 0.8238 -- iter: 1472/2015
[A[ATraining Step: 614  | total loss: [1m[32m0.42505[0m[0m | time: 30.711s
[2K
| Adam | epoch: 010 | loss: 0.42505 - acc: 0.8227 -- iter: 1504/2015
[A[ATraining Step: 615  | total loss: [1m[32m0.42140[0m[0m | time: 31.311s
[2K
| Adam | epoch: 010 | loss: 0.42140 - acc: 0.8217 -- iter: 1536/2015
[A[ATraining Step: 616  | total loss: [1m[32m0.41907[0m[0m | time: 31.937s
[2K
| Adam | epoch: 010 | loss: 0.41907 - acc: 0.8208 -- iter: 1568/2015
[A[ATraining Step: 617  | total loss: [1m[32m0.41621[0m[0m | time: 32.535s
[2K
| Adam | epoch: 010 | loss: 0.41621 - acc: 0.8199 -- iter: 1600/2015
[A[ATraining Step: 618  | total loss: [1m[32m0.41550[0m[0m | time: 33.137s
[2K
| Adam | epoch: 010 | loss: 0.41550 - acc: 0.8192 -- iter: 1632/2015
[A[ATraining Step: 619  | total loss: [1m[32m0.42346[0m[0m | time: 33.758s
[2K
| Adam | epoch: 010 | loss: 0.42346 - acc: 0.8154 -- iter: 1664/2015
[A[ATraining Step: 620  | total loss: [1m[32m0.42197[0m[0m | time: 34.365s
[2K
| Adam | epoch: 010 | loss: 0.42197 - acc: 0.8182 -- iter: 1696/2015
[A[ATraining Step: 621  | total loss: [1m[32m0.41708[0m[0m | time: 34.984s
[2K
| Adam | epoch: 010 | loss: 0.41708 - acc: 0.8177 -- iter: 1728/2015
[A[ATraining Step: 622  | total loss: [1m[32m0.40705[0m[0m | time: 35.604s
[2K
| Adam | epoch: 010 | loss: 0.40705 - acc: 0.8171 -- iter: 1760/2015
[A[ATraining Step: 623  | total loss: [1m[32m0.41682[0m[0m | time: 36.213s
[2K
| Adam | epoch: 010 | loss: 0.41682 - acc: 0.8104 -- iter: 1792/2015
[A[ATraining Step: 624  | total loss: [1m[32m0.40836[0m[0m | time: 36.812s
[2K
| Adam | epoch: 010 | loss: 0.40836 - acc: 0.8169 -- iter: 1824/2015
[A[ATraining Step: 625  | total loss: [1m[32m0.40780[0m[0m | time: 37.458s
[2K
| Adam | epoch: 010 | loss: 0.40780 - acc: 0.8196 -- iter: 1856/2015
[A[ATraining Step: 626  | total loss: [1m[32m0.39365[0m[0m | time: 38.067s
[2K
| Adam | epoch: 010 | loss: 0.39365 - acc: 0.8314 -- iter: 1888/2015
[A[ATraining Step: 627  | total loss: [1m[32m0.40282[0m[0m | time: 38.674s
[2K
| Adam | epoch: 010 | loss: 0.40282 - acc: 0.8232 -- iter: 1920/2015
[A[ATraining Step: 628  | total loss: [1m[32m0.38015[0m[0m | time: 39.283s
[2K
| Adam | epoch: 010 | loss: 0.38015 - acc: 0.8409 -- iter: 1952/2015
[A[ATraining Step: 629  | total loss: [1m[32m0.36257[0m[0m | time: 39.882s
[2K
| Adam | epoch: 010 | loss: 0.36257 - acc: 0.8506 -- iter: 1984/2015
[A[ATraining Step: 630  | total loss: [1m[32m0.37742[0m[0m | time: 42.457s
[2K
| Adam | epoch: 010 | loss: 0.37742 - acc: 0.8468 | val_loss: 0.45543 - val_acc: 0.7937 -- iter: 2015/2015
--
Training Step: 631  | total loss: [1m[32m0.35404[0m[0m | time: 0.599s
[2K
| Adam | epoch: 011 | loss: 0.35404 - acc: 0.8621 -- iter: 0032/2015
[A[ATraining Step: 632  | total loss: [1m[32m0.34660[0m[0m | time: 1.209s
[2K
| Adam | epoch: 011 | loss: 0.34660 - acc: 0.8665 -- iter: 0064/2015
[A[ATraining Step: 633  | total loss: [1m[32m0.34889[0m[0m | time: 1.811s
[2K
| Adam | epoch: 011 | loss: 0.34889 - acc: 0.8642 -- iter: 0096/2015
[A[ATraining Step: 634  | total loss: [1m[32m0.34689[0m[0m | time: 2.414s
[2K
| Adam | epoch: 011 | loss: 0.34689 - acc: 0.8653 -- iter: 0128/2015
[A[ATraining Step: 635  | total loss: [1m[32m0.36614[0m[0m | time: 3.020s
[2K
| Adam | epoch: 011 | loss: 0.36614 - acc: 0.8569 -- iter: 0160/2015
[A[ATraining Step: 636  | total loss: [1m[32m0.36676[0m[0m | time: 3.644s
[2K
| Adam | epoch: 011 | loss: 0.36676 - acc: 0.8556 -- iter: 0192/2015
[A[ATraining Step: 637  | total loss: [1m[32m0.38336[0m[0m | time: 4.241s
[2K
| Adam | epoch: 011 | loss: 0.38336 - acc: 0.8419 -- iter: 0224/2015
[A[ATraining Step: 638  | total loss: [1m[32m0.39846[0m[0m | time: 4.837s
[2K
| Adam | epoch: 011 | loss: 0.39846 - acc: 0.8358 -- iter: 0256/2015
[A[ATraining Step: 639  | total loss: [1m[32m0.39750[0m[0m | time: 5.421s
[2K
| Adam | epoch: 011 | loss: 0.39750 - acc: 0.8366 -- iter: 0288/2015
[A[ATraining Step: 640  | total loss: [1m[32m0.39886[0m[0m | time: 5.998s
[2K
| Adam | epoch: 011 | loss: 0.39886 - acc: 0.8401 -- iter: 0320/2015
[A[ATraining Step: 641  | total loss: [1m[32m0.40067[0m[0m | time: 6.600s
[2K
| Adam | epoch: 011 | loss: 0.40067 - acc: 0.8399 -- iter: 0352/2015
[A[ATraining Step: 642  | total loss: [1m[32m0.40001[0m[0m | time: 7.197s
[2K
| Adam | epoch: 011 | loss: 0.40001 - acc: 0.8434 -- iter: 0384/2015
[A[ATraining Step: 643  | total loss: [1m[32m0.41236[0m[0m | time: 7.792s
[2K
| Adam | epoch: 011 | loss: 0.41236 - acc: 0.8372 -- iter: 0416/2015
[A[ATraining Step: 644  | total loss: [1m[32m0.40427[0m[0m | time: 8.387s
[2K
| Adam | epoch: 011 | loss: 0.40427 - acc: 0.8410 -- iter: 0448/2015
[A[ATraining Step: 645  | total loss: [1m[32m0.39258[0m[0m | time: 8.986s
[2K
| Adam | epoch: 011 | loss: 0.39258 - acc: 0.8475 -- iter: 0480/2015
[A[ATraining Step: 646  | total loss: [1m[32m0.40122[0m[0m | time: 9.592s
[2K
| Adam | epoch: 011 | loss: 0.40122 - acc: 0.8409 -- iter: 0512/2015
[A[ATraining Step: 647  | total loss: [1m[32m0.40769[0m[0m | time: 10.216s
[2K
| Adam | epoch: 011 | loss: 0.40769 - acc: 0.8381 -- iter: 0544/2015
[A[ATraining Step: 648  | total loss: [1m[32m0.38475[0m[0m | time: 10.825s
[2K
| Adam | epoch: 011 | loss: 0.38475 - acc: 0.8511 -- iter: 0576/2015
[A[ATraining Step: 649  | total loss: [1m[32m0.39231[0m[0m | time: 11.423s
[2K
| Adam | epoch: 011 | loss: 0.39231 - acc: 0.8410 -- iter: 0608/2015
[A[ATraining Step: 650  | total loss: [1m[32m0.38865[0m[0m | time: 12.046s
[2K
| Adam | epoch: 011 | loss: 0.38865 - acc: 0.8444 -- iter: 0640/2015
[A[ATraining Step: 651  | total loss: [1m[32m0.37562[0m[0m | time: 12.647s
[2K
| Adam | epoch: 011 | loss: 0.37562 - acc: 0.8506 -- iter: 0672/2015
[A[ATraining Step: 652  | total loss: [1m[32m0.36663[0m[0m | time: 13.246s
[2K
| Adam | epoch: 011 | loss: 0.36663 - acc: 0.8593 -- iter: 0704/2015
[A[ATraining Step: 653  | total loss: [1m[32m0.37487[0m[0m | time: 13.834s
[2K
| Adam | epoch: 011 | loss: 0.37487 - acc: 0.8577 -- iter: 0736/2015
[A[ATraining Step: 654  | total loss: [1m[32m0.37029[0m[0m | time: 14.431s
[2K
| Adam | epoch: 011 | loss: 0.37029 - acc: 0.8595 -- iter: 0768/2015
[A[ATraining Step: 655  | total loss: [1m[32m0.36356[0m[0m | time: 15.041s
[2K
| Adam | epoch: 011 | loss: 0.36356 - acc: 0.8641 -- iter: 0800/2015
[A[ATraining Step: 656  | total loss: [1m[32m0.35632[0m[0m | time: 15.640s
[2K
| Adam | epoch: 011 | loss: 0.35632 - acc: 0.8683 -- iter: 0832/2015
[A[ATraining Step: 657  | total loss: [1m[32m0.37847[0m[0m | time: 16.252s
[2K
| Adam | epoch: 011 | loss: 0.37847 - acc: 0.8565 -- iter: 0864/2015
[A[ATraining Step: 658  | total loss: [1m[32m0.39431[0m[0m | time: 16.857s
[2K
| Adam | epoch: 011 | loss: 0.39431 - acc: 0.8427 -- iter: 0896/2015
[A[ATraining Step: 659  | total loss: [1m[32m0.38418[0m[0m | time: 17.453s
[2K
| Adam | epoch: 011 | loss: 0.38418 - acc: 0.8460 -- iter: 0928/2015
[A[ATraining Step: 660  | total loss: [1m[32m0.38597[0m[0m | time: 18.040s
[2K
| Adam | epoch: 011 | loss: 0.38597 - acc: 0.8426 -- iter: 0960/2015
[A[ATraining Step: 661  | total loss: [1m[32m0.37662[0m[0m | time: 18.661s
[2K
| Adam | epoch: 011 | loss: 0.37662 - acc: 0.8490 -- iter: 0992/2015
[A[ATraining Step: 662  | total loss: [1m[32m0.38873[0m[0m | time: 19.268s
[2K
| Adam | epoch: 011 | loss: 0.38873 - acc: 0.8360 -- iter: 1024/2015
[A[ATraining Step: 663  | total loss: [1m[32m0.38914[0m[0m | time: 19.871s
[2K
| Adam | epoch: 011 | loss: 0.38914 - acc: 0.8367 -- iter: 1056/2015
[A[ATraining Step: 664  | total loss: [1m[32m0.37834[0m[0m | time: 20.502s
[2K
| Adam | epoch: 011 | loss: 0.37834 - acc: 0.8437 -- iter: 1088/2015
[A[ATraining Step: 665  | total loss: [1m[32m0.37649[0m[0m | time: 21.108s
[2K
| Adam | epoch: 011 | loss: 0.37649 - acc: 0.8468 -- iter: 1120/2015
[A[ATraining Step: 666  | total loss: [1m[32m0.38964[0m[0m | time: 21.720s
[2K
| Adam | epoch: 011 | loss: 0.38964 - acc: 0.8371 -- iter: 1152/2015
[A[ATraining Step: 667  | total loss: [1m[32m0.39132[0m[0m | time: 22.325s
[2K
| Adam | epoch: 011 | loss: 0.39132 - acc: 0.8315 -- iter: 1184/2015
[A[ATraining Step: 668  | total loss: [1m[32m0.38338[0m[0m | time: 22.927s
[2K
| Adam | epoch: 011 | loss: 0.38338 - acc: 0.8390 -- iter: 1216/2015
[A[ATraining Step: 669  | total loss: [1m[32m0.37422[0m[0m | time: 23.539s
[2K
| Adam | epoch: 011 | loss: 0.37422 - acc: 0.8457 -- iter: 1248/2015
[A[ATraining Step: 670  | total loss: [1m[32m0.38643[0m[0m | time: 24.164s
[2K
| Adam | epoch: 011 | loss: 0.38643 - acc: 0.8424 -- iter: 1280/2015
[A[ATraining Step: 671  | total loss: [1m[32m0.37903[0m[0m | time: 24.772s
[2K
| Adam | epoch: 011 | loss: 0.37903 - acc: 0.8457 -- iter: 1312/2015
[A[ATraining Step: 672  | total loss: [1m[32m0.37050[0m[0m | time: 25.372s
[2K
| Adam | epoch: 011 | loss: 0.37050 - acc: 0.8549 -- iter: 1344/2015
[A[ATraining Step: 673  | total loss: [1m[32m0.36558[0m[0m | time: 25.983s
[2K
| Adam | epoch: 011 | loss: 0.36558 - acc: 0.8506 -- iter: 1376/2015
[A[ATraining Step: 674  | total loss: [1m[32m0.36331[0m[0m | time: 26.585s
[2K
| Adam | epoch: 011 | loss: 0.36331 - acc: 0.8531 -- iter: 1408/2015
[A[ATraining Step: 675  | total loss: [1m[32m0.35349[0m[0m | time: 27.190s
[2K
| Adam | epoch: 011 | loss: 0.35349 - acc: 0.8615 -- iter: 1440/2015
[A[ATraining Step: 676  | total loss: [1m[32m0.34829[0m[0m | time: 27.793s
[2K
| Adam | epoch: 011 | loss: 0.34829 - acc: 0.8660 -- iter: 1472/2015
[A[ATraining Step: 677  | total loss: [1m[32m0.34339[0m[0m | time: 28.402s
[2K
| Adam | epoch: 011 | loss: 0.34339 - acc: 0.8700 -- iter: 1504/2015
[A[ATraining Step: 678  | total loss: [1m[32m0.35067[0m[0m | time: 29.012s
[2K
| Adam | epoch: 011 | loss: 0.35067 - acc: 0.8643 -- iter: 1536/2015
[A[ATraining Step: 679  | total loss: [1m[32m0.34945[0m[0m | time: 29.608s
[2K
| Adam | epoch: 011 | loss: 0.34945 - acc: 0.8685 -- iter: 1568/2015
[A[ATraining Step: 680  | total loss: [1m[32m0.34551[0m[0m | time: 30.202s
[2K
| Adam | epoch: 011 | loss: 0.34551 - acc: 0.8660 -- iter: 1600/2015
[A[ATraining Step: 681  | total loss: [1m[32m0.34298[0m[0m | time: 30.803s
[2K
| Adam | epoch: 011 | loss: 0.34298 - acc: 0.8700 -- iter: 1632/2015
[A[ATraining Step: 682  | total loss: [1m[32m0.34237[0m[0m | time: 31.415s
[2K
| Adam | epoch: 011 | loss: 0.34237 - acc: 0.8674 -- iter: 1664/2015
[A[ATraining Step: 683  | total loss: [1m[32m0.33850[0m[0m | time: 32.019s
[2K
| Adam | epoch: 011 | loss: 0.33850 - acc: 0.8681 -- iter: 1696/2015
[A[ATraining Step: 684  | total loss: [1m[32m0.33101[0m[0m | time: 32.613s
[2K
| Adam | epoch: 011 | loss: 0.33101 - acc: 0.8688 -- iter: 1728/2015
[A[ATraining Step: 685  | total loss: [1m[32m0.33004[0m[0m | time: 33.234s
[2K
| Adam | epoch: 011 | loss: 0.33004 - acc: 0.8694 -- iter: 1760/2015
[A[ATraining Step: 686  | total loss: [1m[32m0.31623[0m[0m | time: 33.834s
[2K
| Adam | epoch: 011 | loss: 0.31623 - acc: 0.8794 -- iter: 1792/2015
[A[ATraining Step: 687  | total loss: [1m[32m0.31652[0m[0m | time: 34.425s
[2K
| Adam | epoch: 011 | loss: 0.31652 - acc: 0.8758 -- iter: 1824/2015
[A[ATraining Step: 688  | total loss: [1m[32m0.32658[0m[0m | time: 35.064s
[2K
| Adam | epoch: 011 | loss: 0.32658 - acc: 0.8664 -- iter: 1856/2015
[A[ATraining Step: 689  | total loss: [1m[32m0.32226[0m[0m | time: 35.656s
[2K
| Adam | epoch: 011 | loss: 0.32226 - acc: 0.8672 -- iter: 1888/2015
[A[ATraining Step: 690  | total loss: [1m[32m0.32294[0m[0m | time: 36.281s
[2K
| Adam | epoch: 011 | loss: 0.32294 - acc: 0.8649 -- iter: 1920/2015
[A[ATraining Step: 691  | total loss: [1m[32m0.31168[0m[0m | time: 36.889s
[2K
| Adam | epoch: 011 | loss: 0.31168 - acc: 0.8753 -- iter: 1952/2015
[A[ATraining Step: 692  | total loss: [1m[32m0.32849[0m[0m | time: 37.478s
[2K
| Adam | epoch: 011 | loss: 0.32849 - acc: 0.8627 -- iter: 1984/2015
[A[ATraining Step: 693  | total loss: [1m[32m0.32951[0m[0m | time: 40.061s
[2K
| Adam | epoch: 011 | loss: 0.32951 - acc: 0.8671 | val_loss: 0.43455 - val_acc: 0.8127 -- iter: 2015/2015
--
Training Step: 694  | total loss: [1m[32m0.33559[0m[0m | time: 0.626s
[2K
| Adam | epoch: 012 | loss: 0.33559 - acc: 0.8679 -- iter: 0032/2015
[A[ATraining Step: 695  | total loss: [1m[32m0.32066[0m[0m | time: 1.243s
[2K
| Adam | epoch: 012 | loss: 0.32066 - acc: 0.8811 -- iter: 0064/2015
[A[ATraining Step: 696  | total loss: [1m[32m0.32277[0m[0m | time: 1.857s
[2K
| Adam | epoch: 012 | loss: 0.32277 - acc: 0.8805 -- iter: 0096/2015
[A[ATraining Step: 697  | total loss: [1m[32m0.32586[0m[0m | time: 2.461s
[2K
| Adam | epoch: 012 | loss: 0.32586 - acc: 0.8799 -- iter: 0128/2015
[A[ATraining Step: 698  | total loss: [1m[32m0.33074[0m[0m | time: 3.061s
[2K
| Adam | epoch: 012 | loss: 0.33074 - acc: 0.8732 -- iter: 0160/2015
[A[ATraining Step: 699  | total loss: [1m[32m0.33754[0m[0m | time: 3.672s
[2K
| Adam | epoch: 012 | loss: 0.33754 - acc: 0.8577 -- iter: 0192/2015
[A[ATraining Step: 700  | total loss: [1m[32m0.34176[0m[0m | time: 4.280s
[2K
| Adam | epoch: 012 | loss: 0.34176 - acc: 0.8563 -- iter: 0224/2015
[A[ATraining Step: 701  | total loss: [1m[32m0.35620[0m[0m | time: 4.885s
[2K
| Adam | epoch: 012 | loss: 0.35620 - acc: 0.8457 -- iter: 0256/2015
[A[ATraining Step: 702  | total loss: [1m[32m0.34576[0m[0m | time: 5.490s
[2K
| Adam | epoch: 012 | loss: 0.34576 - acc: 0.8580 -- iter: 0288/2015
[A[ATraining Step: 703  | total loss: [1m[32m0.35367[0m[0m | time: 6.078s
[2K
| Adam | epoch: 012 | loss: 0.35367 - acc: 0.8597 -- iter: 0320/2015
[A[ATraining Step: 704  | total loss: [1m[32m0.36139[0m[0m | time: 6.680s
[2K
| Adam | epoch: 012 | loss: 0.36139 - acc: 0.8479 -- iter: 0352/2015
[A[ATraining Step: 705  | total loss: [1m[32m0.36788[0m[0m | time: 7.506s
[2K
| Adam | epoch: 012 | loss: 0.36788 - acc: 0.8373 -- iter: 0384/2015
[A[ATraining Step: 706  | total loss: [1m[32m0.36585[0m[0m | time: 8.110s
[2K
| Adam | epoch: 012 | loss: 0.36585 - acc: 0.8349 -- iter: 0416/2015
[A[ATraining Step: 707  | total loss: [1m[32m0.39071[0m[0m | time: 8.720s
[2K
| Adam | epoch: 012 | loss: 0.39071 - acc: 0.8326 -- iter: 0448/2015
[A[ATraining Step: 708  | total loss: [1m[32m0.39816[0m[0m | time: 9.321s
[2K
| Adam | epoch: 012 | loss: 0.39816 - acc: 0.8306 -- iter: 0480/2015
[A[ATraining Step: 709  | total loss: [1m[32m0.39464[0m[0m | time: 9.940s
[2K
| Adam | epoch: 012 | loss: 0.39464 - acc: 0.8319 -- iter: 0512/2015
[A[ATraining Step: 710  | total loss: [1m[32m0.38392[0m[0m | time: 10.556s
[2K
| Adam | epoch: 012 | loss: 0.38392 - acc: 0.8394 -- iter: 0544/2015
[A[ATraining Step: 711  | total loss: [1m[32m0.38508[0m[0m | time: 11.165s
[2K
| Adam | epoch: 012 | loss: 0.38508 - acc: 0.8429 -- iter: 0576/2015
[A[ATraining Step: 712  | total loss: [1m[32m0.38510[0m[0m | time: 11.770s
[2K
| Adam | epoch: 012 | loss: 0.38510 - acc: 0.8430 -- iter: 0608/2015
[A[ATraining Step: 713  | total loss: [1m[32m0.38239[0m[0m | time: 12.382s
[2K
| Adam | epoch: 012 | loss: 0.38239 - acc: 0.8493 -- iter: 0640/2015
[A[ATraining Step: 714  | total loss: [1m[32m0.39265[0m[0m | time: 13.017s
[2K
| Adam | epoch: 012 | loss: 0.39265 - acc: 0.8488 -- iter: 0672/2015
[A[ATraining Step: 715  | total loss: [1m[32m0.38304[0m[0m | time: 13.618s
[2K
| Adam | epoch: 012 | loss: 0.38304 - acc: 0.8545 -- iter: 0704/2015
[A[ATraining Step: 716  | total loss: [1m[32m0.37407[0m[0m | time: 14.216s
[2K
| Adam | epoch: 012 | loss: 0.37407 - acc: 0.8628 -- iter: 0736/2015
[A[ATraining Step: 717  | total loss: [1m[32m0.35377[0m[0m | time: 14.837s
[2K
| Adam | epoch: 012 | loss: 0.35377 - acc: 0.8703 -- iter: 0768/2015
[A[ATraining Step: 718  | total loss: [1m[32m0.34708[0m[0m | time: 15.444s
[2K
| Adam | epoch: 012 | loss: 0.34708 - acc: 0.8739 -- iter: 0800/2015
[A[ATraining Step: 719  | total loss: [1m[32m0.33730[0m[0m | time: 16.066s
[2K
| Adam | epoch: 012 | loss: 0.33730 - acc: 0.8771 -- iter: 0832/2015
[A[ATraining Step: 720  | total loss: [1m[32m0.35365[0m[0m | time: 16.666s
[2K
| Adam | epoch: 012 | loss: 0.35365 - acc: 0.8644 -- iter: 0864/2015
[A[ATraining Step: 721  | total loss: [1m[32m0.35778[0m[0m | time: 17.262s
[2K
| Adam | epoch: 012 | loss: 0.35778 - acc: 0.8592 -- iter: 0896/2015
[A[ATraining Step: 722  | total loss: [1m[32m0.36288[0m[0m | time: 17.880s
[2K
| Adam | epoch: 012 | loss: 0.36288 - acc: 0.8483 -- iter: 0928/2015
[A[ATraining Step: 723  | total loss: [1m[32m0.38387[0m[0m | time: 18.492s
[2K
| Adam | epoch: 012 | loss: 0.38387 - acc: 0.8385 -- iter: 0960/2015
[A[ATraining Step: 724  | total loss: [1m[32m0.36450[0m[0m | time: 19.106s
[2K
| Adam | epoch: 012 | loss: 0.36450 - acc: 0.8515 -- iter: 0992/2015
[A[ATraining Step: 725  | total loss: [1m[32m0.38841[0m[0m | time: 19.704s
[2K
| Adam | epoch: 012 | loss: 0.38841 - acc: 0.8413 -- iter: 1024/2015
[A[ATraining Step: 726  | total loss: [1m[32m0.39851[0m[0m | time: 20.309s
[2K
| Adam | epoch: 012 | loss: 0.39851 - acc: 0.8353 -- iter: 1056/2015
[A[ATraining Step: 727  | total loss: [1m[32m0.39843[0m[0m | time: 20.913s
[2K
| Adam | epoch: 012 | loss: 0.39843 - acc: 0.8393 -- iter: 1088/2015
[A[ATraining Step: 728  | total loss: [1m[32m0.40315[0m[0m | time: 21.525s
[2K
| Adam | epoch: 012 | loss: 0.40315 - acc: 0.8335 -- iter: 1120/2015
[A[ATraining Step: 729  | total loss: [1m[32m0.38110[0m[0m | time: 22.133s
[2K
| Adam | epoch: 012 | loss: 0.38110 - acc: 0.8470 -- iter: 1152/2015
[A[ATraining Step: 730  | total loss: [1m[32m0.39830[0m[0m | time: 22.728s
[2K
| Adam | epoch: 012 | loss: 0.39830 - acc: 0.8373 -- iter: 1184/2015
[A[ATraining Step: 731  | total loss: [1m[32m0.39900[0m[0m | time: 23.340s
[2K
| Adam | epoch: 012 | loss: 0.39900 - acc: 0.8317 -- iter: 1216/2015
[A[ATraining Step: 732  | total loss: [1m[32m0.39932[0m[0m | time: 23.943s
[2K
| Adam | epoch: 012 | loss: 0.39932 - acc: 0.8298 -- iter: 1248/2015
[A[ATraining Step: 733  | total loss: [1m[32m0.39281[0m[0m | time: 24.540s
[2K
| Adam | epoch: 012 | loss: 0.39281 - acc: 0.8343 -- iter: 1280/2015
[A[ATraining Step: 734  | total loss: [1m[32m0.38083[0m[0m | time: 25.150s
[2K
| Adam | epoch: 012 | loss: 0.38083 - acc: 0.8384 -- iter: 1312/2015
[A[ATraining Step: 735  | total loss: [1m[32m0.38664[0m[0m | time: 25.759s
[2K
| Adam | epoch: 012 | loss: 0.38664 - acc: 0.8264 -- iter: 1344/2015
[A[ATraining Step: 736  | total loss: [1m[32m0.39861[0m[0m | time: 26.375s
[2K
| Adam | epoch: 012 | loss: 0.39861 - acc: 0.8250 -- iter: 1376/2015
[A[ATraining Step: 737  | total loss: [1m[32m0.39431[0m[0m | time: 27.011s
[2K
| Adam | epoch: 012 | loss: 0.39431 - acc: 0.8238 -- iter: 1408/2015
[A[ATraining Step: 738  | total loss: [1m[32m0.38719[0m[0m | time: 27.621s
[2K
| Adam | epoch: 012 | loss: 0.38719 - acc: 0.8258 -- iter: 1440/2015
[A[ATraining Step: 739  | total loss: [1m[32m0.37414[0m[0m | time: 28.205s
[2K
| Adam | epoch: 012 | loss: 0.37414 - acc: 0.8401 -- iter: 1472/2015
[A[ATraining Step: 740  | total loss: [1m[32m0.38702[0m[0m | time: 28.805s
[2K
| Adam | epoch: 012 | loss: 0.38702 - acc: 0.8342 -- iter: 1504/2015
[A[ATraining Step: 741  | total loss: [1m[32m0.39368[0m[0m | time: 29.409s
[2K
| Adam | epoch: 012 | loss: 0.39368 - acc: 0.8320 -- iter: 1536/2015
[A[ATraining Step: 742  | total loss: [1m[32m0.39875[0m[0m | time: 30.025s
[2K
| Adam | epoch: 012 | loss: 0.39875 - acc: 0.8301 -- iter: 1568/2015
[A[ATraining Step: 743  | total loss: [1m[32m0.37496[0m[0m | time: 30.658s
[2K
| Adam | epoch: 012 | loss: 0.37496 - acc: 0.8439 -- iter: 1600/2015
[A[ATraining Step: 744  | total loss: [1m[32m0.36753[0m[0m | time: 31.254s
[2K
| Adam | epoch: 012 | loss: 0.36753 - acc: 0.8470 -- iter: 1632/2015
[A[ATraining Step: 745  | total loss: [1m[32m0.36206[0m[0m | time: 31.837s
[2K
| Adam | epoch: 012 | loss: 0.36206 - acc: 0.8498 -- iter: 1664/2015
[A[ATraining Step: 746  | total loss: [1m[32m0.34427[0m[0m | time: 32.433s
[2K
| Adam | epoch: 012 | loss: 0.34427 - acc: 0.8617 -- iter: 1696/2015
[A[ATraining Step: 747  | total loss: [1m[32m0.34687[0m[0m | time: 33.040s
[2K
| Adam | epoch: 012 | loss: 0.34687 - acc: 0.8568 -- iter: 1728/2015
[A[ATraining Step: 748  | total loss: [1m[32m0.34314[0m[0m | time: 33.641s
[2K
| Adam | epoch: 012 | loss: 0.34314 - acc: 0.8586 -- iter: 1760/2015
[A[ATraining Step: 749  | total loss: [1m[32m0.33014[0m[0m | time: 34.240s
[2K
| Adam | epoch: 012 | loss: 0.33014 - acc: 0.8665 -- iter: 1792/2015
[A[ATraining Step: 750  | total loss: [1m[32m0.33016[0m[0m | time: 34.845s
[2K
| Adam | epoch: 012 | loss: 0.33016 - acc: 0.8674 -- iter: 1824/2015
[A[ATraining Step: 751  | total loss: [1m[32m0.31824[0m[0m | time: 35.465s
[2K
| Adam | epoch: 012 | loss: 0.31824 - acc: 0.8744 -- iter: 1856/2015
[A[ATraining Step: 752  | total loss: [1m[32m0.31090[0m[0m | time: 36.065s
[2K
| Adam | epoch: 012 | loss: 0.31090 - acc: 0.8807 -- iter: 1888/2015
[A[ATraining Step: 753  | total loss: [1m[32m0.32796[0m[0m | time: 36.683s
[2K
| Adam | epoch: 012 | loss: 0.32796 - acc: 0.8645 -- iter: 1920/2015
[A[ATraining Step: 754  | total loss: [1m[32m0.33779[0m[0m | time: 37.315s
[2K
| Adam | epoch: 012 | loss: 0.33779 - acc: 0.8562 -- iter: 1952/2015
[A[ATraining Step: 755  | total loss: [1m[32m0.35552[0m[0m | time: 37.929s
[2K
| Adam | epoch: 012 | loss: 0.35552 - acc: 0.8518 -- iter: 1984/2015
[A[ATraining Step: 756  | total loss: [1m[32m0.35102[0m[0m | time: 40.519s
[2K
| Adam | epoch: 012 | loss: 0.35102 - acc: 0.8572 | val_loss: 0.42926 - val_acc: 0.8127 -- iter: 2015/2015
--
Training Step: 757  | total loss: [1m[32m0.35110[0m[0m | time: 0.610s
[2K
| Adam | epoch: 013 | loss: 0.35110 - acc: 0.8590 -- iter: 0032/2015
[A[ATraining Step: 758  | total loss: [1m[32m0.35618[0m[0m | time: 1.206s
[2K
| Adam | epoch: 013 | loss: 0.35618 - acc: 0.8481 -- iter: 0064/2015
[A[ATraining Step: 759  | total loss: [1m[32m0.35564[0m[0m | time: 1.800s
[2K
| Adam | epoch: 013 | loss: 0.35564 - acc: 0.8477 -- iter: 0096/2015
[A[ATraining Step: 760  | total loss: [1m[32m0.35641[0m[0m | time: 2.404s
[2K
| Adam | epoch: 013 | loss: 0.35641 - acc: 0.8410 -- iter: 0128/2015
[A[ATraining Step: 761  | total loss: [1m[32m0.36346[0m[0m | time: 3.013s
[2K
| Adam | epoch: 013 | loss: 0.36346 - acc: 0.8382 -- iter: 0160/2015
[A[ATraining Step: 762  | total loss: [1m[32m0.36516[0m[0m | time: 3.600s
[2K
| Adam | epoch: 013 | loss: 0.36516 - acc: 0.8387 -- iter: 0192/2015
[A[ATraining Step: 763  | total loss: [1m[32m0.36172[0m[0m | time: 4.192s
[2K
| Adam | epoch: 013 | loss: 0.36172 - acc: 0.8392 -- iter: 0224/2015
[A[ATraining Step: 764  | total loss: [1m[32m0.35330[0m[0m | time: 4.802s
[2K
| Adam | epoch: 013 | loss: 0.35330 - acc: 0.8491 -- iter: 0256/2015
[A[ATraining Step: 765  | total loss: [1m[32m0.34260[0m[0m | time: 5.414s
[2K
| Adam | epoch: 013 | loss: 0.34260 - acc: 0.8579 -- iter: 0288/2015
[A[ATraining Step: 766  | total loss: [1m[32m0.35160[0m[0m | time: 6.020s
[2K
| Adam | epoch: 013 | loss: 0.35160 - acc: 0.8502 -- iter: 0320/2015
[A[ATraining Step: 767  | total loss: [1m[32m0.34879[0m[0m | time: 6.643s
[2K
| Adam | epoch: 013 | loss: 0.34879 - acc: 0.8558 -- iter: 0352/2015
[A[ATraining Step: 768  | total loss: [1m[32m0.33981[0m[0m | time: 7.236s
[2K
| Adam | epoch: 013 | loss: 0.33981 - acc: 0.8606 -- iter: 0384/2015
[A[ATraining Step: 769  | total loss: [1m[32m0.32968[0m[0m | time: 7.864s
[2K
| Adam | epoch: 013 | loss: 0.32968 - acc: 0.8681 -- iter: 0416/2015
[A[ATraining Step: 770  | total loss: [1m[32m0.32874[0m[0m | time: 8.465s
[2K
| Adam | epoch: 013 | loss: 0.32874 - acc: 0.8625 -- iter: 0448/2015
[A[ATraining Step: 771  | total loss: [1m[32m0.33652[0m[0m | time: 9.064s
[2K
| Adam | epoch: 013 | loss: 0.33652 - acc: 0.8575 -- iter: 0480/2015
[A[ATraining Step: 772  | total loss: [1m[32m0.32948[0m[0m | time: 9.678s
[2K
| Adam | epoch: 013 | loss: 0.32948 - acc: 0.8561 -- iter: 0512/2015
[A[ATraining Step: 773  | total loss: [1m[32m0.33540[0m[0m | time: 10.295s
[2K
| Adam | epoch: 013 | loss: 0.33540 - acc: 0.8549 -- iter: 0544/2015
[A[ATraining Step: 774  | total loss: [1m[32m0.33954[0m[0m | time: 10.921s
[2K
| Adam | epoch: 013 | loss: 0.33954 - acc: 0.8569 -- iter: 0576/2015
[A[ATraining Step: 775  | total loss: [1m[32m0.36666[0m[0m | time: 11.513s
[2K
| Adam | epoch: 013 | loss: 0.36666 - acc: 0.8462 -- iter: 0608/2015
[A[ATraining Step: 776  | total loss: [1m[32m0.35803[0m[0m | time: 12.108s
[2K
| Adam | epoch: 013 | loss: 0.35803 - acc: 0.8522 -- iter: 0640/2015
[A[ATraining Step: 777  | total loss: [1m[32m0.36256[0m[0m | time: 12.703s
[2K
| Adam | epoch: 013 | loss: 0.36256 - acc: 0.8514 -- iter: 0672/2015
[A[ATraining Step: 778  | total loss: [1m[32m0.37105[0m[0m | time: 13.308s
[2K
| Adam | epoch: 013 | loss: 0.37105 - acc: 0.8475 -- iter: 0704/2015
[A[ATraining Step: 779  | total loss: [1m[32m0.36080[0m[0m | time: 13.907s
[2K
| Adam | epoch: 013 | loss: 0.36080 - acc: 0.8502 -- iter: 0736/2015
[A[ATraining Step: 780  | total loss: [1m[32m0.36397[0m[0m | time: 14.514s
[2K
| Adam | epoch: 013 | loss: 0.36397 - acc: 0.8465 -- iter: 0768/2015
[A[ATraining Step: 781  | total loss: [1m[32m0.35843[0m[0m | time: 15.133s
[2K
| Adam | epoch: 013 | loss: 0.35843 - acc: 0.8462 -- iter: 0800/2015
[A[ATraining Step: 782  | total loss: [1m[32m0.35137[0m[0m | time: 15.736s
[2K
| Adam | epoch: 013 | loss: 0.35137 - acc: 0.8491 -- iter: 0832/2015
[A[ATraining Step: 783  | total loss: [1m[32m0.35842[0m[0m | time: 16.355s
[2K
| Adam | epoch: 013 | loss: 0.35842 - acc: 0.8548 -- iter: 0864/2015
[A[ATraining Step: 784  | total loss: [1m[32m0.35746[0m[0m | time: 16.975s
[2K
| Adam | epoch: 013 | loss: 0.35746 - acc: 0.8599 -- iter: 0896/2015
[A[ATraining Step: 785  | total loss: [1m[32m0.34821[0m[0m | time: 17.622s
[2K
| Adam | epoch: 013 | loss: 0.34821 - acc: 0.8614 -- iter: 0928/2015
[A[ATraining Step: 786  | total loss: [1m[32m0.34299[0m[0m | time: 18.228s
[2K
| Adam | epoch: 013 | loss: 0.34299 - acc: 0.8659 -- iter: 0960/2015
[A[ATraining Step: 787  | total loss: [1m[32m0.33594[0m[0m | time: 18.821s
[2K
| Adam | epoch: 013 | loss: 0.33594 - acc: 0.8700 -- iter: 0992/2015
[A[ATraining Step: 788  | total loss: [1m[32m0.34235[0m[0m | time: 19.440s
[2K
| Adam | epoch: 013 | loss: 0.34235 - acc: 0.8673 -- iter: 1024/2015
[A[ATraining Step: 789  | total loss: [1m[32m0.33647[0m[0m | time: 20.042s
[2K
| Adam | epoch: 013 | loss: 0.33647 - acc: 0.8744 -- iter: 1056/2015
[A[ATraining Step: 790  | total loss: [1m[32m0.32179[0m[0m | time: 20.667s
[2K
| Adam | epoch: 013 | loss: 0.32179 - acc: 0.8775 -- iter: 1088/2015
[A[ATraining Step: 791  | total loss: [1m[32m0.32741[0m[0m | time: 21.264s
[2K
| Adam | epoch: 013 | loss: 0.32741 - acc: 0.8710 -- iter: 1120/2015
[A[ATraining Step: 792  | total loss: [1m[32m0.32464[0m[0m | time: 21.885s
[2K
| Adam | epoch: 013 | loss: 0.32464 - acc: 0.8746 -- iter: 1152/2015
[A[ATraining Step: 793  | total loss: [1m[32m0.33785[0m[0m | time: 22.506s
[2K
| Adam | epoch: 013 | loss: 0.33785 - acc: 0.8652 -- iter: 1184/2015
[A[ATraining Step: 794  | total loss: [1m[32m0.34450[0m[0m | time: 23.100s
[2K
| Adam | epoch: 013 | loss: 0.34450 - acc: 0.8662 -- iter: 1216/2015
[A[ATraining Step: 795  | total loss: [1m[32m0.33313[0m[0m | time: 23.704s
[2K
| Adam | epoch: 013 | loss: 0.33313 - acc: 0.8733 -- iter: 1248/2015
[A[ATraining Step: 796  | total loss: [1m[32m0.32742[0m[0m | time: 24.320s
[2K
| Adam | epoch: 013 | loss: 0.32742 - acc: 0.8766 -- iter: 1280/2015
[A[ATraining Step: 797  | total loss: [1m[32m0.32595[0m[0m | time: 24.924s
[2K
| Adam | epoch: 013 | loss: 0.32595 - acc: 0.8765 -- iter: 1312/2015
[A[ATraining Step: 798  | total loss: [1m[32m0.31853[0m[0m | time: 25.522s
[2K
| Adam | epoch: 013 | loss: 0.31853 - acc: 0.8794 -- iter: 1344/2015
[A[ATraining Step: 799  | total loss: [1m[32m0.30473[0m[0m | time: 26.119s
[2K
| Adam | epoch: 013 | loss: 0.30473 - acc: 0.8884 -- iter: 1376/2015
[A[ATraining Step: 800  | total loss: [1m[32m0.31354[0m[0m | time: 28.697s
[2K
| Adam | epoch: 013 | loss: 0.31354 - acc: 0.8808 | val_loss: 0.41850 - val_acc: 0.8175 -- iter: 1408/2015
--
Training Step: 801  | total loss: [1m[32m0.32068[0m[0m | time: 29.300s
[2K
| Adam | epoch: 013 | loss: 0.32068 - acc: 0.8740 -- iter: 1440/2015
[A[ATraining Step: 802  | total loss: [1m[32m0.31158[0m[0m | time: 29.891s
[2K
| Adam | epoch: 013 | loss: 0.31158 - acc: 0.8803 -- iter: 1472/2015
[A[ATraining Step: 803  | total loss: [1m[32m0.29575[0m[0m | time: 30.490s
[2K
| Adam | epoch: 013 | loss: 0.29575 - acc: 0.8860 -- iter: 1504/2015
[A[ATraining Step: 804  | total loss: [1m[32m0.29373[0m[0m | time: 31.088s
[2K
| Adam | epoch: 013 | loss: 0.29373 - acc: 0.8849 -- iter: 1536/2015
[A[ATraining Step: 805  | total loss: [1m[32m0.28371[0m[0m | time: 31.691s
[2K
| Adam | epoch: 013 | loss: 0.28371 - acc: 0.8902 -- iter: 1568/2015
[A[ATraining Step: 806  | total loss: [1m[32m0.28240[0m[0m | time: 32.291s
[2K
| Adam | epoch: 013 | loss: 0.28240 - acc: 0.8887 -- iter: 1600/2015
[A[ATraining Step: 807  | total loss: [1m[32m0.27636[0m[0m | time: 32.893s
[2K
| Adam | epoch: 013 | loss: 0.27636 - acc: 0.8935 -- iter: 1632/2015
[A[ATraining Step: 808  | total loss: [1m[32m0.27914[0m[0m | time: 33.500s
[2K
| Adam | epoch: 013 | loss: 0.27914 - acc: 0.8948 -- iter: 1664/2015
[A[ATraining Step: 809  | total loss: [1m[32m0.26823[0m[0m | time: 34.109s
[2K
| Adam | epoch: 013 | loss: 0.26823 - acc: 0.8991 -- iter: 1696/2015
[A[ATraining Step: 810  | total loss: [1m[32m0.25006[0m[0m | time: 34.714s
[2K
| Adam | epoch: 013 | loss: 0.25006 - acc: 0.9092 -- iter: 1728/2015
[A[ATraining Step: 811  | total loss: [1m[32m0.25586[0m[0m | time: 35.317s
[2K
| Adam | epoch: 013 | loss: 0.25586 - acc: 0.9089 -- iter: 1760/2015
[A[ATraining Step: 812  | total loss: [1m[32m0.27029[0m[0m | time: 35.912s
[2K
| Adam | epoch: 013 | loss: 0.27029 - acc: 0.8992 -- iter: 1792/2015
[A[ATraining Step: 813  | total loss: [1m[32m0.27613[0m[0m | time: 36.550s
[2K
| Adam | epoch: 013 | loss: 0.27613 - acc: 0.8906 -- iter: 1824/2015
[A[ATraining Step: 814  | total loss: [1m[32m0.27634[0m[0m | time: 37.182s
[2K
| Adam | epoch: 013 | loss: 0.27634 - acc: 0.8890 -- iter: 1856/2015
[A[ATraining Step: 815  | total loss: [1m[32m0.28839[0m[0m | time: 37.805s
[2K
| Adam | epoch: 013 | loss: 0.28839 - acc: 0.8814 -- iter: 1888/2015
[A[ATraining Step: 816  | total loss: [1m[32m0.28641[0m[0m | time: 38.398s
[2K
| Adam | epoch: 013 | loss: 0.28641 - acc: 0.8901 -- iter: 1920/2015
[A[ATraining Step: 817  | total loss: [1m[32m0.27860[0m[0m | time: 38.997s
[2K
| Adam | epoch: 013 | loss: 0.27860 - acc: 0.8917 -- iter: 1952/2015
[A[ATraining Step: 818  | total loss: [1m[32m0.29958[0m[0m | time: 39.593s
[2K
| Adam | epoch: 013 | loss: 0.29958 - acc: 0.8807 -- iter: 1984/2015
[A[ATraining Step: 819  | total loss: [1m[32m0.30949[0m[0m | time: 42.171s
[2K
| Adam | epoch: 013 | loss: 0.30949 - acc: 0.8739 | val_loss: 0.47420 - val_acc: 0.7905 -- iter: 2015/2015
--
Training Step: 820  | total loss: [1m[32m0.31347[0m[0m | time: 0.610s
[2K
| Adam | epoch: 014 | loss: 0.31347 - acc: 0.8708 -- iter: 0032/2015
[A[ATraining Step: 821  | total loss: [1m[32m0.33155[0m[0m | time: 1.218s
[2K
| Adam | epoch: 014 | loss: 0.33155 - acc: 0.8556 -- iter: 0064/2015
[A[ATraining Step: 822  | total loss: [1m[32m0.33127[0m[0m | time: 1.846s
[2K
| Adam | epoch: 014 | loss: 0.33127 - acc: 0.8513 -- iter: 0096/2015
[A[ATraining Step: 823  | total loss: [1m[32m0.34489[0m[0m | time: 2.470s
[2K
| Adam | epoch: 014 | loss: 0.34489 - acc: 0.8443 -- iter: 0128/2015
[A[ATraining Step: 824  | total loss: [1m[32m0.33355[0m[0m | time: 3.080s
[2K
| Adam | epoch: 014 | loss: 0.33355 - acc: 0.8474 -- iter: 0160/2015
[A[ATraining Step: 825  | total loss: [1m[32m0.32341[0m[0m | time: 3.687s
[2K
| Adam | epoch: 014 | loss: 0.32341 - acc: 0.8533 -- iter: 0192/2015
[A[ATraining Step: 826  | total loss: [1m[32m0.31616[0m[0m | time: 4.270s
[2K
| Adam | epoch: 014 | loss: 0.31616 - acc: 0.8586 -- iter: 0224/2015
[A[ATraining Step: 827  | total loss: [1m[32m0.30924[0m[0m | time: 4.900s
[2K
| Adam | epoch: 014 | loss: 0.30924 - acc: 0.8665 -- iter: 0256/2015
[A[ATraining Step: 828  | total loss: [1m[32m0.30848[0m[0m | time: 5.501s
[2K
| Adam | epoch: 014 | loss: 0.30848 - acc: 0.8673 -- iter: 0288/2015
[A[ATraining Step: 829  | total loss: [1m[32m0.31305[0m[0m | time: 6.102s
[2K
| Adam | epoch: 014 | loss: 0.31305 - acc: 0.8681 -- iter: 0320/2015
[A[ATraining Step: 830  | total loss: [1m[32m0.30616[0m[0m | time: 6.728s
[2K
| Adam | epoch: 014 | loss: 0.30616 - acc: 0.8781 -- iter: 0352/2015
[A[ATraining Step: 831  | total loss: [1m[32m0.29611[0m[0m | time: 7.338s
[2K
| Adam | epoch: 014 | loss: 0.29611 - acc: 0.8872 -- iter: 0384/2015
[A[ATraining Step: 832  | total loss: [1m[32m0.28969[0m[0m | time: 7.924s
[2K
| Adam | epoch: 014 | loss: 0.28969 - acc: 0.8920 -- iter: 0416/2015
[A[ATraining Step: 833  | total loss: [1m[32m0.28424[0m[0m | time: 8.529s
[2K
| Adam | epoch: 014 | loss: 0.28424 - acc: 0.8996 -- iter: 0448/2015
[A[ATraining Step: 834  | total loss: [1m[32m0.28263[0m[0m | time: 9.139s
[2K
| Adam | epoch: 014 | loss: 0.28263 - acc: 0.9034 -- iter: 0480/2015
[A[ATraining Step: 835  | total loss: [1m[32m0.28671[0m[0m | time: 9.734s
[2K
| Adam | epoch: 014 | loss: 0.28671 - acc: 0.9006 -- iter: 0512/2015
[A[ATraining Step: 836  | total loss: [1m[32m0.27556[0m[0m | time: 10.335s
[2K
| Adam | epoch: 014 | loss: 0.27556 - acc: 0.9011 -- iter: 0544/2015
[A[ATraining Step: 837  | total loss: [1m[32m0.28078[0m[0m | time: 10.955s
[2K
| Adam | epoch: 014 | loss: 0.28078 - acc: 0.9016 -- iter: 0576/2015
[A[ATraining Step: 838  | total loss: [1m[32m0.27149[0m[0m | time: 11.554s
[2K
| Adam | epoch: 014 | loss: 0.27149 - acc: 0.9083 -- iter: 0608/2015
[A[ATraining Step: 839  | total loss: [1m[32m0.27368[0m[0m | time: 12.146s
[2K
| Adam | epoch: 014 | loss: 0.27368 - acc: 0.9113 -- iter: 0640/2015
[A[ATraining Step: 840  | total loss: [1m[32m0.26868[0m[0m | time: 12.746s
[2K
| Adam | epoch: 014 | loss: 0.26868 - acc: 0.9108 -- iter: 0672/2015
[A[ATraining Step: 841  | total loss: [1m[32m0.27135[0m[0m | time: 13.345s
[2K
| Adam | epoch: 014 | loss: 0.27135 - acc: 0.9134 -- iter: 0704/2015
[A[ATraining Step: 842  | total loss: [1m[32m0.27931[0m[0m | time: 13.953s
[2K
| Adam | epoch: 014 | loss: 0.27931 - acc: 0.9096 -- iter: 0736/2015
[A[ATraining Step: 843  | total loss: [1m[32m0.27181[0m[0m | time: 14.551s
[2K
| Adam | epoch: 014 | loss: 0.27181 - acc: 0.9124 -- iter: 0768/2015
[A[ATraining Step: 844  | total loss: [1m[32m0.26994[0m[0m | time: 15.130s
[2K
| Adam | epoch: 014 | loss: 0.26994 - acc: 0.9086 -- iter: 0800/2015
[A[ATraining Step: 845  | total loss: [1m[32m0.28202[0m[0m | time: 15.721s
[2K
| Adam | epoch: 014 | loss: 0.28202 - acc: 0.8990 -- iter: 0832/2015
[A[ATraining Step: 846  | total loss: [1m[32m0.28564[0m[0m | time: 16.333s
[2K
| Adam | epoch: 014 | loss: 0.28564 - acc: 0.8966 -- iter: 0864/2015
[A[ATraining Step: 847  | total loss: [1m[32m0.30086[0m[0m | time: 16.932s
[2K
| Adam | epoch: 014 | loss: 0.30086 - acc: 0.8913 -- iter: 0896/2015
[A[ATraining Step: 848  | total loss: [1m[32m0.30090[0m[0m | time: 17.543s
[2K
| Adam | epoch: 014 | loss: 0.30090 - acc: 0.8897 -- iter: 0928/2015
[A[ATraining Step: 849  | total loss: [1m[32m0.32077[0m[0m | time: 18.154s
[2K
| Adam | epoch: 014 | loss: 0.32077 - acc: 0.8851 -- iter: 0960/2015
[A[ATraining Step: 850  | total loss: [1m[32m0.32699[0m[0m | time: 18.765s
[2K
| Adam | epoch: 014 | loss: 0.32699 - acc: 0.8810 -- iter: 0992/2015
[A[ATraining Step: 851  | total loss: [1m[32m0.32852[0m[0m | time: 19.360s
[2K
| Adam | epoch: 014 | loss: 0.32852 - acc: 0.8835 -- iter: 1024/2015
[A[ATraining Step: 852  | total loss: [1m[32m0.31099[0m[0m | time: 19.972s
[2K
| Adam | epoch: 014 | loss: 0.31099 - acc: 0.8952 -- iter: 1056/2015
[A[ATraining Step: 853  | total loss: [1m[32m0.30554[0m[0m | time: 20.576s
[2K
| Adam | epoch: 014 | loss: 0.30554 - acc: 0.8963 -- iter: 1088/2015
[A[ATraining Step: 854  | total loss: [1m[32m0.30696[0m[0m | time: 21.174s
[2K
| Adam | epoch: 014 | loss: 0.30696 - acc: 0.8941 -- iter: 1120/2015
[A[ATraining Step: 855  | total loss: [1m[32m0.29710[0m[0m | time: 21.813s
[2K
| Adam | epoch: 014 | loss: 0.29710 - acc: 0.8985 -- iter: 1152/2015
[A[ATraining Step: 856  | total loss: [1m[32m0.28825[0m[0m | time: 22.412s
[2K
| Adam | epoch: 014 | loss: 0.28825 - acc: 0.8961 -- iter: 1184/2015
[A[ATraining Step: 857  | total loss: [1m[32m0.29288[0m[0m | time: 23.024s
[2K
| Adam | epoch: 014 | loss: 0.29288 - acc: 0.8878 -- iter: 1216/2015
[A[ATraining Step: 858  | total loss: [1m[32m0.28591[0m[0m | time: 23.641s
[2K
| Adam | epoch: 014 | loss: 0.28591 - acc: 0.8927 -- iter: 1248/2015
[A[ATraining Step: 859  | total loss: [1m[32m0.30737[0m[0m | time: 24.225s
[2K
| Adam | epoch: 014 | loss: 0.30737 - acc: 0.8753 -- iter: 1280/2015
[A[ATraining Step: 860  | total loss: [1m[32m0.30621[0m[0m | time: 24.820s
[2K
| Adam | epoch: 014 | loss: 0.30621 - acc: 0.8784 -- iter: 1312/2015
[A[ATraining Step: 861  | total loss: [1m[32m0.29454[0m[0m | time: 25.435s
[2K
| Adam | epoch: 014 | loss: 0.29454 - acc: 0.8875 -- iter: 1344/2015
[A[ATraining Step: 862  | total loss: [1m[32m0.28793[0m[0m | time: 26.061s
[2K
| Adam | epoch: 014 | loss: 0.28793 - acc: 0.8893 -- iter: 1376/2015
[A[ATraining Step: 863  | total loss: [1m[32m0.29038[0m[0m | time: 26.663s
[2K
| Adam | epoch: 014 | loss: 0.29038 - acc: 0.8879 -- iter: 1408/2015
[A[ATraining Step: 864  | total loss: [1m[32m0.31139[0m[0m | time: 27.272s
[2K
| Adam | epoch: 014 | loss: 0.31139 - acc: 0.8835 -- iter: 1440/2015
[A[ATraining Step: 865  | total loss: [1m[32m0.29686[0m[0m | time: 27.875s
[2K
| Adam | epoch: 014 | loss: 0.29686 - acc: 0.8920 -- iter: 1472/2015
[A[ATraining Step: 866  | total loss: [1m[32m0.32537[0m[0m | time: 28.487s
[2K
| Adam | epoch: 014 | loss: 0.32537 - acc: 0.8747 -- iter: 1504/2015
[A[ATraining Step: 867  | total loss: [1m[32m0.31957[0m[0m | time: 29.113s
[2K
| Adam | epoch: 014 | loss: 0.31957 - acc: 0.8810 -- iter: 1536/2015
[A[ATraining Step: 868  | total loss: [1m[32m0.31694[0m[0m | time: 29.742s
[2K
| Adam | epoch: 014 | loss: 0.31694 - acc: 0.8835 -- iter: 1568/2015
[A[ATraining Step: 869  | total loss: [1m[32m0.32840[0m[0m | time: 30.334s
[2K
| Adam | epoch: 014 | loss: 0.32840 - acc: 0.8764 -- iter: 1600/2015
[A[ATraining Step: 870  | total loss: [1m[32m0.32280[0m[0m | time: 30.949s
[2K
| Adam | epoch: 014 | loss: 0.32280 - acc: 0.8763 -- iter: 1632/2015
[A[ATraining Step: 871  | total loss: [1m[32m0.30580[0m[0m | time: 31.557s
[2K
| Adam | epoch: 014 | loss: 0.30580 - acc: 0.8824 -- iter: 1664/2015
[A[ATraining Step: 872  | total loss: [1m[32m0.29079[0m[0m | time: 32.161s
[2K
| Adam | epoch: 014 | loss: 0.29079 - acc: 0.8879 -- iter: 1696/2015
[A[ATraining Step: 873  | total loss: [1m[32m0.28164[0m[0m | time: 32.762s
[2K
| Adam | epoch: 014 | loss: 0.28164 - acc: 0.8960 -- iter: 1728/2015
[A[ATraining Step: 874  | total loss: [1m[32m0.26635[0m[0m | time: 33.355s
[2K
| Adam | epoch: 014 | loss: 0.26635 - acc: 0.9064 -- iter: 1760/2015
[A[ATraining Step: 875  | total loss: [1m[32m0.28007[0m[0m | time: 33.946s
[2K
| Adam | epoch: 014 | loss: 0.28007 - acc: 0.9001 -- iter: 1792/2015
[A[ATraining Step: 876  | total loss: [1m[32m0.27157[0m[0m | time: 34.546s
[2K
| Adam | epoch: 014 | loss: 0.27157 - acc: 0.9007 -- iter: 1824/2015
[A[ATraining Step: 877  | total loss: [1m[32m0.27196[0m[0m | time: 35.150s
[2K
| Adam | epoch: 014 | loss: 0.27196 - acc: 0.8982 -- iter: 1856/2015
[A[ATraining Step: 878  | total loss: [1m[32m0.28023[0m[0m | time: 35.770s
[2K
| Adam | epoch: 014 | loss: 0.28023 - acc: 0.8958 -- iter: 1888/2015
[A[ATraining Step: 879  | total loss: [1m[32m0.27473[0m[0m | time: 36.371s
[2K
| Adam | epoch: 014 | loss: 0.27473 - acc: 0.9000 -- iter: 1920/2015
[A[ATraining Step: 880  | total loss: [1m[32m0.27488[0m[0m | time: 36.990s
[2K
| Adam | epoch: 014 | loss: 0.27488 - acc: 0.9038 -- iter: 1952/2015
[A[ATraining Step: 881  | total loss: [1m[32m0.26186[0m[0m | time: 37.584s
[2K
| Adam | epoch: 014 | loss: 0.26186 - acc: 0.9134 -- iter: 1984/2015
[A[ATraining Step: 882  | total loss: [1m[32m0.25668[0m[0m | time: 40.159s
[2K
| Adam | epoch: 014 | loss: 0.25668 - acc: 0.9158 | val_loss: 0.37634 - val_acc: 0.8571 -- iter: 2015/2015
--
Training Step: 883  | total loss: [1m[32m0.25667[0m[0m | time: 0.621s
[2K
| Adam | epoch: 015 | loss: 0.25667 - acc: 0.9055 -- iter: 0032/2015
[A[ATraining Step: 884  | total loss: [1m[32m0.25425[0m[0m | time: 1.220s
[2K
| Adam | epoch: 015 | loss: 0.25425 - acc: 0.9087 -- iter: 0064/2015
[A[ATraining Step: 885  | total loss: [1m[32m0.25970[0m[0m | time: 1.843s
[2K
| Adam | epoch: 015 | loss: 0.25970 - acc: 0.9053 -- iter: 0096/2015
[A[ATraining Step: 886  | total loss: [1m[32m0.25871[0m[0m | time: 2.467s
[2K
| Adam | epoch: 015 | loss: 0.25871 - acc: 0.9054 -- iter: 0128/2015
[A[ATraining Step: 887  | total loss: [1m[32m0.26029[0m[0m | time: 3.068s
[2K
| Adam | epoch: 015 | loss: 0.26029 - acc: 0.9024 -- iter: 0160/2015
[A[ATraining Step: 888  | total loss: [1m[32m0.27142[0m[0m | time: 3.663s
[2K
| Adam | epoch: 015 | loss: 0.27142 - acc: 0.8965 -- iter: 0192/2015
[A[ATraining Step: 889  | total loss: [1m[32m0.27159[0m[0m | time: 4.277s
[2K
| Adam | epoch: 015 | loss: 0.27159 - acc: 0.8943 -- iter: 0224/2015
[A[ATraining Step: 890  | total loss: [1m[32m0.26401[0m[0m | time: 4.886s
[2K
| Adam | epoch: 015 | loss: 0.26401 - acc: 0.9018 -- iter: 0256/2015
[A[ATraining Step: 891  | total loss: [1m[32m0.26203[0m[0m | time: 5.486s
[2K
| Adam | epoch: 015 | loss: 0.26203 - acc: 0.9022 -- iter: 0288/2015
[A[ATraining Step: 892  | total loss: [1m[32m0.26107[0m[0m | time: 6.083s
[2K
| Adam | epoch: 015 | loss: 0.26107 - acc: 0.9026 -- iter: 0320/2015
[A[ATraining Step: 893  | total loss: [1m[32m0.25800[0m[0m | time: 6.703s
[2K
| Adam | epoch: 015 | loss: 0.25800 - acc: 0.9030 -- iter: 0352/2015
[A[ATraining Step: 894  | total loss: [1m[32m0.24455[0m[0m | time: 7.303s
[2K
| Adam | epoch: 015 | loss: 0.24455 - acc: 0.9127 -- iter: 0384/2015
[A[ATraining Step: 895  | total loss: [1m[32m0.24192[0m[0m | time: 7.912s
[2K
| Adam | epoch: 015 | loss: 0.24192 - acc: 0.9089 -- iter: 0416/2015
[A[ATraining Step: 896  | total loss: [1m[32m0.25637[0m[0m | time: 8.531s
[2K
| Adam | epoch: 015 | loss: 0.25637 - acc: 0.8987 -- iter: 0448/2015
[A[ATraining Step: 897  | total loss: [1m[32m0.26399[0m[0m | time: 9.133s
[2K
| Adam | epoch: 015 | loss: 0.26399 - acc: 0.8991 -- iter: 0480/2015
[A[ATraining Step: 898  | total loss: [1m[32m0.25456[0m[0m | time: 9.748s
[2K
| Adam | epoch: 015 | loss: 0.25456 - acc: 0.9061 -- iter: 0512/2015
[A[ATraining Step: 899  | total loss: [1m[32m0.25672[0m[0m | time: 10.347s
[2K
| Adam | epoch: 015 | loss: 0.25672 - acc: 0.8999 -- iter: 0544/2015
[A[ATraining Step: 900  | total loss: [1m[32m0.26953[0m[0m | time: 10.944s
[2K
| Adam | epoch: 015 | loss: 0.26953 - acc: 0.8880 -- iter: 0576/2015
[A[ATraining Step: 901  | total loss: [1m[32m0.26906[0m[0m | time: 11.542s
[2K
| Adam | epoch: 015 | loss: 0.26906 - acc: 0.8929 -- iter: 0608/2015
[A[ATraining Step: 902  | total loss: [1m[32m0.26688[0m[0m | time: 12.182s
[2K
| Adam | epoch: 015 | loss: 0.26688 - acc: 0.8943 -- iter: 0640/2015
[A[ATraining Step: 903  | total loss: [1m[32m0.27394[0m[0m | time: 12.790s
[2K
| Adam | epoch: 015 | loss: 0.27394 - acc: 0.8924 -- iter: 0672/2015
[A[ATraining Step: 904  | total loss: [1m[32m0.26164[0m[0m | time: 13.392s
[2K
| Adam | epoch: 015 | loss: 0.26164 - acc: 0.9000 -- iter: 0704/2015
[A[ATraining Step: 905  | total loss: [1m[32m0.26174[0m[0m | time: 13.981s
[2K
| Adam | epoch: 015 | loss: 0.26174 - acc: 0.8975 -- iter: 0736/2015
[A[ATraining Step: 906  | total loss: [1m[32m0.26565[0m[0m | time: 14.577s
[2K
| Adam | epoch: 015 | loss: 0.26565 - acc: 0.8984 -- iter: 0768/2015
[A[ATraining Step: 907  | total loss: [1m[32m0.28824[0m[0m | time: 15.179s
[2K
| Adam | epoch: 015 | loss: 0.28824 - acc: 0.8929 -- iter: 0800/2015
[A[ATraining Step: 908  | total loss: [1m[32m0.28560[0m[0m | time: 15.780s
[2K
| Adam | epoch: 015 | loss: 0.28560 - acc: 0.8942 -- iter: 0832/2015
[A[ATraining Step: 909  | total loss: [1m[32m0.29425[0m[0m | time: 16.381s
[2K
| Adam | epoch: 015 | loss: 0.29425 - acc: 0.8892 -- iter: 0864/2015
[A[ATraining Step: 910  | total loss: [1m[32m0.29510[0m[0m | time: 17.014s
[2K
| Adam | epoch: 015 | loss: 0.29510 - acc: 0.8846 -- iter: 0896/2015
[A[ATraining Step: 911  | total loss: [1m[32m0.28005[0m[0m | time: 17.613s
[2K
| Adam | epoch: 015 | loss: 0.28005 - acc: 0.8962 -- iter: 0928/2015
[A[ATraining Step: 912  | total loss: [1m[32m0.27476[0m[0m | time: 18.222s
[2K
| Adam | epoch: 015 | loss: 0.27476 - acc: 0.8972 -- iter: 0960/2015
[A[ATraining Step: 913  | total loss: [1m[32m0.27648[0m[0m | time: 18.831s
[2K
| Adam | epoch: 015 | loss: 0.27648 - acc: 0.8950 -- iter: 0992/2015
[A[ATraining Step: 914  | total loss: [1m[32m0.27528[0m[0m | time: 19.435s
[2K
| Adam | epoch: 015 | loss: 0.27528 - acc: 0.8992 -- iter: 1024/2015
[A[ATraining Step: 915  | total loss: [1m[32m0.26305[0m[0m | time: 20.027s
[2K
| Adam | epoch: 015 | loss: 0.26305 - acc: 0.9031 -- iter: 1056/2015
[A[ATraining Step: 916  | total loss: [1m[32m0.27361[0m[0m | time: 20.631s
[2K
| Adam | epoch: 015 | loss: 0.27361 - acc: 0.8971 -- iter: 1088/2015
[A[ATraining Step: 917  | total loss: [1m[32m0.27222[0m[0m | time: 21.230s
[2K
| Adam | epoch: 015 | loss: 0.27222 - acc: 0.9012 -- iter: 1120/2015
[A[ATraining Step: 918  | total loss: [1m[32m0.27725[0m[0m | time: 21.835s
[2K
| Adam | epoch: 015 | loss: 0.27725 - acc: 0.8923 -- iter: 1152/2015
[A[ATraining Step: 919  | total loss: [1m[32m0.26457[0m[0m | time: 22.435s
[2K
| Adam | epoch: 015 | loss: 0.26457 - acc: 0.8999 -- iter: 1184/2015
[A[ATraining Step: 920  | total loss: [1m[32m0.24573[0m[0m | time: 23.034s
[2K
| Adam | epoch: 015 | loss: 0.24573 - acc: 0.9099 -- iter: 1216/2015
[A[ATraining Step: 921  | total loss: [1m[32m0.25614[0m[0m | time: 23.650s
[2K
| Adam | epoch: 015 | loss: 0.25614 - acc: 0.9065 -- iter: 1248/2015
[A[ATraining Step: 922  | total loss: [1m[32m0.24889[0m[0m | time: 24.275s
[2K
| Adam | epoch: 015 | loss: 0.24889 - acc: 0.9064 -- iter: 1280/2015
[A[ATraining Step: 923  | total loss: [1m[32m0.23770[0m[0m | time: 24.885s
[2K
| Adam | epoch: 015 | loss: 0.23770 - acc: 0.9095 -- iter: 1312/2015
[A[ATraining Step: 924  | total loss: [1m[32m0.26140[0m[0m | time: 25.489s
[2K
| Adam | epoch: 015 | loss: 0.26140 - acc: 0.8998 -- iter: 1344/2015
[A[ATraining Step: 925  | total loss: [1m[32m0.27240[0m[0m | time: 26.090s
[2K
| Adam | epoch: 015 | loss: 0.27240 - acc: 0.8880 -- iter: 1376/2015
[A[ATraining Step: 926  | total loss: [1m[32m0.26887[0m[0m | time: 26.702s
[2K
| Adam | epoch: 015 | loss: 0.26887 - acc: 0.8867 -- iter: 1408/2015
[A[ATraining Step: 927  | total loss: [1m[32m0.25902[0m[0m | time: 27.311s
[2K
| Adam | epoch: 015 | loss: 0.25902 - acc: 0.8918 -- iter: 1440/2015
[A[ATraining Step: 928  | total loss: [1m[32m0.25050[0m[0m | time: 27.930s
[2K
| Adam | epoch: 015 | loss: 0.25050 - acc: 0.8932 -- iter: 1472/2015
[A[ATraining Step: 929  | total loss: [1m[32m0.23669[0m[0m | time: 28.555s
[2K
| Adam | epoch: 015 | loss: 0.23669 - acc: 0.9008 -- iter: 1504/2015
[A[ATraining Step: 930  | total loss: [1m[32m0.23912[0m[0m | time: 29.164s
[2K
| Adam | epoch: 015 | loss: 0.23912 - acc: 0.8982 -- iter: 1536/2015
[A[ATraining Step: 931  | total loss: [1m[32m0.24872[0m[0m | time: 29.771s
[2K
| Adam | epoch: 015 | loss: 0.24872 - acc: 0.8990 -- iter: 1568/2015
[A[ATraining Step: 932  | total loss: [1m[32m0.24292[0m[0m | time: 30.368s
[2K
| Adam | epoch: 015 | loss: 0.24292 - acc: 0.9060 -- iter: 1600/2015
[A[ATraining Step: 933  | total loss: [1m[32m0.25903[0m[0m | time: 30.977s
[2K
| Adam | epoch: 015 | loss: 0.25903 - acc: 0.8997 -- iter: 1632/2015
[A[ATraining Step: 934  | total loss: [1m[32m0.25167[0m[0m | time: 31.575s
[2K
| Adam | epoch: 015 | loss: 0.25167 - acc: 0.9035 -- iter: 1664/2015
[A[ATraining Step: 935  | total loss: [1m[32m0.25572[0m[0m | time: 32.169s
[2K
| Adam | epoch: 015 | loss: 0.25572 - acc: 0.9007 -- iter: 1696/2015
[A[ATraining Step: 936  | total loss: [1m[32m0.24609[0m[0m | time: 32.778s
[2K
| Adam | epoch: 015 | loss: 0.24609 - acc: 0.9044 -- iter: 1728/2015
[A[ATraining Step: 937  | total loss: [1m[32m0.25227[0m[0m | time: 33.369s
[2K
| Adam | epoch: 015 | loss: 0.25227 - acc: 0.8952 -- iter: 1760/2015
[A[ATraining Step: 938  | total loss: [1m[32m0.24683[0m[0m | time: 33.972s
[2K
| Adam | epoch: 015 | loss: 0.24683 - acc: 0.8994 -- iter: 1792/2015
[A[ATraining Step: 939  | total loss: [1m[32m0.25038[0m[0m | time: 34.577s
[2K
| Adam | epoch: 015 | loss: 0.25038 - acc: 0.8970 -- iter: 1824/2015
[A[ATraining Step: 940  | total loss: [1m[32m0.24885[0m[0m | time: 35.174s
[2K
| Adam | epoch: 015 | loss: 0.24885 - acc: 0.8979 -- iter: 1856/2015
[A[ATraining Step: 941  | total loss: [1m[32m0.25033[0m[0m | time: 35.764s
[2K
| Adam | epoch: 015 | loss: 0.25033 - acc: 0.8956 -- iter: 1888/2015
[A[ATraining Step: 942  | total loss: [1m[32m0.24498[0m[0m | time: 36.372s
[2K
| Adam | epoch: 015 | loss: 0.24498 - acc: 0.8998 -- iter: 1920/2015
[A[ATraining Step: 943  | total loss: [1m[32m0.23371[0m[0m | time: 36.992s
[2K
| Adam | epoch: 015 | loss: 0.23371 - acc: 0.9098 -- iter: 1952/2015
[A[ATraining Step: 944  | total loss: [1m[32m0.22760[0m[0m | time: 37.588s
[2K
| Adam | epoch: 015 | loss: 0.22760 - acc: 0.9157 -- iter: 1984/2015
[A[ATraining Step: 945  | total loss: [1m[32m0.22440[0m[0m | time: 40.186s
[2K
| Adam | epoch: 015 | loss: 0.22440 - acc: 0.9179 | val_loss: 0.37875 - val_acc: 0.8476 -- iter: 2015/2015
--
Training Step: 946  | total loss: [1m[32m0.21126[0m[0m | time: 0.603s
[2K
| Adam | epoch: 016 | loss: 0.21126 - acc: 0.9261 -- iter: 0032/2015
[A[ATraining Step: 947  | total loss: [1m[32m0.20006[0m[0m | time: 1.246s
[2K
| Adam | epoch: 016 | loss: 0.20006 - acc: 0.9335 -- iter: 0064/2015
[A[ATraining Step: 948  | total loss: [1m[32m0.20147[0m[0m | time: 1.854s
[2K
| Adam | epoch: 016 | loss: 0.20147 - acc: 0.9308 -- iter: 0096/2015
[A[ATraining Step: 949  | total loss: [1m[32m0.21656[0m[0m | time: 2.461s
[2K
| Adam | epoch: 016 | loss: 0.21656 - acc: 0.9252 -- iter: 0128/2015
[A[ATraining Step: 950  | total loss: [1m[32m0.20019[0m[0m | time: 3.055s
[2K
| Adam | epoch: 016 | loss: 0.20019 - acc: 0.9327 -- iter: 0160/2015
[A[ATraining Step: 951  | total loss: [1m[32m0.20933[0m[0m | time: 3.655s
[2K
| Adam | epoch: 016 | loss: 0.20933 - acc: 0.9332 -- iter: 0192/2015
[A[ATraining Step: 952  | total loss: [1m[32m0.21215[0m[0m | time: 4.249s
[2K
| Adam | epoch: 016 | loss: 0.21215 - acc: 0.9305 -- iter: 0224/2015
[A[ATraining Step: 953  | total loss: [1m[32m0.19657[0m[0m | time: 4.872s
[2K
| Adam | epoch: 016 | loss: 0.19657 - acc: 0.9374 -- iter: 0256/2015
[A[ATraining Step: 954  | total loss: [1m[32m0.20696[0m[0m | time: 5.479s
[2K
| Adam | epoch: 016 | loss: 0.20696 - acc: 0.9312 -- iter: 0288/2015
[A[ATraining Step: 955  | total loss: [1m[32m0.22407[0m[0m | time: 6.073s
[2K
| Adam | epoch: 016 | loss: 0.22407 - acc: 0.9256 -- iter: 0320/2015
[A[ATraining Step: 956  | total loss: [1m[32m0.22107[0m[0m | time: 6.683s
[2K
| Adam | epoch: 016 | loss: 0.22107 - acc: 0.9268 -- iter: 0352/2015
[A[ATraining Step: 957  | total loss: [1m[32m0.22512[0m[0m | time: 7.278s
[2K
| Adam | epoch: 016 | loss: 0.22512 - acc: 0.9216 -- iter: 0384/2015
[A[ATraining Step: 958  | total loss: [1m[32m0.23625[0m[0m | time: 7.881s
[2K
| Adam | epoch: 016 | loss: 0.23625 - acc: 0.9169 -- iter: 0416/2015
[A[ATraining Step: 959  | total loss: [1m[32m0.25881[0m[0m | time: 8.488s
[2K
| Adam | epoch: 016 | loss: 0.25881 - acc: 0.9065 -- iter: 0448/2015
[A[ATraining Step: 960  | total loss: [1m[32m0.25099[0m[0m | time: 9.081s
[2K
| Adam | epoch: 016 | loss: 0.25099 - acc: 0.9062 -- iter: 0480/2015
[A[ATraining Step: 961  | total loss: [1m[32m0.24269[0m[0m | time: 9.669s
[2K
| Adam | epoch: 016 | loss: 0.24269 - acc: 0.9123 -- iter: 0512/2015
[A[ATraining Step: 962  | total loss: [1m[32m0.23887[0m[0m | time: 10.270s
[2K
| Adam | epoch: 016 | loss: 0.23887 - acc: 0.9117 -- iter: 0544/2015
[A[ATraining Step: 963  | total loss: [1m[32m0.23141[0m[0m | time: 10.880s
[2K
| Adam | epoch: 016 | loss: 0.23141 - acc: 0.9143 -- iter: 0576/2015
[A[ATraining Step: 964  | total loss: [1m[32m0.24156[0m[0m | time: 11.491s
[2K
| Adam | epoch: 016 | loss: 0.24156 - acc: 0.9135 -- iter: 0608/2015
[A[ATraining Step: 965  | total loss: [1m[32m0.24433[0m[0m | time: 12.119s
[2K
| Adam | epoch: 016 | loss: 0.24433 - acc: 0.9128 -- iter: 0640/2015
[A[ATraining Step: 966  | total loss: [1m[32m0.24082[0m[0m | time: 12.720s
[2K
| Adam | epoch: 016 | loss: 0.24082 - acc: 0.9090 -- iter: 0672/2015
[A[ATraining Step: 967  | total loss: [1m[32m0.23016[0m[0m | time: 13.327s
[2K
| Adam | epoch: 016 | loss: 0.23016 - acc: 0.9150 -- iter: 0704/2015
[A[ATraining Step: 968  | total loss: [1m[32m0.21840[0m[0m | time: 13.928s
[2K
| Adam | epoch: 016 | loss: 0.21840 - acc: 0.9203 -- iter: 0736/2015
[A[ATraining Step: 969  | total loss: [1m[32m0.23186[0m[0m | time: 14.532s
[2K
| Adam | epoch: 016 | loss: 0.23186 - acc: 0.9189 -- iter: 0768/2015
[A[ATraining Step: 970  | total loss: [1m[32m0.22452[0m[0m | time: 15.132s
[2K
| Adam | epoch: 016 | loss: 0.22452 - acc: 0.9208 -- iter: 0800/2015
[A[ATraining Step: 971  | total loss: [1m[32m0.21402[0m[0m | time: 15.730s
[2K
| Adam | epoch: 016 | loss: 0.21402 - acc: 0.9225 -- iter: 0832/2015
[A[ATraining Step: 972  | total loss: [1m[32m0.25384[0m[0m | time: 16.341s
[2K
| Adam | epoch: 016 | loss: 0.25384 - acc: 0.9115 -- iter: 0864/2015
[A[ATraining Step: 973  | total loss: [1m[32m0.27139[0m[0m | time: 16.961s
[2K
| Adam | epoch: 016 | loss: 0.27139 - acc: 0.9078 -- iter: 0896/2015
[A[ATraining Step: 974  | total loss: [1m[32m0.27194[0m[0m | time: 17.558s
[2K
| Adam | epoch: 016 | loss: 0.27194 - acc: 0.9045 -- iter: 0928/2015
[A[ATraining Step: 975  | total loss: [1m[32m0.26594[0m[0m | time: 18.164s
[2K
| Adam | epoch: 016 | loss: 0.26594 - acc: 0.9047 -- iter: 0960/2015
[A[ATraining Step: 976  | total loss: [1m[32m0.26505[0m[0m | time: 18.773s
[2K
| Adam | epoch: 016 | loss: 0.26505 - acc: 0.9049 -- iter: 0992/2015
[A[ATraining Step: 977  | total loss: [1m[32m0.26135[0m[0m | time: 19.387s
[2K
| Adam | epoch: 016 | loss: 0.26135 - acc: 0.9081 -- iter: 1024/2015
[A[ATraining Step: 978  | total loss: [1m[32m0.25279[0m[0m | time: 19.990s
[2K
| Adam | epoch: 016 | loss: 0.25279 - acc: 0.9142 -- iter: 1056/2015
[A[ATraining Step: 979  | total loss: [1m[32m0.25409[0m[0m | time: 20.591s
[2K
| Adam | epoch: 016 | loss: 0.25409 - acc: 0.9103 -- iter: 1088/2015
[A[ATraining Step: 980  | total loss: [1m[32m0.27108[0m[0m | time: 21.209s
[2K
| Adam | epoch: 016 | loss: 0.27108 - acc: 0.9005 -- iter: 1120/2015
[A[ATraining Step: 981  | total loss: [1m[32m0.25387[0m[0m | time: 21.813s
[2K
| Adam | epoch: 016 | loss: 0.25387 - acc: 0.9104 -- iter: 1152/2015
[A[ATraining Step: 982  | total loss: [1m[32m0.25300[0m[0m | time: 22.417s
[2K
| Adam | epoch: 016 | loss: 0.25300 - acc: 0.9100 -- iter: 1184/2015
[A[ATraining Step: 983  | total loss: [1m[32m0.24679[0m[0m | time: 23.041s
[2K
| Adam | epoch: 016 | loss: 0.24679 - acc: 0.9096 -- iter: 1216/2015
[A[ATraining Step: 984  | total loss: [1m[32m0.25743[0m[0m | time: 23.639s
[2K
| Adam | epoch: 016 | loss: 0.25743 - acc: 0.8999 -- iter: 1248/2015
[A[ATraining Step: 985  | total loss: [1m[32m0.25682[0m[0m | time: 24.245s
[2K
| Adam | epoch: 016 | loss: 0.25682 - acc: 0.9006 -- iter: 1280/2015
[A[ATraining Step: 986  | total loss: [1m[32m0.25431[0m[0m | time: 24.858s
[2K
| Adam | epoch: 016 | loss: 0.25431 - acc: 0.8980 -- iter: 1312/2015
[A[ATraining Step: 987  | total loss: [1m[32m0.25469[0m[0m | time: 25.466s
[2K
| Adam | epoch: 016 | loss: 0.25469 - acc: 0.8957 -- iter: 1344/2015
[A[ATraining Step: 988  | total loss: [1m[32m0.24482[0m[0m | time: 26.082s
[2K
| Adam | epoch: 016 | loss: 0.24482 - acc: 0.8999 -- iter: 1376/2015
[A[ATraining Step: 989  | total loss: [1m[32m0.24353[0m[0m | time: 26.710s
[2K
| Adam | epoch: 016 | loss: 0.24353 - acc: 0.9005 -- iter: 1408/2015
[A[ATraining Step: 990  | total loss: [1m[32m0.25330[0m[0m | time: 27.337s
[2K
| Adam | epoch: 016 | loss: 0.25330 - acc: 0.8917 -- iter: 1440/2015
[A[ATraining Step: 991  | total loss: [1m[32m0.23830[0m[0m | time: 27.955s
[2K
| Adam | epoch: 016 | loss: 0.23830 - acc: 0.9025 -- iter: 1472/2015
[A[ATraining Step: 992  | total loss: [1m[32m0.23351[0m[0m | time: 28.568s
[2K
| Adam | epoch: 016 | loss: 0.23351 - acc: 0.9060 -- iter: 1504/2015
[A[ATraining Step: 993  | total loss: [1m[32m0.22137[0m[0m | time: 29.177s
[2K
| Adam | epoch: 016 | loss: 0.22137 - acc: 0.9092 -- iter: 1536/2015
[A[ATraining Step: 994  | total loss: [1m[32m0.22610[0m[0m | time: 29.775s
[2K
| Adam | epoch: 016 | loss: 0.22610 - acc: 0.9058 -- iter: 1568/2015
[A[ATraining Step: 995  | total loss: [1m[32m0.22565[0m[0m | time: 30.386s
[2K
| Adam | epoch: 016 | loss: 0.22565 - acc: 0.9121 -- iter: 1600/2015
[A[ATraining Step: 996  | total loss: [1m[32m0.22674[0m[0m | time: 31.028s
[2K
| Adam | epoch: 016 | loss: 0.22674 - acc: 0.9146 -- iter: 1632/2015
[A[ATraining Step: 997  | total loss: [1m[32m0.20960[0m[0m | time: 31.631s
[2K
| Adam | epoch: 016 | loss: 0.20960 - acc: 0.9231 -- iter: 1664/2015
[A[ATraining Step: 998  | total loss: [1m[32m0.19812[0m[0m | time: 32.238s
[2K
| Adam | epoch: 016 | loss: 0.19812 - acc: 0.9308 -- iter: 1696/2015
[A[ATraining Step: 999  | total loss: [1m[32m0.19541[0m[0m | time: 32.838s
[2K
| Adam | epoch: 016 | loss: 0.19541 - acc: 0.9315 -- iter: 1728/2015
[A[ATraining Step: 1000  | total loss: [1m[32m0.23172[0m[0m | time: 35.419s
[2K
| Adam | epoch: 016 | loss: 0.23172 - acc: 0.9227 | val_loss: 0.41185 - val_acc: 0.8429 -- iter: 1760/2015
--
Training Step: 1001  | total loss: [1m[32m0.22182[0m[0m | time: 36.029s
[2K
| Adam | epoch: 016 | loss: 0.22182 - acc: 0.9273 -- iter: 1792/2015
[A[ATraining Step: 1002  | total loss: [1m[32m0.23653[0m[0m | time: 36.643s
[2K
| Adam | epoch: 016 | loss: 0.23653 - acc: 0.9190 -- iter: 1824/2015
[A[ATraining Step: 1003  | total loss: [1m[32m0.23194[0m[0m | time: 37.250s
[2K
| Adam | epoch: 016 | loss: 0.23194 - acc: 0.9239 -- iter: 1856/2015
[A[ATraining Step: 1004  | total loss: [1m[32m0.22752[0m[0m | time: 37.849s
[2K
| Adam | epoch: 016 | loss: 0.22752 - acc: 0.9253 -- iter: 1888/2015
[A[ATraining Step: 1005  | total loss: [1m[32m0.21207[0m[0m | time: 38.452s
[2K
| Adam | epoch: 016 | loss: 0.21207 - acc: 0.9328 -- iter: 1920/2015
[A[ATraining Step: 1006  | total loss: [1m[32m0.20976[0m[0m | time: 39.054s
[2K
| Adam | epoch: 016 | loss: 0.20976 - acc: 0.9364 -- iter: 1952/2015
[A[ATraining Step: 1007  | total loss: [1m[32m0.20160[0m[0m | time: 39.652s
[2K
| Adam | epoch: 016 | loss: 0.20160 - acc: 0.9396 -- iter: 1984/2015
[A[ATraining Step: 1008  | total loss: [1m[32m0.20302[0m[0m | time: 42.252s
[2K
| Adam | epoch: 016 | loss: 0.20302 - acc: 0.9394 | val_loss: 0.39501 - val_acc: 0.8460 -- iter: 2015/2015
--
Training Step: 1009  | total loss: [1m[32m0.19194[0m[0m | time: 0.622s
[2K
| Adam | epoch: 017 | loss: 0.19194 - acc: 0.9455 -- iter: 0032/2015
[A[ATraining Step: 1010  | total loss: [1m[32m0.18641[0m[0m | time: 1.224s
[2K
| Adam | epoch: 017 | loss: 0.18641 - acc: 0.9478 -- iter: 0064/2015
[A[ATraining Step: 1011  | total loss: [1m[32m0.18005[0m[0m | time: 1.824s
[2K
| Adam | epoch: 017 | loss: 0.18005 - acc: 0.9499 -- iter: 0096/2015
[A[ATraining Step: 1012  | total loss: [1m[32m0.19742[0m[0m | time: 2.429s
[2K
| Adam | epoch: 017 | loss: 0.19742 - acc: 0.9393 -- iter: 0128/2015
[A[ATraining Step: 1013  | total loss: [1m[32m0.19774[0m[0m | time: 3.065s
[2K
| Adam | epoch: 017 | loss: 0.19774 - acc: 0.9422 -- iter: 0160/2015
[A[ATraining Step: 1014  | total loss: [1m[32m0.20592[0m[0m | time: 3.683s
[2K
| Adam | epoch: 017 | loss: 0.20592 - acc: 0.9417 -- iter: 0192/2015
[A[ATraining Step: 1015  | total loss: [1m[32m0.19529[0m[0m | time: 4.279s
[2K
| Adam | epoch: 017 | loss: 0.19529 - acc: 0.9444 -- iter: 0224/2015
[A[ATraining Step: 1016  | total loss: [1m[32m0.18796[0m[0m | time: 4.877s
[2K
| Adam | epoch: 017 | loss: 0.18796 - acc: 0.9438 -- iter: 0256/2015
[A[ATraining Step: 1017  | total loss: [1m[32m0.20408[0m[0m | time: 5.477s
[2K
| Adam | epoch: 017 | loss: 0.20408 - acc: 0.9400 -- iter: 0288/2015
[A[ATraining Step: 1018  | total loss: [1m[32m0.19369[0m[0m | time: 6.080s
[2K
| Adam | epoch: 017 | loss: 0.19369 - acc: 0.9429 -- iter: 0320/2015
[A[ATraining Step: 1019  | total loss: [1m[32m0.18919[0m[0m | time: 6.722s
[2K
| Adam | epoch: 017 | loss: 0.18919 - acc: 0.9455 -- iter: 0352/2015
[A[ATraining Step: 1020  | total loss: [1m[32m0.18403[0m[0m | time: 7.327s
[2K
| Adam | epoch: 017 | loss: 0.18403 - acc: 0.9509 -- iter: 0384/2015
[A[ATraining Step: 1021  | total loss: [1m[32m0.18927[0m[0m | time: 7.936s
[2K
| Adam | epoch: 017 | loss: 0.18927 - acc: 0.9527 -- iter: 0416/2015
[A[ATraining Step: 1022  | total loss: [1m[32m0.18663[0m[0m | time: 8.565s
[2K
| Adam | epoch: 017 | loss: 0.18663 - acc: 0.9512 -- iter: 0448/2015
[A[ATraining Step: 1023  | total loss: [1m[32m0.18358[0m[0m | time: 9.168s
[2K
| Adam | epoch: 017 | loss: 0.18358 - acc: 0.9498 -- iter: 0480/2015
[A[ATraining Step: 1024  | total loss: [1m[32m0.20092[0m[0m | time: 9.762s
[2K
| Adam | epoch: 017 | loss: 0.20092 - acc: 0.9419 -- iter: 0512/2015
[A[ATraining Step: 1025  | total loss: [1m[32m0.21512[0m[0m | time: 10.370s
[2K
| Adam | epoch: 017 | loss: 0.21512 - acc: 0.9381 -- iter: 0544/2015
[A[ATraining Step: 1026  | total loss: [1m[32m0.21857[0m[0m | time: 10.975s
[2K
| Adam | epoch: 017 | loss: 0.21857 - acc: 0.9318 -- iter: 0576/2015
[A[ATraining Step: 1027  | total loss: [1m[32m0.23405[0m[0m | time: 11.611s
[2K
| Adam | epoch: 017 | loss: 0.23405 - acc: 0.9167 -- iter: 0608/2015
[A[ATraining Step: 1028  | total loss: [1m[32m0.23488[0m[0m | time: 12.235s
[2K
| Adam | epoch: 017 | loss: 0.23488 - acc: 0.9157 -- iter: 0640/2015
[A[ATraining Step: 1029  | total loss: [1m[32m0.23815[0m[0m | time: 12.854s
[2K
| Adam | epoch: 017 | loss: 0.23815 - acc: 0.9116 -- iter: 0672/2015
[A[ATraining Step: 1030  | total loss: [1m[32m0.25199[0m[0m | time: 13.446s
[2K
| Adam | epoch: 017 | loss: 0.25199 - acc: 0.9017 -- iter: 0704/2015
[A[ATraining Step: 1031  | total loss: [1m[32m0.24067[0m[0m | time: 14.047s
[2K
| Adam | epoch: 017 | loss: 0.24067 - acc: 0.9084 -- iter: 0736/2015
[A[ATraining Step: 1032  | total loss: [1m[32m0.24498[0m[0m | time: 14.671s
[2K
| Adam | epoch: 017 | loss: 0.24498 - acc: 0.9113 -- iter: 0768/2015
[A[ATraining Step: 1033  | total loss: [1m[32m0.23311[0m[0m | time: 15.303s
[2K
| Adam | epoch: 017 | loss: 0.23311 - acc: 0.9202 -- iter: 0800/2015
[A[ATraining Step: 1034  | total loss: [1m[32m0.24453[0m[0m | time: 15.902s
[2K
| Adam | epoch: 017 | loss: 0.24453 - acc: 0.9157 -- iter: 0832/2015
[A[ATraining Step: 1035  | total loss: [1m[32m0.23752[0m[0m | time: 16.505s
[2K
| Adam | epoch: 017 | loss: 0.23752 - acc: 0.9210 -- iter: 0864/2015
[A[ATraining Step: 1036  | total loss: [1m[32m0.23162[0m[0m | time: 17.105s
[2K
| Adam | epoch: 017 | loss: 0.23162 - acc: 0.9226 -- iter: 0896/2015
[A[ATraining Step: 1037  | total loss: [1m[32m0.23509[0m[0m | time: 17.695s
[2K
| Adam | epoch: 017 | loss: 0.23509 - acc: 0.9147 -- iter: 0928/2015
[A[ATraining Step: 1038  | total loss: [1m[32m0.23000[0m[0m | time: 18.315s
[2K
| Adam | epoch: 017 | loss: 0.23000 - acc: 0.9139 -- iter: 0960/2015
[A[ATraining Step: 1039  | total loss: [1m[32m0.22719[0m[0m | time: 18.920s
[2K
| Adam | epoch: 017 | loss: 0.22719 - acc: 0.9131 -- iter: 0992/2015
[A[ATraining Step: 1040  | total loss: [1m[32m0.21456[0m[0m | time: 19.534s
[2K
| Adam | epoch: 017 | loss: 0.21456 - acc: 0.9187 -- iter: 1024/2015
[A[ATraining Step: 1041  | total loss: [1m[32m0.22230[0m[0m | time: 20.151s
[2K
| Adam | epoch: 017 | loss: 0.22230 - acc: 0.9174 -- iter: 1056/2015
[A[ATraining Step: 1042  | total loss: [1m[32m0.22685[0m[0m | time: 20.765s
[2K
| Adam | epoch: 017 | loss: 0.22685 - acc: 0.9163 -- iter: 1088/2015
[A[ATraining Step: 1043  | total loss: [1m[32m0.21046[0m[0m | time: 21.370s
[2K
| Adam | epoch: 017 | loss: 0.21046 - acc: 0.9247 -- iter: 1120/2015
[A[ATraining Step: 1044  | total loss: [1m[32m0.22239[0m[0m | time: 22.000s
[2K
| Adam | epoch: 017 | loss: 0.22239 - acc: 0.9228 -- iter: 1152/2015
[A[ATraining Step: 1045  | total loss: [1m[32m0.21080[0m[0m | time: 22.633s
[2K
| Adam | epoch: 017 | loss: 0.21080 - acc: 0.9306 -- iter: 1184/2015
[A[ATraining Step: 1046  | total loss: [1m[32m0.20586[0m[0m | time: 23.233s
[2K
| Adam | epoch: 017 | loss: 0.20586 - acc: 0.9281 -- iter: 1216/2015
[A[ATraining Step: 1047  | total loss: [1m[32m0.23066[0m[0m | time: 23.845s
[2K
| Adam | epoch: 017 | loss: 0.23066 - acc: 0.9228 -- iter: 1248/2015
[A[ATraining Step: 1048  | total loss: [1m[32m0.22092[0m[0m | time: 24.457s
[2K
| Adam | epoch: 017 | loss: 0.22092 - acc: 0.9243 -- iter: 1280/2015
[A[ATraining Step: 1049  | total loss: [1m[32m0.24239[0m[0m | time: 25.057s
[2K
| Adam | epoch: 017 | loss: 0.24239 - acc: 0.9194 -- iter: 1312/2015
[A[ATraining Step: 1050  | total loss: [1m[32m0.25226[0m[0m | time: 25.655s
[2K
| Adam | epoch: 017 | loss: 0.25226 - acc: 0.9149 -- iter: 1344/2015
[A[ATraining Step: 1051  | total loss: [1m[32m0.24484[0m[0m | time: 26.273s
[2K
| Adam | epoch: 017 | loss: 0.24484 - acc: 0.9172 -- iter: 1376/2015
[A[ATraining Step: 1052  | total loss: [1m[32m0.24880[0m[0m | time: 26.871s
[2K
| Adam | epoch: 017 | loss: 0.24880 - acc: 0.9161 -- iter: 1408/2015
[A[ATraining Step: 1053  | total loss: [1m[32m0.24314[0m[0m | time: 27.473s
[2K
| Adam | epoch: 017 | loss: 0.24314 - acc: 0.9151 -- iter: 1440/2015
[A[ATraining Step: 1054  | total loss: [1m[32m0.24026[0m[0m | time: 28.083s
[2K
| Adam | epoch: 017 | loss: 0.24026 - acc: 0.9080 -- iter: 1472/2015
[A[ATraining Step: 1055  | total loss: [1m[32m0.23148[0m[0m | time: 28.675s
[2K
| Adam | epoch: 017 | loss: 0.23148 - acc: 0.9140 -- iter: 1504/2015
[A[ATraining Step: 1056  | total loss: [1m[32m0.23488[0m[0m | time: 29.273s
[2K
| Adam | epoch: 017 | loss: 0.23488 - acc: 0.9164 -- iter: 1536/2015
[A[ATraining Step: 1057  | total loss: [1m[32m0.22999[0m[0m | time: 29.865s
[2K
| Adam | epoch: 017 | loss: 0.22999 - acc: 0.9216 -- iter: 1568/2015
[A[ATraining Step: 1058  | total loss: [1m[32m0.21261[0m[0m | time: 30.472s
[2K
| Adam | epoch: 017 | loss: 0.21261 - acc: 0.9295 -- iter: 1600/2015
[A[ATraining Step: 1059  | total loss: [1m[32m0.20323[0m[0m | time: 31.096s
[2K
| Adam | epoch: 017 | loss: 0.20323 - acc: 0.9334 -- iter: 1632/2015
[A[ATraining Step: 1060  | total loss: [1m[32m0.21228[0m[0m | time: 31.699s
[2K
| Adam | epoch: 017 | loss: 0.21228 - acc: 0.9338 -- iter: 1664/2015
[A[ATraining Step: 1061  | total loss: [1m[32m0.19556[0m[0m | time: 32.317s
[2K
| Adam | epoch: 017 | loss: 0.19556 - acc: 0.9404 -- iter: 1696/2015
[A[ATraining Step: 1062  | total loss: [1m[32m0.18819[0m[0m | time: 32.930s
[2K
| Adam | epoch: 017 | loss: 0.18819 - acc: 0.9433 -- iter: 1728/2015
[A[ATraining Step: 1063  | total loss: [1m[32m0.18036[0m[0m | time: 33.530s
[2K
| Adam | epoch: 017 | loss: 0.18036 - acc: 0.9458 -- iter: 1760/2015
[A[ATraining Step: 1064  | total loss: [1m[32m0.17477[0m[0m | time: 34.137s
[2K
| Adam | epoch: 017 | loss: 0.17477 - acc: 0.9481 -- iter: 1792/2015
[A[ATraining Step: 1065  | total loss: [1m[32m0.17038[0m[0m | time: 34.741s
[2K
| Adam | epoch: 017 | loss: 0.17038 - acc: 0.9502 -- iter: 1824/2015
[A[ATraining Step: 1066  | total loss: [1m[32m0.19729[0m[0m | time: 35.353s
[2K
| Adam | epoch: 017 | loss: 0.19729 - acc: 0.9395 -- iter: 1856/2015
[A[ATraining Step: 1067  | total loss: [1m[32m0.18733[0m[0m | time: 35.961s
[2K
| Adam | epoch: 017 | loss: 0.18733 - acc: 0.9424 -- iter: 1888/2015
[A[ATraining Step: 1068  | total loss: [1m[32m0.18499[0m[0m | time: 36.595s
[2K
| Adam | epoch: 017 | loss: 0.18499 - acc: 0.9420 -- iter: 1920/2015
[A[ATraining Step: 1069  | total loss: [1m[32m0.20444[0m[0m | time: 37.197s
[2K
| Adam | epoch: 017 | loss: 0.20444 - acc: 0.9353 -- iter: 1952/2015
[A[ATraining Step: 1070  | total loss: [1m[32m0.19335[0m[0m | time: 37.833s
[2K
| Adam | epoch: 017 | loss: 0.19335 - acc: 0.9417 -- iter: 1984/2015
[A[ATraining Step: 1071  | total loss: [1m[32m0.19476[0m[0m | time: 40.422s
[2K
| Adam | epoch: 017 | loss: 0.19476 - acc: 0.9382 | val_loss: 0.37918 - val_acc: 0.8476 -- iter: 2015/2015
--
Training Step: 1072  | total loss: [1m[32m0.19180[0m[0m | time: 0.621s
[2K
| Adam | epoch: 018 | loss: 0.19180 - acc: 0.9381 -- iter: 0032/2015
[A[ATraining Step: 1073  | total loss: [1m[32m0.18948[0m[0m | time: 1.219s
[2K
| Adam | epoch: 018 | loss: 0.18948 - acc: 0.9349 -- iter: 0064/2015
[A[ATraining Step: 1074  | total loss: [1m[32m0.18400[0m[0m | time: 1.824s
[2K
| Adam | epoch: 018 | loss: 0.18400 - acc: 0.9352 -- iter: 0096/2015
[A[ATraining Step: 1075  | total loss: [1m[32m0.18121[0m[0m | time: 2.426s
[2K
| Adam | epoch: 018 | loss: 0.18121 - acc: 0.9323 -- iter: 0128/2015
[A[ATraining Step: 1076  | total loss: [1m[32m0.19607[0m[0m | time: 3.049s
[2K
| Adam | epoch: 018 | loss: 0.19607 - acc: 0.9234 -- iter: 0160/2015
[A[ATraining Step: 1077  | total loss: [1m[32m0.19457[0m[0m | time: 3.674s
[2K
| Adam | epoch: 018 | loss: 0.19457 - acc: 0.9217 -- iter: 0192/2015
[A[ATraining Step: 1078  | total loss: [1m[32m0.18644[0m[0m | time: 4.276s
[2K
| Adam | epoch: 018 | loss: 0.18644 - acc: 0.9295 -- iter: 0224/2015
[A[ATraining Step: 1079  | total loss: [1m[32m0.19239[0m[0m | time: 4.889s
[2K
| Adam | epoch: 018 | loss: 0.19239 - acc: 0.9241 -- iter: 0256/2015
[A[ATraining Step: 1080  | total loss: [1m[32m0.19153[0m[0m | time: 5.498s
[2K
| Adam | epoch: 018 | loss: 0.19153 - acc: 0.9286 -- iter: 0288/2015
[A[ATraining Step: 1081  | total loss: [1m[32m0.21591[0m[0m | time: 6.096s
[2K
| Adam | epoch: 018 | loss: 0.21591 - acc: 0.9201 -- iter: 0320/2015
[A[ATraining Step: 1082  | total loss: [1m[32m0.20322[0m[0m | time: 6.691s
[2K
| Adam | epoch: 018 | loss: 0.20322 - acc: 0.9281 -- iter: 0352/2015
[A[ATraining Step: 1083  | total loss: [1m[32m0.20022[0m[0m | time: 7.312s
[2K
| Adam | epoch: 018 | loss: 0.20022 - acc: 0.9259 -- iter: 0384/2015
[A[ATraining Step: 1084  | total loss: [1m[32m0.20046[0m[0m | time: 7.932s
[2K
| Adam | epoch: 018 | loss: 0.20046 - acc: 0.9302 -- iter: 0416/2015
[A[ATraining Step: 1085  | total loss: [1m[32m0.20543[0m[0m | time: 8.559s
[2K
| Adam | epoch: 018 | loss: 0.20543 - acc: 0.9247 -- iter: 0448/2015
[A[ATraining Step: 1086  | total loss: [1m[32m0.19301[0m[0m | time: 9.169s
[2K
| Adam | epoch: 018 | loss: 0.19301 - acc: 0.9322 -- iter: 0480/2015
[A[ATraining Step: 1087  | total loss: [1m[32m0.18349[0m[0m | time: 9.753s
[2K
| Adam | epoch: 018 | loss: 0.18349 - acc: 0.9358 -- iter: 0512/2015
[A[ATraining Step: 1088  | total loss: [1m[32m0.17226[0m[0m | time: 10.346s
[2K
| Adam | epoch: 018 | loss: 0.17226 - acc: 0.9423 -- iter: 0544/2015
[A[ATraining Step: 1089  | total loss: [1m[32m0.16186[0m[0m | time: 10.948s
[2K
| Adam | epoch: 018 | loss: 0.16186 - acc: 0.9480 -- iter: 0576/2015
[A[ATraining Step: 1090  | total loss: [1m[32m0.15315[0m[0m | time: 11.574s
[2K
| Adam | epoch: 018 | loss: 0.15315 - acc: 0.9501 -- iter: 0608/2015
[A[ATraining Step: 1091  | total loss: [1m[32m0.15579[0m[0m | time: 12.186s
[2K
| Adam | epoch: 018 | loss: 0.15579 - acc: 0.9457 -- iter: 0640/2015
[A[ATraining Step: 1092  | total loss: [1m[32m0.16158[0m[0m | time: 12.805s
[2K
| Adam | epoch: 018 | loss: 0.16158 - acc: 0.9386 -- iter: 0672/2015
[A[ATraining Step: 1093  | total loss: [1m[32m0.16733[0m[0m | time: 13.405s
[2K
| Adam | epoch: 018 | loss: 0.16733 - acc: 0.9385 -- iter: 0704/2015
[A[ATraining Step: 1094  | total loss: [1m[32m0.18044[0m[0m | time: 14.025s
[2K
| Adam | epoch: 018 | loss: 0.18044 - acc: 0.9291 -- iter: 0736/2015
[A[ATraining Step: 1095  | total loss: [1m[32m0.19129[0m[0m | time: 14.633s
[2K
| Adam | epoch: 018 | loss: 0.19129 - acc: 0.9299 -- iter: 0768/2015
[A[ATraining Step: 1096  | total loss: [1m[32m0.17967[0m[0m | time: 15.212s
[2K
| Adam | epoch: 018 | loss: 0.17967 - acc: 0.9338 -- iter: 0800/2015
[A[ATraining Step: 1097  | total loss: [1m[32m0.17852[0m[0m | time: 15.808s
[2K
| Adam | epoch: 018 | loss: 0.17852 - acc: 0.9310 -- iter: 0832/2015
[A[ATraining Step: 1098  | total loss: [1m[32m0.16928[0m[0m | time: 16.413s
[2K
| Adam | epoch: 018 | loss: 0.16928 - acc: 0.9348 -- iter: 0864/2015
[A[ATraining Step: 1099  | total loss: [1m[32m0.16508[0m[0m | time: 17.008s
[2K
| Adam | epoch: 018 | loss: 0.16508 - acc: 0.9382 -- iter: 0896/2015
[A[ATraining Step: 1100  | total loss: [1m[32m0.15391[0m[0m | time: 17.602s
[2K
| Adam | epoch: 018 | loss: 0.15391 - acc: 0.9444 -- iter: 0928/2015
[A[ATraining Step: 1101  | total loss: [1m[32m0.15147[0m[0m | time: 18.208s
[2K
| Adam | epoch: 018 | loss: 0.15147 - acc: 0.9468 -- iter: 0960/2015
[A[ATraining Step: 1102  | total loss: [1m[32m0.14200[0m[0m | time: 18.819s
[2K
| Adam | epoch: 018 | loss: 0.14200 - acc: 0.9521 -- iter: 0992/2015
[A[ATraining Step: 1103  | total loss: [1m[32m0.13575[0m[0m | time: 19.424s
[2K
| Adam | epoch: 018 | loss: 0.13575 - acc: 0.9569 -- iter: 1024/2015
[A[ATraining Step: 1104  | total loss: [1m[32m0.13145[0m[0m | time: 20.039s
[2K
| Adam | epoch: 018 | loss: 0.13145 - acc: 0.9581 -- iter: 1056/2015
[A[ATraining Step: 1105  | total loss: [1m[32m0.15481[0m[0m | time: 20.634s
[2K
| Adam | epoch: 018 | loss: 0.15481 - acc: 0.9529 -- iter: 1088/2015
[A[ATraining Step: 1106  | total loss: [1m[32m0.15042[0m[0m | time: 21.274s
[2K
| Adam | epoch: 018 | loss: 0.15042 - acc: 0.9545 -- iter: 1120/2015
[A[ATraining Step: 1107  | total loss: [1m[32m0.14798[0m[0m | time: 21.902s
[2K
| Adam | epoch: 018 | loss: 0.14798 - acc: 0.9559 -- iter: 1152/2015
[A[ATraining Step: 1108  | total loss: [1m[32m0.17143[0m[0m | time: 22.505s
[2K
| Adam | epoch: 018 | loss: 0.17143 - acc: 0.9447 -- iter: 1184/2015
[A[ATraining Step: 1109  | total loss: [1m[32m0.16866[0m[0m | time: 23.100s
[2K
| Adam | epoch: 018 | loss: 0.16866 - acc: 0.9440 -- iter: 1216/2015
[A[ATraining Step: 1110  | total loss: [1m[32m0.17353[0m[0m | time: 23.716s
[2K
| Adam | epoch: 018 | loss: 0.17353 - acc: 0.9465 -- iter: 1248/2015
[A[ATraining Step: 1111  | total loss: [1m[32m0.16796[0m[0m | time: 24.327s
[2K
| Adam | epoch: 018 | loss: 0.16796 - acc: 0.9487 -- iter: 1280/2015
[A[ATraining Step: 1112  | total loss: [1m[32m0.17325[0m[0m | time: 24.940s
[2K
| Adam | epoch: 018 | loss: 0.17325 - acc: 0.9476 -- iter: 1312/2015
[A[ATraining Step: 1113  | total loss: [1m[32m0.17419[0m[0m | time: 25.540s
[2K
| Adam | epoch: 018 | loss: 0.17419 - acc: 0.9434 -- iter: 1344/2015
[A[ATraining Step: 1114  | total loss: [1m[32m0.19104[0m[0m | time: 26.149s
[2K
| Adam | epoch: 018 | loss: 0.19104 - acc: 0.9366 -- iter: 1376/2015
[A[ATraining Step: 1115  | total loss: [1m[32m0.19427[0m[0m | time: 26.751s
[2K
| Adam | epoch: 018 | loss: 0.19427 - acc: 0.9273 -- iter: 1408/2015
[A[ATraining Step: 1116  | total loss: [1m[32m0.18404[0m[0m | time: 27.374s
[2K
| Adam | epoch: 018 | loss: 0.18404 - acc: 0.9315 -- iter: 1440/2015
[A[ATraining Step: 1117  | total loss: [1m[32m0.17385[0m[0m | time: 27.965s
[2K
| Adam | epoch: 018 | loss: 0.17385 - acc: 0.9383 -- iter: 1472/2015
[A[ATraining Step: 1118  | total loss: [1m[32m0.16937[0m[0m | time: 28.571s
[2K
| Adam | epoch: 018 | loss: 0.16937 - acc: 0.9414 -- iter: 1504/2015
[A[ATraining Step: 1119  | total loss: [1m[32m0.16569[0m[0m | time: 29.179s
[2K
| Adam | epoch: 018 | loss: 0.16569 - acc: 0.9378 -- iter: 1536/2015
[A[ATraining Step: 1120  | total loss: [1m[32m0.18174[0m[0m | time: 29.779s
[2K
| Adam | epoch: 018 | loss: 0.18174 - acc: 0.9347 -- iter: 1568/2015
[A[ATraining Step: 1121  | total loss: [1m[32m0.18259[0m[0m | time: 30.384s
[2K
| Adam | epoch: 018 | loss: 0.18259 - acc: 0.9350 -- iter: 1600/2015
[A[ATraining Step: 1122  | total loss: [1m[32m0.17779[0m[0m | time: 30.976s
[2K
| Adam | epoch: 018 | loss: 0.17779 - acc: 0.9352 -- iter: 1632/2015
[A[ATraining Step: 1123  | total loss: [1m[32m0.16790[0m[0m | time: 31.591s
[2K
| Adam | epoch: 018 | loss: 0.16790 - acc: 0.9386 -- iter: 1664/2015
[A[ATraining Step: 1124  | total loss: [1m[32m0.17068[0m[0m | time: 32.199s
[2K
| Adam | epoch: 018 | loss: 0.17068 - acc: 0.9322 -- iter: 1696/2015
[A[ATraining Step: 1125  | total loss: [1m[32m0.16668[0m[0m | time: 32.794s
[2K
| Adam | epoch: 018 | loss: 0.16668 - acc: 0.9327 -- iter: 1728/2015
[A[ATraining Step: 1126  | total loss: [1m[32m0.17096[0m[0m | time: 33.393s
[2K
| Adam | epoch: 018 | loss: 0.17096 - acc: 0.9332 -- iter: 1760/2015
[A[ATraining Step: 1127  | total loss: [1m[32m0.16048[0m[0m | time: 34.008s
[2K
| Adam | epoch: 018 | loss: 0.16048 - acc: 0.9368 -- iter: 1792/2015
[A[ATraining Step: 1128  | total loss: [1m[32m0.16746[0m[0m | time: 34.609s
[2K
| Adam | epoch: 018 | loss: 0.16746 - acc: 0.9368 -- iter: 1824/2015
[A[ATraining Step: 1129  | total loss: [1m[32m0.16339[0m[0m | time: 35.203s
[2K
| Adam | epoch: 018 | loss: 0.16339 - acc: 0.9432 -- iter: 1856/2015
[A[ATraining Step: 1130  | total loss: [1m[32m0.16705[0m[0m | time: 35.802s
[2K
| Adam | epoch: 018 | loss: 0.16705 - acc: 0.9363 -- iter: 1888/2015
[A[ATraining Step: 1131  | total loss: [1m[32m0.15800[0m[0m | time: 36.425s
[2K
| Adam | epoch: 018 | loss: 0.15800 - acc: 0.9396 -- iter: 1920/2015
[A[ATraining Step: 1132  | total loss: [1m[32m0.15607[0m[0m | time: 37.050s
[2K
| Adam | epoch: 018 | loss: 0.15607 - acc: 0.9425 -- iter: 1952/2015
[A[ATraining Step: 1133  | total loss: [1m[32m0.16008[0m[0m | time: 37.654s
[2K
| Adam | epoch: 018 | loss: 0.16008 - acc: 0.9451 -- iter: 1984/2015
[A[ATraining Step: 1134  | total loss: [1m[32m0.15246[0m[0m | time: 40.222s
[2K
| Adam | epoch: 018 | loss: 0.15246 - acc: 0.9475 | val_loss: 0.40766 - val_acc: 0.8508 -- iter: 2015/2015
--
Training Step: 1135  | total loss: [1m[32m0.15337[0m[0m | time: 0.616s
[2K
| Adam | epoch: 019 | loss: 0.15337 - acc: 0.9465 -- iter: 0032/2015
[A[ATraining Step: 1136  | total loss: [1m[32m0.15750[0m[0m | time: 1.211s
[2K
| Adam | epoch: 019 | loss: 0.15750 - acc: 0.9456 -- iter: 0064/2015
[A[ATraining Step: 1137  | total loss: [1m[32m0.14535[0m[0m | time: 1.816s
[2K
| Adam | epoch: 019 | loss: 0.14535 - acc: 0.9510 -- iter: 0096/2015
[A[ATraining Step: 1138  | total loss: [1m[32m0.15361[0m[0m | time: 2.421s
[2K
| Adam | epoch: 019 | loss: 0.15361 - acc: 0.9434 -- iter: 0128/2015
[A[ATraining Step: 1139  | total loss: [1m[32m0.17031[0m[0m | time: 3.033s
[2K
| Adam | epoch: 019 | loss: 0.17031 - acc: 0.9366 -- iter: 0160/2015
[A[ATraining Step: 1140  | total loss: [1m[32m0.16263[0m[0m | time: 3.657s
[2K
| Adam | epoch: 019 | loss: 0.16263 - acc: 0.9429 -- iter: 0192/2015
[A[ATraining Step: 1141  | total loss: [1m[32m0.15742[0m[0m | time: 4.266s
[2K
| Adam | epoch: 019 | loss: 0.15742 - acc: 0.9486 -- iter: 0224/2015
[A[ATraining Step: 1142  | total loss: [1m[32m0.14756[0m[0m | time: 4.885s
[2K
| Adam | epoch: 019 | loss: 0.14756 - acc: 0.9538 -- iter: 0256/2015
[A[ATraining Step: 1143  | total loss: [1m[32m0.16356[0m[0m | time: 5.481s
[2K
| Adam | epoch: 019 | loss: 0.16356 - acc: 0.9521 -- iter: 0288/2015
[A[ATraining Step: 1144  | total loss: [1m[32m0.15390[0m[0m | time: 6.086s
[2K
| Adam | epoch: 019 | loss: 0.15390 - acc: 0.9569 -- iter: 0320/2015
[A[ATraining Step: 1145  | total loss: [1m[32m0.15348[0m[0m | time: 6.687s
[2K
| Adam | epoch: 019 | loss: 0.15348 - acc: 0.9581 -- iter: 0352/2015
[A[ATraining Step: 1146  | total loss: [1m[32m0.15849[0m[0m | time: 7.285s
[2K
| Adam | epoch: 019 | loss: 0.15849 - acc: 0.9561 -- iter: 0384/2015
[A[ATraining Step: 1147  | total loss: [1m[32m0.15412[0m[0m | time: 7.891s
[2K
| Adam | epoch: 019 | loss: 0.15412 - acc: 0.9542 -- iter: 0416/2015
[A[ATraining Step: 1148  | total loss: [1m[32m0.14822[0m[0m | time: 8.503s
[2K
| Adam | epoch: 019 | loss: 0.14822 - acc: 0.9557 -- iter: 0448/2015
[A[ATraining Step: 1149  | total loss: [1m[32m0.14436[0m[0m | time: 9.118s
[2K
| Adam | epoch: 019 | loss: 0.14436 - acc: 0.9570 -- iter: 0480/2015
[A[ATraining Step: 1150  | total loss: [1m[32m0.14298[0m[0m | time: 9.728s
[2K
| Adam | epoch: 019 | loss: 0.14298 - acc: 0.9550 -- iter: 0512/2015
[A[ATraining Step: 1151  | total loss: [1m[32m0.14243[0m[0m | time: 10.319s
[2K
| Adam | epoch: 019 | loss: 0.14243 - acc: 0.9533 -- iter: 0544/2015
[A[ATraining Step: 1152  | total loss: [1m[32m0.14323[0m[0m | time: 10.901s
[2K
| Adam | epoch: 019 | loss: 0.14323 - acc: 0.9515 -- iter: 0576/2015
[A[ATraining Step: 1153  | total loss: [1m[32m0.14207[0m[0m | time: 11.496s
[2K
| Adam | epoch: 019 | loss: 0.14207 - acc: 0.9499 -- iter: 0608/2015
[A[ATraining Step: 1154  | total loss: [1m[32m0.13820[0m[0m | time: 12.093s
[2K
| Adam | epoch: 019 | loss: 0.13820 - acc: 0.9518 -- iter: 0640/2015
[A[ATraining Step: 1155  | total loss: [1m[32m0.14761[0m[0m | time: 12.693s
[2K
| Adam | epoch: 019 | loss: 0.14761 - acc: 0.9503 -- iter: 0672/2015
[A[ATraining Step: 1156  | total loss: [1m[32m0.14552[0m[0m | time: 13.301s
[2K
| Adam | epoch: 019 | loss: 0.14552 - acc: 0.9459 -- iter: 0704/2015
[A[ATraining Step: 1157  | total loss: [1m[32m0.14640[0m[0m | time: 13.925s
[2K
| Adam | epoch: 019 | loss: 0.14640 - acc: 0.9451 -- iter: 0736/2015
[A[ATraining Step: 1158  | total loss: [1m[32m0.13722[0m[0m | time: 14.536s
[2K
| Adam | epoch: 019 | loss: 0.13722 - acc: 0.9506 -- iter: 0768/2015
[A[ATraining Step: 1159  | total loss: [1m[32m0.12804[0m[0m | time: 15.131s
[2K
| Adam | epoch: 019 | loss: 0.12804 - acc: 0.9555 -- iter: 0800/2015
[A[ATraining Step: 1160  | total loss: [1m[32m0.12372[0m[0m | time: 15.741s
[2K
| Adam | epoch: 019 | loss: 0.12372 - acc: 0.9568 -- iter: 0832/2015
[A[ATraining Step: 1161  | total loss: [1m[32m0.12278[0m[0m | time: 16.352s
[2K
| Adam | epoch: 019 | loss: 0.12278 - acc: 0.9580 -- iter: 0864/2015
[A[ATraining Step: 1162  | total loss: [1m[32m0.11874[0m[0m | time: 16.960s
[2K
| Adam | epoch: 019 | loss: 0.11874 - acc: 0.9591 -- iter: 0896/2015
[A[ATraining Step: 1163  | total loss: [1m[32m0.12940[0m[0m | time: 17.559s
[2K
| Adam | epoch: 019 | loss: 0.12940 - acc: 0.9538 -- iter: 0928/2015
[A[ATraining Step: 1164  | total loss: [1m[32m0.12179[0m[0m | time: 18.187s
[2K
| Adam | epoch: 019 | loss: 0.12179 - acc: 0.9584 -- iter: 0960/2015
[A[ATraining Step: 1165  | total loss: [1m[32m0.11679[0m[0m | time: 18.796s
[2K
| Adam | epoch: 019 | loss: 0.11679 - acc: 0.9626 -- iter: 0992/2015
[A[ATraining Step: 1166  | total loss: [1m[32m0.12906[0m[0m | time: 19.390s
[2K
| Adam | epoch: 019 | loss: 0.12906 - acc: 0.9570 -- iter: 1024/2015
[A[ATraining Step: 1167  | total loss: [1m[32m0.13312[0m[0m | time: 19.999s
[2K
| Adam | epoch: 019 | loss: 0.13312 - acc: 0.9550 -- iter: 1056/2015
[A[ATraining Step: 1168  | total loss: [1m[32m0.13832[0m[0m | time: 20.602s
[2K
| Adam | epoch: 019 | loss: 0.13832 - acc: 0.9533 -- iter: 1088/2015
[A[ATraining Step: 1169  | total loss: [1m[32m0.13901[0m[0m | time: 21.210s
[2K
| Adam | epoch: 019 | loss: 0.13901 - acc: 0.9517 -- iter: 1120/2015
[A[ATraining Step: 1170  | total loss: [1m[32m0.13659[0m[0m | time: 21.839s
[2K
| Adam | epoch: 019 | loss: 0.13659 - acc: 0.9534 -- iter: 1152/2015
[A[ATraining Step: 1171  | total loss: [1m[32m0.13131[0m[0m | time: 22.442s
[2K
| Adam | epoch: 019 | loss: 0.13131 - acc: 0.9581 -- iter: 1184/2015
[A[ATraining Step: 1172  | total loss: [1m[32m0.13510[0m[0m | time: 23.034s
[2K
| Adam | epoch: 019 | loss: 0.13510 - acc: 0.9560 -- iter: 1216/2015
[A[ATraining Step: 1173  | total loss: [1m[32m0.13564[0m[0m | time: 23.635s
[2K
| Adam | epoch: 019 | loss: 0.13564 - acc: 0.9573 -- iter: 1248/2015
[A[ATraining Step: 1174  | total loss: [1m[32m0.14886[0m[0m | time: 24.242s
[2K
| Adam | epoch: 019 | loss: 0.14886 - acc: 0.9490 -- iter: 1280/2015
[A[ATraining Step: 1175  | total loss: [1m[32m0.13907[0m[0m | time: 24.851s
[2K
| Adam | epoch: 019 | loss: 0.13907 - acc: 0.9541 -- iter: 1312/2015
[A[ATraining Step: 1176  | total loss: [1m[32m0.14268[0m[0m | time: 25.450s
[2K
| Adam | epoch: 019 | loss: 0.14268 - acc: 0.9525 -- iter: 1344/2015
[A[ATraining Step: 1177  | total loss: [1m[32m0.14415[0m[0m | time: 26.058s
[2K
| Adam | epoch: 019 | loss: 0.14415 - acc: 0.9510 -- iter: 1376/2015
[A[ATraining Step: 1178  | total loss: [1m[32m0.13638[0m[0m | time: 26.688s
[2K
| Adam | epoch: 019 | loss: 0.13638 - acc: 0.9559 -- iter: 1408/2015
[A[ATraining Step: 1179  | total loss: [1m[32m0.15120[0m[0m | time: 27.296s
[2K
| Adam | epoch: 019 | loss: 0.15120 - acc: 0.9478 -- iter: 1440/2015
[A[ATraining Step: 1180  | total loss: [1m[32m0.16562[0m[0m | time: 27.910s
[2K
| Adam | epoch: 019 | loss: 0.16562 - acc: 0.9343 -- iter: 1472/2015
[A[ATraining Step: 1181  | total loss: [1m[32m0.18768[0m[0m | time: 28.514s
[2K
| Adam | epoch: 019 | loss: 0.18768 - acc: 0.9315 -- iter: 1504/2015
[A[ATraining Step: 1182  | total loss: [1m[32m0.18229[0m[0m | time: 29.129s
[2K
| Adam | epoch: 019 | loss: 0.18229 - acc: 0.9321 -- iter: 1536/2015
[A[ATraining Step: 1183  | total loss: [1m[32m0.17346[0m[0m | time: 29.729s
[2K
| Adam | epoch: 019 | loss: 0.17346 - acc: 0.9357 -- iter: 1568/2015
[A[ATraining Step: 1184  | total loss: [1m[32m0.17702[0m[0m | time: 30.334s
[2K
| Adam | epoch: 019 | loss: 0.17702 - acc: 0.9390 -- iter: 1600/2015
[A[ATraining Step: 1185  | total loss: [1m[32m0.16436[0m[0m | time: 30.951s
[2K
| Adam | epoch: 019 | loss: 0.16436 - acc: 0.9451 -- iter: 1632/2015
[A[ATraining Step: 1186  | total loss: [1m[32m0.15620[0m[0m | time: 31.552s
[2K
| Adam | epoch: 019 | loss: 0.15620 - acc: 0.9475 -- iter: 1664/2015
[A[ATraining Step: 1187  | total loss: [1m[32m0.15640[0m[0m | time: 32.145s
[2K
| Adam | epoch: 019 | loss: 0.15640 - acc: 0.9496 -- iter: 1696/2015
[A[ATraining Step: 1188  | total loss: [1m[32m0.15561[0m[0m | time: 32.754s
[2K
| Adam | epoch: 019 | loss: 0.15561 - acc: 0.9515 -- iter: 1728/2015
[A[ATraining Step: 1189  | total loss: [1m[32m0.15395[0m[0m | time: 33.347s
[2K
| Adam | epoch: 019 | loss: 0.15395 - acc: 0.9533 -- iter: 1760/2015
[A[ATraining Step: 1190  | total loss: [1m[32m0.15031[0m[0m | time: 33.956s
[2K
| Adam | epoch: 019 | loss: 0.15031 - acc: 0.9548 -- iter: 1792/2015
[A[ATraining Step: 1191  | total loss: [1m[32m0.14568[0m[0m | time: 34.563s
[2K
| Adam | epoch: 019 | loss: 0.14568 - acc: 0.9562 -- iter: 1824/2015
[A[ATraining Step: 1192  | total loss: [1m[32m0.13643[0m[0m | time: 35.174s
[2K
| Adam | epoch: 019 | loss: 0.13643 - acc: 0.9606 -- iter: 1856/2015
[A[ATraining Step: 1193  | total loss: [1m[32m0.13855[0m[0m | time: 35.783s
[2K
| Adam | epoch: 019 | loss: 0.13855 - acc: 0.9614 -- iter: 1888/2015
[A[ATraining Step: 1194  | total loss: [1m[32m0.12911[0m[0m | time: 36.388s
[2K
| Adam | epoch: 019 | loss: 0.12911 - acc: 0.9653 -- iter: 1920/2015
[A[ATraining Step: 1195  | total loss: [1m[32m0.12131[0m[0m | time: 36.984s
[2K
| Adam | epoch: 019 | loss: 0.12131 - acc: 0.9656 -- iter: 1952/2015
[A[ATraining Step: 1196  | total loss: [1m[32m0.12141[0m[0m | time: 37.601s
[2K
| Adam | epoch: 019 | loss: 0.12141 - acc: 0.9628 -- iter: 1984/2015
[A[ATraining Step: 1197  | total loss: [1m[32m0.12578[0m[0m | time: 40.219s
[2K
| Adam | epoch: 019 | loss: 0.12578 - acc: 0.9603 | val_loss: 0.41108 - val_acc: 0.8492 -- iter: 2015/2015
--
Training Step: 1198  | total loss: [1m[32m0.12500[0m[0m | time: 0.607s
[2K
| Adam | epoch: 020 | loss: 0.12500 - acc: 0.9580 -- iter: 0032/2015
[A[ATraining Step: 1199  | total loss: [1m[32m0.11885[0m[0m | time: 1.206s
[2K
| Adam | epoch: 020 | loss: 0.11885 - acc: 0.9622 -- iter: 0064/2015
[A[ATraining Step: 1200  | total loss: [1m[32m0.10975[0m[0m | time: 3.776s
[2K
| Adam | epoch: 020 | loss: 0.10975 - acc: 0.9660 | val_loss: 0.40177 - val_acc: 0.8667 -- iter: 0096/2015
--
Training Step: 1201  | total loss: [1m[32m0.12732[0m[0m | time: 4.400s
[2K
| Adam | epoch: 020 | loss: 0.12732 - acc: 0.9600 -- iter: 0128/2015
[A[ATraining Step: 1202  | total loss: [1m[32m0.12403[0m[0m | time: 5.009s
[2K
| Adam | epoch: 020 | loss: 0.12403 - acc: 0.9609 -- iter: 0160/2015
[A[ATraining Step: 1203  | total loss: [1m[32m0.12188[0m[0m | time: 5.630s
[2K
| Adam | epoch: 020 | loss: 0.12188 - acc: 0.9585 -- iter: 0192/2015
[A[ATraining Step: 1204  | total loss: [1m[32m0.13651[0m[0m | time: 6.227s
[2K
| Adam | epoch: 020 | loss: 0.13651 - acc: 0.9533 -- iter: 0224/2015
[A[ATraining Step: 1205  | total loss: [1m[32m0.14264[0m[0m | time: 6.837s
[2K
| Adam | epoch: 020 | loss: 0.14264 - acc: 0.9517 -- iter: 0256/2015
[A[ATraining Step: 1206  | total loss: [1m[32m0.15024[0m[0m | time: 7.431s
[2K
| Adam | epoch: 020 | loss: 0.15024 - acc: 0.9472 -- iter: 0288/2015
[A[ATraining Step: 1207  | total loss: [1m[32m0.15130[0m[0m | time: 8.042s
[2K
| Adam | epoch: 020 | loss: 0.15130 - acc: 0.9431 -- iter: 0320/2015
[A[ATraining Step: 1208  | total loss: [1m[32m0.15033[0m[0m | time: 8.641s
[2K
| Adam | epoch: 020 | loss: 0.15033 - acc: 0.9394 -- iter: 0352/2015
[A[ATraining Step: 1209  | total loss: [1m[32m0.14404[0m[0m | time: 9.251s
[2K
| Adam | epoch: 020 | loss: 0.14404 - acc: 0.9423 -- iter: 0384/2015
[A[ATraining Step: 1210  | total loss: [1m[32m0.15671[0m[0m | time: 9.839s
[2K
| Adam | epoch: 020 | loss: 0.15671 - acc: 0.9387 -- iter: 0416/2015
[A[ATraining Step: 1211  | total loss: [1m[32m0.14812[0m[0m | time: 10.432s
[2K
| Adam | epoch: 020 | loss: 0.14812 - acc: 0.9417 -- iter: 0448/2015
[A[ATraining Step: 1212  | total loss: [1m[32m0.14255[0m[0m | time: 11.031s
[2K
| Adam | epoch: 020 | loss: 0.14255 - acc: 0.9444 -- iter: 0480/2015
[A[ATraining Step: 1213  | total loss: [1m[32m0.14152[0m[0m | time: 11.627s
[2K
| Adam | epoch: 020 | loss: 0.14152 - acc: 0.9469 -- iter: 0512/2015
[A[ATraining Step: 1214  | total loss: [1m[32m0.13993[0m[0m | time: 12.240s
[2K
| Adam | epoch: 020 | loss: 0.13993 - acc: 0.9491 -- iter: 0544/2015
[A[ATraining Step: 1215  | total loss: [1m[32m0.13846[0m[0m | time: 12.837s
[2K
| Adam | epoch: 020 | loss: 0.13846 - acc: 0.9479 -- iter: 0576/2015
[A[ATraining Step: 1216  | total loss: [1m[32m0.13550[0m[0m | time: 13.418s
[2K
| Adam | epoch: 020 | loss: 0.13550 - acc: 0.9499 -- iter: 0608/2015
[A[ATraining Step: 1217  | total loss: [1m[32m0.13231[0m[0m | time: 14.024s
[2K
| Adam | epoch: 020 | loss: 0.13231 - acc: 0.9517 -- iter: 0640/2015
[A[ATraining Step: 1218  | total loss: [1m[32m0.12814[0m[0m | time: 14.621s
[2K
| Adam | epoch: 020 | loss: 0.12814 - acc: 0.9534 -- iter: 0672/2015
[A[ATraining Step: 1219  | total loss: [1m[32m0.11958[0m[0m | time: 15.233s
[2K
| Adam | epoch: 020 | loss: 0.11958 - acc: 0.9580 -- iter: 0704/2015
[A[ATraining Step: 1220  | total loss: [1m[32m0.11627[0m[0m | time: 15.827s
[2K
| Adam | epoch: 020 | loss: 0.11627 - acc: 0.9591 -- iter: 0736/2015
[A[ATraining Step: 1221  | total loss: [1m[32m0.11502[0m[0m | time: 16.575s
[2K
| Adam | epoch: 020 | loss: 0.11502 - acc: 0.9601 -- iter: 0768/2015
[A[ATraining Step: 1222  | total loss: [1m[32m0.11028[0m[0m | time: 17.186s
[2K
| Adam | epoch: 020 | loss: 0.11028 - acc: 0.9609 -- iter: 0800/2015
[A[ATraining Step: 1223  | total loss: [1m[32m0.10422[0m[0m | time: 17.787s
[2K
| Adam | epoch: 020 | loss: 0.10422 - acc: 0.9648 -- iter: 0832/2015
[A[ATraining Step: 1224  | total loss: [1m[32m0.11010[0m[0m | time: 18.392s
[2K
| Adam | epoch: 020 | loss: 0.11010 - acc: 0.9590 -- iter: 0864/2015
[A[ATraining Step: 1225  | total loss: [1m[32m0.11130[0m[0m | time: 18.997s
[2K
| Adam | epoch: 020 | loss: 0.11130 - acc: 0.9600 -- iter: 0896/2015
[A[ATraining Step: 1226  | total loss: [1m[32m0.12443[0m[0m | time: 19.599s
[2K
| Adam | epoch: 020 | loss: 0.12443 - acc: 0.9515 -- iter: 0928/2015
[A[ATraining Step: 1227  | total loss: [1m[32m0.13157[0m[0m | time: 20.206s
[2K
| Adam | epoch: 020 | loss: 0.13157 - acc: 0.9469 -- iter: 0960/2015
[A[ATraining Step: 1228  | total loss: [1m[32m0.12722[0m[0m | time: 20.818s
[2K
| Adam | epoch: 020 | loss: 0.12722 - acc: 0.9491 -- iter: 0992/2015
[A[ATraining Step: 1229  | total loss: [1m[32m0.12376[0m[0m | time: 21.453s
[2K
| Adam | epoch: 020 | loss: 0.12376 - acc: 0.9511 -- iter: 1024/2015
[A[ATraining Step: 1230  | total loss: [1m[32m0.11554[0m[0m | time: 22.052s
[2K
| Adam | epoch: 020 | loss: 0.11554 - acc: 0.9560 -- iter: 1056/2015
[A[ATraining Step: 1231  | total loss: [1m[32m0.12168[0m[0m | time: 22.657s
[2K
| Adam | epoch: 020 | loss: 0.12168 - acc: 0.9479 -- iter: 1088/2015
[A[ATraining Step: 1232  | total loss: [1m[32m0.12142[0m[0m | time: 23.256s
[2K
| Adam | epoch: 020 | loss: 0.12142 - acc: 0.9500 -- iter: 1120/2015
[A[ATraining Step: 1233  | total loss: [1m[32m0.13293[0m[0m | time: 23.853s
[2K
| Adam | epoch: 020 | loss: 0.13293 - acc: 0.9425 -- iter: 1152/2015
[A[ATraining Step: 1234  | total loss: [1m[32m0.13506[0m[0m | time: 24.460s
[2K
| Adam | epoch: 020 | loss: 0.13506 - acc: 0.9420 -- iter: 1184/2015
[A[ATraining Step: 1235  | total loss: [1m[32m0.12394[0m[0m | time: 25.059s
[2K
| Adam | epoch: 020 | loss: 0.12394 - acc: 0.9478 -- iter: 1216/2015
[A[ATraining Step: 1236  | total loss: [1m[32m0.12364[0m[0m | time: 25.652s
[2K
| Adam | epoch: 020 | loss: 0.12364 - acc: 0.9499 -- iter: 1248/2015
[A[ATraining Step: 1237  | total loss: [1m[32m0.12936[0m[0m | time: 26.277s
[2K
| Adam | epoch: 020 | loss: 0.12936 - acc: 0.9486 -- iter: 1280/2015
[A[ATraining Step: 1238  | total loss: [1m[32m0.14101[0m[0m | time: 26.896s
[2K
| Adam | epoch: 020 | loss: 0.14101 - acc: 0.9475 -- iter: 1312/2015
[A[ATraining Step: 1239  | total loss: [1m[32m0.14074[0m[0m | time: 27.487s
[2K
| Adam | epoch: 020 | loss: 0.14074 - acc: 0.9496 -- iter: 1344/2015
[A[ATraining Step: 1240  | total loss: [1m[32m0.12970[0m[0m | time: 28.077s
[2K
| Adam | epoch: 020 | loss: 0.12970 - acc: 0.9547 -- iter: 1376/2015
[A[ATraining Step: 1241  | total loss: [1m[32m0.13734[0m[0m | time: 28.674s
[2K
| Adam | epoch: 020 | loss: 0.13734 - acc: 0.9498 -- iter: 1408/2015
[A[ATraining Step: 1242  | total loss: [1m[32m0.13080[0m[0m | time: 29.274s
[2K
| Adam | epoch: 020 | loss: 0.13080 - acc: 0.9486 -- iter: 1440/2015
[A[ATraining Step: 1243  | total loss: [1m[32m0.12282[0m[0m | time: 29.877s
[2K
| Adam | epoch: 020 | loss: 0.12282 - acc: 0.9506 -- iter: 1472/2015
[A[ATraining Step: 1244  | total loss: [1m[32m0.11938[0m[0m | time: 30.475s
[2K
| Adam | epoch: 020 | loss: 0.11938 - acc: 0.9524 -- iter: 1504/2015
[A[ATraining Step: 1245  | total loss: [1m[32m0.13878[0m[0m | time: 31.078s
[2K
| Adam | epoch: 020 | loss: 0.13878 - acc: 0.9509 -- iter: 1536/2015
[A[ATraining Step: 1246  | total loss: [1m[32m0.12925[0m[0m | time: 31.675s
[2K
| Adam | epoch: 020 | loss: 0.12925 - acc: 0.9558 -- iter: 1568/2015
[A[ATraining Step: 1247  | total loss: [1m[32m0.12674[0m[0m | time: 32.267s
[2K
| Adam | epoch: 020 | loss: 0.12674 - acc: 0.9540 -- iter: 1600/2015
[A[ATraining Step: 1248  | total loss: [1m[32m0.14512[0m[0m | time: 32.867s
[2K
| Adam | epoch: 020 | loss: 0.14512 - acc: 0.9524 -- iter: 1632/2015
[A[ATraining Step: 1249  | total loss: [1m[32m0.13397[0m[0m | time: 33.480s
[2K
| Adam | epoch: 020 | loss: 0.13397 - acc: 0.9571 -- iter: 1664/2015
[A[ATraining Step: 1250  | total loss: [1m[32m0.13251[0m[0m | time: 34.084s
[2K
| Adam | epoch: 020 | loss: 0.13251 - acc: 0.9583 -- iter: 1696/2015
[A[ATraining Step: 1251  | total loss: [1m[32m0.12147[0m[0m | time: 34.670s
[2K
| Adam | epoch: 020 | loss: 0.12147 - acc: 0.9625 -- iter: 1728/2015
[A[ATraining Step: 1252  | total loss: [1m[32m0.13022[0m[0m | time: 35.269s
[2K
| Adam | epoch: 020 | loss: 0.13022 - acc: 0.9631 -- iter: 1760/2015
[A[ATraining Step: 1253  | total loss: [1m[32m0.12122[0m[0m | time: 35.874s
[2K
| Adam | epoch: 020 | loss: 0.12122 - acc: 0.9668 -- iter: 1792/2015
[A[ATraining Step: 1254  | total loss: [1m[32m0.11518[0m[0m | time: 36.501s
[2K
| Adam | epoch: 020 | loss: 0.11518 - acc: 0.9701 -- iter: 1824/2015
[A[ATraining Step: 1255  | total loss: [1m[32m0.12677[0m[0m | time: 37.119s
[2K
| Adam | epoch: 020 | loss: 0.12677 - acc: 0.9668 -- iter: 1856/2015
[A[ATraining Step: 1256  | total loss: [1m[32m0.11952[0m[0m | time: 37.714s
[2K
| Adam | epoch: 020 | loss: 0.11952 - acc: 0.9670 -- iter: 1888/2015
[A[ATraining Step: 1257  | total loss: [1m[32m0.11746[0m[0m | time: 38.317s
[2K
| Adam | epoch: 020 | loss: 0.11746 - acc: 0.9672 -- iter: 1920/2015
[A[ATraining Step: 1258  | total loss: [1m[32m0.12491[0m[0m | time: 38.934s
[2K
| Adam | epoch: 020 | loss: 0.12491 - acc: 0.9642 -- iter: 1952/2015
[A[ATraining Step: 1259  | total loss: [1m[32m0.12249[0m[0m | time: 39.535s
[2K
| Adam | epoch: 020 | loss: 0.12249 - acc: 0.9647 -- iter: 1984/2015
[A[ATraining Step: 1260  | total loss: [1m[32m0.11646[0m[0m | time: 42.093s
[2K
| Adam | epoch: 020 | loss: 0.11646 - acc: 0.9682 | val_loss: 0.50892 - val_acc: 0.8270 -- iter: 2015/2015
--
Training Step: 1261  | total loss: [1m[32m0.11594[0m[0m | time: 0.611s
[2K
| Adam | epoch: 021 | loss: 0.11594 - acc: 0.9651 -- iter: 0032/2015
[A[ATraining Step: 1262  | total loss: [1m[32m0.11237[0m[0m | time: 1.215s
[2K
| Adam | epoch: 021 | loss: 0.11237 - acc: 0.9686 -- iter: 0064/2015
[A[ATraining Step: 1263  | total loss: [1m[32m0.11691[0m[0m | time: 1.857s
[2K
| Adam | epoch: 021 | loss: 0.11691 - acc: 0.9655 -- iter: 0096/2015
[A[ATraining Step: 1264  | total loss: [1m[32m0.10997[0m[0m | time: 2.467s
[2K
| Adam | epoch: 021 | loss: 0.10997 - acc: 0.9690 -- iter: 0128/2015
[A[ATraining Step: 1265  | total loss: [1m[32m0.11344[0m[0m | time: 3.069s
[2K
| Adam | epoch: 021 | loss: 0.11344 - acc: 0.9689 -- iter: 0160/2015
[A[ATraining Step: 1266  | total loss: [1m[32m0.11750[0m[0m | time: 3.678s
[2K
| Adam | epoch: 021 | loss: 0.11750 - acc: 0.9689 -- iter: 0192/2015
[A[ATraining Step: 1267  | total loss: [1m[32m0.11212[0m[0m | time: 4.275s
[2K
| Adam | epoch: 021 | loss: 0.11212 - acc: 0.9720 -- iter: 0224/2015
[A[ATraining Step: 1268  | total loss: [1m[32m0.10675[0m[0m | time: 4.866s
[2K
| Adam | epoch: 021 | loss: 0.10675 - acc: 0.9717 -- iter: 0256/2015
[A[ATraining Step: 1269  | total loss: [1m[32m0.11789[0m[0m | time: 5.487s
[2K
| Adam | epoch: 021 | loss: 0.11789 - acc: 0.9683 -- iter: 0288/2015
[A[ATraining Step: 1270  | total loss: [1m[32m0.11543[0m[0m | time: 6.097s
[2K
| Adam | epoch: 021 | loss: 0.11543 - acc: 0.9683 -- iter: 0320/2015
[A[ATraining Step: 1271  | total loss: [1m[32m0.11256[0m[0m | time: 6.717s
[2K
| Adam | epoch: 021 | loss: 0.11256 - acc: 0.9652 -- iter: 0352/2015
[A[ATraining Step: 1272  | total loss: [1m[32m0.10678[0m[0m | time: 7.319s
[2K
| Adam | epoch: 021 | loss: 0.10678 - acc: 0.9687 -- iter: 0384/2015
[A[ATraining Step: 1273  | total loss: [1m[32m0.12165[0m[0m | time: 7.938s
[2K
| Adam | epoch: 021 | loss: 0.12165 - acc: 0.9656 -- iter: 0416/2015
[A[ATraining Step: 1274  | total loss: [1m[32m0.12020[0m[0m | time: 8.564s
[2K
| Adam | epoch: 021 | loss: 0.12020 - acc: 0.9659 -- iter: 0448/2015
[A[ATraining Step: 1275  | total loss: [1m[32m0.13470[0m[0m | time: 9.172s
[2K
| Adam | epoch: 021 | loss: 0.13470 - acc: 0.9599 -- iter: 0480/2015
[A[ATraining Step: 1276  | total loss: [1m[32m0.15498[0m[0m | time: 9.784s
[2K
| Adam | epoch: 021 | loss: 0.15498 - acc: 0.9452 -- iter: 0512/2015
[A[ATraining Step: 1277  | total loss: [1m[32m0.14509[0m[0m | time: 10.397s
[2K
| Adam | epoch: 021 | loss: 0.14509 - acc: 0.9507 -- iter: 0544/2015
[A[ATraining Step: 1278  | total loss: [1m[32m0.14254[0m[0m | time: 10.996s
[2K
| Adam | epoch: 021 | loss: 0.14254 - acc: 0.9494 -- iter: 0576/2015
[A[ATraining Step: 1279  | total loss: [1m[32m0.13601[0m[0m | time: 11.591s
[2K
| Adam | epoch: 021 | loss: 0.13601 - acc: 0.9513 -- iter: 0608/2015
[A[ATraining Step: 1280  | total loss: [1m[32m0.13540[0m[0m | time: 12.206s
[2K
| Adam | epoch: 021 | loss: 0.13540 - acc: 0.9529 -- iter: 0640/2015
[A[ATraining Step: 1281  | total loss: [1m[32m0.15090[0m[0m | time: 12.812s
[2K
| Adam | epoch: 021 | loss: 0.15090 - acc: 0.9351 -- iter: 0672/2015
[A[ATraining Step: 1282  | total loss: [1m[32m0.15389[0m[0m | time: 13.441s
[2K
| Adam | epoch: 021 | loss: 0.15389 - acc: 0.9353 -- iter: 0704/2015
[A[ATraining Step: 1283  | total loss: [1m[32m0.17493[0m[0m | time: 14.044s
[2K
| Adam | epoch: 021 | loss: 0.17493 - acc: 0.9230 -- iter: 0736/2015
[A[ATraining Step: 1284  | total loss: [1m[32m0.17620[0m[0m | time: 14.670s
[2K
| Adam | epoch: 021 | loss: 0.17620 - acc: 0.9245 -- iter: 0768/2015
[A[ATraining Step: 1285  | total loss: [1m[32m0.16543[0m[0m | time: 15.280s
[2K
| Adam | epoch: 021 | loss: 0.16543 - acc: 0.9289 -- iter: 0800/2015
[A[ATraining Step: 1286  | total loss: [1m[32m0.17185[0m[0m | time: 15.882s
[2K
| Adam | epoch: 021 | loss: 0.17185 - acc: 0.9266 -- iter: 0832/2015
[A[ATraining Step: 1287  | total loss: [1m[32m0.16372[0m[0m | time: 16.503s
[2K
| Adam | epoch: 021 | loss: 0.16372 - acc: 0.9309 -- iter: 0864/2015
[A[ATraining Step: 1288  | total loss: [1m[32m0.16049[0m[0m | time: 17.113s
[2K
| Adam | epoch: 021 | loss: 0.16049 - acc: 0.9315 -- iter: 0896/2015
[A[ATraining Step: 1289  | total loss: [1m[32m0.15597[0m[0m | time: 17.715s
[2K
| Adam | epoch: 021 | loss: 0.15597 - acc: 0.9290 -- iter: 0928/2015
[A[ATraining Step: 1290  | total loss: [1m[32m0.14948[0m[0m | time: 18.321s
[2K
| Adam | epoch: 021 | loss: 0.14948 - acc: 0.9330 -- iter: 0960/2015
[A[ATraining Step: 1291  | total loss: [1m[32m0.14504[0m[0m | time: 18.928s
[2K
| Adam | epoch: 021 | loss: 0.14504 - acc: 0.9334 -- iter: 0992/2015
[A[ATraining Step: 1292  | total loss: [1m[32m0.14205[0m[0m | time: 19.531s
[2K
| Adam | epoch: 021 | loss: 0.14205 - acc: 0.9338 -- iter: 1024/2015
[A[ATraining Step: 1293  | total loss: [1m[32m0.14690[0m[0m | time: 20.141s
[2K
| Adam | epoch: 021 | loss: 0.14690 - acc: 0.9342 -- iter: 1056/2015
[A[ATraining Step: 1294  | total loss: [1m[32m0.15010[0m[0m | time: 20.747s
[2K
| Adam | epoch: 021 | loss: 0.15010 - acc: 0.9345 -- iter: 1088/2015
[A[ATraining Step: 1295  | total loss: [1m[32m0.17219[0m[0m | time: 21.354s
[2K
| Adam | epoch: 021 | loss: 0.17219 - acc: 0.9223 -- iter: 1120/2015
[A[ATraining Step: 1296  | total loss: [1m[32m0.16713[0m[0m | time: 21.949s
[2K
| Adam | epoch: 021 | loss: 0.16713 - acc: 0.9270 -- iter: 1152/2015
[A[ATraining Step: 1297  | total loss: [1m[32m0.16503[0m[0m | time: 22.552s
[2K
| Adam | epoch: 021 | loss: 0.16503 - acc: 0.9311 -- iter: 1184/2015
[A[ATraining Step: 1298  | total loss: [1m[32m0.15059[0m[0m | time: 23.151s
[2K
| Adam | epoch: 021 | loss: 0.15059 - acc: 0.9380 -- iter: 1216/2015
[A[ATraining Step: 1299  | total loss: [1m[32m0.15349[0m[0m | time: 23.754s
[2K
| Adam | epoch: 021 | loss: 0.15349 - acc: 0.9411 -- iter: 1248/2015
[A[ATraining Step: 1300  | total loss: [1m[32m0.16416[0m[0m | time: 24.348s
[2K
| Adam | epoch: 021 | loss: 0.16416 - acc: 0.9376 -- iter: 1280/2015
[A[ATraining Step: 1301  | total loss: [1m[32m0.15136[0m[0m | time: 24.983s
[2K
| Adam | epoch: 021 | loss: 0.15136 - acc: 0.9439 -- iter: 1312/2015
[A[ATraining Step: 1302  | total loss: [1m[32m0.14077[0m[0m | time: 25.584s
[2K
| Adam | epoch: 021 | loss: 0.14077 - acc: 0.9495 -- iter: 1344/2015
[A[ATraining Step: 1303  | total loss: [1m[32m0.14009[0m[0m | time: 26.187s
[2K
| Adam | epoch: 021 | loss: 0.14009 - acc: 0.9483 -- iter: 1376/2015
[A[ATraining Step: 1304  | total loss: [1m[32m0.13469[0m[0m | time: 26.796s
[2K
| Adam | epoch: 021 | loss: 0.13469 - acc: 0.9503 -- iter: 1408/2015
[A[ATraining Step: 1305  | total loss: [1m[32m0.12821[0m[0m | time: 27.380s
[2K
| Adam | epoch: 021 | loss: 0.12821 - acc: 0.9553 -- iter: 1440/2015
[A[ATraining Step: 1306  | total loss: [1m[32m0.11777[0m[0m | time: 27.970s
[2K
| Adam | epoch: 021 | loss: 0.11777 - acc: 0.9598 -- iter: 1472/2015
[A[ATraining Step: 1307  | total loss: [1m[32m0.11917[0m[0m | time: 28.623s
[2K
| Adam | epoch: 021 | loss: 0.11917 - acc: 0.9607 -- iter: 1504/2015
[A[ATraining Step: 1308  | total loss: [1m[32m0.11108[0m[0m | time: 29.226s
[2K
| Adam | epoch: 021 | loss: 0.11108 - acc: 0.9646 -- iter: 1536/2015
[A[ATraining Step: 1309  | total loss: [1m[32m0.11210[0m[0m | time: 29.832s
[2K
| Adam | epoch: 021 | loss: 0.11210 - acc: 0.9619 -- iter: 1568/2015
[A[ATraining Step: 1310  | total loss: [1m[32m0.10979[0m[0m | time: 30.445s
[2K
| Adam | epoch: 021 | loss: 0.10979 - acc: 0.9626 -- iter: 1600/2015
[A[ATraining Step: 1311  | total loss: [1m[32m0.10330[0m[0m | time: 31.051s
[2K
| Adam | epoch: 021 | loss: 0.10330 - acc: 0.9663 -- iter: 1632/2015
[A[ATraining Step: 1312  | total loss: [1m[32m0.10285[0m[0m | time: 31.662s
[2K
| Adam | epoch: 021 | loss: 0.10285 - acc: 0.9666 -- iter: 1664/2015
[A[ATraining Step: 1313  | total loss: [1m[32m0.11357[0m[0m | time: 32.272s
[2K
| Adam | epoch: 021 | loss: 0.11357 - acc: 0.9637 -- iter: 1696/2015
[A[ATraining Step: 1314  | total loss: [1m[32m0.11619[0m[0m | time: 32.856s
[2K
| Adam | epoch: 021 | loss: 0.11619 - acc: 0.9610 -- iter: 1728/2015
[A[ATraining Step: 1315  | total loss: [1m[32m0.10743[0m[0m | time: 33.458s
[2K
| Adam | epoch: 021 | loss: 0.10743 - acc: 0.9649 -- iter: 1760/2015
[A[ATraining Step: 1316  | total loss: [1m[32m0.10730[0m[0m | time: 34.063s
[2K
| Adam | epoch: 021 | loss: 0.10730 - acc: 0.9653 -- iter: 1792/2015
[A[ATraining Step: 1317  | total loss: [1m[32m0.10097[0m[0m | time: 34.670s
[2K
| Adam | epoch: 021 | loss: 0.10097 - acc: 0.9688 -- iter: 1824/2015
[A[ATraining Step: 1318  | total loss: [1m[32m0.09693[0m[0m | time: 35.282s
[2K
| Adam | epoch: 021 | loss: 0.09693 - acc: 0.9688 -- iter: 1856/2015
[A[ATraining Step: 1319  | total loss: [1m[32m0.09317[0m[0m | time: 35.882s
[2K
| Adam | epoch: 021 | loss: 0.09317 - acc: 0.9688 -- iter: 1888/2015
[A[ATraining Step: 1320  | total loss: [1m[32m0.08775[0m[0m | time: 36.490s
[2K
| Adam | epoch: 021 | loss: 0.08775 - acc: 0.9719 -- iter: 1920/2015
[A[ATraining Step: 1321  | total loss: [1m[32m0.08856[0m[0m | time: 37.085s
[2K
| Adam | epoch: 021 | loss: 0.08856 - acc: 0.9716 -- iter: 1952/2015
[A[ATraining Step: 1322  | total loss: [1m[32m0.08792[0m[0m | time: 37.721s
[2K
| Adam | epoch: 021 | loss: 0.08792 - acc: 0.9744 -- iter: 1984/2015
[A[ATraining Step: 1323  | total loss: [1m[32m0.08548[0m[0m | time: 40.285s
[2K
| Adam | epoch: 021 | loss: 0.08548 - acc: 0.9739 | val_loss: 0.42283 - val_acc: 0.8619 -- iter: 2015/2015
--
Training Step: 1324  | total loss: [1m[32m0.10337[0m[0m | time: 0.625s
[2K
| Adam | epoch: 022 | loss: 0.10337 - acc: 0.9702 -- iter: 0032/2015
[A[ATraining Step: 1325  | total loss: [1m[32m0.11943[0m[0m | time: 1.221s
[2K
| Adam | epoch: 022 | loss: 0.11943 - acc: 0.9638 -- iter: 0064/2015
[A[ATraining Step: 1326  | total loss: [1m[32m0.11353[0m[0m | time: 1.835s
[2K
| Adam | epoch: 022 | loss: 0.11353 - acc: 0.9674 -- iter: 0096/2015
[A[ATraining Step: 1327  | total loss: [1m[32m0.10632[0m[0m | time: 2.453s
[2K
| Adam | epoch: 022 | loss: 0.10632 - acc: 0.9707 -- iter: 0128/2015
[A[ATraining Step: 1328  | total loss: [1m[32m0.09842[0m[0m | time: 3.062s
[2K
| Adam | epoch: 022 | loss: 0.09842 - acc: 0.9736 -- iter: 0160/2015
[A[ATraining Step: 1329  | total loss: [1m[32m0.09492[0m[0m | time: 3.663s
[2K
| Adam | epoch: 022 | loss: 0.09492 - acc: 0.9763 -- iter: 0192/2015
[A[ATraining Step: 1330  | total loss: [1m[32m0.09099[0m[0m | time: 4.275s
[2K
| Adam | epoch: 022 | loss: 0.09099 - acc: 0.9786 -- iter: 0224/2015
[A[ATraining Step: 1331  | total loss: [1m[32m0.08879[0m[0m | time: 4.873s
[2K
| Adam | epoch: 022 | loss: 0.08879 - acc: 0.9777 -- iter: 0256/2015
[A[ATraining Step: 1332  | total loss: [1m[32m0.08745[0m[0m | time: 5.477s
[2K
| Adam | epoch: 022 | loss: 0.08745 - acc: 0.9768 -- iter: 0288/2015
[A[ATraining Step: 1333  | total loss: [1m[32m0.09620[0m[0m | time: 6.093s
[2K
| Adam | epoch: 022 | loss: 0.09620 - acc: 0.9728 -- iter: 0320/2015
[A[ATraining Step: 1334  | total loss: [1m[32m0.09527[0m[0m | time: 6.699s
[2K
| Adam | epoch: 022 | loss: 0.09527 - acc: 0.9724 -- iter: 0352/2015
[A[ATraining Step: 1335  | total loss: [1m[32m0.09007[0m[0m | time: 7.307s
[2K
| Adam | epoch: 022 | loss: 0.09007 - acc: 0.9752 -- iter: 0384/2015
[A[ATraining Step: 1336  | total loss: [1m[32m0.08970[0m[0m | time: 7.917s
[2K
| Adam | epoch: 022 | loss: 0.08970 - acc: 0.9745 -- iter: 0416/2015
[A[ATraining Step: 1337  | total loss: [1m[32m0.08717[0m[0m | time: 8.533s
[2K
| Adam | epoch: 022 | loss: 0.08717 - acc: 0.9740 -- iter: 0448/2015
[A[ATraining Step: 1338  | total loss: [1m[32m0.08562[0m[0m | time: 9.165s
[2K
| Adam | epoch: 022 | loss: 0.08562 - acc: 0.9734 -- iter: 0480/2015
[A[ATraining Step: 1339  | total loss: [1m[32m0.07931[0m[0m | time: 9.802s
[2K
| Adam | epoch: 022 | loss: 0.07931 - acc: 0.9761 -- iter: 0512/2015
[A[ATraining Step: 1340  | total loss: [1m[32m0.07566[0m[0m | time: 10.415s
[2K
| Adam | epoch: 022 | loss: 0.07566 - acc: 0.9785 -- iter: 0544/2015
[A[ATraining Step: 1341  | total loss: [1m[32m0.09075[0m[0m | time: 11.039s
[2K
| Adam | epoch: 022 | loss: 0.09075 - acc: 0.9744 -- iter: 0576/2015
[A[ATraining Step: 1342  | total loss: [1m[32m0.09849[0m[0m | time: 11.637s
[2K
| Adam | epoch: 022 | loss: 0.09849 - acc: 0.9707 -- iter: 0608/2015
[A[ATraining Step: 1343  | total loss: [1m[32m0.09825[0m[0m | time: 12.230s
[2K
| Adam | epoch: 022 | loss: 0.09825 - acc: 0.9705 -- iter: 0640/2015
[A[ATraining Step: 1344  | total loss: [1m[32m0.13003[0m[0m | time: 12.811s
[2K
| Adam | epoch: 022 | loss: 0.13003 - acc: 0.9573 -- iter: 0672/2015
[A[ATraining Step: 1345  | total loss: [1m[32m0.15430[0m[0m | time: 13.409s
[2K
| Adam | epoch: 022 | loss: 0.15430 - acc: 0.9487 -- iter: 0704/2015
[A[ATraining Step: 1346  | total loss: [1m[32m0.14362[0m[0m | time: 14.025s
[2K
| Adam | epoch: 022 | loss: 0.14362 - acc: 0.9538 -- iter: 0736/2015
[A[ATraining Step: 1347  | total loss: [1m[32m0.13559[0m[0m | time: 14.641s
[2K
| Adam | epoch: 022 | loss: 0.13559 - acc: 0.9584 -- iter: 0768/2015
[A[ATraining Step: 1348  | total loss: [1m[32m0.12572[0m[0m | time: 15.243s
[2K
| Adam | epoch: 022 | loss: 0.12572 - acc: 0.9626 -- iter: 0800/2015
[A[ATraining Step: 1349  | total loss: [1m[32m0.11970[0m[0m | time: 15.868s
[2K
| Adam | epoch: 022 | loss: 0.11970 - acc: 0.9663 -- iter: 0832/2015
[A[ATraining Step: 1350  | total loss: [1m[32m0.11836[0m[0m | time: 16.473s
[2K
| Adam | epoch: 022 | loss: 0.11836 - acc: 0.9635 -- iter: 0864/2015
[A[ATraining Step: 1351  | total loss: [1m[32m0.11218[0m[0m | time: 17.079s
[2K
| Adam | epoch: 022 | loss: 0.11218 - acc: 0.9671 -- iter: 0896/2015
[A[ATraining Step: 1352  | total loss: [1m[32m0.10448[0m[0m | time: 17.677s
[2K
| Adam | epoch: 022 | loss: 0.10448 - acc: 0.9704 -- iter: 0928/2015
[A[ATraining Step: 1353  | total loss: [1m[32m0.09714[0m[0m | time: 18.281s
[2K
| Adam | epoch: 022 | loss: 0.09714 - acc: 0.9734 -- iter: 0960/2015
[A[ATraining Step: 1354  | total loss: [1m[32m0.09362[0m[0m | time: 18.921s
[2K
| Adam | epoch: 022 | loss: 0.09362 - acc: 0.9760 -- iter: 0992/2015
[A[ATraining Step: 1355  | total loss: [1m[32m0.09438[0m[0m | time: 19.527s
[2K
| Adam | epoch: 022 | loss: 0.09438 - acc: 0.9722 -- iter: 1024/2015
[A[ATraining Step: 1356  | total loss: [1m[32m0.09780[0m[0m | time: 20.130s
[2K
| Adam | epoch: 022 | loss: 0.09780 - acc: 0.9687 -- iter: 1056/2015
[A[ATraining Step: 1357  | total loss: [1m[32m0.09331[0m[0m | time: 20.736s
[2K
| Adam | epoch: 022 | loss: 0.09331 - acc: 0.9687 -- iter: 1088/2015
[A[ATraining Step: 1358  | total loss: [1m[32m0.08813[0m[0m | time: 21.345s
[2K
| Adam | epoch: 022 | loss: 0.08813 - acc: 0.9718 -- iter: 1120/2015
[A[ATraining Step: 1359  | total loss: [1m[32m0.08145[0m[0m | time: 21.948s
[2K
| Adam | epoch: 022 | loss: 0.08145 - acc: 0.9747 -- iter: 1152/2015
[A[ATraining Step: 1360  | total loss: [1m[32m0.07647[0m[0m | time: 22.561s
[2K
| Adam | epoch: 022 | loss: 0.07647 - acc: 0.9772 -- iter: 1184/2015
[A[ATraining Step: 1361  | total loss: [1m[32m0.07567[0m[0m | time: 23.168s
[2K
| Adam | epoch: 022 | loss: 0.07567 - acc: 0.9763 -- iter: 1216/2015
[A[ATraining Step: 1362  | total loss: [1m[32m0.07327[0m[0m | time: 23.771s
[2K
| Adam | epoch: 022 | loss: 0.07327 - acc: 0.9787 -- iter: 1248/2015
[A[ATraining Step: 1363  | total loss: [1m[32m0.07444[0m[0m | time: 24.392s
[2K
| Adam | epoch: 022 | loss: 0.07444 - acc: 0.9777 -- iter: 1280/2015
[A[ATraining Step: 1364  | total loss: [1m[32m0.07641[0m[0m | time: 24.993s
[2K
| Adam | epoch: 022 | loss: 0.07641 - acc: 0.9737 -- iter: 1312/2015
[A[ATraining Step: 1365  | total loss: [1m[32m0.07032[0m[0m | time: 25.625s
[2K
| Adam | epoch: 022 | loss: 0.07032 - acc: 0.9763 -- iter: 1344/2015
[A[ATraining Step: 1366  | total loss: [1m[32m0.06849[0m[0m | time: 26.261s
[2K
| Adam | epoch: 022 | loss: 0.06849 - acc: 0.9787 -- iter: 1376/2015
[A[ATraining Step: 1367  | total loss: [1m[32m0.06427[0m[0m | time: 26.860s
[2K
| Adam | epoch: 022 | loss: 0.06427 - acc: 0.9808 -- iter: 1408/2015
[A[ATraining Step: 1368  | total loss: [1m[32m0.07787[0m[0m | time: 27.468s
[2K
| Adam | epoch: 022 | loss: 0.07787 - acc: 0.9796 -- iter: 1440/2015
[A[ATraining Step: 1369  | total loss: [1m[32m0.07203[0m[0m | time: 28.078s
[2K
| Adam | epoch: 022 | loss: 0.07203 - acc: 0.9817 -- iter: 1472/2015
[A[ATraining Step: 1370  | total loss: [1m[32m0.07635[0m[0m | time: 28.687s
[2K
| Adam | epoch: 022 | loss: 0.07635 - acc: 0.9772 -- iter: 1504/2015
[A[ATraining Step: 1371  | total loss: [1m[32m0.07208[0m[0m | time: 29.293s
[2K
| Adam | epoch: 022 | loss: 0.07208 - acc: 0.9795 -- iter: 1536/2015
[A[ATraining Step: 1372  | total loss: [1m[32m0.06762[0m[0m | time: 29.885s
[2K
| Adam | epoch: 022 | loss: 0.06762 - acc: 0.9816 -- iter: 1568/2015
[A[ATraining Step: 1373  | total loss: [1m[32m0.06695[0m[0m | time: 30.484s
[2K
| Adam | epoch: 022 | loss: 0.06695 - acc: 0.9803 -- iter: 1600/2015
[A[ATraining Step: 1374  | total loss: [1m[32m0.06538[0m[0m | time: 31.088s
[2K
| Adam | epoch: 022 | loss: 0.06538 - acc: 0.9791 -- iter: 1632/2015
[A[ATraining Step: 1375  | total loss: [1m[32m0.07126[0m[0m | time: 31.698s
[2K
| Adam | epoch: 022 | loss: 0.07126 - acc: 0.9781 -- iter: 1664/2015
[A[ATraining Step: 1376  | total loss: [1m[32m0.08438[0m[0m | time: 32.321s
[2K
| Adam | epoch: 022 | loss: 0.08438 - acc: 0.9772 -- iter: 1696/2015
[A[ATraining Step: 1377  | total loss: [1m[32m0.07881[0m[0m | time: 32.926s
[2K
| Adam | epoch: 022 | loss: 0.07881 - acc: 0.9794 -- iter: 1728/2015
[A[ATraining Step: 1378  | total loss: [1m[32m0.08544[0m[0m | time: 33.539s
[2K
| Adam | epoch: 022 | loss: 0.08544 - acc: 0.9752 -- iter: 1760/2015
[A[ATraining Step: 1379  | total loss: [1m[32m0.08074[0m[0m | time: 34.147s
[2K
| Adam | epoch: 022 | loss: 0.08074 - acc: 0.9777 -- iter: 1792/2015
[A[ATraining Step: 1380  | total loss: [1m[32m0.07567[0m[0m | time: 34.751s
[2K
| Adam | epoch: 022 | loss: 0.07567 - acc: 0.9799 -- iter: 1824/2015
[A[ATraining Step: 1381  | total loss: [1m[32m0.06965[0m[0m | time: 35.362s
[2K
| Adam | epoch: 022 | loss: 0.06965 - acc: 0.9820 -- iter: 1856/2015
[A[ATraining Step: 1382  | total loss: [1m[32m0.06729[0m[0m | time: 35.962s
[2K
| Adam | epoch: 022 | loss: 0.06729 - acc: 0.9838 -- iter: 1888/2015
[A[ATraining Step: 1383  | total loss: [1m[32m0.06228[0m[0m | time: 36.574s
[2K
| Adam | epoch: 022 | loss: 0.06228 - acc: 0.9854 -- iter: 1920/2015
[A[ATraining Step: 1384  | total loss: [1m[32m0.05902[0m[0m | time: 37.200s
[2K
| Adam | epoch: 022 | loss: 0.05902 - acc: 0.9868 -- iter: 1952/2015
[A[ATraining Step: 1385  | total loss: [1m[32m0.05530[0m[0m | time: 37.807s
[2K
| Adam | epoch: 022 | loss: 0.05530 - acc: 0.9882 -- iter: 1984/2015
[A[ATraining Step: 1386  | total loss: [1m[32m0.05330[0m[0m | time: 40.394s
[2K
| Adam | epoch: 022 | loss: 0.05330 - acc: 0.9893 | val_loss: 0.46909 - val_acc: 0.8556 -- iter: 2015/2015
--
Training Step: 1387  | total loss: [1m[32m0.05147[0m[0m | time: 0.589s
[2K
| Adam | epoch: 023 | loss: 0.05147 - acc: 0.9904 -- iter: 0032/2015
[A[ATraining Step: 1388  | total loss: [1m[32m0.05058[0m[0m | time: 1.213s
[2K
| Adam | epoch: 023 | loss: 0.05058 - acc: 0.9914 -- iter: 0064/2015
[A[ATraining Step: 1389  | total loss: [1m[32m0.04990[0m[0m | time: 1.828s
[2K
| Adam | epoch: 023 | loss: 0.04990 - acc: 0.9922 -- iter: 0096/2015
[A[ATraining Step: 1390  | total loss: [1m[32m0.05059[0m[0m | time: 2.425s
[2K
| Adam | epoch: 023 | loss: 0.05059 - acc: 0.9899 -- iter: 0128/2015
[A[ATraining Step: 1391  | total loss: [1m[32m0.05044[0m[0m | time: 3.031s
[2K
| Adam | epoch: 023 | loss: 0.05044 - acc: 0.9909 -- iter: 0160/2015
[A[ATraining Step: 1392  | total loss: [1m[32m0.04772[0m[0m | time: 3.645s
[2K
| Adam | epoch: 023 | loss: 0.04772 - acc: 0.9918 -- iter: 0192/2015
[A[ATraining Step: 1393  | total loss: [1m[32m0.04448[0m[0m | time: 4.245s
[2K
| Adam | epoch: 023 | loss: 0.04448 - acc: 0.9926 -- iter: 0224/2015
[A[ATraining Step: 1394  | total loss: [1m[32m0.04592[0m[0m | time: 4.840s
[2K
| Adam | epoch: 023 | loss: 0.04592 - acc: 0.9902 -- iter: 0256/2015
[A[ATraining Step: 1395  | total loss: [1m[32m0.04709[0m[0m | time: 5.456s
[2K
| Adam | epoch: 023 | loss: 0.04709 - acc: 0.9881 -- iter: 0288/2015
[A[ATraining Step: 1396  | total loss: [1m[32m0.04735[0m[0m | time: 6.052s
[2K
| Adam | epoch: 023 | loss: 0.04735 - acc: 0.9893 -- iter: 0320/2015
[A[ATraining Step: 1397  | total loss: [1m[32m0.05004[0m[0m | time: 6.687s
[2K
| Adam | epoch: 023 | loss: 0.05004 - acc: 0.9872 -- iter: 0352/2015
[A[ATraining Step: 1398  | total loss: [1m[32m0.06047[0m[0m | time: 7.287s
[2K
| Adam | epoch: 023 | loss: 0.06047 - acc: 0.9791 -- iter: 0384/2015
[A[ATraining Step: 1399  | total loss: [1m[32m0.06168[0m[0m | time: 7.882s
[2K
| Adam | epoch: 023 | loss: 0.06168 - acc: 0.9781 -- iter: 0416/2015
[A[ATraining Step: 1400  | total loss: [1m[32m0.07644[0m[0m | time: 10.451s
[2K
| Adam | epoch: 023 | loss: 0.07644 - acc: 0.9772 | val_loss: 0.44178 - val_acc: 0.8635 -- iter: 0448/2015
--
Training Step: 1401  | total loss: [1m[32m0.07340[0m[0m | time: 11.067s
[2K
| Adam | epoch: 023 | loss: 0.07340 - acc: 0.9794 -- iter: 0480/2015
[A[ATraining Step: 1402  | total loss: [1m[32m0.06784[0m[0m | time: 11.671s
[2K
| Adam | epoch: 023 | loss: 0.06784 - acc: 0.9815 -- iter: 0512/2015
[A[ATraining Step: 1403  | total loss: [1m[32m0.06216[0m[0m | time: 12.276s
[2K
| Adam | epoch: 023 | loss: 0.06216 - acc: 0.9833 -- iter: 0544/2015
[A[ATraining Step: 1404  | total loss: [1m[32m0.05972[0m[0m | time: 12.886s
[2K
| Adam | epoch: 023 | loss: 0.05972 - acc: 0.9850 -- iter: 0576/2015
[A[ATraining Step: 1405  | total loss: [1m[32m0.05767[0m[0m | time: 13.497s
[2K
| Adam | epoch: 023 | loss: 0.05767 - acc: 0.9865 -- iter: 0608/2015
[A[ATraining Step: 1406  | total loss: [1m[32m0.05620[0m[0m | time: 14.116s
[2K
| Adam | epoch: 023 | loss: 0.05620 - acc: 0.9879 -- iter: 0640/2015
[A[ATraining Step: 1407  | total loss: [1m[32m0.05403[0m[0m | time: 14.725s
[2K
| Adam | epoch: 023 | loss: 0.05403 - acc: 0.9891 -- iter: 0672/2015
[A[ATraining Step: 1408  | total loss: [1m[32m0.06801[0m[0m | time: 15.313s
[2K
| Adam | epoch: 023 | loss: 0.06801 - acc: 0.9837 -- iter: 0704/2015
[A[ATraining Step: 1409  | total loss: [1m[32m0.07850[0m[0m | time: 15.919s
[2K
| Adam | epoch: 023 | loss: 0.07850 - acc: 0.9789 -- iter: 0736/2015
[A[ATraining Step: 1410  | total loss: [1m[32m0.07243[0m[0m | time: 16.524s
[2K
| Adam | epoch: 023 | loss: 0.07243 - acc: 0.9810 -- iter: 0768/2015
[A[ATraining Step: 1411  | total loss: [1m[32m0.07463[0m[0m | time: 17.126s
[2K
| Adam | epoch: 023 | loss: 0.07463 - acc: 0.9767 -- iter: 0800/2015
[A[ATraining Step: 1412  | total loss: [1m[32m0.06840[0m[0m | time: 17.726s
[2K
| Adam | epoch: 023 | loss: 0.06840 - acc: 0.9790 -- iter: 0832/2015
[A[ATraining Step: 1413  | total loss: [1m[32m0.06336[0m[0m | time: 18.344s
[2K
| Adam | epoch: 023 | loss: 0.06336 - acc: 0.9811 -- iter: 0864/2015
[A[ATraining Step: 1414  | total loss: [1m[32m0.06231[0m[0m | time: 18.937s
[2K
| Adam | epoch: 023 | loss: 0.06231 - acc: 0.9830 -- iter: 0896/2015
[A[ATraining Step: 1415  | total loss: [1m[32m0.06966[0m[0m | time: 19.548s
[2K
| Adam | epoch: 023 | loss: 0.06966 - acc: 0.9816 -- iter: 0928/2015
[A[ATraining Step: 1416  | total loss: [1m[32m0.07722[0m[0m | time: 20.162s
[2K
| Adam | epoch: 023 | loss: 0.07722 - acc: 0.9740 -- iter: 0960/2015
[A[ATraining Step: 1417  | total loss: [1m[32m0.07698[0m[0m | time: 20.756s
[2K
| Adam | epoch: 023 | loss: 0.07698 - acc: 0.9735 -- iter: 0992/2015
[A[ATraining Step: 1418  | total loss: [1m[32m0.08085[0m[0m | time: 21.354s
[2K
| Adam | epoch: 023 | loss: 0.08085 - acc: 0.9699 -- iter: 1024/2015
[A[ATraining Step: 1419  | total loss: [1m[32m0.09391[0m[0m | time: 21.972s
[2K
| Adam | epoch: 023 | loss: 0.09391 - acc: 0.9667 -- iter: 1056/2015
[A[ATraining Step: 1420  | total loss: [1m[32m0.08689[0m[0m | time: 22.583s
[2K
| Adam | epoch: 023 | loss: 0.08689 - acc: 0.9700 -- iter: 1088/2015
[A[ATraining Step: 1421  | total loss: [1m[32m0.08434[0m[0m | time: 23.194s
[2K
| Adam | epoch: 023 | loss: 0.08434 - acc: 0.9699 -- iter: 1120/2015
[A[ATraining Step: 1422  | total loss: [1m[32m0.08299[0m[0m | time: 23.797s
[2K
| Adam | epoch: 023 | loss: 0.08299 - acc: 0.9729 -- iter: 1152/2015
[A[ATraining Step: 1423  | total loss: [1m[32m0.09333[0m[0m | time: 24.394s
[2K
| Adam | epoch: 023 | loss: 0.09333 - acc: 0.9725 -- iter: 1184/2015
[A[ATraining Step: 1424  | total loss: [1m[32m0.08860[0m[0m | time: 25.007s
[2K
| Adam | epoch: 023 | loss: 0.08860 - acc: 0.9752 -- iter: 1216/2015
[A[ATraining Step: 1425  | total loss: [1m[32m0.08445[0m[0m | time: 25.608s
[2K
| Adam | epoch: 023 | loss: 0.08445 - acc: 0.9746 -- iter: 1248/2015
[A[ATraining Step: 1426  | total loss: [1m[32m0.08539[0m[0m | time: 26.206s
[2K
| Adam | epoch: 023 | loss: 0.08539 - acc: 0.9709 -- iter: 1280/2015
[A[ATraining Step: 1427  | total loss: [1m[32m0.10228[0m[0m | time: 26.821s
[2K
| Adam | epoch: 023 | loss: 0.10228 - acc: 0.9675 -- iter: 1312/2015
[A[ATraining Step: 1428  | total loss: [1m[32m0.09401[0m[0m | time: 27.438s
[2K
| Adam | epoch: 023 | loss: 0.09401 - acc: 0.9708 -- iter: 1344/2015
[A[ATraining Step: 1429  | total loss: [1m[32m0.09178[0m[0m | time: 28.037s
[2K
| Adam | epoch: 023 | loss: 0.09178 - acc: 0.9737 -- iter: 1376/2015
[A[ATraining Step: 1430  | total loss: [1m[32m0.08564[0m[0m | time: 28.641s
[2K
| Adam | epoch: 023 | loss: 0.08564 - acc: 0.9763 -- iter: 1408/2015
[A[ATraining Step: 1431  | total loss: [1m[32m0.08216[0m[0m | time: 29.281s
[2K
| Adam | epoch: 023 | loss: 0.08216 - acc: 0.9756 -- iter: 1440/2015
[A[ATraining Step: 1432  | total loss: [1m[32m0.07913[0m[0m | time: 29.875s
[2K
| Adam | epoch: 023 | loss: 0.07913 - acc: 0.9780 -- iter: 1472/2015
[A[ATraining Step: 1433  | total loss: [1m[32m0.07521[0m[0m | time: 30.479s
[2K
| Adam | epoch: 023 | loss: 0.07521 - acc: 0.9802 -- iter: 1504/2015
[A[ATraining Step: 1434  | total loss: [1m[32m0.07404[0m[0m | time: 31.084s
[2K
| Adam | epoch: 023 | loss: 0.07404 - acc: 0.9791 -- iter: 1536/2015
[A[ATraining Step: 1435  | total loss: [1m[32m0.07018[0m[0m | time: 31.694s
[2K
| Adam | epoch: 023 | loss: 0.07018 - acc: 0.9812 -- iter: 1568/2015
[A[ATraining Step: 1436  | total loss: [1m[32m0.06466[0m[0m | time: 32.321s
[2K
| Adam | epoch: 023 | loss: 0.06466 - acc: 0.9830 -- iter: 1600/2015
[A[ATraining Step: 1437  | total loss: [1m[32m0.06295[0m[0m | time: 32.920s
[2K
| Adam | epoch: 023 | loss: 0.06295 - acc: 0.9847 -- iter: 1632/2015
[A[ATraining Step: 1438  | total loss: [1m[32m0.05935[0m[0m | time: 33.517s
[2K
| Adam | epoch: 023 | loss: 0.05935 - acc: 0.9863 -- iter: 1664/2015
[A[ATraining Step: 1439  | total loss: [1m[32m0.06228[0m[0m | time: 34.115s
[2K
| Adam | epoch: 023 | loss: 0.06228 - acc: 0.9845 -- iter: 1696/2015
[A[ATraining Step: 1440  | total loss: [1m[32m0.10388[0m[0m | time: 34.727s
[2K
| Adam | epoch: 023 | loss: 0.10388 - acc: 0.9798 -- iter: 1728/2015
[A[ATraining Step: 1441  | total loss: [1m[32m0.09645[0m[0m | time: 35.330s
[2K
| Adam | epoch: 023 | loss: 0.09645 - acc: 0.9818 -- iter: 1760/2015
[A[ATraining Step: 1442  | total loss: [1m[32m0.09077[0m[0m | time: 35.937s
[2K
| Adam | epoch: 023 | loss: 0.09077 - acc: 0.9836 -- iter: 1792/2015
[A[ATraining Step: 1443  | total loss: [1m[32m0.08422[0m[0m | time: 36.550s
[2K
| Adam | epoch: 023 | loss: 0.08422 - acc: 0.9853 -- iter: 1824/2015
[A[ATraining Step: 1444  | total loss: [1m[32m0.09283[0m[0m | time: 37.165s
[2K
| Adam | epoch: 023 | loss: 0.09283 - acc: 0.9836 -- iter: 1856/2015
[A[ATraining Step: 1445  | total loss: [1m[32m0.08560[0m[0m | time: 37.760s
[2K
| Adam | epoch: 023 | loss: 0.08560 - acc: 0.9853 -- iter: 1888/2015
[A[ATraining Step: 1446  | total loss: [1m[32m0.08077[0m[0m | time: 38.368s
[2K
| Adam | epoch: 023 | loss: 0.08077 - acc: 0.9836 -- iter: 1920/2015
[A[ATraining Step: 1447  | total loss: [1m[32m0.07967[0m[0m | time: 38.971s
[2K
| Adam | epoch: 023 | loss: 0.07967 - acc: 0.9821 -- iter: 1952/2015
[A[ATraining Step: 1448  | total loss: [1m[32m0.07342[0m[0m | time: 39.577s
[2K
| Adam | epoch: 023 | loss: 0.07342 - acc: 0.9839 -- iter: 1984/2015
[A[ATraining Step: 1449  | total loss: [1m[32m0.07031[0m[0m | time: 42.143s
[2K
| Adam | epoch: 023 | loss: 0.07031 - acc: 0.9855 | val_loss: 0.42151 - val_acc: 0.8603 -- iter: 2015/2015
--
Training Step: 1450  | total loss: [1m[32m0.06582[0m[0m | time: 0.617s
[2K
| Adam | epoch: 024 | loss: 0.06582 - acc: 0.9870 -- iter: 0032/2015
[A[ATraining Step: 1451  | total loss: [1m[32m0.06099[0m[0m | time: 1.228s
[2K
| Adam | epoch: 024 | loss: 0.06099 - acc: 0.9883 -- iter: 0064/2015
[A[ATraining Step: 1452  | total loss: [1m[32m0.05861[0m[0m | time: 1.833s
[2K
| Adam | epoch: 024 | loss: 0.05861 - acc: 0.9894 -- iter: 0096/2015
[A[ATraining Step: 1453  | total loss: [1m[32m0.05475[0m[0m | time: 2.437s
[2K
| Adam | epoch: 024 | loss: 0.05475 - acc: 0.9905 -- iter: 0128/2015
[A[ATraining Step: 1454  | total loss: [1m[32m0.05311[0m[0m | time: 3.044s
[2K
| Adam | epoch: 024 | loss: 0.05311 - acc: 0.9915 -- iter: 0160/2015
[A[ATraining Step: 1455  | total loss: [1m[32m0.05223[0m[0m | time: 3.659s
[2K
| Adam | epoch: 024 | loss: 0.05223 - acc: 0.9892 -- iter: 0192/2015
[A[ATraining Step: 1456  | total loss: [1m[32m0.05195[0m[0m | time: 4.287s
[2K
| Adam | epoch: 024 | loss: 0.05195 - acc: 0.9903 -- iter: 0224/2015
[A[ATraining Step: 1457  | total loss: [1m[32m0.05502[0m[0m | time: 4.897s
[2K
| Adam | epoch: 024 | loss: 0.05502 - acc: 0.9881 -- iter: 0256/2015
[A[ATraining Step: 1458  | total loss: [1m[32m0.05301[0m[0m | time: 5.504s
[2K
| Adam | epoch: 024 | loss: 0.05301 - acc: 0.9893 -- iter: 0288/2015
[A[ATraining Step: 1459  | total loss: [1m[32m0.04951[0m[0m | time: 6.108s
[2K
| Adam | epoch: 024 | loss: 0.04951 - acc: 0.9904 -- iter: 0320/2015
[A[ATraining Step: 1460  | total loss: [1m[32m0.04618[0m[0m | time: 6.724s
[2K
| Adam | epoch: 024 | loss: 0.04618 - acc: 0.9913 -- iter: 0352/2015
[A[ATraining Step: 1461  | total loss: [1m[32m0.04678[0m[0m | time: 7.340s
[2K
| Adam | epoch: 024 | loss: 0.04678 - acc: 0.9922 -- iter: 0384/2015
[A[ATraining Step: 1462  | total loss: [1m[32m0.04635[0m[0m | time: 7.933s
[2K
| Adam | epoch: 024 | loss: 0.04635 - acc: 0.9930 -- iter: 0416/2015
[A[ATraining Step: 1463  | total loss: [1m[32m0.04690[0m[0m | time: 8.533s
[2K
| Adam | epoch: 024 | loss: 0.04690 - acc: 0.9937 -- iter: 0448/2015
[A[ATraining Step: 1464  | total loss: [1m[32m0.04713[0m[0m | time: 9.121s
[2K
| Adam | epoch: 024 | loss: 0.04713 - acc: 0.9943 -- iter: 0480/2015
[A[ATraining Step: 1465  | total loss: [1m[32m0.05477[0m[0m | time: 9.731s
[2K
| Adam | epoch: 024 | loss: 0.05477 - acc: 0.9886 -- iter: 0512/2015
[A[ATraining Step: 1466  | total loss: [1m[32m0.05336[0m[0m | time: 10.326s
[2K
| Adam | epoch: 024 | loss: 0.05336 - acc: 0.9898 -- iter: 0544/2015
[A[ATraining Step: 1467  | total loss: [1m[32m0.05053[0m[0m | time: 10.936s
[2K
| Adam | epoch: 024 | loss: 0.05053 - acc: 0.9908 -- iter: 0576/2015
[A[ATraining Step: 1468  | total loss: [1m[32m0.04909[0m[0m | time: 11.529s
[2K
| Adam | epoch: 024 | loss: 0.04909 - acc: 0.9917 -- iter: 0608/2015
[A[ATraining Step: 1469  | total loss: [1m[32m0.04729[0m[0m | time: 12.145s
[2K
| Adam | epoch: 024 | loss: 0.04729 - acc: 0.9925 -- iter: 0640/2015
[A[ATraining Step: 1470  | total loss: [1m[32m0.05281[0m[0m | time: 12.742s
[2K
| Adam | epoch: 024 | loss: 0.05281 - acc: 0.9870 -- iter: 0672/2015
[A[ATraining Step: 1471  | total loss: [1m[32m0.05708[0m[0m | time: 13.337s
[2K
| Adam | epoch: 024 | loss: 0.05708 - acc: 0.9852 -- iter: 0704/2015
[A[ATraining Step: 1472  | total loss: [1m[32m0.05479[0m[0m | time: 13.926s
[2K
| Adam | epoch: 024 | loss: 0.05479 - acc: 0.9867 -- iter: 0736/2015
[A[ATraining Step: 1473  | total loss: [1m[32m0.05392[0m[0m | time: 14.539s
[2K
| Adam | epoch: 024 | loss: 0.05392 - acc: 0.9880 -- iter: 0768/2015
[A[ATraining Step: 1474  | total loss: [1m[32m0.05313[0m[0m | time: 15.156s
[2K
| Adam | epoch: 024 | loss: 0.05313 - acc: 0.9861 -- iter: 0800/2015
[A[ATraining Step: 1475  | total loss: [1m[32m0.05071[0m[0m | time: 15.770s
[2K
| Adam | epoch: 024 | loss: 0.05071 - acc: 0.9875 -- iter: 0832/2015
[A[ATraining Step: 1476  | total loss: [1m[32m0.05323[0m[0m | time: 16.379s
[2K
| Adam | epoch: 024 | loss: 0.05323 - acc: 0.9856 -- iter: 0864/2015
[A[ATraining Step: 1477  | total loss: [1m[32m0.05046[0m[0m | time: 16.987s
[2K
| Adam | epoch: 024 | loss: 0.05046 - acc: 0.9870 -- iter: 0896/2015
[A[ATraining Step: 1478  | total loss: [1m[32m0.05037[0m[0m | time: 17.590s
[2K
| Adam | epoch: 024 | loss: 0.05037 - acc: 0.9852 -- iter: 0928/2015
[A[ATraining Step: 1479  | total loss: [1m[32m0.04778[0m[0m | time: 18.196s
[2K
| Adam | epoch: 024 | loss: 0.04778 - acc: 0.9867 -- iter: 0960/2015
[A[ATraining Step: 1480  | total loss: [1m[32m0.04853[0m[0m | time: 18.809s
[2K
| Adam | epoch: 024 | loss: 0.04853 - acc: 0.9849 -- iter: 0992/2015
[A[ATraining Step: 1481  | total loss: [1m[32m0.05478[0m[0m | time: 19.408s
[2K
| Adam | epoch: 024 | loss: 0.05478 - acc: 0.9802 -- iter: 1024/2015
[A[ATraining Step: 1482  | total loss: [1m[32m0.05282[0m[0m | time: 20.013s
[2K
| Adam | epoch: 024 | loss: 0.05282 - acc: 0.9821 -- iter: 1056/2015
[A[ATraining Step: 1483  | total loss: [1m[32m0.05048[0m[0m | time: 20.657s
[2K
| Adam | epoch: 024 | loss: 0.05048 - acc: 0.9839 -- iter: 1088/2015
[A[ATraining Step: 1484  | total loss: [1m[32m0.04828[0m[0m | time: 21.252s
[2K
| Adam | epoch: 024 | loss: 0.04828 - acc: 0.9855 -- iter: 1120/2015
[A[ATraining Step: 1485  | total loss: [1m[32m0.04712[0m[0m | time: 21.855s
[2K
| Adam | epoch: 024 | loss: 0.04712 - acc: 0.9870 -- iter: 1152/2015
[A[ATraining Step: 1486  | total loss: [1m[32m0.05142[0m[0m | time: 22.462s
[2K
| Adam | epoch: 024 | loss: 0.05142 - acc: 0.9820 -- iter: 1184/2015
[A[ATraining Step: 1487  | total loss: [1m[32m0.05059[0m[0m | time: 23.086s
[2K
| Adam | epoch: 024 | loss: 0.05059 - acc: 0.9807 -- iter: 1216/2015
[A[ATraining Step: 1488  | total loss: [1m[32m0.04702[0m[0m | time: 23.701s
[2K
| Adam | epoch: 024 | loss: 0.04702 - acc: 0.9826 -- iter: 1248/2015
[A[ATraining Step: 1489  | total loss: [1m[32m0.04808[0m[0m | time: 24.300s
[2K
| Adam | epoch: 024 | loss: 0.04808 - acc: 0.9812 -- iter: 1280/2015
[A[ATraining Step: 1490  | total loss: [1m[32m0.07232[0m[0m | time: 24.909s
[2K
| Adam | epoch: 024 | loss: 0.07232 - acc: 0.9737 -- iter: 1312/2015
[A[ATraining Step: 1491  | total loss: [1m[32m0.06960[0m[0m | time: 25.510s
[2K
| Adam | epoch: 024 | loss: 0.06960 - acc: 0.9764 -- iter: 1344/2015
[A[ATraining Step: 1492  | total loss: [1m[32m0.06722[0m[0m | time: 26.102s
[2K
| Adam | epoch: 024 | loss: 0.06722 - acc: 0.9787 -- iter: 1376/2015
[A[ATraining Step: 1493  | total loss: [1m[32m0.06399[0m[0m | time: 26.704s
[2K
| Adam | epoch: 024 | loss: 0.06399 - acc: 0.9809 -- iter: 1408/2015
[A[ATraining Step: 1494  | total loss: [1m[32m0.06110[0m[0m | time: 27.308s
[2K
| Adam | epoch: 024 | loss: 0.06110 - acc: 0.9828 -- iter: 1440/2015
[A[ATraining Step: 1495  | total loss: [1m[32m0.05903[0m[0m | time: 27.900s
[2K
| Adam | epoch: 024 | loss: 0.05903 - acc: 0.9845 -- iter: 1472/2015
[A[ATraining Step: 1496  | total loss: [1m[32m0.05588[0m[0m | time: 28.497s
[2K
| Adam | epoch: 024 | loss: 0.05588 - acc: 0.9860 -- iter: 1504/2015
[A[ATraining Step: 1497  | total loss: [1m[32m0.05273[0m[0m | time: 29.073s
[2K
| Adam | epoch: 024 | loss: 0.05273 - acc: 0.9874 -- iter: 1536/2015
[A[ATraining Step: 1498  | total loss: [1m[32m0.05802[0m[0m | time: 29.679s
[2K
| Adam | epoch: 024 | loss: 0.05802 - acc: 0.9824 -- iter: 1568/2015
[A[ATraining Step: 1499  | total loss: [1m[32m0.05813[0m[0m | time: 30.296s
[2K
| Adam | epoch: 024 | loss: 0.05813 - acc: 0.9842 -- iter: 1600/2015
[A[ATraining Step: 1500  | total loss: [1m[32m0.07331[0m[0m | time: 30.920s
[2K
| Adam | epoch: 024 | loss: 0.07331 - acc: 0.9827 -- iter: 1632/2015
[A[ATraining Step: 1501  | total loss: [1m[32m0.06962[0m[0m | time: 31.522s
[2K
| Adam | epoch: 024 | loss: 0.06962 - acc: 0.9844 -- iter: 1664/2015
[A[ATraining Step: 1502  | total loss: [1m[32m0.06630[0m[0m | time: 32.133s
[2K
| Adam | epoch: 024 | loss: 0.06630 - acc: 0.9860 -- iter: 1696/2015
[A[ATraining Step: 1503  | total loss: [1m[32m0.06062[0m[0m | time: 32.745s
[2K
| Adam | epoch: 024 | loss: 0.06062 - acc: 0.9874 -- iter: 1728/2015
[A[ATraining Step: 1504  | total loss: [1m[32m0.08894[0m[0m | time: 33.349s
[2K
| Adam | epoch: 024 | loss: 0.08894 - acc: 0.9824 -- iter: 1760/2015
[A[ATraining Step: 1505  | total loss: [1m[32m0.08173[0m[0m | time: 33.984s
[2K
| Adam | epoch: 024 | loss: 0.08173 - acc: 0.9841 -- iter: 1792/2015
[A[ATraining Step: 1506  | total loss: [1m[32m0.07714[0m[0m | time: 34.585s
[2K
| Adam | epoch: 024 | loss: 0.07714 - acc: 0.9857 -- iter: 1824/2015
[A[ATraining Step: 1507  | total loss: [1m[32m0.07486[0m[0m | time: 35.188s
[2K
| Adam | epoch: 024 | loss: 0.07486 - acc: 0.9840 -- iter: 1856/2015
[A[ATraining Step: 1508  | total loss: [1m[32m0.06868[0m[0m | time: 35.785s
[2K
| Adam | epoch: 024 | loss: 0.06868 - acc: 0.9856 -- iter: 1888/2015
[A[ATraining Step: 1509  | total loss: [1m[32m0.06495[0m[0m | time: 36.395s
[2K
| Adam | epoch: 024 | loss: 0.06495 - acc: 0.9839 -- iter: 1920/2015
[A[ATraining Step: 1510  | total loss: [1m[32m0.06133[0m[0m | time: 36.997s
[2K
| Adam | epoch: 024 | loss: 0.06133 - acc: 0.9855 -- iter: 1952/2015
[A[ATraining Step: 1511  | total loss: [1m[32m0.05616[0m[0m | time: 37.625s
[2K
| Adam | epoch: 024 | loss: 0.05616 - acc: 0.9870 -- iter: 1984/2015
[A[ATraining Step: 1512  | total loss: [1m[32m0.05520[0m[0m | time: 40.191s
[2K
| Adam | epoch: 024 | loss: 0.05520 - acc: 0.9883 | val_loss: 0.45186 - val_acc: 0.8714 -- iter: 2015/2015
--
Training Step: 1513  | total loss: [1m[32m0.05368[0m[0m | time: 0.620s
[2K
| Adam | epoch: 025 | loss: 0.05368 - acc: 0.9863 -- iter: 0032/2015
[A[ATraining Step: 1514  | total loss: [1m[32m0.05053[0m[0m | time: 1.223s
[2K
| Adam | epoch: 025 | loss: 0.05053 - acc: 0.9877 -- iter: 0064/2015
[A[ATraining Step: 1515  | total loss: [1m[32m0.04661[0m[0m | time: 1.818s
[2K
| Adam | epoch: 025 | loss: 0.04661 - acc: 0.9889 -- iter: 0096/2015
[A[ATraining Step: 1516  | total loss: [1m[32m0.04352[0m[0m | time: 2.411s
[2K
| Adam | epoch: 025 | loss: 0.04352 - acc: 0.9900 -- iter: 0128/2015
[A[ATraining Step: 1517  | total loss: [1m[32m0.04164[0m[0m | time: 3.012s
[2K
| Adam | epoch: 025 | loss: 0.04164 - acc: 0.9910 -- iter: 0160/2015
[A[ATraining Step: 1518  | total loss: [1m[32m0.03959[0m[0m | time: 3.625s
[2K
| Adam | epoch: 025 | loss: 0.03959 - acc: 0.9919 -- iter: 0192/2015
[A[ATraining Step: 1519  | total loss: [1m[32m0.04297[0m[0m | time: 4.278s
[2K
| Adam | epoch: 025 | loss: 0.04297 - acc: 0.9896 -- iter: 0224/2015
[A[ATraining Step: 1520  | total loss: [1m[32m0.03945[0m[0m | time: 4.887s
[2K
| Adam | epoch: 025 | loss: 0.03945 - acc: 0.9907 -- iter: 0256/2015
[A[ATraining Step: 1521  | total loss: [1m[32m0.04624[0m[0m | time: 5.509s
[2K
| Adam | epoch: 025 | loss: 0.04624 - acc: 0.9853 -- iter: 0288/2015
[A[ATraining Step: 1522  | total loss: [1m[32m0.04586[0m[0m | time: 6.135s
[2K
| Adam | epoch: 025 | loss: 0.04586 - acc: 0.9868 -- iter: 0320/2015
[A[ATraining Step: 1523  | total loss: [1m[32m0.04414[0m[0m | time: 6.765s
[2K
| Adam | epoch: 025 | loss: 0.04414 - acc: 0.9881 -- iter: 0352/2015
[A[ATraining Step: 1524  | total loss: [1m[32m0.04028[0m[0m | time: 7.365s
[2K
| Adam | epoch: 025 | loss: 0.04028 - acc: 0.9893 -- iter: 0384/2015
[A[ATraining Step: 1525  | total loss: [1m[32m0.04766[0m[0m | time: 7.957s
[2K
| Adam | epoch: 025 | loss: 0.04766 - acc: 0.9873 -- iter: 0416/2015
[A[ATraining Step: 1526  | total loss: [1m[32m0.05278[0m[0m | time: 8.574s
[2K
| Adam | epoch: 025 | loss: 0.05278 - acc: 0.9823 -- iter: 0448/2015
[A[ATraining Step: 1527  | total loss: [1m[32m0.05147[0m[0m | time: 9.175s
[2K
| Adam | epoch: 025 | loss: 0.05147 - acc: 0.9809 -- iter: 0480/2015
[A[ATraining Step: 1528  | total loss: [1m[32m0.05765[0m[0m | time: 9.773s
[2K
| Adam | epoch: 025 | loss: 0.05765 - acc: 0.9766 -- iter: 0512/2015
[A[ATraining Step: 1529  | total loss: [1m[32m0.05307[0m[0m | time: 10.403s
[2K
| Adam | epoch: 025 | loss: 0.05307 - acc: 0.9789 -- iter: 0544/2015
[A[ATraining Step: 1530  | total loss: [1m[32m0.05150[0m[0m | time: 11.017s
[2K
| Adam | epoch: 025 | loss: 0.05150 - acc: 0.9810 -- iter: 0576/2015
[A[ATraining Step: 1531  | total loss: [1m[32m0.04937[0m[0m | time: 11.626s
[2K
| Adam | epoch: 025 | loss: 0.04937 - acc: 0.9829 -- iter: 0608/2015
[A[ATraining Step: 1532  | total loss: [1m[32m0.04621[0m[0m | time: 12.228s
[2K
| Adam | epoch: 025 | loss: 0.04621 - acc: 0.9846 -- iter: 0640/2015
[A[ATraining Step: 1533  | total loss: [1m[32m0.06432[0m[0m | time: 12.842s
[2K
| Adam | epoch: 025 | loss: 0.06432 - acc: 0.9799 -- iter: 0672/2015
[A[ATraining Step: 1534  | total loss: [1m[32m0.07818[0m[0m | time: 13.448s
[2K
| Adam | epoch: 025 | loss: 0.07818 - acc: 0.9788 -- iter: 0704/2015
[A[ATraining Step: 1535  | total loss: [1m[32m0.07124[0m[0m | time: 14.037s
[2K
| Adam | epoch: 025 | loss: 0.07124 - acc: 0.9809 -- iter: 0736/2015
[A[ATraining Step: 1536  | total loss: [1m[32m0.06599[0m[0m | time: 14.623s
[2K
| Adam | epoch: 025 | loss: 0.06599 - acc: 0.9828 -- iter: 0768/2015
[A[ATraining Step: 1537  | total loss: [1m[32m0.06131[0m[0m | time: 15.230s
[2K
| Adam | epoch: 025 | loss: 0.06131 - acc: 0.9845 -- iter: 0800/2015
[A[ATraining Step: 1538  | total loss: [1m[32m0.05629[0m[0m | time: 15.842s
[2K
| Adam | epoch: 025 | loss: 0.05629 - acc: 0.9861 -- iter: 0832/2015
[A[ATraining Step: 1539  | total loss: [1m[32m0.06801[0m[0m | time: 16.441s
[2K
| Adam | epoch: 025 | loss: 0.06801 - acc: 0.9844 -- iter: 0864/2015
[A[ATraining Step: 1540  | total loss: [1m[32m0.06337[0m[0m | time: 17.069s
[2K
| Adam | epoch: 025 | loss: 0.06337 - acc: 0.9859 -- iter: 0896/2015
[A[ATraining Step: 1541  | total loss: [1m[32m0.06279[0m[0m | time: 17.689s
[2K
| Adam | epoch: 025 | loss: 0.06279 - acc: 0.9842 -- iter: 0928/2015
[A[ATraining Step: 1542  | total loss: [1m[32m0.06273[0m[0m | time: 18.302s
[2K
| Adam | epoch: 025 | loss: 0.06273 - acc: 0.9827 -- iter: 0960/2015
[A[ATraining Step: 1543  | total loss: [1m[32m0.05789[0m[0m | time: 18.918s
[2K
| Adam | epoch: 025 | loss: 0.05789 - acc: 0.9844 -- iter: 0992/2015
[A[ATraining Step: 1544  | total loss: [1m[32m0.06201[0m[0m | time: 19.540s
[2K
| Adam | epoch: 025 | loss: 0.06201 - acc: 0.9828 -- iter: 1024/2015
[A[ATraining Step: 1545  | total loss: [1m[32m0.05849[0m[0m | time: 20.144s
[2K
| Adam | epoch: 025 | loss: 0.05849 - acc: 0.9845 -- iter: 1056/2015
[A[ATraining Step: 1546  | total loss: [1m[32m0.05444[0m[0m | time: 20.729s
[2K
| Adam | epoch: 025 | loss: 0.05444 - acc: 0.9861 -- iter: 1088/2015
[A[ATraining Step: 1547  | total loss: [1m[32m0.05054[0m[0m | time: 21.332s
[2K
| Adam | epoch: 025 | loss: 0.05054 - acc: 0.9875 -- iter: 1120/2015
[A[ATraining Step: 1548  | total loss: [1m[32m0.04715[0m[0m | time: 21.944s
[2K
| Adam | epoch: 025 | loss: 0.04715 - acc: 0.9887 -- iter: 1152/2015
[A[ATraining Step: 1549  | total loss: [1m[32m0.04773[0m[0m | time: 22.540s
[2K
| Adam | epoch: 025 | loss: 0.04773 - acc: 0.9867 -- iter: 1184/2015
[A[ATraining Step: 1550  | total loss: [1m[32m0.04384[0m[0m | time: 23.135s
[2K
| Adam | epoch: 025 | loss: 0.04384 - acc: 0.9881 -- iter: 1216/2015
[A[ATraining Step: 1551  | total loss: [1m[32m0.04148[0m[0m | time: 23.732s
[2K
| Adam | epoch: 025 | loss: 0.04148 - acc: 0.9893 -- iter: 1248/2015
[A[ATraining Step: 1552  | total loss: [1m[32m0.03925[0m[0m | time: 24.358s
[2K
| Adam | epoch: 025 | loss: 0.03925 - acc: 0.9903 -- iter: 1280/2015
[A[ATraining Step: 1553  | total loss: [1m[32m0.04214[0m[0m | time: 24.965s
[2K
| Adam | epoch: 025 | loss: 0.04214 - acc: 0.9913 -- iter: 1312/2015
[A[ATraining Step: 1554  | total loss: [1m[32m0.03976[0m[0m | time: 25.593s
[2K
| Adam | epoch: 025 | loss: 0.03976 - acc: 0.9922 -- iter: 1344/2015
[A[ATraining Step: 1555  | total loss: [1m[32m0.04527[0m[0m | time: 26.199s
[2K
| Adam | epoch: 025 | loss: 0.04527 - acc: 0.9867 -- iter: 1376/2015
[A[ATraining Step: 1556  | total loss: [1m[32m0.04335[0m[0m | time: 26.804s
[2K
| Adam | epoch: 025 | loss: 0.04335 - acc: 0.9880 -- iter: 1408/2015
[A[ATraining Step: 1557  | total loss: [1m[32m0.04043[0m[0m | time: 27.406s
[2K
| Adam | epoch: 025 | loss: 0.04043 - acc: 0.9892 -- iter: 1440/2015
[A[ATraining Step: 1558  | total loss: [1m[32m0.04076[0m[0m | time: 27.982s
[2K
| Adam | epoch: 025 | loss: 0.04076 - acc: 0.9872 -- iter: 1472/2015
[A[ATraining Step: 1559  | total loss: [1m[32m0.04087[0m[0m | time: 28.577s
[2K
| Adam | epoch: 025 | loss: 0.04087 - acc: 0.9885 -- iter: 1504/2015
[A[ATraining Step: 1560  | total loss: [1m[32m0.03780[0m[0m | time: 29.182s
[2K
| Adam | epoch: 025 | loss: 0.03780 - acc: 0.9896 -- iter: 1536/2015
[A[ATraining Step: 1561  | total loss: [1m[32m0.03518[0m[0m | time: 29.807s
[2K
| Adam | epoch: 025 | loss: 0.03518 - acc: 0.9907 -- iter: 1568/2015
[A[ATraining Step: 1562  | total loss: [1m[32m0.03394[0m[0m | time: 30.424s
[2K
| Adam | epoch: 025 | loss: 0.03394 - acc: 0.9916 -- iter: 1600/2015
[A[ATraining Step: 1563  | total loss: [1m[32m0.03492[0m[0m | time: 31.055s
[2K
| Adam | epoch: 025 | loss: 0.03492 - acc: 0.9924 -- iter: 1632/2015
[A[ATraining Step: 1564  | total loss: [1m[32m0.03581[0m[0m | time: 31.682s
[2K
| Adam | epoch: 025 | loss: 0.03581 - acc: 0.9901 -- iter: 1664/2015
[A[ATraining Step: 1565  | total loss: [1m[32m0.03487[0m[0m | time: 32.307s
[2K
| Adam | epoch: 025 | loss: 0.03487 - acc: 0.9911 -- iter: 1696/2015
[A[ATraining Step: 1566  | total loss: [1m[32m0.03342[0m[0m | time: 32.911s
[2K
| Adam | epoch: 025 | loss: 0.03342 - acc: 0.9920 -- iter: 1728/2015
[A[ATraining Step: 1567  | total loss: [1m[32m0.03383[0m[0m | time: 33.511s
[2K
| Adam | epoch: 025 | loss: 0.03383 - acc: 0.9928 -- iter: 1760/2015
[A[ATraining Step: 1568  | total loss: [1m[32m0.03399[0m[0m | time: 34.114s
[2K
| Adam | epoch: 025 | loss: 0.03399 - acc: 0.9935 -- iter: 1792/2015
[A[ATraining Step: 1569  | total loss: [1m[32m0.03181[0m[0m | time: 34.705s
[2K
| Adam | epoch: 025 | loss: 0.03181 - acc: 0.9941 -- iter: 1824/2015
[A[ATraining Step: 1570  | total loss: [1m[32m0.02991[0m[0m | time: 35.318s
[2K
| Adam | epoch: 025 | loss: 0.02991 - acc: 0.9947 -- iter: 1856/2015
[A[ATraining Step: 1571  | total loss: [1m[32m0.02926[0m[0m | time: 36.011s
[2K
| Adam | epoch: 025 | loss: 0.02926 - acc: 0.9952 -- iter: 1888/2015
[A[ATraining Step: 1572  | total loss: [1m[32m0.02701[0m[0m | time: 36.613s
[2K
| Adam | epoch: 025 | loss: 0.02701 - acc: 0.9957 -- iter: 1920/2015
[A[ATraining Step: 1573  | total loss: [1m[32m0.02615[0m[0m | time: 37.224s
[2K
| Adam | epoch: 025 | loss: 0.02615 - acc: 0.9961 -- iter: 1952/2015
[A[ATraining Step: 1574  | total loss: [1m[32m0.02473[0m[0m | time: 37.831s
[2K
| Adam | epoch: 025 | loss: 0.02473 - acc: 0.9965 -- iter: 1984/2015
[A[ATraining Step: 1575  | total loss: [1m[32m0.02383[0m[0m | time: 40.415s
[2K
| Adam | epoch: 025 | loss: 0.02383 - acc: 0.9969 | val_loss: 0.48636 - val_acc: 0.8698 -- iter: 2015/2015
--
Training Step: 1576  | total loss: [1m[32m0.02432[0m[0m | time: 0.590s
[2K
| Adam | epoch: 026 | loss: 0.02432 - acc: 0.9972 -- iter: 0032/2015
[A[ATraining Step: 1577  | total loss: [1m[32m0.02310[0m[0m | time: 1.186s
[2K
| Adam | epoch: 026 | loss: 0.02310 - acc: 0.9975 -- iter: 0064/2015
[A[ATraining Step: 1578  | total loss: [1m[32m0.02187[0m[0m | time: 1.784s
[2K
| Adam | epoch: 026 | loss: 0.02187 - acc: 0.9977 -- iter: 0096/2015
[A[ATraining Step: 1579  | total loss: [1m[32m0.02124[0m[0m | time: 2.420s
[2K
| Adam | epoch: 026 | loss: 0.02124 - acc: 0.9980 -- iter: 0128/2015
[A[ATraining Step: 1580  | total loss: [1m[32m0.02119[0m[0m | time: 3.030s
[2K
| Adam | epoch: 026 | loss: 0.02119 - acc: 0.9982 -- iter: 0160/2015
[A[ATraining Step: 1581  | total loss: [1m[32m0.02019[0m[0m | time: 3.636s
[2K
| Adam | epoch: 026 | loss: 0.02019 - acc: 0.9983 -- iter: 0192/2015
[A[ATraining Step: 1582  | total loss: [1m[32m0.02429[0m[0m | time: 4.247s
[2K
| Adam | epoch: 026 | loss: 0.02429 - acc: 0.9954 -- iter: 0224/2015
[A[ATraining Step: 1583  | total loss: [1m[32m0.02399[0m[0m | time: 4.874s
[2K
| Adam | epoch: 026 | loss: 0.02399 - acc: 0.9958 -- iter: 0256/2015
[A[ATraining Step: 1584  | total loss: [1m[32m0.02375[0m[0m | time: 5.482s
[2K
| Adam | epoch: 026 | loss: 0.02375 - acc: 0.9963 -- iter: 0288/2015
[A[ATraining Step: 1585  | total loss: [1m[32m0.02293[0m[0m | time: 6.085s
[2K
| Adam | epoch: 026 | loss: 0.02293 - acc: 0.9966 -- iter: 0320/2015
[A[ATraining Step: 1586  | total loss: [1m[32m0.02259[0m[0m | time: 6.697s
[2K
| Adam | epoch: 026 | loss: 0.02259 - acc: 0.9970 -- iter: 0352/2015
[A[ATraining Step: 1587  | total loss: [1m[32m0.02288[0m[0m | time: 7.297s
[2K
| Adam | epoch: 026 | loss: 0.02288 - acc: 0.9973 -- iter: 0384/2015
[A[ATraining Step: 1588  | total loss: [1m[32m0.02342[0m[0m | time: 7.900s
[2K
| Adam | epoch: 026 | loss: 0.02342 - acc: 0.9975 -- iter: 0416/2015
[A[ATraining Step: 1589  | total loss: [1m[32m0.02267[0m[0m | time: 8.532s
[2K
| Adam | epoch: 026 | loss: 0.02267 - acc: 0.9978 -- iter: 0448/2015
[A[ATraining Step: 1590  | total loss: [1m[32m0.02225[0m[0m | time: 9.128s
[2K
| Adam | epoch: 026 | loss: 0.02225 - acc: 0.9980 -- iter: 0480/2015
[A[ATraining Step: 1591  | total loss: [1m[32m0.02113[0m[0m | time: 9.718s
[2K
| Adam | epoch: 026 | loss: 0.02113 - acc: 0.9982 -- iter: 0512/2015
[A[ATraining Step: 1592  | total loss: [1m[32m0.02037[0m[0m | time: 10.312s
[2K
| Adam | epoch: 026 | loss: 0.02037 - acc: 0.9984 -- iter: 0544/2015
[A[ATraining Step: 1593  | total loss: [1m[32m0.01979[0m[0m | time: 10.921s
[2K
| Adam | epoch: 026 | loss: 0.01979 - acc: 0.9986 -- iter: 0576/2015
[A[ATraining Step: 1594  | total loss: [1m[32m0.01862[0m[0m | time: 11.538s
[2K
| Adam | epoch: 026 | loss: 0.01862 - acc: 0.9987 -- iter: 0608/2015
[A[ATraining Step: 1595  | total loss: [1m[32m0.01714[0m[0m | time: 12.160s
[2K
| Adam | epoch: 026 | loss: 0.01714 - acc: 0.9988 -- iter: 0640/2015
[A[ATraining Step: 1596  | total loss: [1m[32m0.01645[0m[0m | time: 12.765s
[2K
| Adam | epoch: 026 | loss: 0.01645 - acc: 0.9989 -- iter: 0672/2015
[A[ATraining Step: 1597  | total loss: [1m[32m0.01553[0m[0m | time: 13.365s
[2K
| Adam | epoch: 026 | loss: 0.01553 - acc: 0.9990 -- iter: 0704/2015
[A[ATraining Step: 1598  | total loss: [1m[32m0.01676[0m[0m | time: 13.966s
[2K
| Adam | epoch: 026 | loss: 0.01676 - acc: 0.9991 -- iter: 0736/2015
[A[ATraining Step: 1599  | total loss: [1m[32m0.01633[0m[0m | time: 14.542s
[2K
| Adam | epoch: 026 | loss: 0.01633 - acc: 0.9992 -- iter: 0768/2015
[A[ATraining Step: 1600  | total loss: [1m[32m0.01622[0m[0m | time: 17.114s
[2K
| Adam | epoch: 026 | loss: 0.01622 - acc: 0.9993 | val_loss: 0.51728 - val_acc: 0.8619 -- iter: 0800/2015
--
Training Step: 1601  | total loss: [1m[32m0.01594[0m[0m | time: 17.719s
[2K
| Adam | epoch: 026 | loss: 0.01594 - acc: 0.9994 -- iter: 0832/2015
[A[ATraining Step: 1602  | total loss: [1m[32m0.01734[0m[0m | time: 18.325s
[2K
| Adam | epoch: 026 | loss: 0.01734 - acc: 0.9994 -- iter: 0864/2015
[A[ATraining Step: 1603  | total loss: [1m[32m0.01791[0m[0m | time: 18.928s
[2K
| Adam | epoch: 026 | loss: 0.01791 - acc: 0.9995 -- iter: 0896/2015
[A[ATraining Step: 1604  | total loss: [1m[32m0.01789[0m[0m | time: 19.532s
[2K
| Adam | epoch: 026 | loss: 0.01789 - acc: 0.9995 -- iter: 0928/2015
[A[ATraining Step: 1605  | total loss: [1m[32m0.03253[0m[0m | time: 20.138s
[2K
| Adam | epoch: 026 | loss: 0.03253 - acc: 0.9965 -- iter: 0960/2015
[A[ATraining Step: 1606  | total loss: [1m[32m0.02944[0m[0m | time: 20.743s
[2K
| Adam | epoch: 026 | loss: 0.02944 - acc: 0.9968 -- iter: 0992/2015
[A[ATraining Step: 1607  | total loss: [1m[32m0.02707[0m[0m | time: 21.343s
[2K
| Adam | epoch: 026 | loss: 0.02707 - acc: 0.9971 -- iter: 1024/2015
[A[ATraining Step: 1608  | total loss: [1m[32m0.02637[0m[0m | time: 21.975s
[2K
| Adam | epoch: 026 | loss: 0.02637 - acc: 0.9974 -- iter: 1056/2015
[A[ATraining Step: 1609  | total loss: [1m[32m0.02597[0m[0m | time: 22.586s
[2K
| Adam | epoch: 026 | loss: 0.02597 - acc: 0.9977 -- iter: 1088/2015
[A[ATraining Step: 1610  | total loss: [1m[32m0.02466[0m[0m | time: 23.194s
[2K
| Adam | epoch: 026 | loss: 0.02466 - acc: 0.9979 -- iter: 1120/2015
[A[ATraining Step: 1611  | total loss: [1m[32m0.02396[0m[0m | time: 23.833s
[2K
| Adam | epoch: 026 | loss: 0.02396 - acc: 0.9981 -- iter: 1152/2015
[A[ATraining Step: 1612  | total loss: [1m[32m0.02186[0m[0m | time: 24.446s
[2K
| Adam | epoch: 026 | loss: 0.02186 - acc: 0.9983 -- iter: 1184/2015
[A[ATraining Step: 1613  | total loss: [1m[32m0.04304[0m[0m | time: 25.048s
[2K
| Adam | epoch: 026 | loss: 0.04304 - acc: 0.9954 -- iter: 1216/2015
[A[ATraining Step: 1614  | total loss: [1m[32m0.03925[0m[0m | time: 25.653s
[2K
| Adam | epoch: 026 | loss: 0.03925 - acc: 0.9958 -- iter: 1248/2015
[A[ATraining Step: 1615  | total loss: [1m[32m0.03670[0m[0m | time: 26.252s
[2K
| Adam | epoch: 026 | loss: 0.03670 - acc: 0.9962 -- iter: 1280/2015
[A[ATraining Step: 1616  | total loss: [1m[32m0.03388[0m[0m | time: 26.886s
[2K
| Adam | epoch: 026 | loss: 0.03388 - acc: 0.9966 -- iter: 1312/2015
[A[ATraining Step: 1617  | total loss: [1m[32m0.03565[0m[0m | time: 27.496s
[2K
| Adam | epoch: 026 | loss: 0.03565 - acc: 0.9938 -- iter: 1344/2015
[A[ATraining Step: 1618  | total loss: [1m[32m0.03550[0m[0m | time: 28.123s
[2K
| Adam | epoch: 026 | loss: 0.03550 - acc: 0.9944 -- iter: 1376/2015
[A[ATraining Step: 1619  | total loss: [1m[32m0.03251[0m[0m | time: 28.719s
[2K
| Adam | epoch: 026 | loss: 0.03251 - acc: 0.9950 -- iter: 1408/2015
[A[ATraining Step: 1620  | total loss: [1m[32m0.05040[0m[0m | time: 29.340s
[2K
| Adam | epoch: 026 | loss: 0.05040 - acc: 0.9924 -- iter: 1440/2015
[A[ATraining Step: 1621  | total loss: [1m[32m0.04787[0m[0m | time: 29.951s
[2K
| Adam | epoch: 026 | loss: 0.04787 - acc: 0.9931 -- iter: 1472/2015
[A[ATraining Step: 1622  | total loss: [1m[32m0.04400[0m[0m | time: 30.557s
[2K
| Adam | epoch: 026 | loss: 0.04400 - acc: 0.9938 -- iter: 1504/2015
[A[ATraining Step: 1623  | total loss: [1m[32m0.04208[0m[0m | time: 31.147s
[2K
| Adam | epoch: 026 | loss: 0.04208 - acc: 0.9944 -- iter: 1536/2015
[A[ATraining Step: 1624  | total loss: [1m[32m0.04431[0m[0m | time: 31.753s
[2K
| Adam | epoch: 026 | loss: 0.04431 - acc: 0.9919 -- iter: 1568/2015
[A[ATraining Step: 1625  | total loss: [1m[32m0.04644[0m[0m | time: 32.361s
[2K
| Adam | epoch: 026 | loss: 0.04644 - acc: 0.9896 -- iter: 1600/2015
[A[ATraining Step: 1626  | total loss: [1m[32m0.04742[0m[0m | time: 32.935s
[2K
| Adam | epoch: 026 | loss: 0.04742 - acc: 0.9875 -- iter: 1632/2015
[A[ATraining Step: 1627  | total loss: [1m[32m0.04422[0m[0m | time: 33.535s
[2K
| Adam | epoch: 026 | loss: 0.04422 - acc: 0.9887 -- iter: 1664/2015
[A[ATraining Step: 1628  | total loss: [1m[32m0.04303[0m[0m | time: 34.142s
[2K
| Adam | epoch: 026 | loss: 0.04303 - acc: 0.9899 -- iter: 1696/2015
[A[ATraining Step: 1629  | total loss: [1m[32m0.04757[0m[0m | time: 34.775s
[2K
| Adam | epoch: 026 | loss: 0.04757 - acc: 0.9877 -- iter: 1728/2015
[A[ATraining Step: 1630  | total loss: [1m[32m0.04471[0m[0m | time: 35.381s
[2K
| Adam | epoch: 026 | loss: 0.04471 - acc: 0.9890 -- iter: 1760/2015
[A[ATraining Step: 1631  | total loss: [1m[32m0.04493[0m[0m | time: 35.983s
[2K
| Adam | epoch: 026 | loss: 0.04493 - acc: 0.9901 -- iter: 1792/2015
[A[ATraining Step: 1632  | total loss: [1m[32m0.07315[0m[0m | time: 36.615s
[2K
| Adam | epoch: 026 | loss: 0.07315 - acc: 0.9817 -- iter: 1824/2015
[A[ATraining Step: 1633  | total loss: [1m[32m0.06856[0m[0m | time: 37.217s
[2K
| Adam | epoch: 026 | loss: 0.06856 - acc: 0.9835 -- iter: 1856/2015
[A[ATraining Step: 1634  | total loss: [1m[32m0.06568[0m[0m | time: 37.833s
[2K
| Adam | epoch: 026 | loss: 0.06568 - acc: 0.9852 -- iter: 1888/2015
[A[ATraining Step: 1635  | total loss: [1m[32m0.05963[0m[0m | time: 38.432s
[2K
| Adam | epoch: 026 | loss: 0.05963 - acc: 0.9867 -- iter: 1920/2015
[A[ATraining Step: 1636  | total loss: [1m[32m0.05395[0m[0m | time: 39.037s
[2K
| Adam | epoch: 026 | loss: 0.05395 - acc: 0.9880 -- iter: 1952/2015
[A[ATraining Step: 1637  | total loss: [1m[32m0.04925[0m[0m | time: 39.639s
[2K
| Adam | epoch: 026 | loss: 0.04925 - acc: 0.9892 -- iter: 1984/2015
[A[ATraining Step: 1638  | total loss: [1m[32m0.04652[0m[0m | time: 42.241s
[2K
| Adam | epoch: 026 | loss: 0.04652 - acc: 0.9903 | val_loss: 0.52218 - val_acc: 0.8571 -- iter: 2015/2015
--
Training Step: 1639  | total loss: [1m[32m0.04307[0m[0m | time: 0.617s
[2K
| Adam | epoch: 027 | loss: 0.04307 - acc: 0.9912 -- iter: 0032/2015
[A[ATraining Step: 1640  | total loss: [1m[32m0.03947[0m[0m | time: 1.221s
[2K
| Adam | epoch: 027 | loss: 0.03947 - acc: 0.9921 -- iter: 0064/2015
[A[ATraining Step: 1641  | total loss: [1m[32m0.03622[0m[0m | time: 1.825s
[2K
| Adam | epoch: 027 | loss: 0.03622 - acc: 0.9929 -- iter: 0096/2015
[A[ATraining Step: 1642  | total loss: [1m[32m0.05209[0m[0m | time: 2.420s
[2K
| Adam | epoch: 027 | loss: 0.05209 - acc: 0.9905 -- iter: 0128/2015
[A[ATraining Step: 1643  | total loss: [1m[32m0.04832[0m[0m | time: 3.026s
[2K
| Adam | epoch: 027 | loss: 0.04832 - acc: 0.9914 -- iter: 0160/2015
[A[ATraining Step: 1644  | total loss: [1m[32m0.04412[0m[0m | time: 3.619s
[2K
| Adam | epoch: 027 | loss: 0.04412 - acc: 0.9923 -- iter: 0192/2015
[A[ATraining Step: 1645  | total loss: [1m[32m0.04035[0m[0m | time: 4.221s
[2K
| Adam | epoch: 027 | loss: 0.04035 - acc: 0.9931 -- iter: 0224/2015
[A[ATraining Step: 1646  | total loss: [1m[32m0.03678[0m[0m | time: 4.812s
[2K
| Adam | epoch: 027 | loss: 0.03678 - acc: 0.9938 -- iter: 0256/2015
[A[ATraining Step: 1647  | total loss: [1m[32m0.03360[0m[0m | time: 5.425s
[2K
| Adam | epoch: 027 | loss: 0.03360 - acc: 0.9944 -- iter: 0288/2015
[A[ATraining Step: 1648  | total loss: [1m[32m0.03081[0m[0m | time: 6.028s
[2K
| Adam | epoch: 027 | loss: 0.03081 - acc: 0.9949 -- iter: 0320/2015
[A[ATraining Step: 1649  | total loss: [1m[32m0.02906[0m[0m | time: 6.658s
[2K
| Adam | epoch: 027 | loss: 0.02906 - acc: 0.9955 -- iter: 0352/2015
[A[ATraining Step: 1650  | total loss: [1m[32m0.02662[0m[0m | time: 7.258s
[2K
| Adam | epoch: 027 | loss: 0.02662 - acc: 0.9959 -- iter: 0384/2015
[A[ATraining Step: 1651  | total loss: [1m[32m0.02740[0m[0m | time: 7.864s
[2K
| Adam | epoch: 027 | loss: 0.02740 - acc: 0.9932 -- iter: 0416/2015
[A[ATraining Step: 1652  | total loss: [1m[32m0.02563[0m[0m | time: 8.462s
[2K
| Adam | epoch: 027 | loss: 0.02563 - acc: 0.9939 -- iter: 0448/2015
[A[ATraining Step: 1653  | total loss: [1m[32m0.02469[0m[0m | time: 9.070s
[2K
| Adam | epoch: 027 | loss: 0.02469 - acc: 0.9945 -- iter: 0480/2015
[A[ATraining Step: 1654  | total loss: [1m[32m0.02311[0m[0m | time: 9.680s
[2K
| Adam | epoch: 027 | loss: 0.02311 - acc: 0.9950 -- iter: 0512/2015
[A[ATraining Step: 1655  | total loss: [1m[32m0.02226[0m[0m | time: 10.302s
[2K
| Adam | epoch: 027 | loss: 0.02226 - acc: 0.9955 -- iter: 0544/2015
[A[ATraining Step: 1656  | total loss: [1m[32m0.02059[0m[0m | time: 10.923s
[2K
| Adam | epoch: 027 | loss: 0.02059 - acc: 0.9960 -- iter: 0576/2015
[A[ATraining Step: 1657  | total loss: [1m[32m0.01910[0m[0m | time: 11.523s
[2K
| Adam | epoch: 027 | loss: 0.01910 - acc: 0.9964 -- iter: 0608/2015
[A[ATraining Step: 1658  | total loss: [1m[32m0.01811[0m[0m | time: 12.131s
[2K
| Adam | epoch: 027 | loss: 0.01811 - acc: 0.9967 -- iter: 0640/2015
[A[ATraining Step: 1659  | total loss: [1m[32m0.01709[0m[0m | time: 12.731s
[2K
| Adam | epoch: 027 | loss: 0.01709 - acc: 0.9971 -- iter: 0672/2015
[A[ATraining Step: 1660  | total loss: [1m[32m0.01680[0m[0m | time: 13.334s
[2K
| Adam | epoch: 027 | loss: 0.01680 - acc: 0.9974 -- iter: 0704/2015
[A[ATraining Step: 1661  | total loss: [1m[32m0.01616[0m[0m | time: 13.937s
[2K
| Adam | epoch: 027 | loss: 0.01616 - acc: 0.9976 -- iter: 0736/2015
[A[ATraining Step: 1662  | total loss: [1m[32m0.01725[0m[0m | time: 14.562s
[2K
| Adam | epoch: 027 | loss: 0.01725 - acc: 0.9979 -- iter: 0768/2015
[A[ATraining Step: 1663  | total loss: [1m[32m0.01675[0m[0m | time: 15.150s
[2K
| Adam | epoch: 027 | loss: 0.01675 - acc: 0.9981 -- iter: 0800/2015
[A[ATraining Step: 1664  | total loss: [1m[32m0.01685[0m[0m | time: 15.742s
[2K
| Adam | epoch: 027 | loss: 0.01685 - acc: 0.9983 -- iter: 0832/2015
[A[ATraining Step: 1665  | total loss: [1m[32m0.01692[0m[0m | time: 16.357s
[2K
| Adam | epoch: 027 | loss: 0.01692 - acc: 0.9984 -- iter: 0864/2015
[A[ATraining Step: 1666  | total loss: [1m[32m0.01803[0m[0m | time: 16.948s
[2K
| Adam | epoch: 027 | loss: 0.01803 - acc: 0.9955 -- iter: 0896/2015
[A[ATraining Step: 1667  | total loss: [1m[32m0.01686[0m[0m | time: 17.564s
[2K
| Adam | epoch: 027 | loss: 0.01686 - acc: 0.9959 -- iter: 0928/2015
[A[ATraining Step: 1668  | total loss: [1m[32m0.01611[0m[0m | time: 18.178s
[2K
| Adam | epoch: 027 | loss: 0.01611 - acc: 0.9963 -- iter: 0960/2015
[A[ATraining Step: 1669  | total loss: [1m[32m0.01555[0m[0m | time: 18.787s
[2K
| Adam | epoch: 027 | loss: 0.01555 - acc: 0.9967 -- iter: 0992/2015
[A[ATraining Step: 1670  | total loss: [1m[32m0.01479[0m[0m | time: 19.386s
[2K
| Adam | epoch: 027 | loss: 0.01479 - acc: 0.9970 -- iter: 1024/2015
[A[ATraining Step: 1671  | total loss: [1m[32m0.01509[0m[0m | time: 19.978s
[2K
| Adam | epoch: 027 | loss: 0.01509 - acc: 0.9973 -- iter: 1056/2015
[A[ATraining Step: 1672  | total loss: [1m[32m0.01522[0m[0m | time: 20.568s
[2K
| Adam | epoch: 027 | loss: 0.01522 - acc: 0.9976 -- iter: 1088/2015
[A[ATraining Step: 1673  | total loss: [1m[32m0.03119[0m[0m | time: 21.175s
[2K
| Adam | epoch: 027 | loss: 0.03119 - acc: 0.9947 -- iter: 1120/2015
[A[ATraining Step: 1674  | total loss: [1m[32m0.02930[0m[0m | time: 21.792s
[2K
| Adam | epoch: 027 | loss: 0.02930 - acc: 0.9952 -- iter: 1152/2015
[A[ATraining Step: 1675  | total loss: [1m[32m0.02728[0m[0m | time: 22.390s
[2K
| Adam | epoch: 027 | loss: 0.02728 - acc: 0.9957 -- iter: 1184/2015
[A[ATraining Step: 1676  | total loss: [1m[32m0.03778[0m[0m | time: 23.008s
[2K
| Adam | epoch: 027 | loss: 0.03778 - acc: 0.9930 -- iter: 1216/2015
[A[ATraining Step: 1677  | total loss: [1m[32m0.03492[0m[0m | time: 23.615s
[2K
| Adam | epoch: 027 | loss: 0.03492 - acc: 0.9937 -- iter: 1248/2015
[A[ATraining Step: 1678  | total loss: [1m[32m0.03218[0m[0m | time: 24.208s
[2K
| Adam | epoch: 027 | loss: 0.03218 - acc: 0.9943 -- iter: 1280/2015
[A[ATraining Step: 1679  | total loss: [1m[32m0.02952[0m[0m | time: 24.801s
[2K
| Adam | epoch: 027 | loss: 0.02952 - acc: 0.9949 -- iter: 1312/2015
[A[ATraining Step: 1680  | total loss: [1m[32m0.02693[0m[0m | time: 25.412s
[2K
| Adam | epoch: 027 | loss: 0.02693 - acc: 0.9954 -- iter: 1344/2015
[A[ATraining Step: 1681  | total loss: [1m[32m0.02564[0m[0m | time: 26.017s
[2K
| Adam | epoch: 027 | loss: 0.02564 - acc: 0.9959 -- iter: 1376/2015
[A[ATraining Step: 1682  | total loss: [1m[32m0.02393[0m[0m | time: 26.612s
[2K
| Adam | epoch: 027 | loss: 0.02393 - acc: 0.9963 -- iter: 1408/2015
[A[ATraining Step: 1683  | total loss: [1m[32m0.02580[0m[0m | time: 27.212s
[2K
| Adam | epoch: 027 | loss: 0.02580 - acc: 0.9935 -- iter: 1440/2015
[A[ATraining Step: 1684  | total loss: [1m[32m0.03952[0m[0m | time: 27.808s
[2K
| Adam | epoch: 027 | loss: 0.03952 - acc: 0.9911 -- iter: 1472/2015
[A[ATraining Step: 1685  | total loss: [1m[32m0.03600[0m[0m | time: 28.419s
[2K
| Adam | epoch: 027 | loss: 0.03600 - acc: 0.9920 -- iter: 1504/2015
[A[ATraining Step: 1686  | total loss: [1m[32m0.03358[0m[0m | time: 29.011s
[2K
| Adam | epoch: 027 | loss: 0.03358 - acc: 0.9928 -- iter: 1536/2015
[A[ATraining Step: 1687  | total loss: [1m[32m0.03232[0m[0m | time: 29.612s
[2K
| Adam | epoch: 027 | loss: 0.03232 - acc: 0.9935 -- iter: 1568/2015
[A[ATraining Step: 1688  | total loss: [1m[32m0.02988[0m[0m | time: 30.211s
[2K
| Adam | epoch: 027 | loss: 0.02988 - acc: 0.9941 -- iter: 1600/2015
[A[ATraining Step: 1689  | total loss: [1m[32m0.02885[0m[0m | time: 30.807s
[2K
| Adam | epoch: 027 | loss: 0.02885 - acc: 0.9947 -- iter: 1632/2015
[A[ATraining Step: 1690  | total loss: [1m[32m0.02691[0m[0m | time: 31.423s
[2K
| Adam | epoch: 027 | loss: 0.02691 - acc: 0.9952 -- iter: 1664/2015
[A[ATraining Step: 1691  | total loss: [1m[32m0.02814[0m[0m | time: 32.022s
[2K
| Adam | epoch: 027 | loss: 0.02814 - acc: 0.9926 -- iter: 1696/2015
[A[ATraining Step: 1692  | total loss: [1m[32m0.02745[0m[0m | time: 32.619s
[2K
| Adam | epoch: 027 | loss: 0.02745 - acc: 0.9933 -- iter: 1728/2015
[A[ATraining Step: 1693  | total loss: [1m[32m0.04571[0m[0m | time: 33.221s
[2K
| Adam | epoch: 027 | loss: 0.04571 - acc: 0.9878 -- iter: 1760/2015
[A[ATraining Step: 1694  | total loss: [1m[32m0.05210[0m[0m | time: 33.815s
[2K
| Adam | epoch: 027 | loss: 0.05210 - acc: 0.9796 -- iter: 1792/2015
[A[ATraining Step: 1695  | total loss: [1m[32m0.04832[0m[0m | time: 34.410s
[2K
| Adam | epoch: 027 | loss: 0.04832 - acc: 0.9816 -- iter: 1824/2015
[A[ATraining Step: 1696  | total loss: [1m[32m0.04415[0m[0m | time: 35.013s
[2K
| Adam | epoch: 027 | loss: 0.04415 - acc: 0.9835 -- iter: 1856/2015
[A[ATraining Step: 1697  | total loss: [1m[32m0.04150[0m[0m | time: 35.657s
[2K
| Adam | epoch: 027 | loss: 0.04150 - acc: 0.9851 -- iter: 1888/2015
[A[ATraining Step: 1698  | total loss: [1m[32m0.03889[0m[0m | time: 36.259s
[2K
| Adam | epoch: 027 | loss: 0.03889 - acc: 0.9866 -- iter: 1920/2015
[A[ATraining Step: 1699  | total loss: [1m[32m0.03653[0m[0m | time: 36.865s
[2K
| Adam | epoch: 027 | loss: 0.03653 - acc: 0.9880 -- iter: 1952/2015
[A[ATraining Step: 1700  | total loss: [1m[32m0.03368[0m[0m | time: 37.501s
[2K
| Adam | epoch: 027 | loss: 0.03368 - acc: 0.9892 -- iter: 1984/2015
[A[ATraining Step: 1701  | total loss: [1m[32m0.03062[0m[0m | time: 40.100s
[2K
| Adam | epoch: 027 | loss: 0.03062 - acc: 0.9902 | val_loss: 0.56040 - val_acc: 0.8556 -- iter: 2015/2015
--
Training Step: 1702  | total loss: [1m[32m0.02808[0m[0m | time: 0.619s
[2K
| Adam | epoch: 028 | loss: 0.02808 - acc: 0.9912 -- iter: 0032/2015
[A[ATraining Step: 1703  | total loss: [1m[32m0.02646[0m[0m | time: 1.245s
[2K
| Adam | epoch: 028 | loss: 0.02646 - acc: 0.9921 -- iter: 0064/2015
[A[ATraining Step: 1704  | total loss: [1m[32m0.02427[0m[0m | time: 1.874s
[2K
| Adam | epoch: 028 | loss: 0.02427 - acc: 0.9929 -- iter: 0096/2015
[A[ATraining Step: 1705  | total loss: [1m[32m0.02246[0m[0m | time: 2.474s
[2K
| Adam | epoch: 028 | loss: 0.02246 - acc: 0.9936 -- iter: 0128/2015
[A[ATraining Step: 1706  | total loss: [1m[32m0.02070[0m[0m | time: 3.081s
[2K
| Adam | epoch: 028 | loss: 0.02070 - acc: 0.9942 -- iter: 0160/2015
[A[ATraining Step: 1707  | total loss: [1m[32m0.01895[0m[0m | time: 3.672s
[2K
| Adam | epoch: 028 | loss: 0.01895 - acc: 0.9948 -- iter: 0192/2015
[A[ATraining Step: 1708  | total loss: [1m[32m0.01756[0m[0m | time: 4.277s
[2K
| Adam | epoch: 028 | loss: 0.01756 - acc: 0.9953 -- iter: 0224/2015
[A[ATraining Step: 1709  | total loss: [1m[32m0.01977[0m[0m | time: 4.880s
[2K
| Adam | epoch: 028 | loss: 0.01977 - acc: 0.9927 -- iter: 0256/2015
[A[ATraining Step: 1710  | total loss: [1m[32m0.01832[0m[0m | time: 5.486s
[2K
| Adam | epoch: 028 | loss: 0.01832 - acc: 0.9934 -- iter: 0288/2015
[A[ATraining Step: 1711  | total loss: [1m[32m0.02675[0m[0m | time: 6.097s
[2K
| Adam | epoch: 028 | loss: 0.02675 - acc: 0.9909 -- iter: 0320/2015
[A[ATraining Step: 1712  | total loss: [1m[32m0.02441[0m[0m | time: 6.699s
[2K
| Adam | epoch: 028 | loss: 0.02441 - acc: 0.9918 -- iter: 0352/2015
[A[ATraining Step: 1713  | total loss: [1m[32m0.03974[0m[0m | time: 7.298s
[2K
| Adam | epoch: 028 | loss: 0.03974 - acc: 0.9895 -- iter: 0384/2015
[A[ATraining Step: 1714  | total loss: [1m[32m0.03622[0m[0m | time: 7.900s
[2K
| Adam | epoch: 028 | loss: 0.03622 - acc: 0.9906 -- iter: 0416/2015
[A[ATraining Step: 1715  | total loss: [1m[32m0.03433[0m[0m | time: 8.491s
[2K
| Adam | epoch: 028 | loss: 0.03433 - acc: 0.9915 -- iter: 0448/2015
[A[ATraining Step: 1716  | total loss: [1m[32m0.03168[0m[0m | time: 9.127s
[2K
| Adam | epoch: 028 | loss: 0.03168 - acc: 0.9924 -- iter: 0480/2015
[A[ATraining Step: 1717  | total loss: [1m[32m0.02905[0m[0m | time: 9.728s
[2K
| Adam | epoch: 028 | loss: 0.02905 - acc: 0.9931 -- iter: 0512/2015
[A[ATraining Step: 1718  | total loss: [1m[32m0.02713[0m[0m | time: 10.333s
[2K
| Adam | epoch: 028 | loss: 0.02713 - acc: 0.9938 -- iter: 0544/2015
[A[ATraining Step: 1719  | total loss: [1m[32m0.02516[0m[0m | time: 10.940s
[2K
| Adam | epoch: 028 | loss: 0.02516 - acc: 0.9944 -- iter: 0576/2015
[A[ATraining Step: 1720  | total loss: [1m[32m0.02327[0m[0m | time: 11.537s
[2K
| Adam | epoch: 028 | loss: 0.02327 - acc: 0.9950 -- iter: 0608/2015
[A[ATraining Step: 1721  | total loss: [1m[32m0.02173[0m[0m | time: 12.163s
[2K
| Adam | epoch: 028 | loss: 0.02173 - acc: 0.9955 -- iter: 0640/2015
[A[ATraining Step: 1722  | total loss: [1m[32m0.02108[0m[0m | time: 12.776s
[2K
| Adam | epoch: 028 | loss: 0.02108 - acc: 0.9959 -- iter: 0672/2015
[A[ATraining Step: 1723  | total loss: [1m[32m0.01931[0m[0m | time: 13.383s
[2K
| Adam | epoch: 028 | loss: 0.01931 - acc: 0.9964 -- iter: 0704/2015
[A[ATraining Step: 1724  | total loss: [1m[32m0.01980[0m[0m | time: 13.984s
[2K
| Adam | epoch: 028 | loss: 0.01980 - acc: 0.9967 -- iter: 0736/2015
[A[ATraining Step: 1725  | total loss: [1m[32m0.01922[0m[0m | time: 14.590s
[2K
| Adam | epoch: 028 | loss: 0.01922 - acc: 0.9970 -- iter: 0768/2015
[A[ATraining Step: 1726  | total loss: [1m[32m0.03723[0m[0m | time: 15.201s
[2K
| Adam | epoch: 028 | loss: 0.03723 - acc: 0.9942 -- iter: 0800/2015
[A[ATraining Step: 1727  | total loss: [1m[32m0.03489[0m[0m | time: 15.797s
[2K
| Adam | epoch: 028 | loss: 0.03489 - acc: 0.9948 -- iter: 0832/2015
[A[ATraining Step: 1728  | total loss: [1m[32m0.03195[0m[0m | time: 16.377s
[2K
| Adam | epoch: 028 | loss: 0.03195 - acc: 0.9953 -- iter: 0864/2015
[A[ATraining Step: 1729  | total loss: [1m[32m0.02984[0m[0m | time: 17.025s
[2K
| Adam | epoch: 028 | loss: 0.02984 - acc: 0.9958 -- iter: 0896/2015
[A[ATraining Step: 1730  | total loss: [1m[32m0.02937[0m[0m | time: 17.634s
[2K
| Adam | epoch: 028 | loss: 0.02937 - acc: 0.9962 -- iter: 0928/2015
[A[ATraining Step: 1731  | total loss: [1m[32m0.02695[0m[0m | time: 18.230s
[2K
| Adam | epoch: 028 | loss: 0.02695 - acc: 0.9966 -- iter: 0960/2015
[A[ATraining Step: 1732  | total loss: [1m[32m0.02580[0m[0m | time: 18.866s
[2K
| Adam | epoch: 028 | loss: 0.02580 - acc: 0.9969 -- iter: 0992/2015
[A[ATraining Step: 1733  | total loss: [1m[32m0.02463[0m[0m | time: 19.472s
[2K
| Adam | epoch: 028 | loss: 0.02463 - acc: 0.9972 -- iter: 1024/2015
[A[ATraining Step: 1734  | total loss: [1m[32m0.02335[0m[0m | time: 20.090s
[2K
| Adam | epoch: 028 | loss: 0.02335 - acc: 0.9975 -- iter: 1056/2015
[A[ATraining Step: 1735  | total loss: [1m[32m0.02696[0m[0m | time: 20.704s
[2K
| Adam | epoch: 028 | loss: 0.02696 - acc: 0.9946 -- iter: 1088/2015
[A[ATraining Step: 1736  | total loss: [1m[32m0.02684[0m[0m | time: 21.313s
[2K
| Adam | epoch: 028 | loss: 0.02684 - acc: 0.9952 -- iter: 1120/2015
[A[ATraining Step: 1737  | total loss: [1m[32m0.02468[0m[0m | time: 21.921s
[2K
| Adam | epoch: 028 | loss: 0.02468 - acc: 0.9957 -- iter: 1152/2015
[A[ATraining Step: 1738  | total loss: [1m[32m0.02350[0m[0m | time: 22.533s
[2K
| Adam | epoch: 028 | loss: 0.02350 - acc: 0.9961 -- iter: 1184/2015
[A[ATraining Step: 1739  | total loss: [1m[32m0.02148[0m[0m | time: 23.132s
[2K
| Adam | epoch: 028 | loss: 0.02148 - acc: 0.9965 -- iter: 1216/2015
[A[ATraining Step: 1740  | total loss: [1m[32m0.02289[0m[0m | time: 23.739s
[2K
| Adam | epoch: 028 | loss: 0.02289 - acc: 0.9968 -- iter: 1248/2015
[A[ATraining Step: 1741  | total loss: [1m[32m0.02357[0m[0m | time: 24.333s
[2K
| Adam | epoch: 028 | loss: 0.02357 - acc: 0.9940 -- iter: 1280/2015
[A[ATraining Step: 1742  | total loss: [1m[32m0.02151[0m[0m | time: 24.955s
[2K
| Adam | epoch: 028 | loss: 0.02151 - acc: 0.9946 -- iter: 1312/2015
[A[ATraining Step: 1743  | total loss: [1m[32m0.04016[0m[0m | time: 25.565s
[2K
| Adam | epoch: 028 | loss: 0.04016 - acc: 0.9920 -- iter: 1344/2015
[A[ATraining Step: 1744  | total loss: [1m[32m0.03760[0m[0m | time: 26.167s
[2K
| Adam | epoch: 028 | loss: 0.03760 - acc: 0.9928 -- iter: 1376/2015
[A[ATraining Step: 1745  | total loss: [1m[32m0.03481[0m[0m | time: 26.768s
[2K
| Adam | epoch: 028 | loss: 0.03481 - acc: 0.9935 -- iter: 1408/2015
[A[ATraining Step: 1746  | total loss: [1m[32m0.03186[0m[0m | time: 27.358s
[2K
| Adam | epoch: 028 | loss: 0.03186 - acc: 0.9942 -- iter: 1440/2015
[A[ATraining Step: 1747  | total loss: [1m[32m0.03091[0m[0m | time: 27.953s
[2K
| Adam | epoch: 028 | loss: 0.03091 - acc: 0.9948 -- iter: 1472/2015
[A[ATraining Step: 1748  | total loss: [1m[32m0.02868[0m[0m | time: 28.564s
[2K
| Adam | epoch: 028 | loss: 0.02868 - acc: 0.9953 -- iter: 1504/2015
[A[ATraining Step: 1749  | total loss: [1m[32m0.02706[0m[0m | time: 29.149s
[2K
| Adam | epoch: 028 | loss: 0.02706 - acc: 0.9958 -- iter: 1536/2015
[A[ATraining Step: 1750  | total loss: [1m[32m0.02514[0m[0m | time: 29.750s
[2K
| Adam | epoch: 028 | loss: 0.02514 - acc: 0.9962 -- iter: 1568/2015
[A[ATraining Step: 1751  | total loss: [1m[32m0.02296[0m[0m | time: 30.355s
[2K
| Adam | epoch: 028 | loss: 0.02296 - acc: 0.9966 -- iter: 1600/2015
[A[ATraining Step: 1752  | total loss: [1m[32m0.02117[0m[0m | time: 30.956s
[2K
| Adam | epoch: 028 | loss: 0.02117 - acc: 0.9969 -- iter: 1632/2015
[A[ATraining Step: 1753  | total loss: [1m[32m0.01996[0m[0m | time: 31.565s
[2K
| Adam | epoch: 028 | loss: 0.01996 - acc: 0.9972 -- iter: 1664/2015
[A[ATraining Step: 1754  | total loss: [1m[32m0.01906[0m[0m | time: 32.221s
[2K
| Adam | epoch: 028 | loss: 0.01906 - acc: 0.9975 -- iter: 1696/2015
[A[ATraining Step: 1755  | total loss: [1m[32m0.01847[0m[0m | time: 32.824s
[2K
| Adam | epoch: 028 | loss: 0.01847 - acc: 0.9978 -- iter: 1728/2015
[A[ATraining Step: 1756  | total loss: [1m[32m0.02481[0m[0m | time: 33.435s
[2K
| Adam | epoch: 028 | loss: 0.02481 - acc: 0.9949 -- iter: 1760/2015
[A[ATraining Step: 1757  | total loss: [1m[32m0.02326[0m[0m | time: 34.046s
[2K
| Adam | epoch: 028 | loss: 0.02326 - acc: 0.9954 -- iter: 1792/2015
[A[ATraining Step: 1758  | total loss: [1m[32m0.02149[0m[0m | time: 34.642s
[2K
| Adam | epoch: 028 | loss: 0.02149 - acc: 0.9958 -- iter: 1824/2015
[A[ATraining Step: 1759  | total loss: [1m[32m0.01971[0m[0m | time: 35.238s
[2K
| Adam | epoch: 028 | loss: 0.01971 - acc: 0.9962 -- iter: 1856/2015
[A[ATraining Step: 1760  | total loss: [1m[32m0.03739[0m[0m | time: 35.851s
[2K
| Adam | epoch: 028 | loss: 0.03739 - acc: 0.9935 -- iter: 1888/2015
[A[ATraining Step: 1761  | total loss: [1m[32m0.03424[0m[0m | time: 36.484s
[2K
| Adam | epoch: 028 | loss: 0.03424 - acc: 0.9941 -- iter: 1920/2015
[A[ATraining Step: 1762  | total loss: [1m[32m0.03803[0m[0m | time: 37.082s
[2K
| Adam | epoch: 028 | loss: 0.03803 - acc: 0.9885 -- iter: 1952/2015
[A[ATraining Step: 1763  | total loss: [1m[32m0.03504[0m[0m | time: 37.696s
[2K
| Adam | epoch: 028 | loss: 0.03504 - acc: 0.9896 -- iter: 1984/2015
[A[ATraining Step: 1764  | total loss: [1m[32m0.03615[0m[0m | time: 40.279s
[2K
| Adam | epoch: 028 | loss: 0.03615 - acc: 0.9875 | val_loss: 0.58504 - val_acc: 0.8603 -- iter: 2015/2015
--
Training Step: 1765  | total loss: [1m[32m0.03294[0m[0m | time: 0.621s
[2K
| Adam | epoch: 029 | loss: 0.03294 - acc: 0.9888 -- iter: 0032/2015
[A[ATraining Step: 1766  | total loss: [1m[32m0.03030[0m[0m | time: 1.220s
[2K
| Adam | epoch: 029 | loss: 0.03030 - acc: 0.9899 -- iter: 0064/2015
[A[ATraining Step: 1767  | total loss: [1m[32m0.02765[0m[0m | time: 1.820s
[2K
| Adam | epoch: 029 | loss: 0.02765 - acc: 0.9909 -- iter: 0096/2015
[A[ATraining Step: 1768  | total loss: [1m[32m0.02559[0m[0m | time: 2.424s
[2K
| Adam | epoch: 029 | loss: 0.02559 - acc: 0.9918 -- iter: 0128/2015
[A[ATraining Step: 1769  | total loss: [1m[32m0.02775[0m[0m | time: 3.029s
[2K
| Adam | epoch: 029 | loss: 0.02775 - acc: 0.9895 -- iter: 0160/2015
[A[ATraining Step: 1770  | total loss: [1m[32m0.03221[0m[0m | time: 3.627s
[2K
| Adam | epoch: 029 | loss: 0.03221 - acc: 0.9843 -- iter: 0192/2015
[A[ATraining Step: 1771  | total loss: [1m[32m0.02962[0m[0m | time: 4.226s
[2K
| Adam | epoch: 029 | loss: 0.02962 - acc: 0.9859 -- iter: 0224/2015
[A[ATraining Step: 1772  | total loss: [1m[32m0.02692[0m[0m | time: 4.842s
[2K
| Adam | epoch: 029 | loss: 0.02692 - acc: 0.9873 -- iter: 0256/2015
[A[ATraining Step: 1773  | total loss: [1m[32m0.04680[0m[0m | time: 5.436s
[2K
| Adam | epoch: 029 | loss: 0.04680 - acc: 0.9854 -- iter: 0288/2015
[A[ATraining Step: 1774  | total loss: [1m[32m0.04345[0m[0m | time: 6.055s
[2K
| Adam | epoch: 029 | loss: 0.04345 - acc: 0.9869 -- iter: 0320/2015
[A[ATraining Step: 1775  | total loss: [1m[32m0.04260[0m[0m | time: 6.671s
[2K
| Adam | epoch: 029 | loss: 0.04260 - acc: 0.9882 -- iter: 0352/2015
[A[ATraining Step: 1776  | total loss: [1m[32m0.03978[0m[0m | time: 7.287s
[2K
| Adam | epoch: 029 | loss: 0.03978 - acc: 0.9894 -- iter: 0384/2015
[A[ATraining Step: 1777  | total loss: [1m[32m0.03612[0m[0m | time: 7.893s
[2K
| Adam | epoch: 029 | loss: 0.03612 - acc: 0.9904 -- iter: 0416/2015
[A[ATraining Step: 1778  | total loss: [1m[32m0.04877[0m[0m | time: 8.506s
[2K
| Adam | epoch: 029 | loss: 0.04877 - acc: 0.9883 -- iter: 0448/2015
[A[ATraining Step: 1779  | total loss: [1m[32m0.06093[0m[0m | time: 9.116s
[2K
| Adam | epoch: 029 | loss: 0.06093 - acc: 0.9801 -- iter: 0480/2015
[A[ATraining Step: 1780  | total loss: [1m[32m0.08021[0m[0m | time: 9.751s
[2K
| Adam | epoch: 029 | loss: 0.08021 - acc: 0.9758 -- iter: 0512/2015
[A[ATraining Step: 1781  | total loss: [1m[32m0.08852[0m[0m | time: 10.365s
[2K
| Adam | epoch: 029 | loss: 0.08852 - acc: 0.9689 -- iter: 0544/2015
[A[ATraining Step: 1782  | total loss: [1m[32m0.08050[0m[0m | time: 10.974s
[2K
| Adam | epoch: 029 | loss: 0.08050 - acc: 0.9720 -- iter: 0576/2015
[A[ATraining Step: 1783  | total loss: [1m[32m0.08202[0m[0m | time: 11.581s
[2K
| Adam | epoch: 029 | loss: 0.08202 - acc: 0.9717 -- iter: 0608/2015
[A[ATraining Step: 1784  | total loss: [1m[32m0.08548[0m[0m | time: 12.182s
[2K
| Adam | epoch: 029 | loss: 0.08548 - acc: 0.9682 -- iter: 0640/2015
[A[ATraining Step: 1785  | total loss: [1m[32m0.11639[0m[0m | time: 12.808s
[2K
| Adam | epoch: 029 | loss: 0.11639 - acc: 0.9527 -- iter: 0672/2015
[A[ATraining Step: 1786  | total loss: [1m[32m0.12943[0m[0m | time: 13.408s
[2K
| Adam | epoch: 029 | loss: 0.12943 - acc: 0.9480 -- iter: 0704/2015
[A[ATraining Step: 1787  | total loss: [1m[32m0.16263[0m[0m | time: 14.017s
[2K
| Adam | epoch: 029 | loss: 0.16263 - acc: 0.9313 -- iter: 0736/2015
[A[ATraining Step: 1788  | total loss: [1m[32m0.15161[0m[0m | time: 14.643s
[2K
| Adam | epoch: 029 | loss: 0.15161 - acc: 0.9382 -- iter: 0768/2015
[A[ATraining Step: 1789  | total loss: [1m[32m0.13669[0m[0m | time: 15.282s
[2K
| Adam | epoch: 029 | loss: 0.13669 - acc: 0.9444 -- iter: 0800/2015
[A[ATraining Step: 1790  | total loss: [1m[32m0.12373[0m[0m | time: 15.892s
[2K
| Adam | epoch: 029 | loss: 0.12373 - acc: 0.9500 -- iter: 0832/2015
[A[ATraining Step: 1791  | total loss: [1m[32m0.11919[0m[0m | time: 16.480s
[2K
| Adam | epoch: 029 | loss: 0.11919 - acc: 0.9518 -- iter: 0864/2015
[A[ATraining Step: 1792  | total loss: [1m[32m0.11053[0m[0m | time: 17.056s
[2K
| Adam | epoch: 029 | loss: 0.11053 - acc: 0.9566 -- iter: 0896/2015
[A[ATraining Step: 1793  | total loss: [1m[32m0.10115[0m[0m | time: 17.670s
[2K
| Adam | epoch: 029 | loss: 0.10115 - acc: 0.9610 -- iter: 0928/2015
[A[ATraining Step: 1794  | total loss: [1m[32m0.09172[0m[0m | time: 18.270s
[2K
| Adam | epoch: 029 | loss: 0.09172 - acc: 0.9649 -- iter: 0960/2015
[A[ATraining Step: 1795  | total loss: [1m[32m0.08377[0m[0m | time: 18.888s
[2K
| Adam | epoch: 029 | loss: 0.08377 - acc: 0.9684 -- iter: 0992/2015
[A[ATraining Step: 1796  | total loss: [1m[32m0.07709[0m[0m | time: 19.492s
[2K
| Adam | epoch: 029 | loss: 0.07709 - acc: 0.9716 -- iter: 1024/2015
[A[ATraining Step: 1797  | total loss: [1m[32m0.07764[0m[0m | time: 20.097s
[2K
| Adam | epoch: 029 | loss: 0.07764 - acc: 0.9682 -- iter: 1056/2015
[A[ATraining Step: 1798  | total loss: [1m[32m0.07886[0m[0m | time: 20.691s
[2K
| Adam | epoch: 029 | loss: 0.07886 - acc: 0.9682 -- iter: 1088/2015
[A[ATraining Step: 1799  | total loss: [1m[32m0.07566[0m[0m | time: 21.324s
[2K
| Adam | epoch: 029 | loss: 0.07566 - acc: 0.9714 -- iter: 1120/2015
[A[ATraining Step: 1800  | total loss: [1m[32m0.06889[0m[0m | time: 23.910s
[2K
| Adam | epoch: 029 | loss: 0.06889 - acc: 0.9743 | val_loss: 0.73951 - val_acc: 0.8206 -- iter: 1152/2015
--
Training Step: 1801  | total loss: [1m[32m0.06371[0m[0m | time: 24.516s
[2K
| Adam | epoch: 029 | loss: 0.06371 - acc: 0.9768 -- iter: 1184/2015
[A[ATraining Step: 1802  | total loss: [1m[32m0.06893[0m[0m | time: 25.133s
[2K
| Adam | epoch: 029 | loss: 0.06893 - acc: 0.9729 -- iter: 1216/2015
[A[ATraining Step: 1803  | total loss: [1m[32m0.06715[0m[0m | time: 25.768s
[2K
| Adam | epoch: 029 | loss: 0.06715 - acc: 0.9756 -- iter: 1248/2015
[A[ATraining Step: 1804  | total loss: [1m[32m0.06275[0m[0m | time: 26.375s
[2K
| Adam | epoch: 029 | loss: 0.06275 - acc: 0.9780 -- iter: 1280/2015
[A[ATraining Step: 1805  | total loss: [1m[32m0.05884[0m[0m | time: 26.970s
[2K
| Adam | epoch: 029 | loss: 0.05884 - acc: 0.9802 -- iter: 1312/2015
[A[ATraining Step: 1806  | total loss: [1m[32m0.05420[0m[0m | time: 27.566s
[2K
| Adam | epoch: 029 | loss: 0.05420 - acc: 0.9822 -- iter: 1344/2015
[A[ATraining Step: 1807  | total loss: [1m[32m0.05043[0m[0m | time: 28.187s
[2K
| Adam | epoch: 029 | loss: 0.05043 - acc: 0.9840 -- iter: 1376/2015
[A[ATraining Step: 1808  | total loss: [1m[32m0.04894[0m[0m | time: 28.809s
[2K
| Adam | epoch: 029 | loss: 0.04894 - acc: 0.9825 -- iter: 1408/2015
[A[ATraining Step: 1809  | total loss: [1m[32m0.04456[0m[0m | time: 29.403s
[2K
| Adam | epoch: 029 | loss: 0.04456 - acc: 0.9842 -- iter: 1440/2015
[A[ATraining Step: 1810  | total loss: [1m[32m0.04047[0m[0m | time: 29.993s
[2K
| Adam | epoch: 029 | loss: 0.04047 - acc: 0.9858 -- iter: 1472/2015
[A[ATraining Step: 1811  | total loss: [1m[32m0.03780[0m[0m | time: 30.583s
[2K
| Adam | epoch: 029 | loss: 0.03780 - acc: 0.9872 -- iter: 1504/2015
[A[ATraining Step: 1812  | total loss: [1m[32m0.03930[0m[0m | time: 31.209s
[2K
| Adam | epoch: 029 | loss: 0.03930 - acc: 0.9854 -- iter: 1536/2015
[A[ATraining Step: 1813  | total loss: [1m[32m0.03910[0m[0m | time: 31.810s
[2K
| Adam | epoch: 029 | loss: 0.03910 - acc: 0.9868 -- iter: 1568/2015
[A[ATraining Step: 1814  | total loss: [1m[32m0.03581[0m[0m | time: 32.417s
[2K
| Adam | epoch: 029 | loss: 0.03581 - acc: 0.9882 -- iter: 1600/2015
[A[ATraining Step: 1815  | total loss: [1m[32m0.03296[0m[0m | time: 33.012s
[2K
| Adam | epoch: 029 | loss: 0.03296 - acc: 0.9893 -- iter: 1632/2015
[A[ATraining Step: 1816  | total loss: [1m[32m0.03590[0m[0m | time: 33.619s
[2K
| Adam | epoch: 029 | loss: 0.03590 - acc: 0.9873 -- iter: 1664/2015
[A[ATraining Step: 1817  | total loss: [1m[32m0.03484[0m[0m | time: 34.219s
[2K
| Adam | epoch: 029 | loss: 0.03484 - acc: 0.9886 -- iter: 1696/2015
[A[ATraining Step: 1818  | total loss: [1m[32m0.03327[0m[0m | time: 34.831s
[2K
| Adam | epoch: 029 | loss: 0.03327 - acc: 0.9897 -- iter: 1728/2015
[A[ATraining Step: 1819  | total loss: [1m[32m0.03096[0m[0m | time: 35.429s
[2K
| Adam | epoch: 029 | loss: 0.03096 - acc: 0.9907 -- iter: 1760/2015
[A[ATraining Step: 1820  | total loss: [1m[32m0.02975[0m[0m | time: 36.032s
[2K
| Adam | epoch: 029 | loss: 0.02975 - acc: 0.9917 -- iter: 1792/2015
[A[ATraining Step: 1821  | total loss: [1m[32m0.02789[0m[0m | time: 36.640s
[2K
| Adam | epoch: 029 | loss: 0.02789 - acc: 0.9925 -- iter: 1824/2015
[A[ATraining Step: 1822  | total loss: [1m[32m0.02553[0m[0m | time: 37.237s
[2K
| Adam | epoch: 029 | loss: 0.02553 - acc: 0.9932 -- iter: 1856/2015
[A[ATraining Step: 1823  | total loss: [1m[32m0.02573[0m[0m | time: 37.868s
[2K
| Adam | epoch: 029 | loss: 0.02573 - acc: 0.9939 -- iter: 1888/2015
[A[ATraining Step: 1824  | total loss: [1m[32m0.02381[0m[0m | time: 38.465s
[2K
| Adam | epoch: 029 | loss: 0.02381 - acc: 0.9945 -- iter: 1920/2015
[A[ATraining Step: 1825  | total loss: [1m[32m0.02252[0m[0m | time: 39.069s
[2K
| Adam | epoch: 029 | loss: 0.02252 - acc: 0.9951 -- iter: 1952/2015
[A[ATraining Step: 1826  | total loss: [1m[32m0.02173[0m[0m | time: 39.674s
[2K
| Adam | epoch: 029 | loss: 0.02173 - acc: 0.9956 -- iter: 1984/2015
[A[ATraining Step: 1827  | total loss: [1m[32m0.02053[0m[0m | time: 42.254s
[2K
| Adam | epoch: 029 | loss: 0.02053 - acc: 0.9960 | val_loss: 0.55983 - val_acc: 0.8698 -- iter: 2015/2015
--
Training Step: 1828  | total loss: [1m[32m0.01887[0m[0m | time: 0.607s
[2K
| Adam | epoch: 030 | loss: 0.01887 - acc: 0.9964 -- iter: 0032/2015
[A[ATraining Step: 1829  | total loss: [1m[32m0.01741[0m[0m | time: 1.208s
[2K
| Adam | epoch: 030 | loss: 0.01741 - acc: 0.9968 -- iter: 0064/2015
[A[ATraining Step: 1830  | total loss: [1m[32m0.01723[0m[0m | time: 1.817s
[2K
| Adam | epoch: 030 | loss: 0.01723 - acc: 0.9971 -- iter: 0096/2015
[A[ATraining Step: 1831  | total loss: [1m[32m0.01575[0m[0m | time: 2.429s
[2K
| Adam | epoch: 030 | loss: 0.01575 - acc: 0.9974 -- iter: 0128/2015
[A[ATraining Step: 1832  | total loss: [1m[32m0.01508[0m[0m | time: 3.031s
[2K
| Adam | epoch: 030 | loss: 0.01508 - acc: 0.9976 -- iter: 0160/2015
[A[ATraining Step: 1833  | total loss: [1m[32m0.01408[0m[0m | time: 3.639s
[2K
| Adam | epoch: 030 | loss: 0.01408 - acc: 0.9979 -- iter: 0192/2015
[A[ATraining Step: 1834  | total loss: [1m[32m0.02717[0m[0m | time: 4.234s
[2K
| Adam | epoch: 030 | loss: 0.02717 - acc: 0.9950 -- iter: 0224/2015
[A[ATraining Step: 1835  | total loss: [1m[32m0.02482[0m[0m | time: 4.845s
[2K
| Adam | epoch: 030 | loss: 0.02482 - acc: 0.9955 -- iter: 0256/2015
[A[ATraining Step: 1836  | total loss: [1m[32m0.02252[0m[0m | time: 5.479s
[2K
| Adam | epoch: 030 | loss: 0.02252 - acc: 0.9959 -- iter: 0288/2015
[A[ATraining Step: 1837  | total loss: [1m[32m0.02090[0m[0m | time: 6.102s
[2K
| Adam | epoch: 030 | loss: 0.02090 - acc: 0.9963 -- iter: 0320/2015
[A[ATraining Step: 1838  | total loss: [1m[32m0.01960[0m[0m | time: 6.714s
[2K
| Adam | epoch: 030 | loss: 0.01960 - acc: 0.9967 -- iter: 0352/2015
[A[ATraining Step: 1839  | total loss: [1m[32m0.01811[0m[0m | time: 7.290s
[2K
| Adam | epoch: 030 | loss: 0.01811 - acc: 0.9970 -- iter: 0384/2015
[A[ATraining Step: 1840  | total loss: [1m[32m0.01696[0m[0m | time: 7.886s
[2K
| Adam | epoch: 030 | loss: 0.01696 - acc: 0.9973 -- iter: 0416/2015
[A[ATraining Step: 1841  | total loss: [1m[32m0.01590[0m[0m | time: 8.481s
[2K
| Adam | epoch: 030 | loss: 0.01590 - acc: 0.9976 -- iter: 0448/2015
[A[ATraining Step: 1842  | total loss: [1m[32m0.01471[0m[0m | time: 9.101s
[2K
| Adam | epoch: 030 | loss: 0.01471 - acc: 0.9978 -- iter: 0480/2015
[A[ATraining Step: 1843  | total loss: [1m[32m0.01365[0m[0m | time: 9.710s
[2K
| Adam | epoch: 030 | loss: 0.01365 - acc: 0.9980 -- iter: 0512/2015
[A[ATraining Step: 1844  | total loss: [1m[32m0.01265[0m[0m | time: 10.319s
[2K
| Adam | epoch: 030 | loss: 0.01265 - acc: 0.9982 -- iter: 0544/2015
[A[ATraining Step: 1845  | total loss: [1m[32m0.01184[0m[0m | time: 10.915s
[2K
| Adam | epoch: 030 | loss: 0.01184 - acc: 0.9984 -- iter: 0576/2015
[A[ATraining Step: 1846  | total loss: [1m[32m0.01151[0m[0m | time: 11.521s
[2K
| Adam | epoch: 030 | loss: 0.01151 - acc: 0.9986 -- iter: 0608/2015
[A[ATraining Step: 1847  | total loss: [1m[32m0.01060[0m[0m | time: 12.130s
[2K
| Adam | epoch: 030 | loss: 0.01060 - acc: 0.9987 -- iter: 0640/2015
[A[ATraining Step: 1848  | total loss: [1m[32m0.00997[0m[0m | time: 12.765s
[2K
| Adam | epoch: 030 | loss: 0.00997 - acc: 0.9988 -- iter: 0672/2015
[A[ATraining Step: 1849  | total loss: [1m[32m0.00931[0m[0m | time: 13.374s
[2K
| Adam | epoch: 030 | loss: 0.00931 - acc: 0.9990 -- iter: 0704/2015
[A[ATraining Step: 1850  | total loss: [1m[32m0.00887[0m[0m | time: 13.985s
[2K
| Adam | epoch: 030 | loss: 0.00887 - acc: 0.9991 -- iter: 0736/2015
[A[ATraining Step: 1851  | total loss: [1m[32m0.00832[0m[0m | time: 14.591s
[2K
| Adam | epoch: 030 | loss: 0.00832 - acc: 0.9992 -- iter: 0768/2015
[A[ATraining Step: 1852  | total loss: [1m[32m0.00777[0m[0m | time: 15.183s
[2K
| Adam | epoch: 030 | loss: 0.00777 - acc: 0.9992 -- iter: 0800/2015
[A[ATraining Step: 1853  | total loss: [1m[32m0.00715[0m[0m | time: 15.783s
[2K
| Adam | epoch: 030 | loss: 0.00715 - acc: 0.9993 -- iter: 0832/2015
[A[ATraining Step: 1854  | total loss: [1m[32m0.00682[0m[0m | time: 16.395s
[2K
| Adam | epoch: 030 | loss: 0.00682 - acc: 0.9994 -- iter: 0864/2015
[A[ATraining Step: 1855  | total loss: [1m[32m0.00643[0m[0m | time: 16.983s
[2K
| Adam | epoch: 030 | loss: 0.00643 - acc: 0.9994 -- iter: 0896/2015
[A[ATraining Step: 1856  | total loss: [1m[32m0.00629[0m[0m | time: 17.568s
[2K
| Adam | epoch: 030 | loss: 0.00629 - acc: 0.9995 -- iter: 0928/2015
[A[ATraining Step: 1857  | total loss: [1m[32m0.00597[0m[0m | time: 18.193s
[2K
| Adam | epoch: 030 | loss: 0.00597 - acc: 0.9996 -- iter: 0960/2015
[A[ATraining Step: 1858  | total loss: [1m[32m0.00599[0m[0m | time: 18.793s
[2K
| Adam | epoch: 030 | loss: 0.00599 - acc: 0.9996 -- iter: 0992/2015
[A[ATraining Step: 1859  | total loss: [1m[32m0.00581[0m[0m | time: 19.398s
[2K
| Adam | epoch: 030 | loss: 0.00581 - acc: 0.9996 -- iter: 1024/2015
[A[ATraining Step: 1860  | total loss: [1m[32m0.00773[0m[0m | time: 20.001s
[2K
| Adam | epoch: 030 | loss: 0.00773 - acc: 0.9997 -- iter: 1056/2015
[A[ATraining Step: 1861  | total loss: [1m[32m0.00731[0m[0m | time: 20.621s
[2K
| Adam | epoch: 030 | loss: 0.00731 - acc: 0.9997 -- iter: 1088/2015
[A[ATraining Step: 1862  | total loss: [1m[32m0.00692[0m[0m | time: 21.229s
[2K
| Adam | epoch: 030 | loss: 0.00692 - acc: 0.9997 -- iter: 1120/2015
[A[ATraining Step: 1863  | total loss: [1m[32m0.00957[0m[0m | time: 21.835s
[2K
| Adam | epoch: 030 | loss: 0.00957 - acc: 0.9966 -- iter: 1152/2015
[A[ATraining Step: 1864  | total loss: [1m[32m0.00925[0m[0m | time: 22.438s
[2K
| Adam | epoch: 030 | loss: 0.00925 - acc: 0.9970 -- iter: 1184/2015
[A[ATraining Step: 1865  | total loss: [1m[32m0.01256[0m[0m | time: 23.048s
[2K
| Adam | epoch: 030 | loss: 0.01256 - acc: 0.9942 -- iter: 1216/2015
[A[ATraining Step: 1866  | total loss: [1m[32m0.01174[0m[0m | time: 23.650s
[2K
| Adam | epoch: 030 | loss: 0.01174 - acc: 0.9947 -- iter: 1248/2015
[A[ATraining Step: 1867  | total loss: [1m[32m0.01469[0m[0m | time: 24.278s
[2K
| Adam | epoch: 030 | loss: 0.01469 - acc: 0.9921 -- iter: 1280/2015
[A[ATraining Step: 1868  | total loss: [1m[32m0.01462[0m[0m | time: 24.879s
[2K
| Adam | epoch: 030 | loss: 0.01462 - acc: 0.9929 -- iter: 1312/2015
[A[ATraining Step: 1869  | total loss: [1m[32m0.01337[0m[0m | time: 25.479s
[2K
| Adam | epoch: 030 | loss: 0.01337 - acc: 0.9936 -- iter: 1344/2015
[A[ATraining Step: 1870  | total loss: [1m[32m0.01498[0m[0m | time: 26.076s
[2K
| Adam | epoch: 030 | loss: 0.01498 - acc: 0.9911 -- iter: 1376/2015
[A[ATraining Step: 1871  | total loss: [1m[32m0.01366[0m[0m | time: 26.686s
[2K
| Adam | epoch: 030 | loss: 0.01366 - acc: 0.9920 -- iter: 1408/2015
[A[ATraining Step: 1872  | total loss: [1m[32m0.01281[0m[0m | time: 27.313s
[2K
| Adam | epoch: 030 | loss: 0.01281 - acc: 0.9928 -- iter: 1440/2015
[A[ATraining Step: 1873  | total loss: [1m[32m0.02422[0m[0m | time: 27.915s
[2K
| Adam | epoch: 030 | loss: 0.02422 - acc: 0.9904 -- iter: 1472/2015
[A[ATraining Step: 1874  | total loss: [1m[32m0.02312[0m[0m | time: 28.521s
[2K
| Adam | epoch: 030 | loss: 0.02312 - acc: 0.9914 -- iter: 1504/2015
[A[ATraining Step: 1875  | total loss: [1m[32m0.02109[0m[0m | time: 29.134s
[2K
| Adam | epoch: 030 | loss: 0.02109 - acc: 0.9922 -- iter: 1536/2015
[A[ATraining Step: 1876  | total loss: [1m[32m0.02215[0m[0m | time: 29.731s
[2K
| Adam | epoch: 030 | loss: 0.02215 - acc: 0.9930 -- iter: 1568/2015
[A[ATraining Step: 1877  | total loss: [1m[32m0.02017[0m[0m | time: 30.327s
[2K
| Adam | epoch: 030 | loss: 0.02017 - acc: 0.9937 -- iter: 1600/2015
[A[ATraining Step: 1878  | total loss: [1m[32m0.01846[0m[0m | time: 30.944s
[2K
| Adam | epoch: 030 | loss: 0.01846 - acc: 0.9943 -- iter: 1632/2015
[A[ATraining Step: 1879  | total loss: [1m[32m0.01720[0m[0m | time: 31.540s
[2K
| Adam | epoch: 030 | loss: 0.01720 - acc: 0.9949 -- iter: 1664/2015
[A[ATraining Step: 1880  | total loss: [1m[32m0.01842[0m[0m | time: 32.141s
[2K
| Adam | epoch: 030 | loss: 0.01842 - acc: 0.9954 -- iter: 1696/2015
[A[ATraining Step: 1881  | total loss: [1m[32m0.01722[0m[0m | time: 32.746s
[2K
| Adam | epoch: 030 | loss: 0.01722 - acc: 0.9959 -- iter: 1728/2015
[A[ATraining Step: 1882  | total loss: [1m[32m0.01581[0m[0m | time: 33.355s
[2K
| Adam | epoch: 030 | loss: 0.01581 - acc: 0.9963 -- iter: 1760/2015
[A[ATraining Step: 1883  | total loss: [1m[32m0.01504[0m[0m | time: 33.972s
[2K
| Adam | epoch: 030 | loss: 0.01504 - acc: 0.9967 -- iter: 1792/2015
[A[ATraining Step: 1884  | total loss: [1m[32m0.01375[0m[0m | time: 34.583s
[2K
| Adam | epoch: 030 | loss: 0.01375 - acc: 0.9970 -- iter: 1824/2015
[A[ATraining Step: 1885  | total loss: [1m[32m0.03176[0m[0m | time: 35.189s
[2K
| Adam | epoch: 030 | loss: 0.03176 - acc: 0.9942 -- iter: 1856/2015
[A[ATraining Step: 1886  | total loss: [1m[32m0.02972[0m[0m | time: 35.789s
[2K
| Adam | epoch: 030 | loss: 0.02972 - acc: 0.9948 -- iter: 1888/2015
[A[ATraining Step: 1887  | total loss: [1m[32m0.02743[0m[0m | time: 36.391s
[2K
| Adam | epoch: 030 | loss: 0.02743 - acc: 0.9953 -- iter: 1920/2015
[A[ATraining Step: 1888  | total loss: [1m[32m0.04453[0m[0m | time: 37.019s
[2K
| Adam | epoch: 030 | loss: 0.04453 - acc: 0.9926 -- iter: 1952/2015
[A[ATraining Step: 1889  | total loss: [1m[32m0.04539[0m[0m | time: 37.615s
[2K
| Adam | epoch: 030 | loss: 0.04539 - acc: 0.9902 -- iter: 1984/2015
[A[ATraining Step: 1890  | total loss: [1m[32m0.04193[0m[0m | time: 40.202s
[2K
| Adam | epoch: 030 | loss: 0.04193 - acc: 0.9912 | val_loss: 0.57677 - val_acc: 0.8587 -- iter: 2015/2015
--
2018-08-02 00:06:55.561980: W tensorflow/core/framework/allocator.cc:101] Allocation of 5705763840 exceeds 10% of system memory.
2018-08-02 00:06:57.375841: W tensorflow/core/framework/allocator.cc:101] Allocation of 5705763840 exceeds 10% of system memory.
Validation AUC:0.926108870967742
Validation AUPRC:0.9308564688658012
Test AUC:0.9273036406199548
Test AUPRC:0.9247905558665784
BestTestF1Score	0.87	0.72	0.86	0.82	0.93	302	67	237	24	0.41
BestTestMCCScore	0.88	0.74	0.87	0.86	0.9	292	49	255	34	0.76
BestTestAccuracyScore	0.88	0.74	0.87	0.86	0.9	292	49	255	34	0.76
BestValidationF1Score	0.87	0.73	0.87	0.85	0.9	287	51	259	33	0.41
BestValidationMCC	0.87	0.74	0.87	0.87	0.87	279	42	268	41	0.76
BestValidationAccuracy	0.87	0.74	0.87	0.87	0.87	279	42	268	41	0.76
TestPredictions (Threshold:0.76)
CHEMBL216406,TN,INACT,0.07999999821186066	CHEMBL73096,TN,INACT,0.2800000011920929	CHEMBL1161419,TN,INACT,0.0	CHEMBL46195,TN,INACT,0.0	CHEMBL2312641,TP,ACT,1.0	CHEMBL294349,TN,INACT,0.0	CHEMBL59733,TN,INACT,0.0	CHEMBL194305,FN,ACT,0.009999999776482582	CHEMBL3121429,TP,ACT,1.0	CHEMBL73979,TP,ACT,0.9900000095367432	CHEMBL91752,TN,INACT,0.0	CHEMBL3759927,TP,ACT,1.0	CHEMBL3361000,TP,ACT,1.0	CHEMBL297599,TN,INACT,0.009999999776482582	CHEMBL352925,TN,INACT,0.0	CHEMBL31354,TP,ACT,1.0	CHEMBL482562,TP,ACT,1.0	CHEMBL522691,TP,ACT,1.0	CHEMBL1834624,TN,INACT,0.0	CHEMBL429238,TN,INACT,0.0	CHEMBL478073,TP,ACT,1.0	CHEMBL2159319,TP,ACT,1.0	CHEMBL494428,TP,ACT,1.0	CHEMBL3262418,TP,ACT,1.0	CHEMBL12529,FP,INACT,1.0	CHEMBL3360997,TP,ACT,1.0	CHEMBL2312937,TP,ACT,1.0	CHEMBL3114163,TN,INACT,0.019999999552965164	CHEMBL73392,TN,INACT,0.10999999940395355	CHEMBL47040,TN,INACT,0.49000000953674316	CHEMBL3235731,TP,ACT,1.0	CHEMBL260971,TP,ACT,1.0	CHEMBL602889,TP,ACT,1.0	CHEMBL81069,TP,ACT,0.9300000071525574	CHEMBL605405,FN,ACT,0.7099999785423279	CHEMBL131495,TP,ACT,1.0	CHEMBL54125,TN,INACT,0.0	CHEMBL193435,TP,ACT,1.0	CHEMBL3262420,TP,ACT,1.0	CHEMBL2037529,TP,ACT,0.9800000190734863	CHEMBL3577343,TN,INACT,0.0	CHEMBL1917343,TP,ACT,1.0	CHEMBL3409048,TP,ACT,1.0	CHEMBL390298,TN,INACT,0.0	CHEMBL3289968,TP,ACT,1.0	CHEMBL426317,TP,ACT,1.0	CHEMBL446693,TN,INACT,0.0	CHEMBL3290010,TP,ACT,1.0	CHEMBL3423329,TP,ACT,1.0	CHEMBL9250,TP,ACT,1.0	CHEMBL188486,FN,ACT,0.009999999776482582	CHEMBL137483,TN,INACT,0.009999999776482582	CHEMBL2164336,TP,ACT,1.0	CHEMBL3769534,TP,ACT,1.0	CHEMBL432897,TN,INACT,0.25	CHEMBL3088176,TN,INACT,0.2800000011920929	CHEMBL59931,TN,INACT,0.0	CHEMBL275451,TP,ACT,0.9900000095367432	CHEMBL180389,FP,INACT,0.7699999809265137	CHEMBL1949977,TP,ACT,0.9700000286102295	CHEMBL83090,TP,ACT,1.0	CHEMBL168855,TN,INACT,0.0	CHEMBL3633650,TN,INACT,0.0	CHEMBL112314,TN,INACT,0.0	CHEMBL601250,TP,ACT,0.8999999761581421	CHEMBL305371,TN,INACT,0.0	CHEMBL49935,TN,INACT,0.0	CHEMBL69036,TN,INACT,0.20000000298023224	CHEMBL52396,TN,INACT,0.0	CHEMBL2159320,TP,ACT,1.0	CHEMBL3409041,TP,ACT,1.0	CHEMBL3251298,TN,INACT,0.0	CHEMBL1917345,TP,ACT,1.0	CHEMBL258075,TP,ACT,0.9100000262260437	CHEMBL78624,TN,INACT,0.0	CHEMBL433134,TP,ACT,1.0	CHEMBL3759161,TP,ACT,1.0	CHEMBL3818994,TP,ACT,1.0	CHEMBL3360993,TP,ACT,0.9200000166893005	CHEMBL3589940,FP,INACT,1.0	CHEMBL229620,FP,INACT,1.0	CHEMBL3262430,TP,ACT,1.0	CHEMBL1940419,TP,ACT,0.9900000095367432	CHEMBL3401480,TP,ACT,1.0	CHEMBL478682,TP,ACT,0.9399999976158142	CHEMBL64120,TN,INACT,0.0	CHEMBL411,TN,INACT,0.019999999552965164	CHEMBL343969,TN,INACT,0.6100000143051147	CHEMBL26607,TN,INACT,0.0	CHEMBL3343667,FN,ACT,0.09000000357627869	CHEMBL3113601,TP,ACT,1.0	CHEMBL600606,TP,ACT,1.0	CHEMBL402143,TP,ACT,1.0	CHEMBL133257,TN,INACT,0.0	CHEMBL3403340,TN,INACT,0.05999999865889549	CHEMBL1083787,FP,INACT,0.8899999856948853	CHEMBL348890,TP,ACT,1.0	CHEMBL2159464,TP,ACT,0.8500000238418579	CHEMBL323176,TN,INACT,0.0	CHEMBL434063,TN,INACT,0.05000000074505806	CHEMBL25688,TN,INACT,0.0	CHEMBL285010,FP,INACT,0.9800000190734863	CHEMBL3741657,TP,ACT,1.0	CHEMBL307352,TP,ACT,0.9900000095367432	CHEMBL559260,TP,ACT,1.0	CHEMBL599819,TP,ACT,0.9900000095367432	CHEMBL3289996,TP,ACT,1.0	CHEMBL302196,TN,INACT,0.0	CHEMBL2205812,TP,ACT,1.0	CHEMBL259199,TP,ACT,1.0	CHEMBL153398,TP,ACT,1.0	CHEMBL3121439,TP,ACT,1.0	CHEMBL3289993,TP,ACT,1.0	CHEMBL269083,TP,ACT,1.0	CHEMBL10808,TN,INACT,0.33000001311302185	CHEMBL3216068,TP,ACT,1.0	CHEMBL1644267,TP,ACT,0.8799999952316284	CHEMBL212160,TN,INACT,0.05999999865889549	CHEMBL391192,FN,ACT,0.5	CHEMBL408976,TP,ACT,1.0	CHEMBL2443001,TN,INACT,0.019999999552965164	CHEMBL326263,TP,ACT,0.9900000095367432	CHEMBL74066,TN,INACT,0.03999999910593033	CHEMBL362540,TP,ACT,1.0	CHEMBL2159314,TP,ACT,1.0	CHEMBL1223054,FP,INACT,0.9700000286102295	CHEMBL474708,TN,INACT,0.0	CHEMBL42065,FP,INACT,1.0	CHEMBL1917348,TP,ACT,1.0	CHEMBL233501,TN,INACT,0.009999999776482582	CHEMBL104,FP,INACT,0.8899999856948853	CHEMBL274318,TN,INACT,0.0	CHEMBL341825,FP,INACT,0.9200000166893005	CHEMBL287987,TN,INACT,0.27000001072883606	CHEMBL1917331,TP,ACT,1.0	CHEMBL2058407,FN,ACT,0.0	CHEMBL2113067,TN,INACT,0.0	CHEMBL1917334,TP,ACT,1.0	CHEMBL461089,TN,INACT,0.0	CHEMBL1983100,TN,INACT,0.05000000074505806	CHEMBL299097,TN,INACT,0.46000000834465027	CHEMBL68094,TP,ACT,1.0	CHEMBL410226,TP,ACT,1.0	CHEMBL261572,TP,ACT,1.0	CHEMBL3409034,TP,ACT,1.0	CHEMBL267543,TP,ACT,0.9100000262260437	CHEMBL268881,TN,INACT,0.009999999776482582	CHEMBL1917360,TP,ACT,1.0	CHEMBL3360996,TP,ACT,1.0	CHEMBL716,FN,ACT,0.3199999928474426	CHEMBL102452,TN,INACT,0.0	CHEMBL2181166,TP,ACT,0.9900000095367432	CHEMBL239259,TP,ACT,0.9900000095367432	CHEMBL2159306,TP,ACT,0.9300000071525574	CHEMBL404097,FP,INACT,0.9800000190734863	CHEMBL26782,TN,INACT,0.1599999964237213	CHEMBL110064,TN,INACT,0.0	CHEMBL2158026,TP,ACT,1.0	CHEMBL64321,TN,INACT,0.0	CHEMBL261719,TP,ACT,1.0	CHEMBL2181188,TP,ACT,1.0	CHEMBL407818,TN,INACT,0.009999999776482582	CHEMBL349689,TN,INACT,0.0	CHEMBL260761,TP,ACT,1.0	CHEMBL3423335,TP,ACT,1.0	CHEMBL479,TP,ACT,0.9900000095367432	CHEMBL9347,TP,ACT,1.0	CHEMBL493416,TP,ACT,1.0	CHEMBL3290991,TN,INACT,0.2199999988079071	CHEMBL87496,TN,INACT,0.75	CHEMBL304888,TN,INACT,0.0	CHEMBL284912,TN,INACT,0.0	CHEMBL121289,TN,INACT,0.0	CHEMBL2387335,TN,INACT,0.0	CHEMBL214335,FN,ACT,0.23999999463558197	CHEMBL11629,TN,INACT,0.009999999776482582	CHEMBL305512,TN,INACT,0.0	CHEMBL1631540,TP,ACT,1.0	CHEMBL325935,TN,INACT,0.0	CHEMBL1916700,TN,INACT,0.009999999776482582	CHEMBL3113604,TP,ACT,1.0	CHEMBL209821,TP,ACT,1.0	CHEMBL2376483,TP,ACT,1.0	CHEMBL2037432,TP,ACT,0.9900000095367432	CHEMBL241102,FN,ACT,0.25999999046325684	CHEMBL512542,TN,INACT,0.7300000190734863	CHEMBL2164341,TP,ACT,1.0	CHEMBL76480,FP,INACT,0.9700000286102295	CHEMBL66011,FP,INACT,0.9900000095367432	CHEMBL54,TP,ACT,0.9599999785423279	CHEMBL3665440,TN,INACT,0.0	CHEMBL514965,TN,INACT,0.0	CHEMBL1098359,FP,INACT,0.9700000286102295	CHEMBL409156,TP,ACT,1.0	CHEMBL232791,TP,ACT,1.0	CHEMBL71907,FP,INACT,0.9700000286102295	CHEMBL408493,TN,INACT,0.3100000023841858	CHEMBL3092756,TP,ACT,0.7699999809265137	CHEMBL182070,TP,ACT,1.0	CHEMBL357983,TN,INACT,0.5199999809265137	CHEMBL114379,TP,ACT,0.8999999761581421	CHEMBL3289997,TP,ACT,0.9800000190734863	CHEMBL3326983,TP,ACT,1.0	CHEMBL3403333,FP,INACT,1.0	CHEMBL416662,TN,INACT,0.0	CHEMBL3423337,TP,ACT,0.9900000095367432	CHEMBL3321777,TP,ACT,1.0	CHEMBL195706,TP,ACT,1.0	CHEMBL12846,TP,ACT,0.9800000190734863	CHEMBL258496,TP,ACT,1.0	CHEMBL3235756,TP,ACT,1.0	CHEMBL137781,TP,ACT,1.0	CHEMBL3759617,TP,ACT,1.0	CHEMBL605787,TP,ACT,1.0	CHEMBL3423331,TP,ACT,1.0	CHEMBL182797,TP,ACT,1.0	CHEMBL3289978,TP,ACT,1.0	CHEMBL80438,TN,INACT,0.029999999329447746	CHEMBL23529,TN,INACT,0.6100000143051147	CHEMBL364124,FN,ACT,0.3100000023841858	CHEMBL50188,TN,INACT,0.0	CHEMBL605582,TP,ACT,1.0	CHEMBL40966,TN,INACT,0.27000001072883606	CHEMBL392970,FN,ACT,0.0	CHEMBL3758814,TP,ACT,1.0	CHEMBL3770522,TP,ACT,1.0	CHEMBL1949962,TP,ACT,0.9900000095367432	CHEMBL332701,TP,ACT,1.0	CHEMBL3121415,TP,ACT,1.0	CHEMBL212631,TN,INACT,0.09000000357627869	CHEMBL319534,TN,INACT,0.0	CHEMBL2391352,TN,INACT,0.0	CHEMBL3758684,TP,ACT,1.0	CHEMBL489408,FN,ACT,0.009999999776482582	CHEMBL261019,TP,ACT,1.0	CHEMBL497749,TP,ACT,1.0	CHEMBL309017,TN,INACT,0.0	CHEMBL3262435,TP,ACT,0.9599999785423279	CHEMBL1201353,TN,INACT,0.03999999910593033	CHEMBL93868,TP,ACT,0.9300000071525574	CHEMBL228996,TN,INACT,0.03999999910593033	CHEMBL222755,TP,ACT,1.0	CHEMBL424369,TN,INACT,0.0	CHEMBL154068,TN,INACT,0.009999999776482582	CHEMBL3747744,TP,ACT,1.0	CHEMBL182174,TP,ACT,1.0	CHEMBL302829,TN,INACT,0.0	CHEMBL124675,TN,INACT,0.009999999776482582	CHEMBL2159469,TP,ACT,1.0	CHEMBL316968,TN,INACT,0.009999999776482582	CHEMBL6995,TN,INACT,0.0	CHEMBL70869,TP,ACT,1.0	CHEMBL308414,TN,INACT,0.009999999776482582	CHEMBL3403741,TN,INACT,0.0	CHEMBL2324200,FP,INACT,0.800000011920929	CHEMBL108417,TN,INACT,0.0	CHEMBL50740,TN,INACT,0.009999999776482582	CHEMBL2042403,TN,INACT,0.029999999329447746	CHEMBL65669,TN,INACT,0.0	CHEMBL1836793,TP,ACT,1.0	CHEMBL2381771,TN,INACT,0.0	CHEMBL3746806,TP,ACT,1.0	CHEMBL2181969,TN,INACT,0.0	CHEMBL140365,FP,INACT,0.8899999856948853	CHEMBL3087714,TN,INACT,0.5600000023841858	CHEMBL419912,TN,INACT,0.0	CHEMBL195437,TN,INACT,0.03999999910593033	CHEMBL259408,TP,ACT,1.0	CHEMBL3590085,FP,INACT,1.0	CHEMBL1192069,TN,INACT,0.0	CHEMBL1632206,TP,ACT,1.0	CHEMBL71165,FN,ACT,0.4699999988079071	CHEMBL302150,TN,INACT,0.0	CHEMBL228082,TP,ACT,0.9700000286102295	CHEMBL133868,TN,INACT,0.75	CHEMBL476615,TP,ACT,0.9900000095367432	CHEMBL553794,TP,ACT,0.9900000095367432	CHEMBL260022,TP,ACT,1.0	CHEMBL423918,TN,INACT,0.0	CHEMBL444128,TN,INACT,0.0	CHEMBL33224,TN,INACT,0.10000000149011612	CHEMBL261653,TP,ACT,1.0	CHEMBL2096822,TN,INACT,0.0	CHEMBL120513,TN,INACT,0.0	CHEMBL223686,TN,INACT,0.10999999940395355	CHEMBL3289959,TP,ACT,1.0	CHEMBL3121435,TP,ACT,1.0	CHEMBL180343,FP,INACT,0.8799999952316284	CHEMBL3326991,TP,ACT,1.0	CHEMBL1914488,TP,ACT,1.0	CHEMBL574602,TN,INACT,0.009999999776482582	CHEMBL1949975,TP,ACT,0.9399999976158142	CHEMBL3423378,TP,ACT,1.0	CHEMBL2158715,TN,INACT,0.550000011920929	CHEMBL430683,TN,INACT,0.0	CHEMBL298612,TN,INACT,0.0	CHEMBL605081,FN,ACT,0.1599999964237213	CHEMBL259414,TP,ACT,1.0	CHEMBL3403332,FP,INACT,1.0	CHEMBL7143,TP,ACT,0.9399999976158142	CHEMBL126472,FP,INACT,0.9200000166893005	CHEMBL41818,TN,INACT,0.6600000262260437	CHEMBL3310109,TP,ACT,1.0	CHEMBL130005,TN,INACT,0.05999999865889549	CHEMBL1910141,TP,ACT,0.7799999713897705	CHEMBL296908,TN,INACT,0.20000000298023224	CHEMBL88629,TN,INACT,0.0	CHEMBL476464,TP,ACT,1.0	CHEMBL104210,TN,INACT,0.3700000047683716	CHEMBL120278,TN,INACT,0.009999999776482582	CHEMBL294649,TN,INACT,0.0	CHEMBL404037,FP,INACT,1.0	CHEMBL3087709,TN,INACT,0.0	CHEMBL2442999,TP,ACT,1.0	CHEMBL3423404,FP,INACT,0.7699999809265137	CHEMBL2037527,TP,ACT,0.9900000095367432	CHEMBL484427,TN,INACT,0.0	CHEMBL80317,TN,INACT,0.009999999776482582	CHEMBL2369710,TN,INACT,0.0	CHEMBL33108,TN,INACT,0.0	CHEMBL7257,TP,ACT,0.8899999856948853	CHEMBL78977,TP,ACT,1.0	CHEMBL508011,TN,INACT,0.03999999910593033	CHEMBL1782811,TP,ACT,0.9700000286102295	CHEMBL333868,FP,INACT,1.0	CHEMBL291293,TN,INACT,0.7200000286102295	CHEMBL490634,TP,ACT,1.0	CHEMBL3409256,FN,ACT,0.05000000074505806	CHEMBL308634,TN,INACT,0.009999999776482582	CHEMBL228736,TN,INACT,0.1599999964237213	CHEMBL3581249,FN,ACT,0.0	CHEMBL3290014,TP,ACT,0.9800000190734863	CHEMBL3235755,TP,ACT,1.0	CHEMBL297473,TN,INACT,0.009999999776482582	CHEMBL271253,FN,ACT,0.6399999856948853	CHEMBL174259,TN,INACT,0.019999999552965164	CHEMBL2112095,TN,INACT,0.029999999329447746	CHEMBL3747148,TP,ACT,1.0	CHEMBL263700,TP,ACT,0.8299999833106995	CHEMBL74902,TN,INACT,0.0	CHEMBL300725,TN,INACT,0.3499999940395355	CHEMBL7185,TN,INACT,0.0	CHEMBL408451,TP,ACT,0.800000011920929	CHEMBL140984,TN,INACT,0.10999999940395355	CHEMBL319924,TN,INACT,0.0	CHEMBL142811,FP,INACT,1.0	CHEMBL2377445,TP,ACT,1.0	CHEMBL411919,TP,ACT,1.0	CHEMBL63289,TN,INACT,0.009999999776482582	CHEMBL240279,TN,INACT,0.41999998688697815	CHEMBL3343668,FN,ACT,0.6899999976158142	CHEMBL3739561,TP,ACT,1.0	CHEMBL288967,TN,INACT,0.0	CHEMBL600822,TP,ACT,1.0	CHEMBL3759651,TP,ACT,1.0	CHEMBL3290019,TP,ACT,1.0	CHEMBL328422,TN,INACT,0.0	CHEMBL182356,TP,ACT,1.0	CHEMBL338310,TN,INACT,0.20999999344348907	CHEMBL13052,TP,ACT,0.9599999785423279	CHEMBL238520,TP,ACT,1.0	CHEMBL2436819,TN,INACT,0.0	CHEMBL1946254,TP,ACT,1.0	CHEMBL418411,TN,INACT,0.0	CHEMBL1949978,TP,ACT,1.0	CHEMBL298534,TN,INACT,0.0	CHEMBL393539,TP,ACT,0.9900000095367432	CHEMBL3759437,TP,ACT,1.0	CHEMBL603093,TP,ACT,1.0	CHEMBL78642,TN,INACT,0.0	CHEMBL439790,TN,INACT,0.029999999329447746	CHEMBL2436814,TN,INACT,0.0	CHEMBL11671,TN,INACT,0.0	CHEMBL606556,FN,ACT,0.6100000143051147	CHEMBL10813,TN,INACT,0.05000000074505806	CHEMBL2436816,TN,INACT,0.03999999910593033	CHEMBL2062850,TN,INACT,0.0	CHEMBL6437,TP,ACT,1.0	CHEMBL601022,TP,ACT,1.0	CHEMBL3735265,TN,INACT,0.05000000074505806	CHEMBL1949968,TP,ACT,0.9900000095367432	CHEMBL112777,TN,INACT,0.009999999776482582	CHEMBL28056,FN,ACT,0.019999999552965164	CHEMBL1949974,FN,ACT,0.6299999952316284	CHEMBL114478,TN,INACT,0.009999999776482582	CHEMBL273921,TP,ACT,1.0	CHEMBL3310714,TP,ACT,1.0	CHEMBL3121434,TP,ACT,1.0	CHEMBL2312639,TP,ACT,1.0	CHEMBL240023,FN,ACT,0.009999999776482582	CHEMBL3819567,TP,ACT,1.0	CHEMBL324652,TN,INACT,0.09000000357627869	CHEMBL3739745,TP,ACT,1.0	CHEMBL262589,TP,ACT,0.9900000095367432	CHEMBL3818398,TP,ACT,1.0	CHEMBL416151,TN,INACT,0.009999999776482582	CHEMBL27995,TN,INACT,0.5400000214576721	CHEMBL182840,TP,ACT,0.9800000190734863	CHEMBL3354069,FP,INACT,1.0	CHEMBL3235726,FN,ACT,0.7599999904632568	CHEMBL3577342,TN,INACT,0.0	CHEMBL1791272,TN,INACT,0.0	CHEMBL353502,TN,INACT,0.05999999865889549	CHEMBL307326,TN,INACT,0.009999999776482582	CHEMBL21343,FN,ACT,0.0	CHEMBL62592,TN,INACT,0.009999999776482582	CHEMBL2436824,TN,INACT,0.009999999776482582	CHEMBL3746083,TP,ACT,1.0	CHEMBL3121417,TP,ACT,1.0	CHEMBL3290978,TN,INACT,0.019999999552965164	CHEMBL182006,TP,ACT,1.0	CHEMBL3114144,TN,INACT,0.019999999552965164	CHEMBL2442276,FN,ACT,0.0	CHEMBL3321778,TP,ACT,1.0	CHEMBL260804,TP,ACT,1.0	CHEMBL160903,TP,ACT,0.800000011920929	CHEMBL3747117,TP,ACT,1.0	CHEMBL565745,TP,ACT,0.8199999928474426	CHEMBL110904,TN,INACT,0.0	CHEMBL1259241,TN,INACT,0.009999999776482582	CHEMBL114012,TP,ACT,1.0	CHEMBL2164335,TP,ACT,1.0	CHEMBL1631532,TP,ACT,1.0	CHEMBL3409038,TP,ACT,1.0	CHEMBL3739820,FP,INACT,1.0	CHEMBL3290016,TP,ACT,1.0	CHEMBL329861,TN,INACT,0.0	CHEMBL1170027,TN,INACT,0.0	CHEMBL2042401,TN,INACT,0.0	CHEMBL1642117,TP,ACT,1.0	CHEMBL3235727,TP,ACT,1.0	CHEMBL3290009,TP,ACT,1.0	CHEMBL561750,TP,ACT,0.9599999785423279	CHEMBL426385,TN,INACT,0.0	CHEMBL95067,TP,ACT,0.9900000095367432	CHEMBL589390,FN,ACT,0.12999999523162842	CHEMBL267014,TP,ACT,0.9700000286102295	CHEMBL2312346,TN,INACT,0.14000000059604645	CHEMBL81424,TP,ACT,1.0	CHEMBL3310119,FN,ACT,0.20999999344348907	CHEMBL116448,TP,ACT,1.0	CHEMBL2037519,TP,ACT,0.949999988079071	CHEMBL299524,FP,INACT,0.8999999761581421	CHEMBL344154,TN,INACT,0.009999999776482582	CHEMBL389902,FP,INACT,1.0	CHEMBL89953,FP,INACT,0.9200000166893005	CHEMBL414605,TN,INACT,0.0	CHEMBL9840,TP,ACT,0.9599999785423279	CHEMBL2158039,TP,ACT,0.9800000190734863	CHEMBL430706,FN,ACT,0.0	CHEMBL1836857,TP,ACT,1.0	CHEMBL3235742,TP,ACT,1.0	CHEMBL3113597,TP,ACT,1.0	CHEMBL2370238,TN,INACT,0.0	CHEMBL3581254,TP,ACT,1.0	CHEMBL3233674,TP,ACT,1.0	CHEMBL260872,TP,ACT,1.0	CHEMBL94902,TN,INACT,0.0	CHEMBL53662,TN,INACT,0.20000000298023224	CHEMBL3765208,TP,ACT,0.9399999976158142	CHEMBL726,FP,INACT,0.9599999785423279	CHEMBL390842,TN,INACT,0.0	CHEMBL2037530,TP,ACT,1.0	CHEMBL71765,TN,INACT,0.0	CHEMBL327626,TN,INACT,0.1599999964237213	CHEMBL113956,TP,ACT,0.9399999976158142	CHEMBL97518,TP,ACT,0.9900000095367432	CHEMBL3759233,TP,ACT,0.9300000071525574	CHEMBL3423401,FP,INACT,0.9800000190734863	CHEMBL3262432,TP,ACT,1.0	CHEMBL3262409,TP,ACT,1.0	CHEMBL45087,TN,INACT,0.0	CHEMBL461087,TN,INACT,0.0	CHEMBL3216275,TP,ACT,0.800000011920929	CHEMBL197159,TN,INACT,0.0	CHEMBL3758619,FN,ACT,0.03999999910593033	CHEMBL40317,TN,INACT,0.49000000953674316	CHEMBL27763,TN,INACT,0.03999999910593033	CHEMBL71170,TP,ACT,1.0	CHEMBL3290986,FP,INACT,1.0	CHEMBL354210,FP,INACT,0.9900000095367432	CHEMBL264761,TN,INACT,0.0	CHEMBL401745,FN,ACT,0.05999999865889549	CHEMBL391191,FN,ACT,0.6000000238418579	CHEMBL3818124,TP,ACT,1.0	CHEMBL495685,TP,ACT,1.0	CHEMBL2159318,TP,ACT,1.0	CHEMBL12259,TP,ACT,1.0	CHEMBL3289981,TP,ACT,1.0	CHEMBL12702,TP,ACT,1.0	CHEMBL81607,TP,ACT,1.0	CHEMBL89445,TN,INACT,0.7400000095367432	CHEMBL3423408,FP,INACT,1.0	CHEMBL469855,FP,INACT,0.9900000095367432	CHEMBL3608763,TN,INACT,0.009999999776482582	CHEMBL1917353,TP,ACT,1.0	CHEMBL320804,TN,INACT,0.0	CHEMBL112876,TP,ACT,1.0	CHEMBL3235747,TP,ACT,1.0	CHEMBL1910139,TP,ACT,0.9700000286102295	CHEMBL1949979,TP,ACT,1.0	CHEMBL2052004,TN,INACT,0.009999999776482582	CHEMBL3343666,TP,ACT,1.0	CHEMBL324685,TN,INACT,0.0	CHEMBL182805,TP,ACT,1.0	CHEMBL2312347,FP,INACT,1.0	CHEMBL29846,TP,ACT,0.9700000286102295	CHEMBL301060,TN,INACT,0.0	CHEMBL148967,TN,INACT,0.0	CHEMBL62660,TN,INACT,0.0	CHEMBL165012,TN,INACT,0.28999999165534973	CHEMBL2111775,TN,INACT,0.0	CHEMBL166089,TN,INACT,0.0	CHEMBL2207493,TN,INACT,0.18000000715255737	CHEMBL258995,TP,ACT,1.0	CHEMBL261337,TP,ACT,1.0	CHEMBL2181168,TP,ACT,1.0	CHEMBL481414,TN,INACT,0.07999999821186066	CHEMBL1907969,TN,INACT,0.1899999976158142	CHEMBL173708,TN,INACT,0.0	CHEMBL3759342,TP,ACT,0.9900000095367432	CHEMBL3217760,TN,INACT,0.029999999329447746	CHEMBL312266,TN,INACT,0.019999999552965164	CHEMBL52438,TN,INACT,0.0	CHEMBL117036,TN,INACT,0.019999999552965164	CHEMBL292725,TN,INACT,0.0	CHEMBL260551,TP,ACT,1.0	CHEMBL3764477,TP,ACT,1.0	CHEMBL3290977,TN,INACT,0.009999999776482582	CHEMBL407412,TP,ACT,1.0	CHEMBL476462,TP,ACT,1.0	CHEMBL3361003,TP,ACT,1.0	CHEMBL3289962,TP,ACT,0.9900000095367432	CHEMBL351183,TN,INACT,0.6000000238418579	CHEMBL73917,TN,INACT,0.029999999329447746	CHEMBL1949969,TP,ACT,1.0	CHEMBL71,TP,ACT,0.9900000095367432	CHEMBL494510,TN,INACT,0.0	CHEMBL2442994,TP,ACT,1.0	CHEMBL310594,TP,ACT,1.0	CHEMBL603092,TP,ACT,1.0	CHEMBL386152,TN,INACT,0.0	CHEMBL600012,TP,ACT,1.0	CHEMBL411105,TP,ACT,1.0	CHEMBL3343669,TP,ACT,1.0	CHEMBL3289971,TP,ACT,1.0	CHEMBL3216729,TP,ACT,1.0	CHEMBL406414,TP,ACT,1.0	CHEMBL3581248,TP,ACT,1.0	CHEMBL334498,FP,INACT,0.9900000095367432	CHEMBL191226,FP,INACT,1.0	CHEMBL3121423,TP,ACT,1.0	CHEMBL3769606,TP,ACT,1.0	CHEMBL549,TN,INACT,0.0	CHEMBL3759874,TP,ACT,1.0	CHEMBL63845,TN,INACT,0.27000001072883606	CHEMBL601673,TP,ACT,1.0	CHEMBL100624,TN,INACT,0.0	CHEMBL140006,TN,INACT,0.0	CHEMBL414085,TN,INACT,0.0	CHEMBL179638,TN,INACT,0.029999999329447746	CHEMBL73272,TN,INACT,0.0	CHEMBL305313,TN,INACT,0.0	CHEMBL1221449,TP,ACT,0.8299999833106995	CHEMBL610515,TP,ACT,1.0	CHEMBL455493,TN,INACT,0.009999999776482582	CHEMBL2159487,TP,ACT,1.0	CHEMBL2392349,TP,ACT,1.0	CHEMBL286214,TN,INACT,0.0	CHEMBL52772,TN,INACT,0.0	CHEMBL298649,TN,INACT,0.0	CHEMBL3321797,TP,ACT,1.0	CHEMBL229388,TN,INACT,0.0	CHEMBL410128,TP,ACT,1.0	CHEMBL293232,TN,INACT,0.0	CHEMBL204171,TP,ACT,1.0	CHEMBL1259071,TN,INACT,0.03999999910593033	CHEMBL46,TN,INACT,0.009999999776482582	CHEMBL3665439,TN,INACT,0.0	CHEMBL440864,FP,INACT,0.8899999856948853	CHEMBL3343663,TP,ACT,1.0	CHEMBL167335,TN,INACT,0.0	CHEMBL3234532,TN,INACT,0.029999999329447746	CHEMBL241083,TN,INACT,0.3799999952316284	CHEMBL254500,TN,INACT,0.019999999552965164	CHEMBL286682,TN,INACT,0.009999999776482582	CHEMBL344602,TN,INACT,0.019999999552965164	CHEMBL194659,TP,ACT,1.0	CHEMBL259010,TP,ACT,1.0	CHEMBL3235754,TP,ACT,1.0	CHEMBL2062854,TN,INACT,0.0	CHEMBL419617,TN,INACT,0.009999999776482582	CHEMBL3235739,TP,ACT,1.0	CHEMBL189192,TN,INACT,0.009999999776482582	CHEMBL261187,TP,ACT,1.0	CHEMBL281232,FP,INACT,0.8199999928474426	CHEMBL3310123,TP,ACT,1.0	CHEMBL97283,TN,INACT,0.0	CHEMBL3290000,TP,ACT,0.9800000190734863	CHEMBL1223277,FP,INACT,0.9599999785423279	CHEMBL3290021,TP,ACT,1.0	CHEMBL267044,TN,INACT,0.009999999776482582	CHEMBL16639,TN,INACT,0.009999999776482582	CHEMBL3262427,TP,ACT,1.0	CHEMBL343158,FP,INACT,0.800000011920929	CHEMBL70889,TP,ACT,1.0	CHEMBL81485,TP,ACT,1.0	CHEMBL492793,TP,ACT,1.0	CHEMBL252198,TN,INACT,0.0	CHEMBL2159454,TP,ACT,0.9800000190734863	CHEMBL163,TN,INACT,0.0	CHEMBL45305,FP,INACT,1.0	CHEMBL3309718,TN,INACT,0.0	CHEMBL217699,TN,INACT,0.0	CHEMBL150696,FP,INACT,1.0	CHEMBL272873,TN,INACT,0.1599999964237213	CHEMBL3104091,TP,ACT,0.9900000095367432	CHEMBL2079597,FP,INACT,0.9800000190734863	CHEMBL2159307,TP,ACT,1.0	CHEMBL267777,FN,ACT,0.07000000029802322	CHEMBL266591,FN,ACT,0.029999999329447746	CHEMBL142822,FP,INACT,1.0	CHEMBL326877,TN,INACT,0.07000000029802322	CHEMBL307659,TN,INACT,0.0	CHEMBL323854,TN,INACT,0.0	CHEMBL458409,TN,INACT,0.0	CHEMBL516334,TN,INACT,0.6100000143051147	CHEMBL408492,TN,INACT,0.0	CHEMBL59517,FP,INACT,0.9900000095367432	CHEMBL408191,FN,ACT,0.4399999976158142	

