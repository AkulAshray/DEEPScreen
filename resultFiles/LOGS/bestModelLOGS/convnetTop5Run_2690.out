CNNModel CHEMBL2345 adam 0.0001 30 256 0 0.6 False True
Number of active compounds :	312
Number of inactive compounds :	312
---------------------------------
Run id: CNNModel_CHEMBL2345_adam_0.0001_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2345_adam_0.0001_30_256_0.6_True/
---------------------------------
Training samples: 384
Validation samples: 120
--
Training Step: 1  | time: 0.779s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/384
[A[ATraining Step: 2  | total loss: [1m[32m0.62386[0m[0m | time: 1.403s
[2K
| Adam | epoch: 001 | loss: 0.62386 - acc: 0.3937 -- iter: 064/384
[A[ATraining Step: 3  | total loss: [1m[32m0.68015[0m[0m | time: 2.007s
[2K
| Adam | epoch: 001 | loss: 0.68015 - acc: 0.5318 -- iter: 096/384
[A[ATraining Step: 4  | total loss: [1m[32m0.68940[0m[0m | time: 2.618s
[2K
| Adam | epoch: 001 | loss: 0.68940 - acc: 0.5548 -- iter: 128/384
[A[ATraining Step: 5  | total loss: [1m[32m0.69187[0m[0m | time: 3.231s
[2K
| Adam | epoch: 001 | loss: 0.69187 - acc: 0.5169 -- iter: 160/384
[A[ATraining Step: 6  | total loss: [1m[32m0.69118[0m[0m | time: 3.849s
[2K
| Adam | epoch: 001 | loss: 0.69118 - acc: 0.5663 -- iter: 192/384
[A[ATraining Step: 7  | total loss: [1m[32m0.69386[0m[0m | time: 4.461s
[2K
| Adam | epoch: 001 | loss: 0.69386 - acc: 0.4703 -- iter: 224/384
[A[ATraining Step: 8  | total loss: [1m[32m0.69335[0m[0m | time: 5.074s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.4870 -- iter: 256/384
[A[ATraining Step: 9  | total loss: [1m[32m0.69397[0m[0m | time: 5.701s
[2K
| Adam | epoch: 001 | loss: 0.69397 - acc: 0.4608 -- iter: 288/384
[A[ATraining Step: 10  | total loss: [1m[32m0.69238[0m[0m | time: 6.310s
[2K
| Adam | epoch: 001 | loss: 0.69238 - acc: 0.5273 -- iter: 320/384
[A[ATraining Step: 11  | total loss: [1m[32m0.69408[0m[0m | time: 6.907s
[2K
| Adam | epoch: 001 | loss: 0.69408 - acc: 0.4699 -- iter: 352/384
[A[ATraining Step: 12  | total loss: [1m[32m0.69365[0m[0m | time: 8.584s
[2K
| Adam | epoch: 001 | loss: 0.69365 - acc: 0.4835 | val_loss: 0.69359 - val_acc: 0.4833 -- iter: 384/384
--
Training Step: 13  | total loss: [1m[32m0.69263[0m[0m | time: 0.624s
[2K
| Adam | epoch: 002 | loss: 0.69263 - acc: 0.5173 -- iter: 032/384
[A[ATraining Step: 14  | total loss: [1m[32m0.69214[0m[0m | time: 1.228s
[2K
| Adam | epoch: 002 | loss: 0.69214 - acc: 0.5358 -- iter: 064/384
[A[ATraining Step: 15  | total loss: [1m[32m0.69230[0m[0m | time: 1.841s
[2K
| Adam | epoch: 002 | loss: 0.69230 - acc: 0.5340 -- iter: 096/384
[A[ATraining Step: 16  | total loss: [1m[32m0.69022[0m[0m | time: 2.455s
[2K
| Adam | epoch: 002 | loss: 0.69022 - acc: 0.6033 -- iter: 128/384
[A[ATraining Step: 17  | total loss: [1m[32m0.69130[0m[0m | time: 3.081s
[2K
| Adam | epoch: 002 | loss: 0.69130 - acc: 0.5661 -- iter: 160/384
[A[ATraining Step: 18  | total loss: [1m[32m0.69369[0m[0m | time: 3.684s
[2K
| Adam | epoch: 002 | loss: 0.69369 - acc: 0.5000 -- iter: 192/384
[A[ATraining Step: 19  | total loss: [1m[32m0.69339[0m[0m | time: 4.285s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.5000 -- iter: 224/384
[A[ATraining Step: 20  | total loss: [1m[32m0.69140[0m[0m | time: 4.888s
[2K
| Adam | epoch: 002 | loss: 0.69140 - acc: 0.5502 -- iter: 256/384
[A[ATraining Step: 21  | total loss: [1m[32m0.69243[0m[0m | time: 5.501s
[2K
| Adam | epoch: 002 | loss: 0.69243 - acc: 0.5249 -- iter: 288/384
[A[ATraining Step: 22  | total loss: [1m[32m0.69214[0m[0m | time: 6.121s
[2K
| Adam | epoch: 002 | loss: 0.69214 - acc: 0.5268 -- iter: 320/384
[A[ATraining Step: 23  | total loss: [1m[32m0.69262[0m[0m | time: 6.724s
[2K
| Adam | epoch: 002 | loss: 0.69262 - acc: 0.5190 -- iter: 352/384
[A[ATraining Step: 24  | total loss: [1m[32m0.69364[0m[0m | time: 8.328s
[2K
| Adam | epoch: 002 | loss: 0.69364 - acc: 0.4961 | val_loss: 0.69417 - val_acc: 0.4833 -- iter: 384/384
--
Training Step: 25  | total loss: [1m[32m0.69342[0m[0m | time: 0.614s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.4972 -- iter: 032/384
[A[ATraining Step: 26  | total loss: [1m[32m0.69429[0m[0m | time: 1.210s
[2K
| Adam | epoch: 003 | loss: 0.69429 - acc: 0.4814 -- iter: 064/384
[A[ATraining Step: 27  | total loss: [1m[32m0.69501[0m[0m | time: 1.814s
[2K
| Adam | epoch: 003 | loss: 0.69501 - acc: 0.4701 -- iter: 096/384
[A[ATraining Step: 28  | total loss: [1m[32m0.69543[0m[0m | time: 2.423s
[2K
| Adam | epoch: 003 | loss: 0.69543 - acc: 0.4541 -- iter: 128/384
[A[ATraining Step: 29  | total loss: [1m[32m0.69522[0m[0m | time: 3.023s
[2K
| Adam | epoch: 003 | loss: 0.69522 - acc: 0.4577 -- iter: 160/384
[A[ATraining Step: 30  | total loss: [1m[32m0.69429[0m[0m | time: 3.632s
[2K
| Adam | epoch: 003 | loss: 0.69429 - acc: 0.4825 -- iter: 192/384
[A[ATraining Step: 31  | total loss: [1m[32m0.69433[0m[0m | time: 4.238s
[2K
| Adam | epoch: 003 | loss: 0.69433 - acc: 0.4793 -- iter: 224/384
[A[ATraining Step: 32  | total loss: [1m[32m0.69336[0m[0m | time: 4.837s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.5051 -- iter: 256/384
[A[ATraining Step: 33  | total loss: [1m[32m0.69316[0m[0m | time: 5.428s
[2K
| Adam | epoch: 003 | loss: 0.69316 - acc: 0.5108 -- iter: 288/384
[A[ATraining Step: 34  | total loss: [1m[32m0.69285[0m[0m | time: 6.035s
[2K
| Adam | epoch: 003 | loss: 0.69285 - acc: 0.5219 -- iter: 320/384
[A[ATraining Step: 35  | total loss: [1m[32m0.69208[0m[0m | time: 6.640s
[2K
| Adam | epoch: 003 | loss: 0.69208 - acc: 0.5435 -- iter: 352/384
[A[ATraining Step: 36  | total loss: [1m[32m0.69247[0m[0m | time: 8.259s
[2K
| Adam | epoch: 003 | loss: 0.69247 - acc: 0.5218 | val_loss: 0.69364 - val_acc: 0.4833 -- iter: 384/384
--
Training Step: 37  | total loss: [1m[32m0.69207[0m[0m | time: 0.607s
[2K
| Adam | epoch: 004 | loss: 0.69207 - acc: 0.5362 -- iter: 032/384
[A[ATraining Step: 38  | total loss: [1m[32m0.69268[0m[0m | time: 1.244s
[2K
| Adam | epoch: 004 | loss: 0.69268 - acc: 0.5169 -- iter: 064/384
[A[ATraining Step: 39  | total loss: [1m[32m0.69324[0m[0m | time: 1.843s
[2K
| Adam | epoch: 004 | loss: 0.69324 - acc: 0.5017 -- iter: 096/384
[A[ATraining Step: 40  | total loss: [1m[32m0.69359[0m[0m | time: 2.442s
[2K
| Adam | epoch: 004 | loss: 0.69359 - acc: 0.4896 -- iter: 128/384
[A[ATraining Step: 41  | total loss: [1m[32m0.69390[0m[0m | time: 3.038s
[2K
| Adam | epoch: 004 | loss: 0.69390 - acc: 0.4801 -- iter: 160/384
[A[ATraining Step: 42  | total loss: [1m[32m0.69349[0m[0m | time: 3.647s
[2K
| Adam | epoch: 004 | loss: 0.69349 - acc: 0.4893 -- iter: 192/384
[A[ATraining Step: 43  | total loss: [1m[32m0.69379[0m[0m | time: 4.258s
[2K
| Adam | epoch: 004 | loss: 0.69379 - acc: 0.4746 -- iter: 224/384
[A[ATraining Step: 44  | total loss: [1m[32m0.69349[0m[0m | time: 4.875s
[2K
| Adam | epoch: 004 | loss: 0.69349 - acc: 0.4844 -- iter: 256/384
[A[ATraining Step: 45  | total loss: [1m[32m0.69342[0m[0m | time: 5.482s
[2K
| Adam | epoch: 004 | loss: 0.69342 - acc: 0.4871 -- iter: 288/384
[A[ATraining Step: 46  | total loss: [1m[32m0.69312[0m[0m | time: 6.094s
[2K
| Adam | epoch: 004 | loss: 0.69312 - acc: 0.4996 -- iter: 320/384
[A[ATraining Step: 47  | total loss: [1m[32m0.69264[0m[0m | time: 6.747s
[2K
| Adam | epoch: 004 | loss: 0.69264 - acc: 0.5202 -- iter: 352/384
[A[ATraining Step: 48  | total loss: [1m[32m0.69278[0m[0m | time: 8.349s
[2K
| Adam | epoch: 004 | loss: 0.69278 - acc: 0.5119 | val_loss: 0.69325 - val_acc: 0.4833 -- iter: 384/384
--
Training Step: 49  | total loss: [1m[32m0.69306[0m[0m | time: 0.604s
[2K
| Adam | epoch: 005 | loss: 0.69306 - acc: 0.5001 -- iter: 032/384
[A[ATraining Step: 50  | total loss: [1m[32m0.69302[0m[0m | time: 1.243s
[2K
| Adam | epoch: 005 | loss: 0.69302 - acc: 0.5001 -- iter: 064/384
[A[ATraining Step: 51  | total loss: [1m[32m0.69317[0m[0m | time: 1.837s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.4906 -- iter: 096/384
[A[ATraining Step: 52  | total loss: [1m[32m0.69291[0m[0m | time: 2.453s
[2K
| Adam | epoch: 005 | loss: 0.69291 - acc: 0.5060 -- iter: 128/384
[A[ATraining Step: 53  | total loss: [1m[32m0.69265[0m[0m | time: 3.048s
[2K
| Adam | epoch: 005 | loss: 0.69265 - acc: 0.5190 -- iter: 160/384
[A[ATraining Step: 54  | total loss: [1m[32m0.69236[0m[0m | time: 3.651s
[2K
| Adam | epoch: 005 | loss: 0.69236 - acc: 0.5344 -- iter: 192/384
[A[ATraining Step: 55  | total loss: [1m[32m0.69274[0m[0m | time: 4.289s
[2K
| Adam | epoch: 005 | loss: 0.69274 - acc: 0.5116 -- iter: 224/384
[A[ATraining Step: 56  | total loss: [1m[32m0.69295[0m[0m | time: 4.889s
[2K
| Adam | epoch: 005 | loss: 0.69295 - acc: 0.5012 -- iter: 256/384
[A[ATraining Step: 57  | total loss: [1m[32m0.69294[0m[0m | time: 5.493s
[2K
| Adam | epoch: 005 | loss: 0.69294 - acc: 0.5010 -- iter: 288/384
[A[ATraining Step: 58  | total loss: [1m[32m0.69301[0m[0m | time: 6.098s
[2K
| Adam | epoch: 005 | loss: 0.69301 - acc: 0.4966 -- iter: 320/384
[A[ATraining Step: 59  | total loss: [1m[32m0.69295[0m[0m | time: 6.709s
[2K
| Adam | epoch: 005 | loss: 0.69295 - acc: 0.4971 -- iter: 352/384
[A[ATraining Step: 60  | total loss: [1m[32m0.69317[0m[0m | time: 8.315s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.4851 | val_loss: 0.69308 - val_acc: 0.4833 -- iter: 384/384
--
Training Step: 61  | total loss: [1m[32m0.69303[0m[0m | time: 0.609s
[2K
| Adam | epoch: 006 | loss: 0.69303 - acc: 0.4911 -- iter: 032/384
[A[ATraining Step: 62  | total loss: [1m[32m0.69273[0m[0m | time: 1.213s
[2K
| Adam | epoch: 006 | loss: 0.69273 - acc: 0.5043 -- iter: 064/384
[A[ATraining Step: 63  | total loss: [1m[32m0.69292[0m[0m | time: 1.820s
[2K
| Adam | epoch: 006 | loss: 0.69292 - acc: 0.4958 -- iter: 096/384
[A[ATraining Step: 64  | total loss: [1m[32m0.69270[0m[0m | time: 2.423s
[2K
| Adam | epoch: 006 | loss: 0.69270 - acc: 0.5042 -- iter: 128/384
[A[ATraining Step: 65  | total loss: [1m[32m0.69292[0m[0m | time: 3.028s
[2K
| Adam | epoch: 006 | loss: 0.69292 - acc: 0.4882 -- iter: 160/384
[A[ATraining Step: 66  | total loss: [1m[32m0.69309[0m[0m | time: 3.624s
[2K
| Adam | epoch: 006 | loss: 0.69309 - acc: 0.4745 -- iter: 192/384
[A[ATraining Step: 67  | total loss: [1m[32m0.69323[0m[0m | time: 4.224s
[2K
| Adam | epoch: 006 | loss: 0.69323 - acc: 0.4663 -- iter: 224/384
[A[ATraining Step: 68  | total loss: [1m[32m0.69305[0m[0m | time: 4.827s
[2K
| Adam | epoch: 006 | loss: 0.69305 - acc: 0.4777 -- iter: 256/384
[A[ATraining Step: 69  | total loss: [1m[32m0.69288[0m[0m | time: 5.439s
[2K
| Adam | epoch: 006 | loss: 0.69288 - acc: 0.4949 -- iter: 288/384
[A[ATraining Step: 70  | total loss: [1m[32m0.69279[0m[0m | time: 6.059s
[2K
| Adam | epoch: 006 | loss: 0.69279 - acc: 0.5063 -- iter: 320/384
[A[ATraining Step: 71  | total loss: [1m[32m0.69283[0m[0m | time: 6.672s
[2K
| Adam | epoch: 006 | loss: 0.69283 - acc: 0.4985 -- iter: 352/384
[A[ATraining Step: 72  | total loss: [1m[32m0.69272[0m[0m | time: 8.285s
[2K
| Adam | epoch: 006 | loss: 0.69272 - acc: 0.4986 | val_loss: 0.69282 - val_acc: 0.4833 -- iter: 384/384
--
Training Step: 73  | total loss: [1m[32m0.69271[0m[0m | time: 0.606s
[2K
| Adam | epoch: 007 | loss: 0.69271 - acc: 0.4988 -- iter: 032/384
[A[ATraining Step: 74  | total loss: [1m[32m0.69235[0m[0m | time: 1.208s
[2K
| Adam | epoch: 007 | loss: 0.69235 - acc: 0.5195 -- iter: 064/384
[A[ATraining Step: 75  | total loss: [1m[32m0.69182[0m[0m | time: 1.810s
[2K
| Adam | epoch: 007 | loss: 0.69182 - acc: 0.5479 -- iter: 096/384
[A[ATraining Step: 76  | total loss: [1m[32m0.69196[0m[0m | time: 2.414s
[2K
| Adam | epoch: 007 | loss: 0.69196 - acc: 0.5427 -- iter: 128/384
[A[ATraining Step: 77  | total loss: [1m[32m0.69217[0m[0m | time: 3.026s
[2K
| Adam | epoch: 007 | loss: 0.69217 - acc: 0.5349 -- iter: 160/384
[A[ATraining Step: 78  | total loss: [1m[32m0.69301[0m[0m | time: 3.641s
[2K
| Adam | epoch: 007 | loss: 0.69301 - acc: 0.5116 -- iter: 192/384
[A[ATraining Step: 79  | total loss: [1m[32m0.69379[0m[0m | time: 4.241s
[2K
| Adam | epoch: 007 | loss: 0.69379 - acc: 0.4910 -- iter: 224/384
[A[ATraining Step: 80  | total loss: [1m[32m0.69441[0m[0m | time: 4.842s
[2K
| Adam | epoch: 007 | loss: 0.69441 - acc: 0.4728 -- iter: 256/384
[A[ATraining Step: 81  | total loss: [1m[32m0.69399[0m[0m | time: 5.426s
[2K
| Adam | epoch: 007 | loss: 0.69399 - acc: 0.4819 -- iter: 288/384
[A[ATraining Step: 82  | total loss: [1m[32m0.69381[0m[0m | time: 6.040s
[2K
| Adam | epoch: 007 | loss: 0.69381 - acc: 0.4868 -- iter: 320/384
[A[ATraining Step: 83  | total loss: [1m[32m0.69410[0m[0m | time: 6.645s
[2K
| Adam | epoch: 007 | loss: 0.69410 - acc: 0.4725 -- iter: 352/384
[A[ATraining Step: 84  | total loss: [1m[32m0.69384[0m[0m | time: 8.246s
[2K
| Adam | epoch: 007 | loss: 0.69384 - acc: 0.4784 | val_loss: 0.69280 - val_acc: 0.4833 -- iter: 384/384
--
Training Step: 85  | total loss: [1m[32m0.69373[0m[0m | time: 0.610s
[2K
| Adam | epoch: 008 | loss: 0.69373 - acc: 0.4805 -- iter: 032/384
[A[ATraining Step: 86  | total loss: [1m[32m0.69368[0m[0m | time: 1.242s
[2K
| Adam | epoch: 008 | loss: 0.69368 - acc: 0.4762 -- iter: 064/384
[A[ATraining Step: 87  | total loss: [1m[32m0.69354[0m[0m | time: 1.842s
[2K
| Adam | epoch: 008 | loss: 0.69354 - acc: 0.4849 -- iter: 096/384
[A[ATraining Step: 88  | total loss: [1m[32m0.69338[0m[0m | time: 2.449s
[2K
| Adam | epoch: 008 | loss: 0.69338 - acc: 0.4926 -- iter: 128/384
[A[ATraining Step: 89  | total loss: [1m[32m0.69326[0m[0m | time: 3.054s
[2K
| Adam | epoch: 008 | loss: 0.69326 - acc: 0.4965 -- iter: 160/384
[A[ATraining Step: 90  | total loss: [1m[32m0.69313[0m[0m | time: 3.670s
[2K
| Adam | epoch: 008 | loss: 0.69313 - acc: 0.4968 -- iter: 192/384
[A[ATraining Step: 91  | total loss: [1m[32m0.69297[0m[0m | time: 4.284s
[2K
| Adam | epoch: 008 | loss: 0.69297 - acc: 0.5128 -- iter: 224/384
[A[ATraining Step: 92  | total loss: [1m[32m0.69282[0m[0m | time: 4.880s
[2K
| Adam | epoch: 008 | loss: 0.69282 - acc: 0.5209 -- iter: 256/384
[A[ATraining Step: 93  | total loss: [1m[32m0.69290[0m[0m | time: 5.484s
[2K
| Adam | epoch: 008 | loss: 0.69290 - acc: 0.5032 -- iter: 288/384
[A[ATraining Step: 94  | total loss: [1m[32m0.69284[0m[0m | time: 6.091s
[2K
| Adam | epoch: 008 | loss: 0.69284 - acc: 0.5028 -- iter: 320/384
[A[ATraining Step: 95  | total loss: [1m[32m0.69272[0m[0m | time: 6.704s
[2K
| Adam | epoch: 008 | loss: 0.69272 - acc: 0.5088 -- iter: 352/384
[A[ATraining Step: 96  | total loss: [1m[32m0.69266[0m[0m | time: 8.317s
[2K
| Adam | epoch: 008 | loss: 0.69266 - acc: 0.5048 | val_loss: 0.69206 - val_acc: 0.5417 -- iter: 384/384
--
Training Step: 97  | total loss: [1m[32m0.69262[0m[0m | time: 0.613s
[2K
| Adam | epoch: 009 | loss: 0.69262 - acc: 0.5043 -- iter: 032/384
[A[ATraining Step: 98  | total loss: [1m[32m0.69259[0m[0m | time: 1.216s
[2K
| Adam | epoch: 009 | loss: 0.69259 - acc: 0.5039 -- iter: 064/384
[A[ATraining Step: 99  | total loss: [1m[32m0.69248[0m[0m | time: 1.850s
[2K
| Adam | epoch: 009 | loss: 0.69248 - acc: 0.5285 -- iter: 096/384
[A[ATraining Step: 100  | total loss: [1m[32m0.69238[0m[0m | time: 2.449s
[2K
| Adam | epoch: 009 | loss: 0.69238 - acc: 0.5413 -- iter: 128/384
[A[ATraining Step: 101  | total loss: [1m[32m0.69230[0m[0m | time: 3.095s
[2K
| Adam | epoch: 009 | loss: 0.69230 - acc: 0.5559 -- iter: 160/384
[A[ATraining Step: 102  | total loss: [1m[32m0.69219[0m[0m | time: 3.694s
[2K
| Adam | epoch: 009 | loss: 0.69219 - acc: 0.5847 -- iter: 192/384
[A[ATraining Step: 103  | total loss: [1m[32m0.69219[0m[0m | time: 4.326s
[2K
| Adam | epoch: 009 | loss: 0.69219 - acc: 0.5762 -- iter: 224/384
[A[ATraining Step: 104  | total loss: [1m[32m0.69211[0m[0m | time: 4.956s
[2K
| Adam | epoch: 009 | loss: 0.69211 - acc: 0.5842 -- iter: 256/384
[A[ATraining Step: 105  | total loss: [1m[32m0.69191[0m[0m | time: 5.552s
[2K
| Adam | epoch: 009 | loss: 0.69191 - acc: 0.5977 -- iter: 288/384
[A[ATraining Step: 106  | total loss: [1m[32m0.69163[0m[0m | time: 6.153s
[2K
| Adam | epoch: 009 | loss: 0.69163 - acc: 0.6098 -- iter: 320/384
[A[ATraining Step: 107  | total loss: [1m[32m0.69171[0m[0m | time: 6.767s
[2K
| Adam | epoch: 009 | loss: 0.69171 - acc: 0.5926 -- iter: 352/384
[A[ATraining Step: 108  | total loss: [1m[32m0.69135[0m[0m | time: 8.409s
[2K
| Adam | epoch: 009 | loss: 0.69135 - acc: 0.5958 | val_loss: 0.69189 - val_acc: 0.4833 -- iter: 384/384
--
Training Step: 109  | total loss: [1m[32m0.69140[0m[0m | time: 0.627s
[2K
| Adam | epoch: 010 | loss: 0.69140 - acc: 0.5831 -- iter: 032/384
[A[ATraining Step: 110  | total loss: [1m[32m0.69172[0m[0m | time: 1.225s
[2K
| Adam | epoch: 010 | loss: 0.69172 - acc: 0.5623 -- iter: 064/384
[A[ATraining Step: 111  | total loss: [1m[32m0.69176[0m[0m | time: 1.832s
[2K
| Adam | epoch: 010 | loss: 0.69176 - acc: 0.5498 -- iter: 096/384
[A[ATraining Step: 112  | total loss: [1m[32m0.69173[0m[0m | time: 2.434s
[2K
| Adam | epoch: 010 | loss: 0.69173 - acc: 0.5448 -- iter: 128/384
[A[ATraining Step: 113  | total loss: [1m[32m0.69146[0m[0m | time: 3.038s
[2K
| Adam | epoch: 010 | loss: 0.69146 - acc: 0.5747 -- iter: 160/384
[A[ATraining Step: 114  | total loss: [1m[32m0.69119[0m[0m | time: 3.639s
[2K
| Adam | epoch: 010 | loss: 0.69119 - acc: 0.5766 -- iter: 192/384
[A[ATraining Step: 115  | total loss: [1m[32m0.69163[0m[0m | time: 4.253s
[2K
| Adam | epoch: 010 | loss: 0.69163 - acc: 0.5471 -- iter: 224/384
[A[ATraining Step: 116  | total loss: [1m[32m0.69183[0m[0m | time: 4.882s
[2K
| Adam | epoch: 010 | loss: 0.69183 - acc: 0.5267 -- iter: 256/384
[A[ATraining Step: 117  | total loss: [1m[32m0.69164[0m[0m | time: 5.476s
[2K
| Adam | epoch: 010 | loss: 0.69164 - acc: 0.5366 -- iter: 288/384
[A[ATraining Step: 118  | total loss: [1m[32m0.69134[0m[0m | time: 6.076s
[2K
| Adam | epoch: 010 | loss: 0.69134 - acc: 0.5610 -- iter: 320/384
[A[ATraining Step: 119  | total loss: [1m[32m0.69103[0m[0m | time: 6.677s
[2K
| Adam | epoch: 010 | loss: 0.69103 - acc: 0.5893 -- iter: 352/384
[A[ATraining Step: 120  | total loss: [1m[32m0.69094[0m[0m | time: 8.306s
[2K
| Adam | epoch: 010 | loss: 0.69094 - acc: 0.5898 | val_loss: 0.68872 - val_acc: 0.6083 -- iter: 384/384
--
Training Step: 121  | total loss: [1m[32m0.69080[0m[0m | time: 0.629s
[2K
| Adam | epoch: 011 | loss: 0.69080 - acc: 0.5933 -- iter: 032/384
[A[ATraining Step: 122  | total loss: [1m[32m0.69070[0m[0m | time: 1.244s
[2K
| Adam | epoch: 011 | loss: 0.69070 - acc: 0.5965 -- iter: 064/384
[A[ATraining Step: 123  | total loss: [1m[32m0.69044[0m[0m | time: 1.854s
[2K
| Adam | epoch: 011 | loss: 0.69044 - acc: 0.6087 -- iter: 096/384
[A[ATraining Step: 124  | total loss: [1m[32m0.69010[0m[0m | time: 2.460s
[2K
| Adam | epoch: 011 | loss: 0.69010 - acc: 0.6259 -- iter: 128/384
[A[ATraining Step: 125  | total loss: [1m[32m0.68977[0m[0m | time: 3.064s
[2K
| Adam | epoch: 011 | loss: 0.68977 - acc: 0.6352 -- iter: 160/384
[A[ATraining Step: 126  | total loss: [1m[32m0.68930[0m[0m | time: 3.695s
[2K
| Adam | epoch: 011 | loss: 0.68930 - acc: 0.6467 -- iter: 192/384
[A[ATraining Step: 127  | total loss: [1m[32m0.68897[0m[0m | time: 4.320s
[2K
| Adam | epoch: 011 | loss: 0.68897 - acc: 0.6508 -- iter: 224/384
[A[ATraining Step: 128  | total loss: [1m[32m0.68860[0m[0m | time: 4.942s
[2K
| Adam | epoch: 011 | loss: 0.68860 - acc: 0.6545 -- iter: 256/384
[A[ATraining Step: 129  | total loss: [1m[32m0.68799[0m[0m | time: 5.542s
[2K
| Adam | epoch: 011 | loss: 0.68799 - acc: 0.6765 -- iter: 288/384
[A[ATraining Step: 130  | total loss: [1m[32m0.68790[0m[0m | time: 6.154s
[2K
| Adam | epoch: 011 | loss: 0.68790 - acc: 0.6776 -- iter: 320/384
[A[ATraining Step: 131  | total loss: [1m[32m0.68768[0m[0m | time: 6.755s
[2K
| Adam | epoch: 011 | loss: 0.68768 - acc: 0.6755 -- iter: 352/384
[A[ATraining Step: 132  | total loss: [1m[32m0.68714[0m[0m | time: 8.380s
[2K
| Adam | epoch: 011 | loss: 0.68714 - acc: 0.6829 | val_loss: 0.68247 - val_acc: 0.7250 -- iter: 384/384
--
Training Step: 133  | total loss: [1m[32m0.68719[0m[0m | time: 0.607s
[2K
| Adam | epoch: 012 | loss: 0.68719 - acc: 0.6646 -- iter: 032/384
[A[ATraining Step: 134  | total loss: [1m[32m0.68628[0m[0m | time: 1.205s
[2K
| Adam | epoch: 012 | loss: 0.68628 - acc: 0.6700 -- iter: 064/384
[A[ATraining Step: 135  | total loss: [1m[32m0.68586[0m[0m | time: 1.811s
[2K
| Adam | epoch: 012 | loss: 0.68586 - acc: 0.6718 -- iter: 096/384
[A[ATraining Step: 136  | total loss: [1m[32m0.68533[0m[0m | time: 2.414s
[2K
| Adam | epoch: 012 | loss: 0.68533 - acc: 0.6765 -- iter: 128/384
[A[ATraining Step: 137  | total loss: [1m[32m0.68479[0m[0m | time: 3.018s
[2K
| Adam | epoch: 012 | loss: 0.68479 - acc: 0.6870 -- iter: 160/384
[A[ATraining Step: 138  | total loss: [1m[32m0.68446[0m[0m | time: 3.634s
[2K
| Adam | epoch: 012 | loss: 0.68446 - acc: 0.6870 -- iter: 192/384
[A[ATraining Step: 139  | total loss: [1m[32m0.68360[0m[0m | time: 4.247s
[2K
| Adam | epoch: 012 | loss: 0.68360 - acc: 0.6871 -- iter: 224/384
[A[ATraining Step: 140  | total loss: [1m[32m0.68185[0m[0m | time: 4.845s
[2K
| Adam | epoch: 012 | loss: 0.68185 - acc: 0.6902 -- iter: 256/384
[A[ATraining Step: 141  | total loss: [1m[32m0.68279[0m[0m | time: 5.480s
[2K
| Adam | epoch: 012 | loss: 0.68279 - acc: 0.6618 -- iter: 288/384
[A[ATraining Step: 142  | total loss: [1m[32m0.68243[0m[0m | time: 6.093s
[2K
| Adam | epoch: 012 | loss: 0.68243 - acc: 0.6550 -- iter: 320/384
[A[ATraining Step: 143  | total loss: [1m[32m0.68074[0m[0m | time: 6.699s
[2K
| Adam | epoch: 012 | loss: 0.68074 - acc: 0.6645 -- iter: 352/384
[A[ATraining Step: 144  | total loss: [1m[32m0.67907[0m[0m | time: 8.331s
[2K
| Adam | epoch: 012 | loss: 0.67907 - acc: 0.6793 | val_loss: 0.66960 - val_acc: 0.6750 -- iter: 384/384
--
Training Step: 145  | total loss: [1m[32m0.67812[0m[0m | time: 0.641s
[2K
| Adam | epoch: 013 | loss: 0.67812 - acc: 0.6770 -- iter: 032/384
[A[ATraining Step: 146  | total loss: [1m[32m0.67680[0m[0m | time: 1.268s
[2K
| Adam | epoch: 013 | loss: 0.67680 - acc: 0.6874 -- iter: 064/384
[A[ATraining Step: 147  | total loss: [1m[32m0.67546[0m[0m | time: 1.887s
[2K
| Adam | epoch: 013 | loss: 0.67546 - acc: 0.6812 -- iter: 096/384
[A[ATraining Step: 148  | total loss: [1m[32m0.67678[0m[0m | time: 2.497s
[2K
| Adam | epoch: 013 | loss: 0.67678 - acc: 0.6599 -- iter: 128/384
[A[ATraining Step: 149  | total loss: [1m[32m0.67493[0m[0m | time: 3.112s
[2K
| Adam | epoch: 013 | loss: 0.67493 - acc: 0.6596 -- iter: 160/384
[A[ATraining Step: 150  | total loss: [1m[32m0.67400[0m[0m | time: 3.703s
[2K
| Adam | epoch: 013 | loss: 0.67400 - acc: 0.6624 -- iter: 192/384
[A[ATraining Step: 151  | total loss: [1m[32m0.67172[0m[0m | time: 4.302s
[2K
| Adam | epoch: 013 | loss: 0.67172 - acc: 0.6680 -- iter: 224/384
[A[ATraining Step: 152  | total loss: [1m[32m0.67046[0m[0m | time: 4.897s
[2K
| Adam | epoch: 013 | loss: 0.67046 - acc: 0.6731 -- iter: 256/384
[A[ATraining Step: 153  | total loss: [1m[32m0.66725[0m[0m | time: 5.503s
[2K
| Adam | epoch: 013 | loss: 0.66725 - acc: 0.6776 -- iter: 288/384
[A[ATraining Step: 154  | total loss: [1m[32m0.66427[0m[0m | time: 6.118s
[2K
| Adam | epoch: 013 | loss: 0.66427 - acc: 0.6880 -- iter: 320/384
[A[ATraining Step: 155  | total loss: [1m[32m0.66462[0m[0m | time: 6.740s
[2K
| Adam | epoch: 013 | loss: 0.66462 - acc: 0.6817 -- iter: 352/384
[A[ATraining Step: 156  | total loss: [1m[32m0.66251[0m[0m | time: 8.367s
[2K
| Adam | epoch: 013 | loss: 0.66251 - acc: 0.6917 | val_loss: 0.65728 - val_acc: 0.5833 -- iter: 384/384
--
Training Step: 157  | total loss: [1m[32m0.65977[0m[0m | time: 0.630s
[2K
| Adam | epoch: 014 | loss: 0.65977 - acc: 0.6975 -- iter: 032/384
[A[ATraining Step: 158  | total loss: [1m[32m0.65923[0m[0m | time: 1.231s
[2K
| Adam | epoch: 014 | loss: 0.65923 - acc: 0.6902 -- iter: 064/384
[A[ATraining Step: 159  | total loss: [1m[32m0.65764[0m[0m | time: 1.832s
[2K
| Adam | epoch: 014 | loss: 0.65764 - acc: 0.6868 -- iter: 096/384
[A[ATraining Step: 160  | total loss: [1m[32m0.65652[0m[0m | time: 2.454s
[2K
| Adam | epoch: 014 | loss: 0.65652 - acc: 0.6838 -- iter: 128/384
[A[ATraining Step: 161  | total loss: [1m[32m0.65749[0m[0m | time: 3.068s
[2K
| Adam | epoch: 014 | loss: 0.65749 - acc: 0.6779 -- iter: 160/384
[A[ATraining Step: 162  | total loss: [1m[32m0.65548[0m[0m | time: 3.688s
[2K
| Adam | epoch: 014 | loss: 0.65548 - acc: 0.6757 -- iter: 192/384
[A[ATraining Step: 163  | total loss: [1m[32m0.65023[0m[0m | time: 4.309s
[2K
| Adam | epoch: 014 | loss: 0.65023 - acc: 0.6832 -- iter: 224/384
[A[ATraining Step: 164  | total loss: [1m[32m0.64802[0m[0m | time: 4.912s
[2K
| Adam | epoch: 014 | loss: 0.64802 - acc: 0.6774 -- iter: 256/384
[A[ATraining Step: 165  | total loss: [1m[32m0.64425[0m[0m | time: 5.510s
[2K
| Adam | epoch: 014 | loss: 0.64425 - acc: 0.6752 -- iter: 288/384
[A[ATraining Step: 166  | total loss: [1m[32m0.64132[0m[0m | time: 6.125s
[2K
| Adam | epoch: 014 | loss: 0.64132 - acc: 0.6796 -- iter: 320/384
[A[ATraining Step: 167  | total loss: [1m[32m0.63958[0m[0m | time: 6.718s
[2K
| Adam | epoch: 014 | loss: 0.63958 - acc: 0.6866 -- iter: 352/384
[A[ATraining Step: 168  | total loss: [1m[32m0.63015[0m[0m | time: 8.345s
[2K
| Adam | epoch: 014 | loss: 0.63015 - acc: 0.7023 | val_loss: 0.60829 - val_acc: 0.6417 -- iter: 384/384
--
Training Step: 169  | total loss: [1m[32m0.63586[0m[0m | time: 0.638s
[2K
| Adam | epoch: 015 | loss: 0.63586 - acc: 0.6790 -- iter: 032/384
[A[ATraining Step: 170  | total loss: [1m[32m0.63775[0m[0m | time: 1.241s
[2K
| Adam | epoch: 015 | loss: 0.63775 - acc: 0.6798 -- iter: 064/384
[A[ATraining Step: 171  | total loss: [1m[32m0.63417[0m[0m | time: 1.846s
[2K
| Adam | epoch: 015 | loss: 0.63417 - acc: 0.6806 -- iter: 096/384
[A[ATraining Step: 172  | total loss: [1m[32m0.63419[0m[0m | time: 2.457s
[2K
| Adam | epoch: 015 | loss: 0.63419 - acc: 0.6782 -- iter: 128/384
[A[ATraining Step: 173  | total loss: [1m[32m0.63121[0m[0m | time: 3.092s
[2K
| Adam | epoch: 015 | loss: 0.63121 - acc: 0.6791 -- iter: 160/384
[A[ATraining Step: 174  | total loss: [1m[32m0.62800[0m[0m | time: 3.705s
[2K
| Adam | epoch: 015 | loss: 0.62800 - acc: 0.6831 -- iter: 192/384
[A[ATraining Step: 175  | total loss: [1m[32m0.61926[0m[0m | time: 4.306s
[2K
| Adam | epoch: 015 | loss: 0.61926 - acc: 0.6929 -- iter: 224/384
[A[ATraining Step: 176  | total loss: [1m[32m0.62675[0m[0m | time: 4.909s
[2K
| Adam | epoch: 015 | loss: 0.62675 - acc: 0.6767 -- iter: 256/384
[A[ATraining Step: 177  | total loss: [1m[32m0.62220[0m[0m | time: 5.821s
[2K
| Adam | epoch: 015 | loss: 0.62220 - acc: 0.6778 -- iter: 288/384
[A[ATraining Step: 178  | total loss: [1m[32m0.61595[0m[0m | time: 6.813s
[2K
| Adam | epoch: 015 | loss: 0.61595 - acc: 0.6788 -- iter: 320/384
[A[ATraining Step: 179  | total loss: [1m[32m0.61949[0m[0m | time: 7.877s
[2K
| Adam | epoch: 015 | loss: 0.61949 - acc: 0.6609 -- iter: 352/384
[A[ATraining Step: 180  | total loss: [1m[32m0.62851[0m[0m | time: 9.726s
[2K
| Adam | epoch: 015 | loss: 0.62851 - acc: 0.6448 | val_loss: 0.58709 - val_acc: 0.6500 -- iter: 384/384
--
Training Step: 181  | total loss: [1m[32m0.62527[0m[0m | time: 1.164s
[2K
| Adam | epoch: 016 | loss: 0.62527 - acc: 0.6459 -- iter: 032/384
[A[ATraining Step: 182  | total loss: [1m[32m0.61821[0m[0m | time: 2.050s
[2K
| Adam | epoch: 016 | loss: 0.61821 - acc: 0.6470 -- iter: 064/384
[A[ATraining Step: 183  | total loss: [1m[32m0.60884[0m[0m | time: 2.688s
[2K
| Adam | epoch: 016 | loss: 0.60884 - acc: 0.6667 -- iter: 096/384
[A[ATraining Step: 184  | total loss: [1m[32m0.59667[0m[0m | time: 3.331s
[2K
| Adam | epoch: 016 | loss: 0.59667 - acc: 0.6844 -- iter: 128/384
[A[ATraining Step: 185  | total loss: [1m[32m0.59141[0m[0m | time: 4.431s
[2K
| Adam | epoch: 016 | loss: 0.59141 - acc: 0.6909 -- iter: 160/384
[A[ATraining Step: 186  | total loss: [1m[32m0.59769[0m[0m | time: 5.512s
[2K
| Adam | epoch: 016 | loss: 0.59769 - acc: 0.6843 -- iter: 192/384
[A[ATraining Step: 187  | total loss: [1m[32m0.60040[0m[0m | time: 6.495s
[2K
| Adam | epoch: 016 | loss: 0.60040 - acc: 0.6847 -- iter: 224/384
[A[ATraining Step: 188  | total loss: [1m[32m0.59870[0m[0m | time: 7.521s
[2K
| Adam | epoch: 016 | loss: 0.59870 - acc: 0.6881 -- iter: 256/384
[A[ATraining Step: 189  | total loss: [1m[32m0.60392[0m[0m | time: 8.450s
[2K
| Adam | epoch: 016 | loss: 0.60392 - acc: 0.6724 -- iter: 288/384
[A[ATraining Step: 190  | total loss: [1m[32m0.59691[0m[0m | time: 9.420s
[2K
| Adam | epoch: 016 | loss: 0.59691 - acc: 0.6770 -- iter: 320/384
[A[ATraining Step: 191  | total loss: [1m[32m0.59021[0m[0m | time: 10.410s
[2K
| Adam | epoch: 016 | loss: 0.59021 - acc: 0.6906 -- iter: 352/384
[A[ATraining Step: 192  | total loss: [1m[32m0.58823[0m[0m | time: 12.521s
[2K
| Adam | epoch: 016 | loss: 0.58823 - acc: 0.6996 | val_loss: 0.56207 - val_acc: 0.7083 -- iter: 384/384
--
Training Step: 193  | total loss: [1m[32m0.58093[0m[0m | time: 0.938s
[2K
| Adam | epoch: 017 | loss: 0.58093 - acc: 0.7140 -- iter: 032/384
[A[ATraining Step: 194  | total loss: [1m[32m0.59615[0m[0m | time: 1.939s
[2K
| Adam | epoch: 017 | loss: 0.59615 - acc: 0.6926 -- iter: 064/384
[A[ATraining Step: 195  | total loss: [1m[32m0.58568[0m[0m | time: 2.903s
[2K
| Adam | epoch: 017 | loss: 0.58568 - acc: 0.7078 -- iter: 096/384
[A[ATraining Step: 196  | total loss: [1m[32m0.57537[0m[0m | time: 3.982s
[2K
| Adam | epoch: 017 | loss: 0.57537 - acc: 0.7182 -- iter: 128/384
[A[ATraining Step: 197  | total loss: [1m[32m0.56675[0m[0m | time: 5.087s
[2K
| Adam | epoch: 017 | loss: 0.56675 - acc: 0.7277 -- iter: 160/384
[A[ATraining Step: 198  | total loss: [1m[32m0.55746[0m[0m | time: 5.946s
[2K
| Adam | epoch: 017 | loss: 0.55746 - acc: 0.7393 -- iter: 192/384
[A[ATraining Step: 199  | total loss: [1m[32m0.55139[0m[0m | time: 7.037s
[2K
| Adam | epoch: 017 | loss: 0.55139 - acc: 0.7497 -- iter: 224/384
[A[ATraining Step: 200  | total loss: [1m[32m0.54630[0m[0m | time: 9.069s
[2K
| Adam | epoch: 017 | loss: 0.54630 - acc: 0.7591 | val_loss: 0.51099 - val_acc: 0.8000 -- iter: 256/384
--
Training Step: 201  | total loss: [1m[32m0.53366[0m[0m | time: 10.207s
[2K
| Adam | epoch: 017 | loss: 0.53366 - acc: 0.7707 -- iter: 288/384
[A[ATraining Step: 202  | total loss: [1m[32m0.52929[0m[0m | time: 11.223s
[2K
| Adam | epoch: 017 | loss: 0.52929 - acc: 0.7686 -- iter: 320/384
[A[ATraining Step: 203  | total loss: [1m[32m0.53784[0m[0m | time: 12.064s
[2K
| Adam | epoch: 017 | loss: 0.53784 - acc: 0.7543 -- iter: 352/384
[A[ATraining Step: 204  | total loss: [1m[32m0.52733[0m[0m | time: 14.196s
[2K
| Adam | epoch: 017 | loss: 0.52733 - acc: 0.7601 | val_loss: 0.53652 - val_acc: 0.7000 -- iter: 384/384
--
Training Step: 205  | total loss: [1m[32m0.52896[0m[0m | time: 0.950s
[2K
| Adam | epoch: 018 | loss: 0.52896 - acc: 0.7591 -- iter: 032/384
[A[ATraining Step: 206  | total loss: [1m[32m0.52826[0m[0m | time: 2.038s
[2K
| Adam | epoch: 018 | loss: 0.52826 - acc: 0.7644 -- iter: 064/384
[A[ATraining Step: 207  | total loss: [1m[32m0.52021[0m[0m | time: 3.027s
[2K
| Adam | epoch: 018 | loss: 0.52021 - acc: 0.7724 -- iter: 096/384
[A[ATraining Step: 208  | total loss: [1m[32m0.51290[0m[0m | time: 4.035s
[2K
| Adam | epoch: 018 | loss: 0.51290 - acc: 0.7732 -- iter: 128/384
[A[ATraining Step: 209  | total loss: [1m[32m0.50643[0m[0m | time: 5.082s
[2K
| Adam | epoch: 018 | loss: 0.50643 - acc: 0.7803 -- iter: 160/384
[A[ATraining Step: 210  | total loss: [1m[32m0.49838[0m[0m | time: 6.202s
[2K
| Adam | epoch: 018 | loss: 0.49838 - acc: 0.7773 -- iter: 192/384
[A[ATraining Step: 211  | total loss: [1m[32m0.49071[0m[0m | time: 7.200s
[2K
| Adam | epoch: 018 | loss: 0.49071 - acc: 0.7808 -- iter: 224/384
[A[ATraining Step: 212  | total loss: [1m[32m0.49837[0m[0m | time: 8.148s
[2K
| Adam | epoch: 018 | loss: 0.49837 - acc: 0.7777 -- iter: 256/384
[A[ATraining Step: 213  | total loss: [1m[32m0.49290[0m[0m | time: 9.126s
[2K
| Adam | epoch: 018 | loss: 0.49290 - acc: 0.7656 -- iter: 288/384
[A[ATraining Step: 214  | total loss: [1m[32m0.48393[0m[0m | time: 10.081s
[2K
| Adam | epoch: 018 | loss: 0.48393 - acc: 0.7796 -- iter: 320/384
[A[ATraining Step: 215  | total loss: [1m[32m0.50169[0m[0m | time: 11.176s
[2K
| Adam | epoch: 018 | loss: 0.50169 - acc: 0.7673 -- iter: 352/384
[A[ATraining Step: 216  | total loss: [1m[32m0.50623[0m[0m | time: 13.265s
[2K
| Adam | epoch: 018 | loss: 0.50623 - acc: 0.7687 | val_loss: 0.53550 - val_acc: 0.6500 -- iter: 384/384
--
Training Step: 217  | total loss: [1m[32m0.50649[0m[0m | time: 0.970s
[2K
| Adam | epoch: 019 | loss: 0.50649 - acc: 0.7543 -- iter: 032/384
[A[ATraining Step: 218  | total loss: [1m[32m0.49688[0m[0m | time: 1.829s
[2K
| Adam | epoch: 019 | loss: 0.49688 - acc: 0.7633 -- iter: 064/384
[A[ATraining Step: 219  | total loss: [1m[32m0.49267[0m[0m | time: 2.770s
[2K
| Adam | epoch: 019 | loss: 0.49267 - acc: 0.7713 -- iter: 096/384
[A[ATraining Step: 220  | total loss: [1m[32m0.47445[0m[0m | time: 3.748s
[2K
| Adam | epoch: 019 | loss: 0.47445 - acc: 0.7848 -- iter: 128/384
[A[ATraining Step: 221  | total loss: [1m[32m0.46701[0m[0m | time: 4.723s
[2K
| Adam | epoch: 019 | loss: 0.46701 - acc: 0.7938 -- iter: 160/384
[A[ATraining Step: 222  | total loss: [1m[32m0.46072[0m[0m | time: 5.824s
[2K
| Adam | epoch: 019 | loss: 0.46072 - acc: 0.7988 -- iter: 192/384
[A[ATraining Step: 223  | total loss: [1m[32m0.44751[0m[0m | time: 6.929s
[2K
| Adam | epoch: 019 | loss: 0.44751 - acc: 0.8033 -- iter: 224/384
[A[ATraining Step: 224  | total loss: [1m[32m0.45503[0m[0m | time: 7.771s
[2K
| Adam | epoch: 019 | loss: 0.45503 - acc: 0.7980 -- iter: 256/384
[A[ATraining Step: 225  | total loss: [1m[32m0.44265[0m[0m | time: 8.850s
[2K
| Adam | epoch: 019 | loss: 0.44265 - acc: 0.8057 -- iter: 288/384
[A[ATraining Step: 226  | total loss: [1m[32m0.44461[0m[0m | time: 9.945s
[2K
| Adam | epoch: 019 | loss: 0.44461 - acc: 0.7970 -- iter: 320/384
[A[ATraining Step: 227  | total loss: [1m[32m0.45923[0m[0m | time: 11.037s
[2K
| Adam | epoch: 019 | loss: 0.45923 - acc: 0.7798 -- iter: 352/384
[A[ATraining Step: 228  | total loss: [1m[32m0.46624[0m[0m | time: 12.892s
[2K
| Adam | epoch: 019 | loss: 0.46624 - acc: 0.7768 | val_loss: 0.46872 - val_acc: 0.7667 -- iter: 384/384
--
Training Step: 229  | total loss: [1m[32m0.45407[0m[0m | time: 1.019s
[2K
| Adam | epoch: 020 | loss: 0.45407 - acc: 0.7804 -- iter: 032/384
[A[ATraining Step: 230  | total loss: [1m[32m0.44734[0m[0m | time: 1.879s
[2K
| Adam | epoch: 020 | loss: 0.44734 - acc: 0.7898 -- iter: 064/384
[A[ATraining Step: 231  | total loss: [1m[32m0.45016[0m[0m | time: 3.017s
[2K
| Adam | epoch: 020 | loss: 0.45016 - acc: 0.7827 -- iter: 096/384
[A[ATraining Step: 232  | total loss: [1m[32m0.44444[0m[0m | time: 4.088s
[2K
| Adam | epoch: 020 | loss: 0.44444 - acc: 0.7951 -- iter: 128/384
[A[ATraining Step: 233  | total loss: [1m[32m0.45293[0m[0m | time: 5.132s
[2K
| Adam | epoch: 020 | loss: 0.45293 - acc: 0.7906 -- iter: 160/384
[A[ATraining Step: 234  | total loss: [1m[32m0.44671[0m[0m | time: 6.066s
[2K
| Adam | epoch: 020 | loss: 0.44671 - acc: 0.7896 -- iter: 192/384
[A[ATraining Step: 235  | total loss: [1m[32m0.44048[0m[0m | time: 7.073s
[2K
| Adam | epoch: 020 | loss: 0.44048 - acc: 0.7919 -- iter: 224/384
[A[ATraining Step: 236  | total loss: [1m[32m0.43436[0m[0m | time: 8.046s
[2K
| Adam | epoch: 020 | loss: 0.43436 - acc: 0.8002 -- iter: 256/384
[A[ATraining Step: 237  | total loss: [1m[32m0.43394[0m[0m | time: 9.083s
[2K
| Adam | epoch: 020 | loss: 0.43394 - acc: 0.8046 -- iter: 288/384
[A[ATraining Step: 238  | total loss: [1m[32m0.42275[0m[0m | time: 10.195s
[2K
| Adam | epoch: 020 | loss: 0.42275 - acc: 0.8148 -- iter: 320/384
[A[ATraining Step: 239  | total loss: [1m[32m0.42155[0m[0m | time: 11.113s
[2K
| Adam | epoch: 020 | loss: 0.42155 - acc: 0.8145 -- iter: 352/384
[A[ATraining Step: 240  | total loss: [1m[32m0.42200[0m[0m | time: 13.005s
[2K
| Adam | epoch: 020 | loss: 0.42200 - acc: 0.8112 | val_loss: 0.42144 - val_acc: 0.8000 -- iter: 384/384
--
Training Step: 241  | total loss: [1m[32m0.44420[0m[0m | time: 1.061s
[2K
| Adam | epoch: 021 | loss: 0.44420 - acc: 0.8051 -- iter: 032/384
[A[ATraining Step: 242  | total loss: [1m[32m0.43459[0m[0m | time: 2.159s
[2K
| Adam | epoch: 021 | loss: 0.43459 - acc: 0.8152 -- iter: 064/384
[A[ATraining Step: 243  | total loss: [1m[32m0.42629[0m[0m | time: 3.023s
[2K
| Adam | epoch: 021 | loss: 0.42629 - acc: 0.8181 -- iter: 096/384
[A[ATraining Step: 244  | total loss: [1m[32m0.40723[0m[0m | time: 4.073s
[2K
| Adam | epoch: 021 | loss: 0.40723 - acc: 0.8300 -- iter: 128/384
[A[ATraining Step: 245  | total loss: [1m[32m0.40594[0m[0m | time: 5.122s
[2K
| Adam | epoch: 021 | loss: 0.40594 - acc: 0.8251 -- iter: 160/384
[A[ATraining Step: 246  | total loss: [1m[32m0.40313[0m[0m | time: 5.959s
[2K
| Adam | epoch: 021 | loss: 0.40313 - acc: 0.8270 -- iter: 192/384
[A[ATraining Step: 247  | total loss: [1m[32m0.40555[0m[0m | time: 6.876s
[2K
| Adam | epoch: 021 | loss: 0.40555 - acc: 0.8224 -- iter: 224/384
[A[ATraining Step: 248  | total loss: [1m[32m0.40859[0m[0m | time: 7.809s
[2K
| Adam | epoch: 021 | loss: 0.40859 - acc: 0.8152 -- iter: 256/384
[A[ATraining Step: 249  | total loss: [1m[32m0.41675[0m[0m | time: 8.800s
[2K
| Adam | epoch: 021 | loss: 0.41675 - acc: 0.8087 -- iter: 288/384
[A[ATraining Step: 250  | total loss: [1m[32m0.40550[0m[0m | time: 9.702s
[2K
| Adam | epoch: 021 | loss: 0.40550 - acc: 0.8153 -- iter: 320/384
[A[ATraining Step: 251  | total loss: [1m[32m0.40596[0m[0m | time: 10.337s
[2K
| Adam | epoch: 021 | loss: 0.40596 - acc: 0.8150 -- iter: 352/384
[A[ATraining Step: 252  | total loss: [1m[32m0.40228[0m[0m | time: 11.970s
[2K
| Adam | epoch: 021 | loss: 0.40228 - acc: 0.8179 | val_loss: 0.43593 - val_acc: 0.8250 -- iter: 384/384
--
Training Step: 253  | total loss: [1m[32m0.41628[0m[0m | time: 1.025s
[2K
| Adam | epoch: 022 | loss: 0.41628 - acc: 0.8080 -- iter: 032/384
[A[ATraining Step: 254  | total loss: [1m[32m0.41189[0m[0m | time: 2.024s
[2K
| Adam | epoch: 022 | loss: 0.41189 - acc: 0.8115 -- iter: 064/384
[A[ATraining Step: 255  | total loss: [1m[32m0.41160[0m[0m | time: 3.021s
[2K
| Adam | epoch: 022 | loss: 0.41160 - acc: 0.8148 -- iter: 096/384
[A[ATraining Step: 256  | total loss: [1m[32m0.42086[0m[0m | time: 4.115s
[2K
| Adam | epoch: 022 | loss: 0.42086 - acc: 0.8083 -- iter: 128/384
[A[ATraining Step: 257  | total loss: [1m[32m0.41566[0m[0m | time: 5.167s
[2K
| Adam | epoch: 022 | loss: 0.41566 - acc: 0.8150 -- iter: 160/384
[A[ATraining Step: 258  | total loss: [1m[32m0.41742[0m[0m | time: 6.004s
[2K
| Adam | epoch: 022 | loss: 0.41742 - acc: 0.8116 -- iter: 192/384
[A[ATraining Step: 259  | total loss: [1m[32m0.41348[0m[0m | time: 6.621s
[2K
| Adam | epoch: 022 | loss: 0.41348 - acc: 0.8179 -- iter: 224/384
[A[ATraining Step: 260  | total loss: [1m[32m0.40944[0m[0m | time: 7.238s
[2K
| Adam | epoch: 022 | loss: 0.40944 - acc: 0.8174 -- iter: 256/384
[A[ATraining Step: 261  | total loss: [1m[32m0.40073[0m[0m | time: 7.854s
[2K
| Adam | epoch: 022 | loss: 0.40073 - acc: 0.8200 -- iter: 288/384
[A[ATraining Step: 262  | total loss: [1m[32m0.39250[0m[0m | time: 8.449s
[2K
| Adam | epoch: 022 | loss: 0.39250 - acc: 0.8224 -- iter: 320/384
[A[ATraining Step: 263  | total loss: [1m[32m0.39163[0m[0m | time: 9.073s
[2K
| Adam | epoch: 022 | loss: 0.39163 - acc: 0.8277 -- iter: 352/384
[A[ATraining Step: 264  | total loss: [1m[32m0.37429[0m[0m | time: 10.671s
[2K
| Adam | epoch: 022 | loss: 0.37429 - acc: 0.8386 | val_loss: 0.39482 - val_acc: 0.8333 -- iter: 384/384
--
Training Step: 265  | total loss: [1m[32m0.38521[0m[0m | time: 0.603s
[2K
| Adam | epoch: 023 | loss: 0.38521 - acc: 0.8329 -- iter: 032/384
[A[ATraining Step: 266  | total loss: [1m[32m0.37883[0m[0m | time: 1.195s
[2K
| Adam | epoch: 023 | loss: 0.37883 - acc: 0.8371 -- iter: 064/384
[A[ATraining Step: 267  | total loss: [1m[32m0.38184[0m[0m | time: 1.813s
[2K
| Adam | epoch: 023 | loss: 0.38184 - acc: 0.8284 -- iter: 096/384
[A[ATraining Step: 268  | total loss: [1m[32m0.38672[0m[0m | time: 2.440s
[2K
| Adam | epoch: 023 | loss: 0.38672 - acc: 0.8206 -- iter: 128/384
[A[ATraining Step: 269  | total loss: [1m[32m0.37993[0m[0m | time: 3.043s
[2K
| Adam | epoch: 023 | loss: 0.37993 - acc: 0.8260 -- iter: 160/384
[A[ATraining Step: 270  | total loss: [1m[32m0.38631[0m[0m | time: 3.649s
[2K
| Adam | epoch: 023 | loss: 0.38631 - acc: 0.8184 -- iter: 192/384
[A[ATraining Step: 271  | total loss: [1m[32m0.38323[0m[0m | time: 4.259s
[2K
| Adam | epoch: 023 | loss: 0.38323 - acc: 0.8209 -- iter: 224/384
[A[ATraining Step: 272  | total loss: [1m[32m0.38020[0m[0m | time: 4.879s
[2K
| Adam | epoch: 023 | loss: 0.38020 - acc: 0.8232 -- iter: 256/384
[A[ATraining Step: 273  | total loss: [1m[32m0.37594[0m[0m | time: 5.494s
[2K
| Adam | epoch: 023 | loss: 0.37594 - acc: 0.8346 -- iter: 288/384
[A[ATraining Step: 274  | total loss: [1m[32m0.37351[0m[0m | time: 6.119s
[2K
| Adam | epoch: 023 | loss: 0.37351 - acc: 0.8387 -- iter: 320/384
[A[ATraining Step: 275  | total loss: [1m[32m0.37026[0m[0m | time: 6.722s
[2K
| Adam | epoch: 023 | loss: 0.37026 - acc: 0.8392 -- iter: 352/384
[A[ATraining Step: 276  | total loss: [1m[32m0.35969[0m[0m | time: 8.346s
[2K
| Adam | epoch: 023 | loss: 0.35969 - acc: 0.8428 | val_loss: 0.38166 - val_acc: 0.8167 -- iter: 384/384
--
Training Step: 277  | total loss: [1m[32m0.36206[0m[0m | time: 0.622s
[2K
| Adam | epoch: 024 | loss: 0.36206 - acc: 0.8366 -- iter: 032/384
[A[ATraining Step: 278  | total loss: [1m[32m0.36842[0m[0m | time: 1.254s
[2K
| Adam | epoch: 024 | loss: 0.36842 - acc: 0.8311 -- iter: 064/384
[A[ATraining Step: 279  | total loss: [1m[32m0.35764[0m[0m | time: 1.864s
[2K
| Adam | epoch: 024 | loss: 0.35764 - acc: 0.8417 -- iter: 096/384
[A[ATraining Step: 280  | total loss: [1m[32m0.34283[0m[0m | time: 2.504s
[2K
| Adam | epoch: 024 | loss: 0.34283 - acc: 0.8544 -- iter: 128/384
[A[ATraining Step: 281  | total loss: [1m[32m0.35328[0m[0m | time: 3.132s
[2K
| Adam | epoch: 024 | loss: 0.35328 - acc: 0.8440 -- iter: 160/384
[A[ATraining Step: 282  | total loss: [1m[32m0.35745[0m[0m | time: 3.762s
[2K
| Adam | epoch: 024 | loss: 0.35745 - acc: 0.8440 -- iter: 192/384
[A[ATraining Step: 283  | total loss: [1m[32m0.33869[0m[0m | time: 4.392s
[2K
| Adam | epoch: 024 | loss: 0.33869 - acc: 0.8564 -- iter: 224/384
[A[ATraining Step: 284  | total loss: [1m[32m0.32823[0m[0m | time: 5.023s
[2K
| Adam | epoch: 024 | loss: 0.32823 - acc: 0.8583 -- iter: 256/384
[A[ATraining Step: 285  | total loss: [1m[32m0.33079[0m[0m | time: 5.625s
[2K
| Adam | epoch: 024 | loss: 0.33079 - acc: 0.8568 -- iter: 288/384
[A[ATraining Step: 286  | total loss: [1m[32m0.34657[0m[0m | time: 6.218s
[2K
| Adam | epoch: 024 | loss: 0.34657 - acc: 0.8430 -- iter: 320/384
[A[ATraining Step: 287  | total loss: [1m[32m0.36066[0m[0m | time: 6.821s
[2K
| Adam | epoch: 024 | loss: 0.36066 - acc: 0.8337 -- iter: 352/384
[A[ATraining Step: 288  | total loss: [1m[32m0.34606[0m[0m | time: 8.458s
[2K
| Adam | epoch: 024 | loss: 0.34606 - acc: 0.8441 | val_loss: 0.37616 - val_acc: 0.8667 -- iter: 384/384
--
Training Step: 289  | total loss: [1m[32m0.33853[0m[0m | time: 0.943s
[2K
| Adam | epoch: 025 | loss: 0.33853 - acc: 0.8503 -- iter: 032/384
[A[ATraining Step: 290  | total loss: [1m[32m0.32835[0m[0m | time: 1.966s
[2K
| Adam | epoch: 025 | loss: 0.32835 - acc: 0.8559 -- iter: 064/384
[A[ATraining Step: 291  | total loss: [1m[32m0.35174[0m[0m | time: 2.815s
[2K
| Adam | epoch: 025 | loss: 0.35174 - acc: 0.8484 -- iter: 096/384
[A[ATraining Step: 292  | total loss: [1m[32m0.34538[0m[0m | time: 3.936s
[2K
| Adam | epoch: 025 | loss: 0.34538 - acc: 0.8511 -- iter: 128/384
[A[ATraining Step: 293  | total loss: [1m[32m0.34602[0m[0m | time: 5.101s
[2K
| Adam | epoch: 025 | loss: 0.34602 - acc: 0.8472 -- iter: 160/384
[A[ATraining Step: 294  | total loss: [1m[32m0.33414[0m[0m | time: 6.125s
[2K
| Adam | epoch: 025 | loss: 0.33414 - acc: 0.8563 -- iter: 192/384
[A[ATraining Step: 295  | total loss: [1m[32m0.34414[0m[0m | time: 7.520s
[2K
| Adam | epoch: 025 | loss: 0.34414 - acc: 0.8519 -- iter: 224/384
[A[ATraining Step: 296  | total loss: [1m[32m0.33646[0m[0m | time: 8.477s
[2K
| Adam | epoch: 025 | loss: 0.33646 - acc: 0.8605 -- iter: 256/384
[A[ATraining Step: 297  | total loss: [1m[32m0.34526[0m[0m | time: 9.481s
[2K
| Adam | epoch: 025 | loss: 0.34526 - acc: 0.8432 -- iter: 288/384
[A[ATraining Step: 298  | total loss: [1m[32m0.32886[0m[0m | time: 10.420s
[2K
| Adam | epoch: 025 | loss: 0.32886 - acc: 0.8495 -- iter: 320/384
[A[ATraining Step: 299  | total loss: [1m[32m0.31961[0m[0m | time: 11.450s
[2K
| Adam | epoch: 025 | loss: 0.31961 - acc: 0.8551 -- iter: 352/384
[A[ATraining Step: 300  | total loss: [1m[32m0.31032[0m[0m | time: 13.510s
[2K
| Adam | epoch: 025 | loss: 0.31032 - acc: 0.8634 | val_loss: 0.43213 - val_acc: 0.8250 -- iter: 384/384
--
Training Step: 301  | total loss: [1m[32m0.31519[0m[0m | time: 0.906s
[2K
| Adam | epoch: 026 | loss: 0.31519 - acc: 0.8614 -- iter: 032/384
[A[ATraining Step: 302  | total loss: [1m[32m0.32651[0m[0m | time: 1.873s
[2K
| Adam | epoch: 026 | loss: 0.32651 - acc: 0.8503 -- iter: 064/384
[A[ATraining Step: 303  | total loss: [1m[32m0.33204[0m[0m | time: 2.872s
[2K
| Adam | epoch: 026 | loss: 0.33204 - acc: 0.8465 -- iter: 096/384
[A[ATraining Step: 304  | total loss: [1m[32m0.34680[0m[0m | time: 3.875s
[2K
| Adam | epoch: 026 | loss: 0.34680 - acc: 0.8462 -- iter: 128/384
[A[ATraining Step: 305  | total loss: [1m[32m0.32759[0m[0m | time: 5.014s
[2K
| Adam | epoch: 026 | loss: 0.32759 - acc: 0.8585 -- iter: 160/384
[A[ATraining Step: 306  | total loss: [1m[32m0.32338[0m[0m | time: 5.905s
[2K
| Adam | epoch: 026 | loss: 0.32338 - acc: 0.8601 -- iter: 192/384
[A[ATraining Step: 307  | total loss: [1m[32m0.32636[0m[0m | time: 6.901s
[2K
| Adam | epoch: 026 | loss: 0.32636 - acc: 0.8585 -- iter: 224/384
[A[ATraining Step: 308  | total loss: [1m[32m0.31730[0m[0m | time: 7.965s
[2K
| Adam | epoch: 026 | loss: 0.31730 - acc: 0.8601 -- iter: 256/384
[A[ATraining Step: 309  | total loss: [1m[32m0.32340[0m[0m | time: 8.996s
[2K
| Adam | epoch: 026 | loss: 0.32340 - acc: 0.8585 -- iter: 288/384
[A[ATraining Step: 310  | total loss: [1m[32m0.31727[0m[0m | time: 10.292s
[2K
| Adam | epoch: 026 | loss: 0.31727 - acc: 0.8602 -- iter: 320/384
[A[ATraining Step: 311  | total loss: [1m[32m0.30891[0m[0m | time: 11.133s
[2K
| Adam | epoch: 026 | loss: 0.30891 - acc: 0.8679 -- iter: 352/384
[A[ATraining Step: 312  | total loss: [1m[32m0.30148[0m[0m | time: 13.083s
[2K
| Adam | epoch: 026 | loss: 0.30148 - acc: 0.8748 | val_loss: 0.35689 - val_acc: 0.8667 -- iter: 384/384
--
Training Step: 313  | total loss: [1m[32m0.29420[0m[0m | time: 0.973s
[2K
| Adam | epoch: 027 | loss: 0.29420 - acc: 0.8811 -- iter: 032/384
[A[ATraining Step: 314  | total loss: [1m[32m0.28939[0m[0m | time: 2.042s
[2K
| Adam | epoch: 027 | loss: 0.28939 - acc: 0.8836 -- iter: 064/384
[A[ATraining Step: 315  | total loss: [1m[32m0.30048[0m[0m | time: 3.107s
[2K
| Adam | epoch: 027 | loss: 0.30048 - acc: 0.8765 -- iter: 096/384
[A[ATraining Step: 316  | total loss: [1m[32m0.30933[0m[0m | time: 4.142s
[2K
| Adam | epoch: 027 | loss: 0.30933 - acc: 0.8732 -- iter: 128/384
[A[ATraining Step: 317  | total loss: [1m[32m0.29445[0m[0m | time: 4.979s
[2K
| Adam | epoch: 027 | loss: 0.29445 - acc: 0.8765 -- iter: 160/384
[A[ATraining Step: 318  | total loss: [1m[32m0.29464[0m[0m | time: 5.951s
[2K
| Adam | epoch: 027 | loss: 0.29464 - acc: 0.8764 -- iter: 192/384
[A[ATraining Step: 319  | total loss: [1m[32m0.31734[0m[0m | time: 6.885s
[2K
| Adam | epoch: 027 | loss: 0.31734 - acc: 0.8669 -- iter: 224/384
[A[ATraining Step: 320  | total loss: [1m[32m0.30380[0m[0m | time: 7.903s
[2K
| Adam | epoch: 027 | loss: 0.30380 - acc: 0.8771 -- iter: 256/384
[A[ATraining Step: 321  | total loss: [1m[32m0.30112[0m[0m | time: 9.022s
[2K
| Adam | epoch: 027 | loss: 0.30112 - acc: 0.8706 -- iter: 288/384
[A[ATraining Step: 322  | total loss: [1m[32m0.30387[0m[0m | time: 10.097s
[2K
| Adam | epoch: 027 | loss: 0.30387 - acc: 0.8648 -- iter: 320/384
[A[ATraining Step: 323  | total loss: [1m[32m0.30129[0m[0m | time: 10.950s
[2K
| Adam | epoch: 027 | loss: 0.30129 - acc: 0.8721 -- iter: 352/384
[A[ATraining Step: 324  | total loss: [1m[32m0.29663[0m[0m | time: 13.084s
[2K
| Adam | epoch: 027 | loss: 0.29663 - acc: 0.8755 | val_loss: 0.39609 - val_acc: 0.8000 -- iter: 384/384
--
Training Step: 325  | total loss: [1m[32m0.29311[0m[0m | time: 0.985s
[2K
| Adam | epoch: 028 | loss: 0.29311 - acc: 0.8754 -- iter: 032/384
[A[ATraining Step: 326  | total loss: [1m[32m0.29206[0m[0m | time: 2.082s
[2K
| Adam | epoch: 028 | loss: 0.29206 - acc: 0.8816 -- iter: 064/384
[A[ATraining Step: 327  | total loss: [1m[32m0.29038[0m[0m | time: 3.142s
[2K
| Adam | epoch: 028 | loss: 0.29038 - acc: 0.8872 -- iter: 096/384
[A[ATraining Step: 328  | total loss: [1m[32m0.28339[0m[0m | time: 3.990s
[2K
| Adam | epoch: 028 | loss: 0.28339 - acc: 0.8923 -- iter: 128/384
[A[ATraining Step: 329  | total loss: [1m[32m0.27877[0m[0m | time: 5.155s
[2K
| Adam | epoch: 028 | loss: 0.27877 - acc: 0.8905 -- iter: 160/384
[A[ATraining Step: 330  | total loss: [1m[32m0.27538[0m[0m | time: 6.239s
[2K
| Adam | epoch: 028 | loss: 0.27538 - acc: 0.8921 -- iter: 192/384
[A[ATraining Step: 331  | total loss: [1m[32m0.27729[0m[0m | time: 7.140s
[2K
| Adam | epoch: 028 | loss: 0.27729 - acc: 0.8873 -- iter: 224/384
[A[ATraining Step: 332  | total loss: [1m[32m0.28245[0m[0m | time: 8.059s
[2K
| Adam | epoch: 028 | loss: 0.28245 - acc: 0.8860 -- iter: 256/384
[A[ATraining Step: 333  | total loss: [1m[32m0.27752[0m[0m | time: 9.005s
[2K
| Adam | epoch: 028 | loss: 0.27752 - acc: 0.8912 -- iter: 288/384
[A[ATraining Step: 334  | total loss: [1m[32m0.28688[0m[0m | time: 9.985s
[2K
| Adam | epoch: 028 | loss: 0.28688 - acc: 0.8833 -- iter: 320/384
[A[ATraining Step: 335  | total loss: [1m[32m0.27980[0m[0m | time: 10.913s
[2K
| Adam | epoch: 028 | loss: 0.27980 - acc: 0.8887 -- iter: 352/384
[A[ATraining Step: 336  | total loss: [1m[32m0.27357[0m[0m | time: 12.989s
[2K
| Adam | epoch: 028 | loss: 0.27357 - acc: 0.8936 | val_loss: 0.41923 - val_acc: 0.7750 -- iter: 384/384
--
Training Step: 337  | total loss: [1m[32m0.27145[0m[0m | time: 1.077s
[2K
| Adam | epoch: 029 | loss: 0.27145 - acc: 0.8949 -- iter: 032/384
[A[ATraining Step: 338  | total loss: [1m[32m0.26316[0m[0m | time: 1.987s
[2K
| Adam | epoch: 029 | loss: 0.26316 - acc: 0.8991 -- iter: 064/384
[A[ATraining Step: 339  | total loss: [1m[32m0.25738[0m[0m | time: 2.935s
[2K
| Adam | epoch: 029 | loss: 0.25738 - acc: 0.9030 -- iter: 096/384
[A[ATraining Step: 340  | total loss: [1m[32m0.25827[0m[0m | time: 3.947s
[2K
| Adam | epoch: 029 | loss: 0.25827 - acc: 0.9033 -- iter: 128/384
[A[ATraining Step: 341  | total loss: [1m[32m0.24902[0m[0m | time: 4.917s
[2K
| Adam | epoch: 029 | loss: 0.24902 - acc: 0.9067 -- iter: 160/384
[A[ATraining Step: 342  | total loss: [1m[32m0.25224[0m[0m | time: 6.029s
[2K
| Adam | epoch: 029 | loss: 0.25224 - acc: 0.9035 -- iter: 192/384
[A[ATraining Step: 343  | total loss: [1m[32m0.25565[0m[0m | time: 7.020s
[2K
| Adam | epoch: 029 | loss: 0.25565 - acc: 0.9038 -- iter: 224/384
[A[ATraining Step: 344  | total loss: [1m[32m0.24694[0m[0m | time: 7.934s
[2K
| Adam | epoch: 029 | loss: 0.24694 - acc: 0.9103 -- iter: 256/384
[A[ATraining Step: 345  | total loss: [1m[32m0.24454[0m[0m | time: 8.996s
[2K
| Adam | epoch: 029 | loss: 0.24454 - acc: 0.9037 -- iter: 288/384
[A[ATraining Step: 346  | total loss: [1m[32m0.25168[0m[0m | time: 10.064s
[2K
| Adam | epoch: 029 | loss: 0.25168 - acc: 0.9008 -- iter: 320/384
[A[ATraining Step: 347  | total loss: [1m[32m0.24317[0m[0m | time: 11.409s
[2K
| Adam | epoch: 029 | loss: 0.24317 - acc: 0.9076 -- iter: 352/384
[A[ATraining Step: 348  | total loss: [1m[32m0.23214[0m[0m | time: 14.958s
[2K
| Adam | epoch: 029 | loss: 0.23214 - acc: 0.9106 | val_loss: 0.42397 - val_acc: 0.7917 -- iter: 384/384
--
Training Step: 349  | total loss: [1m[32m0.24106[0m[0m | time: 0.936s
[2K
| Adam | epoch: 030 | loss: 0.24106 - acc: 0.9070 -- iter: 032/384
[A[ATraining Step: 350  | total loss: [1m[32m0.23932[0m[0m | time: 1.916s
[2K
| Adam | epoch: 030 | loss: 0.23932 - acc: 0.9069 -- iter: 064/384
[A[ATraining Step: 351  | total loss: [1m[32m0.23685[0m[0m | time: 2.959s
[2K
| Adam | epoch: 030 | loss: 0.23685 - acc: 0.9100 -- iter: 096/384
[A[ATraining Step: 352  | total loss: [1m[32m0.23393[0m[0m | time: 4.121s
[2K
| Adam | epoch: 030 | loss: 0.23393 - acc: 0.9096 -- iter: 128/384
[A[ATraining Step: 353  | total loss: [1m[32m0.23445[0m[0m | time: 5.042s
[2K
| Adam | epoch: 030 | loss: 0.23445 - acc: 0.9062 -- iter: 160/384
[A[ATraining Step: 354  | total loss: [1m[32m0.22849[0m[0m | time: 6.003s
[2K
| Adam | epoch: 030 | loss: 0.22849 - acc: 0.9093 -- iter: 192/384
[A[ATraining Step: 355  | total loss: [1m[32m0.22410[0m[0m | time: 7.031s
[2K
| Adam | epoch: 030 | loss: 0.22410 - acc: 0.9090 -- iter: 224/384
[A[ATraining Step: 356  | total loss: [1m[32m0.22741[0m[0m | time: 7.975s
[2K
| Adam | epoch: 030 | loss: 0.22741 - acc: 0.9056 -- iter: 256/384
[A[ATraining Step: 357  | total loss: [1m[32m0.22789[0m[0m | time: 9.076s
[2K
| Adam | epoch: 030 | loss: 0.22789 - acc: 0.9057 -- iter: 288/384
[A[ATraining Step: 358  | total loss: [1m[32m0.22328[0m[0m | time: 10.183s
[2K
| Adam | epoch: 030 | loss: 0.22328 - acc: 0.9088 -- iter: 320/384
[A[ATraining Step: 359  | total loss: [1m[32m0.21736[0m[0m | time: 11.014s
[2K
| Adam | epoch: 030 | loss: 0.21736 - acc: 0.9148 -- iter: 352/384
[A[ATraining Step: 360  | total loss: [1m[32m0.22695[0m[0m | time: 13.189s
[2K
| Adam | epoch: 030 | loss: 0.22695 - acc: 0.9108 | val_loss: 0.34883 - val_acc: 0.8250 -- iter: 384/384
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9221357063403782
Validation AUPRC:0.9358206948763564
Test AUC:0.9437762237762238
Test AUPRC:0.95941938267493
BestTestF1Score	0.87	0.73	0.87	0.9	0.85	55	6	49	10	0.63
BestTestMCCScore	0.86	0.73	0.86	0.93	0.8	52	4	51	13	0.75
BestTestAccuracyScore	0.86	0.73	0.86	0.93	0.8	52	4	51	13	0.75
BestValidationF1Score	0.85	0.72	0.86	0.89	0.81	47	6	56	11	0.63
BestValidationMCC	0.84	0.73	0.86	0.94	0.76	44	3	59	14	0.75
BestValidationAccuracy	0.84	0.73	0.86	0.94	0.76	44	3	59	14	0.75
TestPredictions (Threshold:0.75)
CHEMBL498249,TN,INACT,0.4699999988079071	CHEMBL1933289,TP,ACT,0.9700000286102295	CHEMBL379849,TN,INACT,0.23000000417232513	CHEMBL3673664,TP,ACT,0.9900000095367432	CHEMBL6291,FN,ACT,0.6499999761581421	CHEMBL3673576,TP,ACT,0.9900000095367432	CHEMBL3673625,TP,ACT,0.9700000286102295	CHEMBL2392375,TN,INACT,0.019999999552965164	CHEMBL527039,TN,INACT,0.20000000298023224	CHEMBL1739550,TP,ACT,0.9700000286102295	CHEMBL458076,TN,INACT,0.029999999329447746	CHEMBL3673662,TP,ACT,0.9900000095367432	CHEMBL1775070,FN,ACT,0.2800000011920929	CHEMBL3673603,TP,ACT,0.9900000095367432	CHEMBL1938800,TP,ACT,0.9900000095367432	CHEMBL2392366,TN,INACT,0.009999999776482582	CHEMBL2392246,TN,INACT,0.019999999552965164	CHEMBL3604791,TP,ACT,0.75	CHEMBL1767126,TN,INACT,0.05999999865889549	CHEMBL524820,FP,INACT,0.800000011920929	CHEMBL1331525,TN,INACT,0.7400000095367432	CHEMBL3673614,TP,ACT,0.9900000095367432	CHEMBL1938786,TP,ACT,0.9800000190734863	CHEMBL1938794,TP,ACT,0.9900000095367432	CHEMBL101779,TN,INACT,0.46000000834465027	CHEMBL3673583,TP,ACT,0.9900000095367432	CHEMBL2392378,TN,INACT,0.009999999776482582	CHEMBL3604775,TP,ACT,0.8700000047683716	CHEMBL414861,TN,INACT,0.38999998569488525	CHEMBL495727,FN,ACT,0.36000001430511475	CHEMBL262623,FP,INACT,0.9599999785423279	CHEMBL3673642,TP,ACT,0.9900000095367432	CHEMBL3673586,TP,ACT,0.9900000095367432	CHEMBL1938765,TP,ACT,0.9900000095367432	CHEMBL1910756,TN,INACT,0.14000000059604645	CHEMBL3673652,TP,ACT,0.9599999785423279	CHEMBL1938782,TP,ACT,0.9900000095367432	CHEMBL3356439,TP,ACT,0.9900000095367432	CHEMBL175828,TN,INACT,0.38999998569488525	CHEMBL559683,TN,INACT,0.07000000029802322	CHEMBL380958,TN,INACT,0.009999999776482582	CHEMBL2312645,TN,INACT,0.1899999976158142	CHEMBL1685061,TN,INACT,0.10999999940395355	CHEMBL2392233,TN,INACT,0.019999999552965164	CHEMBL603469,TP,ACT,0.9700000286102295	CHEMBL3673593,TP,ACT,0.9900000095367432	CHEMBL1910623,TP,ACT,0.9200000166893005	CHEMBL507059,TN,INACT,0.12999999523162842	CHEMBL264666,TN,INACT,0.25999999046325684	CHEMBL1784660,TN,INACT,0.6299999952316284	CHEMBL419069,TN,INACT,0.6100000143051147	CHEMBL3109401,FP,INACT,0.8199999928474426	CHEMBL67655,TN,INACT,0.38999998569488525	CHEMBL3673631,TP,ACT,0.9800000190734863	CHEMBL2017517,TP,ACT,0.9800000190734863	CHEMBL1938796,TP,ACT,0.9900000095367432	CHEMBL204892,TN,INACT,0.029999999329447746	CHEMBL230761,TN,INACT,0.6499999761581421	CHEMBL378627,FN,ACT,0.6700000166893005	CHEMBL2392240,TN,INACT,0.019999999552965164	CHEMBL3673573,TP,ACT,0.9300000071525574	CHEMBL3673607,TP,ACT,0.9900000095367432	CHEMBL3672511,TN,INACT,0.47999998927116394	CHEMBL3673663,TP,ACT,0.9900000095367432	CHEMBL448003,TN,INACT,0.05999999865889549	CHEMBL223393,TN,INACT,0.11999999731779099	CHEMBL390066,TN,INACT,0.25	CHEMBL2177841,FP,INACT,0.8100000023841858	CHEMBL255210,TP,ACT,1.0	CHEMBL1287853,TP,ACT,0.8100000023841858	CHEMBL3673570,TP,ACT,0.9599999785423279	CHEMBL1270399,TP,ACT,0.8600000143051147	CHEMBL456378,TN,INACT,0.10000000149011612	CHEMBL1933285,TP,ACT,0.9900000095367432	CHEMBL1933279,TP,ACT,0.9900000095367432	CHEMBL1775069,FN,ACT,0.41999998688697815	CHEMBL1908397,FN,ACT,0.6299999952316284	CHEMBL3673657,TP,ACT,0.9900000095367432	CHEMBL1933283,TP,ACT,0.9800000190734863	CHEMBL1933146,TP,ACT,0.9900000095367432	CHEMBL515674,TN,INACT,0.15000000596046448	CHEMBL3596524,TN,INACT,0.019999999552965164	CHEMBL3673567,TP,ACT,0.9900000095367432	CHEMBL525538,TN,INACT,0.03999999910593033	CHEMBL2347073,FN,ACT,0.2800000011920929	CHEMBL447960,TN,INACT,0.2199999988079071	CHEMBL228114,TN,INACT,0.44999998807907104	CHEMBL3604796,TP,ACT,0.8299999833106995	CHEMBL535,FN,ACT,0.3700000047683716	CHEMBL1933148,TP,ACT,0.9900000095367432	CHEMBL3673604,TP,ACT,0.9900000095367432	CHEMBL490241,TN,INACT,0.019999999552965164	CHEMBL3604887,FN,ACT,0.49000000953674316	CHEMBL3604789,TP,ACT,0.9700000286102295	CHEMBL246327,TN,INACT,0.07999999821186066	CHEMBL608533,FN,ACT,0.6800000071525574	CHEMBL3673602,TP,ACT,0.9900000095367432	CHEMBL2381116,FN,ACT,0.05999999865889549	CHEMBL3609567,TN,INACT,0.3799999952316284	CHEMBL3673598,TP,ACT,0.9700000286102295	CHEMBL3673649,TP,ACT,0.9900000095367432	CHEMBL2312649,TN,INACT,0.10000000149011612	CHEMBL558601,TN,INACT,0.14000000059604645	CHEMBL469346,TN,INACT,0.10000000149011612	CHEMBL3609568,TN,INACT,0.019999999552965164	CHEMBL3672514,TN,INACT,0.25999999046325684	CHEMBL444877,TN,INACT,0.5099999904632568	CHEMBL3673640,TP,ACT,0.949999988079071	CHEMBL3604778,TP,ACT,0.9800000190734863	CHEMBL2392236,TN,INACT,0.029999999329447746	CHEMBL3673589,TP,ACT,0.9800000190734863	CHEMBL457191,TN,INACT,0.009999999776482582	CHEMBL515414,FN,ACT,0.4000000059604645	CHEMBL1915456,TN,INACT,0.12999999523162842	CHEMBL1933278,TP,ACT,0.9800000190734863	CHEMBL1938799,TP,ACT,0.9900000095367432	CHEMBL1721885,FN,ACT,0.3499999940395355	CHEMBL3102933,TN,INACT,0.1599999964237213	CHEMBL334248,TN,INACT,0.5600000023841858	CHEMBL3673601,TP,ACT,0.9900000095367432	

