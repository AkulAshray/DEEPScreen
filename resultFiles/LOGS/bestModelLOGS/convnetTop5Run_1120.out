CNNModel CHEMBL5408 adam 0.0005 30 256 0 0.6 False True
Number of active compounds :	229
Number of inactive compounds :	229
---------------------------------
Run id: CNNModel_CHEMBL5408_adam_0.0005_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5408_adam_0.0005_30_256_0.6_True/
---------------------------------
Training samples: 285
Validation samples: 90
--
Training Step: 1  | time: 1.384s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/285
[A[ATraining Step: 2  | total loss: [1m[32m0.62354[0m[0m | time: 2.400s
[2K
| Adam | epoch: 001 | loss: 0.62354 - acc: 0.5062 -- iter: 064/285
[A[ATraining Step: 3  | total loss: [1m[32m0.68213[0m[0m | time: 3.429s
[2K
| Adam | epoch: 001 | loss: 0.68213 - acc: 0.4500 -- iter: 096/285
[A[ATraining Step: 4  | total loss: [1m[32m0.69092[0m[0m | time: 4.466s
[2K
| Adam | epoch: 001 | loss: 0.69092 - acc: 0.4172 -- iter: 128/285
[A[ATraining Step: 5  | total loss: [1m[32m0.69261[0m[0m | time: 5.461s
[2K
| Adam | epoch: 001 | loss: 0.69261 - acc: 0.4745 -- iter: 160/285
[A[ATraining Step: 6  | total loss: [1m[32m0.69317[0m[0m | time: 6.455s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.4105 -- iter: 192/285
[A[ATraining Step: 7  | total loss: [1m[32m0.69307[0m[0m | time: 7.488s
[2K
| Adam | epoch: 001 | loss: 0.69307 - acc: 0.5205 -- iter: 224/285
[A[ATraining Step: 8  | total loss: [1m[32m0.69335[0m[0m | time: 8.508s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.5090 -- iter: 256/285
[A[ATraining Step: 9  | total loss: [1m[32m0.69259[0m[0m | time: 10.540s
[2K
| Adam | epoch: 001 | loss: 0.69259 - acc: 0.5538 | val_loss: 0.69198 - val_acc: 0.5556 -- iter: 285/285
--
Training Step: 10  | total loss: [1m[32m0.69464[0m[0m | time: 0.956s
[2K
| Adam | epoch: 002 | loss: 0.69464 - acc: 0.4666 -- iter: 032/285
[A[ATraining Step: 11  | total loss: [1m[32m0.69534[0m[0m | time: 2.093s
[2K
| Adam | epoch: 002 | loss: 0.69534 - acc: 0.4252 -- iter: 064/285
[A[ATraining Step: 12  | total loss: [1m[32m0.69434[0m[0m | time: 3.422s
[2K
| Adam | epoch: 002 | loss: 0.69434 - acc: 0.4589 -- iter: 096/285
[A[ATraining Step: 13  | total loss: [1m[32m0.69375[0m[0m | time: 4.813s
[2K
| Adam | epoch: 002 | loss: 0.69375 - acc: 0.4899 -- iter: 128/285
[A[ATraining Step: 14  | total loss: [1m[32m0.69407[0m[0m | time: 6.169s
[2K
| Adam | epoch: 002 | loss: 0.69407 - acc: 0.4301 -- iter: 160/285
[A[ATraining Step: 15  | total loss: [1m[32m0.69389[0m[0m | time: 8.149s
[2K
| Adam | epoch: 002 | loss: 0.69389 - acc: 0.4330 -- iter: 192/285
[A[ATraining Step: 16  | total loss: [1m[32m0.69347[0m[0m | time: 13.327s
[2K
| Adam | epoch: 002 | loss: 0.69347 - acc: 0.5167 -- iter: 224/285
[A[ATraining Step: 17  | total loss: [1m[32m0.69331[0m[0m | time: 14.487s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.5332 -- iter: 256/285
[A[ATraining Step: 18  | total loss: [1m[32m0.69320[0m[0m | time: 16.749s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.5542 | val_loss: 0.69291 - val_acc: 0.5556 -- iter: 285/285
--
Training Step: 19  | total loss: [1m[32m0.69314[0m[0m | time: 0.953s
[2K
| Adam | epoch: 003 | loss: 0.69314 - acc: 0.5465 -- iter: 032/285
[A[ATraining Step: 20  | total loss: [1m[32m0.69327[0m[0m | time: 2.084s
[2K
| Adam | epoch: 003 | loss: 0.69327 - acc: 0.5039 -- iter: 064/285
[A[ATraining Step: 21  | total loss: [1m[32m0.69336[0m[0m | time: 3.015s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.4759 -- iter: 096/285
[A[ATraining Step: 22  | total loss: [1m[32m0.69331[0m[0m | time: 3.692s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.4831 -- iter: 128/285
[A[ATraining Step: 23  | total loss: [1m[32m0.69323[0m[0m | time: 4.281s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.4971 -- iter: 160/285
[A[ATraining Step: 24  | total loss: [1m[32m0.69323[0m[0m | time: 5.418s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.4891 -- iter: 192/285
[A[ATraining Step: 25  | total loss: [1m[32m0.69328[0m[0m | time: 6.519s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.4665 -- iter: 224/285
[A[ATraining Step: 26  | total loss: [1m[32m0.69323[0m[0m | time: 7.685s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.5002 -- iter: 256/285
[A[ATraining Step: 27  | total loss: [1m[32m0.69321[0m[0m | time: 18.629s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.5002 | val_loss: 0.69313 - val_acc: 0.6778 -- iter: 285/285
--
Training Step: 28  | total loss: [1m[32m0.69319[0m[0m | time: 1.082s
[2K
| Adam | epoch: 004 | loss: 0.69319 - acc: 0.5079 -- iter: 032/285
[A[ATraining Step: 29  | total loss: [1m[32m0.69317[0m[0m | time: 2.205s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5364 -- iter: 064/285
[A[ATraining Step: 30  | total loss: [1m[32m0.69317[0m[0m | time: 3.163s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5400 -- iter: 096/285
[A[ATraining Step: 31  | total loss: [1m[32m0.69313[0m[0m | time: 4.038s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.5427 -- iter: 128/285
[A[ATraining Step: 32  | total loss: [1m[32m0.69323[0m[0m | time: 5.155s
[2K
| Adam | epoch: 004 | loss: 0.69323 - acc: 0.5050 -- iter: 160/285
[A[ATraining Step: 33  | total loss: [1m[32m0.69337[0m[0m | time: 6.270s
[2K
| Adam | epoch: 004 | loss: 0.69337 - acc: 0.4627 -- iter: 192/285
[A[ATraining Step: 34  | total loss: [1m[32m0.69332[0m[0m | time: 7.294s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.4707 -- iter: 224/285
[A[ATraining Step: 35  | total loss: [1m[32m0.69329[0m[0m | time: 10.731s
[2K
| Adam | epoch: 004 | loss: 0.69329 - acc: 0.4768 -- iter: 256/285
[A[ATraining Step: 36  | total loss: [1m[32m0.69324[0m[0m | time: 12.591s
[2K
| Adam | epoch: 004 | loss: 0.69324 - acc: 0.5135 | val_loss: 0.69309 - val_acc: 0.6222 -- iter: 285/285
--
Training Step: 37  | total loss: [1m[32m0.69321[0m[0m | time: 0.988s
[2K
| Adam | epoch: 005 | loss: 0.69321 - acc: 0.5546 -- iter: 032/285
[A[ATraining Step: 38  | total loss: [1m[32m0.69319[0m[0m | time: 2.738s
[2K
| Adam | epoch: 005 | loss: 0.69319 - acc: 0.5500 -- iter: 064/285
[A[ATraining Step: 39  | total loss: [1m[32m0.69316[0m[0m | time: 4.924s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.5524 -- iter: 096/285
[A[ATraining Step: 40  | total loss: [1m[32m0.69308[0m[0m | time: 7.878s
[2K
| Adam | epoch: 005 | loss: 0.69308 - acc: 0.5652 -- iter: 128/285
[A[ATraining Step: 41  | total loss: [1m[32m0.69298[0m[0m | time: 9.605s
[2K
| Adam | epoch: 005 | loss: 0.69298 - acc: 0.5754 -- iter: 160/285
[A[ATraining Step: 42  | total loss: [1m[32m0.69321[0m[0m | time: 11.247s
[2K
| Adam | epoch: 005 | loss: 0.69321 - acc: 0.5337 -- iter: 192/285
[A[ATraining Step: 43  | total loss: [1m[32m0.69328[0m[0m | time: 12.825s
[2K
| Adam | epoch: 005 | loss: 0.69328 - acc: 0.5167 -- iter: 224/285
[A[ATraining Step: 44  | total loss: [1m[32m0.69354[0m[0m | time: 14.489s
[2K
| Adam | epoch: 005 | loss: 0.69354 - acc: 0.4814 -- iter: 256/285
[A[ATraining Step: 45  | total loss: [1m[32m0.69347[0m[0m | time: 33.857s
[2K
| Adam | epoch: 005 | loss: 0.69347 - acc: 0.4845 | val_loss: 0.69284 - val_acc: 0.5556 -- iter: 285/285
--
Training Step: 46  | total loss: [1m[32m0.69350[0m[0m | time: 23.477s
[2K
| Adam | epoch: 006 | loss: 0.69350 - acc: 0.4715 -- iter: 032/285
[A[ATraining Step: 47  | total loss: [1m[32m0.69324[0m[0m | time: 25.131s
[2K
| Adam | epoch: 006 | loss: 0.69324 - acc: 0.5171 -- iter: 064/285
[A[ATraining Step: 48  | total loss: [1m[32m0.69313[0m[0m | time: 26.722s
[2K
| Adam | epoch: 006 | loss: 0.69313 - acc: 0.5294 -- iter: 096/285
[A[ATraining Step: 49  | total loss: [1m[32m0.69318[0m[0m | time: 28.135s
[2K
| Adam | epoch: 006 | loss: 0.69318 - acc: 0.5149 -- iter: 128/285
[A[ATraining Step: 50  | total loss: [1m[32m0.69301[0m[0m | time: 29.549s
[2K
| Adam | epoch: 006 | loss: 0.69301 - acc: 0.5367 -- iter: 160/285
[A[ATraining Step: 51  | total loss: [1m[32m0.69284[0m[0m | time: 31.020s
[2K
| Adam | epoch: 006 | loss: 0.69284 - acc: 0.5547 -- iter: 192/285
[A[ATraining Step: 52  | total loss: [1m[32m0.69297[0m[0m | time: 32.570s
[2K
| Adam | epoch: 006 | loss: 0.69297 - acc: 0.5371 -- iter: 224/285
[A[ATraining Step: 53  | total loss: [1m[32m0.69298[0m[0m | time: 34.135s
[2K
| Adam | epoch: 006 | loss: 0.69298 - acc: 0.5317 -- iter: 256/285
[A[ATraining Step: 54  | total loss: [1m[32m0.69292[0m[0m | time: 36.912s
[2K
| Adam | epoch: 006 | loss: 0.69292 - acc: 0.5316 | val_loss: 0.69217 - val_acc: 0.5556 -- iter: 285/285
--
Training Step: 55  | total loss: [1m[32m0.69314[0m[0m | time: 1.383s
[2K
| Adam | epoch: 007 | loss: 0.69314 - acc: 0.5137 -- iter: 032/285
[A[ATraining Step: 56  | total loss: [1m[32m0.69314[0m[0m | time: 2.939s
[2K
| Adam | epoch: 007 | loss: 0.69314 - acc: 0.5118 -- iter: 064/285
[A[ATraining Step: 57  | total loss: [1m[32m0.69293[0m[0m | time: 5.263s
[2K
| Adam | epoch: 007 | loss: 0.69293 - acc: 0.5231 -- iter: 096/285
[A[ATraining Step: 58  | total loss: [1m[32m0.69316[0m[0m | time: 7.685s
[2K
| Adam | epoch: 007 | loss: 0.69316 - acc: 0.5072 -- iter: 128/285
[A[ATraining Step: 59  | total loss: [1m[32m0.69292[0m[0m | time: 9.203s
[2K
| Adam | epoch: 007 | loss: 0.69292 - acc: 0.5188 -- iter: 160/285
[A[ATraining Step: 60  | total loss: [1m[32m0.69261[0m[0m | time: 10.551s
[2K
| Adam | epoch: 007 | loss: 0.69261 - acc: 0.5323 -- iter: 192/285
[A[ATraining Step: 61  | total loss: [1m[32m0.69230[0m[0m | time: 11.792s
[2K
| Adam | epoch: 007 | loss: 0.69230 - acc: 0.5438 -- iter: 224/285
[A[ATraining Step: 62  | total loss: [1m[32m0.69214[0m[0m | time: 12.977s
[2K
| Adam | epoch: 007 | loss: 0.69214 - acc: 0.5462 -- iter: 256/285
[A[ATraining Step: 63  | total loss: [1m[32m0.69173[0m[0m | time: 15.292s
[2K
| Adam | epoch: 007 | loss: 0.69173 - acc: 0.5562 | val_loss: 0.68959 - val_acc: 0.5556 -- iter: 285/285
--
Training Step: 64  | total loss: [1m[32m0.69202[0m[0m | time: 1.406s
[2K
| Adam | epoch: 008 | loss: 0.69202 - acc: 0.5453 -- iter: 032/285
[A[ATraining Step: 65  | total loss: [1m[32m0.69265[0m[0m | time: 2.824s
[2K
| Adam | epoch: 008 | loss: 0.69265 - acc: 0.5281 -- iter: 064/285
[A[ATraining Step: 66  | total loss: [1m[32m0.69286[0m[0m | time: 4.478s
[2K
| Adam | epoch: 008 | loss: 0.69286 - acc: 0.5171 -- iter: 096/285
[A[ATraining Step: 67  | total loss: [1m[32m0.69319[0m[0m | time: 6.124s
[2K
| Adam | epoch: 008 | loss: 0.69319 - acc: 0.5038 -- iter: 128/285
[A[ATraining Step: 68  | total loss: [1m[32m0.69320[0m[0m | time: 7.812s
[2K
| Adam | epoch: 008 | loss: 0.69320 - acc: 0.4997 -- iter: 160/285
[A[ATraining Step: 69  | total loss: [1m[32m0.69314[0m[0m | time: 9.488s
[2K
| Adam | epoch: 008 | loss: 0.69314 - acc: 0.4960 -- iter: 192/285
[A[ATraining Step: 70  | total loss: [1m[32m0.69319[0m[0m | time: 10.851s
[2K
| Adam | epoch: 008 | loss: 0.69319 - acc: 0.4866 -- iter: 224/285
[A[ATraining Step: 71  | total loss: [1m[32m0.69315[0m[0m | time: 11.906s
[2K
| Adam | epoch: 008 | loss: 0.69315 - acc: 0.4783 -- iter: 256/285
[A[ATraining Step: 72  | total loss: [1m[32m0.69229[0m[0m | time: 13.558s
[2K
| Adam | epoch: 008 | loss: 0.69229 - acc: 0.4948 | val_loss: 0.68292 - val_acc: 0.5556 -- iter: 285/285
--
Training Step: 73  | total loss: [1m[32m0.69164[0m[0m | time: 0.617s
[2K
| Adam | epoch: 009 | loss: 0.69164 - acc: 0.5058 -- iter: 032/285
[A[ATraining Step: 74  | total loss: [1m[32m0.69095[0m[0m | time: 1.224s
[2K
| Adam | epoch: 009 | loss: 0.69095 - acc: 0.5086 -- iter: 064/285
[A[ATraining Step: 75  | total loss: [1m[32m0.69047[0m[0m | time: 1.909s
[2K
| Adam | epoch: 009 | loss: 0.69047 - acc: 0.5076 -- iter: 096/285
[A[ATraining Step: 76  | total loss: [1m[32m0.68989[0m[0m | time: 2.553s
[2K
| Adam | epoch: 009 | loss: 0.68989 - acc: 0.5068 -- iter: 128/285
[A[ATraining Step: 77  | total loss: [1m[32m0.69142[0m[0m | time: 3.199s
[2K
| Adam | epoch: 009 | loss: 0.69142 - acc: 0.4929 -- iter: 160/285
[A[ATraining Step: 78  | total loss: [1m[32m0.68926[0m[0m | time: 3.835s
[2K
| Adam | epoch: 009 | loss: 0.68926 - acc: 0.5002 -- iter: 192/285
[A[ATraining Step: 79  | total loss: [1m[32m0.68772[0m[0m | time: 4.441s
[2K
| Adam | epoch: 009 | loss: 0.68772 - acc: 0.5163 -- iter: 224/285
[A[ATraining Step: 80  | total loss: [1m[32m0.68589[0m[0m | time: 5.118s
[2K
| Adam | epoch: 009 | loss: 0.68589 - acc: 0.5376 -- iter: 256/285
[A[ATraining Step: 81  | total loss: [1m[32m0.68331[0m[0m | time: 6.838s
[2K
| Adam | epoch: 009 | loss: 0.68331 - acc: 0.5564 | val_loss: 0.61987 - val_acc: 0.7333 -- iter: 285/285
--
Training Step: 82  | total loss: [1m[32m0.68175[0m[0m | time: 0.621s
[2K
| Adam | epoch: 010 | loss: 0.68175 - acc: 0.5602 -- iter: 032/285
[A[ATraining Step: 83  | total loss: [1m[32m0.67836[0m[0m | time: 1.281s
[2K
| Adam | epoch: 010 | loss: 0.67836 - acc: 0.5698 -- iter: 064/285
[A[ATraining Step: 84  | total loss: [1m[32m0.67364[0m[0m | time: 1.884s
[2K
| Adam | epoch: 010 | loss: 0.67364 - acc: 0.5815 -- iter: 096/285
[A[ATraining Step: 85  | total loss: [1m[32m0.66853[0m[0m | time: 2.499s
[2K
| Adam | epoch: 010 | loss: 0.66853 - acc: 0.5984 -- iter: 128/285
[A[ATraining Step: 86  | total loss: [1m[32m0.66057[0m[0m | time: 3.163s
[2K
| Adam | epoch: 010 | loss: 0.66057 - acc: 0.6042 -- iter: 160/285
[A[ATraining Step: 87  | total loss: [1m[32m0.65371[0m[0m | time: 3.837s
[2K
| Adam | epoch: 010 | loss: 0.65371 - acc: 0.6156 -- iter: 192/285
[A[ATraining Step: 88  | total loss: [1m[32m0.65270[0m[0m | time: 4.455s
[2K
| Adam | epoch: 010 | loss: 0.65270 - acc: 0.6228 -- iter: 224/285
[A[ATraining Step: 89  | total loss: [1m[32m0.65221[0m[0m | time: 5.064s
[2K
| Adam | epoch: 010 | loss: 0.65221 - acc: 0.6199 -- iter: 256/285
[A[ATraining Step: 90  | total loss: [1m[32m0.64653[0m[0m | time: 6.688s
[2K
| Adam | epoch: 010 | loss: 0.64653 - acc: 0.6303 | val_loss: 0.47279 - val_acc: 0.7667 -- iter: 285/285
--
Training Step: 91  | total loss: [1m[32m0.63653[0m[0m | time: 0.683s
[2K
| Adam | epoch: 011 | loss: 0.63653 - acc: 0.6466 -- iter: 032/285
[A[ATraining Step: 92  | total loss: [1m[32m0.62419[0m[0m | time: 1.337s
[2K
| Adam | epoch: 011 | loss: 0.62419 - acc: 0.6538 -- iter: 064/285
[A[ATraining Step: 93  | total loss: [1m[32m0.62271[0m[0m | time: 1.959s
[2K
| Adam | epoch: 011 | loss: 0.62271 - acc: 0.6572 -- iter: 096/285
[A[ATraining Step: 94  | total loss: [1m[32m0.61290[0m[0m | time: 2.588s
[2K
| Adam | epoch: 011 | loss: 0.61290 - acc: 0.6633 -- iter: 128/285
[A[ATraining Step: 95  | total loss: [1m[32m0.59211[0m[0m | time: 3.238s
[2K
| Adam | epoch: 011 | loss: 0.59211 - acc: 0.6845 -- iter: 160/285
[A[ATraining Step: 96  | total loss: [1m[32m0.59909[0m[0m | time: 3.872s
[2K
| Adam | epoch: 011 | loss: 0.59909 - acc: 0.6817 -- iter: 192/285
[A[ATraining Step: 97  | total loss: [1m[32m0.58959[0m[0m | time: 4.541s
[2K
| Adam | epoch: 011 | loss: 0.58959 - acc: 0.6916 -- iter: 224/285
[A[ATraining Step: 98  | total loss: [1m[32m0.61953[0m[0m | time: 5.163s
[2K
| Adam | epoch: 011 | loss: 0.61953 - acc: 0.6694 -- iter: 256/285
[A[ATraining Step: 99  | total loss: [1m[32m0.60125[0m[0m | time: 6.790s
[2K
| Adam | epoch: 011 | loss: 0.60125 - acc: 0.6837 | val_loss: 0.44327 - val_acc: 0.8222 -- iter: 285/285
--
Training Step: 100  | total loss: [1m[32m0.59203[0m[0m | time: 0.843s
[2K
| Adam | epoch: 012 | loss: 0.59203 - acc: 0.6843 -- iter: 032/285
[A[ATraining Step: 101  | total loss: [1m[32m0.58180[0m[0m | time: 1.837s
[2K
| Adam | epoch: 012 | loss: 0.58180 - acc: 0.6883 -- iter: 064/285
[A[ATraining Step: 102  | total loss: [1m[32m0.56676[0m[0m | time: 2.941s
[2K
| Adam | epoch: 012 | loss: 0.56676 - acc: 0.6976 -- iter: 096/285
[A[ATraining Step: 103  | total loss: [1m[32m0.54475[0m[0m | time: 4.069s
[2K
| Adam | epoch: 012 | loss: 0.54475 - acc: 0.7184 -- iter: 128/285
[A[ATraining Step: 104  | total loss: [1m[32m0.53861[0m[0m | time: 4.963s
[2K
| Adam | epoch: 012 | loss: 0.53861 - acc: 0.7247 -- iter: 160/285
[A[ATraining Step: 105  | total loss: [1m[32m0.52513[0m[0m | time: 5.927s
[2K
| Adam | epoch: 012 | loss: 0.52513 - acc: 0.7366 -- iter: 192/285
[A[ATraining Step: 106  | total loss: [1m[32m0.53583[0m[0m | time: 6.997s
[2K
| Adam | epoch: 012 | loss: 0.53583 - acc: 0.7223 -- iter: 224/285
[A[ATraining Step: 107  | total loss: [1m[32m0.51718[0m[0m | time: 8.057s
[2K
| Adam | epoch: 012 | loss: 0.51718 - acc: 0.7345 -- iter: 256/285
[A[ATraining Step: 108  | total loss: [1m[32m0.50809[0m[0m | time: 10.156s
[2K
| Adam | epoch: 012 | loss: 0.50809 - acc: 0.7485 | val_loss: 0.46912 - val_acc: 0.8000 -- iter: 285/285
--
Training Step: 109  | total loss: [1m[32m0.49017[0m[0m | time: 1.021s
[2K
| Adam | epoch: 013 | loss: 0.49017 - acc: 0.7643 -- iter: 032/285
[A[ATraining Step: 110  | total loss: [1m[32m0.49939[0m[0m | time: 1.979s
[2K
| Adam | epoch: 013 | loss: 0.49939 - acc: 0.7499 -- iter: 064/285
[A[ATraining Step: 111  | total loss: [1m[32m0.49179[0m[0m | time: 2.938s
[2K
| Adam | epoch: 013 | loss: 0.49179 - acc: 0.7611 -- iter: 096/285
[A[ATraining Step: 112  | total loss: [1m[32m0.48136[0m[0m | time: 3.931s
[2K
| Adam | epoch: 013 | loss: 0.48136 - acc: 0.7663 -- iter: 128/285
[A[ATraining Step: 113  | total loss: [1m[32m0.47900[0m[0m | time: 4.988s
[2K
| Adam | epoch: 013 | loss: 0.47900 - acc: 0.7615 -- iter: 160/285
[A[ATraining Step: 114  | total loss: [1m[32m0.46394[0m[0m | time: 6.111s
[2K
| Adam | epoch: 013 | loss: 0.46394 - acc: 0.7698 -- iter: 192/285
[A[ATraining Step: 115  | total loss: [1m[32m0.45204[0m[0m | time: 7.213s
[2K
| Adam | epoch: 013 | loss: 0.45204 - acc: 0.7834 -- iter: 224/285
[A[ATraining Step: 116  | total loss: [1m[32m0.46386[0m[0m | time: 8.151s
[2K
| Adam | epoch: 013 | loss: 0.46386 - acc: 0.7801 -- iter: 256/285
[A[ATraining Step: 117  | total loss: [1m[32m0.45678[0m[0m | time: 10.228s
[2K
| Adam | epoch: 013 | loss: 0.45678 - acc: 0.7833 | val_loss: 0.37343 - val_acc: 0.8444 -- iter: 285/285
--
Training Step: 118  | total loss: [1m[32m0.44196[0m[0m | time: 1.137s
[2K
| Adam | epoch: 014 | loss: 0.44196 - acc: 0.7987 -- iter: 032/285
[A[ATraining Step: 119  | total loss: [1m[32m0.43180[0m[0m | time: 2.017s
[2K
| Adam | epoch: 014 | loss: 0.43180 - acc: 0.8032 -- iter: 064/285
[A[ATraining Step: 120  | total loss: [1m[32m0.42686[0m[0m | time: 3.006s
[2K
| Adam | epoch: 014 | loss: 0.42686 - acc: 0.8022 -- iter: 096/285
[A[ATraining Step: 121  | total loss: [1m[32m0.41788[0m[0m | time: 4.031s
[2K
| Adam | epoch: 014 | loss: 0.41788 - acc: 0.8116 -- iter: 128/285
[A[ATraining Step: 122  | total loss: [1m[32m0.40644[0m[0m | time: 4.991s
[2K
| Adam | epoch: 014 | loss: 0.40644 - acc: 0.8180 -- iter: 160/285
[A[ATraining Step: 123  | total loss: [1m[32m0.39448[0m[0m | time: 6.220s
[2K
| Adam | epoch: 014 | loss: 0.39448 - acc: 0.8299 -- iter: 192/285
[A[ATraining Step: 124  | total loss: [1m[32m0.37328[0m[0m | time: 7.356s
[2K
| Adam | epoch: 014 | loss: 0.37328 - acc: 0.8407 -- iter: 224/285
[A[ATraining Step: 125  | total loss: [1m[32m0.36217[0m[0m | time: 8.402s
[2K
| Adam | epoch: 014 | loss: 0.36217 - acc: 0.8472 -- iter: 256/285
[A[ATraining Step: 126  | total loss: [1m[32m0.36144[0m[0m | time: 10.299s
[2K
| Adam | epoch: 014 | loss: 0.36144 - acc: 0.8500 | val_loss: 0.33127 - val_acc: 0.8778 -- iter: 285/285
--
Training Step: 127  | total loss: [1m[32m0.35600[0m[0m | time: 1.079s
[2K
| Adam | epoch: 015 | loss: 0.35600 - acc: 0.8525 -- iter: 032/285
[A[ATraining Step: 128  | total loss: [1m[32m0.33466[0m[0m | time: 1.943s
[2K
| Adam | epoch: 015 | loss: 0.33466 - acc: 0.8641 -- iter: 064/285
[A[ATraining Step: 129  | total loss: [1m[32m0.32859[0m[0m | time: 2.970s
[2K
| Adam | epoch: 015 | loss: 0.32859 - acc: 0.8715 -- iter: 096/285
[A[ATraining Step: 130  | total loss: [1m[32m0.33131[0m[0m | time: 3.910s
[2K
| Adam | epoch: 015 | loss: 0.33131 - acc: 0.8671 -- iter: 128/285
[A[ATraining Step: 131  | total loss: [1m[32m0.32699[0m[0m | time: 4.852s
[2K
| Adam | epoch: 015 | loss: 0.32699 - acc: 0.8735 -- iter: 160/285
[A[ATraining Step: 132  | total loss: [1m[32m0.31646[0m[0m | time: 5.509s
[2K
| Adam | epoch: 015 | loss: 0.31646 - acc: 0.8768 -- iter: 192/285
[A[ATraining Step: 133  | total loss: [1m[32m0.30825[0m[0m | time: 6.144s
[2K
| Adam | epoch: 015 | loss: 0.30825 - acc: 0.8828 -- iter: 224/285
[A[ATraining Step: 134  | total loss: [1m[32m0.29616[0m[0m | time: 6.828s
[2K
| Adam | epoch: 015 | loss: 0.29616 - acc: 0.8883 -- iter: 256/285
[A[ATraining Step: 135  | total loss: [1m[32m0.28778[0m[0m | time: 8.524s
[2K
| Adam | epoch: 015 | loss: 0.28778 - acc: 0.8932 | val_loss: 0.32204 - val_acc: 0.8667 -- iter: 285/285
--
Training Step: 136  | total loss: [1m[32m0.28101[0m[0m | time: 0.656s
[2K
| Adam | epoch: 016 | loss: 0.28101 - acc: 0.9008 -- iter: 032/285
[A[ATraining Step: 137  | total loss: [1m[32m0.27179[0m[0m | time: 1.277s
[2K
| Adam | epoch: 016 | loss: 0.27179 - acc: 0.9013 -- iter: 064/285
[A[ATraining Step: 138  | total loss: [1m[32m0.27769[0m[0m | time: 1.924s
[2K
| Adam | epoch: 016 | loss: 0.27769 - acc: 0.8987 -- iter: 096/285
[A[ATraining Step: 139  | total loss: [1m[32m0.25600[0m[0m | time: 2.511s
[2K
| Adam | epoch: 016 | loss: 0.25600 - acc: 0.9088 -- iter: 128/285
[A[ATraining Step: 140  | total loss: [1m[32m0.25159[0m[0m | time: 3.116s
[2K
| Adam | epoch: 016 | loss: 0.25159 - acc: 0.9110 -- iter: 160/285
[A[ATraining Step: 141  | total loss: [1m[32m0.24584[0m[0m | time: 3.723s
[2K
| Adam | epoch: 016 | loss: 0.24584 - acc: 0.9130 -- iter: 192/285
[A[ATraining Step: 142  | total loss: [1m[32m0.24844[0m[0m | time: 4.383s
[2K
| Adam | epoch: 016 | loss: 0.24844 - acc: 0.9124 -- iter: 224/285
[A[ATraining Step: 143  | total loss: [1m[32m0.24417[0m[0m | time: 5.004s
[2K
| Adam | epoch: 016 | loss: 0.24417 - acc: 0.9086 -- iter: 256/285
[A[ATraining Step: 144  | total loss: [1m[32m0.22587[0m[0m | time: 6.631s
[2K
| Adam | epoch: 016 | loss: 0.22587 - acc: 0.9178 | val_loss: 0.43400 - val_acc: 0.8333 -- iter: 285/285
--
Training Step: 145  | total loss: [1m[32m0.21128[0m[0m | time: 0.639s
[2K
| Adam | epoch: 017 | loss: 0.21128 - acc: 0.9260 -- iter: 032/285
[A[ATraining Step: 146  | total loss: [1m[32m0.20923[0m[0m | time: 1.280s
[2K
| Adam | epoch: 017 | loss: 0.20923 - acc: 0.9271 -- iter: 064/285
[A[ATraining Step: 147  | total loss: [1m[32m0.21689[0m[0m | time: 1.911s
[2K
| Adam | epoch: 017 | loss: 0.21689 - acc: 0.9250 -- iter: 096/285
[A[ATraining Step: 148  | total loss: [1m[32m0.24029[0m[0m | time: 2.528s
[2K
| Adam | epoch: 017 | loss: 0.24029 - acc: 0.9200 -- iter: 128/285
[A[ATraining Step: 149  | total loss: [1m[32m0.24378[0m[0m | time: 3.121s
[2K
| Adam | epoch: 017 | loss: 0.24378 - acc: 0.9155 -- iter: 160/285
[A[ATraining Step: 150  | total loss: [1m[32m0.23778[0m[0m | time: 3.747s
[2K
| Adam | epoch: 017 | loss: 0.23778 - acc: 0.9171 -- iter: 192/285
[A[ATraining Step: 151  | total loss: [1m[32m0.22154[0m[0m | time: 4.467s
[2K
| Adam | epoch: 017 | loss: 0.22154 - acc: 0.9254 -- iter: 224/285
[A[ATraining Step: 152  | total loss: [1m[32m0.21658[0m[0m | time: 5.392s
[2K
| Adam | epoch: 017 | loss: 0.21658 - acc: 0.9266 -- iter: 256/285
[A[ATraining Step: 153  | total loss: [1m[32m0.20376[0m[0m | time: 7.215s
[2K
| Adam | epoch: 017 | loss: 0.20376 - acc: 0.9339 | val_loss: 0.36364 - val_acc: 0.8667 -- iter: 285/285
--
Training Step: 154  | total loss: [1m[32m0.20756[0m[0m | time: 0.853s
[2K
| Adam | epoch: 018 | loss: 0.20756 - acc: 0.9343 -- iter: 032/285
[A[ATraining Step: 155  | total loss: [1m[32m0.19256[0m[0m | time: 1.761s
[2K
| Adam | epoch: 018 | loss: 0.19256 - acc: 0.9409 -- iter: 064/285
[A[ATraining Step: 156  | total loss: [1m[32m0.18007[0m[0m | time: 2.670s
[2K
| Adam | epoch: 018 | loss: 0.18007 - acc: 0.9468 -- iter: 096/285
[A[ATraining Step: 157  | total loss: [1m[32m0.18413[0m[0m | time: 3.574s
[2K
| Adam | epoch: 018 | loss: 0.18413 - acc: 0.9427 -- iter: 128/285
[A[ATraining Step: 158  | total loss: [1m[32m0.27389[0m[0m | time: 4.765s
[2K
| Adam | epoch: 018 | loss: 0.27389 - acc: 0.9297 -- iter: 160/285
[A[ATraining Step: 159  | total loss: [1m[32m0.26121[0m[0m | time: 5.731s
[2K
| Adam | epoch: 018 | loss: 0.26121 - acc: 0.9305 -- iter: 192/285
[A[ATraining Step: 160  | total loss: [1m[32m0.24032[0m[0m | time: 6.710s
[2K
| Adam | epoch: 018 | loss: 0.24032 - acc: 0.9374 -- iter: 224/285
[A[ATraining Step: 161  | total loss: [1m[32m0.22152[0m[0m | time: 7.543s
[2K
| Adam | epoch: 018 | loss: 0.22152 - acc: 0.9437 -- iter: 256/285
[A[ATraining Step: 162  | total loss: [1m[32m0.21900[0m[0m | time: 9.552s
[2K
| Adam | epoch: 018 | loss: 0.21900 - acc: 0.9431 | val_loss: 0.35101 - val_acc: 0.8556 -- iter: 285/285
--
Training Step: 163  | total loss: [1m[32m0.20165[0m[0m | time: 1.011s
[2K
| Adam | epoch: 019 | loss: 0.20165 - acc: 0.9488 -- iter: 032/285
[A[ATraining Step: 164  | total loss: [1m[32m0.18907[0m[0m | time: 1.957s
[2K
| Adam | epoch: 019 | loss: 0.18907 - acc: 0.9539 -- iter: 064/285
[A[ATraining Step: 165  | total loss: [1m[32m0.17425[0m[0m | time: 3.042s
[2K
| Adam | epoch: 019 | loss: 0.17425 - acc: 0.9585 -- iter: 096/285
[A[ATraining Step: 166  | total loss: [1m[32m0.16561[0m[0m | time: 4.215s
[2K
| Adam | epoch: 019 | loss: 0.16561 - acc: 0.9595 -- iter: 128/285
[A[ATraining Step: 167  | total loss: [1m[32m0.16192[0m[0m | time: 5.168s
[2K
| Adam | epoch: 019 | loss: 0.16192 - acc: 0.9604 -- iter: 160/285
[A[ATraining Step: 168  | total loss: [1m[32m0.19542[0m[0m | time: 6.171s
[2K
| Adam | epoch: 019 | loss: 0.19542 - acc: 0.9550 -- iter: 192/285
[A[ATraining Step: 169  | total loss: [1m[32m0.17940[0m[0m | time: 7.077s
[2K
| Adam | epoch: 019 | loss: 0.17940 - acc: 0.9595 -- iter: 224/285
[A[ATraining Step: 170  | total loss: [1m[32m0.16667[0m[0m | time: 7.983s
[2K
| Adam | epoch: 019 | loss: 0.16667 - acc: 0.9636 -- iter: 256/285
[A[ATraining Step: 171  | total loss: [1m[32m0.15486[0m[0m | time: 10.058s
[2K
| Adam | epoch: 019 | loss: 0.15486 - acc: 0.9672 | val_loss: 0.37265 - val_acc: 0.8667 -- iter: 285/285
--
Training Step: 172  | total loss: [1m[32m0.14437[0m[0m | time: 1.207s
[2K
| Adam | epoch: 020 | loss: 0.14437 - acc: 0.9705 -- iter: 032/285
[A[ATraining Step: 173  | total loss: [1m[32m0.14176[0m[0m | time: 2.124s
[2K
| Adam | epoch: 020 | loss: 0.14176 - acc: 0.9703 -- iter: 064/285
[A[ATraining Step: 174  | total loss: [1m[32m0.13069[0m[0m | time: 3.072s
[2K
| Adam | epoch: 020 | loss: 0.13069 - acc: 0.9733 -- iter: 096/285
[A[ATraining Step: 175  | total loss: [1m[32m0.12658[0m[0m | time: 4.061s
[2K
| Adam | epoch: 020 | loss: 0.12658 - acc: 0.9728 -- iter: 128/285
[A[ATraining Step: 176  | total loss: [1m[32m0.13439[0m[0m | time: 5.038s
[2K
| Adam | epoch: 020 | loss: 0.13439 - acc: 0.9662 -- iter: 160/285
[A[ATraining Step: 177  | total loss: [1m[32m0.13512[0m[0m | time: 6.102s
[2K
| Adam | epoch: 020 | loss: 0.13512 - acc: 0.9633 -- iter: 192/285
[A[ATraining Step: 178  | total loss: [1m[32m0.12333[0m[0m | time: 7.146s
[2K
| Adam | epoch: 020 | loss: 0.12333 - acc: 0.9670 -- iter: 224/285
[A[ATraining Step: 179  | total loss: [1m[32m0.12171[0m[0m | time: 8.054s
[2K
| Adam | epoch: 020 | loss: 0.12171 - acc: 0.9672 -- iter: 256/285
[A[ATraining Step: 180  | total loss: [1m[32m0.14410[0m[0m | time: 10.043s
[2K
| Adam | epoch: 020 | loss: 0.14410 - acc: 0.9566 | val_loss: 0.41266 - val_acc: 0.8444 -- iter: 285/285
--
Training Step: 181  | total loss: [1m[32m0.15300[0m[0m | time: 0.643s
[2K
| Adam | epoch: 021 | loss: 0.15300 - acc: 0.9506 -- iter: 032/285
[A[ATraining Step: 182  | total loss: [1m[32m0.14048[0m[0m | time: 1.307s
[2K
| Adam | epoch: 021 | loss: 0.14048 - acc: 0.9556 -- iter: 064/285
[A[ATraining Step: 183  | total loss: [1m[32m0.13046[0m[0m | time: 1.975s
[2K
| Adam | epoch: 021 | loss: 0.13046 - acc: 0.9600 -- iter: 096/285
[A[ATraining Step: 184  | total loss: [1m[32m0.12578[0m[0m | time: 2.591s
[2K
| Adam | epoch: 021 | loss: 0.12578 - acc: 0.9609 -- iter: 128/285
[A[ATraining Step: 185  | total loss: [1m[32m0.12921[0m[0m | time: 3.249s
[2K
| Adam | epoch: 021 | loss: 0.12921 - acc: 0.9554 -- iter: 160/285
[A[ATraining Step: 186  | total loss: [1m[32m0.11967[0m[0m | time: 3.854s
[2K
| Adam | epoch: 021 | loss: 0.11967 - acc: 0.9599 -- iter: 192/285
[A[ATraining Step: 187  | total loss: [1m[32m0.11007[0m[0m | time: 4.485s
[2K
| Adam | epoch: 021 | loss: 0.11007 - acc: 0.9639 -- iter: 224/285
[A[ATraining Step: 188  | total loss: [1m[32m0.17914[0m[0m | time: 5.123s
[2K
| Adam | epoch: 021 | loss: 0.17914 - acc: 0.9488 -- iter: 256/285
[A[ATraining Step: 189  | total loss: [1m[32m0.17896[0m[0m | time: 6.728s
[2K
| Adam | epoch: 021 | loss: 0.17896 - acc: 0.9476 | val_loss: 0.41807 - val_acc: 0.8556 -- iter: 285/285
--
Training Step: 190  | total loss: [1m[32m0.16791[0m[0m | time: 0.614s
[2K
| Adam | epoch: 022 | loss: 0.16791 - acc: 0.9529 -- iter: 032/285
[A[ATraining Step: 191  | total loss: [1m[32m0.15406[0m[0m | time: 1.228s
[2K
| Adam | epoch: 022 | loss: 0.15406 - acc: 0.9576 -- iter: 064/285
[A[ATraining Step: 192  | total loss: [1m[32m0.14738[0m[0m | time: 1.846s
[2K
| Adam | epoch: 022 | loss: 0.14738 - acc: 0.9587 -- iter: 096/285
[A[ATraining Step: 193  | total loss: [1m[32m0.13715[0m[0m | time: 2.492s
[2K
| Adam | epoch: 022 | loss: 0.13715 - acc: 0.9628 -- iter: 128/285
[A[ATraining Step: 194  | total loss: [1m[32m0.13667[0m[0m | time: 3.126s
[2K
| Adam | epoch: 022 | loss: 0.13667 - acc: 0.9634 -- iter: 160/285
[A[ATraining Step: 195  | total loss: [1m[32m0.13519[0m[0m | time: 3.743s
[2K
| Adam | epoch: 022 | loss: 0.13519 - acc: 0.9640 -- iter: 192/285
[A[ATraining Step: 196  | total loss: [1m[32m0.12781[0m[0m | time: 4.396s
[2K
| Adam | epoch: 022 | loss: 0.12781 - acc: 0.9644 -- iter: 224/285
[A[ATraining Step: 197  | total loss: [1m[32m0.12082[0m[0m | time: 5.052s
[2K
| Adam | epoch: 022 | loss: 0.12082 - acc: 0.9680 -- iter: 256/285
[A[ATraining Step: 198  | total loss: [1m[32m0.13641[0m[0m | time: 6.676s
[2K
| Adam | epoch: 022 | loss: 0.13641 - acc: 0.9649 | val_loss: 0.39568 - val_acc: 0.8444 -- iter: 285/285
--
Training Step: 199  | total loss: [1m[32m0.12968[0m[0m | time: 0.566s
[2K
| Adam | epoch: 023 | loss: 0.12968 - acc: 0.9653 -- iter: 032/285
[A[ATraining Step: 200  | total loss: [1m[32m0.12293[0m[0m | time: 2.146s
[2K
| Adam | epoch: 023 | loss: 0.12293 - acc: 0.9688 | val_loss: 0.30037 - val_acc: 0.8667 -- iter: 064/285
--
Training Step: 201  | total loss: [1m[32m0.11380[0m[0m | time: 3.243s
[2K
| Adam | epoch: 023 | loss: 0.11380 - acc: 0.9719 -- iter: 096/285
[A[ATraining Step: 202  | total loss: [1m[32m0.10504[0m[0m | time: 4.127s
[2K
| Adam | epoch: 023 | loss: 0.10504 - acc: 0.9747 -- iter: 128/285
[A[ATraining Step: 203  | total loss: [1m[32m0.10066[0m[0m | time: 5.094s
[2K
| Adam | epoch: 023 | loss: 0.10066 - acc: 0.9741 -- iter: 160/285
[A[ATraining Step: 204  | total loss: [1m[32m0.09340[0m[0m | time: 6.212s
[2K
| Adam | epoch: 023 | loss: 0.09340 - acc: 0.9767 -- iter: 192/285
[A[ATraining Step: 205  | total loss: [1m[32m0.08624[0m[0m | time: 7.227s
[2K
| Adam | epoch: 023 | loss: 0.08624 - acc: 0.9790 -- iter: 224/285
[A[ATraining Step: 206  | total loss: [1m[32m0.07960[0m[0m | time: 8.373s
[2K
| Adam | epoch: 023 | loss: 0.07960 - acc: 0.9811 -- iter: 256/285
[A[ATraining Step: 207  | total loss: [1m[32m0.07508[0m[0m | time: 10.403s
[2K
| Adam | epoch: 023 | loss: 0.07508 - acc: 0.9830 | val_loss: 0.37737 - val_acc: 0.8556 -- iter: 285/285
--
Training Step: 208  | total loss: [1m[32m0.07060[0m[0m | time: 0.874s
[2K
| Adam | epoch: 024 | loss: 0.07060 - acc: 0.9847 -- iter: 032/285
[A[ATraining Step: 209  | total loss: [1m[32m0.06477[0m[0m | time: 1.771s
[2K
| Adam | epoch: 024 | loss: 0.06477 - acc: 0.9862 -- iter: 064/285
[A[ATraining Step: 210  | total loss: [1m[32m0.05910[0m[0m | time: 2.604s
[2K
| Adam | epoch: 024 | loss: 0.05910 - acc: 0.9876 -- iter: 096/285
[A[ATraining Step: 211  | total loss: [1m[32m0.05393[0m[0m | time: 3.550s
[2K
| Adam | epoch: 024 | loss: 0.05393 - acc: 0.9889 -- iter: 128/285
[A[ATraining Step: 212  | total loss: [1m[32m0.04904[0m[0m | time: 4.461s
[2K
| Adam | epoch: 024 | loss: 0.04904 - acc: 0.9900 -- iter: 160/285
[A[ATraining Step: 213  | total loss: [1m[32m0.04472[0m[0m | time: 5.414s
[2K
| Adam | epoch: 024 | loss: 0.04472 - acc: 0.9910 -- iter: 192/285
[A[ATraining Step: 214  | total loss: [1m[32m0.04065[0m[0m | time: 6.527s
[2K
| Adam | epoch: 024 | loss: 0.04065 - acc: 0.9919 -- iter: 224/285
[A[ATraining Step: 215  | total loss: [1m[32m0.03715[0m[0m | time: 7.648s
[2K
| Adam | epoch: 024 | loss: 0.03715 - acc: 0.9927 -- iter: 256/285
[A[ATraining Step: 216  | total loss: [1m[32m0.03441[0m[0m | time: 9.630s
[2K
| Adam | epoch: 024 | loss: 0.03441 - acc: 0.9934 | val_loss: 0.43777 - val_acc: 0.8667 -- iter: 285/285
--
Training Step: 217  | total loss: [1m[32m0.03162[0m[0m | time: 1.087s
[2K
| Adam | epoch: 025 | loss: 0.03162 - acc: 0.9941 -- iter: 032/285
[A[ATraining Step: 218  | total loss: [1m[32m0.05010[0m[0m | time: 2.187s
[2K
| Adam | epoch: 025 | loss: 0.05010 - acc: 0.9915 -- iter: 064/285
[A[ATraining Step: 219  | total loss: [1m[32m0.04557[0m[0m | time: 3.075s
[2K
| Adam | epoch: 025 | loss: 0.04557 - acc: 0.9924 -- iter: 096/285
[A[ATraining Step: 220  | total loss: [1m[32m0.04203[0m[0m | time: 4.044s
[2K
| Adam | epoch: 025 | loss: 0.04203 - acc: 0.9932 -- iter: 128/285
[A[ATraining Step: 221  | total loss: [1m[32m0.03876[0m[0m | time: 5.155s
[2K
| Adam | epoch: 025 | loss: 0.03876 - acc: 0.9938 -- iter: 160/285
[A[ATraining Step: 222  | total loss: [1m[32m0.03582[0m[0m | time: 6.177s
[2K
| Adam | epoch: 025 | loss: 0.03582 - acc: 0.9945 -- iter: 192/285
[A[ATraining Step: 223  | total loss: [1m[32m0.03290[0m[0m | time: 7.062s
[2K
| Adam | epoch: 025 | loss: 0.03290 - acc: 0.9950 -- iter: 224/285
[A[ATraining Step: 224  | total loss: [1m[32m0.02999[0m[0m | time: 8.065s
[2K
| Adam | epoch: 025 | loss: 0.02999 - acc: 0.9955 -- iter: 256/285
[A[ATraining Step: 225  | total loss: [1m[32m0.02734[0m[0m | time: 10.076s
[2K
| Adam | epoch: 025 | loss: 0.02734 - acc: 0.9960 | val_loss: 0.53141 - val_acc: 0.8444 -- iter: 285/285
--
Training Step: 226  | total loss: [1m[32m0.02488[0m[0m | time: 1.063s
[2K
| Adam | epoch: 026 | loss: 0.02488 - acc: 0.9964 -- iter: 032/285
[A[ATraining Step: 227  | total loss: [1m[32m0.02437[0m[0m | time: 2.147s
[2K
| Adam | epoch: 026 | loss: 0.02437 - acc: 0.9967 -- iter: 064/285
[A[ATraining Step: 228  | total loss: [1m[32m0.04238[0m[0m | time: 2.932s
[2K
| Adam | epoch: 026 | loss: 0.04238 - acc: 0.9939 -- iter: 096/285
[A[ATraining Step: 229  | total loss: [1m[32m0.03873[0m[0m | time: 3.528s
[2K
| Adam | epoch: 026 | loss: 0.03873 - acc: 0.9945 -- iter: 128/285
[A[ATraining Step: 230  | total loss: [1m[32m0.03573[0m[0m | time: 4.151s
[2K
| Adam | epoch: 026 | loss: 0.03573 - acc: 0.9951 -- iter: 160/285
[A[ATraining Step: 231  | total loss: [1m[32m0.03277[0m[0m | time: 4.777s
[2K
| Adam | epoch: 026 | loss: 0.03277 - acc: 0.9956 -- iter: 192/285
[A[ATraining Step: 232  | total loss: [1m[32m0.03023[0m[0m | time: 5.419s
[2K
| Adam | epoch: 026 | loss: 0.03023 - acc: 0.9960 -- iter: 224/285
[A[ATraining Step: 233  | total loss: [1m[32m0.02837[0m[0m | time: 6.039s
[2K
| Adam | epoch: 026 | loss: 0.02837 - acc: 0.9964 -- iter: 256/285
[A[ATraining Step: 234  | total loss: [1m[32m0.02576[0m[0m | time: 7.682s
[2K
| Adam | epoch: 026 | loss: 0.02576 - acc: 0.9968 | val_loss: 0.39818 - val_acc: 0.8444 -- iter: 285/285
--
Training Step: 235  | total loss: [1m[32m0.02360[0m[0m | time: 0.804s
[2K
| Adam | epoch: 027 | loss: 0.02360 - acc: 0.9971 -- iter: 032/285
[A[ATraining Step: 236  | total loss: [1m[32m0.02180[0m[0m | time: 1.419s
[2K
| Adam | epoch: 027 | loss: 0.02180 - acc: 0.9974 -- iter: 064/285
[A[ATraining Step: 237  | total loss: [1m[32m0.02044[0m[0m | time: 2.072s
[2K
| Adam | epoch: 027 | loss: 0.02044 - acc: 0.9976 -- iter: 096/285
[A[ATraining Step: 238  | total loss: [1m[32m0.01924[0m[0m | time: 2.702s
[2K
| Adam | epoch: 027 | loss: 0.01924 - acc: 0.9979 -- iter: 128/285
[A[ATraining Step: 239  | total loss: [1m[32m0.01773[0m[0m | time: 3.268s
[2K
| Adam | epoch: 027 | loss: 0.01773 - acc: 0.9981 -- iter: 160/285
[A[ATraining Step: 240  | total loss: [1m[32m0.01629[0m[0m | time: 3.838s
[2K
| Adam | epoch: 027 | loss: 0.01629 - acc: 0.9983 -- iter: 192/285
[A[ATraining Step: 241  | total loss: [1m[32m0.01490[0m[0m | time: 4.484s
[2K
| Adam | epoch: 027 | loss: 0.01490 - acc: 0.9985 -- iter: 224/285
[A[ATraining Step: 242  | total loss: [1m[32m0.01359[0m[0m | time: 5.104s
[2K
| Adam | epoch: 027 | loss: 0.01359 - acc: 0.9986 -- iter: 256/285
[A[ATraining Step: 243  | total loss: [1m[32m0.01254[0m[0m | time: 6.713s
[2K
| Adam | epoch: 027 | loss: 0.01254 - acc: 0.9987 | val_loss: 0.40680 - val_acc: 0.8778 -- iter: 285/285
--
Training Step: 244  | total loss: [1m[32m0.01217[0m[0m | time: 0.619s
[2K
| Adam | epoch: 028 | loss: 0.01217 - acc: 0.9989 -- iter: 032/285
[A[ATraining Step: 245  | total loss: [1m[32m0.01115[0m[0m | time: 1.275s
[2K
| Adam | epoch: 028 | loss: 0.01115 - acc: 0.9990 -- iter: 064/285
[A[ATraining Step: 246  | total loss: [1m[32m0.01024[0m[0m | time: 1.909s
[2K
| Adam | epoch: 028 | loss: 0.01024 - acc: 0.9991 -- iter: 096/285
[A[ATraining Step: 247  | total loss: [1m[32m0.00965[0m[0m | time: 2.566s
[2K
| Adam | epoch: 028 | loss: 0.00965 - acc: 0.9992 -- iter: 128/285
[A[ATraining Step: 248  | total loss: [1m[32m0.02872[0m[0m | time: 3.319s
[2K
| Adam | epoch: 028 | loss: 0.02872 - acc: 0.9961 -- iter: 160/285
[A[ATraining Step: 249  | total loss: [1m[32m0.02637[0m[0m | time: 4.376s
[2K
| Adam | epoch: 028 | loss: 0.02637 - acc: 0.9965 -- iter: 192/285
[A[ATraining Step: 250  | total loss: [1m[32m0.02527[0m[0m | time: 5.414s
[2K
| Adam | epoch: 028 | loss: 0.02527 - acc: 0.9969 -- iter: 224/285
[A[ATraining Step: 251  | total loss: [1m[32m0.02485[0m[0m | time: 6.363s
[2K
| Adam | epoch: 028 | loss: 0.02485 - acc: 0.9972 -- iter: 256/285
[A[ATraining Step: 252  | total loss: [1m[32m0.02287[0m[0m | time: 8.253s
[2K
| Adam | epoch: 028 | loss: 0.02287 - acc: 0.9975 | val_loss: 0.38404 - val_acc: 0.8889 -- iter: 285/285
--
Training Step: 253  | total loss: [1m[32m0.02287[0m[0m | time: 0.895s
[2K
| Adam | epoch: 029 | loss: 0.02287 - acc: 0.9977 -- iter: 032/285
[A[ATraining Step: 254  | total loss: [1m[32m0.02069[0m[0m | time: 1.898s
[2K
| Adam | epoch: 029 | loss: 0.02069 - acc: 0.9979 -- iter: 064/285
[A[ATraining Step: 255  | total loss: [1m[32m0.01878[0m[0m | time: 2.975s
[2K
| Adam | epoch: 029 | loss: 0.01878 - acc: 0.9982 -- iter: 096/285
[A[ATraining Step: 256  | total loss: [1m[32m0.01748[0m[0m | time: 4.150s
[2K
| Adam | epoch: 029 | loss: 0.01748 - acc: 0.9983 -- iter: 128/285
[A[ATraining Step: 257  | total loss: [1m[32m0.02139[0m[0m | time: 5.026s
[2K
| Adam | epoch: 029 | loss: 0.02139 - acc: 0.9954 -- iter: 160/285
[A[ATraining Step: 258  | total loss: [1m[32m0.01961[0m[0m | time: 6.087s
[2K
| Adam | epoch: 029 | loss: 0.01961 - acc: 0.9958 -- iter: 192/285
[A[ATraining Step: 259  | total loss: [1m[32m0.01781[0m[0m | time: 6.982s
[2K
| Adam | epoch: 029 | loss: 0.01781 - acc: 0.9963 -- iter: 224/285
[A[ATraining Step: 260  | total loss: [1m[32m0.01618[0m[0m | time: 7.904s
[2K
| Adam | epoch: 029 | loss: 0.01618 - acc: 0.9966 -- iter: 256/285
[A[ATraining Step: 261  | total loss: [1m[32m0.01481[0m[0m | time: 10.039s
[2K
| Adam | epoch: 029 | loss: 0.01481 - acc: 0.9970 | val_loss: 0.52589 - val_acc: 0.8667 -- iter: 285/285
--
Training Step: 262  | total loss: [1m[32m0.01414[0m[0m | time: 0.962s
[2K
| Adam | epoch: 030 | loss: 0.01414 - acc: 0.9973 -- iter: 032/285
[A[ATraining Step: 263  | total loss: [1m[32m0.01307[0m[0m | time: 1.893s
[2K
| Adam | epoch: 030 | loss: 0.01307 - acc: 0.9975 -- iter: 064/285
[A[ATraining Step: 264  | total loss: [1m[32m0.01377[0m[0m | time: 2.809s
[2K
| Adam | epoch: 030 | loss: 0.01377 - acc: 0.9978 -- iter: 096/285
[A[ATraining Step: 265  | total loss: [1m[32m0.01308[0m[0m | time: 3.731s
[2K
| Adam | epoch: 030 | loss: 0.01308 - acc: 0.9980 -- iter: 128/285
[A[ATraining Step: 266  | total loss: [1m[32m0.01196[0m[0m | time: 4.685s
[2K
| Adam | epoch: 030 | loss: 0.01196 - acc: 0.9982 -- iter: 160/285
[A[ATraining Step: 267  | total loss: [1m[32m0.01095[0m[0m | time: 5.501s
[2K
| Adam | epoch: 030 | loss: 0.01095 - acc: 0.9984 -- iter: 192/285
[A[ATraining Step: 268  | total loss: [1m[32m0.04863[0m[0m | time: 6.434s
[2K
| Adam | epoch: 030 | loss: 0.04863 - acc: 0.9954 -- iter: 224/285
[A[ATraining Step: 269  | total loss: [1m[32m0.04432[0m[0m | time: 7.309s
[2K
| Adam | epoch: 030 | loss: 0.04432 - acc: 0.9959 -- iter: 256/285
[A[ATraining Step: 270  | total loss: [1m[32m0.04042[0m[0m | time: 9.173s
[2K
| Adam | epoch: 030 | loss: 0.04042 - acc: 0.9963 | val_loss: 0.88790 - val_acc: 0.8111 -- iter: 285/285
--
Validation AUC:0.919
Validation AUPRC:0.9304339670352211
Test AUC:0.9666500746640119
Test AUPRC:0.961222494937871
BestTestF1Score	0.89	0.8	0.9	0.86	0.93	38	6	43	3	0.01
BestTestMCCScore	0.88	0.78	0.89	0.86	0.9	37	6	43	4	0.02
BestTestAccuracyScore	0.88	0.78	0.89	0.86	0.9	37	6	43	4	0.02
BestValidationF1Score	0.87	0.71	0.86	0.89	0.84	42	5	35	8	0.01
BestValidationMCC	0.86	0.72	0.86	0.91	0.82	41	4	36	9	0.02
BestValidationAccuracy	0.86	0.72	0.86	0.91	0.82	41	4	36	9	0.02
TestPredictions (Threshold:0.02)
CHEMBL173453,FP,INACT,0.03999999910593033	CHEMBL2381116,TN,INACT,0.0	CHEMBL3682432,TP,ACT,0.09000000357627869	CHEMBL558601,TN,INACT,0.0	CHEMBL3687155,TP,ACT,0.9700000286102295	CHEMBL1784649,TN,INACT,0.0	CHEMBL2207217,FN,ACT,0.0	CHEMBL2207220,TP,ACT,1.0	CHEMBL3687122,TP,ACT,0.9900000095367432	CHEMBL2207195,TP,ACT,0.2199999988079071	CHEMBL3687110,TP,ACT,0.8700000047683716	CHEMBL99779,TN,INACT,0.0	CHEMBL3125726,TP,ACT,0.9399999976158142	CHEMBL3687166,TP,ACT,0.12999999523162842	CHEMBL3125727,TP,ACT,0.9900000095367432	CHEMBL1801932,FP,INACT,0.05000000074505806	CHEMBL1240703,TP,ACT,0.8100000023841858	CHEMBL2207206,TP,ACT,0.8799999952316284	CHEMBL490241,TN,INACT,0.0	CHEMBL2158866,FP,INACT,0.9800000190734863	CHEMBL3687180,TP,ACT,1.0	CHEMBL3687142,TP,ACT,1.0	CHEMBL100312,FP,INACT,0.029999999329447746	CHEMBL169757,TN,INACT,0.0	CHEMBL495758,TN,INACT,0.0	CHEMBL3691660,TN,INACT,0.0	CHEMBL2011903,TP,ACT,0.9900000095367432	CHEMBL2207198,TP,ACT,1.0	CHEMBL328627,TN,INACT,0.0	CHEMBL3687175,TP,ACT,1.0	CHEMBL1288069,TN,INACT,0.0	CHEMBL1257164,TN,INACT,0.0	CHEMBL487526,TN,INACT,0.0	CHEMBL3687117,TP,ACT,0.9900000095367432	CHEMBL1910759,TN,INACT,0.0	CHEMBL489627,TN,INACT,0.0	CHEMBL551663,TN,INACT,0.0	CHEMBL3687113,TP,ACT,1.0	CHEMBL335938,TN,INACT,0.0	CHEMBL551722,FP,INACT,0.03999999910593033	CHEMBL2207183,TP,ACT,0.07000000029802322	CHEMBL3125731,TP,ACT,0.9399999976158142	CHEMBL523780,TN,INACT,0.0	CHEMBL264667,TN,INACT,0.0	CHEMBL3687185,TP,ACT,0.9800000190734863	CHEMBL1784660,TN,INACT,0.0	CHEMBL318461,TN,INACT,0.0	CHEMBL3682434,FN,ACT,0.019999999552965164	CHEMBL2011916,TP,ACT,0.9800000190734863	CHEMBL172973,TN,INACT,0.0	CHEMBL563948,TN,INACT,0.0	CHEMBL78223,TN,INACT,0.0	CHEMBL452812,TN,INACT,0.0	CHEMBL3682421,TP,ACT,1.0	CHEMBL3687187,TP,ACT,0.9900000095367432	CHEMBL509499,TN,INACT,0.0	CHEMBL509435,TN,INACT,0.0	CHEMBL557525,TN,INACT,0.0	CHEMBL601719,TP,ACT,0.09000000357627869	CHEMBL3687168,TP,ACT,0.28999999165534973	CHEMBL488646,TN,INACT,0.0	CHEMBL178133,TN,INACT,0.0	CHEMBL1287975,TN,INACT,0.0	CHEMBL77155,TN,INACT,0.009999999776482582	CHEMBL572878,TP,ACT,0.28999999165534973	CHEMBL2312652,TN,INACT,0.0	CHEMBL2207215,TP,ACT,1.0	CHEMBL482919,TN,INACT,0.0	CHEMBL551936,TN,INACT,0.0	CHEMBL463384,TN,INACT,0.0	CHEMBL1767275,TN,INACT,0.0	CHEMBL515356,TN,INACT,0.0	CHEMBL3639713,TN,INACT,0.0	CHEMBL2011936,TP,ACT,1.0	CHEMBL2011940,TP,ACT,1.0	CHEMBL3687176,TP,ACT,0.9900000095367432	CHEMBL559683,TN,INACT,0.0	CHEMBL3125729,TP,ACT,0.9900000095367432	CHEMBL178397,FP,INACT,0.4699999988079071	CHEMBL1922210,TN,INACT,0.0	CHEMBL3687127,TP,ACT,0.029999999329447746	CHEMBL486487,TN,INACT,0.0	CHEMBL2207204,FN,ACT,0.009999999776482582	CHEMBL2207192,TP,ACT,0.8799999952316284	CHEMBL2011904,FN,ACT,0.009999999776482582	CHEMBL2011902,TP,ACT,0.9900000095367432	CHEMBL523938,TN,INACT,0.0	CHEMBL458076,TN,INACT,0.0	CHEMBL3687149,TP,ACT,0.9800000190734863	CHEMBL2207196,TP,ACT,0.75	

