CNNModel CHEMBL1875 adam 0.0005 15 128 0 0.8 False True
Number of active compounds :	473
Number of inactive compounds :	473
---------------------------------
Run id: CNNModel_CHEMBL1875_adam_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1875_adam_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 588
Validation samples: 184
--
Training Step: 1  | time: 1.459s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/588
[A[ATraining Step: 2  | total loss: [1m[32m0.62361[0m[0m | time: 9.223s
[2K
| Adam | epoch: 001 | loss: 0.62361 - acc: 0.5625 -- iter: 064/588
[A[ATraining Step: 3  | total loss: [1m[32m0.68006[0m[0m | time: 29.560s
[2K
| Adam | epoch: 001 | loss: 0.68006 - acc: 0.5369 -- iter: 096/588
[A[ATraining Step: 4  | total loss: [1m[32m0.68304[0m[0m | time: 53.004s
[2K
| Adam | epoch: 001 | loss: 0.68304 - acc: 0.6733 -- iter: 128/588
[A[ATraining Step: 5  | total loss: [1m[32m0.68601[0m[0m | time: 72.177s
[2K
| Adam | epoch: 001 | loss: 0.68601 - acc: 0.5966 -- iter: 160/588
[A[ATraining Step: 6  | total loss: [1m[32m0.69653[0m[0m | time: 81.202s
[2K
| Adam | epoch: 001 | loss: 0.69653 - acc: 0.5144 -- iter: 192/588
[A[ATraining Step: 7  | total loss: [1m[32m0.69615[0m[0m | time: 85.438s
[2K
| Adam | epoch: 001 | loss: 0.69615 - acc: 0.5058 -- iter: 224/588
[A[ATraining Step: 8  | total loss: [1m[32m0.69692[0m[0m | time: 91.203s
[2K
| Adam | epoch: 001 | loss: 0.69692 - acc: 0.5025 -- iter: 256/588
[A[ATraining Step: 9  | total loss: [1m[32m0.69743[0m[0m | time: 98.852s
[2K
| Adam | epoch: 001 | loss: 0.69743 - acc: 0.4846 -- iter: 288/588
[A[ATraining Step: 10  | total loss: [1m[32m0.69714[0m[0m | time: 99.868s
[2K
| Adam | epoch: 001 | loss: 0.69714 - acc: 0.4767 -- iter: 320/588
[A[ATraining Step: 11  | total loss: [1m[32m0.69371[0m[0m | time: 100.968s
[2K
| Adam | epoch: 001 | loss: 0.69371 - acc: 0.5173 -- iter: 352/588
[A[ATraining Step: 12  | total loss: [1m[32m0.69565[0m[0m | time: 114.577s
[2K
| Adam | epoch: 001 | loss: 0.69565 - acc: 0.4533 -- iter: 384/588
[A[ATraining Step: 13  | total loss: [1m[32m0.69429[0m[0m | time: 117.235s
[2K
| Adam | epoch: 001 | loss: 0.69429 - acc: 0.4867 -- iter: 416/588
[A[ATraining Step: 14  | total loss: [1m[32m0.69335[0m[0m | time: 118.470s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.5305 -- iter: 448/588
[A[ATraining Step: 15  | total loss: [1m[32m0.69345[0m[0m | time: 119.492s
[2K
| Adam | epoch: 001 | loss: 0.69345 - acc: 0.4941 -- iter: 480/588
[A[ATraining Step: 16  | total loss: [1m[32m0.69354[0m[0m | time: 120.668s
[2K
| Adam | epoch: 001 | loss: 0.69354 - acc: 0.4729 -- iter: 512/588
[A[ATraining Step: 17  | total loss: [1m[32m0.69353[0m[0m | time: 126.948s
[2K
| Adam | epoch: 001 | loss: 0.69353 - acc: 0.4489 -- iter: 544/588
[A[ATraining Step: 18  | total loss: [1m[32m0.69338[0m[0m | time: 140.669s
[2K
| Adam | epoch: 001 | loss: 0.69338 - acc: 0.4774 -- iter: 576/588
[A[ATraining Step: 19  | total loss: [1m[32m0.69360[0m[0m | time: 187.477s
[2K
| Adam | epoch: 001 | loss: 0.69360 - acc: 0.4433 | val_loss: 0.69308 - val_acc: 0.5109 -- iter: 588/588
--
Training Step: 20  | total loss: [1m[32m0.69369[0m[0m | time: 0.445s
[2K
| Adam | epoch: 002 | loss: 0.69369 - acc: 0.4079 -- iter: 032/588
[A[ATraining Step: 21  | total loss: [1m[32m0.69361[0m[0m | time: 9.587s
[2K
| Adam | epoch: 002 | loss: 0.69361 - acc: 0.4106 -- iter: 064/588
[A[ATraining Step: 22  | total loss: [1m[32m0.69365[0m[0m | time: 10.708s
[2K
| Adam | epoch: 002 | loss: 0.69365 - acc: 0.4093 -- iter: 096/588
[A[ATraining Step: 23  | total loss: [1m[32m0.69320[0m[0m | time: 22.134s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.4629 -- iter: 128/588
[A[ATraining Step: 24  | total loss: [1m[32m0.69331[0m[0m | time: 23.430s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4645 -- iter: 160/588
[A[ATraining Step: 25  | total loss: [1m[32m0.69372[0m[0m | time: 24.711s
[2K
| Adam | epoch: 002 | loss: 0.69372 - acc: 0.4401 -- iter: 192/588
[A[ATraining Step: 26  | total loss: [1m[32m0.69344[0m[0m | time: 25.906s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.4642 -- iter: 224/588
[A[ATraining Step: 27  | total loss: [1m[32m0.69258[0m[0m | time: 33.440s
[2K
| Adam | epoch: 002 | loss: 0.69258 - acc: 0.5297 -- iter: 256/588
[A[ATraining Step: 28  | total loss: [1m[32m0.69322[0m[0m | time: 59.816s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4910 -- iter: 288/588
[A[ATraining Step: 29  | total loss: [1m[32m0.69294[0m[0m | time: 72.776s
[2K
| Adam | epoch: 002 | loss: 0.69294 - acc: 0.5084 -- iter: 320/588
[A[ATraining Step: 30  | total loss: [1m[32m0.69313[0m[0m | time: 80.315s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.4990 -- iter: 352/588
[A[ATraining Step: 31  | total loss: [1m[32m0.69338[0m[0m | time: 101.418s
[2K
| Adam | epoch: 002 | loss: 0.69338 - acc: 0.4848 -- iter: 384/588
[A[ATraining Step: 32  | total loss: [1m[32m0.69360[0m[0m | time: 110.012s
[2K
| Adam | epoch: 002 | loss: 0.69360 - acc: 0.4742 -- iter: 416/588
[A[ATraining Step: 33  | total loss: [1m[32m0.69369[0m[0m | time: 111.029s
[2K
| Adam | epoch: 002 | loss: 0.69369 - acc: 0.4661 -- iter: 448/588
[A[ATraining Step: 34  | total loss: [1m[32m0.69396[0m[0m | time: 112.644s
[2K
| Adam | epoch: 002 | loss: 0.69396 - acc: 0.4466 -- iter: 480/588
[A[ATraining Step: 35  | total loss: [1m[32m0.69346[0m[0m | time: 113.697s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.4839 -- iter: 512/588
[A[ATraining Step: 36  | total loss: [1m[32m0.69337[0m[0m | time: 114.745s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4872 -- iter: 544/588
[A[ATraining Step: 37  | total loss: [1m[32m0.69292[0m[0m | time: 119.864s
[2K
| Adam | epoch: 002 | loss: 0.69292 - acc: 0.5273 -- iter: 576/588
[A[ATraining Step: 38  | total loss: [1m[32m0.69308[0m[0m | time: 132.372s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5097 | val_loss: 0.69313 - val_acc: 0.4891 -- iter: 588/588
--
Training Step: 39  | total loss: [1m[32m0.69322[0m[0m | time: 0.486s
[2K
| Adam | epoch: 003 | loss: 0.69322 - acc: 0.4959 -- iter: 032/588
[A[ATraining Step: 40  | total loss: [1m[32m0.69275[0m[0m | time: 0.891s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5279 -- iter: 064/588
[A[ATraining Step: 41  | total loss: [1m[32m0.69230[0m[0m | time: 2.087s
[2K
| Adam | epoch: 003 | loss: 0.69230 - acc: 0.5534 -- iter: 096/588
[A[ATraining Step: 42  | total loss: [1m[32m0.69235[0m[0m | time: 2.959s
[2K
| Adam | epoch: 003 | loss: 0.69235 - acc: 0.5494 -- iter: 128/588
[A[ATraining Step: 43  | total loss: [1m[32m0.69209[0m[0m | time: 5.225s
[2K
| Adam | epoch: 003 | loss: 0.69209 - acc: 0.5572 -- iter: 160/588
[A[ATraining Step: 44  | total loss: [1m[32m0.69229[0m[0m | time: 16.994s
[2K
| Adam | epoch: 003 | loss: 0.69229 - acc: 0.5473 -- iter: 192/588
[A[ATraining Step: 45  | total loss: [1m[32m0.69212[0m[0m | time: 20.921s
[2K
| Adam | epoch: 003 | loss: 0.69212 - acc: 0.5499 -- iter: 224/588
[A[ATraining Step: 46  | total loss: [1m[32m0.69190[0m[0m | time: 21.811s
[2K
| Adam | epoch: 003 | loss: 0.69190 - acc: 0.5520 -- iter: 256/588
[A[ATraining Step: 47  | total loss: [1m[32m0.69235[0m[0m | time: 22.817s
[2K
| Adam | epoch: 003 | loss: 0.69235 - acc: 0.5384 -- iter: 288/588
[A[ATraining Step: 48  | total loss: [1m[32m0.69225[0m[0m | time: 23.701s
[2K
| Adam | epoch: 003 | loss: 0.69225 - acc: 0.5372 -- iter: 320/588
[A[ATraining Step: 49  | total loss: [1m[32m0.69269[0m[0m | time: 24.584s
[2K
| Adam | epoch: 003 | loss: 0.69269 - acc: 0.5264 -- iter: 352/588
[A[ATraining Step: 50  | total loss: [1m[32m0.69280[0m[0m | time: 25.547s
[2K
| Adam | epoch: 003 | loss: 0.69280 - acc: 0.5223 -- iter: 384/588
[A[ATraining Step: 51  | total loss: [1m[32m0.69346[0m[0m | time: 26.479s
[2K
| Adam | epoch: 003 | loss: 0.69346 - acc: 0.5094 -- iter: 416/588
[A[ATraining Step: 52  | total loss: [1m[32m0.69326[0m[0m | time: 27.383s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.5127 -- iter: 448/588
[A[ATraining Step: 53  | total loss: [1m[32m0.69398[0m[0m | time: 28.336s
[2K
| Adam | epoch: 003 | loss: 0.69398 - acc: 0.4970 -- iter: 480/588
[A[ATraining Step: 54  | total loss: [1m[32m0.69428[0m[0m | time: 29.238s
[2K
| Adam | epoch: 003 | loss: 0.69428 - acc: 0.4883 -- iter: 512/588
[A[ATraining Step: 55  | total loss: [1m[32m0.69389[0m[0m | time: 30.336s
[2K
| Adam | epoch: 003 | loss: 0.69389 - acc: 0.4945 -- iter: 544/588
[A[ATraining Step: 56  | total loss: [1m[32m0.69392[0m[0m | time: 31.466s
[2K
| Adam | epoch: 003 | loss: 0.69392 - acc: 0.4908 -- iter: 576/588
[A[ATraining Step: 57  | total loss: [1m[32m0.69333[0m[0m | time: 33.976s
[2K
| Adam | epoch: 003 | loss: 0.69333 - acc: 0.5051 | val_loss: 0.69319 - val_acc: 0.4891 -- iter: 588/588
--
Training Step: 58  | total loss: [1m[32m0.69355[0m[0m | time: 0.974s
[2K
| Adam | epoch: 004 | loss: 0.69355 - acc: 0.4959 -- iter: 032/588
[A[ATraining Step: 59  | total loss: [1m[32m0.69303[0m[0m | time: 1.356s
[2K
| Adam | epoch: 004 | loss: 0.69303 - acc: 0.5090 -- iter: 064/588
[A[ATraining Step: 60  | total loss: [1m[32m0.69344[0m[0m | time: 1.732s
[2K
| Adam | epoch: 004 | loss: 0.69344 - acc: 0.4968 -- iter: 096/588
[A[ATraining Step: 61  | total loss: [1m[32m0.69373[0m[0m | time: 2.681s
[2K
| Adam | epoch: 004 | loss: 0.69373 - acc: 0.4863 -- iter: 128/588
[A[ATraining Step: 62  | total loss: [1m[32m0.69398[0m[0m | time: 3.668s
[2K
| Adam | epoch: 004 | loss: 0.69398 - acc: 0.4760 -- iter: 160/588
[A[ATraining Step: 63  | total loss: [1m[32m0.69371[0m[0m | time: 4.648s
[2K
| Adam | epoch: 004 | loss: 0.69371 - acc: 0.4830 -- iter: 192/588
[A[ATraining Step: 64  | total loss: [1m[32m0.69370[0m[0m | time: 5.552s
[2K
| Adam | epoch: 004 | loss: 0.69370 - acc: 0.4813 -- iter: 224/588
[A[ATraining Step: 65  | total loss: [1m[32m0.69342[0m[0m | time: 6.705s
[2K
| Adam | epoch: 004 | loss: 0.69342 - acc: 0.4913 -- iter: 256/588
[A[ATraining Step: 66  | total loss: [1m[32m0.69298[0m[0m | time: 7.804s
[2K
| Adam | epoch: 004 | loss: 0.69298 - acc: 0.5037 -- iter: 288/588
[A[ATraining Step: 67  | total loss: [1m[32m0.69254[0m[0m | time: 8.569s
[2K
| Adam | epoch: 004 | loss: 0.69254 - acc: 0.5145 -- iter: 320/588
[A[ATraining Step: 68  | total loss: [1m[32m0.69216[0m[0m | time: 9.443s
[2K
| Adam | epoch: 004 | loss: 0.69216 - acc: 0.5202 -- iter: 352/588
[A[ATraining Step: 69  | total loss: [1m[32m0.69170[0m[0m | time: 10.360s
[2K
| Adam | epoch: 004 | loss: 0.69170 - acc: 0.5252 -- iter: 384/588
[A[ATraining Step: 70  | total loss: [1m[32m0.69234[0m[0m | time: 11.315s
[2K
| Adam | epoch: 004 | loss: 0.69234 - acc: 0.5078 -- iter: 416/588
[A[ATraining Step: 71  | total loss: [1m[32m0.69195[0m[0m | time: 12.235s
[2K
| Adam | epoch: 004 | loss: 0.69195 - acc: 0.5141 -- iter: 448/588
[A[ATraining Step: 72  | total loss: [1m[32m0.69226[0m[0m | time: 13.201s
[2K
| Adam | epoch: 004 | loss: 0.69226 - acc: 0.5019 -- iter: 480/588
[A[ATraining Step: 73  | total loss: [1m[32m0.69172[0m[0m | time: 14.237s
[2K
| Adam | epoch: 004 | loss: 0.69172 - acc: 0.5087 -- iter: 512/588
[A[ATraining Step: 74  | total loss: [1m[32m0.69141[0m[0m | time: 15.187s
[2K
| Adam | epoch: 004 | loss: 0.69141 - acc: 0.5043 -- iter: 544/588
[A[ATraining Step: 75  | total loss: [1m[32m0.68977[0m[0m | time: 16.001s
[2K
| Adam | epoch: 004 | loss: 0.68977 - acc: 0.5241 -- iter: 576/588
[A[ATraining Step: 76  | total loss: [1m[32m0.68920[0m[0m | time: 18.287s
[2K
| Adam | epoch: 004 | loss: 0.68920 - acc: 0.5216 | val_loss: 0.68158 - val_acc: 0.4891 -- iter: 588/588
--
Training Step: 77  | total loss: [1m[32m0.68876[0m[0m | time: 0.916s
[2K
| Adam | epoch: 005 | loss: 0.68876 - acc: 0.5193 -- iter: 032/588
[A[ATraining Step: 78  | total loss: [1m[32m0.68904[0m[0m | time: 1.839s
[2K
| Adam | epoch: 005 | loss: 0.68904 - acc: 0.5075 -- iter: 064/588
[A[ATraining Step: 79  | total loss: [1m[32m0.68954[0m[0m | time: 2.216s
[2K
| Adam | epoch: 005 | loss: 0.68954 - acc: 0.4970 -- iter: 096/588
[A[ATraining Step: 80  | total loss: [1m[32m0.68804[0m[0m | time: 2.609s
[2K
| Adam | epoch: 005 | loss: 0.68804 - acc: 0.5229 -- iter: 128/588
[A[ATraining Step: 81  | total loss: [1m[32m0.68636[0m[0m | time: 3.553s
[2K
| Adam | epoch: 005 | loss: 0.68636 - acc: 0.5458 -- iter: 160/588
[A[ATraining Step: 82  | total loss: [1m[32m0.68566[0m[0m | time: 4.494s
[2K
| Adam | epoch: 005 | loss: 0.68566 - acc: 0.5569 -- iter: 192/588
[A[ATraining Step: 83  | total loss: [1m[32m0.68274[0m[0m | time: 5.394s
[2K
| Adam | epoch: 005 | loss: 0.68274 - acc: 0.5668 -- iter: 224/588
[A[ATraining Step: 84  | total loss: [1m[32m0.67816[0m[0m | time: 6.417s
[2K
| Adam | epoch: 005 | loss: 0.67816 - acc: 0.5883 -- iter: 256/588
[A[ATraining Step: 85  | total loss: [1m[32m0.67129[0m[0m | time: 7.265s
[2K
| Adam | epoch: 005 | loss: 0.67129 - acc: 0.5919 -- iter: 288/588
[A[ATraining Step: 86  | total loss: [1m[32m0.67162[0m[0m | time: 8.426s
[2K
| Adam | epoch: 005 | loss: 0.67162 - acc: 0.5859 -- iter: 320/588
[A[ATraining Step: 87  | total loss: [1m[32m0.66389[0m[0m | time: 9.574s
[2K
| Adam | epoch: 005 | loss: 0.66389 - acc: 0.6023 -- iter: 352/588
[A[ATraining Step: 88  | total loss: [1m[32m0.65492[0m[0m | time: 10.457s
[2K
| Adam | epoch: 005 | loss: 0.65492 - acc: 0.6264 -- iter: 384/588
[A[ATraining Step: 89  | total loss: [1m[32m0.65658[0m[0m | time: 11.331s
[2K
| Adam | epoch: 005 | loss: 0.65658 - acc: 0.6169 -- iter: 416/588
[A[ATraining Step: 90  | total loss: [1m[32m0.64027[0m[0m | time: 12.291s
[2K
| Adam | epoch: 005 | loss: 0.64027 - acc: 0.6396 -- iter: 448/588
[A[ATraining Step: 91  | total loss: [1m[32m0.65397[0m[0m | time: 13.204s
[2K
| Adam | epoch: 005 | loss: 0.65397 - acc: 0.6413 -- iter: 480/588
[A[ATraining Step: 92  | total loss: [1m[32m0.64387[0m[0m | time: 14.119s
[2K
| Adam | epoch: 005 | loss: 0.64387 - acc: 0.6459 -- iter: 512/588
[A[ATraining Step: 93  | total loss: [1m[32m0.64578[0m[0m | time: 15.089s
[2K
| Adam | epoch: 005 | loss: 0.64578 - acc: 0.6469 -- iter: 544/588
[A[ATraining Step: 94  | total loss: [1m[32m0.64009[0m[0m | time: 16.011s
[2K
| Adam | epoch: 005 | loss: 0.64009 - acc: 0.6572 -- iter: 576/588
[A[ATraining Step: 95  | total loss: [1m[32m0.62832[0m[0m | time: 17.965s
[2K
| Adam | epoch: 005 | loss: 0.62832 - acc: 0.6728 | val_loss: 0.68029 - val_acc: 0.5815 -- iter: 588/588
--
Training Step: 96  | total loss: [1m[32m0.62285[0m[0m | time: 0.960s
[2K
| Adam | epoch: 006 | loss: 0.62285 - acc: 0.6774 -- iter: 032/588
[A[ATraining Step: 97  | total loss: [1m[32m0.62412[0m[0m | time: 1.798s
[2K
| Adam | epoch: 006 | loss: 0.62412 - acc: 0.6690 -- iter: 064/588
[A[ATraining Step: 98  | total loss: [1m[32m0.62621[0m[0m | time: 2.725s
[2K
| Adam | epoch: 006 | loss: 0.62621 - acc: 0.6583 -- iter: 096/588
[A[ATraining Step: 99  | total loss: [1m[32m0.62543[0m[0m | time: 3.102s
[2K
| Adam | epoch: 006 | loss: 0.62543 - acc: 0.6613 -- iter: 128/588
[A[ATraining Step: 100  | total loss: [1m[32m0.63057[0m[0m | time: 3.496s
[2K
| Adam | epoch: 006 | loss: 0.63057 - acc: 0.6451 -- iter: 160/588
[A[ATraining Step: 101  | total loss: [1m[32m0.63605[0m[0m | time: 4.423s
[2K
| Adam | epoch: 006 | loss: 0.63605 - acc: 0.6390 -- iter: 192/588
[A[ATraining Step: 102  | total loss: [1m[32m0.62436[0m[0m | time: 5.392s
[2K
| Adam | epoch: 006 | loss: 0.62436 - acc: 0.6532 -- iter: 224/588
[A[ATraining Step: 103  | total loss: [1m[32m0.61535[0m[0m | time: 6.367s
[2K
| Adam | epoch: 006 | loss: 0.61535 - acc: 0.6691 -- iter: 256/588
[A[ATraining Step: 104  | total loss: [1m[32m0.61628[0m[0m | time: 7.406s
[2K
| Adam | epoch: 006 | loss: 0.61628 - acc: 0.6678 -- iter: 288/588
[A[ATraining Step: 105  | total loss: [1m[32m0.61836[0m[0m | time: 8.353s
[2K
| Adam | epoch: 006 | loss: 0.61836 - acc: 0.6667 -- iter: 320/588
[A[ATraining Step: 106  | total loss: [1m[32m0.61620[0m[0m | time: 9.346s
[2K
| Adam | epoch: 006 | loss: 0.61620 - acc: 0.6688 -- iter: 352/588
[A[ATraining Step: 107  | total loss: [1m[32m0.60908[0m[0m | time: 10.412s
[2K
| Adam | epoch: 006 | loss: 0.60908 - acc: 0.6706 -- iter: 384/588
[A[ATraining Step: 108  | total loss: [1m[32m0.61721[0m[0m | time: 11.565s
[2K
| Adam | epoch: 006 | loss: 0.61721 - acc: 0.6661 -- iter: 416/588
[A[ATraining Step: 109  | total loss: [1m[32m0.61185[0m[0m | time: 12.346s
[2K
| Adam | epoch: 006 | loss: 0.61185 - acc: 0.6713 -- iter: 448/588
[A[ATraining Step: 110  | total loss: [1m[32m0.60115[0m[0m | time: 13.289s
[2K
| Adam | epoch: 006 | loss: 0.60115 - acc: 0.6761 -- iter: 480/588
[A[ATraining Step: 111  | total loss: [1m[32m0.60664[0m[0m | time: 14.233s
[2K
| Adam | epoch: 006 | loss: 0.60664 - acc: 0.6710 -- iter: 512/588
[A[ATraining Step: 112  | total loss: [1m[32m0.60280[0m[0m | time: 15.221s
[2K
| Adam | epoch: 006 | loss: 0.60280 - acc: 0.6695 -- iter: 544/588
[A[ATraining Step: 113  | total loss: [1m[32m0.61133[0m[0m | time: 16.156s
[2K
| Adam | epoch: 006 | loss: 0.61133 - acc: 0.6650 -- iter: 576/588
[A[ATraining Step: 114  | total loss: [1m[32m0.60456[0m[0m | time: 18.177s
[2K
| Adam | epoch: 006 | loss: 0.60456 - acc: 0.6735 | val_loss: 0.53880 - val_acc: 0.7446 -- iter: 588/588
--
Training Step: 115  | total loss: [1m[32m0.59592[0m[0m | time: 0.963s
[2K
| Adam | epoch: 007 | loss: 0.59592 - acc: 0.6874 -- iter: 032/588
[A[ATraining Step: 116  | total loss: [1m[32m0.59113[0m[0m | time: 2.225s
[2K
| Adam | epoch: 007 | loss: 0.59113 - acc: 0.6874 -- iter: 064/588
[A[ATraining Step: 117  | total loss: [1m[32m0.58809[0m[0m | time: 3.248s
[2K
| Adam | epoch: 007 | loss: 0.58809 - acc: 0.6906 -- iter: 096/588
[A[ATraining Step: 118  | total loss: [1m[32m0.58243[0m[0m | time: 6.464s
[2K
| Adam | epoch: 007 | loss: 0.58243 - acc: 0.6965 -- iter: 128/588
[A[ATraining Step: 119  | total loss: [1m[32m0.57560[0m[0m | time: 6.852s
[2K
| Adam | epoch: 007 | loss: 0.57560 - acc: 0.7050 -- iter: 160/588
[A[ATraining Step: 120  | total loss: [1m[32m0.58052[0m[0m | time: 7.203s
[2K
| Adam | epoch: 007 | loss: 0.58052 - acc: 0.6928 -- iter: 192/588
[A[ATraining Step: 121  | total loss: [1m[32m0.58195[0m[0m | time: 8.179s
[2K
| Adam | epoch: 007 | loss: 0.58195 - acc: 0.6819 -- iter: 224/588
[A[ATraining Step: 122  | total loss: [1m[32m0.57031[0m[0m | time: 9.075s
[2K
| Adam | epoch: 007 | loss: 0.57031 - acc: 0.6949 -- iter: 256/588
[A[ATraining Step: 123  | total loss: [1m[32m0.54263[0m[0m | time: 9.998s
[2K
| Adam | epoch: 007 | loss: 0.54263 - acc: 0.7223 -- iter: 288/588
[A[ATraining Step: 124  | total loss: [1m[32m0.54679[0m[0m | time: 10.953s
[2K
| Adam | epoch: 007 | loss: 0.54679 - acc: 0.7188 -- iter: 320/588
[A[ATraining Step: 125  | total loss: [1m[32m0.54441[0m[0m | time: 12.016s
[2K
| Adam | epoch: 007 | loss: 0.54441 - acc: 0.7188 -- iter: 352/588
[A[ATraining Step: 126  | total loss: [1m[32m0.53929[0m[0m | time: 12.936s
[2K
| Adam | epoch: 007 | loss: 0.53929 - acc: 0.7251 -- iter: 384/588
[A[ATraining Step: 127  | total loss: [1m[32m0.53231[0m[0m | time: 13.811s
[2K
| Adam | epoch: 007 | loss: 0.53231 - acc: 0.7307 -- iter: 416/588
[A[ATraining Step: 128  | total loss: [1m[32m0.54891[0m[0m | time: 14.975s
[2K
| Adam | epoch: 007 | loss: 0.54891 - acc: 0.7295 -- iter: 448/588
[A[ATraining Step: 129  | total loss: [1m[32m0.54282[0m[0m | time: 16.126s
[2K
| Adam | epoch: 007 | loss: 0.54282 - acc: 0.7378 -- iter: 480/588
[A[ATraining Step: 130  | total loss: [1m[32m0.55891[0m[0m | time: 17.014s
[2K
| Adam | epoch: 007 | loss: 0.55891 - acc: 0.7234 -- iter: 512/588
[A[ATraining Step: 131  | total loss: [1m[32m0.55047[0m[0m | time: 18.600s
[2K
| Adam | epoch: 007 | loss: 0.55047 - acc: 0.7323 -- iter: 544/588
[A[ATraining Step: 132  | total loss: [1m[32m0.55111[0m[0m | time: 19.439s
[2K
| Adam | epoch: 007 | loss: 0.55111 - acc: 0.7278 -- iter: 576/588
[A[ATraining Step: 133  | total loss: [1m[32m0.54975[0m[0m | time: 21.452s
[2K
| Adam | epoch: 007 | loss: 0.54975 - acc: 0.7238 | val_loss: 0.49993 - val_acc: 0.7935 -- iter: 588/588
--
Training Step: 134  | total loss: [1m[32m0.54377[0m[0m | time: 1.058s
[2K
| Adam | epoch: 008 | loss: 0.54377 - acc: 0.7295 -- iter: 032/588
[A[ATraining Step: 135  | total loss: [1m[32m0.53769[0m[0m | time: 2.025s
[2K
| Adam | epoch: 008 | loss: 0.53769 - acc: 0.7410 -- iter: 064/588
[A[ATraining Step: 136  | total loss: [1m[32m0.52096[0m[0m | time: 3.002s
[2K
| Adam | epoch: 008 | loss: 0.52096 - acc: 0.7544 -- iter: 096/588
[A[ATraining Step: 137  | total loss: [1m[32m0.51947[0m[0m | time: 3.859s
[2K
| Adam | epoch: 008 | loss: 0.51947 - acc: 0.7508 -- iter: 128/588
[A[ATraining Step: 138  | total loss: [1m[32m0.52687[0m[0m | time: 4.999s
[2K
| Adam | epoch: 008 | loss: 0.52687 - acc: 0.7507 -- iter: 160/588
[A[ATraining Step: 139  | total loss: [1m[32m0.52821[0m[0m | time: 5.468s
[2K
| Adam | epoch: 008 | loss: 0.52821 - acc: 0.7475 -- iter: 192/588
[A[ATraining Step: 140  | total loss: [1m[32m0.52871[0m[0m | time: 5.916s
[2K
| Adam | epoch: 008 | loss: 0.52871 - acc: 0.7478 -- iter: 224/588
[A[ATraining Step: 141  | total loss: [1m[32m0.52613[0m[0m | time: 6.757s
[2K
| Adam | epoch: 008 | loss: 0.52613 - acc: 0.7480 -- iter: 256/588
[A[ATraining Step: 142  | total loss: [1m[32m0.52610[0m[0m | time: 7.627s
[2K
| Adam | epoch: 008 | loss: 0.52610 - acc: 0.7451 -- iter: 288/588
[A[ATraining Step: 143  | total loss: [1m[32m0.51850[0m[0m | time: 8.532s
[2K
| Adam | epoch: 008 | loss: 0.51850 - acc: 0.7518 -- iter: 320/588
[A[ATraining Step: 144  | total loss: [1m[32m0.51113[0m[0m | time: 9.464s
[2K
| Adam | epoch: 008 | loss: 0.51113 - acc: 0.7579 -- iter: 352/588
[A[ATraining Step: 145  | total loss: [1m[32m0.49330[0m[0m | time: 10.379s
[2K
| Adam | epoch: 008 | loss: 0.49330 - acc: 0.7696 -- iter: 384/588
[A[ATraining Step: 146  | total loss: [1m[32m0.49733[0m[0m | time: 11.391s
[2K
| Adam | epoch: 008 | loss: 0.49733 - acc: 0.7770 -- iter: 416/588
[A[ATraining Step: 147  | total loss: [1m[32m0.48413[0m[0m | time: 12.398s
[2K
| Adam | epoch: 008 | loss: 0.48413 - acc: 0.7806 -- iter: 448/588
[A[ATraining Step: 148  | total loss: [1m[32m0.47605[0m[0m | time: 13.395s
[2K
| Adam | epoch: 008 | loss: 0.47605 - acc: 0.7869 -- iter: 480/588
[A[ATraining Step: 149  | total loss: [1m[32m0.48288[0m[0m | time: 14.298s
[2K
| Adam | epoch: 008 | loss: 0.48288 - acc: 0.7832 -- iter: 512/588
[A[ATraining Step: 150  | total loss: [1m[32m0.47421[0m[0m | time: 15.370s
[2K
| Adam | epoch: 008 | loss: 0.47421 - acc: 0.7924 -- iter: 544/588
[A[ATraining Step: 151  | total loss: [1m[32m0.47075[0m[0m | time: 16.474s
[2K
| Adam | epoch: 008 | loss: 0.47075 - acc: 0.7913 -- iter: 576/588
[A[ATraining Step: 152  | total loss: [1m[32m0.47777[0m[0m | time: 18.456s
[2K
| Adam | epoch: 008 | loss: 0.47777 - acc: 0.7871 | val_loss: 0.44707 - val_acc: 0.7826 -- iter: 588/588
--
Training Step: 153  | total loss: [1m[32m0.47762[0m[0m | time: 0.970s
[2K
| Adam | epoch: 009 | loss: 0.47762 - acc: 0.7803 -- iter: 032/588
[A[ATraining Step: 154  | total loss: [1m[32m0.47250[0m[0m | time: 1.894s
[2K
| Adam | epoch: 009 | loss: 0.47250 - acc: 0.7866 -- iter: 064/588
[A[ATraining Step: 155  | total loss: [1m[32m0.46829[0m[0m | time: 2.809s
[2K
| Adam | epoch: 009 | loss: 0.46829 - acc: 0.7830 -- iter: 096/588
[A[ATraining Step: 156  | total loss: [1m[32m0.45399[0m[0m | time: 3.792s
[2K
| Adam | epoch: 009 | loss: 0.45399 - acc: 0.7922 -- iter: 128/588
[A[ATraining Step: 157  | total loss: [1m[32m0.47798[0m[0m | time: 4.764s
[2K
| Adam | epoch: 009 | loss: 0.47798 - acc: 0.7755 -- iter: 160/588
[A[ATraining Step: 158  | total loss: [1m[32m0.47673[0m[0m | time: 5.638s
[2K
| Adam | epoch: 009 | loss: 0.47673 - acc: 0.7698 -- iter: 192/588
[A[ATraining Step: 159  | total loss: [1m[32m0.47027[0m[0m | time: 5.980s
[2K
| Adam | epoch: 009 | loss: 0.47027 - acc: 0.7741 -- iter: 224/588
[A[ATraining Step: 160  | total loss: [1m[32m0.46923[0m[0m | time: 6.349s
[2K
| Adam | epoch: 009 | loss: 0.46923 - acc: 0.7717 -- iter: 256/588
[A[ATraining Step: 161  | total loss: [1m[32m0.47439[0m[0m | time: 7.458s
[2K
| Adam | epoch: 009 | loss: 0.47439 - acc: 0.7695 -- iter: 288/588
[A[ATraining Step: 162  | total loss: [1m[32m0.46701[0m[0m | time: 8.641s
[2K
| Adam | epoch: 009 | loss: 0.46701 - acc: 0.7738 -- iter: 320/588
[A[ATraining Step: 163  | total loss: [1m[32m0.44635[0m[0m | time: 9.419s
[2K
| Adam | epoch: 009 | loss: 0.44635 - acc: 0.7902 -- iter: 352/588
[A[ATraining Step: 164  | total loss: [1m[32m0.44208[0m[0m | time: 10.363s
[2K
| Adam | epoch: 009 | loss: 0.44208 - acc: 0.7893 -- iter: 384/588
[A[ATraining Step: 165  | total loss: [1m[32m0.44116[0m[0m | time: 11.374s
[2K
| Adam | epoch: 009 | loss: 0.44116 - acc: 0.7885 -- iter: 416/588
[A[ATraining Step: 166  | total loss: [1m[32m0.42164[0m[0m | time: 12.291s
[2K
| Adam | epoch: 009 | loss: 0.42164 - acc: 0.8002 -- iter: 448/588
[A[ATraining Step: 167  | total loss: [1m[32m0.41513[0m[0m | time: 13.327s
[2K
| Adam | epoch: 009 | loss: 0.41513 - acc: 0.8015 -- iter: 480/588
[A[ATraining Step: 168  | total loss: [1m[32m0.40670[0m[0m | time: 14.341s
[2K
| Adam | epoch: 009 | loss: 0.40670 - acc: 0.8088 -- iter: 512/588
[A[ATraining Step: 169  | total loss: [1m[32m0.38702[0m[0m | time: 15.261s
[2K
| Adam | epoch: 009 | loss: 0.38702 - acc: 0.8154 -- iter: 544/588
[A[ATraining Step: 170  | total loss: [1m[32m0.38836[0m[0m | time: 16.189s
[2K
| Adam | epoch: 009 | loss: 0.38836 - acc: 0.8120 -- iter: 576/588
[A[ATraining Step: 171  | total loss: [1m[32m0.40548[0m[0m | time: 18.283s
[2K
| Adam | epoch: 009 | loss: 0.40548 - acc: 0.8027 | val_loss: 0.39908 - val_acc: 0.8370 -- iter: 588/588
--
Training Step: 172  | total loss: [1m[32m0.42087[0m[0m | time: 0.740s
[2K
| Adam | epoch: 010 | loss: 0.42087 - acc: 0.7912 -- iter: 032/588
[A[ATraining Step: 173  | total loss: [1m[32m0.42652[0m[0m | time: 1.590s
[2K
| Adam | epoch: 010 | loss: 0.42652 - acc: 0.7871 -- iter: 064/588
[A[ATraining Step: 174  | total loss: [1m[32m0.41029[0m[0m | time: 2.531s
[2K
| Adam | epoch: 010 | loss: 0.41029 - acc: 0.7959 -- iter: 096/588
[A[ATraining Step: 175  | total loss: [1m[32m0.40056[0m[0m | time: 3.407s
[2K
| Adam | epoch: 010 | loss: 0.40056 - acc: 0.8006 -- iter: 128/588
[A[ATraining Step: 176  | total loss: [1m[32m0.40452[0m[0m | time: 4.295s
[2K
| Adam | epoch: 010 | loss: 0.40452 - acc: 0.8050 -- iter: 160/588
[A[ATraining Step: 177  | total loss: [1m[32m0.40313[0m[0m | time: 5.253s
[2K
| Adam | epoch: 010 | loss: 0.40313 - acc: 0.8120 -- iter: 192/588
[A[ATraining Step: 178  | total loss: [1m[32m0.38972[0m[0m | time: 6.331s
[2K
| Adam | epoch: 010 | loss: 0.38972 - acc: 0.8214 -- iter: 224/588
[A[ATraining Step: 179  | total loss: [1m[32m0.39864[0m[0m | time: 6.678s
[2K
| Adam | epoch: 010 | loss: 0.39864 - acc: 0.8174 -- iter: 256/588
[A[ATraining Step: 180  | total loss: [1m[32m0.40943[0m[0m | time: 7.018s
[2K
| Adam | epoch: 010 | loss: 0.40943 - acc: 0.8106 -- iter: 288/588
[A[ATraining Step: 181  | total loss: [1m[32m0.41784[0m[0m | time: 7.884s
[2K
| Adam | epoch: 010 | loss: 0.41784 - acc: 0.8129 -- iter: 320/588
[A[ATraining Step: 182  | total loss: [1m[32m0.40895[0m[0m | time: 8.981s
[2K
| Adam | epoch: 010 | loss: 0.40895 - acc: 0.8066 -- iter: 352/588
[A[ATraining Step: 183  | total loss: [1m[32m0.40652[0m[0m | time: 10.088s
[2K
| Adam | epoch: 010 | loss: 0.40652 - acc: 0.8072 -- iter: 384/588
[A[ATraining Step: 184  | total loss: [1m[32m0.38796[0m[0m | time: 10.873s
[2K
| Adam | epoch: 010 | loss: 0.38796 - acc: 0.8202 -- iter: 416/588
[A[ATraining Step: 185  | total loss: [1m[32m0.37870[0m[0m | time: 11.742s
[2K
| Adam | epoch: 010 | loss: 0.37870 - acc: 0.8288 -- iter: 448/588
[A[ATraining Step: 186  | total loss: [1m[32m0.38150[0m[0m | time: 12.688s
[2K
| Adam | epoch: 010 | loss: 0.38150 - acc: 0.8335 -- iter: 480/588
[A[ATraining Step: 187  | total loss: [1m[32m0.39297[0m[0m | time: 13.635s
[2K
| Adam | epoch: 010 | loss: 0.39297 - acc: 0.8282 -- iter: 512/588
[A[ATraining Step: 188  | total loss: [1m[32m0.44001[0m[0m | time: 14.578s
[2K
| Adam | epoch: 010 | loss: 0.44001 - acc: 0.8110 -- iter: 544/588
[A[ATraining Step: 189  | total loss: [1m[32m0.43165[0m[0m | time: 15.537s
[2K
| Adam | epoch: 010 | loss: 0.43165 - acc: 0.8143 -- iter: 576/588
[A[ATraining Step: 190  | total loss: [1m[32m0.41725[0m[0m | time: 17.508s
[2K
| Adam | epoch: 010 | loss: 0.41725 - acc: 0.8235 | val_loss: 0.44158 - val_acc: 0.8261 -- iter: 588/588
--
Training Step: 191  | total loss: [1m[32m0.41500[0m[0m | time: 0.979s
[2K
| Adam | epoch: 011 | loss: 0.41500 - acc: 0.8255 -- iter: 032/588
[A[ATraining Step: 192  | total loss: [1m[32m0.40166[0m[0m | time: 2.073s
[2K
| Adam | epoch: 011 | loss: 0.40166 - acc: 0.8398 -- iter: 064/588
[A[ATraining Step: 193  | total loss: [1m[32m0.41174[0m[0m | time: 3.094s
[2K
| Adam | epoch: 011 | loss: 0.41174 - acc: 0.8309 -- iter: 096/588
[A[ATraining Step: 194  | total loss: [1m[32m0.41148[0m[0m | time: 3.867s
[2K
| Adam | epoch: 011 | loss: 0.41148 - acc: 0.8322 -- iter: 128/588
[A[ATraining Step: 195  | total loss: [1m[32m0.40372[0m[0m | time: 4.702s
[2K
| Adam | epoch: 011 | loss: 0.40372 - acc: 0.8333 -- iter: 160/588
[A[ATraining Step: 196  | total loss: [1m[32m0.38746[0m[0m | time: 5.631s
[2K
| Adam | epoch: 011 | loss: 0.38746 - acc: 0.8469 -- iter: 192/588
[A[ATraining Step: 197  | total loss: [1m[32m0.38123[0m[0m | time: 6.538s
[2K
| Adam | epoch: 011 | loss: 0.38123 - acc: 0.8497 -- iter: 224/588
[A[ATraining Step: 198  | total loss: [1m[32m0.37187[0m[0m | time: 7.431s
[2K
| Adam | epoch: 011 | loss: 0.37187 - acc: 0.8553 -- iter: 256/588
[A[ATraining Step: 199  | total loss: [1m[32m0.35814[0m[0m | time: 7.802s
[2K
| Adam | epoch: 011 | loss: 0.35814 - acc: 0.8604 -- iter: 288/588
[A[ATraining Step: 200  | total loss: [1m[32m0.33924[0m[0m | time: 9.185s
[2K
| Adam | epoch: 011 | loss: 0.33924 - acc: 0.8744 | val_loss: 0.34054 - val_acc: 0.8696 -- iter: 320/588
--
Training Step: 201  | total loss: [1m[32m0.31938[0m[0m | time: 10.004s
[2K
| Adam | epoch: 011 | loss: 0.31938 - acc: 0.8869 -- iter: 352/588
[A[ATraining Step: 202  | total loss: [1m[32m0.30461[0m[0m | time: 11.087s
[2K
| Adam | epoch: 011 | loss: 0.30461 - acc: 0.8920 -- iter: 384/588
[A[ATraining Step: 203  | total loss: [1m[32m0.30079[0m[0m | time: 12.366s
[2K
| Adam | epoch: 011 | loss: 0.30079 - acc: 0.8934 -- iter: 416/588
[A[ATraining Step: 204  | total loss: [1m[32m0.29249[0m[0m | time: 25.356s
[2K
| Adam | epoch: 011 | loss: 0.29249 - acc: 0.8916 -- iter: 448/588
[A[ATraining Step: 205  | total loss: [1m[32m0.30256[0m[0m | time: 26.252s
[2K
| Adam | epoch: 011 | loss: 0.30256 - acc: 0.8837 -- iter: 480/588
[A[ATraining Step: 206  | total loss: [1m[32m0.29289[0m[0m | time: 27.203s
[2K
| Adam | epoch: 011 | loss: 0.29289 - acc: 0.8859 -- iter: 512/588
[A[ATraining Step: 207  | total loss: [1m[32m0.27394[0m[0m | time: 28.143s
[2K
| Adam | epoch: 011 | loss: 0.27394 - acc: 0.8942 -- iter: 544/588
[A[ATraining Step: 208  | total loss: [1m[32m0.28393[0m[0m | time: 29.132s
[2K
| Adam | epoch: 011 | loss: 0.28393 - acc: 0.8954 -- iter: 576/588
[A[ATraining Step: 209  | total loss: [1m[32m0.29732[0m[0m | time: 31.055s
[2K
| Adam | epoch: 011 | loss: 0.29732 - acc: 0.8902 | val_loss: 0.30996 - val_acc: 0.8696 -- iter: 588/588
--
Training Step: 210  | total loss: [1m[32m0.27888[0m[0m | time: 0.875s
[2K
| Adam | epoch: 012 | loss: 0.27888 - acc: 0.8981 -- iter: 032/588
[A[ATraining Step: 211  | total loss: [1m[32m0.28086[0m[0m | time: 1.722s
[2K
| Adam | epoch: 012 | loss: 0.28086 - acc: 0.8958 -- iter: 064/588
[A[ATraining Step: 212  | total loss: [1m[32m0.27189[0m[0m | time: 2.802s
[2K
| Adam | epoch: 012 | loss: 0.27189 - acc: 0.9000 -- iter: 096/588
[A[ATraining Step: 213  | total loss: [1m[32m0.25957[0m[0m | time: 3.862s
[2K
| Adam | epoch: 012 | loss: 0.25957 - acc: 0.9037 -- iter: 128/588
[A[ATraining Step: 214  | total loss: [1m[32m0.24387[0m[0m | time: 5.783s
[2K
| Adam | epoch: 012 | loss: 0.24387 - acc: 0.9071 -- iter: 160/588
[A[ATraining Step: 215  | total loss: [1m[32m0.23370[0m[0m | time: 6.651s
[2K
| Adam | epoch: 012 | loss: 0.23370 - acc: 0.9070 -- iter: 192/588
[A[ATraining Step: 216  | total loss: [1m[32m0.22920[0m[0m | time: 7.599s
[2K
| Adam | epoch: 012 | loss: 0.22920 - acc: 0.9069 -- iter: 224/588
[A[ATraining Step: 217  | total loss: [1m[32m0.21775[0m[0m | time: 8.535s
[2K
| Adam | epoch: 012 | loss: 0.21775 - acc: 0.9162 -- iter: 256/588
[A[ATraining Step: 218  | total loss: [1m[32m0.20673[0m[0m | time: 9.439s
[2K
| Adam | epoch: 012 | loss: 0.20673 - acc: 0.9246 -- iter: 288/588
[A[ATraining Step: 219  | total loss: [1m[32m0.21393[0m[0m | time: 9.866s
[2K
| Adam | epoch: 012 | loss: 0.21393 - acc: 0.9228 -- iter: 320/588
[A[ATraining Step: 220  | total loss: [1m[32m0.20824[0m[0m | time: 10.259s
[2K
| Adam | epoch: 012 | loss: 0.20824 - acc: 0.9222 -- iter: 352/588
[A[ATraining Step: 221  | total loss: [1m[32m0.19809[0m[0m | time: 11.230s
[2K
| Adam | epoch: 012 | loss: 0.19809 - acc: 0.9216 -- iter: 384/588
[A[ATraining Step: 222  | total loss: [1m[32m0.18671[0m[0m | time: 12.266s
[2K
| Adam | epoch: 012 | loss: 0.18671 - acc: 0.9295 -- iter: 416/588
[A[ATraining Step: 223  | total loss: [1m[32m0.18356[0m[0m | time: 13.145s
[2K
| Adam | epoch: 012 | loss: 0.18356 - acc: 0.9334 -- iter: 448/588
[A[ATraining Step: 224  | total loss: [1m[32m0.19584[0m[0m | time: 14.181s
[2K
| Adam | epoch: 012 | loss: 0.19584 - acc: 0.9244 -- iter: 480/588
[A[ATraining Step: 225  | total loss: [1m[32m0.19374[0m[0m | time: 15.361s
[2K
| Adam | epoch: 012 | loss: 0.19374 - acc: 0.9289 -- iter: 512/588
[A[ATraining Step: 226  | total loss: [1m[32m0.18572[0m[0m | time: 16.280s
[2K
| Adam | epoch: 012 | loss: 0.18572 - acc: 0.9360 -- iter: 544/588
[A[ATraining Step: 227  | total loss: [1m[32m0.18484[0m[0m | time: 21.166s
[2K
| Adam | epoch: 012 | loss: 0.18484 - acc: 0.9361 -- iter: 576/588
[A[ATraining Step: 228  | total loss: [1m[32m0.18203[0m[0m | time: 23.125s
[2K
| Adam | epoch: 012 | loss: 0.18203 - acc: 0.9363 | val_loss: 0.29454 - val_acc: 0.9022 -- iter: 588/588
--
Training Step: 229  | total loss: [1m[32m0.16975[0m[0m | time: 1.003s
[2K
| Adam | epoch: 013 | loss: 0.16975 - acc: 0.9426 -- iter: 032/588
[A[ATraining Step: 230  | total loss: [1m[32m0.15991[0m[0m | time: 1.991s
[2K
| Adam | epoch: 013 | loss: 0.15991 - acc: 0.9484 -- iter: 064/588
[A[ATraining Step: 231  | total loss: [1m[32m0.16719[0m[0m | time: 3.071s
[2K
| Adam | epoch: 013 | loss: 0.16719 - acc: 0.9442 -- iter: 096/588
[A[ATraining Step: 232  | total loss: [1m[32m0.16503[0m[0m | time: 4.049s
[2K
| Adam | epoch: 013 | loss: 0.16503 - acc: 0.9466 -- iter: 128/588
[A[ATraining Step: 233  | total loss: [1m[32m0.15961[0m[0m | time: 4.997s
[2K
| Adam | epoch: 013 | loss: 0.15961 - acc: 0.9457 -- iter: 160/588
[A[ATraining Step: 234  | total loss: [1m[32m0.17717[0m[0m | time: 6.224s
[2K
| Adam | epoch: 013 | loss: 0.17717 - acc: 0.9386 -- iter: 192/588
[A[ATraining Step: 235  | total loss: [1m[32m0.17009[0m[0m | time: 7.313s
[2K
| Adam | epoch: 013 | loss: 0.17009 - acc: 0.9385 -- iter: 224/588
[A[ATraining Step: 236  | total loss: [1m[32m0.15567[0m[0m | time: 12.742s
[2K
| Adam | epoch: 013 | loss: 0.15567 - acc: 0.9447 -- iter: 256/588
[A[ATraining Step: 237  | total loss: [1m[32m0.15554[0m[0m | time: 13.741s
[2K
| Adam | epoch: 013 | loss: 0.15554 - acc: 0.9440 -- iter: 288/588
[A[ATraining Step: 238  | total loss: [1m[32m0.14504[0m[0m | time: 14.687s
[2K
| Adam | epoch: 013 | loss: 0.14504 - acc: 0.9496 -- iter: 320/588
[A[ATraining Step: 239  | total loss: [1m[32m0.13845[0m[0m | time: 15.069s
[2K
| Adam | epoch: 013 | loss: 0.13845 - acc: 0.9515 -- iter: 352/588
[A[ATraining Step: 240  | total loss: [1m[32m0.13309[0m[0m | time: 15.476s
[2K
| Adam | epoch: 013 | loss: 0.13309 - acc: 0.9563 -- iter: 384/588
[A[ATraining Step: 241  | total loss: [1m[32m0.12135[0m[0m | time: 16.487s
[2K
| Adam | epoch: 013 | loss: 0.12135 - acc: 0.9607 -- iter: 416/588
[A[ATraining Step: 242  | total loss: [1m[32m0.11621[0m[0m | time: 17.414s
[2K
| Adam | epoch: 013 | loss: 0.11621 - acc: 0.9646 -- iter: 448/588
[A[ATraining Step: 243  | total loss: [1m[32m0.12279[0m[0m | time: 18.407s
[2K
| Adam | epoch: 013 | loss: 0.12279 - acc: 0.9619 -- iter: 480/588
[A[ATraining Step: 244  | total loss: [1m[32m0.11952[0m[0m | time: 19.213s
[2K
| Adam | epoch: 013 | loss: 0.11952 - acc: 0.9626 -- iter: 512/588
[A[ATraining Step: 245  | total loss: [1m[32m0.11338[0m[0m | time: 20.263s
[2K
| Adam | epoch: 013 | loss: 0.11338 - acc: 0.9632 -- iter: 544/588
[A[ATraining Step: 246  | total loss: [1m[32m0.12025[0m[0m | time: 21.323s
[2K
| Adam | epoch: 013 | loss: 0.12025 - acc: 0.9638 -- iter: 576/588
[A[ATraining Step: 247  | total loss: [1m[32m0.11864[0m[0m | time: 23.250s
[2K
| Adam | epoch: 013 | loss: 0.11864 - acc: 0.9643 | val_loss: 0.27218 - val_acc: 0.8967 -- iter: 588/588
--
Training Step: 248  | total loss: [1m[32m0.14885[0m[0m | time: 0.944s
[2K
| Adam | epoch: 014 | loss: 0.14885 - acc: 0.9553 -- iter: 032/588
[A[ATraining Step: 249  | total loss: [1m[32m0.14355[0m[0m | time: 1.896s
[2K
| Adam | epoch: 014 | loss: 0.14355 - acc: 0.9567 -- iter: 064/588
[A[ATraining Step: 250  | total loss: [1m[32m0.13218[0m[0m | time: 2.835s
[2K
| Adam | epoch: 014 | loss: 0.13218 - acc: 0.9610 -- iter: 096/588
[A[ATraining Step: 251  | total loss: [1m[32m0.13560[0m[0m | time: 3.826s
[2K
| Adam | epoch: 014 | loss: 0.13560 - acc: 0.9587 -- iter: 128/588
[A[ATraining Step: 252  | total loss: [1m[32m0.12983[0m[0m | time: 4.811s
[2K
| Adam | epoch: 014 | loss: 0.12983 - acc: 0.9597 -- iter: 160/588
[A[ATraining Step: 253  | total loss: [1m[32m0.12501[0m[0m | time: 5.659s
[2K
| Adam | epoch: 014 | loss: 0.12501 - acc: 0.9606 -- iter: 192/588
[A[ATraining Step: 254  | total loss: [1m[32m0.12220[0m[0m | time: 6.695s
[2K
| Adam | epoch: 014 | loss: 0.12220 - acc: 0.9614 -- iter: 224/588
[A[ATraining Step: 255  | total loss: [1m[32m0.12026[0m[0m | time: 7.780s
[2K
| Adam | epoch: 014 | loss: 0.12026 - acc: 0.9653 -- iter: 256/588
[A[ATraining Step: 256  | total loss: [1m[32m0.11341[0m[0m | time: 8.770s
[2K
| Adam | epoch: 014 | loss: 0.11341 - acc: 0.9687 -- iter: 288/588
[A[ATraining Step: 257  | total loss: [1m[32m0.10700[0m[0m | time: 9.550s
[2K
| Adam | epoch: 014 | loss: 0.10700 - acc: 0.9719 -- iter: 320/588
[A[ATraining Step: 258  | total loss: [1m[32m0.10326[0m[0m | time: 10.524s
[2K
| Adam | epoch: 014 | loss: 0.10326 - acc: 0.9715 -- iter: 352/588
[A[ATraining Step: 259  | total loss: [1m[32m0.09649[0m[0m | time: 10.888s
[2K
| Adam | epoch: 014 | loss: 0.09649 - acc: 0.9744 -- iter: 384/588
[A[ATraining Step: 260  | total loss: [1m[32m0.08815[0m[0m | time: 11.272s
[2K
| Adam | epoch: 014 | loss: 0.08815 - acc: 0.9770 -- iter: 416/588
[A[ATraining Step: 261  | total loss: [1m[32m0.08069[0m[0m | time: 12.190s
[2K
| Adam | epoch: 014 | loss: 0.08069 - acc: 0.9793 -- iter: 448/588
[A[ATraining Step: 262  | total loss: [1m[32m0.09471[0m[0m | time: 13.128s
[2K
| Adam | epoch: 014 | loss: 0.09471 - acc: 0.9720 -- iter: 480/588
[A[ATraining Step: 263  | total loss: [1m[32m0.09053[0m[0m | time: 14.061s
[2K
| Adam | epoch: 014 | loss: 0.09053 - acc: 0.9716 -- iter: 512/588
[A[ATraining Step: 264  | total loss: [1m[32m0.09154[0m[0m | time: 14.982s
[2K
| Adam | epoch: 014 | loss: 0.09154 - acc: 0.9713 -- iter: 544/588
[A[ATraining Step: 265  | total loss: [1m[32m0.08643[0m[0m | time: 15.971s
[2K
| Adam | epoch: 014 | loss: 0.08643 - acc: 0.9742 -- iter: 576/588
[A[ATraining Step: 266  | total loss: [1m[32m0.08453[0m[0m | time: 18.247s
[2K
| Adam | epoch: 014 | loss: 0.08453 - acc: 0.9737 | val_loss: 0.28323 - val_acc: 0.9185 -- iter: 588/588
--
Training Step: 267  | total loss: [1m[32m0.07986[0m[0m | time: 0.879s
[2K
| Adam | epoch: 015 | loss: 0.07986 - acc: 0.9763 -- iter: 032/588
[A[ATraining Step: 268  | total loss: [1m[32m0.10406[0m[0m | time: 1.801s
[2K
| Adam | epoch: 015 | loss: 0.10406 - acc: 0.9724 -- iter: 064/588
[A[ATraining Step: 269  | total loss: [1m[32m0.09808[0m[0m | time: 2.744s
[2K
| Adam | epoch: 015 | loss: 0.09808 - acc: 0.9721 -- iter: 096/588
[A[ATraining Step: 270  | total loss: [1m[32m0.09979[0m[0m | time: 3.685s
[2K
| Adam | epoch: 015 | loss: 0.09979 - acc: 0.9655 -- iter: 128/588
[A[ATraining Step: 271  | total loss: [1m[32m0.11400[0m[0m | time: 4.656s
[2K
| Adam | epoch: 015 | loss: 0.11400 - acc: 0.9596 -- iter: 160/588
[A[ATraining Step: 272  | total loss: [1m[32m0.11346[0m[0m | time: 5.644s
[2K
| Adam | epoch: 015 | loss: 0.11346 - acc: 0.9573 -- iter: 192/588
[A[ATraining Step: 273  | total loss: [1m[32m0.11927[0m[0m | time: 6.547s
[2K
| Adam | epoch: 015 | loss: 0.11927 - acc: 0.9491 -- iter: 224/588
[A[ATraining Step: 274  | total loss: [1m[32m0.11007[0m[0m | time: 7.451s
[2K
| Adam | epoch: 015 | loss: 0.11007 - acc: 0.9542 -- iter: 256/588
[A[ATraining Step: 275  | total loss: [1m[32m0.10223[0m[0m | time: 8.562s
[2K
| Adam | epoch: 015 | loss: 0.10223 - acc: 0.9588 -- iter: 288/588
[A[ATraining Step: 276  | total loss: [1m[32m0.10408[0m[0m | time: 9.723s
[2K
| Adam | epoch: 015 | loss: 0.10408 - acc: 0.9598 -- iter: 320/588
[A[ATraining Step: 277  | total loss: [1m[32m0.09518[0m[0m | time: 10.502s
[2K
| Adam | epoch: 015 | loss: 0.09518 - acc: 0.9638 -- iter: 352/588
[A[ATraining Step: 278  | total loss: [1m[32m0.08944[0m[0m | time: 11.420s
[2K
| Adam | epoch: 015 | loss: 0.08944 - acc: 0.9674 -- iter: 384/588
[A[ATraining Step: 279  | total loss: [1m[32m0.08337[0m[0m | time: 11.786s
[2K
| Adam | epoch: 015 | loss: 0.08337 - acc: 0.9707 -- iter: 416/588
[A[ATraining Step: 280  | total loss: [1m[32m0.09781[0m[0m | time: 12.132s
[2K
| Adam | epoch: 015 | loss: 0.09781 - acc: 0.9569 -- iter: 448/588
[A[ATraining Step: 281  | total loss: [1m[32m0.09854[0m[0m | time: 13.092s
[2K
| Adam | epoch: 015 | loss: 0.09854 - acc: 0.9612 -- iter: 480/588
[A[ATraining Step: 282  | total loss: [1m[32m0.09113[0m[0m | time: 13.964s
[2K
| Adam | epoch: 015 | loss: 0.09113 - acc: 0.9651 -- iter: 512/588
[A[ATraining Step: 283  | total loss: [1m[32m0.08526[0m[0m | time: 14.828s
[2K
| Adam | epoch: 015 | loss: 0.08526 - acc: 0.9686 -- iter: 544/588
[A[ATraining Step: 284  | total loss: [1m[32m0.08192[0m[0m | time: 15.882s
[2K
| Adam | epoch: 015 | loss: 0.08192 - acc: 0.9718 -- iter: 576/588
[A[ATraining Step: 285  | total loss: [1m[32m0.07662[0m[0m | time: 17.800s
[2K
| Adam | epoch: 015 | loss: 0.07662 - acc: 0.9746 | val_loss: 0.30639 - val_acc: 0.8859 -- iter: 588/588
--
Validation AUC:0.9591016548463357
Validation AUPRC:0.9627902899122345
Test AUC:0.9431966726084373
Test AUPRC:0.8865890070139547
BestTestF1Score	0.86	0.72	0.86	0.8	0.92	78	19	80	7	0.15
BestTestMCCScore	0.87	0.79	0.89	0.95	0.81	69	4	95	16	0.81
BestTestAccuracyScore	0.87	0.79	0.89	0.95	0.81	69	4	95	16	0.81
BestValidationF1Score	0.9	0.8	0.9	0.85	0.96	86	15	79	4	0.15
BestValidationMCC	0.9	0.81	0.9	0.93	0.87	78	6	88	12	0.81
BestValidationAccuracy	0.9	0.81	0.9	0.93	0.87	78	6	88	12	0.81
TestPredictions (Threshold:0.81)
CHEMBL370646,TP,ACT,0.8799999952316284	CHEMBL3741322,TP,ACT,0.9800000190734863	CHEMBL450729,TN,INACT,0.009999999776482582	CHEMBL122914,TP,ACT,0.9900000095367432	CHEMBL312940,TP,ACT,0.9900000095367432	CHEMBL44262,TN,INACT,0.0	CHEMBL3739470,TP,ACT,1.0	CHEMBL3740732,TP,ACT,1.0	CHEMBL549449,TP,ACT,0.9700000286102295	CHEMBL570487,TP,ACT,0.9900000095367432	CHEMBL555210,FN,ACT,0.23999999463558197	CHEMBL72738,TN,INACT,0.009999999776482582	CHEMBL555222,FN,ACT,0.029999999329447746	CHEMBL1632171,TP,ACT,1.0	CHEMBL2370511,TN,INACT,0.0	CHEMBL332645,TN,INACT,0.38999998569488525	CHEMBL461088,TN,INACT,0.0	CHEMBL162095,TN,INACT,0.009999999776482582	CHEMBL297173,TN,INACT,0.009999999776482582	CHEMBL1170027,TN,INACT,0.0	CHEMBL147340,TN,INACT,0.0	CHEMBL158078,TN,INACT,0.009999999776482582	CHEMBL1258560,TP,ACT,0.9800000190734863	CHEMBL72841,TN,INACT,0.019999999552965164	CHEMBL558757,TP,ACT,0.8199999928474426	CHEMBL170335,TN,INACT,0.05000000074505806	CHEMBL182999,TP,ACT,1.0	CHEMBL1632175,TP,ACT,0.9800000190734863	CHEMBL104172,TN,INACT,0.009999999776482582	CHEMBL565146,TP,ACT,0.9800000190734863	CHEMBL104994,TN,INACT,0.03999999910593033	CHEMBL312670,TN,INACT,0.0	CHEMBL43661,TN,INACT,0.25	CHEMBL2179590,TP,ACT,0.9800000190734863	CHEMBL2087329,TP,ACT,0.9900000095367432	CHEMBL3740472,TP,ACT,0.9800000190734863	CHEMBL43788,TN,INACT,0.029999999329447746	CHEMBL252231,TN,INACT,0.05000000074505806	CHEMBL416069,TN,INACT,0.0	CHEMBL3741608,TP,ACT,1.0	CHEMBL367354,TP,ACT,0.9900000095367432	CHEMBL3741548,TP,ACT,1.0	CHEMBL550302,TP,ACT,0.8999999761581421	CHEMBL89203,TN,INACT,0.0	CHEMBL539713,FN,ACT,0.7799999713897705	CHEMBL62703,TN,INACT,0.5	CHEMBL3093186,FN,ACT,0.6800000071525574	CHEMBL360245,TP,ACT,0.9800000190734863	CHEMBL282199,FN,ACT,0.009999999776482582	CHEMBL140620,FP,INACT,0.8399999737739563	CHEMBL343969,FP,INACT,1.0	CHEMBL2402896,FN,ACT,0.11999999731779099	CHEMBL148967,TN,INACT,0.019999999552965164	CHEMBL45087,TN,INACT,0.0	CHEMBL311455,TN,INACT,0.029999999329447746	CHEMBL2181171,TP,ACT,1.0	CHEMBL129198,TN,INACT,0.05000000074505806	CHEMBL3084582,FN,ACT,0.019999999552965164	CHEMBL287045,TP,ACT,0.9900000095367432	CHEMBL89457,TN,INACT,0.05000000074505806	CHEMBL15585,FN,ACT,0.46000000834465027	CHEMBL47404,TN,INACT,0.009999999776482582	CHEMBL302359,TN,INACT,0.05999999865889549	CHEMBL391191,TN,INACT,0.019999999552965164	CHEMBL74066,TN,INACT,0.7099999785423279	CHEMBL78830,TN,INACT,0.03999999910593033	CHEMBL2111789,TN,INACT,0.0	CHEMBL154068,FP,INACT,1.0	CHEMBL1907839,TN,INACT,0.05000000074505806	CHEMBL3759759,TP,ACT,0.9900000095367432	CHEMBL252232,TN,INACT,0.05999999865889549	CHEMBL59347,TN,INACT,0.5699999928474426	CHEMBL99331,TN,INACT,0.07000000029802322	CHEMBL2181170,TP,ACT,0.9900000095367432	CHEMBL109478,TN,INACT,0.009999999776482582	CHEMBL422411,TN,INACT,0.05000000074505806	CHEMBL550064,TP,ACT,0.9700000286102295	CHEMBL2179588,TP,ACT,0.8899999856948853	CHEMBL64120,TN,INACT,0.0	CHEMBL45160,TN,INACT,0.009999999776482582	CHEMBL3741733,TP,ACT,0.9900000095367432	CHEMBL2087332,TP,ACT,1.0	CHEMBL39879,TN,INACT,0.019999999552965164	CHEMBL59597,TN,INACT,0.11999999731779099	CHEMBL2179679,TP,ACT,1.0	CHEMBL92318,TN,INACT,0.10999999940395355	CHEMBL1632162,TP,ACT,1.0	CHEMBL2402904,TP,ACT,0.9800000190734863	CHEMBL303386,TN,INACT,0.07000000029802322	CHEMBL3758433,TP,ACT,0.9900000095367432	CHEMBL1907665,TN,INACT,0.009999999776482582	CHEMBL327999,TP,ACT,0.9900000095367432	CHEMBL85251,TP,ACT,0.9900000095367432	CHEMBL2181185,TP,ACT,0.9900000095367432	CHEMBL2058699,FN,ACT,0.7099999785423279	CHEMBL141365,TN,INACT,0.009999999776482582	CHEMBL3739611,TP,ACT,1.0	CHEMBL3220223,TP,ACT,0.949999988079071	CHEMBL124485,TP,ACT,0.9900000095367432	CHEMBL76949,TN,INACT,0.10000000149011612	CHEMBL423666,TN,INACT,0.0	CHEMBL371718,TP,ACT,0.8999999761581421	CHEMBL324586,TN,INACT,0.009999999776482582	CHEMBL2058705,FN,ACT,0.6800000071525574	CHEMBL173708,TN,INACT,0.029999999329447746	CHEMBL241514,TN,INACT,0.3100000023841858	CHEMBL88506,TN,INACT,0.009999999776482582	CHEMBL2335158,TN,INACT,0.03999999910593033	CHEMBL320763,TN,INACT,0.009999999776482582	CHEMBL3143400,TN,INACT,0.0	CHEMBL227429,TN,INACT,0.0	CHEMBL3291084,TP,ACT,0.9700000286102295	CHEMBL2179703,TP,ACT,0.8600000143051147	CHEMBL438915,FP,INACT,0.8100000023841858	CHEMBL602474,TN,INACT,0.009999999776482582	CHEMBL3740844,FN,ACT,0.5199999809265137	CHEMBL3218121,TN,INACT,0.0	CHEMBL3741199,FN,ACT,0.07999999821186066	CHEMBL3234532,TN,INACT,0.23000000417232513	CHEMBL361118,TP,ACT,1.0	CHEMBL1907840,TN,INACT,0.7599999904632568	CHEMBL2402897,TP,ACT,0.8700000047683716	CHEMBL109248,TN,INACT,0.18000000715255737	CHEMBL540981,TP,ACT,1.0	CHEMBL104,TN,INACT,0.0	CHEMBL307034,TN,INACT,0.10000000149011612	CHEMBL209121,TN,INACT,0.0	CHEMBL89225,TP,ACT,1.0	CHEMBL2179581,TP,ACT,0.9599999785423279	CHEMBL283320,TN,INACT,0.0	CHEMBL2440452,FN,ACT,0.07000000029802322	CHEMBL107680,TN,INACT,0.03999999910593033	CHEMBL3329806,TP,ACT,0.9900000095367432	CHEMBL175698,TN,INACT,0.0	CHEMBL296291,TN,INACT,0.0	CHEMBL45269,TN,INACT,0.009999999776482582	CHEMBL556326,TP,ACT,0.9800000190734863	CHEMBL76360,TN,INACT,0.019999999552965164	CHEMBL334933,TN,INACT,0.0	CHEMBL324652,TN,INACT,0.009999999776482582	CHEMBL1765667,TN,INACT,0.009999999776482582	CHEMBL171108,TN,INACT,0.019999999552965164	CHEMBL3742080,FN,ACT,0.7099999785423279	CHEMBL2113157,TP,ACT,0.9900000095367432	CHEMBL1263,TN,INACT,0.5400000214576721	CHEMBL33884,TP,ACT,0.9100000262260437	CHEMBL140365,TN,INACT,0.25999999046325684	CHEMBL76576,TN,INACT,0.009999999776482582	CHEMBL569585,TP,ACT,0.9900000095367432	CHEMBL309017,TN,INACT,0.6800000071525574	CHEMBL3758945,TP,ACT,0.9800000190734863	CHEMBL74515,TN,INACT,0.019999999552965164	CHEMBL48031,TN,INACT,0.0	CHEMBL328285,TN,INACT,0.6800000071525574	CHEMBL111218,TN,INACT,0.0	CHEMBL179799,TP,ACT,1.0	CHEMBL64461,TN,INACT,0.009999999776482582	CHEMBL289284,TN,INACT,0.0	CHEMBL3633665,TN,INACT,0.05999999865889549	CHEMBL141354,TN,INACT,0.6899999976158142	CHEMBL189580,TP,ACT,0.8899999856948853	CHEMBL551820,TP,ACT,0.8999999761581421	CHEMBL160626,TN,INACT,0.46000000834465027	CHEMBL1258222,TP,ACT,1.0	CHEMBL2058704,TP,ACT,0.8899999856948853	CHEMBL3759362,TP,ACT,0.9900000095367432	CHEMBL550459,TP,ACT,0.9599999785423279	CHEMBL1083787,FN,ACT,0.2199999988079071	CHEMBL63937,TN,INACT,0.0	CHEMBL125670,TP,ACT,0.9900000095367432	CHEMBL2179586,TP,ACT,0.9300000071525574	CHEMBL217002,TN,INACT,0.009999999776482582	CHEMBL371300,FN,ACT,0.029999999329447746	CHEMBL76779,TN,INACT,0.03999999910593033	CHEMBL417719,TN,INACT,0.0	CHEMBL2179678,TP,ACT,1.0	CHEMBL2179582,TP,ACT,1.0	CHEMBL180835,TP,ACT,1.0	CHEMBL110695,TN,INACT,0.009999999776482582	CHEMBL1258561,TP,ACT,0.9700000286102295	CHEMBL2179680,TP,ACT,0.9700000286102295	CHEMBL603858,TN,INACT,0.009999999776482582	CHEMBL2440456,TP,ACT,0.949999988079071	CHEMBL109926,TN,INACT,0.009999999776482582	

