CNNModel CHEMBL5522 adam 0.0005 15 256 0 0.8 False True
Number of active compounds :	221
Number of inactive compounds :	221
---------------------------------
Run id: CNNModel_CHEMBL5522_adam_0.0005_15_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5522_adam_0.0005_15_256_0.8_True/
---------------------------------
Training samples: 269
Validation samples: 85
--
Training Step: 1  | time: 0.748s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/269
[A[ATraining Step: 2  | total loss: [1m[32m0.62393[0m[0m | time: 1.359s
[2K
| Adam | epoch: 001 | loss: 0.62393 - acc: 0.3937 -- iter: 064/269
[A[ATraining Step: 3  | total loss: [1m[32m0.68028[0m[0m | time: 1.967s
[2K
| Adam | epoch: 001 | loss: 0.68028 - acc: 0.5318 -- iter: 096/269
[A[ATraining Step: 4  | total loss: [1m[32m0.69005[0m[0m | time: 2.566s
[2K
| Adam | epoch: 001 | loss: 0.69005 - acc: 0.5080 -- iter: 128/269
[A[ATraining Step: 5  | total loss: [1m[32m0.69054[0m[0m | time: 3.181s
[2K
| Adam | epoch: 001 | loss: 0.69054 - acc: 0.5674 -- iter: 160/269
[A[ATraining Step: 6  | total loss: [1m[32m0.69351[0m[0m | time: 3.790s
[2K
| Adam | epoch: 001 | loss: 0.69351 - acc: 0.5040 -- iter: 192/269
[A[ATraining Step: 7  | total loss: [1m[32m0.68982[0m[0m | time: 4.400s
[2K
| Adam | epoch: 001 | loss: 0.68982 - acc: 0.5578 -- iter: 224/269
[A[ATraining Step: 8  | total loss: [1m[32m0.69880[0m[0m | time: 5.013s
[2K
| Adam | epoch: 001 | loss: 0.69880 - acc: 0.4550 -- iter: 256/269
[A[ATraining Step: 9  | total loss: [1m[32m0.68682[0m[0m | time: 6.345s
[2K
| Adam | epoch: 001 | loss: 0.68682 - acc: 0.6112 | val_loss: 0.69525 - val_acc: 0.4941 -- iter: 269/269
--
Training Step: 10  | total loss: [1m[32m0.68534[0m[0m | time: 0.284s
[2K
| Adam | epoch: 002 | loss: 0.68534 - acc: 0.6133 -- iter: 032/269
[A[ATraining Step: 11  | total loss: [1m[32m0.68325[0m[0m | time: 0.897s
[2K
| Adam | epoch: 002 | loss: 0.68325 - acc: 0.6143 -- iter: 064/269
[A[ATraining Step: 12  | total loss: [1m[32m0.69463[0m[0m | time: 1.518s
[2K
| Adam | epoch: 002 | loss: 0.69463 - acc: 0.5347 -- iter: 096/269
[A[ATraining Step: 13  | total loss: [1m[32m0.68604[0m[0m | time: 2.141s
[2K
| Adam | epoch: 002 | loss: 0.68604 - acc: 0.5734 -- iter: 128/269
[A[ATraining Step: 14  | total loss: [1m[32m0.68283[0m[0m | time: 2.776s
[2K
| Adam | epoch: 002 | loss: 0.68283 - acc: 0.5817 -- iter: 160/269
[A[ATraining Step: 15  | total loss: [1m[32m0.69668[0m[0m | time: 3.399s
[2K
| Adam | epoch: 002 | loss: 0.69668 - acc: 0.5253 -- iter: 192/269
[A[ATraining Step: 16  | total loss: [1m[32m0.69758[0m[0m | time: 4.008s
[2K
| Adam | epoch: 002 | loss: 0.69758 - acc: 0.5158 -- iter: 224/269
[A[ATraining Step: 17  | total loss: [1m[32m0.69094[0m[0m | time: 4.621s
[2K
| Adam | epoch: 002 | loss: 0.69094 - acc: 0.5439 -- iter: 256/269
[A[ATraining Step: 18  | total loss: [1m[32m0.68674[0m[0m | time: 6.229s
[2K
| Adam | epoch: 002 | loss: 0.68674 - acc: 0.5611 | val_loss: 0.69737 - val_acc: 0.4941 -- iter: 269/269
--
Training Step: 19  | total loss: [1m[32m0.68447[0m[0m | time: 0.282s
[2K
| Adam | epoch: 003 | loss: 0.68447 - acc: 0.5720 -- iter: 032/269
[A[ATraining Step: 20  | total loss: [1m[32m0.68115[0m[0m | time: 0.572s
[2K
| Adam | epoch: 003 | loss: 0.68115 - acc: 0.5859 -- iter: 064/269
[A[ATraining Step: 21  | total loss: [1m[32m0.67822[0m[0m | time: 1.183s
[2K
| Adam | epoch: 003 | loss: 0.67822 - acc: 0.5951 -- iter: 096/269
[A[ATraining Step: 22  | total loss: [1m[32m0.68724[0m[0m | time: 1.787s
[2K
| Adam | epoch: 003 | loss: 0.68724 - acc: 0.5572 -- iter: 128/269
[A[ATraining Step: 23  | total loss: [1m[32m0.69733[0m[0m | time: 2.429s
[2K
| Adam | epoch: 003 | loss: 0.69733 - acc: 0.5134 -- iter: 160/269
[A[ATraining Step: 24  | total loss: [1m[32m0.69329[0m[0m | time: 3.049s
[2K
| Adam | epoch: 003 | loss: 0.69329 - acc: 0.5272 -- iter: 192/269
[A[ATraining Step: 25  | total loss: [1m[32m0.68690[0m[0m | time: 3.653s
[2K
| Adam | epoch: 003 | loss: 0.68690 - acc: 0.5539 -- iter: 224/269
[A[ATraining Step: 26  | total loss: [1m[32m0.68399[0m[0m | time: 4.255s
[2K
| Adam | epoch: 003 | loss: 0.68399 - acc: 0.5644 -- iter: 256/269
[A[ATraining Step: 27  | total loss: [1m[32m0.68798[0m[0m | time: 5.863s
[2K
| Adam | epoch: 003 | loss: 0.68798 - acc: 0.5398 | val_loss: 0.69293 - val_acc: 0.4941 -- iter: 269/269
--
Training Step: 28  | total loss: [1m[32m0.68482[0m[0m | time: 0.626s
[2K
| Adam | epoch: 004 | loss: 0.68482 - acc: 0.5533 -- iter: 032/269
[A[ATraining Step: 29  | total loss: [1m[32m0.68500[0m[0m | time: 0.929s
[2K
| Adam | epoch: 004 | loss: 0.68500 - acc: 0.5479 -- iter: 064/269
[A[ATraining Step: 30  | total loss: [1m[32m0.68645[0m[0m | time: 1.201s
[2K
| Adam | epoch: 004 | loss: 0.68645 - acc: 0.5457 -- iter: 096/269
[A[ATraining Step: 31  | total loss: [1m[32m0.68761[0m[0m | time: 1.811s
[2K
| Adam | epoch: 004 | loss: 0.68761 - acc: 0.5440 -- iter: 128/269
[A[ATraining Step: 32  | total loss: [1m[32m0.68033[0m[0m | time: 2.443s
[2K
| Adam | epoch: 004 | loss: 0.68033 - acc: 0.5763 -- iter: 160/269
[A[ATraining Step: 33  | total loss: [1m[32m0.68119[0m[0m | time: 3.048s
[2K
| Adam | epoch: 004 | loss: 0.68119 - acc: 0.5664 -- iter: 192/269
[A[ATraining Step: 34  | total loss: [1m[32m0.68200[0m[0m | time: 3.647s
[2K
| Adam | epoch: 004 | loss: 0.68200 - acc: 0.5589 -- iter: 224/269
[A[ATraining Step: 35  | total loss: [1m[32m0.67976[0m[0m | time: 4.257s
[2K
| Adam | epoch: 004 | loss: 0.67976 - acc: 0.5596 -- iter: 256/269
[A[ATraining Step: 36  | total loss: [1m[32m0.68957[0m[0m | time: 5.867s
[2K
| Adam | epoch: 004 | loss: 0.68957 - acc: 0.5155 | val_loss: 0.68183 - val_acc: 0.4941 -- iter: 269/269
--
Training Step: 37  | total loss: [1m[32m0.68578[0m[0m | time: 0.626s
[2K
| Adam | epoch: 005 | loss: 0.68578 - acc: 0.5249 -- iter: 032/269
[A[ATraining Step: 38  | total loss: [1m[32m0.68264[0m[0m | time: 1.239s
[2K
| Adam | epoch: 005 | loss: 0.68264 - acc: 0.5322 -- iter: 064/269
[A[ATraining Step: 39  | total loss: [1m[32m0.68022[0m[0m | time: 1.530s
[2K
| Adam | epoch: 005 | loss: 0.68022 - acc: 0.5380 -- iter: 096/269
[A[ATraining Step: 40  | total loss: [1m[32m0.66746[0m[0m | time: 1.800s
[2K
| Adam | epoch: 005 | loss: 0.66746 - acc: 0.5958 -- iter: 128/269
[A[ATraining Step: 41  | total loss: [1m[32m0.64879[0m[0m | time: 2.397s
[2K
| Adam | epoch: 005 | loss: 0.64879 - acc: 0.6418 -- iter: 160/269
[A[ATraining Step: 42  | total loss: [1m[32m0.65370[0m[0m | time: 3.000s
[2K
| Adam | epoch: 005 | loss: 0.65370 - acc: 0.6219 -- iter: 192/269
[A[ATraining Step: 43  | total loss: [1m[32m0.64696[0m[0m | time: 3.601s
[2K
| Adam | epoch: 005 | loss: 0.64696 - acc: 0.6280 -- iter: 224/269
[A[ATraining Step: 44  | total loss: [1m[32m0.65427[0m[0m | time: 4.200s
[2K
| Adam | epoch: 005 | loss: 0.65427 - acc: 0.6166 -- iter: 256/269
[A[ATraining Step: 45  | total loss: [1m[32m0.67003[0m[0m | time: 5.823s
[2K
| Adam | epoch: 005 | loss: 0.67003 - acc: 0.5968 | val_loss: 0.67857 - val_acc: 0.4941 -- iter: 269/269
--
Training Step: 46  | total loss: [1m[32m0.69395[0m[0m | time: 0.630s
[2K
| Adam | epoch: 006 | loss: 0.69395 - acc: 0.5546 -- iter: 032/269
[A[ATraining Step: 47  | total loss: [1m[32m0.68923[0m[0m | time: 1.230s
[2K
| Adam | epoch: 006 | loss: 0.68923 - acc: 0.5457 -- iter: 064/269
[A[ATraining Step: 48  | total loss: [1m[32m0.68150[0m[0m | time: 1.843s
[2K
| Adam | epoch: 006 | loss: 0.68150 - acc: 0.5484 -- iter: 096/269
[A[ATraining Step: 49  | total loss: [1m[32m0.67822[0m[0m | time: 2.151s
[2K
| Adam | epoch: 006 | loss: 0.67822 - acc: 0.5506 -- iter: 128/269
[A[ATraining Step: 50  | total loss: [1m[32m0.67366[0m[0m | time: 2.424s
[2K
| Adam | epoch: 006 | loss: 0.67366 - acc: 0.5607 -- iter: 160/269
[A[ATraining Step: 51  | total loss: [1m[32m0.67008[0m[0m | time: 3.039s
[2K
| Adam | epoch: 006 | loss: 0.67008 - acc: 0.5808 -- iter: 192/269
[A[ATraining Step: 52  | total loss: [1m[32m0.66789[0m[0m | time: 3.642s
[2K
| Adam | epoch: 006 | loss: 0.66789 - acc: 0.5921 -- iter: 224/269
[A[ATraining Step: 53  | total loss: [1m[32m0.66610[0m[0m | time: 4.247s
[2K
| Adam | epoch: 006 | loss: 0.66610 - acc: 0.6154 -- iter: 256/269
[A[ATraining Step: 54  | total loss: [1m[32m0.66340[0m[0m | time: 5.850s
[2K
| Adam | epoch: 006 | loss: 0.66340 - acc: 0.6395 | val_loss: 0.63089 - val_acc: 0.6941 -- iter: 269/269
--
Training Step: 55  | total loss: [1m[32m0.65675[0m[0m | time: 0.603s
[2K
| Adam | epoch: 007 | loss: 0.65675 - acc: 0.6731 -- iter: 032/269
[A[ATraining Step: 56  | total loss: [1m[32m0.64984[0m[0m | time: 1.204s
[2K
| Adam | epoch: 007 | loss: 0.64984 - acc: 0.6883 -- iter: 064/269
[A[ATraining Step: 57  | total loss: [1m[32m0.64339[0m[0m | time: 1.818s
[2K
| Adam | epoch: 007 | loss: 0.64339 - acc: 0.6969 -- iter: 096/269
[A[ATraining Step: 58  | total loss: [1m[32m0.62943[0m[0m | time: 2.425s
[2K
| Adam | epoch: 007 | loss: 0.62943 - acc: 0.6998 -- iter: 128/269
[A[ATraining Step: 59  | total loss: [1m[32m0.61632[0m[0m | time: 2.702s
[2K
| Adam | epoch: 007 | loss: 0.61632 - acc: 0.7066 -- iter: 160/269
[A[ATraining Step: 60  | total loss: [1m[32m0.60492[0m[0m | time: 2.975s
[2K
| Adam | epoch: 007 | loss: 0.60492 - acc: 0.7149 -- iter: 192/269
[A[ATraining Step: 61  | total loss: [1m[32m0.59082[0m[0m | time: 3.580s
[2K
| Adam | epoch: 007 | loss: 0.59082 - acc: 0.7320 -- iter: 224/269
[A[ATraining Step: 62  | total loss: [1m[32m0.58449[0m[0m | time: 4.188s
[2K
| Adam | epoch: 007 | loss: 0.58449 - acc: 0.7223 -- iter: 256/269
[A[ATraining Step: 63  | total loss: [1m[32m0.57483[0m[0m | time: 5.806s
[2K
| Adam | epoch: 007 | loss: 0.57483 - acc: 0.7179 | val_loss: 0.49319 - val_acc: 0.8000 -- iter: 269/269
--
Training Step: 64  | total loss: [1m[32m0.57039[0m[0m | time: 0.613s
[2K
| Adam | epoch: 008 | loss: 0.57039 - acc: 0.7219 -- iter: 032/269
[A[ATraining Step: 65  | total loss: [1m[32m0.55767[0m[0m | time: 1.216s
[2K
| Adam | epoch: 008 | loss: 0.55767 - acc: 0.7330 -- iter: 064/269
[A[ATraining Step: 66  | total loss: [1m[32m0.54750[0m[0m | time: 1.854s
[2K
| Adam | epoch: 008 | loss: 0.54750 - acc: 0.7427 -- iter: 096/269
[A[ATraining Step: 67  | total loss: [1m[32m0.52233[0m[0m | time: 2.468s
[2K
| Adam | epoch: 008 | loss: 0.52233 - acc: 0.7548 -- iter: 128/269
[A[ATraining Step: 68  | total loss: [1m[32m0.50684[0m[0m | time: 3.075s
[2K
| Adam | epoch: 008 | loss: 0.50684 - acc: 0.7617 -- iter: 160/269
[A[ATraining Step: 69  | total loss: [1m[32m0.50089[0m[0m | time: 3.355s
[2K
| Adam | epoch: 008 | loss: 0.50089 - acc: 0.7640 -- iter: 192/269
[A[ATraining Step: 70  | total loss: [1m[32m0.47664[0m[0m | time: 3.642s
[2K
| Adam | epoch: 008 | loss: 0.47664 - acc: 0.7823 -- iter: 224/269
[A[ATraining Step: 71  | total loss: [1m[32m0.44825[0m[0m | time: 4.260s
[2K
| Adam | epoch: 008 | loss: 0.44825 - acc: 0.8071 -- iter: 256/269
[A[ATraining Step: 72  | total loss: [1m[32m0.43052[0m[0m | time: 5.862s
[2K
| Adam | epoch: 008 | loss: 0.43052 - acc: 0.8112 | val_loss: 0.42145 - val_acc: 0.8118 -- iter: 269/269
--
Training Step: 73  | total loss: [1m[32m0.42572[0m[0m | time: 0.622s
[2K
| Adam | epoch: 009 | loss: 0.42572 - acc: 0.8114 -- iter: 032/269
[A[ATraining Step: 74  | total loss: [1m[32m0.42884[0m[0m | time: 1.222s
[2K
| Adam | epoch: 009 | loss: 0.42884 - acc: 0.7978 -- iter: 064/269
[A[ATraining Step: 75  | total loss: [1m[32m0.40746[0m[0m | time: 1.818s
[2K
| Adam | epoch: 009 | loss: 0.40746 - acc: 0.8163 -- iter: 096/269
[A[ATraining Step: 76  | total loss: [1m[32m0.39322[0m[0m | time: 2.427s
[2K
| Adam | epoch: 009 | loss: 0.39322 - acc: 0.8226 -- iter: 128/269
[A[ATraining Step: 77  | total loss: [1m[32m0.39230[0m[0m | time: 3.042s
[2K
| Adam | epoch: 009 | loss: 0.39230 - acc: 0.8215 -- iter: 160/269
[A[ATraining Step: 78  | total loss: [1m[32m0.41417[0m[0m | time: 3.643s
[2K
| Adam | epoch: 009 | loss: 0.41417 - acc: 0.8075 -- iter: 192/269
[A[ATraining Step: 79  | total loss: [1m[32m0.40168[0m[0m | time: 3.915s
[2K
| Adam | epoch: 009 | loss: 0.40168 - acc: 0.8145 -- iter: 224/269
[A[ATraining Step: 80  | total loss: [1m[32m0.37381[0m[0m | time: 4.193s
[2K
| Adam | epoch: 009 | loss: 0.37381 - acc: 0.8256 -- iter: 256/269
[A[ATraining Step: 81  | total loss: [1m[32m0.35222[0m[0m | time: 5.809s
[2K
| Adam | epoch: 009 | loss: 0.35222 - acc: 0.8355 | val_loss: 0.43191 - val_acc: 0.7882 -- iter: 269/269
--
Training Step: 82  | total loss: [1m[32m0.36240[0m[0m | time: 0.612s
[2K
| Adam | epoch: 010 | loss: 0.36240 - acc: 0.8332 -- iter: 032/269
[A[ATraining Step: 83  | total loss: [1m[32m0.34872[0m[0m | time: 1.229s
[2K
| Adam | epoch: 010 | loss: 0.34872 - acc: 0.8342 -- iter: 064/269
[A[ATraining Step: 84  | total loss: [1m[32m0.33659[0m[0m | time: 1.868s
[2K
| Adam | epoch: 010 | loss: 0.33659 - acc: 0.8445 -- iter: 096/269
[A[ATraining Step: 85  | total loss: [1m[32m0.32992[0m[0m | time: 2.461s
[2K
| Adam | epoch: 010 | loss: 0.32992 - acc: 0.8538 -- iter: 128/269
[A[ATraining Step: 86  | total loss: [1m[32m0.31763[0m[0m | time: 3.066s
[2K
| Adam | epoch: 010 | loss: 0.31763 - acc: 0.8622 -- iter: 160/269
[A[ATraining Step: 87  | total loss: [1m[32m0.32200[0m[0m | time: 3.672s
[2K
| Adam | epoch: 010 | loss: 0.32200 - acc: 0.8572 -- iter: 192/269
[A[ATraining Step: 88  | total loss: [1m[32m0.31970[0m[0m | time: 4.278s
[2K
| Adam | epoch: 010 | loss: 0.31970 - acc: 0.8528 -- iter: 224/269
[A[ATraining Step: 89  | total loss: [1m[32m0.31380[0m[0m | time: 4.550s
[2K
| Adam | epoch: 010 | loss: 0.31380 - acc: 0.8581 -- iter: 256/269
[A[ATraining Step: 90  | total loss: [1m[32m0.28875[0m[0m | time: 5.834s
[2K
| Adam | epoch: 010 | loss: 0.28875 - acc: 0.8723 | val_loss: 0.30076 - val_acc: 0.9059 -- iter: 269/269
--
Training Step: 91  | total loss: [1m[32m0.26789[0m[0m | time: 0.601s
[2K
| Adam | epoch: 011 | loss: 0.26789 - acc: 0.8851 -- iter: 032/269
[A[ATraining Step: 92  | total loss: [1m[32m0.25268[0m[0m | time: 1.209s
[2K
| Adam | epoch: 011 | loss: 0.25268 - acc: 0.8934 -- iter: 064/269
[A[ATraining Step: 93  | total loss: [1m[32m0.26769[0m[0m | time: 1.820s
[2K
| Adam | epoch: 011 | loss: 0.26769 - acc: 0.8853 -- iter: 096/269
[A[ATraining Step: 94  | total loss: [1m[32m0.28159[0m[0m | time: 2.419s
[2K
| Adam | epoch: 011 | loss: 0.28159 - acc: 0.8843 -- iter: 128/269
[A[ATraining Step: 95  | total loss: [1m[32m0.26225[0m[0m | time: 3.036s
[2K
| Adam | epoch: 011 | loss: 0.26225 - acc: 0.8959 -- iter: 160/269
[A[ATraining Step: 96  | total loss: [1m[32m0.24325[0m[0m | time: 3.657s
[2K
| Adam | epoch: 011 | loss: 0.24325 - acc: 0.9032 -- iter: 192/269
[A[ATraining Step: 97  | total loss: [1m[32m0.24190[0m[0m | time: 4.266s
[2K
| Adam | epoch: 011 | loss: 0.24190 - acc: 0.9066 -- iter: 224/269
[A[ATraining Step: 98  | total loss: [1m[32m0.25680[0m[0m | time: 4.867s
[2K
| Adam | epoch: 011 | loss: 0.25680 - acc: 0.9066 -- iter: 256/269
[A[ATraining Step: 99  | total loss: [1m[32m0.23936[0m[0m | time: 6.147s
[2K
| Adam | epoch: 011 | loss: 0.23936 - acc: 0.9128 | val_loss: 0.21850 - val_acc: 0.9176 -- iter: 269/269
--
Training Step: 100  | total loss: [1m[32m0.21842[0m[0m | time: 0.275s
[2K
| Adam | epoch: 012 | loss: 0.21842 - acc: 0.9215 -- iter: 032/269
[A[ATraining Step: 101  | total loss: [1m[32m0.20005[0m[0m | time: 0.893s
[2K
| Adam | epoch: 012 | loss: 0.20005 - acc: 0.9294 -- iter: 064/269
[A[ATraining Step: 102  | total loss: [1m[32m0.19180[0m[0m | time: 1.499s
[2K
| Adam | epoch: 012 | loss: 0.19180 - acc: 0.9333 -- iter: 096/269
[A[ATraining Step: 103  | total loss: [1m[32m0.19099[0m[0m | time: 2.095s
[2K
| Adam | epoch: 012 | loss: 0.19099 - acc: 0.9306 -- iter: 128/269
[A[ATraining Step: 104  | total loss: [1m[32m0.17568[0m[0m | time: 2.693s
[2K
| Adam | epoch: 012 | loss: 0.17568 - acc: 0.9375 -- iter: 160/269
[A[ATraining Step: 105  | total loss: [1m[32m0.18513[0m[0m | time: 3.312s
[2K
| Adam | epoch: 012 | loss: 0.18513 - acc: 0.9313 -- iter: 192/269
[A[ATraining Step: 106  | total loss: [1m[32m0.17286[0m[0m | time: 3.914s
[2K
| Adam | epoch: 012 | loss: 0.17286 - acc: 0.9350 -- iter: 224/269
[A[ATraining Step: 107  | total loss: [1m[32m0.16783[0m[0m | time: 4.519s
[2K
| Adam | epoch: 012 | loss: 0.16783 - acc: 0.9384 -- iter: 256/269
[A[ATraining Step: 108  | total loss: [1m[32m0.20743[0m[0m | time: 6.138s
[2K
| Adam | epoch: 012 | loss: 0.20743 - acc: 0.9383 | val_loss: 0.21494 - val_acc: 0.9176 -- iter: 269/269
--
Training Step: 109  | total loss: [1m[32m0.19485[0m[0m | time: 0.285s
[2K
| Adam | epoch: 013 | loss: 0.19485 - acc: 0.9414 -- iter: 032/269
[A[ATraining Step: 110  | total loss: [1m[32m0.18186[0m[0m | time: 0.557s
[2K
| Adam | epoch: 013 | loss: 0.18186 - acc: 0.9472 -- iter: 064/269
[A[ATraining Step: 111  | total loss: [1m[32m0.16822[0m[0m | time: 1.162s
[2K
| Adam | epoch: 013 | loss: 0.16822 - acc: 0.9525 -- iter: 096/269
[A[ATraining Step: 112  | total loss: [1m[32m0.16839[0m[0m | time: 1.769s
[2K
| Adam | epoch: 013 | loss: 0.16839 - acc: 0.9510 -- iter: 128/269
[A[ATraining Step: 113  | total loss: [1m[32m0.16112[0m[0m | time: 2.384s
[2K
| Adam | epoch: 013 | loss: 0.16112 - acc: 0.9496 -- iter: 160/269
[A[ATraining Step: 114  | total loss: [1m[32m0.14885[0m[0m | time: 2.998s
[2K
| Adam | epoch: 013 | loss: 0.14885 - acc: 0.9547 -- iter: 192/269
[A[ATraining Step: 115  | total loss: [1m[32m0.14689[0m[0m | time: 3.604s
[2K
| Adam | epoch: 013 | loss: 0.14689 - acc: 0.9561 -- iter: 224/269
[A[ATraining Step: 116  | total loss: [1m[32m0.14673[0m[0m | time: 4.235s
[2K
| Adam | epoch: 013 | loss: 0.14673 - acc: 0.9574 -- iter: 256/269
[A[ATraining Step: 117  | total loss: [1m[32m0.13822[0m[0m | time: 5.852s
[2K
| Adam | epoch: 013 | loss: 0.13822 - acc: 0.9585 | val_loss: 0.21781 - val_acc: 0.9176 -- iter: 269/269
--
Training Step: 118  | total loss: [1m[32m0.14213[0m[0m | time: 0.602s
[2K
| Adam | epoch: 014 | loss: 0.14213 - acc: 0.9564 -- iter: 032/269
[A[ATraining Step: 119  | total loss: [1m[32m0.14550[0m[0m | time: 0.897s
[2K
| Adam | epoch: 014 | loss: 0.14550 - acc: 0.9545 -- iter: 064/269
[A[ATraining Step: 120  | total loss: [1m[32m0.13781[0m[0m | time: 1.192s
[2K
| Adam | epoch: 014 | loss: 0.13781 - acc: 0.9591 -- iter: 096/269
[A[ATraining Step: 121  | total loss: [1m[32m0.12778[0m[0m | time: 1.806s
[2K
| Adam | epoch: 014 | loss: 0.12778 - acc: 0.9631 -- iter: 128/269
[A[ATraining Step: 122  | total loss: [1m[32m0.11828[0m[0m | time: 2.411s
[2K
| Adam | epoch: 014 | loss: 0.11828 - acc: 0.9668 -- iter: 160/269
[A[ATraining Step: 123  | total loss: [1m[32m0.11928[0m[0m | time: 3.018s
[2K
| Adam | epoch: 014 | loss: 0.11928 - acc: 0.9639 -- iter: 192/269
[A[ATraining Step: 124  | total loss: [1m[32m0.12434[0m[0m | time: 3.624s
[2K
| Adam | epoch: 014 | loss: 0.12434 - acc: 0.9581 -- iter: 224/269
[A[ATraining Step: 125  | total loss: [1m[32m0.11497[0m[0m | time: 4.220s
[2K
| Adam | epoch: 014 | loss: 0.11497 - acc: 0.9623 -- iter: 256/269
[A[ATraining Step: 126  | total loss: [1m[32m0.10526[0m[0m | time: 5.899s
[2K
| Adam | epoch: 014 | loss: 0.10526 - acc: 0.9661 | val_loss: 0.24599 - val_acc: 0.9176 -- iter: 269/269
--
Training Step: 127  | total loss: [1m[32m0.09777[0m[0m | time: 0.618s
[2K
| Adam | epoch: 015 | loss: 0.09777 - acc: 0.9695 -- iter: 032/269
[A[ATraining Step: 128  | total loss: [1m[32m0.10019[0m[0m | time: 1.228s
[2K
| Adam | epoch: 015 | loss: 0.10019 - acc: 0.9663 -- iter: 064/269
[A[ATraining Step: 129  | total loss: [1m[32m0.09749[0m[0m | time: 1.506s
[2K
| Adam | epoch: 015 | loss: 0.09749 - acc: 0.9665 -- iter: 096/269
[A[ATraining Step: 130  | total loss: [1m[32m0.09064[0m[0m | time: 1.774s
[2K
| Adam | epoch: 015 | loss: 0.09064 - acc: 0.9699 -- iter: 128/269
[A[ATraining Step: 131  | total loss: [1m[32m0.08355[0m[0m | time: 2.371s
[2K
| Adam | epoch: 015 | loss: 0.08355 - acc: 0.9729 -- iter: 160/269
[A[ATraining Step: 132  | total loss: [1m[32m0.07784[0m[0m | time: 2.981s
[2K
| Adam | epoch: 015 | loss: 0.07784 - acc: 0.9756 -- iter: 192/269
[A[ATraining Step: 133  | total loss: [1m[32m0.07152[0m[0m | time: 3.582s
[2K
| Adam | epoch: 015 | loss: 0.07152 - acc: 0.9780 -- iter: 224/269
[A[ATraining Step: 134  | total loss: [1m[32m0.06874[0m[0m | time: 4.184s
[2K
| Adam | epoch: 015 | loss: 0.06874 - acc: 0.9771 -- iter: 256/269
[A[ATraining Step: 135  | total loss: [1m[32m0.06265[0m[0m | time: 5.793s
[2K
| Adam | epoch: 015 | loss: 0.06265 - acc: 0.9794 | val_loss: 0.27775 - val_acc: 0.9176 -- iter: 269/269
--
Validation AUC:0.9756367663344407
Validation AUPRC:0.9799271165428233
Test AUC:0.971111111111111
Test AUPRC:0.9800786264441592
BestTestF1Score	0.96	0.93	0.96	1.0	0.92	37	0	45	3	0.09
BestTestMCCScore	0.93	0.89	0.94	1.0	0.88	35	0	45	5	0.47
BestTestAccuracyScore	0.93	0.89	0.94	1.0	0.88	35	0	45	5	0.47
BestValidationF1Score	0.93	0.86	0.93	0.93	0.93	39	3	40	3	0.09
BestValidationMCC	0.92	0.86	0.93	0.97	0.88	37	1	42	5	0.47
BestValidationAccuracy	0.92	0.86	0.93	0.97	0.88	37	1	42	5	0.47
TestPredictions (Threshold:0.47)
CHEMBL3696421,TP,ACT,1.0	CHEMBL3692310,TP,ACT,0.9900000095367432	CHEMBL256244,TN,INACT,0.0	CHEMBL2376845,TN,INACT,0.0	CHEMBL3692232,TP,ACT,1.0	CHEMBL3692282,TP,ACT,0.9800000190734863	CHEMBL3692316,TP,ACT,1.0	CHEMBL3696406,TP,ACT,1.0	CHEMBL3696374,TP,ACT,0.8899999856948853	CHEMBL2380909,TN,INACT,0.0	CHEMBL2376858,TN,INACT,0.0	CHEMBL1215434,TN,INACT,0.0	CHEMBL3692231,TP,ACT,1.0	CHEMBL3696426,TP,ACT,0.9900000095367432	CHEMBL3221241,TN,INACT,0.0	CHEMBL3617064,TN,INACT,0.0	CHEMBL3696469,TP,ACT,1.0	CHEMBL408340,TN,INACT,0.05000000074505806	CHEMBL3337590,TN,INACT,0.0	CHEMBL3696471,TP,ACT,0.9100000262260437	CHEMBL534967,TN,INACT,0.0	CHEMBL2087063,TN,INACT,0.0	CHEMBL2018453,TN,INACT,0.0	CHEMBL249592,TN,INACT,0.0	CHEMBL3696403,TP,ACT,0.9900000095367432	CHEMBL27768,TN,INACT,0.0	CHEMBL3677853,TN,INACT,0.0	CHEMBL3260892,TN,INACT,0.0	CHEMBL470670,TN,INACT,0.0	CHEMBL2376865,TN,INACT,0.0	CHEMBL3692264,TP,ACT,0.949999988079071	CHEMBL3589904,TN,INACT,0.0	CHEMBL2380891,TN,INACT,0.0	CHEMBL3692333,FN,ACT,0.4300000071525574	CHEMBL3692300,TP,ACT,1.0	CHEMBL3696387,TP,ACT,0.6000000238418579	CHEMBL3692267,TP,ACT,0.9599999785423279	CHEMBL3692334,TP,ACT,0.9200000166893005	CHEMBL3692308,TP,ACT,0.9900000095367432	CHEMBL3692272,FN,ACT,0.0	CHEMBL3696470,TP,ACT,1.0	CHEMBL3696447,TP,ACT,0.9599999785423279	CHEMBL3682816,TN,INACT,0.0	CHEMBL2376868,TN,INACT,0.0	CHEMBL2376860,TN,INACT,0.019999999552965164	CHEMBL2380882,TN,INACT,0.0	CHEMBL3692252,TP,ACT,1.0	CHEMBL3696422,FN,ACT,0.0	CHEMBL3696404,TP,ACT,1.0	CHEMBL509860,TN,INACT,0.0	CHEMBL3422813,TN,INACT,0.0	CHEMBL3696372,TP,ACT,1.0	CHEMBL3353580,TN,INACT,0.0	CHEMBL3696420,TP,ACT,1.0	CHEMBL2376846,TN,INACT,0.009999999776482582	CHEMBL3696472,TP,ACT,0.6600000262260437	CHEMBL3692337,TP,ACT,0.9700000286102295	CHEMBL2380915,TN,INACT,0.0	CHEMBL2385998,TN,INACT,0.0	CHEMBL2380913,TN,INACT,0.0	CHEMBL3692324,TP,ACT,0.9900000095367432	CHEMBL3696395,TP,ACT,0.5899999737739563	CHEMBL316720,TN,INACT,0.0	CHEMBL3692223,FN,ACT,0.10000000149011612	CHEMBL2087058,TN,INACT,0.07000000029802322	CHEMBL2376843,TN,INACT,0.0	CHEMBL2087056,TN,INACT,0.0	CHEMBL3355290,TN,INACT,0.009999999776482582	CHEMBL3696465,TP,ACT,0.8700000047683716	CHEMBL3696467,TP,ACT,1.0	CHEMBL3398240,TN,INACT,0.0	CHEMBL3787319,TN,INACT,0.0	CHEMBL3696396,TP,ACT,1.0	CHEMBL3696390,TP,ACT,0.9800000190734863	CHEMBL3696355,TP,ACT,1.0	CHEMBL1277793,TN,INACT,0.009999999776482582	CHEMBL3696371,TP,ACT,1.0	CHEMBL3325534,TN,INACT,0.0	CHEMBL2385997,TN,INACT,0.0	CHEMBL3613642,TN,INACT,0.0	CHEMBL2312043,TN,INACT,0.0	CHEMBL2376854,TN,INACT,0.0	CHEMBL3692241,TP,ACT,0.8999999761581421	CHEMBL3664218,FN,ACT,0.009999999776482582	CHEMBL3359448,TN,INACT,0.0	

