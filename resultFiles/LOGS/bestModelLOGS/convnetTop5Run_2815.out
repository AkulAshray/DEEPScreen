CNNModel CHEMBL2858 adam 0.001 15 128 0 0.8 False True
Number of active compounds :	469
Number of inactive compounds :	469
---------------------------------
Run id: CNNModel_CHEMBL2858_adam_0.001_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2858_adam_0.001_15_128_0.8_True/
---------------------------------
Training samples: 595
Validation samples: 186
--
Training Step: 1  | time: 1.321s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/595
[A[ATraining Step: 2  | total loss: [1m[32m0.62394[0m[0m | time: 1.931s
[2K
| Adam | epoch: 001 | loss: 0.62394 - acc: 0.4219 -- iter: 064/595
[A[ATraining Step: 3  | total loss: [1m[32m0.68056[0m[0m | time: 2.545s
[2K
| Adam | epoch: 001 | loss: 0.68056 - acc: 0.5114 -- iter: 096/595
[A[ATraining Step: 4  | total loss: [1m[32m0.68747[0m[0m | time: 3.168s
[2K
| Adam | epoch: 001 | loss: 0.68747 - acc: 0.5497 -- iter: 128/595
[A[ATraining Step: 5  | total loss: [1m[32m0.66707[0m[0m | time: 3.794s
[2K
| Adam | epoch: 001 | loss: 0.66707 - acc: 0.6667 -- iter: 160/595
[A[ATraining Step: 6  | total loss: [1m[32m0.67051[0m[0m | time: 4.417s
[2K
| Adam | epoch: 001 | loss: 0.67051 - acc: 0.6198 -- iter: 192/595
[A[ATraining Step: 7  | total loss: [1m[32m0.68358[0m[0m | time: 5.035s
[2K
| Adam | epoch: 001 | loss: 0.68358 - acc: 0.6042 -- iter: 224/595
[A[ATraining Step: 8  | total loss: [1m[32m0.68647[0m[0m | time: 5.644s
[2K
| Adam | epoch: 001 | loss: 0.68647 - acc: 0.5807 -- iter: 256/595
[A[ATraining Step: 9  | total loss: [1m[32m0.69600[0m[0m | time: 6.284s
[2K
| Adam | epoch: 001 | loss: 0.69600 - acc: 0.5380 -- iter: 288/595
[A[ATraining Step: 10  | total loss: [1m[32m0.70329[0m[0m | time: 6.915s
[2K
| Adam | epoch: 001 | loss: 0.70329 - acc: 0.4565 -- iter: 320/595
[A[ATraining Step: 11  | total loss: [1m[32m0.69134[0m[0m | time: 7.521s
[2K
| Adam | epoch: 001 | loss: 0.69134 - acc: 0.5955 -- iter: 352/595
[A[ATraining Step: 12  | total loss: [1m[32m0.68871[0m[0m | time: 8.144s
[2K
| Adam | epoch: 001 | loss: 0.68871 - acc: 0.6369 -- iter: 384/595
[A[ATraining Step: 13  | total loss: [1m[32m0.69063[0m[0m | time: 8.757s
[2K
| Adam | epoch: 001 | loss: 0.69063 - acc: 0.5782 -- iter: 416/595
[A[ATraining Step: 14  | total loss: [1m[32m0.69216[0m[0m | time: 9.372s
[2K
| Adam | epoch: 001 | loss: 0.69216 - acc: 0.5334 -- iter: 448/595
[A[ATraining Step: 15  | total loss: [1m[32m0.69024[0m[0m | time: 9.984s
[2K
| Adam | epoch: 001 | loss: 0.69024 - acc: 0.5815 -- iter: 480/595
[A[ATraining Step: 16  | total loss: [1m[32m0.68820[0m[0m | time: 10.638s
[2K
| Adam | epoch: 001 | loss: 0.68820 - acc: 0.6330 -- iter: 512/595
[A[ATraining Step: 17  | total loss: [1m[32m0.68889[0m[0m | time: 11.252s
[2K
| Adam | epoch: 001 | loss: 0.68889 - acc: 0.6076 -- iter: 544/595
[A[ATraining Step: 18  | total loss: [1m[32m0.69198[0m[0m | time: 11.899s
[2K
| Adam | epoch: 001 | loss: 0.69198 - acc: 0.5379 -- iter: 576/595
[A[ATraining Step: 19  | total loss: [1m[32m0.69075[0m[0m | time: 13.319s
[2K
| Adam | epoch: 001 | loss: 0.69075 - acc: 0.5565 | val_loss: 0.69492 - val_acc: 0.4731 -- iter: 595/595
--
Training Step: 20  | total loss: [1m[32m0.69492[0m[0m | time: 0.402s
[2K
| Adam | epoch: 002 | loss: 0.69492 - acc: 0.4791 -- iter: 032/595
[A[ATraining Step: 21  | total loss: [1m[32m0.69763[0m[0m | time: 1.045s
[2K
| Adam | epoch: 002 | loss: 0.69763 - acc: 0.4284 -- iter: 064/595
[A[ATraining Step: 22  | total loss: [1m[32m0.69591[0m[0m | time: 1.666s
[2K
| Adam | epoch: 002 | loss: 0.69591 - acc: 0.4593 -- iter: 096/595
[A[ATraining Step: 23  | total loss: [1m[32m0.69563[0m[0m | time: 2.268s
[2K
| Adam | epoch: 002 | loss: 0.69563 - acc: 0.4620 -- iter: 128/595
[A[ATraining Step: 24  | total loss: [1m[32m0.69627[0m[0m | time: 2.883s
[2K
| Adam | epoch: 002 | loss: 0.69627 - acc: 0.4463 -- iter: 160/595
[A[ATraining Step: 25  | total loss: [1m[32m0.69618[0m[0m | time: 3.508s
[2K
| Adam | epoch: 002 | loss: 0.69618 - acc: 0.4439 -- iter: 192/595
[A[ATraining Step: 26  | total loss: [1m[32m0.69510[0m[0m | time: 4.385s
[2K
| Adam | epoch: 002 | loss: 0.69510 - acc: 0.4670 -- iter: 224/595
[A[ATraining Step: 27  | total loss: [1m[32m0.69431[0m[0m | time: 5.382s
[2K
| Adam | epoch: 002 | loss: 0.69431 - acc: 0.4836 -- iter: 256/595
[A[ATraining Step: 28  | total loss: [1m[32m0.69380[0m[0m | time: 6.289s
[2K
| Adam | epoch: 002 | loss: 0.69380 - acc: 0.4955 -- iter: 288/595
[A[ATraining Step: 29  | total loss: [1m[32m0.69395[0m[0m | time: 7.210s
[2K
| Adam | epoch: 002 | loss: 0.69395 - acc: 0.4890 -- iter: 320/595
[A[ATraining Step: 30  | total loss: [1m[32m0.69334[0m[0m | time: 8.084s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.5064 -- iter: 352/595
[A[ATraining Step: 31  | total loss: [1m[32m0.69310[0m[0m | time: 9.024s
[2K
| Adam | epoch: 002 | loss: 0.69310 - acc: 0.5121 -- iter: 384/595
[A[ATraining Step: 32  | total loss: [1m[32m0.69270[0m[0m | time: 9.908s
[2K
| Adam | epoch: 002 | loss: 0.69270 - acc: 0.5235 -- iter: 416/595
[A[ATraining Step: 33  | total loss: [1m[32m0.69366[0m[0m | time: 10.919s
[2K
| Adam | epoch: 002 | loss: 0.69366 - acc: 0.4909 -- iter: 448/595
[A[ATraining Step: 34  | total loss: [1m[32m0.69353[0m[0m | time: 11.936s
[2K
| Adam | epoch: 002 | loss: 0.69353 - acc: 0.4928 -- iter: 480/595
[A[ATraining Step: 35  | total loss: [1m[32m0.69296[0m[0m | time: 12.796s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5140 -- iter: 512/595
[A[ATraining Step: 36  | total loss: [1m[32m0.69269[0m[0m | time: 13.686s
[2K
| Adam | epoch: 002 | loss: 0.69269 - acc: 0.5239 -- iter: 544/595
[A[ATraining Step: 37  | total loss: [1m[32m0.69297[0m[0m | time: 14.658s
[2K
| Adam | epoch: 002 | loss: 0.69297 - acc: 0.5129 -- iter: 576/595
[A[ATraining Step: 38  | total loss: [1m[32m0.69268[0m[0m | time: 16.548s
[2K
| Adam | epoch: 002 | loss: 0.69268 - acc: 0.5226 | val_loss: 0.69397 - val_acc: 0.4731 -- iter: 595/595
--
Training Step: 39  | total loss: [1m[32m0.69278[0m[0m | time: 1.368s
[2K
| Adam | epoch: 003 | loss: 0.69278 - acc: 0.5182 -- iter: 032/595
[A[ATraining Step: 40  | total loss: [1m[32m0.69275[0m[0m | time: 5.597s
[2K
| Adam | epoch: 003 | loss: 0.69275 - acc: 0.5198 -- iter: 064/595
[A[ATraining Step: 41  | total loss: [1m[32m0.69270[0m[0m | time: 15.869s
[2K
| Adam | epoch: 003 | loss: 0.69270 - acc: 0.5210 -- iter: 096/595
[A[ATraining Step: 42  | total loss: [1m[32m0.69297[0m[0m | time: 16.727s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5116 -- iter: 128/595
[A[ATraining Step: 43  | total loss: [1m[32m0.69234[0m[0m | time: 17.749s
[2K
| Adam | epoch: 003 | loss: 0.69234 - acc: 0.5316 -- iter: 160/595
[A[ATraining Step: 44  | total loss: [1m[32m0.69249[0m[0m | time: 18.654s
[2K
| Adam | epoch: 003 | loss: 0.69249 - acc: 0.5261 -- iter: 192/595
[A[ATraining Step: 45  | total loss: [1m[32m0.69296[0m[0m | time: 19.750s
[2K
| Adam | epoch: 003 | loss: 0.69296 - acc: 0.5111 -- iter: 224/595
[A[ATraining Step: 46  | total loss: [1m[32m0.69178[0m[0m | time: 20.738s
[2K
| Adam | epoch: 003 | loss: 0.69178 - acc: 0.5457 -- iter: 256/595
[A[ATraining Step: 47  | total loss: [1m[32m0.69148[0m[0m | time: 21.714s
[2K
| Adam | epoch: 003 | loss: 0.69148 - acc: 0.5535 -- iter: 288/595
[A[ATraining Step: 48  | total loss: [1m[32m0.69232[0m[0m | time: 22.583s
[2K
| Adam | epoch: 003 | loss: 0.69232 - acc: 0.5299 -- iter: 320/595
[A[ATraining Step: 49  | total loss: [1m[32m0.69209[0m[0m | time: 23.683s
[2K
| Adam | epoch: 003 | loss: 0.69209 - acc: 0.5350 -- iter: 352/595
[A[ATraining Step: 50  | total loss: [1m[32m0.69229[0m[0m | time: 25.056s
[2K
| Adam | epoch: 003 | loss: 0.69229 - acc: 0.5296 -- iter: 384/595
[A[ATraining Step: 51  | total loss: [1m[32m0.69221[0m[0m | time: 26.727s
[2K
| Adam | epoch: 003 | loss: 0.69221 - acc: 0.5298 -- iter: 416/595
[A[ATraining Step: 52  | total loss: [1m[32m0.69216[0m[0m | time: 31.652s
[2K
| Adam | epoch: 003 | loss: 0.69216 - acc: 0.5301 -- iter: 448/595
[A[ATraining Step: 53  | total loss: [1m[32m0.69236[0m[0m | time: 38.294s
[2K
| Adam | epoch: 003 | loss: 0.69236 - acc: 0.5256 -- iter: 480/595
[A[ATraining Step: 54  | total loss: [1m[32m0.69076[0m[0m | time: 39.229s
[2K
| Adam | epoch: 003 | loss: 0.69076 - acc: 0.5537 -- iter: 512/595
[A[ATraining Step: 55  | total loss: [1m[32m0.69148[0m[0m | time: 40.177s
[2K
| Adam | epoch: 003 | loss: 0.69148 - acc: 0.5415 -- iter: 544/595
[A[ATraining Step: 56  | total loss: [1m[32m0.69295[0m[0m | time: 41.162s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.5181 -- iter: 576/595
[A[ATraining Step: 57  | total loss: [1m[32m0.69270[0m[0m | time: 43.190s
[2K
| Adam | epoch: 003 | loss: 0.69270 - acc: 0.5199 | val_loss: 0.69520 - val_acc: 0.4731 -- iter: 595/595
--
Training Step: 58  | total loss: [1m[32m0.69302[0m[0m | time: 2.653s
[2K
| Adam | epoch: 004 | loss: 0.69302 - acc: 0.5129 -- iter: 032/595
[A[ATraining Step: 59  | total loss: [1m[32m0.69225[0m[0m | time: 3.790s
[2K
| Adam | epoch: 004 | loss: 0.69225 - acc: 0.5238 -- iter: 064/595
[A[ATraining Step: 60  | total loss: [1m[32m0.69205[0m[0m | time: 10.910s
[2K
| Adam | epoch: 004 | loss: 0.69205 - acc: 0.5241 -- iter: 096/595
[A[ATraining Step: 61  | total loss: [1m[32m0.69185[0m[0m | time: 23.770s
[2K
| Adam | epoch: 004 | loss: 0.69185 - acc: 0.5244 -- iter: 128/595
[A[ATraining Step: 62  | total loss: [1m[32m0.69199[0m[0m | time: 27.449s
[2K
| Adam | epoch: 004 | loss: 0.69199 - acc: 0.5213 -- iter: 160/595
[A[ATraining Step: 63  | total loss: [1m[32m0.69113[0m[0m | time: 28.500s
[2K
| Adam | epoch: 004 | loss: 0.69113 - acc: 0.5305 -- iter: 192/595
[A[ATraining Step: 64  | total loss: [1m[32m0.69056[0m[0m | time: 29.449s
[2K
| Adam | epoch: 004 | loss: 0.69056 - acc: 0.5345 -- iter: 224/595
[A[ATraining Step: 65  | total loss: [1m[32m0.69148[0m[0m | time: 30.410s
[2K
| Adam | epoch: 004 | loss: 0.69148 - acc: 0.5264 -- iter: 256/595
[A[ATraining Step: 66  | total loss: [1m[32m0.68999[0m[0m | time: 31.487s
[2K
| Adam | epoch: 004 | loss: 0.68999 - acc: 0.5346 -- iter: 288/595
[A[ATraining Step: 67  | total loss: [1m[32m0.68706[0m[0m | time: 32.523s
[2K
| Adam | epoch: 004 | loss: 0.68706 - acc: 0.5492 -- iter: 320/595
[A[ATraining Step: 68  | total loss: [1m[32m0.69466[0m[0m | time: 33.388s
[2K
| Adam | epoch: 004 | loss: 0.69466 - acc: 0.5174 -- iter: 352/595
[A[ATraining Step: 69  | total loss: [1m[32m0.69589[0m[0m | time: 34.406s
[2K
| Adam | epoch: 004 | loss: 0.69589 - acc: 0.5081 -- iter: 384/595
[A[ATraining Step: 70  | total loss: [1m[32m0.69305[0m[0m | time: 35.618s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5216 -- iter: 416/595
[A[ATraining Step: 71  | total loss: [1m[32m0.68928[0m[0m | time: 36.861s
[2K
| Adam | epoch: 004 | loss: 0.68928 - acc: 0.5440 -- iter: 448/595
[A[ATraining Step: 72  | total loss: [1m[32m0.68896[0m[0m | time: 40.869s
[2K
| Adam | epoch: 004 | loss: 0.68896 - acc: 0.5426 -- iter: 480/595
[A[ATraining Step: 73  | total loss: [1m[32m0.68971[0m[0m | time: 41.700s
[2K
| Adam | epoch: 004 | loss: 0.68971 - acc: 0.5344 -- iter: 512/595
[A[ATraining Step: 74  | total loss: [1m[32m0.68651[0m[0m | time: 42.609s
[2K
| Adam | epoch: 004 | loss: 0.68651 - acc: 0.5512 -- iter: 544/595
[A[ATraining Step: 75  | total loss: [1m[32m0.68482[0m[0m | time: 43.577s
[2K
| Adam | epoch: 004 | loss: 0.68482 - acc: 0.5558 -- iter: 576/595
[A[ATraining Step: 76  | total loss: [1m[32m0.68220[0m[0m | time: 45.590s
[2K
| Adam | epoch: 004 | loss: 0.68220 - acc: 0.5632 | val_loss: 0.70629 - val_acc: 0.4731 -- iter: 595/595
--
Training Step: 77  | total loss: [1m[32m0.68301[0m[0m | time: 1.401s
[2K
| Adam | epoch: 005 | loss: 0.68301 - acc: 0.5565 -- iter: 032/595
[A[ATraining Step: 78  | total loss: [1m[32m0.68322[0m[0m | time: 3.900s
[2K
| Adam | epoch: 005 | loss: 0.68322 - acc: 0.5539 -- iter: 064/595
[A[ATraining Step: 79  | total loss: [1m[32m0.69353[0m[0m | time: 8.502s
[2K
| Adam | epoch: 005 | loss: 0.69353 - acc: 0.5289 -- iter: 096/595
[A[ATraining Step: 80  | total loss: [1m[32m0.68721[0m[0m | time: 22.093s
[2K
| Adam | epoch: 005 | loss: 0.68721 - acc: 0.5394 -- iter: 128/595
[A[ATraining Step: 81  | total loss: [1m[32m0.68166[0m[0m | time: 23.706s
[2K
| Adam | epoch: 005 | loss: 0.68166 - acc: 0.5487 -- iter: 160/595
[A[ATraining Step: 82  | total loss: [1m[32m0.68013[0m[0m | time: 24.610s
[2K
| Adam | epoch: 005 | loss: 0.68013 - acc: 0.5501 -- iter: 192/595
[A[ATraining Step: 83  | total loss: [1m[32m0.67707[0m[0m | time: 25.588s
[2K
| Adam | epoch: 005 | loss: 0.67707 - acc: 0.5576 -- iter: 224/595
[A[ATraining Step: 84  | total loss: [1m[32m0.67039[0m[0m | time: 26.528s
[2K
| Adam | epoch: 005 | loss: 0.67039 - acc: 0.5737 -- iter: 256/595
[A[ATraining Step: 85  | total loss: [1m[32m0.67467[0m[0m | time: 27.562s
[2K
| Adam | epoch: 005 | loss: 0.67467 - acc: 0.5632 -- iter: 288/595
[A[ATraining Step: 86  | total loss: [1m[32m0.67873[0m[0m | time: 28.663s
[2K
| Adam | epoch: 005 | loss: 0.67873 - acc: 0.5475 -- iter: 320/595
[A[ATraining Step: 87  | total loss: [1m[32m0.68169[0m[0m | time: 29.597s
[2K
| Adam | epoch: 005 | loss: 0.68169 - acc: 0.5334 -- iter: 352/595
[A[ATraining Step: 88  | total loss: [1m[32m0.67865[0m[0m | time: 30.683s
[2K
| Adam | epoch: 005 | loss: 0.67865 - acc: 0.5332 -- iter: 384/595
[A[ATraining Step: 89  | total loss: [1m[32m0.67776[0m[0m | time: 32.010s
[2K
| Adam | epoch: 005 | loss: 0.67776 - acc: 0.5267 -- iter: 416/595
[A[ATraining Step: 90  | total loss: [1m[32m0.67447[0m[0m | time: 33.150s
[2K
| Adam | epoch: 005 | loss: 0.67447 - acc: 0.5397 -- iter: 448/595
[A[ATraining Step: 91  | total loss: [1m[32m0.67224[0m[0m | time: 35.953s
[2K
| Adam | epoch: 005 | loss: 0.67224 - acc: 0.5357 -- iter: 480/595
[A[ATraining Step: 92  | total loss: [1m[32m0.67174[0m[0m | time: 36.886s
[2K
| Adam | epoch: 005 | loss: 0.67174 - acc: 0.5353 -- iter: 512/595
[A[ATraining Step: 93  | total loss: [1m[32m0.66010[0m[0m | time: 37.892s
[2K
| Adam | epoch: 005 | loss: 0.66010 - acc: 0.5567 -- iter: 544/595
[A[ATraining Step: 94  | total loss: [1m[32m0.65225[0m[0m | time: 38.914s
[2K
| Adam | epoch: 005 | loss: 0.65225 - acc: 0.5604 -- iter: 576/595
[A[ATraining Step: 95  | total loss: [1m[32m0.65535[0m[0m | time: 41.178s
[2K
| Adam | epoch: 005 | loss: 0.65535 - acc: 0.5544 | val_loss: 0.62253 - val_acc: 0.4731 -- iter: 595/595
--
Training Step: 96  | total loss: [1m[32m0.65425[0m[0m | time: 1.257s
[2K
| Adam | epoch: 006 | loss: 0.65425 - acc: 0.5521 -- iter: 032/595
[A[ATraining Step: 97  | total loss: [1m[32m0.64922[0m[0m | time: 6.936s
[2K
| Adam | epoch: 006 | loss: 0.64922 - acc: 0.5438 -- iter: 064/595
[A[ATraining Step: 98  | total loss: [1m[32m0.64502[0m[0m | time: 9.851s
[2K
| Adam | epoch: 006 | loss: 0.64502 - acc: 0.5488 -- iter: 096/595
[A[ATraining Step: 99  | total loss: [1m[32m0.64469[0m[0m | time: 16.341s
[2K
| Adam | epoch: 006 | loss: 0.64469 - acc: 0.5689 -- iter: 128/595
[A[ATraining Step: 100  | total loss: [1m[32m0.64449[0m[0m | time: 16.915s
[2K
| Adam | epoch: 006 | loss: 0.64449 - acc: 0.5751 -- iter: 160/595
[A[ATraining Step: 101  | total loss: [1m[32m0.64156[0m[0m | time: 17.882s
[2K
| Adam | epoch: 006 | loss: 0.64156 - acc: 0.5861 -- iter: 192/595
[A[ATraining Step: 102  | total loss: [1m[32m0.63698[0m[0m | time: 18.851s
[2K
| Adam | epoch: 006 | loss: 0.63698 - acc: 0.5931 -- iter: 224/595
[A[ATraining Step: 103  | total loss: [1m[32m0.62851[0m[0m | time: 19.872s
[2K
| Adam | epoch: 006 | loss: 0.62851 - acc: 0.6119 -- iter: 256/595
[A[ATraining Step: 104  | total loss: [1m[32m0.62775[0m[0m | time: 20.892s
[2K
| Adam | epoch: 006 | loss: 0.62775 - acc: 0.5976 -- iter: 288/595
[A[ATraining Step: 105  | total loss: [1m[32m0.61606[0m[0m | time: 21.900s
[2K
| Adam | epoch: 006 | loss: 0.61606 - acc: 0.6097 -- iter: 320/595
[A[ATraining Step: 106  | total loss: [1m[32m0.61104[0m[0m | time: 22.858s
[2K
| Adam | epoch: 006 | loss: 0.61104 - acc: 0.6268 -- iter: 352/595
[A[ATraining Step: 107  | total loss: [1m[32m0.61126[0m[0m | time: 24.009s
[2K
| Adam | epoch: 006 | loss: 0.61126 - acc: 0.6360 -- iter: 384/595
[A[ATraining Step: 108  | total loss: [1m[32m0.61565[0m[0m | time: 25.325s
[2K
| Adam | epoch: 006 | loss: 0.61565 - acc: 0.6381 -- iter: 416/595
[A[ATraining Step: 109  | total loss: [1m[32m0.61315[0m[0m | time: 26.317s
[2K
| Adam | epoch: 006 | loss: 0.61315 - acc: 0.6461 -- iter: 448/595
[A[ATraining Step: 110  | total loss: [1m[32m0.60152[0m[0m | time: 31.045s
[2K
| Adam | epoch: 006 | loss: 0.60152 - acc: 0.6565 -- iter: 480/595
[A[ATraining Step: 111  | total loss: [1m[32m0.57217[0m[0m | time: 33.804s
[2K
| Adam | epoch: 006 | loss: 0.57217 - acc: 0.6815 -- iter: 512/595
[A[ATraining Step: 112  | total loss: [1m[32m0.56219[0m[0m | time: 34.861s
[2K
| Adam | epoch: 006 | loss: 0.56219 - acc: 0.6977 -- iter: 544/595
[A[ATraining Step: 113  | total loss: [1m[32m0.58433[0m[0m | time: 35.958s
[2K
| Adam | epoch: 006 | loss: 0.58433 - acc: 0.7029 -- iter: 576/595
[A[ATraining Step: 114  | total loss: [1m[32m0.58069[0m[0m | time: 38.082s
[2K
| Adam | epoch: 006 | loss: 0.58069 - acc: 0.7014 | val_loss: 0.59599 - val_acc: 0.6935 -- iter: 595/595
--
Training Step: 115  | total loss: [1m[32m0.58147[0m[0m | time: 2.230s
[2K
| Adam | epoch: 007 | loss: 0.58147 - acc: 0.7031 -- iter: 032/595
[A[ATraining Step: 116  | total loss: [1m[32m0.58318[0m[0m | time: 3.277s
[2K
| Adam | epoch: 007 | loss: 0.58318 - acc: 0.6953 -- iter: 064/595
[A[ATraining Step: 117  | total loss: [1m[32m0.57555[0m[0m | time: 4.303s
[2K
| Adam | epoch: 007 | loss: 0.57555 - acc: 0.7008 -- iter: 096/595
[A[ATraining Step: 118  | total loss: [1m[32m0.57743[0m[0m | time: 5.257s
[2K
| Adam | epoch: 007 | loss: 0.57743 - acc: 0.6901 -- iter: 128/595
[A[ATraining Step: 119  | total loss: [1m[32m0.57879[0m[0m | time: 5.884s
[2K
| Adam | epoch: 007 | loss: 0.57879 - acc: 0.6992 -- iter: 160/595
[A[ATraining Step: 120  | total loss: [1m[32m0.57542[0m[0m | time: 6.609s
[2K
| Adam | epoch: 007 | loss: 0.57542 - acc: 0.7030 -- iter: 192/595
[A[ATraining Step: 121  | total loss: [1m[32m0.57324[0m[0m | time: 7.683s
[2K
| Adam | epoch: 007 | loss: 0.57324 - acc: 0.7011 -- iter: 224/595
[A[ATraining Step: 122  | total loss: [1m[32m0.56789[0m[0m | time: 8.559s
[2K
| Adam | epoch: 007 | loss: 0.56789 - acc: 0.7029 -- iter: 256/595
[A[ATraining Step: 123  | total loss: [1m[32m0.56578[0m[0m | time: 9.846s
[2K
| Adam | epoch: 007 | loss: 0.56578 - acc: 0.7107 -- iter: 288/595
[A[ATraining Step: 124  | total loss: [1m[32m0.54923[0m[0m | time: 11.183s
[2K
| Adam | epoch: 007 | loss: 0.54923 - acc: 0.7303 -- iter: 320/595
[A[ATraining Step: 125  | total loss: [1m[32m0.54194[0m[0m | time: 12.835s
[2K
| Adam | epoch: 007 | loss: 0.54194 - acc: 0.7354 -- iter: 352/595
[A[ATraining Step: 126  | total loss: [1m[32m0.53323[0m[0m | time: 18.342s
[2K
| Adam | epoch: 007 | loss: 0.53323 - acc: 0.7493 -- iter: 384/595
[A[ATraining Step: 127  | total loss: [1m[32m0.54069[0m[0m | time: 22.074s
[2K
| Adam | epoch: 007 | loss: 0.54069 - acc: 0.7400 -- iter: 416/595
[A[ATraining Step: 128  | total loss: [1m[32m0.55317[0m[0m | time: 25.731s
[2K
| Adam | epoch: 007 | loss: 0.55317 - acc: 0.7379 -- iter: 448/595
[A[ATraining Step: 129  | total loss: [1m[32m0.55998[0m[0m | time: 26.676s
[2K
| Adam | epoch: 007 | loss: 0.55998 - acc: 0.7328 -- iter: 480/595
[A[ATraining Step: 130  | total loss: [1m[32m0.56161[0m[0m | time: 27.709s
[2K
| Adam | epoch: 007 | loss: 0.56161 - acc: 0.7377 -- iter: 512/595
[A[ATraining Step: 131  | total loss: [1m[32m0.54570[0m[0m | time: 28.708s
[2K
| Adam | epoch: 007 | loss: 0.54570 - acc: 0.7452 -- iter: 544/595
[A[ATraining Step: 132  | total loss: [1m[32m0.52935[0m[0m | time: 29.954s
[2K
| Adam | epoch: 007 | loss: 0.52935 - acc: 0.7519 -- iter: 576/595
[A[ATraining Step: 133  | total loss: [1m[32m0.51782[0m[0m | time: 32.015s
[2K
| Adam | epoch: 007 | loss: 0.51782 - acc: 0.7580 | val_loss: 0.47174 - val_acc: 0.7473 -- iter: 595/595
--
Training Step: 134  | total loss: [1m[32m0.51469[0m[0m | time: 4.774s
[2K
| Adam | epoch: 008 | loss: 0.51469 - acc: 0.7572 -- iter: 032/595
[A[ATraining Step: 135  | total loss: [1m[32m0.50205[0m[0m | time: 6.458s
[2K
| Adam | epoch: 008 | loss: 0.50205 - acc: 0.7689 -- iter: 064/595
[A[ATraining Step: 136  | total loss: [1m[32m0.49416[0m[0m | time: 17.778s
[2K
| Adam | epoch: 008 | loss: 0.49416 - acc: 0.7764 -- iter: 096/595
[A[ATraining Step: 137  | total loss: [1m[32m0.47886[0m[0m | time: 19.168s
[2K
| Adam | epoch: 008 | loss: 0.47886 - acc: 0.7863 -- iter: 128/595
[A[ATraining Step: 138  | total loss: [1m[32m0.48188[0m[0m | time: 20.165s
[2K
| Adam | epoch: 008 | loss: 0.48188 - acc: 0.7795 -- iter: 160/595
[A[ATraining Step: 139  | total loss: [1m[32m0.47425[0m[0m | time: 20.786s
[2K
| Adam | epoch: 008 | loss: 0.47425 - acc: 0.7797 -- iter: 192/595
[A[ATraining Step: 140  | total loss: [1m[32m0.46029[0m[0m | time: 21.416s
[2K
| Adam | epoch: 008 | loss: 0.46029 - acc: 0.7912 -- iter: 224/595
[A[ATraining Step: 141  | total loss: [1m[32m0.46280[0m[0m | time: 22.433s
[2K
| Adam | epoch: 008 | loss: 0.46280 - acc: 0.7805 -- iter: 256/595
[A[ATraining Step: 142  | total loss: [1m[32m0.46870[0m[0m | time: 23.562s
[2K
| Adam | epoch: 008 | loss: 0.46870 - acc: 0.7712 -- iter: 288/595
[A[ATraining Step: 143  | total loss: [1m[32m0.44914[0m[0m | time: 24.517s
[2K
| Adam | epoch: 008 | loss: 0.44914 - acc: 0.7816 -- iter: 320/595
[A[ATraining Step: 144  | total loss: [1m[32m0.43921[0m[0m | time: 25.427s
[2K
| Adam | epoch: 008 | loss: 0.43921 - acc: 0.7909 -- iter: 352/595
[A[ATraining Step: 145  | total loss: [1m[32m0.43210[0m[0m | time: 26.722s
[2K
| Adam | epoch: 008 | loss: 0.43210 - acc: 0.7931 -- iter: 384/595
[A[ATraining Step: 146  | total loss: [1m[32m0.42459[0m[0m | time: 28.047s
[2K
| Adam | epoch: 008 | loss: 0.42459 - acc: 0.8013 -- iter: 416/595
[A[ATraining Step: 147  | total loss: [1m[32m0.40720[0m[0m | time: 29.288s
[2K
| Adam | epoch: 008 | loss: 0.40720 - acc: 0.8118 -- iter: 448/595
[A[ATraining Step: 148  | total loss: [1m[32m0.44506[0m[0m | time: 31.238s
[2K
| Adam | epoch: 008 | loss: 0.44506 - acc: 0.8056 -- iter: 480/595
[A[ATraining Step: 149  | total loss: [1m[32m0.45471[0m[0m | time: 32.195s
[2K
| Adam | epoch: 008 | loss: 0.45471 - acc: 0.7907 -- iter: 512/595
[A[ATraining Step: 150  | total loss: [1m[32m0.43355[0m[0m | time: 33.102s
[2K
| Adam | epoch: 008 | loss: 0.43355 - acc: 0.7960 -- iter: 544/595
[A[ATraining Step: 151  | total loss: [1m[32m0.41709[0m[0m | time: 34.105s
[2K
| Adam | epoch: 008 | loss: 0.41709 - acc: 0.8039 -- iter: 576/595
[A[ATraining Step: 152  | total loss: [1m[32m0.40654[0m[0m | time: 36.150s
[2K
| Adam | epoch: 008 | loss: 0.40654 - acc: 0.8110 | val_loss: 0.30164 - val_acc: 0.8548 -- iter: 595/595
--
Training Step: 153  | total loss: [1m[32m0.38914[0m[0m | time: 2.481s
[2K
| Adam | epoch: 009 | loss: 0.38914 - acc: 0.8236 -- iter: 032/595
[A[ATraining Step: 154  | total loss: [1m[32m0.36165[0m[0m | time: 11.197s
[2K
| Adam | epoch: 009 | loss: 0.36165 - acc: 0.8413 -- iter: 064/595
[A[ATraining Step: 155  | total loss: [1m[32m0.35279[0m[0m | time: 12.156s
[2K
| Adam | epoch: 009 | loss: 0.35279 - acc: 0.8478 -- iter: 096/595
[A[ATraining Step: 156  | total loss: [1m[32m0.34082[0m[0m | time: 13.258s
[2K
| Adam | epoch: 009 | loss: 0.34082 - acc: 0.8536 -- iter: 128/595
[A[ATraining Step: 157  | total loss: [1m[32m0.31745[0m[0m | time: 14.325s
[2K
| Adam | epoch: 009 | loss: 0.31745 - acc: 0.8651 -- iter: 160/595
[A[ATraining Step: 158  | total loss: [1m[32m0.33771[0m[0m | time: 15.475s
[2K
| Adam | epoch: 009 | loss: 0.33771 - acc: 0.8567 -- iter: 192/595
[A[ATraining Step: 159  | total loss: [1m[32m0.35761[0m[0m | time: 16.127s
[2K
| Adam | epoch: 009 | loss: 0.35761 - acc: 0.8461 -- iter: 224/595
[A[ATraining Step: 160  | total loss: [1m[32m0.35139[0m[0m | time: 16.717s
[2K
| Adam | epoch: 009 | loss: 0.35139 - acc: 0.8562 -- iter: 256/595
[A[ATraining Step: 161  | total loss: [1m[32m0.34565[0m[0m | time: 17.659s
[2K
| Adam | epoch: 009 | loss: 0.34565 - acc: 0.8653 -- iter: 288/595
[A[ATraining Step: 162  | total loss: [1m[32m0.34876[0m[0m | time: 18.977s
[2K
| Adam | epoch: 009 | loss: 0.34876 - acc: 0.8569 -- iter: 320/595
[A[ATraining Step: 163  | total loss: [1m[32m0.34616[0m[0m | time: 20.348s
[2K
| Adam | epoch: 009 | loss: 0.34616 - acc: 0.8587 -- iter: 352/595
[A[ATraining Step: 164  | total loss: [1m[32m0.34858[0m[0m | time: 22.935s
[2K
| Adam | epoch: 009 | loss: 0.34858 - acc: 0.8603 -- iter: 384/595
[A[ATraining Step: 165  | total loss: [1m[32m0.35402[0m[0m | time: 34.700s
[2K
| Adam | epoch: 009 | loss: 0.35402 - acc: 0.8587 -- iter: 416/595
[A[ATraining Step: 166  | total loss: [1m[32m0.35496[0m[0m | time: 35.640s
[2K
| Adam | epoch: 009 | loss: 0.35496 - acc: 0.8572 -- iter: 448/595
[A[ATraining Step: 167  | total loss: [1m[32m0.34150[0m[0m | time: 36.711s
[2K
| Adam | epoch: 009 | loss: 0.34150 - acc: 0.8652 -- iter: 480/595
[A[ATraining Step: 168  | total loss: [1m[32m0.32617[0m[0m | time: 37.760s
[2K
| Adam | epoch: 009 | loss: 0.32617 - acc: 0.8787 -- iter: 512/595
[A[ATraining Step: 169  | total loss: [1m[32m0.32246[0m[0m | time: 38.877s
[2K
| Adam | epoch: 009 | loss: 0.32246 - acc: 0.8752 -- iter: 544/595
[A[ATraining Step: 170  | total loss: [1m[32m0.32105[0m[0m | time: 40.055s
[2K
| Adam | epoch: 009 | loss: 0.32105 - acc: 0.8752 -- iter: 576/595
[A[ATraining Step: 171  | total loss: [1m[32m0.31644[0m[0m | time: 42.168s
[2K
| Adam | epoch: 009 | loss: 0.31644 - acc: 0.8783 | val_loss: 0.28284 - val_acc: 0.9032 -- iter: 595/595
--
Training Step: 172  | total loss: [1m[32m0.30593[0m[0m | time: 0.664s
[2K
| Adam | epoch: 010 | loss: 0.30593 - acc: 0.8842 -- iter: 032/595
[A[ATraining Step: 173  | total loss: [1m[32m0.29950[0m[0m | time: 1.271s
[2K
| Adam | epoch: 010 | loss: 0.29950 - acc: 0.8802 -- iter: 064/595
[A[ATraining Step: 174  | total loss: [1m[32m0.28513[0m[0m | time: 1.890s
[2K
| Adam | epoch: 010 | loss: 0.28513 - acc: 0.8859 -- iter: 096/595
[A[ATraining Step: 175  | total loss: [1m[32m0.27544[0m[0m | time: 2.571s
[2K
| Adam | epoch: 010 | loss: 0.27544 - acc: 0.8911 -- iter: 128/595
[A[ATraining Step: 176  | total loss: [1m[32m0.26153[0m[0m | time: 3.259s
[2K
| Adam | epoch: 010 | loss: 0.26153 - acc: 0.9020 -- iter: 160/595
[A[ATraining Step: 177  | total loss: [1m[32m0.26652[0m[0m | time: 3.907s
[2K
| Adam | epoch: 010 | loss: 0.26652 - acc: 0.9024 -- iter: 192/595
[A[ATraining Step: 178  | total loss: [1m[32m0.25628[0m[0m | time: 4.566s
[2K
| Adam | epoch: 010 | loss: 0.25628 - acc: 0.9059 -- iter: 224/595
[A[ATraining Step: 179  | total loss: [1m[32m0.25134[0m[0m | time: 4.959s
[2K
| Adam | epoch: 010 | loss: 0.25134 - acc: 0.9059 -- iter: 256/595
[A[ATraining Step: 180  | total loss: [1m[32m0.25920[0m[0m | time: 5.382s
[2K
| Adam | epoch: 010 | loss: 0.25920 - acc: 0.8995 -- iter: 288/595
[A[ATraining Step: 181  | total loss: [1m[32m0.26104[0m[0m | time: 6.054s
[2K
| Adam | epoch: 010 | loss: 0.26104 - acc: 0.9043 -- iter: 320/595
[A[ATraining Step: 182  | total loss: [1m[32m0.26702[0m[0m | time: 6.729s
[2K
| Adam | epoch: 010 | loss: 0.26702 - acc: 0.9014 -- iter: 352/595
[A[ATraining Step: 183  | total loss: [1m[32m0.25646[0m[0m | time: 7.375s
[2K
| Adam | epoch: 010 | loss: 0.25646 - acc: 0.9081 -- iter: 384/595
[A[ATraining Step: 184  | total loss: [1m[32m0.24908[0m[0m | time: 8.066s
[2K
| Adam | epoch: 010 | loss: 0.24908 - acc: 0.9142 -- iter: 416/595
[A[ATraining Step: 185  | total loss: [1m[32m0.26106[0m[0m | time: 8.736s
[2K
| Adam | epoch: 010 | loss: 0.26106 - acc: 0.9103 -- iter: 448/595
[A[ATraining Step: 186  | total loss: [1m[32m0.25243[0m[0m | time: 9.380s
[2K
| Adam | epoch: 010 | loss: 0.25243 - acc: 0.9130 -- iter: 480/595
[A[ATraining Step: 187  | total loss: [1m[32m0.27560[0m[0m | time: 10.074s
[2K
| Adam | epoch: 010 | loss: 0.27560 - acc: 0.9154 -- iter: 512/595
[A[ATraining Step: 188  | total loss: [1m[32m0.28091[0m[0m | time: 10.698s
[2K
| Adam | epoch: 010 | loss: 0.28091 - acc: 0.9083 -- iter: 544/595
[A[ATraining Step: 189  | total loss: [1m[32m0.27288[0m[0m | time: 11.366s
[2K
| Adam | epoch: 010 | loss: 0.27288 - acc: 0.9112 -- iter: 576/595
[A[ATraining Step: 190  | total loss: [1m[32m0.27573[0m[0m | time: 13.087s
[2K
| Adam | epoch: 010 | loss: 0.27573 - acc: 0.9076 | val_loss: 0.30286 - val_acc: 0.8441 -- iter: 595/595
--
Training Step: 191  | total loss: [1m[32m0.26624[0m[0m | time: 0.670s
[2K
| Adam | epoch: 011 | loss: 0.26624 - acc: 0.9074 -- iter: 032/595
[A[ATraining Step: 192  | total loss: [1m[32m0.25080[0m[0m | time: 1.369s
[2K
| Adam | epoch: 011 | loss: 0.25080 - acc: 0.9167 -- iter: 064/595
[A[ATraining Step: 193  | total loss: [1m[32m0.24230[0m[0m | time: 1.994s
[2K
| Adam | epoch: 011 | loss: 0.24230 - acc: 0.9219 -- iter: 096/595
[A[ATraining Step: 194  | total loss: [1m[32m0.24170[0m[0m | time: 2.673s
[2K
| Adam | epoch: 011 | loss: 0.24170 - acc: 0.9203 -- iter: 128/595
[A[ATraining Step: 195  | total loss: [1m[32m0.24596[0m[0m | time: 3.358s
[2K
| Adam | epoch: 011 | loss: 0.24596 - acc: 0.9189 -- iter: 160/595
[A[ATraining Step: 196  | total loss: [1m[32m0.23269[0m[0m | time: 4.044s
[2K
| Adam | epoch: 011 | loss: 0.23269 - acc: 0.9239 -- iter: 192/595
[A[ATraining Step: 197  | total loss: [1m[32m0.22306[0m[0m | time: 5.334s
[2K
| Adam | epoch: 011 | loss: 0.22306 - acc: 0.9284 -- iter: 224/595
[A[ATraining Step: 198  | total loss: [1m[32m0.28158[0m[0m | time: 6.772s
[2K
| Adam | epoch: 011 | loss: 0.28158 - acc: 0.9199 -- iter: 256/595
[A[ATraining Step: 199  | total loss: [1m[32m0.28510[0m[0m | time: 7.376s
[2K
| Adam | epoch: 011 | loss: 0.28510 - acc: 0.9154 -- iter: 288/595
[A[ATraining Step: 200  | total loss: [1m[32m0.27244[0m[0m | time: 23.256s
[2K
| Adam | epoch: 011 | loss: 0.27244 - acc: 0.9186 | val_loss: 0.58716 - val_acc: 0.7688 -- iter: 320/595
--
Training Step: 201  | total loss: [1m[32m0.26052[0m[0m | time: 24.488s
[2K
| Adam | epoch: 011 | loss: 0.26052 - acc: 0.9215 -- iter: 352/595
[A[ATraining Step: 202  | total loss: [1m[32m0.29425[0m[0m | time: 25.491s
[2K
| Adam | epoch: 011 | loss: 0.29425 - acc: 0.9012 -- iter: 384/595
[A[ATraining Step: 203  | total loss: [1m[32m0.30826[0m[0m | time: 26.535s
[2K
| Adam | epoch: 011 | loss: 0.30826 - acc: 0.8924 -- iter: 416/595
[A[ATraining Step: 204  | total loss: [1m[32m0.31145[0m[0m | time: 27.515s
[2K
| Adam | epoch: 011 | loss: 0.31145 - acc: 0.8875 -- iter: 448/595
[A[ATraining Step: 205  | total loss: [1m[32m0.29634[0m[0m | time: 28.451s
[2K
| Adam | epoch: 011 | loss: 0.29634 - acc: 0.8894 -- iter: 480/595
[A[ATraining Step: 206  | total loss: [1m[32m0.29981[0m[0m | time: 29.374s
[2K
| Adam | epoch: 011 | loss: 0.29981 - acc: 0.8879 -- iter: 512/595
[A[ATraining Step: 207  | total loss: [1m[32m0.31343[0m[0m | time: 30.440s
[2K
| Adam | epoch: 011 | loss: 0.31343 - acc: 0.8773 -- iter: 544/595
[A[ATraining Step: 208  | total loss: [1m[32m0.31248[0m[0m | time: 31.375s
[2K
| Adam | epoch: 011 | loss: 0.31248 - acc: 0.8739 -- iter: 576/595
[A[ATraining Step: 209  | total loss: [1m[32m0.30855[0m[0m | time: 33.556s
[2K
| Adam | epoch: 011 | loss: 0.30855 - acc: 0.8803 | val_loss: 0.33422 - val_acc: 0.8763 -- iter: 595/595
--
Training Step: 210  | total loss: [1m[32m0.29905[0m[0m | time: 1.070s
[2K
| Adam | epoch: 012 | loss: 0.29905 - acc: 0.8860 -- iter: 032/595
[A[ATraining Step: 211  | total loss: [1m[32m0.29198[0m[0m | time: 4.059s
[2K
| Adam | epoch: 012 | loss: 0.29198 - acc: 0.8880 -- iter: 064/595
[A[ATraining Step: 212  | total loss: [1m[32m0.28201[0m[0m | time: 5.140s
[2K
| Adam | epoch: 012 | loss: 0.28201 - acc: 0.8930 -- iter: 096/595
[A[ATraining Step: 213  | total loss: [1m[32m0.30492[0m[0m | time: 6.302s
[2K
| Adam | epoch: 012 | loss: 0.30492 - acc: 0.8880 -- iter: 128/595
[A[ATraining Step: 214  | total loss: [1m[32m0.29022[0m[0m | time: 7.413s
[2K
| Adam | epoch: 012 | loss: 0.29022 - acc: 0.8961 -- iter: 160/595
[A[ATraining Step: 215  | total loss: [1m[32m0.27331[0m[0m | time: 8.509s
[2K
| Adam | epoch: 012 | loss: 0.27331 - acc: 0.9034 -- iter: 192/595
[A[ATraining Step: 216  | total loss: [1m[32m0.26674[0m[0m | time: 9.509s
[2K
| Adam | epoch: 012 | loss: 0.26674 - acc: 0.9037 -- iter: 224/595
[A[ATraining Step: 217  | total loss: [1m[32m0.26427[0m[0m | time: 10.579s
[2K
| Adam | epoch: 012 | loss: 0.26427 - acc: 0.9008 -- iter: 256/595
[A[ATraining Step: 218  | total loss: [1m[32m0.25574[0m[0m | time: 11.802s
[2K
| Adam | epoch: 012 | loss: 0.25574 - acc: 0.9045 -- iter: 288/595
[A[ATraining Step: 219  | total loss: [1m[32m0.26127[0m[0m | time: 12.634s
[2K
| Adam | epoch: 012 | loss: 0.26127 - acc: 0.9078 -- iter: 320/595
[A[ATraining Step: 220  | total loss: [1m[32m0.24797[0m[0m | time: 13.731s
[2K
| Adam | epoch: 012 | loss: 0.24797 - acc: 0.9117 -- iter: 352/595
[A[ATraining Step: 221  | total loss: [1m[32m0.23477[0m[0m | time: 21.542s
[2K
| Adam | epoch: 012 | loss: 0.23477 - acc: 0.9206 -- iter: 384/595
[A[ATraining Step: 222  | total loss: [1m[32m0.21908[0m[0m | time: 24.827s
[2K
| Adam | epoch: 012 | loss: 0.21908 - acc: 0.9285 -- iter: 416/595
[A[ATraining Step: 223  | total loss: [1m[32m0.20670[0m[0m | time: 25.726s
[2K
| Adam | epoch: 012 | loss: 0.20670 - acc: 0.9325 -- iter: 448/595
[A[ATraining Step: 224  | total loss: [1m[32m0.19859[0m[0m | time: 26.806s
[2K
| Adam | epoch: 012 | loss: 0.19859 - acc: 0.9330 -- iter: 480/595
[A[ATraining Step: 225  | total loss: [1m[32m0.18854[0m[0m | time: 27.795s
[2K
| Adam | epoch: 012 | loss: 0.18854 - acc: 0.9366 -- iter: 512/595
[A[ATraining Step: 226  | total loss: [1m[32m0.18273[0m[0m | time: 28.875s
[2K
| Adam | epoch: 012 | loss: 0.18273 - acc: 0.9398 -- iter: 544/595
[A[ATraining Step: 227  | total loss: [1m[32m0.18975[0m[0m | time: 29.956s
[2K
| Adam | epoch: 012 | loss: 0.18975 - acc: 0.9365 -- iter: 576/595
[A[ATraining Step: 228  | total loss: [1m[32m0.26636[0m[0m | time: 31.977s
[2K
| Adam | epoch: 012 | loss: 0.26636 - acc: 0.9241 | val_loss: 0.23638 - val_acc: 0.8978 -- iter: 595/595
--
Training Step: 229  | total loss: [1m[32m0.26261[0m[0m | time: 9.162s
[2K
| Adam | epoch: 013 | loss: 0.26261 - acc: 0.9223 -- iter: 032/595
[A[ATraining Step: 230  | total loss: [1m[32m0.27885[0m[0m | time: 10.245s
[2K
| Adam | epoch: 013 | loss: 0.27885 - acc: 0.9207 -- iter: 064/595
[A[ATraining Step: 231  | total loss: [1m[32m0.26955[0m[0m | time: 11.324s
[2K
| Adam | epoch: 013 | loss: 0.26955 - acc: 0.9224 -- iter: 096/595
[A[ATraining Step: 232  | total loss: [1m[32m0.25958[0m[0m | time: 12.342s
[2K
| Adam | epoch: 013 | loss: 0.25958 - acc: 0.9270 -- iter: 128/595
[A[ATraining Step: 233  | total loss: [1m[32m0.24044[0m[0m | time: 13.491s
[2K
| Adam | epoch: 013 | loss: 0.24044 - acc: 0.9343 -- iter: 160/595
[A[ATraining Step: 234  | total loss: [1m[32m0.22188[0m[0m | time: 14.562s
[2K
| Adam | epoch: 013 | loss: 0.22188 - acc: 0.9409 -- iter: 192/595
[A[ATraining Step: 235  | total loss: [1m[32m0.21409[0m[0m | time: 15.552s
[2K
| Adam | epoch: 013 | loss: 0.21409 - acc: 0.9437 -- iter: 224/595
[A[ATraining Step: 236  | total loss: [1m[32m0.20533[0m[0m | time: 16.829s
[2K
| Adam | epoch: 013 | loss: 0.20533 - acc: 0.9462 -- iter: 256/595
[A[ATraining Step: 237  | total loss: [1m[32m0.19180[0m[0m | time: 18.167s
[2K
| Adam | epoch: 013 | loss: 0.19180 - acc: 0.9484 -- iter: 288/595
[A[ATraining Step: 238  | total loss: [1m[32m0.18855[0m[0m | time: 19.066s
[2K
| Adam | epoch: 013 | loss: 0.18855 - acc: 0.9505 -- iter: 320/595
[A[ATraining Step: 239  | total loss: [1m[32m0.19704[0m[0m | time: 22.280s
[2K
| Adam | epoch: 013 | loss: 0.19704 - acc: 0.9460 -- iter: 352/595
[A[ATraining Step: 240  | total loss: [1m[32m0.18561[0m[0m | time: 23.874s
[2K
| Adam | epoch: 013 | loss: 0.18561 - acc: 0.9514 -- iter: 384/595
[A[ATraining Step: 241  | total loss: [1m[32m0.17413[0m[0m | time: 27.401s
[2K
| Adam | epoch: 013 | loss: 0.17413 - acc: 0.9563 -- iter: 416/595
[A[ATraining Step: 242  | total loss: [1m[32m0.17659[0m[0m | time: 28.456s
[2K
| Adam | epoch: 013 | loss: 0.17659 - acc: 0.9482 -- iter: 448/595
[A[ATraining Step: 243  | total loss: [1m[32m0.19535[0m[0m | time: 29.549s
[2K
| Adam | epoch: 013 | loss: 0.19535 - acc: 0.9346 -- iter: 480/595
[A[ATraining Step: 244  | total loss: [1m[32m0.18341[0m[0m | time: 30.555s
[2K
| Adam | epoch: 013 | loss: 0.18341 - acc: 0.9411 -- iter: 512/595
[A[ATraining Step: 245  | total loss: [1m[32m0.18248[0m[0m | time: 31.693s
[2K
| Adam | epoch: 013 | loss: 0.18248 - acc: 0.9408 -- iter: 544/595
[A[ATraining Step: 246  | total loss: [1m[32m0.18131[0m[0m | time: 32.717s
[2K
| Adam | epoch: 013 | loss: 0.18131 - acc: 0.9373 -- iter: 576/595
[A[ATraining Step: 247  | total loss: [1m[32m0.20107[0m[0m | time: 34.955s
[2K
| Adam | epoch: 013 | loss: 0.20107 - acc: 0.9311 | val_loss: 0.24562 - val_acc: 0.9247 -- iter: 595/595
--
Training Step: 248  | total loss: [1m[32m0.22203[0m[0m | time: 1.282s
[2K
| Adam | epoch: 014 | loss: 0.22203 - acc: 0.9255 -- iter: 032/595
[A[ATraining Step: 249  | total loss: [1m[32m0.20416[0m[0m | time: 2.647s
[2K
| Adam | epoch: 014 | loss: 0.20416 - acc: 0.9329 -- iter: 064/595
[A[ATraining Step: 250  | total loss: [1m[32m0.19585[0m[0m | time: 3.831s
[2K
| Adam | epoch: 014 | loss: 0.19585 - acc: 0.9365 -- iter: 096/595
[A[ATraining Step: 251  | total loss: [1m[32m0.19177[0m[0m | time: 6.149s
[2K
| Adam | epoch: 014 | loss: 0.19177 - acc: 0.9366 -- iter: 128/595
[A[ATraining Step: 252  | total loss: [1m[32m0.19025[0m[0m | time: 7.438s
[2K
| Adam | epoch: 014 | loss: 0.19025 - acc: 0.9336 -- iter: 160/595
[A[ATraining Step: 253  | total loss: [1m[32m0.18571[0m[0m | time: 8.463s
[2K
| Adam | epoch: 014 | loss: 0.18571 - acc: 0.9340 -- iter: 192/595
[A[ATraining Step: 254  | total loss: [1m[32m0.17470[0m[0m | time: 9.475s
[2K
| Adam | epoch: 014 | loss: 0.17470 - acc: 0.9406 -- iter: 224/595
[A[ATraining Step: 255  | total loss: [1m[32m0.16368[0m[0m | time: 10.495s
[2K
| Adam | epoch: 014 | loss: 0.16368 - acc: 0.9434 -- iter: 256/595
[A[ATraining Step: 256  | total loss: [1m[32m0.18151[0m[0m | time: 11.646s
[2K
| Adam | epoch: 014 | loss: 0.18151 - acc: 0.9334 -- iter: 288/595
[A[ATraining Step: 257  | total loss: [1m[32m0.18409[0m[0m | time: 12.666s
[2K
| Adam | epoch: 014 | loss: 0.18409 - acc: 0.9307 -- iter: 320/595
[A[ATraining Step: 258  | total loss: [1m[32m0.18244[0m[0m | time: 13.657s
[2K
| Adam | epoch: 014 | loss: 0.18244 - acc: 0.9314 -- iter: 352/595
[A[ATraining Step: 259  | total loss: [1m[32m0.19698[0m[0m | time: 14.367s
[2K
| Adam | epoch: 014 | loss: 0.19698 - acc: 0.9289 -- iter: 384/595
[A[ATraining Step: 260  | total loss: [1m[32m0.19696[0m[0m | time: 15.154s
[2K
| Adam | epoch: 014 | loss: 0.19696 - acc: 0.9255 -- iter: 416/595
[A[ATraining Step: 261  | total loss: [1m[32m0.19225[0m[0m | time: 16.488s
[2K
| Adam | epoch: 014 | loss: 0.19225 - acc: 0.9224 -- iter: 448/595
[A[ATraining Step: 262  | total loss: [1m[32m0.18435[0m[0m | time: 20.211s
[2K
| Adam | epoch: 014 | loss: 0.18435 - acc: 0.9270 -- iter: 480/595
[A[ATraining Step: 263  | total loss: [1m[32m0.17013[0m[0m | time: 22.672s
[2K
| Adam | epoch: 014 | loss: 0.17013 - acc: 0.9343 -- iter: 512/595
[A[ATraining Step: 264  | total loss: [1m[32m0.17522[0m[0m | time: 23.640s
[2K
| Adam | epoch: 014 | loss: 0.17522 - acc: 0.9284 -- iter: 544/595
[A[ATraining Step: 265  | total loss: [1m[32m0.17245[0m[0m | time: 24.675s
[2K
| Adam | epoch: 014 | loss: 0.17245 - acc: 0.9262 -- iter: 576/595
[A[ATraining Step: 266  | total loss: [1m[32m0.15997[0m[0m | time: 26.995s
[2K
| Adam | epoch: 014 | loss: 0.15997 - acc: 0.9336 | val_loss: 0.21509 - val_acc: 0.9355 -- iter: 595/595
--
Training Step: 267  | total loss: [1m[32m0.17751[0m[0m | time: 1.792s
[2K
| Adam | epoch: 015 | loss: 0.17751 - acc: 0.9371 -- iter: 032/595
[A[ATraining Step: 268  | total loss: [1m[32m0.18982[0m[0m | time: 2.743s
[2K
| Adam | epoch: 015 | loss: 0.18982 - acc: 0.9402 -- iter: 064/595
[A[ATraining Step: 269  | total loss: [1m[32m0.17851[0m[0m | time: 3.813s
[2K
| Adam | epoch: 015 | loss: 0.17851 - acc: 0.9462 -- iter: 096/595
[A[ATraining Step: 270  | total loss: [1m[32m0.17476[0m[0m | time: 4.842s
[2K
| Adam | epoch: 015 | loss: 0.17476 - acc: 0.9485 -- iter: 128/595
[A[ATraining Step: 271  | total loss: [1m[32m0.17047[0m[0m | time: 6.035s
[2K
| Adam | epoch: 015 | loss: 0.17047 - acc: 0.9505 -- iter: 160/595
[A[ATraining Step: 272  | total loss: [1m[32m0.16732[0m[0m | time: 7.103s
[2K
| Adam | epoch: 015 | loss: 0.16732 - acc: 0.9523 -- iter: 192/595
[A[ATraining Step: 273  | total loss: [1m[32m0.16209[0m[0m | time: 8.078s
[2K
| Adam | epoch: 015 | loss: 0.16209 - acc: 0.9540 -- iter: 224/595
[A[ATraining Step: 274  | total loss: [1m[32m0.14863[0m[0m | time: 9.229s
[2K
| Adam | epoch: 015 | loss: 0.14863 - acc: 0.9586 -- iter: 256/595
[A[ATraining Step: 275  | total loss: [1m[32m0.17257[0m[0m | time: 10.588s
[2K
| Adam | epoch: 015 | loss: 0.17257 - acc: 0.9502 -- iter: 288/595
[A[ATraining Step: 276  | total loss: [1m[32m0.15703[0m[0m | time: 11.492s
[2K
| Adam | epoch: 015 | loss: 0.15703 - acc: 0.9552 -- iter: 320/595
[A[ATraining Step: 277  | total loss: [1m[32m0.15874[0m[0m | time: 16.117s
[2K
| Adam | epoch: 015 | loss: 0.15874 - acc: 0.9534 -- iter: 352/595
[A[ATraining Step: 278  | total loss: [1m[32m0.15484[0m[0m | time: 17.049s
[2K
| Adam | epoch: 015 | loss: 0.15484 - acc: 0.9550 -- iter: 384/595
[A[ATraining Step: 279  | total loss: [1m[32m0.14377[0m[0m | time: 17.721s
[2K
| Adam | epoch: 015 | loss: 0.14377 - acc: 0.9595 -- iter: 416/595
[A[ATraining Step: 280  | total loss: [1m[32m0.13333[0m[0m | time: 18.369s
[2K
| Adam | epoch: 015 | loss: 0.13333 - acc: 0.9635 -- iter: 448/595
[A[ATraining Step: 281  | total loss: [1m[32m0.12336[0m[0m | time: 19.452s
[2K
| Adam | epoch: 015 | loss: 0.12336 - acc: 0.9672 -- iter: 480/595
[A[ATraining Step: 282  | total loss: [1m[32m0.12189[0m[0m | time: 20.606s
[2K
| Adam | epoch: 015 | loss: 0.12189 - acc: 0.9673 -- iter: 512/595
[A[ATraining Step: 283  | total loss: [1m[32m0.12072[0m[0m | time: 21.629s
[2K
| Adam | epoch: 015 | loss: 0.12072 - acc: 0.9643 -- iter: 544/595
[A[ATraining Step: 284  | total loss: [1m[32m0.11550[0m[0m | time: 22.789s
[2K
| Adam | epoch: 015 | loss: 0.11550 - acc: 0.9679 -- iter: 576/595
[A[ATraining Step: 285  | total loss: [1m[32m0.13198[0m[0m | time: 25.221s
[2K
| Adam | epoch: 015 | loss: 0.13198 - acc: 0.9617 | val_loss: 0.29919 - val_acc: 0.8710 -- iter: 595/595
--
Validation AUC:0.9681122448979592
Validation AUPRC:0.9735719680571419
Test AUC:0.975
Test AUPRC:0.9182775312887972
BestTestF1Score	0.92	0.86	0.93	0.9	0.93	71	8	102	5	0.87
BestTestMCCScore	0.93	0.88	0.94	0.92	0.93	71	6	104	5	0.91
BestTestAccuracyScore	0.93	0.88	0.94	0.92	0.93	71	6	104	5	0.91
BestValidationF1Score	0.92	0.86	0.93	0.94	0.91	80	5	93	8	0.87
BestValidationMCC	0.92	0.86	0.93	0.95	0.9	79	4	94	9	0.91
BestValidationAccuracy	0.92	0.86	0.93	0.95	0.9	79	4	94	9	0.91
TestPredictions (Threshold:0.91)
CHEMBL193946,TP,ACT,0.9900000095367432	CHEMBL556578,TP,ACT,1.0	CHEMBL121403,TP,ACT,0.9900000095367432	CHEMBL1916635,TN,INACT,0.4699999988079071	CHEMBL2442639,TN,INACT,0.019999999552965164	CHEMBL567175,TP,ACT,1.0	CHEMBL165012,TN,INACT,0.4399999976158142	CHEMBL2163539,TP,ACT,1.0	CHEMBL123099,TN,INACT,0.5	CHEMBL80505,TN,INACT,0.6499999761581421	CHEMBL148240,TP,ACT,0.9900000095367432	CHEMBL142295,TN,INACT,0.10000000149011612	CHEMBL3092395,TP,ACT,1.0	CHEMBL424987,TP,ACT,1.0	CHEMBL44262,TN,INACT,0.009999999776482582	CHEMBL74515,TN,INACT,0.009999999776482582	CHEMBL461089,TN,INACT,0.029999999329447746	CHEMBL111023,TN,INACT,0.009999999776482582	CHEMBL78601,TN,INACT,0.029999999329447746	CHEMBL100729,TP,ACT,0.9800000190734863	CHEMBL357628,TN,INACT,0.18000000715255737	CHEMBL365068,TP,ACT,1.0	CHEMBL134186,TP,ACT,0.9900000095367432	CHEMBL515170,TN,INACT,0.07000000029802322	CHEMBL603858,TN,INACT,0.019999999552965164	CHEMBL305146,TP,ACT,0.9900000095367432	CHEMBL64461,TN,INACT,0.019999999552965164	CHEMBL2016677,TP,ACT,1.0	CHEMBL368629,TN,INACT,0.17000000178813934	CHEMBL2334774,TP,ACT,0.9900000095367432	CHEMBL295651,TN,INACT,0.8999999761581421	CHEMBL3326350,TP,ACT,0.9700000286102295	CHEMBL319036,TN,INACT,0.09000000357627869	CHEMBL2057693,TP,ACT,1.0	CHEMBL2442640,TN,INACT,0.05000000074505806	CHEMBL2016678,TP,ACT,1.0	CHEMBL453,TN,INACT,0.019999999552965164	CHEMBL186742,TP,ACT,1.0	CHEMBL1834902,TP,ACT,1.0	CHEMBL104159,TP,ACT,0.9900000095367432	CHEMBL108076,TP,ACT,0.9599999785423279	CHEMBL1929368,TP,ACT,0.9900000095367432	CHEMBL78929,TN,INACT,0.07999999821186066	CHEMBL174463,TN,INACT,0.8100000023841858	CHEMBL297599,TN,INACT,0.009999999776482582	CHEMBL329861,TN,INACT,0.05000000074505806	CHEMBL2335158,TN,INACT,0.019999999552965164	CHEMBL302038,TN,INACT,0.7699999809265137	CHEMBL233552,TN,INACT,0.019999999552965164	CHEMBL414570,FP,INACT,1.0	CHEMBL462650,TN,INACT,0.019999999552965164	CHEMBL414165,TN,INACT,0.019999999552965164	CHEMBL3217022,TP,ACT,1.0	CHEMBL2205414,TP,ACT,1.0	CHEMBL328285,TN,INACT,0.3700000047683716	CHEMBL2204036,TP,ACT,1.0	CHEMBL147340,TN,INACT,0.009999999776482582	CHEMBL3633656,TN,INACT,0.05999999865889549	CHEMBL254500,TN,INACT,0.07000000029802322	CHEMBL293232,TN,INACT,0.009999999776482582	CHEMBL3238446,TN,INACT,0.41999998688697815	CHEMBL1270282,TP,ACT,1.0	CHEMBL416069,TN,INACT,0.009999999776482582	CHEMBL602269,TN,INACT,0.10000000149011612	CHEMBL553155,TN,INACT,0.07000000029802322	CHEMBL111218,TN,INACT,0.009999999776482582	CHEMBL3218123,TN,INACT,0.009999999776482582	CHEMBL3339377,TP,ACT,1.0	CHEMBL324685,TN,INACT,0.009999999776482582	CHEMBL1076,TN,INACT,0.14000000059604645	CHEMBL3810142,TN,INACT,0.8399999737739563	CHEMBL80532,TN,INACT,0.029999999329447746	CHEMBL2147916,TP,ACT,1.0	CHEMBL432974,TN,INACT,0.029999999329447746	CHEMBL2419122,TP,ACT,1.0	CHEMBL2387736,TP,ACT,1.0	CHEMBL310427,TN,INACT,0.8799999952316284	CHEMBL118553,TN,INACT,0.25	CHEMBL1270185,FN,ACT,0.6899999976158142	CHEMBL434542,TP,ACT,1.0	CHEMBL2437067,TP,ACT,0.9900000095367432	CHEMBL334933,TN,INACT,0.27000001072883606	CHEMBL3215686,TP,ACT,1.0	CHEMBL552619,TP,ACT,0.9800000190734863	CHEMBL359141,TN,INACT,0.009999999776482582	CHEMBL2204035,TP,ACT,1.0	CHEMBL401093,TP,ACT,1.0	CHEMBL610549,FN,ACT,0.7400000095367432	CHEMBL48031,TN,INACT,0.009999999776482582	CHEMBL340537,TP,ACT,0.9700000286102295	CHEMBL191915,TN,INACT,0.05000000074505806	CHEMBL3264746,TP,ACT,1.0	CHEMBL291821,TN,INACT,0.029999999329447746	CHEMBL1765667,TN,INACT,0.009999999776482582	CHEMBL2112451,TN,INACT,0.009999999776482582	CHEMBL61792,TN,INACT,0.019999999552965164	CHEMBL2204033,TP,ACT,1.0	CHEMBL3216603,TP,ACT,1.0	CHEMBL322547,TN,INACT,0.009999999776482582	CHEMBL2437062,FN,ACT,0.8500000238418579	CHEMBL293874,TN,INACT,0.029999999329447746	CHEMBL2057689,TP,ACT,0.9599999785423279	CHEMBL175698,TN,INACT,0.019999999552965164	CHEMBL3339379,TP,ACT,1.0	CHEMBL429238,FP,INACT,1.0	CHEMBL302150,TN,INACT,0.009999999776482582	CHEMBL2016675,TP,ACT,1.0	CHEMBL2147921,TP,ACT,1.0	CHEMBL363480,TP,ACT,1.0	CHEMBL173059,FP,INACT,0.9700000286102295	CHEMBL963,TP,ACT,1.0	CHEMBL92318,TN,INACT,0.009999999776482582	CHEMBL2205419,TP,ACT,1.0	CHEMBL1078642,TN,INACT,0.019999999552965164	CHEMBL1834900,TP,ACT,1.0	CHEMBL2368123,TP,ACT,0.9900000095367432	CHEMBL323951,TN,INACT,0.009999999776482582	CHEMBL399708,TP,ACT,1.0	CHEMBL2369493,FP,INACT,0.9399999976158142	CHEMBL76860,TN,INACT,0.019999999552965164	CHEMBL2398752,TN,INACT,0.05999999865889549	CHEMBL2113072,TN,INACT,0.6299999952316284	CHEMBL522201,TP,ACT,1.0	CHEMBL2419124,TP,ACT,1.0	CHEMBL357077,TN,INACT,0.019999999552965164	CHEMBL2057692,TP,ACT,0.9800000190734863	CHEMBL344154,TN,INACT,0.029999999329447746	CHEMBL73272,TN,INACT,0.029999999329447746	CHEMBL320763,TN,INACT,0.009999999776482582	CHEMBL421523,TN,INACT,0.05999999865889549	CHEMBL59,TN,INACT,0.75	CHEMBL2370509,TN,INACT,0.009999999776482582	CHEMBL2147907,TP,ACT,1.0	CHEMBL76360,TN,INACT,0.019999999552965164	CHEMBL2017149,TP,ACT,0.9800000190734863	CHEMBL3339380,TP,ACT,1.0	CHEMBL440765,FN,ACT,0.49000000953674316	CHEMBL2147909,TP,ACT,1.0	CHEMBL3780248,TN,INACT,0.03999999910593033	CHEMBL252231,TN,INACT,0.09000000357627869	CHEMBL2111789,TN,INACT,0.009999999776482582	CHEMBL415879,TN,INACT,0.029999999329447746	CHEMBL3633650,TN,INACT,0.5699999928474426	CHEMBL459043,TP,ACT,1.0	CHEMBL328422,TN,INACT,0.009999999776482582	CHEMBL39879,TN,INACT,0.019999999552965164	CHEMBL2042400,TN,INACT,0.019999999552965164	CHEMBL2147915,TP,ACT,1.0	CHEMBL2017145,TP,ACT,0.9900000095367432	CHEMBL3216841,TP,ACT,1.0	CHEMBL141048,TN,INACT,0.3799999952316284	CHEMBL2322893,TN,INACT,0.03999999910593033	CHEMBL44615,TN,INACT,0.029999999329447746	CHEMBL351183,TN,INACT,0.7200000286102295	CHEMBL336033,TN,INACT,0.019999999552965164	CHEMBL2370690,TP,ACT,0.9900000095367432	CHEMBL241082,TN,INACT,0.6200000047683716	CHEMBL312750,TN,INACT,0.7799999713897705	CHEMBL187376,TP,ACT,1.0	CHEMBL174448,TN,INACT,0.07000000029802322	CHEMBL267094,FP,INACT,0.9399999976158142	CHEMBL283535,TN,INACT,0.019999999552965164	CHEMBL43661,TN,INACT,0.12999999523162842	CHEMBL1270383,TP,ACT,1.0	CHEMBL434674,TN,INACT,0.25	CHEMBL3604279,TP,ACT,0.9900000095367432	CHEMBL15689,FP,INACT,0.9200000166893005	CHEMBL2151327,FN,ACT,0.7300000190734863	CHEMBL545363,TN,INACT,0.009999999776482582	CHEMBL2311157,TP,ACT,0.9599999785423279	CHEMBL345951,TN,INACT,0.009999999776482582	CHEMBL184744,TP,ACT,1.0	CHEMBL2436047,TP,ACT,1.0	CHEMBL147238,TN,INACT,0.009999999776482582	CHEMBL186741,TP,ACT,1.0	CHEMBL2016679,TP,ACT,0.9900000095367432	CHEMBL527880,TN,INACT,0.8399999737739563	CHEMBL2324200,TN,INACT,0.5400000214576721	CHEMBL169675,TN,INACT,0.3700000047683716	CHEMBL343969,TN,INACT,0.029999999329447746	CHEMBL303386,TN,INACT,0.03999999910593033	CHEMBL3238444,TN,INACT,0.6399999856948853	CHEMBL140495,TN,INACT,0.15000000596046448	CHEMBL11131,TN,INACT,0.7400000095367432	CHEMBL542881,TP,ACT,0.9900000095367432	CHEMBL164968,TN,INACT,0.009999999776482582	

