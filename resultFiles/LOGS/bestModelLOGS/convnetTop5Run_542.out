CNNModel CHEMBL2736 adam 0.001 30 32 0 0.8 False True
Number of active compounds :	243
Number of inactive compounds :	243
---------------------------------
Run id: CNNModel_CHEMBL2736_adam_0.001_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2736_adam_0.001_30_32_0.8_True/
---------------------------------
Training samples: 275
Validation samples: 87
--
Training Step: 1  | time: 0.839s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/275
[A[ATraining Step: 2  | total loss: [1m[32m0.62449[0m[0m | time: 1.460s
[2K
| Adam | epoch: 001 | loss: 0.62449 - acc: 0.3375 -- iter: 064/275
[A[ATraining Step: 3  | total loss: [1m[32m0.68552[0m[0m | time: 2.063s
[2K
| Adam | epoch: 001 | loss: 0.68552 - acc: 0.2915 -- iter: 096/275
[A[ATraining Step: 4  | total loss: [1m[32m0.69145[0m[0m | time: 2.694s
[2K
| Adam | epoch: 001 | loss: 0.69145 - acc: 0.4010 -- iter: 128/275
[A[ATraining Step: 5  | total loss: [1m[32m0.69230[0m[0m | time: 3.301s
[2K
| Adam | epoch: 001 | loss: 0.69230 - acc: 0.5128 -- iter: 160/275
[A[ATraining Step: 6  | total loss: [1m[32m0.69359[0m[0m | time: 3.901s
[2K
| Adam | epoch: 001 | loss: 0.69359 - acc: 0.4644 -- iter: 192/275
[A[ATraining Step: 7  | total loss: [1m[32m0.69268[0m[0m | time: 4.510s
[2K
| Adam | epoch: 001 | loss: 0.69268 - acc: 0.5233 -- iter: 224/275
[A[ATraining Step: 8  | total loss: [1m[32m0.69344[0m[0m | time: 5.118s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.4926 -- iter: 256/275
[A[ATraining Step: 9  | total loss: [1m[32m0.69413[0m[0m | time: 6.527s
[2K
| Adam | epoch: 001 | loss: 0.69413 - acc: 0.4634 | val_loss: 0.69319 - val_acc: 0.4943 -- iter: 275/275
--
Training Step: 10  | total loss: [1m[32m0.69439[0m[0m | time: 0.394s
[2K
| Adam | epoch: 002 | loss: 0.69439 - acc: 0.4422 -- iter: 032/275
[A[ATraining Step: 11  | total loss: [1m[32m0.69431[0m[0m | time: 1.011s
[2K
| Adam | epoch: 002 | loss: 0.69431 - acc: 0.4322 -- iter: 064/275
[A[ATraining Step: 12  | total loss: [1m[32m0.69368[0m[0m | time: 1.636s
[2K
| Adam | epoch: 002 | loss: 0.69368 - acc: 0.4768 -- iter: 096/275
[A[ATraining Step: 13  | total loss: [1m[32m0.69337[0m[0m | time: 2.252s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.5671 -- iter: 128/275
[A[ATraining Step: 14  | total loss: [1m[32m0.69358[0m[0m | time: 2.865s
[2K
| Adam | epoch: 002 | loss: 0.69358 - acc: 0.4885 -- iter: 160/275
[A[ATraining Step: 15  | total loss: [1m[32m0.69344[0m[0m | time: 3.495s
[2K
| Adam | epoch: 002 | loss: 0.69344 - acc: 0.4808 -- iter: 192/275
[A[ATraining Step: 16  | total loss: [1m[32m0.69352[0m[0m | time: 4.128s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.4294 -- iter: 224/275
[A[ATraining Step: 17  | total loss: [1m[32m0.69337[0m[0m | time: 4.729s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4773 -- iter: 256/275
[A[ATraining Step: 18  | total loss: [1m[32m0.69333[0m[0m | time: 6.344s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4852 | val_loss: 0.69314 - val_acc: 0.5057 -- iter: 275/275
--
Training Step: 19  | total loss: [1m[32m0.69328[0m[0m | time: 0.414s
[2K
| Adam | epoch: 003 | loss: 0.69328 - acc: 0.4901 -- iter: 032/275
[A[ATraining Step: 20  | total loss: [1m[32m0.69325[0m[0m | time: 0.798s
[2K
| Adam | epoch: 003 | loss: 0.69325 - acc: 0.4679 -- iter: 064/275
[A[ATraining Step: 21  | total loss: [1m[32m0.69319[0m[0m | time: 1.402s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5024 -- iter: 096/275
[A[ATraining Step: 22  | total loss: [1m[32m0.69300[0m[0m | time: 2.020s
[2K
| Adam | epoch: 003 | loss: 0.69300 - acc: 0.5298 -- iter: 128/275
[A[ATraining Step: 23  | total loss: [1m[32m0.69261[0m[0m | time: 2.644s
[2K
| Adam | epoch: 003 | loss: 0.69261 - acc: 0.5574 -- iter: 160/275
[A[ATraining Step: 24  | total loss: [1m[32m0.69217[0m[0m | time: 3.249s
[2K
| Adam | epoch: 003 | loss: 0.69217 - acc: 0.5676 -- iter: 192/275
[A[ATraining Step: 25  | total loss: [1m[32m0.69331[0m[0m | time: 3.850s
[2K
| Adam | epoch: 003 | loss: 0.69331 - acc: 0.5236 -- iter: 224/275
[A[ATraining Step: 26  | total loss: [1m[32m0.69493[0m[0m | time: 4.446s
[2K
| Adam | epoch: 003 | loss: 0.69493 - acc: 0.4760 -- iter: 256/275
[A[ATraining Step: 27  | total loss: [1m[32m0.69340[0m[0m | time: 6.059s
[2K
| Adam | epoch: 003 | loss: 0.69340 - acc: 0.5143 | val_loss: 0.69303 - val_acc: 0.5057 -- iter: 275/275
--
Training Step: 28  | total loss: [1m[32m0.69442[0m[0m | time: 0.616s
[2K
| Adam | epoch: 004 | loss: 0.69442 - acc: 0.4795 -- iter: 032/275
[A[ATraining Step: 29  | total loss: [1m[32m0.69390[0m[0m | time: 1.016s
[2K
| Adam | epoch: 004 | loss: 0.69390 - acc: 0.4921 -- iter: 064/275
[A[ATraining Step: 30  | total loss: [1m[32m0.69351[0m[0m | time: 1.415s
[2K
| Adam | epoch: 004 | loss: 0.69351 - acc: 0.5002 -- iter: 096/275
[A[ATraining Step: 31  | total loss: [1m[32m0.69320[0m[0m | time: 2.014s
[2K
| Adam | epoch: 004 | loss: 0.69320 - acc: 0.5062 -- iter: 128/275
[A[ATraining Step: 32  | total loss: [1m[32m0.69272[0m[0m | time: 2.618s
[2K
| Adam | epoch: 004 | loss: 0.69272 - acc: 0.5189 -- iter: 160/275
[A[ATraining Step: 33  | total loss: [1m[32m0.69305[0m[0m | time: 3.227s
[2K
| Adam | epoch: 004 | loss: 0.69305 - acc: 0.5079 -- iter: 192/275
[A[ATraining Step: 34  | total loss: [1m[32m0.69223[0m[0m | time: 3.846s
[2K
| Adam | epoch: 004 | loss: 0.69223 - acc: 0.5330 -- iter: 224/275
[A[ATraining Step: 35  | total loss: [1m[32m0.69263[0m[0m | time: 4.476s
[2K
| Adam | epoch: 004 | loss: 0.69263 - acc: 0.5195 -- iter: 256/275
[A[ATraining Step: 36  | total loss: [1m[32m0.69322[0m[0m | time: 6.112s
[2K
| Adam | epoch: 004 | loss: 0.69322 - acc: 0.5028 | val_loss: 0.69302 - val_acc: 0.5057 -- iter: 275/275
--
Training Step: 37  | total loss: [1m[32m0.69291[0m[0m | time: 0.699s
[2K
| Adam | epoch: 005 | loss: 0.69291 - acc: 0.5085 -- iter: 032/275
[A[ATraining Step: 38  | total loss: [1m[32m0.69364[0m[0m | time: 1.306s
[2K
| Adam | epoch: 005 | loss: 0.69364 - acc: 0.4885 -- iter: 064/275
[A[ATraining Step: 39  | total loss: [1m[32m0.69315[0m[0m | time: 1.688s
[2K
| Adam | epoch: 005 | loss: 0.69315 - acc: 0.5026 -- iter: 096/275
[A[ATraining Step: 40  | total loss: [1m[32m0.69438[0m[0m | time: 2.065s
[2K
| Adam | epoch: 005 | loss: 0.69438 - acc: 0.4676 -- iter: 128/275
[A[ATraining Step: 41  | total loss: [1m[32m0.69521[0m[0m | time: 2.683s
[2K
| Adam | epoch: 005 | loss: 0.69521 - acc: 0.4397 -- iter: 160/275
[A[ATraining Step: 42  | total loss: [1m[32m0.69414[0m[0m | time: 3.283s
[2K
| Adam | epoch: 005 | loss: 0.69414 - acc: 0.4787 -- iter: 192/275
[A[ATraining Step: 43  | total loss: [1m[32m0.69314[0m[0m | time: 3.879s
[2K
| Adam | epoch: 005 | loss: 0.69314 - acc: 0.5155 -- iter: 224/275
[A[ATraining Step: 44  | total loss: [1m[32m0.69339[0m[0m | time: 4.477s
[2K
| Adam | epoch: 005 | loss: 0.69339 - acc: 0.5020 -- iter: 256/275
[A[ATraining Step: 45  | total loss: [1m[32m0.69358[0m[0m | time: 6.090s
[2K
| Adam | epoch: 005 | loss: 0.69358 - acc: 0.4911 | val_loss: 0.69303 - val_acc: 0.5057 -- iter: 275/275
--
Training Step: 46  | total loss: [1m[32m0.69378[0m[0m | time: 0.604s
[2K
| Adam | epoch: 006 | loss: 0.69378 - acc: 0.4821 -- iter: 032/275
[A[ATraining Step: 47  | total loss: [1m[32m0.69370[0m[0m | time: 1.209s
[2K
| Adam | epoch: 006 | loss: 0.69370 - acc: 0.4851 -- iter: 064/275
[A[ATraining Step: 48  | total loss: [1m[32m0.69384[0m[0m | time: 1.817s
[2K
| Adam | epoch: 006 | loss: 0.69384 - acc: 0.4774 -- iter: 096/275
[A[ATraining Step: 49  | total loss: [1m[32m0.69341[0m[0m | time: 2.209s
[2K
| Adam | epoch: 006 | loss: 0.69341 - acc: 0.5007 -- iter: 128/275
[A[ATraining Step: 50  | total loss: [1m[32m0.69340[0m[0m | time: 2.598s
[2K
| Adam | epoch: 006 | loss: 0.69340 - acc: 0.4965 -- iter: 160/275
[A[ATraining Step: 51  | total loss: [1m[32m0.69338[0m[0m | time: 3.247s
[2K
| Adam | epoch: 006 | loss: 0.69338 - acc: 0.4930 -- iter: 192/275
[A[ATraining Step: 52  | total loss: [1m[32m0.69308[0m[0m | time: 3.842s
[2K
| Adam | epoch: 006 | loss: 0.69308 - acc: 0.5081 -- iter: 224/275
[A[ATraining Step: 53  | total loss: [1m[32m0.69310[0m[0m | time: 4.498s
[2K
| Adam | epoch: 006 | loss: 0.69310 - acc: 0.5069 -- iter: 256/275
[A[ATraining Step: 54  | total loss: [1m[32m0.69353[0m[0m | time: 6.102s
[2K
| Adam | epoch: 006 | loss: 0.69353 - acc: 0.4787 | val_loss: 0.69289 - val_acc: 0.5057 -- iter: 275/275
--
Training Step: 55  | total loss: [1m[32m0.69381[0m[0m | time: 0.609s
[2K
| Adam | epoch: 007 | loss: 0.69381 - acc: 0.4594 -- iter: 032/275
[A[ATraining Step: 56  | total loss: [1m[32m0.69337[0m[0m | time: 1.213s
[2K
| Adam | epoch: 007 | loss: 0.69337 - acc: 0.4959 -- iter: 064/275
[A[ATraining Step: 57  | total loss: [1m[32m0.69331[0m[0m | time: 1.826s
[2K
| Adam | epoch: 007 | loss: 0.69331 - acc: 0.4965 -- iter: 096/275
[A[ATraining Step: 58  | total loss: [1m[32m0.69306[0m[0m | time: 2.436s
[2K
| Adam | epoch: 007 | loss: 0.69306 - acc: 0.5183 -- iter: 128/275
[A[ATraining Step: 59  | total loss: [1m[32m0.69293[0m[0m | time: 2.820s
[2K
| Adam | epoch: 007 | loss: 0.69293 - acc: 0.5242 -- iter: 160/275
[A[ATraining Step: 60  | total loss: [1m[32m0.69294[0m[0m | time: 3.191s
[2K
| Adam | epoch: 007 | loss: 0.69294 - acc: 0.5175 -- iter: 192/275
[A[ATraining Step: 61  | total loss: [1m[32m0.69296[0m[0m | time: 3.790s
[2K
| Adam | epoch: 007 | loss: 0.69296 - acc: 0.5118 -- iter: 224/275
[A[ATraining Step: 62  | total loss: [1m[32m0.69293[0m[0m | time: 4.395s
[2K
| Adam | epoch: 007 | loss: 0.69293 - acc: 0.5103 -- iter: 256/275
[A[ATraining Step: 63  | total loss: [1m[32m0.69251[0m[0m | time: 6.004s
[2K
| Adam | epoch: 007 | loss: 0.69251 - acc: 0.5248 | val_loss: 0.69114 - val_acc: 0.5057 -- iter: 275/275
--
Training Step: 64  | total loss: [1m[32m0.69257[0m[0m | time: 0.632s
[2K
| Adam | epoch: 008 | loss: 0.69257 - acc: 0.5178 -- iter: 032/275
[A[ATraining Step: 65  | total loss: [1m[32m0.69302[0m[0m | time: 1.254s
[2K
| Adam | epoch: 008 | loss: 0.69302 - acc: 0.4964 -- iter: 064/275
[A[ATraining Step: 66  | total loss: [1m[32m0.69295[0m[0m | time: 1.883s
[2K
| Adam | epoch: 008 | loss: 0.69295 - acc: 0.4816 -- iter: 096/275
[A[ATraining Step: 67  | total loss: [1m[32m0.69270[0m[0m | time: 2.497s
[2K
| Adam | epoch: 008 | loss: 0.69270 - acc: 0.4876 -- iter: 128/275
[A[ATraining Step: 68  | total loss: [1m[32m0.69238[0m[0m | time: 3.122s
[2K
| Adam | epoch: 008 | loss: 0.69238 - acc: 0.5186 -- iter: 160/275
[A[ATraining Step: 69  | total loss: [1m[32m0.69190[0m[0m | time: 3.495s
[2K
| Adam | epoch: 008 | loss: 0.69190 - acc: 0.5457 -- iter: 192/275
[A[ATraining Step: 70  | total loss: [1m[32m0.69066[0m[0m | time: 3.891s
[2K
| Adam | epoch: 008 | loss: 0.69066 - acc: 0.5617 -- iter: 224/275
[A[ATraining Step: 71  | total loss: [1m[32m0.68816[0m[0m | time: 4.500s
[2K
| Adam | epoch: 008 | loss: 0.68816 - acc: 0.5756 -- iter: 256/275
[A[ATraining Step: 72  | total loss: [1m[32m0.69078[0m[0m | time: 6.138s
[2K
| Adam | epoch: 008 | loss: 0.69078 - acc: 0.5601 | val_loss: 0.69026 - val_acc: 0.5057 -- iter: 275/275
--
Training Step: 73  | total loss: [1m[32m0.69423[0m[0m | time: 0.629s
[2K
| Adam | epoch: 009 | loss: 0.69423 - acc: 0.5430 -- iter: 032/275
[A[ATraining Step: 74  | total loss: [1m[32m0.69689[0m[0m | time: 1.241s
[2K
| Adam | epoch: 009 | loss: 0.69689 - acc: 0.5246 -- iter: 064/275
[A[ATraining Step: 75  | total loss: [1m[32m0.69580[0m[0m | time: 1.863s
[2K
| Adam | epoch: 009 | loss: 0.69580 - acc: 0.5253 -- iter: 096/275
[A[ATraining Step: 76  | total loss: [1m[32m0.69549[0m[0m | time: 2.491s
[2K
| Adam | epoch: 009 | loss: 0.69549 - acc: 0.5159 -- iter: 128/275
[A[ATraining Step: 77  | total loss: [1m[32m0.69424[0m[0m | time: 3.092s
[2K
| Adam | epoch: 009 | loss: 0.69424 - acc: 0.5208 -- iter: 160/275
[A[ATraining Step: 78  | total loss: [1m[32m0.69348[0m[0m | time: 3.727s
[2K
| Adam | epoch: 009 | loss: 0.69348 - acc: 0.5252 -- iter: 192/275
[A[ATraining Step: 79  | total loss: [1m[32m0.69286[0m[0m | time: 4.100s
[2K
| Adam | epoch: 009 | loss: 0.69286 - acc: 0.5387 -- iter: 224/275
[A[ATraining Step: 80  | total loss: [1m[32m0.69188[0m[0m | time: 4.500s
[2K
| Adam | epoch: 009 | loss: 0.69188 - acc: 0.5536 -- iter: 256/275
[A[ATraining Step: 81  | total loss: [1m[32m0.69073[0m[0m | time: 6.102s
[2K
| Adam | epoch: 009 | loss: 0.69073 - acc: 0.5668 | val_loss: 0.68370 - val_acc: 0.5057 -- iter: 275/275
--
Training Step: 82  | total loss: [1m[32m0.69001[0m[0m | time: 0.630s
[2K
| Adam | epoch: 010 | loss: 0.69001 - acc: 0.5695 -- iter: 032/275
[A[ATraining Step: 83  | total loss: [1m[32m0.68914[0m[0m | time: 1.232s
[2K
| Adam | epoch: 010 | loss: 0.68914 - acc: 0.5688 -- iter: 064/275
[A[ATraining Step: 84  | total loss: [1m[32m0.68747[0m[0m | time: 1.824s
[2K
| Adam | epoch: 010 | loss: 0.68747 - acc: 0.5682 -- iter: 096/275
[A[ATraining Step: 85  | total loss: [1m[32m0.68755[0m[0m | time: 2.425s
[2K
| Adam | epoch: 010 | loss: 0.68755 - acc: 0.5614 -- iter: 128/275
[A[ATraining Step: 86  | total loss: [1m[32m0.68510[0m[0m | time: 3.048s
[2K
| Adam | epoch: 010 | loss: 0.68510 - acc: 0.5802 -- iter: 160/275
[A[ATraining Step: 87  | total loss: [1m[32m0.67963[0m[0m | time: 3.659s
[2K
| Adam | epoch: 010 | loss: 0.67963 - acc: 0.6066 -- iter: 192/275
[A[ATraining Step: 88  | total loss: [1m[32m0.67710[0m[0m | time: 4.275s
[2K
| Adam | epoch: 010 | loss: 0.67710 - acc: 0.6053 -- iter: 224/275
[A[ATraining Step: 89  | total loss: [1m[32m0.67278[0m[0m | time: 4.643s
[2K
| Adam | epoch: 010 | loss: 0.67278 - acc: 0.6073 -- iter: 256/275
[A[ATraining Step: 90  | total loss: [1m[32m0.65803[0m[0m | time: 6.032s
[2K
| Adam | epoch: 010 | loss: 0.65803 - acc: 0.6360 | val_loss: 0.57170 - val_acc: 0.6897 -- iter: 275/275
--
Training Step: 91  | total loss: [1m[32m0.64176[0m[0m | time: 0.606s
[2K
| Adam | epoch: 011 | loss: 0.64176 - acc: 0.6566 -- iter: 032/275
[A[ATraining Step: 92  | total loss: [1m[32m0.62702[0m[0m | time: 1.229s
[2K
| Adam | epoch: 011 | loss: 0.62702 - acc: 0.6691 -- iter: 064/275
[A[ATraining Step: 93  | total loss: [1m[32m0.64331[0m[0m | time: 1.859s
[2K
| Adam | epoch: 011 | loss: 0.64331 - acc: 0.6616 -- iter: 096/275
[A[ATraining Step: 94  | total loss: [1m[32m0.62265[0m[0m | time: 2.474s
[2K
| Adam | epoch: 011 | loss: 0.62265 - acc: 0.6735 -- iter: 128/275
[A[ATraining Step: 95  | total loss: [1m[32m0.62869[0m[0m | time: 3.101s
[2K
| Adam | epoch: 011 | loss: 0.62869 - acc: 0.6718 -- iter: 160/275
[A[ATraining Step: 96  | total loss: [1m[32m0.61198[0m[0m | time: 3.717s
[2K
| Adam | epoch: 011 | loss: 0.61198 - acc: 0.6796 -- iter: 192/275
[A[ATraining Step: 97  | total loss: [1m[32m0.61426[0m[0m | time: 4.347s
[2K
| Adam | epoch: 011 | loss: 0.61426 - acc: 0.6773 -- iter: 224/275
[A[ATraining Step: 98  | total loss: [1m[32m0.62077[0m[0m | time: 4.966s
[2K
| Adam | epoch: 011 | loss: 0.62077 - acc: 0.6783 -- iter: 256/275
[A[ATraining Step: 99  | total loss: [1m[32m0.61634[0m[0m | time: 6.351s
[2K
| Adam | epoch: 011 | loss: 0.61634 - acc: 0.6855 | val_loss: 0.57266 - val_acc: 0.7241 -- iter: 275/275
--
Training Step: 100  | total loss: [1m[32m0.59674[0m[0m | time: 0.410s
[2K
| Adam | epoch: 012 | loss: 0.59674 - acc: 0.7117 -- iter: 032/275
[A[ATraining Step: 101  | total loss: [1m[32m0.57908[0m[0m | time: 1.016s
[2K
| Adam | epoch: 012 | loss: 0.57908 - acc: 0.7247 -- iter: 064/275
[A[ATraining Step: 102  | total loss: [1m[32m0.58533[0m[0m | time: 1.626s
[2K
| Adam | epoch: 012 | loss: 0.58533 - acc: 0.7210 -- iter: 096/275
[A[ATraining Step: 103  | total loss: [1m[32m0.58361[0m[0m | time: 2.240s
[2K
| Adam | epoch: 012 | loss: 0.58361 - acc: 0.7270 -- iter: 128/275
[A[ATraining Step: 104  | total loss: [1m[32m0.58667[0m[0m | time: 2.822s
[2K
| Adam | epoch: 012 | loss: 0.58667 - acc: 0.7199 -- iter: 160/275
[A[ATraining Step: 105  | total loss: [1m[32m0.57971[0m[0m | time: 3.431s
[2K
| Adam | epoch: 012 | loss: 0.57971 - acc: 0.7229 -- iter: 192/275
[A[ATraining Step: 106  | total loss: [1m[32m0.57338[0m[0m | time: 4.032s
[2K
| Adam | epoch: 012 | loss: 0.57338 - acc: 0.7319 -- iter: 224/275
[A[ATraining Step: 107  | total loss: [1m[32m0.56541[0m[0m | time: 4.635s
[2K
| Adam | epoch: 012 | loss: 0.56541 - acc: 0.7337 -- iter: 256/275
[A[ATraining Step: 108  | total loss: [1m[32m0.57696[0m[0m | time: 6.248s
[2K
| Adam | epoch: 012 | loss: 0.57696 - acc: 0.7228 | val_loss: 0.56681 - val_acc: 0.7241 -- iter: 275/275
--
Training Step: 109  | total loss: [1m[32m0.55909[0m[0m | time: 0.395s
[2K
| Adam | epoch: 013 | loss: 0.55909 - acc: 0.7318 -- iter: 032/275
[A[ATraining Step: 110  | total loss: [1m[32m0.55680[0m[0m | time: 0.779s
[2K
| Adam | epoch: 013 | loss: 0.55680 - acc: 0.7376 -- iter: 064/275
[A[ATraining Step: 111  | total loss: [1m[32m0.55425[0m[0m | time: 1.384s
[2K
| Adam | epoch: 013 | loss: 0.55425 - acc: 0.7428 -- iter: 096/275
[A[ATraining Step: 112  | total loss: [1m[32m0.54907[0m[0m | time: 1.995s
[2K
| Adam | epoch: 013 | loss: 0.54907 - acc: 0.7404 -- iter: 128/275
[A[ATraining Step: 113  | total loss: [1m[32m0.52355[0m[0m | time: 2.638s
[2K
| Adam | epoch: 013 | loss: 0.52355 - acc: 0.7601 -- iter: 160/275
[A[ATraining Step: 114  | total loss: [1m[32m0.51579[0m[0m | time: 3.237s
[2K
| Adam | epoch: 013 | loss: 0.51579 - acc: 0.7622 -- iter: 192/275
[A[ATraining Step: 115  | total loss: [1m[32m0.50514[0m[0m | time: 3.848s
[2K
| Adam | epoch: 013 | loss: 0.50514 - acc: 0.7735 -- iter: 224/275
[A[ATraining Step: 116  | total loss: [1m[32m0.49549[0m[0m | time: 4.457s
[2K
| Adam | epoch: 013 | loss: 0.49549 - acc: 0.7774 -- iter: 256/275
[A[ATraining Step: 117  | total loss: [1m[32m0.50623[0m[0m | time: 6.060s
[2K
| Adam | epoch: 013 | loss: 0.50623 - acc: 0.7746 | val_loss: 0.48938 - val_acc: 0.7586 -- iter: 275/275
--
Training Step: 118  | total loss: [1m[32m0.49569[0m[0m | time: 0.620s
[2K
| Adam | epoch: 014 | loss: 0.49569 - acc: 0.7815 -- iter: 032/275
[A[ATraining Step: 119  | total loss: [1m[32m0.49187[0m[0m | time: 0.995s
[2K
| Adam | epoch: 014 | loss: 0.49187 - acc: 0.7846 -- iter: 064/275
[A[ATraining Step: 120  | total loss: [1m[32m0.47799[0m[0m | time: 1.366s
[2K
| Adam | epoch: 014 | loss: 0.47799 - acc: 0.7904 -- iter: 096/275
[A[ATraining Step: 121  | total loss: [1m[32m0.46410[0m[0m | time: 1.980s
[2K
| Adam | epoch: 014 | loss: 0.46410 - acc: 0.7903 -- iter: 128/275
[A[ATraining Step: 122  | total loss: [1m[32m0.46235[0m[0m | time: 2.572s
[2K
| Adam | epoch: 014 | loss: 0.46235 - acc: 0.7925 -- iter: 160/275
[A[ATraining Step: 123  | total loss: [1m[32m0.45768[0m[0m | time: 3.188s
[2K
| Adam | epoch: 014 | loss: 0.45768 - acc: 0.7914 -- iter: 192/275
[A[ATraining Step: 124  | total loss: [1m[32m0.44576[0m[0m | time: 3.820s
[2K
| Adam | epoch: 014 | loss: 0.44576 - acc: 0.7998 -- iter: 224/275
[A[ATraining Step: 125  | total loss: [1m[32m0.42472[0m[0m | time: 4.417s
[2K
| Adam | epoch: 014 | loss: 0.42472 - acc: 0.8135 -- iter: 256/275
[A[ATraining Step: 126  | total loss: [1m[32m0.43558[0m[0m | time: 6.169s
[2K
| Adam | epoch: 014 | loss: 0.43558 - acc: 0.8040 | val_loss: 0.56998 - val_acc: 0.7126 -- iter: 275/275
--
Training Step: 127  | total loss: [1m[32m0.42973[0m[0m | time: 0.604s
[2K
| Adam | epoch: 015 | loss: 0.42973 - acc: 0.8111 -- iter: 032/275
[A[ATraining Step: 128  | total loss: [1m[32m0.44041[0m[0m | time: 1.246s
[2K
| Adam | epoch: 015 | loss: 0.44041 - acc: 0.7988 -- iter: 064/275
[A[ATraining Step: 129  | total loss: [1m[32m0.45374[0m[0m | time: 1.625s
[2K
| Adam | epoch: 015 | loss: 0.45374 - acc: 0.7939 -- iter: 096/275
[A[ATraining Step: 130  | total loss: [1m[32m0.43664[0m[0m | time: 1.996s
[2K
| Adam | epoch: 015 | loss: 0.43664 - acc: 0.7987 -- iter: 128/275
[A[ATraining Step: 131  | total loss: [1m[32m0.42367[0m[0m | time: 2.601s
[2K
| Adam | epoch: 015 | loss: 0.42367 - acc: 0.7978 -- iter: 160/275
[A[ATraining Step: 132  | total loss: [1m[32m0.41795[0m[0m | time: 3.192s
[2K
| Adam | epoch: 015 | loss: 0.41795 - acc: 0.7961 -- iter: 192/275
[A[ATraining Step: 133  | total loss: [1m[32m0.40560[0m[0m | time: 3.795s
[2K
| Adam | epoch: 015 | loss: 0.40560 - acc: 0.8040 -- iter: 224/275
[A[ATraining Step: 134  | total loss: [1m[32m0.41396[0m[0m | time: 4.392s
[2K
| Adam | epoch: 015 | loss: 0.41396 - acc: 0.8018 -- iter: 256/275
[A[ATraining Step: 135  | total loss: [1m[32m0.39812[0m[0m | time: 5.992s
[2K
| Adam | epoch: 015 | loss: 0.39812 - acc: 0.8091 | val_loss: 0.41998 - val_acc: 0.7931 -- iter: 275/275
--
Training Step: 136  | total loss: [1m[32m0.38212[0m[0m | time: 0.610s
[2K
| Adam | epoch: 016 | loss: 0.38212 - acc: 0.8188 -- iter: 032/275
[A[ATraining Step: 137  | total loss: [1m[32m0.37806[0m[0m | time: 1.236s
[2K
| Adam | epoch: 016 | loss: 0.37806 - acc: 0.8275 -- iter: 064/275
[A[ATraining Step: 138  | total loss: [1m[32m0.35864[0m[0m | time: 1.844s
[2K
| Adam | epoch: 016 | loss: 0.35864 - acc: 0.8385 -- iter: 096/275
[A[ATraining Step: 139  | total loss: [1m[32m0.34385[0m[0m | time: 2.322s
[2K
| Adam | epoch: 016 | loss: 0.34385 - acc: 0.8453 -- iter: 128/275
[A[ATraining Step: 140  | total loss: [1m[32m0.36196[0m[0m | time: 2.764s
[2K
| Adam | epoch: 016 | loss: 0.36196 - acc: 0.8397 -- iter: 160/275
[A[ATraining Step: 141  | total loss: [1m[32m0.37840[0m[0m | time: 3.528s
[2K
| Adam | epoch: 016 | loss: 0.37840 - acc: 0.8294 -- iter: 192/275
[A[ATraining Step: 142  | total loss: [1m[32m0.36324[0m[0m | time: 4.383s
[2K
| Adam | epoch: 016 | loss: 0.36324 - acc: 0.8371 -- iter: 224/275
[A[ATraining Step: 143  | total loss: [1m[32m0.36069[0m[0m | time: 5.153s
[2K
| Adam | epoch: 016 | loss: 0.36069 - acc: 0.8440 -- iter: 256/275
[A[ATraining Step: 144  | total loss: [1m[32m0.36813[0m[0m | time: 6.927s
[2K
| Adam | epoch: 016 | loss: 0.36813 - acc: 0.8440 | val_loss: 0.46646 - val_acc: 0.7931 -- iter: 275/275
--
Training Step: 145  | total loss: [1m[32m0.37425[0m[0m | time: 0.796s
[2K
| Adam | epoch: 017 | loss: 0.37425 - acc: 0.8377 -- iter: 032/275
[A[ATraining Step: 146  | total loss: [1m[32m0.36706[0m[0m | time: 1.578s
[2K
| Adam | epoch: 017 | loss: 0.36706 - acc: 0.8383 -- iter: 064/275
[A[ATraining Step: 147  | total loss: [1m[32m0.35272[0m[0m | time: 2.349s
[2K
| Adam | epoch: 017 | loss: 0.35272 - acc: 0.8482 -- iter: 096/275
[A[ATraining Step: 148  | total loss: [1m[32m0.34804[0m[0m | time: 3.130s
[2K
| Adam | epoch: 017 | loss: 0.34804 - acc: 0.8572 -- iter: 128/275
[A[ATraining Step: 149  | total loss: [1m[32m0.33713[0m[0m | time: 3.638s
[2K
| Adam | epoch: 017 | loss: 0.33713 - acc: 0.8621 -- iter: 160/275
[A[ATraining Step: 150  | total loss: [1m[32m0.32283[0m[0m | time: 4.121s
[2K
| Adam | epoch: 017 | loss: 0.32283 - acc: 0.8653 -- iter: 192/275
[A[ATraining Step: 151  | total loss: [1m[32m0.30929[0m[0m | time: 4.871s
[2K
| Adam | epoch: 017 | loss: 0.30929 - acc: 0.8683 -- iter: 224/275
[A[ATraining Step: 152  | total loss: [1m[32m0.29096[0m[0m | time: 5.616s
[2K
| Adam | epoch: 017 | loss: 0.29096 - acc: 0.8783 -- iter: 256/275
[A[ATraining Step: 153  | total loss: [1m[32m0.27979[0m[0m | time: 7.344s
[2K
| Adam | epoch: 017 | loss: 0.27979 - acc: 0.8874 | val_loss: 0.34922 - val_acc: 0.8621 -- iter: 275/275
--
Training Step: 154  | total loss: [1m[32m0.26574[0m[0m | time: 0.797s
[2K
| Adam | epoch: 018 | loss: 0.26574 - acc: 0.8955 -- iter: 032/275
[A[ATraining Step: 155  | total loss: [1m[32m0.26094[0m[0m | time: 1.554s
[2K
| Adam | epoch: 018 | loss: 0.26094 - acc: 0.8935 -- iter: 064/275
[A[ATraining Step: 156  | total loss: [1m[32m0.23920[0m[0m | time: 2.267s
[2K
| Adam | epoch: 018 | loss: 0.23920 - acc: 0.9041 -- iter: 096/275
[A[ATraining Step: 157  | total loss: [1m[32m0.23409[0m[0m | time: 2.995s
[2K
| Adam | epoch: 018 | loss: 0.23409 - acc: 0.9075 -- iter: 128/275
[A[ATraining Step: 158  | total loss: [1m[32m0.22787[0m[0m | time: 3.732s
[2K
| Adam | epoch: 018 | loss: 0.22787 - acc: 0.9073 -- iter: 160/275
[A[ATraining Step: 159  | total loss: [1m[32m0.22193[0m[0m | time: 4.185s
[2K
| Adam | epoch: 018 | loss: 0.22193 - acc: 0.9072 -- iter: 192/275
[A[ATraining Step: 160  | total loss: [1m[32m0.20829[0m[0m | time: 4.609s
[2K
| Adam | epoch: 018 | loss: 0.20829 - acc: 0.9165 -- iter: 224/275
[A[ATraining Step: 161  | total loss: [1m[32m0.20059[0m[0m | time: 5.349s
[2K
| Adam | epoch: 018 | loss: 0.20059 - acc: 0.9143 -- iter: 256/275
[A[ATraining Step: 162  | total loss: [1m[32m0.19807[0m[0m | time: 7.082s
[2K
| Adam | epoch: 018 | loss: 0.19807 - acc: 0.9135 | val_loss: 0.44436 - val_acc: 0.8621 -- iter: 275/275
--
Training Step: 163  | total loss: [1m[32m0.18411[0m[0m | time: 0.765s
[2K
| Adam | epoch: 019 | loss: 0.18411 - acc: 0.9222 -- iter: 032/275
[A[ATraining Step: 164  | total loss: [1m[32m0.19107[0m[0m | time: 1.569s
[2K
| Adam | epoch: 019 | loss: 0.19107 - acc: 0.9174 -- iter: 064/275
[A[ATraining Step: 165  | total loss: [1m[32m0.20346[0m[0m | time: 2.314s
[2K
| Adam | epoch: 019 | loss: 0.20346 - acc: 0.9132 -- iter: 096/275
[A[ATraining Step: 166  | total loss: [1m[32m0.19467[0m[0m | time: 3.102s
[2K
| Adam | epoch: 019 | loss: 0.19467 - acc: 0.9188 -- iter: 128/275
[A[ATraining Step: 167  | total loss: [1m[32m0.18795[0m[0m | time: 3.966s
[2K
| Adam | epoch: 019 | loss: 0.18795 - acc: 0.9238 -- iter: 160/275
[A[ATraining Step: 168  | total loss: [1m[32m0.17595[0m[0m | time: 4.724s
[2K
| Adam | epoch: 019 | loss: 0.17595 - acc: 0.9314 -- iter: 192/275
[A[ATraining Step: 169  | total loss: [1m[32m0.17236[0m[0m | time: 5.247s
[2K
| Adam | epoch: 019 | loss: 0.17236 - acc: 0.9320 -- iter: 224/275
[A[ATraining Step: 170  | total loss: [1m[32m0.15832[0m[0m | time: 5.804s
[2K
| Adam | epoch: 019 | loss: 0.15832 - acc: 0.9388 -- iter: 256/275
[A[ATraining Step: 171  | total loss: [1m[32m0.15067[0m[0m | time: 7.568s
[2K
| Adam | epoch: 019 | loss: 0.15067 - acc: 0.9449 | val_loss: 0.36179 - val_acc: 0.9080 -- iter: 275/275
--
Training Step: 172  | total loss: [1m[32m0.14028[0m[0m | time: 0.753s
[2K
| Adam | epoch: 020 | loss: 0.14028 - acc: 0.9504 -- iter: 032/275
[A[ATraining Step: 173  | total loss: [1m[32m0.13921[0m[0m | time: 1.478s
[2K
| Adam | epoch: 020 | loss: 0.13921 - acc: 0.9523 -- iter: 064/275
[A[ATraining Step: 174  | total loss: [1m[32m0.13631[0m[0m | time: 2.206s
[2K
| Adam | epoch: 020 | loss: 0.13631 - acc: 0.9539 -- iter: 096/275
[A[ATraining Step: 175  | total loss: [1m[32m0.12995[0m[0m | time: 2.921s
[2K
| Adam | epoch: 020 | loss: 0.12995 - acc: 0.9554 -- iter: 128/275
[A[ATraining Step: 176  | total loss: [1m[32m0.12021[0m[0m | time: 3.643s
[2K
| Adam | epoch: 020 | loss: 0.12021 - acc: 0.9599 -- iter: 160/275
[A[ATraining Step: 177  | total loss: [1m[32m0.11550[0m[0m | time: 4.370s
[2K
| Adam | epoch: 020 | loss: 0.11550 - acc: 0.9607 -- iter: 192/275
[A[ATraining Step: 178  | total loss: [1m[32m0.20340[0m[0m | time: 5.095s
[2K
| Adam | epoch: 020 | loss: 0.20340 - acc: 0.9459 -- iter: 224/275
[A[ATraining Step: 179  | total loss: [1m[32m0.20384[0m[0m | time: 5.566s
[2K
| Adam | epoch: 020 | loss: 0.20384 - acc: 0.9420 -- iter: 256/275
[A[ATraining Step: 180  | total loss: [1m[32m0.20211[0m[0m | time: 7.004s
[2K
| Adam | epoch: 020 | loss: 0.20211 - acc: 0.9372 | val_loss: 0.36595 - val_acc: 0.8851 -- iter: 275/275
--
Training Step: 181  | total loss: [1m[32m0.18564[0m[0m | time: 0.748s
[2K
| Adam | epoch: 021 | loss: 0.18564 - acc: 0.9435 -- iter: 032/275
[A[ATraining Step: 182  | total loss: [1m[32m0.16912[0m[0m | time: 1.471s
[2K
| Adam | epoch: 021 | loss: 0.16912 - acc: 0.9492 -- iter: 064/275
[A[ATraining Step: 183  | total loss: [1m[32m0.16587[0m[0m | time: 2.395s
[2K
| Adam | epoch: 021 | loss: 0.16587 - acc: 0.9480 -- iter: 096/275
[A[ATraining Step: 184  | total loss: [1m[32m0.16613[0m[0m | time: 3.064s
[2K
| Adam | epoch: 021 | loss: 0.16613 - acc: 0.9438 -- iter: 128/275
[A[ATraining Step: 185  | total loss: [1m[32m0.15132[0m[0m | time: 3.679s
[2K
| Adam | epoch: 021 | loss: 0.15132 - acc: 0.9494 -- iter: 160/275
[A[ATraining Step: 186  | total loss: [1m[32m0.14121[0m[0m | time: 4.366s
[2K
| Adam | epoch: 021 | loss: 0.14121 - acc: 0.9545 -- iter: 192/275
[A[ATraining Step: 187  | total loss: [1m[32m0.15062[0m[0m | time: 5.061s
[2K
| Adam | epoch: 021 | loss: 0.15062 - acc: 0.9559 -- iter: 224/275
[A[ATraining Step: 188  | total loss: [1m[32m0.14657[0m[0m | time: 5.845s
[2K
| Adam | epoch: 021 | loss: 0.14657 - acc: 0.9572 -- iter: 256/275
[A[ATraining Step: 189  | total loss: [1m[32m0.13360[0m[0m | time: 7.322s
[2K
| Adam | epoch: 021 | loss: 0.13360 - acc: 0.9615 | val_loss: 0.47934 - val_acc: 0.8161 -- iter: 275/275
--
Training Step: 190  | total loss: [1m[32m0.12359[0m[0m | time: 0.448s
[2K
| Adam | epoch: 022 | loss: 0.12359 - acc: 0.9653 -- iter: 032/275
[A[ATraining Step: 191  | total loss: [1m[32m0.11468[0m[0m | time: 1.222s
[2K
| Adam | epoch: 022 | loss: 0.11468 - acc: 0.9688 -- iter: 064/275
[A[ATraining Step: 192  | total loss: [1m[32m0.10576[0m[0m | time: 1.954s
[2K
| Adam | epoch: 022 | loss: 0.10576 - acc: 0.9719 -- iter: 096/275
[A[ATraining Step: 193  | total loss: [1m[32m0.10037[0m[0m | time: 2.716s
[2K
| Adam | epoch: 022 | loss: 0.10037 - acc: 0.9716 -- iter: 128/275
[A[ATraining Step: 194  | total loss: [1m[32m0.09133[0m[0m | time: 3.521s
[2K
| Adam | epoch: 022 | loss: 0.09133 - acc: 0.9744 -- iter: 160/275
[A[ATraining Step: 195  | total loss: [1m[32m0.08448[0m[0m | time: 4.250s
[2K
| Adam | epoch: 022 | loss: 0.08448 - acc: 0.9770 -- iter: 192/275
[A[ATraining Step: 196  | total loss: [1m[32m0.08805[0m[0m | time: 4.999s
[2K
| Adam | epoch: 022 | loss: 0.08805 - acc: 0.9762 -- iter: 224/275
[A[ATraining Step: 197  | total loss: [1m[32m0.08104[0m[0m | time: 5.714s
[2K
| Adam | epoch: 022 | loss: 0.08104 - acc: 0.9786 -- iter: 256/275
[A[ATraining Step: 198  | total loss: [1m[32m0.07430[0m[0m | time: 7.573s
[2K
| Adam | epoch: 022 | loss: 0.07430 - acc: 0.9807 | val_loss: 0.44955 - val_acc: 0.8161 -- iter: 275/275
--
Training Step: 199  | total loss: [1m[32m0.06982[0m[0m | time: 0.388s
[2K
| Adam | epoch: 023 | loss: 0.06982 - acc: 0.9826 -- iter: 032/275
[A[ATraining Step: 200  | total loss: [1m[32m0.06515[0m[0m | time: 1.835s
[2K
| Adam | epoch: 023 | loss: 0.06515 - acc: 0.9844 | val_loss: 0.50878 - val_acc: 0.8161 -- iter: 064/275
--
Training Step: 201  | total loss: [1m[32m0.06074[0m[0m | time: 2.580s
[2K
| Adam | epoch: 023 | loss: 0.06074 - acc: 0.9859 -- iter: 096/275
[A[ATraining Step: 202  | total loss: [1m[32m0.05585[0m[0m | time: 3.313s
[2K
| Adam | epoch: 023 | loss: 0.05585 - acc: 0.9873 -- iter: 128/275
[A[ATraining Step: 203  | total loss: [1m[32m0.05406[0m[0m | time: 4.078s
[2K
| Adam | epoch: 023 | loss: 0.05406 - acc: 0.9886 -- iter: 160/275
[A[ATraining Step: 204  | total loss: [1m[32m0.04928[0m[0m | time: 4.839s
[2K
| Adam | epoch: 023 | loss: 0.04928 - acc: 0.9897 -- iter: 192/275
[A[ATraining Step: 205  | total loss: [1m[32m0.04526[0m[0m | time: 5.569s
[2K
| Adam | epoch: 023 | loss: 0.04526 - acc: 0.9908 -- iter: 224/275
[A[ATraining Step: 206  | total loss: [1m[32m0.04128[0m[0m | time: 6.297s
[2K
| Adam | epoch: 023 | loss: 0.04128 - acc: 0.9917 -- iter: 256/275
[A[ATraining Step: 207  | total loss: [1m[32m0.05893[0m[0m | time: 8.067s
[2K
| Adam | epoch: 023 | loss: 0.05893 - acc: 0.9894 | val_loss: 0.46702 - val_acc: 0.8851 -- iter: 275/275
--
Training Step: 208  | total loss: [1m[32m0.05450[0m[0m | time: 0.794s
[2K
| Adam | epoch: 024 | loss: 0.05450 - acc: 0.9905 -- iter: 032/275
[A[ATraining Step: 209  | total loss: [1m[32m0.05001[0m[0m | time: 1.338s
[2K
| Adam | epoch: 024 | loss: 0.05001 - acc: 0.9914 -- iter: 064/275
[A[ATraining Step: 210  | total loss: [1m[32m0.04722[0m[0m | time: 1.822s
[2K
| Adam | epoch: 024 | loss: 0.04722 - acc: 0.9923 -- iter: 096/275
[A[ATraining Step: 211  | total loss: [1m[32m0.04298[0m[0m | time: 2.626s
[2K
| Adam | epoch: 024 | loss: 0.04298 - acc: 0.9930 -- iter: 128/275
[A[ATraining Step: 212  | total loss: [1m[32m0.04018[0m[0m | time: 3.423s
[2K
| Adam | epoch: 024 | loss: 0.04018 - acc: 0.9937 -- iter: 160/275
[A[ATraining Step: 213  | total loss: [1m[32m0.03828[0m[0m | time: 4.150s
[2K
| Adam | epoch: 024 | loss: 0.03828 - acc: 0.9944 -- iter: 192/275
[A[ATraining Step: 214  | total loss: [1m[32m0.03564[0m[0m | time: 4.743s
[2K
| Adam | epoch: 024 | loss: 0.03564 - acc: 0.9949 -- iter: 224/275
[A[ATraining Step: 215  | total loss: [1m[32m0.04373[0m[0m | time: 5.341s
[2K
| Adam | epoch: 024 | loss: 0.04373 - acc: 0.9923 -- iter: 256/275
[A[ATraining Step: 216  | total loss: [1m[32m0.04099[0m[0m | time: 7.102s
[2K
| Adam | epoch: 024 | loss: 0.04099 - acc: 0.9931 | val_loss: 0.52709 - val_acc: 0.8966 -- iter: 275/275
--
Training Step: 217  | total loss: [1m[32m0.04518[0m[0m | time: 0.770s
[2K
| Adam | epoch: 025 | loss: 0.04518 - acc: 0.9906 -- iter: 032/275
[A[ATraining Step: 218  | total loss: [1m[32m0.06299[0m[0m | time: 1.491s
[2K
| Adam | epoch: 025 | loss: 0.06299 - acc: 0.9885 -- iter: 064/275
[A[ATraining Step: 219  | total loss: [1m[32m0.05706[0m[0m | time: 1.960s
[2K
| Adam | epoch: 025 | loss: 0.05706 - acc: 0.9896 -- iter: 096/275
[A[ATraining Step: 220  | total loss: [1m[32m0.05177[0m[0m | time: 2.423s
[2K
| Adam | epoch: 025 | loss: 0.05177 - acc: 0.9907 -- iter: 128/275
[A[ATraining Step: 221  | total loss: [1m[32m0.04753[0m[0m | time: 3.142s
[2K
| Adam | epoch: 025 | loss: 0.04753 - acc: 0.9916 -- iter: 160/275
[A[ATraining Step: 222  | total loss: [1m[32m0.04915[0m[0m | time: 3.874s
[2K
| Adam | epoch: 025 | loss: 0.04915 - acc: 0.9862 -- iter: 192/275
[A[ATraining Step: 223  | total loss: [1m[32m0.04465[0m[0m | time: 4.618s
[2K
| Adam | epoch: 025 | loss: 0.04465 - acc: 0.9876 -- iter: 224/275
[A[ATraining Step: 224  | total loss: [1m[32m0.04228[0m[0m | time: 5.356s
[2K
| Adam | epoch: 025 | loss: 0.04228 - acc: 0.9888 -- iter: 256/275
[A[ATraining Step: 225  | total loss: [1m[32m0.05655[0m[0m | time: 7.105s
[2K
| Adam | epoch: 025 | loss: 0.05655 - acc: 0.9837 | val_loss: 0.43773 - val_acc: 0.8621 -- iter: 275/275
--
Training Step: 226  | total loss: [1m[32m0.05194[0m[0m | time: 0.908s
[2K
| Adam | epoch: 026 | loss: 0.05194 - acc: 0.9853 -- iter: 032/275
[A[ATraining Step: 227  | total loss: [1m[32m0.04717[0m[0m | time: 1.522s
[2K
| Adam | epoch: 026 | loss: 0.04717 - acc: 0.9868 -- iter: 064/275
[A[ATraining Step: 228  | total loss: [1m[32m0.05990[0m[0m | time: 2.128s
[2K
| Adam | epoch: 026 | loss: 0.05990 - acc: 0.9850 -- iter: 096/275
[A[ATraining Step: 229  | total loss: [1m[32m0.05928[0m[0m | time: 2.517s
[2K
| Adam | epoch: 026 | loss: 0.05928 - acc: 0.9834 -- iter: 128/275
[A[ATraining Step: 230  | total loss: [1m[32m0.05419[0m[0m | time: 2.922s
[2K
| Adam | epoch: 026 | loss: 0.05419 - acc: 0.9850 -- iter: 160/275
[A[ATraining Step: 231  | total loss: [1m[32m0.04996[0m[0m | time: 3.658s
[2K
| Adam | epoch: 026 | loss: 0.04996 - acc: 0.9865 -- iter: 192/275
[A[ATraining Step: 232  | total loss: [1m[32m0.04576[0m[0m | time: 4.397s
[2K
| Adam | epoch: 026 | loss: 0.04576 - acc: 0.9879 -- iter: 224/275
[A[ATraining Step: 233  | total loss: [1m[32m0.04732[0m[0m | time: 5.142s
[2K
| Adam | epoch: 026 | loss: 0.04732 - acc: 0.9860 -- iter: 256/275
[A[ATraining Step: 234  | total loss: [1m[32m0.04335[0m[0m | time: 6.872s
[2K
| Adam | epoch: 026 | loss: 0.04335 - acc: 0.9874 | val_loss: 0.42395 - val_acc: 0.8391 -- iter: 275/275
--
Training Step: 235  | total loss: [1m[32m0.04037[0m[0m | time: 0.778s
[2K
| Adam | epoch: 027 | loss: 0.04037 - acc: 0.9886 -- iter: 032/275
[A[ATraining Step: 236  | total loss: [1m[32m0.03828[0m[0m | time: 1.567s
[2K
| Adam | epoch: 027 | loss: 0.03828 - acc: 0.9898 -- iter: 064/275
[A[ATraining Step: 237  | total loss: [1m[32m0.03502[0m[0m | time: 2.279s
[2K
| Adam | epoch: 027 | loss: 0.03502 - acc: 0.9908 -- iter: 096/275
[A[ATraining Step: 238  | total loss: [1m[32m0.04405[0m[0m | time: 3.052s
[2K
| Adam | epoch: 027 | loss: 0.04405 - acc: 0.9886 -- iter: 128/275
[A[ATraining Step: 239  | total loss: [1m[32m0.05116[0m[0m | time: 3.517s
[2K
| Adam | epoch: 027 | loss: 0.05116 - acc: 0.9866 -- iter: 160/275
[A[ATraining Step: 240  | total loss: [1m[32m0.04645[0m[0m | time: 3.989s
[2K
| Adam | epoch: 027 | loss: 0.04645 - acc: 0.9879 -- iter: 192/275
[A[ATraining Step: 241  | total loss: [1m[32m0.04215[0m[0m | time: 4.810s
[2K
| Adam | epoch: 027 | loss: 0.04215 - acc: 0.9891 -- iter: 224/275
[A[ATraining Step: 242  | total loss: [1m[32m0.03872[0m[0m | time: 5.603s
[2K
| Adam | epoch: 027 | loss: 0.03872 - acc: 0.9902 -- iter: 256/275
[A[ATraining Step: 243  | total loss: [1m[32m0.03681[0m[0m | time: 7.331s
[2K
| Adam | epoch: 027 | loss: 0.03681 - acc: 0.9912 | val_loss: 0.36932 - val_acc: 0.8966 -- iter: 275/275
--
Training Step: 244  | total loss: [1m[32m0.04262[0m[0m | time: 0.632s
[2K
| Adam | epoch: 028 | loss: 0.04262 - acc: 0.9890 -- iter: 032/275
[A[ATraining Step: 245  | total loss: [1m[32m0.03877[0m[0m | time: 1.282s
[2K
| Adam | epoch: 028 | loss: 0.03877 - acc: 0.9901 -- iter: 064/275
[A[ATraining Step: 246  | total loss: [1m[32m0.03611[0m[0m | time: 2.053s
[2K
| Adam | epoch: 028 | loss: 0.03611 - acc: 0.9911 -- iter: 096/275
[A[ATraining Step: 247  | total loss: [1m[32m0.03569[0m[0m | time: 2.819s
[2K
| Adam | epoch: 028 | loss: 0.03569 - acc: 0.9920 -- iter: 128/275
[A[ATraining Step: 248  | total loss: [1m[32m0.05523[0m[0m | time: 3.612s
[2K
| Adam | epoch: 028 | loss: 0.05523 - acc: 0.9896 -- iter: 160/275
[A[ATraining Step: 249  | total loss: [1m[32m0.05102[0m[0m | time: 4.040s
[2K
| Adam | epoch: 028 | loss: 0.05102 - acc: 0.9907 -- iter: 192/275
[A[ATraining Step: 250  | total loss: [1m[32m0.05425[0m[0m | time: 4.532s
[2K
| Adam | epoch: 028 | loss: 0.05425 - acc: 0.9863 -- iter: 224/275
[A[ATraining Step: 251  | total loss: [1m[32m0.05020[0m[0m | time: 5.209s
[2K
| Adam | epoch: 028 | loss: 0.05020 - acc: 0.9877 -- iter: 256/275
[A[ATraining Step: 252  | total loss: [1m[32m0.04883[0m[0m | time: 6.986s
[2K
| Adam | epoch: 028 | loss: 0.04883 - acc: 0.9858 | val_loss: 0.48963 - val_acc: 0.8391 -- iter: 275/275
--
Training Step: 253  | total loss: [1m[32m0.04488[0m[0m | time: 0.740s
[2K
| Adam | epoch: 029 | loss: 0.04488 - acc: 0.9872 -- iter: 032/275
[A[ATraining Step: 254  | total loss: [1m[32m0.04081[0m[0m | time: 1.464s
[2K
| Adam | epoch: 029 | loss: 0.04081 - acc: 0.9885 -- iter: 064/275
[A[ATraining Step: 255  | total loss: [1m[32m0.03720[0m[0m | time: 2.191s
[2K
| Adam | epoch: 029 | loss: 0.03720 - acc: 0.9897 -- iter: 096/275
[A[ATraining Step: 256  | total loss: [1m[32m0.03434[0m[0m | time: 2.910s
[2K
| Adam | epoch: 029 | loss: 0.03434 - acc: 0.9907 -- iter: 128/275
[A[ATraining Step: 257  | total loss: [1m[32m0.03156[0m[0m | time: 3.626s
[2K
| Adam | epoch: 029 | loss: 0.03156 - acc: 0.9916 -- iter: 160/275
[A[ATraining Step: 258  | total loss: [1m[32m0.02908[0m[0m | time: 4.369s
[2K
| Adam | epoch: 029 | loss: 0.02908 - acc: 0.9925 -- iter: 192/275
[A[ATraining Step: 259  | total loss: [1m[32m0.02672[0m[0m | time: 4.830s
[2K
| Adam | epoch: 029 | loss: 0.02672 - acc: 0.9932 -- iter: 224/275
[A[ATraining Step: 260  | total loss: [1m[32m0.02444[0m[0m | time: 5.268s
[2K
| Adam | epoch: 029 | loss: 0.02444 - acc: 0.9939 -- iter: 256/275
[A[ATraining Step: 261  | total loss: [1m[32m0.02234[0m[0m | time: 7.169s
[2K
| Adam | epoch: 029 | loss: 0.02234 - acc: 0.9945 | val_loss: 0.40689 - val_acc: 0.9080 -- iter: 275/275
--
Training Step: 262  | total loss: [1m[32m0.02062[0m[0m | time: 0.806s
[2K
| Adam | epoch: 030 | loss: 0.02062 - acc: 0.9951 -- iter: 032/275
[A[ATraining Step: 263  | total loss: [1m[32m0.01916[0m[0m | time: 1.667s
[2K
| Adam | epoch: 030 | loss: 0.01916 - acc: 0.9955 -- iter: 064/275
[A[ATraining Step: 264  | total loss: [1m[32m0.01770[0m[0m | time: 2.518s
[2K
| Adam | epoch: 030 | loss: 0.01770 - acc: 0.9960 -- iter: 096/275
[A[ATraining Step: 265  | total loss: [1m[32m0.01659[0m[0m | time: 3.327s
[2K
| Adam | epoch: 030 | loss: 0.01659 - acc: 0.9964 -- iter: 128/275
[A[ATraining Step: 266  | total loss: [1m[32m0.01519[0m[0m | time: 4.199s
[2K
| Adam | epoch: 030 | loss: 0.01519 - acc: 0.9968 -- iter: 160/275
[A[ATraining Step: 267  | total loss: [1m[32m0.04119[0m[0m | time: 4.940s
[2K
| Adam | epoch: 030 | loss: 0.04119 - acc: 0.9940 -- iter: 192/275
[A[ATraining Step: 268  | total loss: [1m[32m0.06333[0m[0m | time: 5.727s
[2K
| Adam | epoch: 030 | loss: 0.06333 - acc: 0.9914 -- iter: 224/275
[A[ATraining Step: 269  | total loss: [1m[32m0.05744[0m[0m | time: 6.237s
[2K
| Adam | epoch: 030 | loss: 0.05744 - acc: 0.9923 -- iter: 256/275
[A[ATraining Step: 270  | total loss: [1m[32m0.05214[0m[0m | time: 7.692s
[2K
| Adam | epoch: 030 | loss: 0.05214 - acc: 0.9931 | val_loss: 0.41298 - val_acc: 0.8966 -- iter: 275/275
--
Validation AUC:0.9349894291754756
Validation AUPRC:0.9176936522654684
Test AUC:0.9362162162162164
Test AUPRC:0.8862473094322414
BestTestF1Score	0.86	0.76	0.89	0.89	0.84	31	4	46	6	0.64
BestTestMCCScore	0.86	0.76	0.89	0.89	0.84	31	4	46	6	0.64
BestTestAccuracyScore	0.86	0.76	0.89	0.89	0.84	31	4	46	6	0.64
BestValidationF1Score	0.9	0.82	0.91	0.95	0.86	37	2	42	6	0.64
BestValidationMCC	0.9	0.82	0.91	0.95	0.86	37	2	42	6	0.64
BestValidationAccuracy	0.9	0.82	0.91	0.95	0.86	37	2	42	6	0.64
TestPredictions (Threshold:0.64)
CHEMBL284193,TN,INACT,0.0	CHEMBL2021372,TN,INACT,0.009999999776482582	CHEMBL3633656,TN,INACT,0.0	CHEMBL3633655,FP,INACT,0.8899999856948853	CHEMBL323713,TN,INACT,0.0	CHEMBL2023462,TP,ACT,0.9700000286102295	CHEMBL2204334,TN,INACT,0.0	CHEMBL1922727,FN,ACT,0.3199999928474426	CHEMBL322965,TN,INACT,0.0	CHEMBL348542,TN,INACT,0.0	CHEMBL1672246,FN,ACT,0.20000000298023224	CHEMBL91677,TN,INACT,0.0	CHEMBL122005,TN,INACT,0.0	CHEMBL367189,TN,INACT,0.009999999776482582	CHEMBL3609741,TP,ACT,0.9599999785423279	CHEMBL1209519,TP,ACT,0.800000011920929	CHEMBL3759376,TP,ACT,0.9900000095367432	CHEMBL2023455,TP,ACT,0.8700000047683716	CHEMBL164669,TN,INACT,0.0	CHEMBL1209746,TP,ACT,0.8799999952316284	CHEMBL1402439,TN,INACT,0.0	CHEMBL3798197,TP,ACT,0.9800000190734863	CHEMBL572128,TN,INACT,0.0	CHEMBL244584,TN,INACT,0.0	CHEMBL3758967,TP,ACT,0.949999988079071	CHEMBL563423,TP,ACT,0.9399999976158142	CHEMBL3628114,TP,ACT,0.9900000095367432	CHEMBL299683,FP,INACT,0.9100000262260437	CHEMBL1921854,TP,ACT,0.9900000095367432	CHEMBL378945,TN,INACT,0.0	CHEMBL327936,TN,INACT,0.0	CHEMBL3809795,TP,ACT,0.9900000095367432	CHEMBL1209661,FN,ACT,0.009999999776482582	CHEMBL267006,TN,INACT,0.05000000074505806	CHEMBL13260,TN,INACT,0.07999999821186066	CHEMBL315484,TN,INACT,0.0	CHEMBL477396,FN,ACT,0.5199999809265137	CHEMBL3758986,TP,ACT,0.9800000190734863	CHEMBL76232,FP,INACT,1.0	CHEMBL254429,TN,INACT,0.009999999776482582	CHEMBL2023452,TP,ACT,0.8999999761581421	CHEMBL2023470,TP,ACT,0.9700000286102295	CHEMBL1209521,TP,ACT,0.9800000190734863	CHEMBL40157,TN,INACT,0.0	CHEMBL3609729,TP,ACT,0.9900000095367432	CHEMBL2023469,TP,ACT,0.9900000095367432	CHEMBL46527,TN,INACT,0.009999999776482582	CHEMBL198310,TN,INACT,0.0	CHEMBL1672236,TP,ACT,0.9900000095367432	CHEMBL279998,TN,INACT,0.009999999776482582	CHEMBL34880,TP,ACT,0.9399999976158142	CHEMBL1672241,TP,ACT,0.949999988079071	CHEMBL211442,TN,INACT,0.6000000238418579	CHEMBL154678,TN,INACT,0.0	CHEMBL538307,TN,INACT,0.019999999552965164	CHEMBL3800579,TP,ACT,1.0	CHEMBL3759555,TP,ACT,0.9900000095367432	CHEMBL115664,TN,INACT,0.009999999776482582	CHEMBL284012,TN,INACT,0.009999999776482582	CHEMBL553885,TN,INACT,0.009999999776482582	CHEMBL1921961,TP,ACT,0.9900000095367432	CHEMBL3798517,TP,ACT,0.8399999737739563	CHEMBL113571,TN,INACT,0.0	CHEMBL252531,FP,INACT,0.9300000071525574	CHEMBL1921853,TP,ACT,1.0	CHEMBL39372,TN,INACT,0.0	CHEMBL41013,TN,INACT,0.0	CHEMBL3122221,TN,INACT,0.019999999552965164	CHEMBL3759289,TP,ACT,0.9800000190734863	CHEMBL277475,FN,ACT,0.009999999776482582	CHEMBL2346778,TN,INACT,0.029999999329447746	CHEMBL571063,FN,ACT,0.20000000298023224	CHEMBL112291,TN,INACT,0.0	CHEMBL3799708,TP,ACT,0.9599999785423279	CHEMBL444979,TN,INACT,0.03999999910593033	CHEMBL3423094,TN,INACT,0.0	CHEMBL2408581,TN,INACT,0.0	CHEMBL187941,TN,INACT,0.009999999776482582	CHEMBL2114116,TN,INACT,0.0	CHEMBL1672256,TP,ACT,0.6499999761581421	CHEMBL433392,TN,INACT,0.0	CHEMBL178058,TN,INACT,0.0	CHEMBL3609734,TP,ACT,0.9599999785423279	CHEMBL3401722,TN,INACT,0.0	CHEMBL2023633,TP,ACT,0.8100000023841858	CHEMBL3122225,TN,INACT,0.3100000023841858	CHEMBL324584,TN,INACT,0.3400000035762787	

