ImageNetInceptionV2 CHEMBL2014 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	1379
Number of inactive compounds :	1379
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2014_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2014_adam_0.001_15_0.8/
---------------------------------
Training samples: 1750
Validation samples: 548
--
Training Step: 1  | time: 99.041s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1750
[A[ATraining Step: 2  | total loss: [1m[32m0.66894[0m[0m | time: 167.341s
[2K
| Adam | epoch: 001 | loss: 0.66894 - acc: 0.4219 -- iter: 0064/1750
[A[ATraining Step: 3  | total loss: [1m[32m0.73035[0m[0m | time: 221.709s
[2K
| Adam | epoch: 001 | loss: 0.73035 - acc: 0.5114 -- iter: 0096/1750
[A[ATraining Step: 4  | total loss: [1m[32m0.94670[0m[0m | time: 286.949s
[2K
| Adam | epoch: 001 | loss: 0.94670 - acc: 0.6200 -- iter: 0128/1750
[A[ATraining Step: 5  | total loss: [1m[32m0.65132[0m[0m | time: 311.476s
[2K
| Adam | epoch: 001 | loss: 0.65132 - acc: 0.6235 -- iter: 0160/1750
[A[ATraining Step: 6  | total loss: [1m[32m0.63336[0m[0m | time: 368.654s
[2K
| Adam | epoch: 001 | loss: 0.63336 - acc: 0.6245 -- iter: 0192/1750
[A[ATraining Step: 7  | total loss: [1m[32m0.58172[0m[0m | time: 410.387s
[2K
| Adam | epoch: 001 | loss: 0.58172 - acc: 0.6810 -- iter: 0224/1750
[A[ATraining Step: 8  | total loss: [1m[32m0.62675[0m[0m | time: 476.447s
[2K
| Adam | epoch: 001 | loss: 0.62675 - acc: 0.6144 -- iter: 0256/1750
[A[ATraining Step: 9  | total loss: [1m[32m0.65805[0m[0m | time: 519.397s
[2K
| Adam | epoch: 001 | loss: 0.65805 - acc: 0.5869 -- iter: 0288/1750
[A[ATraining Step: 10  | total loss: [1m[32m0.62192[0m[0m | time: 529.262s
[2K
| Adam | epoch: 001 | loss: 0.62192 - acc: 0.6060 -- iter: 0320/1750
[A[ATraining Step: 11  | total loss: [1m[32m0.63273[0m[0m | time: 595.618s
[2K
| Adam | epoch: 001 | loss: 0.63273 - acc: 0.6742 -- iter: 0352/1750
[A[ATraining Step: 12  | total loss: [1m[32m0.57411[0m[0m | time: 632.675s
[2K
| Adam | epoch: 001 | loss: 0.57411 - acc: 0.7083 -- iter: 0384/1750
[A[ATraining Step: 13  | total loss: [1m[32m0.57609[0m[0m | time: 671.384s
[2K
| Adam | epoch: 001 | loss: 0.57609 - acc: 0.7262 -- iter: 0416/1750
[A[ATraining Step: 14  | total loss: [1m[32m0.59618[0m[0m | time: 689.832s
[2K
| Adam | epoch: 001 | loss: 0.59618 - acc: 0.6976 -- iter: 0448/1750
[A[ATraining Step: 15  | total loss: [1m[32m0.60301[0m[0m | time: 699.803s
[2K
| Adam | epoch: 001 | loss: 0.60301 - acc: 0.6814 -- iter: 0480/1750
[A[ATraining Step: 16  | total loss: [1m[32m0.60002[0m[0m | time: 711.067s
[2K
| Adam | epoch: 001 | loss: 0.60002 - acc: 0.6837 -- iter: 0512/1750
[A[ATraining Step: 17  | total loss: [1m[32m0.66439[0m[0m | time: 744.453s
[2K
| Adam | epoch: 001 | loss: 0.66439 - acc: 0.6513 -- iter: 0544/1750
[A[ATraining Step: 18  | total loss: [1m[32m0.60829[0m[0m | time: 768.384s
[2K
| Adam | epoch: 001 | loss: 0.60829 - acc: 0.6747 -- iter: 0576/1750
[A[ATraining Step: 19  | total loss: [1m[32m0.54520[0m[0m | time: 827.932s
[2K
| Adam | epoch: 001 | loss: 0.54520 - acc: 0.7206 -- iter: 0608/1750
[A[ATraining Step: 20  | total loss: [1m[32m0.53423[0m[0m | time: 837.980s
[2K
| Adam | epoch: 001 | loss: 0.53423 - acc: 0.7200 -- iter: 0640/1750
[A[ATraining Step: 21  | total loss: [1m[32m0.66572[0m[0m | time: 858.178s
[2K
| Adam | epoch: 001 | loss: 0.66572 - acc: 0.6517 -- iter: 0672/1750
[A[ATraining Step: 22  | total loss: [1m[32m0.68364[0m[0m | time: 878.639s
[2K
| Adam | epoch: 001 | loss: 0.68364 - acc: 0.6531 -- iter: 0704/1750
[A[ATraining Step: 23  | total loss: [1m[32m0.74610[0m[0m | time: 888.220s
[2K
| Adam | epoch: 001 | loss: 0.74610 - acc: 0.6449 -- iter: 0736/1750
[A[ATraining Step: 24  | total loss: [1m[32m0.72079[0m[0m | time: 898.128s
[2K
| Adam | epoch: 001 | loss: 0.72079 - acc: 0.6569 -- iter: 0768/1750
[A[ATraining Step: 25  | total loss: [1m[32m0.67918[0m[0m | time: 907.806s
[2K
| Adam | epoch: 001 | loss: 0.67918 - acc: 0.6652 -- iter: 0800/1750
[A[ATraining Step: 26  | total loss: [1m[32m0.63224[0m[0m | time: 917.817s
[2K
| Adam | epoch: 001 | loss: 0.63224 - acc: 0.6794 -- iter: 0832/1750
[A[ATraining Step: 27  | total loss: [1m[32m0.60690[0m[0m | time: 936.093s
[2K
| Adam | epoch: 001 | loss: 0.60690 - acc: 0.6895 -- iter: 0864/1750
[A[ATraining Step: 28  | total loss: [1m[32m0.62153[0m[0m | time: 968.423s
[2K
| Adam | epoch: 001 | loss: 0.62153 - acc: 0.6734 -- iter: 0896/1750
[A[ATraining Step: 29  | total loss: [1m[32m0.59474[0m[0m | time: 988.365s
[2K
| Adam | epoch: 001 | loss: 0.59474 - acc: 0.6920 -- iter: 0928/1750
[A[ATraining Step: 30  | total loss: [1m[32m0.57958[0m[0m | time: 998.073s
[2K
| Adam | epoch: 001 | loss: 0.57958 - acc: 0.6984 -- iter: 0960/1750
[A[ATraining Step: 31  | total loss: [1m[32m0.57768[0m[0m | time: 1008.492s
[2K
| Adam | epoch: 001 | loss: 0.57768 - acc: 0.6959 -- iter: 0992/1750
[A[ATraining Step: 32  | total loss: [1m[32m0.52347[0m[0m | time: 1029.140s
[2K
| Adam | epoch: 001 | loss: 0.52347 - acc: 0.7362 -- iter: 1024/1750
[A[ATraining Step: 33  | total loss: [1m[32m0.49934[0m[0m | time: 1039.045s
[2K
| Adam | epoch: 001 | loss: 0.49934 - acc: 0.7529 -- iter: 1056/1750
[A[ATraining Step: 34  | total loss: [1m[32m0.49004[0m[0m | time: 1049.137s
[2K
| Adam | epoch: 001 | loss: 0.49004 - acc: 0.7389 -- iter: 1088/1750
[A[ATraining Step: 35  | total loss: [1m[32m0.49983[0m[0m | time: 1074.059s
[2K
| Adam | epoch: 001 | loss: 0.49983 - acc: 0.7412 -- iter: 1120/1750
[A[ATraining Step: 36  | total loss: [1m[32m0.47771[0m[0m | time: 1085.634s
[2K
| Adam | epoch: 001 | loss: 0.47771 - acc: 0.7622 -- iter: 1152/1750
[A[ATraining Step: 37  | total loss: [1m[32m0.47843[0m[0m | time: 1096.650s
[2K
| Adam | epoch: 001 | loss: 0.47843 - acc: 0.7598 -- iter: 1184/1750
[A[ATraining Step: 38  | total loss: [1m[32m0.50682[0m[0m | time: 1121.697s
[2K
| Adam | epoch: 001 | loss: 0.50682 - acc: 0.7334 -- iter: 1216/1750
[A[ATraining Step: 39  | total loss: [1m[32m0.50974[0m[0m | time: 1136.703s
[2K
| Adam | epoch: 001 | loss: 0.50974 - acc: 0.7366 -- iter: 1248/1750
[A[ATraining Step: 40  | total loss: [1m[32m0.56005[0m[0m | time: 1145.775s
[2K
| Adam | epoch: 001 | loss: 0.56005 - acc: 0.7215 -- iter: 1280/1750
[A[ATraining Step: 41  | total loss: [1m[32m0.54993[0m[0m | time: 1154.596s
[2K
| Adam | epoch: 001 | loss: 0.54993 - acc: 0.7267 -- iter: 1312/1750
[A[ATraining Step: 42  | total loss: [1m[32m0.54817[0m[0m | time: 1163.708s
[2K
| Adam | epoch: 001 | loss: 0.54817 - acc: 0.7197 -- iter: 1344/1750
[A[ATraining Step: 43  | total loss: [1m[32m0.53922[0m[0m | time: 1172.394s
[2K
| Adam | epoch: 001 | loss: 0.53922 - acc: 0.7250 -- iter: 1376/1750
[A[ATraining Step: 44  | total loss: [1m[32m0.52395[0m[0m | time: 1185.130s
[2K
| Adam | epoch: 001 | loss: 0.52395 - acc: 0.7348 -- iter: 1408/1750
[A[ATraining Step: 45  | total loss: [1m[32m0.52670[0m[0m | time: 1193.949s
[2K
| Adam | epoch: 001 | loss: 0.52670 - acc: 0.7320 -- iter: 1440/1750
[A[ATraining Step: 46  | total loss: [1m[32m0.52098[0m[0m | time: 1202.872s
[2K
| Adam | epoch: 001 | loss: 0.52098 - acc: 0.7246 -- iter: 1472/1750
[A[ATraining Step: 47  | total loss: [1m[32m0.49954[0m[0m | time: 1211.607s
[2K
| Adam | epoch: 001 | loss: 0.49954 - acc: 0.7441 -- iter: 1504/1750
[A[ATraining Step: 48  | total loss: [1m[32m0.49985[0m[0m | time: 1220.527s
[2K
| Adam | epoch: 001 | loss: 0.49985 - acc: 0.7451 -- iter: 1536/1750
[A[ATraining Step: 49  | total loss: [1m[32m0.47491[0m[0m | time: 1231.741s
[2K
| Adam | epoch: 001 | loss: 0.47491 - acc: 0.7656 -- iter: 1568/1750
[A[ATraining Step: 50  | total loss: [1m[32m0.48052[0m[0m | time: 1240.709s
[2K
| Adam | epoch: 001 | loss: 0.48052 - acc: 0.7583 -- iter: 1600/1750
[A[ATraining Step: 51  | total loss: [1m[32m0.46482[0m[0m | time: 1249.541s
[2K
| Adam | epoch: 001 | loss: 0.46482 - acc: 0.7809 -- iter: 1632/1750
[A[ATraining Step: 52  | total loss: [1m[32m0.48188[0m[0m | time: 1258.463s
[2K
| Adam | epoch: 001 | loss: 0.48188 - acc: 0.7762 -- iter: 1664/1750
[A[ATraining Step: 53  | total loss: [1m[32m0.47555[0m[0m | time: 1267.849s
[2K
| Adam | epoch: 001 | loss: 0.47555 - acc: 0.7816 -- iter: 1696/1750
[A[ATraining Step: 54  | total loss: [1m[32m0.45508[0m[0m | time: 1276.670s
[2K
| Adam | epoch: 001 | loss: 0.45508 - acc: 0.7906 -- iter: 1728/1750
[A[ATraining Step: 55  | total loss: [1m[32m0.50051[0m[0m | time: 1319.042s
[2K
| Adam | epoch: 001 | loss: 0.50051 - acc: 0.7670 | val_loss: 0.85882 - val_acc: 0.5748 -- iter: 1750/1750
--
Training Step: 56  | total loss: [1m[32m0.48479[0m[0m | time: 7.304s
[2K
| Adam | epoch: 002 | loss: 0.48479 - acc: 0.7742 -- iter: 0032/1750
[A[ATraining Step: 57  | total loss: [1m[32m0.46080[0m[0m | time: 17.005s
[2K
| Adam | epoch: 002 | loss: 0.46080 - acc: 0.7928 -- iter: 0064/1750
[A[ATraining Step: 58  | total loss: [1m[32m0.44250[0m[0m | time: 26.254s
[2K
| Adam | epoch: 002 | loss: 0.44250 - acc: 0.7998 -- iter: 0096/1750
[A[ATraining Step: 59  | total loss: [1m[32m0.45285[0m[0m | time: 35.343s
[2K
| Adam | epoch: 002 | loss: 0.45285 - acc: 0.7889 -- iter: 0128/1750
[A[ATraining Step: 60  | total loss: [1m[32m0.43584[0m[0m | time: 44.409s
[2K
| Adam | epoch: 002 | loss: 0.43584 - acc: 0.7962 -- iter: 0160/1750
[A[ATraining Step: 61  | total loss: [1m[32m0.44884[0m[0m | time: 54.112s
[2K
| Adam | epoch: 002 | loss: 0.44884 - acc: 0.7861 -- iter: 0192/1750
[A[ATraining Step: 62  | total loss: [1m[32m0.46365[0m[0m | time: 67.958s
[2K
| Adam | epoch: 002 | loss: 0.46365 - acc: 0.7774 -- iter: 0224/1750
[A[ATraining Step: 63  | total loss: [1m[32m0.46730[0m[0m | time: 77.394s
[2K
| Adam | epoch: 002 | loss: 0.46730 - acc: 0.7779 -- iter: 0256/1750
[A[ATraining Step: 64  | total loss: [1m[32m0.49314[0m[0m | time: 87.249s
[2K
| Adam | epoch: 002 | loss: 0.49314 - acc: 0.7783 -- iter: 0288/1750
[A[ATraining Step: 65  | total loss: [1m[32m0.49657[0m[0m | time: 96.932s
[2K
| Adam | epoch: 002 | loss: 0.49657 - acc: 0.7748 -- iter: 0320/1750
[A[ATraining Step: 66  | total loss: [1m[32m0.48693[0m[0m | time: 106.221s
[2K
| Adam | epoch: 002 | loss: 0.48693 - acc: 0.7756 -- iter: 0352/1750
[A[ATraining Step: 67  | total loss: [1m[32m0.50420[0m[0m | time: 115.320s
[2K
| Adam | epoch: 002 | loss: 0.50420 - acc: 0.7763 -- iter: 0384/1750
[A[ATraining Step: 68  | total loss: [1m[32m0.51615[0m[0m | time: 124.763s
[2K
| Adam | epoch: 002 | loss: 0.51615 - acc: 0.7806 -- iter: 0416/1750
[A[ATraining Step: 69  | total loss: [1m[32m0.56003[0m[0m | time: 136.256s
[2K
| Adam | epoch: 002 | loss: 0.56003 - acc: 0.7551 -- iter: 0448/1750
[A[ATraining Step: 70  | total loss: [1m[32m0.54382[0m[0m | time: 145.608s
[2K
| Adam | epoch: 002 | loss: 0.54382 - acc: 0.7545 -- iter: 0480/1750
[A[ATraining Step: 71  | total loss: [1m[32m0.54753[0m[0m | time: 154.986s
[2K
| Adam | epoch: 002 | loss: 0.54753 - acc: 0.7504 -- iter: 0512/1750
[A[ATraining Step: 72  | total loss: [1m[32m0.52082[0m[0m | time: 164.097s
[2K
| Adam | epoch: 002 | loss: 0.52082 - acc: 0.7715 -- iter: 0544/1750
[A[ATraining Step: 73  | total loss: [1m[32m0.49745[0m[0m | time: 173.903s
[2K
| Adam | epoch: 002 | loss: 0.49745 - acc: 0.7830 -- iter: 0576/1750
[A[ATraining Step: 74  | total loss: [1m[32m0.47959[0m[0m | time: 183.794s
[2K
| Adam | epoch: 002 | loss: 0.47959 - acc: 0.7862 -- iter: 0608/1750
[A[ATraining Step: 75  | total loss: [1m[32m0.47556[0m[0m | time: 192.745s
[2K
| Adam | epoch: 002 | loss: 0.47556 - acc: 0.7857 -- iter: 0640/1750
[A[ATraining Step: 76  | total loss: [1m[32m0.47901[0m[0m | time: 203.441s
[2K
| Adam | epoch: 002 | loss: 0.47901 - acc: 0.7885 -- iter: 0672/1750
[A[ATraining Step: 77  | total loss: [1m[32m0.46914[0m[0m | time: 212.638s
[2K
| Adam | epoch: 002 | loss: 0.46914 - acc: 0.7911 -- iter: 0704/1750
[A[ATraining Step: 78  | total loss: [1m[32m0.46866[0m[0m | time: 221.832s
[2K
| Adam | epoch: 002 | loss: 0.46866 - acc: 0.7868 -- iter: 0736/1750
[A[ATraining Step: 79  | total loss: [1m[32m0.48819[0m[0m | time: 230.663s
[2K
| Adam | epoch: 002 | loss: 0.48819 - acc: 0.7700 -- iter: 0768/1750
[A[ATraining Step: 80  | total loss: [1m[32m0.51764[0m[0m | time: 248.619s
[2K
| Adam | epoch: 002 | loss: 0.51764 - acc: 0.7552 -- iter: 0800/1750
[A[ATraining Step: 81  | total loss: [1m[32m0.52663[0m[0m | time: 257.626s
[2K
| Adam | epoch: 002 | loss: 0.52663 - acc: 0.7484 -- iter: 0832/1750
[A[ATraining Step: 82  | total loss: [1m[32m0.51102[0m[0m | time: 267.078s
[2K
| Adam | epoch: 002 | loss: 0.51102 - acc: 0.7579 -- iter: 0864/1750
[A[ATraining Step: 83  | total loss: [1m[32m0.51472[0m[0m | time: 275.959s
[2K
| Adam | epoch: 002 | loss: 0.51472 - acc: 0.7540 -- iter: 0896/1750
[A[ATraining Step: 84  | total loss: [1m[32m0.50507[0m[0m | time: 285.148s
[2K
| Adam | epoch: 002 | loss: 0.50507 - acc: 0.7598 -- iter: 0928/1750
[A[ATraining Step: 85  | total loss: [1m[32m0.49101[0m[0m | time: 294.169s
[2K
| Adam | epoch: 002 | loss: 0.49101 - acc: 0.7714 -- iter: 0960/1750
[A[ATraining Step: 86  | total loss: [1m[32m0.46778[0m[0m | time: 303.318s
[2K
| Adam | epoch: 002 | loss: 0.46778 - acc: 0.7880 -- iter: 0992/1750
[A[ATraining Step: 87  | total loss: [1m[32m0.45410[0m[0m | time: 312.353s
[2K
| Adam | epoch: 002 | loss: 0.45410 - acc: 0.7935 -- iter: 1024/1750
[A[ATraining Step: 88  | total loss: [1m[32m0.43898[0m[0m | time: 321.145s
[2K
| Adam | epoch: 002 | loss: 0.43898 - acc: 0.8017 -- iter: 1056/1750
[A[ATraining Step: 89  | total loss: [1m[32m0.44250[0m[0m | time: 330.086s
[2K
| Adam | epoch: 002 | loss: 0.44250 - acc: 0.7996 -- iter: 1088/1750
[A[ATraining Step: 90  | total loss: [1m[32m0.44667[0m[0m | time: 340.036s
[2K
| Adam | epoch: 002 | loss: 0.44667 - acc: 0.8009 -- iter: 1120/1750
[A[ATraining Step: 91  | total loss: [1m[32m0.44515[0m[0m | time: 349.049s
[2K
| Adam | epoch: 002 | loss: 0.44515 - acc: 0.7958 -- iter: 1152/1750
[A[ATraining Step: 92  | total loss: [1m[32m0.46336[0m[0m | time: 357.922s
[2K
| Adam | epoch: 002 | loss: 0.46336 - acc: 0.7913 -- iter: 1184/1750
[A[ATraining Step: 93  | total loss: [1m[32m0.44602[0m[0m | time: 370.952s
[2K
| Adam | epoch: 002 | loss: 0.44602 - acc: 0.8059 -- iter: 1216/1750
[A[ATraining Step: 94  | total loss: [1m[32m0.41923[0m[0m | time: 380.404s
[2K
| Adam | epoch: 002 | loss: 0.41923 - acc: 0.8190 -- iter: 1248/1750
[A[ATraining Step: 95  | total loss: [1m[32m0.41138[0m[0m | time: 389.465s
[2K
| Adam | epoch: 002 | loss: 0.41138 - acc: 0.8215 -- iter: 1280/1750
[A[ATraining Step: 96  | total loss: [1m[32m0.43955[0m[0m | time: 398.822s
[2K
| Adam | epoch: 002 | loss: 0.43955 - acc: 0.8019 -- iter: 1312/1750
[A[ATraining Step: 97  | total loss: [1m[32m0.43226[0m[0m | time: 407.945s
[2K
| Adam | epoch: 002 | loss: 0.43226 - acc: 0.8061 -- iter: 1344/1750
[A[ATraining Step: 98  | total loss: [1m[32m0.42929[0m[0m | time: 416.891s
[2K
| Adam | epoch: 002 | loss: 0.42929 - acc: 0.8036 -- iter: 1376/1750
[A[ATraining Step: 99  | total loss: [1m[32m0.41817[0m[0m | time: 434.217s
[2K
| Adam | epoch: 002 | loss: 0.41817 - acc: 0.8076 -- iter: 1408/1750
[A[ATraining Step: 100  | total loss: [1m[32m0.41177[0m[0m | time: 443.088s
[2K
| Adam | epoch: 002 | loss: 0.41177 - acc: 0.8175 -- iter: 1440/1750
[A[ATraining Step: 101  | total loss: [1m[32m0.40176[0m[0m | time: 452.239s
[2K
| Adam | epoch: 002 | loss: 0.40176 - acc: 0.8232 -- iter: 1472/1750
[A[ATraining Step: 102  | total loss: [1m[32m0.39487[0m[0m | time: 461.177s
[2K
| Adam | epoch: 002 | loss: 0.39487 - acc: 0.8284 -- iter: 1504/1750
[A[ATraining Step: 103  | total loss: [1m[32m0.40035[0m[0m | time: 470.406s
[2K
| Adam | epoch: 002 | loss: 0.40035 - acc: 0.8299 -- iter: 1536/1750
[A[ATraining Step: 104  | total loss: [1m[32m0.39163[0m[0m | time: 479.371s
[2K
| Adam | epoch: 002 | loss: 0.39163 - acc: 0.8376 -- iter: 1568/1750
[A[ATraining Step: 105  | total loss: [1m[32m0.40185[0m[0m | time: 488.182s
[2K
| Adam | epoch: 002 | loss: 0.40185 - acc: 0.8351 -- iter: 1600/1750
[A[ATraining Step: 106  | total loss: [1m[32m0.38709[0m[0m | time: 497.383s
[2K
| Adam | epoch: 002 | loss: 0.38709 - acc: 0.8422 -- iter: 1632/1750
[A[ATraining Step: 107  | total loss: [1m[32m0.37789[0m[0m | time: 506.391s
[2K
| Adam | epoch: 002 | loss: 0.37789 - acc: 0.8486 -- iter: 1664/1750
[A[ATraining Step: 108  | total loss: [1m[32m0.38650[0m[0m | time: 515.438s
[2K
| Adam | epoch: 002 | loss: 0.38650 - acc: 0.8356 -- iter: 1696/1750
[A[ATraining Step: 109  | total loss: [1m[32m0.36861[0m[0m | time: 524.273s
[2K
| Adam | epoch: 002 | loss: 0.36861 - acc: 0.8427 -- iter: 1728/1750
[A[ATraining Step: 110  | total loss: [1m[32m0.38488[0m[0m | time: 560.456s
[2K
| Adam | epoch: 002 | loss: 0.38488 - acc: 0.8365 | val_loss: 0.87434 - val_acc: 0.6405 -- iter: 1750/1750
--
Training Step: 111  | total loss: [1m[32m0.39871[0m[0m | time: 6.525s
[2K
| Adam | epoch: 003 | loss: 0.39871 - acc: 0.8279 -- iter: 0032/1750
[A[ATraining Step: 112  | total loss: [1m[32m0.40109[0m[0m | time: 13.264s
[2K
| Adam | epoch: 003 | loss: 0.40109 - acc: 0.8269 -- iter: 0064/1750
[A[ATraining Step: 113  | total loss: [1m[32m0.39118[0m[0m | time: 21.881s
[2K
| Adam | epoch: 003 | loss: 0.39118 - acc: 0.8260 -- iter: 0096/1750
[A[ATraining Step: 114  | total loss: [1m[32m0.38419[0m[0m | time: 30.592s
[2K
| Adam | epoch: 003 | loss: 0.38419 - acc: 0.8309 -- iter: 0128/1750
[A[ATraining Step: 115  | total loss: [1m[32m0.38498[0m[0m | time: 41.424s
[2K
| Adam | epoch: 003 | loss: 0.38498 - acc: 0.8291 -- iter: 0160/1750
[A[ATraining Step: 116  | total loss: [1m[32m0.37835[0m[0m | time: 50.302s
[2K
| Adam | epoch: 003 | loss: 0.37835 - acc: 0.8305 -- iter: 0192/1750
[A[ATraining Step: 117  | total loss: [1m[32m0.36798[0m[0m | time: 59.060s
[2K
| Adam | epoch: 003 | loss: 0.36798 - acc: 0.8350 -- iter: 0224/1750
[A[ATraining Step: 118  | total loss: [1m[32m0.36121[0m[0m | time: 67.967s
[2K
| Adam | epoch: 003 | loss: 0.36121 - acc: 0.8359 -- iter: 0256/1750
[A[ATraining Step: 119  | total loss: [1m[32m0.35852[0m[0m | time: 76.685s
[2K
| Adam | epoch: 003 | loss: 0.35852 - acc: 0.8398 -- iter: 0288/1750
[A[ATraining Step: 120  | total loss: [1m[32m0.35930[0m[0m | time: 91.269s
[2K
| Adam | epoch: 003 | loss: 0.35930 - acc: 0.8402 -- iter: 0320/1750
[A[ATraining Step: 121  | total loss: [1m[32m0.37345[0m[0m | time: 100.443s
[2K
| Adam | epoch: 003 | loss: 0.37345 - acc: 0.8343 -- iter: 0352/1750
[A[ATraining Step: 122  | total loss: [1m[32m0.36263[0m[0m | time: 109.517s
[2K
| Adam | epoch: 003 | loss: 0.36263 - acc: 0.8446 -- iter: 0384/1750
[A[ATraining Step: 123  | total loss: [1m[32m0.37920[0m[0m | time: 119.200s
[2K
| Adam | epoch: 003 | loss: 0.37920 - acc: 0.8383 -- iter: 0416/1750
[A[ATraining Step: 124  | total loss: [1m[32m0.37614[0m[0m | time: 127.877s
[2K
| Adam | epoch: 003 | loss: 0.37614 - acc: 0.8419 -- iter: 0448/1750
[A[ATraining Step: 125  | total loss: [1m[32m0.38401[0m[0m | time: 136.952s
[2K
| Adam | epoch: 003 | loss: 0.38401 - acc: 0.8421 -- iter: 0480/1750
[A[ATraining Step: 126  | total loss: [1m[32m0.38471[0m[0m | time: 145.428s
[2K
| Adam | epoch: 003 | loss: 0.38471 - acc: 0.8423 -- iter: 0512/1750
[A[ATraining Step: 127  | total loss: [1m[32m0.38758[0m[0m | time: 154.601s
[2K
| Adam | epoch: 003 | loss: 0.38758 - acc: 0.8362 -- iter: 0544/1750
[A[ATraining Step: 128  | total loss: [1m[32m0.39389[0m[0m | time: 163.303s
[2K
| Adam | epoch: 003 | loss: 0.39389 - acc: 0.8369 -- iter: 0576/1750
[A[ATraining Step: 129  | total loss: [1m[32m0.40346[0m[0m | time: 174.219s
[2K
| Adam | epoch: 003 | loss: 0.40346 - acc: 0.8282 -- iter: 0608/1750
[A[ATraining Step: 130  | total loss: [1m[32m0.38740[0m[0m | time: 182.977s
[2K
| Adam | epoch: 003 | loss: 0.38740 - acc: 0.8392 -- iter: 0640/1750
[A[ATraining Step: 131  | total loss: [1m[32m0.37293[0m[0m | time: 191.730s
[2K
| Adam | epoch: 003 | loss: 0.37293 - acc: 0.8459 -- iter: 0672/1750
[A[ATraining Step: 132  | total loss: [1m[32m0.36772[0m[0m | time: 200.349s
[2K
| Adam | epoch: 003 | loss: 0.36772 - acc: 0.8488 -- iter: 0704/1750
[A[ATraining Step: 133  | total loss: [1m[32m0.37653[0m[0m | time: 209.215s
[2K
| Adam | epoch: 003 | loss: 0.37653 - acc: 0.8483 -- iter: 0736/1750
[A[ATraining Step: 134  | total loss: [1m[32m0.38151[0m[0m | time: 217.943s
[2K
| Adam | epoch: 003 | loss: 0.38151 - acc: 0.8353 -- iter: 0768/1750
[A[ATraining Step: 135  | total loss: [1m[32m0.36658[0m[0m | time: 226.503s
[2K
| Adam | epoch: 003 | loss: 0.36658 - acc: 0.8487 -- iter: 0800/1750
[A[ATraining Step: 136  | total loss: [1m[32m0.35135[0m[0m | time: 235.365s
[2K
| Adam | epoch: 003 | loss: 0.35135 - acc: 0.8576 -- iter: 0832/1750
[A[ATraining Step: 137  | total loss: [1m[32m0.34973[0m[0m | time: 244.060s
[2K
| Adam | epoch: 003 | loss: 0.34973 - acc: 0.8531 -- iter: 0864/1750
[A[ATraining Step: 138  | total loss: [1m[32m0.34456[0m[0m | time: 252.724s
[2K
| Adam | epoch: 003 | loss: 0.34456 - acc: 0.8490 -- iter: 0896/1750
[A[ATraining Step: 139  | total loss: [1m[32m0.33563[0m[0m | time: 261.498s
[2K
| Adam | epoch: 003 | loss: 0.33563 - acc: 0.8547 -- iter: 0928/1750
[A[ATraining Step: 140  | total loss: [1m[32m0.33881[0m[0m | time: 270.152s
[2K
| Adam | epoch: 003 | loss: 0.33881 - acc: 0.8505 -- iter: 0960/1750
[A[ATraining Step: 141  | total loss: [1m[32m0.33727[0m[0m | time: 279.117s
[2K
| Adam | epoch: 003 | loss: 0.33727 - acc: 0.8530 -- iter: 0992/1750
[A[ATraining Step: 142  | total loss: [1m[32m0.32964[0m[0m | time: 287.772s
[2K
| Adam | epoch: 003 | loss: 0.32964 - acc: 0.8614 -- iter: 1024/1750
[A[ATraining Step: 143  | total loss: [1m[32m0.31762[0m[0m | time: 296.613s
[2K
| Adam | epoch: 003 | loss: 0.31762 - acc: 0.8659 -- iter: 1056/1750
[A[ATraining Step: 144  | total loss: [1m[32m0.31346[0m[0m | time: 305.404s
[2K
| Adam | epoch: 003 | loss: 0.31346 - acc: 0.8637 -- iter: 1088/1750
[A[ATraining Step: 145  | total loss: [1m[32m0.31723[0m[0m | time: 314.293s
[2K
| Adam | epoch: 003 | loss: 0.31723 - acc: 0.8586 -- iter: 1120/1750
[A[ATraining Step: 146  | total loss: [1m[32m0.31796[0m[0m | time: 323.217s
[2K
| Adam | epoch: 003 | loss: 0.31796 - acc: 0.8571 -- iter: 1152/1750
[A[ATraining Step: 147  | total loss: [1m[32m0.32244[0m[0m | time: 332.064s
[2K
| Adam | epoch: 003 | loss: 0.32244 - acc: 0.8557 -- iter: 1184/1750
[A[ATraining Step: 148  | total loss: [1m[32m0.33478[0m[0m | time: 340.960s
[2K
| Adam | epoch: 003 | loss: 0.33478 - acc: 0.8483 -- iter: 1216/1750
[A[ATraining Step: 149  | total loss: [1m[32m0.33289[0m[0m | time: 349.511s
[2K
| Adam | epoch: 003 | loss: 0.33289 - acc: 0.8416 -- iter: 1248/1750
[A[ATraining Step: 150  | total loss: [1m[32m0.32023[0m[0m | time: 358.108s
[2K
| Adam | epoch: 003 | loss: 0.32023 - acc: 0.8512 -- iter: 1280/1750
[A[ATraining Step: 151  | total loss: [1m[32m0.31078[0m[0m | time: 366.984s
[2K
| Adam | epoch: 003 | loss: 0.31078 - acc: 0.8598 -- iter: 1312/1750
[A[ATraining Step: 152  | total loss: [1m[32m0.34846[0m[0m | time: 375.794s
[2K
| Adam | epoch: 003 | loss: 0.34846 - acc: 0.8457 -- iter: 1344/1750
[A[ATraining Step: 153  | total loss: [1m[32m0.33120[0m[0m | time: 384.359s
[2K
| Adam | epoch: 003 | loss: 0.33120 - acc: 0.8549 -- iter: 1376/1750
[A[ATraining Step: 154  | total loss: [1m[32m0.31756[0m[0m | time: 393.100s
[2K
| Adam | epoch: 003 | loss: 0.31756 - acc: 0.8600 -- iter: 1408/1750
[A[ATraining Step: 155  | total loss: [1m[32m0.31425[0m[0m | time: 401.845s
[2K
| Adam | epoch: 003 | loss: 0.31425 - acc: 0.8615 -- iter: 1440/1750
[A[ATraining Step: 156  | total loss: [1m[32m0.31000[0m[0m | time: 410.406s
[2K
| Adam | epoch: 003 | loss: 0.31000 - acc: 0.8629 -- iter: 1472/1750
[A[ATraining Step: 157  | total loss: [1m[32m0.31101[0m[0m | time: 419.099s
[2K
| Adam | epoch: 003 | loss: 0.31101 - acc: 0.8610 -- iter: 1504/1750
[A[ATraining Step: 158  | total loss: [1m[32m0.31491[0m[0m | time: 427.888s
[2K
| Adam | epoch: 003 | loss: 0.31491 - acc: 0.8592 -- iter: 1536/1750
[A[ATraining Step: 159  | total loss: [1m[32m0.31565[0m[0m | time: 436.817s
[2K
| Adam | epoch: 003 | loss: 0.31565 - acc: 0.8608 -- iter: 1568/1750
[A[ATraining Step: 160  | total loss: [1m[32m0.31388[0m[0m | time: 445.757s
[2K
| Adam | epoch: 003 | loss: 0.31388 - acc: 0.8560 -- iter: 1600/1750
[A[ATraining Step: 161  | total loss: [1m[32m0.32538[0m[0m | time: 454.420s
[2K
| Adam | epoch: 003 | loss: 0.32538 - acc: 0.8579 -- iter: 1632/1750
[A[ATraining Step: 162  | total loss: [1m[32m0.32292[0m[0m | time: 462.963s
[2K
| Adam | epoch: 003 | loss: 0.32292 - acc: 0.8565 -- iter: 1664/1750
[A[ATraining Step: 163  | total loss: [1m[32m0.30271[0m[0m | time: 471.516s
[2K
| Adam | epoch: 003 | loss: 0.30271 - acc: 0.8708 -- iter: 1696/1750
[A[ATraining Step: 164  | total loss: [1m[32m0.30696[0m[0m | time: 480.348s
[2K
| Adam | epoch: 003 | loss: 0.30696 - acc: 0.8712 -- iter: 1728/1750
[A[ATraining Step: 165  | total loss: [1m[32m0.30719[0m[0m | time: 514.125s
[2K
| Adam | epoch: 003 | loss: 0.30719 - acc: 0.8747 | val_loss: 3.85307 - val_acc: 0.5018 -- iter: 1750/1750
--
Training Step: 166  | total loss: [1m[32m0.33731[0m[0m | time: 9.124s
[2K
| Adam | epoch: 004 | loss: 0.33731 - acc: 0.8591 -- iter: 0032/1750
[A[ATraining Step: 167  | total loss: [1m[32m0.34793[0m[0m | time: 15.630s
[2K
| Adam | epoch: 004 | loss: 0.34793 - acc: 0.8545 -- iter: 0064/1750
[A[ATraining Step: 168  | total loss: [1m[32m0.36697[0m[0m | time: 21.999s
[2K
| Adam | epoch: 004 | loss: 0.36697 - acc: 0.8418 -- iter: 0096/1750
[A[ATraining Step: 169  | total loss: [1m[32m0.36343[0m[0m | time: 30.688s
[2K
| Adam | epoch: 004 | loss: 0.36343 - acc: 0.8485 -- iter: 0128/1750
[A[ATraining Step: 170  | total loss: [1m[32m0.37796[0m[0m | time: 39.608s
[2K
| Adam | epoch: 004 | loss: 0.37796 - acc: 0.8449 -- iter: 0160/1750
[A[ATraining Step: 171  | total loss: [1m[32m0.36870[0m[0m | time: 49.473s
[2K
| Adam | epoch: 004 | loss: 0.36870 - acc: 0.8479 -- iter: 0192/1750
[A[ATraining Step: 172  | total loss: [1m[32m0.36873[0m[0m | time: 58.277s
[2K
| Adam | epoch: 004 | loss: 0.36873 - acc: 0.8444 -- iter: 0224/1750
[A[ATraining Step: 173  | total loss: [1m[32m0.37984[0m[0m | time: 69.040s
[2K
| Adam | epoch: 004 | loss: 0.37984 - acc: 0.8318 -- iter: 0256/1750
[A[ATraining Step: 174  | total loss: [1m[32m0.37337[0m[0m | time: 78.269s
[2K
| Adam | epoch: 004 | loss: 0.37337 - acc: 0.8330 -- iter: 0288/1750
[A[ATraining Step: 175  | total loss: [1m[32m0.37086[0m[0m | time: 87.417s
[2K
| Adam | epoch: 004 | loss: 0.37086 - acc: 0.8372 -- iter: 0320/1750
[A[ATraining Step: 176  | total loss: [1m[32m0.35321[0m[0m | time: 101.791s
[2K
| Adam | epoch: 004 | loss: 0.35321 - acc: 0.8472 -- iter: 0352/1750
[A[ATraining Step: 177  | total loss: [1m[32m0.34658[0m[0m | time: 110.396s
[2K
| Adam | epoch: 004 | loss: 0.34658 - acc: 0.8500 -- iter: 0384/1750
[A[ATraining Step: 178  | total loss: [1m[32m0.35081[0m[0m | time: 119.204s
[2K
| Adam | epoch: 004 | loss: 0.35081 - acc: 0.8556 -- iter: 0416/1750
[A[ATraining Step: 179  | total loss: [1m[32m0.36577[0m[0m | time: 127.949s
[2K
| Adam | epoch: 004 | loss: 0.36577 - acc: 0.8419 -- iter: 0448/1750
[A[ATraining Step: 180  | total loss: [1m[32m0.35004[0m[0m | time: 136.675s
[2K
| Adam | epoch: 004 | loss: 0.35004 - acc: 0.8515 -- iter: 0480/1750
[A[ATraining Step: 181  | total loss: [1m[32m0.34632[0m[0m | time: 145.334s
[2K
| Adam | epoch: 004 | loss: 0.34632 - acc: 0.8538 -- iter: 0512/1750
[A[ATraining Step: 182  | total loss: [1m[32m0.33640[0m[0m | time: 154.259s
[2K
| Adam | epoch: 004 | loss: 0.33640 - acc: 0.8591 -- iter: 0544/1750
[A[ATraining Step: 183  | total loss: [1m[32m0.33147[0m[0m | time: 163.003s
[2K
| Adam | epoch: 004 | loss: 0.33147 - acc: 0.8607 -- iter: 0576/1750
[A[ATraining Step: 184  | total loss: [1m[32m0.33494[0m[0m | time: 180.133s
[2K
| Adam | epoch: 004 | loss: 0.33494 - acc: 0.8527 -- iter: 0608/1750
[A[ATraining Step: 185  | total loss: [1m[32m0.33563[0m[0m | time: 188.845s
[2K
| Adam | epoch: 004 | loss: 0.33563 - acc: 0.8518 -- iter: 0640/1750
[A[ATraining Step: 186  | total loss: [1m[32m0.33373[0m[0m | time: 197.567s
[2K
| Adam | epoch: 004 | loss: 0.33373 - acc: 0.8542 -- iter: 0672/1750
[A[ATraining Step: 187  | total loss: [1m[32m0.33438[0m[0m | time: 206.267s
[2K
| Adam | epoch: 004 | loss: 0.33438 - acc: 0.8531 -- iter: 0704/1750
[A[ATraining Step: 188  | total loss: [1m[32m0.34572[0m[0m | time: 214.626s
[2K
| Adam | epoch: 004 | loss: 0.34572 - acc: 0.8522 -- iter: 0736/1750
[A[ATraining Step: 189  | total loss: [1m[32m0.33730[0m[0m | time: 223.384s
[2K
| Adam | epoch: 004 | loss: 0.33730 - acc: 0.8576 -- iter: 0768/1750
[A[ATraining Step: 190  | total loss: [1m[32m0.33162[0m[0m | time: 231.759s
[2K
| Adam | epoch: 004 | loss: 0.33162 - acc: 0.8593 -- iter: 0800/1750
[A[ATraining Step: 191  | total loss: [1m[32m0.34055[0m[0m | time: 240.624s
[2K
| Adam | epoch: 004 | loss: 0.34055 - acc: 0.8484 -- iter: 0832/1750
[A[ATraining Step: 192  | total loss: [1m[32m0.38679[0m[0m | time: 249.217s
[2K
| Adam | epoch: 004 | loss: 0.38679 - acc: 0.8354 -- iter: 0864/1750
[A[ATraining Step: 193  | total loss: [1m[32m0.36457[0m[0m | time: 257.855s
[2K
| Adam | epoch: 004 | loss: 0.36457 - acc: 0.8488 -- iter: 0896/1750
[A[ATraining Step: 194  | total loss: [1m[32m0.34946[0m[0m | time: 267.169s
[2K
| Adam | epoch: 004 | loss: 0.34946 - acc: 0.8576 -- iter: 0928/1750
[A[ATraining Step: 195  | total loss: [1m[32m0.33613[0m[0m | time: 275.781s
[2K
| Adam | epoch: 004 | loss: 0.33613 - acc: 0.8625 -- iter: 0960/1750
[A[ATraining Step: 196  | total loss: [1m[32m0.33433[0m[0m | time: 284.539s
[2K
| Adam | epoch: 004 | loss: 0.33433 - acc: 0.8669 -- iter: 0992/1750
[A[ATraining Step: 197  | total loss: [1m[32m0.34600[0m[0m | time: 293.236s
[2K
| Adam | epoch: 004 | loss: 0.34600 - acc: 0.8583 -- iter: 1024/1750
[A[ATraining Step: 198  | total loss: [1m[32m0.34684[0m[0m | time: 302.042s
[2K
| Adam | epoch: 004 | loss: 0.34684 - acc: 0.8537 -- iter: 1056/1750
[A[ATraining Step: 199  | total loss: [1m[32m0.33636[0m[0m | time: 311.025s
[2K
| Adam | epoch: 004 | loss: 0.33636 - acc: 0.8590 -- iter: 1088/1750
[A[ATraining Step: 200  | total loss: [1m[32m0.33877[0m[0m | time: 344.988s
[2K
| Adam | epoch: 004 | loss: 0.33877 - acc: 0.8575 | val_loss: 0.41444 - val_acc: 0.8084 -- iter: 1120/1750
--
Training Step: 201  | total loss: [1m[32m0.32392[0m[0m | time: 353.874s
[2K
| Adam | epoch: 004 | loss: 0.32392 - acc: 0.8686 -- iter: 1152/1750
[A[ATraining Step: 202  | total loss: [1m[32m0.31585[0m[0m | time: 362.503s
[2K
| Adam | epoch: 004 | loss: 0.31585 - acc: 0.8755 -- iter: 1184/1750
[A[ATraining Step: 203  | total loss: [1m[32m0.31816[0m[0m | time: 371.149s
[2K
| Adam | epoch: 004 | loss: 0.31816 - acc: 0.8692 -- iter: 1216/1750
[A[ATraining Step: 204  | total loss: [1m[32m0.32325[0m[0m | time: 379.864s
[2K
| Adam | epoch: 004 | loss: 0.32325 - acc: 0.8635 -- iter: 1248/1750
[A[ATraining Step: 205  | total loss: [1m[32m0.32793[0m[0m | time: 388.592s
[2K
| Adam | epoch: 004 | loss: 0.32793 - acc: 0.8647 -- iter: 1280/1750
[A[ATraining Step: 206  | total loss: [1m[32m0.30235[0m[0m | time: 397.332s
[2K
| Adam | epoch: 004 | loss: 0.30235 - acc: 0.8782 -- iter: 1312/1750
[A[ATraining Step: 207  | total loss: [1m[32m0.30443[0m[0m | time: 406.606s
[2K
| Adam | epoch: 004 | loss: 0.30443 - acc: 0.8748 -- iter: 1344/1750
[A[ATraining Step: 208  | total loss: [1m[32m0.29605[0m[0m | time: 415.255s
[2K
| Adam | epoch: 004 | loss: 0.29605 - acc: 0.8779 -- iter: 1376/1750
[A[ATraining Step: 209  | total loss: [1m[32m0.28870[0m[0m | time: 423.809s
[2K
| Adam | epoch: 004 | loss: 0.28870 - acc: 0.8776 -- iter: 1408/1750
[A[ATraining Step: 210  | total loss: [1m[32m0.29613[0m[0m | time: 432.748s
[2K
| Adam | epoch: 004 | loss: 0.29613 - acc: 0.8773 -- iter: 1440/1750
[A[ATraining Step: 211  | total loss: [1m[32m0.28620[0m[0m | time: 441.469s
[2K
| Adam | epoch: 004 | loss: 0.28620 - acc: 0.8771 -- iter: 1472/1750
[A[ATraining Step: 212  | total loss: [1m[32m0.27160[0m[0m | time: 450.247s
[2K
| Adam | epoch: 004 | loss: 0.27160 - acc: 0.8832 -- iter: 1504/1750
[A[ATraining Step: 213  | total loss: [1m[32m0.27040[0m[0m | time: 458.733s
[2K
| Adam | epoch: 004 | loss: 0.27040 - acc: 0.8823 -- iter: 1536/1750
[A[ATraining Step: 214  | total loss: [1m[32m0.26717[0m[0m | time: 467.340s
[2K
| Adam | epoch: 004 | loss: 0.26717 - acc: 0.8847 -- iter: 1568/1750
[A[ATraining Step: 215  | total loss: [1m[32m0.28551[0m[0m | time: 476.162s
[2K
| Adam | epoch: 004 | loss: 0.28551 - acc: 0.8775 -- iter: 1600/1750
[A[ATraining Step: 216  | total loss: [1m[32m0.30582[0m[0m | time: 484.841s
[2K
| Adam | epoch: 004 | loss: 0.30582 - acc: 0.8710 -- iter: 1632/1750
[A[ATraining Step: 217  | total loss: [1m[32m0.30615[0m[0m | time: 493.419s
[2K
| Adam | epoch: 004 | loss: 0.30615 - acc: 0.8714 -- iter: 1664/1750
[A[ATraining Step: 218  | total loss: [1m[32m0.31571[0m[0m | time: 502.054s
[2K
| Adam | epoch: 004 | loss: 0.31571 - acc: 0.8686 -- iter: 1696/1750
[A[ATraining Step: 219  | total loss: [1m[32m0.31186[0m[0m | time: 510.850s
[2K
| Adam | epoch: 004 | loss: 0.31186 - acc: 0.8724 -- iter: 1728/1750
[A[ATraining Step: 220  | total loss: [1m[32m0.30155[0m[0m | time: 544.758s
[2K
| Adam | epoch: 004 | loss: 0.30155 - acc: 0.8789 | val_loss: 0.37722 - val_acc: 0.8504 -- iter: 1750/1750
--
Training Step: 221  | total loss: [1m[32m0.30263[0m[0m | time: 8.785s
[2K
| Adam | epoch: 005 | loss: 0.30263 - acc: 0.8723 -- iter: 0032/1750
[A[ATraining Step: 222  | total loss: [1m[32m0.29351[0m[0m | time: 17.592s
[2K
| Adam | epoch: 005 | loss: 0.29351 - acc: 0.8757 -- iter: 0064/1750
[A[ATraining Step: 223  | total loss: [1m[32m0.30683[0m[0m | time: 24.261s
[2K
| Adam | epoch: 005 | loss: 0.30683 - acc: 0.8725 -- iter: 0096/1750
[A[ATraining Step: 224  | total loss: [1m[32m0.30606[0m[0m | time: 30.598s
[2K
| Adam | epoch: 005 | loss: 0.30606 - acc: 0.8761 -- iter: 0128/1750
[A[ATraining Step: 225  | total loss: [1m[32m0.29234[0m[0m | time: 39.247s
[2K
| Adam | epoch: 005 | loss: 0.29234 - acc: 0.8794 -- iter: 0160/1750
[A[ATraining Step: 226  | total loss: [1m[32m0.28130[0m[0m | time: 47.854s
[2K
| Adam | epoch: 005 | loss: 0.28130 - acc: 0.8821 -- iter: 0192/1750
[A[ATraining Step: 227  | total loss: [1m[32m0.29520[0m[0m | time: 56.813s
[2K
| Adam | epoch: 005 | loss: 0.29520 - acc: 0.8752 -- iter: 0224/1750
[A[ATraining Step: 228  | total loss: [1m[32m0.28102[0m[0m | time: 65.634s
[2K
| Adam | epoch: 005 | loss: 0.28102 - acc: 0.8814 -- iter: 0256/1750
[A[ATraining Step: 229  | total loss: [1m[32m0.29657[0m[0m | time: 74.317s
[2K
| Adam | epoch: 005 | loss: 0.29657 - acc: 0.8682 -- iter: 0288/1750
[A[ATraining Step: 230  | total loss: [1m[32m0.30313[0m[0m | time: 83.051s
[2K
| Adam | epoch: 005 | loss: 0.30313 - acc: 0.8627 -- iter: 0320/1750
[A[ATraining Step: 231  | total loss: [1m[32m0.29349[0m[0m | time: 91.824s
[2K
| Adam | epoch: 005 | loss: 0.29349 - acc: 0.8639 -- iter: 0352/1750
[A[ATraining Step: 232  | total loss: [1m[32m0.29626[0m[0m | time: 100.505s
[2K
| Adam | epoch: 005 | loss: 0.29626 - acc: 0.8619 -- iter: 0384/1750
[A[ATraining Step: 233  | total loss: [1m[32m0.28899[0m[0m | time: 109.298s
[2K
| Adam | epoch: 005 | loss: 0.28899 - acc: 0.8632 -- iter: 0416/1750
[A[ATraining Step: 234  | total loss: [1m[32m0.28416[0m[0m | time: 118.303s
[2K
| Adam | epoch: 005 | loss: 0.28416 - acc: 0.8675 -- iter: 0448/1750
[A[ATraining Step: 235  | total loss: [1m[32m0.27415[0m[0m | time: 127.230s
[2K
| Adam | epoch: 005 | loss: 0.27415 - acc: 0.8745 -- iter: 0480/1750
[A[ATraining Step: 236  | total loss: [1m[32m0.27305[0m[0m | time: 136.487s
[2K
| Adam | epoch: 005 | loss: 0.27305 - acc: 0.8746 -- iter: 0512/1750
[A[ATraining Step: 237  | total loss: [1m[32m0.26500[0m[0m | time: 145.186s
[2K
| Adam | epoch: 005 | loss: 0.26500 - acc: 0.8746 -- iter: 0544/1750
[A[ATraining Step: 238  | total loss: [1m[32m0.26052[0m[0m | time: 153.870s
[2K
| Adam | epoch: 005 | loss: 0.26052 - acc: 0.8778 -- iter: 0576/1750
[A[ATraining Step: 239  | total loss: [1m[32m0.24754[0m[0m | time: 162.605s
[2K
| Adam | epoch: 005 | loss: 0.24754 - acc: 0.8837 -- iter: 0608/1750
[A[ATraining Step: 240  | total loss: [1m[32m0.27201[0m[0m | time: 171.573s
[2K
| Adam | epoch: 005 | loss: 0.27201 - acc: 0.8704 -- iter: 0640/1750
[A[ATraining Step: 241  | total loss: [1m[32m0.26338[0m[0m | time: 180.259s
[2K
| Adam | epoch: 005 | loss: 0.26338 - acc: 0.8771 -- iter: 0672/1750
[A[ATraining Step: 242  | total loss: [1m[32m0.25685[0m[0m | time: 188.814s
[2K
| Adam | epoch: 005 | loss: 0.25685 - acc: 0.8800 -- iter: 0704/1750
[A[ATraining Step: 243  | total loss: [1m[32m0.26048[0m[0m | time: 197.367s
[2K
| Adam | epoch: 005 | loss: 0.26048 - acc: 0.8826 -- iter: 0736/1750
[A[ATraining Step: 244  | total loss: [1m[32m0.27258[0m[0m | time: 206.122s
[2K
| Adam | epoch: 005 | loss: 0.27258 - acc: 0.8850 -- iter: 0768/1750
[A[ATraining Step: 245  | total loss: [1m[32m0.28882[0m[0m | time: 214.980s
[2K
| Adam | epoch: 005 | loss: 0.28882 - acc: 0.8809 -- iter: 0800/1750
[A[ATraining Step: 246  | total loss: [1m[32m0.28354[0m[0m | time: 223.742s
[2K
| Adam | epoch: 005 | loss: 0.28354 - acc: 0.8834 -- iter: 0832/1750
[A[ATraining Step: 247  | total loss: [1m[32m0.26316[0m[0m | time: 232.382s
[2K
| Adam | epoch: 005 | loss: 0.26316 - acc: 0.8919 -- iter: 0864/1750
[A[ATraining Step: 248  | total loss: [1m[32m0.27183[0m[0m | time: 241.057s
[2K
| Adam | epoch: 005 | loss: 0.27183 - acc: 0.8871 -- iter: 0896/1750
[A[ATraining Step: 249  | total loss: [1m[32m0.25715[0m[0m | time: 249.594s
[2K
| Adam | epoch: 005 | loss: 0.25715 - acc: 0.8953 -- iter: 0928/1750
[A[ATraining Step: 250  | total loss: [1m[32m0.24817[0m[0m | time: 258.586s
[2K
| Adam | epoch: 005 | loss: 0.24817 - acc: 0.8964 -- iter: 0960/1750
[A[ATraining Step: 251  | total loss: [1m[32m0.24915[0m[0m | time: 267.291s
[2K
| Adam | epoch: 005 | loss: 0.24915 - acc: 0.8942 -- iter: 0992/1750
[A[ATraining Step: 252  | total loss: [1m[32m0.24709[0m[0m | time: 276.050s
[2K
| Adam | epoch: 005 | loss: 0.24709 - acc: 0.8986 -- iter: 1024/1750
[A[ATraining Step: 253  | total loss: [1m[32m0.24169[0m[0m | time: 284.563s
[2K
| Adam | epoch: 005 | loss: 0.24169 - acc: 0.8993 -- iter: 1056/1750
[A[ATraining Step: 254  | total loss: [1m[32m0.23990[0m[0m | time: 293.234s
[2K
| Adam | epoch: 005 | loss: 0.23990 - acc: 0.9000 -- iter: 1088/1750
[A[ATraining Step: 255  | total loss: [1m[32m0.22459[0m[0m | time: 301.939s
[2K
| Adam | epoch: 005 | loss: 0.22459 - acc: 0.9100 -- iter: 1120/1750
[A[ATraining Step: 256  | total loss: [1m[32m0.22854[0m[0m | time: 310.639s
[2K
| Adam | epoch: 005 | loss: 0.22854 - acc: 0.9034 -- iter: 1152/1750
[A[ATraining Step: 257  | total loss: [1m[32m0.22528[0m[0m | time: 319.632s
[2K
| Adam | epoch: 005 | loss: 0.22528 - acc: 0.9068 -- iter: 1184/1750
[A[ATraining Step: 258  | total loss: [1m[32m0.21932[0m[0m | time: 328.282s
[2K
| Adam | epoch: 005 | loss: 0.21932 - acc: 0.9099 -- iter: 1216/1750
[A[ATraining Step: 259  | total loss: [1m[32m0.22731[0m[0m | time: 337.186s
[2K
| Adam | epoch: 005 | loss: 0.22731 - acc: 0.9033 -- iter: 1248/1750
[A[ATraining Step: 260  | total loss: [1m[32m0.22640[0m[0m | time: 345.920s
[2K
| Adam | epoch: 005 | loss: 0.22640 - acc: 0.9036 -- iter: 1280/1750
[A[ATraining Step: 261  | total loss: [1m[32m0.21111[0m[0m | time: 354.582s
[2K
| Adam | epoch: 005 | loss: 0.21111 - acc: 0.9132 -- iter: 1312/1750
[A[ATraining Step: 262  | total loss: [1m[32m0.21914[0m[0m | time: 363.259s
[2K
| Adam | epoch: 005 | loss: 0.21914 - acc: 0.9063 -- iter: 1344/1750
[A[ATraining Step: 263  | total loss: [1m[32m0.21732[0m[0m | time: 372.053s
[2K
| Adam | epoch: 005 | loss: 0.21732 - acc: 0.9031 -- iter: 1376/1750
[A[ATraining Step: 264  | total loss: [1m[32m0.21473[0m[0m | time: 380.681s
[2K
| Adam | epoch: 005 | loss: 0.21473 - acc: 0.9034 -- iter: 1408/1750
[A[ATraining Step: 265  | total loss: [1m[32m0.21160[0m[0m | time: 389.430s
[2K
| Adam | epoch: 005 | loss: 0.21160 - acc: 0.9037 -- iter: 1440/1750
[A[ATraining Step: 266  | total loss: [1m[32m0.21369[0m[0m | time: 397.850s
[2K
| Adam | epoch: 005 | loss: 0.21369 - acc: 0.9071 -- iter: 1472/1750
[A[ATraining Step: 267  | total loss: [1m[32m0.20673[0m[0m | time: 406.712s
[2K
| Adam | epoch: 005 | loss: 0.20673 - acc: 0.9070 -- iter: 1504/1750
[A[ATraining Step: 268  | total loss: [1m[32m0.19438[0m[0m | time: 415.414s
[2K
| Adam | epoch: 005 | loss: 0.19438 - acc: 0.9132 -- iter: 1536/1750
[A[ATraining Step: 269  | total loss: [1m[32m0.18289[0m[0m | time: 423.888s
[2K
| Adam | epoch: 005 | loss: 0.18289 - acc: 0.9187 -- iter: 1568/1750
[A[ATraining Step: 270  | total loss: [1m[32m0.19557[0m[0m | time: 432.608s
[2K
| Adam | epoch: 005 | loss: 0.19557 - acc: 0.9175 -- iter: 1600/1750
[A[ATraining Step: 271  | total loss: [1m[32m0.22383[0m[0m | time: 441.275s
[2K
| Adam | epoch: 005 | loss: 0.22383 - acc: 0.9039 -- iter: 1632/1750
[A[ATraining Step: 272  | total loss: [1m[32m0.21143[0m[0m | time: 450.100s
[2K
| Adam | epoch: 005 | loss: 0.21143 - acc: 0.9104 -- iter: 1664/1750
[A[ATraining Step: 273  | total loss: [1m[32m0.20760[0m[0m | time: 458.619s
[2K
| Adam | epoch: 005 | loss: 0.20760 - acc: 0.9068 -- iter: 1696/1750
[A[ATraining Step: 274  | total loss: [1m[32m0.20808[0m[0m | time: 467.306s
[2K
| Adam | epoch: 005 | loss: 0.20808 - acc: 0.9068 -- iter: 1728/1750
[A[ATraining Step: 275  | total loss: [1m[32m0.20896[0m[0m | time: 500.849s
[2K
| Adam | epoch: 005 | loss: 0.20896 - acc: 0.9067 | val_loss: 1.41037 - val_acc: 0.5931 -- iter: 1750/1750
--
Training Step: 276  | total loss: [1m[32m0.19337[0m[0m | time: 8.685s
[2K
| Adam | epoch: 006 | loss: 0.19337 - acc: 0.9129 -- iter: 0032/1750
[A[ATraining Step: 277  | total loss: [1m[32m0.18456[0m[0m | time: 17.205s
[2K
| Adam | epoch: 006 | loss: 0.18456 - acc: 0.9216 -- iter: 0064/1750
[A[ATraining Step: 278  | total loss: [1m[32m0.17605[0m[0m | time: 25.784s
[2K
| Adam | epoch: 006 | loss: 0.17605 - acc: 0.9263 -- iter: 0096/1750
[A[ATraining Step: 279  | total loss: [1m[32m0.21198[0m[0m | time: 32.550s
[2K
| Adam | epoch: 006 | loss: 0.21198 - acc: 0.9118 -- iter: 0128/1750
[A[ATraining Step: 280  | total loss: [1m[32m0.24927[0m[0m | time: 38.792s
[2K
| Adam | epoch: 006 | loss: 0.24927 - acc: 0.9025 -- iter: 0160/1750
[A[ATraining Step: 281  | total loss: [1m[32m0.22871[0m[0m | time: 47.403s
[2K
| Adam | epoch: 006 | loss: 0.22871 - acc: 0.9122 -- iter: 0192/1750
[A[ATraining Step: 282  | total loss: [1m[32m0.23627[0m[0m | time: 56.095s
[2K
| Adam | epoch: 006 | loss: 0.23627 - acc: 0.9085 -- iter: 0224/1750
[A[ATraining Step: 283  | total loss: [1m[32m0.23773[0m[0m | time: 64.814s
[2K
| Adam | epoch: 006 | loss: 0.23773 - acc: 0.9051 -- iter: 0256/1750
[A[ATraining Step: 284  | total loss: [1m[32m0.23987[0m[0m | time: 73.562s
[2K
| Adam | epoch: 006 | loss: 0.23987 - acc: 0.9021 -- iter: 0288/1750
[A[ATraining Step: 285  | total loss: [1m[32m0.26490[0m[0m | time: 81.862s
[2K
| Adam | epoch: 006 | loss: 0.26490 - acc: 0.8994 -- iter: 0320/1750
[A[ATraining Step: 286  | total loss: [1m[32m0.28784[0m[0m | time: 90.458s
[2K
| Adam | epoch: 006 | loss: 0.28784 - acc: 0.8876 -- iter: 0352/1750
[A[ATraining Step: 287  | total loss: [1m[32m0.33214[0m[0m | time: 99.165s
[2K
| Adam | epoch: 006 | loss: 0.33214 - acc: 0.8738 -- iter: 0384/1750
[A[ATraining Step: 288  | total loss: [1m[32m0.31843[0m[0m | time: 108.069s
[2K
| Adam | epoch: 006 | loss: 0.31843 - acc: 0.8771 -- iter: 0416/1750
[A[ATraining Step: 289  | total loss: [1m[32m0.29879[0m[0m | time: 116.672s
[2K
| Adam | epoch: 006 | loss: 0.29879 - acc: 0.8862 -- iter: 0448/1750
[A[ATraining Step: 290  | total loss: [1m[32m0.28913[0m[0m | time: 125.241s
[2K
| Adam | epoch: 006 | loss: 0.28913 - acc: 0.8882 -- iter: 0480/1750
[A[ATraining Step: 291  | total loss: [1m[32m0.27589[0m[0m | time: 133.771s
[2K
| Adam | epoch: 006 | loss: 0.27589 - acc: 0.8963 -- iter: 0512/1750
[A[ATraining Step: 292  | total loss: [1m[32m0.27045[0m[0m | time: 142.444s
[2K
| Adam | epoch: 006 | loss: 0.27045 - acc: 0.8942 -- iter: 0544/1750
[A[ATraining Step: 293  | total loss: [1m[32m0.27667[0m[0m | time: 151.144s
[2K
| Adam | epoch: 006 | loss: 0.27667 - acc: 0.8891 -- iter: 0576/1750
[A[ATraining Step: 294  | total loss: [1m[32m0.28315[0m[0m | time: 159.871s
[2K
| Adam | epoch: 006 | loss: 0.28315 - acc: 0.8846 -- iter: 0608/1750
[A[ATraining Step: 295  | total loss: [1m[32m0.28647[0m[0m | time: 168.144s
[2K
| Adam | epoch: 006 | loss: 0.28647 - acc: 0.8836 -- iter: 0640/1750
[A[ATraining Step: 296  | total loss: [1m[32m0.28428[0m[0m | time: 176.692s
[2K
| Adam | epoch: 006 | loss: 0.28428 - acc: 0.8796 -- iter: 0672/1750
[A[ATraining Step: 297  | total loss: [1m[32m0.28136[0m[0m | time: 185.385s
[2K
| Adam | epoch: 006 | loss: 0.28136 - acc: 0.8823 -- iter: 0704/1750
[A[ATraining Step: 298  | total loss: [1m[32m0.26597[0m[0m | time: 194.073s
[2K
| Adam | epoch: 006 | loss: 0.26597 - acc: 0.8878 -- iter: 0736/1750
[A[ATraining Step: 299  | total loss: [1m[32m0.28163[0m[0m | time: 202.678s
[2K
| Adam | epoch: 006 | loss: 0.28163 - acc: 0.8678 -- iter: 0768/1750
[A[ATraining Step: 300  | total loss: [1m[32m0.28016[0m[0m | time: 211.442s
[2K
| Adam | epoch: 006 | loss: 0.28016 - acc: 0.8716 -- iter: 0800/1750
[A[ATraining Step: 301  | total loss: [1m[32m0.29441[0m[0m | time: 220.037s
[2K
| Adam | epoch: 006 | loss: 0.29441 - acc: 0.8626 -- iter: 0832/1750
[A[ATraining Step: 302  | total loss: [1m[32m0.29668[0m[0m | time: 228.643s
[2K
| Adam | epoch: 006 | loss: 0.29668 - acc: 0.8701 -- iter: 0864/1750
[A[ATraining Step: 303  | total loss: [1m[32m0.28454[0m[0m | time: 237.287s
[2K
| Adam | epoch: 006 | loss: 0.28454 - acc: 0.8800 -- iter: 0896/1750
[A[ATraining Step: 304  | total loss: [1m[32m0.29420[0m[0m | time: 245.920s
[2K
| Adam | epoch: 006 | loss: 0.29420 - acc: 0.8732 -- iter: 0928/1750
[A[ATraining Step: 305  | total loss: [1m[32m0.27604[0m[0m | time: 254.456s
[2K
| Adam | epoch: 006 | loss: 0.27604 - acc: 0.8796 -- iter: 0960/1750
[A[ATraining Step: 306  | total loss: [1m[32m0.28139[0m[0m | time: 263.194s
[2K
| Adam | epoch: 006 | loss: 0.28139 - acc: 0.8823 -- iter: 0992/1750
[A[ATraining Step: 307  | total loss: [1m[32m0.28362[0m[0m | time: 271.646s
[2K
| Adam | epoch: 006 | loss: 0.28362 - acc: 0.8878 -- iter: 1024/1750
[A[ATraining Step: 308  | total loss: [1m[32m0.27050[0m[0m | time: 280.095s
[2K
| Adam | epoch: 006 | loss: 0.27050 - acc: 0.8928 -- iter: 1056/1750
[A[ATraining Step: 309  | total loss: [1m[32m0.26927[0m[0m | time: 288.950s
[2K
| Adam | epoch: 006 | loss: 0.26927 - acc: 0.8879 -- iter: 1088/1750
[A[ATraining Step: 310  | total loss: [1m[32m0.25135[0m[0m | time: 297.410s
[2K
| Adam | epoch: 006 | loss: 0.25135 - acc: 0.8960 -- iter: 1120/1750
[A[ATraining Step: 311  | total loss: [1m[32m0.25876[0m[0m | time: 306.103s
[2K
| Adam | epoch: 006 | loss: 0.25876 - acc: 0.8939 -- iter: 1152/1750
[A[ATraining Step: 312  | total loss: [1m[32m0.25065[0m[0m | time: 314.671s
[2K
| Adam | epoch: 006 | loss: 0.25065 - acc: 0.8951 -- iter: 1184/1750
[A[ATraining Step: 313  | total loss: [1m[32m0.23618[0m[0m | time: 323.246s
[2K
| Adam | epoch: 006 | loss: 0.23618 - acc: 0.9025 -- iter: 1216/1750
[A[ATraining Step: 314  | total loss: [1m[32m0.25753[0m[0m | time: 331.814s
[2K
| Adam | epoch: 006 | loss: 0.25753 - acc: 0.8966 -- iter: 1248/1750
[A[ATraining Step: 315  | total loss: [1m[32m0.27280[0m[0m | time: 340.482s
[2K
| Adam | epoch: 006 | loss: 0.27280 - acc: 0.8913 -- iter: 1280/1750
[A[ATraining Step: 316  | total loss: [1m[32m0.25138[0m[0m | time: 349.141s
[2K
| Adam | epoch: 006 | loss: 0.25138 - acc: 0.9022 -- iter: 1312/1750
[A[ATraining Step: 317  | total loss: [1m[32m0.25037[0m[0m | time: 357.595s
[2K
| Adam | epoch: 006 | loss: 0.25037 - acc: 0.9057 -- iter: 1344/1750
[A[ATraining Step: 318  | total loss: [1m[32m0.24230[0m[0m | time: 366.166s
[2K
| Adam | epoch: 006 | loss: 0.24230 - acc: 0.9089 -- iter: 1376/1750
[A[ATraining Step: 319  | total loss: [1m[32m0.24527[0m[0m | time: 374.815s
[2K
| Adam | epoch: 006 | loss: 0.24527 - acc: 0.9086 -- iter: 1408/1750
[A[ATraining Step: 320  | total loss: [1m[32m0.25197[0m[0m | time: 383.471s
[2K
| Adam | epoch: 006 | loss: 0.25197 - acc: 0.9053 -- iter: 1440/1750
[A[ATraining Step: 321  | total loss: [1m[32m0.26470[0m[0m | time: 392.083s
[2K
| Adam | epoch: 006 | loss: 0.26470 - acc: 0.8960 -- iter: 1472/1750
[A[ATraining Step: 322  | total loss: [1m[32m0.25542[0m[0m | time: 400.810s
[2K
| Adam | epoch: 006 | loss: 0.25542 - acc: 0.8970 -- iter: 1504/1750
[A[ATraining Step: 323  | total loss: [1m[32m0.24512[0m[0m | time: 409.732s
[2K
| Adam | epoch: 006 | loss: 0.24512 - acc: 0.9011 -- iter: 1536/1750
[A[ATraining Step: 324  | total loss: [1m[32m0.24201[0m[0m | time: 418.319s
[2K
| Adam | epoch: 006 | loss: 0.24201 - acc: 0.9047 -- iter: 1568/1750
[A[ATraining Step: 325  | total loss: [1m[32m0.22746[0m[0m | time: 427.105s
[2K
| Adam | epoch: 006 | loss: 0.22746 - acc: 0.9111 -- iter: 1600/1750
[A[ATraining Step: 326  | total loss: [1m[32m0.21469[0m[0m | time: 435.800s
[2K
| Adam | epoch: 006 | loss: 0.21469 - acc: 0.9200 -- iter: 1632/1750
[A[ATraining Step: 327  | total loss: [1m[32m0.20243[0m[0m | time: 444.651s
[2K
| Adam | epoch: 006 | loss: 0.20243 - acc: 0.9280 -- iter: 1664/1750
[A[ATraining Step: 328  | total loss: [1m[32m0.18805[0m[0m | time: 453.248s
[2K
| Adam | epoch: 006 | loss: 0.18805 - acc: 0.9352 -- iter: 1696/1750
[A[ATraining Step: 329  | total loss: [1m[32m0.17986[0m[0m | time: 462.056s
[2K
| Adam | epoch: 006 | loss: 0.17986 - acc: 0.9354 -- iter: 1728/1750
[A[ATraining Step: 330  | total loss: [1m[32m0.18232[0m[0m | time: 496.492s
[2K
| Adam | epoch: 006 | loss: 0.18232 - acc: 0.9325 | val_loss: 1.80762 - val_acc: 0.6150 -- iter: 1750/1750
--
Training Step: 331  | total loss: [1m[32m0.19243[0m[0m | time: 8.738s
[2K
| Adam | epoch: 007 | loss: 0.19243 - acc: 0.9299 -- iter: 0032/1750
[A[ATraining Step: 332  | total loss: [1m[32m0.18715[0m[0m | time: 17.571s
[2K
| Adam | epoch: 007 | loss: 0.18715 - acc: 0.9338 -- iter: 0064/1750
[A[ATraining Step: 333  | total loss: [1m[32m0.18782[0m[0m | time: 26.453s
[2K
| Adam | epoch: 007 | loss: 0.18782 - acc: 0.9279 -- iter: 0096/1750
[A[ATraining Step: 334  | total loss: [1m[32m0.18588[0m[0m | time: 35.528s
[2K
| Adam | epoch: 007 | loss: 0.18588 - acc: 0.9226 -- iter: 0128/1750
[A[ATraining Step: 335  | total loss: [1m[32m0.18828[0m[0m | time: 42.057s
[2K
| Adam | epoch: 007 | loss: 0.18828 - acc: 0.9178 -- iter: 0160/1750
[A[ATraining Step: 336  | total loss: [1m[32m0.17602[0m[0m | time: 48.688s
[2K
| Adam | epoch: 007 | loss: 0.17602 - acc: 0.9261 -- iter: 0192/1750
[A[ATraining Step: 337  | total loss: [1m[32m0.16299[0m[0m | time: 57.420s
[2K
| Adam | epoch: 007 | loss: 0.16299 - acc: 0.9335 -- iter: 0224/1750
[A[ATraining Step: 338  | total loss: [1m[32m0.16391[0m[0m | time: 66.154s
[2K
| Adam | epoch: 007 | loss: 0.16391 - acc: 0.9370 -- iter: 0256/1750
[A[ATraining Step: 339  | total loss: [1m[32m0.16693[0m[0m | time: 75.053s
[2K
| Adam | epoch: 007 | loss: 0.16693 - acc: 0.9370 -- iter: 0288/1750
[A[ATraining Step: 340  | total loss: [1m[32m0.18308[0m[0m | time: 83.897s
[2K
| Adam | epoch: 007 | loss: 0.18308 - acc: 0.9371 -- iter: 0320/1750
[A[ATraining Step: 341  | total loss: [1m[32m0.19252[0m[0m | time: 92.528s
[2K
| Adam | epoch: 007 | loss: 0.19252 - acc: 0.9309 -- iter: 0352/1750
[A[ATraining Step: 342  | total loss: [1m[32m0.18337[0m[0m | time: 101.372s
[2K
| Adam | epoch: 007 | loss: 0.18337 - acc: 0.9347 -- iter: 0384/1750
[A[ATraining Step: 343  | total loss: [1m[32m0.17680[0m[0m | time: 110.364s
[2K
| Adam | epoch: 007 | loss: 0.17680 - acc: 0.9349 -- iter: 0416/1750
[A[ATraining Step: 344  | total loss: [1m[32m0.20527[0m[0m | time: 119.230s
[2K
| Adam | epoch: 007 | loss: 0.20527 - acc: 0.9258 -- iter: 0448/1750
[A[ATraining Step: 345  | total loss: [1m[32m0.25857[0m[0m | time: 128.091s
[2K
| Adam | epoch: 007 | loss: 0.25857 - acc: 0.9020 -- iter: 0480/1750
[A[ATraining Step: 346  | total loss: [1m[32m0.24157[0m[0m | time: 136.895s
[2K
| Adam | epoch: 007 | loss: 0.24157 - acc: 0.9118 -- iter: 0512/1750
[A[ATraining Step: 347  | total loss: [1m[32m0.24108[0m[0m | time: 145.415s
[2K
| Adam | epoch: 007 | loss: 0.24108 - acc: 0.9112 -- iter: 0544/1750
[A[ATraining Step: 348  | total loss: [1m[32m0.23856[0m[0m | time: 154.086s
[2K
| Adam | epoch: 007 | loss: 0.23856 - acc: 0.9107 -- iter: 0576/1750
[A[ATraining Step: 349  | total loss: [1m[32m0.23190[0m[0m | time: 163.103s
[2K
| Adam | epoch: 007 | loss: 0.23190 - acc: 0.9134 -- iter: 0608/1750
[A[ATraining Step: 350  | total loss: [1m[32m0.23757[0m[0m | time: 171.827s
[2K
| Adam | epoch: 007 | loss: 0.23757 - acc: 0.9064 -- iter: 0640/1750
[A[ATraining Step: 351  | total loss: [1m[32m0.26444[0m[0m | time: 180.766s
[2K
| Adam | epoch: 007 | loss: 0.26444 - acc: 0.8971 -- iter: 0672/1750
[A[ATraining Step: 352  | total loss: [1m[32m0.24817[0m[0m | time: 189.604s
[2K
| Adam | epoch: 007 | loss: 0.24817 - acc: 0.9042 -- iter: 0704/1750
[A[ATraining Step: 353  | total loss: [1m[32m0.24371[0m[0m | time: 198.381s
[2K
| Adam | epoch: 007 | loss: 0.24371 - acc: 0.9076 -- iter: 0736/1750
[A[ATraining Step: 354  | total loss: [1m[32m0.23072[0m[0m | time: 207.085s
[2K
| Adam | epoch: 007 | loss: 0.23072 - acc: 0.9105 -- iter: 0768/1750
[A[ATraining Step: 355  | total loss: [1m[32m0.23914[0m[0m | time: 215.996s
[2K
| Adam | epoch: 007 | loss: 0.23914 - acc: 0.9039 -- iter: 0800/1750
[A[ATraining Step: 356  | total loss: [1m[32m0.23466[0m[0m | time: 225.091s
[2K
| Adam | epoch: 007 | loss: 0.23466 - acc: 0.9010 -- iter: 0832/1750
[A[ATraining Step: 357  | total loss: [1m[32m0.23627[0m[0m | time: 233.895s
[2K
| Adam | epoch: 007 | loss: 0.23627 - acc: 0.9015 -- iter: 0864/1750
[A[ATraining Step: 358  | total loss: [1m[32m0.25876[0m[0m | time: 242.401s
[2K
| Adam | epoch: 007 | loss: 0.25876 - acc: 0.8989 -- iter: 0896/1750
[A[ATraining Step: 359  | total loss: [1m[32m0.26327[0m[0m | time: 251.642s
[2K
| Adam | epoch: 007 | loss: 0.26327 - acc: 0.8996 -- iter: 0928/1750
[A[ATraining Step: 360  | total loss: [1m[32m0.28964[0m[0m | time: 260.457s
[2K
| Adam | epoch: 007 | loss: 0.28964 - acc: 0.8971 -- iter: 0960/1750
[A[ATraining Step: 361  | total loss: [1m[32m0.29230[0m[0m | time: 269.169s
[2K
| Adam | epoch: 007 | loss: 0.29230 - acc: 0.8949 -- iter: 0992/1750
[A[ATraining Step: 362  | total loss: [1m[32m0.30500[0m[0m | time: 278.024s
[2K
| Adam | epoch: 007 | loss: 0.30500 - acc: 0.8898 -- iter: 1024/1750
[A[ATraining Step: 363  | total loss: [1m[32m0.29221[0m[0m | time: 286.924s
[2K
| Adam | epoch: 007 | loss: 0.29221 - acc: 0.8914 -- iter: 1056/1750
[A[ATraining Step: 364  | total loss: [1m[32m0.28332[0m[0m | time: 295.659s
[2K
| Adam | epoch: 007 | loss: 0.28332 - acc: 0.8929 -- iter: 1088/1750
[A[ATraining Step: 365  | total loss: [1m[32m0.26559[0m[0m | time: 304.469s
[2K
| Adam | epoch: 007 | loss: 0.26559 - acc: 0.9005 -- iter: 1120/1750
[A[ATraining Step: 366  | total loss: [1m[32m0.25809[0m[0m | time: 313.549s
[2K
| Adam | epoch: 007 | loss: 0.25809 - acc: 0.9011 -- iter: 1152/1750
[A[ATraining Step: 367  | total loss: [1m[32m0.24850[0m[0m | time: 322.571s
[2K
| Adam | epoch: 007 | loss: 0.24850 - acc: 0.9016 -- iter: 1184/1750
[A[ATraining Step: 368  | total loss: [1m[32m0.24463[0m[0m | time: 331.638s
[2K
| Adam | epoch: 007 | loss: 0.24463 - acc: 0.9052 -- iter: 1216/1750
[A[ATraining Step: 369  | total loss: [1m[32m0.23653[0m[0m | time: 340.404s
[2K
| Adam | epoch: 007 | loss: 0.23653 - acc: 0.9053 -- iter: 1248/1750
[A[ATraining Step: 370  | total loss: [1m[32m0.23032[0m[0m | time: 349.317s
[2K
| Adam | epoch: 007 | loss: 0.23032 - acc: 0.9054 -- iter: 1280/1750
[A[ATraining Step: 371  | total loss: [1m[32m0.22687[0m[0m | time: 358.474s
[2K
| Adam | epoch: 007 | loss: 0.22687 - acc: 0.9055 -- iter: 1312/1750
[A[ATraining Step: 372  | total loss: [1m[32m0.21207[0m[0m | time: 367.622s
[2K
| Adam | epoch: 007 | loss: 0.21207 - acc: 0.9149 -- iter: 1344/1750
[A[ATraining Step: 373  | total loss: [1m[32m0.22612[0m[0m | time: 377.083s
[2K
| Adam | epoch: 007 | loss: 0.22612 - acc: 0.9109 -- iter: 1376/1750
[A[ATraining Step: 374  | total loss: [1m[32m0.22880[0m[0m | time: 386.295s
[2K
| Adam | epoch: 007 | loss: 0.22880 - acc: 0.9042 -- iter: 1408/1750
[A[ATraining Step: 375  | total loss: [1m[32m0.21221[0m[0m | time: 395.180s
[2K
| Adam | epoch: 007 | loss: 0.21221 - acc: 0.9138 -- iter: 1440/1750
[A[ATraining Step: 376  | total loss: [1m[32m0.20070[0m[0m | time: 404.087s
[2K
| Adam | epoch: 007 | loss: 0.20070 - acc: 0.9162 -- iter: 1472/1750
[A[ATraining Step: 377  | total loss: [1m[32m0.18623[0m[0m | time: 413.271s
[2K
| Adam | epoch: 007 | loss: 0.18623 - acc: 0.9246 -- iter: 1504/1750
[A[ATraining Step: 378  | total loss: [1m[32m0.18933[0m[0m | time: 422.559s
[2K
| Adam | epoch: 007 | loss: 0.18933 - acc: 0.9196 -- iter: 1536/1750
[A[ATraining Step: 379  | total loss: [1m[32m0.18824[0m[0m | time: 431.598s
[2K
| Adam | epoch: 007 | loss: 0.18824 - acc: 0.9214 -- iter: 1568/1750
[A[ATraining Step: 380  | total loss: [1m[32m0.17653[0m[0m | time: 440.725s
[2K
| Adam | epoch: 007 | loss: 0.17653 - acc: 0.9261 -- iter: 1600/1750
[A[ATraining Step: 381  | total loss: [1m[32m0.16539[0m[0m | time: 449.794s
[2K
| Adam | epoch: 007 | loss: 0.16539 - acc: 0.9335 -- iter: 1632/1750
[A[ATraining Step: 382  | total loss: [1m[32m0.15588[0m[0m | time: 458.916s
[2K
| Adam | epoch: 007 | loss: 0.15588 - acc: 0.9402 -- iter: 1664/1750
[A[ATraining Step: 383  | total loss: [1m[32m0.15885[0m[0m | time: 468.095s
[2K
| Adam | epoch: 007 | loss: 0.15885 - acc: 0.9368 -- iter: 1696/1750
[A[ATraining Step: 384  | total loss: [1m[32m0.16928[0m[0m | time: 477.374s
[2K
| Adam | epoch: 007 | loss: 0.16928 - acc: 0.9337 -- iter: 1728/1750
[A[ATraining Step: 385  | total loss: [1m[32m0.16834[0m[0m | time: 513.579s
[2K
| Adam | epoch: 007 | loss: 0.16834 - acc: 0.9278 | val_loss: 1.05796 - val_acc: 0.7062 -- iter: 1750/1750
--
Training Step: 386  | total loss: [1m[32m0.17257[0m[0m | time: 40.749s
[2K
| Adam | epoch: 008 | loss: 0.17257 - acc: 0.9226 -- iter: 0032/1750
[A[ATraining Step: 387  | total loss: [1m[32m0.18327[0m[0m | time: 100.120s
[2K
| Adam | epoch: 008 | loss: 0.18327 - acc: 0.9241 -- iter: 0064/1750
[A[ATraining Step: 388  | total loss: [1m[32m0.20218[0m[0m | time: 151.827s
[2K
| Adam | epoch: 008 | loss: 0.20218 - acc: 0.9254 -- iter: 0096/1750
[A[ATraining Step: 389  | total loss: [1m[32m0.19425[0m[0m | time: 161.617s
[2K
| Adam | epoch: 008 | loss: 0.19425 - acc: 0.9266 -- iter: 0128/1750
[A[ATraining Step: 390  | total loss: [1m[32m0.19158[0m[0m | time: 170.507s
[2K
| Adam | epoch: 008 | loss: 0.19158 - acc: 0.9308 -- iter: 0160/1750
[A[ATraining Step: 391  | total loss: [1m[32m0.18490[0m[0m | time: 177.216s
[2K
| Adam | epoch: 008 | loss: 0.18490 - acc: 0.9315 -- iter: 0192/1750
[A[ATraining Step: 392  | total loss: [1m[32m0.17634[0m[0m | time: 183.661s
[2K
| Adam | epoch: 008 | loss: 0.17634 - acc: 0.9338 -- iter: 0224/1750
[A[ATraining Step: 393  | total loss: [1m[32m0.16384[0m[0m | time: 192.218s
[2K
| Adam | epoch: 008 | loss: 0.16384 - acc: 0.9404 -- iter: 0256/1750
[A[ATraining Step: 394  | total loss: [1m[32m0.16642[0m[0m | time: 201.069s
[2K
| Adam | epoch: 008 | loss: 0.16642 - acc: 0.9401 -- iter: 0288/1750
[A[ATraining Step: 395  | total loss: [1m[32m0.16211[0m[0m | time: 254.232s
[2K
| Adam | epoch: 008 | loss: 0.16211 - acc: 0.9430 -- iter: 0320/1750
[A[ATraining Step: 396  | total loss: [1m[32m0.15586[0m[0m | time: 278.052s
[2K
| Adam | epoch: 008 | loss: 0.15586 - acc: 0.9456 -- iter: 0352/1750
[A[ATraining Step: 397  | total loss: [1m[32m0.15224[0m[0m | time: 304.091s
[2K
| Adam | epoch: 008 | loss: 0.15224 - acc: 0.9479 -- iter: 0384/1750
[A[ATraining Step: 398  | total loss: [1m[32m0.15190[0m[0m | time: 364.526s
[2K
| Adam | epoch: 008 | loss: 0.15190 - acc: 0.9468 -- iter: 0416/1750
[A[ATraining Step: 399  | total loss: [1m[32m0.14767[0m[0m | time: 373.687s
[2K
| Adam | epoch: 008 | loss: 0.14767 - acc: 0.9459 -- iter: 0448/1750
[A[ATraining Step: 400  | total loss: [1m[32m0.15667[0m[0m | time: 497.063s
[2K
| Adam | epoch: 008 | loss: 0.15667 - acc: 0.9388 | val_loss: 0.42918 - val_acc: 0.8631 -- iter: 0480/1750
--
Training Step: 401  | total loss: [1m[32m0.15283[0m[0m | time: 506.022s
[2K
| Adam | epoch: 008 | loss: 0.15283 - acc: 0.9387 -- iter: 0512/1750
[A[ATraining Step: 402  | total loss: [1m[32m0.17256[0m[0m | time: 515.015s
[2K
| Adam | epoch: 008 | loss: 0.17256 - acc: 0.9261 -- iter: 0544/1750
[A[ATraining Step: 403  | total loss: [1m[32m0.16172[0m[0m | time: 529.357s
[2K
| Adam | epoch: 008 | loss: 0.16172 - acc: 0.9335 -- iter: 0576/1750
[A[ATraining Step: 404  | total loss: [1m[32m0.16616[0m[0m | time: 560.048s
[2K
| Adam | epoch: 008 | loss: 0.16616 - acc: 0.9307 -- iter: 0608/1750
[A[ATraining Step: 405  | total loss: [1m[32m0.18053[0m[0m | time: 602.122s
[2K
| Adam | epoch: 008 | loss: 0.18053 - acc: 0.9220 -- iter: 0640/1750
[A[ATraining Step: 406  | total loss: [1m[32m0.16719[0m[0m | time: 617.026s
[2K
| Adam | epoch: 008 | loss: 0.16719 - acc: 0.9298 -- iter: 0672/1750
[A[ATraining Step: 407  | total loss: [1m[32m0.18986[0m[0m | time: 625.873s
[2K
| Adam | epoch: 008 | loss: 0.18986 - acc: 0.9212 -- iter: 0704/1750
[A[ATraining Step: 408  | total loss: [1m[32m0.17722[0m[0m | time: 634.713s
[2K
| Adam | epoch: 008 | loss: 0.17722 - acc: 0.9291 -- iter: 0736/1750
[A[ATraining Step: 409  | total loss: [1m[32m0.17851[0m[0m | time: 651.626s
[2K
| Adam | epoch: 008 | loss: 0.17851 - acc: 0.9237 -- iter: 0768/1750
[A[ATraining Step: 410  | total loss: [1m[32m0.19210[0m[0m | time: 680.191s
[2K
| Adam | epoch: 008 | loss: 0.19210 - acc: 0.9251 -- iter: 0800/1750
[A[ATraining Step: 411  | total loss: [1m[32m0.19552[0m[0m | time: 706.170s
[2K
| Adam | epoch: 008 | loss: 0.19552 - acc: 0.9232 -- iter: 0832/1750
[A[ATraining Step: 412  | total loss: [1m[32m0.18275[0m[0m | time: 737.653s
[2K
| Adam | epoch: 008 | loss: 0.18275 - acc: 0.9309 -- iter: 0864/1750
[A[ATraining Step: 413  | total loss: [1m[32m0.18188[0m[0m | time: 746.592s
[2K
| Adam | epoch: 008 | loss: 0.18188 - acc: 0.9347 -- iter: 0896/1750
[A[ATraining Step: 414  | total loss: [1m[32m0.19020[0m[0m | time: 755.575s
[2K
| Adam | epoch: 008 | loss: 0.19020 - acc: 0.9287 -- iter: 0928/1750
[A[ATraining Step: 415  | total loss: [1m[32m0.20751[0m[0m | time: 770.089s
[2K
| Adam | epoch: 008 | loss: 0.20751 - acc: 0.9233 -- iter: 0960/1750
[A[ATraining Step: 416  | total loss: [1m[32m0.20351[0m[0m | time: 785.261s
[2K
| Adam | epoch: 008 | loss: 0.20351 - acc: 0.9279 -- iter: 0992/1750
[A[ATraining Step: 417  | total loss: [1m[32m0.19866[0m[0m | time: 801.150s
[2K
| Adam | epoch: 008 | loss: 0.19866 - acc: 0.9288 -- iter: 1024/1750
[A[ATraining Step: 418  | total loss: [1m[32m0.19613[0m[0m | time: 846.151s
[2K
| Adam | epoch: 008 | loss: 0.19613 - acc: 0.9297 -- iter: 1056/1750
[A[ATraining Step: 419  | total loss: [1m[32m0.18233[0m[0m | time: 855.133s
[2K
| Adam | epoch: 008 | loss: 0.18233 - acc: 0.9336 -- iter: 1088/1750
[A[ATraining Step: 420  | total loss: [1m[32m0.17988[0m[0m | time: 864.066s
[2K
| Adam | epoch: 008 | loss: 0.17988 - acc: 0.9340 -- iter: 1120/1750
[A[ATraining Step: 421  | total loss: [1m[32m0.16587[0m[0m | time: 881.054s
[2K
| Adam | epoch: 008 | loss: 0.16587 - acc: 0.9406 -- iter: 1152/1750
[A[ATraining Step: 422  | total loss: [1m[32m0.18205[0m[0m | time: 898.031s
[2K
| Adam | epoch: 008 | loss: 0.18205 - acc: 0.9340 -- iter: 1184/1750
[A[ATraining Step: 423  | total loss: [1m[32m0.17633[0m[0m | time: 912.847s
[2K
| Adam | epoch: 008 | loss: 0.17633 - acc: 0.9344 -- iter: 1216/1750
[A[ATraining Step: 424  | total loss: [1m[32m0.17750[0m[0m | time: 969.934s
[2K
| Adam | epoch: 008 | loss: 0.17750 - acc: 0.9378 -- iter: 1248/1750
[A[ATraining Step: 425  | total loss: [1m[32m0.17086[0m[0m | time: 978.824s
[2K
| Adam | epoch: 008 | loss: 0.17086 - acc: 0.9440 -- iter: 1280/1750
[A[ATraining Step: 426  | total loss: [1m[32m0.17584[0m[0m | time: 987.898s
[2K
| Adam | epoch: 008 | loss: 0.17584 - acc: 0.9403 -- iter: 1312/1750
[A[ATraining Step: 427  | total loss: [1m[32m0.20285[0m[0m | time: 1008.338s
[2K
| Adam | epoch: 008 | loss: 0.20285 - acc: 0.9244 -- iter: 1344/1750
[A[ATraining Step: 428  | total loss: [1m[32m0.19312[0m[0m | time: 1041.106s
[2K
| Adam | epoch: 008 | loss: 0.19312 - acc: 0.9288 -- iter: 1376/1750
[A[ATraining Step: 429  | total loss: [1m[32m0.18703[0m[0m | time: 1062.234s
[2K
| Adam | epoch: 008 | loss: 0.18703 - acc: 0.9297 -- iter: 1408/1750
[A[ATraining Step: 430  | total loss: [1m[32m0.17671[0m[0m | time: 1078.991s
[2K
| Adam | epoch: 008 | loss: 0.17671 - acc: 0.9336 -- iter: 1440/1750
[A[ATraining Step: 431  | total loss: [1m[32m0.16744[0m[0m | time: 1087.744s
[2K
| Adam | epoch: 008 | loss: 0.16744 - acc: 0.9402 -- iter: 1472/1750
[A[ATraining Step: 432  | total loss: [1m[32m0.16577[0m[0m | time: 1096.863s
[2K
| Adam | epoch: 008 | loss: 0.16577 - acc: 0.9431 -- iter: 1504/1750
[A[ATraining Step: 433  | total loss: [1m[32m0.17452[0m[0m | time: 1112.187s
[2K
| Adam | epoch: 008 | loss: 0.17452 - acc: 0.9425 -- iter: 1536/1750
[A[ATraining Step: 434  | total loss: [1m[32m0.16958[0m[0m | time: 1126.107s
[2K
| Adam | epoch: 008 | loss: 0.16958 - acc: 0.9420 -- iter: 1568/1750
[A[ATraining Step: 435  | total loss: [1m[32m0.17086[0m[0m | time: 1140.541s
[2K
| Adam | epoch: 008 | loss: 0.17086 - acc: 0.9384 -- iter: 1600/1750
[A[ATraining Step: 436  | total loss: [1m[32m0.17969[0m[0m | time: 1153.343s
[2K
| Adam | epoch: 008 | loss: 0.17969 - acc: 0.9415 -- iter: 1632/1750
[A[ATraining Step: 437  | total loss: [1m[32m0.17813[0m[0m | time: 1164.708s
[2K
| Adam | epoch: 008 | loss: 0.17813 - acc: 0.9411 -- iter: 1664/1750
[A[ATraining Step: 438  | total loss: [1m[32m0.18044[0m[0m | time: 1177.224s
[2K
| Adam | epoch: 008 | loss: 0.18044 - acc: 0.9345 -- iter: 1696/1750
[A[ATraining Step: 439  | total loss: [1m[32m0.17823[0m[0m | time: 1222.932s
[2K
| Adam | epoch: 008 | loss: 0.17823 - acc: 0.9379 -- iter: 1728/1750
[A[ATraining Step: 440  | total loss: [1m[32m0.16730[0m[0m | time: 1327.446s
[2K
| Adam | epoch: 008 | loss: 0.16730 - acc: 0.9410 | val_loss: 2.22062 - val_acc: 0.5182 -- iter: 1750/1750
--
Training Step: 441  | total loss: [1m[32m0.16710[0m[0m | time: 24.350s
[2K
| Adam | epoch: 009 | loss: 0.16710 - acc: 0.9406 -- iter: 0032/1750
[A[ATraining Step: 442  | total loss: [1m[32m0.17005[0m[0m | time: 46.597s
[2K
| Adam | epoch: 009 | loss: 0.17005 - acc: 0.9403 -- iter: 0064/1750
[A[ATraining Step: 443  | total loss: [1m[32m0.16828[0m[0m | time: 61.891s
[2K
| Adam | epoch: 009 | loss: 0.16828 - acc: 0.9432 -- iter: 0096/1750
[A[ATraining Step: 444  | total loss: [1m[32m0.15810[0m[0m | time: 73.258s
[2K
| Adam | epoch: 009 | loss: 0.15810 - acc: 0.9488 -- iter: 0128/1750
[A[ATraining Step: 445  | total loss: [1m[32m0.14413[0m[0m | time: 92.986s
[2K
| Adam | epoch: 009 | loss: 0.14413 - acc: 0.9540 -- iter: 0160/1750
[A[ATraining Step: 446  | total loss: [1m[32m0.15091[0m[0m | time: 132.930s
[2K
| Adam | epoch: 009 | loss: 0.15091 - acc: 0.9492 -- iter: 0192/1750
[A[ATraining Step: 447  | total loss: [1m[32m0.14089[0m[0m | time: 144.965s
[2K
| Adam | epoch: 009 | loss: 0.14089 - acc: 0.9543 -- iter: 0224/1750
[A[ATraining Step: 448  | total loss: [1m[32m0.14682[0m[0m | time: 175.277s
[2K
| Adam | epoch: 009 | loss: 0.14682 - acc: 0.9452 -- iter: 0256/1750
[A[ATraining Step: 449  | total loss: [1m[32m0.13800[0m[0m | time: 189.298s
[2K
| Adam | epoch: 009 | loss: 0.13800 - acc: 0.9507 -- iter: 0288/1750
[A[ATraining Step: 450  | total loss: [1m[32m0.13852[0m[0m | time: 203.802s
[2K
| Adam | epoch: 009 | loss: 0.13852 - acc: 0.9525 -- iter: 0320/1750
[A[ATraining Step: 451  | total loss: [1m[32m0.13990[0m[0m | time: 286.367s
[2K
| Adam | epoch: 009 | loss: 0.13990 - acc: 0.9479 -- iter: 0352/1750
[A[ATraining Step: 452  | total loss: [1m[32m0.14351[0m[0m | time: 326.036s
[2K
| Adam | epoch: 009 | loss: 0.14351 - acc: 0.9500 -- iter: 0384/1750
[A[ATraining Step: 453  | total loss: [1m[32m0.13795[0m[0m | time: 391.251s
[2K
| Adam | epoch: 009 | loss: 0.13795 - acc: 0.9518 -- iter: 0416/1750
[A[ATraining Step: 454  | total loss: [1m[32m0.15764[0m[0m | time: 426.462s
[2K
| Adam | epoch: 009 | loss: 0.15764 - acc: 0.9442 -- iter: 0448/1750
[A[ATraining Step: 455  | total loss: [1m[32m0.16365[0m[0m | time: 440.903s
[2K
| Adam | epoch: 009 | loss: 0.16365 - acc: 0.9435 -- iter: 0480/1750
[A[ATraining Step: 456  | total loss: [1m[32m0.16121[0m[0m | time: 452.110s
[2K
| Adam | epoch: 009 | loss: 0.16121 - acc: 0.9460 -- iter: 0512/1750
[A[ATraining Step: 457  | total loss: [1m[32m0.15831[0m[0m | time: 463.834s
[2K
| Adam | epoch: 009 | loss: 0.15831 - acc: 0.9452 -- iter: 0544/1750
[A[ATraining Step: 458  | total loss: [1m[32m0.17107[0m[0m | time: 484.894s
[2K
| Adam | epoch: 009 | loss: 0.17107 - acc: 0.9381 -- iter: 0576/1750
[A[ATraining Step: 459  | total loss: [1m[32m0.15987[0m[0m | time: 513.071s
[2K
| Adam | epoch: 009 | loss: 0.15987 - acc: 0.9412 -- iter: 0608/1750
[A[ATraining Step: 460  | total loss: [1m[32m0.15786[0m[0m | time: 556.786s
[2K
| Adam | epoch: 009 | loss: 0.15786 - acc: 0.9440 -- iter: 0640/1750
[A[ATraining Step: 461  | total loss: [1m[32m0.14983[0m[0m | time: 575.715s
[2K
| Adam | epoch: 009 | loss: 0.14983 - acc: 0.9464 -- iter: 0672/1750
[A[ATraining Step: 462  | total loss: [1m[32m0.14250[0m[0m | time: 587.216s
[2K
| Adam | epoch: 009 | loss: 0.14250 - acc: 0.9518 -- iter: 0704/1750
[A[ATraining Step: 463  | total loss: [1m[32m0.15717[0m[0m | time: 600.569s
[2K
| Adam | epoch: 009 | loss: 0.15717 - acc: 0.9410 -- iter: 0736/1750
[A[ATraining Step: 464  | total loss: [1m[32m0.14702[0m[0m | time: 661.312s
[2K
| Adam | epoch: 009 | loss: 0.14702 - acc: 0.9469 -- iter: 0768/1750
[A[ATraining Step: 465  | total loss: [1m[32m0.13574[0m[0m | time: 685.450s
[2K
| Adam | epoch: 009 | loss: 0.13574 - acc: 0.9522 -- iter: 0800/1750
[A[ATraining Step: 466  | total loss: [1m[32m0.15326[0m[0m | time: 702.380s
[2K
| Adam | epoch: 009 | loss: 0.15326 - acc: 0.9476 -- iter: 0832/1750
[A[ATraining Step: 467  | total loss: [1m[32m0.14781[0m[0m | time: 713.995s
[2K
| Adam | epoch: 009 | loss: 0.14781 - acc: 0.9497 -- iter: 0864/1750
[A[ATraining Step: 468  | total loss: [1m[32m0.18491[0m[0m | time: 724.671s
[2K
| Adam | epoch: 009 | loss: 0.18491 - acc: 0.9422 -- iter: 0896/1750
[A[ATraining Step: 469  | total loss: [1m[32m0.17255[0m[0m | time: 738.038s
[2K
| Adam | epoch: 009 | loss: 0.17255 - acc: 0.9449 -- iter: 0928/1750
[A[ATraining Step: 470  | total loss: [1m[32m0.16059[0m[0m | time: 749.304s
[2K
| Adam | epoch: 009 | loss: 0.16059 - acc: 0.9473 -- iter: 0960/1750
[A[ATraining Step: 471  | total loss: [1m[32m0.18198[0m[0m | time: 760.620s
[2K
| Adam | epoch: 009 | loss: 0.18198 - acc: 0.9307 -- iter: 0992/1750
[A[ATraining Step: 472  | total loss: [1m[32m0.19448[0m[0m | time: 771.183s
[2K
| Adam | epoch: 009 | loss: 0.19448 - acc: 0.9314 -- iter: 1024/1750
[A[ATraining Step: 473  | total loss: [1m[32m0.17860[0m[0m | time: 781.971s
[2K
| Adam | epoch: 009 | loss: 0.17860 - acc: 0.9382 -- iter: 1056/1750
[A[ATraining Step: 474  | total loss: [1m[32m0.17169[0m[0m | time: 792.718s
[2K
| Adam | epoch: 009 | loss: 0.17169 - acc: 0.9382 -- iter: 1088/1750
[A[ATraining Step: 475  | total loss: [1m[32m0.17330[0m[0m | time: 803.848s
[2K
| Adam | epoch: 009 | loss: 0.17330 - acc: 0.9350 -- iter: 1120/1750
[A[ATraining Step: 476  | total loss: [1m[32m0.16021[0m[0m | time: 814.219s
[2K
| Adam | epoch: 009 | loss: 0.16021 - acc: 0.9415 -- iter: 1152/1750
[A[ATraining Step: 477  | total loss: [1m[32m0.14929[0m[0m | time: 825.326s
[2K
| Adam | epoch: 009 | loss: 0.14929 - acc: 0.9473 -- iter: 1184/1750
[A[ATraining Step: 478  | total loss: [1m[32m0.14967[0m[0m | time: 836.276s
[2K
| Adam | epoch: 009 | loss: 0.14967 - acc: 0.9463 -- iter: 1216/1750
[A[ATraining Step: 479  | total loss: [1m[32m0.14530[0m[0m | time: 847.248s
[2K
| Adam | epoch: 009 | loss: 0.14530 - acc: 0.9486 -- iter: 1248/1750
[A[ATraining Step: 480  | total loss: [1m[32m0.13744[0m[0m | time: 858.184s
[2K
| Adam | epoch: 009 | loss: 0.13744 - acc: 0.9537 -- iter: 1280/1750
[A[ATraining Step: 481  | total loss: [1m[32m0.16002[0m[0m | time: 868.671s
[2K
| Adam | epoch: 009 | loss: 0.16002 - acc: 0.9458 -- iter: 1312/1750
[A[ATraining Step: 482  | total loss: [1m[32m0.15177[0m[0m | time: 879.868s
[2K
| Adam | epoch: 009 | loss: 0.15177 - acc: 0.9481 -- iter: 1344/1750
[A[ATraining Step: 483  | total loss: [1m[32m0.14161[0m[0m | time: 890.674s
[2K
| Adam | epoch: 009 | loss: 0.14161 - acc: 0.9502 -- iter: 1376/1750
[A[ATraining Step: 484  | total loss: [1m[32m0.13142[0m[0m | time: 901.840s
[2K
| Adam | epoch: 009 | loss: 0.13142 - acc: 0.9552 -- iter: 1408/1750
[A[ATraining Step: 485  | total loss: [1m[32m0.12536[0m[0m | time: 913.034s
[2K
| Adam | epoch: 009 | loss: 0.12536 - acc: 0.9534 -- iter: 1440/1750
[A[ATraining Step: 486  | total loss: [1m[32m0.12566[0m[0m | time: 924.254s
[2K
| Adam | epoch: 009 | loss: 0.12566 - acc: 0.9518 -- iter: 1472/1750
[A[ATraining Step: 487  | total loss: [1m[32m0.12162[0m[0m | time: 934.906s
[2K
| Adam | epoch: 009 | loss: 0.12162 - acc: 0.9535 -- iter: 1504/1750
[A[ATraining Step: 488  | total loss: [1m[32m0.12511[0m[0m | time: 946.226s
[2K
| Adam | epoch: 009 | loss: 0.12511 - acc: 0.9488 -- iter: 1536/1750
[A[ATraining Step: 489  | total loss: [1m[32m0.12284[0m[0m | time: 957.424s
[2K
| Adam | epoch: 009 | loss: 0.12284 - acc: 0.9477 -- iter: 1568/1750
[A[ATraining Step: 490  | total loss: [1m[32m0.12615[0m[0m | time: 968.348s
[2K
| Adam | epoch: 009 | loss: 0.12615 - acc: 0.9404 -- iter: 1600/1750
[A[ATraining Step: 491  | total loss: [1m[32m0.13250[0m[0m | time: 979.834s
[2K
| Adam | epoch: 009 | loss: 0.13250 - acc: 0.9370 -- iter: 1632/1750
[A[ATraining Step: 492  | total loss: [1m[32m0.13261[0m[0m | time: 991.118s
[2K
| Adam | epoch: 009 | loss: 0.13261 - acc: 0.9402 -- iter: 1664/1750
[A[ATraining Step: 493  | total loss: [1m[32m0.15045[0m[0m | time: 1002.169s
[2K
| Adam | epoch: 009 | loss: 0.15045 - acc: 0.9243 -- iter: 1696/1750
[A[ATraining Step: 494  | total loss: [1m[32m0.15250[0m[0m | time: 1012.840s
[2K
| Adam | epoch: 009 | loss: 0.15250 - acc: 0.9225 -- iter: 1728/1750
[A[ATraining Step: 495  | total loss: [1m[32m0.16353[0m[0m | time: 1058.141s
[2K
| Adam | epoch: 009 | loss: 0.16353 - acc: 0.9177 | val_loss: 0.28305 - val_acc: 0.9142 -- iter: 1750/1750
--
Training Step: 496  | total loss: [1m[32m0.15546[0m[0m | time: 11.108s
[2K
| Adam | epoch: 010 | loss: 0.15546 - acc: 0.9228 -- iter: 0032/1750
[A[ATraining Step: 497  | total loss: [1m[32m0.15790[0m[0m | time: 22.357s
[2K
| Adam | epoch: 010 | loss: 0.15790 - acc: 0.9212 -- iter: 0064/1750
[A[ATraining Step: 498  | total loss: [1m[32m0.15175[0m[0m | time: 33.086s
[2K
| Adam | epoch: 010 | loss: 0.15175 - acc: 0.9259 -- iter: 0096/1750
[A[ATraining Step: 499  | total loss: [1m[32m0.15214[0m[0m | time: 44.350s
[2K
| Adam | epoch: 010 | loss: 0.15214 - acc: 0.9271 -- iter: 0128/1750
[A[ATraining Step: 500  | total loss: [1m[32m0.14668[0m[0m | time: 54.829s
[2K
| Adam | epoch: 010 | loss: 0.14668 - acc: 0.9312 -- iter: 0160/1750
[A[ATraining Step: 501  | total loss: [1m[32m0.13730[0m[0m | time: 65.541s
[2K
| Adam | epoch: 010 | loss: 0.13730 - acc: 0.9381 -- iter: 0192/1750
[A[ATraining Step: 502  | total loss: [1m[32m0.14493[0m[0m | time: 76.779s
[2K
| Adam | epoch: 010 | loss: 0.14493 - acc: 0.9318 -- iter: 0224/1750
[A[ATraining Step: 503  | total loss: [1m[32m0.14015[0m[0m | time: 84.735s
[2K
| Adam | epoch: 010 | loss: 0.14015 - acc: 0.9355 -- iter: 0256/1750
[A[ATraining Step: 504  | total loss: [1m[32m0.13052[0m[0m | time: 92.578s
[2K
| Adam | epoch: 010 | loss: 0.13052 - acc: 0.9420 -- iter: 0288/1750
[A[ATraining Step: 505  | total loss: [1m[32m0.12081[0m[0m | time: 102.961s
[2K
| Adam | epoch: 010 | loss: 0.12081 - acc: 0.9478 -- iter: 0320/1750
[A[ATraining Step: 506  | total loss: [1m[32m0.12278[0m[0m | time: 114.309s
[2K
| Adam | epoch: 010 | loss: 0.12278 - acc: 0.9467 -- iter: 0352/1750
[A[ATraining Step: 507  | total loss: [1m[32m0.11705[0m[0m | time: 124.457s
[2K
| Adam | epoch: 010 | loss: 0.11705 - acc: 0.9489 -- iter: 0384/1750
[A[ATraining Step: 508  | total loss: [1m[32m0.12063[0m[0m | time: 132.977s
[2K
| Adam | epoch: 010 | loss: 0.12063 - acc: 0.9415 -- iter: 0416/1750
[A[ATraining Step: 509  | total loss: [1m[32m0.11464[0m[0m | time: 141.654s
[2K
| Adam | epoch: 010 | loss: 0.11464 - acc: 0.9443 -- iter: 0448/1750
[A[ATraining Step: 510  | total loss: [1m[32m0.11043[0m[0m | time: 150.205s
[2K
| Adam | epoch: 010 | loss: 0.11043 - acc: 0.9467 -- iter: 0480/1750
[A[ATraining Step: 511  | total loss: [1m[32m0.10556[0m[0m | time: 158.595s
[2K
| Adam | epoch: 010 | loss: 0.10556 - acc: 0.9520 -- iter: 0512/1750
[A[ATraining Step: 512  | total loss: [1m[32m0.09996[0m[0m | time: 167.317s
[2K
| Adam | epoch: 010 | loss: 0.09996 - acc: 0.9568 -- iter: 0544/1750
[A[ATraining Step: 513  | total loss: [1m[32m0.10271[0m[0m | time: 176.004s
[2K
| Adam | epoch: 010 | loss: 0.10271 - acc: 0.9549 -- iter: 0576/1750
[A[ATraining Step: 514  | total loss: [1m[32m0.09649[0m[0m | time: 184.487s
[2K
| Adam | epoch: 010 | loss: 0.09649 - acc: 0.9594 -- iter: 0608/1750
[A[ATraining Step: 515  | total loss: [1m[32m0.09731[0m[0m | time: 193.229s
[2K
| Adam | epoch: 010 | loss: 0.09731 - acc: 0.9603 -- iter: 0640/1750
[A[ATraining Step: 516  | total loss: [1m[32m0.09170[0m[0m | time: 201.887s
[2K
| Adam | epoch: 010 | loss: 0.09170 - acc: 0.9643 -- iter: 0672/1750
[A[ATraining Step: 517  | total loss: [1m[32m0.09650[0m[0m | time: 210.417s
[2K
| Adam | epoch: 010 | loss: 0.09650 - acc: 0.9616 -- iter: 0704/1750
[A[ATraining Step: 518  | total loss: [1m[32m0.09390[0m[0m | time: 219.238s
[2K
| Adam | epoch: 010 | loss: 0.09390 - acc: 0.9655 -- iter: 0736/1750
[A[ATraining Step: 519  | total loss: [1m[32m0.09866[0m[0m | time: 227.480s
[2K
| Adam | epoch: 010 | loss: 0.09866 - acc: 0.9658 -- iter: 0768/1750
[A[ATraining Step: 520  | total loss: [1m[32m0.15629[0m[0m | time: 236.039s
[2K
| Adam | epoch: 010 | loss: 0.15629 - acc: 0.9505 -- iter: 0800/1750
[A[ATraining Step: 521  | total loss: [1m[32m0.14579[0m[0m | time: 244.617s
[2K
| Adam | epoch: 010 | loss: 0.14579 - acc: 0.9554 -- iter: 0832/1750
[A[ATraining Step: 522  | total loss: [1m[32m0.13505[0m[0m | time: 253.162s
[2K
| Adam | epoch: 010 | loss: 0.13505 - acc: 0.9599 -- iter: 0864/1750
[A[ATraining Step: 523  | total loss: [1m[32m0.13786[0m[0m | time: 261.687s
[2K
| Adam | epoch: 010 | loss: 0.13786 - acc: 0.9576 -- iter: 0896/1750
[A[ATraining Step: 524  | total loss: [1m[32m0.13856[0m[0m | time: 270.500s
[2K
| Adam | epoch: 010 | loss: 0.13856 - acc: 0.9556 -- iter: 0928/1750
[A[ATraining Step: 525  | total loss: [1m[32m0.12832[0m[0m | time: 278.883s
[2K
| Adam | epoch: 010 | loss: 0.12832 - acc: 0.9569 -- iter: 0960/1750
[A[ATraining Step: 526  | total loss: [1m[32m0.12242[0m[0m | time: 287.576s
[2K
| Adam | epoch: 010 | loss: 0.12242 - acc: 0.9581 -- iter: 0992/1750
[A[ATraining Step: 527  | total loss: [1m[32m0.13418[0m[0m | time: 296.171s
[2K
| Adam | epoch: 010 | loss: 0.13418 - acc: 0.9529 -- iter: 1024/1750
[A[ATraining Step: 528  | total loss: [1m[32m0.15986[0m[0m | time: 304.805s
[2K
| Adam | epoch: 010 | loss: 0.15986 - acc: 0.9483 -- iter: 1056/1750
[A[ATraining Step: 529  | total loss: [1m[32m0.16177[0m[0m | time: 313.342s
[2K
| Adam | epoch: 010 | loss: 0.16177 - acc: 0.9503 -- iter: 1088/1750
[A[ATraining Step: 530  | total loss: [1m[32m0.15454[0m[0m | time: 322.120s
[2K
| Adam | epoch: 010 | loss: 0.15454 - acc: 0.9522 -- iter: 1120/1750
[A[ATraining Step: 531  | total loss: [1m[32m0.15464[0m[0m | time: 331.036s
[2K
| Adam | epoch: 010 | loss: 0.15464 - acc: 0.9476 -- iter: 1152/1750
[A[ATraining Step: 532  | total loss: [1m[32m0.14359[0m[0m | time: 339.416s
[2K
| Adam | epoch: 010 | loss: 0.14359 - acc: 0.9528 -- iter: 1184/1750
[A[ATraining Step: 533  | total loss: [1m[32m0.14144[0m[0m | time: 348.192s
[2K
| Adam | epoch: 010 | loss: 0.14144 - acc: 0.9513 -- iter: 1216/1750
[A[ATraining Step: 534  | total loss: [1m[32m0.14558[0m[0m | time: 356.766s
[2K
| Adam | epoch: 010 | loss: 0.14558 - acc: 0.9437 -- iter: 1248/1750
[A[ATraining Step: 535  | total loss: [1m[32m0.14868[0m[0m | time: 365.582s
[2K
| Adam | epoch: 010 | loss: 0.14868 - acc: 0.9399 -- iter: 1280/1750
[A[ATraining Step: 536  | total loss: [1m[32m0.14057[0m[0m | time: 374.191s
[2K
| Adam | epoch: 010 | loss: 0.14057 - acc: 0.9459 -- iter: 1312/1750
[A[ATraining Step: 537  | total loss: [1m[32m0.14384[0m[0m | time: 383.052s
[2K
| Adam | epoch: 010 | loss: 0.14384 - acc: 0.9420 -- iter: 1344/1750
[A[ATraining Step: 538  | total loss: [1m[32m0.14222[0m[0m | time: 391.741s
[2K
| Adam | epoch: 010 | loss: 0.14222 - acc: 0.9446 -- iter: 1376/1750
[A[ATraining Step: 539  | total loss: [1m[32m0.14876[0m[0m | time: 400.286s
[2K
| Adam | epoch: 010 | loss: 0.14876 - acc: 0.9408 -- iter: 1408/1750
[A[ATraining Step: 540  | total loss: [1m[32m0.16240[0m[0m | time: 409.151s
[2K
| Adam | epoch: 010 | loss: 0.16240 - acc: 0.9405 -- iter: 1440/1750
[A[ATraining Step: 541  | total loss: [1m[32m0.15349[0m[0m | time: 417.735s
[2K
| Adam | epoch: 010 | loss: 0.15349 - acc: 0.9402 -- iter: 1472/1750
[A[ATraining Step: 542  | total loss: [1m[32m0.14049[0m[0m | time: 426.488s
[2K
| Adam | epoch: 010 | loss: 0.14049 - acc: 0.9462 -- iter: 1504/1750
[A[ATraining Step: 543  | total loss: [1m[32m0.12870[0m[0m | time: 434.887s
[2K
| Adam | epoch: 010 | loss: 0.12870 - acc: 0.9515 -- iter: 1536/1750
[A[ATraining Step: 544  | total loss: [1m[32m0.13387[0m[0m | time: 443.527s
[2K
| Adam | epoch: 010 | loss: 0.13387 - acc: 0.9470 -- iter: 1568/1750
[A[ATraining Step: 545  | total loss: [1m[32m0.12787[0m[0m | time: 452.078s
[2K
| Adam | epoch: 010 | loss: 0.12787 - acc: 0.9492 -- iter: 1600/1750
[A[ATraining Step: 546  | total loss: [1m[32m0.12979[0m[0m | time: 460.714s
[2K
| Adam | epoch: 010 | loss: 0.12979 - acc: 0.9449 -- iter: 1632/1750
[A[ATraining Step: 547  | total loss: [1m[32m0.12535[0m[0m | time: 469.776s
[2K
| Adam | epoch: 010 | loss: 0.12535 - acc: 0.9473 -- iter: 1664/1750
[A[ATraining Step: 548  | total loss: [1m[32m0.11900[0m[0m | time: 478.356s
[2K
| Adam | epoch: 010 | loss: 0.11900 - acc: 0.9494 -- iter: 1696/1750
[A[ATraining Step: 549  | total loss: [1m[32m0.11522[0m[0m | time: 486.934s
[2K
| Adam | epoch: 010 | loss: 0.11522 - acc: 0.9514 -- iter: 1728/1750
[A[ATraining Step: 550  | total loss: [1m[32m0.11535[0m[0m | time: 521.443s
[2K
| Adam | epoch: 010 | loss: 0.11535 - acc: 0.9500 | val_loss: 1.16041 - val_acc: 0.6697 -- iter: 1750/1750
--
Training Step: 551  | total loss: [1m[32m0.11218[0m[0m | time: 8.623s
[2K
| Adam | epoch: 011 | loss: 0.11218 - acc: 0.9518 -- iter: 0032/1750
[A[ATraining Step: 552  | total loss: [1m[32m0.12072[0m[0m | time: 17.232s
[2K
| Adam | epoch: 011 | loss: 0.12072 - acc: 0.9473 -- iter: 0064/1750
[A[ATraining Step: 553  | total loss: [1m[32m0.11328[0m[0m | time: 25.688s
[2K
| Adam | epoch: 011 | loss: 0.11328 - acc: 0.9494 -- iter: 0096/1750
[A[ATraining Step: 554  | total loss: [1m[32m0.11926[0m[0m | time: 34.531s
[2K
| Adam | epoch: 011 | loss: 0.11926 - acc: 0.9451 -- iter: 0128/1750
[A[ATraining Step: 555  | total loss: [1m[32m0.12166[0m[0m | time: 42.798s
[2K
| Adam | epoch: 011 | loss: 0.12166 - acc: 0.9444 -- iter: 0160/1750
[A[ATraining Step: 556  | total loss: [1m[32m0.11424[0m[0m | time: 51.518s
[2K
| Adam | epoch: 011 | loss: 0.11424 - acc: 0.9468 -- iter: 0192/1750
[A[ATraining Step: 557  | total loss: [1m[32m0.11080[0m[0m | time: 60.158s
[2K
| Adam | epoch: 011 | loss: 0.11080 - acc: 0.9459 -- iter: 0224/1750
[A[ATraining Step: 558  | total loss: [1m[32m0.10440[0m[0m | time: 68.825s
[2K
| Adam | epoch: 011 | loss: 0.10440 - acc: 0.9482 -- iter: 0256/1750
[A[ATraining Step: 559  | total loss: [1m[32m0.10163[0m[0m | time: 74.951s
[2K
| Adam | epoch: 011 | loss: 0.10163 - acc: 0.9502 -- iter: 0288/1750
[A[ATraining Step: 560  | total loss: [1m[32m0.10746[0m[0m | time: 81.211s
[2K
| Adam | epoch: 011 | loss: 0.10746 - acc: 0.9461 -- iter: 0320/1750
[A[ATraining Step: 561  | total loss: [1m[32m0.09932[0m[0m | time: 89.823s
[2K
| Adam | epoch: 011 | loss: 0.09932 - acc: 0.9515 -- iter: 0352/1750
[A[ATraining Step: 562  | total loss: [1m[32m0.09613[0m[0m | time: 98.228s
[2K
| Adam | epoch: 011 | loss: 0.09613 - acc: 0.9532 -- iter: 0384/1750
[A[ATraining Step: 563  | total loss: [1m[32m0.11455[0m[0m | time: 106.983s
[2K
| Adam | epoch: 011 | loss: 0.11455 - acc: 0.9548 -- iter: 0416/1750
[A[ATraining Step: 564  | total loss: [1m[32m0.10944[0m[0m | time: 115.471s
[2K
| Adam | epoch: 011 | loss: 0.10944 - acc: 0.9593 -- iter: 0448/1750
[A[ATraining Step: 565  | total loss: [1m[32m0.10117[0m[0m | time: 124.218s
[2K
| Adam | epoch: 011 | loss: 0.10117 - acc: 0.9634 -- iter: 0480/1750
[A[ATraining Step: 566  | total loss: [1m[32m0.09955[0m[0m | time: 132.653s
[2K
| Adam | epoch: 011 | loss: 0.09955 - acc: 0.9670 -- iter: 0512/1750
[A[ATraining Step: 567  | total loss: [1m[32m0.10254[0m[0m | time: 141.426s
[2K
| Adam | epoch: 011 | loss: 0.10254 - acc: 0.9672 -- iter: 0544/1750
[A[ATraining Step: 568  | total loss: [1m[32m0.11068[0m[0m | time: 150.033s
[2K
| Adam | epoch: 011 | loss: 0.11068 - acc: 0.9642 -- iter: 0576/1750
[A[ATraining Step: 569  | total loss: [1m[32m0.11300[0m[0m | time: 159.079s
[2K
| Adam | epoch: 011 | loss: 0.11300 - acc: 0.9647 -- iter: 0608/1750
[A[ATraining Step: 570  | total loss: [1m[32m0.10887[0m[0m | time: 167.693s
[2K
| Adam | epoch: 011 | loss: 0.10887 - acc: 0.9651 -- iter: 0640/1750
[A[ATraining Step: 571  | total loss: [1m[32m0.11669[0m[0m | time: 176.501s
[2K
| Adam | epoch: 011 | loss: 0.11669 - acc: 0.9623 -- iter: 0672/1750
[A[ATraining Step: 572  | total loss: [1m[32m0.10773[0m[0m | time: 184.939s
[2K
| Adam | epoch: 011 | loss: 0.10773 - acc: 0.9661 -- iter: 0704/1750
[A[ATraining Step: 573  | total loss: [1m[32m0.10775[0m[0m | time: 193.693s
[2K
| Adam | epoch: 011 | loss: 0.10775 - acc: 0.9664 -- iter: 0736/1750
[A[ATraining Step: 574  | total loss: [1m[32m0.11450[0m[0m | time: 202.196s
[2K
| Adam | epoch: 011 | loss: 0.11450 - acc: 0.9572 -- iter: 0768/1750
[A[ATraining Step: 575  | total loss: [1m[32m0.11713[0m[0m | time: 210.948s
[2K
| Adam | epoch: 011 | loss: 0.11713 - acc: 0.9553 -- iter: 0800/1750
[A[ATraining Step: 576  | total loss: [1m[32m0.10861[0m[0m | time: 219.472s
[2K
| Adam | epoch: 011 | loss: 0.10861 - acc: 0.9597 -- iter: 0832/1750
[A[ATraining Step: 577  | total loss: [1m[32m0.10649[0m[0m | time: 227.859s
[2K
| Adam | epoch: 011 | loss: 0.10649 - acc: 0.9606 -- iter: 0864/1750
[A[ATraining Step: 578  | total loss: [1m[32m0.10306[0m[0m | time: 236.360s
[2K
| Adam | epoch: 011 | loss: 0.10306 - acc: 0.9614 -- iter: 0896/1750
[A[ATraining Step: 579  | total loss: [1m[32m0.11514[0m[0m | time: 244.763s
[2K
| Adam | epoch: 011 | loss: 0.11514 - acc: 0.9559 -- iter: 0928/1750
[A[ATraining Step: 580  | total loss: [1m[32m0.11466[0m[0m | time: 253.495s
[2K
| Adam | epoch: 011 | loss: 0.11466 - acc: 0.9541 -- iter: 0960/1750
[A[ATraining Step: 581  | total loss: [1m[32m0.11387[0m[0m | time: 262.126s
[2K
| Adam | epoch: 011 | loss: 0.11387 - acc: 0.9555 -- iter: 0992/1750
[A[ATraining Step: 582  | total loss: [1m[32m0.10635[0m[0m | time: 270.736s
[2K
| Adam | epoch: 011 | loss: 0.10635 - acc: 0.9600 -- iter: 1024/1750
[A[ATraining Step: 583  | total loss: [1m[32m0.10658[0m[0m | time: 279.684s
[2K
| Adam | epoch: 011 | loss: 0.10658 - acc: 0.9577 -- iter: 1056/1750
[A[ATraining Step: 584  | total loss: [1m[32m0.10016[0m[0m | time: 288.057s
[2K
| Adam | epoch: 011 | loss: 0.10016 - acc: 0.9620 -- iter: 1088/1750
[A[ATraining Step: 585  | total loss: [1m[32m0.09391[0m[0m | time: 296.511s
[2K
| Adam | epoch: 011 | loss: 0.09391 - acc: 0.9658 -- iter: 1120/1750
[A[ATraining Step: 586  | total loss: [1m[32m0.08872[0m[0m | time: 305.014s
[2K
| Adam | epoch: 011 | loss: 0.08872 - acc: 0.9661 -- iter: 1152/1750
[A[ATraining Step: 587  | total loss: [1m[32m0.08646[0m[0m | time: 313.599s
[2K
| Adam | epoch: 011 | loss: 0.08646 - acc: 0.9663 -- iter: 1184/1750
[A[ATraining Step: 588  | total loss: [1m[32m0.08250[0m[0m | time: 322.008s
[2K
| Adam | epoch: 011 | loss: 0.08250 - acc: 0.9697 -- iter: 1216/1750
[A[ATraining Step: 589  | total loss: [1m[32m0.08199[0m[0m | time: 330.682s
[2K
| Adam | epoch: 011 | loss: 0.08199 - acc: 0.9727 -- iter: 1248/1750
[A[ATraining Step: 590  | total loss: [1m[32m0.07752[0m[0m | time: 339.279s
[2K
| Adam | epoch: 011 | loss: 0.07752 - acc: 0.9755 -- iter: 1280/1750
[A[ATraining Step: 591  | total loss: [1m[32m0.07417[0m[0m | time: 347.571s
[2K
| Adam | epoch: 011 | loss: 0.07417 - acc: 0.9779 -- iter: 1312/1750
[A[ATraining Step: 592  | total loss: [1m[32m0.07243[0m[0m | time: 356.093s
[2K
| Adam | epoch: 011 | loss: 0.07243 - acc: 0.9770 -- iter: 1344/1750
[A[ATraining Step: 593  | total loss: [1m[32m0.06777[0m[0m | time: 364.560s
[2K
| Adam | epoch: 011 | loss: 0.06777 - acc: 0.9793 -- iter: 1376/1750
[A[ATraining Step: 594  | total loss: [1m[32m0.06207[0m[0m | time: 373.348s
[2K
| Adam | epoch: 011 | loss: 0.06207 - acc: 0.9814 -- iter: 1408/1750
[A[ATraining Step: 595  | total loss: [1m[32m0.05838[0m[0m | time: 381.977s
[2K
| Adam | epoch: 011 | loss: 0.05838 - acc: 0.9832 -- iter: 1440/1750
[A[ATraining Step: 596  | total loss: [1m[32m0.06121[0m[0m | time: 390.781s
[2K
| Adam | epoch: 011 | loss: 0.06121 - acc: 0.9787 -- iter: 1472/1750
[A[ATraining Step: 597  | total loss: [1m[32m0.06136[0m[0m | time: 399.163s
[2K
| Adam | epoch: 011 | loss: 0.06136 - acc: 0.9777 -- iter: 1504/1750
[A[ATraining Step: 598  | total loss: [1m[32m0.05639[0m[0m | time: 407.792s
[2K
| Adam | epoch: 011 | loss: 0.05639 - acc: 0.9799 -- iter: 1536/1750
[A[ATraining Step: 599  | total loss: [1m[32m0.05322[0m[0m | time: 416.514s
[2K
| Adam | epoch: 011 | loss: 0.05322 - acc: 0.9819 -- iter: 1568/1750
[A[ATraining Step: 600  | total loss: [1m[32m0.05182[0m[0m | time: 451.075s
[2K
| Adam | epoch: 011 | loss: 0.05182 - acc: 0.9837 | val_loss: 0.49975 - val_acc: 0.8942 -- iter: 1600/1750
--
Training Step: 601  | total loss: [1m[32m0.05083[0m[0m | time: 459.894s
[2K
| Adam | epoch: 011 | loss: 0.05083 - acc: 0.9822 -- iter: 1632/1750
[A[ATraining Step: 602  | total loss: [1m[32m0.06496[0m[0m | time: 468.378s
[2K
| Adam | epoch: 011 | loss: 0.06496 - acc: 0.9778 -- iter: 1664/1750
[A[ATraining Step: 603  | total loss: [1m[32m0.08059[0m[0m | time: 477.386s
[2K
| Adam | epoch: 011 | loss: 0.08059 - acc: 0.9737 -- iter: 1696/1750
[A[ATraining Step: 604  | total loss: [1m[32m0.07282[0m[0m | time: 486.070s
[2K
| Adam | epoch: 011 | loss: 0.07282 - acc: 0.9764 -- iter: 1728/1750
[A[ATraining Step: 605  | total loss: [1m[32m0.06828[0m[0m | time: 520.535s
[2K
| Adam | epoch: 011 | loss: 0.06828 - acc: 0.9787 | val_loss: 0.70591 - val_acc: 0.8723 -- iter: 1750/1750
--
Training Step: 606  | total loss: [1m[32m0.06221[0m[0m | time: 8.506s
[2K
| Adam | epoch: 012 | loss: 0.06221 - acc: 0.9808 -- iter: 0032/1750
[A[ATraining Step: 607  | total loss: [1m[32m0.06341[0m[0m | time: 16.944s
[2K
| Adam | epoch: 012 | loss: 0.06341 - acc: 0.9796 -- iter: 0064/1750
[A[ATraining Step: 608  | total loss: [1m[32m0.07046[0m[0m | time: 25.512s
[2K
| Adam | epoch: 012 | loss: 0.07046 - acc: 0.9785 -- iter: 0096/1750
[A[ATraining Step: 609  | total loss: [1m[32m0.07729[0m[0m | time: 34.205s
[2K
| Adam | epoch: 012 | loss: 0.07729 - acc: 0.9776 -- iter: 0128/1750
[A[ATraining Step: 610  | total loss: [1m[32m0.07109[0m[0m | time: 42.770s
[2K
| Adam | epoch: 012 | loss: 0.07109 - acc: 0.9798 -- iter: 0160/1750
[A[ATraining Step: 611  | total loss: [1m[32m0.06903[0m[0m | time: 51.190s
[2K
| Adam | epoch: 012 | loss: 0.06903 - acc: 0.9787 -- iter: 0192/1750
[A[ATraining Step: 612  | total loss: [1m[32m0.06950[0m[0m | time: 59.664s
[2K
| Adam | epoch: 012 | loss: 0.06950 - acc: 0.9777 -- iter: 0224/1750
[A[ATraining Step: 613  | total loss: [1m[32m0.06629[0m[0m | time: 68.184s
[2K
| Adam | epoch: 012 | loss: 0.06629 - acc: 0.9799 -- iter: 0256/1750
[A[ATraining Step: 614  | total loss: [1m[32m0.07180[0m[0m | time: 76.617s
[2K
| Adam | epoch: 012 | loss: 0.07180 - acc: 0.9788 -- iter: 0288/1750
[A[ATraining Step: 615  | total loss: [1m[32m0.06496[0m[0m | time: 82.680s
[2K
| Adam | epoch: 012 | loss: 0.06496 - acc: 0.9809 -- iter: 0320/1750
[A[ATraining Step: 616  | total loss: [1m[32m0.06321[0m[0m | time: 88.701s
[2K
| Adam | epoch: 012 | loss: 0.06321 - acc: 0.9828 -- iter: 0352/1750
[A[ATraining Step: 617  | total loss: [1m[32m0.05877[0m[0m | time: 97.279s
[2K
| Adam | epoch: 012 | loss: 0.05877 - acc: 0.9846 -- iter: 0384/1750
[A[ATraining Step: 618  | total loss: [1m[32m0.07790[0m[0m | time: 105.789s
[2K
| Adam | epoch: 012 | loss: 0.07790 - acc: 0.9767 -- iter: 0416/1750
[A[ATraining Step: 619  | total loss: [1m[32m0.07496[0m[0m | time: 114.456s
[2K
| Adam | epoch: 012 | loss: 0.07496 - acc: 0.9791 -- iter: 0448/1750
[A[ATraining Step: 620  | total loss: [1m[32m0.06980[0m[0m | time: 123.203s
[2K
| Adam | epoch: 012 | loss: 0.06980 - acc: 0.9812 -- iter: 0480/1750
[A[ATraining Step: 621  | total loss: [1m[32m0.06681[0m[0m | time: 131.853s
[2K
| Adam | epoch: 012 | loss: 0.06681 - acc: 0.9799 -- iter: 0512/1750
[A[ATraining Step: 622  | total loss: [1m[32m0.08015[0m[0m | time: 140.262s
[2K
| Adam | epoch: 012 | loss: 0.08015 - acc: 0.9725 -- iter: 0544/1750
[A[ATraining Step: 623  | total loss: [1m[32m0.07597[0m[0m | time: 148.749s
[2K
| Adam | epoch: 012 | loss: 0.07597 - acc: 0.9753 -- iter: 0576/1750
[A[ATraining Step: 624  | total loss: [1m[32m0.07780[0m[0m | time: 157.349s
[2K
| Adam | epoch: 012 | loss: 0.07780 - acc: 0.9715 -- iter: 0608/1750
[A[ATraining Step: 625  | total loss: [1m[32m0.07315[0m[0m | time: 165.968s
[2K
| Adam | epoch: 012 | loss: 0.07315 - acc: 0.9744 -- iter: 0640/1750
[A[ATraining Step: 626  | total loss: [1m[32m0.07415[0m[0m | time: 174.322s
[2K
| Adam | epoch: 012 | loss: 0.07415 - acc: 0.9738 -- iter: 0672/1750
[A[ATraining Step: 627  | total loss: [1m[32m0.06741[0m[0m | time: 182.670s
[2K
| Adam | epoch: 012 | loss: 0.06741 - acc: 0.9764 -- iter: 0704/1750
[A[ATraining Step: 628  | total loss: [1m[32m0.06383[0m[0m | time: 191.267s
[2K
| Adam | epoch: 012 | loss: 0.06383 - acc: 0.9757 -- iter: 0736/1750
[A[ATraining Step: 629  | total loss: [1m[32m0.07351[0m[0m | time: 199.616s
[2K
| Adam | epoch: 012 | loss: 0.07351 - acc: 0.9718 -- iter: 0768/1750
[A[ATraining Step: 630  | total loss: [1m[32m0.07312[0m[0m | time: 208.145s
[2K
| Adam | epoch: 012 | loss: 0.07312 - acc: 0.9684 -- iter: 0800/1750
[A[ATraining Step: 631  | total loss: [1m[32m0.07035[0m[0m | time: 217.024s
[2K
| Adam | epoch: 012 | loss: 0.07035 - acc: 0.9684 -- iter: 0832/1750
[A[ATraining Step: 632  | total loss: [1m[32m0.06485[0m[0m | time: 225.588s
[2K
| Adam | epoch: 012 | loss: 0.06485 - acc: 0.9716 -- iter: 0864/1750
[A[ATraining Step: 633  | total loss: [1m[32m0.06052[0m[0m | time: 234.199s
[2K
| Adam | epoch: 012 | loss: 0.06052 - acc: 0.9744 -- iter: 0896/1750
[A[ATraining Step: 634  | total loss: [1m[32m0.06083[0m[0m | time: 242.661s
[2K
| Adam | epoch: 012 | loss: 0.06083 - acc: 0.9707 -- iter: 0928/1750
[A[ATraining Step: 635  | total loss: [1m[32m0.05888[0m[0m | time: 251.227s
[2K
| Adam | epoch: 012 | loss: 0.05888 - acc: 0.9705 -- iter: 0960/1750
[A[ATraining Step: 636  | total loss: [1m[32m0.05776[0m[0m | time: 259.791s
[2K
| Adam | epoch: 012 | loss: 0.05776 - acc: 0.9735 -- iter: 0992/1750
[A[ATraining Step: 637  | total loss: [1m[32m0.05774[0m[0m | time: 268.167s
[2K
| Adam | epoch: 012 | loss: 0.05774 - acc: 0.9730 -- iter: 1024/1750
[A[ATraining Step: 638  | total loss: [1m[32m0.06082[0m[0m | time: 276.860s
[2K
| Adam | epoch: 012 | loss: 0.06082 - acc: 0.9726 -- iter: 1056/1750
[A[ATraining Step: 639  | total loss: [1m[32m0.07520[0m[0m | time: 285.485s
[2K
| Adam | epoch: 012 | loss: 0.07520 - acc: 0.9691 -- iter: 1088/1750
[A[ATraining Step: 640  | total loss: [1m[32m0.09246[0m[0m | time: 294.229s
[2K
| Adam | epoch: 012 | loss: 0.09246 - acc: 0.9690 -- iter: 1120/1750
[A[ATraining Step: 641  | total loss: [1m[32m0.08394[0m[0m | time: 302.654s
[2K
| Adam | epoch: 012 | loss: 0.08394 - acc: 0.9721 -- iter: 1152/1750
[A[ATraining Step: 642  | total loss: [1m[32m0.07733[0m[0m | time: 311.252s
[2K
| Adam | epoch: 012 | loss: 0.07733 - acc: 0.9749 -- iter: 1184/1750
[A[ATraining Step: 643  | total loss: [1m[32m0.07113[0m[0m | time: 320.000s
[2K
| Adam | epoch: 012 | loss: 0.07113 - acc: 0.9774 -- iter: 1216/1750
[A[ATraining Step: 644  | total loss: [1m[32m0.08491[0m[0m | time: 328.646s
[2K
| Adam | epoch: 012 | loss: 0.08491 - acc: 0.9734 -- iter: 1248/1750
[A[ATraining Step: 645  | total loss: [1m[32m0.08162[0m[0m | time: 337.188s
[2K
| Adam | epoch: 012 | loss: 0.08162 - acc: 0.9761 -- iter: 1280/1750
[A[ATraining Step: 646  | total loss: [1m[32m0.10100[0m[0m | time: 345.724s
[2K
| Adam | epoch: 012 | loss: 0.10100 - acc: 0.9754 -- iter: 1312/1750
[A[ATraining Step: 647  | total loss: [1m[32m0.09281[0m[0m | time: 354.161s
[2K
| Adam | epoch: 012 | loss: 0.09281 - acc: 0.9778 -- iter: 1344/1750
[A[ATraining Step: 648  | total loss: [1m[32m0.09158[0m[0m | time: 362.682s
[2K
| Adam | epoch: 012 | loss: 0.09158 - acc: 0.9800 -- iter: 1376/1750
[A[ATraining Step: 649  | total loss: [1m[32m0.13478[0m[0m | time: 371.197s
[2K
| Adam | epoch: 012 | loss: 0.13478 - acc: 0.9664 -- iter: 1408/1750
[A[ATraining Step: 650  | total loss: [1m[32m0.12583[0m[0m | time: 379.962s
[2K
| Adam | epoch: 012 | loss: 0.12583 - acc: 0.9666 -- iter: 1440/1750
[A[ATraining Step: 651  | total loss: [1m[32m0.12030[0m[0m | time: 388.508s
[2K
| Adam | epoch: 012 | loss: 0.12030 - acc: 0.9669 -- iter: 1472/1750
[A[ATraining Step: 652  | total loss: [1m[32m0.11628[0m[0m | time: 396.990s
[2K
| Adam | epoch: 012 | loss: 0.11628 - acc: 0.9670 -- iter: 1504/1750
[A[ATraining Step: 653  | total loss: [1m[32m0.11043[0m[0m | time: 405.678s
[2K
| Adam | epoch: 012 | loss: 0.11043 - acc: 0.9672 -- iter: 1536/1750
[A[ATraining Step: 654  | total loss: [1m[32m0.10246[0m[0m | time: 414.429s
[2K
| Adam | epoch: 012 | loss: 0.10246 - acc: 0.9705 -- iter: 1568/1750
[A[ATraining Step: 655  | total loss: [1m[32m0.10396[0m[0m | time: 423.050s
[2K
| Adam | epoch: 012 | loss: 0.10396 - acc: 0.9641 -- iter: 1600/1750
[A[ATraining Step: 656  | total loss: [1m[32m0.10212[0m[0m | time: 431.605s
[2K
| Adam | epoch: 012 | loss: 0.10212 - acc: 0.9645 -- iter: 1632/1750
[A[ATraining Step: 657  | total loss: [1m[32m0.09461[0m[0m | time: 439.663s
[2K
| Adam | epoch: 012 | loss: 0.09461 - acc: 0.9681 -- iter: 1664/1750
[A[ATraining Step: 658  | total loss: [1m[32m0.08945[0m[0m | time: 448.491s
[2K
| Adam | epoch: 012 | loss: 0.08945 - acc: 0.9682 -- iter: 1696/1750
[A[ATraining Step: 659  | total loss: [1m[32m0.08749[0m[0m | time: 457.019s
[2K
| Adam | epoch: 012 | loss: 0.08749 - acc: 0.9682 -- iter: 1728/1750
[A[ATraining Step: 660  | total loss: [1m[32m0.09105[0m[0m | time: 491.655s
[2K
| Adam | epoch: 012 | loss: 0.09105 - acc: 0.9651 | val_loss: 0.68857 - val_acc: 0.8066 -- iter: 1750/1750
--
Training Step: 661  | total loss: [1m[32m0.09823[0m[0m | time: 8.528s
[2K
| Adam | epoch: 013 | loss: 0.09823 - acc: 0.9624 -- iter: 0032/1750
[A[ATraining Step: 662  | total loss: [1m[32m0.09019[0m[0m | time: 17.104s
[2K
| Adam | epoch: 013 | loss: 0.09019 - acc: 0.9661 -- iter: 0064/1750
[A[ATraining Step: 663  | total loss: [1m[32m0.08275[0m[0m | time: 25.566s
[2K
| Adam | epoch: 013 | loss: 0.08275 - acc: 0.9695 -- iter: 0096/1750
[A[ATraining Step: 664  | total loss: [1m[32m0.08505[0m[0m | time: 34.101s
[2K
| Adam | epoch: 013 | loss: 0.08505 - acc: 0.9663 -- iter: 0128/1750
[A[ATraining Step: 665  | total loss: [1m[32m0.07756[0m[0m | time: 42.969s
[2K
| Adam | epoch: 013 | loss: 0.07756 - acc: 0.9697 -- iter: 0160/1750
[A[ATraining Step: 666  | total loss: [1m[32m0.07155[0m[0m | time: 51.454s
[2K
| Adam | epoch: 013 | loss: 0.07155 - acc: 0.9727 -- iter: 0192/1750
[A[ATraining Step: 667  | total loss: [1m[32m0.07036[0m[0m | time: 59.986s
[2K
| Adam | epoch: 013 | loss: 0.07036 - acc: 0.9723 -- iter: 0224/1750
[A[ATraining Step: 668  | total loss: [1m[32m0.06884[0m[0m | time: 68.453s
[2K
| Adam | epoch: 013 | loss: 0.06884 - acc: 0.9720 -- iter: 0256/1750
[A[ATraining Step: 669  | total loss: [1m[32m0.06283[0m[0m | time: 77.062s
[2K
| Adam | epoch: 013 | loss: 0.06283 - acc: 0.9748 -- iter: 0288/1750
[A[ATraining Step: 670  | total loss: [1m[32m0.06174[0m[0m | time: 85.804s
[2K
| Adam | epoch: 013 | loss: 0.06174 - acc: 0.9742 -- iter: 0320/1750
[A[ATraining Step: 671  | total loss: [1m[32m0.08662[0m[0m | time: 92.081s
[2K
| Adam | epoch: 013 | loss: 0.08662 - acc: 0.9674 -- iter: 0352/1750
[A[ATraining Step: 672  | total loss: [1m[32m0.07828[0m[0m | time: 98.290s
[2K
| Adam | epoch: 013 | loss: 0.07828 - acc: 0.9706 -- iter: 0384/1750
[A[ATraining Step: 673  | total loss: [1m[32m0.07067[0m[0m | time: 106.795s
[2K
| Adam | epoch: 013 | loss: 0.07067 - acc: 0.9736 -- iter: 0416/1750
[A[ATraining Step: 674  | total loss: [1m[32m0.06581[0m[0m | time: 115.021s
[2K
| Adam | epoch: 013 | loss: 0.06581 - acc: 0.9762 -- iter: 0448/1750
[A[ATraining Step: 675  | total loss: [1m[32m0.08600[0m[0m | time: 123.854s
[2K
| Adam | epoch: 013 | loss: 0.08600 - acc: 0.9692 -- iter: 0480/1750
[A[ATraining Step: 676  | total loss: [1m[32m0.11994[0m[0m | time: 132.782s
[2K
| Adam | epoch: 013 | loss: 0.11994 - acc: 0.9535 -- iter: 0512/1750
[A[ATraining Step: 677  | total loss: [1m[32m0.11338[0m[0m | time: 141.240s
[2K
| Adam | epoch: 013 | loss: 0.11338 - acc: 0.9551 -- iter: 0544/1750
[A[ATraining Step: 678  | total loss: [1m[32m0.10524[0m[0m | time: 149.855s
[2K
| Adam | epoch: 013 | loss: 0.10524 - acc: 0.9564 -- iter: 0576/1750
[A[ATraining Step: 679  | total loss: [1m[32m0.10377[0m[0m | time: 158.668s
[2K
| Adam | epoch: 013 | loss: 0.10377 - acc: 0.9545 -- iter: 0608/1750
[A[ATraining Step: 680  | total loss: [1m[32m0.11500[0m[0m | time: 167.272s
[2K
| Adam | epoch: 013 | loss: 0.11500 - acc: 0.9497 -- iter: 0640/1750
[A[ATraining Step: 681  | total loss: [1m[32m0.10692[0m[0m | time: 175.843s
[2K
| Adam | epoch: 013 | loss: 0.10692 - acc: 0.9547 -- iter: 0672/1750
[A[ATraining Step: 682  | total loss: [1m[32m0.11543[0m[0m | time: 184.510s
[2K
| Adam | epoch: 013 | loss: 0.11543 - acc: 0.9530 -- iter: 0704/1750
[A[ATraining Step: 683  | total loss: [1m[32m0.10927[0m[0m | time: 193.004s
[2K
| Adam | epoch: 013 | loss: 0.10927 - acc: 0.9577 -- iter: 0736/1750
[A[ATraining Step: 684  | total loss: [1m[32m0.10798[0m[0m | time: 201.567s
[2K
| Adam | epoch: 013 | loss: 0.10798 - acc: 0.9557 -- iter: 0768/1750
[A[ATraining Step: 685  | total loss: [1m[32m0.10367[0m[0m | time: 210.276s
[2K
| Adam | epoch: 013 | loss: 0.10367 - acc: 0.9570 -- iter: 0800/1750
[A[ATraining Step: 686  | total loss: [1m[32m0.09701[0m[0m | time: 218.814s
[2K
| Adam | epoch: 013 | loss: 0.09701 - acc: 0.9582 -- iter: 0832/1750
[A[ATraining Step: 687  | total loss: [1m[32m0.09438[0m[0m | time: 227.712s
[2K
| Adam | epoch: 013 | loss: 0.09438 - acc: 0.9592 -- iter: 0864/1750
[A[ATraining Step: 688  | total loss: [1m[32m0.10049[0m[0m | time: 236.538s
[2K
| Adam | epoch: 013 | loss: 0.10049 - acc: 0.9571 -- iter: 0896/1750
[A[ATraining Step: 689  | total loss: [1m[32m0.09493[0m[0m | time: 245.389s
[2K
| Adam | epoch: 013 | loss: 0.09493 - acc: 0.9614 -- iter: 0928/1750
[A[ATraining Step: 690  | total loss: [1m[32m0.10990[0m[0m | time: 253.955s
[2K
| Adam | epoch: 013 | loss: 0.10990 - acc: 0.9496 -- iter: 0960/1750
[A[ATraining Step: 691  | total loss: [1m[32m0.10716[0m[0m | time: 262.545s
[2K
| Adam | epoch: 013 | loss: 0.10716 - acc: 0.9484 -- iter: 0992/1750
[A[ATraining Step: 692  | total loss: [1m[32m0.11425[0m[0m | time: 271.122s
[2K
| Adam | epoch: 013 | loss: 0.11425 - acc: 0.9473 -- iter: 1024/1750
[A[ATraining Step: 693  | total loss: [1m[32m0.10503[0m[0m | time: 279.774s
[2K
| Adam | epoch: 013 | loss: 0.10503 - acc: 0.9526 -- iter: 1056/1750
[A[ATraining Step: 694  | total loss: [1m[32m0.10771[0m[0m | time: 288.678s
[2K
| Adam | epoch: 013 | loss: 0.10771 - acc: 0.9542 -- iter: 1088/1750
[A[ATraining Step: 695  | total loss: [1m[32m0.09946[0m[0m | time: 297.131s
[2K
| Adam | epoch: 013 | loss: 0.09946 - acc: 0.9588 -- iter: 1120/1750
[A[ATraining Step: 696  | total loss: [1m[32m0.15279[0m[0m | time: 305.956s
[2K
| Adam | epoch: 013 | loss: 0.15279 - acc: 0.9566 -- iter: 1152/1750
[A[ATraining Step: 697  | total loss: [1m[32m0.15365[0m[0m | time: 314.623s
[2K
| Adam | epoch: 013 | loss: 0.15365 - acc: 0.9547 -- iter: 1184/1750
[A[ATraining Step: 698  | total loss: [1m[32m0.14162[0m[0m | time: 323.508s
[2K
| Adam | epoch: 013 | loss: 0.14162 - acc: 0.9593 -- iter: 1216/1750
[A[ATraining Step: 699  | total loss: [1m[32m0.12852[0m[0m | time: 332.352s
[2K
| Adam | epoch: 013 | loss: 0.12852 - acc: 0.9633 -- iter: 1248/1750
[A[ATraining Step: 700  | total loss: [1m[32m0.12891[0m[0m | time: 341.197s
[2K
| Adam | epoch: 013 | loss: 0.12891 - acc: 0.9607 -- iter: 1280/1750
[A[ATraining Step: 701  | total loss: [1m[32m0.13483[0m[0m | time: 349.757s
[2K
| Adam | epoch: 013 | loss: 0.13483 - acc: 0.9615 -- iter: 1312/1750
[A[ATraining Step: 702  | total loss: [1m[32m0.12451[0m[0m | time: 358.608s
[2K
| Adam | epoch: 013 | loss: 0.12451 - acc: 0.9654 -- iter: 1344/1750
[A[ATraining Step: 703  | total loss: [1m[32m0.11476[0m[0m | time: 367.264s
[2K
| Adam | epoch: 013 | loss: 0.11476 - acc: 0.9689 -- iter: 1376/1750
[A[ATraining Step: 704  | total loss: [1m[32m0.11238[0m[0m | time: 375.779s
[2K
| Adam | epoch: 013 | loss: 0.11238 - acc: 0.9657 -- iter: 1408/1750
[A[ATraining Step: 705  | total loss: [1m[32m0.10402[0m[0m | time: 384.147s
[2K
| Adam | epoch: 013 | loss: 0.10402 - acc: 0.9691 -- iter: 1440/1750
[A[ATraining Step: 706  | total loss: [1m[32m0.10073[0m[0m | time: 392.755s
[2K
| Adam | epoch: 013 | loss: 0.10073 - acc: 0.9691 -- iter: 1472/1750
[A[ATraining Step: 707  | total loss: [1m[32m0.09200[0m[0m | time: 401.470s
[2K
| Adam | epoch: 013 | loss: 0.09200 - acc: 0.9722 -- iter: 1504/1750
[A[ATraining Step: 708  | total loss: [1m[32m0.08765[0m[0m | time: 410.124s
[2K
| Adam | epoch: 013 | loss: 0.08765 - acc: 0.9719 -- iter: 1536/1750
[A[ATraining Step: 709  | total loss: [1m[32m0.08681[0m[0m | time: 418.861s
[2K
| Adam | epoch: 013 | loss: 0.08681 - acc: 0.9715 -- iter: 1568/1750
[A[ATraining Step: 710  | total loss: [1m[32m0.07957[0m[0m | time: 427.228s
[2K
| Adam | epoch: 013 | loss: 0.07957 - acc: 0.9744 -- iter: 1600/1750
[A[ATraining Step: 711  | total loss: [1m[32m0.07662[0m[0m | time: 435.885s
[2K
| Adam | epoch: 013 | loss: 0.07662 - acc: 0.9738 -- iter: 1632/1750
[A[ATraining Step: 712  | total loss: [1m[32m0.08817[0m[0m | time: 444.525s
[2K
| Adam | epoch: 013 | loss: 0.08817 - acc: 0.9671 -- iter: 1664/1750
[A[ATraining Step: 713  | total loss: [1m[32m0.08145[0m[0m | time: 453.226s
[2K
| Adam | epoch: 013 | loss: 0.08145 - acc: 0.9704 -- iter: 1696/1750
[A[ATraining Step: 714  | total loss: [1m[32m0.09070[0m[0m | time: 461.847s
[2K
| Adam | epoch: 013 | loss: 0.09070 - acc: 0.9671 -- iter: 1728/1750
[A[ATraining Step: 715  | total loss: [1m[32m0.08339[0m[0m | time: 496.784s
[2K
| Adam | epoch: 013 | loss: 0.08339 - acc: 0.9704 | val_loss: 0.42074 - val_acc: 0.8540 -- iter: 1750/1750
--
Training Step: 716  | total loss: [1m[32m0.07922[0m[0m | time: 8.674s
[2K
| Adam | epoch: 014 | loss: 0.07922 - acc: 0.9702 -- iter: 0032/1750
[A[ATraining Step: 717  | total loss: [1m[32m0.08633[0m[0m | time: 17.726s
[2K
| Adam | epoch: 014 | loss: 0.08633 - acc: 0.9701 -- iter: 0064/1750
[A[ATraining Step: 718  | total loss: [1m[32m0.09216[0m[0m | time: 26.604s
[2K
| Adam | epoch: 014 | loss: 0.09216 - acc: 0.9699 -- iter: 0096/1750
[A[ATraining Step: 719  | total loss: [1m[32m0.09023[0m[0m | time: 35.573s
[2K
| Adam | epoch: 014 | loss: 0.09023 - acc: 0.9667 -- iter: 0128/1750
[A[ATraining Step: 720  | total loss: [1m[32m0.08287[0m[0m | time: 44.176s
[2K
| Adam | epoch: 014 | loss: 0.08287 - acc: 0.9700 -- iter: 0160/1750
[A[ATraining Step: 721  | total loss: [1m[32m0.07966[0m[0m | time: 52.847s
[2K
| Adam | epoch: 014 | loss: 0.07966 - acc: 0.9699 -- iter: 0192/1750
[A[ATraining Step: 722  | total loss: [1m[32m0.07459[0m[0m | time: 61.597s
[2K
| Adam | epoch: 014 | loss: 0.07459 - acc: 0.9729 -- iter: 0224/1750
[A[ATraining Step: 723  | total loss: [1m[32m0.06792[0m[0m | time: 70.179s
[2K
| Adam | epoch: 014 | loss: 0.06792 - acc: 0.9756 -- iter: 0256/1750
[A[ATraining Step: 724  | total loss: [1m[32m0.06907[0m[0m | time: 78.840s
[2K
| Adam | epoch: 014 | loss: 0.06907 - acc: 0.9718 -- iter: 0288/1750
[A[ATraining Step: 725  | total loss: [1m[32m0.06485[0m[0m | time: 87.733s
[2K
| Adam | epoch: 014 | loss: 0.06485 - acc: 0.9715 -- iter: 0320/1750
[A[ATraining Step: 726  | total loss: [1m[32m0.06110[0m[0m | time: 96.422s
[2K
| Adam | epoch: 014 | loss: 0.06110 - acc: 0.9712 -- iter: 0352/1750
[A[ATraining Step: 727  | total loss: [1m[32m0.07818[0m[0m | time: 102.706s
[2K
| Adam | epoch: 014 | loss: 0.07818 - acc: 0.9647 -- iter: 0384/1750
[A[ATraining Step: 728  | total loss: [1m[32m0.07328[0m[0m | time: 109.078s
[2K
| Adam | epoch: 014 | loss: 0.07328 - acc: 0.9683 -- iter: 0416/1750
[A[ATraining Step: 729  | total loss: [1m[32m0.06742[0m[0m | time: 117.706s
[2K
| Adam | epoch: 014 | loss: 0.06742 - acc: 0.9714 -- iter: 0448/1750
[A[ATraining Step: 730  | total loss: [1m[32m0.06433[0m[0m | time: 126.558s
[2K
| Adam | epoch: 014 | loss: 0.06433 - acc: 0.9712 -- iter: 0480/1750
[A[ATraining Step: 731  | total loss: [1m[32m0.06173[0m[0m | time: 135.403s
[2K
| Adam | epoch: 014 | loss: 0.06173 - acc: 0.9740 -- iter: 0512/1750
[A[ATraining Step: 732  | total loss: [1m[32m0.06441[0m[0m | time: 144.096s
[2K
| Adam | epoch: 014 | loss: 0.06441 - acc: 0.9704 -- iter: 0544/1750
[A[ATraining Step: 733  | total loss: [1m[32m0.07039[0m[0m | time: 153.292s
[2K
| Adam | epoch: 014 | loss: 0.07039 - acc: 0.9702 -- iter: 0576/1750
[A[ATraining Step: 734  | total loss: [1m[32m0.06554[0m[0m | time: 162.122s
[2K
| Adam | epoch: 014 | loss: 0.06554 - acc: 0.9732 -- iter: 0608/1750
[A[ATraining Step: 735  | total loss: [1m[32m0.06949[0m[0m | time: 171.015s
[2K
| Adam | epoch: 014 | loss: 0.06949 - acc: 0.9728 -- iter: 0640/1750
[A[ATraining Step: 736  | total loss: [1m[32m0.07405[0m[0m | time: 179.938s
[2K
| Adam | epoch: 014 | loss: 0.07405 - acc: 0.9724 -- iter: 0672/1750
[A[ATraining Step: 737  | total loss: [1m[32m0.07427[0m[0m | time: 189.119s
[2K
| Adam | epoch: 014 | loss: 0.07427 - acc: 0.9689 -- iter: 0704/1750
[A[ATraining Step: 738  | total loss: [1m[32m0.07446[0m[0m | time: 197.669s
[2K
| Adam | epoch: 014 | loss: 0.07446 - acc: 0.9689 -- iter: 0736/1750
[A[ATraining Step: 739  | total loss: [1m[32m0.07131[0m[0m | time: 206.338s
[2K
| Adam | epoch: 014 | loss: 0.07131 - acc: 0.9720 -- iter: 0768/1750
[A[ATraining Step: 740  | total loss: [1m[32m0.07873[0m[0m | time: 215.069s
[2K
| Adam | epoch: 014 | loss: 0.07873 - acc: 0.9685 -- iter: 0800/1750
[A[ATraining Step: 741  | total loss: [1m[32m0.08153[0m[0m | time: 223.542s
[2K
| Adam | epoch: 014 | loss: 0.08153 - acc: 0.9685 -- iter: 0832/1750
[A[ATraining Step: 742  | total loss: [1m[32m0.07575[0m[0m | time: 232.255s
[2K
| Adam | epoch: 014 | loss: 0.07575 - acc: 0.9717 -- iter: 0864/1750
[A[ATraining Step: 743  | total loss: [1m[32m0.07500[0m[0m | time: 241.235s
[2K
| Adam | epoch: 014 | loss: 0.07500 - acc: 0.9714 -- iter: 0896/1750
[A[ATraining Step: 744  | total loss: [1m[32m0.07456[0m[0m | time: 249.913s
[2K
| Adam | epoch: 014 | loss: 0.07456 - acc: 0.9711 -- iter: 0928/1750
[A[ATraining Step: 745  | total loss: [1m[32m0.06893[0m[0m | time: 258.884s
[2K
| Adam | epoch: 014 | loss: 0.06893 - acc: 0.9740 -- iter: 0960/1750
[A[ATraining Step: 746  | total loss: [1m[32m0.06477[0m[0m | time: 267.837s
[2K
| Adam | epoch: 014 | loss: 0.06477 - acc: 0.9766 -- iter: 0992/1750
[A[ATraining Step: 747  | total loss: [1m[32m0.06175[0m[0m | time: 276.393s
[2K
| Adam | epoch: 014 | loss: 0.06175 - acc: 0.9758 -- iter: 1024/1750
[A[ATraining Step: 748  | total loss: [1m[32m0.05795[0m[0m | time: 285.003s
[2K
| Adam | epoch: 014 | loss: 0.05795 - acc: 0.9782 -- iter: 1056/1750
[A[ATraining Step: 749  | total loss: [1m[32m0.05693[0m[0m | time: 294.120s
[2K
| Adam | epoch: 014 | loss: 0.05693 - acc: 0.9773 -- iter: 1088/1750
[A[ATraining Step: 750  | total loss: [1m[32m0.05738[0m[0m | time: 303.268s
[2K
| Adam | epoch: 014 | loss: 0.05738 - acc: 0.9733 -- iter: 1120/1750
[A[ATraining Step: 751  | total loss: [1m[32m0.06575[0m[0m | time: 311.920s
[2K
| Adam | epoch: 014 | loss: 0.06575 - acc: 0.9697 -- iter: 1152/1750
[A[ATraining Step: 752  | total loss: [1m[32m0.06236[0m[0m | time: 320.836s
[2K
| Adam | epoch: 014 | loss: 0.06236 - acc: 0.9728 -- iter: 1184/1750
[A[ATraining Step: 753  | total loss: [1m[32m0.09816[0m[0m | time: 329.704s
[2K
| Adam | epoch: 014 | loss: 0.09816 - acc: 0.9630 -- iter: 1216/1750
[A[ATraining Step: 754  | total loss: [1m[32m0.09649[0m[0m | time: 338.534s
[2K
| Adam | epoch: 014 | loss: 0.09649 - acc: 0.9573 -- iter: 1248/1750
[A[ATraining Step: 755  | total loss: [1m[32m0.08745[0m[0m | time: 347.230s
[2K
| Adam | epoch: 014 | loss: 0.08745 - acc: 0.9616 -- iter: 1280/1750
[A[ATraining Step: 756  | total loss: [1m[32m0.13457[0m[0m | time: 355.947s
[2K
| Adam | epoch: 014 | loss: 0.13457 - acc: 0.9467 -- iter: 1312/1750
[A[ATraining Step: 757  | total loss: [1m[32m0.12203[0m[0m | time: 364.712s
[2K
| Adam | epoch: 014 | loss: 0.12203 - acc: 0.9520 -- iter: 1344/1750
[A[ATraining Step: 758  | total loss: [1m[32m0.11050[0m[0m | time: 373.526s
[2K
| Adam | epoch: 014 | loss: 0.11050 - acc: 0.9568 -- iter: 1376/1750
[A[ATraining Step: 759  | total loss: [1m[32m0.09998[0m[0m | time: 382.148s
[2K
| Adam | epoch: 014 | loss: 0.09998 - acc: 0.9611 -- iter: 1408/1750
[A[ATraining Step: 760  | total loss: [1m[32m0.10698[0m[0m | time: 390.865s
[2K
| Adam | epoch: 014 | loss: 0.10698 - acc: 0.9619 -- iter: 1440/1750
[A[ATraining Step: 761  | total loss: [1m[32m0.11002[0m[0m | time: 399.724s
[2K
| Adam | epoch: 014 | loss: 0.11002 - acc: 0.9594 -- iter: 1472/1750
[A[ATraining Step: 762  | total loss: [1m[32m0.12236[0m[0m | time: 408.579s
[2K
| Adam | epoch: 014 | loss: 0.12236 - acc: 0.9573 -- iter: 1504/1750
[A[ATraining Step: 763  | total loss: [1m[32m0.11284[0m[0m | time: 417.173s
[2K
| Adam | epoch: 014 | loss: 0.11284 - acc: 0.9615 -- iter: 1536/1750
[A[ATraining Step: 764  | total loss: [1m[32m0.10579[0m[0m | time: 425.912s
[2K
| Adam | epoch: 014 | loss: 0.10579 - acc: 0.9654 -- iter: 1568/1750
[A[ATraining Step: 765  | total loss: [1m[32m0.10895[0m[0m | time: 434.466s
[2K
| Adam | epoch: 014 | loss: 0.10895 - acc: 0.9595 -- iter: 1600/1750
[A[ATraining Step: 766  | total loss: [1m[32m0.10049[0m[0m | time: 443.057s
[2K
| Adam | epoch: 014 | loss: 0.10049 - acc: 0.9635 -- iter: 1632/1750
[A[ATraining Step: 767  | total loss: [1m[32m0.09525[0m[0m | time: 451.673s
[2K
| Adam | epoch: 014 | loss: 0.09525 - acc: 0.9672 -- iter: 1664/1750
[A[ATraining Step: 768  | total loss: [1m[32m0.09003[0m[0m | time: 460.274s
[2K
| Adam | epoch: 014 | loss: 0.09003 - acc: 0.9673 -- iter: 1696/1750
[A[ATraining Step: 769  | total loss: [1m[32m0.09928[0m[0m | time: 469.033s
[2K
| Adam | epoch: 014 | loss: 0.09928 - acc: 0.9612 -- iter: 1728/1750
[A[ATraining Step: 770  | total loss: [1m[32m0.12213[0m[0m | time: 505.505s
[2K
| Adam | epoch: 014 | loss: 0.12213 - acc: 0.9588 | val_loss: 0.63819 - val_acc: 0.8339 -- iter: 1750/1750
--
Training Step: 771  | total loss: [1m[32m0.11278[0m[0m | time: 8.617s
[2K
| Adam | epoch: 015 | loss: 0.11278 - acc: 0.9630 -- iter: 0032/1750
[A[ATraining Step: 772  | total loss: [1m[32m0.13173[0m[0m | time: 17.535s
[2K
| Adam | epoch: 015 | loss: 0.13173 - acc: 0.9542 -- iter: 0064/1750
[A[ATraining Step: 773  | total loss: [1m[32m0.12053[0m[0m | time: 26.747s
[2K
| Adam | epoch: 015 | loss: 0.12053 - acc: 0.9587 -- iter: 0096/1750
[A[ATraining Step: 774  | total loss: [1m[32m0.12160[0m[0m | time: 35.535s
[2K
| Adam | epoch: 015 | loss: 0.12160 - acc: 0.9566 -- iter: 0128/1750
[A[ATraining Step: 775  | total loss: [1m[32m0.12686[0m[0m | time: 44.424s
[2K
| Adam | epoch: 015 | loss: 0.12686 - acc: 0.9485 -- iter: 0160/1750
[A[ATraining Step: 776  | total loss: [1m[32m0.11963[0m[0m | time: 53.120s
[2K
| Adam | epoch: 015 | loss: 0.11963 - acc: 0.9536 -- iter: 0192/1750
[A[ATraining Step: 777  | total loss: [1m[32m0.10916[0m[0m | time: 61.657s
[2K
| Adam | epoch: 015 | loss: 0.10916 - acc: 0.9583 -- iter: 0224/1750
[A[ATraining Step: 778  | total loss: [1m[32m0.10531[0m[0m | time: 70.569s
[2K
| Adam | epoch: 015 | loss: 0.10531 - acc: 0.9593 -- iter: 0256/1750
[A[ATraining Step: 779  | total loss: [1m[32m0.09564[0m[0m | time: 79.547s
[2K
| Adam | epoch: 015 | loss: 0.09564 - acc: 0.9634 -- iter: 0288/1750
[A[ATraining Step: 780  | total loss: [1m[32m0.09012[0m[0m | time: 88.268s
[2K
| Adam | epoch: 015 | loss: 0.09012 - acc: 0.9639 -- iter: 0320/1750
[A[ATraining Step: 781  | total loss: [1m[32m0.10791[0m[0m | time: 96.890s
[2K
| Adam | epoch: 015 | loss: 0.10791 - acc: 0.9550 -- iter: 0352/1750
[A[ATraining Step: 782  | total loss: [1m[32m0.10032[0m[0m | time: 105.732s
[2K
| Adam | epoch: 015 | loss: 0.10032 - acc: 0.9595 -- iter: 0384/1750
[A[ATraining Step: 783  | total loss: [1m[32m0.09530[0m[0m | time: 112.285s
[2K
| Adam | epoch: 015 | loss: 0.09530 - acc: 0.9604 -- iter: 0416/1750
[A[ATraining Step: 784  | total loss: [1m[32m0.09092[0m[0m | time: 118.434s
[2K
| Adam | epoch: 015 | loss: 0.09092 - acc: 0.9644 -- iter: 0448/1750
[A[ATraining Step: 785  | total loss: [1m[32m0.08433[0m[0m | time: 127.181s
[2K
| Adam | epoch: 015 | loss: 0.08433 - acc: 0.9680 -- iter: 0480/1750
[A[ATraining Step: 786  | total loss: [1m[32m0.08724[0m[0m | time: 136.122s
[2K
| Adam | epoch: 015 | loss: 0.08724 - acc: 0.9618 -- iter: 0512/1750
[A[ATraining Step: 787  | total loss: [1m[32m0.09682[0m[0m | time: 144.977s
[2K
| Adam | epoch: 015 | loss: 0.09682 - acc: 0.9562 -- iter: 0544/1750
[A[ATraining Step: 788  | total loss: [1m[32m0.09913[0m[0m | time: 153.977s
[2K
| Adam | epoch: 015 | loss: 0.09913 - acc: 0.9544 -- iter: 0576/1750
[A[ATraining Step: 789  | total loss: [1m[32m0.09497[0m[0m | time: 162.841s
[2K
| Adam | epoch: 015 | loss: 0.09497 - acc: 0.9558 -- iter: 0608/1750
[A[ATraining Step: 790  | total loss: [1m[32m0.08682[0m[0m | time: 171.718s
[2K
| Adam | epoch: 015 | loss: 0.08682 - acc: 0.9602 -- iter: 0640/1750
[A[ATraining Step: 791  | total loss: [1m[32m0.08030[0m[0m | time: 180.920s
[2K
| Adam | epoch: 015 | loss: 0.08030 - acc: 0.9642 -- iter: 0672/1750
[A[ATraining Step: 792  | total loss: [1m[32m0.08284[0m[0m | time: 190.106s
[2K
| Adam | epoch: 015 | loss: 0.08284 - acc: 0.9615 -- iter: 0704/1750
[A[ATraining Step: 793  | total loss: [1m[32m0.07762[0m[0m | time: 199.085s
[2K
| Adam | epoch: 015 | loss: 0.07762 - acc: 0.9654 -- iter: 0736/1750
[A[ATraining Step: 794  | total loss: [1m[32m0.07579[0m[0m | time: 207.881s
[2K
| Adam | epoch: 015 | loss: 0.07579 - acc: 0.9657 -- iter: 0768/1750
[A[ATraining Step: 795  | total loss: [1m[32m0.07137[0m[0m | time: 216.685s
[2K
| Adam | epoch: 015 | loss: 0.07137 - acc: 0.9691 -- iter: 0800/1750
[A[ATraining Step: 796  | total loss: [1m[32m0.07105[0m[0m | time: 225.237s
[2K
| Adam | epoch: 015 | loss: 0.07105 - acc: 0.9691 -- iter: 0832/1750
[A[ATraining Step: 797  | total loss: [1m[32m0.07455[0m[0m | time: 234.004s
[2K
| Adam | epoch: 015 | loss: 0.07455 - acc: 0.9659 -- iter: 0864/1750
[A[ATraining Step: 798  | total loss: [1m[32m0.08128[0m[0m | time: 242.753s
[2K
| Adam | epoch: 015 | loss: 0.08128 - acc: 0.9631 -- iter: 0896/1750
[A[ATraining Step: 799  | total loss: [1m[32m0.07820[0m[0m | time: 251.507s
[2K
| Adam | epoch: 015 | loss: 0.07820 - acc: 0.9637 -- iter: 0928/1750
[A[ATraining Step: 800  | total loss: [1m[32m0.07903[0m[0m | time: 287.261s
[2K
| Adam | epoch: 015 | loss: 0.07903 - acc: 0.9610 | val_loss: 0.51197 - val_acc: 0.8193 -- iter: 0960/1750
--
Training Step: 801  | total loss: [1m[32m0.07175[0m[0m | time: 295.884s
[2K
| Adam | epoch: 015 | loss: 0.07175 - acc: 0.9649 -- iter: 0992/1750
[A[ATraining Step: 802  | total loss: [1m[32m0.06588[0m[0m | time: 304.643s
[2K
| Adam | epoch: 015 | loss: 0.06588 - acc: 0.9684 -- iter: 1024/1750
[A[ATraining Step: 803  | total loss: [1m[32m0.06144[0m[0m | time: 313.447s
[2K
| Adam | epoch: 015 | loss: 0.06144 - acc: 0.9716 -- iter: 1056/1750
[A[ATraining Step: 804  | total loss: [1m[32m0.06536[0m[0m | time: 322.332s
[2K
| Adam | epoch: 015 | loss: 0.06536 - acc: 0.9682 -- iter: 1088/1750
[A[ATraining Step: 805  | total loss: [1m[32m0.09536[0m[0m | time: 330.928s
[2K
| Adam | epoch: 015 | loss: 0.09536 - acc: 0.9620 -- iter: 1120/1750
[A[ATraining Step: 806  | total loss: [1m[32m0.08722[0m[0m | time: 339.781s
[2K
| Adam | epoch: 015 | loss: 0.08722 - acc: 0.9658 -- iter: 1152/1750
[A[ATraining Step: 807  | total loss: [1m[32m0.07935[0m[0m | time: 348.277s
[2K
| Adam | epoch: 015 | loss: 0.07935 - acc: 0.9692 -- iter: 1184/1750
[A[ATraining Step: 808  | total loss: [1m[32m0.13453[0m[0m | time: 356.996s
[2K
| Adam | epoch: 015 | loss: 0.13453 - acc: 0.9660 -- iter: 1216/1750
[A[ATraining Step: 809  | total loss: [1m[32m0.12480[0m[0m | time: 365.938s
[2K
| Adam | epoch: 015 | loss: 0.12480 - acc: 0.9663 -- iter: 1248/1750
[A[ATraining Step: 810  | total loss: [1m[32m0.11965[0m[0m | time: 374.682s
[2K
| Adam | epoch: 015 | loss: 0.11965 - acc: 0.9666 -- iter: 1280/1750
[A[ATraining Step: 811  | total loss: [1m[32m0.11672[0m[0m | time: 383.594s
[2K
| Adam | epoch: 015 | loss: 0.11672 - acc: 0.9637 -- iter: 1312/1750
[A[ATraining Step: 812  | total loss: [1m[32m0.11153[0m[0m | time: 392.288s
[2K
| Adam | epoch: 015 | loss: 0.11153 - acc: 0.9642 -- iter: 1344/1750
[A[ATraining Step: 813  | total loss: [1m[32m0.14686[0m[0m | time: 401.145s
[2K
| Adam | epoch: 015 | loss: 0.14686 - acc: 0.9552 -- iter: 1376/1750
[A[ATraining Step: 814  | total loss: [1m[32m0.13669[0m[0m | time: 409.954s
[2K
| Adam | epoch: 015 | loss: 0.13669 - acc: 0.9566 -- iter: 1408/1750
[A[ATraining Step: 815  | total loss: [1m[32m0.12382[0m[0m | time: 418.912s
[2K
| Adam | epoch: 015 | loss: 0.12382 - acc: 0.9609 -- iter: 1440/1750
[A[ATraining Step: 816  | total loss: [1m[32m0.11949[0m[0m | time: 427.549s
[2K
| Adam | epoch: 015 | loss: 0.11949 - acc: 0.9617 -- iter: 1472/1750
[A[ATraining Step: 817  | total loss: [1m[32m0.11006[0m[0m | time: 436.349s
[2K
| Adam | epoch: 015 | loss: 0.11006 - acc: 0.9655 -- iter: 1504/1750
[A[ATraining Step: 818  | total loss: [1m[32m0.10041[0m[0m | time: 445.028s
[2K
| Adam | epoch: 015 | loss: 0.10041 - acc: 0.9690 -- iter: 1536/1750
[A[ATraining Step: 819  | total loss: [1m[32m0.09194[0m[0m | time: 453.609s
[2K
| Adam | epoch: 015 | loss: 0.09194 - acc: 0.9721 -- iter: 1568/1750
[A[ATraining Step: 820  | total loss: [1m[32m0.09470[0m[0m | time: 462.385s
[2K
| Adam | epoch: 015 | loss: 0.09470 - acc: 0.9686 -- iter: 1600/1750
[A[ATraining Step: 821  | total loss: [1m[32m0.08660[0m[0m | time: 471.272s
[2K
| Adam | epoch: 015 | loss: 0.08660 - acc: 0.9718 -- iter: 1632/1750
[A[ATraining Step: 822  | total loss: [1m[32m0.08081[0m[0m | time: 480.175s
[2K
| Adam | epoch: 015 | loss: 0.08081 - acc: 0.9746 -- iter: 1664/1750
[A[ATraining Step: 823  | total loss: [1m[32m0.08016[0m[0m | time: 488.740s
[2K
| Adam | epoch: 015 | loss: 0.08016 - acc: 0.9709 -- iter: 1696/1750
[A[ATraining Step: 824  | total loss: [1m[32m0.07306[0m[0m | time: 497.495s
[2K
| Adam | epoch: 015 | loss: 0.07306 - acc: 0.9738 -- iter: 1728/1750
[A[ATraining Step: 825  | total loss: [1m[32m0.06751[0m[0m | time: 533.733s
[2K
| Adam | epoch: 015 | loss: 0.06751 - acc: 0.9764 | val_loss: 0.27212 - val_acc: 0.9252 -- iter: 1750/1750
--
Validation AUC:0.9674046248934357
Validation AUPRC:0.9666496977113228
Test AUC:0.9737073560767591
Test AUPRC:0.9712291047926949
BestTestF1Score	0.92	0.85	0.93	0.94	0.91	244	16	264	24	0.61
BestTestMCCScore	0.92	0.85	0.93	0.94	0.91	244	16	264	24	0.61
BestTestAccuracyScore	0.92	0.85	0.93	0.94	0.91	244	16	264	24	0.61
BestValidationF1Score	0.93	0.86	0.93	0.93	0.92	251	18	258	21	0.61
BestValidationMCC	0.93	0.86	0.93	0.93	0.92	251	18	258	21	0.61
BestValidationAccuracy	0.93	0.86	0.93	0.93	0.92	251	18	258	21	0.61
TestPredictions (Threshold:0.61)
CHEMBL410653,TP,ACT,1.0	CHEMBL328089,TN,INACT,0.0	CHEMBL3349279,TP,ACT,1.0	CHEMBL3403336,FP,INACT,0.9800000190734863	CHEMBL60189,TN,INACT,0.17000000178813934	CHEMBL379284,TP,ACT,0.9800000190734863	CHEMBL34328,TN,INACT,0.009999999776482582	CHEMBL211210,TP,ACT,0.9399999976158142	CHEMBL27716,TP,ACT,0.9900000095367432	CHEMBL449278,TN,INACT,0.0	CHEMBL125925,TN,INACT,0.03999999910593033	CHEMBL239819,TP,ACT,1.0	CHEMBL216741,TN,INACT,0.0	CHEMBL2064141,TP,ACT,0.949999988079071	CHEMBL233748,TP,ACT,1.0	CHEMBL402473,TN,INACT,0.0	CHEMBL466919,TP,ACT,1.0	CHEMBL315391,TN,INACT,0.1599999964237213	CHEMBL60509,TN,INACT,0.009999999776482582	CHEMBL3647961,TP,ACT,1.0	CHEMBL3764246,TN,INACT,0.05000000074505806	CHEMBL59597,TN,INACT,0.03999999910593033	CHEMBL168632,TN,INACT,0.019999999552965164	CHEMBL3349252,TP,ACT,1.0	CHEMBL1650849,TP,ACT,1.0	CHEMBL3326225,TP,ACT,1.0	CHEMBL272592,TP,ACT,1.0	CHEMBL177524,TN,INACT,0.0	CHEMBL3084636,TP,ACT,0.7400000095367432	CHEMBL307614,TN,INACT,0.0	CHEMBL233494,TP,ACT,1.0	CHEMBL3410301,TN,INACT,0.019999999552965164	CHEMBL46195,TN,INACT,0.0	CHEMBL368629,TN,INACT,0.0	CHEMBL2372052,TP,ACT,1.0	CHEMBL3350741,TN,INACT,0.47999998927116394	CHEMBL240074,TP,ACT,1.0	CHEMBL2311547,TN,INACT,0.019999999552965164	CHEMBL3785718,TP,ACT,1.0	CHEMBL2436819,TN,INACT,0.0	CHEMBL165175,TN,INACT,0.0	CHEMBL228858,TP,ACT,1.0	CHEMBL392753,TP,ACT,1.0	CHEMBL3665428,TP,ACT,0.8700000047683716	CHEMBL233820,TP,ACT,1.0	CHEMBL228736,TP,ACT,1.0	CHEMBL417358,TN,INACT,0.0	CHEMBL309194,TN,INACT,0.009999999776482582	CHEMBL114484,TP,ACT,0.9900000095367432	CHEMBL118619,TN,INACT,0.0	CHEMBL3218120,TN,INACT,0.0	CHEMBL2062861,TN,INACT,0.029999999329447746	CHEMBL1079400,FN,ACT,0.47999998927116394	CHEMBL31524,TN,INACT,0.009999999776482582	CHEMBL45456,TN,INACT,0.0	CHEMBL1762388,TP,ACT,0.9700000286102295	CHEMBL233721,TP,ACT,1.0	CHEMBL12529,TN,INACT,0.0	CHEMBL3577342,TN,INACT,0.009999999776482582	CHEMBL516334,TN,INACT,0.1899999976158142	CHEMBL2436717,TN,INACT,0.0	CHEMBL3349264,TP,ACT,1.0	CHEMBL110064,TN,INACT,0.009999999776482582	CHEMBL448155,TP,ACT,0.949999988079071	CHEMBL272084,FN,ACT,0.46000000834465027	CHEMBL118553,TN,INACT,0.1899999976158142	CHEMBL292293,TN,INACT,0.0	CHEMBL434060,TP,ACT,0.9900000095367432	CHEMBL2436721,TN,INACT,0.03999999910593033	CHEMBL3785560,TP,ACT,1.0	CHEMBL554299,TP,ACT,1.0	CHEMBL216821,TN,INACT,0.009999999776482582	CHEMBL1162590,TN,INACT,0.0	CHEMBL1081741,TP,ACT,1.0	CHEMBL1090461,TN,INACT,0.0	CHEMBL3084667,TP,ACT,1.0	CHEMBL2087028,TN,INACT,0.0	CHEMBL480426,TP,ACT,1.0	CHEMBL3325880,TP,ACT,1.0	CHEMBL62660,TN,INACT,0.019999999552965164	CHEMBL2113072,TN,INACT,0.009999999776482582	CHEMBL466067,TP,ACT,1.0	CHEMBL477665,TN,INACT,0.029999999329447746	CHEMBL43330,TN,INACT,0.36000001430511475	CHEMBL438537,TP,ACT,0.9599999785423279	CHEMBL26061,TN,INACT,0.0	CHEMBL413571,TP,ACT,0.9900000095367432	CHEMBL254500,TN,INACT,0.009999999776482582	CHEMBL78830,TN,INACT,0.0	CHEMBL3403733,TN,INACT,0.0	CHEMBL328925,TN,INACT,0.09000000357627869	CHEMBL2163919,TN,INACT,0.0	CHEMBL64000,TN,INACT,0.0	CHEMBL3581756,TP,ACT,1.0	CHEMBL63114,TN,INACT,0.0	CHEMBL3217760,FP,INACT,0.9800000190734863	CHEMBL209213,FN,ACT,0.5299999713897705	CHEMBL63012,TN,INACT,0.07999999821186066	CHEMBL215278,TN,INACT,0.009999999776482582	CHEMBL355851,TN,INACT,0.009999999776482582	CHEMBL2094002,TN,INACT,0.0	CHEMBL468307,TP,ACT,1.0	CHEMBL457451,TP,ACT,1.0	CHEMBL305512,TN,INACT,0.07000000029802322	CHEMBL45269,TN,INACT,0.0	CHEMBL2088042,TP,ACT,1.0	CHEMBL3325705,TN,INACT,0.09000000357627869	CHEMBL240895,TP,ACT,0.9900000095367432	CHEMBL45160,TN,INACT,0.0	CHEMBL283910,TP,ACT,1.0	CHEMBL3349258,TP,ACT,1.0	CHEMBL468953,TP,ACT,1.0	CHEMBL475096,TP,ACT,0.9900000095367432	CHEMBL319356,TN,INACT,0.0	CHEMBL284217,TP,ACT,1.0	CHEMBL62808,TN,INACT,0.17000000178813934	CHEMBL322678,TN,INACT,0.0	CHEMBL3326220,TP,ACT,0.9900000095367432	CHEMBL3084661,TP,ACT,1.0	CHEMBL320228,TN,INACT,0.0	CHEMBL428253,TP,ACT,1.0	CHEMBL2387199,TP,ACT,1.0	CHEMBL3403333,TN,INACT,0.4300000071525574	CHEMBL3665429,TP,ACT,1.0	CHEMBL3262372,TP,ACT,0.9900000095367432	CHEMBL3394754,FN,ACT,0.5699999928474426	CHEMBL285357,TN,INACT,0.28999999165534973	CHEMBL467314,TP,ACT,1.0	CHEMBL424214,TN,INACT,0.0	CHEMBL146462,TP,ACT,0.9900000095367432	CHEMBL560937,TP,ACT,1.0	CHEMBL1916700,TN,INACT,0.3100000023841858	CHEMBL241514,TN,INACT,0.009999999776482582	CHEMBL1983100,TN,INACT,0.019999999552965164	CHEMBL1783821,TP,ACT,1.0	CHEMBL419272,TP,ACT,0.9900000095367432	CHEMBL114074,TN,INACT,0.0	CHEMBL286214,TN,INACT,0.41999998688697815	CHEMBL143341,TN,INACT,0.009999999776482582	CHEMBL286682,TN,INACT,0.009999999776482582	CHEMBL411,TN,INACT,0.0	CHEMBL312268,TN,INACT,0.0	CHEMBL198867,TP,ACT,1.0	CHEMBL87496,TN,INACT,0.0	CHEMBL2062858,TN,INACT,0.0	CHEMBL1437,TN,INACT,0.0	CHEMBL151668,TN,INACT,0.05000000074505806	CHEMBL284969,TN,INACT,0.019999999552965164	CHEMBL310427,TN,INACT,0.0	CHEMBL302359,TN,INACT,0.0	CHEMBL198046,TP,ACT,1.0	CHEMBL89689,TN,INACT,0.0	CHEMBL2112345,TP,ACT,1.0	CHEMBL512247,TP,ACT,0.9800000190734863	CHEMBL112777,TN,INACT,0.0	CHEMBL2371034,TP,ACT,1.0	CHEMBL1782794,TN,INACT,0.029999999329447746	CHEMBL193,TN,INACT,0.0	CHEMBL1762390,FN,ACT,0.009999999776482582	CHEMBL82249,FP,INACT,0.9200000166893005	CHEMBL1702620,TN,INACT,0.03999999910593033	CHEMBL106359,FN,ACT,0.0	CHEMBL103404,TN,INACT,0.0	CHEMBL291516,TN,INACT,0.20000000298023224	CHEMBL2391836,TN,INACT,0.0	CHEMBL3659471,FN,ACT,0.41999998688697815	CHEMBL377542,TN,INACT,0.09000000357627869	CHEMBL3236485,TP,ACT,0.9200000166893005	CHEMBL246585,TN,INACT,0.5299999713897705	CHEMBL95986,TN,INACT,0.009999999776482582	CHEMBL271341,TP,ACT,1.0	CHEMBL419617,TN,INACT,0.0	CHEMBL466252,TP,ACT,0.9900000095367432	CHEMBL262544,TP,ACT,1.0	CHEMBL106487,TN,INACT,0.0	CHEMBL407991,TP,ACT,0.7599999904632568	CHEMBL375781,TN,INACT,0.0	CHEMBL2387197,TP,ACT,1.0	CHEMBL76360,TN,INACT,0.0	CHEMBL589,TN,INACT,0.0	CHEMBL275469,TN,INACT,0.07999999821186066	CHEMBL1428,TN,INACT,0.0	CHEMBL3349276,TP,ACT,1.0	CHEMBL15675,TN,INACT,0.0	CHEMBL374603,TP,ACT,1.0	CHEMBL260768,TP,ACT,1.0	CHEMBL2387189,TP,ACT,1.0	CHEMBL172788,TN,INACT,0.03999999910593033	CHEMBL2436719,TN,INACT,0.029999999329447746	CHEMBL77877,TP,ACT,0.9100000262260437	CHEMBL228686,TP,ACT,1.0	CHEMBL3608763,FP,INACT,0.6499999761581421	CHEMBL382086,FN,ACT,0.6000000238418579	CHEMBL3262545,TP,ACT,1.0	CHEMBL344568,FP,INACT,0.9900000095367432	CHEMBL515554,TP,ACT,1.0	CHEMBL513277,TN,INACT,0.0	CHEMBL200227,TP,ACT,0.9900000095367432	CHEMBL1762393,FN,ACT,0.3100000023841858	CHEMBL72738,TN,INACT,0.03999999910593033	CHEMBL2163568,TN,INACT,0.0	CHEMBL415845,TP,ACT,1.0	CHEMBL414767,TP,ACT,1.0	CHEMBL1079940,TP,ACT,1.0	CHEMBL202220,TP,ACT,0.8600000143051147	CHEMBL119385,TN,INACT,0.03999999910593033	CHEMBL241087,TP,ACT,1.0	CHEMBL3403343,TN,INACT,0.38999998569488525	CHEMBL111105,TP,ACT,1.0	CHEMBL423260,TN,INACT,0.0	CHEMBL232076,TP,ACT,1.0	CHEMBL29782,TN,INACT,0.0	CHEMBL608816,TN,INACT,0.0	CHEMBL238637,TP,ACT,0.9700000286102295	CHEMBL202225,TP,ACT,1.0	CHEMBL109926,TN,INACT,0.0	CHEMBL146013,TP,ACT,0.9700000286102295	CHEMBL316857,TN,INACT,0.0	CHEMBL391518,TP,ACT,1.0	CHEMBL44615,TN,INACT,0.0	CHEMBL426303,TP,ACT,0.9700000286102295	CHEMBL353088,TN,INACT,0.0	CHEMBL466308,TP,ACT,1.0	CHEMBL2088038,TP,ACT,0.9599999785423279	CHEMBL89575,TN,INACT,0.009999999776482582	CHEMBL2088035,TP,ACT,1.0	CHEMBL241083,FP,INACT,0.9300000071525574	CHEMBL325043,TN,INACT,0.0	CHEMBL50740,TN,INACT,0.009999999776482582	CHEMBL142822,TN,INACT,0.019999999552965164	CHEMBL425225,TP,ACT,1.0	CHEMBL417654,TN,INACT,0.0	CHEMBL264846,TP,ACT,0.9900000095367432	CHEMBL1762382,TP,ACT,0.9700000286102295	CHEMBL391422,TP,ACT,1.0	CHEMBL429238,TN,INACT,0.07999999821186066	CHEMBL1782798,TN,INACT,0.0	CHEMBL1916704,TN,INACT,0.0	CHEMBL166089,TN,INACT,0.0	CHEMBL3144469,TP,ACT,0.9900000095367432	CHEMBL418375,TN,INACT,0.0	CHEMBL299538,TN,INACT,0.1899999976158142	CHEMBL234581,TP,ACT,0.9800000190734863	CHEMBL2387194,TP,ACT,1.0	CHEMBL166736,TN,INACT,0.0	CHEMBL541164,TN,INACT,0.0	CHEMBL3262088,TP,ACT,0.8299999833106995	CHEMBL228913,TP,ACT,1.0	CHEMBL543251,TN,INACT,0.009999999776482582	CHEMBL79030,TN,INACT,0.0	CHEMBL1762373,TP,ACT,1.0	CHEMBL240086,TP,ACT,1.0	CHEMBL560468,FN,ACT,0.20000000298023224	CHEMBL201826,TP,ACT,0.9300000071525574	CHEMBL3786338,TP,ACT,1.0	CHEMBL2373213,TN,INACT,0.029999999329447746	CHEMBL1765670,TN,INACT,0.05999999865889549	CHEMBL553082,TN,INACT,0.009999999776482582	CHEMBL67313,TN,INACT,0.0	CHEMBL104848,TN,INACT,0.019999999552965164	CHEMBL291992,TN,INACT,0.009999999776482582	CHEMBL336081,TN,INACT,0.009999999776482582	CHEMBL474708,TP,ACT,1.0	CHEMBL259263,TP,ACT,1.0	CHEMBL1080153,TN,INACT,0.0	CHEMBL182995,TP,ACT,1.0	CHEMBL1782812,TN,INACT,0.07000000029802322	CHEMBL518950,TP,ACT,0.9800000190734863	CHEMBL306645,TN,INACT,0.0	CHEMBL472677,TP,ACT,0.9900000095367432	CHEMBL105483,TN,INACT,0.0	CHEMBL351531,TN,INACT,0.0	CHEMBL371966,FN,ACT,0.5099999904632568	CHEMBL2204353,TP,ACT,0.9599999785423279	CHEMBL421665,TP,ACT,1.0	CHEMBL240023,FP,INACT,0.8700000047683716	CHEMBL7303,TN,INACT,0.0	CHEMBL2387192,TP,ACT,1.0	CHEMBL3218124,TN,INACT,0.5899999737739563	CHEMBL515829,TP,ACT,0.9399999976158142	CHEMBL73133,TN,INACT,0.009999999776482582	CHEMBL608462,TN,INACT,0.0	CHEMBL420359,TN,INACT,0.019999999552965164	CHEMBL410706,TP,ACT,0.9800000190734863	CHEMBL137483,TN,INACT,0.0	CHEMBL562077,TP,ACT,1.0	CHEMBL2207493,FP,INACT,0.9900000095367432	CHEMBL232067,TP,ACT,1.0	CHEMBL1762400,FN,ACT,0.3799999952316284	CHEMBL563686,TP,ACT,0.7900000214576721	CHEMBL3665420,TP,ACT,0.8100000023841858	CHEMBL302027,TN,INACT,0.33000001311302185	CHEMBL552615,TN,INACT,0.009999999776482582	CHEMBL3349266,TP,ACT,0.9900000095367432	CHEMBL511374,TP,ACT,1.0	CHEMBL3403732,TN,INACT,0.0	CHEMBL3647962,TP,ACT,0.9700000286102295	CHEMBL466630,TP,ACT,0.9800000190734863	CHEMBL1080464,TP,ACT,0.9900000095367432	CHEMBL231874,TP,ACT,1.0	CHEMBL3349270,TP,ACT,1.0	CHEMBL324635,TP,ACT,0.949999988079071	CHEMBL302829,TN,INACT,0.09000000357627869	CHEMBL3585387,FN,ACT,0.12999999523162842	CHEMBL1086749,TP,ACT,0.9900000095367432	CHEMBL393356,TP,ACT,1.0	CHEMBL3236484,TP,ACT,0.6200000047683716	CHEMBL439035,TP,ACT,1.0	CHEMBL230253,TP,ACT,1.0	CHEMBL3143400,TN,INACT,0.0	CHEMBL50456,TN,INACT,0.0	CHEMBL2088059,TP,ACT,1.0	CHEMBL1762402,FN,ACT,0.10999999940395355	CHEMBL3394747,TP,ACT,0.9700000286102295	CHEMBL467497,TP,ACT,1.0	CHEMBL345971,TN,INACT,0.0	CHEMBL1765667,TN,INACT,0.05999999865889549	CHEMBL320582,TP,ACT,0.9700000286102295	CHEMBL2088033,TP,ACT,0.75	CHEMBL52735,TN,INACT,0.0	CHEMBL26483,TP,ACT,0.9900000095367432	CHEMBL1076500,FN,ACT,0.05999999865889549	CHEMBL280367,TN,INACT,0.0	CHEMBL403515,TP,ACT,1.0	CHEMBL312266,TN,INACT,0.0	CHEMBL551813,TN,INACT,0.0	CHEMBL240897,TP,ACT,0.9900000095367432	CHEMBL455493,TN,INACT,0.0	CHEMBL10801,TN,INACT,0.0	CHEMBL3740042,FP,INACT,0.800000011920929	CHEMBL3325751,TP,ACT,1.0	CHEMBL468308,TP,ACT,1.0	CHEMBL3325962,TP,ACT,1.0	CHEMBL1762379,TP,ACT,1.0	CHEMBL132222,TN,INACT,0.0	CHEMBL396460,TP,ACT,1.0	CHEMBL3349273,TP,ACT,1.0	CHEMBL202094,TP,ACT,0.9399999976158142	CHEMBL619,TN,INACT,0.0	CHEMBL58228,TN,INACT,0.0	CHEMBL405948,TP,ACT,0.9399999976158142	CHEMBL379657,TP,ACT,0.9900000095367432	CHEMBL472125,TP,ACT,0.9900000095367432	CHEMBL259291,TP,ACT,0.9900000095367432	CHEMBL64727,TN,INACT,0.009999999776482582	CHEMBL130861,FP,INACT,0.6800000071525574	CHEMBL1762385,TP,ACT,1.0	CHEMBL3577344,TN,INACT,0.029999999329447746	CHEMBL2369493,TN,INACT,0.1899999976158142	CHEMBL57908,TN,INACT,0.07000000029802322	CHEMBL11629,TN,INACT,0.0	CHEMBL252198,TN,INACT,0.0	CHEMBL2111766,TN,INACT,0.0	CHEMBL54603,TP,ACT,1.0	CHEMBL467488,TP,ACT,0.9700000286102295	CHEMBL96755,TN,INACT,0.0	CHEMBL373654,TN,INACT,0.4300000071525574	CHEMBL421523,TN,INACT,0.0	CHEMBL3084555,TP,ACT,1.0	CHEMBL2436720,TN,INACT,0.07999999821186066	CHEMBL272873,TN,INACT,0.009999999776482582	CHEMBL1079943,TP,ACT,1.0	CHEMBL2064145,TP,ACT,1.0	CHEMBL208603,TP,ACT,0.9900000095367432	CHEMBL552482,TP,ACT,1.0	CHEMBL1834415,TP,ACT,0.9700000286102295	CHEMBL181342,TP,ACT,1.0	CHEMBL316961,TP,ACT,0.9700000286102295	CHEMBL297599,TN,INACT,0.0	CHEMBL1762380,TP,ACT,0.9800000190734863	CHEMBL370226,TP,ACT,1.0	CHEMBL418105,TP,ACT,1.0	CHEMBL2088057,TP,ACT,1.0	CHEMBL196866,TN,INACT,0.009999999776482582	CHEMBL557576,TN,INACT,0.0	CHEMBL416453,TN,INACT,0.0	CHEMBL3325882,FN,ACT,0.05999999865889549	CHEMBL515901,TP,ACT,0.9800000190734863	CHEMBL1762413,FN,ACT,0.009999999776482582	CHEMBL141078,FN,ACT,0.10000000149011612	CHEMBL25688,TN,INACT,0.019999999552965164	CHEMBL323074,FP,INACT,0.7799999713897705	CHEMBL1783822,TP,ACT,1.0	CHEMBL21328,TN,INACT,0.0	CHEMBL434063,TN,INACT,0.0	CHEMBL64239,TN,INACT,0.0	CHEMBL92539,TN,INACT,0.15000000596046448	CHEMBL594803,TN,INACT,0.0	CHEMBL3326228,TP,ACT,1.0	CHEMBL3290991,TN,INACT,0.009999999776482582	CHEMBL174463,TN,INACT,0.07000000029802322	CHEMBL473068,TP,ACT,0.9800000190734863	CHEMBL377736,TP,ACT,0.7599999904632568	CHEMBL264084,TP,ACT,1.0	CHEMBL286411,TP,ACT,1.0	CHEMBL228793,TP,ACT,1.0	CHEMBL511223,TP,ACT,1.0	CHEMBL121289,TN,INACT,0.0	CHEMBL3114143,TN,INACT,0.0	CHEMBL167335,TN,INACT,0.0	CHEMBL384681,TP,ACT,0.8999999761581421	CHEMBL272600,TP,ACT,1.0	CHEMBL1170027,FP,INACT,0.9800000190734863	CHEMBL436732,TP,ACT,0.9599999785423279	CHEMBL434284,TN,INACT,0.0	CHEMBL560469,TP,ACT,0.9900000095367432	CHEMBL512962,TP,ACT,1.0	CHEMBL321579,TN,INACT,0.0	CHEMBL391486,TP,ACT,1.0	CHEMBL78326,TN,INACT,0.009999999776482582	CHEMBL109509,TP,ACT,0.8500000238418579	CHEMBL28939,TN,INACT,0.07999999821186066	CHEMBL240941,TP,ACT,1.0	CHEMBL513660,TP,ACT,1.0	CHEMBL434944,TP,ACT,1.0	CHEMBL75200,TN,INACT,0.23999999463558197	CHEMBL2088054,TP,ACT,0.9700000286102295	CHEMBL3326224,TP,ACT,1.0	CHEMBL2042401,TN,INACT,0.0	CHEMBL20844,TN,INACT,0.0	CHEMBL311185,TP,ACT,0.9700000286102295	CHEMBL3403340,FP,INACT,0.9900000095367432	CHEMBL357077,TN,INACT,0.0	CHEMBL2387196,TP,ACT,1.0	CHEMBL108904,TP,ACT,1.0	CHEMBL468936,TP,ACT,0.9900000095367432	CHEMBL251997,TN,INACT,0.30000001192092896	CHEMBL2376804,TN,INACT,0.0	CHEMBL3084677,TP,ACT,1.0	CHEMBL27729,TP,ACT,1.0	CHEMBL3585401,TP,ACT,1.0	CHEMBL466702,TP,ACT,0.9800000190734863	CHEMBL2088040,TP,ACT,1.0	CHEMBL549638,TN,INACT,0.6000000238418579	CHEMBL27403,FP,INACT,0.9700000286102295	CHEMBL228850,TP,ACT,1.0	CHEMBL337128,FN,ACT,0.1599999964237213	CHEMBL501756,TN,INACT,0.10000000149011612	CHEMBL3670296,TP,ACT,1.0	CHEMBL364147,TP,ACT,1.0	CHEMBL1087370,TP,ACT,0.7300000190734863	CHEMBL88506,TN,INACT,0.0	CHEMBL121350,TN,INACT,0.27000001072883606	CHEMBL488655,TP,ACT,0.9800000190734863	CHEMBL114891,TN,INACT,0.0	CHEMBL259065,TP,ACT,0.6899999976158142	CHEMBL2322893,TN,INACT,0.0	CHEMBL449966,TP,ACT,1.0	CHEMBL279520,TN,INACT,0.0	CHEMBL378173,FP,INACT,1.0	CHEMBL364625,TP,ACT,0.9900000095367432	CHEMBL75141,TN,INACT,0.0	CHEMBL212574,TP,ACT,1.0	CHEMBL432334,TN,INACT,0.029999999329447746	CHEMBL48448,TN,INACT,0.0	CHEMBL3349274,TP,ACT,1.0	CHEMBL418658,TN,INACT,0.009999999776482582	CHEMBL443765,TP,ACT,1.0	CHEMBL2312376,TN,INACT,0.6000000238418579	CHEMBL149763,TN,INACT,0.44999998807907104	CHEMBL3581261,TN,INACT,0.0	CHEMBL1076625,TN,INACT,0.0	CHEMBL2064157,TP,ACT,1.0	CHEMBL481366,TP,ACT,1.0	CHEMBL606031,TN,INACT,0.0	CHEMBL536034,TN,INACT,0.009999999776482582	CHEMBL1081374,TP,ACT,0.9900000095367432	CHEMBL421349,TN,INACT,0.07000000029802322	CHEMBL469856,TN,INACT,0.0	CHEMBL62703,TN,INACT,0.5799999833106995	CHEMBL259764,TP,ACT,0.9300000071525574	CHEMBL239820,TP,ACT,1.0	CHEMBL64461,TN,INACT,0.05999999865889549	CHEMBL3581752,TP,ACT,1.0	CHEMBL267014,TN,INACT,0.009999999776482582	CHEMBL117036,TN,INACT,0.009999999776482582	CHEMBL103828,TN,INACT,0.0	CHEMBL321248,TN,INACT,0.0	CHEMBL3349262,TP,ACT,1.0	CHEMBL511658,TP,ACT,1.0	CHEMBL211696,TN,INACT,0.5099999904632568	CHEMBL393985,TP,ACT,1.0	CHEMBL3349282,TP,ACT,0.949999988079071	CHEMBL3084541,TP,ACT,1.0	CHEMBL2112346,TP,ACT,0.9900000095367432	CHEMBL168223,TN,INACT,0.009999999776482582	CHEMBL281811,TN,INACT,0.0	CHEMBL322537,TN,INACT,0.0	CHEMBL501088,TP,ACT,1.0	CHEMBL3780633,TN,INACT,0.0	CHEMBL120370,TN,INACT,0.0	CHEMBL401451,TP,ACT,0.9300000071525574	CHEMBL3647958,TP,ACT,1.0	CHEMBL104223,TN,INACT,0.0	CHEMBL3234454,TN,INACT,0.0	CHEMBL362240,TP,ACT,1.0	CHEMBL62066,TN,INACT,0.0	CHEMBL110933,TP,ACT,1.0	CHEMBL515091,TP,ACT,1.0	CHEMBL78668,TN,INACT,0.0	CHEMBL407818,TN,INACT,0.029999999329447746	CHEMBL1081192,TP,ACT,1.0	CHEMBL44463,TN,INACT,0.0	CHEMBL558766,TN,INACT,0.6000000238418579	CHEMBL410115,TN,INACT,0.0	CHEMBL494406,TP,ACT,0.9800000190734863	CHEMBL310361,TN,INACT,0.0	CHEMBL3787051,TP,ACT,1.0	CHEMBL1762389,FN,ACT,0.0	CHEMBL232477,TP,ACT,0.8700000047683716	CHEMBL239822,TP,ACT,1.0	CHEMBL3114165,TN,INACT,0.029999999329447746	CHEMBL451335,TN,INACT,0.0	CHEMBL1093044,TN,INACT,0.009999999776482582	CHEMBL323517,TN,INACT,0.28999999165534973	CHEMBL1760025,FN,ACT,0.5899999737739563	CHEMBL241067,TP,ACT,1.0	CHEMBL162706,TN,INACT,0.0	CHEMBL560993,FP,INACT,0.949999988079071	CHEMBL2112488,TN,INACT,0.0	CHEMBL1088569,FN,ACT,0.09000000357627869	CHEMBL466222,FN,ACT,0.14000000059604645	CHEMBL51675,TN,INACT,0.009999999776482582	CHEMBL200371,TP,ACT,0.9599999785423279	CHEMBL1078642,TN,INACT,0.0	CHEMBL271342,TP,ACT,1.0	CHEMBL306150,TP,ACT,0.8899999856948853	CHEMBL374336,TN,INACT,0.019999999552965164	CHEMBL3589940,TN,INACT,0.0	CHEMBL121307,TN,INACT,0.019999999552965164	CHEMBL513136,TP,ACT,1.0	CHEMBL1098507,TN,INACT,0.019999999552965164	CHEMBL388123,TP,ACT,1.0	CHEMBL21509,TN,INACT,0.0	CHEMBL562663,TP,ACT,0.9700000286102295	CHEMBL63289,TN,INACT,0.009999999776482582	CHEMBL101054,TN,INACT,0.33000001311302185	CHEMBL228849,TP,ACT,1.0	CHEMBL473279,TP,ACT,1.0	CHEMBL3309516,FN,ACT,0.05000000074505806	CHEMBL3326905,TN,INACT,0.009999999776482582	CHEMBL409351,TP,ACT,1.0	CHEMBL283057,TN,INACT,0.0	CHEMBL416019,TN,INACT,0.009999999776482582	CHEMBL415584,TP,ACT,1.0	CHEMBL545185,TN,INACT,0.07999999821186066	CHEMBL490,TN,INACT,0.019999999552965164	CHEMBL422701,TN,INACT,0.0	

