CNNModel CHEMBL5102 adam 0.0005 15 32 0 0.6 False True
Number of active compounds :	501
Number of inactive compounds :	334
---------------------------------
Run id: CNNModel_CHEMBL5102_adam_0.0005_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5102_adam_0.0005_15_32_0.6_True/
---------------------------------
Training samples: 502
Validation samples: 157
--
Training Step: 1  | time: 1.606s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/502
[A[ATraining Step: 2  | total loss: [1m[32m0.62388[0m[0m | time: 2.654s
[2K
| Adam | epoch: 001 | loss: 0.62388 - acc: 0.4219 -- iter: 064/502
[A[ATraining Step: 3  | total loss: [1m[32m0.67821[0m[0m | time: 3.766s
[2K
| Adam | epoch: 001 | loss: 0.67821 - acc: 0.5881 -- iter: 096/502
[A[ATraining Step: 4  | total loss: [1m[32m0.67850[0m[0m | time: 4.782s
[2K
| Adam | epoch: 001 | loss: 0.67850 - acc: 0.6626 -- iter: 128/502
[A[ATraining Step: 5  | total loss: [1m[32m0.69139[0m[0m | time: 5.934s
[2K
| Adam | epoch: 001 | loss: 0.69139 - acc: 0.5500 -- iter: 160/502
[A[ATraining Step: 6  | total loss: [1m[32m0.69412[0m[0m | time: 7.189s
[2K
| Adam | epoch: 001 | loss: 0.69412 - acc: 0.5380 -- iter: 192/502
[A[ATraining Step: 7  | total loss: [1m[32m0.67040[0m[0m | time: 8.396s
[2K
| Adam | epoch: 001 | loss: 0.67040 - acc: 0.6277 -- iter: 224/502
[A[ATraining Step: 8  | total loss: [1m[32m0.67316[0m[0m | time: 9.566s
[2K
| Adam | epoch: 001 | loss: 0.67316 - acc: 0.6086 -- iter: 256/502
[A[ATraining Step: 9  | total loss: [1m[32m0.68861[0m[0m | time: 10.680s
[2K
| Adam | epoch: 001 | loss: 0.68861 - acc: 0.5676 -- iter: 288/502
[A[ATraining Step: 10  | total loss: [1m[32m0.69645[0m[0m | time: 12.043s
[2K
| Adam | epoch: 001 | loss: 0.69645 - acc: 0.5494 -- iter: 320/502
[A[ATraining Step: 11  | total loss: [1m[32m0.69254[0m[0m | time: 14.018s
[2K
| Adam | epoch: 001 | loss: 0.69254 - acc: 0.5556 -- iter: 352/502
[A[ATraining Step: 12  | total loss: [1m[32m0.68567[0m[0m | time: 15.136s
[2K
| Adam | epoch: 001 | loss: 0.68567 - acc: 0.5728 -- iter: 384/502
[A[ATraining Step: 13  | total loss: [1m[32m0.67972[0m[0m | time: 16.228s
[2K
| Adam | epoch: 001 | loss: 0.67972 - acc: 0.5952 -- iter: 416/502
[A[ATraining Step: 14  | total loss: [1m[32m0.68212[0m[0m | time: 17.436s
[2K
| Adam | epoch: 001 | loss: 0.68212 - acc: 0.5818 -- iter: 448/502
[A[ATraining Step: 15  | total loss: [1m[32m0.69530[0m[0m | time: 18.607s
[2K
| Adam | epoch: 001 | loss: 0.69530 - acc: 0.5131 -- iter: 480/502
[A[ATraining Step: 16  | total loss: [1m[32m0.68561[0m[0m | time: 20.569s
[2K
| Adam | epoch: 001 | loss: 0.68561 - acc: 0.5668 | val_loss: 0.68147 - val_acc: 0.5924 -- iter: 502/502
--
Training Step: 17  | total loss: [1m[32m0.68412[0m[0m | time: 0.670s
[2K
| Adam | epoch: 002 | loss: 0.68412 - acc: 0.5755 -- iter: 032/502
[A[ATraining Step: 18  | total loss: [1m[32m0.68340[0m[0m | time: 1.954s
[2K
| Adam | epoch: 002 | loss: 0.68340 - acc: 0.5808 -- iter: 064/502
[A[ATraining Step: 19  | total loss: [1m[32m0.68270[0m[0m | time: 3.300s
[2K
| Adam | epoch: 002 | loss: 0.68270 - acc: 0.5851 -- iter: 096/502
[A[ATraining Step: 20  | total loss: [1m[32m0.68359[0m[0m | time: 4.883s
[2K
| Adam | epoch: 002 | loss: 0.68359 - acc: 0.5779 -- iter: 128/502
[A[ATraining Step: 21  | total loss: [1m[32m0.68240[0m[0m | time: 15.087s
[2K
| Adam | epoch: 002 | loss: 0.68240 - acc: 0.5828 -- iter: 160/502
[A[ATraining Step: 22  | total loss: [1m[32m0.69246[0m[0m | time: 16.051s
[2K
| Adam | epoch: 002 | loss: 0.69246 - acc: 0.5298 -- iter: 192/502
[A[ATraining Step: 23  | total loss: [1m[32m0.69392[0m[0m | time: 17.200s
[2K
| Adam | epoch: 002 | loss: 0.69392 - acc: 0.5212 -- iter: 224/502
[A[ATraining Step: 24  | total loss: [1m[32m0.68955[0m[0m | time: 18.403s
[2K
| Adam | epoch: 002 | loss: 0.68955 - acc: 0.5416 -- iter: 256/502
[A[ATraining Step: 25  | total loss: [1m[32m0.68969[0m[0m | time: 19.388s
[2K
| Adam | epoch: 002 | loss: 0.68969 - acc: 0.5388 -- iter: 288/502
[A[ATraining Step: 26  | total loss: [1m[32m0.68233[0m[0m | time: 20.577s
[2K
| Adam | epoch: 002 | loss: 0.68233 - acc: 0.5781 -- iter: 320/502
[A[ATraining Step: 27  | total loss: [1m[32m0.67013[0m[0m | time: 21.800s
[2K
| Adam | epoch: 002 | loss: 0.67013 - acc: 0.6384 -- iter: 352/502
[A[ATraining Step: 28  | total loss: [1m[32m0.67613[0m[0m | time: 22.857s
[2K
| Adam | epoch: 002 | loss: 0.67613 - acc: 0.6116 -- iter: 384/502
[A[ATraining Step: 29  | total loss: [1m[32m0.68796[0m[0m | time: 23.908s
[2K
| Adam | epoch: 002 | loss: 0.68796 - acc: 0.5693 -- iter: 416/502
[A[ATraining Step: 30  | total loss: [1m[32m0.68917[0m[0m | time: 25.077s
[2K
| Adam | epoch: 002 | loss: 0.68917 - acc: 0.5603 -- iter: 448/502
[A[ATraining Step: 31  | total loss: [1m[32m0.67743[0m[0m | time: 26.344s
[2K
| Adam | epoch: 002 | loss: 0.67743 - acc: 0.5968 -- iter: 480/502
[A[ATraining Step: 32  | total loss: [1m[32m0.68148[0m[0m | time: 52.584s
[2K
| Adam | epoch: 002 | loss: 0.68148 - acc: 0.5821 | val_loss: 0.67388 - val_acc: 0.5924 -- iter: 502/502
--
Training Step: 33  | total loss: [1m[32m0.67249[0m[0m | time: 0.740s
[2K
| Adam | epoch: 003 | loss: 0.67249 - acc: 0.6052 -- iter: 032/502
[A[ATraining Step: 34  | total loss: [1m[32m0.67265[0m[0m | time: 1.548s
[2K
| Adam | epoch: 003 | loss: 0.67265 - acc: 0.6022 -- iter: 064/502
[A[ATraining Step: 35  | total loss: [1m[32m0.67269[0m[0m | time: 2.702s
[2K
| Adam | epoch: 003 | loss: 0.67269 - acc: 0.5998 -- iter: 096/502
[A[ATraining Step: 36  | total loss: [1m[32m0.66970[0m[0m | time: 3.885s
[2K
| Adam | epoch: 003 | loss: 0.66970 - acc: 0.6050 -- iter: 128/502
[A[ATraining Step: 37  | total loss: [1m[32m0.67742[0m[0m | time: 5.019s
[2K
| Adam | epoch: 003 | loss: 0.67742 - acc: 0.5902 -- iter: 160/502
[A[ATraining Step: 38  | total loss: [1m[32m0.66713[0m[0m | time: 6.132s
[2K
| Adam | epoch: 003 | loss: 0.66713 - acc: 0.6092 -- iter: 192/502
[A[ATraining Step: 39  | total loss: [1m[32m0.67611[0m[0m | time: 7.163s
[2K
| Adam | epoch: 003 | loss: 0.67611 - acc: 0.5883 -- iter: 224/502
[A[ATraining Step: 40  | total loss: [1m[32m0.68081[0m[0m | time: 8.322s
[2K
| Adam | epoch: 003 | loss: 0.68081 - acc: 0.5776 -- iter: 256/502
[A[ATraining Step: 41  | total loss: [1m[32m0.67261[0m[0m | time: 9.672s
[2K
| Adam | epoch: 003 | loss: 0.67261 - acc: 0.5978 -- iter: 288/502
[A[ATraining Step: 42  | total loss: [1m[32m0.67399[0m[0m | time: 10.814s
[2K
| Adam | epoch: 003 | loss: 0.67399 - acc: 0.5915 -- iter: 320/502
[A[ATraining Step: 43  | total loss: [1m[32m0.67486[0m[0m | time: 34.795s
[2K
| Adam | epoch: 003 | loss: 0.67486 - acc: 0.5863 -- iter: 352/502
[A[ATraining Step: 44  | total loss: [1m[32m0.67301[0m[0m | time: 35.753s
[2K
| Adam | epoch: 003 | loss: 0.67301 - acc: 0.5930 -- iter: 384/502
[A[ATraining Step: 45  | total loss: [1m[32m0.66946[0m[0m | time: 36.859s
[2K
| Adam | epoch: 003 | loss: 0.66946 - acc: 0.6038 -- iter: 416/502
[A[ATraining Step: 46  | total loss: [1m[32m0.67086[0m[0m | time: 37.934s
[2K
| Adam | epoch: 003 | loss: 0.67086 - acc: 0.5969 -- iter: 448/502
[A[ATraining Step: 47  | total loss: [1m[32m0.66984[0m[0m | time: 39.031s
[2K
| Adam | epoch: 003 | loss: 0.66984 - acc: 0.5964 -- iter: 480/502
[A[ATraining Step: 48  | total loss: [1m[32m0.66550[0m[0m | time: 41.156s
[2K
| Adam | epoch: 003 | loss: 0.66550 - acc: 0.6060 | val_loss: 0.66571 - val_acc: 0.5924 -- iter: 502/502
--
Training Step: 49  | total loss: [1m[32m0.67287[0m[0m | time: 1.142s
[2K
| Adam | epoch: 004 | loss: 0.67287 - acc: 0.5893 -- iter: 032/502
[A[ATraining Step: 50  | total loss: [1m[32m0.68299[0m[0m | time: 1.968s
[2K
| Adam | epoch: 004 | loss: 0.68299 - acc: 0.5657 -- iter: 064/502
[A[ATraining Step: 51  | total loss: [1m[32m0.67983[0m[0m | time: 2.769s
[2K
| Adam | epoch: 004 | loss: 0.67983 - acc: 0.5696 -- iter: 096/502
[A[ATraining Step: 52  | total loss: [1m[32m0.67740[0m[0m | time: 4.126s
[2K
| Adam | epoch: 004 | loss: 0.67740 - acc: 0.5728 -- iter: 128/502
[A[ATraining Step: 53  | total loss: [1m[32m0.67532[0m[0m | time: 8.169s
[2K
| Adam | epoch: 004 | loss: 0.67532 - acc: 0.5759 -- iter: 160/502
[A[ATraining Step: 54  | total loss: [1m[32m0.67796[0m[0m | time: 32.066s
[2K
| Adam | epoch: 004 | loss: 0.67796 - acc: 0.5648 -- iter: 192/502
[A[ATraining Step: 55  | total loss: [1m[32m0.67694[0m[0m | time: 32.988s
[2K
| Adam | epoch: 004 | loss: 0.67694 - acc: 0.5645 -- iter: 224/502
[A[ATraining Step: 56  | total loss: [1m[32m0.67341[0m[0m | time: 34.090s
[2K
| Adam | epoch: 004 | loss: 0.67341 - acc: 0.5774 -- iter: 256/502
[A[ATraining Step: 57  | total loss: [1m[32m0.67275[0m[0m | time: 35.170s
[2K
| Adam | epoch: 004 | loss: 0.67275 - acc: 0.5753 -- iter: 288/502
[A[ATraining Step: 58  | total loss: [1m[32m0.66921[0m[0m | time: 36.334s
[2K
| Adam | epoch: 004 | loss: 0.66921 - acc: 0.5779 -- iter: 320/502
[A[ATraining Step: 59  | total loss: [1m[32m0.66927[0m[0m | time: 37.586s
[2K
| Adam | epoch: 004 | loss: 0.66927 - acc: 0.5674 -- iter: 352/502
[A[ATraining Step: 60  | total loss: [1m[32m0.67151[0m[0m | time: 38.724s
[2K
| Adam | epoch: 004 | loss: 0.67151 - acc: 0.5543 -- iter: 384/502
[A[ATraining Step: 61  | total loss: [1m[32m0.66860[0m[0m | time: 39.745s
[2K
| Adam | epoch: 004 | loss: 0.66860 - acc: 0.5595 -- iter: 416/502
[A[ATraining Step: 62  | total loss: [1m[32m0.66453[0m[0m | time: 40.917s
[2K
| Adam | epoch: 004 | loss: 0.66453 - acc: 0.5679 -- iter: 448/502
[A[ATraining Step: 63  | total loss: [1m[32m0.66797[0m[0m | time: 42.086s
[2K
| Adam | epoch: 004 | loss: 0.66797 - acc: 0.5593 -- iter: 480/502
[A[ATraining Step: 64  | total loss: [1m[32m0.66475[0m[0m | time: 44.493s
[2K
| Adam | epoch: 004 | loss: 0.66475 - acc: 0.5597 | val_loss: 0.62171 - val_acc: 0.5987 -- iter: 502/502
--
Training Step: 65  | total loss: [1m[32m0.66209[0m[0m | time: 1.099s
[2K
| Adam | epoch: 005 | loss: 0.66209 - acc: 0.5716 -- iter: 032/502
[A[ATraining Step: 66  | total loss: [1m[32m0.65209[0m[0m | time: 2.248s
[2K
| Adam | epoch: 005 | loss: 0.65209 - acc: 0.5857 -- iter: 064/502
[A[ATraining Step: 67  | total loss: [1m[32m0.64584[0m[0m | time: 3.081s
[2K
| Adam | epoch: 005 | loss: 0.64584 - acc: 0.5942 -- iter: 096/502
[A[ATraining Step: 68  | total loss: [1m[32m0.63963[0m[0m | time: 3.879s
[2K
| Adam | epoch: 005 | loss: 0.63963 - acc: 0.5992 -- iter: 128/502
[A[ATraining Step: 69  | total loss: [1m[32m0.63301[0m[0m | time: 5.063s
[2K
| Adam | epoch: 005 | loss: 0.63301 - acc: 0.6141 -- iter: 160/502
[A[ATraining Step: 70  | total loss: [1m[32m0.63196[0m[0m | time: 6.318s
[2K
| Adam | epoch: 005 | loss: 0.63196 - acc: 0.6190 -- iter: 192/502
[A[ATraining Step: 71  | total loss: [1m[32m0.62061[0m[0m | time: 7.330s
[2K
| Adam | epoch: 005 | loss: 0.62061 - acc: 0.6482 -- iter: 224/502
[A[ATraining Step: 72  | total loss: [1m[32m0.61484[0m[0m | time: 8.533s
[2K
| Adam | epoch: 005 | loss: 0.61484 - acc: 0.6561 -- iter: 256/502
[A[ATraining Step: 73  | total loss: [1m[32m0.61221[0m[0m | time: 9.747s
[2K
| Adam | epoch: 005 | loss: 0.61221 - acc: 0.6561 -- iter: 288/502
[A[ATraining Step: 74  | total loss: [1m[32m0.60075[0m[0m | time: 10.805s
[2K
| Adam | epoch: 005 | loss: 0.60075 - acc: 0.6664 -- iter: 320/502
[A[ATraining Step: 75  | total loss: [1m[32m0.59559[0m[0m | time: 12.030s
[2K
| Adam | epoch: 005 | loss: 0.59559 - acc: 0.6721 -- iter: 352/502
[A[ATraining Step: 76  | total loss: [1m[32m0.59214[0m[0m | time: 13.055s
[2K
| Adam | epoch: 005 | loss: 0.59214 - acc: 0.6771 -- iter: 384/502
[A[ATraining Step: 77  | total loss: [1m[32m0.57449[0m[0m | time: 14.019s
[2K
| Adam | epoch: 005 | loss: 0.57449 - acc: 0.7014 -- iter: 416/502
[A[ATraining Step: 78  | total loss: [1m[32m0.56922[0m[0m | time: 14.797s
[2K
| Adam | epoch: 005 | loss: 0.56922 - acc: 0.6999 -- iter: 448/502
[A[ATraining Step: 79  | total loss: [1m[32m0.55589[0m[0m | time: 15.552s
[2K
| Adam | epoch: 005 | loss: 0.55589 - acc: 0.7051 -- iter: 480/502
[A[ATraining Step: 80  | total loss: [1m[32m0.54799[0m[0m | time: 17.280s
[2K
| Adam | epoch: 005 | loss: 0.54799 - acc: 0.7097 | val_loss: 0.48513 - val_acc: 0.7389 -- iter: 502/502
--
Training Step: 81  | total loss: [1m[32m0.54357[0m[0m | time: 0.746s
[2K
| Adam | epoch: 006 | loss: 0.54357 - acc: 0.7138 -- iter: 032/502
[A[ATraining Step: 82  | total loss: [1m[32m0.54586[0m[0m | time: 1.478s
[2K
| Adam | epoch: 006 | loss: 0.54586 - acc: 0.7111 -- iter: 064/502
[A[ATraining Step: 83  | total loss: [1m[32m0.54859[0m[0m | time: 2.235s
[2K
| Adam | epoch: 006 | loss: 0.54859 - acc: 0.7088 -- iter: 096/502
[A[ATraining Step: 84  | total loss: [1m[32m0.54746[0m[0m | time: 2.884s
[2K
| Adam | epoch: 006 | loss: 0.54746 - acc: 0.7066 -- iter: 128/502
[A[ATraining Step: 85  | total loss: [1m[32m0.53730[0m[0m | time: 3.408s
[2K
| Adam | epoch: 006 | loss: 0.53730 - acc: 0.7178 -- iter: 160/502
[A[ATraining Step: 86  | total loss: [1m[32m0.53535[0m[0m | time: 4.098s
[2K
| Adam | epoch: 006 | loss: 0.53535 - acc: 0.7187 -- iter: 192/502
[A[ATraining Step: 87  | total loss: [1m[32m0.51864[0m[0m | time: 4.838s
[2K
| Adam | epoch: 006 | loss: 0.51864 - acc: 0.7312 -- iter: 224/502
[A[ATraining Step: 88  | total loss: [1m[32m0.50501[0m[0m | time: 5.636s
[2K
| Adam | epoch: 006 | loss: 0.50501 - acc: 0.7394 -- iter: 256/502
[A[ATraining Step: 89  | total loss: [1m[32m0.49638[0m[0m | time: 6.427s
[2K
| Adam | epoch: 006 | loss: 0.49638 - acc: 0.7498 -- iter: 288/502
[A[ATraining Step: 90  | total loss: [1m[32m0.50230[0m[0m | time: 7.196s
[2K
| Adam | epoch: 006 | loss: 0.50230 - acc: 0.7467 -- iter: 320/502
[A[ATraining Step: 91  | total loss: [1m[32m0.48722[0m[0m | time: 7.984s
[2K
| Adam | epoch: 006 | loss: 0.48722 - acc: 0.7533 -- iter: 352/502
[A[ATraining Step: 92  | total loss: [1m[32m0.47242[0m[0m | time: 8.750s
[2K
| Adam | epoch: 006 | loss: 0.47242 - acc: 0.7623 -- iter: 384/502
[A[ATraining Step: 93  | total loss: [1m[32m0.46660[0m[0m | time: 9.493s
[2K
| Adam | epoch: 006 | loss: 0.46660 - acc: 0.7767 -- iter: 416/502
[A[ATraining Step: 94  | total loss: [1m[32m0.45760[0m[0m | time: 10.270s
[2K
| Adam | epoch: 006 | loss: 0.45760 - acc: 0.7865 -- iter: 448/502
[A[ATraining Step: 95  | total loss: [1m[32m0.45198[0m[0m | time: 11.025s
[2K
| Adam | epoch: 006 | loss: 0.45198 - acc: 0.7860 -- iter: 480/502
[A[ATraining Step: 96  | total loss: [1m[32m0.43373[0m[0m | time: 12.798s
[2K
| Adam | epoch: 006 | loss: 0.43373 - acc: 0.8012 | val_loss: 0.41123 - val_acc: 0.7834 -- iter: 502/502
--
Training Step: 97  | total loss: [1m[32m0.42303[0m[0m | time: 0.823s
[2K
| Adam | epoch: 007 | loss: 0.42303 - acc: 0.8086 -- iter: 032/502
[A[ATraining Step: 98  | total loss: [1m[32m0.41360[0m[0m | time: 1.613s
[2K
| Adam | epoch: 007 | loss: 0.41360 - acc: 0.8152 -- iter: 064/502
[A[ATraining Step: 99  | total loss: [1m[32m0.41333[0m[0m | time: 2.441s
[2K
| Adam | epoch: 007 | loss: 0.41333 - acc: 0.8149 -- iter: 096/502
[A[ATraining Step: 100  | total loss: [1m[32m0.40254[0m[0m | time: 3.202s
[2K
| Adam | epoch: 007 | loss: 0.40254 - acc: 0.8209 -- iter: 128/502
[A[ATraining Step: 101  | total loss: [1m[32m0.40553[0m[0m | time: 3.720s
[2K
| Adam | epoch: 007 | loss: 0.40553 - acc: 0.8232 -- iter: 160/502
[A[ATraining Step: 102  | total loss: [1m[32m0.38886[0m[0m | time: 4.727s
[2K
| Adam | epoch: 007 | loss: 0.38886 - acc: 0.8318 -- iter: 192/502
[A[ATraining Step: 103  | total loss: [1m[32m0.37482[0m[0m | time: 5.911s
[2K
| Adam | epoch: 007 | loss: 0.37482 - acc: 0.8395 -- iter: 224/502
[A[ATraining Step: 104  | total loss: [1m[32m0.36775[0m[0m | time: 7.342s
[2K
| Adam | epoch: 007 | loss: 0.36775 - acc: 0.8462 -- iter: 256/502
[A[ATraining Step: 105  | total loss: [1m[32m0.35391[0m[0m | time: 9.241s
[2K
| Adam | epoch: 007 | loss: 0.35391 - acc: 0.8522 -- iter: 288/502
[A[ATraining Step: 106  | total loss: [1m[32m0.33211[0m[0m | time: 10.338s
[2K
| Adam | epoch: 007 | loss: 0.33211 - acc: 0.8607 -- iter: 320/502
[A[ATraining Step: 107  | total loss: [1m[32m0.33860[0m[0m | time: 11.361s
[2K
| Adam | epoch: 007 | loss: 0.33860 - acc: 0.8559 -- iter: 352/502
[A[ATraining Step: 108  | total loss: [1m[32m0.33214[0m[0m | time: 12.506s
[2K
| Adam | epoch: 007 | loss: 0.33214 - acc: 0.8609 -- iter: 384/502
[A[ATraining Step: 109  | total loss: [1m[32m0.31891[0m[0m | time: 13.615s
[2K
| Adam | epoch: 007 | loss: 0.31891 - acc: 0.8624 -- iter: 416/502
[A[ATraining Step: 110  | total loss: [1m[32m0.39409[0m[0m | time: 14.852s
[2K
| Adam | epoch: 007 | loss: 0.39409 - acc: 0.8292 -- iter: 448/502
[A[ATraining Step: 111  | total loss: [1m[32m0.50911[0m[0m | time: 16.078s
[2K
| Adam | epoch: 007 | loss: 0.50911 - acc: 0.7901 -- iter: 480/502
[A[ATraining Step: 112  | total loss: [1m[32m0.56379[0m[0m | time: 18.265s
[2K
| Adam | epoch: 007 | loss: 0.56379 - acc: 0.7767 | val_loss: 0.30623 - val_acc: 0.8535 -- iter: 502/502
--
Training Step: 113  | total loss: [1m[32m0.56854[0m[0m | time: 1.105s
[2K
| Adam | epoch: 008 | loss: 0.56854 - acc: 0.7771 -- iter: 032/502
[A[ATraining Step: 114  | total loss: [1m[32m0.54044[0m[0m | time: 2.154s
[2K
| Adam | epoch: 008 | loss: 0.54044 - acc: 0.7869 -- iter: 064/502
[A[ATraining Step: 115  | total loss: [1m[32m0.53343[0m[0m | time: 3.354s
[2K
| Adam | epoch: 008 | loss: 0.53343 - acc: 0.7864 -- iter: 096/502
[A[ATraining Step: 116  | total loss: [1m[32m0.52266[0m[0m | time: 4.668s
[2K
| Adam | epoch: 008 | loss: 0.52266 - acc: 0.7890 -- iter: 128/502
[A[ATraining Step: 117  | total loss: [1m[32m0.50527[0m[0m | time: 5.973s
[2K
| Adam | epoch: 008 | loss: 0.50527 - acc: 0.7913 -- iter: 160/502
[A[ATraining Step: 118  | total loss: [1m[32m0.48840[0m[0m | time: 6.908s
[2K
| Adam | epoch: 008 | loss: 0.48840 - acc: 0.7997 -- iter: 192/502
[A[ATraining Step: 119  | total loss: [1m[32m0.46584[0m[0m | time: 7.660s
[2K
| Adam | epoch: 008 | loss: 0.46584 - acc: 0.8061 -- iter: 224/502
[A[ATraining Step: 120  | total loss: [1m[32m0.44946[0m[0m | time: 8.791s
[2K
| Adam | epoch: 008 | loss: 0.44946 - acc: 0.8118 -- iter: 256/502
[A[ATraining Step: 121  | total loss: [1m[32m0.43466[0m[0m | time: 9.966s
[2K
| Adam | epoch: 008 | loss: 0.43466 - acc: 0.8182 -- iter: 288/502
[A[ATraining Step: 122  | total loss: [1m[32m0.40479[0m[0m | time: 11.211s
[2K
| Adam | epoch: 008 | loss: 0.40479 - acc: 0.8363 -- iter: 320/502
[A[ATraining Step: 123  | total loss: [1m[32m0.37802[0m[0m | time: 12.329s
[2K
| Adam | epoch: 008 | loss: 0.37802 - acc: 0.8465 -- iter: 352/502
[A[ATraining Step: 124  | total loss: [1m[32m0.35952[0m[0m | time: 22.079s
[2K
| Adam | epoch: 008 | loss: 0.35952 - acc: 0.8556 -- iter: 384/502
[A[ATraining Step: 125  | total loss: [1m[32m0.34534[0m[0m | time: 23.229s
[2K
| Adam | epoch: 008 | loss: 0.34534 - acc: 0.8669 -- iter: 416/502
[A[ATraining Step: 126  | total loss: [1m[32m0.33753[0m[0m | time: 24.413s
[2K
| Adam | epoch: 008 | loss: 0.33753 - acc: 0.8677 -- iter: 448/502
[A[ATraining Step: 127  | total loss: [1m[32m0.32880[0m[0m | time: 25.560s
[2K
| Adam | epoch: 008 | loss: 0.32880 - acc: 0.8684 -- iter: 480/502
[A[ATraining Step: 128  | total loss: [1m[32m0.32622[0m[0m | time: 27.824s
[2K
| Adam | epoch: 008 | loss: 0.32622 - acc: 0.8691 | val_loss: 0.31688 - val_acc: 0.8535 -- iter: 502/502
--
Training Step: 129  | total loss: [1m[32m0.31902[0m[0m | time: 1.050s
[2K
| Adam | epoch: 009 | loss: 0.31902 - acc: 0.8728 -- iter: 032/502
[A[ATraining Step: 130  | total loss: [1m[32m0.31372[0m[0m | time: 2.277s
[2K
| Adam | epoch: 009 | loss: 0.31372 - acc: 0.8761 -- iter: 064/502
[A[ATraining Step: 131  | total loss: [1m[32m0.30344[0m[0m | time: 3.427s
[2K
| Adam | epoch: 009 | loss: 0.30344 - acc: 0.8823 -- iter: 096/502
[A[ATraining Step: 132  | total loss: [1m[32m0.29301[0m[0m | time: 4.826s
[2K
| Adam | epoch: 009 | loss: 0.29301 - acc: 0.8816 -- iter: 128/502
[A[ATraining Step: 133  | total loss: [1m[32m0.27871[0m[0m | time: 7.882s
[2K
| Adam | epoch: 009 | loss: 0.27871 - acc: 0.8903 -- iter: 160/502
[A[ATraining Step: 134  | total loss: [1m[32m0.26639[0m[0m | time: 8.989s
[2K
| Adam | epoch: 009 | loss: 0.26639 - acc: 0.8981 -- iter: 192/502
[A[ATraining Step: 135  | total loss: [1m[32m0.27023[0m[0m | time: 9.844s
[2K
| Adam | epoch: 009 | loss: 0.27023 - acc: 0.8896 -- iter: 224/502
[A[ATraining Step: 136  | total loss: [1m[32m0.26931[0m[0m | time: 10.644s
[2K
| Adam | epoch: 009 | loss: 0.26931 - acc: 0.8870 -- iter: 256/502
[A[ATraining Step: 137  | total loss: [1m[32m0.25816[0m[0m | time: 11.756s
[2K
| Adam | epoch: 009 | loss: 0.25816 - acc: 0.8983 -- iter: 288/502
[A[ATraining Step: 138  | total loss: [1m[32m0.27862[0m[0m | time: 12.963s
[2K
| Adam | epoch: 009 | loss: 0.27862 - acc: 0.8928 -- iter: 320/502
[A[ATraining Step: 139  | total loss: [1m[32m0.27718[0m[0m | time: 14.152s
[2K
| Adam | epoch: 009 | loss: 0.27718 - acc: 0.8879 -- iter: 352/502
[A[ATraining Step: 140  | total loss: [1m[32m0.27366[0m[0m | time: 15.150s
[2K
| Adam | epoch: 009 | loss: 0.27366 - acc: 0.8897 -- iter: 384/502
[A[ATraining Step: 141  | total loss: [1m[32m0.28016[0m[0m | time: 16.484s
[2K
| Adam | epoch: 009 | loss: 0.28016 - acc: 0.8883 -- iter: 416/502
[A[ATraining Step: 142  | total loss: [1m[32m0.29271[0m[0m | time: 17.656s
[2K
| Adam | epoch: 009 | loss: 0.29271 - acc: 0.8776 -- iter: 448/502
[A[ATraining Step: 143  | total loss: [1m[32m0.31065[0m[0m | time: 19.082s
[2K
| Adam | epoch: 009 | loss: 0.31065 - acc: 0.8679 -- iter: 480/502
[A[ATraining Step: 144  | total loss: [1m[32m0.29736[0m[0m | time: 37.188s
[2K
| Adam | epoch: 009 | loss: 0.29736 - acc: 0.8749 | val_loss: 0.47492 - val_acc: 0.8025 -- iter: 502/502
--
Training Step: 145  | total loss: [1m[32m0.27687[0m[0m | time: 1.176s
[2K
| Adam | epoch: 010 | loss: 0.27687 - acc: 0.8843 -- iter: 032/502
[A[ATraining Step: 146  | total loss: [1m[32m0.28618[0m[0m | time: 2.272s
[2K
| Adam | epoch: 010 | loss: 0.28618 - acc: 0.8865 -- iter: 064/502
[A[ATraining Step: 147  | total loss: [1m[32m0.28724[0m[0m | time: 3.668s
[2K
| Adam | epoch: 010 | loss: 0.28724 - acc: 0.8853 -- iter: 096/502
[A[ATraining Step: 148  | total loss: [1m[32m0.26418[0m[0m | time: 4.882s
[2K
| Adam | epoch: 010 | loss: 0.26418 - acc: 0.8968 -- iter: 128/502
[A[ATraining Step: 149  | total loss: [1m[32m0.24924[0m[0m | time: 5.914s
[2K
| Adam | epoch: 010 | loss: 0.24924 - acc: 0.9040 -- iter: 160/502
[A[ATraining Step: 150  | total loss: [1m[32m0.24019[0m[0m | time: 7.087s
[2K
| Adam | epoch: 010 | loss: 0.24019 - acc: 0.9073 -- iter: 192/502
[A[ATraining Step: 151  | total loss: [1m[32m0.22789[0m[0m | time: 8.257s
[2K
| Adam | epoch: 010 | loss: 0.22789 - acc: 0.9104 -- iter: 224/502
[A[ATraining Step: 152  | total loss: [1m[32m0.22337[0m[0m | time: 9.170s
[2K
| Adam | epoch: 010 | loss: 0.22337 - acc: 0.9131 -- iter: 256/502
[A[ATraining Step: 153  | total loss: [1m[32m0.24458[0m[0m | time: 10.037s
[2K
| Adam | epoch: 010 | loss: 0.24458 - acc: 0.9127 -- iter: 288/502
[A[ATraining Step: 154  | total loss: [1m[32m0.26752[0m[0m | time: 14.102s
[2K
| Adam | epoch: 010 | loss: 0.26752 - acc: 0.9123 -- iter: 320/502
[A[ATraining Step: 155  | total loss: [1m[32m0.40149[0m[0m | time: 15.370s
[2K
| Adam | epoch: 010 | loss: 0.40149 - acc: 0.8773 -- iter: 352/502
[A[ATraining Step: 156  | total loss: [1m[32m0.37593[0m[0m | time: 16.479s
[2K
| Adam | epoch: 010 | loss: 0.37593 - acc: 0.8834 -- iter: 384/502
[A[ATraining Step: 157  | total loss: [1m[32m0.36171[0m[0m | time: 17.601s
[2K
| Adam | epoch: 010 | loss: 0.36171 - acc: 0.8888 -- iter: 416/502
[A[ATraining Step: 158  | total loss: [1m[32m0.34672[0m[0m | time: 18.820s
[2K
| Adam | epoch: 010 | loss: 0.34672 - acc: 0.8936 -- iter: 448/502
[A[ATraining Step: 159  | total loss: [1m[32m0.33311[0m[0m | time: 20.022s
[2K
| Adam | epoch: 010 | loss: 0.33311 - acc: 0.8918 -- iter: 480/502
[A[ATraining Step: 160  | total loss: [1m[32m0.31060[0m[0m | time: 22.049s
[2K
| Adam | epoch: 010 | loss: 0.31060 - acc: 0.9026 | val_loss: 0.38427 - val_acc: 0.7834 -- iter: 502/502
--
Training Step: 161  | total loss: [1m[32m0.29970[0m[0m | time: 1.267s
[2K
| Adam | epoch: 011 | loss: 0.29970 - acc: 0.9030 -- iter: 032/502
[A[ATraining Step: 162  | total loss: [1m[32m0.29191[0m[0m | time: 2.468s
[2K
| Adam | epoch: 011 | loss: 0.29191 - acc: 0.9002 -- iter: 064/502
[A[ATraining Step: 163  | total loss: [1m[32m0.28371[0m[0m | time: 14.279s
[2K
| Adam | epoch: 011 | loss: 0.28371 - acc: 0.9039 -- iter: 096/502
[A[ATraining Step: 164  | total loss: [1m[32m0.26775[0m[0m | time: 15.409s
[2K
| Adam | epoch: 011 | loss: 0.26775 - acc: 0.9135 -- iter: 128/502
[A[ATraining Step: 165  | total loss: [1m[32m0.25892[0m[0m | time: 16.533s
[2K
| Adam | epoch: 011 | loss: 0.25892 - acc: 0.9190 -- iter: 160/502
[A[ATraining Step: 166  | total loss: [1m[32m0.25350[0m[0m | time: 17.707s
[2K
| Adam | epoch: 011 | loss: 0.25350 - acc: 0.9209 -- iter: 192/502
[A[ATraining Step: 167  | total loss: [1m[32m0.25643[0m[0m | time: 18.815s
[2K
| Adam | epoch: 011 | loss: 0.25643 - acc: 0.9194 -- iter: 224/502
[A[ATraining Step: 168  | total loss: [1m[32m0.24387[0m[0m | time: 20.093s
[2K
| Adam | epoch: 011 | loss: 0.24387 - acc: 0.9275 -- iter: 256/502
[A[ATraining Step: 169  | total loss: [1m[32m0.22891[0m[0m | time: 20.891s
[2K
| Adam | epoch: 011 | loss: 0.22891 - acc: 0.9347 -- iter: 288/502
[A[ATraining Step: 170  | total loss: [1m[32m0.22423[0m[0m | time: 21.563s
[2K
| Adam | epoch: 011 | loss: 0.22423 - acc: 0.9276 -- iter: 320/502
[A[ATraining Step: 171  | total loss: [1m[32m0.21764[0m[0m | time: 22.789s
[2K
| Adam | epoch: 011 | loss: 0.21764 - acc: 0.9258 -- iter: 352/502
[A[ATraining Step: 172  | total loss: [1m[32m0.25608[0m[0m | time: 24.036s
[2K
| Adam | epoch: 011 | loss: 0.25608 - acc: 0.9144 -- iter: 384/502
[A[ATraining Step: 173  | total loss: [1m[32m0.23597[0m[0m | time: 25.366s
[2K
| Adam | epoch: 011 | loss: 0.23597 - acc: 0.9230 -- iter: 416/502
[A[ATraining Step: 174  | total loss: [1m[32m0.22575[0m[0m | time: 26.330s
[2K
| Adam | epoch: 011 | loss: 0.22575 - acc: 0.9244 -- iter: 448/502
[A[ATraining Step: 175  | total loss: [1m[32m0.22177[0m[0m | time: 27.343s
[2K
| Adam | epoch: 011 | loss: 0.22177 - acc: 0.9258 -- iter: 480/502
[A[ATraining Step: 176  | total loss: [1m[32m0.21107[0m[0m | time: 29.585s
[2K
| Adam | epoch: 011 | loss: 0.21107 - acc: 0.9301 | val_loss: 0.31483 - val_acc: 0.8408 -- iter: 502/502
--
Training Step: 177  | total loss: [1m[32m0.20345[0m[0m | time: 1.347s
[2K
| Adam | epoch: 012 | loss: 0.20345 - acc: 0.9308 -- iter: 032/502
[A[ATraining Step: 178  | total loss: [1m[32m0.20256[0m[0m | time: 2.583s
[2K
| Adam | epoch: 012 | loss: 0.20256 - acc: 0.9252 -- iter: 064/502
[A[ATraining Step: 179  | total loss: [1m[32m0.19547[0m[0m | time: 3.563s
[2K
| Adam | epoch: 012 | loss: 0.19547 - acc: 0.9264 -- iter: 096/502
[A[ATraining Step: 180  | total loss: [1m[32m0.18179[0m[0m | time: 4.862s
[2K
| Adam | epoch: 012 | loss: 0.18179 - acc: 0.9338 -- iter: 128/502
[A[ATraining Step: 181  | total loss: [1m[32m0.16753[0m[0m | time: 5.917s
[2K
| Adam | epoch: 012 | loss: 0.16753 - acc: 0.9404 -- iter: 160/502
[A[ATraining Step: 182  | total loss: [1m[32m0.15819[0m[0m | time: 7.362s
[2K
| Adam | epoch: 012 | loss: 0.15819 - acc: 0.9433 -- iter: 192/502
[A[ATraining Step: 183  | total loss: [1m[32m0.15154[0m[0m | time: 18.315s
[2K
| Adam | epoch: 012 | loss: 0.15154 - acc: 0.9458 -- iter: 224/502
[A[ATraining Step: 184  | total loss: [1m[32m0.14198[0m[0m | time: 19.254s
[2K
| Adam | epoch: 012 | loss: 0.14198 - acc: 0.9512 -- iter: 256/502
[A[ATraining Step: 185  | total loss: [1m[32m0.14165[0m[0m | time: 20.395s
[2K
| Adam | epoch: 012 | loss: 0.14165 - acc: 0.9530 -- iter: 288/502
[A[ATraining Step: 186  | total loss: [1m[32m0.13782[0m[0m | time: 21.201s
[2K
| Adam | epoch: 012 | loss: 0.13782 - acc: 0.9514 -- iter: 320/502
[A[ATraining Step: 187  | total loss: [1m[32m0.12954[0m[0m | time: 22.001s
[2K
| Adam | epoch: 012 | loss: 0.12954 - acc: 0.9563 -- iter: 352/502
[A[ATraining Step: 188  | total loss: [1m[32m0.12099[0m[0m | time: 23.105s
[2K
| Adam | epoch: 012 | loss: 0.12099 - acc: 0.9607 -- iter: 384/502
[A[ATraining Step: 189  | total loss: [1m[32m0.14316[0m[0m | time: 24.356s
[2K
| Adam | epoch: 012 | loss: 0.14316 - acc: 0.9521 -- iter: 416/502
[A[ATraining Step: 190  | total loss: [1m[32m0.13197[0m[0m | time: 25.598s
[2K
| Adam | epoch: 012 | loss: 0.13197 - acc: 0.9569 -- iter: 448/502
[A[ATraining Step: 191  | total loss: [1m[32m0.12072[0m[0m | time: 26.725s
[2K
| Adam | epoch: 012 | loss: 0.12072 - acc: 0.9612 -- iter: 480/502
[A[ATraining Step: 192  | total loss: [1m[32m0.11133[0m[0m | time: 28.916s
[2K
| Adam | epoch: 012 | loss: 0.11133 - acc: 0.9651 | val_loss: 0.29525 - val_acc: 0.9045 -- iter: 502/502
--
Training Step: 193  | total loss: [1m[32m0.10700[0m[0m | time: 1.135s
[2K
| Adam | epoch: 013 | loss: 0.10700 - acc: 0.9686 -- iter: 032/502
[A[ATraining Step: 194  | total loss: [1m[32m0.09823[0m[0m | time: 2.222s
[2K
| Adam | epoch: 013 | loss: 0.09823 - acc: 0.9717 -- iter: 064/502
[A[ATraining Step: 195  | total loss: [1m[32m0.09153[0m[0m | time: 2.954s
[2K
| Adam | epoch: 013 | loss: 0.09153 - acc: 0.9745 -- iter: 096/502
[A[ATraining Step: 196  | total loss: [1m[32m0.08439[0m[0m | time: 3.764s
[2K
| Adam | epoch: 013 | loss: 0.08439 - acc: 0.9771 -- iter: 128/502
[A[ATraining Step: 197  | total loss: [1m[32m0.08281[0m[0m | time: 4.552s
[2K
| Adam | epoch: 013 | loss: 0.08281 - acc: 0.9794 -- iter: 160/502
[A[ATraining Step: 198  | total loss: [1m[32m0.07857[0m[0m | time: 5.218s
[2K
| Adam | epoch: 013 | loss: 0.07857 - acc: 0.9814 -- iter: 192/502
[A[ATraining Step: 199  | total loss: [1m[32m0.07474[0m[0m | time: 6.080s
[2K
| Adam | epoch: 013 | loss: 0.07474 - acc: 0.9833 -- iter: 224/502
[A[ATraining Step: 200  | total loss: [1m[32m0.07005[0m[0m | time: 7.923s
[2K
| Adam | epoch: 013 | loss: 0.07005 - acc: 0.9850 | val_loss: 0.40372 - val_acc: 0.8917 -- iter: 256/502
--
Training Step: 201  | total loss: [1m[32m0.07222[0m[0m | time: 8.709s
[2K
| Adam | epoch: 013 | loss: 0.07222 - acc: 0.9833 -- iter: 288/502
[A[ATraining Step: 202  | total loss: [1m[32m0.07283[0m[0m | time: 9.521s
[2K
| Adam | epoch: 013 | loss: 0.07283 - acc: 0.9819 -- iter: 320/502
[A[ATraining Step: 203  | total loss: [1m[32m0.06785[0m[0m | time: 10.115s
[2K
| Adam | epoch: 013 | loss: 0.06785 - acc: 0.9837 -- iter: 352/502
[A[ATraining Step: 204  | total loss: [1m[32m0.10169[0m[0m | time: 10.595s
[2K
| Adam | epoch: 013 | loss: 0.10169 - acc: 0.9717 -- iter: 384/502
[A[ATraining Step: 205  | total loss: [1m[32m0.12798[0m[0m | time: 11.329s
[2K
| Adam | epoch: 013 | loss: 0.12798 - acc: 0.9609 -- iter: 416/502
[A[ATraining Step: 206  | total loss: [1m[32m0.21393[0m[0m | time: 12.088s
[2K
| Adam | epoch: 013 | loss: 0.21393 - acc: 0.9429 -- iter: 448/502
[A[ATraining Step: 207  | total loss: [1m[32m0.20111[0m[0m | time: 12.822s
[2K
| Adam | epoch: 013 | loss: 0.20111 - acc: 0.9424 -- iter: 480/502
[A[ATraining Step: 208  | total loss: [1m[32m0.18214[0m[0m | time: 14.626s
[2K
| Adam | epoch: 013 | loss: 0.18214 - acc: 0.9481 | val_loss: 0.43946 - val_acc: 0.8726 -- iter: 502/502
--
Training Step: 209  | total loss: [1m[32m0.16624[0m[0m | time: 0.820s
[2K
| Adam | epoch: 014 | loss: 0.16624 - acc: 0.9533 -- iter: 032/502
[A[ATraining Step: 210  | total loss: [1m[32m0.15469[0m[0m | time: 1.608s
[2K
| Adam | epoch: 014 | loss: 0.15469 - acc: 0.9580 -- iter: 064/502
[A[ATraining Step: 211  | total loss: [1m[32m0.14349[0m[0m | time: 2.540s
[2K
| Adam | epoch: 014 | loss: 0.14349 - acc: 0.9622 -- iter: 096/502
[A[ATraining Step: 212  | total loss: [1m[32m0.13057[0m[0m | time: 3.211s
[2K
| Adam | epoch: 014 | loss: 0.13057 - acc: 0.9660 -- iter: 128/502
[A[ATraining Step: 213  | total loss: [1m[32m0.12453[0m[0m | time: 3.999s
[2K
| Adam | epoch: 014 | loss: 0.12453 - acc: 0.9663 -- iter: 160/502
[A[ATraining Step: 214  | total loss: [1m[32m0.11478[0m[0m | time: 4.747s
[2K
| Adam | epoch: 014 | loss: 0.11478 - acc: 0.9696 -- iter: 192/502
[A[ATraining Step: 215  | total loss: [1m[32m0.10598[0m[0m | time: 5.693s
[2K
| Adam | epoch: 014 | loss: 0.10598 - acc: 0.9727 -- iter: 224/502
[A[ATraining Step: 216  | total loss: [1m[32m0.09787[0m[0m | time: 6.989s
[2K
| Adam | epoch: 014 | loss: 0.09787 - acc: 0.9754 -- iter: 256/502
[A[ATraining Step: 217  | total loss: [1m[32m0.09208[0m[0m | time: 8.318s
[2K
| Adam | epoch: 014 | loss: 0.09208 - acc: 0.9779 -- iter: 288/502
[A[ATraining Step: 218  | total loss: [1m[32m0.08534[0m[0m | time: 9.506s
[2K
| Adam | epoch: 014 | loss: 0.08534 - acc: 0.9801 -- iter: 320/502
[A[ATraining Step: 219  | total loss: [1m[32m0.08429[0m[0m | time: 10.494s
[2K
| Adam | epoch: 014 | loss: 0.08429 - acc: 0.9789 -- iter: 352/502
[A[ATraining Step: 220  | total loss: [1m[32m0.07952[0m[0m | time: 11.262s
[2K
| Adam | epoch: 014 | loss: 0.07952 - acc: 0.9810 -- iter: 384/502
[A[ATraining Step: 221  | total loss: [1m[32m0.07268[0m[0m | time: 12.007s
[2K
| Adam | epoch: 014 | loss: 0.07268 - acc: 0.9829 -- iter: 416/502
[A[ATraining Step: 222  | total loss: [1m[32m0.06628[0m[0m | time: 13.103s
[2K
| Adam | epoch: 014 | loss: 0.06628 - acc: 0.9846 -- iter: 448/502
[A[ATraining Step: 223  | total loss: [1m[32m0.11262[0m[0m | time: 14.359s
[2K
| Adam | epoch: 014 | loss: 0.11262 - acc: 0.9768 -- iter: 480/502
[A[ATraining Step: 224  | total loss: [1m[32m0.10369[0m[0m | time: 16.801s
[2K
| Adam | epoch: 014 | loss: 0.10369 - acc: 0.9791 | val_loss: 0.32274 - val_acc: 0.9045 -- iter: 502/502
--
Training Step: 225  | total loss: [1m[32m0.09581[0m[0m | time: 1.290s
[2K
| Adam | epoch: 015 | loss: 0.09581 - acc: 0.9812 -- iter: 032/502
[A[ATraining Step: 226  | total loss: [1m[32m0.08772[0m[0m | time: 2.444s
[2K
| Adam | epoch: 015 | loss: 0.08772 - acc: 0.9831 -- iter: 064/502
[A[ATraining Step: 227  | total loss: [1m[32m0.08030[0m[0m | time: 3.742s
[2K
| Adam | epoch: 015 | loss: 0.08030 - acc: 0.9848 -- iter: 096/502
[A[ATraining Step: 228  | total loss: [1m[32m0.07286[0m[0m | time: 4.887s
[2K
| Adam | epoch: 015 | loss: 0.07286 - acc: 0.9863 -- iter: 128/502
[A[ATraining Step: 229  | total loss: [1m[32m0.06794[0m[0m | time: 5.935s
[2K
| Adam | epoch: 015 | loss: 0.06794 - acc: 0.9877 -- iter: 160/502
[A[ATraining Step: 230  | total loss: [1m[32m0.06444[0m[0m | time: 7.047s
[2K
| Adam | epoch: 015 | loss: 0.06444 - acc: 0.9889 -- iter: 192/502
[A[ATraining Step: 231  | total loss: [1m[32m0.05929[0m[0m | time: 8.234s
[2K
| Adam | epoch: 015 | loss: 0.05929 - acc: 0.9900 -- iter: 224/502
[A[ATraining Step: 232  | total loss: [1m[32m0.05489[0m[0m | time: 9.402s
[2K
| Adam | epoch: 015 | loss: 0.05489 - acc: 0.9910 -- iter: 256/502
[A[ATraining Step: 233  | total loss: [1m[32m0.05385[0m[0m | time: 10.695s
[2K
| Adam | epoch: 015 | loss: 0.05385 - acc: 0.9888 -- iter: 288/502
[A[ATraining Step: 234  | total loss: [1m[32m0.04959[0m[0m | time: 11.722s
[2K
| Adam | epoch: 015 | loss: 0.04959 - acc: 0.9899 -- iter: 320/502
[A[ATraining Step: 235  | total loss: [1m[32m0.04527[0m[0m | time: 12.827s
[2K
| Adam | epoch: 015 | loss: 0.04527 - acc: 0.9909 -- iter: 352/502
[A[ATraining Step: 236  | total loss: [1m[32m0.04219[0m[0m | time: 14.084s
[2K
| Adam | epoch: 015 | loss: 0.04219 - acc: 0.9918 -- iter: 384/502
[A[ATraining Step: 237  | total loss: [1m[32m0.03872[0m[0m | time: 14.960s
[2K
| Adam | epoch: 015 | loss: 0.03872 - acc: 0.9926 -- iter: 416/502
[A[ATraining Step: 238  | total loss: [1m[32m0.04226[0m[0m | time: 16.047s
[2K
| Adam | epoch: 015 | loss: 0.04226 - acc: 0.9888 -- iter: 448/502
[A[ATraining Step: 239  | total loss: [1m[32m0.04033[0m[0m | time: 17.067s
[2K
| Adam | epoch: 015 | loss: 0.04033 - acc: 0.9900 -- iter: 480/502
[A[ATraining Step: 240  | total loss: [1m[32m0.09005[0m[0m | time: 19.284s
[2K
| Adam | epoch: 015 | loss: 0.09005 - acc: 0.9816 | val_loss: 0.38907 - val_acc: 0.8917 -- iter: 502/502
--
Validation AUC:0.9548051075268817
Validation AUPRC:0.9736766989308475
Test AUC:0.9822660098522167
Test AUPRC:0.9869629322817288
BestTestF1Score	0.93	0.85	0.92	0.91	0.95	83	8	62	4	0.12
BestTestMCCScore	0.93	0.85	0.92	0.91	0.95	83	8	62	4	0.12
BestTestAccuracyScore	0.93	0.85	0.92	0.91	0.95	83	8	62	4	0.12
BestValidationF1Score	0.93	0.85	0.92	0.97	0.9	84	3	61	9	0.12
BestValidationMCC	0.93	0.85	0.92	0.97	0.9	84	3	61	9	0.12
BestValidationAccuracy	0.93	0.85	0.92	0.97	0.9	84	3	61	9	0.12
TestPredictions (Threshold:0.12)
CHEMBL2087063,TN,INACT,0.05000000074505806	CHEMBL2322553,TN,INACT,0.05000000074505806	CHEMBL187886,TP,ACT,1.0	CHEMBL516191,TP,ACT,1.0	CHEMBL3353580,TN,INACT,0.009999999776482582	CHEMBL3325769,TN,INACT,0.009999999776482582	CHEMBL3355290,TN,INACT,0.0	CHEMBL1277576,TP,ACT,1.0	CHEMBL198457,FN,ACT,0.009999999776482582	CHEMBL3677853,TN,INACT,0.0	CHEMBL1892778,TN,INACT,0.029999999329447746	CHEMBL3753259,TN,INACT,0.0	CHEMBL3113249,TN,INACT,0.0	CHEMBL239387,TP,ACT,1.0	CHEMBL2057848,TP,ACT,0.8600000143051147	CHEMBL369647,FN,ACT,0.09000000357627869	CHEMBL186109,TP,ACT,1.0	CHEMBL3422821,FP,INACT,0.3400000035762787	CHEMBL1644417,TP,ACT,0.9700000286102295	CHEMBL75124,TP,ACT,0.3700000047683716	CHEMBL2430157,TN,INACT,0.0	CHEMBL1940377,TP,ACT,0.9900000095367432	CHEMBL3689047,TP,ACT,0.9300000071525574	CHEMBL3085880,TN,INACT,0.0	CHEMBL3612653,TN,INACT,0.0	CHEMBL1278197,TP,ACT,0.9900000095367432	CHEMBL72561,TP,ACT,0.9900000095367432	CHEMBL2087044,TN,INACT,0.019999999552965164	CHEMBL249592,TN,INACT,0.009999999776482582	CHEMBL188155,TP,ACT,0.7599999904632568	CHEMBL107638,TP,ACT,0.9900000095367432	CHEMBL1277669,TP,ACT,1.0	CHEMBL254407,TP,ACT,0.9599999785423279	CHEMBL2029633,TP,ACT,1.0	CHEMBL2322549,TN,INACT,0.0	CHEMBL500075,TP,ACT,1.0	CHEMBL2042266,TP,ACT,0.9900000095367432	CHEMBL229218,TP,ACT,0.9599999785423279	CHEMBL2322280,TN,INACT,0.019999999552965164	CHEMBL2042263,TP,ACT,0.17000000178813934	CHEMBL319078,TP,ACT,0.9800000190734863	CHEMBL2312043,FP,INACT,0.49000000953674316	CHEMBL3288626,TP,ACT,0.9900000095367432	CHEMBL3689067,TP,ACT,0.9800000190734863	CHEMBL72104,TP,ACT,0.9900000095367432	CHEMBL260229,FP,INACT,0.15000000596046448	CHEMBL1290285,TN,INACT,0.0	CHEMBL177003,TP,ACT,0.9300000071525574	CHEMBL3288628,TP,ACT,0.9900000095367432	CHEMBL1684585,TN,INACT,0.0	CHEMBL229214,TP,ACT,1.0	CHEMBL246862,TP,ACT,0.9900000095367432	CHEMBL237354,TP,ACT,0.9300000071525574	CHEMBL400674,TP,ACT,0.7699999809265137	CHEMBL265865,TP,ACT,0.9900000095367432	CHEMBL265438,TN,INACT,0.0	CHEMBL2322283,TN,INACT,0.0	CHEMBL504206,TP,ACT,1.0	CHEMBL1972820,TN,INACT,0.0	CHEMBL3646661,FP,INACT,0.1599999964237213	CHEMBL105782,TN,INACT,0.009999999776482582	CHEMBL1940208,TP,ACT,0.7400000095367432	CHEMBL197516,TP,ACT,0.9800000190734863	CHEMBL2298875,TN,INACT,0.0	CHEMBL1940380,TP,ACT,0.9900000095367432	CHEMBL387511,TP,ACT,0.9200000166893005	CHEMBL3689041,TP,ACT,0.9800000190734863	CHEMBL3634333,TN,INACT,0.0	CHEMBL370797,TP,ACT,0.9900000095367432	CHEMBL229217,TP,ACT,1.0	CHEMBL3325768,TN,INACT,0.0	CHEMBL3298247,TN,INACT,0.0	CHEMBL254614,TP,ACT,0.9900000095367432	CHEMBL3682291,TN,INACT,0.0	CHEMBL1277306,TP,ACT,0.9900000095367432	CHEMBL1277118,TP,ACT,1.0	CHEMBL3589911,TN,INACT,0.0	CHEMBL388824,TP,ACT,1.0	CHEMBL1277029,TP,ACT,1.0	CHEMBL1277027,TP,ACT,1.0	CHEMBL2376854,TN,INACT,0.0	CHEMBL3697711,TN,INACT,0.0	CHEMBL1940206,TP,ACT,0.8399999737739563	CHEMBL1277482,TP,ACT,1.0	CHEMBL227207,TP,ACT,0.7900000214576721	CHEMBL1277394,TP,ACT,0.9900000095367432	CHEMBL1277209,TP,ACT,1.0	CHEMBL97880,TP,ACT,0.9900000095367432	CHEMBL3288633,TP,ACT,0.9700000286102295	CHEMBL98171,FP,INACT,0.5099999904632568	CHEMBL189640,TP,ACT,1.0	CHEMBL425180,TP,ACT,1.0	CHEMBL220492,TN,INACT,0.009999999776482582	CHEMBL2087069,TN,INACT,0.009999999776482582	CHEMBL1940385,TP,ACT,1.0	CHEMBL2425547,TP,ACT,1.0	CHEMBL246861,TP,ACT,0.9900000095367432	CHEMBL2029637,TP,ACT,1.0	CHEMBL73789,TP,ACT,1.0	CHEMBL1278013,TP,ACT,0.9900000095367432	CHEMBL519199,TN,INACT,0.10999999940395355	CHEMBL3677851,TN,INACT,0.0	CHEMBL3416893,TN,INACT,0.0	CHEMBL188264,TP,ACT,0.9900000095367432	CHEMBL241690,TP,ACT,0.9800000190734863	CHEMBL3113251,TN,INACT,0.0	CHEMBL2429871,TN,INACT,0.0	CHEMBL3085879,TN,INACT,0.0	CHEMBL2414499,TP,ACT,0.9900000095367432	CHEMBL466587,TN,INACT,0.0	CHEMBL254245,TP,ACT,1.0	CHEMBL363244,TP,ACT,1.0	CHEMBL241704,TP,ACT,1.0	CHEMBL3398238,FP,INACT,0.9800000190734863	CHEMBL1277026,TP,ACT,1.0	CHEMBL3112596,TN,INACT,0.07999999821186066	CHEMBL392540,TP,ACT,0.9900000095367432	CHEMBL3085873,TN,INACT,0.009999999776482582	CHEMBL3593946,TN,INACT,0.009999999776482582	CHEMBL488817,FP,INACT,0.38999998569488525	CHEMBL3644107,TN,INACT,0.009999999776482582	CHEMBL27768,TN,INACT,0.0	CHEMBL2322279,TN,INACT,0.0	CHEMBL227260,TP,ACT,0.9900000095367432	CHEMBL360909,TP,ACT,0.8100000023841858	CHEMBL605157,TN,INACT,0.029999999329447746	CHEMBL510228,TP,ACT,1.0	CHEMBL370055,TP,ACT,1.0	CHEMBL369022,FN,ACT,0.0	CHEMBL2057856,TP,ACT,0.8600000143051147	CHEMBL503101,TP,ACT,1.0	CHEMBL1215434,TN,INACT,0.0	CHEMBL3684331,TP,ACT,0.949999988079071	CHEMBL3288621,TP,ACT,0.9900000095367432	CHEMBL584211,TN,INACT,0.0	CHEMBL3110213,TN,INACT,0.0	CHEMBL52564,TN,INACT,0.0	CHEMBL3359447,FP,INACT,0.3799999952316284	CHEMBL377545,TN,INACT,0.0	CHEMBL241703,TP,ACT,1.0	CHEMBL481246,TN,INACT,0.0	CHEMBL430173,FN,ACT,0.03999999910593033	CHEMBL1580791,TN,INACT,0.0	CHEMBL368807,TP,ACT,0.7799999713897705	CHEMBL1917113,TN,INACT,0.0	CHEMBL3085875,TN,INACT,0.05999999865889549	CHEMBL2322252,TN,INACT,0.009999999776482582	CHEMBL2386178,TN,INACT,0.0	CHEMBL2208211,TN,INACT,0.10999999940395355	CHEMBL3687624,TN,INACT,0.009999999776482582	CHEMBL186886,TP,ACT,1.0	CHEMBL3689044,TP,ACT,0.9900000095367432	CHEMBL1940379,TP,ACT,0.9700000286102295	CHEMBL2057851,TP,ACT,0.7200000286102295	CHEMBL3594130,TN,INACT,0.0	CHEMBL408340,TN,INACT,0.009999999776482582	CHEMBL2087075,TN,INACT,0.0	

