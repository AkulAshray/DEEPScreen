ImageNetInceptionV2 CHEMBL4303 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	259
Number of inactive compounds :	173
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4303_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4303_adam_0.0005_15_0.6/
---------------------------------
Training samples: 275
Validation samples: 86
--
Training Step: 1  | time: 377.683s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/275
[A[ATraining Step: 2  | total loss: [1m[32m0.61130[0m[0m | time: 543.427s
[2K
| Adam | epoch: 001 | loss: 0.61130 - acc: 0.5344 -- iter: 064/275
[A[ATraining Step: 3  | total loss: [1m[32m1.20549[0m[0m | time: 856.664s
[2K
| Adam | epoch: 001 | loss: 1.20549 - acc: 0.5574 -- iter: 096/275
[A[ATraining Step: 4  | total loss: [1m[32m0.68241[0m[0m | time: 1099.289s
[2K
| Adam | epoch: 001 | loss: 0.68241 - acc: 0.7253 -- iter: 128/275
[A[ATraining Step: 5  | total loss: [1m[32m0.61913[0m[0m | time: 1336.138s
[2K
| Adam | epoch: 001 | loss: 0.61913 - acc: 0.6991 -- iter: 160/275
[A[ATraining Step: 6  | total loss: [1m[32m0.65572[0m[0m | time: 1566.011s
[2K
| Adam | epoch: 001 | loss: 0.65572 - acc: 0.6314 -- iter: 192/275
[A[ATraining Step: 7  | total loss: [1m[32m0.58338[0m[0m | time: 1693.977s
[2K
| Adam | epoch: 001 | loss: 0.58338 - acc: 0.6651 -- iter: 224/275
[A[ATraining Step: 8  | total loss: [1m[32m0.51553[0m[0m | time: 2042.416s
[2K
| Adam | epoch: 001 | loss: 0.51553 - acc: 0.7304 -- iter: 256/275
[A[ATraining Step: 9  | total loss: [1m[32m0.42437[0m[0m | time: 2481.653s
[2K
| Adam | epoch: 001 | loss: 0.42437 - acc: 0.8235 | val_loss: 1.21773 - val_acc: 0.4884 -- iter: 275/275
--
Training Step: 10  | total loss: [1m[32m0.45764[0m[0m | time: 153.094s
[2K
| Adam | epoch: 002 | loss: 0.45764 - acc: 0.8328 -- iter: 032/275
[A[ATraining Step: 11  | total loss: [1m[32m0.34333[0m[0m | time: 405.294s
[2K
| Adam | epoch: 002 | loss: 0.34333 - acc: 0.8871 -- iter: 064/275
[A[ATraining Step: 12  | total loss: [1m[32m0.37002[0m[0m | time: 629.950s
[2K
| Adam | epoch: 002 | loss: 0.37002 - acc: 0.8254 -- iter: 096/275
[A[ATraining Step: 13  | total loss: [1m[32m0.55850[0m[0m | time: 672.569s
[2K
| Adam | epoch: 002 | loss: 0.55850 - acc: 0.7395 -- iter: 128/275
[A[ATraining Step: 14  | total loss: [1m[32m0.52210[0m[0m | time: 792.845s
[2K
| Adam | epoch: 002 | loss: 0.52210 - acc: 0.7694 -- iter: 160/275
[A[ATraining Step: 15  | total loss: [1m[32m0.45275[0m[0m | time: 877.066s
[2K
| Adam | epoch: 002 | loss: 0.45275 - acc: 0.8229 -- iter: 192/275
[A[ATraining Step: 16  | total loss: [1m[32m0.44317[0m[0m | time: 932.791s
[2K
| Adam | epoch: 002 | loss: 0.44317 - acc: 0.7956 -- iter: 224/275
[A[ATraining Step: 17  | total loss: [1m[32m0.40793[0m[0m | time: 1004.066s
[2K
| Adam | epoch: 002 | loss: 0.40793 - acc: 0.8242 -- iter: 256/275
[A[ATraining Step: 18  | total loss: [1m[32m0.33619[0m[0m | time: 1029.414s
[2K
| Adam | epoch: 002 | loss: 0.33619 - acc: 0.8742 | val_loss: 1.72940 - val_acc: 0.4884 -- iter: 275/275
--
Training Step: 19  | total loss: [1m[32m0.28259[0m[0m | time: 6.008s
[2K
| Adam | epoch: 003 | loss: 0.28259 - acc: 0.9057 -- iter: 032/275
[A[ATraining Step: 20  | total loss: [1m[32m0.23210[0m[0m | time: 12.081s
[2K
| Adam | epoch: 003 | loss: 0.23210 - acc: 0.9191 -- iter: 064/275
[A[ATraining Step: 21  | total loss: [1m[32m0.17376[0m[0m | time: 50.251s
[2K
| Adam | epoch: 003 | loss: 0.17376 - acc: 0.9442 -- iter: 096/275
[A[ATraining Step: 22  | total loss: [1m[32m0.15143[0m[0m | time: 72.555s
[2K
| Adam | epoch: 003 | loss: 0.15143 - acc: 0.9516 -- iter: 128/275
[A[ATraining Step: 23  | total loss: [1m[32m0.12656[0m[0m | time: 107.755s
[2K
| Adam | epoch: 003 | loss: 0.12656 - acc: 0.9656 -- iter: 160/275
[A[ATraining Step: 24  | total loss: [1m[32m0.12918[0m[0m | time: 179.171s
[2K
| Adam | epoch: 003 | loss: 0.12918 - acc: 0.9577 -- iter: 192/275
[A[ATraining Step: 25  | total loss: [1m[32m0.13926[0m[0m | time: 223.998s
[2K
| Adam | epoch: 003 | loss: 0.13926 - acc: 0.9522 -- iter: 224/275
[A[ATraining Step: 26  | total loss: [1m[32m0.16795[0m[0m | time: 244.368s
[2K
| Adam | epoch: 003 | loss: 0.16795 - acc: 0.9318 -- iter: 256/275
[A[ATraining Step: 27  | total loss: [1m[32m0.14246[0m[0m | time: 275.216s
[2K
| Adam | epoch: 003 | loss: 0.14246 - acc: 0.9493 | val_loss: 1.26325 - val_acc: 0.4884 -- iter: 275/275
--
Training Step: 28  | total loss: [1m[32m0.22680[0m[0m | time: 53.136s
[2K
| Adam | epoch: 004 | loss: 0.22680 - acc: 0.9385 -- iter: 032/275
[A[ATraining Step: 29  | total loss: [1m[32m0.18035[0m[0m | time: 62.075s
[2K
| Adam | epoch: 004 | loss: 0.18035 - acc: 0.9459 -- iter: 064/275
[A[ATraining Step: 30  | total loss: [1m[32m0.14880[0m[0m | time: 70.309s
[2K
| Adam | epoch: 004 | loss: 0.14880 - acc: 0.9587 -- iter: 096/275
[A[ATraining Step: 31  | total loss: [1m[32m0.12029[0m[0m | time: 95.343s
[2K
| Adam | epoch: 004 | loss: 0.12029 - acc: 0.9682 -- iter: 128/275
[A[ATraining Step: 32  | total loss: [1m[32m0.09859[0m[0m | time: 109.699s
[2K
| Adam | epoch: 004 | loss: 0.09859 - acc: 0.9754 -- iter: 160/275
[A[ATraining Step: 33  | total loss: [1m[32m0.09118[0m[0m | time: 125.785s
[2K
| Adam | epoch: 004 | loss: 0.09118 - acc: 0.9739 -- iter: 192/275
[A[ATraining Step: 34  | total loss: [1m[32m0.10228[0m[0m | time: 145.221s
[2K
| Adam | epoch: 004 | loss: 0.10228 - acc: 0.9661 -- iter: 224/275
[A[ATraining Step: 35  | total loss: [1m[32m0.10816[0m[0m | time: 154.864s
[2K
| Adam | epoch: 004 | loss: 0.10816 - acc: 0.9667 -- iter: 256/275
[A[ATraining Step: 36  | total loss: [1m[32m0.11671[0m[0m | time: 167.846s
[2K
| Adam | epoch: 004 | loss: 0.11671 - acc: 0.9607 | val_loss: 3.91108 - val_acc: 0.4884 -- iter: 275/275
--
Training Step: 37  | total loss: [1m[32m0.14238[0m[0m | time: 31.775s
[2K
| Adam | epoch: 005 | loss: 0.14238 - acc: 0.9561 -- iter: 032/275
[A[ATraining Step: 38  | total loss: [1m[32m0.11803[0m[0m | time: 44.899s
[2K
| Adam | epoch: 005 | loss: 0.11803 - acc: 0.9647 -- iter: 064/275
[A[ATraining Step: 39  | total loss: [1m[32m0.12136[0m[0m | time: 53.652s
[2K
| Adam | epoch: 005 | loss: 0.12136 - acc: 0.9595 -- iter: 096/275
[A[ATraining Step: 40  | total loss: [1m[32m0.10252[0m[0m | time: 62.437s
[2K
| Adam | epoch: 005 | loss: 0.10252 - acc: 0.9671 -- iter: 128/275
[A[ATraining Step: 41  | total loss: [1m[32m0.08939[0m[0m | time: 103.899s
[2K
| Adam | epoch: 005 | loss: 0.08939 - acc: 0.9731 -- iter: 160/275
[A[ATraining Step: 42  | total loss: [1m[32m0.08179[0m[0m | time: 117.647s
[2K
| Adam | epoch: 005 | loss: 0.08179 - acc: 0.9723 -- iter: 192/275
[A[ATraining Step: 43  | total loss: [1m[32m0.09229[0m[0m | time: 142.347s
[2K
| Adam | epoch: 005 | loss: 0.09229 - acc: 0.9662 -- iter: 224/275
[A[ATraining Step: 44  | total loss: [1m[32m0.08490[0m[0m | time: 156.216s
[2K
| Adam | epoch: 005 | loss: 0.08490 - acc: 0.9666 -- iter: 256/275
[A[ATraining Step: 45  | total loss: [1m[32m0.07563[0m[0m | time: 178.962s
[2K
| Adam | epoch: 005 | loss: 0.07563 - acc: 0.9723 | val_loss: 3.62355 - val_acc: 0.4884 -- iter: 275/275
--
Training Step: 46  | total loss: [1m[32m0.06712[0m[0m | time: 29.836s
[2K
| Adam | epoch: 006 | loss: 0.06712 - acc: 0.9769 -- iter: 032/275
[A[ATraining Step: 47  | total loss: [1m[32m0.06230[0m[0m | time: 39.653s
[2K
| Adam | epoch: 006 | loss: 0.06230 - acc: 0.9807 -- iter: 064/275
[A[ATraining Step: 48  | total loss: [1m[32m0.05460[0m[0m | time: 48.473s
[2K
| Adam | epoch: 006 | loss: 0.05460 - acc: 0.9838 -- iter: 096/275
[A[ATraining Step: 49  | total loss: [1m[32m0.04808[0m[0m | time: 54.167s
[2K
| Adam | epoch: 006 | loss: 0.04808 - acc: 0.9864 -- iter: 128/275
[A[ATraining Step: 50  | total loss: [1m[32m0.04217[0m[0m | time: 66.741s
[2K
| Adam | epoch: 006 | loss: 0.04217 - acc: 0.9885 -- iter: 160/275
[A[ATraining Step: 51  | total loss: [1m[32m0.03638[0m[0m | time: 79.705s
[2K
| Adam | epoch: 006 | loss: 0.03638 - acc: 0.9902 -- iter: 192/275
[A[ATraining Step: 52  | total loss: [1m[32m0.04932[0m[0m | time: 113.353s
[2K
| Adam | epoch: 006 | loss: 0.04932 - acc: 0.9870 -- iter: 224/275
[A[ATraining Step: 53  | total loss: [1m[32m0.06870[0m[0m | time: 140.730s
[2K
| Adam | epoch: 006 | loss: 0.06870 - acc: 0.9797 -- iter: 256/275
[A[ATraining Step: 54  | total loss: [1m[32m0.06658[0m[0m | time: 170.796s
[2K
| Adam | epoch: 006 | loss: 0.06658 - acc: 0.9826 | val_loss: 0.93478 - val_acc: 0.7558 -- iter: 275/275
--
Training Step: 55  | total loss: [1m[32m0.06612[0m[0m | time: 17.682s
[2K
| Adam | epoch: 007 | loss: 0.06612 - acc: 0.9807 -- iter: 032/275
[A[ATraining Step: 56  | total loss: [1m[32m0.05767[0m[0m | time: 34.046s
[2K
| Adam | epoch: 007 | loss: 0.05767 - acc: 0.9834 -- iter: 064/275
[A[ATraining Step: 57  | total loss: [1m[32m0.05710[0m[0m | time: 50.356s
[2K
| Adam | epoch: 007 | loss: 0.05710 - acc: 0.9814 -- iter: 096/275
[A[ATraining Step: 58  | total loss: [1m[32m0.09355[0m[0m | time: 65.789s
[2K
| Adam | epoch: 007 | loss: 0.09355 - acc: 0.9754 -- iter: 128/275
[A[ATraining Step: 59  | total loss: [1m[32m0.08623[0m[0m | time: 74.890s
[2K
| Adam | epoch: 007 | loss: 0.08623 - acc: 0.9745 -- iter: 160/275
[A[ATraining Step: 60  | total loss: [1m[32m0.07535[0m[0m | time: 85.536s
[2K
| Adam | epoch: 007 | loss: 0.07535 - acc: 0.9779 -- iter: 192/275
[A[ATraining Step: 61  | total loss: [1m[32m0.06615[0m[0m | time: 104.396s
[2K
| Adam | epoch: 007 | loss: 0.06615 - acc: 0.9808 -- iter: 224/275
[A[ATraining Step: 62  | total loss: [1m[32m0.06593[0m[0m | time: 121.733s
[2K
| Adam | epoch: 007 | loss: 0.06593 - acc: 0.9792 -- iter: 256/275
[A[ATraining Step: 63  | total loss: [1m[32m0.06336[0m[0m | time: 141.617s
[2K
| Adam | epoch: 007 | loss: 0.06336 - acc: 0.9779 | val_loss: 1.82228 - val_acc: 0.5581 -- iter: 275/275
--
Training Step: 64  | total loss: [1m[32m0.06721[0m[0m | time: 8.858s
[2K
| Adam | epoch: 008 | loss: 0.06721 - acc: 0.9728 -- iter: 032/275
[A[ATraining Step: 65  | total loss: [1m[32m0.07082[0m[0m | time: 19.040s
[2K
| Adam | epoch: 008 | loss: 0.07082 - acc: 0.9723 -- iter: 064/275
[A[ATraining Step: 66  | total loss: [1m[32m0.06323[0m[0m | time: 60.395s
[2K
| Adam | epoch: 008 | loss: 0.06323 - acc: 0.9757 -- iter: 096/275
[A[ATraining Step: 67  | total loss: [1m[32m0.05824[0m[0m | time: 78.724s
[2K
| Adam | epoch: 008 | loss: 0.05824 - acc: 0.9786 -- iter: 128/275
[A[ATraining Step: 68  | total loss: [1m[32m0.08460[0m[0m | time: 95.614s
[2K
| Adam | epoch: 008 | loss: 0.08460 - acc: 0.9774 -- iter: 160/275
[A[ATraining Step: 69  | total loss: [1m[32m0.07921[0m[0m | time: 104.222s
[2K
| Adam | epoch: 008 | loss: 0.07921 - acc: 0.9801 -- iter: 192/275
[A[ATraining Step: 70  | total loss: [1m[32m0.08243[0m[0m | time: 112.757s
[2K
| Adam | epoch: 008 | loss: 0.08243 - acc: 0.9763 -- iter: 224/275
[A[ATraining Step: 71  | total loss: [1m[32m0.07395[0m[0m | time: 147.506s
[2K
| Adam | epoch: 008 | loss: 0.07395 - acc: 0.9790 -- iter: 256/275
[A[ATraining Step: 72  | total loss: [1m[32m0.10046[0m[0m | time: 181.960s
[2K
| Adam | epoch: 008 | loss: 0.10046 - acc: 0.9673 | val_loss: 0.75030 - val_acc: 0.7442 -- iter: 275/275
--
Training Step: 73  | total loss: [1m[32m0.10027[0m[0m | time: 13.743s
[2K
| Adam | epoch: 009 | loss: 0.10027 - acc: 0.9675 -- iter: 032/275
[A[ATraining Step: 74  | total loss: [1m[32m0.09584[0m[0m | time: 27.191s
[2K
| Adam | epoch: 009 | loss: 0.09584 - acc: 0.9676 -- iter: 064/275
[A[ATraining Step: 75  | total loss: [1m[32m0.09030[0m[0m | time: 41.250s
[2K
| Adam | epoch: 009 | loss: 0.09030 - acc: 0.9677 -- iter: 096/275
[A[ATraining Step: 76  | total loss: [1m[32m0.08700[0m[0m | time: 54.532s
[2K
| Adam | epoch: 009 | loss: 0.08700 - acc: 0.9678 -- iter: 128/275
[A[ATraining Step: 77  | total loss: [1m[32m0.11387[0m[0m | time: 68.426s
[2K
| Adam | epoch: 009 | loss: 0.11387 - acc: 0.9580 -- iter: 160/275
[A[ATraining Step: 78  | total loss: [1m[32m0.11325[0m[0m | time: 82.321s
[2K
| Adam | epoch: 009 | loss: 0.11325 - acc: 0.9591 -- iter: 192/275
[A[ATraining Step: 79  | total loss: [1m[32m0.10705[0m[0m | time: 87.981s
[2K
| Adam | epoch: 009 | loss: 0.10705 - acc: 0.9601 -- iter: 224/275
[A[ATraining Step: 80  | total loss: [1m[32m0.11003[0m[0m | time: 93.836s
[2K
| Adam | epoch: 009 | loss: 0.11003 - acc: 0.9588 -- iter: 256/275
[A[ATraining Step: 81  | total loss: [1m[32m0.10089[0m[0m | time: 111.549s
[2K
| Adam | epoch: 009 | loss: 0.10089 - acc: 0.9630 | val_loss: 1.85057 - val_acc: 0.7442 -- iter: 275/275
--
Training Step: 82  | total loss: [1m[32m0.11842[0m[0m | time: 8.526s
[2K
| Adam | epoch: 010 | loss: 0.11842 - acc: 0.9636 -- iter: 032/275
[A[ATraining Step: 83  | total loss: [1m[32m0.11718[0m[0m | time: 17.238s
[2K
| Adam | epoch: 010 | loss: 0.11718 - acc: 0.9610 -- iter: 064/275
[A[ATraining Step: 84  | total loss: [1m[32m0.10891[0m[0m | time: 26.050s
[2K
| Adam | epoch: 010 | loss: 0.10891 - acc: 0.9649 -- iter: 096/275
[A[ATraining Step: 85  | total loss: [1m[32m0.10305[0m[0m | time: 34.511s
[2K
| Adam | epoch: 010 | loss: 0.10305 - acc: 0.9684 -- iter: 128/275
[A[ATraining Step: 86  | total loss: [1m[32m0.09575[0m[0m | time: 42.906s
[2K
| Adam | epoch: 010 | loss: 0.09575 - acc: 0.9715 -- iter: 160/275
[A[ATraining Step: 87  | total loss: [1m[32m0.09098[0m[0m | time: 51.502s
[2K
| Adam | epoch: 010 | loss: 0.09098 - acc: 0.9744 -- iter: 192/275
[A[ATraining Step: 88  | total loss: [1m[32m0.08874[0m[0m | time: 59.847s
[2K
| Adam | epoch: 010 | loss: 0.08874 - acc: 0.9738 -- iter: 224/275
[A[ATraining Step: 89  | total loss: [1m[32m0.09337[0m[0m | time: 65.474s
[2K
| Adam | epoch: 010 | loss: 0.09337 - acc: 0.9702 -- iter: 256/275
[A[ATraining Step: 90  | total loss: [1m[32m0.10630[0m[0m | time: 75.052s
[2K
| Adam | epoch: 010 | loss: 0.10630 - acc: 0.9626 | val_loss: 6.37596 - val_acc: 0.5116 -- iter: 275/275
--
Training Step: 91  | total loss: [1m[32m0.10274[0m[0m | time: 8.737s
[2K
| Adam | epoch: 011 | loss: 0.10274 - acc: 0.9664 -- iter: 032/275
[A[ATraining Step: 92  | total loss: [1m[32m0.10140[0m[0m | time: 17.320s
[2K
| Adam | epoch: 011 | loss: 0.10140 - acc: 0.9666 -- iter: 064/275
[A[ATraining Step: 93  | total loss: [1m[32m0.09371[0m[0m | time: 26.135s
[2K
| Adam | epoch: 011 | loss: 0.09371 - acc: 0.9700 -- iter: 096/275
[A[ATraining Step: 94  | total loss: [1m[32m0.08733[0m[0m | time: 34.704s
[2K
| Adam | epoch: 011 | loss: 0.08733 - acc: 0.9730 -- iter: 128/275
[A[ATraining Step: 95  | total loss: [1m[32m0.08072[0m[0m | time: 43.437s
[2K
| Adam | epoch: 011 | loss: 0.08072 - acc: 0.9757 -- iter: 160/275
[A[ATraining Step: 96  | total loss: [1m[32m0.08305[0m[0m | time: 52.107s
[2K
| Adam | epoch: 011 | loss: 0.08305 - acc: 0.9718 -- iter: 192/275
[A[ATraining Step: 97  | total loss: [1m[32m0.07718[0m[0m | time: 60.607s
[2K
| Adam | epoch: 011 | loss: 0.07718 - acc: 0.9747 -- iter: 224/275
[A[ATraining Step: 98  | total loss: [1m[32m0.07061[0m[0m | time: 69.212s
[2K
| Adam | epoch: 011 | loss: 0.07061 - acc: 0.9772 -- iter: 256/275
[A[ATraining Step: 99  | total loss: [1m[32m0.06456[0m[0m | time: 79.028s
[2K
| Adam | epoch: 011 | loss: 0.06456 - acc: 0.9795 | val_loss: 1.64864 - val_acc: 0.6628 -- iter: 275/275
--
Training Step: 100  | total loss: [1m[32m0.06184[0m[0m | time: 5.598s
[2K
| Adam | epoch: 012 | loss: 0.06184 - acc: 0.9815 -- iter: 032/275
[A[ATraining Step: 101  | total loss: [1m[32m0.05626[0m[0m | time: 14.494s
[2K
| Adam | epoch: 012 | loss: 0.05626 - acc: 0.9834 -- iter: 064/275
[A[ATraining Step: 102  | total loss: [1m[32m0.05598[0m[0m | time: 23.556s
[2K
| Adam | epoch: 012 | loss: 0.05598 - acc: 0.9850 -- iter: 096/275
[A[ATraining Step: 103  | total loss: [1m[32m0.06077[0m[0m | time: 32.072s
[2K
| Adam | epoch: 012 | loss: 0.06077 - acc: 0.9803 -- iter: 128/275
[A[ATraining Step: 104  | total loss: [1m[32m0.05522[0m[0m | time: 40.590s
[2K
| Adam | epoch: 012 | loss: 0.05522 - acc: 0.9823 -- iter: 160/275
[A[ATraining Step: 105  | total loss: [1m[32m0.05983[0m[0m | time: 49.031s
[2K
| Adam | epoch: 012 | loss: 0.05983 - acc: 0.9809 -- iter: 192/275
[A[ATraining Step: 106  | total loss: [1m[32m0.05586[0m[0m | time: 57.663s
[2K
| Adam | epoch: 012 | loss: 0.05586 - acc: 0.9828 -- iter: 224/275
[A[ATraining Step: 107  | total loss: [1m[32m0.05084[0m[0m | time: 66.457s
[2K
| Adam | epoch: 012 | loss: 0.05084 - acc: 0.9845 -- iter: 256/275
[A[ATraining Step: 108  | total loss: [1m[32m0.05059[0m[0m | time: 79.219s
[2K
| Adam | epoch: 012 | loss: 0.05059 - acc: 0.9830 | val_loss: 0.68178 - val_acc: 0.8256 -- iter: 275/275
--
Training Step: 109  | total loss: [1m[32m0.04804[0m[0m | time: 5.486s
[2K
| Adam | epoch: 013 | loss: 0.04804 - acc: 0.9815 -- iter: 032/275
[A[ATraining Step: 110  | total loss: [1m[32m0.04597[0m[0m | time: 11.078s
[2K
| Adam | epoch: 013 | loss: 0.04597 - acc: 0.9834 -- iter: 064/275
[A[ATraining Step: 111  | total loss: [1m[32m0.04174[0m[0m | time: 19.840s
[2K
| Adam | epoch: 013 | loss: 0.04174 - acc: 0.9850 -- iter: 096/275
[A[ATraining Step: 112  | total loss: [1m[32m0.03848[0m[0m | time: 28.349s
[2K
| Adam | epoch: 013 | loss: 0.03848 - acc: 0.9865 -- iter: 128/275
[A[ATraining Step: 113  | total loss: [1m[32m0.03915[0m[0m | time: 37.117s
[2K
| Adam | epoch: 013 | loss: 0.03915 - acc: 0.9848 -- iter: 160/275
[A[ATraining Step: 114  | total loss: [1m[32m0.04430[0m[0m | time: 45.621s
[2K
| Adam | epoch: 013 | loss: 0.04430 - acc: 0.9800 -- iter: 192/275
[A[ATraining Step: 115  | total loss: [1m[32m0.04010[0m[0m | time: 54.176s
[2K
| Adam | epoch: 013 | loss: 0.04010 - acc: 0.9820 -- iter: 224/275
[A[ATraining Step: 116  | total loss: [1m[32m0.03617[0m[0m | time: 62.970s
[2K
| Adam | epoch: 013 | loss: 0.03617 - acc: 0.9838 -- iter: 256/275
[A[ATraining Step: 117  | total loss: [1m[32m0.04728[0m[0m | time: 75.905s
[2K
| Adam | epoch: 013 | loss: 0.04728 - acc: 0.9761 | val_loss: 1.84018 - val_acc: 0.6279 -- iter: 275/275
--
Training Step: 118  | total loss: [1m[32m0.04291[0m[0m | time: 9.014s
[2K
| Adam | epoch: 014 | loss: 0.04291 - acc: 0.9785 -- iter: 032/275
[A[ATraining Step: 119  | total loss: [1m[32m0.03879[0m[0m | time: 14.628s
[2K
| Adam | epoch: 014 | loss: 0.03879 - acc: 0.9806 -- iter: 064/275
[A[ATraining Step: 120  | total loss: [1m[32m0.03612[0m[0m | time: 20.177s
[2K
| Adam | epoch: 014 | loss: 0.03612 - acc: 0.9826 -- iter: 096/275
[A[ATraining Step: 121  | total loss: [1m[32m0.03345[0m[0m | time: 28.563s
[2K
| Adam | epoch: 014 | loss: 0.03345 - acc: 0.9843 -- iter: 128/275
[A[ATraining Step: 122  | total loss: [1m[32m0.03049[0m[0m | time: 37.161s
[2K
| Adam | epoch: 014 | loss: 0.03049 - acc: 0.9859 -- iter: 160/275
[A[ATraining Step: 123  | total loss: [1m[32m0.03138[0m[0m | time: 45.444s
[2K
| Adam | epoch: 014 | loss: 0.03138 - acc: 0.9873 -- iter: 192/275
[A[ATraining Step: 124  | total loss: [1m[32m0.02842[0m[0m | time: 54.009s
[2K
| Adam | epoch: 014 | loss: 0.02842 - acc: 0.9886 -- iter: 224/275
[A[ATraining Step: 125  | total loss: [1m[32m0.02592[0m[0m | time: 62.787s
[2K
| Adam | epoch: 014 | loss: 0.02592 - acc: 0.9897 -- iter: 256/275
[A[ATraining Step: 126  | total loss: [1m[32m0.02491[0m[0m | time: 75.375s
[2K
| Adam | epoch: 014 | loss: 0.02491 - acc: 0.9907 | val_loss: 0.99786 - val_acc: 0.7558 -- iter: 275/275
--
Training Step: 127  | total loss: [1m[32m0.02560[0m[0m | time: 8.738s
[2K
| Adam | epoch: 015 | loss: 0.02560 - acc: 0.9885 -- iter: 032/275
[A[ATraining Step: 128  | total loss: [1m[32m0.02335[0m[0m | time: 17.048s
[2K
| Adam | epoch: 015 | loss: 0.02335 - acc: 0.9897 -- iter: 064/275
[A[ATraining Step: 129  | total loss: [1m[32m0.02143[0m[0m | time: 22.546s
[2K
| Adam | epoch: 015 | loss: 0.02143 - acc: 0.9907 -- iter: 096/275
[A[ATraining Step: 130  | total loss: [1m[32m0.03979[0m[0m | time: 28.050s
[2K
| Adam | epoch: 015 | loss: 0.03979 - acc: 0.9758 -- iter: 128/275
[A[ATraining Step: 131  | total loss: [1m[32m0.04139[0m[0m | time: 36.759s
[2K
| Adam | epoch: 015 | loss: 0.04139 - acc: 0.9783 -- iter: 160/275
[A[ATraining Step: 132  | total loss: [1m[32m0.03882[0m[0m | time: 45.184s
[2K
| Adam | epoch: 015 | loss: 0.03882 - acc: 0.9804 -- iter: 192/275
[A[ATraining Step: 133  | total loss: [1m[32m0.03757[0m[0m | time: 53.640s
[2K
| Adam | epoch: 015 | loss: 0.03757 - acc: 0.9824 -- iter: 224/275
[A[ATraining Step: 134  | total loss: [1m[32m0.03440[0m[0m | time: 61.920s
[2K
| Adam | epoch: 015 | loss: 0.03440 - acc: 0.9842 -- iter: 256/275
[A[ATraining Step: 135  | total loss: [1m[32m0.03128[0m[0m | time: 74.460s
[2K
| Adam | epoch: 015 | loss: 0.03128 - acc: 0.9857 | val_loss: 2.21031 - val_acc: 0.6977 -- iter: 275/275
--
Validation AUC:0.8966450216450217
Validation AUPRC:0.8747703529462648
Test AUC:0.8306674020959736
Test AUPRC:0.8272667601369232
BestTestF1Score	0.84	0.6	0.8	0.77	0.94	46	14	23	3	1.0
BestTestMCCScore	0.84	0.6	0.8	0.77	0.94	46	14	23	3	1.0
BestTestAccuracyScore	0.84	0.6	0.8	0.77	0.94	46	14	23	3	1.0
BestValidationF1Score	0.84	0.65	0.81	0.75	0.95	42	14	28	2	1.0
BestValidationMCC	0.84	0.65	0.81	0.75	0.95	42	14	28	2	1.0
BestValidationAccuracy	0.84	0.65	0.81	0.75	0.95	42	14	28	2	1.0
TestPredictions (Threshold:1.0)
CHEMBL3309984,TP,ACT,1.0	CHEMBL3235356,TP,ACT,1.0	CHEMBL3686086,TP,ACT,1.0	CHEMBL3264527,FP,INACT,1.0	CHEMBL1941080,TP,ACT,1.0	CHEMBL1941047,TP,ACT,1.0	CHEMBL3805792,TN,INACT,0.44999998807907104	CHEMBL302453,FP,INACT,1.0	CHEMBL2158584,TP,ACT,1.0	CHEMBL2413579,TP,ACT,1.0	CHEMBL2181107,FN,ACT,0.0	CHEMBL1940924,TP,ACT,1.0	CHEMBL3310152,TP,ACT,1.0	CHEMBL3264526,FP,INACT,1.0	CHEMBL3360773,TN,INACT,0.9200000166893005	CHEMBL3600798,TP,ACT,1.0	CHEMBL192013,TN,INACT,0.9399999976158142	CHEMBL1622311,TP,ACT,1.0	CHEMBL404630,TP,ACT,1.0	CHEMBL3235358,TP,ACT,1.0	CHEMBL200001,TP,ACT,1.0	CHEMBL1940919,TP,ACT,1.0	CHEMBL512064,TP,ACT,1.0	CHEMBL1802335,TN,INACT,0.009999999776482582	CHEMBL2413587,FP,INACT,1.0	CHEMBL3805350,FP,INACT,1.0	CHEMBL2042903,TP,ACT,1.0	CHEMBL3426780,FP,INACT,1.0	CHEMBL561426,TN,INACT,0.3199999928474426	CHEMBL3104859,TP,ACT,1.0	CHEMBL3650974,FP,INACT,1.0	CHEMBL3686088,TP,ACT,1.0	CHEMBL3600498,TP,ACT,1.0	CHEMBL3235355,TP,ACT,1.0	CHEMBL1917726,FP,INACT,1.0	CHEMBL2419342,TP,ACT,1.0	CHEMBL3600800,TP,ACT,1.0	CHEMBL539379,TN,INACT,0.009999999776482582	CHEMBL3235333,TP,ACT,1.0	CHEMBL2011847,TP,ACT,1.0	CHEMBL193282,FP,INACT,1.0	CHEMBL3264529,TN,INACT,0.46000000834465027	CHEMBL3235363,TP,ACT,1.0	CHEMBL3126064,FN,ACT,0.9800000190734863	CHEMBL2042862,TP,ACT,1.0	CHEMBL3814920,TN,INACT,0.9800000190734863	CHEMBL549547,TN,INACT,0.1599999964237213	CHEMBL3221335,TN,INACT,0.4099999964237213	CHEMBL3235844,TN,INACT,0.8199999928474426	CHEMBL3309991,TP,ACT,1.0	CHEMBL3650956,TN,INACT,0.0	CHEMBL3686080,TP,ACT,1.0	CHEMBL3686104,TP,ACT,1.0	CHEMBL3126080,TP,ACT,1.0	CHEMBL381115,TP,ACT,1.0	CHEMBL2042872,TP,ACT,1.0	CHEMBL3805571,TN,INACT,0.49000000953674316	CHEMBL3126070,TN,INACT,0.9399999976158142	CHEMBL3310155,FN,ACT,0.9900000095367432	CHEMBL3126057,TP,ACT,1.0	CHEMBL1923070,FP,INACT,1.0	CHEMBL554496,TP,ACT,1.0	CHEMBL1941049,TP,ACT,1.0	CHEMBL1230189,TN,INACT,0.9900000095367432	CHEMBL2042858,TP,ACT,1.0	CHEMBL273986,FP,INACT,1.0	CHEMBL1882758,TN,INACT,0.27000001072883606	CHEMBL1456711,TN,INACT,0.10000000149011612	CHEMBL414883,TP,ACT,1.0	CHEMBL3589892,TN,INACT,0.14000000059604645	CHEMBL3264541,FP,INACT,1.0	CHEMBL193892,TN,INACT,0.09000000357627869	CHEMBL3309995,TP,ACT,1.0	CHEMBL365118,FP,INACT,1.0	CHEMBL3309864,TN,INACT,0.0	CHEMBL3805121,FP,INACT,1.0	CHEMBL1941076,TP,ACT,1.0	CHEMBL2042885,TN,INACT,0.3100000023841858	CHEMBL3235842,TN,INACT,0.9900000095367432	CHEMBL1593156,TN,INACT,0.9800000190734863	CHEMBL1940925,TP,ACT,1.0	CHEMBL2158576,TP,ACT,1.0	CHEMBL2042866,TP,ACT,1.0	CHEMBL506415,TP,ACT,1.0	CHEMBL2042891,TP,ACT,1.0	CHEMBL3686072,TP,ACT,1.0	

