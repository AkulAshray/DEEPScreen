ImageNetInceptionV2 CHEMBL3310 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	155
Number of inactive compounds :	155
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3310_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3310_adam_0.001_15_0.6/
---------------------------------
Training samples: 183
Validation samples: 58
--
Training Step: 1  | time: 40.345s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/183
[A[ATraining Step: 2  | total loss: [1m[32m0.60741[0m[0m | time: 58.846s
[2K
| Adam | epoch: 001 | loss: 0.60741 - acc: 0.5906 -- iter: 064/183
[A[ATraining Step: 3  | total loss: [1m[32m0.77677[0m[0m | time: 79.201s
[2K
| Adam | epoch: 001 | loss: 0.77677 - acc: 0.7210 -- iter: 096/183
[A[ATraining Step: 4  | total loss: [1m[32m0.72356[0m[0m | time: 96.268s
[2K
| Adam | epoch: 001 | loss: 0.72356 - acc: 0.6256 -- iter: 128/183
[A[ATraining Step: 5  | total loss: [1m[32m0.75403[0m[0m | time: 116.896s
[2K
| Adam | epoch: 001 | loss: 0.75403 - acc: 0.4954 -- iter: 160/183
[A[ATraining Step: 6  | total loss: [1m[32m0.73583[0m[0m | time: 131.660s
[2K
| Adam | epoch: 001 | loss: 0.73583 - acc: 0.5385 | val_loss: 0.80219 - val_acc: 0.3966 -- iter: 183/183
--
Training Step: 7  | total loss: [1m[32m0.61249[0m[0m | time: 6.211s
[2K
| Adam | epoch: 002 | loss: 0.61249 - acc: 0.6067 -- iter: 032/183
[A[ATraining Step: 8  | total loss: [1m[32m0.47244[0m[0m | time: 27.994s
[2K
| Adam | epoch: 002 | loss: 0.47244 - acc: 0.7301 -- iter: 064/183
[A[ATraining Step: 9  | total loss: [1m[32m0.74300[0m[0m | time: 69.680s
[2K
| Adam | epoch: 002 | loss: 0.74300 - acc: 0.6745 -- iter: 096/183
[A[ATraining Step: 10  | total loss: [1m[32m0.62149[0m[0m | time: 135.232s
[2K
| Adam | epoch: 002 | loss: 0.62149 - acc: 0.7122 -- iter: 128/183
[A[ATraining Step: 11  | total loss: [1m[32m0.58192[0m[0m | time: 212.231s
[2K
| Adam | epoch: 002 | loss: 0.58192 - acc: 0.7597 -- iter: 160/183
[A[ATraining Step: 12  | total loss: [1m[32m0.54076[0m[0m | time: 296.914s
[2K
| Adam | epoch: 002 | loss: 0.54076 - acc: 0.7554 | val_loss: 3.02630 - val_acc: 0.3966 -- iter: 183/183
--
Training Step: 13  | total loss: [1m[32m0.64575[0m[0m | time: 7.847s
[2K
| Adam | epoch: 003 | loss: 0.64575 - acc: 0.6593 -- iter: 032/183
[A[ATraining Step: 14  | total loss: [1m[32m0.54621[0m[0m | time: 15.195s
[2K
| Adam | epoch: 003 | loss: 0.54621 - acc: 0.7275 -- iter: 064/183
[A[ATraining Step: 15  | total loss: [1m[32m0.48621[0m[0m | time: 48.046s
[2K
| Adam | epoch: 003 | loss: 0.48621 - acc: 0.7661 -- iter: 096/183
[A[ATraining Step: 16  | total loss: [1m[32m0.53235[0m[0m | time: 80.071s
[2K
| Adam | epoch: 003 | loss: 0.53235 - acc: 0.7483 -- iter: 128/183
[A[ATraining Step: 17  | total loss: [1m[32m0.53637[0m[0m | time: 174.599s
[2K
| Adam | epoch: 003 | loss: 0.53637 - acc: 0.7489 -- iter: 160/183
[A[ATraining Step: 18  | total loss: [1m[32m0.44108[0m[0m | time: 218.253s
[2K
| Adam | epoch: 003 | loss: 0.44108 - acc: 0.7926 | val_loss: 1.73917 - val_acc: 0.3966 -- iter: 183/183
--
Training Step: 19  | total loss: [1m[32m0.40420[0m[0m | time: 35.458s
[2K
| Adam | epoch: 004 | loss: 0.40420 - acc: 0.8201 -- iter: 032/183
[A[ATraining Step: 20  | total loss: [1m[32m0.35522[0m[0m | time: 43.237s
[2K
| Adam | epoch: 004 | loss: 0.35522 - acc: 0.8478 -- iter: 064/183
[A[ATraining Step: 21  | total loss: [1m[32m0.47857[0m[0m | time: 50.727s
[2K
| Adam | epoch: 004 | loss: 0.47857 - acc: 0.7871 -- iter: 096/183
[A[ATraining Step: 22  | total loss: [1m[32m0.43633[0m[0m | time: 66.774s
[2K
| Adam | epoch: 004 | loss: 0.43633 - acc: 0.7988 -- iter: 128/183
[A[ATraining Step: 23  | total loss: [1m[32m0.41651[0m[0m | time: 116.116s
[2K
| Adam | epoch: 004 | loss: 0.41651 - acc: 0.8209 -- iter: 160/183
[A[ATraining Step: 24  | total loss: [1m[32m0.36308[0m[0m | time: 160.145s
[2K
| Adam | epoch: 004 | loss: 0.36308 - acc: 0.8625 | val_loss: 1.81823 - val_acc: 0.3966 -- iter: 183/183
--
Training Step: 25  | total loss: [1m[32m0.34971[0m[0m | time: 11.400s
[2K
| Adam | epoch: 005 | loss: 0.34971 - acc: 0.8574 -- iter: 032/183
[A[ATraining Step: 26  | total loss: [1m[32m0.32501[0m[0m | time: 21.693s
[2K
| Adam | epoch: 005 | loss: 0.32501 - acc: 0.8703 -- iter: 064/183
[A[ATraining Step: 27  | total loss: [1m[32m0.31982[0m[0m | time: 29.042s
[2K
| Adam | epoch: 005 | loss: 0.31982 - acc: 0.8635 -- iter: 096/183
[A[ATraining Step: 28  | total loss: [1m[32m0.27133[0m[0m | time: 36.160s
[2K
| Adam | epoch: 005 | loss: 0.27133 - acc: 0.8976 -- iter: 128/183
[A[ATraining Step: 29  | total loss: [1m[32m0.23145[0m[0m | time: 70.894s
[2K
| Adam | epoch: 005 | loss: 0.23145 - acc: 0.9225 -- iter: 160/183
[A[ATraining Step: 30  | total loss: [1m[32m0.31261[0m[0m | time: 86.994s
[2K
| Adam | epoch: 005 | loss: 0.31261 - acc: 0.8891 | val_loss: 1.30923 - val_acc: 0.3966 -- iter: 183/183
--
Training Step: 31  | total loss: [1m[32m0.26636[0m[0m | time: 8.110s
[2K
| Adam | epoch: 006 | loss: 0.26636 - acc: 0.9002 -- iter: 032/183
[A[ATraining Step: 32  | total loss: [1m[32m0.23920[0m[0m | time: 16.119s
[2K
| Adam | epoch: 006 | loss: 0.23920 - acc: 0.9157 -- iter: 064/183
[A[ATraining Step: 33  | total loss: [1m[32m0.22611[0m[0m | time: 24.016s
[2K
| Adam | epoch: 006 | loss: 0.22611 - acc: 0.9204 -- iter: 096/183
[A[ATraining Step: 34  | total loss: [1m[32m0.21277[0m[0m | time: 30.118s
[2K
| Adam | epoch: 006 | loss: 0.21277 - acc: 0.9174 -- iter: 128/183
[A[ATraining Step: 35  | total loss: [1m[32m0.23874[0m[0m | time: 36.161s
[2K
| Adam | epoch: 006 | loss: 0.23874 - acc: 0.8983 -- iter: 160/183
[A[ATraining Step: 36  | total loss: [1m[32m0.20414[0m[0m | time: 47.104s
[2K
| Adam | epoch: 006 | loss: 0.20414 - acc: 0.9191 | val_loss: 2.87306 - val_acc: 0.3966 -- iter: 183/183
--
Training Step: 37  | total loss: [1m[32m0.20822[0m[0m | time: 8.160s
[2K
| Adam | epoch: 007 | loss: 0.20822 - acc: 0.9165 -- iter: 032/183
[A[ATraining Step: 38  | total loss: [1m[32m0.21822[0m[0m | time: 16.347s
[2K
| Adam | epoch: 007 | loss: 0.21822 - acc: 0.9084 -- iter: 064/183
[A[ATraining Step: 39  | total loss: [1m[32m0.21265[0m[0m | time: 24.563s
[2K
| Adam | epoch: 007 | loss: 0.21265 - acc: 0.9020 -- iter: 096/183
[A[ATraining Step: 40  | total loss: [1m[32m0.19604[0m[0m | time: 32.929s
[2K
| Adam | epoch: 007 | loss: 0.19604 - acc: 0.9087 -- iter: 128/183
[A[ATraining Step: 41  | total loss: [1m[32m0.19339[0m[0m | time: 39.073s
[2K
| Adam | epoch: 007 | loss: 0.19339 - acc: 0.9082 -- iter: 160/183
[A[ATraining Step: 42  | total loss: [1m[32m0.16740[0m[0m | time: 47.701s
[2K
| Adam | epoch: 007 | loss: 0.16740 - acc: 0.9247 | val_loss: 3.07773 - val_acc: 0.3966 -- iter: 183/183
--
Training Step: 43  | total loss: [1m[32m0.14395[0m[0m | time: 7.959s
[2K
| Adam | epoch: 008 | loss: 0.14395 - acc: 0.9380 -- iter: 032/183
[A[ATraining Step: 44  | total loss: [1m[32m0.15861[0m[0m | time: 15.824s
[2K
| Adam | epoch: 008 | loss: 0.15861 - acc: 0.9379 -- iter: 064/183
[A[ATraining Step: 45  | total loss: [1m[32m0.20782[0m[0m | time: 24.014s
[2K
| Adam | epoch: 008 | loss: 0.20782 - acc: 0.9432 -- iter: 096/183
[A[ATraining Step: 46  | total loss: [1m[32m0.20175[0m[0m | time: 32.279s
[2K
| Adam | epoch: 008 | loss: 0.20175 - acc: 0.9422 -- iter: 128/183
[A[ATraining Step: 47  | total loss: [1m[32m0.18279[0m[0m | time: 40.422s
[2K
| Adam | epoch: 008 | loss: 0.18279 - acc: 0.9466 -- iter: 160/183
[A[ATraining Step: 48  | total loss: [1m[32m0.15807[0m[0m | time: 49.158s
[2K
| Adam | epoch: 008 | loss: 0.15807 - acc: 0.9551 | val_loss: 3.74384 - val_acc: 0.3966 -- iter: 183/183
--
Training Step: 49  | total loss: [1m[32m0.14319[0m[0m | time: 6.160s
[2K
| Adam | epoch: 009 | loss: 0.14319 - acc: 0.9554 -- iter: 032/183
[A[ATraining Step: 50  | total loss: [1m[32m0.12760[0m[0m | time: 14.615s
[2K
| Adam | epoch: 009 | loss: 0.12760 - acc: 0.9623 -- iter: 064/183
[A[ATraining Step: 51  | total loss: [1m[32m0.11560[0m[0m | time: 22.924s
[2K
| Adam | epoch: 009 | loss: 0.11560 - acc: 0.9680 -- iter: 096/183
[A[ATraining Step: 52  | total loss: [1m[32m0.14555[0m[0m | time: 31.378s
[2K
| Adam | epoch: 009 | loss: 0.14555 - acc: 0.9588 -- iter: 128/183
[A[ATraining Step: 53  | total loss: [1m[32m0.12677[0m[0m | time: 39.683s
[2K
| Adam | epoch: 009 | loss: 0.12677 - acc: 0.9649 -- iter: 160/183
[A[ATraining Step: 54  | total loss: [1m[32m0.11935[0m[0m | time: 50.471s
[2K
| Adam | epoch: 009 | loss: 0.11935 - acc: 0.9654 | val_loss: 2.14010 - val_acc: 0.4138 -- iter: 183/183
--
Training Step: 55  | total loss: [1m[32m0.12498[0m[0m | time: 6.085s
[2K
| Adam | epoch: 010 | loss: 0.12498 - acc: 0.9614 -- iter: 032/183
[A[ATraining Step: 56  | total loss: [1m[32m0.11906[0m[0m | time: 12.132s
[2K
| Adam | epoch: 010 | loss: 0.11906 - acc: 0.9607 -- iter: 064/183
[A[ATraining Step: 57  | total loss: [1m[32m0.10459[0m[0m | time: 20.307s
[2K
| Adam | epoch: 010 | loss: 0.10459 - acc: 0.9662 -- iter: 096/183
[A[ATraining Step: 58  | total loss: [1m[32m0.13144[0m[0m | time: 28.527s
[2K
| Adam | epoch: 010 | loss: 0.13144 - acc: 0.9580 -- iter: 128/183
[A[ATraining Step: 59  | total loss: [1m[32m0.13003[0m[0m | time: 36.636s
[2K
| Adam | epoch: 010 | loss: 0.13003 - acc: 0.9553 -- iter: 160/183
[A[ATraining Step: 60  | total loss: [1m[32m0.11810[0m[0m | time: 47.360s
[2K
| Adam | epoch: 010 | loss: 0.11810 - acc: 0.9570 | val_loss: 4.08214 - val_acc: 0.3966 -- iter: 183/183
--
Training Step: 61  | total loss: [1m[32m0.11004[0m[0m | time: 8.249s
[2K
| Adam | epoch: 011 | loss: 0.11004 - acc: 0.9586 -- iter: 032/183
[A[ATraining Step: 62  | total loss: [1m[32m0.10785[0m[0m | time: 14.181s
[2K
| Adam | epoch: 011 | loss: 0.10785 - acc: 0.9599 -- iter: 064/183
[A[ATraining Step: 63  | total loss: [1m[32m0.09688[0m[0m | time: 20.202s
[2K
| Adam | epoch: 011 | loss: 0.09688 - acc: 0.9650 -- iter: 096/183
[A[ATraining Step: 64  | total loss: [1m[32m0.08859[0m[0m | time: 28.249s
[2K
| Adam | epoch: 011 | loss: 0.08859 - acc: 0.9693 -- iter: 128/183
[A[ATraining Step: 65  | total loss: [1m[32m0.13621[0m[0m | time: 36.602s
[2K
| Adam | epoch: 011 | loss: 0.13621 - acc: 0.9539 -- iter: 160/183
[A[ATraining Step: 66  | total loss: [1m[32m0.17123[0m[0m | time: 47.361s
[2K
| Adam | epoch: 011 | loss: 0.17123 - acc: 0.9443 | val_loss: 7.67859 - val_acc: 0.6034 -- iter: 183/183
--
Training Step: 67  | total loss: [1m[32m0.15537[0m[0m | time: 8.242s
[2K
| Adam | epoch: 012 | loss: 0.15537 - acc: 0.9510 -- iter: 032/183
[A[ATraining Step: 68  | total loss: [1m[32m0.20967[0m[0m | time: 16.536s
[2K
| Adam | epoch: 012 | loss: 0.20967 - acc: 0.9198 -- iter: 064/183
[A[ATraining Step: 69  | total loss: [1m[32m0.21758[0m[0m | time: 22.631s
[2K
| Adam | epoch: 012 | loss: 0.21758 - acc: 0.9182 -- iter: 096/183
[A[ATraining Step: 70  | total loss: [1m[32m0.20295[0m[0m | time: 28.582s
[2K
| Adam | epoch: 012 | loss: 0.20295 - acc: 0.9226 -- iter: 128/183
[A[ATraining Step: 71  | total loss: [1m[32m0.18367[0m[0m | time: 36.787s
[2K
| Adam | epoch: 012 | loss: 0.18367 - acc: 0.9314 -- iter: 160/183
[A[ATraining Step: 72  | total loss: [1m[32m0.17517[0m[0m | time: 47.444s
[2K
| Adam | epoch: 012 | loss: 0.17517 - acc: 0.9391 | val_loss: 1.42143 - val_acc: 0.5172 -- iter: 183/183
--
Training Step: 73  | total loss: [1m[32m0.17670[0m[0m | time: 8.309s
[2K
| Adam | epoch: 013 | loss: 0.17670 - acc: 0.9390 -- iter: 032/183
[A[ATraining Step: 74  | total loss: [1m[32m0.18151[0m[0m | time: 16.300s
[2K
| Adam | epoch: 013 | loss: 0.18151 - acc: 0.9354 -- iter: 064/183
[A[ATraining Step: 75  | total loss: [1m[32m0.17212[0m[0m | time: 24.471s
[2K
| Adam | epoch: 013 | loss: 0.17212 - acc: 0.9390 -- iter: 096/183
[A[ATraining Step: 76  | total loss: [1m[32m0.16207[0m[0m | time: 30.639s
[2K
| Adam | epoch: 013 | loss: 0.16207 - acc: 0.9422 -- iter: 128/183
[A[ATraining Step: 77  | total loss: [1m[32m0.14813[0m[0m | time: 36.766s
[2K
| Adam | epoch: 013 | loss: 0.14813 - acc: 0.9483 -- iter: 160/183
[A[ATraining Step: 78  | total loss: [1m[32m0.13375[0m[0m | time: 47.712s
[2K
| Adam | epoch: 013 | loss: 0.13375 - acc: 0.9537 | val_loss: 2.39130 - val_acc: 0.6724 -- iter: 183/183
--
Training Step: 79  | total loss: [1m[32m0.12994[0m[0m | time: 12.208s
[2K
| Adam | epoch: 014 | loss: 0.12994 - acc: 0.9553 -- iter: 032/183
[A[ATraining Step: 80  | total loss: [1m[32m0.11970[0m[0m | time: 25.771s
[2K
| Adam | epoch: 014 | loss: 0.11970 - acc: 0.9598 -- iter: 064/183
[A[ATraining Step: 81  | total loss: [1m[32m0.11286[0m[0m | time: 36.086s
[2K
| Adam | epoch: 014 | loss: 0.11286 - acc: 0.9607 -- iter: 096/183
[A[ATraining Step: 82  | total loss: [1m[32m0.10697[0m[0m | time: 57.011s
[2K
| Adam | epoch: 014 | loss: 0.10697 - acc: 0.9615 -- iter: 128/183
[A[ATraining Step: 83  | total loss: [1m[32m0.10266[0m[0m | time: 64.844s
[2K
| Adam | epoch: 014 | loss: 0.10266 - acc: 0.9623 -- iter: 160/183
[A[ATraining Step: 84  | total loss: [1m[32m0.09594[0m[0m | time: 75.961s
[2K
| Adam | epoch: 014 | loss: 0.09594 - acc: 0.9660 | val_loss: 0.92750 - val_acc: 0.6724 -- iter: 183/183
--
Training Step: 85  | total loss: [1m[32m0.08977[0m[0m | time: 9.871s
[2K
| Adam | epoch: 015 | loss: 0.08977 - acc: 0.9694 -- iter: 032/183
[A[ATraining Step: 86  | total loss: [1m[32m0.10320[0m[0m | time: 25.353s
[2K
| Adam | epoch: 015 | loss: 0.10320 - acc: 0.9631 -- iter: 064/183
[A[ATraining Step: 87  | total loss: [1m[32m0.09733[0m[0m | time: 46.959s
[2K
| Adam | epoch: 015 | loss: 0.09733 - acc: 0.9637 -- iter: 096/183
[A[ATraining Step: 88  | total loss: [1m[32m0.09367[0m[0m | time: 57.287s
[2K
| Adam | epoch: 015 | loss: 0.09367 - acc: 0.9673 -- iter: 128/183
[A[ATraining Step: 89  | total loss: [1m[32m0.08533[0m[0m | time: 67.756s
[2K
| Adam | epoch: 015 | loss: 0.08533 - acc: 0.9706 -- iter: 160/183
[A[ATraining Step: 90  | total loss: [1m[32m0.07790[0m[0m | time: 79.040s
[2K
| Adam | epoch: 015 | loss: 0.07790 - acc: 0.9735 | val_loss: 0.89723 - val_acc: 0.7069 -- iter: 183/183
--
Validation AUC:0.8012422360248447
Validation AUPRC:0.854076053397058
Test AUC:0.7975155279503106
Test AUPRC:0.8797640387497593
BestTestF1Score	0.79	0.41	0.72	0.72	0.89	31	12	11	4	0.01
BestTestMCCScore	0.76	0.43	0.72	0.79	0.74	26	7	16	9	0.23
BestTestAccuracyScore	0.76	0.43	0.72	0.79	0.74	26	7	16	9	0.23
BestValidationF1Score	0.8	0.41	0.72	0.71	0.91	32	13	10	3	0.01
BestValidationMCC	0.79	0.5	0.76	0.82	0.77	27	6	17	8	0.23
BestValidationAccuracy	0.79	0.5	0.76	0.82	0.77	27	6	17	8	0.23
TestPredictions (Threshold:0.23)
CHEMBL141885,TN,INACT,0.009999999776482582	CHEMBL3792560,TP,ACT,0.8399999737739563	CHEMBL3698506,FP,INACT,0.7300000190734863	CHEMBL55895,TN,INACT,0.14000000059604645	CHEMBL2179618,TP,ACT,1.0	CHEMBL186311,FP,INACT,0.6499999761581421	CHEMBL472345,TN,INACT,0.0	CHEMBL3356524,TP,ACT,0.5400000214576721	CHEMBL3739529,TN,INACT,0.0	CHEMBL3235464,TN,INACT,0.009999999776482582	CHEMBL1083086,TP,ACT,0.4099999964237213	CHEMBL3617543,TN,INACT,0.0	CHEMBL2413294,FP,INACT,0.2800000011920929	CHEMBL178456,FN,ACT,0.019999999552965164	CHEMBL3356925,TP,ACT,0.9800000190734863	CHEMBL3670669,TP,ACT,0.6800000071525574	CHEMBL3356929,TP,ACT,0.7900000214576721	CHEMBL3769415,TN,INACT,0.0	CHEMBL561209,TN,INACT,0.009999999776482582	CHEMBL1767046,FP,INACT,0.3799999952316284	CHEMBL3394285,FN,ACT,0.0	CHEMBL2105763,FN,ACT,0.0	CHEMBL2425959,TP,ACT,1.0	CHEMBL326433,TP,ACT,0.5600000023841858	CHEMBL3356934,FN,ACT,0.019999999552965164	CHEMBL3356919,TP,ACT,0.9100000262260437	CHEMBL3356928,TP,ACT,0.9399999976158142	CHEMBL3098696,TP,ACT,0.7400000095367432	CHEMBL3356920,TP,ACT,0.949999988079071	CHEMBL3110005,FP,INACT,0.8500000238418579	CHEMBL3356926,TP,ACT,0.949999988079071	CHEMBL512179,TN,INACT,0.0	CHEMBL1767044,TN,INACT,0.019999999552965164	CHEMBL3670668,FN,ACT,0.07000000029802322	CHEMBL3426803,FN,ACT,0.0	CHEMBL2312167,TP,ACT,0.9100000262260437	CHEMBL3356916,TP,ACT,0.41999998688697815	CHEMBL2425955,FN,ACT,0.009999999776482582	CHEMBL1767037,TN,INACT,0.0	CHEMBL2431901,TN,INACT,0.009999999776482582	CHEMBL3233755,TP,ACT,0.49000000953674316	CHEMBL2425970,FN,ACT,0.10000000149011612	CHEMBL3356918,TP,ACT,1.0	CHEMBL513589,TN,INACT,0.0	CHEMBL3098604,TP,ACT,0.9800000190734863	CHEMBL3356937,FN,ACT,0.12999999523162842	CHEMBL406734,TN,INACT,0.1899999976158142	CHEMBL3352992,TP,ACT,1.0	CHEMBL2046612,TN,INACT,0.029999999329447746	CHEMBL489332,TP,ACT,0.4000000059604645	CHEMBL3233698,TP,ACT,0.9800000190734863	CHEMBL2046619,FP,INACT,0.8899999856948853	CHEMBL3098606,TP,ACT,0.9900000095367432	CHEMBL3622726,TP,ACT,1.0	CHEMBL1851943,TP,ACT,0.9599999785423279	CHEMBL98,TP,ACT,0.5199999809265137	CHEMBL1767041,TN,INACT,0.05999999865889549	CHEMBL2088208,FP,INACT,0.36000001430511475	

