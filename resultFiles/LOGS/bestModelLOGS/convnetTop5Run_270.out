CNNModel CHEMBL4358 adam 0.001 30 256 0 0.6 False True
Number of active compounds :	145
Number of inactive compounds :	145
---------------------------------
Run id: CNNModel_CHEMBL4358_adam_0.001_30_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4358_adam_0.001_30_256_0.6_True/
---------------------------------
Training samples: 185
Validation samples: 58
--
Training Step: 1  | time: 1.248s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/185
[A[ATraining Step: 2  | total loss: [1m[32m0.62358[0m[0m | time: 2.106s
[2K
| Adam | epoch: 001 | loss: 0.62358 - acc: 0.5906 -- iter: 064/185
[A[ATraining Step: 3  | total loss: [1m[32m0.67861[0m[0m | time: 2.973s
[2K
| Adam | epoch: 001 | loss: 0.67861 - acc: 0.5420 -- iter: 096/185
[A[ATraining Step: 4  | total loss: [1m[32m0.71527[0m[0m | time: 3.951s
[2K
| Adam | epoch: 001 | loss: 0.71527 - acc: 0.4402 -- iter: 128/185
[A[ATraining Step: 5  | total loss: [1m[32m0.69705[0m[0m | time: 4.895s
[2K
| Adam | epoch: 001 | loss: 0.69705 - acc: 0.5249 -- iter: 160/185
[A[ATraining Step: 6  | total loss: [1m[32m0.69544[0m[0m | time: 6.690s
[2K
| Adam | epoch: 001 | loss: 0.69544 - acc: 0.4888 | val_loss: 0.69210 - val_acc: 0.5517 -- iter: 185/185
--
Training Step: 7  | total loss: [1m[32m0.69243[0m[0m | time: 0.981s
[2K
| Adam | epoch: 002 | loss: 0.69243 - acc: 0.5795 -- iter: 032/185
[A[ATraining Step: 8  | total loss: [1m[32m0.69117[0m[0m | time: 8.053s
[2K
| Adam | epoch: 002 | loss: 0.69117 - acc: 0.6135 -- iter: 064/185
[A[ATraining Step: 9  | total loss: [1m[32m0.69418[0m[0m | time: 28.428s
[2K
| Adam | epoch: 002 | loss: 0.69418 - acc: 0.4873 -- iter: 096/185
[A[ATraining Step: 10  | total loss: [1m[32m0.69546[0m[0m | time: 50.022s
[2K
| Adam | epoch: 002 | loss: 0.69546 - acc: 0.4311 -- iter: 128/185
[A[ATraining Step: 11  | total loss: [1m[32m0.69316[0m[0m | time: 50.870s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5230 -- iter: 160/185
[A[ATraining Step: 12  | total loss: [1m[32m0.69326[0m[0m | time: 52.810s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.5126 | val_loss: 0.69214 - val_acc: 0.5517 -- iter: 185/185
--
Training Step: 13  | total loss: [1m[32m0.69367[0m[0m | time: 0.850s
[2K
| Adam | epoch: 003 | loss: 0.69367 - acc: 0.4938 -- iter: 032/185
[A[ATraining Step: 14  | total loss: [1m[32m0.69336[0m[0m | time: 1.637s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.5045 -- iter: 064/185
[A[ATraining Step: 15  | total loss: [1m[32m0.69309[0m[0m | time: 2.497s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5106 -- iter: 096/185
[A[ATraining Step: 16  | total loss: [1m[32m0.69334[0m[0m | time: 3.672s
[2K
| Adam | epoch: 003 | loss: 0.69334 - acc: 0.4949 -- iter: 128/185
[A[ATraining Step: 17  | total loss: [1m[32m0.69278[0m[0m | time: 4.991s
[2K
| Adam | epoch: 003 | loss: 0.69278 - acc: 0.5192 -- iter: 160/185
[A[ATraining Step: 18  | total loss: [1m[32m0.69269[0m[0m | time: 7.278s
[2K
| Adam | epoch: 003 | loss: 0.69269 - acc: 0.5234 | val_loss: 0.69185 - val_acc: 0.5517 -- iter: 185/185
--
Training Step: 19  | total loss: [1m[32m0.69193[0m[0m | time: 31.275s
[2K
| Adam | epoch: 004 | loss: 0.69193 - acc: 0.5573 -- iter: 032/185
[A[ATraining Step: 20  | total loss: [1m[32m0.69419[0m[0m | time: 50.669s
[2K
| Adam | epoch: 004 | loss: 0.69419 - acc: 0.4685 -- iter: 064/185
[A[ATraining Step: 21  | total loss: [1m[32m0.69556[0m[0m | time: 72.298s
[2K
| Adam | epoch: 004 | loss: 0.69556 - acc: 0.4100 -- iter: 096/185
[A[ATraining Step: 22  | total loss: [1m[32m0.69620[0m[0m | time: 90.589s
[2K
| Adam | epoch: 004 | loss: 0.69620 - acc: 0.3710 -- iter: 128/185
[A[ATraining Step: 23  | total loss: [1m[32m0.69485[0m[0m | time: 91.458s
[2K
| Adam | epoch: 004 | loss: 0.69485 - acc: 0.4448 -- iter: 160/185
[A[ATraining Step: 24  | total loss: [1m[32m0.69408[0m[0m | time: 93.420s
[2K
| Adam | epoch: 004 | loss: 0.69408 - acc: 0.4867 | val_loss: 0.69273 - val_acc: 0.5517 -- iter: 185/185
--
Training Step: 25  | total loss: [1m[32m0.69361[0m[0m | time: 0.886s
[2K
| Adam | epoch: 005 | loss: 0.69361 - acc: 0.5159 -- iter: 032/185
[A[ATraining Step: 26  | total loss: [1m[32m0.69358[0m[0m | time: 2.088s
[2K
| Adam | epoch: 005 | loss: 0.69358 - acc: 0.5034 -- iter: 064/185
[A[ATraining Step: 27  | total loss: [1m[32m0.69366[0m[0m | time: 3.138s
[2K
| Adam | epoch: 005 | loss: 0.69366 - acc: 0.4784 -- iter: 096/185
[A[ATraining Step: 28  | total loss: [1m[32m0.69376[0m[0m | time: 3.877s
[2K
| Adam | epoch: 005 | loss: 0.69376 - acc: 0.4388 -- iter: 128/185
[A[ATraining Step: 29  | total loss: [1m[32m0.69370[0m[0m | time: 32.101s
[2K
| Adam | epoch: 005 | loss: 0.69370 - acc: 0.4099 -- iter: 160/185
[A[ATraining Step: 30  | total loss: [1m[32m0.69359[0m[0m | time: 68.913s
[2K
| Adam | epoch: 005 | loss: 0.69359 - acc: 0.4238 | val_loss: 0.69376 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 31  | total loss: [1m[32m0.69336[0m[0m | time: 0.866s
[2K
| Adam | epoch: 006 | loss: 0.69336 - acc: 0.4558 -- iter: 032/185
[A[ATraining Step: 32  | total loss: [1m[32m0.69335[0m[0m | time: 1.868s
[2K
| Adam | epoch: 006 | loss: 0.69335 - acc: 0.4658 -- iter: 064/185
[A[ATraining Step: 33  | total loss: [1m[32m0.69351[0m[0m | time: 2.763s
[2K
| Adam | epoch: 006 | loss: 0.69351 - acc: 0.4596 -- iter: 096/185
[A[ATraining Step: 34  | total loss: [1m[32m0.69354[0m[0m | time: 3.482s
[2K
| Adam | epoch: 006 | loss: 0.69354 - acc: 0.4615 -- iter: 128/185
[A[ATraining Step: 35  | total loss: [1m[32m0.69287[0m[0m | time: 4.393s
[2K
| Adam | epoch: 006 | loss: 0.69287 - acc: 0.4989 -- iter: 160/185
[A[ATraining Step: 36  | total loss: [1m[32m0.69233[0m[0m | time: 6.462s
[2K
| Adam | epoch: 006 | loss: 0.69233 - acc: 0.5278 | val_loss: 0.69502 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 37  | total loss: [1m[32m0.69270[0m[0m | time: 1.275s
[2K
| Adam | epoch: 007 | loss: 0.69270 - acc: 0.5160 -- iter: 032/185
[A[ATraining Step: 38  | total loss: [1m[32m0.69221[0m[0m | time: 5.012s
[2K
| Adam | epoch: 007 | loss: 0.69221 - acc: 0.5312 -- iter: 064/185
[A[ATraining Step: 39  | total loss: [1m[32m0.69248[0m[0m | time: 5.882s
[2K
| Adam | epoch: 007 | loss: 0.69248 - acc: 0.5252 -- iter: 096/185
[A[ATraining Step: 40  | total loss: [1m[32m0.69337[0m[0m | time: 6.946s
[2K
| Adam | epoch: 007 | loss: 0.69337 - acc: 0.5029 -- iter: 128/185
[A[ATraining Step: 41  | total loss: [1m[32m0.69240[0m[0m | time: 7.800s
[2K
| Adam | epoch: 007 | loss: 0.69240 - acc: 0.5253 -- iter: 160/185
[A[ATraining Step: 42  | total loss: [1m[32m0.69243[0m[0m | time: 9.534s
[2K
| Adam | epoch: 007 | loss: 0.69243 - acc: 0.5244 | val_loss: 0.69678 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 43  | total loss: [1m[32m0.69248[0m[0m | time: 0.836s
[2K
| Adam | epoch: 008 | loss: 0.69248 - acc: 0.5236 -- iter: 032/185
[A[ATraining Step: 44  | total loss: [1m[32m0.69377[0m[0m | time: 2.105s
[2K
| Adam | epoch: 008 | loss: 0.69377 - acc: 0.5033 -- iter: 064/185
[A[ATraining Step: 45  | total loss: [1m[32m0.69276[0m[0m | time: 3.325s
[2K
| Adam | epoch: 008 | loss: 0.69276 - acc: 0.5186 -- iter: 096/185
[A[ATraining Step: 46  | total loss: [1m[32m0.69453[0m[0m | time: 25.390s
[2K
| Adam | epoch: 008 | loss: 0.69453 - acc: 0.4895 -- iter: 128/185
[A[ATraining Step: 47  | total loss: [1m[32m0.69384[0m[0m | time: 53.422s
[2K
| Adam | epoch: 008 | loss: 0.69384 - acc: 0.5014 -- iter: 160/185
[A[ATraining Step: 48  | total loss: [1m[32m0.69396[0m[0m | time: 92.845s
[2K
| Adam | epoch: 008 | loss: 0.69396 - acc: 0.4962 | val_loss: 0.69579 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 49  | total loss: [1m[32m0.69438[0m[0m | time: 0.778s
[2K
| Adam | epoch: 009 | loss: 0.69438 - acc: 0.4873 -- iter: 032/185
[A[ATraining Step: 50  | total loss: [1m[32m0.69468[0m[0m | time: 1.743s
[2K
| Adam | epoch: 009 | loss: 0.69468 - acc: 0.4800 -- iter: 064/185
[A[ATraining Step: 51  | total loss: [1m[32m0.69372[0m[0m | time: 2.777s
[2K
| Adam | epoch: 009 | loss: 0.69372 - acc: 0.5021 -- iter: 096/185
[A[ATraining Step: 52  | total loss: [1m[32m0.69365[0m[0m | time: 3.916s
[2K
| Adam | epoch: 009 | loss: 0.69365 - acc: 0.5018 -- iter: 128/185
[A[ATraining Step: 53  | total loss: [1m[32m0.69343[0m[0m | time: 4.915s
[2K
| Adam | epoch: 009 | loss: 0.69343 - acc: 0.5061 -- iter: 160/185
[A[ATraining Step: 54  | total loss: [1m[32m0.69317[0m[0m | time: 6.799s
[2K
| Adam | epoch: 009 | loss: 0.69317 - acc: 0.5098 | val_loss: 0.69521 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 55  | total loss: [1m[32m0.69319[0m[0m | time: 1.018s
[2K
| Adam | epoch: 010 | loss: 0.69319 - acc: 0.5084 -- iter: 032/185
[A[ATraining Step: 56  | total loss: [1m[32m0.69309[0m[0m | time: 25.884s
[2K
| Adam | epoch: 010 | loss: 0.69309 - acc: 0.5100 -- iter: 064/185
[A[ATraining Step: 57  | total loss: [1m[32m0.69302[0m[0m | time: 44.870s
[2K
| Adam | epoch: 010 | loss: 0.69302 - acc: 0.5114 -- iter: 096/185
[A[ATraining Step: 58  | total loss: [1m[32m0.69321[0m[0m | time: 59.475s
[2K
| Adam | epoch: 010 | loss: 0.69321 - acc: 0.5056 -- iter: 128/185
[A[ATraining Step: 59  | total loss: [1m[32m0.69290[0m[0m | time: 60.447s
[2K
| Adam | epoch: 010 | loss: 0.69290 - acc: 0.5132 -- iter: 160/185
[A[ATraining Step: 60  | total loss: [1m[32m0.69277[0m[0m | time: 62.388s
[2K
| Adam | epoch: 010 | loss: 0.69277 - acc: 0.5156 | val_loss: 0.69521 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 61  | total loss: [1m[32m0.69294[0m[0m | time: 1.216s
[2K
| Adam | epoch: 011 | loss: 0.69294 - acc: 0.5095 -- iter: 032/185
[A[ATraining Step: 62  | total loss: [1m[32m0.69283[0m[0m | time: 2.029s
[2K
| Adam | epoch: 011 | loss: 0.69283 - acc: 0.5123 -- iter: 064/185
[A[ATraining Step: 63  | total loss: [1m[32m0.69277[0m[0m | time: 2.891s
[2K
| Adam | epoch: 011 | loss: 0.69277 - acc: 0.5133 -- iter: 096/185
[A[ATraining Step: 64  | total loss: [1m[32m0.69273[0m[0m | time: 4.020s
[2K
| Adam | epoch: 011 | loss: 0.69273 - acc: 0.5141 -- iter: 128/185
[A[ATraining Step: 65  | total loss: [1m[32m0.69309[0m[0m | time: 5.048s
[2K
| Adam | epoch: 011 | loss: 0.69309 - acc: 0.5047 -- iter: 160/185
[A[ATraining Step: 66  | total loss: [1m[32m0.69368[0m[0m | time: 7.050s
[2K
| Adam | epoch: 011 | loss: 0.69368 - acc: 0.4889 | val_loss: 0.69515 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 67  | total loss: [1m[32m0.69296[0m[0m | time: 1.055s
[2K
| Adam | epoch: 012 | loss: 0.69296 - acc: 0.5090 -- iter: 032/185
[A[ATraining Step: 68  | total loss: [1m[32m0.69313[0m[0m | time: 2.009s
[2K
| Adam | epoch: 012 | loss: 0.69313 - acc: 0.5042 -- iter: 064/185
[A[ATraining Step: 69  | total loss: [1m[32m0.69245[0m[0m | time: 2.845s
[2K
| Adam | epoch: 012 | loss: 0.69245 - acc: 0.5220 -- iter: 096/185
[A[ATraining Step: 70  | total loss: [1m[32m0.69280[0m[0m | time: 3.738s
[2K
| Adam | epoch: 012 | loss: 0.69280 - acc: 0.5125 -- iter: 128/185
[A[ATraining Step: 71  | total loss: [1m[32m0.69314[0m[0m | time: 4.800s
[2K
| Adam | epoch: 012 | loss: 0.69314 - acc: 0.5043 -- iter: 160/185
[A[ATraining Step: 72  | total loss: [1m[32m0.69340[0m[0m | time: 6.858s
[2K
| Adam | epoch: 012 | loss: 0.69340 - acc: 0.4968 | val_loss: 0.69501 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 73  | total loss: [1m[32m0.69341[0m[0m | time: 0.645s
[2K
| Adam | epoch: 013 | loss: 0.69341 - acc: 0.4971 -- iter: 032/185
[A[ATraining Step: 74  | total loss: [1m[32m0.69352[0m[0m | time: 1.316s
[2K
| Adam | epoch: 013 | loss: 0.69352 - acc: 0.4940 -- iter: 064/185
[A[ATraining Step: 75  | total loss: [1m[32m0.69290[0m[0m | time: 2.066s
[2K
| Adam | epoch: 013 | loss: 0.69290 - acc: 0.5116 -- iter: 096/185
[A[ATraining Step: 76  | total loss: [1m[32m0.69315[0m[0m | time: 2.643s
[2K
| Adam | epoch: 013 | loss: 0.69315 - acc: 0.5037 -- iter: 128/185
[A[ATraining Step: 77  | total loss: [1m[32m0.69291[0m[0m | time: 3.213s
[2K
| Adam | epoch: 013 | loss: 0.69291 - acc: 0.5096 -- iter: 160/185
[A[ATraining Step: 78  | total loss: [1m[32m0.69268[0m[0m | time: 4.878s
[2K
| Adam | epoch: 013 | loss: 0.69268 - acc: 0.5149 | val_loss: 0.69506 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 79  | total loss: [1m[32m0.69291[0m[0m | time: 0.667s
[2K
| Adam | epoch: 014 | loss: 0.69291 - acc: 0.5069 -- iter: 032/185
[A[ATraining Step: 80  | total loss: [1m[32m0.69288[0m[0m | time: 1.318s
[2K
| Adam | epoch: 014 | loss: 0.69288 - acc: 0.5062 -- iter: 064/185
[A[ATraining Step: 81  | total loss: [1m[32m0.69267[0m[0m | time: 2.033s
[2K
| Adam | epoch: 014 | loss: 0.69267 - acc: 0.5119 -- iter: 096/185
[A[ATraining Step: 82  | total loss: [1m[32m0.69224[0m[0m | time: 2.677s
[2K
| Adam | epoch: 014 | loss: 0.69224 - acc: 0.5201 -- iter: 128/185
[A[ATraining Step: 83  | total loss: [1m[32m0.69179[0m[0m | time: 3.232s
[2K
| Adam | epoch: 014 | loss: 0.69179 - acc: 0.5274 -- iter: 160/185
[A[ATraining Step: 84  | total loss: [1m[32m0.69217[0m[0m | time: 4.745s
[2K
| Adam | epoch: 014 | loss: 0.69217 - acc: 0.5187 | val_loss: 0.69513 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 85  | total loss: [1m[32m0.69248[0m[0m | time: 0.662s
[2K
| Adam | epoch: 015 | loss: 0.69248 - acc: 0.5108 -- iter: 032/185
[A[ATraining Step: 86  | total loss: [1m[32m0.69322[0m[0m | time: 1.278s
[2K
| Adam | epoch: 015 | loss: 0.69322 - acc: 0.4972 -- iter: 064/185
[A[ATraining Step: 87  | total loss: [1m[32m0.69324[0m[0m | time: 1.953s
[2K
| Adam | epoch: 015 | loss: 0.69324 - acc: 0.4944 -- iter: 096/185
[A[ATraining Step: 88  | total loss: [1m[32m0.69310[0m[0m | time: 2.651s
[2K
| Adam | epoch: 015 | loss: 0.69310 - acc: 0.4950 -- iter: 128/185
[A[ATraining Step: 89  | total loss: [1m[32m0.69293[0m[0m | time: 3.319s
[2K
| Adam | epoch: 015 | loss: 0.69293 - acc: 0.4955 -- iter: 160/185
[A[ATraining Step: 90  | total loss: [1m[32m0.69228[0m[0m | time: 4.896s
[2K
| Adam | epoch: 015 | loss: 0.69228 - acc: 0.5053 | val_loss: 0.69734 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 91  | total loss: [1m[32m0.69070[0m[0m | time: 1.006s
[2K
| Adam | epoch: 016 | loss: 0.69070 - acc: 0.5188 -- iter: 032/185
[A[ATraining Step: 92  | total loss: [1m[32m0.68849[0m[0m | time: 1.875s
[2K
| Adam | epoch: 016 | loss: 0.68849 - acc: 0.5309 -- iter: 064/185
[A[ATraining Step: 93  | total loss: [1m[32m0.69194[0m[0m | time: 3.782s
[2K
| Adam | epoch: 016 | loss: 0.69194 - acc: 0.5153 -- iter: 096/185
[A[ATraining Step: 94  | total loss: [1m[32m0.68962[0m[0m | time: 4.823s
[2K
| Adam | epoch: 016 | loss: 0.68962 - acc: 0.5231 -- iter: 128/185
[A[ATraining Step: 95  | total loss: [1m[32m0.69243[0m[0m | time: 5.794s
[2K
| Adam | epoch: 016 | loss: 0.69243 - acc: 0.5083 -- iter: 160/185
[A[ATraining Step: 96  | total loss: [1m[32m0.69064[0m[0m | time: 7.698s
[2K
| Adam | epoch: 016 | loss: 0.69064 - acc: 0.5137 | val_loss: 0.69419 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 97  | total loss: [1m[32m0.69120[0m[0m | time: 0.748s
[2K
| Adam | epoch: 017 | loss: 0.69120 - acc: 0.5061 -- iter: 032/185
[A[ATraining Step: 98  | total loss: [1m[32m0.68877[0m[0m | time: 1.755s
[2K
| Adam | epoch: 017 | loss: 0.68877 - acc: 0.5155 -- iter: 064/185
[A[ATraining Step: 99  | total loss: [1m[32m0.68614[0m[0m | time: 3.076s
[2K
| Adam | epoch: 017 | loss: 0.68614 - acc: 0.5240 -- iter: 096/185
[A[ATraining Step: 100  | total loss: [1m[32m0.68581[0m[0m | time: 4.009s
[2K
| Adam | epoch: 017 | loss: 0.68581 - acc: 0.5216 -- iter: 128/185
[A[ATraining Step: 101  | total loss: [1m[32m0.68481[0m[0m | time: 16.282s
[2K
| Adam | epoch: 017 | loss: 0.68481 - acc: 0.5194 -- iter: 160/185
[A[ATraining Step: 102  | total loss: [1m[32m0.68247[0m[0m | time: 52.782s
[2K
| Adam | epoch: 017 | loss: 0.68247 - acc: 0.5206 | val_loss: 0.68051 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 103  | total loss: [1m[32m0.68111[0m[0m | time: 1.040s
[2K
| Adam | epoch: 018 | loss: 0.68111 - acc: 0.5185 -- iter: 032/185
[A[ATraining Step: 104  | total loss: [1m[32m0.67854[0m[0m | time: 1.882s
[2K
| Adam | epoch: 018 | loss: 0.67854 - acc: 0.5167 -- iter: 064/185
[A[ATraining Step: 105  | total loss: [1m[32m0.67714[0m[0m | time: 2.712s
[2K
| Adam | epoch: 018 | loss: 0.67714 - acc: 0.5130 -- iter: 096/185
[A[ATraining Step: 106  | total loss: [1m[32m0.67477[0m[0m | time: 3.821s
[2K
| Adam | epoch: 018 | loss: 0.67477 - acc: 0.5097 -- iter: 128/185
[A[ATraining Step: 107  | total loss: [1m[32m0.67355[0m[0m | time: 4.903s
[2K
| Adam | epoch: 018 | loss: 0.67355 - acc: 0.5119 -- iter: 160/185
[A[ATraining Step: 108  | total loss: [1m[32m0.66593[0m[0m | time: 6.831s
[2K
| Adam | epoch: 018 | loss: 0.66593 - acc: 0.5138 | val_loss: 0.61621 - val_acc: 0.4483 -- iter: 185/185
--
Training Step: 109  | total loss: [1m[32m0.66378[0m[0m | time: 1.231s
[2K
| Adam | epoch: 019 | loss: 0.66378 - acc: 0.5062 -- iter: 032/185
[A[ATraining Step: 110  | total loss: [1m[32m0.65815[0m[0m | time: 5.118s
[2K
| Adam | epoch: 019 | loss: 0.65815 - acc: 0.5087 -- iter: 064/185
[A[ATraining Step: 111  | total loss: [1m[32m0.64945[0m[0m | time: 13.977s
[2K
| Adam | epoch: 019 | loss: 0.64945 - acc: 0.5234 -- iter: 096/185
[A[ATraining Step: 112  | total loss: [1m[32m0.65402[0m[0m | time: 14.759s
[2K
| Adam | epoch: 019 | loss: 0.65402 - acc: 0.5231 -- iter: 128/185
[A[ATraining Step: 113  | total loss: [1m[32m0.64517[0m[0m | time: 15.794s
[2K
| Adam | epoch: 019 | loss: 0.64517 - acc: 0.5428 -- iter: 160/185
[A[ATraining Step: 114  | total loss: [1m[32m0.63856[0m[0m | time: 17.814s
[2K
| Adam | epoch: 019 | loss: 0.63856 - acc: 0.5698 | val_loss: 0.58900 - val_acc: 0.7241 -- iter: 185/185
--
Training Step: 115  | total loss: [1m[32m0.63268[0m[0m | time: 1.153s
[2K
| Adam | epoch: 020 | loss: 0.63268 - acc: 0.5878 -- iter: 032/185
[A[ATraining Step: 116  | total loss: [1m[32m0.62430[0m[0m | time: 2.431s
[2K
| Adam | epoch: 020 | loss: 0.62430 - acc: 0.6040 -- iter: 064/185
[A[ATraining Step: 117  | total loss: [1m[32m0.61664[0m[0m | time: 3.682s
[2K
| Adam | epoch: 020 | loss: 0.61664 - acc: 0.6124 -- iter: 096/185
[A[ATraining Step: 118  | total loss: [1m[32m0.60722[0m[0m | time: 13.765s
[2K
| Adam | epoch: 020 | loss: 0.60722 - acc: 0.6324 -- iter: 128/185
[A[ATraining Step: 119  | total loss: [1m[32m0.59541[0m[0m | time: 27.140s
[2K
| Adam | epoch: 020 | loss: 0.59541 - acc: 0.6451 -- iter: 160/185
[A[ATraining Step: 120  | total loss: [1m[32m0.58796[0m[0m | time: 30.778s
[2K
| Adam | epoch: 020 | loss: 0.58796 - acc: 0.6606 | val_loss: 0.54923 - val_acc: 0.7931 -- iter: 185/185
--
Training Step: 121  | total loss: [1m[32m0.58577[0m[0m | time: 1.105s
[2K
| Adam | epoch: 021 | loss: 0.58577 - acc: 0.6571 -- iter: 032/185
[A[ATraining Step: 122  | total loss: [1m[32m0.58476[0m[0m | time: 2.195s
[2K
| Adam | epoch: 021 | loss: 0.58476 - acc: 0.6632 -- iter: 064/185
[A[ATraining Step: 123  | total loss: [1m[32m0.57805[0m[0m | time: 3.179s
[2K
| Adam | epoch: 021 | loss: 0.57805 - acc: 0.6750 -- iter: 096/185
[A[ATraining Step: 124  | total loss: [1m[32m0.57484[0m[0m | time: 4.286s
[2K
| Adam | epoch: 021 | loss: 0.57484 - acc: 0.6731 -- iter: 128/185
[A[ATraining Step: 125  | total loss: [1m[32m0.56846[0m[0m | time: 5.323s
[2K
| Adam | epoch: 021 | loss: 0.56846 - acc: 0.6871 -- iter: 160/185
[A[ATraining Step: 126  | total loss: [1m[32m0.55223[0m[0m | time: 15.096s
[2K
| Adam | epoch: 021 | loss: 0.55223 - acc: 0.7064 | val_loss: 0.54859 - val_acc: 0.7931 -- iter: 185/185
--
Training Step: 127  | total loss: [1m[32m0.53624[0m[0m | time: 16.986s
[2K
| Adam | epoch: 022 | loss: 0.53624 - acc: 0.7277 -- iter: 032/185
[A[ATraining Step: 128  | total loss: [1m[32m0.52862[0m[0m | time: 28.256s
[2K
| Adam | epoch: 022 | loss: 0.52862 - acc: 0.7331 -- iter: 064/185
[A[ATraining Step: 129  | total loss: [1m[32m0.52641[0m[0m | time: 38.333s
[2K
| Adam | epoch: 022 | loss: 0.52641 - acc: 0.7410 -- iter: 096/185
[A[ATraining Step: 130  | total loss: [1m[32m0.51825[0m[0m | time: 39.376s
[2K
| Adam | epoch: 022 | loss: 0.51825 - acc: 0.7357 -- iter: 128/185
[A[ATraining Step: 131  | total loss: [1m[32m0.52115[0m[0m | time: 40.289s
[2K
| Adam | epoch: 022 | loss: 0.52115 - acc: 0.7402 -- iter: 160/185
[A[ATraining Step: 132  | total loss: [1m[32m0.51874[0m[0m | time: 42.135s
[2K
| Adam | epoch: 022 | loss: 0.51874 - acc: 0.7318 | val_loss: 0.52967 - val_acc: 0.7586 -- iter: 185/185
--
Training Step: 133  | total loss: [1m[32m0.52913[0m[0m | time: 0.888s
[2K
| Adam | epoch: 023 | loss: 0.52913 - acc: 0.7307 -- iter: 032/185
[A[ATraining Step: 134  | total loss: [1m[32m0.53360[0m[0m | time: 1.972s
[2K
| Adam | epoch: 023 | loss: 0.53360 - acc: 0.7336 -- iter: 064/185
[A[ATraining Step: 135  | total loss: [1m[32m0.53235[0m[0m | time: 3.131s
[2K
| Adam | epoch: 023 | loss: 0.53235 - acc: 0.7384 -- iter: 096/185
[A[ATraining Step: 136  | total loss: [1m[32m0.53672[0m[0m | time: 4.327s
[2K
| Adam | epoch: 023 | loss: 0.53672 - acc: 0.7395 -- iter: 128/185
[A[ATraining Step: 137  | total loss: [1m[32m0.53298[0m[0m | time: 29.573s
[2K
| Adam | epoch: 023 | loss: 0.53298 - acc: 0.7374 -- iter: 160/185
[A[ATraining Step: 138  | total loss: [1m[32m0.52284[0m[0m | time: 63.361s
[2K
| Adam | epoch: 023 | loss: 0.52284 - acc: 0.7449 | val_loss: 1.16844 - val_acc: 0.5690 -- iter: 185/185
--
Training Step: 139  | total loss: [1m[32m0.52719[0m[0m | time: 1.078s
[2K
| Adam | epoch: 024 | loss: 0.52719 - acc: 0.7423 -- iter: 032/185
[A[ATraining Step: 140  | total loss: [1m[32m0.53821[0m[0m | time: 25.069s
[2K
| Adam | epoch: 024 | loss: 0.53821 - acc: 0.7321 -- iter: 064/185
[A[ATraining Step: 141  | total loss: [1m[32m0.54052[0m[0m | time: 36.921s
[2K
| Adam | epoch: 024 | loss: 0.54052 - acc: 0.7389 -- iter: 096/185
[A[ATraining Step: 142  | total loss: [1m[32m0.52983[0m[0m | time: 38.953s
[2K
| Adam | epoch: 024 | loss: 0.52983 - acc: 0.7494 -- iter: 128/185
[A[ATraining Step: 143  | total loss: [1m[32m0.53966[0m[0m | time: 41.891s
[2K
| Adam | epoch: 024 | loss: 0.53966 - acc: 0.7463 -- iter: 160/185
[A[ATraining Step: 144  | total loss: [1m[32m0.53869[0m[0m | time: 65.102s
[2K
| Adam | epoch: 024 | loss: 0.53869 - acc: 0.7404 | val_loss: 0.56921 - val_acc: 0.7586 -- iter: 185/185
--
Training Step: 145  | total loss: [1m[32m0.54194[0m[0m | time: 2.299s
[2K
| Adam | epoch: 025 | loss: 0.54194 - acc: 0.7383 -- iter: 032/185
[A[ATraining Step: 146  | total loss: [1m[32m0.55001[0m[0m | time: 12.063s
[2K
| Adam | epoch: 025 | loss: 0.55001 - acc: 0.7332 -- iter: 064/185
[A[ATraining Step: 147  | total loss: [1m[32m0.55424[0m[0m | time: 18.798s
[2K
| Adam | epoch: 025 | loss: 0.55424 - acc: 0.7279 -- iter: 096/185
[A[ATraining Step: 148  | total loss: [1m[32m0.55484[0m[0m | time: 28.021s
[2K
| Adam | epoch: 025 | loss: 0.55484 - acc: 0.7271 -- iter: 128/185
[A[ATraining Step: 149  | total loss: [1m[32m0.54090[0m[0m | time: 29.197s
[2K
| Adam | epoch: 025 | loss: 0.54090 - acc: 0.7450 -- iter: 160/185
[A[ATraining Step: 150  | total loss: [1m[32m0.53010[0m[0m | time: 48.880s
[2K
| Adam | epoch: 025 | loss: 0.53010 - acc: 0.7517 | val_loss: 0.62920 - val_acc: 0.7069 -- iter: 185/185
--
Training Step: 151  | total loss: [1m[32m0.52437[0m[0m | time: 12.121s
[2K
| Adam | epoch: 026 | loss: 0.52437 - acc: 0.7578 -- iter: 032/185
[A[ATraining Step: 152  | total loss: [1m[32m0.51982[0m[0m | time: 26.796s
[2K
| Adam | epoch: 026 | loss: 0.51982 - acc: 0.7508 -- iter: 064/185
[A[ATraining Step: 153  | total loss: [1m[32m0.50580[0m[0m | time: 35.785s
[2K
| Adam | epoch: 026 | loss: 0.50580 - acc: 0.7570 -- iter: 096/185
[A[ATraining Step: 154  | total loss: [1m[32m0.49246[0m[0m | time: 36.783s
[2K
| Adam | epoch: 026 | loss: 0.49246 - acc: 0.7693 -- iter: 128/185
[A[ATraining Step: 155  | total loss: [1m[32m0.47667[0m[0m | time: 41.398s
[2K
| Adam | epoch: 026 | loss: 0.47667 - acc: 0.7803 -- iter: 160/185
[A[ATraining Step: 156  | total loss: [1m[32m0.46953[0m[0m | time: 43.973s
[2K
| Adam | epoch: 026 | loss: 0.46953 - acc: 0.7836 | val_loss: 0.47084 - val_acc: 0.8103 -- iter: 185/185
--
Training Step: 157  | total loss: [1m[32m0.47733[0m[0m | time: 1.383s
[2K
| Adam | epoch: 027 | loss: 0.47733 - acc: 0.7771 -- iter: 032/185
[A[ATraining Step: 158  | total loss: [1m[32m0.45627[0m[0m | time: 2.567s
[2K
| Adam | epoch: 027 | loss: 0.45627 - acc: 0.7900 -- iter: 064/185
[A[ATraining Step: 159  | total loss: [1m[32m0.46211[0m[0m | time: 3.628s
[2K
| Adam | epoch: 027 | loss: 0.46211 - acc: 0.7860 -- iter: 096/185
[A[ATraining Step: 160  | total loss: [1m[32m0.45961[0m[0m | time: 4.568s
[2K
| Adam | epoch: 027 | loss: 0.45961 - acc: 0.7855 -- iter: 128/185
[A[ATraining Step: 161  | total loss: [1m[32m0.44526[0m[0m | time: 5.642s
[2K
| Adam | epoch: 027 | loss: 0.44526 - acc: 0.7910 -- iter: 160/185
[A[ATraining Step: 162  | total loss: [1m[32m0.42966[0m[0m | time: 8.137s
[2K
| Adam | epoch: 027 | loss: 0.42966 - acc: 0.8079 | val_loss: 0.47123 - val_acc: 0.8103 -- iter: 185/185
--
Training Step: 163  | total loss: [1m[32m0.41351[0m[0m | time: 30.520s
[2K
| Adam | epoch: 028 | loss: 0.41351 - acc: 0.8208 -- iter: 032/185
[A[ATraining Step: 164  | total loss: [1m[32m0.41562[0m[0m | time: 52.001s
[2K
| Adam | epoch: 028 | loss: 0.41562 - acc: 0.8200 -- iter: 064/185
[A[ATraining Step: 165  | total loss: [1m[32m0.41041[0m[0m | time: 84.756s
[2K
| Adam | epoch: 028 | loss: 0.41041 - acc: 0.8224 -- iter: 096/185
[A[ATraining Step: 166  | total loss: [1m[32m0.40494[0m[0m | time: 99.270s
[2K
| Adam | epoch: 028 | loss: 0.40494 - acc: 0.8245 -- iter: 128/185
[A[ATraining Step: 167  | total loss: [1m[32m0.40286[0m[0m | time: 112.950s
[2K
| Adam | epoch: 028 | loss: 0.40286 - acc: 0.8233 -- iter: 160/185
[A[ATraining Step: 168  | total loss: [1m[32m0.38647[0m[0m | time: 176.914s
[2K
| Adam | epoch: 028 | loss: 0.38647 - acc: 0.8370 | val_loss: 0.66379 - val_acc: 0.7931 -- iter: 185/185
--
Training Step: 169  | total loss: [1m[32m0.37140[0m[0m | time: 6.748s
[2K
| Adam | epoch: 029 | loss: 0.37140 - acc: 0.8493 -- iter: 032/185
[A[ATraining Step: 170  | total loss: [1m[32m0.35500[0m[0m | time: 25.129s
[2K
| Adam | epoch: 029 | loss: 0.35500 - acc: 0.8581 -- iter: 064/185
[A[ATraining Step: 171  | total loss: [1m[32m0.35953[0m[0m | time: 48.975s
[2K
| Adam | epoch: 029 | loss: 0.35953 - acc: 0.8535 -- iter: 096/185
[A[ATraining Step: 172  | total loss: [1m[32m0.36621[0m[0m | time: 69.590s
[2K
| Adam | epoch: 029 | loss: 0.36621 - acc: 0.8494 -- iter: 128/185
[A[ATraining Step: 173  | total loss: [1m[32m0.36145[0m[0m | time: 92.438s
[2K
| Adam | epoch: 029 | loss: 0.36145 - acc: 0.8520 -- iter: 160/185
[A[ATraining Step: 174  | total loss: [1m[32m0.35600[0m[0m | time: 130.060s
[2K
| Adam | epoch: 029 | loss: 0.35600 - acc: 0.8512 | val_loss: 0.62117 - val_acc: 0.7931 -- iter: 185/185
--
Training Step: 175  | total loss: [1m[32m0.35454[0m[0m | time: 1.168s
[2K
| Adam | epoch: 030 | loss: 0.35454 - acc: 0.8501 -- iter: 032/185
[A[ATraining Step: 176  | total loss: [1m[32m0.34666[0m[0m | time: 9.445s
[2K
| Adam | epoch: 030 | loss: 0.34666 - acc: 0.8530 -- iter: 064/185
[A[ATraining Step: 177  | total loss: [1m[32m0.33644[0m[0m | time: 10.668s
[2K
| Adam | epoch: 030 | loss: 0.33644 - acc: 0.8584 -- iter: 096/185
[A[ATraining Step: 178  | total loss: [1m[32m0.32723[0m[0m | time: 12.011s
[2K
| Adam | epoch: 030 | loss: 0.32723 - acc: 0.8632 -- iter: 128/185
[A[ATraining Step: 179  | total loss: [1m[32m0.33369[0m[0m | time: 13.389s
[2K
| Adam | epoch: 030 | loss: 0.33369 - acc: 0.8612 -- iter: 160/185
[A[ATraining Step: 180  | total loss: [1m[32m0.33189[0m[0m | time: 15.723s
[2K
| Adam | epoch: 030 | loss: 0.33189 - acc: 0.8657 | val_loss: 1.73758 - val_acc: 0.5690 -- iter: 185/185
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8846153846153846
Validation AUPRC:0.8944472808962538
Test AUC:0.8071428571428572
Test AUPRC:0.8250794179381467
BestTestF1Score	0.79	0.56	0.78	0.73	0.86	24	9	21	4	0.99
BestTestMCCScore	0.79	0.56	0.78	0.73	0.86	24	9	21	4	0.99
BestTestAccuracyScore	0.71	0.45	0.72	0.71	0.71	20	8	22	8	1.0
BestValidationF1Score	0.79	0.6	0.79	0.72	0.88	23	9	23	3	0.99
BestValidationMCC	0.79	0.6	0.79	0.72	0.88	23	9	23	3	0.99
BestValidationAccuracy	0.77	0.58	0.79	0.77	0.77	20	6	26	6	1.0
TestPredictions (Threshold:0.99)
CHEMBL17775,FP,INACT,1.0	CHEMBL433554,TP,ACT,1.0	CHEMBL1916447,FP,INACT,1.0	CHEMBL52,FN,ACT,0.20000000298023224	CHEMBL360987,TP,ACT,1.0	CHEMBL460862,TP,ACT,0.9900000095367432	CHEMBL425336,TP,ACT,1.0	CHEMBL104195,TN,INACT,0.2199999988079071	CHEMBL392570,TP,ACT,1.0	CHEMBL235275,TP,ACT,1.0	CHEMBL1163221,FP,INACT,1.0	CHEMBL179335,TP,ACT,1.0	CHEMBL44,FN,ACT,0.7300000190734863	CHEMBL1916430,TN,INACT,0.9599999785423279	CHEMBL1929092,TN,INACT,0.20000000298023224	CHEMBL180947,TP,ACT,1.0	CHEMBL361315,TP,ACT,1.0	CHEMBL1929090,TN,INACT,0.1599999964237213	CHEMBL236828,TP,ACT,1.0	CHEMBL177085,FP,INACT,1.0	CHEMBL2165866,TN,INACT,0.7300000190734863	CHEMBL178495,TP,ACT,1.0	CHEMBL181028,TP,ACT,1.0	CHEMBL235251,TP,ACT,1.0	CHEMBL1796843,TP,ACT,1.0	CHEMBL1916435,FP,INACT,1.0	CHEMBL181340,FP,INACT,1.0	CHEMBL3262913,TN,INACT,0.9700000286102295	CHEMBL1796851,TP,ACT,0.9900000095367432	CHEMBL320923,TN,INACT,0.2800000011920929	CHEMBL1796845,TP,ACT,0.9900000095367432	CHEMBL3094153,TN,INACT,0.2199999988079071	CHEMBL1009,FN,ACT,0.5799999833106995	CHEMBL1916444,FP,INACT,1.0	CHEMBL46469,FP,INACT,1.0	CHEMBL406,FN,ACT,0.27000001072883606	CHEMBL2165874,TN,INACT,0.8100000023841858	CHEMBL427319,TP,ACT,1.0	CHEMBL926,TP,ACT,1.0	CHEMBL236827,TP,ACT,1.0	CHEMBL1164950,TN,INACT,0.8999999761581421	CHEMBL1164396,TN,INACT,0.6000000238418579	CHEMBL179844,TP,ACT,1.0	CHEMBL391038,TP,ACT,1.0	CHEMBL186858,TN,INACT,0.9700000286102295	CHEMBL2147415,TN,INACT,0.8100000023841858	CHEMBL459721,TN,INACT,0.9300000071525574	CHEMBL281259,TN,INACT,0.6100000143051147	CHEMBL1916428,TN,INACT,0.6000000238418579	CHEMBL1796850,TP,ACT,1.0	CHEMBL505073,TN,INACT,0.9800000190734863	CHEMBL2165873,TN,INACT,0.2199999988079071	CHEMBL193482,TP,ACT,0.9900000095367432	CHEMBL512897,FP,INACT,0.9900000095367432	CHEMBL1929093,TN,INACT,0.2199999988079071	CHEMBL2163373,TN,INACT,0.6700000166893005	CHEMBL180838,TP,ACT,1.0	CHEMBL107150,TN,INACT,0.9800000190734863	

