ImageNetInceptionV2 CHEMBL3374 adam 0.0005 15 0 0 0.6 False True
Number of active compounds :	264
Number of inactive compounds :	264
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3374_adam_0.0005_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3374_adam_0.0005_15_0.6/
---------------------------------
Training samples: 313
Validation samples: 99
--
Training Step: 1  | time: 53.624s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/313
[A[ATraining Step: 2  | total loss: [1m[32m0.69130[0m[0m | time: 61.754s
[2K
| Adam | epoch: 001 | loss: 0.69130 - acc: 0.4219 -- iter: 064/313
[A[ATraining Step: 3  | total loss: [1m[32m0.53116[0m[0m | time: 69.794s
[2K
| Adam | epoch: 001 | loss: 0.53116 - acc: 0.6648 -- iter: 096/313
[A[ATraining Step: 4  | total loss: [1m[32m0.42059[0m[0m | time: 78.730s
[2K
| Adam | epoch: 001 | loss: 0.42059 - acc: 0.7756 -- iter: 128/313
[A[ATraining Step: 5  | total loss: [1m[32m0.39592[0m[0m | time: 91.781s
[2K
| Adam | epoch: 001 | loss: 0.39592 - acc: 0.8228 -- iter: 160/313
[A[ATraining Step: 6  | total loss: [1m[32m0.36869[0m[0m | time: 104.554s
[2K
| Adam | epoch: 001 | loss: 0.36869 - acc: 0.8162 -- iter: 192/313
[A[ATraining Step: 7  | total loss: [1m[32m0.59495[0m[0m | time: 117.374s
[2K
| Adam | epoch: 001 | loss: 0.59495 - acc: 0.8515 -- iter: 224/313
[A[ATraining Step: 8  | total loss: [1m[32m0.57801[0m[0m | time: 129.927s
[2K
| Adam | epoch: 001 | loss: 0.57801 - acc: 0.7944 -- iter: 256/313
[A[ATraining Step: 9  | total loss: [1m[32m0.44587[0m[0m | time: 142.856s
[2K
| Adam | epoch: 001 | loss: 0.44587 - acc: 0.8040 -- iter: 288/313
[A[ATraining Step: 10  | total loss: [1m[32m0.31415[0m[0m | time: 172.500s
[2K
| Adam | epoch: 001 | loss: 0.31415 - acc: 0.8864 | val_loss: 2.49085 - val_acc: 0.5354 -- iter: 313/313
--
Training Step: 11  | total loss: [1m[32m0.29456[0m[0m | time: 10.049s
[2K
| Adam | epoch: 002 | loss: 0.29456 - acc: 0.8833 -- iter: 032/313
[A[ATraining Step: 12  | total loss: [1m[32m0.26579[0m[0m | time: 22.733s
[2K
| Adam | epoch: 002 | loss: 0.26579 - acc: 0.8818 -- iter: 064/313
[A[ATraining Step: 13  | total loss: [1m[32m0.19636[0m[0m | time: 35.056s
[2K
| Adam | epoch: 002 | loss: 0.19636 - acc: 0.9057 -- iter: 096/313
[A[ATraining Step: 14  | total loss: [1m[32m0.27829[0m[0m | time: 47.735s
[2K
| Adam | epoch: 002 | loss: 0.27829 - acc: 0.9187 -- iter: 128/313
[A[ATraining Step: 15  | total loss: [1m[32m0.20657[0m[0m | time: 60.329s
[2K
| Adam | epoch: 002 | loss: 0.20657 - acc: 0.9383 -- iter: 160/313
[A[ATraining Step: 16  | total loss: [1m[32m0.25503[0m[0m | time: 72.738s
[2K
| Adam | epoch: 002 | loss: 0.25503 - acc: 0.8911 -- iter: 192/313
[A[ATraining Step: 17  | total loss: [1m[32m0.22243[0m[0m | time: 85.168s
[2K
| Adam | epoch: 002 | loss: 0.22243 - acc: 0.9191 -- iter: 224/313
[A[ATraining Step: 18  | total loss: [1m[32m0.17841[0m[0m | time: 97.850s
[2K
| Adam | epoch: 002 | loss: 0.17841 - acc: 0.9363 -- iter: 256/313
[A[ATraining Step: 19  | total loss: [1m[32m0.14159[0m[0m | time: 110.910s
[2K
| Adam | epoch: 002 | loss: 0.14159 - acc: 0.9575 -- iter: 288/313
[A[ATraining Step: 20  | total loss: [1m[32m0.20368[0m[0m | time: 123.524s
[2K
| Adam | epoch: 002 | loss: 0.20368 - acc: 0.9209 | val_loss: 4.23429 - val_acc: 0.5354 -- iter: 313/313
--
Training Step: 21  | total loss: [1m[32m0.17409[0m[0m | time: 10.240s
[2K
| Adam | epoch: 003 | loss: 0.17409 - acc: 0.9261 -- iter: 032/313
[A[ATraining Step: 22  | total loss: [1m[32m0.15786[0m[0m | time: 21.061s
[2K
| Adam | epoch: 003 | loss: 0.15786 - acc: 0.9363 -- iter: 064/313
[A[ATraining Step: 23  | total loss: [1m[32m0.25211[0m[0m | time: 46.106s
[2K
| Adam | epoch: 003 | loss: 0.25211 - acc: 0.9083 -- iter: 096/313
[A[ATraining Step: 24  | total loss: [1m[32m0.18975[0m[0m | time: 69.746s
[2K
| Adam | epoch: 003 | loss: 0.18975 - acc: 0.9341 -- iter: 128/313
[A[ATraining Step: 25  | total loss: [1m[32m0.17645[0m[0m | time: 105.145s
[2K
| Adam | epoch: 003 | loss: 0.17645 - acc: 0.9435 -- iter: 160/313
[A[ATraining Step: 26  | total loss: [1m[32m0.14256[0m[0m | time: 123.572s
[2K
| Adam | epoch: 003 | loss: 0.14256 - acc: 0.9502 -- iter: 192/313
[A[ATraining Step: 27  | total loss: [1m[32m0.11573[0m[0m | time: 159.223s
[2K
| Adam | epoch: 003 | loss: 0.11573 - acc: 0.9630 -- iter: 224/313
[A[ATraining Step: 28  | total loss: [1m[32m0.10751[0m[0m | time: 187.479s
[2K
| Adam | epoch: 003 | loss: 0.10751 - acc: 0.9723 -- iter: 256/313
[A[ATraining Step: 29  | total loss: [1m[32m0.11178[0m[0m | time: 197.499s
[2K
| Adam | epoch: 003 | loss: 0.11178 - acc: 0.9714 -- iter: 288/313
[A[ATraining Step: 30  | total loss: [1m[32m0.13199[0m[0m | time: 210.119s
[2K
| Adam | epoch: 003 | loss: 0.13199 - acc: 0.9708 | val_loss: 3.40529 - val_acc: 0.5354 -- iter: 313/313
--
Training Step: 31  | total loss: [1m[32m0.15299[0m[0m | time: 11.859s
[2K
| Adam | epoch: 004 | loss: 0.15299 - acc: 0.9487 -- iter: 032/313
[A[ATraining Step: 32  | total loss: [1m[32m0.13657[0m[0m | time: 22.391s
[2K
| Adam | epoch: 004 | loss: 0.13657 - acc: 0.9532 -- iter: 064/313
[A[ATraining Step: 33  | total loss: [1m[32m0.12530[0m[0m | time: 32.717s
[2K
| Adam | epoch: 004 | loss: 0.12530 - acc: 0.9635 -- iter: 096/313
[A[ATraining Step: 34  | total loss: [1m[32m0.19671[0m[0m | time: 46.397s
[2K
| Adam | epoch: 004 | loss: 0.19671 - acc: 0.9456 -- iter: 128/313
[A[ATraining Step: 35  | total loss: [1m[32m0.17877[0m[0m | time: 67.657s
[2K
| Adam | epoch: 004 | loss: 0.17877 - acc: 0.9439 -- iter: 160/313
[A[ATraining Step: 36  | total loss: [1m[32m0.15848[0m[0m | time: 81.664s
[2K
| Adam | epoch: 004 | loss: 0.15848 - acc: 0.9490 -- iter: 192/313
[A[ATraining Step: 37  | total loss: [1m[32m0.13089[0m[0m | time: 99.107s
[2K
| Adam | epoch: 004 | loss: 0.13089 - acc: 0.9592 -- iter: 224/313
[A[ATraining Step: 38  | total loss: [1m[32m0.13125[0m[0m | time: 109.010s
[2K
| Adam | epoch: 004 | loss: 0.13125 - acc: 0.9549 -- iter: 256/313
[A[ATraining Step: 39  | total loss: [1m[32m0.13453[0m[0m | time: 116.765s
[2K
| Adam | epoch: 004 | loss: 0.13453 - acc: 0.9516 -- iter: 288/313
[A[ATraining Step: 40  | total loss: [1m[32m0.12282[0m[0m | time: 130.920s
[2K
| Adam | epoch: 004 | loss: 0.12282 - acc: 0.9548 | val_loss: 2.94896 - val_acc: 0.5354 -- iter: 313/313
--
Training Step: 41  | total loss: [1m[32m0.10647[0m[0m | time: 12.119s
[2K
| Adam | epoch: 005 | loss: 0.10647 - acc: 0.9631 -- iter: 032/313
[A[ATraining Step: 42  | total loss: [1m[32m0.09738[0m[0m | time: 24.437s
[2K
| Adam | epoch: 005 | loss: 0.09738 - acc: 0.9698 -- iter: 064/313
[A[ATraining Step: 43  | total loss: [1m[32m0.09774[0m[0m | time: 34.984s
[2K
| Adam | epoch: 005 | loss: 0.09774 - acc: 0.9641 -- iter: 096/313
[A[ATraining Step: 44  | total loss: [1m[32m0.09025[0m[0m | time: 45.856s
[2K
| Adam | epoch: 005 | loss: 0.09025 - acc: 0.9703 -- iter: 128/313
[A[ATraining Step: 45  | total loss: [1m[32m0.12497[0m[0m | time: 58.063s
[2K
| Adam | epoch: 005 | loss: 0.12497 - acc: 0.9685 -- iter: 160/313
[A[ATraining Step: 46  | total loss: [1m[32m0.10827[0m[0m | time: 71.057s
[2K
| Adam | epoch: 005 | loss: 0.10827 - acc: 0.9738 -- iter: 192/313
[A[ATraining Step: 47  | total loss: [1m[32m0.10652[0m[0m | time: 79.786s
[2K
| Adam | epoch: 005 | loss: 0.10652 - acc: 0.9730 -- iter: 224/313
[A[ATraining Step: 48  | total loss: [1m[32m0.09596[0m[0m | time: 87.842s
[2K
| Adam | epoch: 005 | loss: 0.09596 - acc: 0.9773 -- iter: 256/313
[A[ATraining Step: 49  | total loss: [1m[32m0.08207[0m[0m | time: 95.633s
[2K
| Adam | epoch: 005 | loss: 0.08207 - acc: 0.9809 -- iter: 288/313
[A[ATraining Step: 50  | total loss: [1m[32m0.07132[0m[0m | time: 115.262s
[2K
| Adam | epoch: 005 | loss: 0.07132 - acc: 0.9839 | val_loss: 2.20116 - val_acc: 0.5354 -- iter: 313/313
--
Training Step: 51  | total loss: [1m[32m0.06967[0m[0m | time: 12.193s
[2K
| Adam | epoch: 006 | loss: 0.06967 - acc: 0.9815 -- iter: 032/313
[A[ATraining Step: 52  | total loss: [1m[32m0.06904[0m[0m | time: 24.313s
[2K
| Adam | epoch: 006 | loss: 0.06904 - acc: 0.9796 -- iter: 064/313
[A[ATraining Step: 53  | total loss: [1m[32m0.06938[0m[0m | time: 36.693s
[2K
| Adam | epoch: 006 | loss: 0.06938 - acc: 0.9780 -- iter: 096/313
[A[ATraining Step: 54  | total loss: [1m[32m0.06390[0m[0m | time: 47.073s
[2K
| Adam | epoch: 006 | loss: 0.06390 - acc: 0.9812 -- iter: 128/313
[A[ATraining Step: 55  | total loss: [1m[32m0.05860[0m[0m | time: 57.366s
[2K
| Adam | epoch: 006 | loss: 0.05860 - acc: 0.9839 -- iter: 160/313
[A[ATraining Step: 56  | total loss: [1m[32m0.09480[0m[0m | time: 67.571s
[2K
| Adam | epoch: 006 | loss: 0.09480 - acc: 0.9805 -- iter: 192/313
[A[ATraining Step: 57  | total loss: [1m[32m0.08271[0m[0m | time: 75.352s
[2K
| Adam | epoch: 006 | loss: 0.08271 - acc: 0.9832 -- iter: 224/313
[A[ATraining Step: 58  | total loss: [1m[32m0.07204[0m[0m | time: 83.155s
[2K
| Adam | epoch: 006 | loss: 0.07204 - acc: 0.9855 -- iter: 256/313
[A[ATraining Step: 59  | total loss: [1m[32m0.06797[0m[0m | time: 91.103s
[2K
| Adam | epoch: 006 | loss: 0.06797 - acc: 0.9833 -- iter: 288/313
[A[ATraining Step: 60  | total loss: [1m[32m0.06474[0m[0m | time: 105.647s
[2K
| Adam | epoch: 006 | loss: 0.06474 - acc: 0.9813 | val_loss: 2.35371 - val_acc: 0.5354 -- iter: 313/313
--
Training Step: 61  | total loss: [1m[32m0.06164[0m[0m | time: 12.468s
[2K
| Adam | epoch: 007 | loss: 0.06164 - acc: 0.9838 -- iter: 032/313
[A[ATraining Step: 62  | total loss: [1m[32m0.07222[0m[0m | time: 25.513s
[2K
| Adam | epoch: 007 | loss: 0.07222 - acc: 0.9818 -- iter: 064/313
[A[ATraining Step: 63  | total loss: [1m[32m0.06495[0m[0m | time: 37.732s
[2K
| Adam | epoch: 007 | loss: 0.06495 - acc: 0.9841 -- iter: 096/313
[A[ATraining Step: 64  | total loss: [1m[32m0.06228[0m[0m | time: 50.323s
[2K
| Adam | epoch: 007 | loss: 0.06228 - acc: 0.9822 -- iter: 128/313
[A[ATraining Step: 65  | total loss: [1m[32m0.05570[0m[0m | time: 60.882s
[2K
| Adam | epoch: 007 | loss: 0.05570 - acc: 0.9844 -- iter: 160/313
[A[ATraining Step: 66  | total loss: [1m[32m0.05027[0m[0m | time: 71.320s
[2K
| Adam | epoch: 007 | loss: 0.05027 - acc: 0.9863 -- iter: 192/313
[A[ATraining Step: 67  | total loss: [1m[32m0.04532[0m[0m | time: 81.380s
[2K
| Adam | epoch: 007 | loss: 0.04532 - acc: 0.9880 -- iter: 224/313
[A[ATraining Step: 68  | total loss: [1m[32m0.04327[0m[0m | time: 89.378s
[2K
| Adam | epoch: 007 | loss: 0.04327 - acc: 0.9894 -- iter: 256/313
[A[ATraining Step: 69  | total loss: [1m[32m0.04266[0m[0m | time: 97.333s
[2K
| Adam | epoch: 007 | loss: 0.04266 - acc: 0.9906 -- iter: 288/313
[A[ATraining Step: 70  | total loss: [1m[32m0.03849[0m[0m | time: 109.674s
[2K
| Adam | epoch: 007 | loss: 0.03849 - acc: 0.9917 | val_loss: 0.21550 - val_acc: 0.8990 -- iter: 313/313
--
Training Step: 71  | total loss: [1m[32m0.03434[0m[0m | time: 17.868s
[2K
| Adam | epoch: 008 | loss: 0.03434 - acc: 0.9926 -- iter: 032/313
[A[ATraining Step: 72  | total loss: [1m[32m0.03107[0m[0m | time: 43.550s
[2K
| Adam | epoch: 008 | loss: 0.03107 - acc: 0.9935 -- iter: 064/313
[A[ATraining Step: 73  | total loss: [1m[32m0.02899[0m[0m | time: 55.747s
[2K
| Adam | epoch: 008 | loss: 0.02899 - acc: 0.9942 -- iter: 096/313
[A[ATraining Step: 74  | total loss: [1m[32m0.02891[0m[0m | time: 134.319s
[2K
| Adam | epoch: 008 | loss: 0.02891 - acc: 0.9914 -- iter: 128/313
[A[ATraining Step: 75  | total loss: [1m[32m0.02664[0m[0m | time: 224.836s
[2K
| Adam | epoch: 008 | loss: 0.02664 - acc: 0.9923 -- iter: 160/313
[A[ATraining Step: 76  | total loss: [1m[32m0.02518[0m[0m | time: 234.423s
[2K
| Adam | epoch: 008 | loss: 0.02518 - acc: 0.9932 -- iter: 192/313
[A[ATraining Step: 77  | total loss: [1m[32m0.02286[0m[0m | time: 241.036s
[2K
| Adam | epoch: 008 | loss: 0.02286 - acc: 0.9939 -- iter: 224/313
[A[ATraining Step: 78  | total loss: [1m[32m0.04471[0m[0m | time: 248.961s
[2K
| Adam | epoch: 008 | loss: 0.04471 - acc: 0.9903 -- iter: 256/313
[A[ATraining Step: 79  | total loss: [1m[32m0.04161[0m[0m | time: 259.200s
[2K
| Adam | epoch: 008 | loss: 0.04161 - acc: 0.9913 -- iter: 288/313
[A[ATraining Step: 80  | total loss: [1m[32m0.03868[0m[0m | time: 278.594s
[2K
| Adam | epoch: 008 | loss: 0.03868 - acc: 0.9922 | val_loss: 0.95975 - val_acc: 0.6263 -- iter: 313/313
--
Training Step: 81  | total loss: [1m[32m0.03607[0m[0m | time: 92.790s
[2K
| Adam | epoch: 009 | loss: 0.03607 - acc: 0.9930 -- iter: 032/313
[A[ATraining Step: 82  | total loss: [1m[32m0.03357[0m[0m | time: 159.508s
[2K
| Adam | epoch: 009 | loss: 0.03357 - acc: 0.9937 -- iter: 064/313
[A[ATraining Step: 83  | total loss: [1m[32m0.03536[0m[0m | time: 172.093s
[2K
| Adam | epoch: 009 | loss: 0.03536 - acc: 0.9912 -- iter: 096/313
[A[ATraining Step: 84  | total loss: [1m[32m0.04517[0m[0m | time: 184.714s
[2K
| Adam | epoch: 009 | loss: 0.04517 - acc: 0.9890 -- iter: 128/313
[A[ATraining Step: 85  | total loss: [1m[32m0.04490[0m[0m | time: 194.291s
[2K
| Adam | epoch: 009 | loss: 0.04490 - acc: 0.9869 -- iter: 160/313
[A[ATraining Step: 86  | total loss: [1m[32m0.04068[0m[0m | time: 201.999s
[2K
| Adam | epoch: 009 | loss: 0.04068 - acc: 0.9883 -- iter: 192/313
[A[ATraining Step: 87  | total loss: [1m[32m0.04307[0m[0m | time: 208.603s
[2K
| Adam | epoch: 009 | loss: 0.04307 - acc: 0.9863 -- iter: 224/313
[A[ATraining Step: 88  | total loss: [1m[32m0.07895[0m[0m | time: 216.473s
[2K
| Adam | epoch: 009 | loss: 0.07895 - acc: 0.9797 -- iter: 256/313
[A[ATraining Step: 89  | total loss: [1m[32m0.11221[0m[0m | time: 228.692s
[2K
| Adam | epoch: 009 | loss: 0.11221 - acc: 0.9737 -- iter: 288/313
[A[ATraining Step: 90  | total loss: [1m[32m0.10207[0m[0m | time: 248.497s
[2K
| Adam | epoch: 009 | loss: 0.10207 - acc: 0.9763 | val_loss: 9.58884 - val_acc: 0.4646 -- iter: 313/313
--
Training Step: 91  | total loss: [1m[32m0.09291[0m[0m | time: 12.927s
[2K
| Adam | epoch: 010 | loss: 0.09291 - acc: 0.9787 -- iter: 032/313
[A[ATraining Step: 92  | total loss: [1m[32m0.08422[0m[0m | time: 25.501s
[2K
| Adam | epoch: 010 | loss: 0.08422 - acc: 0.9808 -- iter: 064/313
[A[ATraining Step: 93  | total loss: [1m[32m0.07704[0m[0m | time: 37.738s
[2K
| Adam | epoch: 010 | loss: 0.07704 - acc: 0.9827 -- iter: 096/313
[A[ATraining Step: 94  | total loss: [1m[32m0.07453[0m[0m | time: 48.479s
[2K
| Adam | epoch: 010 | loss: 0.07453 - acc: 0.9813 -- iter: 128/313
[A[ATraining Step: 95  | total loss: [1m[32m0.06811[0m[0m | time: 56.349s
[2K
| Adam | epoch: 010 | loss: 0.06811 - acc: 0.9832 -- iter: 160/313
[A[ATraining Step: 96  | total loss: [1m[32m0.09031[0m[0m | time: 64.459s
[2K
| Adam | epoch: 010 | loss: 0.09031 - acc: 0.9786 -- iter: 192/313
[A[ATraining Step: 97  | total loss: [1m[32m0.11061[0m[0m | time: 72.351s
[2K
| Adam | epoch: 010 | loss: 0.11061 - acc: 0.9777 -- iter: 224/313
[A[ATraining Step: 98  | total loss: [1m[32m0.11575[0m[0m | time: 79.556s
[2K
| Adam | epoch: 010 | loss: 0.11575 - acc: 0.9705 -- iter: 256/313
[A[ATraining Step: 99  | total loss: [1m[32m0.10575[0m[0m | time: 89.803s
[2K
| Adam | epoch: 010 | loss: 0.10575 - acc: 0.9735 -- iter: 288/313
[A[ATraining Step: 100  | total loss: [1m[32m0.10927[0m[0m | time: 109.528s
[2K
| Adam | epoch: 010 | loss: 0.10927 - acc: 0.9721 | val_loss: 0.26747 - val_acc: 0.8889 -- iter: 313/313
--
Training Step: 101  | total loss: [1m[32m0.10102[0m[0m | time: 12.300s
[2K
| Adam | epoch: 011 | loss: 0.10102 - acc: 0.9749 -- iter: 032/313
[A[ATraining Step: 102  | total loss: [1m[32m0.11323[0m[0m | time: 24.129s
[2K
| Adam | epoch: 011 | loss: 0.11323 - acc: 0.9649 -- iter: 064/313
[A[ATraining Step: 103  | total loss: [1m[32m0.11989[0m[0m | time: 36.738s
[2K
| Adam | epoch: 011 | loss: 0.11989 - acc: 0.9622 -- iter: 096/313
[A[ATraining Step: 104  | total loss: [1m[32m0.12059[0m[0m | time: 49.791s
[2K
| Adam | epoch: 011 | loss: 0.12059 - acc: 0.9628 -- iter: 128/313
[A[ATraining Step: 105  | total loss: [1m[32m0.11226[0m[0m | time: 58.381s
[2K
| Adam | epoch: 011 | loss: 0.11226 - acc: 0.9665 -- iter: 160/313
[A[ATraining Step: 106  | total loss: [1m[32m0.10797[0m[0m | time: 66.330s
[2K
| Adam | epoch: 011 | loss: 0.10797 - acc: 0.9668 -- iter: 192/313
[A[ATraining Step: 107  | total loss: [1m[32m0.10198[0m[0m | time: 75.619s
[2K
| Adam | epoch: 011 | loss: 0.10198 - acc: 0.9701 -- iter: 224/313
[A[ATraining Step: 108  | total loss: [1m[32m0.10775[0m[0m | time: 87.508s
[2K
| Adam | epoch: 011 | loss: 0.10775 - acc: 0.9668 -- iter: 256/313
[A[ATraining Step: 109  | total loss: [1m[32m0.11006[0m[0m | time: 97.823s
[2K
| Adam | epoch: 011 | loss: 0.11006 - acc: 0.9670 -- iter: 288/313
[A[ATraining Step: 110  | total loss: [1m[32m0.10069[0m[0m | time: 115.011s
[2K
| Adam | epoch: 011 | loss: 0.10069 - acc: 0.9703 | val_loss: 2.01821 - val_acc: 0.5354 -- iter: 313/313
--
Training Step: 111  | total loss: [1m[32m0.11844[0m[0m | time: 12.489s
[2K
| Adam | epoch: 012 | loss: 0.11844 - acc: 0.9693 -- iter: 032/313
[A[ATraining Step: 112  | total loss: [1m[32m0.10903[0m[0m | time: 25.172s
[2K
| Adam | epoch: 012 | loss: 0.10903 - acc: 0.9724 -- iter: 064/313
[A[ATraining Step: 113  | total loss: [1m[32m0.10525[0m[0m | time: 37.588s
[2K
| Adam | epoch: 012 | loss: 0.10525 - acc: 0.9751 -- iter: 096/313
[A[ATraining Step: 114  | total loss: [1m[32m0.09795[0m[0m | time: 47.440s
[2K
| Adam | epoch: 012 | loss: 0.09795 - acc: 0.9776 -- iter: 128/313
[A[ATraining Step: 115  | total loss: [1m[32m0.10827[0m[0m | time: 55.225s
[2K
| Adam | epoch: 012 | loss: 0.10827 - acc: 0.9674 -- iter: 160/313
[A[ATraining Step: 116  | total loss: [1m[32m0.11151[0m[0m | time: 63.278s
[2K
| Adam | epoch: 012 | loss: 0.11151 - acc: 0.9675 -- iter: 192/313
[A[ATraining Step: 117  | total loss: [1m[32m0.10121[0m[0m | time: 71.215s
[2K
| Adam | epoch: 012 | loss: 0.10121 - acc: 0.9707 -- iter: 224/313
[A[ATraining Step: 118  | total loss: [1m[32m0.09206[0m[0m | time: 81.570s
[2K
| Adam | epoch: 012 | loss: 0.09206 - acc: 0.9737 -- iter: 256/313
[A[ATraining Step: 119  | total loss: [1m[32m0.09962[0m[0m | time: 93.593s
[2K
| Adam | epoch: 012 | loss: 0.09962 - acc: 0.9701 -- iter: 288/313
[A[ATraining Step: 120  | total loss: [1m[32m0.11061[0m[0m | time: 111.296s
[2K
| Adam | epoch: 012 | loss: 0.11061 - acc: 0.9668 | val_loss: 0.53346 - val_acc: 0.8586 -- iter: 313/313
--
Training Step: 121  | total loss: [1m[32m0.10088[0m[0m | time: 10.685s
[2K
| Adam | epoch: 013 | loss: 0.10088 - acc: 0.9701 -- iter: 032/313
[A[ATraining Step: 122  | total loss: [1m[32m0.09118[0m[0m | time: 22.823s
[2K
| Adam | epoch: 013 | loss: 0.09118 - acc: 0.9731 -- iter: 064/313
[A[ATraining Step: 123  | total loss: [1m[32m0.08265[0m[0m | time: 34.934s
[2K
| Adam | epoch: 013 | loss: 0.08265 - acc: 0.9758 -- iter: 096/313
[A[ATraining Step: 124  | total loss: [1m[32m0.08227[0m[0m | time: 47.364s
[2K
| Adam | epoch: 013 | loss: 0.08227 - acc: 0.9751 -- iter: 128/313
[A[ATraining Step: 125  | total loss: [1m[32m0.07633[0m[0m | time: 55.201s
[2K
| Adam | epoch: 013 | loss: 0.07633 - acc: 0.9776 -- iter: 160/313
[A[ATraining Step: 126  | total loss: [1m[32m0.07760[0m[0m | time: 63.185s
[2K
| Adam | epoch: 013 | loss: 0.07760 - acc: 0.9767 -- iter: 192/313
[A[ATraining Step: 127  | total loss: [1m[32m0.07324[0m[0m | time: 72.609s
[2K
| Adam | epoch: 013 | loss: 0.07324 - acc: 0.9759 -- iter: 224/313
[A[ATraining Step: 128  | total loss: [1m[32m0.06738[0m[0m | time: 84.910s
[2K
| Adam | epoch: 013 | loss: 0.06738 - acc: 0.9783 -- iter: 256/313
[A[ATraining Step: 129  | total loss: [1m[32m0.06139[0m[0m | time: 97.139s
[2K
| Adam | epoch: 013 | loss: 0.06139 - acc: 0.9805 -- iter: 288/313
[A[ATraining Step: 130  | total loss: [1m[32m0.05596[0m[0m | time: 116.427s
[2K
| Adam | epoch: 013 | loss: 0.05596 - acc: 0.9824 | val_loss: 0.98991 - val_acc: 0.7980 -- iter: 313/313
--
Training Step: 131  | total loss: [1m[32m0.05251[0m[0m | time: 10.236s
[2K
| Adam | epoch: 014 | loss: 0.05251 - acc: 0.9842 -- iter: 032/313
[A[ATraining Step: 132  | total loss: [1m[32m0.05341[0m[0m | time: 20.840s
[2K
| Adam | epoch: 014 | loss: 0.05341 - acc: 0.9818 -- iter: 064/313
[A[ATraining Step: 133  | total loss: [1m[32m0.11632[0m[0m | time: 33.431s
[2K
| Adam | epoch: 014 | loss: 0.11632 - acc: 0.9756 -- iter: 096/313
[A[ATraining Step: 134  | total loss: [1m[32m0.10592[0m[0m | time: 41.924s
[2K
| Adam | epoch: 014 | loss: 0.10592 - acc: 0.9780 -- iter: 128/313
[A[ATraining Step: 135  | total loss: [1m[32m0.09815[0m[0m | time: 49.887s
[2K
| Adam | epoch: 014 | loss: 0.09815 - acc: 0.9802 -- iter: 160/313
[A[ATraining Step: 136  | total loss: [1m[32m0.08982[0m[0m | time: 57.782s
[2K
| Adam | epoch: 014 | loss: 0.08982 - acc: 0.9822 -- iter: 192/313
[A[ATraining Step: 137  | total loss: [1m[32m0.08511[0m[0m | time: 65.701s
[2K
| Adam | epoch: 014 | loss: 0.08511 - acc: 0.9809 -- iter: 224/313
[A[ATraining Step: 138  | total loss: [1m[32m0.07771[0m[0m | time: 79.219s
[2K
| Adam | epoch: 014 | loss: 0.07771 - acc: 0.9828 -- iter: 256/313
[A[ATraining Step: 139  | total loss: [1m[32m0.07115[0m[0m | time: 87.029s
[2K
| Adam | epoch: 014 | loss: 0.07115 - acc: 0.9845 -- iter: 288/313
[A[ATraining Step: 140  | total loss: [1m[32m0.06517[0m[0m | time: 99.376s
[2K
| Adam | epoch: 014 | loss: 0.06517 - acc: 0.9860 | val_loss: 0.17485 - val_acc: 0.8889 -- iter: 313/313
--
Training Step: 141  | total loss: [1m[32m0.06070[0m[0m | time: 7.930s
[2K
| Adam | epoch: 015 | loss: 0.06070 - acc: 0.9874 -- iter: 032/313
[A[ATraining Step: 142  | total loss: [1m[32m0.05652[0m[0m | time: 14.531s
[2K
| Adam | epoch: 015 | loss: 0.05652 - acc: 0.9887 -- iter: 064/313
[A[ATraining Step: 143  | total loss: [1m[32m0.05200[0m[0m | time: 20.921s
[2K
| Adam | epoch: 015 | loss: 0.05200 - acc: 0.9898 -- iter: 096/313
[A[ATraining Step: 144  | total loss: [1m[32m0.06582[0m[0m | time: 28.901s
[2K
| Adam | epoch: 015 | loss: 0.06582 - acc: 0.9868 -- iter: 128/313
[A[ATraining Step: 145  | total loss: [1m[32m0.06119[0m[0m | time: 36.870s
[2K
| Adam | epoch: 015 | loss: 0.06119 - acc: 0.9882 -- iter: 160/313
[A[ATraining Step: 146  | total loss: [1m[32m0.05625[0m[0m | time: 44.708s
[2K
| Adam | epoch: 015 | loss: 0.05625 - acc: 0.9893 -- iter: 192/313
[A[ATraining Step: 147  | total loss: [1m[32m0.05311[0m[0m | time: 52.683s
[2K
| Adam | epoch: 015 | loss: 0.05311 - acc: 0.9904 -- iter: 224/313
[A[ATraining Step: 148  | total loss: [1m[32m0.05308[0m[0m | time: 60.613s
[2K
| Adam | epoch: 015 | loss: 0.05308 - acc: 0.9882 -- iter: 256/313
[A[ATraining Step: 149  | total loss: [1m[32m0.05174[0m[0m | time: 68.519s
[2K
| Adam | epoch: 015 | loss: 0.05174 - acc: 0.9863 -- iter: 288/313
[A[ATraining Step: 150  | total loss: [1m[32m0.04711[0m[0m | time: 80.845s
[2K
| Adam | epoch: 015 | loss: 0.04711 - acc: 0.9877 | val_loss: 0.26756 - val_acc: 0.8788 -- iter: 313/313
--
Validation AUC:0.9840032813781789
Validation AUPRC:0.9836741354502023
Test AUC:0.9627118644067797
Test AUPRC:0.9533457147353378
BestTestF1Score	0.89	0.84	0.92	0.97	0.82	33	1	58	7	0.98
BestTestMCCScore	0.89	0.84	0.92	0.97	0.82	33	1	58	7	0.98
BestTestAccuracyScore	0.89	0.84	0.92	0.97	0.82	33	1	58	7	0.98
BestValidationF1Score	0.93	0.88	0.94	1.0	0.87	40	0	53	6	0.98
BestValidationMCC	0.93	0.88	0.94	1.0	0.87	40	0	53	6	0.98
BestValidationAccuracy	0.93	0.88	0.94	1.0	0.87	40	0	53	6	0.98
TestPredictions (Threshold:0.98)
CHEMBL2058372,TP,ACT,0.9900000095367432	CHEMBL77962,TN,INACT,0.0	CHEMBL2369493,TN,INACT,0.25999999046325684	CHEMBL267094,TN,INACT,0.5199999809265137	CHEMBL357077,TN,INACT,0.0	CHEMBL369359,TN,INACT,0.0	CHEMBL52791,TP,ACT,1.0	CHEMBL245319,TN,INACT,0.05999999865889549	CHEMBL80807,TN,INACT,0.0	CHEMBL424214,TN,INACT,0.09000000357627869	CHEMBL241514,TN,INACT,0.0	CHEMBL296927,TN,INACT,0.0	CHEMBL39879,TN,INACT,0.009999999776482582	CHEMBL3780633,TN,INACT,0.14000000059604645	CHEMBL602269,TN,INACT,0.009999999776482582	CHEMBL78853,TN,INACT,0.0	CHEMBL412717,TP,ACT,1.0	CHEMBL241684,TP,ACT,1.0	CHEMBL2042401,TN,INACT,0.0	CHEMBL287374,TN,INACT,0.800000011920929	CHEMBL40796,TN,INACT,0.0	CHEMBL308924,TN,INACT,0.0	CHEMBL27065,TN,INACT,0.44999998807907104	CHEMBL24550,TP,ACT,1.0	CHEMBL419762,TP,ACT,1.0	CHEMBL309397,TN,INACT,0.0	CHEMBL40317,TN,INACT,0.0	CHEMBL53631,FN,ACT,0.0	CHEMBL2398752,TN,INACT,0.03999999910593033	CHEMBL421523,TN,INACT,0.0	CHEMBL45456,TN,INACT,0.0	CHEMBL414570,TN,INACT,0.9700000286102295	CHEMBL300186,TP,ACT,1.0	CHEMBL384349,FN,ACT,0.029999999329447746	CHEMBL3309718,TN,INACT,0.0	CHEMBL112414,TP,ACT,1.0	CHEMBL116094,TP,ACT,1.0	CHEMBL320763,TN,INACT,0.07999999821186066	CHEMBL123099,TN,INACT,0.07000000029802322	CHEMBL442251,FN,ACT,0.949999988079071	CHEMBL2058376,FN,ACT,0.20000000298023224	CHEMBL322537,TN,INACT,0.03999999910593033	CHEMBL320124,TN,INACT,0.07999999821186066	CHEMBL170335,TN,INACT,0.0	CHEMBL274447,TP,ACT,0.9900000095367432	CHEMBL112777,TN,INACT,0.1899999976158142	CHEMBL322547,TN,INACT,0.07999999821186066	CHEMBL7632,TP,ACT,1.0	CHEMBL320254,TN,INACT,0.009999999776482582	CHEMBL340612,TP,ACT,1.0	CHEMBL49170,TP,ACT,0.9900000095367432	CHEMBL45160,TN,INACT,0.0	CHEMBL174463,TN,INACT,0.0	CHEMBL325935,TN,INACT,0.019999999552965164	CHEMBL69144,TP,ACT,1.0	CHEMBL552615,TN,INACT,0.0	CHEMBL55366,TP,ACT,0.9900000095367432	CHEMBL298203,TN,INACT,0.019999999552965164	CHEMBL45875,TN,INACT,0.0	CHEMBL275304,TP,ACT,1.0	CHEMBL191915,TN,INACT,0.0	CHEMBL283535,TN,INACT,0.0	CHEMBL99331,TN,INACT,0.0	CHEMBL300105,TP,ACT,1.0	CHEMBL114074,TN,INACT,0.009999999776482582	CHEMBL48031,TN,INACT,0.0	CHEMBL299151,FN,ACT,0.9599999785423279	CHEMBL294075,FN,ACT,0.9700000286102295	CHEMBL302127,TP,ACT,1.0	CHEMBL461088,TN,INACT,0.009999999776482582	CHEMBL133257,TN,INACT,0.05999999865889549	CHEMBL293001,TP,ACT,1.0	CHEMBL264230,FN,ACT,0.6499999761581421	CHEMBL451335,TN,INACT,0.0	CHEMBL293874,TN,INACT,0.10000000149011612	CHEMBL128590,TP,ACT,0.9900000095367432	CHEMBL9666,TN,INACT,0.0	CHEMBL57783,TP,ACT,1.0	CHEMBL15689,FP,INACT,1.0	CHEMBL446314,TP,ACT,1.0	CHEMBL10801,TN,INACT,0.7300000190734863	CHEMBL298741,TP,ACT,1.0	CHEMBL284546,TP,ACT,1.0	CHEMBL50592,TP,ACT,0.9800000190734863	CHEMBL293308,TP,ACT,1.0	CHEMBL175228,TN,INACT,0.7099999785423279	CHEMBL300861,TP,ACT,1.0	CHEMBL2058373,TP,ACT,1.0	CHEMBL324586,TN,INACT,0.14000000059604645	CHEMBL116054,TP,ACT,1.0	CHEMBL104172,TN,INACT,0.5699999928474426	CHEMBL1983100,TN,INACT,0.0	CHEMBL54194,TP,ACT,1.0	CHEMBL305190,TP,ACT,1.0	CHEMBL79030,TN,INACT,0.0	CHEMBL352779,TN,INACT,0.009999999776482582	CHEMBL118553,TN,INACT,0.009999999776482582	CHEMBL68516,TP,ACT,0.9900000095367432	CHEMBL69154,TP,ACT,1.0	

