ImageNetInceptionV2 CHEMBL284 RMSprop 0.0005 15 0 0 0.8 False True
Number of active compounds :	861
Number of inactive compounds :	574
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL284_RMSprop_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL284_RMSprop_0.0005_15_0.8/
---------------------------------
Training samples: 900
Validation samples: 282
--
Training Step: 1  | time: 46.224s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/900
[A[ATraining Step: 2  | total loss: [1m[32m0.59903[0m[0m | time: 61.864s
[2K
| RMSProp | epoch: 001 | loss: 0.59903 - acc: 0.5344 -- iter: 064/900
[A[ATraining Step: 3  | total loss: [1m[32m0.69430[0m[0m | time: 72.425s
[2K
| RMSProp | epoch: 001 | loss: 0.69430 - acc: 0.5063 -- iter: 096/900
[A[ATraining Step: 4  | total loss: [1m[32m0.70606[0m[0m | time: 83.984s
[2K
| RMSProp | epoch: 001 | loss: 0.70606 - acc: 0.5719 -- iter: 128/900
[A[ATraining Step: 5  | total loss: [1m[32m0.65024[0m[0m | time: 96.605s
[2K
| RMSProp | epoch: 001 | loss: 0.65024 - acc: 0.6519 -- iter: 160/900
[A[ATraining Step: 6  | total loss: [1m[32m0.67863[0m[0m | time: 106.041s
[2K
| RMSProp | epoch: 001 | loss: 0.67863 - acc: 0.6145 -- iter: 192/900
[A[ATraining Step: 7  | total loss: [1m[32m0.70170[0m[0m | time: 117.201s
[2K
| RMSProp | epoch: 001 | loss: 0.70170 - acc: 0.5833 -- iter: 224/900
[A[ATraining Step: 8  | total loss: [1m[32m0.71325[0m[0m | time: 126.101s
[2K
| RMSProp | epoch: 001 | loss: 0.71325 - acc: 0.5540 -- iter: 256/900
[A[ATraining Step: 9  | total loss: [1m[32m0.70216[0m[0m | time: 135.076s
[2K
| RMSProp | epoch: 001 | loss: 0.70216 - acc: 0.5585 -- iter: 288/900
[A[ATraining Step: 10  | total loss: [1m[32m0.73687[0m[0m | time: 144.172s
[2K
| RMSProp | epoch: 001 | loss: 0.73687 - acc: 0.4824 -- iter: 320/900
[A[ATraining Step: 11  | total loss: [1m[32m0.71712[0m[0m | time: 153.193s
[2K
| RMSProp | epoch: 001 | loss: 0.71712 - acc: 0.5055 -- iter: 352/900
[A[ATraining Step: 12  | total loss: [1m[32m0.71244[0m[0m | time: 162.107s
[2K
| RMSProp | epoch: 001 | loss: 0.71244 - acc: 0.5171 -- iter: 384/900
[A[ATraining Step: 13  | total loss: [1m[32m0.70285[0m[0m | time: 171.270s
[2K
| RMSProp | epoch: 001 | loss: 0.70285 - acc: 0.5366 -- iter: 416/900
[A[ATraining Step: 14  | total loss: [1m[32m0.71713[0m[0m | time: 180.331s
[2K
| RMSProp | epoch: 001 | loss: 0.71713 - acc: 0.4960 -- iter: 448/900
[A[ATraining Step: 15  | total loss: [1m[32m0.70474[0m[0m | time: 189.178s
[2K
| RMSProp | epoch: 001 | loss: 0.70474 - acc: 0.5220 -- iter: 480/900
[A[ATraining Step: 16  | total loss: [1m[32m0.69981[0m[0m | time: 197.908s
[2K
| RMSProp | epoch: 001 | loss: 0.69981 - acc: 0.5489 -- iter: 512/900
[A[ATraining Step: 17  | total loss: [1m[32m0.67516[0m[0m | time: 206.659s
[2K
| RMSProp | epoch: 001 | loss: 0.67516 - acc: 0.5651 -- iter: 544/900
[A[ATraining Step: 18  | total loss: [1m[32m0.69521[0m[0m | time: 215.697s
[2K
| RMSProp | epoch: 001 | loss: 0.69521 - acc: 0.5534 -- iter: 576/900
[A[ATraining Step: 19  | total loss: [1m[32m0.70530[0m[0m | time: 225.353s
[2K
| RMSProp | epoch: 001 | loss: 0.70530 - acc: 0.5252 -- iter: 608/900
[A[ATraining Step: 20  | total loss: [1m[32m0.70093[0m[0m | time: 234.065s
[2K
| RMSProp | epoch: 001 | loss: 0.70093 - acc: 0.5472 -- iter: 640/900
[A[ATraining Step: 21  | total loss: [1m[32m0.71676[0m[0m | time: 243.010s
[2K
| RMSProp | epoch: 001 | loss: 0.71676 - acc: 0.5035 -- iter: 672/900
[A[ATraining Step: 22  | total loss: [1m[32m0.71628[0m[0m | time: 251.841s
[2K
| RMSProp | epoch: 001 | loss: 0.71628 - acc: 0.5118 -- iter: 704/900
[A[ATraining Step: 23  | total loss: [1m[32m0.70981[0m[0m | time: 260.608s
[2K
| RMSProp | epoch: 001 | loss: 0.70981 - acc: 0.5174 -- iter: 736/900
[A[ATraining Step: 24  | total loss: [1m[32m0.70539[0m[0m | time: 270.023s
[2K
| RMSProp | epoch: 001 | loss: 0.70539 - acc: 0.5125 -- iter: 768/900
[A[ATraining Step: 25  | total loss: [1m[32m0.70616[0m[0m | time: 279.324s
[2K
| RMSProp | epoch: 001 | loss: 0.70616 - acc: 0.5006 -- iter: 800/900
[A[ATraining Step: 26  | total loss: [1m[32m0.69461[0m[0m | time: 288.136s
[2K
| RMSProp | epoch: 001 | loss: 0.69461 - acc: 0.5170 -- iter: 832/900
[A[ATraining Step: 27  | total loss: [1m[32m0.69945[0m[0m | time: 297.172s
[2K
| RMSProp | epoch: 001 | loss: 0.69945 - acc: 0.5287 -- iter: 864/900
[A[ATraining Step: 28  | total loss: [1m[32m0.69205[0m[0m | time: 306.110s
[2K
| RMSProp | epoch: 001 | loss: 0.69205 - acc: 0.5528 -- iter: 896/900
[A[ATraining Step: 29  | total loss: [1m[32m0.68985[0m[0m | time: 326.356s
[2K
| RMSProp | epoch: 001 | loss: 0.68985 - acc: 0.5475 | val_loss: 0.67645 - val_acc: 0.6099 -- iter: 900/900
--
Training Step: 30  | total loss: [1m[32m0.68763[0m[0m | time: 1.802s
[2K
| RMSProp | epoch: 002 | loss: 0.68763 - acc: 0.5363 -- iter: 032/900
[A[ATraining Step: 31  | total loss: [1m[32m0.66492[0m[0m | time: 10.724s
[2K
| RMSProp | epoch: 002 | loss: 0.66492 - acc: 0.5856 -- iter: 064/900
[A[ATraining Step: 32  | total loss: [1m[32m0.67568[0m[0m | time: 19.813s
[2K
| RMSProp | epoch: 002 | loss: 0.67568 - acc: 0.5452 -- iter: 096/900
[A[ATraining Step: 33  | total loss: [1m[32m0.67516[0m[0m | time: 28.983s
[2K
| RMSProp | epoch: 002 | loss: 0.67516 - acc: 0.5353 -- iter: 128/900
[A[ATraining Step: 34  | total loss: [1m[32m0.67001[0m[0m | time: 37.912s
[2K
| RMSProp | epoch: 002 | loss: 0.67001 - acc: 0.5612 -- iter: 160/900
[A[ATraining Step: 35  | total loss: [1m[32m0.67114[0m[0m | time: 46.797s
[2K
| RMSProp | epoch: 002 | loss: 0.67114 - acc: 0.5615 -- iter: 192/900
[A[ATraining Step: 36  | total loss: [1m[32m0.67130[0m[0m | time: 56.097s
[2K
| RMSProp | epoch: 002 | loss: 0.67130 - acc: 0.5681 -- iter: 224/900
[A[ATraining Step: 37  | total loss: [1m[32m0.68035[0m[0m | time: 65.077s
[2K
| RMSProp | epoch: 002 | loss: 0.68035 - acc: 0.5607 -- iter: 256/900
[A[ATraining Step: 38  | total loss: [1m[32m0.68854[0m[0m | time: 74.039s
[2K
| RMSProp | epoch: 002 | loss: 0.68854 - acc: 0.5488 -- iter: 288/900
[A[ATraining Step: 39  | total loss: [1m[32m0.67913[0m[0m | time: 83.521s
[2K
| RMSProp | epoch: 002 | loss: 0.67913 - acc: 0.5634 -- iter: 320/900
[A[ATraining Step: 40  | total loss: [1m[32m0.67890[0m[0m | time: 92.302s
[2K
| RMSProp | epoch: 002 | loss: 0.67890 - acc: 0.5515 -- iter: 352/900
[A[ATraining Step: 41  | total loss: [1m[32m0.68326[0m[0m | time: 102.023s
[2K
| RMSProp | epoch: 002 | loss: 0.68326 - acc: 0.5306 -- iter: 384/900
[A[ATraining Step: 42  | total loss: [1m[32m0.68722[0m[0m | time: 111.869s
[2K
| RMSProp | epoch: 002 | loss: 0.68722 - acc: 0.5082 -- iter: 416/900
[A[ATraining Step: 43  | total loss: [1m[32m0.68539[0m[0m | time: 120.481s
[2K
| RMSProp | epoch: 002 | loss: 0.68539 - acc: 0.5178 -- iter: 448/900
[A[ATraining Step: 44  | total loss: [1m[32m0.68189[0m[0m | time: 134.972s
[2K
| RMSProp | epoch: 002 | loss: 0.68189 - acc: 0.5309 -- iter: 480/900
[A[ATraining Step: 45  | total loss: [1m[32m0.68348[0m[0m | time: 263.772s
[2K
| RMSProp | epoch: 002 | loss: 0.68348 - acc: 0.5363 -- iter: 512/900
[A[ATraining Step: 46  | total loss: [1m[32m0.68134[0m[0m | time: 368.542s
[2K
| RMSProp | epoch: 002 | loss: 0.68134 - acc: 0.5459 -- iter: 544/900
[A[ATraining Step: 47  | total loss: [1m[32m0.69315[0m[0m | time: 456.579s
[2K
| RMSProp | epoch: 002 | loss: 0.69315 - acc: 0.5281 -- iter: 576/900
[A[ATraining Step: 48  | total loss: [1m[32m0.68927[0m[0m | time: 493.451s
[2K
| RMSProp | epoch: 002 | loss: 0.68927 - acc: 0.5487 -- iter: 608/900
[A[ATraining Step: 49  | total loss: [1m[32m0.70086[0m[0m | time: 529.318s
[2K
| RMSProp | epoch: 002 | loss: 0.70086 - acc: 0.5164 -- iter: 640/900
[A[ATraining Step: 50  | total loss: [1m[32m0.70028[0m[0m | time: 544.914s
[2K
| RMSProp | epoch: 002 | loss: 0.70028 - acc: 0.5235 -- iter: 672/900
[A[ATraining Step: 51  | total loss: [1m[32m0.69495[0m[0m | time: 565.917s
[2K
| RMSProp | epoch: 002 | loss: 0.69495 - acc: 0.5247 -- iter: 704/900
[A[ATraining Step: 52  | total loss: [1m[32m0.68295[0m[0m | time: 599.846s
[2K
| RMSProp | epoch: 002 | loss: 0.68295 - acc: 0.5491 -- iter: 736/900
[A[ATraining Step: 53  | total loss: [1m[32m0.67364[0m[0m | time: 630.547s
[2K
| RMSProp | epoch: 002 | loss: 0.67364 - acc: 0.5695 -- iter: 768/900
[A[ATraining Step: 54  | total loss: [1m[32m0.67333[0m[0m | time: 644.980s
[2K
| RMSProp | epoch: 002 | loss: 0.67333 - acc: 0.5821 -- iter: 800/900
[A[ATraining Step: 55  | total loss: [1m[32m0.69424[0m[0m | time: 667.933s
[2K
| RMSProp | epoch: 002 | loss: 0.69424 - acc: 0.5615 -- iter: 832/900
[A[ATraining Step: 56  | total loss: [1m[32m0.69328[0m[0m | time: 686.538s
[2K
| RMSProp | epoch: 002 | loss: 0.69328 - acc: 0.5748 -- iter: 864/900
[A[ATraining Step: 57  | total loss: [1m[32m0.68772[0m[0m | time: 708.979s
[2K
| RMSProp | epoch: 002 | loss: 0.68772 - acc: 0.5731 -- iter: 896/900
[A[ATraining Step: 58  | total loss: [1m[32m0.68098[0m[0m | time: 745.035s
[2K
| RMSProp | epoch: 002 | loss: 0.68098 - acc: 0.5802 | val_loss: 0.66694 - val_acc: 0.6064 -- iter: 900/900
--
Training Step: 59  | total loss: [1m[32m0.67002[0m[0m | time: 3.322s
[2K
| RMSProp | epoch: 003 | loss: 0.67002 - acc: 0.5946 -- iter: 032/900
[A[ATraining Step: 60  | total loss: [1m[32m0.69516[0m[0m | time: 6.577s
[2K
| RMSProp | epoch: 003 | loss: 0.69516 - acc: 0.5490 -- iter: 064/900
[A[ATraining Step: 61  | total loss: [1m[32m0.67596[0m[0m | time: 77.718s
[2K
| RMSProp | epoch: 003 | loss: 0.67596 - acc: 0.5752 -- iter: 096/900
[A[ATraining Step: 62  | total loss: [1m[32m0.67934[0m[0m | time: 144.228s
[2K
| RMSProp | epoch: 003 | loss: 0.67934 - acc: 0.5736 -- iter: 128/900
[A[ATraining Step: 63  | total loss: [1m[32m0.67554[0m[0m | time: 175.229s
[2K
| RMSProp | epoch: 003 | loss: 0.67554 - acc: 0.5801 -- iter: 160/900
[A[ATraining Step: 64  | total loss: [1m[32m0.68934[0m[0m | time: 191.440s
[2K
| RMSProp | epoch: 003 | loss: 0.68934 - acc: 0.5623 -- iter: 192/900
[A[ATraining Step: 65  | total loss: [1m[32m0.69237[0m[0m | time: 205.852s
[2K
| RMSProp | epoch: 003 | loss: 0.69237 - acc: 0.5469 -- iter: 224/900
[A[ATraining Step: 66  | total loss: [1m[32m0.69125[0m[0m | time: 222.131s
[2K
| RMSProp | epoch: 003 | loss: 0.69125 - acc: 0.5450 -- iter: 256/900
[A[ATraining Step: 67  | total loss: [1m[32m0.68669[0m[0m | time: 236.133s
[2K
| RMSProp | epoch: 003 | loss: 0.68669 - acc: 0.5583 -- iter: 288/900
[A[ATraining Step: 68  | total loss: [1m[32m0.68610[0m[0m | time: 255.455s
[2K
| RMSProp | epoch: 003 | loss: 0.68610 - acc: 0.5551 -- iter: 320/900
[A[ATraining Step: 69  | total loss: [1m[32m0.68067[0m[0m | time: 269.040s
[2K
| RMSProp | epoch: 003 | loss: 0.68067 - acc: 0.5669 -- iter: 352/900
[A[ATraining Step: 70  | total loss: [1m[32m0.67220[0m[0m | time: 283.278s
[2K
| RMSProp | epoch: 003 | loss: 0.67220 - acc: 0.5809 -- iter: 384/900
[A[ATraining Step: 71  | total loss: [1m[32m0.66575[0m[0m | time: 297.589s
[2K
| RMSProp | epoch: 003 | loss: 0.66575 - acc: 0.5859 -- iter: 416/900
[A[ATraining Step: 72  | total loss: [1m[32m0.66746[0m[0m | time: 311.275s
[2K
| RMSProp | epoch: 003 | loss: 0.66746 - acc: 0.5833 -- iter: 448/900
[A[ATraining Step: 73  | total loss: [1m[32m0.66650[0m[0m | time: 325.770s
[2K
| RMSProp | epoch: 003 | loss: 0.66650 - acc: 0.5809 -- iter: 480/900
[A[ATraining Step: 74  | total loss: [1m[32m0.67368[0m[0m | time: 339.903s
[2K
| RMSProp | epoch: 003 | loss: 0.67368 - acc: 0.5755 -- iter: 512/900
[A[ATraining Step: 75  | total loss: [1m[32m0.67417[0m[0m | time: 355.502s
[2K
| RMSProp | epoch: 003 | loss: 0.67417 - acc: 0.5843 -- iter: 544/900
[A[ATraining Step: 76  | total loss: [1m[32m0.66910[0m[0m | time: 371.956s
[2K
| RMSProp | epoch: 003 | loss: 0.66910 - acc: 0.5886 -- iter: 576/900
[A[ATraining Step: 77  | total loss: [1m[32m0.67236[0m[0m | time: 390.744s
[2K
| RMSProp | epoch: 003 | loss: 0.67236 - acc: 0.5792 -- iter: 608/900
[A[ATraining Step: 78  | total loss: [1m[32m0.67754[0m[0m | time: 404.679s
[2K
| RMSProp | epoch: 003 | loss: 0.67754 - acc: 0.5742 -- iter: 640/900
[A[ATraining Step: 79  | total loss: [1m[32m0.67513[0m[0m | time: 418.885s
[2K
| RMSProp | epoch: 003 | loss: 0.67513 - acc: 0.5762 -- iter: 672/900
[A[ATraining Step: 80  | total loss: [1m[32m0.67393[0m[0m | time: 435.963s
[2K
| RMSProp | epoch: 003 | loss: 0.67393 - acc: 0.5812 -- iter: 704/900
[A[ATraining Step: 81  | total loss: [1m[32m0.67427[0m[0m | time: 450.074s
[2K
| RMSProp | epoch: 003 | loss: 0.67427 - acc: 0.5856 -- iter: 736/900
[A[ATraining Step: 82  | total loss: [1m[32m0.67305[0m[0m | time: 459.619s
[2K
| RMSProp | epoch: 003 | loss: 0.67305 - acc: 0.5896 -- iter: 768/900
[A[ATraining Step: 83  | total loss: [1m[32m0.67082[0m[0m | time: 474.027s
[2K
| RMSProp | epoch: 003 | loss: 0.67082 - acc: 0.5994 -- iter: 800/900
[A[ATraining Step: 84  | total loss: [1m[32m0.67941[0m[0m | time: 489.044s
[2K
| RMSProp | epoch: 003 | loss: 0.67941 - acc: 0.5832 -- iter: 832/900
[A[ATraining Step: 85  | total loss: [1m[32m0.67096[0m[0m | time: 498.190s
[2K
| RMSProp | epoch: 003 | loss: 0.67096 - acc: 0.5842 -- iter: 864/900
[A[ATraining Step: 86  | total loss: [1m[32m0.65649[0m[0m | time: 507.536s
[2K
| RMSProp | epoch: 003 | loss: 0.65649 - acc: 0.6102 -- iter: 896/900
[A[ATraining Step: 87  | total loss: [1m[32m0.65854[0m[0m | time: 531.208s
[2K
| RMSProp | epoch: 003 | loss: 0.65854 - acc: 0.6117 | val_loss: 1.03949 - val_acc: 0.6064 -- iter: 900/900
--
Training Step: 88  | total loss: [1m[32m0.65610[0m[0m | time: 33.683s
[2K
| RMSProp | epoch: 004 | loss: 0.65610 - acc: 0.6161 -- iter: 032/900
[A[ATraining Step: 89  | total loss: [1m[32m0.65168[0m[0m | time: 36.467s
[2K
| RMSProp | epoch: 004 | loss: 0.65168 - acc: 0.6139 -- iter: 064/900
[A[ATraining Step: 90  | total loss: [1m[32m0.67210[0m[0m | time: 39.540s
[2K
| RMSProp | epoch: 004 | loss: 0.67210 - acc: 0.6025 -- iter: 096/900
[A[ATraining Step: 91  | total loss: [1m[32m0.64114[0m[0m | time: 80.332s
[2K
| RMSProp | epoch: 004 | loss: 0.64114 - acc: 0.6423 -- iter: 128/900
[A[ATraining Step: 92  | total loss: [1m[32m0.64037[0m[0m | time: 150.891s
[2K
| RMSProp | epoch: 004 | loss: 0.64037 - acc: 0.6343 -- iter: 160/900
[A[ATraining Step: 93  | total loss: [1m[32m0.64329[0m[0m | time: 187.855s
[2K
| RMSProp | epoch: 004 | loss: 0.64329 - acc: 0.6334 -- iter: 192/900
[A[ATraining Step: 94  | total loss: [1m[32m0.63560[0m[0m | time: 226.780s
[2K
| RMSProp | epoch: 004 | loss: 0.63560 - acc: 0.6481 -- iter: 224/900
[A[ATraining Step: 95  | total loss: [1m[32m0.64511[0m[0m | time: 241.006s
[2K
| RMSProp | epoch: 004 | loss: 0.64511 - acc: 0.6302 -- iter: 256/900
[A[ATraining Step: 96  | total loss: [1m[32m0.64441[0m[0m | time: 254.343s
[2K
| RMSProp | epoch: 004 | loss: 0.64441 - acc: 0.6266 -- iter: 288/900
[A[ATraining Step: 97  | total loss: [1m[32m0.62924[0m[0m | time: 268.009s
[2K
| RMSProp | epoch: 004 | loss: 0.62924 - acc: 0.6358 -- iter: 320/900
[A[ATraining Step: 98  | total loss: [1m[32m0.61882[0m[0m | time: 282.041s
[2K
| RMSProp | epoch: 004 | loss: 0.61882 - acc: 0.6441 -- iter: 352/900
[A[ATraining Step: 99  | total loss: [1m[32m0.62883[0m[0m | time: 295.910s
[2K
| RMSProp | epoch: 004 | loss: 0.62883 - acc: 0.6422 -- iter: 384/900
[A[ATraining Step: 100  | total loss: [1m[32m0.62958[0m[0m | time: 310.221s
[2K
| RMSProp | epoch: 004 | loss: 0.62958 - acc: 0.6436 -- iter: 416/900
[A[ATraining Step: 101  | total loss: [1m[32m0.64025[0m[0m | time: 323.633s
[2K
| RMSProp | epoch: 004 | loss: 0.64025 - acc: 0.6386 -- iter: 448/900
[A[ATraining Step: 102  | total loss: [1m[32m0.65053[0m[0m | time: 337.285s
[2K
| RMSProp | epoch: 004 | loss: 0.65053 - acc: 0.6279 -- iter: 480/900
[A[ATraining Step: 103  | total loss: [1m[32m0.64796[0m[0m | time: 351.067s
[2K
| RMSProp | epoch: 004 | loss: 0.64796 - acc: 0.6338 -- iter: 512/900
[A[ATraining Step: 104  | total loss: [1m[32m0.64580[0m[0m | time: 364.872s
[2K
| RMSProp | epoch: 004 | loss: 0.64580 - acc: 0.6454 -- iter: 544/900
[A[ATraining Step: 105  | total loss: [1m[32m0.64470[0m[0m | time: 378.615s
[2K
| RMSProp | epoch: 004 | loss: 0.64470 - acc: 0.6465 -- iter: 576/900
[A[ATraining Step: 106  | total loss: [1m[32m0.63886[0m[0m | time: 392.383s
[2K
| RMSProp | epoch: 004 | loss: 0.63886 - acc: 0.6569 -- iter: 608/900
[A[ATraining Step: 107  | total loss: [1m[32m0.63918[0m[0m | time: 405.865s
[2K
| RMSProp | epoch: 004 | loss: 0.63918 - acc: 0.6568 -- iter: 640/900
[A[ATraining Step: 108  | total loss: [1m[32m0.63559[0m[0m | time: 419.629s
[2K
| RMSProp | epoch: 004 | loss: 0.63559 - acc: 0.6661 -- iter: 672/900
[A[ATraining Step: 109  | total loss: [1m[32m0.63591[0m[0m | time: 433.216s
[2K
| RMSProp | epoch: 004 | loss: 0.63591 - acc: 0.6683 -- iter: 704/900
[A[ATraining Step: 110  | total loss: [1m[32m0.62851[0m[0m | time: 447.135s
[2K
| RMSProp | epoch: 004 | loss: 0.62851 - acc: 0.6796 -- iter: 736/900
[A[ATraining Step: 111  | total loss: [1m[32m0.62453[0m[0m | time: 462.344s
[2K
| RMSProp | epoch: 004 | loss: 0.62453 - acc: 0.6804 -- iter: 768/900
[A[ATraining Step: 112  | total loss: [1m[32m0.62775[0m[0m | time: 475.536s
[2K
| RMSProp | epoch: 004 | loss: 0.62775 - acc: 0.6748 -- iter: 800/900
[A[ATraining Step: 113  | total loss: [1m[32m0.61902[0m[0m | time: 489.644s
[2K
| RMSProp | epoch: 004 | loss: 0.61902 - acc: 0.6823 -- iter: 832/900
[A[ATraining Step: 114  | total loss: [1m[32m0.63231[0m[0m | time: 503.389s
[2K
| RMSProp | epoch: 004 | loss: 0.63231 - acc: 0.6766 -- iter: 864/900
[A[ATraining Step: 115  | total loss: [1m[32m0.63232[0m[0m | time: 516.725s
[2K
| RMSProp | epoch: 004 | loss: 0.63232 - acc: 0.6777 -- iter: 896/900
[A[ATraining Step: 116  | total loss: [1m[32m0.62059[0m[0m | time: 551.991s
[2K
| RMSProp | epoch: 004 | loss: 0.62059 - acc: 0.6880 | val_loss: 2.95856 - val_acc: 0.3936 -- iter: 900/900
--
Training Step: 117  | total loss: [1m[32m0.61039[0m[0m | time: 13.710s
[2K
| RMSProp | epoch: 005 | loss: 0.61039 - acc: 0.6942 -- iter: 032/900
[A[ATraining Step: 118  | total loss: [1m[32m0.60599[0m[0m | time: 26.970s
[2K
| RMSProp | epoch: 005 | loss: 0.60599 - acc: 0.6936 -- iter: 064/900
[A[ATraining Step: 119  | total loss: [1m[32m0.61406[0m[0m | time: 30.178s
[2K
| RMSProp | epoch: 005 | loss: 0.61406 - acc: 0.6930 -- iter: 096/900
[A[ATraining Step: 120  | total loss: [1m[32m0.59617[0m[0m | time: 33.206s
[2K
| RMSProp | epoch: 005 | loss: 0.59617 - acc: 0.6987 -- iter: 128/900
[A[ATraining Step: 121  | total loss: [1m[32m0.54083[0m[0m | time: 46.385s
[2K
| RMSProp | epoch: 005 | loss: 0.54083 - acc: 0.7288 -- iter: 160/900
[A[ATraining Step: 122  | total loss: [1m[32m0.55279[0m[0m | time: 59.591s
[2K
| RMSProp | epoch: 005 | loss: 0.55279 - acc: 0.7278 -- iter: 192/900
[A[ATraining Step: 123  | total loss: [1m[32m0.55199[0m[0m | time: 73.823s
[2K
| RMSProp | epoch: 005 | loss: 0.55199 - acc: 0.7238 -- iter: 224/900
[A[ATraining Step: 124  | total loss: [1m[32m0.57907[0m[0m | time: 88.383s
[2K
| RMSProp | epoch: 005 | loss: 0.57907 - acc: 0.7076 -- iter: 256/900
[A[ATraining Step: 125  | total loss: [1m[32m0.58979[0m[0m | time: 99.574s
[2K
| RMSProp | epoch: 005 | loss: 0.58979 - acc: 0.6994 -- iter: 288/900
[A[ATraining Step: 126  | total loss: [1m[32m0.59088[0m[0m | time: 108.430s
[2K
| RMSProp | epoch: 005 | loss: 0.59088 - acc: 0.6919 -- iter: 320/900
[A[ATraining Step: 127  | total loss: [1m[32m0.59702[0m[0m | time: 117.436s
[2K
| RMSProp | epoch: 005 | loss: 0.59702 - acc: 0.6852 -- iter: 352/900
[A[ATraining Step: 128  | total loss: [1m[32m0.57252[0m[0m | time: 126.396s
[2K
| RMSProp | epoch: 005 | loss: 0.57252 - acc: 0.7042 -- iter: 384/900
[A[ATraining Step: 129  | total loss: [1m[32m0.56014[0m[0m | time: 138.697s
[2K
| RMSProp | epoch: 005 | loss: 0.56014 - acc: 0.7119 -- iter: 416/900
[A[ATraining Step: 130  | total loss: [1m[32m0.56810[0m[0m | time: 152.325s
[2K
| RMSProp | epoch: 005 | loss: 0.56810 - acc: 0.7095 -- iter: 448/900
[A[ATraining Step: 131  | total loss: [1m[32m0.59580[0m[0m | time: 166.018s
[2K
| RMSProp | epoch: 005 | loss: 0.59580 - acc: 0.6854 -- iter: 480/900
[A[ATraining Step: 132  | total loss: [1m[32m0.58287[0m[0m | time: 179.378s
[2K
| RMSProp | epoch: 005 | loss: 0.58287 - acc: 0.6981 -- iter: 512/900
[A[ATraining Step: 133  | total loss: [1m[32m0.58073[0m[0m | time: 192.910s
[2K
| RMSProp | epoch: 005 | loss: 0.58073 - acc: 0.7033 -- iter: 544/900
[A[ATraining Step: 134  | total loss: [1m[32m0.56874[0m[0m | time: 206.572s
[2K
| RMSProp | epoch: 005 | loss: 0.56874 - acc: 0.7080 -- iter: 576/900
[A[ATraining Step: 135  | total loss: [1m[32m0.58319[0m[0m | time: 220.392s
[2K
| RMSProp | epoch: 005 | loss: 0.58319 - acc: 0.7091 -- iter: 608/900
[A[ATraining Step: 136  | total loss: [1m[32m0.60476[0m[0m | time: 234.002s
[2K
| RMSProp | epoch: 005 | loss: 0.60476 - acc: 0.6913 -- iter: 640/900
[A[ATraining Step: 137  | total loss: [1m[32m0.60844[0m[0m | time: 247.834s
[2K
| RMSProp | epoch: 005 | loss: 0.60844 - acc: 0.6784 -- iter: 672/900
[A[ATraining Step: 138  | total loss: [1m[32m0.59552[0m[0m | time: 261.204s
[2K
| RMSProp | epoch: 005 | loss: 0.59552 - acc: 0.6887 -- iter: 704/900
[A[ATraining Step: 139  | total loss: [1m[32m0.59706[0m[0m | time: 274.887s
[2K
| RMSProp | epoch: 005 | loss: 0.59706 - acc: 0.6854 -- iter: 736/900
[A[ATraining Step: 140  | total loss: [1m[32m0.60032[0m[0m | time: 288.443s
[2K
| RMSProp | epoch: 005 | loss: 0.60032 - acc: 0.6888 -- iter: 768/900
[A[ATraining Step: 141  | total loss: [1m[32m0.60477[0m[0m | time: 301.869s
[2K
| RMSProp | epoch: 005 | loss: 0.60477 - acc: 0.6793 -- iter: 800/900
[A[ATraining Step: 142  | total loss: [1m[32m0.60025[0m[0m | time: 315.764s
[2K
| RMSProp | epoch: 005 | loss: 0.60025 - acc: 0.6863 -- iter: 832/900
[A[ATraining Step: 143  | total loss: [1m[32m0.61722[0m[0m | time: 336.893s
[2K
| RMSProp | epoch: 005 | loss: 0.61722 - acc: 0.6708 -- iter: 864/900
[A[ATraining Step: 144  | total loss: [1m[32m0.60075[0m[0m | time: 360.004s
[2K
| RMSProp | epoch: 005 | loss: 0.60075 - acc: 0.6850 -- iter: 896/900
[A[ATraining Step: 145  | total loss: [1m[32m0.62318[0m[0m | time: 400.732s
[2K
| RMSProp | epoch: 005 | loss: 0.62318 - acc: 0.6821 | val_loss: 0.64009 - val_acc: 0.6064 -- iter: 900/900
--
Training Step: 146  | total loss: [1m[32m0.62711[0m[0m | time: 13.556s
[2K
| RMSProp | epoch: 006 | loss: 0.62711 - acc: 0.6795 -- iter: 032/900
[A[ATraining Step: 147  | total loss: [1m[32m0.61611[0m[0m | time: 27.277s
[2K
| RMSProp | epoch: 006 | loss: 0.61611 - acc: 0.6928 -- iter: 064/900
[A[ATraining Step: 148  | total loss: [1m[32m0.60179[0m[0m | time: 40.922s
[2K
| RMSProp | epoch: 006 | loss: 0.60179 - acc: 0.7048 -- iter: 096/900
[A[ATraining Step: 149  | total loss: [1m[32m0.58450[0m[0m | time: 43.846s
[2K
| RMSProp | epoch: 006 | loss: 0.58450 - acc: 0.7156 -- iter: 128/900
[A[ATraining Step: 150  | total loss: [1m[32m0.55024[0m[0m | time: 47.384s
[2K
| RMSProp | epoch: 006 | loss: 0.55024 - acc: 0.7440 -- iter: 160/900
[A[ATraining Step: 151  | total loss: [1m[32m0.50291[0m[0m | time: 60.776s
[2K
| RMSProp | epoch: 006 | loss: 0.50291 - acc: 0.7696 -- iter: 192/900
[A[ATraining Step: 152  | total loss: [1m[32m0.50032[0m[0m | time: 74.277s
[2K
| RMSProp | epoch: 006 | loss: 0.50032 - acc: 0.7676 -- iter: 224/900
[A[ATraining Step: 153  | total loss: [1m[32m0.49904[0m[0m | time: 87.801s
[2K
| RMSProp | epoch: 006 | loss: 0.49904 - acc: 0.7690 -- iter: 256/900
[A[ATraining Step: 154  | total loss: [1m[32m0.50352[0m[0m | time: 101.882s
[2K
| RMSProp | epoch: 006 | loss: 0.50352 - acc: 0.7702 -- iter: 288/900
[A[ATraining Step: 155  | total loss: [1m[32m0.49326[0m[0m | time: 115.418s
[2K
| RMSProp | epoch: 006 | loss: 0.49326 - acc: 0.7807 -- iter: 320/900
[A[ATraining Step: 156  | total loss: [1m[32m0.49075[0m[0m | time: 129.701s
[2K
| RMSProp | epoch: 006 | loss: 0.49075 - acc: 0.7776 -- iter: 352/900
[A[ATraining Step: 157  | total loss: [1m[32m0.52310[0m[0m | time: 142.937s
[2K
| RMSProp | epoch: 006 | loss: 0.52310 - acc: 0.7593 -- iter: 384/900
[A[ATraining Step: 158  | total loss: [1m[32m0.52654[0m[0m | time: 156.482s
[2K
| RMSProp | epoch: 006 | loss: 0.52654 - acc: 0.7583 -- iter: 416/900
[A[ATraining Step: 159  | total loss: [1m[32m0.51300[0m[0m | time: 170.784s
[2K
| RMSProp | epoch: 006 | loss: 0.51300 - acc: 0.7700 -- iter: 448/900
[A[ATraining Step: 160  | total loss: [1m[32m0.49651[0m[0m | time: 184.755s
[2K
| RMSProp | epoch: 006 | loss: 0.49651 - acc: 0.7774 -- iter: 480/900
[A[ATraining Step: 161  | total loss: [1m[32m0.51415[0m[0m | time: 198.457s
[2K
| RMSProp | epoch: 006 | loss: 0.51415 - acc: 0.7778 -- iter: 512/900
[A[ATraining Step: 162  | total loss: [1m[32m0.51222[0m[0m | time: 212.870s
[2K
| RMSProp | epoch: 006 | loss: 0.51222 - acc: 0.7812 -- iter: 544/900
[A[ATraining Step: 163  | total loss: [1m[32m0.53250[0m[0m | time: 253.810s
[2K
| RMSProp | epoch: 006 | loss: 0.53250 - acc: 0.7719 -- iter: 576/900
[A[ATraining Step: 164  | total loss: [1m[32m0.53645[0m[0m | time: 267.925s
[2K
| RMSProp | epoch: 006 | loss: 0.53645 - acc: 0.7634 -- iter: 608/900
[A[ATraining Step: 165  | total loss: [1m[32m0.53631[0m[0m | time: 282.331s
[2K
| RMSProp | epoch: 006 | loss: 0.53631 - acc: 0.7683 -- iter: 640/900
[A[ATraining Step: 166  | total loss: [1m[32m0.52435[0m[0m | time: 291.287s
[2K
| RMSProp | epoch: 006 | loss: 0.52435 - acc: 0.7727 -- iter: 672/900
[A[ATraining Step: 167  | total loss: [1m[32m0.52180[0m[0m | time: 300.220s
[2K
| RMSProp | epoch: 006 | loss: 0.52180 - acc: 0.7736 -- iter: 704/900
[A[ATraining Step: 168  | total loss: [1m[32m0.54514[0m[0m | time: 311.112s
[2K
| RMSProp | epoch: 006 | loss: 0.54514 - acc: 0.7619 -- iter: 736/900
[A[ATraining Step: 169  | total loss: [1m[32m0.55794[0m[0m | time: 324.595s
[2K
| RMSProp | epoch: 006 | loss: 0.55794 - acc: 0.7544 -- iter: 768/900
[A[ATraining Step: 170  | total loss: [1m[32m0.57005[0m[0m | time: 337.166s
[2K
| RMSProp | epoch: 006 | loss: 0.57005 - acc: 0.7352 -- iter: 800/900
[A[ATraining Step: 171  | total loss: [1m[32m0.56928[0m[0m | time: 350.490s
[2K
| RMSProp | epoch: 006 | loss: 0.56928 - acc: 0.7305 -- iter: 832/900
[A[ATraining Step: 172  | total loss: [1m[32m0.56717[0m[0m | time: 379.718s
[2K
| RMSProp | epoch: 006 | loss: 0.56717 - acc: 0.7324 -- iter: 864/900
[A[ATraining Step: 173  | total loss: [1m[32m0.55280[0m[0m | time: 401.854s
[2K
| RMSProp | epoch: 006 | loss: 0.55280 - acc: 0.7435 -- iter: 896/900
[A[ATraining Step: 174  | total loss: [1m[32m0.55109[0m[0m | time: 465.997s
[2K
| RMSProp | epoch: 006 | loss: 0.55109 - acc: 0.7442 | val_loss: 1.22010 - val_acc: 0.3972 -- iter: 900/900
--
Training Step: 175  | total loss: [1m[32m0.56077[0m[0m | time: 14.820s
[2K
| RMSProp | epoch: 007 | loss: 0.56077 - acc: 0.7354 -- iter: 032/900
[A[ATraining Step: 176  | total loss: [1m[32m0.55014[0m[0m | time: 28.357s
[2K
| RMSProp | epoch: 007 | loss: 0.55014 - acc: 0.7400 -- iter: 064/900
[A[ATraining Step: 177  | total loss: [1m[32m0.55269[0m[0m | time: 41.929s
[2K
| RMSProp | epoch: 007 | loss: 0.55269 - acc: 0.7472 -- iter: 096/900
[A[ATraining Step: 178  | total loss: [1m[32m0.53723[0m[0m | time: 55.434s
[2K
| RMSProp | epoch: 007 | loss: 0.53723 - acc: 0.7506 -- iter: 128/900
[A[ATraining Step: 179  | total loss: [1m[32m0.53997[0m[0m | time: 58.393s
[2K
| RMSProp | epoch: 007 | loss: 0.53997 - acc: 0.7381 -- iter: 160/900
[A[ATraining Step: 180  | total loss: [1m[32m0.55111[0m[0m | time: 61.395s
[2K
| RMSProp | epoch: 007 | loss: 0.55111 - acc: 0.7393 -- iter: 192/900
[A[ATraining Step: 181  | total loss: [1m[32m0.52450[0m[0m | time: 74.667s
[2K
| RMSProp | epoch: 007 | loss: 0.52450 - acc: 0.7403 -- iter: 224/900
[A[ATraining Step: 182  | total loss: [1m[32m0.52316[0m[0m | time: 88.787s
[2K
| RMSProp | epoch: 007 | loss: 0.52316 - acc: 0.7444 -- iter: 256/900
[A[ATraining Step: 183  | total loss: [1m[32m0.51542[0m[0m | time: 102.881s
[2K
| RMSProp | epoch: 007 | loss: 0.51542 - acc: 0.7512 -- iter: 288/900
[A[ATraining Step: 184  | total loss: [1m[32m0.50926[0m[0m | time: 116.111s
[2K
| RMSProp | epoch: 007 | loss: 0.50926 - acc: 0.7574 -- iter: 320/900
[A[ATraining Step: 185  | total loss: [1m[32m0.51242[0m[0m | time: 129.450s
[2K
| RMSProp | epoch: 007 | loss: 0.51242 - acc: 0.7598 -- iter: 352/900
[A[ATraining Step: 186  | total loss: [1m[32m0.50037[0m[0m | time: 142.947s
[2K
| RMSProp | epoch: 007 | loss: 0.50037 - acc: 0.7682 -- iter: 384/900
[A[ATraining Step: 187  | total loss: [1m[32m0.48061[0m[0m | time: 156.591s
[2K
| RMSProp | epoch: 007 | loss: 0.48061 - acc: 0.7757 -- iter: 416/900
[A[ATraining Step: 188  | total loss: [1m[32m0.49829[0m[0m | time: 169.898s
[2K
| RMSProp | epoch: 007 | loss: 0.49829 - acc: 0.7763 -- iter: 448/900
[A[ATraining Step: 189  | total loss: [1m[32m0.50113[0m[0m | time: 183.364s
[2K
| RMSProp | epoch: 007 | loss: 0.50113 - acc: 0.7768 -- iter: 480/900
[A[ATraining Step: 190  | total loss: [1m[32m0.48964[0m[0m | time: 197.001s
[2K
| RMSProp | epoch: 007 | loss: 0.48964 - acc: 0.7803 -- iter: 512/900
[A[ATraining Step: 191  | total loss: [1m[32m0.49716[0m[0m | time: 210.523s
[2K
| RMSProp | epoch: 007 | loss: 0.49716 - acc: 0.7773 -- iter: 544/900
[A[ATraining Step: 192  | total loss: [1m[32m0.49970[0m[0m | time: 223.939s
[2K
| RMSProp | epoch: 007 | loss: 0.49970 - acc: 0.7714 -- iter: 576/900
[A[ATraining Step: 193  | total loss: [1m[32m0.49322[0m[0m | time: 237.292s
[2K
| RMSProp | epoch: 007 | loss: 0.49322 - acc: 0.7756 -- iter: 608/900
[A[ATraining Step: 194  | total loss: [1m[32m0.49709[0m[0m | time: 251.039s
[2K
| RMSProp | epoch: 007 | loss: 0.49709 - acc: 0.7667 -- iter: 640/900
[A[ATraining Step: 195  | total loss: [1m[32m0.50651[0m[0m | time: 264.568s
[2K
| RMSProp | epoch: 007 | loss: 0.50651 - acc: 0.7619 -- iter: 672/900
[A[ATraining Step: 196  | total loss: [1m[32m0.49027[0m[0m | time: 278.161s
[2K
| RMSProp | epoch: 007 | loss: 0.49027 - acc: 0.7764 -- iter: 704/900
[A[ATraining Step: 197  | total loss: [1m[32m0.46527[0m[0m | time: 291.851s
[2K
| RMSProp | epoch: 007 | loss: 0.46527 - acc: 0.7925 -- iter: 736/900
[A[ATraining Step: 198  | total loss: [1m[32m0.45448[0m[0m | time: 305.069s
[2K
| RMSProp | epoch: 007 | loss: 0.45448 - acc: 0.8039 -- iter: 768/900
[A[ATraining Step: 199  | total loss: [1m[32m0.47050[0m[0m | time: 317.981s
[2K
| RMSProp | epoch: 007 | loss: 0.47050 - acc: 0.7954 -- iter: 800/900
[A[ATraining Step: 200  | total loss: [1m[32m0.48965[0m[0m | time: 369.242s
[2K
| RMSProp | epoch: 007 | loss: 0.48965 - acc: 0.7783 | val_loss: 3.16660 - val_acc: 0.3936 -- iter: 832/900
--
Training Step: 201  | total loss: [1m[32m0.49969[0m[0m | time: 382.714s
[2K
| RMSProp | epoch: 007 | loss: 0.49969 - acc: 0.7661 -- iter: 864/900
[A[ATraining Step: 202  | total loss: [1m[32m0.49460[0m[0m | time: 396.928s
[2K
| RMSProp | epoch: 007 | loss: 0.49460 - acc: 0.7708 -- iter: 896/900
[A[ATraining Step: 203  | total loss: [1m[32m0.49705[0m[0m | time: 421.024s
[2K
| RMSProp | epoch: 007 | loss: 0.49705 - acc: 0.7718 | val_loss: 0.86806 - val_acc: 0.4539 -- iter: 900/900
--
Training Step: 204  | total loss: [1m[32m0.49164[0m[0m | time: 12.888s
[2K
| RMSProp | epoch: 008 | loss: 0.49164 - acc: 0.7727 -- iter: 032/900
[A[ATraining Step: 205  | total loss: [1m[32m0.51486[0m[0m | time: 25.896s
[2K
| RMSProp | epoch: 008 | loss: 0.51486 - acc: 0.7580 -- iter: 064/900
[A[ATraining Step: 206  | total loss: [1m[32m0.52043[0m[0m | time: 38.658s
[2K
| RMSProp | epoch: 008 | loss: 0.52043 - acc: 0.7478 -- iter: 096/900
[A[ATraining Step: 207  | total loss: [1m[32m0.51826[0m[0m | time: 51.610s
[2K
| RMSProp | epoch: 008 | loss: 0.51826 - acc: 0.7449 -- iter: 128/900
[A[ATraining Step: 208  | total loss: [1m[32m0.49955[0m[0m | time: 64.194s
[2K
| RMSProp | epoch: 008 | loss: 0.49955 - acc: 0.7642 -- iter: 160/900
[A[ATraining Step: 209  | total loss: [1m[32m0.47468[0m[0m | time: 66.858s
[2K
| RMSProp | epoch: 008 | loss: 0.47468 - acc: 0.7815 -- iter: 192/900
[A[ATraining Step: 210  | total loss: [1m[32m0.44177[0m[0m | time: 69.731s
[2K
| RMSProp | epoch: 008 | loss: 0.44177 - acc: 0.8033 -- iter: 224/900
[A[ATraining Step: 211  | total loss: [1m[32m0.41977[0m[0m | time: 82.499s
[2K
| RMSProp | epoch: 008 | loss: 0.41977 - acc: 0.8230 -- iter: 256/900
[A[ATraining Step: 212  | total loss: [1m[32m0.42962[0m[0m | time: 95.634s
[2K
| RMSProp | epoch: 008 | loss: 0.42962 - acc: 0.8220 -- iter: 288/900
[A[ATraining Step: 213  | total loss: [1m[32m0.44274[0m[0m | time: 108.860s
[2K
| RMSProp | epoch: 008 | loss: 0.44274 - acc: 0.8148 -- iter: 320/900
[A[ATraining Step: 214  | total loss: [1m[32m0.46243[0m[0m | time: 122.299s
[2K
| RMSProp | epoch: 008 | loss: 0.46243 - acc: 0.8052 -- iter: 352/900
[A[ATraining Step: 215  | total loss: [1m[32m0.46780[0m[0m | time: 135.134s
[2K
| RMSProp | epoch: 008 | loss: 0.46780 - acc: 0.7996 -- iter: 384/900
[A[ATraining Step: 216  | total loss: [1m[32m0.48176[0m[0m | time: 159.659s
[2K
| RMSProp | epoch: 008 | loss: 0.48176 - acc: 0.7947 -- iter: 416/900
[A[ATraining Step: 217  | total loss: [1m[32m0.48631[0m[0m | time: 172.796s
[2K
| RMSProp | epoch: 008 | loss: 0.48631 - acc: 0.7902 -- iter: 448/900
[A[ATraining Step: 218  | total loss: [1m[32m0.45754[0m[0m | time: 185.280s
[2K
| RMSProp | epoch: 008 | loss: 0.45754 - acc: 0.8049 -- iter: 480/900
[A[ATraining Step: 219  | total loss: [1m[32m0.46133[0m[0m | time: 206.486s
[2K
| RMSProp | epoch: 008 | loss: 0.46133 - acc: 0.8088 -- iter: 512/900
[A[ATraining Step: 220  | total loss: [1m[32m0.47037[0m[0m | time: 219.087s
[2K
| RMSProp | epoch: 008 | loss: 0.47037 - acc: 0.8029 -- iter: 544/900
[A[ATraining Step: 221  | total loss: [1m[32m0.46924[0m[0m | time: 231.831s
[2K
| RMSProp | epoch: 008 | loss: 0.46924 - acc: 0.7914 -- iter: 576/900
[A[ATraining Step: 222  | total loss: [1m[32m0.47698[0m[0m | time: 244.860s
[2K
| RMSProp | epoch: 008 | loss: 0.47698 - acc: 0.7841 -- iter: 608/900
[A[ATraining Step: 223  | total loss: [1m[32m0.46927[0m[0m | time: 257.925s
[2K
| RMSProp | epoch: 008 | loss: 0.46927 - acc: 0.7870 -- iter: 640/900
[A[ATraining Step: 224  | total loss: [1m[32m0.46235[0m[0m | time: 270.770s
[2K
| RMSProp | epoch: 008 | loss: 0.46235 - acc: 0.7926 -- iter: 672/900
[A[ATraining Step: 225  | total loss: [1m[32m0.44720[0m[0m | time: 283.690s
[2K
| RMSProp | epoch: 008 | loss: 0.44720 - acc: 0.7978 -- iter: 704/900
[A[ATraining Step: 226  | total loss: [1m[32m0.45349[0m[0m | time: 296.526s
[2K
| RMSProp | epoch: 008 | loss: 0.45349 - acc: 0.7992 -- iter: 736/900
[A[ATraining Step: 227  | total loss: [1m[32m0.46044[0m[0m | time: 309.302s
[2K
| RMSProp | epoch: 008 | loss: 0.46044 - acc: 0.8037 -- iter: 768/900
[A[ATraining Step: 228  | total loss: [1m[32m0.46455[0m[0m | time: 322.057s
[2K
| RMSProp | epoch: 008 | loss: 0.46455 - acc: 0.7952 -- iter: 800/900
[A[ATraining Step: 229  | total loss: [1m[32m0.45533[0m[0m | time: 334.603s
[2K
| RMSProp | epoch: 008 | loss: 0.45533 - acc: 0.7938 -- iter: 832/900
[A[ATraining Step: 230  | total loss: [1m[32m0.45994[0m[0m | time: 347.134s
[2K
| RMSProp | epoch: 008 | loss: 0.45994 - acc: 0.7925 -- iter: 864/900
[A[ATraining Step: 231  | total loss: [1m[32m0.45308[0m[0m | time: 360.137s
[2K
| RMSProp | epoch: 008 | loss: 0.45308 - acc: 0.8008 -- iter: 896/900
[A[ATraining Step: 232  | total loss: [1m[32m0.43756[0m[0m | time: 393.985s
[2K
| RMSProp | epoch: 008 | loss: 0.43756 - acc: 0.8082 | val_loss: 0.87162 - val_acc: 0.4574 -- iter: 900/900
--
Training Step: 233  | total loss: [1m[32m0.43719[0m[0m | time: 12.830s
[2K
| RMSProp | epoch: 009 | loss: 0.43719 - acc: 0.8086 -- iter: 032/900
[A[ATraining Step: 234  | total loss: [1m[32m0.46606[0m[0m | time: 25.195s
[2K
| RMSProp | epoch: 009 | loss: 0.46606 - acc: 0.7934 -- iter: 064/900
[A[ATraining Step: 235  | total loss: [1m[32m0.47718[0m[0m | time: 37.851s
[2K
| RMSProp | epoch: 009 | loss: 0.47718 - acc: 0.7859 -- iter: 096/900
[A[ATraining Step: 236  | total loss: [1m[32m0.46642[0m[0m | time: 50.651s
[2K
| RMSProp | epoch: 009 | loss: 0.46642 - acc: 0.7886 -- iter: 128/900
[A[ATraining Step: 237  | total loss: [1m[32m0.45647[0m[0m | time: 64.271s
[2K
| RMSProp | epoch: 009 | loss: 0.45647 - acc: 0.7879 -- iter: 160/900
[A[ATraining Step: 238  | total loss: [1m[32m0.46470[0m[0m | time: 76.892s
[2K
| RMSProp | epoch: 009 | loss: 0.46470 - acc: 0.7934 -- iter: 192/900
[A[ATraining Step: 239  | total loss: [1m[32m0.49771[0m[0m | time: 78.657s
[2K
| RMSProp | epoch: 009 | loss: 0.49771 - acc: 0.7735 -- iter: 224/900
[A[ATraining Step: 240  | total loss: [1m[32m0.52049[0m[0m | time: 80.416s
[2K
| RMSProp | epoch: 009 | loss: 0.52049 - acc: 0.7711 -- iter: 256/900
[A[ATraining Step: 241  | total loss: [1m[32m0.47815[0m[0m | time: 88.734s
[2K
| RMSProp | epoch: 009 | loss: 0.47815 - acc: 0.7940 -- iter: 288/900
[A[ATraining Step: 242  | total loss: [1m[32m0.49148[0m[0m | time: 97.780s
[2K
| RMSProp | epoch: 009 | loss: 0.49148 - acc: 0.7865 -- iter: 320/900
[A[ATraining Step: 243  | total loss: [1m[32m0.48384[0m[0m | time: 110.714s
[2K
| RMSProp | epoch: 009 | loss: 0.48384 - acc: 0.7891 -- iter: 352/900
[A[ATraining Step: 244  | total loss: [1m[32m0.47644[0m[0m | time: 122.787s
[2K
| RMSProp | epoch: 009 | loss: 0.47644 - acc: 0.7977 -- iter: 384/900
[A[ATraining Step: 245  | total loss: [1m[32m0.45615[0m[0m | time: 135.452s
[2K
| RMSProp | epoch: 009 | loss: 0.45615 - acc: 0.8117 -- iter: 416/900
[A[ATraining Step: 246  | total loss: [1m[32m0.43004[0m[0m | time: 147.813s
[2K
| RMSProp | epoch: 009 | loss: 0.43004 - acc: 0.8242 -- iter: 448/900
[A[ATraining Step: 247  | total loss: [1m[32m0.39447[0m[0m | time: 160.533s
[2K
| RMSProp | epoch: 009 | loss: 0.39447 - acc: 0.8418 -- iter: 480/900
[A[ATraining Step: 248  | total loss: [1m[32m0.40872[0m[0m | time: 173.632s
[2K
| RMSProp | epoch: 009 | loss: 0.40872 - acc: 0.8358 -- iter: 512/900
[A[ATraining Step: 249  | total loss: [1m[32m0.45066[0m[0m | time: 186.409s
[2K
| RMSProp | epoch: 009 | loss: 0.45066 - acc: 0.8241 -- iter: 544/900
[A[ATraining Step: 250  | total loss: [1m[32m0.43934[0m[0m | time: 199.418s
[2K
| RMSProp | epoch: 009 | loss: 0.43934 - acc: 0.8167 -- iter: 576/900
[A[ATraining Step: 251  | total loss: [1m[32m0.42184[0m[0m | time: 212.259s
[2K
| RMSProp | epoch: 009 | loss: 0.42184 - acc: 0.8225 -- iter: 608/900
[A[ATraining Step: 252  | total loss: [1m[32m0.40248[0m[0m | time: 224.414s
[2K
| RMSProp | epoch: 009 | loss: 0.40248 - acc: 0.8309 -- iter: 640/900
[A[ATraining Step: 253  | total loss: [1m[32m0.41789[0m[0m | time: 237.631s
[2K
| RMSProp | epoch: 009 | loss: 0.41789 - acc: 0.8259 -- iter: 672/900
[A[ATraining Step: 254  | total loss: [1m[32m0.41093[0m[0m | time: 250.188s
[2K
| RMSProp | epoch: 009 | loss: 0.41093 - acc: 0.8308 -- iter: 704/900
[A[ATraining Step: 255  | total loss: [1m[32m0.39852[0m[0m | time: 262.527s
[2K
| RMSProp | epoch: 009 | loss: 0.39852 - acc: 0.8384 -- iter: 736/900
[A[ATraining Step: 256  | total loss: [1m[32m0.40499[0m[0m | time: 275.096s
[2K
| RMSProp | epoch: 009 | loss: 0.40499 - acc: 0.8420 -- iter: 768/900
[A[ATraining Step: 257  | total loss: [1m[32m0.40496[0m[0m | time: 287.310s
[2K
| RMSProp | epoch: 009 | loss: 0.40496 - acc: 0.8359 -- iter: 800/900
[A[ATraining Step: 258  | total loss: [1m[32m0.39318[0m[0m | time: 299.586s
[2K
| RMSProp | epoch: 009 | loss: 0.39318 - acc: 0.8367 -- iter: 832/900
[A[ATraining Step: 259  | total loss: [1m[32m0.38150[0m[0m | time: 311.884s
[2K
| RMSProp | epoch: 009 | loss: 0.38150 - acc: 0.8374 -- iter: 864/900
[A[ATraining Step: 260  | total loss: [1m[32m0.36629[0m[0m | time: 324.642s
[2K
| RMSProp | epoch: 009 | loss: 0.36629 - acc: 0.8412 -- iter: 896/900
[A[ATraining Step: 261  | total loss: [1m[32m0.36773[0m[0m | time: 357.594s
[2K
| RMSProp | epoch: 009 | loss: 0.36773 - acc: 0.8414 | val_loss: 3.70792 - val_acc: 0.6064 -- iter: 900/900
--
Training Step: 262  | total loss: [1m[32m0.34870[0m[0m | time: 12.421s
[2K
| RMSProp | epoch: 010 | loss: 0.34870 - acc: 0.8542 -- iter: 032/900
[A[ATraining Step: 263  | total loss: [1m[32m0.36239[0m[0m | time: 24.936s
[2K
| RMSProp | epoch: 010 | loss: 0.36239 - acc: 0.8469 -- iter: 064/900
[A[ATraining Step: 264  | total loss: [1m[32m0.34746[0m[0m | time: 37.404s
[2K
| RMSProp | epoch: 010 | loss: 0.34746 - acc: 0.8466 -- iter: 096/900
[A[ATraining Step: 265  | total loss: [1m[32m0.35016[0m[0m | time: 50.179s
[2K
| RMSProp | epoch: 010 | loss: 0.35016 - acc: 0.8463 -- iter: 128/900
[A[ATraining Step: 266  | total loss: [1m[32m0.33960[0m[0m | time: 63.186s
[2K
| RMSProp | epoch: 010 | loss: 0.33960 - acc: 0.8554 -- iter: 160/900
[A[ATraining Step: 267  | total loss: [1m[32m0.35088[0m[0m | time: 75.845s
[2K
| RMSProp | epoch: 010 | loss: 0.35088 - acc: 0.8480 -- iter: 192/900
[A[ATraining Step: 268  | total loss: [1m[32m0.34831[0m[0m | time: 88.475s
[2K
| RMSProp | epoch: 010 | loss: 0.34831 - acc: 0.8476 -- iter: 224/900
[A[ATraining Step: 269  | total loss: [1m[32m0.33749[0m[0m | time: 91.538s
[2K
| RMSProp | epoch: 010 | loss: 0.33749 - acc: 0.8472 -- iter: 256/900
[A[ATraining Step: 270  | total loss: [1m[32m0.43947[0m[0m | time: 93.987s
[2K
| RMSProp | epoch: 010 | loss: 0.43947 - acc: 0.8125 -- iter: 288/900
[A[ATraining Step: 271  | total loss: [1m[32m0.44024[0m[0m | time: 106.644s
[2K
| RMSProp | epoch: 010 | loss: 0.44024 - acc: 0.8062 -- iter: 320/900
[A[ATraining Step: 272  | total loss: [1m[32m0.49345[0m[0m | time: 119.429s
[2K
| RMSProp | epoch: 010 | loss: 0.49345 - acc: 0.7850 -- iter: 352/900
[A[ATraining Step: 273  | total loss: [1m[32m0.48893[0m[0m | time: 132.127s
[2K
| RMSProp | epoch: 010 | loss: 0.48893 - acc: 0.7846 -- iter: 384/900
[A[ATraining Step: 274  | total loss: [1m[32m0.45806[0m[0m | time: 144.769s
[2K
| RMSProp | epoch: 010 | loss: 0.45806 - acc: 0.8030 -- iter: 416/900
[A[ATraining Step: 275  | total loss: [1m[32m0.43561[0m[0m | time: 157.306s
[2K
| RMSProp | epoch: 010 | loss: 0.43561 - acc: 0.8133 -- iter: 448/900
[A[ATraining Step: 276  | total loss: [1m[32m0.40578[0m[0m | time: 169.887s
[2K
| RMSProp | epoch: 010 | loss: 0.40578 - acc: 0.8289 -- iter: 480/900
[A[ATraining Step: 277  | total loss: [1m[32m0.38082[0m[0m | time: 182.532s
[2K
| RMSProp | epoch: 010 | loss: 0.38082 - acc: 0.8366 -- iter: 512/900
[A[ATraining Step: 278  | total loss: [1m[32m0.36114[0m[0m | time: 195.452s
[2K
| RMSProp | epoch: 010 | loss: 0.36114 - acc: 0.8498 -- iter: 544/900
[A[ATraining Step: 279  | total loss: [1m[32m0.34715[0m[0m | time: 208.847s
[2K
| RMSProp | epoch: 010 | loss: 0.34715 - acc: 0.8586 -- iter: 576/900
[A[ATraining Step: 280  | total loss: [1m[32m0.34438[0m[0m | time: 219.130s
[2K
| RMSProp | epoch: 010 | loss: 0.34438 - acc: 0.8602 -- iter: 608/900
[A[ATraining Step: 281  | total loss: [1m[32m0.35692[0m[0m | time: 227.251s
[2K
| RMSProp | epoch: 010 | loss: 0.35692 - acc: 0.8430 -- iter: 640/900
[A[ATraining Step: 282  | total loss: [1m[32m0.35114[0m[0m | time: 235.534s
[2K
| RMSProp | epoch: 010 | loss: 0.35114 - acc: 0.8493 -- iter: 672/900
[A[ATraining Step: 283  | total loss: [1m[32m0.34502[0m[0m | time: 248.172s
[2K
| RMSProp | epoch: 010 | loss: 0.34502 - acc: 0.8519 -- iter: 704/900
[A[ATraining Step: 284  | total loss: [1m[32m0.33511[0m[0m | time: 260.472s
[2K
| RMSProp | epoch: 010 | loss: 0.33511 - acc: 0.8573 -- iter: 736/900
[A[ATraining Step: 285  | total loss: [1m[32m0.32550[0m[0m | time: 272.862s
[2K
| RMSProp | epoch: 010 | loss: 0.32550 - acc: 0.8591 -- iter: 768/900
[A[ATraining Step: 286  | total loss: [1m[32m0.31276[0m[0m | time: 285.433s
[2K
| RMSProp | epoch: 010 | loss: 0.31276 - acc: 0.8638 -- iter: 800/900
[A[ATraining Step: 287  | total loss: [1m[32m0.31740[0m[0m | time: 297.120s
[2K
| RMSProp | epoch: 010 | loss: 0.31740 - acc: 0.8618 -- iter: 832/900
[A[ATraining Step: 288  | total loss: [1m[32m0.30596[0m[0m | time: 309.288s
[2K
| RMSProp | epoch: 010 | loss: 0.30596 - acc: 0.8600 -- iter: 864/900
[A[ATraining Step: 289  | total loss: [1m[32m0.29353[0m[0m | time: 321.453s
[2K
| RMSProp | epoch: 010 | loss: 0.29353 - acc: 0.8677 -- iter: 896/900
[A[ATraining Step: 290  | total loss: [1m[32m0.28513[0m[0m | time: 354.873s
[2K
| RMSProp | epoch: 010 | loss: 0.28513 - acc: 0.8716 | val_loss: 1.13150 - val_acc: 0.4787 -- iter: 900/900
--
Training Step: 291  | total loss: [1m[32m0.28358[0m[0m | time: 12.320s
[2K
| RMSProp | epoch: 011 | loss: 0.28358 - acc: 0.8782 -- iter: 032/900
[A[ATraining Step: 292  | total loss: [1m[32m0.29861[0m[0m | time: 24.551s
[2K
| RMSProp | epoch: 011 | loss: 0.29861 - acc: 0.8716 -- iter: 064/900
[A[ATraining Step: 293  | total loss: [1m[32m0.30212[0m[0m | time: 36.870s
[2K
| RMSProp | epoch: 011 | loss: 0.30212 - acc: 0.8719 -- iter: 096/900
[A[ATraining Step: 294  | total loss: [1m[32m0.30368[0m[0m | time: 50.067s
[2K
| RMSProp | epoch: 011 | loss: 0.30368 - acc: 0.8660 -- iter: 128/900
[A[ATraining Step: 295  | total loss: [1m[32m0.30573[0m[0m | time: 62.632s
[2K
| RMSProp | epoch: 011 | loss: 0.30573 - acc: 0.8669 -- iter: 160/900
[A[ATraining Step: 296  | total loss: [1m[32m0.29263[0m[0m | time: 75.511s
[2K
| RMSProp | epoch: 011 | loss: 0.29263 - acc: 0.8708 -- iter: 192/900
[A[ATraining Step: 297  | total loss: [1m[32m0.30036[0m[0m | time: 88.156s
[2K
| RMSProp | epoch: 011 | loss: 0.30036 - acc: 0.8744 -- iter: 224/900
[A[ATraining Step: 298  | total loss: [1m[32m0.46437[0m[0m | time: 100.398s
[2K
| RMSProp | epoch: 011 | loss: 0.46437 - acc: 0.8307 -- iter: 256/900
[A[ATraining Step: 299  | total loss: [1m[32m0.45632[0m[0m | time: 102.986s
[2K
| RMSProp | epoch: 011 | loss: 0.45632 - acc: 0.8257 -- iter: 288/900
[A[ATraining Step: 300  | total loss: [1m[32m0.48969[0m[0m | time: 105.865s
[2K
| RMSProp | epoch: 011 | loss: 0.48969 - acc: 0.7932 -- iter: 320/900
[A[ATraining Step: 301  | total loss: [1m[32m0.44671[0m[0m | time: 118.467s
[2K
| RMSProp | epoch: 011 | loss: 0.44671 - acc: 0.8139 -- iter: 352/900
[A[ATraining Step: 302  | total loss: [1m[32m0.42033[0m[0m | time: 131.235s
[2K
| RMSProp | epoch: 011 | loss: 0.42033 - acc: 0.8262 -- iter: 384/900
[A[ATraining Step: 303  | total loss: [1m[32m0.40170[0m[0m | time: 144.108s
[2K
| RMSProp | epoch: 011 | loss: 0.40170 - acc: 0.8311 -- iter: 416/900
[A[ATraining Step: 304  | total loss: [1m[32m0.37065[0m[0m | time: 156.408s
[2K
| RMSProp | epoch: 011 | loss: 0.37065 - acc: 0.8449 -- iter: 448/900
[A[ATraining Step: 305  | total loss: [1m[32m0.34431[0m[0m | time: 169.029s
[2K
| RMSProp | epoch: 011 | loss: 0.34431 - acc: 0.8573 -- iter: 480/900
[A[ATraining Step: 306  | total loss: [1m[32m0.31736[0m[0m | time: 181.798s
[2K
| RMSProp | epoch: 011 | loss: 0.31736 - acc: 0.8684 -- iter: 512/900
[A[ATraining Step: 307  | total loss: [1m[32m0.29709[0m[0m | time: 194.538s
[2K
| RMSProp | epoch: 011 | loss: 0.29709 - acc: 0.8784 -- iter: 544/900
[A[ATraining Step: 308  | total loss: [1m[32m0.27634[0m[0m | time: 207.339s
[2K
| RMSProp | epoch: 011 | loss: 0.27634 - acc: 0.8906 -- iter: 576/900
[A[ATraining Step: 309  | total loss: [1m[32m0.27575[0m[0m | time: 219.517s
[2K
| RMSProp | epoch: 011 | loss: 0.27575 - acc: 0.8953 -- iter: 608/900
[A[ATraining Step: 310  | total loss: [1m[32m0.27446[0m[0m | time: 231.882s
[2K
| RMSProp | epoch: 011 | loss: 0.27446 - acc: 0.8933 -- iter: 640/900
[A[ATraining Step: 311  | total loss: [1m[32m0.28268[0m[0m | time: 244.504s
[2K
| RMSProp | epoch: 011 | loss: 0.28268 - acc: 0.8946 -- iter: 672/900
[A[ATraining Step: 312  | total loss: [1m[32m0.27297[0m[0m | time: 257.075s
[2K
| RMSProp | epoch: 011 | loss: 0.27297 - acc: 0.8957 -- iter: 704/900
[A[ATraining Step: 313  | total loss: [1m[32m0.27129[0m[0m | time: 269.607s
[2K
| RMSProp | epoch: 011 | loss: 0.27129 - acc: 0.8999 -- iter: 736/900
[A[ATraining Step: 314  | total loss: [1m[32m0.26743[0m[0m | time: 282.168s
[2K
| RMSProp | epoch: 011 | loss: 0.26743 - acc: 0.9068 -- iter: 768/900
[A[ATraining Step: 315  | total loss: [1m[32m0.27966[0m[0m | time: 294.744s
[2K
| RMSProp | epoch: 011 | loss: 0.27966 - acc: 0.8974 -- iter: 800/900
[A[ATraining Step: 316  | total loss: [1m[32m0.27964[0m[0m | time: 307.463s
[2K
| RMSProp | epoch: 011 | loss: 0.27964 - acc: 0.8920 -- iter: 832/900
[A[ATraining Step: 317  | total loss: [1m[32m0.30113[0m[0m | time: 319.903s
[2K
| RMSProp | epoch: 011 | loss: 0.30113 - acc: 0.8809 -- iter: 864/900
[A[ATraining Step: 318  | total loss: [1m[32m0.29275[0m[0m | time: 332.860s
[2K
| RMSProp | epoch: 011 | loss: 0.29275 - acc: 0.8866 -- iter: 896/900
[A[ATraining Step: 319  | total loss: [1m[32m0.27352[0m[0m | time: 363.529s
[2K
| RMSProp | epoch: 011 | loss: 0.27352 - acc: 0.8948 | val_loss: 1.90470 - val_acc: 0.4149 -- iter: 900/900
--
Training Step: 320  | total loss: [1m[32m0.25486[0m[0m | time: 12.489s
[2K
| RMSProp | epoch: 012 | loss: 0.25486 - acc: 0.9022 -- iter: 032/900
[A[ATraining Step: 321  | total loss: [1m[32m0.25834[0m[0m | time: 25.007s
[2K
| RMSProp | epoch: 012 | loss: 0.25834 - acc: 0.8963 -- iter: 064/900
[A[ATraining Step: 322  | total loss: [1m[32m0.24750[0m[0m | time: 38.049s
[2K
| RMSProp | epoch: 012 | loss: 0.24750 - acc: 0.9036 -- iter: 096/900
[A[ATraining Step: 323  | total loss: [1m[32m0.24243[0m[0m | time: 50.768s
[2K
| RMSProp | epoch: 012 | loss: 0.24243 - acc: 0.8976 -- iter: 128/900
[A[ATraining Step: 324  | total loss: [1m[32m0.23905[0m[0m | time: 63.367s
[2K
| RMSProp | epoch: 012 | loss: 0.23905 - acc: 0.8953 -- iter: 160/900
[A[ATraining Step: 325  | total loss: [1m[32m0.22640[0m[0m | time: 75.561s
[2K
| RMSProp | epoch: 012 | loss: 0.22640 - acc: 0.8996 -- iter: 192/900
[A[ATraining Step: 326  | total loss: [1m[32m0.22361[0m[0m | time: 88.381s
[2K
| RMSProp | epoch: 012 | loss: 0.22361 - acc: 0.9034 -- iter: 224/900
[A[ATraining Step: 327  | total loss: [1m[32m0.21818[0m[0m | time: 101.013s
[2K
| RMSProp | epoch: 012 | loss: 0.21818 - acc: 0.9068 -- iter: 256/900
[A[ATraining Step: 328  | total loss: [1m[32m0.20348[0m[0m | time: 113.539s
[2K
| RMSProp | epoch: 012 | loss: 0.20348 - acc: 0.9161 -- iter: 288/900
[A[ATraining Step: 329  | total loss: [1m[32m0.18482[0m[0m | time: 116.073s
[2K
| RMSProp | epoch: 012 | loss: 0.18482 - acc: 0.9245 -- iter: 320/900
[A[ATraining Step: 330  | total loss: [1m[32m0.16694[0m[0m | time: 118.950s
[2K
| RMSProp | epoch: 012 | loss: 0.16694 - acc: 0.9320 -- iter: 352/900
[A[ATraining Step: 331  | total loss: [1m[32m0.15038[0m[0m | time: 131.582s
[2K
| RMSProp | epoch: 012 | loss: 0.15038 - acc: 0.9388 -- iter: 384/900
[A[ATraining Step: 332  | total loss: [1m[32m0.14353[0m[0m | time: 144.123s
[2K
| RMSProp | epoch: 012 | loss: 0.14353 - acc: 0.9387 -- iter: 416/900
[A[ATraining Step: 333  | total loss: [1m[32m0.13957[0m[0m | time: 156.971s
[2K
| RMSProp | epoch: 012 | loss: 0.13957 - acc: 0.9417 -- iter: 448/900
[A[ATraining Step: 334  | total loss: [1m[32m0.14294[0m[0m | time: 169.644s
[2K
| RMSProp | epoch: 012 | loss: 0.14294 - acc: 0.9413 -- iter: 480/900
[A[ATraining Step: 335  | total loss: [1m[32m0.13769[0m[0m | time: 181.532s
[2K
| RMSProp | epoch: 012 | loss: 0.13769 - acc: 0.9440 -- iter: 512/900
[A[ATraining Step: 336  | total loss: [1m[32m0.13567[0m[0m | time: 194.781s
[2K
| RMSProp | epoch: 012 | loss: 0.13567 - acc: 0.9465 -- iter: 544/900
[A[ATraining Step: 337  | total loss: [1m[32m0.12798[0m[0m | time: 206.935s
[2K
| RMSProp | epoch: 012 | loss: 0.12798 - acc: 0.9487 -- iter: 576/900
[A[ATraining Step: 338  | total loss: [1m[32m0.12061[0m[0m | time: 219.492s
[2K
| RMSProp | epoch: 012 | loss: 0.12061 - acc: 0.9539 -- iter: 608/900
[A[ATraining Step: 339  | total loss: [1m[32m0.12862[0m[0m | time: 232.325s
[2K
| RMSProp | epoch: 012 | loss: 0.12862 - acc: 0.9460 -- iter: 640/900
[A[ATraining Step: 340  | total loss: [1m[32m0.15490[0m[0m | time: 245.193s
[2K
| RMSProp | epoch: 012 | loss: 0.15490 - acc: 0.9357 -- iter: 672/900
[A[ATraining Step: 341  | total loss: [1m[32m0.15456[0m[0m | time: 257.993s
[2K
| RMSProp | epoch: 012 | loss: 0.15456 - acc: 0.9359 -- iter: 704/900
[A[ATraining Step: 342  | total loss: [1m[32m0.15499[0m[0m | time: 270.822s
[2K
| RMSProp | epoch: 012 | loss: 0.15499 - acc: 0.9361 -- iter: 736/900
[A[ATraining Step: 343  | total loss: [1m[32m0.17449[0m[0m | time: 283.343s
[2K
| RMSProp | epoch: 012 | loss: 0.17449 - acc: 0.9237 -- iter: 768/900
[A[ATraining Step: 344  | total loss: [1m[32m0.17199[0m[0m | time: 295.654s
[2K
| RMSProp | epoch: 012 | loss: 0.17199 - acc: 0.9251 -- iter: 800/900
[A[ATraining Step: 345  | total loss: [1m[32m0.15971[0m[0m | time: 308.075s
[2K
| RMSProp | epoch: 012 | loss: 0.15971 - acc: 0.9326 -- iter: 832/900
[A[ATraining Step: 346  | total loss: [1m[32m0.14783[0m[0m | time: 320.941s
[2K
| RMSProp | epoch: 012 | loss: 0.14783 - acc: 0.9393 -- iter: 864/900
[A[ATraining Step: 347  | total loss: [1m[32m0.13822[0m[0m | time: 333.794s
[2K
| RMSProp | epoch: 012 | loss: 0.13822 - acc: 0.9454 -- iter: 896/900
[A[ATraining Step: 348  | total loss: [1m[32m0.12745[0m[0m | time: 366.951s
[2K
| RMSProp | epoch: 012 | loss: 0.12745 - acc: 0.9509 | val_loss: 9.06337 - val_acc: 0.6064 -- iter: 900/900
--
Training Step: 349  | total loss: [1m[32m0.13698[0m[0m | time: 12.503s
[2K
| RMSProp | epoch: 013 | loss: 0.13698 - acc: 0.9495 -- iter: 032/900
[A[ATraining Step: 350  | total loss: [1m[32m0.16236[0m[0m | time: 24.651s
[2K
| RMSProp | epoch: 013 | loss: 0.16236 - acc: 0.9452 -- iter: 064/900
[A[ATraining Step: 351  | total loss: [1m[32m0.16445[0m[0m | time: 36.815s
[2K
| RMSProp | epoch: 013 | loss: 0.16445 - acc: 0.9413 -- iter: 096/900
[A[ATraining Step: 352  | total loss: [1m[32m0.17062[0m[0m | time: 49.480s
[2K
| RMSProp | epoch: 013 | loss: 0.17062 - acc: 0.9378 -- iter: 128/900
[A[ATraining Step: 353  | total loss: [1m[32m0.18214[0m[0m | time: 62.440s
[2K
| RMSProp | epoch: 013 | loss: 0.18214 - acc: 0.9378 -- iter: 160/900
[A[ATraining Step: 354  | total loss: [1m[32m0.18110[0m[0m | time: 75.291s
[2K
| RMSProp | epoch: 013 | loss: 0.18110 - acc: 0.9409 -- iter: 192/900
[A[ATraining Step: 355  | total loss: [1m[32m0.16916[0m[0m | time: 89.055s
[2K
| RMSProp | epoch: 013 | loss: 0.16916 - acc: 0.9468 -- iter: 224/900
[A[ATraining Step: 356  | total loss: [1m[32m0.17695[0m[0m | time: 102.147s
[2K
| RMSProp | epoch: 013 | loss: 0.17695 - acc: 0.9458 -- iter: 256/900
[A[ATraining Step: 357  | total loss: [1m[32m0.18268[0m[0m | time: 110.429s
[2K
| RMSProp | epoch: 013 | loss: 0.18268 - acc: 0.9388 -- iter: 288/900
[A[ATraining Step: 358  | total loss: [1m[32m0.17367[0m[0m | time: 118.717s
[2K
| RMSProp | epoch: 013 | loss: 0.17367 - acc: 0.9386 -- iter: 320/900
[A[ATraining Step: 359  | total loss: [1m[32m0.16982[0m[0m | time: 120.486s
[2K
| RMSProp | epoch: 013 | loss: 0.16982 - acc: 0.9385 -- iter: 352/900
[A[ATraining Step: 360  | total loss: [1m[32m0.15901[0m[0m | time: 123.143s
[2K
| RMSProp | epoch: 013 | loss: 0.15901 - acc: 0.9447 -- iter: 384/900
[A[ATraining Step: 361  | total loss: [1m[32m0.14553[0m[0m | time: 135.923s
[2K
| RMSProp | epoch: 013 | loss: 0.14553 - acc: 0.9502 -- iter: 416/900
[A[ATraining Step: 362  | total loss: [1m[32m0.13645[0m[0m | time: 148.303s
[2K
| RMSProp | epoch: 013 | loss: 0.13645 - acc: 0.9521 -- iter: 448/900
[A[ATraining Step: 363  | total loss: [1m[32m0.12652[0m[0m | time: 160.573s
[2K
| RMSProp | epoch: 013 | loss: 0.12652 - acc: 0.9537 -- iter: 480/900
[A[ATraining Step: 364  | total loss: [1m[32m0.12237[0m[0m | time: 173.193s
[2K
| RMSProp | epoch: 013 | loss: 0.12237 - acc: 0.9552 -- iter: 512/900
[A[ATraining Step: 365  | total loss: [1m[32m0.12042[0m[0m | time: 186.132s
[2K
| RMSProp | epoch: 013 | loss: 0.12042 - acc: 0.9566 -- iter: 544/900
[A[ATraining Step: 366  | total loss: [1m[32m0.11865[0m[0m | time: 198.457s
[2K
| RMSProp | epoch: 013 | loss: 0.11865 - acc: 0.9515 -- iter: 576/900
[A[ATraining Step: 367  | total loss: [1m[32m0.13965[0m[0m | time: 210.574s
[2K
| RMSProp | epoch: 013 | loss: 0.13965 - acc: 0.9470 -- iter: 608/900
[A[ATraining Step: 368  | total loss: [1m[32m0.12864[0m[0m | time: 223.456s
[2K
| RMSProp | epoch: 013 | loss: 0.12864 - acc: 0.9523 -- iter: 640/900
[A[ATraining Step: 369  | total loss: [1m[32m0.12985[0m[0m | time: 236.177s
[2K
| RMSProp | epoch: 013 | loss: 0.12985 - acc: 0.9508 -- iter: 672/900
[A[ATraining Step: 370  | total loss: [1m[32m0.13980[0m[0m | time: 248.902s
[2K
| RMSProp | epoch: 013 | loss: 0.13980 - acc: 0.9433 -- iter: 704/900
[A[ATraining Step: 371  | total loss: [1m[32m0.18023[0m[0m | time: 261.851s
[2K
| RMSProp | epoch: 013 | loss: 0.18023 - acc: 0.9302 -- iter: 736/900
[A[ATraining Step: 372  | total loss: [1m[32m0.17101[0m[0m | time: 274.492s
[2K
| RMSProp | epoch: 013 | loss: 0.17101 - acc: 0.9340 -- iter: 768/900
[A[ATraining Step: 373  | total loss: [1m[32m0.15808[0m[0m | time: 286.862s
[2K
| RMSProp | epoch: 013 | loss: 0.15808 - acc: 0.9375 -- iter: 800/900
[A[ATraining Step: 374  | total loss: [1m[32m0.16847[0m[0m | time: 299.493s
[2K
| RMSProp | epoch: 013 | loss: 0.16847 - acc: 0.9375 -- iter: 832/900
[A[ATraining Step: 375  | total loss: [1m[32m0.19043[0m[0m | time: 311.935s
[2K
| RMSProp | epoch: 013 | loss: 0.19043 - acc: 0.9344 -- iter: 864/900
[A[ATraining Step: 376  | total loss: [1m[32m0.18806[0m[0m | time: 324.366s
[2K
| RMSProp | epoch: 013 | loss: 0.18806 - acc: 0.9378 -- iter: 896/900
[A[ATraining Step: 377  | total loss: [1m[32m0.17761[0m[0m | time: 357.211s
[2K
| RMSProp | epoch: 013 | loss: 0.17761 - acc: 0.9378 | val_loss: 0.95484 - val_acc: 0.6950 -- iter: 900/900
--
Training Step: 378  | total loss: [1m[32m0.17260[0m[0m | time: 12.653s
[2K
| RMSProp | epoch: 014 | loss: 0.17260 - acc: 0.9346 -- iter: 032/900
[A[ATraining Step: 379  | total loss: [1m[32m0.15908[0m[0m | time: 25.103s
[2K
| RMSProp | epoch: 014 | loss: 0.15908 - acc: 0.9412 -- iter: 064/900
[A[ATraining Step: 380  | total loss: [1m[32m0.14642[0m[0m | time: 37.345s
[2K
| RMSProp | epoch: 014 | loss: 0.14642 - acc: 0.9471 -- iter: 096/900
[A[ATraining Step: 381  | total loss: [1m[32m0.15251[0m[0m | time: 49.829s
[2K
| RMSProp | epoch: 014 | loss: 0.15251 - acc: 0.9461 -- iter: 128/900
[A[ATraining Step: 382  | total loss: [1m[32m0.15429[0m[0m | time: 62.484s
[2K
| RMSProp | epoch: 014 | loss: 0.15429 - acc: 0.9421 -- iter: 160/900
[A[ATraining Step: 383  | total loss: [1m[32m0.15114[0m[0m | time: 74.677s
[2K
| RMSProp | epoch: 014 | loss: 0.15114 - acc: 0.9417 -- iter: 192/900
[A[ATraining Step: 384  | total loss: [1m[32m0.16256[0m[0m | time: 86.862s
[2K
| RMSProp | epoch: 014 | loss: 0.16256 - acc: 0.9381 -- iter: 224/900
[A[ATraining Step: 385  | total loss: [1m[32m0.18077[0m[0m | time: 99.453s
[2K
| RMSProp | epoch: 014 | loss: 0.18077 - acc: 0.9380 -- iter: 256/900
[A[ATraining Step: 386  | total loss: [1m[32m0.17219[0m[0m | time: 111.975s
[2K
| RMSProp | epoch: 014 | loss: 0.17219 - acc: 0.9411 -- iter: 288/900
[A[ATraining Step: 387  | total loss: [1m[32m0.16744[0m[0m | time: 124.746s
[2K
| RMSProp | epoch: 014 | loss: 0.16744 - acc: 0.9376 -- iter: 320/900
[A[ATraining Step: 388  | total loss: [1m[32m0.18433[0m[0m | time: 137.550s
[2K
| RMSProp | epoch: 014 | loss: 0.18433 - acc: 0.9407 -- iter: 352/900
[A[ATraining Step: 389  | total loss: [1m[32m0.17581[0m[0m | time: 140.098s
[2K
| RMSProp | epoch: 014 | loss: 0.17581 - acc: 0.9435 -- iter: 384/900
[A[ATraining Step: 390  | total loss: [1m[32m0.15996[0m[0m | time: 142.946s
[2K
| RMSProp | epoch: 014 | loss: 0.15996 - acc: 0.9492 -- iter: 416/900
[A[ATraining Step: 391  | total loss: [1m[32m0.14419[0m[0m | time: 155.498s
[2K
| RMSProp | epoch: 014 | loss: 0.14419 - acc: 0.9543 -- iter: 448/900
[A[ATraining Step: 392  | total loss: [1m[32m0.13733[0m[0m | time: 168.379s
[2K
| RMSProp | epoch: 014 | loss: 0.13733 - acc: 0.9557 -- iter: 480/900
[A[ATraining Step: 393  | total loss: [1m[32m0.14935[0m[0m | time: 181.142s
[2K
| RMSProp | epoch: 014 | loss: 0.14935 - acc: 0.9570 -- iter: 512/900
[A[ATraining Step: 394  | total loss: [1m[32m0.14255[0m[0m | time: 193.912s
[2K
| RMSProp | epoch: 014 | loss: 0.14255 - acc: 0.9582 -- iter: 544/900
[A[ATraining Step: 395  | total loss: [1m[32m0.14194[0m[0m | time: 207.299s
[2K
| RMSProp | epoch: 014 | loss: 0.14194 - acc: 0.9530 -- iter: 576/900
[A[ATraining Step: 396  | total loss: [1m[32m0.14644[0m[0m | time: 221.208s
[2K
| RMSProp | epoch: 014 | loss: 0.14644 - acc: 0.9515 -- iter: 608/900
[A[ATraining Step: 397  | total loss: [1m[32m0.13565[0m[0m | time: 229.858s
[2K
| RMSProp | epoch: 014 | loss: 0.13565 - acc: 0.9563 -- iter: 640/900
[A[ATraining Step: 398  | total loss: [1m[32m0.12848[0m[0m | time: 238.157s
[2K
| RMSProp | epoch: 014 | loss: 0.12848 - acc: 0.9575 -- iter: 672/900
[A[ATraining Step: 399  | total loss: [1m[32m0.12406[0m[0m | time: 247.647s
[2K
| RMSProp | epoch: 014 | loss: 0.12406 - acc: 0.9555 -- iter: 704/900
[A[ATraining Step: 400  | total loss: [1m[32m0.11679[0m[0m | time: 280.705s
[2K
| RMSProp | epoch: 014 | loss: 0.11679 - acc: 0.9600 | val_loss: 3.29987 - val_acc: 0.6064 -- iter: 736/900
--
Training Step: 401  | total loss: [1m[32m0.12452[0m[0m | time: 293.424s
[2K
| RMSProp | epoch: 014 | loss: 0.12452 - acc: 0.9609 -- iter: 768/900
[A[ATraining Step: 402  | total loss: [1m[32m0.12134[0m[0m | time: 305.191s
[2K
| RMSProp | epoch: 014 | loss: 0.12134 - acc: 0.9617 -- iter: 800/900
[A[ATraining Step: 403  | total loss: [1m[32m0.12236[0m[0m | time: 317.517s
[2K
| RMSProp | epoch: 014 | loss: 0.12236 - acc: 0.9624 -- iter: 832/900
[A[ATraining Step: 404  | total loss: [1m[32m0.11585[0m[0m | time: 329.038s
[2K
| RMSProp | epoch: 014 | loss: 0.11585 - acc: 0.9630 -- iter: 864/900
[A[ATraining Step: 405  | total loss: [1m[32m0.13424[0m[0m | time: 341.136s
[2K
| RMSProp | epoch: 014 | loss: 0.13424 - acc: 0.9605 -- iter: 896/900
[A[ATraining Step: 406  | total loss: [1m[32m0.13235[0m[0m | time: 374.584s
[2K
| RMSProp | epoch: 014 | loss: 0.13235 - acc: 0.9550 | val_loss: 0.93815 - val_acc: 0.7695 -- iter: 900/900
--
Training Step: 407  | total loss: [1m[32m0.14344[0m[0m | time: 12.698s
[2K
| RMSProp | epoch: 015 | loss: 0.14344 - acc: 0.9533 -- iter: 032/900
[A[ATraining Step: 408  | total loss: [1m[32m0.13350[0m[0m | time: 25.586s
[2K
| RMSProp | epoch: 015 | loss: 0.13350 - acc: 0.9580 -- iter: 064/900
[A[ATraining Step: 409  | total loss: [1m[32m0.12843[0m[0m | time: 37.987s
[2K
| RMSProp | epoch: 015 | loss: 0.12843 - acc: 0.9590 -- iter: 096/900
[A[ATraining Step: 410  | total loss: [1m[32m0.12004[0m[0m | time: 50.671s
[2K
| RMSProp | epoch: 015 | loss: 0.12004 - acc: 0.9600 -- iter: 128/900
[A[ATraining Step: 411  | total loss: [1m[32m0.12144[0m[0m | time: 63.049s
[2K
| RMSProp | epoch: 015 | loss: 0.12144 - acc: 0.9546 -- iter: 160/900
[A[ATraining Step: 412  | total loss: [1m[32m0.11631[0m[0m | time: 75.562s
[2K
| RMSProp | epoch: 015 | loss: 0.11631 - acc: 0.9592 -- iter: 192/900
[A[ATraining Step: 413  | total loss: [1m[32m0.14874[0m[0m | time: 87.917s
[2K
| RMSProp | epoch: 015 | loss: 0.14874 - acc: 0.9539 -- iter: 224/900
[A[ATraining Step: 414  | total loss: [1m[32m0.14054[0m[0m | time: 100.383s
[2K
| RMSProp | epoch: 015 | loss: 0.14054 - acc: 0.9554 -- iter: 256/900
[A[ATraining Step: 415  | total loss: [1m[32m0.14030[0m[0m | time: 112.872s
[2K
| RMSProp | epoch: 015 | loss: 0.14030 - acc: 0.9504 -- iter: 288/900
[A[ATraining Step: 416  | total loss: [1m[32m0.14269[0m[0m | time: 125.547s
[2K
| RMSProp | epoch: 015 | loss: 0.14269 - acc: 0.9523 -- iter: 320/900
[A[ATraining Step: 417  | total loss: [1m[32m0.15252[0m[0m | time: 138.142s
[2K
| RMSProp | epoch: 015 | loss: 0.15252 - acc: 0.9446 -- iter: 352/900
[A[ATraining Step: 418  | total loss: [1m[32m0.15294[0m[0m | time: 150.433s
[2K
| RMSProp | epoch: 015 | loss: 0.15294 - acc: 0.9438 -- iter: 384/900
[A[ATraining Step: 419  | total loss: [1m[32m0.14529[0m[0m | time: 153.278s
[2K
| RMSProp | epoch: 015 | loss: 0.14529 - acc: 0.9432 -- iter: 416/900
[A[ATraining Step: 420  | total loss: [1m[32m0.13267[0m[0m | time: 156.148s
[2K
| RMSProp | epoch: 015 | loss: 0.13267 - acc: 0.9489 -- iter: 448/900
[A[ATraining Step: 421  | total loss: [1m[32m0.12123[0m[0m | time: 168.445s
[2K
| RMSProp | epoch: 015 | loss: 0.12123 - acc: 0.9540 -- iter: 480/900
[A[ATraining Step: 422  | total loss: [1m[32m0.13688[0m[0m | time: 180.420s
[2K
| RMSProp | epoch: 015 | loss: 0.13688 - acc: 0.9430 -- iter: 512/900
[A[ATraining Step: 423  | total loss: [1m[32m0.13035[0m[0m | time: 192.434s
[2K
| RMSProp | epoch: 015 | loss: 0.13035 - acc: 0.9456 -- iter: 544/900
[A[ATraining Step: 424  | total loss: [1m[32m0.12613[0m[0m | time: 204.651s
[2K
| RMSProp | epoch: 015 | loss: 0.12613 - acc: 0.9447 -- iter: 576/900
[A[ATraining Step: 425  | total loss: [1m[32m0.12375[0m[0m | time: 217.017s
[2K
| RMSProp | epoch: 015 | loss: 0.12375 - acc: 0.9471 -- iter: 608/900
[A[ATraining Step: 426  | total loss: [1m[32m0.11409[0m[0m | time: 229.668s
[2K
| RMSProp | epoch: 015 | loss: 0.11409 - acc: 0.9524 -- iter: 640/900
[A[ATraining Step: 427  | total loss: [1m[32m0.10518[0m[0m | time: 242.488s
[2K
| RMSProp | epoch: 015 | loss: 0.10518 - acc: 0.9572 -- iter: 672/900
[A[ATraining Step: 428  | total loss: [1m[32m0.09671[0m[0m | time: 254.489s
[2K
| RMSProp | epoch: 015 | loss: 0.09671 - acc: 0.9615 -- iter: 704/900
[A[ATraining Step: 429  | total loss: [1m[32m0.11459[0m[0m | time: 267.555s
[2K
| RMSProp | epoch: 015 | loss: 0.11459 - acc: 0.9559 -- iter: 736/900
[A[ATraining Step: 430  | total loss: [1m[32m0.11932[0m[0m | time: 279.997s
[2K
| RMSProp | epoch: 015 | loss: 0.11932 - acc: 0.9541 -- iter: 768/900
[A[ATraining Step: 431  | total loss: [1m[32m0.12260[0m[0m | time: 292.609s
[2K
| RMSProp | epoch: 015 | loss: 0.12260 - acc: 0.9493 -- iter: 800/900
[A[ATraining Step: 432  | total loss: [1m[32m0.12564[0m[0m | time: 306.337s
[2K
| RMSProp | epoch: 015 | loss: 0.12564 - acc: 0.9481 -- iter: 832/900
[A[ATraining Step: 433  | total loss: [1m[32m0.12766[0m[0m | time: 318.705s
[2K
| RMSProp | epoch: 015 | loss: 0.12766 - acc: 0.9471 -- iter: 864/900
[A[ATraining Step: 434  | total loss: [1m[32m0.11726[0m[0m | time: 326.996s
[2K
| RMSProp | epoch: 015 | loss: 0.11726 - acc: 0.9524 -- iter: 896/900
[A[ATraining Step: 435  | total loss: [1m[32m0.12074[0m[0m | time: 348.460s
[2K
| RMSProp | epoch: 015 | loss: 0.12074 - acc: 0.9509 | val_loss: 1.19165 - val_acc: 0.6596 -- iter: 900/900
--
Validation AUC:0.8738211896106634
Validation AUPRC:0.9030551046217686
Test AUC:0.8958077436582109
Test AUPRC:0.91435349600524
BestTestF1Score	0.87	0.68	0.85	0.89	0.86	150	18	89	25	0.01
BestTestMCCScore	0.87	0.68	0.85	0.89	0.86	150	18	89	25	0.01
BestTestAccuracyScore	0.87	0.68	0.85	0.89	0.86	150	18	89	25	0.01
BestValidationF1Score	0.83	0.59	0.8	0.85	0.81	139	24	87	32	0.01
BestValidationMCC	0.83	0.59	0.8	0.85	0.81	139	24	87	32	0.01
BestValidationAccuracy	0.83	0.59	0.8	0.85	0.81	139	24	87	32	0.01
TestPredictions (Threshold:0.01)
CHEMBL153037,TN,INACT,0.0	CHEMBL3680628,TP,ACT,0.11999999731779099	CHEMBL225493,TP,ACT,0.18000000715255737	CHEMBL245747,TP,ACT,0.10000000149011612	CHEMBL3215611,TP,ACT,0.3400000035762787	CHEMBL539758,FP,INACT,0.05000000074505806	CHEMBL380860,TP,ACT,0.9700000286102295	CHEMBL2058974,TP,ACT,1.0	CHEMBL2086615,TP,ACT,0.8799999952316284	CHEMBL563272,TP,ACT,0.9100000262260437	CHEMBL211024,TP,ACT,1.0	CHEMBL3393897,TN,INACT,0.009999999776482582	CHEMBL96229,TN,INACT,0.0	CHEMBL460950,TP,ACT,0.8299999833106995	CHEMBL164,TN,INACT,0.0	CHEMBL1221633,TN,INACT,0.009999999776482582	CHEMBL170051,FN,ACT,0.009999999776482582	CHEMBL380240,TP,ACT,0.36000001430511475	CHEMBL1814394,TN,INACT,0.009999999776482582	CHEMBL9237,FP,INACT,0.6499999761581421	CHEMBL443622,TN,INACT,0.0	CHEMBL208952,TP,ACT,0.14000000059604645	CHEMBL93507,TN,INACT,0.0	CHEMBL9323,TN,INACT,0.0	CHEMBL355716,TP,ACT,0.09000000357627869	CHEMBL1242379,TN,INACT,0.0	CHEMBL199450,TP,ACT,0.949999988079071	CHEMBL402151,TP,ACT,0.03999999910593033	CHEMBL216835,TP,ACT,0.029999999329447746	CHEMBL1215088,FN,ACT,0.0	CHEMBL393498,TP,ACT,0.9700000286102295	CHEMBL1288288,TP,ACT,0.3499999940395355	CHEMBL246782,FN,ACT,0.009999999776482582	CHEMBL1683141,TP,ACT,1.0	CHEMBL3219657,TN,INACT,0.0	CHEMBL536312,TP,ACT,0.550000011920929	CHEMBL88405,FP,INACT,0.20999999344348907	CHEMBL1795517,TN,INACT,0.0	CHEMBL2334683,TP,ACT,1.0	CHEMBL472992,TP,ACT,1.0	CHEMBL461496,TN,INACT,0.0	CHEMBL1684644,TN,INACT,0.009999999776482582	CHEMBL389538,TP,ACT,0.6000000238418579	CHEMBL3697944,TP,ACT,0.019999999552965164	CHEMBL431885,TP,ACT,0.8799999952316284	CHEMBL517776,TP,ACT,0.9800000190734863	CHEMBL2159182,FN,ACT,0.0	CHEMBL2346929,TP,ACT,0.5799999833106995	CHEMBL208957,TP,ACT,0.5699999928474426	CHEMBL217753,FP,INACT,0.12999999523162842	CHEMBL1814393,TN,INACT,0.0	CHEMBL289562,TN,INACT,0.0	CHEMBL1684751,TN,INACT,0.0	CHEMBL3086660,FN,ACT,0.0	CHEMBL3127992,TP,ACT,0.6399999856948853	CHEMBL1242209,TN,INACT,0.0	CHEMBL237568,TP,ACT,0.1599999964237213	CHEMBL1929396,FP,INACT,0.2199999988079071	CHEMBL232920,TP,ACT,1.0	CHEMBL1650416,TP,ACT,0.36000001430511475	CHEMBL472101,TP,ACT,0.5600000023841858	CHEMBL1229644,TP,ACT,1.0	CHEMBL1682977,TP,ACT,0.05000000074505806	CHEMBL472102,TP,ACT,0.05999999865889549	CHEMBL461228,TN,INACT,0.0	CHEMBL1275853,TP,ACT,0.05999999865889549	CHEMBL1683481,TP,ACT,0.7099999785423279	CHEMBL195547,TP,ACT,0.05000000074505806	CHEMBL3644784,TP,ACT,1.0	CHEMBL3819072,TN,INACT,0.0	CHEMBL3330060,TP,ACT,0.9700000286102295	CHEMBL3220151,TN,INACT,0.0	CHEMBL1097368,TN,INACT,0.009999999776482582	CHEMBL487432,FP,INACT,0.07000000029802322	CHEMBL196933,FN,ACT,0.009999999776482582	CHEMBL184651,TP,ACT,0.15000000596046448	CHEMBL1818906,TN,INACT,0.0	CHEMBL399189,FP,INACT,0.03999999910593033	CHEMBL1096737,TN,INACT,0.0	CHEMBL1085269,TP,ACT,1.0	CHEMBL2337369,TN,INACT,0.0	CHEMBL1951430,TP,ACT,0.05999999865889549	CHEMBL371480,TP,ACT,0.9399999976158142	CHEMBL2335376,TN,INACT,0.0	CHEMBL1209915,TN,INACT,0.0	CHEMBL466590,TN,INACT,0.0	CHEMBL1683485,TP,ACT,0.7200000286102295	CHEMBL365322,TP,ACT,0.25999999046325684	CHEMBL1818905,TN,INACT,0.0	CHEMBL184071,TP,ACT,0.3199999928474426	CHEMBL429829,TP,ACT,0.8700000047683716	CHEMBL1241772,TN,INACT,0.0	CHEMBL376359,FN,ACT,0.009999999776482582	CHEMBL175034,TP,ACT,0.5	CHEMBL50,TN,INACT,0.0	CHEMBL404210,TP,ACT,0.10999999940395355	CHEMBL475574,TP,ACT,0.9599999785423279	CHEMBL1684763,TN,INACT,0.0	CHEMBL1814395,TN,INACT,0.0	CHEMBL2058970,TP,ACT,1.0	CHEMBL471515,TP,ACT,0.7400000095367432	CHEMBL1684779,TN,INACT,0.0	CHEMBL230342,TP,ACT,0.029999999329447746	CHEMBL1683999,TP,ACT,0.9300000071525574	CHEMBL453574,FP,INACT,0.05000000074505806	CHEMBL2058972,TP,ACT,1.0	CHEMBL2337368,TN,INACT,0.0	CHEMBL251958,TN,INACT,0.009999999776482582	CHEMBL480536,TP,ACT,0.8299999833106995	CHEMBL1650449,TP,ACT,0.6700000166893005	CHEMBL3686748,FN,ACT,0.009999999776482582	CHEMBL473419,TP,ACT,1.0	CHEMBL321509,TP,ACT,0.9700000286102295	CHEMBL1684756,TN,INACT,0.0	CHEMBL2408699,TN,INACT,0.0	CHEMBL3098312,TN,INACT,0.0	CHEMBL328694,TN,INACT,0.0	CHEMBL422564,TN,INACT,0.009999999776482582	CHEMBL377320,TP,ACT,0.019999999552965164	CHEMBL1833982,TN,INACT,0.0	CHEMBL242811,TP,ACT,1.0	CHEMBL400841,TP,ACT,0.949999988079071	CHEMBL461291,TN,INACT,0.0	CHEMBL217059,TP,ACT,0.07999999821186066	CHEMBL1683479,TP,ACT,0.23999999463558197	CHEMBL379340,TP,ACT,0.949999988079071	CHEMBL3652795,TN,INACT,0.0	CHEMBL186877,FN,ACT,0.0	CHEMBL201544,TP,ACT,0.9599999785423279	CHEMBL513725,TP,ACT,0.9800000190734863	CHEMBL93354,TP,ACT,0.029999999329447746	CHEMBL1683115,TP,ACT,1.0	CHEMBL9238,TP,ACT,0.1899999976158142	CHEMBL521155,TN,INACT,0.0	CHEMBL151999,TN,INACT,0.0	CHEMBL328994,TP,ACT,0.6399999856948853	CHEMBL235225,TP,ACT,0.019999999552965164	CHEMBL383012,TP,ACT,0.20000000298023224	CHEMBL234045,TP,ACT,0.8899999856948853	CHEMBL217091,TN,INACT,0.0	CHEMBL3125571,TN,INACT,0.0	CHEMBL231050,TP,ACT,0.36000001430511475	CHEMBL2334681,TP,ACT,0.05000000074505806	CHEMBL1683504,FN,ACT,0.009999999776482582	CHEMBL1683558,TP,ACT,0.7099999785423279	CHEMBL1202091,TP,ACT,0.7900000214576721	CHEMBL589598,TP,ACT,0.9800000190734863	CHEMBL3425754,TP,ACT,1.0	CHEMBL474015,TN,INACT,0.0	CHEMBL3274329,TN,INACT,0.0	CHEMBL1684638,TN,INACT,0.0	CHEMBL3654426,TP,ACT,0.949999988079071	CHEMBL1683137,FN,ACT,0.009999999776482582	CHEMBL3350816,TP,ACT,0.9900000095367432	CHEMBL1242112,TN,INACT,0.0	CHEMBL425558,TP,ACT,0.8399999737739563	CHEMBL525183,FN,ACT,0.0	CHEMBL2063025,FN,ACT,0.0	CHEMBL1683126,FN,ACT,0.0	CHEMBL377749,TP,ACT,0.019999999552965164	CHEMBL425375,TP,ACT,0.9900000095367432	CHEMBL389624,TP,ACT,0.019999999552965164	CHEMBL1684000,TP,ACT,0.949999988079071	CHEMBL3236120,TP,ACT,0.07999999821186066	CHEMBL238114,TP,ACT,0.33000001311302185	CHEMBL2023560,FP,INACT,1.0	CHEMBL1818903,FP,INACT,0.05999999865889549	CHEMBL3236670,TN,INACT,0.0	CHEMBL402645,TP,ACT,0.9900000095367432	CHEMBL1771580,TN,INACT,0.0	CHEMBL378597,TP,ACT,0.019999999552965164	CHEMBL185067,TP,ACT,0.07000000029802322	CHEMBL3358994,TN,INACT,0.0	CHEMBL470477,TP,ACT,0.44999998807907104	CHEMBL400761,TP,ACT,0.46000000834465027	CHEMBL387300,TN,INACT,0.009999999776482582	CHEMBL474211,TP,ACT,0.9700000286102295	CHEMBL65561,FP,INACT,0.30000001192092896	CHEMBL2069842,TP,ACT,0.9800000190734863	CHEMBL3402118,TP,ACT,0.8600000143051147	CHEMBL217290,TP,ACT,0.6700000166893005	CHEMBL1779708,TP,ACT,0.8999999761581421	CHEMBL1085597,TP,ACT,1.0	CHEMBL2441834,TP,ACT,0.1599999964237213	CHEMBL486253,TN,INACT,0.0	CHEMBL230495,TP,ACT,0.9900000095367432	CHEMBL3805235,TP,ACT,0.8500000238418579	CHEMBL197301,TP,ACT,0.9700000286102295	CHEMBL1209540,FN,ACT,0.0	CHEMBL3109161,FP,INACT,0.07999999821186066	CHEMBL1092013,TN,INACT,0.0	CHEMBL378010,TP,ACT,1.0	CHEMBL183517,FN,ACT,0.0	CHEMBL1230015,TP,ACT,0.9800000190734863	CHEMBL496953,TN,INACT,0.0	CHEMBL231196,TP,ACT,0.7099999785423279	CHEMBL3093924,TP,ACT,0.9800000190734863	CHEMBL1684636,TN,INACT,0.0	CHEMBL260701,TP,ACT,1.0	CHEMBL390194,TP,ACT,1.0	CHEMBL391559,TP,ACT,0.8399999737739563	CHEMBL1818941,TN,INACT,0.009999999776482582	CHEMBL391929,TP,ACT,0.47999998927116394	CHEMBL2088592,TN,INACT,0.0	CHEMBL2206478,TP,ACT,0.36000001430511475	CHEMBL377944,TP,ACT,0.2199999988079071	CHEMBL399726,TP,ACT,0.019999999552965164	CHEMBL2418629,TP,ACT,0.7699999809265137	CHEMBL3734964,TP,ACT,0.8700000047683716	CHEMBL1684643,TN,INACT,0.0	CHEMBL183418,TP,ACT,0.07999999821186066	CHEMBL2346921,TP,ACT,0.23000000417232513	CHEMBL250399,TP,ACT,0.11999999731779099	CHEMBL2334682,TP,ACT,0.8700000047683716	CHEMBL363250,TP,ACT,0.20999999344348907	CHEMBL2425081,TN,INACT,0.0	CHEMBL359592,TN,INACT,0.0	CHEMBL365567,TP,ACT,1.0	CHEMBL3125570,TN,INACT,0.0	CHEMBL507056,TN,INACT,0.0	CHEMBL507202,TN,INACT,0.0	CHEMBL2063037,TP,ACT,0.6899999976158142	CHEMBL452470,TN,INACT,0.0	CHEMBL2086598,TP,ACT,0.029999999329447746	CHEMBL283309,TP,ACT,0.9900000095367432	CHEMBL276056,FN,ACT,0.0	CHEMBL93847,TP,ACT,0.9900000095367432	CHEMBL3800113,FP,INACT,0.9900000095367432	CHEMBL1683977,TP,ACT,0.3700000047683716	CHEMBL372110,TP,ACT,0.6700000166893005	CHEMBL147691,FP,INACT,0.05999999865889549	CHEMBL1818921,TN,INACT,0.0	CHEMBL1818917,TN,INACT,0.0	CHEMBL248837,FN,ACT,0.009999999776482582	CHEMBL3654421,TP,ACT,0.3400000035762787	CHEMBL184527,FN,ACT,0.009999999776482582	CHEMBL2261077,FP,INACT,0.4399999976158142	CHEMBL3350930,FN,ACT,0.0	CHEMBL1093100,TN,INACT,0.009999999776482582	CHEMBL365280,FN,ACT,0.0	CHEMBL463230,FN,ACT,0.009999999776482582	CHEMBL392139,TN,INACT,0.0	CHEMBL382382,TN,INACT,0.0	CHEMBL610512,TN,INACT,0.0	CHEMBL208964,FN,ACT,0.0	CHEMBL400359,TN,INACT,0.0	CHEMBL462497,TN,INACT,0.0	CHEMBL1684773,TN,INACT,0.0	CHEMBL554683,FN,ACT,0.0	CHEMBL592778,TP,ACT,0.9900000095367432	CHEMBL559011,TP,ACT,1.0	CHEMBL1683098,TP,ACT,0.8999999761581421	CHEMBL1684777,TN,INACT,0.0	CHEMBL445437,TP,ACT,0.05000000074505806	CHEMBL2337362,TN,INACT,0.0	CHEMBL1684771,TN,INACT,0.0	CHEMBL200586,TN,INACT,0.0	CHEMBL1097190,TN,INACT,0.0	CHEMBL3798795,TN,INACT,0.0	CHEMBL1215235,TP,ACT,0.019999999552965164	CHEMBL518629,TP,ACT,0.1599999964237213	CHEMBL263946,TP,ACT,0.10000000149011612	CHEMBL598754,FP,INACT,0.03999999910593033	CHEMBL392552,TP,ACT,0.9800000190734863	CHEMBL3799629,TN,INACT,0.009999999776482582	CHEMBL562388,TP,ACT,0.7400000095367432	CHEMBL391578,TP,ACT,0.9700000286102295	CHEMBL3233567,FP,INACT,0.5099999904632568	CHEMBL1241582,TN,INACT,0.0	CHEMBL1242663,TN,INACT,0.0	CHEMBL1650422,TP,ACT,0.8700000047683716	CHEMBL566929,FP,INACT,0.029999999329447746	CHEMBL67680,TP,ACT,0.4099999964237213	CHEMBL3353355,TN,INACT,0.009999999776482582	CHEMBL3329626,FN,ACT,0.0	CHEMBL3408421,TN,INACT,0.0	CHEMBL520089,TP,ACT,0.7900000214576721	CHEMBL1650444,TP,ACT,0.4099999964237213	CHEMBL387552,TP,ACT,0.7599999904632568	CHEMBL3236107,TP,ACT,0.8999999761581421	CHEMBL255492,TP,ACT,0.9300000071525574	CHEMBL387444,TP,ACT,0.27000001072883606	

