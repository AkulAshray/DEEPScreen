CNNModel CHEMBL3199 adam 0.0005 30 128 0 0.8 False True
Number of active compounds :	867
Number of inactive compounds :	867
---------------------------------
Run id: CNNModel_CHEMBL3199_adam_0.0005_30_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3199_adam_0.0005_30_128_0.8_True/
---------------------------------
Training samples: 1105
Validation samples: 346
--
Training Step: 1  | time: 1.565s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1105
[A[ATraining Step: 2  | total loss: [1m[32m0.62414[0m[0m | time: 2.495s
[2K
| Adam | epoch: 001 | loss: 0.62414 - acc: 0.3375 -- iter: 0064/1105
[A[ATraining Step: 3  | total loss: [1m[32m0.67926[0m[0m | time: 3.356s
[2K
| Adam | epoch: 001 | loss: 0.67926 - acc: 0.5983 -- iter: 0096/1105
[A[ATraining Step: 4  | total loss: [1m[32m0.69040[0m[0m | time: 4.390s
[2K
| Adam | epoch: 001 | loss: 0.69040 - acc: 0.5011 -- iter: 0128/1105
[A[ATraining Step: 5  | total loss: [1m[32m0.69577[0m[0m | time: 5.453s
[2K
| Adam | epoch: 001 | loss: 0.69577 - acc: 0.4138 -- iter: 0160/1105
[A[ATraining Step: 6  | total loss: [1m[32m0.69394[0m[0m | time: 6.620s
[2K
| Adam | epoch: 001 | loss: 0.69394 - acc: 0.4692 -- iter: 0192/1105
[A[ATraining Step: 7  | total loss: [1m[32m0.69299[0m[0m | time: 7.788s
[2K
| Adam | epoch: 001 | loss: 0.69299 - acc: 0.5064 -- iter: 0224/1105
[A[ATraining Step: 8  | total loss: [1m[32m0.69219[0m[0m | time: 8.646s
[2K
| Adam | epoch: 001 | loss: 0.69219 - acc: 0.5380 -- iter: 0256/1105
[A[ATraining Step: 9  | total loss: [1m[32m0.69318[0m[0m | time: 9.746s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.5013 -- iter: 0288/1105
[A[ATraining Step: 10  | total loss: [1m[32m0.69390[0m[0m | time: 10.870s
[2K
| Adam | epoch: 001 | loss: 0.69390 - acc: 0.4694 -- iter: 0320/1105
[A[ATraining Step: 11  | total loss: [1m[32m0.69267[0m[0m | time: 11.936s
[2K
| Adam | epoch: 001 | loss: 0.69267 - acc: 0.5283 -- iter: 0352/1105
[A[ATraining Step: 12  | total loss: [1m[32m0.69340[0m[0m | time: 12.882s
[2K
| Adam | epoch: 001 | loss: 0.69340 - acc: 0.4874 -- iter: 0384/1105
[A[ATraining Step: 13  | total loss: [1m[32m0.69212[0m[0m | time: 13.906s
[2K
| Adam | epoch: 001 | loss: 0.69212 - acc: 0.5464 -- iter: 0416/1105
[A[ATraining Step: 14  | total loss: [1m[32m0.69136[0m[0m | time: 14.919s
[2K
| Adam | epoch: 001 | loss: 0.69136 - acc: 0.5786 -- iter: 0448/1105
[A[ATraining Step: 15  | total loss: [1m[32m0.69131[0m[0m | time: 15.970s
[2K
| Adam | epoch: 001 | loss: 0.69131 - acc: 0.5723 -- iter: 0480/1105
[A[ATraining Step: 16  | total loss: [1m[32m0.69303[0m[0m | time: 17.079s
[2K
| Adam | epoch: 001 | loss: 0.69303 - acc: 0.5217 -- iter: 0512/1105
[A[ATraining Step: 17  | total loss: [1m[32m0.69481[0m[0m | time: 17.982s
[2K
| Adam | epoch: 001 | loss: 0.69481 - acc: 0.4802 -- iter: 0544/1105
[A[ATraining Step: 18  | total loss: [1m[32m0.69527[0m[0m | time: 18.937s
[2K
| Adam | epoch: 001 | loss: 0.69527 - acc: 0.4654 -- iter: 0576/1105
[A[ATraining Step: 19  | total loss: [1m[32m0.69407[0m[0m | time: 20.001s
[2K
| Adam | epoch: 001 | loss: 0.69407 - acc: 0.4873 -- iter: 0608/1105
[A[ATraining Step: 20  | total loss: [1m[32m0.69484[0m[0m | time: 21.075s
[2K
| Adam | epoch: 001 | loss: 0.69484 - acc: 0.4613 -- iter: 0640/1105
[A[ATraining Step: 21  | total loss: [1m[32m0.69403[0m[0m | time: 22.075s
[2K
| Adam | epoch: 001 | loss: 0.69403 - acc: 0.4830 -- iter: 0672/1105
[A[ATraining Step: 22  | total loss: [1m[32m0.69312[0m[0m | time: 23.030s
[2K
| Adam | epoch: 001 | loss: 0.69312 - acc: 0.5162 -- iter: 0704/1105
[A[ATraining Step: 23  | total loss: [1m[32m0.69248[0m[0m | time: 24.036s
[2K
| Adam | epoch: 001 | loss: 0.69248 - acc: 0.5387 -- iter: 0736/1105
[A[ATraining Step: 24  | total loss: [1m[32m0.69318[0m[0m | time: 25.015s
[2K
| Adam | epoch: 001 | loss: 0.69318 - acc: 0.5103 -- iter: 0768/1105
[A[ATraining Step: 25  | total loss: [1m[32m0.69211[0m[0m | time: 26.035s
[2K
| Adam | epoch: 001 | loss: 0.69211 - acc: 0.5501 -- iter: 0800/1105
[A[ATraining Step: 26  | total loss: [1m[32m0.69265[0m[0m | time: 27.208s
[2K
| Adam | epoch: 001 | loss: 0.69265 - acc: 0.5285 -- iter: 0832/1105
[A[ATraining Step: 27  | total loss: [1m[32m0.69273[0m[0m | time: 28.140s
[2K
| Adam | epoch: 001 | loss: 0.69273 - acc: 0.5212 -- iter: 0864/1105
[A[ATraining Step: 28  | total loss: [1m[32m0.69220[0m[0m | time: 29.217s
[2K
| Adam | epoch: 001 | loss: 0.69220 - acc: 0.5393 -- iter: 0896/1105
[A[ATraining Step: 29  | total loss: [1m[32m0.69200[0m[0m | time: 30.330s
[2K
| Adam | epoch: 001 | loss: 0.69200 - acc: 0.5450 -- iter: 0928/1105
[A[ATraining Step: 30  | total loss: [1m[32m0.69329[0m[0m | time: 31.431s
[2K
| Adam | epoch: 001 | loss: 0.69329 - acc: 0.5047 -- iter: 0960/1105
[A[ATraining Step: 31  | total loss: [1m[32m0.69328[0m[0m | time: 32.261s
[2K
| Adam | epoch: 001 | loss: 0.69328 - acc: 0.5036 -- iter: 0992/1105
[A[ATraining Step: 32  | total loss: [1m[32m0.69342[0m[0m | time: 33.269s
[2K
| Adam | epoch: 001 | loss: 0.69342 - acc: 0.4958 -- iter: 1024/1105
[A[ATraining Step: 33  | total loss: [1m[32m0.69474[0m[0m | time: 34.237s
[2K
| Adam | epoch: 001 | loss: 0.69474 - acc: 0.4555 -- iter: 1056/1105
[A[ATraining Step: 34  | total loss: [1m[32m0.69379[0m[0m | time: 35.192s
[2K
| Adam | epoch: 001 | loss: 0.69379 - acc: 0.4852 -- iter: 1088/1105
[A[ATraining Step: 35  | total loss: [1m[32m0.69386[0m[0m | time: 38.005s
[2K
| Adam | epoch: 001 | loss: 0.69386 - acc: 0.4817 | val_loss: 0.69356 - val_acc: 0.4827 -- iter: 1105/1105
--
Training Step: 36  | total loss: [1m[32m0.69422[0m[0m | time: 0.490s
[2K
| Adam | epoch: 002 | loss: 0.69422 - acc: 0.4674 -- iter: 0032/1105
[A[ATraining Step: 37  | total loss: [1m[32m0.69444[0m[0m | time: 1.613s
[2K
| Adam | epoch: 002 | loss: 0.69444 - acc: 0.4563 -- iter: 0064/1105
[A[ATraining Step: 38  | total loss: [1m[32m0.69419[0m[0m | time: 2.688s
[2K
| Adam | epoch: 002 | loss: 0.69419 - acc: 0.4648 -- iter: 0096/1105
[A[ATraining Step: 39  | total loss: [1m[32m0.69416[0m[0m | time: 3.779s
[2K
| Adam | epoch: 002 | loss: 0.69416 - acc: 0.4596 -- iter: 0128/1105
[A[ATraining Step: 40  | total loss: [1m[32m0.69398[0m[0m | time: 4.679s
[2K
| Adam | epoch: 002 | loss: 0.69398 - acc: 0.4672 -- iter: 0160/1105
[A[ATraining Step: 41  | total loss: [1m[32m0.69391[0m[0m | time: 5.630s
[2K
| Adam | epoch: 002 | loss: 0.69391 - acc: 0.4675 -- iter: 0192/1105
[A[ATraining Step: 42  | total loss: [1m[32m0.69363[0m[0m | time: 6.689s
[2K
| Adam | epoch: 002 | loss: 0.69363 - acc: 0.4846 -- iter: 0224/1105
[A[ATraining Step: 43  | total loss: [1m[32m0.69358[0m[0m | time: 7.681s
[2K
| Adam | epoch: 002 | loss: 0.69358 - acc: 0.4818 -- iter: 0256/1105
[A[ATraining Step: 44  | total loss: [1m[32m0.69360[0m[0m | time: 8.878s
[2K
| Adam | epoch: 002 | loss: 0.69360 - acc: 0.4741 -- iter: 0288/1105
[A[ATraining Step: 45  | total loss: [1m[32m0.69352[0m[0m | time: 10.029s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.4785 -- iter: 0320/1105
[A[ATraining Step: 46  | total loss: [1m[32m0.69343[0m[0m | time: 10.845s
[2K
| Adam | epoch: 002 | loss: 0.69343 - acc: 0.4873 -- iter: 0352/1105
[A[ATraining Step: 47  | total loss: [1m[32m0.69334[0m[0m | time: 12.024s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4996 -- iter: 0384/1105
[A[ATraining Step: 48  | total loss: [1m[32m0.69337[0m[0m | time: 13.227s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.4746 -- iter: 0416/1105
[A[ATraining Step: 49  | total loss: [1m[32m0.69331[0m[0m | time: 14.251s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4983 -- iter: 0448/1105
[A[ATraining Step: 50  | total loss: [1m[32m0.69328[0m[0m | time: 15.154s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.4889 -- iter: 0480/1105
[A[ATraining Step: 51  | total loss: [1m[32m0.69321[0m[0m | time: 16.190s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.5192 -- iter: 0512/1105
[A[ATraining Step: 52  | total loss: [1m[32m0.69324[0m[0m | time: 17.153s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.5022 -- iter: 0544/1105
[A[ATraining Step: 53  | total loss: [1m[32m0.69329[0m[0m | time: 18.117s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4789 -- iter: 0576/1105
[A[ATraining Step: 54  | total loss: [1m[32m0.69323[0m[0m | time: 19.201s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.4910 -- iter: 0608/1105
[A[ATraining Step: 55  | total loss: [1m[32m0.69317[0m[0m | time: 20.319s
[2K
| Adam | epoch: 002 | loss: 0.69317 - acc: 0.5057 -- iter: 0640/1105
[A[ATraining Step: 56  | total loss: [1m[32m0.69320[0m[0m | time: 21.176s
[2K
| Adam | epoch: 002 | loss: 0.69320 - acc: 0.4873 -- iter: 0672/1105
[A[ATraining Step: 57  | total loss: [1m[32m0.69323[0m[0m | time: 22.305s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.4804 -- iter: 0704/1105
[A[ATraining Step: 58  | total loss: [1m[32m0.69324[0m[0m | time: 23.439s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4746 -- iter: 0736/1105
[A[ATraining Step: 59  | total loss: [1m[32m0.69324[0m[0m | time: 24.447s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4738 -- iter: 0768/1105
[A[ATraining Step: 60  | total loss: [1m[32m0.69321[0m[0m | time: 25.372s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4938 -- iter: 0800/1105
[A[ATraining Step: 61  | total loss: [1m[32m0.69319[0m[0m | time: 26.474s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5028 -- iter: 0832/1105
[A[ATraining Step: 62  | total loss: [1m[32m0.69319[0m[0m | time: 27.404s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5064 -- iter: 0864/1105
[A[ATraining Step: 63  | total loss: [1m[32m0.69317[0m[0m | time: 28.383s
[2K
| Adam | epoch: 002 | loss: 0.69317 - acc: 0.5135 -- iter: 0896/1105
[A[ATraining Step: 64  | total loss: [1m[32m0.69316[0m[0m | time: 29.483s
[2K
| Adam | epoch: 002 | loss: 0.69316 - acc: 0.5196 -- iter: 0928/1105
[A[ATraining Step: 65  | total loss: [1m[32m0.69314[0m[0m | time: 30.672s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5211 -- iter: 0960/1105
[A[ATraining Step: 66  | total loss: [1m[32m0.69314[0m[0m | time: 31.554s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5071 -- iter: 0992/1105
[A[ATraining Step: 67  | total loss: [1m[32m0.69314[0m[0m | time: 32.620s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5063 -- iter: 1024/1105
[A[ATraining Step: 68  | total loss: [1m[32m0.69314[0m[0m | time: 33.727s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5018 -- iter: 1056/1105
[A[ATraining Step: 69  | total loss: [1m[32m0.69315[0m[0m | time: 34.668s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.4980 -- iter: 1088/1105
[A[ATraining Step: 70  | total loss: [1m[32m0.69317[0m[0m | time: 37.460s
[2K
| Adam | epoch: 002 | loss: 0.69317 - acc: 0.4874 | val_loss: 0.69298 - val_acc: 0.4827 -- iter: 1105/1105
--
Training Step: 71  | total loss: [1m[32m0.69309[0m[0m | time: 0.579s
[2K
| Adam | epoch: 003 | loss: 0.69309 - acc: 0.5030 -- iter: 0032/1105
[A[ATraining Step: 72  | total loss: [1m[32m0.69301[0m[0m | time: 1.236s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5193 -- iter: 0064/1105
[A[ATraining Step: 73  | total loss: [1m[32m0.69289[0m[0m | time: 2.395s
[2K
| Adam | epoch: 003 | loss: 0.69289 - acc: 0.5335 -- iter: 0096/1105
[A[ATraining Step: 74  | total loss: [1m[32m0.69301[0m[0m | time: 3.314s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5195 -- iter: 0128/1105
[A[ATraining Step: 75  | total loss: [1m[32m0.69298[0m[0m | time: 4.384s
[2K
| Adam | epoch: 003 | loss: 0.69298 - acc: 0.5208 -- iter: 0160/1105
[A[ATraining Step: 76  | total loss: [1m[32m0.69272[0m[0m | time: 5.497s
[2K
| Adam | epoch: 003 | loss: 0.69272 - acc: 0.5353 -- iter: 0192/1105
[A[ATraining Step: 77  | total loss: [1m[32m0.69269[0m[0m | time: 6.538s
[2K
| Adam | epoch: 003 | loss: 0.69269 - acc: 0.5349 -- iter: 0224/1105
[A[ATraining Step: 78  | total loss: [1m[32m0.69236[0m[0m | time: 7.388s
[2K
| Adam | epoch: 003 | loss: 0.69236 - acc: 0.5443 -- iter: 0256/1105
[A[ATraining Step: 79  | total loss: [1m[32m0.69282[0m[0m | time: 8.393s
[2K
| Adam | epoch: 003 | loss: 0.69282 - acc: 0.5300 -- iter: 0288/1105
[A[ATraining Step: 80  | total loss: [1m[32m0.69280[0m[0m | time: 9.379s
[2K
| Adam | epoch: 003 | loss: 0.69280 - acc: 0.5269 -- iter: 0320/1105
[A[ATraining Step: 81  | total loss: [1m[32m0.69344[0m[0m | time: 10.425s
[2K
| Adam | epoch: 003 | loss: 0.69344 - acc: 0.5084 -- iter: 0352/1105
[A[ATraining Step: 82  | total loss: [1m[32m0.69366[0m[0m | time: 11.493s
[2K
| Adam | epoch: 003 | loss: 0.69366 - acc: 0.4982 -- iter: 0384/1105
[A[ATraining Step: 83  | total loss: [1m[32m0.69370[0m[0m | time: 12.556s
[2K
| Adam | epoch: 003 | loss: 0.69370 - acc: 0.4921 -- iter: 0416/1105
[A[ATraining Step: 84  | total loss: [1m[32m0.69369[0m[0m | time: 13.399s
[2K
| Adam | epoch: 003 | loss: 0.69369 - acc: 0.4898 -- iter: 0448/1105
[A[ATraining Step: 85  | total loss: [1m[32m0.69365[0m[0m | time: 14.535s
[2K
| Adam | epoch: 003 | loss: 0.69365 - acc: 0.4846 -- iter: 0480/1105
[A[ATraining Step: 86  | total loss: [1m[32m0.69356[0m[0m | time: 15.665s
[2K
| Adam | epoch: 003 | loss: 0.69356 - acc: 0.4861 -- iter: 0512/1105
[A[ATraining Step: 87  | total loss: [1m[32m0.69341[0m[0m | time: 16.674s
[2K
| Adam | epoch: 003 | loss: 0.69341 - acc: 0.4937 -- iter: 0544/1105
[A[ATraining Step: 88  | total loss: [1m[32m0.69319[0m[0m | time: 17.624s
[2K
| Adam | epoch: 003 | loss: 0.69319 - acc: 0.5037 -- iter: 0576/1105
[A[ATraining Step: 89  | total loss: [1m[32m0.69326[0m[0m | time: 18.614s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.4971 -- iter: 0608/1105
[A[ATraining Step: 90  | total loss: [1m[32m0.69317[0m[0m | time: 19.678s
[2K
| Adam | epoch: 003 | loss: 0.69317 - acc: 0.4974 -- iter: 0640/1105
[A[ATraining Step: 91  | total loss: [1m[32m0.69310[0m[0m | time: 20.720s
[2K
| Adam | epoch: 003 | loss: 0.69310 - acc: 0.5008 -- iter: 0672/1105
[A[ATraining Step: 92  | total loss: [1m[32m0.69289[0m[0m | time: 21.786s
[2K
| Adam | epoch: 003 | loss: 0.69289 - acc: 0.5070 -- iter: 0704/1105
[A[ATraining Step: 93  | total loss: [1m[32m0.69272[0m[0m | time: 22.819s
[2K
| Adam | epoch: 003 | loss: 0.69272 - acc: 0.5094 -- iter: 0736/1105
[A[ATraining Step: 94  | total loss: [1m[32m0.69273[0m[0m | time: 23.851s
[2K
| Adam | epoch: 003 | loss: 0.69273 - acc: 0.5053 -- iter: 0768/1105
[A[ATraining Step: 95  | total loss: [1m[32m0.69219[0m[0m | time: 24.963s
[2K
| Adam | epoch: 003 | loss: 0.69219 - acc: 0.5173 -- iter: 0800/1105
[A[ATraining Step: 96  | total loss: [1m[32m0.69162[0m[0m | time: 26.125s
[2K
| Adam | epoch: 003 | loss: 0.69162 - acc: 0.5249 -- iter: 0832/1105
[A[ATraining Step: 97  | total loss: [1m[32m0.69200[0m[0m | time: 26.986s
[2K
| Adam | epoch: 003 | loss: 0.69200 - acc: 0.5162 -- iter: 0864/1105
[A[ATraining Step: 98  | total loss: [1m[32m0.69311[0m[0m | time: 27.940s
[2K
| Adam | epoch: 003 | loss: 0.69311 - acc: 0.5021 -- iter: 0896/1105
[A[ATraining Step: 99  | total loss: [1m[32m0.69312[0m[0m | time: 28.921s
[2K
| Adam | epoch: 003 | loss: 0.69312 - acc: 0.4894 -- iter: 0928/1105
[A[ATraining Step: 100  | total loss: [1m[32m0.69304[0m[0m | time: 29.897s
[2K
| Adam | epoch: 003 | loss: 0.69304 - acc: 0.4779 -- iter: 0960/1105
[A[ATraining Step: 101  | total loss: [1m[32m0.69278[0m[0m | time: 30.938s
[2K
| Adam | epoch: 003 | loss: 0.69278 - acc: 0.5020 -- iter: 0992/1105
[A[ATraining Step: 102  | total loss: [1m[32m0.69250[0m[0m | time: 32.067s
[2K
| Adam | epoch: 003 | loss: 0.69250 - acc: 0.5174 -- iter: 1024/1105
[A[ATraining Step: 103  | total loss: [1m[32m0.69259[0m[0m | time: 33.010s
[2K
| Adam | epoch: 003 | loss: 0.69259 - acc: 0.5126 -- iter: 1056/1105
[A[ATraining Step: 104  | total loss: [1m[32m0.69268[0m[0m | time: 34.038s
[2K
| Adam | epoch: 003 | loss: 0.69268 - acc: 0.5082 -- iter: 1088/1105
[A[ATraining Step: 105  | total loss: [1m[32m0.69235[0m[0m | time: 36.987s
[2K
| Adam | epoch: 003 | loss: 0.69235 - acc: 0.5136 | val_loss: 0.68937 - val_acc: 0.5405 -- iter: 1105/1105
--
Training Step: 106  | total loss: [1m[32m0.69313[0m[0m | time: 0.974s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.5029 -- iter: 0032/1105
[A[ATraining Step: 107  | total loss: [1m[32m0.69346[0m[0m | time: 1.582s
[2K
| Adam | epoch: 004 | loss: 0.69346 - acc: 0.4932 -- iter: 0064/1105
[A[ATraining Step: 108  | total loss: [1m[32m0.69313[0m[0m | time: 2.172s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.4968 -- iter: 0096/1105
[A[ATraining Step: 109  | total loss: [1m[32m0.69280[0m[0m | time: 3.176s
[2K
| Adam | epoch: 004 | loss: 0.69280 - acc: 0.5060 -- iter: 0128/1105
[A[ATraining Step: 110  | total loss: [1m[32m0.69279[0m[0m | time: 4.401s
[2K
| Adam | epoch: 004 | loss: 0.69279 - acc: 0.5085 -- iter: 0160/1105
[A[ATraining Step: 111  | total loss: [1m[32m0.69266[0m[0m | time: 5.494s
[2K
| Adam | epoch: 004 | loss: 0.69266 - acc: 0.5170 -- iter: 0192/1105
[A[ATraining Step: 112  | total loss: [1m[32m0.69226[0m[0m | time: 6.366s
[2K
| Adam | epoch: 004 | loss: 0.69226 - acc: 0.5341 -- iter: 0224/1105
[A[ATraining Step: 113  | total loss: [1m[32m0.69123[0m[0m | time: 7.517s
[2K
| Adam | epoch: 004 | loss: 0.69123 - acc: 0.5338 -- iter: 0256/1105
[A[ATraining Step: 114  | total loss: [1m[32m0.68832[0m[0m | time: 8.609s
[2K
| Adam | epoch: 004 | loss: 0.68832 - acc: 0.5429 -- iter: 0288/1105
[A[ATraining Step: 115  | total loss: [1m[32m0.69020[0m[0m | time: 9.599s
[2K
| Adam | epoch: 004 | loss: 0.69020 - acc: 0.5324 -- iter: 0320/1105
[A[ATraining Step: 116  | total loss: [1m[32m0.69114[0m[0m | time: 10.509s
[2K
| Adam | epoch: 004 | loss: 0.69114 - acc: 0.5291 -- iter: 0352/1105
[A[ATraining Step: 117  | total loss: [1m[32m0.68832[0m[0m | time: 11.474s
[2K
| Adam | epoch: 004 | loss: 0.68832 - acc: 0.5231 -- iter: 0384/1105
[A[ATraining Step: 118  | total loss: [1m[32m0.68596[0m[0m | time: 12.436s
[2K
| Adam | epoch: 004 | loss: 0.68596 - acc: 0.5395 -- iter: 0416/1105
[A[ATraining Step: 119  | total loss: [1m[32m0.68738[0m[0m | time: 13.415s
[2K
| Adam | epoch: 004 | loss: 0.68738 - acc: 0.5325 -- iter: 0448/1105
[A[ATraining Step: 120  | total loss: [1m[32m0.68748[0m[0m | time: 14.567s
[2K
| Adam | epoch: 004 | loss: 0.68748 - acc: 0.5355 -- iter: 0480/1105
[A[ATraining Step: 121  | total loss: [1m[32m0.68577[0m[0m | time: 15.576s
[2K
| Adam | epoch: 004 | loss: 0.68577 - acc: 0.5319 -- iter: 0512/1105
[A[ATraining Step: 122  | total loss: [1m[32m0.68521[0m[0m | time: 16.531s
[2K
| Adam | epoch: 004 | loss: 0.68521 - acc: 0.5350 -- iter: 0544/1105
[A[ATraining Step: 123  | total loss: [1m[32m0.68357[0m[0m | time: 17.685s
[2K
| Adam | epoch: 004 | loss: 0.68357 - acc: 0.5346 -- iter: 0576/1105
[A[ATraining Step: 124  | total loss: [1m[32m0.67824[0m[0m | time: 18.811s
[2K
| Adam | epoch: 004 | loss: 0.67824 - acc: 0.5530 -- iter: 0608/1105
[A[ATraining Step: 125  | total loss: [1m[32m0.67609[0m[0m | time: 19.666s
[2K
| Adam | epoch: 004 | loss: 0.67609 - acc: 0.5508 -- iter: 0640/1105
[A[ATraining Step: 126  | total loss: [1m[32m0.67953[0m[0m | time: 20.677s
[2K
| Adam | epoch: 004 | loss: 0.67953 - acc: 0.5426 -- iter: 0672/1105
[A[ATraining Step: 127  | total loss: [1m[32m0.67339[0m[0m | time: 21.658s
[2K
| Adam | epoch: 004 | loss: 0.67339 - acc: 0.5540 -- iter: 0704/1105
[A[ATraining Step: 128  | total loss: [1m[32m0.67288[0m[0m | time: 22.655s
[2K
| Adam | epoch: 004 | loss: 0.67288 - acc: 0.5580 -- iter: 0736/1105
[A[ATraining Step: 129  | total loss: [1m[32m0.67469[0m[0m | time: 23.747s
[2K
| Adam | epoch: 004 | loss: 0.67469 - acc: 0.5584 -- iter: 0768/1105
[A[ATraining Step: 130  | total loss: [1m[32m0.67672[0m[0m | time: 24.801s
[2K
| Adam | epoch: 004 | loss: 0.67672 - acc: 0.5557 -- iter: 0800/1105
[A[ATraining Step: 131  | total loss: [1m[32m0.67879[0m[0m | time: 25.615s
[2K
| Adam | epoch: 004 | loss: 0.67879 - acc: 0.5501 -- iter: 0832/1105
[A[ATraining Step: 132  | total loss: [1m[32m0.67502[0m[0m | time: 26.720s
[2K
| Adam | epoch: 004 | loss: 0.67502 - acc: 0.5545 -- iter: 0864/1105
[A[ATraining Step: 133  | total loss: [1m[32m0.67482[0m[0m | time: 27.943s
[2K
| Adam | epoch: 004 | loss: 0.67482 - acc: 0.5647 -- iter: 0896/1105
[A[ATraining Step: 134  | total loss: [1m[32m0.67663[0m[0m | time: 28.889s
[2K
| Adam | epoch: 004 | loss: 0.67663 - acc: 0.5676 -- iter: 0928/1105
[A[ATraining Step: 135  | total loss: [1m[32m0.67461[0m[0m | time: 29.798s
[2K
| Adam | epoch: 004 | loss: 0.67461 - acc: 0.5827 -- iter: 0960/1105
[A[ATraining Step: 136  | total loss: [1m[32m0.67064[0m[0m | time: 30.820s
[2K
| Adam | epoch: 004 | loss: 0.67064 - acc: 0.5963 -- iter: 0992/1105
[A[ATraining Step: 137  | total loss: [1m[32m0.67729[0m[0m | time: 31.780s
[2K
| Adam | epoch: 004 | loss: 0.67729 - acc: 0.5835 -- iter: 1024/1105
[A[ATraining Step: 138  | total loss: [1m[32m0.67280[0m[0m | time: 32.857s
[2K
| Adam | epoch: 004 | loss: 0.67280 - acc: 0.5846 -- iter: 1056/1105
[A[ATraining Step: 139  | total loss: [1m[32m0.67244[0m[0m | time: 34.011s
[2K
| Adam | epoch: 004 | loss: 0.67244 - acc: 0.5917 -- iter: 1088/1105
[A[ATraining Step: 140  | total loss: [1m[32m0.67160[0m[0m | time: 36.737s
[2K
| Adam | epoch: 004 | loss: 0.67160 - acc: 0.5919 | val_loss: 0.64686 - val_acc: 0.6127 -- iter: 1105/1105
--
Training Step: 141  | total loss: [1m[32m0.66583[0m[0m | time: 1.138s
[2K
| Adam | epoch: 005 | loss: 0.66583 - acc: 0.6046 -- iter: 0032/1105
[A[ATraining Step: 142  | total loss: [1m[32m0.67029[0m[0m | time: 1.968s
[2K
| Adam | epoch: 005 | loss: 0.67029 - acc: 0.5973 -- iter: 0064/1105
[A[ATraining Step: 143  | total loss: [1m[32m0.66854[0m[0m | time: 2.562s
[2K
| Adam | epoch: 005 | loss: 0.66854 - acc: 0.5907 -- iter: 0096/1105
[A[ATraining Step: 144  | total loss: [1m[32m0.66347[0m[0m | time: 3.134s
[2K
| Adam | epoch: 005 | loss: 0.66347 - acc: 0.6081 -- iter: 0128/1105
[A[ATraining Step: 145  | total loss: [1m[32m0.65777[0m[0m | time: 4.128s
[2K
| Adam | epoch: 005 | loss: 0.65777 - acc: 0.6237 -- iter: 0160/1105
[A[ATraining Step: 146  | total loss: [1m[32m0.65694[0m[0m | time: 5.144s
[2K
| Adam | epoch: 005 | loss: 0.65694 - acc: 0.6176 -- iter: 0192/1105
[A[ATraining Step: 147  | total loss: [1m[32m0.65450[0m[0m | time: 6.279s
[2K
| Adam | epoch: 005 | loss: 0.65450 - acc: 0.6277 -- iter: 0224/1105
[A[ATraining Step: 148  | total loss: [1m[32m0.66261[0m[0m | time: 7.361s
[2K
| Adam | epoch: 005 | loss: 0.66261 - acc: 0.6150 -- iter: 0256/1105
[A[ATraining Step: 149  | total loss: [1m[32m0.65782[0m[0m | time: 8.177s
[2K
| Adam | epoch: 005 | loss: 0.65782 - acc: 0.6128 -- iter: 0288/1105
[A[ATraining Step: 150  | total loss: [1m[32m0.65640[0m[0m | time: 9.293s
[2K
| Adam | epoch: 005 | loss: 0.65640 - acc: 0.6078 -- iter: 0320/1105
[A[ATraining Step: 151  | total loss: [1m[32m0.66404[0m[0m | time: 10.437s
[2K
| Adam | epoch: 005 | loss: 0.66404 - acc: 0.5970 -- iter: 0352/1105
[A[ATraining Step: 152  | total loss: [1m[32m0.66200[0m[0m | time: 11.491s
[2K
| Adam | epoch: 005 | loss: 0.66200 - acc: 0.5998 -- iter: 0384/1105
[A[ATraining Step: 153  | total loss: [1m[32m0.65435[0m[0m | time: 12.405s
[2K
| Adam | epoch: 005 | loss: 0.65435 - acc: 0.6117 -- iter: 0416/1105
[A[ATraining Step: 154  | total loss: [1m[32m0.64888[0m[0m | time: 13.419s
[2K
| Adam | epoch: 005 | loss: 0.64888 - acc: 0.6193 -- iter: 0448/1105
[A[ATraining Step: 155  | total loss: [1m[32m0.64188[0m[0m | time: 14.434s
[2K
| Adam | epoch: 005 | loss: 0.64188 - acc: 0.6261 -- iter: 0480/1105
[A[ATraining Step: 156  | total loss: [1m[32m0.63590[0m[0m | time: 15.470s
[2K
| Adam | epoch: 005 | loss: 0.63590 - acc: 0.6354 -- iter: 0512/1105
[A[ATraining Step: 157  | total loss: [1m[32m0.62991[0m[0m | time: 16.683s
[2K
| Adam | epoch: 005 | loss: 0.62991 - acc: 0.6468 -- iter: 0544/1105
[A[ATraining Step: 158  | total loss: [1m[32m0.63282[0m[0m | time: 17.648s
[2K
| Adam | epoch: 005 | loss: 0.63282 - acc: 0.6447 -- iter: 0576/1105
[A[ATraining Step: 159  | total loss: [1m[32m0.62455[0m[0m | time: 18.554s
[2K
| Adam | epoch: 005 | loss: 0.62455 - acc: 0.6552 -- iter: 0608/1105
[A[ATraining Step: 160  | total loss: [1m[32m0.62876[0m[0m | time: 19.649s
[2K
| Adam | epoch: 005 | loss: 0.62876 - acc: 0.6490 -- iter: 0640/1105
[A[ATraining Step: 161  | total loss: [1m[32m0.62402[0m[0m | time: 20.767s
[2K
| Adam | epoch: 005 | loss: 0.62402 - acc: 0.6560 -- iter: 0672/1105
[A[ATraining Step: 162  | total loss: [1m[32m0.61749[0m[0m | time: 21.855s
[2K
| Adam | epoch: 005 | loss: 0.61749 - acc: 0.6654 -- iter: 0704/1105
[A[ATraining Step: 163  | total loss: [1m[32m0.62896[0m[0m | time: 22.970s
[2K
| Adam | epoch: 005 | loss: 0.62896 - acc: 0.6582 -- iter: 0736/1105
[A[ATraining Step: 164  | total loss: [1m[32m0.63211[0m[0m | time: 24.098s
[2K
| Adam | epoch: 005 | loss: 0.63211 - acc: 0.6549 -- iter: 0768/1105
[A[ATraining Step: 165  | total loss: [1m[32m0.62112[0m[0m | time: 25.225s
[2K
| Adam | epoch: 005 | loss: 0.62112 - acc: 0.6707 -- iter: 0800/1105
[A[ATraining Step: 166  | total loss: [1m[32m0.61255[0m[0m | time: 26.343s
[2K
| Adam | epoch: 005 | loss: 0.61255 - acc: 0.6786 -- iter: 0832/1105
[A[ATraining Step: 167  | total loss: [1m[32m0.60565[0m[0m | time: 27.329s
[2K
| Adam | epoch: 005 | loss: 0.60565 - acc: 0.6826 -- iter: 0864/1105
[A[ATraining Step: 168  | total loss: [1m[32m0.60953[0m[0m | time: 28.461s
[2K
| Adam | epoch: 005 | loss: 0.60953 - acc: 0.6737 -- iter: 0896/1105
[A[ATraining Step: 169  | total loss: [1m[32m0.61442[0m[0m | time: 29.413s
[2K
| Adam | epoch: 005 | loss: 0.61442 - acc: 0.6720 -- iter: 0928/1105
[A[ATraining Step: 170  | total loss: [1m[32m0.61920[0m[0m | time: 30.056s
[2K
| Adam | epoch: 005 | loss: 0.61920 - acc: 0.6579 -- iter: 0960/1105
[A[ATraining Step: 171  | total loss: [1m[32m0.61718[0m[0m | time: 30.679s
[2K
| Adam | epoch: 005 | loss: 0.61718 - acc: 0.6609 -- iter: 0992/1105
[A[ATraining Step: 172  | total loss: [1m[32m0.61706[0m[0m | time: 31.325s
[2K
| Adam | epoch: 005 | loss: 0.61706 - acc: 0.6604 -- iter: 1024/1105
[A[ATraining Step: 173  | total loss: [1m[32m0.62750[0m[0m | time: 31.932s
[2K
| Adam | epoch: 005 | loss: 0.62750 - acc: 0.6412 -- iter: 1056/1105
[A[ATraining Step: 174  | total loss: [1m[32m0.62922[0m[0m | time: 32.541s
[2K
| Adam | epoch: 005 | loss: 0.62922 - acc: 0.6427 -- iter: 1088/1105
[A[ATraining Step: 175  | total loss: [1m[32m0.63909[0m[0m | time: 34.277s
[2K
| Adam | epoch: 005 | loss: 0.63909 - acc: 0.6316 | val_loss: 0.67093 - val_acc: 0.6040 -- iter: 1105/1105
--
Training Step: 176  | total loss: [1m[32m0.63602[0m[0m | time: 0.650s
[2K
| Adam | epoch: 006 | loss: 0.63602 - acc: 0.6278 -- iter: 0032/1105
[A[ATraining Step: 177  | total loss: [1m[32m0.63477[0m[0m | time: 1.270s
[2K
| Adam | epoch: 006 | loss: 0.63477 - acc: 0.6244 -- iter: 0064/1105
[A[ATraining Step: 178  | total loss: [1m[32m0.64706[0m[0m | time: 1.890s
[2K
| Adam | epoch: 006 | loss: 0.64706 - acc: 0.6151 -- iter: 0096/1105
[A[ATraining Step: 179  | total loss: [1m[32m0.65041[0m[0m | time: 2.246s
[2K
| Adam | epoch: 006 | loss: 0.65041 - acc: 0.6130 -- iter: 0128/1105
[A[ATraining Step: 180  | total loss: [1m[32m0.65111[0m[0m | time: 2.593s
[2K
| Adam | epoch: 006 | loss: 0.65111 - acc: 0.6046 -- iter: 0160/1105
[A[ATraining Step: 181  | total loss: [1m[32m0.65249[0m[0m | time: 3.201s
[2K
| Adam | epoch: 006 | loss: 0.65249 - acc: 0.6030 -- iter: 0192/1105
[A[ATraining Step: 182  | total loss: [1m[32m0.65259[0m[0m | time: 3.845s
[2K
| Adam | epoch: 006 | loss: 0.65259 - acc: 0.6052 -- iter: 0224/1105
[A[ATraining Step: 183  | total loss: [1m[32m0.65102[0m[0m | time: 4.470s
[2K
| Adam | epoch: 006 | loss: 0.65102 - acc: 0.6165 -- iter: 0256/1105
[A[ATraining Step: 184  | total loss: [1m[32m0.64869[0m[0m | time: 5.101s
[2K
| Adam | epoch: 006 | loss: 0.64869 - acc: 0.6361 -- iter: 0288/1105
[A[ATraining Step: 185  | total loss: [1m[32m0.64713[0m[0m | time: 5.697s
[2K
| Adam | epoch: 006 | loss: 0.64713 - acc: 0.6413 -- iter: 0320/1105
[A[ATraining Step: 186  | total loss: [1m[32m0.64472[0m[0m | time: 6.352s
[2K
| Adam | epoch: 006 | loss: 0.64472 - acc: 0.6428 -- iter: 0352/1105
[A[ATraining Step: 187  | total loss: [1m[32m0.64141[0m[0m | time: 6.946s
[2K
| Adam | epoch: 006 | loss: 0.64141 - acc: 0.6504 -- iter: 0384/1105
[A[ATraining Step: 188  | total loss: [1m[32m0.63340[0m[0m | time: 7.545s
[2K
| Adam | epoch: 006 | loss: 0.63340 - acc: 0.6634 -- iter: 0416/1105
[A[ATraining Step: 189  | total loss: [1m[32m0.63071[0m[0m | time: 8.146s
[2K
| Adam | epoch: 006 | loss: 0.63071 - acc: 0.6659 -- iter: 0448/1105
[A[ATraining Step: 190  | total loss: [1m[32m0.62725[0m[0m | time: 8.748s
[2K
| Adam | epoch: 006 | loss: 0.62725 - acc: 0.6649 -- iter: 0480/1105
[A[ATraining Step: 191  | total loss: [1m[32m0.62486[0m[0m | time: 9.355s
[2K
| Adam | epoch: 006 | loss: 0.62486 - acc: 0.6672 -- iter: 0512/1105
[A[ATraining Step: 192  | total loss: [1m[32m0.62364[0m[0m | time: 9.962s
[2K
| Adam | epoch: 006 | loss: 0.62364 - acc: 0.6629 -- iter: 0544/1105
[A[ATraining Step: 193  | total loss: [1m[32m0.64390[0m[0m | time: 10.592s
[2K
| Adam | epoch: 006 | loss: 0.64390 - acc: 0.6498 -- iter: 0576/1105
[A[ATraining Step: 194  | total loss: [1m[32m0.64780[0m[0m | time: 11.202s
[2K
| Adam | epoch: 006 | loss: 0.64780 - acc: 0.6535 -- iter: 0608/1105
[A[ATraining Step: 195  | total loss: [1m[32m0.64290[0m[0m | time: 11.827s
[2K
| Adam | epoch: 006 | loss: 0.64290 - acc: 0.6601 -- iter: 0640/1105
[A[ATraining Step: 196  | total loss: [1m[32m0.63648[0m[0m | time: 12.434s
[2K
| Adam | epoch: 006 | loss: 0.63648 - acc: 0.6628 -- iter: 0672/1105
[A[ATraining Step: 197  | total loss: [1m[32m0.62494[0m[0m | time: 13.051s
[2K
| Adam | epoch: 006 | loss: 0.62494 - acc: 0.6778 -- iter: 0704/1105
[A[ATraining Step: 198  | total loss: [1m[32m0.63311[0m[0m | time: 13.692s
[2K
| Adam | epoch: 006 | loss: 0.63311 - acc: 0.6662 -- iter: 0736/1105
[A[ATraining Step: 199  | total loss: [1m[32m0.61951[0m[0m | time: 14.330s
[2K
| Adam | epoch: 006 | loss: 0.61951 - acc: 0.6715 -- iter: 0768/1105
[A[ATraining Step: 200  | total loss: [1m[32m0.60834[0m[0m | time: 16.091s
[2K
| Adam | epoch: 006 | loss: 0.60834 - acc: 0.6793 | val_loss: 0.61058 - val_acc: 0.6705 -- iter: 0800/1105
--
Training Step: 201  | total loss: [1m[32m0.60826[0m[0m | time: 16.693s
[2K
| Adam | epoch: 006 | loss: 0.60826 - acc: 0.6770 -- iter: 0832/1105
[A[ATraining Step: 202  | total loss: [1m[32m0.59625[0m[0m | time: 17.305s
[2K
| Adam | epoch: 006 | loss: 0.59625 - acc: 0.6937 -- iter: 0864/1105
[A[ATraining Step: 203  | total loss: [1m[32m0.60962[0m[0m | time: 17.950s
[2K
| Adam | epoch: 006 | loss: 0.60962 - acc: 0.6775 -- iter: 0896/1105
[A[ATraining Step: 204  | total loss: [1m[32m0.60810[0m[0m | time: 18.553s
[2K
| Adam | epoch: 006 | loss: 0.60810 - acc: 0.6722 -- iter: 0928/1105
[A[ATraining Step: 205  | total loss: [1m[32m0.60364[0m[0m | time: 19.164s
[2K
| Adam | epoch: 006 | loss: 0.60364 - acc: 0.6862 -- iter: 0960/1105
[A[ATraining Step: 206  | total loss: [1m[32m0.59506[0m[0m | time: 19.782s
[2K
| Adam | epoch: 006 | loss: 0.59506 - acc: 0.6957 -- iter: 0992/1105
[A[ATraining Step: 207  | total loss: [1m[32m0.58501[0m[0m | time: 20.416s
[2K
| Adam | epoch: 006 | loss: 0.58501 - acc: 0.7074 -- iter: 1024/1105
[A[ATraining Step: 208  | total loss: [1m[32m0.58051[0m[0m | time: 21.176s
[2K
| Adam | epoch: 006 | loss: 0.58051 - acc: 0.7117 -- iter: 1056/1105
[A[ATraining Step: 209  | total loss: [1m[32m0.56505[0m[0m | time: 22.210s
[2K
| Adam | epoch: 006 | loss: 0.56505 - acc: 0.7218 -- iter: 1088/1105
[A[ATraining Step: 210  | total loss: [1m[32m0.56390[0m[0m | time: 24.755s
[2K
| Adam | epoch: 006 | loss: 0.56390 - acc: 0.7277 | val_loss: 0.54322 - val_acc: 0.7312 -- iter: 1105/1105
--
Training Step: 211  | total loss: [1m[32m0.57034[0m[0m | time: 0.994s
[2K
| Adam | epoch: 007 | loss: 0.57034 - acc: 0.7143 -- iter: 0032/1105
[A[ATraining Step: 212  | total loss: [1m[32m0.56151[0m[0m | time: 1.858s
[2K
| Adam | epoch: 007 | loss: 0.56151 - acc: 0.7210 -- iter: 0064/1105
[A[ATraining Step: 213  | total loss: [1m[32m0.54854[0m[0m | time: 2.909s
[2K
| Adam | epoch: 007 | loss: 0.54854 - acc: 0.7302 -- iter: 0096/1105
[A[ATraining Step: 214  | total loss: [1m[32m0.54068[0m[0m | time: 3.930s
[2K
| Adam | epoch: 007 | loss: 0.54068 - acc: 0.7384 -- iter: 0128/1105
[A[ATraining Step: 215  | total loss: [1m[32m0.54295[0m[0m | time: 4.438s
[2K
| Adam | epoch: 007 | loss: 0.54295 - acc: 0.7396 -- iter: 0160/1105
[A[ATraining Step: 216  | total loss: [1m[32m0.56459[0m[0m | time: 4.996s
[2K
| Adam | epoch: 007 | loss: 0.56459 - acc: 0.7244 -- iter: 0192/1105
[A[ATraining Step: 217  | total loss: [1m[32m0.57589[0m[0m | time: 5.912s
[2K
| Adam | epoch: 007 | loss: 0.57589 - acc: 0.7167 -- iter: 0224/1105
[A[ATraining Step: 218  | total loss: [1m[32m0.57524[0m[0m | time: 6.887s
[2K
| Adam | epoch: 007 | loss: 0.57524 - acc: 0.7169 -- iter: 0256/1105
[A[ATraining Step: 219  | total loss: [1m[32m0.56677[0m[0m | time: 7.813s
[2K
| Adam | epoch: 007 | loss: 0.56677 - acc: 0.7140 -- iter: 0288/1105
[A[ATraining Step: 220  | total loss: [1m[32m0.56270[0m[0m | time: 8.897s
[2K
| Adam | epoch: 007 | loss: 0.56270 - acc: 0.7269 -- iter: 0320/1105
[A[ATraining Step: 221  | total loss: [1m[32m0.55270[0m[0m | time: 10.005s
[2K
| Adam | epoch: 007 | loss: 0.55270 - acc: 0.7324 -- iter: 0352/1105
[A[ATraining Step: 222  | total loss: [1m[32m0.53513[0m[0m | time: 10.924s
[2K
| Adam | epoch: 007 | loss: 0.53513 - acc: 0.7404 -- iter: 0384/1105
[A[ATraining Step: 223  | total loss: [1m[32m0.53958[0m[0m | time: 11.866s
[2K
| Adam | epoch: 007 | loss: 0.53958 - acc: 0.7351 -- iter: 0416/1105
[A[ATraining Step: 224  | total loss: [1m[32m0.53351[0m[0m | time: 12.847s
[2K
| Adam | epoch: 007 | loss: 0.53351 - acc: 0.7366 -- iter: 0448/1105
[A[ATraining Step: 225  | total loss: [1m[32m0.53015[0m[0m | time: 13.845s
[2K
| Adam | epoch: 007 | loss: 0.53015 - acc: 0.7379 -- iter: 0480/1105
[A[ATraining Step: 226  | total loss: [1m[32m0.52404[0m[0m | time: 14.923s
[2K
| Adam | epoch: 007 | loss: 0.52404 - acc: 0.7391 -- iter: 0512/1105
[A[ATraining Step: 227  | total loss: [1m[32m0.54347[0m[0m | time: 16.078s
[2K
| Adam | epoch: 007 | loss: 0.54347 - acc: 0.7183 -- iter: 0544/1105
[A[ATraining Step: 228  | total loss: [1m[32m0.52469[0m[0m | time: 16.944s
[2K
| Adam | epoch: 007 | loss: 0.52469 - acc: 0.7371 -- iter: 0576/1105
[A[ATraining Step: 229  | total loss: [1m[32m0.52578[0m[0m | time: 18.060s
[2K
| Adam | epoch: 007 | loss: 0.52578 - acc: 0.7384 -- iter: 0608/1105
[A[ATraining Step: 230  | total loss: [1m[32m0.52204[0m[0m | time: 19.169s
[2K
| Adam | epoch: 007 | loss: 0.52204 - acc: 0.7365 -- iter: 0640/1105
[A[ATraining Step: 231  | total loss: [1m[32m0.51743[0m[0m | time: 20.152s
[2K
| Adam | epoch: 007 | loss: 0.51743 - acc: 0.7409 -- iter: 0672/1105
[A[ATraining Step: 232  | total loss: [1m[32m0.52083[0m[0m | time: 21.060s
[2K
| Adam | epoch: 007 | loss: 0.52083 - acc: 0.7293 -- iter: 0704/1105
[A[ATraining Step: 233  | total loss: [1m[32m0.50832[0m[0m | time: 22.055s
[2K
| Adam | epoch: 007 | loss: 0.50832 - acc: 0.7439 -- iter: 0736/1105
[A[ATraining Step: 234  | total loss: [1m[32m0.51308[0m[0m | time: 23.031s
[2K
| Adam | epoch: 007 | loss: 0.51308 - acc: 0.7383 -- iter: 0768/1105
[A[ATraining Step: 235  | total loss: [1m[32m0.51982[0m[0m | time: 24.059s
[2K
| Adam | epoch: 007 | loss: 0.51982 - acc: 0.7301 -- iter: 0800/1105
[A[ATraining Step: 236  | total loss: [1m[32m0.52038[0m[0m | time: 25.131s
[2K
| Adam | epoch: 007 | loss: 0.52038 - acc: 0.7289 -- iter: 0832/1105
[A[ATraining Step: 237  | total loss: [1m[32m0.51409[0m[0m | time: 26.189s
[2K
| Adam | epoch: 007 | loss: 0.51409 - acc: 0.7342 -- iter: 0864/1105
[A[ATraining Step: 238  | total loss: [1m[32m0.50386[0m[0m | time: 27.049s
[2K
| Adam | epoch: 007 | loss: 0.50386 - acc: 0.7482 -- iter: 0896/1105
[A[ATraining Step: 239  | total loss: [1m[32m0.50497[0m[0m | time: 28.107s
[2K
| Adam | epoch: 007 | loss: 0.50497 - acc: 0.7515 -- iter: 0928/1105
[A[ATraining Step: 240  | total loss: [1m[32m0.49933[0m[0m | time: 29.259s
[2K
| Adam | epoch: 007 | loss: 0.49933 - acc: 0.7514 -- iter: 0960/1105
[A[ATraining Step: 241  | total loss: [1m[32m0.48427[0m[0m | time: 30.204s
[2K
| Adam | epoch: 007 | loss: 0.48427 - acc: 0.7606 -- iter: 0992/1105
[A[ATraining Step: 242  | total loss: [1m[32m0.50807[0m[0m | time: 31.177s
[2K
| Adam | epoch: 007 | loss: 0.50807 - acc: 0.7471 -- iter: 1024/1105
[A[ATraining Step: 243  | total loss: [1m[32m0.50167[0m[0m | time: 32.208s
[2K
| Adam | epoch: 007 | loss: 0.50167 - acc: 0.7442 -- iter: 1056/1105
[A[ATraining Step: 244  | total loss: [1m[32m0.50055[0m[0m | time: 33.219s
[2K
| Adam | epoch: 007 | loss: 0.50055 - acc: 0.7448 -- iter: 1088/1105
[A[ATraining Step: 245  | total loss: [1m[32m0.48779[0m[0m | time: 36.288s
[2K
| Adam | epoch: 007 | loss: 0.48779 - acc: 0.7578 | val_loss: 0.50877 - val_acc: 0.7717 -- iter: 1105/1105
--
Training Step: 246  | total loss: [1m[32m0.48267[0m[0m | time: 1.037s
[2K
| Adam | epoch: 008 | loss: 0.48267 - acc: 0.7602 -- iter: 0032/1105
[A[ATraining Step: 247  | total loss: [1m[32m0.47973[0m[0m | time: 2.092s
[2K
| Adam | epoch: 008 | loss: 0.47973 - acc: 0.7654 -- iter: 0064/1105
[A[ATraining Step: 248  | total loss: [1m[32m0.46368[0m[0m | time: 3.229s
[2K
| Adam | epoch: 008 | loss: 0.46368 - acc: 0.7795 -- iter: 0096/1105
[A[ATraining Step: 249  | total loss: [1m[32m0.45374[0m[0m | time: 4.094s
[2K
| Adam | epoch: 008 | loss: 0.45374 - acc: 0.7890 -- iter: 0128/1105
[A[ATraining Step: 250  | total loss: [1m[32m0.44630[0m[0m | time: 5.048s
[2K
| Adam | epoch: 008 | loss: 0.44630 - acc: 0.7976 -- iter: 0160/1105
[A[ATraining Step: 251  | total loss: [1m[32m0.46035[0m[0m | time: 5.608s
[2K
| Adam | epoch: 008 | loss: 0.46035 - acc: 0.7866 -- iter: 0192/1105
[A[ATraining Step: 252  | total loss: [1m[32m0.46809[0m[0m | time: 6.176s
[2K
| Adam | epoch: 008 | loss: 0.46809 - acc: 0.7903 -- iter: 0224/1105
[A[ATraining Step: 253  | total loss: [1m[32m0.47611[0m[0m | time: 7.184s
[2K
| Adam | epoch: 008 | loss: 0.47611 - acc: 0.7936 -- iter: 0256/1105
[A[ATraining Step: 254  | total loss: [1m[32m0.45804[0m[0m | time: 8.369s
[2K
| Adam | epoch: 008 | loss: 0.45804 - acc: 0.7986 -- iter: 0288/1105
[A[ATraining Step: 255  | total loss: [1m[32m0.47085[0m[0m | time: 9.463s
[2K
| Adam | epoch: 008 | loss: 0.47085 - acc: 0.7907 -- iter: 0320/1105
[A[ATraining Step: 256  | total loss: [1m[32m0.48409[0m[0m | time: 10.291s
[2K
| Adam | epoch: 008 | loss: 0.48409 - acc: 0.7897 -- iter: 0352/1105
[A[ATraining Step: 257  | total loss: [1m[32m0.48250[0m[0m | time: 11.387s
[2K
| Adam | epoch: 008 | loss: 0.48250 - acc: 0.7857 -- iter: 0384/1105
[A[ATraining Step: 258  | total loss: [1m[32m0.46440[0m[0m | time: 12.545s
[2K
| Adam | epoch: 008 | loss: 0.46440 - acc: 0.7947 -- iter: 0416/1105
[A[ATraining Step: 259  | total loss: [1m[32m0.45702[0m[0m | time: 13.553s
[2K
| Adam | epoch: 008 | loss: 0.45702 - acc: 0.7996 -- iter: 0448/1105
[A[ATraining Step: 260  | total loss: [1m[32m0.45426[0m[0m | time: 14.459s
[2K
| Adam | epoch: 008 | loss: 0.45426 - acc: 0.7946 -- iter: 0480/1105
[A[ATraining Step: 261  | total loss: [1m[32m0.46774[0m[0m | time: 15.536s
[2K
| Adam | epoch: 008 | loss: 0.46774 - acc: 0.7777 -- iter: 0512/1105
[A[ATraining Step: 262  | total loss: [1m[32m0.46263[0m[0m | time: 16.558s
[2K
| Adam | epoch: 008 | loss: 0.46263 - acc: 0.7811 -- iter: 0544/1105
[A[ATraining Step: 263  | total loss: [1m[32m0.45597[0m[0m | time: 17.583s
[2K
| Adam | epoch: 008 | loss: 0.45597 - acc: 0.7843 -- iter: 0576/1105
[A[ATraining Step: 264  | total loss: [1m[32m0.44394[0m[0m | time: 18.826s
[2K
| Adam | epoch: 008 | loss: 0.44394 - acc: 0.7934 -- iter: 0608/1105
[A[ATraining Step: 265  | total loss: [1m[32m0.45992[0m[0m | time: 19.798s
[2K
| Adam | epoch: 008 | loss: 0.45992 - acc: 0.7765 -- iter: 0640/1105
[A[ATraining Step: 266  | total loss: [1m[32m0.45688[0m[0m | time: 20.767s
[2K
| Adam | epoch: 008 | loss: 0.45688 - acc: 0.7801 -- iter: 0672/1105
[A[ATraining Step: 267  | total loss: [1m[32m0.44869[0m[0m | time: 21.876s
[2K
| Adam | epoch: 008 | loss: 0.44869 - acc: 0.7865 -- iter: 0704/1105
[A[ATraining Step: 268  | total loss: [1m[32m0.45011[0m[0m | time: 22.950s
[2K
| Adam | epoch: 008 | loss: 0.45011 - acc: 0.7860 -- iter: 0736/1105
[A[ATraining Step: 269  | total loss: [1m[32m0.45902[0m[0m | time: 23.796s
[2K
| Adam | epoch: 008 | loss: 0.45902 - acc: 0.7886 -- iter: 0768/1105
[A[ATraining Step: 270  | total loss: [1m[32m0.45226[0m[0m | time: 24.750s
[2K
| Adam | epoch: 008 | loss: 0.45226 - acc: 0.7816 -- iter: 0800/1105
[A[ATraining Step: 271  | total loss: [1m[32m0.44976[0m[0m | time: 25.737s
[2K
| Adam | epoch: 008 | loss: 0.44976 - acc: 0.7785 -- iter: 0832/1105
[A[ATraining Step: 272  | total loss: [1m[32m0.44484[0m[0m | time: 26.636s
[2K
| Adam | epoch: 008 | loss: 0.44484 - acc: 0.7819 -- iter: 0864/1105
[A[ATraining Step: 273  | total loss: [1m[32m0.43162[0m[0m | time: 27.750s
[2K
| Adam | epoch: 008 | loss: 0.43162 - acc: 0.7974 -- iter: 0896/1105
[A[ATraining Step: 274  | total loss: [1m[32m0.44179[0m[0m | time: 28.871s
[2K
| Adam | epoch: 008 | loss: 0.44179 - acc: 0.7927 -- iter: 0928/1105
[A[ATraining Step: 275  | total loss: [1m[32m0.44741[0m[0m | time: 29.821s
[2K
| Adam | epoch: 008 | loss: 0.44741 - acc: 0.7915 -- iter: 0960/1105
[A[ATraining Step: 276  | total loss: [1m[32m0.43673[0m[0m | time: 30.765s
[2K
| Adam | epoch: 008 | loss: 0.43673 - acc: 0.7999 -- iter: 0992/1105
[A[ATraining Step: 277  | total loss: [1m[32m0.44446[0m[0m | time: 31.847s
[2K
| Adam | epoch: 008 | loss: 0.44446 - acc: 0.8011 -- iter: 1024/1105
[A[ATraining Step: 278  | total loss: [1m[32m0.42631[0m[0m | time: 33.033s
[2K
| Adam | epoch: 008 | loss: 0.42631 - acc: 0.8117 -- iter: 1056/1105
[A[ATraining Step: 279  | total loss: [1m[32m0.42862[0m[0m | time: 33.848s
[2K
| Adam | epoch: 008 | loss: 0.42862 - acc: 0.8117 -- iter: 1088/1105
[A[ATraining Step: 280  | total loss: [1m[32m0.41347[0m[0m | time: 36.666s
[2K
| Adam | epoch: 008 | loss: 0.41347 - acc: 0.8243 | val_loss: 0.49512 - val_acc: 0.7890 -- iter: 1105/1105
--
Training Step: 281  | total loss: [1m[32m0.39063[0m[0m | time: 1.078s
[2K
| Adam | epoch: 009 | loss: 0.39063 - acc: 0.8419 -- iter: 0032/1105
[A[ATraining Step: 282  | total loss: [1m[32m0.38286[0m[0m | time: 2.160s
[2K
| Adam | epoch: 009 | loss: 0.38286 - acc: 0.8483 -- iter: 0064/1105
[A[ATraining Step: 283  | total loss: [1m[32m0.38360[0m[0m | time: 3.040s
[2K
| Adam | epoch: 009 | loss: 0.38360 - acc: 0.8479 -- iter: 0096/1105
[A[ATraining Step: 284  | total loss: [1m[32m0.37305[0m[0m | time: 4.047s
[2K
| Adam | epoch: 009 | loss: 0.37305 - acc: 0.8506 -- iter: 0128/1105
[A[ATraining Step: 285  | total loss: [1m[32m0.37892[0m[0m | time: 5.142s
[2K
| Adam | epoch: 009 | loss: 0.37892 - acc: 0.8468 -- iter: 0160/1105
[A[ATraining Step: 286  | total loss: [1m[32m0.37966[0m[0m | time: 6.117s
[2K
| Adam | epoch: 009 | loss: 0.37966 - acc: 0.8496 -- iter: 0192/1105
[A[ATraining Step: 287  | total loss: [1m[32m0.36999[0m[0m | time: 6.618s
[2K
| Adam | epoch: 009 | loss: 0.36999 - acc: 0.8553 -- iter: 0224/1105
[A[ATraining Step: 288  | total loss: [1m[32m0.38339[0m[0m | time: 7.117s
[2K
| Adam | epoch: 009 | loss: 0.38339 - acc: 0.8521 -- iter: 0256/1105
[A[ATraining Step: 289  | total loss: [1m[32m0.38512[0m[0m | time: 8.059s
[2K
| Adam | epoch: 009 | loss: 0.38512 - acc: 0.8433 -- iter: 0288/1105
[A[ATraining Step: 290  | total loss: [1m[32m0.39467[0m[0m | time: 9.088s
[2K
| Adam | epoch: 009 | loss: 0.39467 - acc: 0.8403 -- iter: 0320/1105
[A[ATraining Step: 291  | total loss: [1m[32m0.40823[0m[0m | time: 10.059s
[2K
| Adam | epoch: 009 | loss: 0.40823 - acc: 0.8219 -- iter: 0352/1105
[A[ATraining Step: 292  | total loss: [1m[32m0.42020[0m[0m | time: 11.186s
[2K
| Adam | epoch: 009 | loss: 0.42020 - acc: 0.8178 -- iter: 0384/1105
[A[ATraining Step: 293  | total loss: [1m[32m0.42998[0m[0m | time: 12.266s
[2K
| Adam | epoch: 009 | loss: 0.42998 - acc: 0.8173 -- iter: 0416/1105
[A[ATraining Step: 294  | total loss: [1m[32m0.43400[0m[0m | time: 13.103s
[2K
| Adam | epoch: 009 | loss: 0.43400 - acc: 0.8137 -- iter: 0448/1105
[A[ATraining Step: 295  | total loss: [1m[32m0.45406[0m[0m | time: 14.220s
[2K
| Adam | epoch: 009 | loss: 0.45406 - acc: 0.8042 -- iter: 0480/1105
[A[ATraining Step: 296  | total loss: [1m[32m0.43740[0m[0m | time: 15.304s
[2K
| Adam | epoch: 009 | loss: 0.43740 - acc: 0.8113 -- iter: 0512/1105
[A[ATraining Step: 297  | total loss: [1m[32m0.42198[0m[0m | time: 16.304s
[2K
| Adam | epoch: 009 | loss: 0.42198 - acc: 0.8176 -- iter: 0544/1105
[A[ATraining Step: 298  | total loss: [1m[32m0.40696[0m[0m | time: 17.218s
[2K
| Adam | epoch: 009 | loss: 0.40696 - acc: 0.8296 -- iter: 0576/1105
[A[ATraining Step: 299  | total loss: [1m[32m0.39967[0m[0m | time: 18.210s
[2K
| Adam | epoch: 009 | loss: 0.39967 - acc: 0.8279 -- iter: 0608/1105
[A[ATraining Step: 300  | total loss: [1m[32m0.41317[0m[0m | time: 19.201s
[2K
| Adam | epoch: 009 | loss: 0.41317 - acc: 0.8201 -- iter: 0640/1105
[A[ATraining Step: 301  | total loss: [1m[32m0.41467[0m[0m | time: 20.242s
[2K
| Adam | epoch: 009 | loss: 0.41467 - acc: 0.8131 -- iter: 0672/1105
[A[ATraining Step: 302  | total loss: [1m[32m0.40384[0m[0m | time: 21.378s
[2K
| Adam | epoch: 009 | loss: 0.40384 - acc: 0.8224 -- iter: 0704/1105
[A[ATraining Step: 303  | total loss: [1m[32m0.40818[0m[0m | time: 22.301s
[2K
| Adam | epoch: 009 | loss: 0.40818 - acc: 0.8152 -- iter: 0736/1105
[A[ATraining Step: 304  | total loss: [1m[32m0.41275[0m[0m | time: 23.279s
[2K
| Adam | epoch: 009 | loss: 0.41275 - acc: 0.8118 -- iter: 0768/1105
[A[ATraining Step: 305  | total loss: [1m[32m0.40098[0m[0m | time: 24.377s
[2K
| Adam | epoch: 009 | loss: 0.40098 - acc: 0.8181 -- iter: 0800/1105
[A[ATraining Step: 306  | total loss: [1m[32m0.38342[0m[0m | time: 25.452s
[2K
| Adam | epoch: 009 | loss: 0.38342 - acc: 0.8269 -- iter: 0832/1105
[A[ATraining Step: 307  | total loss: [1m[32m0.39316[0m[0m | time: 26.331s
[2K
| Adam | epoch: 009 | loss: 0.39316 - acc: 0.8224 -- iter: 0864/1105
[A[ATraining Step: 308  | total loss: [1m[32m0.38668[0m[0m | time: 27.242s
[2K
| Adam | epoch: 009 | loss: 0.38668 - acc: 0.8307 -- iter: 0896/1105
[A[ATraining Step: 309  | total loss: [1m[32m0.37848[0m[0m | time: 28.205s
[2K
| Adam | epoch: 009 | loss: 0.37848 - acc: 0.8383 -- iter: 0928/1105
[A[ATraining Step: 310  | total loss: [1m[32m0.37266[0m[0m | time: 29.212s
[2K
| Adam | epoch: 009 | loss: 0.37266 - acc: 0.8388 -- iter: 0960/1105
[A[ATraining Step: 311  | total loss: [1m[32m0.37867[0m[0m | time: 30.283s
[2K
| Adam | epoch: 009 | loss: 0.37867 - acc: 0.8331 -- iter: 0992/1105
[A[ATraining Step: 312  | total loss: [1m[32m0.38447[0m[0m | time: 31.417s
[2K
| Adam | epoch: 009 | loss: 0.38447 - acc: 0.8310 -- iter: 1024/1105
[A[ATraining Step: 313  | total loss: [1m[32m0.38430[0m[0m | time: 32.338s
[2K
| Adam | epoch: 009 | loss: 0.38430 - acc: 0.8354 -- iter: 1056/1105
[A[ATraining Step: 314  | total loss: [1m[32m0.36870[0m[0m | time: 33.347s
[2K
| Adam | epoch: 009 | loss: 0.36870 - acc: 0.8425 -- iter: 1088/1105
[A[ATraining Step: 315  | total loss: [1m[32m0.34866[0m[0m | time: 36.271s
[2K
| Adam | epoch: 009 | loss: 0.34866 - acc: 0.8551 | val_loss: 0.54737 - val_acc: 0.7543 -- iter: 1105/1105
--
Training Step: 316  | total loss: [1m[32m0.36710[0m[0m | time: 0.921s
[2K
| Adam | epoch: 010 | loss: 0.36710 - acc: 0.8446 -- iter: 0032/1105
[A[ATraining Step: 317  | total loss: [1m[32m0.36922[0m[0m | time: 1.944s
[2K
| Adam | epoch: 010 | loss: 0.36922 - acc: 0.8414 -- iter: 0064/1105
[A[ATraining Step: 318  | total loss: [1m[32m0.36664[0m[0m | time: 2.909s
[2K
| Adam | epoch: 010 | loss: 0.36664 - acc: 0.8354 -- iter: 0096/1105
[A[ATraining Step: 319  | total loss: [1m[32m0.38229[0m[0m | time: 3.922s
[2K
| Adam | epoch: 010 | loss: 0.38229 - acc: 0.8331 -- iter: 0128/1105
[A[ATraining Step: 320  | total loss: [1m[32m0.38579[0m[0m | time: 5.022s
[2K
| Adam | epoch: 010 | loss: 0.38579 - acc: 0.8373 -- iter: 0160/1105
[A[ATraining Step: 321  | total loss: [1m[32m0.38598[0m[0m | time: 6.003s
[2K
| Adam | epoch: 010 | loss: 0.38598 - acc: 0.8379 -- iter: 0192/1105
[A[ATraining Step: 322  | total loss: [1m[32m0.37322[0m[0m | time: 6.987s
[2K
| Adam | epoch: 010 | loss: 0.37322 - acc: 0.8479 -- iter: 0224/1105
[A[ATraining Step: 323  | total loss: [1m[32m0.36330[0m[0m | time: 7.606s
[2K
| Adam | epoch: 010 | loss: 0.36330 - acc: 0.8569 -- iter: 0256/1105
[A[ATraining Step: 324  | total loss: [1m[32m0.35200[0m[0m | time: 8.246s
[2K
| Adam | epoch: 010 | loss: 0.35200 - acc: 0.8653 -- iter: 0288/1105
[A[ATraining Step: 325  | total loss: [1m[32m0.34100[0m[0m | time: 9.406s
[2K
| Adam | epoch: 010 | loss: 0.34100 - acc: 0.8729 -- iter: 0320/1105
[A[ATraining Step: 326  | total loss: [1m[32m0.34511[0m[0m | time: 10.280s
[2K
| Adam | epoch: 010 | loss: 0.34511 - acc: 0.8700 -- iter: 0352/1105
[A[ATraining Step: 327  | total loss: [1m[32m0.33730[0m[0m | time: 11.187s
[2K
| Adam | epoch: 010 | loss: 0.33730 - acc: 0.8705 -- iter: 0384/1105
[A[ATraining Step: 328  | total loss: [1m[32m0.33478[0m[0m | time: 12.152s
[2K
| Adam | epoch: 010 | loss: 0.33478 - acc: 0.8740 -- iter: 0416/1105
[A[ATraining Step: 329  | total loss: [1m[32m0.33078[0m[0m | time: 13.167s
[2K
| Adam | epoch: 010 | loss: 0.33078 - acc: 0.8773 -- iter: 0448/1105
[A[ATraining Step: 330  | total loss: [1m[32m0.32439[0m[0m | time: 14.253s
[2K
| Adam | epoch: 010 | loss: 0.32439 - acc: 0.8770 -- iter: 0480/1105
[A[ATraining Step: 331  | total loss: [1m[32m0.31896[0m[0m | time: 15.473s
[2K
| Adam | epoch: 010 | loss: 0.31896 - acc: 0.8768 -- iter: 0512/1105
[A[ATraining Step: 332  | total loss: [1m[32m0.32142[0m[0m | time: 16.342s
[2K
| Adam | epoch: 010 | loss: 0.32142 - acc: 0.8798 -- iter: 0544/1105
[A[ATraining Step: 333  | total loss: [1m[32m0.30438[0m[0m | time: 17.393s
[2K
| Adam | epoch: 010 | loss: 0.30438 - acc: 0.8887 -- iter: 0576/1105
[A[ATraining Step: 334  | total loss: [1m[32m0.29017[0m[0m | time: 18.517s
[2K
| Adam | epoch: 010 | loss: 0.29017 - acc: 0.8967 -- iter: 0608/1105
[A[ATraining Step: 335  | total loss: [1m[32m0.27855[0m[0m | time: 19.559s
[2K
| Adam | epoch: 010 | loss: 0.27855 - acc: 0.9008 -- iter: 0640/1105
[A[ATraining Step: 336  | total loss: [1m[32m0.27052[0m[0m | time: 20.450s
[2K
| Adam | epoch: 010 | loss: 0.27052 - acc: 0.9044 -- iter: 0672/1105
[A[ATraining Step: 337  | total loss: [1m[32m0.25695[0m[0m | time: 21.406s
[2K
| Adam | epoch: 010 | loss: 0.25695 - acc: 0.9077 -- iter: 0704/1105
[A[ATraining Step: 338  | total loss: [1m[32m0.24637[0m[0m | time: 22.336s
[2K
| Adam | epoch: 010 | loss: 0.24637 - acc: 0.9107 -- iter: 0736/1105
[A[ATraining Step: 339  | total loss: [1m[32m0.23155[0m[0m | time: 23.324s
[2K
| Adam | epoch: 010 | loss: 0.23155 - acc: 0.9196 -- iter: 0768/1105
[A[ATraining Step: 340  | total loss: [1m[32m0.24874[0m[0m | time: 24.406s
[2K
| Adam | epoch: 010 | loss: 0.24874 - acc: 0.9058 -- iter: 0800/1105
[A[ATraining Step: 341  | total loss: [1m[32m0.23889[0m[0m | time: 25.537s
[2K
| Adam | epoch: 010 | loss: 0.23889 - acc: 0.9121 -- iter: 0832/1105
[A[ATraining Step: 342  | total loss: [1m[32m0.25482[0m[0m | time: 26.379s
[2K
| Adam | epoch: 010 | loss: 0.25482 - acc: 0.9084 -- iter: 0864/1105
[A[ATraining Step: 343  | total loss: [1m[32m0.24589[0m[0m | time: 27.479s
[2K
| Adam | epoch: 010 | loss: 0.24589 - acc: 0.9113 -- iter: 0896/1105
[A[ATraining Step: 344  | total loss: [1m[32m0.24740[0m[0m | time: 28.699s
[2K
| Adam | epoch: 010 | loss: 0.24740 - acc: 0.9077 -- iter: 0928/1105
[A[ATraining Step: 345  | total loss: [1m[32m0.26683[0m[0m | time: 29.663s
[2K
| Adam | epoch: 010 | loss: 0.26683 - acc: 0.8982 -- iter: 0960/1105
[A[ATraining Step: 346  | total loss: [1m[32m0.26068[0m[0m | time: 30.525s
[2K
| Adam | epoch: 010 | loss: 0.26068 - acc: 0.8990 -- iter: 0992/1105
[A[ATraining Step: 347  | total loss: [1m[32m0.24698[0m[0m | time: 31.446s
[2K
| Adam | epoch: 010 | loss: 0.24698 - acc: 0.9059 -- iter: 1024/1105
[A[ATraining Step: 348  | total loss: [1m[32m0.26359[0m[0m | time: 32.429s
[2K
| Adam | epoch: 010 | loss: 0.26359 - acc: 0.8997 -- iter: 1056/1105
[A[ATraining Step: 349  | total loss: [1m[32m0.25815[0m[0m | time: 33.478s
[2K
| Adam | epoch: 010 | loss: 0.25815 - acc: 0.9004 -- iter: 1088/1105
[A[ATraining Step: 350  | total loss: [1m[32m0.24461[0m[0m | time: 36.532s
[2K
| Adam | epoch: 010 | loss: 0.24461 - acc: 0.9103 | val_loss: 0.55602 - val_acc: 0.7688 -- iter: 1105/1105
--
Training Step: 351  | total loss: [1m[32m0.24723[0m[0m | time: 1.139s
[2K
| Adam | epoch: 011 | loss: 0.24723 - acc: 0.9131 -- iter: 0032/1105
[A[ATraining Step: 352  | total loss: [1m[32m0.25092[0m[0m | time: 2.297s
[2K
| Adam | epoch: 011 | loss: 0.25092 - acc: 0.9124 -- iter: 0064/1105
[A[ATraining Step: 353  | total loss: [1m[32m0.24957[0m[0m | time: 3.255s
[2K
| Adam | epoch: 011 | loss: 0.24957 - acc: 0.9118 -- iter: 0096/1105
[A[ATraining Step: 354  | total loss: [1m[32m0.24288[0m[0m | time: 4.217s
[2K
| Adam | epoch: 011 | loss: 0.24288 - acc: 0.9175 -- iter: 0128/1105
[A[ATraining Step: 355  | total loss: [1m[32m0.23180[0m[0m | time: 5.237s
[2K
| Adam | epoch: 011 | loss: 0.23180 - acc: 0.9226 -- iter: 0160/1105
[A[ATraining Step: 356  | total loss: [1m[32m0.23461[0m[0m | time: 6.223s
[2K
| Adam | epoch: 011 | loss: 0.23461 - acc: 0.9210 -- iter: 0192/1105
[A[ATraining Step: 357  | total loss: [1m[32m0.23475[0m[0m | time: 7.275s
[2K
| Adam | epoch: 011 | loss: 0.23475 - acc: 0.9226 -- iter: 0224/1105
[A[ATraining Step: 358  | total loss: [1m[32m0.24414[0m[0m | time: 8.415s
[2K
| Adam | epoch: 011 | loss: 0.24414 - acc: 0.9147 -- iter: 0256/1105
[A[ATraining Step: 359  | total loss: [1m[32m0.23623[0m[0m | time: 8.969s
[2K
| Adam | epoch: 011 | loss: 0.23623 - acc: 0.9201 -- iter: 0288/1105
[A[ATraining Step: 360  | total loss: [1m[32m0.25305[0m[0m | time: 9.466s
[2K
| Adam | epoch: 011 | loss: 0.25305 - acc: 0.9105 -- iter: 0320/1105
[A[ATraining Step: 361  | total loss: [1m[32m0.26225[0m[0m | time: 10.588s
[2K
| Adam | epoch: 011 | loss: 0.26225 - acc: 0.9077 -- iter: 0352/1105
[A[ATraining Step: 362  | total loss: [1m[32m0.29100[0m[0m | time: 11.768s
[2K
| Adam | epoch: 011 | loss: 0.29100 - acc: 0.9013 -- iter: 0384/1105
[A[ATraining Step: 363  | total loss: [1m[32m0.28109[0m[0m | time: 12.773s
[2K
| Adam | epoch: 011 | loss: 0.28109 - acc: 0.9049 -- iter: 0416/1105
[A[ATraining Step: 364  | total loss: [1m[32m0.29712[0m[0m | time: 13.636s
[2K
| Adam | epoch: 011 | loss: 0.29712 - acc: 0.8988 -- iter: 0448/1105
[A[ATraining Step: 365  | total loss: [1m[32m0.27785[0m[0m | time: 14.657s
[2K
| Adam | epoch: 011 | loss: 0.27785 - acc: 0.9089 -- iter: 0480/1105
[A[ATraining Step: 366  | total loss: [1m[32m0.27412[0m[0m | time: 15.725s
[2K
| Adam | epoch: 011 | loss: 0.27412 - acc: 0.9086 -- iter: 0512/1105
[A[ATraining Step: 367  | total loss: [1m[32m0.25658[0m[0m | time: 16.752s
[2K
| Adam | epoch: 011 | loss: 0.25658 - acc: 0.9178 -- iter: 0544/1105
[A[ATraining Step: 368  | total loss: [1m[32m0.24819[0m[0m | time: 17.829s
[2K
| Adam | epoch: 011 | loss: 0.24819 - acc: 0.9197 -- iter: 0576/1105
[A[ATraining Step: 369  | total loss: [1m[32m0.24728[0m[0m | time: 18.746s
[2K
| Adam | epoch: 011 | loss: 0.24728 - acc: 0.9184 -- iter: 0608/1105
[A[ATraining Step: 370  | total loss: [1m[32m0.24075[0m[0m | time: 19.764s
[2K
| Adam | epoch: 011 | loss: 0.24075 - acc: 0.9172 -- iter: 0640/1105
[A[ATraining Step: 371  | total loss: [1m[32m0.23110[0m[0m | time: 20.909s
[2K
| Adam | epoch: 011 | loss: 0.23110 - acc: 0.9223 -- iter: 0672/1105
[A[ATraining Step: 372  | total loss: [1m[32m0.22674[0m[0m | time: 22.059s
[2K
| Adam | epoch: 011 | loss: 0.22674 - acc: 0.9239 -- iter: 0704/1105
[A[ATraining Step: 373  | total loss: [1m[32m0.22636[0m[0m | time: 22.872s
[2K
| Adam | epoch: 011 | loss: 0.22636 - acc: 0.9221 -- iter: 0736/1105
[A[ATraining Step: 374  | total loss: [1m[32m0.22307[0m[0m | time: 23.792s
[2K
| Adam | epoch: 011 | loss: 0.22307 - acc: 0.9236 -- iter: 0768/1105
[A[ATraining Step: 375  | total loss: [1m[32m0.24138[0m[0m | time: 24.766s
[2K
| Adam | epoch: 011 | loss: 0.24138 - acc: 0.9063 -- iter: 0800/1105
[A[ATraining Step: 376  | total loss: [1m[32m0.24974[0m[0m | time: 25.780s
[2K
| Adam | epoch: 011 | loss: 0.24974 - acc: 0.8969 -- iter: 0832/1105
[A[ATraining Step: 377  | total loss: [1m[32m0.24217[0m[0m | time: 26.793s
[2K
| Adam | epoch: 011 | loss: 0.24217 - acc: 0.9041 -- iter: 0864/1105
[A[ATraining Step: 378  | total loss: [1m[32m0.23741[0m[0m | time: 27.918s
[2K
| Adam | epoch: 011 | loss: 0.23741 - acc: 0.9074 -- iter: 0896/1105
[A[ATraining Step: 379  | total loss: [1m[32m0.24318[0m[0m | time: 28.859s
[2K
| Adam | epoch: 011 | loss: 0.24318 - acc: 0.9042 -- iter: 0928/1105
[A[ATraining Step: 380  | total loss: [1m[32m0.27663[0m[0m | time: 29.834s
[2K
| Adam | epoch: 011 | loss: 0.27663 - acc: 0.8981 -- iter: 0960/1105
[A[ATraining Step: 381  | total loss: [1m[32m0.26315[0m[0m | time: 30.909s
[2K
| Adam | epoch: 011 | loss: 0.26315 - acc: 0.9052 -- iter: 0992/1105
[A[ATraining Step: 382  | total loss: [1m[32m0.26794[0m[0m | time: 32.027s
[2K
| Adam | epoch: 011 | loss: 0.26794 - acc: 0.8959 -- iter: 1024/1105
[A[ATraining Step: 383  | total loss: [1m[32m0.25686[0m[0m | time: 32.900s
[2K
| Adam | epoch: 011 | loss: 0.25686 - acc: 0.8970 -- iter: 1056/1105
[A[ATraining Step: 384  | total loss: [1m[32m0.27498[0m[0m | time: 33.794s
[2K
| Adam | epoch: 011 | loss: 0.27498 - acc: 0.8885 -- iter: 1088/1105
[A[ATraining Step: 385  | total loss: [1m[32m0.27172[0m[0m | time: 36.630s
[2K
| Adam | epoch: 011 | loss: 0.27172 - acc: 0.8872 | val_loss: 0.51555 - val_acc: 0.7948 -- iter: 1105/1105
--
Training Step: 386  | total loss: [1m[32m0.27345[0m[0m | time: 1.034s
[2K
| Adam | epoch: 012 | loss: 0.27345 - acc: 0.8859 -- iter: 0032/1105
[A[ATraining Step: 387  | total loss: [1m[32m0.25579[0m[0m | time: 1.918s
[2K
| Adam | epoch: 012 | loss: 0.25579 - acc: 0.8942 -- iter: 0064/1105
[A[ATraining Step: 388  | total loss: [1m[32m0.26220[0m[0m | time: 2.898s
[2K
| Adam | epoch: 012 | loss: 0.26220 - acc: 0.8892 -- iter: 0096/1105
[A[ATraining Step: 389  | total loss: [1m[32m0.27724[0m[0m | time: 3.928s
[2K
| Adam | epoch: 012 | loss: 0.27724 - acc: 0.8815 -- iter: 0128/1105
[A[ATraining Step: 390  | total loss: [1m[32m0.27504[0m[0m | time: 4.969s
[2K
| Adam | epoch: 012 | loss: 0.27504 - acc: 0.8809 -- iter: 0160/1105
[A[ATraining Step: 391  | total loss: [1m[32m0.30561[0m[0m | time: 6.021s
[2K
| Adam | epoch: 012 | loss: 0.30561 - acc: 0.8584 -- iter: 0192/1105
[A[ATraining Step: 392  | total loss: [1m[32m0.28495[0m[0m | time: 7.203s
[2K
| Adam | epoch: 012 | loss: 0.28495 - acc: 0.8726 -- iter: 0224/1105
[A[ATraining Step: 393  | total loss: [1m[32m0.26533[0m[0m | time: 8.227s
[2K
| Adam | epoch: 012 | loss: 0.26533 - acc: 0.8853 -- iter: 0256/1105
[A[ATraining Step: 394  | total loss: [1m[32m0.26356[0m[0m | time: 9.266s
[2K
| Adam | epoch: 012 | loss: 0.26356 - acc: 0.8811 -- iter: 0288/1105
[A[ATraining Step: 395  | total loss: [1m[32m0.26436[0m[0m | time: 9.868s
[2K
| Adam | epoch: 012 | loss: 0.26436 - acc: 0.8837 -- iter: 0320/1105
[A[ATraining Step: 396  | total loss: [1m[32m0.25870[0m[0m | time: 10.508s
[2K
| Adam | epoch: 012 | loss: 0.25870 - acc: 0.8776 -- iter: 0352/1105
[A[ATraining Step: 397  | total loss: [1m[32m0.24313[0m[0m | time: 11.603s
[2K
| Adam | epoch: 012 | loss: 0.24313 - acc: 0.8899 -- iter: 0384/1105
[A[ATraining Step: 398  | total loss: [1m[32m0.23582[0m[0m | time: 12.662s
[2K
| Adam | epoch: 012 | loss: 0.23582 - acc: 0.8915 -- iter: 0416/1105
[A[ATraining Step: 399  | total loss: [1m[32m0.23734[0m[0m | time: 13.574s
[2K
| Adam | epoch: 012 | loss: 0.23734 - acc: 0.8899 -- iter: 0448/1105
[A[ATraining Step: 400  | total loss: [1m[32m0.24403[0m[0m | time: 15.316s
[2K
| Adam | epoch: 012 | loss: 0.24403 - acc: 0.8853 | val_loss: 0.48578 - val_acc: 0.8208 -- iter: 0480/1105
--
Training Step: 401  | total loss: [1m[32m0.23660[0m[0m | time: 15.924s
[2K
| Adam | epoch: 012 | loss: 0.23660 - acc: 0.8936 -- iter: 0512/1105
[A[ATraining Step: 402  | total loss: [1m[32m0.22853[0m[0m | time: 16.523s
[2K
| Adam | epoch: 012 | loss: 0.22853 - acc: 0.8949 -- iter: 0544/1105
[A[ATraining Step: 403  | total loss: [1m[32m0.21388[0m[0m | time: 17.141s
[2K
| Adam | epoch: 012 | loss: 0.21388 - acc: 0.9054 -- iter: 0576/1105
[A[ATraining Step: 404  | total loss: [1m[32m0.20574[0m[0m | time: 17.744s
[2K
| Adam | epoch: 012 | loss: 0.20574 - acc: 0.9117 -- iter: 0608/1105
[A[ATraining Step: 405  | total loss: [1m[32m0.18975[0m[0m | time: 18.357s
[2K
| Adam | epoch: 012 | loss: 0.18975 - acc: 0.9205 -- iter: 0640/1105
[A[ATraining Step: 406  | total loss: [1m[32m0.18607[0m[0m | time: 18.973s
[2K
| Adam | epoch: 012 | loss: 0.18607 - acc: 0.9191 -- iter: 0672/1105
[A[ATraining Step: 407  | total loss: [1m[32m0.17770[0m[0m | time: 19.583s
[2K
| Adam | epoch: 012 | loss: 0.17770 - acc: 0.9272 -- iter: 0704/1105
[A[ATraining Step: 408  | total loss: [1m[32m0.20260[0m[0m | time: 20.179s
[2K
| Adam | epoch: 012 | loss: 0.20260 - acc: 0.9220 -- iter: 0736/1105
[A[ATraining Step: 409  | total loss: [1m[32m0.18920[0m[0m | time: 20.791s
[2K
| Adam | epoch: 012 | loss: 0.18920 - acc: 0.9298 -- iter: 0768/1105
[A[ATraining Step: 410  | total loss: [1m[32m0.18391[0m[0m | time: 21.390s
[2K
| Adam | epoch: 012 | loss: 0.18391 - acc: 0.9306 -- iter: 0800/1105
[A[ATraining Step: 411  | total loss: [1m[32m0.17091[0m[0m | time: 22.002s
[2K
| Adam | epoch: 012 | loss: 0.17091 - acc: 0.9344 -- iter: 0832/1105
[A[ATraining Step: 412  | total loss: [1m[32m0.18053[0m[0m | time: 22.619s
[2K
| Adam | epoch: 012 | loss: 0.18053 - acc: 0.9316 -- iter: 0864/1105
[A[ATraining Step: 413  | total loss: [1m[32m0.17034[0m[0m | time: 23.217s
[2K
| Adam | epoch: 012 | loss: 0.17034 - acc: 0.9353 -- iter: 0896/1105
[A[ATraining Step: 414  | total loss: [1m[32m0.16218[0m[0m | time: 23.842s
[2K
| Adam | epoch: 012 | loss: 0.16218 - acc: 0.9386 -- iter: 0928/1105
[A[ATraining Step: 415  | total loss: [1m[32m0.16529[0m[0m | time: 24.448s
[2K
| Adam | epoch: 012 | loss: 0.16529 - acc: 0.9354 -- iter: 0960/1105
[A[ATraining Step: 416  | total loss: [1m[32m0.15875[0m[0m | time: 25.074s
[2K
| Adam | epoch: 012 | loss: 0.15875 - acc: 0.9419 -- iter: 0992/1105
[A[ATraining Step: 417  | total loss: [1m[32m0.14835[0m[0m | time: 25.675s
[2K
| Adam | epoch: 012 | loss: 0.14835 - acc: 0.9477 -- iter: 1024/1105
[A[ATraining Step: 418  | total loss: [1m[32m0.15264[0m[0m | time: 26.290s
[2K
| Adam | epoch: 012 | loss: 0.15264 - acc: 0.9467 -- iter: 1056/1105
[A[ATraining Step: 419  | total loss: [1m[32m0.15987[0m[0m | time: 26.930s
[2K
| Adam | epoch: 012 | loss: 0.15987 - acc: 0.9457 -- iter: 1088/1105
[A[ATraining Step: 420  | total loss: [1m[32m0.15682[0m[0m | time: 28.643s
[2K
| Adam | epoch: 012 | loss: 0.15682 - acc: 0.9449 | val_loss: 0.55197 - val_acc: 0.8035 -- iter: 1105/1105
--
Training Step: 421  | total loss: [1m[32m0.14649[0m[0m | time: 0.623s
[2K
| Adam | epoch: 013 | loss: 0.14649 - acc: 0.9473 -- iter: 0032/1105
[A[ATraining Step: 422  | total loss: [1m[32m0.13765[0m[0m | time: 1.225s
[2K
| Adam | epoch: 013 | loss: 0.13765 - acc: 0.9494 -- iter: 0064/1105
[A[ATraining Step: 423  | total loss: [1m[32m0.12817[0m[0m | time: 1.823s
[2K
| Adam | epoch: 013 | loss: 0.12817 - acc: 0.9545 -- iter: 0096/1105
[A[ATraining Step: 424  | total loss: [1m[32m0.12306[0m[0m | time: 2.421s
[2K
| Adam | epoch: 013 | loss: 0.12306 - acc: 0.9590 -- iter: 0128/1105
[A[ATraining Step: 425  | total loss: [1m[32m0.11879[0m[0m | time: 3.050s
[2K
| Adam | epoch: 013 | loss: 0.11879 - acc: 0.9600 -- iter: 0160/1105
[A[ATraining Step: 426  | total loss: [1m[32m0.11745[0m[0m | time: 3.669s
[2K
| Adam | epoch: 013 | loss: 0.11745 - acc: 0.9578 -- iter: 0192/1105
[A[ATraining Step: 427  | total loss: [1m[32m0.11544[0m[0m | time: 4.331s
[2K
| Adam | epoch: 013 | loss: 0.11544 - acc: 0.9589 -- iter: 0224/1105
[A[ATraining Step: 428  | total loss: [1m[32m0.11579[0m[0m | time: 4.959s
[2K
| Adam | epoch: 013 | loss: 0.11579 - acc: 0.9599 -- iter: 0256/1105
[A[ATraining Step: 429  | total loss: [1m[32m0.10785[0m[0m | time: 5.578s
[2K
| Adam | epoch: 013 | loss: 0.10785 - acc: 0.9639 -- iter: 0288/1105
[A[ATraining Step: 430  | total loss: [1m[32m0.10527[0m[0m | time: 6.184s
[2K
| Adam | epoch: 013 | loss: 0.10527 - acc: 0.9644 -- iter: 0320/1105
[A[ATraining Step: 431  | total loss: [1m[32m0.10030[0m[0m | time: 6.553s
[2K
| Adam | epoch: 013 | loss: 0.10030 - acc: 0.9648 -- iter: 0352/1105
[A[ATraining Step: 432  | total loss: [1m[32m0.14891[0m[0m | time: 6.928s
[2K
| Adam | epoch: 013 | loss: 0.14891 - acc: 0.9624 -- iter: 0384/1105
[A[ATraining Step: 433  | total loss: [1m[32m0.18705[0m[0m | time: 7.551s
[2K
| Adam | epoch: 013 | loss: 0.18705 - acc: 0.9603 -- iter: 0416/1105
[A[ATraining Step: 434  | total loss: [1m[32m0.17729[0m[0m | time: 8.156s
[2K
| Adam | epoch: 013 | loss: 0.17729 - acc: 0.9643 -- iter: 0448/1105
[A[ATraining Step: 435  | total loss: [1m[32m0.17441[0m[0m | time: 8.773s
[2K
| Adam | epoch: 013 | loss: 0.17441 - acc: 0.9647 -- iter: 0480/1105
[A[ATraining Step: 436  | total loss: [1m[32m0.18956[0m[0m | time: 9.387s
[2K
| Adam | epoch: 013 | loss: 0.18956 - acc: 0.9589 -- iter: 0512/1105
[A[ATraining Step: 437  | total loss: [1m[32m0.17364[0m[0m | time: 10.003s
[2K
| Adam | epoch: 013 | loss: 0.17364 - acc: 0.9630 -- iter: 0544/1105
[A[ATraining Step: 438  | total loss: [1m[32m0.16227[0m[0m | time: 10.616s
[2K
| Adam | epoch: 013 | loss: 0.16227 - acc: 0.9667 -- iter: 0576/1105
[A[ATraining Step: 439  | total loss: [1m[32m0.15310[0m[0m | time: 11.251s
[2K
| Adam | epoch: 013 | loss: 0.15310 - acc: 0.9669 -- iter: 0608/1105
[A[ATraining Step: 440  | total loss: [1m[32m0.14752[0m[0m | time: 11.877s
[2K
| Adam | epoch: 013 | loss: 0.14752 - acc: 0.9671 -- iter: 0640/1105
[A[ATraining Step: 441  | total loss: [1m[32m0.14857[0m[0m | time: 12.498s
[2K
| Adam | epoch: 013 | loss: 0.14857 - acc: 0.9672 -- iter: 0672/1105
[A[ATraining Step: 442  | total loss: [1m[32m0.15164[0m[0m | time: 13.316s
[2K
| Adam | epoch: 013 | loss: 0.15164 - acc: 0.9643 -- iter: 0704/1105
[A[ATraining Step: 443  | total loss: [1m[32m0.14139[0m[0m | time: 14.424s
[2K
| Adam | epoch: 013 | loss: 0.14139 - acc: 0.9678 -- iter: 0736/1105
[A[ATraining Step: 444  | total loss: [1m[32m0.13640[0m[0m | time: 15.545s
[2K
| Adam | epoch: 013 | loss: 0.13640 - acc: 0.9679 -- iter: 0768/1105
[A[ATraining Step: 445  | total loss: [1m[32m0.12881[0m[0m | time: 16.491s
[2K
| Adam | epoch: 013 | loss: 0.12881 - acc: 0.9711 -- iter: 0800/1105
[A[ATraining Step: 446  | total loss: [1m[32m0.13092[0m[0m | time: 17.452s
[2K
| Adam | epoch: 013 | loss: 0.13092 - acc: 0.9709 -- iter: 0832/1105
[A[ATraining Step: 447  | total loss: [1m[32m0.12461[0m[0m | time: 18.465s
[2K
| Adam | epoch: 013 | loss: 0.12461 - acc: 0.9707 -- iter: 0864/1105
[A[ATraining Step: 448  | total loss: [1m[32m0.11828[0m[0m | time: 19.501s
[2K
| Adam | epoch: 013 | loss: 0.11828 - acc: 0.9736 -- iter: 0896/1105
[A[ATraining Step: 449  | total loss: [1m[32m0.12110[0m[0m | time: 20.531s
[2K
| Adam | epoch: 013 | loss: 0.12110 - acc: 0.9700 -- iter: 0928/1105
[A[ATraining Step: 450  | total loss: [1m[32m0.12002[0m[0m | time: 21.620s
[2K
| Adam | epoch: 013 | loss: 0.12002 - acc: 0.9699 -- iter: 0960/1105
[A[ATraining Step: 451  | total loss: [1m[32m0.11153[0m[0m | time: 22.515s
[2K
| Adam | epoch: 013 | loss: 0.11153 - acc: 0.9729 -- iter: 0992/1105
[A[ATraining Step: 452  | total loss: [1m[32m0.11245[0m[0m | time: 23.441s
[2K
| Adam | epoch: 013 | loss: 0.11245 - acc: 0.9725 -- iter: 1024/1105
[A[ATraining Step: 453  | total loss: [1m[32m0.10499[0m[0m | time: 24.456s
[2K
| Adam | epoch: 013 | loss: 0.10499 - acc: 0.9752 -- iter: 1056/1105
[A[ATraining Step: 454  | total loss: [1m[32m0.11243[0m[0m | time: 25.271s
[2K
| Adam | epoch: 013 | loss: 0.11243 - acc: 0.9683 -- iter: 1088/1105
[A[ATraining Step: 455  | total loss: [1m[32m0.10497[0m[0m | time: 27.940s
[2K
| Adam | epoch: 013 | loss: 0.10497 - acc: 0.9715 | val_loss: 0.54063 - val_acc: 0.8150 -- iter: 1105/1105
--
Training Step: 456  | total loss: [1m[32m0.09854[0m[0m | time: 0.936s
[2K
| Adam | epoch: 014 | loss: 0.09854 - acc: 0.9743 -- iter: 0032/1105
[A[ATraining Step: 457  | total loss: [1m[32m0.09044[0m[0m | time: 1.995s
[2K
| Adam | epoch: 014 | loss: 0.09044 - acc: 0.9769 -- iter: 0064/1105
[A[ATraining Step: 458  | total loss: [1m[32m0.10427[0m[0m | time: 2.870s
[2K
| Adam | epoch: 014 | loss: 0.10427 - acc: 0.9730 -- iter: 0096/1105
[A[ATraining Step: 459  | total loss: [1m[32m0.09511[0m[0m | time: 3.768s
[2K
| Adam | epoch: 014 | loss: 0.09511 - acc: 0.9757 -- iter: 0128/1105
[A[ATraining Step: 460  | total loss: [1m[32m0.09597[0m[0m | time: 4.683s
[2K
| Adam | epoch: 014 | loss: 0.09597 - acc: 0.9719 -- iter: 0160/1105
[A[ATraining Step: 461  | total loss: [1m[32m0.08986[0m[0m | time: 5.674s
[2K
| Adam | epoch: 014 | loss: 0.08986 - acc: 0.9747 -- iter: 0192/1105
[A[ATraining Step: 462  | total loss: [1m[32m0.08325[0m[0m | time: 6.643s
[2K
| Adam | epoch: 014 | loss: 0.08325 - acc: 0.9772 -- iter: 0224/1105
[A[ATraining Step: 463  | total loss: [1m[32m0.07931[0m[0m | time: 7.715s
[2K
| Adam | epoch: 014 | loss: 0.07931 - acc: 0.9795 -- iter: 0256/1105
[A[ATraining Step: 464  | total loss: [1m[32m0.08661[0m[0m | time: 8.813s
[2K
| Adam | epoch: 014 | loss: 0.08661 - acc: 0.9753 -- iter: 0288/1105
[A[ATraining Step: 465  | total loss: [1m[32m0.08436[0m[0m | time: 9.754s
[2K
| Adam | epoch: 014 | loss: 0.08436 - acc: 0.9746 -- iter: 0320/1105
[A[ATraining Step: 466  | total loss: [1m[32m0.09400[0m[0m | time: 10.706s
[2K
| Adam | epoch: 014 | loss: 0.09400 - acc: 0.9740 -- iter: 0352/1105
[A[ATraining Step: 467  | total loss: [1m[32m0.08914[0m[0m | time: 11.273s
[2K
| Adam | epoch: 014 | loss: 0.08914 - acc: 0.9766 -- iter: 0384/1105
[A[ATraining Step: 468  | total loss: [1m[32m0.08547[0m[0m | time: 11.827s
[2K
| Adam | epoch: 014 | loss: 0.08547 - acc: 0.9731 -- iter: 0416/1105
[A[ATraining Step: 469  | total loss: [1m[32m0.07941[0m[0m | time: 12.783s
[2K
| Adam | epoch: 014 | loss: 0.07941 - acc: 0.9758 -- iter: 0448/1105
[A[ATraining Step: 470  | total loss: [1m[32m0.09968[0m[0m | time: 13.883s
[2K
| Adam | epoch: 014 | loss: 0.09968 - acc: 0.9657 -- iter: 0480/1105
[A[ATraining Step: 471  | total loss: [1m[32m0.09435[0m[0m | time: 14.947s
[2K
| Adam | epoch: 014 | loss: 0.09435 - acc: 0.9691 -- iter: 0512/1105
[A[ATraining Step: 472  | total loss: [1m[32m0.10857[0m[0m | time: 15.798s
[2K
| Adam | epoch: 014 | loss: 0.10857 - acc: 0.9691 -- iter: 0544/1105
[A[ATraining Step: 473  | total loss: [1m[32m0.10062[0m[0m | time: 16.876s
[2K
| Adam | epoch: 014 | loss: 0.10062 - acc: 0.9722 -- iter: 0576/1105
[A[ATraining Step: 474  | total loss: [1m[32m0.09943[0m[0m | time: 17.953s
[2K
| Adam | epoch: 014 | loss: 0.09943 - acc: 0.9718 -- iter: 0608/1105
[A[ATraining Step: 475  | total loss: [1m[32m0.09338[0m[0m | time: 18.965s
[2K
| Adam | epoch: 014 | loss: 0.09338 - acc: 0.9747 -- iter: 0640/1105
[A[ATraining Step: 476  | total loss: [1m[32m0.08985[0m[0m | time: 19.801s
[2K
| Adam | epoch: 014 | loss: 0.08985 - acc: 0.9741 -- iter: 0672/1105
[A[ATraining Step: 477  | total loss: [1m[32m0.09263[0m[0m | time: 20.782s
[2K
| Adam | epoch: 014 | loss: 0.09263 - acc: 0.9735 -- iter: 0704/1105
[A[ATraining Step: 478  | total loss: [1m[32m0.08540[0m[0m | time: 21.809s
[2K
| Adam | epoch: 014 | loss: 0.08540 - acc: 0.9762 -- iter: 0736/1105
[A[ATraining Step: 479  | total loss: [1m[32m0.08274[0m[0m | time: 22.812s
[2K
| Adam | epoch: 014 | loss: 0.08274 - acc: 0.9786 -- iter: 0768/1105
[A[ATraining Step: 480  | total loss: [1m[32m0.08452[0m[0m | time: 23.884s
[2K
| Adam | epoch: 014 | loss: 0.08452 - acc: 0.9776 -- iter: 0800/1105
[A[ATraining Step: 481  | total loss: [1m[32m0.08926[0m[0m | time: 24.931s
[2K
| Adam | epoch: 014 | loss: 0.08926 - acc: 0.9767 -- iter: 0832/1105
[A[ATraining Step: 482  | total loss: [1m[32m0.08535[0m[0m | time: 25.791s
[2K
| Adam | epoch: 014 | loss: 0.08535 - acc: 0.9759 -- iter: 0864/1105
[A[ATraining Step: 483  | total loss: [1m[32m0.08373[0m[0m | time: 26.956s
[2K
| Adam | epoch: 014 | loss: 0.08373 - acc: 0.9783 -- iter: 0896/1105
[A[ATraining Step: 484  | total loss: [1m[32m0.08152[0m[0m | time: 28.055s
[2K
| Adam | epoch: 014 | loss: 0.08152 - acc: 0.9805 -- iter: 0928/1105
[A[ATraining Step: 485  | total loss: [1m[32m0.07618[0m[0m | time: 29.018s
[2K
| Adam | epoch: 014 | loss: 0.07618 - acc: 0.9824 -- iter: 0960/1105
[A[ATraining Step: 486  | total loss: [1m[32m0.07232[0m[0m | time: 29.922s
[2K
| Adam | epoch: 014 | loss: 0.07232 - acc: 0.9842 -- iter: 0992/1105
[A[ATraining Step: 487  | total loss: [1m[32m0.06748[0m[0m | time: 30.863s
[2K
| Adam | epoch: 014 | loss: 0.06748 - acc: 0.9858 -- iter: 1024/1105
[A[ATraining Step: 488  | total loss: [1m[32m0.06473[0m[0m | time: 31.788s
[2K
| Adam | epoch: 014 | loss: 0.06473 - acc: 0.9872 -- iter: 1056/1105
[A[ATraining Step: 489  | total loss: [1m[32m0.06453[0m[0m | time: 32.804s
[2K
| Adam | epoch: 014 | loss: 0.06453 - acc: 0.9854 -- iter: 1088/1105
[A[ATraining Step: 490  | total loss: [1m[32m0.05868[0m[0m | time: 35.739s
[2K
| Adam | epoch: 014 | loss: 0.05868 - acc: 0.9868 | val_loss: 0.66146 - val_acc: 0.7919 -- iter: 1105/1105
--
Training Step: 491  | total loss: [1m[32m0.05442[0m[0m | time: 1.150s
[2K
| Adam | epoch: 015 | loss: 0.05442 - acc: 0.9881 -- iter: 0032/1105
[A[ATraining Step: 492  | total loss: [1m[32m0.06396[0m[0m | time: 2.196s
[2K
| Adam | epoch: 015 | loss: 0.06396 - acc: 0.9862 -- iter: 0064/1105
[A[ATraining Step: 493  | total loss: [1m[32m0.05855[0m[0m | time: 3.219s
[2K
| Adam | epoch: 015 | loss: 0.05855 - acc: 0.9876 -- iter: 0096/1105
[A[ATraining Step: 494  | total loss: [1m[32m0.05394[0m[0m | time: 4.130s
[2K
| Adam | epoch: 015 | loss: 0.05394 - acc: 0.9888 -- iter: 0128/1105
[A[ATraining Step: 495  | total loss: [1m[32m0.06329[0m[0m | time: 5.145s
[2K
| Adam | epoch: 015 | loss: 0.06329 - acc: 0.9868 -- iter: 0160/1105
[A[ATraining Step: 496  | total loss: [1m[32m0.05814[0m[0m | time: 6.116s
[2K
| Adam | epoch: 015 | loss: 0.05814 - acc: 0.9881 -- iter: 0192/1105
[A[ATraining Step: 497  | total loss: [1m[32m0.05420[0m[0m | time: 7.003s
[2K
| Adam | epoch: 015 | loss: 0.05420 - acc: 0.9893 -- iter: 0224/1105
[A[ATraining Step: 498  | total loss: [1m[32m0.05163[0m[0m | time: 8.185s
[2K
| Adam | epoch: 015 | loss: 0.05163 - acc: 0.9904 -- iter: 0256/1105
[A[ATraining Step: 499  | total loss: [1m[32m0.05175[0m[0m | time: 9.186s
[2K
| Adam | epoch: 015 | loss: 0.05175 - acc: 0.9882 -- iter: 0288/1105
[A[ATraining Step: 500  | total loss: [1m[32m0.05112[0m[0m | time: 10.052s
[2K
| Adam | epoch: 015 | loss: 0.05112 - acc: 0.9863 -- iter: 0320/1105
[A[ATraining Step: 501  | total loss: [1m[32m0.06139[0m[0m | time: 11.154s
[2K
| Adam | epoch: 015 | loss: 0.06139 - acc: 0.9845 -- iter: 0352/1105
[A[ATraining Step: 502  | total loss: [1m[32m0.05595[0m[0m | time: 12.304s
[2K
| Adam | epoch: 015 | loss: 0.05595 - acc: 0.9861 -- iter: 0384/1105
[A[ATraining Step: 503  | total loss: [1m[32m0.05338[0m[0m | time: 12.868s
[2K
| Adam | epoch: 015 | loss: 0.05338 - acc: 0.9875 -- iter: 0416/1105
[A[ATraining Step: 504  | total loss: [1m[32m0.05426[0m[0m | time: 13.370s
[2K
| Adam | epoch: 015 | loss: 0.05426 - acc: 0.9828 -- iter: 0448/1105
[A[ATraining Step: 505  | total loss: [1m[32m0.04987[0m[0m | time: 14.278s
[2K
| Adam | epoch: 015 | loss: 0.04987 - acc: 0.9846 -- iter: 0480/1105
[A[ATraining Step: 506  | total loss: [1m[32m0.04578[0m[0m | time: 15.216s
[2K
| Adam | epoch: 015 | loss: 0.04578 - acc: 0.9861 -- iter: 0512/1105
[A[ATraining Step: 507  | total loss: [1m[32m0.06238[0m[0m | time: 16.178s
[2K
| Adam | epoch: 015 | loss: 0.06238 - acc: 0.9812 -- iter: 0544/1105
[A[ATraining Step: 508  | total loss: [1m[32m0.16143[0m[0m | time: 17.231s
[2K
| Adam | epoch: 015 | loss: 0.16143 - acc: 0.9675 -- iter: 0576/1105
[A[ATraining Step: 509  | total loss: [1m[32m0.14601[0m[0m | time: 18.316s
[2K
| Adam | epoch: 015 | loss: 0.14601 - acc: 0.9707 -- iter: 0608/1105
[A[ATraining Step: 510  | total loss: [1m[32m0.14401[0m[0m | time: 19.240s
[2K
| Adam | epoch: 015 | loss: 0.14401 - acc: 0.9705 -- iter: 0640/1105
[A[ATraining Step: 511  | total loss: [1m[32m0.13114[0m[0m | time: 20.183s
[2K
| Adam | epoch: 015 | loss: 0.13114 - acc: 0.9735 -- iter: 0672/1105
[A[ATraining Step: 512  | total loss: [1m[32m0.12149[0m[0m | time: 21.310s
[2K
| Adam | epoch: 015 | loss: 0.12149 - acc: 0.9761 -- iter: 0704/1105
[A[ATraining Step: 513  | total loss: [1m[32m0.11155[0m[0m | time: 22.424s
[2K
| Adam | epoch: 015 | loss: 0.11155 - acc: 0.9785 -- iter: 0736/1105
[A[ATraining Step: 514  | total loss: [1m[32m0.10539[0m[0m | time: 23.302s
[2K
| Adam | epoch: 015 | loss: 0.10539 - acc: 0.9775 -- iter: 0768/1105
[A[ATraining Step: 515  | total loss: [1m[32m0.09597[0m[0m | time: 24.238s
[2K
| Adam | epoch: 015 | loss: 0.09597 - acc: 0.9798 -- iter: 0800/1105
[A[ATraining Step: 516  | total loss: [1m[32m0.08789[0m[0m | time: 25.164s
[2K
| Adam | epoch: 015 | loss: 0.08789 - acc: 0.9818 -- iter: 0832/1105
[A[ATraining Step: 517  | total loss: [1m[32m0.08239[0m[0m | time: 26.125s
[2K
| Adam | epoch: 015 | loss: 0.08239 - acc: 0.9836 -- iter: 0864/1105
[A[ATraining Step: 518  | total loss: [1m[32m0.08295[0m[0m | time: 27.138s
[2K
| Adam | epoch: 015 | loss: 0.08295 - acc: 0.9821 -- iter: 0896/1105
[A[ATraining Step: 519  | total loss: [1m[32m0.07829[0m[0m | time: 28.167s
[2K
| Adam | epoch: 015 | loss: 0.07829 - acc: 0.9839 -- iter: 0928/1105
[A[ATraining Step: 520  | total loss: [1m[32m0.08631[0m[0m | time: 29.114s
[2K
| Adam | epoch: 015 | loss: 0.08631 - acc: 0.9824 -- iter: 0960/1105
[A[ATraining Step: 521  | total loss: [1m[32m0.08385[0m[0m | time: 30.072s
[2K
| Adam | epoch: 015 | loss: 0.08385 - acc: 0.9810 -- iter: 0992/1105
[A[ATraining Step: 522  | total loss: [1m[32m0.08159[0m[0m | time: 31.205s
[2K
| Adam | epoch: 015 | loss: 0.08159 - acc: 0.9798 -- iter: 1024/1105
[A[ATraining Step: 523  | total loss: [1m[32m0.07494[0m[0m | time: 32.399s
[2K
| Adam | epoch: 015 | loss: 0.07494 - acc: 0.9818 -- iter: 1056/1105
[A[ATraining Step: 524  | total loss: [1m[32m0.06959[0m[0m | time: 33.222s
[2K
| Adam | epoch: 015 | loss: 0.06959 - acc: 0.9837 -- iter: 1088/1105
[A[ATraining Step: 525  | total loss: [1m[32m0.06484[0m[0m | time: 36.014s
[2K
| Adam | epoch: 015 | loss: 0.06484 - acc: 0.9853 | val_loss: 0.67044 - val_acc: 0.7919 -- iter: 1105/1105
--
Training Step: 526  | total loss: [1m[32m0.06041[0m[0m | time: 1.099s
[2K
| Adam | epoch: 016 | loss: 0.06041 - acc: 0.9868 -- iter: 0032/1105
[A[ATraining Step: 527  | total loss: [1m[32m0.06298[0m[0m | time: 2.268s
[2K
| Adam | epoch: 016 | loss: 0.06298 - acc: 0.9850 -- iter: 0064/1105
[A[ATraining Step: 528  | total loss: [1m[32m0.07212[0m[0m | time: 3.163s
[2K
| Adam | epoch: 016 | loss: 0.07212 - acc: 0.9833 -- iter: 0096/1105
[A[ATraining Step: 529  | total loss: [1m[32m0.07405[0m[0m | time: 4.046s
[2K
| Adam | epoch: 016 | loss: 0.07405 - acc: 0.9819 -- iter: 0128/1105
[A[ATraining Step: 530  | total loss: [1m[32m0.06777[0m[0m | time: 5.135s
[2K
| Adam | epoch: 016 | loss: 0.06777 - acc: 0.9837 -- iter: 0160/1105
[A[ATraining Step: 531  | total loss: [1m[32m0.06824[0m[0m | time: 6.215s
[2K
| Adam | epoch: 016 | loss: 0.06824 - acc: 0.9822 -- iter: 0192/1105
[A[ATraining Step: 532  | total loss: [1m[32m0.07889[0m[0m | time: 7.081s
[2K
| Adam | epoch: 016 | loss: 0.07889 - acc: 0.9777 -- iter: 0224/1105
[A[ATraining Step: 533  | total loss: [1m[32m0.07735[0m[0m | time: 8.041s
[2K
| Adam | epoch: 016 | loss: 0.07735 - acc: 0.9737 -- iter: 0256/1105
[A[ATraining Step: 534  | total loss: [1m[32m0.07101[0m[0m | time: 9.009s
[2K
| Adam | epoch: 016 | loss: 0.07101 - acc: 0.9763 -- iter: 0288/1105
[A[ATraining Step: 535  | total loss: [1m[32m0.06855[0m[0m | time: 9.964s
[2K
| Adam | epoch: 016 | loss: 0.06855 - acc: 0.9756 -- iter: 0320/1105
[A[ATraining Step: 536  | total loss: [1m[32m0.06861[0m[0m | time: 10.982s
[2K
| Adam | epoch: 016 | loss: 0.06861 - acc: 0.9749 -- iter: 0352/1105
[A[ATraining Step: 537  | total loss: [1m[32m0.06726[0m[0m | time: 12.050s
[2K
| Adam | epoch: 016 | loss: 0.06726 - acc: 0.9774 -- iter: 0384/1105
[A[ATraining Step: 538  | total loss: [1m[32m0.06604[0m[0m | time: 12.939s
[2K
| Adam | epoch: 016 | loss: 0.06604 - acc: 0.9765 -- iter: 0416/1105
[A[ATraining Step: 539  | total loss: [1m[32m0.08434[0m[0m | time: 13.504s
[2K
| Adam | epoch: 016 | loss: 0.08434 - acc: 0.9726 -- iter: 0448/1105
[A[ATraining Step: 540  | total loss: [1m[32m0.09889[0m[0m | time: 14.118s
[2K
| Adam | epoch: 016 | loss: 0.09889 - acc: 0.9695 -- iter: 0480/1105
[A[ATraining Step: 541  | total loss: [1m[32m0.10338[0m[0m | time: 15.233s
[2K
| Adam | epoch: 016 | loss: 0.10338 - acc: 0.9667 -- iter: 0512/1105
[A[ATraining Step: 542  | total loss: [1m[32m0.09454[0m[0m | time: 16.241s
[2K
| Adam | epoch: 016 | loss: 0.09454 - acc: 0.9700 -- iter: 0544/1105
[A[ATraining Step: 543  | total loss: [1m[32m0.09352[0m[0m | time: 17.065s
[2K
| Adam | epoch: 016 | loss: 0.09352 - acc: 0.9699 -- iter: 0576/1105
[A[ATraining Step: 544  | total loss: [1m[32m0.33332[0m[0m | time: 18.006s
[2K
| Adam | epoch: 016 | loss: 0.33332 - acc: 0.9229 -- iter: 0608/1105
[A[ATraining Step: 545  | total loss: [1m[32m0.30220[0m[0m | time: 19.039s
[2K
| Adam | epoch: 016 | loss: 0.30220 - acc: 0.9306 -- iter: 0640/1105
[A[ATraining Step: 546  | total loss: [1m[32m0.27339[0m[0m | time: 19.994s
[2K
| Adam | epoch: 016 | loss: 0.27339 - acc: 0.9375 -- iter: 0672/1105
[A[ATraining Step: 547  | total loss: [1m[32m0.24978[0m[0m | time: 21.024s
[2K
| Adam | epoch: 016 | loss: 0.24978 - acc: 0.9438 -- iter: 0704/1105
[A[ATraining Step: 548  | total loss: [1m[32m0.22728[0m[0m | time: 22.069s
[2K
| Adam | epoch: 016 | loss: 0.22728 - acc: 0.9494 -- iter: 0736/1105
[A[ATraining Step: 549  | total loss: [1m[32m0.20684[0m[0m | time: 22.947s
[2K
| Adam | epoch: 016 | loss: 0.20684 - acc: 0.9545 -- iter: 0768/1105
[A[ATraining Step: 550  | total loss: [1m[32m0.19226[0m[0m | time: 23.931s
[2K
| Adam | epoch: 016 | loss: 0.19226 - acc: 0.9559 -- iter: 0800/1105
[A[ATraining Step: 551  | total loss: [1m[32m0.18655[0m[0m | time: 25.032s
[2K
| Adam | epoch: 016 | loss: 0.18655 - acc: 0.9572 -- iter: 0832/1105
[A[ATraining Step: 552  | total loss: [1m[32m0.17327[0m[0m | time: 26.124s
[2K
| Adam | epoch: 016 | loss: 0.17327 - acc: 0.9615 -- iter: 0864/1105
[A[ATraining Step: 553  | total loss: [1m[32m0.15953[0m[0m | time: 26.963s
[2K
| Adam | epoch: 016 | loss: 0.15953 - acc: 0.9653 -- iter: 0896/1105
[A[ATraining Step: 554  | total loss: [1m[32m0.14700[0m[0m | time: 27.955s
[2K
| Adam | epoch: 016 | loss: 0.14700 - acc: 0.9688 -- iter: 0928/1105
[A[ATraining Step: 555  | total loss: [1m[32m0.14267[0m[0m | time: 28.920s
[2K
| Adam | epoch: 016 | loss: 0.14267 - acc: 0.9688 -- iter: 0960/1105
[A[ATraining Step: 556  | total loss: [1m[32m0.13050[0m[0m | time: 29.906s
[2K
| Adam | epoch: 016 | loss: 0.13050 - acc: 0.9719 -- iter: 0992/1105
[A[ATraining Step: 557  | total loss: [1m[32m0.11982[0m[0m | time: 30.914s
[2K
| Adam | epoch: 016 | loss: 0.11982 - acc: 0.9747 -- iter: 1024/1105
[A[ATraining Step: 558  | total loss: [1m[32m0.11097[0m[0m | time: 32.042s
[2K
| Adam | epoch: 016 | loss: 0.11097 - acc: 0.9772 -- iter: 1056/1105
[A[ATraining Step: 559  | total loss: [1m[32m0.10327[0m[0m | time: 32.964s
[2K
| Adam | epoch: 016 | loss: 0.10327 - acc: 0.9795 -- iter: 1088/1105
[A[ATraining Step: 560  | total loss: [1m[32m0.09610[0m[0m | time: 36.055s
[2K
| Adam | epoch: 016 | loss: 0.09610 - acc: 0.9816 | val_loss: 0.59465 - val_acc: 0.7948 -- iter: 1105/1105
--
Training Step: 561  | total loss: [1m[32m0.09464[0m[0m | time: 0.973s
[2K
| Adam | epoch: 017 | loss: 0.09464 - acc: 0.9803 -- iter: 0032/1105
[A[ATraining Step: 562  | total loss: [1m[32m0.09259[0m[0m | time: 2.048s
[2K
| Adam | epoch: 017 | loss: 0.09259 - acc: 0.9791 -- iter: 0064/1105
[A[ATraining Step: 563  | total loss: [1m[32m0.08685[0m[0m | time: 3.064s
[2K
| Adam | epoch: 017 | loss: 0.08685 - acc: 0.9812 -- iter: 0096/1105
[A[ATraining Step: 564  | total loss: [1m[32m0.08237[0m[0m | time: 3.999s
[2K
| Adam | epoch: 017 | loss: 0.08237 - acc: 0.9800 -- iter: 0128/1105
[A[ATraining Step: 565  | total loss: [1m[32m0.07516[0m[0m | time: 5.059s
[2K
| Adam | epoch: 017 | loss: 0.07516 - acc: 0.9820 -- iter: 0160/1105
[A[ATraining Step: 566  | total loss: [1m[32m0.07726[0m[0m | time: 6.055s
[2K
| Adam | epoch: 017 | loss: 0.07726 - acc: 0.9807 -- iter: 0192/1105
[A[ATraining Step: 567  | total loss: [1m[32m0.07034[0m[0m | time: 6.983s
[2K
| Adam | epoch: 017 | loss: 0.07034 - acc: 0.9826 -- iter: 0224/1105
[A[ATraining Step: 568  | total loss: [1m[32m0.06441[0m[0m | time: 8.069s
[2K
| Adam | epoch: 017 | loss: 0.06441 - acc: 0.9843 -- iter: 0256/1105
[A[ATraining Step: 569  | total loss: [1m[32m0.06087[0m[0m | time: 9.145s
[2K
| Adam | epoch: 017 | loss: 0.06087 - acc: 0.9859 -- iter: 0288/1105
[A[ATraining Step: 570  | total loss: [1m[32m0.05792[0m[0m | time: 10.083s
[2K
| Adam | epoch: 017 | loss: 0.05792 - acc: 0.9842 -- iter: 0320/1105
[A[ATraining Step: 571  | total loss: [1m[32m0.05338[0m[0m | time: 11.056s
[2K
| Adam | epoch: 017 | loss: 0.05338 - acc: 0.9858 -- iter: 0352/1105
[A[ATraining Step: 572  | total loss: [1m[32m0.05217[0m[0m | time: 12.030s
[2K
| Adam | epoch: 017 | loss: 0.05217 - acc: 0.9872 -- iter: 0384/1105
[A[ATraining Step: 573  | total loss: [1m[32m0.08071[0m[0m | time: 13.034s
[2K
| Adam | epoch: 017 | loss: 0.08071 - acc: 0.9822 -- iter: 0416/1105
[A[ATraining Step: 574  | total loss: [1m[32m0.07417[0m[0m | time: 14.110s
[2K
| Adam | epoch: 017 | loss: 0.07417 - acc: 0.9840 -- iter: 0448/1105
[A[ATraining Step: 575  | total loss: [1m[32m0.07669[0m[0m | time: 14.809s
[2K
| Adam | epoch: 017 | loss: 0.07669 - acc: 0.9825 -- iter: 0480/1105
[A[ATraining Step: 576  | total loss: [1m[32m0.07046[0m[0m | time: 15.448s
[2K
| Adam | epoch: 017 | loss: 0.07046 - acc: 0.9842 -- iter: 0512/1105
[A[ATraining Step: 577  | total loss: [1m[32m0.06561[0m[0m | time: 16.316s
[2K
| Adam | epoch: 017 | loss: 0.06561 - acc: 0.9858 -- iter: 0544/1105
[A[ATraining Step: 578  | total loss: [1m[32m0.06012[0m[0m | time: 17.294s
[2K
| Adam | epoch: 017 | loss: 0.06012 - acc: 0.9872 -- iter: 0576/1105
[A[ATraining Step: 579  | total loss: [1m[32m0.05495[0m[0m | time: 18.397s
[2K
| Adam | epoch: 017 | loss: 0.05495 - acc: 0.9885 -- iter: 0608/1105
[A[ATraining Step: 580  | total loss: [1m[32m0.11704[0m[0m | time: 19.401s
[2K
| Adam | epoch: 017 | loss: 0.11704 - acc: 0.9771 -- iter: 0640/1105
[A[ATraining Step: 581  | total loss: [1m[32m0.10833[0m[0m | time: 20.288s
[2K
| Adam | epoch: 017 | loss: 0.10833 - acc: 0.9794 -- iter: 0672/1105
[A[ATraining Step: 582  | total loss: [1m[32m0.10469[0m[0m | time: 21.279s
[2K
| Adam | epoch: 017 | loss: 0.10469 - acc: 0.9784 -- iter: 0704/1105
[A[ATraining Step: 583  | total loss: [1m[32m0.09680[0m[0m | time: 22.261s
[2K
| Adam | epoch: 017 | loss: 0.09680 - acc: 0.9805 -- iter: 0736/1105
[A[ATraining Step: 584  | total loss: [1m[32m0.09219[0m[0m | time: 23.218s
[2K
| Adam | epoch: 017 | loss: 0.09219 - acc: 0.9794 -- iter: 0768/1105
[A[ATraining Step: 585  | total loss: [1m[32m0.08392[0m[0m | time: 24.260s
[2K
| Adam | epoch: 017 | loss: 0.08392 - acc: 0.9814 -- iter: 0800/1105
[A[ATraining Step: 586  | total loss: [1m[32m0.07671[0m[0m | time: 25.361s
[2K
| Adam | epoch: 017 | loss: 0.07671 - acc: 0.9833 -- iter: 0832/1105
[A[ATraining Step: 587  | total loss: [1m[32m0.07092[0m[0m | time: 26.205s
[2K
| Adam | epoch: 017 | loss: 0.07092 - acc: 0.9849 -- iter: 0864/1105
[A[ATraining Step: 588  | total loss: [1m[32m0.06464[0m[0m | time: 27.356s
[2K
| Adam | epoch: 017 | loss: 0.06464 - acc: 0.9865 -- iter: 0896/1105
[A[ATraining Step: 589  | total loss: [1m[32m0.05995[0m[0m | time: 28.510s
[2K
| Adam | epoch: 017 | loss: 0.05995 - acc: 0.9878 -- iter: 0928/1105
[A[ATraining Step: 590  | total loss: [1m[32m0.06764[0m[0m | time: 29.534s
[2K
| Adam | epoch: 017 | loss: 0.06764 - acc: 0.9859 -- iter: 0960/1105
[A[ATraining Step: 591  | total loss: [1m[32m0.06189[0m[0m | time: 30.393s
[2K
| Adam | epoch: 017 | loss: 0.06189 - acc: 0.9873 -- iter: 0992/1105
[A[ATraining Step: 592  | total loss: [1m[32m0.08049[0m[0m | time: 31.313s
[2K
| Adam | epoch: 017 | loss: 0.08049 - acc: 0.9823 -- iter: 1024/1105
[A[ATraining Step: 593  | total loss: [1m[32m0.07322[0m[0m | time: 32.264s
[2K
| Adam | epoch: 017 | loss: 0.07322 - acc: 0.9841 -- iter: 1056/1105
[A[ATraining Step: 594  | total loss: [1m[32m0.06664[0m[0m | time: 33.278s
[2K
| Adam | epoch: 017 | loss: 0.06664 - acc: 0.9857 -- iter: 1088/1105
[A[ATraining Step: 595  | total loss: [1m[32m0.06098[0m[0m | time: 36.218s
[2K
| Adam | epoch: 017 | loss: 0.06098 - acc: 0.9871 | val_loss: 0.61164 - val_acc: 0.8150 -- iter: 1105/1105
--
Training Step: 596  | total loss: [1m[32m0.06015[0m[0m | time: 1.007s
[2K
| Adam | epoch: 018 | loss: 0.06015 - acc: 0.9853 -- iter: 0032/1105
[A[ATraining Step: 597  | total loss: [1m[32m0.05817[0m[0m | time: 2.130s
[2K
| Adam | epoch: 018 | loss: 0.05817 - acc: 0.9868 -- iter: 0064/1105
[A[ATraining Step: 598  | total loss: [1m[32m0.05560[0m[0m | time: 3.249s
[2K
| Adam | epoch: 018 | loss: 0.05560 - acc: 0.9881 -- iter: 0096/1105
[A[ATraining Step: 599  | total loss: [1m[32m0.05098[0m[0m | time: 4.100s
[2K
| Adam | epoch: 018 | loss: 0.05098 - acc: 0.9893 -- iter: 0128/1105
[A[ATraining Step: 600  | total loss: [1m[32m0.04714[0m[0m | time: 6.886s
[2K
| Adam | epoch: 018 | loss: 0.04714 - acc: 0.9903 | val_loss: 0.67703 - val_acc: 0.7948 -- iter: 0160/1105
--
Training Step: 601  | total loss: [1m[32m0.04428[0m[0m | time: 7.912s
[2K
| Adam | epoch: 018 | loss: 0.04428 - acc: 0.9913 -- iter: 0192/1105
[A[ATraining Step: 602  | total loss: [1m[32m0.04967[0m[0m | time: 9.030s
[2K
| Adam | epoch: 018 | loss: 0.04967 - acc: 0.9891 -- iter: 0224/1105
[A[ATraining Step: 603  | total loss: [1m[32m0.04545[0m[0m | time: 10.002s
[2K
| Adam | epoch: 018 | loss: 0.04545 - acc: 0.9901 -- iter: 0256/1105
[A[ATraining Step: 604  | total loss: [1m[32m0.04196[0m[0m | time: 10.956s
[2K
| Adam | epoch: 018 | loss: 0.04196 - acc: 0.9911 -- iter: 0288/1105
[A[ATraining Step: 605  | total loss: [1m[32m0.03856[0m[0m | time: 12.085s
[2K
| Adam | epoch: 018 | loss: 0.03856 - acc: 0.9920 -- iter: 0320/1105
[A[ATraining Step: 606  | total loss: [1m[32m0.03646[0m[0m | time: 13.170s
[2K
| Adam | epoch: 018 | loss: 0.03646 - acc: 0.9928 -- iter: 0352/1105
[A[ATraining Step: 607  | total loss: [1m[32m0.03378[0m[0m | time: 14.026s
[2K
| Adam | epoch: 018 | loss: 0.03378 - acc: 0.9935 -- iter: 0384/1105
[A[ATraining Step: 608  | total loss: [1m[32m0.04851[0m[0m | time: 15.019s
[2K
| Adam | epoch: 018 | loss: 0.04851 - acc: 0.9879 -- iter: 0416/1105
[A[ATraining Step: 609  | total loss: [1m[32m0.04676[0m[0m | time: 16.015s
[2K
| Adam | epoch: 018 | loss: 0.04676 - acc: 0.9891 -- iter: 0448/1105
[A[ATraining Step: 610  | total loss: [1m[32m0.04303[0m[0m | time: 16.971s
[2K
| Adam | epoch: 018 | loss: 0.04303 - acc: 0.9902 -- iter: 0480/1105
[A[ATraining Step: 611  | total loss: [1m[32m0.04090[0m[0m | time: 17.594s
[2K
| Adam | epoch: 018 | loss: 0.04090 - acc: 0.9912 -- iter: 0512/1105
[A[ATraining Step: 612  | total loss: [1m[32m0.03824[0m[0m | time: 18.263s
[2K
| Adam | epoch: 018 | loss: 0.03824 - acc: 0.9921 -- iter: 0544/1105
[A[ATraining Step: 613  | total loss: [1m[32m0.03532[0m[0m | time: 19.376s
[2K
| Adam | epoch: 018 | loss: 0.03532 - acc: 0.9929 -- iter: 0576/1105
[A[ATraining Step: 614  | total loss: [1m[32m0.03400[0m[0m | time: 20.264s
[2K
| Adam | epoch: 018 | loss: 0.03400 - acc: 0.9936 -- iter: 0608/1105
[A[ATraining Step: 615  | total loss: [1m[32m0.03102[0m[0m | time: 21.378s
[2K
| Adam | epoch: 018 | loss: 0.03102 - acc: 0.9942 -- iter: 0640/1105
[A[ATraining Step: 616  | total loss: [1m[32m0.02859[0m[0m | time: 22.494s
[2K
| Adam | epoch: 018 | loss: 0.02859 - acc: 0.9948 -- iter: 0672/1105
[A[ATraining Step: 617  | total loss: [1m[32m0.02661[0m[0m | time: 23.501s
[2K
| Adam | epoch: 018 | loss: 0.02661 - acc: 0.9953 -- iter: 0704/1105
[A[ATraining Step: 618  | total loss: [1m[32m0.02437[0m[0m | time: 24.408s
[2K
| Adam | epoch: 018 | loss: 0.02437 - acc: 0.9958 -- iter: 0736/1105
[A[ATraining Step: 619  | total loss: [1m[32m0.02361[0m[0m | time: 25.384s
[2K
| Adam | epoch: 018 | loss: 0.02361 - acc: 0.9962 -- iter: 0768/1105
[A[ATraining Step: 620  | total loss: [1m[32m0.02574[0m[0m | time: 26.441s
[2K
| Adam | epoch: 018 | loss: 0.02574 - acc: 0.9935 -- iter: 0800/1105
[A[ATraining Step: 621  | total loss: [1m[32m0.02387[0m[0m | time: 27.509s
[2K
| Adam | epoch: 018 | loss: 0.02387 - acc: 0.9941 -- iter: 0832/1105
[A[ATraining Step: 622  | total loss: [1m[32m0.02209[0m[0m | time: 28.687s
[2K
| Adam | epoch: 018 | loss: 0.02209 - acc: 0.9947 -- iter: 0864/1105
[A[ATraining Step: 623  | total loss: [1m[32m0.02113[0m[0m | time: 29.642s
[2K
| Adam | epoch: 018 | loss: 0.02113 - acc: 0.9952 -- iter: 0896/1105
[A[ATraining Step: 624  | total loss: [1m[32m0.01942[0m[0m | time: 30.554s
[2K
| Adam | epoch: 018 | loss: 0.01942 - acc: 0.9957 -- iter: 0928/1105
[A[ATraining Step: 625  | total loss: [1m[32m0.02906[0m[0m | time: 31.649s
[2K
| Adam | epoch: 018 | loss: 0.02906 - acc: 0.9899 -- iter: 0960/1105
[A[ATraining Step: 626  | total loss: [1m[32m0.02657[0m[0m | time: 32.769s
[2K
| Adam | epoch: 018 | loss: 0.02657 - acc: 0.9909 -- iter: 0992/1105
[A[ATraining Step: 627  | total loss: [1m[32m0.03310[0m[0m | time: 33.793s
[2K
| Adam | epoch: 018 | loss: 0.03310 - acc: 0.9887 -- iter: 1024/1105
[A[ATraining Step: 628  | total loss: [1m[32m0.03195[0m[0m | time: 34.943s
[2K
| Adam | epoch: 018 | loss: 0.03195 - acc: 0.9898 -- iter: 1056/1105
[A[ATraining Step: 629  | total loss: [1m[32m0.03651[0m[0m | time: 35.958s
[2K
| Adam | epoch: 018 | loss: 0.03651 - acc: 0.9877 -- iter: 1088/1105
[A[ATraining Step: 630  | total loss: [1m[32m0.03331[0m[0m | time: 38.882s
[2K
| Adam | epoch: 018 | loss: 0.03331 - acc: 0.9889 | val_loss: 0.74993 - val_acc: 0.8006 -- iter: 1105/1105
--
Training Step: 631  | total loss: [1m[32m0.03047[0m[0m | time: 1.139s
[2K
| Adam | epoch: 019 | loss: 0.03047 - acc: 0.9900 -- iter: 0032/1105
[A[ATraining Step: 632  | total loss: [1m[32m0.02816[0m[0m | time: 2.275s
[2K
| Adam | epoch: 019 | loss: 0.02816 - acc: 0.9910 -- iter: 0064/1105
[A[ATraining Step: 633  | total loss: [1m[32m0.04692[0m[0m | time: 2.969s
[2K
| Adam | epoch: 019 | loss: 0.04692 - acc: 0.9888 -- iter: 0096/1105
[A[ATraining Step: 634  | total loss: [1m[32m0.04413[0m[0m | time: 3.592s
[2K
| Adam | epoch: 019 | loss: 0.04413 - acc: 0.9899 -- iter: 0128/1105
[A[ATraining Step: 635  | total loss: [1m[32m0.04299[0m[0m | time: 4.219s
[2K
| Adam | epoch: 019 | loss: 0.04299 - acc: 0.9909 -- iter: 0160/1105
[A[ATraining Step: 636  | total loss: [1m[32m0.03911[0m[0m | time: 4.829s
[2K
| Adam | epoch: 019 | loss: 0.03911 - acc: 0.9918 -- iter: 0192/1105
[A[ATraining Step: 637  | total loss: [1m[32m0.03590[0m[0m | time: 5.456s
[2K
| Adam | epoch: 019 | loss: 0.03590 - acc: 0.9927 -- iter: 0224/1105
[A[ATraining Step: 638  | total loss: [1m[32m0.03263[0m[0m | time: 6.051s
[2K
| Adam | epoch: 019 | loss: 0.03263 - acc: 0.9934 -- iter: 0256/1105
[A[ATraining Step: 639  | total loss: [1m[32m0.03652[0m[0m | time: 6.647s
[2K
| Adam | epoch: 019 | loss: 0.03652 - acc: 0.9909 -- iter: 0288/1105
[A[ATraining Step: 640  | total loss: [1m[32m0.03350[0m[0m | time: 7.259s
[2K
| Adam | epoch: 019 | loss: 0.03350 - acc: 0.9918 -- iter: 0320/1105
[A[ATraining Step: 641  | total loss: [1m[32m0.05036[0m[0m | time: 7.910s
[2K
| Adam | epoch: 019 | loss: 0.05036 - acc: 0.9864 -- iter: 0352/1105
[A[ATraining Step: 642  | total loss: [1m[32m0.04663[0m[0m | time: 8.535s
[2K
| Adam | epoch: 019 | loss: 0.04663 - acc: 0.9878 -- iter: 0384/1105
[A[ATraining Step: 643  | total loss: [1m[32m0.06122[0m[0m | time: 9.134s
[2K
| Adam | epoch: 019 | loss: 0.06122 - acc: 0.9859 -- iter: 0416/1105
[A[ATraining Step: 644  | total loss: [1m[32m0.05621[0m[0m | time: 9.742s
[2K
| Adam | epoch: 019 | loss: 0.05621 - acc: 0.9873 -- iter: 0448/1105
[A[ATraining Step: 645  | total loss: [1m[32m0.05206[0m[0m | time: 10.356s
[2K
| Adam | epoch: 019 | loss: 0.05206 - acc: 0.9885 -- iter: 0480/1105
[A[ATraining Step: 646  | total loss: [1m[32m0.04795[0m[0m | time: 10.975s
[2K
| Adam | epoch: 019 | loss: 0.04795 - acc: 0.9897 -- iter: 0512/1105
[A[ATraining Step: 647  | total loss: [1m[32m0.04443[0m[0m | time: 11.339s
[2K
| Adam | epoch: 019 | loss: 0.04443 - acc: 0.9907 -- iter: 0544/1105
[A[ATraining Step: 648  | total loss: [1m[32m0.04055[0m[0m | time: 11.684s
[2K
| Adam | epoch: 019 | loss: 0.04055 - acc: 0.9917 -- iter: 0576/1105
[A[ATraining Step: 649  | total loss: [1m[32m0.03724[0m[0m | time: 12.310s
[2K
| Adam | epoch: 019 | loss: 0.03724 - acc: 0.9925 -- iter: 0608/1105
[A[ATraining Step: 650  | total loss: [1m[32m0.03471[0m[0m | time: 12.963s
[2K
| Adam | epoch: 019 | loss: 0.03471 - acc: 0.9932 -- iter: 0640/1105
[A[ATraining Step: 651  | total loss: [1m[32m0.03283[0m[0m | time: 13.578s
[2K
| Adam | epoch: 019 | loss: 0.03283 - acc: 0.9939 -- iter: 0672/1105
[A[ATraining Step: 652  | total loss: [1m[32m0.07885[0m[0m | time: 14.182s
[2K
| Adam | epoch: 019 | loss: 0.07885 - acc: 0.9789 -- iter: 0704/1105
[A[ATraining Step: 653  | total loss: [1m[32m0.07217[0m[0m | time: 14.781s
[2K
| Adam | epoch: 019 | loss: 0.07217 - acc: 0.9810 -- iter: 0736/1105
[A[ATraining Step: 654  | total loss: [1m[32m0.06615[0m[0m | time: 15.377s
[2K
| Adam | epoch: 019 | loss: 0.06615 - acc: 0.9829 -- iter: 0768/1105
[A[ATraining Step: 655  | total loss: [1m[32m0.06976[0m[0m | time: 15.990s
[2K
| Adam | epoch: 019 | loss: 0.06976 - acc: 0.9815 -- iter: 0800/1105
[A[ATraining Step: 656  | total loss: [1m[32m0.06729[0m[0m | time: 16.604s
[2K
| Adam | epoch: 019 | loss: 0.06729 - acc: 0.9802 -- iter: 0832/1105
[A[ATraining Step: 657  | total loss: [1m[32m0.07678[0m[0m | time: 17.206s
[2K
| Adam | epoch: 019 | loss: 0.07678 - acc: 0.9791 -- iter: 0864/1105
[A[ATraining Step: 658  | total loss: [1m[32m0.07020[0m[0m | time: 17.814s
[2K
| Adam | epoch: 019 | loss: 0.07020 - acc: 0.9812 -- iter: 0896/1105
[A[ATraining Step: 659  | total loss: [1m[32m0.06392[0m[0m | time: 18.424s
[2K
| Adam | epoch: 019 | loss: 0.06392 - acc: 0.9830 -- iter: 0928/1105
[A[ATraining Step: 660  | total loss: [1m[32m0.05844[0m[0m | time: 19.045s
[2K
| Adam | epoch: 019 | loss: 0.05844 - acc: 0.9847 -- iter: 0960/1105
[A[ATraining Step: 661  | total loss: [1m[32m0.05345[0m[0m | time: 19.659s
[2K
| Adam | epoch: 019 | loss: 0.05345 - acc: 0.9863 -- iter: 0992/1105
[A[ATraining Step: 662  | total loss: [1m[32m0.06540[0m[0m | time: 20.273s
[2K
| Adam | epoch: 019 | loss: 0.06540 - acc: 0.9845 -- iter: 1024/1105
[A[ATraining Step: 663  | total loss: [1m[32m0.05985[0m[0m | time: 20.881s
[2K
| Adam | epoch: 019 | loss: 0.05985 - acc: 0.9861 -- iter: 1056/1105
[A[ATraining Step: 664  | total loss: [1m[32m0.05463[0m[0m | time: 21.515s
[2K
| Adam | epoch: 019 | loss: 0.05463 - acc: 0.9875 -- iter: 1088/1105
[A[ATraining Step: 665  | total loss: [1m[32m0.05023[0m[0m | time: 23.267s
[2K
| Adam | epoch: 019 | loss: 0.05023 - acc: 0.9887 | val_loss: 0.58879 - val_acc: 0.8092 -- iter: 1105/1105
--
Training Step: 666  | total loss: [1m[32m0.04648[0m[0m | time: 0.620s
[2K
| Adam | epoch: 020 | loss: 0.04648 - acc: 0.9898 -- iter: 0032/1105
[A[ATraining Step: 667  | total loss: [1m[32m0.05370[0m[0m | time: 1.239s
[2K
| Adam | epoch: 020 | loss: 0.05370 - acc: 0.9877 -- iter: 0064/1105
[A[ATraining Step: 668  | total loss: [1m[32m0.05841[0m[0m | time: 1.843s
[2K
| Adam | epoch: 020 | loss: 0.05841 - acc: 0.9858 -- iter: 0096/1105
[A[ATraining Step: 669  | total loss: [1m[32m0.05361[0m[0m | time: 2.454s
[2K
| Adam | epoch: 020 | loss: 0.05361 - acc: 0.9873 -- iter: 0128/1105
[A[ATraining Step: 670  | total loss: [1m[32m0.05566[0m[0m | time: 3.076s
[2K
| Adam | epoch: 020 | loss: 0.05566 - acc: 0.9854 -- iter: 0160/1105
[A[ATraining Step: 671  | total loss: [1m[32m0.05101[0m[0m | time: 3.686s
[2K
| Adam | epoch: 020 | loss: 0.05101 - acc: 0.9869 -- iter: 0192/1105
[A[ATraining Step: 672  | total loss: [1m[32m0.04686[0m[0m | time: 4.320s
[2K
| Adam | epoch: 020 | loss: 0.04686 - acc: 0.9882 -- iter: 0224/1105
[A[ATraining Step: 673  | total loss: [1m[32m0.04364[0m[0m | time: 5.079s
[2K
| Adam | epoch: 020 | loss: 0.04364 - acc: 0.9894 -- iter: 0256/1105
[A[ATraining Step: 674  | total loss: [1m[32m0.04018[0m[0m | time: 6.110s
[2K
| Adam | epoch: 020 | loss: 0.04018 - acc: 0.9904 -- iter: 0288/1105
[A[ATraining Step: 675  | total loss: [1m[32m0.03760[0m[0m | time: 7.220s
[2K
| Adam | epoch: 020 | loss: 0.03760 - acc: 0.9914 -- iter: 0320/1105
[A[ATraining Step: 676  | total loss: [1m[32m0.03474[0m[0m | time: 8.126s
[2K
| Adam | epoch: 020 | loss: 0.03474 - acc: 0.9922 -- iter: 0352/1105
[A[ATraining Step: 677  | total loss: [1m[32m0.04474[0m[0m | time: 9.036s
[2K
| Adam | epoch: 020 | loss: 0.04474 - acc: 0.9899 -- iter: 0384/1105
[A[ATraining Step: 678  | total loss: [1m[32m0.04095[0m[0m | time: 10.015s
[2K
| Adam | epoch: 020 | loss: 0.04095 - acc: 0.9909 -- iter: 0416/1105
[A[ATraining Step: 679  | total loss: [1m[32m0.03754[0m[0m | time: 10.996s
[2K
| Adam | epoch: 020 | loss: 0.03754 - acc: 0.9918 -- iter: 0448/1105
[A[ATraining Step: 680  | total loss: [1m[32m0.03439[0m[0m | time: 12.085s
[2K
| Adam | epoch: 020 | loss: 0.03439 - acc: 0.9926 -- iter: 0480/1105
[A[ATraining Step: 681  | total loss: [1m[32m0.03196[0m[0m | time: 13.152s
[2K
| Adam | epoch: 020 | loss: 0.03196 - acc: 0.9934 -- iter: 0512/1105
[A[ATraining Step: 682  | total loss: [1m[32m0.02926[0m[0m | time: 14.105s
[2K
| Adam | epoch: 020 | loss: 0.02926 - acc: 0.9940 -- iter: 0544/1105
[A[ATraining Step: 683  | total loss: [1m[32m0.02710[0m[0m | time: 14.592s
[2K
| Adam | epoch: 020 | loss: 0.02710 - acc: 0.9946 -- iter: 0576/1105
[A[ATraining Step: 684  | total loss: [1m[32m0.03766[0m[0m | time: 15.218s
[2K
| Adam | epoch: 020 | loss: 0.03766 - acc: 0.9893 -- iter: 0608/1105
[A[ATraining Step: 685  | total loss: [1m[32m0.03566[0m[0m | time: 16.343s
[2K
| Adam | epoch: 020 | loss: 0.03566 - acc: 0.9904 -- iter: 0640/1105
[A[ATraining Step: 686  | total loss: [1m[32m0.03769[0m[0m | time: 17.386s
[2K
| Adam | epoch: 020 | loss: 0.03769 - acc: 0.9882 -- iter: 0672/1105
[A[ATraining Step: 687  | total loss: [1m[32m0.03710[0m[0m | time: 18.290s
[2K
| Adam | epoch: 020 | loss: 0.03710 - acc: 0.9894 -- iter: 0704/1105
[A[ATraining Step: 688  | total loss: [1m[32m0.05091[0m[0m | time: 19.201s
[2K
| Adam | epoch: 020 | loss: 0.05091 - acc: 0.9873 -- iter: 0736/1105
[A[ATraining Step: 689  | total loss: [1m[32m0.04715[0m[0m | time: 20.135s
[2K
| Adam | epoch: 020 | loss: 0.04715 - acc: 0.9886 -- iter: 0768/1105
[A[ATraining Step: 690  | total loss: [1m[32m0.04953[0m[0m | time: 21.106s
[2K
| Adam | epoch: 020 | loss: 0.04953 - acc: 0.9866 -- iter: 0800/1105
[A[ATraining Step: 691  | total loss: [1m[32m0.04513[0m[0m | time: 22.171s
[2K
| Adam | epoch: 020 | loss: 0.04513 - acc: 0.9879 -- iter: 0832/1105
[A[ATraining Step: 692  | total loss: [1m[32m0.05523[0m[0m | time: 23.295s
[2K
| Adam | epoch: 020 | loss: 0.05523 - acc: 0.9860 -- iter: 0864/1105
[A[ATraining Step: 693  | total loss: [1m[32m0.05107[0m[0m | time: 24.199s
[2K
| Adam | epoch: 020 | loss: 0.05107 - acc: 0.9874 -- iter: 0896/1105
[A[ATraining Step: 694  | total loss: [1m[32m0.04781[0m[0m | time: 25.151s
[2K
| Adam | epoch: 020 | loss: 0.04781 - acc: 0.9887 -- iter: 0928/1105
[A[ATraining Step: 695  | total loss: [1m[32m0.04475[0m[0m | time: 26.189s
[2K
| Adam | epoch: 020 | loss: 0.04475 - acc: 0.9898 -- iter: 0960/1105
[A[ATraining Step: 696  | total loss: [1m[32m0.04660[0m[0m | time: 27.038s
[2K
| Adam | epoch: 020 | loss: 0.04660 - acc: 0.9846 -- iter: 0992/1105
[A[ATraining Step: 697  | total loss: [1m[32m0.04436[0m[0m | time: 27.985s
[2K
| Adam | epoch: 020 | loss: 0.04436 - acc: 0.9861 -- iter: 1024/1105
[A[ATraining Step: 698  | total loss: [1m[32m0.04175[0m[0m | time: 28.919s
[2K
| Adam | epoch: 020 | loss: 0.04175 - acc: 0.9875 -- iter: 1056/1105
[A[ATraining Step: 699  | total loss: [1m[32m0.04372[0m[0m | time: 29.865s
[2K
| Adam | epoch: 020 | loss: 0.04372 - acc: 0.9856 -- iter: 1088/1105
[A[ATraining Step: 700  | total loss: [1m[32m0.04002[0m[0m | time: 32.504s
[2K
| Adam | epoch: 020 | loss: 0.04002 - acc: 0.9871 | val_loss: 0.63382 - val_acc: 0.8150 -- iter: 1105/1105
--
Training Step: 701  | total loss: [1m[32m0.04077[0m[0m | time: 0.889s
[2K
| Adam | epoch: 021 | loss: 0.04077 - acc: 0.9852 -- iter: 0032/1105
[A[ATraining Step: 702  | total loss: [1m[32m0.03735[0m[0m | time: 1.764s
[2K
| Adam | epoch: 021 | loss: 0.03735 - acc: 0.9867 -- iter: 0064/1105
[A[ATraining Step: 703  | total loss: [1m[32m0.06901[0m[0m | time: 2.725s
[2K
| Adam | epoch: 021 | loss: 0.06901 - acc: 0.9849 -- iter: 0096/1105
[A[ATraining Step: 704  | total loss: [1m[32m0.07717[0m[0m | time: 3.665s
[2K
| Adam | epoch: 021 | loss: 0.07717 - acc: 0.9833 -- iter: 0128/1105
[A[ATraining Step: 705  | total loss: [1m[32m0.07409[0m[0m | time: 4.796s
[2K
| Adam | epoch: 021 | loss: 0.07409 - acc: 0.9818 -- iter: 0160/1105
[A[ATraining Step: 706  | total loss: [1m[32m0.06717[0m[0m | time: 5.926s
[2K
| Adam | epoch: 021 | loss: 0.06717 - acc: 0.9837 -- iter: 0192/1105
[A[ATraining Step: 707  | total loss: [1m[32m0.06162[0m[0m | time: 6.872s
[2K
| Adam | epoch: 021 | loss: 0.06162 - acc: 0.9853 -- iter: 0224/1105
[A[ATraining Step: 708  | total loss: [1m[32m0.05777[0m[0m | time: 7.766s
[2K
| Adam | epoch: 021 | loss: 0.05777 - acc: 0.9868 -- iter: 0256/1105
[A[ATraining Step: 709  | total loss: [1m[32m0.06099[0m[0m | time: 8.825s
[2K
| Adam | epoch: 021 | loss: 0.06099 - acc: 0.9850 -- iter: 0288/1105
[A[ATraining Step: 710  | total loss: [1m[32m0.05699[0m[0m | time: 9.786s
[2K
| Adam | epoch: 021 | loss: 0.05699 - acc: 0.9865 -- iter: 0320/1105
[A[ATraining Step: 711  | total loss: [1m[32m0.06308[0m[0m | time: 10.879s
[2K
| Adam | epoch: 021 | loss: 0.06308 - acc: 0.9847 -- iter: 0352/1105
[A[ATraining Step: 712  | total loss: [1m[32m0.05786[0m[0m | time: 11.987s
[2K
| Adam | epoch: 021 | loss: 0.05786 - acc: 0.9862 -- iter: 0384/1105
[A[ATraining Step: 713  | total loss: [1m[32m0.05284[0m[0m | time: 12.933s
[2K
| Adam | epoch: 021 | loss: 0.05284 - acc: 0.9876 -- iter: 0416/1105
[A[ATraining Step: 714  | total loss: [1m[32m0.05356[0m[0m | time: 13.930s
[2K
| Adam | epoch: 021 | loss: 0.05356 - acc: 0.9857 -- iter: 0448/1105
[A[ATraining Step: 715  | total loss: [1m[32m0.04914[0m[0m | time: 15.018s
[2K
| Adam | epoch: 021 | loss: 0.04914 - acc: 0.9871 -- iter: 0480/1105
[A[ATraining Step: 716  | total loss: [1m[32m0.04542[0m[0m | time: 16.090s
[2K
| Adam | epoch: 021 | loss: 0.04542 - acc: 0.9884 -- iter: 0512/1105
[A[ATraining Step: 717  | total loss: [1m[32m0.04691[0m[0m | time: 16.951s
[2K
| Adam | epoch: 021 | loss: 0.04691 - acc: 0.9865 -- iter: 0544/1105
[A[ATraining Step: 718  | total loss: [1m[32m0.04532[0m[0m | time: 17.871s
[2K
| Adam | epoch: 021 | loss: 0.04532 - acc: 0.9878 -- iter: 0576/1105
[A[ATraining Step: 719  | total loss: [1m[32m0.04375[0m[0m | time: 18.435s
[2K
| Adam | epoch: 021 | loss: 0.04375 - acc: 0.9890 -- iter: 0608/1105
[A[ATraining Step: 720  | total loss: [1m[32m0.04053[0m[0m | time: 18.978s
[2K
| Adam | epoch: 021 | loss: 0.04053 - acc: 0.9901 -- iter: 0640/1105
[A[ATraining Step: 721  | total loss: [1m[32m0.03948[0m[0m | time: 19.975s
[2K
| Adam | epoch: 021 | loss: 0.03948 - acc: 0.9911 -- iter: 0672/1105
[A[ATraining Step: 722  | total loss: [1m[32m0.03888[0m[0m | time: 21.042s
[2K
| Adam | epoch: 021 | loss: 0.03888 - acc: 0.9920 -- iter: 0704/1105
[A[ATraining Step: 723  | total loss: [1m[32m0.03851[0m[0m | time: 22.088s
[2K
| Adam | epoch: 021 | loss: 0.03851 - acc: 0.9928 -- iter: 0736/1105
[A[ATraining Step: 724  | total loss: [1m[32m0.11572[0m[0m | time: 22.994s
[2K
| Adam | epoch: 021 | loss: 0.11572 - acc: 0.9779 -- iter: 0768/1105
[A[ATraining Step: 725  | total loss: [1m[32m0.11328[0m[0m | time: 24.043s
[2K
| Adam | epoch: 021 | loss: 0.11328 - acc: 0.9770 -- iter: 0800/1105
[A[ATraining Step: 726  | total loss: [1m[32m0.10331[0m[0m | time: 25.100s
[2K
| Adam | epoch: 021 | loss: 0.10331 - acc: 0.9793 -- iter: 0832/1105
[A[ATraining Step: 727  | total loss: [1m[32m0.09391[0m[0m | time: 26.144s
[2K
| Adam | epoch: 021 | loss: 0.09391 - acc: 0.9814 -- iter: 0864/1105
[A[ATraining Step: 728  | total loss: [1m[32m0.09160[0m[0m | time: 26.963s
[2K
| Adam | epoch: 021 | loss: 0.09160 - acc: 0.9801 -- iter: 0896/1105
[A[ATraining Step: 729  | total loss: [1m[32m0.08314[0m[0m | time: 27.918s
[2K
| Adam | epoch: 021 | loss: 0.08314 - acc: 0.9821 -- iter: 0928/1105
[A[ATraining Step: 730  | total loss: [1m[32m0.07600[0m[0m | time: 28.949s
[2K
| Adam | epoch: 021 | loss: 0.07600 - acc: 0.9839 -- iter: 0960/1105
[A[ATraining Step: 731  | total loss: [1m[32m0.07993[0m[0m | time: 30.031s
[2K
| Adam | epoch: 021 | loss: 0.07993 - acc: 0.9792 -- iter: 0992/1105
[A[ATraining Step: 732  | total loss: [1m[32m0.07376[0m[0m | time: 31.080s
[2K
| Adam | epoch: 021 | loss: 0.07376 - acc: 0.9813 -- iter: 1024/1105
[A[ATraining Step: 733  | total loss: [1m[32m0.08326[0m[0m | time: 32.164s
[2K
| Adam | epoch: 021 | loss: 0.08326 - acc: 0.9801 -- iter: 1056/1105
[A[ATraining Step: 734  | total loss: [1m[32m0.09122[0m[0m | time: 33.031s
[2K
| Adam | epoch: 021 | loss: 0.09122 - acc: 0.9789 -- iter: 1088/1105
[A[ATraining Step: 735  | total loss: [1m[32m0.08359[0m[0m | time: 35.874s
[2K
| Adam | epoch: 021 | loss: 0.08359 - acc: 0.9810 | val_loss: 0.62808 - val_acc: 0.8035 -- iter: 1105/1105
--
Training Step: 736  | total loss: [1m[32m0.08488[0m[0m | time: 0.955s
[2K
| Adam | epoch: 022 | loss: 0.08488 - acc: 0.9798 -- iter: 0032/1105
[A[ATraining Step: 737  | total loss: [1m[32m0.07887[0m[0m | time: 1.847s
[2K
| Adam | epoch: 022 | loss: 0.07887 - acc: 0.9818 -- iter: 0064/1105
[A[ATraining Step: 738  | total loss: [1m[32m0.07252[0m[0m | time: 2.894s
[2K
| Adam | epoch: 022 | loss: 0.07252 - acc: 0.9836 -- iter: 0096/1105
[A[ATraining Step: 739  | total loss: [1m[32m0.06639[0m[0m | time: 3.891s
[2K
| Adam | epoch: 022 | loss: 0.06639 - acc: 0.9853 -- iter: 0128/1105
[A[ATraining Step: 740  | total loss: [1m[32m0.07084[0m[0m | time: 4.857s
[2K
| Adam | epoch: 022 | loss: 0.07084 - acc: 0.9836 -- iter: 0160/1105
[A[ATraining Step: 741  | total loss: [1m[32m0.07260[0m[0m | time: 5.885s
[2K
| Adam | epoch: 022 | loss: 0.07260 - acc: 0.9821 -- iter: 0192/1105
[A[ATraining Step: 742  | total loss: [1m[32m0.06659[0m[0m | time: 6.895s
[2K
| Adam | epoch: 022 | loss: 0.06659 - acc: 0.9839 -- iter: 0224/1105
[A[ATraining Step: 743  | total loss: [1m[32m0.06098[0m[0m | time: 7.778s
[2K
| Adam | epoch: 022 | loss: 0.06098 - acc: 0.9855 -- iter: 0256/1105
[A[ATraining Step: 744  | total loss: [1m[32m0.05725[0m[0m | time: 8.944s
[2K
| Adam | epoch: 022 | loss: 0.05725 - acc: 0.9870 -- iter: 0288/1105
[A[ATraining Step: 745  | total loss: [1m[32m0.05292[0m[0m | time: 10.034s
[2K
| Adam | epoch: 022 | loss: 0.05292 - acc: 0.9883 -- iter: 0320/1105
[A[ATraining Step: 746  | total loss: [1m[32m0.04857[0m[0m | time: 10.906s
[2K
| Adam | epoch: 022 | loss: 0.04857 - acc: 0.9895 -- iter: 0352/1105
[A[ATraining Step: 747  | total loss: [1m[32m0.04548[0m[0m | time: 11.887s
[2K
| Adam | epoch: 022 | loss: 0.04548 - acc: 0.9905 -- iter: 0384/1105
[A[ATraining Step: 748  | total loss: [1m[32m0.04497[0m[0m | time: 12.876s
[2K
| Adam | epoch: 022 | loss: 0.04497 - acc: 0.9883 -- iter: 0416/1105
[A[ATraining Step: 749  | total loss: [1m[32m0.04259[0m[0m | time: 13.852s
[2K
| Adam | epoch: 022 | loss: 0.04259 - acc: 0.9895 -- iter: 0448/1105
[A[ATraining Step: 750  | total loss: [1m[32m0.04477[0m[0m | time: 14.877s
[2K
| Adam | epoch: 022 | loss: 0.04477 - acc: 0.9874 -- iter: 0480/1105
[A[ATraining Step: 751  | total loss: [1m[32m0.04895[0m[0m | time: 15.969s
[2K
| Adam | epoch: 022 | loss: 0.04895 - acc: 0.9856 -- iter: 0512/1105
[A[ATraining Step: 752  | total loss: [1m[32m0.04604[0m[0m | time: 16.862s
[2K
| Adam | epoch: 022 | loss: 0.04604 - acc: 0.9870 -- iter: 0544/1105
[A[ATraining Step: 753  | total loss: [1m[32m0.04363[0m[0m | time: 17.832s
[2K
| Adam | epoch: 022 | loss: 0.04363 - acc: 0.9883 -- iter: 0576/1105
[A[ATraining Step: 754  | total loss: [1m[32m0.04139[0m[0m | time: 19.019s
[2K
| Adam | epoch: 022 | loss: 0.04139 - acc: 0.9895 -- iter: 0608/1105
[A[ATraining Step: 755  | total loss: [1m[32m0.03910[0m[0m | time: 19.738s
[2K
| Adam | epoch: 022 | loss: 0.03910 - acc: 0.9905 -- iter: 0640/1105
[A[ATraining Step: 756  | total loss: [1m[32m0.03598[0m[0m | time: 20.348s
[2K
| Adam | epoch: 022 | loss: 0.03598 - acc: 0.9915 -- iter: 0672/1105
[A[ATraining Step: 757  | total loss: [1m[32m0.03307[0m[0m | time: 21.239s
[2K
| Adam | epoch: 022 | loss: 0.03307 - acc: 0.9923 -- iter: 0704/1105
[A[ATraining Step: 758  | total loss: [1m[32m0.03034[0m[0m | time: 22.201s
[2K
| Adam | epoch: 022 | loss: 0.03034 - acc: 0.9931 -- iter: 0736/1105
[A[ATraining Step: 759  | total loss: [1m[32m0.06036[0m[0m | time: 23.174s
[2K
| Adam | epoch: 022 | loss: 0.06036 - acc: 0.9844 -- iter: 0768/1105
[A[ATraining Step: 760  | total loss: [1m[32m0.08078[0m[0m | time: 24.187s
[2K
| Adam | epoch: 022 | loss: 0.08078 - acc: 0.9797 -- iter: 0800/1105
[A[ATraining Step: 761  | total loss: [1m[32m0.07325[0m[0m | time: 25.298s
[2K
| Adam | epoch: 022 | loss: 0.07325 - acc: 0.9817 -- iter: 0832/1105
[A[ATraining Step: 762  | total loss: [1m[32m0.07222[0m[0m | time: 26.267s
[2K
| Adam | epoch: 022 | loss: 0.07222 - acc: 0.9804 -- iter: 0864/1105
[A[ATraining Step: 763  | total loss: [1m[32m0.08558[0m[0m | time: 27.184s
[2K
| Adam | epoch: 022 | loss: 0.08558 - acc: 0.9793 -- iter: 0896/1105
[A[ATraining Step: 764  | total loss: [1m[32m0.07829[0m[0m | time: 28.276s
[2K
| Adam | epoch: 022 | loss: 0.07829 - acc: 0.9813 -- iter: 0928/1105
[A[ATraining Step: 765  | total loss: [1m[32m0.08117[0m[0m | time: 29.371s
[2K
| Adam | epoch: 022 | loss: 0.08117 - acc: 0.9801 -- iter: 0960/1105
[A[ATraining Step: 766  | total loss: [1m[32m0.07388[0m[0m | time: 30.331s
[2K
| Adam | epoch: 022 | loss: 0.07388 - acc: 0.9821 -- iter: 0992/1105
[A[ATraining Step: 767  | total loss: [1m[32m0.06964[0m[0m | time: 31.231s
[2K
| Adam | epoch: 022 | loss: 0.06964 - acc: 0.9839 -- iter: 1024/1105
[A[ATraining Step: 768  | total loss: [1m[32m0.06457[0m[0m | time: 32.278s
[2K
| Adam | epoch: 022 | loss: 0.06457 - acc: 0.9855 -- iter: 1056/1105
[A[ATraining Step: 769  | total loss: [1m[32m0.08316[0m[0m | time: 33.250s
[2K
| Adam | epoch: 022 | loss: 0.08316 - acc: 0.9776 -- iter: 1088/1105
[A[ATraining Step: 770  | total loss: [1m[32m0.08381[0m[0m | time: 36.273s
[2K
| Adam | epoch: 022 | loss: 0.08381 - acc: 0.9736 | val_loss: 0.73264 - val_acc: 0.7948 -- iter: 1105/1105
--
Training Step: 771  | total loss: [1m[32m0.08027[0m[0m | time: 0.943s
[2K
| Adam | epoch: 023 | loss: 0.08027 - acc: 0.9762 -- iter: 0032/1105
[A[ATraining Step: 772  | total loss: [1m[32m0.08028[0m[0m | time: 2.077s
[2K
| Adam | epoch: 023 | loss: 0.08028 - acc: 0.9755 -- iter: 0064/1105
[A[ATraining Step: 773  | total loss: [1m[32m0.07391[0m[0m | time: 3.186s
[2K
| Adam | epoch: 023 | loss: 0.07391 - acc: 0.9779 -- iter: 0096/1105
[A[ATraining Step: 774  | total loss: [1m[32m0.07144[0m[0m | time: 4.025s
[2K
| Adam | epoch: 023 | loss: 0.07144 - acc: 0.9801 -- iter: 0128/1105
[A[ATraining Step: 775  | total loss: [1m[32m0.06971[0m[0m | time: 4.959s
[2K
| Adam | epoch: 023 | loss: 0.06971 - acc: 0.9821 -- iter: 0160/1105
[A[ATraining Step: 776  | total loss: [1m[32m0.07808[0m[0m | time: 5.955s
[2K
| Adam | epoch: 023 | loss: 0.07808 - acc: 0.9808 -- iter: 0192/1105
[A[ATraining Step: 777  | total loss: [1m[32m0.07191[0m[0m | time: 6.957s
[2K
| Adam | epoch: 023 | loss: 0.07191 - acc: 0.9827 -- iter: 0224/1105
[A[ATraining Step: 778  | total loss: [1m[32m0.06776[0m[0m | time: 8.076s
[2K
| Adam | epoch: 023 | loss: 0.06776 - acc: 0.9844 -- iter: 0256/1105
[A[ATraining Step: 779  | total loss: [1m[32m0.07508[0m[0m | time: 9.179s
[2K
| Adam | epoch: 023 | loss: 0.07508 - acc: 0.9797 -- iter: 0288/1105
[A[ATraining Step: 780  | total loss: [1m[32m0.06848[0m[0m | time: 10.041s
[2K
| Adam | epoch: 023 | loss: 0.06848 - acc: 0.9818 -- iter: 0320/1105
[A[ATraining Step: 781  | total loss: [1m[32m0.06304[0m[0m | time: 10.956s
[2K
| Adam | epoch: 023 | loss: 0.06304 - acc: 0.9836 -- iter: 0352/1105
[A[ATraining Step: 782  | total loss: [1m[32m0.06991[0m[0m | time: 12.042s
[2K
| Adam | epoch: 023 | loss: 0.06991 - acc: 0.9790 -- iter: 0384/1105
[A[ATraining Step: 783  | total loss: [1m[32m0.06892[0m[0m | time: 13.155s
[2K
| Adam | epoch: 023 | loss: 0.06892 - acc: 0.9780 -- iter: 0416/1105
[A[ATraining Step: 784  | total loss: [1m[32m0.07892[0m[0m | time: 13.995s
[2K
| Adam | epoch: 023 | loss: 0.07892 - acc: 0.9770 -- iter: 0448/1105
[A[ATraining Step: 785  | total loss: [1m[32m0.07215[0m[0m | time: 14.920s
[2K
| Adam | epoch: 023 | loss: 0.07215 - acc: 0.9793 -- iter: 0480/1105
[A[ATraining Step: 786  | total loss: [1m[32m0.06587[0m[0m | time: 15.871s
[2K
| Adam | epoch: 023 | loss: 0.06587 - acc: 0.9814 -- iter: 0512/1105
[A[ATraining Step: 787  | total loss: [1m[32m0.06105[0m[0m | time: 16.891s
[2K
| Adam | epoch: 023 | loss: 0.06105 - acc: 0.9833 -- iter: 0544/1105
[A[ATraining Step: 788  | total loss: [1m[32m0.05670[0m[0m | time: 17.955s
[2K
| Adam | epoch: 023 | loss: 0.05670 - acc: 0.9849 -- iter: 0576/1105
[A[ATraining Step: 789  | total loss: [1m[32m0.06336[0m[0m | time: 19.099s
[2K
| Adam | epoch: 023 | loss: 0.06336 - acc: 0.9802 -- iter: 0608/1105
[A[ATraining Step: 790  | total loss: [1m[32m0.06071[0m[0m | time: 20.028s
[2K
| Adam | epoch: 023 | loss: 0.06071 - acc: 0.9822 -- iter: 0640/1105
[A[ATraining Step: 791  | total loss: [1m[32m0.06391[0m[0m | time: 20.593s
[2K
| Adam | epoch: 023 | loss: 0.06391 - acc: 0.9808 -- iter: 0672/1105
[A[ATraining Step: 792  | total loss: [1m[32m0.05799[0m[0m | time: 21.292s
[2K
| Adam | epoch: 023 | loss: 0.05799 - acc: 0.9827 -- iter: 0704/1105
[A[ATraining Step: 793  | total loss: [1m[32m0.05255[0m[0m | time: 22.405s
[2K
| Adam | epoch: 023 | loss: 0.05255 - acc: 0.9845 -- iter: 0736/1105
[A[ATraining Step: 794  | total loss: [1m[32m0.04813[0m[0m | time: 23.445s
[2K
| Adam | epoch: 023 | loss: 0.04813 - acc: 0.9860 -- iter: 0768/1105
[A[ATraining Step: 795  | total loss: [1m[32m0.06264[0m[0m | time: 24.265s
[2K
| Adam | epoch: 023 | loss: 0.06264 - acc: 0.9780 -- iter: 0800/1105
[A[ATraining Step: 796  | total loss: [1m[32m0.16014[0m[0m | time: 25.162s
[2K
| Adam | epoch: 023 | loss: 0.16014 - acc: 0.9584 -- iter: 0832/1105
[A[ATraining Step: 797  | total loss: [1m[32m0.14936[0m[0m | time: 26.141s
[2K
| Adam | epoch: 023 | loss: 0.14936 - acc: 0.9625 -- iter: 0864/1105
[A[ATraining Step: 798  | total loss: [1m[32m0.13643[0m[0m | time: 27.205s
[2K
| Adam | epoch: 023 | loss: 0.13643 - acc: 0.9663 -- iter: 0896/1105
[A[ATraining Step: 799  | total loss: [1m[32m0.13678[0m[0m | time: 28.259s
[2K
| Adam | epoch: 023 | loss: 0.13678 - acc: 0.9634 -- iter: 0928/1105
[A[ATraining Step: 800  | total loss: [1m[32m0.12380[0m[0m | time: 30.921s
[2K
| Adam | epoch: 023 | loss: 0.12380 - acc: 0.9671 | val_loss: 0.65390 - val_acc: 0.7890 -- iter: 0960/1105
--
Training Step: 801  | total loss: [1m[32m0.11277[0m[0m | time: 32.017s
[2K
| Adam | epoch: 023 | loss: 0.11277 - acc: 0.9704 -- iter: 0992/1105
[A[ATraining Step: 802  | total loss: [1m[32m0.10621[0m[0m | time: 33.132s
[2K
| Adam | epoch: 023 | loss: 0.10621 - acc: 0.9702 -- iter: 1024/1105
[A[ATraining Step: 803  | total loss: [1m[32m0.09774[0m[0m | time: 34.048s
[2K
| Adam | epoch: 023 | loss: 0.09774 - acc: 0.9732 -- iter: 1056/1105
[A[ATraining Step: 804  | total loss: [1m[32m0.09492[0m[0m | time: 34.976s
[2K
| Adam | epoch: 023 | loss: 0.09492 - acc: 0.9727 -- iter: 1088/1105
[A[ATraining Step: 805  | total loss: [1m[32m0.08738[0m[0m | time: 37.676s
[2K
| Adam | epoch: 023 | loss: 0.08738 - acc: 0.9755 | val_loss: 0.59668 - val_acc: 0.8006 -- iter: 1105/1105
--
Training Step: 806  | total loss: [1m[32m0.08571[0m[0m | time: 1.139s
[2K
| Adam | epoch: 024 | loss: 0.08571 - acc: 0.9748 -- iter: 0032/1105
[A[ATraining Step: 807  | total loss: [1m[32m0.07953[0m[0m | time: 2.155s
[2K
| Adam | epoch: 024 | loss: 0.07953 - acc: 0.9773 -- iter: 0064/1105
[A[ATraining Step: 808  | total loss: [1m[32m0.08148[0m[0m | time: 2.988s
[2K
| Adam | epoch: 024 | loss: 0.08148 - acc: 0.9765 -- iter: 0096/1105
[A[ATraining Step: 809  | total loss: [1m[32m0.07538[0m[0m | time: 4.111s
[2K
| Adam | epoch: 024 | loss: 0.07538 - acc: 0.9788 -- iter: 0128/1105
[A[ATraining Step: 810  | total loss: [1m[32m0.07502[0m[0m | time: 5.236s
[2K
| Adam | epoch: 024 | loss: 0.07502 - acc: 0.9778 -- iter: 0160/1105
[A[ATraining Step: 811  | total loss: [1m[32m0.06971[0m[0m | time: 6.197s
[2K
| Adam | epoch: 024 | loss: 0.06971 - acc: 0.9800 -- iter: 0192/1105
[A[ATraining Step: 812  | total loss: [1m[32m0.06564[0m[0m | time: 7.127s
[2K
| Adam | epoch: 024 | loss: 0.06564 - acc: 0.9820 -- iter: 0224/1105
[A[ATraining Step: 813  | total loss: [1m[32m0.06063[0m[0m | time: 8.158s
[2K
| Adam | epoch: 024 | loss: 0.06063 - acc: 0.9838 -- iter: 0256/1105
[A[ATraining Step: 814  | total loss: [1m[32m0.05965[0m[0m | time: 9.100s
[2K
| Adam | epoch: 024 | loss: 0.05965 - acc: 0.9823 -- iter: 0288/1105
[A[ATraining Step: 815  | total loss: [1m[32m0.05526[0m[0m | time: 10.089s
[2K
| Adam | epoch: 024 | loss: 0.05526 - acc: 0.9841 -- iter: 0320/1105
[A[ATraining Step: 816  | total loss: [1m[32m0.06817[0m[0m | time: 11.184s
[2K
| Adam | epoch: 024 | loss: 0.06817 - acc: 0.9794 -- iter: 0352/1105
[A[ATraining Step: 817  | total loss: [1m[32m0.07777[0m[0m | time: 12.180s
[2K
| Adam | epoch: 024 | loss: 0.07777 - acc: 0.9784 -- iter: 0384/1105
[A[ATraining Step: 818  | total loss: [1m[32m0.08302[0m[0m | time: 13.111s
[2K
| Adam | epoch: 024 | loss: 0.08302 - acc: 0.9743 -- iter: 0416/1105
[A[ATraining Step: 819  | total loss: [1m[32m0.07645[0m[0m | time: 14.186s
[2K
| Adam | epoch: 024 | loss: 0.07645 - acc: 0.9768 -- iter: 0448/1105
[A[ATraining Step: 820  | total loss: [1m[32m0.08284[0m[0m | time: 15.310s
[2K
| Adam | epoch: 024 | loss: 0.08284 - acc: 0.9760 -- iter: 0480/1105
[A[ATraining Step: 821  | total loss: [1m[32m0.07701[0m[0m | time: 16.204s
[2K
| Adam | epoch: 024 | loss: 0.07701 - acc: 0.9784 -- iter: 0512/1105
[A[ATraining Step: 822  | total loss: [1m[32m0.07023[0m[0m | time: 17.175s
[2K
| Adam | epoch: 024 | loss: 0.07023 - acc: 0.9806 -- iter: 0544/1105
[A[ATraining Step: 823  | total loss: [1m[32m0.06688[0m[0m | time: 18.157s
[2K
| Adam | epoch: 024 | loss: 0.06688 - acc: 0.9825 -- iter: 0576/1105
[A[ATraining Step: 824  | total loss: [1m[32m0.06110[0m[0m | time: 19.144s
[2K
| Adam | epoch: 024 | loss: 0.06110 - acc: 0.9843 -- iter: 0608/1105
[A[ATraining Step: 825  | total loss: [1m[32m0.06029[0m[0m | time: 20.245s
[2K
| Adam | epoch: 024 | loss: 0.06029 - acc: 0.9827 -- iter: 0640/1105
[A[ATraining Step: 826  | total loss: [1m[32m0.06998[0m[0m | time: 21.347s
[2K
| Adam | epoch: 024 | loss: 0.06998 - acc: 0.9782 -- iter: 0672/1105
[A[ATraining Step: 827  | total loss: [1m[32m0.06417[0m[0m | time: 21.873s
[2K
| Adam | epoch: 024 | loss: 0.06417 - acc: 0.9804 -- iter: 0704/1105
[A[ATraining Step: 828  | total loss: [1m[32m0.05981[0m[0m | time: 22.375s
[2K
| Adam | epoch: 024 | loss: 0.05981 - acc: 0.9823 -- iter: 0736/1105
[A[ATraining Step: 829  | total loss: [1m[32m0.05517[0m[0m | time: 23.544s
[2K
| Adam | epoch: 024 | loss: 0.05517 - acc: 0.9841 -- iter: 0768/1105
[A[ATraining Step: 830  | total loss: [1m[32m0.05041[0m[0m | time: 24.664s
[2K
| Adam | epoch: 024 | loss: 0.05041 - acc: 0.9857 -- iter: 0800/1105
[A[ATraining Step: 831  | total loss: [1m[32m0.04709[0m[0m | time: 25.607s
[2K
| Adam | epoch: 024 | loss: 0.04709 - acc: 0.9871 -- iter: 0832/1105
[A[ATraining Step: 832  | total loss: [1m[32m0.07381[0m[0m | time: 26.493s
[2K
| Adam | epoch: 024 | loss: 0.07381 - acc: 0.9822 -- iter: 0864/1105
[A[ATraining Step: 833  | total loss: [1m[32m0.06740[0m[0m | time: 27.427s
[2K
| Adam | epoch: 024 | loss: 0.06740 - acc: 0.9839 -- iter: 0896/1105
[A[ATraining Step: 834  | total loss: [1m[32m0.06136[0m[0m | time: 28.381s
[2K
| Adam | epoch: 024 | loss: 0.06136 - acc: 0.9856 -- iter: 0928/1105
[A[ATraining Step: 835  | total loss: [1m[32m0.05584[0m[0m | time: 29.344s
[2K
| Adam | epoch: 024 | loss: 0.05584 - acc: 0.9870 -- iter: 0960/1105
[A[ATraining Step: 836  | total loss: [1m[32m0.05201[0m[0m | time: 30.416s
[2K
| Adam | epoch: 024 | loss: 0.05201 - acc: 0.9883 -- iter: 0992/1105
[A[ATraining Step: 837  | total loss: [1m[32m0.05131[0m[0m | time: 31.453s
[2K
| Adam | epoch: 024 | loss: 0.05131 - acc: 0.9863 -- iter: 1024/1105
[A[ATraining Step: 838  | total loss: [1m[32m0.04855[0m[0m | time: 32.314s
[2K
| Adam | epoch: 024 | loss: 0.04855 - acc: 0.9877 -- iter: 1056/1105
[A[ATraining Step: 839  | total loss: [1m[32m0.05359[0m[0m | time: 33.470s
[2K
| Adam | epoch: 024 | loss: 0.05359 - acc: 0.9858 -- iter: 1088/1105
[A[ATraining Step: 840  | total loss: [1m[32m0.05143[0m[0m | time: 36.207s
[2K
| Adam | epoch: 024 | loss: 0.05143 - acc: 0.9841 | val_loss: 0.72672 - val_acc: 0.8121 -- iter: 1105/1105
--
Training Step: 841  | total loss: [1m[32m0.04666[0m[0m | time: 0.968s
[2K
| Adam | epoch: 025 | loss: 0.04666 - acc: 0.9857 -- iter: 0032/1105
[A[ATraining Step: 842  | total loss: [1m[32m0.04392[0m[0m | time: 1.933s
[2K
| Adam | epoch: 025 | loss: 0.04392 - acc: 0.9871 -- iter: 0064/1105
[A[ATraining Step: 843  | total loss: [1m[32m0.04134[0m[0m | time: 2.919s
[2K
| Adam | epoch: 025 | loss: 0.04134 - acc: 0.9884 -- iter: 0096/1105
[A[ATraining Step: 844  | total loss: [1m[32m0.04005[0m[0m | time: 4.026s
[2K
| Adam | epoch: 025 | loss: 0.04005 - acc: 0.9896 -- iter: 0128/1105
[A[ATraining Step: 845  | total loss: [1m[32m0.03859[0m[0m | time: 5.116s
[2K
| Adam | epoch: 025 | loss: 0.03859 - acc: 0.9906 -- iter: 0160/1105
[A[ATraining Step: 846  | total loss: [1m[32m0.03550[0m[0m | time: 5.987s
[2K
| Adam | epoch: 025 | loss: 0.03550 - acc: 0.9916 -- iter: 0192/1105
[A[ATraining Step: 847  | total loss: [1m[32m0.03256[0m[0m | time: 7.133s
[2K
| Adam | epoch: 025 | loss: 0.03256 - acc: 0.9924 -- iter: 0224/1105
[A[ATraining Step: 848  | total loss: [1m[32m0.02993[0m[0m | time: 8.257s
[2K
| Adam | epoch: 025 | loss: 0.02993 - acc: 0.9932 -- iter: 0256/1105
[A[ATraining Step: 849  | total loss: [1m[32m0.02750[0m[0m | time: 9.195s
[2K
| Adam | epoch: 025 | loss: 0.02750 - acc: 0.9938 -- iter: 0288/1105
[A[ATraining Step: 850  | total loss: [1m[32m0.02636[0m[0m | time: 10.081s
[2K
| Adam | epoch: 025 | loss: 0.02636 - acc: 0.9945 -- iter: 0320/1105
[A[ATraining Step: 851  | total loss: [1m[32m0.03565[0m[0m | time: 11.080s
[2K
| Adam | epoch: 025 | loss: 0.03565 - acc: 0.9919 -- iter: 0352/1105
[A[ATraining Step: 852  | total loss: [1m[32m0.04348[0m[0m | time: 12.043s
[2K
| Adam | epoch: 025 | loss: 0.04348 - acc: 0.9896 -- iter: 0384/1105
[A[ATraining Step: 853  | total loss: [1m[32m0.04315[0m[0m | time: 13.096s
[2K
| Adam | epoch: 025 | loss: 0.04315 - acc: 0.9875 -- iter: 0416/1105
[A[ATraining Step: 854  | total loss: [1m[32m0.03954[0m[0m | time: 14.214s
[2K
| Adam | epoch: 025 | loss: 0.03954 - acc: 0.9887 -- iter: 0448/1105
[A[ATraining Step: 855  | total loss: [1m[32m0.03618[0m[0m | time: 15.201s
[2K
| Adam | epoch: 025 | loss: 0.03618 - acc: 0.9899 -- iter: 0480/1105
[A[ATraining Step: 856  | total loss: [1m[32m0.03363[0m[0m | time: 16.200s
[2K
| Adam | epoch: 025 | loss: 0.03363 - acc: 0.9909 -- iter: 0512/1105
[A[ATraining Step: 857  | total loss: [1m[32m0.03082[0m[0m | time: 17.260s
[2K
| Adam | epoch: 025 | loss: 0.03082 - acc: 0.9918 -- iter: 0544/1105
[A[ATraining Step: 858  | total loss: [1m[32m0.04945[0m[0m | time: 18.262s
[2K
| Adam | epoch: 025 | loss: 0.04945 - acc: 0.9864 -- iter: 0576/1105
[A[ATraining Step: 859  | total loss: [1m[32m0.04490[0m[0m | time: 19.241s
[2K
| Adam | epoch: 025 | loss: 0.04490 - acc: 0.9877 -- iter: 0608/1105
[A[ATraining Step: 860  | total loss: [1m[32m0.04105[0m[0m | time: 20.283s
[2K
| Adam | epoch: 025 | loss: 0.04105 - acc: 0.9890 -- iter: 0640/1105
[A[ATraining Step: 861  | total loss: [1m[32m0.03736[0m[0m | time: 21.269s
[2K
| Adam | epoch: 025 | loss: 0.03736 - acc: 0.9901 -- iter: 0672/1105
[A[ATraining Step: 862  | total loss: [1m[32m0.03414[0m[0m | time: 22.419s
[2K
| Adam | epoch: 025 | loss: 0.03414 - acc: 0.9911 -- iter: 0704/1105
[A[ATraining Step: 863  | total loss: [1m[32m0.03178[0m[0m | time: 23.091s
[2K
| Adam | epoch: 025 | loss: 0.03178 - acc: 0.9919 -- iter: 0736/1105
[A[ATraining Step: 864  | total loss: [1m[32m0.02891[0m[0m | time: 23.693s
[2K
| Adam | epoch: 025 | loss: 0.02891 - acc: 0.9928 -- iter: 0768/1105
[A[ATraining Step: 865  | total loss: [1m[32m0.02632[0m[0m | time: 24.699s
[2K
| Adam | epoch: 025 | loss: 0.02632 - acc: 0.9935 -- iter: 0800/1105
[A[ATraining Step: 866  | total loss: [1m[32m0.02801[0m[0m | time: 25.772s
[2K
| Adam | epoch: 025 | loss: 0.02801 - acc: 0.9910 -- iter: 0832/1105
[A[ATraining Step: 867  | total loss: [1m[32m0.02548[0m[0m | time: 26.755s
[2K
| Adam | epoch: 025 | loss: 0.02548 - acc: 0.9919 -- iter: 0864/1105
[A[ATraining Step: 868  | total loss: [1m[32m0.05622[0m[0m | time: 27.425s
[2K
| Adam | epoch: 025 | loss: 0.05622 - acc: 0.9865 -- iter: 0896/1105
[A[ATraining Step: 869  | total loss: [1m[32m0.05235[0m[0m | time: 28.030s
[2K
| Adam | epoch: 025 | loss: 0.05235 - acc: 0.9878 -- iter: 0928/1105
[A[ATraining Step: 870  | total loss: [1m[32m0.04739[0m[0m | time: 28.649s
[2K
| Adam | epoch: 025 | loss: 0.04739 - acc: 0.9890 -- iter: 0960/1105
[A[ATraining Step: 871  | total loss: [1m[32m0.04315[0m[0m | time: 29.279s
[2K
| Adam | epoch: 025 | loss: 0.04315 - acc: 0.9901 -- iter: 0992/1105
[A[ATraining Step: 872  | total loss: [1m[32m0.03934[0m[0m | time: 29.884s
[2K
| Adam | epoch: 025 | loss: 0.03934 - acc: 0.9911 -- iter: 1024/1105
[A[ATraining Step: 873  | total loss: [1m[32m0.03581[0m[0m | time: 30.494s
[2K
| Adam | epoch: 025 | loss: 0.03581 - acc: 0.9920 -- iter: 1056/1105
[A[ATraining Step: 874  | total loss: [1m[32m0.03947[0m[0m | time: 31.096s
[2K
| Adam | epoch: 025 | loss: 0.03947 - acc: 0.9866 -- iter: 1088/1105
[A[ATraining Step: 875  | total loss: [1m[32m0.04040[0m[0m | time: 32.816s
[2K
| Adam | epoch: 025 | loss: 0.04040 - acc: 0.9848 | val_loss: 0.74541 - val_acc: 0.8121 -- iter: 1105/1105
--
Training Step: 876  | total loss: [1m[32m0.03670[0m[0m | time: 0.613s
[2K
| Adam | epoch: 026 | loss: 0.03670 - acc: 0.9863 -- iter: 0032/1105
[A[ATraining Step: 877  | total loss: [1m[32m0.03331[0m[0m | time: 1.239s
[2K
| Adam | epoch: 026 | loss: 0.03331 - acc: 0.9877 -- iter: 0064/1105
[A[ATraining Step: 878  | total loss: [1m[32m0.03604[0m[0m | time: 1.862s
[2K
| Adam | epoch: 026 | loss: 0.03604 - acc: 0.9858 -- iter: 0096/1105
[A[ATraining Step: 879  | total loss: [1m[32m0.03692[0m[0m | time: 2.490s
[2K
| Adam | epoch: 026 | loss: 0.03692 - acc: 0.9841 -- iter: 0128/1105
[A[ATraining Step: 880  | total loss: [1m[32m0.04091[0m[0m | time: 3.113s
[2K
| Adam | epoch: 026 | loss: 0.04091 - acc: 0.9825 -- iter: 0160/1105
[A[ATraining Step: 881  | total loss: [1m[32m0.03726[0m[0m | time: 3.738s
[2K
| Adam | epoch: 026 | loss: 0.03726 - acc: 0.9843 -- iter: 0192/1105
[A[ATraining Step: 882  | total loss: [1m[32m0.03397[0m[0m | time: 4.371s
[2K
| Adam | epoch: 026 | loss: 0.03397 - acc: 0.9859 -- iter: 0224/1105
[A[ATraining Step: 883  | total loss: [1m[32m0.03685[0m[0m | time: 4.977s
[2K
| Adam | epoch: 026 | loss: 0.03685 - acc: 0.9841 -- iter: 0256/1105
[A[ATraining Step: 884  | total loss: [1m[32m0.03382[0m[0m | time: 5.578s
[2K
| Adam | epoch: 026 | loss: 0.03382 - acc: 0.9857 -- iter: 0288/1105
[A[ATraining Step: 885  | total loss: [1m[32m0.03259[0m[0m | time: 6.180s
[2K
| Adam | epoch: 026 | loss: 0.03259 - acc: 0.9872 -- iter: 0320/1105
[A[ATraining Step: 886  | total loss: [1m[32m0.03154[0m[0m | time: 6.785s
[2K
| Adam | epoch: 026 | loss: 0.03154 - acc: 0.9884 -- iter: 0352/1105
[A[ATraining Step: 887  | total loss: [1m[32m0.03020[0m[0m | time: 7.416s
[2K
| Adam | epoch: 026 | loss: 0.03020 - acc: 0.9896 -- iter: 0384/1105
[A[ATraining Step: 888  | total loss: [1m[32m0.03423[0m[0m | time: 8.025s
[2K
| Adam | epoch: 026 | loss: 0.03423 - acc: 0.9875 -- iter: 0416/1105
[A[ATraining Step: 889  | total loss: [1m[32m0.04389[0m[0m | time: 8.623s
[2K
| Adam | epoch: 026 | loss: 0.04389 - acc: 0.9856 -- iter: 0448/1105
[A[ATraining Step: 890  | total loss: [1m[32m0.04819[0m[0m | time: 9.224s
[2K
| Adam | epoch: 026 | loss: 0.04819 - acc: 0.9839 -- iter: 0480/1105
[A[ATraining Step: 891  | total loss: [1m[32m0.04832[0m[0m | time: 9.834s
[2K
| Adam | epoch: 026 | loss: 0.04832 - acc: 0.9824 -- iter: 0512/1105
[A[ATraining Step: 892  | total loss: [1m[32m0.04470[0m[0m | time: 10.733s
[2K
| Adam | epoch: 026 | loss: 0.04470 - acc: 0.9842 -- iter: 0544/1105
[A[ATraining Step: 893  | total loss: [1m[32m0.04202[0m[0m | time: 11.773s
[2K
| Adam | epoch: 026 | loss: 0.04202 - acc: 0.9858 -- iter: 0576/1105
[A[ATraining Step: 894  | total loss: [1m[32m0.03842[0m[0m | time: 12.775s
[2K
| Adam | epoch: 026 | loss: 0.03842 - acc: 0.9872 -- iter: 0608/1105
[A[ATraining Step: 895  | total loss: [1m[32m0.03694[0m[0m | time: 13.650s
[2K
| Adam | epoch: 026 | loss: 0.03694 - acc: 0.9885 -- iter: 0640/1105
[A[ATraining Step: 896  | total loss: [1m[32m0.04294[0m[0m | time: 14.628s
[2K
| Adam | epoch: 026 | loss: 0.04294 - acc: 0.9834 -- iter: 0672/1105
[A[ATraining Step: 897  | total loss: [1m[32m0.03933[0m[0m | time: 15.619s
[2K
| Adam | epoch: 026 | loss: 0.03933 - acc: 0.9850 -- iter: 0704/1105
[A[ATraining Step: 898  | total loss: [1m[32m0.06079[0m[0m | time: 16.642s
[2K
| Adam | epoch: 026 | loss: 0.06079 - acc: 0.9803 -- iter: 0736/1105
[A[ATraining Step: 899  | total loss: [1m[32m0.05540[0m[0m | time: 17.197s
[2K
| Adam | epoch: 026 | loss: 0.05540 - acc: 0.9823 -- iter: 0768/1105
[A[ATraining Step: 900  | total loss: [1m[32m0.07744[0m[0m | time: 17.875s
[2K
| Adam | epoch: 026 | loss: 0.07744 - acc: 0.9723 -- iter: 0800/1105
[A[ATraining Step: 901  | total loss: [1m[32m0.07529[0m[0m | time: 18.940s
[2K
| Adam | epoch: 026 | loss: 0.07529 - acc: 0.9692 -- iter: 0832/1105
[A[ATraining Step: 902  | total loss: [1m[32m0.06825[0m[0m | time: 19.816s
[2K
| Adam | epoch: 026 | loss: 0.06825 - acc: 0.9722 -- iter: 0864/1105
[A[ATraining Step: 903  | total loss: [1m[32m0.06183[0m[0m | time: 20.769s
[2K
| Adam | epoch: 026 | loss: 0.06183 - acc: 0.9750 -- iter: 0896/1105
[A[ATraining Step: 904  | total loss: [1m[32m0.07368[0m[0m | time: 21.850s
[2K
| Adam | epoch: 026 | loss: 0.07368 - acc: 0.9744 -- iter: 0928/1105
[A[ATraining Step: 905  | total loss: [1m[32m0.06880[0m[0m | time: 22.932s
[2K
| Adam | epoch: 026 | loss: 0.06880 - acc: 0.9770 -- iter: 0960/1105
[A[ATraining Step: 906  | total loss: [1m[32m0.06361[0m[0m | time: 23.735s
[2K
| Adam | epoch: 026 | loss: 0.06361 - acc: 0.9793 -- iter: 0992/1105
[A[ATraining Step: 907  | total loss: [1m[32m0.06079[0m[0m | time: 24.740s
[2K
| Adam | epoch: 026 | loss: 0.06079 - acc: 0.9813 -- iter: 1024/1105
[A[ATraining Step: 908  | total loss: [1m[32m0.05705[0m[0m | time: 25.733s
[2K
| Adam | epoch: 026 | loss: 0.05705 - acc: 0.9832 -- iter: 1056/1105
[A[ATraining Step: 909  | total loss: [1m[32m0.05208[0m[0m | time: 26.695s
[2K
| Adam | epoch: 026 | loss: 0.05208 - acc: 0.9849 -- iter: 1088/1105
[A[ATraining Step: 910  | total loss: [1m[32m0.04758[0m[0m | time: 29.680s
[2K
| Adam | epoch: 026 | loss: 0.04758 - acc: 0.9864 | val_loss: 0.75329 - val_acc: 0.7890 -- iter: 1105/1105
--
Training Step: 911  | total loss: [1m[32m0.04354[0m[0m | time: 0.945s
[2K
| Adam | epoch: 027 | loss: 0.04354 - acc: 0.9878 -- iter: 0032/1105
[A[ATraining Step: 912  | total loss: [1m[32m0.04013[0m[0m | time: 1.992s
[2K
| Adam | epoch: 027 | loss: 0.04013 - acc: 0.9890 -- iter: 0064/1105
[A[ATraining Step: 913  | total loss: [1m[32m0.03868[0m[0m | time: 3.164s
[2K
| Adam | epoch: 027 | loss: 0.03868 - acc: 0.9901 -- iter: 0096/1105
[A[ATraining Step: 914  | total loss: [1m[32m0.05283[0m[0m | time: 4.024s
[2K
| Adam | epoch: 027 | loss: 0.05283 - acc: 0.9817 -- iter: 0128/1105
[A[ATraining Step: 915  | total loss: [1m[32m0.04806[0m[0m | time: 4.959s
[2K
| Adam | epoch: 027 | loss: 0.04806 - acc: 0.9835 -- iter: 0160/1105
[A[ATraining Step: 916  | total loss: [1m[32m0.04362[0m[0m | time: 5.921s
[2K
| Adam | epoch: 027 | loss: 0.04362 - acc: 0.9852 -- iter: 0192/1105
[A[ATraining Step: 917  | total loss: [1m[32m0.04138[0m[0m | time: 6.911s
[2K
| Adam | epoch: 027 | loss: 0.04138 - acc: 0.9867 -- iter: 0224/1105
[A[ATraining Step: 918  | total loss: [1m[32m0.03770[0m[0m | time: 7.961s
[2K
| Adam | epoch: 027 | loss: 0.03770 - acc: 0.9880 -- iter: 0256/1105
[A[ATraining Step: 919  | total loss: [1m[32m0.04684[0m[0m | time: 9.028s
[2K
| Adam | epoch: 027 | loss: 0.04684 - acc: 0.9861 -- iter: 0288/1105
[A[ATraining Step: 920  | total loss: [1m[32m0.07639[0m[0m | time: 9.924s
[2K
| Adam | epoch: 027 | loss: 0.07639 - acc: 0.9812 -- iter: 0320/1105
[A[ATraining Step: 921  | total loss: [1m[32m0.06939[0m[0m | time: 10.921s
[2K
| Adam | epoch: 027 | loss: 0.06939 - acc: 0.9831 -- iter: 0352/1105
[A[ATraining Step: 922  | total loss: [1m[32m0.06595[0m[0m | time: 11.985s
[2K
| Adam | epoch: 027 | loss: 0.06595 - acc: 0.9848 -- iter: 0384/1105
[A[ATraining Step: 923  | total loss: [1m[32m0.06068[0m[0m | time: 12.788s
[2K
| Adam | epoch: 027 | loss: 0.06068 - acc: 0.9863 -- iter: 0416/1105
[A[ATraining Step: 924  | total loss: [1m[32m0.05506[0m[0m | time: 13.646s
[2K
| Adam | epoch: 027 | loss: 0.05506 - acc: 0.9877 -- iter: 0448/1105
[A[ATraining Step: 925  | total loss: [1m[32m0.05129[0m[0m | time: 14.587s
[2K
| Adam | epoch: 027 | loss: 0.05129 - acc: 0.9889 -- iter: 0480/1105
[A[ATraining Step: 926  | total loss: [1m[32m0.04674[0m[0m | time: 15.571s
[2K
| Adam | epoch: 027 | loss: 0.04674 - acc: 0.9900 -- iter: 0512/1105
[A[ATraining Step: 927  | total loss: [1m[32m0.04287[0m[0m | time: 16.438s
[2K
| Adam | epoch: 027 | loss: 0.04287 - acc: 0.9910 -- iter: 0544/1105
[A[ATraining Step: 928  | total loss: [1m[32m0.04033[0m[0m | time: 17.508s
[2K
| Adam | epoch: 027 | loss: 0.04033 - acc: 0.9919 -- iter: 0576/1105
[A[ATraining Step: 929  | total loss: [1m[32m0.03897[0m[0m | time: 18.365s
[2K
| Adam | epoch: 027 | loss: 0.03897 - acc: 0.9927 -- iter: 0608/1105
[A[ATraining Step: 930  | total loss: [1m[32m0.03608[0m[0m | time: 19.265s
[2K
| Adam | epoch: 027 | loss: 0.03608 - acc: 0.9934 -- iter: 0640/1105
[A[ATraining Step: 931  | total loss: [1m[32m0.05116[0m[0m | time: 20.187s
[2K
| Adam | epoch: 027 | loss: 0.05116 - acc: 0.9910 -- iter: 0672/1105
[A[ATraining Step: 932  | total loss: [1m[32m0.04868[0m[0m | time: 21.151s
[2K
| Adam | epoch: 027 | loss: 0.04868 - acc: 0.9919 -- iter: 0704/1105
[A[ATraining Step: 933  | total loss: [1m[32m0.04413[0m[0m | time: 22.116s
[2K
| Adam | epoch: 027 | loss: 0.04413 - acc: 0.9927 -- iter: 0736/1105
[A[ATraining Step: 934  | total loss: [1m[32m0.04028[0m[0m | time: 23.238s
[2K
| Adam | epoch: 027 | loss: 0.04028 - acc: 0.9934 -- iter: 0768/1105
[A[ATraining Step: 935  | total loss: [1m[32m0.03700[0m[0m | time: 23.890s
[2K
| Adam | epoch: 027 | loss: 0.03700 - acc: 0.9941 -- iter: 0800/1105
[A[ATraining Step: 936  | total loss: [1m[32m0.03397[0m[0m | time: 24.504s
[2K
| Adam | epoch: 027 | loss: 0.03397 - acc: 0.9947 -- iter: 0832/1105
[A[ATraining Step: 937  | total loss: [1m[32m0.03120[0m[0m | time: 25.383s
[2K
| Adam | epoch: 027 | loss: 0.03120 - acc: 0.9952 -- iter: 0864/1105
[A[ATraining Step: 938  | total loss: [1m[32m0.02902[0m[0m | time: 26.336s
[2K
| Adam | epoch: 027 | loss: 0.02902 - acc: 0.9957 -- iter: 0896/1105
[A[ATraining Step: 939  | total loss: [1m[32m0.04039[0m[0m | time: 27.324s
[2K
| Adam | epoch: 027 | loss: 0.04039 - acc: 0.9899 -- iter: 0928/1105
[A[ATraining Step: 940  | total loss: [1m[32m0.04021[0m[0m | time: 28.280s
[2K
| Adam | epoch: 027 | loss: 0.04021 - acc: 0.9878 -- iter: 0960/1105
[A[ATraining Step: 941  | total loss: [1m[32m0.04433[0m[0m | time: 29.289s
[2K
| Adam | epoch: 027 | loss: 0.04433 - acc: 0.9859 -- iter: 0992/1105
[A[ATraining Step: 942  | total loss: [1m[32m0.04045[0m[0m | time: 30.435s
[2K
| Adam | epoch: 027 | loss: 0.04045 - acc: 0.9873 -- iter: 1024/1105
[A[ATraining Step: 943  | total loss: [1m[32m0.03714[0m[0m | time: 31.298s
[2K
| Adam | epoch: 027 | loss: 0.03714 - acc: 0.9885 -- iter: 1056/1105
[A[ATraining Step: 944  | total loss: [1m[32m0.03456[0m[0m | time: 32.326s
[2K
| Adam | epoch: 027 | loss: 0.03456 - acc: 0.9897 -- iter: 1088/1105
[A[ATraining Step: 945  | total loss: [1m[32m0.03401[0m[0m | time: 35.165s
[2K
| Adam | epoch: 027 | loss: 0.03401 - acc: 0.9876 | val_loss: 0.74198 - val_acc: 0.8064 -- iter: 1105/1105
--
Training Step: 946  | total loss: [1m[32m0.03084[0m[0m | time: 0.949s
[2K
| Adam | epoch: 028 | loss: 0.03084 - acc: 0.9888 -- iter: 0032/1105
[A[ATraining Step: 947  | total loss: [1m[32m0.02817[0m[0m | time: 1.935s
[2K
| Adam | epoch: 028 | loss: 0.02817 - acc: 0.9900 -- iter: 0064/1105
[A[ATraining Step: 948  | total loss: [1m[32m0.02561[0m[0m | time: 2.894s
[2K
| Adam | epoch: 028 | loss: 0.02561 - acc: 0.9910 -- iter: 0096/1105
[A[ATraining Step: 949  | total loss: [1m[32m0.02621[0m[0m | time: 3.871s
[2K
| Adam | epoch: 028 | loss: 0.02621 - acc: 0.9887 -- iter: 0128/1105
[A[ATraining Step: 950  | total loss: [1m[32m0.02457[0m[0m | time: 4.868s
[2K
| Adam | epoch: 028 | loss: 0.02457 - acc: 0.9899 -- iter: 0160/1105
[A[ATraining Step: 951  | total loss: [1m[32m0.02285[0m[0m | time: 5.893s
[2K
| Adam | epoch: 028 | loss: 0.02285 - acc: 0.9909 -- iter: 0192/1105
[A[ATraining Step: 952  | total loss: [1m[32m0.02116[0m[0m | time: 6.846s
[2K
| Adam | epoch: 028 | loss: 0.02116 - acc: 0.9918 -- iter: 0224/1105
[A[ATraining Step: 953  | total loss: [1m[32m0.02061[0m[0m | time: 7.941s
[2K
| Adam | epoch: 028 | loss: 0.02061 - acc: 0.9926 -- iter: 0256/1105
[A[ATraining Step: 954  | total loss: [1m[32m0.01902[0m[0m | time: 8.993s
[2K
| Adam | epoch: 028 | loss: 0.01902 - acc: 0.9933 -- iter: 0288/1105
[A[ATraining Step: 955  | total loss: [1m[32m0.01738[0m[0m | time: 9.923s
[2K
| Adam | epoch: 028 | loss: 0.01738 - acc: 0.9940 -- iter: 0320/1105
[A[ATraining Step: 956  | total loss: [1m[32m0.01627[0m[0m | time: 10.807s
[2K
| Adam | epoch: 028 | loss: 0.01627 - acc: 0.9946 -- iter: 0352/1105
[A[ATraining Step: 957  | total loss: [1m[32m0.01518[0m[0m | time: 11.782s
[2K
| Adam | epoch: 028 | loss: 0.01518 - acc: 0.9952 -- iter: 0384/1105
[A[ATraining Step: 958  | total loss: [1m[32m0.01406[0m[0m | time: 12.775s
[2K
| Adam | epoch: 028 | loss: 0.01406 - acc: 0.9956 -- iter: 0416/1105
[A[ATraining Step: 959  | total loss: [1m[32m0.01295[0m[0m | time: 13.758s
[2K
| Adam | epoch: 028 | loss: 0.01295 - acc: 0.9961 -- iter: 0448/1105
[A[ATraining Step: 960  | total loss: [1m[32m0.01224[0m[0m | time: 14.871s
[2K
| Adam | epoch: 028 | loss: 0.01224 - acc: 0.9965 -- iter: 0480/1105
[A[ATraining Step: 961  | total loss: [1m[32m0.01168[0m[0m | time: 15.768s
[2K
| Adam | epoch: 028 | loss: 0.01168 - acc: 0.9968 -- iter: 0512/1105
[A[ATraining Step: 962  | total loss: [1m[32m0.01141[0m[0m | time: 16.771s
[2K
| Adam | epoch: 028 | loss: 0.01141 - acc: 0.9971 -- iter: 0544/1105
[A[ATraining Step: 963  | total loss: [1m[32m0.01106[0m[0m | time: 17.837s
[2K
| Adam | epoch: 028 | loss: 0.01106 - acc: 0.9974 -- iter: 0576/1105
[A[ATraining Step: 964  | total loss: [1m[32m0.01042[0m[0m | time: 18.960s
[2K
| Adam | epoch: 028 | loss: 0.01042 - acc: 0.9977 -- iter: 0608/1105
[A[ATraining Step: 965  | total loss: [1m[32m0.00965[0m[0m | time: 19.844s
[2K
| Adam | epoch: 028 | loss: 0.00965 - acc: 0.9979 -- iter: 0640/1105
[A[ATraining Step: 966  | total loss: [1m[32m0.00882[0m[0m | time: 20.769s
[2K
| Adam | epoch: 028 | loss: 0.00882 - acc: 0.9981 -- iter: 0672/1105
[A[ATraining Step: 967  | total loss: [1m[32m0.00809[0m[0m | time: 21.709s
[2K
| Adam | epoch: 028 | loss: 0.00809 - acc: 0.9983 -- iter: 0704/1105
[A[ATraining Step: 968  | total loss: [1m[32m0.00738[0m[0m | time: 22.715s
[2K
| Adam | epoch: 028 | loss: 0.00738 - acc: 0.9985 -- iter: 0736/1105
[A[ATraining Step: 969  | total loss: [1m[32m0.00889[0m[0m | time: 23.827s
[2K
| Adam | epoch: 028 | loss: 0.00889 - acc: 0.9986 -- iter: 0768/1105
[A[ATraining Step: 970  | total loss: [1m[32m0.00873[0m[0m | time: 24.876s
[2K
| Adam | epoch: 028 | loss: 0.00873 - acc: 0.9988 -- iter: 0800/1105
[A[ATraining Step: 971  | total loss: [1m[32m0.00816[0m[0m | time: 25.443s
[2K
| Adam | epoch: 028 | loss: 0.00816 - acc: 0.9989 -- iter: 0832/1105
[A[ATraining Step: 972  | total loss: [1m[32m0.03949[0m[0m | time: 25.931s
[2K
| Adam | epoch: 028 | loss: 0.03949 - acc: 0.9931 -- iter: 0864/1105
[A[ATraining Step: 973  | total loss: [1m[32m0.05588[0m[0m | time: 27.079s
[2K
| Adam | epoch: 028 | loss: 0.05588 - acc: 0.9879 -- iter: 0896/1105
[A[ATraining Step: 974  | total loss: [1m[32m0.07183[0m[0m | time: 28.219s
[2K
| Adam | epoch: 028 | loss: 0.07183 - acc: 0.9829 -- iter: 0928/1105
[A[ATraining Step: 975  | total loss: [1m[32m0.06771[0m[0m | time: 29.169s
[2K
| Adam | epoch: 028 | loss: 0.06771 - acc: 0.9846 -- iter: 0960/1105
[A[ATraining Step: 976  | total loss: [1m[32m0.17600[0m[0m | time: 30.036s
[2K
| Adam | epoch: 028 | loss: 0.17600 - acc: 0.9705 -- iter: 0992/1105
[A[ATraining Step: 977  | total loss: [1m[32m0.16115[0m[0m | time: 31.079s
[2K
| Adam | epoch: 028 | loss: 0.16115 - acc: 0.9735 -- iter: 1024/1105
[A[ATraining Step: 978  | total loss: [1m[32m0.14610[0m[0m | time: 32.038s
[2K
| Adam | epoch: 028 | loss: 0.14610 - acc: 0.9761 -- iter: 1056/1105
[A[ATraining Step: 979  | total loss: [1m[32m0.13235[0m[0m | time: 33.071s
[2K
| Adam | epoch: 028 | loss: 0.13235 - acc: 0.9785 -- iter: 1088/1105
[A[ATraining Step: 980  | total loss: [1m[32m0.12060[0m[0m | time: 35.890s
[2K
| Adam | epoch: 028 | loss: 0.12060 - acc: 0.9807 | val_loss: 0.60002 - val_acc: 0.7977 -- iter: 1105/1105
--
Training Step: 981  | total loss: [1m[32m0.11066[0m[0m | time: 1.212s
[2K
| Adam | epoch: 029 | loss: 0.11066 - acc: 0.9826 -- iter: 0032/1105
[A[ATraining Step: 982  | total loss: [1m[32m0.10147[0m[0m | time: 2.296s
[2K
| Adam | epoch: 029 | loss: 0.10147 - acc: 0.9843 -- iter: 0064/1105
[A[ATraining Step: 983  | total loss: [1m[32m0.09876[0m[0m | time: 3.231s
[2K
| Adam | epoch: 029 | loss: 0.09876 - acc: 0.9828 -- iter: 0096/1105
[A[ATraining Step: 984  | total loss: [1m[32m0.09523[0m[0m | time: 4.168s
[2K
| Adam | epoch: 029 | loss: 0.09523 - acc: 0.9814 -- iter: 0128/1105
[A[ATraining Step: 985  | total loss: [1m[32m0.08788[0m[0m | time: 5.143s
[2K
| Adam | epoch: 029 | loss: 0.08788 - acc: 0.9832 -- iter: 0160/1105
[A[ATraining Step: 986  | total loss: [1m[32m0.08429[0m[0m | time: 6.098s
[2K
| Adam | epoch: 029 | loss: 0.08429 - acc: 0.9849 -- iter: 0192/1105
[A[ATraining Step: 987  | total loss: [1m[32m0.07888[0m[0m | time: 7.063s
[2K
| Adam | epoch: 029 | loss: 0.07888 - acc: 0.9864 -- iter: 0224/1105
[A[ATraining Step: 988  | total loss: [1m[32m0.07320[0m[0m | time: 8.181s
[2K
| Adam | epoch: 029 | loss: 0.07320 - acc: 0.9878 -- iter: 0256/1105
[A[ATraining Step: 989  | total loss: [1m[32m0.06827[0m[0m | time: 9.174s
[2K
| Adam | epoch: 029 | loss: 0.06827 - acc: 0.9890 -- iter: 0288/1105
[A[ATraining Step: 990  | total loss: [1m[32m0.08251[0m[0m | time: 10.077s
[2K
| Adam | epoch: 029 | loss: 0.08251 - acc: 0.9870 -- iter: 0320/1105
[A[ATraining Step: 991  | total loss: [1m[32m0.07586[0m[0m | time: 11.175s
[2K
| Adam | epoch: 029 | loss: 0.07586 - acc: 0.9883 -- iter: 0352/1105
[A[ATraining Step: 992  | total loss: [1m[32m0.06994[0m[0m | time: 12.300s
[2K
| Adam | epoch: 029 | loss: 0.06994 - acc: 0.9894 -- iter: 0384/1105
[A[ATraining Step: 993  | total loss: [1m[32m0.06460[0m[0m | time: 13.194s
[2K
| Adam | epoch: 029 | loss: 0.06460 - acc: 0.9905 -- iter: 0416/1105
[A[ATraining Step: 994  | total loss: [1m[32m0.06060[0m[0m | time: 14.110s
[2K
| Adam | epoch: 029 | loss: 0.06060 - acc: 0.9915 -- iter: 0448/1105
[A[ATraining Step: 995  | total loss: [1m[32m0.05709[0m[0m | time: 15.064s
[2K
| Adam | epoch: 029 | loss: 0.05709 - acc: 0.9923 -- iter: 0480/1105
[A[ATraining Step: 996  | total loss: [1m[32m0.05613[0m[0m | time: 15.946s
[2K
| Adam | epoch: 029 | loss: 0.05613 - acc: 0.9931 -- iter: 0512/1105
[A[ATraining Step: 997  | total loss: [1m[32m0.06142[0m[0m | time: 16.995s
[2K
| Adam | epoch: 029 | loss: 0.06142 - acc: 0.9906 -- iter: 0544/1105
[A[ATraining Step: 998  | total loss: [1m[32m0.05819[0m[0m | time: 18.007s
[2K
| Adam | epoch: 029 | loss: 0.05819 - acc: 0.9916 -- iter: 0576/1105
[A[ATraining Step: 999  | total loss: [1m[32m0.05341[0m[0m | time: 19.020s
[2K
| Adam | epoch: 029 | loss: 0.05341 - acc: 0.9924 -- iter: 0608/1105
[A[ATraining Step: 1000  | total loss: [1m[32m0.04892[0m[0m | time: 21.794s
[2K
| Adam | epoch: 029 | loss: 0.04892 - acc: 0.9932 | val_loss: 0.70638 - val_acc: 0.8179 -- iter: 0640/1105
--
Training Step: 1001  | total loss: [1m[32m0.04558[0m[0m | time: 22.852s
[2K
| Adam | epoch: 029 | loss: 0.04558 - acc: 0.9939 -- iter: 0672/1105
[A[ATraining Step: 1002  | total loss: [1m[32m0.04273[0m[0m | time: 23.686s
[2K
| Adam | epoch: 029 | loss: 0.04273 - acc: 0.9945 -- iter: 0704/1105
[A[ATraining Step: 1003  | total loss: [1m[32m0.03932[0m[0m | time: 24.654s
[2K
| Adam | epoch: 029 | loss: 0.03932 - acc: 0.9950 -- iter: 0736/1105
[A[ATraining Step: 1004  | total loss: [1m[32m0.03786[0m[0m | time: 25.655s
[2K
| Adam | epoch: 029 | loss: 0.03786 - acc: 0.9955 -- iter: 0768/1105
[A[ATraining Step: 1005  | total loss: [1m[32m0.03914[0m[0m | time: 26.672s
[2K
| Adam | epoch: 029 | loss: 0.03914 - acc: 0.9928 -- iter: 0800/1105
[A[ATraining Step: 1006  | total loss: [1m[32m0.03668[0m[0m | time: 27.786s
[2K
| Adam | epoch: 029 | loss: 0.03668 - acc: 0.9936 -- iter: 0832/1105
[A[ATraining Step: 1007  | total loss: [1m[32m0.03370[0m[0m | time: 28.401s
[2K
| Adam | epoch: 029 | loss: 0.03370 - acc: 0.9942 -- iter: 0864/1105
[A[ATraining Step: 1008  | total loss: [1m[32m0.05163[0m[0m | time: 28.955s
[2K
| Adam | epoch: 029 | loss: 0.05163 - acc: 0.9889 -- iter: 0896/1105
[A[ATraining Step: 1009  | total loss: [1m[32m0.05818[0m[0m | time: 29.814s
[2K
| Adam | epoch: 029 | loss: 0.05818 - acc: 0.9841 -- iter: 0928/1105
[A[ATraining Step: 1010  | total loss: [1m[32m0.05398[0m[0m | time: 30.948s
[2K
| Adam | epoch: 029 | loss: 0.05398 - acc: 0.9857 -- iter: 0960/1105
[A[ATraining Step: 1011  | total loss: [1m[32m0.04904[0m[0m | time: 32.055s
[2K
| Adam | epoch: 029 | loss: 0.04904 - acc: 0.9871 -- iter: 0992/1105
[A[ATraining Step: 1012  | total loss: [1m[32m0.09614[0m[0m | time: 33.008s
[2K
| Adam | epoch: 029 | loss: 0.09614 - acc: 0.9791 -- iter: 1024/1105
[A[ATraining Step: 1013  | total loss: [1m[32m0.11461[0m[0m | time: 33.964s
[2K
| Adam | epoch: 029 | loss: 0.11461 - acc: 0.9687 -- iter: 1056/1105
[A[ATraining Step: 1014  | total loss: [1m[32m0.12043[0m[0m | time: 34.989s
[2K
| Adam | epoch: 029 | loss: 0.12043 - acc: 0.9655 -- iter: 1088/1105
[A[ATraining Step: 1015  | total loss: [1m[32m0.10943[0m[0m | time: 37.987s
[2K
| Adam | epoch: 029 | loss: 0.10943 - acc: 0.9690 | val_loss: 0.66288 - val_acc: 0.7890 -- iter: 1105/1105
--
Training Step: 1016  | total loss: [1m[32m0.10038[0m[0m | time: 0.946s
[2K
| Adam | epoch: 030 | loss: 0.10038 - acc: 0.9721 -- iter: 0032/1105
[A[ATraining Step: 1017  | total loss: [1m[32m0.09190[0m[0m | time: 1.943s
[2K
| Adam | epoch: 030 | loss: 0.09190 - acc: 0.9749 -- iter: 0064/1105
[A[ATraining Step: 1018  | total loss: [1m[32m0.08423[0m[0m | time: 3.110s
[2K
| Adam | epoch: 030 | loss: 0.08423 - acc: 0.9774 -- iter: 0096/1105
[A[ATraining Step: 1019  | total loss: [1m[32m0.07727[0m[0m | time: 4.148s
[2K
| Adam | epoch: 030 | loss: 0.07727 - acc: 0.9796 -- iter: 0128/1105
[A[ATraining Step: 1020  | total loss: [1m[32m0.08566[0m[0m | time: 4.969s
[2K
| Adam | epoch: 030 | loss: 0.08566 - acc: 0.9754 -- iter: 0160/1105
[A[ATraining Step: 1021  | total loss: [1m[32m0.08094[0m[0m | time: 5.897s
[2K
| Adam | epoch: 030 | loss: 0.08094 - acc: 0.9779 -- iter: 0192/1105
[A[ATraining Step: 1022  | total loss: [1m[32m0.07549[0m[0m | time: 6.884s
[2K
| Adam | epoch: 030 | loss: 0.07549 - acc: 0.9801 -- iter: 0224/1105
[A[ATraining Step: 1023  | total loss: [1m[32m0.08770[0m[0m | time: 7.834s
[2K
| Adam | epoch: 030 | loss: 0.08770 - acc: 0.9790 -- iter: 0256/1105
[A[ATraining Step: 1024  | total loss: [1m[32m0.08533[0m[0m | time: 8.901s
[2K
| Adam | epoch: 030 | loss: 0.08533 - acc: 0.9779 -- iter: 0288/1105
[A[ATraining Step: 1025  | total loss: [1m[32m0.07747[0m[0m | time: 9.960s
[2K
| Adam | epoch: 030 | loss: 0.07747 - acc: 0.9802 -- iter: 0320/1105
[A[ATraining Step: 1026  | total loss: [1m[32m0.07408[0m[0m | time: 10.843s
[2K
| Adam | epoch: 030 | loss: 0.07408 - acc: 0.9790 -- iter: 0352/1105
[A[ATraining Step: 1027  | total loss: [1m[32m0.08137[0m[0m | time: 11.826s
[2K
| Adam | epoch: 030 | loss: 0.08137 - acc: 0.9749 -- iter: 0384/1105
[A[ATraining Step: 1028  | total loss: [1m[32m0.07457[0m[0m | time: 12.968s
[2K
| Adam | epoch: 030 | loss: 0.07457 - acc: 0.9774 -- iter: 0416/1105
[A[ATraining Step: 1029  | total loss: [1m[32m0.06917[0m[0m | time: 14.097s
[2K
| Adam | epoch: 030 | loss: 0.06917 - acc: 0.9796 -- iter: 0448/1105
[A[ATraining Step: 1030  | total loss: [1m[32m0.06364[0m[0m | time: 14.894s
[2K
| Adam | epoch: 030 | loss: 0.06364 - acc: 0.9817 -- iter: 0480/1105
[A[ATraining Step: 1031  | total loss: [1m[32m0.05926[0m[0m | time: 15.889s
[2K
| Adam | epoch: 030 | loss: 0.05926 - acc: 0.9835 -- iter: 0512/1105
[A[ATraining Step: 1032  | total loss: [1m[32m0.05437[0m[0m | time: 16.848s
[2K
| Adam | epoch: 030 | loss: 0.05437 - acc: 0.9852 -- iter: 0544/1105
[A[ATraining Step: 1033  | total loss: [1m[32m0.05520[0m[0m | time: 17.826s
[2K
| Adam | epoch: 030 | loss: 0.05520 - acc: 0.9835 -- iter: 0576/1105
[A[ATraining Step: 1034  | total loss: [1m[32m0.05086[0m[0m | time: 18.909s
[2K
| Adam | epoch: 030 | loss: 0.05086 - acc: 0.9852 -- iter: 0608/1105
[A[ATraining Step: 1035  | total loss: [1m[32m0.04660[0m[0m | time: 19.905s
[2K
| Adam | epoch: 030 | loss: 0.04660 - acc: 0.9866 -- iter: 0640/1105
[A[ATraining Step: 1036  | total loss: [1m[32m0.04319[0m[0m | time: 20.799s
[2K
| Adam | epoch: 030 | loss: 0.04319 - acc: 0.9880 -- iter: 0672/1105
[A[ATraining Step: 1037  | total loss: [1m[32m0.05208[0m[0m | time: 21.759s
[2K
| Adam | epoch: 030 | loss: 0.05208 - acc: 0.9861 -- iter: 0704/1105
[A[ATraining Step: 1038  | total loss: [1m[32m0.04772[0m[0m | time: 22.914s
[2K
| Adam | epoch: 030 | loss: 0.04772 - acc: 0.9875 -- iter: 0736/1105
[A[ATraining Step: 1039  | total loss: [1m[32m0.04368[0m[0m | time: 24.052s
[2K
| Adam | epoch: 030 | loss: 0.04368 - acc: 0.9887 -- iter: 0768/1105
[A[ATraining Step: 1040  | total loss: [1m[32m0.04016[0m[0m | time: 24.872s
[2K
| Adam | epoch: 030 | loss: 0.04016 - acc: 0.9898 -- iter: 0800/1105
[A[ATraining Step: 1041  | total loss: [1m[32m0.03674[0m[0m | time: 25.844s
[2K
| Adam | epoch: 030 | loss: 0.03674 - acc: 0.9909 -- iter: 0832/1105
[A[ATraining Step: 1042  | total loss: [1m[32m0.03787[0m[0m | time: 26.744s
[2K
| Adam | epoch: 030 | loss: 0.03787 - acc: 0.9886 -- iter: 0864/1105
[A[ATraining Step: 1043  | total loss: [1m[32m0.03507[0m[0m | time: 27.281s
[2K
| Adam | epoch: 030 | loss: 0.03507 - acc: 0.9898 -- iter: 0896/1105
[A[ATraining Step: 1044  | total loss: [1m[32m0.03258[0m[0m | time: 27.865s
[2K
| Adam | epoch: 030 | loss: 0.03258 - acc: 0.9908 -- iter: 0928/1105
[A[ATraining Step: 1045  | total loss: [1m[32m0.03013[0m[0m | time: 28.909s
[2K
| Adam | epoch: 030 | loss: 0.03013 - acc: 0.9917 -- iter: 0960/1105
[A[ATraining Step: 1046  | total loss: [1m[32m0.02804[0m[0m | time: 29.989s
[2K
| Adam | epoch: 030 | loss: 0.02804 - acc: 0.9925 -- iter: 0992/1105
[A[ATraining Step: 1047  | total loss: [1m[32m0.02689[0m[0m | time: 30.922s
[2K
| Adam | epoch: 030 | loss: 0.02689 - acc: 0.9933 -- iter: 1024/1105
[A[ATraining Step: 1048  | total loss: [1m[32m0.04219[0m[0m | time: 31.986s
[2K
| Adam | epoch: 030 | loss: 0.04219 - acc: 0.9908 -- iter: 1056/1105
[A[ATraining Step: 1049  | total loss: [1m[32m0.05073[0m[0m | time: 33.062s
[2K
| Adam | epoch: 030 | loss: 0.05073 - acc: 0.9886 -- iter: 1088/1105
[A[ATraining Step: 1050  | total loss: [1m[32m0.04671[0m[0m | time: 35.553s
[2K
| Adam | epoch: 030 | loss: 0.04671 - acc: 0.9898 | val_loss: 0.72967 - val_acc: 0.8006 -- iter: 1105/1105
--
Validation AUC:0.8883685143679123
Validation AUPRC:0.9114461124553646
Test AUC:0.8952361795568071
Test AUPRC:0.9085135926506899
BestTestF1Score	0.84	0.7	0.85	0.84	0.85	138	27	156	25	0.73
BestTestMCCScore	0.83	0.69	0.84	0.86	0.8	131	22	161	32	0.88
BestTestAccuracyScore	0.83	0.69	0.84	0.86	0.8	131	22	161	32	0.88
BestValidationF1Score	0.81	0.63	0.81	0.84	0.79	142	28	139	37	0.73
BestValidationMCC	0.81	0.64	0.82	0.87	0.75	135	20	147	44	0.88
BestValidationAccuracy	0.81	0.64	0.82	0.87	0.75	135	20	147	44	0.88
TestPredictions (Threshold:0.88)
CHEMBL1773485,TN,INACT,0.12999999523162842	CHEMBL3260177,TN,INACT,0.009999999776482582	CHEMBL190152,FP,INACT,0.9599999785423279	CHEMBL1834065,TN,INACT,0.0	CHEMBL2335968,TP,ACT,1.0	CHEMBL421501,TP,ACT,1.0	CHEMBL3764488,TN,INACT,0.0	CHEMBL1952059,TN,INACT,0.23000000417232513	CHEMBL604046,TN,INACT,0.009999999776482582	CHEMBL180145,TP,ACT,1.0	CHEMBL241856,TP,ACT,1.0	CHEMBL424707,TP,ACT,1.0	CHEMBL128780,FN,ACT,0.8500000238418579	CHEMBL344384,TN,INACT,0.0	CHEMBL222999,TN,INACT,0.2800000011920929	CHEMBL2396908,TN,INACT,0.8700000047683716	CHEMBL3577552,TP,ACT,1.0	CHEMBL2178786,TP,ACT,1.0	CHEMBL229051,TN,INACT,0.0	CHEMBL486901,TP,ACT,1.0	CHEMBL583495,FN,ACT,0.1599999964237213	CHEMBL220686,TN,INACT,0.0	CHEMBL575619,TP,ACT,0.9800000190734863	CHEMBL2332543,TN,INACT,0.0	CHEMBL340929,TN,INACT,0.14000000059604645	CHEMBL3277217,TN,INACT,0.029999999329447746	CHEMBL566788,TP,ACT,0.9900000095367432	CHEMBL430712,TN,INACT,0.0	CHEMBL155300,TP,ACT,0.9800000190734863	CHEMBL353720,TN,INACT,0.0	CHEMBL72967,TP,ACT,1.0	CHEMBL3233993,TN,INACT,0.10000000149011612	CHEMBL375126,TN,INACT,0.009999999776482582	CHEMBL490507,TN,INACT,0.019999999552965164	CHEMBL3577507,TP,ACT,0.9599999785423279	CHEMBL166194,TN,INACT,0.09000000357627869	CHEMBL3127008,TP,ACT,1.0	CHEMBL3339000,TN,INACT,0.0	CHEMBL1084543,TN,INACT,0.0	CHEMBL342245,TN,INACT,0.0	CHEMBL95161,FP,INACT,0.9599999785423279	CHEMBL1669489,TN,INACT,0.0	CHEMBL2380677,TN,INACT,0.0	CHEMBL3398323,TP,ACT,1.0	CHEMBL42531,FN,ACT,0.009999999776482582	CHEMBL101518,TP,ACT,1.0	CHEMBL1766140,TN,INACT,0.009999999776482582	CHEMBL2299044,FN,ACT,0.0	CHEMBL191315,FP,INACT,0.9900000095367432	CHEMBL456786,TP,ACT,1.0	CHEMBL147025,TN,INACT,0.23000000417232513	CHEMBL3087797,TN,INACT,0.0	CHEMBL597794,FP,INACT,0.9900000095367432	CHEMBL3577517,TP,ACT,1.0	CHEMBL2069791,TP,ACT,1.0	CHEMBL3338959,TN,INACT,0.009999999776482582	CHEMBL457622,TP,ACT,1.0	CHEMBL478706,TP,ACT,0.9900000095367432	CHEMBL2323352,TN,INACT,0.5899999737739563	CHEMBL73447,TP,ACT,1.0	CHEMBL255230,TN,INACT,0.0	CHEMBL3220805,FP,INACT,0.9100000262260437	CHEMBL1669488,TN,INACT,0.7900000214576721	CHEMBL435673,TP,ACT,1.0	CHEMBL1762000,TN,INACT,0.019999999552965164	CHEMBL413170,TP,ACT,1.0	CHEMBL2069762,TP,ACT,0.9800000190734863	CHEMBL3577512,TP,ACT,0.9700000286102295	CHEMBL361866,TN,INACT,0.6200000047683716	CHEMBL161149,TP,ACT,1.0	CHEMBL2376365,TP,ACT,1.0	CHEMBL397101,TN,INACT,0.0	CHEMBL128452,TP,ACT,1.0	CHEMBL221669,TN,INACT,0.029999999329447746	CHEMBL277665,TN,INACT,0.0	CHEMBL456989,TP,ACT,0.9900000095367432	CHEMBL74927,TP,ACT,1.0	CHEMBL2234836,TN,INACT,0.0	CHEMBL473257,TP,ACT,1.0	CHEMBL161179,FN,ACT,0.25999999046325684	CHEMBL3398320,TP,ACT,1.0	CHEMBL224822,TN,INACT,0.09000000357627869	CHEMBL159353,FN,ACT,0.75	CHEMBL362583,TP,ACT,1.0	CHEMBL1085275,TN,INACT,0.28999999165534973	CHEMBL491528,TN,INACT,0.05000000074505806	CHEMBL595616,TP,ACT,1.0	CHEMBL3577502,TP,ACT,1.0	CHEMBL359698,TN,INACT,0.4699999988079071	CHEMBL3398300,FN,ACT,0.0	CHEMBL607843,TP,ACT,1.0	CHEMBL748,TN,INACT,0.009999999776482582	CHEMBL24844,TN,INACT,0.0	CHEMBL703,TN,INACT,0.029999999329447746	CHEMBL163508,FN,ACT,0.0	CHEMBL225638,TN,INACT,0.0	CHEMBL2441689,TN,INACT,0.009999999776482582	CHEMBL389583,FN,ACT,0.009999999776482582	CHEMBL1916927,TN,INACT,0.019999999552965164	CHEMBL457193,TP,ACT,0.9900000095367432	CHEMBL2376369,TP,ACT,1.0	CHEMBL346399,TN,INACT,0.36000001430511475	CHEMBL345638,TP,ACT,0.9399999976158142	CHEMBL3087794,TN,INACT,0.009999999776482582	CHEMBL76658,TP,ACT,1.0	CHEMBL343054,TN,INACT,0.0	CHEMBL374758,TN,INACT,0.019999999552965164	CHEMBL131579,TP,ACT,0.9800000190734863	CHEMBL1257887,TN,INACT,0.009999999776482582	CHEMBL3338944,TN,INACT,0.0	CHEMBL1642971,TN,INACT,0.05999999865889549	CHEMBL2323351,TN,INACT,0.0	CHEMBL123280,TP,ACT,0.9900000095367432	CHEMBL107572,TP,ACT,0.9900000095367432	CHEMBL1652,TN,INACT,0.03999999910593033	CHEMBL555320,TP,ACT,1.0	CHEMBL2425410,TN,INACT,0.0	CHEMBL498966,TP,ACT,0.949999988079071	CHEMBL229050,TN,INACT,0.009999999776482582	CHEMBL542732,TP,ACT,1.0	CHEMBL2425406,TN,INACT,0.7300000190734863	CHEMBL330883,TP,ACT,0.9300000071525574	CHEMBL2178784,TP,ACT,1.0	CHEMBL130847,TP,ACT,0.9900000095367432	CHEMBL3398315,TP,ACT,1.0	CHEMBL449003,TP,ACT,0.9700000286102295	CHEMBL2069774,TP,ACT,1.0	CHEMBL3237541,TN,INACT,0.10999999940395355	CHEMBL592430,TN,INACT,0.009999999776482582	CHEMBL309173,TP,ACT,0.9900000095367432	CHEMBL2069783,TP,ACT,1.0	CHEMBL538358,TN,INACT,0.0	CHEMBL245080,TP,ACT,1.0	CHEMBL230006,TN,INACT,0.10000000149011612	CHEMBL343365,TN,INACT,0.009999999776482582	CHEMBL147517,TN,INACT,0.7200000286102295	CHEMBL3577538,TP,ACT,1.0	CHEMBL18903,FN,ACT,0.0	CHEMBL472814,TP,ACT,1.0	CHEMBL593998,TP,ACT,1.0	CHEMBL1834070,TN,INACT,0.0	CHEMBL472776,TP,ACT,1.0	CHEMBL298896,FN,ACT,0.009999999776482582	CHEMBL115350,TP,ACT,0.9200000166893005	CHEMBL53715,TN,INACT,0.009999999776482582	CHEMBL456130,TP,ACT,0.9700000286102295	CHEMBL464220,TP,ACT,0.9900000095367432	CHEMBL229104,TN,INACT,0.0	CHEMBL347813,TP,ACT,1.0	CHEMBL475161,TP,ACT,1.0	CHEMBL267836,TP,ACT,1.0	CHEMBL3277220,TN,INACT,0.009999999776482582	CHEMBL3339007,TN,INACT,0.0	CHEMBL3237533,TN,INACT,0.0	CHEMBL456748,TP,ACT,0.949999988079071	CHEMBL1651040,FP,INACT,0.9700000286102295	CHEMBL154257,TN,INACT,0.019999999552965164	CHEMBL2234840,TN,INACT,0.0	CHEMBL170902,TN,INACT,0.009999999776482582	CHEMBL389283,TN,INACT,0.0	CHEMBL542234,TP,ACT,1.0	CHEMBL2299225,FN,ACT,0.0	CHEMBL3775913,TN,INACT,0.7699999809265137	CHEMBL597821,TN,INACT,0.0	CHEMBL3337471,TN,INACT,0.0	CHEMBL332894,TP,ACT,0.9900000095367432	CHEMBL474836,TN,INACT,0.009999999776482582	CHEMBL100819,FN,ACT,0.019999999552965164	CHEMBL2376360,TP,ACT,1.0	CHEMBL473767,TP,ACT,1.0	CHEMBL75121,TN,INACT,0.03999999910593033	CHEMBL191461,TN,INACT,0.38999998569488525	CHEMBL1081464,TP,ACT,0.9399999976158142	CHEMBL2332532,TN,INACT,0.0	CHEMBL1651048,TN,INACT,0.009999999776482582	CHEMBL2323708,TP,ACT,0.9700000286102295	CHEMBL2323710,TP,ACT,1.0	CHEMBL372710,TN,INACT,0.0	CHEMBL2234833,TN,INACT,0.0	CHEMBL3828586,TN,INACT,0.0	CHEMBL2069795,TP,ACT,0.9900000095367432	CHEMBL3577504,TP,ACT,1.0	CHEMBL3828385,TN,INACT,0.0	CHEMBL485021,TP,ACT,1.0	CHEMBL282917,TN,INACT,0.009999999776482582	CHEMBL241011,TP,ACT,0.9700000286102295	CHEMBL3289936,TN,INACT,0.0	CHEMBL455352,FN,ACT,0.03999999910593033	CHEMBL121374,FP,INACT,0.9900000095367432	CHEMBL497276,FP,INACT,0.9900000095367432	CHEMBL1916768,TN,INACT,0.03999999910593033	CHEMBL71994,TN,INACT,0.009999999776482582	CHEMBL340427,TP,ACT,0.9900000095367432	CHEMBL1766151,TN,INACT,0.0	CHEMBL3338955,FP,INACT,0.949999988079071	CHEMBL3577505,TP,ACT,0.9900000095367432	CHEMBL244837,TN,INACT,0.0	CHEMBL3398318,TP,ACT,1.0	CHEMBL2178791,TP,ACT,1.0	CHEMBL229052,TN,INACT,0.0	CHEMBL1766143,TN,INACT,0.0	CHEMBL100334,TP,ACT,0.9900000095367432	CHEMBL3398312,TP,ACT,0.9900000095367432	CHEMBL1929401,FN,ACT,0.44999998807907104	CHEMBL402976,TN,INACT,0.009999999776482582	CHEMBL73933,TP,ACT,0.9800000190734863	CHEMBL291233,TN,INACT,0.0	CHEMBL3220507,TN,INACT,0.0	CHEMBL444427,TN,INACT,0.09000000357627869	CHEMBL3338963,TN,INACT,0.019999999552965164	CHEMBL544369,TP,ACT,1.0	CHEMBL3770206,TN,INACT,0.0	CHEMBL136916,FP,INACT,0.8899999856948853	CHEMBL477167,TN,INACT,0.0	CHEMBL264242,TP,ACT,1.0	CHEMBL2069787,TP,ACT,1.0	CHEMBL108632,TP,ACT,0.9900000095367432	CHEMBL323655,FP,INACT,1.0	CHEMBL105874,FN,ACT,0.029999999329447746	CHEMBL162734,FP,INACT,0.9700000286102295	CHEMBL121102,FN,ACT,0.75	CHEMBL51168,FP,INACT,0.9399999976158142	CHEMBL31184,TN,INACT,0.09000000357627869	CHEMBL2323712,TP,ACT,1.0	CHEMBL2338670,FN,ACT,0.0	CHEMBL19470,TN,INACT,0.0	CHEMBL119634,TN,INACT,0.3799999952316284	CHEMBL385778,TN,INACT,0.009999999776482582	CHEMBL306776,TP,ACT,1.0	CHEMBL2178785,TP,ACT,1.0	CHEMBL2310904,TN,INACT,0.0	CHEMBL319797,FN,ACT,0.07999999821186066	CHEMBL187370,TN,INACT,0.0	CHEMBL73593,TP,ACT,0.9900000095367432	CHEMBL543667,TP,ACT,1.0	CHEMBL472812,TP,ACT,1.0	CHEMBL2299221,FN,ACT,0.0	CHEMBL1762001,TN,INACT,0.0	CHEMBL395282,TP,ACT,1.0	CHEMBL125278,TN,INACT,0.03999999910593033	CHEMBL1651047,TN,INACT,0.009999999776482582	CHEMBL2022933,TN,INACT,0.029999999329447746	CHEMBL3605422,TN,INACT,0.0	CHEMBL3577547,TP,ACT,1.0	CHEMBL258928,TP,ACT,1.0	CHEMBL2069779,TP,ACT,1.0	CHEMBL2178783,TP,ACT,1.0	CHEMBL572865,TN,INACT,0.8600000143051147	CHEMBL3142709,TN,INACT,0.0	CHEMBL76470,TP,ACT,0.9599999785423279	CHEMBL389580,TP,ACT,1.0	CHEMBL3338991,TN,INACT,0.0	CHEMBL361540,TP,ACT,1.0	CHEMBL1770555,TN,INACT,0.019999999552965164	CHEMBL53830,TN,INACT,0.009999999776482582	CHEMBL276539,TN,INACT,0.009999999776482582	CHEMBL360055,TN,INACT,0.46000000834465027	CHEMBL434898,TP,ACT,1.0	CHEMBL3754631,TN,INACT,0.0	CHEMBL2332978,TN,INACT,0.009999999776482582	CHEMBL288316,TN,INACT,0.009999999776482582	CHEMBL3577521,TP,ACT,1.0	CHEMBL3289942,TN,INACT,0.0	CHEMBL75919,FP,INACT,0.9900000095367432	CHEMBL136611,TN,INACT,0.0	CHEMBL540830,TP,ACT,1.0	CHEMBL3393679,TN,INACT,0.0	CHEMBL1952062,TN,INACT,0.009999999776482582	CHEMBL359412,TN,INACT,0.009999999776482582	CHEMBL332376,TP,ACT,1.0	CHEMBL175975,TP,ACT,1.0	CHEMBL474577,TP,ACT,1.0	CHEMBL347749,TN,INACT,0.009999999776482582	CHEMBL158637,TP,ACT,0.9900000095367432	CHEMBL1940612,TN,INACT,0.019999999552965164	CHEMBL2160220,TN,INACT,0.2199999988079071	CHEMBL2181436,TN,INACT,0.0	CHEMBL3398310,TP,ACT,0.9100000262260437	CHEMBL148771,TN,INACT,0.029999999329447746	CHEMBL225366,FP,INACT,0.9900000095367432	CHEMBL123936,FP,INACT,0.9900000095367432	CHEMBL459825,TN,INACT,0.0	CHEMBL575830,TN,INACT,0.019999999552965164	CHEMBL389582,TP,ACT,1.0	CHEMBL147465,TN,INACT,0.0	CHEMBL594225,FN,ACT,0.0	CHEMBL147968,TN,INACT,0.0	CHEMBL543711,FP,INACT,1.0	CHEMBL1377579,TN,INACT,0.009999999776482582	CHEMBL127917,TN,INACT,0.0	CHEMBL475685,TP,ACT,0.9900000095367432	CHEMBL474190,TP,ACT,0.9900000095367432	CHEMBL331637,FP,INACT,0.9700000286102295	CHEMBL123361,TN,INACT,0.009999999776482582	CHEMBL214269,TP,ACT,0.9800000190734863	CHEMBL308793,FN,ACT,0.7799999713897705	CHEMBL594904,TP,ACT,1.0	CHEMBL3819247,TN,INACT,0.029999999329447746	CHEMBL1952067,TN,INACT,0.009999999776482582	CHEMBL2323716,TP,ACT,0.9900000095367432	CHEMBL318026,FN,ACT,0.009999999776482582	CHEMBL310918,TP,ACT,1.0	CHEMBL1081085,TN,INACT,0.10000000149011612	CHEMBL106582,FN,ACT,0.009999999776482582	CHEMBL456881,TN,INACT,0.4099999964237213	CHEMBL2069646,TP,ACT,1.0	CHEMBL397501,TP,ACT,0.9900000095367432	CHEMBL19487,TN,INACT,0.009999999776482582	CHEMBL2234520,TN,INACT,0.019999999552965164	CHEMBL2441691,TN,INACT,0.009999999776482582	CHEMBL434948,FP,INACT,1.0	CHEMBL121524,TP,ACT,0.9900000095367432	CHEMBL2323709,TP,ACT,0.8899999856948853	CHEMBL322392,TP,ACT,1.0	CHEMBL1766144,TN,INACT,0.0	CHEMBL497071,FN,ACT,0.7599999904632568	CHEMBL3087806,TN,INACT,0.009999999776482582	CHEMBL2069645,TP,ACT,1.0	CHEMBL2069767,TP,ACT,1.0	CHEMBL2376376,FN,ACT,0.8199999928474426	CHEMBL240047,TN,INACT,0.0	CHEMBL53240,TN,INACT,0.0	CHEMBL15576,TP,ACT,0.9900000095367432	CHEMBL2376368,TP,ACT,1.0	CHEMBL281799,FN,ACT,0.7300000190734863	CHEMBL3321878,FP,INACT,0.9700000286102295	CHEMBL1257996,TN,INACT,0.019999999552965164	CHEMBL473606,TP,ACT,1.0	CHEMBL50410,TN,INACT,0.0	CHEMBL575621,FN,ACT,0.46000000834465027	CHEMBL2160222,FP,INACT,0.9800000190734863	CHEMBL15043,TN,INACT,0.009999999776482582	CHEMBL126457,TN,INACT,0.009999999776482582	CHEMBL117447,TN,INACT,0.0	CHEMBL397871,TN,INACT,0.0	CHEMBL318170,TN,INACT,0.0	CHEMBL3335063,FP,INACT,0.9800000190734863	CHEMBL538556,FN,ACT,0.0	CHEMBL131827,TP,ACT,0.9900000095367432	CHEMBL15916,FN,ACT,0.019999999552965164	CHEMBL115897,TN,INACT,0.4399999976158142	CHEMBL119822,FN,ACT,0.019999999552965164	CHEMBL3321880,FN,ACT,0.009999999776482582	CHEMBL116379,TN,INACT,0.0	CHEMBL2069777,TP,ACT,1.0	CHEMBL307693,TP,ACT,0.9900000095367432	

