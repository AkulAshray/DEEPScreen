ImageNetInceptionV2 CHEMBL4722 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	2252
Number of inactive compounds :	2252
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4722_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4722_adam_0.001_15_0.8/
---------------------------------
Training samples: 2867
Validation samples: 897
--
Training Step: 1  | time: 76.492s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2867
[A[ATraining Step: 2  | total loss: [1m[32m0.63038[0m[0m | time: 91.292s
[2K
| Adam | epoch: 001 | loss: 0.63038 - acc: 0.5344 -- iter: 0064/2867
[A[ATraining Step: 3  | total loss: [1m[32m0.67066[0m[0m | time: 106.311s
[2K
| Adam | epoch: 001 | loss: 0.67066 - acc: 0.6341 -- iter: 0096/2867
[A[ATraining Step: 4  | total loss: [1m[32m1.21770[0m[0m | time: 124.792s
[2K
| Adam | epoch: 001 | loss: 1.21770 - acc: 0.5335 -- iter: 0128/2867
[A[ATraining Step: 5  | total loss: [1m[32m1.00249[0m[0m | time: 142.587s
[2K
| Adam | epoch: 001 | loss: 1.00249 - acc: 0.5752 -- iter: 0160/2867
[A[ATraining Step: 6  | total loss: [1m[32m0.76650[0m[0m | time: 159.497s
[2K
| Adam | epoch: 001 | loss: 0.76650 - acc: 0.6072 -- iter: 0192/2867
[A[ATraining Step: 7  | total loss: [1m[32m0.78305[0m[0m | time: 178.463s
[2K
| Adam | epoch: 001 | loss: 0.78305 - acc: 0.5616 -- iter: 0224/2867
[A[ATraining Step: 8  | total loss: [1m[32m0.81168[0m[0m | time: 201.511s
[2K
| Adam | epoch: 001 | loss: 0.81168 - acc: 0.4215 -- iter: 0256/2867
[A[ATraining Step: 9  | total loss: [1m[32m0.87260[0m[0m | time: 220.785s
[2K
| Adam | epoch: 001 | loss: 0.87260 - acc: 0.4134 -- iter: 0288/2867
[A[ATraining Step: 10  | total loss: [1m[32m0.79582[0m[0m | time: 237.777s
[2K
| Adam | epoch: 001 | loss: 0.79582 - acc: 0.4567 -- iter: 0320/2867
[A[ATraining Step: 11  | total loss: [1m[32m0.77761[0m[0m | time: 254.772s
[2K
| Adam | epoch: 001 | loss: 0.77761 - acc: 0.4624 -- iter: 0352/2867
[A[ATraining Step: 12  | total loss: [1m[32m0.79560[0m[0m | time: 271.688s
[2K
| Adam | epoch: 001 | loss: 0.79560 - acc: 0.5496 -- iter: 0384/2867
[A[ATraining Step: 13  | total loss: [1m[32m0.75403[0m[0m | time: 289.185s
[2K
| Adam | epoch: 001 | loss: 0.75403 - acc: 0.5819 -- iter: 0416/2867
[A[ATraining Step: 14  | total loss: [1m[32m0.76641[0m[0m | time: 309.342s
[2K
| Adam | epoch: 001 | loss: 0.76641 - acc: 0.6379 -- iter: 0448/2867
[A[ATraining Step: 15  | total loss: [1m[32m0.73872[0m[0m | time: 329.882s
[2K
| Adam | epoch: 001 | loss: 0.73872 - acc: 0.5962 -- iter: 0480/2867
[A[ATraining Step: 16  | total loss: [1m[32m0.73437[0m[0m | time: 347.381s
[2K
| Adam | epoch: 001 | loss: 0.73437 - acc: 0.5953 -- iter: 0512/2867
[A[ATraining Step: 17  | total loss: [1m[32m0.72955[0m[0m | time: 364.524s
[2K
| Adam | epoch: 001 | loss: 0.72955 - acc: 0.5722 -- iter: 0544/2867
[A[ATraining Step: 18  | total loss: [1m[32m0.71376[0m[0m | time: 378.664s
[2K
| Adam | epoch: 001 | loss: 0.71376 - acc: 0.5689 -- iter: 0576/2867
[A[ATraining Step: 19  | total loss: [1m[32m0.70061[0m[0m | time: 393.863s
[2K
| Adam | epoch: 001 | loss: 0.70061 - acc: 0.5772 -- iter: 0608/2867
[A[ATraining Step: 20  | total loss: [1m[32m0.69037[0m[0m | time: 405.959s
[2K
| Adam | epoch: 001 | loss: 0.69037 - acc: 0.5825 -- iter: 0640/2867
[A[ATraining Step: 21  | total loss: [1m[32m0.71040[0m[0m | time: 420.816s
[2K
| Adam | epoch: 001 | loss: 0.71040 - acc: 0.5860 -- iter: 0672/2867
[A[ATraining Step: 22  | total loss: [1m[32m0.67269[0m[0m | time: 438.179s
[2K
| Adam | epoch: 001 | loss: 0.67269 - acc: 0.6352 -- iter: 0704/2867
[A[ATraining Step: 23  | total loss: [1m[32m0.69447[0m[0m | time: 455.005s
[2K
| Adam | epoch: 001 | loss: 0.69447 - acc: 0.6050 -- iter: 0736/2867
[A[ATraining Step: 24  | total loss: [1m[32m0.67804[0m[0m | time: 472.536s
[2K
| Adam | epoch: 001 | loss: 0.67804 - acc: 0.6106 -- iter: 0768/2867
[A[ATraining Step: 25  | total loss: [1m[32m0.66792[0m[0m | time: 489.525s
[2K
| Adam | epoch: 001 | loss: 0.66792 - acc: 0.5975 -- iter: 0800/2867
[A[ATraining Step: 26  | total loss: [1m[32m0.67636[0m[0m | time: 507.486s
[2K
| Adam | epoch: 001 | loss: 0.67636 - acc: 0.5800 -- iter: 0832/2867
[A[ATraining Step: 27  | total loss: [1m[32m0.67412[0m[0m | time: 526.337s
[2K
| Adam | epoch: 001 | loss: 0.67412 - acc: 0.5674 -- iter: 0864/2867
[A[ATraining Step: 28  | total loss: [1m[32m0.65156[0m[0m | time: 544.616s
[2K
| Adam | epoch: 001 | loss: 0.65156 - acc: 0.6131 -- iter: 0896/2867
[A[ATraining Step: 29  | total loss: [1m[32m0.62583[0m[0m | time: 556.538s
[2K
| Adam | epoch: 001 | loss: 0.62583 - acc: 0.6464 -- iter: 0928/2867
[A[ATraining Step: 30  | total loss: [1m[32m0.61499[0m[0m | time: 568.380s
[2K
| Adam | epoch: 001 | loss: 0.61499 - acc: 0.6561 -- iter: 0960/2867
[A[ATraining Step: 31  | total loss: [1m[32m0.61411[0m[0m | time: 583.842s
[2K
| Adam | epoch: 001 | loss: 0.61411 - acc: 0.6489 -- iter: 0992/2867
[A[ATraining Step: 32  | total loss: [1m[32m0.62362[0m[0m | time: 600.377s
[2K
| Adam | epoch: 001 | loss: 0.62362 - acc: 0.6506 -- iter: 1024/2867
[A[ATraining Step: 33  | total loss: [1m[32m0.64613[0m[0m | time: 617.059s
[2K
| Adam | epoch: 001 | loss: 0.64613 - acc: 0.6450 -- iter: 1056/2867
[A[ATraining Step: 34  | total loss: [1m[32m0.66486[0m[0m | time: 635.675s
[2K
| Adam | epoch: 001 | loss: 0.66486 - acc: 0.6340 -- iter: 1088/2867
[A[ATraining Step: 35  | total loss: [1m[32m0.66581[0m[0m | time: 653.536s
[2K
| Adam | epoch: 001 | loss: 0.66581 - acc: 0.6256 -- iter: 1120/2867
[A[ATraining Step: 36  | total loss: [1m[32m0.67701[0m[0m | time: 670.228s
[2K
| Adam | epoch: 001 | loss: 0.67701 - acc: 0.6063 -- iter: 1152/2867
[A[ATraining Step: 37  | total loss: [1m[32m0.68506[0m[0m | time: 683.570s
[2K
| Adam | epoch: 001 | loss: 0.68506 - acc: 0.5975 -- iter: 1184/2867
[A[ATraining Step: 38  | total loss: [1m[32m0.67955[0m[0m | time: 698.273s
[2K
| Adam | epoch: 001 | loss: 0.67955 - acc: 0.5907 -- iter: 1216/2867
[A[ATraining Step: 39  | total loss: [1m[32m0.66610[0m[0m | time: 715.459s
[2K
| Adam | epoch: 001 | loss: 0.66610 - acc: 0.6092 -- iter: 1248/2867
[A[ATraining Step: 40  | total loss: [1m[32m0.64593[0m[0m | time: 732.156s
[2K
| Adam | epoch: 001 | loss: 0.64593 - acc: 0.6532 -- iter: 1280/2867
[A[ATraining Step: 41  | total loss: [1m[32m0.65928[0m[0m | time: 751.452s
[2K
| Adam | epoch: 001 | loss: 0.65928 - acc: 0.6308 -- iter: 1312/2867
[A[ATraining Step: 42  | total loss: [1m[32m0.68099[0m[0m | time: 770.754s
[2K
| Adam | epoch: 001 | loss: 0.68099 - acc: 0.6072 -- iter: 1344/2867
[A[ATraining Step: 43  | total loss: [1m[32m0.66416[0m[0m | time: 791.160s
[2K
| Adam | epoch: 001 | loss: 0.66416 - acc: 0.6104 -- iter: 1376/2867
[A[ATraining Step: 44  | total loss: [1m[32m0.67103[0m[0m | time: 807.097s
[2K
| Adam | epoch: 001 | loss: 0.67103 - acc: 0.6021 -- iter: 1408/2867
[A[ATraining Step: 45  | total loss: [1m[32m0.67130[0m[0m | time: 824.607s
[2K
| Adam | epoch: 001 | loss: 0.67130 - acc: 0.6113 -- iter: 1440/2867
[A[ATraining Step: 46  | total loss: [1m[32m0.65906[0m[0m | time: 842.242s
[2K
| Adam | epoch: 001 | loss: 0.65906 - acc: 0.6188 -- iter: 1472/2867
[A[ATraining Step: 47  | total loss: [1m[32m0.65678[0m[0m | time: 858.591s
[2K
| Adam | epoch: 001 | loss: 0.65678 - acc: 0.6147 -- iter: 1504/2867
[A[ATraining Step: 48  | total loss: [1m[32m0.64820[0m[0m | time: 875.404s
[2K
| Adam | epoch: 001 | loss: 0.64820 - acc: 0.6214 -- iter: 1536/2867
[A[ATraining Step: 49  | total loss: [1m[32m0.64169[0m[0m | time: 892.506s
[2K
| Adam | epoch: 001 | loss: 0.64169 - acc: 0.6170 -- iter: 1568/2867
[A[ATraining Step: 50  | total loss: [1m[32m0.63121[0m[0m | time: 909.326s
[2K
| Adam | epoch: 001 | loss: 0.63121 - acc: 0.6328 -- iter: 1600/2867
[A[ATraining Step: 51  | total loss: [1m[32m0.67165[0m[0m | time: 925.762s
[2K
| Adam | epoch: 001 | loss: 0.67165 - acc: 0.6173 -- iter: 1632/2867
[A[ATraining Step: 52  | total loss: [1m[32m0.66728[0m[0m | time: 942.853s
[2K
| Adam | epoch: 001 | loss: 0.66728 - acc: 0.6231 -- iter: 1664/2867
[A[ATraining Step: 53  | total loss: [1m[32m0.62946[0m[0m | time: 959.544s
[2K
| Adam | epoch: 001 | loss: 0.62946 - acc: 0.6603 -- iter: 1696/2867
[A[ATraining Step: 54  | total loss: [1m[32m0.67089[0m[0m | time: 980.758s
[2K
| Adam | epoch: 001 | loss: 0.67089 - acc: 0.6416 -- iter: 1728/2867
[A[ATraining Step: 55  | total loss: [1m[32m0.66423[0m[0m | time: 997.127s
[2K
| Adam | epoch: 001 | loss: 0.66423 - acc: 0.6303 -- iter: 1760/2867
[A[ATraining Step: 56  | total loss: [1m[32m0.66120[0m[0m | time: 1013.573s
[2K
| Adam | epoch: 001 | loss: 0.66120 - acc: 0.6339 -- iter: 1792/2867
[A[ATraining Step: 57  | total loss: [1m[32m0.65581[0m[0m | time: 1029.604s
[2K
| Adam | epoch: 001 | loss: 0.65581 - acc: 0.6413 -- iter: 1824/2867
[A[ATraining Step: 58  | total loss: [1m[32m0.65388[0m[0m | time: 1046.636s
[2K
| Adam | epoch: 001 | loss: 0.65388 - acc: 0.6306 -- iter: 1856/2867
[A[ATraining Step: 59  | total loss: [1m[32m0.64804[0m[0m | time: 1060.661s
[2K
| Adam | epoch: 001 | loss: 0.64804 - acc: 0.6340 -- iter: 1888/2867
[A[ATraining Step: 60  | total loss: [1m[32m0.63025[0m[0m | time: 1072.592s
[2K
| Adam | epoch: 001 | loss: 0.63025 - acc: 0.6535 -- iter: 1920/2867
[A[ATraining Step: 61  | total loss: [1m[32m0.63023[0m[0m | time: 1087.520s
[2K
| Adam | epoch: 001 | loss: 0.63023 - acc: 0.6539 -- iter: 1952/2867
[A[ATraining Step: 62  | total loss: [1m[32m0.66041[0m[0m | time: 1104.525s
[2K
| Adam | epoch: 001 | loss: 0.66041 - acc: 0.6381 -- iter: 1984/2867
[A[ATraining Step: 63  | total loss: [1m[32m0.65601[0m[0m | time: 1121.610s
[2K
| Adam | epoch: 001 | loss: 0.65601 - acc: 0.6404 -- iter: 2016/2867
[A[ATraining Step: 64  | total loss: [1m[32m0.65100[0m[0m | time: 1135.951s
[2K
| Adam | epoch: 001 | loss: 0.65100 - acc: 0.6463 -- iter: 2048/2867
[A[ATraining Step: 65  | total loss: [1m[32m0.63047[0m[0m | time: 1148.300s
[2K
| Adam | epoch: 001 | loss: 0.63047 - acc: 0.6591 -- iter: 2080/2867
[A[ATraining Step: 66  | total loss: [1m[32m0.62091[0m[0m | time: 1162.279s
[2K
| Adam | epoch: 001 | loss: 0.62091 - acc: 0.6663 -- iter: 2112/2867
[A[ATraining Step: 67  | total loss: [1m[32m0.61524[0m[0m | time: 1186.224s
[2K
| Adam | epoch: 001 | loss: 0.61524 - acc: 0.6651 -- iter: 2144/2867
[A[ATraining Step: 68  | total loss: [1m[32m0.61680[0m[0m | time: 1207.778s
[2K
| Adam | epoch: 001 | loss: 0.61680 - acc: 0.6641 -- iter: 2176/2867
[A[ATraining Step: 69  | total loss: [1m[32m0.62102[0m[0m | time: 1224.320s
[2K
| Adam | epoch: 001 | loss: 0.62102 - acc: 0.6632 -- iter: 2208/2867
[A[ATraining Step: 70  | total loss: [1m[32m0.62510[0m[0m | time: 1241.385s
[2K
| Adam | epoch: 001 | loss: 0.62510 - acc: 0.6515 -- iter: 2240/2867
[A[ATraining Step: 71  | total loss: [1m[32m0.62188[0m[0m | time: 1258.444s
[2K
| Adam | epoch: 001 | loss: 0.62188 - acc: 0.6556 -- iter: 2272/2867
[A[ATraining Step: 72  | total loss: [1m[32m0.61640[0m[0m | time: 1274.543s
[2K
| Adam | epoch: 001 | loss: 0.61640 - acc: 0.6627 -- iter: 2304/2867
[A[ATraining Step: 73  | total loss: [1m[32m0.61728[0m[0m | time: 1302.792s
[2K
| Adam | epoch: 001 | loss: 0.61728 - acc: 0.6620 -- iter: 2336/2867
[A[ATraining Step: 74  | total loss: [1m[32m0.61137[0m[0m | time: 1328.565s
[2K
| Adam | epoch: 001 | loss: 0.61137 - acc: 0.6614 -- iter: 2368/2867
[A[ATraining Step: 75  | total loss: [1m[32m0.60274[0m[0m | time: 1373.399s
[2K
| Adam | epoch: 001 | loss: 0.60274 - acc: 0.6642 -- iter: 2400/2867
[A[ATraining Step: 76  | total loss: [1m[32m0.59330[0m[0m | time: 1389.181s
[2K
| Adam | epoch: 001 | loss: 0.59330 - acc: 0.6734 -- iter: 2432/2867
[A[ATraining Step: 77  | total loss: [1m[32m0.58281[0m[0m | time: 1405.356s
[2K
| Adam | epoch: 001 | loss: 0.58281 - acc: 0.6848 -- iter: 2464/2867
[A[ATraining Step: 78  | total loss: [1m[32m0.59822[0m[0m | time: 1422.113s
[2K
| Adam | epoch: 001 | loss: 0.59822 - acc: 0.6720 -- iter: 2496/2867
[A[ATraining Step: 79  | total loss: [1m[32m0.60490[0m[0m | time: 1438.997s
[2K
| Adam | epoch: 001 | loss: 0.60490 - acc: 0.6704 -- iter: 2528/2867
[A[ATraining Step: 80  | total loss: [1m[32m0.60510[0m[0m | time: 1455.830s
[2K
| Adam | epoch: 001 | loss: 0.60510 - acc: 0.6753 -- iter: 2560/2867
[A[ATraining Step: 81  | total loss: [1m[32m0.61455[0m[0m | time: 1472.555s
[2K
| Adam | epoch: 001 | loss: 0.61455 - acc: 0.6671 -- iter: 2592/2867
[A[ATraining Step: 82  | total loss: [1m[32m0.60550[0m[0m | time: 1488.952s
[2K
| Adam | epoch: 001 | loss: 0.60550 - acc: 0.6754 -- iter: 2624/2867
[A[ATraining Step: 83  | total loss: [1m[32m0.60659[0m[0m | time: 1505.737s
[2K
| Adam | epoch: 001 | loss: 0.60659 - acc: 0.6735 -- iter: 2656/2867
[A[ATraining Step: 84  | total loss: [1m[32m0.60590[0m[0m | time: 1525.136s
[2K
| Adam | epoch: 001 | loss: 0.60590 - acc: 0.6717 -- iter: 2688/2867
[A[ATraining Step: 85  | total loss: [1m[32m0.59758[0m[0m | time: 1541.851s
[2K
| Adam | epoch: 001 | loss: 0.59758 - acc: 0.6827 -- iter: 2720/2867
[A[ATraining Step: 86  | total loss: [1m[32m0.59647[0m[0m | time: 1558.916s
[2K
| Adam | epoch: 001 | loss: 0.59647 - acc: 0.6801 -- iter: 2752/2867
[A[ATraining Step: 87  | total loss: [1m[32m0.60089[0m[0m | time: 1572.293s
[2K
| Adam | epoch: 001 | loss: 0.60089 - acc: 0.6777 -- iter: 2784/2867
[A[ATraining Step: 88  | total loss: [1m[32m0.61308[0m[0m | time: 1584.142s
[2K
| Adam | epoch: 001 | loss: 0.61308 - acc: 0.6724 -- iter: 2816/2867
[A[ATraining Step: 89  | total loss: [1m[32m0.61113[0m[0m | time: 1596.962s
[2K
| Adam | epoch: 001 | loss: 0.61113 - acc: 0.6770 -- iter: 2848/2867
[A[ATraining Step: 90  | total loss: [1m[32m0.58909[0m[0m | time: 1709.231s
[2K
| Adam | epoch: 001 | loss: 0.58909 - acc: 0.6937 | val_loss: 0.60015 - val_acc: 0.6745 -- iter: 2867/2867
--
Training Step: 91  | total loss: [1m[32m0.58406[0m[0m | time: 11.196s
[2K
| Adam | epoch: 002 | loss: 0.58406 - acc: 0.6980 -- iter: 0032/2867
[A[ATraining Step: 92  | total loss: [1m[32m0.56736[0m[0m | time: 26.655s
[2K
| Adam | epoch: 002 | loss: 0.56736 - acc: 0.7124 -- iter: 0064/2867
[A[ATraining Step: 93  | total loss: [1m[32m0.56214[0m[0m | time: 39.879s
[2K
| Adam | epoch: 002 | loss: 0.56214 - acc: 0.7162 -- iter: 0096/2867
[A[ATraining Step: 94  | total loss: [1m[32m0.58656[0m[0m | time: 56.134s
[2K
| Adam | epoch: 002 | loss: 0.58656 - acc: 0.7071 -- iter: 0128/2867
[A[ATraining Step: 95  | total loss: [1m[32m0.58589[0m[0m | time: 74.008s
[2K
| Adam | epoch: 002 | loss: 0.58589 - acc: 0.7114 -- iter: 0160/2867
[A[ATraining Step: 96  | total loss: [1m[32m0.58533[0m[0m | time: 93.501s
[2K
| Adam | epoch: 002 | loss: 0.58533 - acc: 0.7184 -- iter: 0192/2867
[A[ATraining Step: 97  | total loss: [1m[32m0.58574[0m[0m | time: 109.992s
[2K
| Adam | epoch: 002 | loss: 0.58574 - acc: 0.7090 -- iter: 0224/2867
[A[ATraining Step: 98  | total loss: [1m[32m0.60847[0m[0m | time: 126.424s
[2K
| Adam | epoch: 002 | loss: 0.60847 - acc: 0.6944 -- iter: 0256/2867
[A[ATraining Step: 99  | total loss: [1m[32m0.60284[0m[0m | time: 143.174s
[2K
| Adam | epoch: 002 | loss: 0.60284 - acc: 0.6906 -- iter: 0288/2867
[A[ATraining Step: 100  | total loss: [1m[32m0.58939[0m[0m | time: 159.630s
[2K
| Adam | epoch: 002 | loss: 0.58939 - acc: 0.7027 -- iter: 0320/2867
[A[ATraining Step: 101  | total loss: [1m[32m0.59633[0m[0m | time: 177.187s
[2K
| Adam | epoch: 002 | loss: 0.59633 - acc: 0.7043 -- iter: 0352/2867
[A[ATraining Step: 102  | total loss: [1m[32m0.58652[0m[0m | time: 194.543s
[2K
| Adam | epoch: 002 | loss: 0.58652 - acc: 0.7120 -- iter: 0384/2867
[A[ATraining Step: 103  | total loss: [1m[32m0.59046[0m[0m | time: 210.755s
[2K
| Adam | epoch: 002 | loss: 0.59046 - acc: 0.7096 -- iter: 0416/2867
[A[ATraining Step: 104  | total loss: [1m[32m0.60651[0m[0m | time: 223.156s
[2K
| Adam | epoch: 002 | loss: 0.60651 - acc: 0.6980 -- iter: 0448/2867
[A[ATraining Step: 105  | total loss: [1m[32m0.59728[0m[0m | time: 236.331s
[2K
| Adam | epoch: 002 | loss: 0.59728 - acc: 0.7063 -- iter: 0480/2867
[A[ATraining Step: 106  | total loss: [1m[32m0.60014[0m[0m | time: 252.045s
[2K
| Adam | epoch: 002 | loss: 0.60014 - acc: 0.7013 -- iter: 0512/2867
[A[ATraining Step: 107  | total loss: [1m[32m0.58743[0m[0m | time: 264.166s
[2K
| Adam | epoch: 002 | loss: 0.58743 - acc: 0.7124 -- iter: 0544/2867
[A[ATraining Step: 108  | total loss: [1m[32m0.59530[0m[0m | time: 276.727s
[2K
| Adam | epoch: 002 | loss: 0.59530 - acc: 0.7006 -- iter: 0576/2867
[A[ATraining Step: 109  | total loss: [1m[32m0.59730[0m[0m | time: 291.796s
[2K
| Adam | epoch: 002 | loss: 0.59730 - acc: 0.6961 -- iter: 0608/2867
[A[ATraining Step: 110  | total loss: [1m[32m0.59313[0m[0m | time: 308.741s
[2K
| Adam | epoch: 002 | loss: 0.59313 - acc: 0.6984 -- iter: 0640/2867
[A[ATraining Step: 111  | total loss: [1m[32m0.61171[0m[0m | time: 325.679s
[2K
| Adam | epoch: 002 | loss: 0.61171 - acc: 0.6848 -- iter: 0672/2867
[A[ATraining Step: 112  | total loss: [1m[32m0.61284[0m[0m | time: 343.064s
[2K
| Adam | epoch: 002 | loss: 0.61284 - acc: 0.6820 -- iter: 0704/2867
[A[ATraining Step: 113  | total loss: [1m[32m0.59565[0m[0m | time: 359.702s
[2K
| Adam | epoch: 002 | loss: 0.59565 - acc: 0.7013 -- iter: 0736/2867
[A[ATraining Step: 114  | total loss: [1m[32m0.59712[0m[0m | time: 376.210s
[2K
| Adam | epoch: 002 | loss: 0.59712 - acc: 0.6936 -- iter: 0768/2867
[A[ATraining Step: 115  | total loss: [1m[32m0.59838[0m[0m | time: 392.959s
[2K
| Adam | epoch: 002 | loss: 0.59838 - acc: 0.6930 -- iter: 0800/2867
[A[ATraining Step: 116  | total loss: [1m[32m0.59038[0m[0m | time: 408.731s
[2K
| Adam | epoch: 002 | loss: 0.59038 - acc: 0.7050 -- iter: 0832/2867
[A[ATraining Step: 117  | total loss: [1m[32m0.60723[0m[0m | time: 436.462s
[2K
| Adam | epoch: 002 | loss: 0.60723 - acc: 0.6907 -- iter: 0864/2867
[A[ATraining Step: 118  | total loss: [1m[32m0.60791[0m[0m | time: 453.383s
[2K
| Adam | epoch: 002 | loss: 0.60791 - acc: 0.6873 -- iter: 0896/2867
[A[ATraining Step: 119  | total loss: [1m[32m0.62161[0m[0m | time: 470.183s
[2K
| Adam | epoch: 002 | loss: 0.62161 - acc: 0.6810 -- iter: 0928/2867
[A[ATraining Step: 120  | total loss: [1m[32m0.62836[0m[0m | time: 486.767s
[2K
| Adam | epoch: 002 | loss: 0.62836 - acc: 0.6786 -- iter: 0960/2867
[A[ATraining Step: 121  | total loss: [1m[32m0.63774[0m[0m | time: 503.137s
[2K
| Adam | epoch: 002 | loss: 0.63774 - acc: 0.6638 -- iter: 0992/2867
[A[ATraining Step: 122  | total loss: [1m[32m0.63692[0m[0m | time: 520.037s
[2K
| Adam | epoch: 002 | loss: 0.63692 - acc: 0.6600 -- iter: 1024/2867
[A[ATraining Step: 123  | total loss: [1m[32m0.63651[0m[0m | time: 537.186s
[2K
| Adam | epoch: 002 | loss: 0.63651 - acc: 0.6533 -- iter: 1056/2867
[A[ATraining Step: 124  | total loss: [1m[32m0.64486[0m[0m | time: 553.649s
[2K
| Adam | epoch: 002 | loss: 0.64486 - acc: 0.6255 -- iter: 1088/2867
[A[ATraining Step: 125  | total loss: [1m[32m0.64011[0m[0m | time: 570.758s
[2K
| Adam | epoch: 002 | loss: 0.64011 - acc: 0.6317 -- iter: 1120/2867
[A[ATraining Step: 126  | total loss: [1m[32m0.63240[0m[0m | time: 587.970s
[2K
| Adam | epoch: 002 | loss: 0.63240 - acc: 0.6467 -- iter: 1152/2867
[A[ATraining Step: 127  | total loss: [1m[32m0.63494[0m[0m | time: 609.869s
[2K
| Adam | epoch: 002 | loss: 0.63494 - acc: 0.6445 -- iter: 1184/2867
[A[ATraining Step: 128  | total loss: [1m[32m0.62641[0m[0m | time: 626.528s
[2K
| Adam | epoch: 002 | loss: 0.62641 - acc: 0.6582 -- iter: 1216/2867
[A[ATraining Step: 129  | total loss: [1m[32m0.63035[0m[0m | time: 643.335s
[2K
| Adam | epoch: 002 | loss: 0.63035 - acc: 0.6580 -- iter: 1248/2867
[A[ATraining Step: 130  | total loss: [1m[32m0.62430[0m[0m | time: 659.891s
[2K
| Adam | epoch: 002 | loss: 0.62430 - acc: 0.6672 -- iter: 1280/2867
[A[ATraining Step: 131  | total loss: [1m[32m0.62364[0m[0m | time: 676.720s
[2K
| Adam | epoch: 002 | loss: 0.62364 - acc: 0.6692 -- iter: 1312/2867
[A[ATraining Step: 132  | total loss: [1m[32m0.63464[0m[0m | time: 693.721s
[2K
| Adam | epoch: 002 | loss: 0.63464 - acc: 0.6554 -- iter: 1344/2867
[A[ATraining Step: 133  | total loss: [1m[32m0.64008[0m[0m | time: 710.716s
[2K
| Adam | epoch: 002 | loss: 0.64008 - acc: 0.6524 -- iter: 1376/2867
[A[ATraining Step: 134  | total loss: [1m[32m0.62974[0m[0m | time: 726.753s
[2K
| Adam | epoch: 002 | loss: 0.62974 - acc: 0.6621 -- iter: 1408/2867
[A[ATraining Step: 135  | total loss: [1m[32m0.62397[0m[0m | time: 738.976s
[2K
| Adam | epoch: 002 | loss: 0.62397 - acc: 0.6615 -- iter: 1440/2867
[A[ATraining Step: 136  | total loss: [1m[32m0.62800[0m[0m | time: 750.815s
[2K
| Adam | epoch: 002 | loss: 0.62800 - acc: 0.6610 -- iter: 1472/2867
[A[ATraining Step: 137  | total loss: [1m[32m0.62651[0m[0m | time: 767.090s
[2K
| Adam | epoch: 002 | loss: 0.62651 - acc: 0.6668 -- iter: 1504/2867
[A[ATraining Step: 138  | total loss: [1m[32m0.62770[0m[0m | time: 783.986s
[2K
| Adam | epoch: 002 | loss: 0.62770 - acc: 0.6751 -- iter: 1536/2867
[A[ATraining Step: 139  | total loss: [1m[32m0.62095[0m[0m | time: 800.986s
[2K
| Adam | epoch: 002 | loss: 0.62095 - acc: 0.6732 -- iter: 1568/2867
[A[ATraining Step: 140  | total loss: [1m[32m0.61695[0m[0m | time: 817.845s
[2K
| Adam | epoch: 002 | loss: 0.61695 - acc: 0.6684 -- iter: 1600/2867
[A[ATraining Step: 141  | total loss: [1m[32m0.61395[0m[0m | time: 834.475s
[2K
| Adam | epoch: 002 | loss: 0.61395 - acc: 0.6703 -- iter: 1632/2867
[A[ATraining Step: 142  | total loss: [1m[32m0.62215[0m[0m | time: 851.297s
[2K
| Adam | epoch: 002 | loss: 0.62215 - acc: 0.6627 -- iter: 1664/2867
[A[ATraining Step: 143  | total loss: [1m[32m0.61048[0m[0m | time: 870.798s
[2K
| Adam | epoch: 002 | loss: 0.61048 - acc: 0.6808 -- iter: 1696/2867
[A[ATraining Step: 144  | total loss: [1m[32m0.60842[0m[0m | time: 887.680s
[2K
| Adam | epoch: 002 | loss: 0.60842 - acc: 0.6846 -- iter: 1728/2867
[A[ATraining Step: 145  | total loss: [1m[32m0.60946[0m[0m | time: 904.627s
[2K
| Adam | epoch: 002 | loss: 0.60946 - acc: 0.6849 -- iter: 1760/2867
[A[ATraining Step: 146  | total loss: [1m[32m0.60151[0m[0m | time: 921.828s
[2K
| Adam | epoch: 002 | loss: 0.60151 - acc: 0.6851 -- iter: 1792/2867
[A[ATraining Step: 147  | total loss: [1m[32m0.60109[0m[0m | time: 936.899s
[2K
| Adam | epoch: 002 | loss: 0.60109 - acc: 0.6791 -- iter: 1824/2867
[A[ATraining Step: 148  | total loss: [1m[32m0.57860[0m[0m | time: 949.218s
[2K
| Adam | epoch: 002 | loss: 0.57860 - acc: 0.6987 -- iter: 1856/2867
[A[ATraining Step: 149  | total loss: [1m[32m0.57415[0m[0m | time: 962.617s
[2K
| Adam | epoch: 002 | loss: 0.57415 - acc: 0.7101 -- iter: 1888/2867
[A[ATraining Step: 150  | total loss: [1m[32m0.60490[0m[0m | time: 979.034s
[2K
| Adam | epoch: 002 | loss: 0.60490 - acc: 0.6922 -- iter: 1920/2867
[A[ATraining Step: 151  | total loss: [1m[32m0.59461[0m[0m | time: 996.073s
[2K
| Adam | epoch: 002 | loss: 0.59461 - acc: 0.7042 -- iter: 1952/2867
[A[ATraining Step: 152  | total loss: [1m[32m0.58468[0m[0m | time: 1012.695s
[2K
| Adam | epoch: 002 | loss: 0.58468 - acc: 0.7088 -- iter: 1984/2867
[A[ATraining Step: 153  | total loss: [1m[32m0.56560[0m[0m | time: 1032.079s
[2K
| Adam | epoch: 002 | loss: 0.56560 - acc: 0.7223 -- iter: 2016/2867
[A[ATraining Step: 154  | total loss: [1m[32m0.55497[0m[0m | time: 1049.643s
[2K
| Adam | epoch: 002 | loss: 0.55497 - acc: 0.7344 -- iter: 2048/2867
[A[ATraining Step: 155  | total loss: [1m[32m0.55730[0m[0m | time: 1066.326s
[2K
| Adam | epoch: 002 | loss: 0.55730 - acc: 0.7391 -- iter: 2080/2867
[A[ATraining Step: 156  | total loss: [1m[32m0.56040[0m[0m | time: 1083.153s
[2K
| Adam | epoch: 002 | loss: 0.56040 - acc: 0.7371 -- iter: 2112/2867
[A[ATraining Step: 157  | total loss: [1m[32m0.54610[0m[0m | time: 1100.182s
[2K
| Adam | epoch: 002 | loss: 0.54610 - acc: 0.7415 -- iter: 2144/2867
[A[ATraining Step: 158  | total loss: [1m[32m0.54429[0m[0m | time: 1116.905s
[2K
| Adam | epoch: 002 | loss: 0.54429 - acc: 0.7455 -- iter: 2176/2867
[A[ATraining Step: 159  | total loss: [1m[32m0.54882[0m[0m | time: 1133.373s
[2K
| Adam | epoch: 002 | loss: 0.54882 - acc: 0.7428 -- iter: 2208/2867
[A[ATraining Step: 160  | total loss: [1m[32m0.56936[0m[0m | time: 1149.104s
[2K
| Adam | epoch: 002 | loss: 0.56936 - acc: 0.7373 -- iter: 2240/2867
[A[ATraining Step: 161  | total loss: [1m[32m0.56983[0m[0m | time: 1165.912s
[2K
| Adam | epoch: 002 | loss: 0.56983 - acc: 0.7292 -- iter: 2272/2867
[A[ATraining Step: 162  | total loss: [1m[32m0.56528[0m[0m | time: 1179.723s
[2K
| Adam | epoch: 002 | loss: 0.56528 - acc: 0.7250 -- iter: 2304/2867
[A[ATraining Step: 163  | total loss: [1m[32m0.56227[0m[0m | time: 1191.985s
[2K
| Adam | epoch: 002 | loss: 0.56227 - acc: 0.7213 -- iter: 2336/2867
[A[ATraining Step: 164  | total loss: [1m[32m0.55599[0m[0m | time: 1205.969s
[2K
| Adam | epoch: 002 | loss: 0.55599 - acc: 0.7366 -- iter: 2368/2867
[A[ATraining Step: 165  | total loss: [1m[32m0.55703[0m[0m | time: 1223.093s
[2K
| Adam | epoch: 002 | loss: 0.55703 - acc: 0.7255 -- iter: 2400/2867
[A[ATraining Step: 166  | total loss: [1m[32m0.54333[0m[0m | time: 1239.550s
[2K
| Adam | epoch: 002 | loss: 0.54333 - acc: 0.7373 -- iter: 2432/2867
[A[ATraining Step: 167  | total loss: [1m[32m0.54317[0m[0m | time: 1256.259s
[2K
| Adam | epoch: 002 | loss: 0.54317 - acc: 0.7386 -- iter: 2464/2867
[A[ATraining Step: 168  | total loss: [1m[32m0.53562[0m[0m | time: 1272.897s
[2K
| Adam | epoch: 002 | loss: 0.53562 - acc: 0.7397 -- iter: 2496/2867
[A[ATraining Step: 169  | total loss: [1m[32m0.54802[0m[0m | time: 1290.095s
[2K
| Adam | epoch: 002 | loss: 0.54802 - acc: 0.7314 -- iter: 2528/2867
[A[ATraining Step: 170  | total loss: [1m[32m0.54058[0m[0m | time: 1306.883s
[2K
| Adam | epoch: 002 | loss: 0.54058 - acc: 0.7332 -- iter: 2560/2867
[A[ATraining Step: 171  | total loss: [1m[32m0.54686[0m[0m | time: 1323.458s
[2K
| Adam | epoch: 002 | loss: 0.54686 - acc: 0.7224 -- iter: 2592/2867
[A[ATraining Step: 172  | total loss: [1m[32m0.55110[0m[0m | time: 1340.251s
[2K
| Adam | epoch: 002 | loss: 0.55110 - acc: 0.7158 -- iter: 2624/2867
[A[ATraining Step: 173  | total loss: [1m[32m0.54917[0m[0m | time: 1356.667s
[2K
| Adam | epoch: 002 | loss: 0.54917 - acc: 0.7161 -- iter: 2656/2867
[A[ATraining Step: 174  | total loss: [1m[32m0.55663[0m[0m | time: 1374.310s
[2K
| Adam | epoch: 002 | loss: 0.55663 - acc: 0.7132 -- iter: 2688/2867
[A[ATraining Step: 175  | total loss: [1m[32m0.54838[0m[0m | time: 1391.321s
[2K
| Adam | epoch: 002 | loss: 0.54838 - acc: 0.7200 -- iter: 2720/2867
[A[ATraining Step: 176  | total loss: [1m[32m0.54268[0m[0m | time: 1407.886s
[2K
| Adam | epoch: 002 | loss: 0.54268 - acc: 0.7293 -- iter: 2752/2867
[A[ATraining Step: 177  | total loss: [1m[32m0.54463[0m[0m | time: 1424.547s
[2K
| Adam | epoch: 002 | loss: 0.54463 - acc: 0.7251 -- iter: 2784/2867
[A[ATraining Step: 178  | total loss: [1m[32m0.53689[0m[0m | time: 1440.916s
[2K
| Adam | epoch: 002 | loss: 0.53689 - acc: 0.7338 -- iter: 2816/2867
[A[ATraining Step: 179  | total loss: [1m[32m0.52058[0m[0m | time: 1457.906s
[2K
| Adam | epoch: 002 | loss: 0.52058 - acc: 0.7511 -- iter: 2848/2867
[A[ATraining Step: 180  | total loss: [1m[32m0.53007[0m[0m | time: 1564.169s
[2K
| Adam | epoch: 002 | loss: 0.53007 - acc: 0.7447 | val_loss: 1.03605 - val_acc: 0.5240 -- iter: 2867/2867
--
Training Step: 181  | total loss: [1m[32m0.54908[0m[0m | time: 11.234s
[2K
| Adam | epoch: 003 | loss: 0.54908 - acc: 0.7296 -- iter: 0032/2867
[A[ATraining Step: 182  | total loss: [1m[32m0.55292[0m[0m | time: 23.585s
[2K
| Adam | epoch: 003 | loss: 0.55292 - acc: 0.7409 -- iter: 0064/2867
[A[ATraining Step: 183  | total loss: [1m[32m0.54711[0m[0m | time: 37.578s
[2K
| Adam | epoch: 003 | loss: 0.54711 - acc: 0.7510 -- iter: 0096/2867
[A[ATraining Step: 184  | total loss: [1m[32m0.54653[0m[0m | time: 48.424s
[2K
| Adam | epoch: 003 | loss: 0.54653 - acc: 0.7384 -- iter: 0128/2867
[A[ATraining Step: 185  | total loss: [1m[32m0.54326[0m[0m | time: 56.789s
[2K
| Adam | epoch: 003 | loss: 0.54326 - acc: 0.7427 -- iter: 0160/2867
[A[ATraining Step: 186  | total loss: [1m[32m0.53899[0m[0m | time: 68.713s
[2K
| Adam | epoch: 003 | loss: 0.53899 - acc: 0.7465 -- iter: 0192/2867
[A[ATraining Step: 187  | total loss: [1m[32m0.54943[0m[0m | time: 81.136s
[2K
| Adam | epoch: 003 | loss: 0.54943 - acc: 0.7344 -- iter: 0224/2867
[A[ATraining Step: 188  | total loss: [1m[32m0.54173[0m[0m | time: 95.931s
[2K
| Adam | epoch: 003 | loss: 0.54173 - acc: 0.7359 -- iter: 0256/2867
[A[ATraining Step: 189  | total loss: [1m[32m0.52351[0m[0m | time: 112.703s
[2K
| Adam | epoch: 003 | loss: 0.52351 - acc: 0.7467 -- iter: 0288/2867
[A[ATraining Step: 190  | total loss: [1m[32m0.51233[0m[0m | time: 129.174s
[2K
| Adam | epoch: 003 | loss: 0.51233 - acc: 0.7564 -- iter: 0320/2867
[A[ATraining Step: 191  | total loss: [1m[32m0.51113[0m[0m | time: 146.241s
[2K
| Adam | epoch: 003 | loss: 0.51113 - acc: 0.7558 -- iter: 0352/2867
[A[ATraining Step: 192  | total loss: [1m[32m0.50669[0m[0m | time: 163.348s
[2K
| Adam | epoch: 003 | loss: 0.50669 - acc: 0.7521 -- iter: 0384/2867
[A[ATraining Step: 193  | total loss: [1m[32m0.51690[0m[0m | time: 180.165s
[2K
| Adam | epoch: 003 | loss: 0.51690 - acc: 0.7456 -- iter: 0416/2867
[A[ATraining Step: 194  | total loss: [1m[32m0.50992[0m[0m | time: 197.094s
[2K
| Adam | epoch: 003 | loss: 0.50992 - acc: 0.7523 -- iter: 0448/2867
[A[ATraining Step: 195  | total loss: [1m[32m0.52155[0m[0m | time: 213.917s
[2K
| Adam | epoch: 003 | loss: 0.52155 - acc: 0.7521 -- iter: 0480/2867
[A[ATraining Step: 196  | total loss: [1m[32m0.52075[0m[0m | time: 230.107s
[2K
| Adam | epoch: 003 | loss: 0.52075 - acc: 0.7581 -- iter: 0512/2867
[A[ATraining Step: 197  | total loss: [1m[32m0.53462[0m[0m | time: 246.590s
[2K
| Adam | epoch: 003 | loss: 0.53462 - acc: 0.7542 -- iter: 0544/2867
[A[ATraining Step: 198  | total loss: [1m[32m0.52524[0m[0m | time: 264.534s
[2K
| Adam | epoch: 003 | loss: 0.52524 - acc: 0.7569 -- iter: 0576/2867
[A[ATraining Step: 199  | total loss: [1m[32m0.51366[0m[0m | time: 281.202s
[2K
| Adam | epoch: 003 | loss: 0.51366 - acc: 0.7625 -- iter: 0608/2867
[A[ATraining Step: 200  | total loss: [1m[32m0.53194[0m[0m | time: 386.646s
[2K
| Adam | epoch: 003 | loss: 0.53194 - acc: 0.7518 | val_loss: 0.93044 - val_acc: 0.5262 -- iter: 0640/2867
--
Training Step: 201  | total loss: [1m[32m0.52252[0m[0m | time: 403.175s
[2K
| Adam | epoch: 003 | loss: 0.52252 - acc: 0.7579 -- iter: 0672/2867
[A[ATraining Step: 202  | total loss: [1m[32m0.51689[0m[0m | time: 420.069s
[2K
| Adam | epoch: 003 | loss: 0.51689 - acc: 0.7540 -- iter: 0704/2867
[A[ATraining Step: 203  | total loss: [1m[32m0.50259[0m[0m | time: 436.475s
[2K
| Adam | epoch: 003 | loss: 0.50259 - acc: 0.7661 -- iter: 0736/2867
[A[ATraining Step: 204  | total loss: [1m[32m0.49243[0m[0m | time: 453.339s
[2K
| Adam | epoch: 003 | loss: 0.49243 - acc: 0.7676 -- iter: 0768/2867
[A[ATraining Step: 205  | total loss: [1m[32m0.51011[0m[0m | time: 466.585s
[2K
| Adam | epoch: 003 | loss: 0.51011 - acc: 0.7596 -- iter: 0800/2867
[A[ATraining Step: 206  | total loss: [1m[32m0.49625[0m[0m | time: 479.189s
[2K
| Adam | epoch: 003 | loss: 0.49625 - acc: 0.7649 -- iter: 0832/2867
[A[ATraining Step: 207  | total loss: [1m[32m0.50042[0m[0m | time: 494.625s
[2K
| Adam | epoch: 003 | loss: 0.50042 - acc: 0.7571 -- iter: 0864/2867
[A[ATraining Step: 208  | total loss: [1m[32m0.49747[0m[0m | time: 511.002s
[2K
| Adam | epoch: 003 | loss: 0.49747 - acc: 0.7627 -- iter: 0896/2867
[A[ATraining Step: 209  | total loss: [1m[32m0.48182[0m[0m | time: 527.756s
[2K
| Adam | epoch: 003 | loss: 0.48182 - acc: 0.7708 -- iter: 0928/2867
[A[ATraining Step: 210  | total loss: [1m[32m0.48987[0m[0m | time: 544.451s
[2K
| Adam | epoch: 003 | loss: 0.48987 - acc: 0.7687 -- iter: 0960/2867
[A[ATraining Step: 211  | total loss: [1m[32m0.48976[0m[0m | time: 561.478s
[2K
| Adam | epoch: 003 | loss: 0.48976 - acc: 0.7637 -- iter: 0992/2867
[A[ATraining Step: 212  | total loss: [1m[32m0.48921[0m[0m | time: 579.962s
[2K
| Adam | epoch: 003 | loss: 0.48921 - acc: 0.7655 -- iter: 1024/2867
[A[ATraining Step: 213  | total loss: [1m[32m0.51657[0m[0m | time: 597.063s
[2K
| Adam | epoch: 003 | loss: 0.51657 - acc: 0.7545 -- iter: 1056/2867
[A[ATraining Step: 214  | total loss: [1m[32m0.51078[0m[0m | time: 613.447s
[2K
| Adam | epoch: 003 | loss: 0.51078 - acc: 0.7635 -- iter: 1088/2867
[A[ATraining Step: 215  | total loss: [1m[32m0.52734[0m[0m | time: 630.269s
[2K
| Adam | epoch: 003 | loss: 0.52734 - acc: 0.7559 -- iter: 1120/2867
[A[ATraining Step: 216  | total loss: [1m[32m0.50702[0m[0m | time: 647.051s
[2K
| Adam | epoch: 003 | loss: 0.50702 - acc: 0.7678 -- iter: 1152/2867
[A[ATraining Step: 217  | total loss: [1m[32m0.50162[0m[0m | time: 663.647s
[2K
| Adam | epoch: 003 | loss: 0.50162 - acc: 0.7723 -- iter: 1184/2867
[A[ATraining Step: 218  | total loss: [1m[32m0.49788[0m[0m | time: 680.246s
[2K
| Adam | epoch: 003 | loss: 0.49788 - acc: 0.7700 -- iter: 1216/2867
[A[ATraining Step: 219  | total loss: [1m[32m0.50826[0m[0m | time: 697.269s
[2K
| Adam | epoch: 003 | loss: 0.50826 - acc: 0.7587 -- iter: 1248/2867
[A[ATraining Step: 220  | total loss: [1m[32m0.51036[0m[0m | time: 715.140s
[2K
| Adam | epoch: 003 | loss: 0.51036 - acc: 0.7547 -- iter: 1280/2867
[A[ATraining Step: 221  | total loss: [1m[32m0.50551[0m[0m | time: 731.968s
[2K
| Adam | epoch: 003 | loss: 0.50551 - acc: 0.7636 -- iter: 1312/2867
[A[ATraining Step: 222  | total loss: [1m[32m0.50540[0m[0m | time: 749.318s
[2K
| Adam | epoch: 003 | loss: 0.50540 - acc: 0.7747 -- iter: 1344/2867
[A[ATraining Step: 223  | total loss: [1m[32m0.50343[0m[0m | time: 766.727s
[2K
| Adam | epoch: 003 | loss: 0.50343 - acc: 0.7754 -- iter: 1376/2867
[A[ATraining Step: 224  | total loss: [1m[32m0.48909[0m[0m | time: 779.644s
[2K
| Adam | epoch: 003 | loss: 0.48909 - acc: 0.7885 -- iter: 1408/2867
[A[ATraining Step: 225  | total loss: [1m[32m0.47833[0m[0m | time: 792.465s
[2K
| Adam | epoch: 003 | loss: 0.47833 - acc: 0.8002 -- iter: 1440/2867
[A[ATraining Step: 226  | total loss: [1m[32m0.48319[0m[0m | time: 809.450s
[2K
| Adam | epoch: 003 | loss: 0.48319 - acc: 0.7890 -- iter: 1472/2867
[A[ATraining Step: 227  | total loss: [1m[32m0.50274[0m[0m | time: 828.370s
[2K
| Adam | epoch: 003 | loss: 0.50274 - acc: 0.7788 -- iter: 1504/2867
[A[ATraining Step: 228  | total loss: [1m[32m0.50485[0m[0m | time: 846.855s
[2K
| Adam | epoch: 003 | loss: 0.50485 - acc: 0.7759 -- iter: 1536/2867
[A[ATraining Step: 229  | total loss: [1m[32m0.50216[0m[0m | time: 862.998s
[2K
| Adam | epoch: 003 | loss: 0.50216 - acc: 0.7796 -- iter: 1568/2867
[A[ATraining Step: 230  | total loss: [1m[32m0.49237[0m[0m | time: 879.679s
[2K
| Adam | epoch: 003 | loss: 0.49237 - acc: 0.7860 -- iter: 1600/2867
[A[ATraining Step: 231  | total loss: [1m[32m0.50983[0m[0m | time: 896.614s
[2K
| Adam | epoch: 003 | loss: 0.50983 - acc: 0.7730 -- iter: 1632/2867
[A[ATraining Step: 232  | total loss: [1m[32m0.50575[0m[0m | time: 911.228s
[2K
| Adam | epoch: 003 | loss: 0.50575 - acc: 0.7739 -- iter: 1664/2867
[A[ATraining Step: 233  | total loss: [1m[32m0.52103[0m[0m | time: 923.844s
[2K
| Adam | epoch: 003 | loss: 0.52103 - acc: 0.7715 -- iter: 1696/2867
[A[ATraining Step: 234  | total loss: [1m[32m0.51769[0m[0m | time: 938.897s
[2K
| Adam | epoch: 003 | loss: 0.51769 - acc: 0.7693 -- iter: 1728/2867
[A[ATraining Step: 235  | total loss: [1m[32m0.50456[0m[0m | time: 955.748s
[2K
| Adam | epoch: 003 | loss: 0.50456 - acc: 0.7768 -- iter: 1760/2867
[A[ATraining Step: 236  | total loss: [1m[32m0.49866[0m[0m | time: 972.488s
[2K
| Adam | epoch: 003 | loss: 0.49866 - acc: 0.7803 -- iter: 1792/2867
[A[ATraining Step: 237  | total loss: [1m[32m0.50443[0m[0m | time: 989.531s
[2K
| Adam | epoch: 003 | loss: 0.50443 - acc: 0.7648 -- iter: 1824/2867
[A[ATraining Step: 238  | total loss: [1m[32m0.50969[0m[0m | time: 1006.524s
[2K
| Adam | epoch: 003 | loss: 0.50969 - acc: 0.7602 -- iter: 1856/2867
[A[ATraining Step: 239  | total loss: [1m[32m0.50055[0m[0m | time: 1022.606s
[2K
| Adam | epoch: 003 | loss: 0.50055 - acc: 0.7654 -- iter: 1888/2867
[A[ATraining Step: 240  | total loss: [1m[32m0.48791[0m[0m | time: 1039.573s
[2K
| Adam | epoch: 003 | loss: 0.48791 - acc: 0.7733 -- iter: 1920/2867
[A[ATraining Step: 241  | total loss: [1m[32m0.47565[0m[0m | time: 1056.490s
[2K
| Adam | epoch: 003 | loss: 0.47565 - acc: 0.7772 -- iter: 1952/2867
[A[ATraining Step: 242  | total loss: [1m[32m0.45807[0m[0m | time: 1073.232s
[2K
| Adam | epoch: 003 | loss: 0.45807 - acc: 0.7838 -- iter: 1984/2867
[A[ATraining Step: 243  | total loss: [1m[32m0.45228[0m[0m | time: 1089.974s
[2K
| Adam | epoch: 003 | loss: 0.45228 - acc: 0.7805 -- iter: 2016/2867
[A[ATraining Step: 244  | total loss: [1m[32m0.45322[0m[0m | time: 1106.527s
[2K
| Adam | epoch: 003 | loss: 0.45322 - acc: 0.7805 -- iter: 2048/2867
[A[ATraining Step: 245  | total loss: [1m[32m0.44471[0m[0m | time: 1123.263s
[2K
| Adam | epoch: 003 | loss: 0.44471 - acc: 0.7869 -- iter: 2080/2867
[A[ATraining Step: 246  | total loss: [1m[32m0.45740[0m[0m | time: 1140.589s
[2K
| Adam | epoch: 003 | loss: 0.45740 - acc: 0.7863 -- iter: 2112/2867
[A[ATraining Step: 247  | total loss: [1m[32m0.45858[0m[0m | time: 1157.697s
[2K
| Adam | epoch: 003 | loss: 0.45858 - acc: 0.7795 -- iter: 2144/2867
[A[ATraining Step: 248  | total loss: [1m[32m0.46210[0m[0m | time: 1174.923s
[2K
| Adam | epoch: 003 | loss: 0.46210 - acc: 0.7828 -- iter: 2176/2867
[A[ATraining Step: 249  | total loss: [1m[32m0.47770[0m[0m | time: 1192.663s
[2K
| Adam | epoch: 003 | loss: 0.47770 - acc: 0.7796 -- iter: 2208/2867
[A[ATraining Step: 250  | total loss: [1m[32m0.46470[0m[0m | time: 1209.623s
[2K
| Adam | epoch: 003 | loss: 0.46470 - acc: 0.7860 -- iter: 2240/2867
[A[ATraining Step: 251  | total loss: [1m[32m0.47807[0m[0m | time: 1227.360s
[2K
| Adam | epoch: 003 | loss: 0.47807 - acc: 0.7793 -- iter: 2272/2867
[A[ATraining Step: 252  | total loss: [1m[32m0.47492[0m[0m | time: 1243.855s
[2K
| Adam | epoch: 003 | loss: 0.47492 - acc: 0.7795 -- iter: 2304/2867
[A[ATraining Step: 253  | total loss: [1m[32m0.46376[0m[0m | time: 1259.980s
[2K
| Adam | epoch: 003 | loss: 0.46376 - acc: 0.7796 -- iter: 2336/2867
[A[ATraining Step: 254  | total loss: [1m[32m0.46915[0m[0m | time: 1276.755s
[2K
| Adam | epoch: 003 | loss: 0.46915 - acc: 0.7798 -- iter: 2368/2867
[A[ATraining Step: 255  | total loss: [1m[32m0.47685[0m[0m | time: 1293.748s
[2K
| Adam | epoch: 003 | loss: 0.47685 - acc: 0.7737 -- iter: 2400/2867
[A[ATraining Step: 256  | total loss: [1m[32m0.47904[0m[0m | time: 1310.936s
[2K
| Adam | epoch: 003 | loss: 0.47904 - acc: 0.7682 -- iter: 2432/2867
[A[ATraining Step: 257  | total loss: [1m[32m0.48594[0m[0m | time: 1328.248s
[2K
| Adam | epoch: 003 | loss: 0.48594 - acc: 0.7726 -- iter: 2464/2867
[A[ATraining Step: 258  | total loss: [1m[32m0.48145[0m[0m | time: 1345.247s
[2K
| Adam | epoch: 003 | loss: 0.48145 - acc: 0.7766 -- iter: 2496/2867
[A[ATraining Step: 259  | total loss: [1m[32m0.49099[0m[0m | time: 1361.504s
[2K
| Adam | epoch: 003 | loss: 0.49099 - acc: 0.7802 -- iter: 2528/2867
[A[ATraining Step: 260  | total loss: [1m[32m0.48989[0m[0m | time: 1373.978s
[2K
| Adam | epoch: 003 | loss: 0.48989 - acc: 0.7772 -- iter: 2560/2867
[A[ATraining Step: 261  | total loss: [1m[32m0.47535[0m[0m | time: 1387.426s
[2K
| Adam | epoch: 003 | loss: 0.47535 - acc: 0.7838 -- iter: 2592/2867
[A[ATraining Step: 262  | total loss: [1m[32m0.47486[0m[0m | time: 1403.557s
[2K
| Adam | epoch: 003 | loss: 0.47486 - acc: 0.7836 -- iter: 2624/2867
[A[ATraining Step: 263  | total loss: [1m[32m0.46625[0m[0m | time: 1429.940s
[2K
| Adam | epoch: 003 | loss: 0.46625 - acc: 0.7865 -- iter: 2656/2867
[A[ATraining Step: 264  | total loss: [1m[32m0.46076[0m[0m | time: 1446.635s
[2K
| Adam | epoch: 003 | loss: 0.46076 - acc: 0.7922 -- iter: 2688/2867
[A[ATraining Step: 265  | total loss: [1m[32m0.47875[0m[0m | time: 1463.749s
[2K
| Adam | epoch: 003 | loss: 0.47875 - acc: 0.7911 -- iter: 2720/2867
[A[ATraining Step: 266  | total loss: [1m[32m0.48648[0m[0m | time: 1489.652s
[2K
| Adam | epoch: 003 | loss: 0.48648 - acc: 0.7870 -- iter: 2752/2867
[A[ATraining Step: 267  | total loss: [1m[32m0.50354[0m[0m | time: 1503.403s
[2K
| Adam | epoch: 003 | loss: 0.50354 - acc: 0.7770 -- iter: 2784/2867
[A[ATraining Step: 268  | total loss: [1m[32m0.50953[0m[0m | time: 1516.209s
[2K
| Adam | epoch: 003 | loss: 0.50953 - acc: 0.7837 -- iter: 2816/2867
[A[ATraining Step: 269  | total loss: [1m[32m0.50722[0m[0m | time: 1529.772s
[2K
| Adam | epoch: 003 | loss: 0.50722 - acc: 0.7835 -- iter: 2848/2867
[A[ATraining Step: 270  | total loss: [1m[32m0.50909[0m[0m | time: 1633.424s
[2K
| Adam | epoch: 003 | loss: 0.50909 - acc: 0.7707 | val_loss: 1.19310 - val_acc: 0.5897 -- iter: 2867/2867
--
Training Step: 271  | total loss: [1m[32m0.50783[0m[0m | time: 16.906s
[2K
| Adam | epoch: 004 | loss: 0.50783 - acc: 0.7624 -- iter: 0032/2867
[A[ATraining Step: 272  | total loss: [1m[32m0.51499[0m[0m | time: 28.238s
[2K
| Adam | epoch: 004 | loss: 0.51499 - acc: 0.7612 -- iter: 0064/2867
[A[ATraining Step: 273  | total loss: [1m[32m0.49203[0m[0m | time: 39.373s
[2K
| Adam | epoch: 004 | loss: 0.49203 - acc: 0.7745 -- iter: 0096/2867
[A[ATraining Step: 274  | total loss: [1m[32m0.46720[0m[0m | time: 55.760s
[2K
| Adam | epoch: 004 | loss: 0.46720 - acc: 0.7918 -- iter: 0128/2867
[A[ATraining Step: 275  | total loss: [1m[32m0.47004[0m[0m | time: 73.198s
[2K
| Adam | epoch: 004 | loss: 0.47004 - acc: 0.7876 -- iter: 0160/2867
[A[ATraining Step: 276  | total loss: [1m[32m0.45613[0m[0m | time: 89.012s
[2K
| Adam | epoch: 004 | loss: 0.45613 - acc: 0.7964 -- iter: 0192/2867
[A[ATraining Step: 277  | total loss: [1m[32m0.46758[0m[0m | time: 105.152s
[2K
| Adam | epoch: 004 | loss: 0.46758 - acc: 0.7917 -- iter: 0224/2867
[A[ATraining Step: 278  | total loss: [1m[32m0.45315[0m[0m | time: 121.206s
[2K
| Adam | epoch: 004 | loss: 0.45315 - acc: 0.8001 -- iter: 0256/2867
[A[ATraining Step: 279  | total loss: [1m[32m0.46827[0m[0m | time: 137.768s
[2K
| Adam | epoch: 004 | loss: 0.46827 - acc: 0.7888 -- iter: 0288/2867
[A[ATraining Step: 280  | total loss: [1m[32m0.45829[0m[0m | time: 154.169s
[2K
| Adam | epoch: 004 | loss: 0.45829 - acc: 0.7974 -- iter: 0320/2867
[A[ATraining Step: 281  | total loss: [1m[32m0.45325[0m[0m | time: 171.164s
[2K
| Adam | epoch: 004 | loss: 0.45325 - acc: 0.7896 -- iter: 0352/2867
[A[ATraining Step: 282  | total loss: [1m[32m0.44805[0m[0m | time: 187.317s
[2K
| Adam | epoch: 004 | loss: 0.44805 - acc: 0.7887 -- iter: 0384/2867
[A[ATraining Step: 283  | total loss: [1m[32m0.44378[0m[0m | time: 199.517s
[2K
| Adam | epoch: 004 | loss: 0.44378 - acc: 0.7849 -- iter: 0416/2867
[A[ATraining Step: 284  | total loss: [1m[32m0.45043[0m[0m | time: 211.786s
[2K
| Adam | epoch: 004 | loss: 0.45043 - acc: 0.7751 -- iter: 0448/2867
[A[ATraining Step: 285  | total loss: [1m[32m0.43487[0m[0m | time: 227.926s
[2K
| Adam | epoch: 004 | loss: 0.43487 - acc: 0.7820 -- iter: 0480/2867
[A[ATraining Step: 286  | total loss: [1m[32m0.44354[0m[0m | time: 244.859s
[2K
| Adam | epoch: 004 | loss: 0.44354 - acc: 0.7725 -- iter: 0512/2867
[A[ATraining Step: 287  | total loss: [1m[32m0.44388[0m[0m | time: 261.310s
[2K
| Adam | epoch: 004 | loss: 0.44388 - acc: 0.7828 -- iter: 0544/2867
[A[ATraining Step: 288  | total loss: [1m[32m0.43723[0m[0m | time: 278.043s
[2K
| Adam | epoch: 004 | loss: 0.43723 - acc: 0.7920 -- iter: 0576/2867
[A[ATraining Step: 289  | total loss: [1m[32m0.44498[0m[0m | time: 294.874s
[2K
| Adam | epoch: 004 | loss: 0.44498 - acc: 0.7909 -- iter: 0608/2867
[A[ATraining Step: 290  | total loss: [1m[32m0.44564[0m[0m | time: 311.725s
[2K
| Adam | epoch: 004 | loss: 0.44564 - acc: 0.7931 -- iter: 0640/2867
[A[ATraining Step: 291  | total loss: [1m[32m0.45664[0m[0m | time: 327.791s
[2K
| Adam | epoch: 004 | loss: 0.45664 - acc: 0.7982 -- iter: 0672/2867
[A[ATraining Step: 292  | total loss: [1m[32m0.47181[0m[0m | time: 344.615s
[2K
| Adam | epoch: 004 | loss: 0.47181 - acc: 0.7902 -- iter: 0704/2867
[A[ATraining Step: 293  | total loss: [1m[32m0.47180[0m[0m | time: 361.456s
[2K
| Adam | epoch: 004 | loss: 0.47180 - acc: 0.7893 -- iter: 0736/2867
[A[ATraining Step: 294  | total loss: [1m[32m0.46843[0m[0m | time: 378.082s
[2K
| Adam | epoch: 004 | loss: 0.46843 - acc: 0.7823 -- iter: 0768/2867
[A[ATraining Step: 295  | total loss: [1m[32m0.48124[0m[0m | time: 395.455s
[2K
| Adam | epoch: 004 | loss: 0.48124 - acc: 0.7728 -- iter: 0800/2867
[A[ATraining Step: 296  | total loss: [1m[32m0.48361[0m[0m | time: 411.903s
[2K
| Adam | epoch: 004 | loss: 0.48361 - acc: 0.7736 -- iter: 0832/2867
[A[ATraining Step: 297  | total loss: [1m[32m0.46976[0m[0m | time: 429.258s
[2K
| Adam | epoch: 004 | loss: 0.46976 - acc: 0.7806 -- iter: 0864/2867
[A[ATraining Step: 298  | total loss: [1m[32m0.47992[0m[0m | time: 445.748s
[2K
| Adam | epoch: 004 | loss: 0.47992 - acc: 0.7745 -- iter: 0896/2867
[A[ATraining Step: 299  | total loss: [1m[32m0.49823[0m[0m | time: 461.997s
[2K
| Adam | epoch: 004 | loss: 0.49823 - acc: 0.7658 -- iter: 0928/2867
[A[ATraining Step: 300  | total loss: [1m[32m0.49257[0m[0m | time: 478.791s
[2K
| Adam | epoch: 004 | loss: 0.49257 - acc: 0.7673 -- iter: 0960/2867
[A[ATraining Step: 301  | total loss: [1m[32m0.49432[0m[0m | time: 495.439s
[2K
| Adam | epoch: 004 | loss: 0.49432 - acc: 0.7656 -- iter: 0992/2867
[A[ATraining Step: 302  | total loss: [1m[32m0.48281[0m[0m | time: 512.748s
[2K
| Adam | epoch: 004 | loss: 0.48281 - acc: 0.7734 -- iter: 1024/2867
[A[ATraining Step: 303  | total loss: [1m[32m0.47444[0m[0m | time: 529.910s
[2K
| Adam | epoch: 004 | loss: 0.47444 - acc: 0.7773 -- iter: 1056/2867
[A[ATraining Step: 304  | total loss: [1m[32m0.46991[0m[0m | time: 542.452s
[2K
| Adam | epoch: 004 | loss: 0.46991 - acc: 0.7871 -- iter: 1088/2867
[A[ATraining Step: 305  | total loss: [1m[32m0.47290[0m[0m | time: 555.389s
[2K
| Adam | epoch: 004 | loss: 0.47290 - acc: 0.7802 -- iter: 1120/2867
[A[ATraining Step: 306  | total loss: [1m[32m0.47895[0m[0m | time: 571.956s
[2K
| Adam | epoch: 004 | loss: 0.47895 - acc: 0.7772 -- iter: 1152/2867
[A[ATraining Step: 307  | total loss: [1m[32m0.47185[0m[0m | time: 588.723s
[2K
| Adam | epoch: 004 | loss: 0.47185 - acc: 0.7807 -- iter: 1184/2867
[A[ATraining Step: 308  | total loss: [1m[32m0.46418[0m[0m | time: 605.460s
[2K
| Adam | epoch: 004 | loss: 0.46418 - acc: 0.7870 -- iter: 1216/2867
[A[ATraining Step: 309  | total loss: [1m[32m0.45211[0m[0m | time: 622.817s
[2K
| Adam | epoch: 004 | loss: 0.45211 - acc: 0.7958 -- iter: 1248/2867
[A[ATraining Step: 310  | total loss: [1m[32m0.44476[0m[0m | time: 635.634s
[2K
| Adam | epoch: 004 | loss: 0.44476 - acc: 0.8006 -- iter: 1280/2867
[A[ATraining Step: 311  | total loss: [1m[32m0.45696[0m[0m | time: 648.073s
[2K
| Adam | epoch: 004 | loss: 0.45696 - acc: 0.7893 -- iter: 1312/2867
[A[ATraining Step: 312  | total loss: [1m[32m0.44196[0m[0m | time: 662.965s
[2K
| Adam | epoch: 004 | loss: 0.44196 - acc: 0.8041 -- iter: 1344/2867
[A[ATraining Step: 313  | total loss: [1m[32m0.43341[0m[0m | time: 679.444s
[2K
| Adam | epoch: 004 | loss: 0.43341 - acc: 0.8112 -- iter: 1376/2867
[A[ATraining Step: 314  | total loss: [1m[32m0.44516[0m[0m | time: 696.335s
[2K
| Adam | epoch: 004 | loss: 0.44516 - acc: 0.7989 -- iter: 1408/2867
[A[ATraining Step: 315  | total loss: [1m[32m0.46625[0m[0m | time: 713.588s
[2K
| Adam | epoch: 004 | loss: 0.46625 - acc: 0.7877 -- iter: 1440/2867
[A[ATraining Step: 316  | total loss: [1m[32m0.45681[0m[0m | time: 730.354s
[2K
| Adam | epoch: 004 | loss: 0.45681 - acc: 0.7964 -- iter: 1472/2867
[A[ATraining Step: 317  | total loss: [1m[32m0.44977[0m[0m | time: 742.404s
[2K
| Adam | epoch: 004 | loss: 0.44977 - acc: 0.7918 -- iter: 1504/2867
[A[ATraining Step: 318  | total loss: [1m[32m0.44331[0m[0m | time: 758.194s
[2K
| Adam | epoch: 004 | loss: 0.44331 - acc: 0.7939 -- iter: 1536/2867
[A[ATraining Step: 319  | total loss: [1m[32m0.42948[0m[0m | time: 774.851s
[2K
| Adam | epoch: 004 | loss: 0.42948 - acc: 0.8051 -- iter: 1568/2867
[A[ATraining Step: 320  | total loss: [1m[32m0.43869[0m[0m | time: 791.414s
[2K
| Adam | epoch: 004 | loss: 0.43869 - acc: 0.8027 -- iter: 1600/2867
[A[ATraining Step: 321  | total loss: [1m[32m0.43304[0m[0m | time: 808.299s
[2K
| Adam | epoch: 004 | loss: 0.43304 - acc: 0.8006 -- iter: 1632/2867
[A[ATraining Step: 322  | total loss: [1m[32m0.43337[0m[0m | time: 825.034s
[2K
| Adam | epoch: 004 | loss: 0.43337 - acc: 0.7986 -- iter: 1664/2867
[A[ATraining Step: 323  | total loss: [1m[32m0.43499[0m[0m | time: 841.863s
[2K
| Adam | epoch: 004 | loss: 0.43499 - acc: 0.7938 -- iter: 1696/2867
[A[ATraining Step: 324  | total loss: [1m[32m0.42379[0m[0m | time: 858.254s
[2K
| Adam | epoch: 004 | loss: 0.42379 - acc: 0.8019 -- iter: 1728/2867
[A[ATraining Step: 325  | total loss: [1m[32m0.42686[0m[0m | time: 874.185s
[2K
| Adam | epoch: 004 | loss: 0.42686 - acc: 0.7967 -- iter: 1760/2867
[A[ATraining Step: 326  | total loss: [1m[32m0.42274[0m[0m | time: 890.824s
[2K
| Adam | epoch: 004 | loss: 0.42274 - acc: 0.7983 -- iter: 1792/2867
[A[ATraining Step: 327  | total loss: [1m[32m0.43093[0m[0m | time: 907.048s
[2K
| Adam | epoch: 004 | loss: 0.43093 - acc: 0.7903 -- iter: 1824/2867
[A[ATraining Step: 328  | total loss: [1m[32m0.43270[0m[0m | time: 923.559s
[2K
| Adam | epoch: 004 | loss: 0.43270 - acc: 0.7832 -- iter: 1856/2867
[A[ATraining Step: 329  | total loss: [1m[32m0.42274[0m[0m | time: 940.153s
[2K
| Adam | epoch: 004 | loss: 0.42274 - acc: 0.7892 -- iter: 1888/2867
[A[ATraining Step: 330  | total loss: [1m[32m0.44457[0m[0m | time: 956.322s
[2K
| Adam | epoch: 004 | loss: 0.44457 - acc: 0.7791 -- iter: 1920/2867
[A[ATraining Step: 331  | total loss: [1m[32m0.44590[0m[0m | time: 972.659s
[2K
| Adam | epoch: 004 | loss: 0.44590 - acc: 0.7855 -- iter: 1952/2867
[A[ATraining Step: 332  | total loss: [1m[32m0.47958[0m[0m | time: 989.919s
[2K
| Adam | epoch: 004 | loss: 0.47958 - acc: 0.7726 -- iter: 1984/2867
[A[ATraining Step: 333  | total loss: [1m[32m0.46262[0m[0m | time: 1006.522s
[2K
| Adam | epoch: 004 | loss: 0.46262 - acc: 0.7828 -- iter: 2016/2867
[A[ATraining Step: 334  | total loss: [1m[32m0.45137[0m[0m | time: 1022.783s
[2K
| Adam | epoch: 004 | loss: 0.45137 - acc: 0.7889 -- iter: 2048/2867
[A[ATraining Step: 335  | total loss: [1m[32m0.44583[0m[0m | time: 1039.557s
[2K
| Adam | epoch: 004 | loss: 0.44583 - acc: 0.7944 -- iter: 2080/2867
[A[ATraining Step: 336  | total loss: [1m[32m0.43726[0m[0m | time: 1056.673s
[2K
| Adam | epoch: 004 | loss: 0.43726 - acc: 0.7993 -- iter: 2112/2867
[A[ATraining Step: 337  | total loss: [1m[32m0.41666[0m[0m | time: 1073.005s
[2K
| Adam | epoch: 004 | loss: 0.41666 - acc: 0.8163 -- iter: 2144/2867
[A[ATraining Step: 338  | total loss: [1m[32m0.41600[0m[0m | time: 1084.648s
[2K
| Adam | epoch: 004 | loss: 0.41600 - acc: 0.8190 -- iter: 2176/2867
[A[ATraining Step: 339  | total loss: [1m[32m0.41326[0m[0m | time: 1096.754s
[2K
| Adam | epoch: 004 | loss: 0.41326 - acc: 0.8184 -- iter: 2208/2867
[A[ATraining Step: 340  | total loss: [1m[32m0.41909[0m[0m | time: 1111.031s
[2K
| Adam | epoch: 004 | loss: 0.41909 - acc: 0.8115 -- iter: 2240/2867
[A[ATraining Step: 341  | total loss: [1m[32m0.41785[0m[0m | time: 1131.652s
[2K
| Adam | epoch: 004 | loss: 0.41785 - acc: 0.8241 -- iter: 2272/2867
[A[ATraining Step: 342  | total loss: [1m[32m0.42452[0m[0m | time: 1147.555s
[2K
| Adam | epoch: 004 | loss: 0.42452 - acc: 0.8198 -- iter: 2304/2867
[A[ATraining Step: 343  | total loss: [1m[32m0.42288[0m[0m | time: 1159.004s
[2K
| Adam | epoch: 004 | loss: 0.42288 - acc: 0.8129 -- iter: 2336/2867
[A[ATraining Step: 344  | total loss: [1m[32m0.41342[0m[0m | time: 1170.488s
[2K
| Adam | epoch: 004 | loss: 0.41342 - acc: 0.8222 -- iter: 2368/2867
[A[ATraining Step: 345  | total loss: [1m[32m0.41161[0m[0m | time: 1182.247s
[2K
| Adam | epoch: 004 | loss: 0.41161 - acc: 0.8306 -- iter: 2400/2867
[A[ATraining Step: 346  | total loss: [1m[32m0.41520[0m[0m | time: 1194.402s
[2K
| Adam | epoch: 004 | loss: 0.41520 - acc: 0.8132 -- iter: 2432/2867
[A[ATraining Step: 347  | total loss: [1m[32m0.41450[0m[0m | time: 1205.764s
[2K
| Adam | epoch: 004 | loss: 0.41450 - acc: 0.8162 -- iter: 2464/2867
[A[ATraining Step: 348  | total loss: [1m[32m0.42011[0m[0m | time: 1217.490s
[2K
| Adam | epoch: 004 | loss: 0.42011 - acc: 0.8096 -- iter: 2496/2867
[A[ATraining Step: 349  | total loss: [1m[32m0.41467[0m[0m | time: 1230.041s
[2K
| Adam | epoch: 004 | loss: 0.41467 - acc: 0.8193 -- iter: 2528/2867
[A[ATraining Step: 350  | total loss: [1m[32m0.41195[0m[0m | time: 1242.823s
[2K
| Adam | epoch: 004 | loss: 0.41195 - acc: 0.8186 -- iter: 2560/2867
[A[ATraining Step: 351  | total loss: [1m[32m0.40762[0m[0m | time: 1251.591s
[2K
| Adam | epoch: 004 | loss: 0.40762 - acc: 0.8242 -- iter: 2592/2867
[A[ATraining Step: 352  | total loss: [1m[32m0.39411[0m[0m | time: 1259.841s
[2K
| Adam | epoch: 004 | loss: 0.39411 - acc: 0.8356 -- iter: 2624/2867
[A[ATraining Step: 353  | total loss: [1m[32m0.39818[0m[0m | time: 1268.304s
[2K
| Adam | epoch: 004 | loss: 0.39818 - acc: 0.8301 -- iter: 2656/2867
[A[ATraining Step: 354  | total loss: [1m[32m0.42735[0m[0m | time: 1279.969s
[2K
| Adam | epoch: 004 | loss: 0.42735 - acc: 0.8159 -- iter: 2688/2867
[A[ATraining Step: 355  | total loss: [1m[32m0.44614[0m[0m | time: 1291.746s
[2K
| Adam | epoch: 004 | loss: 0.44614 - acc: 0.8124 -- iter: 2720/2867
[A[ATraining Step: 356  | total loss: [1m[32m0.43457[0m[0m | time: 1303.228s
[2K
| Adam | epoch: 004 | loss: 0.43457 - acc: 0.8187 -- iter: 2752/2867
[A[ATraining Step: 357  | total loss: [1m[32m0.42136[0m[0m | time: 1315.165s
[2K
| Adam | epoch: 004 | loss: 0.42136 - acc: 0.8243 -- iter: 2784/2867
[A[ATraining Step: 358  | total loss: [1m[32m0.41966[0m[0m | time: 1326.847s
[2K
| Adam | epoch: 004 | loss: 0.41966 - acc: 0.8169 -- iter: 2816/2867
[A[ATraining Step: 359  | total loss: [1m[32m0.40188[0m[0m | time: 1338.560s
[2K
| Adam | epoch: 004 | loss: 0.40188 - acc: 0.8227 -- iter: 2848/2867
[A[ATraining Step: 360  | total loss: [1m[32m0.39932[0m[0m | time: 1410.739s
[2K
| Adam | epoch: 004 | loss: 0.39932 - acc: 0.8279 | val_loss: 4.27967 - val_acc: 0.5106 -- iter: 2867/2867
--
Training Step: 361  | total loss: [1m[32m0.39500[0m[0m | time: 11.968s
[2K
| Adam | epoch: 005 | loss: 0.39500 - acc: 0.8295 -- iter: 0032/2867
[A[ATraining Step: 362  | total loss: [1m[32m0.38394[0m[0m | time: 23.372s
[2K
| Adam | epoch: 005 | loss: 0.38394 - acc: 0.8309 -- iter: 0064/2867
[A[ATraining Step: 363  | total loss: [1m[32m0.38623[0m[0m | time: 30.752s
[2K
| Adam | epoch: 005 | loss: 0.38623 - acc: 0.8291 -- iter: 0096/2867
[A[ATraining Step: 364  | total loss: [1m[32m0.36271[0m[0m | time: 37.890s
[2K
| Adam | epoch: 005 | loss: 0.36271 - acc: 0.8462 -- iter: 0128/2867
[A[ATraining Step: 365  | total loss: [1m[32m0.33757[0m[0m | time: 49.745s
[2K
| Adam | epoch: 005 | loss: 0.33757 - acc: 0.8616 -- iter: 0160/2867
[A[ATraining Step: 366  | total loss: [1m[32m0.32243[0m[0m | time: 61.193s
[2K
| Adam | epoch: 005 | loss: 0.32243 - acc: 0.8691 -- iter: 0192/2867
[A[ATraining Step: 367  | total loss: [1m[32m0.33411[0m[0m | time: 72.868s
[2K
| Adam | epoch: 005 | loss: 0.33411 - acc: 0.8541 -- iter: 0224/2867
[A[ATraining Step: 368  | total loss: [1m[32m0.34818[0m[0m | time: 84.655s
[2K
| Adam | epoch: 005 | loss: 0.34818 - acc: 0.8562 -- iter: 0256/2867
[A[ATraining Step: 369  | total loss: [1m[32m0.34575[0m[0m | time: 96.053s
[2K
| Adam | epoch: 005 | loss: 0.34575 - acc: 0.8550 -- iter: 0288/2867
[A[ATraining Step: 370  | total loss: [1m[32m0.35165[0m[0m | time: 107.954s
[2K
| Adam | epoch: 005 | loss: 0.35165 - acc: 0.8570 -- iter: 0320/2867
[A[ATraining Step: 371  | total loss: [1m[32m0.32828[0m[0m | time: 119.660s
[2K
| Adam | epoch: 005 | loss: 0.32828 - acc: 0.8681 -- iter: 0352/2867
[A[ATraining Step: 372  | total loss: [1m[32m0.32830[0m[0m | time: 130.922s
[2K
| Adam | epoch: 005 | loss: 0.32830 - acc: 0.8626 -- iter: 0384/2867
[A[ATraining Step: 373  | total loss: [1m[32m0.32993[0m[0m | time: 142.386s
[2K
| Adam | epoch: 005 | loss: 0.32993 - acc: 0.8576 -- iter: 0416/2867
[A[ATraining Step: 374  | total loss: [1m[32m0.36930[0m[0m | time: 154.103s
[2K
| Adam | epoch: 005 | loss: 0.36930 - acc: 0.8468 -- iter: 0448/2867
[A[ATraining Step: 375  | total loss: [1m[32m0.39005[0m[0m | time: 165.775s
[2K
| Adam | epoch: 005 | loss: 0.39005 - acc: 0.8246 -- iter: 0480/2867
[A[ATraining Step: 376  | total loss: [1m[32m0.37954[0m[0m | time: 177.495s
[2K
| Adam | epoch: 005 | loss: 0.37954 - acc: 0.8328 -- iter: 0512/2867
[A[ATraining Step: 377  | total loss: [1m[32m0.37581[0m[0m | time: 189.426s
[2K
| Adam | epoch: 005 | loss: 0.37581 - acc: 0.8339 -- iter: 0544/2867
[A[ATraining Step: 378  | total loss: [1m[32m0.36392[0m[0m | time: 201.170s
[2K
| Adam | epoch: 005 | loss: 0.36392 - acc: 0.8349 -- iter: 0576/2867
[A[ATraining Step: 379  | total loss: [1m[32m0.37932[0m[0m | time: 212.986s
[2K
| Adam | epoch: 005 | loss: 0.37932 - acc: 0.8295 -- iter: 0608/2867
[A[ATraining Step: 380  | total loss: [1m[32m0.37972[0m[0m | time: 224.531s
[2K
| Adam | epoch: 005 | loss: 0.37972 - acc: 0.8309 -- iter: 0640/2867
[A[ATraining Step: 381  | total loss: [1m[32m0.36261[0m[0m | time: 235.987s
[2K
| Adam | epoch: 005 | loss: 0.36261 - acc: 0.8416 -- iter: 0672/2867
[A[ATraining Step: 382  | total loss: [1m[32m0.36959[0m[0m | time: 247.863s
[2K
| Adam | epoch: 005 | loss: 0.36959 - acc: 0.8387 -- iter: 0704/2867
[A[ATraining Step: 383  | total loss: [1m[32m0.37706[0m[0m | time: 259.274s
[2K
| Adam | epoch: 005 | loss: 0.37706 - acc: 0.8423 -- iter: 0736/2867
[A[ATraining Step: 384  | total loss: [1m[32m0.37270[0m[0m | time: 271.243s
[2K
| Adam | epoch: 005 | loss: 0.37270 - acc: 0.8456 -- iter: 0768/2867
[A[ATraining Step: 385  | total loss: [1m[32m0.37974[0m[0m | time: 282.939s
[2K
| Adam | epoch: 005 | loss: 0.37974 - acc: 0.8454 -- iter: 0800/2867
[A[ATraining Step: 386  | total loss: [1m[32m0.37532[0m[0m | time: 294.690s
[2K
| Adam | epoch: 005 | loss: 0.37532 - acc: 0.8421 -- iter: 0832/2867
[A[ATraining Step: 387  | total loss: [1m[32m0.36282[0m[0m | time: 306.885s
[2K
| Adam | epoch: 005 | loss: 0.36282 - acc: 0.8485 -- iter: 0864/2867
[A[ATraining Step: 388  | total loss: [1m[32m0.36277[0m[0m | time: 319.558s
[2K
| Adam | epoch: 005 | loss: 0.36277 - acc: 0.8418 -- iter: 0896/2867
[A[ATraining Step: 389  | total loss: [1m[32m0.35947[0m[0m | time: 330.354s
[2K
| Adam | epoch: 005 | loss: 0.35947 - acc: 0.8451 -- iter: 0928/2867
[A[ATraining Step: 390  | total loss: [1m[32m0.35690[0m[0m | time: 338.383s
[2K
| Adam | epoch: 005 | loss: 0.35690 - acc: 0.8450 -- iter: 0960/2867
[A[ATraining Step: 391  | total loss: [1m[32m0.34179[0m[0m | time: 346.426s
[2K
| Adam | epoch: 005 | loss: 0.34179 - acc: 0.8542 -- iter: 0992/2867
[A[ATraining Step: 392  | total loss: [1m[32m0.34798[0m[0m | time: 357.339s
[2K
| Adam | epoch: 005 | loss: 0.34798 - acc: 0.8469 -- iter: 1024/2867
[A[ATraining Step: 393  | total loss: [1m[32m0.35422[0m[0m | time: 368.704s
[2K
| Adam | epoch: 005 | loss: 0.35422 - acc: 0.8466 -- iter: 1056/2867
[A[ATraining Step: 394  | total loss: [1m[32m0.37364[0m[0m | time: 380.312s
[2K
| Adam | epoch: 005 | loss: 0.37364 - acc: 0.8401 -- iter: 1088/2867
[A[ATraining Step: 395  | total loss: [1m[32m0.38532[0m[0m | time: 392.151s
[2K
| Adam | epoch: 005 | loss: 0.38532 - acc: 0.8279 -- iter: 1120/2867
[A[ATraining Step: 396  | total loss: [1m[32m0.40031[0m[0m | time: 403.879s
[2K
| Adam | epoch: 005 | loss: 0.40031 - acc: 0.8202 -- iter: 1152/2867
[A[ATraining Step: 397  | total loss: [1m[32m0.41038[0m[0m | time: 415.736s
[2K
| Adam | epoch: 005 | loss: 0.41038 - acc: 0.8131 -- iter: 1184/2867
[A[ATraining Step: 398  | total loss: [1m[32m0.41561[0m[0m | time: 427.375s
[2K
| Adam | epoch: 005 | loss: 0.41561 - acc: 0.8193 -- iter: 1216/2867
[A[ATraining Step: 399  | total loss: [1m[32m0.42190[0m[0m | time: 438.706s
[2K
| Adam | epoch: 005 | loss: 0.42190 - acc: 0.8155 -- iter: 1248/2867
[A[ATraining Step: 400  | total loss: [1m[32m0.42887[0m[0m | time: 511.957s
[2K
| Adam | epoch: 005 | loss: 0.42887 - acc: 0.8090 | val_loss: 0.53916 - val_acc: 0.7737 -- iter: 1280/2867
--
Training Step: 401  | total loss: [1m[32m0.41862[0m[0m | time: 523.727s
[2K
| Adam | epoch: 005 | loss: 0.41862 - acc: 0.8156 -- iter: 1312/2867
[A[ATraining Step: 402  | total loss: [1m[32m0.40385[0m[0m | time: 534.666s
[2K
| Adam | epoch: 005 | loss: 0.40385 - acc: 0.8246 -- iter: 1344/2867
[A[ATraining Step: 403  | total loss: [1m[32m0.40410[0m[0m | time: 546.116s
[2K
| Adam | epoch: 005 | loss: 0.40410 - acc: 0.8234 -- iter: 1376/2867
[A[ATraining Step: 404  | total loss: [1m[32m0.39964[0m[0m | time: 557.900s
[2K
| Adam | epoch: 005 | loss: 0.39964 - acc: 0.8286 -- iter: 1408/2867
[A[ATraining Step: 405  | total loss: [1m[32m0.39816[0m[0m | time: 569.746s
[2K
| Adam | epoch: 005 | loss: 0.39816 - acc: 0.8270 -- iter: 1440/2867
[A[ATraining Step: 406  | total loss: [1m[32m0.41066[0m[0m | time: 581.549s
[2K
| Adam | epoch: 005 | loss: 0.41066 - acc: 0.8161 -- iter: 1472/2867
[A[ATraining Step: 407  | total loss: [1m[32m0.40658[0m[0m | time: 593.166s
[2K
| Adam | epoch: 005 | loss: 0.40658 - acc: 0.8189 -- iter: 1504/2867
[A[ATraining Step: 408  | total loss: [1m[32m0.41565[0m[0m | time: 604.461s
[2K
| Adam | epoch: 005 | loss: 0.41565 - acc: 0.8120 -- iter: 1536/2867
[A[ATraining Step: 409  | total loss: [1m[32m0.42101[0m[0m | time: 616.156s
[2K
| Adam | epoch: 005 | loss: 0.42101 - acc: 0.8183 -- iter: 1568/2867
[A[ATraining Step: 410  | total loss: [1m[32m0.42580[0m[0m | time: 627.577s
[2K
| Adam | epoch: 005 | loss: 0.42580 - acc: 0.8177 -- iter: 1600/2867
[A[ATraining Step: 411  | total loss: [1m[32m0.40896[0m[0m | time: 638.974s
[2K
| Adam | epoch: 005 | loss: 0.40896 - acc: 0.8297 -- iter: 1632/2867
[A[ATraining Step: 412  | total loss: [1m[32m0.39918[0m[0m | time: 650.586s
[2K
| Adam | epoch: 005 | loss: 0.39918 - acc: 0.8342 -- iter: 1664/2867
[A[ATraining Step: 413  | total loss: [1m[32m0.39504[0m[0m | time: 662.540s
[2K
| Adam | epoch: 005 | loss: 0.39504 - acc: 0.8352 -- iter: 1696/2867
[A[ATraining Step: 414  | total loss: [1m[32m0.39242[0m[0m | time: 674.175s
[2K
| Adam | epoch: 005 | loss: 0.39242 - acc: 0.8392 -- iter: 1728/2867
[A[ATraining Step: 415  | total loss: [1m[32m0.39215[0m[0m | time: 685.614s
[2K
| Adam | epoch: 005 | loss: 0.39215 - acc: 0.8334 -- iter: 1760/2867
[A[ATraining Step: 416  | total loss: [1m[32m0.40859[0m[0m | time: 697.658s
[2K
| Adam | epoch: 005 | loss: 0.40859 - acc: 0.8313 -- iter: 1792/2867
[A[ATraining Step: 417  | total loss: [1m[32m0.41484[0m[0m | time: 709.361s
[2K
| Adam | epoch: 005 | loss: 0.41484 - acc: 0.8325 -- iter: 1824/2867
[A[ATraining Step: 418  | total loss: [1m[32m0.42476[0m[0m | time: 720.294s
[2K
| Adam | epoch: 005 | loss: 0.42476 - acc: 0.8243 -- iter: 1856/2867
[A[ATraining Step: 419  | total loss: [1m[32m0.45063[0m[0m | time: 731.401s
[2K
| Adam | epoch: 005 | loss: 0.45063 - acc: 0.8169 -- iter: 1888/2867
[A[ATraining Step: 420  | total loss: [1m[32m0.43146[0m[0m | time: 743.090s
[2K
| Adam | epoch: 005 | loss: 0.43146 - acc: 0.8195 -- iter: 1920/2867
[A[ATraining Step: 421  | total loss: [1m[32m0.47020[0m[0m | time: 755.076s
[2K
| Adam | epoch: 005 | loss: 0.47020 - acc: 0.7970 -- iter: 1952/2867
[A[ATraining Step: 422  | total loss: [1m[32m0.46354[0m[0m | time: 766.554s
[2K
| Adam | epoch: 005 | loss: 0.46354 - acc: 0.7954 -- iter: 1984/2867
[A[ATraining Step: 423  | total loss: [1m[32m0.45317[0m[0m | time: 778.028s
[2K
| Adam | epoch: 005 | loss: 0.45317 - acc: 0.7971 -- iter: 2016/2867
[A[ATraining Step: 424  | total loss: [1m[32m0.44486[0m[0m | time: 789.978s
[2K
| Adam | epoch: 005 | loss: 0.44486 - acc: 0.8049 -- iter: 2048/2867
[A[ATraining Step: 425  | total loss: [1m[32m0.43064[0m[0m | time: 802.252s
[2K
| Adam | epoch: 005 | loss: 0.43064 - acc: 0.8057 -- iter: 2080/2867
[A[ATraining Step: 426  | total loss: [1m[32m0.42349[0m[0m | time: 813.997s
[2K
| Adam | epoch: 005 | loss: 0.42349 - acc: 0.8126 -- iter: 2112/2867
[A[ATraining Step: 427  | total loss: [1m[32m0.41370[0m[0m | time: 821.868s
[2K
| Adam | epoch: 005 | loss: 0.41370 - acc: 0.8126 -- iter: 2144/2867
[A[ATraining Step: 428  | total loss: [1m[32m0.40462[0m[0m | time: 829.803s
[2K
| Adam | epoch: 005 | loss: 0.40462 - acc: 0.8219 -- iter: 2176/2867
[A[ATraining Step: 429  | total loss: [1m[32m0.39410[0m[0m | time: 837.810s
[2K
| Adam | epoch: 005 | loss: 0.39410 - acc: 0.8366 -- iter: 2208/2867
[A[ATraining Step: 430  | total loss: [1m[32m0.38114[0m[0m | time: 849.514s
[2K
| Adam | epoch: 005 | loss: 0.38114 - acc: 0.8436 -- iter: 2240/2867
[A[ATraining Step: 431  | total loss: [1m[32m0.37368[0m[0m | time: 860.902s
[2K
| Adam | epoch: 005 | loss: 0.37368 - acc: 0.8499 -- iter: 2272/2867
[A[ATraining Step: 432  | total loss: [1m[32m0.37098[0m[0m | time: 872.253s
[2K
| Adam | epoch: 005 | loss: 0.37098 - acc: 0.8492 -- iter: 2304/2867
[A[ATraining Step: 433  | total loss: [1m[32m0.36900[0m[0m | time: 883.510s
[2K
| Adam | epoch: 005 | loss: 0.36900 - acc: 0.8487 -- iter: 2336/2867
[A[ATraining Step: 434  | total loss: [1m[32m0.37306[0m[0m | time: 895.248s
[2K
| Adam | epoch: 005 | loss: 0.37306 - acc: 0.8482 -- iter: 2368/2867
[A[ATraining Step: 435  | total loss: [1m[32m0.35971[0m[0m | time: 906.809s
[2K
| Adam | epoch: 005 | loss: 0.35971 - acc: 0.8571 -- iter: 2400/2867
[A[ATraining Step: 436  | total loss: [1m[32m0.34634[0m[0m | time: 918.327s
[2K
| Adam | epoch: 005 | loss: 0.34634 - acc: 0.8620 -- iter: 2432/2867
[A[ATraining Step: 437  | total loss: [1m[32m0.33501[0m[0m | time: 929.774s
[2K
| Adam | epoch: 005 | loss: 0.33501 - acc: 0.8727 -- iter: 2464/2867
[A[ATraining Step: 438  | total loss: [1m[32m0.33254[0m[0m | time: 941.349s
[2K
| Adam | epoch: 005 | loss: 0.33254 - acc: 0.8761 -- iter: 2496/2867
[A[ATraining Step: 439  | total loss: [1m[32m0.34430[0m[0m | time: 952.818s
[2K
| Adam | epoch: 005 | loss: 0.34430 - acc: 0.8728 -- iter: 2528/2867
[A[ATraining Step: 440  | total loss: [1m[32m0.33174[0m[0m | time: 964.791s
[2K
| Adam | epoch: 005 | loss: 0.33174 - acc: 0.8824 -- iter: 2560/2867
[A[ATraining Step: 441  | total loss: [1m[32m0.33367[0m[0m | time: 976.652s
[2K
| Adam | epoch: 005 | loss: 0.33367 - acc: 0.8879 -- iter: 2592/2867
[A[ATraining Step: 442  | total loss: [1m[32m0.32982[0m[0m | time: 988.501s
[2K
| Adam | epoch: 005 | loss: 0.32982 - acc: 0.8898 -- iter: 2624/2867
[A[ATraining Step: 443  | total loss: [1m[32m0.34815[0m[0m | time: 1000.343s
[2K
| Adam | epoch: 005 | loss: 0.34815 - acc: 0.8789 -- iter: 2656/2867
[A[ATraining Step: 444  | total loss: [1m[32m0.35101[0m[0m | time: 1011.943s
[2K
| Adam | epoch: 005 | loss: 0.35101 - acc: 0.8785 -- iter: 2688/2867
[A[ATraining Step: 445  | total loss: [1m[32m0.34772[0m[0m | time: 1023.528s
[2K
| Adam | epoch: 005 | loss: 0.34772 - acc: 0.8782 -- iter: 2720/2867
[A[ATraining Step: 446  | total loss: [1m[32m0.34589[0m[0m | time: 1035.186s
[2K
| Adam | epoch: 005 | loss: 0.34589 - acc: 0.8810 -- iter: 2752/2867
[A[ATraining Step: 447  | total loss: [1m[32m0.35307[0m[0m | time: 1046.625s
[2K
| Adam | epoch: 005 | loss: 0.35307 - acc: 0.8710 -- iter: 2784/2867
[A[ATraining Step: 448  | total loss: [1m[32m0.34200[0m[0m | time: 1058.069s
[2K
| Adam | epoch: 005 | loss: 0.34200 - acc: 0.8745 -- iter: 2816/2867
[A[ATraining Step: 449  | total loss: [1m[32m0.36342[0m[0m | time: 1068.887s
[2K
| Adam | epoch: 005 | loss: 0.36342 - acc: 0.8715 -- iter: 2848/2867
[A[ATraining Step: 450  | total loss: [1m[32m0.35912[0m[0m | time: 1141.518s
[2K
| Adam | epoch: 005 | loss: 0.35912 - acc: 0.8687 | val_loss: 1.66842 - val_acc: 0.6878 -- iter: 2867/2867
--
Training Step: 451  | total loss: [1m[32m0.36767[0m[0m | time: 11.808s
[2K
| Adam | epoch: 006 | loss: 0.36767 - acc: 0.8693 -- iter: 0032/2867
[A[ATraining Step: 452  | total loss: [1m[32m0.37393[0m[0m | time: 23.308s
[2K
| Adam | epoch: 006 | loss: 0.37393 - acc: 0.8636 -- iter: 0064/2867
[A[ATraining Step: 453  | total loss: [1m[32m0.36737[0m[0m | time: 34.755s
[2K
| Adam | epoch: 006 | loss: 0.36737 - acc: 0.8616 -- iter: 0096/2867
[A[ATraining Step: 454  | total loss: [1m[32m0.37622[0m[0m | time: 42.914s
[2K
| Adam | epoch: 006 | loss: 0.37622 - acc: 0.8536 -- iter: 0128/2867
[A[ATraining Step: 455  | total loss: [1m[32m0.38334[0m[0m | time: 50.218s
[2K
| Adam | epoch: 006 | loss: 0.38334 - acc: 0.8419 -- iter: 0160/2867
[A[ATraining Step: 456  | total loss: [1m[32m0.36613[0m[0m | time: 61.812s
[2K
| Adam | epoch: 006 | loss: 0.36613 - acc: 0.8419 -- iter: 0192/2867
[A[ATraining Step: 457  | total loss: [1m[32m0.36680[0m[0m | time: 73.309s
[2K
| Adam | epoch: 006 | loss: 0.36680 - acc: 0.8421 -- iter: 0224/2867
[A[ATraining Step: 458  | total loss: [1m[32m0.40264[0m[0m | time: 84.770s
[2K
| Adam | epoch: 006 | loss: 0.40264 - acc: 0.8298 -- iter: 0256/2867
[A[ATraining Step: 459  | total loss: [1m[32m0.41720[0m[0m | time: 96.504s
[2K
| Adam | epoch: 006 | loss: 0.41720 - acc: 0.8281 -- iter: 0288/2867
[A[ATraining Step: 460  | total loss: [1m[32m0.39968[0m[0m | time: 107.983s
[2K
| Adam | epoch: 006 | loss: 0.39968 - acc: 0.8296 -- iter: 0320/2867
[A[ATraining Step: 461  | total loss: [1m[32m0.42467[0m[0m | time: 119.265s
[2K
| Adam | epoch: 006 | loss: 0.42467 - acc: 0.8217 -- iter: 0352/2867
[A[ATraining Step: 462  | total loss: [1m[32m0.42765[0m[0m | time: 131.119s
[2K
| Adam | epoch: 006 | loss: 0.42765 - acc: 0.8176 -- iter: 0384/2867
[A[ATraining Step: 463  | total loss: [1m[32m0.42904[0m[0m | time: 142.829s
[2K
| Adam | epoch: 006 | loss: 0.42904 - acc: 0.8046 -- iter: 0416/2867
[A[ATraining Step: 464  | total loss: [1m[32m0.43241[0m[0m | time: 155.041s
[2K
| Adam | epoch: 006 | loss: 0.43241 - acc: 0.7960 -- iter: 0448/2867
[A[ATraining Step: 465  | total loss: [1m[32m0.43106[0m[0m | time: 165.016s
[2K
| Adam | epoch: 006 | loss: 0.43106 - acc: 0.7914 -- iter: 0480/2867
[A[ATraining Step: 466  | total loss: [1m[32m0.42829[0m[0m | time: 173.097s
[2K
| Adam | epoch: 006 | loss: 0.42829 - acc: 0.7873 -- iter: 0512/2867
[A[ATraining Step: 467  | total loss: [1m[32m0.42902[0m[0m | time: 181.348s
[2K
| Adam | epoch: 006 | loss: 0.42902 - acc: 0.7804 -- iter: 0544/2867
[A[ATraining Step: 468  | total loss: [1m[32m0.41848[0m[0m | time: 189.282s
[2K
| Adam | epoch: 006 | loss: 0.41848 - acc: 0.7899 -- iter: 0576/2867
[A[ATraining Step: 469  | total loss: [1m[32m0.41400[0m[0m | time: 198.923s
[2K
| Adam | epoch: 006 | loss: 0.41400 - acc: 0.7953 -- iter: 0608/2867
[A[ATraining Step: 470  | total loss: [1m[32m0.41490[0m[0m | time: 210.630s
[2K
| Adam | epoch: 006 | loss: 0.41490 - acc: 0.7939 -- iter: 0640/2867
[A[ATraining Step: 471  | total loss: [1m[32m0.41309[0m[0m | time: 222.401s
[2K
| Adam | epoch: 006 | loss: 0.41309 - acc: 0.7989 -- iter: 0672/2867
[A[ATraining Step: 472  | total loss: [1m[32m0.41344[0m[0m | time: 233.668s
[2K
| Adam | epoch: 006 | loss: 0.41344 - acc: 0.8002 -- iter: 0704/2867
[A[ATraining Step: 473  | total loss: [1m[32m0.39890[0m[0m | time: 245.497s
[2K
| Adam | epoch: 006 | loss: 0.39890 - acc: 0.8108 -- iter: 0736/2867
[A[ATraining Step: 474  | total loss: [1m[32m0.39431[0m[0m | time: 257.466s
[2K
| Adam | epoch: 006 | loss: 0.39431 - acc: 0.8110 -- iter: 0768/2867
[A[ATraining Step: 475  | total loss: [1m[32m0.41676[0m[0m | time: 269.347s
[2K
| Adam | epoch: 006 | loss: 0.41676 - acc: 0.8018 -- iter: 0800/2867
[A[ATraining Step: 476  | total loss: [1m[32m0.42018[0m[0m | time: 280.702s
[2K
| Adam | epoch: 006 | loss: 0.42018 - acc: 0.7966 -- iter: 0832/2867
[A[ATraining Step: 477  | total loss: [1m[32m0.41299[0m[0m | time: 292.516s
[2K
| Adam | epoch: 006 | loss: 0.41299 - acc: 0.8013 -- iter: 0864/2867
[A[ATraining Step: 478  | total loss: [1m[32m0.41600[0m[0m | time: 304.027s
[2K
| Adam | epoch: 006 | loss: 0.41600 - acc: 0.8056 -- iter: 0896/2867
[A[ATraining Step: 479  | total loss: [1m[32m0.42275[0m[0m | time: 316.091s
[2K
| Adam | epoch: 006 | loss: 0.42275 - acc: 0.8031 -- iter: 0928/2867
[A[ATraining Step: 480  | total loss: [1m[32m0.41303[0m[0m | time: 327.782s
[2K
| Adam | epoch: 006 | loss: 0.41303 - acc: 0.8166 -- iter: 0960/2867
[A[ATraining Step: 481  | total loss: [1m[32m0.40748[0m[0m | time: 339.707s
[2K
| Adam | epoch: 006 | loss: 0.40748 - acc: 0.8255 -- iter: 0992/2867
[A[ATraining Step: 482  | total loss: [1m[32m0.42775[0m[0m | time: 351.065s
[2K
| Adam | epoch: 006 | loss: 0.42775 - acc: 0.8180 -- iter: 1024/2867
[A[ATraining Step: 483  | total loss: [1m[32m0.42177[0m[0m | time: 362.635s
[2K
| Adam | epoch: 006 | loss: 0.42177 - acc: 0.8112 -- iter: 1056/2867
[A[ATraining Step: 484  | total loss: [1m[32m0.40739[0m[0m | time: 374.319s
[2K
| Adam | epoch: 006 | loss: 0.40739 - acc: 0.8269 -- iter: 1088/2867
[A[ATraining Step: 485  | total loss: [1m[32m0.40166[0m[0m | time: 386.154s
[2K
| Adam | epoch: 006 | loss: 0.40166 - acc: 0.8286 -- iter: 1120/2867
[A[ATraining Step: 486  | total loss: [1m[32m0.40258[0m[0m | time: 397.664s
[2K
| Adam | epoch: 006 | loss: 0.40258 - acc: 0.8333 -- iter: 1152/2867
[A[ATraining Step: 487  | total loss: [1m[32m0.40440[0m[0m | time: 409.319s
[2K
| Adam | epoch: 006 | loss: 0.40440 - acc: 0.8374 -- iter: 1184/2867
[A[ATraining Step: 488  | total loss: [1m[32m0.39956[0m[0m | time: 421.035s
[2K
| Adam | epoch: 006 | loss: 0.39956 - acc: 0.8412 -- iter: 1216/2867
[A[ATraining Step: 489  | total loss: [1m[32m0.39160[0m[0m | time: 432.228s
[2K
| Adam | epoch: 006 | loss: 0.39160 - acc: 0.8383 -- iter: 1248/2867
[A[ATraining Step: 490  | total loss: [1m[32m0.41893[0m[0m | time: 443.144s
[2K
| Adam | epoch: 006 | loss: 0.41893 - acc: 0.8326 -- iter: 1280/2867
[A[ATraining Step: 491  | total loss: [1m[32m0.42276[0m[0m | time: 454.927s
[2K
| Adam | epoch: 006 | loss: 0.42276 - acc: 0.8212 -- iter: 1312/2867
[A[ATraining Step: 492  | total loss: [1m[32m0.41485[0m[0m | time: 466.583s
[2K
| Adam | epoch: 006 | loss: 0.41485 - acc: 0.8235 -- iter: 1344/2867
[A[ATraining Step: 493  | total loss: [1m[32m0.40766[0m[0m | time: 478.200s
[2K
| Adam | epoch: 006 | loss: 0.40766 - acc: 0.8318 -- iter: 1376/2867
[A[ATraining Step: 494  | total loss: [1m[32m0.40388[0m[0m | time: 490.013s
[2K
| Adam | epoch: 006 | loss: 0.40388 - acc: 0.8361 -- iter: 1408/2867
[A[ATraining Step: 495  | total loss: [1m[32m0.40133[0m[0m | time: 501.710s
[2K
| Adam | epoch: 006 | loss: 0.40133 - acc: 0.8306 -- iter: 1440/2867
[A[ATraining Step: 496  | total loss: [1m[32m0.41428[0m[0m | time: 513.473s
[2K
| Adam | epoch: 006 | loss: 0.41428 - acc: 0.8194 -- iter: 1472/2867
[A[ATraining Step: 497  | total loss: [1m[32m0.41028[0m[0m | time: 525.343s
[2K
| Adam | epoch: 006 | loss: 0.41028 - acc: 0.8218 -- iter: 1504/2867
[A[ATraining Step: 498  | total loss: [1m[32m0.40936[0m[0m | time: 536.715s
[2K
| Adam | epoch: 006 | loss: 0.40936 - acc: 0.8240 -- iter: 1536/2867
[A[ATraining Step: 499  | total loss: [1m[32m0.40319[0m[0m | time: 548.449s
[2K
| Adam | epoch: 006 | loss: 0.40319 - acc: 0.8291 -- iter: 1568/2867
[A[ATraining Step: 500  | total loss: [1m[32m0.40513[0m[0m | time: 560.779s
[2K
| Adam | epoch: 006 | loss: 0.40513 - acc: 0.8368 -- iter: 1600/2867
[A[ATraining Step: 501  | total loss: [1m[32m0.38981[0m[0m | time: 572.212s
[2K
| Adam | epoch: 006 | loss: 0.38981 - acc: 0.8438 -- iter: 1632/2867
[A[ATraining Step: 502  | total loss: [1m[32m0.44047[0m[0m | time: 584.010s
[2K
| Adam | epoch: 006 | loss: 0.44047 - acc: 0.8188 -- iter: 1664/2867
[A[ATraining Step: 503  | total loss: [1m[32m0.42406[0m[0m | time: 596.054s
[2K
| Adam | epoch: 006 | loss: 0.42406 - acc: 0.8307 -- iter: 1696/2867
[A[ATraining Step: 504  | total loss: [1m[32m0.40250[0m[0m | time: 607.819s
[2K
| Adam | epoch: 006 | loss: 0.40250 - acc: 0.8445 -- iter: 1728/2867
[A[ATraining Step: 505  | total loss: [1m[32m0.41851[0m[0m | time: 619.492s
[2K
| Adam | epoch: 006 | loss: 0.41851 - acc: 0.8350 -- iter: 1760/2867
[A[ATraining Step: 506  | total loss: [1m[32m0.40905[0m[0m | time: 630.990s
[2K
| Adam | epoch: 006 | loss: 0.40905 - acc: 0.8359 -- iter: 1792/2867
[A[ATraining Step: 507  | total loss: [1m[32m0.40106[0m[0m | time: 642.756s
[2K
| Adam | epoch: 006 | loss: 0.40106 - acc: 0.8398 -- iter: 1824/2867
[A[ATraining Step: 508  | total loss: [1m[32m0.39121[0m[0m | time: 654.560s
[2K
| Adam | epoch: 006 | loss: 0.39121 - acc: 0.8433 -- iter: 1856/2867
[A[ATraining Step: 509  | total loss: [1m[32m0.39148[0m[0m | time: 665.966s
[2K
| Adam | epoch: 006 | loss: 0.39148 - acc: 0.8465 -- iter: 1888/2867
[A[ATraining Step: 510  | total loss: [1m[32m0.38415[0m[0m | time: 678.383s
[2K
| Adam | epoch: 006 | loss: 0.38415 - acc: 0.8462 -- iter: 1920/2867
[A[ATraining Step: 511  | total loss: [1m[32m0.36782[0m[0m | time: 691.307s
[2K
| Adam | epoch: 006 | loss: 0.36782 - acc: 0.8553 -- iter: 1952/2867
[A[ATraining Step: 512  | total loss: [1m[32m0.37480[0m[0m | time: 699.726s
[2K
| Adam | epoch: 006 | loss: 0.37480 - acc: 0.8573 -- iter: 1984/2867
[A[ATraining Step: 513  | total loss: [1m[32m0.38903[0m[0m | time: 707.736s
[2K
| Adam | epoch: 006 | loss: 0.38903 - acc: 0.8466 -- iter: 2016/2867
[A[ATraining Step: 514  | total loss: [1m[32m0.38565[0m[0m | time: 716.554s
[2K
| Adam | epoch: 006 | loss: 0.38565 - acc: 0.8525 -- iter: 2048/2867
[A[ATraining Step: 515  | total loss: [1m[32m0.39041[0m[0m | time: 727.910s
[2K
| Adam | epoch: 006 | loss: 0.39041 - acc: 0.8454 -- iter: 2080/2867
[A[ATraining Step: 516  | total loss: [1m[32m0.36607[0m[0m | time: 739.245s
[2K
| Adam | epoch: 006 | loss: 0.36607 - acc: 0.8577 -- iter: 2112/2867
[A[ATraining Step: 517  | total loss: [1m[32m0.38534[0m[0m | time: 750.861s
[2K
| Adam | epoch: 006 | loss: 0.38534 - acc: 0.8470 -- iter: 2144/2867
[A[ATraining Step: 518  | total loss: [1m[32m0.39762[0m[0m | time: 762.471s
[2K
| Adam | epoch: 006 | loss: 0.39762 - acc: 0.8435 -- iter: 2176/2867
[A[ATraining Step: 519  | total loss: [1m[32m0.38483[0m[0m | time: 774.244s
[2K
| Adam | epoch: 006 | loss: 0.38483 - acc: 0.8498 -- iter: 2208/2867
[A[ATraining Step: 520  | total loss: [1m[32m0.36341[0m[0m | time: 785.867s
[2K
| Adam | epoch: 006 | loss: 0.36341 - acc: 0.8648 -- iter: 2240/2867
[A[ATraining Step: 521  | total loss: [1m[32m0.34986[0m[0m | time: 797.813s
[2K
| Adam | epoch: 006 | loss: 0.34986 - acc: 0.8690 -- iter: 2272/2867
[A[ATraining Step: 522  | total loss: [1m[32m0.34818[0m[0m | time: 809.577s
[2K
| Adam | epoch: 006 | loss: 0.34818 - acc: 0.8664 -- iter: 2304/2867
[A[ATraining Step: 523  | total loss: [1m[32m0.34325[0m[0m | time: 821.526s
[2K
| Adam | epoch: 006 | loss: 0.34325 - acc: 0.8735 -- iter: 2336/2867
[A[ATraining Step: 524  | total loss: [1m[32m0.32554[0m[0m | time: 832.961s
[2K
| Adam | epoch: 006 | loss: 0.32554 - acc: 0.8799 -- iter: 2368/2867
[A[ATraining Step: 525  | total loss: [1m[32m0.31775[0m[0m | time: 844.500s
[2K
| Adam | epoch: 006 | loss: 0.31775 - acc: 0.8794 -- iter: 2400/2867
[A[ATraining Step: 526  | total loss: [1m[32m0.31757[0m[0m | time: 855.758s
[2K
| Adam | epoch: 006 | loss: 0.31757 - acc: 0.8696 -- iter: 2432/2867
[A[ATraining Step: 527  | total loss: [1m[32m0.32015[0m[0m | time: 868.107s
[2K
| Adam | epoch: 006 | loss: 0.32015 - acc: 0.8733 -- iter: 2464/2867
[A[ATraining Step: 528  | total loss: [1m[32m0.32050[0m[0m | time: 879.911s
[2K
| Adam | epoch: 006 | loss: 0.32050 - acc: 0.8703 -- iter: 2496/2867
[A[ATraining Step: 529  | total loss: [1m[32m0.32778[0m[0m | time: 891.637s
[2K
| Adam | epoch: 006 | loss: 0.32778 - acc: 0.8677 -- iter: 2528/2867
[A[ATraining Step: 530  | total loss: [1m[32m0.33317[0m[0m | time: 903.469s
[2K
| Adam | epoch: 006 | loss: 0.33317 - acc: 0.8684 -- iter: 2560/2867
[A[ATraining Step: 531  | total loss: [1m[32m0.32534[0m[0m | time: 915.298s
[2K
| Adam | epoch: 006 | loss: 0.32534 - acc: 0.8722 -- iter: 2592/2867
[A[ATraining Step: 532  | total loss: [1m[32m0.34756[0m[0m | time: 926.936s
[2K
| Adam | epoch: 006 | loss: 0.34756 - acc: 0.8631 -- iter: 2624/2867
[A[ATraining Step: 533  | total loss: [1m[32m0.34754[0m[0m | time: 938.787s
[2K
| Adam | epoch: 006 | loss: 0.34754 - acc: 0.8643 -- iter: 2656/2867
[A[ATraining Step: 534  | total loss: [1m[32m0.37397[0m[0m | time: 950.288s
[2K
| Adam | epoch: 006 | loss: 0.37397 - acc: 0.8529 -- iter: 2688/2867
[A[ATraining Step: 535  | total loss: [1m[32m0.36323[0m[0m | time: 961.701s
[2K
| Adam | epoch: 006 | loss: 0.36323 - acc: 0.8551 -- iter: 2720/2867
[A[ATraining Step: 536  | total loss: [1m[32m0.36426[0m[0m | time: 972.504s
[2K
| Adam | epoch: 006 | loss: 0.36426 - acc: 0.8539 -- iter: 2752/2867
[A[ATraining Step: 537  | total loss: [1m[32m0.35679[0m[0m | time: 984.048s
[2K
| Adam | epoch: 006 | loss: 0.35679 - acc: 0.8592 -- iter: 2784/2867
[A[ATraining Step: 538  | total loss: [1m[32m0.34346[0m[0m | time: 995.569s
[2K
| Adam | epoch: 006 | loss: 0.34346 - acc: 0.8639 -- iter: 2816/2867
[A[ATraining Step: 539  | total loss: [1m[32m0.33306[0m[0m | time: 1007.380s
[2K
| Adam | epoch: 006 | loss: 0.33306 - acc: 0.8712 -- iter: 2848/2867
[A[ATraining Step: 540  | total loss: [1m[32m0.32157[0m[0m | time: 1075.759s
[2K
| Adam | epoch: 006 | loss: 0.32157 - acc: 0.8779 | val_loss: 0.45507 - val_acc: 0.8027 -- iter: 2867/2867
--
Training Step: 541  | total loss: [1m[32m0.30850[0m[0m | time: 11.963s
[2K
| Adam | epoch: 007 | loss: 0.30850 - acc: 0.8807 -- iter: 0032/2867
[A[ATraining Step: 542  | total loss: [1m[32m0.32303[0m[0m | time: 23.765s
[2K
| Adam | epoch: 007 | loss: 0.32303 - acc: 0.8801 -- iter: 0064/2867
[A[ATraining Step: 543  | total loss: [1m[32m0.30629[0m[0m | time: 35.486s
[2K
| Adam | epoch: 007 | loss: 0.30629 - acc: 0.8890 -- iter: 0096/2867
[A[ATraining Step: 544  | total loss: [1m[32m0.33087[0m[0m | time: 47.280s
[2K
| Adam | epoch: 007 | loss: 0.33087 - acc: 0.8688 -- iter: 0128/2867
[A[ATraining Step: 545  | total loss: [1m[32m0.32012[0m[0m | time: 54.870s
[2K
| Adam | epoch: 007 | loss: 0.32012 - acc: 0.8726 -- iter: 0160/2867
[A[ATraining Step: 546  | total loss: [1m[32m0.31309[0m[0m | time: 62.736s
[2K
| Adam | epoch: 007 | loss: 0.31309 - acc: 0.8695 -- iter: 0192/2867
[A[ATraining Step: 547  | total loss: [1m[32m0.29528[0m[0m | time: 74.406s
[2K
| Adam | epoch: 007 | loss: 0.29528 - acc: 0.8826 -- iter: 0224/2867
[A[ATraining Step: 548  | total loss: [1m[32m0.28387[0m[0m | time: 86.330s
[2K
| Adam | epoch: 007 | loss: 0.28387 - acc: 0.8850 -- iter: 0256/2867
[A[ATraining Step: 549  | total loss: [1m[32m0.28136[0m[0m | time: 98.145s
[2K
| Adam | epoch: 007 | loss: 0.28136 - acc: 0.8902 -- iter: 0288/2867
[A[ATraining Step: 550  | total loss: [1m[32m0.26712[0m[0m | time: 110.504s
[2K
| Adam | epoch: 007 | loss: 0.26712 - acc: 0.8981 -- iter: 0320/2867
[A[ATraining Step: 551  | total loss: [1m[32m0.25471[0m[0m | time: 123.564s
[2K
| Adam | epoch: 007 | loss: 0.25471 - acc: 0.8989 -- iter: 0352/2867
[A[ATraining Step: 552  | total loss: [1m[32m0.24792[0m[0m | time: 133.593s
[2K
| Adam | epoch: 007 | loss: 0.24792 - acc: 0.8996 -- iter: 0384/2867
[A[ATraining Step: 553  | total loss: [1m[32m0.25577[0m[0m | time: 141.546s
[2K
| Adam | epoch: 007 | loss: 0.25577 - acc: 0.8909 -- iter: 0416/2867
[A[ATraining Step: 554  | total loss: [1m[32m0.26175[0m[0m | time: 149.344s
[2K
| Adam | epoch: 007 | loss: 0.26175 - acc: 0.8893 -- iter: 0448/2867
[A[ATraining Step: 555  | total loss: [1m[32m0.24705[0m[0m | time: 160.847s
[2K
| Adam | epoch: 007 | loss: 0.24705 - acc: 0.8973 -- iter: 0480/2867
[A[ATraining Step: 556  | total loss: [1m[32m0.25888[0m[0m | time: 172.718s
[2K
| Adam | epoch: 007 | loss: 0.25888 - acc: 0.8950 -- iter: 0512/2867
[A[ATraining Step: 557  | total loss: [1m[32m0.26126[0m[0m | time: 184.384s
[2K
| Adam | epoch: 007 | loss: 0.26126 - acc: 0.8899 -- iter: 0544/2867
[A[ATraining Step: 558  | total loss: [1m[32m0.27062[0m[0m | time: 195.837s
[2K
| Adam | epoch: 007 | loss: 0.27062 - acc: 0.8853 -- iter: 0576/2867
[A[ATraining Step: 559  | total loss: [1m[32m0.27276[0m[0m | time: 207.486s
[2K
| Adam | epoch: 007 | loss: 0.27276 - acc: 0.8843 -- iter: 0608/2867
[A[ATraining Step: 560  | total loss: [1m[32m0.27068[0m[0m | time: 219.300s
[2K
| Adam | epoch: 007 | loss: 0.27068 - acc: 0.8833 -- iter: 0640/2867
[A[ATraining Step: 561  | total loss: [1m[32m0.28443[0m[0m | time: 231.117s
[2K
| Adam | epoch: 007 | loss: 0.28443 - acc: 0.8763 -- iter: 0672/2867
[A[ATraining Step: 562  | total loss: [1m[32m0.27909[0m[0m | time: 243.288s
[2K
| Adam | epoch: 007 | loss: 0.27909 - acc: 0.8793 -- iter: 0704/2867
[A[ATraining Step: 563  | total loss: [1m[32m0.28319[0m[0m | time: 255.003s
[2K
| Adam | epoch: 007 | loss: 0.28319 - acc: 0.8757 -- iter: 0736/2867
[A[ATraining Step: 564  | total loss: [1m[32m0.28367[0m[0m | time: 266.896s
[2K
| Adam | epoch: 007 | loss: 0.28367 - acc: 0.8788 -- iter: 0768/2867
[A[ATraining Step: 565  | total loss: [1m[32m0.30100[0m[0m | time: 278.595s
[2K
| Adam | epoch: 007 | loss: 0.30100 - acc: 0.8690 -- iter: 0800/2867
[A[ATraining Step: 566  | total loss: [1m[32m0.29877[0m[0m | time: 290.479s
[2K
| Adam | epoch: 007 | loss: 0.29877 - acc: 0.8696 -- iter: 0832/2867
[A[ATraining Step: 567  | total loss: [1m[32m0.30309[0m[0m | time: 302.014s
[2K
| Adam | epoch: 007 | loss: 0.30309 - acc: 0.8764 -- iter: 0864/2867
[A[ATraining Step: 568  | total loss: [1m[32m0.31754[0m[0m | time: 313.642s
[2K
| Adam | epoch: 007 | loss: 0.31754 - acc: 0.8731 -- iter: 0896/2867
[A[ATraining Step: 569  | total loss: [1m[32m0.30805[0m[0m | time: 325.308s
[2K
| Adam | epoch: 007 | loss: 0.30805 - acc: 0.8827 -- iter: 0928/2867
[A[ATraining Step: 570  | total loss: [1m[32m0.32444[0m[0m | time: 337.086s
[2K
| Adam | epoch: 007 | loss: 0.32444 - acc: 0.8788 -- iter: 0960/2867
[A[ATraining Step: 571  | total loss: [1m[32m0.33919[0m[0m | time: 349.117s
[2K
| Adam | epoch: 007 | loss: 0.33919 - acc: 0.8722 -- iter: 0992/2867
[A[ATraining Step: 572  | total loss: [1m[32m0.36282[0m[0m | time: 360.721s
[2K
| Adam | epoch: 007 | loss: 0.36282 - acc: 0.8537 -- iter: 1024/2867
[A[ATraining Step: 573  | total loss: [1m[32m0.37134[0m[0m | time: 372.677s
[2K
| Adam | epoch: 007 | loss: 0.37134 - acc: 0.8465 -- iter: 1056/2867
[A[ATraining Step: 574  | total loss: [1m[32m0.38931[0m[0m | time: 384.182s
[2K
| Adam | epoch: 007 | loss: 0.38931 - acc: 0.8337 -- iter: 1088/2867
[A[ATraining Step: 575  | total loss: [1m[32m0.38538[0m[0m | time: 396.091s
[2K
| Adam | epoch: 007 | loss: 0.38538 - acc: 0.8347 -- iter: 1120/2867
[A[ATraining Step: 576  | total loss: [1m[32m0.37346[0m[0m | time: 407.792s
[2K
| Adam | epoch: 007 | loss: 0.37346 - acc: 0.8418 -- iter: 1152/2867
[A[ATraining Step: 577  | total loss: [1m[32m0.36997[0m[0m | time: 418.900s
[2K
| Adam | epoch: 007 | loss: 0.36997 - acc: 0.8452 -- iter: 1184/2867
[A[ATraining Step: 578  | total loss: [1m[32m0.36756[0m[0m | time: 430.652s
[2K
| Adam | epoch: 007 | loss: 0.36756 - acc: 0.8513 -- iter: 1216/2867
[A[ATraining Step: 579  | total loss: [1m[32m0.37503[0m[0m | time: 442.351s
[2K
| Adam | epoch: 007 | loss: 0.37503 - acc: 0.8443 -- iter: 1248/2867
[A[ATraining Step: 580  | total loss: [1m[32m0.36147[0m[0m | time: 454.106s
[2K
| Adam | epoch: 007 | loss: 0.36147 - acc: 0.8536 -- iter: 1280/2867
[A[ATraining Step: 581  | total loss: [1m[32m0.35292[0m[0m | time: 465.727s
[2K
| Adam | epoch: 007 | loss: 0.35292 - acc: 0.8620 -- iter: 1312/2867
[A[ATraining Step: 582  | total loss: [1m[32m0.34249[0m[0m | time: 477.711s
[2K
| Adam | epoch: 007 | loss: 0.34249 - acc: 0.8664 -- iter: 1344/2867
[A[ATraining Step: 583  | total loss: [1m[32m0.34087[0m[0m | time: 489.341s
[2K
| Adam | epoch: 007 | loss: 0.34087 - acc: 0.8641 -- iter: 1376/2867
[A[ATraining Step: 584  | total loss: [1m[32m0.33840[0m[0m | time: 500.712s
[2K
| Adam | epoch: 007 | loss: 0.33840 - acc: 0.8621 -- iter: 1408/2867
[A[ATraining Step: 585  | total loss: [1m[32m0.34480[0m[0m | time: 512.585s
[2K
| Adam | epoch: 007 | loss: 0.34480 - acc: 0.8603 -- iter: 1440/2867
[A[ATraining Step: 586  | total loss: [1m[32m0.33105[0m[0m | time: 524.099s
[2K
| Adam | epoch: 007 | loss: 0.33105 - acc: 0.8711 -- iter: 1472/2867
[A[ATraining Step: 587  | total loss: [1m[32m0.32563[0m[0m | time: 535.719s
[2K
| Adam | epoch: 007 | loss: 0.32563 - acc: 0.8715 -- iter: 1504/2867
[A[ATraining Step: 588  | total loss: [1m[32m0.31487[0m[0m | time: 547.405s
[2K
| Adam | epoch: 007 | loss: 0.31487 - acc: 0.8750 -- iter: 1536/2867
[A[ATraining Step: 589  | total loss: [1m[32m0.31722[0m[0m | time: 558.899s
[2K
| Adam | epoch: 007 | loss: 0.31722 - acc: 0.8687 -- iter: 1568/2867
[A[ATraining Step: 590  | total loss: [1m[32m0.33732[0m[0m | time: 570.727s
[2K
| Adam | epoch: 007 | loss: 0.33732 - acc: 0.8631 -- iter: 1600/2867
[A[ATraining Step: 591  | total loss: [1m[32m0.33055[0m[0m | time: 582.404s
[2K
| Adam | epoch: 007 | loss: 0.33055 - acc: 0.8612 -- iter: 1632/2867
[A[ATraining Step: 592  | total loss: [1m[32m0.33591[0m[0m | time: 594.030s
[2K
| Adam | epoch: 007 | loss: 0.33591 - acc: 0.8469 -- iter: 1664/2867
[A[ATraining Step: 593  | total loss: [1m[32m0.34371[0m[0m | time: 605.501s
[2K
| Adam | epoch: 007 | loss: 0.34371 - acc: 0.8404 -- iter: 1696/2867
[A[ATraining Step: 594  | total loss: [1m[32m0.36704[0m[0m | time: 617.148s
[2K
| Adam | epoch: 007 | loss: 0.36704 - acc: 0.8313 -- iter: 1728/2867
[A[ATraining Step: 595  | total loss: [1m[32m0.37957[0m[0m | time: 629.873s
[2K
| Adam | epoch: 007 | loss: 0.37957 - acc: 0.8169 -- iter: 1760/2867
[A[ATraining Step: 596  | total loss: [1m[32m0.38917[0m[0m | time: 642.543s
[2K
| Adam | epoch: 007 | loss: 0.38917 - acc: 0.8134 -- iter: 1792/2867
[A[ATraining Step: 597  | total loss: [1m[32m0.37255[0m[0m | time: 651.103s
[2K
| Adam | epoch: 007 | loss: 0.37255 - acc: 0.8227 -- iter: 1824/2867
[A[ATraining Step: 598  | total loss: [1m[32m0.35884[0m[0m | time: 659.214s
[2K
| Adam | epoch: 007 | loss: 0.35884 - acc: 0.8341 -- iter: 1856/2867
[A[ATraining Step: 599  | total loss: [1m[32m0.34905[0m[0m | time: 667.399s
[2K
| Adam | epoch: 007 | loss: 0.34905 - acc: 0.8445 -- iter: 1888/2867
[A[ATraining Step: 600  | total loss: [1m[32m0.33707[0m[0m | time: 735.397s
[2K
| Adam | epoch: 007 | loss: 0.33707 - acc: 0.8569 | val_loss: 0.83200 - val_acc: 0.7525 -- iter: 1920/2867
--
Training Step: 601  | total loss: [1m[32m0.35147[0m[0m | time: 747.454s
[2K
| Adam | epoch: 007 | loss: 0.35147 - acc: 0.8525 -- iter: 1952/2867
[A[ATraining Step: 602  | total loss: [1m[32m0.34446[0m[0m | time: 759.119s
[2K
| Adam | epoch: 007 | loss: 0.34446 - acc: 0.8547 -- iter: 1984/2867
[A[ATraining Step: 603  | total loss: [1m[32m0.33491[0m[0m | time: 770.683s
[2K
| Adam | epoch: 007 | loss: 0.33491 - acc: 0.8567 -- iter: 2016/2867
[A[ATraining Step: 604  | total loss: [1m[32m0.34526[0m[0m | time: 781.945s
[2K
| Adam | epoch: 007 | loss: 0.34526 - acc: 0.8617 -- iter: 2048/2867
[A[ATraining Step: 605  | total loss: [1m[32m0.33468[0m[0m | time: 793.599s
[2K
| Adam | epoch: 007 | loss: 0.33468 - acc: 0.8662 -- iter: 2080/2867
[A[ATraining Step: 606  | total loss: [1m[32m0.33638[0m[0m | time: 805.523s
[2K
| Adam | epoch: 007 | loss: 0.33638 - acc: 0.8702 -- iter: 2112/2867
[A[ATraining Step: 607  | total loss: [1m[32m0.33027[0m[0m | time: 817.329s
[2K
| Adam | epoch: 007 | loss: 0.33027 - acc: 0.8706 -- iter: 2144/2867
[A[ATraining Step: 608  | total loss: [1m[32m0.33009[0m[0m | time: 828.965s
[2K
| Adam | epoch: 007 | loss: 0.33009 - acc: 0.8680 -- iter: 2176/2867
[A[ATraining Step: 609  | total loss: [1m[32m0.32736[0m[0m | time: 840.468s
[2K
| Adam | epoch: 007 | loss: 0.32736 - acc: 0.8655 -- iter: 2208/2867
[A[ATraining Step: 610  | total loss: [1m[32m0.32281[0m[0m | time: 852.242s
[2K
| Adam | epoch: 007 | loss: 0.32281 - acc: 0.8696 -- iter: 2240/2867
[A[ATraining Step: 611  | total loss: [1m[32m0.31743[0m[0m | time: 864.090s
[2K
| Adam | epoch: 007 | loss: 0.31743 - acc: 0.8701 -- iter: 2272/2867
[A[ATraining Step: 612  | total loss: [1m[32m0.32042[0m[0m | time: 875.613s
[2K
| Adam | epoch: 007 | loss: 0.32042 - acc: 0.8738 -- iter: 2304/2867
[A[ATraining Step: 613  | total loss: [1m[32m0.33697[0m[0m | time: 887.400s
[2K
| Adam | epoch: 007 | loss: 0.33697 - acc: 0.8614 -- iter: 2336/2867
[A[ATraining Step: 614  | total loss: [1m[32m0.32806[0m[0m | time: 899.372s
[2K
| Adam | epoch: 007 | loss: 0.32806 - acc: 0.8690 -- iter: 2368/2867
[A[ATraining Step: 615  | total loss: [1m[32m0.32256[0m[0m | time: 910.981s
[2K
| Adam | epoch: 007 | loss: 0.32256 - acc: 0.8758 -- iter: 2400/2867
[A[ATraining Step: 616  | total loss: [1m[32m0.32694[0m[0m | time: 922.580s
[2K
| Adam | epoch: 007 | loss: 0.32694 - acc: 0.8758 -- iter: 2432/2867
[A[ATraining Step: 617  | total loss: [1m[32m0.31584[0m[0m | time: 934.145s
[2K
| Adam | epoch: 007 | loss: 0.31584 - acc: 0.8788 -- iter: 2464/2867
[A[ATraining Step: 618  | total loss: [1m[32m0.31568[0m[0m | time: 945.363s
[2K
| Adam | epoch: 007 | loss: 0.31568 - acc: 0.8753 -- iter: 2496/2867
[A[ATraining Step: 619  | total loss: [1m[32m0.31374[0m[0m | time: 956.876s
[2K
| Adam | epoch: 007 | loss: 0.31374 - acc: 0.8753 -- iter: 2528/2867
[A[ATraining Step: 620  | total loss: [1m[32m0.30854[0m[0m | time: 968.482s
[2K
| Adam | epoch: 007 | loss: 0.30854 - acc: 0.8784 -- iter: 2560/2867
[A[ATraining Step: 621  | total loss: [1m[32m0.31031[0m[0m | time: 980.111s
[2K
| Adam | epoch: 007 | loss: 0.31031 - acc: 0.8749 -- iter: 2592/2867
[A[ATraining Step: 622  | total loss: [1m[32m0.30155[0m[0m | time: 991.823s
[2K
| Adam | epoch: 007 | loss: 0.30155 - acc: 0.8749 -- iter: 2624/2867
[A[ATraining Step: 623  | total loss: [1m[32m0.29599[0m[0m | time: 1003.642s
[2K
| Adam | epoch: 007 | loss: 0.29599 - acc: 0.8749 -- iter: 2656/2867
[A[ATraining Step: 624  | total loss: [1m[32m0.28370[0m[0m | time: 1015.245s
[2K
| Adam | epoch: 007 | loss: 0.28370 - acc: 0.8812 -- iter: 2688/2867
[A[ATraining Step: 625  | total loss: [1m[32m0.27071[0m[0m | time: 1026.983s
[2K
| Adam | epoch: 007 | loss: 0.27071 - acc: 0.8931 -- iter: 2720/2867
[A[ATraining Step: 626  | total loss: [1m[32m0.26191[0m[0m | time: 1038.356s
[2K
| Adam | epoch: 007 | loss: 0.26191 - acc: 0.8944 -- iter: 2752/2867
[A[ATraining Step: 627  | total loss: [1m[32m0.29967[0m[0m | time: 1050.055s
[2K
| Adam | epoch: 007 | loss: 0.29967 - acc: 0.8799 -- iter: 2784/2867
[A[ATraining Step: 628  | total loss: [1m[32m0.29368[0m[0m | time: 1061.490s
[2K
| Adam | epoch: 007 | loss: 0.29368 - acc: 0.8857 -- iter: 2816/2867
[A[ATraining Step: 629  | total loss: [1m[32m0.28361[0m[0m | time: 1073.077s
[2K
| Adam | epoch: 007 | loss: 0.28361 - acc: 0.8846 -- iter: 2848/2867
[A[ATraining Step: 630  | total loss: [1m[32m0.27451[0m[0m | time: 1146.848s
[2K
| Adam | epoch: 007 | loss: 0.27451 - acc: 0.8868 | val_loss: 0.62185 - val_acc: 0.7246 -- iter: 2867/2867
--
Training Step: 631  | total loss: [1m[32m0.26121[0m[0m | time: 8.029s
[2K
| Adam | epoch: 008 | loss: 0.26121 - acc: 0.8887 -- iter: 0032/2867
[A[ATraining Step: 632  | total loss: [1m[32m0.26127[0m[0m | time: 19.246s
[2K
| Adam | epoch: 008 | loss: 0.26127 - acc: 0.8874 -- iter: 0064/2867
[A[ATraining Step: 633  | total loss: [1m[32m0.26393[0m[0m | time: 31.227s
[2K
| Adam | epoch: 008 | loss: 0.26393 - acc: 0.8893 -- iter: 0096/2867
[A[ATraining Step: 634  | total loss: [1m[32m0.25313[0m[0m | time: 43.009s
[2K
| Adam | epoch: 008 | loss: 0.25313 - acc: 0.8941 -- iter: 0128/2867
[A[ATraining Step: 635  | total loss: [1m[32m0.26339[0m[0m | time: 55.101s
[2K
| Adam | epoch: 008 | loss: 0.26339 - acc: 0.8953 -- iter: 0160/2867
[A[ATraining Step: 636  | total loss: [1m[32m0.25635[0m[0m | time: 63.656s
[2K
| Adam | epoch: 008 | loss: 0.25635 - acc: 0.8964 -- iter: 0192/2867
[A[ATraining Step: 637  | total loss: [1m[32m0.23779[0m[0m | time: 71.129s
[2K
| Adam | epoch: 008 | loss: 0.23779 - acc: 0.9068 -- iter: 0224/2867
[A[ATraining Step: 638  | total loss: [1m[32m0.21976[0m[0m | time: 82.851s
[2K
| Adam | epoch: 008 | loss: 0.21976 - acc: 0.9161 -- iter: 0256/2867
[A[ATraining Step: 639  | total loss: [1m[32m0.21396[0m[0m | time: 94.726s
[2K
| Adam | epoch: 008 | loss: 0.21396 - acc: 0.9213 -- iter: 0288/2867
[A[ATraining Step: 640  | total loss: [1m[32m0.23100[0m[0m | time: 106.599s
[2K
| Adam | epoch: 008 | loss: 0.23100 - acc: 0.9136 -- iter: 0320/2867
[A[ATraining Step: 641  | total loss: [1m[32m0.25036[0m[0m | time: 118.598s
[2K
| Adam | epoch: 008 | loss: 0.25036 - acc: 0.9066 -- iter: 0352/2867
[A[ATraining Step: 642  | total loss: [1m[32m0.23799[0m[0m | time: 130.731s
[2K
| Adam | epoch: 008 | loss: 0.23799 - acc: 0.9128 -- iter: 0384/2867
[A[ATraining Step: 643  | total loss: [1m[32m0.24228[0m[0m | time: 142.454s
[2K
| Adam | epoch: 008 | loss: 0.24228 - acc: 0.9059 -- iter: 0416/2867
[A[ATraining Step: 644  | total loss: [1m[32m0.24097[0m[0m | time: 154.570s
[2K
| Adam | epoch: 008 | loss: 0.24097 - acc: 0.9091 -- iter: 0448/2867
[A[ATraining Step: 645  | total loss: [1m[32m0.22969[0m[0m | time: 166.385s
[2K
| Adam | epoch: 008 | loss: 0.22969 - acc: 0.9119 -- iter: 0480/2867
[A[ATraining Step: 646  | total loss: [1m[32m0.22147[0m[0m | time: 177.911s
[2K
| Adam | epoch: 008 | loss: 0.22147 - acc: 0.9176 -- iter: 0512/2867
[A[ATraining Step: 647  | total loss: [1m[32m0.23703[0m[0m | time: 189.871s
[2K
| Adam | epoch: 008 | loss: 0.23703 - acc: 0.9008 -- iter: 0544/2867
[A[ATraining Step: 648  | total loss: [1m[32m0.23455[0m[0m | time: 201.822s
[2K
| Adam | epoch: 008 | loss: 0.23455 - acc: 0.9014 -- iter: 0576/2867
[A[ATraining Step: 649  | total loss: [1m[32m0.22736[0m[0m | time: 213.318s
[2K
| Adam | epoch: 008 | loss: 0.22736 - acc: 0.9050 -- iter: 0608/2867
[A[ATraining Step: 650  | total loss: [1m[32m0.22197[0m[0m | time: 224.983s
[2K
| Adam | epoch: 008 | loss: 0.22197 - acc: 0.9082 -- iter: 0640/2867
[A[ATraining Step: 651  | total loss: [1m[32m0.21337[0m[0m | time: 236.255s
[2K
| Adam | epoch: 008 | loss: 0.21337 - acc: 0.9143 -- iter: 0672/2867
[A[ATraining Step: 652  | total loss: [1m[32m0.22973[0m[0m | time: 248.094s
[2K
| Adam | epoch: 008 | loss: 0.22973 - acc: 0.9104 -- iter: 0704/2867
[A[ATraining Step: 653  | total loss: [1m[32m0.22072[0m[0m | time: 260.117s
[2K
| Adam | epoch: 008 | loss: 0.22072 - acc: 0.9131 -- iter: 0736/2867
[A[ATraining Step: 654  | total loss: [1m[32m0.21180[0m[0m | time: 271.986s
[2K
| Adam | epoch: 008 | loss: 0.21180 - acc: 0.9186 -- iter: 0768/2867
[A[ATraining Step: 655  | total loss: [1m[32m0.25008[0m[0m | time: 283.831s
[2K
| Adam | epoch: 008 | loss: 0.25008 - acc: 0.9018 -- iter: 0800/2867
[A[ATraining Step: 656  | total loss: [1m[32m0.24779[0m[0m | time: 295.377s
[2K
| Adam | epoch: 008 | loss: 0.24779 - acc: 0.9022 -- iter: 0832/2867
[A[ATraining Step: 657  | total loss: [1m[32m0.27151[0m[0m | time: 306.091s
[2K
| Adam | epoch: 008 | loss: 0.27151 - acc: 0.8964 -- iter: 0864/2867
[A[ATraining Step: 658  | total loss: [1m[32m0.27217[0m[0m | time: 317.604s
[2K
| Adam | epoch: 008 | loss: 0.27217 - acc: 0.8974 -- iter: 0896/2867
[A[ATraining Step: 659  | total loss: [1m[32m0.26745[0m[0m | time: 329.169s
[2K
| Adam | epoch: 008 | loss: 0.26745 - acc: 0.9045 -- iter: 0928/2867
[A[ATraining Step: 660  | total loss: [1m[32m0.28508[0m[0m | time: 341.158s
[2K
| Adam | epoch: 008 | loss: 0.28508 - acc: 0.8953 -- iter: 0960/2867
[A[ATraining Step: 661  | total loss: [1m[32m0.27680[0m[0m | time: 352.913s
[2K
| Adam | epoch: 008 | loss: 0.27680 - acc: 0.8995 -- iter: 0992/2867
[A[ATraining Step: 662  | total loss: [1m[32m0.27724[0m[0m | time: 364.312s
[2K
| Adam | epoch: 008 | loss: 0.27724 - acc: 0.9002 -- iter: 1024/2867
[A[ATraining Step: 663  | total loss: [1m[32m0.27424[0m[0m | time: 375.998s
[2K
| Adam | epoch: 008 | loss: 0.27424 - acc: 0.9008 -- iter: 1056/2867
[A[ATraining Step: 664  | total loss: [1m[32m0.28950[0m[0m | time: 387.461s
[2K
| Adam | epoch: 008 | loss: 0.28950 - acc: 0.8888 -- iter: 1088/2867
[A[ATraining Step: 665  | total loss: [1m[32m0.29011[0m[0m | time: 398.635s
[2K
| Adam | epoch: 008 | loss: 0.29011 - acc: 0.8906 -- iter: 1120/2867
[A[ATraining Step: 666  | total loss: [1m[32m0.28538[0m[0m | time: 410.030s
[2K
| Adam | epoch: 008 | loss: 0.28538 - acc: 0.8890 -- iter: 1152/2867
[A[ATraining Step: 667  | total loss: [1m[32m0.28140[0m[0m | time: 421.425s
[2K
| Adam | epoch: 008 | loss: 0.28140 - acc: 0.8908 -- iter: 1184/2867
[A[ATraining Step: 668  | total loss: [1m[32m0.27835[0m[0m | time: 432.887s
[2K
| Adam | epoch: 008 | loss: 0.27835 - acc: 0.8892 -- iter: 1216/2867
[A[ATraining Step: 669  | total loss: [1m[32m0.27767[0m[0m | time: 444.547s
[2K
| Adam | epoch: 008 | loss: 0.27767 - acc: 0.8909 -- iter: 1248/2867
[A[ATraining Step: 670  | total loss: [1m[32m0.28334[0m[0m | time: 456.380s
[2K
| Adam | epoch: 008 | loss: 0.28334 - acc: 0.8893 -- iter: 1280/2867
[A[ATraining Step: 671  | total loss: [1m[32m0.28029[0m[0m | time: 468.195s
[2K
| Adam | epoch: 008 | loss: 0.28029 - acc: 0.8879 -- iter: 1312/2867
[A[ATraining Step: 672  | total loss: [1m[32m0.27600[0m[0m | time: 479.382s
[2K
| Adam | epoch: 008 | loss: 0.27600 - acc: 0.8897 -- iter: 1344/2867
[A[ATraining Step: 673  | total loss: [1m[32m0.27399[0m[0m | time: 491.779s
[2K
| Adam | epoch: 008 | loss: 0.27399 - acc: 0.8882 -- iter: 1376/2867
[A[ATraining Step: 674  | total loss: [1m[32m0.28486[0m[0m | time: 503.787s
[2K
| Adam | epoch: 008 | loss: 0.28486 - acc: 0.8807 -- iter: 1408/2867
[A[ATraining Step: 675  | total loss: [1m[32m0.30313[0m[0m | time: 512.872s
[2K
| Adam | epoch: 008 | loss: 0.30313 - acc: 0.8738 -- iter: 1440/2867
[A[ATraining Step: 676  | total loss: [1m[32m0.31506[0m[0m | time: 520.946s
[2K
| Adam | epoch: 008 | loss: 0.31506 - acc: 0.8708 -- iter: 1472/2867
[A[ATraining Step: 677  | total loss: [1m[32m0.30309[0m[0m | time: 529.159s
[2K
| Adam | epoch: 008 | loss: 0.30309 - acc: 0.8775 -- iter: 1504/2867
[A[ATraining Step: 678  | total loss: [1m[32m0.29351[0m[0m | time: 540.295s
[2K
| Adam | epoch: 008 | loss: 0.29351 - acc: 0.8835 -- iter: 1536/2867
[A[ATraining Step: 679  | total loss: [1m[32m0.30956[0m[0m | time: 551.883s
[2K
| Adam | epoch: 008 | loss: 0.30956 - acc: 0.8795 -- iter: 1568/2867
[A[ATraining Step: 680  | total loss: [1m[32m0.29784[0m[0m | time: 563.157s
[2K
| Adam | epoch: 008 | loss: 0.29784 - acc: 0.8853 -- iter: 1600/2867
[A[ATraining Step: 681  | total loss: [1m[32m0.29990[0m[0m | time: 574.668s
[2K
| Adam | epoch: 008 | loss: 0.29990 - acc: 0.8843 -- iter: 1632/2867
[A[ATraining Step: 682  | total loss: [1m[32m0.28434[0m[0m | time: 586.419s
[2K
| Adam | epoch: 008 | loss: 0.28434 - acc: 0.8927 -- iter: 1664/2867
[A[ATraining Step: 683  | total loss: [1m[32m0.27403[0m[0m | time: 598.150s
[2K
| Adam | epoch: 008 | loss: 0.27403 - acc: 0.8972 -- iter: 1696/2867
[A[ATraining Step: 684  | total loss: [1m[32m0.27278[0m[0m | time: 609.318s
[2K
| Adam | epoch: 008 | loss: 0.27278 - acc: 0.8950 -- iter: 1728/2867
[A[ATraining Step: 685  | total loss: [1m[32m0.27578[0m[0m | time: 621.149s
[2K
| Adam | epoch: 008 | loss: 0.27578 - acc: 0.8930 -- iter: 1760/2867
[A[ATraining Step: 686  | total loss: [1m[32m0.29462[0m[0m | time: 633.155s
[2K
| Adam | epoch: 008 | loss: 0.29462 - acc: 0.8787 -- iter: 1792/2867
[A[ATraining Step: 687  | total loss: [1m[32m0.32650[0m[0m | time: 644.942s
[2K
| Adam | epoch: 008 | loss: 0.32650 - acc: 0.8721 -- iter: 1824/2867
[A[ATraining Step: 688  | total loss: [1m[32m0.33385[0m[0m | time: 656.490s
[2K
| Adam | epoch: 008 | loss: 0.33385 - acc: 0.8692 -- iter: 1856/2867
[A[ATraining Step: 689  | total loss: [1m[32m0.33450[0m[0m | time: 668.653s
[2K
| Adam | epoch: 008 | loss: 0.33450 - acc: 0.8729 -- iter: 1888/2867
[A[ATraining Step: 690  | total loss: [1m[32m0.35811[0m[0m | time: 679.924s
[2K
| Adam | epoch: 008 | loss: 0.35811 - acc: 0.8606 -- iter: 1920/2867
[A[ATraining Step: 691  | total loss: [1m[32m0.34997[0m[0m | time: 691.681s
[2K
| Adam | epoch: 008 | loss: 0.34997 - acc: 0.8621 -- iter: 1952/2867
[A[ATraining Step: 692  | total loss: [1m[32m0.33814[0m[0m | time: 703.464s
[2K
| Adam | epoch: 008 | loss: 0.33814 - acc: 0.8665 -- iter: 1984/2867
[A[ATraining Step: 693  | total loss: [1m[32m0.34307[0m[0m | time: 715.038s
[2K
| Adam | epoch: 008 | loss: 0.34307 - acc: 0.8642 -- iter: 2016/2867
[A[ATraining Step: 694  | total loss: [1m[32m0.32389[0m[0m | time: 727.093s
[2K
| Adam | epoch: 008 | loss: 0.32389 - acc: 0.8778 -- iter: 2048/2867
[A[ATraining Step: 695  | total loss: [1m[32m0.31639[0m[0m | time: 738.539s
[2K
| Adam | epoch: 008 | loss: 0.31639 - acc: 0.8744 -- iter: 2080/2867
[A[ATraining Step: 696  | total loss: [1m[32m0.33756[0m[0m | time: 749.690s
[2K
| Adam | epoch: 008 | loss: 0.33756 - acc: 0.8651 -- iter: 2112/2867
[A[ATraining Step: 697  | total loss: [1m[32m0.32094[0m[0m | time: 761.317s
[2K
| Adam | epoch: 008 | loss: 0.32094 - acc: 0.8754 -- iter: 2144/2867
[A[ATraining Step: 698  | total loss: [1m[32m0.31041[0m[0m | time: 773.073s
[2K
| Adam | epoch: 008 | loss: 0.31041 - acc: 0.8817 -- iter: 2176/2867
[A[ATraining Step: 699  | total loss: [1m[32m0.29928[0m[0m | time: 784.980s
[2K
| Adam | epoch: 008 | loss: 0.29928 - acc: 0.8841 -- iter: 2208/2867
[A[ATraining Step: 700  | total loss: [1m[32m0.29231[0m[0m | time: 796.984s
[2K
| Adam | epoch: 008 | loss: 0.29231 - acc: 0.8895 -- iter: 2240/2867
[A[ATraining Step: 701  | total loss: [1m[32m0.29049[0m[0m | time: 808.443s
[2K
| Adam | epoch: 008 | loss: 0.29049 - acc: 0.8880 -- iter: 2272/2867
[A[ATraining Step: 702  | total loss: [1m[32m0.28970[0m[0m | time: 820.222s
[2K
| Adam | epoch: 008 | loss: 0.28970 - acc: 0.8836 -- iter: 2304/2867
[A[ATraining Step: 703  | total loss: [1m[32m0.27979[0m[0m | time: 831.415s
[2K
| Adam | epoch: 008 | loss: 0.27979 - acc: 0.8921 -- iter: 2336/2867
[A[ATraining Step: 704  | total loss: [1m[32m0.27004[0m[0m | time: 842.785s
[2K
| Adam | epoch: 008 | loss: 0.27004 - acc: 0.8966 -- iter: 2368/2867
[A[ATraining Step: 705  | total loss: [1m[32m0.25639[0m[0m | time: 854.243s
[2K
| Adam | epoch: 008 | loss: 0.25639 - acc: 0.9070 -- iter: 2400/2867
[A[ATraining Step: 706  | total loss: [1m[32m0.25102[0m[0m | time: 865.954s
[2K
| Adam | epoch: 008 | loss: 0.25102 - acc: 0.9132 -- iter: 2432/2867
[A[ATraining Step: 707  | total loss: [1m[32m0.24618[0m[0m | time: 877.866s
[2K
| Adam | epoch: 008 | loss: 0.24618 - acc: 0.9125 -- iter: 2464/2867
[A[ATraining Step: 708  | total loss: [1m[32m0.24696[0m[0m | time: 889.774s
[2K
| Adam | epoch: 008 | loss: 0.24696 - acc: 0.9087 -- iter: 2496/2867
[A[ATraining Step: 709  | total loss: [1m[32m0.23824[0m[0m | time: 901.400s
[2K
| Adam | epoch: 008 | loss: 0.23824 - acc: 0.9116 -- iter: 2528/2867
[A[ATraining Step: 710  | total loss: [1m[32m0.23073[0m[0m | time: 912.945s
[2K
| Adam | epoch: 008 | loss: 0.23073 - acc: 0.9173 -- iter: 2560/2867
[A[ATraining Step: 711  | total loss: [1m[32m0.23433[0m[0m | time: 924.855s
[2K
| Adam | epoch: 008 | loss: 0.23433 - acc: 0.9162 -- iter: 2592/2867
[A[ATraining Step: 712  | total loss: [1m[32m0.23890[0m[0m | time: 936.969s
[2K
| Adam | epoch: 008 | loss: 0.23890 - acc: 0.9183 -- iter: 2624/2867
[A[ATraining Step: 713  | total loss: [1m[32m0.23159[0m[0m | time: 948.856s
[2K
| Adam | epoch: 008 | loss: 0.23159 - acc: 0.9171 -- iter: 2656/2867
[A[ATraining Step: 714  | total loss: [1m[32m0.21586[0m[0m | time: 960.510s
[2K
| Adam | epoch: 008 | loss: 0.21586 - acc: 0.9223 -- iter: 2688/2867
[A[ATraining Step: 715  | total loss: [1m[32m0.22070[0m[0m | time: 972.132s
[2K
| Adam | epoch: 008 | loss: 0.22070 - acc: 0.9176 -- iter: 2720/2867
[A[ATraining Step: 716  | total loss: [1m[32m0.22110[0m[0m | time: 984.265s
[2K
| Adam | epoch: 008 | loss: 0.22110 - acc: 0.9196 -- iter: 2752/2867
[A[ATraining Step: 717  | total loss: [1m[32m0.21303[0m[0m | time: 995.901s
[2K
| Adam | epoch: 008 | loss: 0.21303 - acc: 0.9213 -- iter: 2784/2867
[A[ATraining Step: 718  | total loss: [1m[32m0.21350[0m[0m | time: 1008.690s
[2K
| Adam | epoch: 008 | loss: 0.21350 - acc: 0.9198 -- iter: 2816/2867
[A[ATraining Step: 719  | total loss: [1m[32m0.20987[0m[0m | time: 1021.430s
[2K
| Adam | epoch: 008 | loss: 0.20987 - acc: 0.9185 -- iter: 2848/2867
[A[ATraining Step: 720  | total loss: [1m[32m0.19925[0m[0m | time: 1082.085s
[2K
| Adam | epoch: 008 | loss: 0.19925 - acc: 0.9266 | val_loss: 0.75058 - val_acc: 0.7681 -- iter: 2867/2867
--
Training Step: 721  | total loss: [1m[32m0.19003[0m[0m | time: 12.460s
[2K
| Adam | epoch: 009 | loss: 0.19003 - acc: 0.9308 -- iter: 0032/2867
[A[ATraining Step: 722  | total loss: [1m[32m0.19238[0m[0m | time: 24.957s
[2K
| Adam | epoch: 009 | loss: 0.19238 - acc: 0.9284 -- iter: 0064/2867
[A[ATraining Step: 723  | total loss: [1m[32m0.19048[0m[0m | time: 42.984s
[2K
| Adam | epoch: 009 | loss: 0.19048 - acc: 0.9262 -- iter: 0096/2867
[A[ATraining Step: 724  | total loss: [1m[32m0.20407[0m[0m | time: 65.248s
[2K
| Adam | epoch: 009 | loss: 0.20407 - acc: 0.9179 -- iter: 0128/2867
[A[ATraining Step: 725  | total loss: [1m[32m0.19421[0m[0m | time: 83.745s
[2K
| Adam | epoch: 009 | loss: 0.19421 - acc: 0.9230 -- iter: 0160/2867
[A[ATraining Step: 726  | total loss: [1m[32m0.19360[0m[0m | time: 101.387s
[2K
| Adam | epoch: 009 | loss: 0.19360 - acc: 0.9276 -- iter: 0192/2867
[A[ATraining Step: 727  | total loss: [1m[32m0.19363[0m[0m | time: 113.022s
[2K
| Adam | epoch: 009 | loss: 0.19363 - acc: 0.9255 -- iter: 0224/2867
[A[ATraining Step: 728  | total loss: [1m[32m0.19814[0m[0m | time: 126.104s
[2K
| Adam | epoch: 009 | loss: 0.19814 - acc: 0.9224 -- iter: 0256/2867
[A[ATraining Step: 729  | total loss: [1m[32m0.18738[0m[0m | time: 144.398s
[2K
| Adam | epoch: 009 | loss: 0.18738 - acc: 0.9249 -- iter: 0288/2867
[A[ATraining Step: 730  | total loss: [1m[32m0.20052[0m[0m | time: 157.402s
[2K
| Adam | epoch: 009 | loss: 0.20052 - acc: 0.9199 -- iter: 0320/2867
[A[ATraining Step: 731  | total loss: [1m[32m0.20038[0m[0m | time: 170.172s
[2K
| Adam | epoch: 009 | loss: 0.20038 - acc: 0.9185 -- iter: 0352/2867
[A[ATraining Step: 732  | total loss: [1m[32m0.21018[0m[0m | time: 182.098s
[2K
| Adam | epoch: 009 | loss: 0.21018 - acc: 0.9110 -- iter: 0384/2867
[A[ATraining Step: 733  | total loss: [1m[32m0.20460[0m[0m | time: 194.073s
[2K
| Adam | epoch: 009 | loss: 0.20460 - acc: 0.9106 -- iter: 0416/2867
[A[ATraining Step: 734  | total loss: [1m[32m0.22509[0m[0m | time: 209.008s
[2K
| Adam | epoch: 009 | loss: 0.22509 - acc: 0.9070 -- iter: 0448/2867
[A[ATraining Step: 735  | total loss: [1m[32m0.21201[0m[0m | time: 227.619s
[2K
| Adam | epoch: 009 | loss: 0.21201 - acc: 0.9132 -- iter: 0480/2867
[A[ATraining Step: 736  | total loss: [1m[32m0.20516[0m[0m | time: 245.765s
[2K
| Adam | epoch: 009 | loss: 0.20516 - acc: 0.9125 -- iter: 0512/2867
[A[ATraining Step: 737  | total loss: [1m[32m0.20795[0m[0m | time: 270.318s
[2K
| Adam | epoch: 009 | loss: 0.20795 - acc: 0.9150 -- iter: 0544/2867
[A[ATraining Step: 738  | total loss: [1m[32m0.21229[0m[0m | time: 294.508s
[2K
| Adam | epoch: 009 | loss: 0.21229 - acc: 0.9110 -- iter: 0576/2867
[A[ATraining Step: 739  | total loss: [1m[32m0.20092[0m[0m | time: 312.887s
[2K
| Adam | epoch: 009 | loss: 0.20092 - acc: 0.9199 -- iter: 0608/2867
[A[ATraining Step: 740  | total loss: [1m[32m0.20168[0m[0m | time: 331.116s
[2K
| Adam | epoch: 009 | loss: 0.20168 - acc: 0.9185 -- iter: 0640/2867
[A[ATraining Step: 741  | total loss: [1m[32m0.20944[0m[0m | time: 343.136s
[2K
| Adam | epoch: 009 | loss: 0.20944 - acc: 0.9142 -- iter: 0672/2867
[A[ATraining Step: 742  | total loss: [1m[32m0.20262[0m[0m | time: 354.757s
[2K
| Adam | epoch: 009 | loss: 0.20262 - acc: 0.9165 -- iter: 0704/2867
[A[ATraining Step: 743  | total loss: [1m[32m0.19535[0m[0m | time: 373.179s
[2K
| Adam | epoch: 009 | loss: 0.19535 - acc: 0.9155 -- iter: 0736/2867
[A[ATraining Step: 744  | total loss: [1m[32m0.19504[0m[0m | time: 390.406s
[2K
| Adam | epoch: 009 | loss: 0.19504 - acc: 0.9177 -- iter: 0768/2867
[A[ATraining Step: 745  | total loss: [1m[32m0.20369[0m[0m | time: 408.070s
[2K
| Adam | epoch: 009 | loss: 0.20369 - acc: 0.9134 -- iter: 0800/2867
[A[ATraining Step: 746  | total loss: [1m[32m0.20042[0m[0m | time: 425.752s
[2K
| Adam | epoch: 009 | loss: 0.20042 - acc: 0.9127 -- iter: 0832/2867
[A[ATraining Step: 747  | total loss: [1m[32m0.18641[0m[0m | time: 444.018s
[2K
| Adam | epoch: 009 | loss: 0.18641 - acc: 0.9214 -- iter: 0864/2867
[A[ATraining Step: 748  | total loss: [1m[32m0.18898[0m[0m | time: 462.113s
[2K
| Adam | epoch: 009 | loss: 0.18898 - acc: 0.9230 -- iter: 0896/2867
[A[ATraining Step: 749  | total loss: [1m[32m0.18846[0m[0m | time: 477.128s
[2K
| Adam | epoch: 009 | loss: 0.18846 - acc: 0.9182 -- iter: 0928/2867
[A[ATraining Step: 750  | total loss: [1m[32m0.18571[0m[0m | time: 489.425s
[2K
| Adam | epoch: 009 | loss: 0.18571 - acc: 0.9202 -- iter: 0960/2867
[A[ATraining Step: 751  | total loss: [1m[32m0.19085[0m[0m | time: 504.997s
[2K
| Adam | epoch: 009 | loss: 0.19085 - acc: 0.9219 -- iter: 0992/2867
[A[ATraining Step: 752  | total loss: [1m[32m0.18636[0m[0m | time: 521.851s
[2K
| Adam | epoch: 009 | loss: 0.18636 - acc: 0.9266 -- iter: 1024/2867
[A[ATraining Step: 753  | total loss: [1m[32m0.21961[0m[0m | time: 541.348s
[2K
| Adam | epoch: 009 | loss: 0.21961 - acc: 0.9120 -- iter: 1056/2867
[A[ATraining Step: 754  | total loss: [1m[32m0.22622[0m[0m | time: 559.502s
[2K
| Adam | epoch: 009 | loss: 0.22622 - acc: 0.9115 -- iter: 1088/2867
[A[ATraining Step: 755  | total loss: [1m[32m0.25800[0m[0m | time: 578.252s
[2K
| Adam | epoch: 009 | loss: 0.25800 - acc: 0.9016 -- iter: 1120/2867
[A[ATraining Step: 756  | total loss: [1m[32m0.24597[0m[0m | time: 596.631s
[2K
| Adam | epoch: 009 | loss: 0.24597 - acc: 0.9052 -- iter: 1152/2867
[A[ATraining Step: 757  | total loss: [1m[32m0.24355[0m[0m | time: 610.634s
[2K
| Adam | epoch: 009 | loss: 0.24355 - acc: 0.9053 -- iter: 1184/2867
[A[ATraining Step: 758  | total loss: [1m[32m0.23687[0m[0m | time: 618.717s
[2K
| Adam | epoch: 009 | loss: 0.23687 - acc: 0.9054 -- iter: 1216/2867
[A[ATraining Step: 759  | total loss: [1m[32m0.24724[0m[0m | time: 627.681s
[2K
| Adam | epoch: 009 | loss: 0.24724 - acc: 0.8992 -- iter: 1248/2867
[A[ATraining Step: 760  | total loss: [1m[32m0.25471[0m[0m | time: 643.208s
[2K
| Adam | epoch: 009 | loss: 0.25471 - acc: 0.8937 -- iter: 1280/2867
[A[ATraining Step: 761  | total loss: [1m[32m0.27236[0m[0m | time: 661.623s
[2K
| Adam | epoch: 009 | loss: 0.27236 - acc: 0.8824 -- iter: 1312/2867
[A[ATraining Step: 762  | total loss: [1m[32m0.27503[0m[0m | time: 679.334s
[2K
| Adam | epoch: 009 | loss: 0.27503 - acc: 0.8879 -- iter: 1344/2867
[A[ATraining Step: 763  | total loss: [1m[32m0.29111[0m[0m | time: 694.537s
[2K
| Adam | epoch: 009 | loss: 0.29111 - acc: 0.8741 -- iter: 1376/2867
[A[ATraining Step: 764  | total loss: [1m[32m0.27875[0m[0m | time: 710.570s
[2K
| Adam | epoch: 009 | loss: 0.27875 - acc: 0.8836 -- iter: 1408/2867
[A[ATraining Step: 765  | total loss: [1m[32m0.28710[0m[0m | time: 731.756s
[2K
| Adam | epoch: 009 | loss: 0.28710 - acc: 0.8796 -- iter: 1440/2867
[A[ATraining Step: 766  | total loss: [1m[32m0.29396[0m[0m | time: 748.340s
[2K
| Adam | epoch: 009 | loss: 0.29396 - acc: 0.8823 -- iter: 1472/2867
[A[ATraining Step: 767  | total loss: [1m[32m0.31524[0m[0m | time: 760.546s
[2K
| Adam | epoch: 009 | loss: 0.31524 - acc: 0.8784 -- iter: 1504/2867
[A[ATraining Step: 768  | total loss: [1m[32m0.31207[0m[0m | time: 772.728s
[2K
| Adam | epoch: 009 | loss: 0.31207 - acc: 0.8781 -- iter: 1536/2867
[A[ATraining Step: 769  | total loss: [1m[32m0.30579[0m[0m | time: 785.875s
[2K
| Adam | epoch: 009 | loss: 0.30579 - acc: 0.8809 -- iter: 1568/2867
[A[ATraining Step: 770  | total loss: [1m[32m0.29571[0m[0m | time: 804.726s
[2K
| Adam | epoch: 009 | loss: 0.29571 - acc: 0.8866 -- iter: 1600/2867
[A[ATraining Step: 771  | total loss: [1m[32m0.30660[0m[0m | time: 823.497s
[2K
| Adam | epoch: 009 | loss: 0.30660 - acc: 0.8792 -- iter: 1632/2867
[A[ATraining Step: 772  | total loss: [1m[32m0.29678[0m[0m | time: 842.073s
[2K
| Adam | epoch: 009 | loss: 0.29678 - acc: 0.8819 -- iter: 1664/2867
[A[ATraining Step: 773  | total loss: [1m[32m0.30404[0m[0m | time: 859.565s
[2K
| Adam | epoch: 009 | loss: 0.30404 - acc: 0.8843 -- iter: 1696/2867
[A[ATraining Step: 774  | total loss: [1m[32m0.29047[0m[0m | time: 883.194s
[2K
| Adam | epoch: 009 | loss: 0.29047 - acc: 0.8865 -- iter: 1728/2867
[A[ATraining Step: 775  | total loss: [1m[32m0.28150[0m[0m | time: 904.163s
[2K
| Adam | epoch: 009 | loss: 0.28150 - acc: 0.8947 -- iter: 1760/2867
[A[ATraining Step: 776  | total loss: [1m[32m0.27323[0m[0m | time: 916.715s
[2K
| Adam | epoch: 009 | loss: 0.27323 - acc: 0.8959 -- iter: 1792/2867
[A[ATraining Step: 777  | total loss: [1m[32m0.26512[0m[0m | time: 928.335s
[2K
| Adam | epoch: 009 | loss: 0.26512 - acc: 0.9000 -- iter: 1824/2867
[A[ATraining Step: 778  | total loss: [1m[32m0.26159[0m[0m | time: 944.646s
[2K
| Adam | epoch: 009 | loss: 0.26159 - acc: 0.8975 -- iter: 1856/2867
[A[ATraining Step: 779  | total loss: [1m[32m0.28028[0m[0m | time: 963.193s
[2K
| Adam | epoch: 009 | loss: 0.28028 - acc: 0.8859 -- iter: 1888/2867
[A[ATraining Step: 780  | total loss: [1m[32m0.26972[0m[0m | time: 981.295s
[2K
| Adam | epoch: 009 | loss: 0.26972 - acc: 0.8911 -- iter: 1920/2867
[A[ATraining Step: 781  | total loss: [1m[32m0.26540[0m[0m | time: 1021.877s
[2K
| Adam | epoch: 009 | loss: 0.26540 - acc: 0.8895 -- iter: 1952/2867
[A[ATraining Step: 782  | total loss: [1m[32m0.28631[0m[0m | time: 1038.993s
[2K
| Adam | epoch: 009 | loss: 0.28631 - acc: 0.8849 -- iter: 1984/2867
[A[ATraining Step: 783  | total loss: [1m[32m0.28024[0m[0m | time: 1056.251s
[2K
| Adam | epoch: 009 | loss: 0.28024 - acc: 0.8839 -- iter: 2016/2867
[A[ATraining Step: 784  | total loss: [1m[32m0.30719[0m[0m | time: 1072.485s
[2K
| Adam | epoch: 009 | loss: 0.30719 - acc: 0.8736 -- iter: 2048/2867
[A[ATraining Step: 785  | total loss: [1m[32m0.29640[0m[0m | time: 1084.746s
[2K
| Adam | epoch: 009 | loss: 0.29640 - acc: 0.8800 -- iter: 2080/2867
[A[ATraining Step: 786  | total loss: [1m[32m0.28296[0m[0m | time: 1099.290s
[2K
| Adam | epoch: 009 | loss: 0.28296 - acc: 0.8858 -- iter: 2112/2867
[A[ATraining Step: 787  | total loss: [1m[32m0.36339[0m[0m | time: 1120.119s
[2K
| Adam | epoch: 009 | loss: 0.36339 - acc: 0.8628 -- iter: 2144/2867
[A[ATraining Step: 788  | total loss: [1m[32m0.34429[0m[0m | time: 1138.332s
[2K
| Adam | epoch: 009 | loss: 0.34429 - acc: 0.8734 -- iter: 2176/2867
[A[ATraining Step: 789  | total loss: [1m[32m0.34541[0m[0m | time: 1155.931s
[2K
| Adam | epoch: 009 | loss: 0.34541 - acc: 0.8704 -- iter: 2208/2867
[A[ATraining Step: 790  | total loss: [1m[32m0.33516[0m[0m | time: 1173.963s
[2K
| Adam | epoch: 009 | loss: 0.33516 - acc: 0.8771 -- iter: 2240/2867
[A[ATraining Step: 791  | total loss: [1m[32m0.32821[0m[0m | time: 1194.511s
[2K
| Adam | epoch: 009 | loss: 0.32821 - acc: 0.8769 -- iter: 2272/2867
[A[ATraining Step: 792  | total loss: [1m[32m0.32928[0m[0m | time: 1210.936s
[2K
| Adam | epoch: 009 | loss: 0.32928 - acc: 0.8705 -- iter: 2304/2867
[A[ATraining Step: 793  | total loss: [1m[32m0.32215[0m[0m | time: 1223.088s
[2K
| Adam | epoch: 009 | loss: 0.32215 - acc: 0.8741 -- iter: 2336/2867
[A[ATraining Step: 794  | total loss: [1m[32m0.30373[0m[0m | time: 1237.336s
[2K
| Adam | epoch: 009 | loss: 0.30373 - acc: 0.8867 -- iter: 2368/2867
[A[ATraining Step: 795  | total loss: [1m[32m0.28878[0m[0m | time: 1254.672s
[2K
| Adam | epoch: 009 | loss: 0.28878 - acc: 0.8917 -- iter: 2400/2867
[A[ATraining Step: 796  | total loss: [1m[32m0.28169[0m[0m | time: 1272.682s
[2K
| Adam | epoch: 009 | loss: 0.28169 - acc: 0.8901 -- iter: 2432/2867
[A[ATraining Step: 797  | total loss: [1m[32m0.27172[0m[0m | time: 1290.696s
[2K
| Adam | epoch: 009 | loss: 0.27172 - acc: 0.8948 -- iter: 2464/2867
[A[ATraining Step: 798  | total loss: [1m[32m0.25660[0m[0m | time: 1309.629s
[2K
| Adam | epoch: 009 | loss: 0.25660 - acc: 0.8991 -- iter: 2496/2867
[A[ATraining Step: 799  | total loss: [1m[32m0.24581[0m[0m | time: 1327.394s
[2K
| Adam | epoch: 009 | loss: 0.24581 - acc: 0.9029 -- iter: 2528/2867
[A[ATraining Step: 800  | total loss: [1m[32m0.24537[0m[0m | time: 1422.447s
[2K
| Adam | epoch: 009 | loss: 0.24537 - acc: 0.9033 | val_loss: 2.12505 - val_acc: 0.6288 -- iter: 2560/2867
--
Training Step: 801  | total loss: [1m[32m0.24909[0m[0m | time: 1441.069s
[2K
| Adam | epoch: 009 | loss: 0.24909 - acc: 0.9036 -- iter: 2592/2867
[A[ATraining Step: 802  | total loss: [1m[32m0.23775[0m[0m | time: 1462.499s
[2K
| Adam | epoch: 009 | loss: 0.23775 - acc: 0.9069 -- iter: 2624/2867
[A[ATraining Step: 803  | total loss: [1m[32m0.24456[0m[0m | time: 1476.194s
[2K
| Adam | epoch: 009 | loss: 0.24456 - acc: 0.8975 -- iter: 2656/2867
[A[ATraining Step: 804  | total loss: [1m[32m0.27230[0m[0m | time: 1488.746s
[2K
| Adam | epoch: 009 | loss: 0.27230 - acc: 0.8921 -- iter: 2688/2867
[A[ATraining Step: 805  | total loss: [1m[32m0.28056[0m[0m | time: 1504.648s
[2K
| Adam | epoch: 009 | loss: 0.28056 - acc: 0.8842 -- iter: 2720/2867
[A[ATraining Step: 806  | total loss: [1m[32m0.27770[0m[0m | time: 1521.897s
[2K
| Adam | epoch: 009 | loss: 0.27770 - acc: 0.8832 -- iter: 2752/2867
[A[ATraining Step: 807  | total loss: [1m[32m0.26827[0m[0m | time: 1539.994s
[2K
| Adam | epoch: 009 | loss: 0.26827 - acc: 0.8887 -- iter: 2784/2867
[A[ATraining Step: 808  | total loss: [1m[32m0.25558[0m[0m | time: 1558.241s
[2K
| Adam | epoch: 009 | loss: 0.25558 - acc: 0.8936 -- iter: 2816/2867
[A[ATraining Step: 809  | total loss: [1m[32m0.24393[0m[0m | time: 1576.148s
[2K
| Adam | epoch: 009 | loss: 0.24393 - acc: 0.8980 -- iter: 2848/2867
[A[ATraining Step: 810  | total loss: [1m[32m0.27002[0m[0m | time: 1677.472s
[2K
| Adam | epoch: 009 | loss: 0.27002 - acc: 0.8863 | val_loss: 6.76723 - val_acc: 0.5095 -- iter: 2867/2867
--
Training Step: 811  | total loss: [1m[32m0.27635[0m[0m | time: 18.146s
[2K
| Adam | epoch: 010 | loss: 0.27635 - acc: 0.8883 -- iter: 0032/2867
[A[ATraining Step: 812  | total loss: [1m[32m0.26343[0m[0m | time: 32.442s
[2K
| Adam | epoch: 010 | loss: 0.26343 - acc: 0.8932 -- iter: 0064/2867
[A[ATraining Step: 813  | total loss: [1m[32m0.25645[0m[0m | time: 44.901s
[2K
| Adam | epoch: 010 | loss: 0.25645 - acc: 0.9008 -- iter: 0096/2867
[A[ATraining Step: 814  | total loss: [1m[32m0.27989[0m[0m | time: 62.008s
[2K
| Adam | epoch: 010 | loss: 0.27989 - acc: 0.8857 -- iter: 0128/2867
[A[ATraining Step: 815  | total loss: [1m[32m0.26740[0m[0m | time: 80.956s
[2K
| Adam | epoch: 010 | loss: 0.26740 - acc: 0.8940 -- iter: 0160/2867
[A[ATraining Step: 816  | total loss: [1m[32m0.25804[0m[0m | time: 97.756s
[2K
| Adam | epoch: 010 | loss: 0.25804 - acc: 0.9015 -- iter: 0192/2867
[A[ATraining Step: 817  | total loss: [1m[32m0.24380[0m[0m | time: 115.548s
[2K
| Adam | epoch: 010 | loss: 0.24380 - acc: 0.9082 -- iter: 0224/2867
[A[ATraining Step: 818  | total loss: [1m[32m0.24153[0m[0m | time: 127.585s
[2K
| Adam | epoch: 010 | loss: 0.24153 - acc: 0.9111 -- iter: 0256/2867
[A[ATraining Step: 819  | total loss: [1m[32m0.24964[0m[0m | time: 139.500s
[2K
| Adam | epoch: 010 | loss: 0.24964 - acc: 0.9042 -- iter: 0288/2867
[A[ATraining Step: 820  | total loss: [1m[32m0.23891[0m[0m | time: 157.146s
[2K
| Adam | epoch: 010 | loss: 0.23891 - acc: 0.9085 -- iter: 0320/2867
[A[ATraining Step: 821  | total loss: [1m[32m0.22609[0m[0m | time: 169.185s
[2K
| Adam | epoch: 010 | loss: 0.22609 - acc: 0.9146 -- iter: 0352/2867
[A[ATraining Step: 822  | total loss: [1m[32m0.22668[0m[0m | time: 181.114s
[2K
| Adam | epoch: 010 | loss: 0.22668 - acc: 0.9137 -- iter: 0384/2867
[A[ATraining Step: 823  | total loss: [1m[32m0.24234[0m[0m | time: 198.976s
[2K
| Adam | epoch: 010 | loss: 0.24234 - acc: 0.9099 -- iter: 0416/2867
[A[ATraining Step: 824  | total loss: [1m[32m0.25688[0m[0m | time: 223.170s
[2K
| Adam | epoch: 010 | loss: 0.25688 - acc: 0.9032 -- iter: 0448/2867
[A[ATraining Step: 825  | total loss: [1m[32m0.25372[0m[0m | time: 262.718s
[2K
| Adam | epoch: 010 | loss: 0.25372 - acc: 0.9004 -- iter: 0480/2867
[A[ATraining Step: 826  | total loss: [1m[32m0.24282[0m[0m | time: 279.278s
[2K
| Adam | epoch: 010 | loss: 0.24282 - acc: 0.9041 -- iter: 0512/2867
[A[ATraining Step: 827  | total loss: [1m[32m0.22532[0m[0m | time: 296.237s
[2K
| Adam | epoch: 010 | loss: 0.22532 - acc: 0.9137 -- iter: 0544/2867
[A[ATraining Step: 828  | total loss: [1m[32m0.21704[0m[0m | time: 313.874s
[2K
| Adam | epoch: 010 | loss: 0.21704 - acc: 0.9192 -- iter: 0576/2867
[A[ATraining Step: 829  | total loss: [1m[32m0.20280[0m[0m | time: 329.256s
[2K
| Adam | epoch: 010 | loss: 0.20280 - acc: 0.9273 -- iter: 0608/2867
[A[ATraining Step: 830  | total loss: [1m[32m0.19747[0m[0m | time: 341.867s
[2K
| Adam | epoch: 010 | loss: 0.19747 - acc: 0.9252 -- iter: 0640/2867
[A[ATraining Step: 831  | total loss: [1m[32m0.19730[0m[0m | time: 356.471s
[2K
| Adam | epoch: 010 | loss: 0.19730 - acc: 0.9264 -- iter: 0672/2867
[A[ATraining Step: 832  | total loss: [1m[32m0.21857[0m[0m | time: 375.555s
[2K
| Adam | epoch: 010 | loss: 0.21857 - acc: 0.9182 -- iter: 0704/2867
[A[ATraining Step: 833  | total loss: [1m[32m0.21626[0m[0m | time: 393.205s
[2K
| Adam | epoch: 010 | loss: 0.21626 - acc: 0.9232 -- iter: 0736/2867
[A[ATraining Step: 834  | total loss: [1m[32m0.23478[0m[0m | time: 406.501s
[2K
| Adam | epoch: 010 | loss: 0.23478 - acc: 0.9153 -- iter: 0768/2867
[A[ATraining Step: 835  | total loss: [1m[32m0.24118[0m[0m | time: 420.605s
[2K
| Adam | epoch: 010 | loss: 0.24118 - acc: 0.9050 -- iter: 0800/2867
[A[ATraining Step: 836  | total loss: [1m[32m0.24153[0m[0m | time: 437.976s
[2K
| Adam | epoch: 010 | loss: 0.24153 - acc: 0.9020 -- iter: 0832/2867
[A[ATraining Step: 837  | total loss: [1m[32m0.23600[0m[0m | time: 455.426s
[2K
| Adam | epoch: 010 | loss: 0.23600 - acc: 0.9024 -- iter: 0864/2867
[A[ATraining Step: 838  | total loss: [1m[32m0.23877[0m[0m | time: 467.696s
[2K
| Adam | epoch: 010 | loss: 0.23877 - acc: 0.8997 -- iter: 0896/2867
[A[ATraining Step: 839  | total loss: [1m[32m0.26455[0m[0m | time: 480.872s
[2K
| Adam | epoch: 010 | loss: 0.26455 - acc: 0.8910 -- iter: 0928/2867
[A[ATraining Step: 840  | total loss: [1m[32m0.27456[0m[0m | time: 499.493s
[2K
| Adam | epoch: 010 | loss: 0.27456 - acc: 0.8769 -- iter: 0960/2867
[A[ATraining Step: 841  | total loss: [1m[32m0.27184[0m[0m | time: 517.917s
[2K
| Adam | epoch: 010 | loss: 0.27184 - acc: 0.8829 -- iter: 0992/2867
[A[ATraining Step: 842  | total loss: [1m[32m0.26759[0m[0m | time: 536.001s
[2K
| Adam | epoch: 010 | loss: 0.26759 - acc: 0.8884 -- iter: 1024/2867
[A[ATraining Step: 843  | total loss: [1m[32m0.29096[0m[0m | time: 554.110s
[2K
| Adam | epoch: 010 | loss: 0.29096 - acc: 0.8808 -- iter: 1056/2867
[A[ATraining Step: 844  | total loss: [1m[32m0.30187[0m[0m | time: 571.637s
[2K
| Adam | epoch: 010 | loss: 0.30187 - acc: 0.8677 -- iter: 1088/2867
[A[ATraining Step: 845  | total loss: [1m[32m0.28657[0m[0m | time: 588.415s
[2K
| Adam | epoch: 010 | loss: 0.28657 - acc: 0.8747 -- iter: 1120/2867
[A[ATraining Step: 846  | total loss: [1m[32m0.27964[0m[0m | time: 600.941s
[2K
| Adam | epoch: 010 | loss: 0.27964 - acc: 0.8778 -- iter: 1152/2867
[A[ATraining Step: 847  | total loss: [1m[32m0.28636[0m[0m | time: 614.159s
[2K
| Adam | epoch: 010 | loss: 0.28636 - acc: 0.8807 -- iter: 1184/2867
[A[ATraining Step: 848  | total loss: [1m[32m0.28930[0m[0m | time: 631.837s
[2K
| Adam | epoch: 010 | loss: 0.28930 - acc: 0.8832 -- iter: 1216/2867
[A[ATraining Step: 849  | total loss: [1m[32m0.28478[0m[0m | time: 649.439s
[2K
| Adam | epoch: 010 | loss: 0.28478 - acc: 0.8855 -- iter: 1248/2867
[A[ATraining Step: 850  | total loss: [1m[32m0.27555[0m[0m | time: 667.550s
[2K
| Adam | epoch: 010 | loss: 0.27555 - acc: 0.8907 -- iter: 1280/2867
[A[ATraining Step: 851  | total loss: [1m[32m0.26273[0m[0m | time: 684.986s
[2K
| Adam | epoch: 010 | loss: 0.26273 - acc: 0.8985 -- iter: 1312/2867
[A[ATraining Step: 852  | total loss: [1m[32m0.26113[0m[0m | time: 702.418s
[2K
| Adam | epoch: 010 | loss: 0.26113 - acc: 0.8962 -- iter: 1344/2867
[A[ATraining Step: 853  | total loss: [1m[32m0.25990[0m[0m | time: 719.886s
[2K
| Adam | epoch: 010 | loss: 0.25990 - acc: 0.8941 -- iter: 1376/2867
[A[ATraining Step: 854  | total loss: [1m[32m0.26393[0m[0m | time: 734.080s
[2K
| Adam | epoch: 010 | loss: 0.26393 - acc: 0.8922 -- iter: 1408/2867
[A[ATraining Step: 855  | total loss: [1m[32m0.25699[0m[0m | time: 746.416s
[2K
| Adam | epoch: 010 | loss: 0.25699 - acc: 0.8967 -- iter: 1440/2867
[A[ATraining Step: 856  | total loss: [1m[32m0.26522[0m[0m | time: 762.695s
[2K
| Adam | epoch: 010 | loss: 0.26522 - acc: 0.9008 -- iter: 1472/2867
[A[ATraining Step: 857  | total loss: [1m[32m0.26543[0m[0m | time: 786.001s
[2K
| Adam | epoch: 010 | loss: 0.26543 - acc: 0.8982 -- iter: 1504/2867
[A[ATraining Step: 858  | total loss: [1m[32m0.25634[0m[0m | time: 803.726s
[2K
| Adam | epoch: 010 | loss: 0.25634 - acc: 0.9021 -- iter: 1536/2867
[A[ATraining Step: 859  | total loss: [1m[32m0.24945[0m[0m | time: 822.138s
[2K
| Adam | epoch: 010 | loss: 0.24945 - acc: 0.9057 -- iter: 1568/2867
[A[ATraining Step: 860  | total loss: [1m[32m0.23109[0m[0m | time: 840.022s
[2K
| Adam | epoch: 010 | loss: 0.23109 - acc: 0.9151 -- iter: 1600/2867
[A[ATraining Step: 861  | total loss: [1m[32m0.21857[0m[0m | time: 857.734s
[2K
| Adam | epoch: 010 | loss: 0.21857 - acc: 0.9236 -- iter: 1632/2867
[A[ATraining Step: 862  | total loss: [1m[32m0.21054[0m[0m | time: 874.104s
[2K
| Adam | epoch: 010 | loss: 0.21054 - acc: 0.9250 -- iter: 1664/2867
[A[ATraining Step: 863  | total loss: [1m[32m0.21256[0m[0m | time: 886.234s
[2K
| Adam | epoch: 010 | loss: 0.21256 - acc: 0.9169 -- iter: 1696/2867
[A[ATraining Step: 864  | total loss: [1m[32m0.21184[0m[0m | time: 898.423s
[2K
| Adam | epoch: 010 | loss: 0.21184 - acc: 0.9158 -- iter: 1728/2867
[A[ATraining Step: 865  | total loss: [1m[32m0.20575[0m[0m | time: 911.325s
[2K
| Adam | epoch: 010 | loss: 0.20575 - acc: 0.9211 -- iter: 1760/2867
[A[ATraining Step: 866  | total loss: [1m[32m0.19384[0m[0m | time: 928.948s
[2K
| Adam | epoch: 010 | loss: 0.19384 - acc: 0.9259 -- iter: 1792/2867
[A[ATraining Step: 867  | total loss: [1m[32m0.18703[0m[0m | time: 947.017s
[2K
| Adam | epoch: 010 | loss: 0.18703 - acc: 0.9270 -- iter: 1824/2867
[A[ATraining Step: 868  | total loss: [1m[32m0.19303[0m[0m | time: 964.909s
[2K
| Adam | epoch: 010 | loss: 0.19303 - acc: 0.9281 -- iter: 1856/2867
[A[ATraining Step: 869  | total loss: [1m[32m0.19485[0m[0m | time: 982.398s
[2K
| Adam | epoch: 010 | loss: 0.19485 - acc: 0.9259 -- iter: 1888/2867
[A[ATraining Step: 870  | total loss: [1m[32m0.19752[0m[0m | time: 1000.382s
[2K
| Adam | epoch: 010 | loss: 0.19752 - acc: 0.9270 -- iter: 1920/2867
[A[ATraining Step: 871  | total loss: [1m[32m0.18862[0m[0m | time: 1018.002s
[2K
| Adam | epoch: 010 | loss: 0.18862 - acc: 0.9281 -- iter: 1952/2867
[A[ATraining Step: 872  | total loss: [1m[32m0.19025[0m[0m | time: 1030.714s
[2K
| Adam | epoch: 010 | loss: 0.19025 - acc: 0.9290 -- iter: 1984/2867
[A[ATraining Step: 873  | total loss: [1m[32m0.18948[0m[0m | time: 1043.526s
[2K
| Adam | epoch: 010 | loss: 0.18948 - acc: 0.9299 -- iter: 2016/2867
[A[ATraining Step: 874  | total loss: [1m[32m0.18264[0m[0m | time: 1062.252s
[2K
| Adam | epoch: 010 | loss: 0.18264 - acc: 0.9306 -- iter: 2048/2867
[A[ATraining Step: 875  | total loss: [1m[32m0.18632[0m[0m | time: 1079.820s
[2K
| Adam | epoch: 010 | loss: 0.18632 - acc: 0.9251 -- iter: 2080/2867
[A[ATraining Step: 876  | total loss: [1m[32m0.19844[0m[0m | time: 1093.874s
[2K
| Adam | epoch: 010 | loss: 0.19844 - acc: 0.9169 -- iter: 2112/2867
[A[ATraining Step: 877  | total loss: [1m[32m0.19877[0m[0m | time: 1108.193s
[2K
| Adam | epoch: 010 | loss: 0.19877 - acc: 0.9221 -- iter: 2144/2867
[A[ATraining Step: 878  | total loss: [1m[32m0.19488[0m[0m | time: 1125.975s
[2K
| Adam | epoch: 010 | loss: 0.19488 - acc: 0.9237 -- iter: 2176/2867
[A[ATraining Step: 879  | total loss: [1m[32m0.19733[0m[0m | time: 1150.269s
[2K
| Adam | epoch: 010 | loss: 0.19733 - acc: 0.9188 -- iter: 2208/2867
[A[ATraining Step: 880  | total loss: [1m[32m0.19367[0m[0m | time: 1168.176s
[2K
| Adam | epoch: 010 | loss: 0.19367 - acc: 0.9207 -- iter: 2240/2867
[A[ATraining Step: 881  | total loss: [1m[32m0.19602[0m[0m | time: 1176.403s
[2K
| Adam | epoch: 010 | loss: 0.19602 - acc: 0.9192 -- iter: 2272/2867
[A[ATraining Step: 882  | total loss: [1m[32m0.19569[0m[0m | time: 1190.360s
[2K
| Adam | epoch: 010 | loss: 0.19569 - acc: 0.9211 -- iter: 2304/2867
[A[ATraining Step: 883  | total loss: [1m[32m0.19578[0m[0m | time: 1203.465s
[2K
| Adam | epoch: 010 | loss: 0.19578 - acc: 0.9196 -- iter: 2336/2867
[A[ATraining Step: 884  | total loss: [1m[32m0.18052[0m[0m | time: 1215.853s
[2K
| Adam | epoch: 010 | loss: 0.18052 - acc: 0.9276 -- iter: 2368/2867
[A[ATraining Step: 885  | total loss: [1m[32m0.16839[0m[0m | time: 1229.031s
[2K
| Adam | epoch: 010 | loss: 0.16839 - acc: 0.9349 -- iter: 2400/2867
[A[ATraining Step: 886  | total loss: [1m[32m0.17901[0m[0m | time: 1241.867s
[2K
| Adam | epoch: 010 | loss: 0.17901 - acc: 0.9289 -- iter: 2432/2867
[A[ATraining Step: 887  | total loss: [1m[32m0.17440[0m[0m | time: 1254.816s
[2K
| Adam | epoch: 010 | loss: 0.17440 - acc: 0.9329 -- iter: 2464/2867
[A[ATraining Step: 888  | total loss: [1m[32m0.16778[0m[0m | time: 1263.085s
[2K
| Adam | epoch: 010 | loss: 0.16778 - acc: 0.9364 -- iter: 2496/2867
[A[ATraining Step: 889  | total loss: [1m[32m0.18413[0m[0m | time: 1271.301s
[2K
| Adam | epoch: 010 | loss: 0.18413 - acc: 0.9241 -- iter: 2528/2867
[A[ATraining Step: 890  | total loss: [1m[32m0.18755[0m[0m | time: 1281.098s
[2K
| Adam | epoch: 010 | loss: 0.18755 - acc: 0.9223 -- iter: 2560/2867
[A[ATraining Step: 891  | total loss: [1m[32m0.18186[0m[0m | time: 1293.994s
[2K
| Adam | epoch: 010 | loss: 0.18186 - acc: 0.9238 -- iter: 2592/2867
[A[ATraining Step: 892  | total loss: [1m[32m0.18187[0m[0m | time: 1307.208s
[2K
| Adam | epoch: 010 | loss: 0.18187 - acc: 0.9220 -- iter: 2624/2867
[A[ATraining Step: 893  | total loss: [1m[32m0.19809[0m[0m | time: 1319.757s
[2K
| Adam | epoch: 010 | loss: 0.19809 - acc: 0.9236 -- iter: 2656/2867
[A[ATraining Step: 894  | total loss: [1m[32m0.18334[0m[0m | time: 1332.316s
[2K
| Adam | epoch: 010 | loss: 0.18334 - acc: 0.9281 -- iter: 2688/2867
[A[ATraining Step: 895  | total loss: [1m[32m0.17022[0m[0m | time: 1345.498s
[2K
| Adam | epoch: 010 | loss: 0.17022 - acc: 0.9353 -- iter: 2720/2867
[A[ATraining Step: 896  | total loss: [1m[32m0.17096[0m[0m | time: 1357.680s
[2K
| Adam | epoch: 010 | loss: 0.17096 - acc: 0.9355 -- iter: 2752/2867
[A[ATraining Step: 897  | total loss: [1m[32m0.18158[0m[0m | time: 1365.725s
[2K
| Adam | epoch: 010 | loss: 0.18158 - acc: 0.9388 -- iter: 2784/2867
[A[ATraining Step: 898  | total loss: [1m[32m0.18537[0m[0m | time: 1373.833s
[2K
| Adam | epoch: 010 | loss: 0.18537 - acc: 0.9356 -- iter: 2816/2867
[A[ATraining Step: 899  | total loss: [1m[32m0.17929[0m[0m | time: 1382.024s
[2K
| Adam | epoch: 010 | loss: 0.17929 - acc: 0.9358 -- iter: 2848/2867
[A[ATraining Step: 900  | total loss: [1m[32m0.16717[0m[0m | time: 1459.622s
[2K
| Adam | epoch: 010 | loss: 0.16717 - acc: 0.9422 | val_loss: 1.22487 - val_acc: 0.7514 -- iter: 2867/2867
--
Training Step: 901  | total loss: [1m[32m0.16666[0m[0m | time: 9.289s
[2K
| Adam | epoch: 011 | loss: 0.16666 - acc: 0.9448 -- iter: 0032/2867
[A[ATraining Step: 902  | total loss: [1m[32m0.15418[0m[0m | time: 22.551s
[2K
| Adam | epoch: 011 | loss: 0.15418 - acc: 0.9504 -- iter: 0064/2867
[A[ATraining Step: 903  | total loss: [1m[32m0.15133[0m[0m | time: 35.721s
[2K
| Adam | epoch: 011 | loss: 0.15133 - acc: 0.9491 -- iter: 0096/2867
[A[ATraining Step: 904  | total loss: [1m[32m0.14569[0m[0m | time: 48.992s
[2K
| Adam | epoch: 011 | loss: 0.14569 - acc: 0.9510 -- iter: 0128/2867
[A[ATraining Step: 905  | total loss: [1m[32m0.15316[0m[0m | time: 62.278s
[2K
| Adam | epoch: 011 | loss: 0.15316 - acc: 0.9497 -- iter: 0160/2867
[A[ATraining Step: 906  | total loss: [1m[32m0.15366[0m[0m | time: 74.855s
[2K
| Adam | epoch: 011 | loss: 0.15366 - acc: 0.9422 -- iter: 0192/2867
[A[ATraining Step: 907  | total loss: [1m[32m0.15265[0m[0m | time: 87.111s
[2K
| Adam | epoch: 011 | loss: 0.15265 - acc: 0.9449 -- iter: 0224/2867
[A[ATraining Step: 908  | total loss: [1m[32m0.15275[0m[0m | time: 95.061s
[2K
| Adam | epoch: 011 | loss: 0.15275 - acc: 0.9441 -- iter: 0256/2867
[A[ATraining Step: 909  | total loss: [1m[32m0.14549[0m[0m | time: 100.510s
[2K
| Adam | epoch: 011 | loss: 0.14549 - acc: 0.9497 -- iter: 0288/2867
[A[ATraining Step: 910  | total loss: [1m[32m0.15422[0m[0m | time: 105.941s
[2K
| Adam | epoch: 011 | loss: 0.15422 - acc: 0.9442 -- iter: 0320/2867
[A[ATraining Step: 911  | total loss: [1m[32m0.14550[0m[0m | time: 117.282s
[2K
| Adam | epoch: 011 | loss: 0.14550 - acc: 0.9498 -- iter: 0352/2867
[A[ATraining Step: 912  | total loss: [1m[32m0.14582[0m[0m | time: 130.642s
[2K
| Adam | epoch: 011 | loss: 0.14582 - acc: 0.9486 -- iter: 0384/2867
[A[ATraining Step: 913  | total loss: [1m[32m0.13456[0m[0m | time: 143.752s
[2K
| Adam | epoch: 011 | loss: 0.13456 - acc: 0.9537 -- iter: 0416/2867
[A[ATraining Step: 914  | total loss: [1m[32m0.14158[0m[0m | time: 157.353s
[2K
| Adam | epoch: 011 | loss: 0.14158 - acc: 0.9490 -- iter: 0448/2867
[A[ATraining Step: 915  | total loss: [1m[32m0.14237[0m[0m | time: 170.696s
[2K
| Adam | epoch: 011 | loss: 0.14237 - acc: 0.9478 -- iter: 0480/2867
[A[ATraining Step: 916  | total loss: [1m[32m0.15344[0m[0m | time: 183.710s
[2K
| Adam | epoch: 011 | loss: 0.15344 - acc: 0.9437 -- iter: 0512/2867
[A[ATraining Step: 917  | total loss: [1m[32m0.14234[0m[0m | time: 194.805s
[2K
| Adam | epoch: 011 | loss: 0.14234 - acc: 0.9493 -- iter: 0544/2867
[A[ATraining Step: 918  | total loss: [1m[32m0.13433[0m[0m | time: 203.004s
[2K
| Adam | epoch: 011 | loss: 0.13433 - acc: 0.9512 -- iter: 0576/2867
[A[ATraining Step: 919  | total loss: [1m[32m0.13241[0m[0m | time: 211.234s
[2K
| Adam | epoch: 011 | loss: 0.13241 - acc: 0.9467 -- iter: 0608/2867
[A[ATraining Step: 920  | total loss: [1m[32m0.12322[0m[0m | time: 223.857s
[2K
| Adam | epoch: 011 | loss: 0.12322 - acc: 0.9521 -- iter: 0640/2867
[A[ATraining Step: 921  | total loss: [1m[32m0.11783[0m[0m | time: 236.610s
[2K
| Adam | epoch: 011 | loss: 0.11783 - acc: 0.9506 -- iter: 0672/2867
[A[ATraining Step: 922  | total loss: [1m[32m0.12309[0m[0m | time: 249.986s
[2K
| Adam | epoch: 011 | loss: 0.12309 - acc: 0.9524 -- iter: 0704/2867
[A[ATraining Step: 923  | total loss: [1m[32m0.13069[0m[0m | time: 263.127s
[2K
| Adam | epoch: 011 | loss: 0.13069 - acc: 0.9478 -- iter: 0736/2867
[A[ATraining Step: 924  | total loss: [1m[32m0.13124[0m[0m | time: 275.665s
[2K
| Adam | epoch: 011 | loss: 0.13124 - acc: 0.9468 -- iter: 0768/2867
[A[ATraining Step: 925  | total loss: [1m[32m0.13629[0m[0m | time: 288.792s
[2K
| Adam | epoch: 011 | loss: 0.13629 - acc: 0.9458 -- iter: 0800/2867
[A[ATraining Step: 926  | total loss: [1m[32m0.13650[0m[0m | time: 299.622s
[2K
| Adam | epoch: 011 | loss: 0.13650 - acc: 0.9450 -- iter: 0832/2867
[A[ATraining Step: 927  | total loss: [1m[32m0.14795[0m[0m | time: 307.581s
[2K
| Adam | epoch: 011 | loss: 0.14795 - acc: 0.9411 -- iter: 0864/2867
[A[ATraining Step: 928  | total loss: [1m[32m0.13870[0m[0m | time: 315.664s
[2K
| Adam | epoch: 011 | loss: 0.13870 - acc: 0.9439 -- iter: 0896/2867
[A[ATraining Step: 929  | total loss: [1m[32m0.12918[0m[0m | time: 325.638s
[2K
| Adam | epoch: 011 | loss: 0.12918 - acc: 0.9495 -- iter: 0928/2867
[A[ATraining Step: 930  | total loss: [1m[32m0.14155[0m[0m | time: 338.388s
[2K
| Adam | epoch: 011 | loss: 0.14155 - acc: 0.9421 -- iter: 0960/2867
[A[ATraining Step: 931  | total loss: [1m[32m0.15437[0m[0m | time: 351.588s
[2K
| Adam | epoch: 011 | loss: 0.15437 - acc: 0.9385 -- iter: 0992/2867
[A[ATraining Step: 932  | total loss: [1m[32m0.14492[0m[0m | time: 364.090s
[2K
| Adam | epoch: 011 | loss: 0.14492 - acc: 0.9415 -- iter: 1024/2867
[A[ATraining Step: 933  | total loss: [1m[32m0.13873[0m[0m | time: 377.037s
[2K
| Adam | epoch: 011 | loss: 0.13873 - acc: 0.9442 -- iter: 1056/2867
[A[ATraining Step: 934  | total loss: [1m[32m0.13511[0m[0m | time: 389.792s
[2K
| Adam | epoch: 011 | loss: 0.13511 - acc: 0.9467 -- iter: 1088/2867
[A[ATraining Step: 935  | total loss: [1m[32m0.14084[0m[0m | time: 401.969s
[2K
| Adam | epoch: 011 | loss: 0.14084 - acc: 0.9426 -- iter: 1120/2867
[A[ATraining Step: 936  | total loss: [1m[32m0.14184[0m[0m | time: 410.148s
[2K
| Adam | epoch: 011 | loss: 0.14184 - acc: 0.9390 -- iter: 1152/2867
[A[ATraining Step: 937  | total loss: [1m[32m0.15675[0m[0m | time: 418.494s
[2K
| Adam | epoch: 011 | loss: 0.15675 - acc: 0.9357 -- iter: 1184/2867
[A[ATraining Step: 938  | total loss: [1m[32m0.16219[0m[0m | time: 430.667s
[2K
| Adam | epoch: 011 | loss: 0.16219 - acc: 0.9328 -- iter: 1216/2867
[A[ATraining Step: 939  | total loss: [1m[32m0.16220[0m[0m | time: 443.174s
[2K
| Adam | epoch: 011 | loss: 0.16220 - acc: 0.9301 -- iter: 1248/2867
[A[ATraining Step: 940  | total loss: [1m[32m0.16964[0m[0m | time: 456.172s
[2K
| Adam | epoch: 011 | loss: 0.16964 - acc: 0.9309 -- iter: 1280/2867
[A[ATraining Step: 941  | total loss: [1m[32m0.16286[0m[0m | time: 469.381s
[2K
| Adam | epoch: 011 | loss: 0.16286 - acc: 0.9347 -- iter: 1312/2867
[A[ATraining Step: 942  | total loss: [1m[32m0.14941[0m[0m | time: 482.333s
[2K
| Adam | epoch: 011 | loss: 0.14941 - acc: 0.9412 -- iter: 1344/2867
[A[ATraining Step: 943  | total loss: [1m[32m0.16199[0m[0m | time: 495.836s
[2K
| Adam | epoch: 011 | loss: 0.16199 - acc: 0.9346 -- iter: 1376/2867
[A[ATraining Step: 944  | total loss: [1m[32m0.16159[0m[0m | time: 505.278s
[2K
| Adam | epoch: 011 | loss: 0.16159 - acc: 0.9349 -- iter: 1408/2867
[A[ATraining Step: 945  | total loss: [1m[32m0.15322[0m[0m | time: 513.521s
[2K
| Adam | epoch: 011 | loss: 0.15322 - acc: 0.9414 -- iter: 1440/2867
[A[ATraining Step: 946  | total loss: [1m[32m0.15865[0m[0m | time: 522.767s
[2K
| Adam | epoch: 011 | loss: 0.15865 - acc: 0.9379 -- iter: 1472/2867
[A[ATraining Step: 947  | total loss: [1m[32m0.15749[0m[0m | time: 535.654s
[2K
| Adam | epoch: 011 | loss: 0.15749 - acc: 0.9410 -- iter: 1504/2867
[A[ATraining Step: 948  | total loss: [1m[32m0.15047[0m[0m | time: 548.091s
[2K
| Adam | epoch: 011 | loss: 0.15047 - acc: 0.9437 -- iter: 1536/2867
[A[ATraining Step: 949  | total loss: [1m[32m0.15365[0m[0m | time: 560.336s
[2K
| Adam | epoch: 011 | loss: 0.15365 - acc: 0.9431 -- iter: 1568/2867
[A[ATraining Step: 950  | total loss: [1m[32m0.15601[0m[0m | time: 570.674s
[2K
| Adam | epoch: 011 | loss: 0.15601 - acc: 0.9394 -- iter: 1600/2867
[A[ATraining Step: 951  | total loss: [1m[32m0.17092[0m[0m | time: 580.092s
[2K
| Adam | epoch: 011 | loss: 0.17092 - acc: 0.9330 -- iter: 1632/2867
[A[ATraining Step: 952  | total loss: [1m[32m0.19265[0m[0m | time: 593.011s
[2K
| Adam | epoch: 011 | loss: 0.19265 - acc: 0.9241 -- iter: 1664/2867
[A[ATraining Step: 953  | total loss: [1m[32m0.21719[0m[0m | time: 606.409s
[2K
| Adam | epoch: 011 | loss: 0.21719 - acc: 0.9223 -- iter: 1696/2867
[A[ATraining Step: 954  | total loss: [1m[32m0.20383[0m[0m | time: 618.488s
[2K
| Adam | epoch: 011 | loss: 0.20383 - acc: 0.9238 -- iter: 1728/2867
[A[ATraining Step: 955  | total loss: [1m[32m0.24208[0m[0m | time: 626.590s
[2K
| Adam | epoch: 011 | loss: 0.24208 - acc: 0.9095 -- iter: 1760/2867
[A[ATraining Step: 956  | total loss: [1m[32m0.27479[0m[0m | time: 634.634s
[2K
| Adam | epoch: 011 | loss: 0.27479 - acc: 0.9061 -- iter: 1792/2867
[A[ATraining Step: 957  | total loss: [1m[32m0.26702[0m[0m | time: 645.456s
[2K
| Adam | epoch: 011 | loss: 0.26702 - acc: 0.9061 -- iter: 1824/2867
[A[ATraining Step: 958  | total loss: [1m[32m0.25665[0m[0m | time: 658.568s
[2K
| Adam | epoch: 011 | loss: 0.25665 - acc: 0.9030 -- iter: 1856/2867
[A[ATraining Step: 959  | total loss: [1m[32m0.25289[0m[0m | time: 672.012s
[2K
| Adam | epoch: 011 | loss: 0.25289 - acc: 0.9002 -- iter: 1888/2867
[A[ATraining Step: 960  | total loss: [1m[32m0.25738[0m[0m | time: 684.272s
[2K
| Adam | epoch: 011 | loss: 0.25738 - acc: 0.8946 -- iter: 1920/2867
[A[ATraining Step: 961  | total loss: [1m[32m0.24806[0m[0m | time: 696.921s
[2K
| Adam | epoch: 011 | loss: 0.24806 - acc: 0.9020 -- iter: 1952/2867
[A[ATraining Step: 962  | total loss: [1m[32m0.23867[0m[0m | time: 710.512s
[2K
| Adam | epoch: 011 | loss: 0.23867 - acc: 0.9055 -- iter: 1984/2867
[A[ATraining Step: 963  | total loss: [1m[32m0.22679[0m[0m | time: 721.191s
[2K
| Adam | epoch: 011 | loss: 0.22679 - acc: 0.9118 -- iter: 2016/2867
[A[ATraining Step: 964  | total loss: [1m[32m0.21674[0m[0m | time: 729.420s
[2K
| Adam | epoch: 011 | loss: 0.21674 - acc: 0.9175 -- iter: 2048/2867
[A[ATraining Step: 965  | total loss: [1m[32m0.21499[0m[0m | time: 737.737s
[2K
| Adam | epoch: 011 | loss: 0.21499 - acc: 0.9164 -- iter: 2080/2867
[A[ATraining Step: 966  | total loss: [1m[32m0.22467[0m[0m | time: 745.799s
[2K
| Adam | epoch: 011 | loss: 0.22467 - acc: 0.9123 -- iter: 2112/2867
[A[ATraining Step: 967  | total loss: [1m[32m0.22204[0m[0m | time: 758.000s
[2K
| Adam | epoch: 011 | loss: 0.22204 - acc: 0.9117 -- iter: 2144/2867
[A[ATraining Step: 968  | total loss: [1m[32m0.21221[0m[0m | time: 766.289s
[2K
| Adam | epoch: 011 | loss: 0.21221 - acc: 0.9174 -- iter: 2176/2867
[A[ATraining Step: 969  | total loss: [1m[32m0.20256[0m[0m | time: 774.566s
[2K
| Adam | epoch: 011 | loss: 0.20256 - acc: 0.9225 -- iter: 2208/2867
[A[ATraining Step: 970  | total loss: [1m[32m0.19186[0m[0m | time: 782.571s
[2K
| Adam | epoch: 011 | loss: 0.19186 - acc: 0.9271 -- iter: 2240/2867
[A[ATraining Step: 971  | total loss: [1m[32m0.18174[0m[0m | time: 790.605s
[2K
| Adam | epoch: 011 | loss: 0.18174 - acc: 0.9344 -- iter: 2272/2867
[A[ATraining Step: 972  | total loss: [1m[32m0.17299[0m[0m | time: 798.783s
[2K
| Adam | epoch: 011 | loss: 0.17299 - acc: 0.9379 -- iter: 2304/2867
[A[ATraining Step: 973  | total loss: [1m[32m0.17811[0m[0m | time: 807.073s
[2K
| Adam | epoch: 011 | loss: 0.17811 - acc: 0.9378 -- iter: 2336/2867
[A[ATraining Step: 974  | total loss: [1m[32m0.17469[0m[0m | time: 815.183s
[2K
| Adam | epoch: 011 | loss: 0.17469 - acc: 0.9409 -- iter: 2368/2867
[A[ATraining Step: 975  | total loss: [1m[32m0.17673[0m[0m | time: 823.420s
[2K
| Adam | epoch: 011 | loss: 0.17673 - acc: 0.9406 -- iter: 2400/2867
[A[ATraining Step: 976  | total loss: [1m[32m0.17554[0m[0m | time: 831.588s
[2K
| Adam | epoch: 011 | loss: 0.17554 - acc: 0.9403 -- iter: 2432/2867
[A[ATraining Step: 977  | total loss: [1m[32m0.18206[0m[0m | time: 839.694s
[2K
| Adam | epoch: 011 | loss: 0.18206 - acc: 0.9431 -- iter: 2464/2867
[A[ATraining Step: 978  | total loss: [1m[32m0.18371[0m[0m | time: 847.820s
[2K
| Adam | epoch: 011 | loss: 0.18371 - acc: 0.9363 -- iter: 2496/2867
[A[ATraining Step: 979  | total loss: [1m[32m0.19812[0m[0m | time: 856.052s
[2K
| Adam | epoch: 011 | loss: 0.19812 - acc: 0.9364 -- iter: 2528/2867
[A[ATraining Step: 980  | total loss: [1m[32m0.20412[0m[0m | time: 864.212s
[2K
| Adam | epoch: 011 | loss: 0.20412 - acc: 0.9334 -- iter: 2560/2867
[A[ATraining Step: 981  | total loss: [1m[32m0.20544[0m[0m | time: 872.240s
[2K
| Adam | epoch: 011 | loss: 0.20544 - acc: 0.9307 -- iter: 2592/2867
[A[ATraining Step: 982  | total loss: [1m[32m0.19451[0m[0m | time: 880.407s
[2K
| Adam | epoch: 011 | loss: 0.19451 - acc: 0.9345 -- iter: 2624/2867
[A[ATraining Step: 983  | total loss: [1m[32m0.17959[0m[0m | time: 888.551s
[2K
| Adam | epoch: 011 | loss: 0.17959 - acc: 0.9410 -- iter: 2656/2867
[A[ATraining Step: 984  | total loss: [1m[32m0.17922[0m[0m | time: 896.455s
[2K
| Adam | epoch: 011 | loss: 0.17922 - acc: 0.9344 -- iter: 2688/2867
[A[ATraining Step: 985  | total loss: [1m[32m0.17343[0m[0m | time: 904.503s
[2K
| Adam | epoch: 011 | loss: 0.17343 - acc: 0.9347 -- iter: 2720/2867
[A[ATraining Step: 986  | total loss: [1m[32m0.16081[0m[0m | time: 912.661s
[2K
| Adam | epoch: 011 | loss: 0.16081 - acc: 0.9413 -- iter: 2752/2867
[A[ATraining Step: 987  | total loss: [1m[32m0.16369[0m[0m | time: 920.689s
[2K
| Adam | epoch: 011 | loss: 0.16369 - acc: 0.9409 -- iter: 2784/2867
[A[ATraining Step: 988  | total loss: [1m[32m0.15400[0m[0m | time: 928.620s
[2K
| Adam | epoch: 011 | loss: 0.15400 - acc: 0.9437 -- iter: 2816/2867
[A[ATraining Step: 989  | total loss: [1m[32m0.15586[0m[0m | time: 936.656s
[2K
| Adam | epoch: 011 | loss: 0.15586 - acc: 0.9462 -- iter: 2848/2867
[A[ATraining Step: 990  | total loss: [1m[32m0.15295[0m[0m | time: 985.619s
[2K
| Adam | epoch: 011 | loss: 0.15295 - acc: 0.9453 | val_loss: 0.81968 - val_acc: 0.7380 -- iter: 2867/2867
--
Training Step: 991  | total loss: [1m[32m0.15032[0m[0m | time: 8.064s
[2K
| Adam | epoch: 012 | loss: 0.15032 - acc: 0.9445 -- iter: 0032/2867
[A[ATraining Step: 992  | total loss: [1m[32m0.17361[0m[0m | time: 16.143s
[2K
| Adam | epoch: 012 | loss: 0.17361 - acc: 0.9376 -- iter: 0064/2867
[A[ATraining Step: 993  | total loss: [1m[32m0.18898[0m[0m | time: 24.189s
[2K
| Adam | epoch: 012 | loss: 0.18898 - acc: 0.9313 -- iter: 0096/2867
[A[ATraining Step: 994  | total loss: [1m[32m0.17725[0m[0m | time: 32.285s
[2K
| Adam | epoch: 012 | loss: 0.17725 - acc: 0.9382 -- iter: 0128/2867
[A[ATraining Step: 995  | total loss: [1m[32m0.17320[0m[0m | time: 40.337s
[2K
| Adam | epoch: 012 | loss: 0.17320 - acc: 0.9381 -- iter: 0160/2867
[A[ATraining Step: 996  | total loss: [1m[32m0.16901[0m[0m | time: 48.427s
[2K
| Adam | epoch: 012 | loss: 0.16901 - acc: 0.9381 -- iter: 0192/2867
[A[ATraining Step: 997  | total loss: [1m[32m0.15934[0m[0m | time: 56.508s
[2K
| Adam | epoch: 012 | loss: 0.15934 - acc: 0.9443 -- iter: 0224/2867
[A[ATraining Step: 998  | total loss: [1m[32m0.15775[0m[0m | time: 64.849s
[2K
| Adam | epoch: 012 | loss: 0.15775 - acc: 0.9467 -- iter: 0256/2867
[A[ATraining Step: 999  | total loss: [1m[32m0.17946[0m[0m | time: 72.988s
[2K
| Adam | epoch: 012 | loss: 0.17946 - acc: 0.9395 -- iter: 0288/2867
[A[ATraining Step: 1000  | total loss: [1m[32m0.16703[0m[0m | time: 119.547s
[2K
| Adam | epoch: 012 | loss: 0.16703 - acc: 0.9456 | val_loss: 2.22225 - val_acc: 0.5764 -- iter: 0320/2867
--
Training Step: 1001  | total loss: [1m[32m0.15524[0m[0m | time: 124.945s
[2K
| Adam | epoch: 012 | loss: 0.15524 - acc: 0.9510 -- iter: 0352/2867
[A[ATraining Step: 1002  | total loss: [1m[32m0.14253[0m[0m | time: 132.958s
[2K
| Adam | epoch: 012 | loss: 0.14253 - acc: 0.9559 -- iter: 0384/2867
[A[ATraining Step: 1003  | total loss: [1m[32m0.18486[0m[0m | time: 141.165s
[2K
| Adam | epoch: 012 | loss: 0.18486 - acc: 0.9385 -- iter: 0416/2867
[A[ATraining Step: 1004  | total loss: [1m[32m0.17713[0m[0m | time: 149.250s
[2K
| Adam | epoch: 012 | loss: 0.17713 - acc: 0.9415 -- iter: 0448/2867
[A[ATraining Step: 1005  | total loss: [1m[32m0.18694[0m[0m | time: 157.375s
[2K
| Adam | epoch: 012 | loss: 0.18694 - acc: 0.9380 -- iter: 0480/2867
[A[ATraining Step: 1006  | total loss: [1m[32m0.17574[0m[0m | time: 165.434s
[2K
| Adam | epoch: 012 | loss: 0.17574 - acc: 0.9379 -- iter: 0512/2867
[A[ATraining Step: 1007  | total loss: [1m[32m0.17296[0m[0m | time: 178.157s
[2K
| Adam | epoch: 012 | loss: 0.17296 - acc: 0.9379 -- iter: 0544/2867
[A[ATraining Step: 1008  | total loss: [1m[32m0.16792[0m[0m | time: 190.716s
[2K
| Adam | epoch: 012 | loss: 0.16792 - acc: 0.9347 -- iter: 0576/2867
[A[ATraining Step: 1009  | total loss: [1m[32m0.16005[0m[0m | time: 204.459s
[2K
| Adam | epoch: 012 | loss: 0.16005 - acc: 0.9350 -- iter: 0608/2867
[A[ATraining Step: 1010  | total loss: [1m[32m0.15180[0m[0m | time: 218.752s
[2K
| Adam | epoch: 012 | loss: 0.15180 - acc: 0.9384 -- iter: 0640/2867
[A[ATraining Step: 1011  | total loss: [1m[32m0.15823[0m[0m | time: 231.999s
[2K
| Adam | epoch: 012 | loss: 0.15823 - acc: 0.9352 -- iter: 0672/2867
[A[ATraining Step: 1012  | total loss: [1m[32m0.14617[0m[0m | time: 245.865s
[2K
| Adam | epoch: 012 | loss: 0.14617 - acc: 0.9416 -- iter: 0704/2867
[A[ATraining Step: 1013  | total loss: [1m[32m0.14272[0m[0m | time: 259.952s
[2K
| Adam | epoch: 012 | loss: 0.14272 - acc: 0.9443 -- iter: 0736/2867
[A[ATraining Step: 1014  | total loss: [1m[32m0.13968[0m[0m | time: 274.214s
[2K
| Adam | epoch: 012 | loss: 0.13968 - acc: 0.9468 -- iter: 0768/2867
[A[ATraining Step: 1015  | total loss: [1m[32m0.15299[0m[0m | time: 287.700s
[2K
| Adam | epoch: 012 | loss: 0.15299 - acc: 0.9459 -- iter: 0800/2867
[A[ATraining Step: 1016  | total loss: [1m[32m0.15201[0m[0m | time: 296.565s
[2K
| Adam | epoch: 012 | loss: 0.15201 - acc: 0.9450 -- iter: 0832/2867
[A[ATraining Step: 1017  | total loss: [1m[32m0.15380[0m[0m | time: 307.952s
[2K
| Adam | epoch: 012 | loss: 0.15380 - acc: 0.9443 -- iter: 0864/2867
[A[ATraining Step: 1018  | total loss: [1m[32m0.14963[0m[0m | time: 316.090s
[2K
| Adam | epoch: 012 | loss: 0.14963 - acc: 0.9436 -- iter: 0896/2867
[A[ATraining Step: 1019  | total loss: [1m[32m0.13886[0m[0m | time: 324.085s
[2K
| Adam | epoch: 012 | loss: 0.13886 - acc: 0.9492 -- iter: 0928/2867
[A[ATraining Step: 1020  | total loss: [1m[32m0.13071[0m[0m | time: 332.315s
[2K
| Adam | epoch: 012 | loss: 0.13071 - acc: 0.9512 -- iter: 0960/2867
[A[ATraining Step: 1021  | total loss: [1m[32m0.13273[0m[0m | time: 340.633s
[2K
| Adam | epoch: 012 | loss: 0.13273 - acc: 0.9498 -- iter: 0992/2867
[A[ATraining Step: 1022  | total loss: [1m[32m0.12756[0m[0m | time: 353.452s
[2K
| Adam | epoch: 012 | loss: 0.12756 - acc: 0.9517 -- iter: 1024/2867
[A[ATraining Step: 1023  | total loss: [1m[32m0.13034[0m[0m | time: 367.090s
[2K
| Adam | epoch: 012 | loss: 0.13034 - acc: 0.9472 -- iter: 1056/2867
[A[ATraining Step: 1024  | total loss: [1m[32m0.12890[0m[0m | time: 380.531s
[2K
| Adam | epoch: 012 | loss: 0.12890 - acc: 0.9462 -- iter: 1088/2867
[A[ATraining Step: 1025  | total loss: [1m[32m0.13320[0m[0m | time: 394.451s
[2K
| Adam | epoch: 012 | loss: 0.13320 - acc: 0.9453 -- iter: 1120/2867
[A[ATraining Step: 1026  | total loss: [1m[32m0.13995[0m[0m | time: 408.035s
[2K
| Adam | epoch: 012 | loss: 0.13995 - acc: 0.9414 -- iter: 1152/2867
[A[ATraining Step: 1027  | total loss: [1m[32m0.12942[0m[0m | time: 421.384s
[2K
| Adam | epoch: 012 | loss: 0.12942 - acc: 0.9473 -- iter: 1184/2867
[A[ATraining Step: 1028  | total loss: [1m[32m0.13614[0m[0m | time: 435.012s
[2K
| Adam | epoch: 012 | loss: 0.13614 - acc: 0.9494 -- iter: 1216/2867
[A[ATraining Step: 1029  | total loss: [1m[32m0.12993[0m[0m | time: 448.374s
[2K
| Adam | epoch: 012 | loss: 0.12993 - acc: 0.9514 -- iter: 1248/2867
[A[ATraining Step: 1030  | total loss: [1m[32m0.13114[0m[0m | time: 462.406s
[2K
| Adam | epoch: 012 | loss: 0.13114 - acc: 0.9500 -- iter: 1280/2867
[A[ATraining Step: 1031  | total loss: [1m[32m0.12643[0m[0m | time: 473.454s
[2K
| Adam | epoch: 012 | loss: 0.12643 - acc: 0.9487 -- iter: 1312/2867
[A[ATraining Step: 1032  | total loss: [1m[32m0.13419[0m[0m | time: 481.830s
[2K
| Adam | epoch: 012 | loss: 0.13419 - acc: 0.9476 -- iter: 1344/2867
[A[ATraining Step: 1033  | total loss: [1m[32m0.13837[0m[0m | time: 490.090s
[2K
| Adam | epoch: 012 | loss: 0.13837 - acc: 0.9435 -- iter: 1376/2867
[A[ATraining Step: 1034  | total loss: [1m[32m0.15060[0m[0m | time: 501.190s
[2K
| Adam | epoch: 012 | loss: 0.15060 - acc: 0.9366 -- iter: 1408/2867
[A[ATraining Step: 1035  | total loss: [1m[32m0.15612[0m[0m | time: 515.206s
[2K
| Adam | epoch: 012 | loss: 0.15612 - acc: 0.9305 -- iter: 1440/2867
[A[ATraining Step: 1036  | total loss: [1m[32m0.14674[0m[0m | time: 528.817s
[2K
| Adam | epoch: 012 | loss: 0.14674 - acc: 0.9343 -- iter: 1472/2867
[A[ATraining Step: 1037  | total loss: [1m[32m0.15493[0m[0m | time: 542.557s
[2K
| Adam | epoch: 012 | loss: 0.15493 - acc: 0.9284 -- iter: 1504/2867
[A[ATraining Step: 1038  | total loss: [1m[32m0.15432[0m[0m | time: 555.964s
[2K
| Adam | epoch: 012 | loss: 0.15432 - acc: 0.9261 -- iter: 1536/2867
[A[ATraining Step: 1039  | total loss: [1m[32m0.15312[0m[0m | time: 569.785s
[2K
| Adam | epoch: 012 | loss: 0.15312 - acc: 0.9273 -- iter: 1568/2867
[A[ATraining Step: 1040  | total loss: [1m[32m0.15065[0m[0m | time: 583.682s
[2K
| Adam | epoch: 012 | loss: 0.15065 - acc: 0.9252 -- iter: 1600/2867
[A[ATraining Step: 1041  | total loss: [1m[32m0.14299[0m[0m | time: 597.455s
[2K
| Adam | epoch: 012 | loss: 0.14299 - acc: 0.9295 -- iter: 1632/2867
[A[ATraining Step: 1042  | total loss: [1m[32m0.14667[0m[0m | time: 611.299s
[2K
| Adam | epoch: 012 | loss: 0.14667 - acc: 0.9335 -- iter: 1664/2867
[A[ATraining Step: 1043  | total loss: [1m[32m0.14213[0m[0m | time: 619.774s
[2K
| Adam | epoch: 012 | loss: 0.14213 - acc: 0.9370 -- iter: 1696/2867
[A[ATraining Step: 1044  | total loss: [1m[32m0.16964[0m[0m | time: 627.891s
[2K
| Adam | epoch: 012 | loss: 0.16964 - acc: 0.9277 -- iter: 1728/2867
[A[ATraining Step: 1045  | total loss: [1m[32m0.17146[0m[0m | time: 637.249s
[2K
| Adam | epoch: 012 | loss: 0.17146 - acc: 0.9318 -- iter: 1760/2867
[A[ATraining Step: 1046  | total loss: [1m[32m0.16514[0m[0m | time: 649.736s
[2K
| Adam | epoch: 012 | loss: 0.16514 - acc: 0.9355 -- iter: 1792/2867
[A[ATraining Step: 1047  | total loss: [1m[32m0.15397[0m[0m | time: 661.960s
[2K
| Adam | epoch: 012 | loss: 0.15397 - acc: 0.9419 -- iter: 1824/2867
[A[ATraining Step: 1048  | total loss: [1m[32m0.14594[0m[0m | time: 675.001s
[2K
| Adam | epoch: 012 | loss: 0.14594 - acc: 0.9446 -- iter: 1856/2867
[A[ATraining Step: 1049  | total loss: [1m[32m0.14886[0m[0m | time: 688.825s
[2K
| Adam | epoch: 012 | loss: 0.14886 - acc: 0.9439 -- iter: 1888/2867
[A[ATraining Step: 1050  | total loss: [1m[32m0.14954[0m[0m | time: 702.506s
[2K
| Adam | epoch: 012 | loss: 0.14954 - acc: 0.9433 -- iter: 1920/2867
[A[ATraining Step: 1051  | total loss: [1m[32m0.13843[0m[0m | time: 717.074s
[2K
| Adam | epoch: 012 | loss: 0.13843 - acc: 0.9489 -- iter: 1952/2867
[A[ATraining Step: 1052  | total loss: [1m[32m0.14886[0m[0m | time: 730.708s
[2K
| Adam | epoch: 012 | loss: 0.14886 - acc: 0.9447 -- iter: 1984/2867
[A[ATraining Step: 1053  | total loss: [1m[32m0.14804[0m[0m | time: 744.530s
[2K
| Adam | epoch: 012 | loss: 0.14804 - acc: 0.9408 -- iter: 2016/2867
[A[ATraining Step: 1054  | total loss: [1m[32m0.15259[0m[0m | time: 757.598s
[2K
| Adam | epoch: 012 | loss: 0.15259 - acc: 0.9342 -- iter: 2048/2867
[A[ATraining Step: 1055  | total loss: [1m[32m0.15563[0m[0m | time: 765.754s
[2K
| Adam | epoch: 012 | loss: 0.15563 - acc: 0.9346 -- iter: 2080/2867
[A[ATraining Step: 1056  | total loss: [1m[32m0.14808[0m[0m | time: 773.759s
[2K
| Adam | epoch: 012 | loss: 0.14808 - acc: 0.9380 -- iter: 2112/2867
[A[ATraining Step: 1057  | total loss: [1m[32m0.16137[0m[0m | time: 781.915s
[2K
| Adam | epoch: 012 | loss: 0.16137 - acc: 0.9286 -- iter: 2144/2867
[A[ATraining Step: 1058  | total loss: [1m[32m0.15625[0m[0m | time: 789.926s
[2K
| Adam | epoch: 012 | loss: 0.15625 - acc: 0.9295 -- iter: 2176/2867
[A[ATraining Step: 1059  | total loss: [1m[32m0.15413[0m[0m | time: 803.574s
[2K
| Adam | epoch: 012 | loss: 0.15413 - acc: 0.9303 -- iter: 2208/2867
[A[ATraining Step: 1060  | total loss: [1m[32m0.26626[0m[0m | time: 816.458s
[2K
| Adam | epoch: 012 | loss: 0.26626 - acc: 0.9091 -- iter: 2240/2867
[A[ATraining Step: 1061  | total loss: [1m[32m0.25787[0m[0m | time: 829.033s
[2K
| Adam | epoch: 012 | loss: 0.25787 - acc: 0.9151 -- iter: 2272/2867
[A[ATraining Step: 1062  | total loss: [1m[32m0.25542[0m[0m | time: 842.627s
[2K
| Adam | epoch: 012 | loss: 0.25542 - acc: 0.9111 -- iter: 2304/2867
[A[ATraining Step: 1063  | total loss: [1m[32m0.24194[0m[0m | time: 856.600s
[2K
| Adam | epoch: 012 | loss: 0.24194 - acc: 0.9168 -- iter: 2336/2867
[A[ATraining Step: 1064  | total loss: [1m[32m0.24505[0m[0m | time: 872.342s
[2K
| Adam | epoch: 012 | loss: 0.24505 - acc: 0.9126 -- iter: 2368/2867
[A[ATraining Step: 1065  | total loss: [1m[32m0.23454[0m[0m | time: 887.746s
[2K
| Adam | epoch: 012 | loss: 0.23454 - acc: 0.9120 -- iter: 2400/2867
[A[ATraining Step: 1066  | total loss: [1m[32m0.21940[0m[0m | time: 972.638s
[2K
| Adam | epoch: 012 | loss: 0.21940 - acc: 0.9177 -- iter: 2432/2867
[A[ATraining Step: 1067  | total loss: [1m[32m0.21998[0m[0m | time: 1007.875s
[2K
| Adam | epoch: 012 | loss: 0.21998 - acc: 0.9165 -- iter: 2464/2867
[A[ATraining Step: 1068  | total loss: [1m[32m0.20669[0m[0m | time: 1021.692s
[2K
| Adam | epoch: 012 | loss: 0.20669 - acc: 0.9218 -- iter: 2496/2867
[A[ATraining Step: 1069  | total loss: [1m[32m0.21544[0m[0m | time: 1035.876s
[2K
| Adam | epoch: 012 | loss: 0.21544 - acc: 0.9202 -- iter: 2528/2867
[A[ATraining Step: 1070  | total loss: [1m[32m0.20634[0m[0m | time: 1050.090s
[2K
| Adam | epoch: 012 | loss: 0.20634 - acc: 0.9219 -- iter: 2560/2867
[A[ATraining Step: 1071  | total loss: [1m[32m0.19599[0m[0m | time: 1067.948s
[2K
| Adam | epoch: 012 | loss: 0.19599 - acc: 0.9235 -- iter: 2592/2867
[A[ATraining Step: 1072  | total loss: [1m[32m0.18918[0m[0m | time: 1085.134s
[2K
| Adam | epoch: 012 | loss: 0.18918 - acc: 0.9249 -- iter: 2624/2867
[A[ATraining Step: 1073  | total loss: [1m[32m0.19229[0m[0m | time: 1098.905s
[2K
| Adam | epoch: 012 | loss: 0.19229 - acc: 0.9262 -- iter: 2656/2867
[A[ATraining Step: 1074  | total loss: [1m[32m0.17841[0m[0m | time: 1109.390s
[2K
| Adam | epoch: 012 | loss: 0.17841 - acc: 0.9335 -- iter: 2688/2867
[A[ATraining Step: 1075  | total loss: [1m[32m0.17390[0m[0m | time: 1120.445s
[2K
| Adam | epoch: 012 | loss: 0.17390 - acc: 0.9371 -- iter: 2720/2867
[A[ATraining Step: 1076  | total loss: [1m[32m0.19551[0m[0m | time: 1128.546s
[2K
| Adam | epoch: 012 | loss: 0.19551 - acc: 0.9309 -- iter: 2752/2867
[A[ATraining Step: 1077  | total loss: [1m[32m0.18868[0m[0m | time: 1136.706s
[2K
| Adam | epoch: 012 | loss: 0.18868 - acc: 0.9346 -- iter: 2784/2867
[A[ATraining Step: 1078  | total loss: [1m[32m0.19098[0m[0m | time: 1145.234s
[2K
| Adam | epoch: 012 | loss: 0.19098 - acc: 0.9287 -- iter: 2816/2867
[A[ATraining Step: 1079  | total loss: [1m[32m0.18693[0m[0m | time: 1153.813s
[2K
| Adam | epoch: 012 | loss: 0.18693 - acc: 0.9264 -- iter: 2848/2867
[A[ATraining Step: 1080  | total loss: [1m[32m0.17384[0m[0m | time: 1238.607s
[2K
| Adam | epoch: 012 | loss: 0.17384 - acc: 0.9307 | val_loss: 1.75723 - val_acc: 0.5920 -- iter: 2867/2867
--
Training Step: 1081  | total loss: [1m[32m0.18190[0m[0m | time: 9.786s
[2K
| Adam | epoch: 013 | loss: 0.18190 - acc: 0.9282 -- iter: 0032/2867
[A[ATraining Step: 1082  | total loss: [1m[32m0.18823[0m[0m | time: 17.924s
[2K
| Adam | epoch: 013 | loss: 0.18823 - acc: 0.9229 -- iter: 0064/2867
[A[ATraining Step: 1083  | total loss: [1m[32m0.18077[0m[0m | time: 27.710s
[2K
| Adam | epoch: 013 | loss: 0.18077 - acc: 0.9244 -- iter: 0096/2867
[A[ATraining Step: 1084  | total loss: [1m[32m0.18451[0m[0m | time: 40.784s
[2K
| Adam | epoch: 013 | loss: 0.18451 - acc: 0.9257 -- iter: 0128/2867
[A[ATraining Step: 1085  | total loss: [1m[32m0.17102[0m[0m | time: 54.945s
[2K
| Adam | epoch: 013 | loss: 0.17102 - acc: 0.9300 -- iter: 0160/2867
[A[ATraining Step: 1086  | total loss: [1m[32m0.17242[0m[0m | time: 68.978s
[2K
| Adam | epoch: 013 | loss: 0.17242 - acc: 0.9276 -- iter: 0192/2867
[A[ATraining Step: 1087  | total loss: [1m[32m0.16195[0m[0m | time: 82.657s
[2K
| Adam | epoch: 013 | loss: 0.16195 - acc: 0.9317 -- iter: 0224/2867
[A[ATraining Step: 1088  | total loss: [1m[32m0.15137[0m[0m | time: 96.647s
[2K
| Adam | epoch: 013 | loss: 0.15137 - acc: 0.9386 -- iter: 0256/2867
[A[ATraining Step: 1089  | total loss: [1m[32m0.15028[0m[0m | time: 110.492s
[2K
| Adam | epoch: 013 | loss: 0.15028 - acc: 0.9384 -- iter: 0288/2867
[A[ATraining Step: 1090  | total loss: [1m[32m0.15608[0m[0m | time: 124.365s
[2K
| Adam | epoch: 013 | loss: 0.15608 - acc: 0.9384 -- iter: 0320/2867
[A[ATraining Step: 1091  | total loss: [1m[32m0.16454[0m[0m | time: 133.592s
[2K
| Adam | epoch: 013 | loss: 0.16454 - acc: 0.9383 -- iter: 0352/2867
[A[ATraining Step: 1092  | total loss: [1m[32m0.15516[0m[0m | time: 141.481s
[2K
| Adam | epoch: 013 | loss: 0.15516 - acc: 0.9392 -- iter: 0384/2867
[A[ATraining Step: 1093  | total loss: [1m[32m0.14367[0m[0m | time: 149.673s
[2K
| Adam | epoch: 013 | loss: 0.14367 - acc: 0.9453 -- iter: 0416/2867
[A[ATraining Step: 1094  | total loss: [1m[32m0.14011[0m[0m | time: 158.015s
[2K
| Adam | epoch: 013 | loss: 0.14011 - acc: 0.9445 -- iter: 0448/2867
[A[ATraining Step: 1095  | total loss: [1m[32m0.13884[0m[0m | time: 171.150s
[2K
| Adam | epoch: 013 | loss: 0.13884 - acc: 0.9469 -- iter: 0480/2867
[A[ATraining Step: 1096  | total loss: [1m[32m0.13858[0m[0m | time: 184.328s
[2K
| Adam | epoch: 013 | loss: 0.13858 - acc: 0.9460 -- iter: 0512/2867
[A[ATraining Step: 1097  | total loss: [1m[32m0.13179[0m[0m | time: 198.001s
[2K
| Adam | epoch: 013 | loss: 0.13179 - acc: 0.9482 -- iter: 0544/2867
[A[ATraining Step: 1098  | total loss: [1m[32m0.14432[0m[0m | time: 212.611s
[2K
| Adam | epoch: 013 | loss: 0.14432 - acc: 0.9440 -- iter: 0576/2867
[A[ATraining Step: 1099  | total loss: [1m[32m0.15120[0m[0m | time: 226.246s
[2K
| Adam | epoch: 013 | loss: 0.15120 - acc: 0.9434 -- iter: 0608/2867
[A[ATraining Step: 1100  | total loss: [1m[32m0.14982[0m[0m | time: 239.779s
[2K
| Adam | epoch: 013 | loss: 0.14982 - acc: 0.9428 -- iter: 0640/2867
[A[ATraining Step: 1101  | total loss: [1m[32m0.14020[0m[0m | time: 253.529s
[2K
| Adam | epoch: 013 | loss: 0.14020 - acc: 0.9485 -- iter: 0672/2867
[A[ATraining Step: 1102  | total loss: [1m[32m0.13077[0m[0m | time: 267.472s
[2K
| Adam | epoch: 013 | loss: 0.13077 - acc: 0.9537 -- iter: 0704/2867
[A[ATraining Step: 1103  | total loss: [1m[32m0.12357[0m[0m | time: 278.602s
[2K
| Adam | epoch: 013 | loss: 0.12357 - acc: 0.9583 -- iter: 0736/2867
[A[ATraining Step: 1104  | total loss: [1m[32m0.11942[0m[0m | time: 286.983s
[2K
| Adam | epoch: 013 | loss: 0.11942 - acc: 0.9593 -- iter: 0768/2867
[A[ATraining Step: 1105  | total loss: [1m[32m0.12216[0m[0m | time: 295.261s
[2K
| Adam | epoch: 013 | loss: 0.12216 - acc: 0.9540 -- iter: 0800/2867
[A[ATraining Step: 1106  | total loss: [1m[32m0.11201[0m[0m | time: 308.928s
[2K
| Adam | epoch: 013 | loss: 0.11201 - acc: 0.9586 -- iter: 0832/2867
[A[ATraining Step: 1107  | total loss: [1m[32m0.10971[0m[0m | time: 322.429s
[2K
| Adam | epoch: 013 | loss: 0.10971 - acc: 0.9596 -- iter: 0864/2867
[A[ATraining Step: 1108  | total loss: [1m[32m0.10904[0m[0m | time: 336.080s
[2K
| Adam | epoch: 013 | loss: 0.10904 - acc: 0.9606 -- iter: 0896/2867
[A[ATraining Step: 1109  | total loss: [1m[32m0.11411[0m[0m | time: 350.164s
[2K
| Adam | epoch: 013 | loss: 0.11411 - acc: 0.9614 -- iter: 0928/2867
[A[ATraining Step: 1110  | total loss: [1m[32m0.11780[0m[0m | time: 363.506s
[2K
| Adam | epoch: 013 | loss: 0.11780 - acc: 0.9590 -- iter: 0960/2867
[A[ATraining Step: 1111  | total loss: [1m[32m0.12493[0m[0m | time: 377.531s
[2K
| Adam | epoch: 013 | loss: 0.12493 - acc: 0.9600 -- iter: 0992/2867
[A[ATraining Step: 1112  | total loss: [1m[32m0.11536[0m[0m | time: 391.442s
[2K
| Adam | epoch: 013 | loss: 0.11536 - acc: 0.9640 -- iter: 1024/2867
[A[ATraining Step: 1113  | total loss: [1m[32m0.13297[0m[0m | time: 404.902s
[2K
| Adam | epoch: 013 | loss: 0.13297 - acc: 0.9613 -- iter: 1056/2867
[A[ATraining Step: 1114  | total loss: [1m[32m0.12213[0m[0m | time: 415.797s
[2K
| Adam | epoch: 013 | loss: 0.12213 - acc: 0.9652 -- iter: 1088/2867
[A[ATraining Step: 1115  | total loss: [1m[32m0.12016[0m[0m | time: 424.015s
[2K
| Adam | epoch: 013 | loss: 0.12016 - acc: 0.9655 -- iter: 1120/2867
[A[ATraining Step: 1116  | total loss: [1m[32m0.11339[0m[0m | time: 432.238s
[2K
| Adam | epoch: 013 | loss: 0.11339 - acc: 0.9659 -- iter: 1152/2867
[A[ATraining Step: 1117  | total loss: [1m[32m0.11235[0m[0m | time: 446.264s
[2K
| Adam | epoch: 013 | loss: 0.11235 - acc: 0.9630 -- iter: 1184/2867
[A[ATraining Step: 1118  | total loss: [1m[32m0.14547[0m[0m | time: 459.680s
[2K
| Adam | epoch: 013 | loss: 0.14547 - acc: 0.9449 -- iter: 1216/2867
[A[ATraining Step: 1119  | total loss: [1m[32m0.14879[0m[0m | time: 472.878s
[2K
| Adam | epoch: 013 | loss: 0.14879 - acc: 0.9410 -- iter: 1248/2867
[A[ATraining Step: 1120  | total loss: [1m[32m0.15394[0m[0m | time: 486.779s
[2K
| Adam | epoch: 013 | loss: 0.15394 - acc: 0.9406 -- iter: 1280/2867
[A[ATraining Step: 1121  | total loss: [1m[32m0.14521[0m[0m | time: 500.216s
[2K
| Adam | epoch: 013 | loss: 0.14521 - acc: 0.9435 -- iter: 1312/2867
[A[ATraining Step: 1122  | total loss: [1m[32m0.13514[0m[0m | time: 513.839s
[2K
| Adam | epoch: 013 | loss: 0.13514 - acc: 0.9460 -- iter: 1344/2867
[A[ATraining Step: 1123  | total loss: [1m[32m0.13653[0m[0m | time: 527.609s
[2K
| Adam | epoch: 013 | loss: 0.13653 - acc: 0.9483 -- iter: 1376/2867
[A[ATraining Step: 1124  | total loss: [1m[32m0.12699[0m[0m | time: 541.303s
[2K
| Adam | epoch: 013 | loss: 0.12699 - acc: 0.9534 -- iter: 1408/2867
[A[ATraining Step: 1125  | total loss: [1m[32m0.14273[0m[0m | time: 551.863s
[2K
| Adam | epoch: 013 | loss: 0.14273 - acc: 0.9487 -- iter: 1440/2867
[A[ATraining Step: 1126  | total loss: [1m[32m0.14668[0m[0m | time: 560.108s
[2K
| Adam | epoch: 013 | loss: 0.14668 - acc: 0.9476 -- iter: 1472/2867
[A[ATraining Step: 1127  | total loss: [1m[32m0.16056[0m[0m | time: 568.258s
[2K
| Adam | epoch: 013 | loss: 0.16056 - acc: 0.9372 -- iter: 1504/2867
[A[ATraining Step: 1128  | total loss: [1m[32m0.15819[0m[0m | time: 580.416s
[2K
| Adam | epoch: 013 | loss: 0.15819 - acc: 0.9341 -- iter: 1536/2867
[A[ATraining Step: 1129  | total loss: [1m[32m0.14578[0m[0m | time: 594.350s
[2K
| Adam | epoch: 013 | loss: 0.14578 - acc: 0.9407 -- iter: 1568/2867
[A[ATraining Step: 1130  | total loss: [1m[32m0.14586[0m[0m | time: 608.102s
[2K
| Adam | epoch: 013 | loss: 0.14586 - acc: 0.9373 -- iter: 1600/2867
[A[ATraining Step: 1131  | total loss: [1m[32m0.14506[0m[0m | time: 621.696s
[2K
| Adam | epoch: 013 | loss: 0.14506 - acc: 0.9373 -- iter: 1632/2867
[A[ATraining Step: 1132  | total loss: [1m[32m0.13692[0m[0m | time: 635.690s
[2K
| Adam | epoch: 013 | loss: 0.13692 - acc: 0.9404 -- iter: 1664/2867
[A[ATraining Step: 1133  | total loss: [1m[32m0.12685[0m[0m | time: 649.085s
[2K
| Adam | epoch: 013 | loss: 0.12685 - acc: 0.9464 -- iter: 1696/2867
[A[ATraining Step: 1134  | total loss: [1m[32m0.11783[0m[0m | time: 662.537s
[2K
| Adam | epoch: 013 | loss: 0.11783 - acc: 0.9517 -- iter: 1728/2867
[A[ATraining Step: 1135  | total loss: [1m[32m0.14083[0m[0m | time: 676.214s
[2K
| Adam | epoch: 013 | loss: 0.14083 - acc: 0.9503 -- iter: 1760/2867
[A[ATraining Step: 1136  | total loss: [1m[32m0.14202[0m[0m | time: 688.684s
[2K
| Adam | epoch: 013 | loss: 0.14202 - acc: 0.9459 -- iter: 1792/2867
[A[ATraining Step: 1137  | total loss: [1m[32m0.13697[0m[0m | time: 696.867s
[2K
| Adam | epoch: 013 | loss: 0.13697 - acc: 0.9513 -- iter: 1824/2867
[A[ATraining Step: 1138  | total loss: [1m[32m0.13626[0m[0m | time: 705.047s
[2K
| Adam | epoch: 013 | loss: 0.13626 - acc: 0.9468 -- iter: 1856/2867
[A[ATraining Step: 1139  | total loss: [1m[32m0.13882[0m[0m | time: 718.884s
[2K
| Adam | epoch: 013 | loss: 0.13882 - acc: 0.9459 -- iter: 1888/2867
[A[ATraining Step: 1140  | total loss: [1m[32m0.13444[0m[0m | time: 732.568s
[2K
| Adam | epoch: 013 | loss: 0.13444 - acc: 0.9482 -- iter: 1920/2867
[A[ATraining Step: 1141  | total loss: [1m[32m0.13141[0m[0m | time: 746.198s
[2K
| Adam | epoch: 013 | loss: 0.13141 - acc: 0.9502 -- iter: 1952/2867
[A[ATraining Step: 1142  | total loss: [1m[32m0.13320[0m[0m | time: 759.615s
[2K
| Adam | epoch: 013 | loss: 0.13320 - acc: 0.9490 -- iter: 1984/2867
[A[ATraining Step: 1143  | total loss: [1m[32m0.13802[0m[0m | time: 772.985s
[2K
| Adam | epoch: 013 | loss: 0.13802 - acc: 0.9478 -- iter: 2016/2867
[A[ATraining Step: 1144  | total loss: [1m[32m0.12860[0m[0m | time: 786.233s
[2K
| Adam | epoch: 013 | loss: 0.12860 - acc: 0.9530 -- iter: 2048/2867
[A[ATraining Step: 1145  | total loss: [1m[32m0.12393[0m[0m | time: 799.670s
[2K
| Adam | epoch: 013 | loss: 0.12393 - acc: 0.9546 -- iter: 2080/2867
[A[ATraining Step: 1146  | total loss: [1m[32m0.11626[0m[0m | time: 813.480s
[2K
| Adam | epoch: 013 | loss: 0.11626 - acc: 0.9591 -- iter: 2112/2867
[A[ATraining Step: 1147  | total loss: [1m[32m0.12720[0m[0m | time: 824.691s
[2K
| Adam | epoch: 013 | loss: 0.12720 - acc: 0.9539 -- iter: 2144/2867
[A[ATraining Step: 1148  | total loss: [1m[32m0.12729[0m[0m | time: 832.984s
[2K
| Adam | epoch: 013 | loss: 0.12729 - acc: 0.9522 -- iter: 2176/2867
[A[ATraining Step: 1149  | total loss: [1m[32m0.12412[0m[0m | time: 841.390s
[2K
| Adam | epoch: 013 | loss: 0.12412 - acc: 0.9539 -- iter: 2208/2867
[A[ATraining Step: 1150  | total loss: [1m[32m0.12042[0m[0m | time: 853.887s
[2K
| Adam | epoch: 013 | loss: 0.12042 - acc: 0.9554 -- iter: 2240/2867
[A[ATraining Step: 1151  | total loss: [1m[32m0.20545[0m[0m | time: 867.667s
[2K
| Adam | epoch: 013 | loss: 0.20545 - acc: 0.9473 -- iter: 2272/2867
[A[ATraining Step: 1152  | total loss: [1m[32m0.19531[0m[0m | time: 881.435s
[2K
| Adam | epoch: 013 | loss: 0.19531 - acc: 0.9495 -- iter: 2304/2867
[A[ATraining Step: 1153  | total loss: [1m[32m0.17978[0m[0m | time: 894.881s
[2K
| Adam | epoch: 013 | loss: 0.17978 - acc: 0.9545 -- iter: 2336/2867
[A[ATraining Step: 1154  | total loss: [1m[32m0.16656[0m[0m | time: 909.041s
[2K
| Adam | epoch: 013 | loss: 0.16656 - acc: 0.9559 -- iter: 2368/2867
[A[ATraining Step: 1155  | total loss: [1m[32m0.16085[0m[0m | time: 922.519s
[2K
| Adam | epoch: 013 | loss: 0.16085 - acc: 0.9510 -- iter: 2400/2867
[A[ATraining Step: 1156  | total loss: [1m[32m0.15245[0m[0m | time: 936.063s
[2K
| Adam | epoch: 013 | loss: 0.15245 - acc: 0.9528 -- iter: 2432/2867
[A[ATraining Step: 1157  | total loss: [1m[32m0.15149[0m[0m | time: 949.691s
[2K
| Adam | epoch: 013 | loss: 0.15149 - acc: 0.9544 -- iter: 2464/2867
[A[ATraining Step: 1158  | total loss: [1m[32m0.14000[0m[0m | time: 961.688s
[2K
| Adam | epoch: 013 | loss: 0.14000 - acc: 0.9558 -- iter: 2496/2867
[A[ATraining Step: 1159  | total loss: [1m[32m0.12877[0m[0m | time: 969.831s
[2K
| Adam | epoch: 013 | loss: 0.12877 - acc: 0.9602 -- iter: 2528/2867
[A[ATraining Step: 1160  | total loss: [1m[32m0.13548[0m[0m | time: 978.028s
[2K
| Adam | epoch: 013 | loss: 0.13548 - acc: 0.9548 -- iter: 2560/2867
[A[ATraining Step: 1161  | total loss: [1m[32m0.13052[0m[0m | time: 986.338s
[2K
| Adam | epoch: 013 | loss: 0.13052 - acc: 0.9562 -- iter: 2592/2867
[A[ATraining Step: 1162  | total loss: [1m[32m0.12253[0m[0m | time: 996.704s
[2K
| Adam | epoch: 013 | loss: 0.12253 - acc: 0.9575 -- iter: 2624/2867
[A[ATraining Step: 1163  | total loss: [1m[32m0.11659[0m[0m | time: 1010.630s
[2K
| Adam | epoch: 013 | loss: 0.11659 - acc: 0.9586 -- iter: 2656/2867
[A[ATraining Step: 1164  | total loss: [1m[32m0.11864[0m[0m | time: 1024.364s
[2K
| Adam | epoch: 013 | loss: 0.11864 - acc: 0.9565 -- iter: 2688/2867
[A[ATraining Step: 1165  | total loss: [1m[32m0.11169[0m[0m | time: 1038.400s
[2K
| Adam | epoch: 013 | loss: 0.11169 - acc: 0.9608 -- iter: 2720/2867
[A[ATraining Step: 1166  | total loss: [1m[32m0.11028[0m[0m | time: 1052.023s
[2K
| Adam | epoch: 013 | loss: 0.11028 - acc: 0.9585 -- iter: 2752/2867
[A[ATraining Step: 1167  | total loss: [1m[32m0.10763[0m[0m | time: 1065.510s
[2K
| Adam | epoch: 013 | loss: 0.10763 - acc: 0.9595 -- iter: 2784/2867
[A[ATraining Step: 1168  | total loss: [1m[32m0.10534[0m[0m | time: 1078.861s
[2K
| Adam | epoch: 013 | loss: 0.10534 - acc: 0.9604 -- iter: 2816/2867
[A[ATraining Step: 1169  | total loss: [1m[32m0.09981[0m[0m | time: 1092.298s
[2K
| Adam | epoch: 013 | loss: 0.09981 - acc: 0.9644 -- iter: 2848/2867
[A[ATraining Step: 1170  | total loss: [1m[32m0.09964[0m[0m | time: 1152.006s
[2K
| Adam | epoch: 013 | loss: 0.09964 - acc: 0.9648 | val_loss: 1.82124 - val_acc: 0.6867 -- iter: 2867/2867
--
Training Step: 1171  | total loss: [1m[32m0.09876[0m[0m | time: 13.628s
[2K
| Adam | epoch: 014 | loss: 0.09876 - acc: 0.9652 -- iter: 0032/2867
[A[ATraining Step: 1172  | total loss: [1m[32m0.09938[0m[0m | time: 27.168s
[2K
| Adam | epoch: 014 | loss: 0.09938 - acc: 0.9625 -- iter: 0064/2867
[A[ATraining Step: 1173  | total loss: [1m[32m0.09761[0m[0m | time: 40.206s
[2K
| Adam | epoch: 014 | loss: 0.09761 - acc: 0.9631 -- iter: 0096/2867
[A[ATraining Step: 1174  | total loss: [1m[32m0.09264[0m[0m | time: 53.615s
[2K
| Adam | epoch: 014 | loss: 0.09264 - acc: 0.9637 -- iter: 0128/2867
[A[ATraining Step: 1175  | total loss: [1m[32m0.08475[0m[0m | time: 67.036s
[2K
| Adam | epoch: 014 | loss: 0.08475 - acc: 0.9673 -- iter: 0160/2867
[A[ATraining Step: 1176  | total loss: [1m[32m0.08185[0m[0m | time: 76.997s
[2K
| Adam | epoch: 014 | loss: 0.08185 - acc: 0.9674 -- iter: 0192/2867
[A[ATraining Step: 1177  | total loss: [1m[32m0.09501[0m[0m | time: 85.378s
[2K
| Adam | epoch: 014 | loss: 0.09501 - acc: 0.9613 -- iter: 0224/2867
[A[ATraining Step: 1178  | total loss: [1m[32m0.09792[0m[0m | time: 95.372s
[2K
| Adam | epoch: 014 | loss: 0.09792 - acc: 0.9589 -- iter: 0256/2867
[A[ATraining Step: 1179  | total loss: [1m[32m0.09117[0m[0m | time: 108.576s
[2K
| Adam | epoch: 014 | loss: 0.09117 - acc: 0.9630 -- iter: 0288/2867
[A[ATraining Step: 1180  | total loss: [1m[32m0.10255[0m[0m | time: 121.947s
[2K
| Adam | epoch: 014 | loss: 0.10255 - acc: 0.9542 -- iter: 0320/2867
[A[ATraining Step: 1181  | total loss: [1m[32m0.09792[0m[0m | time: 136.064s
[2K
| Adam | epoch: 014 | loss: 0.09792 - acc: 0.9557 -- iter: 0352/2867
[A[ATraining Step: 1182  | total loss: [1m[32m0.09671[0m[0m | time: 145.013s
[2K
| Adam | epoch: 014 | loss: 0.09671 - acc: 0.9570 -- iter: 0384/2867
[A[ATraining Step: 1183  | total loss: [1m[32m0.09278[0m[0m | time: 153.719s
[2K
| Adam | epoch: 014 | loss: 0.09278 - acc: 0.9613 -- iter: 0416/2867
[A[ATraining Step: 1184  | total loss: [1m[32m0.08588[0m[0m | time: 167.248s
[2K
| Adam | epoch: 014 | loss: 0.08588 - acc: 0.9652 -- iter: 0448/2867
[A[ATraining Step: 1185  | total loss: [1m[32m0.08221[0m[0m | time: 180.643s
[2K
| Adam | epoch: 014 | loss: 0.08221 - acc: 0.9686 -- iter: 0480/2867
[A[ATraining Step: 1186  | total loss: [1m[32m0.07753[0m[0m | time: 194.589s
[2K
| Adam | epoch: 014 | loss: 0.07753 - acc: 0.9718 -- iter: 0512/2867
[A[ATraining Step: 1187  | total loss: [1m[32m0.07241[0m[0m | time: 207.726s
[2K
| Adam | epoch: 014 | loss: 0.07241 - acc: 0.9746 -- iter: 0544/2867
[A[ATraining Step: 1188  | total loss: [1m[32m0.06773[0m[0m | time: 215.908s
[2K
| Adam | epoch: 014 | loss: 0.06773 - acc: 0.9771 -- iter: 0576/2867
[A[ATraining Step: 1189  | total loss: [1m[32m0.07242[0m[0m | time: 224.059s
[2K
| Adam | epoch: 014 | loss: 0.07242 - acc: 0.9763 -- iter: 0608/2867
[A[ATraining Step: 1190  | total loss: [1m[32m0.06801[0m[0m | time: 233.305s
[2K
| Adam | epoch: 014 | loss: 0.06801 - acc: 0.9787 -- iter: 0640/2867
[A[ATraining Step: 1191  | total loss: [1m[32m0.06489[0m[0m | time: 246.424s
[2K
| Adam | epoch: 014 | loss: 0.06489 - acc: 0.9808 -- iter: 0672/2867
[A[ATraining Step: 1192  | total loss: [1m[32m0.06429[0m[0m | time: 259.963s
[2K
| Adam | epoch: 014 | loss: 0.06429 - acc: 0.9827 -- iter: 0704/2867
[A[ATraining Step: 1193  | total loss: [1m[32m0.07365[0m[0m | time: 273.958s
[2K
| Adam | epoch: 014 | loss: 0.07365 - acc: 0.9751 -- iter: 0736/2867
[A[ATraining Step: 1194  | total loss: [1m[32m0.06879[0m[0m | time: 287.855s
[2K
| Adam | epoch: 014 | loss: 0.06879 - acc: 0.9776 -- iter: 0768/2867
[A[ATraining Step: 1195  | total loss: [1m[32m0.06633[0m[0m | time: 300.979s
[2K
| Adam | epoch: 014 | loss: 0.06633 - acc: 0.9798 -- iter: 0800/2867
[A[ATraining Step: 1196  | total loss: [1m[32m0.06969[0m[0m | time: 314.304s
[2K
| Adam | epoch: 014 | loss: 0.06969 - acc: 0.9756 -- iter: 0832/2867
[A[ATraining Step: 1197  | total loss: [1m[32m0.07736[0m[0m | time: 327.579s
[2K
| Adam | epoch: 014 | loss: 0.07736 - acc: 0.9749 -- iter: 0864/2867
[A[ATraining Step: 1198  | total loss: [1m[32m0.08736[0m[0m | time: 340.972s
[2K
| Adam | epoch: 014 | loss: 0.08736 - acc: 0.9680 -- iter: 0896/2867
[A[ATraining Step: 1199  | total loss: [1m[32m0.08879[0m[0m | time: 352.054s
[2K
| Adam | epoch: 014 | loss: 0.08879 - acc: 0.9681 -- iter: 0928/2867
[A[ATraining Step: 1200  | total loss: [1m[32m0.08184[0m[0m | time: 424.091s
[2K
| Adam | epoch: 014 | loss: 0.08184 - acc: 0.9713 | val_loss: 0.73859 - val_acc: 0.8038 -- iter: 0960/2867
--
Training Step: 1201  | total loss: [1m[32m0.08001[0m[0m | time: 438.203s
[2K
| Adam | epoch: 014 | loss: 0.08001 - acc: 0.9710 -- iter: 0992/2867
[A[ATraining Step: 1202  | total loss: [1m[32m0.08145[0m[0m | time: 451.997s
[2K
| Adam | epoch: 014 | loss: 0.08145 - acc: 0.9708 -- iter: 1024/2867
[A[ATraining Step: 1203  | total loss: [1m[32m0.07487[0m[0m | time: 462.225s
[2K
| Adam | epoch: 014 | loss: 0.07487 - acc: 0.9737 -- iter: 1056/2867
[A[ATraining Step: 1204  | total loss: [1m[32m0.07489[0m[0m | time: 470.370s
[2K
| Adam | epoch: 014 | loss: 0.07489 - acc: 0.9732 -- iter: 1088/2867
[A[ATraining Step: 1205  | total loss: [1m[32m0.09202[0m[0m | time: 479.105s
[2K
| Adam | epoch: 014 | loss: 0.09202 - acc: 0.9665 -- iter: 1120/2867
[A[ATraining Step: 1206  | total loss: [1m[32m0.09965[0m[0m | time: 492.487s
[2K
| Adam | epoch: 014 | loss: 0.09965 - acc: 0.9605 -- iter: 1152/2867
[A[ATraining Step: 1207  | total loss: [1m[32m0.09708[0m[0m | time: 505.890s
[2K
| Adam | epoch: 014 | loss: 0.09708 - acc: 0.9613 -- iter: 1184/2867
[A[ATraining Step: 1208  | total loss: [1m[32m0.09251[0m[0m | time: 519.774s
[2K
| Adam | epoch: 014 | loss: 0.09251 - acc: 0.9621 -- iter: 1216/2867
[A[ATraining Step: 1209  | total loss: [1m[32m0.08545[0m[0m | time: 533.269s
[2K
| Adam | epoch: 014 | loss: 0.08545 - acc: 0.9659 -- iter: 1248/2867
[A[ATraining Step: 1210  | total loss: [1m[32m0.08606[0m[0m | time: 546.375s
[2K
| Adam | epoch: 014 | loss: 0.08606 - acc: 0.9630 -- iter: 1280/2867
[A[ATraining Step: 1211  | total loss: [1m[32m0.09369[0m[0m | time: 559.958s
[2K
| Adam | epoch: 014 | loss: 0.09369 - acc: 0.9605 -- iter: 1312/2867
[A[ATraining Step: 1212  | total loss: [1m[32m0.08556[0m[0m | time: 573.865s
[2K
| Adam | epoch: 014 | loss: 0.08556 - acc: 0.9644 -- iter: 1344/2867
[A[ATraining Step: 1213  | total loss: [1m[32m0.09955[0m[0m | time: 587.511s
[2K
| Adam | epoch: 014 | loss: 0.09955 - acc: 0.9555 -- iter: 1376/2867
[A[ATraining Step: 1214  | total loss: [1m[32m0.09826[0m[0m | time: 597.816s
[2K
| Adam | epoch: 014 | loss: 0.09826 - acc: 0.9568 -- iter: 1408/2867
[A[ATraining Step: 1215  | total loss: [1m[32m0.09594[0m[0m | time: 606.135s
[2K
| Adam | epoch: 014 | loss: 0.09594 - acc: 0.9580 -- iter: 1440/2867
[A[ATraining Step: 1216  | total loss: [1m[32m0.09083[0m[0m | time: 615.054s
[2K
| Adam | epoch: 014 | loss: 0.09083 - acc: 0.9591 -- iter: 1472/2867
[A[ATraining Step: 1217  | total loss: [1m[32m0.08499[0m[0m | time: 628.309s
[2K
| Adam | epoch: 014 | loss: 0.08499 - acc: 0.9632 -- iter: 1504/2867
[A[ATraining Step: 1218  | total loss: [1m[32m0.08774[0m[0m | time: 641.456s
[2K
| Adam | epoch: 014 | loss: 0.08774 - acc: 0.9637 -- iter: 1536/2867
[A[ATraining Step: 1219  | total loss: [1m[32m0.08253[0m[0m | time: 654.769s
[2K
| Adam | epoch: 014 | loss: 0.08253 - acc: 0.9642 -- iter: 1568/2867
[A[ATraining Step: 1220  | total loss: [1m[32m0.11225[0m[0m | time: 668.728s
[2K
| Adam | epoch: 014 | loss: 0.11225 - acc: 0.9522 -- iter: 1600/2867
[A[ATraining Step: 1221  | total loss: [1m[32m0.10816[0m[0m | time: 681.775s
[2K
| Adam | epoch: 014 | loss: 0.10816 - acc: 0.9538 -- iter: 1632/2867
[A[ATraining Step: 1222  | total loss: [1m[32m0.11072[0m[0m | time: 695.363s
[2K
| Adam | epoch: 014 | loss: 0.11072 - acc: 0.9522 -- iter: 1664/2867
[A[ATraining Step: 1223  | total loss: [1m[32m0.12544[0m[0m | time: 708.570s
[2K
| Adam | epoch: 014 | loss: 0.12544 - acc: 0.9476 -- iter: 1696/2867
[A[ATraining Step: 1224  | total loss: [1m[32m0.13076[0m[0m | time: 722.228s
[2K
| Adam | epoch: 014 | loss: 0.13076 - acc: 0.9435 -- iter: 1728/2867
[A[ATraining Step: 1225  | total loss: [1m[32m0.13020[0m[0m | time: 733.488s
[2K
| Adam | epoch: 014 | loss: 0.13020 - acc: 0.9460 -- iter: 1760/2867
[A[ATraining Step: 1226  | total loss: [1m[32m0.13170[0m[0m | time: 741.609s
[2K
| Adam | epoch: 014 | loss: 0.13170 - acc: 0.9420 -- iter: 1792/2867
[A[ATraining Step: 1227  | total loss: [1m[32m0.13211[0m[0m | time: 749.685s
[2K
| Adam | epoch: 014 | loss: 0.13211 - acc: 0.9447 -- iter: 1824/2867
[A[ATraining Step: 1228  | total loss: [1m[32m0.12475[0m[0m | time: 757.939s
[2K
| Adam | epoch: 014 | loss: 0.12475 - acc: 0.9471 -- iter: 1856/2867
[A[ATraining Step: 1229  | total loss: [1m[32m0.13742[0m[0m | time: 770.142s
[2K
| Adam | epoch: 014 | loss: 0.13742 - acc: 0.9430 -- iter: 1888/2867
[A[ATraining Step: 1230  | total loss: [1m[32m0.12895[0m[0m | time: 783.950s
[2K
| Adam | epoch: 014 | loss: 0.12895 - acc: 0.9456 -- iter: 1920/2867
[A[ATraining Step: 1231  | total loss: [1m[32m0.14478[0m[0m | time: 797.325s
[2K
| Adam | epoch: 014 | loss: 0.14478 - acc: 0.9417 -- iter: 1952/2867
[A[ATraining Step: 1232  | total loss: [1m[32m0.13227[0m[0m | time: 810.794s
[2K
| Adam | epoch: 014 | loss: 0.13227 - acc: 0.9475 -- iter: 1984/2867
[A[ATraining Step: 1233  | total loss: [1m[32m0.12351[0m[0m | time: 824.052s
[2K
| Adam | epoch: 014 | loss: 0.12351 - acc: 0.9527 -- iter: 2016/2867
[A[ATraining Step: 1234  | total loss: [1m[32m0.13494[0m[0m | time: 837.788s
[2K
| Adam | epoch: 014 | loss: 0.13494 - acc: 0.9481 -- iter: 2048/2867
[A[ATraining Step: 1235  | total loss: [1m[32m0.14108[0m[0m | time: 851.303s
[2K
| Adam | epoch: 014 | loss: 0.14108 - acc: 0.9408 -- iter: 2080/2867
[A[ATraining Step: 1236  | total loss: [1m[32m0.14042[0m[0m | time: 864.940s
[2K
| Adam | epoch: 014 | loss: 0.14042 - acc: 0.9373 -- iter: 2112/2867
[A[ATraining Step: 1237  | total loss: [1m[32m0.14819[0m[0m | time: 877.378s
[2K
| Adam | epoch: 014 | loss: 0.14819 - acc: 0.9405 -- iter: 2144/2867
[A[ATraining Step: 1238  | total loss: [1m[32m0.13808[0m[0m | time: 885.681s
[2K
| Adam | epoch: 014 | loss: 0.13808 - acc: 0.9433 -- iter: 2176/2867
[A[ATraining Step: 1239  | total loss: [1m[32m0.12991[0m[0m | time: 893.909s
[2K
| Adam | epoch: 014 | loss: 0.12991 - acc: 0.9458 -- iter: 2208/2867
[A[ATraining Step: 1240  | total loss: [1m[32m0.13288[0m[0m | time: 904.626s
[2K
| Adam | epoch: 014 | loss: 0.13288 - acc: 0.9419 -- iter: 2240/2867
[A[ATraining Step: 1241  | total loss: [1m[32m0.12710[0m[0m | time: 917.995s
[2K
| Adam | epoch: 014 | loss: 0.12710 - acc: 0.9414 -- iter: 2272/2867
[A[ATraining Step: 1242  | total loss: [1m[32m0.17221[0m[0m | time: 931.544s
[2K
| Adam | epoch: 014 | loss: 0.17221 - acc: 0.9348 -- iter: 2304/2867
[A[ATraining Step: 1243  | total loss: [1m[32m0.15841[0m[0m | time: 945.316s
[2K
| Adam | epoch: 014 | loss: 0.15841 - acc: 0.9413 -- iter: 2336/2867
[A[ATraining Step: 1244  | total loss: [1m[32m0.14981[0m[0m | time: 958.517s
[2K
| Adam | epoch: 014 | loss: 0.14981 - acc: 0.9472 -- iter: 2368/2867
[A[ATraining Step: 1245  | total loss: [1m[32m0.14121[0m[0m | time: 972.082s
[2K
| Adam | epoch: 014 | loss: 0.14121 - acc: 0.9493 -- iter: 2400/2867
[A[ATraining Step: 1246  | total loss: [1m[32m0.13952[0m[0m | time: 985.908s
[2K
| Adam | epoch: 014 | loss: 0.13952 - acc: 0.9513 -- iter: 2432/2867
[A[ATraining Step: 1247  | total loss: [1m[32m0.13654[0m[0m | time: 999.190s
[2K
| Adam | epoch: 014 | loss: 0.13654 - acc: 0.9468 -- iter: 2464/2867
[A[ATraining Step: 1248  | total loss: [1m[32m0.13165[0m[0m | time: 1013.337s
[2K
| Adam | epoch: 014 | loss: 0.13165 - acc: 0.9459 -- iter: 2496/2867
[A[ATraining Step: 1249  | total loss: [1m[32m0.11998[0m[0m | time: 1021.529s
[2K
| Adam | epoch: 014 | loss: 0.11998 - acc: 0.9513 -- iter: 2528/2867
[A[ATraining Step: 1250  | total loss: [1m[32m0.11551[0m[0m | time: 1029.819s
[2K
| Adam | epoch: 014 | loss: 0.11551 - acc: 0.9530 -- iter: 2560/2867
[A[ATraining Step: 1251  | total loss: [1m[32m0.12799[0m[0m | time: 1040.612s
[2K
| Adam | epoch: 014 | loss: 0.12799 - acc: 0.9546 -- iter: 2592/2867
[A[ATraining Step: 1252  | total loss: [1m[32m0.11998[0m[0m | time: 1054.282s
[2K
| Adam | epoch: 014 | loss: 0.11998 - acc: 0.9560 -- iter: 2624/2867
[A[ATraining Step: 1253  | total loss: [1m[32m0.12380[0m[0m | time: 1067.988s
[2K
| Adam | epoch: 014 | loss: 0.12380 - acc: 0.9542 -- iter: 2656/2867
[A[ATraining Step: 1254  | total loss: [1m[32m0.12008[0m[0m | time: 1081.995s
[2K
| Adam | epoch: 014 | loss: 0.12008 - acc: 0.9525 -- iter: 2688/2867
[A[ATraining Step: 1255  | total loss: [1m[32m0.12005[0m[0m | time: 1094.950s
[2K
| Adam | epoch: 014 | loss: 0.12005 - acc: 0.9541 -- iter: 2720/2867
[A[ATraining Step: 1256  | total loss: [1m[32m0.11164[0m[0m | time: 1107.976s
[2K
| Adam | epoch: 014 | loss: 0.11164 - acc: 0.9587 -- iter: 2752/2867
[A[ATraining Step: 1257  | total loss: [1m[32m0.11173[0m[0m | time: 1121.197s
[2K
| Adam | epoch: 014 | loss: 0.11173 - acc: 0.9566 -- iter: 2784/2867
[A[ATraining Step: 1258  | total loss: [1m[32m0.11695[0m[0m | time: 1134.341s
[2K
| Adam | epoch: 014 | loss: 0.11695 - acc: 0.9578 -- iter: 2816/2867
[A[ATraining Step: 1259  | total loss: [1m[32m0.10873[0m[0m | time: 1148.176s
[2K
| Adam | epoch: 014 | loss: 0.10873 - acc: 0.9620 -- iter: 2848/2867
[A[ATraining Step: 1260  | total loss: [1m[32m0.10009[0m[0m | time: 1216.528s
[2K
| Adam | epoch: 014 | loss: 0.10009 - acc: 0.9658 | val_loss: 0.64394 - val_acc: 0.8161 -- iter: 2867/2867
--
Training Step: 1261  | total loss: [1m[32m0.09218[0m[0m | time: 13.691s
[2K
| Adam | epoch: 015 | loss: 0.09218 - acc: 0.9692 -- iter: 0032/2867
[A[ATraining Step: 1262  | total loss: [1m[32m0.09108[0m[0m | time: 24.139s
[2K
| Adam | epoch: 015 | loss: 0.09108 - acc: 0.9692 -- iter: 0064/2867
[A[ATraining Step: 1263  | total loss: [1m[32m0.08517[0m[0m | time: 32.376s
[2K
| Adam | epoch: 015 | loss: 0.08517 - acc: 0.9691 -- iter: 0096/2867
[A[ATraining Step: 1264  | total loss: [1m[32m0.07904[0m[0m | time: 42.031s
[2K
| Adam | epoch: 015 | loss: 0.07904 - acc: 0.9722 -- iter: 0128/2867
[A[ATraining Step: 1265  | total loss: [1m[32m0.07245[0m[0m | time: 55.596s
[2K
| Adam | epoch: 015 | loss: 0.07245 - acc: 0.9750 -- iter: 0160/2867
[A[ATraining Step: 1266  | total loss: [1m[32m0.06743[0m[0m | time: 69.185s
[2K
| Adam | epoch: 015 | loss: 0.06743 - acc: 0.9775 -- iter: 0192/2867
[A[ATraining Step: 1267  | total loss: [1m[32m0.06333[0m[0m | time: 82.993s
[2K
| Adam | epoch: 015 | loss: 0.06333 - acc: 0.9798 -- iter: 0224/2867
[A[ATraining Step: 1268  | total loss: [1m[32m0.05955[0m[0m | time: 96.711s
[2K
| Adam | epoch: 015 | loss: 0.05955 - acc: 0.9818 -- iter: 0256/2867
[A[ATraining Step: 1269  | total loss: [1m[32m0.07020[0m[0m | time: 110.106s
[2K
| Adam | epoch: 015 | loss: 0.07020 - acc: 0.9774 -- iter: 0288/2867
[A[ATraining Step: 1270  | total loss: [1m[32m0.07364[0m[0m | time: 122.954s
[2K
| Adam | epoch: 015 | loss: 0.07364 - acc: 0.9765 -- iter: 0320/2867
[A[ATraining Step: 1271  | total loss: [1m[32m0.07482[0m[0m | time: 136.574s
[2K
| Adam | epoch: 015 | loss: 0.07482 - acc: 0.9726 -- iter: 0352/2867
[A[ATraining Step: 1272  | total loss: [1m[32m0.07574[0m[0m | time: 149.482s
[2K
| Adam | epoch: 015 | loss: 0.07574 - acc: 0.9722 -- iter: 0384/2867
[A[ATraining Step: 1273  | total loss: [1m[32m0.08209[0m[0m | time: 156.558s
[2K
| Adam | epoch: 015 | loss: 0.08209 - acc: 0.9687 -- iter: 0416/2867
[A[ATraining Step: 1274  | total loss: [1m[32m0.08448[0m[0m | time: 162.078s
[2K
| Adam | epoch: 015 | loss: 0.08448 - acc: 0.9666 -- iter: 0448/2867
[A[ATraining Step: 1275  | total loss: [1m[32m0.08040[0m[0m | time: 170.490s
[2K
| Adam | epoch: 015 | loss: 0.08040 - acc: 0.9699 -- iter: 0480/2867
[A[ATraining Step: 1276  | total loss: [1m[32m0.07757[0m[0m | time: 181.574s
[2K
| Adam | epoch: 015 | loss: 0.07757 - acc: 0.9698 -- iter: 0512/2867
[A[ATraining Step: 1277  | total loss: [1m[32m0.07083[0m[0m | time: 195.001s
[2K
| Adam | epoch: 015 | loss: 0.07083 - acc: 0.9728 -- iter: 0544/2867
[A[ATraining Step: 1278  | total loss: [1m[32m0.06518[0m[0m | time: 208.673s
[2K
| Adam | epoch: 015 | loss: 0.06518 - acc: 0.9756 -- iter: 0576/2867
[A[ATraining Step: 1279  | total loss: [1m[32m0.07149[0m[0m | time: 221.882s
[2K
| Adam | epoch: 015 | loss: 0.07149 - acc: 0.9686 -- iter: 0608/2867
[A[ATraining Step: 1280  | total loss: [1m[32m0.06721[0m[0m | time: 235.091s
[2K
| Adam | epoch: 015 | loss: 0.06721 - acc: 0.9718 -- iter: 0640/2867
[A[ATraining Step: 1281  | total loss: [1m[32m0.07556[0m[0m | time: 248.242s
[2K
| Adam | epoch: 015 | loss: 0.07556 - acc: 0.9715 -- iter: 0672/2867
[A[ATraining Step: 1282  | total loss: [1m[32m0.07528[0m[0m | time: 261.874s
[2K
| Adam | epoch: 015 | loss: 0.07528 - acc: 0.9712 -- iter: 0704/2867
[A[ATraining Step: 1283  | total loss: [1m[32m0.07119[0m[0m | time: 275.306s
[2K
| Adam | epoch: 015 | loss: 0.07119 - acc: 0.9709 -- iter: 0736/2867
[A[ATraining Step: 1284  | total loss: [1m[32m0.07088[0m[0m | time: 288.540s
[2K
| Adam | epoch: 015 | loss: 0.07088 - acc: 0.9707 -- iter: 0768/2867
[A[ATraining Step: 1285  | total loss: [1m[32m0.06491[0m[0m | time: 296.822s
[2K
| Adam | epoch: 015 | loss: 0.06491 - acc: 0.9737 -- iter: 0800/2867
[A[ATraining Step: 1286  | total loss: [1m[32m0.06826[0m[0m | time: 304.932s
[2K
| Adam | epoch: 015 | loss: 0.06826 - acc: 0.9700 -- iter: 0832/2867
[A[ATraining Step: 1287  | total loss: [1m[32m0.07143[0m[0m | time: 315.830s
[2K
| Adam | epoch: 015 | loss: 0.07143 - acc: 0.9699 -- iter: 0864/2867
[A[ATraining Step: 1288  | total loss: [1m[32m0.06970[0m[0m | time: 329.451s
[2K
| Adam | epoch: 015 | loss: 0.06970 - acc: 0.9698 -- iter: 0896/2867
[A[ATraining Step: 1289  | total loss: [1m[32m0.07344[0m[0m | time: 342.912s
[2K
| Adam | epoch: 015 | loss: 0.07344 - acc: 0.9697 -- iter: 0928/2867
[A[ATraining Step: 1290  | total loss: [1m[32m0.07760[0m[0m | time: 356.869s
[2K
| Adam | epoch: 015 | loss: 0.07760 - acc: 0.9696 -- iter: 0960/2867
[A[ATraining Step: 1291  | total loss: [1m[32m0.07593[0m[0m | time: 369.895s
[2K
| Adam | epoch: 015 | loss: 0.07593 - acc: 0.9695 -- iter: 0992/2867
[A[ATraining Step: 1292  | total loss: [1m[32m0.07164[0m[0m | time: 383.499s
[2K
| Adam | epoch: 015 | loss: 0.07164 - acc: 0.9726 -- iter: 1024/2867
[A[ATraining Step: 1293  | total loss: [1m[32m0.07176[0m[0m | time: 396.898s
[2K
| Adam | epoch: 015 | loss: 0.07176 - acc: 0.9722 -- iter: 1056/2867
[A[ATraining Step: 1294  | total loss: [1m[32m0.07255[0m[0m | time: 410.227s
[2K
| Adam | epoch: 015 | loss: 0.07255 - acc: 0.9718 -- iter: 1088/2867
[A[ATraining Step: 1295  | total loss: [1m[32m0.06680[0m[0m | time: 423.121s
[2K
| Adam | epoch: 015 | loss: 0.06680 - acc: 0.9747 -- iter: 1120/2867
[A[ATraining Step: 1296  | total loss: [1m[32m0.06859[0m[0m | time: 432.325s
[2K
| Adam | epoch: 015 | loss: 0.06859 - acc: 0.9741 -- iter: 1152/2867
[A[ATraining Step: 1297  | total loss: [1m[32m0.07080[0m[0m | time: 440.787s
[2K
| Adam | epoch: 015 | loss: 0.07080 - acc: 0.9735 -- iter: 1184/2867
[A[ATraining Step: 1298  | total loss: [1m[32m0.07698[0m[0m | time: 451.126s
[2K
| Adam | epoch: 015 | loss: 0.07698 - acc: 0.9668 -- iter: 1216/2867
[A[ATraining Step: 1299  | total loss: [1m[32m0.08113[0m[0m | time: 464.698s
[2K
| Adam | epoch: 015 | loss: 0.08113 - acc: 0.9639 -- iter: 1248/2867
[A[ATraining Step: 1300  | total loss: [1m[32m0.07529[0m[0m | time: 478.587s
[2K
| Adam | epoch: 015 | loss: 0.07529 - acc: 0.9675 -- iter: 1280/2867
[A[ATraining Step: 1301  | total loss: [1m[32m0.07293[0m[0m | time: 492.067s
[2K
| Adam | epoch: 015 | loss: 0.07293 - acc: 0.9676 -- iter: 1312/2867
[A[ATraining Step: 1302  | total loss: [1m[32m0.06795[0m[0m | time: 505.241s
[2K
| Adam | epoch: 015 | loss: 0.06795 - acc: 0.9709 -- iter: 1344/2867
[A[ATraining Step: 1303  | total loss: [1m[32m0.06776[0m[0m | time: 518.639s
[2K
| Adam | epoch: 015 | loss: 0.06776 - acc: 0.9706 -- iter: 1376/2867
[A[ATraining Step: 1304  | total loss: [1m[32m0.06839[0m[0m | time: 532.404s
[2K
| Adam | epoch: 015 | loss: 0.06839 - acc: 0.9705 -- iter: 1408/2867
[A[ATraining Step: 1305  | total loss: [1m[32m0.06726[0m[0m | time: 545.935s
[2K
| Adam | epoch: 015 | loss: 0.06726 - acc: 0.9703 -- iter: 1440/2867
[A[ATraining Step: 1306  | total loss: [1m[32m0.08159[0m[0m | time: 559.109s
[2K
| Adam | epoch: 015 | loss: 0.08159 - acc: 0.9670 -- iter: 1472/2867
[A[ATraining Step: 1307  | total loss: [1m[32m0.08060[0m[0m | time: 569.346s
[2K
| Adam | epoch: 015 | loss: 0.08060 - acc: 0.9641 -- iter: 1504/2867
[A[ATraining Step: 1308  | total loss: [1m[32m0.07572[0m[0m | time: 577.488s
[2K
| Adam | epoch: 015 | loss: 0.07572 - acc: 0.9645 -- iter: 1536/2867
[A[ATraining Step: 1309  | total loss: [1m[32m0.08298[0m[0m | time: 586.949s
[2K
| Adam | epoch: 015 | loss: 0.08298 - acc: 0.9618 -- iter: 1568/2867
[A[ATraining Step: 1310  | total loss: [1m[32m0.08293[0m[0m | time: 599.660s
[2K
| Adam | epoch: 015 | loss: 0.08293 - acc: 0.9625 -- iter: 1600/2867
[A[ATraining Step: 1311  | total loss: [1m[32m0.09764[0m[0m | time: 613.052s
[2K
| Adam | epoch: 015 | loss: 0.09764 - acc: 0.9569 -- iter: 1632/2867
[A[ATraining Step: 1312  | total loss: [1m[32m0.09349[0m[0m | time: 626.984s
[2K
| Adam | epoch: 015 | loss: 0.09349 - acc: 0.9581 -- iter: 1664/2867
[A[ATraining Step: 1313  | total loss: [1m[32m0.08495[0m[0m | time: 639.851s
[2K
| Adam | epoch: 015 | loss: 0.08495 - acc: 0.9623 -- iter: 1696/2867
[A[ATraining Step: 1314  | total loss: [1m[32m0.08275[0m[0m | time: 653.597s
[2K
| Adam | epoch: 015 | loss: 0.08275 - acc: 0.9629 -- iter: 1728/2867
[A[ATraining Step: 1315  | total loss: [1m[32m0.07696[0m[0m | time: 666.743s
[2K
| Adam | epoch: 015 | loss: 0.07696 - acc: 0.9666 -- iter: 1760/2867
[A[ATraining Step: 1316  | total loss: [1m[32m0.07141[0m[0m | time: 680.281s
[2K
| Adam | epoch: 015 | loss: 0.07141 - acc: 0.9700 -- iter: 1792/2867
[A[ATraining Step: 1317  | total loss: [1m[32m0.07199[0m[0m | time: 693.870s
[2K
| Adam | epoch: 015 | loss: 0.07199 - acc: 0.9698 -- iter: 1824/2867
[A[ATraining Step: 1318  | total loss: [1m[32m0.07510[0m[0m | time: 704.210s
[2K
| Adam | epoch: 015 | loss: 0.07510 - acc: 0.9697 -- iter: 1856/2867
[A[ATraining Step: 1319  | total loss: [1m[32m0.07516[0m[0m | time: 712.400s
[2K
| Adam | epoch: 015 | loss: 0.07516 - acc: 0.9696 -- iter: 1888/2867
[A[ATraining Step: 1320  | total loss: [1m[32m0.07947[0m[0m | time: 721.016s
[2K
| Adam | epoch: 015 | loss: 0.07947 - acc: 0.9664 -- iter: 1920/2867
[A[ATraining Step: 1321  | total loss: [1m[32m0.08615[0m[0m | time: 734.419s
[2K
| Adam | epoch: 015 | loss: 0.08615 - acc: 0.9604 -- iter: 1952/2867
[A[ATraining Step: 1322  | total loss: [1m[32m0.08018[0m[0m | time: 746.780s
[2K
| Adam | epoch: 015 | loss: 0.08018 - acc: 0.9644 -- iter: 1984/2867
[A[ATraining Step: 1323  | total loss: [1m[32m0.07407[0m[0m | time: 760.211s
[2K
| Adam | epoch: 015 | loss: 0.07407 - acc: 0.9679 -- iter: 2016/2867
[A[ATraining Step: 1324  | total loss: [1m[32m0.09021[0m[0m | time: 774.586s
[2K
| Adam | epoch: 015 | loss: 0.09021 - acc: 0.9649 -- iter: 2048/2867
[A[ATraining Step: 1325  | total loss: [1m[32m0.08452[0m[0m | time: 787.913s
[2K
| Adam | epoch: 015 | loss: 0.08452 - acc: 0.9684 -- iter: 2080/2867
[A[ATraining Step: 1326  | total loss: [1m[32m0.07773[0m[0m | time: 801.576s
[2K
| Adam | epoch: 015 | loss: 0.07773 - acc: 0.9716 -- iter: 2112/2867
[A[ATraining Step: 1327  | total loss: [1m[32m0.08970[0m[0m | time: 814.923s
[2K
| Adam | epoch: 015 | loss: 0.08970 - acc: 0.9713 -- iter: 2144/2867
[A[ATraining Step: 1328  | total loss: [1m[32m0.09890[0m[0m | time: 828.431s
[2K
| Adam | epoch: 015 | loss: 0.09890 - acc: 0.9679 -- iter: 2176/2867
[A[ATraining Step: 1329  | total loss: [1m[32m0.09336[0m[0m | time: 839.724s
[2K
| Adam | epoch: 015 | loss: 0.09336 - acc: 0.9711 -- iter: 2208/2867
[A[ATraining Step: 1330  | total loss: [1m[32m0.08665[0m[0m | time: 848.310s
[2K
| Adam | epoch: 015 | loss: 0.08665 - acc: 0.9740 -- iter: 2240/2867
[A[ATraining Step: 1331  | total loss: [1m[32m0.08439[0m[0m | time: 856.764s
[2K
| Adam | epoch: 015 | loss: 0.08439 - acc: 0.9735 -- iter: 2272/2867
[A[ATraining Step: 1332  | total loss: [1m[32m0.08005[0m[0m | time: 868.377s
[2K
| Adam | epoch: 015 | loss: 0.08005 - acc: 0.9730 -- iter: 2304/2867
[A[ATraining Step: 1333  | total loss: [1m[32m0.08457[0m[0m | time: 882.267s
[2K
| Adam | epoch: 015 | loss: 0.08457 - acc: 0.9694 -- iter: 2336/2867
[A[ATraining Step: 1334  | total loss: [1m[32m0.07770[0m[0m | time: 895.245s
[2K
| Adam | epoch: 015 | loss: 0.07770 - acc: 0.9725 -- iter: 2368/2867
[A[ATraining Step: 1335  | total loss: [1m[32m0.07215[0m[0m | time: 908.563s
[2K
| Adam | epoch: 015 | loss: 0.07215 - acc: 0.9753 -- iter: 2400/2867
[A[ATraining Step: 1336  | total loss: [1m[32m0.07028[0m[0m | time: 922.501s
[2K
| Adam | epoch: 015 | loss: 0.07028 - acc: 0.9746 -- iter: 2432/2867
[A[ATraining Step: 1337  | total loss: [1m[32m0.06963[0m[0m | time: 936.763s
[2K
| Adam | epoch: 015 | loss: 0.06963 - acc: 0.9740 -- iter: 2464/2867
[A[ATraining Step: 1338  | total loss: [1m[32m0.06603[0m[0m | time: 950.277s
[2K
| Adam | epoch: 015 | loss: 0.06603 - acc: 0.9766 -- iter: 2496/2867
[A[ATraining Step: 1339  | total loss: [1m[32m0.06076[0m[0m | time: 963.292s
[2K
| Adam | epoch: 015 | loss: 0.06076 - acc: 0.9790 -- iter: 2528/2867
[A[ATraining Step: 1340  | total loss: [1m[32m0.05924[0m[0m | time: 976.399s
[2K
| Adam | epoch: 015 | loss: 0.05924 - acc: 0.9779 -- iter: 2560/2867
[A[ATraining Step: 1341  | total loss: [1m[32m0.05548[0m[0m | time: 984.448s
[2K
| Adam | epoch: 015 | loss: 0.05548 - acc: 0.9801 -- iter: 2592/2867
[A[ATraining Step: 1342  | total loss: [1m[32m0.05981[0m[0m | time: 992.875s
[2K
| Adam | epoch: 015 | loss: 0.05981 - acc: 0.9728 -- iter: 2624/2867
[A[ATraining Step: 1343  | total loss: [1m[32m0.05678[0m[0m | time: 1002.443s
[2K
| Adam | epoch: 015 | loss: 0.05678 - acc: 0.9755 -- iter: 2656/2867
[A[ATraining Step: 1344  | total loss: [1m[32m0.05148[0m[0m | time: 1015.433s
[2K
| Adam | epoch: 015 | loss: 0.05148 - acc: 0.9779 -- iter: 2688/2867
[A[ATraining Step: 1345  | total loss: [1m[32m0.04752[0m[0m | time: 1028.611s
[2K
| Adam | epoch: 015 | loss: 0.04752 - acc: 0.9801 -- iter: 2720/2867
[A[ATraining Step: 1346  | total loss: [1m[32m0.04425[0m[0m | time: 1041.756s
[2K
| Adam | epoch: 015 | loss: 0.04425 - acc: 0.9821 -- iter: 2752/2867
[A[ATraining Step: 1347  | total loss: [1m[32m0.04548[0m[0m | time: 1054.718s
[2K
| Adam | epoch: 015 | loss: 0.04548 - acc: 0.9777 -- iter: 2784/2867
[A[ATraining Step: 1348  | total loss: [1m[32m0.04546[0m[0m | time: 1068.063s
[2K
| Adam | epoch: 015 | loss: 0.04546 - acc: 0.9799 -- iter: 2816/2867
[A[ATraining Step: 1349  | total loss: [1m[32m0.04469[0m[0m | time: 1081.088s
[2K
| Adam | epoch: 015 | loss: 0.04469 - acc: 0.9788 -- iter: 2848/2867
[A[ATraining Step: 1350  | total loss: [1m[32m0.04239[0m[0m | time: 1150.166s
[2K
| Adam | epoch: 015 | loss: 0.04239 - acc: 0.9809 | val_loss: 0.76922 - val_acc: 0.8294 -- iter: 2867/2867
--
Validation AUC:0.905286760675669
Validation AUPRC:0.8997063644598512
Test AUC:0.9286403277612593
Test AUPRC:0.9242509615667374
BestTestF1Score	0.86	0.7	0.85	0.83	0.89	403	83	360	51	0.07
BestTestMCCScore	0.85	0.71	0.85	0.89	0.81	366	45	398	88	0.47
BestTestAccuracyScore	0.85	0.71	0.85	0.89	0.81	366	45	398	88	0.47
BestValidationF1Score	0.82	0.65	0.82	0.79	0.85	365	95	375	62	0.07
BestValidationMCC	0.81	0.66	0.83	0.86	0.77	328	52	418	99	0.47
BestValidationAccuracy	0.81	0.66	0.83	0.86	0.77	328	52	418	99	0.47
TestPredictions (Threshold:0.47)
CHEMBL1258114,TP,ACT,0.5799999833106995	CHEMBL2386791,TP,ACT,1.0	CHEMBL1208885,TN,INACT,0.0	CHEMBL2022366,TP,ACT,1.0	CHEMBL3675409,TP,ACT,1.0	CHEMBL1830681,FN,ACT,0.27000001072883606	CHEMBL3685306,TP,ACT,1.0	CHEMBL1161234,TN,INACT,0.0	CHEMBL3298285,TP,ACT,1.0	CHEMBL491574,FN,ACT,0.07999999821186066	CHEMBL3670481,TP,ACT,1.0	CHEMBL593292,TP,ACT,1.0	CHEMBL2046883,TP,ACT,1.0	CHEMBL334248,TN,INACT,0.3499999940395355	CHEMBL1540020,TN,INACT,0.07999999821186066	CHEMBL3714963,FN,ACT,0.0	CHEMBL1091975,TP,ACT,1.0	CHEMBL3115319,TN,INACT,0.009999999776482582	CHEMBL48504,FP,INACT,0.8899999856948853	CHEMBL578061,TP,ACT,0.7900000214576721	CHEMBL2070439,TN,INACT,0.0	CHEMBL569720,FP,INACT,0.9599999785423279	CHEMBL389147,TN,INACT,0.009999999776482582	CHEMBL106379,TN,INACT,0.0	CHEMBL3632674,TN,INACT,0.0	CHEMBL517647,FN,ACT,0.019999999552965164	CHEMBL560301,TP,ACT,0.7900000214576721	CHEMBL1668419,TN,INACT,0.0	CHEMBL1320813,FP,INACT,1.0	CHEMBL309800,TN,INACT,0.0	CHEMBL3675383,FN,ACT,0.0	CHEMBL3109952,FN,ACT,0.05999999865889549	CHEMBL3691660,TN,INACT,0.4699999988079071	CHEMBL1258913,TP,ACT,1.0	CHEMBL3622956,FP,INACT,0.9399999976158142	CHEMBL606000,TP,ACT,0.9800000190734863	CHEMBL3675403,TP,ACT,1.0	CHEMBL2170425,FN,ACT,0.10999999940395355	CHEMBL469776,TN,INACT,0.0	CHEMBL3133821,FN,ACT,0.14000000059604645	CHEMBL3792988,TP,ACT,1.0	CHEMBL2386795,TP,ACT,0.8299999833106995	CHEMBL140891,TN,INACT,0.0	CHEMBL142648,TN,INACT,0.0	CHEMBL486457,TN,INACT,0.0	CHEMBL2163627,TN,INACT,0.11999999731779099	CHEMBL3545110,FP,INACT,1.0	CHEMBL83228,TN,INACT,0.009999999776482582	CHEMBL192668,TN,INACT,0.0	CHEMBL3330133,TP,ACT,1.0	CHEMBL504155,FN,ACT,0.029999999329447746	CHEMBL3676319,TN,INACT,0.009999999776482582	CHEMBL472203,TP,ACT,1.0	CHEMBL1269497,TN,INACT,0.0	CHEMBL3680462,TP,ACT,1.0	CHEMBL271138,TN,INACT,0.0	CHEMBL1086334,TP,ACT,1.0	CHEMBL1098060,FN,ACT,0.44999998807907104	CHEMBL499229,TP,ACT,0.9200000166893005	CHEMBL2409597,FP,INACT,1.0	CHEMBL88812,TN,INACT,0.0	CHEMBL1822646,TP,ACT,1.0	CHEMBL3716523,TP,ACT,0.949999988079071	CHEMBL3609568,TN,INACT,0.0	CHEMBL3706680,TP,ACT,1.0	CHEMBL370670,FP,INACT,0.5600000023841858	CHEMBL2163409,TP,ACT,1.0	CHEMBL2140523,TN,INACT,0.20000000298023224	CHEMBL3685307,TP,ACT,0.9800000190734863	CHEMBL3792712,TP,ACT,0.9900000095367432	CHEMBL491758,TP,ACT,0.8299999833106995	CHEMBL1094135,TP,ACT,0.7300000190734863	CHEMBL3685302,TP,ACT,1.0	CHEMBL472194,TP,ACT,1.0	CHEMBL2425141,TN,INACT,0.0	CHEMBL209849,TP,ACT,0.9800000190734863	CHEMBL28120,TN,INACT,0.0	CHEMBL1258266,FN,ACT,0.20999999344348907	CHEMBL334032,TN,INACT,0.0	CHEMBL1347258,TN,INACT,0.0	CHEMBL1760505,TN,INACT,0.27000001072883606	CHEMBL2425110,TN,INACT,0.0	CHEMBL412278,FP,INACT,0.47999998927116394	CHEMBL1083801,FN,ACT,0.019999999552965164	CHEMBL1173544,TP,ACT,0.8700000047683716	CHEMBL1172418,TN,INACT,0.0	CHEMBL3343311,TP,ACT,1.0	CHEMBL1242846,TN,INACT,0.0	CHEMBL1083786,TP,ACT,0.9900000095367432	CHEMBL1956893,TN,INACT,0.0	CHEMBL3685278,TP,ACT,1.0	CHEMBL2113332,TN,INACT,0.0	CHEMBL3393492,FN,ACT,0.0	CHEMBL2012406,TP,ACT,0.9900000095367432	CHEMBL3680485,TP,ACT,1.0	CHEMBL75049,TN,INACT,0.0	CHEMBL3675503,TP,ACT,1.0	CHEMBL1319281,TN,INACT,0.0	CHEMBL1643138,TP,ACT,1.0	CHEMBL390156,FP,INACT,0.6100000143051147	CHEMBL557050,TN,INACT,0.0	CHEMBL3680579,TP,ACT,0.8299999833106995	CHEMBL3675474,TP,ACT,1.0	CHEMBL1651450,TP,ACT,0.5799999833106995	CHEMBL49120,TN,INACT,0.009999999776482582	CHEMBL2163403,TP,ACT,1.0	CHEMBL405059,TN,INACT,0.0	CHEMBL551633,TP,ACT,0.8199999928474426	CHEMBL478798,TN,INACT,0.009999999776482582	CHEMBL456964,TN,INACT,0.0	CHEMBL2382017,TN,INACT,0.0	CHEMBL2069625,TN,INACT,0.0	CHEMBL258818,TN,INACT,0.0	CHEMBL3680451,TP,ACT,1.0	CHEMBL466154,TN,INACT,0.0	CHEMBL3353406,TN,INACT,0.019999999552965164	CHEMBL3680467,TP,ACT,1.0	CHEMBL76076,TN,INACT,0.0	CHEMBL591050,TN,INACT,0.0	CHEMBL201654,TP,ACT,0.9100000262260437	CHEMBL2170587,TP,ACT,0.7900000214576721	CHEMBL119388,TN,INACT,0.0	CHEMBL2163977,TN,INACT,0.0	CHEMBL598727,TN,INACT,0.0	CHEMBL499172,FP,INACT,0.8899999856948853	CHEMBL2380841,TP,ACT,0.5	CHEMBL3716279,TP,ACT,0.9900000095367432	CHEMBL1083142,TN,INACT,0.0	CHEMBL1428011,TN,INACT,0.0	CHEMBL2022113,TP,ACT,1.0	CHEMBL435054,TN,INACT,0.009999999776482582	CHEMBL134042,TN,INACT,0.0	CHEMBL1079612,TN,INACT,0.0	CHEMBL3675489,TP,ACT,1.0	CHEMBL299763,TN,INACT,0.0	CHEMBL2409594,TN,INACT,0.0	CHEMBL3675500,TP,ACT,1.0	CHEMBL1214854,TP,ACT,0.7200000286102295	CHEMBL1910757,TN,INACT,0.3799999952316284	CHEMBL62701,TN,INACT,0.0	CHEMBL383899,TP,ACT,0.9900000095367432	CHEMBL2012309,TP,ACT,0.7200000286102295	CHEMBL3685264,TP,ACT,0.9399999976158142	CHEMBL1983268,TP,ACT,1.0	CHEMBL2392110,TP,ACT,1.0	CHEMBL1801129,FN,ACT,0.07000000029802322	CHEMBL3360318,TN,INACT,0.17000000178813934	CHEMBL321312,TN,INACT,0.0	CHEMBL1095709,TP,ACT,1.0	CHEMBL565183,TP,ACT,1.0	CHEMBL454973,TN,INACT,0.38999998569488525	CHEMBL3421974,TN,INACT,0.0	CHEMBL427325,TN,INACT,0.0	CHEMBL191003,FN,ACT,0.4399999976158142	CHEMBL1765876,TP,ACT,0.7900000214576721	CHEMBL438610,TN,INACT,0.009999999776482582	CHEMBL1825102,TP,ACT,1.0	CHEMBL1253861,TN,INACT,0.4399999976158142	CHEMBL272198,TP,ACT,1.0	CHEMBL504824,FN,ACT,0.05000000074505806	CHEMBL3680558,TP,ACT,1.0	CHEMBL483451,TP,ACT,0.9900000095367432	CHEMBL1641989,TN,INACT,0.0	CHEMBL3715917,TP,ACT,0.9900000095367432	CHEMBL2398641,TP,ACT,1.0	CHEMBL1783550,TN,INACT,0.0	CHEMBL595615,TP,ACT,1.0	CHEMBL565459,FN,ACT,0.25	CHEMBL77412,TN,INACT,0.009999999776482582	CHEMBL287306,TN,INACT,0.0	CHEMBL3629605,TN,INACT,0.0	CHEMBL3685245,TP,ACT,0.5400000214576721	CHEMBL441811,TN,INACT,0.0	CHEMBL1822642,TP,ACT,1.0	CHEMBL513154,TN,INACT,0.0	CHEMBL215322,TP,ACT,1.0	CHEMBL126077,FN,ACT,0.0	CHEMBL1784656,TN,INACT,0.0	CHEMBL315701,TN,INACT,0.0	CHEMBL1684366,TN,INACT,0.0	CHEMBL3314274,FP,INACT,0.9900000095367432	CHEMBL245377,TN,INACT,0.07999999821186066	CHEMBL196363,FP,INACT,0.8600000143051147	CHEMBL454473,TN,INACT,0.0	CHEMBL3675341,TP,ACT,1.0	CHEMBL491575,TP,ACT,0.9100000262260437	CHEMBL3237169,TP,ACT,0.9900000095367432	CHEMBL3680596,TP,ACT,1.0	CHEMBL293500,TN,INACT,0.09000000357627869	CHEMBL3670429,TP,ACT,1.0	CHEMBL599631,TP,ACT,1.0	CHEMBL523780,TN,INACT,0.0	CHEMBL487892,TP,ACT,1.0	CHEMBL3680487,TP,ACT,1.0	CHEMBL3670500,TP,ACT,1.0	CHEMBL3593285,TP,ACT,1.0	CHEMBL207297,TN,INACT,0.0	CHEMBL120703,TN,INACT,0.09000000357627869	CHEMBL2071201,TP,ACT,0.9900000095367432	CHEMBL314146,TN,INACT,0.0	CHEMBL599210,TP,ACT,1.0	CHEMBL3670472,TP,ACT,1.0	CHEMBL1173522,TP,ACT,1.0	CHEMBL482774,TP,ACT,1.0	CHEMBL491045,FN,ACT,0.0	CHEMBL2029905,TP,ACT,1.0	CHEMBL3716786,TP,ACT,0.9900000095367432	CHEMBL150573,TN,INACT,0.0	CHEMBL2420911,FN,ACT,0.0	CHEMBL2163616,TN,INACT,0.0	CHEMBL3600869,TP,ACT,1.0	CHEMBL2163400,TP,ACT,1.0	CHEMBL3675377,TP,ACT,1.0	CHEMBL199298,FP,INACT,0.9900000095367432	CHEMBL309016,TN,INACT,0.0	CHEMBL3670473,TP,ACT,0.949999988079071	CHEMBL510668,TN,INACT,0.009999999776482582	CHEMBL1241492,TN,INACT,0.0	CHEMBL2163406,TP,ACT,1.0	CHEMBL1499974,TN,INACT,0.0	CHEMBL3680561,TP,ACT,1.0	CHEMBL3622206,FN,ACT,0.3799999952316284	CHEMBL3680586,TP,ACT,1.0	CHEMBL405681,TN,INACT,0.0	CHEMBL3670491,FN,ACT,0.25	CHEMBL604748,TN,INACT,0.0	CHEMBL1779747,TN,INACT,0.009999999776482582	CHEMBL3670434,TP,ACT,1.0	CHEMBL2163608,TN,INACT,0.05999999865889549	CHEMBL1078828,FN,ACT,0.0	CHEMBL80915,TN,INACT,0.0	CHEMBL549792,TN,INACT,0.0	CHEMBL55360,TN,INACT,0.0	CHEMBL1086088,FN,ACT,0.019999999552965164	CHEMBL1287914,TN,INACT,0.0	CHEMBL444877,TN,INACT,0.0	CHEMBL2391133,FN,ACT,0.0	CHEMBL1643353,TN,INACT,0.0	CHEMBL1922211,TN,INACT,0.0	CHEMBL492125,FN,ACT,0.0	CHEMBL522387,TN,INACT,0.029999999329447746	CHEMBL318248,TN,INACT,0.0	CHEMBL2163609,TN,INACT,0.019999999552965164	CHEMBL115895,TN,INACT,0.0	CHEMBL592210,TN,INACT,0.0	CHEMBL2392234,TN,INACT,0.0	CHEMBL3675445,TP,ACT,1.0	CHEMBL1173545,FN,ACT,0.23000000417232513	CHEMBL3218291,FP,INACT,0.7400000095367432	CHEMBL3685275,TP,ACT,1.0	CHEMBL2322140,FN,ACT,0.07999999821186066	CHEMBL45477,TN,INACT,0.009999999776482582	CHEMBL1490940,TN,INACT,0.0	CHEMBL304284,TN,INACT,0.0	CHEMBL1095466,FP,INACT,0.6299999952316284	CHEMBL77243,TN,INACT,0.0	CHEMBL131773,TN,INACT,0.0	CHEMBL378175,TN,INACT,0.009999999776482582	CHEMBL3236668,TN,INACT,0.0	CHEMBL1643142,TN,INACT,0.0	CHEMBL2337372,TN,INACT,0.0	CHEMBL2409790,TP,ACT,0.9800000190734863	CHEMBL3237167,TP,ACT,0.9900000095367432	CHEMBL3600763,TP,ACT,0.9599999785423279	CHEMBL1807469,TP,ACT,1.0	CHEMBL3675431,TP,ACT,1.0	CHEMBL2022377,TP,ACT,1.0	CHEMBL3675399,TP,ACT,1.0	CHEMBL77032,TN,INACT,0.07999999821186066	CHEMBL1095475,TP,ACT,0.8700000047683716	CHEMBL3685263,TP,ACT,1.0	CHEMBL132399,TN,INACT,0.0	CHEMBL3298373,TP,ACT,1.0	CHEMBL3692208,FN,ACT,0.0	CHEMBL1922120,TN,INACT,0.0	CHEMBL1214781,FN,ACT,0.029999999329447746	CHEMBL2170422,TP,ACT,0.9100000262260437	CHEMBL431249,TN,INACT,0.009999999776482582	CHEMBL1801103,TP,ACT,0.8399999737739563	CHEMBL482779,TP,ACT,1.0	CHEMBL1085833,TP,ACT,1.0	CHEMBL506669,TN,INACT,0.05000000074505806	CHEMBL3323024,FN,ACT,0.0	CHEMBL1308000,TN,INACT,0.0	CHEMBL3670486,TP,ACT,1.0	CHEMBL499145,TN,INACT,0.0	CHEMBL496754,TP,ACT,0.9700000286102295	CHEMBL260531,TP,ACT,0.9900000095367432	CHEMBL3675528,FN,ACT,0.009999999776482582	CHEMBL501368,TN,INACT,0.0	CHEMBL458248,TN,INACT,0.0	CHEMBL29197,TN,INACT,0.0	CHEMBL563948,TN,INACT,0.0	CHEMBL3318030,TN,INACT,0.3100000023841858	CHEMBL553695,TN,INACT,0.029999999329447746	CHEMBL3675401,TP,ACT,1.0	CHEMBL77303,TN,INACT,0.0	CHEMBL2030987,FN,ACT,0.05000000074505806	CHEMBL2382012,TN,INACT,0.0	CHEMBL522760,TN,INACT,0.46000000834465027	CHEMBL1084969,TP,ACT,0.9900000095367432	CHEMBL2375548,TN,INACT,0.0	CHEMBL1790805,TN,INACT,0.0	CHEMBL3685201,TP,ACT,0.8999999761581421	CHEMBL77262,TN,INACT,0.0	CHEMBL1173823,TP,ACT,1.0	CHEMBL477165,TN,INACT,0.019999999552965164	CHEMBL2030985,FN,ACT,0.25	CHEMBL178133,TN,INACT,0.0	CHEMBL3717995,TP,ACT,0.9900000095367432	CHEMBL318188,TN,INACT,0.0	CHEMBL226471,TN,INACT,0.3400000035762787	CHEMBL3263640,FP,INACT,0.9800000190734863	CHEMBL3670418,TP,ACT,0.7900000214576721	CHEMBL2029904,TP,ACT,1.0	CHEMBL405120,TP,ACT,1.0	CHEMBL3393496,TP,ACT,0.9900000095367432	CHEMBL1096492,TP,ACT,0.800000011920929	CHEMBL469206,FN,ACT,0.10999999940395355	CHEMBL70942,TN,INACT,0.0	CHEMBL1173801,TP,ACT,1.0	CHEMBL3685237,TP,ACT,1.0	CHEMBL2420584,TN,INACT,0.0	CHEMBL3675521,TP,ACT,0.9900000095367432	CHEMBL217037,TP,ACT,1.0	CHEMBL3593288,TP,ACT,1.0	CHEMBL176815,TN,INACT,0.0	CHEMBL3685240,TP,ACT,1.0	CHEMBL1090360,TP,ACT,1.0	CHEMBL2170411,FN,ACT,0.0	CHEMBL2022123,TP,ACT,1.0	CHEMBL504408,TN,INACT,0.0	CHEMBL73820,TN,INACT,0.0	CHEMBL1289926,FN,ACT,0.009999999776482582	CHEMBL311135,TN,INACT,0.0	CHEMBL78037,TN,INACT,0.009999999776482582	CHEMBL321359,TN,INACT,0.0	CHEMBL3670419,TP,ACT,1.0	CHEMBL3087782,TP,ACT,0.9900000095367432	CHEMBL2030982,FN,ACT,0.3799999952316284	CHEMBL3680416,TP,ACT,1.0	CHEMBL602472,TN,INACT,0.15000000596046448	CHEMBL363857,TP,ACT,0.9900000095367432	CHEMBL269528,TN,INACT,0.0	CHEMBL1512579,FN,ACT,0.03999999910593033	CHEMBL564746,TN,INACT,0.0	CHEMBL1384896,TN,INACT,0.009999999776482582	CHEMBL2336574,TN,INACT,0.0	CHEMBL2393372,TN,INACT,0.0	CHEMBL1086557,FN,ACT,0.0	CHEMBL90277,TN,INACT,0.0	CHEMBL504135,TN,INACT,0.0	CHEMBL2177668,TN,INACT,0.0	CHEMBL2036727,FP,INACT,0.8299999833106995	CHEMBL3680510,TP,ACT,1.0	CHEMBL2029514,TN,INACT,0.0	CHEMBL3670490,TP,ACT,1.0	CHEMBL456759,TN,INACT,0.0	CHEMBL475352,TP,ACT,0.9900000095367432	CHEMBL3675392,TP,ACT,1.0	CHEMBL154822,TN,INACT,0.0	CHEMBL127277,TN,INACT,0.0	CHEMBL202926,TP,ACT,1.0	CHEMBL310726,TN,INACT,0.0	CHEMBL358243,TN,INACT,0.0	CHEMBL524321,FN,ACT,0.36000001430511475	CHEMBL1086584,TP,ACT,1.0	CHEMBL3633690,TN,INACT,0.0	CHEMBL266540,TN,INACT,0.0	CHEMBL3680419,TP,ACT,1.0	CHEMBL512184,TP,ACT,1.0	CHEMBL3685206,TP,ACT,0.8899999856948853	CHEMBL3675374,TP,ACT,1.0	CHEMBL485878,TN,INACT,0.0	CHEMBL1688209,TN,INACT,0.0	CHEMBL1078220,TN,INACT,0.0	CHEMBL3237177,TP,ACT,1.0	CHEMBL1241771,TN,INACT,0.0	CHEMBL3675320,FN,ACT,0.4000000059604645	CHEMBL3680599,TP,ACT,0.9900000095367432	CHEMBL55592,TN,INACT,0.0	CHEMBL1688207,TN,INACT,0.0	CHEMBL453336,TN,INACT,0.0	CHEMBL410903,TP,ACT,1.0	CHEMBL1214708,FN,ACT,0.029999999329447746	CHEMBL348146,TN,INACT,0.0	CHEMBL2030974,TP,ACT,0.8999999761581421	CHEMBL3798556,TN,INACT,0.03999999910593033	CHEMBL3393491,FN,ACT,0.11999999731779099	CHEMBL1241301,TN,INACT,0.0	CHEMBL349810,TN,INACT,0.12999999523162842	CHEMBL3685305,TP,ACT,1.0	CHEMBL3675397,TP,ACT,0.9800000190734863	CHEMBL3629331,FP,INACT,0.9800000190734863	CHEMBL1214783,TP,ACT,0.7400000095367432	CHEMBL1307610,TN,INACT,0.0	CHEMBL1651472,FN,ACT,0.019999999552965164	CHEMBL1825096,TP,ACT,1.0	CHEMBL475817,TN,INACT,0.11999999731779099	CHEMBL216388,TP,ACT,1.0	CHEMBL236694,TP,ACT,0.9700000286102295	CHEMBL386253,TP,ACT,1.0	CHEMBL307179,TN,INACT,0.0	CHEMBL3670438,TP,ACT,1.0	CHEMBL3685203,TP,ACT,0.9900000095367432	CHEMBL3670416,TP,ACT,0.5899999737739563	CHEMBL598185,TP,ACT,1.0	CHEMBL525921,TN,INACT,0.0	CHEMBL117369,TN,INACT,0.14000000059604645	CHEMBL2323552,TN,INACT,0.0	CHEMBL1801130,FN,ACT,0.23999999463558197	CHEMBL332497,TN,INACT,0.0	CHEMBL1372854,TN,INACT,0.0	CHEMBL77068,TN,INACT,0.0	CHEMBL192489,TN,INACT,0.0	CHEMBL2380843,TP,ACT,0.8999999761581421	CHEMBL558925,TN,INACT,0.0	CHEMBL484601,TP,ACT,1.0	CHEMBL3670488,TP,ACT,0.6399999856948853	CHEMBL1241482,TN,INACT,0.0	CHEMBL422564,FP,INACT,0.5	CHEMBL1349023,TN,INACT,0.0	CHEMBL562030,TP,ACT,0.9900000095367432	CHEMBL2030977,TP,ACT,0.9900000095367432	CHEMBL1522377,TN,INACT,0.0	CHEMBL1643147,TP,ACT,0.8399999737739563	CHEMBL395601,TP,ACT,0.9700000286102295	CHEMBL483081,TN,INACT,0.0	CHEMBL3675524,TP,ACT,1.0	CHEMBL1933747,TN,INACT,0.0	CHEMBL1331525,TN,INACT,0.019999999552965164	CHEMBL562415,TP,ACT,0.9900000095367432	CHEMBL496588,TN,INACT,0.009999999776482582	CHEMBL232148,TN,INACT,0.0	CHEMBL3298291,TP,ACT,0.8100000023841858	CHEMBL336644,TN,INACT,0.0	CHEMBL95477,TN,INACT,0.0	CHEMBL3085798,TP,ACT,1.0	CHEMBL3685224,TP,ACT,1.0	CHEMBL3675380,TP,ACT,1.0	CHEMBL2023147,TN,INACT,0.0	CHEMBL2322141,FP,INACT,1.0	CHEMBL3797839,TN,INACT,0.03999999910593033	CHEMBL1172147,TN,INACT,0.0	CHEMBL1083774,FN,ACT,0.3199999928474426	CHEMBL330360,TN,INACT,0.0	CHEMBL1822491,TP,ACT,1.0	CHEMBL2030979,TP,ACT,1.0	CHEMBL3675404,TP,ACT,1.0	CHEMBL1807305,TP,ACT,1.0	CHEMBL354496,TN,INACT,0.0	CHEMBL476189,TN,INACT,0.0	CHEMBL1980391,FN,ACT,0.009999999776482582	CHEMBL1642269,TN,INACT,0.0	CHEMBL3685331,TP,ACT,1.0	CHEMBL441643,TN,INACT,0.0	CHEMBL1825100,TP,ACT,1.0	CHEMBL1088348,TN,INACT,0.019999999552965164	CHEMBL3675411,TP,ACT,1.0	CHEMBL458420,TP,ACT,0.9900000095367432	CHEMBL1214995,TP,ACT,1.0	CHEMBL3670499,TP,ACT,0.9900000095367432	CHEMBL458023,TP,ACT,1.0	CHEMBL262434,TP,ACT,1.0	CHEMBL3298287,TP,ACT,0.9900000095367432	CHEMBL472946,FN,ACT,0.009999999776482582	CHEMBL2063443,TP,ACT,0.9599999785423279	CHEMBL1762181,TN,INACT,0.0	CHEMBL3675522,TP,ACT,1.0	CHEMBL226813,TN,INACT,0.0	CHEMBL594661,TP,ACT,1.0	CHEMBL3685241,TP,ACT,0.9800000190734863	CHEMBL1828881,TN,INACT,0.0	CHEMBL295316,TN,INACT,0.0	CHEMBL304340,TN,INACT,0.0	CHEMBL3800262,TN,INACT,0.0	CHEMBL3393489,TP,ACT,0.9900000095367432	CHEMBL17637,TN,INACT,0.0	CHEMBL2207505,FN,ACT,0.029999999329447746	CHEMBL508307,TP,ACT,0.8999999761581421	CHEMBL3680406,TP,ACT,1.0	CHEMBL215417,FP,INACT,1.0	CHEMBL2380828,TP,ACT,1.0	CHEMBL1257164,FP,INACT,0.9800000190734863	CHEMBL3403031,TP,ACT,0.7400000095367432	CHEMBL1215349,FN,ACT,0.019999999552965164	CHEMBL3087774,TP,ACT,1.0	CHEMBL312078,TN,INACT,0.0	CHEMBL3685256,TP,ACT,0.9700000286102295	CHEMBL1258379,TP,ACT,0.8500000238418579	CHEMBL3680601,TP,ACT,1.0	CHEMBL598449,TN,INACT,0.009999999776482582	CHEMBL3323029,TP,ACT,1.0	CHEMBL2030990,TP,ACT,1.0	CHEMBL201638,TN,INACT,0.23000000417232513	CHEMBL3717942,TP,ACT,0.9399999976158142	CHEMBL2380830,TP,ACT,1.0	CHEMBL3706673,TP,ACT,1.0	CHEMBL3600760,FN,ACT,0.0	CHEMBL3675518,TP,ACT,0.9900000095367432	CHEMBL559882,TN,INACT,0.0	CHEMBL230761,TN,INACT,0.0	CHEMBL100675,TN,INACT,0.0	CHEMBL3680425,TP,ACT,1.0	CHEMBL422240,TN,INACT,0.0	CHEMBL3658032,FP,INACT,0.9300000071525574	CHEMBL2315560,TN,INACT,0.009999999776482582	CHEMBL430206,TN,INACT,0.23000000417232513	CHEMBL3393471,TP,ACT,0.5799999833106995	CHEMBL499864,TN,INACT,0.0	CHEMBL1651480,TP,ACT,0.9900000095367432	CHEMBL344779,TN,INACT,0.0	CHEMBL1651451,FN,ACT,0.07999999821186066	CHEMBL1370575,TN,INACT,0.0	CHEMBL335938,TN,INACT,0.0	CHEMBL67608,TN,INACT,0.0	CHEMBL2170441,TP,ACT,0.8100000023841858	CHEMBL422714,TN,INACT,0.0	CHEMBL3670480,TP,ACT,0.9800000190734863	CHEMBL2203775,TP,ACT,0.9700000286102295	CHEMBL2392113,FN,ACT,0.23999999463558197	CHEMBL3680504,TP,ACT,1.0	CHEMBL1496523,TN,INACT,0.20999999344348907	CHEMBL452355,TP,ACT,0.9800000190734863	CHEMBL204087,FN,ACT,0.0	CHEMBL2012412,TP,ACT,0.699999988079071	CHEMBL3745929,TN,INACT,0.0	CHEMBL3685253,TP,ACT,0.9900000095367432	CHEMBL498130,TN,INACT,0.0	CHEMBL3622957,TN,INACT,0.1599999964237213	CHEMBL169264,TN,INACT,0.0	CHEMBL238617,TN,INACT,0.0	CHEMBL425363,TN,INACT,0.0	CHEMBL473825,FP,INACT,1.0	CHEMBL491759,TP,ACT,0.9700000286102295	CHEMBL259381,TN,INACT,0.0	CHEMBL3237171,FN,ACT,0.0	CHEMBL1807480,TP,ACT,1.0	CHEMBL3675463,TP,ACT,1.0	CHEMBL384054,TP,ACT,1.0	CHEMBL1213111,TP,ACT,1.0	CHEMBL213230,TN,INACT,0.029999999329447746	CHEMBL3680553,TP,ACT,1.0	CHEMBL1830260,TN,INACT,0.009999999776482582	CHEMBL3692207,FN,ACT,0.05999999865889549	CHEMBL3314282,FP,INACT,0.5699999928474426	CHEMBL3675353,TP,ACT,1.0	CHEMBL2386812,TP,ACT,1.0	CHEMBL339077,TN,INACT,0.0	CHEMBL3675462,TP,ACT,1.0	CHEMBL559845,TP,ACT,0.6700000166893005	CHEMBL115519,TN,INACT,0.0	CHEMBL1287975,TN,INACT,0.009999999776482582	CHEMBL1642271,TN,INACT,0.0	CHEMBL1684372,TN,INACT,0.019999999552965164	CHEMBL1527654,TN,INACT,0.0	CHEMBL156797,TN,INACT,0.0	CHEMBL519891,TN,INACT,0.0	CHEMBL3680403,TP,ACT,0.949999988079071	CHEMBL1392879,TN,INACT,0.0	CHEMBL456143,TN,INACT,0.0	CHEMBL481584,TN,INACT,0.0	CHEMBL2398652,TP,ACT,1.0	CHEMBL456796,TN,INACT,0.0	CHEMBL3675402,TP,ACT,0.7699999809265137	CHEMBL3685232,TP,ACT,1.0	CHEMBL1084079,TP,ACT,0.9900000095367432	CHEMBL1651523,TN,INACT,0.0	CHEMBL2348175,TN,INACT,0.0	CHEMBL478488,TN,INACT,0.0	CHEMBL2163404,TP,ACT,1.0	CHEMBL525530,TN,INACT,0.3400000035762787	CHEMBL1945450,TN,INACT,0.0	CHEMBL1934327,TP,ACT,1.0	CHEMBL3675486,TP,ACT,1.0	CHEMBL3194854,TN,INACT,0.0	CHEMBL3685247,TP,ACT,1.0	CHEMBL3190499,TN,INACT,0.0	CHEMBL1097368,TN,INACT,0.029999999329447746	CHEMBL3675450,TP,ACT,1.0	CHEMBL3237182,TP,ACT,1.0	CHEMBL214949,TN,INACT,0.05000000074505806	CHEMBL496972,FP,INACT,0.5099999904632568	CHEMBL2392109,FN,ACT,0.10000000149011612	CHEMBL399914,TN,INACT,0.009999999776482582	CHEMBL3685298,TP,ACT,1.0	CHEMBL1257331,FN,ACT,0.0	CHEMBL2426289,TN,INACT,0.019999999552965164	CHEMBL1257332,FN,ACT,0.029999999329447746	CHEMBL3665654,TN,INACT,0.0	CHEMBL78249,TN,INACT,0.0	CHEMBL3675434,TP,ACT,0.9900000095367432	CHEMBL3675371,TP,ACT,1.0	CHEMBL328623,TN,INACT,0.0	CHEMBL339856,TN,INACT,0.0	CHEMBL3692206,TP,ACT,1.0	CHEMBL2029907,TP,ACT,0.9700000286102295	CHEMBL590521,TN,INACT,0.0	CHEMBL3675329,TP,ACT,1.0	CHEMBL3680521,TP,ACT,0.9900000095367432	CHEMBL3680390,TP,ACT,0.6600000262260437	CHEMBL3670406,TP,ACT,0.9900000095367432	CHEMBL3680387,TP,ACT,1.0	CHEMBL2012397,FN,ACT,0.23999999463558197	CHEMBL3680585,TP,ACT,1.0	CHEMBL3675449,TP,ACT,0.9900000095367432	CHEMBL249089,TN,INACT,0.0	CHEMBL1765757,FN,ACT,0.15000000596046448	CHEMBL1801111,TP,ACT,0.9300000071525574	CHEMBL1236904,TP,ACT,0.699999988079071	CHEMBL1684370,TN,INACT,0.0	CHEMBL1254545,TN,INACT,0.0	CHEMBL1547674,TN,INACT,0.009999999776482582	CHEMBL327725,TN,INACT,0.0	CHEMBL3675355,TP,ACT,1.0	CHEMBL556670,TN,INACT,0.0	CHEMBL7350,TN,INACT,0.0	CHEMBL102047,TN,INACT,0.07999999821186066	CHEMBL1651477,TP,ACT,0.9900000095367432	CHEMBL559881,TN,INACT,0.0	CHEMBL3685272,FN,ACT,0.019999999552965164	CHEMBL523463,FN,ACT,0.07999999821186066	CHEMBL3715109,TP,ACT,1.0	CHEMBL394223,TP,ACT,0.9800000190734863	CHEMBL2163405,TP,ACT,1.0	CHEMBL193966,TN,INACT,0.019999999552965164	CHEMBL3685221,TP,ACT,1.0	CHEMBL209148,TN,INACT,0.03999999910593033	CHEMBL1084887,TP,ACT,1.0	CHEMBL202721,TP,ACT,1.0	CHEMBL33175,TN,INACT,0.0	CHEMBL332342,TN,INACT,0.0	CHEMBL245967,FN,ACT,0.0	CHEMBL1933736,TN,INACT,0.03999999910593033	CHEMBL104,TN,INACT,0.0	CHEMBL3417327,FN,ACT,0.07000000029802322	CHEMBL1367188,TN,INACT,0.0	CHEMBL3780571,TN,INACT,0.2199999988079071	CHEMBL3189536,TN,INACT,0.0	CHEMBL1432472,TN,INACT,0.0	CHEMBL3680587,TP,ACT,0.9599999785423279	CHEMBL3670453,TP,ACT,1.0	CHEMBL559702,TN,INACT,0.0	CHEMBL560245,TN,INACT,0.0	CHEMBL1161235,TN,INACT,0.0	CHEMBL310313,TN,INACT,0.0	CHEMBL3675319,TP,ACT,0.5299999713897705	CHEMBL2409602,FP,INACT,0.9900000095367432	CHEMBL2392111,TP,ACT,0.9800000190734863	CHEMBL1242569,FP,INACT,0.5799999833106995	CHEMBL3680428,TP,ACT,0.9800000190734863	CHEMBL3680484,TP,ACT,0.9700000286102295	CHEMBL21096,TN,INACT,0.0	CHEMBL1495244,TN,INACT,0.0	CHEMBL3593295,TP,ACT,0.8399999737739563	CHEMBL2029910,TP,ACT,0.8799999952316284	CHEMBL153624,TN,INACT,0.0	CHEMBL1651469,FN,ACT,0.0	CHEMBL3675511,TP,ACT,1.0	CHEMBL3134612,TN,INACT,0.0	CHEMBL602645,TN,INACT,0.0	CHEMBL3665657,TN,INACT,0.0	CHEMBL512208,TN,INACT,0.0	CHEMBL3680511,TP,ACT,0.9800000190734863	CHEMBL550825,TP,ACT,0.6800000071525574	CHEMBL56319,TN,INACT,0.029999999329447746	CHEMBL236937,TN,INACT,0.0	CHEMBL3408947,TP,ACT,1.0	CHEMBL1494345,TN,INACT,0.0	CHEMBL2398649,TP,ACT,1.0	CHEMBL521201,FN,ACT,0.0	CHEMBL3639742,TP,ACT,1.0	CHEMBL313746,TN,INACT,0.03999999910593033	CHEMBL2030984,TP,ACT,1.0	CHEMBL1779745,TN,INACT,0.0	CHEMBL3675395,FN,ACT,0.0	CHEMBL2380826,TP,ACT,0.9900000095367432	CHEMBL3685234,TP,ACT,0.9700000286102295	CHEMBL1095465,TN,INACT,0.019999999552965164	CHEMBL2170429,TP,ACT,0.9399999976158142	CHEMBL66127,TN,INACT,0.0	CHEMBL1822653,TP,ACT,1.0	CHEMBL1784649,TN,INACT,0.11999999731779099	CHEMBL306929,TN,INACT,0.0	CHEMBL2022114,TP,ACT,0.9900000095367432	CHEMBL561136,TN,INACT,0.0	CHEMBL1825095,FN,ACT,0.029999999329447746	CHEMBL360190,TP,ACT,0.8799999952316284	CHEMBL3600870,FN,ACT,0.3199999928474426	CHEMBL2392106,TP,ACT,0.7300000190734863	CHEMBL2170593,TP,ACT,1.0	CHEMBL527039,TN,INACT,0.0	CHEMBL3353409,TN,INACT,0.0	CHEMBL3593292,TP,ACT,1.0	CHEMBL1651479,FN,ACT,0.3799999952316284	CHEMBL3330409,FN,ACT,0.0	CHEMBL1084630,TP,ACT,0.800000011920929	CHEMBL2012414,TP,ACT,1.0	CHEMBL3792621,TP,ACT,0.5600000023841858	CHEMBL3087818,TN,INACT,0.0	CHEMBL3716346,FN,ACT,0.0	CHEMBL3675432,TP,ACT,1.0	CHEMBL2398639,TP,ACT,1.0	CHEMBL593221,TP,ACT,1.0	CHEMBL3586473,TP,ACT,0.7699999809265137	CHEMBL104264,TN,INACT,0.0	CHEMBL1688210,TN,INACT,0.0	CHEMBL76035,TN,INACT,0.0	CHEMBL2163623,TN,INACT,0.019999999552965164	CHEMBL603469,FN,ACT,0.28999999165534973	CHEMBL1076330,TN,INACT,0.0	CHEMBL1242756,TN,INACT,0.0	CHEMBL2386789,TP,ACT,1.0	CHEMBL1085848,TP,ACT,1.0	CHEMBL3685222,TP,ACT,1.0	CHEMBL563733,FP,INACT,1.0	CHEMBL1480223,TN,INACT,0.0	CHEMBL457390,TN,INACT,0.0	CHEMBL1241483,TN,INACT,0.0	CHEMBL608533,TP,ACT,0.9100000262260437	CHEMBL3622207,FN,ACT,0.3400000035762787	CHEMBL3237188,TP,ACT,0.8100000023841858	CHEMBL1173023,TN,INACT,0.0	CHEMBL1172877,TN,INACT,0.0	CHEMBL458857,TN,INACT,0.0	CHEMBL230232,FP,INACT,1.0	CHEMBL1097022,TP,ACT,1.0	CHEMBL1213153,FN,ACT,0.0	CHEMBL2437297,TN,INACT,0.0	CHEMBL3622836,TN,INACT,0.0	CHEMBL1173152,FN,ACT,0.20999999344348907	CHEMBL160207,TN,INACT,0.0	CHEMBL3675350,TP,ACT,1.0	CHEMBL1651488,FN,ACT,0.0	CHEMBL3680431,TP,ACT,1.0	CHEMBL3665669,FP,INACT,0.800000011920929	CHEMBL570111,TP,ACT,0.9900000095367432	CHEMBL1765739,TP,ACT,0.9599999785423279	CHEMBL1615182,TN,INACT,0.1599999964237213	CHEMBL3685218,FN,ACT,0.0	CHEMBL410840,TP,ACT,1.0	CHEMBL3675387,TP,ACT,1.0	CHEMBL589847,TN,INACT,0.0	CHEMBL3109956,FP,INACT,0.9900000095367432	CHEMBL527026,TN,INACT,0.0	CHEMBL2022968,FN,ACT,0.20999999344348907	CHEMBL1439313,TN,INACT,0.0	CHEMBL1614775,TP,ACT,0.9900000095367432	CHEMBL591440,TN,INACT,0.0	CHEMBL1910602,TN,INACT,0.0	CHEMBL561834,TP,ACT,0.6800000071525574	CHEMBL3115324,TN,INACT,0.03999999910593033	CHEMBL456965,TN,INACT,0.0	CHEMBL513078,TP,ACT,1.0	CHEMBL360278,TN,INACT,0.009999999776482582	CHEMBL1215071,TP,ACT,0.5799999833106995	CHEMBL3609567,TN,INACT,0.0	CHEMBL3716175,TP,ACT,0.9800000190734863	CHEMBL3109932,TP,ACT,0.5600000023841858	CHEMBL1241862,TN,INACT,0.009999999776482582	CHEMBL520975,FN,ACT,0.09000000357627869	CHEMBL23507,TN,INACT,0.0	CHEMBL217804,TP,ACT,1.0	CHEMBL3716977,TP,ACT,1.0	CHEMBL1094784,TN,INACT,0.0	CHEMBL293250,TN,INACT,0.0	CHEMBL3675322,FN,ACT,0.019999999552965164	CHEMBL422466,TN,INACT,0.11999999731779099	CHEMBL2063466,TP,ACT,0.9900000095367432	CHEMBL348834,TN,INACT,0.0	CHEMBL1599435,TN,INACT,0.0	CHEMBL3098326,TN,INACT,0.0	CHEMBL1214925,TP,ACT,0.9599999785423279	CHEMBL3680430,TP,ACT,1.0	CHEMBL3685282,TP,ACT,1.0	CHEMBL392525,FN,ACT,0.0	CHEMBL1172697,TN,INACT,0.0	CHEMBL1254309,TN,INACT,0.07000000029802322	CHEMBL1094477,TP,ACT,0.7200000286102295	CHEMBL3810033,TN,INACT,0.0	CHEMBL201865,TN,INACT,0.0	CHEMBL3680554,TP,ACT,0.9800000190734863	CHEMBL1095463,FP,INACT,0.9200000166893005	CHEMBL1684373,TN,INACT,0.0	CHEMBL277430,FP,INACT,0.75	CHEMBL2335376,TN,INACT,0.0	CHEMBL605781,TP,ACT,0.7599999904632568	CHEMBL1783558,TN,INACT,0.0	CHEMBL270755,TP,ACT,1.0	CHEMBL603198,TN,INACT,0.0	CHEMBL236279,FP,INACT,0.6899999976158142	CHEMBL3675345,TP,ACT,0.8999999761581421	CHEMBL523490,TP,ACT,0.9900000095367432	CHEMBL1096416,TN,INACT,0.0	CHEMBL559628,TN,INACT,0.0	CHEMBL3675446,TP,ACT,0.8399999737739563	CHEMBL1642270,TN,INACT,0.0	CHEMBL189851,TN,INACT,0.019999999552965164	CHEMBL2088259,FP,INACT,1.0	CHEMBL3685231,TP,ACT,0.9900000095367432	CHEMBL381932,TN,INACT,0.0	CHEMBL3237163,FN,ACT,0.3199999928474426	CHEMBL485502,TN,INACT,0.0	CHEMBL1097190,TN,INACT,0.0	CHEMBL3675439,TP,ACT,1.0	CHEMBL1087054,TN,INACT,0.0	CHEMBL2147366,TN,INACT,0.14000000059604645	CHEMBL267213,TN,INACT,0.0	CHEMBL335284,TN,INACT,0.0	CHEMBL2163611,FP,INACT,0.9900000095367432	CHEMBL1958316,TN,INACT,0.0	CHEMBL1242660,TN,INACT,0.0	CHEMBL3680592,FN,ACT,0.019999999552965164	CHEMBL507714,TP,ACT,0.5699999928474426	CHEMBL101052,FP,INACT,0.8399999737739563	CHEMBL2170413,TP,ACT,0.9599999785423279	CHEMBL3680549,TP,ACT,1.0	CHEMBL1458559,TN,INACT,0.0	CHEMBL3109933,TN,INACT,0.009999999776482582	CHEMBL1083152,FN,ACT,0.0	CHEMBL430417,FP,INACT,0.6899999976158142	CHEMBL110065,TN,INACT,0.0	CHEMBL552038,TP,ACT,0.9200000166893005	CHEMBL1801131,TP,ACT,0.7099999785423279	CHEMBL3675357,TP,ACT,1.0	CHEMBL2398647,TP,ACT,0.7099999785423279	CHEMBL1171638,TN,INACT,0.0	CHEMBL407143,TN,INACT,0.009999999776482582	CHEMBL246309,TN,INACT,0.0	CHEMBL1822495,TP,ACT,1.0	CHEMBL558859,TN,INACT,0.0	CHEMBL3675481,TP,ACT,1.0	CHEMBL2170594,FP,INACT,0.9900000095367432	CHEMBL3087823,TP,ACT,0.7099999785423279	CHEMBL1231066,TP,ACT,0.7799999713897705	CHEMBL424899,TP,ACT,1.0	CHEMBL1374352,TN,INACT,0.0	CHEMBL1086583,TP,ACT,1.0	CHEMBL28626,TN,INACT,0.0	CHEMBL3237172,TP,ACT,1.0	CHEMBL2064388,TN,INACT,0.009999999776482582	CHEMBL3680448,TP,ACT,0.9399999976158142	CHEMBL1973716,FP,INACT,0.6899999976158142	CHEMBL3746351,FP,INACT,0.9700000286102295	CHEMBL2316152,TN,INACT,0.0	CHEMBL1668413,TN,INACT,0.0	CHEMBL430853,TN,INACT,0.0	CHEMBL3706684,TP,ACT,1.0	CHEMBL1417364,TN,INACT,0.0	CHEMBL808,TN,INACT,0.019999999552965164	CHEMBL3718679,TP,ACT,1.0	CHEMBL549303,TN,INACT,0.0	CHEMBL550856,TN,INACT,0.0	CHEMBL3623850,TN,INACT,0.0	CHEMBL3675390,FN,ACT,0.20999999344348907	CHEMBL1738705,TN,INACT,0.25999999046325684	CHEMBL475014,TN,INACT,0.0	CHEMBL496994,TN,INACT,0.0	CHEMBL1461987,TN,INACT,0.0	CHEMBL2207510,TP,ACT,1.0	CHEMBL404742,TP,ACT,0.9399999976158142	CHEMBL2380836,TP,ACT,1.0	CHEMBL2170427,TP,ACT,0.9900000095367432	CHEMBL190252,TP,ACT,1.0	CHEMBL373834,TN,INACT,0.30000001192092896	CHEMBL3680495,TP,ACT,1.0	CHEMBL236487,TN,INACT,0.4699999988079071	CHEMBL2036728,FP,INACT,1.0	CHEMBL2398659,TP,ACT,0.9900000095367432	CHEMBL2163610,TN,INACT,0.0	CHEMBL2022370,TP,ACT,1.0	CHEMBL502279,TN,INACT,0.0	CHEMBL3422068,TP,ACT,0.8799999952316284	CHEMBL3393465,TP,ACT,0.8700000047683716	CHEMBL3675465,TP,ACT,1.0	CHEMBL467321,TN,INACT,0.30000001192092896	CHEMBL489736,TP,ACT,0.9700000286102295	CHEMBL382416,TP,ACT,0.7599999904632568	CHEMBL1944923,TN,INACT,0.1599999964237213	CHEMBL1545746,TN,INACT,0.0	CHEMBL3298375,TP,ACT,0.9200000166893005	CHEMBL130871,TN,INACT,0.0	CHEMBL2392236,TN,INACT,0.0	CHEMBL600048,TN,INACT,0.0	CHEMBL591457,FP,INACT,0.5400000214576721	CHEMBL1651452,TP,ACT,1.0	CHEMBL1084888,TP,ACT,0.9599999785423279	CHEMBL555321,TN,INACT,0.0	CHEMBL3087778,TP,ACT,1.0	CHEMBL560817,TP,ACT,1.0	CHEMBL3675516,TP,ACT,1.0	CHEMBL1808342,TP,ACT,1.0	CHEMBL245212,FP,INACT,0.8799999952316284	CHEMBL429743,TP,ACT,0.9900000095367432	CHEMBL19996,TN,INACT,0.0	CHEMBL311119,TN,INACT,0.0	CHEMBL3675347,TP,ACT,1.0	

