ImageNetInceptionV2 CHEMBL2304404 adam 0.0001 15 0 0 0.6 False True
Number of active compounds :	160
Number of inactive compounds :	160
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2304404_adam_0.0001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2304404_adam_0.0001_15_0.6/
---------------------------------
Training samples: 192
Validation samples: 61
--
Training Step: 1  | time: 66.855s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/192
[A[ATraining Step: 2  | total loss: [1m[32m0.65170[0m[0m | time: 78.390s
[2K
| Adam | epoch: 001 | loss: 0.65170 - acc: 0.4500 -- iter: 064/192
[A[ATraining Step: 3  | total loss: [1m[32m0.66632[0m[0m | time: 88.089s
[2K
| Adam | epoch: 001 | loss: 0.66632 - acc: 0.5932 -- iter: 096/192
[A[ATraining Step: 4  | total loss: [1m[32m0.65714[0m[0m | time: 96.117s
[2K
| Adam | epoch: 001 | loss: 0.65714 - acc: 0.5702 -- iter: 128/192
[A[ATraining Step: 5  | total loss: [1m[32m0.54454[0m[0m | time: 104.251s
[2K
| Adam | epoch: 001 | loss: 0.54454 - acc: 0.8028 -- iter: 160/192
[A[ATraining Step: 6  | total loss: [1m[32m0.55178[0m[0m | time: 128.292s
[2K
| Adam | epoch: 001 | loss: 0.55178 - acc: 0.7689 | val_loss: 0.65386 - val_acc: 0.6393 -- iter: 192/192
--
Training Step: 7  | total loss: [1m[32m0.55177[0m[0m | time: 22.852s
[2K
| Adam | epoch: 002 | loss: 0.55177 - acc: 0.6825 -- iter: 032/192
[A[ATraining Step: 8  | total loss: [1m[32m0.48506[0m[0m | time: 34.229s
[2K
| Adam | epoch: 002 | loss: 0.48506 - acc: 0.7732 -- iter: 064/192
[A[ATraining Step: 9  | total loss: [1m[32m0.47908[0m[0m | time: 45.517s
[2K
| Adam | epoch: 002 | loss: 0.47908 - acc: 0.7775 -- iter: 096/192
[A[ATraining Step: 10  | total loss: [1m[32m0.78887[0m[0m | time: 57.270s
[2K
| Adam | epoch: 002 | loss: 0.78887 - acc: 0.6075 -- iter: 128/192
[A[ATraining Step: 11  | total loss: [1m[32m0.55198[0m[0m | time: 68.542s
[2K
| Adam | epoch: 002 | loss: 0.55198 - acc: 0.7638 -- iter: 160/192
[A[ATraining Step: 12  | total loss: [1m[32m0.42734[0m[0m | time: 85.494s
[2K
| Adam | epoch: 002 | loss: 0.42734 - acc: 0.8138 | val_loss: 0.72951 - val_acc: 0.3607 -- iter: 192/192
--
Training Step: 13  | total loss: [1m[32m0.40243[0m[0m | time: 8.077s
[2K
| Adam | epoch: 003 | loss: 0.40243 - acc: 0.8401 -- iter: 032/192
[A[ATraining Step: 14  | total loss: [1m[32m0.34257[0m[0m | time: 17.499s
[2K
| Adam | epoch: 003 | loss: 0.34257 - acc: 0.8927 -- iter: 064/192
[A[ATraining Step: 15  | total loss: [1m[32m0.28762[0m[0m | time: 29.405s
[2K
| Adam | epoch: 003 | loss: 0.28762 - acc: 0.9347 -- iter: 096/192
[A[ATraining Step: 16  | total loss: [1m[32m0.27672[0m[0m | time: 40.725s
[2K
| Adam | epoch: 003 | loss: 0.27672 - acc: 0.9357 -- iter: 128/192
[A[ATraining Step: 17  | total loss: [1m[32m0.24265[0m[0m | time: 53.501s
[2K
| Adam | epoch: 003 | loss: 0.24265 - acc: 0.9476 -- iter: 160/192
[A[ATraining Step: 18  | total loss: [1m[32m0.20610[0m[0m | time: 75.097s
[2K
| Adam | epoch: 003 | loss: 0.20610 - acc: 0.9549 | val_loss: 0.88797 - val_acc: 0.6393 -- iter: 192/192
--
Training Step: 19  | total loss: [1m[32m0.18026[0m[0m | time: 11.043s
[2K
| Adam | epoch: 004 | loss: 0.18026 - acc: 0.9595 -- iter: 032/192
[A[ATraining Step: 20  | total loss: [1m[32m0.16921[0m[0m | time: 25.305s
[2K
| Adam | epoch: 004 | loss: 0.16921 - acc: 0.9625 -- iter: 064/192
[A[ATraining Step: 21  | total loss: [1m[32m0.15843[0m[0m | time: 45.257s
[2K
| Adam | epoch: 004 | loss: 0.15843 - acc: 0.9644 -- iter: 096/192
[A[ATraining Step: 22  | total loss: [1m[32m0.13342[0m[0m | time: 56.774s
[2K
| Adam | epoch: 004 | loss: 0.13342 - acc: 0.9751 -- iter: 128/192
[A[ATraining Step: 23  | total loss: [1m[32m0.13924[0m[0m | time: 68.283s
[2K
| Adam | epoch: 004 | loss: 0.13924 - acc: 0.9642 -- iter: 160/192
[A[ATraining Step: 24  | total loss: [1m[32m0.12395[0m[0m | time: 80.438s
[2K
| Adam | epoch: 004 | loss: 0.12395 - acc: 0.9743 | val_loss: 1.53321 - val_acc: 0.6393 -- iter: 192/192
--
Training Step: 25  | total loss: [1m[32m0.09999[0m[0m | time: 11.562s
[2K
| Adam | epoch: 005 | loss: 0.09999 - acc: 0.9813 -- iter: 032/192
[A[ATraining Step: 26  | total loss: [1m[32m0.08298[0m[0m | time: 22.677s
[2K
| Adam | epoch: 005 | loss: 0.08298 - acc: 0.9862 -- iter: 064/192
[A[ATraining Step: 27  | total loss: [1m[32m0.06741[0m[0m | time: 35.474s
[2K
| Adam | epoch: 005 | loss: 0.06741 - acc: 0.9898 -- iter: 096/192
[A[ATraining Step: 28  | total loss: [1m[32m0.05757[0m[0m | time: 60.662s
[2K
| Adam | epoch: 005 | loss: 0.05757 - acc: 0.9923 -- iter: 128/192
[A[ATraining Step: 29  | total loss: [1m[32m0.04846[0m[0m | time: 71.845s
[2K
| Adam | epoch: 005 | loss: 0.04846 - acc: 0.9942 -- iter: 160/192
[A[ATraining Step: 30  | total loss: [1m[32m0.08920[0m[0m | time: 87.049s
[2K
| Adam | epoch: 005 | loss: 0.08920 - acc: 0.9882 | val_loss: 2.09799 - val_acc: 0.6393 -- iter: 192/192
--
Training Step: 31  | total loss: [1m[32m0.12085[0m[0m | time: 11.314s
[2K
| Adam | epoch: 006 | loss: 0.12085 - acc: 0.9837 -- iter: 032/192
[A[ATraining Step: 32  | total loss: [1m[32m0.09765[0m[0m | time: 23.057s
[2K
| Adam | epoch: 006 | loss: 0.09765 - acc: 0.9874 -- iter: 064/192
[A[ATraining Step: 33  | total loss: [1m[32m0.09148[0m[0m | time: 31.344s
[2K
| Adam | epoch: 006 | loss: 0.09148 - acc: 0.9833 -- iter: 096/192
[A[ATraining Step: 34  | total loss: [1m[32m0.07658[0m[0m | time: 39.360s
[2K
| Adam | epoch: 006 | loss: 0.07658 - acc: 0.9869 -- iter: 128/192
[A[ATraining Step: 35  | total loss: [1m[32m0.06444[0m[0m | time: 47.413s
[2K
| Adam | epoch: 006 | loss: 0.06444 - acc: 0.9896 -- iter: 160/192
[A[ATraining Step: 36  | total loss: [1m[32m0.05374[0m[0m | time: 67.262s
[2K
| Adam | epoch: 006 | loss: 0.05374 - acc: 0.9917 | val_loss: 1.97290 - val_acc: 0.6393 -- iter: 192/192
--
Training Step: 37  | total loss: [1m[32m0.04491[0m[0m | time: 11.261s
[2K
| Adam | epoch: 007 | loss: 0.04491 - acc: 0.9934 -- iter: 032/192
[A[ATraining Step: 38  | total loss: [1m[32m0.06863[0m[0m | time: 22.792s
[2K
| Adam | epoch: 007 | loss: 0.06863 - acc: 0.9886 -- iter: 064/192
[A[ATraining Step: 39  | total loss: [1m[32m0.05785[0m[0m | time: 33.881s
[2K
| Adam | epoch: 007 | loss: 0.05785 - acc: 0.9908 -- iter: 096/192
[A[ATraining Step: 40  | total loss: [1m[32m0.04827[0m[0m | time: 55.688s
[2K
| Adam | epoch: 007 | loss: 0.04827 - acc: 0.9925 -- iter: 128/192
[A[ATraining Step: 41  | total loss: [1m[32m0.04090[0m[0m | time: 87.581s
[2K
| Adam | epoch: 007 | loss: 0.04090 - acc: 0.9939 -- iter: 160/192
[A[ATraining Step: 42  | total loss: [1m[32m0.04335[0m[0m | time: 101.911s
[2K
| Adam | epoch: 007 | loss: 0.04335 - acc: 0.9893 | val_loss: 1.39015 - val_acc: 0.6393 -- iter: 192/192
--
Training Step: 43  | total loss: [1m[32m0.03834[0m[0m | time: 7.975s
[2K
| Adam | epoch: 008 | loss: 0.03834 - acc: 0.9912 -- iter: 032/192
[A[ATraining Step: 44  | total loss: [1m[32m0.04909[0m[0m | time: 15.833s
[2K
| Adam | epoch: 008 | loss: 0.04909 - acc: 0.9873 -- iter: 064/192
[A[ATraining Step: 45  | total loss: [1m[32m0.11384[0m[0m | time: 25.024s
[2K
| Adam | epoch: 008 | loss: 0.11384 - acc: 0.9789 -- iter: 096/192
[A[ATraining Step: 46  | total loss: [1m[32m0.09653[0m[0m | time: 36.490s
[2K
| Adam | epoch: 008 | loss: 0.09653 - acc: 0.9824 -- iter: 128/192
[A[ATraining Step: 47  | total loss: [1m[32m0.08338[0m[0m | time: 50.288s
[2K
| Adam | epoch: 008 | loss: 0.08338 - acc: 0.9853 -- iter: 160/192
[A[ATraining Step: 48  | total loss: [1m[32m0.07097[0m[0m | time: 101.998s
[2K
| Adam | epoch: 008 | loss: 0.07097 - acc: 0.9876 | val_loss: 0.48621 - val_acc: 0.7377 -- iter: 192/192
--
Training Step: 49  | total loss: [1m[32m0.07070[0m[0m | time: 11.577s
[2K
| Adam | epoch: 009 | loss: 0.07070 - acc: 0.9847 -- iter: 032/192
[A[ATraining Step: 50  | total loss: [1m[32m0.06443[0m[0m | time: 23.262s
[2K
| Adam | epoch: 009 | loss: 0.06443 - acc: 0.9870 -- iter: 064/192
[A[ATraining Step: 51  | total loss: [1m[32m0.05815[0m[0m | time: 33.180s
[2K
| Adam | epoch: 009 | loss: 0.05815 - acc: 0.9890 -- iter: 096/192
[A[ATraining Step: 52  | total loss: [1m[32m0.07016[0m[0m | time: 43.709s
[2K
| Adam | epoch: 009 | loss: 0.07016 - acc: 0.9860 -- iter: 128/192
[A[ATraining Step: 53  | total loss: [1m[32m0.06468[0m[0m | time: 55.375s
[2K
| Adam | epoch: 009 | loss: 0.06468 - acc: 0.9880 -- iter: 160/192
[A[ATraining Step: 54  | total loss: [1m[32m0.07503[0m[0m | time: 66.473s
[2K
| Adam | epoch: 009 | loss: 0.07503 - acc: 0.9807 | val_loss: 0.78476 - val_acc: 0.5410 -- iter: 192/192
--
Training Step: 55  | total loss: [1m[32m0.06563[0m[0m | time: 11.978s
[2K
| Adam | epoch: 010 | loss: 0.06563 - acc: 0.9835 -- iter: 032/192
[A[ATraining Step: 56  | total loss: [1m[32m0.05728[0m[0m | time: 34.896s
[2K
| Adam | epoch: 010 | loss: 0.05728 - acc: 0.9858 -- iter: 064/192
[A[ATraining Step: 57  | total loss: [1m[32m0.05004[0m[0m | time: 53.440s
[2K
| Adam | epoch: 010 | loss: 0.05004 - acc: 0.9878 -- iter: 096/192
[A[ATraining Step: 58  | total loss: [1m[32m0.04504[0m[0m | time: 64.860s
[2K
| Adam | epoch: 010 | loss: 0.04504 - acc: 0.9894 -- iter: 128/192
[A[ATraining Step: 59  | total loss: [1m[32m0.06726[0m[0m | time: 76.171s
[2K
| Adam | epoch: 010 | loss: 0.06726 - acc: 0.9866 -- iter: 160/192
[A[ATraining Step: 60  | total loss: [1m[32m0.06067[0m[0m | time: 91.354s
[2K
| Adam | epoch: 010 | loss: 0.06067 - acc: 0.9884 | val_loss: 1.17058 - val_acc: 0.4590 -- iter: 192/192
--
Training Step: 61  | total loss: [1m[32m0.05344[0m[0m | time: 11.020s
[2K
| Adam | epoch: 011 | loss: 0.05344 - acc: 0.9899 -- iter: 032/192
[A[ATraining Step: 62  | total loss: [1m[32m0.04865[0m[0m | time: 21.544s
[2K
| Adam | epoch: 011 | loss: 0.04865 - acc: 0.9912 -- iter: 064/192
[A[ATraining Step: 63  | total loss: [1m[32m0.04462[0m[0m | time: 32.575s
[2K
| Adam | epoch: 011 | loss: 0.04462 - acc: 0.9923 -- iter: 096/192
[A[ATraining Step: 64  | total loss: [1m[32m0.04107[0m[0m | time: 40.646s
[2K
| Adam | epoch: 011 | loss: 0.04107 - acc: 0.9933 -- iter: 128/192
[A[ATraining Step: 65  | total loss: [1m[32m0.03677[0m[0m | time: 48.592s
[2K
| Adam | epoch: 011 | loss: 0.03677 - acc: 0.9941 -- iter: 160/192
[A[ATraining Step: 66  | total loss: [1m[32m0.08947[0m[0m | time: 60.982s
[2K
| Adam | epoch: 011 | loss: 0.08947 - acc: 0.9872 | val_loss: 0.38240 - val_acc: 0.8525 -- iter: 192/192
--
Training Step: 67  | total loss: [1m[32m0.07942[0m[0m | time: 23.440s
[2K
| Adam | epoch: 012 | loss: 0.07942 - acc: 0.9888 -- iter: 032/192
[A[ATraining Step: 68  | total loss: [1m[32m0.07084[0m[0m | time: 34.640s
[2K
| Adam | epoch: 012 | loss: 0.07084 - acc: 0.9901 -- iter: 064/192
[A[ATraining Step: 69  | total loss: [1m[32m0.06430[0m[0m | time: 45.671s
[2K
| Adam | epoch: 012 | loss: 0.06430 - acc: 0.9913 -- iter: 096/192
[A[ATraining Step: 70  | total loss: [1m[32m0.06271[0m[0m | time: 57.179s
[2K
| Adam | epoch: 012 | loss: 0.06271 - acc: 0.9887 -- iter: 128/192
[A[ATraining Step: 71  | total loss: [1m[32m0.05771[0m[0m | time: 68.547s
[2K
| Adam | epoch: 012 | loss: 0.05771 - acc: 0.9899 -- iter: 160/192
[A[ATraining Step: 72  | total loss: [1m[32m0.05260[0m[0m | time: 84.319s
[2K
| Adam | epoch: 012 | loss: 0.05260 - acc: 0.9911 | val_loss: 0.50821 - val_acc: 0.8689 -- iter: 192/192
--
Training Step: 73  | total loss: [1m[32m0.05215[0m[0m | time: 7.842s
[2K
| Adam | epoch: 013 | loss: 0.05215 - acc: 0.9886 -- iter: 032/192
[A[ATraining Step: 74  | total loss: [1m[32m0.04900[0m[0m | time: 17.861s
[2K
| Adam | epoch: 013 | loss: 0.04900 - acc: 0.9899 -- iter: 064/192
[A[ATraining Step: 75  | total loss: [1m[32m0.04450[0m[0m | time: 29.684s
[2K
| Adam | epoch: 013 | loss: 0.04450 - acc: 0.9910 -- iter: 096/192
[A[ATraining Step: 76  | total loss: [1m[32m0.04284[0m[0m | time: 40.869s
[2K
| Adam | epoch: 013 | loss: 0.04284 - acc: 0.9919 -- iter: 128/192
[A[ATraining Step: 77  | total loss: [1m[32m0.04012[0m[0m | time: 52.810s
[2K
| Adam | epoch: 013 | loss: 0.04012 - acc: 0.9928 -- iter: 160/192
[A[ATraining Step: 78  | total loss: [1m[32m0.03802[0m[0m | time: 69.416s
[2K
| Adam | epoch: 013 | loss: 0.03802 - acc: 0.9935 | val_loss: 0.51894 - val_acc: 0.8033 -- iter: 192/192
--
Training Step: 79  | total loss: [1m[32m0.03641[0m[0m | time: 11.209s
[2K
| Adam | epoch: 014 | loss: 0.03641 - acc: 0.9942 -- iter: 032/192
[A[ATraining Step: 80  | total loss: [1m[32m0.06375[0m[0m | time: 22.345s
[2K
| Adam | epoch: 014 | loss: 0.06375 - acc: 0.9884 -- iter: 064/192
[A[ATraining Step: 81  | total loss: [1m[32m0.05784[0m[0m | time: 33.330s
[2K
| Adam | epoch: 014 | loss: 0.05784 - acc: 0.9896 -- iter: 096/192
[A[ATraining Step: 82  | total loss: [1m[32m0.05297[0m[0m | time: 76.435s
[2K
| Adam | epoch: 014 | loss: 0.05297 - acc: 0.9906 -- iter: 128/192
[A[ATraining Step: 83  | total loss: [1m[32m0.05073[0m[0m | time: 87.603s
[2K
| Adam | epoch: 014 | loss: 0.05073 - acc: 0.9884 -- iter: 160/192
[A[ATraining Step: 84  | total loss: [1m[32m0.06343[0m[0m | time: 102.556s
[2K
| Adam | epoch: 014 | loss: 0.06343 - acc: 0.9833 | val_loss: 1.82490 - val_acc: 0.4098 -- iter: 192/192
--
Training Step: 85  | total loss: [1m[32m0.06761[0m[0m | time: 9.994s
[2K
| Adam | epoch: 015 | loss: 0.06761 - acc: 0.9819 -- iter: 032/192
[A[ATraining Step: 86  | total loss: [1m[32m0.06148[0m[0m | time: 20.804s
[2K
| Adam | epoch: 015 | loss: 0.06148 - acc: 0.9837 -- iter: 064/192
[A[ATraining Step: 87  | total loss: [1m[32m0.09683[0m[0m | time: 37.487s
[2K
| Adam | epoch: 015 | loss: 0.09683 - acc: 0.9791 -- iter: 096/192
[A[ATraining Step: 88  | total loss: [1m[32m0.08791[0m[0m | time: 48.544s
[2K
| Adam | epoch: 015 | loss: 0.08791 - acc: 0.9812 -- iter: 128/192
[A[ATraining Step: 89  | total loss: [1m[32m0.07969[0m[0m | time: 59.844s
[2K
| Adam | epoch: 015 | loss: 0.07969 - acc: 0.9830 -- iter: 160/192
[A[ATraining Step: 90  | total loss: [1m[32m0.07289[0m[0m | time: 75.329s
[2K
| Adam | epoch: 015 | loss: 0.07289 - acc: 0.9847 | val_loss: 0.64717 - val_acc: 0.7377 -- iter: 192/192
--
Validation AUC:0.9055944055944055
Validation AUPRC:0.8492552525447262
Test AUC:0.9263736263736264
Test AUPRC:0.8272988939536553
BestTestF1Score	0.89	0.8	0.9	0.86	0.92	24	4	31	2	0.93
BestTestMCCScore	0.89	0.8	0.9	0.86	0.92	24	4	31	2	0.93
BestTestAccuracyScore	0.89	0.8	0.9	0.86	0.92	24	4	31	2	0.93
BestValidationF1Score	0.84	0.75	0.89	0.86	0.82	18	3	36	4	0.93
BestValidationMCC	0.84	0.75	0.89	0.86	0.82	18	3	36	4	0.93
BestValidationAccuracy	0.84	0.75	0.89	0.86	0.82	18	3	36	4	0.93
TestPredictions (Threshold:0.93)
CHEMBL292904,TP,ACT,0.949999988079071	CHEMBL127167,TP,ACT,0.9599999785423279	CHEMBL352779,TN,INACT,0.0	CHEMBL461709,TN,INACT,0.0	CHEMBL604242,TP,ACT,0.9300000071525574	CHEMBL21937,TN,INACT,0.0	CHEMBL31838,FP,INACT,1.0	CHEMBL418101,TP,ACT,0.9599999785423279	CHEMBL307805,TP,ACT,0.9900000095367432	CHEMBL611919,FN,ACT,0.7799999713897705	CHEMBL307942,TP,ACT,0.9800000190734863	CHEMBL3109772,TN,INACT,0.5099999904632568	CHEMBL95727,TN,INACT,0.07000000029802322	CHEMBL227429,TN,INACT,0.009999999776482582	CHEMBL294649,TN,INACT,0.009999999776482582	CHEMBL116486,TP,ACT,0.9800000190734863	CHEMBL320763,TN,INACT,0.0	CHEMBL611916,TN,INACT,0.6100000143051147	CHEMBL62350,TP,ACT,0.949999988079071	CHEMBL424949,TP,ACT,0.9800000190734863	CHEMBL183,TP,ACT,1.0	CHEMBL122703,FP,INACT,0.9900000095367432	CHEMBL227378,TN,INACT,0.12999999523162842	CHEMBL165012,TN,INACT,0.5400000214576721	CHEMBL489640,TP,ACT,0.949999988079071	CHEMBL334849,FP,INACT,0.9700000286102295	CHEMBL513277,TN,INACT,0.6000000238418579	CHEMBL415321,TP,ACT,0.9900000095367432	CHEMBL298474,TP,ACT,0.9900000095367432	CHEMBL404557,TN,INACT,0.0	CHEMBL84144,TP,ACT,0.9900000095367432	CHEMBL278332,TP,ACT,0.9800000190734863	CHEMBL321309,TP,ACT,0.9900000095367432	CHEMBL59347,TN,INACT,0.5699999928474426	CHEMBL407818,TN,INACT,0.800000011920929	CHEMBL337080,TP,ACT,0.949999988079071	CHEMBL113,TN,INACT,0.8100000023841858	CHEMBL104189,TP,ACT,0.9800000190734863	CHEMBL109206,TN,INACT,0.0	CHEMBL68738,TP,ACT,0.9700000286102295	CHEMBL31859,TN,INACT,0.8100000023841858	CHEMBL353502,TN,INACT,0.009999999776482582	CHEMBL131275,TP,ACT,0.9900000095367432	CHEMBL1180343,TN,INACT,0.09000000357627869	CHEMBL293232,TN,INACT,0.7200000286102295	CHEMBL142410,TP,ACT,0.9900000095367432	CHEMBL173327,TP,ACT,1.0	CHEMBL298612,TN,INACT,0.3400000035762787	CHEMBL453,TN,INACT,0.029999999329447746	CHEMBL460470,TN,INACT,0.38999998569488525	CHEMBL368629,TN,INACT,0.15000000596046448	CHEMBL21328,TN,INACT,0.6700000166893005	CHEMBL11131,TN,INACT,0.6600000262260437	CHEMBL99331,TN,INACT,0.6600000262260437	CHEMBL282160,FP,INACT,0.9599999785423279	CHEMBL594803,TN,INACT,0.18000000715255737	CHEMBL26522,TN,INACT,0.029999999329447746	CHEMBL83822,FN,ACT,0.699999988079071	CHEMBL1983100,TN,INACT,0.3799999952316284	CHEMBL143565,TP,ACT,0.9700000286102295	CHEMBL33115,TP,ACT,0.9900000095367432	

