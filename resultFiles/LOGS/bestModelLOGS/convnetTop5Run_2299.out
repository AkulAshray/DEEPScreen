ImageNetInceptionV2 CHEMBL4829 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	234
Number of inactive compounds :	156
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4829_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4829_adam_0.001_15_0.8/
---------------------------------
Training samples: 248
Validation samples: 78
--
Training Step: 1  | time: 180.327s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/248
[A[ATraining Step: 2  | total loss: [1m[32m0.57458[0m[0m | time: 263.134s
[2K
| Adam | epoch: 001 | loss: 0.57458 - acc: 0.6469 -- iter: 064/248
[A[ATraining Step: 3  | total loss: [1m[32m0.73597[0m[0m | time: 314.091s
[2K
| Adam | epoch: 001 | loss: 0.73597 - acc: 0.7057 -- iter: 096/248
[A[ATraining Step: 4  | total loss: [1m[32m0.62238[0m[0m | time: 415.776s
[2K
| Adam | epoch: 001 | loss: 0.62238 - acc: 0.7155 -- iter: 128/248
[A[ATraining Step: 5  | total loss: [1m[32m0.52367[0m[0m | time: 521.849s
[2K
| Adam | epoch: 001 | loss: 0.52367 - acc: 0.7826 -- iter: 160/248
[A[ATraining Step: 6  | total loss: [1m[32m0.65575[0m[0m | time: 588.140s
[2K
| Adam | epoch: 001 | loss: 0.65575 - acc: 0.6612 -- iter: 192/248
[A[ATraining Step: 7  | total loss: [1m[32m0.65194[0m[0m | time: 609.822s
[2K
| Adam | epoch: 001 | loss: 0.65194 - acc: 0.7145 -- iter: 224/248
[A[ATraining Step: 8  | total loss: [1m[32m0.66669[0m[0m | time: 634.832s
[2K
| Adam | epoch: 001 | loss: 0.66669 - acc: 0.6466 | val_loss: 2.26993 - val_acc: 0.4231 -- iter: 248/248
--
Training Step: 9  | total loss: [1m[32m0.55597[0m[0m | time: 12.507s
[2K
| Adam | epoch: 002 | loss: 0.55597 - acc: 0.7454 -- iter: 032/248
[A[ATraining Step: 10  | total loss: [1m[32m0.47185[0m[0m | time: 46.349s
[2K
| Adam | epoch: 002 | loss: 0.47185 - acc: 0.8102 -- iter: 064/248
[A[ATraining Step: 11  | total loss: [1m[32m0.40944[0m[0m | time: 69.427s
[2K
| Adam | epoch: 002 | loss: 0.40944 - acc: 0.8557 -- iter: 096/248
[A[ATraining Step: 12  | total loss: [1m[32m0.40815[0m[0m | time: 91.009s
[2K
| Adam | epoch: 002 | loss: 0.40815 - acc: 0.8363 -- iter: 128/248
[A[ATraining Step: 13  | total loss: [1m[32m0.44800[0m[0m | time: 194.040s
[2K
| Adam | epoch: 002 | loss: 0.44800 - acc: 0.7725 -- iter: 160/248
[A[ATraining Step: 14  | total loss: [1m[32m0.38255[0m[0m | time: 263.495s
[2K
| Adam | epoch: 002 | loss: 0.38255 - acc: 0.8144 -- iter: 192/248
[A[ATraining Step: 15  | total loss: [1m[32m0.34903[0m[0m | time: 308.977s
[2K
| Adam | epoch: 002 | loss: 0.34903 - acc: 0.8381 -- iter: 224/248
[A[ATraining Step: 16  | total loss: [1m[32m0.36420[0m[0m | time: 335.371s
[2K
| Adam | epoch: 002 | loss: 0.36420 - acc: 0.8168 | val_loss: 2.88004 - val_acc: 0.4231 -- iter: 248/248
--
Training Step: 17  | total loss: [1m[32m0.28885[0m[0m | time: 11.313s
[2K
| Adam | epoch: 003 | loss: 0.28885 - acc: 0.8603 -- iter: 032/248
[A[ATraining Step: 18  | total loss: [1m[32m0.28481[0m[0m | time: 26.911s
[2K
| Adam | epoch: 003 | loss: 0.28481 - acc: 0.8798 -- iter: 064/248
[A[ATraining Step: 19  | total loss: [1m[32m0.23588[0m[0m | time: 74.784s
[2K
| Adam | epoch: 003 | loss: 0.23588 - acc: 0.9060 -- iter: 096/248
[A[ATraining Step: 20  | total loss: [1m[32m0.26198[0m[0m | time: 93.791s
[2K
| Adam | epoch: 003 | loss: 0.26198 - acc: 0.8759 -- iter: 128/248
[A[ATraining Step: 21  | total loss: [1m[32m0.34914[0m[0m | time: 123.202s
[2K
| Adam | epoch: 003 | loss: 0.34914 - acc: 0.8756 -- iter: 160/248
[A[ATraining Step: 22  | total loss: [1m[32m0.49147[0m[0m | time: 143.797s
[2K
| Adam | epoch: 003 | loss: 0.49147 - acc: 0.8379 -- iter: 192/248
[A[ATraining Step: 23  | total loss: [1m[32m0.37964[0m[0m | time: 158.782s
[2K
| Adam | epoch: 003 | loss: 0.37964 - acc: 0.8759 -- iter: 224/248
[A[ATraining Step: 24  | total loss: [1m[32m0.29467[0m[0m | time: 209.263s
[2K
| Adam | epoch: 003 | loss: 0.29467 - acc: 0.9020 | val_loss: 2.82352 - val_acc: 0.4231 -- iter: 248/248
--
Training Step: 25  | total loss: [1m[32m0.25392[0m[0m | time: 20.832s
[2K
| Adam | epoch: 004 | loss: 0.25392 - acc: 0.9117 -- iter: 032/248
[A[ATraining Step: 26  | total loss: [1m[32m0.22560[0m[0m | time: 32.260s
[2K
| Adam | epoch: 004 | loss: 0.22560 - acc: 0.9351 -- iter: 064/248
[A[ATraining Step: 27  | total loss: [1m[32m0.24511[0m[0m | time: 42.872s
[2K
| Adam | epoch: 004 | loss: 0.24511 - acc: 0.9196 -- iter: 096/248
[A[ATraining Step: 28  | total loss: [1m[32m0.23147[0m[0m | time: 53.080s
[2K
| Adam | epoch: 004 | loss: 0.23147 - acc: 0.9189 -- iter: 128/248
[A[ATraining Step: 29  | total loss: [1m[32m0.22700[0m[0m | time: 62.970s
[2K
| Adam | epoch: 004 | loss: 0.22700 - acc: 0.9158 -- iter: 160/248
[A[ATraining Step: 30  | total loss: [1m[32m0.20431[0m[0m | time: 77.136s
[2K
| Adam | epoch: 004 | loss: 0.20431 - acc: 0.9284 -- iter: 192/248
[A[ATraining Step: 31  | total loss: [1m[32m0.18203[0m[0m | time: 97.918s
[2K
| Adam | epoch: 004 | loss: 0.18203 - acc: 0.9377 -- iter: 224/248
[A[ATraining Step: 32  | total loss: [1m[32m0.15248[0m[0m | time: 120.805s
[2K
| Adam | epoch: 004 | loss: 0.15248 - acc: 0.9517 | val_loss: 3.37669 - val_acc: 0.4231 -- iter: 248/248
--
Training Step: 33  | total loss: [1m[32m0.16210[0m[0m | time: 13.383s
[2K
| Adam | epoch: 005 | loss: 0.16210 - acc: 0.9486 -- iter: 032/248
[A[ATraining Step: 34  | total loss: [1m[32m0.16154[0m[0m | time: 23.572s
[2K
| Adam | epoch: 005 | loss: 0.16154 - acc: 0.9529 -- iter: 064/248
[A[ATraining Step: 35  | total loss: [1m[32m0.16690[0m[0m | time: 33.265s
[2K
| Adam | epoch: 005 | loss: 0.16690 - acc: 0.9562 -- iter: 096/248
[A[ATraining Step: 36  | total loss: [1m[32m0.13918[0m[0m | time: 45.100s
[2K
| Adam | epoch: 005 | loss: 0.13918 - acc: 0.9652 -- iter: 128/248
[A[ATraining Step: 37  | total loss: [1m[32m0.11583[0m[0m | time: 61.389s
[2K
| Adam | epoch: 005 | loss: 0.11583 - acc: 0.9721 -- iter: 160/248
[A[ATraining Step: 38  | total loss: [1m[32m0.10416[0m[0m | time: 83.067s
[2K
| Adam | epoch: 005 | loss: 0.10416 - acc: 0.9776 -- iter: 192/248
[A[ATraining Step: 39  | total loss: [1m[32m0.11413[0m[0m | time: 101.861s
[2K
| Adam | epoch: 005 | loss: 0.11413 - acc: 0.9759 -- iter: 224/248
[A[ATraining Step: 40  | total loss: [1m[32m0.10050[0m[0m | time: 130.899s
[2K
| Adam | epoch: 005 | loss: 0.10050 - acc: 0.9804 | val_loss: 3.71517 - val_acc: 0.4231 -- iter: 248/248
--
Training Step: 41  | total loss: [1m[32m0.09930[0m[0m | time: 13.543s
[2K
| Adam | epoch: 006 | loss: 0.09930 - acc: 0.9783 -- iter: 032/248
[A[ATraining Step: 42  | total loss: [1m[32m0.09141[0m[0m | time: 31.273s
[2K
| Adam | epoch: 006 | loss: 0.09141 - acc: 0.9822 -- iter: 064/248
[A[ATraining Step: 43  | total loss: [1m[32m0.07962[0m[0m | time: 48.197s
[2K
| Adam | epoch: 006 | loss: 0.07962 - acc: 0.9853 -- iter: 096/248
[A[ATraining Step: 44  | total loss: [1m[32m0.07159[0m[0m | time: 61.457s
[2K
| Adam | epoch: 006 | loss: 0.07159 - acc: 0.9879 -- iter: 128/248
[A[ATraining Step: 45  | total loss: [1m[32m0.07218[0m[0m | time: 78.810s
[2K
| Adam | epoch: 006 | loss: 0.07218 - acc: 0.9829 -- iter: 160/248
[A[ATraining Step: 46  | total loss: [1m[32m0.06409[0m[0m | time: 91.096s
[2K
| Adam | epoch: 006 | loss: 0.06409 - acc: 0.9857 -- iter: 192/248
[A[ATraining Step: 47  | total loss: [1m[32m0.05608[0m[0m | time: 101.231s
[2K
| Adam | epoch: 006 | loss: 0.05608 - acc: 0.9880 -- iter: 224/248
[A[ATraining Step: 48  | total loss: [1m[32m0.09027[0m[0m | time: 121.489s
[2K
| Adam | epoch: 006 | loss: 0.09027 - acc: 0.9849 | val_loss: 4.45784 - val_acc: 0.4231 -- iter: 248/248
--
Training Step: 49  | total loss: [1m[32m0.15362[0m[0m | time: 15.184s
[2K
| Adam | epoch: 007 | loss: 0.15362 - acc: 0.9775 -- iter: 032/248
[A[ATraining Step: 50  | total loss: [1m[32m0.13161[0m[0m | time: 29.805s
[2K
| Adam | epoch: 007 | loss: 0.13161 - acc: 0.9810 -- iter: 064/248
[A[ATraining Step: 51  | total loss: [1m[32m0.13841[0m[0m | time: 40.231s
[2K
| Adam | epoch: 007 | loss: 0.13841 - acc: 0.9696 -- iter: 096/248
[A[ATraining Step: 52  | total loss: [1m[32m0.12027[0m[0m | time: 50.397s
[2K
| Adam | epoch: 007 | loss: 0.12027 - acc: 0.9741 -- iter: 128/248
[A[ATraining Step: 53  | total loss: [1m[32m0.10969[0m[0m | time: 59.368s
[2K
| Adam | epoch: 007 | loss: 0.10969 - acc: 0.9779 -- iter: 160/248
[A[ATraining Step: 54  | total loss: [1m[32m0.09468[0m[0m | time: 69.712s
[2K
| Adam | epoch: 007 | loss: 0.09468 - acc: 0.9811 -- iter: 192/248
[A[ATraining Step: 55  | total loss: [1m[32m0.08282[0m[0m | time: 85.971s
[2K
| Adam | epoch: 007 | loss: 0.08282 - acc: 0.9838 -- iter: 224/248
[A[ATraining Step: 56  | total loss: [1m[32m0.07488[0m[0m | time: 106.529s
[2K
| Adam | epoch: 007 | loss: 0.07488 - acc: 0.9861 | val_loss: 1.69477 - val_acc: 0.5641 -- iter: 248/248
--
Training Step: 57  | total loss: [1m[32m0.07704[0m[0m | time: 10.720s
[2K
| Adam | epoch: 008 | loss: 0.07704 - acc: 0.9837 -- iter: 032/248
[A[ATraining Step: 58  | total loss: [1m[32m0.07053[0m[0m | time: 20.881s
[2K
| Adam | epoch: 008 | loss: 0.07053 - acc: 0.9859 -- iter: 064/248
[A[ATraining Step: 59  | total loss: [1m[32m0.06778[0m[0m | time: 34.851s
[2K
| Adam | epoch: 008 | loss: 0.06778 - acc: 0.9878 -- iter: 096/248
[A[ATraining Step: 60  | total loss: [1m[32m0.06831[0m[0m | time: 52.799s
[2K
| Adam | epoch: 008 | loss: 0.06831 - acc: 0.9853 -- iter: 128/248
[A[ATraining Step: 61  | total loss: [1m[32m0.06214[0m[0m | time: 68.820s
[2K
| Adam | epoch: 008 | loss: 0.06214 - acc: 0.9872 -- iter: 160/248
[A[ATraining Step: 62  | total loss: [1m[32m0.05520[0m[0m | time: 79.829s
[2K
| Adam | epoch: 008 | loss: 0.05520 - acc: 0.9889 -- iter: 192/248
[A[ATraining Step: 63  | total loss: [1m[32m0.06957[0m[0m | time: 91.202s
[2K
| Adam | epoch: 008 | loss: 0.06957 - acc: 0.9797 -- iter: 224/248
[A[ATraining Step: 64  | total loss: [1m[32m0.06371[0m[0m | time: 111.645s
[2K
| Adam | epoch: 008 | loss: 0.06371 - acc: 0.9822 | val_loss: 0.41646 - val_acc: 0.9359 -- iter: 248/248
--
Training Step: 65  | total loss: [1m[32m0.08923[0m[0m | time: 15.309s
[2K
| Adam | epoch: 009 | loss: 0.08923 - acc: 0.9767 -- iter: 032/248
[A[ATraining Step: 66  | total loss: [1m[32m0.10801[0m[0m | time: 30.468s
[2K
| Adam | epoch: 009 | loss: 0.10801 - acc: 0.9644 -- iter: 064/248
[A[ATraining Step: 67  | total loss: [1m[32m0.13258[0m[0m | time: 45.577s
[2K
| Adam | epoch: 009 | loss: 0.13258 - acc: 0.9649 -- iter: 096/248
[A[ATraining Step: 68  | total loss: [1m[32m0.12979[0m[0m | time: 59.500s
[2K
| Adam | epoch: 009 | loss: 0.12979 - acc: 0.9616 -- iter: 128/248
[A[ATraining Step: 69  | total loss: [1m[32m0.12075[0m[0m | time: 72.614s
[2K
| Adam | epoch: 009 | loss: 0.12075 - acc: 0.9661 -- iter: 160/248
[A[ATraining Step: 70  | total loss: [1m[32m0.15628[0m[0m | time: 84.352s
[2K
| Adam | epoch: 009 | loss: 0.15628 - acc: 0.9520 -- iter: 192/248
[A[ATraining Step: 71  | total loss: [1m[32m0.14957[0m[0m | time: 92.501s
[2K
| Adam | epoch: 009 | loss: 0.14957 - acc: 0.9539 -- iter: 224/248
[A[ATraining Step: 72  | total loss: [1m[32m0.14250[0m[0m | time: 106.016s
[2K
| Adam | epoch: 009 | loss: 0.14250 - acc: 0.9544 | val_loss: 0.93213 - val_acc: 0.6282 -- iter: 248/248
--
Training Step: 73  | total loss: [1m[32m0.13036[0m[0m | time: 38.819s
[2K
| Adam | epoch: 010 | loss: 0.13036 - acc: 0.9595 -- iter: 032/248
[A[ATraining Step: 74  | total loss: [1m[32m0.12680[0m[0m | time: 83.855s
[2K
| Adam | epoch: 010 | loss: 0.12680 - acc: 0.9605 -- iter: 064/248
[A[ATraining Step: 75  | total loss: [1m[32m0.14799[0m[0m | time: 104.600s
[2K
| Adam | epoch: 010 | loss: 0.14799 - acc: 0.9546 -- iter: 096/248
[A[ATraining Step: 76  | total loss: [1m[32m0.26346[0m[0m | time: 130.731s
[2K
| Adam | epoch: 010 | loss: 0.26346 - acc: 0.9293 -- iter: 128/248
[A[ATraining Step: 77  | total loss: [1m[32m0.23697[0m[0m | time: 141.015s
[2K
| Adam | epoch: 010 | loss: 0.23697 - acc: 0.9368 -- iter: 160/248
[A[ATraining Step: 78  | total loss: [1m[32m0.21441[0m[0m | time: 159.894s
[2K
| Adam | epoch: 010 | loss: 0.21441 - acc: 0.9434 -- iter: 192/248
[A[ATraining Step: 79  | total loss: [1m[32m0.20421[0m[0m | time: 180.081s
[2K
| Adam | epoch: 010 | loss: 0.20421 - acc: 0.9396 -- iter: 224/248
[A[ATraining Step: 80  | total loss: [1m[32m0.19287[0m[0m | time: 193.617s
[2K
| Adam | epoch: 010 | loss: 0.19287 - acc: 0.9426 | val_loss: 0.26380 - val_acc: 0.9231 -- iter: 248/248
--
Training Step: 81  | total loss: [1m[32m0.17808[0m[0m | time: 6.666s
[2K
| Adam | epoch: 011 | loss: 0.17808 - acc: 0.9484 -- iter: 032/248
[A[ATraining Step: 82  | total loss: [1m[32m0.16349[0m[0m | time: 15.073s
[2K
| Adam | epoch: 011 | loss: 0.16349 - acc: 0.9535 -- iter: 064/248
[A[ATraining Step: 83  | total loss: [1m[32m0.16410[0m[0m | time: 23.487s
[2K
| Adam | epoch: 011 | loss: 0.16410 - acc: 0.9551 -- iter: 096/248
[A[ATraining Step: 84  | total loss: [1m[32m0.15362[0m[0m | time: 31.758s
[2K
| Adam | epoch: 011 | loss: 0.15362 - acc: 0.9564 -- iter: 128/248
[A[ATraining Step: 85  | total loss: [1m[32m0.14947[0m[0m | time: 40.238s
[2K
| Adam | epoch: 011 | loss: 0.14947 - acc: 0.9577 -- iter: 160/248
[A[ATraining Step: 86  | total loss: [1m[32m0.13874[0m[0m | time: 48.693s
[2K
| Adam | epoch: 011 | loss: 0.13874 - acc: 0.9619 -- iter: 192/248
[A[ATraining Step: 87  | total loss: [1m[32m0.12839[0m[0m | time: 56.849s
[2K
| Adam | epoch: 011 | loss: 0.12839 - acc: 0.9657 -- iter: 224/248
[A[ATraining Step: 88  | total loss: [1m[32m0.12278[0m[0m | time: 68.810s
[2K
| Adam | epoch: 011 | loss: 0.12278 - acc: 0.9691 | val_loss: 0.43328 - val_acc: 0.7949 -- iter: 248/248
--
Training Step: 89  | total loss: [1m[32m0.12308[0m[0m | time: 6.568s
[2K
| Adam | epoch: 012 | loss: 0.12308 - acc: 0.9660 -- iter: 032/248
[A[ATraining Step: 90  | total loss: [1m[32m0.14818[0m[0m | time: 13.225s
[2K
| Adam | epoch: 012 | loss: 0.14818 - acc: 0.9610 -- iter: 064/248
[A[ATraining Step: 91  | total loss: [1m[32m0.13824[0m[0m | time: 21.532s
[2K
| Adam | epoch: 012 | loss: 0.13824 - acc: 0.9649 -- iter: 096/248
[A[ATraining Step: 92  | total loss: [1m[32m0.13867[0m[0m | time: 29.873s
[2K
| Adam | epoch: 012 | loss: 0.13867 - acc: 0.9622 -- iter: 128/248
[A[ATraining Step: 93  | total loss: [1m[32m0.13713[0m[0m | time: 38.132s
[2K
| Adam | epoch: 012 | loss: 0.13713 - acc: 0.9597 -- iter: 160/248
[A[ATraining Step: 94  | total loss: [1m[32m0.14432[0m[0m | time: 46.321s
[2K
| Adam | epoch: 012 | loss: 0.14432 - acc: 0.9575 -- iter: 192/248
[A[ATraining Step: 95  | total loss: [1m[32m0.13804[0m[0m | time: 54.570s
[2K
| Adam | epoch: 012 | loss: 0.13804 - acc: 0.9586 -- iter: 224/248
[A[ATraining Step: 96  | total loss: [1m[32m0.13327[0m[0m | time: 66.457s
[2K
| Adam | epoch: 012 | loss: 0.13327 - acc: 0.9596 | val_loss: 3.76289 - val_acc: 0.6282 -- iter: 248/248
--
Training Step: 97  | total loss: [1m[32m0.13249[0m[0m | time: 8.122s
[2K
| Adam | epoch: 013 | loss: 0.13249 - acc: 0.9574 -- iter: 032/248
[A[ATraining Step: 98  | total loss: [1m[32m0.12434[0m[0m | time: 14.604s
[2K
| Adam | epoch: 013 | loss: 0.12434 - acc: 0.9617 -- iter: 064/248
[A[ATraining Step: 99  | total loss: [1m[32m0.20284[0m[0m | time: 21.187s
[2K
| Adam | epoch: 013 | loss: 0.20284 - acc: 0.9405 -- iter: 096/248
[A[ATraining Step: 100  | total loss: [1m[32m0.22643[0m[0m | time: 29.611s
[2K
| Adam | epoch: 013 | loss: 0.22643 - acc: 0.9256 -- iter: 128/248
[A[ATraining Step: 101  | total loss: [1m[32m0.21440[0m[0m | time: 37.724s
[2K
| Adam | epoch: 013 | loss: 0.21440 - acc: 0.9268 -- iter: 160/248
[A[ATraining Step: 102  | total loss: [1m[32m0.19741[0m[0m | time: 45.931s
[2K
| Adam | epoch: 013 | loss: 0.19741 - acc: 0.9341 -- iter: 192/248
[A[ATraining Step: 103  | total loss: [1m[32m0.19056[0m[0m | time: 54.265s
[2K
| Adam | epoch: 013 | loss: 0.19056 - acc: 0.9376 -- iter: 224/248
[A[ATraining Step: 104  | total loss: [1m[32m0.17621[0m[0m | time: 66.347s
[2K
| Adam | epoch: 013 | loss: 0.17621 - acc: 0.9438 | val_loss: 0.96181 - val_acc: 0.5897 -- iter: 248/248
--
Training Step: 105  | total loss: [1m[32m0.16328[0m[0m | time: 8.313s
[2K
| Adam | epoch: 014 | loss: 0.16328 - acc: 0.9495 -- iter: 032/248
[A[ATraining Step: 106  | total loss: [1m[32m0.16093[0m[0m | time: 16.647s
[2K
| Adam | epoch: 014 | loss: 0.16093 - acc: 0.9514 -- iter: 064/248
[A[ATraining Step: 107  | total loss: [1m[32m0.15060[0m[0m | time: 23.241s
[2K
| Adam | epoch: 014 | loss: 0.15060 - acc: 0.9562 -- iter: 096/248
[A[ATraining Step: 108  | total loss: [1m[32m0.14858[0m[0m | time: 29.644s
[2K
| Adam | epoch: 014 | loss: 0.14858 - acc: 0.9565 -- iter: 128/248
[A[ATraining Step: 109  | total loss: [1m[32m0.13524[0m[0m | time: 37.671s
[2K
| Adam | epoch: 014 | loss: 0.13524 - acc: 0.9608 -- iter: 160/248
[A[ATraining Step: 110  | total loss: [1m[32m0.13990[0m[0m | time: 45.685s
[2K
| Adam | epoch: 014 | loss: 0.13990 - acc: 0.9585 -- iter: 192/248
[A[ATraining Step: 111  | total loss: [1m[32m0.13871[0m[0m | time: 53.768s
[2K
| Adam | epoch: 014 | loss: 0.13871 - acc: 0.9595 -- iter: 224/248
[A[ATraining Step: 112  | total loss: [1m[32m0.14557[0m[0m | time: 65.434s
[2K
| Adam | epoch: 014 | loss: 0.14557 - acc: 0.9604 | val_loss: 8.49465 - val_acc: 0.5769 -- iter: 248/248
--
Training Step: 113  | total loss: [1m[32m0.13233[0m[0m | time: 8.059s
[2K
| Adam | epoch: 015 | loss: 0.13233 - acc: 0.9644 -- iter: 032/248
[A[ATraining Step: 114  | total loss: [1m[32m0.12030[0m[0m | time: 16.168s
[2K
| Adam | epoch: 015 | loss: 0.12030 - acc: 0.9679 -- iter: 064/248
[A[ATraining Step: 115  | total loss: [1m[32m0.12704[0m[0m | time: 24.603s
[2K
| Adam | epoch: 015 | loss: 0.12704 - acc: 0.9649 -- iter: 096/248
[A[ATraining Step: 116  | total loss: [1m[32m0.12618[0m[0m | time: 30.909s
[2K
| Adam | epoch: 015 | loss: 0.12618 - acc: 0.9653 -- iter: 128/248
[A[ATraining Step: 117  | total loss: [1m[32m0.11902[0m[0m | time: 37.345s
[2K
| Adam | epoch: 015 | loss: 0.11902 - acc: 0.9646 -- iter: 160/248
[A[ATraining Step: 118  | total loss: [1m[32m0.11248[0m[0m | time: 45.441s
[2K
| Adam | epoch: 015 | loss: 0.11248 - acc: 0.9640 -- iter: 192/248
[A[ATraining Step: 119  | total loss: [1m[32m0.10754[0m[0m | time: 53.934s
[2K
| Adam | epoch: 015 | loss: 0.10754 - acc: 0.9644 -- iter: 224/248
[A[ATraining Step: 120  | total loss: [1m[32m0.10311[0m[0m | time: 65.835s
[2K
| Adam | epoch: 015 | loss: 0.10311 - acc: 0.9680 | val_loss: 1.33558 - val_acc: 0.7692 -- iter: 248/248
--
Validation AUC:0.9612794612794613
Validation AUPRC:0.9481095839131246
Test AUC:0.8983957219251336
Test AUPRC:0.8735646828559578
BestTestF1Score	0.89	0.74	0.86	0.8	1.0	44	11	23	0	1.0
BestTestMCCScore	0.89	0.74	0.86	0.8	1.0	44	11	23	0	1.0
BestTestAccuracyScore	0.89	0.74	0.86	0.8	1.0	44	11	23	0	1.0
BestValidationF1Score	0.93	0.83	0.91	0.87	1.0	45	7	26	0	1.0
BestValidationMCC	0.93	0.83	0.91	0.87	1.0	45	7	26	0	1.0
BestValidationAccuracy	0.93	0.83	0.91	0.87	1.0	45	7	26	0	1.0
TestPredictions (Threshold:1.0)
CHEMBL3667152,TP,ACT,1.0	CHEMBL3686164,TP,ACT,1.0	CHEMBL3659736,TP,ACT,1.0	CHEMBL111058,TN,INACT,0.25	CHEMBL77277,TN,INACT,0.36000001430511475	CHEMBL1093809,TP,ACT,1.0	CHEMBL3691047,TP,ACT,1.0	CHEMBL3680215,TP,ACT,1.0	CHEMBL565627,FP,INACT,1.0	CHEMBL3686530,TP,ACT,1.0	CHEMBL3686247,TP,ACT,1.0	CHEMBL1798046,FP,INACT,1.0	CHEMBL1097739,TN,INACT,0.8799999952316284	CHEMBL3691056,TP,ACT,1.0	CHEMBL1089883,TP,ACT,1.0	CHEMBL3680305,TP,ACT,1.0	CHEMBL2262733,TN,INACT,0.9900000095367432	CHEMBL583576,TN,INACT,0.009999999776482582	CHEMBL3686648,TP,ACT,1.0	CHEMBL1952083,TN,INACT,0.9300000071525574	CHEMBL3686258,TP,ACT,1.0	CHEMBL2158920,TN,INACT,0.009999999776482582	CHEMBL3691094,TP,ACT,1.0	CHEMBL3410537,FP,INACT,1.0	CHEMBL3690739,FP,INACT,1.0	CHEMBL3686540,TP,ACT,1.0	CHEMBL578159,FP,INACT,1.0	CHEMBL158897,TN,INACT,0.07999999821186066	CHEMBL3690710,FP,INACT,1.0	CHEMBL565710,TN,INACT,0.25999999046325684	CHEMBL3639974,TP,ACT,1.0	CHEMBL3690704,TP,ACT,1.0	CHEMBL247803,TN,INACT,0.7300000190734863	CHEMBL579183,TN,INACT,0.029999999329447746	CHEMBL3695046,TP,ACT,1.0	CHEMBL3686206,TP,ACT,1.0	CHEMBL3690812,FP,INACT,1.0	CHEMBL3691077,TP,ACT,1.0	CHEMBL3686250,TP,ACT,1.0	CHEMBL3690732,TP,ACT,1.0	CHEMBL219948,TP,ACT,1.0	CHEMBL393192,TP,ACT,1.0	CHEMBL1241252,TN,INACT,0.15000000596046448	CHEMBL3662501,TP,ACT,1.0	CHEMBL3680302,TP,ACT,1.0	CHEMBL3694981,TP,ACT,1.0	CHEMBL1241254,TN,INACT,0.05999999865889549	CHEMBL68162,FP,INACT,1.0	CHEMBL1213411,TN,INACT,0.0	CHEMBL3690687,FP,INACT,1.0	CHEMBL3690671,TP,ACT,1.0	CHEMBL3662320,TP,ACT,1.0	CHEMBL3691038,TP,ACT,1.0	CHEMBL2030411,TP,ACT,1.0	CHEMBL3662478,TP,ACT,1.0	CHEMBL3691098,TP,ACT,1.0	CHEMBL565892,TN,INACT,0.8500000238418579	CHEMBL1232568,TN,INACT,0.12999999523162842	CHEMBL3686505,TP,ACT,1.0	CHEMBL3690806,TP,ACT,1.0	CHEMBL1572622,TN,INACT,0.75	CHEMBL338962,FP,INACT,1.0	CHEMBL3690664,TP,ACT,1.0	CHEMBL3686625,TP,ACT,1.0	CHEMBL3695063,TP,ACT,1.0	CHEMBL2158921,TN,INACT,0.019999999552965164	CHEMBL1213371,TN,INACT,0.6600000262260437	CHEMBL33778,TN,INACT,0.03999999910593033	CHEMBL3686619,TP,ACT,1.0	CHEMBL3667111,TP,ACT,1.0	CHEMBL3690676,TP,ACT,1.0	CHEMBL3087999,TN,INACT,0.8299999833106995	CHEMBL219902,TP,ACT,1.0	CHEMBL3658224,TP,ACT,1.0	CHEMBL3691225,TP,ACT,1.0	CHEMBL1798053,FP,INACT,1.0	CHEMBL3818503,TN,INACT,0.9700000286102295	CHEMBL2158924,TN,INACT,0.009999999776482582	

