CNNModel CHEMBL2373 adam 0.0005 15 128 0 0.8 False True
Number of active compounds :	292
Number of inactive compounds :	292
---------------------------------
Run id: CNNModel_CHEMBL2373_adam_0.0005_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2373_adam_0.0005_15_128_0.8_True/
---------------------------------
Training samples: 373
Validation samples: 117
--
Training Step: 1  | time: 0.776s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/373
[A[ATraining Step: 2  | total loss: [1m[32m0.62387[0m[0m | time: 1.395s
[2K
| Adam | epoch: 001 | loss: 0.62387 - acc: 0.4219 -- iter: 064/373
[A[ATraining Step: 3  | total loss: [1m[32m0.68050[0m[0m | time: 2.008s
[2K
| Adam | epoch: 001 | loss: 0.68050 - acc: 0.5114 -- iter: 096/373
[A[ATraining Step: 4  | total loss: [1m[32m0.69173[0m[0m | time: 2.609s
[2K
| Adam | epoch: 001 | loss: 0.69173 - acc: 0.4325 -- iter: 128/373
[A[ATraining Step: 5  | total loss: [1m[32m0.69322[0m[0m | time: 3.231s
[2K
| Adam | epoch: 001 | loss: 0.69322 - acc: 0.4360 -- iter: 160/373
[A[ATraining Step: 6  | total loss: [1m[32m0.69302[0m[0m | time: 3.851s
[2K
| Adam | epoch: 001 | loss: 0.69302 - acc: 0.5173 -- iter: 192/373
[A[ATraining Step: 7  | total loss: [1m[32m0.69341[0m[0m | time: 4.493s
[2K
| Adam | epoch: 001 | loss: 0.69341 - acc: 0.4882 -- iter: 224/373
[A[ATraining Step: 8  | total loss: [1m[32m0.69351[0m[0m | time: 5.141s
[2K
| Adam | epoch: 001 | loss: 0.69351 - acc: 0.4772 -- iter: 256/373
[A[ATraining Step: 9  | total loss: [1m[32m0.69307[0m[0m | time: 5.748s
[2K
| Adam | epoch: 001 | loss: 0.69307 - acc: 0.5058 -- iter: 288/373
[A[ATraining Step: 10  | total loss: [1m[32m0.69335[0m[0m | time: 6.353s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.4873 -- iter: 320/373
[A[ATraining Step: 11  | total loss: [1m[32m0.69362[0m[0m | time: 6.964s
[2K
| Adam | epoch: 001 | loss: 0.69362 - acc: 0.4637 -- iter: 352/373
[A[ATraining Step: 12  | total loss: [1m[32m0.69341[0m[0m | time: 8.404s
[2K
| Adam | epoch: 001 | loss: 0.69341 - acc: 0.4800 | val_loss: 0.69333 - val_acc: 0.4701 -- iter: 373/373
--
Training Step: 13  | total loss: [1m[32m0.69305[0m[0m | time: 0.418s
[2K
| Adam | epoch: 002 | loss: 0.69305 - acc: 0.5804 -- iter: 032/373
[A[ATraining Step: 14  | total loss: [1m[32m0.69231[0m[0m | time: 1.023s
[2K
| Adam | epoch: 002 | loss: 0.69231 - acc: 0.6547 -- iter: 064/373
[A[ATraining Step: 15  | total loss: [1m[32m0.69236[0m[0m | time: 1.629s
[2K
| Adam | epoch: 002 | loss: 0.69236 - acc: 0.6064 -- iter: 096/373
[A[ATraining Step: 16  | total loss: [1m[32m0.69258[0m[0m | time: 2.231s
[2K
| Adam | epoch: 002 | loss: 0.69258 - acc: 0.5665 -- iter: 128/373
[A[ATraining Step: 17  | total loss: [1m[32m0.69169[0m[0m | time: 2.846s
[2K
| Adam | epoch: 002 | loss: 0.69169 - acc: 0.5763 -- iter: 160/373
[A[ATraining Step: 18  | total loss: [1m[32m0.69101[0m[0m | time: 3.448s
[2K
| Adam | epoch: 002 | loss: 0.69101 - acc: 0.5715 -- iter: 192/373
[A[ATraining Step: 19  | total loss: [1m[32m0.69444[0m[0m | time: 4.054s
[2K
| Adam | epoch: 002 | loss: 0.69444 - acc: 0.5164 -- iter: 224/373
[A[ATraining Step: 20  | total loss: [1m[32m0.69337[0m[0m | time: 4.670s
[2K
| Adam | epoch: 002 | loss: 0.69337 - acc: 0.5212 -- iter: 256/373
[A[ATraining Step: 21  | total loss: [1m[32m0.69201[0m[0m | time: 5.282s
[2K
| Adam | epoch: 002 | loss: 0.69201 - acc: 0.5340 -- iter: 288/373
[A[ATraining Step: 22  | total loss: [1m[32m0.69350[0m[0m | time: 5.889s
[2K
| Adam | epoch: 002 | loss: 0.69350 - acc: 0.5144 -- iter: 320/373
[A[ATraining Step: 23  | total loss: [1m[32m0.69193[0m[0m | time: 6.503s
[2K
| Adam | epoch: 002 | loss: 0.69193 - acc: 0.5284 -- iter: 352/373
[A[ATraining Step: 24  | total loss: [1m[32m0.69414[0m[0m | time: 8.142s
[2K
| Adam | epoch: 002 | loss: 0.69414 - acc: 0.5028 | val_loss: 0.69702 - val_acc: 0.4701 -- iter: 373/373
--
Training Step: 25  | total loss: [1m[32m0.68901[0m[0m | time: 0.421s
[2K
| Adam | epoch: 003 | loss: 0.68901 - acc: 0.5617 -- iter: 032/373
[A[ATraining Step: 26  | total loss: [1m[32m0.69183[0m[0m | time: 0.853s
[2K
| Adam | epoch: 003 | loss: 0.69183 - acc: 0.5265 -- iter: 064/373
[A[ATraining Step: 27  | total loss: [1m[32m0.69432[0m[0m | time: 1.455s
[2K
| Adam | epoch: 003 | loss: 0.69432 - acc: 0.5013 -- iter: 096/373
[A[ATraining Step: 28  | total loss: [1m[32m0.69326[0m[0m | time: 2.059s
[2K
| Adam | epoch: 003 | loss: 0.69326 - acc: 0.5088 -- iter: 128/373
[A[ATraining Step: 29  | total loss: [1m[32m0.69288[0m[0m | time: 2.664s
[2K
| Adam | epoch: 003 | loss: 0.69288 - acc: 0.5066 -- iter: 160/373
[A[ATraining Step: 30  | total loss: [1m[32m0.69297[0m[0m | time: 3.265s
[2K
| Adam | epoch: 003 | loss: 0.69297 - acc: 0.5051 -- iter: 192/373
[A[ATraining Step: 31  | total loss: [1m[32m0.69394[0m[0m | time: 3.867s
[2K
| Adam | epoch: 003 | loss: 0.69394 - acc: 0.4895 -- iter: 224/373
[A[ATraining Step: 32  | total loss: [1m[32m0.69466[0m[0m | time: 4.469s
[2K
| Adam | epoch: 003 | loss: 0.69466 - acc: 0.4778 -- iter: 256/373
[A[ATraining Step: 33  | total loss: [1m[32m0.69451[0m[0m | time: 5.067s
[2K
| Adam | epoch: 003 | loss: 0.69451 - acc: 0.4758 -- iter: 288/373
[A[ATraining Step: 34  | total loss: [1m[32m0.69382[0m[0m | time: 5.669s
[2K
| Adam | epoch: 003 | loss: 0.69382 - acc: 0.4810 -- iter: 320/373
[A[ATraining Step: 35  | total loss: [1m[32m0.69403[0m[0m | time: 6.280s
[2K
| Adam | epoch: 003 | loss: 0.69403 - acc: 0.4719 -- iter: 352/373
[A[ATraining Step: 36  | total loss: [1m[32m0.69398[0m[0m | time: 7.912s
[2K
| Adam | epoch: 003 | loss: 0.69398 - acc: 0.4712 | val_loss: 0.69329 - val_acc: 0.4701 -- iter: 373/373
--
Training Step: 37  | total loss: [1m[32m0.69227[0m[0m | time: 0.629s
[2K
| Adam | epoch: 004 | loss: 0.69227 - acc: 0.5145 -- iter: 032/373
[A[ATraining Step: 38  | total loss: [1m[32m0.69210[0m[0m | time: 1.064s
[2K
| Adam | epoch: 004 | loss: 0.69210 - acc: 0.5055 -- iter: 064/373
[A[ATraining Step: 39  | total loss: [1m[32m0.69293[0m[0m | time: 1.483s
[2K
| Adam | epoch: 004 | loss: 0.69293 - acc: 0.4726 -- iter: 096/373
[A[ATraining Step: 40  | total loss: [1m[32m0.69309[0m[0m | time: 2.087s
[2K
| Adam | epoch: 004 | loss: 0.69309 - acc: 0.4465 -- iter: 128/373
[A[ATraining Step: 41  | total loss: [1m[32m0.69280[0m[0m | time: 2.684s
[2K
| Adam | epoch: 004 | loss: 0.69280 - acc: 0.4678 -- iter: 160/373
[A[ATraining Step: 42  | total loss: [1m[32m0.69278[0m[0m | time: 3.281s
[2K
| Adam | epoch: 004 | loss: 0.69278 - acc: 0.4736 -- iter: 192/373
[A[ATraining Step: 43  | total loss: [1m[32m0.69231[0m[0m | time: 3.911s
[2K
| Adam | epoch: 004 | loss: 0.69231 - acc: 0.4948 -- iter: 224/373
[A[ATraining Step: 44  | total loss: [1m[32m0.69183[0m[0m | time: 4.513s
[2K
| Adam | epoch: 004 | loss: 0.69183 - acc: 0.5227 -- iter: 256/373
[A[ATraining Step: 45  | total loss: [1m[32m0.69095[0m[0m | time: 5.138s
[2K
| Adam | epoch: 004 | loss: 0.69095 - acc: 0.5348 -- iter: 288/373
[A[ATraining Step: 46  | total loss: [1m[32m0.68955[0m[0m | time: 5.764s
[2K
| Adam | epoch: 004 | loss: 0.68955 - acc: 0.5446 -- iter: 320/373
[A[ATraining Step: 47  | total loss: [1m[32m0.69239[0m[0m | time: 6.367s
[2K
| Adam | epoch: 004 | loss: 0.69239 - acc: 0.5117 -- iter: 352/373
[A[ATraining Step: 48  | total loss: [1m[32m0.69254[0m[0m | time: 7.977s
[2K
| Adam | epoch: 004 | loss: 0.69254 - acc: 0.4998 | val_loss: 0.69004 - val_acc: 0.5214 -- iter: 373/373
--
Training Step: 49  | total loss: [1m[32m0.69027[0m[0m | time: 0.612s
[2K
| Adam | epoch: 005 | loss: 0.69027 - acc: 0.5097 -- iter: 032/373
[A[ATraining Step: 50  | total loss: [1m[32m0.68977[0m[0m | time: 1.242s
[2K
| Adam | epoch: 005 | loss: 0.68977 - acc: 0.5179 -- iter: 064/373
[A[ATraining Step: 51  | total loss: [1m[32m0.68765[0m[0m | time: 1.657s
[2K
| Adam | epoch: 005 | loss: 0.68765 - acc: 0.5581 -- iter: 096/373
[A[ATraining Step: 52  | total loss: [1m[32m0.68990[0m[0m | time: 2.087s
[2K
| Adam | epoch: 005 | loss: 0.68990 - acc: 0.5529 -- iter: 128/373
[A[ATraining Step: 53  | total loss: [1m[32m0.69163[0m[0m | time: 2.699s
[2K
| Adam | epoch: 005 | loss: 0.69163 - acc: 0.5486 -- iter: 160/373
[A[ATraining Step: 54  | total loss: [1m[32m0.68887[0m[0m | time: 3.311s
[2K
| Adam | epoch: 005 | loss: 0.68887 - acc: 0.5597 -- iter: 192/373
[A[ATraining Step: 55  | total loss: [1m[32m0.68490[0m[0m | time: 3.928s
[2K
| Adam | epoch: 005 | loss: 0.68490 - acc: 0.5824 -- iter: 224/373
[A[ATraining Step: 56  | total loss: [1m[32m0.68338[0m[0m | time: 4.531s
[2K
| Adam | epoch: 005 | loss: 0.68338 - acc: 0.6016 -- iter: 256/373
[A[ATraining Step: 57  | total loss: [1m[32m0.68087[0m[0m | time: 5.139s
[2K
| Adam | epoch: 005 | loss: 0.68087 - acc: 0.6265 -- iter: 288/373
[A[ATraining Step: 58  | total loss: [1m[32m0.67760[0m[0m | time: 5.788s
[2K
| Adam | epoch: 005 | loss: 0.67760 - acc: 0.6476 -- iter: 320/373
[A[ATraining Step: 59  | total loss: [1m[32m0.67300[0m[0m | time: 6.386s
[2K
| Adam | epoch: 005 | loss: 0.67300 - acc: 0.6613 -- iter: 352/373
[A[ATraining Step: 60  | total loss: [1m[32m0.67512[0m[0m | time: 8.001s
[2K
| Adam | epoch: 005 | loss: 0.67512 - acc: 0.6317 | val_loss: 0.66688 - val_acc: 0.6068 -- iter: 373/373
--
Training Step: 61  | total loss: [1m[32m0.67605[0m[0m | time: 0.603s
[2K
| Adam | epoch: 006 | loss: 0.67605 - acc: 0.6186 -- iter: 032/373
[A[ATraining Step: 62  | total loss: [1m[32m0.67383[0m[0m | time: 1.234s
[2K
| Adam | epoch: 006 | loss: 0.67383 - acc: 0.6194 -- iter: 064/373
[A[ATraining Step: 63  | total loss: [1m[32m0.67483[0m[0m | time: 1.834s
[2K
| Adam | epoch: 006 | loss: 0.67483 - acc: 0.6201 -- iter: 096/373
[A[ATraining Step: 64  | total loss: [1m[32m0.67555[0m[0m | time: 2.245s
[2K
| Adam | epoch: 006 | loss: 0.67555 - acc: 0.6090 -- iter: 128/373
[A[ATraining Step: 65  | total loss: [1m[32m0.66837[0m[0m | time: 2.658s
[2K
| Adam | epoch: 006 | loss: 0.66837 - acc: 0.6279 -- iter: 160/373
[A[ATraining Step: 66  | total loss: [1m[32m0.66033[0m[0m | time: 3.258s
[2K
| Adam | epoch: 006 | loss: 0.66033 - acc: 0.6384 -- iter: 192/373
[A[ATraining Step: 67  | total loss: [1m[32m0.65891[0m[0m | time: 3.885s
[2K
| Adam | epoch: 006 | loss: 0.65891 - acc: 0.6368 -- iter: 224/373
[A[ATraining Step: 68  | total loss: [1m[32m0.64699[0m[0m | time: 4.499s
[2K
| Adam | epoch: 006 | loss: 0.64699 - acc: 0.6502 -- iter: 256/373
[A[ATraining Step: 69  | total loss: [1m[32m0.64366[0m[0m | time: 5.097s
[2K
| Adam | epoch: 006 | loss: 0.64366 - acc: 0.6582 -- iter: 288/373
[A[ATraining Step: 70  | total loss: [1m[32m0.64260[0m[0m | time: 5.696s
[2K
| Adam | epoch: 006 | loss: 0.64260 - acc: 0.6616 -- iter: 320/373
[A[ATraining Step: 71  | total loss: [1m[32m0.63319[0m[0m | time: 6.316s
[2K
| Adam | epoch: 006 | loss: 0.63319 - acc: 0.6717 -- iter: 352/373
[A[ATraining Step: 72  | total loss: [1m[32m0.62882[0m[0m | time: 7.931s
[2K
| Adam | epoch: 006 | loss: 0.62882 - acc: 0.6734 | val_loss: 0.66575 - val_acc: 0.5470 -- iter: 373/373
--
Training Step: 73  | total loss: [1m[32m0.61849[0m[0m | time: 0.613s
[2K
| Adam | epoch: 007 | loss: 0.61849 - acc: 0.6785 -- iter: 032/373
[A[ATraining Step: 74  | total loss: [1m[32m0.61709[0m[0m | time: 1.219s
[2K
| Adam | epoch: 007 | loss: 0.61709 - acc: 0.6726 -- iter: 064/373
[A[ATraining Step: 75  | total loss: [1m[32m0.64396[0m[0m | time: 1.824s
[2K
| Adam | epoch: 007 | loss: 0.64396 - acc: 0.6471 -- iter: 096/373
[A[ATraining Step: 76  | total loss: [1m[32m0.63736[0m[0m | time: 2.431s
[2K
| Adam | epoch: 007 | loss: 0.63736 - acc: 0.6548 -- iter: 128/373
[A[ATraining Step: 77  | total loss: [1m[32m0.62444[0m[0m | time: 2.841s
[2K
| Adam | epoch: 007 | loss: 0.62444 - acc: 0.6682 -- iter: 160/373
[A[ATraining Step: 78  | total loss: [1m[32m0.62081[0m[0m | time: 3.258s
[2K
| Adam | epoch: 007 | loss: 0.62081 - acc: 0.6730 -- iter: 192/373
[A[ATraining Step: 79  | total loss: [1m[32m0.61173[0m[0m | time: 3.873s
[2K
| Adam | epoch: 007 | loss: 0.61173 - acc: 0.6822 -- iter: 224/373
[A[ATraining Step: 80  | total loss: [1m[32m0.60471[0m[0m | time: 4.493s
[2K
| Adam | epoch: 007 | loss: 0.60471 - acc: 0.6891 -- iter: 256/373
[A[ATraining Step: 81  | total loss: [1m[32m0.59629[0m[0m | time: 5.107s
[2K
| Adam | epoch: 007 | loss: 0.59629 - acc: 0.6953 -- iter: 288/373
[A[ATraining Step: 82  | total loss: [1m[32m0.59763[0m[0m | time: 5.719s
[2K
| Adam | epoch: 007 | loss: 0.59763 - acc: 0.6851 -- iter: 320/373
[A[ATraining Step: 83  | total loss: [1m[32m0.59907[0m[0m | time: 6.338s
[2K
| Adam | epoch: 007 | loss: 0.59907 - acc: 0.6822 -- iter: 352/373
[A[ATraining Step: 84  | total loss: [1m[32m0.59420[0m[0m | time: 7.947s
[2K
| Adam | epoch: 007 | loss: 0.59420 - acc: 0.6859 | val_loss: 0.61316 - val_acc: 0.6496 -- iter: 373/373
--
Training Step: 85  | total loss: [1m[32m0.58905[0m[0m | time: 0.623s
[2K
| Adam | epoch: 008 | loss: 0.58905 - acc: 0.6829 -- iter: 032/373
[A[ATraining Step: 86  | total loss: [1m[32m0.59026[0m[0m | time: 1.226s
[2K
| Adam | epoch: 008 | loss: 0.59026 - acc: 0.6771 -- iter: 064/373
[A[ATraining Step: 87  | total loss: [1m[32m0.59153[0m[0m | time: 1.843s
[2K
| Adam | epoch: 008 | loss: 0.59153 - acc: 0.6719 -- iter: 096/373
[A[ATraining Step: 88  | total loss: [1m[32m0.59136[0m[0m | time: 2.457s
[2K
| Adam | epoch: 008 | loss: 0.59136 - acc: 0.6672 -- iter: 128/373
[A[ATraining Step: 89  | total loss: [1m[32m0.57411[0m[0m | time: 3.060s
[2K
| Adam | epoch: 008 | loss: 0.57411 - acc: 0.6818 -- iter: 160/373
[A[ATraining Step: 90  | total loss: [1m[32m0.56220[0m[0m | time: 3.478s
[2K
| Adam | epoch: 008 | loss: 0.56220 - acc: 0.6948 -- iter: 192/373
[A[ATraining Step: 91  | total loss: [1m[32m0.57299[0m[0m | time: 3.889s
[2K
| Adam | epoch: 008 | loss: 0.57299 - acc: 0.6920 -- iter: 224/373
[A[ATraining Step: 92  | total loss: [1m[32m0.57108[0m[0m | time: 4.490s
[2K
| Adam | epoch: 008 | loss: 0.57108 - acc: 0.6895 -- iter: 256/373
[A[ATraining Step: 93  | total loss: [1m[32m0.56614[0m[0m | time: 5.089s
[2K
| Adam | epoch: 008 | loss: 0.56614 - acc: 0.6924 -- iter: 288/373
[A[ATraining Step: 94  | total loss: [1m[32m0.58118[0m[0m | time: 5.702s
[2K
| Adam | epoch: 008 | loss: 0.58118 - acc: 0.6825 -- iter: 320/373
[A[ATraining Step: 95  | total loss: [1m[32m0.58244[0m[0m | time: 6.333s
[2K
| Adam | epoch: 008 | loss: 0.58244 - acc: 0.6705 -- iter: 352/373
[A[ATraining Step: 96  | total loss: [1m[32m0.58149[0m[0m | time: 7.950s
[2K
| Adam | epoch: 008 | loss: 0.58149 - acc: 0.6785 | val_loss: 0.60102 - val_acc: 0.6581 -- iter: 373/373
--
Training Step: 97  | total loss: [1m[32m0.57567[0m[0m | time: 0.606s
[2K
| Adam | epoch: 009 | loss: 0.57567 - acc: 0.6825 -- iter: 032/373
[A[ATraining Step: 98  | total loss: [1m[32m0.57719[0m[0m | time: 1.200s
[2K
| Adam | epoch: 009 | loss: 0.57719 - acc: 0.6861 -- iter: 064/373
[A[ATraining Step: 99  | total loss: [1m[32m0.57945[0m[0m | time: 1.798s
[2K
| Adam | epoch: 009 | loss: 0.57945 - acc: 0.6863 -- iter: 096/373
[A[ATraining Step: 100  | total loss: [1m[32m0.57148[0m[0m | time: 2.401s
[2K
| Adam | epoch: 009 | loss: 0.57148 - acc: 0.6895 -- iter: 128/373
[A[ATraining Step: 101  | total loss: [1m[32m0.57683[0m[0m | time: 2.997s
[2K
| Adam | epoch: 009 | loss: 0.57683 - acc: 0.6893 -- iter: 160/373
[A[ATraining Step: 102  | total loss: [1m[32m0.57351[0m[0m | time: 3.596s
[2K
| Adam | epoch: 009 | loss: 0.57351 - acc: 0.6923 -- iter: 192/373
[A[ATraining Step: 103  | total loss: [1m[32m0.55945[0m[0m | time: 4.024s
[2K
| Adam | epoch: 009 | loss: 0.55945 - acc: 0.7168 -- iter: 224/373
[A[ATraining Step: 104  | total loss: [1m[32m0.54934[0m[0m | time: 4.439s
[2K
| Adam | epoch: 009 | loss: 0.54934 - acc: 0.7308 -- iter: 256/373
[A[ATraining Step: 105  | total loss: [1m[32m0.53870[0m[0m | time: 5.049s
[2K
| Adam | epoch: 009 | loss: 0.53870 - acc: 0.7435 -- iter: 288/373
[A[ATraining Step: 106  | total loss: [1m[32m0.53138[0m[0m | time: 5.658s
[2K
| Adam | epoch: 009 | loss: 0.53138 - acc: 0.7472 -- iter: 320/373
[A[ATraining Step: 107  | total loss: [1m[32m0.52479[0m[0m | time: 6.265s
[2K
| Adam | epoch: 009 | loss: 0.52479 - acc: 0.7506 -- iter: 352/373
[A[ATraining Step: 108  | total loss: [1m[32m0.51181[0m[0m | time: 7.866s
[2K
| Adam | epoch: 009 | loss: 0.51181 - acc: 0.7631 | val_loss: 0.54602 - val_acc: 0.7350 -- iter: 373/373
--
Training Step: 109  | total loss: [1m[32m0.50063[0m[0m | time: 0.602s
[2K
| Adam | epoch: 010 | loss: 0.50063 - acc: 0.7680 -- iter: 032/373
[A[ATraining Step: 110  | total loss: [1m[32m0.49056[0m[0m | time: 1.205s
[2K
| Adam | epoch: 010 | loss: 0.49056 - acc: 0.7756 -- iter: 064/373
[A[ATraining Step: 111  | total loss: [1m[32m0.47395[0m[0m | time: 1.812s
[2K
| Adam | epoch: 010 | loss: 0.47395 - acc: 0.7887 -- iter: 096/373
[A[ATraining Step: 112  | total loss: [1m[32m0.46524[0m[0m | time: 2.414s
[2K
| Adam | epoch: 010 | loss: 0.46524 - acc: 0.7942 -- iter: 128/373
[A[ATraining Step: 113  | total loss: [1m[32m0.45115[0m[0m | time: 3.032s
[2K
| Adam | epoch: 010 | loss: 0.45115 - acc: 0.8022 -- iter: 160/373
[A[ATraining Step: 114  | total loss: [1m[32m0.44629[0m[0m | time: 3.640s
[2K
| Adam | epoch: 010 | loss: 0.44629 - acc: 0.8033 -- iter: 192/373
[A[ATraining Step: 115  | total loss: [1m[32m0.44317[0m[0m | time: 4.242s
[2K
| Adam | epoch: 010 | loss: 0.44317 - acc: 0.7948 -- iter: 224/373
[A[ATraining Step: 116  | total loss: [1m[32m0.41780[0m[0m | time: 4.673s
[2K
| Adam | epoch: 010 | loss: 0.41780 - acc: 0.8060 -- iter: 256/373
[A[ATraining Step: 117  | total loss: [1m[32m0.40900[0m[0m | time: 5.101s
[2K
| Adam | epoch: 010 | loss: 0.40900 - acc: 0.8158 -- iter: 288/373
[A[ATraining Step: 118  | total loss: [1m[32m0.40609[0m[0m | time: 5.710s
[2K
| Adam | epoch: 010 | loss: 0.40609 - acc: 0.8200 -- iter: 320/373
[A[ATraining Step: 119  | total loss: [1m[32m0.43703[0m[0m | time: 6.323s
[2K
| Adam | epoch: 010 | loss: 0.43703 - acc: 0.8099 -- iter: 352/373
[A[ATraining Step: 120  | total loss: [1m[32m0.42563[0m[0m | time: 7.943s
[2K
| Adam | epoch: 010 | loss: 0.42563 - acc: 0.8132 | val_loss: 0.41349 - val_acc: 0.7949 -- iter: 373/373
--
Training Step: 121  | total loss: [1m[32m0.41591[0m[0m | time: 0.603s
[2K
| Adam | epoch: 011 | loss: 0.41591 - acc: 0.8225 -- iter: 032/373
[A[ATraining Step: 122  | total loss: [1m[32m0.41915[0m[0m | time: 1.204s
[2K
| Adam | epoch: 011 | loss: 0.41915 - acc: 0.8215 -- iter: 064/373
[A[ATraining Step: 123  | total loss: [1m[32m0.40880[0m[0m | time: 1.813s
[2K
| Adam | epoch: 011 | loss: 0.40880 - acc: 0.8206 -- iter: 096/373
[A[ATraining Step: 124  | total loss: [1m[32m0.38334[0m[0m | time: 2.429s
[2K
| Adam | epoch: 011 | loss: 0.38334 - acc: 0.8354 -- iter: 128/373
[A[ATraining Step: 125  | total loss: [1m[32m0.36658[0m[0m | time: 3.037s
[2K
| Adam | epoch: 011 | loss: 0.36658 - acc: 0.8519 -- iter: 160/373
[A[ATraining Step: 126  | total loss: [1m[32m0.36768[0m[0m | time: 3.672s
[2K
| Adam | epoch: 011 | loss: 0.36768 - acc: 0.8448 -- iter: 192/373
[A[ATraining Step: 127  | total loss: [1m[32m0.38087[0m[0m | time: 4.257s
[2K
| Adam | epoch: 011 | loss: 0.38087 - acc: 0.8322 -- iter: 224/373
[A[ATraining Step: 128  | total loss: [1m[32m0.36459[0m[0m | time: 4.866s
[2K
| Adam | epoch: 011 | loss: 0.36459 - acc: 0.8428 -- iter: 256/373
[A[ATraining Step: 129  | total loss: [1m[32m0.35015[0m[0m | time: 5.288s
[2K
| Adam | epoch: 011 | loss: 0.35015 - acc: 0.8491 -- iter: 288/373
[A[ATraining Step: 130  | total loss: [1m[32m0.35296[0m[0m | time: 5.710s
[2K
| Adam | epoch: 011 | loss: 0.35296 - acc: 0.8451 -- iter: 320/373
[A[ATraining Step: 131  | total loss: [1m[32m0.34606[0m[0m | time: 6.312s
[2K
| Adam | epoch: 011 | loss: 0.34606 - acc: 0.8463 -- iter: 352/373
[A[ATraining Step: 132  | total loss: [1m[32m0.33814[0m[0m | time: 7.917s
[2K
| Adam | epoch: 011 | loss: 0.33814 - acc: 0.8555 | val_loss: 0.36878 - val_acc: 0.8376 -- iter: 373/373
--
Training Step: 133  | total loss: [1m[32m0.33814[0m[0m | time: 0.616s
[2K
| Adam | epoch: 012 | loss: 0.33814 - acc: 0.8574 -- iter: 032/373
[A[ATraining Step: 134  | total loss: [1m[32m0.31998[0m[0m | time: 1.215s
[2K
| Adam | epoch: 012 | loss: 0.31998 - acc: 0.8654 -- iter: 064/373
[A[ATraining Step: 135  | total loss: [1m[32m0.31000[0m[0m | time: 1.819s
[2K
| Adam | epoch: 012 | loss: 0.31000 - acc: 0.8695 -- iter: 096/373
[A[ATraining Step: 136  | total loss: [1m[32m0.29910[0m[0m | time: 2.422s
[2K
| Adam | epoch: 012 | loss: 0.29910 - acc: 0.8763 -- iter: 128/373
[A[ATraining Step: 137  | total loss: [1m[32m0.30873[0m[0m | time: 3.019s
[2K
| Adam | epoch: 012 | loss: 0.30873 - acc: 0.8731 -- iter: 160/373
[A[ATraining Step: 138  | total loss: [1m[32m0.29702[0m[0m | time: 3.617s
[2K
| Adam | epoch: 012 | loss: 0.29702 - acc: 0.8764 -- iter: 192/373
[A[ATraining Step: 139  | total loss: [1m[32m0.28922[0m[0m | time: 4.218s
[2K
| Adam | epoch: 012 | loss: 0.28922 - acc: 0.8762 -- iter: 224/373
[A[ATraining Step: 140  | total loss: [1m[32m0.28473[0m[0m | time: 4.831s
[2K
| Adam | epoch: 012 | loss: 0.28473 - acc: 0.8730 -- iter: 256/373
[A[ATraining Step: 141  | total loss: [1m[32m0.27504[0m[0m | time: 5.441s
[2K
| Adam | epoch: 012 | loss: 0.27504 - acc: 0.8794 -- iter: 288/373
[A[ATraining Step: 142  | total loss: [1m[32m0.25897[0m[0m | time: 5.868s
[2K
| Adam | epoch: 012 | loss: 0.25897 - acc: 0.8852 -- iter: 320/373
[A[ATraining Step: 143  | total loss: [1m[32m0.25929[0m[0m | time: 6.277s
[2K
| Adam | epoch: 012 | loss: 0.25929 - acc: 0.8824 -- iter: 352/373
[A[ATraining Step: 144  | total loss: [1m[32m0.24980[0m[0m | time: 7.905s
[2K
| Adam | epoch: 012 | loss: 0.24980 - acc: 0.8894 | val_loss: 0.43884 - val_acc: 0.8205 -- iter: 373/373
--
Training Step: 145  | total loss: [1m[32m0.23923[0m[0m | time: 0.613s
[2K
| Adam | epoch: 013 | loss: 0.23923 - acc: 0.8942 -- iter: 032/373
[A[ATraining Step: 146  | total loss: [1m[32m0.24035[0m[0m | time: 1.227s
[2K
| Adam | epoch: 013 | loss: 0.24035 - acc: 0.8986 -- iter: 064/373
[A[ATraining Step: 147  | total loss: [1m[32m0.22982[0m[0m | time: 1.836s
[2K
| Adam | epoch: 013 | loss: 0.22982 - acc: 0.8993 -- iter: 096/373
[A[ATraining Step: 148  | total loss: [1m[32m0.21252[0m[0m | time: 2.440s
[2K
| Adam | epoch: 013 | loss: 0.21252 - acc: 0.9094 -- iter: 128/373
[A[ATraining Step: 149  | total loss: [1m[32m0.21125[0m[0m | time: 3.064s
[2K
| Adam | epoch: 013 | loss: 0.21125 - acc: 0.9091 -- iter: 160/373
[A[ATraining Step: 150  | total loss: [1m[32m0.20309[0m[0m | time: 3.699s
[2K
| Adam | epoch: 013 | loss: 0.20309 - acc: 0.9150 -- iter: 192/373
[A[ATraining Step: 151  | total loss: [1m[32m0.19189[0m[0m | time: 4.300s
[2K
| Adam | epoch: 013 | loss: 0.19189 - acc: 0.9204 -- iter: 224/373
[A[ATraining Step: 152  | total loss: [1m[32m0.18410[0m[0m | time: 4.898s
[2K
| Adam | epoch: 013 | loss: 0.18410 - acc: 0.9253 -- iter: 256/373
[A[ATraining Step: 153  | total loss: [1m[32m0.18193[0m[0m | time: 5.507s
[2K
| Adam | epoch: 013 | loss: 0.18193 - acc: 0.9265 -- iter: 288/373
[A[ATraining Step: 154  | total loss: [1m[32m0.18138[0m[0m | time: 6.112s
[2K
| Adam | epoch: 013 | loss: 0.18138 - acc: 0.9245 -- iter: 320/373
[A[ATraining Step: 155  | total loss: [1m[32m0.17273[0m[0m | time: 6.522s
[2K
| Adam | epoch: 013 | loss: 0.17273 - acc: 0.9320 -- iter: 352/373
[A[ATraining Step: 156  | total loss: [1m[32m0.15846[0m[0m | time: 7.943s
[2K
| Adam | epoch: 013 | loss: 0.15846 - acc: 0.9388 | val_loss: 0.46540 - val_acc: 0.8120 -- iter: 373/373
--
Training Step: 157  | total loss: [1m[32m0.14494[0m[0m | time: 0.603s
[2K
| Adam | epoch: 014 | loss: 0.14494 - acc: 0.9449 -- iter: 032/373
[A[ATraining Step: 158  | total loss: [1m[32m0.13971[0m[0m | time: 1.262s
[2K
| Adam | epoch: 014 | loss: 0.13971 - acc: 0.9473 -- iter: 064/373
[A[ATraining Step: 159  | total loss: [1m[32m0.13119[0m[0m | time: 1.869s
[2K
| Adam | epoch: 014 | loss: 0.13119 - acc: 0.9526 -- iter: 096/373
[A[ATraining Step: 160  | total loss: [1m[32m0.12129[0m[0m | time: 2.486s
[2K
| Adam | epoch: 014 | loss: 0.12129 - acc: 0.9573 -- iter: 128/373
[A[ATraining Step: 161  | total loss: [1m[32m0.12578[0m[0m | time: 3.090s
[2K
| Adam | epoch: 014 | loss: 0.12578 - acc: 0.9553 -- iter: 160/373
[A[ATraining Step: 162  | total loss: [1m[32m0.13796[0m[0m | time: 3.690s
[2K
| Adam | epoch: 014 | loss: 0.13796 - acc: 0.9504 -- iter: 192/373
[A[ATraining Step: 163  | total loss: [1m[32m0.13867[0m[0m | time: 4.297s
[2K
| Adam | epoch: 014 | loss: 0.13867 - acc: 0.9460 -- iter: 224/373
[A[ATraining Step: 164  | total loss: [1m[32m0.12962[0m[0m | time: 4.897s
[2K
| Adam | epoch: 014 | loss: 0.12962 - acc: 0.9514 -- iter: 256/373
[A[ATraining Step: 165  | total loss: [1m[32m0.12161[0m[0m | time: 5.493s
[2K
| Adam | epoch: 014 | loss: 0.12161 - acc: 0.9563 -- iter: 288/373
[A[ATraining Step: 166  | total loss: [1m[32m0.11593[0m[0m | time: 6.089s
[2K
| Adam | epoch: 014 | loss: 0.11593 - acc: 0.9575 -- iter: 320/373
[A[ATraining Step: 167  | total loss: [1m[32m0.11487[0m[0m | time: 6.708s
[2K
| Adam | epoch: 014 | loss: 0.11487 - acc: 0.9555 -- iter: 352/373
[A[ATraining Step: 168  | total loss: [1m[32m0.10728[0m[0m | time: 8.139s
[2K
| Adam | epoch: 014 | loss: 0.10728 - acc: 0.9600 | val_loss: 0.44759 - val_acc: 0.8034 -- iter: 373/373
--
Training Step: 169  | total loss: [1m[32m0.10489[0m[0m | time: 0.433s
[2K
| Adam | epoch: 015 | loss: 0.10489 - acc: 0.9640 -- iter: 032/373
[A[ATraining Step: 170  | total loss: [1m[32m0.09875[0m[0m | time: 1.055s
[2K
| Adam | epoch: 015 | loss: 0.09875 - acc: 0.9676 -- iter: 064/373
[A[ATraining Step: 171  | total loss: [1m[32m0.09355[0m[0m | time: 1.663s
[2K
| Adam | epoch: 015 | loss: 0.09355 - acc: 0.9708 -- iter: 096/373
[A[ATraining Step: 172  | total loss: [1m[32m0.08937[0m[0m | time: 2.281s
[2K
| Adam | epoch: 015 | loss: 0.08937 - acc: 0.9737 -- iter: 128/373
[A[ATraining Step: 173  | total loss: [1m[32m0.08356[0m[0m | time: 2.888s
[2K
| Adam | epoch: 015 | loss: 0.08356 - acc: 0.9764 -- iter: 160/373
[A[ATraining Step: 174  | total loss: [1m[32m0.09586[0m[0m | time: 3.507s
[2K
| Adam | epoch: 015 | loss: 0.09586 - acc: 0.9725 -- iter: 192/373
[A[ATraining Step: 175  | total loss: [1m[32m0.08922[0m[0m | time: 4.108s
[2K
| Adam | epoch: 015 | loss: 0.08922 - acc: 0.9752 -- iter: 224/373
[A[ATraining Step: 176  | total loss: [1m[32m0.14554[0m[0m | time: 4.709s
[2K
| Adam | epoch: 015 | loss: 0.14554 - acc: 0.9683 -- iter: 256/373
[A[ATraining Step: 177  | total loss: [1m[32m0.13621[0m[0m | time: 5.314s
[2K
| Adam | epoch: 015 | loss: 0.13621 - acc: 0.9684 -- iter: 288/373
[A[ATraining Step: 178  | total loss: [1m[32m0.12712[0m[0m | time: 5.913s
[2K
| Adam | epoch: 015 | loss: 0.12712 - acc: 0.9684 -- iter: 320/373
[A[ATraining Step: 179  | total loss: [1m[32m0.11542[0m[0m | time: 6.527s
[2K
| Adam | epoch: 015 | loss: 0.11542 - acc: 0.9716 -- iter: 352/373
[A[ATraining Step: 180  | total loss: [1m[32m0.11250[0m[0m | time: 8.156s
[2K
| Adam | epoch: 015 | loss: 0.11250 - acc: 0.9713 | val_loss: 0.53346 - val_acc: 0.8291 -- iter: 373/373
--
Validation AUC:0.9310850439882699
Validation AUPRC:0.9328683688439217
Test AUC:0.919496487119438
Test AUPRC:0.9214828206850918
BestTestF1Score	0.89	0.76	0.88	0.86	0.92	56	9	47	5	0.87
BestTestMCCScore	0.89	0.76	0.88	0.86	0.92	56	9	47	5	0.87
BestTestAccuracyScore	0.89	0.76	0.88	0.86	0.92	56	9	47	5	0.87
BestValidationF1Score	0.9	0.78	0.89	0.89	0.9	56	7	48	6	0.87
BestValidationMCC	0.9	0.78	0.89	0.89	0.9	56	7	48	6	0.87
BestValidationAccuracy	0.9	0.78	0.89	0.89	0.9	56	7	48	6	0.87
TestPredictions (Threshold:0.87)
CHEMBL441305,FP,INACT,1.0	CHEMBL3646970,TP,ACT,1.0	CHEMBL3646909,TP,ACT,1.0	CHEMBL3646986,TP,ACT,1.0	CHEMBL185283,TN,INACT,0.0	CHEMBL3647013,TP,ACT,1.0	CHEMBL251948,TN,INACT,0.0	CHEMBL127385,FN,ACT,0.6100000143051147	CHEMBL105724,TN,INACT,0.7300000190734863	CHEMBL3646960,TP,ACT,1.0	CHEMBL475496,FP,INACT,0.9900000095367432	CHEMBL425497,TP,ACT,0.9900000095367432	CHEMBL486953,TP,ACT,0.9700000286102295	CHEMBL414085,TN,INACT,0.10000000149011612	CHEMBL171211,TP,ACT,0.9900000095367432	CHEMBL174463,TN,INACT,0.4000000059604645	CHEMBL296245,FP,INACT,0.9100000262260437	CHEMBL3327366,TN,INACT,0.0	CHEMBL126106,TN,INACT,0.4399999976158142	CHEMBL3646939,TP,ACT,1.0	CHEMBL3646988,TP,ACT,1.0	CHEMBL42359,TN,INACT,0.18000000715255737	CHEMBL400677,TN,INACT,0.0	CHEMBL1916689,FP,INACT,1.0	CHEMBL3639459,TP,ACT,1.0	CHEMBL486971,TP,ACT,1.0	CHEMBL3665436,TN,INACT,0.75	CHEMBL2115042,TN,INACT,0.18000000715255737	CHEMBL3646943,TP,ACT,1.0	CHEMBL250715,TN,INACT,0.0	CHEMBL1082013,TN,INACT,0.05000000074505806	CHEMBL351183,TN,INACT,0.46000000834465027	CHEMBL3326660,FP,INACT,0.949999988079071	CHEMBL3646973,TP,ACT,1.0	CHEMBL2391440,TN,INACT,0.20999999344348907	CHEMBL3646964,TP,ACT,1.0	CHEMBL173442,FN,ACT,0.3199999928474426	CHEMBL408493,TN,INACT,0.6800000071525574	CHEMBL357975,FP,INACT,1.0	CHEMBL552615,TN,INACT,0.0	CHEMBL259639,TP,ACT,0.9100000262260437	CHEMBL2370691,FN,ACT,0.009999999776482582	CHEMBL462650,TN,INACT,0.3100000023841858	CHEMBL228900,TN,INACT,0.019999999552965164	CHEMBL297173,TN,INACT,0.6800000071525574	CHEMBL439468,TP,ACT,0.9700000286102295	CHEMBL3326770,TN,INACT,0.0	CHEMBL25573,TN,INACT,0.17000000178813934	CHEMBL3647036,TP,ACT,1.0	CHEMBL3646941,TP,ACT,1.0	CHEMBL513344,TP,ACT,1.0	CHEMBL361121,TN,INACT,0.05999999865889549	CHEMBL412591,FP,INACT,0.9399999976158142	CHEMBL3647017,TP,ACT,0.9599999785423279	CHEMBL3646991,TP,ACT,0.949999988079071	CHEMBL142295,TN,INACT,0.009999999776482582	CHEMBL479395,TP,ACT,0.9900000095367432	CHEMBL168632,TN,INACT,0.8600000143051147	CHEMBL100861,TN,INACT,0.7699999809265137	CHEMBL193818,TN,INACT,0.07999999821186066	CHEMBL400382,TN,INACT,0.0	CHEMBL258658,TP,ACT,0.9599999785423279	CHEMBL2115465,TN,INACT,0.20000000298023224	CHEMBL295651,TN,INACT,0.4399999976158142	CHEMBL410032,TP,ACT,1.0	CHEMBL112637,TN,INACT,0.20999999344348907	CHEMBL604277,TP,ACT,0.8899999856948853	CHEMBL3650412,TN,INACT,0.20000000298023224	CHEMBL118072,TP,ACT,1.0	CHEMBL40986,TN,INACT,0.1899999976158142	CHEMBL313981,TN,INACT,0.1599999964237213	CHEMBL249894,TN,INACT,0.0	CHEMBL3647003,TP,ACT,1.0	CHEMBL602474,TN,INACT,0.7599999904632568	CHEMBL3350366,TP,ACT,1.0	CHEMBL487167,TP,ACT,1.0	CHEMBL3646901,TP,ACT,1.0	CHEMBL3646996,TP,ACT,0.9900000095367432	CHEMBL1170029,FN,ACT,0.699999988079071	CHEMBL3646978,TP,ACT,1.0	CHEMBL3646917,TP,ACT,1.0	CHEMBL3646919,TP,ACT,1.0	CHEMBL3350743,TP,ACT,1.0	CHEMBL3647039,TP,ACT,1.0	CHEMBL291589,TP,ACT,0.9900000095367432	CHEMBL3646998,TP,ACT,0.9800000190734863	CHEMBL1169838,FN,ACT,0.41999998688697815	CHEMBL3350739,TP,ACT,1.0	CHEMBL3290766,TN,INACT,0.8199999928474426	CHEMBL3646944,TP,ACT,1.0	CHEMBL3646997,TP,ACT,0.9900000095367432	CHEMBL11629,TN,INACT,0.36000001430511475	CHEMBL194070,TN,INACT,0.0	CHEMBL259643,TP,ACT,0.9300000071525574	CHEMBL259984,TP,ACT,1.0	CHEMBL126521,FP,INACT,1.0	CHEMBL66454,TP,ACT,0.949999988079071	CHEMBL307127,TP,ACT,0.9900000095367432	CHEMBL2113067,TN,INACT,0.019999999552965164	CHEMBL400481,TN,INACT,0.0	CHEMBL486748,TP,ACT,0.9900000095367432	CHEMBL1488893,TN,INACT,0.07000000029802322	CHEMBL292939,TN,INACT,0.8299999833106995	CHEMBL3327368,TN,INACT,0.009999999776482582	CHEMBL95727,TN,INACT,0.0	CHEMBL69696,TP,ACT,1.0	CHEMBL302038,TN,INACT,0.800000011920929	CHEMBL2096822,FP,INACT,0.9800000190734863	CHEMBL3646914,TP,ACT,1.0	CHEMBL471017,TP,ACT,1.0	CHEMBL69192,TP,ACT,1.0	CHEMBL3647040,TP,ACT,1.0	CHEMBL3350715,TP,ACT,1.0	CHEMBL3647029,TP,ACT,1.0	CHEMBL3647023,TP,ACT,1.0	CHEMBL519540,TP,ACT,1.0	CHEMBL2372212,TN,INACT,0.11999999731779099	

