ImageNetInceptionV2 CHEMBL2611 adam 0.001 30 0 0 0.6 False True
Number of active compounds :	202
Number of inactive compounds :	164
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2611_adam_0.001_30_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2611_adam_0.001_30_0.6/
---------------------------------
Training samples: 192
Validation samples: 61
--
Training Step: 1  | time: 74.335s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/192
[A[ATraining Step: 2  | total loss: [1m[32m0.64043[0m[0m | time: 92.701s
[2K
| Adam | epoch: 001 | loss: 0.64043 - acc: 0.4500 -- iter: 064/192
[A[ATraining Step: 3  | total loss: [1m[32m0.52433[0m[0m | time: 110.888s
[2K
| Adam | epoch: 001 | loss: 0.52433 - acc: 0.7210 -- iter: 096/192
[A[ATraining Step: 4  | total loss: [1m[32m0.34918[0m[0m | time: 127.336s
[2K
| Adam | epoch: 001 | loss: 0.34918 - acc: 0.8365 -- iter: 128/192
[A[ATraining Step: 5  | total loss: [1m[32m0.51107[0m[0m | time: 140.389s
[2K
| Adam | epoch: 001 | loss: 0.51107 - acc: 0.8632 -- iter: 160/192
[A[ATraining Step: 6  | total loss: [1m[32m0.42321[0m[0m | time: 172.534s
[2K
| Adam | epoch: 001 | loss: 0.42321 - acc: 0.8708 | val_loss: 4.12984 - val_acc: 0.4262 -- iter: 192/192
--
Training Step: 7  | total loss: [1m[32m0.32181[0m[0m | time: 15.348s
[2K
| Adam | epoch: 002 | loss: 0.32181 - acc: 0.9108 -- iter: 032/192
[A[ATraining Step: 8  | total loss: [1m[32m0.22747[0m[0m | time: 27.289s
[2K
| Adam | epoch: 002 | loss: 0.22747 - acc: 0.9434 -- iter: 064/192
[A[ATraining Step: 9  | total loss: [1m[32m0.29117[0m[0m | time: 41.778s
[2K
| Adam | epoch: 002 | loss: 0.29117 - acc: 0.9072 -- iter: 096/192
[A[ATraining Step: 10  | total loss: [1m[32m0.26117[0m[0m | time: 60.164s
[2K
| Adam | epoch: 002 | loss: 0.26117 - acc: 0.8911 -- iter: 128/192
[A[ATraining Step: 11  | total loss: [1m[32m0.30594[0m[0m | time: 77.762s
[2K
| Adam | epoch: 002 | loss: 0.30594 - acc: 0.8835 -- iter: 160/192
[A[ATraining Step: 12  | total loss: [1m[32m0.19825[0m[0m | time: 102.615s
[2K
| Adam | epoch: 002 | loss: 0.19825 - acc: 0.9359 | val_loss: 6.11048 - val_acc: 0.4262 -- iter: 192/192
--
Training Step: 13  | total loss: [1m[32m0.16570[0m[0m | time: 18.275s
[2K
| Adam | epoch: 003 | loss: 0.16570 - acc: 0.9366 -- iter: 032/192
[A[ATraining Step: 14  | total loss: [1m[32m0.23294[0m[0m | time: 37.172s
[2K
| Adam | epoch: 003 | loss: 0.23294 - acc: 0.9114 -- iter: 064/192
[A[ATraining Step: 15  | total loss: [1m[32m0.19004[0m[0m | time: 54.362s
[2K
| Adam | epoch: 003 | loss: 0.19004 - acc: 0.9216 -- iter: 096/192
[A[ATraining Step: 16  | total loss: [1m[32m0.18425[0m[0m | time: 72.842s
[2K
| Adam | epoch: 003 | loss: 0.18425 - acc: 0.9276 -- iter: 128/192
[A[ATraining Step: 17  | total loss: [1m[32m0.40178[0m[0m | time: 91.002s
[2K
| Adam | epoch: 003 | loss: 0.40178 - acc: 0.8974 -- iter: 160/192
[A[ATraining Step: 18  | total loss: [1m[32m0.27072[0m[0m | time: 115.500s
[2K
| Adam | epoch: 003 | loss: 0.27072 - acc: 0.9329 | val_loss: 3.74800 - val_acc: 0.4262 -- iter: 192/192
--
Training Step: 19  | total loss: [1m[32m0.21937[0m[0m | time: 20.024s
[2K
| Adam | epoch: 004 | loss: 0.21937 - acc: 0.9449 -- iter: 032/192
[A[ATraining Step: 20  | total loss: [1m[32m0.17165[0m[0m | time: 37.802s
[2K
| Adam | epoch: 004 | loss: 0.17165 - acc: 0.9626 -- iter: 064/192
[A[ATraining Step: 21  | total loss: [1m[32m0.16508[0m[0m | time: 55.828s
[2K
| Adam | epoch: 004 | loss: 0.16508 - acc: 0.9548 -- iter: 096/192
[A[ATraining Step: 22  | total loss: [1m[32m0.14336[0m[0m | time: 74.322s
[2K
| Adam | epoch: 004 | loss: 0.14336 - acc: 0.9590 -- iter: 128/192
[A[ATraining Step: 23  | total loss: [1m[32m0.12843[0m[0m | time: 92.946s
[2K
| Adam | epoch: 004 | loss: 0.12843 - acc: 0.9618 -- iter: 160/192
[A[ATraining Step: 24  | total loss: [1m[32m0.13664[0m[0m | time: 117.080s
[2K
| Adam | epoch: 004 | loss: 0.13664 - acc: 0.9638 | val_loss: 4.52933 - val_acc: 0.4262 -- iter: 192/192
--
Training Step: 25  | total loss: [1m[32m0.10399[0m[0m | time: 17.893s
[2K
| Adam | epoch: 005 | loss: 0.10399 - acc: 0.9736 -- iter: 032/192
[A[ATraining Step: 26  | total loss: [1m[32m0.08862[0m[0m | time: 36.555s
[2K
| Adam | epoch: 005 | loss: 0.08862 - acc: 0.9806 -- iter: 064/192
[A[ATraining Step: 27  | total loss: [1m[32m0.07067[0m[0m | time: 54.355s
[2K
| Adam | epoch: 005 | loss: 0.07067 - acc: 0.9856 -- iter: 096/192
[A[ATraining Step: 28  | total loss: [1m[32m0.08391[0m[0m | time: 76.362s
[2K
| Adam | epoch: 005 | loss: 0.08391 - acc: 0.9814 -- iter: 128/192
[A[ATraining Step: 29  | total loss: [1m[32m0.07801[0m[0m | time: 98.661s
[2K
| Adam | epoch: 005 | loss: 0.07801 - acc: 0.9783 -- iter: 160/192
[A[ATraining Step: 30  | total loss: [1m[32m0.06363[0m[0m | time: 123.521s
[2K
| Adam | epoch: 005 | loss: 0.06363 - acc: 0.9835 | val_loss: 0.39659 - val_acc: 0.7705 -- iter: 192/192
--
Training Step: 31  | total loss: [1m[32m0.65068[0m[0m | time: 17.713s
[2K
| Adam | epoch: 006 | loss: 0.65068 - acc: 0.8863 -- iter: 032/192
[A[ATraining Step: 32  | total loss: [1m[32m0.52716[0m[0m | time: 36.018s
[2K
| Adam | epoch: 006 | loss: 0.52716 - acc: 0.9049 -- iter: 064/192
[A[ATraining Step: 33  | total loss: [1m[32m0.44079[0m[0m | time: 54.330s
[2K
| Adam | epoch: 006 | loss: 0.44079 - acc: 0.9120 -- iter: 096/192
[A[ATraining Step: 34  | total loss: [1m[32m0.38604[0m[0m | time: 68.669s
[2K
| Adam | epoch: 006 | loss: 0.38604 - acc: 0.9108 -- iter: 128/192
[A[ATraining Step: 35  | total loss: [1m[32m0.32021[0m[0m | time: 81.621s
[2K
| Adam | epoch: 006 | loss: 0.32021 - acc: 0.9229 -- iter: 160/192
[A[ATraining Step: 36  | total loss: [1m[32m0.26633[0m[0m | time: 103.015s
[2K
| Adam | epoch: 006 | loss: 0.26633 - acc: 0.9323 | val_loss: 0.38086 - val_acc: 0.8689 -- iter: 192/192
--
Training Step: 37  | total loss: [1m[32m0.22335[0m[0m | time: 11.635s
[2K
| Adam | epoch: 007 | loss: 0.22335 - acc: 0.9458 -- iter: 032/192
[A[ATraining Step: 38  | total loss: [1m[32m0.18910[0m[0m | time: 23.134s
[2K
| Adam | epoch: 007 | loss: 0.18910 - acc: 0.9564 -- iter: 064/192
[A[ATraining Step: 39  | total loss: [1m[32m0.16330[0m[0m | time: 34.591s
[2K
| Adam | epoch: 007 | loss: 0.16330 - acc: 0.9588 -- iter: 096/192
[A[ATraining Step: 40  | total loss: [1m[32m0.15217[0m[0m | time: 45.840s
[2K
| Adam | epoch: 007 | loss: 0.15217 - acc: 0.9548 -- iter: 128/192
[A[ATraining Step: 41  | total loss: [1m[32m0.13498[0m[0m | time: 57.720s
[2K
| Adam | epoch: 007 | loss: 0.13498 - acc: 0.9631 -- iter: 160/192
[A[ATraining Step: 42  | total loss: [1m[32m0.11796[0m[0m | time: 73.496s
[2K
| Adam | epoch: 007 | loss: 0.11796 - acc: 0.9697 | val_loss: 0.65348 - val_acc: 0.7705 -- iter: 192/192
--
Training Step: 43  | total loss: [1m[32m0.10287[0m[0m | time: 10.533s
[2K
| Adam | epoch: 008 | loss: 0.10287 - acc: 0.9751 -- iter: 032/192
[A[ATraining Step: 44  | total loss: [1m[32m0.09117[0m[0m | time: 21.066s
[2K
| Adam | epoch: 008 | loss: 0.09117 - acc: 0.9794 -- iter: 064/192
[A[ATraining Step: 45  | total loss: [1m[32m0.08786[0m[0m | time: 33.043s
[2K
| Adam | epoch: 008 | loss: 0.08786 - acc: 0.9829 -- iter: 096/192
[A[ATraining Step: 46  | total loss: [1m[32m0.07922[0m[0m | time: 44.314s
[2K
| Adam | epoch: 008 | loss: 0.07922 - acc: 0.9805 -- iter: 128/192
[A[ATraining Step: 47  | total loss: [1m[32m0.06741[0m[0m | time: 55.956s
[2K
| Adam | epoch: 008 | loss: 0.06741 - acc: 0.9837 -- iter: 160/192
[A[ATraining Step: 48  | total loss: [1m[32m0.05847[0m[0m | time: 71.490s
[2K
| Adam | epoch: 008 | loss: 0.05847 - acc: 0.9863 | val_loss: 0.72394 - val_acc: 0.8361 -- iter: 192/192
--
Training Step: 49  | total loss: [1m[32m0.05071[0m[0m | time: 11.600s
[2K
| Adam | epoch: 009 | loss: 0.05071 - acc: 0.9885 -- iter: 032/192
[A[ATraining Step: 50  | total loss: [1m[32m0.04477[0m[0m | time: 23.026s
[2K
| Adam | epoch: 009 | loss: 0.04477 - acc: 0.9903 -- iter: 064/192
[A[ATraining Step: 51  | total loss: [1m[32m0.04037[0m[0m | time: 35.075s
[2K
| Adam | epoch: 009 | loss: 0.04037 - acc: 0.9918 -- iter: 096/192
[A[ATraining Step: 52  | total loss: [1m[32m0.03934[0m[0m | time: 46.674s
[2K
| Adam | epoch: 009 | loss: 0.03934 - acc: 0.9930 -- iter: 128/192
[A[ATraining Step: 53  | total loss: [1m[32m0.03540[0m[0m | time: 58.197s
[2K
| Adam | epoch: 009 | loss: 0.03540 - acc: 0.9940 -- iter: 160/192
[A[ATraining Step: 54  | total loss: [1m[32m0.03145[0m[0m | time: 74.048s
[2K
| Adam | epoch: 009 | loss: 0.03145 - acc: 0.9949 | val_loss: 0.36230 - val_acc: 0.9344 -- iter: 192/192
--
Training Step: 55  | total loss: [1m[32m0.02936[0m[0m | time: 11.875s
[2K
| Adam | epoch: 010 | loss: 0.02936 - acc: 0.9956 -- iter: 032/192
[A[ATraining Step: 56  | total loss: [1m[32m0.02613[0m[0m | time: 24.225s
[2K
| Adam | epoch: 010 | loss: 0.02613 - acc: 0.9962 -- iter: 064/192
[A[ATraining Step: 57  | total loss: [1m[32m0.02334[0m[0m | time: 36.622s
[2K
| Adam | epoch: 010 | loss: 0.02334 - acc: 0.9968 -- iter: 096/192
[A[ATraining Step: 58  | total loss: [1m[32m0.02140[0m[0m | time: 44.885s
[2K
| Adam | epoch: 010 | loss: 0.02140 - acc: 0.9972 -- iter: 128/192
[A[ATraining Step: 59  | total loss: [1m[32m0.01884[0m[0m | time: 52.842s
[2K
| Adam | epoch: 010 | loss: 0.01884 - acc: 0.9976 -- iter: 160/192
[A[ATraining Step: 60  | total loss: [1m[32m0.01656[0m[0m | time: 63.539s
[2K
| Adam | epoch: 010 | loss: 0.01656 - acc: 0.9979 | val_loss: 0.23336 - val_acc: 0.9836 -- iter: 192/192
--
Training Step: 61  | total loss: [1m[32m0.01506[0m[0m | time: 7.895s
[2K
| Adam | epoch: 011 | loss: 0.01506 - acc: 0.9982 -- iter: 032/192
[A[ATraining Step: 62  | total loss: [1m[32m0.01350[0m[0m | time: 15.913s
[2K
| Adam | epoch: 011 | loss: 0.01350 - acc: 0.9984 -- iter: 064/192
[A[ATraining Step: 63  | total loss: [1m[32m0.01252[0m[0m | time: 23.708s
[2K
| Adam | epoch: 011 | loss: 0.01252 - acc: 0.9986 -- iter: 096/192
[A[ATraining Step: 64  | total loss: [1m[32m0.01142[0m[0m | time: 31.604s
[2K
| Adam | epoch: 011 | loss: 0.01142 - acc: 0.9988 -- iter: 128/192
[A[ATraining Step: 65  | total loss: [1m[32m0.01028[0m[0m | time: 39.452s
[2K
| Adam | epoch: 011 | loss: 0.01028 - acc: 0.9989 -- iter: 160/192
[A[ATraining Step: 66  | total loss: [1m[32m0.16802[0m[0m | time: 50.056s
[2K
| Adam | epoch: 011 | loss: 0.16802 - acc: 0.9877 | val_loss: 0.30755 - val_acc: 0.8689 -- iter: 192/192
--
Training Step: 67  | total loss: [1m[32m0.14815[0m[0m | time: 7.859s
[2K
| Adam | epoch: 012 | loss: 0.14815 - acc: 0.9891 -- iter: 032/192
[A[ATraining Step: 68  | total loss: [1m[32m0.13200[0m[0m | time: 15.865s
[2K
| Adam | epoch: 012 | loss: 0.13200 - acc: 0.9904 -- iter: 064/192
[A[ATraining Step: 69  | total loss: [1m[32m0.11722[0m[0m | time: 23.851s
[2K
| Adam | epoch: 012 | loss: 0.11722 - acc: 0.9915 -- iter: 096/192
[A[ATraining Step: 70  | total loss: [1m[32m0.10741[0m[0m | time: 31.847s
[2K
| Adam | epoch: 012 | loss: 0.10741 - acc: 0.9925 -- iter: 128/192
[A[ATraining Step: 71  | total loss: [1m[32m0.09787[0m[0m | time: 39.641s
[2K
| Adam | epoch: 012 | loss: 0.09787 - acc: 0.9934 -- iter: 160/192
[A[ATraining Step: 72  | total loss: [1m[32m0.08921[0m[0m | time: 50.176s
[2K
| Adam | epoch: 012 | loss: 0.08921 - acc: 0.9941 | val_loss: 0.35683 - val_acc: 0.9344 -- iter: 192/192
--
Training Step: 73  | total loss: [1m[32m0.08009[0m[0m | time: 7.909s
[2K
| Adam | epoch: 013 | loss: 0.08009 - acc: 0.9948 -- iter: 032/192
[A[ATraining Step: 74  | total loss: [1m[32m0.07237[0m[0m | time: 15.617s
[2K
| Adam | epoch: 013 | loss: 0.07237 - acc: 0.9953 -- iter: 064/192
[A[ATraining Step: 75  | total loss: [1m[32m0.06515[0m[0m | time: 23.429s
[2K
| Adam | epoch: 013 | loss: 0.06515 - acc: 0.9959 -- iter: 096/192
[A[ATraining Step: 76  | total loss: [1m[32m0.06061[0m[0m | time: 31.211s
[2K
| Adam | epoch: 013 | loss: 0.06061 - acc: 0.9963 -- iter: 128/192
[A[ATraining Step: 77  | total loss: [1m[32m0.05554[0m[0m | time: 38.933s
[2K
| Adam | epoch: 013 | loss: 0.05554 - acc: 0.9967 -- iter: 160/192
[A[ATraining Step: 78  | total loss: [1m[32m0.05076[0m[0m | time: 49.448s
[2K
| Adam | epoch: 013 | loss: 0.05076 - acc: 0.9970 | val_loss: 0.29819 - val_acc: 0.9672 -- iter: 192/192
--
Training Step: 79  | total loss: [1m[32m0.04784[0m[0m | time: 7.842s
[2K
| Adam | epoch: 014 | loss: 0.04784 - acc: 0.9973 -- iter: 032/192
[A[ATraining Step: 80  | total loss: [1m[32m0.06729[0m[0m | time: 15.469s
[2K
| Adam | epoch: 014 | loss: 0.06729 - acc: 0.9944 -- iter: 064/192
[A[ATraining Step: 81  | total loss: [1m[32m0.06133[0m[0m | time: 23.291s
[2K
| Adam | epoch: 014 | loss: 0.06133 - acc: 0.9950 -- iter: 096/192
[A[ATraining Step: 82  | total loss: [1m[32m0.05722[0m[0m | time: 30.963s
[2K
| Adam | epoch: 014 | loss: 0.05722 - acc: 0.9955 -- iter: 128/192
[A[ATraining Step: 83  | total loss: [1m[32m0.05242[0m[0m | time: 38.806s
[2K
| Adam | epoch: 014 | loss: 0.05242 - acc: 0.9959 -- iter: 160/192
[A[ATraining Step: 84  | total loss: [1m[32m0.04951[0m[0m | time: 49.289s
[2K
| Adam | epoch: 014 | loss: 0.04951 - acc: 0.9963 | val_loss: 0.33028 - val_acc: 0.8689 -- iter: 192/192
--
Training Step: 85  | total loss: [1m[32m0.04615[0m[0m | time: 7.866s
[2K
| Adam | epoch: 015 | loss: 0.04615 - acc: 0.9967 -- iter: 032/192
[A[ATraining Step: 86  | total loss: [1m[32m0.04193[0m[0m | time: 15.724s
[2K
| Adam | epoch: 015 | loss: 0.04193 - acc: 0.9970 -- iter: 064/192
[A[ATraining Step: 87  | total loss: [1m[32m0.22076[0m[0m | time: 23.360s
[2K
| Adam | epoch: 015 | loss: 0.22076 - acc: 0.9661 -- iter: 096/192
[A[ATraining Step: 88  | total loss: [1m[32m0.20119[0m[0m | time: 31.203s
[2K
| Adam | epoch: 015 | loss: 0.20119 - acc: 0.9695 -- iter: 128/192
[A[ATraining Step: 89  | total loss: [1m[32m0.18592[0m[0m | time: 38.942s
[2K
| Adam | epoch: 015 | loss: 0.18592 - acc: 0.9694 -- iter: 160/192
[A[ATraining Step: 90  | total loss: [1m[32m0.17202[0m[0m | time: 49.414s
[2K
| Adam | epoch: 015 | loss: 0.17202 - acc: 0.9725 | val_loss: 3.74579 - val_acc: 0.4426 -- iter: 192/192
--
Training Step: 91  | total loss: [1m[32m0.17310[0m[0m | time: 7.678s
[2K
| Adam | epoch: 016 | loss: 0.17310 - acc: 0.9690 -- iter: 032/192
[A[ATraining Step: 92  | total loss: [1m[32m0.16254[0m[0m | time: 15.384s
[2K
| Adam | epoch: 016 | loss: 0.16254 - acc: 0.9721 -- iter: 064/192
[A[ATraining Step: 93  | total loss: [1m[32m0.15217[0m[0m | time: 23.082s
[2K
| Adam | epoch: 016 | loss: 0.15217 - acc: 0.9749 -- iter: 096/192
[A[ATraining Step: 94  | total loss: [1m[32m0.14172[0m[0m | time: 30.786s
[2K
| Adam | epoch: 016 | loss: 0.14172 - acc: 0.9774 -- iter: 128/192
[A[ATraining Step: 95  | total loss: [1m[32m0.14251[0m[0m | time: 38.701s
[2K
| Adam | epoch: 016 | loss: 0.14251 - acc: 0.9796 -- iter: 160/192
[A[ATraining Step: 96  | total loss: [1m[32m0.13681[0m[0m | time: 49.195s
[2K
| Adam | epoch: 016 | loss: 0.13681 - acc: 0.9817 | val_loss: 2.24551 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 97  | total loss: [1m[32m0.12866[0m[0m | time: 7.739s
[2K
| Adam | epoch: 017 | loss: 0.12866 - acc: 0.9835 -- iter: 032/192
[A[ATraining Step: 98  | total loss: [1m[32m0.12083[0m[0m | time: 15.591s
[2K
| Adam | epoch: 017 | loss: 0.12083 - acc: 0.9852 -- iter: 064/192
[A[ATraining Step: 99  | total loss: [1m[32m0.11275[0m[0m | time: 23.191s
[2K
| Adam | epoch: 017 | loss: 0.11275 - acc: 0.9866 -- iter: 096/192
[A[ATraining Step: 100  | total loss: [1m[32m0.10872[0m[0m | time: 31.002s
[2K
| Adam | epoch: 017 | loss: 0.10872 - acc: 0.9849 -- iter: 128/192
[A[ATraining Step: 101  | total loss: [1m[32m0.09941[0m[0m | time: 38.728s
[2K
| Adam | epoch: 017 | loss: 0.09941 - acc: 0.9864 -- iter: 160/192
[A[ATraining Step: 102  | total loss: [1m[32m0.09127[0m[0m | time: 49.393s
[2K
| Adam | epoch: 017 | loss: 0.09127 - acc: 0.9877 | val_loss: 0.35854 - val_acc: 0.8525 -- iter: 192/192
--
Training Step: 103  | total loss: [1m[32m0.08508[0m[0m | time: 7.698s
[2K
| Adam | epoch: 018 | loss: 0.08508 - acc: 0.9890 -- iter: 032/192
[A[ATraining Step: 104  | total loss: [1m[32m0.07855[0m[0m | time: 15.464s
[2K
| Adam | epoch: 018 | loss: 0.07855 - acc: 0.9901 -- iter: 064/192
[A[ATraining Step: 105  | total loss: [1m[32m0.08418[0m[0m | time: 23.284s
[2K
| Adam | epoch: 018 | loss: 0.08418 - acc: 0.9848 -- iter: 096/192
[A[ATraining Step: 106  | total loss: [1m[32m0.08344[0m[0m | time: 31.192s
[2K
| Adam | epoch: 018 | loss: 0.08344 - acc: 0.9832 -- iter: 128/192
[A[ATraining Step: 107  | total loss: [1m[32m0.07589[0m[0m | time: 38.916s
[2K
| Adam | epoch: 018 | loss: 0.07589 - acc: 0.9849 -- iter: 160/192
[A[ATraining Step: 108  | total loss: [1m[32m0.07100[0m[0m | time: 49.369s
[2K
| Adam | epoch: 018 | loss: 0.07100 - acc: 0.9864 | val_loss: 1.04137 - val_acc: 0.5738 -- iter: 192/192
--
Training Step: 109  | total loss: [1m[32m0.06637[0m[0m | time: 7.931s
[2K
| Adam | epoch: 019 | loss: 0.06637 - acc: 0.9878 -- iter: 032/192
[A[ATraining Step: 110  | total loss: [1m[32m0.06123[0m[0m | time: 15.672s
[2K
| Adam | epoch: 019 | loss: 0.06123 - acc: 0.9890 -- iter: 064/192
[A[ATraining Step: 111  | total loss: [1m[32m0.05623[0m[0m | time: 23.490s
[2K
| Adam | epoch: 019 | loss: 0.05623 - acc: 0.9901 -- iter: 096/192
[A[ATraining Step: 112  | total loss: [1m[32m0.05266[0m[0m | time: 31.276s
[2K
| Adam | epoch: 019 | loss: 0.05266 - acc: 0.9911 -- iter: 128/192
[A[ATraining Step: 113  | total loss: [1m[32m0.04914[0m[0m | time: 38.938s
[2K
| Adam | epoch: 019 | loss: 0.04914 - acc: 0.9920 -- iter: 160/192
[A[ATraining Step: 114  | total loss: [1m[32m0.05072[0m[0m | time: 49.461s
[2K
| Adam | epoch: 019 | loss: 0.05072 - acc: 0.9896 | val_loss: 0.64705 - val_acc: 0.8525 -- iter: 192/192
--
Training Step: 115  | total loss: [1m[32m0.06132[0m[0m | time: 7.902s
[2K
| Adam | epoch: 020 | loss: 0.06132 - acc: 0.9876 -- iter: 032/192
[A[ATraining Step: 116  | total loss: [1m[32m0.05606[0m[0m | time: 15.714s
[2K
| Adam | epoch: 020 | loss: 0.05606 - acc: 0.9888 -- iter: 064/192
[A[ATraining Step: 117  | total loss: [1m[32m0.05110[0m[0m | time: 23.597s
[2K
| Adam | epoch: 020 | loss: 0.05110 - acc: 0.9899 -- iter: 096/192
[A[ATraining Step: 118  | total loss: [1m[32m0.04948[0m[0m | time: 31.412s
[2K
| Adam | epoch: 020 | loss: 0.04948 - acc: 0.9909 -- iter: 128/192
[A[ATraining Step: 119  | total loss: [1m[32m0.04522[0m[0m | time: 39.138s
[2K
| Adam | epoch: 020 | loss: 0.04522 - acc: 0.9918 -- iter: 160/192
[A[ATraining Step: 120  | total loss: [1m[32m0.04139[0m[0m | time: 49.651s
[2K
| Adam | epoch: 020 | loss: 0.04139 - acc: 0.9927 | val_loss: 0.35487 - val_acc: 0.9180 -- iter: 192/192
--
Training Step: 121  | total loss: [1m[32m0.03807[0m[0m | time: 8.052s
[2K
| Adam | epoch: 021 | loss: 0.03807 - acc: 0.9934 -- iter: 032/192
[A[ATraining Step: 122  | total loss: [1m[32m0.06242[0m[0m | time: 15.904s
[2K
| Adam | epoch: 021 | loss: 0.06242 - acc: 0.9909 -- iter: 064/192
[A[ATraining Step: 123  | total loss: [1m[32m0.05675[0m[0m | time: 23.683s
[2K
| Adam | epoch: 021 | loss: 0.05675 - acc: 0.9918 -- iter: 096/192
[A[ATraining Step: 124  | total loss: [1m[32m0.05168[0m[0m | time: 31.414s
[2K
| Adam | epoch: 021 | loss: 0.05168 - acc: 0.9926 -- iter: 128/192
[A[ATraining Step: 125  | total loss: [1m[32m0.04669[0m[0m | time: 39.205s
[2K
| Adam | epoch: 021 | loss: 0.04669 - acc: 0.9934 -- iter: 160/192
[A[ATraining Step: 126  | total loss: [1m[32m0.04249[0m[0m | time: 49.514s
[2K
| Adam | epoch: 021 | loss: 0.04249 - acc: 0.9940 | val_loss: 0.53341 - val_acc: 0.8197 -- iter: 192/192
--
Training Step: 127  | total loss: [1m[32m0.03886[0m[0m | time: 7.805s
[2K
| Adam | epoch: 022 | loss: 0.03886 - acc: 0.9946 -- iter: 032/192
[A[ATraining Step: 128  | total loss: [1m[32m0.03589[0m[0m | time: 15.600s
[2K
| Adam | epoch: 022 | loss: 0.03589 - acc: 0.9952 -- iter: 064/192
[A[ATraining Step: 129  | total loss: [1m[32m0.05233[0m[0m | time: 23.460s
[2K
| Adam | epoch: 022 | loss: 0.05233 - acc: 0.9925 -- iter: 096/192
[A[ATraining Step: 130  | total loss: [1m[32m0.04777[0m[0m | time: 31.284s
[2K
| Adam | epoch: 022 | loss: 0.04777 - acc: 0.9933 -- iter: 128/192
[A[ATraining Step: 131  | total loss: [1m[32m0.04663[0m[0m | time: 39.150s
[2K
| Adam | epoch: 022 | loss: 0.04663 - acc: 0.9940 -- iter: 160/192
[A[ATraining Step: 132  | total loss: [1m[32m0.04238[0m[0m | time: 49.600s
[2K
| Adam | epoch: 022 | loss: 0.04238 - acc: 0.9946 | val_loss: 0.37724 - val_acc: 0.8361 -- iter: 192/192
--
Training Step: 133  | total loss: [1m[32m0.03845[0m[0m | time: 7.825s
[2K
| Adam | epoch: 023 | loss: 0.03845 - acc: 0.9951 -- iter: 032/192
[A[ATraining Step: 134  | total loss: [1m[32m0.03486[0m[0m | time: 15.587s
[2K
| Adam | epoch: 023 | loss: 0.03486 - acc: 0.9956 -- iter: 064/192
[A[ATraining Step: 135  | total loss: [1m[32m0.03202[0m[0m | time: 23.395s
[2K
| Adam | epoch: 023 | loss: 0.03202 - acc: 0.9960 -- iter: 096/192
[A[ATraining Step: 136  | total loss: [1m[32m0.07840[0m[0m | time: 31.045s
[2K
| Adam | epoch: 023 | loss: 0.07840 - acc: 0.9933 -- iter: 128/192
[A[ATraining Step: 137  | total loss: [1m[32m0.07276[0m[0m | time: 38.863s
[2K
| Adam | epoch: 023 | loss: 0.07276 - acc: 0.9940 -- iter: 160/192
[A[ATraining Step: 138  | total loss: [1m[32m0.06575[0m[0m | time: 49.325s
[2K
| Adam | epoch: 023 | loss: 0.06575 - acc: 0.9946 | val_loss: 0.38870 - val_acc: 0.8197 -- iter: 192/192
--
Training Step: 139  | total loss: [1m[32m0.05989[0m[0m | time: 7.794s
[2K
| Adam | epoch: 024 | loss: 0.05989 - acc: 0.9951 -- iter: 032/192
[A[ATraining Step: 140  | total loss: [1m[32m0.05507[0m[0m | time: 15.816s
[2K
| Adam | epoch: 024 | loss: 0.05507 - acc: 0.9956 -- iter: 064/192
[A[ATraining Step: 141  | total loss: [1m[32m0.05038[0m[0m | time: 23.470s
[2K
| Adam | epoch: 024 | loss: 0.05038 - acc: 0.9960 -- iter: 096/192
[A[ATraining Step: 142  | total loss: [1m[32m0.04720[0m[0m | time: 31.343s
[2K
| Adam | epoch: 024 | loss: 0.04720 - acc: 0.9964 -- iter: 128/192
[A[ATraining Step: 143  | total loss: [1m[32m0.04376[0m[0m | time: 39.141s
[2K
| Adam | epoch: 024 | loss: 0.04376 - acc: 0.9968 -- iter: 160/192
[A[ATraining Step: 144  | total loss: [1m[32m0.03971[0m[0m | time: 49.590s
[2K
| Adam | epoch: 024 | loss: 0.03971 - acc: 0.9971 | val_loss: 0.29275 - val_acc: 0.8361 -- iter: 192/192
--
Training Step: 145  | total loss: [1m[32m0.03605[0m[0m | time: 7.871s
[2K
| Adam | epoch: 025 | loss: 0.03605 - acc: 0.9974 -- iter: 032/192
[A[ATraining Step: 146  | total loss: [1m[32m0.03304[0m[0m | time: 15.470s
[2K
| Adam | epoch: 025 | loss: 0.03304 - acc: 0.9977 -- iter: 064/192
[A[ATraining Step: 147  | total loss: [1m[32m0.03251[0m[0m | time: 23.284s
[2K
| Adam | epoch: 025 | loss: 0.03251 - acc: 0.9979 -- iter: 096/192
[A[ATraining Step: 148  | total loss: [1m[32m0.03084[0m[0m | time: 30.981s
[2K
| Adam | epoch: 025 | loss: 0.03084 - acc: 0.9981 -- iter: 128/192
[A[ATraining Step: 149  | total loss: [1m[32m0.02816[0m[0m | time: 38.810s
[2K
| Adam | epoch: 025 | loss: 0.02816 - acc: 0.9983 -- iter: 160/192
[A[ATraining Step: 150  | total loss: [1m[32m0.04648[0m[0m | time: 49.295s
[2K
| Adam | epoch: 025 | loss: 0.04648 - acc: 0.9953 | val_loss: 0.19938 - val_acc: 0.9672 -- iter: 192/192
--
Training Step: 151  | total loss: [1m[32m0.04255[0m[0m | time: 8.179s
[2K
| Adam | epoch: 026 | loss: 0.04255 - acc: 0.9958 -- iter: 032/192
[A[ATraining Step: 152  | total loss: [1m[32m0.03858[0m[0m | time: 21.136s
[2K
| Adam | epoch: 026 | loss: 0.03858 - acc: 0.9962 -- iter: 064/192
[A[ATraining Step: 153  | total loss: [1m[32m0.03510[0m[0m | time: 33.772s
[2K
| Adam | epoch: 026 | loss: 0.03510 - acc: 0.9966 -- iter: 096/192
[A[ATraining Step: 154  | total loss: [1m[32m0.03228[0m[0m | time: 46.811s
[2K
| Adam | epoch: 026 | loss: 0.03228 - acc: 0.9969 -- iter: 128/192
[A[ATraining Step: 155  | total loss: [1m[32m0.03028[0m[0m | time: 60.405s
[2K
| Adam | epoch: 026 | loss: 0.03028 - acc: 0.9973 -- iter: 160/192
[A[ATraining Step: 156  | total loss: [1m[32m0.02873[0m[0m | time: 78.185s
[2K
| Adam | epoch: 026 | loss: 0.02873 - acc: 0.9975 | val_loss: 0.39481 - val_acc: 0.9508 -- iter: 192/192
--
Training Step: 157  | total loss: [1m[32m0.04289[0m[0m | time: 7.947s
[2K
| Adam | epoch: 027 | loss: 0.04289 - acc: 0.9946 -- iter: 032/192
[A[ATraining Step: 158  | total loss: [1m[32m0.03994[0m[0m | time: 15.734s
[2K
| Adam | epoch: 027 | loss: 0.03994 - acc: 0.9952 -- iter: 064/192
[A[ATraining Step: 159  | total loss: [1m[32m0.04008[0m[0m | time: 23.627s
[2K
| Adam | epoch: 027 | loss: 0.04008 - acc: 0.9925 -- iter: 096/192
[A[ATraining Step: 160  | total loss: [1m[32m0.03668[0m[0m | time: 31.562s
[2K
| Adam | epoch: 027 | loss: 0.03668 - acc: 0.9933 -- iter: 128/192
[A[ATraining Step: 161  | total loss: [1m[32m0.03356[0m[0m | time: 40.634s
[2K
| Adam | epoch: 027 | loss: 0.03356 - acc: 0.9940 -- iter: 160/192
[A[ATraining Step: 162  | total loss: [1m[32m0.03053[0m[0m | time: 58.646s
[2K
| Adam | epoch: 027 | loss: 0.03053 - acc: 0.9946 | val_loss: 0.45243 - val_acc: 0.9508 -- iter: 192/192
--
Training Step: 163  | total loss: [1m[32m0.02809[0m[0m | time: 13.311s
[2K
| Adam | epoch: 028 | loss: 0.02809 - acc: 0.9951 -- iter: 032/192
[A[ATraining Step: 164  | total loss: [1m[32m0.02540[0m[0m | time: 25.654s
[2K
| Adam | epoch: 028 | loss: 0.02540 - acc: 0.9956 -- iter: 064/192
[A[ATraining Step: 165  | total loss: [1m[32m0.02343[0m[0m | time: 33.370s
[2K
| Adam | epoch: 028 | loss: 0.02343 - acc: 0.9960 -- iter: 096/192
[A[ATraining Step: 166  | total loss: [1m[32m0.02130[0m[0m | time: 41.319s
[2K
| Adam | epoch: 028 | loss: 0.02130 - acc: 0.9964 -- iter: 128/192
[A[ATraining Step: 167  | total loss: [1m[32m0.01938[0m[0m | time: 49.500s
[2K
| Adam | epoch: 028 | loss: 0.01938 - acc: 0.9968 -- iter: 160/192
[A[ATraining Step: 168  | total loss: [1m[32m0.02844[0m[0m | time: 65.975s
[2K
| Adam | epoch: 028 | loss: 0.02844 - acc: 0.9909 | val_loss: 0.24904 - val_acc: 0.9508 -- iter: 192/192
--
Training Step: 169  | total loss: [1m[32m0.03027[0m[0m | time: 13.544s
[2K
| Adam | epoch: 029 | loss: 0.03027 - acc: 0.9918 -- iter: 032/192
[A[ATraining Step: 170  | total loss: [1m[32m0.02733[0m[0m | time: 24.601s
[2K
| Adam | epoch: 029 | loss: 0.02733 - acc: 0.9926 -- iter: 064/192
[A[ATraining Step: 171  | total loss: [1m[32m0.13286[0m[0m | time: 32.503s
[2K
| Adam | epoch: 029 | loss: 0.13286 - acc: 0.9840 -- iter: 096/192
[A[ATraining Step: 172  | total loss: [1m[32m0.11969[0m[0m | time: 40.318s
[2K
| Adam | epoch: 029 | loss: 0.11969 - acc: 0.9856 -- iter: 128/192
[A[ATraining Step: 173  | total loss: [1m[32m0.10804[0m[0m | time: 48.159s
[2K
| Adam | epoch: 029 | loss: 0.10804 - acc: 0.9870 -- iter: 160/192
[A[ATraining Step: 174  | total loss: [1m[32m0.09757[0m[0m | time: 65.256s
[2K
| Adam | epoch: 029 | loss: 0.09757 - acc: 0.9883 | val_loss: 0.75006 - val_acc: 0.7049 -- iter: 192/192
--
Training Step: 175  | total loss: [1m[32m0.08907[0m[0m | time: 13.403s
[2K
| Adam | epoch: 030 | loss: 0.08907 - acc: 0.9895 -- iter: 032/192
[A[ATraining Step: 176  | total loss: [1m[32m0.08087[0m[0m | time: 27.675s
[2K
| Adam | epoch: 030 | loss: 0.08087 - acc: 0.9905 -- iter: 064/192
[A[ATraining Step: 177  | total loss: [1m[32m0.07702[0m[0m | time: 36.907s
[2K
| Adam | epoch: 030 | loss: 0.07702 - acc: 0.9884 -- iter: 096/192
[A[ATraining Step: 178  | total loss: [1m[32m0.12013[0m[0m | time: 46.454s
[2K
| Adam | epoch: 030 | loss: 0.12013 - acc: 0.9801 -- iter: 128/192
[A[ATraining Step: 179  | total loss: [1m[32m0.11296[0m[0m | time: 56.077s
[2K
| Adam | epoch: 030 | loss: 0.11296 - acc: 0.9821 -- iter: 160/192
[A[ATraining Step: 180  | total loss: [1m[32m0.10663[0m[0m | time: 71.608s
[2K
| Adam | epoch: 030 | loss: 0.10663 - acc: 0.9839 | val_loss: 0.31957 - val_acc: 0.8689 -- iter: 192/192
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9373626373626374
Validation AUPRC:0.9405361048555712
Test AUC:1.0
Test AUPRC:1.0
BestTestF1Score	1.0	1.0	1.0	1.0	1.0	36	0	25	0	0.37
BestTestMCCScore	1.0	1.0	1.0	1.0	1.0	36	0	25	0	0.37
BestTestAccuracyScore	0.99	0.97	0.98	1.0	0.97	35	0	25	1	0.47
BestValidationF1Score	0.91	0.78	0.89	0.83	1.0	35	7	19	0	0.37
BestValidationMCC	0.91	0.78	0.89	0.83	1.0	35	7	19	0	0.37
BestValidationAccuracy	0.9	0.76	0.89	0.89	0.91	32	4	22	3	0.47
TestPredictions (Threshold:0.37)
CHEMBL1829273,TN,INACT,0.09000000357627869	CHEMBL1808915,TP,ACT,0.9800000190734863	CHEMBL453336,TN,INACT,0.10999999940395355	CHEMBL602645,TN,INACT,0.17000000178813934	CHEMBL293749,TN,INACT,0.07000000029802322	CHEMBL1808913,TP,ACT,0.9800000190734863	CHEMBL3115587,TP,ACT,0.7200000286102295	CHEMBL3115591,TP,ACT,0.699999988079071	CHEMBL527041,TP,ACT,0.9800000190734863	CHEMBL568067,TP,ACT,1.0	CHEMBL501270,TP,ACT,0.7200000286102295	CHEMBL3126393,TP,ACT,1.0	CHEMBL569916,TP,ACT,1.0	CHEMBL55993,TN,INACT,0.019999999552965164	CHEMBL2179431,TP,ACT,0.9900000095367432	CHEMBL506831,TP,ACT,0.9900000095367432	CHEMBL2325101,TN,INACT,0.07999999821186066	CHEMBL589259,TN,INACT,0.10999999940395355	CHEMBL31184,TN,INACT,0.11999999731779099	CHEMBL2049163,TP,ACT,1.0	CHEMBL500184,TP,ACT,0.8899999856948853	CHEMBL56219,TN,INACT,0.05999999865889549	CHEMBL569918,TP,ACT,1.0	CHEMBL1808928,TP,ACT,1.0	CHEMBL1808911,TP,ACT,0.9900000095367432	CHEMBL521155,TN,INACT,0.05999999865889549	CHEMBL1254545,TN,INACT,0.10999999940395355	CHEMBL2324873,TN,INACT,0.14000000059604645	CHEMBL589847,TN,INACT,0.029999999329447746	CHEMBL1808929,TP,ACT,1.0	CHEMBL591051,TN,INACT,0.05999999865889549	CHEMBL199865,TN,INACT,0.14000000059604645	CHEMBL569950,TP,ACT,0.9900000095367432	CHEMBL3115590,TP,ACT,0.5899999737739563	CHEMBL526873,TP,ACT,0.949999988079071	CHEMBL1808914,TP,ACT,0.9700000286102295	CHEMBL1796184,TN,INACT,0.10000000149011612	CHEMBL1770733,TN,INACT,0.019999999552965164	CHEMBL1808919,TP,ACT,0.6899999976158142	CHEMBL196536,TN,INACT,0.07000000029802322	CHEMBL501797,TP,ACT,0.949999988079071	CHEMBL499187,TP,ACT,0.9599999785423279	CHEMBL503035,TP,ACT,1.0	CHEMBL209511,TN,INACT,0.029999999329447746	CHEMBL509337,TP,ACT,0.8199999928474426	CHEMBL269528,TN,INACT,0.23999999463558197	CHEMBL1172878,TN,INACT,0.03999999910593033	CHEMBL116423,TN,INACT,0.36000001430511475	CHEMBL14326,TN,INACT,0.07999999821186066	CHEMBL505833,TP,ACT,0.4699999988079071	CHEMBL448278,TP,ACT,1.0	CHEMBL488769,TP,ACT,0.9800000190734863	CHEMBL408241,TP,ACT,0.6200000047683716	CHEMBL2049020,TP,ACT,0.9900000095367432	CHEMBL568505,TP,ACT,0.9700000286102295	CHEMBL524837,TP,ACT,0.9599999785423279	CHEMBL525748,TP,ACT,0.9900000095367432	CHEMBL566340,TP,ACT,1.0	CHEMBL113996,TN,INACT,0.10000000149011612	CHEMBL503500,TP,ACT,0.9900000095367432	CHEMBL2325092,TN,INACT,0.12999999523162842	

