ImageNetInceptionV2 CHEMBL240 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	1972
Number of inactive compounds :	1315
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL240_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL240_adam_0.001_15_0.6/
---------------------------------
Training samples: 2102
Validation samples: 658
--
Training Step: 1  | time: 100.573s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2102
[A[ATraining Step: 2  | total loss: [1m[32m0.59207[0m[0m | time: 271.992s
[2K
| Adam | epoch: 001 | loss: 0.59207 - acc: 0.5906 -- iter: 0064/2102
[A[ATraining Step: 3  | total loss: [1m[32m0.78460[0m[0m | time: 372.048s
[2K
| Adam | epoch: 001 | loss: 0.78460 - acc: 0.6187 -- iter: 0096/2102
[A[ATraining Step: 4  | total loss: [1m[32m0.73325[0m[0m | time: 434.838s
[2K
| Adam | epoch: 001 | loss: 0.73325 - acc: 0.6000 -- iter: 0128/2102
[A[ATraining Step: 5  | total loss: [1m[32m0.57978[0m[0m | time: 762.019s
[2K
| Adam | epoch: 001 | loss: 0.57978 - acc: 0.7038 -- iter: 0160/2102
[A[ATraining Step: 6  | total loss: [1m[32m0.72506[0m[0m | time: 1011.231s
[2K
| Adam | epoch: 001 | loss: 0.72506 - acc: 0.6933 -- iter: 0192/2102
[A[ATraining Step: 7  | total loss: [1m[32m0.60022[0m[0m | time: 1120.789s
[2K
| Adam | epoch: 001 | loss: 0.60022 - acc: 0.7461 -- iter: 0224/2102
[A[ATraining Step: 8  | total loss: [1m[32m0.74427[0m[0m | time: 1376.368s
[2K
| Adam | epoch: 001 | loss: 0.74427 - acc: 0.6428 -- iter: 0256/2102
[A[ATraining Step: 9  | total loss: [1m[32m0.70483[0m[0m | time: 1461.691s
[2K
| Adam | epoch: 001 | loss: 0.70483 - acc: 0.6334 -- iter: 0288/2102
[A[ATraining Step: 10  | total loss: [1m[32m0.68480[0m[0m | time: 1514.826s
[2K
| Adam | epoch: 001 | loss: 0.68480 - acc: 0.6604 -- iter: 0320/2102
[A[ATraining Step: 11  | total loss: [1m[32m0.68372[0m[0m | time: 1577.799s
[2K
| Adam | epoch: 001 | loss: 0.68372 - acc: 0.6437 -- iter: 0352/2102
[A[ATraining Step: 12  | total loss: [1m[32m0.69166[0m[0m | time: 1623.826s
[2K
| Adam | epoch: 001 | loss: 0.69166 - acc: 0.6212 -- iter: 0384/2102
[A[ATraining Step: 13  | total loss: [1m[32m0.67570[0m[0m | time: 1743.395s
[2K
| Adam | epoch: 001 | loss: 0.67570 - acc: 0.6094 -- iter: 0416/2102
[A[ATraining Step: 14  | total loss: [1m[32m0.73570[0m[0m | time: 1753.748s
[2K
| Adam | epoch: 001 | loss: 0.73570 - acc: 0.5902 -- iter: 0448/2102
[A[ATraining Step: 15  | total loss: [1m[32m0.68954[0m[0m | time: 2210.011s
[2K
| Adam | epoch: 001 | loss: 0.68954 - acc: 0.6528 -- iter: 0480/2102
[A[ATraining Step: 16  | total loss: [1m[32m0.68598[0m[0m | time: 2303.951s
[2K
| Adam | epoch: 001 | loss: 0.68598 - acc: 0.6658 -- iter: 0512/2102
[A[ATraining Step: 17  | total loss: [1m[32m0.64070[0m[0m | time: 2554.201s
[2K
| Adam | epoch: 001 | loss: 0.64070 - acc: 0.6849 -- iter: 0544/2102
[A[ATraining Step: 18  | total loss: [1m[32m0.62209[0m[0m | time: 2714.150s
[2K
| Adam | epoch: 001 | loss: 0.62209 - acc: 0.6858 -- iter: 0576/2102
[A[ATraining Step: 19  | total loss: [1m[32m0.65662[0m[0m | time: 3241.345s
[2K
| Adam | epoch: 001 | loss: 0.65662 - acc: 0.6447 -- iter: 0608/2102
[A[ATraining Step: 20  | total loss: [1m[32m0.68734[0m[0m | time: 3414.256s
[2K
| Adam | epoch: 001 | loss: 0.68734 - acc: 0.5881 -- iter: 0640/2102
[A[ATraining Step: 21  | total loss: [1m[32m0.66879[0m[0m | time: 3457.561s
[2K
| Adam | epoch: 001 | loss: 0.66879 - acc: 0.6287 -- iter: 0672/2102
[A[ATraining Step: 22  | total loss: [1m[32m0.66882[0m[0m | time: 3466.414s
[2K
| Adam | epoch: 001 | loss: 0.66882 - acc: 0.6276 -- iter: 0704/2102
[A[ATraining Step: 23  | total loss: [1m[32m0.66879[0m[0m | time: 3537.055s
[2K
| Adam | epoch: 001 | loss: 0.66879 - acc: 0.6177 -- iter: 0736/2102
[A[ATraining Step: 24  | total loss: [1m[32m0.67120[0m[0m | time: 3545.944s
[2K
| Adam | epoch: 001 | loss: 0.67120 - acc: 0.5934 -- iter: 0768/2102
[A[ATraining Step: 25  | total loss: [1m[32m0.66576[0m[0m | time: 3555.084s
[2K
| Adam | epoch: 001 | loss: 0.66576 - acc: 0.6106 -- iter: 0800/2102
[A[ATraining Step: 26  | total loss: [1m[32m0.65785[0m[0m | time: 3564.380s
[2K
| Adam | epoch: 001 | loss: 0.65785 - acc: 0.5978 -- iter: 0832/2102
[A[ATraining Step: 27  | total loss: [1m[32m0.68816[0m[0m | time: 3573.498s
[2K
| Adam | epoch: 001 | loss: 0.68816 - acc: 0.5646 -- iter: 0864/2102
[A[ATraining Step: 28  | total loss: [1m[32m0.66062[0m[0m | time: 3582.847s
[2K
| Adam | epoch: 001 | loss: 0.66062 - acc: 0.6032 -- iter: 0896/2102
[A[ATraining Step: 29  | total loss: [1m[32m0.64992[0m[0m | time: 3592.219s
[2K
| Adam | epoch: 001 | loss: 0.64992 - acc: 0.6161 -- iter: 0928/2102
[A[ATraining Step: 30  | total loss: [1m[32m0.65160[0m[0m | time: 3601.583s
[2K
| Adam | epoch: 001 | loss: 0.65160 - acc: 0.6182 -- iter: 0960/2102
[A[ATraining Step: 31  | total loss: [1m[32m0.68241[0m[0m | time: 3611.054s
[2K
| Adam | epoch: 001 | loss: 0.68241 - acc: 0.5981 -- iter: 0992/2102
[A[ATraining Step: 32  | total loss: [1m[32m0.68533[0m[0m | time: 3620.395s
[2K
| Adam | epoch: 001 | loss: 0.68533 - acc: 0.5971 -- iter: 1024/2102
[A[ATraining Step: 33  | total loss: [1m[32m0.67560[0m[0m | time: 3630.006s
[2K
| Adam | epoch: 001 | loss: 0.67560 - acc: 0.6101 -- iter: 1056/2102
[A[ATraining Step: 34  | total loss: [1m[32m0.66453[0m[0m | time: 3639.131s
[2K
| Adam | epoch: 001 | loss: 0.66453 - acc: 0.6334 -- iter: 1088/2102
[A[ATraining Step: 35  | total loss: [1m[32m0.66419[0m[0m | time: 3648.342s
[2K
| Adam | epoch: 001 | loss: 0.66419 - acc: 0.6513 -- iter: 1120/2102
[A[ATraining Step: 36  | total loss: [1m[32m0.67399[0m[0m | time: 3687.929s
[2K
| Adam | epoch: 001 | loss: 0.67399 - acc: 0.6523 -- iter: 1152/2102
[A[ATraining Step: 37  | total loss: [1m[32m0.68312[0m[0m | time: 3767.266s
[2K
| Adam | epoch: 001 | loss: 0.68312 - acc: 0.6406 -- iter: 1184/2102
[A[ATraining Step: 38  | total loss: [1m[32m0.69392[0m[0m | time: 3776.746s
[2K
| Adam | epoch: 001 | loss: 0.69392 - acc: 0.6253 -- iter: 1216/2102
[A[ATraining Step: 39  | total loss: [1m[32m0.67853[0m[0m | time: 3810.502s
[2K
| Adam | epoch: 001 | loss: 0.67853 - acc: 0.6312 -- iter: 1248/2102
[A[ATraining Step: 40  | total loss: [1m[32m0.66121[0m[0m | time: 3821.055s
[2K
| Adam | epoch: 001 | loss: 0.66121 - acc: 0.6476 -- iter: 1280/2102
[A[ATraining Step: 41  | total loss: [1m[32m0.65956[0m[0m | time: 3830.571s
[2K
| Adam | epoch: 001 | loss: 0.65956 - acc: 0.6435 -- iter: 1312/2102
[A[ATraining Step: 42  | total loss: [1m[32m0.66112[0m[0m | time: 3839.883s
[2K
| Adam | epoch: 001 | loss: 0.66112 - acc: 0.6345 -- iter: 1344/2102
[A[ATraining Step: 43  | total loss: [1m[32m0.65753[0m[0m | time: 3849.009s
[2K
| Adam | epoch: 001 | loss: 0.65753 - acc: 0.6384 -- iter: 1376/2102
[A[ATraining Step: 44  | total loss: [1m[32m0.67586[0m[0m | time: 3858.266s
[2K
| Adam | epoch: 001 | loss: 0.67586 - acc: 0.6036 -- iter: 1408/2102
[A[ATraining Step: 45  | total loss: [1m[32m0.67736[0m[0m | time: 3867.610s
[2K
| Adam | epoch: 001 | loss: 0.67736 - acc: 0.6019 -- iter: 1440/2102
[A[ATraining Step: 46  | total loss: [1m[32m0.67648[0m[0m | time: 3886.470s
[2K
| Adam | epoch: 001 | loss: 0.67648 - acc: 0.6058 -- iter: 1472/2102
[A[ATraining Step: 47  | total loss: [1m[32m0.69008[0m[0m | time: 3895.510s
[2K
| Adam | epoch: 001 | loss: 0.69008 - acc: 0.5833 -- iter: 1504/2102
[A[ATraining Step: 48  | total loss: [1m[32m0.70475[0m[0m | time: 3908.795s
[2K
| Adam | epoch: 001 | loss: 0.70475 - acc: 0.5298 -- iter: 1536/2102
[A[ATraining Step: 49  | total loss: [1m[32m0.70405[0m[0m | time: 3918.261s
[2K
| Adam | epoch: 001 | loss: 0.70405 - acc: 0.5349 -- iter: 1568/2102
[A[ATraining Step: 50  | total loss: [1m[32m0.70296[0m[0m | time: 3927.624s
[2K
| Adam | epoch: 001 | loss: 0.70296 - acc: 0.5344 -- iter: 1600/2102
[A[ATraining Step: 51  | total loss: [1m[32m0.69704[0m[0m | time: 3936.881s
[2K
| Adam | epoch: 001 | loss: 0.69704 - acc: 0.5482 -- iter: 1632/2102
[A[ATraining Step: 52  | total loss: [1m[32m0.68756[0m[0m | time: 3946.373s
[2K
| Adam | epoch: 001 | loss: 0.68756 - acc: 0.5691 -- iter: 1664/2102
[A[ATraining Step: 53  | total loss: [1m[32m0.70591[0m[0m | time: 3955.509s
[2K
| Adam | epoch: 001 | loss: 0.70591 - acc: 0.5589 -- iter: 1696/2102
[A[ATraining Step: 54  | total loss: [1m[32m0.68586[0m[0m | time: 3980.974s
[2K
| Adam | epoch: 001 | loss: 0.68586 - acc: 0.5866 -- iter: 1728/2102
[A[ATraining Step: 55  | total loss: [1m[32m0.69110[0m[0m | time: 4017.955s
[2K
| Adam | epoch: 001 | loss: 0.69110 - acc: 0.5877 -- iter: 1760/2102
[A[ATraining Step: 56  | total loss: [1m[32m0.68610[0m[0m | time: 4027.514s
[2K
| Adam | epoch: 001 | loss: 0.68610 - acc: 0.6017 -- iter: 1792/2102
[A[ATraining Step: 57  | total loss: [1m[32m0.67886[0m[0m | time: 4037.254s
[2K
| Adam | epoch: 001 | loss: 0.67886 - acc: 0.6136 -- iter: 1824/2102
[A[ATraining Step: 58  | total loss: [1m[32m0.67458[0m[0m | time: 4046.621s
[2K
| Adam | epoch: 001 | loss: 0.67458 - acc: 0.6279 -- iter: 1856/2102
[A[ATraining Step: 59  | total loss: [1m[32m0.65978[0m[0m | time: 4063.374s
[2K
| Adam | epoch: 001 | loss: 0.65978 - acc: 0.6359 -- iter: 1888/2102
[A[ATraining Step: 60  | total loss: [1m[32m0.66765[0m[0m | time: 4072.249s
[2K
| Adam | epoch: 001 | loss: 0.66765 - acc: 0.6303 -- iter: 1920/2102
[A[ATraining Step: 61  | total loss: [1m[32m0.66766[0m[0m | time: 4081.218s
[2K
| Adam | epoch: 001 | loss: 0.66766 - acc: 0.6256 -- iter: 1952/2102
[A[ATraining Step: 62  | total loss: [1m[32m0.67202[0m[0m | time: 4130.757s
[2K
| Adam | epoch: 001 | loss: 0.67202 - acc: 0.6215 -- iter: 1984/2102
[A[ATraining Step: 63  | total loss: [1m[32m0.67367[0m[0m | time: 4140.086s
[2K
| Adam | epoch: 001 | loss: 0.67367 - acc: 0.6061 -- iter: 2016/2102
[A[ATraining Step: 64  | total loss: [1m[32m0.67466[0m[0m | time: 4149.423s
[2K
| Adam | epoch: 001 | loss: 0.67466 - acc: 0.5967 -- iter: 2048/2102
[A[ATraining Step: 65  | total loss: [1m[32m0.66928[0m[0m | time: 4176.275s
[2K
| Adam | epoch: 001 | loss: 0.66928 - acc: 0.6002 -- iter: 2080/2102
[A[ATraining Step: 66  | total loss: [1m[32m0.67432[0m[0m | time: 4866.804s
[2K
| Adam | epoch: 001 | loss: 0.67432 - acc: 0.5880 | val_loss: 0.67614 - val_acc: 0.5805 -- iter: 2102/2102
--
Training Step: 67  | total loss: [1m[32m0.69218[0m[0m | time: 674.092s
[2K
| Adam | epoch: 002 | loss: 0.69218 - acc: 0.5556 -- iter: 0032/2102
[A[ATraining Step: 68  | total loss: [1m[32m0.68788[0m[0m | time: 929.108s
[2K
| Adam | epoch: 002 | loss: 0.68788 - acc: 0.5598 -- iter: 0064/2102
[A[ATraining Step: 69  | total loss: [1m[32m0.68277[0m[0m | time: 1257.210s
[2K
| Adam | epoch: 002 | loss: 0.68277 - acc: 0.5711 -- iter: 0096/2102
[A[ATraining Step: 70  | total loss: [1m[32m0.67136[0m[0m | time: 1698.162s
[2K
| Adam | epoch: 002 | loss: 0.67136 - acc: 0.5917 -- iter: 0128/2102
[A[ATraining Step: 71  | total loss: [1m[32m0.65926[0m[0m | time: 2023.769s
[2K
| Adam | epoch: 002 | loss: 0.65926 - acc: 0.6098 -- iter: 0160/2102
[A[ATraining Step: 72  | total loss: [1m[32m0.64674[0m[0m | time: 2312.815s
[2K
| Adam | epoch: 002 | loss: 0.64674 - acc: 0.6255 -- iter: 0192/2102
[A[ATraining Step: 73  | total loss: [1m[32m0.65857[0m[0m | time: 2669.357s
[2K
| Adam | epoch: 002 | loss: 0.65857 - acc: 0.6290 -- iter: 0224/2102
[A[ATraining Step: 74  | total loss: [1m[32m0.67272[0m[0m | time: 2867.337s
[2K
| Adam | epoch: 002 | loss: 0.67272 - acc: 0.6285 -- iter: 0256/2102
[A[ATraining Step: 75  | total loss: [1m[32m0.68464[0m[0m | time: 3169.558s
[2K
| Adam | epoch: 002 | loss: 0.68464 - acc: 0.6214 -- iter: 0288/2102
[A[ATraining Step: 76  | total loss: [1m[32m0.68208[0m[0m | time: 3356.752s
[2K
| Adam | epoch: 002 | loss: 0.68208 - acc: 0.6217 -- iter: 0320/2102
[A[ATraining Step: 77  | total loss: [1m[32m0.67767[0m[0m | time: 3419.190s
[2K
| Adam | epoch: 002 | loss: 0.67767 - acc: 0.6221 -- iter: 0352/2102
[A[ATraining Step: 78  | total loss: [1m[32m0.67799[0m[0m | time: 3554.403s
[2K
| Adam | epoch: 002 | loss: 0.67799 - acc: 0.6224 -- iter: 0384/2102
[A[ATraining Step: 79  | total loss: [1m[32m0.68012[0m[0m | time: 3869.814s
[2K
| Adam | epoch: 002 | loss: 0.68012 - acc: 0.6162 -- iter: 0416/2102
[A[ATraining Step: 80  | total loss: [1m[32m0.68717[0m[0m | time: 4031.546s
[2K
| Adam | epoch: 002 | loss: 0.68717 - acc: 0.5979 -- iter: 0448/2102
[A[ATraining Step: 81  | total loss: [1m[32m0.69400[0m[0m | time: 4146.042s
[2K
| Adam | epoch: 002 | loss: 0.69400 - acc: 0.5943 -- iter: 0480/2102
[A[ATraining Step: 82  | total loss: [1m[32m0.67988[0m[0m | time: 4301.567s
[2K
| Adam | epoch: 002 | loss: 0.67988 - acc: 0.6005 -- iter: 0512/2102
[A[ATraining Step: 83  | total loss: [1m[32m0.68331[0m[0m | time: 4340.245s
[2K
| Adam | epoch: 002 | loss: 0.68331 - acc: 0.6030 -- iter: 0544/2102
[A[ATraining Step: 84  | total loss: [1m[32m0.69355[0m[0m | time: 4376.851s
[2K
| Adam | epoch: 002 | loss: 0.69355 - acc: 0.5864 -- iter: 0576/2102
[A[ATraining Step: 85  | total loss: [1m[32m0.68893[0m[0m | time: 4512.182s
[2K
| Adam | epoch: 002 | loss: 0.68893 - acc: 0.5934 -- iter: 0608/2102
[A[ATraining Step: 86  | total loss: [1m[32m0.69093[0m[0m | time: 4578.846s
[2K
| Adam | epoch: 002 | loss: 0.69093 - acc: 0.5872 -- iter: 0640/2102
[A[ATraining Step: 87  | total loss: [1m[32m0.68291[0m[0m | time: 4614.466s
[2K
| Adam | epoch: 002 | loss: 0.68291 - acc: 0.5941 -- iter: 0672/2102
[A[ATraining Step: 88  | total loss: [1m[32m0.67576[0m[0m | time: 4707.856s
[2K
| Adam | epoch: 002 | loss: 0.67576 - acc: 0.5972 -- iter: 0704/2102
[A[ATraining Step: 89  | total loss: [1m[32m0.67638[0m[0m | time: 4746.542s
[2K
| Adam | epoch: 002 | loss: 0.67638 - acc: 0.6000 -- iter: 0736/2102
[A[ATraining Step: 90  | total loss: [1m[32m0.68628[0m[0m | time: 4785.153s
[2K
| Adam | epoch: 002 | loss: 0.68628 - acc: 0.5994 -- iter: 0768/2102
[A[ATraining Step: 91  | total loss: [1m[32m0.66762[0m[0m | time: 4798.181s
[2K
| Adam | epoch: 002 | loss: 0.66762 - acc: 0.6175 -- iter: 0800/2102
[A[ATraining Step: 92  | total loss: [1m[32m0.68211[0m[0m | time: 4836.675s
[2K
| Adam | epoch: 002 | loss: 0.68211 - acc: 0.6152 -- iter: 0832/2102
[A[ATraining Step: 93  | total loss: [1m[32m0.67905[0m[0m | time: 4848.919s
[2K
| Adam | epoch: 002 | loss: 0.67905 - acc: 0.6193 -- iter: 0864/2102
[A[ATraining Step: 94  | total loss: [1m[32m0.68681[0m[0m | time: 4977.005s
[2K
| Adam | epoch: 002 | loss: 0.68681 - acc: 0.6073 -- iter: 0896/2102
[A[ATraining Step: 95  | total loss: [1m[32m0.68486[0m[0m | time: 5018.858s
[2K
| Adam | epoch: 002 | loss: 0.68486 - acc: 0.6029 -- iter: 0928/2102
[A[ATraining Step: 96  | total loss: [1m[32m0.69519[0m[0m | time: 5033.953s
[2K
| Adam | epoch: 002 | loss: 0.69519 - acc: 0.5988 -- iter: 0960/2102
[A[ATraining Step: 97  | total loss: [1m[32m0.68962[0m[0m | time: 5079.927s
[2K
| Adam | epoch: 002 | loss: 0.68962 - acc: 0.6046 -- iter: 0992/2102
[A[ATraining Step: 98  | total loss: [1m[32m0.68695[0m[0m | time: 5162.139s
[2K
| Adam | epoch: 002 | loss: 0.68695 - acc: 0.6129 -- iter: 1024/2102
[A[ATraining Step: 99  | total loss: [1m[32m0.67555[0m[0m | time: 5191.978s
[2K
| Adam | epoch: 002 | loss: 0.67555 - acc: 0.6234 -- iter: 1056/2102
[A[ATraining Step: 100  | total loss: [1m[32m0.68255[0m[0m | time: 5227.030s
[2K
| Adam | epoch: 002 | loss: 0.68255 - acc: 0.6205 -- iter: 1088/2102
[A[ATraining Step: 101  | total loss: [1m[32m0.68076[0m[0m | time: 5266.644s
[2K
| Adam | epoch: 002 | loss: 0.68076 - acc: 0.6178 -- iter: 1120/2102
[A[ATraining Step: 102  | total loss: [1m[32m0.69260[0m[0m | time: 5383.560s
[2K
| Adam | epoch: 002 | loss: 0.69260 - acc: 0.6092 -- iter: 1152/2102
[A[ATraining Step: 103  | total loss: [1m[32m0.70048[0m[0m | time: 5447.700s
[2K
| Adam | epoch: 002 | loss: 0.70048 - acc: 0.5920 -- iter: 1184/2102
[A[ATraining Step: 104  | total loss: [1m[32m0.70577[0m[0m | time: 5476.868s
[2K
| Adam | epoch: 002 | loss: 0.70577 - acc: 0.5797 -- iter: 1216/2102
[A[ATraining Step: 105  | total loss: [1m[32m0.70555[0m[0m | time: 5554.224s
[2K
| Adam | epoch: 002 | loss: 0.70555 - acc: 0.5686 -- iter: 1248/2102
[A[ATraining Step: 106  | total loss: [1m[32m0.70710[0m[0m | time: 5579.771s
[2K
| Adam | epoch: 002 | loss: 0.70710 - acc: 0.5555 -- iter: 1280/2102
[A[ATraining Step: 107  | total loss: [1m[32m0.70664[0m[0m | time: 5594.709s
[2K
| Adam | epoch: 002 | loss: 0.70664 - acc: 0.5499 -- iter: 1312/2102
[A[ATraining Step: 108  | total loss: [1m[32m0.70422[0m[0m | time: 5652.657s
[2K
| Adam | epoch: 002 | loss: 0.70422 - acc: 0.5512 -- iter: 1344/2102
[A[ATraining Step: 109  | total loss: [1m[32m0.70109[0m[0m | time: 5746.649s
[2K
| Adam | epoch: 002 | loss: 0.70109 - acc: 0.5492 -- iter: 1376/2102
[A[ATraining Step: 110  | total loss: [1m[32m0.68808[0m[0m | time: 5760.087s
[2K
| Adam | epoch: 002 | loss: 0.68808 - acc: 0.5661 -- iter: 1408/2102
[A[ATraining Step: 111  | total loss: [1m[32m0.67386[0m[0m | time: 5790.207s
[2K
| Adam | epoch: 002 | loss: 0.67386 - acc: 0.5814 -- iter: 1440/2102
[A[ATraining Step: 112  | total loss: [1m[32m0.66514[0m[0m | time: 5836.007s
[2K
| Adam | epoch: 002 | loss: 0.66514 - acc: 0.5951 -- iter: 1472/2102
[A[ATraining Step: 113  | total loss: [1m[32m0.66883[0m[0m | time: 5871.805s
[2K
| Adam | epoch: 002 | loss: 0.66883 - acc: 0.5981 -- iter: 1504/2102
[A[ATraining Step: 114  | total loss: [1m[32m0.67887[0m[0m | time: 5939.563s
[2K
| Adam | epoch: 002 | loss: 0.67887 - acc: 0.5977 -- iter: 1536/2102
[A[ATraining Step: 115  | total loss: [1m[32m0.66775[0m[0m | time: 6026.679s
[2K
| Adam | epoch: 002 | loss: 0.66775 - acc: 0.6067 -- iter: 1568/2102
[A[ATraining Step: 116  | total loss: [1m[32m0.65971[0m[0m | time: 6039.481s
[2K
| Adam | epoch: 002 | loss: 0.65971 - acc: 0.6147 -- iter: 1600/2102
[A[ATraining Step: 117  | total loss: [1m[32m0.66833[0m[0m | time: 6055.584s
[2K
| Adam | epoch: 002 | loss: 0.66833 - acc: 0.6126 -- iter: 1632/2102
[A[ATraining Step: 118  | total loss: [1m[32m0.67910[0m[0m | time: 6076.197s
[2K
| Adam | epoch: 002 | loss: 0.67910 - acc: 0.5983 -- iter: 1664/2102
[A[ATraining Step: 119  | total loss: [1m[32m0.67830[0m[0m | time: 6096.484s
[2K
| Adam | epoch: 002 | loss: 0.67830 - acc: 0.6041 -- iter: 1696/2102
[A[ATraining Step: 120  | total loss: [1m[32m0.67126[0m[0m | time: 6123.945s
[2K
| Adam | epoch: 002 | loss: 0.67126 - acc: 0.6030 -- iter: 1728/2102
[A[ATraining Step: 121  | total loss: [1m[32m0.67600[0m[0m | time: 6141.621s
[2K
| Adam | epoch: 002 | loss: 0.67600 - acc: 0.5990 -- iter: 1760/2102
[A[ATraining Step: 122  | total loss: [1m[32m0.68599[0m[0m | time: 6155.431s
[2K
| Adam | epoch: 002 | loss: 0.68599 - acc: 0.5922 -- iter: 1792/2102
[A[ATraining Step: 123  | total loss: [1m[32m0.68857[0m[0m | time: 6185.138s
[2K
| Adam | epoch: 002 | loss: 0.68857 - acc: 0.5861 -- iter: 1824/2102
[A[ATraining Step: 124  | total loss: [1m[32m0.68168[0m[0m | time: 6209.888s
[2K
| Adam | epoch: 002 | loss: 0.68168 - acc: 0.5869 -- iter: 1856/2102
[A[ATraining Step: 125  | total loss: [1m[32m0.68935[0m[0m | time: 6227.658s
[2K
| Adam | epoch: 002 | loss: 0.68935 - acc: 0.5751 -- iter: 1888/2102
[A[ATraining Step: 126  | total loss: [1m[32m0.68017[0m[0m | time: 6240.706s
[2K
| Adam | epoch: 002 | loss: 0.68017 - acc: 0.5894 -- iter: 1920/2102
[A[ATraining Step: 127  | total loss: [1m[32m0.67836[0m[0m | time: 6254.098s
[2K
| Adam | epoch: 002 | loss: 0.67836 - acc: 0.5836 -- iter: 1952/2102
[A[ATraining Step: 128  | total loss: [1m[32m0.67347[0m[0m | time: 6301.273s
[2K
| Adam | epoch: 002 | loss: 0.67347 - acc: 0.5846 -- iter: 1984/2102
[A[ATraining Step: 129  | total loss: [1m[32m0.66650[0m[0m | time: 6389.011s
[2K
| Adam | epoch: 002 | loss: 0.66650 - acc: 0.5887 -- iter: 2016/2102
[A[ATraining Step: 130  | total loss: [1m[32m0.65377[0m[0m | time: 6423.992s
[2K
| Adam | epoch: 002 | loss: 0.65377 - acc: 0.6017 -- iter: 2048/2102
[A[ATraining Step: 131  | total loss: [1m[32m0.66162[0m[0m | time: 6459.979s
[2K
| Adam | epoch: 002 | loss: 0.66162 - acc: 0.5978 -- iter: 2080/2102
[A[ATraining Step: 132  | total loss: [1m[32m0.65322[0m[0m | time: 7913.482s
[2K
| Adam | epoch: 002 | loss: 0.65322 - acc: 0.6067 | val_loss: 0.62898 - val_acc: 0.6702 -- iter: 2102/2102
--
Training Step: 133  | total loss: [1m[32m0.64030[0m[0m | time: 143.276s
[2K
| Adam | epoch: 003 | loss: 0.64030 - acc: 0.6179 -- iter: 0032/2102
[A[ATraining Step: 134  | total loss: [1m[32m0.62701[0m[0m | time: 202.299s
[2K
| Adam | epoch: 003 | loss: 0.62701 - acc: 0.6334 -- iter: 0064/2102
[A[ATraining Step: 135  | total loss: [1m[32m0.61516[0m[0m | time: 402.808s
[2K
| Adam | epoch: 003 | loss: 0.61516 - acc: 0.6519 -- iter: 0096/2102
[A[ATraining Step: 136  | total loss: [1m[32m0.62538[0m[0m | time: 518.535s
[2K
| Adam | epoch: 003 | loss: 0.62538 - acc: 0.6304 -- iter: 0128/2102
[A[ATraining Step: 137  | total loss: [1m[32m0.63868[0m[0m | time: 572.326s
[2K
| Adam | epoch: 003 | loss: 0.63868 - acc: 0.6237 -- iter: 0160/2102
[A[ATraining Step: 138  | total loss: [1m[32m0.64221[0m[0m | time: 772.332s
[2K
| Adam | epoch: 003 | loss: 0.64221 - acc: 0.6238 -- iter: 0192/2102
[A[ATraining Step: 139  | total loss: [1m[32m0.63779[0m[0m | time: 941.957s
[2K
| Adam | epoch: 003 | loss: 0.63779 - acc: 0.6302 -- iter: 0224/2102
[A[ATraining Step: 140  | total loss: [1m[32m0.64561[0m[0m | time: 955.082s
[2K
| Adam | epoch: 003 | loss: 0.64561 - acc: 0.6296 -- iter: 0256/2102
[A[ATraining Step: 141  | total loss: [1m[32m0.64388[0m[0m | time: 968.181s
[2K
| Adam | epoch: 003 | loss: 0.64388 - acc: 0.6292 -- iter: 0288/2102
[A[ATraining Step: 142  | total loss: [1m[32m0.66643[0m[0m | time: 985.726s
[2K
| Adam | epoch: 003 | loss: 0.66643 - acc: 0.6163 -- iter: 0320/2102
[A[ATraining Step: 143  | total loss: [1m[32m0.65804[0m[0m | time: 998.818s
[2K
| Adam | epoch: 003 | loss: 0.65804 - acc: 0.6265 -- iter: 0352/2102
[A[ATraining Step: 144  | total loss: [1m[32m0.65203[0m[0m | time: 1012.029s
[2K
| Adam | epoch: 003 | loss: 0.65203 - acc: 0.6295 -- iter: 0384/2102
[A[ATraining Step: 145  | total loss: [1m[32m0.64434[0m[0m | time: 1025.206s
[2K
| Adam | epoch: 003 | loss: 0.64434 - acc: 0.6322 -- iter: 0416/2102
[A[ATraining Step: 146  | total loss: [1m[32m0.63638[0m[0m | time: 1039.147s
[2K
| Adam | epoch: 003 | loss: 0.63638 - acc: 0.6439 -- iter: 0448/2102
[A[ATraining Step: 147  | total loss: [1m[32m0.62767[0m[0m | time: 1053.117s
[2K
| Adam | epoch: 003 | loss: 0.62767 - acc: 0.6483 -- iter: 0480/2102
[A[ATraining Step: 148  | total loss: [1m[32m0.62306[0m[0m | time: 1066.619s
[2K
| Adam | epoch: 003 | loss: 0.62306 - acc: 0.6522 -- iter: 0512/2102
[A[ATraining Step: 149  | total loss: [1m[32m0.61983[0m[0m | time: 1080.095s
[2K
| Adam | epoch: 003 | loss: 0.61983 - acc: 0.6620 -- iter: 0544/2102
[A[ATraining Step: 150  | total loss: [1m[32m0.60251[0m[0m | time: 1092.906s
[2K
| Adam | epoch: 003 | loss: 0.60251 - acc: 0.6770 -- iter: 0576/2102
[A[ATraining Step: 151  | total loss: [1m[32m0.58835[0m[0m | time: 1106.010s
[2K
| Adam | epoch: 003 | loss: 0.58835 - acc: 0.6812 -- iter: 0608/2102
[A[ATraining Step: 152  | total loss: [1m[32m0.59124[0m[0m | time: 1119.085s
[2K
| Adam | epoch: 003 | loss: 0.59124 - acc: 0.6693 -- iter: 0640/2102
[A[ATraining Step: 153  | total loss: [1m[32m0.58475[0m[0m | time: 1131.650s
[2K
| Adam | epoch: 003 | loss: 0.58475 - acc: 0.6743 -- iter: 0672/2102
[A[ATraining Step: 154  | total loss: [1m[32m0.58836[0m[0m | time: 1145.070s
[2K
| Adam | epoch: 003 | loss: 0.58836 - acc: 0.6787 -- iter: 0704/2102
[A[ATraining Step: 155  | total loss: [1m[32m0.57890[0m[0m | time: 1157.922s
[2K
| Adam | epoch: 003 | loss: 0.57890 - acc: 0.6796 -- iter: 0736/2102
[A[ATraining Step: 156  | total loss: [1m[32m0.59082[0m[0m | time: 1171.115s
[2K
| Adam | epoch: 003 | loss: 0.59082 - acc: 0.6741 -- iter: 0768/2102
[A[ATraining Step: 157  | total loss: [1m[32m0.60733[0m[0m | time: 1192.421s
[2K
| Adam | epoch: 003 | loss: 0.60733 - acc: 0.6630 -- iter: 0800/2102
[A[ATraining Step: 158  | total loss: [1m[32m0.60694[0m[0m | time: 1205.175s
[2K
| Adam | epoch: 003 | loss: 0.60694 - acc: 0.6748 -- iter: 0832/2102
[A[ATraining Step: 159  | total loss: [1m[32m0.61737[0m[0m | time: 1218.086s
[2K
| Adam | epoch: 003 | loss: 0.61737 - acc: 0.6605 -- iter: 0864/2102
[A[ATraining Step: 160  | total loss: [1m[32m0.62021[0m[0m | time: 1230.888s
[2K
| Adam | epoch: 003 | loss: 0.62021 - acc: 0.6569 -- iter: 0896/2102
[A[ATraining Step: 161  | total loss: [1m[32m0.62551[0m[0m | time: 1243.206s
[2K
| Adam | epoch: 003 | loss: 0.62551 - acc: 0.6537 -- iter: 0928/2102
[A[ATraining Step: 162  | total loss: [1m[32m0.64137[0m[0m | time: 1256.055s
[2K
| Adam | epoch: 003 | loss: 0.64137 - acc: 0.6477 -- iter: 0960/2102
[A[ATraining Step: 163  | total loss: [1m[32m0.64981[0m[0m | time: 1268.739s
[2K
| Adam | epoch: 003 | loss: 0.64981 - acc: 0.6361 -- iter: 0992/2102
[A[ATraining Step: 164  | total loss: [1m[32m0.64908[0m[0m | time: 1281.577s
[2K
| Adam | epoch: 003 | loss: 0.64908 - acc: 0.6318 -- iter: 1024/2102
[A[ATraining Step: 165  | total loss: [1m[32m0.63705[0m[0m | time: 1330.829s
[2K
| Adam | epoch: 003 | loss: 0.63705 - acc: 0.6405 -- iter: 1056/2102
[A[ATraining Step: 166  | total loss: [1m[32m0.63820[0m[0m | time: 1343.602s
[2K
| Adam | epoch: 003 | loss: 0.63820 - acc: 0.6390 -- iter: 1088/2102
[A[ATraining Step: 167  | total loss: [1m[32m0.63517[0m[0m | time: 1356.427s
[2K
| Adam | epoch: 003 | loss: 0.63517 - acc: 0.6345 -- iter: 1120/2102
[A[ATraining Step: 168  | total loss: [1m[32m0.63727[0m[0m | time: 1369.005s
[2K
| Adam | epoch: 003 | loss: 0.63727 - acc: 0.6241 -- iter: 1152/2102
[A[ATraining Step: 169  | total loss: [1m[32m0.64045[0m[0m | time: 1381.500s
[2K
| Adam | epoch: 003 | loss: 0.64045 - acc: 0.6211 -- iter: 1184/2102
[A[ATraining Step: 170  | total loss: [1m[32m0.63167[0m[0m | time: 1394.124s
[2K
| Adam | epoch: 003 | loss: 0.63167 - acc: 0.6309 -- iter: 1216/2102
[A[ATraining Step: 171  | total loss: [1m[32m0.63986[0m[0m | time: 1406.587s
[2K
| Adam | epoch: 003 | loss: 0.63986 - acc: 0.6240 -- iter: 1248/2102
[A[ATraining Step: 172  | total loss: [1m[32m0.65138[0m[0m | time: 1418.879s
[2K
| Adam | epoch: 003 | loss: 0.65138 - acc: 0.6179 -- iter: 1280/2102
[A[ATraining Step: 173  | total loss: [1m[32m0.64029[0m[0m | time: 1428.407s
[2K
| Adam | epoch: 003 | loss: 0.64029 - acc: 0.6311 -- iter: 1312/2102
[A[ATraining Step: 174  | total loss: [1m[32m0.62564[0m[0m | time: 1442.888s
[2K
| Adam | epoch: 003 | loss: 0.62564 - acc: 0.6461 -- iter: 1344/2102
[A[ATraining Step: 175  | total loss: [1m[32m0.63566[0m[0m | time: 1457.149s
[2K
| Adam | epoch: 003 | loss: 0.63566 - acc: 0.6409 -- iter: 1376/2102
[A[ATraining Step: 176  | total loss: [1m[32m0.62815[0m[0m | time: 1471.189s
[2K
| Adam | epoch: 003 | loss: 0.62815 - acc: 0.6487 -- iter: 1408/2102
[A[ATraining Step: 177  | total loss: [1m[32m0.62384[0m[0m | time: 1485.830s
[2K
| Adam | epoch: 003 | loss: 0.62384 - acc: 0.6557 -- iter: 1440/2102
[A[ATraining Step: 178  | total loss: [1m[32m0.62310[0m[0m | time: 1498.787s
[2K
| Adam | epoch: 003 | loss: 0.62310 - acc: 0.6588 -- iter: 1472/2102
[A[ATraining Step: 179  | total loss: [1m[32m0.62265[0m[0m | time: 1507.683s
[2K
| Adam | epoch: 003 | loss: 0.62265 - acc: 0.6680 -- iter: 1504/2102
[A[ATraining Step: 180  | total loss: [1m[32m0.61494[0m[0m | time: 1516.348s
[2K
| Adam | epoch: 003 | loss: 0.61494 - acc: 0.6762 -- iter: 1536/2102
[A[ATraining Step: 181  | total loss: [1m[32m0.60769[0m[0m | time: 1524.988s
[2K
| Adam | epoch: 003 | loss: 0.60769 - acc: 0.6836 -- iter: 1568/2102
[A[ATraining Step: 182  | total loss: [1m[32m0.60184[0m[0m | time: 1537.116s
[2K
| Adam | epoch: 003 | loss: 0.60184 - acc: 0.6871 -- iter: 1600/2102
[A[ATraining Step: 183  | total loss: [1m[32m0.61090[0m[0m | time: 1550.535s
[2K
| Adam | epoch: 003 | loss: 0.61090 - acc: 0.6777 -- iter: 1632/2102
[A[ATraining Step: 184  | total loss: [1m[32m0.60255[0m[0m | time: 1563.668s
[2K
| Adam | epoch: 003 | loss: 0.60255 - acc: 0.6912 -- iter: 1664/2102
[A[ATraining Step: 185  | total loss: [1m[32m0.61299[0m[0m | time: 1576.909s
[2K
| Adam | epoch: 003 | loss: 0.61299 - acc: 0.6971 -- iter: 1696/2102
[A[ATraining Step: 186  | total loss: [1m[32m0.61498[0m[0m | time: 1589.978s
[2K
| Adam | epoch: 003 | loss: 0.61498 - acc: 0.6961 -- iter: 1728/2102
[A[ATraining Step: 187  | total loss: [1m[32m0.60266[0m[0m | time: 1604.681s
[2K
| Adam | epoch: 003 | loss: 0.60266 - acc: 0.7078 -- iter: 1760/2102
[A[ATraining Step: 188  | total loss: [1m[32m0.59639[0m[0m | time: 1617.974s
[2K
| Adam | epoch: 003 | loss: 0.59639 - acc: 0.6995 -- iter: 1792/2102
[A[ATraining Step: 189  | total loss: [1m[32m0.60006[0m[0m | time: 1632.891s
[2K
| Adam | epoch: 003 | loss: 0.60006 - acc: 0.6889 -- iter: 1824/2102
[A[ATraining Step: 190  | total loss: [1m[32m0.60509[0m[0m | time: 1645.989s
[2K
| Adam | epoch: 003 | loss: 0.60509 - acc: 0.6857 -- iter: 1856/2102
[A[ATraining Step: 191  | total loss: [1m[32m0.60578[0m[0m | time: 1658.882s
[2K
| Adam | epoch: 003 | loss: 0.60578 - acc: 0.6827 -- iter: 1888/2102
[A[ATraining Step: 192  | total loss: [1m[32m0.60030[0m[0m | time: 1673.249s
[2K
| Adam | epoch: 003 | loss: 0.60030 - acc: 0.6894 -- iter: 1920/2102
[A[ATraining Step: 193  | total loss: [1m[32m0.59119[0m[0m | time: 1686.154s
[2K
| Adam | epoch: 003 | loss: 0.59119 - acc: 0.6924 -- iter: 1952/2102
[A[ATraining Step: 194  | total loss: [1m[32m0.58688[0m[0m | time: 1699.096s
[2K
| Adam | epoch: 003 | loss: 0.58688 - acc: 0.7013 -- iter: 1984/2102
[A[ATraining Step: 195  | total loss: [1m[32m0.59010[0m[0m | time: 1712.541s
[2K
| Adam | epoch: 003 | loss: 0.59010 - acc: 0.6905 -- iter: 2016/2102
[A[ATraining Step: 196  | total loss: [1m[32m0.58221[0m[0m | time: 1725.750s
[2K
| Adam | epoch: 003 | loss: 0.58221 - acc: 0.6996 -- iter: 2048/2102
[A[ATraining Step: 197  | total loss: [1m[32m0.59102[0m[0m | time: 1738.330s
[2K
| Adam | epoch: 003 | loss: 0.59102 - acc: 0.6984 -- iter: 2080/2102
[A[ATraining Step: 198  | total loss: [1m[32m0.59438[0m[0m | time: 1828.939s
[2K
| Adam | epoch: 003 | loss: 0.59438 - acc: 0.7035 | val_loss: 1.44009 - val_acc: 0.6246 -- iter: 2102/2102
--
Training Step: 199  | total loss: [1m[32m0.57973[0m[0m | time: 15.386s
[2K
| Adam | epoch: 004 | loss: 0.57973 - acc: 0.7113 -- iter: 0032/2102
[A[ATraining Step: 200  | total loss: [1m[32m0.59524[0m[0m | time: 71.886s
[2K
| Adam | epoch: 004 | loss: 0.59524 - acc: 0.6964 | val_loss: 1.25397 - val_acc: 0.6292 -- iter: 0064/2102
--
Training Step: 201  | total loss: [1m[32m0.59065[0m[0m | time: 80.619s
[2K
| Adam | epoch: 004 | loss: 0.59065 - acc: 0.7086 -- iter: 0096/2102
[A[ATraining Step: 202  | total loss: [1m[32m0.58237[0m[0m | time: 93.212s
[2K
| Adam | epoch: 004 | loss: 0.58237 - acc: 0.7059 -- iter: 0128/2102
[A[ATraining Step: 203  | total loss: [1m[32m0.58984[0m[0m | time: 115.629s
[2K
| Adam | epoch: 004 | loss: 0.58984 - acc: 0.6947 -- iter: 0160/2102
[A[ATraining Step: 204  | total loss: [1m[32m0.59806[0m[0m | time: 129.622s
[2K
| Adam | epoch: 004 | loss: 0.59806 - acc: 0.6846 -- iter: 0192/2102
[A[ATraining Step: 205  | total loss: [1m[32m0.59858[0m[0m | time: 142.346s
[2K
| Adam | epoch: 004 | loss: 0.59858 - acc: 0.6818 -- iter: 0224/2102
[A[ATraining Step: 206  | total loss: [1m[32m0.61348[0m[0m | time: 155.022s
[2K
| Adam | epoch: 004 | loss: 0.61348 - acc: 0.6667 -- iter: 0256/2102
[A[ATraining Step: 207  | total loss: [1m[32m0.61657[0m[0m | time: 168.734s
[2K
| Adam | epoch: 004 | loss: 0.61657 - acc: 0.6594 -- iter: 0288/2102
[A[ATraining Step: 208  | total loss: [1m[32m0.62277[0m[0m | time: 181.526s
[2K
| Adam | epoch: 004 | loss: 0.62277 - acc: 0.6654 -- iter: 0320/2102
[A[ATraining Step: 209  | total loss: [1m[32m0.62809[0m[0m | time: 207.068s
[2K
| Adam | epoch: 004 | loss: 0.62809 - acc: 0.6551 -- iter: 0352/2102
[A[ATraining Step: 210  | total loss: [1m[32m0.63332[0m[0m | time: 219.626s
[2K
| Adam | epoch: 004 | loss: 0.63332 - acc: 0.6396 -- iter: 0384/2102
[A[ATraining Step: 211  | total loss: [1m[32m0.63807[0m[0m | time: 232.478s
[2K
| Adam | epoch: 004 | loss: 0.63807 - acc: 0.6319 -- iter: 0416/2102
[A[ATraining Step: 212  | total loss: [1m[32m0.63551[0m[0m | time: 245.635s
[2K
| Adam | epoch: 004 | loss: 0.63551 - acc: 0.6437 -- iter: 0448/2102
[A[ATraining Step: 213  | total loss: [1m[32m0.63981[0m[0m | time: 258.618s
[2K
| Adam | epoch: 004 | loss: 0.63981 - acc: 0.6262 -- iter: 0480/2102
[A[ATraining Step: 214  | total loss: [1m[32m0.63724[0m[0m | time: 272.000s
[2K
| Adam | epoch: 004 | loss: 0.63724 - acc: 0.6386 -- iter: 0512/2102
[A[ATraining Step: 215  | total loss: [1m[32m0.63188[0m[0m | time: 289.159s
[2K
| Adam | epoch: 004 | loss: 0.63188 - acc: 0.6497 -- iter: 0544/2102
[A[ATraining Step: 216  | total loss: [1m[32m0.62558[0m[0m | time: 301.932s
[2K
| Adam | epoch: 004 | loss: 0.62558 - acc: 0.6535 -- iter: 0576/2102
[A[ATraining Step: 217  | total loss: [1m[32m0.62576[0m[0m | time: 314.762s
[2K
| Adam | epoch: 004 | loss: 0.62576 - acc: 0.6475 -- iter: 0608/2102
[A[ATraining Step: 218  | total loss: [1m[32m0.64311[0m[0m | time: 327.486s
[2K
| Adam | epoch: 004 | loss: 0.64311 - acc: 0.6421 -- iter: 0640/2102
[A[ATraining Step: 219  | total loss: [1m[32m0.63958[0m[0m | time: 340.051s
[2K
| Adam | epoch: 004 | loss: 0.63958 - acc: 0.6498 -- iter: 0672/2102
[A[ATraining Step: 220  | total loss: [1m[32m0.65805[0m[0m | time: 352.967s
[2K
| Adam | epoch: 004 | loss: 0.65805 - acc: 0.6348 -- iter: 0704/2102
[A[ATraining Step: 221  | total loss: [1m[32m0.64733[0m[0m | time: 365.831s
[2K
| Adam | epoch: 004 | loss: 0.64733 - acc: 0.6463 -- iter: 0736/2102
[A[ATraining Step: 222  | total loss: [1m[32m0.64242[0m[0m | time: 378.585s
[2K
| Adam | epoch: 004 | loss: 0.64242 - acc: 0.6536 -- iter: 0768/2102
[A[ATraining Step: 223  | total loss: [1m[32m0.64687[0m[0m | time: 391.113s
[2K
| Adam | epoch: 004 | loss: 0.64687 - acc: 0.6538 -- iter: 0800/2102
[A[ATraining Step: 224  | total loss: [1m[32m0.64870[0m[0m | time: 403.668s
[2K
| Adam | epoch: 004 | loss: 0.64870 - acc: 0.6541 -- iter: 0832/2102
[A[ATraining Step: 225  | total loss: [1m[32m0.65280[0m[0m | time: 420.351s
[2K
| Adam | epoch: 004 | loss: 0.65280 - acc: 0.6449 -- iter: 0864/2102
[A[ATraining Step: 226  | total loss: [1m[32m0.63744[0m[0m | time: 433.168s
[2K
| Adam | epoch: 004 | loss: 0.63744 - acc: 0.6523 -- iter: 0896/2102
[A[ATraining Step: 227  | total loss: [1m[32m0.63609[0m[0m | time: 446.026s
[2K
| Adam | epoch: 004 | loss: 0.63609 - acc: 0.6558 -- iter: 0928/2102
[A[ATraining Step: 228  | total loss: [1m[32m0.63321[0m[0m | time: 458.940s
[2K
| Adam | epoch: 004 | loss: 0.63321 - acc: 0.6559 -- iter: 0960/2102
[A[ATraining Step: 229  | total loss: [1m[32m0.64434[0m[0m | time: 482.394s
[2K
| Adam | epoch: 004 | loss: 0.64434 - acc: 0.6372 -- iter: 0992/2102
[A[ATraining Step: 230  | total loss: [1m[32m0.64242[0m[0m | time: 495.115s
[2K
| Adam | epoch: 004 | loss: 0.64242 - acc: 0.6359 -- iter: 1024/2102
[A[ATraining Step: 231  | total loss: [1m[32m0.64432[0m[0m | time: 511.487s
[2K
| Adam | epoch: 004 | loss: 0.64432 - acc: 0.6317 -- iter: 1056/2102
[A[ATraining Step: 232  | total loss: [1m[32m0.65418[0m[0m | time: 527.461s
[2K
| Adam | epoch: 004 | loss: 0.65418 - acc: 0.6279 -- iter: 1088/2102
[A[ATraining Step: 233  | total loss: [1m[32m0.63822[0m[0m | time: 546.084s
[2K
| Adam | epoch: 004 | loss: 0.63822 - acc: 0.6433 -- iter: 1120/2102
[A[ATraining Step: 234  | total loss: [1m[32m0.62802[0m[0m | time: 564.825s
[2K
| Adam | epoch: 004 | loss: 0.62802 - acc: 0.6539 -- iter: 1152/2102
[A[ATraining Step: 235  | total loss: [1m[32m0.62187[0m[0m | time: 578.213s
[2K
| Adam | epoch: 004 | loss: 0.62187 - acc: 0.6573 -- iter: 1184/2102
[A[ATraining Step: 236  | total loss: [1m[32m0.62707[0m[0m | time: 622.103s
[2K
| Adam | epoch: 004 | loss: 0.62707 - acc: 0.6509 -- iter: 1216/2102
[A[ATraining Step: 237  | total loss: [1m[32m0.62728[0m[0m | time: 650.171s
[2K
| Adam | epoch: 004 | loss: 0.62728 - acc: 0.6483 -- iter: 1248/2102
[A[ATraining Step: 238  | total loss: [1m[32m0.61867[0m[0m | time: 662.745s
[2K
| Adam | epoch: 004 | loss: 0.61867 - acc: 0.6554 -- iter: 1280/2102
[A[ATraining Step: 239  | total loss: [1m[32m0.63382[0m[0m | time: 676.313s
[2K
| Adam | epoch: 004 | loss: 0.63382 - acc: 0.6492 -- iter: 1312/2102
[A[ATraining Step: 240  | total loss: [1m[32m0.63025[0m[0m | time: 689.118s
[2K
| Adam | epoch: 004 | loss: 0.63025 - acc: 0.6499 -- iter: 1344/2102
[A[ATraining Step: 241  | total loss: [1m[32m0.62412[0m[0m | time: 704.116s
[2K
| Adam | epoch: 004 | loss: 0.62412 - acc: 0.6537 -- iter: 1376/2102
[A[ATraining Step: 242  | total loss: [1m[32m0.61492[0m[0m | time: 716.759s
[2K
| Adam | epoch: 004 | loss: 0.61492 - acc: 0.6602 -- iter: 1408/2102
[A[ATraining Step: 243  | total loss: [1m[32m0.60677[0m[0m | time: 731.835s
[2K
| Adam | epoch: 004 | loss: 0.60677 - acc: 0.6692 -- iter: 1440/2102
[A[ATraining Step: 244  | total loss: [1m[32m0.61000[0m[0m | time: 744.367s
[2K
| Adam | epoch: 004 | loss: 0.61000 - acc: 0.6616 -- iter: 1472/2102
[A[ATraining Step: 245  | total loss: [1m[32m0.60225[0m[0m | time: 756.779s
[2K
| Adam | epoch: 004 | loss: 0.60225 - acc: 0.6673 -- iter: 1504/2102
[A[ATraining Step: 246  | total loss: [1m[32m0.60550[0m[0m | time: 786.090s
[2K
| Adam | epoch: 004 | loss: 0.60550 - acc: 0.6694 -- iter: 1536/2102
[A[ATraining Step: 247  | total loss: [1m[32m0.58956[0m[0m | time: 798.454s
[2K
| Adam | epoch: 004 | loss: 0.58956 - acc: 0.6868 -- iter: 1568/2102
[A[ATraining Step: 248  | total loss: [1m[32m0.59770[0m[0m | time: 811.279s
[2K
| Adam | epoch: 004 | loss: 0.59770 - acc: 0.6900 -- iter: 1600/2102
[A[ATraining Step: 249  | total loss: [1m[32m0.59571[0m[0m | time: 823.480s
[2K
| Adam | epoch: 004 | loss: 0.59571 - acc: 0.6866 -- iter: 1632/2102
[A[ATraining Step: 250  | total loss: [1m[32m0.58430[0m[0m | time: 836.077s
[2K
| Adam | epoch: 004 | loss: 0.58430 - acc: 0.7023 -- iter: 1664/2102
[A[ATraining Step: 251  | total loss: [1m[32m0.59146[0m[0m | time: 857.090s
[2K
| Adam | epoch: 004 | loss: 0.59146 - acc: 0.7008 -- iter: 1696/2102
[A[ATraining Step: 252  | total loss: [1m[32m0.57239[0m[0m | time: 869.886s
[2K
| Adam | epoch: 004 | loss: 0.57239 - acc: 0.7089 -- iter: 1728/2102
[A[ATraining Step: 253  | total loss: [1m[32m0.56989[0m[0m | time: 882.790s
[2K
| Adam | epoch: 004 | loss: 0.56989 - acc: 0.7067 -- iter: 1760/2102
[A[ATraining Step: 254  | total loss: [1m[32m0.57319[0m[0m | time: 895.471s
[2K
| Adam | epoch: 004 | loss: 0.57319 - acc: 0.7111 -- iter: 1792/2102
[A[ATraining Step: 255  | total loss: [1m[32m0.58267[0m[0m | time: 908.010s
[2K
| Adam | epoch: 004 | loss: 0.58267 - acc: 0.6993 -- iter: 1824/2102
[A[ATraining Step: 256  | total loss: [1m[32m0.59584[0m[0m | time: 920.925s
[2K
| Adam | epoch: 004 | loss: 0.59584 - acc: 0.6982 -- iter: 1856/2102
[A[ATraining Step: 257  | total loss: [1m[32m0.60970[0m[0m | time: 961.419s
[2K
| Adam | epoch: 004 | loss: 0.60970 - acc: 0.6846 -- iter: 1888/2102
[A[ATraining Step: 258  | total loss: [1m[32m0.61211[0m[0m | time: 977.633s
[2K
| Adam | epoch: 004 | loss: 0.61211 - acc: 0.6786 -- iter: 1920/2102
[A[ATraining Step: 259  | total loss: [1m[32m0.60810[0m[0m | time: 1008.768s
[2K
| Adam | epoch: 004 | loss: 0.60810 - acc: 0.6889 -- iter: 1952/2102
[A[ATraining Step: 260  | total loss: [1m[32m0.60000[0m[0m | time: 1021.086s
[2K
| Adam | epoch: 004 | loss: 0.60000 - acc: 0.6919 -- iter: 1984/2102
[A[ATraining Step: 261  | total loss: [1m[32m0.60024[0m[0m | time: 1033.687s
[2K
| Adam | epoch: 004 | loss: 0.60024 - acc: 0.6977 -- iter: 2016/2102
[A[ATraining Step: 262  | total loss: [1m[32m0.59109[0m[0m | time: 1068.916s
[2K
| Adam | epoch: 004 | loss: 0.59109 - acc: 0.6967 -- iter: 2048/2102
[A[ATraining Step: 263  | total loss: [1m[32m0.60201[0m[0m | time: 1081.677s
[2K
| Adam | epoch: 004 | loss: 0.60201 - acc: 0.6770 -- iter: 2080/2102
[A[ATraining Step: 264  | total loss: [1m[32m0.60773[0m[0m | time: 1141.270s
[2K
| Adam | epoch: 004 | loss: 0.60773 - acc: 0.6749 | val_loss: 0.63867 - val_acc: 0.6185 -- iter: 2102/2102
--
Training Step: 265  | total loss: [1m[32m0.61714[0m[0m | time: 14.642s
[2K
| Adam | epoch: 005 | loss: 0.61714 - acc: 0.6699 -- iter: 0032/2102
[A[ATraining Step: 266  | total loss: [1m[32m0.61689[0m[0m | time: 30.153s
[2K
| Adam | epoch: 005 | loss: 0.61689 - acc: 0.6686 -- iter: 0064/2102
[A[ATraining Step: 267  | total loss: [1m[32m0.61020[0m[0m | time: 40.748s
[2K
| Adam | epoch: 005 | loss: 0.61020 - acc: 0.6705 -- iter: 0096/2102
[A[ATraining Step: 268  | total loss: [1m[32m0.59990[0m[0m | time: 51.032s
[2K
| Adam | epoch: 005 | loss: 0.59990 - acc: 0.6807 -- iter: 0128/2102
[A[ATraining Step: 269  | total loss: [1m[32m0.58639[0m[0m | time: 68.468s
[2K
| Adam | epoch: 005 | loss: 0.58639 - acc: 0.6853 -- iter: 0160/2102
[A[ATraining Step: 270  | total loss: [1m[32m0.58932[0m[0m | time: 77.054s
[2K
| Adam | epoch: 005 | loss: 0.58932 - acc: 0.6856 -- iter: 0192/2102
[A[ATraining Step: 271  | total loss: [1m[32m0.59346[0m[0m | time: 89.511s
[2K
| Adam | epoch: 005 | loss: 0.59346 - acc: 0.6764 -- iter: 0224/2102
[A[ATraining Step: 272  | total loss: [1m[32m0.60378[0m[0m | time: 106.624s
[2K
| Adam | epoch: 005 | loss: 0.60378 - acc: 0.6681 -- iter: 0256/2102
[A[ATraining Step: 273  | total loss: [1m[32m0.60107[0m[0m | time: 119.574s
[2K
| Adam | epoch: 005 | loss: 0.60107 - acc: 0.6701 -- iter: 0288/2102
[A[ATraining Step: 274  | total loss: [1m[32m0.62266[0m[0m | time: 132.593s
[2K
| Adam | epoch: 005 | loss: 0.62266 - acc: 0.6531 -- iter: 0320/2102
[A[ATraining Step: 275  | total loss: [1m[32m0.61415[0m[0m | time: 145.299s
[2K
| Adam | epoch: 005 | loss: 0.61415 - acc: 0.6502 -- iter: 0352/2102
[A[ATraining Step: 276  | total loss: [1m[32m0.61459[0m[0m | time: 157.722s
[2K
| Adam | epoch: 005 | loss: 0.61459 - acc: 0.6477 -- iter: 0384/2102
[A[ATraining Step: 277  | total loss: [1m[32m0.60047[0m[0m | time: 170.469s
[2K
| Adam | epoch: 005 | loss: 0.60047 - acc: 0.6642 -- iter: 0416/2102
[A[ATraining Step: 278  | total loss: [1m[32m0.59141[0m[0m | time: 183.178s
[2K
| Adam | epoch: 005 | loss: 0.59141 - acc: 0.6728 -- iter: 0448/2102
[A[ATraining Step: 279  | total loss: [1m[32m0.60108[0m[0m | time: 196.517s
[2K
| Adam | epoch: 005 | loss: 0.60108 - acc: 0.6586 -- iter: 0480/2102
[A[ATraining Step: 280  | total loss: [1m[32m0.59354[0m[0m | time: 217.048s
[2K
| Adam | epoch: 005 | loss: 0.59354 - acc: 0.6584 -- iter: 0512/2102
[A[ATraining Step: 281  | total loss: [1m[32m0.59578[0m[0m | time: 231.016s
[2K
| Adam | epoch: 005 | loss: 0.59578 - acc: 0.6519 -- iter: 0544/2102
[A[ATraining Step: 282  | total loss: [1m[32m0.58417[0m[0m | time: 245.800s
[2K
| Adam | epoch: 005 | loss: 0.58417 - acc: 0.6586 -- iter: 0576/2102
[A[ATraining Step: 283  | total loss: [1m[32m0.59542[0m[0m | time: 260.094s
[2K
| Adam | epoch: 005 | loss: 0.59542 - acc: 0.6584 -- iter: 0608/2102
[A[ATraining Step: 284  | total loss: [1m[32m0.59233[0m[0m | time: 272.749s
[2K
| Adam | epoch: 005 | loss: 0.59233 - acc: 0.6582 -- iter: 0640/2102
[A[ATraining Step: 285  | total loss: [1m[32m0.59179[0m[0m | time: 281.500s
[2K
| Adam | epoch: 005 | loss: 0.59179 - acc: 0.6611 -- iter: 0672/2102
[A[ATraining Step: 286  | total loss: [1m[32m0.58704[0m[0m | time: 294.390s
[2K
| Adam | epoch: 005 | loss: 0.58704 - acc: 0.6669 -- iter: 0704/2102
[A[ATraining Step: 287  | total loss: [1m[32m0.58601[0m[0m | time: 307.079s
[2K
| Adam | epoch: 005 | loss: 0.58601 - acc: 0.6720 -- iter: 0736/2102
[A[ATraining Step: 288  | total loss: [1m[32m0.57839[0m[0m | time: 319.438s
[2K
| Adam | epoch: 005 | loss: 0.57839 - acc: 0.6830 -- iter: 0768/2102
[A[ATraining Step: 289  | total loss: [1m[32m0.60048[0m[0m | time: 333.243s
[2K
| Adam | epoch: 005 | loss: 0.60048 - acc: 0.6709 -- iter: 0800/2102
[A[ATraining Step: 290  | total loss: [1m[32m0.58601[0m[0m | time: 346.240s
[2K
| Adam | epoch: 005 | loss: 0.58601 - acc: 0.6851 -- iter: 0832/2102
[A[ATraining Step: 291  | total loss: [1m[32m0.58430[0m[0m | time: 364.345s
[2K
| Adam | epoch: 005 | loss: 0.58430 - acc: 0.6916 -- iter: 0864/2102
[A[ATraining Step: 292  | total loss: [1m[32m0.59017[0m[0m | time: 388.113s
[2K
| Adam | epoch: 005 | loss: 0.59017 - acc: 0.6880 -- iter: 0896/2102
[A[ATraining Step: 293  | total loss: [1m[32m0.58556[0m[0m | time: 400.751s
[2K
| Adam | epoch: 005 | loss: 0.58556 - acc: 0.6942 -- iter: 0928/2102
[A[ATraining Step: 294  | total loss: [1m[32m0.58352[0m[0m | time: 413.435s
[2K
| Adam | epoch: 005 | loss: 0.58352 - acc: 0.6936 -- iter: 0960/2102
[A[ATraining Step: 295  | total loss: [1m[32m0.58773[0m[0m | time: 425.989s
[2K
| Adam | epoch: 005 | loss: 0.58773 - acc: 0.6930 -- iter: 0992/2102
[A[ATraining Step: 296  | total loss: [1m[32m0.57936[0m[0m | time: 438.456s
[2K
| Adam | epoch: 005 | loss: 0.57936 - acc: 0.7018 -- iter: 1024/2102
[A[ATraining Step: 297  | total loss: [1m[32m0.58718[0m[0m | time: 453.435s
[2K
| Adam | epoch: 005 | loss: 0.58718 - acc: 0.6910 -- iter: 1056/2102
[A[ATraining Step: 298  | total loss: [1m[32m0.58743[0m[0m | time: 466.235s
[2K
| Adam | epoch: 005 | loss: 0.58743 - acc: 0.6938 -- iter: 1088/2102
[A[ATraining Step: 299  | total loss: [1m[32m0.57539[0m[0m | time: 482.981s
[2K
| Adam | epoch: 005 | loss: 0.57539 - acc: 0.7025 -- iter: 1120/2102
[A[ATraining Step: 300  | total loss: [1m[32m0.56905[0m[0m | time: 495.357s
[2K
| Adam | epoch: 005 | loss: 0.56905 - acc: 0.7041 -- iter: 1152/2102
[A[ATraining Step: 301  | total loss: [1m[32m0.58126[0m[0m | time: 508.222s
[2K
| Adam | epoch: 005 | loss: 0.58126 - acc: 0.6837 -- iter: 1184/2102
[A[ATraining Step: 302  | total loss: [1m[32m0.57118[0m[0m | time: 520.408s
[2K
| Adam | epoch: 005 | loss: 0.57118 - acc: 0.6935 -- iter: 1216/2102
[A[ATraining Step: 303  | total loss: [1m[32m0.56791[0m[0m | time: 540.376s
[2K
| Adam | epoch: 005 | loss: 0.56791 - acc: 0.6929 -- iter: 1248/2102
[A[ATraining Step: 304  | total loss: [1m[32m0.54506[0m[0m | time: 553.280s
[2K
| Adam | epoch: 005 | loss: 0.54506 - acc: 0.7048 -- iter: 1280/2102
[A[ATraining Step: 305  | total loss: [1m[32m0.55625[0m[0m | time: 566.005s
[2K
| Adam | epoch: 005 | loss: 0.55625 - acc: 0.6969 -- iter: 1312/2102
[A[ATraining Step: 306  | total loss: [1m[32m0.55757[0m[0m | time: 579.129s
[2K
| Adam | epoch: 005 | loss: 0.55757 - acc: 0.6959 -- iter: 1344/2102
[A[ATraining Step: 307  | total loss: [1m[32m0.54223[0m[0m | time: 592.549s
[2K
| Adam | epoch: 005 | loss: 0.54223 - acc: 0.7138 -- iter: 1376/2102
[A[ATraining Step: 308  | total loss: [1m[32m0.54229[0m[0m | time: 606.413s
[2K
| Adam | epoch: 005 | loss: 0.54229 - acc: 0.7112 -- iter: 1408/2102
[A[ATraining Step: 309  | total loss: [1m[32m0.54525[0m[0m | time: 619.197s
[2K
| Adam | epoch: 005 | loss: 0.54525 - acc: 0.7088 -- iter: 1440/2102
[A[ATraining Step: 310  | total loss: [1m[32m0.53731[0m[0m | time: 632.067s
[2K
| Adam | epoch: 005 | loss: 0.53731 - acc: 0.7161 -- iter: 1472/2102
[A[ATraining Step: 311  | total loss: [1m[32m0.52165[0m[0m | time: 644.905s
[2K
| Adam | epoch: 005 | loss: 0.52165 - acc: 0.7257 -- iter: 1504/2102
[A[ATraining Step: 312  | total loss: [1m[32m0.51656[0m[0m | time: 657.395s
[2K
| Adam | epoch: 005 | loss: 0.51656 - acc: 0.7250 -- iter: 1536/2102
[A[ATraining Step: 313  | total loss: [1m[32m0.51326[0m[0m | time: 670.278s
[2K
| Adam | epoch: 005 | loss: 0.51326 - acc: 0.7275 -- iter: 1568/2102
[A[ATraining Step: 314  | total loss: [1m[32m0.50347[0m[0m | time: 682.965s
[2K
| Adam | epoch: 005 | loss: 0.50347 - acc: 0.7329 -- iter: 1600/2102
[A[ATraining Step: 315  | total loss: [1m[32m0.49566[0m[0m | time: 695.350s
[2K
| Adam | epoch: 005 | loss: 0.49566 - acc: 0.7377 -- iter: 1632/2102
[A[ATraining Step: 316  | total loss: [1m[32m0.50700[0m[0m | time: 708.076s
[2K
| Adam | epoch: 005 | loss: 0.50700 - acc: 0.7296 -- iter: 1664/2102
[A[ATraining Step: 317  | total loss: [1m[32m0.50642[0m[0m | time: 720.874s
[2K
| Adam | epoch: 005 | loss: 0.50642 - acc: 0.7347 -- iter: 1696/2102
[A[ATraining Step: 318  | total loss: [1m[32m0.49794[0m[0m | time: 733.693s
[2K
| Adam | epoch: 005 | loss: 0.49794 - acc: 0.7363 -- iter: 1728/2102
[A[ATraining Step: 319  | total loss: [1m[32m0.50969[0m[0m | time: 746.376s
[2K
| Adam | epoch: 005 | loss: 0.50969 - acc: 0.7314 -- iter: 1760/2102
[A[ATraining Step: 320  | total loss: [1m[32m0.52399[0m[0m | time: 758.872s
[2K
| Adam | epoch: 005 | loss: 0.52399 - acc: 0.7270 -- iter: 1792/2102
[A[ATraining Step: 321  | total loss: [1m[32m0.52550[0m[0m | time: 771.701s
[2K
| Adam | epoch: 005 | loss: 0.52550 - acc: 0.7262 -- iter: 1824/2102
[A[ATraining Step: 322  | total loss: [1m[32m0.52036[0m[0m | time: 784.474s
[2K
| Adam | epoch: 005 | loss: 0.52036 - acc: 0.7348 -- iter: 1856/2102
[A[ATraining Step: 323  | total loss: [1m[32m0.52087[0m[0m | time: 797.574s
[2K
| Adam | epoch: 005 | loss: 0.52087 - acc: 0.7270 -- iter: 1888/2102
[A[ATraining Step: 324  | total loss: [1m[32m0.53417[0m[0m | time: 820.546s
[2K
| Adam | epoch: 005 | loss: 0.53417 - acc: 0.7230 -- iter: 1920/2102
[A[ATraining Step: 325  | total loss: [1m[32m0.54046[0m[0m | time: 832.605s
[2K
| Adam | epoch: 005 | loss: 0.54046 - acc: 0.7195 -- iter: 1952/2102
[A[ATraining Step: 326  | total loss: [1m[32m0.55183[0m[0m | time: 845.451s
[2K
| Adam | epoch: 005 | loss: 0.55183 - acc: 0.7225 -- iter: 1984/2102
[A[ATraining Step: 327  | total loss: [1m[32m0.55920[0m[0m | time: 858.152s
[2K
| Adam | epoch: 005 | loss: 0.55920 - acc: 0.7096 -- iter: 2016/2102
[A[ATraining Step: 328  | total loss: [1m[32m0.57644[0m[0m | time: 870.834s
[2K
| Adam | epoch: 005 | loss: 0.57644 - acc: 0.7012 -- iter: 2048/2102
[A[ATraining Step: 329  | total loss: [1m[32m0.58674[0m[0m | time: 883.434s
[2K
| Adam | epoch: 005 | loss: 0.58674 - acc: 0.6967 -- iter: 2080/2102
[A[ATraining Step: 330  | total loss: [1m[32m0.58326[0m[0m | time: 943.466s
[2K
| Adam | epoch: 005 | loss: 0.58326 - acc: 0.6958 | val_loss: 0.65337 - val_acc: 0.6079 -- iter: 2102/2102
--
Training Step: 331  | total loss: [1m[32m0.58304[0m[0m | time: 12.659s
[2K
| Adam | epoch: 006 | loss: 0.58304 - acc: 0.6949 -- iter: 0032/2102
[A[ATraining Step: 332  | total loss: [1m[32m0.58896[0m[0m | time: 25.806s
[2K
| Adam | epoch: 006 | loss: 0.58896 - acc: 0.6942 -- iter: 0064/2102
[A[ATraining Step: 333  | total loss: [1m[32m0.58706[0m[0m | time: 38.379s
[2K
| Adam | epoch: 006 | loss: 0.58706 - acc: 0.6966 -- iter: 0096/2102
[A[ATraining Step: 334  | total loss: [1m[32m0.59285[0m[0m | time: 47.186s
[2K
| Adam | epoch: 006 | loss: 0.59285 - acc: 0.6832 -- iter: 0128/2102
[A[ATraining Step: 335  | total loss: [1m[32m0.58754[0m[0m | time: 56.341s
[2K
| Adam | epoch: 006 | loss: 0.58754 - acc: 0.6922 -- iter: 0160/2102
[A[ATraining Step: 336  | total loss: [1m[32m0.58321[0m[0m | time: 69.317s
[2K
| Adam | epoch: 006 | loss: 0.58321 - acc: 0.7002 -- iter: 0192/2102
[A[ATraining Step: 337  | total loss: [1m[32m0.57177[0m[0m | time: 82.196s
[2K
| Adam | epoch: 006 | loss: 0.57177 - acc: 0.7146 -- iter: 0224/2102
[A[ATraining Step: 338  | total loss: [1m[32m0.56927[0m[0m | time: 95.156s
[2K
| Adam | epoch: 006 | loss: 0.56927 - acc: 0.7181 -- iter: 0256/2102
[A[ATraining Step: 339  | total loss: [1m[32m0.55942[0m[0m | time: 107.741s
[2K
| Adam | epoch: 006 | loss: 0.55942 - acc: 0.7244 -- iter: 0288/2102
[A[ATraining Step: 340  | total loss: [1m[32m0.57383[0m[0m | time: 120.841s
[2K
| Adam | epoch: 006 | loss: 0.57383 - acc: 0.7145 -- iter: 0320/2102
[A[ATraining Step: 341  | total loss: [1m[32m0.56722[0m[0m | time: 133.452s
[2K
| Adam | epoch: 006 | loss: 0.56722 - acc: 0.7243 -- iter: 0352/2102
[A[ATraining Step: 342  | total loss: [1m[32m0.56626[0m[0m | time: 146.781s
[2K
| Adam | epoch: 006 | loss: 0.56626 - acc: 0.7269 -- iter: 0384/2102
[A[ATraining Step: 343  | total loss: [1m[32m0.55633[0m[0m | time: 159.484s
[2K
| Adam | epoch: 006 | loss: 0.55633 - acc: 0.7292 -- iter: 0416/2102
[A[ATraining Step: 344  | total loss: [1m[32m0.58123[0m[0m | time: 172.258s
[2K
| Adam | epoch: 006 | loss: 0.58123 - acc: 0.7188 -- iter: 0448/2102
[A[ATraining Step: 345  | total loss: [1m[32m0.58721[0m[0m | time: 185.145s
[2K
| Adam | epoch: 006 | loss: 0.58721 - acc: 0.7156 -- iter: 0480/2102
[A[ATraining Step: 346  | total loss: [1m[32m0.59009[0m[0m | time: 198.224s
[2K
| Adam | epoch: 006 | loss: 0.59009 - acc: 0.7066 -- iter: 0512/2102
[A[ATraining Step: 347  | total loss: [1m[32m0.58029[0m[0m | time: 211.280s
[2K
| Adam | epoch: 006 | loss: 0.58029 - acc: 0.7140 -- iter: 0544/2102
[A[ATraining Step: 348  | total loss: [1m[32m0.58059[0m[0m | time: 223.735s
[2K
| Adam | epoch: 006 | loss: 0.58059 - acc: 0.7083 -- iter: 0576/2102
[A[ATraining Step: 349  | total loss: [1m[32m0.57940[0m[0m | time: 236.921s
[2K
| Adam | epoch: 006 | loss: 0.57940 - acc: 0.7062 -- iter: 0608/2102
[A[ATraining Step: 350  | total loss: [1m[32m0.58810[0m[0m | time: 249.887s
[2K
| Adam | epoch: 006 | loss: 0.58810 - acc: 0.6981 -- iter: 0640/2102
[A[ATraining Step: 351  | total loss: [1m[32m0.57869[0m[0m | time: 262.714s
[2K
| Adam | epoch: 006 | loss: 0.57869 - acc: 0.7064 -- iter: 0672/2102
[A[ATraining Step: 352  | total loss: [1m[32m0.55840[0m[0m | time: 275.349s
[2K
| Adam | epoch: 006 | loss: 0.55840 - acc: 0.7232 -- iter: 0704/2102
[A[ATraining Step: 353  | total loss: [1m[32m0.54977[0m[0m | time: 288.322s
[2K
| Adam | epoch: 006 | loss: 0.54977 - acc: 0.7290 -- iter: 0736/2102
[A[ATraining Step: 354  | total loss: [1m[32m0.55188[0m[0m | time: 301.188s
[2K
| Adam | epoch: 006 | loss: 0.55188 - acc: 0.7280 -- iter: 0768/2102
[A[ATraining Step: 355  | total loss: [1m[32m0.55804[0m[0m | time: 313.776s
[2K
| Adam | epoch: 006 | loss: 0.55804 - acc: 0.7208 -- iter: 0800/2102
[A[ATraining Step: 356  | total loss: [1m[32m0.56220[0m[0m | time: 326.967s
[2K
| Adam | epoch: 006 | loss: 0.56220 - acc: 0.7144 -- iter: 0832/2102
[A[ATraining Step: 357  | total loss: [1m[32m0.54461[0m[0m | time: 339.789s
[2K
| Adam | epoch: 006 | loss: 0.54461 - acc: 0.7242 -- iter: 0864/2102
[A[ATraining Step: 358  | total loss: [1m[32m0.55985[0m[0m | time: 352.615s
[2K
| Adam | epoch: 006 | loss: 0.55985 - acc: 0.7143 -- iter: 0896/2102
[A[ATraining Step: 359  | total loss: [1m[32m0.53439[0m[0m | time: 365.219s
[2K
| Adam | epoch: 006 | loss: 0.53439 - acc: 0.7303 -- iter: 0928/2102
[A[ATraining Step: 360  | total loss: [1m[32m0.54561[0m[0m | time: 378.186s
[2K
| Adam | epoch: 006 | loss: 0.54561 - acc: 0.7198 -- iter: 0960/2102
[A[ATraining Step: 361  | total loss: [1m[32m0.55936[0m[0m | time: 391.494s
[2K
| Adam | epoch: 006 | loss: 0.55936 - acc: 0.7072 -- iter: 0992/2102
[A[ATraining Step: 362  | total loss: [1m[32m0.57970[0m[0m | time: 404.287s
[2K
| Adam | epoch: 006 | loss: 0.57970 - acc: 0.6990 -- iter: 1024/2102
[A[ATraining Step: 363  | total loss: [1m[32m0.56620[0m[0m | time: 421.808s
[2K
| Adam | epoch: 006 | loss: 0.56620 - acc: 0.7041 -- iter: 1056/2102
[A[ATraining Step: 364  | total loss: [1m[32m0.56391[0m[0m | time: 434.444s
[2K
| Adam | epoch: 006 | loss: 0.56391 - acc: 0.7056 -- iter: 1088/2102
[A[ATraining Step: 365  | total loss: [1m[32m0.54997[0m[0m | time: 455.935s
[2K
| Adam | epoch: 006 | loss: 0.54997 - acc: 0.7194 -- iter: 1120/2102
[A[ATraining Step: 366  | total loss: [1m[32m0.55135[0m[0m | time: 469.096s
[2K
| Adam | epoch: 006 | loss: 0.55135 - acc: 0.7099 -- iter: 1152/2102
[A[ATraining Step: 367  | total loss: [1m[32m0.55822[0m[0m | time: 482.009s
[2K
| Adam | epoch: 006 | loss: 0.55822 - acc: 0.7077 -- iter: 1184/2102
[A[ATraining Step: 368  | total loss: [1m[32m0.55781[0m[0m | time: 494.728s
[2K
| Adam | epoch: 006 | loss: 0.55781 - acc: 0.6994 -- iter: 1216/2102
[A[ATraining Step: 369  | total loss: [1m[32m0.57139[0m[0m | time: 507.672s
[2K
| Adam | epoch: 006 | loss: 0.57139 - acc: 0.6857 -- iter: 1248/2102
[A[ATraining Step: 370  | total loss: [1m[32m0.57719[0m[0m | time: 520.859s
[2K
| Adam | epoch: 006 | loss: 0.57719 - acc: 0.6859 -- iter: 1280/2102
[A[ATraining Step: 371  | total loss: [1m[32m0.59156[0m[0m | time: 534.759s
[2K
| Adam | epoch: 006 | loss: 0.59156 - acc: 0.6767 -- iter: 1312/2102
[A[ATraining Step: 372  | total loss: [1m[32m0.56966[0m[0m | time: 559.560s
[2K
| Adam | epoch: 006 | loss: 0.56966 - acc: 0.6934 -- iter: 1344/2102
[A[ATraining Step: 373  | total loss: [1m[32m0.56675[0m[0m | time: 573.749s
[2K
| Adam | epoch: 006 | loss: 0.56675 - acc: 0.6959 -- iter: 1376/2102
[A[ATraining Step: 374  | total loss: [1m[32m0.55816[0m[0m | time: 587.850s
[2K
| Adam | epoch: 006 | loss: 0.55816 - acc: 0.6982 -- iter: 1408/2102
[A[ATraining Step: 375  | total loss: [1m[32m0.54230[0m[0m | time: 600.830s
[2K
| Adam | epoch: 006 | loss: 0.54230 - acc: 0.7065 -- iter: 1440/2102
[A[ATraining Step: 376  | total loss: [1m[32m0.52051[0m[0m | time: 609.365s
[2K
| Adam | epoch: 006 | loss: 0.52051 - acc: 0.7265 -- iter: 1472/2102
[A[ATraining Step: 377  | total loss: [1m[32m0.51435[0m[0m | time: 618.226s
[2K
| Adam | epoch: 006 | loss: 0.51435 - acc: 0.7320 -- iter: 1504/2102
[A[ATraining Step: 378  | total loss: [1m[32m0.52934[0m[0m | time: 630.576s
[2K
| Adam | epoch: 006 | loss: 0.52934 - acc: 0.7244 -- iter: 1536/2102
[A[ATraining Step: 379  | total loss: [1m[32m0.55998[0m[0m | time: 644.197s
[2K
| Adam | epoch: 006 | loss: 0.55998 - acc: 0.7113 -- iter: 1568/2102
[A[ATraining Step: 380  | total loss: [1m[32m0.55792[0m[0m | time: 657.417s
[2K
| Adam | epoch: 006 | loss: 0.55792 - acc: 0.7121 -- iter: 1600/2102
[A[ATraining Step: 381  | total loss: [1m[32m0.56660[0m[0m | time: 670.405s
[2K
| Adam | epoch: 006 | loss: 0.56660 - acc: 0.7127 -- iter: 1632/2102
[A[ATraining Step: 382  | total loss: [1m[32m0.57651[0m[0m | time: 683.720s
[2K
| Adam | epoch: 006 | loss: 0.57651 - acc: 0.7040 -- iter: 1664/2102
[A[ATraining Step: 383  | total loss: [1m[32m0.57272[0m[0m | time: 696.791s
[2K
| Adam | epoch: 006 | loss: 0.57272 - acc: 0.7054 -- iter: 1696/2102
[A[ATraining Step: 384  | total loss: [1m[32m0.56119[0m[0m | time: 709.629s
[2K
| Adam | epoch: 006 | loss: 0.56119 - acc: 0.7068 -- iter: 1728/2102
[A[ATraining Step: 385  | total loss: [1m[32m0.55760[0m[0m | time: 722.401s
[2K
| Adam | epoch: 006 | loss: 0.55760 - acc: 0.7111 -- iter: 1760/2102
[A[ATraining Step: 386  | total loss: [1m[32m0.56397[0m[0m | time: 735.219s
[2K
| Adam | epoch: 006 | loss: 0.56397 - acc: 0.7150 -- iter: 1792/2102
[A[ATraining Step: 387  | total loss: [1m[32m0.55267[0m[0m | time: 748.097s
[2K
| Adam | epoch: 006 | loss: 0.55267 - acc: 0.7247 -- iter: 1824/2102
[A[ATraining Step: 388  | total loss: [1m[32m0.55275[0m[0m | time: 761.420s
[2K
| Adam | epoch: 006 | loss: 0.55275 - acc: 0.7241 -- iter: 1856/2102
[A[ATraining Step: 389  | total loss: [1m[32m0.55001[0m[0m | time: 774.609s
[2K
| Adam | epoch: 006 | loss: 0.55001 - acc: 0.7205 -- iter: 1888/2102
[A[ATraining Step: 390  | total loss: [1m[32m0.54317[0m[0m | time: 787.087s
[2K
| Adam | epoch: 006 | loss: 0.54317 - acc: 0.7203 -- iter: 1920/2102
[A[ATraining Step: 391  | total loss: [1m[32m0.54936[0m[0m | time: 800.360s
[2K
| Adam | epoch: 006 | loss: 0.54936 - acc: 0.7108 -- iter: 1952/2102
[A[ATraining Step: 392  | total loss: [1m[32m0.54110[0m[0m | time: 813.286s
[2K
| Adam | epoch: 006 | loss: 0.54110 - acc: 0.7209 -- iter: 1984/2102
[A[ATraining Step: 393  | total loss: [1m[32m0.53730[0m[0m | time: 825.715s
[2K
| Adam | epoch: 006 | loss: 0.53730 - acc: 0.7176 -- iter: 2016/2102
[A[ATraining Step: 394  | total loss: [1m[32m0.53716[0m[0m | time: 838.683s
[2K
| Adam | epoch: 006 | loss: 0.53716 - acc: 0.7146 -- iter: 2048/2102
[A[ATraining Step: 395  | total loss: [1m[32m0.53332[0m[0m | time: 858.303s
[2K
| Adam | epoch: 006 | loss: 0.53332 - acc: 0.7213 -- iter: 2080/2102
[A[ATraining Step: 396  | total loss: [1m[32m0.55028[0m[0m | time: 919.649s
[2K
| Adam | epoch: 006 | loss: 0.55028 - acc: 0.7085 | val_loss: 0.79951 - val_acc: 0.6277 -- iter: 2102/2102
--
Training Step: 397  | total loss: [1m[32m0.54412[0m[0m | time: 12.636s
[2K
| Adam | epoch: 007 | loss: 0.54412 - acc: 0.7158 -- iter: 0032/2102
[A[ATraining Step: 398  | total loss: [1m[32m0.54369[0m[0m | time: 26.045s
[2K
| Adam | epoch: 007 | loss: 0.54369 - acc: 0.7223 -- iter: 0064/2102
[A[ATraining Step: 399  | total loss: [1m[32m0.54107[0m[0m | time: 39.279s
[2K
| Adam | epoch: 007 | loss: 0.54107 - acc: 0.7313 -- iter: 0096/2102
[A[ATraining Step: 400  | total loss: [1m[32m0.54635[0m[0m | time: 101.121s
[2K
| Adam | epoch: 007 | loss: 0.54635 - acc: 0.7363 | val_loss: 0.87359 - val_acc: 0.6292 -- iter: 0128/2102
--
Training Step: 401  | total loss: [1m[32m0.54018[0m[0m | time: 110.898s
[2K
| Adam | epoch: 007 | loss: 0.54018 - acc: 0.7408 -- iter: 0160/2102
[A[ATraining Step: 402  | total loss: [1m[32m0.52871[0m[0m | time: 120.528s
[2K
| Adam | epoch: 007 | loss: 0.52871 - acc: 0.7531 -- iter: 0192/2102
[A[ATraining Step: 403  | total loss: [1m[32m0.51705[0m[0m | time: 133.629s
[2K
| Adam | epoch: 007 | loss: 0.51705 - acc: 0.7596 -- iter: 0224/2102
[A[ATraining Step: 404  | total loss: [1m[32m0.53721[0m[0m | time: 146.469s
[2K
| Adam | epoch: 007 | loss: 0.53721 - acc: 0.7368 -- iter: 0256/2102
[A[ATraining Step: 405  | total loss: [1m[32m0.53521[0m[0m | time: 159.264s
[2K
| Adam | epoch: 007 | loss: 0.53521 - acc: 0.7350 -- iter: 0288/2102
[A[ATraining Step: 406  | total loss: [1m[32m0.55742[0m[0m | time: 172.073s
[2K
| Adam | epoch: 007 | loss: 0.55742 - acc: 0.7115 -- iter: 0320/2102
[A[ATraining Step: 407  | total loss: [1m[32m0.55171[0m[0m | time: 185.073s
[2K
| Adam | epoch: 007 | loss: 0.55171 - acc: 0.7185 -- iter: 0352/2102
[A[ATraining Step: 408  | total loss: [1m[32m0.56770[0m[0m | time: 197.779s
[2K
| Adam | epoch: 007 | loss: 0.56770 - acc: 0.7091 -- iter: 0384/2102
[A[ATraining Step: 409  | total loss: [1m[32m0.55525[0m[0m | time: 210.418s
[2K
| Adam | epoch: 007 | loss: 0.55525 - acc: 0.7163 -- iter: 0416/2102
[A[ATraining Step: 410  | total loss: [1m[32m0.56635[0m[0m | time: 223.751s
[2K
| Adam | epoch: 007 | loss: 0.56635 - acc: 0.7134 -- iter: 0448/2102
[A[ATraining Step: 411  | total loss: [1m[32m0.56051[0m[0m | time: 236.652s
[2K
| Adam | epoch: 007 | loss: 0.56051 - acc: 0.7140 -- iter: 0480/2102
[A[ATraining Step: 412  | total loss: [1m[32m0.56055[0m[0m | time: 249.491s
[2K
| Adam | epoch: 007 | loss: 0.56055 - acc: 0.7145 -- iter: 0512/2102
[A[ATraining Step: 413  | total loss: [1m[32m0.55605[0m[0m | time: 262.086s
[2K
| Adam | epoch: 007 | loss: 0.55605 - acc: 0.7149 -- iter: 0544/2102
[A[ATraining Step: 414  | total loss: [1m[32m0.57048[0m[0m | time: 275.010s
[2K
| Adam | epoch: 007 | loss: 0.57048 - acc: 0.7121 -- iter: 0576/2102
[A[ATraining Step: 415  | total loss: [1m[32m0.57340[0m[0m | time: 287.992s
[2K
| Adam | epoch: 007 | loss: 0.57340 - acc: 0.7066 -- iter: 0608/2102
[A[ATraining Step: 416  | total loss: [1m[32m0.57845[0m[0m | time: 300.419s
[2K
| Adam | epoch: 007 | loss: 0.57845 - acc: 0.7078 -- iter: 0640/2102
[A[ATraining Step: 417  | total loss: [1m[32m0.57002[0m[0m | time: 313.634s
[2K
| Adam | epoch: 007 | loss: 0.57002 - acc: 0.7151 -- iter: 0672/2102
[A[ATraining Step: 418  | total loss: [1m[32m0.56178[0m[0m | time: 326.051s
[2K
| Adam | epoch: 007 | loss: 0.56178 - acc: 0.7186 -- iter: 0704/2102
[A[ATraining Step: 419  | total loss: [1m[32m0.55330[0m[0m | time: 339.158s
[2K
| Adam | epoch: 007 | loss: 0.55330 - acc: 0.7311 -- iter: 0736/2102
[A[ATraining Step: 420  | total loss: [1m[32m0.54373[0m[0m | time: 351.606s
[2K
| Adam | epoch: 007 | loss: 0.54373 - acc: 0.7393 -- iter: 0768/2102
[A[ATraining Step: 421  | total loss: [1m[32m0.53309[0m[0m | time: 364.127s
[2K
| Adam | epoch: 007 | loss: 0.53309 - acc: 0.7435 -- iter: 0800/2102
[A[ATraining Step: 422  | total loss: [1m[32m0.52798[0m[0m | time: 377.320s
[2K
| Adam | epoch: 007 | loss: 0.52798 - acc: 0.7441 -- iter: 0832/2102
[A[ATraining Step: 423  | total loss: [1m[32m0.52680[0m[0m | time: 389.967s
[2K
| Adam | epoch: 007 | loss: 0.52680 - acc: 0.7510 -- iter: 0864/2102
[A[ATraining Step: 424  | total loss: [1m[32m0.51137[0m[0m | time: 402.931s
[2K
| Adam | epoch: 007 | loss: 0.51137 - acc: 0.7540 -- iter: 0896/2102
[A[ATraining Step: 425  | total loss: [1m[32m0.51185[0m[0m | time: 415.654s
[2K
| Adam | epoch: 007 | loss: 0.51185 - acc: 0.7630 -- iter: 0928/2102
[A[ATraining Step: 426  | total loss: [1m[32m0.50339[0m[0m | time: 428.981s
[2K
| Adam | epoch: 007 | loss: 0.50339 - acc: 0.7710 -- iter: 0960/2102
[A[ATraining Step: 427  | total loss: [1m[32m0.52559[0m[0m | time: 441.954s
[2K
| Adam | epoch: 007 | loss: 0.52559 - acc: 0.7596 -- iter: 0992/2102
[A[ATraining Step: 428  | total loss: [1m[32m0.54827[0m[0m | time: 454.811s
[2K
| Adam | epoch: 007 | loss: 0.54827 - acc: 0.7492 -- iter: 1024/2102
[A[ATraining Step: 429  | total loss: [1m[32m0.56553[0m[0m | time: 467.750s
[2K
| Adam | epoch: 007 | loss: 0.56553 - acc: 0.7337 -- iter: 1056/2102
[A[ATraining Step: 430  | total loss: [1m[32m0.58142[0m[0m | time: 480.971s
[2K
| Adam | epoch: 007 | loss: 0.58142 - acc: 0.7259 -- iter: 1088/2102
[A[ATraining Step: 431  | total loss: [1m[32m0.58010[0m[0m | time: 495.688s
[2K
| Adam | epoch: 007 | loss: 0.58010 - acc: 0.7221 -- iter: 1120/2102
[A[ATraining Step: 432  | total loss: [1m[32m0.57082[0m[0m | time: 508.482s
[2K
| Adam | epoch: 007 | loss: 0.57082 - acc: 0.7280 -- iter: 1152/2102
[A[ATraining Step: 433  | total loss: [1m[32m0.56820[0m[0m | time: 521.424s
[2K
| Adam | epoch: 007 | loss: 0.56820 - acc: 0.7365 -- iter: 1184/2102
[A[ATraining Step: 434  | total loss: [1m[32m0.55537[0m[0m | time: 534.377s
[2K
| Adam | epoch: 007 | loss: 0.55537 - acc: 0.7378 -- iter: 1216/2102
[A[ATraining Step: 435  | total loss: [1m[32m0.55695[0m[0m | time: 547.088s
[2K
| Adam | epoch: 007 | loss: 0.55695 - acc: 0.7297 -- iter: 1248/2102
[A[ATraining Step: 436  | total loss: [1m[32m0.55773[0m[0m | time: 559.979s
[2K
| Adam | epoch: 007 | loss: 0.55773 - acc: 0.7254 -- iter: 1280/2102
[A[ATraining Step: 437  | total loss: [1m[32m0.57832[0m[0m | time: 573.111s
[2K
| Adam | epoch: 007 | loss: 0.57832 - acc: 0.7185 -- iter: 1312/2102
[A[ATraining Step: 438  | total loss: [1m[32m0.56419[0m[0m | time: 586.098s
[2K
| Adam | epoch: 007 | loss: 0.56419 - acc: 0.7279 -- iter: 1344/2102
[A[ATraining Step: 439  | total loss: [1m[32m0.56596[0m[0m | time: 598.803s
[2K
| Adam | epoch: 007 | loss: 0.56596 - acc: 0.7208 -- iter: 1376/2102
[A[ATraining Step: 440  | total loss: [1m[32m0.55592[0m[0m | time: 611.395s
[2K
| Adam | epoch: 007 | loss: 0.55592 - acc: 0.7331 -- iter: 1408/2102
[A[ATraining Step: 441  | total loss: [1m[32m0.55947[0m[0m | time: 624.248s
[2K
| Adam | epoch: 007 | loss: 0.55947 - acc: 0.7347 -- iter: 1440/2102
[A[ATraining Step: 442  | total loss: [1m[32m0.55272[0m[0m | time: 637.140s
[2K
| Adam | epoch: 007 | loss: 0.55272 - acc: 0.7456 -- iter: 1472/2102
[A[ATraining Step: 443  | total loss: [1m[32m0.53908[0m[0m | time: 650.248s
[2K
| Adam | epoch: 007 | loss: 0.53908 - acc: 0.7523 -- iter: 1504/2102
[A[ATraining Step: 444  | total loss: [1m[32m0.54431[0m[0m | time: 663.251s
[2K
| Adam | epoch: 007 | loss: 0.54431 - acc: 0.7396 -- iter: 1536/2102
[A[ATraining Step: 445  | total loss: [1m[32m0.54818[0m[0m | time: 676.566s
[2K
| Adam | epoch: 007 | loss: 0.54818 - acc: 0.7313 -- iter: 1568/2102
[A[ATraining Step: 446  | total loss: [1m[32m0.53858[0m[0m | time: 689.288s
[2K
| Adam | epoch: 007 | loss: 0.53858 - acc: 0.7363 -- iter: 1600/2102
[A[ATraining Step: 447  | total loss: [1m[32m0.53005[0m[0m | time: 702.341s
[2K
| Adam | epoch: 007 | loss: 0.53005 - acc: 0.7439 -- iter: 1632/2102
[A[ATraining Step: 448  | total loss: [1m[32m0.52452[0m[0m | time: 715.100s
[2K
| Adam | epoch: 007 | loss: 0.52452 - acc: 0.7476 -- iter: 1664/2102
[A[ATraining Step: 449  | total loss: [1m[32m0.52434[0m[0m | time: 728.381s
[2K
| Adam | epoch: 007 | loss: 0.52434 - acc: 0.7604 -- iter: 1696/2102
[A[ATraining Step: 450  | total loss: [1m[32m0.51752[0m[0m | time: 741.101s
[2K
| Adam | epoch: 007 | loss: 0.51752 - acc: 0.7624 -- iter: 1728/2102
[A[ATraining Step: 451  | total loss: [1m[32m0.52056[0m[0m | time: 753.731s
[2K
| Adam | epoch: 007 | loss: 0.52056 - acc: 0.7675 -- iter: 1760/2102
[A[ATraining Step: 452  | total loss: [1m[32m0.50982[0m[0m | time: 766.638s
[2K
| Adam | epoch: 007 | loss: 0.50982 - acc: 0.7720 -- iter: 1792/2102
[A[ATraining Step: 453  | total loss: [1m[32m0.51987[0m[0m | time: 779.295s
[2K
| Adam | epoch: 007 | loss: 0.51987 - acc: 0.7666 -- iter: 1824/2102
[A[ATraining Step: 454  | total loss: [1m[32m0.52452[0m[0m | time: 792.198s
[2K
| Adam | epoch: 007 | loss: 0.52452 - acc: 0.7587 -- iter: 1856/2102
[A[ATraining Step: 455  | total loss: [1m[32m0.50746[0m[0m | time: 805.380s
[2K
| Adam | epoch: 007 | loss: 0.50746 - acc: 0.7641 -- iter: 1888/2102
[A[ATraining Step: 456  | total loss: [1m[32m0.49802[0m[0m | time: 818.360s
[2K
| Adam | epoch: 007 | loss: 0.49802 - acc: 0.7658 -- iter: 1920/2102
[A[ATraining Step: 457  | total loss: [1m[32m0.50654[0m[0m | time: 831.363s
[2K
| Adam | epoch: 007 | loss: 0.50654 - acc: 0.7580 -- iter: 1952/2102
[A[ATraining Step: 458  | total loss: [1m[32m0.49920[0m[0m | time: 844.152s
[2K
| Adam | epoch: 007 | loss: 0.49920 - acc: 0.7572 -- iter: 1984/2102
[A[ATraining Step: 459  | total loss: [1m[32m0.50031[0m[0m | time: 856.781s
[2K
| Adam | epoch: 007 | loss: 0.50031 - acc: 0.7533 -- iter: 2016/2102
[A[ATraining Step: 460  | total loss: [1m[32m0.48999[0m[0m | time: 869.510s
[2K
| Adam | epoch: 007 | loss: 0.48999 - acc: 0.7561 -- iter: 2048/2102
[A[ATraining Step: 461  | total loss: [1m[32m0.48539[0m[0m | time: 882.243s
[2K
| Adam | epoch: 007 | loss: 0.48539 - acc: 0.7586 -- iter: 2080/2102
[A[ATraining Step: 462  | total loss: [1m[32m0.48666[0m[0m | time: 947.433s
[2K
| Adam | epoch: 007 | loss: 0.48666 - acc: 0.7547 | val_loss: 1.06134 - val_acc: 0.6292 -- iter: 2102/2102
--
Training Step: 463  | total loss: [1m[32m0.48462[0m[0m | time: 8.633s
[2K
| Adam | epoch: 008 | loss: 0.48462 - acc: 0.7604 -- iter: 0032/2102
[A[ATraining Step: 464  | total loss: [1m[32m0.48252[0m[0m | time: 17.218s
[2K
| Adam | epoch: 008 | loss: 0.48252 - acc: 0.7594 -- iter: 0064/2102
[A[ATraining Step: 465  | total loss: [1m[32m0.48816[0m[0m | time: 25.890s
[2K
| Adam | epoch: 008 | loss: 0.48816 - acc: 0.7616 -- iter: 0096/2102
[A[ATraining Step: 466  | total loss: [1m[32m0.49679[0m[0m | time: 39.077s
[2K
| Adam | epoch: 008 | loss: 0.49679 - acc: 0.7573 -- iter: 0128/2102
[A[ATraining Step: 467  | total loss: [1m[32m0.49353[0m[0m | time: 51.842s
[2K
| Adam | epoch: 008 | loss: 0.49353 - acc: 0.7597 -- iter: 0160/2102
[A[ATraining Step: 468  | total loss: [1m[32m0.49355[0m[0m | time: 61.216s
[2K
| Adam | epoch: 008 | loss: 0.49355 - acc: 0.7556 -- iter: 0192/2102
[A[ATraining Step: 469  | total loss: [1m[32m0.49532[0m[0m | time: 70.562s
[2K
| Adam | epoch: 008 | loss: 0.49532 - acc: 0.7573 -- iter: 0224/2102
[A[ATraining Step: 470  | total loss: [1m[32m0.48642[0m[0m | time: 82.780s
[2K
| Adam | epoch: 008 | loss: 0.48642 - acc: 0.7679 -- iter: 0256/2102
[A[ATraining Step: 471  | total loss: [1m[32m0.49794[0m[0m | time: 95.066s
[2K
| Adam | epoch: 008 | loss: 0.49794 - acc: 0.7630 -- iter: 0288/2102
[A[ATraining Step: 472  | total loss: [1m[32m0.52380[0m[0m | time: 107.623s
[2K
| Adam | epoch: 008 | loss: 0.52380 - acc: 0.7523 -- iter: 0320/2102
[A[ATraining Step: 473  | total loss: [1m[32m0.54624[0m[0m | time: 120.015s
[2K
| Adam | epoch: 008 | loss: 0.54624 - acc: 0.7365 -- iter: 0352/2102
[A[ATraining Step: 474  | total loss: [1m[32m0.54768[0m[0m | time: 132.500s
[2K
| Adam | epoch: 008 | loss: 0.54768 - acc: 0.7316 -- iter: 0384/2102
[A[ATraining Step: 475  | total loss: [1m[32m0.53303[0m[0m | time: 145.290s
[2K
| Adam | epoch: 008 | loss: 0.53303 - acc: 0.7428 -- iter: 0416/2102
[A[ATraining Step: 476  | total loss: [1m[32m0.52656[0m[0m | time: 158.236s
[2K
| Adam | epoch: 008 | loss: 0.52656 - acc: 0.7435 -- iter: 0448/2102
[A[ATraining Step: 477  | total loss: [1m[32m0.53555[0m[0m | time: 170.875s
[2K
| Adam | epoch: 008 | loss: 0.53555 - acc: 0.7442 -- iter: 0480/2102
[A[ATraining Step: 478  | total loss: [1m[32m0.52278[0m[0m | time: 183.572s
[2K
| Adam | epoch: 008 | loss: 0.52278 - acc: 0.7510 -- iter: 0512/2102
[A[ATraining Step: 479  | total loss: [1m[32m0.51213[0m[0m | time: 196.048s
[2K
| Adam | epoch: 008 | loss: 0.51213 - acc: 0.7540 -- iter: 0544/2102
[A[ATraining Step: 480  | total loss: [1m[32m0.50044[0m[0m | time: 208.895s
[2K
| Adam | epoch: 008 | loss: 0.50044 - acc: 0.7630 -- iter: 0576/2102
[A[ATraining Step: 481  | total loss: [1m[32m0.51229[0m[0m | time: 221.178s
[2K
| Adam | epoch: 008 | loss: 0.51229 - acc: 0.7461 -- iter: 0608/2102
[A[ATraining Step: 482  | total loss: [1m[32m0.49249[0m[0m | time: 232.877s
[2K
| Adam | epoch: 008 | loss: 0.49249 - acc: 0.7590 -- iter: 0640/2102
[A[ATraining Step: 483  | total loss: [1m[32m0.47948[0m[0m | time: 247.242s
[2K
| Adam | epoch: 008 | loss: 0.47948 - acc: 0.7706 -- iter: 0672/2102
[A[ATraining Step: 484  | total loss: [1m[32m0.48988[0m[0m | time: 261.746s
[2K
| Adam | epoch: 008 | loss: 0.48988 - acc: 0.7623 -- iter: 0704/2102
[A[ATraining Step: 485  | total loss: [1m[32m0.49192[0m[0m | time: 276.080s
[2K
| Adam | epoch: 008 | loss: 0.49192 - acc: 0.7517 -- iter: 0736/2102
[A[ATraining Step: 486  | total loss: [1m[32m0.48688[0m[0m | time: 290.905s
[2K
| Adam | epoch: 008 | loss: 0.48688 - acc: 0.7546 -- iter: 0768/2102
[A[ATraining Step: 487  | total loss: [1m[32m0.49376[0m[0m | time: 304.646s
[2K
| Adam | epoch: 008 | loss: 0.49376 - acc: 0.7510 -- iter: 0800/2102
[A[ATraining Step: 488  | total loss: [1m[32m0.47595[0m[0m | time: 313.631s
[2K
| Adam | epoch: 008 | loss: 0.47595 - acc: 0.7634 -- iter: 0832/2102
[A[ATraining Step: 489  | total loss: [1m[32m0.47624[0m[0m | time: 325.822s
[2K
| Adam | epoch: 008 | loss: 0.47624 - acc: 0.7621 -- iter: 0864/2102
[A[ATraining Step: 490  | total loss: [1m[32m0.49883[0m[0m | time: 338.536s
[2K
| Adam | epoch: 008 | loss: 0.49883 - acc: 0.7578 -- iter: 0896/2102
[A[ATraining Step: 491  | total loss: [1m[32m0.48960[0m[0m | time: 351.737s
[2K
| Adam | epoch: 008 | loss: 0.48960 - acc: 0.7664 -- iter: 0928/2102
[A[ATraining Step: 492  | total loss: [1m[32m0.49920[0m[0m | time: 364.467s
[2K
| Adam | epoch: 008 | loss: 0.49920 - acc: 0.7553 -- iter: 0960/2102
[A[ATraining Step: 493  | total loss: [1m[32m0.49512[0m[0m | time: 376.905s
[2K
| Adam | epoch: 008 | loss: 0.49512 - acc: 0.7579 -- iter: 0992/2102
[A[ATraining Step: 494  | total loss: [1m[32m0.49347[0m[0m | time: 389.670s
[2K
| Adam | epoch: 008 | loss: 0.49347 - acc: 0.7571 -- iter: 1024/2102
[A[ATraining Step: 495  | total loss: [1m[32m0.49376[0m[0m | time: 402.376s
[2K
| Adam | epoch: 008 | loss: 0.49376 - acc: 0.7596 -- iter: 1056/2102
[A[ATraining Step: 496  | total loss: [1m[32m0.49843[0m[0m | time: 414.950s
[2K
| Adam | epoch: 008 | loss: 0.49843 - acc: 0.7492 -- iter: 1088/2102
[A[ATraining Step: 497  | total loss: [1m[32m0.48822[0m[0m | time: 427.210s
[2K
| Adam | epoch: 008 | loss: 0.48822 - acc: 0.7555 -- iter: 1120/2102
[A[ATraining Step: 498  | total loss: [1m[32m0.48318[0m[0m | time: 440.069s
[2K
| Adam | epoch: 008 | loss: 0.48318 - acc: 0.7581 -- iter: 1152/2102
[A[ATraining Step: 499  | total loss: [1m[32m0.48616[0m[0m | time: 452.584s
[2K
| Adam | epoch: 008 | loss: 0.48616 - acc: 0.7542 -- iter: 1184/2102
[A[ATraining Step: 500  | total loss: [1m[32m0.47162[0m[0m | time: 465.446s
[2K
| Adam | epoch: 008 | loss: 0.47162 - acc: 0.7600 -- iter: 1216/2102
[A[ATraining Step: 501  | total loss: [1m[32m0.47745[0m[0m | time: 478.598s
[2K
| Adam | epoch: 008 | loss: 0.47745 - acc: 0.7559 -- iter: 1248/2102
[A[ATraining Step: 502  | total loss: [1m[32m0.47472[0m[0m | time: 490.944s
[2K
| Adam | epoch: 008 | loss: 0.47472 - acc: 0.7647 -- iter: 1280/2102
[A[ATraining Step: 503  | total loss: [1m[32m0.47058[0m[0m | time: 504.090s
[2K
| Adam | epoch: 008 | loss: 0.47058 - acc: 0.7663 -- iter: 1312/2102
[A[ATraining Step: 504  | total loss: [1m[32m0.47883[0m[0m | time: 516.978s
[2K
| Adam | epoch: 008 | loss: 0.47883 - acc: 0.7616 -- iter: 1344/2102
[A[ATraining Step: 505  | total loss: [1m[32m0.46789[0m[0m | time: 529.442s
[2K
| Adam | epoch: 008 | loss: 0.46789 - acc: 0.7760 -- iter: 1376/2102
[A[ATraining Step: 506  | total loss: [1m[32m0.48769[0m[0m | time: 542.100s
[2K
| Adam | epoch: 008 | loss: 0.48769 - acc: 0.7672 -- iter: 1408/2102
[A[ATraining Step: 507  | total loss: [1m[32m0.47610[0m[0m | time: 554.930s
[2K
| Adam | epoch: 008 | loss: 0.47610 - acc: 0.7780 -- iter: 1440/2102
[A[ATraining Step: 508  | total loss: [1m[32m0.48778[0m[0m | time: 568.057s
[2K
| Adam | epoch: 008 | loss: 0.48778 - acc: 0.7689 -- iter: 1472/2102
[A[ATraining Step: 509  | total loss: [1m[32m0.47052[0m[0m | time: 580.263s
[2K
| Adam | epoch: 008 | loss: 0.47052 - acc: 0.7795 -- iter: 1504/2102
[A[ATraining Step: 510  | total loss: [1m[32m0.46528[0m[0m | time: 592.885s
[2K
| Adam | epoch: 008 | loss: 0.46528 - acc: 0.7828 -- iter: 1536/2102
[A[ATraining Step: 511  | total loss: [1m[32m0.45864[0m[0m | time: 605.512s
[2K
| Adam | epoch: 008 | loss: 0.45864 - acc: 0.7827 -- iter: 1568/2102
[A[ATraining Step: 512  | total loss: [1m[32m0.46193[0m[0m | time: 618.016s
[2K
| Adam | epoch: 008 | loss: 0.46193 - acc: 0.7794 -- iter: 1600/2102
[A[ATraining Step: 513  | total loss: [1m[32m0.45595[0m[0m | time: 630.846s
[2K
| Adam | epoch: 008 | loss: 0.45595 - acc: 0.7890 -- iter: 1632/2102
[A[ATraining Step: 514  | total loss: [1m[32m0.45607[0m[0m | time: 643.490s
[2K
| Adam | epoch: 008 | loss: 0.45607 - acc: 0.7882 -- iter: 1664/2102
[A[ATraining Step: 515  | total loss: [1m[32m0.44668[0m[0m | time: 656.468s
[2K
| Adam | epoch: 008 | loss: 0.44668 - acc: 0.7969 -- iter: 1696/2102
[A[ATraining Step: 516  | total loss: [1m[32m0.44975[0m[0m | time: 669.230s
[2K
| Adam | epoch: 008 | loss: 0.44975 - acc: 0.7922 -- iter: 1728/2102
[A[ATraining Step: 517  | total loss: [1m[32m0.43581[0m[0m | time: 682.233s
[2K
| Adam | epoch: 008 | loss: 0.43581 - acc: 0.8036 -- iter: 1760/2102
[A[ATraining Step: 518  | total loss: [1m[32m0.44856[0m[0m | time: 694.582s
[2K
| Adam | epoch: 008 | loss: 0.44856 - acc: 0.7951 -- iter: 1792/2102
[A[ATraining Step: 519  | total loss: [1m[32m0.45136[0m[0m | time: 707.384s
[2K
| Adam | epoch: 008 | loss: 0.45136 - acc: 0.7875 -- iter: 1824/2102
[A[ATraining Step: 520  | total loss: [1m[32m0.44575[0m[0m | time: 719.930s
[2K
| Adam | epoch: 008 | loss: 0.44575 - acc: 0.7900 -- iter: 1856/2102
[A[ATraining Step: 521  | total loss: [1m[32m0.44095[0m[0m | time: 732.602s
[2K
| Adam | epoch: 008 | loss: 0.44095 - acc: 0.7954 -- iter: 1888/2102
[A[ATraining Step: 522  | total loss: [1m[32m0.44125[0m[0m | time: 745.288s
[2K
| Adam | epoch: 008 | loss: 0.44125 - acc: 0.7971 -- iter: 1920/2102
[A[ATraining Step: 523  | total loss: [1m[32m0.44482[0m[0m | time: 757.843s
[2K
| Adam | epoch: 008 | loss: 0.44482 - acc: 0.7892 -- iter: 1952/2102
[A[ATraining Step: 524  | total loss: [1m[32m0.44690[0m[0m | time: 770.436s
[2K
| Adam | epoch: 008 | loss: 0.44690 - acc: 0.7884 -- iter: 1984/2102
[A[ATraining Step: 525  | total loss: [1m[32m0.45683[0m[0m | time: 783.348s
[2K
| Adam | epoch: 008 | loss: 0.45683 - acc: 0.7783 -- iter: 2016/2102
[A[ATraining Step: 526  | total loss: [1m[32m0.46210[0m[0m | time: 796.224s
[2K
| Adam | epoch: 008 | loss: 0.46210 - acc: 0.7880 -- iter: 2048/2102
[A[ATraining Step: 527  | total loss: [1m[32m0.47124[0m[0m | time: 809.386s
[2K
| Adam | epoch: 008 | loss: 0.47124 - acc: 0.7905 -- iter: 2080/2102
[A[ATraining Step: 528  | total loss: [1m[32m0.47387[0m[0m | time: 869.798s
[2K
| Adam | epoch: 008 | loss: 0.47387 - acc: 0.7864 | val_loss: 0.70925 - val_acc: 0.6413 -- iter: 2102/2102
--
Training Step: 529  | total loss: [1m[32m0.48244[0m[0m | time: 13.103s
[2K
| Adam | epoch: 009 | loss: 0.48244 - acc: 0.7796 -- iter: 0032/2102
[A[ATraining Step: 530  | total loss: [1m[32m0.48323[0m[0m | time: 25.615s
[2K
| Adam | epoch: 009 | loss: 0.48323 - acc: 0.7673 -- iter: 0064/2102
[A[ATraining Step: 531  | total loss: [1m[32m0.47559[0m[0m | time: 38.330s
[2K
| Adam | epoch: 009 | loss: 0.47559 - acc: 0.7718 -- iter: 0096/2102
[A[ATraining Step: 532  | total loss: [1m[32m0.47170[0m[0m | time: 50.804s
[2K
| Adam | epoch: 009 | loss: 0.47170 - acc: 0.7728 -- iter: 0128/2102
[A[ATraining Step: 533  | total loss: [1m[32m0.47760[0m[0m | time: 63.422s
[2K
| Adam | epoch: 009 | loss: 0.47760 - acc: 0.7705 -- iter: 0160/2102
[A[ATraining Step: 534  | total loss: [1m[32m0.47806[0m[0m | time: 76.139s
[2K
| Adam | epoch: 009 | loss: 0.47806 - acc: 0.7653 -- iter: 0192/2102
[A[ATraining Step: 535  | total loss: [1m[32m0.46729[0m[0m | time: 84.985s
[2K
| Adam | epoch: 009 | loss: 0.46729 - acc: 0.7732 -- iter: 0224/2102
[A[ATraining Step: 536  | total loss: [1m[32m0.46769[0m[0m | time: 94.234s
[2K
| Adam | epoch: 009 | loss: 0.46769 - acc: 0.7731 -- iter: 0256/2102
[A[ATraining Step: 537  | total loss: [1m[32m0.45792[0m[0m | time: 106.877s
[2K
| Adam | epoch: 009 | loss: 0.45792 - acc: 0.7822 -- iter: 0288/2102
[A[ATraining Step: 538  | total loss: [1m[32m0.47565[0m[0m | time: 119.449s
[2K
| Adam | epoch: 009 | loss: 0.47565 - acc: 0.7821 -- iter: 0320/2102
[A[ATraining Step: 539  | total loss: [1m[32m0.47735[0m[0m | time: 132.199s
[2K
| Adam | epoch: 009 | loss: 0.47735 - acc: 0.7757 -- iter: 0352/2102
[A[ATraining Step: 540  | total loss: [1m[32m0.46937[0m[0m | time: 144.983s
[2K
| Adam | epoch: 009 | loss: 0.46937 - acc: 0.7825 -- iter: 0384/2102
[A[ATraining Step: 541  | total loss: [1m[32m0.48088[0m[0m | time: 157.974s
[2K
| Adam | epoch: 009 | loss: 0.48088 - acc: 0.7699 -- iter: 0416/2102
[A[ATraining Step: 542  | total loss: [1m[32m0.46562[0m[0m | time: 170.910s
[2K
| Adam | epoch: 009 | loss: 0.46562 - acc: 0.7804 -- iter: 0448/2102
[A[ATraining Step: 543  | total loss: [1m[32m0.45165[0m[0m | time: 183.648s
[2K
| Adam | epoch: 009 | loss: 0.45165 - acc: 0.7961 -- iter: 0480/2102
[A[ATraining Step: 544  | total loss: [1m[32m0.46189[0m[0m | time: 196.547s
[2K
| Adam | epoch: 009 | loss: 0.46189 - acc: 0.7853 -- iter: 0512/2102
[A[ATraining Step: 545  | total loss: [1m[32m0.47178[0m[0m | time: 209.202s
[2K
| Adam | epoch: 009 | loss: 0.47178 - acc: 0.7786 -- iter: 0544/2102
[A[ATraining Step: 546  | total loss: [1m[32m0.46491[0m[0m | time: 222.371s
[2K
| Adam | epoch: 009 | loss: 0.46491 - acc: 0.7820 -- iter: 0576/2102
[A[ATraining Step: 547  | total loss: [1m[32m0.47678[0m[0m | time: 235.175s
[2K
| Adam | epoch: 009 | loss: 0.47678 - acc: 0.7819 -- iter: 0608/2102
[A[ATraining Step: 548  | total loss: [1m[32m0.46284[0m[0m | time: 247.985s
[2K
| Adam | epoch: 009 | loss: 0.46284 - acc: 0.7881 -- iter: 0640/2102
[A[ATraining Step: 549  | total loss: [1m[32m0.46903[0m[0m | time: 260.468s
[2K
| Adam | epoch: 009 | loss: 0.46903 - acc: 0.7812 -- iter: 0672/2102
[A[ATraining Step: 550  | total loss: [1m[32m0.46117[0m[0m | time: 272.678s
[2K
| Adam | epoch: 009 | loss: 0.46117 - acc: 0.7843 -- iter: 0704/2102
[A[ATraining Step: 551  | total loss: [1m[32m0.45566[0m[0m | time: 285.287s
[2K
| Adam | epoch: 009 | loss: 0.45566 - acc: 0.7840 -- iter: 0736/2102
[A[ATraining Step: 552  | total loss: [1m[32m0.45669[0m[0m | time: 297.907s
[2K
| Adam | epoch: 009 | loss: 0.45669 - acc: 0.7775 -- iter: 0768/2102
[A[ATraining Step: 553  | total loss: [1m[32m0.46739[0m[0m | time: 310.499s
[2K
| Adam | epoch: 009 | loss: 0.46739 - acc: 0.7685 -- iter: 0800/2102
[A[ATraining Step: 554  | total loss: [1m[32m0.46364[0m[0m | time: 322.940s
[2K
| Adam | epoch: 009 | loss: 0.46364 - acc: 0.7760 -- iter: 0832/2102
[A[ATraining Step: 555  | total loss: [1m[32m0.45988[0m[0m | time: 335.195s
[2K
| Adam | epoch: 009 | loss: 0.45988 - acc: 0.7734 -- iter: 0864/2102
[A[ATraining Step: 556  | total loss: [1m[32m0.47482[0m[0m | time: 348.166s
[2K
| Adam | epoch: 009 | loss: 0.47482 - acc: 0.7679 -- iter: 0896/2102
[A[ATraining Step: 557  | total loss: [1m[32m0.47666[0m[0m | time: 360.946s
[2K
| Adam | epoch: 009 | loss: 0.47666 - acc: 0.7661 -- iter: 0928/2102
[A[ATraining Step: 558  | total loss: [1m[32m0.48420[0m[0m | time: 374.101s
[2K
| Adam | epoch: 009 | loss: 0.48420 - acc: 0.7645 -- iter: 0960/2102
[A[ATraining Step: 559  | total loss: [1m[32m0.48420[0m[0m | time: 386.938s
[2K
| Adam | epoch: 009 | loss: 0.48420 - acc: 0.7631 -- iter: 0992/2102
[A[ATraining Step: 560  | total loss: [1m[32m0.46681[0m[0m | time: 399.665s
[2K
| Adam | epoch: 009 | loss: 0.46681 - acc: 0.7805 -- iter: 1024/2102
[A[ATraining Step: 561  | total loss: [1m[32m0.45772[0m[0m | time: 412.545s
[2K
| Adam | epoch: 009 | loss: 0.45772 - acc: 0.7806 -- iter: 1056/2102
[A[ATraining Step: 562  | total loss: [1m[32m0.45709[0m[0m | time: 425.048s
[2K
| Adam | epoch: 009 | loss: 0.45709 - acc: 0.7744 -- iter: 1088/2102
[A[ATraining Step: 563  | total loss: [1m[32m0.44649[0m[0m | time: 438.020s
[2K
| Adam | epoch: 009 | loss: 0.44649 - acc: 0.7813 -- iter: 1120/2102
[A[ATraining Step: 564  | total loss: [1m[32m0.45710[0m[0m | time: 451.267s
[2K
| Adam | epoch: 009 | loss: 0.45710 - acc: 0.7782 -- iter: 1152/2102
[A[ATraining Step: 565  | total loss: [1m[32m0.46116[0m[0m | time: 465.248s
[2K
| Adam | epoch: 009 | loss: 0.46116 - acc: 0.7691 -- iter: 1184/2102
[A[ATraining Step: 566  | total loss: [1m[32m0.47127[0m[0m | time: 478.974s
[2K
| Adam | epoch: 009 | loss: 0.47127 - acc: 0.7703 -- iter: 1216/2102
[A[ATraining Step: 567  | total loss: [1m[32m0.47733[0m[0m | time: 492.848s
[2K
| Adam | epoch: 009 | loss: 0.47733 - acc: 0.7621 -- iter: 1248/2102
[A[ATraining Step: 568  | total loss: [1m[32m0.47377[0m[0m | time: 505.728s
[2K
| Adam | epoch: 009 | loss: 0.47377 - acc: 0.7640 -- iter: 1280/2102
[A[ATraining Step: 569  | total loss: [1m[32m0.46679[0m[0m | time: 514.297s
[2K
| Adam | epoch: 009 | loss: 0.46679 - acc: 0.7688 -- iter: 1312/2102
[A[ATraining Step: 570  | total loss: [1m[32m0.47824[0m[0m | time: 522.769s
[2K
| Adam | epoch: 009 | loss: 0.47824 - acc: 0.7701 -- iter: 1344/2102
[A[ATraining Step: 571  | total loss: [1m[32m0.46857[0m[0m | time: 533.944s
[2K
| Adam | epoch: 009 | loss: 0.46857 - acc: 0.7743 -- iter: 1376/2102
[A[ATraining Step: 572  | total loss: [1m[32m0.44847[0m[0m | time: 546.594s
[2K
| Adam | epoch: 009 | loss: 0.44847 - acc: 0.7875 -- iter: 1408/2102
[A[ATraining Step: 573  | total loss: [1m[32m0.43984[0m[0m | time: 559.344s
[2K
| Adam | epoch: 009 | loss: 0.43984 - acc: 0.7900 -- iter: 1440/2102
[A[ATraining Step: 574  | total loss: [1m[32m0.43354[0m[0m | time: 571.853s
[2K
| Adam | epoch: 009 | loss: 0.43354 - acc: 0.7860 -- iter: 1472/2102
[A[ATraining Step: 575  | total loss: [1m[32m0.43668[0m[0m | time: 584.716s
[2K
| Adam | epoch: 009 | loss: 0.43668 - acc: 0.7855 -- iter: 1504/2102
[A[ATraining Step: 576  | total loss: [1m[32m0.45306[0m[0m | time: 597.994s
[2K
| Adam | epoch: 009 | loss: 0.45306 - acc: 0.7757 -- iter: 1536/2102
[A[ATraining Step: 577  | total loss: [1m[32m0.43663[0m[0m | time: 610.971s
[2K
| Adam | epoch: 009 | loss: 0.43663 - acc: 0.7857 -- iter: 1568/2102
[A[ATraining Step: 578  | total loss: [1m[32m0.43006[0m[0m | time: 624.076s
[2K
| Adam | epoch: 009 | loss: 0.43006 - acc: 0.7915 -- iter: 1600/2102
[A[ATraining Step: 579  | total loss: [1m[32m0.42447[0m[0m | time: 637.310s
[2K
| Adam | epoch: 009 | loss: 0.42447 - acc: 0.7967 -- iter: 1632/2102
[A[ATraining Step: 580  | total loss: [1m[32m0.43198[0m[0m | time: 650.343s
[2K
| Adam | epoch: 009 | loss: 0.43198 - acc: 0.7952 -- iter: 1664/2102
[A[ATraining Step: 581  | total loss: [1m[32m0.43276[0m[0m | time: 663.228s
[2K
| Adam | epoch: 009 | loss: 0.43276 - acc: 0.7906 -- iter: 1696/2102
[A[ATraining Step: 582  | total loss: [1m[32m0.41714[0m[0m | time: 676.286s
[2K
| Adam | epoch: 009 | loss: 0.41714 - acc: 0.7991 -- iter: 1728/2102
[A[ATraining Step: 583  | total loss: [1m[32m0.40259[0m[0m | time: 689.158s
[2K
| Adam | epoch: 009 | loss: 0.40259 - acc: 0.8067 -- iter: 1760/2102
[A[ATraining Step: 584  | total loss: [1m[32m0.39193[0m[0m | time: 701.945s
[2K
| Adam | epoch: 009 | loss: 0.39193 - acc: 0.8135 -- iter: 1792/2102
[A[ATraining Step: 585  | total loss: [1m[32m0.39015[0m[0m | time: 714.967s
[2K
| Adam | epoch: 009 | loss: 0.39015 - acc: 0.8165 -- iter: 1824/2102
[A[ATraining Step: 586  | total loss: [1m[32m0.37820[0m[0m | time: 727.818s
[2K
| Adam | epoch: 009 | loss: 0.37820 - acc: 0.8224 -- iter: 1856/2102
[A[ATraining Step: 587  | total loss: [1m[32m0.38966[0m[0m | time: 740.499s
[2K
| Adam | epoch: 009 | loss: 0.38966 - acc: 0.8214 -- iter: 1888/2102
[A[ATraining Step: 588  | total loss: [1m[32m0.38284[0m[0m | time: 753.111s
[2K
| Adam | epoch: 009 | loss: 0.38284 - acc: 0.8236 -- iter: 1920/2102
[A[ATraining Step: 589  | total loss: [1m[32m0.39679[0m[0m | time: 765.818s
[2K
| Adam | epoch: 009 | loss: 0.39679 - acc: 0.8225 -- iter: 1952/2102
[A[ATraining Step: 590  | total loss: [1m[32m0.39241[0m[0m | time: 778.846s
[2K
| Adam | epoch: 009 | loss: 0.39241 - acc: 0.8309 -- iter: 1984/2102
[A[ATraining Step: 591  | total loss: [1m[32m0.39646[0m[0m | time: 791.143s
[2K
| Adam | epoch: 009 | loss: 0.39646 - acc: 0.8228 -- iter: 2016/2102
[A[ATraining Step: 592  | total loss: [1m[32m0.40769[0m[0m | time: 803.762s
[2K
| Adam | epoch: 009 | loss: 0.40769 - acc: 0.8186 -- iter: 2048/2102
[A[ATraining Step: 593  | total loss: [1m[32m0.38656[0m[0m | time: 816.928s
[2K
| Adam | epoch: 009 | loss: 0.38656 - acc: 0.8305 -- iter: 2080/2102
[A[ATraining Step: 594  | total loss: [1m[32m0.38674[0m[0m | time: 877.453s
[2K
| Adam | epoch: 009 | loss: 0.38674 - acc: 0.8287 | val_loss: 0.74299 - val_acc: 0.6687 -- iter: 2102/2102
--
Training Step: 595  | total loss: [1m[32m0.38439[0m[0m | time: 13.074s
[2K
| Adam | epoch: 010 | loss: 0.38439 - acc: 0.8271 -- iter: 0032/2102
[A[ATraining Step: 596  | total loss: [1m[32m0.39394[0m[0m | time: 25.845s
[2K
| Adam | epoch: 010 | loss: 0.39394 - acc: 0.8163 -- iter: 0064/2102
[A[ATraining Step: 597  | total loss: [1m[32m0.40263[0m[0m | time: 38.891s
[2K
| Adam | epoch: 010 | loss: 0.40263 - acc: 0.8190 -- iter: 0096/2102
[A[ATraining Step: 598  | total loss: [1m[32m0.40666[0m[0m | time: 51.394s
[2K
| Adam | epoch: 010 | loss: 0.40666 - acc: 0.8184 -- iter: 0128/2102
[A[ATraining Step: 599  | total loss: [1m[32m0.41906[0m[0m | time: 64.370s
[2K
| Adam | epoch: 010 | loss: 0.41906 - acc: 0.8178 -- iter: 0160/2102
[A[ATraining Step: 600  | total loss: [1m[32m0.43786[0m[0m | time: 124.405s
[2K
| Adam | epoch: 010 | loss: 0.43786 - acc: 0.8172 | val_loss: 0.72144 - val_acc: 0.6687 -- iter: 0192/2102
--
Training Step: 601  | total loss: [1m[32m0.44144[0m[0m | time: 137.003s
[2K
| Adam | epoch: 010 | loss: 0.44144 - acc: 0.8199 -- iter: 0224/2102
[A[ATraining Step: 602  | total loss: [1m[32m0.45697[0m[0m | time: 145.930s
[2K
| Adam | epoch: 010 | loss: 0.45697 - acc: 0.8067 -- iter: 0256/2102
[A[ATraining Step: 603  | total loss: [1m[32m0.46308[0m[0m | time: 155.614s
[2K
| Adam | epoch: 010 | loss: 0.46308 - acc: 0.8033 -- iter: 0288/2102
[A[ATraining Step: 604  | total loss: [1m[32m0.45666[0m[0m | time: 168.244s
[2K
| Adam | epoch: 010 | loss: 0.45666 - acc: 0.8093 -- iter: 0320/2102
[A[ATraining Step: 605  | total loss: [1m[32m0.44262[0m[0m | time: 181.381s
[2K
| Adam | epoch: 010 | loss: 0.44262 - acc: 0.8190 -- iter: 0352/2102
[A[ATraining Step: 606  | total loss: [1m[32m0.44641[0m[0m | time: 194.006s
[2K
| Adam | epoch: 010 | loss: 0.44641 - acc: 0.8152 -- iter: 0384/2102
[A[ATraining Step: 607  | total loss: [1m[32m0.43181[0m[0m | time: 206.738s
[2K
| Adam | epoch: 010 | loss: 0.43181 - acc: 0.8243 -- iter: 0416/2102
[A[ATraining Step: 608  | total loss: [1m[32m0.44980[0m[0m | time: 219.070s
[2K
| Adam | epoch: 010 | loss: 0.44980 - acc: 0.8106 -- iter: 0448/2102
[A[ATraining Step: 609  | total loss: [1m[32m0.46263[0m[0m | time: 231.676s
[2K
| Adam | epoch: 010 | loss: 0.46263 - acc: 0.8015 -- iter: 0480/2102
[A[ATraining Step: 610  | total loss: [1m[32m0.45494[0m[0m | time: 244.696s
[2K
| Adam | epoch: 010 | loss: 0.45494 - acc: 0.8026 -- iter: 0512/2102
[A[ATraining Step: 611  | total loss: [1m[32m0.47208[0m[0m | time: 257.883s
[2K
| Adam | epoch: 010 | loss: 0.47208 - acc: 0.7942 -- iter: 0544/2102
[A[ATraining Step: 612  | total loss: [1m[32m0.46277[0m[0m | time: 270.838s
[2K
| Adam | epoch: 010 | loss: 0.46277 - acc: 0.8054 -- iter: 0576/2102
[A[ATraining Step: 613  | total loss: [1m[32m0.46879[0m[0m | time: 283.747s
[2K
| Adam | epoch: 010 | loss: 0.46879 - acc: 0.8030 -- iter: 0608/2102
[A[ATraining Step: 614  | total loss: [1m[32m0.47218[0m[0m | time: 296.674s
[2K
| Adam | epoch: 010 | loss: 0.47218 - acc: 0.7945 -- iter: 0640/2102
[A[ATraining Step: 615  | total loss: [1m[32m0.46952[0m[0m | time: 309.788s
[2K
| Adam | epoch: 010 | loss: 0.46952 - acc: 0.7932 -- iter: 0672/2102
[A[ATraining Step: 616  | total loss: [1m[32m0.47470[0m[0m | time: 322.398s
[2K
| Adam | epoch: 010 | loss: 0.47470 - acc: 0.7889 -- iter: 0704/2102
[A[ATraining Step: 617  | total loss: [1m[32m0.47884[0m[0m | time: 335.050s
[2K
| Adam | epoch: 010 | loss: 0.47884 - acc: 0.7819 -- iter: 0736/2102
[A[ATraining Step: 618  | total loss: [1m[32m0.46348[0m[0m | time: 348.121s
[2K
| Adam | epoch: 010 | loss: 0.46348 - acc: 0.7943 -- iter: 0768/2102
[A[ATraining Step: 619  | total loss: [1m[32m0.45920[0m[0m | time: 360.829s
[2K
| Adam | epoch: 010 | loss: 0.45920 - acc: 0.7961 -- iter: 0800/2102
[A[ATraining Step: 620  | total loss: [1m[32m0.47860[0m[0m | time: 373.932s
[2K
| Adam | epoch: 010 | loss: 0.47860 - acc: 0.7759 -- iter: 0832/2102
[A[ATraining Step: 621  | total loss: [1m[32m0.48153[0m[0m | time: 386.807s
[2K
| Adam | epoch: 010 | loss: 0.48153 - acc: 0.7702 -- iter: 0864/2102
[A[ATraining Step: 622  | total loss: [1m[32m0.47033[0m[0m | time: 399.796s
[2K
| Adam | epoch: 010 | loss: 0.47033 - acc: 0.7838 -- iter: 0896/2102
[A[ATraining Step: 623  | total loss: [1m[32m0.46325[0m[0m | time: 412.424s
[2K
| Adam | epoch: 010 | loss: 0.46325 - acc: 0.7867 -- iter: 0928/2102
[A[ATraining Step: 624  | total loss: [1m[32m0.46025[0m[0m | time: 424.761s
[2K
| Adam | epoch: 010 | loss: 0.46025 - acc: 0.7830 -- iter: 0960/2102
[A[ATraining Step: 625  | total loss: [1m[32m0.46544[0m[0m | time: 437.160s
[2K
| Adam | epoch: 010 | loss: 0.46544 - acc: 0.7797 -- iter: 0992/2102
[A[ATraining Step: 626  | total loss: [1m[32m0.44320[0m[0m | time: 449.648s
[2K
| Adam | epoch: 010 | loss: 0.44320 - acc: 0.7924 -- iter: 1024/2102
[A[ATraining Step: 627  | total loss: [1m[32m0.45158[0m[0m | time: 462.244s
[2K
| Adam | epoch: 010 | loss: 0.45158 - acc: 0.7912 -- iter: 1056/2102
[A[ATraining Step: 628  | total loss: [1m[32m0.44474[0m[0m | time: 475.123s
[2K
| Adam | epoch: 010 | loss: 0.44474 - acc: 0.7996 -- iter: 1088/2102
[A[ATraining Step: 629  | total loss: [1m[32m0.43962[0m[0m | time: 487.651s
[2K
| Adam | epoch: 010 | loss: 0.43962 - acc: 0.8040 -- iter: 1120/2102
[A[ATraining Step: 630  | total loss: [1m[32m0.44532[0m[0m | time: 500.495s
[2K
| Adam | epoch: 010 | loss: 0.44532 - acc: 0.8018 -- iter: 1152/2102
[A[ATraining Step: 631  | total loss: [1m[32m0.43359[0m[0m | time: 513.815s
[2K
| Adam | epoch: 010 | loss: 0.43359 - acc: 0.8122 -- iter: 1184/2102
[A[ATraining Step: 632  | total loss: [1m[32m0.44367[0m[0m | time: 526.686s
[2K
| Adam | epoch: 010 | loss: 0.44367 - acc: 0.8122 -- iter: 1216/2102
[A[ATraining Step: 633  | total loss: [1m[32m0.42531[0m[0m | time: 539.406s
[2K
| Adam | epoch: 010 | loss: 0.42531 - acc: 0.8248 -- iter: 1248/2102
[A[ATraining Step: 634  | total loss: [1m[32m0.40681[0m[0m | time: 552.187s
[2K
| Adam | epoch: 010 | loss: 0.40681 - acc: 0.8329 -- iter: 1280/2102
[A[ATraining Step: 635  | total loss: [1m[32m0.39971[0m[0m | time: 564.858s
[2K
| Adam | epoch: 010 | loss: 0.39971 - acc: 0.8277 -- iter: 1312/2102
[A[ATraining Step: 636  | total loss: [1m[32m0.42855[0m[0m | time: 577.932s
[2K
| Adam | epoch: 010 | loss: 0.42855 - acc: 0.8137 -- iter: 1344/2102
[A[ATraining Step: 637  | total loss: [1m[32m0.43356[0m[0m | time: 590.482s
[2K
| Adam | epoch: 010 | loss: 0.43356 - acc: 0.8105 -- iter: 1376/2102
[A[ATraining Step: 638  | total loss: [1m[32m0.41939[0m[0m | time: 603.333s
[2K
| Adam | epoch: 010 | loss: 0.41939 - acc: 0.8075 -- iter: 1408/2102
[A[ATraining Step: 639  | total loss: [1m[32m0.42341[0m[0m | time: 615.873s
[2K
| Adam | epoch: 010 | loss: 0.42341 - acc: 0.8049 -- iter: 1440/2102
[A[ATraining Step: 640  | total loss: [1m[32m0.42396[0m[0m | time: 628.630s
[2K
| Adam | epoch: 010 | loss: 0.42396 - acc: 0.8026 -- iter: 1472/2102
[A[ATraining Step: 641  | total loss: [1m[32m0.41701[0m[0m | time: 641.472s
[2K
| Adam | epoch: 010 | loss: 0.41701 - acc: 0.8035 -- iter: 1504/2102
[A[ATraining Step: 642  | total loss: [1m[32m0.41385[0m[0m | time: 654.230s
[2K
| Adam | epoch: 010 | loss: 0.41385 - acc: 0.8044 -- iter: 1536/2102
[A[ATraining Step: 643  | total loss: [1m[32m0.41542[0m[0m | time: 667.134s
[2K
| Adam | epoch: 010 | loss: 0.41542 - acc: 0.7990 -- iter: 1568/2102
[A[ATraining Step: 644  | total loss: [1m[32m0.41290[0m[0m | time: 680.069s
[2K
| Adam | epoch: 010 | loss: 0.41290 - acc: 0.8003 -- iter: 1600/2102
[A[ATraining Step: 645  | total loss: [1m[32m0.41205[0m[0m | time: 692.865s
[2K
| Adam | epoch: 010 | loss: 0.41205 - acc: 0.8047 -- iter: 1632/2102
[A[ATraining Step: 646  | total loss: [1m[32m0.39849[0m[0m | time: 705.753s
[2K
| Adam | epoch: 010 | loss: 0.39849 - acc: 0.8117 -- iter: 1664/2102
[A[ATraining Step: 647  | total loss: [1m[32m0.38713[0m[0m | time: 718.266s
[2K
| Adam | epoch: 010 | loss: 0.38713 - acc: 0.8243 -- iter: 1696/2102
[A[ATraining Step: 648  | total loss: [1m[32m0.37783[0m[0m | time: 730.795s
[2K
| Adam | epoch: 010 | loss: 0.37783 - acc: 0.8294 -- iter: 1728/2102
[A[ATraining Step: 649  | total loss: [1m[32m0.37074[0m[0m | time: 743.195s
[2K
| Adam | epoch: 010 | loss: 0.37074 - acc: 0.8371 -- iter: 1760/2102
[A[ATraining Step: 650  | total loss: [1m[32m0.36255[0m[0m | time: 755.818s
[2K
| Adam | epoch: 010 | loss: 0.36255 - acc: 0.8409 -- iter: 1792/2102
[A[ATraining Step: 651  | total loss: [1m[32m0.37452[0m[0m | time: 768.456s
[2K
| Adam | epoch: 010 | loss: 0.37452 - acc: 0.8380 -- iter: 1824/2102
[A[ATraining Step: 652  | total loss: [1m[32m0.37253[0m[0m | time: 781.443s
[2K
| Adam | epoch: 010 | loss: 0.37253 - acc: 0.8355 -- iter: 1856/2102
[A[ATraining Step: 653  | total loss: [1m[32m0.35822[0m[0m | time: 794.133s
[2K
| Adam | epoch: 010 | loss: 0.35822 - acc: 0.8425 -- iter: 1888/2102
[A[ATraining Step: 654  | total loss: [1m[32m0.35084[0m[0m | time: 806.988s
[2K
| Adam | epoch: 010 | loss: 0.35084 - acc: 0.8427 -- iter: 1920/2102
[A[ATraining Step: 655  | total loss: [1m[32m0.35396[0m[0m | time: 819.296s
[2K
| Adam | epoch: 010 | loss: 0.35396 - acc: 0.8365 -- iter: 1952/2102
[A[ATraining Step: 656  | total loss: [1m[32m0.35051[0m[0m | time: 831.856s
[2K
| Adam | epoch: 010 | loss: 0.35051 - acc: 0.8435 -- iter: 1984/2102
[A[ATraining Step: 657  | total loss: [1m[32m0.35943[0m[0m | time: 845.151s
[2K
| Adam | epoch: 010 | loss: 0.35943 - acc: 0.8404 -- iter: 2016/2102
[A[ATraining Step: 658  | total loss: [1m[32m0.37122[0m[0m | time: 859.124s
[2K
| Adam | epoch: 010 | loss: 0.37122 - acc: 0.8345 -- iter: 2048/2102
[A[ATraining Step: 659  | total loss: [1m[32m0.36182[0m[0m | time: 873.141s
[2K
| Adam | epoch: 010 | loss: 0.36182 - acc: 0.8385 -- iter: 2080/2102
[A[ATraining Step: 660  | total loss: [1m[32m0.36900[0m[0m | time: 927.603s
[2K
| Adam | epoch: 010 | loss: 0.36900 - acc: 0.8328 | val_loss: 1.00453 - val_acc: 0.6474 -- iter: 2102/2102
--
Training Step: 661  | total loss: [1m[32m0.37897[0m[0m | time: 12.838s
[2K
| Adam | epoch: 011 | loss: 0.37897 - acc: 0.8308 -- iter: 0032/2102
[A[ATraining Step: 662  | total loss: [1m[32m0.36953[0m[0m | time: 25.456s
[2K
| Adam | epoch: 011 | loss: 0.36953 - acc: 0.8352 -- iter: 0064/2102
[A[ATraining Step: 663  | total loss: [1m[32m0.37124[0m[0m | time: 37.900s
[2K
| Adam | epoch: 011 | loss: 0.37124 - acc: 0.8329 -- iter: 0096/2102
[A[ATraining Step: 664  | total loss: [1m[32m0.35363[0m[0m | time: 50.532s
[2K
| Adam | epoch: 011 | loss: 0.35363 - acc: 0.8371 -- iter: 0128/2102
[A[ATraining Step: 665  | total loss: [1m[32m0.36469[0m[0m | time: 63.209s
[2K
| Adam | epoch: 011 | loss: 0.36469 - acc: 0.8347 -- iter: 0160/2102
[A[ATraining Step: 666  | total loss: [1m[32m0.38942[0m[0m | time: 75.648s
[2K
| Adam | epoch: 011 | loss: 0.38942 - acc: 0.8262 -- iter: 0192/2102
[A[ATraining Step: 667  | total loss: [1m[32m0.41676[0m[0m | time: 88.452s
[2K
| Adam | epoch: 011 | loss: 0.41676 - acc: 0.8217 -- iter: 0224/2102
[A[ATraining Step: 668  | total loss: [1m[32m0.44630[0m[0m | time: 100.900s
[2K
| Adam | epoch: 011 | loss: 0.44630 - acc: 0.8114 -- iter: 0256/2102
[A[ATraining Step: 669  | total loss: [1m[32m0.43791[0m[0m | time: 110.100s
[2K
| Adam | epoch: 011 | loss: 0.43791 - acc: 0.8146 -- iter: 0288/2102
[A[ATraining Step: 670  | total loss: [1m[32m0.43683[0m[0m | time: 119.404s
[2K
| Adam | epoch: 011 | loss: 0.43683 - acc: 0.8150 -- iter: 0320/2102
[A[ATraining Step: 671  | total loss: [1m[32m0.41930[0m[0m | time: 132.408s
[2K
| Adam | epoch: 011 | loss: 0.41930 - acc: 0.8199 -- iter: 0352/2102
[A[ATraining Step: 672  | total loss: [1m[32m0.41421[0m[0m | time: 144.893s
[2K
| Adam | epoch: 011 | loss: 0.41421 - acc: 0.8223 -- iter: 0384/2102
[A[ATraining Step: 673  | total loss: [1m[32m0.41375[0m[0m | time: 157.490s
[2K
| Adam | epoch: 011 | loss: 0.41375 - acc: 0.8213 -- iter: 0416/2102
[A[ATraining Step: 674  | total loss: [1m[32m0.40643[0m[0m | time: 170.146s
[2K
| Adam | epoch: 011 | loss: 0.40643 - acc: 0.8266 -- iter: 0448/2102
[A[ATraining Step: 675  | total loss: [1m[32m0.42316[0m[0m | time: 182.667s
[2K
| Adam | epoch: 011 | loss: 0.42316 - acc: 0.8127 -- iter: 0480/2102
[A[ATraining Step: 676  | total loss: [1m[32m0.43173[0m[0m | time: 194.985s
[2K
| Adam | epoch: 011 | loss: 0.43173 - acc: 0.8096 -- iter: 0512/2102
[A[ATraining Step: 677  | total loss: [1m[32m0.42379[0m[0m | time: 207.645s
[2K
| Adam | epoch: 011 | loss: 0.42379 - acc: 0.8068 -- iter: 0544/2102
[A[ATraining Step: 678  | total loss: [1m[32m0.42896[0m[0m | time: 219.939s
[2K
| Adam | epoch: 011 | loss: 0.42896 - acc: 0.8011 -- iter: 0576/2102
[A[ATraining Step: 679  | total loss: [1m[32m0.42637[0m[0m | time: 232.630s
[2K
| Adam | epoch: 011 | loss: 0.42637 - acc: 0.8053 -- iter: 0608/2102
[A[ATraining Step: 680  | total loss: [1m[32m0.43966[0m[0m | time: 245.242s
[2K
| Adam | epoch: 011 | loss: 0.43966 - acc: 0.7998 -- iter: 0640/2102
[A[ATraining Step: 681  | total loss: [1m[32m0.44786[0m[0m | time: 257.748s
[2K
| Adam | epoch: 011 | loss: 0.44786 - acc: 0.7917 -- iter: 0672/2102
[A[ATraining Step: 682  | total loss: [1m[32m0.43930[0m[0m | time: 270.469s
[2K
| Adam | epoch: 011 | loss: 0.43930 - acc: 0.7969 -- iter: 0704/2102
[A[ATraining Step: 683  | total loss: [1m[32m0.42907[0m[0m | time: 283.273s
[2K
| Adam | epoch: 011 | loss: 0.42907 - acc: 0.8078 -- iter: 0736/2102
[A[ATraining Step: 684  | total loss: [1m[32m0.42758[0m[0m | time: 295.974s
[2K
| Adam | epoch: 011 | loss: 0.42758 - acc: 0.8052 -- iter: 0768/2102
[A[ATraining Step: 685  | total loss: [1m[32m0.43224[0m[0m | time: 309.863s
[2K
| Adam | epoch: 011 | loss: 0.43224 - acc: 0.7965 -- iter: 0800/2102
[A[ATraining Step: 686  | total loss: [1m[32m0.42696[0m[0m | time: 324.099s
[2K
| Adam | epoch: 011 | loss: 0.42696 - acc: 0.7981 -- iter: 0832/2102
[A[ATraining Step: 687  | total loss: [1m[32m0.44290[0m[0m | time: 338.356s
[2K
| Adam | epoch: 011 | loss: 0.44290 - acc: 0.7808 -- iter: 0864/2102
[A[ATraining Step: 688  | total loss: [1m[32m0.44868[0m[0m | time: 352.079s
[2K
| Adam | epoch: 011 | loss: 0.44868 - acc: 0.7715 -- iter: 0896/2102
[A[ATraining Step: 689  | total loss: [1m[32m0.43954[0m[0m | time: 365.841s
[2K
| Adam | epoch: 011 | loss: 0.43954 - acc: 0.7818 -- iter: 0928/2102
[A[ATraining Step: 690  | total loss: [1m[32m0.44442[0m[0m | time: 376.471s
[2K
| Adam | epoch: 011 | loss: 0.44442 - acc: 0.7818 -- iter: 0960/2102
[A[ATraining Step: 691  | total loss: [1m[32m0.44959[0m[0m | time: 387.421s
[2K
| Adam | epoch: 011 | loss: 0.44959 - acc: 0.7724 -- iter: 0992/2102
[A[ATraining Step: 692  | total loss: [1m[32m0.43634[0m[0m | time: 400.246s
[2K
| Adam | epoch: 011 | loss: 0.43634 - acc: 0.7795 -- iter: 1024/2102
[A[ATraining Step: 693  | total loss: [1m[32m0.43598[0m[0m | time: 413.220s
[2K
| Adam | epoch: 011 | loss: 0.43598 - acc: 0.7797 -- iter: 1056/2102
[A[ATraining Step: 694  | total loss: [1m[32m0.42566[0m[0m | time: 425.833s
[2K
| Adam | epoch: 011 | loss: 0.42566 - acc: 0.7798 -- iter: 1088/2102
[A[ATraining Step: 695  | total loss: [1m[32m0.41941[0m[0m | time: 438.404s
[2K
| Adam | epoch: 011 | loss: 0.41941 - acc: 0.7862 -- iter: 1120/2102
[A[ATraining Step: 696  | total loss: [1m[32m0.40607[0m[0m | time: 451.215s
[2K
| Adam | epoch: 011 | loss: 0.40607 - acc: 0.7982 -- iter: 1152/2102
[A[ATraining Step: 697  | total loss: [1m[32m0.39703[0m[0m | time: 463.742s
[2K
| Adam | epoch: 011 | loss: 0.39703 - acc: 0.8059 -- iter: 1184/2102
[A[ATraining Step: 698  | total loss: [1m[32m0.38099[0m[0m | time: 476.006s
[2K
| Adam | epoch: 011 | loss: 0.38099 - acc: 0.8128 -- iter: 1216/2102
[A[ATraining Step: 699  | total loss: [1m[32m0.37879[0m[0m | time: 488.311s
[2K
| Adam | epoch: 011 | loss: 0.37879 - acc: 0.8159 -- iter: 1248/2102
[A[ATraining Step: 700  | total loss: [1m[32m0.39338[0m[0m | time: 501.065s
[2K
| Adam | epoch: 011 | loss: 0.39338 - acc: 0.8124 -- iter: 1280/2102
[A[ATraining Step: 701  | total loss: [1m[32m0.37229[0m[0m | time: 513.512s
[2K
| Adam | epoch: 011 | loss: 0.37229 - acc: 0.8249 -- iter: 1312/2102
[A[ATraining Step: 702  | total loss: [1m[32m0.35943[0m[0m | time: 526.381s
[2K
| Adam | epoch: 011 | loss: 0.35943 - acc: 0.8331 -- iter: 1344/2102
[A[ATraining Step: 703  | total loss: [1m[32m0.33751[0m[0m | time: 538.783s
[2K
| Adam | epoch: 011 | loss: 0.33751 - acc: 0.8466 -- iter: 1376/2102
[A[ATraining Step: 704  | total loss: [1m[32m0.33237[0m[0m | time: 551.288s
[2K
| Adam | epoch: 011 | loss: 0.33237 - acc: 0.8526 -- iter: 1408/2102
[A[ATraining Step: 705  | total loss: [1m[32m0.39946[0m[0m | time: 563.825s
[2K
| Adam | epoch: 011 | loss: 0.39946 - acc: 0.8361 -- iter: 1440/2102
[A[ATraining Step: 706  | total loss: [1m[32m0.38385[0m[0m | time: 576.094s
[2K
| Adam | epoch: 011 | loss: 0.38385 - acc: 0.8400 -- iter: 1472/2102
[A[ATraining Step: 707  | total loss: [1m[32m0.39155[0m[0m | time: 588.714s
[2K
| Adam | epoch: 011 | loss: 0.39155 - acc: 0.8372 -- iter: 1504/2102
[A[ATraining Step: 708  | total loss: [1m[32m0.38663[0m[0m | time: 601.822s
[2K
| Adam | epoch: 011 | loss: 0.38663 - acc: 0.8379 -- iter: 1536/2102
[A[ATraining Step: 709  | total loss: [1m[32m0.37288[0m[0m | time: 614.120s
[2K
| Adam | epoch: 011 | loss: 0.37288 - acc: 0.8478 -- iter: 1568/2102
[A[ATraining Step: 710  | total loss: [1m[32m0.36878[0m[0m | time: 626.729s
[2K
| Adam | epoch: 011 | loss: 0.36878 - acc: 0.8443 -- iter: 1600/2102
[A[ATraining Step: 711  | total loss: [1m[32m0.35621[0m[0m | time: 638.950s
[2K
| Adam | epoch: 011 | loss: 0.35621 - acc: 0.8505 -- iter: 1632/2102
[A[ATraining Step: 712  | total loss: [1m[32m0.35349[0m[0m | time: 651.922s
[2K
| Adam | epoch: 011 | loss: 0.35349 - acc: 0.8530 -- iter: 1664/2102
[A[ATraining Step: 713  | total loss: [1m[32m0.34841[0m[0m | time: 664.676s
[2K
| Adam | epoch: 011 | loss: 0.34841 - acc: 0.8520 -- iter: 1696/2102
[A[ATraining Step: 714  | total loss: [1m[32m0.33451[0m[0m | time: 676.987s
[2K
| Adam | epoch: 011 | loss: 0.33451 - acc: 0.8575 -- iter: 1728/2102
[A[ATraining Step: 715  | total loss: [1m[32m0.32877[0m[0m | time: 689.479s
[2K
| Adam | epoch: 011 | loss: 0.32877 - acc: 0.8623 -- iter: 1760/2102
[A[ATraining Step: 716  | total loss: [1m[32m0.31622[0m[0m | time: 702.103s
[2K
| Adam | epoch: 011 | loss: 0.31622 - acc: 0.8667 -- iter: 1792/2102
[A[ATraining Step: 717  | total loss: [1m[32m0.33983[0m[0m | time: 714.954s
[2K
| Adam | epoch: 011 | loss: 0.33983 - acc: 0.8613 -- iter: 1824/2102
[A[ATraining Step: 718  | total loss: [1m[32m0.34405[0m[0m | time: 727.423s
[2K
| Adam | epoch: 011 | loss: 0.34405 - acc: 0.8533 -- iter: 1856/2102
[A[ATraining Step: 719  | total loss: [1m[32m0.36784[0m[0m | time: 740.058s
[2K
| Adam | epoch: 011 | loss: 0.36784 - acc: 0.8430 -- iter: 1888/2102
[A[ATraining Step: 720  | total loss: [1m[32m0.35937[0m[0m | time: 752.577s
[2K
| Adam | epoch: 011 | loss: 0.35937 - acc: 0.8462 -- iter: 1920/2102
[A[ATraining Step: 721  | total loss: [1m[32m0.37464[0m[0m | time: 765.103s
[2K
| Adam | epoch: 011 | loss: 0.37464 - acc: 0.8334 -- iter: 1952/2102
[A[ATraining Step: 722  | total loss: [1m[32m0.36390[0m[0m | time: 777.688s
[2K
| Adam | epoch: 011 | loss: 0.36390 - acc: 0.8345 -- iter: 1984/2102
[A[ATraining Step: 723  | total loss: [1m[32m0.38822[0m[0m | time: 790.370s
[2K
| Adam | epoch: 011 | loss: 0.38822 - acc: 0.8229 -- iter: 2016/2102
[A[ATraining Step: 724  | total loss: [1m[32m0.39871[0m[0m | time: 802.753s
[2K
| Adam | epoch: 011 | loss: 0.39871 - acc: 0.8281 -- iter: 2048/2102
[A[ATraining Step: 725  | total loss: [1m[32m0.38416[0m[0m | time: 814.769s
[2K
| Adam | epoch: 011 | loss: 0.38416 - acc: 0.8390 -- iter: 2080/2102
[A[ATraining Step: 726  | total loss: [1m[32m0.38566[0m[0m | time: 874.606s
[2K
| Adam | epoch: 011 | loss: 0.38566 - acc: 0.8395 | val_loss: 0.65542 - val_acc: 0.6945 -- iter: 2102/2102
--
Training Step: 727  | total loss: [1m[32m0.39847[0m[0m | time: 12.932s
[2K
| Adam | epoch: 012 | loss: 0.39847 - acc: 0.8337 -- iter: 0032/2102
[A[ATraining Step: 728  | total loss: [1m[32m0.39146[0m[0m | time: 25.856s
[2K
| Adam | epoch: 012 | loss: 0.39146 - acc: 0.8316 -- iter: 0064/2102
[A[ATraining Step: 729  | total loss: [1m[32m0.40522[0m[0m | time: 38.758s
[2K
| Adam | epoch: 012 | loss: 0.40522 - acc: 0.8234 -- iter: 0096/2102
[A[ATraining Step: 730  | total loss: [1m[32m0.40414[0m[0m | time: 51.787s
[2K
| Adam | epoch: 012 | loss: 0.40414 - acc: 0.8192 -- iter: 0128/2102
[A[ATraining Step: 731  | total loss: [1m[32m0.39596[0m[0m | time: 65.604s
[2K
| Adam | epoch: 012 | loss: 0.39596 - acc: 0.8248 -- iter: 0160/2102
[A[ATraining Step: 732  | total loss: [1m[32m0.39128[0m[0m | time: 78.378s
[2K
| Adam | epoch: 012 | loss: 0.39128 - acc: 0.8204 -- iter: 0192/2102
[A[ATraining Step: 733  | total loss: [1m[32m0.38575[0m[0m | time: 90.859s
[2K
| Adam | epoch: 012 | loss: 0.38575 - acc: 0.8228 -- iter: 0224/2102
[A[ATraining Step: 734  | total loss: [1m[32m0.37543[0m[0m | time: 103.841s
[2K
| Adam | epoch: 012 | loss: 0.37543 - acc: 0.8280 -- iter: 0256/2102
[A[ATraining Step: 735  | total loss: [1m[32m0.38036[0m[0m | time: 116.120s
[2K
| Adam | epoch: 012 | loss: 0.38036 - acc: 0.8233 -- iter: 0288/2102
[A[ATraining Step: 736  | total loss: [1m[32m0.38380[0m[0m | time: 125.255s
[2K
| Adam | epoch: 012 | loss: 0.38380 - acc: 0.8254 -- iter: 0320/2102
[A[ATraining Step: 737  | total loss: [1m[32m0.36876[0m[0m | time: 134.643s
[2K
| Adam | epoch: 012 | loss: 0.36876 - acc: 0.8428 -- iter: 0352/2102
[A[ATraining Step: 738  | total loss: [1m[32m0.34851[0m[0m | time: 147.166s
[2K
| Adam | epoch: 012 | loss: 0.34851 - acc: 0.8585 -- iter: 0384/2102
[A[ATraining Step: 739  | total loss: [1m[32m0.34663[0m[0m | time: 159.759s
[2K
| Adam | epoch: 012 | loss: 0.34663 - acc: 0.8602 -- iter: 0416/2102
[A[ATraining Step: 740  | total loss: [1m[32m0.32512[0m[0m | time: 172.425s
[2K
| Adam | epoch: 012 | loss: 0.32512 - acc: 0.8710 -- iter: 0448/2102
[A[ATraining Step: 741  | total loss: [1m[32m0.32781[0m[0m | time: 185.097s
[2K
| Adam | epoch: 012 | loss: 0.32781 - acc: 0.8714 -- iter: 0480/2102
[A[ATraining Step: 742  | total loss: [1m[32m0.32869[0m[0m | time: 197.647s
[2K
| Adam | epoch: 012 | loss: 0.32869 - acc: 0.8655 -- iter: 0512/2102
[A[ATraining Step: 743  | total loss: [1m[32m0.34865[0m[0m | time: 210.268s
[2K
| Adam | epoch: 012 | loss: 0.34865 - acc: 0.8477 -- iter: 0544/2102
[A[ATraining Step: 744  | total loss: [1m[32m0.34700[0m[0m | time: 222.772s
[2K
| Adam | epoch: 012 | loss: 0.34700 - acc: 0.8473 -- iter: 0576/2102
[A[ATraining Step: 745  | total loss: [1m[32m0.37457[0m[0m | time: 235.200s
[2K
| Adam | epoch: 012 | loss: 0.37457 - acc: 0.8345 -- iter: 0608/2102
[A[ATraining Step: 746  | total loss: [1m[32m0.37237[0m[0m | time: 247.689s
[2K
| Adam | epoch: 012 | loss: 0.37237 - acc: 0.8385 -- iter: 0640/2102
[A[ATraining Step: 747  | total loss: [1m[32m0.36371[0m[0m | time: 260.243s
[2K
| Adam | epoch: 012 | loss: 0.36371 - acc: 0.8453 -- iter: 0672/2102
[A[ATraining Step: 748  | total loss: [1m[32m0.38475[0m[0m | time: 272.761s
[2K
| Adam | epoch: 012 | loss: 0.38475 - acc: 0.8389 -- iter: 0704/2102
[A[ATraining Step: 749  | total loss: [1m[32m0.37801[0m[0m | time: 285.369s
[2K
| Adam | epoch: 012 | loss: 0.37801 - acc: 0.8394 -- iter: 0736/2102
[A[ATraining Step: 750  | total loss: [1m[32m0.38497[0m[0m | time: 297.691s
[2K
| Adam | epoch: 012 | loss: 0.38497 - acc: 0.8367 -- iter: 0768/2102
[A[ATraining Step: 751  | total loss: [1m[32m0.38395[0m[0m | time: 310.211s
[2K
| Adam | epoch: 012 | loss: 0.38395 - acc: 0.8374 -- iter: 0800/2102
[A[ATraining Step: 752  | total loss: [1m[32m0.37023[0m[0m | time: 322.752s
[2K
| Adam | epoch: 012 | loss: 0.37023 - acc: 0.8443 -- iter: 0832/2102
[A[ATraining Step: 753  | total loss: [1m[32m0.37830[0m[0m | time: 335.141s
[2K
| Adam | epoch: 012 | loss: 0.37830 - acc: 0.8380 -- iter: 0864/2102
[A[ATraining Step: 754  | total loss: [1m[32m0.36643[0m[0m | time: 346.980s
[2K
| Adam | epoch: 012 | loss: 0.36643 - acc: 0.8479 -- iter: 0896/2102
[A[ATraining Step: 755  | total loss: [1m[32m0.35945[0m[0m | time: 359.183s
[2K
| Adam | epoch: 012 | loss: 0.35945 - acc: 0.8475 -- iter: 0928/2102
[A[ATraining Step: 756  | total loss: [1m[32m0.36272[0m[0m | time: 371.794s
[2K
| Adam | epoch: 012 | loss: 0.36272 - acc: 0.8440 -- iter: 0960/2102
[A[ATraining Step: 757  | total loss: [1m[32m0.38655[0m[0m | time: 384.407s
[2K
| Adam | epoch: 012 | loss: 0.38655 - acc: 0.8252 -- iter: 0992/2102
[A[ATraining Step: 758  | total loss: [1m[32m0.37389[0m[0m | time: 398.520s
[2K
| Adam | epoch: 012 | loss: 0.37389 - acc: 0.8333 -- iter: 1024/2102
[A[ATraining Step: 759  | total loss: [1m[32m0.37211[0m[0m | time: 412.644s
[2K
| Adam | epoch: 012 | loss: 0.37211 - acc: 0.8313 -- iter: 1056/2102
[A[ATraining Step: 760  | total loss: [1m[32m0.36137[0m[0m | time: 426.877s
[2K
| Adam | epoch: 012 | loss: 0.36137 - acc: 0.8356 -- iter: 1088/2102
[A[ATraining Step: 761  | total loss: [1m[32m0.35372[0m[0m | time: 441.381s
[2K
| Adam | epoch: 012 | loss: 0.35372 - acc: 0.8364 -- iter: 1120/2102
[A[ATraining Step: 762  | total loss: [1m[32m0.37597[0m[0m | time: 454.755s
[2K
| Adam | epoch: 012 | loss: 0.37597 - acc: 0.8309 -- iter: 1152/2102
[A[ATraining Step: 763  | total loss: [1m[32m0.39148[0m[0m | time: 463.303s
[2K
| Adam | epoch: 012 | loss: 0.39148 - acc: 0.8228 -- iter: 1184/2102
[A[ATraining Step: 764  | total loss: [1m[32m0.38563[0m[0m | time: 471.832s
[2K
| Adam | epoch: 012 | loss: 0.38563 - acc: 0.8218 -- iter: 1216/2102
[A[ATraining Step: 765  | total loss: [1m[32m0.37860[0m[0m | time: 483.003s
[2K
| Adam | epoch: 012 | loss: 0.37860 - acc: 0.8209 -- iter: 1248/2102
[A[ATraining Step: 766  | total loss: [1m[32m0.38591[0m[0m | time: 502.293s
[2K
| Adam | epoch: 012 | loss: 0.38591 - acc: 0.8200 -- iter: 1280/2102
[A[ATraining Step: 767  | total loss: [1m[32m0.37872[0m[0m | time: 553.705s
[2K
| Adam | epoch: 012 | loss: 0.37872 - acc: 0.8255 -- iter: 1312/2102
[A[ATraining Step: 768  | total loss: [1m[32m0.37091[0m[0m | time: 589.157s
[2K
| Adam | epoch: 012 | loss: 0.37091 - acc: 0.8305 -- iter: 1344/2102
[A[ATraining Step: 769  | total loss: [1m[32m0.40046[0m[0m | time: 647.127s
[2K
| Adam | epoch: 012 | loss: 0.40046 - acc: 0.8193 -- iter: 1376/2102
[A[ATraining Step: 770  | total loss: [1m[32m0.38753[0m[0m | time: 692.308s
[2K
| Adam | epoch: 012 | loss: 0.38753 - acc: 0.8280 -- iter: 1408/2102
[A[ATraining Step: 771  | total loss: [1m[32m0.36603[0m[0m | time: 734.025s
[2K
| Adam | epoch: 012 | loss: 0.36603 - acc: 0.8389 -- iter: 1440/2102
[A[ATraining Step: 772  | total loss: [1m[32m0.37700[0m[0m | time: 780.973s
[2K
| Adam | epoch: 012 | loss: 0.37700 - acc: 0.8363 -- iter: 1472/2102
[A[ATraining Step: 773  | total loss: [1m[32m0.36291[0m[0m | time: 823.401s
[2K
| Adam | epoch: 012 | loss: 0.36291 - acc: 0.8402 -- iter: 1504/2102
[A[ATraining Step: 774  | total loss: [1m[32m0.34464[0m[0m | time: 868.989s
[2K
| Adam | epoch: 012 | loss: 0.34464 - acc: 0.8499 -- iter: 1536/2102
[A[ATraining Step: 775  | total loss: [1m[32m0.36086[0m[0m | time: 897.499s
[2K
| Adam | epoch: 012 | loss: 0.36086 - acc: 0.8430 -- iter: 1568/2102
[A[ATraining Step: 776  | total loss: [1m[32m0.34597[0m[0m | time: 944.810s
[2K
| Adam | epoch: 012 | loss: 0.34597 - acc: 0.8494 -- iter: 1600/2102
[A[ATraining Step: 777  | total loss: [1m[32m0.32438[0m[0m | time: 975.441s
[2K
| Adam | epoch: 012 | loss: 0.32438 - acc: 0.8644 -- iter: 1632/2102
[A[ATraining Step: 778  | total loss: [1m[32m0.30627[0m[0m | time: 999.860s
[2K
| Adam | epoch: 012 | loss: 0.30627 - acc: 0.8717 -- iter: 1664/2102
[A[ATraining Step: 779  | total loss: [1m[32m0.30164[0m[0m | time: 1066.427s
[2K
| Adam | epoch: 012 | loss: 0.30164 - acc: 0.8783 -- iter: 1696/2102
[A[ATraining Step: 780  | total loss: [1m[32m0.29228[0m[0m | time: 1098.967s
[2K
| Adam | epoch: 012 | loss: 0.29228 - acc: 0.8874 -- iter: 1728/2102
[A[ATraining Step: 781  | total loss: [1m[32m0.28602[0m[0m | time: 1187.560s
[2K
| Adam | epoch: 012 | loss: 0.28602 - acc: 0.8955 -- iter: 1760/2102
[A[ATraining Step: 782  | total loss: [1m[32m0.28420[0m[0m | time: 1200.860s
[2K
| Adam | epoch: 012 | loss: 0.28420 - acc: 0.8934 -- iter: 1792/2102
[A[ATraining Step: 783  | total loss: [1m[32m0.28626[0m[0m | time: 1266.235s
[2K
| Adam | epoch: 012 | loss: 0.28626 - acc: 0.8885 -- iter: 1824/2102
[A[ATraining Step: 784  | total loss: [1m[32m0.26878[0m[0m | time: 1279.403s
[2K
| Adam | epoch: 012 | loss: 0.26878 - acc: 0.8965 -- iter: 1856/2102
[A[ATraining Step: 785  | total loss: [1m[32m0.26425[0m[0m | time: 1292.646s
[2K
| Adam | epoch: 012 | loss: 0.26425 - acc: 0.8975 -- iter: 1888/2102
[A[ATraining Step: 786  | total loss: [1m[32m0.27576[0m[0m | time: 1305.639s
[2K
| Adam | epoch: 012 | loss: 0.27576 - acc: 0.8921 -- iter: 1920/2102
[A[ATraining Step: 787  | total loss: [1m[32m0.29892[0m[0m | time: 1318.785s
[2K
| Adam | epoch: 012 | loss: 0.29892 - acc: 0.8841 -- iter: 1952/2102
[A[ATraining Step: 788  | total loss: [1m[32m0.29004[0m[0m | time: 1331.882s
[2K
| Adam | epoch: 012 | loss: 0.29004 - acc: 0.8864 -- iter: 1984/2102
[A[ATraining Step: 789  | total loss: [1m[32m0.29178[0m[0m | time: 1345.116s
[2K
| Adam | epoch: 012 | loss: 0.29178 - acc: 0.8883 -- iter: 2016/2102
[A[ATraining Step: 790  | total loss: [1m[32m0.28569[0m[0m | time: 1358.602s
[2K
| Adam | epoch: 012 | loss: 0.28569 - acc: 0.8901 -- iter: 2048/2102
[A[ATraining Step: 791  | total loss: [1m[32m0.28805[0m[0m | time: 1372.091s
[2K
| Adam | epoch: 012 | loss: 0.28805 - acc: 0.8886 -- iter: 2080/2102
[A[ATraining Step: 792  | total loss: [1m[32m0.28654[0m[0m | time: 1435.276s
[2K
| Adam | epoch: 012 | loss: 0.28654 - acc: 0.8935 | val_loss: 0.87795 - val_acc: 0.6611 -- iter: 2102/2102
--
Training Step: 793  | total loss: [1m[32m0.32228[0m[0m | time: 13.163s
[2K
| Adam | epoch: 013 | loss: 0.32228 - acc: 0.8823 -- iter: 0032/2102
[A[ATraining Step: 794  | total loss: [1m[32m0.31611[0m[0m | time: 26.970s
[2K
| Adam | epoch: 013 | loss: 0.31611 - acc: 0.8784 -- iter: 0064/2102
[A[ATraining Step: 795  | total loss: [1m[32m0.32634[0m[0m | time: 39.987s
[2K
| Adam | epoch: 013 | loss: 0.32634 - acc: 0.8718 -- iter: 0096/2102
[A[ATraining Step: 796  | total loss: [1m[32m0.31822[0m[0m | time: 52.462s
[2K
| Adam | epoch: 013 | loss: 0.31822 - acc: 0.8722 -- iter: 0128/2102
[A[ATraining Step: 797  | total loss: [1m[32m0.32341[0m[0m | time: 65.783s
[2K
| Adam | epoch: 013 | loss: 0.32341 - acc: 0.8724 -- iter: 0160/2102
[A[ATraining Step: 798  | total loss: [1m[32m0.31895[0m[0m | time: 78.778s
[2K
| Adam | epoch: 013 | loss: 0.31895 - acc: 0.8727 -- iter: 0192/2102
[A[ATraining Step: 799  | total loss: [1m[32m0.32120[0m[0m | time: 91.940s
[2K
| Adam | epoch: 013 | loss: 0.32120 - acc: 0.8729 -- iter: 0224/2102
[A[ATraining Step: 800  | total loss: [1m[32m0.30085[0m[0m | time: 157.131s
[2K
| Adam | epoch: 013 | loss: 0.30085 - acc: 0.8856 | val_loss: 3.36945 - val_acc: 0.4088 -- iter: 0256/2102
--
Training Step: 801  | total loss: [1m[32m0.29818[0m[0m | time: 170.091s
[2K
| Adam | epoch: 013 | loss: 0.29818 - acc: 0.8846 -- iter: 0288/2102
[A[ATraining Step: 802  | total loss: [1m[32m0.29644[0m[0m | time: 183.767s
[2K
| Adam | epoch: 013 | loss: 0.29644 - acc: 0.8805 -- iter: 0320/2102
[A[ATraining Step: 803  | total loss: [1m[32m0.30573[0m[0m | time: 193.705s
[2K
| Adam | epoch: 013 | loss: 0.30573 - acc: 0.8768 -- iter: 0352/2102
[A[ATraining Step: 804  | total loss: [1m[32m0.29630[0m[0m | time: 203.228s
[2K
| Adam | epoch: 013 | loss: 0.29630 - acc: 0.8755 -- iter: 0384/2102
[A[ATraining Step: 805  | total loss: [1m[32m0.27376[0m[0m | time: 216.347s
[2K
| Adam | epoch: 013 | loss: 0.27376 - acc: 0.8879 -- iter: 0416/2102
[A[ATraining Step: 806  | total loss: [1m[32m0.27243[0m[0m | time: 229.016s
[2K
| Adam | epoch: 013 | loss: 0.27243 - acc: 0.8867 -- iter: 0448/2102
[A[ATraining Step: 807  | total loss: [1m[32m0.29430[0m[0m | time: 242.232s
[2K
| Adam | epoch: 013 | loss: 0.29430 - acc: 0.8761 -- iter: 0480/2102
[A[ATraining Step: 808  | total loss: [1m[32m0.28015[0m[0m | time: 255.296s
[2K
| Adam | epoch: 013 | loss: 0.28015 - acc: 0.8854 -- iter: 0512/2102
[A[ATraining Step: 809  | total loss: [1m[32m0.30063[0m[0m | time: 268.290s
[2K
| Adam | epoch: 013 | loss: 0.30063 - acc: 0.8781 -- iter: 0544/2102
[A[ATraining Step: 810  | total loss: [1m[32m0.32901[0m[0m | time: 281.414s
[2K
| Adam | epoch: 013 | loss: 0.32901 - acc: 0.8590 -- iter: 0576/2102
[A[ATraining Step: 811  | total loss: [1m[32m0.32340[0m[0m | time: 294.589s
[2K
| Adam | epoch: 013 | loss: 0.32340 - acc: 0.8544 -- iter: 0608/2102
[A[ATraining Step: 812  | total loss: [1m[32m0.30234[0m[0m | time: 307.677s
[2K
| Adam | epoch: 013 | loss: 0.30234 - acc: 0.8658 -- iter: 0640/2102
[A[ATraining Step: 813  | total loss: [1m[32m0.31134[0m[0m | time: 320.841s
[2K
| Adam | epoch: 013 | loss: 0.31134 - acc: 0.8605 -- iter: 0672/2102
[A[ATraining Step: 814  | total loss: [1m[32m0.30160[0m[0m | time: 334.018s
[2K
| Adam | epoch: 013 | loss: 0.30160 - acc: 0.8651 -- iter: 0704/2102
[A[ATraining Step: 815  | total loss: [1m[32m0.30932[0m[0m | time: 347.059s
[2K
| Adam | epoch: 013 | loss: 0.30932 - acc: 0.8629 -- iter: 0736/2102
[A[ATraining Step: 816  | total loss: [1m[32m0.31382[0m[0m | time: 359.643s
[2K
| Adam | epoch: 013 | loss: 0.31382 - acc: 0.8610 -- iter: 0768/2102
[A[ATraining Step: 817  | total loss: [1m[32m0.31263[0m[0m | time: 373.983s
[2K
| Adam | epoch: 013 | loss: 0.31263 - acc: 0.8593 -- iter: 0800/2102
[A[ATraining Step: 818  | total loss: [1m[32m0.34446[0m[0m | time: 389.649s
[2K
| Adam | epoch: 013 | loss: 0.34446 - acc: 0.8452 -- iter: 0832/2102
[A[ATraining Step: 819  | total loss: [1m[32m0.32871[0m[0m | time: 403.232s
[2K
| Adam | epoch: 013 | loss: 0.32871 - acc: 0.8513 -- iter: 0864/2102
[A[ATraining Step: 820  | total loss: [1m[32m0.31703[0m[0m | time: 416.480s
[2K
| Adam | epoch: 013 | loss: 0.31703 - acc: 0.8631 -- iter: 0896/2102
[A[ATraining Step: 821  | total loss: [1m[32m0.32286[0m[0m | time: 431.056s
[2K
| Adam | epoch: 013 | loss: 0.32286 - acc: 0.8580 -- iter: 0928/2102
[A[ATraining Step: 822  | total loss: [1m[32m0.32574[0m[0m | time: 444.352s
[2K
| Adam | epoch: 013 | loss: 0.32574 - acc: 0.8597 -- iter: 0960/2102
[A[ATraining Step: 823  | total loss: [1m[32m0.34337[0m[0m | time: 459.574s
[2K
| Adam | epoch: 013 | loss: 0.34337 - acc: 0.8425 -- iter: 0992/2102
[A[ATraining Step: 824  | total loss: [1m[32m0.34386[0m[0m | time: 472.468s
[2K
| Adam | epoch: 013 | loss: 0.34386 - acc: 0.8457 -- iter: 1024/2102
[A[ATraining Step: 825  | total loss: [1m[32m0.34621[0m[0m | time: 486.268s
[2K
| Adam | epoch: 013 | loss: 0.34621 - acc: 0.8487 -- iter: 1056/2102
[A[ATraining Step: 826  | total loss: [1m[32m0.34729[0m[0m | time: 499.829s
[2K
| Adam | epoch: 013 | loss: 0.34729 - acc: 0.8419 -- iter: 1088/2102
[A[ATraining Step: 827  | total loss: [1m[32m0.33635[0m[0m | time: 523.505s
[2K
| Adam | epoch: 013 | loss: 0.33635 - acc: 0.8484 -- iter: 1120/2102
[A[ATraining Step: 828  | total loss: [1m[32m0.32128[0m[0m | time: 536.476s
[2K
| Adam | epoch: 013 | loss: 0.32128 - acc: 0.8573 -- iter: 1152/2102
[A[ATraining Step: 829  | total loss: [1m[32m0.30798[0m[0m | time: 550.052s
[2K
| Adam | epoch: 013 | loss: 0.30798 - acc: 0.8684 -- iter: 1184/2102
[A[ATraining Step: 830  | total loss: [1m[32m0.31358[0m[0m | time: 564.947s
[2K
| Adam | epoch: 013 | loss: 0.31358 - acc: 0.8628 -- iter: 1216/2102
[A[ATraining Step: 831  | total loss: [1m[32m0.32367[0m[0m | time: 579.403s
[2K
| Adam | epoch: 013 | loss: 0.32367 - acc: 0.8609 -- iter: 1248/2102
[A[ATraining Step: 832  | total loss: [1m[32m0.33612[0m[0m | time: 600.189s
[2K
| Adam | epoch: 013 | loss: 0.33612 - acc: 0.8561 -- iter: 1280/2102
[A[ATraining Step: 833  | total loss: [1m[32m0.33997[0m[0m | time: 616.386s
[2K
| Adam | epoch: 013 | loss: 0.33997 - acc: 0.8548 -- iter: 1312/2102
[A[ATraining Step: 834  | total loss: [1m[32m0.34551[0m[0m | time: 633.686s
[2K
| Adam | epoch: 013 | loss: 0.34551 - acc: 0.8475 -- iter: 1344/2102
[A[ATraining Step: 835  | total loss: [1m[32m0.33107[0m[0m | time: 646.637s
[2K
| Adam | epoch: 013 | loss: 0.33107 - acc: 0.8596 -- iter: 1376/2102
[A[ATraining Step: 836  | total loss: [1m[32m0.33636[0m[0m | time: 665.571s
[2K
| Adam | epoch: 013 | loss: 0.33636 - acc: 0.8549 -- iter: 1408/2102
[A[ATraining Step: 837  | total loss: [1m[32m0.32675[0m[0m | time: 681.539s
[2K
| Adam | epoch: 013 | loss: 0.32675 - acc: 0.8600 -- iter: 1440/2102
[A[ATraining Step: 838  | total loss: [1m[32m0.36109[0m[0m | time: 698.960s
[2K
| Adam | epoch: 013 | loss: 0.36109 - acc: 0.8428 -- iter: 1472/2102
[A[ATraining Step: 839  | total loss: [1m[32m0.35108[0m[0m | time: 712.172s
[2K
| Adam | epoch: 013 | loss: 0.35108 - acc: 0.8523 -- iter: 1504/2102
[A[ATraining Step: 840  | total loss: [1m[32m0.34226[0m[0m | time: 728.654s
[2K
| Adam | epoch: 013 | loss: 0.34226 - acc: 0.8577 -- iter: 1536/2102
[A[ATraining Step: 841  | total loss: [1m[32m0.34831[0m[0m | time: 746.259s
[2K
| Adam | epoch: 013 | loss: 0.34831 - acc: 0.8500 -- iter: 1568/2102
[A[ATraining Step: 842  | total loss: [1m[32m0.35540[0m[0m | time: 771.645s
[2K
| Adam | epoch: 013 | loss: 0.35540 - acc: 0.8431 -- iter: 1600/2102
[A[ATraining Step: 843  | total loss: [1m[32m0.35146[0m[0m | time: 786.931s
[2K
| Adam | epoch: 013 | loss: 0.35146 - acc: 0.8463 -- iter: 1632/2102
[A[ATraining Step: 844  | total loss: [1m[32m0.33854[0m[0m | time: 801.523s
[2K
| Adam | epoch: 013 | loss: 0.33854 - acc: 0.8586 -- iter: 1664/2102
[A[ATraining Step: 845  | total loss: [1m[32m0.33474[0m[0m | time: 816.354s
[2K
| Adam | epoch: 013 | loss: 0.33474 - acc: 0.8602 -- iter: 1696/2102
[A[ATraining Step: 846  | total loss: [1m[32m0.33495[0m[0m | time: 830.891s
[2K
| Adam | epoch: 013 | loss: 0.33495 - acc: 0.8617 -- iter: 1728/2102
[A[ATraining Step: 847  | total loss: [1m[32m0.32757[0m[0m | time: 847.149s
[2K
| Adam | epoch: 013 | loss: 0.32757 - acc: 0.8630 -- iter: 1760/2102
[A[ATraining Step: 848  | total loss: [1m[32m0.32617[0m[0m | time: 861.951s
[2K
| Adam | epoch: 013 | loss: 0.32617 - acc: 0.8611 -- iter: 1792/2102
[A[ATraining Step: 849  | total loss: [1m[32m0.31831[0m[0m | time: 876.807s
[2K
| Adam | epoch: 013 | loss: 0.31831 - acc: 0.8687 -- iter: 1824/2102
[A[ATraining Step: 850  | total loss: [1m[32m0.31124[0m[0m | time: 892.064s
[2K
| Adam | epoch: 013 | loss: 0.31124 - acc: 0.8756 -- iter: 1856/2102
[A[ATraining Step: 851  | total loss: [1m[32m0.30378[0m[0m | time: 906.919s
[2K
| Adam | epoch: 013 | loss: 0.30378 - acc: 0.8787 -- iter: 1888/2102
[A[ATraining Step: 852  | total loss: [1m[32m0.30671[0m[0m | time: 929.679s
[2K
| Adam | epoch: 013 | loss: 0.30671 - acc: 0.8814 -- iter: 1920/2102
[A[ATraining Step: 853  | total loss: [1m[32m0.29844[0m[0m | time: 950.899s
[2K
| Adam | epoch: 013 | loss: 0.29844 - acc: 0.8839 -- iter: 1952/2102
[A[ATraining Step: 854  | total loss: [1m[32m0.28714[0m[0m | time: 994.760s
[2K
| Adam | epoch: 013 | loss: 0.28714 - acc: 0.8924 -- iter: 1984/2102
[A[ATraining Step: 855  | total loss: [1m[32m0.28977[0m[0m | time: 1019.930s
[2K
| Adam | epoch: 013 | loss: 0.28977 - acc: 0.8875 -- iter: 2016/2102
[A[ATraining Step: 856  | total loss: [1m[32m0.30207[0m[0m | time: 1039.404s
[2K
| Adam | epoch: 013 | loss: 0.30207 - acc: 0.8832 -- iter: 2048/2102
[A[ATraining Step: 857  | total loss: [1m[32m0.31200[0m[0m | time: 1073.139s
[2K
| Adam | epoch: 013 | loss: 0.31200 - acc: 0.8792 -- iter: 2080/2102
[A[ATraining Step: 858  | total loss: [1m[32m0.30567[0m[0m | time: 1152.065s
[2K
| Adam | epoch: 013 | loss: 0.30567 - acc: 0.8757 | val_loss: 0.71002 - val_acc: 0.7173 -- iter: 2102/2102
--
Training Step: 859  | total loss: [1m[32m0.30308[0m[0m | time: 13.909s
[2K
| Adam | epoch: 014 | loss: 0.30308 - acc: 0.8756 -- iter: 0032/2102
[A[ATraining Step: 860  | total loss: [1m[32m0.29581[0m[0m | time: 28.908s
[2K
| Adam | epoch: 014 | loss: 0.29581 - acc: 0.8787 -- iter: 0064/2102
[A[ATraining Step: 861  | total loss: [1m[32m0.29989[0m[0m | time: 42.489s
[2K
| Adam | epoch: 014 | loss: 0.29989 - acc: 0.8720 -- iter: 0096/2102
[A[ATraining Step: 862  | total loss: [1m[32m0.30613[0m[0m | time: 57.447s
[2K
| Adam | epoch: 014 | loss: 0.30613 - acc: 0.8692 -- iter: 0128/2102
[A[ATraining Step: 863  | total loss: [1m[32m0.28958[0m[0m | time: 74.724s
[2K
| Adam | epoch: 014 | loss: 0.28958 - acc: 0.8823 -- iter: 0160/2102
[A[ATraining Step: 864  | total loss: [1m[32m0.29283[0m[0m | time: 88.100s
[2K
| Adam | epoch: 014 | loss: 0.29283 - acc: 0.8753 -- iter: 0192/2102
[A[ATraining Step: 865  | total loss: [1m[32m0.28021[0m[0m | time: 101.029s
[2K
| Adam | epoch: 014 | loss: 0.28021 - acc: 0.8847 -- iter: 0224/2102
[A[ATraining Step: 866  | total loss: [1m[32m0.26304[0m[0m | time: 114.791s
[2K
| Adam | epoch: 014 | loss: 0.26304 - acc: 0.8962 -- iter: 0256/2102
[A[ATraining Step: 867  | total loss: [1m[32m0.27984[0m[0m | time: 128.109s
[2K
| Adam | epoch: 014 | loss: 0.27984 - acc: 0.8878 -- iter: 0288/2102
[A[ATraining Step: 868  | total loss: [1m[32m0.26138[0m[0m | time: 143.015s
[2K
| Adam | epoch: 014 | loss: 0.26138 - acc: 0.8959 -- iter: 0320/2102
[A[ATraining Step: 869  | total loss: [1m[32m0.25730[0m[0m | time: 156.401s
[2K
| Adam | epoch: 014 | loss: 0.25730 - acc: 0.8970 -- iter: 0352/2102
[A[ATraining Step: 870  | total loss: [1m[32m0.24527[0m[0m | time: 166.473s
[2K
| Adam | epoch: 014 | loss: 0.24527 - acc: 0.9010 -- iter: 0384/2102
[A[ATraining Step: 871  | total loss: [1m[32m0.24331[0m[0m | time: 175.648s
[2K
| Adam | epoch: 014 | loss: 0.24331 - acc: 0.9018 -- iter: 0416/2102
[A[ATraining Step: 872  | total loss: [1m[32m0.22757[0m[0m | time: 200.429s
[2K
| Adam | epoch: 014 | loss: 0.22757 - acc: 0.9116 -- iter: 0448/2102
[A[ATraining Step: 873  | total loss: [1m[32m0.21742[0m[0m | time: 213.561s
[2K
| Adam | epoch: 014 | loss: 0.21742 - acc: 0.9173 -- iter: 0480/2102
[A[ATraining Step: 874  | total loss: [1m[32m0.20874[0m[0m | time: 227.030s
[2K
| Adam | epoch: 014 | loss: 0.20874 - acc: 0.9194 -- iter: 0512/2102
[A[ATraining Step: 875  | total loss: [1m[32m0.21733[0m[0m | time: 240.695s
[2K
| Adam | epoch: 014 | loss: 0.21733 - acc: 0.9149 -- iter: 0544/2102
[A[ATraining Step: 876  | total loss: [1m[32m0.23142[0m[0m | time: 254.361s
[2K
| Adam | epoch: 014 | loss: 0.23142 - acc: 0.9172 -- iter: 0576/2102
[A[ATraining Step: 877  | total loss: [1m[32m0.22737[0m[0m | time: 267.881s
[2K
| Adam | epoch: 014 | loss: 0.22737 - acc: 0.9192 -- iter: 0608/2102
[A[ATraining Step: 878  | total loss: [1m[32m0.26171[0m[0m | time: 281.389s
[2K
| Adam | epoch: 014 | loss: 0.26171 - acc: 0.9085 -- iter: 0640/2102
[A[ATraining Step: 879  | total loss: [1m[32m0.25748[0m[0m | time: 299.570s
[2K
| Adam | epoch: 014 | loss: 0.25748 - acc: 0.9083 -- iter: 0672/2102
[A[ATraining Step: 880  | total loss: [1m[32m0.25989[0m[0m | time: 313.407s
[2K
| Adam | epoch: 014 | loss: 0.25989 - acc: 0.9112 -- iter: 0704/2102
[A[ATraining Step: 881  | total loss: [1m[32m0.25152[0m[0m | time: 327.247s
[2K
| Adam | epoch: 014 | loss: 0.25152 - acc: 0.9139 -- iter: 0736/2102
[A[ATraining Step: 882  | total loss: [1m[32m0.23326[0m[0m | time: 341.027s
[2K
| Adam | epoch: 014 | loss: 0.23326 - acc: 0.9225 -- iter: 0768/2102
[A[ATraining Step: 883  | total loss: [1m[32m0.22875[0m[0m | time: 354.794s
[2K
| Adam | epoch: 014 | loss: 0.22875 - acc: 0.9209 -- iter: 0800/2102
[A[ATraining Step: 884  | total loss: [1m[32m0.24400[0m[0m | time: 368.239s
[2K
| Adam | epoch: 014 | loss: 0.24400 - acc: 0.9163 -- iter: 0832/2102
[A[ATraining Step: 885  | total loss: [1m[32m0.24735[0m[0m | time: 383.385s
[2K
| Adam | epoch: 014 | loss: 0.24735 - acc: 0.9090 -- iter: 0864/2102
[A[ATraining Step: 886  | total loss: [1m[32m0.23922[0m[0m | time: 398.054s
[2K
| Adam | epoch: 014 | loss: 0.23922 - acc: 0.9056 -- iter: 0896/2102
[A[ATraining Step: 887  | total loss: [1m[32m0.23480[0m[0m | time: 416.689s
[2K
| Adam | epoch: 014 | loss: 0.23480 - acc: 0.9088 -- iter: 0928/2102
[A[ATraining Step: 888  | total loss: [1m[32m0.23062[0m[0m | time: 457.856s
[2K
| Adam | epoch: 014 | loss: 0.23062 - acc: 0.9148 -- iter: 0960/2102
[A[ATraining Step: 889  | total loss: [1m[32m0.22634[0m[0m | time: 475.846s
[2K
| Adam | epoch: 014 | loss: 0.22634 - acc: 0.9171 -- iter: 0992/2102
[A[ATraining Step: 890  | total loss: [1m[32m0.22408[0m[0m | time: 494.394s
[2K
| Adam | epoch: 014 | loss: 0.22408 - acc: 0.9160 -- iter: 1024/2102
[A[ATraining Step: 891  | total loss: [1m[32m0.24457[0m[0m | time: 513.376s
[2K
| Adam | epoch: 014 | loss: 0.24457 - acc: 0.9025 -- iter: 1056/2102
[A[ATraining Step: 892  | total loss: [1m[32m0.23916[0m[0m | time: 528.206s
[2K
| Adam | epoch: 014 | loss: 0.23916 - acc: 0.9060 -- iter: 1088/2102
[A[ATraining Step: 893  | total loss: [1m[32m0.24442[0m[0m | time: 537.640s
[2K
| Adam | epoch: 014 | loss: 0.24442 - acc: 0.8998 -- iter: 1120/2102
[A[ATraining Step: 894  | total loss: [1m[32m0.23245[0m[0m | time: 550.810s
[2K
| Adam | epoch: 014 | loss: 0.23245 - acc: 0.9098 -- iter: 1152/2102
[A[ATraining Step: 895  | total loss: [1m[32m0.24707[0m[0m | time: 563.980s
[2K
| Adam | epoch: 014 | loss: 0.24707 - acc: 0.9063 -- iter: 1184/2102
[A[ATraining Step: 896  | total loss: [1m[32m0.26108[0m[0m | time: 577.791s
[2K
| Adam | epoch: 014 | loss: 0.26108 - acc: 0.9032 -- iter: 1216/2102
[A[ATraining Step: 897  | total loss: [1m[32m0.24667[0m[0m | time: 590.432s
[2K
| Adam | epoch: 014 | loss: 0.24667 - acc: 0.9097 -- iter: 1248/2102
[A[ATraining Step: 898  | total loss: [1m[32m0.25051[0m[0m | time: 603.896s
[2K
| Adam | epoch: 014 | loss: 0.25051 - acc: 0.9031 -- iter: 1280/2102
[A[ATraining Step: 899  | total loss: [1m[32m0.27512[0m[0m | time: 617.204s
[2K
| Adam | epoch: 014 | loss: 0.27512 - acc: 0.8910 -- iter: 1312/2102
[A[ATraining Step: 900  | total loss: [1m[32m0.26079[0m[0m | time: 631.849s
[2K
| Adam | epoch: 014 | loss: 0.26079 - acc: 0.8987 -- iter: 1344/2102
[A[ATraining Step: 901  | total loss: [1m[32m0.26197[0m[0m | time: 645.957s
[2K
| Adam | epoch: 014 | loss: 0.26197 - acc: 0.8964 -- iter: 1376/2102
[A[ATraining Step: 902  | total loss: [1m[32m0.25601[0m[0m | time: 660.659s
[2K
| Adam | epoch: 014 | loss: 0.25601 - acc: 0.8911 -- iter: 1408/2102
[A[ATraining Step: 903  | total loss: [1m[32m0.25971[0m[0m | time: 678.108s
[2K
| Adam | epoch: 014 | loss: 0.25971 - acc: 0.8895 -- iter: 1440/2102
[A[ATraining Step: 904  | total loss: [1m[32m0.25250[0m[0m | time: 698.336s
[2K
| Adam | epoch: 014 | loss: 0.25250 - acc: 0.8943 -- iter: 1472/2102
[A[ATraining Step: 905  | total loss: [1m[32m0.25932[0m[0m | time: 712.533s
[2K
| Adam | epoch: 014 | loss: 0.25932 - acc: 0.8892 -- iter: 1504/2102
[A[ATraining Step: 906  | total loss: [1m[32m0.24518[0m[0m | time: 725.885s
[2K
| Adam | epoch: 014 | loss: 0.24518 - acc: 0.8941 -- iter: 1536/2102
[A[ATraining Step: 907  | total loss: [1m[32m0.23580[0m[0m | time: 740.269s
[2K
| Adam | epoch: 014 | loss: 0.23580 - acc: 0.8984 -- iter: 1568/2102
[A[ATraining Step: 908  | total loss: [1m[32m0.24106[0m[0m | time: 753.817s
[2K
| Adam | epoch: 014 | loss: 0.24106 - acc: 0.8961 -- iter: 1600/2102
[A[ATraining Step: 909  | total loss: [1m[32m0.25338[0m[0m | time: 766.766s
[2K
| Adam | epoch: 014 | loss: 0.25338 - acc: 0.8846 -- iter: 1632/2102
[A[ATraining Step: 910  | total loss: [1m[32m0.25815[0m[0m | time: 780.054s
[2K
| Adam | epoch: 014 | loss: 0.25815 - acc: 0.8868 -- iter: 1664/2102
[A[ATraining Step: 911  | total loss: [1m[32m0.25419[0m[0m | time: 793.257s
[2K
| Adam | epoch: 014 | loss: 0.25419 - acc: 0.8856 -- iter: 1696/2102
[A[ATraining Step: 912  | total loss: [1m[32m0.28005[0m[0m | time: 807.807s
[2K
| Adam | epoch: 014 | loss: 0.28005 - acc: 0.8814 -- iter: 1728/2102
[A[ATraining Step: 913  | total loss: [1m[32m0.27878[0m[0m | time: 820.743s
[2K
| Adam | epoch: 014 | loss: 0.27878 - acc: 0.8839 -- iter: 1760/2102
[A[ATraining Step: 914  | total loss: [1m[32m0.26931[0m[0m | time: 833.864s
[2K
| Adam | epoch: 014 | loss: 0.26931 - acc: 0.8924 -- iter: 1792/2102
[A[ATraining Step: 915  | total loss: [1m[32m0.26908[0m[0m | time: 848.265s
[2K
| Adam | epoch: 014 | loss: 0.26908 - acc: 0.8969 -- iter: 1824/2102
[A[ATraining Step: 916  | total loss: [1m[32m0.26636[0m[0m | time: 864.784s
[2K
| Adam | epoch: 014 | loss: 0.26636 - acc: 0.8978 -- iter: 1856/2102
[A[ATraining Step: 917  | total loss: [1m[32m0.26977[0m[0m | time: 878.202s
[2K
| Adam | epoch: 014 | loss: 0.26977 - acc: 0.8955 -- iter: 1888/2102
[A[ATraining Step: 918  | total loss: [1m[32m0.27090[0m[0m | time: 891.344s
[2K
| Adam | epoch: 014 | loss: 0.27090 - acc: 0.8966 -- iter: 1920/2102
[A[ATraining Step: 919  | total loss: [1m[32m0.26269[0m[0m | time: 905.251s
[2K
| Adam | epoch: 014 | loss: 0.26269 - acc: 0.9007 -- iter: 1952/2102
[A[ATraining Step: 920  | total loss: [1m[32m0.25309[0m[0m | time: 918.598s
[2K
| Adam | epoch: 014 | loss: 0.25309 - acc: 0.9044 -- iter: 1984/2102
[A[ATraining Step: 921  | total loss: [1m[32m0.25299[0m[0m | time: 934.409s
[2K
| Adam | epoch: 014 | loss: 0.25299 - acc: 0.9046 -- iter: 2016/2102
[A[ATraining Step: 922  | total loss: [1m[32m0.26264[0m[0m | time: 947.831s
[2K
| Adam | epoch: 014 | loss: 0.26264 - acc: 0.8985 -- iter: 2048/2102
[A[ATraining Step: 923  | total loss: [1m[32m0.25024[0m[0m | time: 960.808s
[2K
| Adam | epoch: 014 | loss: 0.25024 - acc: 0.8993 -- iter: 2080/2102
[A[ATraining Step: 924  | total loss: [1m[32m0.25197[0m[0m | time: 1037.531s
[2K
| Adam | epoch: 014 | loss: 0.25197 - acc: 0.9031 | val_loss: 0.79789 - val_acc: 0.7188 -- iter: 2102/2102
--
Training Step: 925  | total loss: [1m[32m0.25746[0m[0m | time: 12.735s
[2K
| Adam | epoch: 015 | loss: 0.25746 - acc: 0.8972 -- iter: 0032/2102
[A[ATraining Step: 926  | total loss: [1m[32m0.25631[0m[0m | time: 25.651s
[2K
| Adam | epoch: 015 | loss: 0.25631 - acc: 0.8887 -- iter: 0064/2102
[A[ATraining Step: 927  | total loss: [1m[32m0.25536[0m[0m | time: 38.617s
[2K
| Adam | epoch: 015 | loss: 0.25536 - acc: 0.8873 -- iter: 0096/2102
[A[ATraining Step: 928  | total loss: [1m[32m0.26084[0m[0m | time: 51.111s
[2K
| Adam | epoch: 015 | loss: 0.26084 - acc: 0.8861 -- iter: 0128/2102
[A[ATraining Step: 929  | total loss: [1m[32m0.26043[0m[0m | time: 64.160s
[2K
| Adam | epoch: 015 | loss: 0.26043 - acc: 0.8912 -- iter: 0160/2102
[A[ATraining Step: 930  | total loss: [1m[32m0.25360[0m[0m | time: 77.102s
[2K
| Adam | epoch: 015 | loss: 0.25360 - acc: 0.8990 -- iter: 0192/2102
[A[ATraining Step: 931  | total loss: [1m[32m0.25021[0m[0m | time: 90.016s
[2K
| Adam | epoch: 015 | loss: 0.25021 - acc: 0.8966 -- iter: 0224/2102
[A[ATraining Step: 932  | total loss: [1m[32m0.24326[0m[0m | time: 103.327s
[2K
| Adam | epoch: 015 | loss: 0.24326 - acc: 0.9007 -- iter: 0256/2102
[A[ATraining Step: 933  | total loss: [1m[32m0.23343[0m[0m | time: 116.559s
[2K
| Adam | epoch: 015 | loss: 0.23343 - acc: 0.9075 -- iter: 0288/2102
[A[ATraining Step: 934  | total loss: [1m[32m0.22070[0m[0m | time: 129.496s
[2K
| Adam | epoch: 015 | loss: 0.22070 - acc: 0.9167 -- iter: 0320/2102
[A[ATraining Step: 935  | total loss: [1m[32m0.23336[0m[0m | time: 142.732s
[2K
| Adam | epoch: 015 | loss: 0.23336 - acc: 0.9032 -- iter: 0352/2102
[A[ATraining Step: 936  | total loss: [1m[32m0.22910[0m[0m | time: 156.092s
[2K
| Adam | epoch: 015 | loss: 0.22910 - acc: 0.9066 -- iter: 0384/2102
[A[ATraining Step: 937  | total loss: [1m[32m0.21767[0m[0m | time: 165.831s
[2K
| Adam | epoch: 015 | loss: 0.21767 - acc: 0.9128 -- iter: 0416/2102
[A[ATraining Step: 938  | total loss: [1m[32m0.25637[0m[0m | time: 175.037s
[2K
| Adam | epoch: 015 | loss: 0.25637 - acc: 0.8988 -- iter: 0448/2102
[A[ATraining Step: 939  | total loss: [1m[32m0.25683[0m[0m | time: 188.376s
[2K
| Adam | epoch: 015 | loss: 0.25683 - acc: 0.8998 -- iter: 0480/2102
[A[ATraining Step: 940  | total loss: [1m[32m0.24145[0m[0m | time: 202.404s
[2K
| Adam | epoch: 015 | loss: 0.24145 - acc: 0.9036 -- iter: 0512/2102
[A[ATraining Step: 941  | total loss: [1m[32m0.22776[0m[0m | time: 226.537s
[2K
| Adam | epoch: 015 | loss: 0.22776 - acc: 0.9101 -- iter: 0544/2102
[A[ATraining Step: 942  | total loss: [1m[32m0.23801[0m[0m | time: 239.246s
[2K
| Adam | epoch: 015 | loss: 0.23801 - acc: 0.9004 -- iter: 0576/2102
[A[ATraining Step: 943  | total loss: [1m[32m0.23611[0m[0m | time: 252.027s
[2K
| Adam | epoch: 015 | loss: 0.23611 - acc: 0.8978 -- iter: 0608/2102
[A[ATraining Step: 944  | total loss: [1m[32m0.23538[0m[0m | time: 264.985s
[2K
| Adam | epoch: 015 | loss: 0.23538 - acc: 0.8987 -- iter: 0640/2102
[A[ATraining Step: 945  | total loss: [1m[32m0.26137[0m[0m | time: 277.497s
[2K
| Adam | epoch: 015 | loss: 0.26137 - acc: 0.8869 -- iter: 0672/2102
[A[ATraining Step: 946  | total loss: [1m[32m0.26071[0m[0m | time: 292.293s
[2K
| Adam | epoch: 015 | loss: 0.26071 - acc: 0.8857 -- iter: 0704/2102
[A[ATraining Step: 947  | total loss: [1m[32m0.28090[0m[0m | time: 305.106s
[2K
| Adam | epoch: 015 | loss: 0.28090 - acc: 0.8784 -- iter: 0736/2102
[A[ATraining Step: 948  | total loss: [1m[32m0.29642[0m[0m | time: 317.986s
[2K
| Adam | epoch: 015 | loss: 0.29642 - acc: 0.8718 -- iter: 0768/2102
[A[ATraining Step: 949  | total loss: [1m[32m0.31347[0m[0m | time: 330.855s
[2K
| Adam | epoch: 015 | loss: 0.31347 - acc: 0.8659 -- iter: 0800/2102
[A[ATraining Step: 950  | total loss: [1m[32m0.31472[0m[0m | time: 344.787s
[2K
| Adam | epoch: 015 | loss: 0.31472 - acc: 0.8699 -- iter: 0832/2102
[A[ATraining Step: 951  | total loss: [1m[32m0.31581[0m[0m | time: 357.087s
[2K
| Adam | epoch: 015 | loss: 0.31581 - acc: 0.8767 -- iter: 0864/2102
[A[ATraining Step: 952  | total loss: [1m[32m0.30669[0m[0m | time: 376.134s
[2K
| Adam | epoch: 015 | loss: 0.30669 - acc: 0.8796 -- iter: 0896/2102
[A[ATraining Step: 953  | total loss: [1m[32m0.29156[0m[0m | time: 408.935s
[2K
| Adam | epoch: 015 | loss: 0.29156 - acc: 0.8854 -- iter: 0928/2102
[A[ATraining Step: 954  | total loss: [1m[32m0.27796[0m[0m | time: 423.946s
[2K
| Adam | epoch: 015 | loss: 0.27796 - acc: 0.8906 -- iter: 0960/2102
[A[ATraining Step: 955  | total loss: [1m[32m0.30759[0m[0m | time: 441.954s
[2K
| Adam | epoch: 015 | loss: 0.30759 - acc: 0.8828 -- iter: 0992/2102
[A[ATraining Step: 956  | total loss: [1m[32m0.30468[0m[0m | time: 457.663s
[2K
| Adam | epoch: 015 | loss: 0.30468 - acc: 0.8820 -- iter: 1024/2102
[A[ATraining Step: 957  | total loss: [1m[32m0.30218[0m[0m | time: 470.681s
[2K
| Adam | epoch: 015 | loss: 0.30218 - acc: 0.8813 -- iter: 1056/2102
[A[ATraining Step: 958  | total loss: [1m[32m0.29900[0m[0m | time: 479.144s
[2K
| Adam | epoch: 015 | loss: 0.29900 - acc: 0.8776 -- iter: 1088/2102
[A[ATraining Step: 959  | total loss: [1m[32m0.28564[0m[0m | time: 487.850s
[2K
| Adam | epoch: 015 | loss: 0.28564 - acc: 0.8836 -- iter: 1120/2102
[A[ATraining Step: 960  | total loss: [1m[32m0.28614[0m[0m | time: 496.225s
[2K
| Adam | epoch: 015 | loss: 0.28614 - acc: 0.8796 -- iter: 1152/2102
[A[ATraining Step: 961  | total loss: [1m[32m0.28224[0m[0m | time: 506.037s
[2K
| Adam | epoch: 015 | loss: 0.28224 - acc: 0.8760 -- iter: 1184/2102
[A[ATraining Step: 962  | total loss: [1m[32m0.27090[0m[0m | time: 518.649s
[2K
| Adam | epoch: 015 | loss: 0.27090 - acc: 0.8822 -- iter: 1216/2102
[A[ATraining Step: 963  | total loss: [1m[32m0.28683[0m[0m | time: 531.630s
[2K
| Adam | epoch: 015 | loss: 0.28683 - acc: 0.8721 -- iter: 1248/2102
[A[ATraining Step: 964  | total loss: [1m[32m0.30242[0m[0m | time: 545.056s
[2K
| Adam | epoch: 015 | loss: 0.30242 - acc: 0.8692 -- iter: 1280/2102
[A[ATraining Step: 965  | total loss: [1m[32m0.31722[0m[0m | time: 559.787s
[2K
| Adam | epoch: 015 | loss: 0.31722 - acc: 0.8604 -- iter: 1312/2102
[A[ATraining Step: 966  | total loss: [1m[32m0.32347[0m[0m | time: 572.689s
[2K
| Adam | epoch: 015 | loss: 0.32347 - acc: 0.8556 -- iter: 1344/2102
[A[ATraining Step: 967  | total loss: [1m[32m0.32240[0m[0m | time: 585.769s
[2K
| Adam | epoch: 015 | loss: 0.32240 - acc: 0.8576 -- iter: 1376/2102
[A[ATraining Step: 968  | total loss: [1m[32m0.31228[0m[0m | time: 598.685s
[2K
| Adam | epoch: 015 | loss: 0.31228 - acc: 0.8593 -- iter: 1408/2102
[A[ATraining Step: 969  | total loss: [1m[32m0.31839[0m[0m | time: 611.523s
[2K
| Adam | epoch: 015 | loss: 0.31839 - acc: 0.8578 -- iter: 1440/2102
[A[ATraining Step: 970  | total loss: [1m[32m0.31409[0m[0m | time: 625.594s
[2K
| Adam | epoch: 015 | loss: 0.31409 - acc: 0.8564 -- iter: 1472/2102
[A[ATraining Step: 971  | total loss: [1m[32m0.34025[0m[0m | time: 639.515s
[2K
| Adam | epoch: 015 | loss: 0.34025 - acc: 0.8551 -- iter: 1504/2102
[A[ATraining Step: 972  | total loss: [1m[32m0.33727[0m[0m | time: 664.074s
[2K
| Adam | epoch: 015 | loss: 0.33727 - acc: 0.8633 -- iter: 1536/2102
[A[ATraining Step: 973  | total loss: [1m[32m0.31153[0m[0m | time: 677.345s
[2K
| Adam | epoch: 015 | loss: 0.31153 - acc: 0.8770 -- iter: 1568/2102
[A[ATraining Step: 974  | total loss: [1m[32m0.29293[0m[0m | time: 690.509s
[2K
| Adam | epoch: 015 | loss: 0.29293 - acc: 0.8831 -- iter: 1600/2102
[A[ATraining Step: 975  | total loss: [1m[32m0.29162[0m[0m | time: 703.946s
[2K
| Adam | epoch: 015 | loss: 0.29162 - acc: 0.8822 -- iter: 1632/2102
[A[ATraining Step: 976  | total loss: [1m[32m0.27274[0m[0m | time: 719.811s
[2K
| Adam | epoch: 015 | loss: 0.27274 - acc: 0.8909 -- iter: 1664/2102
[A[ATraining Step: 977  | total loss: [1m[32m0.25463[0m[0m | time: 738.278s
[2K
| Adam | epoch: 015 | loss: 0.25463 - acc: 0.8987 -- iter: 1696/2102
[A[ATraining Step: 978  | total loss: [1m[32m0.25414[0m[0m | time: 750.999s
[2K
| Adam | epoch: 015 | loss: 0.25414 - acc: 0.9026 -- iter: 1728/2102
[A[ATraining Step: 979  | total loss: [1m[32m0.23970[0m[0m | time: 763.692s
[2K
| Adam | epoch: 015 | loss: 0.23970 - acc: 0.9092 -- iter: 1760/2102
[A[ATraining Step: 980  | total loss: [1m[32m0.24353[0m[0m | time: 776.668s
[2K
| Adam | epoch: 015 | loss: 0.24353 - acc: 0.9058 -- iter: 1792/2102
[A[ATraining Step: 981  | total loss: [1m[32m0.24627[0m[0m | time: 790.259s
[2K
| Adam | epoch: 015 | loss: 0.24627 - acc: 0.8996 -- iter: 1824/2102
[A[ATraining Step: 982  | total loss: [1m[32m0.24332[0m[0m | time: 803.514s
[2K
| Adam | epoch: 015 | loss: 0.24332 - acc: 0.8971 -- iter: 1856/2102
[A[ATraining Step: 983  | total loss: [1m[32m0.25097[0m[0m | time: 817.128s
[2K
| Adam | epoch: 015 | loss: 0.25097 - acc: 0.8886 -- iter: 1888/2102
[A[ATraining Step: 984  | total loss: [1m[32m0.24558[0m[0m | time: 830.494s
[2K
| Adam | epoch: 015 | loss: 0.24558 - acc: 0.8935 -- iter: 1920/2102
[A[ATraining Step: 985  | total loss: [1m[32m0.24069[0m[0m | time: 844.301s
[2K
| Adam | epoch: 015 | loss: 0.24069 - acc: 0.8917 -- iter: 1952/2102
[A[ATraining Step: 986  | total loss: [1m[32m0.23641[0m[0m | time: 858.036s
[2K
| Adam | epoch: 015 | loss: 0.23641 - acc: 0.8963 -- iter: 1984/2102
[A[ATraining Step: 987  | total loss: [1m[32m0.22354[0m[0m | time: 871.592s
[2K
| Adam | epoch: 015 | loss: 0.22354 - acc: 0.9035 -- iter: 2016/2102
[A[ATraining Step: 988  | total loss: [1m[32m0.21311[0m[0m | time: 884.639s
[2K
| Adam | epoch: 015 | loss: 0.21311 - acc: 0.9069 -- iter: 2048/2102
[A[ATraining Step: 989  | total loss: [1m[32m0.21616[0m[0m | time: 897.911s
[2K
| Adam | epoch: 015 | loss: 0.21616 - acc: 0.9037 -- iter: 2080/2102
[A[ATraining Step: 990  | total loss: [1m[32m0.21152[0m[0m | time: 986.120s
[2K
| Adam | epoch: 015 | loss: 0.21152 - acc: 0.9071 | val_loss: 1.12999 - val_acc: 0.6915 -- iter: 2102/2102
--
2018-09-06 23:55:49.132319: W tensorflow/core/framework/allocator.cc:101] Allocation of 1467518976 exceeds 10% of system memory.
2018-09-06 23:55:53.521283: W tensorflow/core/framework/allocator.cc:101] Allocation of 1423385600 exceeds 10% of system memory.
2018-09-06 23:56:15.481690: W tensorflow/core/framework/allocator.cc:101] Allocation of 2846771200 exceeds 10% of system memory.
2018-09-06 23:56:58.705576: W tensorflow/core/framework/allocator.cc:101] Allocation of 1942542336 exceeds 10% of system memory.
2018-09-07 00:01:27.268946: W tensorflow/core/framework/allocator.cc:101] Allocation of 1467518976 exceeds 10% of system memory.
2018-09-07 00:01:31.079034: W tensorflow/core/framework/allocator.cc:101] Allocation of 1423385600 exceeds 10% of system memory.
2018-09-07 00:01:54.858728: W tensorflow/core/framework/allocator.cc:101] Allocation of 2846771200 exceeds 10% of system memory.
2018-09-07 00:02:13.131900: W tensorflow/core/framework/allocator.cc:101] Allocation of 1942542336 exceeds 10% of system memory.
Validation AUC:0.7854558823529412
Validation AUPRC:0.8501264847334635
Test AUC:0.7612398342795764
Test AUPRC:0.7960716775649082
BestTestF1Score	0.78	0.38	0.71	0.7	0.89	348	148	118	44	0.87
BestTestMCCScore	0.72	0.38	0.69	0.78	0.68	266	77	189	126	0.99
BestTestAccuracyScore	0.75	0.4	0.71	0.76	0.74	292	92	174	100	0.98
BestValidationF1Score	0.8	0.39	0.72	0.73	0.88	360	134	116	48	0.87
BestValidationMCC	0.77	0.45	0.73	0.82	0.72	293	65	185	115	0.99
BestValidationAccuracy	0.78	0.44	0.73	0.8	0.76	310	79	171	98	0.98
TestPredictions (Threshold:0.99)
CHEMBL2069408,TN,INACT,0.9200000166893005	CHEMBL2177588,TP,ACT,1.0	CHEMBL2170605,TN,INACT,0.9300000071525574	CHEMBL1088804,FP,INACT,0.9900000095367432	CHEMBL1822850,TP,ACT,1.0	CHEMBL2023918,FP,INACT,1.0	CHEMBL3099945,TP,ACT,1.0	CHEMBL1671904,TN,INACT,0.07999999821186066	CHEMBL3703289,TP,ACT,0.9900000095367432	CHEMBL398450,TN,INACT,0.5	CHEMBL2326480,TP,ACT,1.0	CHEMBL1946619,TN,INACT,0.8999999761581421	CHEMBL35476,TN,INACT,0.9300000071525574	CHEMBL2016937,TP,ACT,0.9900000095367432	CHEMBL3753613,TP,ACT,1.0	CHEMBL258132,TP,ACT,0.9900000095367432	CHEMBL1836166,FN,ACT,0.9399999976158142	CHEMBL206249,TP,ACT,0.9900000095367432	CHEMBL383762,TN,INACT,0.9599999785423279	CHEMBL2333614,TP,ACT,1.0	CHEMBL2022735,TN,INACT,0.949999988079071	CHEMBL3425938,FN,ACT,0.9800000190734863	CHEMBL3357997,FN,ACT,0.9399999976158142	CHEMBL419395,TN,INACT,0.36000001430511475	CHEMBL240185,TN,INACT,0.5799999833106995	CHEMBL550261,FN,ACT,0.949999988079071	CHEMBL1079494,TP,ACT,1.0	CHEMBL1089159,TN,INACT,0.9700000286102295	CHEMBL74977,TN,INACT,0.12999999523162842	CHEMBL72,FN,ACT,0.9399999976158142	CHEMBL488021,FP,INACT,1.0	CHEMBL3823030,FP,INACT,1.0	CHEMBL522044,TP,ACT,1.0	CHEMBL473,TP,ACT,0.9900000095367432	CHEMBL550818,TP,ACT,0.9900000095367432	CHEMBL2031882,FP,INACT,1.0	CHEMBL217789,FN,ACT,0.46000000834465027	CHEMBL2440398,FP,INACT,0.9900000095367432	CHEMBL1957677,FN,ACT,0.9399999976158142	CHEMBL485124,TN,INACT,0.9100000262260437	CHEMBL3813836,TN,INACT,0.9700000286102295	CHEMBL513250,TP,ACT,1.0	CHEMBL272086,TP,ACT,1.0	CHEMBL295124,FP,INACT,1.0	CHEMBL1224142,TP,ACT,1.0	CHEMBL558052,TP,ACT,1.0	CHEMBL1083614,FN,ACT,0.9800000190734863	CHEMBL460217,TP,ACT,1.0	CHEMBL3604691,TP,ACT,1.0	CHEMBL1643511,TP,ACT,1.0	CHEMBL583093,FP,INACT,1.0	CHEMBL1784464,TN,INACT,0.7300000190734863	CHEMBL1836258,TP,ACT,1.0	CHEMBL2151322,TN,INACT,0.949999988079071	CHEMBL1086582,TP,ACT,0.9900000095367432	CHEMBL2441435,TP,ACT,0.9900000095367432	CHEMBL2158050,TN,INACT,0.5199999809265137	CHEMBL3314433,TN,INACT,0.44999998807907104	CHEMBL301956,TP,ACT,1.0	CHEMBL1081747,TP,ACT,1.0	CHEMBL473772,TP,ACT,1.0	CHEMBL3355624,TP,ACT,1.0	CHEMBL253835,TN,INACT,0.9100000262260437	CHEMBL551414,TN,INACT,0.9700000286102295	CHEMBL463585,TP,ACT,0.9900000095367432	CHEMBL1098752,TP,ACT,1.0	CHEMBL1085783,TN,INACT,0.8199999928474426	CHEMBL2024309,TN,INACT,0.9700000286102295	CHEMBL1800168,FN,ACT,0.10000000149011612	CHEMBL2112296,TN,INACT,0.9200000166893005	CHEMBL2177301,TP,ACT,1.0	CHEMBL3219117,TN,INACT,0.9200000166893005	CHEMBL2029418,FP,INACT,1.0	CHEMBL216666,TP,ACT,1.0	CHEMBL3604797,TP,ACT,1.0	CHEMBL3353403,FN,ACT,0.7599999904632568	CHEMBL1085778,TP,ACT,1.0	CHEMBL2041180,TN,INACT,0.7200000286102295	CHEMBL3609641,TP,ACT,1.0	CHEMBL22679,TN,INACT,0.12999999523162842	CHEMBL1097455,TP,ACT,0.9900000095367432	CHEMBL2043324,TN,INACT,0.550000011920929	CHEMBL562569,FN,ACT,0.9800000190734863	CHEMBL2179670,TP,ACT,1.0	CHEMBL2158824,TN,INACT,0.9800000190734863	CHEMBL3808653,TN,INACT,0.8799999952316284	CHEMBL221237,TP,ACT,1.0	CHEMBL52794,TP,ACT,1.0	CHEMBL3233187,TN,INACT,0.009999999776482582	CHEMBL481008,TP,ACT,1.0	CHEMBL283309,TN,INACT,0.3400000035762787	CHEMBL2024389,TN,INACT,0.9800000190734863	CHEMBL562836,TP,ACT,1.0	CHEMBL3425805,FP,INACT,1.0	CHEMBL1822301,TN,INACT,0.25999999046325684	CHEMBL22310,TN,INACT,0.23000000417232513	CHEMBL1779710,TN,INACT,0.7400000095367432	CHEMBL458242,TN,INACT,0.2199999988079071	CHEMBL138093,FN,ACT,0.6899999976158142	CHEMBL3221125,TP,ACT,1.0	CHEMBL3085125,FN,ACT,0.9700000286102295	CHEMBL3742181,TP,ACT,1.0	CHEMBL2036776,TP,ACT,0.9900000095367432	CHEMBL1095846,FN,ACT,0.9800000190734863	CHEMBL1951778,TN,INACT,0.0	CHEMBL1097841,TP,ACT,0.9900000095367432	CHEMBL2158823,FP,INACT,0.9900000095367432	CHEMBL214629,TP,ACT,1.0	CHEMBL2023917,FN,ACT,0.8600000143051147	CHEMBL2204245,FP,INACT,1.0	CHEMBL639,TP,ACT,1.0	CHEMBL556648,FN,ACT,0.8999999761581421	CHEMBL2431016,FP,INACT,0.9900000095367432	CHEMBL597032,TP,ACT,1.0	CHEMBL2179216,FN,ACT,0.9599999785423279	CHEMBL563779,TP,ACT,1.0	CHEMBL378547,FN,ACT,0.9800000190734863	CHEMBL3586433,FN,ACT,0.9200000166893005	CHEMBL573493,FP,INACT,1.0	CHEMBL1241737,TP,ACT,1.0	CHEMBL1835153,FP,INACT,1.0	CHEMBL564840,FP,INACT,1.0	CHEMBL2314057,TN,INACT,0.12999999523162842	CHEMBL2391994,FP,INACT,1.0	CHEMBL514564,TP,ACT,1.0	CHEMBL468302,TP,ACT,0.9900000095367432	CHEMBL2059318,TP,ACT,1.0	CHEMBL455121,TN,INACT,0.6600000262260437	CHEMBL564380,TP,ACT,1.0	CHEMBL3582329,TP,ACT,0.9900000095367432	CHEMBL2333623,FN,ACT,0.9800000190734863	CHEMBL1801191,TP,ACT,0.9900000095367432	CHEMBL1085800,FN,ACT,0.9800000190734863	CHEMBL1172999,FN,ACT,0.27000001072883606	CHEMBL3422977,TP,ACT,0.9900000095367432	CHEMBL2064645,FP,INACT,0.9900000095367432	CHEMBL657,FP,INACT,1.0	CHEMBL1160623,TN,INACT,0.0	CHEMBL3354038,TN,INACT,0.09000000357627869	CHEMBL270227,TP,ACT,1.0	CHEMBL2017104,TN,INACT,0.44999998807907104	CHEMBL1271273,TN,INACT,0.75	CHEMBL368204,TP,ACT,1.0	CHEMBL2012032,TP,ACT,0.9900000095367432	CHEMBL3425929,TN,INACT,0.9700000286102295	CHEMBL3318982,TP,ACT,0.9900000095367432	CHEMBL257716,TP,ACT,1.0	CHEMBL1671897,TP,ACT,1.0	CHEMBL3356249,TN,INACT,0.5099999904632568	CHEMBL2152522,TN,INACT,0.8399999737739563	CHEMBL2146857,TP,ACT,0.9900000095367432	CHEMBL3596509,FN,ACT,0.7599999904632568	CHEMBL465956,TN,INACT,0.029999999329447746	CHEMBL213715,TP,ACT,1.0	CHEMBL2012271,TP,ACT,1.0	CHEMBL3787166,TP,ACT,1.0	CHEMBL561584,FP,INACT,1.0	CHEMBL1008,FN,ACT,0.9599999785423279	CHEMBL225261,TP,ACT,1.0	CHEMBL498729,TP,ACT,0.9900000095367432	CHEMBL1782081,TN,INACT,0.3100000023841858	CHEMBL3217170,FN,ACT,0.6899999976158142	CHEMBL3221482,TN,INACT,0.07000000029802322	CHEMBL3609754,TP,ACT,1.0	CHEMBL220963,TP,ACT,1.0	CHEMBL1290706,TP,ACT,1.0	CHEMBL1080164,TP,ACT,1.0	CHEMBL223999,TP,ACT,1.0	CHEMBL1086273,TN,INACT,0.9800000190734863	CHEMBL2203841,TN,INACT,0.9599999785423279	CHEMBL3289794,TN,INACT,0.9399999976158142	CHEMBL2177910,FN,ACT,0.9800000190734863	CHEMBL2017574,FN,ACT,0.9800000190734863	CHEMBL1642183,TP,ACT,1.0	CHEMBL1951605,TN,INACT,0.41999998688697815	CHEMBL1642477,TP,ACT,1.0	CHEMBL2043004,FN,ACT,0.9100000262260437	CHEMBL23924,TN,INACT,0.8199999928474426	CHEMBL3775734,TP,ACT,1.0	CHEMBL243901,FN,ACT,0.8399999737739563	CHEMBL2146868,TP,ACT,1.0	CHEMBL3422754,TP,ACT,1.0	CHEMBL599480,TP,ACT,1.0	CHEMBL3794249,FN,ACT,0.8999999761581421	CHEMBL345639,FP,INACT,1.0	CHEMBL2204942,TP,ACT,1.0	CHEMBL2031973,TP,ACT,1.0	CHEMBL1795860,TN,INACT,0.8999999761581421	CHEMBL2158814,TN,INACT,0.7900000214576721	CHEMBL3237577,FN,ACT,0.10000000149011612	CHEMBL2376789,FN,ACT,0.9700000286102295	CHEMBL197304,TP,ACT,1.0	CHEMBL1744413,TN,INACT,0.0	CHEMBL2017582,TN,INACT,0.8500000238418579	CHEMBL3785774,FP,INACT,1.0	CHEMBL2440407,FN,ACT,0.8100000023841858	CHEMBL549438,TN,INACT,0.8999999761581421	CHEMBL1290391,TP,ACT,1.0	CHEMBL2208427,FN,ACT,0.9800000190734863	CHEMBL2333261,TN,INACT,0.3499999940395355	CHEMBL2016588,TN,INACT,0.4099999964237213	CHEMBL1258948,TP,ACT,1.0	CHEMBL1094041,FP,INACT,1.0	CHEMBL568523,TN,INACT,0.9300000071525574	CHEMBL495346,TP,ACT,0.9900000095367432	CHEMBL3582334,FP,INACT,1.0	CHEMBL1254085,FP,INACT,1.0	CHEMBL1782566,FN,ACT,0.4099999964237213	CHEMBL2336056,TP,ACT,0.9900000095367432	CHEMBL1673438,TN,INACT,0.9700000286102295	CHEMBL1823051,FN,ACT,0.9800000190734863	CHEMBL3577939,FN,ACT,0.6000000238418579	CHEMBL1257938,TP,ACT,1.0	CHEMBL1162962,TP,ACT,1.0	CHEMBL556183,TP,ACT,0.9900000095367432	CHEMBL3354626,TN,INACT,0.029999999329447746	CHEMBL230812,TN,INACT,0.3700000047683716	CHEMBL442923,TP,ACT,1.0	CHEMBL559477,FP,INACT,0.9900000095367432	CHEMBL3582336,TN,INACT,0.9300000071525574	CHEMBL559878,FN,ACT,0.11999999731779099	CHEMBL1160685,TN,INACT,0.019999999552965164	CHEMBL3314424,TN,INACT,0.3199999928474426	CHEMBL518155,TN,INACT,0.9800000190734863	CHEMBL1829627,FP,INACT,1.0	CHEMBL563998,TP,ACT,1.0	CHEMBL1080969,FN,ACT,0.5799999833106995	CHEMBL1171756,FN,ACT,0.9100000262260437	CHEMBL1926763,TN,INACT,0.03999999910593033	CHEMBL1084384,FP,INACT,1.0	CHEMBL479383,FN,ACT,0.6299999952316284	CHEMBL1093053,FP,INACT,1.0	CHEMBL3585953,FN,ACT,0.8299999833106995	CHEMBL2315926,TN,INACT,0.11999999731779099	CHEMBL3793380,FP,INACT,1.0	CHEMBL571221,FN,ACT,0.9800000190734863	CHEMBL551924,TP,ACT,1.0	CHEMBL556450,TP,ACT,1.0	CHEMBL1956991,FN,ACT,0.949999988079071	CHEMBL2335291,TN,INACT,0.9100000262260437	CHEMBL1642471,TP,ACT,1.0	CHEMBL562285,TP,ACT,1.0	CHEMBL1086506,TP,ACT,1.0	CHEMBL1077638,FN,ACT,0.75	CHEMBL3805898,FN,ACT,0.9599999785423279	CHEMBL486737,FP,INACT,1.0	CHEMBL2333619,FP,INACT,0.9900000095367432	CHEMBL148169,TN,INACT,0.5	CHEMBL3628216,TP,ACT,1.0	CHEMBL3120265,FN,ACT,0.9800000190734863	CHEMBL253024,TP,ACT,1.0	CHEMBL3809389,TN,INACT,0.9300000071525574	CHEMBL1494,FN,ACT,0.949999988079071	CHEMBL2333267,TN,INACT,0.9599999785423279	CHEMBL1271756,TP,ACT,0.9900000095367432	CHEMBL256651,TP,ACT,0.9900000095367432	CHEMBL272022,TP,ACT,1.0	CHEMBL1241824,TP,ACT,1.0	CHEMBL3425800,TN,INACT,0.38999998569488525	CHEMBL2326484,FP,INACT,1.0	CHEMBL257369,TP,ACT,1.0	CHEMBL1819275,FN,ACT,0.949999988079071	CHEMBL2331747,TN,INACT,0.9800000190734863	CHEMBL2331574,TN,INACT,0.47999998927116394	CHEMBL2059305,TP,ACT,1.0	CHEMBL1837038,TN,INACT,0.1899999976158142	CHEMBL44903,TN,INACT,0.10000000149011612	CHEMBL512724,TP,ACT,1.0	CHEMBL3585954,FN,ACT,0.9399999976158142	CHEMBL517023,TN,INACT,0.019999999552965164	CHEMBL3342773,FN,ACT,0.20000000298023224	CHEMBL3323077,TP,ACT,1.0	CHEMBL279176,TN,INACT,0.8199999928474426	CHEMBL3580774,TP,ACT,1.0	CHEMBL2179675,TP,ACT,1.0	CHEMBL1956195,FN,ACT,0.49000000953674316	CHEMBL298817,TN,INACT,0.9300000071525574	CHEMBL17157,TP,ACT,1.0	CHEMBL3594316,TN,INACT,0.7599999904632568	CHEMBL1923115,FN,ACT,0.9800000190734863	CHEMBL585530,FN,ACT,0.7400000095367432	CHEMBL564477,FP,INACT,1.0	CHEMBL2403861,TP,ACT,1.0	CHEMBL123105,TN,INACT,0.05000000074505806	CHEMBL502113,TP,ACT,1.0	CHEMBL2325729,TN,INACT,0.9700000286102295	CHEMBL2313786,TN,INACT,0.20000000298023224	CHEMBL2324257,TP,ACT,1.0	CHEMBL560182,FN,ACT,0.8999999761581421	CHEMBL3422764,TP,ACT,1.0	CHEMBL3142625,TN,INACT,0.0	CHEMBL560140,TP,ACT,1.0	CHEMBL2017597,TP,ACT,1.0	CHEMBL472,FP,INACT,0.9900000095367432	CHEMBL2153098,TN,INACT,0.7900000214576721	CHEMBL3142613,TN,INACT,0.05000000074505806	CHEMBL499555,TP,ACT,1.0	CHEMBL3634813,TP,ACT,1.0	CHEMBL1271380,FN,ACT,0.9800000190734863	CHEMBL2326691,TP,ACT,1.0	CHEMBL401752,TP,ACT,1.0	CHEMBL1823340,TP,ACT,1.0	CHEMBL187079,TN,INACT,0.8700000047683716	CHEMBL1927170,TN,INACT,0.10000000149011612	CHEMBL1916533,TP,ACT,1.0	CHEMBL1086481,TP,ACT,0.9900000095367432	CHEMBL3121667,TP,ACT,1.0	CHEMBL2059320,FN,ACT,0.9700000286102295	CHEMBL2324510,TN,INACT,0.9700000286102295	CHEMBL2152523,TN,INACT,0.5299999713897705	CHEMBL2380444,TP,ACT,1.0	CHEMBL1834794,TN,INACT,0.1599999964237213	CHEMBL1136,TN,INACT,0.9700000286102295	CHEMBL3093984,TP,ACT,0.9900000095367432	CHEMBL3703285,FN,ACT,0.9399999976158142	CHEMBL1949693,FN,ACT,0.9399999976158142	CHEMBL113,FN,ACT,0.699999988079071	CHEMBL2313782,TN,INACT,0.15000000596046448	CHEMBL1644605,TP,ACT,1.0	CHEMBL306585,TN,INACT,0.949999988079071	CHEMBL479,TP,ACT,1.0	CHEMBL3823659,TP,ACT,0.9900000095367432	CHEMBL204508,FN,ACT,0.9800000190734863	CHEMBL471757,FP,INACT,1.0	CHEMBL1242923,FP,INACT,1.0	CHEMBL1818218,FN,ACT,0.9399999976158142	CHEMBL1823676,FP,INACT,0.9900000095367432	CHEMBL3703295,FN,ACT,0.8799999952316284	CHEMBL1290058,TP,ACT,1.0	CHEMBL555347,FN,ACT,0.9599999785423279	CHEMBL3577935,TN,INACT,0.10999999940395355	CHEMBL474421,TN,INACT,0.41999998688697815	CHEMBL366759,TN,INACT,0.25	CHEMBL244347,FN,ACT,0.9800000190734863	CHEMBL1760237,TP,ACT,1.0	CHEMBL3605135,TP,ACT,1.0	CHEMBL3221490,TN,INACT,0.6800000071525574	CHEMBL2393431,TP,ACT,1.0	CHEMBL1830693,FP,INACT,1.0	CHEMBL3330060,TN,INACT,0.5299999713897705	CHEMBL3425810,FN,ACT,0.9300000071525574	CHEMBL231396,TN,INACT,0.7799999713897705	CHEMBL253823,TN,INACT,0.23000000417232513	CHEMBL1642475,TP,ACT,1.0	CHEMBL2069324,FP,INACT,1.0	CHEMBL3408388,TP,ACT,0.9900000095367432	CHEMBL1951604,TN,INACT,0.8100000023841858	CHEMBL3594322,FP,INACT,0.9900000095367432	CHEMBL2346972,FP,INACT,1.0	CHEMBL3221529,TN,INACT,0.9100000262260437	CHEMBL3617406,TN,INACT,0.0	CHEMBL3219001,TP,ACT,1.0	CHEMBL2069927,FP,INACT,0.9900000095367432	CHEMBL126923,FP,INACT,1.0	CHEMBL360861,FN,ACT,0.10000000149011612	CHEMBL253375,TN,INACT,0.3700000047683716	CHEMBL445212,TP,ACT,1.0	CHEMBL3099943,FN,ACT,0.9100000262260437	CHEMBL3758397,FN,ACT,0.9599999785423279	CHEMBL3093950,TP,ACT,0.9900000095367432	CHEMBL3582342,TP,ACT,1.0	CHEMBL469375,TP,ACT,1.0	CHEMBL1957008,TN,INACT,0.8100000023841858	CHEMBL146998,TP,ACT,1.0	CHEMBL1744406,TN,INACT,0.009999999776482582	CHEMBL481806,FP,INACT,0.9900000095367432	CHEMBL29217,TN,INACT,0.36000001430511475	CHEMBL3415589,FP,INACT,0.9900000095367432	CHEMBL550535,FN,ACT,0.8700000047683716	CHEMBL469724,FN,ACT,0.9200000166893005	CHEMBL493515,TP,ACT,0.9900000095367432	CHEMBL148058,TP,ACT,1.0	CHEMBL207850,TP,ACT,1.0	CHEMBL509881,TN,INACT,0.3100000023841858	CHEMBL1910309,FN,ACT,0.949999988079071	CHEMBL1089164,TN,INACT,0.699999988079071	CHEMBL2059315,FP,INACT,1.0	CHEMBL550358,FP,INACT,1.0	CHEMBL3218647,TP,ACT,0.9900000095367432	CHEMBL3425940,FN,ACT,0.8999999761581421	CHEMBL523204,FN,ACT,0.7799999713897705	CHEMBL3596513,FP,INACT,1.0	CHEMBL549825,TP,ACT,0.9900000095367432	CHEMBL53321,TP,ACT,1.0	CHEMBL2324243,TP,ACT,1.0	CHEMBL1671906,FP,INACT,0.9900000095367432	CHEMBL399070,TN,INACT,0.0	CHEMBL1818823,TP,ACT,1.0	CHEMBL1289062,FN,ACT,0.9399999976158142	CHEMBL1085397,FN,ACT,0.9800000190734863	CHEMBL707,TP,ACT,1.0	CHEMBL239099,TP,ACT,1.0	CHEMBL2207280,TP,ACT,0.9900000095367432	CHEMBL374438,TP,ACT,1.0	CHEMBL3422010,TN,INACT,0.550000011920929	CHEMBL437206,TN,INACT,0.029999999329447746	CHEMBL254406,TN,INACT,0.07000000029802322	CHEMBL3604694,TP,ACT,1.0	CHEMBL2069411,TP,ACT,1.0	CHEMBL3217125,TN,INACT,0.03999999910593033	CHEMBL1288674,TP,ACT,1.0	CHEMBL2022729,TN,INACT,0.9800000190734863	CHEMBL244946,TP,ACT,1.0	CHEMBL1079461,TP,ACT,1.0	CHEMBL608151,TP,ACT,1.0	CHEMBL551058,FN,ACT,0.18000000715255737	CHEMBL551281,FN,ACT,0.800000011920929	CHEMBL564948,TP,ACT,1.0	CHEMBL2022997,TP,ACT,1.0	CHEMBL446514,TP,ACT,1.0	CHEMBL3120281,TP,ACT,1.0	CHEMBL1813015,TP,ACT,0.9900000095367432	CHEMBL296397,TP,ACT,1.0	CHEMBL1916539,TN,INACT,0.9300000071525574	CHEMBL1950743,FP,INACT,1.0	CHEMBL247688,FN,ACT,0.9399999976158142	CHEMBL1834852,FN,ACT,0.4300000071525574	CHEMBL1951610,TP,ACT,1.0	CHEMBL3120293,FN,ACT,0.6399999856948853	CHEMBL2391804,FP,INACT,1.0	CHEMBL3609631,TP,ACT,1.0	CHEMBL1782571,FN,ACT,0.6399999856948853	CHEMBL3215681,TN,INACT,0.9200000166893005	CHEMBL259732,TP,ACT,1.0	CHEMBL1092108,TP,ACT,1.0	CHEMBL3218887,TN,INACT,0.9700000286102295	CHEMBL2431031,TN,INACT,0.9800000190734863	CHEMBL2022499,FN,ACT,0.9800000190734863	CHEMBL3086045,TP,ACT,1.0	CHEMBL557648,FN,ACT,0.9700000286102295	CHEMBL457930,FN,ACT,0.9800000190734863	CHEMBL1951603,TP,ACT,1.0	CHEMBL240876,TP,ACT,0.9900000095367432	CHEMBL1829615,FP,INACT,0.9900000095367432	CHEMBL549639,TP,ACT,1.0	CHEMBL3747356,FP,INACT,1.0	CHEMBL472363,TP,ACT,1.0	CHEMBL3415598,FP,INACT,0.9900000095367432	CHEMBL1083706,TP,ACT,1.0	CHEMBL1253992,TN,INACT,0.8100000023841858	CHEMBL1084577,FN,ACT,0.41999998688697815	CHEMBL2325207,FN,ACT,0.8999999761581421	CHEMBL2159347,TP,ACT,1.0	CHEMBL364102,TN,INACT,0.009999999776482582	CHEMBL3823914,TN,INACT,0.8199999928474426	CHEMBL273235,TP,ACT,1.0	CHEMBL404404,TP,ACT,1.0	CHEMBL1107,TP,ACT,1.0	CHEMBL195378,FP,INACT,1.0	CHEMBL475723,TN,INACT,0.3199999928474426	CHEMBL2204587,TP,ACT,1.0	CHEMBL403340,TN,INACT,0.009999999776482582	CHEMBL240840,TP,ACT,1.0	CHEMBL43206,TN,INACT,0.009999999776482582	CHEMBL3415585,FN,ACT,0.8500000238418579	CHEMBL564347,TP,ACT,1.0	CHEMBL2204586,FN,ACT,0.949999988079071	CHEMBL3609630,TP,ACT,1.0	CHEMBL1822855,TP,ACT,1.0	CHEMBL1927166,TN,INACT,0.009999999776482582	CHEMBL493679,TP,ACT,0.9900000095367432	CHEMBL3261926,FP,INACT,1.0	CHEMBL225311,TP,ACT,1.0	CHEMBL199015,TN,INACT,0.9599999785423279	CHEMBL1095554,TP,ACT,0.9900000095367432	CHEMBL3188024,TN,INACT,0.7599999904632568	CHEMBL3356251,TN,INACT,0.0	CHEMBL3774411,TP,ACT,1.0	CHEMBL3417045,TP,ACT,1.0	CHEMBL255389,TP,ACT,0.9900000095367432	CHEMBL492449,TP,ACT,1.0	CHEMBL3221111,TP,ACT,1.0	CHEMBL194564,FN,ACT,0.9399999976158142	CHEMBL2022501,FP,INACT,1.0	CHEMBL1916537,TN,INACT,0.6600000262260437	CHEMBL3218890,FP,INACT,1.0	CHEMBL1784476,TN,INACT,0.9800000190734863	CHEMBL43276,TN,INACT,0.9800000190734863	CHEMBL1258949,TP,ACT,1.0	CHEMBL466000,TN,INACT,0.11999999731779099	CHEMBL1080584,TP,ACT,1.0	CHEMBL487066,FN,ACT,0.9599999785423279	CHEMBL2324261,FN,ACT,0.9399999976158142	CHEMBL3604802,TP,ACT,1.0	CHEMBL2324246,TP,ACT,1.0	CHEMBL2441436,TP,ACT,1.0	CHEMBL1823670,TN,INACT,0.8700000047683716	CHEMBL3359261,FP,INACT,0.9900000095367432	CHEMBL1910317,FN,ACT,0.949999988079071	CHEMBL254006,TN,INACT,0.3400000035762787	CHEMBL1923112,TN,INACT,0.9800000190734863	CHEMBL561379,TN,INACT,0.10999999940395355	CHEMBL470581,TP,ACT,1.0	CHEMBL1257577,TP,ACT,1.0	CHEMBL558726,TP,ACT,1.0	CHEMBL2203847,FN,ACT,0.949999988079071	CHEMBL1682272,TN,INACT,0.9300000071525574	CHEMBL1952113,TP,ACT,1.0	CHEMBL1335679,TN,INACT,0.6399999856948853	CHEMBL2165068,TN,INACT,0.8600000143051147	CHEMBL2436978,FP,INACT,1.0	CHEMBL3354688,TP,ACT,1.0	CHEMBL210273,TP,ACT,1.0	CHEMBL2312932,TN,INACT,0.019999999552965164	CHEMBL2017581,FP,INACT,1.0	CHEMBL474484,TN,INACT,0.9800000190734863	CHEMBL205447,TP,ACT,1.0	CHEMBL219074,TN,INACT,0.05999999865889549	CHEMBL2204270,FN,ACT,0.9599999785423279	CHEMBL1671892,FN,ACT,0.8999999761581421	CHEMBL554914,TN,INACT,0.9200000166893005	CHEMBL3582343,FP,INACT,0.9900000095367432	CHEMBL375019,FN,ACT,0.9100000262260437	CHEMBL2177912,TP,ACT,1.0	CHEMBL1257348,TP,ACT,1.0	CHEMBL511205,TP,ACT,0.9900000095367432	CHEMBL3290339,FP,INACT,1.0	CHEMBL270852,TP,ACT,1.0	CHEMBL2147225,TP,ACT,1.0	CHEMBL1834785,FN,ACT,0.7400000095367432	CHEMBL3330823,FN,ACT,0.9399999976158142	CHEMBL1926766,TN,INACT,0.009999999776482582	CHEMBL1829605,TP,ACT,1.0	CHEMBL2380458,FP,INACT,0.9900000095367432	CHEMBL1796070,TN,INACT,0.9599999785423279	CHEMBL485125,TN,INACT,0.949999988079071	CHEMBL3605117,TP,ACT,1.0	CHEMBL1957797,TP,ACT,1.0	CHEMBL2010841,TP,ACT,1.0	CHEMBL1086074,TN,INACT,0.9700000286102295	CHEMBL3785486,TN,INACT,0.8999999761581421	CHEMBL605785,TN,INACT,0.10000000149011612	CHEMBL590593,FN,ACT,0.5299999713897705	CHEMBL37147,TN,INACT,0.07000000029802322	CHEMBL3808957,FP,INACT,1.0	CHEMBL2326686,FP,INACT,1.0	CHEMBL1082111,TP,ACT,1.0	CHEMBL1257698,TP,ACT,1.0	CHEMBL450714,TP,ACT,1.0	CHEMBL174004,TP,ACT,1.0	CHEMBL520543,FN,ACT,0.11999999731779099	CHEMBL3775301,TP,ACT,1.0	CHEMBL1209217,FN,ACT,0.3499999940395355	CHEMBL1795910,FP,INACT,1.0	CHEMBL1950747,TN,INACT,0.9800000190734863	CHEMBL1834631,FN,ACT,0.699999988079071	CHEMBL508861,TP,ACT,1.0	CHEMBL1083705,TP,ACT,1.0	CHEMBL556247,FN,ACT,0.9800000190734863	CHEMBL2158820,TN,INACT,0.9100000262260437	CHEMBL1083429,TN,INACT,0.8999999761581421	CHEMBL2069400,TP,ACT,1.0	CHEMBL1819274,TP,ACT,1.0	CHEMBL3221507,FP,INACT,1.0	CHEMBL3775414,TP,ACT,1.0	CHEMBL3596518,TN,INACT,0.09000000357627869	CHEMBL550405,FN,ACT,0.7400000095367432	CHEMBL3221530,TN,INACT,0.8299999833106995	CHEMBL43697,TP,ACT,0.9900000095367432	CHEMBL3734964,FP,INACT,0.9900000095367432	CHEMBL521830,TP,ACT,0.9900000095367432	CHEMBL3221522,TP,ACT,1.0	CHEMBL217400,TP,ACT,1.0	CHEMBL3792542,FN,ACT,0.8799999952316284	CHEMBL3219119,TN,INACT,0.9800000190734863	CHEMBL453631,TP,ACT,1.0	CHEMBL1289516,TP,ACT,1.0	CHEMBL3775284,TP,ACT,1.0	CHEMBL1834783,FN,ACT,0.7400000095367432	CHEMBL487708,FN,ACT,0.9700000286102295	CHEMBL3087669,FP,INACT,1.0	CHEMBL485620,TN,INACT,0.7599999904632568	CHEMBL512975,TN,INACT,0.8899999856948853	CHEMBL3422978,TP,ACT,0.9900000095367432	CHEMBL3422008,FN,ACT,0.9800000190734863	CHEMBL476954,TN,INACT,0.7799999713897705	CHEMBL360704,TN,INACT,0.8600000143051147	CHEMBL2017573,TN,INACT,0.9599999785423279	CHEMBL1951899,TP,ACT,0.9900000095367432	CHEMBL3287739,TN,INACT,0.33000001311302185	CHEMBL611369,TP,ACT,0.9900000095367432	CHEMBL2314052,TN,INACT,0.12999999523162842	CHEMBL408479,TN,INACT,0.0	CHEMBL3741735,TP,ACT,0.9900000095367432	CHEMBL552367,TP,ACT,1.0	CHEMBL3808921,FN,ACT,0.8299999833106995	CHEMBL1642491,TP,ACT,1.0	CHEMBL1829631,FP,INACT,1.0	CHEMBL1935114,FP,INACT,1.0	CHEMBL1094549,TP,ACT,1.0	CHEMBL1956988,FN,ACT,0.949999988079071	CHEMBL1762805,FN,ACT,0.9800000190734863	CHEMBL1258034,TP,ACT,1.0	CHEMBL458953,TP,ACT,1.0	CHEMBL2146874,TP,ACT,1.0	CHEMBL551347,TP,ACT,1.0	CHEMBL1935441,TP,ACT,1.0	CHEMBL2164397,TN,INACT,0.9200000166893005	CHEMBL209240,TP,ACT,1.0	CHEMBL3085127,TP,ACT,1.0	CHEMBL1980297,TP,ACT,1.0	CHEMBL2017586,FN,ACT,0.9800000190734863	CHEMBL217707,FN,ACT,0.9700000286102295	CHEMBL117225,TN,INACT,0.36000001430511475	CHEMBL1834634,FN,ACT,0.7799999713897705	CHEMBL2208430,FN,ACT,0.9800000190734863	CHEMBL3221511,TN,INACT,0.4399999976158142	CHEMBL339610,TN,INACT,0.9700000286102295	CHEMBL3218908,FN,ACT,0.9200000166893005	CHEMBL1085805,TP,ACT,1.0	CHEMBL555744,FN,ACT,0.8199999928474426	CHEMBL1951916,FN,ACT,0.699999988079071	CHEMBL1823044,TP,ACT,0.9900000095367432	CHEMBL572163,TP,ACT,1.0	CHEMBL3221515,TN,INACT,0.9800000190734863	CHEMBL502288,FN,ACT,0.07000000029802322	CHEMBL1092650,TP,ACT,1.0	CHEMBL3112968,TP,ACT,1.0	CHEMBL1934520,TP,ACT,0.9900000095367432	CHEMBL3785621,TN,INACT,0.11999999731779099	CHEMBL3774588,TP,ACT,1.0	CHEMBL3612927,FN,ACT,0.949999988079071	CHEMBL1927167,FN,ACT,0.11999999731779099	CHEMBL1257565,FN,ACT,0.9800000190734863	CHEMBL1672351,FN,ACT,0.9200000166893005	CHEMBL2333622,TP,ACT,1.0	CHEMBL2347419,TP,ACT,0.9900000095367432	CHEMBL3085132,TP,ACT,1.0	CHEMBL2315930,TN,INACT,0.9300000071525574	CHEMBL3355597,TN,INACT,0.7099999785423279	CHEMBL556478,TP,ACT,1.0	CHEMBL246050,TN,INACT,0.949999988079071	CHEMBL3736135,TN,INACT,0.949999988079071	CHEMBL552460,TN,INACT,0.9800000190734863	CHEMBL1950167,TP,ACT,1.0	CHEMBL2409400,TN,INACT,0.8899999856948853	CHEMBL1084581,FP,INACT,1.0	CHEMBL307429,TN,INACT,0.8600000143051147	CHEMBL508712,TP,ACT,1.0	CHEMBL3593327,TN,INACT,0.2199999988079071	CHEMBL1097,TN,INACT,0.7699999809265137	CHEMBL3585955,TP,ACT,0.9900000095367432	CHEMBL455511,TP,ACT,0.9900000095367432	CHEMBL3605126,TP,ACT,1.0	CHEMBL1771103,TP,ACT,0.9900000095367432	CHEMBL3775408,TP,ACT,1.0	CHEMBL2425060,FP,INACT,0.9900000095367432	CHEMBL2147221,FN,ACT,0.949999988079071	CHEMBL1829621,TP,ACT,0.9900000095367432	CHEMBL3357994,FN,ACT,0.9599999785423279	CHEMBL3650845,TN,INACT,0.019999999552965164	CHEMBL3787345,TN,INACT,0.9700000286102295	CHEMBL2069929,TN,INACT,0.07000000029802322	CHEMBL3822587,FP,INACT,1.0	CHEMBL456172,TN,INACT,0.05000000074505806	CHEMBL2036750,TP,ACT,0.9900000095367432	CHEMBL3582333,FP,INACT,1.0	CHEMBL558248,TP,ACT,1.0	

