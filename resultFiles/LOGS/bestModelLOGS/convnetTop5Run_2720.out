CNNModel CHEMBL1902 adam 0.001 15 256 0 0.6 False True
Number of active compounds :	321
Number of inactive compounds :	214
---------------------------------
Run id: CNNModel_CHEMBL1902_adam_0.001_15_256_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1902_adam_0.001_15_256_0.6_True/
---------------------------------
Training samples: 317
Validation samples: 100
--
Training Step: 1  | time: 1.197s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/317
[A[ATraining Step: 2  | total loss: [1m[32m0.62401[0m[0m | time: 2.172s
[2K
| Adam | epoch: 001 | loss: 0.62401 - acc: 0.4219 -- iter: 064/317
[A[ATraining Step: 3  | total loss: [1m[32m0.68218[0m[0m | time: 3.091s
[2K
| Adam | epoch: 001 | loss: 0.68218 - acc: 0.4091 -- iter: 096/317
[A[ATraining Step: 4  | total loss: [1m[32m0.68951[0m[0m | time: 4.013s
[2K
| Adam | epoch: 001 | loss: 0.68951 - acc: 0.5007 -- iter: 128/317
[A[ATraining Step: 5  | total loss: [1m[32m0.69007[0m[0m | time: 5.059s
[2K
| Adam | epoch: 001 | loss: 0.69007 - acc: 0.5435 -- iter: 160/317
[A[ATraining Step: 6  | total loss: [1m[32m0.68180[0m[0m | time: 6.034s
[2K
| Adam | epoch: 001 | loss: 0.68180 - acc: 0.5959 -- iter: 192/317
[A[ATraining Step: 7  | total loss: [1m[32m0.69515[0m[0m | time: 6.781s
[2K
| Adam | epoch: 001 | loss: 0.69515 - acc: 0.5571 -- iter: 224/317
[A[ATraining Step: 8  | total loss: [1m[32m0.70093[0m[0m | time: 7.630s
[2K
| Adam | epoch: 001 | loss: 0.70093 - acc: 0.5250 -- iter: 256/317
[A[ATraining Step: 9  | total loss: [1m[32m0.69205[0m[0m | time: 8.505s
[2K
| Adam | epoch: 001 | loss: 0.69205 - acc: 0.5448 -- iter: 288/317
[A[ATraining Step: 10  | total loss: [1m[32m0.69300[0m[0m | time: 10.363s
[2K
| Adam | epoch: 001 | loss: 0.69300 - acc: 0.5224 | val_loss: 0.68557 - val_acc: 0.6000 -- iter: 317/317
--
Training Step: 11  | total loss: [1m[32m0.68391[0m[0m | time: 1.013s
[2K
| Adam | epoch: 002 | loss: 0.68391 - acc: 0.6343 -- iter: 032/317
[A[ATraining Step: 12  | total loss: [1m[32m0.68264[0m[0m | time: 1.934s
[2K
| Adam | epoch: 002 | loss: 0.68264 - acc: 0.6437 -- iter: 064/317
[A[ATraining Step: 13  | total loss: [1m[32m0.68874[0m[0m | time: 2.777s
[2K
| Adam | epoch: 002 | loss: 0.68874 - acc: 0.5687 -- iter: 096/317
[A[ATraining Step: 14  | total loss: [1m[32m0.68577[0m[0m | time: 3.666s
[2K
| Adam | epoch: 002 | loss: 0.68577 - acc: 0.5917 -- iter: 128/317
[A[ATraining Step: 15  | total loss: [1m[32m0.67996[0m[0m | time: 4.559s
[2K
| Adam | epoch: 002 | loss: 0.67996 - acc: 0.6292 -- iter: 160/317
[A[ATraining Step: 16  | total loss: [1m[32m0.67566[0m[0m | time: 5.467s
[2K
| Adam | epoch: 002 | loss: 0.67566 - acc: 0.6394 -- iter: 192/317
[A[ATraining Step: 17  | total loss: [1m[32m0.69041[0m[0m | time: 6.393s
[2K
| Adam | epoch: 002 | loss: 0.69041 - acc: 0.5667 -- iter: 224/317
[A[ATraining Step: 18  | total loss: [1m[32m0.68771[0m[0m | time: 7.344s
[2K
| Adam | epoch: 002 | loss: 0.68771 - acc: 0.5652 -- iter: 256/317
[A[ATraining Step: 19  | total loss: [1m[32m0.68927[0m[0m | time: 8.287s
[2K
| Adam | epoch: 002 | loss: 0.68927 - acc: 0.5539 -- iter: 288/317
[A[ATraining Step: 20  | total loss: [1m[32m0.69439[0m[0m | time: 10.189s
[2K
| Adam | epoch: 002 | loss: 0.69439 - acc: 0.5366 | val_loss: 0.67527 - val_acc: 0.6000 -- iter: 317/317
--
Training Step: 21  | total loss: [1m[32m0.69787[0m[0m | time: 0.804s
[2K
| Adam | epoch: 003 | loss: 0.69787 - acc: 0.5155 -- iter: 032/317
[A[ATraining Step: 22  | total loss: [1m[32m0.68806[0m[0m | time: 1.619s
[2K
| Adam | epoch: 003 | loss: 0.68806 - acc: 0.5574 -- iter: 064/317
[A[ATraining Step: 23  | total loss: [1m[32m0.68330[0m[0m | time: 2.507s
[2K
| Adam | epoch: 003 | loss: 0.68330 - acc: 0.5758 -- iter: 096/317
[A[ATraining Step: 24  | total loss: [1m[32m0.68291[0m[0m | time: 3.423s
[2K
| Adam | epoch: 003 | loss: 0.68291 - acc: 0.5721 -- iter: 128/317
[A[ATraining Step: 25  | total loss: [1m[32m0.68478[0m[0m | time: 4.335s
[2K
| Adam | epoch: 003 | loss: 0.68478 - acc: 0.5609 -- iter: 160/317
[A[ATraining Step: 26  | total loss: [1m[32m0.68775[0m[0m | time: 5.287s
[2K
| Adam | epoch: 003 | loss: 0.68775 - acc: 0.5448 -- iter: 192/317
[A[ATraining Step: 27  | total loss: [1m[32m0.68434[0m[0m | time: 6.199s
[2K
| Adam | epoch: 003 | loss: 0.68434 - acc: 0.5574 -- iter: 224/317
[A[ATraining Step: 28  | total loss: [1m[32m0.68194[0m[0m | time: 7.236s
[2K
| Adam | epoch: 003 | loss: 0.68194 - acc: 0.5665 -- iter: 256/317
[A[ATraining Step: 29  | total loss: [1m[32m0.68132[0m[0m | time: 8.314s
[2K
| Adam | epoch: 003 | loss: 0.68132 - acc: 0.5655 -- iter: 288/317
[A[ATraining Step: 30  | total loss: [1m[32m0.68200[0m[0m | time: 10.197s
[2K
| Adam | epoch: 003 | loss: 0.68200 - acc: 0.5574 | val_loss: 0.66505 - val_acc: 0.6000 -- iter: 317/317
--
Training Step: 31  | total loss: [1m[32m0.68397[0m[0m | time: 1.004s
[2K
| Adam | epoch: 004 | loss: 0.68397 - acc: 0.5514 -- iter: 032/317
[A[ATraining Step: 32  | total loss: [1m[32m0.68275[0m[0m | time: 1.788s
[2K
| Adam | epoch: 004 | loss: 0.68275 - acc: 0.5539 -- iter: 064/317
[A[ATraining Step: 33  | total loss: [1m[32m0.67681[0m[0m | time: 2.784s
[2K
| Adam | epoch: 004 | loss: 0.67681 - acc: 0.5685 -- iter: 096/317
[A[ATraining Step: 34  | total loss: [1m[32m0.68029[0m[0m | time: 3.912s
[2K
| Adam | epoch: 004 | loss: 0.68029 - acc: 0.5575 -- iter: 128/317
[A[ATraining Step: 35  | total loss: [1m[32m0.68214[0m[0m | time: 4.746s
[2K
| Adam | epoch: 004 | loss: 0.68214 - acc: 0.5455 -- iter: 160/317
[A[ATraining Step: 36  | total loss: [1m[32m0.68932[0m[0m | time: 5.638s
[2K
| Adam | epoch: 004 | loss: 0.68932 - acc: 0.5234 -- iter: 192/317
[A[ATraining Step: 37  | total loss: [1m[32m0.68849[0m[0m | time: 6.562s
[2K
| Adam | epoch: 004 | loss: 0.68849 - acc: 0.5187 -- iter: 224/317
[A[ATraining Step: 38  | total loss: [1m[32m0.68889[0m[0m | time: 7.451s
[2K
| Adam | epoch: 004 | loss: 0.68889 - acc: 0.5089 -- iter: 256/317
[A[ATraining Step: 39  | total loss: [1m[32m0.68607[0m[0m | time: 8.358s
[2K
| Adam | epoch: 004 | loss: 0.68607 - acc: 0.5312 -- iter: 288/317
[A[ATraining Step: 40  | total loss: [1m[32m0.68247[0m[0m | time: 10.263s
[2K
| Adam | epoch: 004 | loss: 0.68247 - acc: 0.5663 | val_loss: 0.67189 - val_acc: 0.6000 -- iter: 317/317
--
Training Step: 41  | total loss: [1m[32m0.68241[0m[0m | time: 0.805s
[2K
| Adam | epoch: 005 | loss: 0.68241 - acc: 0.5599 -- iter: 032/317
[A[ATraining Step: 42  | total loss: [1m[32m0.67863[0m[0m | time: 1.672s
[2K
| Adam | epoch: 005 | loss: 0.67863 - acc: 0.5772 -- iter: 064/317
[A[ATraining Step: 43  | total loss: [1m[32m0.67432[0m[0m | time: 2.459s
[2K
| Adam | epoch: 005 | loss: 0.67432 - acc: 0.5857 -- iter: 096/317
[A[ATraining Step: 44  | total loss: [1m[32m0.67453[0m[0m | time: 3.249s
[2K
| Adam | epoch: 005 | loss: 0.67453 - acc: 0.5738 -- iter: 128/317
[A[ATraining Step: 45  | total loss: [1m[32m0.67189[0m[0m | time: 4.089s
[2K
| Adam | epoch: 005 | loss: 0.67189 - acc: 0.5701 -- iter: 160/317
[A[ATraining Step: 46  | total loss: [1m[32m0.67566[0m[0m | time: 5.027s
[2K
| Adam | epoch: 005 | loss: 0.67566 - acc: 0.5584 -- iter: 192/317
[A[ATraining Step: 47  | total loss: [1m[32m0.67233[0m[0m | time: 5.951s
[2K
| Adam | epoch: 005 | loss: 0.67233 - acc: 0.5591 -- iter: 224/317
[A[ATraining Step: 48  | total loss: [1m[32m0.66021[0m[0m | time: 6.828s
[2K
| Adam | epoch: 005 | loss: 0.66021 - acc: 0.5797 -- iter: 256/317
[A[ATraining Step: 49  | total loss: [1m[32m0.65099[0m[0m | time: 7.808s
[2K
| Adam | epoch: 005 | loss: 0.65099 - acc: 0.5869 -- iter: 288/317
[A[ATraining Step: 50  | total loss: [1m[32m0.65373[0m[0m | time: 9.875s
[2K
| Adam | epoch: 005 | loss: 0.65373 - acc: 0.5782 | val_loss: 0.60769 - val_acc: 0.6000 -- iter: 317/317
--
Training Step: 51  | total loss: [1m[32m0.64509[0m[0m | time: 0.915s
[2K
| Adam | epoch: 006 | loss: 0.64509 - acc: 0.5806 -- iter: 032/317
[A[ATraining Step: 52  | total loss: [1m[32m0.63797[0m[0m | time: 1.878s
[2K
| Adam | epoch: 006 | loss: 0.63797 - acc: 0.5966 -- iter: 064/317
[A[ATraining Step: 53  | total loss: [1m[32m0.65373[0m[0m | time: 2.813s
[2K
| Adam | epoch: 006 | loss: 0.65373 - acc: 0.5732 -- iter: 096/317
[A[ATraining Step: 54  | total loss: [1m[32m0.65015[0m[0m | time: 3.641s
[2K
| Adam | epoch: 006 | loss: 0.65015 - acc: 0.5807 -- iter: 128/317
[A[ATraining Step: 55  | total loss: [1m[32m0.64891[0m[0m | time: 4.409s
[2K
| Adam | epoch: 006 | loss: 0.64891 - acc: 0.6209 -- iter: 160/317
[A[ATraining Step: 56  | total loss: [1m[32m0.64742[0m[0m | time: 5.410s
[2K
| Adam | epoch: 006 | loss: 0.64742 - acc: 0.6402 -- iter: 192/317
[A[ATraining Step: 57  | total loss: [1m[32m0.63252[0m[0m | time: 6.507s
[2K
| Adam | epoch: 006 | loss: 0.63252 - acc: 0.6684 -- iter: 224/317
[A[ATraining Step: 58  | total loss: [1m[32m0.60651[0m[0m | time: 7.291s
[2K
| Adam | epoch: 006 | loss: 0.60651 - acc: 0.6838 -- iter: 256/317
[A[ATraining Step: 59  | total loss: [1m[32m0.60352[0m[0m | time: 8.104s
[2K
| Adam | epoch: 006 | loss: 0.60352 - acc: 0.6843 -- iter: 288/317
[A[ATraining Step: 60  | total loss: [1m[32m0.62198[0m[0m | time: 10.012s
[2K
| Adam | epoch: 006 | loss: 0.62198 - acc: 0.6682 | val_loss: 0.66369 - val_acc: 0.6000 -- iter: 317/317
--
Training Step: 61  | total loss: [1m[32m0.61276[0m[0m | time: 0.959s
[2K
| Adam | epoch: 007 | loss: 0.61276 - acc: 0.6707 -- iter: 032/317
[A[ATraining Step: 62  | total loss: [1m[32m0.62253[0m[0m | time: 1.750s
[2K
| Adam | epoch: 007 | loss: 0.62253 - acc: 0.6568 -- iter: 064/317
[A[ATraining Step: 63  | total loss: [1m[32m0.62121[0m[0m | time: 2.789s
[2K
| Adam | epoch: 007 | loss: 0.62121 - acc: 0.6646 -- iter: 096/317
[A[ATraining Step: 64  | total loss: [1m[32m0.62054[0m[0m | time: 3.883s
[2K
| Adam | epoch: 007 | loss: 0.62054 - acc: 0.6636 -- iter: 128/317
[A[ATraining Step: 65  | total loss: [1m[32m0.62635[0m[0m | time: 4.735s
[2K
| Adam | epoch: 007 | loss: 0.62635 - acc: 0.6550 -- iter: 160/317
[A[ATraining Step: 66  | total loss: [1m[32m0.62117[0m[0m | time: 5.426s
[2K
| Adam | epoch: 007 | loss: 0.62117 - acc: 0.6550 -- iter: 192/317
[A[ATraining Step: 67  | total loss: [1m[32m0.61470[0m[0m | time: 6.259s
[2K
| Adam | epoch: 007 | loss: 0.61470 - acc: 0.6674 -- iter: 224/317
[A[ATraining Step: 68  | total loss: [1m[32m0.60314[0m[0m | time: 7.123s
[2K
| Adam | epoch: 007 | loss: 0.60314 - acc: 0.6883 -- iter: 256/317
[A[ATraining Step: 69  | total loss: [1m[32m0.59344[0m[0m | time: 8.002s
[2K
| Adam | epoch: 007 | loss: 0.59344 - acc: 0.6955 -- iter: 288/317
[A[ATraining Step: 70  | total loss: [1m[32m0.58966[0m[0m | time: 9.884s
[2K
| Adam | epoch: 007 | loss: 0.58966 - acc: 0.6946 | val_loss: 0.51725 - val_acc: 0.7600 -- iter: 317/317
--
Training Step: 71  | total loss: [1m[32m0.58305[0m[0m | time: 0.858s
[2K
| Adam | epoch: 008 | loss: 0.58305 - acc: 0.7009 -- iter: 032/317
[A[ATraining Step: 72  | total loss: [1m[32m0.57903[0m[0m | time: 1.720s
[2K
| Adam | epoch: 008 | loss: 0.57903 - acc: 0.6994 -- iter: 064/317
[A[ATraining Step: 73  | total loss: [1m[32m0.57003[0m[0m | time: 2.575s
[2K
| Adam | epoch: 008 | loss: 0.57003 - acc: 0.7050 -- iter: 096/317
[A[ATraining Step: 74  | total loss: [1m[32m0.57801[0m[0m | time: 3.495s
[2K
| Adam | epoch: 008 | loss: 0.57801 - acc: 0.6997 -- iter: 128/317
[A[ATraining Step: 75  | total loss: [1m[32m0.57638[0m[0m | time: 4.398s
[2K
| Adam | epoch: 008 | loss: 0.57638 - acc: 0.7051 -- iter: 160/317
[A[ATraining Step: 76  | total loss: [1m[32m0.55433[0m[0m | time: 5.257s
[2K
| Adam | epoch: 008 | loss: 0.55433 - acc: 0.7200 -- iter: 192/317
[A[ATraining Step: 77  | total loss: [1m[32m0.55769[0m[0m | time: 6.099s
[2K
| Adam | epoch: 008 | loss: 0.55769 - acc: 0.7241 -- iter: 224/317
[A[ATraining Step: 78  | total loss: [1m[32m0.56055[0m[0m | time: 6.992s
[2K
| Adam | epoch: 008 | loss: 0.56055 - acc: 0.7133 -- iter: 256/317
[A[ATraining Step: 79  | total loss: [1m[32m0.55074[0m[0m | time: 8.041s
[2K
| Adam | epoch: 008 | loss: 0.55074 - acc: 0.7203 -- iter: 288/317
[A[ATraining Step: 80  | total loss: [1m[32m0.54519[0m[0m | time: 10.094s
[2K
| Adam | epoch: 008 | loss: 0.54519 - acc: 0.7201 | val_loss: 0.46225 - val_acc: 0.8200 -- iter: 317/317
--
Training Step: 81  | total loss: [1m[32m0.53032[0m[0m | time: 0.918s
[2K
| Adam | epoch: 009 | loss: 0.53032 - acc: 0.7295 -- iter: 032/317
[A[ATraining Step: 82  | total loss: [1m[32m0.52102[0m[0m | time: 1.817s
[2K
| Adam | epoch: 009 | loss: 0.52102 - acc: 0.7378 -- iter: 064/317
[A[ATraining Step: 83  | total loss: [1m[32m0.51473[0m[0m | time: 2.633s
[2K
| Adam | epoch: 009 | loss: 0.51473 - acc: 0.7421 -- iter: 096/317
[A[ATraining Step: 84  | total loss: [1m[32m0.51647[0m[0m | time: 3.694s
[2K
| Adam | epoch: 009 | loss: 0.51647 - acc: 0.7367 -- iter: 128/317
[A[ATraining Step: 85  | total loss: [1m[32m0.49885[0m[0m | time: 4.752s
[2K
| Adam | epoch: 009 | loss: 0.49885 - acc: 0.7505 -- iter: 160/317
[A[ATraining Step: 86  | total loss: [1m[32m0.48189[0m[0m | time: 5.613s
[2K
| Adam | epoch: 009 | loss: 0.48189 - acc: 0.7629 -- iter: 192/317
[A[ATraining Step: 87  | total loss: [1m[32m0.46883[0m[0m | time: 6.417s
[2K
| Adam | epoch: 009 | loss: 0.46883 - acc: 0.7742 -- iter: 224/317
[A[ATraining Step: 88  | total loss: [1m[32m0.46239[0m[0m | time: 7.249s
[2K
| Adam | epoch: 009 | loss: 0.46239 - acc: 0.7795 -- iter: 256/317
[A[ATraining Step: 89  | total loss: [1m[32m0.44651[0m[0m | time: 8.132s
[2K
| Adam | epoch: 009 | loss: 0.44651 - acc: 0.7912 -- iter: 288/317
[A[ATraining Step: 90  | total loss: [1m[32m0.44341[0m[0m | time: 10.025s
[2K
| Adam | epoch: 009 | loss: 0.44341 - acc: 0.7933 | val_loss: 0.46104 - val_acc: 0.7900 -- iter: 317/317
--
Training Step: 91  | total loss: [1m[32m0.42834[0m[0m | time: 1.052s
[2K
| Adam | epoch: 010 | loss: 0.42834 - acc: 0.8046 -- iter: 032/317
[A[ATraining Step: 92  | total loss: [1m[32m0.41570[0m[0m | time: 2.086s
[2K
| Adam | epoch: 010 | loss: 0.41570 - acc: 0.8085 -- iter: 064/317
[A[ATraining Step: 93  | total loss: [1m[32m0.39878[0m[0m | time: 2.828s
[2K
| Adam | epoch: 010 | loss: 0.39878 - acc: 0.8152 -- iter: 096/317
[A[ATraining Step: 94  | total loss: [1m[32m0.41112[0m[0m | time: 3.679s
[2K
| Adam | epoch: 010 | loss: 0.41112 - acc: 0.8118 -- iter: 128/317
[A[ATraining Step: 95  | total loss: [1m[32m0.42376[0m[0m | time: 4.548s
[2K
| Adam | epoch: 010 | loss: 0.42376 - acc: 0.8025 -- iter: 160/317
[A[ATraining Step: 96  | total loss: [1m[32m0.40800[0m[0m | time: 5.440s
[2K
| Adam | epoch: 010 | loss: 0.40800 - acc: 0.8129 -- iter: 192/317
[A[ATraining Step: 97  | total loss: [1m[32m0.42784[0m[0m | time: 6.328s
[2K
| Adam | epoch: 010 | loss: 0.42784 - acc: 0.7972 -- iter: 224/317
[A[ATraining Step: 98  | total loss: [1m[32m0.41377[0m[0m | time: 7.207s
[2K
| Adam | epoch: 010 | loss: 0.41377 - acc: 0.8019 -- iter: 256/317
[A[ATraining Step: 99  | total loss: [1m[32m0.39244[0m[0m | time: 8.071s
[2K
| Adam | epoch: 010 | loss: 0.39244 - acc: 0.8182 -- iter: 288/317
[A[ATraining Step: 100  | total loss: [1m[32m0.40161[0m[0m | time: 10.005s
[2K
| Adam | epoch: 010 | loss: 0.40161 - acc: 0.8157 | val_loss: 0.39998 - val_acc: 0.8300 -- iter: 317/317
--
Training Step: 101  | total loss: [1m[32m0.37950[0m[0m | time: 0.932s
[2K
| Adam | epoch: 011 | loss: 0.37950 - acc: 0.8310 -- iter: 032/317
[A[ATraining Step: 102  | total loss: [1m[32m0.36317[0m[0m | time: 1.829s
[2K
| Adam | epoch: 011 | loss: 0.36317 - acc: 0.8385 -- iter: 064/317
[A[ATraining Step: 103  | total loss: [1m[32m0.35746[0m[0m | time: 2.748s
[2K
| Adam | epoch: 011 | loss: 0.35746 - acc: 0.8422 -- iter: 096/317
[A[ATraining Step: 104  | total loss: [1m[32m0.34396[0m[0m | time: 3.638s
[2K
| Adam | epoch: 011 | loss: 0.34396 - acc: 0.8455 -- iter: 128/317
[A[ATraining Step: 105  | total loss: [1m[32m0.33901[0m[0m | time: 4.520s
[2K
| Adam | epoch: 011 | loss: 0.33901 - acc: 0.8484 -- iter: 160/317
[A[ATraining Step: 106  | total loss: [1m[32m0.34396[0m[0m | time: 5.368s
[2K
| Adam | epoch: 011 | loss: 0.34396 - acc: 0.8448 -- iter: 192/317
[A[ATraining Step: 107  | total loss: [1m[32m0.31912[0m[0m | time: 6.398s
[2K
| Adam | epoch: 011 | loss: 0.31912 - acc: 0.8603 -- iter: 224/317
[A[ATraining Step: 108  | total loss: [1m[32m0.31281[0m[0m | time: 7.460s
[2K
| Adam | epoch: 011 | loss: 0.31281 - acc: 0.8681 -- iter: 256/317
[A[ATraining Step: 109  | total loss: [1m[32m0.30171[0m[0m | time: 8.236s
[2K
| Adam | epoch: 011 | loss: 0.30171 - acc: 0.8781 -- iter: 288/317
[A[ATraining Step: 110  | total loss: [1m[32m0.29978[0m[0m | time: 10.022s
[2K
| Adam | epoch: 011 | loss: 0.29978 - acc: 0.8765 | val_loss: 0.41388 - val_acc: 0.8300 -- iter: 317/317
--
Training Step: 111  | total loss: [1m[32m0.30247[0m[0m | time: 0.918s
[2K
| Adam | epoch: 012 | loss: 0.30247 - acc: 0.8751 -- iter: 032/317
[A[ATraining Step: 112  | total loss: [1m[32m0.29155[0m[0m | time: 1.761s
[2K
| Adam | epoch: 012 | loss: 0.29155 - acc: 0.8782 -- iter: 064/317
[A[ATraining Step: 113  | total loss: [1m[32m0.27548[0m[0m | time: 2.723s
[2K
| Adam | epoch: 012 | loss: 0.27548 - acc: 0.8873 -- iter: 096/317
[A[ATraining Step: 114  | total loss: [1m[32m0.28352[0m[0m | time: 3.783s
[2K
| Adam | epoch: 012 | loss: 0.28352 - acc: 0.8860 -- iter: 128/317
[A[ATraining Step: 115  | total loss: [1m[32m0.28463[0m[0m | time: 4.790s
[2K
| Adam | epoch: 012 | loss: 0.28463 - acc: 0.8818 -- iter: 160/317
[A[ATraining Step: 116  | total loss: [1m[32m0.26616[0m[0m | time: 5.521s
[2K
| Adam | epoch: 012 | loss: 0.26616 - acc: 0.8874 -- iter: 192/317
[A[ATraining Step: 117  | total loss: [1m[32m0.25351[0m[0m | time: 6.384s
[2K
| Adam | epoch: 012 | loss: 0.25351 - acc: 0.8924 -- iter: 224/317
[A[ATraining Step: 118  | total loss: [1m[32m0.24732[0m[0m | time: 7.250s
[2K
| Adam | epoch: 012 | loss: 0.24732 - acc: 0.8969 -- iter: 256/317
[A[ATraining Step: 119  | total loss: [1m[32m0.24331[0m[0m | time: 8.105s
[2K
| Adam | epoch: 012 | loss: 0.24331 - acc: 0.9010 -- iter: 288/317
[A[ATraining Step: 120  | total loss: [1m[32m0.24716[0m[0m | time: 9.899s
[2K
| Adam | epoch: 012 | loss: 0.24716 - acc: 0.8984 | val_loss: 0.57746 - val_acc: 0.7900 -- iter: 317/317
--
Training Step: 121  | total loss: [1m[32m0.24782[0m[0m | time: 1.013s
[2K
| Adam | epoch: 013 | loss: 0.24782 - acc: 0.9016 -- iter: 032/317
[A[ATraining Step: 122  | total loss: [1m[32m0.26188[0m[0m | time: 1.945s
[2K
| Adam | epoch: 013 | loss: 0.26188 - acc: 0.8942 -- iter: 064/317
[A[ATraining Step: 123  | total loss: [1m[32m0.29799[0m[0m | time: 2.754s
[2K
| Adam | epoch: 013 | loss: 0.29799 - acc: 0.8704 -- iter: 096/317
[A[ATraining Step: 124  | total loss: [1m[32m0.32007[0m[0m | time: 3.590s
[2K
| Adam | epoch: 013 | loss: 0.32007 - acc: 0.8553 -- iter: 128/317
[A[ATraining Step: 125  | total loss: [1m[32m0.29991[0m[0m | time: 4.458s
[2K
| Adam | epoch: 013 | loss: 0.29991 - acc: 0.8666 -- iter: 160/317
[A[ATraining Step: 126  | total loss: [1m[32m0.29562[0m[0m | time: 5.328s
[2K
| Adam | epoch: 013 | loss: 0.29562 - acc: 0.8737 -- iter: 192/317
[A[ATraining Step: 127  | total loss: [1m[32m0.29072[0m[0m | time: 6.176s
[2K
| Adam | epoch: 013 | loss: 0.29072 - acc: 0.8738 -- iter: 224/317
[A[ATraining Step: 128  | total loss: [1m[32m0.28466[0m[0m | time: 7.033s
[2K
| Adam | epoch: 013 | loss: 0.28466 - acc: 0.8739 -- iter: 256/317
[A[ATraining Step: 129  | total loss: [1m[32m0.26803[0m[0m | time: 7.942s
[2K
| Adam | epoch: 013 | loss: 0.26803 - acc: 0.8803 -- iter: 288/317
[A[ATraining Step: 130  | total loss: [1m[32m0.25487[0m[0m | time: 9.809s
[2K
| Adam | epoch: 013 | loss: 0.25487 - acc: 0.8860 | val_loss: 0.45917 - val_acc: 0.8300 -- iter: 317/317
--
Training Step: 131  | total loss: [1m[32m0.28302[0m[0m | time: 0.826s
[2K
| Adam | epoch: 014 | loss: 0.28302 - acc: 0.8787 -- iter: 032/317
[A[ATraining Step: 132  | total loss: [1m[32m0.27015[0m[0m | time: 1.607s
[2K
| Adam | epoch: 014 | loss: 0.27015 - acc: 0.8805 -- iter: 064/317
[A[ATraining Step: 133  | total loss: [1m[32m0.25417[0m[0m | time: 2.502s
[2K
| Adam | epoch: 014 | loss: 0.25417 - acc: 0.8890 -- iter: 096/317
[A[ATraining Step: 134  | total loss: [1m[32m0.23512[0m[0m | time: 3.352s
[2K
| Adam | epoch: 014 | loss: 0.23512 - acc: 0.9001 -- iter: 128/317
[A[ATraining Step: 135  | total loss: [1m[32m0.22019[0m[0m | time: 4.221s
[2K
| Adam | epoch: 014 | loss: 0.22019 - acc: 0.9069 -- iter: 160/317
[A[ATraining Step: 136  | total loss: [1m[32m0.20973[0m[0m | time: 5.121s
[2K
| Adam | epoch: 014 | loss: 0.20973 - acc: 0.9100 -- iter: 192/317
[A[ATraining Step: 137  | total loss: [1m[32m0.21185[0m[0m | time: 6.004s
[2K
| Adam | epoch: 014 | loss: 0.21185 - acc: 0.9127 -- iter: 224/317
[A[ATraining Step: 138  | total loss: [1m[32m0.19572[0m[0m | time: 6.843s
[2K
| Adam | epoch: 014 | loss: 0.19572 - acc: 0.9215 -- iter: 256/317
[A[ATraining Step: 139  | total loss: [1m[32m0.19585[0m[0m | time: 7.866s
[2K
| Adam | epoch: 014 | loss: 0.19585 - acc: 0.9168 -- iter: 288/317
[A[ATraining Step: 140  | total loss: [1m[32m0.19120[0m[0m | time: 9.940s
[2K
| Adam | epoch: 014 | loss: 0.19120 - acc: 0.9158 | val_loss: 0.43135 - val_acc: 0.8400 -- iter: 317/317
--
Training Step: 141  | total loss: [1m[32m0.18165[0m[0m | time: 0.914s
[2K
| Adam | epoch: 015 | loss: 0.18165 - acc: 0.9179 -- iter: 032/317
[A[ATraining Step: 142  | total loss: [1m[32m0.17349[0m[0m | time: 1.734s
[2K
| Adam | epoch: 015 | loss: 0.17349 - acc: 0.9230 -- iter: 064/317
[A[ATraining Step: 143  | total loss: [1m[32m0.16604[0m[0m | time: 2.541s
[2K
| Adam | epoch: 015 | loss: 0.16604 - acc: 0.9238 -- iter: 096/317
[A[ATraining Step: 144  | total loss: [1m[32m0.15210[0m[0m | time: 3.541s
[2K
| Adam | epoch: 015 | loss: 0.15210 - acc: 0.9314 -- iter: 128/317
[A[ATraining Step: 145  | total loss: [1m[32m0.14472[0m[0m | time: 4.583s
[2K
| Adam | epoch: 015 | loss: 0.14472 - acc: 0.9352 -- iter: 160/317
[A[ATraining Step: 146  | total loss: [1m[32m0.13391[0m[0m | time: 5.527s
[2K
| Adam | epoch: 015 | loss: 0.13391 - acc: 0.9417 -- iter: 192/317
[A[ATraining Step: 147  | total loss: [1m[32m0.12392[0m[0m | time: 6.321s
[2K
| Adam | epoch: 015 | loss: 0.12392 - acc: 0.9475 -- iter: 224/317
[A[ATraining Step: 148  | total loss: [1m[32m0.11522[0m[0m | time: 7.198s
[2K
| Adam | epoch: 015 | loss: 0.11522 - acc: 0.9527 -- iter: 256/317
[A[ATraining Step: 149  | total loss: [1m[32m0.10550[0m[0m | time: 8.055s
[2K
| Adam | epoch: 015 | loss: 0.10550 - acc: 0.9575 -- iter: 288/317
[A[ATraining Step: 150  | total loss: [1m[32m0.09988[0m[0m | time: 9.881s
[2K
| Adam | epoch: 015 | loss: 0.09988 - acc: 0.9586 | val_loss: 0.54495 - val_acc: 0.8300 -- iter: 317/317
--
Validation AUC:0.9295833333333333
Validation AUPRC:0.9430147909492488
Test AUC:0.9334975369458128
Test AUPRC:0.9576944072412676
BestTestF1Score	0.86	0.64	0.82	0.79	0.95	55	15	27	3	0.01
BestTestMCCScore	0.83	0.7	0.83	0.98	0.72	42	1	41	16	0.87
BestTestAccuracyScore	0.83	0.7	0.83	0.98	0.72	42	1	41	16	0.87
BestValidationF1Score	0.88	0.69	0.85	0.83	0.95	57	12	28	3	0.01
BestValidationMCC	0.86	0.72	0.85	0.96	0.78	47	2	38	13	0.87
BestValidationAccuracy	0.86	0.72	0.85	0.96	0.78	47	2	38	13	0.87
TestPredictions (Threshold:0.87)
CHEMBL371424,TP,ACT,1.0	CHEMBL316255,FN,ACT,0.7300000190734863	CHEMBL481815,TN,INACT,0.0	CHEMBL2153264,TN,INACT,0.0	CHEMBL312157,TP,ACT,0.9900000095367432	CHEMBL2059033,TP,ACT,1.0	CHEMBL237815,TN,INACT,0.0	CHEMBL343212,TP,ACT,0.9900000095367432	CHEMBL3586664,TN,INACT,0.0	CHEMBL3794209,TP,ACT,0.9700000286102295	CHEMBL109950,FN,ACT,0.8299999833106995	CHEMBL1086858,TN,INACT,0.0	CHEMBL2059237,TP,ACT,1.0	CHEMBL553081,TN,INACT,0.029999999329447746	CHEMBL151841,FN,ACT,0.7900000214576721	CHEMBL381422,FN,ACT,0.14000000059604645	CHEMBL202517,TP,ACT,0.9900000095367432	CHEMBL416590,FN,ACT,0.27000001072883606	CHEMBL51523,TP,ACT,1.0	CHEMBL1277419,TN,INACT,0.0	CHEMBL88696,TN,INACT,0.0	CHEMBL1087746,TN,INACT,0.0	CHEMBL3792567,TN,INACT,0.4300000071525574	CHEMBL2431021,TN,INACT,0.1899999976158142	CHEMBL148621,TP,ACT,0.9900000095367432	CHEMBL3262017,TN,INACT,0.0	CHEMBL287680,TP,ACT,1.0	CHEMBL1277420,TN,INACT,0.0	CHEMBL201201,FN,ACT,0.12999999523162842	CHEMBL375949,TN,INACT,0.0	CHEMBL481032,TN,INACT,0.12999999523162842	CHEMBL372289,TP,ACT,0.9900000095367432	CHEMBL1277787,TN,INACT,0.0	CHEMBL286227,TP,ACT,0.9900000095367432	CHEMBL33840,FN,ACT,0.11999999731779099	CHEMBL517995,TN,INACT,0.0	CHEMBL299136,TP,ACT,1.0	CHEMBL3793250,TN,INACT,0.0	CHEMBL202097,FN,ACT,0.12999999523162842	CHEMBL57087,FN,ACT,0.3700000047683716	CHEMBL2326356,TN,INACT,0.009999999776482582	CHEMBL2058231,TP,ACT,0.9900000095367432	CHEMBL2348611,FP,INACT,0.8999999761581421	CHEMBL1235837,TN,INACT,0.0	CHEMBL119571,TP,ACT,1.0	CHEMBL325170,FN,ACT,0.0	CHEMBL50795,TP,ACT,0.9900000095367432	CHEMBL148516,TP,ACT,1.0	CHEMBL1086859,TN,INACT,0.0	CHEMBL160,TP,ACT,0.9900000095367432	CHEMBL474637,TN,INACT,0.0	CHEMBL372407,TP,ACT,0.9300000071525574	CHEMBL108296,FN,ACT,0.029999999329447746	CHEMBL149011,TP,ACT,0.949999988079071	CHEMBL129672,TP,ACT,0.9900000095367432	CHEMBL3792925,TN,INACT,0.009999999776482582	CHEMBL1162881,TN,INACT,0.2199999988079071	CHEMBL2058499,TP,ACT,1.0	CHEMBL3794343,TN,INACT,0.5099999904632568	CHEMBL170655,TP,ACT,1.0	CHEMBL479469,TN,INACT,0.10000000149011612	CHEMBL107774,TP,ACT,0.9800000190734863	CHEMBL431441,TP,ACT,1.0	CHEMBL235103,TN,INACT,0.03999999910593033	CHEMBL406996,TP,ACT,1.0	CHEMBL421507,TP,ACT,0.9900000095367432	CHEMBL3262026,TN,INACT,0.0	CHEMBL293155,TP,ACT,1.0	CHEMBL519789,TN,INACT,0.009999999776482582	CHEMBL33612,TP,ACT,0.9900000095367432	CHEMBL14756,TP,ACT,1.0	CHEMBL3125049,TN,INACT,0.23000000417232513	CHEMBL432085,FN,ACT,0.10000000149011612	CHEMBL44833,TN,INACT,0.0	CHEMBL406186,TP,ACT,1.0	CHEMBL202101,TP,ACT,0.9200000166893005	CHEMBL3128241,TN,INACT,0.0	CHEMBL65863,TP,ACT,1.0	CHEMBL276303,TP,ACT,0.9900000095367432	CHEMBL480247,TN,INACT,0.20999999344348907	CHEMBL3793385,TN,INACT,0.18000000715255737	CHEMBL3589092,TN,INACT,0.6800000071525574	CHEMBL3793309,FN,ACT,0.5699999928474426	CHEMBL149707,TP,ACT,0.949999988079071	CHEMBL2059029,TP,ACT,1.0	CHEMBL33166,FN,ACT,0.0	CHEMBL431360,TP,ACT,1.0	CHEMBL2058791,TP,ACT,1.0	CHEMBL444366,TN,INACT,0.0	CHEMBL370367,TP,ACT,0.9800000190734863	CHEMBL370344,TP,ACT,1.0	CHEMBL320478,FN,ACT,0.009999999776482582	CHEMBL517221,TN,INACT,0.0	CHEMBL33317,TP,ACT,0.9900000095367432	CHEMBL1650948,FN,ACT,0.03999999910593033	CHEMBL226445,TN,INACT,0.0	CHEMBL3793921,TN,INACT,0.8600000143051147	CHEMBL1277602,TN,INACT,0.0	CHEMBL2058498,TP,ACT,1.0	CHEMBL2332792,TN,INACT,0.05000000074505806	

