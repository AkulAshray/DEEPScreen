CNNModel CHEMBL4073 RMSprop 0.0005 30 128 0 0.6 False True
Number of active compounds :	402
Number of inactive compounds :	402
---------------------------------
Run id: CNNModel_CHEMBL4073_RMSprop_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4073_RMSprop_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 514
Validation samples: 161
--
Training Step: 1  | time: 1.185s
[2K
| RMSProp | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/514
[A[ATraining Step: 2  | total loss: [1m[32m0.62386[0m[0m | time: 1.999s
[2K
| RMSProp | epoch: 001 | loss: 0.62386 - acc: 0.4500 -- iter: 064/514
[A[ATraining Step: 3  | total loss: [1m[32m0.68043[0m[0m | time: 2.829s
[2K
| RMSProp | epoch: 001 | loss: 0.68043 - acc: 0.4909 -- iter: 096/514
[A[ATraining Step: 4  | total loss: [1m[32m0.68990[0m[0m | time: 3.728s
[2K
| RMSProp | epoch: 001 | loss: 0.68990 - acc: 0.4977 -- iter: 128/514
[A[ATraining Step: 5  | total loss: [1m[32m0.69215[0m[0m | time: 4.592s
[2K
| RMSProp | epoch: 001 | loss: 0.69215 - acc: 0.5426 -- iter: 160/514
[A[ATraining Step: 6  | total loss: [1m[32m0.69288[0m[0m | time: 5.488s
[2K
| RMSProp | epoch: 001 | loss: 0.69288 - acc: 0.5152 -- iter: 192/514
[A[ATraining Step: 7  | total loss: [1m[32m0.69314[0m[0m | time: 6.415s
[2K
| RMSProp | epoch: 001 | loss: 0.69314 - acc: 0.4686 -- iter: 224/514
[A[ATraining Step: 8  | total loss: [1m[32m0.69325[0m[0m | time: 7.316s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4335 -- iter: 256/514
[A[ATraining Step: 9  | total loss: [1m[32m0.69325[0m[0m | time: 8.144s
[2K
| RMSProp | epoch: 001 | loss: 0.69325 - acc: 0.4522 -- iter: 288/514
[A[ATraining Step: 10  | total loss: [1m[32m0.69312[0m[0m | time: 8.995s
[2K
| RMSProp | epoch: 001 | loss: 0.69312 - acc: 0.4917 -- iter: 320/514
[A[ATraining Step: 11  | total loss: [1m[32m0.69322[0m[0m | time: 10.059s
[2K
| RMSProp | epoch: 001 | loss: 0.69322 - acc: 0.4512 -- iter: 352/514
[A[ATraining Step: 12  | total loss: [1m[32m0.69327[0m[0m | time: 11.086s
[2K
| RMSProp | epoch: 001 | loss: 0.69327 - acc: 0.4591 -- iter: 384/514
[A[ATraining Step: 13  | total loss: [1m[32m0.69304[0m[0m | time: 11.855s
[2K
| RMSProp | epoch: 001 | loss: 0.69304 - acc: 0.5570 -- iter: 416/514
[A[ATraining Step: 14  | total loss: [1m[32m0.69301[0m[0m | time: 12.672s
[2K
| RMSProp | epoch: 001 | loss: 0.69301 - acc: 0.5720 -- iter: 448/514
[A[ATraining Step: 15  | total loss: [1m[32m0.69328[0m[0m | time: 13.609s
[2K
| RMSProp | epoch: 001 | loss: 0.69328 - acc: 0.4827 -- iter: 480/514
[A[ATraining Step: 16  | total loss: [1m[32m0.69319[0m[0m | time: 14.457s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4658 -- iter: 512/514
[A[ATraining Step: 17  | total loss: [1m[32m0.69319[0m[0m | time: 15.581s
[2K
| RMSProp | epoch: 001 | loss: 0.69319 - acc: 0.4443 | val_loss: 0.69319 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 18  | total loss: [1m[32m0.69293[0m[0m | time: 0.112s
[2K
| RMSProp | epoch: 002 | loss: 0.69293 - acc: 0.6367 -- iter: 032/514
[A[ATraining Step: 19  | total loss: [1m[32m0.69298[0m[0m | time: 1.151s
[2K
| RMSProp | epoch: 002 | loss: 0.69298 - acc: 0.5911 -- iter: 064/514
[A[ATraining Step: 20  | total loss: [1m[32m0.69307[0m[0m | time: 1.886s
[2K
| RMSProp | epoch: 002 | loss: 0.69307 - acc: 0.5618 -- iter: 096/514
[A[ATraining Step: 21  | total loss: [1m[32m0.69307[0m[0m | time: 2.689s
[2K
| RMSProp | epoch: 002 | loss: 0.69307 - acc: 0.5523 -- iter: 128/514
[A[ATraining Step: 22  | total loss: [1m[32m0.69313[0m[0m | time: 3.550s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5179 -- iter: 160/514
[A[ATraining Step: 23  | total loss: [1m[32m0.69318[0m[0m | time: 4.435s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.4945 -- iter: 192/514
[A[ATraining Step: 24  | total loss: [1m[32m0.69321[0m[0m | time: 5.308s
[2K
| RMSProp | epoch: 002 | loss: 0.69321 - acc: 0.4785 -- iter: 224/514
[A[ATraining Step: 25  | total loss: [1m[32m0.69320[0m[0m | time: 6.230s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4758 -- iter: 256/514
[A[ATraining Step: 26  | total loss: [1m[32m0.69317[0m[0m | time: 7.166s
[2K
| RMSProp | epoch: 002 | loss: 0.69317 - acc: 0.4905 -- iter: 288/514
[A[ATraining Step: 27  | total loss: [1m[32m0.69320[0m[0m | time: 8.109s
[2K
| RMSProp | epoch: 002 | loss: 0.69320 - acc: 0.4849 -- iter: 320/514
[A[ATraining Step: 28  | total loss: [1m[32m0.69312[0m[0m | time: 8.876s
[2K
| RMSProp | epoch: 002 | loss: 0.69312 - acc: 0.5199 -- iter: 352/514
[A[ATraining Step: 29  | total loss: [1m[32m0.69310[0m[0m | time: 9.789s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5151 -- iter: 384/514
[A[ATraining Step: 30  | total loss: [1m[32m0.69304[0m[0m | time: 10.837s
[2K
| RMSProp | epoch: 002 | loss: 0.69304 - acc: 0.5411 -- iter: 416/514
[A[ATraining Step: 31  | total loss: [1m[32m0.69318[0m[0m | time: 11.778s
[2K
| RMSProp | epoch: 002 | loss: 0.69318 - acc: 0.5028 -- iter: 448/514
[A[ATraining Step: 32  | total loss: [1m[32m0.69316[0m[0m | time: 12.550s
[2K
| RMSProp | epoch: 002 | loss: 0.69316 - acc: 0.5022 -- iter: 480/514
[A[ATraining Step: 33  | total loss: [1m[32m0.69313[0m[0m | time: 13.381s
[2K
| RMSProp | epoch: 002 | loss: 0.69313 - acc: 0.5017 -- iter: 512/514
[A[ATraining Step: 34  | total loss: [1m[32m0.69310[0m[0m | time: 15.196s
[2K
| RMSProp | epoch: 002 | loss: 0.69310 - acc: 0.5080 | val_loss: 0.69318 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 35  | total loss: [1m[32m0.69325[0m[0m | time: 0.117s
[2K
| RMSProp | epoch: 003 | loss: 0.69325 - acc: 0.4606 -- iter: 032/514
[A[ATraining Step: 36  | total loss: [1m[32m0.69322[0m[0m | time: 0.210s
[2K
| RMSProp | epoch: 003 | loss: 0.69322 - acc: 0.4686 -- iter: 064/514
[A[ATraining Step: 37  | total loss: [1m[32m0.69280[0m[0m | time: 1.170s
[2K
| RMSProp | epoch: 003 | loss: 0.69280 - acc: 0.5749 -- iter: 096/514
[A[ATraining Step: 38  | total loss: [1m[32m0.69280[0m[0m | time: 1.897s
[2K
| RMSProp | epoch: 003 | loss: 0.69280 - acc: 0.5664 -- iter: 128/514
[A[ATraining Step: 39  | total loss: [1m[32m0.69288[0m[0m | time: 2.820s
[2K
| RMSProp | epoch: 003 | loss: 0.69288 - acc: 0.5537 -- iter: 160/514
[A[ATraining Step: 40  | total loss: [1m[32m0.69296[0m[0m | time: 3.654s
[2K
| RMSProp | epoch: 003 | loss: 0.69296 - acc: 0.5436 -- iter: 192/514
[A[ATraining Step: 41  | total loss: [1m[32m0.69294[0m[0m | time: 4.472s
[2K
| RMSProp | epoch: 003 | loss: 0.69294 - acc: 0.5413 -- iter: 224/514
[A[ATraining Step: 42  | total loss: [1m[32m0.69317[0m[0m | time: 5.291s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.5114 -- iter: 256/514
[A[ATraining Step: 43  | total loss: [1m[32m0.69319[0m[0m | time: 6.179s
[2K
| RMSProp | epoch: 003 | loss: 0.69319 - acc: 0.5094 -- iter: 288/514
[A[ATraining Step: 44  | total loss: [1m[32m0.69329[0m[0m | time: 7.077s
[2K
| RMSProp | epoch: 003 | loss: 0.69329 - acc: 0.4915 -- iter: 320/514
[A[ATraining Step: 45  | total loss: [1m[32m0.69312[0m[0m | time: 7.947s
[2K
| RMSProp | epoch: 003 | loss: 0.69312 - acc: 0.5142 -- iter: 352/514
[A[ATraining Step: 46  | total loss: [1m[32m0.69321[0m[0m | time: 8.766s
[2K
| RMSProp | epoch: 003 | loss: 0.69321 - acc: 0.4962 -- iter: 384/514
[A[ATraining Step: 47  | total loss: [1m[32m0.69318[0m[0m | time: 9.739s
[2K
| RMSProp | epoch: 003 | loss: 0.69318 - acc: 0.4968 -- iter: 416/514
[A[ATraining Step: 48  | total loss: [1m[32m0.69317[0m[0m | time: 10.737s
[2K
| RMSProp | epoch: 003 | loss: 0.69317 - acc: 0.5024 -- iter: 448/514
[A[ATraining Step: 49  | total loss: [1m[32m0.69310[0m[0m | time: 11.650s
[2K
| RMSProp | epoch: 003 | loss: 0.69310 - acc: 0.5069 -- iter: 480/514
[A[ATraining Step: 50  | total loss: [1m[32m0.69309[0m[0m | time: 12.417s
[2K
| RMSProp | epoch: 003 | loss: 0.69309 - acc: 0.5107 -- iter: 512/514
[A[ATraining Step: 51  | total loss: [1m[32m0.69311[0m[0m | time: 14.272s
[2K
| RMSProp | epoch: 003 | loss: 0.69311 - acc: 0.5091 | val_loss: 0.69332 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 52  | total loss: [1m[32m0.69313[0m[0m | time: 0.769s
[2K
| RMSProp | epoch: 004 | loss: 0.69313 - acc: 0.5077 -- iter: 032/514
[A[ATraining Step: 53  | total loss: [1m[32m0.69303[0m[0m | time: 0.879s
[2K
| RMSProp | epoch: 004 | loss: 0.69303 - acc: 0.5250 -- iter: 064/514
[A[ATraining Step: 54  | total loss: [1m[32m0.69317[0m[0m | time: 1.015s
[2K
| RMSProp | epoch: 004 | loss: 0.69317 - acc: 0.5214 -- iter: 096/514
[A[ATraining Step: 55  | total loss: [1m[32m0.69304[0m[0m | time: 2.009s
[2K
| RMSProp | epoch: 004 | loss: 0.69304 - acc: 0.5183 -- iter: 128/514
[A[ATraining Step: 56  | total loss: [1m[32m0.69306[0m[0m | time: 2.979s
[2K
| RMSProp | epoch: 004 | loss: 0.69306 - acc: 0.5157 -- iter: 160/514
[A[ATraining Step: 57  | total loss: [1m[32m0.69308[0m[0m | time: 3.759s
[2K
| RMSProp | epoch: 004 | loss: 0.69308 - acc: 0.5136 -- iter: 192/514
[A[ATraining Step: 58  | total loss: [1m[32m0.69314[0m[0m | time: 4.566s
[2K
| RMSProp | epoch: 004 | loss: 0.69314 - acc: 0.5032 -- iter: 224/514
[A[ATraining Step: 59  | total loss: [1m[32m0.69315[0m[0m | time: 5.395s
[2K
| RMSProp | epoch: 004 | loss: 0.69315 - acc: 0.5028 -- iter: 256/514
[A[ATraining Step: 60  | total loss: [1m[32m0.69303[0m[0m | time: 6.258s
[2K
| RMSProp | epoch: 004 | loss: 0.69303 - acc: 0.5231 -- iter: 288/514
[A[ATraining Step: 61  | total loss: [1m[32m0.69307[0m[0m | time: 7.124s
[2K
| RMSProp | epoch: 004 | loss: 0.69307 - acc: 0.5160 -- iter: 320/514
[A[ATraining Step: 62  | total loss: [1m[32m0.69314[0m[0m | time: 7.991s
[2K
| RMSProp | epoch: 004 | loss: 0.69314 - acc: 0.5059 -- iter: 352/514
[A[ATraining Step: 63  | total loss: [1m[32m0.69324[0m[0m | time: 8.889s
[2K
| RMSProp | epoch: 004 | loss: 0.69324 - acc: 0.4933 -- iter: 384/514
[A[ATraining Step: 64  | total loss: [1m[32m0.69322[0m[0m | time: 9.758s
[2K
| RMSProp | epoch: 004 | loss: 0.69322 - acc: 0.4980 -- iter: 416/514
[A[ATraining Step: 65  | total loss: [1m[32m0.69322[0m[0m | time: 10.593s
[2K
| RMSProp | epoch: 004 | loss: 0.69322 - acc: 0.4983 -- iter: 448/514
[A[ATraining Step: 66  | total loss: [1m[32m0.69314[0m[0m | time: 11.449s
[2K
| RMSProp | epoch: 004 | loss: 0.69314 - acc: 0.5099 -- iter: 480/514
[A[ATraining Step: 67  | total loss: [1m[32m0.69314[0m[0m | time: 12.487s
[2K
| RMSProp | epoch: 004 | loss: 0.69314 - acc: 0.5087 -- iter: 512/514
[A[ATraining Step: 68  | total loss: [1m[32m0.69314[0m[0m | time: 14.528s
[2K
| RMSProp | epoch: 004 | loss: 0.69314 - acc: 0.5077 | val_loss: 0.69331 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 69  | total loss: [1m[32m0.69322[0m[0m | time: 0.845s
[2K
| RMSProp | epoch: 005 | loss: 0.69322 - acc: 0.4958 -- iter: 032/514
[A[ATraining Step: 70  | total loss: [1m[32m0.69321[0m[0m | time: 1.681s
[2K
| RMSProp | epoch: 005 | loss: 0.69321 - acc: 0.4963 -- iter: 064/514
[A[ATraining Step: 71  | total loss: [1m[32m0.69323[0m[0m | time: 1.800s
[2K
| RMSProp | epoch: 005 | loss: 0.69323 - acc: 0.4932 -- iter: 096/514
[A[ATraining Step: 72  | total loss: [1m[32m0.69327[0m[0m | time: 1.911s
[2K
| RMSProp | epoch: 005 | loss: 0.69327 - acc: 0.4939 -- iter: 128/514
[A[ATraining Step: 73  | total loss: [1m[32m0.69332[0m[0m | time: 2.921s
[2K
| RMSProp | epoch: 005 | loss: 0.69332 - acc: 0.4946 -- iter: 160/514
[A[ATraining Step: 74  | total loss: [1m[32m0.69320[0m[0m | time: 3.966s
[2K
| RMSProp | epoch: 005 | loss: 0.69320 - acc: 0.5158 -- iter: 192/514
[A[ATraining Step: 75  | total loss: [1m[32m0.69319[0m[0m | time: 4.699s
[2K
| RMSProp | epoch: 005 | loss: 0.69319 - acc: 0.5107 -- iter: 224/514
[A[ATraining Step: 76  | total loss: [1m[32m0.69322[0m[0m | time: 5.545s
[2K
| RMSProp | epoch: 005 | loss: 0.69322 - acc: 0.5062 -- iter: 256/514
[A[ATraining Step: 77  | total loss: [1m[32m0.69316[0m[0m | time: 6.391s
[2K
| RMSProp | epoch: 005 | loss: 0.69316 - acc: 0.5155 -- iter: 288/514
[A[ATraining Step: 78  | total loss: [1m[32m0.69328[0m[0m | time: 7.236s
[2K
| RMSProp | epoch: 005 | loss: 0.69328 - acc: 0.5008 -- iter: 320/514
[A[ATraining Step: 79  | total loss: [1m[32m0.69323[0m[0m | time: 8.070s
[2K
| RMSProp | epoch: 005 | loss: 0.69323 - acc: 0.5039 -- iter: 352/514
[A[ATraining Step: 80  | total loss: [1m[32m0.69318[0m[0m | time: 8.968s
[2K
| RMSProp | epoch: 005 | loss: 0.69318 - acc: 0.5131 -- iter: 384/514
[A[ATraining Step: 81  | total loss: [1m[32m0.69309[0m[0m | time: 9.827s
[2K
| RMSProp | epoch: 005 | loss: 0.69309 - acc: 0.5213 -- iter: 416/514
[A[ATraining Step: 82  | total loss: [1m[32m0.69302[0m[0m | time: 10.709s
[2K
| RMSProp | epoch: 005 | loss: 0.69302 - acc: 0.5254 -- iter: 448/514
[A[ATraining Step: 83  | total loss: [1m[32m0.69296[0m[0m | time: 11.607s
[2K
| RMSProp | epoch: 005 | loss: 0.69296 - acc: 0.5291 -- iter: 480/514
[A[ATraining Step: 84  | total loss: [1m[32m0.69312[0m[0m | time: 12.546s
[2K
| RMSProp | epoch: 005 | loss: 0.69312 - acc: 0.5168 -- iter: 512/514
[A[ATraining Step: 85  | total loss: [1m[32m0.69323[0m[0m | time: 14.567s
[2K
| RMSProp | epoch: 005 | loss: 0.69323 - acc: 0.5058 | val_loss: 0.69351 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 86  | total loss: [1m[32m0.69312[0m[0m | time: 0.895s
[2K
| RMSProp | epoch: 006 | loss: 0.69312 - acc: 0.5177 -- iter: 032/514
[A[ATraining Step: 87  | total loss: [1m[32m0.69331[0m[0m | time: 1.800s
[2K
| RMSProp | epoch: 006 | loss: 0.69331 - acc: 0.5003 -- iter: 064/514
[A[ATraining Step: 88  | total loss: [1m[32m0.69338[0m[0m | time: 2.645s
[2K
| RMSProp | epoch: 006 | loss: 0.69338 - acc: 0.4909 -- iter: 096/514
[A[ATraining Step: 89  | total loss: [1m[32m0.69330[0m[0m | time: 2.730s
[2K
| RMSProp | epoch: 006 | loss: 0.69330 - acc: 0.5012 -- iter: 128/514
[A[ATraining Step: 90  | total loss: [1m[32m0.69293[0m[0m | time: 2.859s
[2K
| RMSProp | epoch: 006 | loss: 0.69293 - acc: 0.5511 -- iter: 160/514
[A[ATraining Step: 91  | total loss: [1m[32m0.69206[0m[0m | time: 3.865s
[2K
| RMSProp | epoch: 006 | loss: 0.69206 - acc: 0.5959 -- iter: 192/514
[A[ATraining Step: 92  | total loss: [1m[32m0.69242[0m[0m | time: 4.907s
[2K
| RMSProp | epoch: 006 | loss: 0.69242 - acc: 0.5770 -- iter: 224/514
[A[ATraining Step: 93  | total loss: [1m[32m0.69233[0m[0m | time: 5.774s
[2K
| RMSProp | epoch: 006 | loss: 0.69233 - acc: 0.5755 -- iter: 256/514
[A[ATraining Step: 94  | total loss: [1m[32m0.69260[0m[0m | time: 6.582s
[2K
| RMSProp | epoch: 006 | loss: 0.69260 - acc: 0.5617 -- iter: 288/514
[A[ATraining Step: 95  | total loss: [1m[32m0.69258[0m[0m | time: 7.428s
[2K
| RMSProp | epoch: 006 | loss: 0.69258 - acc: 0.5587 -- iter: 320/514
[A[ATraining Step: 96  | total loss: [1m[32m0.69231[0m[0m | time: 8.286s
[2K
| RMSProp | epoch: 006 | loss: 0.69231 - acc: 0.5653 -- iter: 352/514
[A[ATraining Step: 97  | total loss: [1m[32m0.69239[0m[0m | time: 9.168s
[2K
| RMSProp | epoch: 006 | loss: 0.69239 - acc: 0.5588 -- iter: 384/514
[A[ATraining Step: 98  | total loss: [1m[32m0.69267[0m[0m | time: 10.054s
[2K
| RMSProp | epoch: 006 | loss: 0.69267 - acc: 0.5467 -- iter: 416/514
[A[ATraining Step: 99  | total loss: [1m[32m0.69289[0m[0m | time: 10.917s
[2K
| RMSProp | epoch: 006 | loss: 0.69289 - acc: 0.5357 -- iter: 448/514
[A[ATraining Step: 100  | total loss: [1m[32m0.69314[0m[0m | time: 11.844s
[2K
| RMSProp | epoch: 006 | loss: 0.69314 - acc: 0.5228 -- iter: 480/514
[A[ATraining Step: 101  | total loss: [1m[32m0.69300[0m[0m | time: 12.661s
[2K
| RMSProp | epoch: 006 | loss: 0.69300 - acc: 0.5268 -- iter: 512/514
[A[ATraining Step: 102  | total loss: [1m[32m0.69282[0m[0m | time: 14.655s
[2K
| RMSProp | epoch: 006 | loss: 0.69282 - acc: 0.5335 | val_loss: 0.69400 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 103  | total loss: [1m[32m0.69287[0m[0m | time: 0.866s
[2K
| RMSProp | epoch: 007 | loss: 0.69287 - acc: 0.5301 -- iter: 032/514
[A[ATraining Step: 104  | total loss: [1m[32m0.69306[0m[0m | time: 1.763s
[2K
| RMSProp | epoch: 007 | loss: 0.69306 - acc: 0.5209 -- iter: 064/514
[A[ATraining Step: 105  | total loss: [1m[32m0.69314[0m[0m | time: 2.687s
[2K
| RMSProp | epoch: 007 | loss: 0.69314 - acc: 0.5156 -- iter: 096/514
[A[ATraining Step: 106  | total loss: [1m[32m0.69295[0m[0m | time: 3.527s
[2K
| RMSProp | epoch: 007 | loss: 0.69295 - acc: 0.5235 -- iter: 128/514
[A[ATraining Step: 107  | total loss: [1m[32m0.69287[0m[0m | time: 3.607s
[2K
| RMSProp | epoch: 007 | loss: 0.69287 - acc: 0.5242 -- iter: 160/514
[A[ATraining Step: 108  | total loss: [1m[32m0.69295[0m[0m | time: 3.689s
[2K
| RMSProp | epoch: 007 | loss: 0.69295 - acc: 0.5218 -- iter: 192/514
[A[ATraining Step: 109  | total loss: [1m[32m0.69304[0m[0m | time: 4.654s
[2K
| RMSProp | epoch: 007 | loss: 0.69304 - acc: 0.5196 -- iter: 224/514
[A[ATraining Step: 110  | total loss: [1m[32m0.69331[0m[0m | time: 5.689s
[2K
| RMSProp | epoch: 007 | loss: 0.69331 - acc: 0.5083 -- iter: 256/514
[A[ATraining Step: 111  | total loss: [1m[32m0.69309[0m[0m | time: 6.636s
[2K
| RMSProp | epoch: 007 | loss: 0.69309 - acc: 0.5168 -- iter: 288/514
[A[ATraining Step: 112  | total loss: [1m[32m0.69295[0m[0m | time: 7.412s
[2K
| RMSProp | epoch: 007 | loss: 0.69295 - acc: 0.5214 -- iter: 320/514
[A[ATraining Step: 113  | total loss: [1m[32m0.69299[0m[0m | time: 8.345s
[2K
| RMSProp | epoch: 007 | loss: 0.69299 - acc: 0.5193 -- iter: 352/514
[A[ATraining Step: 114  | total loss: [1m[32m0.69321[0m[0m | time: 9.216s
[2K
| RMSProp | epoch: 007 | loss: 0.69321 - acc: 0.5111 -- iter: 384/514
[A[ATraining Step: 115  | total loss: [1m[32m0.69358[0m[0m | time: 10.085s
[2K
| RMSProp | epoch: 007 | loss: 0.69358 - acc: 0.4944 -- iter: 416/514
[A[ATraining Step: 116  | total loss: [1m[32m0.69324[0m[0m | time: 10.950s
[2K
| RMSProp | epoch: 007 | loss: 0.69324 - acc: 0.5137 -- iter: 448/514
[A[ATraining Step: 117  | total loss: [1m[32m0.69330[0m[0m | time: 11.901s
[2K
| RMSProp | epoch: 007 | loss: 0.69330 - acc: 0.5092 -- iter: 480/514
[A[ATraining Step: 118  | total loss: [1m[32m0.69351[0m[0m | time: 12.828s
[2K
| RMSProp | epoch: 007 | loss: 0.69351 - acc: 0.4989 -- iter: 512/514
[A[ATraining Step: 119  | total loss: [1m[32m0.69336[0m[0m | time: 14.726s
[2K
| RMSProp | epoch: 007 | loss: 0.69336 - acc: 0.5052 | val_loss: 0.69383 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 120  | total loss: [1m[32m0.69329[0m[0m | time: 0.948s
[2K
| RMSProp | epoch: 008 | loss: 0.69329 - acc: 0.5078 -- iter: 032/514
[A[ATraining Step: 121  | total loss: [1m[32m0.69329[0m[0m | time: 1.846s
[2K
| RMSProp | epoch: 008 | loss: 0.69329 - acc: 0.5071 -- iter: 064/514
[A[ATraining Step: 122  | total loss: [1m[32m0.69306[0m[0m | time: 2.772s
[2K
| RMSProp | epoch: 008 | loss: 0.69306 - acc: 0.5157 -- iter: 096/514
[A[ATraining Step: 123  | total loss: [1m[32m0.69280[0m[0m | time: 3.692s
[2K
| RMSProp | epoch: 008 | loss: 0.69280 - acc: 0.5235 -- iter: 128/514
[A[ATraining Step: 124  | total loss: [1m[32m0.69317[0m[0m | time: 4.572s
[2K
| RMSProp | epoch: 008 | loss: 0.69317 - acc: 0.5118 -- iter: 160/514
[A[ATraining Step: 125  | total loss: [1m[32m0.69317[0m[0m | time: 4.641s
[2K
| RMSProp | epoch: 008 | loss: 0.69317 - acc: 0.5106 -- iter: 192/514
[A[ATraining Step: 126  | total loss: [1m[32m0.69322[0m[0m | time: 4.750s
[2K
| RMSProp | epoch: 008 | loss: 0.69322 - acc: 0.5096 -- iter: 224/514
[A[ATraining Step: 127  | total loss: [1m[32m0.69322[0m[0m | time: 5.867s
[2K
| RMSProp | epoch: 008 | loss: 0.69322 - acc: 0.5086 -- iter: 256/514
[A[ATraining Step: 128  | total loss: [1m[32m0.69338[0m[0m | time: 6.865s
[2K
| RMSProp | epoch: 008 | loss: 0.69338 - acc: 0.5015 -- iter: 288/514
[A[ATraining Step: 129  | total loss: [1m[32m0.69331[0m[0m | time: 7.718s
[2K
| RMSProp | epoch: 008 | loss: 0.69331 - acc: 0.5045 -- iter: 320/514
[A[ATraining Step: 130  | total loss: [1m[32m0.69366[0m[0m | time: 8.512s
[2K
| RMSProp | epoch: 008 | loss: 0.69366 - acc: 0.4884 -- iter: 352/514
[A[ATraining Step: 131  | total loss: [1m[32m0.69366[0m[0m | time: 9.387s
[2K
| RMSProp | epoch: 008 | loss: 0.69366 - acc: 0.4864 -- iter: 384/514
[A[ATraining Step: 132  | total loss: [1m[32m0.69361[0m[0m | time: 10.263s
[2K
| RMSProp | epoch: 008 | loss: 0.69361 - acc: 0.4878 -- iter: 416/514
[A[ATraining Step: 133  | total loss: [1m[32m0.69343[0m[0m | time: 11.116s
[2K
| RMSProp | epoch: 008 | loss: 0.69343 - acc: 0.5046 -- iter: 448/514
[A[ATraining Step: 134  | total loss: [1m[32m0.69351[0m[0m | time: 11.981s
[2K
| RMSProp | epoch: 008 | loss: 0.69351 - acc: 0.4979 -- iter: 480/514
[A[ATraining Step: 135  | total loss: [1m[32m0.69332[0m[0m | time: 12.840s
[2K
| RMSProp | epoch: 008 | loss: 0.69332 - acc: 0.5075 -- iter: 512/514
[A[ATraining Step: 136  | total loss: [1m[32m0.69353[0m[0m | time: 14.779s
[2K
| RMSProp | epoch: 008 | loss: 0.69353 - acc: 0.4974 | val_loss: 0.69383 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 137  | total loss: [1m[32m0.69332[0m[0m | time: 0.922s
[2K
| RMSProp | epoch: 009 | loss: 0.69332 - acc: 0.5101 -- iter: 032/514
[A[ATraining Step: 138  | total loss: [1m[32m0.69317[0m[0m | time: 1.819s
[2K
| RMSProp | epoch: 009 | loss: 0.69317 - acc: 0.5154 -- iter: 064/514
[A[ATraining Step: 139  | total loss: [1m[32m0.69334[0m[0m | time: 2.691s
[2K
| RMSProp | epoch: 009 | loss: 0.69334 - acc: 0.5076 -- iter: 096/514
[A[ATraining Step: 140  | total loss: [1m[32m0.69347[0m[0m | time: 3.520s
[2K
| RMSProp | epoch: 009 | loss: 0.69347 - acc: 0.5006 -- iter: 128/514
[A[ATraining Step: 141  | total loss: [1m[32m0.69353[0m[0m | time: 4.419s
[2K
| RMSProp | epoch: 009 | loss: 0.69353 - acc: 0.4943 -- iter: 160/514
[A[ATraining Step: 142  | total loss: [1m[32m0.69326[0m[0m | time: 5.412s
[2K
| RMSProp | epoch: 009 | loss: 0.69326 - acc: 0.5167 -- iter: 192/514
[A[ATraining Step: 143  | total loss: [1m[32m0.69324[0m[0m | time: 5.530s
[2K
| RMSProp | epoch: 009 | loss: 0.69324 - acc: 0.5150 -- iter: 224/514
[A[ATraining Step: 144  | total loss: [1m[32m0.69204[0m[0m | time: 5.645s
[2K
| RMSProp | epoch: 009 | loss: 0.69204 - acc: 0.5635 -- iter: 256/514
[A[ATraining Step: 145  | total loss: [1m[32m0.68976[0m[0m | time: 6.502s
[2K
| RMSProp | epoch: 009 | loss: 0.68976 - acc: 0.6072 -- iter: 288/514
[A[ATraining Step: 146  | total loss: [1m[32m0.69100[0m[0m | time: 7.260s
[2K
| RMSProp | epoch: 009 | loss: 0.69100 - acc: 0.5902 -- iter: 320/514
[A[ATraining Step: 147  | total loss: [1m[32m0.69141[0m[0m | time: 8.118s
[2K
| RMSProp | epoch: 009 | loss: 0.69141 - acc: 0.5781 -- iter: 352/514
[A[ATraining Step: 148  | total loss: [1m[32m0.69099[0m[0m | time: 8.947s
[2K
| RMSProp | epoch: 009 | loss: 0.69099 - acc: 0.5828 -- iter: 384/514
[A[ATraining Step: 149  | total loss: [1m[32m0.69175[0m[0m | time: 9.822s
[2K
| RMSProp | epoch: 009 | loss: 0.69175 - acc: 0.5682 -- iter: 416/514
[A[ATraining Step: 150  | total loss: [1m[32m0.69225[0m[0m | time: 10.704s
[2K
| RMSProp | epoch: 009 | loss: 0.69225 - acc: 0.5552 -- iter: 448/514
[A[ATraining Step: 151  | total loss: [1m[32m0.69224[0m[0m | time: 11.617s
[2K
| RMSProp | epoch: 009 | loss: 0.69224 - acc: 0.5528 -- iter: 480/514
[A[ATraining Step: 152  | total loss: [1m[32m0.69252[0m[0m | time: 12.485s
[2K
| RMSProp | epoch: 009 | loss: 0.69252 - acc: 0.5444 -- iter: 512/514
[A[ATraining Step: 153  | total loss: [1m[32m0.69212[0m[0m | time: 14.379s
[2K
| RMSProp | epoch: 009 | loss: 0.69212 - acc: 0.5524 | val_loss: 0.69505 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 154  | total loss: [1m[32m0.69231[0m[0m | time: 0.866s
[2K
| RMSProp | epoch: 010 | loss: 0.69231 - acc: 0.5472 -- iter: 032/514
[A[ATraining Step: 155  | total loss: [1m[32m0.69226[0m[0m | time: 1.752s
[2K
| RMSProp | epoch: 010 | loss: 0.69226 - acc: 0.5456 -- iter: 064/514
[A[ATraining Step: 156  | total loss: [1m[32m0.69236[0m[0m | time: 2.625s
[2K
| RMSProp | epoch: 010 | loss: 0.69236 - acc: 0.5410 -- iter: 096/514
[A[ATraining Step: 157  | total loss: [1m[32m0.69329[0m[0m | time: 3.530s
[2K
| RMSProp | epoch: 010 | loss: 0.69329 - acc: 0.5213 -- iter: 128/514
[A[ATraining Step: 158  | total loss: [1m[32m0.69333[0m[0m | time: 4.365s
[2K
| RMSProp | epoch: 010 | loss: 0.69333 - acc: 0.5192 -- iter: 160/514
[A[ATraining Step: 159  | total loss: [1m[32m0.69325[0m[0m | time: 5.272s
[2K
| RMSProp | epoch: 010 | loss: 0.69325 - acc: 0.5204 -- iter: 192/514
[A[ATraining Step: 160  | total loss: [1m[32m0.69327[0m[0m | time: 6.290s
[2K
| RMSProp | epoch: 010 | loss: 0.69327 - acc: 0.5183 -- iter: 224/514
[A[ATraining Step: 161  | total loss: [1m[32m0.69299[0m[0m | time: 6.403s
[2K
| RMSProp | epoch: 010 | loss: 0.69299 - acc: 0.5259 -- iter: 256/514
[A[ATraining Step: 162  | total loss: [1m[32m0.69513[0m[0m | time: 6.517s
[2K
| RMSProp | epoch: 010 | loss: 0.69513 - acc: 0.4733 -- iter: 288/514
[A[ATraining Step: 163  | total loss: [1m[32m0.69563[0m[0m | time: 7.438s
[2K
| RMSProp | epoch: 010 | loss: 0.69563 - acc: 0.4260 -- iter: 320/514
[A[ATraining Step: 164  | total loss: [1m[32m0.69498[0m[0m | time: 8.179s
[2K
| RMSProp | epoch: 010 | loss: 0.69498 - acc: 0.4427 -- iter: 352/514
[A[ATraining Step: 165  | total loss: [1m[32m0.69559[0m[0m | time: 9.013s
[2K
| RMSProp | epoch: 010 | loss: 0.69559 - acc: 0.4422 -- iter: 384/514
[A[ATraining Step: 166  | total loss: [1m[32m0.69539[0m[0m | time: 9.860s
[2K
| RMSProp | epoch: 010 | loss: 0.69539 - acc: 0.4449 -- iter: 416/514
[A[ATraining Step: 167  | total loss: [1m[32m0.69515[0m[0m | time: 10.706s
[2K
| RMSProp | epoch: 010 | loss: 0.69515 - acc: 0.4504 -- iter: 448/514
[A[ATraining Step: 168  | total loss: [1m[32m0.69482[0m[0m | time: 11.553s
[2K
| RMSProp | epoch: 010 | loss: 0.69482 - acc: 0.4616 -- iter: 480/514
[A[ATraining Step: 169  | total loss: [1m[32m0.69445[0m[0m | time: 12.502s
[2K
| RMSProp | epoch: 010 | loss: 0.69445 - acc: 0.4717 -- iter: 512/514
[A[ATraining Step: 170  | total loss: [1m[32m0.69491[0m[0m | time: 14.376s
[2K
| RMSProp | epoch: 010 | loss: 0.69491 - acc: 0.4651 | val_loss: 0.69250 - val_acc: 0.5280 -- iter: 514/514
--
Training Step: 171  | total loss: [1m[32m0.69465[0m[0m | time: 0.919s
[2K
| RMSProp | epoch: 011 | loss: 0.69465 - acc: 0.4811 -- iter: 032/514
[A[ATraining Step: 172  | total loss: [1m[32m0.69453[0m[0m | time: 1.800s
[2K
| RMSProp | epoch: 011 | loss: 0.69453 - acc: 0.4830 -- iter: 064/514
[A[ATraining Step: 173  | total loss: [1m[32m0.69431[0m[0m | time: 2.624s
[2K
| RMSProp | epoch: 011 | loss: 0.69431 - acc: 0.4878 -- iter: 096/514
[A[ATraining Step: 174  | total loss: [1m[32m0.69416[0m[0m | time: 3.458s
[2K
| RMSProp | epoch: 011 | loss: 0.69416 - acc: 0.4891 -- iter: 128/514
[A[ATraining Step: 175  | total loss: [1m[32m0.69420[0m[0m | time: 4.485s
[2K
| RMSProp | epoch: 011 | loss: 0.69420 - acc: 0.4839 -- iter: 160/514
[A[ATraining Step: 176  | total loss: [1m[32m0.69395[0m[0m | time: 5.495s
[2K
| RMSProp | epoch: 011 | loss: 0.69395 - acc: 0.5011 -- iter: 192/514
[A[ATraining Step: 177  | total loss: [1m[32m0.69449[0m[0m | time: 6.221s
[2K
| RMSProp | epoch: 011 | loss: 0.69449 - acc: 0.4885 -- iter: 224/514
[A[ATraining Step: 178  | total loss: [1m[32m0.69437[0m[0m | time: 7.034s
[2K
| RMSProp | epoch: 011 | loss: 0.69437 - acc: 0.4834 -- iter: 256/514
[A[ATraining Step: 179  | total loss: [1m[32m0.69424[0m[0m | time: 7.121s
[2K
| RMSProp | epoch: 011 | loss: 0.69424 - acc: 0.4851 -- iter: 288/514
[A[ATraining Step: 180  | total loss: [1m[32m0.69409[0m[0m | time: 7.213s
[2K
| RMSProp | epoch: 011 | loss: 0.69409 - acc: 0.4866 -- iter: 320/514
[A[ATraining Step: 181  | total loss: [1m[32m0.69393[0m[0m | time: 8.084s
[2K
| RMSProp | epoch: 011 | loss: 0.69393 - acc: 0.5379 -- iter: 352/514
[A[ATraining Step: 182  | total loss: [1m[32m0.69383[0m[0m | time: 8.980s
[2K
| RMSProp | epoch: 011 | loss: 0.69383 - acc: 0.5466 -- iter: 384/514
[A[ATraining Step: 183  | total loss: [1m[32m0.69393[0m[0m | time: 9.889s
[2K
| RMSProp | epoch: 011 | loss: 0.69393 - acc: 0.5232 -- iter: 416/514
[A[ATraining Step: 184  | total loss: [1m[32m0.69390[0m[0m | time: 10.804s
[2K
| RMSProp | epoch: 011 | loss: 0.69390 - acc: 0.5178 -- iter: 448/514
[A[ATraining Step: 185  | total loss: [1m[32m0.69395[0m[0m | time: 11.707s
[2K
| RMSProp | epoch: 011 | loss: 0.69395 - acc: 0.5035 -- iter: 480/514
[A[ATraining Step: 186  | total loss: [1m[32m0.69384[0m[0m | time: 12.562s
[2K
| RMSProp | epoch: 011 | loss: 0.69384 - acc: 0.5094 -- iter: 512/514
[A[ATraining Step: 187  | total loss: [1m[32m0.69371[0m[0m | time: 14.426s
[2K
| RMSProp | epoch: 011 | loss: 0.69371 - acc: 0.5147 | val_loss: 0.69326 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 188  | total loss: [1m[32m0.69372[0m[0m | time: 0.872s
[2K
| RMSProp | epoch: 012 | loss: 0.69372 - acc: 0.5070 -- iter: 032/514
[A[ATraining Step: 189  | total loss: [1m[32m0.69360[0m[0m | time: 1.724s
[2K
| RMSProp | epoch: 012 | loss: 0.69360 - acc: 0.5188 -- iter: 064/514
[A[ATraining Step: 190  | total loss: [1m[32m0.69355[0m[0m | time: 2.578s
[2K
| RMSProp | epoch: 012 | loss: 0.69355 - acc: 0.5169 -- iter: 096/514
[A[ATraining Step: 191  | total loss: [1m[32m0.69354[0m[0m | time: 3.501s
[2K
| RMSProp | epoch: 012 | loss: 0.69354 - acc: 0.5121 -- iter: 128/514
[A[ATraining Step: 192  | total loss: [1m[32m0.69346[0m[0m | time: 4.411s
[2K
| RMSProp | epoch: 012 | loss: 0.69346 - acc: 0.5140 -- iter: 160/514
[A[ATraining Step: 193  | total loss: [1m[32m0.69342[0m[0m | time: 5.158s
[2K
| RMSProp | epoch: 012 | loss: 0.69342 - acc: 0.5126 -- iter: 192/514
[A[ATraining Step: 194  | total loss: [1m[32m0.69326[0m[0m | time: 6.081s
[2K
| RMSProp | epoch: 012 | loss: 0.69326 - acc: 0.5207 -- iter: 224/514
[A[ATraining Step: 195  | total loss: [1m[32m0.69339[0m[0m | time: 7.084s
[2K
| RMSProp | epoch: 012 | loss: 0.69339 - acc: 0.5124 -- iter: 256/514
[A[ATraining Step: 196  | total loss: [1m[32m0.69346[0m[0m | time: 8.000s
[2K
| RMSProp | epoch: 012 | loss: 0.69346 - acc: 0.5049 -- iter: 288/514
[A[ATraining Step: 197  | total loss: [1m[32m0.69348[0m[0m | time: 8.064s
[2K
| RMSProp | epoch: 012 | loss: 0.69348 - acc: 0.4982 -- iter: 320/514
[A[ATraining Step: 198  | total loss: [1m[32m0.69351[0m[0m | time: 8.127s
[2K
| RMSProp | epoch: 012 | loss: 0.69351 - acc: 0.4483 -- iter: 352/514
[A[ATraining Step: 199  | total loss: [1m[32m0.69028[0m[0m | time: 8.923s
[2K
| RMSProp | epoch: 012 | loss: 0.69028 - acc: 0.5035 -- iter: 384/514
[A[ATraining Step: 200  | total loss: [1m[32m0.69703[0m[0m | time: 10.762s
[2K
| RMSProp | epoch: 012 | loss: 0.69703 - acc: 0.5000 | val_loss: 0.69205 - val_acc: 0.5280 -- iter: 416/514
--
Training Step: 201  | total loss: [1m[32m0.69751[0m[0m | time: 11.777s
[2K
| RMSProp | epoch: 012 | loss: 0.69751 - acc: 0.4875 -- iter: 448/514
[A[ATraining Step: 202  | total loss: [1m[32m0.69721[0m[0m | time: 12.787s
[2K
| RMSProp | epoch: 012 | loss: 0.69721 - acc: 0.4857 -- iter: 480/514
[A[ATraining Step: 203  | total loss: [1m[32m0.69716[0m[0m | time: 13.617s
[2K
| RMSProp | epoch: 012 | loss: 0.69716 - acc: 0.4777 -- iter: 512/514
[A[ATraining Step: 204  | total loss: [1m[32m0.69724[0m[0m | time: 15.402s
[2K
| RMSProp | epoch: 012 | loss: 0.69724 - acc: 0.4612 | val_loss: 0.69281 - val_acc: 0.5280 -- iter: 514/514
--
Training Step: 205  | total loss: [1m[32m0.69680[0m[0m | time: 0.855s
[2K
| RMSProp | epoch: 013 | loss: 0.69680 - acc: 0.4682 -- iter: 032/514
[A[ATraining Step: 206  | total loss: [1m[32m0.69637[0m[0m | time: 1.831s
[2K
| RMSProp | epoch: 013 | loss: 0.69637 - acc: 0.4745 -- iter: 064/514
[A[ATraining Step: 207  | total loss: [1m[32m0.69597[0m[0m | time: 2.807s
[2K
| RMSProp | epoch: 013 | loss: 0.69597 - acc: 0.4802 -- iter: 096/514
[A[ATraining Step: 208  | total loss: [1m[32m0.69557[0m[0m | time: 3.800s
[2K
| RMSProp | epoch: 013 | loss: 0.69557 - acc: 0.4853 -- iter: 128/514
[A[ATraining Step: 209  | total loss: [1m[32m0.69540[0m[0m | time: 4.506s
[2K
| RMSProp | epoch: 013 | loss: 0.69540 - acc: 0.4868 -- iter: 160/514
[A[ATraining Step: 210  | total loss: [1m[32m0.69494[0m[0m | time: 5.332s
[2K
| RMSProp | epoch: 013 | loss: 0.69494 - acc: 0.4975 -- iter: 192/514
[A[ATraining Step: 211  | total loss: [1m[32m0.69531[0m[0m | time: 6.177s
[2K
| RMSProp | epoch: 013 | loss: 0.69531 - acc: 0.4883 -- iter: 224/514
[A[ATraining Step: 212  | total loss: [1m[32m0.69492[0m[0m | time: 7.015s
[2K
| RMSProp | epoch: 013 | loss: 0.69492 - acc: 0.4989 -- iter: 256/514
[A[ATraining Step: 213  | total loss: [1m[32m0.69483[0m[0m | time: 7.881s
[2K
| RMSProp | epoch: 013 | loss: 0.69483 - acc: 0.4959 -- iter: 288/514
[A[ATraining Step: 214  | total loss: [1m[32m0.69460[0m[0m | time: 8.751s
[2K
| RMSProp | epoch: 013 | loss: 0.69460 - acc: 0.4994 -- iter: 320/514
[A[ATraining Step: 215  | total loss: [1m[32m0.69413[0m[0m | time: 8.853s
[2K
| RMSProp | epoch: 013 | loss: 0.69413 - acc: 0.5120 -- iter: 352/514
[A[ATraining Step: 216  | total loss: [1m[32m0.69404[0m[0m | time: 8.948s
[2K
| RMSProp | epoch: 013 | loss: 0.69404 - acc: 0.5108 -- iter: 384/514
[A[ATraining Step: 217  | total loss: [1m[32m0.69378[0m[0m | time: 9.833s
[2K
| RMSProp | epoch: 013 | loss: 0.69378 - acc: 0.5097 -- iter: 416/514
[A[ATraining Step: 218  | total loss: [1m[32m0.69391[0m[0m | time: 10.734s
[2K
| RMSProp | epoch: 013 | loss: 0.69391 - acc: 0.5056 -- iter: 448/514
[A[ATraining Step: 219  | total loss: [1m[32m0.69389[0m[0m | time: 11.614s
[2K
| RMSProp | epoch: 013 | loss: 0.69389 - acc: 0.4988 -- iter: 480/514
[A[ATraining Step: 220  | total loss: [1m[32m0.69388[0m[0m | time: 12.634s
[2K
| RMSProp | epoch: 013 | loss: 0.69388 - acc: 0.4927 -- iter: 512/514
[A[ATraining Step: 221  | total loss: [1m[32m0.69346[0m[0m | time: 14.643s
[2K
| RMSProp | epoch: 013 | loss: 0.69346 - acc: 0.5090 | val_loss: 0.69145 - val_acc: 0.5280 -- iter: 514/514
--
Training Step: 222  | total loss: [1m[32m0.69276[0m[0m | time: 0.933s
[2K
| RMSProp | epoch: 014 | loss: 0.69276 - acc: 0.5175 -- iter: 032/514
[A[ATraining Step: 223  | total loss: [1m[32m0.69455[0m[0m | time: 1.778s
[2K
| RMSProp | epoch: 014 | loss: 0.69455 - acc: 0.5064 -- iter: 064/514
[A[ATraining Step: 224  | total loss: [1m[32m0.69444[0m[0m | time: 2.621s
[2K
| RMSProp | epoch: 014 | loss: 0.69444 - acc: 0.5057 -- iter: 096/514
[A[ATraining Step: 225  | total loss: [1m[32m0.69457[0m[0m | time: 3.621s
[2K
| RMSProp | epoch: 014 | loss: 0.69457 - acc: 0.4958 -- iter: 128/514
[A[ATraining Step: 226  | total loss: [1m[32m0.69430[0m[0m | time: 4.653s
[2K
| RMSProp | epoch: 014 | loss: 0.69430 - acc: 0.5025 -- iter: 160/514
[A[ATraining Step: 227  | total loss: [1m[32m0.69415[0m[0m | time: 5.369s
[2K
| RMSProp | epoch: 014 | loss: 0.69415 - acc: 0.5022 -- iter: 192/514
[A[ATraining Step: 228  | total loss: [1m[32m0.69418[0m[0m | time: 6.165s
[2K
| RMSProp | epoch: 014 | loss: 0.69418 - acc: 0.4957 -- iter: 224/514
[A[ATraining Step: 229  | total loss: [1m[32m0.69413[0m[0m | time: 7.039s
[2K
| RMSProp | epoch: 014 | loss: 0.69413 - acc: 0.4930 -- iter: 256/514
[A[ATraining Step: 230  | total loss: [1m[32m0.69405[0m[0m | time: 7.940s
[2K
| RMSProp | epoch: 014 | loss: 0.69405 - acc: 0.4906 -- iter: 288/514
[A[ATraining Step: 231  | total loss: [1m[32m0.69399[0m[0m | time: 8.786s
[2K
| RMSProp | epoch: 014 | loss: 0.69399 - acc: 0.4915 -- iter: 320/514
[A[ATraining Step: 232  | total loss: [1m[32m0.69389[0m[0m | time: 9.672s
[2K
| RMSProp | epoch: 014 | loss: 0.69389 - acc: 0.4924 -- iter: 352/514
[A[ATraining Step: 233  | total loss: [1m[32m0.69378[0m[0m | time: 9.772s
[2K
| RMSProp | epoch: 014 | loss: 0.69378 - acc: 0.4932 -- iter: 384/514
[A[ATraining Step: 234  | total loss: [1m[32m0.69382[0m[0m | time: 9.859s
[2K
| RMSProp | epoch: 014 | loss: 0.69382 - acc: 0.4938 -- iter: 416/514
[A[ATraining Step: 235  | total loss: [1m[32m0.69372[0m[0m | time: 10.783s
[2K
| RMSProp | epoch: 014 | loss: 0.69372 - acc: 0.4945 -- iter: 448/514
[A[ATraining Step: 236  | total loss: [1m[32m0.69371[0m[0m | time: 11.634s
[2K
| RMSProp | epoch: 014 | loss: 0.69371 - acc: 0.4888 -- iter: 480/514
[A[ATraining Step: 237  | total loss: [1m[32m0.69360[0m[0m | time: 12.457s
[2K
| RMSProp | epoch: 014 | loss: 0.69360 - acc: 0.4961 -- iter: 512/514
[A[ATraining Step: 238  | total loss: [1m[32m0.69346[0m[0m | time: 14.456s
[2K
| RMSProp | epoch: 014 | loss: 0.69346 - acc: 0.5028 | val_loss: 0.69589 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 239  | total loss: [1m[32m0.69292[0m[0m | time: 0.923s
[2K
| RMSProp | epoch: 015 | loss: 0.69292 - acc: 0.5212 -- iter: 032/514
[A[ATraining Step: 240  | total loss: [1m[32m0.69389[0m[0m | time: 1.834s
[2K
| RMSProp | epoch: 015 | loss: 0.69389 - acc: 0.5066 -- iter: 064/514
[A[ATraining Step: 241  | total loss: [1m[32m0.69342[0m[0m | time: 2.750s
[2K
| RMSProp | epoch: 015 | loss: 0.69342 - acc: 0.5216 -- iter: 096/514
[A[ATraining Step: 242  | total loss: [1m[32m0.69352[0m[0m | time: 3.587s
[2K
| RMSProp | epoch: 015 | loss: 0.69352 - acc: 0.5163 -- iter: 128/514
[A[ATraining Step: 243  | total loss: [1m[32m0.69328[0m[0m | time: 4.611s
[2K
| RMSProp | epoch: 015 | loss: 0.69328 - acc: 0.5209 -- iter: 160/514
[A[ATraining Step: 244  | total loss: [1m[32m0.69356[0m[0m | time: 5.640s
[2K
| RMSProp | epoch: 015 | loss: 0.69356 - acc: 0.5126 -- iter: 192/514
[A[ATraining Step: 245  | total loss: [1m[32m0.69364[0m[0m | time: 6.432s
[2K
| RMSProp | epoch: 015 | loss: 0.69364 - acc: 0.5082 -- iter: 224/514
[A[ATraining Step: 246  | total loss: [1m[32m0.69394[0m[0m | time: 7.231s
[2K
| RMSProp | epoch: 015 | loss: 0.69394 - acc: 0.4949 -- iter: 256/514
[A[ATraining Step: 247  | total loss: [1m[32m0.69377[0m[0m | time: 8.077s
[2K
| RMSProp | epoch: 015 | loss: 0.69377 - acc: 0.5016 -- iter: 288/514
[A[ATraining Step: 248  | total loss: [1m[32m0.69373[0m[0m | time: 8.943s
[2K
| RMSProp | epoch: 015 | loss: 0.69373 - acc: 0.5015 -- iter: 320/514
[A[ATraining Step: 249  | total loss: [1m[32m0.69338[0m[0m | time: 9.835s
[2K
| RMSProp | epoch: 015 | loss: 0.69338 - acc: 0.5170 -- iter: 352/514
[A[ATraining Step: 250  | total loss: [1m[32m0.69337[0m[0m | time: 10.711s
[2K
| RMSProp | epoch: 015 | loss: 0.69337 - acc: 0.5153 -- iter: 384/514
[A[ATraining Step: 251  | total loss: [1m[32m0.69368[0m[0m | time: 10.808s
[2K
| RMSProp | epoch: 015 | loss: 0.69368 - acc: 0.5044 -- iter: 416/514
[A[ATraining Step: 252  | total loss: [1m[32m0.69360[0m[0m | time: 10.912s
[2K
| RMSProp | epoch: 015 | loss: 0.69360 - acc: 0.5039 -- iter: 448/514
[A[ATraining Step: 253  | total loss: [1m[32m0.69352[0m[0m | time: 11.803s
[2K
| RMSProp | epoch: 015 | loss: 0.69352 - acc: 0.5035 -- iter: 480/514
[A[ATraining Step: 254  | total loss: [1m[32m0.69355[0m[0m | time: 12.691s
[2K
| RMSProp | epoch: 015 | loss: 0.69355 - acc: 0.5001 -- iter: 512/514
[A[ATraining Step: 255  | total loss: [1m[32m0.69371[0m[0m | time: 14.476s
[2K
| RMSProp | epoch: 015 | loss: 0.69371 - acc: 0.4875 | val_loss: 0.69323 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 256  | total loss: [1m[32m0.69369[0m[0m | time: 0.841s
[2K
| RMSProp | epoch: 016 | loss: 0.69369 - acc: 0.4825 -- iter: 032/514
[A[ATraining Step: 257  | total loss: [1m[32m0.69364[0m[0m | time: 1.776s
[2K
| RMSProp | epoch: 016 | loss: 0.69364 - acc: 0.4843 -- iter: 064/514
[A[ATraining Step: 258  | total loss: [1m[32m0.69364[0m[0m | time: 2.671s
[2K
| RMSProp | epoch: 016 | loss: 0.69364 - acc: 0.4734 -- iter: 096/514
[A[ATraining Step: 259  | total loss: [1m[32m0.69353[0m[0m | time: 3.526s
[2K
| RMSProp | epoch: 016 | loss: 0.69353 - acc: 0.4791 -- iter: 128/514
[A[ATraining Step: 260  | total loss: [1m[32m0.69344[0m[0m | time: 4.325s
[2K
| RMSProp | epoch: 016 | loss: 0.69344 - acc: 0.4844 -- iter: 160/514
[A[ATraining Step: 261  | total loss: [1m[32m0.69319[0m[0m | time: 5.274s
[2K
| RMSProp | epoch: 016 | loss: 0.69319 - acc: 0.4922 -- iter: 192/514
[A[ATraining Step: 262  | total loss: [1m[32m0.69241[0m[0m | time: 6.317s
[2K
| RMSProp | epoch: 016 | loss: 0.69241 - acc: 0.5023 -- iter: 224/514
[A[ATraining Step: 263  | total loss: [1m[32m0.69686[0m[0m | time: 7.217s
[2K
| RMSProp | epoch: 016 | loss: 0.69686 - acc: 0.4958 -- iter: 256/514
[A[ATraining Step: 264  | total loss: [1m[32m0.69605[0m[0m | time: 8.003s
[2K
| RMSProp | epoch: 016 | loss: 0.69605 - acc: 0.5088 -- iter: 288/514
[A[ATraining Step: 265  | total loss: [1m[32m0.69593[0m[0m | time: 8.833s
[2K
| RMSProp | epoch: 016 | loss: 0.69593 - acc: 0.5048 -- iter: 320/514
[A[ATraining Step: 266  | total loss: [1m[32m0.69611[0m[0m | time: 9.746s
[2K
| RMSProp | epoch: 016 | loss: 0.69611 - acc: 0.4949 -- iter: 352/514
[A[ATraining Step: 267  | total loss: [1m[32m0.69605[0m[0m | time: 10.606s
[2K
| RMSProp | epoch: 016 | loss: 0.69605 - acc: 0.4892 -- iter: 384/514
[A[ATraining Step: 268  | total loss: [1m[32m0.69600[0m[0m | time: 11.513s
[2K
| RMSProp | epoch: 016 | loss: 0.69600 - acc: 0.4715 -- iter: 416/514
[A[ATraining Step: 269  | total loss: [1m[32m0.69557[0m[0m | time: 11.610s
[2K
| RMSProp | epoch: 016 | loss: 0.69557 - acc: 0.4869 -- iter: 448/514
[A[ATraining Step: 270  | total loss: [1m[32m0.69528[0m[0m | time: 11.702s
[2K
| RMSProp | epoch: 016 | loss: 0.69528 - acc: 0.4882 -- iter: 480/514
[A[ATraining Step: 271  | total loss: [1m[32m0.69501[0m[0m | time: 12.604s
[2K
| RMSProp | epoch: 016 | loss: 0.69501 - acc: 0.4893 -- iter: 512/514
[A[ATraining Step: 272  | total loss: [1m[32m0.69494[0m[0m | time: 14.490s
[2K
| RMSProp | epoch: 016 | loss: 0.69494 - acc: 0.4842 | val_loss: 0.69269 - val_acc: 0.5280 -- iter: 514/514
--
Training Step: 273  | total loss: [1m[32m0.69479[0m[0m | time: 0.867s
[2K
| RMSProp | epoch: 017 | loss: 0.69479 - acc: 0.4795 -- iter: 032/514
[A[ATraining Step: 274  | total loss: [1m[32m0.69466[0m[0m | time: 1.746s
[2K
| RMSProp | epoch: 017 | loss: 0.69466 - acc: 0.4784 -- iter: 064/514
[A[ATraining Step: 275  | total loss: [1m[32m0.69451[0m[0m | time: 2.606s
[2K
| RMSProp | epoch: 017 | loss: 0.69451 - acc: 0.4743 -- iter: 096/514
[A[ATraining Step: 276  | total loss: [1m[32m0.69438[0m[0m | time: 3.469s
[2K
| RMSProp | epoch: 017 | loss: 0.69438 - acc: 0.4738 -- iter: 128/514
[A[ATraining Step: 277  | total loss: [1m[32m0.69437[0m[0m | time: 4.302s
[2K
| RMSProp | epoch: 017 | loss: 0.69437 - acc: 0.4701 -- iter: 160/514
[A[ATraining Step: 278  | total loss: [1m[32m0.69423[0m[0m | time: 5.179s
[2K
| RMSProp | epoch: 017 | loss: 0.69423 - acc: 0.4763 -- iter: 192/514
[A[ATraining Step: 279  | total loss: [1m[32m0.69407[0m[0m | time: 6.185s
[2K
| RMSProp | epoch: 017 | loss: 0.69407 - acc: 0.4974 -- iter: 224/514
[A[ATraining Step: 280  | total loss: [1m[32m0.69388[0m[0m | time: 7.207s
[2K
| RMSProp | epoch: 017 | loss: 0.69388 - acc: 0.5008 -- iter: 256/514
[A[ATraining Step: 281  | total loss: [1m[32m0.69372[0m[0m | time: 7.916s
[2K
| RMSProp | epoch: 017 | loss: 0.69372 - acc: 0.5038 -- iter: 288/514
[A[ATraining Step: 282  | total loss: [1m[32m0.69377[0m[0m | time: 8.737s
[2K
| RMSProp | epoch: 017 | loss: 0.69377 - acc: 0.4972 -- iter: 320/514
[A[ATraining Step: 283  | total loss: [1m[32m0.69369[0m[0m | time: 9.577s
[2K
| RMSProp | epoch: 017 | loss: 0.69369 - acc: 0.5006 -- iter: 352/514
[A[ATraining Step: 284  | total loss: [1m[32m0.69358[0m[0m | time: 10.436s
[2K
| RMSProp | epoch: 017 | loss: 0.69358 - acc: 0.5162 -- iter: 384/514
[A[ATraining Step: 285  | total loss: [1m[32m0.69326[0m[0m | time: 11.252s
[2K
| RMSProp | epoch: 017 | loss: 0.69326 - acc: 0.5239 -- iter: 416/514
[A[ATraining Step: 286  | total loss: [1m[32m0.69390[0m[0m | time: 12.170s
[2K
| RMSProp | epoch: 017 | loss: 0.69390 - acc: 0.5121 -- iter: 448/514
[A[ATraining Step: 287  | total loss: [1m[32m0.69374[0m[0m | time: 12.266s
[2K
| RMSProp | epoch: 017 | loss: 0.69374 - acc: 0.5234 -- iter: 480/514
[A[ATraining Step: 288  | total loss: [1m[32m0.69343[0m[0m | time: 12.362s
[2K
| RMSProp | epoch: 017 | loss: 0.69343 - acc: 0.5711 -- iter: 512/514
[A[ATraining Step: 289  | total loss: [1m[32m0.69160[0m[0m | time: 14.256s
[2K
| RMSProp | epoch: 017 | loss: 0.69160 - acc: 0.6140 | val_loss: 0.69495 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 290  | total loss: [1m[32m0.69207[0m[0m | time: 0.851s
[2K
| RMSProp | epoch: 018 | loss: 0.69207 - acc: 0.5995 -- iter: 032/514
[A[ATraining Step: 291  | total loss: [1m[32m0.69233[0m[0m | time: 1.712s
[2K
| RMSProp | epoch: 018 | loss: 0.69233 - acc: 0.5864 -- iter: 064/514
[A[ATraining Step: 292  | total loss: [1m[32m0.69258[0m[0m | time: 2.648s
[2K
| RMSProp | epoch: 018 | loss: 0.69258 - acc: 0.5746 -- iter: 096/514
[A[ATraining Step: 293  | total loss: [1m[32m0.69358[0m[0m | time: 3.639s
[2K
| RMSProp | epoch: 018 | loss: 0.69358 - acc: 0.5453 -- iter: 128/514
[A[ATraining Step: 294  | total loss: [1m[32m0.69351[0m[0m | time: 4.436s
[2K
| RMSProp | epoch: 018 | loss: 0.69351 - acc: 0.5408 -- iter: 160/514
[A[ATraining Step: 295  | total loss: [1m[32m0.69319[0m[0m | time: 5.449s
[2K
| RMSProp | epoch: 018 | loss: 0.69319 - acc: 0.5492 -- iter: 192/514
[A[ATraining Step: 296  | total loss: [1m[32m0.69246[0m[0m | time: 6.446s
[2K
| RMSProp | epoch: 018 | loss: 0.69246 - acc: 0.5661 -- iter: 224/514
[A[ATraining Step: 297  | total loss: [1m[32m0.69286[0m[0m | time: 7.341s
[2K
| RMSProp | epoch: 018 | loss: 0.69286 - acc: 0.5533 -- iter: 256/514
[A[ATraining Step: 298  | total loss: [1m[32m0.69231[0m[0m | time: 8.072s
[2K
| RMSProp | epoch: 018 | loss: 0.69231 - acc: 0.5636 -- iter: 288/514
[A[ATraining Step: 299  | total loss: [1m[32m0.69305[0m[0m | time: 8.963s
[2K
| RMSProp | epoch: 018 | loss: 0.69305 - acc: 0.5447 -- iter: 320/514
[A[ATraining Step: 300  | total loss: [1m[32m0.69283[0m[0m | time: 9.818s
[2K
| RMSProp | epoch: 018 | loss: 0.69283 - acc: 0.5465 -- iter: 352/514
[A[ATraining Step: 301  | total loss: [1m[32m0.69302[0m[0m | time: 10.672s
[2K
| RMSProp | epoch: 018 | loss: 0.69302 - acc: 0.5387 -- iter: 384/514
[A[ATraining Step: 302  | total loss: [1m[32m0.69332[0m[0m | time: 11.572s
[2K
| RMSProp | epoch: 018 | loss: 0.69332 - acc: 0.5286 -- iter: 416/514
[A[ATraining Step: 303  | total loss: [1m[32m0.69342[0m[0m | time: 12.500s
[2K
| RMSProp | epoch: 018 | loss: 0.69342 - acc: 0.5226 -- iter: 448/514
[A[ATraining Step: 304  | total loss: [1m[32m0.69321[0m[0m | time: 13.438s
[2K
| RMSProp | epoch: 018 | loss: 0.69321 - acc: 0.5266 -- iter: 480/514
[A[ATraining Step: 305  | total loss: [1m[32m0.69297[0m[0m | time: 13.531s
[2K
| RMSProp | epoch: 018 | loss: 0.69297 - acc: 0.5302 -- iter: 512/514
[A[ATraining Step: 306  | total loss: [1m[32m0.69300[0m[0m | time: 14.658s
[2K
| RMSProp | epoch: 018 | loss: 0.69300 - acc: 0.5272 | val_loss: 0.69435 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 307  | total loss: [1m[32m0.69293[0m[0m | time: 0.957s
[2K
| RMSProp | epoch: 019 | loss: 0.69293 - acc: 0.5245 -- iter: 032/514
[A[ATraining Step: 308  | total loss: [1m[32m0.69344[0m[0m | time: 1.860s
[2K
| RMSProp | epoch: 019 | loss: 0.69344 - acc: 0.5095 -- iter: 064/514
[A[ATraining Step: 309  | total loss: [1m[32m0.69322[0m[0m | time: 2.742s
[2K
| RMSProp | epoch: 019 | loss: 0.69322 - acc: 0.5148 -- iter: 096/514
[A[ATraining Step: 310  | total loss: [1m[32m0.69331[0m[0m | time: 3.623s
[2K
| RMSProp | epoch: 019 | loss: 0.69331 - acc: 0.5102 -- iter: 128/514
[A[ATraining Step: 311  | total loss: [1m[32m0.69355[0m[0m | time: 4.521s
[2K
| RMSProp | epoch: 019 | loss: 0.69355 - acc: 0.4998 -- iter: 160/514
[A[ATraining Step: 312  | total loss: [1m[32m0.69337[0m[0m | time: 5.296s
[2K
| RMSProp | epoch: 019 | loss: 0.69337 - acc: 0.5061 -- iter: 192/514
[A[ATraining Step: 313  | total loss: [1m[32m0.69308[0m[0m | time: 6.301s
[2K
| RMSProp | epoch: 019 | loss: 0.69308 - acc: 0.5148 -- iter: 224/514
[A[ATraining Step: 314  | total loss: [1m[32m0.69365[0m[0m | time: 7.411s
[2K
| RMSProp | epoch: 019 | loss: 0.69365 - acc: 0.4977 -- iter: 256/514
[A[ATraining Step: 315  | total loss: [1m[32m0.69355[0m[0m | time: 8.239s
[2K
| RMSProp | epoch: 019 | loss: 0.69355 - acc: 0.4980 -- iter: 288/514
[A[ATraining Step: 316  | total loss: [1m[32m0.69351[0m[0m | time: 9.071s
[2K
| RMSProp | epoch: 019 | loss: 0.69351 - acc: 0.4950 -- iter: 320/514
[A[ATraining Step: 317  | total loss: [1m[32m0.69340[0m[0m | time: 9.925s
[2K
| RMSProp | epoch: 019 | loss: 0.69340 - acc: 0.4987 -- iter: 352/514
[A[ATraining Step: 318  | total loss: [1m[32m0.69347[0m[0m | time: 10.764s
[2K
| RMSProp | epoch: 019 | loss: 0.69347 - acc: 0.4863 -- iter: 384/514
[A[ATraining Step: 319  | total loss: [1m[32m0.69357[0m[0m | time: 11.593s
[2K
| RMSProp | epoch: 019 | loss: 0.69357 - acc: 0.4814 -- iter: 416/514
[A[ATraining Step: 320  | total loss: [1m[32m0.69344[0m[0m | time: 12.503s
[2K
| RMSProp | epoch: 019 | loss: 0.69344 - acc: 0.4833 -- iter: 448/514
[A[ATraining Step: 321  | total loss: [1m[32m0.69329[0m[0m | time: 13.402s
[2K
| RMSProp | epoch: 019 | loss: 0.69329 - acc: 0.4943 -- iter: 480/514
[A[ATraining Step: 322  | total loss: [1m[32m0.69300[0m[0m | time: 14.284s
[2K
| RMSProp | epoch: 019 | loss: 0.69300 - acc: 0.5168 -- iter: 512/514
[A[ATraining Step: 323  | total loss: [1m[32m0.69315[0m[0m | time: 15.376s
[2K
| RMSProp | epoch: 019 | loss: 0.69315 - acc: 0.5120 | val_loss: 0.69390 - val_acc: 0.4720 -- iter: 514/514
--
Training Step: 324  | total loss: [1m[32m0.69320[0m[0m | time: 0.113s
[2K
| RMSProp | epoch: 020 | loss: 0.69320 - acc: 0.5108 -- iter: 032/514
[A[ATraining Step: 325  | total loss: [1m[32m0.69312[0m[0m | time: 0.966s
[2K
| RMSProp | epoch: 020 | loss: 0.69312 - acc: 0.5097 -- iter: 064/514
[A[ATraining Step: 326  | total loss: [1m[32m0.69340[0m[0m | time: 1.846s
[2K
| RMSProp | epoch: 020 | loss: 0.69340 - acc: 0.4993 -- iter: 096/514
[A[ATraining Step: 327  | total loss: [1m[32m0.69334[0m[0m | time: 2.681s
[2K
| RMSProp | epoch: 020 | loss: 0.69334 - acc: 0.5057 -- iter: 128/514
[A[ATraining Step: 328  | total loss: [1m[32m0.69293[0m[0m | time: 3.542s
[2K
| RMSProp | epoch: 020 | loss: 0.69293 - acc: 0.5145 -- iter: 160/514
[A[ATraining Step: 329  | total loss: [1m[32m0.69379[0m[0m | time: 4.409s
[2K
| RMSProp | epoch: 020 | loss: 0.69379 - acc: 0.4943 -- iter: 192/514
[A[ATraining Step: 330  | total loss: [1m[32m0.69358[0m[0m | time: 5.239s
[2K
| RMSProp | epoch: 020 | loss: 0.69358 - acc: 0.4980 -- iter: 224/514
[A[ATraining Step: 331  | total loss: [1m[32m0.69356[0m[0m | time: 6.153s
[2K
| RMSProp | epoch: 020 | loss: 0.69356 - acc: 0.4919 -- iter: 256/514
[A[ATraining Step: 332  | total loss: [1m[32m0.69342[0m[0m | time: 7.180s
[2K
| RMSProp | epoch: 020 | loss: 0.69342 - acc: 0.4990 -- iter: 288/514
[A[ATraining Step: 333  | total loss: [1m[32m0.69288[0m[0m | time: 8.151s
[2K
| RMSProp | epoch: 020 | loss: 0.69288 - acc: 0.5147 -- iter: 320/514
[A[ATraining Step: 334  | total loss: [1m[32m0.69281[0m[0m | time: 8.921s
[2K
| RMSProp | epoch: 020 | loss: 0.69281 - acc: 0.5132 -- iter: 352/514
[A[ATraining Step: 335  | total loss: [1m[32m0.69239[0m[0m | time: 9.850s
[2K
| RMSProp | epoch: 020 | loss: 0.69239 - acc: 0.5182 -- iter: 384/514
[A[ATraining Step: 336  | total loss: [1m[32m0.69162[0m[0m | time: 10.692s
[2K
| RMSProp | epoch: 020 | loss: 0.69162 - acc: 0.5320 -- iter: 416/514
[A[ATraining Step: 337  | total loss: [1m[32m0.69350[0m[0m | time: 11.533s
[2K
| RMSProp | epoch: 020 | loss: 0.69350 - acc: 0.5100 -- iter: 448/514
[A[ATraining Step: 338  | total loss: [1m[32m0.69290[0m[0m | time: 12.389s
[2K
| RMSProp | epoch: 020 | loss: 0.69290 - acc: 0.5215 -- iter: 480/514
[A[ATraining Step: 339  | total loss: [1m[32m0.69396[0m[0m | time: 13.334s
[2K
| RMSProp | epoch: 020 | loss: 0.69396 - acc: 0.5006 -- iter: 512/514
[A[ATraining Step: 340  | total loss: [1m[32m0.69377[0m[0m | time: 15.262s
[2K
| RMSProp | epoch: 020 | loss: 0.69377 - acc: 0.5006 | val_loss: 0.69048 - val_acc: 0.5280 -- iter: 514/514
--
Training Step: 341  | total loss: [1m[32m0.69369[0m[0m | time: 0.105s
[2K
| RMSProp | epoch: 021 | loss: 0.69369 - acc: 0.4943 -- iter: 032/514
[A[ATraining Step: 342  | total loss: [1m[32m0.69487[0m[0m | time: 0.219s
[2K
| RMSProp | epoch: 021 | loss: 0.69487 - acc: 0.4448 -- iter: 064/514
[A[ATraining Step: 343  | total loss: [1m[32m0.69200[0m[0m | time: 1.102s
[2K
| RMSProp | epoch: 021 | loss: 0.69200 - acc: 0.5003 -- iter: 096/514
[A[ATraining Step: 344  | total loss: [1m[32m0.69159[0m[0m | time: 2.008s
[2K
| RMSProp | epoch: 021 | loss: 0.69159 - acc: 0.5066 -- iter: 128/514
[A[ATraining Step: 345  | total loss: [1m[32m0.69205[0m[0m | time: 2.897s
[2K
| RMSProp | epoch: 021 | loss: 0.69205 - acc: 0.5028 -- iter: 160/514
[A[ATraining Step: 346  | total loss: [1m[32m0.69175[0m[0m | time: 3.761s
[2K
| RMSProp | epoch: 021 | loss: 0.69175 - acc: 0.5056 -- iter: 192/514
[A[ATraining Step: 347  | total loss: [1m[32m0.69180[0m[0m | time: 4.592s
[2K
| RMSProp | epoch: 021 | loss: 0.69180 - acc: 0.4988 -- iter: 224/514
[A[ATraining Step: 348  | total loss: [1m[32m0.69149[0m[0m | time: 5.618s
[2K
| RMSProp | epoch: 021 | loss: 0.69149 - acc: 0.5052 -- iter: 256/514
[A[ATraining Step: 349  | total loss: [1m[32m0.69095[0m[0m | time: 6.645s
[2K
| RMSProp | epoch: 021 | loss: 0.69095 - acc: 0.5078 -- iter: 288/514
[A[ATraining Step: 350  | total loss: [1m[32m0.69012[0m[0m | time: 7.535s
[2K
| RMSProp | epoch: 021 | loss: 0.69012 - acc: 0.5258 -- iter: 320/514
[A[ATraining Step: 351  | total loss: [1m[32m0.68935[0m[0m | time: 8.315s
[2K
| RMSProp | epoch: 021 | loss: 0.68935 - acc: 0.5357 -- iter: 352/514
[A[ATraining Step: 352  | total loss: [1m[32m0.68987[0m[0m | time: 9.228s
[2K
| RMSProp | epoch: 021 | loss: 0.68987 - acc: 0.5259 -- iter: 384/514
[A[ATraining Step: 353  | total loss: [1m[32m0.68900[0m[0m | time: 10.132s
[2K
| RMSProp | epoch: 021 | loss: 0.68900 - acc: 0.5295 -- iter: 416/514
[A[ATraining Step: 354  | total loss: [1m[32m0.69002[0m[0m | time: 10.985s
[2K
| RMSProp | epoch: 021 | loss: 0.69002 - acc: 0.5172 -- iter: 448/514
[A[ATraining Step: 355  | total loss: [1m[32m0.68913[0m[0m | time: 11.853s
[2K
| RMSProp | epoch: 021 | loss: 0.68913 - acc: 0.5217 -- iter: 480/514
[A[ATraining Step: 356  | total loss: [1m[32m0.68796[0m[0m | time: 12.784s
[2K
| RMSProp | epoch: 021 | loss: 0.68796 - acc: 0.5383 -- iter: 512/514
[A[ATraining Step: 357  | total loss: [1m[32m0.68837[0m[0m | time: 14.720s
[2K
| RMSProp | epoch: 021 | loss: 0.68837 - acc: 0.5282 | val_loss: 0.68205 - val_acc: 0.6211 -- iter: 514/514
--
Training Step: 358  | total loss: [1m[32m0.68968[0m[0m | time: 0.952s
[2K
| RMSProp | epoch: 022 | loss: 0.68968 - acc: 0.5192 -- iter: 032/514
[A[ATraining Step: 359  | total loss: [1m[32m0.68922[0m[0m | time: 1.053s
[2K
| RMSProp | epoch: 022 | loss: 0.68922 - acc: 0.5235 -- iter: 064/514
[A[ATraining Step: 360  | total loss: [1m[32m0.68643[0m[0m | time: 1.165s
[2K
| RMSProp | epoch: 022 | loss: 0.68643 - acc: 0.5211 -- iter: 096/514
[A[ATraining Step: 361  | total loss: [1m[32m0.68015[0m[0m | time: 2.093s
[2K
| RMSProp | epoch: 022 | loss: 0.68015 - acc: 0.5690 -- iter: 128/514
[A[ATraining Step: 362  | total loss: [1m[32m0.68068[0m[0m | time: 3.080s
[2K
| RMSProp | epoch: 022 | loss: 0.68068 - acc: 0.5590 -- iter: 160/514
[A[ATraining Step: 363  | total loss: [1m[32m0.67912[0m[0m | time: 4.043s
[2K
| RMSProp | epoch: 022 | loss: 0.67912 - acc: 0.5593 -- iter: 192/514
[A[ATraining Step: 364  | total loss: [1m[32m0.67728[0m[0m | time: 4.953s
[2K
| RMSProp | epoch: 022 | loss: 0.67728 - acc: 0.5753 -- iter: 224/514
[A[ATraining Step: 365  | total loss: [1m[32m0.67505[0m[0m | time: 5.899s
[2K
| RMSProp | epoch: 022 | loss: 0.67505 - acc: 0.5834 -- iter: 256/514
[A[ATraining Step: 366  | total loss: [1m[32m0.67819[0m[0m | time: 6.822s
[2K
| RMSProp | epoch: 022 | loss: 0.67819 - acc: 0.5750 -- iter: 288/514
[A[ATraining Step: 367  | total loss: [1m[32m0.67415[0m[0m | time: 7.782s
[2K
| RMSProp | epoch: 022 | loss: 0.67415 - acc: 0.5957 -- iter: 320/514
[A[ATraining Step: 368  | total loss: [1m[32m0.66979[0m[0m | time: 8.739s
[2K
| RMSProp | epoch: 022 | loss: 0.66979 - acc: 0.6049 -- iter: 352/514
[A[ATraining Step: 369  | total loss: [1m[32m0.66672[0m[0m | time: 9.693s
[2K
| RMSProp | epoch: 022 | loss: 0.66672 - acc: 0.6131 -- iter: 384/514
[A[ATraining Step: 370  | total loss: [1m[32m0.67804[0m[0m | time: 10.596s
[2K
| RMSProp | epoch: 022 | loss: 0.67804 - acc: 0.5956 -- iter: 416/514
[A[ATraining Step: 371  | total loss: [1m[32m0.67493[0m[0m | time: 11.560s
[2K
| RMSProp | epoch: 022 | loss: 0.67493 - acc: 0.6079 -- iter: 448/514
[A[ATraining Step: 372  | total loss: [1m[32m0.67147[0m[0m | time: 12.454s
[2K
| RMSProp | epoch: 022 | loss: 0.67147 - acc: 0.6127 -- iter: 480/514
[A[ATraining Step: 373  | total loss: [1m[32m0.67988[0m[0m | time: 13.434s
[2K
| RMSProp | epoch: 022 | loss: 0.67988 - acc: 0.5921 -- iter: 512/514
[A[ATraining Step: 374  | total loss: [1m[32m0.67544[0m[0m | time: 15.384s
[2K
| RMSProp | epoch: 022 | loss: 0.67544 - acc: 0.6016 | val_loss: 0.66102 - val_acc: 0.5776 -- iter: 514/514
--
Training Step: 375  | total loss: [1m[32m0.67618[0m[0m | time: 0.917s
[2K
| RMSProp | epoch: 023 | loss: 0.67618 - acc: 0.5977 -- iter: 032/514
[A[ATraining Step: 376  | total loss: [1m[32m0.66903[0m[0m | time: 1.892s
[2K
| RMSProp | epoch: 023 | loss: 0.66903 - acc: 0.6036 -- iter: 064/514
[A[ATraining Step: 377  | total loss: [1m[32m0.66383[0m[0m | time: 2.009s
[2K
| RMSProp | epoch: 023 | loss: 0.66383 - acc: 0.6276 -- iter: 096/514
[A[ATraining Step: 378  | total loss: [1m[32m0.64868[0m[0m | time: 2.156s
[2K
| RMSProp | epoch: 023 | loss: 0.64868 - acc: 0.6648 -- iter: 128/514
[A[ATraining Step: 379  | total loss: [1m[32m0.61327[0m[0m | time: 3.088s
[2K
| RMSProp | epoch: 023 | loss: 0.61327 - acc: 0.6983 -- iter: 160/514
[A[ATraining Step: 380  | total loss: [1m[32m0.63037[0m[0m | time: 4.019s
[2K
| RMSProp | epoch: 023 | loss: 0.63037 - acc: 0.6848 -- iter: 192/514
[A[ATraining Step: 381  | total loss: [1m[32m0.63177[0m[0m | time: 4.950s
[2K
| RMSProp | epoch: 023 | loss: 0.63177 - acc: 0.6725 -- iter: 224/514
[A[ATraining Step: 382  | total loss: [1m[32m0.63649[0m[0m | time: 5.914s
[2K
| RMSProp | epoch: 023 | loss: 0.63649 - acc: 0.6584 -- iter: 256/514
[A[ATraining Step: 383  | total loss: [1m[32m0.63707[0m[0m | time: 6.872s
[2K
| RMSProp | epoch: 023 | loss: 0.63707 - acc: 0.6582 -- iter: 288/514
[A[ATraining Step: 384  | total loss: [1m[32m0.63456[0m[0m | time: 7.852s
[2K
| RMSProp | epoch: 023 | loss: 0.63456 - acc: 0.6549 -- iter: 320/514
[A[ATraining Step: 385  | total loss: [1m[32m0.62830[0m[0m | time: 8.810s
[2K
| RMSProp | epoch: 023 | loss: 0.62830 - acc: 0.6738 -- iter: 352/514
[A[ATraining Step: 386  | total loss: [1m[32m0.62483[0m[0m | time: 9.758s
[2K
| RMSProp | epoch: 023 | loss: 0.62483 - acc: 0.6689 -- iter: 384/514
[A[ATraining Step: 387  | total loss: [1m[32m0.62420[0m[0m | time: 10.735s
[2K
| RMSProp | epoch: 023 | loss: 0.62420 - acc: 0.6676 -- iter: 416/514
[A[ATraining Step: 388  | total loss: [1m[32m0.62553[0m[0m | time: 11.766s
[2K
| RMSProp | epoch: 023 | loss: 0.62553 - acc: 0.6602 -- iter: 448/514
[A[ATraining Step: 389  | total loss: [1m[32m0.62213[0m[0m | time: 12.694s
[2K
| RMSProp | epoch: 023 | loss: 0.62213 - acc: 0.6630 -- iter: 480/514
[A[ATraining Step: 390  | total loss: [1m[32m0.61506[0m[0m | time: 13.624s
[2K
| RMSProp | epoch: 023 | loss: 0.61506 - acc: 0.6717 -- iter: 512/514
[A[ATraining Step: 391  | total loss: [1m[32m0.60715[0m[0m | time: 15.567s
[2K
| RMSProp | epoch: 023 | loss: 0.60715 - acc: 0.6764 | val_loss: 0.62478 - val_acc: 0.6584 -- iter: 514/514
--
Training Step: 392  | total loss: [1m[32m0.59809[0m[0m | time: 0.926s
[2K
| RMSProp | epoch: 024 | loss: 0.59809 - acc: 0.6837 -- iter: 032/514
[A[ATraining Step: 393  | total loss: [1m[32m0.59339[0m[0m | time: 1.887s
[2K
| RMSProp | epoch: 024 | loss: 0.59339 - acc: 0.6904 -- iter: 064/514
[A[ATraining Step: 394  | total loss: [1m[32m0.60885[0m[0m | time: 2.856s
[2K
| RMSProp | epoch: 024 | loss: 0.60885 - acc: 0.6744 -- iter: 096/514
[A[ATraining Step: 395  | total loss: [1m[32m0.61526[0m[0m | time: 2.962s
[2K
| RMSProp | epoch: 024 | loss: 0.61526 - acc: 0.6633 -- iter: 128/514
[A[ATraining Step: 396  | total loss: [1m[32m0.61204[0m[0m | time: 3.065s
[2K
| RMSProp | epoch: 024 | loss: 0.61204 - acc: 0.6469 -- iter: 160/514
[A[ATraining Step: 397  | total loss: [1m[32m0.58911[0m[0m | time: 4.043s
[2K
| RMSProp | epoch: 024 | loss: 0.58911 - acc: 0.6822 -- iter: 192/514
[A[ATraining Step: 398  | total loss: [1m[32m0.58732[0m[0m | time: 5.007s
[2K
| RMSProp | epoch: 024 | loss: 0.58732 - acc: 0.6890 -- iter: 224/514
[A[ATraining Step: 399  | total loss: [1m[32m0.58612[0m[0m | time: 5.959s
[2K
| RMSProp | epoch: 024 | loss: 0.58612 - acc: 0.6857 -- iter: 256/514
[A[ATraining Step: 400  | total loss: [1m[32m0.58716[0m[0m | time: 7.906s
[2K
| RMSProp | epoch: 024 | loss: 0.58716 - acc: 0.6890 | val_loss: 0.71427 - val_acc: 0.5714 -- iter: 288/514
--
Training Step: 401  | total loss: [1m[32m0.59326[0m[0m | time: 8.867s
[2K
| RMSProp | epoch: 024 | loss: 0.59326 - acc: 0.6826 -- iter: 320/514
[A[ATraining Step: 402  | total loss: [1m[32m0.60612[0m[0m | time: 9.781s
[2K
| RMSProp | epoch: 024 | loss: 0.60612 - acc: 0.6644 -- iter: 352/514
[A[ATraining Step: 403  | total loss: [1m[32m0.60359[0m[0m | time: 10.745s
[2K
| RMSProp | epoch: 024 | loss: 0.60359 - acc: 0.6729 -- iter: 384/514
[A[ATraining Step: 404  | total loss: [1m[32m0.59579[0m[0m | time: 11.662s
[2K
| RMSProp | epoch: 024 | loss: 0.59579 - acc: 0.6806 -- iter: 416/514
[A[ATraining Step: 405  | total loss: [1m[32m0.58986[0m[0m | time: 12.618s
[2K
| RMSProp | epoch: 024 | loss: 0.58986 - acc: 0.6845 -- iter: 448/514
[A[ATraining Step: 406  | total loss: [1m[32m0.57235[0m[0m | time: 13.588s
[2K
| RMSProp | epoch: 024 | loss: 0.57235 - acc: 0.7098 -- iter: 480/514
[A[ATraining Step: 407  | total loss: [1m[32m0.56055[0m[0m | time: 14.588s
[2K
| RMSProp | epoch: 024 | loss: 0.56055 - acc: 0.7232 -- iter: 512/514
[A[ATraining Step: 408  | total loss: [1m[32m0.54978[0m[0m | time: 16.526s
[2K
| RMSProp | epoch: 024 | loss: 0.54978 - acc: 0.7383 | val_loss: 0.58644 - val_acc: 0.6770 -- iter: 514/514
--
Training Step: 409  | total loss: [1m[32m0.53994[0m[0m | time: 0.943s
[2K
| RMSProp | epoch: 025 | loss: 0.53994 - acc: 0.7426 -- iter: 032/514
[A[ATraining Step: 410  | total loss: [1m[32m0.53934[0m[0m | time: 1.845s
[2K
| RMSProp | epoch: 025 | loss: 0.53934 - acc: 0.7434 -- iter: 064/514
[A[ATraining Step: 411  | total loss: [1m[32m0.56477[0m[0m | time: 2.691s
[2K
| RMSProp | epoch: 025 | loss: 0.56477 - acc: 0.7284 -- iter: 096/514
[A[ATraining Step: 412  | total loss: [1m[32m0.55260[0m[0m | time: 3.302s
[2K
| RMSProp | epoch: 025 | loss: 0.55260 - acc: 0.7399 -- iter: 128/514
[A[ATraining Step: 413  | total loss: [1m[32m0.54337[0m[0m | time: 3.365s
[2K
| RMSProp | epoch: 025 | loss: 0.54337 - acc: 0.7472 -- iter: 160/514
[A[ATraining Step: 414  | total loss: [1m[32m0.69758[0m[0m | time: 3.441s
[2K
| RMSProp | epoch: 025 | loss: 0.69758 - acc: 0.6725 -- iter: 192/514
[A[ATraining Step: 415  | total loss: [1m[32m0.66605[0m[0m | time: 4.054s
[2K
| RMSProp | epoch: 025 | loss: 0.66605 - acc: 0.7052 -- iter: 224/514
[A[ATraining Step: 416  | total loss: [1m[32m0.70436[0m[0m | time: 4.690s
[2K
| RMSProp | epoch: 025 | loss: 0.70436 - acc: 0.6722 -- iter: 256/514
[A[ATraining Step: 417  | total loss: [1m[32m0.68401[0m[0m | time: 5.302s
[2K
| RMSProp | epoch: 025 | loss: 0.68401 - acc: 0.6862 -- iter: 288/514
[A[ATraining Step: 418  | total loss: [1m[32m0.67664[0m[0m | time: 5.902s
[2K
| RMSProp | epoch: 025 | loss: 0.67664 - acc: 0.6832 -- iter: 320/514
[A[ATraining Step: 419  | total loss: [1m[32m0.67210[0m[0m | time: 6.502s
[2K
| RMSProp | epoch: 025 | loss: 0.67210 - acc: 0.6743 -- iter: 352/514
[A[ATraining Step: 420  | total loss: [1m[32m0.65831[0m[0m | time: 7.108s
[2K
| RMSProp | epoch: 025 | loss: 0.65831 - acc: 0.6819 -- iter: 384/514
[A[ATraining Step: 421  | total loss: [1m[32m0.63806[0m[0m | time: 7.725s
[2K
| RMSProp | epoch: 025 | loss: 0.63806 - acc: 0.7043 -- iter: 416/514
[A[ATraining Step: 422  | total loss: [1m[32m0.62660[0m[0m | time: 8.332s
[2K
| RMSProp | epoch: 025 | loss: 0.62660 - acc: 0.7120 -- iter: 448/514
[A[ATraining Step: 423  | total loss: [1m[32m0.60772[0m[0m | time: 8.937s
[2K
| RMSProp | epoch: 025 | loss: 0.60772 - acc: 0.7220 -- iter: 480/514
[A[ATraining Step: 424  | total loss: [1m[32m0.58888[0m[0m | time: 9.564s
[2K
| RMSProp | epoch: 025 | loss: 0.58888 - acc: 0.7373 -- iter: 512/514
[A[ATraining Step: 425  | total loss: [1m[32m0.58111[0m[0m | time: 11.163s
[2K
| RMSProp | epoch: 025 | loss: 0.58111 - acc: 0.7324 | val_loss: 0.60358 - val_acc: 0.6646 -- iter: 514/514
--
Training Step: 426  | total loss: [1m[32m0.61872[0m[0m | time: 0.863s
[2K
| RMSProp | epoch: 026 | loss: 0.61872 - acc: 0.6935 -- iter: 032/514
[A[ATraining Step: 427  | total loss: [1m[32m0.62213[0m[0m | time: 1.700s
[2K
| RMSProp | epoch: 026 | loss: 0.62213 - acc: 0.6898 -- iter: 064/514
[A[ATraining Step: 428  | total loss: [1m[32m0.61415[0m[0m | time: 2.597s
[2K
| RMSProp | epoch: 026 | loss: 0.61415 - acc: 0.6989 -- iter: 096/514
[A[ATraining Step: 429  | total loss: [1m[32m0.59896[0m[0m | time: 3.437s
[2K
| RMSProp | epoch: 026 | loss: 0.59896 - acc: 0.7072 -- iter: 128/514
[A[ATraining Step: 430  | total loss: [1m[32m0.58676[0m[0m | time: 4.292s
[2K
| RMSProp | epoch: 026 | loss: 0.58676 - acc: 0.7239 -- iter: 160/514
[A[ATraining Step: 431  | total loss: [1m[32m0.56921[0m[0m | time: 4.394s
[2K
| RMSProp | epoch: 026 | loss: 0.56921 - acc: 0.7390 -- iter: 192/514
[A[ATraining Step: 432  | total loss: [1m[32m0.53477[0m[0m | time: 4.478s
[2K
| RMSProp | epoch: 026 | loss: 0.53477 - acc: 0.7651 -- iter: 224/514
[A[ATraining Step: 433  | total loss: [1m[32m0.48439[0m[0m | time: 5.355s
[2K
| RMSProp | epoch: 026 | loss: 0.48439 - acc: 0.7886 -- iter: 256/514
[A[ATraining Step: 434  | total loss: [1m[32m0.54858[0m[0m | time: 6.287s
[2K
| RMSProp | epoch: 026 | loss: 0.54858 - acc: 0.7566 -- iter: 288/514
[A[ATraining Step: 435  | total loss: [1m[32m0.54429[0m[0m | time: 7.145s
[2K
| RMSProp | epoch: 026 | loss: 0.54429 - acc: 0.7622 -- iter: 320/514
[A[ATraining Step: 436  | total loss: [1m[32m0.53339[0m[0m | time: 7.983s
[2K
| RMSProp | epoch: 026 | loss: 0.53339 - acc: 0.7673 -- iter: 352/514
[A[ATraining Step: 437  | total loss: [1m[32m0.52381[0m[0m | time: 9.016s
[2K
| RMSProp | epoch: 026 | loss: 0.52381 - acc: 0.7812 -- iter: 384/514
[A[ATraining Step: 438  | total loss: [1m[32m0.52566[0m[0m | time: 10.013s
[2K
| RMSProp | epoch: 026 | loss: 0.52566 - acc: 0.7812 -- iter: 416/514
[A[ATraining Step: 439  | total loss: [1m[32m0.53758[0m[0m | time: 10.772s
[2K
| RMSProp | epoch: 026 | loss: 0.53758 - acc: 0.7687 -- iter: 448/514
[A[ATraining Step: 440  | total loss: [1m[32m0.53885[0m[0m | time: 11.634s
[2K
| RMSProp | epoch: 026 | loss: 0.53885 - acc: 0.7637 -- iter: 480/514
[A[ATraining Step: 441  | total loss: [1m[32m0.52155[0m[0m | time: 12.490s
[2K
| RMSProp | epoch: 026 | loss: 0.52155 - acc: 0.7779 -- iter: 512/514
[A[ATraining Step: 442  | total loss: [1m[32m0.51132[0m[0m | time: 14.327s
[2K
| RMSProp | epoch: 026 | loss: 0.51132 - acc: 0.7845 | val_loss: 0.69144 - val_acc: 0.5901 -- iter: 514/514
--
Training Step: 443  | total loss: [1m[32m0.51155[0m[0m | time: 0.722s
[2K
| RMSProp | epoch: 027 | loss: 0.51155 - acc: 0.7811 -- iter: 032/514
[A[ATraining Step: 444  | total loss: [1m[32m0.50236[0m[0m | time: 1.548s
[2K
| RMSProp | epoch: 027 | loss: 0.50236 - acc: 0.7842 -- iter: 064/514
[A[ATraining Step: 445  | total loss: [1m[32m0.49270[0m[0m | time: 2.401s
[2K
| RMSProp | epoch: 027 | loss: 0.49270 - acc: 0.7933 -- iter: 096/514
[A[ATraining Step: 446  | total loss: [1m[32m0.47768[0m[0m | time: 3.311s
[2K
| RMSProp | epoch: 027 | loss: 0.47768 - acc: 0.7983 -- iter: 128/514
[A[ATraining Step: 447  | total loss: [1m[32m0.48176[0m[0m | time: 4.177s
[2K
| RMSProp | epoch: 027 | loss: 0.48176 - acc: 0.7966 -- iter: 160/514
[A[ATraining Step: 448  | total loss: [1m[32m0.47200[0m[0m | time: 5.081s
[2K
| RMSProp | epoch: 027 | loss: 0.47200 - acc: 0.8045 -- iter: 192/514
[A[ATraining Step: 449  | total loss: [1m[32m0.46721[0m[0m | time: 5.183s
[2K
| RMSProp | epoch: 027 | loss: 0.46721 - acc: 0.8084 -- iter: 224/514
[A[ATraining Step: 450  | total loss: [1m[32m0.43747[0m[0m | time: 5.286s
[2K
| RMSProp | epoch: 027 | loss: 0.43747 - acc: 0.8276 -- iter: 256/514
[A[ATraining Step: 451  | total loss: [1m[32m0.39719[0m[0m | time: 6.238s
[2K
| RMSProp | epoch: 027 | loss: 0.39719 - acc: 0.8448 -- iter: 288/514
[A[ATraining Step: 452  | total loss: [1m[32m0.49751[0m[0m | time: 7.075s
[2K
| RMSProp | epoch: 027 | loss: 0.49751 - acc: 0.8103 -- iter: 320/514
[A[ATraining Step: 453  | total loss: [1m[32m0.47596[0m[0m | time: 7.852s
[2K
| RMSProp | epoch: 027 | loss: 0.47596 - acc: 0.8230 -- iter: 352/514
[A[ATraining Step: 454  | total loss: [1m[32m0.48919[0m[0m | time: 8.926s
[2K
| RMSProp | epoch: 027 | loss: 0.48919 - acc: 0.8064 -- iter: 384/514
[A[ATraining Step: 455  | total loss: [1m[32m0.49983[0m[0m | time: 9.969s
[2K
| RMSProp | epoch: 027 | loss: 0.49983 - acc: 0.7913 -- iter: 416/514
[A[ATraining Step: 456  | total loss: [1m[32m0.49632[0m[0m | time: 10.729s
[2K
| RMSProp | epoch: 027 | loss: 0.49632 - acc: 0.7872 -- iter: 448/514
[A[ATraining Step: 457  | total loss: [1m[32m0.47990[0m[0m | time: 11.543s
[2K
| RMSProp | epoch: 027 | loss: 0.47990 - acc: 0.7991 -- iter: 480/514
[A[ATraining Step: 458  | total loss: [1m[32m0.46375[0m[0m | time: 12.377s
[2K
| RMSProp | epoch: 027 | loss: 0.46375 - acc: 0.8098 -- iter: 512/514
[A[ATraining Step: 459  | total loss: [1m[32m0.45431[0m[0m | time: 14.249s
[2K
| RMSProp | epoch: 027 | loss: 0.45431 - acc: 0.8101 | val_loss: 0.70544 - val_acc: 0.6025 -- iter: 514/514
--
Training Step: 460  | total loss: [1m[32m0.44982[0m[0m | time: 1.056s
[2K
| RMSProp | epoch: 028 | loss: 0.44982 - acc: 0.8041 -- iter: 032/514
[A[ATraining Step: 461  | total loss: [1m[32m0.44625[0m[0m | time: 1.894s
[2K
| RMSProp | epoch: 028 | loss: 0.44625 - acc: 0.8081 -- iter: 064/514
[A[ATraining Step: 462  | total loss: [1m[32m0.43200[0m[0m | time: 2.667s
[2K
| RMSProp | epoch: 028 | loss: 0.43200 - acc: 0.8147 -- iter: 096/514
[A[ATraining Step: 463  | total loss: [1m[32m0.43209[0m[0m | time: 3.478s
[2K
| RMSProp | epoch: 028 | loss: 0.43209 - acc: 0.8145 -- iter: 128/514
[A[ATraining Step: 464  | total loss: [1m[32m0.46411[0m[0m | time: 4.334s
[2K
| RMSProp | epoch: 028 | loss: 0.46411 - acc: 0.7987 -- iter: 160/514
[A[ATraining Step: 465  | total loss: [1m[32m0.46966[0m[0m | time: 5.207s
[2K
| RMSProp | epoch: 028 | loss: 0.46966 - acc: 0.7938 -- iter: 192/514
[A[ATraining Step: 466  | total loss: [1m[32m0.45703[0m[0m | time: 6.068s
[2K
| RMSProp | epoch: 028 | loss: 0.45703 - acc: 0.8019 -- iter: 224/514
[A[ATraining Step: 467  | total loss: [1m[32m0.44811[0m[0m | time: 6.165s
[2K
| RMSProp | epoch: 028 | loss: 0.44811 - acc: 0.8092 -- iter: 256/514
[A[ATraining Step: 468  | total loss: [1m[32m0.41583[0m[0m | time: 6.268s
[2K
| RMSProp | epoch: 028 | loss: 0.41583 - acc: 0.8283 -- iter: 288/514
[A[ATraining Step: 469  | total loss: [1m[32m0.37903[0m[0m | time: 7.189s
[2K
| RMSProp | epoch: 028 | loss: 0.37903 - acc: 0.8455 -- iter: 320/514
[A[ATraining Step: 470  | total loss: [1m[32m0.39631[0m[0m | time: 8.113s
[2K
| RMSProp | epoch: 028 | loss: 0.39631 - acc: 0.8391 -- iter: 352/514
[A[ATraining Step: 471  | total loss: [1m[32m0.42250[0m[0m | time: 8.984s
[2K
| RMSProp | epoch: 028 | loss: 0.42250 - acc: 0.8208 -- iter: 384/514
[A[ATraining Step: 472  | total loss: [1m[32m0.44809[0m[0m | time: 9.922s
[2K
| RMSProp | epoch: 028 | loss: 0.44809 - acc: 0.8075 -- iter: 416/514
[A[ATraining Step: 473  | total loss: [1m[32m0.43936[0m[0m | time: 10.977s
[2K
| RMSProp | epoch: 028 | loss: 0.43936 - acc: 0.8173 -- iter: 448/514
[A[ATraining Step: 474  | total loss: [1m[32m0.45036[0m[0m | time: 11.867s
[2K
| RMSProp | epoch: 028 | loss: 0.45036 - acc: 0.8106 -- iter: 480/514
[A[ATraining Step: 475  | total loss: [1m[32m0.44985[0m[0m | time: 12.578s
[2K
| RMSProp | epoch: 028 | loss: 0.44985 - acc: 0.8139 -- iter: 512/514
[A[ATraining Step: 476  | total loss: [1m[32m0.45016[0m[0m | time: 14.423s
[2K
| RMSProp | epoch: 028 | loss: 0.45016 - acc: 0.8075 | val_loss: 0.57662 - val_acc: 0.7081 -- iter: 514/514
--
Training Step: 477  | total loss: [1m[32m0.43220[0m[0m | time: 0.924s
[2K
| RMSProp | epoch: 029 | loss: 0.43220 - acc: 0.8174 -- iter: 032/514
[A[ATraining Step: 478  | total loss: [1m[32m0.42460[0m[0m | time: 1.669s
[2K
| RMSProp | epoch: 029 | loss: 0.42460 - acc: 0.8232 -- iter: 064/514
[A[ATraining Step: 479  | total loss: [1m[32m0.42624[0m[0m | time: 2.515s
[2K
| RMSProp | epoch: 029 | loss: 0.42624 - acc: 0.8158 -- iter: 096/514
[A[ATraining Step: 480  | total loss: [1m[32m0.44457[0m[0m | time: 3.376s
[2K
| RMSProp | epoch: 029 | loss: 0.44457 - acc: 0.8061 -- iter: 128/514
[A[ATraining Step: 481  | total loss: [1m[32m0.45125[0m[0m | time: 4.247s
[2K
| RMSProp | epoch: 029 | loss: 0.45125 - acc: 0.8036 -- iter: 160/514
[A[ATraining Step: 482  | total loss: [1m[32m0.45427[0m[0m | time: 5.099s
[2K
| RMSProp | epoch: 029 | loss: 0.45427 - acc: 0.8014 -- iter: 192/514
[A[ATraining Step: 483  | total loss: [1m[32m0.44733[0m[0m | time: 5.986s
[2K
| RMSProp | epoch: 029 | loss: 0.44733 - acc: 0.8056 -- iter: 224/514
[A[ATraining Step: 484  | total loss: [1m[32m0.43248[0m[0m | time: 6.853s
[2K
| RMSProp | epoch: 029 | loss: 0.43248 - acc: 0.8188 -- iter: 256/514
[A[ATraining Step: 485  | total loss: [1m[32m0.41978[0m[0m | time: 6.972s
[2K
| RMSProp | epoch: 029 | loss: 0.41978 - acc: 0.8276 -- iter: 288/514
[A[ATraining Step: 486  | total loss: [1m[32m0.41704[0m[0m | time: 7.056s
[2K
| RMSProp | epoch: 029 | loss: 0.41704 - acc: 0.8448 -- iter: 320/514
[A[ATraining Step: 487  | total loss: [1m[32m0.43410[0m[0m | time: 7.892s
[2K
| RMSProp | epoch: 029 | loss: 0.43410 - acc: 0.8103 -- iter: 352/514
[A[ATraining Step: 488  | total loss: [1m[32m0.42611[0m[0m | time: 8.731s
[2K
| RMSProp | epoch: 029 | loss: 0.42611 - acc: 0.8105 -- iter: 384/514
[A[ATraining Step: 489  | total loss: [1m[32m0.42123[0m[0m | time: 9.690s
[2K
| RMSProp | epoch: 029 | loss: 0.42123 - acc: 0.8170 -- iter: 416/514
[A[ATraining Step: 490  | total loss: [1m[32m0.41385[0m[0m | time: 10.736s
[2K
| RMSProp | epoch: 029 | loss: 0.41385 - acc: 0.8197 -- iter: 448/514
[A[ATraining Step: 491  | total loss: [1m[32m0.40404[0m[0m | time: 11.488s
[2K
| RMSProp | epoch: 029 | loss: 0.40404 - acc: 0.8283 -- iter: 480/514
[A[ATraining Step: 492  | total loss: [1m[32m0.42121[0m[0m | time: 12.298s
[2K
| RMSProp | epoch: 029 | loss: 0.42121 - acc: 0.8205 -- iter: 512/514
[A[ATraining Step: 493  | total loss: [1m[32m0.41746[0m[0m | time: 14.188s
[2K
| RMSProp | epoch: 029 | loss: 0.41746 - acc: 0.8228 | val_loss: 0.59570 - val_acc: 0.7019 -- iter: 514/514
--
Training Step: 494  | total loss: [1m[32m0.40368[0m[0m | time: 0.993s
[2K
| RMSProp | epoch: 030 | loss: 0.40368 - acc: 0.8343 -- iter: 032/514
[A[ATraining Step: 495  | total loss: [1m[32m0.40244[0m[0m | time: 1.931s
[2K
| RMSProp | epoch: 030 | loss: 0.40244 - acc: 0.8352 -- iter: 064/514
[A[ATraining Step: 496  | total loss: [1m[32m0.39679[0m[0m | time: 2.670s
[2K
| RMSProp | epoch: 030 | loss: 0.39679 - acc: 0.8330 -- iter: 096/514
[A[ATraining Step: 497  | total loss: [1m[32m0.38648[0m[0m | time: 3.526s
[2K
| RMSProp | epoch: 030 | loss: 0.38648 - acc: 0.8403 -- iter: 128/514
[A[ATraining Step: 498  | total loss: [1m[32m0.40596[0m[0m | time: 4.357s
[2K
| RMSProp | epoch: 030 | loss: 0.40596 - acc: 0.8250 -- iter: 160/514
[A[ATraining Step: 499  | total loss: [1m[32m0.42179[0m[0m | time: 5.166s
[2K
| RMSProp | epoch: 030 | loss: 0.42179 - acc: 0.8050 -- iter: 192/514
[A[ATraining Step: 500  | total loss: [1m[32m0.43825[0m[0m | time: 6.027s
[2K
| RMSProp | epoch: 030 | loss: 0.43825 - acc: 0.7964 -- iter: 224/514
[A[ATraining Step: 501  | total loss: [1m[32m0.44389[0m[0m | time: 6.928s
[2K
| RMSProp | epoch: 030 | loss: 0.44389 - acc: 0.7917 -- iter: 256/514
[A[ATraining Step: 502  | total loss: [1m[32m0.42619[0m[0m | time: 7.849s
[2K
| RMSProp | epoch: 030 | loss: 0.42619 - acc: 0.8063 -- iter: 288/514
[A[ATraining Step: 503  | total loss: [1m[32m0.42413[0m[0m | time: 7.953s
[2K
| RMSProp | epoch: 030 | loss: 0.42413 - acc: 0.8069 -- iter: 320/514
[A[ATraining Step: 504  | total loss: [1m[32m0.39743[0m[0m | time: 8.057s
[2K
| RMSProp | epoch: 030 | loss: 0.39743 - acc: 0.8262 -- iter: 352/514
[A[ATraining Step: 505  | total loss: [1m[32m0.36436[0m[0m | time: 8.959s
[2K
| RMSProp | epoch: 030 | loss: 0.36436 - acc: 0.8436 -- iter: 384/514
[A[ATraining Step: 506  | total loss: [1m[32m0.40026[0m[0m | time: 9.791s
[2K
| RMSProp | epoch: 030 | loss: 0.40026 - acc: 0.8280 -- iter: 416/514
[A[ATraining Step: 507  | total loss: [1m[32m0.39453[0m[0m | time: 10.796s
[2K
| RMSProp | epoch: 030 | loss: 0.39453 - acc: 0.8233 -- iter: 448/514
[A[ATraining Step: 508  | total loss: [1m[32m0.39109[0m[0m | time: 11.838s
[2K
| RMSProp | epoch: 030 | loss: 0.39109 - acc: 0.8285 -- iter: 480/514
[A[ATraining Step: 509  | total loss: [1m[32m0.38677[0m[0m | time: 12.631s
[2K
| RMSProp | epoch: 030 | loss: 0.38677 - acc: 0.8300 -- iter: 512/514
[A[ATraining Step: 510  | total loss: [1m[32m0.37400[0m[0m | time: 14.428s
[2K
| RMSProp | epoch: 030 | loss: 0.37400 - acc: 0.8408 | val_loss: 0.88924 - val_acc: 0.6149 -- iter: 514/514
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.7848297213622292
Validation AUPRC:0.7876702162125817
Test AUC:0.8183364254792825
Test AUPRC:0.8519356644277271
BestTestF1Score	0.75	0.51	0.75	0.8	0.7	59	15	62	25	0.1
BestTestMCCScore	0.75	0.51	0.75	0.8	0.7	59	15	62	25	0.1
BestTestAccuracyScore	0.75	0.51	0.75	0.8	0.7	59	15	62	25	0.1
BestValidationF1Score	0.72	0.49	0.75	0.75	0.68	52	17	68	24	0.1
BestValidationMCC	0.72	0.49	0.75	0.75	0.68	52	17	68	24	0.1
BestValidationAccuracy	0.72	0.49	0.75	0.75	0.68	52	17	68	24	0.1
TestPredictions (Threshold:0.1)
CHEMBL2440578,TN,INACT,0.05999999865889549	CHEMBL43479,TP,ACT,0.10999999940395355	CHEMBL1819333,TN,INACT,0.03999999910593033	CHEMBL268377,TP,ACT,0.27000001072883606	CHEMBL292313,FN,ACT,0.03999999910593033	CHEMBL523446,TN,INACT,0.029999999329447746	CHEMBL404019,FN,ACT,0.029999999329447746	CHEMBL281795,TP,ACT,0.3799999952316284	CHEMBL501081,TN,INACT,0.019999999552965164	CHEMBL573714,TN,INACT,0.03999999910593033	CHEMBL251937,TN,INACT,0.019999999552965164	CHEMBL320782,FN,ACT,0.07999999821186066	CHEMBL97408,TN,INACT,0.019999999552965164	CHEMBL140004,TP,ACT,0.1599999964237213	CHEMBL332145,TN,INACT,0.05999999865889549	CHEMBL7756,TP,ACT,0.6800000071525574	CHEMBL202875,TN,INACT,0.029999999329447746	CHEMBL265583,TN,INACT,0.019999999552965164	CHEMBL418291,TP,ACT,0.11999999731779099	CHEMBL151235,TP,ACT,0.3799999952316284	CHEMBL269834,TN,INACT,0.03999999910593033	CHEMBL1795860,TN,INACT,0.05999999865889549	CHEMBL342005,TN,INACT,0.09000000357627869	CHEMBL323885,TN,INACT,0.07999999821186066	CHEMBL496702,TP,ACT,0.5	CHEMBL271938,TP,ACT,0.33000001311302185	CHEMBL496093,TP,ACT,0.2199999988079071	CHEMBL150077,TP,ACT,0.10999999940395355	CHEMBL19611,FN,ACT,0.05999999865889549	CHEMBL121729,TN,INACT,0.03999999910593033	CHEMBL124558,TP,ACT,0.7099999785423279	CHEMBL1632641,TP,ACT,0.44999998807907104	CHEMBL291994,TP,ACT,0.15000000596046448	CHEMBL226686,TN,INACT,0.029999999329447746	CHEMBL1683463,FP,INACT,0.20000000298023224	CHEMBL1214590,TN,INACT,0.009999999776482582	CHEMBL556692,TN,INACT,0.019999999552965164	CHEMBL2112796,TP,ACT,0.36000001430511475	CHEMBL498915,TP,ACT,0.2199999988079071	CHEMBL3775617,TN,INACT,0.009999999776482582	CHEMBL1819325,TN,INACT,0.019999999552965164	CHEMBL1939861,TN,INACT,0.05000000074505806	CHEMBL247140,FN,ACT,0.03999999910593033	CHEMBL3358151,TN,INACT,0.019999999552965164	CHEMBL342210,TP,ACT,0.6899999976158142	CHEMBL316884,TN,INACT,0.07000000029802322	CHEMBL263909,TN,INACT,0.0	CHEMBL1771217,FN,ACT,0.019999999552965164	CHEMBL151591,TP,ACT,0.8799999952316284	CHEMBL399998,TN,INACT,0.019999999552965164	CHEMBL288599,TN,INACT,0.05999999865889549	CHEMBL120934,TN,INACT,0.05999999865889549	CHEMBL303298,TP,ACT,0.47999998927116394	CHEMBL3142591,TN,INACT,0.05999999865889549	CHEMBL89057,FN,ACT,0.05999999865889549	CHEMBL3358157,TN,INACT,0.019999999552965164	CHEMBL481712,TN,INACT,0.05000000074505806	CHEMBL556277,TN,INACT,0.009999999776482582	CHEMBL1771223,FN,ACT,0.019999999552965164	CHEMBL508335,TP,ACT,0.7200000286102295	CHEMBL2380405,FN,ACT,0.09000000357627869	CHEMBL432397,TP,ACT,0.10000000149011612	CHEMBL2409696,TN,INACT,0.03999999910593033	CHEMBL249859,TN,INACT,0.03999999910593033	CHEMBL39358,TN,INACT,0.029999999329447746	CHEMBL304243,FN,ACT,0.019999999552965164	CHEMBL150027,TP,ACT,0.3100000023841858	CHEMBL339191,FP,INACT,0.33000001311302185	CHEMBL489414,TN,INACT,0.09000000357627869	CHEMBL329617,FP,INACT,0.10000000149011612	CHEMBL200435,TN,INACT,0.029999999329447746	CHEMBL432079,TP,ACT,0.15000000596046448	CHEMBL418472,TN,INACT,0.05999999865889549	CHEMBL36682,TN,INACT,0.029999999329447746	CHEMBL396296,TN,INACT,0.03999999910593033	CHEMBL64013,FN,ACT,0.029999999329447746	CHEMBL135216,FP,INACT,0.10000000149011612	CHEMBL440178,FN,ACT,0.07000000029802322	CHEMBL83368,TP,ACT,0.7200000286102295	CHEMBL484261,TP,ACT,0.1599999964237213	CHEMBL60567,TP,ACT,0.30000001192092896	CHEMBL1770629,TP,ACT,0.30000001192092896	CHEMBL151539,TP,ACT,0.23000000417232513	CHEMBL478079,TN,INACT,0.05999999865889549	CHEMBL91636,FN,ACT,0.05000000074505806	CHEMBL342548,TP,ACT,0.6499999761581421	CHEMBL337309,FP,INACT,0.12999999523162842	CHEMBL437019,TP,ACT,0.949999988079071	CHEMBL45631,FN,ACT,0.07999999821186066	CHEMBL110527,FN,ACT,0.05000000074505806	CHEMBL31164,TP,ACT,0.12999999523162842	CHEMBL441662,TP,ACT,0.5299999713897705	CHEMBL334909,TP,ACT,0.3499999940395355	CHEMBL1771218,FN,ACT,0.009999999776482582	CHEMBL3291003,TN,INACT,0.07000000029802322	CHEMBL140970,TP,ACT,0.5099999904632568	CHEMBL40237,TP,ACT,0.14000000059604645	CHEMBL344714,TP,ACT,0.9700000286102295	CHEMBL312100,FN,ACT,0.05999999865889549	CHEMBL148213,TP,ACT,0.800000011920929	CHEMBL1927185,FP,INACT,0.1599999964237213	CHEMBL514379,FP,INACT,0.1599999964237213	CHEMBL346624,TP,ACT,0.28999999165534973	CHEMBL250069,TN,INACT,0.029999999329447746	CHEMBL285418,FN,ACT,0.05999999865889549	CHEMBL148081,TP,ACT,0.949999988079071	CHEMBL1819323,TN,INACT,0.07000000029802322	CHEMBL42311,TP,ACT,0.11999999731779099	CHEMBL3770935,TN,INACT,0.07999999821186066	CHEMBL47254,TP,ACT,0.2199999988079071	CHEMBL424130,FP,INACT,0.3400000035762787	CHEMBL2431032,TN,INACT,0.07000000029802322	CHEMBL147604,TN,INACT,0.07999999821186066	CHEMBL574274,TN,INACT,0.029999999329447746	CHEMBL575654,TN,INACT,0.009999999776482582	CHEMBL344828,TP,ACT,0.5600000023841858	CHEMBL228230,TN,INACT,0.009999999776482582	CHEMBL62056,FN,ACT,0.03999999910593033	CHEMBL1645389,TN,INACT,0.029999999329447746	CHEMBL358182,TP,ACT,0.5299999713897705	CHEMBL496921,FN,ACT,0.029999999329447746	CHEMBL2048511,FP,INACT,0.10000000149011612	CHEMBL1234724,TP,ACT,0.7099999785423279	CHEMBL441781,TN,INACT,0.09000000357627869	CHEMBL308799,FP,INACT,0.5899999737739563	CHEMBL2048508,FP,INACT,0.12999999523162842	CHEMBL288649,TP,ACT,0.12999999523162842	CHEMBL147261,TP,ACT,0.9599999785423279	CHEMBL115653,TP,ACT,0.18000000715255737	CHEMBL114523,FP,INACT,0.3199999928474426	CHEMBL3828582,TN,INACT,0.009999999776482582	CHEMBL433262,FN,ACT,0.07999999821186066	CHEMBL521689,TP,ACT,0.8100000023841858	CHEMBL2380390,FN,ACT,0.029999999329447746	CHEMBL482319,TN,INACT,0.019999999552965164	CHEMBL272102,FN,ACT,0.03999999910593033	CHEMBL126044,TP,ACT,0.15000000596046448	CHEMBL73380,TN,INACT,0.05999999865889549	CHEMBL344999,TP,ACT,0.5799999833106995	CHEMBL1214592,TN,INACT,0.009999999776482582	CHEMBL399685,TN,INACT,0.009999999776482582	CHEMBL3417758,TN,INACT,0.05000000074505806	CHEMBL62186,FP,INACT,0.10000000149011612	CHEMBL433063,TP,ACT,0.4699999988079071	CHEMBL602700,TN,INACT,0.019999999552965164	CHEMBL1651848,TN,INACT,0.05999999865889549	CHEMBL144313,TP,ACT,0.18000000715255737	CHEMBL147903,TP,ACT,0.9599999785423279	CHEMBL55310,TN,INACT,0.05000000074505806	CHEMBL11306,TP,ACT,0.5199999809265137	CHEMBL370662,TN,INACT,0.05000000074505806	CHEMBL29292,TN,INACT,0.009999999776482582	CHEMBL227501,FN,ACT,0.05999999865889549	CHEMBL125598,TP,ACT,0.550000011920929	CHEMBL324664,TP,ACT,0.800000011920929	CHEMBL3291004,FP,INACT,0.12999999523162842	CHEMBL374377,TP,ACT,0.1899999976158142	CHEMBL147489,FP,INACT,0.18000000715255737	CHEMBL77258,TP,ACT,0.4699999988079071	CHEMBL79433,FN,ACT,0.07000000029802322	CHEMBL227484,TP,ACT,0.1899999976158142	

