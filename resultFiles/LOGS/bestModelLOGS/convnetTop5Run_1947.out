CNNModel CHEMBL2474 adam 0.0005 30 128 0 0.6 False True
Number of active compounds :	120
Number of inactive compounds :	120
---------------------------------
Run id: CNNModel_CHEMBL2474_adam_0.0005_30_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL2474_adam_0.0005_30_128_0.6_True/
---------------------------------
Training samples: 138
Validation samples: 44
--
Training Step: 1  | time: 1.525s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/138
[A[ATraining Step: 2  | total loss: [1m[32m0.62386[0m[0m | time: 2.458s
[2K
| Adam | epoch: 001 | loss: 0.62386 - acc: 0.4219 -- iter: 064/138
[A[ATraining Step: 3  | total loss: [1m[32m0.68075[0m[0m | time: 3.148s
[2K
| Adam | epoch: 001 | loss: 0.68075 - acc: 0.4858 -- iter: 096/138
[A[ATraining Step: 4  | total loss: [1m[32m0.69132[0m[0m | time: 3.754s
[2K
| Adam | epoch: 001 | loss: 0.69132 - acc: 0.3793 -- iter: 128/138
[A[ATraining Step: 5  | total loss: [1m[32m0.69237[0m[0m | time: 4.993s
[2K
| Adam | epoch: 001 | loss: 0.69237 - acc: 0.5710 | val_loss: 0.69329 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 6  | total loss: [1m[32m0.69346[0m[0m | time: 0.222s
[2K
| Adam | epoch: 002 | loss: 0.69346 - acc: 0.3325 -- iter: 032/138
[A[ATraining Step: 7  | total loss: [1m[32m0.69262[0m[0m | time: 0.855s
[2K
| Adam | epoch: 002 | loss: 0.69262 - acc: 0.6730 -- iter: 064/138
[A[ATraining Step: 8  | total loss: [1m[32m0.69270[0m[0m | time: 1.474s
[2K
| Adam | epoch: 002 | loss: 0.69270 - acc: 0.6108 -- iter: 096/138
[A[ATraining Step: 9  | total loss: [1m[32m0.69312[0m[0m | time: 2.457s
[2K
| Adam | epoch: 002 | loss: 0.69312 - acc: 0.5522 -- iter: 128/138
[A[ATraining Step: 10  | total loss: [1m[32m0.69228[0m[0m | time: 4.476s
[2K
| Adam | epoch: 002 | loss: 0.69228 - acc: 0.5573 | val_loss: 0.69782 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 11  | total loss: [1m[32m0.69155[0m[0m | time: 0.225s
[2K
| Adam | epoch: 003 | loss: 0.69155 - acc: 0.5598 -- iter: 032/138
[A[ATraining Step: 12  | total loss: [1m[32m0.68728[0m[0m | time: 0.441s
[2K
| Adam | epoch: 003 | loss: 0.68728 - acc: 0.6229 -- iter: 064/138
[A[ATraining Step: 13  | total loss: [1m[32m0.68215[0m[0m | time: 1.043s
[2K
| Adam | epoch: 003 | loss: 0.68215 - acc: 0.6559 -- iter: 096/138
[A[ATraining Step: 14  | total loss: [1m[32m0.68557[0m[0m | time: 1.667s
[2K
| Adam | epoch: 003 | loss: 0.68557 - acc: 0.6049 -- iter: 128/138
[A[ATraining Step: 15  | total loss: [1m[32m0.69706[0m[0m | time: 3.275s
[2K
| Adam | epoch: 003 | loss: 0.69706 - acc: 0.5394 | val_loss: 0.71343 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 16  | total loss: [1m[32m0.69769[0m[0m | time: 0.623s
[2K
| Adam | epoch: 004 | loss: 0.69769 - acc: 0.5246 -- iter: 032/138
[A[ATraining Step: 17  | total loss: [1m[32m0.69301[0m[0m | time: 0.854s
[2K
| Adam | epoch: 004 | loss: 0.69301 - acc: 0.5383 -- iter: 064/138
[A[ATraining Step: 18  | total loss: [1m[32m0.70263[0m[0m | time: 1.091s
[2K
| Adam | epoch: 004 | loss: 0.70263 - acc: 0.4904 -- iter: 096/138
[A[ATraining Step: 19  | total loss: [1m[32m0.70576[0m[0m | time: 1.700s
[2K
| Adam | epoch: 004 | loss: 0.70576 - acc: 0.4603 -- iter: 128/138
[A[ATraining Step: 20  | total loss: [1m[32m0.69717[0m[0m | time: 3.322s
[2K
| Adam | epoch: 004 | loss: 0.69717 - acc: 0.5132 | val_loss: 0.70043 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 21  | total loss: [1m[32m0.69659[0m[0m | time: 0.621s
[2K
| Adam | epoch: 005 | loss: 0.69659 - acc: 0.5091 -- iter: 032/138
[A[ATraining Step: 22  | total loss: [1m[32m0.69575[0m[0m | time: 1.224s
[2K
| Adam | epoch: 005 | loss: 0.69575 - acc: 0.5064 -- iter: 064/138
[A[ATraining Step: 23  | total loss: [1m[32m0.69508[0m[0m | time: 1.448s
[2K
| Adam | epoch: 005 | loss: 0.69508 - acc: 0.5045 -- iter: 096/138
[A[ATraining Step: 24  | total loss: [1m[32m0.69260[0m[0m | time: 1.665s
[2K
| Adam | epoch: 005 | loss: 0.69260 - acc: 0.5314 -- iter: 128/138
[A[ATraining Step: 25  | total loss: [1m[32m0.69134[0m[0m | time: 3.307s
[2K
| Adam | epoch: 005 | loss: 0.69134 - acc: 0.5501 | val_loss: 0.69752 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 26  | total loss: [1m[32m0.69081[0m[0m | time: 0.614s
[2K
| Adam | epoch: 006 | loss: 0.69081 - acc: 0.5534 -- iter: 032/138
[A[ATraining Step: 27  | total loss: [1m[32m0.69053[0m[0m | time: 1.211s
[2K
| Adam | epoch: 006 | loss: 0.69053 - acc: 0.5557 -- iter: 064/138
[A[ATraining Step: 28  | total loss: [1m[32m0.68987[0m[0m | time: 1.815s
[2K
| Adam | epoch: 006 | loss: 0.68987 - acc: 0.5652 -- iter: 096/138
[A[ATraining Step: 29  | total loss: [1m[32m0.69121[0m[0m | time: 2.032s
[2K
| Adam | epoch: 006 | loss: 0.69121 - acc: 0.5418 -- iter: 128/138
[A[ATraining Step: 30  | total loss: [1m[32m0.69017[0m[0m | time: 3.269s
[2K
| Adam | epoch: 006 | loss: 0.69017 - acc: 0.5556 | val_loss: 0.69801 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 31  | total loss: [1m[32m0.68951[0m[0m | time: 0.943s
[2K
| Adam | epoch: 007 | loss: 0.68951 - acc: 0.5658 -- iter: 032/138
[A[ATraining Step: 32  | total loss: [1m[32m0.68996[0m[0m | time: 1.921s
[2K
| Adam | epoch: 007 | loss: 0.68996 - acc: 0.5580 -- iter: 064/138
[A[ATraining Step: 33  | total loss: [1m[32m0.69027[0m[0m | time: 2.891s
[2K
| Adam | epoch: 007 | loss: 0.69027 - acc: 0.5522 -- iter: 096/138
[A[ATraining Step: 34  | total loss: [1m[32m0.69188[0m[0m | time: 4.015s
[2K
| Adam | epoch: 007 | loss: 0.69188 - acc: 0.5276 -- iter: 128/138
[A[ATraining Step: 35  | total loss: [1m[32m0.69029[0m[0m | time: 5.412s
[2K
| Adam | epoch: 007 | loss: 0.69029 - acc: 0.5480 | val_loss: 0.69915 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 36  | total loss: [1m[32m0.69097[0m[0m | time: 0.359s
[2K
| Adam | epoch: 008 | loss: 0.69097 - acc: 0.5382 -- iter: 032/138
[A[ATraining Step: 37  | total loss: [1m[32m0.69159[0m[0m | time: 1.375s
[2K
| Adam | epoch: 008 | loss: 0.69159 - acc: 0.5305 -- iter: 064/138
[A[ATraining Step: 38  | total loss: [1m[32m0.69211[0m[0m | time: 2.331s
[2K
| Adam | epoch: 008 | loss: 0.69211 - acc: 0.5246 -- iter: 096/138
[A[ATraining Step: 39  | total loss: [1m[32m0.69096[0m[0m | time: 3.345s
[2K
| Adam | epoch: 008 | loss: 0.69096 - acc: 0.5378 -- iter: 128/138
[A[ATraining Step: 40  | total loss: [1m[32m0.69106[0m[0m | time: 5.491s
[2K
| Adam | epoch: 008 | loss: 0.69106 - acc: 0.5366 | val_loss: 0.70004 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 41  | total loss: [1m[32m0.69159[0m[0m | time: 0.342s
[2K
| Adam | epoch: 009 | loss: 0.69159 - acc: 0.5299 -- iter: 032/138
[A[ATraining Step: 42  | total loss: [1m[32m0.69191[0m[0m | time: 0.744s
[2K
| Adam | epoch: 009 | loss: 0.69191 - acc: 0.5245 -- iter: 064/138
[A[ATraining Step: 43  | total loss: [1m[32m0.69216[0m[0m | time: 1.696s
[2K
| Adam | epoch: 009 | loss: 0.69216 - acc: 0.5202 -- iter: 096/138
[A[ATraining Step: 44  | total loss: [1m[32m0.69123[0m[0m | time: 2.677s
[2K
| Adam | epoch: 009 | loss: 0.69123 - acc: 0.5275 -- iter: 128/138
[A[ATraining Step: 45  | total loss: [1m[32m0.69053[0m[0m | time: 4.757s
[2K
| Adam | epoch: 009 | loss: 0.69053 - acc: 0.5334 | val_loss: 0.70137 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 46  | total loss: [1m[32m0.68995[0m[0m | time: 1.053s
[2K
| Adam | epoch: 010 | loss: 0.68995 - acc: 0.5383 -- iter: 032/138
[A[ATraining Step: 47  | total loss: [1m[32m0.68903[0m[0m | time: 1.368s
[2K
| Adam | epoch: 010 | loss: 0.68903 - acc: 0.5474 -- iter: 064/138
[A[ATraining Step: 48  | total loss: [1m[32m0.69367[0m[0m | time: 1.736s
[2K
| Adam | epoch: 010 | loss: 0.69367 - acc: 0.5076 -- iter: 096/138
[A[ATraining Step: 49  | total loss: [1m[32m0.69725[0m[0m | time: 2.706s
[2K
| Adam | epoch: 010 | loss: 0.69725 - acc: 0.4748 -- iter: 128/138
[A[ATraining Step: 50  | total loss: [1m[32m0.69667[0m[0m | time: 4.832s
[2K
| Adam | epoch: 010 | loss: 0.69667 - acc: 0.4787 | val_loss: 0.69842 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 51  | total loss: [1m[32m0.69535[0m[0m | time: 0.783s
[2K
| Adam | epoch: 011 | loss: 0.69535 - acc: 0.4915 -- iter: 032/138
[A[ATraining Step: 52  | total loss: [1m[32m0.69338[0m[0m | time: 1.396s
[2K
| Adam | epoch: 011 | loss: 0.69338 - acc: 0.5162 -- iter: 064/138
[A[ATraining Step: 53  | total loss: [1m[32m0.69363[0m[0m | time: 1.606s
[2K
| Adam | epoch: 011 | loss: 0.69363 - acc: 0.5092 -- iter: 096/138
[A[ATraining Step: 54  | total loss: [1m[32m0.69362[0m[0m | time: 1.817s
[2K
| Adam | epoch: 011 | loss: 0.69362 - acc: 0.5079 -- iter: 128/138
[A[ATraining Step: 55  | total loss: [1m[32m0.69358[0m[0m | time: 3.448s
[2K
| Adam | epoch: 011 | loss: 0.69358 - acc: 0.5068 | val_loss: 0.69650 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 56  | total loss: [1m[32m0.69446[0m[0m | time: 0.617s
[2K
| Adam | epoch: 012 | loss: 0.69446 - acc: 0.4882 -- iter: 032/138
[A[ATraining Step: 57  | total loss: [1m[32m0.69304[0m[0m | time: 1.261s
[2K
| Adam | epoch: 012 | loss: 0.69304 - acc: 0.5115 -- iter: 064/138
[A[ATraining Step: 58  | total loss: [1m[32m0.69206[0m[0m | time: 1.885s
[2K
| Adam | epoch: 012 | loss: 0.69206 - acc: 0.5270 -- iter: 096/138
[A[ATraining Step: 59  | total loss: [1m[32m0.69110[0m[0m | time: 2.115s
[2K
| Adam | epoch: 012 | loss: 0.69110 - acc: 0.5401 -- iter: 128/138
[A[ATraining Step: 60  | total loss: [1m[32m0.69049[0m[0m | time: 3.342s
[2K
| Adam | epoch: 012 | loss: 0.69049 - acc: 0.5481 | val_loss: 0.69808 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 61  | total loss: [1m[32m0.68995[0m[0m | time: 0.611s
[2K
| Adam | epoch: 013 | loss: 0.68995 - acc: 0.5548 -- iter: 032/138
[A[ATraining Step: 62  | total loss: [1m[32m0.69045[0m[0m | time: 1.212s
[2K
| Adam | epoch: 013 | loss: 0.69045 - acc: 0.5438 -- iter: 064/138
[A[ATraining Step: 63  | total loss: [1m[32m0.69176[0m[0m | time: 1.822s
[2K
| Adam | epoch: 013 | loss: 0.69176 - acc: 0.5263 -- iter: 096/138
[A[ATraining Step: 64  | total loss: [1m[32m0.69122[0m[0m | time: 2.432s
[2K
| Adam | epoch: 013 | loss: 0.69122 - acc: 0.5309 -- iter: 128/138
[A[ATraining Step: 65  | total loss: [1m[32m0.68950[0m[0m | time: 3.669s
[2K
| Adam | epoch: 013 | loss: 0.68950 - acc: 0.5463 | val_loss: 0.69943 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 66  | total loss: [1m[32m0.68633[0m[0m | time: 0.220s
[2K
| Adam | epoch: 014 | loss: 0.68633 - acc: 0.5772 -- iter: 032/138
[A[ATraining Step: 67  | total loss: [1m[32m0.68286[0m[0m | time: 0.825s
[2K
| Adam | epoch: 014 | loss: 0.68286 - acc: 0.6039 -- iter: 064/138
[A[ATraining Step: 68  | total loss: [1m[32m0.68621[0m[0m | time: 1.435s
[2K
| Adam | epoch: 014 | loss: 0.68621 - acc: 0.5768 -- iter: 096/138
[A[ATraining Step: 69  | total loss: [1m[32m0.68758[0m[0m | time: 2.301s
[2K
| Adam | epoch: 014 | loss: 0.68758 - acc: 0.5642 -- iter: 128/138
[A[ATraining Step: 70  | total loss: [1m[32m0.68885[0m[0m | time: 4.419s
[2K
| Adam | epoch: 014 | loss: 0.68885 - acc: 0.5532 | val_loss: 0.70040 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 71  | total loss: [1m[32m0.68790[0m[0m | time: 0.371s
[2K
| Adam | epoch: 015 | loss: 0.68790 - acc: 0.5542 -- iter: 032/138
[A[ATraining Step: 72  | total loss: [1m[32m0.69022[0m[0m | time: 0.703s
[2K
| Adam | epoch: 015 | loss: 0.69022 - acc: 0.5369 -- iter: 064/138
[A[ATraining Step: 73  | total loss: [1m[32m0.69128[0m[0m | time: 1.520s
[2K
| Adam | epoch: 015 | loss: 0.69128 - acc: 0.5217 -- iter: 096/138
[A[ATraining Step: 74  | total loss: [1m[32m0.68994[0m[0m | time: 2.567s
[2K
| Adam | epoch: 015 | loss: 0.68994 - acc: 0.5467 -- iter: 128/138
[A[ATraining Step: 75  | total loss: [1m[32m0.68879[0m[0m | time: 4.730s
[2K
| Adam | epoch: 015 | loss: 0.68879 - acc: 0.5688 | val_loss: 0.68544 - val_acc: 0.6591 -- iter: 138/138
--
Training Step: 76  | total loss: [1m[32m0.68804[0m[0m | time: 1.184s
[2K
| Adam | epoch: 016 | loss: 0.68804 - acc: 0.5815 -- iter: 032/138
[A[ATraining Step: 77  | total loss: [1m[32m0.68716[0m[0m | time: 1.640s
[2K
| Adam | epoch: 016 | loss: 0.68716 - acc: 0.5927 -- iter: 064/138
[A[ATraining Step: 78  | total loss: [1m[32m0.68412[0m[0m | time: 2.097s
[2K
| Adam | epoch: 016 | loss: 0.68412 - acc: 0.6249 -- iter: 096/138
[A[ATraining Step: 79  | total loss: [1m[32m0.67996[0m[0m | time: 3.166s
[2K
| Adam | epoch: 016 | loss: 0.67996 - acc: 0.6326 -- iter: 128/138
[A[ATraining Step: 80  | total loss: [1m[32m0.68018[0m[0m | time: 5.088s
[2K
| Adam | epoch: 016 | loss: 0.68018 - acc: 0.6159 | val_loss: 0.70959 - val_acc: 0.4318 -- iter: 138/138
--
Training Step: 81  | total loss: [1m[32m0.67936[0m[0m | time: 1.311s
[2K
| Adam | epoch: 017 | loss: 0.67936 - acc: 0.6105 -- iter: 032/138
[A[ATraining Step: 82  | total loss: [1m[32m0.67928[0m[0m | time: 2.559s
[2K
| Adam | epoch: 017 | loss: 0.67928 - acc: 0.5994 -- iter: 064/138
[A[ATraining Step: 83  | total loss: [1m[32m0.67242[0m[0m | time: 2.901s
[2K
| Adam | epoch: 017 | loss: 0.67242 - acc: 0.6051 -- iter: 096/138
[A[ATraining Step: 84  | total loss: [1m[32m0.67201[0m[0m | time: 3.232s
[2K
| Adam | epoch: 017 | loss: 0.67201 - acc: 0.6146 -- iter: 128/138
[A[ATraining Step: 85  | total loss: [1m[32m0.66801[0m[0m | time: 5.213s
[2K
| Adam | epoch: 017 | loss: 0.66801 - acc: 0.6231 | val_loss: 0.64499 - val_acc: 0.6136 -- iter: 138/138
--
Training Step: 86  | total loss: [1m[32m0.66866[0m[0m | time: 0.614s
[2K
| Adam | epoch: 018 | loss: 0.66866 - acc: 0.6108 -- iter: 032/138
[A[ATraining Step: 87  | total loss: [1m[32m0.66437[0m[0m | time: 1.237s
[2K
| Adam | epoch: 018 | loss: 0.66437 - acc: 0.6247 -- iter: 064/138
[A[ATraining Step: 88  | total loss: [1m[32m0.65737[0m[0m | time: 1.871s
[2K
| Adam | epoch: 018 | loss: 0.65737 - acc: 0.6310 -- iter: 096/138
[A[ATraining Step: 89  | total loss: [1m[32m0.65398[0m[0m | time: 2.090s
[2K
| Adam | epoch: 018 | loss: 0.65398 - acc: 0.6304 -- iter: 128/138
[A[ATraining Step: 90  | total loss: [1m[32m0.66728[0m[0m | time: 3.318s
[2K
| Adam | epoch: 018 | loss: 0.66728 - acc: 0.6274 | val_loss: 0.61368 - val_acc: 0.5682 -- iter: 138/138
--
Training Step: 91  | total loss: [1m[32m0.67154[0m[0m | time: 0.634s
[2K
| Adam | epoch: 019 | loss: 0.67154 - acc: 0.6146 -- iter: 032/138
[A[ATraining Step: 92  | total loss: [1m[32m0.66961[0m[0m | time: 1.236s
[2K
| Adam | epoch: 019 | loss: 0.66961 - acc: 0.6157 -- iter: 064/138
[A[ATraining Step: 93  | total loss: [1m[32m0.66822[0m[0m | time: 1.865s
[2K
| Adam | epoch: 019 | loss: 0.66822 - acc: 0.6041 -- iter: 096/138
[A[ATraining Step: 94  | total loss: [1m[32m0.66479[0m[0m | time: 2.510s
[2K
| Adam | epoch: 019 | loss: 0.66479 - acc: 0.6031 -- iter: 128/138
[A[ATraining Step: 95  | total loss: [1m[32m0.65601[0m[0m | time: 3.726s
[2K
| Adam | epoch: 019 | loss: 0.65601 - acc: 0.6146 | val_loss: 0.62690 - val_acc: 0.7273 -- iter: 138/138
--
Training Step: 96  | total loss: [1m[32m0.64744[0m[0m | time: 0.233s
[2K
| Adam | epoch: 020 | loss: 0.64744 - acc: 0.6332 -- iter: 032/138
[A[ATraining Step: 97  | total loss: [1m[32m0.64031[0m[0m | time: 0.863s
[2K
| Adam | epoch: 020 | loss: 0.64031 - acc: 0.6499 -- iter: 064/138
[A[ATraining Step: 98  | total loss: [1m[32m0.62929[0m[0m | time: 1.484s
[2K
| Adam | epoch: 020 | loss: 0.62929 - acc: 0.6599 -- iter: 096/138
[A[ATraining Step: 99  | total loss: [1m[32m0.62027[0m[0m | time: 2.119s
[2K
| Adam | epoch: 020 | loss: 0.62027 - acc: 0.6689 -- iter: 128/138
[A[ATraining Step: 100  | total loss: [1m[32m0.60919[0m[0m | time: 3.760s
[2K
| Adam | epoch: 020 | loss: 0.60919 - acc: 0.6801 | val_loss: 0.58953 - val_acc: 0.6364 -- iter: 138/138
--
Training Step: 101  | total loss: [1m[32m0.60679[0m[0m | time: 0.218s
[2K
| Adam | epoch: 021 | loss: 0.60679 - acc: 0.6809 -- iter: 032/138
[A[ATraining Step: 102  | total loss: [1m[32m0.59228[0m[0m | time: 0.441s
[2K
| Adam | epoch: 021 | loss: 0.59228 - acc: 0.6828 -- iter: 064/138
[A[ATraining Step: 103  | total loss: [1m[32m0.57562[0m[0m | time: 1.223s
[2K
| Adam | epoch: 021 | loss: 0.57562 - acc: 0.6845 -- iter: 096/138
[A[ATraining Step: 104  | total loss: [1m[32m0.56787[0m[0m | time: 2.250s
[2K
| Adam | epoch: 021 | loss: 0.56787 - acc: 0.6973 -- iter: 128/138
[A[ATraining Step: 105  | total loss: [1m[32m0.56046[0m[0m | time: 4.498s
[2K
| Adam | epoch: 021 | loss: 0.56046 - acc: 0.7026 | val_loss: 0.71194 - val_acc: 0.6591 -- iter: 138/138
--
Training Step: 106  | total loss: [1m[32m0.56843[0m[0m | time: 1.007s
[2K
| Adam | epoch: 022 | loss: 0.56843 - acc: 0.7011 -- iter: 032/138
[A[ATraining Step: 107  | total loss: [1m[32m0.56901[0m[0m | time: 1.428s
[2K
| Adam | epoch: 022 | loss: 0.56901 - acc: 0.6966 -- iter: 064/138
[A[ATraining Step: 108  | total loss: [1m[32m0.54709[0m[0m | time: 1.833s
[2K
| Adam | epoch: 022 | loss: 0.54709 - acc: 0.7169 -- iter: 096/138
[A[ATraining Step: 109  | total loss: [1m[32m0.52543[0m[0m | time: 2.829s
[2K
| Adam | epoch: 022 | loss: 0.52543 - acc: 0.7352 -- iter: 128/138
[A[ATraining Step: 110  | total loss: [1m[32m0.51805[0m[0m | time: 4.843s
[2K
| Adam | epoch: 022 | loss: 0.51805 - acc: 0.7430 | val_loss: 0.59364 - val_acc: 0.6364 -- iter: 138/138
--
Training Step: 111  | total loss: [1m[32m0.51623[0m[0m | time: 1.037s
[2K
| Adam | epoch: 023 | loss: 0.51623 - acc: 0.7437 -- iter: 032/138
[A[ATraining Step: 112  | total loss: [1m[32m0.50101[0m[0m | time: 2.152s
[2K
| Adam | epoch: 023 | loss: 0.50101 - acc: 0.7537 -- iter: 064/138
[A[ATraining Step: 113  | total loss: [1m[32m0.51180[0m[0m | time: 2.530s
[2K
| Adam | epoch: 023 | loss: 0.51180 - acc: 0.7439 -- iter: 096/138
[A[ATraining Step: 114  | total loss: [1m[32m0.49556[0m[0m | time: 2.881s
[2K
| Adam | epoch: 023 | loss: 0.49556 - acc: 0.7495 -- iter: 128/138
[A[ATraining Step: 115  | total loss: [1m[32m0.47128[0m[0m | time: 4.775s
[2K
| Adam | epoch: 023 | loss: 0.47128 - acc: 0.7646 | val_loss: 0.75894 - val_acc: 0.6591 -- iter: 138/138
--
Training Step: 116  | total loss: [1m[32m0.46822[0m[0m | time: 1.164s
[2K
| Adam | epoch: 024 | loss: 0.46822 - acc: 0.7662 -- iter: 032/138
[A[ATraining Step: 117  | total loss: [1m[32m0.47571[0m[0m | time: 2.456s
[2K
| Adam | epoch: 024 | loss: 0.47571 - acc: 0.7584 -- iter: 064/138
[A[ATraining Step: 118  | total loss: [1m[32m0.51864[0m[0m | time: 4.267s
[2K
| Adam | epoch: 024 | loss: 0.51864 - acc: 0.7419 -- iter: 096/138
[A[ATraining Step: 119  | total loss: [1m[32m0.50529[0m[0m | time: 4.941s
[2K
| Adam | epoch: 024 | loss: 0.50529 - acc: 0.7490 -- iter: 128/138
[A[ATraining Step: 120  | total loss: [1m[32m0.48698[0m[0m | time: 6.470s
[2K
| Adam | epoch: 024 | loss: 0.48698 - acc: 0.7541 | val_loss: 0.60297 - val_acc: 0.6591 -- iter: 138/138
--
Training Step: 121  | total loss: [1m[32m0.46917[0m[0m | time: 1.396s
[2K
| Adam | epoch: 025 | loss: 0.46917 - acc: 0.7687 -- iter: 032/138
[A[ATraining Step: 122  | total loss: [1m[32m0.46418[0m[0m | time: 2.951s
[2K
| Adam | epoch: 025 | loss: 0.46418 - acc: 0.7699 -- iter: 064/138
[A[ATraining Step: 123  | total loss: [1m[32m0.45846[0m[0m | time: 4.090s
[2K
| Adam | epoch: 025 | loss: 0.45846 - acc: 0.7742 -- iter: 096/138
[A[ATraining Step: 124  | total loss: [1m[32m0.45501[0m[0m | time: 4.959s
[2K
| Adam | epoch: 025 | loss: 0.45501 - acc: 0.7843 -- iter: 128/138
[A[ATraining Step: 125  | total loss: [1m[32m0.45293[0m[0m | time: 6.448s
[2K
| Adam | epoch: 025 | loss: 0.45293 - acc: 0.7933 | val_loss: 0.65509 - val_acc: 0.6591 -- iter: 138/138
--
Training Step: 126  | total loss: [1m[32m0.43117[0m[0m | time: 0.451s
[2K
| Adam | epoch: 026 | loss: 0.43117 - acc: 0.8140 -- iter: 032/138
[A[ATraining Step: 127  | total loss: [1m[32m0.40531[0m[0m | time: 1.651s
[2K
| Adam | epoch: 026 | loss: 0.40531 - acc: 0.8326 -- iter: 064/138
[A[ATraining Step: 128  | total loss: [1m[32m0.42402[0m[0m | time: 2.895s
[2K
| Adam | epoch: 026 | loss: 0.42402 - acc: 0.8181 -- iter: 096/138
[A[ATraining Step: 129  | total loss: [1m[32m0.43271[0m[0m | time: 4.172s
[2K
| Adam | epoch: 026 | loss: 0.43271 - acc: 0.8113 -- iter: 128/138
[A[ATraining Step: 130  | total loss: [1m[32m0.43013[0m[0m | time: 6.584s
[2K
| Adam | epoch: 026 | loss: 0.43013 - acc: 0.8145 | val_loss: 0.61807 - val_acc: 0.6364 -- iter: 138/138
--
Training Step: 131  | total loss: [1m[32m0.42166[0m[0m | time: 0.445s
[2K
| Adam | epoch: 027 | loss: 0.42166 - acc: 0.8143 -- iter: 032/138
[A[ATraining Step: 132  | total loss: [1m[32m0.40281[0m[0m | time: 0.949s
[2K
| Adam | epoch: 027 | loss: 0.40281 - acc: 0.8329 -- iter: 064/138
[A[ATraining Step: 133  | total loss: [1m[32m0.38247[0m[0m | time: 2.043s
[2K
| Adam | epoch: 027 | loss: 0.38247 - acc: 0.8496 -- iter: 096/138
[A[ATraining Step: 134  | total loss: [1m[32m0.37312[0m[0m | time: 2.997s
[2K
| Adam | epoch: 027 | loss: 0.37312 - acc: 0.8459 -- iter: 128/138
[A[ATraining Step: 135  | total loss: [1m[32m0.36746[0m[0m | time: 5.032s
[2K
| Adam | epoch: 027 | loss: 0.36746 - acc: 0.8457 | val_loss: 0.63298 - val_acc: 0.6364 -- iter: 138/138
--
Training Step: 136  | total loss: [1m[32m0.35992[0m[0m | time: 0.794s
[2K
| Adam | epoch: 028 | loss: 0.35992 - acc: 0.8486 -- iter: 032/138
[A[ATraining Step: 137  | total loss: [1m[32m0.35662[0m[0m | time: 1.018s
[2K
| Adam | epoch: 028 | loss: 0.35662 - acc: 0.8450 -- iter: 064/138
[A[ATraining Step: 138  | total loss: [1m[32m0.34160[0m[0m | time: 1.243s
[2K
| Adam | epoch: 028 | loss: 0.34160 - acc: 0.8605 -- iter: 096/138
[A[ATraining Step: 139  | total loss: [1m[32m0.32305[0m[0m | time: 1.868s
[2K
| Adam | epoch: 028 | loss: 0.32305 - acc: 0.8745 -- iter: 128/138
[A[ATraining Step: 140  | total loss: [1m[32m0.31341[0m[0m | time: 3.484s
[2K
| Adam | epoch: 028 | loss: 0.31341 - acc: 0.8776 | val_loss: 0.82830 - val_acc: 0.6364 -- iter: 138/138
--
Training Step: 141  | total loss: [1m[32m0.31215[0m[0m | time: 1.048s
[2K
| Adam | epoch: 029 | loss: 0.31215 - acc: 0.8774 -- iter: 032/138
[A[ATraining Step: 142  | total loss: [1m[32m0.30410[0m[0m | time: 1.894s
[2K
| Adam | epoch: 029 | loss: 0.30410 - acc: 0.8803 -- iter: 064/138
[A[ATraining Step: 143  | total loss: [1m[32m0.30226[0m[0m | time: 2.132s
[2K
| Adam | epoch: 029 | loss: 0.30226 - acc: 0.8829 -- iter: 096/138
[A[ATraining Step: 144  | total loss: [1m[32m0.27904[0m[0m | time: 2.364s
[2K
| Adam | epoch: 029 | loss: 0.27904 - acc: 0.8946 -- iter: 128/138
[A[ATraining Step: 145  | total loss: [1m[32m0.26176[0m[0m | time: 3.998s
[2K
| Adam | epoch: 029 | loss: 0.26176 - acc: 0.9051 | val_loss: 0.61209 - val_acc: 0.6818 -- iter: 138/138
--
Training Step: 146  | total loss: [1m[32m0.25340[0m[0m | time: 0.923s
[2K
| Adam | epoch: 030 | loss: 0.25340 - acc: 0.9115 -- iter: 032/138
[A[ATraining Step: 147  | total loss: [1m[32m0.24660[0m[0m | time: 1.956s
[2K
| Adam | epoch: 030 | loss: 0.24660 - acc: 0.9141 -- iter: 064/138
[A[ATraining Step: 148  | total loss: [1m[32m0.23579[0m[0m | time: 3.041s
[2K
| Adam | epoch: 030 | loss: 0.23579 - acc: 0.9195 -- iter: 096/138
[A[ATraining Step: 149  | total loss: [1m[32m0.23344[0m[0m | time: 3.457s
[2K
| Adam | epoch: 030 | loss: 0.23344 - acc: 0.9151 -- iter: 128/138
[A[ATraining Step: 150  | total loss: [1m[32m0.22048[0m[0m | time: 4.903s
[2K
| Adam | epoch: 030 | loss: 0.22048 - acc: 0.9236 | val_loss: 0.63328 - val_acc: 0.6591 -- iter: 138/138
--
Validation AUC:0.7810526315789473
Validation AUPRC:0.8585996289483264
Test AUC:0.8884297520661157
Test AUPRC:0.9260547028728847
BestTestF1Score	0.74	0.39	0.66	0.6	0.95	21	14	8	1	0.14
BestTestMCCScore	0.74	0.65	0.8	1.0	0.59	13	0	22	9	0.8
BestTestAccuracyScore	0.74	0.65	0.8	1.0	0.59	13	0	22	9	0.8
BestValidationF1Score	0.76	0.31	0.64	0.61	1.0	25	16	3	0	0.14
BestValidationMCC	0.71	0.5	0.73	0.88	0.6	15	2	17	10	0.8
BestValidationAccuracy	0.71	0.5	0.73	0.88	0.6	15	2	17	10	0.8
TestPredictions (Threshold:0.8)
CHEMBL271696,TP,ACT,0.8899999856948853	CHEMBL166127,TN,INACT,0.20000000298023224	CHEMBL2392900,TP,ACT,0.9900000095367432	CHEMBL2392764,TP,ACT,0.9800000190734863	CHEMBL1738934,FN,ACT,0.7099999785423279	CHEMBL2392912,FN,ACT,0.7799999713897705	CHEMBL472879,TP,ACT,0.9800000190734863	CHEMBL380979,TN,INACT,0.10999999940395355	CHEMBL2392905,FN,ACT,0.7900000214576721	CHEMBL45721,FN,ACT,0.15000000596046448	CHEMBL2392931,TP,ACT,1.0	CHEMBL2392917,TP,ACT,1.0	CHEMBL3337737,TN,INACT,0.3100000023841858	CHEMBL199982,TN,INACT,0.20000000298023224	CHEMBL1945977,TN,INACT,0.03999999910593033	CHEMBL2392893,TP,ACT,1.0	CHEMBL3764960,TN,INACT,0.6700000166893005	CHEMBL256279,FN,ACT,0.7799999713897705	CHEMBL352764,TN,INACT,0.6200000047683716	CHEMBL3764781,TN,INACT,0.019999999552965164	CHEMBL371544,TN,INACT,0.019999999552965164	CHEMBL355427,FN,ACT,0.029999999329447746	CHEMBL1097450,TN,INACT,0.6700000166893005	CHEMBL377198,TN,INACT,0.4399999976158142	CHEMBL3337736,TN,INACT,0.3499999940395355	CHEMBL203476,TN,INACT,0.09000000357627869	CHEMBL1945980,TN,INACT,0.25	CHEMBL3317938,TN,INACT,0.009999999776482582	CHEMBL74898,TN,INACT,0.4099999964237213	CHEMBL2392920,TP,ACT,1.0	CHEMBL2375617,TP,ACT,1.0	CHEMBL1945978,TN,INACT,0.28999999165534973	CHEMBL1215574,TN,INACT,0.029999999329447746	CHEMBL2375627,TP,ACT,1.0	CHEMBL3337738,TN,INACT,0.15000000596046448	CHEMBL193610,FN,ACT,0.4399999976158142	CHEMBL2375610,TP,ACT,1.0	CHEMBL270813,TP,ACT,0.9200000166893005	CHEMBL561227,TN,INACT,0.17000000178813934	CHEMBL402646,TN,INACT,0.15000000596046448	CHEMBL441227,FN,ACT,0.33000001311302185	CHEMBL2392914,TP,ACT,1.0	CHEMBL270142,FN,ACT,0.14000000059604645	CHEMBL571667,TN,INACT,0.07999999821186066	

