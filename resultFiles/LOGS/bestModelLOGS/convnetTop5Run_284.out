ImageNetInceptionV2 CHEMBL3535 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	159
Number of inactive compounds :	159
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3535_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3535_adam_0.001_15_0.6/
---------------------------------
Training samples: 200
Validation samples: 63
--
Training Step: 1  | time: 38.165s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/200
[A[ATraining Step: 2  | total loss: [1m[32m0.60763[0m[0m | time: 49.957s
[2K
| Adam | epoch: 001 | loss: 0.60763 - acc: 0.5344 -- iter: 064/200
[A[ATraining Step: 3  | total loss: [1m[32m0.84092[0m[0m | time: 61.173s
[2K
| Adam | epoch: 001 | loss: 0.84092 - acc: 0.5830 -- iter: 096/200
[A[ATraining Step: 4  | total loss: [1m[32m0.78921[0m[0m | time: 73.860s
[2K
| Adam | epoch: 001 | loss: 0.78921 - acc: 0.5676 -- iter: 128/200
[A[ATraining Step: 5  | total loss: [1m[32m0.63984[0m[0m | time: 86.638s
[2K
| Adam | epoch: 001 | loss: 0.63984 - acc: 0.6290 -- iter: 160/200
[A[ATraining Step: 6  | total loss: [1m[32m0.63686[0m[0m | time: 98.938s
[2K
| Adam | epoch: 001 | loss: 0.63686 - acc: 0.6867 -- iter: 192/200
[A[ATraining Step: 7  | total loss: [1m[32m0.73310[0m[0m | time: 112.330s
[2K
| Adam | epoch: 001 | loss: 0.73310 - acc: 0.6497 | val_loss: 0.76371 - val_acc: 0.5238 -- iter: 200/200
--
Training Step: 8  | total loss: [1m[32m0.79401[0m[0m | time: 2.852s
[2K
| Adam | epoch: 002 | loss: 0.79401 - acc: 0.6358 -- iter: 032/200
[A[ATraining Step: 9  | total loss: [1m[32m0.51574[0m[0m | time: 11.133s
[2K
| Adam | epoch: 002 | loss: 0.51574 - acc: 0.8286 -- iter: 064/200
[A[ATraining Step: 10  | total loss: [1m[32m0.46077[0m[0m | time: 23.036s
[2K
| Adam | epoch: 002 | loss: 0.46077 - acc: 0.8362 -- iter: 096/200
[A[ATraining Step: 11  | total loss: [1m[32m0.41013[0m[0m | time: 35.713s
[2K
| Adam | epoch: 002 | loss: 0.41013 - acc: 0.8250 -- iter: 128/200
[A[ATraining Step: 12  | total loss: [1m[32m0.36326[0m[0m | time: 48.290s
[2K
| Adam | epoch: 002 | loss: 0.36326 - acc: 0.8194 -- iter: 160/200
[A[ATraining Step: 13  | total loss: [1m[32m0.35282[0m[0m | time: 60.841s
[2K
| Adam | epoch: 002 | loss: 0.35282 - acc: 0.8164 -- iter: 192/200
[A[ATraining Step: 14  | total loss: [1m[32m0.33062[0m[0m | time: 76.014s
[2K
| Adam | epoch: 002 | loss: 0.33062 - acc: 0.8404 | val_loss: 2.93202 - val_acc: 0.5238 -- iter: 200/200
--
Training Step: 15  | total loss: [1m[32m0.35542[0m[0m | time: 4.972s
[2K
| Adam | epoch: 003 | loss: 0.35542 - acc: 0.8172 -- iter: 032/200
[A[ATraining Step: 16  | total loss: [1m[32m0.31790[0m[0m | time: 9.690s
[2K
| Adam | epoch: 003 | loss: 0.31790 - acc: 0.8389 -- iter: 064/200
[A[ATraining Step: 17  | total loss: [1m[32m0.23674[0m[0m | time: 22.207s
[2K
| Adam | epoch: 003 | loss: 0.23674 - acc: 0.8969 -- iter: 096/200
[A[ATraining Step: 18  | total loss: [1m[32m0.19022[0m[0m | time: 34.890s
[2K
| Adam | epoch: 003 | loss: 0.19022 - acc: 0.9218 -- iter: 128/200
[A[ATraining Step: 19  | total loss: [1m[32m0.20367[0m[0m | time: 45.563s
[2K
| Adam | epoch: 003 | loss: 0.20367 - acc: 0.9166 -- iter: 160/200
[A[ATraining Step: 20  | total loss: [1m[32m0.18241[0m[0m | time: 53.500s
[2K
| Adam | epoch: 003 | loss: 0.18241 - acc: 0.9334 -- iter: 192/200
[A[ATraining Step: 21  | total loss: [1m[32m0.15708[0m[0m | time: 64.181s
[2K
| Adam | epoch: 003 | loss: 0.15708 - acc: 0.9346 | val_loss: 2.93477 - val_acc: 0.5238 -- iter: 200/200
--
Training Step: 22  | total loss: [1m[32m0.13365[0m[0m | time: 12.764s
[2K
| Adam | epoch: 004 | loss: 0.13365 - acc: 0.9449 -- iter: 032/200
[A[ATraining Step: 23  | total loss: [1m[32m0.16222[0m[0m | time: 17.579s
[2K
| Adam | epoch: 004 | loss: 0.16222 - acc: 0.9427 -- iter: 064/200
[A[ATraining Step: 24  | total loss: [1m[32m0.40135[0m[0m | time: 20.529s
[2K
| Adam | epoch: 004 | loss: 0.40135 - acc: 0.8534 -- iter: 096/200
[A[ATraining Step: 25  | total loss: [1m[32m0.32391[0m[0m | time: 28.459s
[2K
| Adam | epoch: 004 | loss: 0.32391 - acc: 0.8934 -- iter: 128/200
[A[ATraining Step: 26  | total loss: [1m[32m0.31871[0m[0m | time: 36.289s
[2K
| Adam | epoch: 004 | loss: 0.31871 - acc: 0.9133 -- iter: 160/200
[A[ATraining Step: 27  | total loss: [1m[32m0.33497[0m[0m | time: 44.541s
[2K
| Adam | epoch: 004 | loss: 0.33497 - acc: 0.9115 -- iter: 192/200
[A[ATraining Step: 28  | total loss: [1m[32m0.34977[0m[0m | time: 67.587s
[2K
| Adam | epoch: 004 | loss: 0.34977 - acc: 0.9180 | val_loss: 3.22656 - val_acc: 0.5238 -- iter: 200/200
--
Training Step: 29  | total loss: [1m[32m0.28034[0m[0m | time: 8.177s
[2K
| Adam | epoch: 005 | loss: 0.28034 - acc: 0.9379 -- iter: 032/200
[A[ATraining Step: 30  | total loss: [1m[32m0.24782[0m[0m | time: 16.068s
[2K
| Adam | epoch: 005 | loss: 0.24782 - acc: 0.9452 -- iter: 064/200
[A[ATraining Step: 31  | total loss: [1m[32m0.21017[0m[0m | time: 18.861s
[2K
| Adam | epoch: 005 | loss: 0.21017 - acc: 0.9579 -- iter: 096/200
[A[ATraining Step: 32  | total loss: [1m[32m0.17414[0m[0m | time: 21.702s
[2K
| Adam | epoch: 005 | loss: 0.17414 - acc: 0.9674 -- iter: 128/200
[A[ATraining Step: 33  | total loss: [1m[32m0.13937[0m[0m | time: 31.246s
[2K
| Adam | epoch: 005 | loss: 0.13937 - acc: 0.9745 -- iter: 160/200
[A[ATraining Step: 34  | total loss: [1m[32m0.12167[0m[0m | time: 44.019s
[2K
| Adam | epoch: 005 | loss: 0.12167 - acc: 0.9800 -- iter: 192/200
[A[ATraining Step: 35  | total loss: [1m[32m0.14591[0m[0m | time: 61.346s
[2K
| Adam | epoch: 005 | loss: 0.14591 - acc: 0.9645 | val_loss: 3.19978 - val_acc: 0.5238 -- iter: 200/200
--
Training Step: 36  | total loss: [1m[32m0.13257[0m[0m | time: 7.961s
[2K
| Adam | epoch: 006 | loss: 0.13257 - acc: 0.9654 -- iter: 032/200
[A[ATraining Step: 37  | total loss: [1m[32m0.14323[0m[0m | time: 15.810s
[2K
| Adam | epoch: 006 | loss: 0.14323 - acc: 0.9661 -- iter: 064/200
[A[ATraining Step: 38  | total loss: [1m[32m0.12804[0m[0m | time: 29.835s
[2K
| Adam | epoch: 006 | loss: 0.12804 - acc: 0.9666 -- iter: 096/200
[A[ATraining Step: 39  | total loss: [1m[32m0.11358[0m[0m | time: 34.408s
[2K
| Adam | epoch: 006 | loss: 0.11358 - acc: 0.9730 -- iter: 128/200
[A[ATraining Step: 40  | total loss: [1m[32m0.28832[0m[0m | time: 39.454s
[2K
| Adam | epoch: 006 | loss: 0.28832 - acc: 0.9546 -- iter: 160/200
[A[ATraining Step: 41  | total loss: [1m[32m0.24862[0m[0m | time: 52.404s
[2K
| Adam | epoch: 006 | loss: 0.24862 - acc: 0.9630 -- iter: 192/200
[A[ATraining Step: 42  | total loss: [1m[32m0.21779[0m[0m | time: 70.156s
[2K
| Adam | epoch: 006 | loss: 0.21779 - acc: 0.9696 | val_loss: 1.44771 - val_acc: 0.4921 -- iter: 200/200
--
Training Step: 43  | total loss: [1m[32m0.18879[0m[0m | time: 9.432s
[2K
| Adam | epoch: 007 | loss: 0.18879 - acc: 0.9750 -- iter: 032/200
[A[ATraining Step: 44  | total loss: [1m[32m0.16788[0m[0m | time: 21.644s
[2K
| Adam | epoch: 007 | loss: 0.16788 - acc: 0.9793 -- iter: 064/200
[A[ATraining Step: 45  | total loss: [1m[32m0.15323[0m[0m | time: 34.479s
[2K
| Adam | epoch: 007 | loss: 0.15323 - acc: 0.9828 -- iter: 096/200
[A[ATraining Step: 46  | total loss: [1m[32m0.15386[0m[0m | time: 47.825s
[2K
| Adam | epoch: 007 | loss: 0.15386 - acc: 0.9753 -- iter: 128/200
[A[ATraining Step: 47  | total loss: [1m[32m0.14365[0m[0m | time: 52.409s
[2K
| Adam | epoch: 007 | loss: 0.14365 - acc: 0.9742 -- iter: 160/200
[A[ATraining Step: 48  | total loss: [1m[32m0.18222[0m[0m | time: 57.007s
[2K
| Adam | epoch: 007 | loss: 0.18222 - acc: 0.9583 -- iter: 192/200
[A[ATraining Step: 49  | total loss: [1m[32m0.18725[0m[0m | time: 71.116s
[2K
| Adam | epoch: 007 | loss: 0.18725 - acc: 0.9451 | val_loss: 1.48311 - val_acc: 0.5238 -- iter: 200/200
--
Training Step: 50  | total loss: [1m[32m0.16470[0m[0m | time: 12.934s
[2K
| Adam | epoch: 008 | loss: 0.16470 - acc: 0.9488 -- iter: 032/200
[A[ATraining Step: 51  | total loss: [1m[32m0.14250[0m[0m | time: 25.661s
[2K
| Adam | epoch: 008 | loss: 0.14250 - acc: 0.9566 -- iter: 064/200
[A[ATraining Step: 52  | total loss: [1m[32m0.13578[0m[0m | time: 38.765s
[2K
| Adam | epoch: 008 | loss: 0.13578 - acc: 0.9584 -- iter: 096/200
[A[ATraining Step: 53  | total loss: [1m[32m0.12412[0m[0m | time: 49.293s
[2K
| Adam | epoch: 008 | loss: 0.12412 - acc: 0.9646 -- iter: 128/200
[A[ATraining Step: 54  | total loss: [1m[32m0.10921[0m[0m | time: 57.104s
[2K
| Adam | epoch: 008 | loss: 0.10921 - acc: 0.9697 -- iter: 160/200
[A[ATraining Step: 55  | total loss: [1m[32m0.10029[0m[0m | time: 59.841s
[2K
| Adam | epoch: 008 | loss: 0.10029 - acc: 0.9696 -- iter: 192/200
[A[ATraining Step: 56  | total loss: [1m[32m0.08779[0m[0m | time: 65.412s
[2K
| Adam | epoch: 008 | loss: 0.08779 - acc: 0.9738 | val_loss: 0.39808 - val_acc: 0.8730 -- iter: 200/200
--
Training Step: 57  | total loss: [1m[32m0.07755[0m[0m | time: 9.535s
[2K
| Adam | epoch: 009 | loss: 0.07755 - acc: 0.9775 -- iter: 032/200
[A[ATraining Step: 58  | total loss: [1m[32m0.06860[0m[0m | time: 17.369s
[2K
| Adam | epoch: 009 | loss: 0.06860 - acc: 0.9805 -- iter: 064/200
[A[ATraining Step: 59  | total loss: [1m[32m0.06162[0m[0m | time: 25.216s
[2K
| Adam | epoch: 009 | loss: 0.06162 - acc: 0.9832 -- iter: 096/200
[A[ATraining Step: 60  | total loss: [1m[32m0.05643[0m[0m | time: 36.810s
[2K
| Adam | epoch: 009 | loss: 0.05643 - acc: 0.9854 -- iter: 128/200
[A[ATraining Step: 61  | total loss: [1m[32m0.05370[0m[0m | time: 49.822s
[2K
| Adam | epoch: 009 | loss: 0.05370 - acc: 0.9873 -- iter: 160/200
[A[ATraining Step: 62  | total loss: [1m[32m0.06335[0m[0m | time: 62.376s
[2K
| Adam | epoch: 009 | loss: 0.06335 - acc: 0.9809 -- iter: 192/200
[A[ATraining Step: 63  | total loss: [1m[32m0.05637[0m[0m | time: 71.377s
[2K
| Adam | epoch: 009 | loss: 0.05637 - acc: 0.9833 | val_loss: 0.23251 - val_acc: 0.9048 -- iter: 200/200
--
Training Step: 64  | total loss: [1m[32m0.20086[0m[0m | time: 2.684s
[2K
| Adam | epoch: 010 | loss: 0.20086 - acc: 0.9698 -- iter: 032/200
[A[ATraining Step: 65  | total loss: [1m[32m0.17722[0m[0m | time: 12.061s
[2K
| Adam | epoch: 010 | loss: 0.17722 - acc: 0.9735 -- iter: 064/200
[A[ATraining Step: 66  | total loss: [1m[32m0.15800[0m[0m | time: 25.182s
[2K
| Adam | epoch: 010 | loss: 0.15800 - acc: 0.9767 -- iter: 096/200
[A[ATraining Step: 67  | total loss: [1m[32m0.17736[0m[0m | time: 38.434s
[2K
| Adam | epoch: 010 | loss: 0.17736 - acc: 0.9683 -- iter: 128/200
[A[ATraining Step: 68  | total loss: [1m[32m0.15800[0m[0m | time: 51.383s
[2K
| Adam | epoch: 010 | loss: 0.15800 - acc: 0.9720 -- iter: 160/200
[A[ATraining Step: 69  | total loss: [1m[32m0.15391[0m[0m | time: 63.546s
[2K
| Adam | epoch: 010 | loss: 0.15391 - acc: 0.9716 -- iter: 192/200
[A[ATraining Step: 70  | total loss: [1m[32m0.14034[0m[0m | time: 75.628s
[2K
| Adam | epoch: 010 | loss: 0.14034 - acc: 0.9749 | val_loss: 0.53414 - val_acc: 0.7937 -- iter: 200/200
--
Training Step: 71  | total loss: [1m[32m0.13928[0m[0m | time: 5.295s
[2K
| Adam | epoch: 011 | loss: 0.13928 - acc: 0.9707 -- iter: 032/200
[A[ATraining Step: 72  | total loss: [1m[32m0.21614[0m[0m | time: 14.435s
[2K
| Adam | epoch: 011 | loss: 0.21614 - acc: 0.9458 -- iter: 064/200
[A[ATraining Step: 73  | total loss: [1m[32m0.20550[0m[0m | time: 49.975s
[2K
| Adam | epoch: 011 | loss: 0.20550 - acc: 0.9518 -- iter: 096/200
[A[ATraining Step: 74  | total loss: [1m[32m0.19659[0m[0m | time: 79.691s
[2K
| Adam | epoch: 011 | loss: 0.19659 - acc: 0.9537 -- iter: 128/200
[A[ATraining Step: 75  | total loss: [1m[32m0.18544[0m[0m | time: 113.480s
[2K
| Adam | epoch: 011 | loss: 0.18544 - acc: 0.9553 -- iter: 160/200
[A[ATraining Step: 76  | total loss: [1m[32m0.18317[0m[0m | time: 132.133s
[2K
| Adam | epoch: 011 | loss: 0.18317 - acc: 0.9568 -- iter: 192/200
[A[ATraining Step: 77  | total loss: [1m[32m0.19249[0m[0m | time: 152.383s
[2K
| Adam | epoch: 011 | loss: 0.19249 - acc: 0.9481 | val_loss: 0.19308 - val_acc: 0.9206 -- iter: 200/200
--
Training Step: 78  | total loss: [1m[32m0.19781[0m[0m | time: 35.556s
[2K
| Adam | epoch: 012 | loss: 0.19781 - acc: 0.9437 -- iter: 032/200
[A[ATraining Step: 79  | total loss: [1m[32m0.18403[0m[0m | time: 42.929s
[2K
| Adam | epoch: 012 | loss: 0.18403 - acc: 0.9463 -- iter: 064/200
[A[ATraining Step: 80  | total loss: [1m[32m0.27983[0m[0m | time: 49.961s
[2K
| Adam | epoch: 012 | loss: 0.27983 - acc: 0.9390 -- iter: 096/200
[A[ATraining Step: 81  | total loss: [1m[32m0.26496[0m[0m | time: 79.685s
[2K
| Adam | epoch: 012 | loss: 0.26496 - acc: 0.9326 -- iter: 128/200
[A[ATraining Step: 82  | total loss: [1m[32m0.24577[0m[0m | time: 110.238s
[2K
| Adam | epoch: 012 | loss: 0.24577 - acc: 0.9362 -- iter: 160/200
[A[ATraining Step: 83  | total loss: [1m[32m0.23694[0m[0m | time: 124.052s
[2K
| Adam | epoch: 012 | loss: 0.23694 - acc: 0.9363 -- iter: 192/200
[A[ATraining Step: 84  | total loss: [1m[32m0.22108[0m[0m | time: 140.832s
[2K
| Adam | epoch: 012 | loss: 0.22108 - acc: 0.9395 | val_loss: 0.58653 - val_acc: 0.7460 -- iter: 200/200
--
Training Step: 85  | total loss: [1m[32m0.21026[0m[0m | time: 12.462s
[2K
| Adam | epoch: 013 | loss: 0.21026 - acc: 0.9393 -- iter: 032/200
[A[ATraining Step: 86  | total loss: [1m[32m0.21236[0m[0m | time: 23.311s
[2K
| Adam | epoch: 013 | loss: 0.21236 - acc: 0.9298 -- iter: 064/200
[A[ATraining Step: 87  | total loss: [1m[32m0.21966[0m[0m | time: 26.049s
[2K
| Adam | epoch: 013 | loss: 0.21966 - acc: 0.9274 -- iter: 096/200
[A[ATraining Step: 88  | total loss: [1m[32m0.38431[0m[0m | time: 30.083s
[2K
| Adam | epoch: 013 | loss: 0.38431 - acc: 0.9097 -- iter: 128/200
[A[ATraining Step: 89  | total loss: [1m[32m0.35421[0m[0m | time: 42.986s
[2K
| Adam | epoch: 013 | loss: 0.35421 - acc: 0.9187 -- iter: 160/200
[A[ATraining Step: 90  | total loss: [1m[32m0.33000[0m[0m | time: 60.838s
[2K
| Adam | epoch: 013 | loss: 0.33000 - acc: 0.9268 -- iter: 192/200
[A[ATraining Step: 91  | total loss: [1m[32m0.31028[0m[0m | time: 85.208s
[2K
| Adam | epoch: 013 | loss: 0.31028 - acc: 0.9279 | val_loss: 0.41058 - val_acc: 0.8730 -- iter: 200/200
--
Training Step: 92  | total loss: [1m[32m0.29070[0m[0m | time: 21.501s
[2K
| Adam | epoch: 014 | loss: 0.29070 - acc: 0.9320 -- iter: 032/200
[A[ATraining Step: 93  | total loss: [1m[32m0.27114[0m[0m | time: 35.028s
[2K
| Adam | epoch: 014 | loss: 0.27114 - acc: 0.9357 -- iter: 064/200
[A[ATraining Step: 94  | total loss: [1m[32m0.25051[0m[0m | time: 51.943s
[2K
| Adam | epoch: 014 | loss: 0.25051 - acc: 0.9421 -- iter: 096/200
[A[ATraining Step: 95  | total loss: [1m[32m0.23036[0m[0m | time: 58.752s
[2K
| Adam | epoch: 014 | loss: 0.23036 - acc: 0.9448 -- iter: 128/200
[A[ATraining Step: 96  | total loss: [1m[32m0.20794[0m[0m | time: 65.665s
[2K
| Adam | epoch: 014 | loss: 0.20794 - acc: 0.9503 -- iter: 160/200
[A[ATraining Step: 97  | total loss: [1m[32m0.18849[0m[0m | time: 83.697s
[2K
| Adam | epoch: 014 | loss: 0.18849 - acc: 0.9553 -- iter: 192/200
[A[ATraining Step: 98  | total loss: [1m[32m0.17076[0m[0m | time: 108.909s
[2K
| Adam | epoch: 014 | loss: 0.17076 - acc: 0.9597 | val_loss: 2.86021 - val_acc: 0.5238 -- iter: 200/200
--
Training Step: 99  | total loss: [1m[32m0.16627[0m[0m | time: 14.594s
[2K
| Adam | epoch: 015 | loss: 0.16627 - acc: 0.9606 -- iter: 032/200
[A[ATraining Step: 100  | total loss: [1m[32m0.15188[0m[0m | time: 32.829s
[2K
| Adam | epoch: 015 | loss: 0.15188 - acc: 0.9646 -- iter: 064/200
[A[ATraining Step: 101  | total loss: [1m[32m0.14352[0m[0m | time: 51.365s
[2K
| Adam | epoch: 015 | loss: 0.14352 - acc: 0.9650 -- iter: 096/200
[A[ATraining Step: 102  | total loss: [1m[32m0.13129[0m[0m | time: 66.334s
[2K
| Adam | epoch: 015 | loss: 0.13129 - acc: 0.9685 -- iter: 128/200
[A[ATraining Step: 103  | total loss: [1m[32m0.11957[0m[0m | time: 70.465s
[2K
| Adam | epoch: 015 | loss: 0.11957 - acc: 0.9716 -- iter: 160/200
[A[ATraining Step: 104  | total loss: [1m[32m0.10878[0m[0m | time: 74.757s
[2K
| Adam | epoch: 015 | loss: 0.10878 - acc: 0.9745 -- iter: 192/200
[A[ATraining Step: 105  | total loss: [1m[32m0.09896[0m[0m | time: 88.248s
[2K
| Adam | epoch: 015 | loss: 0.09896 - acc: 0.9770 | val_loss: 0.67694 - val_acc: 0.8254 -- iter: 200/200
--
Validation AUC:0.9454545454545454
Validation AUPRC:0.9447386723795549
Test AUC:0.9609053497942387
Test AUPRC:0.9634698161926323
BestTestF1Score	0.93	0.84	0.92	0.94	0.92	33	2	25	3	0.77
BestTestMCCScore	0.93	0.84	0.92	0.94	0.92	33	2	25	3	0.77
BestTestAccuracyScore	0.88	0.75	0.87	0.94	0.83	30	2	25	6	0.94
BestValidationF1Score	0.87	0.75	0.87	0.82	0.93	28	6	27	2	0.77
BestValidationMCC	0.87	0.75	0.87	0.82	0.93	28	6	27	2	0.77
BestValidationAccuracy	0.87	0.75	0.87	0.87	0.87	26	4	29	4	0.94
TestPredictions (Threshold:0.77)
CHEMBL3693833,TP,ACT,1.0	CHEMBL432659,TN,INACT,0.0	CHEMBL932,TN,INACT,0.25	CHEMBL2180072,TP,ACT,1.0	CHEMBL3401745,TP,ACT,0.9700000286102295	CHEMBL219882,TN,INACT,0.3100000023841858	CHEMBL1094374,TP,ACT,0.949999988079071	CHEMBL2179097,TP,ACT,0.9800000190734863	CHEMBL3676169,FN,ACT,0.7400000095367432	CHEMBL3671266,TP,ACT,0.9399999976158142	CHEMBL513593,FP,INACT,1.0	CHEMBL511564,FN,ACT,0.6899999976158142	CHEMBL3693820,TP,ACT,1.0	CHEMBL2178122,TP,ACT,1.0	CHEMBL91634,TN,INACT,0.009999999776482582	CHEMBL514277,TN,INACT,0.05000000074505806	CHEMBL466474,TP,ACT,1.0	CHEMBL359890,TN,INACT,0.05999999865889549	CHEMBL1094588,TN,INACT,0.0	CHEMBL31964,TN,INACT,0.0	CHEMBL2178115,TP,ACT,0.9700000286102295	CHEMBL3676170,TP,ACT,1.0	CHEMBL2179101,TP,ACT,1.0	CHEMBL3360416,TP,ACT,1.0	CHEMBL3693817,TP,ACT,1.0	CHEMBL366545,TN,INACT,0.12999999523162842	CHEMBL2312696,TN,INACT,0.0	CHEMBL3355398,TP,ACT,0.8899999856948853	CHEMBL3693855,TP,ACT,1.0	CHEMBL3693832,TP,ACT,1.0	CHEMBL344720,TN,INACT,0.20999999344348907	CHEMBL31954,TN,INACT,0.0	CHEMBL1940056,TN,INACT,0.07999999821186066	CHEMBL3693825,TP,ACT,1.0	CHEMBL3693821,TP,ACT,1.0	CHEMBL2110680,TN,INACT,0.0	CHEMBL1095583,TN,INACT,0.0	CHEMBL2178121,TP,ACT,1.0	CHEMBL2179094,TP,ACT,1.0	CHEMBL3650345,TN,INACT,0.4699999988079071	CHEMBL3693837,TP,ACT,1.0	CHEMBL329876,TN,INACT,0.0	CHEMBL183465,TN,INACT,0.0	CHEMBL12412,TN,INACT,0.07999999821186066	CHEMBL330241,TN,INACT,0.019999999552965164	CHEMBL578033,TP,ACT,1.0	CHEMBL3693840,TP,ACT,1.0	CHEMBL2179103,TP,ACT,1.0	CHEMBL333985,TN,INACT,0.6200000047683716	CHEMBL360627,TN,INACT,0.019999999552965164	CHEMBL2180071,TP,ACT,1.0	CHEMBL2178120,TP,ACT,0.9700000286102295	CHEMBL3771211,TN,INACT,0.3499999940395355	CHEMBL2177496,TP,ACT,1.0	CHEMBL3693854,TP,ACT,1.0	CHEMBL2179104,TP,ACT,1.0	CHEMBL3693841,TP,ACT,1.0	CHEMBL3360420,FN,ACT,0.4699999988079071	CHEMBL98350,FP,INACT,1.0	CHEMBL3676173,TP,ACT,0.9200000166893005	CHEMBL2179098,TP,ACT,1.0	CHEMBL360874,TN,INACT,0.49000000953674316	CHEMBL1779335,TN,INACT,0.0	

