CNNModel CHEMBL4804 adam 0.001 30 256 0 0.8 False True
Number of active compounds :	283
Number of inactive compounds :	232
---------------------------------
Run id: CNNModel_CHEMBL4804_adam_0.001_30_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4804_adam_0.001_30_256_0.8_True/
---------------------------------
Training samples: 323
Validation samples: 101
--
Training Step: 1  | time: 0.989s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/323
[A[ATraining Step: 2  | total loss: [1m[32m0.62392[0m[0m | time: 1.875s
[2K
| Adam | epoch: 001 | loss: 0.62392 - acc: 0.3375 -- iter: 064/323
[A[ATraining Step: 3  | total loss: [1m[32m0.68006[0m[0m | time: 2.701s
[2K
| Adam | epoch: 001 | loss: 0.68006 - acc: 0.4960 -- iter: 096/323
[A[ATraining Step: 4  | total loss: [1m[32m0.68606[0m[0m | time: 3.564s
[2K
| Adam | epoch: 001 | loss: 0.68606 - acc: 0.5459 -- iter: 128/323
[A[ATraining Step: 5  | total loss: [1m[32m0.68456[0m[0m | time: 4.420s
[2K
| Adam | epoch: 001 | loss: 0.68456 - acc: 0.5574 -- iter: 160/323
[A[ATraining Step: 6  | total loss: [1m[32m0.68832[0m[0m | time: 5.315s
[2K
| Adam | epoch: 001 | loss: 0.68832 - acc: 0.5607 -- iter: 192/323
[A[ATraining Step: 7  | total loss: [1m[32m0.69210[0m[0m | time: 6.210s
[2K
| Adam | epoch: 001 | loss: 0.69210 - acc: 0.5430 -- iter: 224/323
[A[ATraining Step: 8  | total loss: [1m[32m0.68911[0m[0m | time: 7.082s
[2K
| Adam | epoch: 001 | loss: 0.68911 - acc: 0.5540 -- iter: 256/323
[A[ATraining Step: 9  | total loss: [1m[32m0.68919[0m[0m | time: 8.013s
[2K
| Adam | epoch: 001 | loss: 0.68919 - acc: 0.5585 -- iter: 288/323
[A[ATraining Step: 10  | total loss: [1m[32m0.69130[0m[0m | time: 8.844s
[2K
| Adam | epoch: 001 | loss: 0.69130 - acc: 0.5292 -- iter: 320/323
[A[ATraining Step: 11  | total loss: [1m[32m0.69509[0m[0m | time: 10.114s
[2K
| Adam | epoch: 001 | loss: 0.69509 - acc: 0.4710 | val_loss: 0.69026 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 12  | total loss: [1m[32m0.68442[0m[0m | time: 0.140s
[2K
| Adam | epoch: 002 | loss: 0.68442 - acc: 0.7090 -- iter: 032/323
[A[ATraining Step: 13  | total loss: [1m[32m0.67533[0m[0m | time: 1.085s
[2K
| Adam | epoch: 002 | loss: 0.67533 - acc: 0.8337 -- iter: 064/323
[A[ATraining Step: 14  | total loss: [1m[32m0.67843[0m[0m | time: 1.966s
[2K
| Adam | epoch: 002 | loss: 0.67843 - acc: 0.7483 -- iter: 096/323
[A[ATraining Step: 15  | total loss: [1m[32m0.67533[0m[0m | time: 2.866s
[2K
| Adam | epoch: 002 | loss: 0.67533 - acc: 0.7245 -- iter: 128/323
[A[ATraining Step: 16  | total loss: [1m[32m0.68431[0m[0m | time: 3.806s
[2K
| Adam | epoch: 002 | loss: 0.68431 - acc: 0.6403 -- iter: 160/323
[A[ATraining Step: 17  | total loss: [1m[32m0.70194[0m[0m | time: 4.707s
[2K
| Adam | epoch: 002 | loss: 0.70194 - acc: 0.5561 -- iter: 192/323
[A[ATraining Step: 18  | total loss: [1m[32m0.70213[0m[0m | time: 5.564s
[2K
| Adam | epoch: 002 | loss: 0.70213 - acc: 0.5367 -- iter: 224/323
[A[ATraining Step: 19  | total loss: [1m[32m0.70020[0m[0m | time: 6.349s
[2K
| Adam | epoch: 002 | loss: 0.70020 - acc: 0.5244 -- iter: 256/323
[A[ATraining Step: 20  | total loss: [1m[32m0.68745[0m[0m | time: 7.384s
[2K
| Adam | epoch: 002 | loss: 0.68745 - acc: 0.5869 -- iter: 288/323
[A[ATraining Step: 21  | total loss: [1m[32m0.68069[0m[0m | time: 8.403s
[2K
| Adam | epoch: 002 | loss: 0.68069 - acc: 0.6181 -- iter: 320/323
[A[ATraining Step: 22  | total loss: [1m[32m0.68076[0m[0m | time: 10.290s
[2K
| Adam | epoch: 002 | loss: 0.68076 - acc: 0.6108 | val_loss: 0.68691 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 23  | total loss: [1m[32m0.68379[0m[0m | time: 0.143s
[2K
| Adam | epoch: 003 | loss: 0.68379 - acc: 0.5877 -- iter: 032/323
[A[ATraining Step: 24  | total loss: [1m[32m0.71637[0m[0m | time: 0.266s
[2K
| Adam | epoch: 003 | loss: 0.71637 - acc: 0.4224 -- iter: 064/323
[A[ATraining Step: 25  | total loss: [1m[32m0.73392[0m[0m | time: 1.163s
[2K
| Adam | epoch: 003 | loss: 0.73392 - acc: 0.3072 -- iter: 096/323
[A[ATraining Step: 26  | total loss: [1m[32m0.71846[0m[0m | time: 2.103s
[2K
| Adam | epoch: 003 | loss: 0.71846 - acc: 0.3996 -- iter: 128/323
[A[ATraining Step: 27  | total loss: [1m[32m0.71061[0m[0m | time: 2.973s
[2K
| Adam | epoch: 003 | loss: 0.71061 - acc: 0.4415 -- iter: 160/323
[A[ATraining Step: 28  | total loss: [1m[32m0.70650[0m[0m | time: 3.840s
[2K
| Adam | epoch: 003 | loss: 0.70650 - acc: 0.4561 -- iter: 192/323
[A[ATraining Step: 29  | total loss: [1m[32m0.70021[0m[0m | time: 4.769s
[2K
| Adam | epoch: 003 | loss: 0.70021 - acc: 0.5048 -- iter: 224/323
[A[ATraining Step: 30  | total loss: [1m[32m0.69817[0m[0m | time: 5.886s
[2K
| Adam | epoch: 003 | loss: 0.69817 - acc: 0.5111 -- iter: 256/323
[A[ATraining Step: 31  | total loss: [1m[32m0.69775[0m[0m | time: 6.971s
[2K
| Adam | epoch: 003 | loss: 0.69775 - acc: 0.5013 -- iter: 288/323
[A[ATraining Step: 32  | total loss: [1m[32m0.69584[0m[0m | time: 7.679s
[2K
| Adam | epoch: 003 | loss: 0.69584 - acc: 0.5151 -- iter: 320/323
[A[ATraining Step: 33  | total loss: [1m[32m0.69292[0m[0m | time: 9.530s
[2K
| Adam | epoch: 003 | loss: 0.69292 - acc: 0.5461 | val_loss: 0.68987 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 34  | total loss: [1m[32m0.69316[0m[0m | time: 0.971s
[2K
| Adam | epoch: 004 | loss: 0.69316 - acc: 0.5362 -- iter: 032/323
[A[ATraining Step: 35  | total loss: [1m[32m0.69335[0m[0m | time: 1.077s
[2K
| Adam | epoch: 004 | loss: 0.69335 - acc: 0.5286 -- iter: 064/323
[A[ATraining Step: 36  | total loss: [1m[32m0.69569[0m[0m | time: 1.183s
[2K
| Adam | epoch: 004 | loss: 0.69569 - acc: 0.4887 -- iter: 096/323
[A[ATraining Step: 37  | total loss: [1m[32m0.69752[0m[0m | time: 2.077s
[2K
| Adam | epoch: 004 | loss: 0.69752 - acc: 0.4576 -- iter: 128/323
[A[ATraining Step: 38  | total loss: [1m[32m0.69559[0m[0m | time: 3.120s
[2K
| Adam | epoch: 004 | loss: 0.69559 - acc: 0.4842 -- iter: 160/323
[A[ATraining Step: 39  | total loss: [1m[32m0.69446[0m[0m | time: 4.148s
[2K
| Adam | epoch: 004 | loss: 0.69446 - acc: 0.4992 -- iter: 192/323
[A[ATraining Step: 40  | total loss: [1m[32m0.69321[0m[0m | time: 4.968s
[2K
| Adam | epoch: 004 | loss: 0.69321 - acc: 0.5169 -- iter: 224/323
[A[ATraining Step: 41  | total loss: [1m[32m0.69218[0m[0m | time: 5.784s
[2K
| Adam | epoch: 004 | loss: 0.69218 - acc: 0.5311 -- iter: 256/323
[A[ATraining Step: 42  | total loss: [1m[32m0.69283[0m[0m | time: 6.692s
[2K
| Adam | epoch: 004 | loss: 0.69283 - acc: 0.5198 -- iter: 288/323
[A[ATraining Step: 43  | total loss: [1m[32m0.69232[0m[0m | time: 7.572s
[2K
| Adam | epoch: 004 | loss: 0.69232 - acc: 0.5274 -- iter: 320/323
[A[ATraining Step: 44  | total loss: [1m[32m0.69253[0m[0m | time: 9.499s
[2K
| Adam | epoch: 004 | loss: 0.69253 - acc: 0.5226 | val_loss: 0.69018 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 45  | total loss: [1m[32m0.69235[0m[0m | time: 1.036s
[2K
| Adam | epoch: 005 | loss: 0.69235 - acc: 0.5241 -- iter: 032/323
[A[ATraining Step: 46  | total loss: [1m[32m0.69094[0m[0m | time: 2.035s
[2K
| Adam | epoch: 005 | loss: 0.69094 - acc: 0.5461 -- iter: 064/323
[A[ATraining Step: 47  | total loss: [1m[32m0.69108[0m[0m | time: 2.178s
[2K
| Adam | epoch: 005 | loss: 0.69108 - acc: 0.5437 -- iter: 096/323
[A[ATraining Step: 48  | total loss: [1m[32m0.68970[0m[0m | time: 2.270s
[2K
| Adam | epoch: 005 | loss: 0.68970 - acc: 0.5635 -- iter: 128/323
[A[ATraining Step: 49  | total loss: [1m[32m0.68849[0m[0m | time: 3.007s
[2K
| Adam | epoch: 005 | loss: 0.68849 - acc: 0.5797 -- iter: 160/323
[A[ATraining Step: 50  | total loss: [1m[32m0.68894[0m[0m | time: 3.837s
[2K
| Adam | epoch: 005 | loss: 0.68894 - acc: 0.5722 -- iter: 192/323
[A[ATraining Step: 51  | total loss: [1m[32m0.68819[0m[0m | time: 4.735s
[2K
| Adam | epoch: 005 | loss: 0.68819 - acc: 0.5803 -- iter: 224/323
[A[ATraining Step: 52  | total loss: [1m[32m0.68792[0m[0m | time: 5.667s
[2K
| Adam | epoch: 005 | loss: 0.68792 - acc: 0.5823 -- iter: 256/323
[A[ATraining Step: 53  | total loss: [1m[32m0.68766[0m[0m | time: 6.542s
[2K
| Adam | epoch: 005 | loss: 0.68766 - acc: 0.5840 -- iter: 288/323
[A[ATraining Step: 54  | total loss: [1m[32m0.68821[0m[0m | time: 7.440s
[2K
| Adam | epoch: 005 | loss: 0.68821 - acc: 0.5763 -- iter: 320/323
[A[ATraining Step: 55  | total loss: [1m[32m0.68652[0m[0m | time: 9.315s
[2K
| Adam | epoch: 005 | loss: 0.68652 - acc: 0.5922 | val_loss: 0.68865 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 56  | total loss: [1m[32m0.68679[0m[0m | time: 0.882s
[2K
| Adam | epoch: 006 | loss: 0.68679 - acc: 0.5880 -- iter: 032/323
[A[ATraining Step: 57  | total loss: [1m[32m0.68737[0m[0m | time: 1.655s
[2K
| Adam | epoch: 006 | loss: 0.68737 - acc: 0.5802 -- iter: 064/323
[A[ATraining Step: 58  | total loss: [1m[32m0.68787[0m[0m | time: 2.526s
[2K
| Adam | epoch: 006 | loss: 0.68787 - acc: 0.5735 -- iter: 096/323
[A[ATraining Step: 59  | total loss: [1m[32m0.68728[0m[0m | time: 2.658s
[2K
| Adam | epoch: 006 | loss: 0.68728 - acc: 0.5762 -- iter: 128/323
[A[ATraining Step: 60  | total loss: [1m[32m0.69113[0m[0m | time: 2.780s
[2K
| Adam | epoch: 006 | loss: 0.69113 - acc: 0.5441 -- iter: 160/323
[A[ATraining Step: 61  | total loss: [1m[32m0.69451[0m[0m | time: 3.647s
[2K
| Adam | epoch: 006 | loss: 0.69451 - acc: 0.5166 -- iter: 192/323
[A[ATraining Step: 62  | total loss: [1m[32m0.69518[0m[0m | time: 4.498s
[2K
| Adam | epoch: 006 | loss: 0.69518 - acc: 0.5104 -- iter: 224/323
[A[ATraining Step: 63  | total loss: [1m[32m0.69468[0m[0m | time: 5.383s
[2K
| Adam | epoch: 006 | loss: 0.69468 - acc: 0.5131 -- iter: 256/323
[A[ATraining Step: 64  | total loss: [1m[32m0.69665[0m[0m | time: 6.345s
[2K
| Adam | epoch: 006 | loss: 0.69665 - acc: 0.4958 -- iter: 288/323
[A[ATraining Step: 65  | total loss: [1m[32m0.69601[0m[0m | time: 7.200s
[2K
| Adam | epoch: 006 | loss: 0.69601 - acc: 0.5002 -- iter: 320/323
[A[ATraining Step: 66  | total loss: [1m[32m0.69499[0m[0m | time: 9.136s
[2K
| Adam | epoch: 006 | loss: 0.69499 - acc: 0.5078 | val_loss: 0.68852 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 67  | total loss: [1m[32m0.69371[0m[0m | time: 0.785s
[2K
| Adam | epoch: 007 | loss: 0.69371 - acc: 0.5181 -- iter: 032/323
[A[ATraining Step: 68  | total loss: [1m[32m0.69169[0m[0m | time: 1.703s
[2K
| Adam | epoch: 007 | loss: 0.69169 - acc: 0.5344 -- iter: 064/323
[A[ATraining Step: 69  | total loss: [1m[32m0.69123[0m[0m | time: 2.596s
[2K
| Adam | epoch: 007 | loss: 0.69123 - acc: 0.5377 -- iter: 096/323
[A[ATraining Step: 70  | total loss: [1m[32m0.68827[0m[0m | time: 3.474s
[2K
| Adam | epoch: 007 | loss: 0.68827 - acc: 0.5622 -- iter: 128/323
[A[ATraining Step: 71  | total loss: [1m[32m0.68774[0m[0m | time: 3.624s
[2K
| Adam | epoch: 007 | loss: 0.68774 - acc: 0.5658 -- iter: 160/323
[A[ATraining Step: 72  | total loss: [1m[32m0.69075[0m[0m | time: 3.755s
[2K
| Adam | epoch: 007 | loss: 0.69075 - acc: 0.5397 -- iter: 192/323
[A[ATraining Step: 73  | total loss: [1m[32m0.69367[0m[0m | time: 4.667s
[2K
| Adam | epoch: 007 | loss: 0.69367 - acc: 0.5167 -- iter: 224/323
[A[ATraining Step: 74  | total loss: [1m[32m0.69336[0m[0m | time: 5.598s
[2K
| Adam | epoch: 007 | loss: 0.69336 - acc: 0.5183 -- iter: 256/323
[A[ATraining Step: 75  | total loss: [1m[32m0.69390[0m[0m | time: 6.480s
[2K
| Adam | epoch: 007 | loss: 0.69390 - acc: 0.5129 -- iter: 288/323
[A[ATraining Step: 76  | total loss: [1m[32m0.69360[0m[0m | time: 7.405s
[2K
| Adam | epoch: 007 | loss: 0.69360 - acc: 0.5149 -- iter: 320/323
[A[ATraining Step: 77  | total loss: [1m[32m0.69337[0m[0m | time: 9.250s
[2K
| Adam | epoch: 007 | loss: 0.69337 - acc: 0.5166 | val_loss: 0.68842 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 78  | total loss: [1m[32m0.69196[0m[0m | time: 0.907s
[2K
| Adam | epoch: 008 | loss: 0.69196 - acc: 0.5280 -- iter: 032/323
[A[ATraining Step: 79  | total loss: [1m[32m0.69112[0m[0m | time: 1.787s
[2K
| Adam | epoch: 008 | loss: 0.69112 - acc: 0.5348 -- iter: 064/323
[A[ATraining Step: 80  | total loss: [1m[32m0.69034[0m[0m | time: 2.687s
[2K
| Adam | epoch: 008 | loss: 0.69034 - acc: 0.5408 -- iter: 096/323
[A[ATraining Step: 81  | total loss: [1m[32m0.69041[0m[0m | time: 3.596s
[2K
| Adam | epoch: 008 | loss: 0.69041 - acc: 0.5398 -- iter: 128/323
[A[ATraining Step: 82  | total loss: [1m[32m0.68895[0m[0m | time: 4.483s
[2K
| Adam | epoch: 008 | loss: 0.68895 - acc: 0.5515 -- iter: 160/323
[A[ATraining Step: 83  | total loss: [1m[32m0.68960[0m[0m | time: 4.620s
[2K
| Adam | epoch: 008 | loss: 0.68960 - acc: 0.5463 -- iter: 192/323
[A[ATraining Step: 84  | total loss: [1m[32m0.68818[0m[0m | time: 4.764s
[2K
| Adam | epoch: 008 | loss: 0.68818 - acc: 0.5584 -- iter: 224/323
[A[ATraining Step: 85  | total loss: [1m[32m0.68690[0m[0m | time: 5.630s
[2K
| Adam | epoch: 008 | loss: 0.68690 - acc: 0.5692 -- iter: 256/323
[A[ATraining Step: 86  | total loss: [1m[32m0.68735[0m[0m | time: 6.447s
[2K
| Adam | epoch: 008 | loss: 0.68735 - acc: 0.5654 -- iter: 288/323
[A[ATraining Step: 87  | total loss: [1m[32m0.68825[0m[0m | time: 7.489s
[2K
| Adam | epoch: 008 | loss: 0.68825 - acc: 0.5589 -- iter: 320/323
[A[ATraining Step: 88  | total loss: [1m[32m0.68898[0m[0m | time: 9.546s
[2K
| Adam | epoch: 008 | loss: 0.68898 - acc: 0.5530 | val_loss: 0.68782 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 89  | total loss: [1m[32m0.69060[0m[0m | time: 0.866s
[2K
| Adam | epoch: 009 | loss: 0.69060 - acc: 0.5414 -- iter: 032/323
[A[ATraining Step: 90  | total loss: [1m[32m0.69161[0m[0m | time: 1.766s
[2K
| Adam | epoch: 009 | loss: 0.69161 - acc: 0.5342 -- iter: 064/323
[A[ATraining Step: 91  | total loss: [1m[32m0.69157[0m[0m | time: 2.738s
[2K
| Adam | epoch: 009 | loss: 0.69157 - acc: 0.5339 -- iter: 096/323
[A[ATraining Step: 92  | total loss: [1m[32m0.69115[0m[0m | time: 3.594s
[2K
| Adam | epoch: 009 | loss: 0.69115 - acc: 0.5367 -- iter: 128/323
[A[ATraining Step: 93  | total loss: [1m[32m0.68973[0m[0m | time: 4.489s
[2K
| Adam | epoch: 009 | loss: 0.68973 - acc: 0.5456 -- iter: 160/323
[A[ATraining Step: 94  | total loss: [1m[32m0.68850[0m[0m | time: 5.319s
[2K
| Adam | epoch: 009 | loss: 0.68850 - acc: 0.5535 -- iter: 192/323
[A[ATraining Step: 95  | total loss: [1m[32m0.68694[0m[0m | time: 5.423s
[2K
| Adam | epoch: 009 | loss: 0.68694 - acc: 0.5638 -- iter: 224/323
[A[ATraining Step: 96  | total loss: [1m[32m0.68026[0m[0m | time: 5.553s
[2K
| Adam | epoch: 009 | loss: 0.68026 - acc: 0.6074 -- iter: 256/323
[A[ATraining Step: 97  | total loss: [1m[32m0.67354[0m[0m | time: 6.538s
[2K
| Adam | epoch: 009 | loss: 0.67354 - acc: 0.6467 -- iter: 288/323
[A[ATraining Step: 98  | total loss: [1m[32m0.67364[0m[0m | time: 7.560s
[2K
| Adam | epoch: 009 | loss: 0.67364 - acc: 0.6445 -- iter: 320/323
[A[ATraining Step: 99  | total loss: [1m[32m0.67551[0m[0m | time: 9.459s
[2K
| Adam | epoch: 009 | loss: 0.67551 - acc: 0.6332 | val_loss: 0.68710 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 100  | total loss: [1m[32m0.67589[0m[0m | time: 0.909s
[2K
| Adam | epoch: 010 | loss: 0.67589 - acc: 0.6292 -- iter: 032/323
[A[ATraining Step: 101  | total loss: [1m[32m0.67825[0m[0m | time: 1.815s
[2K
| Adam | epoch: 010 | loss: 0.67825 - acc: 0.6163 -- iter: 064/323
[A[ATraining Step: 102  | total loss: [1m[32m0.68187[0m[0m | time: 2.655s
[2K
| Adam | epoch: 010 | loss: 0.68187 - acc: 0.5984 -- iter: 096/323
[A[ATraining Step: 103  | total loss: [1m[32m0.68217[0m[0m | time: 3.565s
[2K
| Adam | epoch: 010 | loss: 0.68217 - acc: 0.5948 -- iter: 128/323
[A[ATraining Step: 104  | total loss: [1m[32m0.68158[0m[0m | time: 4.574s
[2K
| Adam | epoch: 010 | loss: 0.68158 - acc: 0.5947 -- iter: 160/323
[A[ATraining Step: 105  | total loss: [1m[32m0.68272[0m[0m | time: 5.566s
[2K
| Adam | epoch: 010 | loss: 0.68272 - acc: 0.5884 -- iter: 192/323
[A[ATraining Step: 106  | total loss: [1m[32m0.68037[0m[0m | time: 6.271s
[2K
| Adam | epoch: 010 | loss: 0.68037 - acc: 0.5952 -- iter: 224/323
[A[ATraining Step: 107  | total loss: [1m[32m0.67998[0m[0m | time: 6.369s
[2K
| Adam | epoch: 010 | loss: 0.67998 - acc: 0.5950 -- iter: 256/323
[A[ATraining Step: 108  | total loss: [1m[32m0.67717[0m[0m | time: 6.485s
[2K
| Adam | epoch: 010 | loss: 0.67717 - acc: 0.6022 -- iter: 288/323
[A[ATraining Step: 109  | total loss: [1m[32m0.67486[0m[0m | time: 7.419s
[2K
| Adam | epoch: 010 | loss: 0.67486 - acc: 0.6086 -- iter: 320/323
[A[ATraining Step: 110  | total loss: [1m[32m0.67490[0m[0m | time: 9.313s
[2K
| Adam | epoch: 010 | loss: 0.67490 - acc: 0.6071 | val_loss: 0.68829 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 111  | total loss: [1m[32m0.67700[0m[0m | time: 0.821s
[2K
| Adam | epoch: 011 | loss: 0.67700 - acc: 0.5996 -- iter: 032/323
[A[ATraining Step: 112  | total loss: [1m[32m0.67675[0m[0m | time: 1.844s
[2K
| Adam | epoch: 011 | loss: 0.67675 - acc: 0.5990 -- iter: 064/323
[A[ATraining Step: 113  | total loss: [1m[32m0.67489[0m[0m | time: 2.852s
[2K
| Adam | epoch: 011 | loss: 0.67489 - acc: 0.6016 -- iter: 096/323
[A[ATraining Step: 114  | total loss: [1m[32m0.67329[0m[0m | time: 3.721s
[2K
| Adam | epoch: 011 | loss: 0.67329 - acc: 0.6039 -- iter: 128/323
[A[ATraining Step: 115  | total loss: [1m[32m0.67061[0m[0m | time: 4.494s
[2K
| Adam | epoch: 011 | loss: 0.67061 - acc: 0.6092 -- iter: 160/323
[A[ATraining Step: 116  | total loss: [1m[32m0.68084[0m[0m | time: 5.450s
[2K
| Adam | epoch: 011 | loss: 0.68084 - acc: 0.5889 -- iter: 192/323
[A[ATraining Step: 117  | total loss: [1m[32m0.68158[0m[0m | time: 6.324s
[2K
| Adam | epoch: 011 | loss: 0.68158 - acc: 0.5862 -- iter: 224/323
[A[ATraining Step: 118  | total loss: [1m[32m0.68040[0m[0m | time: 7.232s
[2K
| Adam | epoch: 011 | loss: 0.68040 - acc: 0.5870 -- iter: 256/323
[A[ATraining Step: 119  | total loss: [1m[32m0.68293[0m[0m | time: 7.353s
[2K
| Adam | epoch: 011 | loss: 0.68293 - acc: 0.5783 -- iter: 288/323
[A[ATraining Step: 120  | total loss: [1m[32m0.68056[0m[0m | time: 7.472s
[2K
| Adam | epoch: 011 | loss: 0.68056 - acc: 0.5871 -- iter: 320/323
[A[ATraining Step: 121  | total loss: [1m[32m0.67768[0m[0m | time: 9.376s
[2K
| Adam | epoch: 011 | loss: 0.67768 - acc: 0.5951 | val_loss: 0.68749 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 122  | total loss: [1m[32m0.67953[0m[0m | time: 1.026s
[2K
| Adam | epoch: 012 | loss: 0.67953 - acc: 0.5887 -- iter: 032/323
[A[ATraining Step: 123  | total loss: [1m[32m0.68115[0m[0m | time: 1.753s
[2K
| Adam | epoch: 012 | loss: 0.68115 - acc: 0.5829 -- iter: 064/323
[A[ATraining Step: 124  | total loss: [1m[32m0.67724[0m[0m | time: 2.630s
[2K
| Adam | epoch: 012 | loss: 0.67724 - acc: 0.5934 -- iter: 096/323
[A[ATraining Step: 125  | total loss: [1m[32m0.68216[0m[0m | time: 3.530s
[2K
| Adam | epoch: 012 | loss: 0.68216 - acc: 0.5778 -- iter: 128/323
[A[ATraining Step: 126  | total loss: [1m[32m0.68750[0m[0m | time: 4.411s
[2K
| Adam | epoch: 012 | loss: 0.68750 - acc: 0.5607 -- iter: 160/323
[A[ATraining Step: 127  | total loss: [1m[32m0.68789[0m[0m | time: 5.291s
[2K
| Adam | epoch: 012 | loss: 0.68789 - acc: 0.5577 -- iter: 192/323
[A[ATraining Step: 128  | total loss: [1m[32m0.68392[0m[0m | time: 6.224s
[2K
| Adam | epoch: 012 | loss: 0.68392 - acc: 0.5676 -- iter: 224/323
[A[ATraining Step: 129  | total loss: [1m[32m0.68110[0m[0m | time: 7.146s
[2K
| Adam | epoch: 012 | loss: 0.68110 - acc: 0.5733 -- iter: 256/323
[A[ATraining Step: 130  | total loss: [1m[32m0.68192[0m[0m | time: 8.040s
[2K
| Adam | epoch: 012 | loss: 0.68192 - acc: 0.5691 -- iter: 288/323
[A[ATraining Step: 131  | total loss: [1m[32m0.68118[0m[0m | time: 8.169s
[2K
| Adam | epoch: 012 | loss: 0.68118 - acc: 0.5684 -- iter: 320/323
[A[ATraining Step: 132  | total loss: [1m[32m0.68139[0m[0m | time: 9.341s
[2K
| Adam | epoch: 012 | loss: 0.68139 - acc: 0.5783 | val_loss: 0.67177 - val_acc: 0.5545 -- iter: 323/323
--
Training Step: 133  | total loss: [1m[32m0.68077[0m[0m | time: 0.869s
[2K
| Adam | epoch: 013 | loss: 0.68077 - acc: 0.5871 -- iter: 032/323
[A[ATraining Step: 134  | total loss: [1m[32m0.68038[0m[0m | time: 1.746s
[2K
| Adam | epoch: 013 | loss: 0.68038 - acc: 0.5846 -- iter: 064/323
[A[ATraining Step: 135  | total loss: [1m[32m0.67932[0m[0m | time: 2.671s
[2K
| Adam | epoch: 013 | loss: 0.67932 - acc: 0.5856 -- iter: 096/323
[A[ATraining Step: 136  | total loss: [1m[32m0.68262[0m[0m | time: 3.612s
[2K
| Adam | epoch: 013 | loss: 0.68262 - acc: 0.5739 -- iter: 128/323
[A[ATraining Step: 137  | total loss: [1m[32m0.67961[0m[0m | time: 4.544s
[2K
| Adam | epoch: 013 | loss: 0.67961 - acc: 0.5790 -- iter: 160/323
[A[ATraining Step: 138  | total loss: [1m[32m0.67779[0m[0m | time: 5.502s
[2K
| Adam | epoch: 013 | loss: 0.67779 - acc: 0.5805 -- iter: 192/323
[A[ATraining Step: 139  | total loss: [1m[32m0.67555[0m[0m | time: 6.353s
[2K
| Adam | epoch: 013 | loss: 0.67555 - acc: 0.5818 -- iter: 224/323
[A[ATraining Step: 140  | total loss: [1m[32m0.67369[0m[0m | time: 7.304s
[2K
| Adam | epoch: 013 | loss: 0.67369 - acc: 0.5861 -- iter: 256/323
[A[ATraining Step: 141  | total loss: [1m[32m0.66983[0m[0m | time: 8.336s
[2K
| Adam | epoch: 013 | loss: 0.66983 - acc: 0.5869 -- iter: 288/323
[A[ATraining Step: 142  | total loss: [1m[32m0.67252[0m[0m | time: 9.327s
[2K
| Adam | epoch: 013 | loss: 0.67252 - acc: 0.5782 -- iter: 320/323
[A[ATraining Step: 143  | total loss: [1m[32m0.67567[0m[0m | time: 10.452s
[2K
| Adam | epoch: 013 | loss: 0.67567 - acc: 0.5579 | val_loss: 0.65542 - val_acc: 0.7426 -- iter: 323/323
--
Training Step: 144  | total loss: [1m[32m0.67373[0m[0m | time: 0.146s
[2K
| Adam | epoch: 014 | loss: 0.67373 - acc: 0.5688 -- iter: 032/323
[A[ATraining Step: 145  | total loss: [1m[32m0.66954[0m[0m | time: 1.028s
[2K
| Adam | epoch: 014 | loss: 0.66954 - acc: 0.6119 -- iter: 064/323
[A[ATraining Step: 146  | total loss: [1m[32m0.66169[0m[0m | time: 1.891s
[2K
| Adam | epoch: 014 | loss: 0.66169 - acc: 0.6257 -- iter: 096/323
[A[ATraining Step: 147  | total loss: [1m[32m0.65459[0m[0m | time: 2.800s
[2K
| Adam | epoch: 014 | loss: 0.65459 - acc: 0.6256 -- iter: 128/323
[A[ATraining Step: 148  | total loss: [1m[32m0.66156[0m[0m | time: 3.805s
[2K
| Adam | epoch: 014 | loss: 0.66156 - acc: 0.6256 -- iter: 160/323
[A[ATraining Step: 149  | total loss: [1m[32m0.65611[0m[0m | time: 4.802s
[2K
| Adam | epoch: 014 | loss: 0.65611 - acc: 0.6286 -- iter: 192/323
[A[ATraining Step: 150  | total loss: [1m[32m0.64622[0m[0m | time: 5.648s
[2K
| Adam | epoch: 014 | loss: 0.64622 - acc: 0.6408 -- iter: 224/323
[A[ATraining Step: 151  | total loss: [1m[32m0.63876[0m[0m | time: 6.455s
[2K
| Adam | epoch: 014 | loss: 0.63876 - acc: 0.6486 -- iter: 256/323
[A[ATraining Step: 152  | total loss: [1m[32m0.63737[0m[0m | time: 7.384s
[2K
| Adam | epoch: 014 | loss: 0.63737 - acc: 0.6556 -- iter: 288/323
[A[ATraining Step: 153  | total loss: [1m[32m0.63429[0m[0m | time: 8.325s
[2K
| Adam | epoch: 014 | loss: 0.63429 - acc: 0.6650 -- iter: 320/323
[A[ATraining Step: 154  | total loss: [1m[32m0.62510[0m[0m | time: 10.213s
[2K
| Adam | epoch: 014 | loss: 0.62510 - acc: 0.6798 | val_loss: 0.55250 - val_acc: 0.6931 -- iter: 323/323
--
Training Step: 155  | total loss: [1m[32m0.61732[0m[0m | time: 0.145s
[2K
| Adam | epoch: 015 | loss: 0.61732 - acc: 0.6868 -- iter: 032/323
[A[ATraining Step: 156  | total loss: [1m[32m0.61223[0m[0m | time: 0.323s
[2K
| Adam | epoch: 015 | loss: 0.61223 - acc: 0.6848 -- iter: 064/323
[A[ATraining Step: 157  | total loss: [1m[32m0.59432[0m[0m | time: 1.360s
[2K
| Adam | epoch: 015 | loss: 0.59432 - acc: 0.6830 -- iter: 096/323
[A[ATraining Step: 158  | total loss: [1m[32m0.59075[0m[0m | time: 2.502s
[2K
| Adam | epoch: 015 | loss: 0.59075 - acc: 0.6834 -- iter: 128/323
[A[ATraining Step: 159  | total loss: [1m[32m0.59338[0m[0m | time: 3.498s
[2K
| Adam | epoch: 015 | loss: 0.59338 - acc: 0.6776 -- iter: 160/323
[A[ATraining Step: 160  | total loss: [1m[32m0.57948[0m[0m | time: 4.452s
[2K
| Adam | epoch: 015 | loss: 0.57948 - acc: 0.6911 -- iter: 192/323
[A[ATraining Step: 161  | total loss: [1m[32m0.57984[0m[0m | time: 5.515s
[2K
| Adam | epoch: 015 | loss: 0.57984 - acc: 0.6938 -- iter: 224/323
[A[ATraining Step: 162  | total loss: [1m[32m0.57970[0m[0m | time: 6.664s
[2K
| Adam | epoch: 015 | loss: 0.57970 - acc: 0.6932 -- iter: 256/323
[A[ATraining Step: 163  | total loss: [1m[32m0.57883[0m[0m | time: 7.843s
[2K
| Adam | epoch: 015 | loss: 0.57883 - acc: 0.6989 -- iter: 288/323
[A[ATraining Step: 164  | total loss: [1m[32m0.57483[0m[0m | time: 8.947s
[2K
| Adam | epoch: 015 | loss: 0.57483 - acc: 0.7040 -- iter: 320/323
[A[ATraining Step: 165  | total loss: [1m[32m0.59184[0m[0m | time: 11.143s
[2K
| Adam | epoch: 015 | loss: 0.59184 - acc: 0.6867 | val_loss: 0.50045 - val_acc: 0.7822 -- iter: 323/323
--
Training Step: 166  | total loss: [1m[32m0.57615[0m[0m | time: 1.167s
[2K
| Adam | epoch: 016 | loss: 0.57615 - acc: 0.6962 -- iter: 032/323
[A[ATraining Step: 167  | total loss: [1m[32m0.57225[0m[0m | time: 1.329s
[2K
| Adam | epoch: 016 | loss: 0.57225 - acc: 0.6984 -- iter: 064/323
[A[ATraining Step: 168  | total loss: [1m[32m0.55941[0m[0m | time: 1.515s
[2K
| Adam | epoch: 016 | loss: 0.55941 - acc: 0.7286 -- iter: 096/323
[A[ATraining Step: 169  | total loss: [1m[32m0.53555[0m[0m | time: 2.760s
[2K
| Adam | epoch: 016 | loss: 0.53555 - acc: 0.7557 -- iter: 128/323
[A[ATraining Step: 170  | total loss: [1m[32m0.52944[0m[0m | time: 3.861s
[2K
| Adam | epoch: 016 | loss: 0.52944 - acc: 0.7552 -- iter: 160/323
[A[ATraining Step: 171  | total loss: [1m[32m0.52430[0m[0m | time: 4.808s
[2K
| Adam | epoch: 016 | loss: 0.52430 - acc: 0.7578 -- iter: 192/323
[A[ATraining Step: 172  | total loss: [1m[32m0.53360[0m[0m | time: 5.828s
[2K
| Adam | epoch: 016 | loss: 0.53360 - acc: 0.7539 -- iter: 224/323
[A[ATraining Step: 173  | total loss: [1m[32m0.53335[0m[0m | time: 6.894s
[2K
| Adam | epoch: 016 | loss: 0.53335 - acc: 0.7566 -- iter: 256/323
[A[ATraining Step: 174  | total loss: [1m[32m0.53105[0m[0m | time: 7.902s
[2K
| Adam | epoch: 016 | loss: 0.53105 - acc: 0.7466 -- iter: 288/323
[A[ATraining Step: 175  | total loss: [1m[32m0.52436[0m[0m | time: 9.360s
[2K
| Adam | epoch: 016 | loss: 0.52436 - acc: 0.7563 -- iter: 320/323
[A[ATraining Step: 176  | total loss: [1m[32m0.51289[0m[0m | time: 11.271s
[2K
| Adam | epoch: 016 | loss: 0.51289 - acc: 0.7619 | val_loss: 0.43984 - val_acc: 0.8218 -- iter: 323/323
--
Training Step: 177  | total loss: [1m[32m0.49598[0m[0m | time: 1.151s
[2K
| Adam | epoch: 017 | loss: 0.49598 - acc: 0.7670 -- iter: 032/323
[A[ATraining Step: 178  | total loss: [1m[32m0.49010[0m[0m | time: 2.410s
[2K
| Adam | epoch: 017 | loss: 0.49010 - acc: 0.7715 -- iter: 064/323
[A[ATraining Step: 179  | total loss: [1m[32m0.47502[0m[0m | time: 2.599s
[2K
| Adam | epoch: 017 | loss: 0.47502 - acc: 0.7787 -- iter: 096/323
[A[ATraining Step: 180  | total loss: [1m[32m0.46960[0m[0m | time: 2.750s
[2K
| Adam | epoch: 017 | loss: 0.46960 - acc: 0.8009 -- iter: 128/323
[A[ATraining Step: 181  | total loss: [1m[32m0.44266[0m[0m | time: 3.939s
[2K
| Adam | epoch: 017 | loss: 0.44266 - acc: 0.8208 -- iter: 160/323
[A[ATraining Step: 182  | total loss: [1m[32m0.44720[0m[0m | time: 4.852s
[2K
| Adam | epoch: 017 | loss: 0.44720 - acc: 0.8106 -- iter: 192/323
[A[ATraining Step: 183  | total loss: [1m[32m0.43675[0m[0m | time: 5.861s
[2K
| Adam | epoch: 017 | loss: 0.43675 - acc: 0.8170 -- iter: 224/323
[A[ATraining Step: 184  | total loss: [1m[32m0.41935[0m[0m | time: 6.928s
[2K
| Adam | epoch: 017 | loss: 0.41935 - acc: 0.8197 -- iter: 256/323
[A[ATraining Step: 185  | total loss: [1m[32m0.40884[0m[0m | time: 8.040s
[2K
| Adam | epoch: 017 | loss: 0.40884 - acc: 0.8252 -- iter: 288/323
[A[ATraining Step: 186  | total loss: [1m[32m0.43907[0m[0m | time: 9.091s
[2K
| Adam | epoch: 017 | loss: 0.43907 - acc: 0.8115 -- iter: 320/323
[A[ATraining Step: 187  | total loss: [1m[32m0.42333[0m[0m | time: 11.134s
[2K
| Adam | epoch: 017 | loss: 0.42333 - acc: 0.8178 | val_loss: 0.44742 - val_acc: 0.8317 -- iter: 323/323
--
Training Step: 188  | total loss: [1m[32m0.45473[0m[0m | time: 1.069s
[2K
| Adam | epoch: 018 | loss: 0.45473 - acc: 0.8110 -- iter: 032/323
[A[ATraining Step: 189  | total loss: [1m[32m0.43974[0m[0m | time: 2.227s
[2K
| Adam | epoch: 018 | loss: 0.43974 - acc: 0.8143 -- iter: 064/323
[A[ATraining Step: 190  | total loss: [1m[32m0.43678[0m[0m | time: 3.589s
[2K
| Adam | epoch: 018 | loss: 0.43678 - acc: 0.8141 -- iter: 096/323
[A[ATraining Step: 191  | total loss: [1m[32m0.43045[0m[0m | time: 3.801s
[2K
| Adam | epoch: 018 | loss: 0.43045 - acc: 0.8140 -- iter: 128/323
[A[ATraining Step: 192  | total loss: [1m[32m0.44177[0m[0m | time: 3.955s
[2K
| Adam | epoch: 018 | loss: 0.44177 - acc: 0.7992 -- iter: 160/323
[A[ATraining Step: 193  | total loss: [1m[32m0.42716[0m[0m | time: 4.965s
[2K
| Adam | epoch: 018 | loss: 0.42716 - acc: 0.8193 -- iter: 192/323
[A[ATraining Step: 194  | total loss: [1m[32m0.43225[0m[0m | time: 5.709s
[2K
| Adam | epoch: 018 | loss: 0.43225 - acc: 0.8124 -- iter: 224/323
[A[ATraining Step: 195  | total loss: [1m[32m0.44288[0m[0m | time: 6.695s
[2K
| Adam | epoch: 018 | loss: 0.44288 - acc: 0.7999 -- iter: 256/323
[A[ATraining Step: 196  | total loss: [1m[32m0.43697[0m[0m | time: 7.771s
[2K
| Adam | epoch: 018 | loss: 0.43697 - acc: 0.7980 -- iter: 288/323
[A[ATraining Step: 197  | total loss: [1m[32m0.42363[0m[0m | time: 8.914s
[2K
| Adam | epoch: 018 | loss: 0.42363 - acc: 0.8088 -- iter: 320/323
[A[ATraining Step: 198  | total loss: [1m[32m0.41904[0m[0m | time: 11.107s
[2K
| Adam | epoch: 018 | loss: 0.41904 - acc: 0.8123 | val_loss: 0.47815 - val_acc: 0.7723 -- iter: 323/323
--
Training Step: 199  | total loss: [1m[32m0.42129[0m[0m | time: 1.113s
[2K
| Adam | epoch: 019 | loss: 0.42129 - acc: 0.8092 -- iter: 032/323
[A[ATraining Step: 200  | total loss: [1m[32m0.41124[0m[0m | time: 3.175s
[2K
| Adam | epoch: 019 | loss: 0.41124 - acc: 0.8158 | val_loss: 0.44054 - val_acc: 0.7921 -- iter: 064/323
--
Training Step: 201  | total loss: [1m[32m0.40880[0m[0m | time: 4.316s
[2K
| Adam | epoch: 019 | loss: 0.40880 - acc: 0.8123 -- iter: 096/323
[A[ATraining Step: 202  | total loss: [1m[32m0.41125[0m[0m | time: 5.450s
[2K
| Adam | epoch: 019 | loss: 0.41125 - acc: 0.8124 -- iter: 128/323
[A[ATraining Step: 203  | total loss: [1m[32m0.40399[0m[0m | time: 5.550s
[2K
| Adam | epoch: 019 | loss: 0.40399 - acc: 0.8155 -- iter: 160/323
[A[ATraining Step: 204  | total loss: [1m[32m0.38977[0m[0m | time: 5.655s
[2K
| Adam | epoch: 019 | loss: 0.38977 - acc: 0.8340 -- iter: 192/323
[A[ATraining Step: 205  | total loss: [1m[32m0.36295[0m[0m | time: 6.637s
[2K
| Adam | epoch: 019 | loss: 0.36295 - acc: 0.8506 -- iter: 224/323
[A[ATraining Step: 206  | total loss: [1m[32m0.38182[0m[0m | time: 7.679s
[2K
| Adam | epoch: 019 | loss: 0.38182 - acc: 0.8374 -- iter: 256/323
[A[ATraining Step: 207  | total loss: [1m[32m0.40158[0m[0m | time: 8.710s
[2K
| Adam | epoch: 019 | loss: 0.40158 - acc: 0.8224 -- iter: 288/323
[A[ATraining Step: 208  | total loss: [1m[32m0.38894[0m[0m | time: 9.797s
[2K
| Adam | epoch: 019 | loss: 0.38894 - acc: 0.8277 -- iter: 320/323
[A[ATraining Step: 209  | total loss: [1m[32m0.37036[0m[0m | time: 12.025s
[2K
| Adam | epoch: 019 | loss: 0.37036 - acc: 0.8355 | val_loss: 0.62018 - val_acc: 0.7822 -- iter: 323/323
--
Training Step: 210  | total loss: [1m[32m0.39221[0m[0m | time: 1.035s
[2K
| Adam | epoch: 020 | loss: 0.39221 - acc: 0.8332 -- iter: 032/323
[A[ATraining Step: 211  | total loss: [1m[32m0.38222[0m[0m | time: 2.167s
[2K
| Adam | epoch: 020 | loss: 0.38222 - acc: 0.8374 -- iter: 064/323
[A[ATraining Step: 212  | total loss: [1m[32m0.36345[0m[0m | time: 3.355s
[2K
| Adam | epoch: 020 | loss: 0.36345 - acc: 0.8443 -- iter: 096/323
[A[ATraining Step: 213  | total loss: [1m[32m0.35512[0m[0m | time: 4.577s
[2K
| Adam | epoch: 020 | loss: 0.35512 - acc: 0.8473 -- iter: 128/323
[A[ATraining Step: 214  | total loss: [1m[32m0.36091[0m[0m | time: 5.486s
[2K
| Adam | epoch: 020 | loss: 0.36091 - acc: 0.8470 -- iter: 160/323
[A[ATraining Step: 215  | total loss: [1m[32m0.36143[0m[0m | time: 5.622s
[2K
| Adam | epoch: 020 | loss: 0.36143 - acc: 0.8467 -- iter: 192/323
[A[ATraining Step: 216  | total loss: [1m[32m0.36639[0m[0m | time: 5.737s
[2K
| Adam | epoch: 020 | loss: 0.36639 - acc: 0.8287 -- iter: 224/323
[A[ATraining Step: 217  | total loss: [1m[32m0.34828[0m[0m | time: 6.771s
[2K
| Adam | epoch: 020 | loss: 0.34828 - acc: 0.8458 -- iter: 256/323
[A[ATraining Step: 218  | total loss: [1m[32m0.33293[0m[0m | time: 7.856s
[2K
| Adam | epoch: 020 | loss: 0.33293 - acc: 0.8581 -- iter: 288/323
[A[ATraining Step: 219  | total loss: [1m[32m0.33178[0m[0m | time: 8.939s
[2K
| Adam | epoch: 020 | loss: 0.33178 - acc: 0.8567 -- iter: 320/323
[A[ATraining Step: 220  | total loss: [1m[32m0.33553[0m[0m | time: 11.011s
[2K
| Adam | epoch: 020 | loss: 0.33553 - acc: 0.8554 | val_loss: 0.43918 - val_acc: 0.8020 -- iter: 323/323
--
Training Step: 221  | total loss: [1m[32m0.31814[0m[0m | time: 1.189s
[2K
| Adam | epoch: 021 | loss: 0.31814 - acc: 0.8667 -- iter: 032/323
[A[ATraining Step: 222  | total loss: [1m[32m0.30587[0m[0m | time: 2.441s
[2K
| Adam | epoch: 021 | loss: 0.30587 - acc: 0.8707 -- iter: 064/323
[A[ATraining Step: 223  | total loss: [1m[32m0.30073[0m[0m | time: 3.683s
[2K
| Adam | epoch: 021 | loss: 0.30073 - acc: 0.8742 -- iter: 096/323
[A[ATraining Step: 224  | total loss: [1m[32m0.29602[0m[0m | time: 5.002s
[2K
| Adam | epoch: 021 | loss: 0.29602 - acc: 0.8774 -- iter: 128/323
[A[ATraining Step: 225  | total loss: [1m[32m0.31011[0m[0m | time: 6.201s
[2K
| Adam | epoch: 021 | loss: 0.31011 - acc: 0.8741 -- iter: 160/323
[A[ATraining Step: 226  | total loss: [1m[32m0.30063[0m[0m | time: 7.298s
[2K
| Adam | epoch: 021 | loss: 0.30063 - acc: 0.8773 -- iter: 192/323
[A[ATraining Step: 227  | total loss: [1m[32m0.29818[0m[0m | time: 7.387s
[2K
| Adam | epoch: 021 | loss: 0.29818 - acc: 0.8770 -- iter: 224/323
[A[ATraining Step: 228  | total loss: [1m[32m0.27963[0m[0m | time: 7.475s
[2K
| Adam | epoch: 021 | loss: 0.27963 - acc: 0.8893 -- iter: 256/323
[A[ATraining Step: 229  | total loss: [1m[32m0.25482[0m[0m | time: 8.366s
[2K
| Adam | epoch: 021 | loss: 0.25482 - acc: 0.9004 -- iter: 288/323
[A[ATraining Step: 230  | total loss: [1m[32m0.26435[0m[0m | time: 9.386s
[2K
| Adam | epoch: 021 | loss: 0.26435 - acc: 0.8916 -- iter: 320/323
[A[ATraining Step: 231  | total loss: [1m[32m0.28845[0m[0m | time: 11.578s
[2K
| Adam | epoch: 021 | loss: 0.28845 - acc: 0.8743 | val_loss: 0.39371 - val_acc: 0.8515 -- iter: 323/323
--
Training Step: 232  | total loss: [1m[32m0.28585[0m[0m | time: 1.157s
[2K
| Adam | epoch: 022 | loss: 0.28585 - acc: 0.8806 -- iter: 032/323
[A[ATraining Step: 233  | total loss: [1m[32m0.27052[0m[0m | time: 2.220s
[2K
| Adam | epoch: 022 | loss: 0.27052 - acc: 0.8895 -- iter: 064/323
[A[ATraining Step: 234  | total loss: [1m[32m0.28202[0m[0m | time: 3.409s
[2K
| Adam | epoch: 022 | loss: 0.28202 - acc: 0.8818 -- iter: 096/323
[A[ATraining Step: 235  | total loss: [1m[32m0.27069[0m[0m | time: 4.639s
[2K
| Adam | epoch: 022 | loss: 0.27069 - acc: 0.8873 -- iter: 128/323
[A[ATraining Step: 236  | total loss: [1m[32m0.26391[0m[0m | time: 5.757s
[2K
| Adam | epoch: 022 | loss: 0.26391 - acc: 0.8924 -- iter: 160/323
[A[ATraining Step: 237  | total loss: [1m[32m0.25901[0m[0m | time: 6.761s
[2K
| Adam | epoch: 022 | loss: 0.25901 - acc: 0.8937 -- iter: 192/323
[A[ATraining Step: 238  | total loss: [1m[32m0.24861[0m[0m | time: 7.865s
[2K
| Adam | epoch: 022 | loss: 0.24861 - acc: 0.8950 -- iter: 224/323
[A[ATraining Step: 239  | total loss: [1m[32m0.23452[0m[0m | time: 8.078s
[2K
| Adam | epoch: 022 | loss: 0.23452 - acc: 0.9024 -- iter: 256/323
[A[ATraining Step: 240  | total loss: [1m[32m0.21440[0m[0m | time: 8.225s
[2K
| Adam | epoch: 022 | loss: 0.21440 - acc: 0.9121 -- iter: 288/323
[A[ATraining Step: 241  | total loss: [1m[32m0.19546[0m[0m | time: 9.354s
[2K
| Adam | epoch: 022 | loss: 0.19546 - acc: 0.9209 -- iter: 320/323
[A[ATraining Step: 242  | total loss: [1m[32m0.18797[0m[0m | time: 11.459s
[2K
| Adam | epoch: 022 | loss: 0.18797 - acc: 0.9257 | val_loss: 0.42810 - val_acc: 0.8515 -- iter: 323/323
--
Training Step: 243  | total loss: [1m[32m0.18504[0m[0m | time: 1.003s
[2K
| Adam | epoch: 023 | loss: 0.18504 - acc: 0.9269 -- iter: 032/323
[A[ATraining Step: 244  | total loss: [1m[32m0.17316[0m[0m | time: 1.921s
[2K
| Adam | epoch: 023 | loss: 0.17316 - acc: 0.9342 -- iter: 064/323
[A[ATraining Step: 245  | total loss: [1m[32m0.16027[0m[0m | time: 2.946s
[2K
| Adam | epoch: 023 | loss: 0.16027 - acc: 0.9408 -- iter: 096/323
[A[ATraining Step: 246  | total loss: [1m[32m0.14756[0m[0m | time: 4.065s
[2K
| Adam | epoch: 023 | loss: 0.14756 - acc: 0.9467 -- iter: 128/323
[A[ATraining Step: 247  | total loss: [1m[32m0.13568[0m[0m | time: 5.303s
[2K
| Adam | epoch: 023 | loss: 0.13568 - acc: 0.9520 -- iter: 160/323
[A[ATraining Step: 248  | total loss: [1m[32m0.14217[0m[0m | time: 6.403s
[2K
| Adam | epoch: 023 | loss: 0.14217 - acc: 0.9474 -- iter: 192/323
[A[ATraining Step: 249  | total loss: [1m[32m0.13556[0m[0m | time: 7.440s
[2K
| Adam | epoch: 023 | loss: 0.13556 - acc: 0.9496 -- iter: 224/323
[A[ATraining Step: 250  | total loss: [1m[32m0.13939[0m[0m | time: 8.426s
[2K
| Adam | epoch: 023 | loss: 0.13939 - acc: 0.9484 -- iter: 256/323
[A[ATraining Step: 251  | total loss: [1m[32m0.13005[0m[0m | time: 8.559s
[2K
| Adam | epoch: 023 | loss: 0.13005 - acc: 0.9504 -- iter: 288/323
[A[ATraining Step: 252  | total loss: [1m[32m0.30144[0m[0m | time: 8.706s
[2K
| Adam | epoch: 023 | loss: 0.30144 - acc: 0.9220 -- iter: 320/323
[A[ATraining Step: 253  | total loss: [1m[32m0.31985[0m[0m | time: 10.736s
[2K
| Adam | epoch: 023 | loss: 0.31985 - acc: 0.8965 | val_loss: 0.59495 - val_acc: 0.7723 -- iter: 323/323
--
Training Step: 254  | total loss: [1m[32m0.31299[0m[0m | time: 1.097s
[2K
| Adam | epoch: 024 | loss: 0.31299 - acc: 0.8975 -- iter: 032/323
[A[ATraining Step: 255  | total loss: [1m[32m0.31325[0m[0m | time: 2.304s
[2K
| Adam | epoch: 024 | loss: 0.31325 - acc: 0.8984 -- iter: 064/323
[A[ATraining Step: 256  | total loss: [1m[32m0.33170[0m[0m | time: 3.540s
[2K
| Adam | epoch: 024 | loss: 0.33170 - acc: 0.8929 -- iter: 096/323
[A[ATraining Step: 257  | total loss: [1m[32m0.31549[0m[0m | time: 4.619s
[2K
| Adam | epoch: 024 | loss: 0.31549 - acc: 0.8911 -- iter: 128/323
[A[ATraining Step: 258  | total loss: [1m[32m0.29963[0m[0m | time: 5.686s
[2K
| Adam | epoch: 024 | loss: 0.29963 - acc: 0.8957 -- iter: 160/323
[A[ATraining Step: 259  | total loss: [1m[32m0.29160[0m[0m | time: 6.975s
[2K
| Adam | epoch: 024 | loss: 0.29160 - acc: 0.8968 -- iter: 192/323
[A[ATraining Step: 260  | total loss: [1m[32m0.27491[0m[0m | time: 8.202s
[2K
| Adam | epoch: 024 | loss: 0.27491 - acc: 0.9009 -- iter: 224/323
[A[ATraining Step: 261  | total loss: [1m[32m0.26791[0m[0m | time: 9.211s
[2K
| Adam | epoch: 024 | loss: 0.26791 - acc: 0.8983 -- iter: 256/323
[A[ATraining Step: 262  | total loss: [1m[32m0.25827[0m[0m | time: 10.295s
[2K
| Adam | epoch: 024 | loss: 0.25827 - acc: 0.9022 -- iter: 288/323
[A[ATraining Step: 263  | total loss: [1m[32m0.24641[0m[0m | time: 10.449s
[2K
| Adam | epoch: 024 | loss: 0.24641 - acc: 0.9089 -- iter: 320/323
[A[ATraining Step: 264  | total loss: [1m[32m0.22677[0m[0m | time: 11.578s
[2K
| Adam | epoch: 024 | loss: 0.22677 - acc: 0.9180 | val_loss: 0.43848 - val_acc: 0.8416 -- iter: 323/323
--
Training Step: 265  | total loss: [1m[32m0.20872[0m[0m | time: 1.138s
[2K
| Adam | epoch: 025 | loss: 0.20872 - acc: 0.9262 -- iter: 032/323
[A[ATraining Step: 266  | total loss: [1m[32m0.20619[0m[0m | time: 2.306s
[2K
| Adam | epoch: 025 | loss: 0.20619 - acc: 0.9273 -- iter: 064/323
[A[ATraining Step: 267  | total loss: [1m[32m0.19114[0m[0m | time: 3.435s
[2K
| Adam | epoch: 025 | loss: 0.19114 - acc: 0.9346 -- iter: 096/323
[A[ATraining Step: 268  | total loss: [1m[32m0.35259[0m[0m | time: 4.432s
[2K
| Adam | epoch: 025 | loss: 0.35259 - acc: 0.8974 -- iter: 128/323
[A[ATraining Step: 269  | total loss: [1m[32m0.32415[0m[0m | time: 5.501s
[2K
| Adam | epoch: 025 | loss: 0.32415 - acc: 0.9045 -- iter: 160/323
[A[ATraining Step: 270  | total loss: [1m[32m0.30203[0m[0m | time: 6.537s
[2K
| Adam | epoch: 025 | loss: 0.30203 - acc: 0.9141 -- iter: 192/323
[A[ATraining Step: 271  | total loss: [1m[32m0.28451[0m[0m | time: 7.813s
[2K
| Adam | epoch: 025 | loss: 0.28451 - acc: 0.9195 -- iter: 224/323
[A[ATraining Step: 272  | total loss: [1m[32m0.26032[0m[0m | time: 8.996s
[2K
| Adam | epoch: 025 | loss: 0.26032 - acc: 0.9276 -- iter: 256/323
[A[ATraining Step: 273  | total loss: [1m[32m0.23922[0m[0m | time: 10.045s
[2K
| Adam | epoch: 025 | loss: 0.23922 - acc: 0.9348 -- iter: 288/323
[A[ATraining Step: 274  | total loss: [1m[32m0.22394[0m[0m | time: 10.891s
[2K
| Adam | epoch: 025 | loss: 0.22394 - acc: 0.9382 -- iter: 320/323
[A[ATraining Step: 275  | total loss: [1m[32m0.21220[0m[0m | time: 12.016s
[2K
| Adam | epoch: 025 | loss: 0.21220 - acc: 0.9381 | val_loss: 0.45935 - val_acc: 0.8317 -- iter: 323/323
--
Training Step: 276  | total loss: [1m[32m0.19208[0m[0m | time: 0.167s
[2K
| Adam | epoch: 026 | loss: 0.19208 - acc: 0.9443 -- iter: 032/323
[A[ATraining Step: 277  | total loss: [1m[32m0.17367[0m[0m | time: 1.204s
[2K
| Adam | epoch: 026 | loss: 0.17367 - acc: 0.9499 -- iter: 064/323
[A[ATraining Step: 278  | total loss: [1m[32m0.16358[0m[0m | time: 2.314s
[2K
| Adam | epoch: 026 | loss: 0.16358 - acc: 0.9518 -- iter: 096/323
[A[ATraining Step: 279  | total loss: [1m[32m0.15710[0m[0m | time: 3.365s
[2K
| Adam | epoch: 026 | loss: 0.15710 - acc: 0.9535 -- iter: 128/323
[A[ATraining Step: 280  | total loss: [1m[32m0.15643[0m[0m | time: 4.430s
[2K
| Adam | epoch: 026 | loss: 0.15643 - acc: 0.9550 -- iter: 160/323
[A[ATraining Step: 281  | total loss: [1m[32m0.14381[0m[0m | time: 5.701s
[2K
| Adam | epoch: 026 | loss: 0.14381 - acc: 0.9595 -- iter: 192/323
[A[ATraining Step: 282  | total loss: [1m[32m0.13334[0m[0m | time: 6.779s
[2K
| Adam | epoch: 026 | loss: 0.13334 - acc: 0.9636 -- iter: 224/323
[A[ATraining Step: 283  | total loss: [1m[32m0.12408[0m[0m | time: 7.671s
[2K
| Adam | epoch: 026 | loss: 0.12408 - acc: 0.9641 -- iter: 256/323
[A[ATraining Step: 284  | total loss: [1m[32m0.11365[0m[0m | time: 8.724s
[2K
| Adam | epoch: 026 | loss: 0.11365 - acc: 0.9677 -- iter: 288/323
[A[ATraining Step: 285  | total loss: [1m[32m0.10646[0m[0m | time: 9.760s
[2K
| Adam | epoch: 026 | loss: 0.10646 - acc: 0.9709 -- iter: 320/323
[A[ATraining Step: 286  | total loss: [1m[32m0.09746[0m[0m | time: 11.747s
[2K
| Adam | epoch: 026 | loss: 0.09746 - acc: 0.9738 | val_loss: 0.62093 - val_acc: 0.8317 -- iter: 323/323
--
Training Step: 287  | total loss: [1m[32m0.09157[0m[0m | time: 0.138s
[2K
| Adam | epoch: 027 | loss: 0.09157 - acc: 0.9733 -- iter: 032/323
[A[ATraining Step: 288  | total loss: [1m[32m0.08433[0m[0m | time: 0.326s
[2K
| Adam | epoch: 027 | loss: 0.08433 - acc: 0.9760 -- iter: 064/323
[A[ATraining Step: 289  | total loss: [1m[32m0.07676[0m[0m | time: 1.373s
[2K
| Adam | epoch: 027 | loss: 0.07676 - acc: 0.9784 -- iter: 096/323
[A[ATraining Step: 290  | total loss: [1m[32m0.06988[0m[0m | time: 2.411s
[2K
| Adam | epoch: 027 | loss: 0.06988 - acc: 0.9805 -- iter: 128/323
[A[ATraining Step: 291  | total loss: [1m[32m0.10153[0m[0m | time: 3.542s
[2K
| Adam | epoch: 027 | loss: 0.10153 - acc: 0.9762 -- iter: 160/323
[A[ATraining Step: 292  | total loss: [1m[32m0.09389[0m[0m | time: 4.632s
[2K
| Adam | epoch: 027 | loss: 0.09389 - acc: 0.9786 -- iter: 192/323
[A[ATraining Step: 293  | total loss: [1m[32m0.08990[0m[0m | time: 5.766s
[2K
| Adam | epoch: 027 | loss: 0.08990 - acc: 0.9807 -- iter: 224/323
[A[ATraining Step: 294  | total loss: [1m[32m0.08291[0m[0m | time: 6.868s
[2K
| Adam | epoch: 027 | loss: 0.08291 - acc: 0.9827 -- iter: 256/323
[A[ATraining Step: 295  | total loss: [1m[32m0.08178[0m[0m | time: 7.945s
[2K
| Adam | epoch: 027 | loss: 0.08178 - acc: 0.9813 -- iter: 288/323
[A[ATraining Step: 296  | total loss: [1m[32m0.07392[0m[0m | time: 9.138s
[2K
| Adam | epoch: 027 | loss: 0.07392 - acc: 0.9832 -- iter: 320/323
[A[ATraining Step: 297  | total loss: [1m[32m0.07359[0m[0m | time: 11.366s
[2K
| Adam | epoch: 027 | loss: 0.07359 - acc: 0.9817 | val_loss: 0.71208 - val_acc: 0.8020 -- iter: 323/323
--
Training Step: 298  | total loss: [1m[32m0.06805[0m[0m | time: 1.111s
[2K
| Adam | epoch: 028 | loss: 0.06805 - acc: 0.9835 -- iter: 032/323
[A[ATraining Step: 299  | total loss: [1m[32m0.06541[0m[0m | time: 1.235s
[2K
| Adam | epoch: 028 | loss: 0.06541 - acc: 0.9821 -- iter: 064/323
[A[ATraining Step: 300  | total loss: [1m[32m0.05920[0m[0m | time: 1.381s
[2K
| Adam | epoch: 028 | loss: 0.05920 - acc: 0.9839 -- iter: 096/323
[A[ATraining Step: 301  | total loss: [1m[32m0.05345[0m[0m | time: 2.801s
[2K
| Adam | epoch: 028 | loss: 0.05345 - acc: 0.9855 -- iter: 128/323
[A[ATraining Step: 302  | total loss: [1m[32m0.05025[0m[0m | time: 3.722s
[2K
| Adam | epoch: 028 | loss: 0.05025 - acc: 0.9869 -- iter: 160/323
[A[ATraining Step: 303  | total loss: [1m[32m0.04633[0m[0m | time: 4.870s
[2K
| Adam | epoch: 028 | loss: 0.04633 - acc: 0.9882 -- iter: 192/323
[A[ATraining Step: 304  | total loss: [1m[32m0.04267[0m[0m | time: 5.998s
[2K
| Adam | epoch: 028 | loss: 0.04267 - acc: 0.9894 -- iter: 224/323
[A[ATraining Step: 305  | total loss: [1m[32m0.04164[0m[0m | time: 7.117s
[2K
| Adam | epoch: 028 | loss: 0.04164 - acc: 0.9873 -- iter: 256/323
[A[ATraining Step: 306  | total loss: [1m[32m0.03846[0m[0m | time: 8.249s
[2K
| Adam | epoch: 028 | loss: 0.03846 - acc: 0.9886 -- iter: 288/323
[A[ATraining Step: 307  | total loss: [1m[32m0.03766[0m[0m | time: 9.383s
[2K
| Adam | epoch: 028 | loss: 0.03766 - acc: 0.9897 -- iter: 320/323
[A[ATraining Step: 308  | total loss: [1m[32m0.05927[0m[0m | time: 11.453s
[2K
| Adam | epoch: 028 | loss: 0.05927 - acc: 0.9876 | val_loss: 0.69788 - val_acc: 0.8218 -- iter: 323/323
--
Training Step: 309  | total loss: [1m[32m0.05361[0m[0m | time: 1.015s
[2K
| Adam | epoch: 029 | loss: 0.05361 - acc: 0.9889 -- iter: 032/323
[A[ATraining Step: 310  | total loss: [1m[32m0.04860[0m[0m | time: 2.081s
[2K
| Adam | epoch: 029 | loss: 0.04860 - acc: 0.9900 -- iter: 064/323
[A[ATraining Step: 311  | total loss: [1m[32m0.04661[0m[0m | time: 2.199s
[2K
| Adam | epoch: 029 | loss: 0.04661 - acc: 0.9910 -- iter: 096/323
[A[ATraining Step: 312  | total loss: [1m[32m0.04227[0m[0m | time: 2.340s
[2K
| Adam | epoch: 029 | loss: 0.04227 - acc: 0.9919 -- iter: 128/323
[A[ATraining Step: 313  | total loss: [1m[32m0.03836[0m[0m | time: 3.402s
[2K
| Adam | epoch: 029 | loss: 0.03836 - acc: 0.9927 -- iter: 160/323
[A[ATraining Step: 314  | total loss: [1m[32m0.04318[0m[0m | time: 4.494s
[2K
| Adam | epoch: 029 | loss: 0.04318 - acc: 0.9903 -- iter: 192/323
[A[ATraining Step: 315  | total loss: [1m[32m0.04429[0m[0m | time: 5.561s
[2K
| Adam | epoch: 029 | loss: 0.04429 - acc: 0.9913 -- iter: 224/323
[A[ATraining Step: 316  | total loss: [1m[32m0.07119[0m[0m | time: 6.663s
[2K
| Adam | epoch: 029 | loss: 0.07119 - acc: 0.9859 -- iter: 256/323
[A[ATraining Step: 317  | total loss: [1m[32m0.06456[0m[0m | time: 7.714s
[2K
| Adam | epoch: 029 | loss: 0.06456 - acc: 0.9873 -- iter: 288/323
[A[ATraining Step: 318  | total loss: [1m[32m0.07979[0m[0m | time: 8.768s
[2K
| Adam | epoch: 029 | loss: 0.07979 - acc: 0.9855 -- iter: 320/323
[A[ATraining Step: 319  | total loss: [1m[32m0.07513[0m[0m | time: 10.905s
[2K
| Adam | epoch: 029 | loss: 0.07513 - acc: 0.9869 | val_loss: 0.53255 - val_acc: 0.8218 -- iter: 323/323
--
Training Step: 320  | total loss: [1m[32m0.07551[0m[0m | time: 0.731s
[2K
| Adam | epoch: 030 | loss: 0.07551 - acc: 0.9851 -- iter: 032/323
[A[ATraining Step: 321  | total loss: [1m[32m0.07003[0m[0m | time: 1.678s
[2K
| Adam | epoch: 030 | loss: 0.07003 - acc: 0.9866 -- iter: 064/323
[A[ATraining Step: 322  | total loss: [1m[32m0.06497[0m[0m | time: 2.753s
[2K
| Adam | epoch: 030 | loss: 0.06497 - acc: 0.9879 -- iter: 096/323
[A[ATraining Step: 323  | total loss: [1m[32m0.05923[0m[0m | time: 2.951s
[2K
| Adam | epoch: 030 | loss: 0.05923 - acc: 0.9891 -- iter: 128/323
[A[ATraining Step: 324  | total loss: [1m[32m0.05384[0m[0m | time: 3.098s
[2K
| Adam | epoch: 030 | loss: 0.05384 - acc: 0.9902 -- iter: 160/323
[A[ATraining Step: 325  | total loss: [1m[32m0.04886[0m[0m | time: 4.116s
[2K
| Adam | epoch: 030 | loss: 0.04886 - acc: 0.9912 -- iter: 192/323
[A[ATraining Step: 326  | total loss: [1m[32m0.04537[0m[0m | time: 5.137s
[2K
| Adam | epoch: 030 | loss: 0.04537 - acc: 0.9921 -- iter: 224/323
[A[ATraining Step: 327  | total loss: [1m[32m0.04548[0m[0m | time: 6.146s
[2K
| Adam | epoch: 030 | loss: 0.04548 - acc: 0.9929 -- iter: 256/323
[A[ATraining Step: 328  | total loss: [1m[32m0.04378[0m[0m | time: 7.244s
[2K
| Adam | epoch: 030 | loss: 0.04378 - acc: 0.9936 -- iter: 288/323
[A[ATraining Step: 329  | total loss: [1m[32m0.04865[0m[0m | time: 8.390s
[2K
| Adam | epoch: 030 | loss: 0.04865 - acc: 0.9911 -- iter: 320/323
[A[ATraining Step: 330  | total loss: [1m[32m0.04503[0m[0m | time: 10.387s
[2K
| Adam | epoch: 030 | loss: 0.04503 - acc: 0.9920 | val_loss: 0.51237 - val_acc: 0.8416 -- iter: 323/323
--
Validation AUC:0.9123015873015873
Validation AUPRC:0.9208765551202298
Test AUC:0.8508420208500401
Test AUPRC:0.8722841064253783
BestTestF1Score	0.82	0.55	0.78	0.77	0.88	51	15	28	7	0.44
BestTestMCCScore	0.82	0.55	0.78	0.77	0.88	51	15	28	7	0.44
BestTestAccuracyScore	0.82	0.55	0.78	0.77	0.88	51	15	28	7	0.44
BestValidationF1Score	0.88	0.72	0.86	0.84	0.93	52	10	35	4	0.44
BestValidationMCC	0.88	0.72	0.86	0.84	0.93	52	10	35	4	0.44
BestValidationAccuracy	0.88	0.72	0.86	0.84	0.93	52	10	35	4	0.44
TestPredictions (Threshold:0.44)
CHEMBL160222,TN,INACT,0.0	CHEMBL416819,TP,ACT,1.0	CHEMBL1795951,FP,INACT,0.9399999976158142	CHEMBL47989,TP,ACT,0.9900000095367432	CHEMBL1095726,TP,ACT,0.9900000095367432	CHEMBL1672294,TN,INACT,0.009999999776482582	CHEMBL187065,TN,INACT,0.019999999552965164	CHEMBL1096490,FP,INACT,1.0	CHEMBL2062528,TP,ACT,1.0	CHEMBL560991,TP,ACT,0.9900000095367432	CHEMBL362416,TP,ACT,0.9700000286102295	CHEMBL86333,TP,ACT,0.9900000095367432	CHEMBL158551,TN,INACT,0.0	CHEMBL1095106,TP,ACT,0.9900000095367432	CHEMBL160131,TN,INACT,0.0	CHEMBL160261,TN,INACT,0.0	CHEMBL301254,FN,ACT,0.009999999776482582	CHEMBL1795945,TN,INACT,0.009999999776482582	CHEMBL200331,TN,INACT,0.03999999910593033	CHEMBL1517389,FP,INACT,0.9800000190734863	CHEMBL3219193,TN,INACT,0.009999999776482582	CHEMBL1452440,FP,INACT,0.9700000286102295	CHEMBL348408,TN,INACT,0.0	CHEMBL1258522,TN,INACT,0.4399999976158142	CHEMBL2207337,TP,ACT,1.0	CHEMBL2062708,FP,INACT,0.9800000190734863	CHEMBL1823759,TP,ACT,1.0	CHEMBL3219594,TP,ACT,0.9800000190734863	CHEMBL1491991,FP,INACT,0.9900000095367432	CHEMBL1988133,FP,INACT,0.5699999928474426	CHEMBL340653,TP,ACT,1.0	CHEMBL158819,TN,INACT,0.0	CHEMBL562693,TP,ACT,0.9900000095367432	CHEMBL182673,TP,ACT,0.9900000095367432	CHEMBL1098533,TP,ACT,1.0	CHEMBL55934,TP,ACT,0.9700000286102295	CHEMBL527658,TP,ACT,0.6499999761581421	CHEMBL3219182,FN,ACT,0.009999999776482582	CHEMBL1795950,TP,ACT,0.9700000286102295	CHEMBL2436032,TP,ACT,1.0	CHEMBL1481974,FN,ACT,0.33000001311302185	CHEMBL489987,FP,INACT,1.0	CHEMBL2111995,TN,INACT,0.009999999776482582	CHEMBL66953,TN,INACT,0.07999999821186066	CHEMBL337520,TP,ACT,1.0	CHEMBL559679,TP,ACT,0.9800000190734863	CHEMBL1971015,FP,INACT,0.9900000095367432	CHEMBL1823760,TP,ACT,1.0	CHEMBL1095854,TP,ACT,1.0	CHEMBL202197,FN,ACT,0.019999999552965164	CHEMBL158314,FP,INACT,1.0	CHEMBL61058,TN,INACT,0.009999999776482582	CHEMBL1098806,TP,ACT,1.0	CHEMBL1527941,TN,INACT,0.029999999329447746	CHEMBL44064,TP,ACT,1.0	CHEMBL2207335,TP,ACT,0.8500000238418579	CHEMBL346125,TN,INACT,0.0	CHEMBL1094563,TP,ACT,1.0	CHEMBL508233,TP,ACT,0.9399999976158142	CHEMBL345842,TN,INACT,0.0	CHEMBL3426987,FN,ACT,0.009999999776482582	CHEMBL476648,TP,ACT,0.9800000190734863	CHEMBL2206729,FP,INACT,0.800000011920929	CHEMBL1258414,TN,INACT,0.11999999731779099	CHEMBL1099220,TP,ACT,1.0	CHEMBL3219587,TP,ACT,1.0	CHEMBL1334510,FP,INACT,0.9800000190734863	CHEMBL314778,TP,ACT,0.9900000095367432	CHEMBL181815,FN,ACT,0.4000000059604645	CHEMBL1371777,TN,INACT,0.18000000715255737	CHEMBL320558,TN,INACT,0.009999999776482582	CHEMBL345395,TN,INACT,0.0	CHEMBL110983,FP,INACT,0.9800000190734863	CHEMBL131199,TP,ACT,0.9800000190734863	CHEMBL1098476,TP,ACT,1.0	CHEMBL109990,TP,ACT,1.0	CHEMBL3426984,TP,ACT,1.0	CHEMBL6246,FP,INACT,0.8500000238418579	CHEMBL3219591,TP,ACT,1.0	CHEMBL87763,TP,ACT,0.9900000095367432	CHEMBL155756,TN,INACT,0.009999999776482582	CHEMBL1401522,TP,ACT,0.7900000214576721	CHEMBL332036,TP,ACT,1.0	CHEMBL556292,TP,ACT,1.0	CHEMBL448099,TP,ACT,1.0	CHEMBL550189,TP,ACT,0.9900000095367432	CHEMBL562949,TP,ACT,0.949999988079071	CHEMBL61909,TN,INACT,0.4399999976158142	CHEMBL1823959,TP,ACT,1.0	CHEMBL549785,FN,ACT,0.009999999776482582	CHEMBL2206742,TP,ACT,0.9900000095367432	CHEMBL160557,TN,INACT,0.0	CHEMBL3427124,TP,ACT,0.9100000262260437	CHEMBL3356396,TN,INACT,0.009999999776482582	CHEMBL552334,TP,ACT,0.9900000095367432	CHEMBL351345,TN,INACT,0.0	CHEMBL1370674,FP,INACT,0.7400000095367432	CHEMBL181800,TP,ACT,1.0	CHEMBL1097552,TP,ACT,1.0	CHEMBL159202,TN,INACT,0.029999999329447746	CHEMBL561936,TP,ACT,1.0	

