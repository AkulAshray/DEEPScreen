ImageNetInceptionV2 CHEMBL2331 adam 0.0001 30 0 0 0.8 False True
Number of active compounds :	109
Number of inactive compounds :	100
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL2331_adam_0.0001_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL2331_adam_0.0001_30_0.8/
---------------------------------
Training samples: 130
Validation samples: 41
--
Training Step: 1  | time: 149.715s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/130
[A[ATraining Step: 2  | total loss: [1m[32m0.67359[0m[0m | time: 278.219s
[2K
| Adam | epoch: 001 | loss: 0.67359 - acc: 0.3937 -- iter: 064/130
[A[ATraining Step: 3  | total loss: [1m[32m0.64911[0m[0m | time: 347.888s
[2K
| Adam | epoch: 001 | loss: 0.64911 - acc: 0.5574 -- iter: 096/130
[A[ATraining Step: 4  | total loss: [1m[32m0.61476[0m[0m | time: 481.103s
[2K
| Adam | epoch: 001 | loss: 0.61476 - acc: 0.6784 -- iter: 128/130
[A[ATraining Step: 5  | total loss: [1m[32m0.56120[0m[0m | time: 490.555s
[2K
| Adam | epoch: 001 | loss: 0.56120 - acc: 0.7712 | val_loss: 0.71677 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 6  | total loss: [1m[32m0.47326[0m[0m | time: 1.429s
[2K
| Adam | epoch: 002 | loss: 0.47326 - acc: 0.9183 -- iter: 032/130
[A[ATraining Step: 7  | total loss: [1m[32m0.29597[0m[0m | time: 55.157s
[2K
| Adam | epoch: 002 | loss: 0.29597 - acc: 0.9673 -- iter: 064/130
[A[ATraining Step: 8  | total loss: [1m[32m0.45567[0m[0m | time: 146.938s
[2K
| Adam | epoch: 002 | loss: 0.45567 - acc: 0.8275 -- iter: 096/130
[A[ATraining Step: 9  | total loss: [1m[32m0.45302[0m[0m | time: 280.337s
[2K
| Adam | epoch: 002 | loss: 0.45302 - acc: 0.8030 -- iter: 128/130
[A[ATraining Step: 10  | total loss: [1m[32m0.41896[0m[0m | time: 325.024s
[2K
| Adam | epoch: 002 | loss: 0.41896 - acc: 0.8390 | val_loss: 0.69588 - val_acc: 0.5854 -- iter: 130/130
--
Training Step: 11  | total loss: [1m[32m0.35806[0m[0m | time: 1.467s
[2K
| Adam | epoch: 003 | loss: 0.35806 - acc: 0.8857 -- iter: 032/130
[A[ATraining Step: 12  | total loss: [1m[32m0.42044[0m[0m | time: 2.829s
[2K
| Adam | epoch: 003 | loss: 0.42044 - acc: 0.9371 -- iter: 064/130
[A[ATraining Step: 13  | total loss: [1m[32m0.31577[0m[0m | time: 77.676s
[2K
| Adam | epoch: 003 | loss: 0.31577 - acc: 0.9641 -- iter: 096/130
[A[ATraining Step: 14  | total loss: [1m[32m0.37370[0m[0m | time: 142.424s
[2K
| Adam | epoch: 003 | loss: 0.37370 - acc: 0.8765 -- iter: 128/130
[A[ATraining Step: 15  | total loss: [1m[32m0.39261[0m[0m | time: 271.252s
[2K
| Adam | epoch: 003 | loss: 0.39261 - acc: 0.8637 | val_loss: 0.90981 - val_acc: 0.4146 -- iter: 130/130
--
Training Step: 16  | total loss: [1m[32m0.33745[0m[0m | time: 12.470s
[2K
| Adam | epoch: 004 | loss: 0.33745 - acc: 0.8796 -- iter: 032/130
[A[ATraining Step: 17  | total loss: [1m[32m0.28544[0m[0m | time: 14.253s
[2K
| Adam | epoch: 004 | loss: 0.28544 - acc: 0.9117 -- iter: 064/130
[A[ATraining Step: 18  | total loss: [1m[32m0.50319[0m[0m | time: 16.073s
[2K
| Adam | epoch: 004 | loss: 0.50319 - acc: 0.5961 -- iter: 096/130
[A[ATraining Step: 19  | total loss: [1m[32m0.57681[0m[0m | time: 33.132s
[2K
| Adam | epoch: 004 | loss: 0.57681 - acc: 0.5641 -- iter: 128/130
[A[ATraining Step: 20  | total loss: [1m[32m0.48266[0m[0m | time: 58.822s
[2K
| Adam | epoch: 004 | loss: 0.48266 - acc: 0.6841 | val_loss: 1.26654 - val_acc: 0.4146 -- iter: 130/130
--
Training Step: 21  | total loss: [1m[32m0.38956[0m[0m | time: 13.289s
[2K
| Adam | epoch: 005 | loss: 0.38956 - acc: 0.7724 -- iter: 032/130
[A[ATraining Step: 22  | total loss: [1m[32m0.32971[0m[0m | time: 26.756s
[2K
| Adam | epoch: 005 | loss: 0.32971 - acc: 0.8313 -- iter: 064/130
[A[ATraining Step: 23  | total loss: [1m[32m0.28857[0m[0m | time: 28.473s
[2K
| Adam | epoch: 005 | loss: 0.28857 - acc: 0.8622 -- iter: 096/130
[A[ATraining Step: 24  | total loss: [1m[32m0.24836[0m[0m | time: 30.271s
[2K
| Adam | epoch: 005 | loss: 0.24836 - acc: 0.9009 -- iter: 128/130
[A[ATraining Step: 25  | total loss: [1m[32m0.18823[0m[0m | time: 46.372s
[2K
| Adam | epoch: 005 | loss: 0.18823 - acc: 0.9279 | val_loss: 1.37633 - val_acc: 0.4146 -- iter: 130/130
--
Training Step: 26  | total loss: [1m[32m0.16876[0m[0m | time: 12.944s
[2K
| Adam | epoch: 006 | loss: 0.16876 - acc: 0.9387 -- iter: 032/130
[A[ATraining Step: 27  | total loss: [1m[32m0.15224[0m[0m | time: 25.727s
[2K
| Adam | epoch: 006 | loss: 0.15224 - acc: 0.9465 -- iter: 064/130
[A[ATraining Step: 28  | total loss: [1m[32m0.20276[0m[0m | time: 39.561s
[2K
| Adam | epoch: 006 | loss: 0.20276 - acc: 0.9442 -- iter: 096/130
[A[ATraining Step: 29  | total loss: [1m[32m0.17115[0m[0m | time: 41.350s
[2K
| Adam | epoch: 006 | loss: 0.17115 - acc: 0.9578 -- iter: 128/130
[A[ATraining Step: 30  | total loss: [1m[32m0.30745[0m[0m | time: 45.908s
[2K
| Adam | epoch: 006 | loss: 0.30745 - acc: 0.7309 | val_loss: 1.20211 - val_acc: 0.4146 -- iter: 130/130
--
Training Step: 31  | total loss: [1m[32m0.39503[0m[0m | time: 12.024s
[2K
| Adam | epoch: 007 | loss: 0.39503 - acc: 0.6776 -- iter: 032/130
[A[ATraining Step: 32  | total loss: [1m[32m0.32845[0m[0m | time: 24.458s
[2K
| Adam | epoch: 007 | loss: 0.32845 - acc: 0.7431 -- iter: 064/130
[A[ATraining Step: 33  | total loss: [1m[32m0.28661[0m[0m | time: 36.917s
[2K
| Adam | epoch: 007 | loss: 0.28661 - acc: 0.7858 -- iter: 096/130
[A[ATraining Step: 34  | total loss: [1m[32m0.23956[0m[0m | time: 48.980s
[2K
| Adam | epoch: 007 | loss: 0.23956 - acc: 0.8250 -- iter: 128/130
[A[ATraining Step: 35  | total loss: [1m[32m0.19883[0m[0m | time: 53.643s
[2K
| Adam | epoch: 007 | loss: 0.19883 - acc: 0.8616 | val_loss: 1.28233 - val_acc: 0.4146 -- iter: 130/130
--
Training Step: 36  | total loss: [1m[32m0.29067[0m[0m | time: 1.817s
[2K
| Adam | epoch: 008 | loss: 0.29067 - acc: 0.7877 -- iter: 032/130
[A[ATraining Step: 37  | total loss: [1m[32m0.36475[0m[0m | time: 14.527s
[2K
| Adam | epoch: 008 | loss: 0.36475 - acc: 0.7301 -- iter: 064/130
[A[ATraining Step: 38  | total loss: [1m[32m0.30864[0m[0m | time: 31.351s
[2K
| Adam | epoch: 008 | loss: 0.30864 - acc: 0.7768 -- iter: 096/130
[A[ATraining Step: 39  | total loss: [1m[32m0.26542[0m[0m | time: 43.855s
[2K
| Adam | epoch: 008 | loss: 0.26542 - acc: 0.8196 -- iter: 128/130
[A[ATraining Step: 40  | total loss: [1m[32m0.29075[0m[0m | time: 61.954s
[2K
| Adam | epoch: 008 | loss: 0.29075 - acc: 0.8417 | val_loss: 1.11785 - val_acc: 0.4146 -- iter: 130/130
--
Training Step: 41  | total loss: [1m[32m0.24500[0m[0m | time: 1.709s
[2K
| Adam | epoch: 009 | loss: 0.24500 - acc: 0.8708 -- iter: 032/130
[A[ATraining Step: 42  | total loss: [1m[32m0.20415[0m[0m | time: 3.426s
[2K
| Adam | epoch: 009 | loss: 0.20415 - acc: 0.8940 -- iter: 064/130
[A[ATraining Step: 43  | total loss: [1m[32m0.17009[0m[0m | time: 15.294s
[2K
| Adam | epoch: 009 | loss: 0.17009 - acc: 0.9127 -- iter: 096/130
[A[ATraining Step: 44  | total loss: [1m[32m0.14552[0m[0m | time: 27.663s
[2K
| Adam | epoch: 009 | loss: 0.14552 - acc: 0.9278 -- iter: 128/130
[A[ATraining Step: 45  | total loss: [1m[32m0.15375[0m[0m | time: 44.007s
[2K
| Adam | epoch: 009 | loss: 0.15375 - acc: 0.9295 | val_loss: 0.79545 - val_acc: 0.3902 -- iter: 130/130
--
Training Step: 46  | total loss: [1m[32m0.15472[0m[0m | time: 11.897s
[2K
| Adam | epoch: 010 | loss: 0.15472 - acc: 0.9360 -- iter: 032/130
[A[ATraining Step: 47  | total loss: [1m[32m0.13775[0m[0m | time: 13.621s
[2K
| Adam | epoch: 010 | loss: 0.13775 - acc: 0.9465 -- iter: 064/130
[A[ATraining Step: 48  | total loss: [1m[32m0.11671[0m[0m | time: 15.272s
[2K
| Adam | epoch: 010 | loss: 0.11671 - acc: 0.9551 -- iter: 096/130
[A[ATraining Step: 49  | total loss: [1m[32m0.09895[0m[0m | time: 27.878s
[2K
| Adam | epoch: 010 | loss: 0.09895 - acc: 0.9622 -- iter: 128/130
[A[ATraining Step: 50  | total loss: [1m[32m0.10310[0m[0m | time: 43.162s
[2K
| Adam | epoch: 010 | loss: 0.10310 - acc: 0.9632 | val_loss: 0.77911 - val_acc: 0.3902 -- iter: 130/130
--
Training Step: 51  | total loss: [1m[32m0.10674[0m[0m | time: 12.508s
[2K
| Adam | epoch: 011 | loss: 0.10674 - acc: 0.9593 -- iter: 032/130
[A[ATraining Step: 52  | total loss: [1m[32m0.10435[0m[0m | time: 25.340s
[2K
| Adam | epoch: 011 | loss: 0.10435 - acc: 0.9607 -- iter: 064/130
[A[ATraining Step: 53  | total loss: [1m[32m0.11148[0m[0m | time: 27.035s
[2K
| Adam | epoch: 011 | loss: 0.11148 - acc: 0.9619 -- iter: 096/130
[A[ATraining Step: 54  | total loss: [1m[32m0.09617[0m[0m | time: 28.701s
[2K
| Adam | epoch: 011 | loss: 0.09617 - acc: 0.9674 -- iter: 128/130
[A[ATraining Step: 55  | total loss: [1m[32m0.08312[0m[0m | time: 44.473s
[2K
| Adam | epoch: 011 | loss: 0.08312 - acc: 0.9721 | val_loss: 0.62573 - val_acc: 0.7073 -- iter: 130/130
--
Training Step: 56  | total loss: [1m[32m0.08094[0m[0m | time: 12.335s
[2K
| Adam | epoch: 012 | loss: 0.08094 - acc: 0.9716 -- iter: 032/130
[A[ATraining Step: 57  | total loss: [1m[32m0.07670[0m[0m | time: 24.936s
[2K
| Adam | epoch: 012 | loss: 0.07670 - acc: 0.9712 -- iter: 064/130
[A[ATraining Step: 58  | total loss: [1m[32m0.08682[0m[0m | time: 37.172s
[2K
| Adam | epoch: 012 | loss: 0.08682 - acc: 0.9709 -- iter: 096/130
[A[ATraining Step: 59  | total loss: [1m[32m0.07633[0m[0m | time: 38.805s
[2K
| Adam | epoch: 012 | loss: 0.07633 - acc: 0.9748 -- iter: 128/130
[A[ATraining Step: 60  | total loss: [1m[32m0.14290[0m[0m | time: 44.097s
[2K
| Adam | epoch: 012 | loss: 0.14290 - acc: 0.9119 | val_loss: 0.48254 - val_acc: 0.7805 -- iter: 130/130
--
Training Step: 61  | total loss: [1m[32m0.26500[0m[0m | time: 9.652s
[2K
| Adam | epoch: 013 | loss: 0.26500 - acc: 0.8582 -- iter: 032/130
[A[ATraining Step: 62  | total loss: [1m[32m0.23811[0m[0m | time: 19.381s
[2K
| Adam | epoch: 013 | loss: 0.23811 - acc: 0.8724 -- iter: 064/130
[A[ATraining Step: 63  | total loss: [1m[32m0.21396[0m[0m | time: 29.339s
[2K
| Adam | epoch: 013 | loss: 0.21396 - acc: 0.8846 -- iter: 096/130
[A[ATraining Step: 64  | total loss: [1m[32m0.21635[0m[0m | time: 38.936s
[2K
| Adam | epoch: 013 | loss: 0.21635 - acc: 0.8912 -- iter: 128/130
[A[ATraining Step: 65  | total loss: [1m[32m0.20732[0m[0m | time: 42.368s
[2K
| Adam | epoch: 013 | loss: 0.20732 - acc: 0.9008 | val_loss: 0.78820 - val_acc: 0.6585 -- iter: 130/130
--
Training Step: 66  | total loss: [1m[32m0.18370[0m[0m | time: 1.286s
[2K
| Adam | epoch: 014 | loss: 0.18370 - acc: 0.9129 -- iter: 032/130
[A[ATraining Step: 67  | total loss: [1m[32m0.16238[0m[0m | time: 11.010s
[2K
| Adam | epoch: 014 | loss: 0.16238 - acc: 0.9233 -- iter: 064/130
[A[ATraining Step: 68  | total loss: [1m[32m0.17379[0m[0m | time: 20.749s
[2K
| Adam | epoch: 014 | loss: 0.17379 - acc: 0.9213 -- iter: 096/130
[A[ATraining Step: 69  | total loss: [1m[32m0.15863[0m[0m | time: 30.584s
[2K
| Adam | epoch: 014 | loss: 0.15863 - acc: 0.9305 -- iter: 128/130
[A[ATraining Step: 70  | total loss: [1m[32m0.19150[0m[0m | time: 42.639s
[2K
| Adam | epoch: 014 | loss: 0.19150 - acc: 0.9277 | val_loss: 0.55617 - val_acc: 0.7561 -- iter: 130/130
--
Training Step: 71  | total loss: [1m[32m0.17542[0m[0m | time: 1.331s
[2K
| Adam | epoch: 015 | loss: 0.17542 - acc: 0.9324 -- iter: 032/130
[A[ATraining Step: 72  | total loss: [1m[32m0.23195[0m[0m | time: 2.589s
[2K
| Adam | epoch: 015 | loss: 0.23195 - acc: 0.8837 -- iter: 064/130
[A[ATraining Step: 73  | total loss: [1m[32m0.29231[0m[0m | time: 12.310s
[2K
| Adam | epoch: 015 | loss: 0.29231 - acc: 0.8411 -- iter: 096/130
[A[ATraining Step: 74  | total loss: [1m[32m0.26313[0m[0m | time: 22.187s
[2K
| Adam | epoch: 015 | loss: 0.26313 - acc: 0.8585 -- iter: 128/130
[A[ATraining Step: 75  | total loss: [1m[32m0.24231[0m[0m | time: 33.956s
[2K
| Adam | epoch: 015 | loss: 0.24231 - acc: 0.8739 | val_loss: 0.67253 - val_acc: 0.7805 -- iter: 130/130
--
Training Step: 76  | total loss: [1m[32m0.21915[0m[0m | time: 9.772s
[2K
| Adam | epoch: 016 | loss: 0.21915 - acc: 0.8874 -- iter: 032/130
[A[ATraining Step: 77  | total loss: [1m[32m0.20084[0m[0m | time: 11.020s
[2K
| Adam | epoch: 016 | loss: 0.20084 - acc: 0.8993 -- iter: 064/130
[A[ATraining Step: 78  | total loss: [1m[32m0.18273[0m[0m | time: 12.235s
[2K
| Adam | epoch: 016 | loss: 0.18273 - acc: 0.9099 -- iter: 096/130
[A[ATraining Step: 79  | total loss: [1m[32m0.16447[0m[0m | time: 24.035s
[2K
| Adam | epoch: 016 | loss: 0.16447 - acc: 0.9192 -- iter: 128/130
[A[ATraining Step: 80  | total loss: [1m[32m0.15105[0m[0m | time: 39.655s
[2K
| Adam | epoch: 016 | loss: 0.15105 - acc: 0.9274 | val_loss: 0.45072 - val_acc: 0.8293 -- iter: 130/130
--
Training Step: 81  | total loss: [1m[32m0.13881[0m[0m | time: 16.798s
[2K
| Adam | epoch: 017 | loss: 0.13881 - acc: 0.9348 -- iter: 032/130
[A[ATraining Step: 82  | total loss: [1m[32m0.14656[0m[0m | time: 34.681s
[2K
| Adam | epoch: 017 | loss: 0.14656 - acc: 0.9382 -- iter: 064/130
[A[ATraining Step: 83  | total loss: [1m[32m0.13295[0m[0m | time: 36.389s
[2K
| Adam | epoch: 017 | loss: 0.13295 - acc: 0.9444 -- iter: 096/130
[A[ATraining Step: 84  | total loss: [1m[32m0.17965[0m[0m | time: 37.964s
[2K
| Adam | epoch: 017 | loss: 0.17965 - acc: 0.9499 -- iter: 128/130
[A[ATraining Step: 85  | total loss: [1m[32m0.21541[0m[0m | time: 52.841s
[2K
| Adam | epoch: 017 | loss: 0.21541 - acc: 0.9049 | val_loss: 0.48497 - val_acc: 0.8293 -- iter: 130/130
--
Training Step: 86  | total loss: [1m[32m0.19656[0m[0m | time: 15.565s
[2K
| Adam | epoch: 018 | loss: 0.19656 - acc: 0.9144 -- iter: 032/130
[A[ATraining Step: 87  | total loss: [1m[32m0.18881[0m[0m | time: 43.582s
[2K
| Adam | epoch: 018 | loss: 0.18881 - acc: 0.9199 -- iter: 064/130
[A[ATraining Step: 88  | total loss: [1m[32m0.17704[0m[0m | time: 81.779s
[2K
| Adam | epoch: 018 | loss: 0.17704 - acc: 0.9279 -- iter: 096/130
[A[ATraining Step: 89  | total loss: [1m[32m0.16167[0m[0m | time: 84.010s
[2K
| Adam | epoch: 018 | loss: 0.16167 - acc: 0.9351 -- iter: 128/130
[A[ATraining Step: 90  | total loss: [1m[32m0.14611[0m[0m | time: 89.899s
[2K
| Adam | epoch: 018 | loss: 0.14611 - acc: 0.9416 | val_loss: 1.34912 - val_acc: 0.6585 -- iter: 130/130
--
Training Step: 91  | total loss: [1m[32m0.13206[0m[0m | time: 46.767s
[2K
| Adam | epoch: 019 | loss: 0.13206 - acc: 0.9474 -- iter: 032/130
[A[ATraining Step: 92  | total loss: [1m[32m0.12001[0m[0m | time: 154.746s
[2K
| Adam | epoch: 019 | loss: 0.12001 - acc: 0.9527 -- iter: 064/130
[A[ATraining Step: 93  | total loss: [1m[32m0.11132[0m[0m | time: 187.523s
[2K
| Adam | epoch: 019 | loss: 0.11132 - acc: 0.9543 -- iter: 096/130
[A[ATraining Step: 94  | total loss: [1m[32m0.10163[0m[0m | time: 215.221s
[2K
| Adam | epoch: 019 | loss: 0.10163 - acc: 0.9589 -- iter: 128/130
[A[ATraining Step: 95  | total loss: [1m[32m0.09358[0m[0m | time: 220.826s
[2K
| Adam | epoch: 019 | loss: 0.09358 - acc: 0.9630 | val_loss: 1.07751 - val_acc: 0.7317 -- iter: 130/130
--
Training Step: 96  | total loss: [1m[32m0.08511[0m[0m | time: 1.957s
[2K
| Adam | epoch: 020 | loss: 0.08511 - acc: 0.9667 -- iter: 032/130
[A[ATraining Step: 97  | total loss: [1m[32m0.07752[0m[0m | time: 42.697s
[2K
| Adam | epoch: 020 | loss: 0.07752 - acc: 0.9700 -- iter: 064/130
[A[ATraining Step: 98  | total loss: [1m[32m0.07104[0m[0m | time: 81.666s
[2K
| Adam | epoch: 020 | loss: 0.07104 - acc: 0.9730 -- iter: 096/130
[A[ATraining Step: 99  | total loss: [1m[32m0.06498[0m[0m | time: 96.791s
[2K
| Adam | epoch: 020 | loss: 0.06498 - acc: 0.9757 -- iter: 128/130
[A[ATraining Step: 100  | total loss: [1m[32m0.05920[0m[0m | time: 160.109s
[2K
| Adam | epoch: 020 | loss: 0.05920 - acc: 0.9781 | val_loss: 0.87535 - val_acc: 0.8049 -- iter: 130/130
--
Training Step: 101  | total loss: [1m[32m0.05388[0m[0m | time: 1.786s
[2K
| Adam | epoch: 021 | loss: 0.05388 - acc: 0.9803 -- iter: 032/130
[A[ATraining Step: 102  | total loss: [1m[32m0.09089[0m[0m | time: 3.852s
[2K
| Adam | epoch: 021 | loss: 0.09089 - acc: 0.9323 -- iter: 064/130
[A[ATraining Step: 103  | total loss: [1m[32m0.20881[0m[0m | time: 82.405s
[2K
| Adam | epoch: 021 | loss: 0.20881 - acc: 0.8891 -- iter: 096/130
[A[ATraining Step: 104  | total loss: [1m[32m0.18906[0m[0m | time: 101.365s
[2K
| Adam | epoch: 021 | loss: 0.18906 - acc: 0.9002 -- iter: 128/130
[A[ATraining Step: 105  | total loss: [1m[32m0.17138[0m[0m | time: 188.003s
[2K
| Adam | epoch: 021 | loss: 0.17138 - acc: 0.9101 | val_loss: 0.59085 - val_acc: 0.8293 -- iter: 130/130
--
Training Step: 106  | total loss: [1m[32m0.15534[0m[0m | time: 65.423s
[2K
| Adam | epoch: 022 | loss: 0.15534 - acc: 0.9191 -- iter: 032/130
[A[ATraining Step: 107  | total loss: [1m[32m0.14036[0m[0m | time: 67.285s
[2K
| Adam | epoch: 022 | loss: 0.14036 - acc: 0.9272 -- iter: 064/130
[A[ATraining Step: 108  | total loss: [1m[32m0.15850[0m[0m | time: 69.274s
[2K
| Adam | epoch: 022 | loss: 0.15850 - acc: 0.9345 -- iter: 096/130
[A[ATraining Step: 109  | total loss: [1m[32m0.26821[0m[0m | time: 109.555s
[2K
| Adam | epoch: 022 | loss: 0.26821 - acc: 0.8910 -- iter: 128/130
[A[ATraining Step: 110  | total loss: [1m[32m0.24183[0m[0m | time: 188.376s
[2K
| Adam | epoch: 022 | loss: 0.24183 - acc: 0.9019 | val_loss: 0.57685 - val_acc: 0.8537 -- iter: 130/130
--
Training Step: 111  | total loss: [1m[32m0.21791[0m[0m | time: 24.018s
[2K
| Adam | epoch: 023 | loss: 0.21791 - acc: 0.9117 -- iter: 032/130
[A[ATraining Step: 112  | total loss: [1m[32m0.19664[0m[0m | time: 60.279s
[2K
| Adam | epoch: 023 | loss: 0.19664 - acc: 0.9206 -- iter: 064/130
[A[ATraining Step: 113  | total loss: [1m[32m0.17737[0m[0m | time: 62.198s
[2K
| Adam | epoch: 023 | loss: 0.17737 - acc: 0.9285 -- iter: 096/130
[A[ATraining Step: 114  | total loss: [1m[32m0.16084[0m[0m | time: 64.132s
[2K
| Adam | epoch: 023 | loss: 0.16084 - acc: 0.9357 -- iter: 128/130
[A[ATraining Step: 115  | total loss: [1m[32m0.14518[0m[0m | time: 121.707s
[2K
| Adam | epoch: 023 | loss: 0.14518 - acc: 0.9421 | val_loss: 0.51253 - val_acc: 0.8537 -- iter: 130/130
--
Training Step: 116  | total loss: [1m[32m0.13107[0m[0m | time: 14.100s
[2K
| Adam | epoch: 024 | loss: 0.13107 - acc: 0.9479 -- iter: 032/130
[A[ATraining Step: 117  | total loss: [1m[32m0.11853[0m[0m | time: 76.759s
[2K
| Adam | epoch: 024 | loss: 0.11853 - acc: 0.9531 -- iter: 064/130
[A[ATraining Step: 118  | total loss: [1m[32m0.12759[0m[0m | time: 89.995s
[2K
| Adam | epoch: 024 | loss: 0.12759 - acc: 0.9547 -- iter: 096/130
[A[ATraining Step: 119  | total loss: [1m[32m0.11509[0m[0m | time: 91.954s
[2K
| Adam | epoch: 024 | loss: 0.11509 - acc: 0.9592 -- iter: 128/130
[A[ATraining Step: 120  | total loss: [1m[32m0.28622[0m[0m | time: 96.868s
[2K
| Adam | epoch: 024 | loss: 0.28622 - acc: 0.9133 | val_loss: 1.44072 - val_acc: 0.7073 -- iter: 130/130
--
Training Step: 121  | total loss: [1m[32m0.45648[0m[0m | time: 43.378s
[2K
| Adam | epoch: 025 | loss: 0.45648 - acc: 0.8719 -- iter: 032/130
[A[ATraining Step: 122  | total loss: [1m[32m0.41157[0m[0m | time: 80.661s
[2K
| Adam | epoch: 025 | loss: 0.41157 - acc: 0.8848 -- iter: 064/130
[A[ATraining Step: 123  | total loss: [1m[32m0.38820[0m[0m | time: 147.206s
[2K
| Adam | epoch: 025 | loss: 0.38820 - acc: 0.8932 -- iter: 096/130
[A[ATraining Step: 124  | total loss: [1m[32m0.35096[0m[0m | time: 186.700s
[2K
| Adam | epoch: 025 | loss: 0.35096 - acc: 0.9038 -- iter: 128/130
[A[ATraining Step: 125  | total loss: [1m[32m0.31663[0m[0m | time: 191.803s
[2K
| Adam | epoch: 025 | loss: 0.31663 - acc: 0.9135 | val_loss: 0.99689 - val_acc: 0.7561 -- iter: 130/130
--
Training Step: 126  | total loss: [1m[32m0.31855[0m[0m | time: 1.905s
[2K
| Adam | epoch: 026 | loss: 0.31855 - acc: 0.9221 -- iter: 032/130
[A[ATraining Step: 127  | total loss: [1m[32m0.39656[0m[0m | time: 16.279s
[2K
| Adam | epoch: 026 | loss: 0.39656 - acc: 0.8799 -- iter: 064/130
[A[ATraining Step: 128  | total loss: [1m[32m0.36027[0m[0m | time: 29.267s
[2K
| Adam | epoch: 026 | loss: 0.36027 - acc: 0.8919 -- iter: 096/130
[A[ATraining Step: 129  | total loss: [1m[32m0.33203[0m[0m | time: 43.619s
[2K
| Adam | epoch: 026 | loss: 0.33203 - acc: 0.8996 -- iter: 128/130
[A[ATraining Step: 130  | total loss: [1m[32m0.31676[0m[0m | time: 61.636s
[2K
| Adam | epoch: 026 | loss: 0.31676 - acc: 0.9065 | val_loss: 0.50277 - val_acc: 0.8049 -- iter: 130/130
--
Training Step: 131  | total loss: [1m[32m0.28557[0m[0m | time: 2.301s
[2K
| Adam | epoch: 027 | loss: 0.28557 - acc: 0.9159 -- iter: 032/130
[A[ATraining Step: 132  | total loss: [1m[32m0.43411[0m[0m | time: 4.469s
[2K
| Adam | epoch: 027 | loss: 0.43411 - acc: 0.8743 -- iter: 064/130
[A[ATraining Step: 133  | total loss: [1m[32m0.60421[0m[0m | time: 17.864s
[2K
| Adam | epoch: 027 | loss: 0.60421 - acc: 0.8368 -- iter: 096/130
[A[ATraining Step: 134  | total loss: [1m[32m0.54522[0m[0m | time: 31.517s
[2K
| Adam | epoch: 027 | loss: 0.54522 - acc: 0.8532 -- iter: 128/130
[A[ATraining Step: 135  | total loss: [1m[32m0.49495[0m[0m | time: 48.521s
[2K
| Adam | epoch: 027 | loss: 0.49495 - acc: 0.8647 | val_loss: 0.71125 - val_acc: 0.7561 -- iter: 130/130
--
Training Step: 136  | total loss: [1m[32m0.78337[0m[0m | time: 13.542s
[2K
| Adam | epoch: 028 | loss: 0.78337 - acc: 0.8220 -- iter: 032/130
[A[ATraining Step: 137  | total loss: [1m[32m0.70773[0m[0m | time: 15.424s
[2K
| Adam | epoch: 028 | loss: 0.70773 - acc: 0.8398 -- iter: 064/130
[A[ATraining Step: 138  | total loss: [1m[32m0.64395[0m[0m | time: 17.211s
[2K
| Adam | epoch: 028 | loss: 0.64395 - acc: 0.8558 -- iter: 096/130
[A[ATraining Step: 139  | total loss: [1m[32m0.58050[0m[0m | time: 30.537s
[2K
| Adam | epoch: 028 | loss: 0.58050 - acc: 0.8702 -- iter: 128/130
[A[ATraining Step: 140  | total loss: [1m[32m0.52636[0m[0m | time: 47.421s
[2K
| Adam | epoch: 028 | loss: 0.52636 - acc: 0.8832 | val_loss: 0.54489 - val_acc: 0.8293 -- iter: 130/130
--
Training Step: 141  | total loss: [1m[32m0.47920[0m[0m | time: 14.097s
[2K
| Adam | epoch: 029 | loss: 0.47920 - acc: 0.8918 -- iter: 032/130
[A[ATraining Step: 142  | total loss: [1m[32m0.61009[0m[0m | time: 27.334s
[2K
| Adam | epoch: 029 | loss: 0.61009 - acc: 0.8588 -- iter: 064/130
[A[ATraining Step: 143  | total loss: [1m[32m0.55215[0m[0m | time: 29.212s
[2K
| Adam | epoch: 029 | loss: 0.55215 - acc: 0.8730 -- iter: 096/130
[A[ATraining Step: 144  | total loss: [1m[32m0.49881[0m[0m | time: 31.043s
[2K
| Adam | epoch: 029 | loss: 0.49881 - acc: 0.8857 -- iter: 128/130
[A[ATraining Step: 145  | total loss: [1m[32m0.45018[0m[0m | time: 48.566s
[2K
| Adam | epoch: 029 | loss: 0.45018 - acc: 0.8971 | val_loss: 0.68447 - val_acc: 0.7805 -- iter: 130/130
--
Training Step: 146  | total loss: [1m[32m0.41480[0m[0m | time: 13.543s
[2K
| Adam | epoch: 030 | loss: 0.41480 - acc: 0.9074 -- iter: 032/130
[A[ATraining Step: 147  | total loss: [1m[32m0.38585[0m[0m | time: 27.260s
[2K
| Adam | epoch: 030 | loss: 0.38585 - acc: 0.9135 -- iter: 064/130
[A[ATraining Step: 148  | total loss: [1m[32m0.35375[0m[0m | time: 41.749s
[2K
| Adam | epoch: 030 | loss: 0.35375 - acc: 0.9190 -- iter: 096/130
[A[ATraining Step: 149  | total loss: [1m[32m0.32353[0m[0m | time: 43.640s
[2K
| Adam | epoch: 030 | loss: 0.32353 - acc: 0.9271 -- iter: 128/130
[A[ATraining Step: 150  | total loss: [1m[32m0.29244[0m[0m | time: 48.768s
[2K
| Adam | epoch: 030 | loss: 0.29244 - acc: 0.9344 | val_loss: 1.75611 - val_acc: 0.5854 -- iter: 130/130
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8455882352941176
Validation AUPRC:0.8605762410425722
Test AUC:0.7475490196078431
Test AUPRC:0.6309326393124568
BestTestF1Score	0.7	0.43	0.66	0.55	0.94	16	13	11	1	0.99
BestTestMCCScore	0.68	0.43	0.71	0.62	0.76	13	8	16	4	1.0
BestTestAccuracyScore	0.68	0.43	0.71	0.62	0.76	13	8	16	4	1.0
BestValidationF1Score	0.81	0.5	0.76	0.73	0.92	22	8	9	2	0.99
BestValidationMCC	0.81	0.55	0.78	0.83	0.79	19	4	13	5	1.0
BestValidationAccuracy	0.81	0.55	0.78	0.83	0.79	19	4	13	5	1.0
TestPredictions (Threshold:1.0)
CHEMBL3228396,TN,INACT,0.9599999785423279	CHEMBL27954,FP,INACT,1.0	CHEMBL135959,TP,ACT,1.0	CHEMBL541538,TP,ACT,1.0	CHEMBL3228405,TN,INACT,0.949999988079071	CHEMBL350571,TN,INACT,0.8899999856948853	CHEMBL18718,TP,ACT,1.0	CHEMBL294079,TP,ACT,1.0	CHEMBL116945,TN,INACT,0.9900000095367432	CHEMBL25316,FP,INACT,1.0	CHEMBL413311,FP,INACT,1.0	CHEMBL57966,TP,ACT,1.0	CHEMBL99215,FP,INACT,1.0	CHEMBL273939,FP,INACT,1.0	CHEMBL3350780,TN,INACT,0.9900000095367432	CHEMBL59994,FP,INACT,1.0	CHEMBL293023,FP,INACT,1.0	CHEMBL318333,TP,ACT,1.0	CHEMBL308021,TN,INACT,0.9800000190734863	CHEMBL48888,FN,ACT,0.9900000095367432	CHEMBL441679,TP,ACT,1.0	CHEMBL136361,TP,ACT,1.0	CHEMBL288524,TN,INACT,0.8600000143051147	CHEMBL137286,TP,ACT,1.0	CHEMBL19428,TN,INACT,0.9700000286102295	CHEMBL22726,TN,INACT,0.9300000071525574	CHEMBL112357,TN,INACT,0.9900000095367432	CHEMBL39125,TP,ACT,1.0	CHEMBL60724,TN,INACT,0.9900000095367432	CHEMBL19000,TN,INACT,0.9800000190734863	CHEMBL212026,TN,INACT,0.9700000286102295	CHEMBL3228346,TN,INACT,0.9800000190734863	CHEMBL275870,FN,ACT,0.9900000095367432	CHEMBL136304,TP,ACT,1.0	CHEMBL18921,FN,ACT,0.9900000095367432	CHEMBL281289,TP,ACT,1.0	CHEMBL120975,FN,ACT,0.9800000190734863	CHEMBL26640,FP,INACT,1.0	CHEMBL19683,TN,INACT,0.9800000190734863	CHEMBL287837,TP,ACT,1.0	CHEMBL278921,TN,INACT,0.9900000095367432	

