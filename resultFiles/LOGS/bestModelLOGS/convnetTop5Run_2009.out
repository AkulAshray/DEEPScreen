CNNModel CHEMBL4633 adam 0.001 15 256 0 0.8 False True
Number of active compounds :	357
Number of inactive compounds :	344
---------------------------------
Run id: CNNModel_CHEMBL4633_adam_0.001_15_256_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4633_adam_0.001_15_256_0.8_True/
---------------------------------
Training samples: 424
Validation samples: 133
--
Training Step: 1  | time: 1.450s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/424
[A[ATraining Step: 2  | total loss: [1m[32m0.62374[0m[0m | time: 2.448s
[2K
| Adam | epoch: 001 | loss: 0.62374 - acc: 0.4781 -- iter: 064/424
[A[ATraining Step: 3  | total loss: [1m[32m0.68222[0m[0m | time: 3.625s
[2K
| Adam | epoch: 001 | loss: 0.68222 - acc: 0.4193 -- iter: 096/424
[A[ATraining Step: 4  | total loss: [1m[32m0.68872[0m[0m | time: 4.719s
[2K
| Adam | epoch: 001 | loss: 0.68872 - acc: 0.5267 -- iter: 128/424
[A[ATraining Step: 5  | total loss: [1m[32m0.70466[0m[0m | time: 5.581s
[2K
| Adam | epoch: 001 | loss: 0.70466 - acc: 0.4217 -- iter: 160/424
[A[ATraining Step: 6  | total loss: [1m[32m0.69186[0m[0m | time: 6.520s
[2K
| Adam | epoch: 001 | loss: 0.69186 - acc: 0.5926 -- iter: 192/424
[A[ATraining Step: 7  | total loss: [1m[32m0.69409[0m[0m | time: 7.475s
[2K
| Adam | epoch: 001 | loss: 0.69409 - acc: 0.4995 -- iter: 224/424
[A[ATraining Step: 8  | total loss: [1m[32m0.69458[0m[0m | time: 8.433s
[2K
| Adam | epoch: 001 | loss: 0.69458 - acc: 0.4822 -- iter: 256/424
[A[ATraining Step: 9  | total loss: [1m[32m0.69407[0m[0m | time: 9.357s
[2K
| Adam | epoch: 001 | loss: 0.69407 - acc: 0.4751 -- iter: 288/424
[A[ATraining Step: 10  | total loss: [1m[32m0.69422[0m[0m | time: 10.392s
[2K
| Adam | epoch: 001 | loss: 0.69422 - acc: 0.4563 -- iter: 320/424
[A[ATraining Step: 11  | total loss: [1m[32m0.69373[0m[0m | time: 11.471s
[2K
| Adam | epoch: 001 | loss: 0.69373 - acc: 0.4622 -- iter: 352/424
[A[ATraining Step: 12  | total loss: [1m[32m0.69348[0m[0m | time: 12.576s
[2K
| Adam | epoch: 001 | loss: 0.69348 - acc: 0.4651 -- iter: 384/424
[A[ATraining Step: 13  | total loss: [1m[32m0.69326[0m[0m | time: 13.645s
[2K
| Adam | epoch: 001 | loss: 0.69326 - acc: 0.5069 -- iter: 416/424
[A[ATraining Step: 14  | total loss: [1m[32m0.69287[0m[0m | time: 15.036s
[2K
| Adam | epoch: 001 | loss: 0.69287 - acc: 0.5296 | val_loss: 0.69319 - val_acc: 0.4962 -- iter: 424/424
--
Training Step: 15  | total loss: [1m[32m0.69291[0m[0m | time: 0.340s
[2K
| Adam | epoch: 002 | loss: 0.69291 - acc: 0.5180 -- iter: 032/424
[A[ATraining Step: 16  | total loss: [1m[32m0.69277[0m[0m | time: 1.238s
[2K
| Adam | epoch: 002 | loss: 0.69277 - acc: 0.5113 -- iter: 064/424
[A[ATraining Step: 17  | total loss: [1m[32m0.69348[0m[0m | time: 2.125s
[2K
| Adam | epoch: 002 | loss: 0.69348 - acc: 0.4960 -- iter: 096/424
[A[ATraining Step: 18  | total loss: [1m[32m0.69280[0m[0m | time: 3.119s
[2K
| Adam | epoch: 002 | loss: 0.69280 - acc: 0.5082 -- iter: 128/424
[A[ATraining Step: 19  | total loss: [1m[32m0.69332[0m[0m | time: 4.252s
[2K
| Adam | epoch: 002 | loss: 0.69332 - acc: 0.4950 -- iter: 160/424
[A[ATraining Step: 20  | total loss: [1m[32m0.69274[0m[0m | time: 5.188s
[2K
| Adam | epoch: 002 | loss: 0.69274 - acc: 0.4966 -- iter: 192/424
[A[ATraining Step: 21  | total loss: [1m[32m0.69296[0m[0m | time: 6.032s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.4880 -- iter: 224/424
[A[ATraining Step: 22  | total loss: [1m[32m0.69560[0m[0m | time: 7.022s
[2K
| Adam | epoch: 002 | loss: 0.69560 - acc: 0.4260 -- iter: 256/424
[A[ATraining Step: 23  | total loss: [1m[32m0.69449[0m[0m | time: 8.019s
[2K
| Adam | epoch: 002 | loss: 0.69449 - acc: 0.4384 -- iter: 288/424
[A[ATraining Step: 24  | total loss: [1m[32m0.69298[0m[0m | time: 9.055s
[2K
| Adam | epoch: 002 | loss: 0.69298 - acc: 0.4645 -- iter: 320/424
[A[ATraining Step: 25  | total loss: [1m[32m0.69018[0m[0m | time: 10.022s
[2K
| Adam | epoch: 002 | loss: 0.69018 - acc: 0.5083 -- iter: 352/424
[A[ATraining Step: 26  | total loss: [1m[32m0.68829[0m[0m | time: 11.052s
[2K
| Adam | epoch: 002 | loss: 0.68829 - acc: 0.5226 -- iter: 384/424
[A[ATraining Step: 27  | total loss: [1m[32m0.68486[0m[0m | time: 12.099s
[2K
| Adam | epoch: 002 | loss: 0.68486 - acc: 0.5409 -- iter: 416/424
[A[ATraining Step: 28  | total loss: [1m[32m0.67941[0m[0m | time: 14.196s
[2K
| Adam | epoch: 002 | loss: 0.67941 - acc: 0.5541 | val_loss: 0.69004 - val_acc: 0.4962 -- iter: 424/424
--
Training Step: 29  | total loss: [1m[32m0.68258[0m[0m | time: 0.335s
[2K
| Adam | epoch: 003 | loss: 0.68258 - acc: 0.5410 -- iter: 032/424
[A[ATraining Step: 30  | total loss: [1m[32m0.66593[0m[0m | time: 0.574s
[2K
| Adam | epoch: 003 | loss: 0.66593 - acc: 0.5609 -- iter: 064/424
[A[ATraining Step: 31  | total loss: [1m[32m0.64817[0m[0m | time: 1.565s
[2K
| Adam | epoch: 003 | loss: 0.64817 - acc: 0.5757 -- iter: 096/424
[A[ATraining Step: 32  | total loss: [1m[32m0.64759[0m[0m | time: 2.532s
[2K
| Adam | epoch: 003 | loss: 0.64759 - acc: 0.5727 -- iter: 128/424
[A[ATraining Step: 33  | total loss: [1m[32m0.65982[0m[0m | time: 3.506s
[2K
| Adam | epoch: 003 | loss: 0.65982 - acc: 0.5567 -- iter: 160/424
[A[ATraining Step: 34  | total loss: [1m[32m0.65566[0m[0m | time: 4.538s
[2K
| Adam | epoch: 003 | loss: 0.65566 - acc: 0.5245 -- iter: 192/424
[A[ATraining Step: 35  | total loss: [1m[32m0.65527[0m[0m | time: 5.553s
[2K
| Adam | epoch: 003 | loss: 0.65527 - acc: 0.5652 -- iter: 224/424
[A[ATraining Step: 36  | total loss: [1m[32m0.65563[0m[0m | time: 6.610s
[2K
| Adam | epoch: 003 | loss: 0.65563 - acc: 0.6030 -- iter: 256/424
[A[ATraining Step: 37  | total loss: [1m[32m0.64434[0m[0m | time: 7.678s
[2K
| Adam | epoch: 003 | loss: 0.64434 - acc: 0.6199 -- iter: 288/424
[A[ATraining Step: 38  | total loss: [1m[32m0.62804[0m[0m | time: 8.628s
[2K
| Adam | epoch: 003 | loss: 0.62804 - acc: 0.6148 -- iter: 320/424
[A[ATraining Step: 39  | total loss: [1m[32m0.63042[0m[0m | time: 9.875s
[2K
| Adam | epoch: 003 | loss: 0.63042 - acc: 0.6048 -- iter: 352/424
[A[ATraining Step: 40  | total loss: [1m[32m0.62125[0m[0m | time: 10.946s
[2K
| Adam | epoch: 003 | loss: 0.62125 - acc: 0.5793 -- iter: 384/424
[A[ATraining Step: 41  | total loss: [1m[32m0.60900[0m[0m | time: 12.587s
[2K
| Adam | epoch: 003 | loss: 0.60900 - acc: 0.5934 -- iter: 416/424
[A[ATraining Step: 42  | total loss: [1m[32m0.60450[0m[0m | time: 14.335s
[2K
| Adam | epoch: 003 | loss: 0.60450 - acc: 0.6047 | val_loss: 0.59026 - val_acc: 0.7068 -- iter: 424/424
--
Training Step: 43  | total loss: [1m[32m0.60135[0m[0m | time: 0.855s
[2K
| Adam | epoch: 004 | loss: 0.60135 - acc: 0.6303 -- iter: 032/424
[A[ATraining Step: 44  | total loss: [1m[32m0.61052[0m[0m | time: 1.131s
[2K
| Adam | epoch: 004 | loss: 0.61052 - acc: 0.6132 -- iter: 064/424
[A[ATraining Step: 45  | total loss: [1m[32m0.59985[0m[0m | time: 1.396s
[2K
| Adam | epoch: 004 | loss: 0.59985 - acc: 0.6577 -- iter: 096/424
[A[ATraining Step: 46  | total loss: [1m[32m0.58745[0m[0m | time: 2.303s
[2K
| Adam | epoch: 004 | loss: 0.58745 - acc: 0.6939 -- iter: 128/424
[A[ATraining Step: 47  | total loss: [1m[32m0.59013[0m[0m | time: 3.246s
[2K
| Adam | epoch: 004 | loss: 0.59013 - acc: 0.6826 -- iter: 160/424
[A[ATraining Step: 48  | total loss: [1m[32m0.58194[0m[0m | time: 4.053s
[2K
| Adam | epoch: 004 | loss: 0.58194 - acc: 0.6934 -- iter: 192/424
[A[ATraining Step: 49  | total loss: [1m[32m0.57498[0m[0m | time: 4.989s
[2K
| Adam | epoch: 004 | loss: 0.57498 - acc: 0.6974 -- iter: 224/424
[A[ATraining Step: 50  | total loss: [1m[32m0.57583[0m[0m | time: 5.986s
[2K
| Adam | epoch: 004 | loss: 0.57583 - acc: 0.6910 -- iter: 256/424
[A[ATraining Step: 51  | total loss: [1m[32m0.57166[0m[0m | time: 6.946s
[2K
| Adam | epoch: 004 | loss: 0.57166 - acc: 0.6905 -- iter: 288/424
[A[ATraining Step: 52  | total loss: [1m[32m0.55849[0m[0m | time: 7.647s
[2K
| Adam | epoch: 004 | loss: 0.55849 - acc: 0.7041 -- iter: 320/424
[A[ATraining Step: 53  | total loss: [1m[32m0.54368[0m[0m | time: 8.519s
[2K
| Adam | epoch: 004 | loss: 0.54368 - acc: 0.7155 -- iter: 352/424
[A[ATraining Step: 54  | total loss: [1m[32m0.53729[0m[0m | time: 9.381s
[2K
| Adam | epoch: 004 | loss: 0.53729 - acc: 0.7160 -- iter: 384/424
[A[ATraining Step: 55  | total loss: [1m[32m0.54629[0m[0m | time: 10.222s
[2K
| Adam | epoch: 004 | loss: 0.54629 - acc: 0.7030 -- iter: 416/424
[A[ATraining Step: 56  | total loss: [1m[32m0.54351[0m[0m | time: 12.054s
[2K
| Adam | epoch: 004 | loss: 0.54351 - acc: 0.7008 | val_loss: 0.51652 - val_acc: 0.6992 -- iter: 424/424
--
Training Step: 57  | total loss: [1m[32m0.54210[0m[0m | time: 0.918s
[2K
| Adam | epoch: 005 | loss: 0.54210 - acc: 0.6946 -- iter: 032/424
[A[ATraining Step: 58  | total loss: [1m[32m0.53500[0m[0m | time: 1.721s
[2K
| Adam | epoch: 005 | loss: 0.53500 - acc: 0.6937 -- iter: 064/424
[A[ATraining Step: 59  | total loss: [1m[32m0.55525[0m[0m | time: 2.029s
[2K
| Adam | epoch: 005 | loss: 0.55525 - acc: 0.6802 -- iter: 096/424
[A[ATraining Step: 60  | total loss: [1m[32m0.56289[0m[0m | time: 2.310s
[2K
| Adam | epoch: 005 | loss: 0.56289 - acc: 0.6564 -- iter: 128/424
[A[ATraining Step: 61  | total loss: [1m[32m0.55378[0m[0m | time: 3.301s
[2K
| Adam | epoch: 005 | loss: 0.55378 - acc: 0.6849 -- iter: 160/424
[A[ATraining Step: 62  | total loss: [1m[32m0.55164[0m[0m | time: 4.280s
[2K
| Adam | epoch: 005 | loss: 0.55164 - acc: 0.6812 -- iter: 192/424
[A[ATraining Step: 63  | total loss: [1m[32m0.54579[0m[0m | time: 5.017s
[2K
| Adam | epoch: 005 | loss: 0.54579 - acc: 0.6860 -- iter: 224/424
[A[ATraining Step: 64  | total loss: [1m[32m0.55736[0m[0m | time: 5.825s
[2K
| Adam | epoch: 005 | loss: 0.55736 - acc: 0.6784 -- iter: 256/424
[A[ATraining Step: 65  | total loss: [1m[32m0.56022[0m[0m | time: 6.637s
[2K
| Adam | epoch: 005 | loss: 0.56022 - acc: 0.6795 -- iter: 288/424
[A[ATraining Step: 66  | total loss: [1m[32m0.56312[0m[0m | time: 7.466s
[2K
| Adam | epoch: 005 | loss: 0.56312 - acc: 0.6767 -- iter: 320/424
[A[ATraining Step: 67  | total loss: [1m[32m0.55943[0m[0m | time: 8.281s
[2K
| Adam | epoch: 005 | loss: 0.55943 - acc: 0.6817 -- iter: 352/424
[A[ATraining Step: 68  | total loss: [1m[32m0.56616[0m[0m | time: 9.103s
[2K
| Adam | epoch: 005 | loss: 0.56616 - acc: 0.6713 -- iter: 384/424
[A[ATraining Step: 69  | total loss: [1m[32m0.56882[0m[0m | time: 9.988s
[2K
| Adam | epoch: 005 | loss: 0.56882 - acc: 0.6622 -- iter: 416/424
[A[ATraining Step: 70  | total loss: [1m[32m0.55930[0m[0m | time: 11.902s
[2K
| Adam | epoch: 005 | loss: 0.55930 - acc: 0.6832 | val_loss: 0.51531 - val_acc: 0.7669 -- iter: 424/424
--
Training Step: 71  | total loss: [1m[32m0.54688[0m[0m | time: 0.998s
[2K
| Adam | epoch: 006 | loss: 0.54688 - acc: 0.7050 -- iter: 032/424
[A[ATraining Step: 72  | total loss: [1m[32m0.52514[0m[0m | time: 1.728s
[2K
| Adam | epoch: 006 | loss: 0.52514 - acc: 0.7241 -- iter: 064/424
[A[ATraining Step: 73  | total loss: [1m[32m0.53297[0m[0m | time: 2.560s
[2K
| Adam | epoch: 006 | loss: 0.53297 - acc: 0.7062 -- iter: 096/424
[A[ATraining Step: 74  | total loss: [1m[32m0.53226[0m[0m | time: 2.790s
[2K
| Adam | epoch: 006 | loss: 0.53226 - acc: 0.7110 -- iter: 128/424
[A[ATraining Step: 75  | total loss: [1m[32m0.53751[0m[0m | time: 3.073s
[2K
| Adam | epoch: 006 | loss: 0.53751 - acc: 0.7017 -- iter: 160/424
[A[ATraining Step: 76  | total loss: [1m[32m0.53747[0m[0m | time: 3.934s
[2K
| Adam | epoch: 006 | loss: 0.53747 - acc: 0.7202 -- iter: 192/424
[A[ATraining Step: 77  | total loss: [1m[32m0.52513[0m[0m | time: 4.795s
[2K
| Adam | epoch: 006 | loss: 0.52513 - acc: 0.7333 -- iter: 224/424
[A[ATraining Step: 78  | total loss: [1m[32m0.51814[0m[0m | time: 5.652s
[2K
| Adam | epoch: 006 | loss: 0.51814 - acc: 0.7416 -- iter: 256/424
[A[ATraining Step: 79  | total loss: [1m[32m0.52254[0m[0m | time: 6.535s
[2K
| Adam | epoch: 006 | loss: 0.52254 - acc: 0.7392 -- iter: 288/424
[A[ATraining Step: 80  | total loss: [1m[32m0.51794[0m[0m | time: 7.407s
[2K
| Adam | epoch: 006 | loss: 0.51794 - acc: 0.7435 -- iter: 320/424
[A[ATraining Step: 81  | total loss: [1m[32m0.50644[0m[0m | time: 8.250s
[2K
| Adam | epoch: 006 | loss: 0.50644 - acc: 0.7505 -- iter: 352/424
[A[ATraining Step: 82  | total loss: [1m[32m0.50325[0m[0m | time: 9.161s
[2K
| Adam | epoch: 006 | loss: 0.50325 - acc: 0.7505 -- iter: 384/424
[A[ATraining Step: 83  | total loss: [1m[32m0.50141[0m[0m | time: 10.103s
[2K
| Adam | epoch: 006 | loss: 0.50141 - acc: 0.7535 -- iter: 416/424
[A[ATraining Step: 84  | total loss: [1m[32m0.49994[0m[0m | time: 12.074s
[2K
| Adam | epoch: 006 | loss: 0.49994 - acc: 0.7532 | val_loss: 0.44862 - val_acc: 0.7594 -- iter: 424/424
--
Training Step: 85  | total loss: [1m[32m0.50928[0m[0m | time: 0.862s
[2K
| Adam | epoch: 007 | loss: 0.50928 - acc: 0.7372 -- iter: 032/424
[A[ATraining Step: 86  | total loss: [1m[32m0.49033[0m[0m | time: 1.690s
[2K
| Adam | epoch: 007 | loss: 0.49033 - acc: 0.7448 -- iter: 064/424
[A[ATraining Step: 87  | total loss: [1m[32m0.48392[0m[0m | time: 2.496s
[2K
| Adam | epoch: 007 | loss: 0.48392 - acc: 0.7453 -- iter: 096/424
[A[ATraining Step: 88  | total loss: [1m[32m0.50480[0m[0m | time: 3.388s
[2K
| Adam | epoch: 007 | loss: 0.50480 - acc: 0.7551 -- iter: 128/424
[A[ATraining Step: 89  | total loss: [1m[32m0.49815[0m[0m | time: 3.672s
[2K
| Adam | epoch: 007 | loss: 0.49815 - acc: 0.7546 -- iter: 160/424
[A[ATraining Step: 90  | total loss: [1m[32m0.52559[0m[0m | time: 3.931s
[2K
| Adam | epoch: 007 | loss: 0.52559 - acc: 0.7292 -- iter: 192/424
[A[ATraining Step: 91  | total loss: [1m[32m0.54259[0m[0m | time: 4.799s
[2K
| Adam | epoch: 007 | loss: 0.54259 - acc: 0.7062 -- iter: 224/424
[A[ATraining Step: 92  | total loss: [1m[32m0.52492[0m[0m | time: 5.705s
[2K
| Adam | epoch: 007 | loss: 0.52492 - acc: 0.7231 -- iter: 256/424
[A[ATraining Step: 93  | total loss: [1m[32m0.52198[0m[0m | time: 6.609s
[2K
| Adam | epoch: 007 | loss: 0.52198 - acc: 0.7133 -- iter: 288/424
[A[ATraining Step: 94  | total loss: [1m[32m0.51599[0m[0m | time: 7.601s
[2K
| Adam | epoch: 007 | loss: 0.51599 - acc: 0.7170 -- iter: 320/424
[A[ATraining Step: 95  | total loss: [1m[32m0.51189[0m[0m | time: 8.581s
[2K
| Adam | epoch: 007 | loss: 0.51189 - acc: 0.7234 -- iter: 352/424
[A[ATraining Step: 96  | total loss: [1m[32m0.50446[0m[0m | time: 9.311s
[2K
| Adam | epoch: 007 | loss: 0.50446 - acc: 0.7292 -- iter: 384/424
[A[ATraining Step: 97  | total loss: [1m[32m0.49477[0m[0m | time: 10.204s
[2K
| Adam | epoch: 007 | loss: 0.49477 - acc: 0.7500 -- iter: 416/424
[A[ATraining Step: 98  | total loss: [1m[32m0.48240[0m[0m | time: 12.089s
[2K
| Adam | epoch: 007 | loss: 0.48240 - acc: 0.7688 | val_loss: 0.45050 - val_acc: 0.7744 -- iter: 424/424
--
Training Step: 99  | total loss: [1m[32m0.47102[0m[0m | time: 0.896s
[2K
| Adam | epoch: 008 | loss: 0.47102 - acc: 0.7794 -- iter: 032/424
[A[ATraining Step: 100  | total loss: [1m[32m0.46584[0m[0m | time: 1.739s
[2K
| Adam | epoch: 008 | loss: 0.46584 - acc: 0.7890 -- iter: 064/424
[A[ATraining Step: 101  | total loss: [1m[32m0.47714[0m[0m | time: 2.541s
[2K
| Adam | epoch: 008 | loss: 0.47714 - acc: 0.7819 -- iter: 096/424
[A[ATraining Step: 102  | total loss: [1m[32m0.47709[0m[0m | time: 3.469s
[2K
| Adam | epoch: 008 | loss: 0.47709 - acc: 0.7850 -- iter: 128/424
[A[ATraining Step: 103  | total loss: [1m[32m0.47083[0m[0m | time: 4.442s
[2K
| Adam | epoch: 008 | loss: 0.47083 - acc: 0.7877 -- iter: 160/424
[A[ATraining Step: 104  | total loss: [1m[32m0.45721[0m[0m | time: 4.778s
[2K
| Adam | epoch: 008 | loss: 0.45721 - acc: 0.8027 -- iter: 192/424
[A[ATraining Step: 105  | total loss: [1m[32m0.43648[0m[0m | time: 5.055s
[2K
| Adam | epoch: 008 | loss: 0.43648 - acc: 0.8099 -- iter: 224/424
[A[ATraining Step: 106  | total loss: [1m[32m0.40776[0m[0m | time: 5.780s
[2K
| Adam | epoch: 008 | loss: 0.40776 - acc: 0.8289 -- iter: 256/424
[A[ATraining Step: 107  | total loss: [1m[32m0.43223[0m[0m | time: 6.587s
[2K
| Adam | epoch: 008 | loss: 0.43223 - acc: 0.8117 -- iter: 288/424
[A[ATraining Step: 108  | total loss: [1m[32m0.46479[0m[0m | time: 7.472s
[2K
| Adam | epoch: 008 | loss: 0.46479 - acc: 0.8024 -- iter: 320/424
[A[ATraining Step: 109  | total loss: [1m[32m0.46217[0m[0m | time: 8.314s
[2K
| Adam | epoch: 008 | loss: 0.46217 - acc: 0.8065 -- iter: 352/424
[A[ATraining Step: 110  | total loss: [1m[32m0.45596[0m[0m | time: 9.168s
[2K
| Adam | epoch: 008 | loss: 0.45596 - acc: 0.8165 -- iter: 384/424
[A[ATraining Step: 111  | total loss: [1m[32m0.48426[0m[0m | time: 10.145s
[2K
| Adam | epoch: 008 | loss: 0.48426 - acc: 0.8067 -- iter: 416/424
[A[ATraining Step: 112  | total loss: [1m[32m0.48929[0m[0m | time: 12.072s
[2K
| Adam | epoch: 008 | loss: 0.48929 - acc: 0.7979 | val_loss: 0.42117 - val_acc: 0.8195 -- iter: 424/424
--
Training Step: 113  | total loss: [1m[32m0.47603[0m[0m | time: 0.993s
[2K
| Adam | epoch: 009 | loss: 0.47603 - acc: 0.7994 -- iter: 032/424
[A[ATraining Step: 114  | total loss: [1m[32m0.46557[0m[0m | time: 1.696s
[2K
| Adam | epoch: 009 | loss: 0.46557 - acc: 0.8038 -- iter: 064/424
[A[ATraining Step: 115  | total loss: [1m[32m0.47440[0m[0m | time: 2.580s
[2K
| Adam | epoch: 009 | loss: 0.47440 - acc: 0.7922 -- iter: 096/424
[A[ATraining Step: 116  | total loss: [1m[32m0.46722[0m[0m | time: 3.452s
[2K
| Adam | epoch: 009 | loss: 0.46722 - acc: 0.7848 -- iter: 128/424
[A[ATraining Step: 117  | total loss: [1m[32m0.45949[0m[0m | time: 4.259s
[2K
| Adam | epoch: 009 | loss: 0.45949 - acc: 0.7907 -- iter: 160/424
[A[ATraining Step: 118  | total loss: [1m[32m0.45280[0m[0m | time: 5.117s
[2K
| Adam | epoch: 009 | loss: 0.45280 - acc: 0.7992 -- iter: 192/424
[A[ATraining Step: 119  | total loss: [1m[32m0.45970[0m[0m | time: 5.371s
[2K
| Adam | epoch: 009 | loss: 0.45970 - acc: 0.7942 -- iter: 224/424
[A[ATraining Step: 120  | total loss: [1m[32m0.44685[0m[0m | time: 5.621s
[2K
| Adam | epoch: 009 | loss: 0.44685 - acc: 0.8148 -- iter: 256/424
[A[ATraining Step: 121  | total loss: [1m[32m0.43391[0m[0m | time: 6.527s
[2K
| Adam | epoch: 009 | loss: 0.43391 - acc: 0.8333 -- iter: 288/424
[A[ATraining Step: 122  | total loss: [1m[32m0.44370[0m[0m | time: 7.414s
[2K
| Adam | epoch: 009 | loss: 0.44370 - acc: 0.8219 -- iter: 320/424
[A[ATraining Step: 123  | total loss: [1m[32m0.44026[0m[0m | time: 8.221s
[2K
| Adam | epoch: 009 | loss: 0.44026 - acc: 0.8209 -- iter: 352/424
[A[ATraining Step: 124  | total loss: [1m[32m0.44526[0m[0m | time: 9.090s
[2K
| Adam | epoch: 009 | loss: 0.44526 - acc: 0.8138 -- iter: 384/424
[A[ATraining Step: 125  | total loss: [1m[32m0.44389[0m[0m | time: 10.072s
[2K
| Adam | epoch: 009 | loss: 0.44389 - acc: 0.8137 -- iter: 416/424
[A[ATraining Step: 126  | total loss: [1m[32m0.43738[0m[0m | time: 12.064s
[2K
| Adam | epoch: 009 | loss: 0.43738 - acc: 0.8167 | val_loss: 0.38834 - val_acc: 0.8346 -- iter: 424/424
--
Training Step: 127  | total loss: [1m[32m0.41915[0m[0m | time: 0.882s
[2K
| Adam | epoch: 010 | loss: 0.41915 - acc: 0.8225 -- iter: 032/424
[A[ATraining Step: 128  | total loss: [1m[32m0.42311[0m[0m | time: 1.736s
[2K
| Adam | epoch: 010 | loss: 0.42311 - acc: 0.8122 -- iter: 064/424
[A[ATraining Step: 129  | total loss: [1m[32m0.41422[0m[0m | time: 2.606s
[2K
| Adam | epoch: 010 | loss: 0.41422 - acc: 0.8184 -- iter: 096/424
[A[ATraining Step: 130  | total loss: [1m[32m0.40716[0m[0m | time: 3.496s
[2K
| Adam | epoch: 010 | loss: 0.40716 - acc: 0.8241 -- iter: 128/424
[A[ATraining Step: 131  | total loss: [1m[32m0.41691[0m[0m | time: 4.402s
[2K
| Adam | epoch: 010 | loss: 0.41691 - acc: 0.8167 -- iter: 160/424
[A[ATraining Step: 132  | total loss: [1m[32m0.41240[0m[0m | time: 5.231s
[2K
| Adam | epoch: 010 | loss: 0.41240 - acc: 0.8194 -- iter: 192/424
[A[ATraining Step: 133  | total loss: [1m[32m0.44049[0m[0m | time: 6.154s
[2K
| Adam | epoch: 010 | loss: 0.44049 - acc: 0.8218 -- iter: 224/424
[A[ATraining Step: 134  | total loss: [1m[32m0.43826[0m[0m | time: 6.439s
[2K
| Adam | epoch: 010 | loss: 0.43826 - acc: 0.8240 -- iter: 256/424
[A[ATraining Step: 135  | total loss: [1m[32m0.42738[0m[0m | time: 6.731s
[2K
| Adam | epoch: 010 | loss: 0.42738 - acc: 0.8291 -- iter: 288/424
[A[ATraining Step: 136  | total loss: [1m[32m0.41801[0m[0m | time: 7.747s
[2K
| Adam | epoch: 010 | loss: 0.41801 - acc: 0.8337 -- iter: 320/424
[A[ATraining Step: 137  | total loss: [1m[32m0.42043[0m[0m | time: 8.459s
[2K
| Adam | epoch: 010 | loss: 0.42043 - acc: 0.8316 -- iter: 352/424
[A[ATraining Step: 138  | total loss: [1m[32m0.40642[0m[0m | time: 9.255s
[2K
| Adam | epoch: 010 | loss: 0.40642 - acc: 0.8359 -- iter: 384/424
[A[ATraining Step: 139  | total loss: [1m[32m0.40206[0m[0m | time: 10.116s
[2K
| Adam | epoch: 010 | loss: 0.40206 - acc: 0.8367 -- iter: 416/424
[A[ATraining Step: 140  | total loss: [1m[32m0.38943[0m[0m | time: 11.960s
[2K
| Adam | epoch: 010 | loss: 0.38943 - acc: 0.8437 | val_loss: 0.37068 - val_acc: 0.8271 -- iter: 424/424
--
Training Step: 141  | total loss: [1m[32m0.38912[0m[0m | time: 0.931s
[2K
| Adam | epoch: 011 | loss: 0.38912 - acc: 0.8437 -- iter: 032/424
[A[ATraining Step: 142  | total loss: [1m[32m0.40524[0m[0m | time: 1.927s
[2K
| Adam | epoch: 011 | loss: 0.40524 - acc: 0.8281 -- iter: 064/424
[A[ATraining Step: 143  | total loss: [1m[32m0.39453[0m[0m | time: 2.797s
[2K
| Adam | epoch: 011 | loss: 0.39453 - acc: 0.8296 -- iter: 096/424
[A[ATraining Step: 144  | total loss: [1m[32m0.38740[0m[0m | time: 3.767s
[2K
| Adam | epoch: 011 | loss: 0.38740 - acc: 0.8373 -- iter: 128/424
[A[ATraining Step: 145  | total loss: [1m[32m0.39057[0m[0m | time: 4.781s
[2K
| Adam | epoch: 011 | loss: 0.39057 - acc: 0.8379 -- iter: 160/424
[A[ATraining Step: 146  | total loss: [1m[32m0.38939[0m[0m | time: 5.769s
[2K
| Adam | epoch: 011 | loss: 0.38939 - acc: 0.8323 -- iter: 192/424
[A[ATraining Step: 147  | total loss: [1m[32m0.36890[0m[0m | time: 6.477s
[2K
| Adam | epoch: 011 | loss: 0.36890 - acc: 0.8459 -- iter: 224/424
[A[ATraining Step: 148  | total loss: [1m[32m0.37423[0m[0m | time: 7.290s
[2K
| Adam | epoch: 011 | loss: 0.37423 - acc: 0.8363 -- iter: 256/424
[A[ATraining Step: 149  | total loss: [1m[32m0.37468[0m[0m | time: 7.535s
[2K
| Adam | epoch: 011 | loss: 0.37468 - acc: 0.8308 -- iter: 288/424
[A[ATraining Step: 150  | total loss: [1m[32m0.35325[0m[0m | time: 7.769s
[2K
| Adam | epoch: 011 | loss: 0.35325 - acc: 0.8477 -- iter: 320/424
[A[ATraining Step: 151  | total loss: [1m[32m0.33445[0m[0m | time: 8.585s
[2K
| Adam | epoch: 011 | loss: 0.33445 - acc: 0.8630 -- iter: 352/424
[A[ATraining Step: 152  | total loss: [1m[32m0.34283[0m[0m | time: 9.447s
[2K
| Adam | epoch: 011 | loss: 0.34283 - acc: 0.8579 -- iter: 384/424
[A[ATraining Step: 153  | total loss: [1m[32m0.34639[0m[0m | time: 10.342s
[2K
| Adam | epoch: 011 | loss: 0.34639 - acc: 0.8565 -- iter: 416/424
[A[ATraining Step: 154  | total loss: [1m[32m0.33281[0m[0m | time: 12.236s
[2K
| Adam | epoch: 011 | loss: 0.33281 - acc: 0.8646 | val_loss: 0.31356 - val_acc: 0.8647 -- iter: 424/424
--
Training Step: 155  | total loss: [1m[32m0.33872[0m[0m | time: 1.038s
[2K
| Adam | epoch: 012 | loss: 0.33872 - acc: 0.8594 -- iter: 032/424
[A[ATraining Step: 156  | total loss: [1m[32m0.33274[0m[0m | time: 1.939s
[2K
| Adam | epoch: 012 | loss: 0.33274 - acc: 0.8641 -- iter: 064/424
[A[ATraining Step: 157  | total loss: [1m[32m0.33106[0m[0m | time: 2.664s
[2K
| Adam | epoch: 012 | loss: 0.33106 - acc: 0.8652 -- iter: 096/424
[A[ATraining Step: 158  | total loss: [1m[32m0.32119[0m[0m | time: 3.508s
[2K
| Adam | epoch: 012 | loss: 0.32119 - acc: 0.8693 -- iter: 128/424
[A[ATraining Step: 159  | total loss: [1m[32m0.30543[0m[0m | time: 4.349s
[2K
| Adam | epoch: 012 | loss: 0.30543 - acc: 0.8792 -- iter: 160/424
[A[ATraining Step: 160  | total loss: [1m[32m0.29952[0m[0m | time: 5.179s
[2K
| Adam | epoch: 012 | loss: 0.29952 - acc: 0.8819 -- iter: 192/424
[A[ATraining Step: 161  | total loss: [1m[32m0.30079[0m[0m | time: 6.046s
[2K
| Adam | epoch: 012 | loss: 0.30079 - acc: 0.8812 -- iter: 224/424
[A[ATraining Step: 162  | total loss: [1m[32m0.30077[0m[0m | time: 6.978s
[2K
| Adam | epoch: 012 | loss: 0.30077 - acc: 0.8775 -- iter: 256/424
[A[ATraining Step: 163  | total loss: [1m[32m0.29136[0m[0m | time: 7.881s
[2K
| Adam | epoch: 012 | loss: 0.29136 - acc: 0.8804 -- iter: 288/424
[A[ATraining Step: 164  | total loss: [1m[32m0.30435[0m[0m | time: 8.138s
[2K
| Adam | epoch: 012 | loss: 0.30435 - acc: 0.8767 -- iter: 320/424
[A[ATraining Step: 165  | total loss: [1m[32m0.27949[0m[0m | time: 8.431s
[2K
| Adam | epoch: 012 | loss: 0.27949 - acc: 0.8890 -- iter: 352/424
[A[ATraining Step: 166  | total loss: [1m[32m0.25980[0m[0m | time: 9.287s
[2K
| Adam | epoch: 012 | loss: 0.25980 - acc: 0.9001 -- iter: 384/424
[A[ATraining Step: 167  | total loss: [1m[32m0.26104[0m[0m | time: 10.156s
[2K
| Adam | epoch: 012 | loss: 0.26104 - acc: 0.9007 -- iter: 416/424
[A[ATraining Step: 168  | total loss: [1m[32m0.25946[0m[0m | time: 12.108s
[2K
| Adam | epoch: 012 | loss: 0.25946 - acc: 0.9044 | val_loss: 0.60290 - val_acc: 0.7669 -- iter: 424/424
--
Training Step: 169  | total loss: [1m[32m0.25978[0m[0m | time: 0.930s
[2K
| Adam | epoch: 013 | loss: 0.25978 - acc: 0.9046 -- iter: 032/424
[A[ATraining Step: 170  | total loss: [1m[32m0.31814[0m[0m | time: 1.827s
[2K
| Adam | epoch: 013 | loss: 0.31814 - acc: 0.8829 -- iter: 064/424
[A[ATraining Step: 171  | total loss: [1m[32m0.30642[0m[0m | time: 2.705s
[2K
| Adam | epoch: 013 | loss: 0.30642 - acc: 0.8852 -- iter: 096/424
[A[ATraining Step: 172  | total loss: [1m[32m0.29087[0m[0m | time: 3.559s
[2K
| Adam | epoch: 013 | loss: 0.29087 - acc: 0.8936 -- iter: 128/424
[A[ATraining Step: 173  | total loss: [1m[32m0.30438[0m[0m | time: 4.475s
[2K
| Adam | epoch: 013 | loss: 0.30438 - acc: 0.8886 -- iter: 160/424
[A[ATraining Step: 174  | total loss: [1m[32m0.28451[0m[0m | time: 5.398s
[2K
| Adam | epoch: 013 | loss: 0.28451 - acc: 0.8966 -- iter: 192/424
[A[ATraining Step: 175  | total loss: [1m[32m0.26507[0m[0m | time: 6.272s
[2K
| Adam | epoch: 013 | loss: 0.26507 - acc: 0.9069 -- iter: 224/424
[A[ATraining Step: 176  | total loss: [1m[32m0.27618[0m[0m | time: 7.118s
[2K
| Adam | epoch: 013 | loss: 0.27618 - acc: 0.8975 -- iter: 256/424
[A[ATraining Step: 177  | total loss: [1m[32m0.27270[0m[0m | time: 8.144s
[2K
| Adam | epoch: 013 | loss: 0.27270 - acc: 0.8984 -- iter: 288/424
[A[ATraining Step: 178  | total loss: [1m[32m0.25983[0m[0m | time: 9.119s
[2K
| Adam | epoch: 013 | loss: 0.25983 - acc: 0.9023 -- iter: 320/424
[A[ATraining Step: 179  | total loss: [1m[32m0.24625[0m[0m | time: 9.398s
[2K
| Adam | epoch: 013 | loss: 0.24625 - acc: 0.9058 -- iter: 352/424
[A[ATraining Step: 180  | total loss: [1m[32m0.23137[0m[0m | time: 9.634s
[2K
| Adam | epoch: 013 | loss: 0.23137 - acc: 0.9152 -- iter: 384/424
[A[ATraining Step: 181  | total loss: [1m[32m0.21523[0m[0m | time: 10.317s
[2K
| Adam | epoch: 013 | loss: 0.21523 - acc: 0.9237 -- iter: 416/424
[A[ATraining Step: 182  | total loss: [1m[32m0.24037[0m[0m | time: 12.156s
[2K
| Adam | epoch: 013 | loss: 0.24037 - acc: 0.9157 | val_loss: 0.33232 - val_acc: 0.8647 -- iter: 424/424
--
Training Step: 183  | total loss: [1m[32m0.24584[0m[0m | time: 0.856s
[2K
| Adam | epoch: 014 | loss: 0.24584 - acc: 0.9116 -- iter: 032/424
[A[ATraining Step: 184  | total loss: [1m[32m0.25900[0m[0m | time: 1.751s
[2K
| Adam | epoch: 014 | loss: 0.25900 - acc: 0.8986 -- iter: 064/424
[A[ATraining Step: 185  | total loss: [1m[32m0.26543[0m[0m | time: 2.598s
[2K
| Adam | epoch: 014 | loss: 0.26543 - acc: 0.8931 -- iter: 096/424
[A[ATraining Step: 186  | total loss: [1m[32m0.24890[0m[0m | time: 3.484s
[2K
| Adam | epoch: 014 | loss: 0.24890 - acc: 0.9007 -- iter: 128/424
[A[ATraining Step: 187  | total loss: [1m[32m0.29722[0m[0m | time: 4.329s
[2K
| Adam | epoch: 014 | loss: 0.29722 - acc: 0.8762 -- iter: 160/424
[A[ATraining Step: 188  | total loss: [1m[32m0.33862[0m[0m | time: 5.295s
[2K
| Adam | epoch: 014 | loss: 0.33862 - acc: 0.8542 -- iter: 192/424
[A[ATraining Step: 189  | total loss: [1m[32m0.31403[0m[0m | time: 6.240s
[2K
| Adam | epoch: 014 | loss: 0.31403 - acc: 0.8657 -- iter: 224/424
[A[ATraining Step: 190  | total loss: [1m[32m0.31986[0m[0m | time: 7.190s
[2K
| Adam | epoch: 014 | loss: 0.31986 - acc: 0.8666 -- iter: 256/424
[A[ATraining Step: 191  | total loss: [1m[32m0.30245[0m[0m | time: 7.868s
[2K
| Adam | epoch: 014 | loss: 0.30245 - acc: 0.8737 -- iter: 288/424
[A[ATraining Step: 192  | total loss: [1m[32m0.28850[0m[0m | time: 8.674s
[2K
| Adam | epoch: 014 | loss: 0.28850 - acc: 0.8832 -- iter: 320/424
[A[ATraining Step: 193  | total loss: [1m[32m0.29520[0m[0m | time: 9.502s
[2K
| Adam | epoch: 014 | loss: 0.29520 - acc: 0.8855 -- iter: 352/424
[A[ATraining Step: 194  | total loss: [1m[32m0.27446[0m[0m | time: 9.746s
[2K
| Adam | epoch: 014 | loss: 0.27446 - acc: 0.8970 -- iter: 384/424
[A[ATraining Step: 195  | total loss: [1m[32m0.26461[0m[0m | time: 9.996s
[2K
| Adam | epoch: 014 | loss: 0.26461 - acc: 0.9073 -- iter: 416/424
[A[ATraining Step: 196  | total loss: [1m[32m0.24829[0m[0m | time: 11.859s
[2K
| Adam | epoch: 014 | loss: 0.24829 - acc: 0.9165 | val_loss: 0.22349 - val_acc: 0.9023 -- iter: 424/424
--
Training Step: 197  | total loss: [1m[32m0.24937[0m[0m | time: 0.877s
[2K
| Adam | epoch: 015 | loss: 0.24937 - acc: 0.9155 -- iter: 032/424
[A[ATraining Step: 198  | total loss: [1m[32m0.24406[0m[0m | time: 1.706s
[2K
| Adam | epoch: 015 | loss: 0.24406 - acc: 0.9146 -- iter: 064/424
[A[ATraining Step: 199  | total loss: [1m[32m0.23177[0m[0m | time: 2.659s
[2K
| Adam | epoch: 015 | loss: 0.23177 - acc: 0.9200 -- iter: 096/424
[A[ATraining Step: 200  | total loss: [1m[32m0.21650[0m[0m | time: 4.653s
[2K
| Adam | epoch: 015 | loss: 0.21650 - acc: 0.9280 | val_loss: 0.18632 - val_acc: 0.9248 -- iter: 128/424
--
Training Step: 201  | total loss: [1m[32m0.20469[0m[0m | time: 5.487s
[2K
| Adam | epoch: 015 | loss: 0.20469 - acc: 0.9321 -- iter: 160/424
[A[ATraining Step: 202  | total loss: [1m[32m0.19917[0m[0m | time: 6.337s
[2K
| Adam | epoch: 015 | loss: 0.19917 - acc: 0.9357 -- iter: 192/424
[A[ATraining Step: 203  | total loss: [1m[32m0.19307[0m[0m | time: 7.165s
[2K
| Adam | epoch: 015 | loss: 0.19307 - acc: 0.9359 -- iter: 224/424
[A[ATraining Step: 204  | total loss: [1m[32m0.17758[0m[0m | time: 8.057s
[2K
| Adam | epoch: 015 | loss: 0.17758 - acc: 0.9423 -- iter: 256/424
[A[ATraining Step: 205  | total loss: [1m[32m0.16612[0m[0m | time: 8.976s
[2K
| Adam | epoch: 015 | loss: 0.16612 - acc: 0.9450 -- iter: 288/424
[A[ATraining Step: 206  | total loss: [1m[32m0.15668[0m[0m | time: 9.903s
[2K
| Adam | epoch: 015 | loss: 0.15668 - acc: 0.9473 -- iter: 320/424
[A[ATraining Step: 207  | total loss: [1m[32m0.14543[0m[0m | time: 10.826s
[2K
| Adam | epoch: 015 | loss: 0.14543 - acc: 0.9495 -- iter: 352/424
[A[ATraining Step: 208  | total loss: [1m[32m0.14751[0m[0m | time: 11.594s
[2K
| Adam | epoch: 015 | loss: 0.14751 - acc: 0.9514 -- iter: 384/424
[A[ATraining Step: 209  | total loss: [1m[32m0.13561[0m[0m | time: 11.810s
[2K
| Adam | epoch: 015 | loss: 0.13561 - acc: 0.9563 -- iter: 416/424
[A[ATraining Step: 210  | total loss: [1m[32m0.14635[0m[0m | time: 13.127s
[2K
| Adam | epoch: 015 | loss: 0.14635 - acc: 0.9481 | val_loss: 0.59562 - val_acc: 0.7970 -- iter: 424/424
--
Validation AUC:0.9848484848484849
Validation AUPRC:0.9875179938515892
Test AUC:0.9736961451247165
Test AUPRC:0.9745145055010592
BestTestF1Score	0.92	0.85	0.92	0.98	0.86	54	1	69	9	0.01
BestTestMCCScore	0.92	0.85	0.92	0.98	0.86	54	1	69	9	0.01
BestTestAccuracyScore	0.92	0.85	0.92	0.98	0.86	54	1	69	9	0.01
BestValidationF1Score	0.95	0.9	0.95	0.97	0.92	61	2	65	5	0.01
BestValidationMCC	0.95	0.9	0.95	0.97	0.92	61	2	65	5	0.01
BestValidationAccuracy	0.95	0.9	0.95	0.97	0.92	61	2	65	5	0.01
TestPredictions (Threshold:0.01)
CHEMBL59308,FN,ACT,0.0	CHEMBL446913,TN,INACT,0.0	CHEMBL2380899,TN,INACT,0.009999999776482582	CHEMBL3609248,TP,ACT,1.0	CHEMBL3609073,TP,ACT,1.0	CHEMBL1290280,TP,ACT,0.9900000095367432	CHEMBL496692,TP,ACT,0.03999999910593033	CHEMBL1289530,TP,ACT,0.949999988079071	CHEMBL1289848,TP,ACT,0.3100000023841858	CHEMBL3609220,TP,ACT,1.0	CHEMBL1290739,TP,ACT,0.9900000095367432	CHEMBL466611,TN,INACT,0.0	CHEMBL2381025,TN,INACT,0.0	CHEMBL193449,TN,INACT,0.009999999776482582	CHEMBL3113246,TN,INACT,0.0	CHEMBL16683,TP,ACT,0.800000011920929	CHEMBL426096,TN,INACT,0.0	CHEMBL498086,FN,ACT,0.0	CHEMBL1289531,TP,ACT,0.9900000095367432	CHEMBL229165,TN,INACT,0.0	CHEMBL281622,TP,ACT,0.12999999523162842	CHEMBL3687754,TN,INACT,0.0	CHEMBL298608,FN,ACT,0.0	CHEMBL1289527,TP,ACT,0.6000000238418579	CHEMBL114455,TN,INACT,0.0	CHEMBL44297,TN,INACT,0.0	CHEMBL559267,TP,ACT,0.18000000715255737	CHEMBL3113254,TN,INACT,0.0	CHEMBL76997,TP,ACT,0.9700000286102295	CHEMBL23,TN,INACT,0.0	CHEMBL2151783,TN,INACT,0.0	CHEMBL2380883,TN,INACT,0.0	CHEMBL1290509,TP,ACT,0.9900000095367432	CHEMBL473292,TN,INACT,0.0	CHEMBL1290277,TP,ACT,0.4300000071525574	CHEMBL3221247,TN,INACT,0.0	CHEMBL55791,TP,ACT,0.07999999821186066	CHEMBL3609241,TP,ACT,1.0	CHEMBL55091,FN,ACT,0.0	CHEMBL2151778,TN,INACT,0.0	CHEMBL12406,TN,INACT,0.0	CHEMBL111861,TN,INACT,0.0	CHEMBL3184075,TN,INACT,0.0	CHEMBL3262824,TN,INACT,0.0	CHEMBL3260889,TN,INACT,0.0	CHEMBL27783,TN,INACT,0.0	CHEMBL1777855,TN,INACT,0.0	CHEMBL227432,TN,INACT,0.0	CHEMBL329541,TN,INACT,0.0	CHEMBL2298875,TN,INACT,0.0	CHEMBL77317,TP,ACT,0.4000000059604645	CHEMBL3786562,TN,INACT,0.0	CHEMBL3221240,TN,INACT,0.0	CHEMBL3112596,TN,INACT,0.0	CHEMBL306037,TP,ACT,0.029999999329447746	CHEMBL3609036,TP,ACT,1.0	CHEMBL3609226,TP,ACT,1.0	CHEMBL3262830,TN,INACT,0.0	CHEMBL3609028,TP,ACT,1.0	CHEMBL496892,TP,ACT,0.019999999552965164	CHEMBL3609088,TP,ACT,1.0	CHEMBL496971,TN,INACT,0.0	CHEMBL2409401,FP,INACT,0.05999999865889549	CHEMBL2325264,TN,INACT,0.0	CHEMBL1289412,TP,ACT,0.029999999329447746	CHEMBL1256851,TP,ACT,0.9800000190734863	CHEMBL435767,TN,INACT,0.009999999776482582	CHEMBL554816,FN,ACT,0.0	CHEMBL1289850,TP,ACT,0.9900000095367432	CHEMBL443619,TN,INACT,0.0	CHEMBL204484,TN,INACT,0.0	CHEMBL190756,TN,INACT,0.0	CHEMBL3609095,TP,ACT,1.0	CHEMBL38876,TN,INACT,0.0	CHEMBL468913,TN,INACT,0.0	CHEMBL449320,TN,INACT,0.009999999776482582	CHEMBL293083,TP,ACT,0.18000000715255737	CHEMBL16,TN,INACT,0.0	CHEMBL3609026,TP,ACT,1.0	CHEMBL53790,TP,ACT,0.5600000023841858	CHEMBL3687593,TN,INACT,0.0	CHEMBL2381013,TN,INACT,0.0	CHEMBL56261,FN,ACT,0.0	CHEMBL3609080,TP,ACT,1.0	CHEMBL23720,TN,INACT,0.0	CHEMBL525412,TP,ACT,0.8399999737739563	CHEMBL1289526,TP,ACT,0.5799999833106995	CHEMBL3085872,TN,INACT,0.0	CHEMBL2381033,TN,INACT,0.0	CHEMBL524847,TP,ACT,0.05000000074505806	CHEMBL3085880,TN,INACT,0.0	CHEMBL2205324,TN,INACT,0.009999999776482582	CHEMBL417417,FN,ACT,0.009999999776482582	CHEMBL473499,TN,INACT,0.009999999776482582	CHEMBL109698,TP,ACT,0.019999999552965164	CHEMBL1289965,TP,ACT,0.4300000071525574	CHEMBL3609255,TP,ACT,1.0	CHEMBL3262813,TN,INACT,0.0	CHEMBL519199,TN,INACT,0.0	CHEMBL274527,TN,INACT,0.0	CHEMBL75159,TP,ACT,0.03999999910593033	CHEMBL549464,TP,ACT,0.019999999552965164	CHEMBL3682816,TN,INACT,0.0	CHEMBL3609066,TP,ACT,1.0	CHEMBL372177,TN,INACT,0.009999999776482582	CHEMBL473705,TN,INACT,0.0	CHEMBL3683240,TN,INACT,0.0	CHEMBL210829,TN,INACT,0.0	CHEMBL55202,FN,ACT,0.0	CHEMBL3416893,TN,INACT,0.0	CHEMBL1290734,TP,ACT,0.46000000834465027	CHEMBL2205323,FN,ACT,0.009999999776482582	CHEMBL3221241,TN,INACT,0.0	CHEMBL3687624,TN,INACT,0.0	CHEMBL3609039,TP,ACT,1.0	CHEMBL77493,TP,ACT,0.05000000074505806	CHEMBL1972820,TN,INACT,0.0	CHEMBL2380898,TN,INACT,0.009999999776482582	CHEMBL22704,TN,INACT,0.0	CHEMBL378104,TP,ACT,0.019999999552965164	CHEMBL3609041,TP,ACT,1.0	CHEMBL418444,TP,ACT,0.9900000095367432	CHEMBL1290618,TP,ACT,1.0	CHEMBL3608994,TP,ACT,1.0	CHEMBL16806,TP,ACT,0.38999998569488525	CHEMBL473706,TN,INACT,0.0	CHEMBL3609223,TP,ACT,1.0	CHEMBL3609071,TP,ACT,1.0	CHEMBL273245,TN,INACT,0.0	CHEMBL605092,TN,INACT,0.0	CHEMBL3085870,TN,INACT,0.0	CHEMBL2325259,TN,INACT,0.009999999776482582	CHEMBL3609040,TP,ACT,1.0	

