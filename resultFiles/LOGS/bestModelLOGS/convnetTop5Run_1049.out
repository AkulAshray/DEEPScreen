CNNModel CHEMBL5393 adam 0.0005 15 32 0 0.8 False True
Number of active compounds :	332
Number of inactive compounds :	305
---------------------------------
Run id: CNNModel_CHEMBL5393_adam_0.0005_15_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL5393_adam_0.0005_15_32_0.8_True/
---------------------------------
Training samples: 407
Validation samples: 128
--
Training Step: 1  | time: 0.760s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/407
[A[ATraining Step: 2  | total loss: [1m[32m0.62354[0m[0m | time: 1.373s
[2K
| Adam | epoch: 001 | loss: 0.62354 - acc: 0.5344 -- iter: 064/407
[A[ATraining Step: 3  | total loss: [1m[32m0.67587[0m[0m | time: 1.971s
[2K
| Adam | epoch: 001 | loss: 0.67587 - acc: 0.6852 -- iter: 096/407
[A[ATraining Step: 4  | total loss: [1m[32m0.68492[0m[0m | time: 2.572s
[2K
| Adam | epoch: 001 | loss: 0.68492 - acc: 0.5932 -- iter: 128/407
[A[ATraining Step: 5  | total loss: [1m[32m0.68311[0m[0m | time: 3.180s
[2K
| Adam | epoch: 001 | loss: 0.68311 - acc: 0.5936 -- iter: 160/407
[A[ATraining Step: 6  | total loss: [1m[32m0.70752[0m[0m | time: 3.797s
[2K
| Adam | epoch: 001 | loss: 0.70752 - acc: 0.5133 -- iter: 192/407
[A[ATraining Step: 7  | total loss: [1m[32m0.69397[0m[0m | time: 4.408s
[2K
| Adam | epoch: 001 | loss: 0.69397 - acc: 0.5428 -- iter: 224/407
[A[ATraining Step: 8  | total loss: [1m[32m0.68920[0m[0m | time: 5.011s
[2K
| Adam | epoch: 001 | loss: 0.68920 - acc: 0.5539 -- iter: 256/407
[A[ATraining Step: 9  | total loss: [1m[32m0.69437[0m[0m | time: 5.620s
[2K
| Adam | epoch: 001 | loss: 0.69437 - acc: 0.5254 -- iter: 288/407
[A[ATraining Step: 10  | total loss: [1m[32m0.69258[0m[0m | time: 6.233s
[2K
| Adam | epoch: 001 | loss: 0.69258 - acc: 0.5283 -- iter: 320/407
[A[ATraining Step: 11  | total loss: [1m[32m0.68418[0m[0m | time: 6.838s
[2K
| Adam | epoch: 001 | loss: 0.68418 - acc: 0.5889 -- iter: 352/407
[A[ATraining Step: 12  | total loss: [1m[32m0.68196[0m[0m | time: 7.448s
[2K
| Adam | epoch: 001 | loss: 0.68196 - acc: 0.6052 -- iter: 384/407
[A[ATraining Step: 13  | total loss: [1m[32m0.68444[0m[0m | time: 8.958s
[2K
| Adam | epoch: 001 | loss: 0.68444 - acc: 0.5869 | val_loss: 0.70495 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 14  | total loss: [1m[32m0.68544[0m[0m | time: 0.447s
[2K
| Adam | epoch: 002 | loss: 0.68544 - acc: 0.5780 -- iter: 032/407
[A[ATraining Step: 15  | total loss: [1m[32m0.68534[0m[0m | time: 1.070s
[2K
| Adam | epoch: 002 | loss: 0.68534 - acc: 0.5730 -- iter: 064/407
[A[ATraining Step: 16  | total loss: [1m[32m0.67991[0m[0m | time: 1.689s
[2K
| Adam | epoch: 002 | loss: 0.67991 - acc: 0.5925 -- iter: 096/407
[A[ATraining Step: 17  | total loss: [1m[32m0.69002[0m[0m | time: 2.290s
[2K
| Adam | epoch: 002 | loss: 0.69002 - acc: 0.5480 -- iter: 128/407
[A[ATraining Step: 18  | total loss: [1m[32m0.68822[0m[0m | time: 2.885s
[2K
| Adam | epoch: 002 | loss: 0.68822 - acc: 0.5530 -- iter: 160/407
[A[ATraining Step: 19  | total loss: [1m[32m0.69551[0m[0m | time: 3.493s
[2K
| Adam | epoch: 002 | loss: 0.69551 - acc: 0.5249 -- iter: 192/407
[A[ATraining Step: 20  | total loss: [1m[32m0.69235[0m[0m | time: 4.096s
[2K
| Adam | epoch: 002 | loss: 0.69235 - acc: 0.5370 -- iter: 224/407
[A[ATraining Step: 21  | total loss: [1m[32m0.70052[0m[0m | time: 4.718s
[2K
| Adam | epoch: 002 | loss: 0.70052 - acc: 0.4964 -- iter: 256/407
[A[ATraining Step: 22  | total loss: [1m[32m0.69938[0m[0m | time: 5.313s
[2K
| Adam | epoch: 002 | loss: 0.69938 - acc: 0.4975 -- iter: 288/407
[A[ATraining Step: 23  | total loss: [1m[32m0.69289[0m[0m | time: 5.907s
[2K
| Adam | epoch: 002 | loss: 0.69289 - acc: 0.5345 -- iter: 320/407
[A[ATraining Step: 24  | total loss: [1m[32m0.68701[0m[0m | time: 6.510s
[2K
| Adam | epoch: 002 | loss: 0.68701 - acc: 0.5775 -- iter: 352/407
[A[ATraining Step: 25  | total loss: [1m[32m0.68625[0m[0m | time: 7.121s
[2K
| Adam | epoch: 002 | loss: 0.68625 - acc: 0.5820 -- iter: 384/407
[A[ATraining Step: 26  | total loss: [1m[32m0.68348[0m[0m | time: 8.754s
[2K
| Adam | epoch: 002 | loss: 0.68348 - acc: 0.6016 | val_loss: 0.70234 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 27  | total loss: [1m[32m0.68191[0m[0m | time: 0.444s
[2K
| Adam | epoch: 003 | loss: 0.68191 - acc: 0.6076 -- iter: 032/407
[A[ATraining Step: 28  | total loss: [1m[32m0.67965[0m[0m | time: 0.903s
[2K
| Adam | epoch: 003 | loss: 0.67965 - acc: 0.6188 -- iter: 064/407
[A[ATraining Step: 29  | total loss: [1m[32m0.67712[0m[0m | time: 1.492s
[2K
| Adam | epoch: 003 | loss: 0.67712 - acc: 0.6269 -- iter: 096/407
[A[ATraining Step: 30  | total loss: [1m[32m0.68386[0m[0m | time: 2.087s
[2K
| Adam | epoch: 003 | loss: 0.68386 - acc: 0.5894 -- iter: 128/407
[A[ATraining Step: 31  | total loss: [1m[32m0.68022[0m[0m | time: 2.683s
[2K
| Adam | epoch: 003 | loss: 0.68022 - acc: 0.5976 -- iter: 160/407
[A[ATraining Step: 32  | total loss: [1m[32m0.70178[0m[0m | time: 3.291s
[2K
| Adam | epoch: 003 | loss: 0.70178 - acc: 0.5194 -- iter: 192/407
[A[ATraining Step: 33  | total loss: [1m[32m0.70872[0m[0m | time: 3.883s
[2K
| Adam | epoch: 003 | loss: 0.70872 - acc: 0.4877 -- iter: 224/407
[A[ATraining Step: 34  | total loss: [1m[32m0.70527[0m[0m | time: 4.494s
[2K
| Adam | epoch: 003 | loss: 0.70527 - acc: 0.4970 -- iter: 256/407
[A[ATraining Step: 35  | total loss: [1m[32m0.70227[0m[0m | time: 5.090s
[2K
| Adam | epoch: 003 | loss: 0.70227 - acc: 0.5042 -- iter: 288/407
[A[ATraining Step: 36  | total loss: [1m[32m0.69613[0m[0m | time: 5.691s
[2K
| Adam | epoch: 003 | loss: 0.69613 - acc: 0.5353 -- iter: 320/407
[A[ATraining Step: 37  | total loss: [1m[32m0.69512[0m[0m | time: 6.281s
[2K
| Adam | epoch: 003 | loss: 0.69512 - acc: 0.5345 -- iter: 352/407
[A[ATraining Step: 38  | total loss: [1m[32m0.69136[0m[0m | time: 6.910s
[2K
| Adam | epoch: 003 | loss: 0.69136 - acc: 0.5583 -- iter: 384/407
[A[ATraining Step: 39  | total loss: [1m[32m0.69387[0m[0m | time: 8.488s
[2K
| Adam | epoch: 003 | loss: 0.69387 - acc: 0.5292 | val_loss: 0.69847 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 40  | total loss: [1m[32m0.69263[0m[0m | time: 0.591s
[2K
| Adam | epoch: 004 | loss: 0.69263 - acc: 0.5354 -- iter: 032/407
[A[ATraining Step: 41  | total loss: [1m[32m0.69068[0m[0m | time: 1.063s
[2K
| Adam | epoch: 004 | loss: 0.69068 - acc: 0.5519 -- iter: 064/407
[A[ATraining Step: 42  | total loss: [1m[32m0.69171[0m[0m | time: 1.505s
[2K
| Adam | epoch: 004 | loss: 0.69171 - acc: 0.5386 -- iter: 096/407
[A[ATraining Step: 43  | total loss: [1m[32m0.69242[0m[0m | time: 2.104s
[2K
| Adam | epoch: 004 | loss: 0.69242 - acc: 0.5280 -- iter: 128/407
[A[ATraining Step: 44  | total loss: [1m[32m0.69360[0m[0m | time: 2.702s
[2K
| Adam | epoch: 004 | loss: 0.69360 - acc: 0.5123 -- iter: 160/407
[A[ATraining Step: 45  | total loss: [1m[32m0.69137[0m[0m | time: 3.302s
[2K
| Adam | epoch: 004 | loss: 0.69137 - acc: 0.5368 -- iter: 192/407
[A[ATraining Step: 46  | total loss: [1m[32m0.69264[0m[0m | time: 3.903s
[2K
| Adam | epoch: 004 | loss: 0.69264 - acc: 0.5202 -- iter: 224/407
[A[ATraining Step: 47  | total loss: [1m[32m0.69199[0m[0m | time: 4.505s
[2K
| Adam | epoch: 004 | loss: 0.69199 - acc: 0.5271 -- iter: 256/407
[A[ATraining Step: 48  | total loss: [1m[32m0.69267[0m[0m | time: 5.098s
[2K
| Adam | epoch: 004 | loss: 0.69267 - acc: 0.5178 -- iter: 288/407
[A[ATraining Step: 49  | total loss: [1m[32m0.68938[0m[0m | time: 5.701s
[2K
| Adam | epoch: 004 | loss: 0.68938 - acc: 0.5594 -- iter: 320/407
[A[ATraining Step: 50  | total loss: [1m[32m0.68847[0m[0m | time: 6.303s
[2K
| Adam | epoch: 004 | loss: 0.68847 - acc: 0.5695 -- iter: 352/407
[A[ATraining Step: 51  | total loss: [1m[32m0.69011[0m[0m | time: 6.899s
[2K
| Adam | epoch: 004 | loss: 0.69011 - acc: 0.5494 -- iter: 384/407
[A[ATraining Step: 52  | total loss: [1m[32m0.69099[0m[0m | time: 8.506s
[2K
| Adam | epoch: 004 | loss: 0.69099 - acc: 0.5373 | val_loss: 0.69778 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 53  | total loss: [1m[32m0.69098[0m[0m | time: 0.604s
[2K
| Adam | epoch: 005 | loss: 0.69098 - acc: 0.5364 -- iter: 032/407
[A[ATraining Step: 54  | total loss: [1m[32m0.69133[0m[0m | time: 1.187s
[2K
| Adam | epoch: 005 | loss: 0.69133 - acc: 0.5311 -- iter: 064/407
[A[ATraining Step: 55  | total loss: [1m[32m0.69054[0m[0m | time: 1.629s
[2K
| Adam | epoch: 005 | loss: 0.69054 - acc: 0.5401 -- iter: 096/407
[A[ATraining Step: 56  | total loss: [1m[32m0.68799[0m[0m | time: 2.065s
[2K
| Adam | epoch: 005 | loss: 0.68799 - acc: 0.5681 -- iter: 128/407
[A[ATraining Step: 57  | total loss: [1m[32m0.68565[0m[0m | time: 2.660s
[2K
| Adam | epoch: 005 | loss: 0.68565 - acc: 0.5918 -- iter: 160/407
[A[ATraining Step: 58  | total loss: [1m[32m0.68582[0m[0m | time: 3.267s
[2K
| Adam | epoch: 005 | loss: 0.68582 - acc: 0.5878 -- iter: 192/407
[A[ATraining Step: 59  | total loss: [1m[32m0.68647[0m[0m | time: 3.873s
[2K
| Adam | epoch: 005 | loss: 0.68647 - acc: 0.5802 -- iter: 224/407
[A[ATraining Step: 60  | total loss: [1m[32m0.68547[0m[0m | time: 4.469s
[2K
| Adam | epoch: 005 | loss: 0.68547 - acc: 0.5861 -- iter: 256/407
[A[ATraining Step: 61  | total loss: [1m[32m0.68387[0m[0m | time: 5.073s
[2K
| Adam | epoch: 005 | loss: 0.68387 - acc: 0.5953 -- iter: 288/407
[A[ATraining Step: 62  | total loss: [1m[32m0.68799[0m[0m | time: 5.674s
[2K
| Adam | epoch: 005 | loss: 0.68799 - acc: 0.5669 -- iter: 320/407
[A[ATraining Step: 63  | total loss: [1m[32m0.68768[0m[0m | time: 6.266s
[2K
| Adam | epoch: 005 | loss: 0.68768 - acc: 0.5664 -- iter: 352/407
[A[ATraining Step: 64  | total loss: [1m[32m0.68888[0m[0m | time: 6.864s
[2K
| Adam | epoch: 005 | loss: 0.68888 - acc: 0.5581 -- iter: 384/407
[A[ATraining Step: 65  | total loss: [1m[32m0.68852[0m[0m | time: 8.457s
[2K
| Adam | epoch: 005 | loss: 0.68852 - acc: 0.5586 | val_loss: 0.70734 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 66  | total loss: [1m[32m0.68641[0m[0m | time: 0.623s
[2K
| Adam | epoch: 006 | loss: 0.68641 - acc: 0.5667 -- iter: 032/407
[A[ATraining Step: 67  | total loss: [1m[32m0.68310[0m[0m | time: 1.216s
[2K
| Adam | epoch: 006 | loss: 0.68310 - acc: 0.5812 -- iter: 064/407
[A[ATraining Step: 68  | total loss: [1m[32m0.68598[0m[0m | time: 1.822s
[2K
| Adam | epoch: 006 | loss: 0.68598 - acc: 0.5679 -- iter: 096/407
[A[ATraining Step: 69  | total loss: [1m[32m0.68584[0m[0m | time: 2.292s
[2K
| Adam | epoch: 006 | loss: 0.68584 - acc: 0.5672 -- iter: 128/407
[A[ATraining Step: 70  | total loss: [1m[32m0.68984[0m[0m | time: 2.741s
[2K
| Adam | epoch: 006 | loss: 0.68984 - acc: 0.5520 -- iter: 160/407
[A[ATraining Step: 71  | total loss: [1m[32m0.69298[0m[0m | time: 3.354s
[2K
| Adam | epoch: 006 | loss: 0.69298 - acc: 0.5386 -- iter: 192/407
[A[ATraining Step: 72  | total loss: [1m[32m0.69124[0m[0m | time: 3.951s
[2K
| Adam | epoch: 006 | loss: 0.69124 - acc: 0.5448 -- iter: 224/407
[A[ATraining Step: 73  | total loss: [1m[32m0.69346[0m[0m | time: 4.550s
[2K
| Adam | epoch: 006 | loss: 0.69346 - acc: 0.5329 -- iter: 256/407
[A[ATraining Step: 74  | total loss: [1m[32m0.69187[0m[0m | time: 5.127s
[2K
| Adam | epoch: 006 | loss: 0.69187 - acc: 0.5396 -- iter: 288/407
[A[ATraining Step: 75  | total loss: [1m[32m0.69368[0m[0m | time: 5.718s
[2K
| Adam | epoch: 006 | loss: 0.69368 - acc: 0.5285 -- iter: 320/407
[A[ATraining Step: 76  | total loss: [1m[32m0.69384[0m[0m | time: 6.310s
[2K
| Adam | epoch: 006 | loss: 0.69384 - acc: 0.5254 -- iter: 352/407
[A[ATraining Step: 77  | total loss: [1m[32m0.69350[0m[0m | time: 6.909s
[2K
| Adam | epoch: 006 | loss: 0.69350 - acc: 0.5261 -- iter: 384/407
[A[ATraining Step: 78  | total loss: [1m[32m0.69066[0m[0m | time: 8.522s
[2K
| Adam | epoch: 006 | loss: 0.69066 - acc: 0.5462 | val_loss: 0.70043 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 79  | total loss: [1m[32m0.69063[0m[0m | time: 0.594s
[2K
| Adam | epoch: 007 | loss: 0.69063 - acc: 0.5447 -- iter: 032/407
[A[ATraining Step: 80  | total loss: [1m[32m0.69142[0m[0m | time: 1.186s
[2K
| Adam | epoch: 007 | loss: 0.69142 - acc: 0.5369 -- iter: 064/407
[A[ATraining Step: 81  | total loss: [1m[32m0.69210[0m[0m | time: 1.775s
[2K
| Adam | epoch: 007 | loss: 0.69210 - acc: 0.5300 -- iter: 096/407
[A[ATraining Step: 82  | total loss: [1m[32m0.69225[0m[0m | time: 2.383s
[2K
| Adam | epoch: 007 | loss: 0.69225 - acc: 0.5270 -- iter: 128/407
[A[ATraining Step: 83  | total loss: [1m[32m0.69207[0m[0m | time: 2.830s
[2K
| Adam | epoch: 007 | loss: 0.69207 - acc: 0.5274 -- iter: 160/407
[A[ATraining Step: 84  | total loss: [1m[32m0.69196[0m[0m | time: 3.268s
[2K
| Adam | epoch: 007 | loss: 0.69196 - acc: 0.5269 -- iter: 192/407
[A[ATraining Step: 85  | total loss: [1m[32m0.69185[0m[0m | time: 3.870s
[2K
| Adam | epoch: 007 | loss: 0.69185 - acc: 0.5264 -- iter: 224/407
[A[ATraining Step: 86  | total loss: [1m[32m0.69201[0m[0m | time: 4.472s
[2K
| Adam | epoch: 007 | loss: 0.69201 - acc: 0.5237 -- iter: 256/407
[A[ATraining Step: 87  | total loss: [1m[32m0.69061[0m[0m | time: 5.067s
[2K
| Adam | epoch: 007 | loss: 0.69061 - acc: 0.5370 -- iter: 288/407
[A[ATraining Step: 88  | total loss: [1m[32m0.69028[0m[0m | time: 5.660s
[2K
| Adam | epoch: 007 | loss: 0.69028 - acc: 0.5395 -- iter: 320/407
[A[ATraining Step: 89  | total loss: [1m[32m0.69121[0m[0m | time: 6.261s
[2K
| Adam | epoch: 007 | loss: 0.69121 - acc: 0.5293 -- iter: 352/407
[A[ATraining Step: 90  | total loss: [1m[32m0.69023[0m[0m | time: 6.855s
[2K
| Adam | epoch: 007 | loss: 0.69023 - acc: 0.5389 -- iter: 384/407
[A[ATraining Step: 91  | total loss: [1m[32m0.68950[0m[0m | time: 8.451s
[2K
| Adam | epoch: 007 | loss: 0.68950 - acc: 0.5444 | val_loss: 0.69913 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 92  | total loss: [1m[32m0.68915[0m[0m | time: 0.607s
[2K
| Adam | epoch: 008 | loss: 0.68915 - acc: 0.5462 -- iter: 032/407
[A[ATraining Step: 93  | total loss: [1m[32m0.68711[0m[0m | time: 1.199s
[2K
| Adam | epoch: 008 | loss: 0.68711 - acc: 0.5634 -- iter: 064/407
[A[ATraining Step: 94  | total loss: [1m[32m0.68825[0m[0m | time: 1.797s
[2K
| Adam | epoch: 008 | loss: 0.68825 - acc: 0.5540 -- iter: 096/407
[A[ATraining Step: 95  | total loss: [1m[32m0.68828[0m[0m | time: 2.384s
[2K
| Adam | epoch: 008 | loss: 0.68828 - acc: 0.5517 -- iter: 128/407
[A[ATraining Step: 96  | total loss: [1m[32m0.68549[0m[0m | time: 2.992s
[2K
| Adam | epoch: 008 | loss: 0.68549 - acc: 0.5715 -- iter: 160/407
[A[ATraining Step: 97  | total loss: [1m[32m0.68637[0m[0m | time: 3.432s
[2K
| Adam | epoch: 008 | loss: 0.68637 - acc: 0.5644 -- iter: 192/407
[A[ATraining Step: 98  | total loss: [1m[32m0.68455[0m[0m | time: 3.870s
[2K
| Adam | epoch: 008 | loss: 0.68455 - acc: 0.5732 -- iter: 224/407
[A[ATraining Step: 99  | total loss: [1m[32m0.68276[0m[0m | time: 4.464s
[2K
| Adam | epoch: 008 | loss: 0.68276 - acc: 0.5811 -- iter: 256/407
[A[ATraining Step: 100  | total loss: [1m[32m0.68465[0m[0m | time: 5.059s
[2K
| Adam | epoch: 008 | loss: 0.68465 - acc: 0.5698 -- iter: 288/407
[A[ATraining Step: 101  | total loss: [1m[32m0.68207[0m[0m | time: 5.653s
[2K
| Adam | epoch: 008 | loss: 0.68207 - acc: 0.5785 -- iter: 320/407
[A[ATraining Step: 102  | total loss: [1m[32m0.68576[0m[0m | time: 6.265s
[2K
| Adam | epoch: 008 | loss: 0.68576 - acc: 0.5644 -- iter: 352/407
[A[ATraining Step: 103  | total loss: [1m[32m0.68547[0m[0m | time: 6.877s
[2K
| Adam | epoch: 008 | loss: 0.68547 - acc: 0.5642 -- iter: 384/407
[A[ATraining Step: 104  | total loss: [1m[32m0.68603[0m[0m | time: 8.476s
[2K
| Adam | epoch: 008 | loss: 0.68603 - acc: 0.5609 | val_loss: 0.71158 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 105  | total loss: [1m[32m0.69050[0m[0m | time: 0.624s
[2K
| Adam | epoch: 009 | loss: 0.69050 - acc: 0.5454 -- iter: 032/407
[A[ATraining Step: 106  | total loss: [1m[32m0.68904[0m[0m | time: 1.228s
[2K
| Adam | epoch: 009 | loss: 0.68904 - acc: 0.5503 -- iter: 064/407
[A[ATraining Step: 107  | total loss: [1m[32m0.68685[0m[0m | time: 1.837s
[2K
| Adam | epoch: 009 | loss: 0.68685 - acc: 0.5577 -- iter: 096/407
[A[ATraining Step: 108  | total loss: [1m[32m0.68553[0m[0m | time: 2.435s
[2K
| Adam | epoch: 009 | loss: 0.68553 - acc: 0.5613 -- iter: 128/407
[A[ATraining Step: 109  | total loss: [1m[32m0.68605[0m[0m | time: 3.029s
[2K
| Adam | epoch: 009 | loss: 0.68605 - acc: 0.5583 -- iter: 160/407
[A[ATraining Step: 110  | total loss: [1m[32m0.68718[0m[0m | time: 3.628s
[2K
| Adam | epoch: 009 | loss: 0.68718 - acc: 0.5525 -- iter: 192/407
[A[ATraining Step: 111  | total loss: [1m[32m0.68858[0m[0m | time: 4.065s
[2K
| Adam | epoch: 009 | loss: 0.68858 - acc: 0.5441 -- iter: 224/407
[A[ATraining Step: 112  | total loss: [1m[32m0.69067[0m[0m | time: 4.524s
[2K
| Adam | epoch: 009 | loss: 0.69067 - acc: 0.5332 -- iter: 256/407
[A[ATraining Step: 113  | total loss: [1m[32m0.69200[0m[0m | time: 5.138s
[2K
| Adam | epoch: 009 | loss: 0.69200 - acc: 0.5233 -- iter: 288/407
[A[ATraining Step: 114  | total loss: [1m[32m0.69084[0m[0m | time: 5.733s
[2K
| Adam | epoch: 009 | loss: 0.69084 - acc: 0.5304 -- iter: 320/407
[A[ATraining Step: 115  | total loss: [1m[32m0.69026[0m[0m | time: 6.323s
[2K
| Adam | epoch: 009 | loss: 0.69026 - acc: 0.5336 -- iter: 352/407
[A[ATraining Step: 116  | total loss: [1m[32m0.68979[0m[0m | time: 6.917s
[2K
| Adam | epoch: 009 | loss: 0.68979 - acc: 0.5365 -- iter: 384/407
[A[ATraining Step: 117  | total loss: [1m[32m0.68934[0m[0m | time: 8.520s
[2K
| Adam | epoch: 009 | loss: 0.68934 - acc: 0.5391 | val_loss: 0.69885 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 118  | total loss: [1m[32m0.68828[0m[0m | time: 0.601s
[2K
| Adam | epoch: 010 | loss: 0.68828 - acc: 0.5477 -- iter: 032/407
[A[ATraining Step: 119  | total loss: [1m[32m0.68755[0m[0m | time: 1.206s
[2K
| Adam | epoch: 010 | loss: 0.68755 - acc: 0.5523 -- iter: 064/407
[A[ATraining Step: 120  | total loss: [1m[32m0.68780[0m[0m | time: 1.804s
[2K
| Adam | epoch: 010 | loss: 0.68780 - acc: 0.5502 -- iter: 096/407
[A[ATraining Step: 121  | total loss: [1m[32m0.68725[0m[0m | time: 2.409s
[2K
| Adam | epoch: 010 | loss: 0.68725 - acc: 0.5514 -- iter: 128/407
[A[ATraining Step: 122  | total loss: [1m[32m0.68911[0m[0m | time: 3.023s
[2K
| Adam | epoch: 010 | loss: 0.68911 - acc: 0.5400 -- iter: 160/407
[A[ATraining Step: 123  | total loss: [1m[32m0.68444[0m[0m | time: 3.633s
[2K
| Adam | epoch: 010 | loss: 0.68444 - acc: 0.5610 -- iter: 192/407
[A[ATraining Step: 124  | total loss: [1m[32m0.68755[0m[0m | time: 4.219s
[2K
| Adam | epoch: 010 | loss: 0.68755 - acc: 0.5455 -- iter: 224/407
[A[ATraining Step: 125  | total loss: [1m[32m0.68520[0m[0m | time: 4.686s
[2K
| Adam | epoch: 010 | loss: 0.68520 - acc: 0.5535 -- iter: 256/407
[A[ATraining Step: 126  | total loss: [1m[32m0.68640[0m[0m | time: 5.130s
[2K
| Adam | epoch: 010 | loss: 0.68640 - acc: 0.5460 -- iter: 288/407
[A[ATraining Step: 127  | total loss: [1m[32m0.68723[0m[0m | time: 5.733s
[2K
| Adam | epoch: 010 | loss: 0.68723 - acc: 0.5392 -- iter: 320/407
[A[ATraining Step: 128  | total loss: [1m[32m0.68247[0m[0m | time: 6.321s
[2K
| Adam | epoch: 010 | loss: 0.68247 - acc: 0.5603 -- iter: 352/407
[A[ATraining Step: 129  | total loss: [1m[32m0.68111[0m[0m | time: 6.921s
[2K
| Adam | epoch: 010 | loss: 0.68111 - acc: 0.5605 -- iter: 384/407
[A[ATraining Step: 130  | total loss: [1m[32m0.67955[0m[0m | time: 8.514s
[2K
| Adam | epoch: 010 | loss: 0.67955 - acc: 0.5638 | val_loss: 0.71897 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 131  | total loss: [1m[32m0.67919[0m[0m | time: 0.603s
[2K
| Adam | epoch: 011 | loss: 0.67919 - acc: 0.5606 -- iter: 032/407
[A[ATraining Step: 132  | total loss: [1m[32m0.68189[0m[0m | time: 1.200s
[2K
| Adam | epoch: 011 | loss: 0.68189 - acc: 0.5545 -- iter: 064/407
[A[ATraining Step: 133  | total loss: [1m[32m0.68193[0m[0m | time: 1.800s
[2K
| Adam | epoch: 011 | loss: 0.68193 - acc: 0.5553 -- iter: 096/407
[A[ATraining Step: 134  | total loss: [1m[32m0.68588[0m[0m | time: 2.389s
[2K
| Adam | epoch: 011 | loss: 0.68588 - acc: 0.5404 -- iter: 128/407
[A[ATraining Step: 135  | total loss: [1m[32m0.68512[0m[0m | time: 2.972s
[2K
| Adam | epoch: 011 | loss: 0.68512 - acc: 0.5582 -- iter: 160/407
[A[ATraining Step: 136  | total loss: [1m[32m0.68527[0m[0m | time: 3.541s
[2K
| Adam | epoch: 011 | loss: 0.68527 - acc: 0.5587 -- iter: 192/407
[A[ATraining Step: 137  | total loss: [1m[32m0.68553[0m[0m | time: 4.140s
[2K
| Adam | epoch: 011 | loss: 0.68553 - acc: 0.5528 -- iter: 224/407
[A[ATraining Step: 138  | total loss: [1m[32m0.68470[0m[0m | time: 4.739s
[2K
| Adam | epoch: 011 | loss: 0.68470 - acc: 0.5569 -- iter: 256/407
[A[ATraining Step: 139  | total loss: [1m[32m0.68611[0m[0m | time: 5.180s
[2K
| Adam | epoch: 011 | loss: 0.68611 - acc: 0.5512 -- iter: 288/407
[A[ATraining Step: 140  | total loss: [1m[32m0.68465[0m[0m | time: 5.630s
[2K
| Adam | epoch: 011 | loss: 0.68465 - acc: 0.5613 -- iter: 320/407
[A[ATraining Step: 141  | total loss: [1m[32m0.68167[0m[0m | time: 6.223s
[2K
| Adam | epoch: 011 | loss: 0.68167 - acc: 0.5660 -- iter: 352/407
[A[ATraining Step: 142  | total loss: [1m[32m0.67858[0m[0m | time: 6.816s
[2K
| Adam | epoch: 011 | loss: 0.67858 - acc: 0.5688 -- iter: 384/407
[A[ATraining Step: 143  | total loss: [1m[32m0.68125[0m[0m | time: 8.402s
[2K
| Adam | epoch: 011 | loss: 0.68125 - acc: 0.5651 | val_loss: 0.72561 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 144  | total loss: [1m[32m0.69377[0m[0m | time: 0.571s
[2K
| Adam | epoch: 012 | loss: 0.69377 - acc: 0.5398 -- iter: 032/407
[A[ATraining Step: 145  | total loss: [1m[32m0.68680[0m[0m | time: 1.174s
[2K
| Adam | epoch: 012 | loss: 0.68680 - acc: 0.5546 -- iter: 064/407
[A[ATraining Step: 146  | total loss: [1m[32m0.68491[0m[0m | time: 1.769s
[2K
| Adam | epoch: 012 | loss: 0.68491 - acc: 0.5585 -- iter: 096/407
[A[ATraining Step: 147  | total loss: [1m[32m0.68272[0m[0m | time: 2.371s
[2K
| Adam | epoch: 012 | loss: 0.68272 - acc: 0.5620 -- iter: 128/407
[A[ATraining Step: 148  | total loss: [1m[32m0.68141[0m[0m | time: 2.966s
[2K
| Adam | epoch: 012 | loss: 0.68141 - acc: 0.5621 -- iter: 160/407
[A[ATraining Step: 149  | total loss: [1m[32m0.68160[0m[0m | time: 3.585s
[2K
| Adam | epoch: 012 | loss: 0.68160 - acc: 0.5559 -- iter: 192/407
[A[ATraining Step: 150  | total loss: [1m[32m0.67547[0m[0m | time: 4.189s
[2K
| Adam | epoch: 012 | loss: 0.67547 - acc: 0.5753 -- iter: 224/407
[A[ATraining Step: 151  | total loss: [1m[32m0.67681[0m[0m | time: 4.804s
[2K
| Adam | epoch: 012 | loss: 0.67681 - acc: 0.5677 -- iter: 256/407
[A[ATraining Step: 152  | total loss: [1m[32m0.68128[0m[0m | time: 5.394s
[2K
| Adam | epoch: 012 | loss: 0.68128 - acc: 0.5485 -- iter: 288/407
[A[ATraining Step: 153  | total loss: [1m[32m0.68038[0m[0m | time: 5.855s
[2K
| Adam | epoch: 012 | loss: 0.68038 - acc: 0.5467 -- iter: 320/407
[A[ATraining Step: 154  | total loss: [1m[32m0.68176[0m[0m | time: 6.297s
[2K
| Adam | epoch: 012 | loss: 0.68176 - acc: 0.5399 -- iter: 352/407
[A[ATraining Step: 155  | total loss: [1m[32m0.68281[0m[0m | time: 6.907s
[2K
| Adam | epoch: 012 | loss: 0.68281 - acc: 0.5337 -- iter: 384/407
[A[ATraining Step: 156  | total loss: [1m[32m0.68236[0m[0m | time: 8.506s
[2K
| Adam | epoch: 012 | loss: 0.68236 - acc: 0.5335 | val_loss: 0.69314 - val_acc: 0.4531 -- iter: 407/407
--
Training Step: 157  | total loss: [1m[32m0.68107[0m[0m | time: 0.594s
[2K
| Adam | epoch: 013 | loss: 0.68107 - acc: 0.5395 -- iter: 032/407
[A[ATraining Step: 158  | total loss: [1m[32m0.67981[0m[0m | time: 1.209s
[2K
| Adam | epoch: 013 | loss: 0.67981 - acc: 0.5418 -- iter: 064/407
[A[ATraining Step: 159  | total loss: [1m[32m0.67910[0m[0m | time: 1.828s
[2K
| Adam | epoch: 013 | loss: 0.67910 - acc: 0.5408 -- iter: 096/407
[A[ATraining Step: 160  | total loss: [1m[32m0.67822[0m[0m | time: 2.418s
[2K
| Adam | epoch: 013 | loss: 0.67822 - acc: 0.5429 -- iter: 128/407
[A[ATraining Step: 161  | total loss: [1m[32m0.67467[0m[0m | time: 3.037s
[2K
| Adam | epoch: 013 | loss: 0.67467 - acc: 0.5543 -- iter: 160/407
[A[ATraining Step: 162  | total loss: [1m[32m0.67165[0m[0m | time: 3.636s
[2K
| Adam | epoch: 013 | loss: 0.67165 - acc: 0.5582 -- iter: 192/407
[A[ATraining Step: 163  | total loss: [1m[32m0.67362[0m[0m | time: 4.231s
[2K
| Adam | epoch: 013 | loss: 0.67362 - acc: 0.5493 -- iter: 224/407
[A[ATraining Step: 164  | total loss: [1m[32m0.66960[0m[0m | time: 4.826s
[2K
| Adam | epoch: 013 | loss: 0.66960 - acc: 0.5568 -- iter: 256/407
[A[ATraining Step: 165  | total loss: [1m[32m0.66993[0m[0m | time: 5.401s
[2K
| Adam | epoch: 013 | loss: 0.66993 - acc: 0.5512 -- iter: 288/407
[A[ATraining Step: 166  | total loss: [1m[32m0.66805[0m[0m | time: 5.995s
[2K
| Adam | epoch: 013 | loss: 0.66805 - acc: 0.5585 -- iter: 320/407
[A[ATraining Step: 167  | total loss: [1m[32m0.67375[0m[0m | time: 6.434s
[2K
| Adam | epoch: 013 | loss: 0.67375 - acc: 0.5433 -- iter: 352/407
[A[ATraining Step: 168  | total loss: [1m[32m0.67320[0m[0m | time: 6.877s
[2K
| Adam | epoch: 013 | loss: 0.67320 - acc: 0.5412 -- iter: 384/407
[A[ATraining Step: 169  | total loss: [1m[32m0.67209[0m[0m | time: 8.477s
[2K
| Adam | epoch: 013 | loss: 0.67209 - acc: 0.5436 | val_loss: 0.67784 - val_acc: 0.6328 -- iter: 407/407
--
Training Step: 170  | total loss: [1m[32m0.67134[0m[0m | time: 0.606s
[2K
| Adam | epoch: 014 | loss: 0.67134 - acc: 0.5486 -- iter: 032/407
[A[ATraining Step: 171  | total loss: [1m[32m0.67161[0m[0m | time: 1.179s
[2K
| Adam | epoch: 014 | loss: 0.67161 - acc: 0.5562 -- iter: 064/407
[A[ATraining Step: 172  | total loss: [1m[32m0.67196[0m[0m | time: 1.766s
[2K
| Adam | epoch: 014 | loss: 0.67196 - acc: 0.5693 -- iter: 096/407
[A[ATraining Step: 173  | total loss: [1m[32m0.67091[0m[0m | time: 2.367s
[2K
| Adam | epoch: 014 | loss: 0.67091 - acc: 0.5812 -- iter: 128/407
[A[ATraining Step: 174  | total loss: [1m[32m0.66933[0m[0m | time: 2.970s
[2K
| Adam | epoch: 014 | loss: 0.66933 - acc: 0.5824 -- iter: 160/407
[A[ATraining Step: 175  | total loss: [1m[32m0.66095[0m[0m | time: 3.551s
[2K
| Adam | epoch: 014 | loss: 0.66095 - acc: 0.5961 -- iter: 192/407
[A[ATraining Step: 176  | total loss: [1m[32m0.66013[0m[0m | time: 4.150s
[2K
| Adam | epoch: 014 | loss: 0.66013 - acc: 0.5989 -- iter: 224/407
[A[ATraining Step: 177  | total loss: [1m[32m0.65463[0m[0m | time: 4.751s
[2K
| Adam | epoch: 014 | loss: 0.65463 - acc: 0.6016 -- iter: 256/407
[A[ATraining Step: 178  | total loss: [1m[32m0.66544[0m[0m | time: 5.341s
[2K
| Adam | epoch: 014 | loss: 0.66544 - acc: 0.5851 -- iter: 288/407
[A[ATraining Step: 179  | total loss: [1m[32m0.66338[0m[0m | time: 5.938s
[2K
| Adam | epoch: 014 | loss: 0.66338 - acc: 0.5829 -- iter: 320/407
[A[ATraining Step: 180  | total loss: [1m[32m0.65282[0m[0m | time: 6.538s
[2K
| Adam | epoch: 014 | loss: 0.65282 - acc: 0.5996 -- iter: 352/407
[A[ATraining Step: 181  | total loss: [1m[32m0.65176[0m[0m | time: 6.979s
[2K
| Adam | epoch: 014 | loss: 0.65176 - acc: 0.6021 -- iter: 384/407
[A[ATraining Step: 182  | total loss: [1m[32m0.65323[0m[0m | time: 8.416s
[2K
| Adam | epoch: 014 | loss: 0.65323 - acc: 0.6028 | val_loss: 0.65002 - val_acc: 0.5938 -- iter: 407/407
--
Training Step: 183  | total loss: [1m[32m0.65291[0m[0m | time: 0.605s
[2K
| Adam | epoch: 015 | loss: 0.65291 - acc: 0.6034 -- iter: 032/407
[A[ATraining Step: 184  | total loss: [1m[32m0.64400[0m[0m | time: 1.213s
[2K
| Adam | epoch: 015 | loss: 0.64400 - acc: 0.6180 -- iter: 064/407
[A[ATraining Step: 185  | total loss: [1m[32m0.64081[0m[0m | time: 1.821s
[2K
| Adam | epoch: 015 | loss: 0.64081 - acc: 0.6094 -- iter: 096/407
[A[ATraining Step: 186  | total loss: [1m[32m0.64370[0m[0m | time: 2.446s
[2K
| Adam | epoch: 015 | loss: 0.64370 - acc: 0.6016 -- iter: 128/407
[A[ATraining Step: 187  | total loss: [1m[32m0.63099[0m[0m | time: 3.074s
[2K
| Adam | epoch: 015 | loss: 0.63099 - acc: 0.6289 -- iter: 160/407
[A[ATraining Step: 188  | total loss: [1m[32m0.62926[0m[0m | time: 3.664s
[2K
| Adam | epoch: 015 | loss: 0.62926 - acc: 0.6316 -- iter: 192/407
[A[ATraining Step: 189  | total loss: [1m[32m0.61739[0m[0m | time: 4.262s
[2K
| Adam | epoch: 015 | loss: 0.61739 - acc: 0.6528 -- iter: 224/407
[A[ATraining Step: 190  | total loss: [1m[32m0.60629[0m[0m | time: 4.861s
[2K
| Adam | epoch: 015 | loss: 0.60629 - acc: 0.6594 -- iter: 256/407
[A[ATraining Step: 191  | total loss: [1m[32m0.60681[0m[0m | time: 5.458s
[2K
| Adam | epoch: 015 | loss: 0.60681 - acc: 0.6560 -- iter: 288/407
[A[ATraining Step: 192  | total loss: [1m[32m0.58962[0m[0m | time: 6.047s
[2K
| Adam | epoch: 015 | loss: 0.58962 - acc: 0.6810 -- iter: 320/407
[A[ATraining Step: 193  | total loss: [1m[32m0.58777[0m[0m | time: 6.644s
[2K
| Adam | epoch: 015 | loss: 0.58777 - acc: 0.6754 -- iter: 352/407
[A[ATraining Step: 194  | total loss: [1m[32m0.57483[0m[0m | time: 7.240s
[2K
| Adam | epoch: 015 | loss: 0.57483 - acc: 0.6829 -- iter: 384/407
[A[ATraining Step: 195  | total loss: [1m[32m0.56848[0m[0m | time: 8.685s
[2K
| Adam | epoch: 015 | loss: 0.56848 - acc: 0.6865 | val_loss: 0.50434 - val_acc: 0.7266 -- iter: 407/407
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.854679802955665
Validation AUPRC:0.8109960019294757
Test AUC:0.8377321603128054
Test AUPRC:0.824485252114193
BestTestF1Score	0.8	0.58	0.77	0.7	0.92	57	24	42	5	0.36
BestTestMCCScore	0.8	0.58	0.77	0.7	0.92	57	24	42	5	0.36
BestTestAccuracyScore	0.76	0.51	0.75	0.71	0.81	50	20	46	12	0.43
BestValidationF1Score	0.78	0.58	0.76	0.66	0.97	56	29	41	2	0.36
BestValidationMCC	0.78	0.58	0.76	0.66	0.97	56	29	41	2	0.36
BestValidationAccuracy	0.78	0.57	0.78	0.72	0.84	49	19	51	9	0.43
TestPredictions (Threshold:0.36)
CHEMBL229907,TP,ACT,0.6399999856948853	CHEMBL501349,TP,ACT,0.3799999952316284	CHEMBL258909,FP,INACT,0.4399999976158142	CHEMBL3597875,FP,INACT,0.5299999713897705	CHEMBL1632430,FP,INACT,0.6899999976158142	CHEMBL2449339,TN,INACT,0.1899999976158142	CHEMBL1215575,TN,INACT,0.23999999463558197	CHEMBL3765052,TN,INACT,0.25	CHEMBL2449532,TN,INACT,0.17000000178813934	CHEMBL2420083,TP,ACT,0.7599999904632568	CHEMBL2449552,FP,INACT,0.7699999809265137	CHEMBL28,TP,ACT,0.4000000059604645	CHEMBL1945511,TN,INACT,0.20000000298023224	CHEMBL54349,TN,INACT,0.25999999046325684	CHEMBL1779525,TP,ACT,0.9200000166893005	CHEMBL1689341,TP,ACT,0.6700000166893005	CHEMBL1685074,FP,INACT,0.5699999928474426	CHEMBL308954,FN,ACT,0.23000000417232513	CHEMBL552560,TN,INACT,0.2800000011920929	CHEMBL1935222,TP,ACT,0.5199999809265137	CHEMBL258575,FP,INACT,0.5299999713897705	CHEMBL396298,TP,ACT,0.44999998807907104	CHEMBL337309,FP,INACT,0.4399999976158142	CHEMBL474972,TP,ACT,0.5099999904632568	CHEMBL405022,TP,ACT,0.5400000214576721	CHEMBL363325,TN,INACT,0.33000001311302185	CHEMBL2286725,TN,INACT,0.20000000298023224	CHEMBL1935220,TP,ACT,0.4300000071525574	CHEMBL3582156,TP,ACT,0.8199999928474426	CHEMBL1935219,TP,ACT,0.4099999964237213	CHEMBL1779524,TP,ACT,0.9200000166893005	CHEMBL411951,TP,ACT,0.46000000834465027	CHEMBL471170,TN,INACT,0.3499999940395355	CHEMBL551696,FN,ACT,0.2800000011920929	CHEMBL502503,TP,ACT,0.9599999785423279	CHEMBL3426397,TP,ACT,0.4699999988079071	CHEMBL3747767,TP,ACT,0.5600000023841858	CHEMBL1946565,FP,INACT,0.6200000047683716	CHEMBL3746770,TP,ACT,0.5	CHEMBL575808,TP,ACT,0.75	CHEMBL3426465,FP,INACT,0.6899999976158142	CHEMBL103,TN,INACT,0.3199999928474426	CHEMBL3765024,TN,INACT,0.18000000715255737	CHEMBL3110299,TP,ACT,0.7599999904632568	CHEMBL3650431,TN,INACT,0.25	CHEMBL1097450,FP,INACT,0.47999998927116394	CHEMBL3344541,TP,ACT,0.7400000095367432	CHEMBL3746992,TP,ACT,0.41999998688697815	CHEMBL452565,TN,INACT,0.25	CHEMBL3092501,TP,ACT,0.5699999928474426	CHEMBL474757,FP,INACT,0.4699999988079071	CHEMBL3764197,TN,INACT,0.20000000298023224	CHEMBL2331722,TP,ACT,0.8600000143051147	CHEMBL601642,TN,INACT,0.3400000035762787	CHEMBL27834,TN,INACT,0.30000001192092896	CHEMBL561227,TN,INACT,0.28999999165534973	CHEMBL3092486,TP,ACT,0.4399999976158142	CHEMBL116438,FP,INACT,0.46000000834465027	CHEMBL3092489,TP,ACT,0.49000000953674316	CHEMBL3582167,TP,ACT,0.6700000166893005	CHEMBL772,FP,INACT,0.699999988079071	CHEMBL452564,TN,INACT,0.25	CHEMBL260654,TP,ACT,0.6499999761581421	CHEMBL513552,TN,INACT,0.20999999344348907	CHEMBL82279,FP,INACT,0.36000001430511475	CHEMBL242513,FN,ACT,0.3499999940395355	CHEMBL3426398,TP,ACT,0.5799999833106995	CHEMBL1957192,TP,ACT,0.5199999809265137	CHEMBL1215714,FP,INACT,0.8100000023841858	CHEMBL3342121,TP,ACT,0.8199999928474426	CHEMBL1945986,TN,INACT,0.17000000178813934	CHEMBL408709,TN,INACT,0.3499999940395355	CHEMBL2158544,TP,ACT,0.8500000238418579	CHEMBL1215713,FP,INACT,0.46000000834465027	CHEMBL560229,TN,INACT,0.33000001311302185	CHEMBL1241992,FP,INACT,0.7200000286102295	CHEMBL144625,FN,ACT,0.25999999046325684	CHEMBL893,FP,INACT,0.6700000166893005	CHEMBL82459,TN,INACT,0.27000001072883606	CHEMBL2449307,TN,INACT,0.27000001072883606	CHEMBL2335007,TP,ACT,0.8799999952316284	CHEMBL6,FP,INACT,0.5799999833106995	CHEMBL2011288,TP,ACT,0.9599999785423279	CHEMBL3746458,TP,ACT,0.7400000095367432	CHEMBL2449528,TN,INACT,0.33000001311302185	CHEMBL258456,TN,INACT,0.3499999940395355	CHEMBL2449521,TN,INACT,0.2199999988079071	CHEMBL216198,FP,INACT,0.5699999928474426	CHEMBL150,TP,ACT,0.4399999976158142	CHEMBL3808612,TP,ACT,0.9100000262260437	CHEMBL3314525,TN,INACT,0.27000001072883606	CHEMBL453516,TP,ACT,0.7699999809265137	CHEMBL243167,TP,ACT,0.7799999713897705	CHEMBL3342122,TP,ACT,0.7300000190734863	CHEMBL3426482,TN,INACT,0.15000000596046448	CHEMBL490549,TN,INACT,0.2199999988079071	CHEMBL3426396,TP,ACT,0.6600000262260437	CHEMBL3092488,TP,ACT,0.49000000953674316	CHEMBL406597,FN,ACT,0.30000001192092896	CHEMBL2158556,TP,ACT,0.4000000059604645	CHEMBL138662,TP,ACT,0.6600000262260437	CHEMBL1688198,TN,INACT,0.27000001072883606	CHEMBL2331725,TP,ACT,0.949999988079071	CHEMBL3092500,TP,ACT,0.46000000834465027	CHEMBL3353421,FP,INACT,0.38999998569488525	CHEMBL3426448,TN,INACT,0.20999999344348907	CHEMBL1945978,TN,INACT,0.17000000178813934	CHEMBL2449331,TN,INACT,0.20000000298023224	CHEMBL165509,TP,ACT,0.38999998569488525	CHEMBL2449312,TN,INACT,0.1899999976158142	CHEMBL508803,TN,INACT,0.20999999344348907	CHEMBL1215576,TN,INACT,0.2199999988079071	CHEMBL3426393,TP,ACT,0.6700000166893005	CHEMBL147997,TN,INACT,0.1899999976158142	CHEMBL500094,TP,ACT,0.9700000286102295	CHEMBL410316,TP,ACT,0.6100000143051147	CHEMBL486633,FP,INACT,0.3700000047683716	CHEMBL595493,TP,ACT,0.75	CHEMBL259789,FP,INACT,0.4099999964237213	CHEMBL1945513,TN,INACT,0.20000000298023224	CHEMBL2331719,TP,ACT,0.8600000143051147	CHEMBL3110296,TP,ACT,0.9200000166893005	CHEMBL3110293,TP,ACT,0.6800000071525574	CHEMBL3092499,TP,ACT,0.3700000047683716	CHEMBL260896,FP,INACT,0.5199999809265137	CHEMBL2449349,TN,INACT,0.1899999976158142	CHEMBL226968,TN,INACT,0.33000001311302185	CHEMBL2420092,TP,ACT,0.6200000047683716	

