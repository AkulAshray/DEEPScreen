CNNModel CHEMBL3048 adam 0.001 15 128 0 0.8 False True
Number of active compounds :	371
Number of inactive compounds :	371
---------------------------------
Run id: CNNModel_CHEMBL3048_adam_0.001_15_128_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3048_adam_0.001_15_128_0.8_True/
---------------------------------
Training samples: 457
Validation samples: 143
--
Training Step: 1  | time: 2.307s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/457
[A[ATraining Step: 2  | total loss: [1m[32m0.62398[0m[0m | time: 3.880s
[2K
| Adam | epoch: 001 | loss: 0.62398 - acc: 0.4219 -- iter: 064/457
[A[ATraining Step: 3  | total loss: [1m[32m0.67863[0m[0m | time: 5.429s
[2K
| Adam | epoch: 001 | loss: 0.67863 - acc: 0.5625 -- iter: 096/457
[A[ATraining Step: 4  | total loss: [1m[32m0.70344[0m[0m | time: 7.341s
[2K
| Adam | epoch: 001 | loss: 0.70344 - acc: 0.4219 -- iter: 128/457
[A[ATraining Step: 5  | total loss: [1m[32m0.70036[0m[0m | time: 10.676s
[2K
| Adam | epoch: 001 | loss: 0.70036 - acc: 0.4111 -- iter: 160/457
[A[ATraining Step: 6  | total loss: [1m[32m0.69374[0m[0m | time: 13.897s
[2K
| Adam | epoch: 001 | loss: 0.69374 - acc: 0.5486 -- iter: 192/457
[A[ATraining Step: 7  | total loss: [1m[32m0.69165[0m[0m | time: 15.237s
[2K
| Adam | epoch: 001 | loss: 0.69165 - acc: 0.6132 -- iter: 224/457
[A[ATraining Step: 8  | total loss: [1m[32m0.69284[0m[0m | time: 16.731s
[2K
| Adam | epoch: 001 | loss: 0.69284 - acc: 0.5319 -- iter: 256/457
[A[ATraining Step: 9  | total loss: [1m[32m0.69231[0m[0m | time: 18.436s
[2K
| Adam | epoch: 001 | loss: 0.69231 - acc: 0.5481 -- iter: 288/457
[A[ATraining Step: 10  | total loss: [1m[32m0.69387[0m[0m | time: 20.004s
[2K
| Adam | epoch: 001 | loss: 0.69387 - acc: 0.4772 -- iter: 320/457
[A[ATraining Step: 11  | total loss: [1m[32m0.69460[0m[0m | time: 21.523s
[2K
| Adam | epoch: 001 | loss: 0.69460 - acc: 0.4436 -- iter: 352/457
[A[ATraining Step: 12  | total loss: [1m[32m0.69542[0m[0m | time: 23.078s
[2K
| Adam | epoch: 001 | loss: 0.69542 - acc: 0.3987 -- iter: 384/457
[A[ATraining Step: 13  | total loss: [1m[32m0.69446[0m[0m | time: 24.839s
[2K
| Adam | epoch: 001 | loss: 0.69446 - acc: 0.4421 -- iter: 416/457
[A[ATraining Step: 14  | total loss: [1m[32m0.69359[0m[0m | time: 26.473s
[2K
| Adam | epoch: 001 | loss: 0.69359 - acc: 0.4913 -- iter: 448/457
[A[ATraining Step: 15  | total loss: [1m[32m0.69328[0m[0m | time: 28.537s
[2K
| Adam | epoch: 001 | loss: 0.69328 - acc: 0.5070 | val_loss: 0.69329 - val_acc: 0.4895 -- iter: 457/457
--
Training Step: 16  | total loss: [1m[32m0.69293[0m[0m | time: 0.551s
[2K
| Adam | epoch: 002 | loss: 0.69293 - acc: 0.5252 -- iter: 032/457
[A[ATraining Step: 17  | total loss: [1m[32m0.69282[0m[0m | time: 2.263s
[2K
| Adam | epoch: 002 | loss: 0.69282 - acc: 0.5361 -- iter: 064/457
[A[ATraining Step: 18  | total loss: [1m[32m0.69229[0m[0m | time: 6.222s
[2K
| Adam | epoch: 002 | loss: 0.69229 - acc: 0.5777 -- iter: 096/457
[A[ATraining Step: 19  | total loss: [1m[32m0.69182[0m[0m | time: 9.531s
[2K
| Adam | epoch: 002 | loss: 0.69182 - acc: 0.6039 -- iter: 128/457
[A[ATraining Step: 20  | total loss: [1m[32m0.69336[0m[0m | time: 10.927s
[2K
| Adam | epoch: 002 | loss: 0.69336 - acc: 0.5102 -- iter: 160/457
[A[ATraining Step: 21  | total loss: [1m[32m0.69258[0m[0m | time: 12.353s
[2K
| Adam | epoch: 002 | loss: 0.69258 - acc: 0.5458 -- iter: 192/457
[A[ATraining Step: 22  | total loss: [1m[32m0.69199[0m[0m | time: 13.877s
[2K
| Adam | epoch: 002 | loss: 0.69199 - acc: 0.5696 -- iter: 224/457
[A[ATraining Step: 23  | total loss: [1m[32m0.69384[0m[0m | time: 15.402s
[2K
| Adam | epoch: 002 | loss: 0.69384 - acc: 0.4859 -- iter: 256/457
[A[ATraining Step: 24  | total loss: [1m[32m0.69429[0m[0m | time: 16.795s
[2K
| Adam | epoch: 002 | loss: 0.69429 - acc: 0.4635 -- iter: 288/457
[A[ATraining Step: 25  | total loss: [1m[32m0.69362[0m[0m | time: 18.286s
[2K
| Adam | epoch: 002 | loss: 0.69362 - acc: 0.4905 -- iter: 320/457
[A[ATraining Step: 26  | total loss: [1m[32m0.69372[0m[0m | time: 19.997s
[2K
| Adam | epoch: 002 | loss: 0.69372 - acc: 0.4847 -- iter: 352/457
[A[ATraining Step: 27  | total loss: [1m[32m0.69304[0m[0m | time: 21.652s
[2K
| Adam | epoch: 002 | loss: 0.69304 - acc: 0.5128 -- iter: 384/457
[A[ATraining Step: 28  | total loss: [1m[32m0.69273[0m[0m | time: 23.179s
[2K
| Adam | epoch: 002 | loss: 0.69273 - acc: 0.5252 -- iter: 416/457
[A[ATraining Step: 29  | total loss: [1m[32m0.69265[0m[0m | time: 24.572s
[2K
| Adam | epoch: 002 | loss: 0.69265 - acc: 0.5267 -- iter: 448/457
[A[ATraining Step: 30  | total loss: [1m[32m0.69297[0m[0m | time: 27.689s
[2K
| Adam | epoch: 002 | loss: 0.69297 - acc: 0.5130 | val_loss: 0.69346 - val_acc: 0.4895 -- iter: 457/457
--
Training Step: 31  | total loss: [1m[32m0.69406[0m[0m | time: 0.737s
[2K
| Adam | epoch: 003 | loss: 0.69406 - acc: 0.4667 -- iter: 032/457
[A[ATraining Step: 32  | total loss: [1m[32m0.69414[0m[0m | time: 2.004s
[2K
| Adam | epoch: 003 | loss: 0.69414 - acc: 0.4617 -- iter: 064/457
[A[ATraining Step: 33  | total loss: [1m[32m0.69421[0m[0m | time: 3.501s
[2K
| Adam | epoch: 003 | loss: 0.69421 - acc: 0.4579 -- iter: 096/457
[A[ATraining Step: 34  | total loss: [1m[32m0.69368[0m[0m | time: 4.905s
[2K
| Adam | epoch: 003 | loss: 0.69368 - acc: 0.4803 -- iter: 128/457
[A[ATraining Step: 35  | total loss: [1m[32m0.69333[0m[0m | time: 6.461s
[2K
| Adam | epoch: 003 | loss: 0.69333 - acc: 0.4975 -- iter: 160/457
[A[ATraining Step: 36  | total loss: [1m[32m0.69345[0m[0m | time: 8.079s
[2K
| Adam | epoch: 003 | loss: 0.69345 - acc: 0.4916 -- iter: 192/457
[A[ATraining Step: 37  | total loss: [1m[32m0.69293[0m[0m | time: 9.541s
[2K
| Adam | epoch: 003 | loss: 0.69293 - acc: 0.5183 -- iter: 224/457
[A[ATraining Step: 38  | total loss: [1m[32m0.69344[0m[0m | time: 11.056s
[2K
| Adam | epoch: 003 | loss: 0.69344 - acc: 0.4903 -- iter: 256/457
[A[ATraining Step: 39  | total loss: [1m[32m0.69385[0m[0m | time: 12.699s
[2K
| Adam | epoch: 003 | loss: 0.69385 - acc: 0.4682 -- iter: 288/457
[A[ATraining Step: 40  | total loss: [1m[32m0.69342[0m[0m | time: 14.457s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.4917 -- iter: 320/457
[A[ATraining Step: 41  | total loss: [1m[32m0.69347[0m[0m | time: 15.926s
[2K
| Adam | epoch: 003 | loss: 0.69347 - acc: 0.4875 -- iter: 352/457
[A[ATraining Step: 42  | total loss: [1m[32m0.69342[0m[0m | time: 17.419s
[2K
| Adam | epoch: 003 | loss: 0.69342 - acc: 0.4898 -- iter: 384/457
[A[ATraining Step: 43  | total loss: [1m[32m0.69364[0m[0m | time: 18.885s
[2K
| Adam | epoch: 003 | loss: 0.69364 - acc: 0.4750 -- iter: 416/457
[A[ATraining Step: 44  | total loss: [1m[32m0.69305[0m[0m | time: 20.518s
[2K
| Adam | epoch: 003 | loss: 0.69305 - acc: 0.5172 -- iter: 448/457
[A[ATraining Step: 45  | total loss: [1m[32m0.69301[0m[0m | time: 23.355s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5196 | val_loss: 0.69331 - val_acc: 0.4895 -- iter: 457/457
--
Training Step: 46  | total loss: [1m[32m0.69317[0m[0m | time: 1.453s
[2K
| Adam | epoch: 004 | loss: 0.69317 - acc: 0.5059 -- iter: 032/457
[A[ATraining Step: 47  | total loss: [1m[32m0.69323[0m[0m | time: 1.925s
[2K
| Adam | epoch: 004 | loss: 0.69323 - acc: 0.4998 -- iter: 064/457
[A[ATraining Step: 48  | total loss: [1m[32m0.69233[0m[0m | time: 2.387s
[2K
| Adam | epoch: 004 | loss: 0.69233 - acc: 0.5624 -- iter: 096/457
[A[ATraining Step: 49  | total loss: [1m[32m0.69143[0m[0m | time: 3.951s
[2K
| Adam | epoch: 004 | loss: 0.69143 - acc: 0.6139 -- iter: 128/457
[A[ATraining Step: 50  | total loss: [1m[32m0.69182[0m[0m | time: 5.415s
[2K
| Adam | epoch: 004 | loss: 0.69182 - acc: 0.5914 -- iter: 160/457
[A[ATraining Step: 51  | total loss: [1m[32m0.69178[0m[0m | time: 6.991s
[2K
| Adam | epoch: 004 | loss: 0.69178 - acc: 0.5870 -- iter: 192/457
[A[ATraining Step: 52  | total loss: [1m[32m0.69229[0m[0m | time: 8.509s
[2K
| Adam | epoch: 004 | loss: 0.69229 - acc: 0.5646 -- iter: 224/457
[A[ATraining Step: 53  | total loss: [1m[32m0.69290[0m[0m | time: 10.112s
[2K
| Adam | epoch: 004 | loss: 0.69290 - acc: 0.5412 -- iter: 256/457
[A[ATraining Step: 54  | total loss: [1m[32m0.69246[0m[0m | time: 11.694s
[2K
| Adam | epoch: 004 | loss: 0.69246 - acc: 0.5488 -- iter: 288/457
[A[ATraining Step: 55  | total loss: [1m[32m0.69293[0m[0m | time: 13.329s
[2K
| Adam | epoch: 004 | loss: 0.69293 - acc: 0.5329 -- iter: 320/457
[A[ATraining Step: 56  | total loss: [1m[32m0.69313[0m[0m | time: 15.006s
[2K
| Adam | epoch: 004 | loss: 0.69313 - acc: 0.5239 -- iter: 352/457
[A[ATraining Step: 57  | total loss: [1m[32m0.69365[0m[0m | time: 16.570s
[2K
| Adam | epoch: 004 | loss: 0.69365 - acc: 0.5076 -- iter: 384/457
[A[ATraining Step: 58  | total loss: [1m[32m0.69328[0m[0m | time: 18.167s
[2K
| Adam | epoch: 004 | loss: 0.69328 - acc: 0.5151 -- iter: 416/457
[A[ATraining Step: 59  | total loss: [1m[32m0.69325[0m[0m | time: 19.612s
[2K
| Adam | epoch: 004 | loss: 0.69325 - acc: 0.5131 -- iter: 448/457
[A[ATraining Step: 60  | total loss: [1m[32m0.69278[0m[0m | time: 22.349s
[2K
| Adam | epoch: 004 | loss: 0.69278 - acc: 0.5237 | val_loss: 0.69365 - val_acc: 0.4895 -- iter: 457/457
--
Training Step: 61  | total loss: [1m[32m0.69301[0m[0m | time: 1.491s
[2K
| Adam | epoch: 005 | loss: 0.69301 - acc: 0.5166 -- iter: 032/457
[A[ATraining Step: 62  | total loss: [1m[32m0.69334[0m[0m | time: 3.163s
[2K
| Adam | epoch: 005 | loss: 0.69334 - acc: 0.5064 -- iter: 064/457
[A[ATraining Step: 63  | total loss: [1m[32m0.69267[0m[0m | time: 3.713s
[2K
| Adam | epoch: 005 | loss: 0.69267 - acc: 0.5214 -- iter: 096/457
[A[ATraining Step: 64  | total loss: [1m[32m0.69295[0m[0m | time: 4.314s
[2K
| Adam | epoch: 005 | loss: 0.69295 - acc: 0.5118 -- iter: 128/457
[A[ATraining Step: 65  | total loss: [1m[32m0.69320[0m[0m | time: 5.788s
[2K
| Adam | epoch: 005 | loss: 0.69320 - acc: 0.5035 -- iter: 160/457
[A[ATraining Step: 66  | total loss: [1m[32m0.69317[0m[0m | time: 7.261s
[2K
| Adam | epoch: 005 | loss: 0.69317 - acc: 0.5031 -- iter: 192/457
[A[ATraining Step: 67  | total loss: [1m[32m0.69348[0m[0m | time: 8.939s
[2K
| Adam | epoch: 005 | loss: 0.69348 - acc: 0.4952 -- iter: 224/457
[A[ATraining Step: 68  | total loss: [1m[32m0.69325[0m[0m | time: 10.573s
[2K
| Adam | epoch: 005 | loss: 0.69325 - acc: 0.4995 -- iter: 256/457
[A[ATraining Step: 69  | total loss: [1m[32m0.69299[0m[0m | time: 12.154s
[2K
| Adam | epoch: 005 | loss: 0.69299 - acc: 0.5032 -- iter: 288/457
[A[ATraining Step: 70  | total loss: [1m[32m0.69286[0m[0m | time: 13.604s
[2K
| Adam | epoch: 005 | loss: 0.69286 - acc: 0.5028 -- iter: 320/457
[A[ATraining Step: 71  | total loss: [1m[32m0.69316[0m[0m | time: 15.032s
[2K
| Adam | epoch: 005 | loss: 0.69316 - acc: 0.4954 -- iter: 352/457
[A[ATraining Step: 72  | total loss: [1m[32m0.69254[0m[0m | time: 16.609s
[2K
| Adam | epoch: 005 | loss: 0.69254 - acc: 0.5029 -- iter: 384/457
[A[ATraining Step: 73  | total loss: [1m[32m0.69159[0m[0m | time: 18.072s
[2K
| Adam | epoch: 005 | loss: 0.69159 - acc: 0.5130 -- iter: 416/457
[A[ATraining Step: 74  | total loss: [1m[32m0.69121[0m[0m | time: 19.691s
[2K
| Adam | epoch: 005 | loss: 0.69121 - acc: 0.5150 -- iter: 448/457
[A[ATraining Step: 75  | total loss: [1m[32m0.69084[0m[0m | time: 22.483s
[2K
| Adam | epoch: 005 | loss: 0.69084 - acc: 0.5134 | val_loss: 0.69173 - val_acc: 0.4895 -- iter: 457/457
--
Training Step: 76  | total loss: [1m[32m0.69343[0m[0m | time: 1.675s
[2K
| Adam | epoch: 006 | loss: 0.69343 - acc: 0.4986 -- iter: 032/457
[A[ATraining Step: 77  | total loss: [1m[32m0.69239[0m[0m | time: 3.516s
[2K
| Adam | epoch: 006 | loss: 0.69239 - acc: 0.5020 -- iter: 064/457
[A[ATraining Step: 78  | total loss: [1m[32m0.69080[0m[0m | time: 5.009s
[2K
| Adam | epoch: 006 | loss: 0.69080 - acc: 0.5149 -- iter: 096/457
[A[ATraining Step: 79  | total loss: [1m[32m0.69093[0m[0m | time: 5.468s
[2K
| Adam | epoch: 006 | loss: 0.69093 - acc: 0.5069 -- iter: 128/457
[A[ATraining Step: 80  | total loss: [1m[32m0.69000[0m[0m | time: 5.931s
[2K
| Adam | epoch: 006 | loss: 0.69000 - acc: 0.5005 -- iter: 160/457
[A[ATraining Step: 81  | total loss: [1m[32m0.68912[0m[0m | time: 7.702s
[2K
| Adam | epoch: 006 | loss: 0.68912 - acc: 0.4948 -- iter: 192/457
[A[ATraining Step: 82  | total loss: [1m[32m0.69028[0m[0m | time: 9.242s
[2K
| Adam | epoch: 006 | loss: 0.69028 - acc: 0.4891 -- iter: 224/457
[A[ATraining Step: 83  | total loss: [1m[32m0.68762[0m[0m | time: 10.790s
[2K
| Adam | epoch: 006 | loss: 0.68762 - acc: 0.4933 -- iter: 256/457
[A[ATraining Step: 84  | total loss: [1m[32m0.68779[0m[0m | time: 12.347s
[2K
| Adam | epoch: 006 | loss: 0.68779 - acc: 0.4877 -- iter: 288/457
[A[ATraining Step: 85  | total loss: [1m[32m0.68484[0m[0m | time: 14.118s
[2K
| Adam | epoch: 006 | loss: 0.68484 - acc: 0.4952 -- iter: 320/457
[A[ATraining Step: 86  | total loss: [1m[32m0.68190[0m[0m | time: 15.730s
[2K
| Adam | epoch: 006 | loss: 0.68190 - acc: 0.5051 -- iter: 352/457
[A[ATraining Step: 87  | total loss: [1m[32m0.67414[0m[0m | time: 17.152s
[2K
| Adam | epoch: 006 | loss: 0.67414 - acc: 0.5108 -- iter: 384/457
[A[ATraining Step: 88  | total loss: [1m[32m0.67772[0m[0m | time: 18.491s
[2K
| Adam | epoch: 006 | loss: 0.67772 - acc: 0.5066 -- iter: 416/457
[A[ATraining Step: 89  | total loss: [1m[32m0.67219[0m[0m | time: 20.090s
[2K
| Adam | epoch: 006 | loss: 0.67219 - acc: 0.5184 -- iter: 448/457
[A[ATraining Step: 90  | total loss: [1m[32m0.67291[0m[0m | time: 23.209s
[2K
| Adam | epoch: 006 | loss: 0.67291 - acc: 0.5010 | val_loss: 0.66853 - val_acc: 0.5455 -- iter: 457/457
--
Training Step: 91  | total loss: [1m[32m0.66749[0m[0m | time: 1.640s
[2K
| Adam | epoch: 007 | loss: 0.66749 - acc: 0.5228 -- iter: 032/457
[A[ATraining Step: 92  | total loss: [1m[32m0.66362[0m[0m | time: 3.138s
[2K
| Adam | epoch: 007 | loss: 0.66362 - acc: 0.5299 -- iter: 064/457
[A[ATraining Step: 93  | total loss: [1m[32m0.65271[0m[0m | time: 4.767s
[2K
| Adam | epoch: 007 | loss: 0.65271 - acc: 0.5519 -- iter: 096/457
[A[ATraining Step: 94  | total loss: [1m[32m0.64812[0m[0m | time: 6.213s
[2K
| Adam | epoch: 007 | loss: 0.64812 - acc: 0.5654 -- iter: 128/457
[A[ATraining Step: 95  | total loss: [1m[32m0.65217[0m[0m | time: 6.882s
[2K
| Adam | epoch: 007 | loss: 0.65217 - acc: 0.5776 -- iter: 160/457
[A[ATraining Step: 96  | total loss: [1m[32m0.65178[0m[0m | time: 7.483s
[2K
| Adam | epoch: 007 | loss: 0.65178 - acc: 0.5977 -- iter: 192/457
[A[ATraining Step: 97  | total loss: [1m[32m0.65116[0m[0m | time: 12.699s
[2K
| Adam | epoch: 007 | loss: 0.65116 - acc: 0.6046 -- iter: 224/457
[A[ATraining Step: 98  | total loss: [1m[32m0.64499[0m[0m | time: 14.051s
[2K
| Adam | epoch: 007 | loss: 0.64499 - acc: 0.6160 -- iter: 256/457
[A[ATraining Step: 99  | total loss: [1m[32m0.63964[0m[0m | time: 15.549s
[2K
| Adam | epoch: 007 | loss: 0.63964 - acc: 0.6231 -- iter: 288/457
[A[ATraining Step: 100  | total loss: [1m[32m0.64112[0m[0m | time: 17.085s
[2K
| Adam | epoch: 007 | loss: 0.64112 - acc: 0.6264 -- iter: 320/457
[A[ATraining Step: 101  | total loss: [1m[32m0.64285[0m[0m | time: 18.480s
[2K
| Adam | epoch: 007 | loss: 0.64285 - acc: 0.6232 -- iter: 352/457
[A[ATraining Step: 102  | total loss: [1m[32m0.64038[0m[0m | time: 19.958s
[2K
| Adam | epoch: 007 | loss: 0.64038 - acc: 0.6296 -- iter: 384/457
[A[ATraining Step: 103  | total loss: [1m[32m0.63153[0m[0m | time: 21.697s
[2K
| Adam | epoch: 007 | loss: 0.63153 - acc: 0.6416 -- iter: 416/457
[A[ATraining Step: 104  | total loss: [1m[32m0.62128[0m[0m | time: 23.349s
[2K
| Adam | epoch: 007 | loss: 0.62128 - acc: 0.6619 -- iter: 448/457
[A[ATraining Step: 105  | total loss: [1m[32m0.61512[0m[0m | time: 26.306s
[2K
| Adam | epoch: 007 | loss: 0.61512 - acc: 0.6675 | val_loss: 0.58095 - val_acc: 0.6643 -- iter: 457/457
--
Training Step: 106  | total loss: [1m[32m0.62075[0m[0m | time: 1.678s
[2K
| Adam | epoch: 008 | loss: 0.62075 - acc: 0.6602 -- iter: 032/457
[A[ATraining Step: 107  | total loss: [1m[32m0.60486[0m[0m | time: 3.476s
[2K
| Adam | epoch: 008 | loss: 0.60486 - acc: 0.6723 -- iter: 064/457
[A[ATraining Step: 108  | total loss: [1m[32m0.59317[0m[0m | time: 5.104s
[2K
| Adam | epoch: 008 | loss: 0.59317 - acc: 0.6894 -- iter: 096/457
[A[ATraining Step: 109  | total loss: [1m[32m0.59122[0m[0m | time: 25.127s
[2K
| Adam | epoch: 008 | loss: 0.59122 - acc: 0.6924 -- iter: 128/457
[A[ATraining Step: 110  | total loss: [1m[32m0.58873[0m[0m | time: 37.993s
[2K
| Adam | epoch: 008 | loss: 0.58873 - acc: 0.6981 -- iter: 160/457
[A[ATraining Step: 111  | total loss: [1m[32m0.57802[0m[0m | time: 38.384s
[2K
| Adam | epoch: 008 | loss: 0.57802 - acc: 0.7033 -- iter: 192/457
[A[ATraining Step: 112  | total loss: [1m[32m0.57199[0m[0m | time: 38.837s
[2K
| Adam | epoch: 008 | loss: 0.57199 - acc: 0.7108 -- iter: 224/457
[A[ATraining Step: 113  | total loss: [1m[32m0.54666[0m[0m | time: 40.205s
[2K
| Adam | epoch: 008 | loss: 0.54666 - acc: 0.7286 -- iter: 256/457
[A[ATraining Step: 114  | total loss: [1m[32m0.54630[0m[0m | time: 41.765s
[2K
| Adam | epoch: 008 | loss: 0.54630 - acc: 0.7307 -- iter: 288/457
[A[ATraining Step: 115  | total loss: [1m[32m0.54265[0m[0m | time: 43.251s
[2K
| Adam | epoch: 008 | loss: 0.54265 - acc: 0.7358 -- iter: 320/457
[A[ATraining Step: 116  | total loss: [1m[32m0.53783[0m[0m | time: 44.928s
[2K
| Adam | epoch: 008 | loss: 0.53783 - acc: 0.7434 -- iter: 352/457
[A[ATraining Step: 117  | total loss: [1m[32m0.53008[0m[0m | time: 46.654s
[2K
| Adam | epoch: 008 | loss: 0.53008 - acc: 0.7503 -- iter: 384/457
[A[ATraining Step: 118  | total loss: [1m[32m0.54758[0m[0m | time: 48.288s
[2K
| Adam | epoch: 008 | loss: 0.54758 - acc: 0.7409 -- iter: 416/457
[A[ATraining Step: 119  | total loss: [1m[32m0.53480[0m[0m | time: 50.083s
[2K
| Adam | epoch: 008 | loss: 0.53480 - acc: 0.7418 -- iter: 448/457
[A[ATraining Step: 120  | total loss: [1m[32m0.51826[0m[0m | time: 53.014s
[2K
| Adam | epoch: 008 | loss: 0.51826 - acc: 0.7520 | val_loss: 0.58898 - val_acc: 0.7063 -- iter: 457/457
--
Training Step: 121  | total loss: [1m[32m0.52232[0m[0m | time: 1.647s
[2K
| Adam | epoch: 009 | loss: 0.52232 - acc: 0.7518 -- iter: 032/457
[A[ATraining Step: 122  | total loss: [1m[32m0.52428[0m[0m | time: 3.013s
[2K
| Adam | epoch: 009 | loss: 0.52428 - acc: 0.7516 -- iter: 064/457
[A[ATraining Step: 123  | total loss: [1m[32m0.53679[0m[0m | time: 6.876s
[2K
| Adam | epoch: 009 | loss: 0.53679 - acc: 0.7421 -- iter: 096/457
[A[ATraining Step: 124  | total loss: [1m[32m0.52645[0m[0m | time: 19.455s
[2K
| Adam | epoch: 009 | loss: 0.52645 - acc: 0.7460 -- iter: 128/457
[A[ATraining Step: 125  | total loss: [1m[32m0.51708[0m[0m | time: 20.794s
[2K
| Adam | epoch: 009 | loss: 0.51708 - acc: 0.7495 -- iter: 160/457
[A[ATraining Step: 126  | total loss: [1m[32m0.52626[0m[0m | time: 22.265s
[2K
| Adam | epoch: 009 | loss: 0.52626 - acc: 0.7433 -- iter: 192/457
[A[ATraining Step: 127  | total loss: [1m[32m0.52973[0m[0m | time: 22.766s
[2K
| Adam | epoch: 009 | loss: 0.52973 - acc: 0.7346 -- iter: 224/457
[A[ATraining Step: 128  | total loss: [1m[32m0.50336[0m[0m | time: 23.258s
[2K
| Adam | epoch: 009 | loss: 0.50336 - acc: 0.7501 -- iter: 256/457
[A[ATraining Step: 129  | total loss: [1m[32m0.49066[0m[0m | time: 24.715s
[2K
| Adam | epoch: 009 | loss: 0.49066 - acc: 0.7639 -- iter: 288/457
[A[ATraining Step: 130  | total loss: [1m[32m0.49876[0m[0m | time: 26.223s
[2K
| Adam | epoch: 009 | loss: 0.49876 - acc: 0.7500 -- iter: 320/457
[A[ATraining Step: 131  | total loss: [1m[32m0.50103[0m[0m | time: 27.756s
[2K
| Adam | epoch: 009 | loss: 0.50103 - acc: 0.7469 -- iter: 352/457
[A[ATraining Step: 132  | total loss: [1m[32m0.49389[0m[0m | time: 29.435s
[2K
| Adam | epoch: 009 | loss: 0.49389 - acc: 0.7503 -- iter: 384/457
[A[ATraining Step: 133  | total loss: [1m[32m0.48314[0m[0m | time: 30.948s
[2K
| Adam | epoch: 009 | loss: 0.48314 - acc: 0.7597 -- iter: 416/457
[A[ATraining Step: 134  | total loss: [1m[32m0.48647[0m[0m | time: 32.657s
[2K
| Adam | epoch: 009 | loss: 0.48647 - acc: 0.7587 -- iter: 448/457
[A[ATraining Step: 135  | total loss: [1m[32m0.47327[0m[0m | time: 35.669s
[2K
| Adam | epoch: 009 | loss: 0.47327 - acc: 0.7610 | val_loss: 0.55937 - val_acc: 0.7203 -- iter: 457/457
--
Training Step: 136  | total loss: [1m[32m0.48380[0m[0m | time: 1.436s
[2K
| Adam | epoch: 010 | loss: 0.48380 - acc: 0.7536 -- iter: 032/457
[A[ATraining Step: 137  | total loss: [1m[32m0.46779[0m[0m | time: 2.986s
[2K
| Adam | epoch: 010 | loss: 0.46779 - acc: 0.7658 -- iter: 064/457
[A[ATraining Step: 138  | total loss: [1m[32m0.45543[0m[0m | time: 4.420s
[2K
| Adam | epoch: 010 | loss: 0.45543 - acc: 0.7767 -- iter: 096/457
[A[ATraining Step: 139  | total loss: [1m[32m0.45835[0m[0m | time: 5.962s
[2K
| Adam | epoch: 010 | loss: 0.45835 - acc: 0.7740 -- iter: 128/457
[A[ATraining Step: 140  | total loss: [1m[32m0.45308[0m[0m | time: 7.477s
[2K
| Adam | epoch: 010 | loss: 0.45308 - acc: 0.7810 -- iter: 160/457
[A[ATraining Step: 141  | total loss: [1m[32m0.43832[0m[0m | time: 9.104s
[2K
| Adam | epoch: 010 | loss: 0.43832 - acc: 0.7935 -- iter: 192/457
[A[ATraining Step: 142  | total loss: [1m[32m0.46067[0m[0m | time: 10.690s
[2K
| Adam | epoch: 010 | loss: 0.46067 - acc: 0.7767 -- iter: 224/457
[A[ATraining Step: 143  | total loss: [1m[32m0.45892[0m[0m | time: 11.193s
[2K
| Adam | epoch: 010 | loss: 0.45892 - acc: 0.7771 -- iter: 256/457
[A[ATraining Step: 144  | total loss: [1m[32m0.44870[0m[0m | time: 11.752s
[2K
| Adam | epoch: 010 | loss: 0.44870 - acc: 0.7772 -- iter: 288/457
[A[ATraining Step: 145  | total loss: [1m[32m0.44912[0m[0m | time: 13.517s
[2K
| Adam | epoch: 010 | loss: 0.44912 - acc: 0.7661 -- iter: 320/457
[A[ATraining Step: 146  | total loss: [1m[32m0.42901[0m[0m | time: 15.055s
[2K
| Adam | epoch: 010 | loss: 0.42901 - acc: 0.7864 -- iter: 352/457
[A[ATraining Step: 147  | total loss: [1m[32m0.42344[0m[0m | time: 16.772s
[2K
| Adam | epoch: 010 | loss: 0.42344 - acc: 0.7890 -- iter: 384/457
[A[ATraining Step: 148  | total loss: [1m[32m0.42226[0m[0m | time: 18.434s
[2K
| Adam | epoch: 010 | loss: 0.42226 - acc: 0.7945 -- iter: 416/457
[A[ATraining Step: 149  | total loss: [1m[32m0.41797[0m[0m | time: 19.929s
[2K
| Adam | epoch: 010 | loss: 0.41797 - acc: 0.7932 -- iter: 448/457
[A[ATraining Step: 150  | total loss: [1m[32m0.41433[0m[0m | time: 22.909s
[2K
| Adam | epoch: 010 | loss: 0.41433 - acc: 0.7951 | val_loss: 0.56736 - val_acc: 0.7203 -- iter: 457/457
--
Training Step: 151  | total loss: [1m[32m0.40521[0m[0m | time: 1.619s
[2K
| Adam | epoch: 011 | loss: 0.40521 - acc: 0.8062 -- iter: 032/457
[A[ATraining Step: 152  | total loss: [1m[32m0.39370[0m[0m | time: 3.123s
[2K
| Adam | epoch: 011 | loss: 0.39370 - acc: 0.8131 -- iter: 064/457
[A[ATraining Step: 153  | total loss: [1m[32m0.40207[0m[0m | time: 4.546s
[2K
| Adam | epoch: 011 | loss: 0.40207 - acc: 0.8099 -- iter: 096/457
[A[ATraining Step: 154  | total loss: [1m[32m0.39268[0m[0m | time: 5.820s
[2K
| Adam | epoch: 011 | loss: 0.39268 - acc: 0.8164 -- iter: 128/457
[A[ATraining Step: 155  | total loss: [1m[32m0.38839[0m[0m | time: 7.104s
[2K
| Adam | epoch: 011 | loss: 0.38839 - acc: 0.8160 -- iter: 160/457
[A[ATraining Step: 156  | total loss: [1m[32m0.37999[0m[0m | time: 8.335s
[2K
| Adam | epoch: 011 | loss: 0.37999 - acc: 0.8219 -- iter: 192/457
[A[ATraining Step: 157  | total loss: [1m[32m0.38605[0m[0m | time: 9.529s
[2K
| Adam | epoch: 011 | loss: 0.38605 - acc: 0.8116 -- iter: 224/457
[A[ATraining Step: 158  | total loss: [1m[32m0.38034[0m[0m | time: 10.981s
[2K
| Adam | epoch: 011 | loss: 0.38034 - acc: 0.8179 -- iter: 256/457
[A[ATraining Step: 159  | total loss: [1m[32m0.37390[0m[0m | time: 11.433s
[2K
| Adam | epoch: 011 | loss: 0.37390 - acc: 0.8236 -- iter: 288/457
[A[ATraining Step: 160  | total loss: [1m[32m0.38797[0m[0m | time: 11.860s
[2K
| Adam | epoch: 011 | loss: 0.38797 - acc: 0.8191 -- iter: 320/457
[A[ATraining Step: 161  | total loss: [1m[32m0.37341[0m[0m | time: 13.308s
[2K
| Adam | epoch: 011 | loss: 0.37341 - acc: 0.8372 -- iter: 352/457
[A[ATraining Step: 162  | total loss: [1m[32m0.38226[0m[0m | time: 14.457s
[2K
| Adam | epoch: 011 | loss: 0.38226 - acc: 0.8316 -- iter: 384/457
[A[ATraining Step: 163  | total loss: [1m[32m0.37072[0m[0m | time: 15.762s
[2K
| Adam | epoch: 011 | loss: 0.37072 - acc: 0.8359 -- iter: 416/457
[A[ATraining Step: 164  | total loss: [1m[32m0.35436[0m[0m | time: 17.098s
[2K
| Adam | epoch: 011 | loss: 0.35436 - acc: 0.8429 -- iter: 448/457
[A[ATraining Step: 165  | total loss: [1m[32m0.34203[0m[0m | time: 19.369s
[2K
| Adam | epoch: 011 | loss: 0.34203 - acc: 0.8524 | val_loss: 0.59485 - val_acc: 0.7552 -- iter: 457/457
--
Training Step: 166  | total loss: [1m[32m0.32308[0m[0m | time: 1.372s
[2K
| Adam | epoch: 012 | loss: 0.32308 - acc: 0.8640 -- iter: 032/457
[A[ATraining Step: 167  | total loss: [1m[32m0.31505[0m[0m | time: 2.593s
[2K
| Adam | epoch: 012 | loss: 0.31505 - acc: 0.8714 -- iter: 064/457
[A[ATraining Step: 168  | total loss: [1m[32m0.30560[0m[0m | time: 3.921s
[2K
| Adam | epoch: 012 | loss: 0.30560 - acc: 0.8780 -- iter: 096/457
[A[ATraining Step: 169  | total loss: [1m[32m0.30846[0m[0m | time: 5.386s
[2K
| Adam | epoch: 012 | loss: 0.30846 - acc: 0.8714 -- iter: 128/457
[A[ATraining Step: 170  | total loss: [1m[32m0.31617[0m[0m | time: 6.799s
[2K
| Adam | epoch: 012 | loss: 0.31617 - acc: 0.8687 -- iter: 160/457
[A[ATraining Step: 171  | total loss: [1m[32m0.32321[0m[0m | time: 7.959s
[2K
| Adam | epoch: 012 | loss: 0.32321 - acc: 0.8662 -- iter: 192/457
[A[ATraining Step: 172  | total loss: [1m[32m0.34232[0m[0m | time: 9.168s
[2K
| Adam | epoch: 012 | loss: 0.34232 - acc: 0.8577 -- iter: 224/457
[A[ATraining Step: 173  | total loss: [1m[32m0.35604[0m[0m | time: 10.512s
[2K
| Adam | epoch: 012 | loss: 0.35604 - acc: 0.8532 -- iter: 256/457
[A[ATraining Step: 174  | total loss: [1m[32m0.36936[0m[0m | time: 12.065s
[2K
| Adam | epoch: 012 | loss: 0.36936 - acc: 0.8429 -- iter: 288/457
[A[ATraining Step: 175  | total loss: [1m[32m0.35599[0m[0m | time: 12.642s
[2K
| Adam | epoch: 012 | loss: 0.35599 - acc: 0.8554 -- iter: 320/457
[A[ATraining Step: 176  | total loss: [1m[32m0.40983[0m[0m | time: 13.184s
[2K
| Adam | epoch: 012 | loss: 0.40983 - acc: 0.8366 -- iter: 352/457
[A[ATraining Step: 177  | total loss: [1m[32m0.39113[0m[0m | time: 14.627s
[2K
| Adam | epoch: 012 | loss: 0.39113 - acc: 0.8418 -- iter: 384/457
[A[ATraining Step: 178  | total loss: [1m[32m0.37457[0m[0m | time: 16.264s
[2K
| Adam | epoch: 012 | loss: 0.37457 - acc: 0.8514 -- iter: 416/457
[A[ATraining Step: 179  | total loss: [1m[32m0.37278[0m[0m | time: 17.747s
[2K
| Adam | epoch: 012 | loss: 0.37278 - acc: 0.8537 -- iter: 448/457
[A[ATraining Step: 180  | total loss: [1m[32m0.36633[0m[0m | time: 20.504s
[2K
| Adam | epoch: 012 | loss: 0.36633 - acc: 0.8590 | val_loss: 0.50486 - val_acc: 0.7343 -- iter: 457/457
--
Training Step: 181  | total loss: [1m[32m0.36154[0m[0m | time: 1.700s
[2K
| Adam | epoch: 013 | loss: 0.36154 - acc: 0.8637 -- iter: 032/457
[A[ATraining Step: 182  | total loss: [1m[32m0.35207[0m[0m | time: 3.343s
[2K
| Adam | epoch: 013 | loss: 0.35207 - acc: 0.8711 -- iter: 064/457
[A[ATraining Step: 183  | total loss: [1m[32m0.33671[0m[0m | time: 4.902s
[2K
| Adam | epoch: 013 | loss: 0.33671 - acc: 0.8777 -- iter: 096/457
[A[ATraining Step: 184  | total loss: [1m[32m0.32962[0m[0m | time: 6.388s
[2K
| Adam | epoch: 013 | loss: 0.32962 - acc: 0.8806 -- iter: 128/457
[A[ATraining Step: 185  | total loss: [1m[32m0.34137[0m[0m | time: 8.027s
[2K
| Adam | epoch: 013 | loss: 0.34137 - acc: 0.8706 -- iter: 160/457
[A[ATraining Step: 186  | total loss: [1m[32m0.34064[0m[0m | time: 9.521s
[2K
| Adam | epoch: 013 | loss: 0.34064 - acc: 0.8711 -- iter: 192/457
[A[ATraining Step: 187  | total loss: [1m[32m0.33058[0m[0m | time: 11.134s
[2K
| Adam | epoch: 013 | loss: 0.33058 - acc: 0.8777 -- iter: 224/457
[A[ATraining Step: 188  | total loss: [1m[32m0.32527[0m[0m | time: 12.713s
[2K
| Adam | epoch: 013 | loss: 0.32527 - acc: 0.8775 -- iter: 256/457
[A[ATraining Step: 189  | total loss: [1m[32m0.31798[0m[0m | time: 14.254s
[2K
| Adam | epoch: 013 | loss: 0.31798 - acc: 0.8835 -- iter: 288/457
[A[ATraining Step: 190  | total loss: [1m[32m0.31313[0m[0m | time: 15.634s
[2K
| Adam | epoch: 013 | loss: 0.31313 - acc: 0.8857 -- iter: 320/457
[A[ATraining Step: 191  | total loss: [1m[32m0.30103[0m[0m | time: 16.131s
[2K
| Adam | epoch: 013 | loss: 0.30103 - acc: 0.8909 -- iter: 352/457
[A[ATraining Step: 192  | total loss: [1m[32m0.27873[0m[0m | time: 16.611s
[2K
| Adam | epoch: 013 | loss: 0.27873 - acc: 0.9018 -- iter: 384/457
[A[ATraining Step: 193  | total loss: [1m[32m0.27872[0m[0m | time: 18.037s
[2K
| Adam | epoch: 013 | loss: 0.27872 - acc: 0.8894 -- iter: 416/457
[A[ATraining Step: 194  | total loss: [1m[32m0.26866[0m[0m | time: 19.807s
[2K
| Adam | epoch: 013 | loss: 0.26866 - acc: 0.8942 -- iter: 448/457
[A[ATraining Step: 195  | total loss: [1m[32m0.28239[0m[0m | time: 22.811s
[2K
| Adam | epoch: 013 | loss: 0.28239 - acc: 0.8861 | val_loss: 0.66970 - val_acc: 0.7622 -- iter: 457/457
--
Training Step: 196  | total loss: [1m[32m0.27585[0m[0m | time: 1.643s
[2K
| Adam | epoch: 014 | loss: 0.27585 - acc: 0.8881 -- iter: 032/457
[A[ATraining Step: 197  | total loss: [1m[32m0.26389[0m[0m | time: 3.118s
[2K
| Adam | epoch: 014 | loss: 0.26389 - acc: 0.8930 -- iter: 064/457
[A[ATraining Step: 198  | total loss: [1m[32m0.26264[0m[0m | time: 4.899s
[2K
| Adam | epoch: 014 | loss: 0.26264 - acc: 0.8975 -- iter: 096/457
[A[ATraining Step: 199  | total loss: [1m[32m0.24932[0m[0m | time: 6.493s
[2K
| Adam | epoch: 014 | loss: 0.24932 - acc: 0.9046 -- iter: 128/457
[A[ATraining Step: 200  | total loss: [1m[32m0.26137[0m[0m | time: 9.841s
[2K
| Adam | epoch: 014 | loss: 0.26137 - acc: 0.8985 | val_loss: 0.63881 - val_acc: 0.8112 -- iter: 160/457
--
Training Step: 201  | total loss: [1m[32m0.29082[0m[0m | time: 11.390s
[2K
| Adam | epoch: 014 | loss: 0.29082 - acc: 0.8899 -- iter: 192/457
[A[ATraining Step: 202  | total loss: [1m[32m0.28630[0m[0m | time: 12.761s
[2K
| Adam | epoch: 014 | loss: 0.28630 - acc: 0.8978 -- iter: 224/457
[A[ATraining Step: 203  | total loss: [1m[32m0.27894[0m[0m | time: 14.302s
[2K
| Adam | epoch: 014 | loss: 0.27894 - acc: 0.9018 -- iter: 256/457
[A[ATraining Step: 204  | total loss: [1m[32m0.26971[0m[0m | time: 15.820s
[2K
| Adam | epoch: 014 | loss: 0.26971 - acc: 0.9085 -- iter: 288/457
[A[ATraining Step: 205  | total loss: [1m[32m0.26502[0m[0m | time: 17.401s
[2K
| Adam | epoch: 014 | loss: 0.26502 - acc: 0.9051 -- iter: 320/457
[A[ATraining Step: 206  | total loss: [1m[32m0.26057[0m[0m | time: 19.006s
[2K
| Adam | epoch: 014 | loss: 0.26057 - acc: 0.9052 -- iter: 352/457
[A[ATraining Step: 207  | total loss: [1m[32m0.25997[0m[0m | time: 19.485s
[2K
| Adam | epoch: 014 | loss: 0.25997 - acc: 0.9022 -- iter: 384/457
[A[ATraining Step: 208  | total loss: [1m[32m0.25434[0m[0m | time: 20.000s
[2K
| Adam | epoch: 014 | loss: 0.25434 - acc: 0.9009 -- iter: 416/457
[A[ATraining Step: 209  | total loss: [1m[32m0.23499[0m[0m | time: 21.768s
[2K
| Adam | epoch: 014 | loss: 0.23499 - acc: 0.9108 -- iter: 448/457
[A[ATraining Step: 210  | total loss: [1m[32m0.23958[0m[0m | time: 24.683s
[2K
| Adam | epoch: 014 | loss: 0.23958 - acc: 0.9103 | val_loss: 0.63590 - val_acc: 0.7552 -- iter: 457/457
--
Training Step: 211  | total loss: [1m[32m0.24494[0m[0m | time: 1.585s
[2K
| Adam | epoch: 015 | loss: 0.24494 - acc: 0.9068 -- iter: 032/457
[A[ATraining Step: 212  | total loss: [1m[32m0.23532[0m[0m | time: 3.198s
[2K
| Adam | epoch: 015 | loss: 0.23532 - acc: 0.9130 -- iter: 064/457
[A[ATraining Step: 213  | total loss: [1m[32m0.22745[0m[0m | time: 5.048s
[2K
| Adam | epoch: 015 | loss: 0.22745 - acc: 0.9186 -- iter: 096/457
[A[ATraining Step: 214  | total loss: [1m[32m0.22522[0m[0m | time: 6.367s
[2K
| Adam | epoch: 015 | loss: 0.22522 - acc: 0.9142 -- iter: 128/457
[A[ATraining Step: 215  | total loss: [1m[32m0.22232[0m[0m | time: 7.888s
[2K
| Adam | epoch: 015 | loss: 0.22232 - acc: 0.9134 -- iter: 160/457
[A[ATraining Step: 216  | total loss: [1m[32m0.21359[0m[0m | time: 9.434s
[2K
| Adam | epoch: 015 | loss: 0.21359 - acc: 0.9190 -- iter: 192/457
[A[ATraining Step: 217  | total loss: [1m[32m0.20134[0m[0m | time: 10.839s
[2K
| Adam | epoch: 015 | loss: 0.20134 - acc: 0.9208 -- iter: 224/457
[A[ATraining Step: 218  | total loss: [1m[32m0.20507[0m[0m | time: 12.448s
[2K
| Adam | epoch: 015 | loss: 0.20507 - acc: 0.9193 -- iter: 256/457
[A[ATraining Step: 219  | total loss: [1m[32m0.20867[0m[0m | time: 13.846s
[2K
| Adam | epoch: 015 | loss: 0.20867 - acc: 0.9149 -- iter: 288/457
[A[ATraining Step: 220  | total loss: [1m[32m0.19598[0m[0m | time: 15.661s
[2K
| Adam | epoch: 015 | loss: 0.19598 - acc: 0.9203 -- iter: 320/457
[A[ATraining Step: 221  | total loss: [1m[32m0.21230[0m[0m | time: 17.441s
[2K
| Adam | epoch: 015 | loss: 0.21230 - acc: 0.9158 -- iter: 352/457
[A[ATraining Step: 222  | total loss: [1m[32m0.21855[0m[0m | time: 19.013s
[2K
| Adam | epoch: 015 | loss: 0.21855 - acc: 0.9148 -- iter: 384/457
[A[ATraining Step: 223  | total loss: [1m[32m0.22613[0m[0m | time: 19.486s
[2K
| Adam | epoch: 015 | loss: 0.22613 - acc: 0.9140 -- iter: 416/457
[A[ATraining Step: 224  | total loss: [1m[32m0.33960[0m[0m | time: 20.023s
[2K
| Adam | epoch: 015 | loss: 0.33960 - acc: 0.8892 -- iter: 448/457
[A[ATraining Step: 225  | total loss: [1m[32m0.34403[0m[0m | time: 23.318s
[2K
| Adam | epoch: 015 | loss: 0.34403 - acc: 0.8781 | val_loss: 0.65325 - val_acc: 0.7832 -- iter: 457/457
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8438356164383563
Validation AUPRC:0.8546964328983719
Test AUC:0.8716744913928013
Test AUPRC:0.8819961526484218
BestTestF1Score	0.78	0.53	0.75	0.68	0.92	65	30	42	6	0.37
BestTestMCCScore	0.83	0.65	0.82	0.77	0.9	64	19	53	7	0.56
BestTestAccuracyScore	0.83	0.65	0.82	0.77	0.9	64	19	53	7	0.56
BestValidationF1Score	0.8	0.59	0.79	0.74	0.87	61	21	52	9	0.37
BestValidationMCC	0.8	0.6	0.8	0.77	0.83	58	17	56	12	0.56
BestValidationAccuracy	0.8	0.6	0.8	0.77	0.83	58	17	56	12	0.56
TestPredictions (Threshold:0.56)
CHEMBL3645474,TN,INACT,0.27000001072883606	CHEMBL101494,FP,INACT,0.9700000286102295	CHEMBL481032,TP,ACT,0.9700000286102295	CHEMBL3221001,TP,ACT,0.9599999785423279	CHEMBL541552,TN,INACT,0.07000000029802322	CHEMBL114551,FP,INACT,0.5699999928474426	CHEMBL2071545,FP,INACT,0.6299999952316284	CHEMBL1222608,TP,ACT,0.5600000023841858	CHEMBL1796278,FN,ACT,0.03999999910593033	CHEMBL3109191,TP,ACT,1.0	CHEMBL3220997,TP,ACT,0.9700000286102295	CHEMBL1277951,TP,ACT,0.9800000190734863	CHEMBL1911991,FP,INACT,0.9900000095367432	CHEMBL1801506,TN,INACT,0.05000000074505806	CHEMBL89491,TN,INACT,0.4099999964237213	CHEMBL1945753,TN,INACT,0.05000000074505806	CHEMBL3216174,TP,ACT,1.0	CHEMBL3736228,TP,ACT,0.9800000190734863	CHEMBL185766,TN,INACT,0.3799999952316284	CHEMBL2332789,TP,ACT,0.9900000095367432	CHEMBL1222675,TP,ACT,0.9599999785423279	CHEMBL228077,TP,ACT,0.9900000095367432	CHEMBL446971,TP,ACT,0.9599999785423279	CHEMBL3220996,TP,ACT,0.9900000095367432	CHEMBL43245,TP,ACT,1.0	CHEMBL98102,TN,INACT,0.03999999910593033	CHEMBL98630,FP,INACT,0.9800000190734863	CHEMBL185535,TN,INACT,0.4300000071525574	CHEMBL278016,TN,INACT,0.3799999952316284	CHEMBL3216115,TN,INACT,0.05999999865889549	CHEMBL226390,TP,ACT,0.9900000095367432	CHEMBL1276167,FP,INACT,0.9700000286102295	CHEMBL479270,TP,ACT,0.8799999952316284	CHEMBL2071547,TN,INACT,0.550000011920929	CHEMBL474637,FN,ACT,0.44999998807907104	CHEMBL3818545,TP,ACT,0.9800000190734863	CHEMBL3262021,TP,ACT,1.0	CHEMBL3262024,TP,ACT,0.9800000190734863	CHEMBL1911893,FP,INACT,0.9700000286102295	CHEMBL87529,TP,ACT,1.0	CHEMBL1277327,TN,INACT,0.3700000047683716	CHEMBL88177,TP,ACT,0.9300000071525574	CHEMBL442999,TP,ACT,1.0	CHEMBL96680,FN,ACT,0.07000000029802322	CHEMBL521254,TP,ACT,0.9300000071525574	CHEMBL2430146,TP,ACT,0.9900000095367432	CHEMBL317806,TN,INACT,0.07999999821186066	CHEMBL1233715,FP,INACT,0.9599999785423279	CHEMBL1801496,TN,INACT,0.4000000059604645	CHEMBL3645473,TN,INACT,0.07000000029802322	CHEMBL101267,TN,INACT,0.47999998927116394	CHEMBL485527,FP,INACT,0.5600000023841858	CHEMBL295848,TP,ACT,1.0	CHEMBL1222745,TP,ACT,0.949999988079071	CHEMBL1945916,TN,INACT,0.20000000298023224	CHEMBL1946351,TN,INACT,0.10999999940395355	CHEMBL3701182,FP,INACT,0.5799999833106995	CHEMBL99648,TN,INACT,0.05999999865889549	CHEMBL3216851,TP,ACT,0.9800000190734863	CHEMBL3221002,TP,ACT,0.9900000095367432	CHEMBL1911886,FP,INACT,1.0	CHEMBL3215962,TP,ACT,1.0	CHEMBL3735289,TP,ACT,0.9900000095367432	CHEMBL1222607,TP,ACT,0.7400000095367432	CHEMBL473674,TN,INACT,0.03999999910593033	CHEMBL42968,TP,ACT,0.9900000095367432	CHEMBL1944719,TN,INACT,0.14000000059604645	CHEMBL1945752,TN,INACT,0.36000001430511475	CHEMBL1766631,TP,ACT,1.0	CHEMBL330466,TN,INACT,0.23999999463558197	CHEMBL3407815,TP,ACT,1.0	CHEMBL46913,TP,ACT,0.8999999761581421	CHEMBL6573,TN,INACT,0.3400000035762787	CHEMBL3407810,TP,ACT,0.699999988079071	CHEMBL3220999,TP,ACT,0.8299999833106995	CHEMBL1230380,TP,ACT,0.9700000286102295	CHEMBL3217210,TN,INACT,0.05000000074505806	CHEMBL98632,TN,INACT,0.03999999910593033	CHEMBL3125048,TP,ACT,1.0	CHEMBL101598,FP,INACT,0.7300000190734863	CHEMBL241131,FN,ACT,0.30000001192092896	CHEMBL3216994,TN,INACT,0.2800000011920929	CHEMBL1277419,FP,INACT,0.9900000095367432	CHEMBL416071,TP,ACT,0.9900000095367432	CHEMBL544693,TN,INACT,0.3799999952316284	CHEMBL1162881,FP,INACT,0.6800000071525574	CHEMBL44964,TP,ACT,1.0	CHEMBL3645489,TN,INACT,0.4000000059604645	CHEMBL101766,FP,INACT,0.5699999928474426	CHEMBL362366,TN,INACT,0.05000000074505806	CHEMBL479666,TP,ACT,0.9900000095367432	CHEMBL2448330,TN,INACT,0.49000000953674316	CHEMBL186985,TN,INACT,0.07000000029802322	CHEMBL1202117,FP,INACT,0.8100000023841858	CHEMBL100113,TN,INACT,0.10999999940395355	CHEMBL3325611,TP,ACT,1.0	CHEMBL1852332,TN,INACT,0.14000000059604645	CHEMBL91256,TP,ACT,0.9800000190734863	CHEMBL450234,TP,ACT,0.8799999952316284	CHEMBL3394387,TP,ACT,0.9900000095367432	CHEMBL233652,TP,ACT,0.9900000095367432	CHEMBL1944715,TN,INACT,0.12999999523162842	CHEMBL256147,TP,ACT,0.7200000286102295	CHEMBL3125049,TP,ACT,0.9900000095367432	CHEMBL521452,TN,INACT,0.12999999523162842	CHEMBL40833,FN,ACT,0.07000000029802322	CHEMBL1371,FN,ACT,0.05999999865889549	CHEMBL2036265,TN,INACT,0.2800000011920929	CHEMBL86961,TN,INACT,0.05999999865889549	CHEMBL39186,TP,ACT,1.0	CHEMBL3586656,TP,ACT,1.0	CHEMBL470193,TP,ACT,0.9599999785423279	CHEMBL1277694,FP,INACT,0.9900000095367432	CHEMBL3216283,TN,INACT,0.07000000029802322	CHEMBL554248,TN,INACT,0.33000001311302185	CHEMBL3645477,TN,INACT,0.07000000029802322	CHEMBL3645464,TN,INACT,0.03999999910593033	CHEMBL3216993,FP,INACT,0.9700000286102295	CHEMBL290875,FN,ACT,0.05000000074505806	CHEMBL553998,TN,INACT,0.3499999940395355	CHEMBL3819551,TP,ACT,0.9800000190734863	CHEMBL233654,TP,ACT,0.9800000190734863	CHEMBL1615288,TP,ACT,1.0	CHEMBL3215657,TN,INACT,0.03999999910593033	CHEMBL3394388,TP,ACT,1.0	CHEMBL3128245,TP,ACT,0.9900000095367432	CHEMBL1955935,TN,INACT,0.30000001192092896	CHEMBL330548,FP,INACT,0.8399999737739563	CHEMBL88107,TP,ACT,0.7599999904632568	CHEMBL98001,TN,INACT,0.15000000596046448	CHEMBL196721,TN,INACT,0.05000000074505806	CHEMBL233653,TP,ACT,0.7099999785423279	CHEMBL452156,TN,INACT,0.2199999988079071	CHEMBL318704,TN,INACT,0.07999999821186066	CHEMBL174290,TN,INACT,0.12999999523162842	CHEMBL375056,TP,ACT,0.9900000095367432	CHEMBL365637,TN,INACT,0.36000001430511475	CHEMBL542674,TN,INACT,0.05000000074505806	CHEMBL1269156,TP,ACT,0.9800000190734863	CHEMBL469987,TP,ACT,0.9700000286102295	CHEMBL541300,TP,ACT,0.9700000286102295	CHEMBL3262026,TP,ACT,1.0	CHEMBL3216313,TN,INACT,0.05000000074505806	

