CNNModel CHEMBL3360 adam 0.001 15 128 0 0.6 False True
Number of active compounds :	261
Number of inactive compounds :	261
---------------------------------
Run id: CNNModel_CHEMBL3360_adam_0.001_15_128_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3360_adam_0.001_15_128_0.6_True/
---------------------------------
Training samples: 332
Validation samples: 104
--
Training Step: 1  | time: 0.902s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/332
[A[ATraining Step: 2  | total loss: [1m[32m0.62368[0m[0m | time: 1.595s
[2K
| Adam | epoch: 001 | loss: 0.62368 - acc: 0.5062 -- iter: 064/332
[A[ATraining Step: 3  | total loss: [1m[32m0.66748[0m[0m | time: 2.276s
[2K
| Adam | epoch: 001 | loss: 0.66748 - acc: 0.6290 -- iter: 096/332
[A[ATraining Step: 4  | total loss: [1m[32m0.74066[0m[0m | time: 2.976s
[2K
| Adam | epoch: 001 | loss: 0.74066 - acc: 0.4619 -- iter: 128/332
[A[ATraining Step: 5  | total loss: [1m[32m0.70986[0m[0m | time: 3.677s
[2K
| Adam | epoch: 001 | loss: 0.70986 - acc: 0.4883 -- iter: 160/332
[A[ATraining Step: 6  | total loss: [1m[32m0.69499[0m[0m | time: 4.345s
[2K
| Adam | epoch: 001 | loss: 0.69499 - acc: 0.5561 -- iter: 192/332
[A[ATraining Step: 7  | total loss: [1m[32m0.69494[0m[0m | time: 5.060s
[2K
| Adam | epoch: 001 | loss: 0.69494 - acc: 0.5037 -- iter: 224/332
[A[ATraining Step: 8  | total loss: [1m[32m0.69352[0m[0m | time: 5.750s
[2K
| Adam | epoch: 001 | loss: 0.69352 - acc: 0.5192 -- iter: 256/332
[A[ATraining Step: 9  | total loss: [1m[32m0.69346[0m[0m | time: 6.464s
[2K
| Adam | epoch: 001 | loss: 0.69346 - acc: 0.5090 -- iter: 288/332
[A[ATraining Step: 10  | total loss: [1m[32m0.69335[0m[0m | time: 7.175s
[2K
| Adam | epoch: 001 | loss: 0.69335 - acc: 0.5045 -- iter: 320/332
[A[ATraining Step: 11  | total loss: [1m[32m0.69319[0m[0m | time: 8.475s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5024 | val_loss: 0.69323 - val_acc: 0.4904 -- iter: 332/332
--
Training Step: 12  | total loss: [1m[32m0.69315[0m[0m | time: 0.279s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5013 -- iter: 032/332
[A[ATraining Step: 13  | total loss: [1m[32m0.69314[0m[0m | time: 0.954s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5007 -- iter: 064/332
[A[ATraining Step: 14  | total loss: [1m[32m0.69224[0m[0m | time: 1.633s
[2K
| Adam | epoch: 002 | loss: 0.69224 - acc: 0.6155 -- iter: 096/332
[A[ATraining Step: 15  | total loss: [1m[32m0.69268[0m[0m | time: 2.311s
[2K
| Adam | epoch: 002 | loss: 0.69268 - acc: 0.5581 -- iter: 128/332
[A[ATraining Step: 16  | total loss: [1m[32m0.69238[0m[0m | time: 3.022s
[2K
| Adam | epoch: 002 | loss: 0.69238 - acc: 0.5715 -- iter: 160/332
[A[ATraining Step: 17  | total loss: [1m[32m0.69284[0m[0m | time: 3.708s
[2K
| Adam | epoch: 002 | loss: 0.69284 - acc: 0.5345 -- iter: 192/332
[A[ATraining Step: 18  | total loss: [1m[32m0.69294[0m[0m | time: 4.393s
[2K
| Adam | epoch: 002 | loss: 0.69294 - acc: 0.5225 -- iter: 224/332
[A[ATraining Step: 19  | total loss: [1m[32m0.69216[0m[0m | time: 5.093s
[2K
| Adam | epoch: 002 | loss: 0.69216 - acc: 0.5567 -- iter: 256/332
[A[ATraining Step: 20  | total loss: [1m[32m0.69182[0m[0m | time: 5.779s
[2K
| Adam | epoch: 002 | loss: 0.69182 - acc: 0.5686 -- iter: 288/332
[A[ATraining Step: 21  | total loss: [1m[32m0.69280[0m[0m | time: 6.477s
[2K
| Adam | epoch: 002 | loss: 0.69280 - acc: 0.5279 -- iter: 320/332
[A[ATraining Step: 22  | total loss: [1m[32m0.69270[0m[0m | time: 8.193s
[2K
| Adam | epoch: 002 | loss: 0.69270 - acc: 0.5289 | val_loss: 0.69361 - val_acc: 0.4904 -- iter: 332/332
--
Training Step: 23  | total loss: [1m[32m0.69253[0m[0m | time: 0.275s
[2K
| Adam | epoch: 003 | loss: 0.69253 - acc: 0.5296 -- iter: 032/332
[A[ATraining Step: 24  | total loss: [1m[32m0.69358[0m[0m | time: 0.552s
[2K
| Adam | epoch: 003 | loss: 0.69358 - acc: 0.4978 -- iter: 064/332
[A[ATraining Step: 25  | total loss: [1m[32m0.69434[0m[0m | time: 1.239s
[2K
| Adam | epoch: 003 | loss: 0.69434 - acc: 0.4757 -- iter: 096/332
[A[ATraining Step: 26  | total loss: [1m[32m0.69432[0m[0m | time: 1.933s
[2K
| Adam | epoch: 003 | loss: 0.69432 - acc: 0.4739 -- iter: 128/332
[A[ATraining Step: 27  | total loss: [1m[32m0.69372[0m[0m | time: 2.619s
[2K
| Adam | epoch: 003 | loss: 0.69372 - acc: 0.4886 -- iter: 160/332
[A[ATraining Step: 28  | total loss: [1m[32m0.69336[0m[0m | time: 3.305s
[2K
| Adam | epoch: 003 | loss: 0.69336 - acc: 0.4993 -- iter: 192/332
[A[ATraining Step: 29  | total loss: [1m[32m0.69329[0m[0m | time: 3.993s
[2K
| Adam | epoch: 003 | loss: 0.69329 - acc: 0.4995 -- iter: 224/332
[A[ATraining Step: 30  | total loss: [1m[32m0.69405[0m[0m | time: 4.670s
[2K
| Adam | epoch: 003 | loss: 0.69405 - acc: 0.4774 -- iter: 256/332
[A[ATraining Step: 31  | total loss: [1m[32m0.69313[0m[0m | time: 5.343s
[2K
| Adam | epoch: 003 | loss: 0.69313 - acc: 0.5042 -- iter: 288/332
[A[ATraining Step: 32  | total loss: [1m[32m0.69321[0m[0m | time: 6.031s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.5033 -- iter: 320/332
[A[ATraining Step: 33  | total loss: [1m[32m0.69276[0m[0m | time: 7.715s
[2K
| Adam | epoch: 003 | loss: 0.69276 - acc: 0.5163 | val_loss: 0.69350 - val_acc: 0.4904 -- iter: 332/332
--
Training Step: 34  | total loss: [1m[32m0.69285[0m[0m | time: 0.670s
[2K
| Adam | epoch: 004 | loss: 0.69285 - acc: 0.5128 -- iter: 032/332
[A[ATraining Step: 35  | total loss: [1m[32m0.69357[0m[0m | time: 0.938s
[2K
| Adam | epoch: 004 | loss: 0.69357 - acc: 0.4905 -- iter: 064/332
[A[ATraining Step: 36  | total loss: [1m[32m0.69347[0m[0m | time: 1.206s
[2K
| Adam | epoch: 004 | loss: 0.69347 - acc: 0.4924 -- iter: 096/332
[A[ATraining Step: 37  | total loss: [1m[32m0.69341[0m[0m | time: 1.873s
[2K
| Adam | epoch: 004 | loss: 0.69341 - acc: 0.4939 -- iter: 128/332
[A[ATraining Step: 38  | total loss: [1m[32m0.69276[0m[0m | time: 2.547s
[2K
| Adam | epoch: 004 | loss: 0.69276 - acc: 0.5135 -- iter: 160/332
[A[ATraining Step: 39  | total loss: [1m[32m0.69189[0m[0m | time: 3.239s
[2K
| Adam | epoch: 004 | loss: 0.69189 - acc: 0.5408 -- iter: 192/332
[A[ATraining Step: 40  | total loss: [1m[32m0.69155[0m[0m | time: 3.921s
[2K
| Adam | epoch: 004 | loss: 0.69155 - acc: 0.5507 -- iter: 224/332
[A[ATraining Step: 41  | total loss: [1m[32m0.69120[0m[0m | time: 4.601s
[2K
| Adam | epoch: 004 | loss: 0.69120 - acc: 0.5586 -- iter: 256/332
[A[ATraining Step: 42  | total loss: [1m[32m0.69050[0m[0m | time: 5.267s
[2K
| Adam | epoch: 004 | loss: 0.69050 - acc: 0.5706 -- iter: 288/332
[A[ATraining Step: 43  | total loss: [1m[32m0.69093[0m[0m | time: 5.943s
[2K
| Adam | epoch: 004 | loss: 0.69093 - acc: 0.5581 -- iter: 320/332
[A[ATraining Step: 44  | total loss: [1m[32m0.69260[0m[0m | time: 7.623s
[2K
| Adam | epoch: 004 | loss: 0.69260 - acc: 0.5264 | val_loss: 0.69400 - val_acc: 0.4904 -- iter: 332/332
--
Training Step: 45  | total loss: [1m[32m0.69230[0m[0m | time: 0.703s
[2K
| Adam | epoch: 005 | loss: 0.69230 - acc: 0.5273 -- iter: 032/332
[A[ATraining Step: 46  | total loss: [1m[32m0.69245[0m[0m | time: 1.388s
[2K
| Adam | epoch: 005 | loss: 0.69245 - acc: 0.5227 -- iter: 064/332
[A[ATraining Step: 47  | total loss: [1m[32m0.69110[0m[0m | time: 1.666s
[2K
| Adam | epoch: 005 | loss: 0.69110 - acc: 0.5394 -- iter: 096/332
[A[ATraining Step: 48  | total loss: [1m[32m0.69239[0m[0m | time: 1.935s
[2K
| Adam | epoch: 005 | loss: 0.69239 - acc: 0.5197 -- iter: 128/332
[A[ATraining Step: 49  | total loss: [1m[32m0.69325[0m[0m | time: 2.619s
[2K
| Adam | epoch: 005 | loss: 0.69325 - acc: 0.5034 -- iter: 160/332
[A[ATraining Step: 50  | total loss: [1m[32m0.69383[0m[0m | time: 3.280s
[2K
| Adam | epoch: 005 | loss: 0.69383 - acc: 0.4932 -- iter: 192/332
[A[ATraining Step: 51  | total loss: [1m[32m0.69371[0m[0m | time: 3.977s
[2K
| Adam | epoch: 005 | loss: 0.69371 - acc: 0.4942 -- iter: 224/332
[A[ATraining Step: 52  | total loss: [1m[32m0.69230[0m[0m | time: 4.671s
[2K
| Adam | epoch: 005 | loss: 0.69230 - acc: 0.5139 -- iter: 256/332
[A[ATraining Step: 53  | total loss: [1m[32m0.69141[0m[0m | time: 5.340s
[2K
| Adam | epoch: 005 | loss: 0.69141 - acc: 0.5256 -- iter: 288/332
[A[ATraining Step: 54  | total loss: [1m[32m0.69096[0m[0m | time: 6.040s
[2K
| Adam | epoch: 005 | loss: 0.69096 - acc: 0.5265 -- iter: 320/332
[A[ATraining Step: 55  | total loss: [1m[32m0.69014[0m[0m | time: 7.721s
[2K
| Adam | epoch: 005 | loss: 0.69014 - acc: 0.5316 | val_loss: 0.69147 - val_acc: 0.4904 -- iter: 332/332
--
Training Step: 56  | total loss: [1m[32m0.69106[0m[0m | time: 0.682s
[2K
| Adam | epoch: 006 | loss: 0.69106 - acc: 0.5184 -- iter: 032/332
[A[ATraining Step: 57  | total loss: [1m[32m0.69199[0m[0m | time: 1.360s
[2K
| Adam | epoch: 006 | loss: 0.69199 - acc: 0.5072 -- iter: 064/332
[A[ATraining Step: 58  | total loss: [1m[32m0.69106[0m[0m | time: 2.035s
[2K
| Adam | epoch: 006 | loss: 0.69106 - acc: 0.5062 -- iter: 096/332
[A[ATraining Step: 59  | total loss: [1m[32m0.68935[0m[0m | time: 2.302s
[2K
| Adam | epoch: 006 | loss: 0.68935 - acc: 0.5138 -- iter: 128/332
[A[ATraining Step: 60  | total loss: [1m[32m0.68887[0m[0m | time: 2.579s
[2K
| Adam | epoch: 006 | loss: 0.68887 - acc: 0.5009 -- iter: 160/332
[A[ATraining Step: 61  | total loss: [1m[32m0.68793[0m[0m | time: 3.255s
[2K
| Adam | epoch: 006 | loss: 0.68793 - acc: 0.4899 -- iter: 192/332
[A[ATraining Step: 62  | total loss: [1m[32m0.68650[0m[0m | time: 3.928s
[2K
| Adam | epoch: 006 | loss: 0.68650 - acc: 0.4872 -- iter: 224/332
[A[ATraining Step: 63  | total loss: [1m[32m0.68240[0m[0m | time: 4.592s
[2K
| Adam | epoch: 006 | loss: 0.68240 - acc: 0.5047 -- iter: 256/332
[A[ATraining Step: 64  | total loss: [1m[32m0.67685[0m[0m | time: 5.265s
[2K
| Adam | epoch: 006 | loss: 0.67685 - acc: 0.5236 -- iter: 288/332
[A[ATraining Step: 65  | total loss: [1m[32m0.67360[0m[0m | time: 5.971s
[2K
| Adam | epoch: 006 | loss: 0.67360 - acc: 0.5284 -- iter: 320/332
[A[ATraining Step: 66  | total loss: [1m[32m0.66864[0m[0m | time: 7.649s
[2K
| Adam | epoch: 006 | loss: 0.66864 - acc: 0.5364 | val_loss: 0.66482 - val_acc: 0.6250 -- iter: 332/332
--
Training Step: 67  | total loss: [1m[32m0.66402[0m[0m | time: 0.687s
[2K
| Adam | epoch: 007 | loss: 0.66402 - acc: 0.5695 -- iter: 032/332
[A[ATraining Step: 68  | total loss: [1m[32m0.65635[0m[0m | time: 1.399s
[2K
| Adam | epoch: 007 | loss: 0.65635 - acc: 0.5909 -- iter: 064/332
[A[ATraining Step: 69  | total loss: [1m[32m0.64369[0m[0m | time: 2.078s
[2K
| Adam | epoch: 007 | loss: 0.64369 - acc: 0.6204 -- iter: 096/332
[A[ATraining Step: 70  | total loss: [1m[32m0.62982[0m[0m | time: 2.759s
[2K
| Adam | epoch: 007 | loss: 0.62982 - acc: 0.6390 -- iter: 128/332
[A[ATraining Step: 71  | total loss: [1m[32m0.62804[0m[0m | time: 3.031s
[2K
| Adam | epoch: 007 | loss: 0.62804 - acc: 0.6516 -- iter: 160/332
[A[ATraining Step: 72  | total loss: [1m[32m0.63046[0m[0m | time: 3.317s
[2K
| Adam | epoch: 007 | loss: 0.63046 - acc: 0.6627 -- iter: 192/332
[A[ATraining Step: 73  | total loss: [1m[32m0.63360[0m[0m | time: 3.997s
[2K
| Adam | epoch: 007 | loss: 0.63360 - acc: 0.6631 -- iter: 224/332
[A[ATraining Step: 74  | total loss: [1m[32m0.62664[0m[0m | time: 4.687s
[2K
| Adam | epoch: 007 | loss: 0.62664 - acc: 0.6624 -- iter: 256/332
[A[ATraining Step: 75  | total loss: [1m[32m0.62066[0m[0m | time: 5.388s
[2K
| Adam | epoch: 007 | loss: 0.62066 - acc: 0.6685 -- iter: 288/332
[A[ATraining Step: 76  | total loss: [1m[32m0.61853[0m[0m | time: 6.065s
[2K
| Adam | epoch: 007 | loss: 0.61853 - acc: 0.6772 -- iter: 320/332
[A[ATraining Step: 77  | total loss: [1m[32m0.60739[0m[0m | time: 7.785s
[2K
| Adam | epoch: 007 | loss: 0.60739 - acc: 0.6849 | val_loss: 0.63436 - val_acc: 0.6538 -- iter: 332/332
--
Training Step: 78  | total loss: [1m[32m0.59920[0m[0m | time: 0.677s
[2K
| Adam | epoch: 008 | loss: 0.59920 - acc: 0.6950 -- iter: 032/332
[A[ATraining Step: 79  | total loss: [1m[32m0.59073[0m[0m | time: 1.352s
[2K
| Adam | epoch: 008 | loss: 0.59073 - acc: 0.6975 -- iter: 064/332
[A[ATraining Step: 80  | total loss: [1m[32m0.57755[0m[0m | time: 2.015s
[2K
| Adam | epoch: 008 | loss: 0.57755 - acc: 0.7092 -- iter: 096/332
[A[ATraining Step: 81  | total loss: [1m[32m0.56921[0m[0m | time: 2.705s
[2K
| Adam | epoch: 008 | loss: 0.56921 - acc: 0.7165 -- iter: 128/332
[A[ATraining Step: 82  | total loss: [1m[32m0.54996[0m[0m | time: 3.391s
[2K
| Adam | epoch: 008 | loss: 0.54996 - acc: 0.7292 -- iter: 160/332
[A[ATraining Step: 83  | total loss: [1m[32m0.53573[0m[0m | time: 3.656s
[2K
| Adam | epoch: 008 | loss: 0.53573 - acc: 0.7344 -- iter: 192/332
[A[ATraining Step: 84  | total loss: [1m[32m0.54552[0m[0m | time: 3.939s
[2K
| Adam | epoch: 008 | loss: 0.54552 - acc: 0.7360 -- iter: 224/332
[A[ATraining Step: 85  | total loss: [1m[32m0.55417[0m[0m | time: 4.615s
[2K
| Adam | epoch: 008 | loss: 0.55417 - acc: 0.7457 -- iter: 256/332
[A[ATraining Step: 86  | total loss: [1m[32m0.59849[0m[0m | time: 5.299s
[2K
| Adam | epoch: 008 | loss: 0.59849 - acc: 0.7274 -- iter: 288/332
[A[ATraining Step: 87  | total loss: [1m[32m0.58378[0m[0m | time: 5.982s
[2K
| Adam | epoch: 008 | loss: 0.58378 - acc: 0.7359 -- iter: 320/332
[A[ATraining Step: 88  | total loss: [1m[32m0.57464[0m[0m | time: 7.680s
[2K
| Adam | epoch: 008 | loss: 0.57464 - acc: 0.7404 | val_loss: 0.57697 - val_acc: 0.6731 -- iter: 332/332
--
Training Step: 89  | total loss: [1m[32m0.55640[0m[0m | time: 0.673s
[2K
| Adam | epoch: 009 | loss: 0.55640 - acc: 0.7570 -- iter: 032/332
[A[ATraining Step: 90  | total loss: [1m[32m0.55594[0m[0m | time: 1.343s
[2K
| Adam | epoch: 009 | loss: 0.55594 - acc: 0.7532 -- iter: 064/332
[A[ATraining Step: 91  | total loss: [1m[32m0.54993[0m[0m | time: 2.036s
[2K
| Adam | epoch: 009 | loss: 0.54993 - acc: 0.7529 -- iter: 096/332
[A[ATraining Step: 92  | total loss: [1m[32m0.55183[0m[0m | time: 2.714s
[2K
| Adam | epoch: 009 | loss: 0.55183 - acc: 0.7463 -- iter: 128/332
[A[ATraining Step: 93  | total loss: [1m[32m0.54065[0m[0m | time: 3.406s
[2K
| Adam | epoch: 009 | loss: 0.54065 - acc: 0.7561 -- iter: 160/332
[A[ATraining Step: 94  | total loss: [1m[32m0.53297[0m[0m | time: 4.097s
[2K
| Adam | epoch: 009 | loss: 0.53297 - acc: 0.7586 -- iter: 192/332
[A[ATraining Step: 95  | total loss: [1m[32m0.52118[0m[0m | time: 4.371s
[2K
| Adam | epoch: 009 | loss: 0.52118 - acc: 0.7671 -- iter: 224/332
[A[ATraining Step: 96  | total loss: [1m[32m0.50264[0m[0m | time: 4.647s
[2K
| Adam | epoch: 009 | loss: 0.50264 - acc: 0.7737 -- iter: 256/332
[A[ATraining Step: 97  | total loss: [1m[32m0.48319[0m[0m | time: 5.336s
[2K
| Adam | epoch: 009 | loss: 0.48319 - acc: 0.7880 -- iter: 288/332
[A[ATraining Step: 98  | total loss: [1m[32m0.48093[0m[0m | time: 6.023s
[2K
| Adam | epoch: 009 | loss: 0.48093 - acc: 0.7749 -- iter: 320/332
[A[ATraining Step: 99  | total loss: [1m[32m0.46735[0m[0m | time: 7.726s
[2K
| Adam | epoch: 009 | loss: 0.46735 - acc: 0.7849 | val_loss: 0.62944 - val_acc: 0.7019 -- iter: 332/332
--
Training Step: 100  | total loss: [1m[32m0.49407[0m[0m | time: 0.675s
[2K
| Adam | epoch: 010 | loss: 0.49407 - acc: 0.7751 -- iter: 032/332
[A[ATraining Step: 101  | total loss: [1m[32m0.48998[0m[0m | time: 1.352s
[2K
| Adam | epoch: 010 | loss: 0.48998 - acc: 0.7789 -- iter: 064/332
[A[ATraining Step: 102  | total loss: [1m[32m0.49939[0m[0m | time: 2.024s
[2K
| Adam | epoch: 010 | loss: 0.49939 - acc: 0.7760 -- iter: 096/332
[A[ATraining Step: 103  | total loss: [1m[32m0.49062[0m[0m | time: 2.704s
[2K
| Adam | epoch: 010 | loss: 0.49062 - acc: 0.7828 -- iter: 128/332
[A[ATraining Step: 104  | total loss: [1m[32m0.47629[0m[0m | time: 3.399s
[2K
| Adam | epoch: 010 | loss: 0.47629 - acc: 0.7889 -- iter: 160/332
[A[ATraining Step: 105  | total loss: [1m[32m0.48721[0m[0m | time: 4.069s
[2K
| Adam | epoch: 010 | loss: 0.48721 - acc: 0.7818 -- iter: 192/332
[A[ATraining Step: 106  | total loss: [1m[32m0.48105[0m[0m | time: 4.746s
[2K
| Adam | epoch: 010 | loss: 0.48105 - acc: 0.7818 -- iter: 224/332
[A[ATraining Step: 107  | total loss: [1m[32m0.46226[0m[0m | time: 5.017s
[2K
| Adam | epoch: 010 | loss: 0.46226 - acc: 0.7911 -- iter: 256/332
[A[ATraining Step: 108  | total loss: [1m[32m0.46013[0m[0m | time: 5.302s
[2K
| Adam | epoch: 010 | loss: 0.46013 - acc: 0.7870 -- iter: 288/332
[A[ATraining Step: 109  | total loss: [1m[32m0.45401[0m[0m | time: 5.978s
[2K
| Adam | epoch: 010 | loss: 0.45401 - acc: 0.7916 -- iter: 320/332
[A[ATraining Step: 110  | total loss: [1m[32m0.47139[0m[0m | time: 7.694s
[2K
| Adam | epoch: 010 | loss: 0.47139 - acc: 0.7718 | val_loss: 0.51908 - val_acc: 0.7692 -- iter: 332/332
--
Training Step: 111  | total loss: [1m[32m0.46675[0m[0m | time: 0.684s
[2K
| Adam | epoch: 011 | loss: 0.46675 - acc: 0.7759 -- iter: 032/332
[A[ATraining Step: 112  | total loss: [1m[32m0.47440[0m[0m | time: 1.365s
[2K
| Adam | epoch: 011 | loss: 0.47440 - acc: 0.7733 -- iter: 064/332
[A[ATraining Step: 113  | total loss: [1m[32m0.45824[0m[0m | time: 2.061s
[2K
| Adam | epoch: 011 | loss: 0.45824 - acc: 0.7835 -- iter: 096/332
[A[ATraining Step: 114  | total loss: [1m[32m0.45250[0m[0m | time: 2.766s
[2K
| Adam | epoch: 011 | loss: 0.45250 - acc: 0.7864 -- iter: 128/332
[A[ATraining Step: 115  | total loss: [1m[32m0.45397[0m[0m | time: 3.449s
[2K
| Adam | epoch: 011 | loss: 0.45397 - acc: 0.7827 -- iter: 160/332
[A[ATraining Step: 116  | total loss: [1m[32m0.44297[0m[0m | time: 4.117s
[2K
| Adam | epoch: 011 | loss: 0.44297 - acc: 0.7888 -- iter: 192/332
[A[ATraining Step: 117  | total loss: [1m[32m0.44396[0m[0m | time: 4.800s
[2K
| Adam | epoch: 011 | loss: 0.44396 - acc: 0.7850 -- iter: 224/332
[A[ATraining Step: 118  | total loss: [1m[32m0.43522[0m[0m | time: 5.486s
[2K
| Adam | epoch: 011 | loss: 0.43522 - acc: 0.7846 -- iter: 256/332
[A[ATraining Step: 119  | total loss: [1m[32m0.43103[0m[0m | time: 5.757s
[2K
| Adam | epoch: 011 | loss: 0.43103 - acc: 0.7874 -- iter: 288/332
[A[ATraining Step: 120  | total loss: [1m[32m0.43538[0m[0m | time: 6.023s
[2K
| Adam | epoch: 011 | loss: 0.43538 - acc: 0.7836 -- iter: 320/332
[A[ATraining Step: 121  | total loss: [1m[32m0.43135[0m[0m | time: 7.686s
[2K
| Adam | epoch: 011 | loss: 0.43135 - acc: 0.7886 | val_loss: 0.60177 - val_acc: 0.7308 -- iter: 332/332
--
Training Step: 122  | total loss: [1m[32m0.42689[0m[0m | time: 0.712s
[2K
| Adam | epoch: 012 | loss: 0.42689 - acc: 0.7879 -- iter: 032/332
[A[ATraining Step: 123  | total loss: [1m[32m0.42578[0m[0m | time: 1.406s
[2K
| Adam | epoch: 012 | loss: 0.42578 - acc: 0.7903 -- iter: 064/332
[A[ATraining Step: 124  | total loss: [1m[32m0.44119[0m[0m | time: 2.093s
[2K
| Adam | epoch: 012 | loss: 0.44119 - acc: 0.7988 -- iter: 096/332
[A[ATraining Step: 125  | total loss: [1m[32m0.43915[0m[0m | time: 2.768s
[2K
| Adam | epoch: 012 | loss: 0.43915 - acc: 0.8002 -- iter: 128/332
[A[ATraining Step: 126  | total loss: [1m[32m0.41835[0m[0m | time: 3.444s
[2K
| Adam | epoch: 012 | loss: 0.41835 - acc: 0.8139 -- iter: 160/332
[A[ATraining Step: 127  | total loss: [1m[32m0.40295[0m[0m | time: 4.109s
[2K
| Adam | epoch: 012 | loss: 0.40295 - acc: 0.8231 -- iter: 192/332
[A[ATraining Step: 128  | total loss: [1m[32m0.38949[0m[0m | time: 4.800s
[2K
| Adam | epoch: 012 | loss: 0.38949 - acc: 0.8315 -- iter: 224/332
[A[ATraining Step: 129  | total loss: [1m[32m0.38566[0m[0m | time: 5.460s
[2K
| Adam | epoch: 012 | loss: 0.38566 - acc: 0.8358 -- iter: 256/332
[A[ATraining Step: 130  | total loss: [1m[32m0.37070[0m[0m | time: 6.173s
[2K
| Adam | epoch: 012 | loss: 0.37070 - acc: 0.8460 -- iter: 288/332
[A[ATraining Step: 131  | total loss: [1m[32m0.36599[0m[0m | time: 6.444s
[2K
| Adam | epoch: 012 | loss: 0.36599 - acc: 0.8551 -- iter: 320/332
[A[ATraining Step: 132  | total loss: [1m[32m0.36549[0m[0m | time: 7.738s
[2K
| Adam | epoch: 012 | loss: 0.36549 - acc: 0.8529 | val_loss: 0.41488 - val_acc: 0.7981 -- iter: 332/332
--
Training Step: 133  | total loss: [1m[32m0.35938[0m[0m | time: 0.662s
[2K
| Adam | epoch: 013 | loss: 0.35938 - acc: 0.8510 -- iter: 032/332
[A[ATraining Step: 134  | total loss: [1m[32m0.35369[0m[0m | time: 1.345s
[2K
| Adam | epoch: 013 | loss: 0.35369 - acc: 0.8534 -- iter: 064/332
[A[ATraining Step: 135  | total loss: [1m[32m0.34315[0m[0m | time: 2.023s
[2K
| Adam | epoch: 013 | loss: 0.34315 - acc: 0.8587 -- iter: 096/332
[A[ATraining Step: 136  | total loss: [1m[32m0.33738[0m[0m | time: 2.696s
[2K
| Adam | epoch: 013 | loss: 0.33738 - acc: 0.8666 -- iter: 128/332
[A[ATraining Step: 137  | total loss: [1m[32m0.33012[0m[0m | time: 3.371s
[2K
| Adam | epoch: 013 | loss: 0.33012 - acc: 0.8674 -- iter: 160/332
[A[ATraining Step: 138  | total loss: [1m[32m0.31354[0m[0m | time: 4.060s
[2K
| Adam | epoch: 013 | loss: 0.31354 - acc: 0.8775 -- iter: 192/332
[A[ATraining Step: 139  | total loss: [1m[32m0.30398[0m[0m | time: 4.724s
[2K
| Adam | epoch: 013 | loss: 0.30398 - acc: 0.8773 -- iter: 224/332
[A[ATraining Step: 140  | total loss: [1m[32m0.29068[0m[0m | time: 5.405s
[2K
| Adam | epoch: 013 | loss: 0.29068 - acc: 0.8833 -- iter: 256/332
[A[ATraining Step: 141  | total loss: [1m[32m0.27293[0m[0m | time: 6.075s
[2K
| Adam | epoch: 013 | loss: 0.27293 - acc: 0.8918 -- iter: 288/332
[A[ATraining Step: 142  | total loss: [1m[32m0.26951[0m[0m | time: 6.736s
[2K
| Adam | epoch: 013 | loss: 0.26951 - acc: 0.8902 -- iter: 320/332
[A[ATraining Step: 143  | total loss: [1m[32m0.25808[0m[0m | time: 8.020s
[2K
| Adam | epoch: 013 | loss: 0.25808 - acc: 0.8949 | val_loss: 0.47451 - val_acc: 0.8365 -- iter: 332/332
--
Training Step: 144  | total loss: [1m[32m0.24356[0m[0m | time: 0.285s
[2K
| Adam | epoch: 014 | loss: 0.24356 - acc: 0.9054 -- iter: 032/332
[A[ATraining Step: 145  | total loss: [1m[32m0.22334[0m[0m | time: 0.948s
[2K
| Adam | epoch: 014 | loss: 0.22334 - acc: 0.9149 -- iter: 064/332
[A[ATraining Step: 146  | total loss: [1m[32m0.24116[0m[0m | time: 1.624s
[2K
| Adam | epoch: 014 | loss: 0.24116 - acc: 0.9078 -- iter: 096/332
[A[ATraining Step: 147  | total loss: [1m[32m0.24349[0m[0m | time: 2.299s
[2K
| Adam | epoch: 014 | loss: 0.24349 - acc: 0.9045 -- iter: 128/332
[A[ATraining Step: 148  | total loss: [1m[32m0.28274[0m[0m | time: 2.957s
[2K
| Adam | epoch: 014 | loss: 0.28274 - acc: 0.8922 -- iter: 160/332
[A[ATraining Step: 149  | total loss: [1m[32m0.26660[0m[0m | time: 3.637s
[2K
| Adam | epoch: 014 | loss: 0.26660 - acc: 0.8998 -- iter: 192/332
[A[ATraining Step: 150  | total loss: [1m[32m0.27965[0m[0m | time: 4.292s
[2K
| Adam | epoch: 014 | loss: 0.27965 - acc: 0.8973 -- iter: 224/332
[A[ATraining Step: 151  | total loss: [1m[32m0.27140[0m[0m | time: 4.966s
[2K
| Adam | epoch: 014 | loss: 0.27140 - acc: 0.9014 -- iter: 256/332
[A[ATraining Step: 152  | total loss: [1m[32m0.24817[0m[0m | time: 5.630s
[2K
| Adam | epoch: 014 | loss: 0.24817 - acc: 0.9112 -- iter: 288/332
[A[ATraining Step: 153  | total loss: [1m[32m0.23776[0m[0m | time: 6.310s
[2K
| Adam | epoch: 014 | loss: 0.23776 - acc: 0.9170 -- iter: 320/332
[A[ATraining Step: 154  | total loss: [1m[32m0.22410[0m[0m | time: 7.989s
[2K
| Adam | epoch: 014 | loss: 0.22410 - acc: 0.9221 | val_loss: 0.29859 - val_acc: 0.8846 -- iter: 332/332
--
Training Step: 155  | total loss: [1m[32m0.20693[0m[0m | time: 0.275s
[2K
| Adam | epoch: 015 | loss: 0.20693 - acc: 0.9299 -- iter: 032/332
[A[ATraining Step: 156  | total loss: [1m[32m0.19185[0m[0m | time: 0.557s
[2K
| Adam | epoch: 015 | loss: 0.19185 - acc: 0.9369 -- iter: 064/332
[A[ATraining Step: 157  | total loss: [1m[32m0.17680[0m[0m | time: 1.247s
[2K
| Adam | epoch: 015 | loss: 0.17680 - acc: 0.9432 -- iter: 096/332
[A[ATraining Step: 158  | total loss: [1m[32m0.18538[0m[0m | time: 1.925s
[2K
| Adam | epoch: 015 | loss: 0.18538 - acc: 0.9333 -- iter: 128/332
[A[ATraining Step: 159  | total loss: [1m[32m0.18117[0m[0m | time: 2.629s
[2K
| Adam | epoch: 015 | loss: 0.18117 - acc: 0.9337 -- iter: 160/332
[A[ATraining Step: 160  | total loss: [1m[32m0.16806[0m[0m | time: 3.324s
[2K
| Adam | epoch: 015 | loss: 0.16806 - acc: 0.9403 -- iter: 192/332
[A[ATraining Step: 161  | total loss: [1m[32m0.15996[0m[0m | time: 3.988s
[2K
| Adam | epoch: 015 | loss: 0.15996 - acc: 0.9463 -- iter: 224/332
[A[ATraining Step: 162  | total loss: [1m[32m0.16884[0m[0m | time: 4.655s
[2K
| Adam | epoch: 015 | loss: 0.16884 - acc: 0.9392 -- iter: 256/332
[A[ATraining Step: 163  | total loss: [1m[32m0.16105[0m[0m | time: 5.332s
[2K
| Adam | epoch: 015 | loss: 0.16105 - acc: 0.9390 -- iter: 288/332
[A[ATraining Step: 164  | total loss: [1m[32m0.15669[0m[0m | time: 6.005s
[2K
| Adam | epoch: 015 | loss: 0.15669 - acc: 0.9420 -- iter: 320/332
[A[ATraining Step: 165  | total loss: [1m[32m0.16354[0m[0m | time: 7.673s
[2K
| Adam | epoch: 015 | loss: 0.16354 - acc: 0.9384 | val_loss: 0.35771 - val_acc: 0.8462 -- iter: 332/332
--
Validation AUC:0.9456159822419534
Validation AUPRC:0.9500716382680205
Test AUC:0.9496080627099666
Test AUPRC:0.955299211286968
BestTestF1Score	0.92	0.83	0.91	0.91	0.93	53	5	42	4	0.15
BestTestMCCScore	0.88	0.76	0.88	0.96	0.81	46	2	45	11	0.87
BestTestAccuracyScore	0.88	0.76	0.88	0.96	0.81	46	2	45	11	0.87
BestValidationF1Score	0.88	0.76	0.88	0.83	0.94	50	10	41	3	0.15
BestValidationMCC	0.86	0.77	0.88	0.98	0.77	41	1	50	12	0.87
BestValidationAccuracy	0.86	0.77	0.88	0.98	0.77	41	1	50	12	0.87
TestPredictions (Threshold:0.87)
CHEMBL610121,TP,ACT,0.8700000047683716	CHEMBL138746,TP,ACT,1.0	CHEMBL2113620,TP,ACT,1.0	CHEMBL2413106,TP,ACT,0.9200000166893005	CHEMBL610675,TN,INACT,0.15000000596046448	CHEMBL477,FN,ACT,0.029999999329447746	CHEMBL204820,TP,ACT,0.9800000190734863	CHEMBL89203,TN,INACT,0.07000000029802322	CHEMBL1791443,TP,ACT,1.0	CHEMBL515170,TN,INACT,0.009999999776482582	CHEMBL77962,TN,INACT,0.009999999776482582	CHEMBL593861,TN,INACT,0.009999999776482582	CHEMBL45305,TN,INACT,0.09000000357627869	CHEMBL26522,TN,INACT,0.009999999776482582	CHEMBL364671,TP,ACT,1.0	CHEMBL97687,FN,ACT,0.009999999776482582	CHEMBL610426,TP,ACT,1.0	CHEMBL2042403,TN,INACT,0.05999999865889549	CHEMBL2113637,TP,ACT,1.0	CHEMBL593443,TN,INACT,0.0	CHEMBL88506,TN,INACT,0.0	CHEMBL608761,FN,ACT,0.1599999964237213	CHEMBL2113701,TP,ACT,1.0	CHEMBL200732,TP,ACT,1.0	CHEMBL203933,TP,ACT,1.0	CHEMBL78830,TN,INACT,0.009999999776482582	CHEMBL2113540,TP,ACT,1.0	CHEMBL2113567,TP,ACT,1.0	CHEMBL279520,TN,INACT,0.0	CHEMBL175698,TN,INACT,0.009999999776482582	CHEMBL2113615,TP,ACT,1.0	CHEMBL2112162,TP,ACT,0.8999999761581421	CHEMBL114760,TN,INACT,0.5699999928474426	CHEMBL400189,TP,ACT,0.9399999976158142	CHEMBL408493,TN,INACT,0.03999999910593033	CHEMBL80317,TN,INACT,0.0	CHEMBL3125712,TP,ACT,0.8899999856948853	CHEMBL2113418,TP,ACT,0.9900000095367432	CHEMBL583745,FN,ACT,0.6899999976158142	CHEMBL48448,TN,INACT,0.09000000357627869	CHEMBL285819,FN,ACT,0.44999998807907104	CHEMBL450729,TN,INACT,0.0	CHEMBL175228,TN,INACT,0.0	CHEMBL2413107,FN,ACT,0.8399999737739563	CHEMBL2113415,TP,ACT,1.0	CHEMBL612203,TP,ACT,0.9599999785423279	CHEMBL609642,TP,ACT,1.0	CHEMBL2113693,FN,ACT,0.1599999964237213	CHEMBL99331,FP,INACT,1.0	CHEMBL522152,TP,ACT,1.0	CHEMBL311455,TN,INACT,0.0	CHEMBL2112157,TP,ACT,0.8899999856948853	CHEMBL110695,TN,INACT,0.0	CHEMBL2113395,TP,ACT,1.0	CHEMBL609340,TP,ACT,1.0	CHEMBL3351031,FN,ACT,0.23999999463558197	CHEMBL383268,TP,ACT,1.0	CHEMBL295651,TN,INACT,0.03999999910593033	CHEMBL610143,TP,ACT,1.0	CHEMBL331382,TP,ACT,1.0	CHEMBL47404,TN,INACT,0.03999999910593033	CHEMBL2113702,TN,INACT,0.009999999776482582	CHEMBL105672,FN,ACT,0.03999999910593033	CHEMBL48031,TN,INACT,0.0	CHEMBL45456,TN,INACT,0.0	CHEMBL379472,TP,ACT,0.9800000190734863	CHEMBL494086,TP,ACT,0.9800000190734863	CHEMBL519809,TP,ACT,0.9800000190734863	CHEMBL59347,TN,INACT,0.03999999910593033	CHEMBL3125718,TP,ACT,0.8899999856948853	CHEMBL40986,TN,INACT,0.009999999776482582	CHEMBL205058,TP,ACT,0.9900000095367432	CHEMBL2113634,TP,ACT,1.0	CHEMBL3780633,TN,INACT,0.029999999329447746	CHEMBL607784,TP,ACT,1.0	CHEMBL2113635,TP,ACT,1.0	CHEMBL112777,TN,INACT,0.11999999731779099	CHEMBL2113616,TP,ACT,1.0	CHEMBL444550,TP,ACT,0.9900000095367432	CHEMBL513277,TN,INACT,0.0	CHEMBL330003,TN,INACT,0.019999999552965164	CHEMBL3125719,TP,ACT,0.8899999856948853	CHEMBL2113572,TP,ACT,1.0	CHEMBL204246,TP,ACT,1.0	CHEMBL2113638,TP,ACT,1.0	CHEMBL2368369,FN,ACT,0.019999999552965164	CHEMBL2312376,TN,INACT,0.009999999776482582	CHEMBL500569,TP,ACT,0.9900000095367432	CHEMBL327554,TP,ACT,1.0	CHEMBL353502,TN,INACT,0.019999999552965164	CHEMBL168632,FP,INACT,1.0	CHEMBL174463,TN,INACT,0.2800000011920929	CHEMBL2093084,TN,INACT,0.009999999776482582	CHEMBL79030,TN,INACT,0.07000000029802322	CHEMBL2113700,TN,INACT,0.019999999552965164	CHEMBL1180343,TN,INACT,0.029999999329447746	CHEMBL369359,TN,INACT,0.0	CHEMBL2113687,FN,ACT,0.15000000596046448	CHEMBL312551,TN,INACT,0.009999999776482582	CHEMBL311781,TN,INACT,0.009999999776482582	CHEMBL81593,TN,INACT,0.009999999776482582	CHEMBL461088,TN,INACT,0.0	CHEMBL610326,TP,ACT,1.0	CHEMBL112770,TN,INACT,0.009999999776482582	

