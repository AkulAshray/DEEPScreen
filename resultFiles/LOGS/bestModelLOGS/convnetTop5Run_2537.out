ImageNetInceptionV2 CHEMBL3268 adam 0.001 30 0 0 0.8 False True
Number of active compounds :	162
Number of inactive compounds :	162
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3268_adam_0.001_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3268_adam_0.001_30_0.8/
---------------------------------
Training samples: 204
Validation samples: 65
--
Training Step: 1  | time: 36.738s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/204
[A[ATraining Step: 2  | total loss: [1m[32m0.64813[0m[0m | time: 44.739s
[2K
| Adam | epoch: 001 | loss: 0.64813 - acc: 0.3094 -- iter: 064/204
[A[ATraining Step: 3  | total loss: [1m[32m0.71877[0m[0m | time: 52.843s
[2K
| Adam | epoch: 001 | loss: 0.71877 - acc: 0.5420 -- iter: 096/204
[A[ATraining Step: 4  | total loss: [1m[32m0.93950[0m[0m | time: 61.178s
[2K
| Adam | epoch: 001 | loss: 0.93950 - acc: 0.5105 -- iter: 128/204
[A[ATraining Step: 5  | total loss: [1m[32m0.80471[0m[0m | time: 69.402s
[2K
| Adam | epoch: 001 | loss: 0.80471 - acc: 0.5465 -- iter: 160/204
[A[ATraining Step: 6  | total loss: [1m[32m0.77649[0m[0m | time: 77.421s
[2K
| Adam | epoch: 001 | loss: 0.77649 - acc: 0.5769 -- iter: 192/204
[A[ATraining Step: 7  | total loss: [1m[32m0.62376[0m[0m | time: 89.935s
[2K
| Adam | epoch: 001 | loss: 0.62376 - acc: 0.6995 | val_loss: 1.27283 - val_acc: 0.6308 -- iter: 204/204
--
Training Step: 8  | total loss: [1m[32m0.74487[0m[0m | time: 3.797s
[2K
| Adam | epoch: 002 | loss: 0.74487 - acc: 0.5873 -- iter: 032/204
[A[ATraining Step: 9  | total loss: [1m[32m0.64573[0m[0m | time: 12.401s
[2K
| Adam | epoch: 002 | loss: 0.64573 - acc: 0.5852 -- iter: 064/204
[A[ATraining Step: 10  | total loss: [1m[32m0.59338[0m[0m | time: 21.041s
[2K
| Adam | epoch: 002 | loss: 0.59338 - acc: 0.6832 -- iter: 096/204
[A[ATraining Step: 11  | total loss: [1m[32m0.56692[0m[0m | time: 29.293s
[2K
| Adam | epoch: 002 | loss: 0.56692 - acc: 0.7149 -- iter: 128/204
[A[ATraining Step: 12  | total loss: [1m[32m0.54841[0m[0m | time: 37.113s
[2K
| Adam | epoch: 002 | loss: 0.54841 - acc: 0.7166 -- iter: 160/204
[A[ATraining Step: 13  | total loss: [1m[32m0.64792[0m[0m | time: 44.855s
[2K
| Adam | epoch: 002 | loss: 0.64792 - acc: 0.6773 -- iter: 192/204
[A[ATraining Step: 14  | total loss: [1m[32m0.60374[0m[0m | time: 56.826s
[2K
| Adam | epoch: 002 | loss: 0.60374 - acc: 0.6943 | val_loss: 3.91679 - val_acc: 0.6308 -- iter: 204/204
--
Training Step: 15  | total loss: [1m[32m0.53099[0m[0m | time: 3.591s
[2K
| Adam | epoch: 003 | loss: 0.53099 - acc: 0.7528 -- iter: 032/204
[A[ATraining Step: 16  | total loss: [1m[32m0.50339[0m[0m | time: 7.010s
[2K
| Adam | epoch: 003 | loss: 0.50339 - acc: 0.7830 -- iter: 064/204
[A[ATraining Step: 17  | total loss: [1m[32m0.41802[0m[0m | time: 15.737s
[2K
| Adam | epoch: 003 | loss: 0.41802 - acc: 0.8311 -- iter: 096/204
[A[ATraining Step: 18  | total loss: [1m[32m0.39896[0m[0m | time: 23.944s
[2K
| Adam | epoch: 003 | loss: 0.39896 - acc: 0.8138 -- iter: 128/204
[A[ATraining Step: 19  | total loss: [1m[32m0.44254[0m[0m | time: 32.001s
[2K
| Adam | epoch: 003 | loss: 0.44254 - acc: 0.7717 -- iter: 160/204
[A[ATraining Step: 20  | total loss: [1m[32m0.42337[0m[0m | time: 40.169s
[2K
| Adam | epoch: 003 | loss: 0.42337 - acc: 0.7748 -- iter: 192/204
[A[ATraining Step: 21  | total loss: [1m[32m0.50228[0m[0m | time: 51.397s
[2K
| Adam | epoch: 003 | loss: 0.50228 - acc: 0.7671 | val_loss: 4.45784 - val_acc: 0.6308 -- iter: 204/204
--
Training Step: 22  | total loss: [1m[32m0.50344[0m[0m | time: 7.826s
[2K
| Adam | epoch: 004 | loss: 0.50344 - acc: 0.7713 -- iter: 032/204
[A[ATraining Step: 23  | total loss: [1m[32m0.48472[0m[0m | time: 11.326s
[2K
| Adam | epoch: 004 | loss: 0.48472 - acc: 0.8014 -- iter: 064/204
[A[ATraining Step: 24  | total loss: [1m[32m0.49444[0m[0m | time: 14.827s
[2K
| Adam | epoch: 004 | loss: 0.49444 - acc: 0.7870 -- iter: 096/204
[A[ATraining Step: 25  | total loss: [1m[32m0.37776[0m[0m | time: 22.762s
[2K
| Adam | epoch: 004 | loss: 0.37776 - acc: 0.8451 -- iter: 128/204
[A[ATraining Step: 26  | total loss: [1m[32m0.35889[0m[0m | time: 30.901s
[2K
| Adam | epoch: 004 | loss: 0.35889 - acc: 0.8613 -- iter: 160/204
[A[ATraining Step: 27  | total loss: [1m[32m0.37214[0m[0m | time: 38.876s
[2K
| Adam | epoch: 004 | loss: 0.37214 - acc: 0.8487 -- iter: 192/204
[A[ATraining Step: 28  | total loss: [1m[32m0.36834[0m[0m | time: 49.787s
[2K
| Adam | epoch: 004 | loss: 0.36834 - acc: 0.8631 | val_loss: 4.19991 - val_acc: 0.6308 -- iter: 204/204
--
Training Step: 29  | total loss: [1m[32m0.40670[0m[0m | time: 8.000s
[2K
| Adam | epoch: 005 | loss: 0.40670 - acc: 0.8508 -- iter: 032/204
[A[ATraining Step: 30  | total loss: [1m[32m0.47623[0m[0m | time: 15.931s
[2K
| Adam | epoch: 005 | loss: 0.47623 - acc: 0.8343 -- iter: 064/204
[A[ATraining Step: 31  | total loss: [1m[32m0.43062[0m[0m | time: 19.370s
[2K
| Adam | epoch: 005 | loss: 0.43062 - acc: 0.8365 -- iter: 096/204
[A[ATraining Step: 32  | total loss: [1m[32m0.37723[0m[0m | time: 22.965s
[2K
| Adam | epoch: 005 | loss: 0.37723 - acc: 0.8545 -- iter: 128/204
[A[ATraining Step: 33  | total loss: [1m[32m0.30561[0m[0m | time: 31.017s
[2K
| Adam | epoch: 005 | loss: 0.30561 - acc: 0.8865 -- iter: 160/204
[A[ATraining Step: 34  | total loss: [1m[32m0.35382[0m[0m | time: 39.226s
[2K
| Adam | epoch: 005 | loss: 0.35382 - acc: 0.8572 -- iter: 192/204
[A[ATraining Step: 35  | total loss: [1m[32m0.35571[0m[0m | time: 50.055s
[2K
| Adam | epoch: 005 | loss: 0.35571 - acc: 0.8544 | val_loss: 4.09656 - val_acc: 0.6308 -- iter: 204/204
--
Training Step: 36  | total loss: [1m[32m0.32578[0m[0m | time: 7.942s
[2K
| Adam | epoch: 006 | loss: 0.32578 - acc: 0.8714 -- iter: 032/204
[A[ATraining Step: 37  | total loss: [1m[32m0.29258[0m[0m | time: 15.788s
[2K
| Adam | epoch: 006 | loss: 0.29258 - acc: 0.8909 -- iter: 064/204
[A[ATraining Step: 38  | total loss: [1m[32m0.28406[0m[0m | time: 23.903s
[2K
| Adam | epoch: 006 | loss: 0.28406 - acc: 0.9000 -- iter: 096/204
[A[ATraining Step: 39  | total loss: [1m[32m0.35755[0m[0m | time: 27.455s
[2K
| Adam | epoch: 006 | loss: 0.35755 - acc: 0.8713 -- iter: 128/204
[A[ATraining Step: 40  | total loss: [1m[32m0.30069[0m[0m | time: 30.956s
[2K
| Adam | epoch: 006 | loss: 0.30069 - acc: 0.8954 -- iter: 160/204
[A[ATraining Step: 41  | total loss: [1m[32m0.25373[0m[0m | time: 38.761s
[2K
| Adam | epoch: 006 | loss: 0.25373 - acc: 0.9146 -- iter: 192/204
[A[ATraining Step: 42  | total loss: [1m[32m0.23439[0m[0m | time: 49.714s
[2K
| Adam | epoch: 006 | loss: 0.23439 - acc: 0.9244 | val_loss: 4.22517 - val_acc: 0.6308 -- iter: 204/204
--
Training Step: 43  | total loss: [1m[32m0.20394[0m[0m | time: 7.777s
[2K
| Adam | epoch: 007 | loss: 0.20394 - acc: 0.9377 -- iter: 032/204
[A[ATraining Step: 44  | total loss: [1m[32m0.20376[0m[0m | time: 15.761s
[2K
| Adam | epoch: 007 | loss: 0.20376 - acc: 0.9377 -- iter: 064/204
[A[ATraining Step: 45  | total loss: [1m[32m0.22087[0m[0m | time: 23.629s
[2K
| Adam | epoch: 007 | loss: 0.22087 - acc: 0.9323 -- iter: 096/204
[A[ATraining Step: 46  | total loss: [1m[32m0.22741[0m[0m | time: 31.579s
[2K
| Adam | epoch: 007 | loss: 0.22741 - acc: 0.9228 -- iter: 128/204
[A[ATraining Step: 47  | total loss: [1m[32m0.24545[0m[0m | time: 35.051s
[2K
| Adam | epoch: 007 | loss: 0.24545 - acc: 0.9098 -- iter: 160/204
[A[ATraining Step: 48  | total loss: [1m[32m0.22059[0m[0m | time: 38.558s
[2K
| Adam | epoch: 007 | loss: 0.22059 - acc: 0.9243 -- iter: 192/204
[A[ATraining Step: 49  | total loss: [1m[32m0.18866[0m[0m | time: 49.403s
[2K
| Adam | epoch: 007 | loss: 0.18866 - acc: 0.9363 | val_loss: 0.72030 - val_acc: 0.7538 -- iter: 204/204
--
Training Step: 50  | total loss: [1m[32m0.16329[0m[0m | time: 7.852s
[2K
| Adam | epoch: 008 | loss: 0.16329 - acc: 0.9462 -- iter: 032/204
[A[ATraining Step: 51  | total loss: [1m[32m0.16250[0m[0m | time: 15.712s
[2K
| Adam | epoch: 008 | loss: 0.16250 - acc: 0.9448 -- iter: 064/204
[A[ATraining Step: 52  | total loss: [1m[32m0.16979[0m[0m | time: 23.469s
[2K
| Adam | epoch: 008 | loss: 0.16979 - acc: 0.9297 -- iter: 096/204
[A[ATraining Step: 53  | total loss: [1m[32m0.19320[0m[0m | time: 31.169s
[2K
| Adam | epoch: 008 | loss: 0.19320 - acc: 0.9262 -- iter: 128/204
[A[ATraining Step: 54  | total loss: [1m[32m0.19324[0m[0m | time: 39.007s
[2K
| Adam | epoch: 008 | loss: 0.19324 - acc: 0.9324 -- iter: 160/204
[A[ATraining Step: 55  | total loss: [1m[32m0.21746[0m[0m | time: 42.467s
[2K
| Adam | epoch: 008 | loss: 0.21746 - acc: 0.9197 -- iter: 192/204
[A[ATraining Step: 56  | total loss: [1m[32m0.28549[0m[0m | time: 48.910s
[2K
| Adam | epoch: 008 | loss: 0.28549 - acc: 0.8959 | val_loss: 0.59550 - val_acc: 0.7385 -- iter: 204/204
--
Training Step: 57  | total loss: [1m[32m0.26765[0m[0m | time: 7.697s
[2K
| Adam | epoch: 009 | loss: 0.26765 - acc: 0.8987 -- iter: 032/204
[A[ATraining Step: 58  | total loss: [1m[32m0.23750[0m[0m | time: 15.568s
[2K
| Adam | epoch: 009 | loss: 0.23750 - acc: 0.9126 -- iter: 064/204
[A[ATraining Step: 59  | total loss: [1m[32m0.21825[0m[0m | time: 23.364s
[2K
| Adam | epoch: 009 | loss: 0.21825 - acc: 0.9201 -- iter: 096/204
[A[ATraining Step: 60  | total loss: [1m[32m0.21733[0m[0m | time: 31.009s
[2K
| Adam | epoch: 009 | loss: 0.21733 - acc: 0.9141 -- iter: 128/204
[A[ATraining Step: 61  | total loss: [1m[32m0.22889[0m[0m | time: 38.795s
[2K
| Adam | epoch: 009 | loss: 0.22889 - acc: 0.9050 -- iter: 160/204
[A[ATraining Step: 62  | total loss: [1m[32m0.20603[0m[0m | time: 46.569s
[2K
| Adam | epoch: 009 | loss: 0.20603 - acc: 0.9172 -- iter: 192/204
[A[ATraining Step: 63  | total loss: [1m[32m0.19530[0m[0m | time: 52.944s
[2K
| Adam | epoch: 009 | loss: 0.19530 - acc: 0.9237 | val_loss: 1.92609 - val_acc: 0.6462 -- iter: 204/204
--
Training Step: 64  | total loss: [1m[32m0.26903[0m[0m | time: 3.504s
[2K
| Adam | epoch: 010 | loss: 0.26903 - acc: 0.9124 -- iter: 032/204
[A[ATraining Step: 65  | total loss: [1m[32m0.24086[0m[0m | time: 11.310s
[2K
| Adam | epoch: 010 | loss: 0.24086 - acc: 0.9232 -- iter: 064/204
[A[ATraining Step: 66  | total loss: [1m[32m0.22792[0m[0m | time: 19.175s
[2K
| Adam | epoch: 010 | loss: 0.22792 - acc: 0.9288 -- iter: 096/204
[A[ATraining Step: 67  | total loss: [1m[32m0.27292[0m[0m | time: 26.975s
[2K
| Adam | epoch: 010 | loss: 0.27292 - acc: 0.9073 -- iter: 128/204
[A[ATraining Step: 68  | total loss: [1m[32m0.28873[0m[0m | time: 34.862s
[2K
| Adam | epoch: 010 | loss: 0.28873 - acc: 0.9072 -- iter: 160/204
[A[ATraining Step: 69  | total loss: [1m[32m0.28507[0m[0m | time: 42.662s
[2K
| Adam | epoch: 010 | loss: 0.28507 - acc: 0.8998 -- iter: 192/204
[A[ATraining Step: 70  | total loss: [1m[32m0.28744[0m[0m | time: 53.350s
[2K
| Adam | epoch: 010 | loss: 0.28744 - acc: 0.9005 | val_loss: 1.67907 - val_acc: 0.6462 -- iter: 204/204
--
Training Step: 71  | total loss: [1m[32m0.28493[0m[0m | time: 3.536s
[2K
| Adam | epoch: 011 | loss: 0.28493 - acc: 0.9047 -- iter: 032/204
[A[ATraining Step: 72  | total loss: [1m[32m0.30994[0m[0m | time: 7.017s
[2K
| Adam | epoch: 011 | loss: 0.30994 - acc: 0.8967 -- iter: 064/204
[A[ATraining Step: 73  | total loss: [1m[32m0.29367[0m[0m | time: 14.615s
[2K
| Adam | epoch: 011 | loss: 0.29367 - acc: 0.8989 -- iter: 096/204
[A[ATraining Step: 74  | total loss: [1m[32m0.27393[0m[0m | time: 22.600s
[2K
| Adam | epoch: 011 | loss: 0.27393 - acc: 0.9066 -- iter: 128/204
[A[ATraining Step: 75  | total loss: [1m[32m0.26541[0m[0m | time: 30.187s
[2K
| Adam | epoch: 011 | loss: 0.26541 - acc: 0.9099 -- iter: 160/204
[A[ATraining Step: 76  | total loss: [1m[32m0.29470[0m[0m | time: 38.061s
[2K
| Adam | epoch: 011 | loss: 0.29470 - acc: 0.8995 -- iter: 192/204
[A[ATraining Step: 77  | total loss: [1m[32m0.28390[0m[0m | time: 48.846s
[2K
| Adam | epoch: 011 | loss: 0.28390 - acc: 0.8969 | val_loss: 1.71398 - val_acc: 0.6308 -- iter: 204/204
--
Training Step: 78  | total loss: [1m[32m0.26951[0m[0m | time: 7.829s
[2K
| Adam | epoch: 012 | loss: 0.26951 - acc: 0.9011 -- iter: 032/204
[A[ATraining Step: 79  | total loss: [1m[32m0.25920[0m[0m | time: 11.284s
[2K
| Adam | epoch: 012 | loss: 0.25920 - acc: 0.9017 -- iter: 064/204
[A[ATraining Step: 80  | total loss: [1m[32m0.30519[0m[0m | time: 14.691s
[2K
| Adam | epoch: 012 | loss: 0.30519 - acc: 0.9032 -- iter: 096/204
[A[ATraining Step: 81  | total loss: [1m[32m0.27911[0m[0m | time: 22.486s
[2K
| Adam | epoch: 012 | loss: 0.27911 - acc: 0.9130 -- iter: 128/204
[A[ATraining Step: 82  | total loss: [1m[32m0.26346[0m[0m | time: 30.227s
[2K
| Adam | epoch: 012 | loss: 0.26346 - acc: 0.9154 -- iter: 160/204
[A[ATraining Step: 83  | total loss: [1m[32m0.27177[0m[0m | time: 38.079s
[2K
| Adam | epoch: 012 | loss: 0.27177 - acc: 0.9083 -- iter: 192/204
[A[ATraining Step: 84  | total loss: [1m[32m0.27147[0m[0m | time: 48.791s
[2K
| Adam | epoch: 012 | loss: 0.27147 - acc: 0.9112 | val_loss: 0.75546 - val_acc: 0.7692 -- iter: 204/204
--
Training Step: 85  | total loss: [1m[32m0.25916[0m[0m | time: 8.164s
[2K
| Adam | epoch: 013 | loss: 0.25916 - acc: 0.9170 -- iter: 032/204
[A[ATraining Step: 86  | total loss: [1m[32m0.25261[0m[0m | time: 15.791s
[2K
| Adam | epoch: 013 | loss: 0.25261 - acc: 0.9221 -- iter: 064/204
[A[ATraining Step: 87  | total loss: [1m[32m0.30662[0m[0m | time: 19.295s
[2K
| Adam | epoch: 013 | loss: 0.30662 - acc: 0.9018 -- iter: 096/204
[A[ATraining Step: 88  | total loss: [1m[32m0.31189[0m[0m | time: 22.793s
[2K
| Adam | epoch: 013 | loss: 0.31189 - acc: 0.8949 -- iter: 128/204
[A[ATraining Step: 89  | total loss: [1m[32m0.28704[0m[0m | time: 32.485s
[2K
| Adam | epoch: 013 | loss: 0.28704 - acc: 0.9055 -- iter: 160/204
[A[ATraining Step: 90  | total loss: [1m[32m0.28276[0m[0m | time: 46.164s
[2K
| Adam | epoch: 013 | loss: 0.28276 - acc: 0.9087 -- iter: 192/204
[A[ATraining Step: 91  | total loss: [1m[32m0.26511[0m[0m | time: 69.932s
[2K
| Adam | epoch: 013 | loss: 0.26511 - acc: 0.9115 | val_loss: 2.04577 - val_acc: 0.4308 -- iter: 204/204
--
Training Step: 92  | total loss: [1m[32m0.24788[0m[0m | time: 16.116s
[2K
| Adam | epoch: 014 | loss: 0.24788 - acc: 0.9173 -- iter: 032/204
[A[ATraining Step: 93  | total loss: [1m[32m0.22930[0m[0m | time: 31.402s
[2K
| Adam | epoch: 014 | loss: 0.22930 - acc: 0.9224 -- iter: 064/204
[A[ATraining Step: 94  | total loss: [1m[32m0.23519[0m[0m | time: 48.180s
[2K
| Adam | epoch: 014 | loss: 0.23519 - acc: 0.9177 -- iter: 096/204
[A[ATraining Step: 95  | total loss: [1m[32m0.22645[0m[0m | time: 53.973s
[2K
| Adam | epoch: 014 | loss: 0.22645 - acc: 0.9228 -- iter: 128/204
[A[ATraining Step: 96  | total loss: [1m[32m0.26444[0m[0m | time: 58.784s
[2K
| Adam | epoch: 014 | loss: 0.26444 - acc: 0.9138 -- iter: 160/204
[A[ATraining Step: 97  | total loss: [1m[32m0.24055[0m[0m | time: 73.984s
[2K
| Adam | epoch: 014 | loss: 0.24055 - acc: 0.9225 -- iter: 192/204
[A[ATraining Step: 98  | total loss: [1m[32m0.23195[0m[0m | time: 101.779s
[2K
| Adam | epoch: 014 | loss: 0.23195 - acc: 0.9240 | val_loss: 1.41415 - val_acc: 0.6615 -- iter: 204/204
--
Training Step: 99  | total loss: [1m[32m0.23586[0m[0m | time: 12.093s
[2K
| Adam | epoch: 015 | loss: 0.23586 - acc: 0.9253 -- iter: 032/204
[A[ATraining Step: 100  | total loss: [1m[32m0.23382[0m[0m | time: 24.281s
[2K
| Adam | epoch: 015 | loss: 0.23382 - acc: 0.9203 -- iter: 064/204
[A[ATraining Step: 101  | total loss: [1m[32m0.22892[0m[0m | time: 36.759s
[2K
| Adam | epoch: 015 | loss: 0.22892 - acc: 0.9220 -- iter: 096/204
[A[ATraining Step: 102  | total loss: [1m[32m0.23322[0m[0m | time: 48.762s
[2K
| Adam | epoch: 015 | loss: 0.23322 - acc: 0.9204 -- iter: 128/204
[A[ATraining Step: 103  | total loss: [1m[32m0.22327[0m[0m | time: 54.193s
[2K
| Adam | epoch: 015 | loss: 0.22327 - acc: 0.9253 -- iter: 160/204
[A[ATraining Step: 104  | total loss: [1m[32m0.23397[0m[0m | time: 59.648s
[2K
| Adam | epoch: 015 | loss: 0.23397 - acc: 0.9161 -- iter: 192/204
[A[ATraining Step: 105  | total loss: [1m[32m0.21856[0m[0m | time: 76.027s
[2K
| Adam | epoch: 015 | loss: 0.21856 - acc: 0.9245 | val_loss: 0.81635 - val_acc: 0.6923 -- iter: 204/204
--
Training Step: 106  | total loss: [1m[32m0.22234[0m[0m | time: 12.639s
[2K
| Adam | epoch: 016 | loss: 0.22234 - acc: 0.9164 -- iter: 032/204
[A[ATraining Step: 107  | total loss: [1m[32m0.23262[0m[0m | time: 25.675s
[2K
| Adam | epoch: 016 | loss: 0.23262 - acc: 0.9122 -- iter: 064/204
[A[ATraining Step: 108  | total loss: [1m[32m0.22437[0m[0m | time: 37.979s
[2K
| Adam | epoch: 016 | loss: 0.22437 - acc: 0.9148 -- iter: 096/204
[A[ATraining Step: 109  | total loss: [1m[32m0.23788[0m[0m | time: 48.910s
[2K
| Adam | epoch: 016 | loss: 0.23788 - acc: 0.9139 -- iter: 128/204
[A[ATraining Step: 110  | total loss: [1m[32m0.23705[0m[0m | time: 61.140s
[2K
| Adam | epoch: 016 | loss: 0.23705 - acc: 0.9194 -- iter: 160/204
[A[ATraining Step: 111  | total loss: [1m[32m0.23908[0m[0m | time: 66.709s
[2K
| Adam | epoch: 016 | loss: 0.23908 - acc: 0.9212 -- iter: 192/204
[A[ATraining Step: 112  | total loss: [1m[32m0.23150[0m[0m | time: 76.641s
[2K
| Adam | epoch: 016 | loss: 0.23150 - acc: 0.9208 | val_loss: 0.51794 - val_acc: 0.8308 -- iter: 204/204
--
Training Step: 113  | total loss: [1m[32m0.21509[0m[0m | time: 12.974s
[2K
| Adam | epoch: 017 | loss: 0.21509 - acc: 0.9287 -- iter: 032/204
[A[ATraining Step: 114  | total loss: [1m[32m0.22409[0m[0m | time: 25.410s
[2K
| Adam | epoch: 017 | loss: 0.22409 - acc: 0.9264 -- iter: 064/204
[A[ATraining Step: 115  | total loss: [1m[32m0.20896[0m[0m | time: 37.594s
[2K
| Adam | epoch: 017 | loss: 0.20896 - acc: 0.9338 -- iter: 096/204
[A[ATraining Step: 116  | total loss: [1m[32m0.19428[0m[0m | time: 49.203s
[2K
| Adam | epoch: 017 | loss: 0.19428 - acc: 0.9373 -- iter: 128/204
[A[ATraining Step: 117  | total loss: [1m[32m0.20122[0m[0m | time: 58.631s
[2K
| Adam | epoch: 017 | loss: 0.20122 - acc: 0.9311 -- iter: 160/204
[A[ATraining Step: 118  | total loss: [1m[32m0.18951[0m[0m | time: 68.163s
[2K
| Adam | epoch: 017 | loss: 0.18951 - acc: 0.9348 -- iter: 192/204
[A[ATraining Step: 119  | total loss: [1m[32m0.18485[0m[0m | time: 76.442s
[2K
| Adam | epoch: 017 | loss: 0.18485 - acc: 0.9351 | val_loss: 1.15214 - val_acc: 0.6462 -- iter: 204/204
--
Training Step: 120  | total loss: [1m[32m0.25511[0m[0m | time: 3.889s
[2K
| Adam | epoch: 018 | loss: 0.25511 - acc: 0.9249 -- iter: 032/204
[A[ATraining Step: 121  | total loss: [1m[32m0.23258[0m[0m | time: 13.297s
[2K
| Adam | epoch: 018 | loss: 0.23258 - acc: 0.9324 -- iter: 064/204
[A[ATraining Step: 122  | total loss: [1m[32m0.23078[0m[0m | time: 22.761s
[2K
| Adam | epoch: 018 | loss: 0.23078 - acc: 0.9361 -- iter: 096/204
[A[ATraining Step: 123  | total loss: [1m[32m0.21856[0m[0m | time: 32.268s
[2K
| Adam | epoch: 018 | loss: 0.21856 - acc: 0.9393 -- iter: 128/204
[A[ATraining Step: 124  | total loss: [1m[32m0.20662[0m[0m | time: 41.535s
[2K
| Adam | epoch: 018 | loss: 0.20662 - acc: 0.9423 -- iter: 160/204
[A[ATraining Step: 125  | total loss: [1m[32m0.20851[0m[0m | time: 50.983s
[2K
| Adam | epoch: 018 | loss: 0.20851 - acc: 0.9418 -- iter: 192/204
[A[ATraining Step: 126  | total loss: [1m[32m0.19501[0m[0m | time: 64.205s
[2K
| Adam | epoch: 018 | loss: 0.19501 - acc: 0.9445 | val_loss: 1.08776 - val_acc: 0.6462 -- iter: 204/204
--
Training Step: 127  | total loss: [1m[32m0.18783[0m[0m | time: 3.433s
[2K
| Adam | epoch: 019 | loss: 0.18783 - acc: 0.9438 -- iter: 032/204
[A[ATraining Step: 128  | total loss: [1m[32m0.18226[0m[0m | time: 6.897s
[2K
| Adam | epoch: 019 | loss: 0.18226 - acc: 0.9411 -- iter: 064/204
[A[ATraining Step: 129  | total loss: [1m[32m0.16780[0m[0m | time: 14.744s
[2K
| Adam | epoch: 019 | loss: 0.16780 - acc: 0.9470 -- iter: 096/204
[A[ATraining Step: 130  | total loss: [1m[32m0.15302[0m[0m | time: 22.464s
[2K
| Adam | epoch: 019 | loss: 0.15302 - acc: 0.9523 -- iter: 128/204
[A[ATraining Step: 131  | total loss: [1m[32m0.16454[0m[0m | time: 30.272s
[2K
| Adam | epoch: 019 | loss: 0.16454 - acc: 0.9508 -- iter: 160/204
[A[ATraining Step: 132  | total loss: [1m[32m0.15158[0m[0m | time: 37.813s
[2K
| Adam | epoch: 019 | loss: 0.15158 - acc: 0.9557 -- iter: 192/204
[A[ATraining Step: 133  | total loss: [1m[32m0.14037[0m[0m | time: 48.689s
[2K
| Adam | epoch: 019 | loss: 0.14037 - acc: 0.9601 | val_loss: 0.76461 - val_acc: 0.8000 -- iter: 204/204
--
Training Step: 134  | total loss: [1m[32m0.13908[0m[0m | time: 7.760s
[2K
| Adam | epoch: 020 | loss: 0.13908 - acc: 0.9579 -- iter: 032/204
[A[ATraining Step: 135  | total loss: [1m[32m0.13331[0m[0m | time: 11.305s
[2K
| Adam | epoch: 020 | loss: 0.13331 - acc: 0.9621 -- iter: 064/204
[A[ATraining Step: 136  | total loss: [1m[32m0.21801[0m[0m | time: 14.688s
[2K
| Adam | epoch: 020 | loss: 0.21801 - acc: 0.9576 -- iter: 096/204
[A[ATraining Step: 137  | total loss: [1m[32m0.20562[0m[0m | time: 22.345s
[2K
| Adam | epoch: 020 | loss: 0.20562 - acc: 0.9535 -- iter: 128/204
[A[ATraining Step: 138  | total loss: [1m[32m0.18710[0m[0m | time: 30.085s
[2K
| Adam | epoch: 020 | loss: 0.18710 - acc: 0.9581 -- iter: 160/204
[A[ATraining Step: 139  | total loss: [1m[32m0.19136[0m[0m | time: 37.914s
[2K
| Adam | epoch: 020 | loss: 0.19136 - acc: 0.9561 -- iter: 192/204
[A[ATraining Step: 140  | total loss: [1m[32m0.19698[0m[0m | time: 48.718s
[2K
| Adam | epoch: 020 | loss: 0.19698 - acc: 0.9573 | val_loss: 3.90741 - val_acc: 0.4154 -- iter: 204/204
--
Training Step: 141  | total loss: [1m[32m0.18840[0m[0m | time: 7.655s
[2K
| Adam | epoch: 021 | loss: 0.18840 - acc: 0.9553 -- iter: 032/204
[A[ATraining Step: 142  | total loss: [1m[32m0.17897[0m[0m | time: 15.356s
[2K
| Adam | epoch: 021 | loss: 0.17897 - acc: 0.9567 -- iter: 064/204
[A[ATraining Step: 143  | total loss: [1m[32m0.18491[0m[0m | time: 18.834s
[2K
| Adam | epoch: 021 | loss: 0.18491 - acc: 0.9579 -- iter: 096/204
[A[ATraining Step: 144  | total loss: [1m[32m0.22173[0m[0m | time: 22.316s
[2K
| Adam | epoch: 021 | loss: 0.22173 - acc: 0.9538 -- iter: 128/204
[A[ATraining Step: 145  | total loss: [1m[32m0.20789[0m[0m | time: 30.037s
[2K
| Adam | epoch: 021 | loss: 0.20789 - acc: 0.9584 -- iter: 160/204
[A[ATraining Step: 146  | total loss: [1m[32m0.19349[0m[0m | time: 37.950s
[2K
| Adam | epoch: 021 | loss: 0.19349 - acc: 0.9594 -- iter: 192/204
[A[ATraining Step: 147  | total loss: [1m[32m0.19597[0m[0m | time: 48.580s
[2K
| Adam | epoch: 021 | loss: 0.19597 - acc: 0.9541 | val_loss: 0.67737 - val_acc: 0.7538 -- iter: 204/204
--
Training Step: 148  | total loss: [1m[32m0.18551[0m[0m | time: 7.795s
[2K
| Adam | epoch: 022 | loss: 0.18551 - acc: 0.9556 -- iter: 032/204
[A[ATraining Step: 149  | total loss: [1m[32m0.17390[0m[0m | time: 15.536s
[2K
| Adam | epoch: 022 | loss: 0.17390 - acc: 0.9569 -- iter: 064/204
[A[ATraining Step: 150  | total loss: [1m[32m0.16128[0m[0m | time: 23.415s
[2K
| Adam | epoch: 022 | loss: 0.16128 - acc: 0.9612 -- iter: 096/204
[A[ATraining Step: 151  | total loss: [1m[32m0.14904[0m[0m | time: 26.925s
[2K
| Adam | epoch: 022 | loss: 0.14904 - acc: 0.9651 -- iter: 128/204
[A[ATraining Step: 152  | total loss: [1m[32m0.20435[0m[0m | time: 30.334s
[2K
| Adam | epoch: 022 | loss: 0.20435 - acc: 0.9602 -- iter: 160/204
[A[ATraining Step: 153  | total loss: [1m[32m0.19022[0m[0m | time: 37.919s
[2K
| Adam | epoch: 022 | loss: 0.19022 - acc: 0.9642 -- iter: 192/204
[A[ATraining Step: 154  | total loss: [1m[32m0.18365[0m[0m | time: 48.662s
[2K
| Adam | epoch: 022 | loss: 0.18365 - acc: 0.9615 | val_loss: 0.47290 - val_acc: 0.8154 -- iter: 204/204
--
Training Step: 155  | total loss: [1m[32m0.17330[0m[0m | time: 7.622s
[2K
| Adam | epoch: 023 | loss: 0.17330 - acc: 0.9654 -- iter: 032/204
[A[ATraining Step: 156  | total loss: [1m[32m0.16322[0m[0m | time: 15.456s
[2K
| Adam | epoch: 023 | loss: 0.16322 - acc: 0.9657 -- iter: 064/204
[A[ATraining Step: 157  | total loss: [1m[32m0.15005[0m[0m | time: 23.287s
[2K
| Adam | epoch: 023 | loss: 0.15005 - acc: 0.9692 -- iter: 096/204
[A[ATraining Step: 158  | total loss: [1m[32m0.15580[0m[0m | time: 30.961s
[2K
| Adam | epoch: 023 | loss: 0.15580 - acc: 0.9660 -- iter: 128/204
[A[ATraining Step: 159  | total loss: [1m[32m0.16015[0m[0m | time: 34.442s
[2K
| Adam | epoch: 023 | loss: 0.16015 - acc: 0.9600 -- iter: 160/204
[A[ATraining Step: 160  | total loss: [1m[32m0.15657[0m[0m | time: 37.974s
[2K
| Adam | epoch: 023 | loss: 0.15657 - acc: 0.9557 -- iter: 192/204
[A[ATraining Step: 161  | total loss: [1m[32m0.14318[0m[0m | time: 48.671s
[2K
| Adam | epoch: 023 | loss: 0.14318 - acc: 0.9601 | val_loss: 1.33762 - val_acc: 0.5538 -- iter: 204/204
--
Training Step: 162  | total loss: [1m[32m0.13302[0m[0m | time: 7.869s
[2K
| Adam | epoch: 024 | loss: 0.13302 - acc: 0.9641 -- iter: 032/204
[A[ATraining Step: 163  | total loss: [1m[32m0.14345[0m[0m | time: 15.573s
[2K
| Adam | epoch: 024 | loss: 0.14345 - acc: 0.9583 -- iter: 064/204
[A[ATraining Step: 164  | total loss: [1m[32m0.13915[0m[0m | time: 23.377s
[2K
| Adam | epoch: 024 | loss: 0.13915 - acc: 0.9594 -- iter: 096/204
[A[ATraining Step: 165  | total loss: [1m[32m0.13835[0m[0m | time: 31.080s
[2K
| Adam | epoch: 024 | loss: 0.13835 - acc: 0.9540 -- iter: 128/204
[A[ATraining Step: 166  | total loss: [1m[32m0.13008[0m[0m | time: 38.893s
[2K
| Adam | epoch: 024 | loss: 0.13008 - acc: 0.9586 -- iter: 160/204
[A[ATraining Step: 167  | total loss: [1m[32m0.13824[0m[0m | time: 42.321s
[2K
| Adam | epoch: 024 | loss: 0.13824 - acc: 0.9597 -- iter: 192/204
[A[ATraining Step: 168  | total loss: [1m[32m0.17591[0m[0m | time: 48.614s
[2K
| Adam | epoch: 024 | loss: 0.17591 - acc: 0.9554 | val_loss: 0.78258 - val_acc: 0.6769 -- iter: 204/204
--
Training Step: 169  | total loss: [1m[32m0.15954[0m[0m | time: 7.892s
[2K
| Adam | epoch: 025 | loss: 0.15954 - acc: 0.9598 -- iter: 032/204
[A[ATraining Step: 170  | total loss: [1m[32m0.14741[0m[0m | time: 15.726s
[2K
| Adam | epoch: 025 | loss: 0.14741 - acc: 0.9638 -- iter: 064/204
[A[ATraining Step: 171  | total loss: [1m[32m0.15920[0m[0m | time: 23.427s
[2K
| Adam | epoch: 025 | loss: 0.15920 - acc: 0.9550 -- iter: 096/204
[A[ATraining Step: 172  | total loss: [1m[32m0.14852[0m[0m | time: 31.165s
[2K
| Adam | epoch: 025 | loss: 0.14852 - acc: 0.9563 -- iter: 128/204
[A[ATraining Step: 173  | total loss: [1m[32m0.16722[0m[0m | time: 39.166s
[2K
| Adam | epoch: 025 | loss: 0.16722 - acc: 0.9513 -- iter: 160/204
[A[ATraining Step: 174  | total loss: [1m[32m0.15468[0m[0m | time: 47.078s
[2K
| Adam | epoch: 025 | loss: 0.15468 - acc: 0.9531 -- iter: 192/204
[A[ATraining Step: 175  | total loss: [1m[32m0.17129[0m[0m | time: 53.435s
[2K
| Adam | epoch: 025 | loss: 0.17129 - acc: 0.9515 | val_loss: 0.53701 - val_acc: 0.7385 -- iter: 204/204
--
Training Step: 176  | total loss: [1m[32m0.22595[0m[0m | time: 3.514s
[2K
| Adam | epoch: 026 | loss: 0.22595 - acc: 0.9314 -- iter: 032/204
[A[ATraining Step: 177  | total loss: [1m[32m0.22272[0m[0m | time: 11.376s
[2K
| Adam | epoch: 026 | loss: 0.22272 - acc: 0.9299 -- iter: 064/204
[A[ATraining Step: 178  | total loss: [1m[32m0.20673[0m[0m | time: 19.099s
[2K
| Adam | epoch: 026 | loss: 0.20673 - acc: 0.9369 -- iter: 096/204
[A[ATraining Step: 179  | total loss: [1m[32m0.20774[0m[0m | time: 26.829s
[2K
| Adam | epoch: 026 | loss: 0.20774 - acc: 0.9370 -- iter: 128/204
[A[ATraining Step: 180  | total loss: [1m[32m0.19275[0m[0m | time: 34.560s
[2K
| Adam | epoch: 026 | loss: 0.19275 - acc: 0.9433 -- iter: 160/204
[A[ATraining Step: 181  | total loss: [1m[32m0.21755[0m[0m | time: 42.218s
[2K
| Adam | epoch: 026 | loss: 0.21755 - acc: 0.9302 -- iter: 192/204
[A[ATraining Step: 182  | total loss: [1m[32m0.22343[0m[0m | time: 52.883s
[2K
| Adam | epoch: 026 | loss: 0.22343 - acc: 0.9247 | val_loss: 1.51985 - val_acc: 0.6462 -- iter: 204/204
--
Training Step: 183  | total loss: [1m[32m0.22757[0m[0m | time: 3.523s
[2K
| Adam | epoch: 027 | loss: 0.22757 - acc: 0.9228 -- iter: 032/204
[A[ATraining Step: 184  | total loss: [1m[32m0.24695[0m[0m | time: 6.974s
[2K
| Adam | epoch: 027 | loss: 0.24695 - acc: 0.9222 -- iter: 064/204
[A[ATraining Step: 185  | total loss: [1m[32m0.22788[0m[0m | time: 14.593s
[2K
| Adam | epoch: 027 | loss: 0.22788 - acc: 0.9300 -- iter: 096/204
[A[ATraining Step: 186  | total loss: [1m[32m0.21847[0m[0m | time: 22.275s
[2K
| Adam | epoch: 027 | loss: 0.21847 - acc: 0.9307 -- iter: 128/204
[A[ATraining Step: 187  | total loss: [1m[32m0.22807[0m[0m | time: 29.982s
[2K
| Adam | epoch: 027 | loss: 0.22807 - acc: 0.9252 -- iter: 160/204
[A[ATraining Step: 188  | total loss: [1m[32m0.21146[0m[0m | time: 37.712s
[2K
| Adam | epoch: 027 | loss: 0.21146 - acc: 0.9327 -- iter: 192/204
[A[ATraining Step: 189  | total loss: [1m[32m0.20032[0m[0m | time: 48.480s
[2K
| Adam | epoch: 027 | loss: 0.20032 - acc: 0.9331 | val_loss: 1.16601 - val_acc: 0.6462 -- iter: 204/204
--
Training Step: 190  | total loss: [1m[32m0.20454[0m[0m | time: 7.771s
[2K
| Adam | epoch: 028 | loss: 0.20454 - acc: 0.9304 -- iter: 032/204
[A[ATraining Step: 191  | total loss: [1m[32m0.19488[0m[0m | time: 11.239s
[2K
| Adam | epoch: 028 | loss: 0.19488 - acc: 0.9312 -- iter: 064/204
[A[ATraining Step: 192  | total loss: [1m[32m0.24494[0m[0m | time: 14.649s
[2K
| Adam | epoch: 028 | loss: 0.24494 - acc: 0.9214 -- iter: 096/204
[A[ATraining Step: 193  | total loss: [1m[32m0.22497[0m[0m | time: 22.210s
[2K
| Adam | epoch: 028 | loss: 0.22497 - acc: 0.9292 -- iter: 128/204
[A[ATraining Step: 194  | total loss: [1m[32m0.21862[0m[0m | time: 29.859s
[2K
| Adam | epoch: 028 | loss: 0.21862 - acc: 0.9269 -- iter: 160/204
[A[ATraining Step: 195  | total loss: [1m[32m0.19810[0m[0m | time: 38.833s
[2K
| Adam | epoch: 028 | loss: 0.19810 - acc: 0.9342 -- iter: 192/204
[A[ATraining Step: 196  | total loss: [1m[32m0.18495[0m[0m | time: 53.243s
[2K
| Adam | epoch: 028 | loss: 0.18495 - acc: 0.9377 | val_loss: 4.70740 - val_acc: 0.3692 -- iter: 204/204
--
Training Step: 197  | total loss: [1m[32m0.18849[0m[0m | time: 11.048s
[2K
| Adam | epoch: 029 | loss: 0.18849 - acc: 0.9408 -- iter: 032/204
[A[ATraining Step: 198  | total loss: [1m[32m0.21929[0m[0m | time: 21.572s
[2K
| Adam | epoch: 029 | loss: 0.21929 - acc: 0.9311 -- iter: 064/204
[A[ATraining Step: 199  | total loss: [1m[32m0.25851[0m[0m | time: 26.385s
[2K
| Adam | epoch: 029 | loss: 0.25851 - acc: 0.9192 -- iter: 096/204
[A[ATraining Step: 200  | total loss: [1m[32m0.23799[0m[0m | time: 35.313s
[2K
| Adam | epoch: 029 | loss: 0.23799 - acc: 0.9273 | val_loss: 0.64083 - val_acc: 0.7692 -- iter: 128/204
--
Training Step: 201  | total loss: [1m[32m0.22373[0m[0m | time: 46.034s
[2K
| Adam | epoch: 029 | loss: 0.22373 - acc: 0.9346 -- iter: 160/204
[A[ATraining Step: 202  | total loss: [1m[32m0.21361[0m[0m | time: 56.218s
[2K
| Adam | epoch: 029 | loss: 0.21361 - acc: 0.9349 -- iter: 192/204
[A[ATraining Step: 203  | total loss: [1m[32m0.19662[0m[0m | time: 71.337s
[2K
| Adam | epoch: 029 | loss: 0.19662 - acc: 0.9383 | val_loss: 0.65559 - val_acc: 0.8308 -- iter: 204/204
--
Training Step: 204  | total loss: [1m[32m0.18600[0m[0m | time: 10.507s
[2K
| Adam | epoch: 030 | loss: 0.18600 - acc: 0.9413 -- iter: 032/204
[A[ATraining Step: 205  | total loss: [1m[32m0.16962[0m[0m | time: 21.591s
[2K
| Adam | epoch: 030 | loss: 0.16962 - acc: 0.9472 -- iter: 064/204
[A[ATraining Step: 206  | total loss: [1m[32m0.16189[0m[0m | time: 32.099s
[2K
| Adam | epoch: 030 | loss: 0.16189 - acc: 0.9493 -- iter: 096/204
[A[ATraining Step: 207  | total loss: [1m[32m0.14886[0m[0m | time: 37.312s
[2K
| Adam | epoch: 030 | loss: 0.14886 - acc: 0.9544 -- iter: 128/204
[A[ATraining Step: 208  | total loss: [1m[32m0.16133[0m[0m | time: 41.465s
[2K
| Adam | epoch: 030 | loss: 0.16133 - acc: 0.9506 -- iter: 160/204
[A[ATraining Step: 209  | total loss: [1m[32m0.14619[0m[0m | time: 52.490s
[2K
| Adam | epoch: 030 | loss: 0.14619 - acc: 0.9556 -- iter: 192/204
[A[ATraining Step: 210  | total loss: [1m[32m0.13369[0m[0m | time: 66.979s
[2K
| Adam | epoch: 030 | loss: 0.13369 - acc: 0.9600 | val_loss: 0.71972 - val_acc: 0.8154 -- iter: 204/204
--
Validation AUC:0.8333333333333334
Validation AUPRC:0.8509745959317909
Test AUC:0.7727272727272727
Test AUPRC:0.7229397069023309
BestTestF1Score	0.75	0.46	0.71	0.64	0.91	29	16	17	3	0.15
BestTestMCCScore	0.75	0.46	0.71	0.64	0.91	29	16	17	3	0.15
BestTestAccuracyScore	0.75	0.46	0.71	0.64	0.91	29	16	17	3	0.15
BestValidationF1Score	0.9	0.72	0.86	0.82	1.0	41	9	15	0	0.15
BestValidationMCC	0.9	0.72	0.86	0.82	1.0	41	9	15	0	0.15
BestValidationAccuracy	0.9	0.72	0.86	0.82	1.0	41	9	15	0	0.15
TestPredictions (Threshold:0.15)
CHEMBL2397312,TP,ACT,1.0	CHEMBL208652,TN,INACT,0.10000000149011612	CHEMBL3600684,TP,ACT,1.0	CHEMBL2181109,TN,INACT,0.09000000357627869	CHEMBL608154,TP,ACT,1.0	CHEMBL3109127,FP,INACT,1.0	CHEMBL2064572,FP,INACT,0.9900000095367432	CHEMBL3608927,TP,ACT,0.9200000166893005	CHEMBL2158433,TN,INACT,0.009999999776482582	CHEMBL1242291,FP,INACT,0.9300000071525574	CHEMBL1242029,TP,ACT,1.0	CHEMBL1241355,TN,INACT,0.009999999776482582	CHEMBL469565,FP,INACT,0.8700000047683716	CHEMBL1242751,TP,ACT,1.0	CHEMBL1242666,TP,ACT,1.0	CHEMBL1241301,FP,INACT,0.8999999761581421	CHEMBL1242292,FP,INACT,0.9399999976158142	CHEMBL460137,FP,INACT,0.8799999952316284	CHEMBL1242473,TN,INACT,0.029999999329447746	CHEMBL1242658,TN,INACT,0.07000000029802322	CHEMBL2071338,TP,ACT,0.9399999976158142	CHEMBL2418960,TP,ACT,0.5699999928474426	CHEMBL3600779,TP,ACT,0.9800000190734863	CHEMBL1241143,TN,INACT,0.12999999523162842	CHEMBL58782,TN,INACT,0.009999999776482582	CHEMBL1242385,FP,INACT,0.8199999928474426	CHEMBL3600769,FN,ACT,0.009999999776482582	CHEMBL3609514,TP,ACT,0.7200000286102295	CHEMBL2397314,TP,ACT,1.0	CHEMBL2165017,FN,ACT,0.0	CHEMBL3600687,TP,ACT,0.9900000095367432	CHEMBL3318728,FP,INACT,0.6200000047683716	CHEMBL1242378,TN,INACT,0.05000000074505806	CHEMBL1242116,FP,INACT,1.0	CHEMBL3600781,TP,ACT,0.9900000095367432	CHEMBL1645103,TN,INACT,0.0	CHEMBL379218,TP,ACT,0.7400000095367432	CHEMBL2158428,FP,INACT,0.23999999463558197	CHEMBL1241769,TN,INACT,0.03999999910593033	CHEMBL1230020,TP,ACT,1.0	CHEMBL1645107,TP,ACT,1.0	CHEMBL1287853,TP,ACT,0.36000001430511475	CHEMBL1242200,FP,INACT,0.949999988079071	CHEMBL2418954,TP,ACT,0.9800000190734863	CHEMBL2165193,TN,INACT,0.05000000074505806	CHEMBL2153266,TP,ACT,0.1599999964237213	CHEMBL1242662,FN,ACT,0.10999999940395355	CHEMBL1760160,FP,INACT,0.699999988079071	CHEMBL1241357,TN,INACT,0.10000000149011612	CHEMBL1242472,TP,ACT,1.0	CHEMBL557606,FP,INACT,0.9300000071525574	CHEMBL244552,FP,INACT,1.0	CHEMBL3609519,TP,ACT,0.9800000190734863	CHEMBL3589320,TN,INACT,0.0	CHEMBL1241947,TP,ACT,0.9200000166893005	CHEMBL1242844,TN,INACT,0.029999999329447746	CHEMBL3600780,TP,ACT,1.0	CHEMBL2322664,TN,INACT,0.0	CHEMBL1241772,FP,INACT,0.9800000190734863	CHEMBL384304,TP,ACT,0.9800000190734863	CHEMBL1240567,TN,INACT,0.07000000029802322	CHEMBL1242660,TP,ACT,1.0	CHEMBL3600782,TP,ACT,1.0	CHEMBL3600785,TP,ACT,0.6800000071525574	CHEMBL1241484,TP,ACT,1.0	

