ImageNetInceptionV2 CHEMBL259 adam 0.001 15 0 0 0.8 False True
Number of active compounds :	2391
Number of inactive compounds :	2391
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL259_adam_0.001_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL259_adam_0.001_15_0.8/
---------------------------------
Training samples: 2948
Validation samples: 922
--
Training Step: 1  | time: 39.055s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/2948
[A[ATraining Step: 2  | total loss: [1m[32m0.59084[0m[0m | time: 49.404s
[2K
| Adam | epoch: 001 | loss: 0.59084 - acc: 0.5625 -- iter: 0064/2948
[A[ATraining Step: 3  | total loss: [1m[32m0.80977[0m[0m | time: 59.530s
[2K
| Adam | epoch: 001 | loss: 0.80977 - acc: 0.6392 -- iter: 0096/2948
[A[ATraining Step: 4  | total loss: [1m[32m0.53344[0m[0m | time: 73.693s
[2K
| Adam | epoch: 001 | loss: 0.53344 - acc: 0.7457 -- iter: 0128/2948
[A[ATraining Step: 5  | total loss: [1m[32m0.77365[0m[0m | time: 88.695s
[2K
| Adam | epoch: 001 | loss: 0.77365 - acc: 0.6838 -- iter: 0160/2948
[A[ATraining Step: 6  | total loss: [1m[32m0.62548[0m[0m | time: 104.639s
[2K
| Adam | epoch: 001 | loss: 0.62548 - acc: 0.7264 -- iter: 0192/2948
[A[ATraining Step: 7  | total loss: [1m[32m0.51261[0m[0m | time: 121.725s
[2K
| Adam | epoch: 001 | loss: 0.51261 - acc: 0.7405 -- iter: 0224/2948
[A[ATraining Step: 8  | total loss: [1m[32m0.67492[0m[0m | time: 139.067s
[2K
| Adam | epoch: 001 | loss: 0.67492 - acc: 0.6931 -- iter: 0256/2948
[A[ATraining Step: 9  | total loss: [1m[32m0.44794[0m[0m | time: 155.884s
[2K
| Adam | epoch: 001 | loss: 0.44794 - acc: 0.8225 -- iter: 0288/2948
[A[ATraining Step: 10  | total loss: [1m[32m0.49894[0m[0m | time: 176.804s
[2K
| Adam | epoch: 001 | loss: 0.49894 - acc: 0.7706 -- iter: 0320/2948
[A[ATraining Step: 11  | total loss: [1m[32m0.53486[0m[0m | time: 198.952s
[2K
| Adam | epoch: 001 | loss: 0.53486 - acc: 0.7609 -- iter: 0352/2948
[A[ATraining Step: 12  | total loss: [1m[32m0.46986[0m[0m | time: 215.252s
[2K
| Adam | epoch: 001 | loss: 0.46986 - acc: 0.7700 -- iter: 0384/2948
[A[ATraining Step: 13  | total loss: [1m[32m0.63798[0m[0m | time: 236.577s
[2K
| Adam | epoch: 001 | loss: 0.63798 - acc: 0.6811 -- iter: 0416/2948
[A[ATraining Step: 14  | total loss: [1m[32m0.53103[0m[0m | time: 252.307s
[2K
| Adam | epoch: 001 | loss: 0.53103 - acc: 0.7348 -- iter: 0448/2948
[A[ATraining Step: 15  | total loss: [1m[32m0.45998[0m[0m | time: 268.027s
[2K
| Adam | epoch: 001 | loss: 0.45998 - acc: 0.7530 -- iter: 0480/2948
[A[ATraining Step: 16  | total loss: [1m[32m0.40440[0m[0m | time: 285.153s
[2K
| Adam | epoch: 001 | loss: 0.40440 - acc: 0.7870 -- iter: 0512/2948
[A[ATraining Step: 17  | total loss: [1m[32m0.41638[0m[0m | time: 301.983s
[2K
| Adam | epoch: 001 | loss: 0.41638 - acc: 0.7850 -- iter: 0544/2948
[A[ATraining Step: 18  | total loss: [1m[32m0.42532[0m[0m | time: 317.837s
[2K
| Adam | epoch: 001 | loss: 0.42532 - acc: 0.7837 -- iter: 0576/2948
[A[ATraining Step: 19  | total loss: [1m[32m0.38377[0m[0m | time: 333.387s
[2K
| Adam | epoch: 001 | loss: 0.38377 - acc: 0.8141 -- iter: 0608/2948
[A[ATraining Step: 20  | total loss: [1m[32m0.35937[0m[0m | time: 351.899s
[2K
| Adam | epoch: 001 | loss: 0.35937 - acc: 0.8337 -- iter: 0640/2948
[A[ATraining Step: 21  | total loss: [1m[32m0.35008[0m[0m | time: 373.357s
[2K
| Adam | epoch: 001 | loss: 0.35008 - acc: 0.8562 -- iter: 0672/2948
[A[ATraining Step: 22  | total loss: [1m[32m0.29495[0m[0m | time: 393.657s
[2K
| Adam | epoch: 001 | loss: 0.29495 - acc: 0.8900 -- iter: 0704/2948
[A[ATraining Step: 23  | total loss: [1m[32m0.29731[0m[0m | time: 411.863s
[2K
| Adam | epoch: 001 | loss: 0.29731 - acc: 0.9038 -- iter: 0736/2948
[A[ATraining Step: 24  | total loss: [1m[32m0.29997[0m[0m | time: 427.830s
[2K
| Adam | epoch: 001 | loss: 0.29997 - acc: 0.8869 -- iter: 0768/2948
[A[ATraining Step: 25  | total loss: [1m[32m0.31983[0m[0m | time: 445.094s
[2K
| Adam | epoch: 001 | loss: 0.31983 - acc: 0.8836 -- iter: 0800/2948
[A[ATraining Step: 26  | total loss: [1m[32m0.35005[0m[0m | time: 461.056s
[2K
| Adam | epoch: 001 | loss: 0.35005 - acc: 0.8814 -- iter: 0832/2948
[A[ATraining Step: 27  | total loss: [1m[32m0.43701[0m[0m | time: 480.128s
[2K
| Adam | epoch: 001 | loss: 0.43701 - acc: 0.8637 -- iter: 0864/2948
[A[ATraining Step: 28  | total loss: [1m[32m0.48334[0m[0m | time: 501.769s
[2K
| Adam | epoch: 001 | loss: 0.48334 - acc: 0.8509 -- iter: 0896/2948
[A[ATraining Step: 29  | total loss: [1m[32m0.52688[0m[0m | time: 528.583s
[2K
| Adam | epoch: 001 | loss: 0.52688 - acc: 0.8263 -- iter: 0928/2948
[A[ATraining Step: 30  | total loss: [1m[32m0.50608[0m[0m | time: 563.797s
[2K
| Adam | epoch: 001 | loss: 0.50608 - acc: 0.8453 -- iter: 0960/2948
[A[ATraining Step: 31  | total loss: [1m[32m0.49229[0m[0m | time: 608.461s
[2K
| Adam | epoch: 001 | loss: 0.49229 - acc: 0.8449 -- iter: 0992/2948
[A[ATraining Step: 32  | total loss: [1m[32m0.47358[0m[0m | time: 649.873s
[2K
| Adam | epoch: 001 | loss: 0.47358 - acc: 0.8446 -- iter: 1024/2948
[A[ATraining Step: 33  | total loss: [1m[32m0.45869[0m[0m | time: 682.226s
[2K
| Adam | epoch: 001 | loss: 0.45869 - acc: 0.8307 -- iter: 1056/2948
[A[ATraining Step: 34  | total loss: [1m[32m0.42766[0m[0m | time: 711.181s
[2K
| Adam | epoch: 001 | loss: 0.42766 - acc: 0.8335 -- iter: 1088/2948
[A[ATraining Step: 35  | total loss: [1m[32m0.43899[0m[0m | time: 728.786s
[2K
| Adam | epoch: 001 | loss: 0.43899 - acc: 0.8422 -- iter: 1120/2948
[A[ATraining Step: 36  | total loss: [1m[32m0.42838[0m[0m | time: 745.231s
[2K
| Adam | epoch: 001 | loss: 0.42838 - acc: 0.8361 -- iter: 1152/2948
[A[ATraining Step: 37  | total loss: [1m[32m0.39814[0m[0m | time: 767.950s
[2K
| Adam | epoch: 001 | loss: 0.39814 - acc: 0.8439 -- iter: 1184/2948
[A[ATraining Step: 38  | total loss: [1m[32m0.38769[0m[0m | time: 784.148s
[2K
| Adam | epoch: 001 | loss: 0.38769 - acc: 0.8500 -- iter: 1216/2948
[A[ATraining Step: 39  | total loss: [1m[32m0.41245[0m[0m | time: 800.188s
[2K
| Adam | epoch: 001 | loss: 0.41245 - acc: 0.8488 -- iter: 1248/2948
[A[ATraining Step: 40  | total loss: [1m[32m0.42792[0m[0m | time: 816.005s
[2K
| Adam | epoch: 001 | loss: 0.42792 - acc: 0.8420 -- iter: 1280/2948
[A[ATraining Step: 41  | total loss: [1m[32m0.45898[0m[0m | time: 831.713s
[2K
| Adam | epoch: 001 | loss: 0.45898 - acc: 0.8194 -- iter: 1312/2948
[A[ATraining Step: 42  | total loss: [1m[32m0.42235[0m[0m | time: 847.685s
[2K
| Adam | epoch: 001 | loss: 0.42235 - acc: 0.8294 -- iter: 1344/2948
[A[ATraining Step: 43  | total loss: [1m[32m0.44907[0m[0m | time: 863.485s
[2K
| Adam | epoch: 001 | loss: 0.44907 - acc: 0.7988 -- iter: 1376/2948
[A[ATraining Step: 44  | total loss: [1m[32m0.43459[0m[0m | time: 879.756s
[2K
| Adam | epoch: 001 | loss: 0.43459 - acc: 0.8066 -- iter: 1408/2948
[A[ATraining Step: 45  | total loss: [1m[32m0.41355[0m[0m | time: 895.774s
[2K
| Adam | epoch: 001 | loss: 0.41355 - acc: 0.8182 -- iter: 1440/2948
[A[ATraining Step: 46  | total loss: [1m[32m0.38306[0m[0m | time: 912.093s
[2K
| Adam | epoch: 001 | loss: 0.38306 - acc: 0.8329 -- iter: 1472/2948
[A[ATraining Step: 47  | total loss: [1m[32m0.42065[0m[0m | time: 928.949s
[2K
| Adam | epoch: 001 | loss: 0.42065 - acc: 0.8244 -- iter: 1504/2948
[A[ATraining Step: 48  | total loss: [1m[32m0.46701[0m[0m | time: 945.309s
[2K
| Adam | epoch: 001 | loss: 0.46701 - acc: 0.8024 -- iter: 1536/2948
[A[ATraining Step: 49  | total loss: [1m[32m0.47802[0m[0m | time: 960.695s
[2K
| Adam | epoch: 001 | loss: 0.47802 - acc: 0.7892 -- iter: 1568/2948
[A[ATraining Step: 50  | total loss: [1m[32m0.48472[0m[0m | time: 977.271s
[2K
| Adam | epoch: 001 | loss: 0.48472 - acc: 0.7880 -- iter: 1600/2948
[A[ATraining Step: 51  | total loss: [1m[32m0.46364[0m[0m | time: 993.966s
[2K
| Adam | epoch: 001 | loss: 0.46364 - acc: 0.8013 -- iter: 1632/2948
[A[ATraining Step: 52  | total loss: [1m[32m0.45202[0m[0m | time: 1009.267s
[2K
| Adam | epoch: 001 | loss: 0.45202 - acc: 0.8076 -- iter: 1664/2948
[A[ATraining Step: 53  | total loss: [1m[32m0.47870[0m[0m | time: 1025.135s
[2K
| Adam | epoch: 001 | loss: 0.47870 - acc: 0.8037 -- iter: 1696/2948
[A[ATraining Step: 54  | total loss: [1m[32m0.49430[0m[0m | time: 1041.501s
[2K
| Adam | epoch: 001 | loss: 0.49430 - acc: 0.7778 -- iter: 1728/2948
[A[ATraining Step: 55  | total loss: [1m[32m0.51420[0m[0m | time: 1057.289s
[2K
| Adam | epoch: 001 | loss: 0.51420 - acc: 0.7783 -- iter: 1760/2948
[A[ATraining Step: 56  | total loss: [1m[32m0.49141[0m[0m | time: 1073.117s
[2K
| Adam | epoch: 001 | loss: 0.49141 - acc: 0.7831 -- iter: 1792/2948
[A[ATraining Step: 57  | total loss: [1m[32m0.45264[0m[0m | time: 1089.468s
[2K
| Adam | epoch: 001 | loss: 0.45264 - acc: 0.8045 -- iter: 1824/2948
[A[ATraining Step: 58  | total loss: [1m[32m0.44547[0m[0m | time: 1105.711s
[2K
| Adam | epoch: 001 | loss: 0.44547 - acc: 0.8141 -- iter: 1856/2948
[A[ATraining Step: 59  | total loss: [1m[32m0.41273[0m[0m | time: 1121.914s
[2K
| Adam | epoch: 001 | loss: 0.41273 - acc: 0.8265 -- iter: 1888/2948
[A[ATraining Step: 60  | total loss: [1m[32m0.43886[0m[0m | time: 1137.713s
[2K
| Adam | epoch: 001 | loss: 0.43886 - acc: 0.8288 -- iter: 1920/2948
[A[ATraining Step: 61  | total loss: [1m[32m0.44782[0m[0m | time: 1154.220s
[2K
| Adam | epoch: 001 | loss: 0.44782 - acc: 0.8266 -- iter: 1952/2948
[A[ATraining Step: 62  | total loss: [1m[32m0.57197[0m[0m | time: 1169.887s
[2K
| Adam | epoch: 001 | loss: 0.57197 - acc: 0.7967 -- iter: 1984/2948
[A[ATraining Step: 63  | total loss: [1m[32m0.52759[0m[0m | time: 1185.766s
[2K
| Adam | epoch: 001 | loss: 0.52759 - acc: 0.8106 -- iter: 2016/2948
[A[ATraining Step: 64  | total loss: [1m[32m0.52290[0m[0m | time: 1202.180s
[2K
| Adam | epoch: 001 | loss: 0.52290 - acc: 0.8108 -- iter: 2048/2948
[A[ATraining Step: 65  | total loss: [1m[32m0.51335[0m[0m | time: 1218.907s
[2K
| Adam | epoch: 001 | loss: 0.51335 - acc: 0.8033 -- iter: 2080/2948
[A[ATraining Step: 66  | total loss: [1m[32m0.48653[0m[0m | time: 1235.437s
[2K
| Adam | epoch: 001 | loss: 0.48653 - acc: 0.8158 -- iter: 2112/2948
[A[ATraining Step: 67  | total loss: [1m[32m0.49418[0m[0m | time: 1251.678s
[2K
| Adam | epoch: 001 | loss: 0.49418 - acc: 0.8117 -- iter: 2144/2948
[A[ATraining Step: 68  | total loss: [1m[32m0.49123[0m[0m | time: 1268.377s
[2K
| Adam | epoch: 001 | loss: 0.49123 - acc: 0.8118 -- iter: 2176/2948
[A[ATraining Step: 69  | total loss: [1m[32m0.48065[0m[0m | time: 1284.679s
[2K
| Adam | epoch: 001 | loss: 0.48065 - acc: 0.8192 -- iter: 2208/2948
[A[ATraining Step: 70  | total loss: [1m[32m0.46908[0m[0m | time: 1300.674s
[2K
| Adam | epoch: 001 | loss: 0.46908 - acc: 0.8256 -- iter: 2240/2948
[A[ATraining Step: 71  | total loss: [1m[32m0.45953[0m[0m | time: 1317.473s
[2K
| Adam | epoch: 001 | loss: 0.45953 - acc: 0.8277 -- iter: 2272/2948
[A[ATraining Step: 72  | total loss: [1m[32m0.45928[0m[0m | time: 1333.831s
[2K
| Adam | epoch: 001 | loss: 0.45928 - acc: 0.8295 -- iter: 2304/2948
[A[ATraining Step: 73  | total loss: [1m[32m0.44277[0m[0m | time: 1349.803s
[2K
| Adam | epoch: 001 | loss: 0.44277 - acc: 0.8380 -- iter: 2336/2948
[A[ATraining Step: 74  | total loss: [1m[32m0.43603[0m[0m | time: 1365.927s
[2K
| Adam | epoch: 001 | loss: 0.43603 - acc: 0.8421 -- iter: 2368/2948
[A[ATraining Step: 75  | total loss: [1m[32m0.43566[0m[0m | time: 1382.381s
[2K
| Adam | epoch: 001 | loss: 0.43566 - acc: 0.8355 -- iter: 2400/2948
[A[ATraining Step: 76  | total loss: [1m[32m0.41401[0m[0m | time: 1398.447s
[2K
| Adam | epoch: 001 | loss: 0.41401 - acc: 0.8431 -- iter: 2432/2948
[A[ATraining Step: 77  | total loss: [1m[32m0.42977[0m[0m | time: 1414.956s
[2K
| Adam | epoch: 001 | loss: 0.42977 - acc: 0.8332 -- iter: 2464/2948
[A[ATraining Step: 78  | total loss: [1m[32m0.40854[0m[0m | time: 1431.276s
[2K
| Adam | epoch: 001 | loss: 0.40854 - acc: 0.8409 -- iter: 2496/2948
[A[ATraining Step: 79  | total loss: [1m[32m0.42375[0m[0m | time: 1447.411s
[2K
| Adam | epoch: 001 | loss: 0.42375 - acc: 0.8347 -- iter: 2528/2948
[A[ATraining Step: 80  | total loss: [1m[32m0.42202[0m[0m | time: 1463.310s
[2K
| Adam | epoch: 001 | loss: 0.42202 - acc: 0.8324 -- iter: 2560/2948
[A[ATraining Step: 81  | total loss: [1m[32m0.41362[0m[0m | time: 1478.996s
[2K
| Adam | epoch: 001 | loss: 0.41362 - acc: 0.8304 -- iter: 2592/2948
[A[ATraining Step: 82  | total loss: [1m[32m0.40440[0m[0m | time: 1495.306s
[2K
| Adam | epoch: 001 | loss: 0.40440 - acc: 0.8380 -- iter: 2624/2948
[A[ATraining Step: 83  | total loss: [1m[32m0.41255[0m[0m | time: 1508.433s
[2K
| Adam | epoch: 001 | loss: 0.41255 - acc: 0.8386 -- iter: 2656/2948
[A[ATraining Step: 84  | total loss: [1m[32m0.41941[0m[0m | time: 1521.312s
[2K
| Adam | epoch: 001 | loss: 0.41941 - acc: 0.8360 -- iter: 2688/2948
[A[ATraining Step: 85  | total loss: [1m[32m0.40970[0m[0m | time: 1533.564s
[2K
| Adam | epoch: 001 | loss: 0.40970 - acc: 0.8367 -- iter: 2720/2948
[A[ATraining Step: 86  | total loss: [1m[32m0.39999[0m[0m | time: 1546.342s
[2K
| Adam | epoch: 001 | loss: 0.39999 - acc: 0.8374 -- iter: 2752/2948
[A[ATraining Step: 87  | total loss: [1m[32m0.39365[0m[0m | time: 1558.914s
[2K
| Adam | epoch: 001 | loss: 0.39365 - acc: 0.8381 -- iter: 2784/2948
[A[ATraining Step: 88  | total loss: [1m[32m0.40590[0m[0m | time: 1572.003s
[2K
| Adam | epoch: 001 | loss: 0.40590 - acc: 0.8449 -- iter: 2816/2948
[A[ATraining Step: 89  | total loss: [1m[32m0.40132[0m[0m | time: 1584.526s
[2K
| Adam | epoch: 001 | loss: 0.40132 - acc: 0.8479 -- iter: 2848/2948
[A[ATraining Step: 90  | total loss: [1m[32m0.40055[0m[0m | time: 1597.252s
[2K
| Adam | epoch: 001 | loss: 0.40055 - acc: 0.8444 -- iter: 2880/2948
[A[ATraining Step: 91  | total loss: [1m[32m0.40098[0m[0m | time: 1610.024s
[2K
| Adam | epoch: 001 | loss: 0.40098 - acc: 0.8380 -- iter: 2912/2948
[A[ATraining Step: 92  | total loss: [1m[32m0.38945[0m[0m | time: 1622.485s
[2K
| Adam | epoch: 001 | loss: 0.38945 - acc: 0.8449 -- iter: 2944/2948
[A[ATraining Step: 93  | total loss: [1m[32m0.39472[0m[0m | time: 1698.173s
[2K
| Adam | epoch: 001 | loss: 0.39472 - acc: 0.8448 | val_loss: 0.98885 - val_acc: 0.5987 -- iter: 2948/2948
--
Training Step: 94  | total loss: [1m[32m0.43930[0m[0m | time: 1.830s
[2K
| Adam | epoch: 002 | loss: 0.43930 - acc: 0.8353 -- iter: 0032/2948
[A[ATraining Step: 95  | total loss: [1m[32m0.41844[0m[0m | time: 9.884s
[2K
| Adam | epoch: 002 | loss: 0.41844 - acc: 0.8268 -- iter: 0064/2948
[A[ATraining Step: 96  | total loss: [1m[32m0.40379[0m[0m | time: 17.903s
[2K
| Adam | epoch: 002 | loss: 0.40379 - acc: 0.8378 -- iter: 0096/2948
[A[ATraining Step: 97  | total loss: [1m[32m0.41131[0m[0m | time: 25.718s
[2K
| Adam | epoch: 002 | loss: 0.41131 - acc: 0.8415 -- iter: 0128/2948
[A[ATraining Step: 98  | total loss: [1m[32m0.40518[0m[0m | time: 34.150s
[2K
| Adam | epoch: 002 | loss: 0.40518 - acc: 0.8418 -- iter: 0160/2948
[A[ATraining Step: 99  | total loss: [1m[32m0.39066[0m[0m | time: 47.777s
[2K
| Adam | epoch: 002 | loss: 0.39066 - acc: 0.8451 -- iter: 0192/2948
[A[ATraining Step: 100  | total loss: [1m[32m0.38061[0m[0m | time: 59.826s
[2K
| Adam | epoch: 002 | loss: 0.38061 - acc: 0.8512 -- iter: 0224/2948
[A[ATraining Step: 101  | total loss: [1m[32m0.36863[0m[0m | time: 72.607s
[2K
| Adam | epoch: 002 | loss: 0.36863 - acc: 0.8536 -- iter: 0256/2948
[A[ATraining Step: 102  | total loss: [1m[32m0.36276[0m[0m | time: 85.694s
[2K
| Adam | epoch: 002 | loss: 0.36276 - acc: 0.8557 -- iter: 0288/2948
[A[ATraining Step: 103  | total loss: [1m[32m0.38222[0m[0m | time: 98.096s
[2K
| Adam | epoch: 002 | loss: 0.38222 - acc: 0.8545 -- iter: 0320/2948
[A[ATraining Step: 104  | total loss: [1m[32m0.38094[0m[0m | time: 110.730s
[2K
| Adam | epoch: 002 | loss: 0.38094 - acc: 0.8566 -- iter: 0352/2948
[A[ATraining Step: 105  | total loss: [1m[32m0.38690[0m[0m | time: 123.317s
[2K
| Adam | epoch: 002 | loss: 0.38690 - acc: 0.8584 -- iter: 0384/2948
[A[ATraining Step: 106  | total loss: [1m[32m0.37409[0m[0m | time: 136.017s
[2K
| Adam | epoch: 002 | loss: 0.37409 - acc: 0.8601 -- iter: 0416/2948
[A[ATraining Step: 107  | total loss: [1m[32m0.34949[0m[0m | time: 149.040s
[2K
| Adam | epoch: 002 | loss: 0.34949 - acc: 0.8678 -- iter: 0448/2948
[A[ATraining Step: 108  | total loss: [1m[32m0.35865[0m[0m | time: 161.782s
[2K
| Adam | epoch: 002 | loss: 0.35865 - acc: 0.8592 -- iter: 0480/2948
[A[ATraining Step: 109  | total loss: [1m[32m0.36379[0m[0m | time: 174.551s
[2K
| Adam | epoch: 002 | loss: 0.36379 - acc: 0.8576 -- iter: 0512/2948
[A[ATraining Step: 110  | total loss: [1m[32m0.35311[0m[0m | time: 187.461s
[2K
| Adam | epoch: 002 | loss: 0.35311 - acc: 0.8625 -- iter: 0544/2948
[A[ATraining Step: 111  | total loss: [1m[32m0.36301[0m[0m | time: 200.456s
[2K
| Adam | epoch: 002 | loss: 0.36301 - acc: 0.8575 -- iter: 0576/2948
[A[ATraining Step: 112  | total loss: [1m[32m0.36040[0m[0m | time: 213.142s
[2K
| Adam | epoch: 002 | loss: 0.36040 - acc: 0.8592 -- iter: 0608/2948
[A[ATraining Step: 113  | total loss: [1m[32m0.36413[0m[0m | time: 225.947s
[2K
| Adam | epoch: 002 | loss: 0.36413 - acc: 0.8577 -- iter: 0640/2948
[A[ATraining Step: 114  | total loss: [1m[32m0.37904[0m[0m | time: 238.818s
[2K
| Adam | epoch: 002 | loss: 0.37904 - acc: 0.8532 -- iter: 0672/2948
[A[ATraining Step: 115  | total loss: [1m[32m0.38561[0m[0m | time: 251.793s
[2K
| Adam | epoch: 002 | loss: 0.38561 - acc: 0.8554 -- iter: 0704/2948
[A[ATraining Step: 116  | total loss: [1m[32m0.38982[0m[0m | time: 264.625s
[2K
| Adam | epoch: 002 | loss: 0.38982 - acc: 0.8511 -- iter: 0736/2948
[A[ATraining Step: 117  | total loss: [1m[32m0.37922[0m[0m | time: 277.507s
[2K
| Adam | epoch: 002 | loss: 0.37922 - acc: 0.8535 -- iter: 0768/2948
[A[ATraining Step: 118  | total loss: [1m[32m0.37387[0m[0m | time: 290.430s
[2K
| Adam | epoch: 002 | loss: 0.37387 - acc: 0.8556 -- iter: 0800/2948
[A[ATraining Step: 119  | total loss: [1m[32m0.35867[0m[0m | time: 303.164s
[2K
| Adam | epoch: 002 | loss: 0.35867 - acc: 0.8669 -- iter: 0832/2948
[A[ATraining Step: 120  | total loss: [1m[32m0.38013[0m[0m | time: 316.344s
[2K
| Adam | epoch: 002 | loss: 0.38013 - acc: 0.8584 -- iter: 0864/2948
[A[ATraining Step: 121  | total loss: [1m[32m0.37543[0m[0m | time: 328.997s
[2K
| Adam | epoch: 002 | loss: 0.37543 - acc: 0.8569 -- iter: 0896/2948
[A[ATraining Step: 122  | total loss: [1m[32m0.36614[0m[0m | time: 341.865s
[2K
| Adam | epoch: 002 | loss: 0.36614 - acc: 0.8556 -- iter: 0928/2948
[A[ATraining Step: 123  | total loss: [1m[32m0.36322[0m[0m | time: 354.900s
[2K
| Adam | epoch: 002 | loss: 0.36322 - acc: 0.8575 -- iter: 0960/2948
[A[ATraining Step: 124  | total loss: [1m[32m0.36588[0m[0m | time: 367.726s
[2K
| Adam | epoch: 002 | loss: 0.36588 - acc: 0.8499 -- iter: 0992/2948
[A[ATraining Step: 125  | total loss: [1m[32m0.36811[0m[0m | time: 381.091s
[2K
| Adam | epoch: 002 | loss: 0.36811 - acc: 0.8524 -- iter: 1024/2948
[A[ATraining Step: 126  | total loss: [1m[32m0.34788[0m[0m | time: 393.740s
[2K
| Adam | epoch: 002 | loss: 0.34788 - acc: 0.8609 -- iter: 1056/2948
[A[ATraining Step: 127  | total loss: [1m[32m0.33432[0m[0m | time: 406.613s
[2K
| Adam | epoch: 002 | loss: 0.33432 - acc: 0.8686 -- iter: 1088/2948
[A[ATraining Step: 128  | total loss: [1m[32m0.34307[0m[0m | time: 419.664s
[2K
| Adam | epoch: 002 | loss: 0.34307 - acc: 0.8630 -- iter: 1120/2948
[A[ATraining Step: 129  | total loss: [1m[32m0.33977[0m[0m | time: 432.588s
[2K
| Adam | epoch: 002 | loss: 0.33977 - acc: 0.8642 -- iter: 1152/2948
[A[ATraining Step: 130  | total loss: [1m[32m0.33908[0m[0m | time: 445.263s
[2K
| Adam | epoch: 002 | loss: 0.33908 - acc: 0.8684 -- iter: 1184/2948
[A[ATraining Step: 131  | total loss: [1m[32m0.35246[0m[0m | time: 458.278s
[2K
| Adam | epoch: 002 | loss: 0.35246 - acc: 0.8659 -- iter: 1216/2948
[A[ATraining Step: 132  | total loss: [1m[32m0.36399[0m[0m | time: 471.138s
[2K
| Adam | epoch: 002 | loss: 0.36399 - acc: 0.8606 -- iter: 1248/2948
[A[ATraining Step: 133  | total loss: [1m[32m0.34810[0m[0m | time: 484.085s
[2K
| Adam | epoch: 002 | loss: 0.34810 - acc: 0.8651 -- iter: 1280/2948
[A[ATraining Step: 134  | total loss: [1m[32m0.34549[0m[0m | time: 497.054s
[2K
| Adam | epoch: 002 | loss: 0.34549 - acc: 0.8693 -- iter: 1312/2948
[A[ATraining Step: 135  | total loss: [1m[32m0.36181[0m[0m | time: 510.311s
[2K
| Adam | epoch: 002 | loss: 0.36181 - acc: 0.8667 -- iter: 1344/2948
[A[ATraining Step: 136  | total loss: [1m[32m0.36908[0m[0m | time: 523.283s
[2K
| Adam | epoch: 002 | loss: 0.36908 - acc: 0.8707 -- iter: 1376/2948
[A[ATraining Step: 137  | total loss: [1m[32m0.34907[0m[0m | time: 536.363s
[2K
| Adam | epoch: 002 | loss: 0.34907 - acc: 0.8773 -- iter: 1408/2948
[A[ATraining Step: 138  | total loss: [1m[32m0.32926[0m[0m | time: 549.107s
[2K
| Adam | epoch: 002 | loss: 0.32926 - acc: 0.8865 -- iter: 1440/2948
[A[ATraining Step: 139  | total loss: [1m[32m0.33071[0m[0m | time: 562.094s
[2K
| Adam | epoch: 002 | loss: 0.33071 - acc: 0.8822 -- iter: 1472/2948
[A[ATraining Step: 140  | total loss: [1m[32m0.31223[0m[0m | time: 574.971s
[2K
| Adam | epoch: 002 | loss: 0.31223 - acc: 0.8909 -- iter: 1504/2948
[A[ATraining Step: 141  | total loss: [1m[32m0.29295[0m[0m | time: 587.982s
[2K
| Adam | epoch: 002 | loss: 0.29295 - acc: 0.9018 -- iter: 1536/2948
[A[ATraining Step: 142  | total loss: [1m[32m0.27749[0m[0m | time: 601.091s
[2K
| Adam | epoch: 002 | loss: 0.27749 - acc: 0.9085 -- iter: 1568/2948
[A[ATraining Step: 143  | total loss: [1m[32m0.26926[0m[0m | time: 614.319s
[2K
| Adam | epoch: 002 | loss: 0.26926 - acc: 0.9114 -- iter: 1600/2948
[A[ATraining Step: 144  | total loss: [1m[32m0.27639[0m[0m | time: 627.549s
[2K
| Adam | epoch: 002 | loss: 0.27639 - acc: 0.9109 -- iter: 1632/2948
[A[ATraining Step: 145  | total loss: [1m[32m0.26826[0m[0m | time: 640.948s
[2K
| Adam | epoch: 002 | loss: 0.26826 - acc: 0.9167 -- iter: 1664/2948
[A[ATraining Step: 146  | total loss: [1m[32m0.27401[0m[0m | time: 654.245s
[2K
| Adam | epoch: 002 | loss: 0.27401 - acc: 0.9125 -- iter: 1696/2948
[A[ATraining Step: 147  | total loss: [1m[32m0.28374[0m[0m | time: 667.489s
[2K
| Adam | epoch: 002 | loss: 0.28374 - acc: 0.9119 -- iter: 1728/2948
[A[ATraining Step: 148  | total loss: [1m[32m0.28132[0m[0m | time: 680.112s
[2K
| Adam | epoch: 002 | loss: 0.28132 - acc: 0.9113 -- iter: 1760/2948
[A[ATraining Step: 149  | total loss: [1m[32m0.28780[0m[0m | time: 693.791s
[2K
| Adam | epoch: 002 | loss: 0.28780 - acc: 0.9014 -- iter: 1792/2948
[A[ATraining Step: 150  | total loss: [1m[32m0.29378[0m[0m | time: 706.887s
[2K
| Adam | epoch: 002 | loss: 0.29378 - acc: 0.8957 -- iter: 1824/2948
[A[ATraining Step: 151  | total loss: [1m[32m0.30092[0m[0m | time: 720.027s
[2K
| Adam | epoch: 002 | loss: 0.30092 - acc: 0.8905 -- iter: 1856/2948
[A[ATraining Step: 152  | total loss: [1m[32m0.30629[0m[0m | time: 733.191s
[2K
| Adam | epoch: 002 | loss: 0.30629 - acc: 0.8858 -- iter: 1888/2948
[A[ATraining Step: 153  | total loss: [1m[32m0.30236[0m[0m | time: 746.279s
[2K
| Adam | epoch: 002 | loss: 0.30236 - acc: 0.8878 -- iter: 1920/2948
[A[ATraining Step: 154  | total loss: [1m[32m0.31738[0m[0m | time: 759.419s
[2K
| Adam | epoch: 002 | loss: 0.31738 - acc: 0.8897 -- iter: 1952/2948
[A[ATraining Step: 155  | total loss: [1m[32m0.35702[0m[0m | time: 772.428s
[2K
| Adam | epoch: 002 | loss: 0.35702 - acc: 0.8726 -- iter: 1984/2948
[A[ATraining Step: 156  | total loss: [1m[32m0.36389[0m[0m | time: 785.303s
[2K
| Adam | epoch: 002 | loss: 0.36389 - acc: 0.8635 -- iter: 2016/2948
[A[ATraining Step: 157  | total loss: [1m[32m0.35141[0m[0m | time: 798.346s
[2K
| Adam | epoch: 002 | loss: 0.35141 - acc: 0.8677 -- iter: 2048/2948
[A[ATraining Step: 158  | total loss: [1m[32m0.34928[0m[0m | time: 811.198s
[2K
| Adam | epoch: 002 | loss: 0.34928 - acc: 0.8622 -- iter: 2080/2948
[A[ATraining Step: 159  | total loss: [1m[32m0.33049[0m[0m | time: 824.480s
[2K
| Adam | epoch: 002 | loss: 0.33049 - acc: 0.8666 -- iter: 2112/2948
[A[ATraining Step: 160  | total loss: [1m[32m0.32361[0m[0m | time: 837.908s
[2K
| Adam | epoch: 002 | loss: 0.32361 - acc: 0.8706 -- iter: 2144/2948
[A[ATraining Step: 161  | total loss: [1m[32m0.30796[0m[0m | time: 851.009s
[2K
| Adam | epoch: 002 | loss: 0.30796 - acc: 0.8773 -- iter: 2176/2948
[A[ATraining Step: 162  | total loss: [1m[32m0.29217[0m[0m | time: 864.083s
[2K
| Adam | epoch: 002 | loss: 0.29217 - acc: 0.8864 -- iter: 2208/2948
[A[ATraining Step: 163  | total loss: [1m[32m0.29192[0m[0m | time: 877.308s
[2K
| Adam | epoch: 002 | loss: 0.29192 - acc: 0.8853 -- iter: 2240/2948
[A[ATraining Step: 164  | total loss: [1m[32m0.29668[0m[0m | time: 890.573s
[2K
| Adam | epoch: 002 | loss: 0.29668 - acc: 0.8811 -- iter: 2272/2948
[A[ATraining Step: 165  | total loss: [1m[32m0.28654[0m[0m | time: 903.658s
[2K
| Adam | epoch: 002 | loss: 0.28654 - acc: 0.8836 -- iter: 2304/2948
[A[ATraining Step: 166  | total loss: [1m[32m0.29375[0m[0m | time: 916.710s
[2K
| Adam | epoch: 002 | loss: 0.29375 - acc: 0.8890 -- iter: 2336/2948
[A[ATraining Step: 167  | total loss: [1m[32m0.31103[0m[0m | time: 929.931s
[2K
| Adam | epoch: 002 | loss: 0.31103 - acc: 0.8814 -- iter: 2368/2948
[A[ATraining Step: 168  | total loss: [1m[32m0.29789[0m[0m | time: 943.130s
[2K
| Adam | epoch: 002 | loss: 0.29789 - acc: 0.8870 -- iter: 2400/2948
[A[ATraining Step: 169  | total loss: [1m[32m0.31527[0m[0m | time: 956.452s
[2K
| Adam | epoch: 002 | loss: 0.31527 - acc: 0.8764 -- iter: 2432/2948
[A[ATraining Step: 170  | total loss: [1m[32m0.31592[0m[0m | time: 969.528s
[2K
| Adam | epoch: 002 | loss: 0.31592 - acc: 0.8700 -- iter: 2464/2948
[A[ATraining Step: 171  | total loss: [1m[32m0.33262[0m[0m | time: 982.846s
[2K
| Adam | epoch: 002 | loss: 0.33262 - acc: 0.8674 -- iter: 2496/2948
[A[ATraining Step: 172  | total loss: [1m[32m0.34018[0m[0m | time: 995.769s
[2K
| Adam | epoch: 002 | loss: 0.34018 - acc: 0.8588 -- iter: 2528/2948
[A[ATraining Step: 173  | total loss: [1m[32m0.34552[0m[0m | time: 1008.848s
[2K
| Adam | epoch: 002 | loss: 0.34552 - acc: 0.8510 -- iter: 2560/2948
[A[ATraining Step: 174  | total loss: [1m[32m0.32900[0m[0m | time: 1022.108s
[2K
| Adam | epoch: 002 | loss: 0.32900 - acc: 0.8628 -- iter: 2592/2948
[A[ATraining Step: 175  | total loss: [1m[32m0.32285[0m[0m | time: 1035.027s
[2K
| Adam | epoch: 002 | loss: 0.32285 - acc: 0.8640 -- iter: 2624/2948
[A[ATraining Step: 176  | total loss: [1m[32m0.31605[0m[0m | time: 1047.905s
[2K
| Adam | epoch: 002 | loss: 0.31605 - acc: 0.8714 -- iter: 2656/2948
[A[ATraining Step: 177  | total loss: [1m[32m0.30578[0m[0m | time: 1060.870s
[2K
| Adam | epoch: 002 | loss: 0.30578 - acc: 0.8780 -- iter: 2688/2948
[A[ATraining Step: 178  | total loss: [1m[32m0.29134[0m[0m | time: 1073.979s
[2K
| Adam | epoch: 002 | loss: 0.29134 - acc: 0.8839 -- iter: 2720/2948
[A[ATraining Step: 179  | total loss: [1m[32m0.29301[0m[0m | time: 1086.622s
[2K
| Adam | epoch: 002 | loss: 0.29301 - acc: 0.8862 -- iter: 2752/2948
[A[ATraining Step: 180  | total loss: [1m[32m0.30101[0m[0m | time: 1099.531s
[2K
| Adam | epoch: 002 | loss: 0.30101 - acc: 0.8788 -- iter: 2784/2948
[A[ATraining Step: 181  | total loss: [1m[32m0.30437[0m[0m | time: 1112.798s
[2K
| Adam | epoch: 002 | loss: 0.30437 - acc: 0.8815 -- iter: 2816/2948
[A[ATraining Step: 182  | total loss: [1m[32m0.29193[0m[0m | time: 1125.965s
[2K
| Adam | epoch: 002 | loss: 0.29193 - acc: 0.8871 -- iter: 2848/2948
[A[ATraining Step: 183  | total loss: [1m[32m0.30314[0m[0m | time: 1138.926s
[2K
| Adam | epoch: 002 | loss: 0.30314 - acc: 0.8797 -- iter: 2880/2948
[A[ATraining Step: 184  | total loss: [1m[32m0.29335[0m[0m | time: 1152.066s
[2K
| Adam | epoch: 002 | loss: 0.29335 - acc: 0.8855 -- iter: 2912/2948
[A[ATraining Step: 185  | total loss: [1m[32m0.29918[0m[0m | time: 1164.776s
[2K
| Adam | epoch: 002 | loss: 0.29918 - acc: 0.8782 -- iter: 2944/2948
[A[ATraining Step: 186  | total loss: [1m[32m0.28736[0m[0m | time: 1245.195s
[2K
| Adam | epoch: 002 | loss: 0.28736 - acc: 0.8841 | val_loss: 0.29905 - val_acc: 0.8850 -- iter: 2948/2948
--
Training Step: 187  | total loss: [1m[32m0.28198[0m[0m | time: 2.502s
[2K
| Adam | epoch: 003 | loss: 0.28198 - acc: 0.8863 -- iter: 0032/2948
[A[ATraining Step: 188  | total loss: [1m[32m0.29474[0m[0m | time: 4.270s
[2K
| Adam | epoch: 003 | loss: 0.29474 - acc: 0.8727 -- iter: 0064/2948
[A[ATraining Step: 189  | total loss: [1m[32m0.27760[0m[0m | time: 12.394s
[2K
| Adam | epoch: 003 | loss: 0.27760 - acc: 0.8854 -- iter: 0096/2948
[A[ATraining Step: 190  | total loss: [1m[32m0.28867[0m[0m | time: 20.531s
[2K
| Adam | epoch: 003 | loss: 0.28867 - acc: 0.8875 -- iter: 0128/2948
[A[ATraining Step: 191  | total loss: [1m[32m0.31018[0m[0m | time: 31.345s
[2K
| Adam | epoch: 003 | loss: 0.31018 - acc: 0.8800 -- iter: 0160/2948
[A[ATraining Step: 192  | total loss: [1m[32m0.31155[0m[0m | time: 44.633s
[2K
| Adam | epoch: 003 | loss: 0.31155 - acc: 0.8795 -- iter: 0192/2948
[A[ATraining Step: 193  | total loss: [1m[32m0.32450[0m[0m | time: 57.632s
[2K
| Adam | epoch: 003 | loss: 0.32450 - acc: 0.8759 -- iter: 0224/2948
[A[ATraining Step: 194  | total loss: [1m[32m0.31637[0m[0m | time: 70.803s
[2K
| Adam | epoch: 003 | loss: 0.31637 - acc: 0.8821 -- iter: 0256/2948
[A[ATraining Step: 195  | total loss: [1m[32m0.32365[0m[0m | time: 83.989s
[2K
| Adam | epoch: 003 | loss: 0.32365 - acc: 0.8845 -- iter: 0288/2948
[A[ATraining Step: 196  | total loss: [1m[32m0.30879[0m[0m | time: 97.283s
[2K
| Adam | epoch: 003 | loss: 0.30879 - acc: 0.8929 -- iter: 0320/2948
[A[ATraining Step: 197  | total loss: [1m[32m0.30714[0m[0m | time: 110.079s
[2K
| Adam | epoch: 003 | loss: 0.30714 - acc: 0.8880 -- iter: 0352/2948
[A[ATraining Step: 198  | total loss: [1m[32m0.29546[0m[0m | time: 123.512s
[2K
| Adam | epoch: 003 | loss: 0.29546 - acc: 0.8992 -- iter: 0384/2948
[A[ATraining Step: 199  | total loss: [1m[32m0.29617[0m[0m | time: 136.823s
[2K
| Adam | epoch: 003 | loss: 0.29617 - acc: 0.8937 -- iter: 0416/2948
[A[ATraining Step: 200  | total loss: [1m[32m0.30326[0m[0m | time: 216.662s
[2K
| Adam | epoch: 003 | loss: 0.30326 - acc: 0.8887 | val_loss: 0.39675 - val_acc: 0.8124 -- iter: 0448/2948
--
Training Step: 201  | total loss: [1m[32m0.29525[0m[0m | time: 230.312s
[2K
| Adam | epoch: 003 | loss: 0.29525 - acc: 0.8904 -- iter: 0480/2948
[A[ATraining Step: 202  | total loss: [1m[32m0.31693[0m[0m | time: 243.808s
[2K
| Adam | epoch: 003 | loss: 0.31693 - acc: 0.8826 -- iter: 0512/2948
[A[ATraining Step: 203  | total loss: [1m[32m0.31545[0m[0m | time: 255.587s
[2K
| Adam | epoch: 003 | loss: 0.31545 - acc: 0.8850 -- iter: 0544/2948
[A[ATraining Step: 204  | total loss: [1m[32m0.29574[0m[0m | time: 263.945s
[2K
| Adam | epoch: 003 | loss: 0.29574 - acc: 0.8934 -- iter: 0576/2948
[A[ATraining Step: 205  | total loss: [1m[32m0.28489[0m[0m | time: 277.242s
[2K
| Adam | epoch: 003 | loss: 0.28489 - acc: 0.8947 -- iter: 0608/2948
[A[ATraining Step: 206  | total loss: [1m[32m0.28758[0m[0m | time: 289.950s
[2K
| Adam | epoch: 003 | loss: 0.28758 - acc: 0.8927 -- iter: 0640/2948
[A[ATraining Step: 207  | total loss: [1m[32m0.28212[0m[0m | time: 303.026s
[2K
| Adam | epoch: 003 | loss: 0.28212 - acc: 0.8909 -- iter: 0672/2948
[A[ATraining Step: 208  | total loss: [1m[32m0.28262[0m[0m | time: 316.162s
[2K
| Adam | epoch: 003 | loss: 0.28262 - acc: 0.8925 -- iter: 0704/2948
[A[ATraining Step: 209  | total loss: [1m[32m0.29246[0m[0m | time: 329.367s
[2K
| Adam | epoch: 003 | loss: 0.29246 - acc: 0.8876 -- iter: 0736/2948
[A[ATraining Step: 210  | total loss: [1m[32m0.30165[0m[0m | time: 342.455s
[2K
| Adam | epoch: 003 | loss: 0.30165 - acc: 0.8832 -- iter: 0768/2948
[A[ATraining Step: 211  | total loss: [1m[32m0.30191[0m[0m | time: 355.405s
[2K
| Adam | epoch: 003 | loss: 0.30191 - acc: 0.8824 -- iter: 0800/2948
[A[ATraining Step: 212  | total loss: [1m[32m0.30048[0m[0m | time: 368.497s
[2K
| Adam | epoch: 003 | loss: 0.30048 - acc: 0.8848 -- iter: 0832/2948
[A[ATraining Step: 213  | total loss: [1m[32m0.28656[0m[0m | time: 381.720s
[2K
| Adam | epoch: 003 | loss: 0.28656 - acc: 0.8932 -- iter: 0864/2948
[A[ATraining Step: 214  | total loss: [1m[32m0.28241[0m[0m | time: 394.984s
[2K
| Adam | epoch: 003 | loss: 0.28241 - acc: 0.8976 -- iter: 0896/2948
[A[ATraining Step: 215  | total loss: [1m[32m0.29040[0m[0m | time: 408.502s
[2K
| Adam | epoch: 003 | loss: 0.29040 - acc: 0.8922 -- iter: 0928/2948
[A[ATraining Step: 216  | total loss: [1m[32m0.30523[0m[0m | time: 421.250s
[2K
| Adam | epoch: 003 | loss: 0.30523 - acc: 0.8811 -- iter: 0960/2948
[A[ATraining Step: 217  | total loss: [1m[32m0.29130[0m[0m | time: 434.915s
[2K
| Adam | epoch: 003 | loss: 0.29130 - acc: 0.8930 -- iter: 0992/2948
[A[ATraining Step: 218  | total loss: [1m[32m0.28477[0m[0m | time: 447.597s
[2K
| Adam | epoch: 003 | loss: 0.28477 - acc: 0.8975 -- iter: 1024/2948
[A[ATraining Step: 219  | total loss: [1m[32m0.30212[0m[0m | time: 460.505s
[2K
| Adam | epoch: 003 | loss: 0.30212 - acc: 0.8890 -- iter: 1056/2948
[A[ATraining Step: 220  | total loss: [1m[32m0.29919[0m[0m | time: 473.761s
[2K
| Adam | epoch: 003 | loss: 0.29919 - acc: 0.8844 -- iter: 1088/2948
[A[ATraining Step: 221  | total loss: [1m[32m0.29643[0m[0m | time: 486.960s
[2K
| Adam | epoch: 003 | loss: 0.29643 - acc: 0.8804 -- iter: 1120/2948
[A[ATraining Step: 222  | total loss: [1m[32m0.30085[0m[0m | time: 500.457s
[2K
| Adam | epoch: 003 | loss: 0.30085 - acc: 0.8736 -- iter: 1152/2948
[A[ATraining Step: 223  | total loss: [1m[32m0.30305[0m[0m | time: 513.904s
[2K
| Adam | epoch: 003 | loss: 0.30305 - acc: 0.8706 -- iter: 1184/2948
[A[ATraining Step: 224  | total loss: [1m[32m0.30877[0m[0m | time: 526.815s
[2K
| Adam | epoch: 003 | loss: 0.30877 - acc: 0.8710 -- iter: 1216/2948
[A[ATraining Step: 225  | total loss: [1m[32m0.31738[0m[0m | time: 539.870s
[2K
| Adam | epoch: 003 | loss: 0.31738 - acc: 0.8652 -- iter: 1248/2948
[A[ATraining Step: 226  | total loss: [1m[32m0.30879[0m[0m | time: 553.116s
[2K
| Adam | epoch: 003 | loss: 0.30879 - acc: 0.8693 -- iter: 1280/2948
[A[ATraining Step: 227  | total loss: [1m[32m0.29200[0m[0m | time: 566.611s
[2K
| Adam | epoch: 003 | loss: 0.29200 - acc: 0.8761 -- iter: 1312/2948
[A[ATraining Step: 228  | total loss: [1m[32m0.27713[0m[0m | time: 580.062s
[2K
| Adam | epoch: 003 | loss: 0.27713 - acc: 0.8823 -- iter: 1344/2948
[A[ATraining Step: 229  | total loss: [1m[32m0.27559[0m[0m | time: 593.270s
[2K
| Adam | epoch: 003 | loss: 0.27559 - acc: 0.8878 -- iter: 1376/2948
[A[ATraining Step: 230  | total loss: [1m[32m0.26473[0m[0m | time: 606.421s
[2K
| Adam | epoch: 003 | loss: 0.26473 - acc: 0.8927 -- iter: 1408/2948
[A[ATraining Step: 231  | total loss: [1m[32m0.25482[0m[0m | time: 619.716s
[2K
| Adam | epoch: 003 | loss: 0.25482 - acc: 0.8972 -- iter: 1440/2948
[A[ATraining Step: 232  | total loss: [1m[32m0.25975[0m[0m | time: 632.933s
[2K
| Adam | epoch: 003 | loss: 0.25975 - acc: 0.8950 -- iter: 1472/2948
[A[ATraining Step: 233  | total loss: [1m[32m0.24753[0m[0m | time: 646.304s
[2K
| Adam | epoch: 003 | loss: 0.24753 - acc: 0.9024 -- iter: 1504/2948
[A[ATraining Step: 234  | total loss: [1m[32m0.24643[0m[0m | time: 659.661s
[2K
| Adam | epoch: 003 | loss: 0.24643 - acc: 0.9059 -- iter: 1536/2948
[A[ATraining Step: 235  | total loss: [1m[32m0.24579[0m[0m | time: 672.841s
[2K
| Adam | epoch: 003 | loss: 0.24579 - acc: 0.9090 -- iter: 1568/2948
[A[ATraining Step: 236  | total loss: [1m[32m0.23798[0m[0m | time: 686.108s
[2K
| Adam | epoch: 003 | loss: 0.23798 - acc: 0.9150 -- iter: 1600/2948
[A[ATraining Step: 237  | total loss: [1m[32m0.27661[0m[0m | time: 699.097s
[2K
| Adam | epoch: 003 | loss: 0.27661 - acc: 0.9048 -- iter: 1632/2948
[A[ATraining Step: 238  | total loss: [1m[32m0.30315[0m[0m | time: 712.233s
[2K
| Adam | epoch: 003 | loss: 0.30315 - acc: 0.8924 -- iter: 1664/2948
[A[ATraining Step: 239  | total loss: [1m[32m0.32525[0m[0m | time: 725.273s
[2K
| Adam | epoch: 003 | loss: 0.32525 - acc: 0.8875 -- iter: 1696/2948
[A[ATraining Step: 240  | total loss: [1m[32m0.31432[0m[0m | time: 738.358s
[2K
| Adam | epoch: 003 | loss: 0.31432 - acc: 0.8894 -- iter: 1728/2948
[A[ATraining Step: 241  | total loss: [1m[32m0.29623[0m[0m | time: 751.566s
[2K
| Adam | epoch: 003 | loss: 0.29623 - acc: 0.8974 -- iter: 1760/2948
[A[ATraining Step: 242  | total loss: [1m[32m0.28624[0m[0m | time: 764.838s
[2K
| Adam | epoch: 003 | loss: 0.28624 - acc: 0.9014 -- iter: 1792/2948
[A[ATraining Step: 243  | total loss: [1m[32m0.30788[0m[0m | time: 777.950s
[2K
| Adam | epoch: 003 | loss: 0.30788 - acc: 0.8956 -- iter: 1824/2948
[A[ATraining Step: 244  | total loss: [1m[32m0.29964[0m[0m | time: 791.505s
[2K
| Adam | epoch: 003 | loss: 0.29964 - acc: 0.8998 -- iter: 1856/2948
[A[ATraining Step: 245  | total loss: [1m[32m0.29410[0m[0m | time: 804.896s
[2K
| Adam | epoch: 003 | loss: 0.29410 - acc: 0.8973 -- iter: 1888/2948
[A[ATraining Step: 246  | total loss: [1m[32m0.29212[0m[0m | time: 817.625s
[2K
| Adam | epoch: 003 | loss: 0.29212 - acc: 0.8982 -- iter: 1920/2948
[A[ATraining Step: 247  | total loss: [1m[32m0.29167[0m[0m | time: 830.946s
[2K
| Adam | epoch: 003 | loss: 0.29167 - acc: 0.8959 -- iter: 1952/2948
[A[ATraining Step: 248  | total loss: [1m[32m0.28855[0m[0m | time: 844.234s
[2K
| Adam | epoch: 003 | loss: 0.28855 - acc: 0.8969 -- iter: 1984/2948
[A[ATraining Step: 249  | total loss: [1m[32m0.29487[0m[0m | time: 857.374s
[2K
| Adam | epoch: 003 | loss: 0.29487 - acc: 0.8947 -- iter: 2016/2948
[A[ATraining Step: 250  | total loss: [1m[32m0.30791[0m[0m | time: 870.592s
[2K
| Adam | epoch: 003 | loss: 0.30791 - acc: 0.8865 -- iter: 2048/2948
[A[ATraining Step: 251  | total loss: [1m[32m0.29179[0m[0m | time: 883.878s
[2K
| Adam | epoch: 003 | loss: 0.29179 - acc: 0.8947 -- iter: 2080/2948
[A[ATraining Step: 252  | total loss: [1m[32m0.27804[0m[0m | time: 897.220s
[2K
| Adam | epoch: 003 | loss: 0.27804 - acc: 0.8990 -- iter: 2112/2948
[A[ATraining Step: 253  | total loss: [1m[32m0.28375[0m[0m | time: 910.398s
[2K
| Adam | epoch: 003 | loss: 0.28375 - acc: 0.8966 -- iter: 2144/2948
[A[ATraining Step: 254  | total loss: [1m[32m0.26570[0m[0m | time: 923.618s
[2K
| Adam | epoch: 003 | loss: 0.26570 - acc: 0.9038 -- iter: 2176/2948
[A[ATraining Step: 255  | total loss: [1m[32m0.25079[0m[0m | time: 936.859s
[2K
| Adam | epoch: 003 | loss: 0.25079 - acc: 0.9103 -- iter: 2208/2948
[A[ATraining Step: 256  | total loss: [1m[32m0.24850[0m[0m | time: 950.374s
[2K
| Adam | epoch: 003 | loss: 0.24850 - acc: 0.9130 -- iter: 2240/2948
[A[ATraining Step: 257  | total loss: [1m[32m0.24720[0m[0m | time: 963.481s
[2K
| Adam | epoch: 003 | loss: 0.24720 - acc: 0.9092 -- iter: 2272/2948
[A[ATraining Step: 258  | total loss: [1m[32m0.24385[0m[0m | time: 976.419s
[2K
| Adam | epoch: 003 | loss: 0.24385 - acc: 0.9027 -- iter: 2304/2948
[A[ATraining Step: 259  | total loss: [1m[32m0.23740[0m[0m | time: 989.531s
[2K
| Adam | epoch: 003 | loss: 0.23740 - acc: 0.9062 -- iter: 2336/2948
[A[ATraining Step: 260  | total loss: [1m[32m0.22900[0m[0m | time: 1002.540s
[2K
| Adam | epoch: 003 | loss: 0.22900 - acc: 0.9093 -- iter: 2368/2948
[A[ATraining Step: 261  | total loss: [1m[32m0.23058[0m[0m | time: 1015.590s
[2K
| Adam | epoch: 003 | loss: 0.23058 - acc: 0.9059 -- iter: 2400/2948
[A[ATraining Step: 262  | total loss: [1m[32m0.21830[0m[0m | time: 1029.086s
[2K
| Adam | epoch: 003 | loss: 0.21830 - acc: 0.9090 -- iter: 2432/2948
[A[ATraining Step: 263  | total loss: [1m[32m0.21605[0m[0m | time: 1041.942s
[2K
| Adam | epoch: 003 | loss: 0.21605 - acc: 0.9119 -- iter: 2464/2948
[A[ATraining Step: 264  | total loss: [1m[32m0.22416[0m[0m | time: 1055.056s
[2K
| Adam | epoch: 003 | loss: 0.22416 - acc: 0.9113 -- iter: 2496/2948
[A[ATraining Step: 265  | total loss: [1m[32m0.21970[0m[0m | time: 1068.396s
[2K
| Adam | epoch: 003 | loss: 0.21970 - acc: 0.9077 -- iter: 2528/2948
[A[ATraining Step: 266  | total loss: [1m[32m0.21166[0m[0m | time: 1081.494s
[2K
| Adam | epoch: 003 | loss: 0.21166 - acc: 0.9107 -- iter: 2560/2948
[A[ATraining Step: 267  | total loss: [1m[32m0.22677[0m[0m | time: 1094.611s
[2K
| Adam | epoch: 003 | loss: 0.22677 - acc: 0.9102 -- iter: 2592/2948
[A[ATraining Step: 268  | total loss: [1m[32m0.23239[0m[0m | time: 1107.680s
[2K
| Adam | epoch: 003 | loss: 0.23239 - acc: 0.9098 -- iter: 2624/2948
[A[ATraining Step: 269  | total loss: [1m[32m0.22360[0m[0m | time: 1121.126s
[2K
| Adam | epoch: 003 | loss: 0.22360 - acc: 0.9157 -- iter: 2656/2948
[A[ATraining Step: 270  | total loss: [1m[32m0.22124[0m[0m | time: 1134.059s
[2K
| Adam | epoch: 003 | loss: 0.22124 - acc: 0.9179 -- iter: 2688/2948
[A[ATraining Step: 271  | total loss: [1m[32m0.21116[0m[0m | time: 1147.172s
[2K
| Adam | epoch: 003 | loss: 0.21116 - acc: 0.9230 -- iter: 2720/2948
[A[ATraining Step: 272  | total loss: [1m[32m0.20870[0m[0m | time: 1160.476s
[2K
| Adam | epoch: 003 | loss: 0.20870 - acc: 0.9213 -- iter: 2752/2948
[A[ATraining Step: 273  | total loss: [1m[32m0.20936[0m[0m | time: 1173.468s
[2K
| Adam | epoch: 003 | loss: 0.20936 - acc: 0.9229 -- iter: 2784/2948
[A[ATraining Step: 274  | total loss: [1m[32m0.20197[0m[0m | time: 1186.542s
[2K
| Adam | epoch: 003 | loss: 0.20197 - acc: 0.9244 -- iter: 2816/2948
[A[ATraining Step: 275  | total loss: [1m[32m0.20716[0m[0m | time: 1199.909s
[2K
| Adam | epoch: 003 | loss: 0.20716 - acc: 0.9226 -- iter: 2848/2948
[A[ATraining Step: 276  | total loss: [1m[32m0.20132[0m[0m | time: 1213.162s
[2K
| Adam | epoch: 003 | loss: 0.20132 - acc: 0.9241 -- iter: 2880/2948
[A[ATraining Step: 277  | total loss: [1m[32m0.23316[0m[0m | time: 1226.254s
[2K
| Adam | epoch: 003 | loss: 0.23316 - acc: 0.9067 -- iter: 2912/2948
[A[ATraining Step: 278  | total loss: [1m[32m0.23500[0m[0m | time: 1239.364s
[2K
| Adam | epoch: 003 | loss: 0.23500 - acc: 0.9035 -- iter: 2944/2948
[A[ATraining Step: 279  | total loss: [1m[32m0.25838[0m[0m | time: 1320.824s
[2K
| Adam | epoch: 003 | loss: 0.25838 - acc: 0.8850 | val_loss: 0.30583 - val_acc: 0.8731 -- iter: 2948/2948
--
Training Step: 280  | total loss: [1m[32m0.26081[0m[0m | time: 12.711s
[2K
| Adam | epoch: 004 | loss: 0.26081 - acc: 0.8871 -- iter: 0032/2948
[A[ATraining Step: 281  | total loss: [1m[32m0.25867[0m[0m | time: 14.463s
[2K
| Adam | epoch: 004 | loss: 0.25867 - acc: 0.8891 -- iter: 0064/2948
[A[ATraining Step: 282  | total loss: [1m[32m0.34144[0m[0m | time: 16.191s
[2K
| Adam | epoch: 004 | loss: 0.34144 - acc: 0.8501 -- iter: 0096/2948
[A[ATraining Step: 283  | total loss: [1m[32m0.35273[0m[0m | time: 24.387s
[2K
| Adam | epoch: 004 | loss: 0.35273 - acc: 0.8401 -- iter: 0128/2948
[A[ATraining Step: 284  | total loss: [1m[32m0.35957[0m[0m | time: 32.781s
[2K
| Adam | epoch: 004 | loss: 0.35957 - acc: 0.8342 -- iter: 0160/2948
[A[ATraining Step: 285  | total loss: [1m[32m0.36134[0m[0m | time: 45.662s
[2K
| Adam | epoch: 004 | loss: 0.36134 - acc: 0.8383 -- iter: 0192/2948
[A[ATraining Step: 286  | total loss: [1m[32m0.35034[0m[0m | time: 58.670s
[2K
| Adam | epoch: 004 | loss: 0.35034 - acc: 0.8451 -- iter: 0224/2948
[A[ATraining Step: 287  | total loss: [1m[32m0.36959[0m[0m | time: 71.807s
[2K
| Adam | epoch: 004 | loss: 0.36959 - acc: 0.8356 -- iter: 0256/2948
[A[ATraining Step: 288  | total loss: [1m[32m0.35680[0m[0m | time: 85.235s
[2K
| Adam | epoch: 004 | loss: 0.35680 - acc: 0.8427 -- iter: 0288/2948
[A[ATraining Step: 289  | total loss: [1m[32m0.34968[0m[0m | time: 98.442s
[2K
| Adam | epoch: 004 | loss: 0.34968 - acc: 0.8428 -- iter: 0320/2948
[A[ATraining Step: 290  | total loss: [1m[32m0.35725[0m[0m | time: 111.091s
[2K
| Adam | epoch: 004 | loss: 0.35725 - acc: 0.8366 -- iter: 0352/2948
[A[ATraining Step: 291  | total loss: [1m[32m0.40735[0m[0m | time: 124.457s
[2K
| Adam | epoch: 004 | loss: 0.40735 - acc: 0.8280 -- iter: 0384/2948
[A[ATraining Step: 292  | total loss: [1m[32m0.39553[0m[0m | time: 137.862s
[2K
| Adam | epoch: 004 | loss: 0.39553 - acc: 0.8358 -- iter: 0416/2948
[A[ATraining Step: 293  | total loss: [1m[32m0.39942[0m[0m | time: 150.795s
[2K
| Adam | epoch: 004 | loss: 0.39942 - acc: 0.8397 -- iter: 0448/2948
[A[ATraining Step: 294  | total loss: [1m[32m0.39612[0m[0m | time: 163.627s
[2K
| Adam | epoch: 004 | loss: 0.39612 - acc: 0.8432 -- iter: 0480/2948
[A[ATraining Step: 295  | total loss: [1m[32m0.37388[0m[0m | time: 176.426s
[2K
| Adam | epoch: 004 | loss: 0.37388 - acc: 0.8527 -- iter: 0512/2948
[A[ATraining Step: 296  | total loss: [1m[32m0.35695[0m[0m | time: 189.880s
[2K
| Adam | epoch: 004 | loss: 0.35695 - acc: 0.8580 -- iter: 0544/2948
[A[ATraining Step: 297  | total loss: [1m[32m0.35228[0m[0m | time: 203.312s
[2K
| Adam | epoch: 004 | loss: 0.35228 - acc: 0.8628 -- iter: 0576/2948
[A[ATraining Step: 298  | total loss: [1m[32m0.34864[0m[0m | time: 216.624s
[2K
| Adam | epoch: 004 | loss: 0.34864 - acc: 0.8609 -- iter: 0608/2948
[A[ATraining Step: 299  | total loss: [1m[32m0.32757[0m[0m | time: 229.532s
[2K
| Adam | epoch: 004 | loss: 0.32757 - acc: 0.8717 -- iter: 0640/2948
[A[ATraining Step: 300  | total loss: [1m[32m0.30967[0m[0m | time: 242.704s
[2K
| Adam | epoch: 004 | loss: 0.30967 - acc: 0.8814 -- iter: 0672/2948
[A[ATraining Step: 301  | total loss: [1m[32m0.29797[0m[0m | time: 255.622s
[2K
| Adam | epoch: 004 | loss: 0.29797 - acc: 0.8870 -- iter: 0704/2948
[A[ATraining Step: 302  | total loss: [1m[32m0.30816[0m[0m | time: 268.891s
[2K
| Adam | epoch: 004 | loss: 0.30816 - acc: 0.8827 -- iter: 0736/2948
[A[ATraining Step: 303  | total loss: [1m[32m0.29659[0m[0m | time: 281.940s
[2K
| Adam | epoch: 004 | loss: 0.29659 - acc: 0.8819 -- iter: 0768/2948
[A[ATraining Step: 304  | total loss: [1m[32m0.29171[0m[0m | time: 295.314s
[2K
| Adam | epoch: 004 | loss: 0.29171 - acc: 0.8812 -- iter: 0800/2948
[A[ATraining Step: 305  | total loss: [1m[32m0.27864[0m[0m | time: 308.313s
[2K
| Adam | epoch: 004 | loss: 0.27864 - acc: 0.8837 -- iter: 0832/2948
[A[ATraining Step: 306  | total loss: [1m[32m0.27405[0m[0m | time: 321.735s
[2K
| Adam | epoch: 004 | loss: 0.27405 - acc: 0.8860 -- iter: 0864/2948
[A[ATraining Step: 307  | total loss: [1m[32m0.26954[0m[0m | time: 334.978s
[2K
| Adam | epoch: 004 | loss: 0.26954 - acc: 0.8911 -- iter: 0896/2948
[A[ATraining Step: 308  | total loss: [1m[32m0.28558[0m[0m | time: 348.102s
[2K
| Adam | epoch: 004 | loss: 0.28558 - acc: 0.8833 -- iter: 0928/2948
[A[ATraining Step: 309  | total loss: [1m[32m0.27578[0m[0m | time: 361.331s
[2K
| Adam | epoch: 004 | loss: 0.27578 - acc: 0.8856 -- iter: 0960/2948
[A[ATraining Step: 310  | total loss: [1m[32m0.27041[0m[0m | time: 374.262s
[2K
| Adam | epoch: 004 | loss: 0.27041 - acc: 0.8939 -- iter: 0992/2948
[A[ATraining Step: 311  | total loss: [1m[32m0.25727[0m[0m | time: 387.259s
[2K
| Adam | epoch: 004 | loss: 0.25727 - acc: 0.9014 -- iter: 1024/2948
[A[ATraining Step: 312  | total loss: [1m[32m0.26336[0m[0m | time: 400.707s
[2K
| Adam | epoch: 004 | loss: 0.26336 - acc: 0.8987 -- iter: 1056/2948
[A[ATraining Step: 313  | total loss: [1m[32m0.25694[0m[0m | time: 413.895s
[2K
| Adam | epoch: 004 | loss: 0.25694 - acc: 0.9026 -- iter: 1088/2948
[A[ATraining Step: 314  | total loss: [1m[32m0.29021[0m[0m | time: 427.052s
[2K
| Adam | epoch: 004 | loss: 0.29021 - acc: 0.8936 -- iter: 1120/2948
[A[ATraining Step: 315  | total loss: [1m[32m0.27580[0m[0m | time: 440.302s
[2K
| Adam | epoch: 004 | loss: 0.27580 - acc: 0.9011 -- iter: 1152/2948
[A[ATraining Step: 316  | total loss: [1m[32m0.28149[0m[0m | time: 453.604s
[2K
| Adam | epoch: 004 | loss: 0.28149 - acc: 0.8985 -- iter: 1184/2948
[A[ATraining Step: 317  | total loss: [1m[32m0.29631[0m[0m | time: 466.590s
[2K
| Adam | epoch: 004 | loss: 0.29631 - acc: 0.8993 -- iter: 1216/2948
[A[ATraining Step: 318  | total loss: [1m[32m0.31144[0m[0m | time: 479.425s
[2K
| Adam | epoch: 004 | loss: 0.31144 - acc: 0.8875 -- iter: 1248/2948
[A[ATraining Step: 319  | total loss: [1m[32m0.31183[0m[0m | time: 492.836s
[2K
| Adam | epoch: 004 | loss: 0.31183 - acc: 0.8831 -- iter: 1280/2948
[A[ATraining Step: 320  | total loss: [1m[32m0.33544[0m[0m | time: 505.800s
[2K
| Adam | epoch: 004 | loss: 0.33544 - acc: 0.8854 -- iter: 1312/2948
[A[ATraining Step: 321  | total loss: [1m[32m0.31607[0m[0m | time: 518.610s
[2K
| Adam | epoch: 004 | loss: 0.31607 - acc: 0.8938 -- iter: 1344/2948
[A[ATraining Step: 322  | total loss: [1m[32m0.30812[0m[0m | time: 531.369s
[2K
| Adam | epoch: 004 | loss: 0.30812 - acc: 0.8919 -- iter: 1376/2948
[A[ATraining Step: 323  | total loss: [1m[32m0.29739[0m[0m | time: 544.552s
[2K
| Adam | epoch: 004 | loss: 0.29739 - acc: 0.8996 -- iter: 1408/2948
[A[ATraining Step: 324  | total loss: [1m[32m0.28751[0m[0m | time: 557.547s
[2K
| Adam | epoch: 004 | loss: 0.28751 - acc: 0.9002 -- iter: 1440/2948
[A[ATraining Step: 325  | total loss: [1m[32m0.29131[0m[0m | time: 570.623s
[2K
| Adam | epoch: 004 | loss: 0.29131 - acc: 0.9008 -- iter: 1472/2948
[A[ATraining Step: 326  | total loss: [1m[32m0.27470[0m[0m | time: 583.743s
[2K
| Adam | epoch: 004 | loss: 0.27470 - acc: 0.9076 -- iter: 1504/2948
[A[ATraining Step: 327  | total loss: [1m[32m0.27886[0m[0m | time: 596.997s
[2K
| Adam | epoch: 004 | loss: 0.27886 - acc: 0.9075 -- iter: 1536/2948
[A[ATraining Step: 328  | total loss: [1m[32m0.26467[0m[0m | time: 610.016s
[2K
| Adam | epoch: 004 | loss: 0.26467 - acc: 0.9136 -- iter: 1568/2948
[A[ATraining Step: 329  | total loss: [1m[32m0.26206[0m[0m | time: 623.005s
[2K
| Adam | epoch: 004 | loss: 0.26206 - acc: 0.9129 -- iter: 1600/2948
[A[ATraining Step: 330  | total loss: [1m[32m0.26269[0m[0m | time: 635.987s
[2K
| Adam | epoch: 004 | loss: 0.26269 - acc: 0.9060 -- iter: 1632/2948
[A[ATraining Step: 331  | total loss: [1m[32m0.25495[0m[0m | time: 649.201s
[2K
| Adam | epoch: 004 | loss: 0.25495 - acc: 0.9122 -- iter: 1664/2948
[A[ATraining Step: 332  | total loss: [1m[32m0.24543[0m[0m | time: 662.326s
[2K
| Adam | epoch: 004 | loss: 0.24543 - acc: 0.9148 -- iter: 1696/2948
[A[ATraining Step: 333  | total loss: [1m[32m0.23796[0m[0m | time: 675.277s
[2K
| Adam | epoch: 004 | loss: 0.23796 - acc: 0.9139 -- iter: 1728/2948
[A[ATraining Step: 334  | total loss: [1m[32m0.22527[0m[0m | time: 688.474s
[2K
| Adam | epoch: 004 | loss: 0.22527 - acc: 0.9163 -- iter: 1760/2948
[A[ATraining Step: 335  | total loss: [1m[32m0.24161[0m[0m | time: 701.430s
[2K
| Adam | epoch: 004 | loss: 0.24161 - acc: 0.8965 -- iter: 1792/2948
[A[ATraining Step: 336  | total loss: [1m[32m0.24271[0m[0m | time: 714.678s
[2K
| Adam | epoch: 004 | loss: 0.24271 - acc: 0.8912 -- iter: 1824/2948
[A[ATraining Step: 337  | total loss: [1m[32m0.23132[0m[0m | time: 727.814s
[2K
| Adam | epoch: 004 | loss: 0.23132 - acc: 0.8959 -- iter: 1856/2948
[A[ATraining Step: 338  | total loss: [1m[32m0.21741[0m[0m | time: 740.823s
[2K
| Adam | epoch: 004 | loss: 0.21741 - acc: 0.9032 -- iter: 1888/2948
[A[ATraining Step: 339  | total loss: [1m[32m0.21891[0m[0m | time: 754.237s
[2K
| Adam | epoch: 004 | loss: 0.21891 - acc: 0.9003 -- iter: 1920/2948
[A[ATraining Step: 340  | total loss: [1m[32m0.21890[0m[0m | time: 767.281s
[2K
| Adam | epoch: 004 | loss: 0.21890 - acc: 0.9009 -- iter: 1952/2948
[A[ATraining Step: 341  | total loss: [1m[32m0.22998[0m[0m | time: 780.703s
[2K
| Adam | epoch: 004 | loss: 0.22998 - acc: 0.8983 -- iter: 1984/2948
[A[ATraining Step: 342  | total loss: [1m[32m0.24088[0m[0m | time: 794.224s
[2K
| Adam | epoch: 004 | loss: 0.24088 - acc: 0.8929 -- iter: 2016/2948
[A[ATraining Step: 343  | total loss: [1m[32m0.27597[0m[0m | time: 807.299s
[2K
| Adam | epoch: 004 | loss: 0.27597 - acc: 0.8786 -- iter: 2048/2948
[A[ATraining Step: 344  | total loss: [1m[32m0.32501[0m[0m | time: 820.507s
[2K
| Adam | epoch: 004 | loss: 0.32501 - acc: 0.8751 -- iter: 2080/2948
[A[ATraining Step: 345  | total loss: [1m[32m0.31859[0m[0m | time: 833.363s
[2K
| Adam | epoch: 004 | loss: 0.31859 - acc: 0.8782 -- iter: 2112/2948
[A[ATraining Step: 346  | total loss: [1m[32m0.31567[0m[0m | time: 846.411s
[2K
| Adam | epoch: 004 | loss: 0.31567 - acc: 0.8779 -- iter: 2144/2948
[A[ATraining Step: 347  | total loss: [1m[32m0.29862[0m[0m | time: 859.374s
[2K
| Adam | epoch: 004 | loss: 0.29862 - acc: 0.8870 -- iter: 2176/2948
[A[ATraining Step: 348  | total loss: [1m[32m0.28364[0m[0m | time: 872.622s
[2K
| Adam | epoch: 004 | loss: 0.28364 - acc: 0.8920 -- iter: 2208/2948
[A[ATraining Step: 349  | total loss: [1m[32m0.27167[0m[0m | time: 886.127s
[2K
| Adam | epoch: 004 | loss: 0.27167 - acc: 0.9028 -- iter: 2240/2948
[A[ATraining Step: 350  | total loss: [1m[32m0.27253[0m[0m | time: 899.583s
[2K
| Adam | epoch: 004 | loss: 0.27253 - acc: 0.9032 -- iter: 2272/2948
[A[ATraining Step: 351  | total loss: [1m[32m0.28361[0m[0m | time: 912.863s
[2K
| Adam | epoch: 004 | loss: 0.28361 - acc: 0.8941 -- iter: 2304/2948
[A[ATraining Step: 352  | total loss: [1m[32m0.27677[0m[0m | time: 925.938s
[2K
| Adam | epoch: 004 | loss: 0.27677 - acc: 0.8984 -- iter: 2336/2948
[A[ATraining Step: 353  | total loss: [1m[32m0.29371[0m[0m | time: 939.084s
[2K
| Adam | epoch: 004 | loss: 0.29371 - acc: 0.8961 -- iter: 2368/2948
[A[ATraining Step: 354  | total loss: [1m[32m0.26895[0m[0m | time: 951.946s
[2K
| Adam | epoch: 004 | loss: 0.26895 - acc: 0.9065 -- iter: 2400/2948
[A[ATraining Step: 355  | total loss: [1m[32m0.25059[0m[0m | time: 964.849s
[2K
| Adam | epoch: 004 | loss: 0.25059 - acc: 0.9127 -- iter: 2432/2948
[A[ATraining Step: 356  | total loss: [1m[32m0.25077[0m[0m | time: 978.040s
[2K
| Adam | epoch: 004 | loss: 0.25077 - acc: 0.9152 -- iter: 2464/2948
[A[ATraining Step: 357  | total loss: [1m[32m0.24256[0m[0m | time: 991.491s
[2K
| Adam | epoch: 004 | loss: 0.24256 - acc: 0.9174 -- iter: 2496/2948
[A[ATraining Step: 358  | total loss: [1m[32m0.23489[0m[0m | time: 1004.562s
[2K
| Adam | epoch: 004 | loss: 0.23489 - acc: 0.9194 -- iter: 2528/2948
[A[ATraining Step: 359  | total loss: [1m[32m0.22719[0m[0m | time: 1017.513s
[2K
| Adam | epoch: 004 | loss: 0.22719 - acc: 0.9181 -- iter: 2560/2948
[A[ATraining Step: 360  | total loss: [1m[32m0.21310[0m[0m | time: 1030.832s
[2K
| Adam | epoch: 004 | loss: 0.21310 - acc: 0.9263 -- iter: 2592/2948
[A[ATraining Step: 361  | total loss: [1m[32m0.22156[0m[0m | time: 1043.919s
[2K
| Adam | epoch: 004 | loss: 0.22156 - acc: 0.9212 -- iter: 2624/2948
[A[ATraining Step: 362  | total loss: [1m[32m0.21674[0m[0m | time: 1056.852s
[2K
| Adam | epoch: 004 | loss: 0.21674 - acc: 0.9197 -- iter: 2656/2948
[A[ATraining Step: 363  | total loss: [1m[32m0.20709[0m[0m | time: 1070.219s
[2K
| Adam | epoch: 004 | loss: 0.20709 - acc: 0.9246 -- iter: 2688/2948
[A[ATraining Step: 364  | total loss: [1m[32m0.20507[0m[0m | time: 1083.839s
[2K
| Adam | epoch: 004 | loss: 0.20507 - acc: 0.9290 -- iter: 2720/2948
[A[ATraining Step: 365  | total loss: [1m[32m0.20316[0m[0m | time: 1096.792s
[2K
| Adam | epoch: 004 | loss: 0.20316 - acc: 0.9299 -- iter: 2752/2948
[A[ATraining Step: 366  | total loss: [1m[32m0.19231[0m[0m | time: 1110.163s
[2K
| Adam | epoch: 004 | loss: 0.19231 - acc: 0.9369 -- iter: 2784/2948
[A[ATraining Step: 367  | total loss: [1m[32m0.20096[0m[0m | time: 1123.500s
[2K
| Adam | epoch: 004 | loss: 0.20096 - acc: 0.9307 -- iter: 2816/2948
[A[ATraining Step: 368  | total loss: [1m[32m0.18627[0m[0m | time: 1137.049s
[2K
| Adam | epoch: 004 | loss: 0.18627 - acc: 0.9376 -- iter: 2848/2948
[A[ATraining Step: 369  | total loss: [1m[32m0.18117[0m[0m | time: 1150.237s
[2K
| Adam | epoch: 004 | loss: 0.18117 - acc: 0.9407 -- iter: 2880/2948
[A[ATraining Step: 370  | total loss: [1m[32m0.18007[0m[0m | time: 1163.400s
[2K
| Adam | epoch: 004 | loss: 0.18007 - acc: 0.9404 -- iter: 2912/2948
[A[ATraining Step: 371  | total loss: [1m[32m0.18980[0m[0m | time: 1177.099s
[2K
| Adam | epoch: 004 | loss: 0.18980 - acc: 0.9401 -- iter: 2944/2948
[A[ATraining Step: 372  | total loss: [1m[32m0.19961[0m[0m | time: 1258.444s
[2K
| Adam | epoch: 004 | loss: 0.19961 - acc: 0.9367 | val_loss: 0.34327 - val_acc: 0.8731 -- iter: 2948/2948
--
Training Step: 373  | total loss: [1m[32m0.19119[0m[0m | time: 14.086s
[2K
| Adam | epoch: 005 | loss: 0.19119 - acc: 0.9399 -- iter: 0032/2948
[A[ATraining Step: 374  | total loss: [1m[32m0.19912[0m[0m | time: 24.536s
[2K
| Adam | epoch: 005 | loss: 0.19912 - acc: 0.9366 -- iter: 0064/2948
[A[ATraining Step: 375  | total loss: [1m[32m0.18454[0m[0m | time: 26.274s
[2K
| Adam | epoch: 005 | loss: 0.18454 - acc: 0.9429 -- iter: 0096/2948
[A[ATraining Step: 376  | total loss: [1m[32m0.16985[0m[0m | time: 28.014s
[2K
| Adam | epoch: 005 | loss: 0.16985 - acc: 0.9486 -- iter: 0128/2948
[A[ATraining Step: 377  | total loss: [1m[32m0.15529[0m[0m | time: 36.291s
[2K
| Adam | epoch: 005 | loss: 0.15529 - acc: 0.9538 -- iter: 0160/2948
[A[ATraining Step: 378  | total loss: [1m[32m0.15647[0m[0m | time: 44.697s
[2K
| Adam | epoch: 005 | loss: 0.15647 - acc: 0.9521 -- iter: 0192/2948
[A[ATraining Step: 379  | total loss: [1m[32m0.15497[0m[0m | time: 53.336s
[2K
| Adam | epoch: 005 | loss: 0.15497 - acc: 0.9475 -- iter: 0224/2948
[A[ATraining Step: 380  | total loss: [1m[32m0.14831[0m[0m | time: 63.611s
[2K
| Adam | epoch: 005 | loss: 0.14831 - acc: 0.9497 -- iter: 0256/2948
[A[ATraining Step: 381  | total loss: [1m[32m0.15550[0m[0m | time: 76.980s
[2K
| Adam | epoch: 005 | loss: 0.15550 - acc: 0.9516 -- iter: 0288/2948
[A[ATraining Step: 382  | total loss: [1m[32m0.16163[0m[0m | time: 89.990s
[2K
| Adam | epoch: 005 | loss: 0.16163 - acc: 0.9470 -- iter: 0320/2948
[A[ATraining Step: 383  | total loss: [1m[32m0.15907[0m[0m | time: 103.009s
[2K
| Adam | epoch: 005 | loss: 0.15907 - acc: 0.9492 -- iter: 0352/2948
[A[ATraining Step: 384  | total loss: [1m[32m0.15454[0m[0m | time: 116.247s
[2K
| Adam | epoch: 005 | loss: 0.15454 - acc: 0.9512 -- iter: 0384/2948
[A[ATraining Step: 385  | total loss: [1m[32m0.14791[0m[0m | time: 129.700s
[2K
| Adam | epoch: 005 | loss: 0.14791 - acc: 0.9498 -- iter: 0416/2948
[A[ATraining Step: 386  | total loss: [1m[32m0.13759[0m[0m | time: 143.047s
[2K
| Adam | epoch: 005 | loss: 0.13759 - acc: 0.9548 -- iter: 0448/2948
[A[ATraining Step: 387  | total loss: [1m[32m0.13249[0m[0m | time: 156.095s
[2K
| Adam | epoch: 005 | loss: 0.13249 - acc: 0.9562 -- iter: 0480/2948
[A[ATraining Step: 388  | total loss: [1m[32m0.16087[0m[0m | time: 169.406s
[2K
| Adam | epoch: 005 | loss: 0.16087 - acc: 0.9418 -- iter: 0512/2948
[A[ATraining Step: 389  | total loss: [1m[32m0.16278[0m[0m | time: 182.777s
[2K
| Adam | epoch: 005 | loss: 0.16278 - acc: 0.9320 -- iter: 0544/2948
[A[ATraining Step: 390  | total loss: [1m[32m0.15866[0m[0m | time: 196.180s
[2K
| Adam | epoch: 005 | loss: 0.15866 - acc: 0.9295 -- iter: 0576/2948
[A[ATraining Step: 391  | total loss: [1m[32m0.15190[0m[0m | time: 209.580s
[2K
| Adam | epoch: 005 | loss: 0.15190 - acc: 0.9303 -- iter: 0608/2948
[A[ATraining Step: 392  | total loss: [1m[32m0.16421[0m[0m | time: 222.866s
[2K
| Adam | epoch: 005 | loss: 0.16421 - acc: 0.9310 -- iter: 0640/2948
[A[ATraining Step: 393  | total loss: [1m[32m0.18204[0m[0m | time: 236.450s
[2K
| Adam | epoch: 005 | loss: 0.18204 - acc: 0.9254 -- iter: 0672/2948
[A[ATraining Step: 394  | total loss: [1m[32m0.17576[0m[0m | time: 249.610s
[2K
| Adam | epoch: 005 | loss: 0.17576 - acc: 0.9297 -- iter: 0704/2948
[A[ATraining Step: 395  | total loss: [1m[32m0.17626[0m[0m | time: 263.066s
[2K
| Adam | epoch: 005 | loss: 0.17626 - acc: 0.9242 -- iter: 0736/2948
[A[ATraining Step: 396  | total loss: [1m[32m0.22894[0m[0m | time: 276.095s
[2K
| Adam | epoch: 005 | loss: 0.22894 - acc: 0.9068 -- iter: 0768/2948
[A[ATraining Step: 397  | total loss: [1m[32m0.21266[0m[0m | time: 289.604s
[2K
| Adam | epoch: 005 | loss: 0.21266 - acc: 0.9130 -- iter: 0800/2948
[A[ATraining Step: 398  | total loss: [1m[32m0.21042[0m[0m | time: 302.989s
[2K
| Adam | epoch: 005 | loss: 0.21042 - acc: 0.9092 -- iter: 0832/2948
[A[ATraining Step: 399  | total loss: [1m[32m0.19795[0m[0m | time: 316.021s
[2K
| Adam | epoch: 005 | loss: 0.19795 - acc: 0.9183 -- iter: 0864/2948
[A[ATraining Step: 400  | total loss: [1m[32m0.18249[0m[0m | time: 396.967s
[2K
| Adam | epoch: 005 | loss: 0.18249 - acc: 0.9265 | val_loss: 0.67355 - val_acc: 0.7961 -- iter: 0896/2948
--
Training Step: 401  | total loss: [1m[32m0.18328[0m[0m | time: 410.098s
[2K
| Adam | epoch: 005 | loss: 0.18328 - acc: 0.9244 -- iter: 0928/2948
[A[ATraining Step: 402  | total loss: [1m[32m0.18871[0m[0m | time: 423.684s
[2K
| Adam | epoch: 005 | loss: 0.18871 - acc: 0.9226 -- iter: 0960/2948
[A[ATraining Step: 403  | total loss: [1m[32m0.19810[0m[0m | time: 437.494s
[2K
| Adam | epoch: 005 | loss: 0.19810 - acc: 0.9241 -- iter: 0992/2948
[A[ATraining Step: 404  | total loss: [1m[32m0.18617[0m[0m | time: 451.427s
[2K
| Adam | epoch: 005 | loss: 0.18617 - acc: 0.9254 -- iter: 1024/2948
[A[ATraining Step: 405  | total loss: [1m[32m0.19534[0m[0m | time: 465.532s
[2K
| Adam | epoch: 005 | loss: 0.19534 - acc: 0.9235 -- iter: 1056/2948
[A[ATraining Step: 406  | total loss: [1m[32m0.18616[0m[0m | time: 478.665s
[2K
| Adam | epoch: 005 | loss: 0.18616 - acc: 0.9281 -- iter: 1088/2948
[A[ATraining Step: 407  | total loss: [1m[32m0.19418[0m[0m | time: 487.173s
[2K
| Adam | epoch: 005 | loss: 0.19418 - acc: 0.9227 -- iter: 1120/2948
[A[ATraining Step: 408  | total loss: [1m[32m0.18668[0m[0m | time: 499.525s
[2K
| Adam | epoch: 005 | loss: 0.18668 - acc: 0.9242 -- iter: 1152/2948
[A[ATraining Step: 409  | total loss: [1m[32m0.26301[0m[0m | time: 512.482s
[2K
| Adam | epoch: 005 | loss: 0.26301 - acc: 0.9099 -- iter: 1184/2948
[A[ATraining Step: 410  | total loss: [1m[32m0.27101[0m[0m | time: 525.644s
[2K
| Adam | epoch: 005 | loss: 0.27101 - acc: 0.9033 -- iter: 1216/2948
[A[ATraining Step: 411  | total loss: [1m[32m0.25221[0m[0m | time: 538.752s
[2K
| Adam | epoch: 005 | loss: 0.25221 - acc: 0.9099 -- iter: 1248/2948
[A[ATraining Step: 412  | total loss: [1m[32m0.25558[0m[0m | time: 552.042s
[2K
| Adam | epoch: 005 | loss: 0.25558 - acc: 0.9064 -- iter: 1280/2948
[A[ATraining Step: 413  | total loss: [1m[32m0.24780[0m[0m | time: 565.085s
[2K
| Adam | epoch: 005 | loss: 0.24780 - acc: 0.9095 -- iter: 1312/2948
[A[ATraining Step: 414  | total loss: [1m[32m0.25174[0m[0m | time: 577.769s
[2K
| Adam | epoch: 005 | loss: 0.25174 - acc: 0.9092 -- iter: 1344/2948
[A[ATraining Step: 415  | total loss: [1m[32m0.25509[0m[0m | time: 590.808s
[2K
| Adam | epoch: 005 | loss: 0.25509 - acc: 0.9089 -- iter: 1376/2948
[A[ATraining Step: 416  | total loss: [1m[32m0.25124[0m[0m | time: 603.822s
[2K
| Adam | epoch: 005 | loss: 0.25124 - acc: 0.9117 -- iter: 1408/2948
[A[ATraining Step: 417  | total loss: [1m[32m0.24277[0m[0m | time: 617.264s
[2K
| Adam | epoch: 005 | loss: 0.24277 - acc: 0.9143 -- iter: 1440/2948
[A[ATraining Step: 418  | total loss: [1m[32m0.23171[0m[0m | time: 630.224s
[2K
| Adam | epoch: 005 | loss: 0.23171 - acc: 0.9166 -- iter: 1472/2948
[A[ATraining Step: 419  | total loss: [1m[32m0.23060[0m[0m | time: 643.424s
[2K
| Adam | epoch: 005 | loss: 0.23060 - acc: 0.9156 -- iter: 1504/2948
[A[ATraining Step: 420  | total loss: [1m[32m0.21285[0m[0m | time: 656.474s
[2K
| Adam | epoch: 005 | loss: 0.21285 - acc: 0.9240 -- iter: 1536/2948
[A[ATraining Step: 421  | total loss: [1m[32m0.21558[0m[0m | time: 669.629s
[2K
| Adam | epoch: 005 | loss: 0.21558 - acc: 0.9254 -- iter: 1568/2948
[A[ATraining Step: 422  | total loss: [1m[32m0.21913[0m[0m | time: 682.633s
[2K
| Adam | epoch: 005 | loss: 0.21913 - acc: 0.9235 -- iter: 1600/2948
[A[ATraining Step: 423  | total loss: [1m[32m0.21181[0m[0m | time: 695.772s
[2K
| Adam | epoch: 005 | loss: 0.21181 - acc: 0.9249 -- iter: 1632/2948
[A[ATraining Step: 424  | total loss: [1m[32m0.20996[0m[0m | time: 709.015s
[2K
| Adam | epoch: 005 | loss: 0.20996 - acc: 0.9261 -- iter: 1664/2948
[A[ATraining Step: 425  | total loss: [1m[32m0.20725[0m[0m | time: 722.217s
[2K
| Adam | epoch: 005 | loss: 0.20725 - acc: 0.9273 -- iter: 1696/2948
[A[ATraining Step: 426  | total loss: [1m[32m0.20764[0m[0m | time: 735.552s
[2K
| Adam | epoch: 005 | loss: 0.20764 - acc: 0.9283 -- iter: 1728/2948
[A[ATraining Step: 427  | total loss: [1m[32m0.21726[0m[0m | time: 748.381s
[2K
| Adam | epoch: 005 | loss: 0.21726 - acc: 0.9261 -- iter: 1760/2948
[A[ATraining Step: 428  | total loss: [1m[32m0.21353[0m[0m | time: 761.621s
[2K
| Adam | epoch: 005 | loss: 0.21353 - acc: 0.9304 -- iter: 1792/2948
[A[ATraining Step: 429  | total loss: [1m[32m0.22693[0m[0m | time: 774.716s
[2K
| Adam | epoch: 005 | loss: 0.22693 - acc: 0.9279 -- iter: 1824/2948
[A[ATraining Step: 430  | total loss: [1m[32m0.22133[0m[0m | time: 787.814s
[2K
| Adam | epoch: 005 | loss: 0.22133 - acc: 0.9320 -- iter: 1856/2948
[A[ATraining Step: 431  | total loss: [1m[32m0.21516[0m[0m | time: 800.941s
[2K
| Adam | epoch: 005 | loss: 0.21516 - acc: 0.9326 -- iter: 1888/2948
[A[ATraining Step: 432  | total loss: [1m[32m0.22753[0m[0m | time: 814.016s
[2K
| Adam | epoch: 005 | loss: 0.22753 - acc: 0.9237 -- iter: 1920/2948
[A[ATraining Step: 433  | total loss: [1m[32m0.23826[0m[0m | time: 827.345s
[2K
| Adam | epoch: 005 | loss: 0.23826 - acc: 0.9188 -- iter: 1952/2948
[A[ATraining Step: 434  | total loss: [1m[32m0.23874[0m[0m | time: 841.303s
[2K
| Adam | epoch: 005 | loss: 0.23874 - acc: 0.9144 -- iter: 1984/2948
[A[ATraining Step: 435  | total loss: [1m[32m0.23480[0m[0m | time: 854.419s
[2K
| Adam | epoch: 005 | loss: 0.23480 - acc: 0.9136 -- iter: 2016/2948
[A[ATraining Step: 436  | total loss: [1m[32m0.22891[0m[0m | time: 867.914s
[2K
| Adam | epoch: 005 | loss: 0.22891 - acc: 0.9098 -- iter: 2048/2948
[A[ATraining Step: 437  | total loss: [1m[32m0.22694[0m[0m | time: 881.180s
[2K
| Adam | epoch: 005 | loss: 0.22694 - acc: 0.9094 -- iter: 2080/2948
[A[ATraining Step: 438  | total loss: [1m[32m0.23644[0m[0m | time: 894.355s
[2K
| Adam | epoch: 005 | loss: 0.23644 - acc: 0.9028 -- iter: 2112/2948
[A[ATraining Step: 439  | total loss: [1m[32m0.22445[0m[0m | time: 907.632s
[2K
| Adam | epoch: 005 | loss: 0.22445 - acc: 0.9126 -- iter: 2144/2948
[A[ATraining Step: 440  | total loss: [1m[32m0.21849[0m[0m | time: 921.156s
[2K
| Adam | epoch: 005 | loss: 0.21849 - acc: 0.9151 -- iter: 2176/2948
[A[ATraining Step: 441  | total loss: [1m[32m0.21060[0m[0m | time: 934.432s
[2K
| Adam | epoch: 005 | loss: 0.21060 - acc: 0.9142 -- iter: 2208/2948
[A[ATraining Step: 442  | total loss: [1m[32m0.21001[0m[0m | time: 947.946s
[2K
| Adam | epoch: 005 | loss: 0.21001 - acc: 0.9196 -- iter: 2240/2948
[A[ATraining Step: 443  | total loss: [1m[32m0.19486[0m[0m | time: 961.130s
[2K
| Adam | epoch: 005 | loss: 0.19486 - acc: 0.9277 -- iter: 2272/2948
[A[ATraining Step: 444  | total loss: [1m[32m0.18416[0m[0m | time: 974.767s
[2K
| Adam | epoch: 005 | loss: 0.18416 - acc: 0.9318 -- iter: 2304/2948
[A[ATraining Step: 445  | total loss: [1m[32m0.17580[0m[0m | time: 987.893s
[2K
| Adam | epoch: 005 | loss: 0.17580 - acc: 0.9355 -- iter: 2336/2948
[A[ATraining Step: 446  | total loss: [1m[32m0.18002[0m[0m | time: 1001.136s
[2K
| Adam | epoch: 005 | loss: 0.18002 - acc: 0.9325 -- iter: 2368/2948
[A[ATraining Step: 447  | total loss: [1m[32m0.18103[0m[0m | time: 1014.156s
[2K
| Adam | epoch: 005 | loss: 0.18103 - acc: 0.9330 -- iter: 2400/2948
[A[ATraining Step: 448  | total loss: [1m[32m0.17402[0m[0m | time: 1027.870s
[2K
| Adam | epoch: 005 | loss: 0.17402 - acc: 0.9366 -- iter: 2432/2948
[A[ATraining Step: 449  | total loss: [1m[32m0.18645[0m[0m | time: 1041.135s
[2K
| Adam | epoch: 005 | loss: 0.18645 - acc: 0.9398 -- iter: 2464/2948
[A[ATraining Step: 450  | total loss: [1m[32m0.17644[0m[0m | time: 1054.160s
[2K
| Adam | epoch: 005 | loss: 0.17644 - acc: 0.9427 -- iter: 2496/2948
[A[ATraining Step: 451  | total loss: [1m[32m0.17113[0m[0m | time: 1067.518s
[2K
| Adam | epoch: 005 | loss: 0.17113 - acc: 0.9422 -- iter: 2528/2948
[A[ATraining Step: 452  | total loss: [1m[32m0.16619[0m[0m | time: 1081.008s
[2K
| Adam | epoch: 005 | loss: 0.16619 - acc: 0.9449 -- iter: 2560/2948
[A[ATraining Step: 453  | total loss: [1m[32m0.17170[0m[0m | time: 1094.656s
[2K
| Adam | epoch: 005 | loss: 0.17170 - acc: 0.9441 -- iter: 2592/2948
[A[ATraining Step: 454  | total loss: [1m[32m0.19926[0m[0m | time: 1108.162s
[2K
| Adam | epoch: 005 | loss: 0.19926 - acc: 0.9341 -- iter: 2624/2948
[A[ATraining Step: 455  | total loss: [1m[32m0.19598[0m[0m | time: 1122.142s
[2K
| Adam | epoch: 005 | loss: 0.19598 - acc: 0.9344 -- iter: 2656/2948
[A[ATraining Step: 456  | total loss: [1m[32m0.18132[0m[0m | time: 1135.290s
[2K
| Adam | epoch: 005 | loss: 0.18132 - acc: 0.9410 -- iter: 2688/2948
[A[ATraining Step: 457  | total loss: [1m[32m0.18146[0m[0m | time: 1148.583s
[2K
| Adam | epoch: 005 | loss: 0.18146 - acc: 0.9375 -- iter: 2720/2948
[A[ATraining Step: 458  | total loss: [1m[32m0.19150[0m[0m | time: 1161.362s
[2K
| Adam | epoch: 005 | loss: 0.19150 - acc: 0.9281 -- iter: 2752/2948
[A[ATraining Step: 459  | total loss: [1m[32m0.18229[0m[0m | time: 1175.308s
[2K
| Adam | epoch: 005 | loss: 0.18229 - acc: 0.9322 -- iter: 2784/2948
[A[ATraining Step: 460  | total loss: [1m[32m0.17523[0m[0m | time: 1188.307s
[2K
| Adam | epoch: 005 | loss: 0.17523 - acc: 0.9358 -- iter: 2816/2948
[A[ATraining Step: 461  | total loss: [1m[32m0.16815[0m[0m | time: 1201.625s
[2K
| Adam | epoch: 005 | loss: 0.16815 - acc: 0.9391 -- iter: 2848/2948
[A[ATraining Step: 462  | total loss: [1m[32m0.16322[0m[0m | time: 1214.986s
[2K
| Adam | epoch: 005 | loss: 0.16322 - acc: 0.9421 -- iter: 2880/2948
[A[ATraining Step: 463  | total loss: [1m[32m0.17155[0m[0m | time: 1228.383s
[2K
| Adam | epoch: 005 | loss: 0.17155 - acc: 0.9416 -- iter: 2912/2948
[A[ATraining Step: 464  | total loss: [1m[32m0.16254[0m[0m | time: 1241.483s
[2K
| Adam | epoch: 005 | loss: 0.16254 - acc: 0.9444 -- iter: 2944/2948
[A[ATraining Step: 465  | total loss: [1m[32m0.16992[0m[0m | time: 1322.491s
[2K
| Adam | epoch: 005 | loss: 0.16992 - acc: 0.9374 | val_loss: 0.54706 - val_acc: 0.8004 -- iter: 2948/2948
--
Training Step: 466  | total loss: [1m[32m0.17504[0m[0m | time: 13.917s
[2K
| Adam | epoch: 006 | loss: 0.17504 - acc: 0.9374 -- iter: 0032/2948
[A[ATraining Step: 467  | total loss: [1m[32m0.16705[0m[0m | time: 27.638s
[2K
| Adam | epoch: 006 | loss: 0.16705 - acc: 0.9406 -- iter: 0064/2948
[A[ATraining Step: 468  | total loss: [1m[32m0.16643[0m[0m | time: 38.252s
[2K
| Adam | epoch: 006 | loss: 0.16643 - acc: 0.9403 -- iter: 0096/2948
[A[ATraining Step: 469  | total loss: [1m[32m0.16330[0m[0m | time: 39.948s
[2K
| Adam | epoch: 006 | loss: 0.16330 - acc: 0.9431 -- iter: 0128/2948
[A[ATraining Step: 470  | total loss: [1m[32m0.15650[0m[0m | time: 41.665s
[2K
| Adam | epoch: 006 | loss: 0.15650 - acc: 0.9488 -- iter: 0160/2948
[A[ATraining Step: 471  | total loss: [1m[32m0.14536[0m[0m | time: 49.976s
[2K
| Adam | epoch: 006 | loss: 0.14536 - acc: 0.9539 -- iter: 0192/2948
[A[ATraining Step: 472  | total loss: [1m[32m0.13508[0m[0m | time: 61.353s
[2K
| Adam | epoch: 006 | loss: 0.13508 - acc: 0.9585 -- iter: 0224/2948
[A[ATraining Step: 473  | total loss: [1m[32m0.14039[0m[0m | time: 74.681s
[2K
| Adam | epoch: 006 | loss: 0.14039 - acc: 0.9564 -- iter: 0256/2948
[A[ATraining Step: 474  | total loss: [1m[32m0.13933[0m[0m | time: 87.915s
[2K
| Adam | epoch: 006 | loss: 0.13933 - acc: 0.9577 -- iter: 0288/2948
[A[ATraining Step: 475  | total loss: [1m[32m0.13704[0m[0m | time: 100.984s
[2K
| Adam | epoch: 006 | loss: 0.13704 - acc: 0.9556 -- iter: 0320/2948
[A[ATraining Step: 476  | total loss: [1m[32m0.14987[0m[0m | time: 113.974s
[2K
| Adam | epoch: 006 | loss: 0.14987 - acc: 0.9476 -- iter: 0352/2948
[A[ATraining Step: 477  | total loss: [1m[32m0.15049[0m[0m | time: 127.533s
[2K
| Adam | epoch: 006 | loss: 0.15049 - acc: 0.9434 -- iter: 0384/2948
[A[ATraining Step: 478  | total loss: [1m[32m0.15907[0m[0m | time: 140.605s
[2K
| Adam | epoch: 006 | loss: 0.15907 - acc: 0.9428 -- iter: 0416/2948
[A[ATraining Step: 479  | total loss: [1m[32m0.16018[0m[0m | time: 154.048s
[2K
| Adam | epoch: 006 | loss: 0.16018 - acc: 0.9392 -- iter: 0448/2948
[A[ATraining Step: 480  | total loss: [1m[32m0.22278[0m[0m | time: 167.129s
[2K
| Adam | epoch: 006 | loss: 0.22278 - acc: 0.9109 -- iter: 0480/2948
[A[ATraining Step: 481  | total loss: [1m[32m0.23757[0m[0m | time: 180.283s
[2K
| Adam | epoch: 006 | loss: 0.23757 - acc: 0.9011 -- iter: 0512/2948
[A[ATraining Step: 482  | total loss: [1m[32m0.25638[0m[0m | time: 193.625s
[2K
| Adam | epoch: 006 | loss: 0.25638 - acc: 0.9016 -- iter: 0544/2948
[A[ATraining Step: 483  | total loss: [1m[32m0.24549[0m[0m | time: 207.006s
[2K
| Adam | epoch: 006 | loss: 0.24549 - acc: 0.9052 -- iter: 0576/2948
[A[ATraining Step: 484  | total loss: [1m[32m0.23266[0m[0m | time: 220.214s
[2K
| Adam | epoch: 006 | loss: 0.23266 - acc: 0.9115 -- iter: 0608/2948
[A[ATraining Step: 485  | total loss: [1m[32m0.26734[0m[0m | time: 233.524s
[2K
| Adam | epoch: 006 | loss: 0.26734 - acc: 0.9016 -- iter: 0640/2948
[A[ATraining Step: 486  | total loss: [1m[32m0.25916[0m[0m | time: 246.815s
[2K
| Adam | epoch: 006 | loss: 0.25916 - acc: 0.9083 -- iter: 0672/2948
[A[ATraining Step: 487  | total loss: [1m[32m0.24709[0m[0m | time: 260.351s
[2K
| Adam | epoch: 006 | loss: 0.24709 - acc: 0.9081 -- iter: 0704/2948
[A[ATraining Step: 488  | total loss: [1m[32m0.25411[0m[0m | time: 273.640s
[2K
| Adam | epoch: 006 | loss: 0.25411 - acc: 0.9048 -- iter: 0736/2948
[A[ATraining Step: 489  | total loss: [1m[32m0.24357[0m[0m | time: 287.030s
[2K
| Adam | epoch: 006 | loss: 0.24357 - acc: 0.9081 -- iter: 0768/2948
[A[ATraining Step: 490  | total loss: [1m[32m0.23119[0m[0m | time: 300.343s
[2K
| Adam | epoch: 006 | loss: 0.23119 - acc: 0.9173 -- iter: 0800/2948
[A[ATraining Step: 491  | total loss: [1m[32m0.21887[0m[0m | time: 313.207s
[2K
| Adam | epoch: 006 | loss: 0.21887 - acc: 0.9224 -- iter: 0832/2948
[A[ATraining Step: 492  | total loss: [1m[32m0.22166[0m[0m | time: 327.134s
[2K
| Adam | epoch: 006 | loss: 0.22166 - acc: 0.9177 -- iter: 0864/2948
[A[ATraining Step: 493  | total loss: [1m[32m0.22066[0m[0m | time: 340.374s
[2K
| Adam | epoch: 006 | loss: 0.22066 - acc: 0.9165 -- iter: 0896/2948
[A[ATraining Step: 494  | total loss: [1m[32m0.20698[0m[0m | time: 353.496s
[2K
| Adam | epoch: 006 | loss: 0.20698 - acc: 0.9218 -- iter: 0928/2948
[A[ATraining Step: 495  | total loss: [1m[32m0.20218[0m[0m | time: 366.919s
[2K
| Adam | epoch: 006 | loss: 0.20218 - acc: 0.9233 -- iter: 0960/2948
[A[ATraining Step: 496  | total loss: [1m[32m0.19682[0m[0m | time: 380.434s
[2K
| Adam | epoch: 006 | loss: 0.19682 - acc: 0.9279 -- iter: 0992/2948
[A[ATraining Step: 497  | total loss: [1m[32m0.19403[0m[0m | time: 393.737s
[2K
| Adam | epoch: 006 | loss: 0.19403 - acc: 0.9288 -- iter: 1024/2948
[A[ATraining Step: 498  | total loss: [1m[32m0.19759[0m[0m | time: 406.947s
[2K
| Adam | epoch: 006 | loss: 0.19759 - acc: 0.9266 -- iter: 1056/2948
[A[ATraining Step: 499  | total loss: [1m[32m0.19637[0m[0m | time: 420.823s
[2K
| Adam | epoch: 006 | loss: 0.19637 - acc: 0.9245 -- iter: 1088/2948
[A[ATraining Step: 500  | total loss: [1m[32m0.21478[0m[0m | time: 433.932s
[2K
| Adam | epoch: 006 | loss: 0.21478 - acc: 0.9258 -- iter: 1120/2948
[A[ATraining Step: 501  | total loss: [1m[32m0.22863[0m[0m | time: 446.881s
[2K
| Adam | epoch: 006 | loss: 0.22863 - acc: 0.9208 -- iter: 1152/2948
[A[ATraining Step: 502  | total loss: [1m[32m0.21213[0m[0m | time: 460.092s
[2K
| Adam | epoch: 006 | loss: 0.21213 - acc: 0.9256 -- iter: 1184/2948
[A[ATraining Step: 503  | total loss: [1m[32m0.19632[0m[0m | time: 473.295s
[2K
| Adam | epoch: 006 | loss: 0.19632 - acc: 0.9299 -- iter: 1216/2948
[A[ATraining Step: 504  | total loss: [1m[32m0.18358[0m[0m | time: 486.525s
[2K
| Adam | epoch: 006 | loss: 0.18358 - acc: 0.9338 -- iter: 1248/2948
[A[ATraining Step: 505  | total loss: [1m[32m0.21166[0m[0m | time: 500.167s
[2K
| Adam | epoch: 006 | loss: 0.21166 - acc: 0.9279 -- iter: 1280/2948
[A[ATraining Step: 506  | total loss: [1m[32m0.20410[0m[0m | time: 513.648s
[2K
| Adam | epoch: 006 | loss: 0.20410 - acc: 0.9288 -- iter: 1312/2948
[A[ATraining Step: 507  | total loss: [1m[32m0.19525[0m[0m | time: 526.917s
[2K
| Adam | epoch: 006 | loss: 0.19525 - acc: 0.9328 -- iter: 1344/2948
[A[ATraining Step: 508  | total loss: [1m[32m0.20113[0m[0m | time: 540.487s
[2K
| Adam | epoch: 006 | loss: 0.20113 - acc: 0.9302 -- iter: 1376/2948
[A[ATraining Step: 509  | total loss: [1m[32m0.19734[0m[0m | time: 554.053s
[2K
| Adam | epoch: 006 | loss: 0.19734 - acc: 0.9309 -- iter: 1408/2948
[A[ATraining Step: 510  | total loss: [1m[32m0.20662[0m[0m | time: 567.206s
[2K
| Adam | epoch: 006 | loss: 0.20662 - acc: 0.9284 -- iter: 1440/2948
[A[ATraining Step: 511  | total loss: [1m[32m0.20981[0m[0m | time: 580.602s
[2K
| Adam | epoch: 006 | loss: 0.20981 - acc: 0.9231 -- iter: 1472/2948
[A[ATraining Step: 512  | total loss: [1m[32m0.19861[0m[0m | time: 594.000s
[2K
| Adam | epoch: 006 | loss: 0.19861 - acc: 0.9277 -- iter: 1504/2948
[A[ATraining Step: 513  | total loss: [1m[32m0.19351[0m[0m | time: 607.308s
[2K
| Adam | epoch: 006 | loss: 0.19351 - acc: 0.9318 -- iter: 1536/2948
[A[ATraining Step: 514  | total loss: [1m[32m0.18139[0m[0m | time: 621.072s
[2K
| Adam | epoch: 006 | loss: 0.18139 - acc: 0.9386 -- iter: 1568/2948
[A[ATraining Step: 515  | total loss: [1m[32m0.19342[0m[0m | time: 634.798s
[2K
| Adam | epoch: 006 | loss: 0.19342 - acc: 0.9354 -- iter: 1600/2948
[A[ATraining Step: 516  | total loss: [1m[32m0.19299[0m[0m | time: 648.409s
[2K
| Adam | epoch: 006 | loss: 0.19299 - acc: 0.9387 -- iter: 1632/2948
[A[ATraining Step: 517  | total loss: [1m[32m0.17967[0m[0m | time: 662.093s
[2K
| Adam | epoch: 006 | loss: 0.17967 - acc: 0.9448 -- iter: 1664/2948
[A[ATraining Step: 518  | total loss: [1m[32m0.17245[0m[0m | time: 675.511s
[2K
| Adam | epoch: 006 | loss: 0.17245 - acc: 0.9472 -- iter: 1696/2948
[A[ATraining Step: 519  | total loss: [1m[32m0.17729[0m[0m | time: 688.813s
[2K
| Adam | epoch: 006 | loss: 0.17729 - acc: 0.9400 -- iter: 1728/2948
[A[ATraining Step: 520  | total loss: [1m[32m0.17157[0m[0m | time: 702.125s
[2K
| Adam | epoch: 006 | loss: 0.17157 - acc: 0.9429 -- iter: 1760/2948
[A[ATraining Step: 521  | total loss: [1m[32m0.18680[0m[0m | time: 715.568s
[2K
| Adam | epoch: 006 | loss: 0.18680 - acc: 0.9392 -- iter: 1792/2948
[A[ATraining Step: 522  | total loss: [1m[32m0.17072[0m[0m | time: 728.807s
[2K
| Adam | epoch: 006 | loss: 0.17072 - acc: 0.9453 -- iter: 1824/2948
[A[ATraining Step: 523  | total loss: [1m[32m0.18028[0m[0m | time: 742.484s
[2K
| Adam | epoch: 006 | loss: 0.18028 - acc: 0.9414 -- iter: 1856/2948
[A[ATraining Step: 524  | total loss: [1m[32m0.17687[0m[0m | time: 756.285s
[2K
| Adam | epoch: 006 | loss: 0.17687 - acc: 0.9441 -- iter: 1888/2948
[A[ATraining Step: 525  | total loss: [1m[32m0.16998[0m[0m | time: 769.875s
[2K
| Adam | epoch: 006 | loss: 0.16998 - acc: 0.9466 -- iter: 1920/2948
[A[ATraining Step: 526  | total loss: [1m[32m0.16379[0m[0m | time: 783.614s
[2K
| Adam | epoch: 006 | loss: 0.16379 - acc: 0.9457 -- iter: 1952/2948
[A[ATraining Step: 527  | total loss: [1m[32m0.15422[0m[0m | time: 796.761s
[2K
| Adam | epoch: 006 | loss: 0.15422 - acc: 0.9480 -- iter: 1984/2948
[A[ATraining Step: 528  | total loss: [1m[32m0.15115[0m[0m | time: 810.121s
[2K
| Adam | epoch: 006 | loss: 0.15115 - acc: 0.9501 -- iter: 2016/2948
[A[ATraining Step: 529  | total loss: [1m[32m0.15364[0m[0m | time: 823.182s
[2K
| Adam | epoch: 006 | loss: 0.15364 - acc: 0.9488 -- iter: 2048/2948
[A[ATraining Step: 530  | total loss: [1m[32m0.15843[0m[0m | time: 836.275s
[2K
| Adam | epoch: 006 | loss: 0.15843 - acc: 0.9445 -- iter: 2080/2948
[A[ATraining Step: 531  | total loss: [1m[32m0.15089[0m[0m | time: 849.592s
[2K
| Adam | epoch: 006 | loss: 0.15089 - acc: 0.9470 -- iter: 2112/2948
[A[ATraining Step: 532  | total loss: [1m[32m0.14801[0m[0m | time: 863.045s
[2K
| Adam | epoch: 006 | loss: 0.14801 - acc: 0.9491 -- iter: 2144/2948
[A[ATraining Step: 533  | total loss: [1m[32m0.13790[0m[0m | time: 876.480s
[2K
| Adam | epoch: 006 | loss: 0.13790 - acc: 0.9542 -- iter: 2176/2948
[A[ATraining Step: 534  | total loss: [1m[32m0.12589[0m[0m | time: 889.559s
[2K
| Adam | epoch: 006 | loss: 0.12589 - acc: 0.9588 -- iter: 2208/2948
[A[ATraining Step: 535  | total loss: [1m[32m0.11995[0m[0m | time: 903.390s
[2K
| Adam | epoch: 006 | loss: 0.11995 - acc: 0.9598 -- iter: 2240/2948
[A[ATraining Step: 536  | total loss: [1m[32m0.11125[0m[0m | time: 917.172s
[2K
| Adam | epoch: 006 | loss: 0.11125 - acc: 0.9638 -- iter: 2272/2948
[A[ATraining Step: 537  | total loss: [1m[32m0.12971[0m[0m | time: 930.194s
[2K
| Adam | epoch: 006 | loss: 0.12971 - acc: 0.9518 -- iter: 2304/2948
[A[ATraining Step: 538  | total loss: [1m[32m0.14563[0m[0m | time: 943.754s
[2K
| Adam | epoch: 006 | loss: 0.14563 - acc: 0.9473 -- iter: 2336/2948
[A[ATraining Step: 539  | total loss: [1m[32m0.15135[0m[0m | time: 958.105s
[2K
| Adam | epoch: 006 | loss: 0.15135 - acc: 0.9432 -- iter: 2368/2948
[A[ATraining Step: 540  | total loss: [1m[32m0.16760[0m[0m | time: 971.631s
[2K
| Adam | epoch: 006 | loss: 0.16760 - acc: 0.9395 -- iter: 2400/2948
[A[ATraining Step: 541  | total loss: [1m[32m0.18472[0m[0m | time: 985.060s
[2K
| Adam | epoch: 006 | loss: 0.18472 - acc: 0.9299 -- iter: 2432/2948
[A[ATraining Step: 542  | total loss: [1m[32m0.20039[0m[0m | time: 998.608s
[2K
| Adam | epoch: 006 | loss: 0.20039 - acc: 0.9244 -- iter: 2464/2948
[A[ATraining Step: 543  | total loss: [1m[32m0.18996[0m[0m | time: 1012.000s
[2K
| Adam | epoch: 006 | loss: 0.18996 - acc: 0.9288 -- iter: 2496/2948
[A[ATraining Step: 544  | total loss: [1m[32m0.18921[0m[0m | time: 1025.627s
[2K
| Adam | epoch: 006 | loss: 0.18921 - acc: 0.9266 -- iter: 2528/2948
[A[ATraining Step: 545  | total loss: [1m[32m0.17818[0m[0m | time: 1039.445s
[2K
| Adam | epoch: 006 | loss: 0.17818 - acc: 0.9339 -- iter: 2560/2948
[A[ATraining Step: 546  | total loss: [1m[32m0.16585[0m[0m | time: 1053.102s
[2K
| Adam | epoch: 006 | loss: 0.16585 - acc: 0.9405 -- iter: 2592/2948
[A[ATraining Step: 547  | total loss: [1m[32m0.17767[0m[0m | time: 1066.242s
[2K
| Adam | epoch: 006 | loss: 0.17767 - acc: 0.9371 -- iter: 2624/2948
[A[ATraining Step: 548  | total loss: [1m[32m0.17005[0m[0m | time: 1079.704s
[2K
| Adam | epoch: 006 | loss: 0.17005 - acc: 0.9403 -- iter: 2656/2948
[A[ATraining Step: 549  | total loss: [1m[32m0.17208[0m[0m | time: 1093.207s
[2K
| Adam | epoch: 006 | loss: 0.17208 - acc: 0.9369 -- iter: 2688/2948
[A[ATraining Step: 550  | total loss: [1m[32m0.15930[0m[0m | time: 1106.773s
[2K
| Adam | epoch: 006 | loss: 0.15930 - acc: 0.9432 -- iter: 2720/2948
[A[ATraining Step: 551  | total loss: [1m[32m0.15734[0m[0m | time: 1120.591s
[2K
| Adam | epoch: 006 | loss: 0.15734 - acc: 0.9395 -- iter: 2752/2948
[A[ATraining Step: 552  | total loss: [1m[32m0.15262[0m[0m | time: 1134.181s
[2K
| Adam | epoch: 006 | loss: 0.15262 - acc: 0.9393 -- iter: 2784/2948
[A[ATraining Step: 553  | total loss: [1m[32m0.15977[0m[0m | time: 1147.665s
[2K
| Adam | epoch: 006 | loss: 0.15977 - acc: 0.9422 -- iter: 2816/2948
[A[ATraining Step: 554  | total loss: [1m[32m0.16177[0m[0m | time: 1160.985s
[2K
| Adam | epoch: 006 | loss: 0.16177 - acc: 0.9449 -- iter: 2848/2948
[A[ATraining Step: 555  | total loss: [1m[32m0.14941[0m[0m | time: 1174.538s
[2K
| Adam | epoch: 006 | loss: 0.14941 - acc: 0.9504 -- iter: 2880/2948
[A[ATraining Step: 556  | total loss: [1m[32m0.13697[0m[0m | time: 1188.201s
[2K
| Adam | epoch: 006 | loss: 0.13697 - acc: 0.9554 -- iter: 2912/2948
[A[ATraining Step: 557  | total loss: [1m[32m0.12815[0m[0m | time: 1201.745s
[2K
| Adam | epoch: 006 | loss: 0.12815 - acc: 0.9567 -- iter: 2944/2948
[A[ATraining Step: 558  | total loss: [1m[32m0.13561[0m[0m | time: 1284.237s
[2K
| Adam | epoch: 006 | loss: 0.13561 - acc: 0.9548 | val_loss: 0.26042 - val_acc: 0.8980 -- iter: 2948/2948
--
Training Step: 559  | total loss: [1m[32m0.13887[0m[0m | time: 8.532s
[2K
| Adam | epoch: 007 | loss: 0.13887 - acc: 0.9468 -- iter: 0032/2948
[A[ATraining Step: 560  | total loss: [1m[32m0.14397[0m[0m | time: 16.803s
[2K
| Adam | epoch: 007 | loss: 0.14397 - acc: 0.9427 -- iter: 0064/2948
[A[ATraining Step: 561  | total loss: [1m[32m0.13641[0m[0m | time: 27.725s
[2K
| Adam | epoch: 007 | loss: 0.13641 - acc: 0.9453 -- iter: 0096/2948
[A[ATraining Step: 562  | total loss: [1m[32m0.14073[0m[0m | time: 40.679s
[2K
| Adam | epoch: 007 | loss: 0.14073 - acc: 0.9446 -- iter: 0128/2948
[A[ATraining Step: 563  | total loss: [1m[32m0.14461[0m[0m | time: 43.603s
[2K
| Adam | epoch: 007 | loss: 0.14461 - acc: 0.9439 -- iter: 0160/2948
[A[ATraining Step: 564  | total loss: [1m[32m0.13078[0m[0m | time: 46.738s
[2K
| Adam | epoch: 007 | loss: 0.13078 - acc: 0.9495 -- iter: 0192/2948
[A[ATraining Step: 565  | total loss: [1m[32m0.11807[0m[0m | time: 59.378s
[2K
| Adam | epoch: 007 | loss: 0.11807 - acc: 0.9545 -- iter: 0224/2948
[A[ATraining Step: 566  | total loss: [1m[32m0.12416[0m[0m | time: 72.258s
[2K
| Adam | epoch: 007 | loss: 0.12416 - acc: 0.9497 -- iter: 0256/2948
[A[ATraining Step: 567  | total loss: [1m[32m0.12865[0m[0m | time: 84.961s
[2K
| Adam | epoch: 007 | loss: 0.12865 - acc: 0.9454 -- iter: 0288/2948
[A[ATraining Step: 568  | total loss: [1m[32m0.12931[0m[0m | time: 97.913s
[2K
| Adam | epoch: 007 | loss: 0.12931 - acc: 0.9477 -- iter: 0320/2948
[A[ATraining Step: 569  | total loss: [1m[32m0.14177[0m[0m | time: 110.985s
[2K
| Adam | epoch: 007 | loss: 0.14177 - acc: 0.9435 -- iter: 0352/2948
[A[ATraining Step: 570  | total loss: [1m[32m0.13542[0m[0m | time: 124.173s
[2K
| Adam | epoch: 007 | loss: 0.13542 - acc: 0.9461 -- iter: 0384/2948
[A[ATraining Step: 571  | total loss: [1m[32m0.15115[0m[0m | time: 137.320s
[2K
| Adam | epoch: 007 | loss: 0.15115 - acc: 0.9421 -- iter: 0416/2948
[A[ATraining Step: 572  | total loss: [1m[32m0.15628[0m[0m | time: 150.275s
[2K
| Adam | epoch: 007 | loss: 0.15628 - acc: 0.9385 -- iter: 0448/2948
[A[ATraining Step: 573  | total loss: [1m[32m0.15110[0m[0m | time: 163.434s
[2K
| Adam | epoch: 007 | loss: 0.15110 - acc: 0.9415 -- iter: 0480/2948
[A[ATraining Step: 574  | total loss: [1m[32m0.15644[0m[0m | time: 176.545s
[2K
| Adam | epoch: 007 | loss: 0.15644 - acc: 0.9411 -- iter: 0512/2948
[A[ATraining Step: 575  | total loss: [1m[32m0.15574[0m[0m | time: 189.311s
[2K
| Adam | epoch: 007 | loss: 0.15574 - acc: 0.9439 -- iter: 0544/2948
[A[ATraining Step: 576  | total loss: [1m[32m0.18224[0m[0m | time: 202.953s
[2K
| Adam | epoch: 007 | loss: 0.18224 - acc: 0.9370 -- iter: 0576/2948
[A[ATraining Step: 577  | total loss: [1m[32m0.17366[0m[0m | time: 216.800s
[2K
| Adam | epoch: 007 | loss: 0.17366 - acc: 0.9402 -- iter: 0608/2948
[A[ATraining Step: 578  | total loss: [1m[32m0.18032[0m[0m | time: 230.613s
[2K
| Adam | epoch: 007 | loss: 0.18032 - acc: 0.9337 -- iter: 0640/2948
[A[ATraining Step: 579  | total loss: [1m[32m0.17466[0m[0m | time: 244.183s
[2K
| Adam | epoch: 007 | loss: 0.17466 - acc: 0.9372 -- iter: 0672/2948
[A[ATraining Step: 580  | total loss: [1m[32m0.17036[0m[0m | time: 257.341s
[2K
| Adam | epoch: 007 | loss: 0.17036 - acc: 0.9372 -- iter: 0704/2948
[A[ATraining Step: 581  | total loss: [1m[32m0.15843[0m[0m | time: 270.568s
[2K
| Adam | epoch: 007 | loss: 0.15843 - acc: 0.9435 -- iter: 0736/2948
[A[ATraining Step: 582  | total loss: [1m[32m0.14407[0m[0m | time: 284.142s
[2K
| Adam | epoch: 007 | loss: 0.14407 - acc: 0.9491 -- iter: 0768/2948
[A[ATraining Step: 583  | total loss: [1m[32m0.15924[0m[0m | time: 297.495s
[2K
| Adam | epoch: 007 | loss: 0.15924 - acc: 0.9448 -- iter: 0800/2948
[A[ATraining Step: 584  | total loss: [1m[32m0.15934[0m[0m | time: 310.974s
[2K
| Adam | epoch: 007 | loss: 0.15934 - acc: 0.9441 -- iter: 0832/2948
[A[ATraining Step: 585  | total loss: [1m[32m0.14953[0m[0m | time: 324.208s
[2K
| Adam | epoch: 007 | loss: 0.14953 - acc: 0.9497 -- iter: 0864/2948
[A[ATraining Step: 586  | total loss: [1m[32m0.17500[0m[0m | time: 337.846s
[2K
| Adam | epoch: 007 | loss: 0.17500 - acc: 0.9391 -- iter: 0896/2948
[A[ATraining Step: 587  | total loss: [1m[32m0.16490[0m[0m | time: 351.067s
[2K
| Adam | epoch: 007 | loss: 0.16490 - acc: 0.9452 -- iter: 0928/2948
[A[ATraining Step: 588  | total loss: [1m[32m0.16450[0m[0m | time: 364.286s
[2K
| Adam | epoch: 007 | loss: 0.16450 - acc: 0.9382 -- iter: 0960/2948
[A[ATraining Step: 589  | total loss: [1m[32m0.16637[0m[0m | time: 377.971s
[2K
| Adam | epoch: 007 | loss: 0.16637 - acc: 0.9381 -- iter: 0992/2948
[A[ATraining Step: 590  | total loss: [1m[32m0.15923[0m[0m | time: 391.426s
[2K
| Adam | epoch: 007 | loss: 0.15923 - acc: 0.9349 -- iter: 1024/2948
[A[ATraining Step: 591  | total loss: [1m[32m0.15399[0m[0m | time: 405.001s
[2K
| Adam | epoch: 007 | loss: 0.15399 - acc: 0.9414 -- iter: 1056/2948
[A[ATraining Step: 592  | total loss: [1m[32m0.14884[0m[0m | time: 418.819s
[2K
| Adam | epoch: 007 | loss: 0.14884 - acc: 0.9410 -- iter: 1088/2948
[A[ATraining Step: 593  | total loss: [1m[32m0.14241[0m[0m | time: 432.714s
[2K
| Adam | epoch: 007 | loss: 0.14241 - acc: 0.9438 -- iter: 1120/2948
[A[ATraining Step: 594  | total loss: [1m[32m0.14553[0m[0m | time: 445.808s
[2K
| Adam | epoch: 007 | loss: 0.14553 - acc: 0.9432 -- iter: 1152/2948
[A[ATraining Step: 595  | total loss: [1m[32m0.13916[0m[0m | time: 459.359s
[2K
| Adam | epoch: 007 | loss: 0.13916 - acc: 0.9457 -- iter: 1184/2948
[A[ATraining Step: 596  | total loss: [1m[32m0.13373[0m[0m | time: 473.050s
[2K
| Adam | epoch: 007 | loss: 0.13373 - acc: 0.9480 -- iter: 1216/2948
[A[ATraining Step: 597  | total loss: [1m[32m0.12791[0m[0m | time: 486.489s
[2K
| Adam | epoch: 007 | loss: 0.12791 - acc: 0.9470 -- iter: 1248/2948
[A[ATraining Step: 598  | total loss: [1m[32m0.13122[0m[0m | time: 499.707s
[2K
| Adam | epoch: 007 | loss: 0.13122 - acc: 0.9460 -- iter: 1280/2948
[A[ATraining Step: 599  | total loss: [1m[32m0.13009[0m[0m | time: 513.158s
[2K
| Adam | epoch: 007 | loss: 0.13009 - acc: 0.9452 -- iter: 1312/2948
[A[ATraining Step: 600  | total loss: [1m[32m0.13339[0m[0m | time: 596.700s
[2K
| Adam | epoch: 007 | loss: 0.13339 - acc: 0.9475 | val_loss: 0.54791 - val_acc: 0.8308 -- iter: 1344/2948
--
Training Step: 601  | total loss: [1m[32m0.13469[0m[0m | time: 611.022s
[2K
| Adam | epoch: 007 | loss: 0.13469 - acc: 0.9497 -- iter: 1376/2948
[A[ATraining Step: 602  | total loss: [1m[32m0.14924[0m[0m | time: 622.150s
[2K
| Adam | epoch: 007 | loss: 0.14924 - acc: 0.9453 -- iter: 1408/2948
[A[ATraining Step: 603  | total loss: [1m[32m0.14256[0m[0m | time: 630.724s
[2K
| Adam | epoch: 007 | loss: 0.14256 - acc: 0.9508 -- iter: 1440/2948
[A[ATraining Step: 604  | total loss: [1m[32m0.14903[0m[0m | time: 641.983s
[2K
| Adam | epoch: 007 | loss: 0.14903 - acc: 0.9495 -- iter: 1472/2948
[A[ATraining Step: 605  | total loss: [1m[32m0.14454[0m[0m | time: 655.407s
[2K
| Adam | epoch: 007 | loss: 0.14454 - acc: 0.9483 -- iter: 1504/2948
[A[ATraining Step: 606  | total loss: [1m[32m0.14883[0m[0m | time: 668.908s
[2K
| Adam | epoch: 007 | loss: 0.14883 - acc: 0.9472 -- iter: 1536/2948
[A[ATraining Step: 607  | total loss: [1m[32m0.13931[0m[0m | time: 682.377s
[2K
| Adam | epoch: 007 | loss: 0.13931 - acc: 0.9525 -- iter: 1568/2948
[A[ATraining Step: 608  | total loss: [1m[32m0.13531[0m[0m | time: 695.663s
[2K
| Adam | epoch: 007 | loss: 0.13531 - acc: 0.9541 -- iter: 1600/2948
[A[ATraining Step: 609  | total loss: [1m[32m0.14316[0m[0m | time: 708.912s
[2K
| Adam | epoch: 007 | loss: 0.14316 - acc: 0.9524 -- iter: 1632/2948
[A[ATraining Step: 610  | total loss: [1m[32m0.15365[0m[0m | time: 722.498s
[2K
| Adam | epoch: 007 | loss: 0.15365 - acc: 0.9509 -- iter: 1664/2948
[A[ATraining Step: 611  | total loss: [1m[32m0.14662[0m[0m | time: 735.842s
[2K
| Adam | epoch: 007 | loss: 0.14662 - acc: 0.9527 -- iter: 1696/2948
[A[ATraining Step: 612  | total loss: [1m[32m0.17002[0m[0m | time: 749.262s
[2K
| Adam | epoch: 007 | loss: 0.17002 - acc: 0.9512 -- iter: 1728/2948
[A[ATraining Step: 613  | total loss: [1m[32m0.17567[0m[0m | time: 762.693s
[2K
| Adam | epoch: 007 | loss: 0.17567 - acc: 0.9498 -- iter: 1760/2948
[A[ATraining Step: 614  | total loss: [1m[32m0.16450[0m[0m | time: 775.849s
[2K
| Adam | epoch: 007 | loss: 0.16450 - acc: 0.9517 -- iter: 1792/2948
[A[ATraining Step: 615  | total loss: [1m[32m0.15344[0m[0m | time: 788.783s
[2K
| Adam | epoch: 007 | loss: 0.15344 - acc: 0.9566 -- iter: 1824/2948
[A[ATraining Step: 616  | total loss: [1m[32m0.14330[0m[0m | time: 801.805s
[2K
| Adam | epoch: 007 | loss: 0.14330 - acc: 0.9609 -- iter: 1856/2948
[A[ATraining Step: 617  | total loss: [1m[32m0.14558[0m[0m | time: 815.021s
[2K
| Adam | epoch: 007 | loss: 0.14558 - acc: 0.9586 -- iter: 1888/2948
[A[ATraining Step: 618  | total loss: [1m[32m0.14413[0m[0m | time: 828.486s
[2K
| Adam | epoch: 007 | loss: 0.14413 - acc: 0.9533 -- iter: 1920/2948
[A[ATraining Step: 619  | total loss: [1m[32m0.13846[0m[0m | time: 842.544s
[2K
| Adam | epoch: 007 | loss: 0.13846 - acc: 0.9549 -- iter: 1952/2948
[A[ATraining Step: 620  | total loss: [1m[32m0.13046[0m[0m | time: 855.863s
[2K
| Adam | epoch: 007 | loss: 0.13046 - acc: 0.9594 -- iter: 1984/2948
[A[ATraining Step: 621  | total loss: [1m[32m0.11990[0m[0m | time: 869.777s
[2K
| Adam | epoch: 007 | loss: 0.11990 - acc: 0.9634 -- iter: 2016/2948
[A[ATraining Step: 622  | total loss: [1m[32m0.12145[0m[0m | time: 883.352s
[2K
| Adam | epoch: 007 | loss: 0.12145 - acc: 0.9640 -- iter: 2048/2948
[A[ATraining Step: 623  | total loss: [1m[32m0.11364[0m[0m | time: 896.888s
[2K
| Adam | epoch: 007 | loss: 0.11364 - acc: 0.9676 -- iter: 2080/2948
[A[ATraining Step: 624  | total loss: [1m[32m0.12692[0m[0m | time: 910.500s
[2K
| Adam | epoch: 007 | loss: 0.12692 - acc: 0.9646 -- iter: 2112/2948
[A[ATraining Step: 625  | total loss: [1m[32m0.11810[0m[0m | time: 923.659s
[2K
| Adam | epoch: 007 | loss: 0.11810 - acc: 0.9681 -- iter: 2144/2948
[A[ATraining Step: 626  | total loss: [1m[32m0.11290[0m[0m | time: 936.901s
[2K
| Adam | epoch: 007 | loss: 0.11290 - acc: 0.9682 -- iter: 2176/2948
[A[ATraining Step: 627  | total loss: [1m[32m0.10445[0m[0m | time: 950.237s
[2K
| Adam | epoch: 007 | loss: 0.10445 - acc: 0.9714 -- iter: 2208/2948
[A[ATraining Step: 628  | total loss: [1m[32m0.10749[0m[0m | time: 963.803s
[2K
| Adam | epoch: 007 | loss: 0.10749 - acc: 0.9680 -- iter: 2240/2948
[A[ATraining Step: 629  | total loss: [1m[32m0.09934[0m[0m | time: 977.388s
[2K
| Adam | epoch: 007 | loss: 0.09934 - acc: 0.9712 -- iter: 2272/2948
[A[ATraining Step: 630  | total loss: [1m[32m0.10262[0m[0m | time: 990.726s
[2K
| Adam | epoch: 007 | loss: 0.10262 - acc: 0.9678 -- iter: 2304/2948
[A[ATraining Step: 631  | total loss: [1m[32m0.09808[0m[0m | time: 1004.054s
[2K
| Adam | epoch: 007 | loss: 0.09808 - acc: 0.9679 -- iter: 2336/2948
[A[ATraining Step: 632  | total loss: [1m[32m0.09662[0m[0m | time: 1017.017s
[2K
| Adam | epoch: 007 | loss: 0.09662 - acc: 0.9680 -- iter: 2368/2948
[A[ATraining Step: 633  | total loss: [1m[32m0.09680[0m[0m | time: 1030.230s
[2K
| Adam | epoch: 007 | loss: 0.09680 - acc: 0.9681 -- iter: 2400/2948
[A[ATraining Step: 634  | total loss: [1m[32m0.09235[0m[0m | time: 1043.446s
[2K
| Adam | epoch: 007 | loss: 0.09235 - acc: 0.9681 -- iter: 2432/2948
[A[ATraining Step: 635  | total loss: [1m[32m0.08879[0m[0m | time: 1056.739s
[2K
| Adam | epoch: 007 | loss: 0.08879 - acc: 0.9682 -- iter: 2464/2948
[A[ATraining Step: 636  | total loss: [1m[32m0.09133[0m[0m | time: 1069.721s
[2K
| Adam | epoch: 007 | loss: 0.09133 - acc: 0.9682 -- iter: 2496/2948
[A[ATraining Step: 637  | total loss: [1m[32m0.09225[0m[0m | time: 1082.718s
[2K
| Adam | epoch: 007 | loss: 0.09225 - acc: 0.9652 -- iter: 2528/2948
[A[ATraining Step: 638  | total loss: [1m[32m0.08767[0m[0m | time: 1095.700s
[2K
| Adam | epoch: 007 | loss: 0.08767 - acc: 0.9687 -- iter: 2560/2948
[A[ATraining Step: 639  | total loss: [1m[32m0.08378[0m[0m | time: 1109.116s
[2K
| Adam | epoch: 007 | loss: 0.08378 - acc: 0.9718 -- iter: 2592/2948
[A[ATraining Step: 640  | total loss: [1m[32m0.08274[0m[0m | time: 1122.370s
[2K
| Adam | epoch: 007 | loss: 0.08274 - acc: 0.9684 -- iter: 2624/2948
[A[ATraining Step: 641  | total loss: [1m[32m0.08108[0m[0m | time: 1135.534s
[2K
| Adam | epoch: 007 | loss: 0.08108 - acc: 0.9684 -- iter: 2656/2948
[A[ATraining Step: 642  | total loss: [1m[32m0.08581[0m[0m | time: 1148.957s
[2K
| Adam | epoch: 007 | loss: 0.08581 - acc: 0.9684 -- iter: 2688/2948
[A[ATraining Step: 643  | total loss: [1m[32m0.08204[0m[0m | time: 1162.300s
[2K
| Adam | epoch: 007 | loss: 0.08204 - acc: 0.9716 -- iter: 2720/2948
[A[ATraining Step: 644  | total loss: [1m[32m0.09403[0m[0m | time: 1175.505s
[2K
| Adam | epoch: 007 | loss: 0.09403 - acc: 0.9651 -- iter: 2752/2948
[A[ATraining Step: 645  | total loss: [1m[32m0.08982[0m[0m | time: 1188.550s
[2K
| Adam | epoch: 007 | loss: 0.08982 - acc: 0.9654 -- iter: 2784/2948
[A[ATraining Step: 646  | total loss: [1m[32m0.11923[0m[0m | time: 1201.854s
[2K
| Adam | epoch: 007 | loss: 0.11923 - acc: 0.9658 -- iter: 2816/2948
[A[ATraining Step: 647  | total loss: [1m[32m0.12180[0m[0m | time: 1214.830s
[2K
| Adam | epoch: 007 | loss: 0.12180 - acc: 0.9598 -- iter: 2848/2948
[A[ATraining Step: 648  | total loss: [1m[32m0.11491[0m[0m | time: 1228.131s
[2K
| Adam | epoch: 007 | loss: 0.11491 - acc: 0.9638 -- iter: 2880/2948
[A[ATraining Step: 649  | total loss: [1m[32m0.10669[0m[0m | time: 1241.346s
[2K
| Adam | epoch: 007 | loss: 0.10669 - acc: 0.9674 -- iter: 2912/2948
[A[ATraining Step: 650  | total loss: [1m[32m0.10385[0m[0m | time: 1254.676s
[2K
| Adam | epoch: 007 | loss: 0.10385 - acc: 0.9676 -- iter: 2944/2948
[A[ATraining Step: 651  | total loss: [1m[32m0.09619[0m[0m | time: 1337.960s
[2K
| Adam | epoch: 007 | loss: 0.09619 - acc: 0.9708 | val_loss: 6.90504 - val_acc: 0.5011 -- iter: 2948/2948
--
Training Step: 652  | total loss: [1m[32m0.11340[0m[0m | time: 8.270s
[2K
| Adam | epoch: 008 | loss: 0.11340 - acc: 0.9644 -- iter: 0032/2948
[A[ATraining Step: 653  | total loss: [1m[32m0.10457[0m[0m | time: 17.143s
[2K
| Adam | epoch: 008 | loss: 0.10457 - acc: 0.9679 -- iter: 0064/2948
[A[ATraining Step: 654  | total loss: [1m[32m0.12593[0m[0m | time: 30.228s
[2K
| Adam | epoch: 008 | loss: 0.12593 - acc: 0.9649 -- iter: 0096/2948
[A[ATraining Step: 655  | total loss: [1m[32m0.11810[0m[0m | time: 43.125s
[2K
| Adam | epoch: 008 | loss: 0.11810 - acc: 0.9684 -- iter: 0128/2948
[A[ATraining Step: 656  | total loss: [1m[32m0.11314[0m[0m | time: 56.709s
[2K
| Adam | epoch: 008 | loss: 0.11314 - acc: 0.9716 -- iter: 0160/2948
[A[ATraining Step: 657  | total loss: [1m[32m0.10591[0m[0m | time: 60.351s
[2K
| Adam | epoch: 008 | loss: 0.10591 - acc: 0.9744 -- iter: 0192/2948
[A[ATraining Step: 658  | total loss: [1m[32m0.11721[0m[0m | time: 63.208s
[2K
| Adam | epoch: 008 | loss: 0.11721 - acc: 0.9520 -- iter: 0224/2948
[A[ATraining Step: 659  | total loss: [1m[32m0.10802[0m[0m | time: 76.650s
[2K
| Adam | epoch: 008 | loss: 0.10802 - acc: 0.9568 -- iter: 0256/2948
[A[ATraining Step: 660  | total loss: [1m[32m0.10088[0m[0m | time: 90.021s
[2K
| Adam | epoch: 008 | loss: 0.10088 - acc: 0.9611 -- iter: 0288/2948
[A[ATraining Step: 661  | total loss: [1m[32m0.10762[0m[0m | time: 103.232s
[2K
| Adam | epoch: 008 | loss: 0.10762 - acc: 0.9587 -- iter: 0320/2948
[A[ATraining Step: 662  | total loss: [1m[32m0.09837[0m[0m | time: 116.333s
[2K
| Adam | epoch: 008 | loss: 0.09837 - acc: 0.9629 -- iter: 0352/2948
[A[ATraining Step: 663  | total loss: [1m[32m0.09395[0m[0m | time: 129.850s
[2K
| Adam | epoch: 008 | loss: 0.09395 - acc: 0.9666 -- iter: 0384/2948
[A[ATraining Step: 664  | total loss: [1m[32m0.10942[0m[0m | time: 143.256s
[2K
| Adam | epoch: 008 | loss: 0.10942 - acc: 0.9574 -- iter: 0416/2948
[A[ATraining Step: 665  | total loss: [1m[32m0.11317[0m[0m | time: 156.189s
[2K
| Adam | epoch: 008 | loss: 0.11317 - acc: 0.9585 -- iter: 0448/2948
[A[ATraining Step: 666  | total loss: [1m[32m0.11023[0m[0m | time: 169.369s
[2K
| Adam | epoch: 008 | loss: 0.11023 - acc: 0.9596 -- iter: 0480/2948
[A[ATraining Step: 667  | total loss: [1m[32m0.10772[0m[0m | time: 182.728s
[2K
| Adam | epoch: 008 | loss: 0.10772 - acc: 0.9605 -- iter: 0512/2948
[A[ATraining Step: 668  | total loss: [1m[32m0.10448[0m[0m | time: 195.650s
[2K
| Adam | epoch: 008 | loss: 0.10448 - acc: 0.9644 -- iter: 0544/2948
[A[ATraining Step: 669  | total loss: [1m[32m0.13125[0m[0m | time: 208.399s
[2K
| Adam | epoch: 008 | loss: 0.13125 - acc: 0.9492 -- iter: 0576/2948
[A[ATraining Step: 670  | total loss: [1m[32m0.13983[0m[0m | time: 222.037s
[2K
| Adam | epoch: 008 | loss: 0.13983 - acc: 0.9449 -- iter: 0608/2948
[A[ATraining Step: 671  | total loss: [1m[32m0.13414[0m[0m | time: 235.066s
[2K
| Adam | epoch: 008 | loss: 0.13414 - acc: 0.9473 -- iter: 0640/2948
[A[ATraining Step: 672  | total loss: [1m[32m0.14474[0m[0m | time: 248.162s
[2K
| Adam | epoch: 008 | loss: 0.14474 - acc: 0.9495 -- iter: 0672/2948
[A[ATraining Step: 673  | total loss: [1m[32m0.15763[0m[0m | time: 261.548s
[2K
| Adam | epoch: 008 | loss: 0.15763 - acc: 0.9451 -- iter: 0704/2948
[A[ATraining Step: 674  | total loss: [1m[32m0.15767[0m[0m | time: 275.009s
[2K
| Adam | epoch: 008 | loss: 0.15767 - acc: 0.9444 -- iter: 0736/2948
[A[ATraining Step: 675  | total loss: [1m[32m0.14847[0m[0m | time: 287.941s
[2K
| Adam | epoch: 008 | loss: 0.14847 - acc: 0.9468 -- iter: 0768/2948
[A[ATraining Step: 676  | total loss: [1m[32m0.14707[0m[0m | time: 300.951s
[2K
| Adam | epoch: 008 | loss: 0.14707 - acc: 0.9459 -- iter: 0800/2948
[A[ATraining Step: 677  | total loss: [1m[32m0.15033[0m[0m | time: 313.987s
[2K
| Adam | epoch: 008 | loss: 0.15033 - acc: 0.9419 -- iter: 0832/2948
[A[ATraining Step: 678  | total loss: [1m[32m0.16160[0m[0m | time: 327.038s
[2K
| Adam | epoch: 008 | loss: 0.16160 - acc: 0.9384 -- iter: 0864/2948
[A[ATraining Step: 679  | total loss: [1m[32m0.15508[0m[0m | time: 340.679s
[2K
| Adam | epoch: 008 | loss: 0.15508 - acc: 0.9383 -- iter: 0896/2948
[A[ATraining Step: 680  | total loss: [1m[32m0.14174[0m[0m | time: 354.047s
[2K
| Adam | epoch: 008 | loss: 0.14174 - acc: 0.9444 -- iter: 0928/2948
[A[ATraining Step: 681  | total loss: [1m[32m0.13355[0m[0m | time: 367.370s
[2K
| Adam | epoch: 008 | loss: 0.13355 - acc: 0.9469 -- iter: 0960/2948
[A[ATraining Step: 682  | total loss: [1m[32m0.16138[0m[0m | time: 380.824s
[2K
| Adam | epoch: 008 | loss: 0.16138 - acc: 0.9459 -- iter: 0992/2948
[A[ATraining Step: 683  | total loss: [1m[32m0.16198[0m[0m | time: 394.989s
[2K
| Adam | epoch: 008 | loss: 0.16198 - acc: 0.9451 -- iter: 1024/2948
[A[ATraining Step: 684  | total loss: [1m[32m0.16536[0m[0m | time: 408.387s
[2K
| Adam | epoch: 008 | loss: 0.16536 - acc: 0.9475 -- iter: 1056/2948
[A[ATraining Step: 685  | total loss: [1m[32m0.17238[0m[0m | time: 421.960s
[2K
| Adam | epoch: 008 | loss: 0.17238 - acc: 0.9465 -- iter: 1088/2948
[A[ATraining Step: 686  | total loss: [1m[32m0.16498[0m[0m | time: 435.389s
[2K
| Adam | epoch: 008 | loss: 0.16498 - acc: 0.9456 -- iter: 1120/2948
[A[ATraining Step: 687  | total loss: [1m[32m0.15702[0m[0m | time: 448.303s
[2K
| Adam | epoch: 008 | loss: 0.15702 - acc: 0.9479 -- iter: 1152/2948
[A[ATraining Step: 688  | total loss: [1m[32m0.15319[0m[0m | time: 461.726s
[2K
| Adam | epoch: 008 | loss: 0.15319 - acc: 0.9500 -- iter: 1184/2948
[A[ATraining Step: 689  | total loss: [1m[32m0.14912[0m[0m | time: 475.013s
[2K
| Adam | epoch: 008 | loss: 0.14912 - acc: 0.9518 -- iter: 1216/2948
[A[ATraining Step: 690  | total loss: [1m[32m0.13851[0m[0m | time: 488.757s
[2K
| Adam | epoch: 008 | loss: 0.13851 - acc: 0.9567 -- iter: 1248/2948
[A[ATraining Step: 691  | total loss: [1m[32m0.15079[0m[0m | time: 502.392s
[2K
| Adam | epoch: 008 | loss: 0.15079 - acc: 0.9516 -- iter: 1280/2948
[A[ATraining Step: 692  | total loss: [1m[32m0.16382[0m[0m | time: 515.857s
[2K
| Adam | epoch: 008 | loss: 0.16382 - acc: 0.9471 -- iter: 1312/2948
[A[ATraining Step: 693  | total loss: [1m[32m0.15705[0m[0m | time: 528.883s
[2K
| Adam | epoch: 008 | loss: 0.15705 - acc: 0.9461 -- iter: 1344/2948
[A[ATraining Step: 694  | total loss: [1m[32m0.15328[0m[0m | time: 542.373s
[2K
| Adam | epoch: 008 | loss: 0.15328 - acc: 0.9453 -- iter: 1376/2948
[A[ATraining Step: 695  | total loss: [1m[32m0.17127[0m[0m | time: 555.974s
[2K
| Adam | epoch: 008 | loss: 0.17127 - acc: 0.9414 -- iter: 1408/2948
[A[ATraining Step: 696  | total loss: [1m[32m0.15742[0m[0m | time: 569.616s
[2K
| Adam | epoch: 008 | loss: 0.15742 - acc: 0.9472 -- iter: 1440/2948
[A[ATraining Step: 697  | total loss: [1m[32m0.14884[0m[0m | time: 583.190s
[2K
| Adam | epoch: 008 | loss: 0.14884 - acc: 0.9525 -- iter: 1472/2948
[A[ATraining Step: 698  | total loss: [1m[32m0.15753[0m[0m | time: 596.590s
[2K
| Adam | epoch: 008 | loss: 0.15753 - acc: 0.9510 -- iter: 1504/2948
[A[ATraining Step: 699  | total loss: [1m[32m0.14823[0m[0m | time: 610.168s
[2K
| Adam | epoch: 008 | loss: 0.14823 - acc: 0.9528 -- iter: 1536/2948
[A[ATraining Step: 700  | total loss: [1m[32m0.14453[0m[0m | time: 623.588s
[2K
| Adam | epoch: 008 | loss: 0.14453 - acc: 0.9544 -- iter: 1568/2948
[A[ATraining Step: 701  | total loss: [1m[32m0.13460[0m[0m | time: 637.114s
[2K
| Adam | epoch: 008 | loss: 0.13460 - acc: 0.9589 -- iter: 1600/2948
[A[ATraining Step: 702  | total loss: [1m[32m0.14405[0m[0m | time: 650.262s
[2K
| Adam | epoch: 008 | loss: 0.14405 - acc: 0.9537 -- iter: 1632/2948
[A[ATraining Step: 703  | total loss: [1m[32m0.13865[0m[0m | time: 663.786s
[2K
| Adam | epoch: 008 | loss: 0.13865 - acc: 0.9552 -- iter: 1664/2948
[A[ATraining Step: 704  | total loss: [1m[32m0.14031[0m[0m | time: 676.815s
[2K
| Adam | epoch: 008 | loss: 0.14031 - acc: 0.9534 -- iter: 1696/2948
[A[ATraining Step: 705  | total loss: [1m[32m0.14001[0m[0m | time: 690.320s
[2K
| Adam | epoch: 008 | loss: 0.14001 - acc: 0.9549 -- iter: 1728/2948
[A[ATraining Step: 706  | total loss: [1m[32m0.13788[0m[0m | time: 703.772s
[2K
| Adam | epoch: 008 | loss: 0.13788 - acc: 0.9532 -- iter: 1760/2948
[A[ATraining Step: 707  | total loss: [1m[32m0.12854[0m[0m | time: 717.183s
[2K
| Adam | epoch: 008 | loss: 0.12854 - acc: 0.9579 -- iter: 1792/2948
[A[ATraining Step: 708  | total loss: [1m[32m0.11818[0m[0m | time: 730.700s
[2K
| Adam | epoch: 008 | loss: 0.11818 - acc: 0.9621 -- iter: 1824/2948
[A[ATraining Step: 709  | total loss: [1m[32m0.10919[0m[0m | time: 743.904s
[2K
| Adam | epoch: 008 | loss: 0.10919 - acc: 0.9659 -- iter: 1856/2948
[A[ATraining Step: 710  | total loss: [1m[32m0.10753[0m[0m | time: 757.532s
[2K
| Adam | epoch: 008 | loss: 0.10753 - acc: 0.9630 -- iter: 1888/2948
[A[ATraining Step: 711  | total loss: [1m[32m0.10260[0m[0m | time: 770.564s
[2K
| Adam | epoch: 008 | loss: 0.10260 - acc: 0.9667 -- iter: 1920/2948
[A[ATraining Step: 712  | total loss: [1m[32m0.11940[0m[0m | time: 783.465s
[2K
| Adam | epoch: 008 | loss: 0.11940 - acc: 0.9576 -- iter: 1952/2948
[A[ATraining Step: 713  | total loss: [1m[32m0.13038[0m[0m | time: 796.747s
[2K
| Adam | epoch: 008 | loss: 0.13038 - acc: 0.9524 -- iter: 1984/2948
[A[ATraining Step: 714  | total loss: [1m[32m0.13641[0m[0m | time: 809.831s
[2K
| Adam | epoch: 008 | loss: 0.13641 - acc: 0.9478 -- iter: 2016/2948
[A[ATraining Step: 715  | total loss: [1m[32m0.13821[0m[0m | time: 822.807s
[2K
| Adam | epoch: 008 | loss: 0.13821 - acc: 0.9437 -- iter: 2048/2948
[A[ATraining Step: 716  | total loss: [1m[32m0.14643[0m[0m | time: 835.743s
[2K
| Adam | epoch: 008 | loss: 0.14643 - acc: 0.9399 -- iter: 2080/2948
[A[ATraining Step: 717  | total loss: [1m[32m0.15545[0m[0m | time: 848.929s
[2K
| Adam | epoch: 008 | loss: 0.15545 - acc: 0.9397 -- iter: 2112/2948
[A[ATraining Step: 718  | total loss: [1m[32m0.16090[0m[0m | time: 862.186s
[2K
| Adam | epoch: 008 | loss: 0.16090 - acc: 0.9301 -- iter: 2144/2948
[A[ATraining Step: 719  | total loss: [1m[32m0.15878[0m[0m | time: 875.767s
[2K
| Adam | epoch: 008 | loss: 0.15878 - acc: 0.9340 -- iter: 2176/2948
[A[ATraining Step: 720  | total loss: [1m[32m0.18164[0m[0m | time: 889.396s
[2K
| Adam | epoch: 008 | loss: 0.18164 - acc: 0.9281 -- iter: 2208/2948
[A[ATraining Step: 721  | total loss: [1m[32m0.18374[0m[0m | time: 902.983s
[2K
| Adam | epoch: 008 | loss: 0.18374 - acc: 0.9259 -- iter: 2240/2948
[A[ATraining Step: 722  | total loss: [1m[32m0.17542[0m[0m | time: 916.333s
[2K
| Adam | epoch: 008 | loss: 0.17542 - acc: 0.9302 -- iter: 2272/2948
[A[ATraining Step: 723  | total loss: [1m[32m0.16300[0m[0m | time: 930.086s
[2K
| Adam | epoch: 008 | loss: 0.16300 - acc: 0.9371 -- iter: 2304/2948
[A[ATraining Step: 724  | total loss: [1m[32m0.14953[0m[0m | time: 943.277s
[2K
| Adam | epoch: 008 | loss: 0.14953 - acc: 0.9434 -- iter: 2336/2948
[A[ATraining Step: 725  | total loss: [1m[32m0.14909[0m[0m | time: 957.024s
[2K
| Adam | epoch: 008 | loss: 0.14909 - acc: 0.9460 -- iter: 2368/2948
[A[ATraining Step: 726  | total loss: [1m[32m0.14328[0m[0m | time: 970.506s
[2K
| Adam | epoch: 008 | loss: 0.14328 - acc: 0.9482 -- iter: 2400/2948
[A[ATraining Step: 727  | total loss: [1m[32m0.13841[0m[0m | time: 983.924s
[2K
| Adam | epoch: 008 | loss: 0.13841 - acc: 0.9503 -- iter: 2432/2948
[A[ATraining Step: 728  | total loss: [1m[32m0.13051[0m[0m | time: 997.273s
[2K
| Adam | epoch: 008 | loss: 0.13051 - acc: 0.9553 -- iter: 2464/2948
[A[ATraining Step: 729  | total loss: [1m[32m0.12829[0m[0m | time: 1011.232s
[2K
| Adam | epoch: 008 | loss: 0.12829 - acc: 0.9535 -- iter: 2496/2948
[A[ATraining Step: 730  | total loss: [1m[32m0.13441[0m[0m | time: 1024.916s
[2K
| Adam | epoch: 008 | loss: 0.13441 - acc: 0.9488 -- iter: 2528/2948
[A[ATraining Step: 731  | total loss: [1m[32m0.12580[0m[0m | time: 1038.508s
[2K
| Adam | epoch: 008 | loss: 0.12580 - acc: 0.9508 -- iter: 2560/2948
[A[ATraining Step: 732  | total loss: [1m[32m0.11855[0m[0m | time: 1051.305s
[2K
| Adam | epoch: 008 | loss: 0.11855 - acc: 0.9526 -- iter: 2592/2948
[A[ATraining Step: 733  | total loss: [1m[32m0.11698[0m[0m | time: 1064.622s
[2K
| Adam | epoch: 008 | loss: 0.11698 - acc: 0.9479 -- iter: 2624/2948
[A[ATraining Step: 734  | total loss: [1m[32m0.11032[0m[0m | time: 1078.047s
[2K
| Adam | epoch: 008 | loss: 0.11032 - acc: 0.9531 -- iter: 2656/2948
[A[ATraining Step: 735  | total loss: [1m[32m0.11413[0m[0m | time: 1091.122s
[2K
| Adam | epoch: 008 | loss: 0.11413 - acc: 0.9547 -- iter: 2688/2948
[A[ATraining Step: 736  | total loss: [1m[32m0.10521[0m[0m | time: 1104.303s
[2K
| Adam | epoch: 008 | loss: 0.10521 - acc: 0.9592 -- iter: 2720/2948
[A[ATraining Step: 737  | total loss: [1m[32m0.13209[0m[0m | time: 1118.115s
[2K
| Adam | epoch: 008 | loss: 0.13209 - acc: 0.9539 -- iter: 2752/2948
[A[ATraining Step: 738  | total loss: [1m[32m0.13345[0m[0m | time: 1131.501s
[2K
| Adam | epoch: 008 | loss: 0.13345 - acc: 0.9523 -- iter: 2784/2948
[A[ATraining Step: 739  | total loss: [1m[32m0.12126[0m[0m | time: 1145.288s
[2K
| Adam | epoch: 008 | loss: 0.12126 - acc: 0.9571 -- iter: 2816/2948
[A[ATraining Step: 740  | total loss: [1m[32m0.11252[0m[0m | time: 1159.093s
[2K
| Adam | epoch: 008 | loss: 0.11252 - acc: 0.9614 -- iter: 2848/2948
[A[ATraining Step: 741  | total loss: [1m[32m0.10473[0m[0m | time: 1172.955s
[2K
| Adam | epoch: 008 | loss: 0.10473 - acc: 0.9652 -- iter: 2880/2948
[A[ATraining Step: 742  | total loss: [1m[32m0.09966[0m[0m | time: 1186.421s
[2K
| Adam | epoch: 008 | loss: 0.09966 - acc: 0.9687 -- iter: 2912/2948
[A[ATraining Step: 743  | total loss: [1m[32m0.09887[0m[0m | time: 1199.991s
[2K
| Adam | epoch: 008 | loss: 0.09887 - acc: 0.9687 -- iter: 2944/2948
[A[ATraining Step: 744  | total loss: [1m[32m0.09993[0m[0m | time: 1286.691s
[2K
| Adam | epoch: 008 | loss: 0.09993 - acc: 0.9656 | val_loss: 0.19962 - val_acc: 0.9306 -- iter: 2948/2948
--
Training Step: 745  | total loss: [1m[32m0.10882[0m[0m | time: 11.363s
[2K
| Adam | epoch: 009 | loss: 0.10882 - acc: 0.9659 -- iter: 0032/2948
[A[ATraining Step: 746  | total loss: [1m[32m0.10813[0m[0m | time: 24.845s
[2K
| Adam | epoch: 009 | loss: 0.10813 - acc: 0.9662 -- iter: 0064/2948
[A[ATraining Step: 747  | total loss: [1m[32m0.10138[0m[0m | time: 38.133s
[2K
| Adam | epoch: 009 | loss: 0.10138 - acc: 0.9696 -- iter: 0096/2948
[A[ATraining Step: 748  | total loss: [1m[32m0.11961[0m[0m | time: 52.088s
[2K
| Adam | epoch: 009 | loss: 0.11961 - acc: 0.9601 -- iter: 0128/2948
[A[ATraining Step: 749  | total loss: [1m[32m0.12243[0m[0m | time: 65.376s
[2K
| Adam | epoch: 009 | loss: 0.12243 - acc: 0.9578 -- iter: 0160/2948
[A[ATraining Step: 750  | total loss: [1m[32m0.11874[0m[0m | time: 78.656s
[2K
| Adam | epoch: 009 | loss: 0.11874 - acc: 0.9558 -- iter: 0192/2948
[A[ATraining Step: 751  | total loss: [1m[32m0.11284[0m[0m | time: 81.757s
[2K
| Adam | epoch: 009 | loss: 0.11284 - acc: 0.9571 -- iter: 0224/2948
[A[ATraining Step: 752  | total loss: [1m[32m0.16509[0m[0m | time: 85.248s
[2K
| Adam | epoch: 009 | loss: 0.16509 - acc: 0.9364 -- iter: 0256/2948
[A[ATraining Step: 753  | total loss: [1m[32m0.15846[0m[0m | time: 98.218s
[2K
| Adam | epoch: 009 | loss: 0.15846 - acc: 0.9428 -- iter: 0288/2948
[A[ATraining Step: 754  | total loss: [1m[32m0.15240[0m[0m | time: 111.189s
[2K
| Adam | epoch: 009 | loss: 0.15240 - acc: 0.9454 -- iter: 0320/2948
[A[ATraining Step: 755  | total loss: [1m[32m0.13947[0m[0m | time: 124.922s
[2K
| Adam | epoch: 009 | loss: 0.13947 - acc: 0.9508 -- iter: 0352/2948
[A[ATraining Step: 756  | total loss: [1m[32m0.14808[0m[0m | time: 138.399s
[2K
| Adam | epoch: 009 | loss: 0.14808 - acc: 0.9495 -- iter: 0384/2948
[A[ATraining Step: 757  | total loss: [1m[32m0.13866[0m[0m | time: 151.835s
[2K
| Adam | epoch: 009 | loss: 0.13866 - acc: 0.9514 -- iter: 0416/2948
[A[ATraining Step: 758  | total loss: [1m[32m0.16740[0m[0m | time: 165.380s
[2K
| Adam | epoch: 009 | loss: 0.16740 - acc: 0.9469 -- iter: 0448/2948
[A[ATraining Step: 759  | total loss: [1m[32m0.15930[0m[0m | time: 179.042s
[2K
| Adam | epoch: 009 | loss: 0.15930 - acc: 0.9460 -- iter: 0480/2948
[A[ATraining Step: 760  | total loss: [1m[32m0.16046[0m[0m | time: 192.721s
[2K
| Adam | epoch: 009 | loss: 0.16046 - acc: 0.9420 -- iter: 0512/2948
[A[ATraining Step: 761  | total loss: [1m[32m0.16109[0m[0m | time: 206.417s
[2K
| Adam | epoch: 009 | loss: 0.16109 - acc: 0.9384 -- iter: 0544/2948
[A[ATraining Step: 762  | total loss: [1m[32m0.15434[0m[0m | time: 220.405s
[2K
| Adam | epoch: 009 | loss: 0.15434 - acc: 0.9383 -- iter: 0576/2948
[A[ATraining Step: 763  | total loss: [1m[32m0.14291[0m[0m | time: 234.082s
[2K
| Adam | epoch: 009 | loss: 0.14291 - acc: 0.9414 -- iter: 0608/2948
[A[ATraining Step: 764  | total loss: [1m[32m0.13608[0m[0m | time: 247.960s
[2K
| Adam | epoch: 009 | loss: 0.13608 - acc: 0.9441 -- iter: 0640/2948
[A[ATraining Step: 765  | total loss: [1m[32m0.13252[0m[0m | time: 261.359s
[2K
| Adam | epoch: 009 | loss: 0.13252 - acc: 0.9434 -- iter: 0672/2948
[A[ATraining Step: 766  | total loss: [1m[32m0.12131[0m[0m | time: 274.563s
[2K
| Adam | epoch: 009 | loss: 0.12131 - acc: 0.9491 -- iter: 0704/2948
[A[ATraining Step: 767  | total loss: [1m[32m0.11705[0m[0m | time: 287.732s
[2K
| Adam | epoch: 009 | loss: 0.11705 - acc: 0.9479 -- iter: 0736/2948
[A[ATraining Step: 768  | total loss: [1m[32m0.10771[0m[0m | time: 301.426s
[2K
| Adam | epoch: 009 | loss: 0.10771 - acc: 0.9531 -- iter: 0768/2948
[A[ATraining Step: 769  | total loss: [1m[32m0.10018[0m[0m | time: 314.703s
[2K
| Adam | epoch: 009 | loss: 0.10018 - acc: 0.9578 -- iter: 0800/2948
[A[ATraining Step: 770  | total loss: [1m[32m0.09264[0m[0m | time: 328.070s
[2K
| Adam | epoch: 009 | loss: 0.09264 - acc: 0.9620 -- iter: 0832/2948
[A[ATraining Step: 771  | total loss: [1m[32m0.08736[0m[0m | time: 341.159s
[2K
| Adam | epoch: 009 | loss: 0.08736 - acc: 0.9627 -- iter: 0864/2948
[A[ATraining Step: 772  | total loss: [1m[32m0.08020[0m[0m | time: 354.349s
[2K
| Adam | epoch: 009 | loss: 0.08020 - acc: 0.9664 -- iter: 0896/2948
[A[ATraining Step: 773  | total loss: [1m[32m0.09528[0m[0m | time: 367.655s
[2K
| Adam | epoch: 009 | loss: 0.09528 - acc: 0.9604 -- iter: 0928/2948
[A[ATraining Step: 774  | total loss: [1m[32m0.09608[0m[0m | time: 380.771s
[2K
| Adam | epoch: 009 | loss: 0.09608 - acc: 0.9613 -- iter: 0960/2948
[A[ATraining Step: 775  | total loss: [1m[32m0.12382[0m[0m | time: 393.899s
[2K
| Adam | epoch: 009 | loss: 0.12382 - acc: 0.9526 -- iter: 0992/2948
[A[ATraining Step: 776  | total loss: [1m[32m0.13497[0m[0m | time: 407.044s
[2K
| Adam | epoch: 009 | loss: 0.13497 - acc: 0.9449 -- iter: 1024/2948
[A[ATraining Step: 777  | total loss: [1m[32m0.12988[0m[0m | time: 419.972s
[2K
| Adam | epoch: 009 | loss: 0.12988 - acc: 0.9441 -- iter: 1056/2948
[A[ATraining Step: 778  | total loss: [1m[32m0.14350[0m[0m | time: 433.704s
[2K
| Adam | epoch: 009 | loss: 0.14350 - acc: 0.9372 -- iter: 1088/2948
[A[ATraining Step: 779  | total loss: [1m[32m0.14399[0m[0m | time: 447.258s
[2K
| Adam | epoch: 009 | loss: 0.14399 - acc: 0.9372 -- iter: 1120/2948
[A[ATraining Step: 780  | total loss: [1m[32m0.14554[0m[0m | time: 460.987s
[2K
| Adam | epoch: 009 | loss: 0.14554 - acc: 0.9373 -- iter: 1152/2948
[A[ATraining Step: 781  | total loss: [1m[32m0.13588[0m[0m | time: 474.896s
[2K
| Adam | epoch: 009 | loss: 0.13588 - acc: 0.9435 -- iter: 1184/2948
[A[ATraining Step: 782  | total loss: [1m[32m0.12562[0m[0m | time: 488.572s
[2K
| Adam | epoch: 009 | loss: 0.12562 - acc: 0.9492 -- iter: 1216/2948
[A[ATraining Step: 783  | total loss: [1m[32m0.12486[0m[0m | time: 501.857s
[2K
| Adam | epoch: 009 | loss: 0.12486 - acc: 0.9511 -- iter: 1248/2948
[A[ATraining Step: 784  | total loss: [1m[32m0.16295[0m[0m | time: 515.691s
[2K
| Adam | epoch: 009 | loss: 0.16295 - acc: 0.9373 -- iter: 1280/2948
[A[ATraining Step: 785  | total loss: [1m[32m0.15548[0m[0m | time: 529.536s
[2K
| Adam | epoch: 009 | loss: 0.15548 - acc: 0.9373 -- iter: 1312/2948
[A[ATraining Step: 786  | total loss: [1m[32m0.14873[0m[0m | time: 543.233s
[2K
| Adam | epoch: 009 | loss: 0.14873 - acc: 0.9373 -- iter: 1344/2948
[A[ATraining Step: 787  | total loss: [1m[32m0.14138[0m[0m | time: 556.865s
[2K
| Adam | epoch: 009 | loss: 0.14138 - acc: 0.9405 -- iter: 1376/2948
[A[ATraining Step: 788  | total loss: [1m[32m0.13337[0m[0m | time: 570.942s
[2K
| Adam | epoch: 009 | loss: 0.13337 - acc: 0.9464 -- iter: 1408/2948
[A[ATraining Step: 789  | total loss: [1m[32m0.14624[0m[0m | time: 584.598s
[2K
| Adam | epoch: 009 | loss: 0.14624 - acc: 0.9424 -- iter: 1440/2948
[A[ATraining Step: 790  | total loss: [1m[32m0.13674[0m[0m | time: 598.025s
[2K
| Adam | epoch: 009 | loss: 0.13674 - acc: 0.9482 -- iter: 1472/2948
[A[ATraining Step: 791  | total loss: [1m[32m0.13073[0m[0m | time: 611.909s
[2K
| Adam | epoch: 009 | loss: 0.13073 - acc: 0.9502 -- iter: 1504/2948
[A[ATraining Step: 792  | total loss: [1m[32m0.12649[0m[0m | time: 625.342s
[2K
| Adam | epoch: 009 | loss: 0.12649 - acc: 0.9489 -- iter: 1536/2948
[A[ATraining Step: 793  | total loss: [1m[32m0.12348[0m[0m | time: 638.824s
[2K
| Adam | epoch: 009 | loss: 0.12348 - acc: 0.9541 -- iter: 1568/2948
[A[ATraining Step: 794  | total loss: [1m[32m0.11829[0m[0m | time: 652.844s
[2K
| Adam | epoch: 009 | loss: 0.11829 - acc: 0.9555 -- iter: 1600/2948
[A[ATraining Step: 795  | total loss: [1m[32m0.12011[0m[0m | time: 666.392s
[2K
| Adam | epoch: 009 | loss: 0.12011 - acc: 0.9506 -- iter: 1632/2948
[A[ATraining Step: 796  | total loss: [1m[32m0.12308[0m[0m | time: 680.215s
[2K
| Adam | epoch: 009 | loss: 0.12308 - acc: 0.9430 -- iter: 1664/2948
[A[ATraining Step: 797  | total loss: [1m[32m0.11775[0m[0m | time: 693.910s
[2K
| Adam | epoch: 009 | loss: 0.11775 - acc: 0.9487 -- iter: 1696/2948
[A[ATraining Step: 798  | total loss: [1m[32m0.12742[0m[0m | time: 708.066s
[2K
| Adam | epoch: 009 | loss: 0.12742 - acc: 0.9476 -- iter: 1728/2948
[A[ATraining Step: 799  | total loss: [1m[32m0.11767[0m[0m | time: 722.094s
[2K
| Adam | epoch: 009 | loss: 0.11767 - acc: 0.9528 -- iter: 1760/2948
[A[ATraining Step: 800  | total loss: [1m[32m0.11592[0m[0m | time: 810.092s
[2K
| Adam | epoch: 009 | loss: 0.11592 - acc: 0.9513 | val_loss: 0.25399 - val_acc: 0.9197 -- iter: 1792/2948
--
Training Step: 801  | total loss: [1m[32m0.10974[0m[0m | time: 825.186s
[2K
| Adam | epoch: 009 | loss: 0.10974 - acc: 0.9562 -- iter: 1824/2948
[A[ATraining Step: 802  | total loss: [1m[32m0.11706[0m[0m | time: 838.366s
[2K
| Adam | epoch: 009 | loss: 0.11706 - acc: 0.9543 -- iter: 1856/2948
[A[ATraining Step: 803  | total loss: [1m[32m0.12951[0m[0m | time: 851.786s
[2K
| Adam | epoch: 009 | loss: 0.12951 - acc: 0.9495 -- iter: 1888/2948
[A[ATraining Step: 804  | total loss: [1m[32m0.12129[0m[0m | time: 865.523s
[2K
| Adam | epoch: 009 | loss: 0.12129 - acc: 0.9514 -- iter: 1920/2948
[A[ATraining Step: 805  | total loss: [1m[32m0.11331[0m[0m | time: 879.151s
[2K
| Adam | epoch: 009 | loss: 0.11331 - acc: 0.9563 -- iter: 1952/2948
[A[ATraining Step: 806  | total loss: [1m[32m0.12143[0m[0m | time: 892.410s
[2K
| Adam | epoch: 009 | loss: 0.12143 - acc: 0.9544 -- iter: 1984/2948
[A[ATraining Step: 807  | total loss: [1m[32m0.11062[0m[0m | time: 906.068s
[2K
| Adam | epoch: 009 | loss: 0.11062 - acc: 0.9590 -- iter: 2016/2948
[A[ATraining Step: 808  | total loss: [1m[32m0.11271[0m[0m | time: 920.007s
[2K
| Adam | epoch: 009 | loss: 0.11271 - acc: 0.9599 -- iter: 2048/2948
[A[ATraining Step: 809  | total loss: [1m[32m0.11304[0m[0m | time: 933.782s
[2K
| Adam | epoch: 009 | loss: 0.11304 - acc: 0.9577 -- iter: 2080/2948
[A[ATraining Step: 810  | total loss: [1m[32m0.11359[0m[0m | time: 947.469s
[2K
| Adam | epoch: 009 | loss: 0.11359 - acc: 0.9557 -- iter: 2112/2948
[A[ATraining Step: 811  | total loss: [1m[32m0.12166[0m[0m | time: 961.272s
[2K
| Adam | epoch: 009 | loss: 0.12166 - acc: 0.9539 -- iter: 2144/2948
[A[ATraining Step: 812  | total loss: [1m[32m0.12515[0m[0m | time: 974.928s
[2K
| Adam | epoch: 009 | loss: 0.12515 - acc: 0.9522 -- iter: 2176/2948
[A[ATraining Step: 813  | total loss: [1m[32m0.12541[0m[0m | time: 988.283s
[2K
| Adam | epoch: 009 | loss: 0.12541 - acc: 0.9508 -- iter: 2208/2948
[A[ATraining Step: 814  | total loss: [1m[32m0.13305[0m[0m | time: 1002.318s
[2K
| Adam | epoch: 009 | loss: 0.13305 - acc: 0.9526 -- iter: 2240/2948
[A[ATraining Step: 815  | total loss: [1m[32m0.12864[0m[0m | time: 1016.367s
[2K
| Adam | epoch: 009 | loss: 0.12864 - acc: 0.9510 -- iter: 2272/2948
[A[ATraining Step: 816  | total loss: [1m[32m0.12459[0m[0m | time: 1029.854s
[2K
| Adam | epoch: 009 | loss: 0.12459 - acc: 0.9497 -- iter: 2304/2948
[A[ATraining Step: 817  | total loss: [1m[32m0.11645[0m[0m | time: 1043.568s
[2K
| Adam | epoch: 009 | loss: 0.11645 - acc: 0.9547 -- iter: 2336/2948
[A[ATraining Step: 818  | total loss: [1m[32m0.11861[0m[0m | time: 1057.426s
[2K
| Adam | epoch: 009 | loss: 0.11861 - acc: 0.9530 -- iter: 2368/2948
[A[ATraining Step: 819  | total loss: [1m[32m0.12302[0m[0m | time: 1071.354s
[2K
| Adam | epoch: 009 | loss: 0.12302 - acc: 0.9546 -- iter: 2400/2948
[A[ATraining Step: 820  | total loss: [1m[32m0.11256[0m[0m | time: 1085.505s
[2K
| Adam | epoch: 009 | loss: 0.11256 - acc: 0.9591 -- iter: 2432/2948
[A[ATraining Step: 821  | total loss: [1m[32m0.12209[0m[0m | time: 1099.518s
[2K
| Adam | epoch: 009 | loss: 0.12209 - acc: 0.9570 -- iter: 2464/2948
[A[ATraining Step: 822  | total loss: [1m[32m0.12105[0m[0m | time: 1113.430s
[2K
| Adam | epoch: 009 | loss: 0.12105 - acc: 0.9581 -- iter: 2496/2948
[A[ATraining Step: 823  | total loss: [1m[32m0.12700[0m[0m | time: 1127.714s
[2K
| Adam | epoch: 009 | loss: 0.12700 - acc: 0.9561 -- iter: 2528/2948
[A[ATraining Step: 824  | total loss: [1m[32m0.11845[0m[0m | time: 1141.919s
[2K
| Adam | epoch: 009 | loss: 0.11845 - acc: 0.9605 -- iter: 2560/2948
[A[ATraining Step: 825  | total loss: [1m[32m0.11671[0m[0m | time: 1155.930s
[2K
| Adam | epoch: 009 | loss: 0.11671 - acc: 0.9582 -- iter: 2592/2948
[A[ATraining Step: 826  | total loss: [1m[32m0.12303[0m[0m | time: 1169.926s
[2K
| Adam | epoch: 009 | loss: 0.12303 - acc: 0.9530 -- iter: 2624/2948
[A[ATraining Step: 827  | total loss: [1m[32m0.11943[0m[0m | time: 1184.037s
[2K
| Adam | epoch: 009 | loss: 0.11943 - acc: 0.9514 -- iter: 2656/2948
[A[ATraining Step: 828  | total loss: [1m[32m0.11322[0m[0m | time: 1198.219s
[2K
| Adam | epoch: 009 | loss: 0.11322 - acc: 0.9532 -- iter: 2688/2948
[A[ATraining Step: 829  | total loss: [1m[32m0.12488[0m[0m | time: 1212.223s
[2K
| Adam | epoch: 009 | loss: 0.12488 - acc: 0.9453 -- iter: 2720/2948
[A[ATraining Step: 830  | total loss: [1m[32m0.11542[0m[0m | time: 1226.205s
[2K
| Adam | epoch: 009 | loss: 0.11542 - acc: 0.9508 -- iter: 2752/2948
[A[ATraining Step: 831  | total loss: [1m[32m0.12200[0m[0m | time: 1239.900s
[2K
| Adam | epoch: 009 | loss: 0.12200 - acc: 0.9526 -- iter: 2784/2948
[A[ATraining Step: 832  | total loss: [1m[32m0.11619[0m[0m | time: 1253.375s
[2K
| Adam | epoch: 009 | loss: 0.11619 - acc: 0.9573 -- iter: 2816/2948
[A[ATraining Step: 833  | total loss: [1m[32m0.12554[0m[0m | time: 1267.133s
[2K
| Adam | epoch: 009 | loss: 0.12554 - acc: 0.9554 -- iter: 2848/2948
[A[ATraining Step: 834  | total loss: [1m[32m0.12479[0m[0m | time: 1280.601s
[2K
| Adam | epoch: 009 | loss: 0.12479 - acc: 0.9536 -- iter: 2880/2948
[A[ATraining Step: 835  | total loss: [1m[32m0.13140[0m[0m | time: 1293.832s
[2K
| Adam | epoch: 009 | loss: 0.13140 - acc: 0.9488 -- iter: 2912/2948
[A[ATraining Step: 836  | total loss: [1m[32m0.13942[0m[0m | time: 1307.029s
[2K
| Adam | epoch: 009 | loss: 0.13942 - acc: 0.9446 -- iter: 2944/2948
[A[ATraining Step: 837  | total loss: [1m[32m0.13297[0m[0m | time: 1391.628s
[2K
| Adam | epoch: 009 | loss: 0.13297 - acc: 0.9470 | val_loss: 1.22265 - val_acc: 0.6030 -- iter: 2948/2948
--
Training Step: 838  | total loss: [1m[32m0.12854[0m[0m | time: 13.457s
[2K
| Adam | epoch: 010 | loss: 0.12854 - acc: 0.9492 -- iter: 0032/2948
[A[ATraining Step: 839  | total loss: [1m[32m0.11756[0m[0m | time: 27.118s
[2K
| Adam | epoch: 010 | loss: 0.11756 - acc: 0.9543 -- iter: 0064/2948
[A[ATraining Step: 840  | total loss: [1m[32m0.10912[0m[0m | time: 41.101s
[2K
| Adam | epoch: 010 | loss: 0.10912 - acc: 0.9557 -- iter: 0096/2948
[A[ATraining Step: 841  | total loss: [1m[32m0.10155[0m[0m | time: 54.656s
[2K
| Adam | epoch: 010 | loss: 0.10155 - acc: 0.9570 -- iter: 0128/2948
[A[ATraining Step: 842  | total loss: [1m[32m0.09860[0m[0m | time: 68.257s
[2K
| Adam | epoch: 010 | loss: 0.09860 - acc: 0.9582 -- iter: 0160/2948
[A[ATraining Step: 843  | total loss: [1m[32m0.09076[0m[0m | time: 81.640s
[2K
| Adam | epoch: 010 | loss: 0.09076 - acc: 0.9624 -- iter: 0192/2948
[A[ATraining Step: 844  | total loss: [1m[32m0.09904[0m[0m | time: 95.188s
[2K
| Adam | epoch: 010 | loss: 0.09904 - acc: 0.9630 -- iter: 0224/2948
[A[ATraining Step: 845  | total loss: [1m[32m0.10086[0m[0m | time: 98.346s
[2K
| Adam | epoch: 010 | loss: 0.10086 - acc: 0.9605 -- iter: 0256/2948
[A[ATraining Step: 846  | total loss: [1m[32m0.15007[0m[0m | time: 101.834s
[2K
| Adam | epoch: 010 | loss: 0.15007 - acc: 0.9394 -- iter: 0288/2948
[A[ATraining Step: 847  | total loss: [1m[32m0.14608[0m[0m | time: 115.297s
[2K
| Adam | epoch: 010 | loss: 0.14608 - acc: 0.9455 -- iter: 0320/2948
[A[ATraining Step: 848  | total loss: [1m[32m0.14254[0m[0m | time: 128.919s
[2K
| Adam | epoch: 010 | loss: 0.14254 - acc: 0.9415 -- iter: 0352/2948
[A[ATraining Step: 849  | total loss: [1m[32m0.13174[0m[0m | time: 141.988s
[2K
| Adam | epoch: 010 | loss: 0.13174 - acc: 0.9474 -- iter: 0384/2948
[A[ATraining Step: 850  | total loss: [1m[32m0.13994[0m[0m | time: 155.586s
[2K
| Adam | epoch: 010 | loss: 0.13994 - acc: 0.9433 -- iter: 0416/2948
[A[ATraining Step: 851  | total loss: [1m[32m0.13173[0m[0m | time: 169.494s
[2K
| Adam | epoch: 010 | loss: 0.13173 - acc: 0.9458 -- iter: 0448/2948
[A[ATraining Step: 852  | total loss: [1m[32m0.13046[0m[0m | time: 182.981s
[2K
| Adam | epoch: 010 | loss: 0.13046 - acc: 0.9450 -- iter: 0480/2948
[A[ATraining Step: 853  | total loss: [1m[32m0.13603[0m[0m | time: 196.496s
[2K
| Adam | epoch: 010 | loss: 0.13603 - acc: 0.9474 -- iter: 0512/2948
[A[ATraining Step: 854  | total loss: [1m[32m0.12804[0m[0m | time: 210.561s
[2K
| Adam | epoch: 010 | loss: 0.12804 - acc: 0.9495 -- iter: 0544/2948
[A[ATraining Step: 855  | total loss: [1m[32m0.12207[0m[0m | time: 224.007s
[2K
| Adam | epoch: 010 | loss: 0.12207 - acc: 0.9514 -- iter: 0576/2948
[A[ATraining Step: 856  | total loss: [1m[32m0.11707[0m[0m | time: 237.434s
[2K
| Adam | epoch: 010 | loss: 0.11707 - acc: 0.9532 -- iter: 0608/2948
[A[ATraining Step: 857  | total loss: [1m[32m0.13245[0m[0m | time: 250.838s
[2K
| Adam | epoch: 010 | loss: 0.13245 - acc: 0.9516 -- iter: 0640/2948
[A[ATraining Step: 858  | total loss: [1m[32m0.14549[0m[0m | time: 264.272s
[2K
| Adam | epoch: 010 | loss: 0.14549 - acc: 0.9502 -- iter: 0672/2948
[A[ATraining Step: 859  | total loss: [1m[32m0.13225[0m[0m | time: 277.387s
[2K
| Adam | epoch: 010 | loss: 0.13225 - acc: 0.9552 -- iter: 0704/2948
[A[ATraining Step: 860  | total loss: [1m[32m0.13380[0m[0m | time: 290.655s
[2K
| Adam | epoch: 010 | loss: 0.13380 - acc: 0.9565 -- iter: 0736/2948
[A[ATraining Step: 861  | total loss: [1m[32m0.14877[0m[0m | time: 304.152s
[2K
| Adam | epoch: 010 | loss: 0.14877 - acc: 0.9452 -- iter: 0768/2948
[A[ATraining Step: 862  | total loss: [1m[32m0.13637[0m[0m | time: 317.855s
[2K
| Adam | epoch: 010 | loss: 0.13637 - acc: 0.9507 -- iter: 0800/2948
[A[ATraining Step: 863  | total loss: [1m[32m0.13967[0m[0m | time: 331.387s
[2K
| Adam | epoch: 010 | loss: 0.13967 - acc: 0.9463 -- iter: 0832/2948
[A[ATraining Step: 864  | total loss: [1m[32m0.13183[0m[0m | time: 344.956s
[2K
| Adam | epoch: 010 | loss: 0.13183 - acc: 0.9485 -- iter: 0864/2948
[A[ATraining Step: 865  | total loss: [1m[32m0.13233[0m[0m | time: 358.588s
[2K
| Adam | epoch: 010 | loss: 0.13233 - acc: 0.9474 -- iter: 0896/2948
[A[ATraining Step: 866  | total loss: [1m[32m0.12179[0m[0m | time: 372.015s
[2K
| Adam | epoch: 010 | loss: 0.12179 - acc: 0.9527 -- iter: 0928/2948
[A[ATraining Step: 867  | total loss: [1m[32m0.11877[0m[0m | time: 385.552s
[2K
| Adam | epoch: 010 | loss: 0.11877 - acc: 0.9512 -- iter: 0960/2948
[A[ATraining Step: 868  | total loss: [1m[32m0.11859[0m[0m | time: 398.786s
[2K
| Adam | epoch: 010 | loss: 0.11859 - acc: 0.9498 -- iter: 0992/2948
[A[ATraining Step: 869  | total loss: [1m[32m0.13488[0m[0m | time: 412.148s
[2K
| Adam | epoch: 010 | loss: 0.13488 - acc: 0.9361 -- iter: 1024/2948
[A[ATraining Step: 870  | total loss: [1m[32m0.14154[0m[0m | time: 425.277s
[2K
| Adam | epoch: 010 | loss: 0.14154 - acc: 0.9300 -- iter: 1056/2948
[A[ATraining Step: 871  | total loss: [1m[32m0.15090[0m[0m | time: 438.820s
[2K
| Adam | epoch: 010 | loss: 0.15090 - acc: 0.9276 -- iter: 1088/2948
[A[ATraining Step: 872  | total loss: [1m[32m0.16737[0m[0m | time: 452.087s
[2K
| Adam | epoch: 010 | loss: 0.16737 - acc: 0.9255 -- iter: 1120/2948
[A[ATraining Step: 873  | total loss: [1m[32m0.15311[0m[0m | time: 465.221s
[2K
| Adam | epoch: 010 | loss: 0.15311 - acc: 0.9329 -- iter: 1152/2948
[A[ATraining Step: 874  | total loss: [1m[32m0.15262[0m[0m | time: 478.664s
[2K
| Adam | epoch: 010 | loss: 0.15262 - acc: 0.9334 -- iter: 1184/2948
[A[ATraining Step: 875  | total loss: [1m[32m0.15101[0m[0m | time: 492.628s
[2K
| Adam | epoch: 010 | loss: 0.15101 - acc: 0.9369 -- iter: 1216/2948
[A[ATraining Step: 876  | total loss: [1m[32m0.15462[0m[0m | time: 505.877s
[2K
| Adam | epoch: 010 | loss: 0.15462 - acc: 0.9338 -- iter: 1248/2948
[A[ATraining Step: 877  | total loss: [1m[32m0.15466[0m[0m | time: 519.345s
[2K
| Adam | epoch: 010 | loss: 0.15466 - acc: 0.9342 -- iter: 1280/2948
[A[ATraining Step: 878  | total loss: [1m[32m0.14432[0m[0m | time: 533.180s
[2K
| Adam | epoch: 010 | loss: 0.14432 - acc: 0.9408 -- iter: 1312/2948
[A[ATraining Step: 879  | total loss: [1m[32m0.14961[0m[0m | time: 546.452s
[2K
| Adam | epoch: 010 | loss: 0.14961 - acc: 0.9373 -- iter: 1344/2948
[A[ATraining Step: 880  | total loss: [1m[32m0.14530[0m[0m | time: 559.540s
[2K
| Adam | epoch: 010 | loss: 0.14530 - acc: 0.9405 -- iter: 1376/2948
[A[ATraining Step: 881  | total loss: [1m[32m0.14004[0m[0m | time: 573.184s
[2K
| Adam | epoch: 010 | loss: 0.14004 - acc: 0.9433 -- iter: 1408/2948
[A[ATraining Step: 882  | total loss: [1m[32m0.14341[0m[0m | time: 587.028s
[2K
| Adam | epoch: 010 | loss: 0.14341 - acc: 0.9396 -- iter: 1440/2948
[A[ATraining Step: 883  | total loss: [1m[32m0.13503[0m[0m | time: 600.565s
[2K
| Adam | epoch: 010 | loss: 0.13503 - acc: 0.9425 -- iter: 1472/2948
[A[ATraining Step: 884  | total loss: [1m[32m0.12536[0m[0m | time: 613.693s
[2K
| Adam | epoch: 010 | loss: 0.12536 - acc: 0.9451 -- iter: 1504/2948
[A[ATraining Step: 885  | total loss: [1m[32m0.12777[0m[0m | time: 627.064s
[2K
| Adam | epoch: 010 | loss: 0.12777 - acc: 0.9444 -- iter: 1536/2948
[A[ATraining Step: 886  | total loss: [1m[32m0.12495[0m[0m | time: 640.208s
[2K
| Adam | epoch: 010 | loss: 0.12495 - acc: 0.9437 -- iter: 1568/2948
[A[ATraining Step: 887  | total loss: [1m[32m0.12883[0m[0m | time: 653.860s
[2K
| Adam | epoch: 010 | loss: 0.12883 - acc: 0.9431 -- iter: 1600/2948
[A[ATraining Step: 888  | total loss: [1m[32m0.13140[0m[0m | time: 666.641s
[2K
| Adam | epoch: 010 | loss: 0.13140 - acc: 0.9425 -- iter: 1632/2948
[A[ATraining Step: 889  | total loss: [1m[32m0.12925[0m[0m | time: 680.213s
[2K
| Adam | epoch: 010 | loss: 0.12925 - acc: 0.9451 -- iter: 1664/2948
[A[ATraining Step: 890  | total loss: [1m[32m0.12372[0m[0m | time: 693.260s
[2K
| Adam | epoch: 010 | loss: 0.12372 - acc: 0.9506 -- iter: 1696/2948
[A[ATraining Step: 891  | total loss: [1m[32m0.11786[0m[0m | time: 706.429s
[2K
| Adam | epoch: 010 | loss: 0.11786 - acc: 0.9524 -- iter: 1728/2948
[A[ATraining Step: 892  | total loss: [1m[32m0.11700[0m[0m | time: 719.447s
[2K
| Adam | epoch: 010 | loss: 0.11700 - acc: 0.9541 -- iter: 1760/2948
[A[ATraining Step: 893  | total loss: [1m[32m0.10912[0m[0m | time: 733.432s
[2K
| Adam | epoch: 010 | loss: 0.10912 - acc: 0.9587 -- iter: 1792/2948
[A[ATraining Step: 894  | total loss: [1m[32m0.11869[0m[0m | time: 746.688s
[2K
| Adam | epoch: 010 | loss: 0.11869 - acc: 0.9565 -- iter: 1824/2948
[A[ATraining Step: 895  | total loss: [1m[32m0.11080[0m[0m | time: 760.135s
[2K
| Adam | epoch: 010 | loss: 0.11080 - acc: 0.9609 -- iter: 1856/2948
[A[ATraining Step: 896  | total loss: [1m[32m0.10363[0m[0m | time: 773.461s
[2K
| Adam | epoch: 010 | loss: 0.10363 - acc: 0.9648 -- iter: 1888/2948
[A[ATraining Step: 897  | total loss: [1m[32m0.09750[0m[0m | time: 787.093s
[2K
| Adam | epoch: 010 | loss: 0.09750 - acc: 0.9683 -- iter: 1920/2948
[A[ATraining Step: 898  | total loss: [1m[32m0.09305[0m[0m | time: 800.582s
[2K
| Adam | epoch: 010 | loss: 0.09305 - acc: 0.9715 -- iter: 1952/2948
[A[ATraining Step: 899  | total loss: [1m[32m0.08577[0m[0m | time: 813.902s
[2K
| Adam | epoch: 010 | loss: 0.08577 - acc: 0.9743 -- iter: 1984/2948
[A[ATraining Step: 900  | total loss: [1m[32m0.08026[0m[0m | time: 827.171s
[2K
| Adam | epoch: 010 | loss: 0.08026 - acc: 0.9769 -- iter: 2016/2948
[A[ATraining Step: 901  | total loss: [1m[32m0.09021[0m[0m | time: 840.760s
[2K
| Adam | epoch: 010 | loss: 0.09021 - acc: 0.9730 -- iter: 2048/2948
[A[ATraining Step: 902  | total loss: [1m[32m0.09417[0m[0m | time: 854.664s
[2K
| Adam | epoch: 010 | loss: 0.09417 - acc: 0.9694 -- iter: 2080/2948
[A[ATraining Step: 903  | total loss: [1m[32m0.11675[0m[0m | time: 868.142s
[2K
| Adam | epoch: 010 | loss: 0.11675 - acc: 0.9600 -- iter: 2112/2948
[A[ATraining Step: 904  | total loss: [1m[32m0.10798[0m[0m | time: 881.368s
[2K
| Adam | epoch: 010 | loss: 0.10798 - acc: 0.9640 -- iter: 2144/2948
[A[ATraining Step: 905  | total loss: [1m[32m0.11428[0m[0m | time: 894.677s
[2K
| Adam | epoch: 010 | loss: 0.11428 - acc: 0.9582 -- iter: 2176/2948
[A[ATraining Step: 906  | total loss: [1m[32m0.10972[0m[0m | time: 907.903s
[2K
| Adam | epoch: 010 | loss: 0.10972 - acc: 0.9593 -- iter: 2208/2948
[A[ATraining Step: 907  | total loss: [1m[32m0.11155[0m[0m | time: 921.468s
[2K
| Adam | epoch: 010 | loss: 0.11155 - acc: 0.9571 -- iter: 2240/2948
[A[ATraining Step: 908  | total loss: [1m[32m0.10307[0m[0m | time: 934.654s
[2K
| Adam | epoch: 010 | loss: 0.10307 - acc: 0.9614 -- iter: 2272/2948
[A[ATraining Step: 909  | total loss: [1m[32m0.14459[0m[0m | time: 948.057s
[2K
| Adam | epoch: 010 | loss: 0.14459 - acc: 0.9496 -- iter: 2304/2948
[A[ATraining Step: 910  | total loss: [1m[32m0.13206[0m[0m | time: 961.427s
[2K
| Adam | epoch: 010 | loss: 0.13206 - acc: 0.9547 -- iter: 2336/2948
[A[ATraining Step: 911  | total loss: [1m[32m0.12022[0m[0m | time: 974.857s
[2K
| Adam | epoch: 010 | loss: 0.12022 - acc: 0.9592 -- iter: 2368/2948
[A[ATraining Step: 912  | total loss: [1m[32m0.13822[0m[0m | time: 988.562s
[2K
| Adam | epoch: 010 | loss: 0.13822 - acc: 0.9570 -- iter: 2400/2948
[A[ATraining Step: 913  | total loss: [1m[32m0.12482[0m[0m | time: 1001.904s
[2K
| Adam | epoch: 010 | loss: 0.12482 - acc: 0.9613 -- iter: 2432/2948
[A[ATraining Step: 914  | total loss: [1m[32m0.11728[0m[0m | time: 1015.536s
[2K
| Adam | epoch: 010 | loss: 0.11728 - acc: 0.9621 -- iter: 2464/2948
[A[ATraining Step: 915  | total loss: [1m[32m0.10699[0m[0m | time: 1028.717s
[2K
| Adam | epoch: 010 | loss: 0.10699 - acc: 0.9659 -- iter: 2496/2948
[A[ATraining Step: 916  | total loss: [1m[32m0.09804[0m[0m | time: 1041.884s
[2K
| Adam | epoch: 010 | loss: 0.09804 - acc: 0.9693 -- iter: 2528/2948
[A[ATraining Step: 917  | total loss: [1m[32m0.09381[0m[0m | time: 1055.149s
[2K
| Adam | epoch: 010 | loss: 0.09381 - acc: 0.9692 -- iter: 2560/2948
[A[ATraining Step: 918  | total loss: [1m[32m0.08776[0m[0m | time: 1068.194s
[2K
| Adam | epoch: 010 | loss: 0.08776 - acc: 0.9723 -- iter: 2592/2948
[A[ATraining Step: 919  | total loss: [1m[32m0.08979[0m[0m | time: 1081.093s
[2K
| Adam | epoch: 010 | loss: 0.08979 - acc: 0.9688 -- iter: 2624/2948
[A[ATraining Step: 920  | total loss: [1m[32m0.08672[0m[0m | time: 1094.415s
[2K
| Adam | epoch: 010 | loss: 0.08672 - acc: 0.9719 -- iter: 2656/2948
[A[ATraining Step: 921  | total loss: [1m[32m0.09132[0m[0m | time: 1107.567s
[2K
| Adam | epoch: 010 | loss: 0.09132 - acc: 0.9685 -- iter: 2688/2948
[A[ATraining Step: 922  | total loss: [1m[32m0.08997[0m[0m | time: 1120.739s
[2K
| Adam | epoch: 010 | loss: 0.08997 - acc: 0.9716 -- iter: 2720/2948
[A[ATraining Step: 923  | total loss: [1m[32m0.08326[0m[0m | time: 1134.060s
[2K
| Adam | epoch: 010 | loss: 0.08326 - acc: 0.9745 -- iter: 2752/2948
[A[ATraining Step: 924  | total loss: [1m[32m0.08486[0m[0m | time: 1147.571s
[2K
| Adam | epoch: 010 | loss: 0.08486 - acc: 0.9677 -- iter: 2784/2948
[A[ATraining Step: 925  | total loss: [1m[32m0.08296[0m[0m | time: 1160.436s
[2K
| Adam | epoch: 010 | loss: 0.08296 - acc: 0.9678 -- iter: 2816/2948
[A[ATraining Step: 926  | total loss: [1m[32m0.08214[0m[0m | time: 1173.715s
[2K
| Adam | epoch: 010 | loss: 0.08214 - acc: 0.9647 -- iter: 2848/2948
[A[ATraining Step: 927  | total loss: [1m[32m0.07508[0m[0m | time: 1187.186s
[2K
| Adam | epoch: 010 | loss: 0.07508 - acc: 0.9683 -- iter: 2880/2948
[A[ATraining Step: 928  | total loss: [1m[32m0.07737[0m[0m | time: 1199.874s
[2K
| Adam | epoch: 010 | loss: 0.07737 - acc: 0.9652 -- iter: 2912/2948
[A[ATraining Step: 929  | total loss: [1m[32m0.11410[0m[0m | time: 1213.793s
[2K
| Adam | epoch: 010 | loss: 0.11410 - acc: 0.9468 -- iter: 2944/2948
[A[ATraining Step: 930  | total loss: [1m[32m0.10624[0m[0m | time: 1285.750s
[2K
| Adam | epoch: 010 | loss: 0.10624 - acc: 0.9521 | val_loss: 0.23534 - val_acc: 0.9132 -- iter: 2948/2948
--
Training Step: 931  | total loss: [1m[32m0.09997[0m[0m | time: 13.691s
[2K
| Adam | epoch: 011 | loss: 0.09997 - acc: 0.9538 -- iter: 0032/2948
[A[ATraining Step: 932  | total loss: [1m[32m0.09985[0m[0m | time: 26.556s
[2K
| Adam | epoch: 011 | loss: 0.09985 - acc: 0.9553 -- iter: 0064/2948
[A[ATraining Step: 933  | total loss: [1m[32m0.09785[0m[0m | time: 40.456s
[2K
| Adam | epoch: 011 | loss: 0.09785 - acc: 0.9566 -- iter: 0096/2948
[A[ATraining Step: 934  | total loss: [1m[32m0.09019[0m[0m | time: 53.979s
[2K
| Adam | epoch: 011 | loss: 0.09019 - acc: 0.9610 -- iter: 0128/2948
[A[ATraining Step: 935  | total loss: [1m[32m0.08556[0m[0m | time: 67.497s
[2K
| Adam | epoch: 011 | loss: 0.08556 - acc: 0.9617 -- iter: 0160/2948
[A[ATraining Step: 936  | total loss: [1m[32m0.08038[0m[0m | time: 80.444s
[2K
| Adam | epoch: 011 | loss: 0.08038 - acc: 0.9656 -- iter: 0192/2948
[A[ATraining Step: 937  | total loss: [1m[32m0.08037[0m[0m | time: 93.042s
[2K
| Adam | epoch: 011 | loss: 0.08037 - acc: 0.9659 -- iter: 0224/2948
[A[ATraining Step: 938  | total loss: [1m[32m0.07413[0m[0m | time: 105.860s
[2K
| Adam | epoch: 011 | loss: 0.07413 - acc: 0.9693 -- iter: 0256/2948
[A[ATraining Step: 939  | total loss: [1m[32m0.06875[0m[0m | time: 109.148s
[2K
| Adam | epoch: 011 | loss: 0.06875 - acc: 0.9724 -- iter: 0288/2948
[A[ATraining Step: 940  | total loss: [1m[32m0.12363[0m[0m | time: 112.157s
[2K
| Adam | epoch: 011 | loss: 0.12363 - acc: 0.9501 -- iter: 0320/2948
[A[ATraining Step: 941  | total loss: [1m[32m0.12368[0m[0m | time: 125.443s
[2K
| Adam | epoch: 011 | loss: 0.12368 - acc: 0.9551 -- iter: 0352/2948
[A[ATraining Step: 942  | total loss: [1m[32m0.11916[0m[0m | time: 138.585s
[2K
| Adam | epoch: 011 | loss: 0.11916 - acc: 0.9565 -- iter: 0384/2948
[A[ATraining Step: 943  | total loss: [1m[32m0.10797[0m[0m | time: 152.185s
[2K
| Adam | epoch: 011 | loss: 0.10797 - acc: 0.9608 -- iter: 0416/2948
[A[ATraining Step: 944  | total loss: [1m[32m0.12259[0m[0m | time: 165.687s
[2K
| Adam | epoch: 011 | loss: 0.12259 - acc: 0.9554 -- iter: 0448/2948
[A[ATraining Step: 945  | total loss: [1m[32m0.12328[0m[0m | time: 179.213s
[2K
| Adam | epoch: 011 | loss: 0.12328 - acc: 0.9536 -- iter: 0480/2948
[A[ATraining Step: 946  | total loss: [1m[32m0.11218[0m[0m | time: 192.635s
[2K
| Adam | epoch: 011 | loss: 0.11218 - acc: 0.9582 -- iter: 0512/2948
[A[ATraining Step: 947  | total loss: [1m[32m0.10524[0m[0m | time: 205.617s
[2K
| Adam | epoch: 011 | loss: 0.10524 - acc: 0.9624 -- iter: 0544/2948
[A[ATraining Step: 948  | total loss: [1m[32m0.10942[0m[0m | time: 218.575s
[2K
| Adam | epoch: 011 | loss: 0.10942 - acc: 0.9630 -- iter: 0576/2948
[A[ATraining Step: 949  | total loss: [1m[32m0.11517[0m[0m | time: 232.096s
[2K
| Adam | epoch: 011 | loss: 0.11517 - acc: 0.9605 -- iter: 0608/2948
[A[ATraining Step: 950  | total loss: [1m[32m0.11044[0m[0m | time: 245.030s
[2K
| Adam | epoch: 011 | loss: 0.11044 - acc: 0.9613 -- iter: 0640/2948
[A[ATraining Step: 951  | total loss: [1m[32m0.10621[0m[0m | time: 258.459s
[2K
| Adam | epoch: 011 | loss: 0.10621 - acc: 0.9621 -- iter: 0672/2948
[A[ATraining Step: 952  | total loss: [1m[32m0.10673[0m[0m | time: 271.933s
[2K
| Adam | epoch: 011 | loss: 0.10673 - acc: 0.9627 -- iter: 0704/2948
[A[ATraining Step: 953  | total loss: [1m[32m0.12006[0m[0m | time: 284.920s
[2K
| Adam | epoch: 011 | loss: 0.12006 - acc: 0.9571 -- iter: 0736/2948
[A[ATraining Step: 954  | total loss: [1m[32m0.10927[0m[0m | time: 298.171s
[2K
| Adam | epoch: 011 | loss: 0.10927 - acc: 0.9614 -- iter: 0768/2948
[A[ATraining Step: 955  | total loss: [1m[32m0.10892[0m[0m | time: 311.216s
[2K
| Adam | epoch: 011 | loss: 0.10892 - acc: 0.9652 -- iter: 0800/2948
[A[ATraining Step: 956  | total loss: [1m[32m0.10539[0m[0m | time: 324.725s
[2K
| Adam | epoch: 011 | loss: 0.10539 - acc: 0.9656 -- iter: 0832/2948
[A[ATraining Step: 957  | total loss: [1m[32m0.09985[0m[0m | time: 337.742s
[2K
| Adam | epoch: 011 | loss: 0.09985 - acc: 0.9659 -- iter: 0864/2948
[A[ATraining Step: 958  | total loss: [1m[32m0.09614[0m[0m | time: 351.184s
[2K
| Adam | epoch: 011 | loss: 0.09614 - acc: 0.9693 -- iter: 0896/2948
[A[ATraining Step: 959  | total loss: [1m[32m0.09071[0m[0m | time: 364.114s
[2K
| Adam | epoch: 011 | loss: 0.09071 - acc: 0.9693 -- iter: 0928/2948
[A[ATraining Step: 960  | total loss: [1m[32m0.08909[0m[0m | time: 377.770s
[2K
| Adam | epoch: 011 | loss: 0.08909 - acc: 0.9692 -- iter: 0960/2948
[A[ATraining Step: 961  | total loss: [1m[32m0.08157[0m[0m | time: 391.126s
[2K
| Adam | epoch: 011 | loss: 0.08157 - acc: 0.9723 -- iter: 0992/2948
[A[ATraining Step: 962  | total loss: [1m[32m0.07967[0m[0m | time: 404.736s
[2K
| Adam | epoch: 011 | loss: 0.07967 - acc: 0.9719 -- iter: 1024/2948
[A[ATraining Step: 963  | total loss: [1m[32m0.10513[0m[0m | time: 418.060s
[2K
| Adam | epoch: 011 | loss: 0.10513 - acc: 0.9685 -- iter: 1056/2948
[A[ATraining Step: 964  | total loss: [1m[32m0.09844[0m[0m | time: 431.336s
[2K
| Adam | epoch: 011 | loss: 0.09844 - acc: 0.9716 -- iter: 1088/2948
[A[ATraining Step: 965  | total loss: [1m[32m0.08920[0m[0m | time: 444.548s
[2K
| Adam | epoch: 011 | loss: 0.08920 - acc: 0.9745 -- iter: 1120/2948
[A[ATraining Step: 966  | total loss: [1m[32m0.09404[0m[0m | time: 457.878s
[2K
| Adam | epoch: 011 | loss: 0.09404 - acc: 0.9708 -- iter: 1152/2948
[A[ATraining Step: 967  | total loss: [1m[32m0.09899[0m[0m | time: 471.211s
[2K
| Adam | epoch: 011 | loss: 0.09899 - acc: 0.9674 -- iter: 1184/2948
[A[ATraining Step: 968  | total loss: [1m[32m0.12881[0m[0m | time: 484.113s
[2K
| Adam | epoch: 011 | loss: 0.12881 - acc: 0.9551 -- iter: 1216/2948
[A[ATraining Step: 969  | total loss: [1m[32m0.13452[0m[0m | time: 497.025s
[2K
| Adam | epoch: 011 | loss: 0.13452 - acc: 0.9533 -- iter: 1248/2948
[A[ATraining Step: 970  | total loss: [1m[32m0.13976[0m[0m | time: 510.264s
[2K
| Adam | epoch: 011 | loss: 0.13976 - acc: 0.9486 -- iter: 1280/2948
[A[ATraining Step: 971  | total loss: [1m[32m0.14011[0m[0m | time: 523.672s
[2K
| Adam | epoch: 011 | loss: 0.14011 - acc: 0.9475 -- iter: 1312/2948
[A[ATraining Step: 972  | total loss: [1m[32m0.14318[0m[0m | time: 536.858s
[2K
| Adam | epoch: 011 | loss: 0.14318 - acc: 0.9465 -- iter: 1344/2948
[A[ATraining Step: 973  | total loss: [1m[32m0.15666[0m[0m | time: 550.355s
[2K
| Adam | epoch: 011 | loss: 0.15666 - acc: 0.9456 -- iter: 1376/2948
[A[ATraining Step: 974  | total loss: [1m[32m0.19181[0m[0m | time: 563.645s
[2K
| Adam | epoch: 011 | loss: 0.19181 - acc: 0.9385 -- iter: 1408/2948
[A[ATraining Step: 975  | total loss: [1m[32m0.18043[0m[0m | time: 577.014s
[2K
| Adam | epoch: 011 | loss: 0.18043 - acc: 0.9416 -- iter: 1440/2948
[A[ATraining Step: 976  | total loss: [1m[32m0.17976[0m[0m | time: 589.984s
[2K
| Adam | epoch: 011 | loss: 0.17976 - acc: 0.9412 -- iter: 1472/2948
[A[ATraining Step: 977  | total loss: [1m[32m0.16610[0m[0m | time: 603.437s
[2K
| Adam | epoch: 011 | loss: 0.16610 - acc: 0.9470 -- iter: 1504/2948
[A[ATraining Step: 978  | total loss: [1m[32m0.15110[0m[0m | time: 616.785s
[2K
| Adam | epoch: 011 | loss: 0.15110 - acc: 0.9523 -- iter: 1536/2948
[A[ATraining Step: 979  | total loss: [1m[32m0.15769[0m[0m | time: 630.434s
[2K
| Adam | epoch: 011 | loss: 0.15769 - acc: 0.9540 -- iter: 1568/2948
[A[ATraining Step: 980  | total loss: [1m[32m0.14856[0m[0m | time: 643.702s
[2K
| Adam | epoch: 011 | loss: 0.14856 - acc: 0.9555 -- iter: 1600/2948
[A[ATraining Step: 981  | total loss: [1m[32m0.15562[0m[0m | time: 657.249s
[2K
| Adam | epoch: 011 | loss: 0.15562 - acc: 0.9537 -- iter: 1632/2948
[A[ATraining Step: 982  | total loss: [1m[32m0.14103[0m[0m | time: 670.370s
[2K
| Adam | epoch: 011 | loss: 0.14103 - acc: 0.9583 -- iter: 1664/2948
[A[ATraining Step: 983  | total loss: [1m[32m0.15230[0m[0m | time: 683.958s
[2K
| Adam | epoch: 011 | loss: 0.15230 - acc: 0.9531 -- iter: 1696/2948
[A[ATraining Step: 984  | total loss: [1m[32m0.15312[0m[0m | time: 697.059s
[2K
| Adam | epoch: 011 | loss: 0.15312 - acc: 0.9547 -- iter: 1728/2948
[A[ATraining Step: 985  | total loss: [1m[32m0.16883[0m[0m | time: 710.828s
[2K
| Adam | epoch: 011 | loss: 0.16883 - acc: 0.9436 -- iter: 1760/2948
[A[ATraining Step: 986  | total loss: [1m[32m0.17849[0m[0m | time: 723.988s
[2K
| Adam | epoch: 011 | loss: 0.17849 - acc: 0.9367 -- iter: 1792/2948
[A[ATraining Step: 987  | total loss: [1m[32m0.16270[0m[0m | time: 737.079s
[2K
| Adam | epoch: 011 | loss: 0.16270 - acc: 0.9430 -- iter: 1824/2948
[A[ATraining Step: 988  | total loss: [1m[32m0.15392[0m[0m | time: 750.267s
[2K
| Adam | epoch: 011 | loss: 0.15392 - acc: 0.9456 -- iter: 1856/2948
[A[ATraining Step: 989  | total loss: [1m[32m0.17518[0m[0m | time: 763.336s
[2K
| Adam | epoch: 011 | loss: 0.17518 - acc: 0.9385 -- iter: 1888/2948
[A[ATraining Step: 990  | total loss: [1m[32m0.16588[0m[0m | time: 776.565s
[2K
| Adam | epoch: 011 | loss: 0.16588 - acc: 0.9447 -- iter: 1920/2948
[A[ATraining Step: 991  | total loss: [1m[32m0.15287[0m[0m | time: 789.760s
[2K
| Adam | epoch: 011 | loss: 0.15287 - acc: 0.9502 -- iter: 1952/2948
[A[ATraining Step: 992  | total loss: [1m[32m0.14731[0m[0m | time: 803.228s
[2K
| Adam | epoch: 011 | loss: 0.14731 - acc: 0.9552 -- iter: 1984/2948
[A[ATraining Step: 993  | total loss: [1m[32m0.13649[0m[0m | time: 816.657s
[2K
| Adam | epoch: 011 | loss: 0.13649 - acc: 0.9597 -- iter: 2016/2948
[A[ATraining Step: 994  | total loss: [1m[32m0.13086[0m[0m | time: 829.900s
[2K
| Adam | epoch: 011 | loss: 0.13086 - acc: 0.9606 -- iter: 2048/2948
[A[ATraining Step: 995  | total loss: [1m[32m0.13634[0m[0m | time: 843.009s
[2K
| Adam | epoch: 011 | loss: 0.13634 - acc: 0.9520 -- iter: 2080/2948
[A[ATraining Step: 996  | total loss: [1m[32m0.14549[0m[0m | time: 855.918s
[2K
| Adam | epoch: 011 | loss: 0.14549 - acc: 0.9475 -- iter: 2112/2948
[A[ATraining Step: 997  | total loss: [1m[32m0.13465[0m[0m | time: 869.218s
[2K
| Adam | epoch: 011 | loss: 0.13465 - acc: 0.9527 -- iter: 2144/2948
[A[ATraining Step: 998  | total loss: [1m[32m0.12680[0m[0m | time: 883.210s
[2K
| Adam | epoch: 011 | loss: 0.12680 - acc: 0.9574 -- iter: 2176/2948
[A[ATraining Step: 999  | total loss: [1m[32m0.12024[0m[0m | time: 897.249s
[2K
| Adam | epoch: 011 | loss: 0.12024 - acc: 0.9617 -- iter: 2208/2948
[A[ATraining Step: 1000  | total loss: [1m[32m0.11474[0m[0m | time: 972.536s
[2K
| Adam | epoch: 011 | loss: 0.11474 - acc: 0.9655 | val_loss: 0.24048 - val_acc: 0.9143 -- iter: 2240/2948
--
Training Step: 1001  | total loss: [1m[32m0.10582[0m[0m | time: 985.972s
[2K
| Adam | epoch: 011 | loss: 0.10582 - acc: 0.9690 -- iter: 2272/2948
[A[ATraining Step: 1002  | total loss: [1m[32m0.12768[0m[0m | time: 999.461s
[2K
| Adam | epoch: 011 | loss: 0.12768 - acc: 0.9689 -- iter: 2304/2948
[A[ATraining Step: 1003  | total loss: [1m[32m0.12054[0m[0m | time: 1012.771s
[2K
| Adam | epoch: 011 | loss: 0.12054 - acc: 0.9689 -- iter: 2336/2948
[A[ATraining Step: 1004  | total loss: [1m[32m0.12679[0m[0m | time: 1026.319s
[2K
| Adam | epoch: 011 | loss: 0.12679 - acc: 0.9627 -- iter: 2368/2948
[A[ATraining Step: 1005  | total loss: [1m[32m0.11616[0m[0m | time: 1039.583s
[2K
| Adam | epoch: 011 | loss: 0.11616 - acc: 0.9664 -- iter: 2400/2948
[A[ATraining Step: 1006  | total loss: [1m[32m0.10751[0m[0m | time: 1053.063s
[2K
| Adam | epoch: 011 | loss: 0.10751 - acc: 0.9698 -- iter: 2432/2948
[A[ATraining Step: 1007  | total loss: [1m[32m0.11186[0m[0m | time: 1066.269s
[2K
| Adam | epoch: 011 | loss: 0.11186 - acc: 0.9634 -- iter: 2464/2948
[A[ATraining Step: 1008  | total loss: [1m[32m0.10870[0m[0m | time: 1079.574s
[2K
| Adam | epoch: 011 | loss: 0.10870 - acc: 0.9639 -- iter: 2496/2948
[A[ATraining Step: 1009  | total loss: [1m[32m0.10351[0m[0m | time: 1092.594s
[2K
| Adam | epoch: 011 | loss: 0.10351 - acc: 0.9644 -- iter: 2528/2948
[A[ATraining Step: 1010  | total loss: [1m[32m0.09631[0m[0m | time: 1106.384s
[2K
| Adam | epoch: 011 | loss: 0.09631 - acc: 0.9680 -- iter: 2560/2948
[A[ATraining Step: 1011  | total loss: [1m[32m0.09250[0m[0m | time: 1119.938s
[2K
| Adam | epoch: 011 | loss: 0.09250 - acc: 0.9712 -- iter: 2592/2948
[A[ATraining Step: 1012  | total loss: [1m[32m0.10200[0m[0m | time: 1133.382s
[2K
| Adam | epoch: 011 | loss: 0.10200 - acc: 0.9647 -- iter: 2624/2948
[A[ATraining Step: 1013  | total loss: [1m[32m0.09466[0m[0m | time: 1146.671s
[2K
| Adam | epoch: 011 | loss: 0.09466 - acc: 0.9682 -- iter: 2656/2948
[A[ATraining Step: 1014  | total loss: [1m[32m0.08673[0m[0m | time: 1160.041s
[2K
| Adam | epoch: 011 | loss: 0.08673 - acc: 0.9714 -- iter: 2688/2948
[A[ATraining Step: 1015  | total loss: [1m[32m0.08031[0m[0m | time: 1173.758s
[2K
| Adam | epoch: 011 | loss: 0.08031 - acc: 0.9743 -- iter: 2720/2948
[A[ATraining Step: 1016  | total loss: [1m[32m0.08009[0m[0m | time: 1187.071s
[2K
| Adam | epoch: 011 | loss: 0.08009 - acc: 0.9737 -- iter: 2752/2948
[A[ATraining Step: 1017  | total loss: [1m[32m0.07391[0m[0m | time: 1200.277s
[2K
| Adam | epoch: 011 | loss: 0.07391 - acc: 0.9763 -- iter: 2784/2948
[A[ATraining Step: 1018  | total loss: [1m[32m0.07800[0m[0m | time: 1213.180s
[2K
| Adam | epoch: 011 | loss: 0.07800 - acc: 0.9725 -- iter: 2816/2948
[A[ATraining Step: 1019  | total loss: [1m[32m0.07412[0m[0m | time: 1226.345s
[2K
| Adam | epoch: 011 | loss: 0.07412 - acc: 0.9752 -- iter: 2848/2948
[A[ATraining Step: 1020  | total loss: [1m[32m0.06877[0m[0m | time: 1240.256s
[2K
| Adam | epoch: 011 | loss: 0.06877 - acc: 0.9777 -- iter: 2880/2948
[A[ATraining Step: 1021  | total loss: [1m[32m0.06530[0m[0m | time: 1254.257s
[2K
| Adam | epoch: 011 | loss: 0.06530 - acc: 0.9799 -- iter: 2912/2948
[A[ATraining Step: 1022  | total loss: [1m[32m0.06984[0m[0m | time: 1268.193s
[2K
| Adam | epoch: 011 | loss: 0.06984 - acc: 0.9788 -- iter: 2944/2948
[A[ATraining Step: 1023  | total loss: [1m[32m0.07876[0m[0m | time: 1336.722s
[2K
| Adam | epoch: 011 | loss: 0.07876 - acc: 0.9715 | val_loss: 0.22553 - val_acc: 0.9197 -- iter: 2948/2948
--
Training Step: 1024  | total loss: [1m[32m0.07296[0m[0m | time: 13.654s
[2K
| Adam | epoch: 012 | loss: 0.07296 - acc: 0.9744 -- iter: 0032/2948
[A[ATraining Step: 1025  | total loss: [1m[32m0.06746[0m[0m | time: 27.252s
[2K
| Adam | epoch: 012 | loss: 0.06746 - acc: 0.9770 -- iter: 0064/2948
[A[ATraining Step: 1026  | total loss: [1m[32m0.07106[0m[0m | time: 40.214s
[2K
| Adam | epoch: 012 | loss: 0.07106 - acc: 0.9730 -- iter: 0096/2948
[A[ATraining Step: 1027  | total loss: [1m[32m0.06787[0m[0m | time: 53.346s
[2K
| Adam | epoch: 012 | loss: 0.06787 - acc: 0.9757 -- iter: 0128/2948
[A[ATraining Step: 1028  | total loss: [1m[32m0.06402[0m[0m | time: 67.262s
[2K
| Adam | epoch: 012 | loss: 0.06402 - acc: 0.9781 -- iter: 0160/2948
[A[ATraining Step: 1029  | total loss: [1m[32m0.05940[0m[0m | time: 80.639s
[2K
| Adam | epoch: 012 | loss: 0.05940 - acc: 0.9803 -- iter: 0192/2948
[A[ATraining Step: 1030  | total loss: [1m[32m0.05788[0m[0m | time: 93.371s
[2K
| Adam | epoch: 012 | loss: 0.05788 - acc: 0.9823 -- iter: 0224/2948
[A[ATraining Step: 1031  | total loss: [1m[32m0.05318[0m[0m | time: 106.609s
[2K
| Adam | epoch: 012 | loss: 0.05318 - acc: 0.9841 -- iter: 0256/2948
[A[ATraining Step: 1032  | total loss: [1m[32m0.04986[0m[0m | time: 119.977s
[2K
| Adam | epoch: 012 | loss: 0.04986 - acc: 0.9857 -- iter: 0288/2948
[A[ATraining Step: 1033  | total loss: [1m[32m0.04622[0m[0m | time: 122.751s
[2K
| Adam | epoch: 012 | loss: 0.04622 - acc: 0.9871 -- iter: 0320/2948
[A[ATraining Step: 1034  | total loss: [1m[32m0.04163[0m[0m | time: 125.836s
[2K
| Adam | epoch: 012 | loss: 0.04163 - acc: 0.9884 -- iter: 0352/2948
[A[ATraining Step: 1035  | total loss: [1m[32m0.03749[0m[0m | time: 139.371s
[2K
| Adam | epoch: 012 | loss: 0.03749 - acc: 0.9895 -- iter: 0384/2948
[A[ATraining Step: 1036  | total loss: [1m[32m0.03452[0m[0m | time: 152.375s
[2K
| Adam | epoch: 012 | loss: 0.03452 - acc: 0.9906 -- iter: 0416/2948
[A[ATraining Step: 1037  | total loss: [1m[32m0.03430[0m[0m | time: 165.371s
[2K
| Adam | epoch: 012 | loss: 0.03430 - acc: 0.9884 -- iter: 0448/2948
[A[ATraining Step: 1038  | total loss: [1m[32m0.04902[0m[0m | time: 179.027s
[2K
| Adam | epoch: 012 | loss: 0.04902 - acc: 0.9864 -- iter: 0480/2948
[A[ATraining Step: 1039  | total loss: [1m[32m0.04523[0m[0m | time: 192.211s
[2K
| Adam | epoch: 012 | loss: 0.04523 - acc: 0.9878 -- iter: 0512/2948
[A[ATraining Step: 1040  | total loss: [1m[32m0.04313[0m[0m | time: 205.194s
[2K
| Adam | epoch: 012 | loss: 0.04313 - acc: 0.9890 -- iter: 0544/2948
[A[ATraining Step: 1041  | total loss: [1m[32m0.04733[0m[0m | time: 218.432s
[2K
| Adam | epoch: 012 | loss: 0.04733 - acc: 0.9839 -- iter: 0576/2948
[A[ATraining Step: 1042  | total loss: [1m[32m0.04554[0m[0m | time: 231.473s
[2K
| Adam | epoch: 012 | loss: 0.04554 - acc: 0.9824 -- iter: 0608/2948
[A[ATraining Step: 1043  | total loss: [1m[32m0.04688[0m[0m | time: 244.388s
[2K
| Adam | epoch: 012 | loss: 0.04688 - acc: 0.9810 -- iter: 0640/2948
[A[ATraining Step: 1044  | total loss: [1m[32m0.04899[0m[0m | time: 256.689s
[2K
| Adam | epoch: 012 | loss: 0.04899 - acc: 0.9798 -- iter: 0672/2948
[A[ATraining Step: 1045  | total loss: [1m[32m0.05383[0m[0m | time: 270.413s
[2K
| Adam | epoch: 012 | loss: 0.05383 - acc: 0.9755 -- iter: 0704/2948
[A[ATraining Step: 1046  | total loss: [1m[32m0.05124[0m[0m | time: 283.251s
[2K
| Adam | epoch: 012 | loss: 0.05124 - acc: 0.9780 -- iter: 0736/2948
[A[ATraining Step: 1047  | total loss: [1m[32m0.06865[0m[0m | time: 296.354s
[2K
| Adam | epoch: 012 | loss: 0.06865 - acc: 0.9677 -- iter: 0768/2948
[A[ATraining Step: 1048  | total loss: [1m[32m0.06378[0m[0m | time: 309.714s
[2K
| Adam | epoch: 012 | loss: 0.06378 - acc: 0.9709 -- iter: 0800/2948
[A[ATraining Step: 1049  | total loss: [1m[32m0.05780[0m[0m | time: 323.145s
[2K
| Adam | epoch: 012 | loss: 0.05780 - acc: 0.9738 -- iter: 0832/2948
[A[ATraining Step: 1050  | total loss: [1m[32m0.06090[0m[0m | time: 336.602s
[2K
| Adam | epoch: 012 | loss: 0.06090 - acc: 0.9702 -- iter: 0864/2948
[A[ATraining Step: 1051  | total loss: [1m[32m0.07596[0m[0m | time: 350.091s
[2K
| Adam | epoch: 012 | loss: 0.07596 - acc: 0.9701 -- iter: 0896/2948
[A[ATraining Step: 1052  | total loss: [1m[32m0.07052[0m[0m | time: 363.140s
[2K
| Adam | epoch: 012 | loss: 0.07052 - acc: 0.9730 -- iter: 0928/2948
[A[ATraining Step: 1053  | total loss: [1m[32m0.06550[0m[0m | time: 376.442s
[2K
| Adam | epoch: 012 | loss: 0.06550 - acc: 0.9757 -- iter: 0960/2948
[A[ATraining Step: 1054  | total loss: [1m[32m0.06032[0m[0m | time: 389.607s
[2K
| Adam | epoch: 012 | loss: 0.06032 - acc: 0.9782 -- iter: 0992/2948
[A[ATraining Step: 1055  | total loss: [1m[32m0.07628[0m[0m | time: 403.020s
[2K
| Adam | epoch: 012 | loss: 0.07628 - acc: 0.9772 -- iter: 1024/2948
[A[ATraining Step: 1056  | total loss: [1m[32m0.06908[0m[0m | time: 416.649s
[2K
| Adam | epoch: 012 | loss: 0.06908 - acc: 0.9795 -- iter: 1056/2948
[A[ATraining Step: 1057  | total loss: [1m[32m0.06726[0m[0m | time: 429.833s
[2K
| Adam | epoch: 012 | loss: 0.06726 - acc: 0.9784 -- iter: 1088/2948
[A[ATraining Step: 1058  | total loss: [1m[32m0.10531[0m[0m | time: 442.964s
[2K
| Adam | epoch: 012 | loss: 0.10531 - acc: 0.9712 -- iter: 1120/2948
[A[ATraining Step: 1059  | total loss: [1m[32m0.09591[0m[0m | time: 456.280s
[2K
| Adam | epoch: 012 | loss: 0.09591 - acc: 0.9741 -- iter: 1152/2948
[A[ATraining Step: 1060  | total loss: [1m[32m0.09258[0m[0m | time: 469.514s
[2K
| Adam | epoch: 012 | loss: 0.09258 - acc: 0.9736 -- iter: 1184/2948
[A[ATraining Step: 1061  | total loss: [1m[32m0.08535[0m[0m | time: 482.554s
[2K
| Adam | epoch: 012 | loss: 0.08535 - acc: 0.9762 -- iter: 1216/2948
[A[ATraining Step: 1062  | total loss: [1m[32m0.07707[0m[0m | time: 495.973s
[2K
| Adam | epoch: 012 | loss: 0.07707 - acc: 0.9786 -- iter: 1248/2948
[A[ATraining Step: 1063  | total loss: [1m[32m0.08682[0m[0m | time: 509.212s
[2K
| Adam | epoch: 012 | loss: 0.08682 - acc: 0.9713 -- iter: 1280/2948
[A[ATraining Step: 1064  | total loss: [1m[32m0.08397[0m[0m | time: 522.446s
[2K
| Adam | epoch: 012 | loss: 0.08397 - acc: 0.9711 -- iter: 1312/2948
[A[ATraining Step: 1065  | total loss: [1m[32m0.07739[0m[0m | time: 535.608s
[2K
| Adam | epoch: 012 | loss: 0.07739 - acc: 0.9740 -- iter: 1344/2948
[A[ATraining Step: 1066  | total loss: [1m[32m0.07520[0m[0m | time: 549.180s
[2K
| Adam | epoch: 012 | loss: 0.07520 - acc: 0.9735 -- iter: 1376/2948
[A[ATraining Step: 1067  | total loss: [1m[32m0.07481[0m[0m | time: 562.352s
[2K
| Adam | epoch: 012 | loss: 0.07481 - acc: 0.9730 -- iter: 1408/2948
[A[ATraining Step: 1068  | total loss: [1m[32m0.08974[0m[0m | time: 575.529s
[2K
| Adam | epoch: 012 | loss: 0.08974 - acc: 0.9663 -- iter: 1440/2948
[A[ATraining Step: 1069  | total loss: [1m[32m0.08538[0m[0m | time: 588.439s
[2K
| Adam | epoch: 012 | loss: 0.08538 - acc: 0.9697 -- iter: 1472/2948
[A[ATraining Step: 1070  | total loss: [1m[32m0.08510[0m[0m | time: 601.461s
[2K
| Adam | epoch: 012 | loss: 0.08510 - acc: 0.9696 -- iter: 1504/2948
[A[ATraining Step: 1071  | total loss: [1m[32m0.08139[0m[0m | time: 614.572s
[2K
| Adam | epoch: 012 | loss: 0.08139 - acc: 0.9726 -- iter: 1536/2948
[A[ATraining Step: 1072  | total loss: [1m[32m0.07667[0m[0m | time: 627.771s
[2K
| Adam | epoch: 012 | loss: 0.07667 - acc: 0.9754 -- iter: 1568/2948
[A[ATraining Step: 1073  | total loss: [1m[32m0.07426[0m[0m | time: 640.598s
[2K
| Adam | epoch: 012 | loss: 0.07426 - acc: 0.9778 -- iter: 1600/2948
[A[ATraining Step: 1074  | total loss: [1m[32m0.06984[0m[0m | time: 653.791s
[2K
| Adam | epoch: 012 | loss: 0.06984 - acc: 0.9800 -- iter: 1632/2948
[A[ATraining Step: 1075  | total loss: [1m[32m0.06659[0m[0m | time: 667.044s
[2K
| Adam | epoch: 012 | loss: 0.06659 - acc: 0.9820 -- iter: 1664/2948
[A[ATraining Step: 1076  | total loss: [1m[32m0.07345[0m[0m | time: 680.172s
[2K
| Adam | epoch: 012 | loss: 0.07345 - acc: 0.9776 -- iter: 1696/2948
[A[ATraining Step: 1077  | total loss: [1m[32m0.08045[0m[0m | time: 693.548s
[2K
| Adam | epoch: 012 | loss: 0.08045 - acc: 0.9736 -- iter: 1728/2948
[A[ATraining Step: 1078  | total loss: [1m[32m0.07735[0m[0m | time: 706.861s
[2K
| Adam | epoch: 012 | loss: 0.07735 - acc: 0.9731 -- iter: 1760/2948
[A[ATraining Step: 1079  | total loss: [1m[32m0.07123[0m[0m | time: 720.072s
[2K
| Adam | epoch: 012 | loss: 0.07123 - acc: 0.9758 -- iter: 1792/2948
[A[ATraining Step: 1080  | total loss: [1m[32m0.06622[0m[0m | time: 732.906s
[2K
| Adam | epoch: 012 | loss: 0.06622 - acc: 0.9782 -- iter: 1824/2948
[A[ATraining Step: 1081  | total loss: [1m[32m0.06502[0m[0m | time: 745.773s
[2K
| Adam | epoch: 012 | loss: 0.06502 - acc: 0.9804 -- iter: 1856/2948
[A[ATraining Step: 1082  | total loss: [1m[32m0.06617[0m[0m | time: 758.872s
[2K
| Adam | epoch: 012 | loss: 0.06617 - acc: 0.9792 -- iter: 1888/2948
[A[ATraining Step: 1083  | total loss: [1m[32m0.06226[0m[0m | time: 772.424s
[2K
| Adam | epoch: 012 | loss: 0.06226 - acc: 0.9782 -- iter: 1920/2948
[A[ATraining Step: 1084  | total loss: [1m[32m0.05735[0m[0m | time: 786.065s
[2K
| Adam | epoch: 012 | loss: 0.05735 - acc: 0.9804 -- iter: 1952/2948
[A[ATraining Step: 1085  | total loss: [1m[32m0.05641[0m[0m | time: 798.940s
[2K
| Adam | epoch: 012 | loss: 0.05641 - acc: 0.9792 -- iter: 1984/2948
[A[ATraining Step: 1086  | total loss: [1m[32m0.05578[0m[0m | time: 812.554s
[2K
| Adam | epoch: 012 | loss: 0.05578 - acc: 0.9782 -- iter: 2016/2948
[A[ATraining Step: 1087  | total loss: [1m[32m0.05903[0m[0m | time: 825.899s
[2K
| Adam | epoch: 012 | loss: 0.05903 - acc: 0.9772 -- iter: 2048/2948
[A[ATraining Step: 1088  | total loss: [1m[32m0.05553[0m[0m | time: 839.427s
[2K
| Adam | epoch: 012 | loss: 0.05553 - acc: 0.9795 -- iter: 2080/2948
[A[ATraining Step: 1089  | total loss: [1m[32m0.05170[0m[0m | time: 852.453s
[2K
| Adam | epoch: 012 | loss: 0.05170 - acc: 0.9815 -- iter: 2112/2948
[A[ATraining Step: 1090  | total loss: [1m[32m0.04742[0m[0m | time: 866.024s
[2K
| Adam | epoch: 012 | loss: 0.04742 - acc: 0.9834 -- iter: 2144/2948
[A[ATraining Step: 1091  | total loss: [1m[32m0.04504[0m[0m | time: 878.997s
[2K
| Adam | epoch: 012 | loss: 0.04504 - acc: 0.9850 -- iter: 2176/2948
[A[ATraining Step: 1092  | total loss: [1m[32m0.04317[0m[0m | time: 892.223s
[2K
| Adam | epoch: 012 | loss: 0.04317 - acc: 0.9865 -- iter: 2208/2948
[A[ATraining Step: 1093  | total loss: [1m[32m0.04673[0m[0m | time: 905.470s
[2K
| Adam | epoch: 012 | loss: 0.04673 - acc: 0.9848 -- iter: 2240/2948
[A[ATraining Step: 1094  | total loss: [1m[32m0.04307[0m[0m | time: 918.769s
[2K
| Adam | epoch: 012 | loss: 0.04307 - acc: 0.9863 -- iter: 2272/2948
[A[ATraining Step: 1095  | total loss: [1m[32m0.04001[0m[0m | time: 931.756s
[2K
| Adam | epoch: 012 | loss: 0.04001 - acc: 0.9877 -- iter: 2304/2948
[A[ATraining Step: 1096  | total loss: [1m[32m0.09780[0m[0m | time: 944.460s
[2K
| Adam | epoch: 012 | loss: 0.09780 - acc: 0.9795 -- iter: 2336/2948
[A[ATraining Step: 1097  | total loss: [1m[32m0.08834[0m[0m | time: 957.351s
[2K
| Adam | epoch: 012 | loss: 0.08834 - acc: 0.9816 -- iter: 2368/2948
[A[ATraining Step: 1098  | total loss: [1m[32m0.08135[0m[0m | time: 970.237s
[2K
| Adam | epoch: 012 | loss: 0.08135 - acc: 0.9834 -- iter: 2400/2948
[A[ATraining Step: 1099  | total loss: [1m[32m0.07514[0m[0m | time: 982.993s
[2K
| Adam | epoch: 012 | loss: 0.07514 - acc: 0.9851 -- iter: 2432/2948
[A[ATraining Step: 1100  | total loss: [1m[32m0.07551[0m[0m | time: 996.275s
[2K
| Adam | epoch: 012 | loss: 0.07551 - acc: 0.9834 -- iter: 2464/2948
[A[ATraining Step: 1101  | total loss: [1m[32m0.06956[0m[0m | time: 1009.253s
[2K
| Adam | epoch: 012 | loss: 0.06956 - acc: 0.9851 -- iter: 2496/2948
[A[ATraining Step: 1102  | total loss: [1m[32m0.06402[0m[0m | time: 1022.543s
[2K
| Adam | epoch: 012 | loss: 0.06402 - acc: 0.9866 -- iter: 2528/2948
[A[ATraining Step: 1103  | total loss: [1m[32m0.06921[0m[0m | time: 1036.146s
[2K
| Adam | epoch: 012 | loss: 0.06921 - acc: 0.9817 -- iter: 2560/2948
[A[ATraining Step: 1104  | total loss: [1m[32m0.06385[0m[0m | time: 1049.022s
[2K
| Adam | epoch: 012 | loss: 0.06385 - acc: 0.9835 -- iter: 2592/2948
[A[ATraining Step: 1105  | total loss: [1m[32m0.06461[0m[0m | time: 1061.962s
[2K
| Adam | epoch: 012 | loss: 0.06461 - acc: 0.9820 -- iter: 2624/2948
[A[ATraining Step: 1106  | total loss: [1m[32m0.05914[0m[0m | time: 1075.239s
[2K
| Adam | epoch: 012 | loss: 0.05914 - acc: 0.9838 -- iter: 2656/2948
[A[ATraining Step: 1107  | total loss: [1m[32m0.05513[0m[0m | time: 1088.545s
[2K
| Adam | epoch: 012 | loss: 0.05513 - acc: 0.9854 -- iter: 2688/2948
[A[ATraining Step: 1108  | total loss: [1m[32m0.05263[0m[0m | time: 1101.698s
[2K
| Adam | epoch: 012 | loss: 0.05263 - acc: 0.9869 -- iter: 2720/2948
[A[ATraining Step: 1109  | total loss: [1m[32m0.06003[0m[0m | time: 1114.939s
[2K
| Adam | epoch: 012 | loss: 0.06003 - acc: 0.9820 -- iter: 2752/2948
[A[ATraining Step: 1110  | total loss: [1m[32m0.05610[0m[0m | time: 1128.145s
[2K
| Adam | epoch: 012 | loss: 0.05610 - acc: 0.9838 -- iter: 2784/2948
[A[ATraining Step: 1111  | total loss: [1m[32m0.05200[0m[0m | time: 1141.219s
[2K
| Adam | epoch: 012 | loss: 0.05200 - acc: 0.9854 -- iter: 2816/2948
[A[ATraining Step: 1112  | total loss: [1m[32m0.04949[0m[0m | time: 1155.050s
[2K
| Adam | epoch: 012 | loss: 0.04949 - acc: 0.9837 -- iter: 2848/2948
[A[ATraining Step: 1113  | total loss: [1m[32m0.04506[0m[0m | time: 1169.281s
[2K
| Adam | epoch: 012 | loss: 0.04506 - acc: 0.9854 -- iter: 2880/2948
[A[ATraining Step: 1114  | total loss: [1m[32m0.04394[0m[0m | time: 1183.241s
[2K
| Adam | epoch: 012 | loss: 0.04394 - acc: 0.9837 -- iter: 2912/2948
[A[ATraining Step: 1115  | total loss: [1m[32m0.05150[0m[0m | time: 1196.528s
[2K
| Adam | epoch: 012 | loss: 0.05150 - acc: 0.9759 -- iter: 2944/2948
[A[ATraining Step: 1116  | total loss: [1m[32m0.04856[0m[0m | time: 1265.422s
[2K
| Adam | epoch: 012 | loss: 0.04856 - acc: 0.9784 | val_loss: 0.29509 - val_acc: 0.9089 -- iter: 2948/2948
--
Training Step: 1117  | total loss: [1m[32m0.04488[0m[0m | time: 13.211s
[2K
| Adam | epoch: 013 | loss: 0.04488 - acc: 0.9805 -- iter: 0032/2948
[A[ATraining Step: 1118  | total loss: [1m[32m0.05110[0m[0m | time: 26.526s
[2K
| Adam | epoch: 013 | loss: 0.05110 - acc: 0.9762 -- iter: 0064/2948
[A[ATraining Step: 1119  | total loss: [1m[32m0.05535[0m[0m | time: 39.733s
[2K
| Adam | epoch: 013 | loss: 0.05535 - acc: 0.9723 -- iter: 0096/2948
[A[ATraining Step: 1120  | total loss: [1m[32m0.05397[0m[0m | time: 52.636s
[2K
| Adam | epoch: 013 | loss: 0.05397 - acc: 0.9720 -- iter: 0128/2948
[A[ATraining Step: 1121  | total loss: [1m[32m0.05131[0m[0m | time: 65.718s
[2K
| Adam | epoch: 013 | loss: 0.05131 - acc: 0.9748 -- iter: 0160/2948
[A[ATraining Step: 1122  | total loss: [1m[32m0.05469[0m[0m | time: 78.502s
[2K
| Adam | epoch: 013 | loss: 0.05469 - acc: 0.9742 -- iter: 0192/2948
[A[ATraining Step: 1123  | total loss: [1m[32m0.04956[0m[0m | time: 91.763s
[2K
| Adam | epoch: 013 | loss: 0.04956 - acc: 0.9768 -- iter: 0224/2948
[A[ATraining Step: 1124  | total loss: [1m[32m0.04609[0m[0m | time: 104.872s
[2K
| Adam | epoch: 013 | loss: 0.04609 - acc: 0.9791 -- iter: 0256/2948
[A[ATraining Step: 1125  | total loss: [1m[32m0.04275[0m[0m | time: 117.977s
[2K
| Adam | epoch: 013 | loss: 0.04275 - acc: 0.9812 -- iter: 0288/2948
[A[ATraining Step: 1126  | total loss: [1m[32m0.04502[0m[0m | time: 131.254s
[2K
| Adam | epoch: 013 | loss: 0.04502 - acc: 0.9799 -- iter: 0320/2948
[A[ATraining Step: 1127  | total loss: [1m[32m0.04843[0m[0m | time: 134.378s
[2K
| Adam | epoch: 013 | loss: 0.04843 - acc: 0.9788 -- iter: 0352/2948
[A[ATraining Step: 1128  | total loss: [1m[32m0.07754[0m[0m | time: 137.898s
[2K
| Adam | epoch: 013 | loss: 0.07754 - acc: 0.9559 -- iter: 0384/2948
[A[ATraining Step: 1129  | total loss: [1m[32m0.07274[0m[0m | time: 150.778s
[2K
| Adam | epoch: 013 | loss: 0.07274 - acc: 0.9603 -- iter: 0416/2948
[A[ATraining Step: 1130  | total loss: [1m[32m0.07467[0m[0m | time: 164.153s
[2K
| Adam | epoch: 013 | loss: 0.07467 - acc: 0.9612 -- iter: 0448/2948
[A[ATraining Step: 1131  | total loss: [1m[32m0.07474[0m[0m | time: 177.557s
[2K
| Adam | epoch: 013 | loss: 0.07474 - acc: 0.9619 -- iter: 0480/2948
[A[ATraining Step: 1132  | total loss: [1m[32m0.06881[0m[0m | time: 190.945s
[2K
| Adam | epoch: 013 | loss: 0.06881 - acc: 0.9657 -- iter: 0512/2948
[A[ATraining Step: 1133  | total loss: [1m[32m0.06292[0m[0m | time: 204.085s
[2K
| Adam | epoch: 013 | loss: 0.06292 - acc: 0.9692 -- iter: 0544/2948
[A[ATraining Step: 1134  | total loss: [1m[32m0.05758[0m[0m | time: 217.736s
[2K
| Adam | epoch: 013 | loss: 0.05758 - acc: 0.9723 -- iter: 0576/2948
[A[ATraining Step: 1135  | total loss: [1m[32m0.05774[0m[0m | time: 231.115s
[2K
| Adam | epoch: 013 | loss: 0.05774 - acc: 0.9719 -- iter: 0608/2948
[A[ATraining Step: 1136  | total loss: [1m[32m0.06454[0m[0m | time: 244.102s
[2K
| Adam | epoch: 013 | loss: 0.06454 - acc: 0.9653 -- iter: 0640/2948
[A[ATraining Step: 1137  | total loss: [1m[32m0.05921[0m[0m | time: 257.459s
[2K
| Adam | epoch: 013 | loss: 0.05921 - acc: 0.9688 -- iter: 0672/2948
[A[ATraining Step: 1138  | total loss: [1m[32m0.05362[0m[0m | time: 270.741s
[2K
| Adam | epoch: 013 | loss: 0.05362 - acc: 0.9719 -- iter: 0704/2948
[A[ATraining Step: 1139  | total loss: [1m[32m0.05153[0m[0m | time: 283.906s
[2K
| Adam | epoch: 013 | loss: 0.05153 - acc: 0.9747 -- iter: 0736/2948
[A[ATraining Step: 1140  | total loss: [1m[32m0.06653[0m[0m | time: 296.940s
[2K
| Adam | epoch: 013 | loss: 0.06653 - acc: 0.9679 -- iter: 0768/2948
[A[ATraining Step: 1141  | total loss: [1m[32m0.06964[0m[0m | time: 310.152s
[2K
| Adam | epoch: 013 | loss: 0.06964 - acc: 0.9680 -- iter: 0800/2948
[A[ATraining Step: 1142  | total loss: [1m[32m0.08472[0m[0m | time: 324.041s
[2K
| Adam | epoch: 013 | loss: 0.08472 - acc: 0.9649 -- iter: 0832/2948
[A[ATraining Step: 1143  | total loss: [1m[32m0.08157[0m[0m | time: 337.561s
[2K
| Adam | epoch: 013 | loss: 0.08157 - acc: 0.9653 -- iter: 0864/2948
[A[ATraining Step: 1144  | total loss: [1m[32m0.07547[0m[0m | time: 350.951s
[2K
| Adam | epoch: 013 | loss: 0.07547 - acc: 0.9688 -- iter: 0896/2948
[A[ATraining Step: 1145  | total loss: [1m[32m0.06881[0m[0m | time: 364.050s
[2K
| Adam | epoch: 013 | loss: 0.06881 - acc: 0.9719 -- iter: 0928/2948
[A[ATraining Step: 1146  | total loss: [1m[32m0.06379[0m[0m | time: 377.346s
[2K
| Adam | epoch: 013 | loss: 0.06379 - acc: 0.9747 -- iter: 0960/2948
[A[ATraining Step: 1147  | total loss: [1m[32m0.08397[0m[0m | time: 390.195s
[2K
| Adam | epoch: 013 | loss: 0.08397 - acc: 0.9741 -- iter: 0992/2948
[A[ATraining Step: 1148  | total loss: [1m[32m0.11091[0m[0m | time: 403.465s
[2K
| Adam | epoch: 013 | loss: 0.11091 - acc: 0.9705 -- iter: 1024/2948
[A[ATraining Step: 1149  | total loss: [1m[32m0.10358[0m[0m | time: 416.480s
[2K
| Adam | epoch: 013 | loss: 0.10358 - acc: 0.9703 -- iter: 1056/2948
[A[ATraining Step: 1150  | total loss: [1m[32m0.10019[0m[0m | time: 429.913s
[2K
| Adam | epoch: 013 | loss: 0.10019 - acc: 0.9701 -- iter: 1088/2948
[A[ATraining Step: 1151  | total loss: [1m[32m0.09273[0m[0m | time: 443.199s
[2K
| Adam | epoch: 013 | loss: 0.09273 - acc: 0.9731 -- iter: 1120/2948
[A[ATraining Step: 1152  | total loss: [1m[32m0.08441[0m[0m | time: 456.258s
[2K
| Adam | epoch: 013 | loss: 0.08441 - acc: 0.9758 -- iter: 1152/2948
[A[ATraining Step: 1153  | total loss: [1m[32m0.09919[0m[0m | time: 469.468s
[2K
| Adam | epoch: 013 | loss: 0.09919 - acc: 0.9657 -- iter: 1184/2948
[A[ATraining Step: 1154  | total loss: [1m[32m0.10785[0m[0m | time: 482.477s
[2K
| Adam | epoch: 013 | loss: 0.10785 - acc: 0.9598 -- iter: 1216/2948
[A[ATraining Step: 1155  | total loss: [1m[32m0.10297[0m[0m | time: 495.164s
[2K
| Adam | epoch: 013 | loss: 0.10297 - acc: 0.9607 -- iter: 1248/2948
[A[ATraining Step: 1156  | total loss: [1m[32m0.09427[0m[0m | time: 508.296s
[2K
| Adam | epoch: 013 | loss: 0.09427 - acc: 0.9646 -- iter: 1280/2948
[A[ATraining Step: 1157  | total loss: [1m[32m0.08949[0m[0m | time: 521.656s
[2K
| Adam | epoch: 013 | loss: 0.08949 - acc: 0.9650 -- iter: 1312/2948
[A[ATraining Step: 1158  | total loss: [1m[32m0.08176[0m[0m | time: 534.582s
[2K
| Adam | epoch: 013 | loss: 0.08176 - acc: 0.9685 -- iter: 1344/2948
[A[ATraining Step: 1159  | total loss: [1m[32m0.08271[0m[0m | time: 548.076s
[2K
| Adam | epoch: 013 | loss: 0.08271 - acc: 0.9685 -- iter: 1376/2948
[A[ATraining Step: 1160  | total loss: [1m[32m0.07680[0m[0m | time: 561.263s
[2K
| Adam | epoch: 013 | loss: 0.07680 - acc: 0.9717 -- iter: 1408/2948
[A[ATraining Step: 1161  | total loss: [1m[32m0.09283[0m[0m | time: 574.479s
[2K
| Adam | epoch: 013 | loss: 0.09283 - acc: 0.9714 -- iter: 1440/2948
[A[ATraining Step: 1162  | total loss: [1m[32m0.10138[0m[0m | time: 587.088s
[2K
| Adam | epoch: 013 | loss: 0.10138 - acc: 0.9680 -- iter: 1472/2948
[A[ATraining Step: 1163  | total loss: [1m[32m0.13409[0m[0m | time: 600.312s
[2K
| Adam | epoch: 013 | loss: 0.13409 - acc: 0.9556 -- iter: 1504/2948
[A[ATraining Step: 1164  | total loss: [1m[32m0.13323[0m[0m | time: 613.347s
[2K
| Adam | epoch: 013 | loss: 0.13323 - acc: 0.9538 -- iter: 1536/2948
[A[ATraining Step: 1165  | total loss: [1m[32m0.12911[0m[0m | time: 626.419s
[2K
| Adam | epoch: 013 | loss: 0.12911 - acc: 0.9553 -- iter: 1568/2948
[A[ATraining Step: 1166  | total loss: [1m[32m0.12546[0m[0m | time: 639.631s
[2K
| Adam | epoch: 013 | loss: 0.12546 - acc: 0.9566 -- iter: 1600/2948
[A[ATraining Step: 1167  | total loss: [1m[32m0.11695[0m[0m | time: 652.951s
[2K
| Adam | epoch: 013 | loss: 0.11695 - acc: 0.9610 -- iter: 1632/2948
[A[ATraining Step: 1168  | total loss: [1m[32m0.11361[0m[0m | time: 666.022s
[2K
| Adam | epoch: 013 | loss: 0.11361 - acc: 0.9617 -- iter: 1664/2948
[A[ATraining Step: 1169  | total loss: [1m[32m0.10545[0m[0m | time: 679.227s
[2K
| Adam | epoch: 013 | loss: 0.10545 - acc: 0.9656 -- iter: 1696/2948
[A[ATraining Step: 1170  | total loss: [1m[32m0.11811[0m[0m | time: 692.395s
[2K
| Adam | epoch: 013 | loss: 0.11811 - acc: 0.9628 -- iter: 1728/2948
[A[ATraining Step: 1171  | total loss: [1m[32m0.11084[0m[0m | time: 705.693s
[2K
| Adam | epoch: 013 | loss: 0.11084 - acc: 0.9665 -- iter: 1760/2948
[A[ATraining Step: 1172  | total loss: [1m[32m0.11168[0m[0m | time: 719.110s
[2K
| Adam | epoch: 013 | loss: 0.11168 - acc: 0.9667 -- iter: 1792/2948
[A[ATraining Step: 1173  | total loss: [1m[32m0.12561[0m[0m | time: 732.212s
[2K
| Adam | epoch: 013 | loss: 0.12561 - acc: 0.9638 -- iter: 1824/2948
[A[ATraining Step: 1174  | total loss: [1m[32m0.11655[0m[0m | time: 745.357s
[2K
| Adam | epoch: 013 | loss: 0.11655 - acc: 0.9674 -- iter: 1856/2948
[A[ATraining Step: 1175  | total loss: [1m[32m0.11501[0m[0m | time: 758.758s
[2K
| Adam | epoch: 013 | loss: 0.11501 - acc: 0.9675 -- iter: 1888/2948
[A[ATraining Step: 1176  | total loss: [1m[32m0.10748[0m[0m | time: 771.604s
[2K
| Adam | epoch: 013 | loss: 0.10748 - acc: 0.9708 -- iter: 1920/2948
[A[ATraining Step: 1177  | total loss: [1m[32m0.12662[0m[0m | time: 784.818s
[2K
| Adam | epoch: 013 | loss: 0.12662 - acc: 0.9612 -- iter: 1952/2948
[A[ATraining Step: 1178  | total loss: [1m[32m0.11572[0m[0m | time: 797.882s
[2K
| Adam | epoch: 013 | loss: 0.11572 - acc: 0.9651 -- iter: 1984/2948
[A[ATraining Step: 1179  | total loss: [1m[32m0.10512[0m[0m | time: 811.130s
[2K
| Adam | epoch: 013 | loss: 0.10512 - acc: 0.9686 -- iter: 2016/2948
[A[ATraining Step: 1180  | total loss: [1m[32m0.09783[0m[0m | time: 824.864s
[2K
| Adam | epoch: 013 | loss: 0.09783 - acc: 0.9686 -- iter: 2048/2948
[A[ATraining Step: 1181  | total loss: [1m[32m0.09336[0m[0m | time: 837.796s
[2K
| Adam | epoch: 013 | loss: 0.09336 - acc: 0.9686 -- iter: 2080/2948
[A[ATraining Step: 1182  | total loss: [1m[32m0.08765[0m[0m | time: 851.203s
[2K
| Adam | epoch: 013 | loss: 0.08765 - acc: 0.9718 -- iter: 2112/2948
[A[ATraining Step: 1183  | total loss: [1m[32m0.11687[0m[0m | time: 864.689s
[2K
| Adam | epoch: 013 | loss: 0.11687 - acc: 0.9621 -- iter: 2144/2948
[A[ATraining Step: 1184  | total loss: [1m[32m0.11420[0m[0m | time: 877.728s
[2K
| Adam | epoch: 013 | loss: 0.11420 - acc: 0.9596 -- iter: 2176/2948
[A[ATraining Step: 1185  | total loss: [1m[32m0.12354[0m[0m | time: 890.719s
[2K
| Adam | epoch: 013 | loss: 0.12354 - acc: 0.9543 -- iter: 2208/2948
[A[ATraining Step: 1186  | total loss: [1m[32m0.11634[0m[0m | time: 903.757s
[2K
| Adam | epoch: 013 | loss: 0.11634 - acc: 0.9557 -- iter: 2240/2948
[A[ATraining Step: 1187  | total loss: [1m[32m0.10962[0m[0m | time: 917.114s
[2K
| Adam | epoch: 013 | loss: 0.10962 - acc: 0.9602 -- iter: 2272/2948
[A[ATraining Step: 1188  | total loss: [1m[32m0.10169[0m[0m | time: 930.196s
[2K
| Adam | epoch: 013 | loss: 0.10169 - acc: 0.9641 -- iter: 2304/2948
[A[ATraining Step: 1189  | total loss: [1m[32m0.09451[0m[0m | time: 943.330s
[2K
| Adam | epoch: 013 | loss: 0.09451 - acc: 0.9677 -- iter: 2336/2948
[A[ATraining Step: 1190  | total loss: [1m[32m0.09325[0m[0m | time: 956.498s
[2K
| Adam | epoch: 013 | loss: 0.09325 - acc: 0.9647 -- iter: 2368/2948
[A[ATraining Step: 1191  | total loss: [1m[32m0.09325[0m[0m | time: 970.019s
[2K
| Adam | epoch: 013 | loss: 0.09325 - acc: 0.9620 -- iter: 2400/2948
[A[ATraining Step: 1192  | total loss: [1m[32m0.11592[0m[0m | time: 983.022s
[2K
| Adam | epoch: 013 | loss: 0.11592 - acc: 0.9502 -- iter: 2432/2948
[A[ATraining Step: 1193  | total loss: [1m[32m0.10623[0m[0m | time: 996.529s
[2K
| Adam | epoch: 013 | loss: 0.10623 - acc: 0.9551 -- iter: 2464/2948
[A[ATraining Step: 1194  | total loss: [1m[32m0.10128[0m[0m | time: 1010.030s
[2K
| Adam | epoch: 013 | loss: 0.10128 - acc: 0.9565 -- iter: 2496/2948
[A[ATraining Step: 1195  | total loss: [1m[32m0.09382[0m[0m | time: 1023.263s
[2K
| Adam | epoch: 013 | loss: 0.09382 - acc: 0.9609 -- iter: 2528/2948
[A[ATraining Step: 1196  | total loss: [1m[32m0.08745[0m[0m | time: 1037.464s
[2K
| Adam | epoch: 013 | loss: 0.08745 - acc: 0.9648 -- iter: 2560/2948
[A[ATraining Step: 1197  | total loss: [1m[32m0.08355[0m[0m | time: 1051.450s
[2K
| Adam | epoch: 013 | loss: 0.08355 - acc: 0.9652 -- iter: 2592/2948
[A[ATraining Step: 1198  | total loss: [1m[32m0.08166[0m[0m | time: 1065.369s
[2K
| Adam | epoch: 013 | loss: 0.08166 - acc: 0.9655 -- iter: 2624/2948
[A[ATraining Step: 1199  | total loss: [1m[32m0.07387[0m[0m | time: 1079.177s
[2K
| Adam | epoch: 013 | loss: 0.07387 - acc: 0.9690 -- iter: 2656/2948
[A[ATraining Step: 1200  | total loss: [1m[32m0.07788[0m[0m | time: 1153.877s
[2K
| Adam | epoch: 013 | loss: 0.07788 - acc: 0.9690 | val_loss: 0.34380 - val_acc: 0.8655 -- iter: 2688/2948
--
Training Step: 1201  | total loss: [1m[32m0.07102[0m[0m | time: 1167.363s
[2K
| Adam | epoch: 013 | loss: 0.07102 - acc: 0.9721 -- iter: 2720/2948
[A[ATraining Step: 1202  | total loss: [1m[32m0.07289[0m[0m | time: 1180.436s
[2K
| Adam | epoch: 013 | loss: 0.07289 - acc: 0.9717 -- iter: 2752/2948
[A[ATraining Step: 1203  | total loss: [1m[32m0.06739[0m[0m | time: 1194.214s
[2K
| Adam | epoch: 013 | loss: 0.06739 - acc: 0.9746 -- iter: 2784/2948
[A[ATraining Step: 1204  | total loss: [1m[32m0.07725[0m[0m | time: 1207.809s
[2K
| Adam | epoch: 013 | loss: 0.07725 - acc: 0.9740 -- iter: 2816/2948
[A[ATraining Step: 1205  | total loss: [1m[32m0.07096[0m[0m | time: 1221.794s
[2K
| Adam | epoch: 013 | loss: 0.07096 - acc: 0.9766 -- iter: 2848/2948
[A[ATraining Step: 1206  | total loss: [1m[32m0.07017[0m[0m | time: 1236.069s
[2K
| Adam | epoch: 013 | loss: 0.07017 - acc: 0.9727 -- iter: 2880/2948
[A[ATraining Step: 1207  | total loss: [1m[32m0.07751[0m[0m | time: 1250.392s
[2K
| Adam | epoch: 013 | loss: 0.07751 - acc: 0.9629 -- iter: 2912/2948
[A[ATraining Step: 1208  | total loss: [1m[32m0.07264[0m[0m | time: 1264.696s
[2K
| Adam | epoch: 013 | loss: 0.07264 - acc: 0.9666 -- iter: 2944/2948
[A[ATraining Step: 1209  | total loss: [1m[32m0.06583[0m[0m | time: 1333.482s
[2K
| Adam | epoch: 013 | loss: 0.06583 - acc: 0.9699 | val_loss: 0.45430 - val_acc: 0.8178 -- iter: 2948/2948
--
Training Step: 1210  | total loss: [1m[32m0.06125[0m[0m | time: 13.567s
[2K
| Adam | epoch: 014 | loss: 0.06125 - acc: 0.9730 -- iter: 0032/2948
[A[ATraining Step: 1211  | total loss: [1m[32m0.05781[0m[0m | time: 26.887s
[2K
| Adam | epoch: 014 | loss: 0.05781 - acc: 0.9757 -- iter: 0064/2948
[A[ATraining Step: 1212  | total loss: [1m[32m0.05498[0m[0m | time: 40.311s
[2K
| Adam | epoch: 014 | loss: 0.05498 - acc: 0.9781 -- iter: 0096/2948
[A[ATraining Step: 1213  | total loss: [1m[32m0.05076[0m[0m | time: 53.570s
[2K
| Adam | epoch: 014 | loss: 0.05076 - acc: 0.9803 -- iter: 0128/2948
[A[ATraining Step: 1214  | total loss: [1m[32m0.06065[0m[0m | time: 67.041s
[2K
| Adam | epoch: 014 | loss: 0.06065 - acc: 0.9791 -- iter: 0160/2948
[A[ATraining Step: 1215  | total loss: [1m[32m0.07820[0m[0m | time: 79.914s
[2K
| Adam | epoch: 014 | loss: 0.07820 - acc: 0.9718 -- iter: 0192/2948
[A[ATraining Step: 1216  | total loss: [1m[32m0.07824[0m[0m | time: 93.386s
[2K
| Adam | epoch: 014 | loss: 0.07824 - acc: 0.9715 -- iter: 0224/2948
[A[ATraining Step: 1217  | total loss: [1m[32m0.07118[0m[0m | time: 106.312s
[2K
| Adam | epoch: 014 | loss: 0.07118 - acc: 0.9744 -- iter: 0256/2948
[A[ATraining Step: 1218  | total loss: [1m[32m0.07299[0m[0m | time: 119.358s
[2K
| Adam | epoch: 014 | loss: 0.07299 - acc: 0.9738 -- iter: 0288/2948
[A[ATraining Step: 1219  | total loss: [1m[32m0.07053[0m[0m | time: 132.603s
[2K
| Adam | epoch: 014 | loss: 0.07053 - acc: 0.9764 -- iter: 0320/2948
[A[ATraining Step: 1220  | total loss: [1m[32m0.07366[0m[0m | time: 145.725s
[2K
| Adam | epoch: 014 | loss: 0.07366 - acc: 0.9757 -- iter: 0352/2948
[A[ATraining Step: 1221  | total loss: [1m[32m0.06922[0m[0m | time: 148.784s
[2K
| Adam | epoch: 014 | loss: 0.06922 - acc: 0.9781 -- iter: 0384/2948
[A[ATraining Step: 1222  | total loss: [1m[32m0.21566[0m[0m | time: 152.214s
[2K
| Adam | epoch: 014 | loss: 0.21566 - acc: 0.9303 -- iter: 0416/2948
[A[ATraining Step: 1223  | total loss: [1m[32m0.26403[0m[0m | time: 165.181s
[2K
| Adam | epoch: 014 | loss: 0.26403 - acc: 0.8873 -- iter: 0448/2948
[A[ATraining Step: 1224  | total loss: [1m[32m0.24233[0m[0m | time: 178.238s
[2K
| Adam | epoch: 014 | loss: 0.24233 - acc: 0.8985 -- iter: 0480/2948
[A[ATraining Step: 1225  | total loss: [1m[32m0.22001[0m[0m | time: 191.681s
[2K
| Adam | epoch: 014 | loss: 0.22001 - acc: 0.9087 -- iter: 0512/2948
[A[ATraining Step: 1226  | total loss: [1m[32m0.22340[0m[0m | time: 205.095s
[2K
| Adam | epoch: 014 | loss: 0.22340 - acc: 0.9147 -- iter: 0544/2948
[A[ATraining Step: 1227  | total loss: [1m[32m0.23693[0m[0m | time: 218.776s
[2K
| Adam | epoch: 014 | loss: 0.23693 - acc: 0.9076 -- iter: 0576/2948
[A[ATraining Step: 1228  | total loss: [1m[32m0.21958[0m[0m | time: 232.260s
[2K
| Adam | epoch: 014 | loss: 0.21958 - acc: 0.9137 -- iter: 0608/2948
[A[ATraining Step: 1229  | total loss: [1m[32m0.20448[0m[0m | time: 245.329s
[2K
| Adam | epoch: 014 | loss: 0.20448 - acc: 0.9223 -- iter: 0640/2948
[A[ATraining Step: 1230  | total loss: [1m[32m0.19815[0m[0m | time: 258.525s
[2K
| Adam | epoch: 014 | loss: 0.19815 - acc: 0.9239 -- iter: 0672/2948
[A[ATraining Step: 1231  | total loss: [1m[32m0.20724[0m[0m | time: 271.812s
[2K
| Adam | epoch: 014 | loss: 0.20724 - acc: 0.9221 -- iter: 0704/2948
[A[ATraining Step: 1232  | total loss: [1m[32m0.19334[0m[0m | time: 285.166s
[2K
| Adam | epoch: 014 | loss: 0.19334 - acc: 0.9268 -- iter: 0736/2948
[A[ATraining Step: 1233  | total loss: [1m[32m0.17534[0m[0m | time: 298.554s
[2K
| Adam | epoch: 014 | loss: 0.17534 - acc: 0.9341 -- iter: 0768/2948
[A[ATraining Step: 1234  | total loss: [1m[32m0.16507[0m[0m | time: 311.843s
[2K
| Adam | epoch: 014 | loss: 0.16507 - acc: 0.9376 -- iter: 0800/2948
[A[ATraining Step: 1235  | total loss: [1m[32m0.15274[0m[0m | time: 325.406s
[2K
| Adam | epoch: 014 | loss: 0.15274 - acc: 0.9438 -- iter: 0832/2948
[A[ATraining Step: 1236  | total loss: [1m[32m0.14473[0m[0m | time: 339.183s
[2K
| Adam | epoch: 014 | loss: 0.14473 - acc: 0.9463 -- iter: 0864/2948
[A[ATraining Step: 1237  | total loss: [1m[32m0.13464[0m[0m | time: 352.807s
[2K
| Adam | epoch: 014 | loss: 0.13464 - acc: 0.9485 -- iter: 0896/2948
[A[ATraining Step: 1238  | total loss: [1m[32m0.12832[0m[0m | time: 366.533s
[2K
| Adam | epoch: 014 | loss: 0.12832 - acc: 0.9506 -- iter: 0928/2948
[A[ATraining Step: 1239  | total loss: [1m[32m0.12113[0m[0m | time: 379.932s
[2K
| Adam | epoch: 014 | loss: 0.12113 - acc: 0.9555 -- iter: 0960/2948
[A[ATraining Step: 1240  | total loss: [1m[32m0.11282[0m[0m | time: 393.064s
[2K
| Adam | epoch: 014 | loss: 0.11282 - acc: 0.9600 -- iter: 0992/2948
[A[ATraining Step: 1241  | total loss: [1m[32m0.11348[0m[0m | time: 406.313s
[2K
| Adam | epoch: 014 | loss: 0.11348 - acc: 0.9546 -- iter: 1024/2948
[A[ATraining Step: 1242  | total loss: [1m[32m0.11176[0m[0m | time: 419.274s
[2K
| Adam | epoch: 014 | loss: 0.11176 - acc: 0.9529 -- iter: 1056/2948
[A[ATraining Step: 1243  | total loss: [1m[32m0.10116[0m[0m | time: 432.425s
[2K
| Adam | epoch: 014 | loss: 0.10116 - acc: 0.9576 -- iter: 1088/2948
[A[ATraining Step: 1244  | total loss: [1m[32m0.10068[0m[0m | time: 445.551s
[2K
| Adam | epoch: 014 | loss: 0.10068 - acc: 0.9556 -- iter: 1120/2948
[A[ATraining Step: 1245  | total loss: [1m[32m0.10758[0m[0m | time: 459.446s
[2K
| Adam | epoch: 014 | loss: 0.10758 - acc: 0.9569 -- iter: 1152/2948
[A[ATraining Step: 1246  | total loss: [1m[32m0.11786[0m[0m | time: 472.390s
[2K
| Adam | epoch: 014 | loss: 0.11786 - acc: 0.9581 -- iter: 1184/2948
[A[ATraining Step: 1247  | total loss: [1m[32m0.10904[0m[0m | time: 485.128s
[2K
| Adam | epoch: 014 | loss: 0.10904 - acc: 0.9591 -- iter: 1216/2948
[A[ATraining Step: 1248  | total loss: [1m[32m0.10600[0m[0m | time: 498.648s
[2K
| Adam | epoch: 014 | loss: 0.10600 - acc: 0.9601 -- iter: 1248/2948
[A[ATraining Step: 1249  | total loss: [1m[32m0.10991[0m[0m | time: 511.731s
[2K
| Adam | epoch: 014 | loss: 0.10991 - acc: 0.9578 -- iter: 1280/2948
[A[ATraining Step: 1250  | total loss: [1m[32m0.10703[0m[0m | time: 525.055s
[2K
| Adam | epoch: 014 | loss: 0.10703 - acc: 0.9589 -- iter: 1312/2948
[A[ATraining Step: 1251  | total loss: [1m[32m0.09892[0m[0m | time: 537.991s
[2K
| Adam | epoch: 014 | loss: 0.09892 - acc: 0.9630 -- iter: 1344/2948
[A[ATraining Step: 1252  | total loss: [1m[32m0.09717[0m[0m | time: 551.573s
[2K
| Adam | epoch: 014 | loss: 0.09717 - acc: 0.9605 -- iter: 1376/2948
[A[ATraining Step: 1253  | total loss: [1m[32m0.09255[0m[0m | time: 565.081s
[2K
| Adam | epoch: 014 | loss: 0.09255 - acc: 0.9644 -- iter: 1408/2948
[A[ATraining Step: 1254  | total loss: [1m[32m0.08712[0m[0m | time: 578.432s
[2K
| Adam | epoch: 014 | loss: 0.08712 - acc: 0.9649 -- iter: 1440/2948
[A[ATraining Step: 1255  | total loss: [1m[32m0.08061[0m[0m | time: 591.771s
[2K
| Adam | epoch: 014 | loss: 0.08061 - acc: 0.9684 -- iter: 1472/2948
[A[ATraining Step: 1256  | total loss: [1m[32m0.07359[0m[0m | time: 605.142s
[2K
| Adam | epoch: 014 | loss: 0.07359 - acc: 0.9715 -- iter: 1504/2948
[A[ATraining Step: 1257  | total loss: [1m[32m0.09043[0m[0m | time: 618.680s
[2K
| Adam | epoch: 014 | loss: 0.09043 - acc: 0.9619 -- iter: 1536/2948
[A[ATraining Step: 1258  | total loss: [1m[32m0.08590[0m[0m | time: 631.996s
[2K
| Adam | epoch: 014 | loss: 0.08590 - acc: 0.9626 -- iter: 1568/2948
[A[ATraining Step: 1259  | total loss: [1m[32m0.08060[0m[0m | time: 645.280s
[2K
| Adam | epoch: 014 | loss: 0.08060 - acc: 0.9663 -- iter: 1600/2948
[A[ATraining Step: 1260  | total loss: [1m[32m0.07353[0m[0m | time: 658.379s
[2K
| Adam | epoch: 014 | loss: 0.07353 - acc: 0.9697 -- iter: 1632/2948
[A[ATraining Step: 1261  | total loss: [1m[32m0.08085[0m[0m | time: 671.580s
[2K
| Adam | epoch: 014 | loss: 0.08085 - acc: 0.9665 -- iter: 1664/2948
[A[ATraining Step: 1262  | total loss: [1m[32m0.07369[0m[0m | time: 684.661s
[2K
| Adam | epoch: 014 | loss: 0.07369 - acc: 0.9698 -- iter: 1696/2948
[A[ATraining Step: 1263  | total loss: [1m[32m0.06718[0m[0m | time: 698.368s
[2K
| Adam | epoch: 014 | loss: 0.06718 - acc: 0.9728 -- iter: 1728/2948
[A[ATraining Step: 1264  | total loss: [1m[32m0.06685[0m[0m | time: 711.471s
[2K
| Adam | epoch: 014 | loss: 0.06685 - acc: 0.9724 -- iter: 1760/2948
[A[ATraining Step: 1265  | total loss: [1m[32m0.06119[0m[0m | time: 724.670s
[2K
| Adam | epoch: 014 | loss: 0.06119 - acc: 0.9752 -- iter: 1792/2948
[A[ATraining Step: 1266  | total loss: [1m[32m0.06293[0m[0m | time: 738.120s
[2K
| Adam | epoch: 014 | loss: 0.06293 - acc: 0.9745 -- iter: 1824/2948
[A[ATraining Step: 1267  | total loss: [1m[32m0.06428[0m[0m | time: 751.023s
[2K
| Adam | epoch: 014 | loss: 0.06428 - acc: 0.9708 -- iter: 1856/2948
[A[ATraining Step: 1268  | total loss: [1m[32m0.05952[0m[0m | time: 764.175s
[2K
| Adam | epoch: 014 | loss: 0.05952 - acc: 0.9738 -- iter: 1888/2948
[A[ATraining Step: 1269  | total loss: [1m[32m0.05600[0m[0m | time: 777.350s
[2K
| Adam | epoch: 014 | loss: 0.05600 - acc: 0.9764 -- iter: 1920/2948
[A[ATraining Step: 1270  | total loss: [1m[32m0.07286[0m[0m | time: 791.157s
[2K
| Adam | epoch: 014 | loss: 0.07286 - acc: 0.9694 -- iter: 1952/2948
[A[ATraining Step: 1271  | total loss: [1m[32m0.06719[0m[0m | time: 804.585s
[2K
| Adam | epoch: 014 | loss: 0.06719 - acc: 0.9724 -- iter: 1984/2948
[A[ATraining Step: 1272  | total loss: [1m[32m0.07347[0m[0m | time: 818.112s
[2K
| Adam | epoch: 014 | loss: 0.07347 - acc: 0.9721 -- iter: 2016/2948
[A[ATraining Step: 1273  | total loss: [1m[32m0.07423[0m[0m | time: 831.116s
[2K
| Adam | epoch: 014 | loss: 0.07423 - acc: 0.9686 -- iter: 2048/2948
[A[ATraining Step: 1274  | total loss: [1m[32m0.08392[0m[0m | time: 844.534s
[2K
| Adam | epoch: 014 | loss: 0.08392 - acc: 0.9624 -- iter: 2080/2948
[A[ATraining Step: 1275  | total loss: [1m[32m0.07966[0m[0m | time: 857.690s
[2K
| Adam | epoch: 014 | loss: 0.07966 - acc: 0.9661 -- iter: 2112/2948
[A[ATraining Step: 1276  | total loss: [1m[32m0.07707[0m[0m | time: 870.920s
[2K
| Adam | epoch: 014 | loss: 0.07707 - acc: 0.9695 -- iter: 2144/2948
[A[ATraining Step: 1277  | total loss: [1m[32m0.07062[0m[0m | time: 884.107s
[2K
| Adam | epoch: 014 | loss: 0.07062 - acc: 0.9726 -- iter: 2176/2948
[A[ATraining Step: 1278  | total loss: [1m[32m0.06736[0m[0m | time: 897.371s
[2K
| Adam | epoch: 014 | loss: 0.06736 - acc: 0.9722 -- iter: 2208/2948
[A[ATraining Step: 1279  | total loss: [1m[32m0.06380[0m[0m | time: 910.209s
[2K
| Adam | epoch: 014 | loss: 0.06380 - acc: 0.9750 -- iter: 2240/2948
[A[ATraining Step: 1280  | total loss: [1m[32m0.06314[0m[0m | time: 923.179s
[2K
| Adam | epoch: 014 | loss: 0.06314 - acc: 0.9743 -- iter: 2272/2948
[A[ATraining Step: 1281  | total loss: [1m[32m0.07161[0m[0m | time: 936.229s
[2K
| Adam | epoch: 014 | loss: 0.07161 - acc: 0.9707 -- iter: 2304/2948
[A[ATraining Step: 1282  | total loss: [1m[32m0.06760[0m[0m | time: 949.665s
[2K
| Adam | epoch: 014 | loss: 0.06760 - acc: 0.9736 -- iter: 2336/2948
[A[ATraining Step: 1283  | total loss: [1m[32m0.06267[0m[0m | time: 961.901s
[2K
| Adam | epoch: 014 | loss: 0.06267 - acc: 0.9762 -- iter: 2368/2948
[A[ATraining Step: 1284  | total loss: [1m[32m0.38454[0m[0m | time: 975.000s
[2K
| Adam | epoch: 014 | loss: 0.38454 - acc: 0.9411 -- iter: 2400/2948
[A[ATraining Step: 1285  | total loss: [1m[32m0.34804[0m[0m | time: 988.288s
[2K
| Adam | epoch: 014 | loss: 0.34804 - acc: 0.9470 -- iter: 2432/2948
[A[ATraining Step: 1286  | total loss: [1m[32m0.31451[0m[0m | time: 1000.899s
[2K
| Adam | epoch: 014 | loss: 0.31451 - acc: 0.9523 -- iter: 2464/2948
[A[ATraining Step: 1287  | total loss: [1m[32m0.29254[0m[0m | time: 1014.185s
[2K
| Adam | epoch: 014 | loss: 0.29254 - acc: 0.9539 -- iter: 2496/2948
[A[ATraining Step: 1288  | total loss: [1m[32m0.26506[0m[0m | time: 1027.078s
[2K
| Adam | epoch: 014 | loss: 0.26506 - acc: 0.9586 -- iter: 2528/2948
[A[ATraining Step: 1289  | total loss: [1m[32m0.24195[0m[0m | time: 1039.699s
[2K
| Adam | epoch: 014 | loss: 0.24195 - acc: 0.9627 -- iter: 2560/2948
[A[ATraining Step: 1290  | total loss: [1m[32m0.22235[0m[0m | time: 1053.390s
[2K
| Adam | epoch: 014 | loss: 0.22235 - acc: 0.9664 -- iter: 2592/2948
[A[ATraining Step: 1291  | total loss: [1m[32m0.20296[0m[0m | time: 1066.668s
[2K
| Adam | epoch: 014 | loss: 0.20296 - acc: 0.9698 -- iter: 2624/2948
[A[ATraining Step: 1292  | total loss: [1m[32m0.20362[0m[0m | time: 1079.927s
[2K
| Adam | epoch: 014 | loss: 0.20362 - acc: 0.9634 -- iter: 2656/2948
[A[ATraining Step: 1293  | total loss: [1m[32m0.18912[0m[0m | time: 1092.758s
[2K
| Adam | epoch: 014 | loss: 0.18912 - acc: 0.9640 -- iter: 2688/2948
[A[ATraining Step: 1294  | total loss: [1m[32m0.17707[0m[0m | time: 1106.029s
[2K
| Adam | epoch: 014 | loss: 0.17707 - acc: 0.9644 -- iter: 2720/2948
[A[ATraining Step: 1295  | total loss: [1m[32m0.16506[0m[0m | time: 1118.723s
[2K
| Adam | epoch: 014 | loss: 0.16506 - acc: 0.9680 -- iter: 2752/2948
[A[ATraining Step: 1296  | total loss: [1m[32m0.16235[0m[0m | time: 1132.893s
[2K
| Adam | epoch: 014 | loss: 0.16235 - acc: 0.9649 -- iter: 2784/2948
[A[ATraining Step: 1297  | total loss: [1m[32m0.14729[0m[0m | time: 1146.725s
[2K
| Adam | epoch: 014 | loss: 0.14729 - acc: 0.9685 -- iter: 2816/2948
[A[ATraining Step: 1298  | total loss: [1m[32m0.13389[0m[0m | time: 1160.362s
[2K
| Adam | epoch: 014 | loss: 0.13389 - acc: 0.9716 -- iter: 2848/2948
[A[ATraining Step: 1299  | total loss: [1m[32m0.12743[0m[0m | time: 1173.468s
[2K
| Adam | epoch: 014 | loss: 0.12743 - acc: 0.9682 -- iter: 2880/2948
[A[ATraining Step: 1300  | total loss: [1m[32m0.12612[0m[0m | time: 1185.326s
[2K
| Adam | epoch: 014 | loss: 0.12612 - acc: 0.9651 -- iter: 2912/2948
[A[ATraining Step: 1301  | total loss: [1m[32m0.11853[0m[0m | time: 1193.878s
[2K
| Adam | epoch: 014 | loss: 0.11853 - acc: 0.9655 -- iter: 2944/2948
[A[ATraining Step: 1302  | total loss: [1m[32m0.11232[0m[0m | time: 1268.043s
[2K
| Adam | epoch: 014 | loss: 0.11232 - acc: 0.9689 | val_loss: 0.36634 - val_acc: 0.8861 -- iter: 2948/2948
--
Training Step: 1303  | total loss: [1m[32m0.10351[0m[0m | time: 13.281s
[2K
| Adam | epoch: 015 | loss: 0.10351 - acc: 0.9720 -- iter: 0032/2948
[A[ATraining Step: 1304  | total loss: [1m[32m0.09733[0m[0m | time: 26.312s
[2K
| Adam | epoch: 015 | loss: 0.09733 - acc: 0.9717 -- iter: 0064/2948
[A[ATraining Step: 1305  | total loss: [1m[32m0.09067[0m[0m | time: 39.342s
[2K
| Adam | epoch: 015 | loss: 0.09067 - acc: 0.9745 -- iter: 0096/2948
[A[ATraining Step: 1306  | total loss: [1m[32m0.08422[0m[0m | time: 52.458s
[2K
| Adam | epoch: 015 | loss: 0.08422 - acc: 0.9771 -- iter: 0128/2948
[A[ATraining Step: 1307  | total loss: [1m[32m0.07716[0m[0m | time: 65.422s
[2K
| Adam | epoch: 015 | loss: 0.07716 - acc: 0.9794 -- iter: 0160/2948
[A[ATraining Step: 1308  | total loss: [1m[32m0.07204[0m[0m | time: 77.835s
[2K
| Adam | epoch: 015 | loss: 0.07204 - acc: 0.9814 -- iter: 0192/2948
[A[ATraining Step: 1309  | total loss: [1m[32m0.06586[0m[0m | time: 90.390s
[2K
| Adam | epoch: 015 | loss: 0.06586 - acc: 0.9833 -- iter: 0224/2948
[A[ATraining Step: 1310  | total loss: [1m[32m0.06299[0m[0m | time: 103.500s
[2K
| Adam | epoch: 015 | loss: 0.06299 - acc: 0.9850 -- iter: 0256/2948
[A[ATraining Step: 1311  | total loss: [1m[32m0.06202[0m[0m | time: 117.022s
[2K
| Adam | epoch: 015 | loss: 0.06202 - acc: 0.9833 -- iter: 0288/2948
[A[ATraining Step: 1312  | total loss: [1m[32m0.05620[0m[0m | time: 130.097s
[2K
| Adam | epoch: 015 | loss: 0.05620 - acc: 0.9850 -- iter: 0320/2948
[A[ATraining Step: 1313  | total loss: [1m[32m0.05617[0m[0m | time: 143.320s
[2K
| Adam | epoch: 015 | loss: 0.05617 - acc: 0.9834 -- iter: 0352/2948
[A[ATraining Step: 1314  | total loss: [1m[32m0.05429[0m[0m | time: 156.428s
[2K
| Adam | epoch: 015 | loss: 0.05429 - acc: 0.9819 -- iter: 0384/2948
[A[ATraining Step: 1315  | total loss: [1m[32m0.04950[0m[0m | time: 159.580s
[2K
| Adam | epoch: 015 | loss: 0.04950 - acc: 0.9837 -- iter: 0416/2948
[A[ATraining Step: 1316  | total loss: [1m[32m0.09772[0m[0m | time: 163.094s
[2K
| Adam | epoch: 015 | loss: 0.09772 - acc: 0.9604 -- iter: 0448/2948
[A[ATraining Step: 1317  | total loss: [1m[32m0.09118[0m[0m | time: 176.097s
[2K
| Adam | epoch: 015 | loss: 0.09118 - acc: 0.9643 -- iter: 0480/2948
[A[ATraining Step: 1318  | total loss: [1m[32m0.08313[0m[0m | time: 188.932s
[2K
| Adam | epoch: 015 | loss: 0.08313 - acc: 0.9679 -- iter: 0512/2948
[A[ATraining Step: 1319  | total loss: [1m[32m0.08462[0m[0m | time: 202.581s
[2K
| Adam | epoch: 015 | loss: 0.08462 - acc: 0.9649 -- iter: 0544/2948
[A[ATraining Step: 1320  | total loss: [1m[32m0.08781[0m[0m | time: 215.769s
[2K
| Adam | epoch: 015 | loss: 0.08781 - acc: 0.9621 -- iter: 0576/2948
[A[ATraining Step: 1321  | total loss: [1m[32m0.08002[0m[0m | time: 228.628s
[2K
| Adam | epoch: 015 | loss: 0.08002 - acc: 0.9659 -- iter: 0608/2948
[A[ATraining Step: 1322  | total loss: [1m[32m0.07351[0m[0m | time: 241.496s
[2K
| Adam | epoch: 015 | loss: 0.07351 - acc: 0.9693 -- iter: 0640/2948
[A[ATraining Step: 1323  | total loss: [1m[32m0.07061[0m[0m | time: 254.631s
[2K
| Adam | epoch: 015 | loss: 0.07061 - acc: 0.9693 -- iter: 0672/2948
[A[ATraining Step: 1324  | total loss: [1m[32m0.06597[0m[0m | time: 267.688s
[2K
| Adam | epoch: 015 | loss: 0.06597 - acc: 0.9723 -- iter: 0704/2948
[A[ATraining Step: 1325  | total loss: [1m[32m0.06256[0m[0m | time: 280.658s
[2K
| Adam | epoch: 015 | loss: 0.06256 - acc: 0.9751 -- iter: 0736/2948
[A[ATraining Step: 1326  | total loss: [1m[32m0.06782[0m[0m | time: 293.607s
[2K
| Adam | epoch: 015 | loss: 0.06782 - acc: 0.9713 -- iter: 0768/2948
[A[ATraining Step: 1327  | total loss: [1m[32m0.06375[0m[0m | time: 306.747s
[2K
| Adam | epoch: 015 | loss: 0.06375 - acc: 0.9742 -- iter: 0800/2948
[A[ATraining Step: 1328  | total loss: [1m[32m0.06630[0m[0m | time: 320.079s
[2K
| Adam | epoch: 015 | loss: 0.06630 - acc: 0.9737 -- iter: 0832/2948
[A[ATraining Step: 1329  | total loss: [1m[32m0.07328[0m[0m | time: 333.465s
[2K
| Adam | epoch: 015 | loss: 0.07328 - acc: 0.9700 -- iter: 0864/2948
[A[ATraining Step: 1330  | total loss: [1m[32m0.08322[0m[0m | time: 346.547s
[2K
| Adam | epoch: 015 | loss: 0.08322 - acc: 0.9699 -- iter: 0896/2948
[A[ATraining Step: 1331  | total loss: [1m[32m0.07688[0m[0m | time: 359.515s
[2K
| Adam | epoch: 015 | loss: 0.07688 - acc: 0.9729 -- iter: 0928/2948
[A[ATraining Step: 1332  | total loss: [1m[32m0.07420[0m[0m | time: 372.786s
[2K
| Adam | epoch: 015 | loss: 0.07420 - acc: 0.9756 -- iter: 0960/2948
[A[ATraining Step: 1333  | total loss: [1m[32m0.07438[0m[0m | time: 385.711s
[2K
| Adam | epoch: 015 | loss: 0.07438 - acc: 0.9749 -- iter: 0992/2948
[A[ATraining Step: 1334  | total loss: [1m[32m0.06917[0m[0m | time: 398.425s
[2K
| Adam | epoch: 015 | loss: 0.06917 - acc: 0.9774 -- iter: 1024/2948
[A[ATraining Step: 1335  | total loss: [1m[32m0.06763[0m[0m | time: 411.602s
[2K
| Adam | epoch: 015 | loss: 0.06763 - acc: 0.9766 -- iter: 1056/2948
[A[ATraining Step: 1336  | total loss: [1m[32m0.07748[0m[0m | time: 424.764s
[2K
| Adam | epoch: 015 | loss: 0.07748 - acc: 0.9727 -- iter: 1088/2948
[A[ATraining Step: 1337  | total loss: [1m[32m0.07379[0m[0m | time: 437.702s
[2K
| Adam | epoch: 015 | loss: 0.07379 - acc: 0.9754 -- iter: 1120/2948
[A[ATraining Step: 1338  | total loss: [1m[32m0.07070[0m[0m | time: 450.528s
[2K
| Adam | epoch: 015 | loss: 0.07070 - acc: 0.9747 -- iter: 1152/2948
[A[ATraining Step: 1339  | total loss: [1m[32m0.06553[0m[0m | time: 463.453s
[2K
| Adam | epoch: 015 | loss: 0.06553 - acc: 0.9773 -- iter: 1184/2948
[A[ATraining Step: 1340  | total loss: [1m[32m0.06154[0m[0m | time: 476.447s
[2K
| Adam | epoch: 015 | loss: 0.06154 - acc: 0.9795 -- iter: 1216/2948
[A[ATraining Step: 1341  | total loss: [1m[32m0.06190[0m[0m | time: 489.605s
[2K
| Adam | epoch: 015 | loss: 0.06190 - acc: 0.9816 -- iter: 1248/2948
[A[ATraining Step: 1342  | total loss: [1m[32m0.06882[0m[0m | time: 502.592s
[2K
| Adam | epoch: 015 | loss: 0.06882 - acc: 0.9772 -- iter: 1280/2948
[A[ATraining Step: 1343  | total loss: [1m[32m0.06597[0m[0m | time: 516.168s
[2K
| Adam | epoch: 015 | loss: 0.06597 - acc: 0.9763 -- iter: 1312/2948
[A[ATraining Step: 1344  | total loss: [1m[32m0.06131[0m[0m | time: 529.448s
[2K
| Adam | epoch: 015 | loss: 0.06131 - acc: 0.9787 -- iter: 1344/2948
[A[ATraining Step: 1345  | total loss: [1m[32m0.05778[0m[0m | time: 542.534s
[2K
| Adam | epoch: 015 | loss: 0.05778 - acc: 0.9808 -- iter: 1376/2948
[A[ATraining Step: 1346  | total loss: [1m[32m0.06003[0m[0m | time: 555.464s
[2K
| Adam | epoch: 015 | loss: 0.06003 - acc: 0.9796 -- iter: 1408/2948
[A[ATraining Step: 1347  | total loss: [1m[32m0.05473[0m[0m | time: 568.574s
[2K
| Adam | epoch: 015 | loss: 0.05473 - acc: 0.9817 -- iter: 1440/2948
[A[ATraining Step: 1348  | total loss: [1m[32m0.05112[0m[0m | time: 581.534s
[2K
| Adam | epoch: 015 | loss: 0.05112 - acc: 0.9835 -- iter: 1472/2948
[A[ATraining Step: 1349  | total loss: [1m[32m0.04689[0m[0m | time: 594.238s
[2K
| Adam | epoch: 015 | loss: 0.04689 - acc: 0.9851 -- iter: 1504/2948
[A[ATraining Step: 1350  | total loss: [1m[32m0.05761[0m[0m | time: 607.231s
[2K
| Adam | epoch: 015 | loss: 0.05761 - acc: 0.9804 -- iter: 1536/2948
[A[ATraining Step: 1351  | total loss: [1m[32m0.05321[0m[0m | time: 620.518s
[2K
| Adam | epoch: 015 | loss: 0.05321 - acc: 0.9823 -- iter: 1568/2948
[A[ATraining Step: 1352  | total loss: [1m[32m0.05043[0m[0m | time: 633.960s
[2K
| Adam | epoch: 015 | loss: 0.05043 - acc: 0.9841 -- iter: 1600/2948
[A[ATraining Step: 1353  | total loss: [1m[32m0.05072[0m[0m | time: 647.165s
[2K
| Adam | epoch: 015 | loss: 0.05072 - acc: 0.9826 -- iter: 1632/2948
[A[ATraining Step: 1354  | total loss: [1m[32m0.07583[0m[0m | time: 660.381s
[2K
| Adam | epoch: 015 | loss: 0.07583 - acc: 0.9812 -- iter: 1664/2948
[A[ATraining Step: 1355  | total loss: [1m[32m0.08043[0m[0m | time: 673.638s
[2K
| Adam | epoch: 015 | loss: 0.08043 - acc: 0.9799 -- iter: 1696/2948
[A[ATraining Step: 1356  | total loss: [1m[32m0.07464[0m[0m | time: 686.970s
[2K
| Adam | epoch: 015 | loss: 0.07464 - acc: 0.9820 -- iter: 1728/2948
[A[ATraining Step: 1357  | total loss: [1m[32m0.07708[0m[0m | time: 700.192s
[2K
| Adam | epoch: 015 | loss: 0.07708 - acc: 0.9775 -- iter: 1760/2948
[A[ATraining Step: 1358  | total loss: [1m[32m0.08086[0m[0m | time: 713.320s
[2K
| Adam | epoch: 015 | loss: 0.08086 - acc: 0.9766 -- iter: 1792/2948
[A[ATraining Step: 1359  | total loss: [1m[32m0.11229[0m[0m | time: 726.536s
[2K
| Adam | epoch: 015 | loss: 0.11229 - acc: 0.9758 -- iter: 1824/2948
[A[ATraining Step: 1360  | total loss: [1m[32m0.10506[0m[0m | time: 739.970s
[2K
| Adam | epoch: 015 | loss: 0.10506 - acc: 0.9751 -- iter: 1856/2948
[A[ATraining Step: 1361  | total loss: [1m[32m0.09585[0m[0m | time: 753.193s
[2K
| Adam | epoch: 015 | loss: 0.09585 - acc: 0.9776 -- iter: 1888/2948
[A[ATraining Step: 1362  | total loss: [1m[32m0.08825[0m[0m | time: 766.259s
[2K
| Adam | epoch: 015 | loss: 0.08825 - acc: 0.9799 -- iter: 1920/2948
[A[ATraining Step: 1363  | total loss: [1m[32m0.09286[0m[0m | time: 779.500s
[2K
| Adam | epoch: 015 | loss: 0.09286 - acc: 0.9756 -- iter: 1952/2948
[A[ATraining Step: 1364  | total loss: [1m[32m0.08717[0m[0m | time: 792.731s
[2K
| Adam | epoch: 015 | loss: 0.08717 - acc: 0.9781 -- iter: 1984/2948
[A[ATraining Step: 1365  | total loss: [1m[32m0.10577[0m[0m | time: 805.355s
[2K
| Adam | epoch: 015 | loss: 0.10577 - acc: 0.9740 -- iter: 2016/2948
[A[ATraining Step: 1366  | total loss: [1m[32m0.09997[0m[0m | time: 818.326s
[2K
| Adam | epoch: 015 | loss: 0.09997 - acc: 0.9766 -- iter: 2048/2948
[A[ATraining Step: 1367  | total loss: [1m[32m0.09891[0m[0m | time: 831.280s
[2K
| Adam | epoch: 015 | loss: 0.09891 - acc: 0.9727 -- iter: 2080/2948
[A[ATraining Step: 1368  | total loss: [1m[32m0.09015[0m[0m | time: 844.243s
[2K
| Adam | epoch: 015 | loss: 0.09015 - acc: 0.9754 -- iter: 2112/2948
[A[ATraining Step: 1369  | total loss: [1m[32m0.09975[0m[0m | time: 857.180s
[2K
| Adam | epoch: 015 | loss: 0.09975 - acc: 0.9685 -- iter: 2144/2948
[A[ATraining Step: 1370  | total loss: [1m[32m0.09070[0m[0m | time: 870.234s
[2K
| Adam | epoch: 015 | loss: 0.09070 - acc: 0.9717 -- iter: 2176/2948
[A[ATraining Step: 1371  | total loss: [1m[32m0.08596[0m[0m | time: 883.853s
[2K
| Adam | epoch: 015 | loss: 0.08596 - acc: 0.9745 -- iter: 2208/2948
[A[ATraining Step: 1372  | total loss: [1m[32m0.08112[0m[0m | time: 897.035s
[2K
| Adam | epoch: 015 | loss: 0.08112 - acc: 0.9739 -- iter: 2240/2948
[A[ATraining Step: 1373  | total loss: [1m[32m0.07859[0m[0m | time: 910.278s
[2K
| Adam | epoch: 015 | loss: 0.07859 - acc: 0.9734 -- iter: 2272/2948
[A[ATraining Step: 1374  | total loss: [1m[32m0.07120[0m[0m | time: 923.659s
[2K
| Adam | epoch: 015 | loss: 0.07120 - acc: 0.9761 -- iter: 2304/2948
[A[ATraining Step: 1375  | total loss: [1m[32m0.06676[0m[0m | time: 937.153s
[2K
| Adam | epoch: 015 | loss: 0.06676 - acc: 0.9785 -- iter: 2336/2948
[A[ATraining Step: 1376  | total loss: [1m[32m0.06133[0m[0m | time: 950.321s
[2K
| Adam | epoch: 015 | loss: 0.06133 - acc: 0.9806 -- iter: 2368/2948
[A[ATraining Step: 1377  | total loss: [1m[32m0.05649[0m[0m | time: 963.239s
[2K
| Adam | epoch: 015 | loss: 0.05649 - acc: 0.9825 -- iter: 2400/2948
[A[ATraining Step: 1378  | total loss: [1m[32m0.28970[0m[0m | time: 976.576s
[2K
| Adam | epoch: 015 | loss: 0.28970 - acc: 0.9530 -- iter: 2432/2948
[A[ATraining Step: 1379  | total loss: [1m[32m0.26625[0m[0m | time: 989.748s
[2K
| Adam | epoch: 015 | loss: 0.26625 - acc: 0.9546 -- iter: 2464/2948
[A[ATraining Step: 1380  | total loss: [1m[32m0.24070[0m[0m | time: 1002.875s
[2K
| Adam | epoch: 015 | loss: 0.24070 - acc: 0.9592 -- iter: 2496/2948
[A[ATraining Step: 1381  | total loss: [1m[32m0.21984[0m[0m | time: 1015.766s
[2K
| Adam | epoch: 015 | loss: 0.21984 - acc: 0.9632 -- iter: 2528/2948
[A[ATraining Step: 1382  | total loss: [1m[32m0.20739[0m[0m | time: 1029.619s
[2K
| Adam | epoch: 015 | loss: 0.20739 - acc: 0.9607 -- iter: 2560/2948
[A[ATraining Step: 1383  | total loss: [1m[32m0.19112[0m[0m | time: 1043.007s
[2K
| Adam | epoch: 015 | loss: 0.19112 - acc: 0.9646 -- iter: 2592/2948
[A[ATraining Step: 1384  | total loss: [1m[32m0.18960[0m[0m | time: 1056.054s
[2K
| Adam | epoch: 015 | loss: 0.18960 - acc: 0.9619 -- iter: 2624/2948
[A[ATraining Step: 1385  | total loss: [1m[32m0.17427[0m[0m | time: 1069.629s
[2K
| Adam | epoch: 015 | loss: 0.17427 - acc: 0.9657 -- iter: 2656/2948
[A[ATraining Step: 1386  | total loss: [1m[32m0.16107[0m[0m | time: 1082.462s
[2K
| Adam | epoch: 015 | loss: 0.16107 - acc: 0.9660 -- iter: 2688/2948
[A[ATraining Step: 1387  | total loss: [1m[32m0.14929[0m[0m | time: 1095.213s
[2K
| Adam | epoch: 015 | loss: 0.14929 - acc: 0.9694 -- iter: 2720/2948
[A[ATraining Step: 1388  | total loss: [1m[32m0.13830[0m[0m | time: 1109.142s
[2K
| Adam | epoch: 015 | loss: 0.13830 - acc: 0.9725 -- iter: 2752/2948
[A[ATraining Step: 1389  | total loss: [1m[32m0.13042[0m[0m | time: 1123.042s
[2K
| Adam | epoch: 015 | loss: 0.13042 - acc: 0.9752 -- iter: 2784/2948
[A[ATraining Step: 1390  | total loss: [1m[32m0.11985[0m[0m | time: 1137.407s
[2K
| Adam | epoch: 015 | loss: 0.11985 - acc: 0.9777 -- iter: 2816/2948
[A[ATraining Step: 1391  | total loss: [1m[32m0.12007[0m[0m | time: 1151.524s
[2K
| Adam | epoch: 015 | loss: 0.12007 - acc: 0.9768 -- iter: 2848/2948
[A[ATraining Step: 1392  | total loss: [1m[32m0.11245[0m[0m | time: 1162.800s
[2K
| Adam | epoch: 015 | loss: 0.11245 - acc: 0.9791 -- iter: 2880/2948
[A[ATraining Step: 1393  | total loss: [1m[32m0.11016[0m[0m | time: 1171.466s
[2K
| Adam | epoch: 015 | loss: 0.11016 - acc: 0.9781 -- iter: 2912/2948
[A[ATraining Step: 1394  | total loss: [1m[32m0.10330[0m[0m | time: 1180.043s
[2K
| Adam | epoch: 015 | loss: 0.10330 - acc: 0.9803 -- iter: 2944/2948
[A[ATraining Step: 1395  | total loss: [1m[32m0.09609[0m[0m | time: 1313.733s
[2K
| Adam | epoch: 015 | loss: 0.09609 - acc: 0.9822 | val_loss: 0.25123 - val_acc: 0.9132 -- iter: 2948/2948
--
Validation AUC:0.9730912581883894
Validation AUPRC:0.9728555301824581
Test AUC:0.9776528414633572
Test AUPRC:0.9812778777031197
BestTestF1Score	0.93	0.86	0.93	0.96	0.89	428	17	426	51	0.8
BestTestMCCScore	0.93	0.86	0.93	0.96	0.89	428	17	426	51	0.8
BestTestAccuracyScore	0.93	0.86	0.93	0.96	0.89	428	17	426	51	0.8
BestValidationF1Score	0.94	0.87	0.94	0.93	0.94	429	31	435	27	0.8
BestValidationMCC	0.94	0.87	0.94	0.93	0.94	429	31	435	27	0.8
BestValidationAccuracy	0.94	0.87	0.94	0.93	0.94	429	31	435	27	0.8
TestPredictions (Threshold:0.8)
CHEMBL372965,TP,ACT,0.9700000286102295	CHEMBL198723,TP,ACT,1.0	CHEMBL12487,TP,ACT,1.0	CHEMBL1923665,TP,ACT,0.9900000095367432	CHEMBL340755,TN,INACT,0.009999999776482582	CHEMBL324125,TN,INACT,0.0	CHEMBL475534,TN,INACT,0.07999999821186066	CHEMBL454917,TP,ACT,1.0	CHEMBL3600843,TP,ACT,1.0	CHEMBL381501,TP,ACT,1.0	CHEMBL371610,FN,ACT,0.6399999856948853	CHEMBL361714,TP,ACT,1.0	CHEMBL381015,TP,ACT,0.8700000047683716	CHEMBL3423408,FP,INACT,0.8999999761581421	CHEMBL169675,TN,INACT,0.009999999776482582	CHEMBL365893,TP,ACT,1.0	CHEMBL536044,TN,INACT,0.05000000074505806	CHEMBL536977,TP,ACT,1.0	CHEMBL81895,TN,INACT,0.0	CHEMBL396638,FN,ACT,0.07000000029802322	CHEMBL140006,TN,INACT,0.07000000029802322	CHEMBL62445,TN,INACT,0.0	CHEMBL384176,FN,ACT,0.27000001072883606	CHEMBL247230,TP,ACT,1.0	CHEMBL3644311,TP,ACT,1.0	CHEMBL1269570,TP,ACT,1.0	CHEMBL411391,FN,ACT,0.17000000178813934	CHEMBL75773,TN,INACT,0.0	CHEMBL363603,FN,ACT,0.009999999776482582	CHEMBL12615,TP,ACT,0.9800000190734863	CHEMBL2237158,TN,INACT,0.23999999463558197	CHEMBL264027,TN,INACT,0.009999999776482582	CHEMBL204078,TP,ACT,1.0	CHEMBL1091790,TN,INACT,0.0	CHEMBL2415019,TP,ACT,0.9100000262260437	CHEMBL494569,TN,INACT,0.0	CHEMBL28057,TN,INACT,0.029999999329447746	CHEMBL366313,FN,ACT,0.09000000357627869	CHEMBL379200,TP,ACT,0.9900000095367432	CHEMBL2314767,TN,INACT,0.0	CHEMBL84165,TN,INACT,0.09000000357627869	CHEMBL1782798,TN,INACT,0.019999999552965164	CHEMBL11401,TN,INACT,0.0	CHEMBL1917057,TP,ACT,1.0	CHEMBL118507,TN,INACT,0.3100000023841858	CHEMBL1091631,FN,ACT,0.7400000095367432	CHEMBL521715,TP,ACT,1.0	CHEMBL393350,TP,ACT,1.0	CHEMBL377825,TP,ACT,1.0	CHEMBL158471,TP,ACT,0.9399999976158142	CHEMBL411,TN,INACT,0.009999999776482582	CHEMBL1089830,TP,ACT,1.0	CHEMBL500743,TP,ACT,1.0	CHEMBL3663363,TP,ACT,1.0	CHEMBL439560,TP,ACT,1.0	CHEMBL45008,TN,INACT,0.03999999910593033	CHEMBL233372,TP,ACT,1.0	CHEMBL516659,TP,ACT,1.0	CHEMBL236064,TP,ACT,0.9900000095367432	CHEMBL1934066,TN,INACT,0.019999999552965164	CHEMBL216406,TN,INACT,0.0	CHEMBL195638,FN,ACT,0.7699999809265137	CHEMBL237937,FN,ACT,0.6600000262260437	CHEMBL236520,TP,ACT,1.0	CHEMBL209559,TP,ACT,1.0	CHEMBL2163448,FP,INACT,0.9900000095367432	CHEMBL83410,TN,INACT,0.0	CHEMBL121350,TN,INACT,0.46000000834465027	CHEMBL2443005,TN,INACT,0.0	CHEMBL248057,TP,ACT,1.0	CHEMBL424661,TP,ACT,0.8600000143051147	CHEMBL2164434,TN,INACT,0.0	CHEMBL3354733,TP,ACT,1.0	CHEMBL1801144,TP,ACT,1.0	CHEMBL401466,TP,ACT,1.0	CHEMBL215354,TP,ACT,1.0	CHEMBL90374,TN,INACT,0.0	CHEMBL408843,TP,ACT,1.0	CHEMBL332442,TP,ACT,1.0	CHEMBL2310901,TP,ACT,1.0	CHEMBL138878,FN,ACT,0.7099999785423279	CHEMBL608985,TN,INACT,0.0	CHEMBL85918,FN,ACT,0.05000000074505806	CHEMBL112347,FP,INACT,0.8700000047683716	CHEMBL410966,TP,ACT,0.9900000095367432	CHEMBL446757,TP,ACT,1.0	CHEMBL185625,TP,ACT,1.0	CHEMBL239017,TN,INACT,0.0	CHEMBL233357,TP,ACT,0.9900000095367432	CHEMBL213956,TP,ACT,0.9700000286102295	CHEMBL344568,TN,INACT,0.009999999776482582	CHEMBL356213,TN,INACT,0.0	CHEMBL232585,TP,ACT,0.9700000286102295	CHEMBL611916,TN,INACT,0.009999999776482582	CHEMBL114760,TN,INACT,0.029999999329447746	CHEMBL391707,FP,INACT,0.8100000023841858	CHEMBL1089104,TP,ACT,1.0	CHEMBL400481,TN,INACT,0.009999999776482582	CHEMBL270015,TP,ACT,1.0	CHEMBL2113132,TP,ACT,0.9900000095367432	CHEMBL3667945,TP,ACT,1.0	CHEMBL448475,TP,ACT,1.0	CHEMBL225910,TP,ACT,0.9800000190734863	CHEMBL460138,TP,ACT,0.9800000190734863	CHEMBL515179,TN,INACT,0.03999999910593033	CHEMBL188966,TP,ACT,1.0	CHEMBL72841,TN,INACT,0.0	CHEMBL91,TN,INACT,0.0	CHEMBL399487,TP,ACT,1.0	CHEMBL384965,TP,ACT,1.0	CHEMBL293184,TN,INACT,0.019999999552965164	CHEMBL3287329,TP,ACT,1.0	CHEMBL447117,TP,ACT,0.9300000071525574	CHEMBL360717,TP,ACT,1.0	CHEMBL291992,TN,INACT,0.009999999776482582	CHEMBL434345,TP,ACT,1.0	CHEMBL185195,FP,INACT,0.9900000095367432	CHEMBL76949,TN,INACT,0.0	CHEMBL40796,TN,INACT,0.0	CHEMBL1209799,TP,ACT,1.0	CHEMBL235616,FN,ACT,0.7900000214576721	CHEMBL64406,TN,INACT,0.3100000023841858	CHEMBL453,TN,INACT,0.0	CHEMBL53573,TN,INACT,0.009999999776482582	CHEMBL293445,FP,INACT,0.8500000238418579	CHEMBL195548,FN,ACT,0.6100000143051147	CHEMBL285357,TN,INACT,0.0	CHEMBL404706,TP,ACT,1.0	CHEMBL186970,FN,ACT,0.6700000166893005	CHEMBL421523,TN,INACT,0.0	CHEMBL1093306,TP,ACT,1.0	CHEMBL467588,TP,ACT,1.0	CHEMBL62115,TN,INACT,0.019999999552965164	CHEMBL130005,TN,INACT,0.0	CHEMBL503229,TP,ACT,0.8899999856948853	CHEMBL3287357,TP,ACT,0.9900000095367432	CHEMBL3421680,TP,ACT,0.9900000095367432	CHEMBL3354730,TP,ACT,1.0	CHEMBL3287328,TP,ACT,0.9599999785423279	CHEMBL328925,TN,INACT,0.009999999776482582	CHEMBL375440,TP,ACT,0.9900000095367432	CHEMBL249473,TP,ACT,0.9900000095367432	CHEMBL44246,TN,INACT,0.4300000071525574	CHEMBL89494,TN,INACT,0.029999999329447746	CHEMBL3601428,TP,ACT,1.0	CHEMBL207166,TP,ACT,0.9900000095367432	CHEMBL205768,TN,INACT,0.05999999865889549	CHEMBL62804,TN,INACT,0.009999999776482582	CHEMBL451249,TP,ACT,1.0	CHEMBL149391,TN,INACT,0.18000000715255737	CHEMBL1907839,TN,INACT,0.0	CHEMBL86288,TN,INACT,0.0	CHEMBL247422,TP,ACT,1.0	CHEMBL1223054,TN,INACT,0.0	CHEMBL45305,TN,INACT,0.029999999329447746	CHEMBL122236,FN,ACT,0.44999998807907104	CHEMBL248669,TP,ACT,1.0	CHEMBL365004,TP,ACT,1.0	CHEMBL400712,TP,ACT,1.0	CHEMBL9138,TN,INACT,0.05000000074505806	CHEMBL269653,TN,INACT,0.029999999329447746	CHEMBL3120199,TN,INACT,0.03999999910593033	CHEMBL3663340,TP,ACT,1.0	CHEMBL3644292,TP,ACT,0.9399999976158142	CHEMBL439484,TP,ACT,1.0	CHEMBL415661,TP,ACT,0.9700000286102295	CHEMBL2070835,TN,INACT,0.0	CHEMBL237364,TP,ACT,1.0	CHEMBL101554,TN,INACT,0.009999999776482582	CHEMBL255286,TP,ACT,1.0	CHEMBL397584,FN,ACT,0.7799999713897705	CHEMBL185862,TP,ACT,1.0	CHEMBL2024394,TN,INACT,0.009999999776482582	CHEMBL254277,TP,ACT,1.0	CHEMBL726,TN,INACT,0.0	CHEMBL603605,TN,INACT,0.029999999329447746	CHEMBL7002,TN,INACT,0.0	CHEMBL105594,TN,INACT,0.009999999776482582	CHEMBL393788,TP,ACT,1.0	CHEMBL409049,FN,ACT,0.5699999928474426	CHEMBL3646888,TP,ACT,1.0	CHEMBL392116,TN,INACT,0.019999999552965164	CHEMBL392315,TP,ACT,0.9300000071525574	CHEMBL443071,TP,ACT,0.9599999785423279	CHEMBL65339,TP,ACT,1.0	CHEMBL450729,TN,INACT,0.0	CHEMBL30635,TN,INACT,0.7400000095367432	CHEMBL462379,TP,ACT,0.9900000095367432	CHEMBL350631,TN,INACT,0.009999999776482582	CHEMBL80532,TN,INACT,0.0	CHEMBL194368,TP,ACT,1.0	CHEMBL248028,TP,ACT,1.0	CHEMBL2111829,TN,INACT,0.0	CHEMBL119385,TN,INACT,0.0	CHEMBL364560,TP,ACT,1.0	CHEMBL54051,TN,INACT,0.0	CHEMBL545185,TN,INACT,0.05000000074505806	CHEMBL368641,TN,INACT,0.019999999552965164	CHEMBL255793,TN,INACT,0.0	CHEMBL143761,TN,INACT,0.019999999552965164	CHEMBL3667936,TP,ACT,0.9700000286102295	CHEMBL377961,TP,ACT,1.0	CHEMBL190427,FN,ACT,0.14000000059604645	CHEMBL312285,TN,INACT,0.009999999776482582	CHEMBL150365,TN,INACT,0.0	CHEMBL40317,TN,INACT,0.0	CHEMBL214560,TP,ACT,1.0	CHEMBL470301,TP,ACT,0.9900000095367432	CHEMBL364463,TP,ACT,1.0	CHEMBL467772,TP,ACT,1.0	CHEMBL486688,TN,INACT,0.0	CHEMBL1161318,TP,ACT,0.9900000095367432	CHEMBL3663368,TP,ACT,1.0	CHEMBL199073,TP,ACT,1.0	CHEMBL62808,TN,INACT,0.0	CHEMBL121314,TN,INACT,0.0	CHEMBL327450,TP,ACT,0.9900000095367432	CHEMBL574412,TN,INACT,0.029999999329447746	CHEMBL68738,TN,INACT,0.009999999776482582	CHEMBL188459,FN,ACT,0.6800000071525574	CHEMBL2079546,TN,INACT,0.4699999988079071	CHEMBL301559,TN,INACT,0.009999999776482582	CHEMBL2181969,TN,INACT,0.019999999552965164	CHEMBL101162,TN,INACT,0.0	CHEMBL604965,TN,INACT,0.019999999552965164	CHEMBL56,TN,INACT,0.0	CHEMBL392401,TN,INACT,0.009999999776482582	CHEMBL198665,FN,ACT,0.25999999046325684	CHEMBL457059,TP,ACT,0.9900000095367432	CHEMBL2042407,TN,INACT,0.019999999552965164	CHEMBL257547,TN,INACT,0.10000000149011612	CHEMBL3663381,TP,ACT,0.9900000095367432	CHEMBL3663327,TP,ACT,0.9900000095367432	CHEMBL3310159,TN,INACT,0.009999999776482582	CHEMBL1162590,TN,INACT,0.27000001072883606	CHEMBL318830,FP,INACT,1.0	CHEMBL364519,TP,ACT,0.9100000262260437	CHEMBL450463,TN,INACT,0.0	CHEMBL2426688,TN,INACT,0.05000000074505806	CHEMBL3144728,FP,INACT,0.949999988079071	CHEMBL236757,TN,INACT,0.0	CHEMBL1209788,TP,ACT,1.0	CHEMBL2063250,TN,INACT,0.15000000596046448	CHEMBL3663345,TP,ACT,0.9900000095367432	CHEMBL211792,TP,ACT,1.0	CHEMBL322935,TN,INACT,0.009999999776482582	CHEMBL2070253,TP,ACT,0.9200000166893005	CHEMBL371896,FN,ACT,0.009999999776482582	CHEMBL3644347,TP,ACT,1.0	CHEMBL303369,TN,INACT,0.0	CHEMBL3663359,TP,ACT,1.0	CHEMBL250495,TP,ACT,1.0	CHEMBL104994,TN,INACT,0.009999999776482582	CHEMBL417171,TN,INACT,0.009999999776482582	CHEMBL241279,TN,INACT,0.0	CHEMBL312551,TN,INACT,0.0	CHEMBL165175,TN,INACT,0.0	CHEMBL74300,TN,INACT,0.0	CHEMBL250797,TP,ACT,1.0	CHEMBL434029,FN,ACT,0.6000000238418579	CHEMBL303737,TN,INACT,0.0	CHEMBL316687,TN,INACT,0.019999999552965164	CHEMBL452924,TN,INACT,0.0	CHEMBL160626,TN,INACT,0.029999999329447746	CHEMBL342470,TP,ACT,1.0	CHEMBL429314,FN,ACT,0.36000001430511475	CHEMBL15499,TN,INACT,0.0	CHEMBL81923,TN,INACT,0.0	CHEMBL97283,TN,INACT,0.05000000074505806	CHEMBL3667953,TP,ACT,0.9800000190734863	CHEMBL402588,TP,ACT,1.0	CHEMBL9168,TN,INACT,0.05999999865889549	CHEMBL3667915,TP,ACT,0.9900000095367432	CHEMBL1484,TN,INACT,0.5400000214576721	CHEMBL26607,TN,INACT,0.0	CHEMBL8201,TN,INACT,0.0	CHEMBL401593,TP,ACT,1.0	CHEMBL441738,TP,ACT,0.9900000095367432	CHEMBL25976,TN,INACT,0.07999999821186066	CHEMBL89004,TP,ACT,1.0	CHEMBL535602,TN,INACT,0.029999999329447746	CHEMBL2096751,TN,INACT,0.0	CHEMBL241101,TN,INACT,0.019999999552965164	CHEMBL3354726,FN,ACT,0.07999999821186066	CHEMBL236423,TP,ACT,1.0	CHEMBL2062850,TN,INACT,0.019999999552965164	CHEMBL368629,TN,INACT,0.0	CHEMBL416788,TN,INACT,0.10999999940395355	CHEMBL212303,TP,ACT,1.0	CHEMBL255261,TP,ACT,1.0	CHEMBL391183,TP,ACT,1.0	CHEMBL400510,TP,ACT,1.0	CHEMBL2431107,TN,INACT,0.05000000074505806	CHEMBL213381,TP,ACT,1.0	CHEMBL246837,TP,ACT,1.0	CHEMBL89575,TN,INACT,0.0	CHEMBL506272,TP,ACT,1.0	CHEMBL236519,TP,ACT,1.0	CHEMBL237146,TP,ACT,0.9599999785423279	CHEMBL438749,TP,ACT,1.0	CHEMBL59597,TN,INACT,0.0	CHEMBL293874,FP,INACT,0.9900000095367432	CHEMBL412495,TP,ACT,0.9900000095367432	CHEMBL609247,TN,INACT,0.0	CHEMBL249168,TP,ACT,0.949999988079071	CHEMBL187521,TP,ACT,1.0	CHEMBL236803,TP,ACT,1.0	CHEMBL1790738,TN,INACT,0.0	CHEMBL235215,TP,ACT,1.0	CHEMBL2111789,TN,INACT,0.05999999865889549	CHEMBL524060,TP,ACT,1.0	CHEMBL220334,TN,INACT,0.20000000298023224	CHEMBL379490,TP,ACT,1.0	CHEMBL2113141,TP,ACT,1.0	CHEMBL3663318,TP,ACT,0.9900000095367432	CHEMBL286800,TN,INACT,0.009999999776482582	CHEMBL312384,TN,INACT,0.0	CHEMBL392094,FN,ACT,0.029999999329447746	CHEMBL344866,TN,INACT,0.10000000149011612	CHEMBL3663358,TP,ACT,1.0	CHEMBL91362,TN,INACT,0.07000000029802322	CHEMBL240357,TP,ACT,0.9900000095367432	CHEMBL288169,TN,INACT,0.0	CHEMBL362129,TP,ACT,1.0	CHEMBL252231,TN,INACT,0.03999999910593033	CHEMBL317398,TN,INACT,0.0	CHEMBL103950,TN,INACT,0.0	CHEMBL378425,TP,ACT,1.0	CHEMBL3601426,TP,ACT,1.0	CHEMBL1180343,TN,INACT,0.10999999940395355	CHEMBL215886,TP,ACT,1.0	CHEMBL185417,TP,ACT,1.0	CHEMBL355851,TN,INACT,0.009999999776482582	CHEMBL334255,FN,ACT,0.0	CHEMBL3349053,TN,INACT,0.009999999776482582	CHEMBL199186,TN,INACT,0.019999999552965164	CHEMBL2113697,TN,INACT,0.009999999776482582	CHEMBL313379,TN,INACT,0.019999999552965164	CHEMBL2316388,TN,INACT,0.14000000059604645	CHEMBL341316,TP,ACT,1.0	CHEMBL138901,TP,ACT,0.8100000023841858	CHEMBL75141,TN,INACT,0.09000000357627869	CHEMBL252198,TN,INACT,0.009999999776482582	CHEMBL104848,TN,INACT,0.0	CHEMBL256286,TP,ACT,1.0	CHEMBL3663322,TP,ACT,1.0	CHEMBL186227,TP,ACT,1.0	CHEMBL351508,TN,INACT,0.07999999821186066	CHEMBL378408,TP,ACT,1.0	CHEMBL2035944,TP,ACT,0.8500000238418579	CHEMBL3423402,TN,INACT,0.5799999833106995	CHEMBL386707,TP,ACT,1.0	CHEMBL2112664,TN,INACT,0.009999999776482582	CHEMBL360603,TP,ACT,1.0	CHEMBL284887,TN,INACT,0.009999999776482582	CHEMBL275481,TN,INACT,0.20999999344348907	CHEMBL3754008,TN,INACT,0.009999999776482582	CHEMBL2070242,TP,ACT,0.9900000095367432	CHEMBL64903,TN,INACT,0.03999999910593033	CHEMBL51561,TN,INACT,0.0	CHEMBL215617,TP,ACT,1.0	CHEMBL253788,TP,ACT,0.949999988079071	CHEMBL233135,TP,ACT,1.0	CHEMBL66789,TN,INACT,0.05000000074505806	CHEMBL312998,TP,ACT,1.0	CHEMBL360422,TP,ACT,1.0	CHEMBL3663354,TP,ACT,1.0	CHEMBL3667920,TP,ACT,1.0	CHEMBL364711,FN,ACT,0.4300000071525574	CHEMBL394161,TP,ACT,1.0	CHEMBL372621,TP,ACT,1.0	CHEMBL85460,TN,INACT,0.0	CHEMBL143304,TN,INACT,0.3199999928474426	CHEMBL451211,TN,INACT,0.019999999552965164	CHEMBL248205,TP,ACT,1.0	CHEMBL206367,TP,ACT,0.9900000095367432	CHEMBL251997,TN,INACT,0.029999999329447746	CHEMBL235140,TP,ACT,1.0	CHEMBL319356,TN,INACT,0.0	CHEMBL513128,TP,ACT,0.8700000047683716	CHEMBL392092,TP,ACT,1.0	CHEMBL503,TN,INACT,0.7400000095367432	CHEMBL1258999,TN,INACT,0.019999999552965164	CHEMBL105764,TN,INACT,0.0	CHEMBL191159,TP,ACT,1.0	CHEMBL64559,TN,INACT,0.25	CHEMBL399801,TP,ACT,1.0	CHEMBL383719,TP,ACT,1.0	CHEMBL405601,TP,ACT,0.8500000238418579	CHEMBL249571,TP,ACT,1.0	CHEMBL406764,TP,ACT,1.0	CHEMBL216046,TN,INACT,0.009999999776482582	CHEMBL188404,TP,ACT,1.0	CHEMBL186675,TP,ACT,1.0	CHEMBL9219,TN,INACT,0.009999999776482582	CHEMBL2443002,TN,INACT,0.029999999329447746	CHEMBL88630,TP,ACT,0.9399999976158142	CHEMBL236861,TP,ACT,1.0	CHEMBL27065,TN,INACT,0.10000000149011612	CHEMBL519726,TN,INACT,0.009999999776482582	CHEMBL44615,TN,INACT,0.0	CHEMBL140693,TN,INACT,0.10000000149011612	CHEMBL2042403,TN,INACT,0.0	CHEMBL213721,TP,ACT,0.9900000095367432	CHEMBL225964,TP,ACT,1.0	CHEMBL364834,FN,ACT,0.25	CHEMBL89689,TN,INACT,0.0	CHEMBL452838,TP,ACT,1.0	CHEMBL589973,TN,INACT,0.6100000143051147	CHEMBL396434,TP,ACT,0.9599999785423279	CHEMBL3287338,TP,ACT,1.0	CHEMBL3646880,TP,ACT,1.0	CHEMBL610956,TN,INACT,0.4099999964237213	CHEMBL193409,TP,ACT,0.9700000286102295	CHEMBL413439,TP,ACT,0.9900000095367432	CHEMBL609645,TN,INACT,0.009999999776482582	CHEMBL285191,TN,INACT,0.0	CHEMBL389469,TP,ACT,1.0	CHEMBL2431237,TN,INACT,0.23000000417232513	CHEMBL238134,TN,INACT,0.05000000074505806	CHEMBL399474,FN,ACT,0.5299999713897705	CHEMBL3642127,TN,INACT,0.0	CHEMBL3287337,TP,ACT,1.0	CHEMBL64000,TN,INACT,0.009999999776482582	CHEMBL3287333,TP,ACT,0.9900000095367432	CHEMBL562384,TN,INACT,0.07000000029802322	CHEMBL110904,TN,INACT,0.07000000029802322	CHEMBL1090484,TP,ACT,0.9100000262260437	CHEMBL432620,TN,INACT,0.699999988079071	CHEMBL171310,TN,INACT,0.05000000074505806	CHEMBL432407,TP,ACT,1.0	CHEMBL94448,TN,INACT,0.6800000071525574	CHEMBL363757,TN,INACT,0.3100000023841858	CHEMBL458329,TP,ACT,1.0	CHEMBL553155,TN,INACT,0.0	CHEMBL364215,TP,ACT,1.0	CHEMBL248963,TP,ACT,1.0	CHEMBL177524,TN,INACT,0.029999999329447746	CHEMBL64829,TN,INACT,0.6100000143051147	CHEMBL85953,TN,INACT,0.0	CHEMBL1622248,TN,INACT,0.019999999552965164	CHEMBL213026,TP,ACT,1.0	CHEMBL310360,TN,INACT,0.0	CHEMBL389073,TP,ACT,0.9900000095367432	CHEMBL3234532,TN,INACT,0.009999999776482582	CHEMBL194761,TP,ACT,1.0	CHEMBL3667924,TP,ACT,1.0	CHEMBL194011,TP,ACT,0.9399999976158142	CHEMBL42228,TN,INACT,0.0	CHEMBL404854,FN,ACT,0.23000000417232513	CHEMBL1766946,TN,INACT,0.1599999964237213	CHEMBL118,TN,INACT,0.0	CHEMBL3290984,TN,INACT,0.05999999865889549	CHEMBL3644310,TP,ACT,0.9900000095367432	CHEMBL441136,TP,ACT,1.0	CHEMBL2112095,TN,INACT,0.0	CHEMBL363019,TP,ACT,0.9900000095367432	CHEMBL247088,TP,ACT,1.0	CHEMBL3667917,TP,ACT,1.0	CHEMBL331504,TN,INACT,0.009999999776482582	CHEMBL421531,TN,INACT,0.009999999776482582	CHEMBL344284,TN,INACT,0.05000000074505806	CHEMBL1209382,TP,ACT,1.0	CHEMBL289894,TN,INACT,0.0	CHEMBL8743,FN,ACT,0.0	CHEMBL226281,TP,ACT,1.0	CHEMBL3601432,TP,ACT,1.0	CHEMBL91957,TP,ACT,1.0	CHEMBL3114164,TN,INACT,0.0	CHEMBL117899,TN,INACT,0.009999999776482582	CHEMBL26522,TN,INACT,0.0	CHEMBL83905,TN,INACT,0.0	CHEMBL2391356,TN,INACT,0.0	CHEMBL449050,TP,ACT,0.9800000190734863	CHEMBL80845,TN,INACT,0.0	CHEMBL226496,TP,ACT,1.0	CHEMBL262319,TP,ACT,1.0	CHEMBL193,TN,INACT,0.029999999329447746	CHEMBL2112603,FN,ACT,0.05000000074505806	CHEMBL422109,TP,ACT,0.9599999785423279	CHEMBL232724,TP,ACT,1.0	CHEMBL1801141,TP,ACT,1.0	CHEMBL211202,TP,ACT,1.0	CHEMBL95590,TN,INACT,0.0	CHEMBL213747,TP,ACT,1.0	CHEMBL3663317,TP,ACT,0.9900000095367432	CHEMBL503909,TP,ACT,0.9900000095367432	CHEMBL377778,TP,ACT,0.9900000095367432	CHEMBL573950,TN,INACT,0.009999999776482582	CHEMBL29582,TP,ACT,1.0	CHEMBL443953,TN,INACT,0.05999999865889549	CHEMBL338768,TP,ACT,0.9800000190734863	CHEMBL2114058,TN,INACT,0.009999999776482582	CHEMBL2371147,TN,INACT,0.7699999809265137	CHEMBL283535,TN,INACT,0.09000000357627869	CHEMBL458465,TN,INACT,0.0	CHEMBL125925,TN,INACT,0.5799999833106995	CHEMBL3087709,TN,INACT,0.11999999731779099	CHEMBL236639,FN,ACT,0.27000001072883606	CHEMBL29471,TN,INACT,0.009999999776482582	CHEMBL3644297,TP,ACT,1.0	CHEMBL254278,TP,ACT,1.0	CHEMBL248700,FN,ACT,0.75	CHEMBL3667918,TP,ACT,1.0	CHEMBL197541,TP,ACT,1.0	CHEMBL379959,FN,ACT,0.5600000023841858	CHEMBL50993,TN,INACT,0.009999999776482582	CHEMBL133184,TN,INACT,0.009999999776482582	CHEMBL1161316,TP,ACT,0.9599999785423279	CHEMBL323517,TN,INACT,0.0	CHEMBL1801121,TP,ACT,1.0	CHEMBL140108,TP,ACT,1.0	CHEMBL209825,TP,ACT,1.0	CHEMBL438294,TP,ACT,1.0	CHEMBL399715,TP,ACT,1.0	CHEMBL226279,TP,ACT,1.0	CHEMBL1761873,TP,ACT,0.9700000286102295	CHEMBL185469,TP,ACT,1.0	CHEMBL281811,TN,INACT,0.0	CHEMBL1158,TN,INACT,0.0	CHEMBL223625,TN,INACT,0.0	CHEMBL542544,TN,INACT,0.0	CHEMBL116367,TN,INACT,0.0	CHEMBL1923666,TP,ACT,0.9700000286102295	CHEMBL225800,TP,ACT,1.0	CHEMBL323723,TN,INACT,0.009999999776482582	CHEMBL3354737,TP,ACT,0.9900000095367432	CHEMBL543030,TN,INACT,0.0	CHEMBL2092951,TN,INACT,0.019999999552965164	CHEMBL8418,TN,INACT,0.07000000029802322	CHEMBL24586,TN,INACT,0.0	CHEMBL2021988,TN,INACT,0.009999999776482582	CHEMBL26061,TN,INACT,0.0	CHEMBL120370,TN,INACT,0.0	CHEMBL402838,TP,ACT,1.0	CHEMBL362158,TP,ACT,1.0	CHEMBL345551,TN,INACT,0.07000000029802322	CHEMBL15988,TN,INACT,0.0	CHEMBL455394,TP,ACT,1.0	CHEMBL512496,TP,ACT,0.9900000095367432	CHEMBL185852,FN,ACT,0.029999999329447746	CHEMBL27099,TN,INACT,0.0	CHEMBL418678,TN,INACT,0.36000001430511475	CHEMBL3421678,TP,ACT,0.9900000095367432	CHEMBL142822,TN,INACT,0.009999999776482582	CHEMBL235893,TP,ACT,1.0	CHEMBL174632,TN,INACT,0.009999999776482582	CHEMBL2113685,TN,INACT,0.0	CHEMBL316857,TN,INACT,0.0	CHEMBL3663323,TP,ACT,1.0	CHEMBL254279,TP,ACT,1.0	CHEMBL133257,FP,INACT,0.8999999761581421	CHEMBL3663344,TP,ACT,0.9900000095367432	CHEMBL3663379,TP,ACT,1.0	CHEMBL205996,TP,ACT,0.9900000095367432	CHEMBL85999,TN,INACT,0.0	CHEMBL238149,FN,ACT,0.029999999329447746	CHEMBL3667956,TP,ACT,1.0	CHEMBL370321,TP,ACT,1.0	CHEMBL509475,TP,ACT,1.0	CHEMBL408398,TP,ACT,0.8700000047683716	CHEMBL3667947,TP,ACT,1.0	CHEMBL2035940,TP,ACT,0.9700000286102295	CHEMBL179138,TN,INACT,0.0	CHEMBL3114144,TN,INACT,0.0	CHEMBL89852,TN,INACT,0.0	CHEMBL248670,TP,ACT,1.0	CHEMBL237079,TN,INACT,0.029999999329447746	CHEMBL232775,TP,ACT,0.9599999785423279	CHEMBL396433,TP,ACT,1.0	CHEMBL383120,TP,ACT,1.0	CHEMBL110018,TN,INACT,0.0	CHEMBL253530,TN,INACT,0.019999999552965164	CHEMBL1835941,TP,ACT,1.0	CHEMBL3644354,TP,ACT,0.9399999976158142	CHEMBL427666,TP,ACT,1.0	CHEMBL3646857,TP,ACT,0.9900000095367432	CHEMBL384852,TP,ACT,0.9700000286102295	CHEMBL264306,TP,ACT,0.9900000095367432	CHEMBL608330,TN,INACT,0.10999999940395355	CHEMBL275299,TP,ACT,0.8399999737739563	CHEMBL3338850,TN,INACT,0.009999999776482582	CHEMBL3217760,FP,INACT,0.9100000262260437	CHEMBL401585,TP,ACT,1.0	CHEMBL396940,TP,ACT,0.9800000190734863	CHEMBL452955,TN,INACT,0.009999999776482582	CHEMBL33438,TN,INACT,0.0	CHEMBL404206,TP,ACT,1.0	CHEMBL144114,TN,INACT,0.0	CHEMBL322678,TN,INACT,0.0	CHEMBL387851,TN,INACT,0.4300000071525574	CHEMBL2371964,TP,ACT,0.9800000190734863	CHEMBL430882,TN,INACT,0.20000000298023224	CHEMBL268190,TN,INACT,0.05999999865889549	CHEMBL536800,TN,INACT,0.0	CHEMBL276906,TN,INACT,0.18000000715255737	CHEMBL42,TN,INACT,0.0	CHEMBL236737,TP,ACT,1.0	CHEMBL172163,TN,INACT,0.019999999552965164	CHEMBL63790,TN,INACT,0.18000000715255737	CHEMBL2370238,TN,INACT,0.5199999809265137	CHEMBL3646879,TP,ACT,1.0	CHEMBL1761871,FN,ACT,0.699999988079071	CHEMBL418411,TN,INACT,0.009999999776482582	CHEMBL3769501,TN,INACT,0.0	CHEMBL2323792,FP,INACT,1.0	CHEMBL508011,TN,INACT,0.0	CHEMBL438297,FP,INACT,0.8899999856948853	CHEMBL254490,TP,ACT,1.0	CHEMBL25427,TN,INACT,0.0	CHEMBL606990,FN,ACT,0.3100000023841858	CHEMBL3290986,TN,INACT,0.019999999552965164	CHEMBL2207493,TN,INACT,0.0	CHEMBL63631,TN,INACT,0.0	CHEMBL2035936,FN,ACT,0.6700000166893005	CHEMBL1172252,TP,ACT,0.9100000262260437	CHEMBL283606,TN,INACT,0.019999999552965164	CHEMBL17857,TN,INACT,0.029999999329447746	CHEMBL15936,TN,INACT,0.019999999552965164	CHEMBL399714,TP,ACT,1.0	CHEMBL3644295,TP,ACT,1.0	CHEMBL187774,TP,ACT,1.0	CHEMBL1209252,TP,ACT,1.0	CHEMBL16639,TN,INACT,0.0	CHEMBL595265,TN,INACT,0.009999999776482582	CHEMBL294349,TN,INACT,0.0	CHEMBL307857,TP,ACT,0.9800000190734863	CHEMBL226024,TP,ACT,1.0	CHEMBL378571,TP,ACT,0.9300000071525574	CHEMBL62660,TN,INACT,0.0	CHEMBL3644326,TP,ACT,1.0	CHEMBL251966,TP,ACT,1.0	CHEMBL488030,TP,ACT,1.0	CHEMBL297139,TN,INACT,0.009999999776482582	CHEMBL292725,TN,INACT,0.019999999552965164	CHEMBL213214,TP,ACT,1.0	CHEMBL477665,TN,INACT,0.009999999776482582	CHEMBL267265,TP,ACT,0.9900000095367432	CHEMBL2092821,TN,INACT,0.009999999776482582	CHEMBL2145454,FN,ACT,0.6200000047683716	CHEMBL215906,TP,ACT,1.0	CHEMBL264120,FN,ACT,0.23999999463558197	CHEMBL95897,TN,INACT,0.0	CHEMBL501388,TN,INACT,0.23000000417232513	CHEMBL233559,TP,ACT,0.9599999785423279	CHEMBL34328,TN,INACT,0.0	CHEMBL1801116,TP,ACT,1.0	CHEMBL236527,TP,ACT,1.0	CHEMBL412024,TP,ACT,1.0	CHEMBL106487,TN,INACT,0.009999999776482582	CHEMBL3287831,TN,INACT,0.0	CHEMBL91786,TN,INACT,0.0	CHEMBL300735,TN,INACT,0.019999999552965164	CHEMBL232951,TP,ACT,1.0	CHEMBL16108,TN,INACT,0.0	CHEMBL114074,TN,INACT,0.47999998927116394	CHEMBL152986,TN,INACT,0.3199999928474426	CHEMBL3646872,TP,ACT,0.9800000190734863	CHEMBL129014,TN,INACT,0.009999999776482582	CHEMBL439790,TN,INACT,0.0	CHEMBL433598,TP,ACT,1.0	CHEMBL364577,TP,ACT,1.0	CHEMBL377480,TP,ACT,1.0	CHEMBL284855,TN,INACT,0.0	CHEMBL404557,TN,INACT,0.0	CHEMBL208552,TP,ACT,1.0	CHEMBL366573,TN,INACT,0.0	CHEMBL97436,TN,INACT,0.029999999329447746	CHEMBL215697,TP,ACT,0.949999988079071	CHEMBL209587,TP,ACT,1.0	CHEMBL113184,TN,INACT,0.029999999329447746	CHEMBL436903,TP,ACT,0.8299999833106995	CHEMBL123263,TP,ACT,1.0	CHEMBL235138,TP,ACT,1.0	CHEMBL84919,TN,INACT,0.0	CHEMBL293577,TN,INACT,0.009999999776482582	CHEMBL287156,TN,INACT,0.5699999928474426	CHEMBL402017,TP,ACT,1.0	CHEMBL117036,TN,INACT,0.009999999776482582	CHEMBL370926,TP,ACT,1.0	CHEMBL2237157,TN,INACT,0.5400000214576721	CHEMBL364582,TP,ACT,1.0	CHEMBL73392,TN,INACT,0.0	CHEMBL138746,TN,INACT,0.6399999856948853	CHEMBL312266,TN,INACT,0.0	CHEMBL1209796,TP,ACT,0.9900000095367432	CHEMBL263948,TP,ACT,0.9800000190734863	CHEMBL184424,TP,ACT,1.0	CHEMBL399811,FN,ACT,0.5	CHEMBL1916697,TN,INACT,0.0	CHEMBL1765671,TN,INACT,0.07999999821186066	CHEMBL60905,TN,INACT,0.009999999776482582	CHEMBL232972,TP,ACT,0.9900000095367432	CHEMBL2113466,TN,INACT,0.009999999776482582	CHEMBL455189,TP,ACT,0.9800000190734863	CHEMBL236110,TP,ACT,1.0	CHEMBL414101,TP,ACT,1.0	CHEMBL337351,TP,ACT,0.8600000143051147	CHEMBL112770,TN,INACT,0.07000000029802322	CHEMBL3646854,TP,ACT,1.0	CHEMBL412023,TP,ACT,1.0	CHEMBL168372,TN,INACT,0.009999999776482582	CHEMBL400191,TP,ACT,1.0	CHEMBL27809,TN,INACT,0.009999999776482582	CHEMBL144501,TN,INACT,0.0	CHEMBL269576,TN,INACT,0.0	CHEMBL305558,TN,INACT,0.009999999776482582	CHEMBL225801,TP,ACT,1.0	CHEMBL554950,TN,INACT,0.009999999776482582	CHEMBL1214436,TN,INACT,0.03999999910593033	CHEMBL8129,TN,INACT,0.019999999552965164	CHEMBL3663334,TP,ACT,0.9900000095367432	CHEMBL303386,TN,INACT,0.23000000417232513	CHEMBL428480,TN,INACT,0.019999999552965164	CHEMBL258295,FN,ACT,0.550000011920929	CHEMBL61479,FP,INACT,0.9599999785423279	CHEMBL125829,TN,INACT,0.05999999865889549	CHEMBL141354,TN,INACT,0.1899999976158142	CHEMBL437406,TP,ACT,0.949999988079071	CHEMBL8412,TN,INACT,0.0	CHEMBL272514,TP,ACT,1.0	CHEMBL235676,TP,ACT,1.0	CHEMBL73740,TN,INACT,0.03999999910593033	CHEMBL37512,TN,INACT,0.009999999776482582	CHEMBL509340,TP,ACT,0.9900000095367432	CHEMBL430734,TN,INACT,0.07999999821186066	CHEMBL214582,TP,ACT,1.0	CHEMBL249064,TP,ACT,1.0	CHEMBL337212,TN,INACT,0.05000000074505806	CHEMBL344154,TN,INACT,0.019999999552965164	CHEMBL62527,TN,INACT,0.0	CHEMBL267014,TN,INACT,0.03999999910593033	CHEMBL563666,TN,INACT,0.0	CHEMBL3114139,TN,INACT,0.0	CHEMBL513404,TP,ACT,1.0	CHEMBL379400,TP,ACT,1.0	CHEMBL2372588,TP,ACT,1.0	CHEMBL454918,TP,ACT,1.0	CHEMBL195110,TP,ACT,1.0	CHEMBL205552,FN,ACT,0.20999999344348907	CHEMBL2415082,TP,ACT,1.0	CHEMBL170026,TN,INACT,0.1599999964237213	CHEMBL435697,TP,ACT,1.0	CHEMBL2112488,TN,INACT,0.019999999552965164	CHEMBL312958,TN,INACT,0.009999999776482582	CHEMBL3403333,TN,INACT,0.009999999776482582	CHEMBL2062861,TN,INACT,0.019999999552965164	CHEMBL74860,TN,INACT,0.47999998927116394	CHEMBL2096693,TN,INACT,0.5	CHEMBL1076,TN,INACT,0.0	CHEMBL215519,TP,ACT,1.0	CHEMBL427860,TP,ACT,1.0	CHEMBL251380,TP,ACT,1.0	CHEMBL131235,TN,INACT,0.23000000417232513	CHEMBL553000,TP,ACT,1.0	CHEMBL212614,TP,ACT,1.0	CHEMBL378913,TP,ACT,1.0	CHEMBL403029,TN,INACT,0.07000000029802322	CHEMBL52800,TN,INACT,0.15000000596046448	CHEMBL190953,TP,ACT,0.9200000166893005	CHEMBL3667951,TP,ACT,1.0	CHEMBL186030,FN,ACT,0.019999999552965164	CHEMBL14642,TP,ACT,0.8600000143051147	CHEMBL3350496,TN,INACT,0.05000000074505806	CHEMBL26455,TN,INACT,0.0	CHEMBL237714,TP,ACT,1.0	CHEMBL367208,TN,INACT,0.699999988079071	CHEMBL398929,TP,ACT,0.9900000095367432	CHEMBL398665,TP,ACT,0.9800000190734863	CHEMBL538589,TP,ACT,1.0	CHEMBL114770,TN,INACT,0.0	CHEMBL1801094,TP,ACT,1.0	CHEMBL319534,TN,INACT,0.0	CHEMBL3326770,TN,INACT,0.07000000029802322	CHEMBL1161322,TP,ACT,1.0	CHEMBL333075,FN,ACT,0.23999999463558197	CHEMBL2113039,TP,ACT,1.0	CHEMBL430165,TP,ACT,1.0	CHEMBL366171,TP,ACT,1.0	CHEMBL340552,TN,INACT,0.09000000357627869	CHEMBL3642132,TN,INACT,0.0	CHEMBL239232,TN,INACT,0.18000000715255737	CHEMBL356923,FP,INACT,0.9700000286102295	CHEMBL44345,TN,INACT,0.6800000071525574	CHEMBL398408,TP,ACT,1.0	CHEMBL433413,TP,ACT,1.0	CHEMBL351088,TP,ACT,1.0	CHEMBL3287341,TP,ACT,1.0	CHEMBL97584,TN,INACT,0.05000000074505806	CHEMBL276676,FP,INACT,0.9700000286102295	CHEMBL1975908,TN,INACT,0.05000000074505806	CHEMBL2261429,TN,INACT,0.0	CHEMBL107680,TN,INACT,0.009999999776482582	CHEMBL1209194,TP,ACT,1.0	CHEMBL235359,FN,ACT,0.550000011920929	CHEMBL397607,TP,ACT,1.0	CHEMBL61539,TN,INACT,0.1899999976158142	CHEMBL71907,TN,INACT,0.10999999940395355	CHEMBL2113143,TP,ACT,1.0	CHEMBL368339,TN,INACT,0.6000000238418579	CHEMBL296715,TN,INACT,0.05999999865889549	CHEMBL10813,TN,INACT,0.009999999776482582	CHEMBL423405,TN,INACT,0.10999999940395355	CHEMBL8552,TN,INACT,0.0	CHEMBL3644358,TP,ACT,1.0	CHEMBL3799986,TN,INACT,0.0	CHEMBL3663376,TP,ACT,1.0	CHEMBL2070374,TP,ACT,1.0	CHEMBL419912,TN,INACT,0.0	CHEMBL38423,TN,INACT,0.0	CHEMBL197278,TP,ACT,1.0	CHEMBL71,TN,INACT,0.0	CHEMBL427270,TP,ACT,1.0	CHEMBL92152,TN,INACT,0.0	CHEMBL2063246,TN,INACT,0.5699999928474426	CHEMBL1090885,TP,ACT,0.8299999833106995	CHEMBL42219,TN,INACT,0.009999999776482582	CHEMBL180157,TP,ACT,0.9800000190734863	CHEMBL361210,TP,ACT,1.0	CHEMBL400511,TP,ACT,1.0	CHEMBL75590,TN,INACT,0.0	CHEMBL378448,FN,ACT,0.7099999785423279	CHEMBL3667960,TP,ACT,0.9800000190734863	CHEMBL297599,TN,INACT,0.0	CHEMBL299538,TN,INACT,0.27000001072883606	CHEMBL3354742,TP,ACT,0.9900000095367432	CHEMBL1801123,TP,ACT,1.0	CHEMBL410672,TP,ACT,0.9900000095367432	CHEMBL113,TN,INACT,0.0	CHEMBL501642,TP,ACT,0.9800000190734863	CHEMBL398854,TP,ACT,1.0	CHEMBL400786,TP,ACT,1.0	CHEMBL2425370,TN,INACT,0.12999999523162842	CHEMBL241082,TN,INACT,0.009999999776482582	CHEMBL2431111,TN,INACT,0.6800000071525574	CHEMBL276012,TP,ACT,0.9599999785423279	CHEMBL1801126,TP,ACT,1.0	CHEMBL413556,TP,ACT,1.0	CHEMBL208311,TN,INACT,0.009999999776482582	CHEMBL402075,TP,ACT,1.0	CHEMBL303435,TN,INACT,0.0	CHEMBL435901,FP,INACT,0.9900000095367432	CHEMBL31221,TN,INACT,0.0	CHEMBL2070245,TP,ACT,0.9900000095367432	CHEMBL293033,TN,INACT,0.0	CHEMBL2205616,TN,INACT,0.009999999776482582	CHEMBL84825,TN,INACT,0.0	CHEMBL1275791,TN,INACT,0.07000000029802322	CHEMBL400249,TP,ACT,1.0	CHEMBL1269571,TP,ACT,1.0	CHEMBL84583,TN,INACT,0.019999999552965164	CHEMBL9666,TN,INACT,0.0	CHEMBL3644321,TP,ACT,1.0	CHEMBL2021972,TN,INACT,0.009999999776482582	CHEMBL371366,FN,ACT,0.7799999713897705	CHEMBL365401,TP,ACT,1.0	CHEMBL418933,TN,INACT,0.009999999776482582	CHEMBL119555,TN,INACT,0.009999999776482582	CHEMBL279158,TN,INACT,0.0	CHEMBL400787,TP,ACT,1.0	CHEMBL1092860,TP,ACT,1.0	CHEMBL254487,TP,ACT,1.0	CHEMBL226497,TP,ACT,0.9200000166893005	CHEMBL100624,TN,INACT,0.0	CHEMBL211798,TP,ACT,0.9900000095367432	CHEMBL2113695,TN,INACT,0.07000000029802322	CHEMBL215131,TN,INACT,0.03999999910593033	CHEMBL237314,TN,INACT,0.0	CHEMBL225691,TP,ACT,0.8799999952316284	CHEMBL393994,TP,ACT,1.0	CHEMBL72710,TN,INACT,0.0	CHEMBL109206,TN,INACT,0.03999999910593033	CHEMBL389734,TN,INACT,0.0	CHEMBL2314764,TN,INACT,0.03999999910593033	CHEMBL1209706,TP,ACT,1.0	CHEMBL371105,TP,ACT,0.9399999976158142	CHEMBL192153,TP,ACT,0.9900000095367432	CHEMBL316259,TP,ACT,0.9200000166893005	CHEMBL500,TN,INACT,0.0	CHEMBL42129,TN,INACT,0.07999999821186066	CHEMBL363561,TP,ACT,1.0	CHEMBL2312376,TN,INACT,0.009999999776482582	CHEMBL193786,TP,ACT,1.0	CHEMBL63114,TN,INACT,0.009999999776482582	CHEMBL185200,TP,ACT,0.8799999952316284	CHEMBL343158,TN,INACT,0.0	CHEMBL262320,TP,ACT,1.0	CHEMBL193715,TP,ACT,0.8100000023841858	CHEMBL429854,TP,ACT,1.0	CHEMBL436169,TP,ACT,1.0	CHEMBL456886,TP,ACT,0.9900000095367432	CHEMBL672,TN,INACT,0.0	CHEMBL185725,TP,ACT,0.9900000095367432	CHEMBL1093858,TP,ACT,0.9700000286102295	CHEMBL328117,TP,ACT,0.9900000095367432	CHEMBL364629,TN,INACT,0.0	CHEMBL3287324,TP,ACT,0.949999988079071	CHEMBL3663351,TP,ACT,0.9900000095367432	CHEMBL3644283,TP,ACT,0.9900000095367432	CHEMBL401250,TP,ACT,1.0	CHEMBL151525,TN,INACT,0.14000000059604645	CHEMBL123660,FN,ACT,0.12999999523162842	CHEMBL540445,TN,INACT,0.0	CHEMBL236838,TP,ACT,0.9900000095367432	CHEMBL436122,TP,ACT,1.0	CHEMBL462009,TP,ACT,1.0	CHEMBL2181144,TN,INACT,0.0	CHEMBL3667921,TP,ACT,1.0	CHEMBL336033,TN,INACT,0.1899999976158142	CHEMBL180635,TP,ACT,0.9800000190734863	CHEMBL338767,TP,ACT,1.0	CHEMBL394075,TP,ACT,0.9900000095367432	CHEMBL452710,TP,ACT,0.9800000190734863	CHEMBL124410,TP,ACT,0.9399999976158142	CHEMBL3644331,TP,ACT,1.0	CHEMBL112669,TN,INACT,0.0	CHEMBL2112076,TN,INACT,0.4300000071525574	CHEMBL360296,TP,ACT,1.0	CHEMBL439158,TP,ACT,0.9800000190734863	CHEMBL75200,TN,INACT,0.0	CHEMBL396111,TP,ACT,0.9900000095367432	CHEMBL237502,TP,ACT,0.9599999785423279	

