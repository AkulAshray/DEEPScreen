CNNModel CHEMBL3468 adam 0.001 30 32 0 0.8 False True
Number of active compounds :	201
Number of inactive compounds :	134
---------------------------------
Run id: CNNModel_CHEMBL3468_adam_0.001_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3468_adam_0.001_30_32_0.8_True/
---------------------------------
Training samples: 211
Validation samples: 67
--
Training Step: 1  | time: 0.795s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/211
[A[ATraining Step: 2  | total loss: [1m[32m0.62353[0m[0m | time: 1.424s
[2K
| Adam | epoch: 001 | loss: 0.62353 - acc: 0.5625 -- iter: 064/211
[A[ATraining Step: 3  | total loss: [1m[32m0.68237[0m[0m | time: 2.073s
[2K
| Adam | epoch: 001 | loss: 0.68237 - acc: 0.4858 -- iter: 096/211
[A[ATraining Step: 4  | total loss: [1m[32m0.69049[0m[0m | time: 2.724s
[2K
| Adam | epoch: 001 | loss: 0.69049 - acc: 0.4964 -- iter: 128/211
[A[ATraining Step: 5  | total loss: [1m[32m0.69169[0m[0m | time: 3.361s
[2K
| Adam | epoch: 001 | loss: 0.69169 - acc: 0.5205 -- iter: 160/211
[A[ATraining Step: 6  | total loss: [1m[32m0.68835[0m[0m | time: 4.009s
[2K
| Adam | epoch: 001 | loss: 0.68835 - acc: 0.6279 -- iter: 192/211
[A[ATraining Step: 7  | total loss: [1m[32m0.67817[0m[0m | time: 5.440s
[2K
| Adam | epoch: 001 | loss: 0.67817 - acc: 0.7011 | val_loss: 0.64193 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 8  | total loss: [1m[32m0.66490[0m[0m | time: 0.502s
[2K
| Adam | epoch: 002 | loss: 0.66490 - acc: 0.6916 -- iter: 032/211
[A[ATraining Step: 9  | total loss: [1m[32m0.64530[0m[0m | time: 1.291s
[2K
| Adam | epoch: 002 | loss: 0.64530 - acc: 0.6877 -- iter: 064/211
[A[ATraining Step: 10  | total loss: [1m[32m0.72374[0m[0m | time: 2.006s
[2K
| Adam | epoch: 002 | loss: 0.72374 - acc: 0.6407 -- iter: 096/211
[A[ATraining Step: 11  | total loss: [1m[32m0.73179[0m[0m | time: 2.665s
[2K
| Adam | epoch: 002 | loss: 0.73179 - acc: 0.6037 -- iter: 128/211
[A[ATraining Step: 12  | total loss: [1m[32m0.67533[0m[0m | time: 3.318s
[2K
| Adam | epoch: 002 | loss: 0.67533 - acc: 0.6555 -- iter: 160/211
[A[ATraining Step: 13  | total loss: [1m[32m0.69343[0m[0m | time: 4.000s
[2K
| Adam | epoch: 002 | loss: 0.69343 - acc: 0.5754 -- iter: 192/211
[A[ATraining Step: 14  | total loss: [1m[32m0.69799[0m[0m | time: 5.662s
[2K
| Adam | epoch: 002 | loss: 0.69799 - acc: 0.5318 | val_loss: 0.67838 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 15  | total loss: [1m[32m0.68981[0m[0m | time: 0.439s
[2K
| Adam | epoch: 003 | loss: 0.68981 - acc: 0.5683 -- iter: 032/211
[A[ATraining Step: 16  | total loss: [1m[32m0.68265[0m[0m | time: 0.834s
[2K
| Adam | epoch: 003 | loss: 0.68265 - acc: 0.6315 -- iter: 064/211
[A[ATraining Step: 17  | total loss: [1m[32m0.67948[0m[0m | time: 1.498s
[2K
| Adam | epoch: 003 | loss: 0.67948 - acc: 0.6694 -- iter: 096/211
[A[ATraining Step: 18  | total loss: [1m[32m0.68585[0m[0m | time: 2.193s
[2K
| Adam | epoch: 003 | loss: 0.68585 - acc: 0.5891 -- iter: 128/211
[A[ATraining Step: 19  | total loss: [1m[32m0.68847[0m[0m | time: 3.077s
[2K
| Adam | epoch: 003 | loss: 0.68847 - acc: 0.5594 -- iter: 160/211
[A[ATraining Step: 20  | total loss: [1m[32m0.69087[0m[0m | time: 3.902s
[2K
| Adam | epoch: 003 | loss: 0.69087 - acc: 0.5303 -- iter: 192/211
[A[ATraining Step: 21  | total loss: [1m[32m0.68931[0m[0m | time: 5.629s
[2K
| Adam | epoch: 003 | loss: 0.68931 - acc: 0.5597 | val_loss: 0.68354 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 22  | total loss: [1m[32m0.68528[0m[0m | time: 0.822s
[2K
| Adam | epoch: 004 | loss: 0.68528 - acc: 0.6261 -- iter: 032/211
[A[ATraining Step: 23  | total loss: [1m[32m0.68593[0m[0m | time: 1.343s
[2K
| Adam | epoch: 004 | loss: 0.68593 - acc: 0.6167 -- iter: 064/211
[A[ATraining Step: 24  | total loss: [1m[32m0.68371[0m[0m | time: 1.828s
[2K
| Adam | epoch: 004 | loss: 0.68371 - acc: 0.6505 -- iter: 096/211
[A[ATraining Step: 25  | total loss: [1m[32m0.68288[0m[0m | time: 2.469s
[2K
| Adam | epoch: 004 | loss: 0.68288 - acc: 0.6597 -- iter: 128/211
[A[ATraining Step: 26  | total loss: [1m[32m0.68582[0m[0m | time: 3.126s
[2K
| Adam | epoch: 004 | loss: 0.68582 - acc: 0.6174 -- iter: 160/211
[A[ATraining Step: 27  | total loss: [1m[32m0.68855[0m[0m | time: 3.785s
[2K
| Adam | epoch: 004 | loss: 0.68855 - acc: 0.5792 -- iter: 192/211
[A[ATraining Step: 28  | total loss: [1m[32m0.68530[0m[0m | time: 5.525s
[2K
| Adam | epoch: 004 | loss: 0.68530 - acc: 0.6141 | val_loss: 0.67885 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 29  | total loss: [1m[32m0.68338[0m[0m | time: 0.946s
[2K
| Adam | epoch: 005 | loss: 0.68338 - acc: 0.6319 -- iter: 032/211
[A[ATraining Step: 30  | total loss: [1m[32m0.68673[0m[0m | time: 1.815s
[2K
| Adam | epoch: 005 | loss: 0.68673 - acc: 0.5933 -- iter: 064/211
[A[ATraining Step: 31  | total loss: [1m[32m0.68619[0m[0m | time: 2.414s
[2K
| Adam | epoch: 005 | loss: 0.68619 - acc: 0.5934 -- iter: 096/211
[A[ATraining Step: 32  | total loss: [1m[32m0.68340[0m[0m | time: 2.840s
[2K
| Adam | epoch: 005 | loss: 0.68340 - acc: 0.6138 -- iter: 128/211
[A[ATraining Step: 33  | total loss: [1m[32m0.68085[0m[0m | time: 3.795s
[2K
| Adam | epoch: 005 | loss: 0.68085 - acc: 0.6293 -- iter: 160/211
[A[ATraining Step: 34  | total loss: [1m[32m0.67831[0m[0m | time: 4.599s
[2K
| Adam | epoch: 005 | loss: 0.67831 - acc: 0.6418 -- iter: 192/211
[A[ATraining Step: 35  | total loss: [1m[32m0.68617[0m[0m | time: 6.420s
[2K
| Adam | epoch: 005 | loss: 0.68617 - acc: 0.5859 | val_loss: 0.66974 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 36  | total loss: [1m[32m0.68407[0m[0m | time: 1.108s
[2K
| Adam | epoch: 006 | loss: 0.68407 - acc: 0.5939 -- iter: 032/211
[A[ATraining Step: 37  | total loss: [1m[32m0.68447[0m[0m | time: 2.242s
[2K
| Adam | epoch: 006 | loss: 0.68447 - acc: 0.5876 -- iter: 064/211
[A[ATraining Step: 38  | total loss: [1m[32m0.68589[0m[0m | time: 3.208s
[2K
| Adam | epoch: 006 | loss: 0.68589 - acc: 0.5766 -- iter: 096/211
[A[ATraining Step: 39  | total loss: [1m[32m0.68241[0m[0m | time: 3.671s
[2K
| Adam | epoch: 006 | loss: 0.68241 - acc: 0.5919 -- iter: 128/211
[A[ATraining Step: 40  | total loss: [1m[32m0.67149[0m[0m | time: 4.226s
[2K
| Adam | epoch: 006 | loss: 0.67149 - acc: 0.6388 -- iter: 160/211
[A[ATraining Step: 41  | total loss: [1m[32m0.66060[0m[0m | time: 4.877s
[2K
| Adam | epoch: 006 | loss: 0.66060 - acc: 0.6761 -- iter: 192/211
[A[ATraining Step: 42  | total loss: [1m[32m0.66168[0m[0m | time: 6.525s
[2K
| Adam | epoch: 006 | loss: 0.66168 - acc: 0.6669 | val_loss: 0.64463 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 43  | total loss: [1m[32m0.67135[0m[0m | time: 0.877s
[2K
| Adam | epoch: 007 | loss: 0.67135 - acc: 0.6375 -- iter: 032/211
[A[ATraining Step: 44  | total loss: [1m[32m0.67017[0m[0m | time: 1.789s
[2K
| Adam | epoch: 007 | loss: 0.67017 - acc: 0.6353 -- iter: 064/211
[A[ATraining Step: 45  | total loss: [1m[32m0.68350[0m[0m | time: 2.869s
[2K
| Adam | epoch: 007 | loss: 0.68350 - acc: 0.6070 -- iter: 096/211
[A[ATraining Step: 46  | total loss: [1m[32m0.68507[0m[0m | time: 3.836s
[2K
| Adam | epoch: 007 | loss: 0.68507 - acc: 0.5996 -- iter: 128/211
[A[ATraining Step: 47  | total loss: [1m[32m0.68574[0m[0m | time: 4.318s
[2K
| Adam | epoch: 007 | loss: 0.68574 - acc: 0.5935 -- iter: 160/211
[A[ATraining Step: 48  | total loss: [1m[32m0.68144[0m[0m | time: 4.792s
[2K
| Adam | epoch: 007 | loss: 0.68144 - acc: 0.5996 -- iter: 192/211
[A[ATraining Step: 49  | total loss: [1m[32m0.67880[0m[0m | time: 6.447s
[2K
| Adam | epoch: 007 | loss: 0.67880 - acc: 0.6047 | val_loss: 0.65618 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 50  | total loss: [1m[32m0.68449[0m[0m | time: 1.015s
[2K
| Adam | epoch: 008 | loss: 0.68449 - acc: 0.5836 -- iter: 032/211
[A[ATraining Step: 51  | total loss: [1m[32m0.68735[0m[0m | time: 1.871s
[2K
| Adam | epoch: 008 | loss: 0.68735 - acc: 0.5708 -- iter: 064/211
[A[ATraining Step: 52  | total loss: [1m[32m0.68434[0m[0m | time: 2.527s
[2K
| Adam | epoch: 008 | loss: 0.68434 - acc: 0.5790 -- iter: 096/211
[A[ATraining Step: 53  | total loss: [1m[32m0.68578[0m[0m | time: 3.193s
[2K
| Adam | epoch: 008 | loss: 0.68578 - acc: 0.5719 -- iter: 128/211
[A[ATraining Step: 54  | total loss: [1m[32m0.68203[0m[0m | time: 3.833s
[2K
| Adam | epoch: 008 | loss: 0.68203 - acc: 0.5842 -- iter: 160/211
[A[ATraining Step: 55  | total loss: [1m[32m0.67808[0m[0m | time: 4.381s
[2K
| Adam | epoch: 008 | loss: 0.67808 - acc: 0.5989 -- iter: 192/211
[A[ATraining Step: 56  | total loss: [1m[32m0.67467[0m[0m | time: 5.910s
[2K
| Adam | epoch: 008 | loss: 0.67467 - acc: 0.6109 | val_loss: 0.66048 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 57  | total loss: [1m[32m0.67207[0m[0m | time: 0.865s
[2K
| Adam | epoch: 009 | loss: 0.67207 - acc: 0.6211 -- iter: 032/211
[A[ATraining Step: 58  | total loss: [1m[32m0.67271[0m[0m | time: 1.706s
[2K
| Adam | epoch: 009 | loss: 0.67271 - acc: 0.6173 -- iter: 064/211
[A[ATraining Step: 59  | total loss: [1m[32m0.67331[0m[0m | time: 2.526s
[2K
| Adam | epoch: 009 | loss: 0.67331 - acc: 0.6142 -- iter: 096/211
[A[ATraining Step: 60  | total loss: [1m[32m0.67717[0m[0m | time: 3.383s
[2K
| Adam | epoch: 009 | loss: 0.67717 - acc: 0.5991 -- iter: 128/211
[A[ATraining Step: 61  | total loss: [1m[32m0.67824[0m[0m | time: 4.141s
[2K
| Adam | epoch: 009 | loss: 0.67824 - acc: 0.5943 -- iter: 160/211
[A[ATraining Step: 62  | total loss: [1m[32m0.67436[0m[0m | time: 4.939s
[2K
| Adam | epoch: 009 | loss: 0.67436 - acc: 0.6063 -- iter: 192/211
[A[ATraining Step: 63  | total loss: [1m[32m0.67816[0m[0m | time: 6.380s
[2K
| Adam | epoch: 009 | loss: 0.67816 - acc: 0.5928 | val_loss: 0.65537 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 64  | total loss: [1m[32m0.67653[0m[0m | time: 0.744s
[2K
| Adam | epoch: 010 | loss: 0.67653 - acc: 0.5977 -- iter: 032/211
[A[ATraining Step: 65  | total loss: [1m[32m0.67494[0m[0m | time: 1.790s
[2K
| Adam | epoch: 010 | loss: 0.67494 - acc: 0.6018 -- iter: 064/211
[A[ATraining Step: 66  | total loss: [1m[32m0.67502[0m[0m | time: 2.795s
[2K
| Adam | epoch: 010 | loss: 0.67502 - acc: 0.6009 -- iter: 096/211
[A[ATraining Step: 67  | total loss: [1m[32m0.67640[0m[0m | time: 3.713s
[2K
| Adam | epoch: 010 | loss: 0.67640 - acc: 0.5962 -- iter: 128/211
[A[ATraining Step: 68  | total loss: [1m[32m0.67649[0m[0m | time: 4.363s
[2K
| Adam | epoch: 010 | loss: 0.67649 - acc: 0.5960 -- iter: 160/211
[A[ATraining Step: 69  | total loss: [1m[32m0.67244[0m[0m | time: 5.025s
[2K
| Adam | epoch: 010 | loss: 0.67244 - acc: 0.6067 -- iter: 192/211
[A[ATraining Step: 70  | total loss: [1m[32m0.67451[0m[0m | time: 6.676s
[2K
| Adam | epoch: 010 | loss: 0.67451 - acc: 0.6016 | val_loss: 0.65063 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 71  | total loss: [1m[32m0.68020[0m[0m | time: 0.488s
[2K
| Adam | epoch: 011 | loss: 0.68020 - acc: 0.5864 -- iter: 032/211
[A[ATraining Step: 72  | total loss: [1m[32m0.68932[0m[0m | time: 0.958s
[2K
| Adam | epoch: 011 | loss: 0.68932 - acc: 0.5619 -- iter: 064/211
[A[ATraining Step: 73  | total loss: [1m[32m0.69661[0m[0m | time: 1.812s
[2K
| Adam | epoch: 011 | loss: 0.69661 - acc: 0.5404 -- iter: 096/211
[A[ATraining Step: 74  | total loss: [1m[32m0.69560[0m[0m | time: 2.636s
[2K
| Adam | epoch: 011 | loss: 0.69560 - acc: 0.5428 -- iter: 128/211
[A[ATraining Step: 75  | total loss: [1m[32m0.69647[0m[0m | time: 3.287s
[2K
| Adam | epoch: 011 | loss: 0.69647 - acc: 0.5382 -- iter: 160/211
[A[ATraining Step: 76  | total loss: [1m[32m0.69610[0m[0m | time: 4.067s
[2K
| Adam | epoch: 011 | loss: 0.69610 - acc: 0.5374 -- iter: 192/211
[A[ATraining Step: 77  | total loss: [1m[32m0.69235[0m[0m | time: 5.888s
[2K
| Adam | epoch: 011 | loss: 0.69235 - acc: 0.5500 | val_loss: 0.66376 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 78  | total loss: [1m[32m0.68707[0m[0m | time: 1.104s
[2K
| Adam | epoch: 012 | loss: 0.68707 - acc: 0.5710 -- iter: 032/211
[A[ATraining Step: 79  | total loss: [1m[32m0.68542[0m[0m | time: 1.807s
[2K
| Adam | epoch: 012 | loss: 0.68542 - acc: 0.5765 -- iter: 064/211
[A[ATraining Step: 80  | total loss: [1m[32m0.68623[0m[0m | time: 2.418s
[2K
| Adam | epoch: 012 | loss: 0.68623 - acc: 0.5714 -- iter: 096/211
[A[ATraining Step: 81  | total loss: [1m[32m0.68706[0m[0m | time: 3.317s
[2K
| Adam | epoch: 012 | loss: 0.68706 - acc: 0.5668 -- iter: 128/211
[A[ATraining Step: 82  | total loss: [1m[32m0.68749[0m[0m | time: 3.970s
[2K
| Adam | epoch: 012 | loss: 0.68749 - acc: 0.5633 -- iter: 160/211
[A[ATraining Step: 83  | total loss: [1m[32m0.68540[0m[0m | time: 4.622s
[2K
| Adam | epoch: 012 | loss: 0.68540 - acc: 0.5726 -- iter: 192/211
[A[ATraining Step: 84  | total loss: [1m[32m0.68275[0m[0m | time: 6.278s
[2K
| Adam | epoch: 012 | loss: 0.68275 - acc: 0.5841 | val_loss: 0.66528 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 85  | total loss: [1m[32m0.68503[0m[0m | time: 1.012s
[2K
| Adam | epoch: 013 | loss: 0.68503 - acc: 0.5725 -- iter: 032/211
[A[ATraining Step: 86  | total loss: [1m[32m0.68507[0m[0m | time: 1.829s
[2K
| Adam | epoch: 013 | loss: 0.68507 - acc: 0.5715 -- iter: 064/211
[A[ATraining Step: 87  | total loss: [1m[32m0.68377[0m[0m | time: 2.330s
[2K
| Adam | epoch: 013 | loss: 0.68377 - acc: 0.5769 -- iter: 096/211
[A[ATraining Step: 88  | total loss: [1m[32m0.68363[0m[0m | time: 2.822s
[2K
| Adam | epoch: 013 | loss: 0.68363 - acc: 0.5771 -- iter: 128/211
[A[ATraining Step: 89  | total loss: [1m[32m0.68338[0m[0m | time: 3.629s
[2K
| Adam | epoch: 013 | loss: 0.68338 - acc: 0.5773 -- iter: 160/211
[A[ATraining Step: 90  | total loss: [1m[32m0.68084[0m[0m | time: 4.454s
[2K
| Adam | epoch: 013 | loss: 0.68084 - acc: 0.5883 -- iter: 192/211
[A[ATraining Step: 91  | total loss: [1m[32m0.68337[0m[0m | time: 6.105s
[2K
| Adam | epoch: 013 | loss: 0.68337 - acc: 0.5763 | val_loss: 0.66373 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 92  | total loss: [1m[32m0.68215[0m[0m | time: 0.868s
[2K
| Adam | epoch: 014 | loss: 0.68215 - acc: 0.5812 -- iter: 032/211
[A[ATraining Step: 93  | total loss: [1m[32m0.68330[0m[0m | time: 1.746s
[2K
| Adam | epoch: 014 | loss: 0.68330 - acc: 0.5762 -- iter: 064/211
[A[ATraining Step: 94  | total loss: [1m[32m0.68566[0m[0m | time: 2.909s
[2K
| Adam | epoch: 014 | loss: 0.68566 - acc: 0.5655 -- iter: 096/211
[A[ATraining Step: 95  | total loss: [1m[32m0.68188[0m[0m | time: 3.576s
[2K
| Adam | epoch: 014 | loss: 0.68188 - acc: 0.5808 -- iter: 128/211
[A[ATraining Step: 96  | total loss: [1m[32m0.68554[0m[0m | time: 4.234s
[2K
| Adam | epoch: 014 | loss: 0.68554 - acc: 0.5648 -- iter: 160/211
[A[ATraining Step: 97  | total loss: [1m[32m0.68882[0m[0m | time: 5.178s
[2K
| Adam | epoch: 014 | loss: 0.68882 - acc: 0.5504 -- iter: 192/211
[A[ATraining Step: 98  | total loss: [1m[32m0.68630[0m[0m | time: 6.848s
[2K
| Adam | epoch: 014 | loss: 0.68630 - acc: 0.5610 | val_loss: 0.66310 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 99  | total loss: [1m[32m0.68536[0m[0m | time: 1.001s
[2K
| Adam | epoch: 015 | loss: 0.68536 - acc: 0.5643 -- iter: 032/211
[A[ATraining Step: 100  | total loss: [1m[32m0.68237[0m[0m | time: 1.895s
[2K
| Adam | epoch: 015 | loss: 0.68237 - acc: 0.5766 -- iter: 064/211
[A[ATraining Step: 101  | total loss: [1m[32m0.68413[0m[0m | time: 2.688s
[2K
| Adam | epoch: 015 | loss: 0.68413 - acc: 0.5690 -- iter: 096/211
[A[ATraining Step: 102  | total loss: [1m[32m0.68359[0m[0m | time: 3.527s
[2K
| Adam | epoch: 015 | loss: 0.68359 - acc: 0.5714 -- iter: 128/211
[A[ATraining Step: 103  | total loss: [1m[32m0.68379[0m[0m | time: 4.055s
[2K
| Adam | epoch: 015 | loss: 0.68379 - acc: 0.5705 -- iter: 160/211
[A[ATraining Step: 104  | total loss: [1m[32m0.68348[0m[0m | time: 4.541s
[2K
| Adam | epoch: 015 | loss: 0.68348 - acc: 0.5714 -- iter: 192/211
[A[ATraining Step: 105  | total loss: [1m[32m0.68335[0m[0m | time: 6.271s
[2K
| Adam | epoch: 015 | loss: 0.68335 - acc: 0.5721 | val_loss: 0.66127 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 106  | total loss: [1m[32m0.68195[0m[0m | time: 0.913s
[2K
| Adam | epoch: 016 | loss: 0.68195 - acc: 0.5774 -- iter: 032/211
[A[ATraining Step: 107  | total loss: [1m[32m0.67842[0m[0m | time: 1.714s
[2K
| Adam | epoch: 016 | loss: 0.67842 - acc: 0.5916 -- iter: 064/211
[A[ATraining Step: 108  | total loss: [1m[32m0.68065[0m[0m | time: 2.827s
[2K
| Adam | epoch: 016 | loss: 0.68065 - acc: 0.5824 -- iter: 096/211
[A[ATraining Step: 109  | total loss: [1m[32m0.68354[0m[0m | time: 3.951s
[2K
| Adam | epoch: 016 | loss: 0.68354 - acc: 0.5710 -- iter: 128/211
[A[ATraining Step: 110  | total loss: [1m[32m0.68453[0m[0m | time: 4.758s
[2K
| Adam | epoch: 016 | loss: 0.68453 - acc: 0.5671 -- iter: 160/211
[A[ATraining Step: 111  | total loss: [1m[32m0.68215[0m[0m | time: 5.162s
[2K
| Adam | epoch: 016 | loss: 0.68215 - acc: 0.5760 -- iter: 192/211
[A[ATraining Step: 112  | total loss: [1m[32m0.68061[0m[0m | time: 6.575s
[2K
| Adam | epoch: 016 | loss: 0.68061 - acc: 0.5815 | val_loss: 0.65858 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 113  | total loss: [1m[32m0.67911[0m[0m | time: 1.079s
[2K
| Adam | epoch: 017 | loss: 0.67911 - acc: 0.5865 -- iter: 032/211
[A[ATraining Step: 114  | total loss: [1m[32m0.68157[0m[0m | time: 1.897s
[2K
| Adam | epoch: 017 | loss: 0.68157 - acc: 0.5779 -- iter: 064/211
[A[ATraining Step: 115  | total loss: [1m[32m0.68081[0m[0m | time: 2.549s
[2K
| Adam | epoch: 017 | loss: 0.68081 - acc: 0.5795 -- iter: 096/211
[A[ATraining Step: 116  | total loss: [1m[32m0.68028[0m[0m | time: 3.195s
[2K
| Adam | epoch: 017 | loss: 0.68028 - acc: 0.5809 -- iter: 128/211
[A[ATraining Step: 117  | total loss: [1m[32m0.68176[0m[0m | time: 3.957s
[2K
| Adam | epoch: 017 | loss: 0.68176 - acc: 0.5759 -- iter: 160/211
[A[ATraining Step: 118  | total loss: [1m[32m0.68128[0m[0m | time: 4.769s
[2K
| Adam | epoch: 017 | loss: 0.68128 - acc: 0.5777 -- iter: 192/211
[A[ATraining Step: 119  | total loss: [1m[32m0.67886[0m[0m | time: 6.456s
[2K
| Adam | epoch: 017 | loss: 0.67886 - acc: 0.5856 | val_loss: 0.65593 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 120  | total loss: [1m[32m0.67732[0m[0m | time: 0.412s
[2K
| Adam | epoch: 018 | loss: 0.67732 - acc: 0.5902 -- iter: 032/211
[A[ATraining Step: 121  | total loss: [1m[32m0.67590[0m[0m | time: 1.222s
[2K
| Adam | epoch: 018 | loss: 0.67590 - acc: 0.5943 -- iter: 064/211
[A[ATraining Step: 122  | total loss: [1m[32m0.68072[0m[0m | time: 2.019s
[2K
| Adam | epoch: 018 | loss: 0.68072 - acc: 0.5786 -- iter: 096/211
[A[ATraining Step: 123  | total loss: [1m[32m0.67918[0m[0m | time: 2.982s
[2K
| Adam | epoch: 018 | loss: 0.67918 - acc: 0.5833 -- iter: 128/211
[A[ATraining Step: 124  | total loss: [1m[32m0.67765[0m[0m | time: 3.939s
[2K
| Adam | epoch: 018 | loss: 0.67765 - acc: 0.5874 -- iter: 160/211
[A[ATraining Step: 125  | total loss: [1m[32m0.67745[0m[0m | time: 4.774s
[2K
| Adam | epoch: 018 | loss: 0.67745 - acc: 0.5881 -- iter: 192/211
[A[ATraining Step: 126  | total loss: [1m[32m0.67830[0m[0m | time: 6.585s
[2K
| Adam | epoch: 018 | loss: 0.67830 - acc: 0.5855 | val_loss: 0.65287 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 127  | total loss: [1m[32m0.67694[0m[0m | time: 0.430s
[2K
| Adam | epoch: 019 | loss: 0.67694 - acc: 0.5895 -- iter: 032/211
[A[ATraining Step: 128  | total loss: [1m[32m0.67723[0m[0m | time: 0.830s
[2K
| Adam | epoch: 019 | loss: 0.67723 - acc: 0.5884 -- iter: 064/211
[A[ATraining Step: 129  | total loss: [1m[32m0.67758[0m[0m | time: 1.482s
[2K
| Adam | epoch: 019 | loss: 0.67758 - acc: 0.5875 -- iter: 096/211
[A[ATraining Step: 130  | total loss: [1m[32m0.67735[0m[0m | time: 2.464s
[2K
| Adam | epoch: 019 | loss: 0.67735 - acc: 0.5881 -- iter: 128/211
[A[ATraining Step: 131  | total loss: [1m[32m0.67927[0m[0m | time: 3.121s
[2K
| Adam | epoch: 019 | loss: 0.67927 - acc: 0.5824 -- iter: 160/211
[A[ATraining Step: 132  | total loss: [1m[32m0.67664[0m[0m | time: 3.756s
[2K
| Adam | epoch: 019 | loss: 0.67664 - acc: 0.5898 -- iter: 192/211
[A[ATraining Step: 133  | total loss: [1m[32m0.67873[0m[0m | time: 5.602s
[2K
| Adam | epoch: 019 | loss: 0.67873 - acc: 0.5839 | val_loss: 0.65143 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 134  | total loss: [1m[32m0.67947[0m[0m | time: 0.750s
[2K
| Adam | epoch: 020 | loss: 0.67947 - acc: 0.5818 -- iter: 032/211
[A[ATraining Step: 135  | total loss: [1m[32m0.67769[0m[0m | time: 1.232s
[2K
| Adam | epoch: 020 | loss: 0.67769 - acc: 0.5861 -- iter: 064/211
[A[ATraining Step: 136  | total loss: [1m[32m0.68574[0m[0m | time: 1.745s
[2K
| Adam | epoch: 020 | loss: 0.68574 - acc: 0.5643 -- iter: 096/211
[A[ATraining Step: 137  | total loss: [1m[32m0.69254[0m[0m | time: 2.545s
[2K
| Adam | epoch: 020 | loss: 0.69254 - acc: 0.5448 -- iter: 128/211
[A[ATraining Step: 138  | total loss: [1m[32m0.68855[0m[0m | time: 3.206s
[2K
| Adam | epoch: 020 | loss: 0.68855 - acc: 0.5559 -- iter: 160/211
[A[ATraining Step: 139  | total loss: [1m[32m0.68617[0m[0m | time: 3.838s
[2K
| Adam | epoch: 020 | loss: 0.68617 - acc: 0.5628 -- iter: 192/211
[A[ATraining Step: 140  | total loss: [1m[32m0.68587[0m[0m | time: 5.492s
[2K
| Adam | epoch: 020 | loss: 0.68587 - acc: 0.5628 | val_loss: 0.65648 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 141  | total loss: [1m[32m0.68286[0m[0m | time: 0.755s
[2K
| Adam | epoch: 021 | loss: 0.68286 - acc: 0.5721 -- iter: 032/211
[A[ATraining Step: 142  | total loss: [1m[32m0.68413[0m[0m | time: 1.412s
[2K
| Adam | epoch: 021 | loss: 0.68413 - acc: 0.5680 -- iter: 064/211
[A[ATraining Step: 143  | total loss: [1m[32m0.68320[0m[0m | time: 1.816s
[2K
| Adam | epoch: 021 | loss: 0.68320 - acc: 0.5706 -- iter: 096/211
[A[ATraining Step: 144  | total loss: [1m[32m0.68262[0m[0m | time: 2.229s
[2K
| Adam | epoch: 021 | loss: 0.68262 - acc: 0.5714 -- iter: 128/211
[A[ATraining Step: 145  | total loss: [1m[32m0.68235[0m[0m | time: 2.878s
[2K
| Adam | epoch: 021 | loss: 0.68235 - acc: 0.5722 -- iter: 160/211
[A[ATraining Step: 146  | total loss: [1m[32m0.68065[0m[0m | time: 3.770s
[2K
| Adam | epoch: 021 | loss: 0.68065 - acc: 0.5775 -- iter: 192/211
[A[ATraining Step: 147  | total loss: [1m[32m0.68217[0m[0m | time: 5.610s
[2K
| Adam | epoch: 021 | loss: 0.68217 - acc: 0.5729 | val_loss: 0.65733 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 148  | total loss: [1m[32m0.68329[0m[0m | time: 0.744s
[2K
| Adam | epoch: 022 | loss: 0.68329 - acc: 0.5687 -- iter: 032/211
[A[ATraining Step: 149  | total loss: [1m[32m0.68074[0m[0m | time: 1.509s
[2K
| Adam | epoch: 022 | loss: 0.68074 - acc: 0.5774 -- iter: 064/211
[A[ATraining Step: 150  | total loss: [1m[32m0.68301[0m[0m | time: 2.187s
[2K
| Adam | epoch: 022 | loss: 0.68301 - acc: 0.5697 -- iter: 096/211
[A[ATraining Step: 151  | total loss: [1m[32m0.68057[0m[0m | time: 2.591s
[2K
| Adam | epoch: 022 | loss: 0.68057 - acc: 0.5784 -- iter: 128/211
[A[ATraining Step: 152  | total loss: [1m[32m0.67594[0m[0m | time: 2.978s
[2K
| Adam | epoch: 022 | loss: 0.67594 - acc: 0.5942 -- iter: 160/211
[A[ATraining Step: 153  | total loss: [1m[32m0.67139[0m[0m | time: 3.624s
[2K
| Adam | epoch: 022 | loss: 0.67139 - acc: 0.6085 -- iter: 192/211
[A[ATraining Step: 154  | total loss: [1m[32m0.67256[0m[0m | time: 5.300s
[2K
| Adam | epoch: 022 | loss: 0.67256 - acc: 0.6039 | val_loss: 0.64970 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 155  | total loss: [1m[32m0.67815[0m[0m | time: 0.656s
[2K
| Adam | epoch: 023 | loss: 0.67815 - acc: 0.5872 -- iter: 032/211
[A[ATraining Step: 156  | total loss: [1m[32m0.68091[0m[0m | time: 1.280s
[2K
| Adam | epoch: 023 | loss: 0.68091 - acc: 0.5785 -- iter: 064/211
[A[ATraining Step: 157  | total loss: [1m[32m0.67795[0m[0m | time: 1.930s
[2K
| Adam | epoch: 023 | loss: 0.67795 - acc: 0.5863 -- iter: 096/211
[A[ATraining Step: 158  | total loss: [1m[32m0.67509[0m[0m | time: 2.582s
[2K
| Adam | epoch: 023 | loss: 0.67509 - acc: 0.5933 -- iter: 128/211
[A[ATraining Step: 159  | total loss: [1m[32m0.67477[0m[0m | time: 2.970s
[2K
| Adam | epoch: 023 | loss: 0.67477 - acc: 0.5933 -- iter: 160/211
[A[ATraining Step: 160  | total loss: [1m[32m0.67278[0m[0m | time: 3.386s
[2K
| Adam | epoch: 023 | loss: 0.67278 - acc: 0.5972 -- iter: 192/211
[A[ATraining Step: 161  | total loss: [1m[32m0.67055[0m[0m | time: 5.035s
[2K
| Adam | epoch: 023 | loss: 0.67055 - acc: 0.6006 | val_loss: 0.63559 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 162  | total loss: [1m[32m0.67136[0m[0m | time: 0.687s
[2K
| Adam | epoch: 024 | loss: 0.67136 - acc: 0.5968 -- iter: 032/211
[A[ATraining Step: 163  | total loss: [1m[32m0.67640[0m[0m | time: 1.358s
[2K
| Adam | epoch: 024 | loss: 0.67640 - acc: 0.5871 -- iter: 064/211
[A[ATraining Step: 164  | total loss: [1m[32m0.68080[0m[0m | time: 2.007s
[2K
| Adam | epoch: 024 | loss: 0.68080 - acc: 0.5784 -- iter: 096/211
[A[ATraining Step: 165  | total loss: [1m[32m0.67721[0m[0m | time: 2.659s
[2K
| Adam | epoch: 024 | loss: 0.67721 - acc: 0.5862 -- iter: 128/211
[A[ATraining Step: 166  | total loss: [1m[32m0.68173[0m[0m | time: 3.318s
[2K
| Adam | epoch: 024 | loss: 0.68173 - acc: 0.5713 -- iter: 160/211
[A[ATraining Step: 167  | total loss: [1m[32m0.67339[0m[0m | time: 3.748s
[2K
| Adam | epoch: 024 | loss: 0.67339 - acc: 0.5954 -- iter: 192/211
[A[ATraining Step: 168  | total loss: [1m[32m0.67662[0m[0m | time: 5.163s
[2K
| Adam | epoch: 024 | loss: 0.67662 - acc: 0.5833 | val_loss: 0.64284 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 169  | total loss: [1m[32m0.67958[0m[0m | time: 0.686s
[2K
| Adam | epoch: 025 | loss: 0.67958 - acc: 0.5723 -- iter: 032/211
[A[ATraining Step: 170  | total loss: [1m[32m0.67986[0m[0m | time: 1.341s
[2K
| Adam | epoch: 025 | loss: 0.67986 - acc: 0.5682 -- iter: 064/211
[A[ATraining Step: 171  | total loss: [1m[32m0.68028[0m[0m | time: 2.004s
[2K
| Adam | epoch: 025 | loss: 0.68028 - acc: 0.5645 -- iter: 096/211
[A[ATraining Step: 172  | total loss: [1m[32m0.67512[0m[0m | time: 2.669s
[2K
| Adam | epoch: 025 | loss: 0.67512 - acc: 0.5768 -- iter: 128/211
[A[ATraining Step: 173  | total loss: [1m[32m0.67277[0m[0m | time: 3.467s
[2K
| Adam | epoch: 025 | loss: 0.67277 - acc: 0.5785 -- iter: 160/211
[A[ATraining Step: 174  | total loss: [1m[32m0.67154[0m[0m | time: 4.300s
[2K
| Adam | epoch: 025 | loss: 0.67154 - acc: 0.5800 -- iter: 192/211
[A[ATraining Step: 175  | total loss: [1m[32m0.66872[0m[0m | time: 5.776s
[2K
| Adam | epoch: 025 | loss: 0.66872 - acc: 0.5845 | val_loss: 0.61645 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 176  | total loss: [1m[32m0.68132[0m[0m | time: 0.466s
[2K
| Adam | epoch: 026 | loss: 0.68132 - acc: 0.5629 -- iter: 032/211
[A[ATraining Step: 177  | total loss: [1m[32m0.68758[0m[0m | time: 1.132s
[2K
| Adam | epoch: 026 | loss: 0.68758 - acc: 0.5435 -- iter: 064/211
[A[ATraining Step: 178  | total loss: [1m[32m0.68638[0m[0m | time: 1.799s
[2K
| Adam | epoch: 026 | loss: 0.68638 - acc: 0.5454 -- iter: 096/211
[A[ATraining Step: 179  | total loss: [1m[32m0.68501[0m[0m | time: 2.559s
[2K
| Adam | epoch: 026 | loss: 0.68501 - acc: 0.5565 -- iter: 128/211
[A[ATraining Step: 180  | total loss: [1m[32m0.68474[0m[0m | time: 3.411s
[2K
| Adam | epoch: 026 | loss: 0.68474 - acc: 0.5633 -- iter: 160/211
[A[ATraining Step: 181  | total loss: [1m[32m0.68325[0m[0m | time: 4.246s
[2K
| Adam | epoch: 026 | loss: 0.68325 - acc: 0.5789 -- iter: 192/211
[A[ATraining Step: 182  | total loss: [1m[32m0.68358[0m[0m | time: 6.091s
[2K
| Adam | epoch: 026 | loss: 0.68358 - acc: 0.5772 | val_loss: 0.66713 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 183  | total loss: [1m[32m0.68461[0m[0m | time: 0.438s
[2K
| Adam | epoch: 027 | loss: 0.68461 - acc: 0.5695 -- iter: 032/211
[A[ATraining Step: 184  | total loss: [1m[32m0.68545[0m[0m | time: 0.908s
[2K
| Adam | epoch: 027 | loss: 0.68545 - acc: 0.5652 -- iter: 064/211
[A[ATraining Step: 185  | total loss: [1m[32m0.68619[0m[0m | time: 1.745s
[2K
| Adam | epoch: 027 | loss: 0.68619 - acc: 0.5613 -- iter: 096/211
[A[ATraining Step: 186  | total loss: [1m[32m0.68350[0m[0m | time: 2.597s
[2K
| Adam | epoch: 027 | loss: 0.68350 - acc: 0.5739 -- iter: 128/211
[A[ATraining Step: 187  | total loss: [1m[32m0.68255[0m[0m | time: 3.468s
[2K
| Adam | epoch: 027 | loss: 0.68255 - acc: 0.5759 -- iter: 160/211
[A[ATraining Step: 188  | total loss: [1m[32m0.67744[0m[0m | time: 4.296s
[2K
| Adam | epoch: 027 | loss: 0.67744 - acc: 0.5933 -- iter: 192/211
[A[ATraining Step: 189  | total loss: [1m[32m0.67798[0m[0m | time: 6.088s
[2K
| Adam | epoch: 027 | loss: 0.67798 - acc: 0.5871 | val_loss: 0.63358 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 190  | total loss: [1m[32m0.68257[0m[0m | time: 0.905s
[2K
| Adam | epoch: 028 | loss: 0.68257 - acc: 0.5690 -- iter: 032/211
[A[ATraining Step: 191  | total loss: [1m[32m0.68022[0m[0m | time: 1.446s
[2K
| Adam | epoch: 028 | loss: 0.68022 - acc: 0.5684 -- iter: 064/211
[A[ATraining Step: 192  | total loss: [1m[32m0.67256[0m[0m | time: 1.916s
[2K
| Adam | epoch: 028 | loss: 0.67256 - acc: 0.5852 -- iter: 096/211
[A[ATraining Step: 193  | total loss: [1m[32m0.66185[0m[0m | time: 2.799s
[2K
| Adam | epoch: 028 | loss: 0.66185 - acc: 0.6004 -- iter: 128/211
[A[ATraining Step: 194  | total loss: [1m[32m0.66612[0m[0m | time: 3.610s
[2K
| Adam | epoch: 028 | loss: 0.66612 - acc: 0.5935 -- iter: 160/211
[A[ATraining Step: 195  | total loss: [1m[32m0.66302[0m[0m | time: 4.274s
[2K
| Adam | epoch: 028 | loss: 0.66302 - acc: 0.5904 -- iter: 192/211
[A[ATraining Step: 196  | total loss: [1m[32m0.66869[0m[0m | time: 5.964s
[2K
| Adam | epoch: 028 | loss: 0.66869 - acc: 0.5720 | val_loss: 0.59696 - val_acc: 0.6567 -- iter: 211/211
--
Training Step: 197  | total loss: [1m[32m0.65875[0m[0m | time: 0.805s
[2K
| Adam | epoch: 029 | loss: 0.65875 - acc: 0.5866 -- iter: 032/211
[A[ATraining Step: 198  | total loss: [1m[32m0.66027[0m[0m | time: 1.620s
[2K
| Adam | epoch: 029 | loss: 0.66027 - acc: 0.5748 -- iter: 064/211
[A[ATraining Step: 199  | total loss: [1m[32m0.65592[0m[0m | time: 1.996s
[2K
| Adam | epoch: 029 | loss: 0.65592 - acc: 0.5892 -- iter: 096/211
[A[ATraining Step: 200  | total loss: [1m[32m0.65471[0m[0m | time: 3.419s
[2K
| Adam | epoch: 029 | loss: 0.65471 - acc: 0.5829 | val_loss: 0.52763 - val_acc: 0.6567 -- iter: 128/211
--
Training Step: 201  | total loss: [1m[32m0.65146[0m[0m | time: 4.286s
[2K
| Adam | epoch: 029 | loss: 0.65146 - acc: 0.5773 -- iter: 160/211
[A[ATraining Step: 202  | total loss: [1m[32m0.63844[0m[0m | time: 5.130s
[2K
| Adam | epoch: 029 | loss: 0.63844 - acc: 0.5914 -- iter: 192/211
[A[ATraining Step: 203  | total loss: [1m[32m0.64318[0m[0m | time: 6.907s
[2K
| Adam | epoch: 029 | loss: 0.64318 - acc: 0.5823 | val_loss: 0.50716 - val_acc: 0.6866 -- iter: 211/211
--
Training Step: 204  | total loss: [1m[32m0.61954[0m[0m | time: 0.881s
[2K
| Adam | epoch: 030 | loss: 0.61954 - acc: 0.6022 -- iter: 032/211
[A[ATraining Step: 205  | total loss: [1m[32m0.62469[0m[0m | time: 1.761s
[2K
| Adam | epoch: 030 | loss: 0.62469 - acc: 0.5920 -- iter: 064/211
[A[ATraining Step: 206  | total loss: [1m[32m0.61571[0m[0m | time: 2.559s
[2K
| Adam | epoch: 030 | loss: 0.61571 - acc: 0.6140 -- iter: 096/211
[A[ATraining Step: 207  | total loss: [1m[32m0.61328[0m[0m | time: 3.111s
[2K
| Adam | epoch: 030 | loss: 0.61328 - acc: 0.6214 -- iter: 128/211
[A[ATraining Step: 208  | total loss: [1m[32m0.60252[0m[0m | time: 3.508s
[2K
| Adam | epoch: 030 | loss: 0.60252 - acc: 0.6487 -- iter: 160/211
[A[ATraining Step: 209  | total loss: [1m[32m0.58442[0m[0m | time: 4.162s
[2K
| Adam | epoch: 030 | loss: 0.58442 - acc: 0.6786 -- iter: 192/211
[A[ATraining Step: 210  | total loss: [1m[32m0.58186[0m[0m | time: 5.812s
[2K
| Adam | epoch: 030 | loss: 0.58186 - acc: 0.6795 | val_loss: 0.53815 - val_acc: 0.6567 -- iter: 211/211
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.8063241106719368
Validation AUPRC:0.9144382826454699
Test AUC:0.8231481481481482
Test AUPRC:0.8864774326863709
BestTestF1Score	0.81	0.59	0.79	0.88	0.75	30	4	23	10	0.82
BestTestMCCScore	0.81	0.59	0.79	0.88	0.75	30	4	23	10	0.82
BestTestAccuracyScore	0.81	0.59	0.79	0.88	0.75	30	4	23	10	0.82
BestValidationF1Score	0.84	0.63	0.81	0.94	0.75	33	2	21	11	0.82
BestValidationMCC	0.84	0.63	0.81	0.94	0.75	33	2	21	11	0.82
BestValidationAccuracy	0.84	0.63	0.81	0.94	0.75	33	2	21	11	0.82
TestPredictions (Threshold:0.82)
CHEMBL3359195,TP,ACT,1.0	CHEMBL166992,FN,ACT,0.7699999809265137	CHEMBL195150,TN,INACT,0.3400000035762787	CHEMBL362074,FN,ACT,0.5899999737739563	CHEMBL1762353,TP,ACT,1.0	CHEMBL456593,TP,ACT,1.0	CHEMBL317246,TN,INACT,0.36000001430511475	CHEMBL3671678,TN,INACT,0.33000001311302185	CHEMBL248309,FN,ACT,0.3400000035762787	CHEMBL1762355,FN,ACT,0.6800000071525574	CHEMBL3360055,TP,ACT,0.8399999737739563	CHEMBL360903,TN,INACT,0.7400000095367432	CHEMBL182095,TP,ACT,0.9599999785423279	CHEMBL2041033,TN,INACT,0.49000000953674316	CHEMBL149307,FN,ACT,0.4000000059604645	CHEMBL2041041,TN,INACT,0.47999998927116394	CHEMBL2381343,TP,ACT,1.0	CHEMBL1242700,TN,INACT,0.75	CHEMBL511723,TP,ACT,1.0	CHEMBL365119,TN,INACT,0.550000011920929	CHEMBL281751,TN,INACT,0.6499999761581421	CHEMBL3806315,TN,INACT,0.6600000262260437	CHEMBL3233628,TP,ACT,0.8299999833106995	CHEMBL421,TN,INACT,0.4000000059604645	CHEMBL1835402,TN,INACT,0.44999998807907104	CHEMBL1762362,TP,ACT,0.9900000095367432	CHEMBL100927,TP,ACT,0.9300000071525574	CHEMBL317796,FN,ACT,0.5600000023841858	CHEMBL492060,TP,ACT,0.8799999952316284	CHEMBL167882,TP,ACT,0.9900000095367432	CHEMBL409053,TN,INACT,0.4000000059604645	CHEMBL2041042,TN,INACT,0.3499999940395355	CHEMBL196855,TP,ACT,0.9800000190734863	CHEMBL200886,TP,ACT,0.9900000095367432	CHEMBL297304,FP,INACT,0.9700000286102295	CHEMBL69426,TN,INACT,0.7599999904632568	CHEMBL1835315,TN,INACT,0.5099999904632568	CHEMBL352426,TP,ACT,0.9200000166893005	CHEMBL1762348,TP,ACT,0.9100000262260437	CHEMBL567341,TN,INACT,0.4099999964237213	CHEMBL328412,TP,ACT,1.0	CHEMBL382084,TP,ACT,0.9800000190734863	CHEMBL3359184,FN,ACT,0.550000011920929	CHEMBL101714,TP,ACT,0.9700000286102295	CHEMBL3133150,TP,ACT,0.9800000190734863	CHEMBL3805488,FP,INACT,0.9399999976158142	CHEMBL3759602,TN,INACT,0.5	CHEMBL1762350,TP,ACT,0.9800000190734863	CHEMBL100591,FP,INACT,0.9800000190734863	CHEMBL2391863,TN,INACT,0.4099999964237213	CHEMBL3359192,FN,ACT,0.5	CHEMBL178775,TP,ACT,1.0	CHEMBL248508,TP,ACT,1.0	CHEMBL32246,TN,INACT,0.3100000023841858	CHEMBL101545,TP,ACT,0.9200000166893005	CHEMBL3671626,TN,INACT,0.33000001311302185	CHEMBL354101,TN,INACT,0.7300000190734863	CHEMBL376112,TP,ACT,1.0	CHEMBL82932,TP,ACT,0.9900000095367432	CHEMBL521984,FN,ACT,0.36000001430511475	CHEMBL3671639,FP,INACT,0.9800000190734863	CHEMBL3360043,TP,ACT,0.9399999976158142	CHEMBL422379,TN,INACT,0.800000011920929	CHEMBL318791,FN,ACT,0.4699999988079071	CHEMBL217220,TP,ACT,0.9900000095367432	CHEMBL376760,TP,ACT,0.9700000286102295	CHEMBL200677,TP,ACT,1.0	

