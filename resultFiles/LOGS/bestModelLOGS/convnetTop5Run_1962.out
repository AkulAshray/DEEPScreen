ImageNetInceptionV2 CHEMBL1075051 adam 0.0005 15 0 0 0.8 False True
Number of active compounds :	129
Number of inactive compounds :	129
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL1075051_adam_0.0005_15_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL1075051_adam_0.0005_15_0.8/
---------------------------------
Training samples: 160
Validation samples: 51
--
Training Step: 1  | time: 47.956s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/160
[A[ATraining Step: 2  | total loss: [1m[32m0.68197[0m[0m | time: 56.885s
[2K
| Adam | epoch: 001 | loss: 0.68197 - acc: 0.4500 -- iter: 064/160
[A[ATraining Step: 3  | total loss: [1m[32m0.68165[0m[0m | time: 65.815s
[2K
| Adam | epoch: 001 | loss: 0.68165 - acc: 0.5932 -- iter: 096/160
[A[ATraining Step: 4  | total loss: [1m[32m0.54164[0m[0m | time: 74.850s
[2K
| Adam | epoch: 001 | loss: 0.54164 - acc: 0.7811 -- iter: 128/160
[A[ATraining Step: 5  | total loss: [1m[32m0.51925[0m[0m | time: 91.954s
[2K
| Adam | epoch: 001 | loss: 0.51925 - acc: 0.7812 | val_loss: 0.77296 - val_acc: 0.4314 -- iter: 160/160
--
Training Step: 6  | total loss: [1m[32m0.44915[0m[0m | time: 9.300s
[2K
| Adam | epoch: 002 | loss: 0.44915 - acc: 0.8214 -- iter: 032/160
[A[ATraining Step: 7  | total loss: [1m[32m0.23376[0m[0m | time: 18.260s
[2K
| Adam | epoch: 002 | loss: 0.23376 - acc: 0.9286 -- iter: 064/160
[A[ATraining Step: 8  | total loss: [1m[32m0.26676[0m[0m | time: 27.458s
[2K
| Adam | epoch: 002 | loss: 0.26676 - acc: 0.8984 -- iter: 096/160
[A[ATraining Step: 9  | total loss: [1m[32m0.55562[0m[0m | time: 36.566s
[2K
| Adam | epoch: 002 | loss: 0.55562 - acc: 0.8033 -- iter: 128/160
[A[ATraining Step: 10  | total loss: [1m[32m0.34616[0m[0m | time: 48.192s
[2K
| Adam | epoch: 002 | loss: 0.34616 - acc: 0.8860 | val_loss: 1.14534 - val_acc: 0.4314 -- iter: 160/160
--
Training Step: 11  | total loss: [1m[32m0.24922[0m[0m | time: 9.074s
[2K
| Adam | epoch: 003 | loss: 0.24922 - acc: 0.9252 -- iter: 032/160
[A[ATraining Step: 12  | total loss: [1m[32m0.25402[0m[0m | time: 18.044s
[2K
| Adam | epoch: 003 | loss: 0.25402 - acc: 0.9448 -- iter: 064/160
[A[ATraining Step: 13  | total loss: [1m[32m0.18809[0m[0m | time: 27.238s
[2K
| Adam | epoch: 003 | loss: 0.18809 - acc: 0.9551 -- iter: 096/160
[A[ATraining Step: 14  | total loss: [1m[32m0.26158[0m[0m | time: 36.313s
[2K
| Adam | epoch: 003 | loss: 0.26158 - acc: 0.9607 -- iter: 128/160
[A[ATraining Step: 15  | total loss: [1m[32m0.27672[0m[0m | time: 47.864s
[2K
| Adam | epoch: 003 | loss: 0.27672 - acc: 0.9271 | val_loss: 0.69328 - val_acc: 0.5686 -- iter: 160/160
--
Training Step: 16  | total loss: [1m[32m0.18917[0m[0m | time: 9.109s
[2K
| Adam | epoch: 004 | loss: 0.18917 - acc: 0.9545 -- iter: 032/160
[A[ATraining Step: 17  | total loss: [1m[32m0.13840[0m[0m | time: 18.188s
[2K
| Adam | epoch: 004 | loss: 0.13840 - acc: 0.9709 -- iter: 064/160
[A[ATraining Step: 18  | total loss: [1m[32m0.11312[0m[0m | time: 27.236s
[2K
| Adam | epoch: 004 | loss: 0.11312 - acc: 0.9701 -- iter: 096/160
[A[ATraining Step: 19  | total loss: [1m[32m0.07986[0m[0m | time: 36.424s
[2K
| Adam | epoch: 004 | loss: 0.07986 - acc: 0.9801 -- iter: 128/160
[A[ATraining Step: 20  | total loss: [1m[32m0.07801[0m[0m | time: 47.731s
[2K
| Adam | epoch: 004 | loss: 0.07801 - acc: 0.9764 | val_loss: 1.71859 - val_acc: 0.5686 -- iter: 160/160
--
Training Step: 21  | total loss: [1m[32m0.06315[0m[0m | time: 9.111s
[2K
| Adam | epoch: 005 | loss: 0.06315 - acc: 0.9838 -- iter: 032/160
[A[ATraining Step: 22  | total loss: [1m[32m0.04723[0m[0m | time: 18.195s
[2K
| Adam | epoch: 005 | loss: 0.04723 - acc: 0.9886 -- iter: 064/160
[A[ATraining Step: 23  | total loss: [1m[32m0.03911[0m[0m | time: 27.226s
[2K
| Adam | epoch: 005 | loss: 0.03911 - acc: 0.9919 -- iter: 096/160
[A[ATraining Step: 24  | total loss: [1m[32m0.11089[0m[0m | time: 36.463s
[2K
| Adam | epoch: 005 | loss: 0.11089 - acc: 0.9854 -- iter: 128/160
[A[ATraining Step: 25  | total loss: [1m[32m0.08537[0m[0m | time: 47.950s
[2K
| Adam | epoch: 005 | loss: 0.08537 - acc: 0.9894 | val_loss: 4.46852 - val_acc: 0.5686 -- iter: 160/160
--
Training Step: 26  | total loss: [1m[32m0.06520[0m[0m | time: 9.094s
[2K
| Adam | epoch: 006 | loss: 0.06520 - acc: 0.9922 -- iter: 032/160
[A[ATraining Step: 27  | total loss: [1m[32m0.05231[0m[0m | time: 18.306s
[2K
| Adam | epoch: 006 | loss: 0.05231 - acc: 0.9942 -- iter: 064/160
[A[ATraining Step: 28  | total loss: [1m[32m0.11778[0m[0m | time: 29.847s
[2K
| Adam | epoch: 006 | loss: 0.11778 - acc: 0.9878 -- iter: 096/160
[A[ATraining Step: 29  | total loss: [1m[32m0.22017[0m[0m | time: 41.340s
[2K
| Adam | epoch: 006 | loss: 0.22017 - acc: 0.9756 -- iter: 128/160
[A[ATraining Step: 30  | total loss: [1m[32m0.17455[0m[0m | time: 56.155s
[2K
| Adam | epoch: 006 | loss: 0.17455 - acc: 0.9814 | val_loss: 5.45061 - val_acc: 0.5686 -- iter: 160/160
--
Training Step: 31  | total loss: [1m[32m0.13844[0m[0m | time: 11.900s
[2K
| Adam | epoch: 007 | loss: 0.13844 - acc: 0.9857 -- iter: 032/160
[A[ATraining Step: 32  | total loss: [1m[32m0.12038[0m[0m | time: 24.323s
[2K
| Adam | epoch: 007 | loss: 0.12038 - acc: 0.9819 -- iter: 064/160
[A[ATraining Step: 33  | total loss: [1m[32m0.12762[0m[0m | time: 37.088s
[2K
| Adam | epoch: 007 | loss: 0.12762 - acc: 0.9790 -- iter: 096/160
[A[ATraining Step: 34  | total loss: [1m[32m0.10844[0m[0m | time: 49.415s
[2K
| Adam | epoch: 007 | loss: 0.10844 - acc: 0.9835 -- iter: 128/160
[A[ATraining Step: 35  | total loss: [1m[32m0.14864[0m[0m | time: 65.478s
[2K
| Adam | epoch: 007 | loss: 0.14864 - acc: 0.9739 | val_loss: 0.91669 - val_acc: 0.5686 -- iter: 160/160
--
Training Step: 36  | total loss: [1m[32m0.12072[0m[0m | time: 12.431s
[2K
| Adam | epoch: 008 | loss: 0.12072 - acc: 0.9792 -- iter: 032/160
[A[ATraining Step: 37  | total loss: [1m[32m0.10010[0m[0m | time: 25.391s
[2K
| Adam | epoch: 008 | loss: 0.10010 - acc: 0.9834 -- iter: 064/160
[A[ATraining Step: 38  | total loss: [1m[32m0.08758[0m[0m | time: 37.816s
[2K
| Adam | epoch: 008 | loss: 0.08758 - acc: 0.9805 -- iter: 096/160
[A[ATraining Step: 39  | total loss: [1m[32m0.07559[0m[0m | time: 50.424s
[2K
| Adam | epoch: 008 | loss: 0.07559 - acc: 0.9842 -- iter: 128/160
[A[ATraining Step: 40  | total loss: [1m[32m0.06966[0m[0m | time: 66.378s
[2K
| Adam | epoch: 008 | loss: 0.06966 - acc: 0.9813 | val_loss: 0.85123 - val_acc: 0.4706 -- iter: 160/160
--
Training Step: 41  | total loss: [1m[32m0.08691[0m[0m | time: 12.377s
[2K
| Adam | epoch: 009 | loss: 0.08691 - acc: 0.9733 -- iter: 032/160
[A[ATraining Step: 42  | total loss: [1m[32m0.07250[0m[0m | time: 25.218s
[2K
| Adam | epoch: 009 | loss: 0.07250 - acc: 0.9781 -- iter: 064/160
[A[ATraining Step: 43  | total loss: [1m[32m0.06070[0m[0m | time: 37.780s
[2K
| Adam | epoch: 009 | loss: 0.06070 - acc: 0.9820 -- iter: 096/160
[A[ATraining Step: 44  | total loss: [1m[32m0.06142[0m[0m | time: 50.127s
[2K
| Adam | epoch: 009 | loss: 0.06142 - acc: 0.9797 -- iter: 128/160
[A[ATraining Step: 45  | total loss: [1m[32m0.05336[0m[0m | time: 66.870s
[2K
| Adam | epoch: 009 | loss: 0.05336 - acc: 0.9831 | val_loss: 1.72216 - val_acc: 0.5686 -- iter: 160/160
--
Training Step: 46  | total loss: [1m[32m0.08660[0m[0m | time: 12.244s
[2K
| Adam | epoch: 010 | loss: 0.08660 - acc: 0.9807 -- iter: 032/160
[A[ATraining Step: 47  | total loss: [1m[32m0.07824[0m[0m | time: 24.908s
[2K
| Adam | epoch: 010 | loss: 0.07824 - acc: 0.9839 -- iter: 064/160
[A[ATraining Step: 48  | total loss: [1m[32m0.07766[0m[0m | time: 33.894s
[2K
| Adam | epoch: 010 | loss: 0.07766 - acc: 0.9815 -- iter: 096/160
[A[ATraining Step: 49  | total loss: [1m[32m0.07636[0m[0m | time: 43.073s
[2K
| Adam | epoch: 010 | loss: 0.07636 - acc: 0.9794 -- iter: 128/160
[A[ATraining Step: 50  | total loss: [1m[32m0.06960[0m[0m | time: 54.605s
[2K
| Adam | epoch: 010 | loss: 0.06960 - acc: 0.9826 | val_loss: 1.53068 - val_acc: 0.5882 -- iter: 160/160
--
Training Step: 51  | total loss: [1m[32m0.06092[0m[0m | time: 9.186s
[2K
| Adam | epoch: 011 | loss: 0.06092 - acc: 0.9853 -- iter: 032/160
[A[ATraining Step: 52  | total loss: [1m[32m0.09031[0m[0m | time: 18.168s
[2K
| Adam | epoch: 011 | loss: 0.09031 - acc: 0.9828 -- iter: 064/160
[A[ATraining Step: 53  | total loss: [1m[32m0.09574[0m[0m | time: 27.326s
[2K
| Adam | epoch: 011 | loss: 0.09574 - acc: 0.9807 -- iter: 096/160
[A[ATraining Step: 54  | total loss: [1m[32m0.11981[0m[0m | time: 36.179s
[2K
| Adam | epoch: 011 | loss: 0.11981 - acc: 0.9790 -- iter: 128/160
[A[ATraining Step: 55  | total loss: [1m[32m0.13212[0m[0m | time: 47.638s
[2K
| Adam | epoch: 011 | loss: 0.13212 - acc: 0.9775 | val_loss: 0.42030 - val_acc: 0.8431 -- iter: 160/160
--
Training Step: 56  | total loss: [1m[32m0.12539[0m[0m | time: 9.016s
[2K
| Adam | epoch: 012 | loss: 0.12539 - acc: 0.9763 -- iter: 032/160
[A[ATraining Step: 57  | total loss: [1m[32m0.11193[0m[0m | time: 17.991s
[2K
| Adam | epoch: 012 | loss: 0.11193 - acc: 0.9796 -- iter: 064/160
[A[ATraining Step: 58  | total loss: [1m[32m0.11857[0m[0m | time: 26.908s
[2K
| Adam | epoch: 012 | loss: 0.11857 - acc: 0.9781 -- iter: 096/160
[A[ATraining Step: 59  | total loss: [1m[32m0.12270[0m[0m | time: 35.937s
[2K
| Adam | epoch: 012 | loss: 0.12270 - acc: 0.9768 -- iter: 128/160
[A[ATraining Step: 60  | total loss: [1m[32m0.10734[0m[0m | time: 47.363s
[2K
| Adam | epoch: 012 | loss: 0.10734 - acc: 0.9799 | val_loss: 0.41316 - val_acc: 0.8824 -- iter: 160/160
--
Training Step: 61  | total loss: [1m[32m0.09448[0m[0m | time: 8.874s
[2K
| Adam | epoch: 013 | loss: 0.09448 - acc: 0.9825 -- iter: 032/160
[A[ATraining Step: 62  | total loss: [1m[32m0.08935[0m[0m | time: 17.931s
[2K
| Adam | epoch: 013 | loss: 0.08935 - acc: 0.9808 -- iter: 064/160
[A[ATraining Step: 63  | total loss: [1m[32m0.10455[0m[0m | time: 26.942s
[2K
| Adam | epoch: 013 | loss: 0.10455 - acc: 0.9792 -- iter: 096/160
[A[ATraining Step: 64  | total loss: [1m[32m0.12516[0m[0m | time: 35.925s
[2K
| Adam | epoch: 013 | loss: 0.12516 - acc: 0.9740 -- iter: 128/160
[A[ATraining Step: 65  | total loss: [1m[32m0.11596[0m[0m | time: 47.300s
[2K
| Adam | epoch: 013 | loss: 0.11596 - acc: 0.9772 | val_loss: 0.54634 - val_acc: 0.7647 -- iter: 160/160
--
Training Step: 66  | total loss: [1m[32m0.12811[0m[0m | time: 8.969s
[2K
| Adam | epoch: 014 | loss: 0.12811 - acc: 0.9724 -- iter: 032/160
[A[ATraining Step: 67  | total loss: [1m[32m0.12654[0m[0m | time: 17.978s
[2K
| Adam | epoch: 014 | loss: 0.12654 - acc: 0.9720 -- iter: 064/160
[A[ATraining Step: 68  | total loss: [1m[32m0.15400[0m[0m | time: 26.954s
[2K
| Adam | epoch: 014 | loss: 0.15400 - acc: 0.9605 -- iter: 096/160
[A[ATraining Step: 69  | total loss: [1m[32m0.14336[0m[0m | time: 35.966s
[2K
| Adam | epoch: 014 | loss: 0.14336 - acc: 0.9614 -- iter: 128/160
[A[ATraining Step: 70  | total loss: [1m[32m0.13783[0m[0m | time: 47.479s
[2K
| Adam | epoch: 014 | loss: 0.13783 - acc: 0.9623 | val_loss: 1.97746 - val_acc: 0.4314 -- iter: 160/160
--
Training Step: 71  | total loss: [1m[32m0.12608[0m[0m | time: 8.998s
[2K
| Adam | epoch: 015 | loss: 0.12608 - acc: 0.9666 -- iter: 032/160
[A[ATraining Step: 72  | total loss: [1m[32m0.11743[0m[0m | time: 17.822s
[2K
| Adam | epoch: 015 | loss: 0.11743 - acc: 0.9703 -- iter: 064/160
[A[ATraining Step: 73  | total loss: [1m[32m0.10992[0m[0m | time: 26.789s
[2K
| Adam | epoch: 015 | loss: 0.10992 - acc: 0.9736 -- iter: 096/160
[A[ATraining Step: 74  | total loss: [1m[32m0.09971[0m[0m | time: 35.863s
[2K
| Adam | epoch: 015 | loss: 0.09971 - acc: 0.9765 -- iter: 128/160
[A[ATraining Step: 75  | total loss: [1m[32m0.09904[0m[0m | time: 47.278s
[2K
| Adam | epoch: 015 | loss: 0.09904 - acc: 0.9757 | val_loss: 1.21883 - val_acc: 0.5490 -- iter: 160/160
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.
  'precision', 'predicted', average, warn_for)
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.9043887147335423
Validation AUPRC:0.8984002991451726
Test AUC:0.9380952380952381
Test AUPRC:0.9535153068584622
BestTestF1Score	0.9	0.76	0.88	0.9	0.9	27	3	18	3	0.02
BestTestMCCScore	0.9	0.76	0.88	0.9	0.9	27	3	18	3	0.02
BestTestAccuracyScore	0.9	0.76	0.88	0.9	0.9	27	3	18	3	0.02
BestValidationF1Score	0.93	0.84	0.92	0.93	0.93	27	2	20	2	0.02
BestValidationMCC	0.93	0.84	0.92	0.93	0.93	27	2	20	2	0.02
BestValidationAccuracy	0.93	0.84	0.92	0.93	0.93	27	2	20	2	0.02
TestPredictions (Threshold:0.02)
CHEMBL276954,TN,INACT,0.009999999776482582	CHEMBL3326840,FN,ACT,0.009999999776482582	CHEMBL1801201,TP,ACT,0.3799999952316284	CHEMBL1800939,TP,ACT,0.6299999952316284	CHEMBL157083,TP,ACT,0.20000000298023224	CHEMBL13673,TN,INACT,0.0	CHEMBL3326833,TP,ACT,0.05000000074505806	CHEMBL275893,TN,INACT,0.0	CHEMBL2376079,TP,ACT,0.5400000214576721	CHEMBL582969,TN,INACT,0.0	CHEMBL3326820,TP,ACT,0.7400000095367432	CHEMBL174679,TN,INACT,0.0	CHEMBL3326841,TP,ACT,0.49000000953674316	CHEMBL1092690,TP,ACT,0.10999999940395355	CHEMBL1093475,TP,ACT,0.07999999821186066	CHEMBL1800940,TP,ACT,0.800000011920929	CHEMBL3326845,TP,ACT,0.03999999910593033	CHEMBL596672,TN,INACT,0.019999999552965164	CHEMBL2376085,TP,ACT,0.75	CHEMBL104379,TN,INACT,0.0	CHEMBL122259,TN,INACT,0.0	CHEMBL3326818,FN,ACT,0.0	CHEMBL2414375,FP,INACT,0.03999999910593033	CHEMBL60636,TN,INACT,0.0	CHEMBL3326836,TP,ACT,0.38999998569488525	CHEMBL2414369,FP,INACT,0.30000001192092896	CHEMBL56719,TN,INACT,0.0	CHEMBL1801203,TP,ACT,0.07000000029802322	CHEMBL597885,TN,INACT,0.0	CHEMBL105323,TN,INACT,0.0	CHEMBL1801199,TP,ACT,0.11999999731779099	CHEMBL3115742,FN,ACT,0.0	CHEMBL1090603,TN,INACT,0.009999999776482582	CHEMBL3039597,FP,INACT,0.029999999329447746	CHEMBL594790,TN,INACT,0.0	CHEMBL604709,TN,INACT,0.0	CHEMBL1093244,TP,ACT,0.10000000149011612	CHEMBL1801198,TP,ACT,0.17000000178813934	CHEMBL57582,TN,INACT,0.0	CHEMBL57377,TN,INACT,0.0	CHEMBL2376071,TP,ACT,0.23999999463558197	CHEMBL2376070,TP,ACT,0.05000000074505806	CHEMBL2376080,TP,ACT,0.2199999988079071	CHEMBL3326825,TP,ACT,0.7599999904632568	CHEMBL1093476,TP,ACT,0.029999999329447746	CHEMBL3326837,TP,ACT,0.7699999809265137	CHEMBL1800947,TP,ACT,0.6600000262260437	CHEMBL565020,TN,INACT,0.0	CHEMBL1090896,TP,ACT,0.10000000149011612	CHEMBL1093491,TP,ACT,0.05999999865889549	CHEMBL3326816,TP,ACT,0.7099999785423279	

