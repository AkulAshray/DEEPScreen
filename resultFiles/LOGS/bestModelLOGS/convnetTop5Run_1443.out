CNNModel CHEMBL3314 adam 0.001 30 32 0 0.8 False True
Number of active compounds :	144
Number of inactive compounds :	144
---------------------------------
Run id: CNNModel_CHEMBL3314_adam_0.001_30_32_0_0.8_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL3314_adam_0.001_30_32_0.8_True/
---------------------------------
Training samples: 183
Validation samples: 58
--
Training Step: 1  | time: 0.801s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/183
[A[ATraining Step: 2  | total loss: [1m[32m0.62327[0m[0m | time: 1.412s
[2K
| Adam | epoch: 001 | loss: 0.62327 - acc: 0.5625 -- iter: 064/183
[A[ATraining Step: 3  | total loss: [1m[32m0.68583[0m[0m | time: 2.039s
[2K
| Adam | epoch: 001 | loss: 0.68583 - acc: 0.4858 -- iter: 096/183
[A[ATraining Step: 4  | total loss: [1m[32m0.69423[0m[0m | time: 2.831s
[2K
| Adam | epoch: 001 | loss: 0.69423 - acc: 0.4027 -- iter: 128/183
[A[ATraining Step: 5  | total loss: [1m[32m0.69377[0m[0m | time: 3.633s
[2K
| Adam | epoch: 001 | loss: 0.69377 - acc: 0.4052 -- iter: 160/183
[A[ATraining Step: 6  | total loss: [1m[32m0.69295[0m[0m | time: 5.204s
[2K
| Adam | epoch: 001 | loss: 0.69295 - acc: 0.5465 | val_loss: 0.69254 - val_acc: 0.5345 -- iter: 183/183
--
Training Step: 7  | total loss: [1m[32m0.69324[0m[0m | time: 0.759s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.5056 -- iter: 032/183
[A[ATraining Step: 8  | total loss: [1m[32m0.69334[0m[0m | time: 1.773s
[2K
| Adam | epoch: 002 | loss: 0.69334 - acc: 0.4902 -- iter: 064/183
[A[ATraining Step: 9  | total loss: [1m[32m0.69443[0m[0m | time: 2.949s
[2K
| Adam | epoch: 002 | loss: 0.69443 - acc: 0.4292 -- iter: 096/183
[A[ATraining Step: 10  | total loss: [1m[32m0.69379[0m[0m | time: 3.748s
[2K
| Adam | epoch: 002 | loss: 0.69379 - acc: 0.4490 -- iter: 128/183
[A[ATraining Step: 11  | total loss: [1m[32m0.69357[0m[0m | time: 4.615s
[2K
| Adam | epoch: 002 | loss: 0.69357 - acc: 0.4435 -- iter: 160/183
[A[ATraining Step: 12  | total loss: [1m[32m0.69275[0m[0m | time: 6.416s
[2K
| Adam | epoch: 002 | loss: 0.69275 - acc: 0.5393 | val_loss: 0.69428 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 13  | total loss: [1m[32m0.69361[0m[0m | time: 0.454s
[2K
| Adam | epoch: 003 | loss: 0.69361 - acc: 0.4956 -- iter: 032/183
[A[ATraining Step: 14  | total loss: [1m[32m0.69321[0m[0m | time: 0.911s
[2K
| Adam | epoch: 003 | loss: 0.69321 - acc: 0.5063 -- iter: 064/183
[A[ATraining Step: 15  | total loss: [1m[32m0.69299[0m[0m | time: 1.519s
[2K
| Adam | epoch: 003 | loss: 0.69299 - acc: 0.5124 -- iter: 096/183
[A[ATraining Step: 16  | total loss: [1m[32m0.69323[0m[0m | time: 2.307s
[2K
| Adam | epoch: 003 | loss: 0.69323 - acc: 0.5077 -- iter: 128/183
[A[ATraining Step: 17  | total loss: [1m[32m0.69483[0m[0m | time: 3.064s
[2K
| Adam | epoch: 003 | loss: 0.69483 - acc: 0.4712 -- iter: 160/183
[A[ATraining Step: 18  | total loss: [1m[32m0.69575[0m[0m | time: 4.931s
[2K
| Adam | epoch: 003 | loss: 0.69575 - acc: 0.4379 | val_loss: 0.69361 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 19  | total loss: [1m[32m0.69444[0m[0m | time: 0.673s
[2K
| Adam | epoch: 004 | loss: 0.69444 - acc: 0.4794 -- iter: 032/183
[A[ATraining Step: 20  | total loss: [1m[32m0.69336[0m[0m | time: 1.150s
[2K
| Adam | epoch: 004 | loss: 0.69336 - acc: 0.5363 -- iter: 064/183
[A[ATraining Step: 21  | total loss: [1m[32m0.69344[0m[0m | time: 1.760s
[2K
| Adam | epoch: 004 | loss: 0.69344 - acc: 0.5183 -- iter: 096/183
[A[ATraining Step: 22  | total loss: [1m[32m0.69332[0m[0m | time: 2.408s
[2K
| Adam | epoch: 004 | loss: 0.69332 - acc: 0.5063 -- iter: 128/183
[A[ATraining Step: 23  | total loss: [1m[32m0.69278[0m[0m | time: 3.037s
[2K
| Adam | epoch: 004 | loss: 0.69278 - acc: 0.5407 -- iter: 160/183
[A[ATraining Step: 24  | total loss: [1m[32m0.69327[0m[0m | time: 4.653s
[2K
| Adam | epoch: 004 | loss: 0.69327 - acc: 0.5029 | val_loss: 0.69359 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 25  | total loss: [1m[32m0.69375[0m[0m | time: 0.608s
[2K
| Adam | epoch: 005 | loss: 0.69375 - acc: 0.4680 -- iter: 032/183
[A[ATraining Step: 26  | total loss: [1m[32m0.69359[0m[0m | time: 1.241s
[2K
| Adam | epoch: 005 | loss: 0.69359 - acc: 0.4765 -- iter: 064/183
[A[ATraining Step: 27  | total loss: [1m[32m0.69332[0m[0m | time: 1.699s
[2K
| Adam | epoch: 005 | loss: 0.69332 - acc: 0.4986 -- iter: 096/183
[A[ATraining Step: 28  | total loss: [1m[32m0.69335[0m[0m | time: 2.155s
[2K
| Adam | epoch: 005 | loss: 0.69335 - acc: 0.4935 -- iter: 128/183
[A[ATraining Step: 29  | total loss: [1m[32m0.69327[0m[0m | time: 2.790s
[2K
| Adam | epoch: 005 | loss: 0.69327 - acc: 0.4898 -- iter: 160/183
[A[ATraining Step: 30  | total loss: [1m[32m0.69323[0m[0m | time: 4.418s
[2K
| Adam | epoch: 005 | loss: 0.69323 - acc: 0.4922 | val_loss: 0.69336 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 31  | total loss: [1m[32m0.69307[0m[0m | time: 0.651s
[2K
| Adam | epoch: 006 | loss: 0.69307 - acc: 0.5157 -- iter: 032/183
[A[ATraining Step: 32  | total loss: [1m[32m0.69287[0m[0m | time: 1.283s
[2K
| Adam | epoch: 006 | loss: 0.69287 - acc: 0.5403 -- iter: 064/183
[A[ATraining Step: 33  | total loss: [1m[32m0.69285[0m[0m | time: 1.894s
[2K
| Adam | epoch: 006 | loss: 0.69285 - acc: 0.5383 -- iter: 096/183
[A[ATraining Step: 34  | total loss: [1m[32m0.69286[0m[0m | time: 2.405s
[2K
| Adam | epoch: 006 | loss: 0.69286 - acc: 0.5368 -- iter: 128/183
[A[ATraining Step: 35  | total loss: [1m[32m0.69325[0m[0m | time: 2.873s
[2K
| Adam | epoch: 006 | loss: 0.69325 - acc: 0.5063 -- iter: 160/183
[A[ATraining Step: 36  | total loss: [1m[32m0.69359[0m[0m | time: 4.635s
[2K
| Adam | epoch: 006 | loss: 0.69359 - acc: 0.4828 | val_loss: 0.69351 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 37  | total loss: [1m[32m0.69374[0m[0m | time: 1.333s
[2K
| Adam | epoch: 007 | loss: 0.69374 - acc: 0.4675 -- iter: 032/183
[A[ATraining Step: 38  | total loss: [1m[32m0.69370[0m[0m | time: 2.626s
[2K
| Adam | epoch: 007 | loss: 0.69370 - acc: 0.4677 -- iter: 064/183
[A[ATraining Step: 39  | total loss: [1m[32m0.69347[0m[0m | time: 3.523s
[2K
| Adam | epoch: 007 | loss: 0.69347 - acc: 0.4859 -- iter: 096/183
[A[ATraining Step: 40  | total loss: [1m[32m0.69338[0m[0m | time: 4.543s
[2K
| Adam | epoch: 007 | loss: 0.69338 - acc: 0.4944 -- iter: 128/183
[A[ATraining Step: 41  | total loss: [1m[32m0.69322[0m[0m | time: 5.319s
[2K
| Adam | epoch: 007 | loss: 0.69322 - acc: 0.5184 -- iter: 160/183
[A[ATraining Step: 42  | total loss: [1m[32m0.69318[0m[0m | time: 7.095s
[2K
| Adam | epoch: 007 | loss: 0.69318 - acc: 0.5190 | val_loss: 0.69344 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 43  | total loss: [1m[32m0.69313[0m[0m | time: 1.026s
[2K
| Adam | epoch: 008 | loss: 0.69313 - acc: 0.5195 -- iter: 032/183
[A[ATraining Step: 44  | total loss: [1m[32m0.69327[0m[0m | time: 2.544s
[2K
| Adam | epoch: 008 | loss: 0.69327 - acc: 0.4999 -- iter: 064/183
[A[ATraining Step: 45  | total loss: [1m[32m0.69328[0m[0m | time: 3.943s
[2K
| Adam | epoch: 008 | loss: 0.69328 - acc: 0.4946 -- iter: 096/183
[A[ATraining Step: 46  | total loss: [1m[32m0.69315[0m[0m | time: 5.172s
[2K
| Adam | epoch: 008 | loss: 0.69315 - acc: 0.5059 -- iter: 128/183
[A[ATraining Step: 47  | total loss: [1m[32m0.69305[0m[0m | time: 6.022s
[2K
| Adam | epoch: 008 | loss: 0.69305 - acc: 0.5203 -- iter: 160/183
[A[ATraining Step: 48  | total loss: [1m[32m0.69304[0m[0m | time: 7.867s
[2K
| Adam | epoch: 008 | loss: 0.69304 - acc: 0.5220 | val_loss: 0.69351 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 49  | total loss: [1m[32m0.69342[0m[0m | time: 1.005s
[2K
| Adam | epoch: 009 | loss: 0.69342 - acc: 0.4877 -- iter: 032/183
[A[ATraining Step: 50  | total loss: [1m[32m0.69372[0m[0m | time: 2.017s
[2K
| Adam | epoch: 009 | loss: 0.69372 - acc: 0.4592 -- iter: 064/183
[A[ATraining Step: 51  | total loss: [1m[32m0.69354[0m[0m | time: 3.185s
[2K
| Adam | epoch: 009 | loss: 0.69354 - acc: 0.4797 -- iter: 096/183
[A[ATraining Step: 52  | total loss: [1m[32m0.69344[0m[0m | time: 4.598s
[2K
| Adam | epoch: 009 | loss: 0.69344 - acc: 0.4875 -- iter: 128/183
[A[ATraining Step: 53  | total loss: [1m[32m0.69340[0m[0m | time: 5.963s
[2K
| Adam | epoch: 009 | loss: 0.69340 - acc: 0.4893 -- iter: 160/183
[A[ATraining Step: 54  | total loss: [1m[32m0.69332[0m[0m | time: 8.213s
[2K
| Adam | epoch: 009 | loss: 0.69332 - acc: 0.4999 | val_loss: 0.69323 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 55  | total loss: [1m[32m0.69325[0m[0m | time: 0.859s
[2K
| Adam | epoch: 010 | loss: 0.69325 - acc: 0.5223 -- iter: 032/183
[A[ATraining Step: 56  | total loss: [1m[32m0.69323[0m[0m | time: 1.720s
[2K
| Adam | epoch: 010 | loss: 0.69323 - acc: 0.5283 -- iter: 064/183
[A[ATraining Step: 57  | total loss: [1m[32m0.69315[0m[0m | time: 3.151s
[2K
| Adam | epoch: 010 | loss: 0.69315 - acc: 0.5274 -- iter: 096/183
[A[ATraining Step: 58  | total loss: [1m[32m0.69320[0m[0m | time: 4.158s
[2K
| Adam | epoch: 010 | loss: 0.69320 - acc: 0.5151 -- iter: 128/183
[A[ATraining Step: 59  | total loss: [1m[32m0.69305[0m[0m | time: 5.302s
[2K
| Adam | epoch: 010 | loss: 0.69305 - acc: 0.5425 -- iter: 160/183
[A[ATraining Step: 60  | total loss: [1m[32m0.69309[0m[0m | time: 7.646s
[2K
| Adam | epoch: 010 | loss: 0.69309 - acc: 0.5286 | val_loss: 0.69354 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 61  | total loss: [1m[32m0.69310[0m[0m | time: 1.093s
[2K
| Adam | epoch: 011 | loss: 0.69310 - acc: 0.5208 -- iter: 032/183
[A[ATraining Step: 62  | total loss: [1m[32m0.69324[0m[0m | time: 1.910s
[2K
| Adam | epoch: 011 | loss: 0.69324 - acc: 0.5061 -- iter: 064/183
[A[ATraining Step: 63  | total loss: [1m[32m0.69309[0m[0m | time: 2.722s
[2K
| Adam | epoch: 011 | loss: 0.69309 - acc: 0.5136 -- iter: 096/183
[A[ATraining Step: 64  | total loss: [1m[32m0.69295[0m[0m | time: 3.969s
[2K
| Adam | epoch: 011 | loss: 0.69295 - acc: 0.5200 -- iter: 128/183
[A[ATraining Step: 65  | total loss: [1m[32m0.69283[0m[0m | time: 5.207s
[2K
| Adam | epoch: 011 | loss: 0.69283 - acc: 0.5214 -- iter: 160/183
[A[ATraining Step: 66  | total loss: [1m[32m0.69261[0m[0m | time: 7.197s
[2K
| Adam | epoch: 011 | loss: 0.69261 - acc: 0.5264 | val_loss: 0.69465 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 67  | total loss: [1m[32m0.69226[0m[0m | time: 1.445s
[2K
| Adam | epoch: 012 | loss: 0.69226 - acc: 0.5345 -- iter: 032/183
[A[ATraining Step: 68  | total loss: [1m[32m0.69271[0m[0m | time: 2.545s
[2K
| Adam | epoch: 012 | loss: 0.69271 - acc: 0.5193 -- iter: 064/183
[A[ATraining Step: 69  | total loss: [1m[32m0.69228[0m[0m | time: 3.476s
[2K
| Adam | epoch: 012 | loss: 0.69228 - acc: 0.5280 -- iter: 096/183
[A[ATraining Step: 70  | total loss: [1m[32m0.69233[0m[0m | time: 4.408s
[2K
| Adam | epoch: 012 | loss: 0.69233 - acc: 0.5223 -- iter: 128/183
[A[ATraining Step: 71  | total loss: [1m[32m0.69218[0m[0m | time: 5.687s
[2K
| Adam | epoch: 012 | loss: 0.69218 - acc: 0.5172 -- iter: 160/183
[A[ATraining Step: 72  | total loss: [1m[32m0.69239[0m[0m | time: 8.082s
[2K
| Adam | epoch: 012 | loss: 0.69239 - acc: 0.5118 | val_loss: 0.69446 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 73  | total loss: [1m[32m0.69261[0m[0m | time: 1.529s
[2K
| Adam | epoch: 013 | loss: 0.69261 - acc: 0.5035 -- iter: 032/183
[A[ATraining Step: 74  | total loss: [1m[32m0.69218[0m[0m | time: 2.649s
[2K
| Adam | epoch: 013 | loss: 0.69218 - acc: 0.5031 -- iter: 064/183
[A[ATraining Step: 75  | total loss: [1m[32m0.69190[0m[0m | time: 4.001s
[2K
| Adam | epoch: 013 | loss: 0.69190 - acc: 0.4926 -- iter: 096/183
[A[ATraining Step: 76  | total loss: [1m[32m0.69160[0m[0m | time: 4.951s
[2K
| Adam | epoch: 013 | loss: 0.69160 - acc: 0.4901 -- iter: 128/183
[A[ATraining Step: 77  | total loss: [1m[32m0.68969[0m[0m | time: 5.853s
[2K
| Adam | epoch: 013 | loss: 0.68969 - acc: 0.4980 -- iter: 160/183
[A[ATraining Step: 78  | total loss: [1m[32m0.68553[0m[0m | time: 7.984s
[2K
| Adam | epoch: 013 | loss: 0.68553 - acc: 0.5187 | val_loss: 0.83316 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 79  | total loss: [1m[32m0.68066[0m[0m | time: 0.881s
[2K
| Adam | epoch: 014 | loss: 0.68066 - acc: 0.5329 -- iter: 032/183
[A[ATraining Step: 80  | total loss: [1m[32m0.68370[0m[0m | time: 1.692s
[2K
| Adam | epoch: 014 | loss: 0.68370 - acc: 0.5360 -- iter: 064/183
[A[ATraining Step: 81  | total loss: [1m[32m0.67899[0m[0m | time: 2.532s
[2K
| Adam | epoch: 014 | loss: 0.67899 - acc: 0.5450 -- iter: 096/183
[A[ATraining Step: 82  | total loss: [1m[32m0.68392[0m[0m | time: 3.371s
[2K
| Adam | epoch: 014 | loss: 0.68392 - acc: 0.5373 -- iter: 128/183
[A[ATraining Step: 83  | total loss: [1m[32m0.68671[0m[0m | time: 4.002s
[2K
| Adam | epoch: 014 | loss: 0.68671 - acc: 0.5242 -- iter: 160/183
[A[ATraining Step: 84  | total loss: [1m[32m0.68559[0m[0m | time: 5.622s
[2K
| Adam | epoch: 014 | loss: 0.68559 - acc: 0.5370 | val_loss: 0.69491 - val_acc: 0.4655 -- iter: 183/183
--
Training Step: 85  | total loss: [1m[32m0.68531[0m[0m | time: 0.676s
[2K
| Adam | epoch: 015 | loss: 0.68531 - acc: 0.5485 -- iter: 032/183
[A[ATraining Step: 86  | total loss: [1m[32m0.68537[0m[0m | time: 1.524s
[2K
| Adam | epoch: 015 | loss: 0.68537 - acc: 0.5374 -- iter: 064/183
[A[ATraining Step: 87  | total loss: [1m[32m0.68566[0m[0m | time: 2.398s
[2K
| Adam | epoch: 015 | loss: 0.68566 - acc: 0.5181 -- iter: 096/183
[A[ATraining Step: 88  | total loss: [1m[32m0.68612[0m[0m | time: 3.330s
[2K
| Adam | epoch: 015 | loss: 0.68612 - acc: 0.5163 -- iter: 128/183
[A[ATraining Step: 89  | total loss: [1m[32m0.68645[0m[0m | time: 4.222s
[2K
| Adam | epoch: 015 | loss: 0.68645 - acc: 0.5271 -- iter: 160/183
[A[ATraining Step: 90  | total loss: [1m[32m0.68661[0m[0m | time: 5.800s
[2K
| Adam | epoch: 015 | loss: 0.68661 - acc: 0.5307 | val_loss: 0.69286 - val_acc: 0.5172 -- iter: 183/183
--
Training Step: 91  | total loss: [1m[32m0.68661[0m[0m | time: 0.665s
[2K
| Adam | epoch: 016 | loss: 0.68661 - acc: 0.5385 -- iter: 032/183
[A[ATraining Step: 92  | total loss: [1m[32m0.68649[0m[0m | time: 1.490s
[2K
| Adam | epoch: 016 | loss: 0.68649 - acc: 0.5455 -- iter: 064/183
[A[ATraining Step: 93  | total loss: [1m[32m0.68647[0m[0m | time: 2.365s
[2K
| Adam | epoch: 016 | loss: 0.68647 - acc: 0.5472 -- iter: 096/183
[A[ATraining Step: 94  | total loss: [1m[32m0.68638[0m[0m | time: 3.011s
[2K
| Adam | epoch: 016 | loss: 0.68638 - acc: 0.5519 -- iter: 128/183
[A[ATraining Step: 95  | total loss: [1m[32m0.68630[0m[0m | time: 3.857s
[2K
| Adam | epoch: 016 | loss: 0.68630 - acc: 0.5467 -- iter: 160/183
[A[ATraining Step: 96  | total loss: [1m[32m0.68556[0m[0m | time: 5.647s
[2K
| Adam | epoch: 016 | loss: 0.68556 - acc: 0.5608 | val_loss: 0.69412 - val_acc: 0.4828 -- iter: 183/183
--
Training Step: 97  | total loss: [1m[32m0.68498[0m[0m | time: 0.652s
[2K
| Adam | epoch: 017 | loss: 0.68498 - acc: 0.5516 -- iter: 032/183
[A[ATraining Step: 98  | total loss: [1m[32m0.68481[0m[0m | time: 1.304s
[2K
| Adam | epoch: 017 | loss: 0.68481 - acc: 0.5486 -- iter: 064/183
[A[ATraining Step: 99  | total loss: [1m[32m0.68445[0m[0m | time: 2.258s
[2K
| Adam | epoch: 017 | loss: 0.68445 - acc: 0.5502 -- iter: 096/183
[A[ATraining Step: 100  | total loss: [1m[32m0.68385[0m[0m | time: 3.194s
[2K
| Adam | epoch: 017 | loss: 0.68385 - acc: 0.5483 -- iter: 128/183
[A[ATraining Step: 101  | total loss: [1m[32m0.68177[0m[0m | time: 4.220s
[2K
| Adam | epoch: 017 | loss: 0.68177 - acc: 0.5591 -- iter: 160/183
[A[ATraining Step: 102  | total loss: [1m[32m0.67946[0m[0m | time: 6.316s
[2K
| Adam | epoch: 017 | loss: 0.67946 - acc: 0.5595 | val_loss: 0.69444 - val_acc: 0.5172 -- iter: 183/183
--
Training Step: 103  | total loss: [1m[32m0.67824[0m[0m | time: 1.627s
[2K
| Adam | epoch: 018 | loss: 0.67824 - acc: 0.5660 -- iter: 032/183
[A[ATraining Step: 104  | total loss: [1m[32m0.67693[0m[0m | time: 2.670s
[2K
| Adam | epoch: 018 | loss: 0.67693 - acc: 0.5782 -- iter: 064/183
[A[ATraining Step: 105  | total loss: [1m[32m0.67231[0m[0m | time: 3.904s
[2K
| Adam | epoch: 018 | loss: 0.67231 - acc: 0.5943 -- iter: 096/183
[A[ATraining Step: 106  | total loss: [1m[32m0.66443[0m[0m | time: 5.331s
[2K
| Adam | epoch: 018 | loss: 0.66443 - acc: 0.6131 -- iter: 128/183
[A[ATraining Step: 107  | total loss: [1m[32m0.66434[0m[0m | time: 8.157s
[2K
| Adam | epoch: 018 | loss: 0.66434 - acc: 0.6018 -- iter: 160/183
[A[ATraining Step: 108  | total loss: [1m[32m0.66359[0m[0m | time: 10.490s
[2K
| Adam | epoch: 018 | loss: 0.66359 - acc: 0.5885 | val_loss: 0.71347 - val_acc: 0.5000 -- iter: 183/183
--
Training Step: 109  | total loss: [1m[32m0.65805[0m[0m | time: 1.243s
[2K
| Adam | epoch: 019 | loss: 0.65805 - acc: 0.6015 -- iter: 032/183
[A[ATraining Step: 110  | total loss: [1m[32m0.65426[0m[0m | time: 2.674s
[2K
| Adam | epoch: 019 | loss: 0.65426 - acc: 0.6007 -- iter: 064/183
[A[ATraining Step: 111  | total loss: [1m[32m0.65081[0m[0m | time: 3.728s
[2K
| Adam | epoch: 019 | loss: 0.65081 - acc: 0.6063 -- iter: 096/183
[A[ATraining Step: 112  | total loss: [1m[32m0.64678[0m[0m | time: 4.860s
[2K
| Adam | epoch: 019 | loss: 0.64678 - acc: 0.6109 -- iter: 128/183
[A[ATraining Step: 113  | total loss: [1m[32m0.64211[0m[0m | time: 6.067s
[2K
| Adam | epoch: 019 | loss: 0.64211 - acc: 0.6150 -- iter: 160/183
[A[ATraining Step: 114  | total loss: [1m[32m0.62771[0m[0m | time: 8.623s
[2K
| Adam | epoch: 019 | loss: 0.62771 - acc: 0.6160 | val_loss: 0.76340 - val_acc: 0.5517 -- iter: 183/183
--
Training Step: 115  | total loss: [1m[32m0.61705[0m[0m | time: 1.522s
[2K
| Adam | epoch: 020 | loss: 0.61705 - acc: 0.6388 -- iter: 032/183
[A[ATraining Step: 116  | total loss: [1m[32m0.61530[0m[0m | time: 8.261s
[2K
| Adam | epoch: 020 | loss: 0.61530 - acc: 0.6405 -- iter: 064/183
[A[ATraining Step: 117  | total loss: [1m[32m0.60983[0m[0m | time: 9.473s
[2K
| Adam | epoch: 020 | loss: 0.60983 - acc: 0.6452 -- iter: 096/183
[A[ATraining Step: 118  | total loss: [1m[32m0.58764[0m[0m | time: 10.432s
[2K
| Adam | epoch: 020 | loss: 0.58764 - acc: 0.6588 -- iter: 128/183
[A[ATraining Step: 119  | total loss: [1m[32m0.57368[0m[0m | time: 11.326s
[2K
| Adam | epoch: 020 | loss: 0.57368 - acc: 0.6669 -- iter: 160/183
[A[ATraining Step: 120  | total loss: [1m[32m0.55289[0m[0m | time: 13.652s
[2K
| Adam | epoch: 020 | loss: 0.55289 - acc: 0.6871 | val_loss: 0.84533 - val_acc: 0.5000 -- iter: 183/183
--
Training Step: 121  | total loss: [1m[32m0.55075[0m[0m | time: 1.515s
[2K
| Adam | epoch: 021 | loss: 0.55075 - acc: 0.6997 -- iter: 032/183
[A[ATraining Step: 122  | total loss: [1m[32m0.57975[0m[0m | time: 2.786s
[2K
| Adam | epoch: 021 | loss: 0.57975 - acc: 0.6828 -- iter: 064/183
[A[ATraining Step: 123  | total loss: [1m[32m0.57049[0m[0m | time: 4.243s
[2K
| Adam | epoch: 021 | loss: 0.57049 - acc: 0.6927 -- iter: 096/183
[A[ATraining Step: 124  | total loss: [1m[32m0.55164[0m[0m | time: 5.930s
[2K
| Adam | epoch: 021 | loss: 0.55164 - acc: 0.7046 -- iter: 128/183
[A[ATraining Step: 125  | total loss: [1m[32m0.53043[0m[0m | time: 7.133s
[2K
| Adam | epoch: 021 | loss: 0.53043 - acc: 0.7186 -- iter: 160/183
[A[ATraining Step: 126  | total loss: [1m[32m0.53355[0m[0m | time: 11.836s
[2K
| Adam | epoch: 021 | loss: 0.53355 - acc: 0.7119 | val_loss: 0.79498 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 127  | total loss: [1m[32m0.53301[0m[0m | time: 1.086s
[2K
| Adam | epoch: 022 | loss: 0.53301 - acc: 0.7146 -- iter: 032/183
[A[ATraining Step: 128  | total loss: [1m[32m0.52022[0m[0m | time: 2.445s
[2K
| Adam | epoch: 022 | loss: 0.52022 - acc: 0.7244 -- iter: 064/183
[A[ATraining Step: 129  | total loss: [1m[32m0.52106[0m[0m | time: 3.725s
[2K
| Adam | epoch: 022 | loss: 0.52106 - acc: 0.7239 -- iter: 096/183
[A[ATraining Step: 130  | total loss: [1m[32m0.51667[0m[0m | time: 5.018s
[2K
| Adam | epoch: 022 | loss: 0.51667 - acc: 0.7233 -- iter: 128/183
[A[ATraining Step: 131  | total loss: [1m[32m0.49753[0m[0m | time: 6.527s
[2K
| Adam | epoch: 022 | loss: 0.49753 - acc: 0.7385 -- iter: 160/183
[A[ATraining Step: 132  | total loss: [1m[32m0.48541[0m[0m | time: 8.602s
[2K
| Adam | epoch: 022 | loss: 0.48541 - acc: 0.7459 | val_loss: 0.83909 - val_acc: 0.5517 -- iter: 183/183
--
Training Step: 133  | total loss: [1m[32m0.48237[0m[0m | time: 1.100s
[2K
| Adam | epoch: 023 | loss: 0.48237 - acc: 0.7583 -- iter: 032/183
[A[ATraining Step: 134  | total loss: [1m[32m0.47774[0m[0m | time: 2.661s
[2K
| Adam | epoch: 023 | loss: 0.47774 - acc: 0.7651 -- iter: 064/183
[A[ATraining Step: 135  | total loss: [1m[32m0.46617[0m[0m | time: 7.017s
[2K
| Adam | epoch: 023 | loss: 0.46617 - acc: 0.7729 -- iter: 096/183
[A[ATraining Step: 136  | total loss: [1m[32m0.44938[0m[0m | time: 16.204s
[2K
| Adam | epoch: 023 | loss: 0.44938 - acc: 0.7894 -- iter: 128/183
[A[ATraining Step: 137  | total loss: [1m[32m0.44452[0m[0m | time: 25.076s
[2K
| Adam | epoch: 023 | loss: 0.44452 - acc: 0.7854 -- iter: 160/183
[A[ATraining Step: 138  | total loss: [1m[32m0.41889[0m[0m | time: 27.266s
[2K
| Adam | epoch: 023 | loss: 0.41889 - acc: 0.8069 | val_loss: 1.10025 - val_acc: 0.6034 -- iter: 183/183
--
Training Step: 139  | total loss: [1m[32m0.43076[0m[0m | time: 1.088s
[2K
| Adam | epoch: 024 | loss: 0.43076 - acc: 0.8106 -- iter: 032/183
[A[ATraining Step: 140  | total loss: [1m[32m0.42244[0m[0m | time: 2.231s
[2K
| Adam | epoch: 024 | loss: 0.42244 - acc: 0.8165 -- iter: 064/183
[A[ATraining Step: 141  | total loss: [1m[32m0.40368[0m[0m | time: 3.581s
[2K
| Adam | epoch: 024 | loss: 0.40368 - acc: 0.8218 -- iter: 096/183
[A[ATraining Step: 142  | total loss: [1m[32m0.39919[0m[0m | time: 4.774s
[2K
| Adam | epoch: 024 | loss: 0.39919 - acc: 0.8240 -- iter: 128/183
[A[ATraining Step: 143  | total loss: [1m[32m0.38477[0m[0m | time: 6.077s
[2K
| Adam | epoch: 024 | loss: 0.38477 - acc: 0.8353 -- iter: 160/183
[A[ATraining Step: 144  | total loss: [1m[32m0.38615[0m[0m | time: 8.250s
[2K
| Adam | epoch: 024 | loss: 0.38615 - acc: 0.8362 | val_loss: 0.92350 - val_acc: 0.5000 -- iter: 183/183
--
Training Step: 145  | total loss: [1m[32m0.38760[0m[0m | time: 0.868s
[2K
| Adam | epoch: 025 | loss: 0.38760 - acc: 0.8369 -- iter: 032/183
[A[ATraining Step: 146  | total loss: [1m[32m0.37244[0m[0m | time: 1.561s
[2K
| Adam | epoch: 025 | loss: 0.37244 - acc: 0.8470 -- iter: 064/183
[A[ATraining Step: 147  | total loss: [1m[32m0.37146[0m[0m | time: 2.309s
[2K
| Adam | epoch: 025 | loss: 0.37146 - acc: 0.8362 -- iter: 096/183
[A[ATraining Step: 148  | total loss: [1m[32m0.35343[0m[0m | time: 3.164s
[2K
| Adam | epoch: 025 | loss: 0.35343 - acc: 0.8526 -- iter: 128/183
[A[ATraining Step: 149  | total loss: [1m[32m0.34830[0m[0m | time: 3.975s
[2K
| Adam | epoch: 025 | loss: 0.34830 - acc: 0.8486 -- iter: 160/183
[A[ATraining Step: 150  | total loss: [1m[32m0.34076[0m[0m | time: 5.756s
[2K
| Adam | epoch: 025 | loss: 0.34076 - acc: 0.8543 | val_loss: 0.81234 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 151  | total loss: [1m[32m0.32467[0m[0m | time: 0.685s
[2K
| Adam | epoch: 026 | loss: 0.32467 - acc: 0.8658 -- iter: 032/183
[A[ATraining Step: 152  | total loss: [1m[32m0.32427[0m[0m | time: 1.341s
[2K
| Adam | epoch: 026 | loss: 0.32427 - acc: 0.8636 -- iter: 064/183
[A[ATraining Step: 153  | total loss: [1m[32m0.32634[0m[0m | time: 1.826s
[2K
| Adam | epoch: 026 | loss: 0.32634 - acc: 0.8678 -- iter: 096/183
[A[ATraining Step: 154  | total loss: [1m[32m0.30892[0m[0m | time: 2.328s
[2K
| Adam | epoch: 026 | loss: 0.30892 - acc: 0.8767 -- iter: 128/183
[A[ATraining Step: 155  | total loss: [1m[32m0.28709[0m[0m | time: 3.216s
[2K
| Adam | epoch: 026 | loss: 0.28709 - acc: 0.8890 -- iter: 160/183
[A[ATraining Step: 156  | total loss: [1m[32m0.27514[0m[0m | time: 5.049s
[2K
| Adam | epoch: 026 | loss: 0.27514 - acc: 0.8939 | val_loss: 0.92180 - val_acc: 0.6034 -- iter: 183/183
--
Training Step: 157  | total loss: [1m[32m0.28450[0m[0m | time: 0.914s
[2K
| Adam | epoch: 027 | loss: 0.28450 - acc: 0.8951 -- iter: 032/183
[A[ATraining Step: 158  | total loss: [1m[32m0.26622[0m[0m | time: 1.849s
[2K
| Adam | epoch: 027 | loss: 0.26622 - acc: 0.9056 -- iter: 064/183
[A[ATraining Step: 159  | total loss: [1m[32m0.24702[0m[0m | time: 2.797s
[2K
| Adam | epoch: 027 | loss: 0.24702 - acc: 0.9151 -- iter: 096/183
[A[ATraining Step: 160  | total loss: [1m[32m0.25981[0m[0m | time: 3.286s
[2K
| Adam | epoch: 027 | loss: 0.25981 - acc: 0.9110 -- iter: 128/183
[A[ATraining Step: 161  | total loss: [1m[32m0.26128[0m[0m | time: 4.053s
[2K
| Adam | epoch: 027 | loss: 0.26128 - acc: 0.9112 -- iter: 160/183
[A[ATraining Step: 162  | total loss: [1m[32m0.25495[0m[0m | time: 6.677s
[2K
| Adam | epoch: 027 | loss: 0.25495 - acc: 0.9114 | val_loss: 0.99546 - val_acc: 0.5517 -- iter: 183/183
--
Training Step: 163  | total loss: [1m[32m0.24980[0m[0m | time: 16.039s
[2K
| Adam | epoch: 028 | loss: 0.24980 - acc: 0.9140 -- iter: 032/183
[A[ATraining Step: 164  | total loss: [1m[32m0.23701[0m[0m | time: 34.987s
[2K
| Adam | epoch: 028 | loss: 0.23701 - acc: 0.9195 -- iter: 064/183
[A[ATraining Step: 165  | total loss: [1m[32m0.22747[0m[0m | time: 36.287s
[2K
| Adam | epoch: 028 | loss: 0.22747 - acc: 0.9213 -- iter: 096/183
[A[ATraining Step: 166  | total loss: [1m[32m0.22554[0m[0m | time: 37.594s
[2K
| Adam | epoch: 028 | loss: 0.22554 - acc: 0.9167 -- iter: 128/183
[A[ATraining Step: 167  | total loss: [1m[32m0.22067[0m[0m | time: 38.662s
[2K
| Adam | epoch: 028 | loss: 0.22067 - acc: 0.9219 -- iter: 160/183
[A[ATraining Step: 168  | total loss: [1m[32m0.21553[0m[0m | time: 40.642s
[2K
| Adam | epoch: 028 | loss: 0.21553 - acc: 0.9253 | val_loss: 1.19393 - val_acc: 0.5345 -- iter: 183/183
--
Training Step: 169  | total loss: [1m[32m0.21039[0m[0m | time: 0.909s
[2K
| Adam | epoch: 029 | loss: 0.21039 - acc: 0.9285 -- iter: 032/183
[A[ATraining Step: 170  | total loss: [1m[32m0.21966[0m[0m | time: 1.657s
[2K
| Adam | epoch: 029 | loss: 0.21966 - acc: 0.9231 -- iter: 064/183
[A[ATraining Step: 171  | total loss: [1m[32m0.25824[0m[0m | time: 2.691s
[2K
| Adam | epoch: 029 | loss: 0.25824 - acc: 0.9183 -- iter: 096/183
[A[ATraining Step: 172  | total loss: [1m[32m0.24812[0m[0m | time: 3.620s
[2K
| Adam | epoch: 029 | loss: 0.24812 - acc: 0.9202 -- iter: 128/183
[A[ATraining Step: 173  | total loss: [1m[32m0.25543[0m[0m | time: 4.629s
[2K
| Adam | epoch: 029 | loss: 0.25543 - acc: 0.9157 -- iter: 160/183
[A[ATraining Step: 174  | total loss: [1m[32m0.24282[0m[0m | time: 6.846s
[2K
| Adam | epoch: 029 | loss: 0.24282 - acc: 0.9210 | val_loss: 0.98027 - val_acc: 0.6207 -- iter: 183/183
--
Training Step: 175  | total loss: [1m[32m0.23671[0m[0m | time: 15.401s
[2K
| Adam | epoch: 030 | loss: 0.23671 - acc: 0.9246 -- iter: 032/183
[A[ATraining Step: 176  | total loss: [1m[32m0.23374[0m[0m | time: 23.026s
[2K
| Adam | epoch: 030 | loss: 0.23374 - acc: 0.9278 -- iter: 064/183
[A[ATraining Step: 177  | total loss: [1m[32m0.22013[0m[0m | time: 24.369s
[2K
| Adam | epoch: 030 | loss: 0.22013 - acc: 0.9350 -- iter: 096/183
[A[ATraining Step: 178  | total loss: [1m[32m0.21152[0m[0m | time: 25.809s
[2K
| Adam | epoch: 030 | loss: 0.21152 - acc: 0.9384 -- iter: 128/183
[A[ATraining Step: 179  | total loss: [1m[32m0.19990[0m[0m | time: 26.888s
[2K
| Adam | epoch: 030 | loss: 0.19990 - acc: 0.9414 -- iter: 160/183
[A[ATraining Step: 180  | total loss: [1m[32m0.19702[0m[0m | time: 29.213s
[2K
| Adam | epoch: 030 | loss: 0.19702 - acc: 0.9410 | val_loss: 0.94729 - val_acc: 0.6034 -- iter: 183/183
--
/homes/tdogan/miniconda2/envs/my-rdkit-env/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars
  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)
Validation AUC:0.6463560334528076
Validation AUPRC:0.634898308429011
Test AUC:0.7357142857142858
Test AUPRC:0.695164356174245
BestTestF1Score	0.74	0.44	0.69	0.62	0.93	26	16	14	2	0.15
BestTestMCCScore	0.74	0.44	0.69	0.62	0.93	26	16	14	2	0.15
BestTestAccuracyScore	0.59	0.24	0.62	0.62	0.57	16	10	20	12	0.75
BestValidationF1Score	0.68	0.31	0.6	0.54	0.93	25	21	10	2	0.15
BestValidationMCC	0.68	0.31	0.6	0.54	0.93	25	21	10	2	0.15
BestValidationAccuracy	0.55	0.27	0.64	0.65	0.48	13	7	24	14	0.75
TestPredictions (Threshold:0.15)
CHEMBL25945,TP,ACT,0.75	CHEMBL304838,TP,ACT,0.9900000095367432	CHEMBL412582,TP,ACT,0.9599999785423279	CHEMBL108202,TN,INACT,0.14000000059604645	CHEMBL1563513,FP,INACT,0.8399999737739563	CHEMBL2087347,FP,INACT,0.2800000011920929	CHEMBL1313808,TN,INACT,0.14000000059604645	CHEMBL293590,FP,INACT,0.18000000715255737	CHEMBL3099871,TN,INACT,0.10000000149011612	CHEMBL1449269,TN,INACT,0.07999999821186066	CHEMBL87446,FP,INACT,0.800000011920929	CHEMBL171119,TP,ACT,0.8299999833106995	CHEMBL1464645,FP,INACT,0.8799999952316284	CHEMBL174276,TN,INACT,0.03999999910593033	CHEMBL1413681,FP,INACT,0.9800000190734863	CHEMBL1557929,TN,INACT,0.029999999329447746	CHEMBL3143647,TN,INACT,0.029999999329447746	CHEMBL69969,TP,ACT,0.949999988079071	CHEMBL125796,TP,ACT,0.6200000047683716	CHEMBL87407,TP,ACT,1.0	CHEMBL291261,TP,ACT,0.9800000190734863	CHEMBL313182,TP,ACT,0.9599999785423279	CHEMBL69090,FP,INACT,0.9599999785423279	CHEMBL308215,TP,ACT,0.9900000095367432	CHEMBL285285,TP,ACT,0.9700000286102295	CHEMBL1346897,FP,INACT,0.949999988079071	CHEMBL26297,TP,ACT,1.0	CHEMBL305066,TP,ACT,0.7699999809265137	CHEMBL171492,TP,ACT,0.6700000166893005	CHEMBL1339887,TN,INACT,0.10000000149011612	CHEMBL3143649,FP,INACT,0.1899999976158142	CHEMBL69991,TP,ACT,0.7699999809265137	CHEMBL60244,TN,INACT,0.05999999865889549	CHEMBL104,FP,INACT,0.9200000166893005	CHEMBL28420,FN,ACT,0.09000000357627869	CHEMBL69009,TP,ACT,0.38999998569488525	CHEMBL3408410,TN,INACT,0.029999999329447746	CHEMBL3408421,TN,INACT,0.03999999910593033	CHEMBL170200,TP,ACT,1.0	CHEMBL26285,TP,ACT,1.0	CHEMBL170402,TP,ACT,0.5899999737739563	CHEMBL69611,FP,INACT,0.8299999833106995	CHEMBL105171,FP,INACT,0.27000001072883606	CHEMBL310871,FN,ACT,0.05999999865889549	CHEMBL442366,FP,INACT,0.9100000262260437	CHEMBL170683,TP,ACT,0.7400000095367432	CHEMBL406121,FP,INACT,0.4399999976158142	CHEMBL22979,TP,ACT,0.23000000417232513	CHEMBL448737,TN,INACT,0.11999999731779099	CHEMBL367319,TP,ACT,0.2199999988079071	CHEMBL273334,TP,ACT,0.25	CHEMBL3325624,TN,INACT,0.05000000074505806	CHEMBL65936,TP,ACT,0.8500000238418579	CHEMBL294290,TP,ACT,0.15000000596046448	CHEMBL3085154,FP,INACT,1.0	CHEMBL1704776,FP,INACT,0.1599999964237213	CHEMBL421718,TP,ACT,0.6700000166893005	CHEMBL2441058,TN,INACT,0.05000000074505806	

