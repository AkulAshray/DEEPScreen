ImageNetInceptionV2 CHEMBL4631 adam 0.0005 30 0 0 0.8 False True
Number of active compounds :	192
Number of inactive compounds :	192
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL4631_adam_0.0005_30_0_0_0.8_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL4631_adam_0.0005_30_0.8/
---------------------------------
Training samples: 244
Validation samples: 77
--
Training Step: 1  | time: 37.873s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/244
[A[ATraining Step: 2  | total loss: [1m[32m0.61629[0m[0m | time: 46.428s
[2K
| Adam | epoch: 001 | loss: 0.61629 - acc: 0.4500 -- iter: 064/244
[A[ATraining Step: 3  | total loss: [1m[32m1.15816[0m[0m | time: 54.895s
[2K
| Adam | epoch: 001 | loss: 1.15816 - acc: 0.5676 -- iter: 096/244
[A[ATraining Step: 4  | total loss: [1m[32m0.55281[0m[0m | time: 63.470s
[2K
| Adam | epoch: 001 | loss: 0.55281 - acc: 0.7982 -- iter: 128/244
[A[ATraining Step: 5  | total loss: [1m[32m0.48862[0m[0m | time: 72.031s
[2K
| Adam | epoch: 001 | loss: 0.48862 - acc: 0.7865 -- iter: 160/244
[A[ATraining Step: 6  | total loss: [1m[32m0.41306[0m[0m | time: 80.516s
[2K
| Adam | epoch: 001 | loss: 0.41306 - acc: 0.7831 -- iter: 192/244
[A[ATraining Step: 7  | total loss: [1m[32m0.42820[0m[0m | time: 88.951s
[2K
| Adam | epoch: 001 | loss: 0.42820 - acc: 0.7632 -- iter: 224/244
[A[ATraining Step: 8  | total loss: [1m[32m0.42615[0m[0m | time: 104.047s
[2K
| Adam | epoch: 001 | loss: 0.42615 - acc: 0.8085 | val_loss: 2.01621 - val_acc: 0.4416 -- iter: 244/244
--
Training Step: 9  | total loss: [1m[32m0.40149[0m[0m | time: 6.096s
[2K
| Adam | epoch: 002 | loss: 0.40149 - acc: 0.8305 -- iter: 032/244
[A[ATraining Step: 10  | total loss: [1m[32m0.25457[0m[0m | time: 14.727s
[2K
| Adam | epoch: 002 | loss: 0.25457 - acc: 0.9152 -- iter: 064/244
[A[ATraining Step: 11  | total loss: [1m[32m0.26223[0m[0m | time: 23.259s
[2K
| Adam | epoch: 002 | loss: 0.26223 - acc: 0.9110 -- iter: 096/244
[A[ATraining Step: 12  | total loss: [1m[32m0.25427[0m[0m | time: 31.670s
[2K
| Adam | epoch: 002 | loss: 0.25427 - acc: 0.8948 -- iter: 128/244
[A[ATraining Step: 13  | total loss: [1m[32m0.29893[0m[0m | time: 40.491s
[2K
| Adam | epoch: 002 | loss: 0.29893 - acc: 0.8997 -- iter: 160/244
[A[ATraining Step: 14  | total loss: [1m[32m0.29152[0m[0m | time: 49.182s
[2K
| Adam | epoch: 002 | loss: 0.29152 - acc: 0.9024 -- iter: 192/244
[A[ATraining Step: 15  | total loss: [1m[32m0.28226[0m[0m | time: 57.940s
[2K
| Adam | epoch: 002 | loss: 0.28226 - acc: 0.8917 -- iter: 224/244
[A[ATraining Step: 16  | total loss: [1m[32m0.25172[0m[0m | time: 70.074s
[2K
| Adam | epoch: 002 | loss: 0.25172 - acc: 0.9089 | val_loss: 1.92734 - val_acc: 0.4416 -- iter: 244/244
--
Training Step: 17  | total loss: [1m[32m0.24996[0m[0m | time: 5.700s
[2K
| Adam | epoch: 003 | loss: 0.24996 - acc: 0.9079 -- iter: 032/244
[A[ATraining Step: 18  | total loss: [1m[32m0.25599[0m[0m | time: 11.375s
[2K
| Adam | epoch: 003 | loss: 0.25599 - acc: 0.9225 -- iter: 064/244
[A[ATraining Step: 19  | total loss: [1m[32m0.19516[0m[0m | time: 19.992s
[2K
| Adam | epoch: 003 | loss: 0.19516 - acc: 0.9483 -- iter: 096/244
[A[ATraining Step: 20  | total loss: [1m[32m0.16577[0m[0m | time: 28.641s
[2K
| Adam | epoch: 003 | loss: 0.16577 - acc: 0.9549 -- iter: 128/244
[A[ATraining Step: 21  | total loss: [1m[32m0.21466[0m[0m | time: 37.226s
[2K
| Adam | epoch: 003 | loss: 0.21466 - acc: 0.9010 -- iter: 160/244
[A[ATraining Step: 22  | total loss: [1m[32m0.17888[0m[0m | time: 46.295s
[2K
| Adam | epoch: 003 | loss: 0.17888 - acc: 0.9213 -- iter: 192/244
[A[ATraining Step: 23  | total loss: [1m[32m0.16028[0m[0m | time: 54.828s
[2K
| Adam | epoch: 003 | loss: 0.16028 - acc: 0.9351 -- iter: 224/244
[A[ATraining Step: 24  | total loss: [1m[32m0.12231[0m[0m | time: 66.945s
[2K
| Adam | epoch: 003 | loss: 0.12231 - acc: 0.9533 | val_loss: 4.94720 - val_acc: 0.4416 -- iter: 244/244
--
Training Step: 25  | total loss: [1m[32m0.11211[0m[0m | time: 8.732s
[2K
| Adam | epoch: 004 | loss: 0.11211 - acc: 0.9575 -- iter: 032/244
[A[ATraining Step: 26  | total loss: [1m[32m0.25102[0m[0m | time: 14.402s
[2K
| Adam | epoch: 004 | loss: 0.25102 - acc: 0.9109 -- iter: 064/244
[A[ATraining Step: 27  | total loss: [1m[32m0.20679[0m[0m | time: 20.226s
[2K
| Adam | epoch: 004 | loss: 0.20679 - acc: 0.9338 -- iter: 096/244
[A[ATraining Step: 28  | total loss: [1m[32m0.16311[0m[0m | time: 28.686s
[2K
| Adam | epoch: 004 | loss: 0.16311 - acc: 0.9503 -- iter: 128/244
[A[ATraining Step: 29  | total loss: [1m[32m0.16257[0m[0m | time: 37.309s
[2K
| Adam | epoch: 004 | loss: 0.16257 - acc: 0.9320 -- iter: 160/244
[A[ATraining Step: 30  | total loss: [1m[32m0.16803[0m[0m | time: 47.978s
[2K
| Adam | epoch: 004 | loss: 0.16803 - acc: 0.9259 -- iter: 192/244
[A[ATraining Step: 31  | total loss: [1m[32m0.16479[0m[0m | time: 58.550s
[2K
| Adam | epoch: 004 | loss: 0.16479 - acc: 0.9286 -- iter: 224/244
[A[ATraining Step: 32  | total loss: [1m[32m0.18891[0m[0m | time: 72.809s
[2K
| Adam | epoch: 004 | loss: 0.18891 - acc: 0.9306 | val_loss: 5.96892 - val_acc: 0.4416 -- iter: 244/244
--
Training Step: 33  | total loss: [1m[32m0.16299[0m[0m | time: 10.715s
[2K
| Adam | epoch: 005 | loss: 0.16299 - acc: 0.9390 -- iter: 032/244
[A[ATraining Step: 34  | total loss: [1m[32m0.16905[0m[0m | time: 21.586s
[2K
| Adam | epoch: 005 | loss: 0.16905 - acc: 0.9320 -- iter: 064/244
[A[ATraining Step: 35  | total loss: [1m[32m0.16336[0m[0m | time: 29.360s
[2K
| Adam | epoch: 005 | loss: 0.16336 - acc: 0.9397 -- iter: 096/244
[A[ATraining Step: 36  | total loss: [1m[32m0.17597[0m[0m | time: 36.092s
[2K
| Adam | epoch: 005 | loss: 0.17597 - acc: 0.9315 -- iter: 128/244
[A[ATraining Step: 37  | total loss: [1m[32m0.16235[0m[0m | time: 46.789s
[2K
| Adam | epoch: 005 | loss: 0.16235 - acc: 0.9352 -- iter: 160/244
[A[ATraining Step: 38  | total loss: [1m[32m0.13849[0m[0m | time: 57.571s
[2K
| Adam | epoch: 005 | loss: 0.13849 - acc: 0.9479 -- iter: 192/244
[A[ATraining Step: 39  | total loss: [1m[32m0.12000[0m[0m | time: 67.968s
[2K
| Adam | epoch: 005 | loss: 0.12000 - acc: 0.9579 -- iter: 224/244
[A[ATraining Step: 40  | total loss: [1m[32m0.10473[0m[0m | time: 83.206s
[2K
| Adam | epoch: 005 | loss: 0.10473 - acc: 0.9658 | val_loss: 7.70972 - val_acc: 0.4416 -- iter: 244/244
--
Training Step: 41  | total loss: [1m[32m0.10718[0m[0m | time: 10.884s
[2K
| Adam | epoch: 006 | loss: 0.10718 - acc: 0.9663 -- iter: 032/244
[A[ATraining Step: 42  | total loss: [1m[32m0.10008[0m[0m | time: 21.577s
[2K
| Adam | epoch: 006 | loss: 0.10008 - acc: 0.9668 -- iter: 064/244
[A[ATraining Step: 43  | total loss: [1m[32m0.10114[0m[0m | time: 32.194s
[2K
| Adam | epoch: 006 | loss: 0.10114 - acc: 0.9616 -- iter: 096/244
[A[ATraining Step: 44  | total loss: [1m[32m0.09185[0m[0m | time: 39.791s
[2K
| Adam | epoch: 006 | loss: 0.09185 - acc: 0.9682 -- iter: 128/244
[A[ATraining Step: 45  | total loss: [1m[32m0.07937[0m[0m | time: 47.144s
[2K
| Adam | epoch: 006 | loss: 0.07937 - acc: 0.9736 -- iter: 160/244
[A[ATraining Step: 46  | total loss: [1m[32m0.06839[0m[0m | time: 57.197s
[2K
| Adam | epoch: 006 | loss: 0.06839 - acc: 0.9780 -- iter: 192/244
[A[ATraining Step: 47  | total loss: [1m[32m0.09612[0m[0m | time: 68.090s
[2K
| Adam | epoch: 006 | loss: 0.09612 - acc: 0.9765 -- iter: 224/244
[A[ATraining Step: 48  | total loss: [1m[32m0.12837[0m[0m | time: 83.466s
[2K
| Adam | epoch: 006 | loss: 0.12837 - acc: 0.9753 | val_loss: 4.62798 - val_acc: 0.4416 -- iter: 244/244
--
Training Step: 49  | total loss: [1m[32m0.15810[0m[0m | time: 10.977s
[2K
| Adam | epoch: 007 | loss: 0.15810 - acc: 0.9693 -- iter: 032/244
[A[ATraining Step: 50  | total loss: [1m[32m0.13862[0m[0m | time: 21.659s
[2K
| Adam | epoch: 007 | loss: 0.13862 - acc: 0.9741 -- iter: 064/244
[A[ATraining Step: 51  | total loss: [1m[32m0.11984[0m[0m | time: 34.223s
[2K
| Adam | epoch: 007 | loss: 0.11984 - acc: 0.9780 -- iter: 096/244
[A[ATraining Step: 52  | total loss: [1m[32m0.12693[0m[0m | time: 46.859s
[2K
| Adam | epoch: 007 | loss: 0.12693 - acc: 0.9766 -- iter: 128/244
[A[ATraining Step: 53  | total loss: [1m[32m0.11299[0m[0m | time: 55.907s
[2K
| Adam | epoch: 007 | loss: 0.11299 - acc: 0.9801 -- iter: 160/244
[A[ATraining Step: 54  | total loss: [1m[32m0.12958[0m[0m | time: 64.800s
[2K
| Adam | epoch: 007 | loss: 0.12958 - acc: 0.9757 -- iter: 192/244
[A[ATraining Step: 55  | total loss: [1m[32m0.12274[0m[0m | time: 77.311s
[2K
| Adam | epoch: 007 | loss: 0.12274 - acc: 0.9720 -- iter: 224/244
[A[ATraining Step: 56  | total loss: [1m[32m0.11455[0m[0m | time: 96.122s
[2K
| Adam | epoch: 007 | loss: 0.11455 - acc: 0.9760 | val_loss: 0.59051 - val_acc: 0.8052 -- iter: 244/244
--
Training Step: 57  | total loss: [1m[32m0.12005[0m[0m | time: 13.328s
[2K
| Adam | epoch: 008 | loss: 0.12005 - acc: 0.9750 -- iter: 032/244
[A[ATraining Step: 58  | total loss: [1m[32m0.13276[0m[0m | time: 26.320s
[2K
| Adam | epoch: 008 | loss: 0.13276 - acc: 0.9741 -- iter: 064/244
[A[ATraining Step: 59  | total loss: [1m[32m0.12883[0m[0m | time: 39.797s
[2K
| Adam | epoch: 008 | loss: 0.12883 - acc: 0.9692 -- iter: 096/244
[A[ATraining Step: 60  | total loss: [1m[32m0.11922[0m[0m | time: 51.403s
[2K
| Adam | epoch: 008 | loss: 0.11922 - acc: 0.9691 -- iter: 128/244
[A[ATraining Step: 61  | total loss: [1m[32m0.13690[0m[0m | time: 64.832s
[2K
| Adam | epoch: 008 | loss: 0.13690 - acc: 0.9650 -- iter: 160/244
[A[ATraining Step: 62  | total loss: [1m[32m0.14523[0m[0m | time: 73.575s
[2K
| Adam | epoch: 008 | loss: 0.14523 - acc: 0.9534 -- iter: 192/244
[A[ATraining Step: 63  | total loss: [1m[32m0.12928[0m[0m | time: 82.427s
[2K
| Adam | epoch: 008 | loss: 0.12928 - acc: 0.9593 -- iter: 224/244
[A[ATraining Step: 64  | total loss: [1m[32m0.11731[0m[0m | time: 100.776s
[2K
| Adam | epoch: 008 | loss: 0.11731 - acc: 0.9644 | val_loss: 0.76354 - val_acc: 0.7013 -- iter: 244/244
--
Training Step: 65  | total loss: [1m[32m0.13171[0m[0m | time: 13.331s
[2K
| Adam | epoch: 009 | loss: 0.13171 - acc: 0.9495 -- iter: 032/244
[A[ATraining Step: 66  | total loss: [1m[32m0.12687[0m[0m | time: 25.786s
[2K
| Adam | epoch: 009 | loss: 0.12687 - acc: 0.9519 -- iter: 064/244
[A[ATraining Step: 67  | total loss: [1m[32m0.12459[0m[0m | time: 38.717s
[2K
| Adam | epoch: 009 | loss: 0.12459 - acc: 0.9539 -- iter: 096/244
[A[ATraining Step: 68  | total loss: [1m[32m0.11273[0m[0m | time: 51.808s
[2K
| Adam | epoch: 009 | loss: 0.11273 - acc: 0.9594 -- iter: 128/244
[A[ATraining Step: 69  | total loss: [1m[32m0.10153[0m[0m | time: 65.116s
[2K
| Adam | epoch: 009 | loss: 0.10153 - acc: 0.9641 -- iter: 160/244
[A[ATraining Step: 70  | total loss: [1m[32m0.09258[0m[0m | time: 78.557s
[2K
| Adam | epoch: 009 | loss: 0.09258 - acc: 0.9683 -- iter: 192/244
[A[ATraining Step: 71  | total loss: [1m[32m0.09069[0m[0m | time: 86.898s
[2K
| Adam | epoch: 009 | loss: 0.09069 - acc: 0.9683 -- iter: 224/244
[A[ATraining Step: 72  | total loss: [1m[32m0.08933[0m[0m | time: 98.740s
[2K
| Adam | epoch: 009 | loss: 0.08933 - acc: 0.9663 | val_loss: 0.23899 - val_acc: 0.9091 -- iter: 244/244
--
Training Step: 73  | total loss: [1m[32m0.08322[0m[0m | time: 11.195s
[2K
| Adam | epoch: 010 | loss: 0.08322 - acc: 0.9700 -- iter: 032/244
[A[ATraining Step: 74  | total loss: [1m[32m0.09477[0m[0m | time: 21.905s
[2K
| Adam | epoch: 010 | loss: 0.09477 - acc: 0.9664 -- iter: 064/244
[A[ATraining Step: 75  | total loss: [1m[32m0.08820[0m[0m | time: 32.679s
[2K
| Adam | epoch: 010 | loss: 0.08820 - acc: 0.9667 -- iter: 096/244
[A[ATraining Step: 76  | total loss: [1m[32m0.10951[0m[0m | time: 43.478s
[2K
| Adam | epoch: 010 | loss: 0.10951 - acc: 0.9636 -- iter: 128/244
[A[ATraining Step: 77  | total loss: [1m[32m0.11224[0m[0m | time: 54.199s
[2K
| Adam | epoch: 010 | loss: 0.11224 - acc: 0.9608 -- iter: 160/244
[A[ATraining Step: 78  | total loss: [1m[32m0.10195[0m[0m | time: 64.638s
[2K
| Adam | epoch: 010 | loss: 0.10195 - acc: 0.9649 -- iter: 192/244
[A[ATraining Step: 79  | total loss: [1m[32m0.09407[0m[0m | time: 75.410s
[2K
| Adam | epoch: 010 | loss: 0.09407 - acc: 0.9685 -- iter: 224/244
[A[ATraining Step: 80  | total loss: [1m[32m0.09730[0m[0m | time: 87.432s
[2K
| Adam | epoch: 010 | loss: 0.09730 - acc: 0.9686 | val_loss: 0.68153 - val_acc: 0.8442 -- iter: 244/244
--
Training Step: 81  | total loss: [1m[32m0.10957[0m[0m | time: 7.992s
[2K
| Adam | epoch: 011 | loss: 0.10957 - acc: 0.9667 -- iter: 032/244
[A[ATraining Step: 82  | total loss: [1m[32m0.10845[0m[0m | time: 19.236s
[2K
| Adam | epoch: 011 | loss: 0.10845 - acc: 0.9650 -- iter: 064/244
[A[ATraining Step: 83  | total loss: [1m[32m0.14160[0m[0m | time: 31.060s
[2K
| Adam | epoch: 011 | loss: 0.14160 - acc: 0.9623 -- iter: 096/244
[A[ATraining Step: 84  | total loss: [1m[32m0.13091[0m[0m | time: 41.884s
[2K
| Adam | epoch: 011 | loss: 0.13091 - acc: 0.9660 -- iter: 128/244
[A[ATraining Step: 85  | total loss: [1m[32m0.12643[0m[0m | time: 53.746s
[2K
| Adam | epoch: 011 | loss: 0.12643 - acc: 0.9632 -- iter: 160/244
[A[ATraining Step: 86  | total loss: [1m[32m0.12113[0m[0m | time: 65.439s
[2K
| Adam | epoch: 011 | loss: 0.12113 - acc: 0.9637 -- iter: 192/244
[A[ATraining Step: 87  | total loss: [1m[32m0.12241[0m[0m | time: 76.264s
[2K
| Adam | epoch: 011 | loss: 0.12241 - acc: 0.9611 -- iter: 224/244
[A[ATraining Step: 88  | total loss: [1m[32m0.12824[0m[0m | time: 92.274s
[2K
| Adam | epoch: 011 | loss: 0.12824 - acc: 0.9588 | val_loss: 0.34468 - val_acc: 0.8571 -- iter: 244/244
--
Training Step: 89  | total loss: [1m[32m0.11777[0m[0m | time: 8.086s
[2K
| Adam | epoch: 012 | loss: 0.11777 - acc: 0.9629 -- iter: 032/244
[A[ATraining Step: 90  | total loss: [1m[32m0.14852[0m[0m | time: 14.948s
[2K
| Adam | epoch: 012 | loss: 0.14852 - acc: 0.9616 -- iter: 064/244
[A[ATraining Step: 91  | total loss: [1m[32m0.16136[0m[0m | time: 26.147s
[2K
| Adam | epoch: 012 | loss: 0.16136 - acc: 0.9604 -- iter: 096/244
[A[ATraining Step: 92  | total loss: [1m[32m0.15403[0m[0m | time: 37.389s
[2K
| Adam | epoch: 012 | loss: 0.15403 - acc: 0.9613 -- iter: 128/244
[A[ATraining Step: 93  | total loss: [1m[32m0.15209[0m[0m | time: 47.838s
[2K
| Adam | epoch: 012 | loss: 0.15209 - acc: 0.9589 -- iter: 160/244
[A[ATraining Step: 94  | total loss: [1m[32m0.14040[0m[0m | time: 58.679s
[2K
| Adam | epoch: 012 | loss: 0.14040 - acc: 0.9630 -- iter: 192/244
[A[ATraining Step: 95  | total loss: [1m[32m0.13181[0m[0m | time: 69.901s
[2K
| Adam | epoch: 012 | loss: 0.13181 - acc: 0.9667 -- iter: 224/244
[A[ATraining Step: 96  | total loss: [1m[32m0.12703[0m[0m | time: 85.371s
[2K
| Adam | epoch: 012 | loss: 0.12703 - acc: 0.9669 | val_loss: 2.37405 - val_acc: 0.6753 -- iter: 244/244
--
Training Step: 97  | total loss: [1m[32m0.12998[0m[0m | time: 8.767s
[2K
| Adam | epoch: 013 | loss: 0.12998 - acc: 0.9577 -- iter: 032/244
[A[ATraining Step: 98  | total loss: [1m[32m0.13382[0m[0m | time: 14.547s
[2K
| Adam | epoch: 013 | loss: 0.13382 - acc: 0.9557 -- iter: 064/244
[A[ATraining Step: 99  | total loss: [1m[32m0.12909[0m[0m | time: 20.282s
[2K
| Adam | epoch: 013 | loss: 0.12909 - acc: 0.9551 -- iter: 096/244
[A[ATraining Step: 100  | total loss: [1m[32m0.12013[0m[0m | time: 28.936s
[2K
| Adam | epoch: 013 | loss: 0.12013 - acc: 0.9596 -- iter: 128/244
[A[ATraining Step: 101  | total loss: [1m[32m0.12203[0m[0m | time: 37.812s
[2K
| Adam | epoch: 013 | loss: 0.12203 - acc: 0.9605 -- iter: 160/244
[A[ATraining Step: 102  | total loss: [1m[32m0.11359[0m[0m | time: 46.427s
[2K
| Adam | epoch: 013 | loss: 0.11359 - acc: 0.9645 -- iter: 192/244
[A[ATraining Step: 103  | total loss: [1m[32m0.12231[0m[0m | time: 55.121s
[2K
| Adam | epoch: 013 | loss: 0.12231 - acc: 0.9618 -- iter: 224/244
[A[ATraining Step: 104  | total loss: [1m[32m0.11580[0m[0m | time: 67.333s
[2K
| Adam | epoch: 013 | loss: 0.11580 - acc: 0.9656 | val_loss: 0.81766 - val_acc: 0.7143 -- iter: 244/244
--
Training Step: 105  | total loss: [1m[32m0.10800[0m[0m | time: 8.692s
[2K
| Adam | epoch: 014 | loss: 0.10800 - acc: 0.9690 -- iter: 032/244
[A[ATraining Step: 106  | total loss: [1m[32m0.10080[0m[0m | time: 17.320s
[2K
| Adam | epoch: 014 | loss: 0.10080 - acc: 0.9690 -- iter: 064/244
[A[ATraining Step: 107  | total loss: [1m[32m0.09680[0m[0m | time: 23.046s
[2K
| Adam | epoch: 014 | loss: 0.09680 - acc: 0.9690 -- iter: 096/244
[A[ATraining Step: 108  | total loss: [1m[32m0.08891[0m[0m | time: 28.817s
[2K
| Adam | epoch: 014 | loss: 0.08891 - acc: 0.9721 -- iter: 128/244
[A[ATraining Step: 109  | total loss: [1m[32m0.08179[0m[0m | time: 37.429s
[2K
| Adam | epoch: 014 | loss: 0.08179 - acc: 0.9749 -- iter: 160/244
[A[ATraining Step: 110  | total loss: [1m[32m0.07470[0m[0m | time: 46.147s
[2K
| Adam | epoch: 014 | loss: 0.07470 - acc: 0.9774 -- iter: 192/244
[A[ATraining Step: 111  | total loss: [1m[32m0.06932[0m[0m | time: 54.674s
[2K
| Adam | epoch: 014 | loss: 0.06932 - acc: 0.9796 -- iter: 224/244
[A[ATraining Step: 112  | total loss: [1m[32m0.08187[0m[0m | time: 66.962s
[2K
| Adam | epoch: 014 | loss: 0.08187 - acc: 0.9754 | val_loss: 1.22453 - val_acc: 0.6104 -- iter: 244/244
--
Training Step: 113  | total loss: [1m[32m0.07817[0m[0m | time: 8.686s
[2K
| Adam | epoch: 015 | loss: 0.07817 - acc: 0.9779 -- iter: 032/244
[A[ATraining Step: 114  | total loss: [1m[32m0.07993[0m[0m | time: 17.228s
[2K
| Adam | epoch: 015 | loss: 0.07993 - acc: 0.9770 -- iter: 064/244
[A[ATraining Step: 115  | total loss: [1m[32m0.07559[0m[0m | time: 25.704s
[2K
| Adam | epoch: 015 | loss: 0.07559 - acc: 0.9793 -- iter: 096/244
[A[ATraining Step: 116  | total loss: [1m[32m0.06900[0m[0m | time: 31.411s
[2K
| Adam | epoch: 015 | loss: 0.06900 - acc: 0.9814 -- iter: 128/244
[A[ATraining Step: 117  | total loss: [1m[32m0.06333[0m[0m | time: 37.308s
[2K
| Adam | epoch: 015 | loss: 0.06333 - acc: 0.9832 -- iter: 160/244
[A[ATraining Step: 118  | total loss: [1m[32m0.05826[0m[0m | time: 45.913s
[2K
| Adam | epoch: 015 | loss: 0.05826 - acc: 0.9849 -- iter: 192/244
[A[ATraining Step: 119  | total loss: [1m[32m0.06030[0m[0m | time: 54.962s
[2K
| Adam | epoch: 015 | loss: 0.06030 - acc: 0.9802 -- iter: 224/244
[A[ATraining Step: 120  | total loss: [1m[32m0.06295[0m[0m | time: 66.933s
[2K
| Adam | epoch: 015 | loss: 0.06295 - acc: 0.9790 | val_loss: 0.24297 - val_acc: 0.9091 -- iter: 244/244
--
Training Step: 121  | total loss: [1m[32m0.10477[0m[0m | time: 8.614s
[2K
| Adam | epoch: 016 | loss: 0.10477 - acc: 0.9749 -- iter: 032/244
[A[ATraining Step: 122  | total loss: [1m[32m0.09581[0m[0m | time: 17.462s
[2K
| Adam | epoch: 016 | loss: 0.09581 - acc: 0.9774 -- iter: 064/244
[A[ATraining Step: 123  | total loss: [1m[32m0.08680[0m[0m | time: 26.166s
[2K
| Adam | epoch: 016 | loss: 0.08680 - acc: 0.9796 -- iter: 096/244
[A[ATraining Step: 124  | total loss: [1m[32m0.07923[0m[0m | time: 34.876s
[2K
| Adam | epoch: 016 | loss: 0.07923 - acc: 0.9817 -- iter: 128/244
[A[ATraining Step: 125  | total loss: [1m[32m0.07673[0m[0m | time: 40.879s
[2K
| Adam | epoch: 016 | loss: 0.07673 - acc: 0.9804 -- iter: 160/244
[A[ATraining Step: 126  | total loss: [1m[32m0.13853[0m[0m | time: 46.835s
[2K
| Adam | epoch: 016 | loss: 0.13853 - acc: 0.9573 -- iter: 192/244
[A[ATraining Step: 127  | total loss: [1m[32m0.16893[0m[0m | time: 55.449s
[2K
| Adam | epoch: 016 | loss: 0.16893 - acc: 0.9516 -- iter: 224/244
[A[ATraining Step: 128  | total loss: [1m[32m0.16698[0m[0m | time: 67.828s
[2K
| Adam | epoch: 016 | loss: 0.16698 - acc: 0.9502 | val_loss: 0.22649 - val_acc: 0.8831 -- iter: 244/244
--
Training Step: 129  | total loss: [1m[32m0.16364[0m[0m | time: 8.758s
[2K
| Adam | epoch: 017 | loss: 0.16364 - acc: 0.9489 -- iter: 032/244
[A[ATraining Step: 130  | total loss: [1m[32m0.14942[0m[0m | time: 17.444s
[2K
| Adam | epoch: 017 | loss: 0.14942 - acc: 0.9540 -- iter: 064/244
[A[ATraining Step: 131  | total loss: [1m[32m0.13625[0m[0m | time: 26.444s
[2K
| Adam | epoch: 017 | loss: 0.13625 - acc: 0.9586 -- iter: 096/244
[A[ATraining Step: 132  | total loss: [1m[32m0.13332[0m[0m | time: 35.207s
[2K
| Adam | epoch: 017 | loss: 0.13332 - acc: 0.9596 -- iter: 128/244
[A[ATraining Step: 133  | total loss: [1m[32m0.12564[0m[0m | time: 43.906s
[2K
| Adam | epoch: 017 | loss: 0.12564 - acc: 0.9637 -- iter: 160/244
[A[ATraining Step: 134  | total loss: [1m[32m0.13278[0m[0m | time: 49.940s
[2K
| Adam | epoch: 017 | loss: 0.13278 - acc: 0.9579 -- iter: 192/244
[A[ATraining Step: 135  | total loss: [1m[32m0.12928[0m[0m | time: 55.887s
[2K
| Adam | epoch: 017 | loss: 0.12928 - acc: 0.9571 -- iter: 224/244
[A[ATraining Step: 136  | total loss: [1m[32m0.12006[0m[0m | time: 67.962s
[2K
| Adam | epoch: 017 | loss: 0.12006 - acc: 0.9614 | val_loss: 1.07053 - val_acc: 0.7532 -- iter: 244/244
--
Training Step: 137  | total loss: [1m[32m0.11587[0m[0m | time: 8.966s
[2K
| Adam | epoch: 018 | loss: 0.11587 - acc: 0.9653 -- iter: 032/244
[A[ATraining Step: 138  | total loss: [1m[32m0.11036[0m[0m | time: 17.707s
[2K
| Adam | epoch: 018 | loss: 0.11036 - acc: 0.9656 -- iter: 064/244
[A[ATraining Step: 139  | total loss: [1m[32m0.12743[0m[0m | time: 26.590s
[2K
| Adam | epoch: 018 | loss: 0.12743 - acc: 0.9628 -- iter: 096/244
[A[ATraining Step: 140  | total loss: [1m[32m0.11632[0m[0m | time: 35.294s
[2K
| Adam | epoch: 018 | loss: 0.11632 - acc: 0.9665 -- iter: 128/244
[A[ATraining Step: 141  | total loss: [1m[32m0.12828[0m[0m | time: 44.134s
[2K
| Adam | epoch: 018 | loss: 0.12828 - acc: 0.9636 -- iter: 160/244
[A[ATraining Step: 142  | total loss: [1m[32m0.13247[0m[0m | time: 54.702s
[2K
| Adam | epoch: 018 | loss: 0.13247 - acc: 0.9579 -- iter: 192/244
[A[ATraining Step: 143  | total loss: [1m[32m0.12256[0m[0m | time: 61.962s
[2K
| Adam | epoch: 018 | loss: 0.12256 - acc: 0.9590 -- iter: 224/244
[A[ATraining Step: 144  | total loss: [1m[32m0.11211[0m[0m | time: 72.768s
[2K
| Adam | epoch: 018 | loss: 0.11211 - acc: 0.9631 | val_loss: 0.27423 - val_acc: 0.9091 -- iter: 244/244
--
Training Step: 145  | total loss: [1m[32m0.10352[0m[0m | time: 10.760s
[2K
| Adam | epoch: 019 | loss: 0.10352 - acc: 0.9668 -- iter: 032/244
[A[ATraining Step: 146  | total loss: [1m[32m0.10369[0m[0m | time: 20.845s
[2K
| Adam | epoch: 019 | loss: 0.10369 - acc: 0.9638 -- iter: 064/244
[A[ATraining Step: 147  | total loss: [1m[32m0.10334[0m[0m | time: 31.553s
[2K
| Adam | epoch: 019 | loss: 0.10334 - acc: 0.9612 -- iter: 096/244
[A[ATraining Step: 148  | total loss: [1m[32m0.11016[0m[0m | time: 42.302s
[2K
| Adam | epoch: 019 | loss: 0.11016 - acc: 0.9620 -- iter: 128/244
[A[ATraining Step: 149  | total loss: [1m[32m0.10962[0m[0m | time: 52.635s
[2K
| Adam | epoch: 019 | loss: 0.10962 - acc: 0.9595 -- iter: 160/244
[A[ATraining Step: 150  | total loss: [1m[32m0.10183[0m[0m | time: 63.128s
[2K
| Adam | epoch: 019 | loss: 0.10183 - acc: 0.9636 -- iter: 192/244
[A[ATraining Step: 151  | total loss: [1m[32m0.10898[0m[0m | time: 72.904s
[2K
| Adam | epoch: 019 | loss: 0.10898 - acc: 0.9641 -- iter: 224/244
[A[ATraining Step: 152  | total loss: [1m[32m0.10057[0m[0m | time: 84.647s
[2K
| Adam | epoch: 019 | loss: 0.10057 - acc: 0.9677 | val_loss: 1.14890 - val_acc: 0.7792 -- iter: 244/244
--
Training Step: 153  | total loss: [1m[32m0.10301[0m[0m | time: 6.670s
[2K
| Adam | epoch: 020 | loss: 0.10301 - acc: 0.9659 -- iter: 032/244
[A[ATraining Step: 154  | total loss: [1m[32m0.09559[0m[0m | time: 17.337s
[2K
| Adam | epoch: 020 | loss: 0.09559 - acc: 0.9693 -- iter: 064/244
[A[ATraining Step: 155  | total loss: [1m[32m0.08916[0m[0m | time: 27.583s
[2K
| Adam | epoch: 020 | loss: 0.08916 - acc: 0.9693 -- iter: 096/244
[A[ATraining Step: 156  | total loss: [1m[32m0.08110[0m[0m | time: 38.067s
[2K
| Adam | epoch: 020 | loss: 0.08110 - acc: 0.9723 -- iter: 128/244
[A[ATraining Step: 157  | total loss: [1m[32m0.07376[0m[0m | time: 48.772s
[2K
| Adam | epoch: 020 | loss: 0.07376 - acc: 0.9751 -- iter: 160/244
[A[ATraining Step: 158  | total loss: [1m[32m0.06804[0m[0m | time: 59.001s
[2K
| Adam | epoch: 020 | loss: 0.06804 - acc: 0.9776 -- iter: 192/244
[A[ATraining Step: 159  | total loss: [1m[32m0.06748[0m[0m | time: 69.568s
[2K
| Adam | epoch: 020 | loss: 0.06748 - acc: 0.9767 -- iter: 224/244
[A[ATraining Step: 160  | total loss: [1m[32m0.06414[0m[0m | time: 83.901s
[2K
| Adam | epoch: 020 | loss: 0.06414 - acc: 0.9790 | val_loss: 1.08726 - val_acc: 0.8052 -- iter: 244/244
--
Training Step: 161  | total loss: [1m[32m0.06072[0m[0m | time: 7.550s
[2K
| Adam | epoch: 021 | loss: 0.06072 - acc: 0.9780 -- iter: 032/244
[A[ATraining Step: 162  | total loss: [1m[32m0.07810[0m[0m | time: 13.694s
[2K
| Adam | epoch: 021 | loss: 0.07810 - acc: 0.9752 -- iter: 064/244
[A[ATraining Step: 163  | total loss: [1m[32m0.08104[0m[0m | time: 24.235s
[2K
| Adam | epoch: 021 | loss: 0.08104 - acc: 0.9727 -- iter: 096/244
[A[ATraining Step: 164  | total loss: [1m[32m0.08303[0m[0m | time: 35.092s
[2K
| Adam | epoch: 021 | loss: 0.08303 - acc: 0.9723 -- iter: 128/244
[A[ATraining Step: 165  | total loss: [1m[32m0.07688[0m[0m | time: 45.068s
[2K
| Adam | epoch: 021 | loss: 0.07688 - acc: 0.9751 -- iter: 160/244
[A[ATraining Step: 166  | total loss: [1m[32m0.10808[0m[0m | time: 55.906s
[2K
| Adam | epoch: 021 | loss: 0.10808 - acc: 0.9713 -- iter: 192/244
[A[ATraining Step: 167  | total loss: [1m[32m0.09893[0m[0m | time: 65.699s
[2K
| Adam | epoch: 021 | loss: 0.09893 - acc: 0.9742 -- iter: 224/244
[A[ATraining Step: 168  | total loss: [1m[32m0.10842[0m[0m | time: 80.752s
[2K
| Adam | epoch: 021 | loss: 0.10842 - acc: 0.9643 | val_loss: 0.27688 - val_acc: 0.8961 -- iter: 244/244
--
Training Step: 169  | total loss: [1m[32m0.10190[0m[0m | time: 10.398s
[2K
| Adam | epoch: 022 | loss: 0.10190 - acc: 0.9678 -- iter: 032/244
[A[ATraining Step: 170  | total loss: [1m[32m0.10315[0m[0m | time: 17.815s
[2K
| Adam | epoch: 022 | loss: 0.10315 - acc: 0.9679 -- iter: 064/244
[A[ATraining Step: 171  | total loss: [1m[32m0.14518[0m[0m | time: 25.598s
[2K
| Adam | epoch: 022 | loss: 0.14518 - acc: 0.9661 -- iter: 096/244
[A[ATraining Step: 172  | total loss: [1m[32m0.16752[0m[0m | time: 36.276s
[2K
| Adam | epoch: 022 | loss: 0.16752 - acc: 0.9645 -- iter: 128/244
[A[ATraining Step: 173  | total loss: [1m[32m0.17376[0m[0m | time: 47.109s
[2K
| Adam | epoch: 022 | loss: 0.17376 - acc: 0.9556 -- iter: 160/244
[A[ATraining Step: 174  | total loss: [1m[32m0.16495[0m[0m | time: 56.564s
[2K
| Adam | epoch: 022 | loss: 0.16495 - acc: 0.9600 -- iter: 192/244
[A[ATraining Step: 175  | total loss: [1m[32m0.15863[0m[0m | time: 67.671s
[2K
| Adam | epoch: 022 | loss: 0.15863 - acc: 0.9609 -- iter: 224/244
[A[ATraining Step: 176  | total loss: [1m[32m0.15979[0m[0m | time: 82.563s
[2K
| Adam | epoch: 022 | loss: 0.15979 - acc: 0.9585 | val_loss: 0.28437 - val_acc: 0.9221 -- iter: 244/244
--
Training Step: 177  | total loss: [1m[32m0.14861[0m[0m | time: 10.551s
[2K
| Adam | epoch: 023 | loss: 0.14861 - acc: 0.9627 -- iter: 032/244
[A[ATraining Step: 178  | total loss: [1m[32m0.14043[0m[0m | time: 21.189s
[2K
| Adam | epoch: 023 | loss: 0.14043 - acc: 0.9664 -- iter: 064/244
[A[ATraining Step: 179  | total loss: [1m[32m0.13096[0m[0m | time: 27.803s
[2K
| Adam | epoch: 023 | loss: 0.13096 - acc: 0.9698 -- iter: 096/244
[A[ATraining Step: 180  | total loss: [1m[32m0.11994[0m[0m | time: 35.303s
[2K
| Adam | epoch: 023 | loss: 0.11994 - acc: 0.9728 -- iter: 128/244
[A[ATraining Step: 181  | total loss: [1m[32m0.10940[0m[0m | time: 46.295s
[2K
| Adam | epoch: 023 | loss: 0.10940 - acc: 0.9755 -- iter: 160/244
[A[ATraining Step: 182  | total loss: [1m[32m0.10537[0m[0m | time: 56.384s
[2K
| Adam | epoch: 023 | loss: 0.10537 - acc: 0.9780 -- iter: 192/244
[A[ATraining Step: 183  | total loss: [1m[32m0.10273[0m[0m | time: 67.501s
[2K
| Adam | epoch: 023 | loss: 0.10273 - acc: 0.9770 -- iter: 224/244
[A[ATraining Step: 184  | total loss: [1m[32m0.09318[0m[0m | time: 81.497s
[2K
| Adam | epoch: 023 | loss: 0.09318 - acc: 0.9793 | val_loss: 1.49583 - val_acc: 0.6364 -- iter: 244/244
--
Training Step: 185  | total loss: [1m[32m0.08483[0m[0m | time: 10.800s
[2K
| Adam | epoch: 024 | loss: 0.08483 - acc: 0.9814 -- iter: 032/244
[A[ATraining Step: 186  | total loss: [1m[32m0.07961[0m[0m | time: 20.827s
[2K
| Adam | epoch: 024 | loss: 0.07961 - acc: 0.9833 -- iter: 064/244
[A[ATraining Step: 187  | total loss: [1m[32m0.07232[0m[0m | time: 31.630s
[2K
| Adam | epoch: 024 | loss: 0.07232 - acc: 0.9849 -- iter: 096/244
[A[ATraining Step: 188  | total loss: [1m[32m0.07512[0m[0m | time: 39.233s
[2K
| Adam | epoch: 024 | loss: 0.07512 - acc: 0.9833 -- iter: 128/244
[A[ATraining Step: 189  | total loss: [1m[32m0.07345[0m[0m | time: 45.946s
[2K
| Adam | epoch: 024 | loss: 0.07345 - acc: 0.9800 -- iter: 160/244
[A[ATraining Step: 190  | total loss: [1m[32m0.06918[0m[0m | time: 56.551s
[2K
| Adam | epoch: 024 | loss: 0.06918 - acc: 0.9820 -- iter: 192/244
[A[ATraining Step: 191  | total loss: [1m[32m0.06873[0m[0m | time: 66.888s
[2K
| Adam | epoch: 024 | loss: 0.06873 - acc: 0.9807 -- iter: 224/244
[A[ATraining Step: 192  | total loss: [1m[32m0.06303[0m[0m | time: 81.754s
[2K
| Adam | epoch: 024 | loss: 0.06303 - acc: 0.9826 | val_loss: 2.02152 - val_acc: 0.6364 -- iter: 244/244
--
Training Step: 193  | total loss: [1m[32m0.06059[0m[0m | time: 10.086s
[2K
| Adam | epoch: 025 | loss: 0.06059 - acc: 0.9812 -- iter: 032/244
[A[ATraining Step: 194  | total loss: [1m[32m0.05497[0m[0m | time: 18.890s
[2K
| Adam | epoch: 025 | loss: 0.05497 - acc: 0.9831 -- iter: 064/244
[A[ATraining Step: 195  | total loss: [1m[32m0.05021[0m[0m | time: 27.480s
[2K
| Adam | epoch: 025 | loss: 0.05021 - acc: 0.9848 -- iter: 096/244
[A[ATraining Step: 196  | total loss: [1m[32m0.04646[0m[0m | time: 36.111s
[2K
| Adam | epoch: 025 | loss: 0.04646 - acc: 0.9863 -- iter: 128/244
[A[ATraining Step: 197  | total loss: [1m[32m0.04217[0m[0m | time: 41.987s
[2K
| Adam | epoch: 025 | loss: 0.04217 - acc: 0.9877 -- iter: 160/244
[A[ATraining Step: 198  | total loss: [1m[32m0.04013[0m[0m | time: 47.839s
[2K
| Adam | epoch: 025 | loss: 0.04013 - acc: 0.9889 -- iter: 192/244
[A[ATraining Step: 199  | total loss: [1m[32m0.03734[0m[0m | time: 56.571s
[2K
| Adam | epoch: 025 | loss: 0.03734 - acc: 0.9900 -- iter: 224/244
[A[ATraining Step: 200  | total loss: [1m[32m0.03611[0m[0m | time: 68.817s
[2K
| Adam | epoch: 025 | loss: 0.03611 - acc: 0.9879 | val_loss: 0.29762 - val_acc: 0.9221 -- iter: 244/244
--
Training Step: 201  | total loss: [1m[32m0.03310[0m[0m | time: 8.823s
[2K
| Adam | epoch: 026 | loss: 0.03310 - acc: 0.9891 -- iter: 032/244
[A[ATraining Step: 202  | total loss: [1m[32m0.05367[0m[0m | time: 17.451s
[2K
| Adam | epoch: 026 | loss: 0.05367 - acc: 0.9871 -- iter: 064/244
[A[ATraining Step: 203  | total loss: [1m[32m0.05199[0m[0m | time: 26.061s
[2K
| Adam | epoch: 026 | loss: 0.05199 - acc: 0.9852 -- iter: 096/244
[A[ATraining Step: 204  | total loss: [1m[32m0.05017[0m[0m | time: 34.656s
[2K
| Adam | epoch: 026 | loss: 0.05017 - acc: 0.9836 -- iter: 128/244
[A[ATraining Step: 205  | total loss: [1m[32m0.05567[0m[0m | time: 43.374s
[2K
| Adam | epoch: 026 | loss: 0.05567 - acc: 0.9821 -- iter: 160/244
[A[ATraining Step: 206  | total loss: [1m[32m0.05146[0m[0m | time: 49.135s
[2K
| Adam | epoch: 026 | loss: 0.05146 - acc: 0.9839 -- iter: 192/244
[A[ATraining Step: 207  | total loss: [1m[32m0.04645[0m[0m | time: 54.850s
[2K
| Adam | epoch: 026 | loss: 0.04645 - acc: 0.9855 -- iter: 224/244
[A[ATraining Step: 208  | total loss: [1m[32m0.04200[0m[0m | time: 66.882s
[2K
| Adam | epoch: 026 | loss: 0.04200 - acc: 0.9870 | val_loss: 5.06507 - val_acc: 0.4416 -- iter: 244/244
--
Training Step: 209  | total loss: [1m[32m0.03954[0m[0m | time: 8.684s
[2K
| Adam | epoch: 027 | loss: 0.03954 - acc: 0.9883 -- iter: 032/244
[A[ATraining Step: 210  | total loss: [1m[32m0.03816[0m[0m | time: 17.389s
[2K
| Adam | epoch: 027 | loss: 0.03816 - acc: 0.9894 -- iter: 064/244
[A[ATraining Step: 211  | total loss: [1m[32m0.08094[0m[0m | time: 25.986s
[2K
| Adam | epoch: 027 | loss: 0.08094 - acc: 0.9874 -- iter: 096/244
[A[ATraining Step: 212  | total loss: [1m[32m0.07566[0m[0m | time: 34.594s
[2K
| Adam | epoch: 027 | loss: 0.07566 - acc: 0.9855 -- iter: 128/244
[A[ATraining Step: 213  | total loss: [1m[32m0.07335[0m[0m | time: 43.260s
[2K
| Adam | epoch: 027 | loss: 0.07335 - acc: 0.9838 -- iter: 160/244
[A[ATraining Step: 214  | total loss: [1m[32m0.06655[0m[0m | time: 52.155s
[2K
| Adam | epoch: 027 | loss: 0.06655 - acc: 0.9854 -- iter: 192/244
[A[ATraining Step: 215  | total loss: [1m[32m0.06088[0m[0m | time: 58.089s
[2K
| Adam | epoch: 027 | loss: 0.06088 - acc: 0.9869 -- iter: 224/244
[A[ATraining Step: 216  | total loss: [1m[32m0.05785[0m[0m | time: 67.526s
[2K
| Adam | epoch: 027 | loss: 0.05785 - acc: 0.9882 | val_loss: 2.69784 - val_acc: 0.4805 -- iter: 244/244
--
Training Step: 217  | total loss: [1m[32m0.05376[0m[0m | time: 8.659s
[2K
| Adam | epoch: 028 | loss: 0.05376 - acc: 0.9894 -- iter: 032/244
[A[ATraining Step: 218  | total loss: [1m[32m0.04999[0m[0m | time: 17.492s
[2K
| Adam | epoch: 028 | loss: 0.04999 - acc: 0.9905 -- iter: 064/244
[A[ATraining Step: 219  | total loss: [1m[32m0.05231[0m[0m | time: 26.242s
[2K
| Adam | epoch: 028 | loss: 0.05231 - acc: 0.9883 -- iter: 096/244
[A[ATraining Step: 220  | total loss: [1m[32m0.04885[0m[0m | time: 35.024s
[2K
| Adam | epoch: 028 | loss: 0.04885 - acc: 0.9895 -- iter: 128/244
[A[ATraining Step: 221  | total loss: [1m[32m0.04524[0m[0m | time: 43.665s
[2K
| Adam | epoch: 028 | loss: 0.04524 - acc: 0.9905 -- iter: 160/244
[A[ATraining Step: 222  | total loss: [1m[32m0.04319[0m[0m | time: 52.235s
[2K
| Adam | epoch: 028 | loss: 0.04319 - acc: 0.9915 -- iter: 192/244
[A[ATraining Step: 223  | total loss: [1m[32m0.03961[0m[0m | time: 60.854s
[2K
| Adam | epoch: 028 | loss: 0.03961 - acc: 0.9923 -- iter: 224/244
[A[ATraining Step: 224  | total loss: [1m[32m0.03592[0m[0m | time: 70.225s
[2K
| Adam | epoch: 028 | loss: 0.03592 - acc: 0.9931 | val_loss: 0.25818 - val_acc: 0.9221 -- iter: 244/244
--
Training Step: 225  | total loss: [1m[32m0.03495[0m[0m | time: 5.994s
[2K
| Adam | epoch: 029 | loss: 0.03495 - acc: 0.9938 -- iter: 032/244
[A[ATraining Step: 226  | total loss: [1m[32m0.03401[0m[0m | time: 14.601s
[2K
| Adam | epoch: 029 | loss: 0.03401 - acc: 0.9944 -- iter: 064/244
[A[ATraining Step: 227  | total loss: [1m[32m0.03276[0m[0m | time: 23.161s
[2K
| Adam | epoch: 029 | loss: 0.03276 - acc: 0.9950 -- iter: 096/244
[A[ATraining Step: 228  | total loss: [1m[32m0.03021[0m[0m | time: 31.832s
[2K
| Adam | epoch: 029 | loss: 0.03021 - acc: 0.9955 -- iter: 128/244
[A[ATraining Step: 229  | total loss: [1m[32m0.04848[0m[0m | time: 40.396s
[2K
| Adam | epoch: 029 | loss: 0.04848 - acc: 0.9928 -- iter: 160/244
[A[ATraining Step: 230  | total loss: [1m[32m0.04384[0m[0m | time: 49.068s
[2K
| Adam | epoch: 029 | loss: 0.04384 - acc: 0.9935 -- iter: 192/244
[A[ATraining Step: 231  | total loss: [1m[32m0.03958[0m[0m | time: 57.570s
[2K
| Adam | epoch: 029 | loss: 0.03958 - acc: 0.9942 -- iter: 224/244
[A[ATraining Step: 232  | total loss: [1m[32m0.03637[0m[0m | time: 69.633s
[2K
| Adam | epoch: 029 | loss: 0.03637 - acc: 0.9947 | val_loss: 1.35450 - val_acc: 0.6623 -- iter: 244/244
--
Training Step: 233  | total loss: [1m[32m0.03358[0m[0m | time: 5.718s
[2K
| Adam | epoch: 030 | loss: 0.03358 - acc: 0.9953 -- iter: 032/244
[A[ATraining Step: 234  | total loss: [1m[32m0.03202[0m[0m | time: 11.573s
[2K
| Adam | epoch: 030 | loss: 0.03202 - acc: 0.9957 -- iter: 064/244
[A[ATraining Step: 235  | total loss: [1m[32m0.03040[0m[0m | time: 20.124s
[2K
| Adam | epoch: 030 | loss: 0.03040 - acc: 0.9962 -- iter: 096/244
[A[ATraining Step: 236  | total loss: [1m[32m0.02754[0m[0m | time: 28.720s
[2K
| Adam | epoch: 030 | loss: 0.02754 - acc: 0.9966 -- iter: 128/244
[A[ATraining Step: 237  | total loss: [1m[32m0.02505[0m[0m | time: 37.272s
[2K
| Adam | epoch: 030 | loss: 0.02505 - acc: 0.9969 -- iter: 160/244
[A[ATraining Step: 238  | total loss: [1m[32m0.02385[0m[0m | time: 46.093s
[2K
| Adam | epoch: 030 | loss: 0.02385 - acc: 0.9972 -- iter: 192/244
[A[ATraining Step: 239  | total loss: [1m[32m0.02166[0m[0m | time: 54.744s
[2K
| Adam | epoch: 030 | loss: 0.02166 - acc: 0.9975 -- iter: 224/244
[A[ATraining Step: 240  | total loss: [1m[32m0.03962[0m[0m | time: 66.852s
[2K
| Adam | epoch: 030 | loss: 0.03962 - acc: 0.9946 | val_loss: 0.33831 - val_acc: 0.8701 -- iter: 244/244
--
Validation AUC:0.9733242134062927
Validation AUPRC:0.979956545844195
Test AUC:0.945945945945946
Test AUPRC:0.9108148690058426
BestTestF1Score	0.87	0.74	0.87	0.85	0.89	33	6	34	4	0.18
BestTestMCCScore	0.88	0.77	0.88	0.87	0.89	33	5	35	4	0.4
BestTestAccuracyScore	0.88	0.77	0.88	0.87	0.89	33	5	35	4	0.4
BestValidationF1Score	0.93	0.84	0.92	0.93	0.93	40	3	31	3	0.18
BestValidationMCC	0.93	0.84	0.92	0.95	0.91	39	2	32	4	0.4
BestValidationAccuracy	0.93	0.84	0.92	0.95	0.91	39	2	32	4	0.4
TestPredictions (Threshold:0.4)
CHEMBL128360,TN,INACT,0.0	CHEMBL552615,TN,INACT,0.0	CHEMBL433349,TP,ACT,1.0	CHEMBL594376,TN,INACT,0.0	CHEMBL417712,TN,INACT,0.0	CHEMBL2370070,TP,ACT,1.0	CHEMBL3144845,TN,INACT,0.009999999776482582	CHEMBL100624,TN,INACT,0.0	CHEMBL6568,TN,INACT,0.0	CHEMBL329609,TP,ACT,1.0	CHEMBL21937,TN,INACT,0.0	CHEMBL44134,TN,INACT,0.0	CHEMBL3144732,TP,ACT,1.0	CHEMBL358461,FN,ACT,0.14000000059604645	CHEMBL1916635,TN,INACT,0.009999999776482582	CHEMBL191915,TN,INACT,0.0	CHEMBL3309718,TN,INACT,0.0	CHEMBL432091,FP,INACT,1.0	CHEMBL2370066,TP,ACT,1.0	CHEMBL408492,FP,INACT,0.6299999952316284	CHEMBL438915,FP,INACT,0.800000011920929	CHEMBL602269,TN,INACT,0.0	CHEMBL368629,TN,INACT,0.3499999940395355	CHEMBL93331,TP,ACT,1.0	CHEMBL438380,TP,ACT,0.5199999809265137	CHEMBL1983100,TN,INACT,0.0	CHEMBL168632,TN,INACT,0.009999999776482582	CHEMBL386181,TP,ACT,1.0	CHEMBL319719,TP,ACT,1.0	CHEMBL3144736,FP,INACT,0.47999998927116394	CHEMBL2296900,TP,ACT,0.9900000095367432	CHEMBL405709,TP,ACT,1.0	CHEMBL265164,TP,ACT,0.9300000071525574	CHEMBL313760,TP,ACT,1.0	CHEMBL150481,TN,INACT,0.0	CHEMBL957,FN,ACT,0.03999999910593033	CHEMBL315622,TP,ACT,0.9599999785423279	CHEMBL369359,TN,INACT,0.0	CHEMBL424214,TN,INACT,0.0	CHEMBL2322893,TN,INACT,0.0	CHEMBL2391353,TN,INACT,0.0	CHEMBL43661,TN,INACT,0.009999999776482582	CHEMBL407933,TP,ACT,0.9900000095367432	CHEMBL2369736,TP,ACT,0.5400000214576721	CHEMBL312979,TP,ACT,1.0	CHEMBL2391356,TN,INACT,0.0	CHEMBL414570,TN,INACT,0.11999999731779099	CHEMBL281865,TP,ACT,1.0	CHEMBL437472,TP,ACT,0.7400000095367432	CHEMBL343477,TN,INACT,0.17000000178813934	CHEMBL86965,TP,ACT,0.5099999904632568	CHEMBL1222310,TP,ACT,0.9700000286102295	CHEMBL315280,TP,ACT,1.0	CHEMBL2369709,TP,ACT,0.6200000047683716	CHEMBL86814,TP,ACT,1.0	CHEMBL86489,FN,ACT,0.07999999821186066	CHEMBL279520,TN,INACT,0.0	CHEMBL314364,FN,ACT,0.03999999910593033	CHEMBL595022,TN,INACT,0.0	CHEMBL3109772,TN,INACT,0.0	CHEMBL352779,TN,INACT,0.0	CHEMBL422128,TP,ACT,0.75	CHEMBL330885,TN,INACT,0.0	CHEMBL436884,TP,ACT,1.0	CHEMBL227429,TN,INACT,0.0	CHEMBL421349,TP,ACT,0.9700000286102295	CHEMBL2111789,TN,INACT,0.0	CHEMBL88019,TP,ACT,0.9399999976158142	CHEMBL86703,TP,ACT,1.0	CHEMBL2370254,TP,ACT,0.6499999761581421	CHEMBL87243,TP,ACT,1.0	CHEMBL315936,TP,ACT,0.41999998688697815	CHEMBL9666,TN,INACT,0.0	CHEMBL3780248,FP,INACT,0.49000000953674316	CHEMBL86505,TP,ACT,0.4000000059604645	CHEMBL39879,TN,INACT,0.0	CHEMBL42360,TN,INACT,0.0	

