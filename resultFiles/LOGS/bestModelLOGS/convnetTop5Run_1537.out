ImageNetInceptionV2 CHEMBL3478 adam 0.001 15 0 0 0.6 False True
Number of active compounds :	191
Number of inactive compounds :	191
---------------------------------
Run id: ImageNetInceptionV2_CHEMBL3478_adam_0.001_15_0_0_0.6_False_True_id
Log directory: ../tflearnLogs/ImageNetInceptionV2_CHEMBL3478_adam_0.001_15_0.6/
---------------------------------
Training samples: 244
Validation samples: 77
--
Training Step: 1  | time: 101.159s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/244
[A[ATraining Step: 2  | total loss: [1m[32m0.67937[0m[0m | time: 379.957s
[2K
| Adam | epoch: 001 | loss: 0.67937 - acc: 0.4781 -- iter: 064/244
[A[ATraining Step: 3  | total loss: [1m[32m0.59930[0m[0m | time: 480.366s
[2K
| Adam | epoch: 001 | loss: 0.59930 - acc: 0.6750 -- iter: 096/244
[A[ATraining Step: 4  | total loss: [1m[32m0.86265[0m[0m | time: 618.191s
[2K
| Adam | epoch: 001 | loss: 0.86265 - acc: 0.6375 -- iter: 128/244
[A[ATraining Step: 5  | total loss: [1m[32m0.66301[0m[0m | time: 697.794s
[2K
| Adam | epoch: 001 | loss: 0.66301 - acc: 0.7154 -- iter: 160/244
[A[ATraining Step: 6  | total loss: [1m[32m0.61739[0m[0m | time: 754.952s
[2K
| Adam | epoch: 001 | loss: 0.61739 - acc: 0.7376 -- iter: 192/244
[A[ATraining Step: 7  | total loss: [1m[32m0.62545[0m[0m | time: 806.032s
[2K
| Adam | epoch: 001 | loss: 0.62545 - acc: 0.6888 -- iter: 224/244
[A[ATraining Step: 8  | total loss: [1m[32m0.60988[0m[0m | time: 857.621s
[2K
| Adam | epoch: 001 | loss: 0.60988 - acc: 0.7056 | val_loss: 2.00777 - val_acc: 0.5844 -- iter: 244/244
--
Training Step: 9  | total loss: [1m[32m0.62983[0m[0m | time: 6.886s
[2K
| Adam | epoch: 002 | loss: 0.62983 - acc: 0.7556 -- iter: 032/244
[A[ATraining Step: 10  | total loss: [1m[32m0.48173[0m[0m | time: 31.463s
[2K
| Adam | epoch: 002 | loss: 0.48173 - acc: 0.8278 -- iter: 064/244
[A[ATraining Step: 11  | total loss: [1m[32m0.48627[0m[0m | time: 93.906s
[2K
| Adam | epoch: 002 | loss: 0.48627 - acc: 0.7169 -- iter: 096/244
[A[ATraining Step: 12  | total loss: [1m[32m0.45958[0m[0m | time: 213.135s
[2K
| Adam | epoch: 002 | loss: 0.45958 - acc: 0.7740 -- iter: 128/244
[A[ATraining Step: 13  | total loss: [1m[32m0.42091[0m[0m | time: 258.954s
[2K
| Adam | epoch: 002 | loss: 0.42091 - acc: 0.8307 -- iter: 160/244
[A[ATraining Step: 14  | total loss: [1m[32m0.39145[0m[0m | time: 290.827s
[2K
| Adam | epoch: 002 | loss: 0.39145 - acc: 0.8360 -- iter: 192/244
[A[ATraining Step: 15  | total loss: [1m[32m0.34844[0m[0m | time: 335.575s
[2K
| Adam | epoch: 002 | loss: 0.34844 - acc: 0.8635 -- iter: 224/244
[A[ATraining Step: 16  | total loss: [1m[32m0.32057[0m[0m | time: 366.388s
[2K
| Adam | epoch: 002 | loss: 0.32057 - acc: 0.8678 | val_loss: 1.13444 - val_acc: 0.5844 -- iter: 244/244
--
Training Step: 17  | total loss: [1m[32m0.34787[0m[0m | time: 59.214s
[2K
| Adam | epoch: 003 | loss: 0.34787 - acc: 0.8592 -- iter: 032/244
[A[ATraining Step: 18  | total loss: [1m[32m0.33047[0m[0m | time: 100.749s
[2K
| Adam | epoch: 003 | loss: 0.33047 - acc: 0.8733 -- iter: 064/244
[A[ATraining Step: 19  | total loss: [1m[32m0.24915[0m[0m | time: 120.784s
[2K
| Adam | epoch: 003 | loss: 0.24915 - acc: 0.9155 -- iter: 096/244
[A[ATraining Step: 20  | total loss: [1m[32m0.33060[0m[0m | time: 135.895s
[2K
| Adam | epoch: 003 | loss: 0.33060 - acc: 0.8724 -- iter: 128/244
[A[ATraining Step: 21  | total loss: [1m[32m0.28246[0m[0m | time: 151.366s
[2K
| Adam | epoch: 003 | loss: 0.28246 - acc: 0.8926 -- iter: 160/244
[A[ATraining Step: 22  | total loss: [1m[32m0.28213[0m[0m | time: 218.035s
[2K
| Adam | epoch: 003 | loss: 0.28213 - acc: 0.8873 -- iter: 192/244
[A[ATraining Step: 23  | total loss: [1m[32m0.25202[0m[0m | time: 269.080s
[2K
| Adam | epoch: 003 | loss: 0.25202 - acc: 0.8928 -- iter: 224/244
[A[ATraining Step: 24  | total loss: [1m[32m0.21804[0m[0m | time: 315.604s
[2K
| Adam | epoch: 003 | loss: 0.21804 - acc: 0.9142 | val_loss: 2.19068 - val_acc: 0.5844 -- iter: 244/244
--
Training Step: 25  | total loss: [1m[32m0.23953[0m[0m | time: 23.295s
[2K
| Adam | epoch: 004 | loss: 0.23953 - acc: 0.9120 -- iter: 032/244
[A[ATraining Step: 26  | total loss: [1m[32m0.23231[0m[0m | time: 30.982s
[2K
| Adam | epoch: 004 | loss: 0.23231 - acc: 0.9105 -- iter: 064/244
[A[ATraining Step: 27  | total loss: [1m[32m0.21899[0m[0m | time: 36.700s
[2K
| Adam | epoch: 004 | loss: 0.21899 - acc: 0.9206 -- iter: 096/244
[A[ATraining Step: 28  | total loss: [1m[32m0.18600[0m[0m | time: 45.449s
[2K
| Adam | epoch: 004 | loss: 0.18600 - acc: 0.9405 -- iter: 128/244
[A[ATraining Step: 29  | total loss: [1m[32m0.23138[0m[0m | time: 55.718s
[2K
| Adam | epoch: 004 | loss: 0.23138 - acc: 0.9170 -- iter: 160/244
[A[ATraining Step: 30  | total loss: [1m[32m0.25995[0m[0m | time: 68.354s
[2K
| Adam | epoch: 004 | loss: 0.25995 - acc: 0.9218 -- iter: 192/244
[A[ATraining Step: 31  | total loss: [1m[32m0.42040[0m[0m | time: 81.050s
[2K
| Adam | epoch: 004 | loss: 0.42040 - acc: 0.8822 -- iter: 224/244
[A[ATraining Step: 32  | total loss: [1m[32m0.37460[0m[0m | time: 100.655s
[2K
| Adam | epoch: 004 | loss: 0.37460 - acc: 0.8876 | val_loss: 3.65662 - val_acc: 0.5844 -- iter: 244/244
--
Training Step: 33  | total loss: [1m[32m0.34383[0m[0m | time: 13.001s
[2K
| Adam | epoch: 005 | loss: 0.34383 - acc: 0.8848 -- iter: 032/244
[A[ATraining Step: 34  | total loss: [1m[32m0.32336[0m[0m | time: 25.307s
[2K
| Adam | epoch: 005 | loss: 0.32336 - acc: 0.8894 -- iter: 064/244
[A[ATraining Step: 35  | total loss: [1m[32m0.29250[0m[0m | time: 31.086s
[2K
| Adam | epoch: 005 | loss: 0.29250 - acc: 0.8995 -- iter: 096/244
[A[ATraining Step: 36  | total loss: [1m[32m0.26105[0m[0m | time: 36.855s
[2K
| Adam | epoch: 005 | loss: 0.26105 - acc: 0.9200 -- iter: 128/244
[A[ATraining Step: 37  | total loss: [1m[32m0.22547[0m[0m | time: 46.896s
[2K
| Adam | epoch: 005 | loss: 0.22547 - acc: 0.9360 -- iter: 160/244
[A[ATraining Step: 38  | total loss: [1m[32m0.23924[0m[0m | time: 59.924s
[2K
| Adam | epoch: 005 | loss: 0.23924 - acc: 0.9241 -- iter: 192/244
[A[ATraining Step: 39  | total loss: [1m[32m0.21900[0m[0m | time: 72.507s
[2K
| Adam | epoch: 005 | loss: 0.21900 - acc: 0.9267 -- iter: 224/244
[A[ATraining Step: 40  | total loss: [1m[32m0.41018[0m[0m | time: 91.167s
[2K
| Adam | epoch: 005 | loss: 0.41018 - acc: 0.8760 | val_loss: 1.11285 - val_acc: 0.4805 -- iter: 244/244
--
Training Step: 41  | total loss: [1m[32m0.39156[0m[0m | time: 13.271s
[2K
| Adam | epoch: 006 | loss: 0.39156 - acc: 0.8815 -- iter: 032/244
[A[ATraining Step: 42  | total loss: [1m[32m0.35872[0m[0m | time: 26.088s
[2K
| Adam | epoch: 006 | loss: 0.35872 - acc: 0.8860 -- iter: 064/244
[A[ATraining Step: 43  | total loss: [1m[32m0.33653[0m[0m | time: 34.682s
[2K
| Adam | epoch: 006 | loss: 0.33653 - acc: 0.8896 -- iter: 096/244
[A[ATraining Step: 44  | total loss: [1m[32m0.29602[0m[0m | time: 40.737s
[2K
| Adam | epoch: 006 | loss: 0.29602 - acc: 0.9087 -- iter: 128/244
[A[ATraining Step: 45  | total loss: [1m[32m0.27343[0m[0m | time: 46.470s
[2K
| Adam | epoch: 006 | loss: 0.27343 - acc: 0.9157 -- iter: 160/244
[A[ATraining Step: 46  | total loss: [1m[32m0.25025[0m[0m | time: 55.037s
[2K
| Adam | epoch: 006 | loss: 0.25025 - acc: 0.9297 -- iter: 192/244
[A[ATraining Step: 47  | total loss: [1m[32m0.26329[0m[0m | time: 87.531s
[2K
| Adam | epoch: 006 | loss: 0.26329 - acc: 0.9106 -- iter: 224/244
[A[ATraining Step: 48  | total loss: [1m[32m0.24671[0m[0m | time: 106.730s
[2K
| Adam | epoch: 006 | loss: 0.24671 - acc: 0.9099 | val_loss: 0.67655 - val_acc: 0.7273 -- iter: 244/244
--
Training Step: 49  | total loss: [1m[32m0.26359[0m[0m | time: 13.170s
[2K
| Adam | epoch: 007 | loss: 0.26359 - acc: 0.9093 -- iter: 032/244
[A[ATraining Step: 50  | total loss: [1m[32m0.23325[0m[0m | time: 26.757s
[2K
| Adam | epoch: 007 | loss: 0.23325 - acc: 0.9234 -- iter: 064/244
[A[ATraining Step: 51  | total loss: [1m[32m0.22686[0m[0m | time: 35.703s
[2K
| Adam | epoch: 007 | loss: 0.22686 - acc: 0.9255 -- iter: 096/244
[A[ATraining Step: 52  | total loss: [1m[32m0.21294[0m[0m | time: 44.354s
[2K
| Adam | epoch: 007 | loss: 0.21294 - acc: 0.9320 -- iter: 128/244
[A[ATraining Step: 53  | total loss: [1m[32m0.19563[0m[0m | time: 50.238s
[2K
| Adam | epoch: 007 | loss: 0.19563 - acc: 0.9374 -- iter: 160/244
[A[ATraining Step: 54  | total loss: [1m[32m0.19539[0m[0m | time: 59.422s
[2K
| Adam | epoch: 007 | loss: 0.19539 - acc: 0.9320 -- iter: 192/244
[A[ATraining Step: 55  | total loss: [1m[32m0.18257[0m[0m | time: 72.205s
[2K
| Adam | epoch: 007 | loss: 0.18257 - acc: 0.9417 -- iter: 224/244
[A[ATraining Step: 56  | total loss: [1m[32m0.16581[0m[0m | time: 91.034s
[2K
| Adam | epoch: 007 | loss: 0.16581 - acc: 0.9499 | val_loss: 0.97659 - val_acc: 0.5065 -- iter: 244/244
--
Training Step: 57  | total loss: [1m[32m0.18051[0m[0m | time: 13.132s
[2K
| Adam | epoch: 008 | loss: 0.18051 - acc: 0.9482 -- iter: 032/244
[A[ATraining Step: 58  | total loss: [1m[32m0.17707[0m[0m | time: 26.366s
[2K
| Adam | epoch: 008 | loss: 0.17707 - acc: 0.9425 -- iter: 064/244
[A[ATraining Step: 59  | total loss: [1m[32m0.17311[0m[0m | time: 38.059s
[2K
| Adam | epoch: 008 | loss: 0.17311 - acc: 0.9460 -- iter: 096/244
[A[ATraining Step: 60  | total loss: [1m[32m0.15476[0m[0m | time: 46.897s
[2K
| Adam | epoch: 008 | loss: 0.15476 - acc: 0.9531 -- iter: 128/244
[A[ATraining Step: 61  | total loss: [1m[32m0.14059[0m[0m | time: 55.640s
[2K
| Adam | epoch: 008 | loss: 0.14059 - acc: 0.9593 -- iter: 160/244
[A[ATraining Step: 62  | total loss: [1m[32m0.14669[0m[0m | time: 64.274s
[2K
| Adam | epoch: 008 | loss: 0.14669 - acc: 0.9605 -- iter: 192/244
[A[ATraining Step: 63  | total loss: [1m[32m0.13750[0m[0m | time: 72.841s
[2K
| Adam | epoch: 008 | loss: 0.13750 - acc: 0.9592 -- iter: 224/244
[A[ATraining Step: 64  | total loss: [1m[32m0.12455[0m[0m | time: 92.375s
[2K
| Adam | epoch: 008 | loss: 0.12455 - acc: 0.9643 | val_loss: 1.09169 - val_acc: 0.6364 -- iter: 244/244
--
Training Step: 65  | total loss: [1m[32m0.11816[0m[0m | time: 11.841s
[2K
| Adam | epoch: 009 | loss: 0.11816 - acc: 0.9648 -- iter: 032/244
[A[ATraining Step: 66  | total loss: [1m[32m0.11087[0m[0m | time: 24.624s
[2K
| Adam | epoch: 009 | loss: 0.11087 - acc: 0.9653 -- iter: 064/244
[A[ATraining Step: 67  | total loss: [1m[32m0.15612[0m[0m | time: 38.165s
[2K
| Adam | epoch: 009 | loss: 0.15612 - acc: 0.9582 -- iter: 096/244
[A[ATraining Step: 68  | total loss: [1m[32m0.14889[0m[0m | time: 46.935s
[2K
| Adam | epoch: 009 | loss: 0.14889 - acc: 0.9595 -- iter: 128/244
[A[ATraining Step: 69  | total loss: [1m[32m0.13539[0m[0m | time: 55.646s
[2K
| Adam | epoch: 009 | loss: 0.13539 - acc: 0.9642 -- iter: 160/244
[A[ATraining Step: 70  | total loss: [1m[32m0.12333[0m[0m | time: 64.376s
[2K
| Adam | epoch: 009 | loss: 0.12333 - acc: 0.9683 -- iter: 192/244
[A[ATraining Step: 71  | total loss: [1m[32m0.12237[0m[0m | time: 70.174s
[2K
| Adam | epoch: 009 | loss: 0.12237 - acc: 0.9684 -- iter: 224/244
[A[ATraining Step: 72  | total loss: [1m[32m0.13130[0m[0m | time: 84.242s
[2K
| Adam | epoch: 009 | loss: 0.13130 - acc: 0.9663 | val_loss: 0.99059 - val_acc: 0.5714 -- iter: 244/244
--
Training Step: 73  | total loss: [1m[32m0.13008[0m[0m | time: 12.930s
[2K
| Adam | epoch: 010 | loss: 0.13008 - acc: 0.9645 -- iter: 032/244
[A[ATraining Step: 74  | total loss: [1m[32m0.13315[0m[0m | time: 26.280s
[2K
| Adam | epoch: 010 | loss: 0.13315 - acc: 0.9615 -- iter: 064/244
[A[ATraining Step: 75  | total loss: [1m[32m0.12675[0m[0m | time: 38.750s
[2K
| Adam | epoch: 010 | loss: 0.12675 - acc: 0.9623 -- iter: 096/244
[A[ATraining Step: 76  | total loss: [1m[32m0.14108[0m[0m | time: 52.092s
[2K
| Adam | epoch: 010 | loss: 0.14108 - acc: 0.9597 -- iter: 128/244
[A[ATraining Step: 77  | total loss: [1m[32m0.14735[0m[0m | time: 64.065s
[2K
| Adam | epoch: 010 | loss: 0.14735 - acc: 0.9573 -- iter: 160/244
[A[ATraining Step: 78  | total loss: [1m[32m0.13484[0m[0m | time: 72.635s
[2K
| Adam | epoch: 010 | loss: 0.13484 - acc: 0.9618 -- iter: 192/244
[A[ATraining Step: 79  | total loss: [1m[32m0.14449[0m[0m | time: 81.299s
[2K
| Adam | epoch: 010 | loss: 0.14449 - acc: 0.9593 -- iter: 224/244
[A[ATraining Step: 80  | total loss: [1m[32m0.14945[0m[0m | time: 94.800s
[2K
| Adam | epoch: 010 | loss: 0.14945 - acc: 0.9570 | val_loss: 1.13736 - val_acc: 0.7922 -- iter: 244/244
--
Training Step: 81  | total loss: [1m[32m0.14433[0m[0m | time: 8.494s
[2K
| Adam | epoch: 011 | loss: 0.14433 - acc: 0.9614 -- iter: 032/244
[A[ATraining Step: 82  | total loss: [1m[32m0.13599[0m[0m | time: 23.916s
[2K
| Adam | epoch: 011 | loss: 0.13599 - acc: 0.9652 -- iter: 064/244
[A[ATraining Step: 83  | total loss: [1m[32m0.15020[0m[0m | time: 37.102s
[2K
| Adam | epoch: 011 | loss: 0.15020 - acc: 0.9593 -- iter: 096/244
[A[ATraining Step: 84  | total loss: [1m[32m0.14654[0m[0m | time: 48.649s
[2K
| Adam | epoch: 011 | loss: 0.14654 - acc: 0.9603 -- iter: 128/244
[A[ATraining Step: 85  | total loss: [1m[32m0.14997[0m[0m | time: 59.178s
[2K
| Adam | epoch: 011 | loss: 0.14997 - acc: 0.9580 -- iter: 160/244
[A[ATraining Step: 86  | total loss: [1m[32m0.14200[0m[0m | time: 67.906s
[2K
| Adam | epoch: 011 | loss: 0.14200 - acc: 0.9591 -- iter: 192/244
[A[ATraining Step: 87  | total loss: [1m[32m0.13774[0m[0m | time: 77.605s
[2K
| Adam | epoch: 011 | loss: 0.13774 - acc: 0.9569 -- iter: 224/244
[A[ATraining Step: 88  | total loss: [1m[32m0.12683[0m[0m | time: 95.937s
[2K
| Adam | epoch: 011 | loss: 0.12683 - acc: 0.9612 | val_loss: 0.43463 - val_acc: 0.8182 -- iter: 244/244
--
Training Step: 89  | total loss: [1m[32m0.14086[0m[0m | time: 8.672s
[2K
| Adam | epoch: 012 | loss: 0.14086 - acc: 0.9526 -- iter: 032/244
[A[ATraining Step: 90  | total loss: [1m[32m0.14430[0m[0m | time: 17.516s
[2K
| Adam | epoch: 012 | loss: 0.14430 - acc: 0.9523 -- iter: 064/244
[A[ATraining Step: 91  | total loss: [1m[32m0.13384[0m[0m | time: 30.558s
[2K
| Adam | epoch: 012 | loss: 0.13384 - acc: 0.9571 -- iter: 096/244
[A[ATraining Step: 92  | total loss: [1m[32m0.13016[0m[0m | time: 42.880s
[2K
| Adam | epoch: 012 | loss: 0.13016 - acc: 0.9552 -- iter: 128/244
[A[ATraining Step: 93  | total loss: [1m[32m0.12630[0m[0m | time: 53.774s
[2K
| Adam | epoch: 012 | loss: 0.12630 - acc: 0.9565 -- iter: 160/244
[A[ATraining Step: 94  | total loss: [1m[32m0.13738[0m[0m | time: 62.541s
[2K
| Adam | epoch: 012 | loss: 0.13738 - acc: 0.9546 -- iter: 192/244
[A[ATraining Step: 95  | total loss: [1m[32m0.13093[0m[0m | time: 71.110s
[2K
| Adam | epoch: 012 | loss: 0.13093 - acc: 0.9591 -- iter: 224/244
[A[ATraining Step: 96  | total loss: [1m[32m0.12236[0m[0m | time: 89.337s
[2K
| Adam | epoch: 012 | loss: 0.12236 - acc: 0.9632 | val_loss: 1.31237 - val_acc: 0.6883 -- iter: 244/244
--
Training Step: 97  | total loss: [1m[32m0.12481[0m[0m | time: 12.839s
[2K
| Adam | epoch: 013 | loss: 0.12481 - acc: 0.9607 -- iter: 032/244
[A[ATraining Step: 98  | total loss: [1m[32m0.12277[0m[0m | time: 21.895s
[2K
| Adam | epoch: 013 | loss: 0.12277 - acc: 0.9646 -- iter: 064/244
[A[ATraining Step: 99  | total loss: [1m[32m0.11697[0m[0m | time: 30.492s
[2K
| Adam | epoch: 013 | loss: 0.11697 - acc: 0.9681 -- iter: 096/244
[A[ATraining Step: 100  | total loss: [1m[32m0.10908[0m[0m | time: 81.897s
[2K
| Adam | epoch: 013 | loss: 0.10908 - acc: 0.9713 -- iter: 128/244
[A[ATraining Step: 101  | total loss: [1m[32m0.11557[0m[0m | time: 116.534s
[2K
| Adam | epoch: 013 | loss: 0.11557 - acc: 0.9679 -- iter: 160/244
[A[ATraining Step: 102  | total loss: [1m[32m0.10706[0m[0m | time: 128.192s
[2K
| Adam | epoch: 013 | loss: 0.10706 - acc: 0.9711 -- iter: 192/244
[A[ATraining Step: 103  | total loss: [1m[32m0.11660[0m[0m | time: 136.938s
[2K
| Adam | epoch: 013 | loss: 0.11660 - acc: 0.9709 -- iter: 224/244
[A[ATraining Step: 104  | total loss: [1m[32m0.10878[0m[0m | time: 150.435s
[2K
| Adam | epoch: 013 | loss: 0.10878 - acc: 0.9707 | val_loss: 0.50430 - val_acc: 0.8312 -- iter: 244/244
--
Training Step: 105  | total loss: [1m[32m0.10284[0m[0m | time: 22.726s
[2K
| Adam | epoch: 014 | loss: 0.10284 - acc: 0.9705 -- iter: 032/244
[A[ATraining Step: 106  | total loss: [1m[32m0.10848[0m[0m | time: 42.667s
[2K
| Adam | epoch: 014 | loss: 0.10848 - acc: 0.9703 -- iter: 064/244
[A[ATraining Step: 107  | total loss: [1m[32m0.11254[0m[0m | time: 51.344s
[2K
| Adam | epoch: 014 | loss: 0.11254 - acc: 0.9670 -- iter: 096/244
[A[ATraining Step: 108  | total loss: [1m[32m0.10923[0m[0m | time: 59.916s
[2K
| Adam | epoch: 014 | loss: 0.10923 - acc: 0.9653 -- iter: 128/244
[A[ATraining Step: 109  | total loss: [1m[32m0.09901[0m[0m | time: 72.295s
[2K
| Adam | epoch: 014 | loss: 0.09901 - acc: 0.9688 -- iter: 160/244
[A[ATraining Step: 110  | total loss: [1m[32m0.09841[0m[0m | time: 80.821s
[2K
| Adam | epoch: 014 | loss: 0.09841 - acc: 0.9688 -- iter: 192/244
[A[ATraining Step: 111  | total loss: [1m[32m0.09756[0m[0m | time: 89.740s
[2K
| Adam | epoch: 014 | loss: 0.09756 - acc: 0.9688 -- iter: 224/244
[A[ATraining Step: 112  | total loss: [1m[32m0.08919[0m[0m | time: 107.069s
[2K
| Adam | epoch: 014 | loss: 0.08919 - acc: 0.9719 | val_loss: 1.79792 - val_acc: 0.6494 -- iter: 244/244
--
Training Step: 113  | total loss: [1m[32m0.09307[0m[0m | time: 13.419s
[2K
| Adam | epoch: 015 | loss: 0.09307 - acc: 0.9685 -- iter: 032/244
[A[ATraining Step: 114  | total loss: [1m[32m0.08534[0m[0m | time: 26.545s
[2K
| Adam | epoch: 015 | loss: 0.08534 - acc: 0.9716 -- iter: 064/244
[A[ATraining Step: 115  | total loss: [1m[32m0.08007[0m[0m | time: 42.927s
[2K
| Adam | epoch: 015 | loss: 0.08007 - acc: 0.9713 -- iter: 096/244
[A[ATraining Step: 116  | total loss: [1m[32m0.07354[0m[0m | time: 52.006s
[2K
| Adam | epoch: 015 | loss: 0.07354 - acc: 0.9742 -- iter: 128/244
[A[ATraining Step: 117  | total loss: [1m[32m0.06811[0m[0m | time: 59.941s
[2K
| Adam | epoch: 015 | loss: 0.06811 - acc: 0.9768 -- iter: 160/244
[A[ATraining Step: 118  | total loss: [1m[32m0.06327[0m[0m | time: 68.977s
[2K
| Adam | epoch: 015 | loss: 0.06327 - acc: 0.9791 -- iter: 192/244
[A[ATraining Step: 119  | total loss: [1m[32m0.06106[0m[0m | time: 77.627s
[2K
| Adam | epoch: 015 | loss: 0.06106 - acc: 0.9781 -- iter: 224/244
[A[ATraining Step: 120  | total loss: [1m[32m0.05813[0m[0m | time: 98.856s
[2K
| Adam | epoch: 015 | loss: 0.05813 - acc: 0.9803 | val_loss: 0.69210 - val_acc: 0.7662 -- iter: 244/244
--
Validation AUC:0.8708333333333333
Validation AUPRC:0.9140757737198486
Test AUC:0.9414600550964187
Test AUPRC:0.9671990537734096
BestTestF1Score	0.89	0.77	0.88	0.93	0.86	38	3	30	6	0.38
BestTestMCCScore	0.83	0.71	0.83	1.0	0.7	31	0	33	13	0.97
BestTestAccuracyScore	0.84	0.73	0.84	1.0	0.73	32	0	33	12	0.91
BestValidationF1Score	0.84	0.57	0.79	0.77	0.91	41	12	20	4	0.38
BestValidationMCC	0.79	0.62	0.79	0.94	0.69	31	2	30	14	0.97
BestValidationAccuracy	0.82	0.62	0.81	0.89	0.76	34	4	28	11	0.91
TestPredictions (Threshold:0.97)
CHEMBL341866,TN,INACT,0.029999999329447746	CHEMBL31954,TN,INACT,0.009999999776482582	CHEMBL8068,TN,INACT,0.0	CHEMBL3823913,TN,INACT,0.009999999776482582	CHEMBL604271,TP,ACT,1.0	CHEMBL2387436,TN,INACT,0.33000001311302185	CHEMBL28597,TN,INACT,0.0	CHEMBL308199,TP,ACT,1.0	CHEMBL337770,TP,ACT,1.0	CHEMBL504118,TP,ACT,1.0	CHEMBL1090703,TN,INACT,0.07000000029802322	CHEMBL1940056,TN,INACT,0.0	CHEMBL3617181,TN,INACT,0.009999999776482582	CHEMBL488080,TP,ACT,1.0	CHEMBL90059,TN,INACT,0.25999999046325684	CHEMBL342008,TP,ACT,1.0	CHEMBL2381188,TN,INACT,0.15000000596046448	CHEMBL1779440,TN,INACT,0.029999999329447746	CHEMBL2030210,FN,ACT,0.029999999329447746	CHEMBL471701,TP,ACT,1.0	CHEMBL18965,FN,ACT,0.15000000596046448	CHEMBL3403355,TN,INACT,0.4699999988079071	CHEMBL284745,TP,ACT,1.0	CHEMBL596489,TP,ACT,1.0	CHEMBL185108,TN,INACT,0.029999999329447746	CHEMBL596454,TP,ACT,1.0	CHEMBL140874,TP,ACT,1.0	CHEMBL419447,TP,ACT,1.0	CHEMBL285913,FN,ACT,0.05999999865889549	CHEMBL513593,FN,ACT,0.9399999976158142	CHEMBL423550,TP,ACT,1.0	CHEMBL429476,TP,ACT,1.0	CHEMBL28240,TN,INACT,0.0	CHEMBL3356649,TN,INACT,0.0	CHEMBL3822479,TN,INACT,0.009999999776482582	CHEMBL303671,TP,ACT,1.0	CHEMBL344630,TP,ACT,1.0	CHEMBL356323,TN,INACT,0.11999999731779099	CHEMBL369431,TN,INACT,0.019999999552965164	CHEMBL344852,TP,ACT,1.0	CHEMBL366491,TN,INACT,0.019999999552965164	CHEMBL248087,TP,ACT,0.9900000095367432	CHEMBL514277,TN,INACT,0.17000000178813934	CHEMBL343973,TP,ACT,1.0	CHEMBL1095583,TN,INACT,0.4000000059604645	CHEMBL305989,FN,ACT,0.7200000286102295	CHEMBL19046,FN,ACT,0.7200000286102295	CHEMBL3822740,TN,INACT,0.009999999776482582	CHEMBL141703,TP,ACT,1.0	CHEMBL68152,TP,ACT,0.9900000095367432	CHEMBL470310,FN,ACT,0.7699999809265137	CHEMBL2331810,TN,INACT,0.0	CHEMBL164253,TN,INACT,0.009999999776482582	CHEMBL2041589,TN,INACT,0.0	CHEMBL138256,TP,ACT,1.0	CHEMBL343325,TP,ACT,1.0	CHEMBL3617182,TN,INACT,0.009999999776482582	CHEMBL553934,TN,INACT,0.14000000059604645	CHEMBL141975,TP,ACT,1.0	CHEMBL306389,TN,INACT,0.09000000357627869	CHEMBL2030216,TP,ACT,1.0	CHEMBL140599,TP,ACT,1.0	CHEMBL473301,FN,ACT,0.6100000143051147	CHEMBL3823102,TN,INACT,0.0	CHEMBL313463,TN,INACT,0.029999999329447746	CHEMBL303920,TP,ACT,0.9800000190734863	CHEMBL3823779,TN,INACT,0.0	CHEMBL521075,TP,ACT,1.0	CHEMBL2030202,FN,ACT,0.38999998569488525	CHEMBL137400,FN,ACT,0.019999999552965164	CHEMBL397116,TP,ACT,1.0	CHEMBL2387437,TN,INACT,0.6000000238418579	CHEMBL28676,FN,ACT,0.1899999976158142	CHEMBL192,FN,ACT,0.8399999737739563	CHEMBL189,FN,ACT,0.0	CHEMBL2022219,TP,ACT,1.0	CHEMBL18964,TP,ACT,0.9800000190734863	

