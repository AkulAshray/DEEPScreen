CNNModel CHEMBL1075232 adam 0.0005 15 32 0 0.6 False True
Number of active compounds :	361
Number of inactive compounds :	361
---------------------------------
Run id: CNNModel_CHEMBL1075232_adam_0.0005_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL1075232_adam_0.0005_15_32_0.6_True/
---------------------------------
Training samples: 421
Validation samples: 132
--
Training Step: 1  | time: 2.533s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 032/421
[A[ATraining Step: 2  | total loss: [1m[32m0.62504[0m[0m | time: 3.500s
[2K
| Adam | epoch: 001 | loss: 0.62504 - acc: 0.2250 -- iter: 064/421
[A[ATraining Step: 3  | total loss: [1m[32m0.68097[0m[0m | time: 4.454s
[2K
| Adam | epoch: 001 | loss: 0.68097 - acc: 0.4244 -- iter: 096/421
[A[ATraining Step: 4  | total loss: [1m[32m0.68758[0m[0m | time: 5.450s
[2K
| Adam | epoch: 001 | loss: 0.68758 - acc: 0.5749 -- iter: 128/421
[A[ATraining Step: 5  | total loss: [1m[32m0.68758[0m[0m | time: 6.535s
[2K
| Adam | epoch: 001 | loss: 0.68758 - acc: 0.5879 -- iter: 160/421
[A[ATraining Step: 6  | total loss: [1m[32m0.69194[0m[0m | time: 7.585s
[2K
| Adam | epoch: 001 | loss: 0.69194 - acc: 0.5314 -- iter: 192/421
[A[ATraining Step: 7  | total loss: [1m[32m0.69736[0m[0m | time: 8.407s
[2K
| Adam | epoch: 001 | loss: 0.69736 - acc: 0.4938 -- iter: 224/421
[A[ATraining Step: 8  | total loss: [1m[32m0.68860[0m[0m | time: 9.686s
[2K
| Adam | epoch: 001 | loss: 0.68860 - acc: 0.5500 -- iter: 256/421
[A[ATraining Step: 9  | total loss: [1m[32m0.71231[0m[0m | time: 10.987s
[2K
| Adam | epoch: 001 | loss: 0.71231 - acc: 0.4077 -- iter: 288/421
[A[ATraining Step: 10  | total loss: [1m[32m0.69831[0m[0m | time: 12.194s
[2K
| Adam | epoch: 001 | loss: 0.69831 - acc: 0.5007 -- iter: 320/421
[A[ATraining Step: 11  | total loss: [1m[32m0.70221[0m[0m | time: 17.421s
[2K
| Adam | epoch: 001 | loss: 0.70221 - acc: 0.4412 -- iter: 352/421
[A[ATraining Step: 12  | total loss: [1m[32m0.69638[0m[0m | time: 18.310s
[2K
| Adam | epoch: 001 | loss: 0.69638 - acc: 0.4958 -- iter: 384/421
[A[ATraining Step: 13  | total loss: [1m[32m0.69157[0m[0m | time: 19.304s
[2K
| Adam | epoch: 001 | loss: 0.69157 - acc: 0.5645 -- iter: 416/421
[A[ATraining Step: 14  | total loss: [1m[32m0.69298[0m[0m | time: 20.604s
[2K
| Adam | epoch: 001 | loss: 0.69298 - acc: 0.5254 | val_loss: 0.68977 - val_acc: 0.5909 -- iter: 421/421
--
Training Step: 15  | total loss: [1m[32m0.69201[0m[0m | time: 0.275s
[2K
| Adam | epoch: 002 | loss: 0.69201 - acc: 0.5546 -- iter: 032/421
[A[ATraining Step: 16  | total loss: [1m[32m0.69121[0m[0m | time: 1.284s
[2K
| Adam | epoch: 002 | loss: 0.69121 - acc: 0.5716 -- iter: 064/421
[A[ATraining Step: 17  | total loss: [1m[32m0.69235[0m[0m | time: 2.285s
[2K
| Adam | epoch: 002 | loss: 0.69235 - acc: 0.5346 -- iter: 096/421
[A[ATraining Step: 18  | total loss: [1m[32m0.69262[0m[0m | time: 3.222s
[2K
| Adam | epoch: 002 | loss: 0.69262 - acc: 0.5226 -- iter: 128/421
[A[ATraining Step: 19  | total loss: [1m[32m0.69237[0m[0m | time: 4.291s
[2K
| Adam | epoch: 002 | loss: 0.69237 - acc: 0.5255 -- iter: 160/421
[A[ATraining Step: 20  | total loss: [1m[32m0.69296[0m[0m | time: 5.244s
[2K
| Adam | epoch: 002 | loss: 0.69296 - acc: 0.5073 -- iter: 192/421
[A[ATraining Step: 21  | total loss: [1m[32m0.69261[0m[0m | time: 6.204s
[2K
| Adam | epoch: 002 | loss: 0.69261 - acc: 0.5147 -- iter: 224/421
[A[ATraining Step: 22  | total loss: [1m[32m0.69211[0m[0m | time: 7.519s
[2K
| Adam | epoch: 002 | loss: 0.69211 - acc: 0.5290 -- iter: 256/421
[A[ATraining Step: 23  | total loss: [1m[32m0.69154[0m[0m | time: 8.743s
[2K
| Adam | epoch: 002 | loss: 0.69154 - acc: 0.5478 -- iter: 288/421
[A[ATraining Step: 24  | total loss: [1m[32m0.69192[0m[0m | time: 9.590s
[2K
| Adam | epoch: 002 | loss: 0.69192 - acc: 0.5344 -- iter: 320/421
[A[ATraining Step: 25  | total loss: [1m[32m0.69249[0m[0m | time: 10.542s
[2K
| Adam | epoch: 002 | loss: 0.69249 - acc: 0.5165 -- iter: 352/421
[A[ATraining Step: 26  | total loss: [1m[32m0.69070[0m[0m | time: 11.492s
[2K
| Adam | epoch: 002 | loss: 0.69070 - acc: 0.5617 -- iter: 384/421
[A[ATraining Step: 27  | total loss: [1m[32m0.69230[0m[0m | time: 12.573s
[2K
| Adam | epoch: 002 | loss: 0.69230 - acc: 0.5218 -- iter: 416/421
[A[ATraining Step: 28  | total loss: [1m[32m0.69206[0m[0m | time: 14.404s
[2K
| Adam | epoch: 002 | loss: 0.69206 - acc: 0.5241 | val_loss: 0.68854 - val_acc: 0.5909 -- iter: 421/421
--
Training Step: 29  | total loss: [1m[32m0.69226[0m[0m | time: 0.207s
[2K
| Adam | epoch: 003 | loss: 0.69226 - acc: 0.5183 -- iter: 032/421
[A[ATraining Step: 30  | total loss: [1m[32m0.69115[0m[0m | time: 0.738s
[2K
| Adam | epoch: 003 | loss: 0.69115 - acc: 0.5376 -- iter: 064/421
[A[ATraining Step: 31  | total loss: [1m[32m0.69048[0m[0m | time: 1.616s
[2K
| Adam | epoch: 003 | loss: 0.69048 - acc: 0.5520 -- iter: 096/421
[A[ATraining Step: 32  | total loss: [1m[32m0.69094[0m[0m | time: 2.523s
[2K
| Adam | epoch: 003 | loss: 0.69094 - acc: 0.5403 -- iter: 128/421
[A[ATraining Step: 33  | total loss: [1m[32m0.69008[0m[0m | time: 3.514s
[2K
| Adam | epoch: 003 | loss: 0.69008 - acc: 0.5520 -- iter: 160/421
[A[ATraining Step: 34  | total loss: [1m[32m0.69109[0m[0m | time: 4.538s
[2K
| Adam | epoch: 003 | loss: 0.69109 - acc: 0.5342 -- iter: 192/421
[A[ATraining Step: 35  | total loss: [1m[32m0.69045[0m[0m | time: 5.601s
[2K
| Adam | epoch: 003 | loss: 0.69045 - acc: 0.5401 -- iter: 224/421
[A[ATraining Step: 36  | total loss: [1m[32m0.68959[0m[0m | time: 6.662s
[2K
| Adam | epoch: 003 | loss: 0.68959 - acc: 0.5447 -- iter: 256/421
[A[ATraining Step: 37  | total loss: [1m[32m0.68691[0m[0m | time: 7.554s
[2K
| Adam | epoch: 003 | loss: 0.68691 - acc: 0.5670 -- iter: 288/421
[A[ATraining Step: 38  | total loss: [1m[32m0.68871[0m[0m | time: 8.804s
[2K
| Adam | epoch: 003 | loss: 0.68871 - acc: 0.5478 -- iter: 320/421
[A[ATraining Step: 39  | total loss: [1m[32m0.68886[0m[0m | time: 10.151s
[2K
| Adam | epoch: 003 | loss: 0.68886 - acc: 0.5446 -- iter: 352/421
[A[ATraining Step: 40  | total loss: [1m[32m0.69283[0m[0m | time: 11.207s
[2K
| Adam | epoch: 003 | loss: 0.69283 - acc: 0.5128 -- iter: 384/421
[A[ATraining Step: 41  | total loss: [1m[32m0.68958[0m[0m | time: 20.886s
[2K
| Adam | epoch: 003 | loss: 0.68958 - acc: 0.5334 -- iter: 416/421
[A[ATraining Step: 42  | total loss: [1m[32m0.69067[0m[0m | time: 26.338s
[2K
| Adam | epoch: 003 | loss: 0.69067 - acc: 0.5218 | val_loss: 0.68088 - val_acc: 0.5909 -- iter: 421/421
--
Training Step: 43  | total loss: [1m[32m0.69148[0m[0m | time: 1.039s
[2K
| Adam | epoch: 004 | loss: 0.69148 - acc: 0.5069 -- iter: 032/421
[A[ATraining Step: 44  | total loss: [1m[32m0.69209[0m[0m | time: 1.322s
[2K
| Adam | epoch: 004 | loss: 0.69209 - acc: 0.4949 -- iter: 064/421
[A[ATraining Step: 45  | total loss: [1m[32m0.68973[0m[0m | time: 1.578s
[2K
| Adam | epoch: 004 | loss: 0.68973 - acc: 0.5127 -- iter: 096/421
[A[ATraining Step: 46  | total loss: [1m[32m0.68724[0m[0m | time: 2.461s
[2K
| Adam | epoch: 004 | loss: 0.68724 - acc: 0.5273 -- iter: 128/421
[A[ATraining Step: 47  | total loss: [1m[32m0.68325[0m[0m | time: 3.079s
[2K
| Adam | epoch: 004 | loss: 0.68325 - acc: 0.5586 -- iter: 160/421
[A[ATraining Step: 48  | total loss: [1m[32m0.67845[0m[0m | time: 3.690s
[2K
| Adam | epoch: 004 | loss: 0.67845 - acc: 0.5793 -- iter: 192/421
[A[ATraining Step: 49  | total loss: [1m[32m0.67896[0m[0m | time: 4.330s
[2K
| Adam | epoch: 004 | loss: 0.67896 - acc: 0.5717 -- iter: 224/421
[A[ATraining Step: 50  | total loss: [1m[32m0.67762[0m[0m | time: 4.936s
[2K
| Adam | epoch: 004 | loss: 0.67762 - acc: 0.5703 -- iter: 256/421
[A[ATraining Step: 51  | total loss: [1m[32m0.67916[0m[0m | time: 5.535s
[2K
| Adam | epoch: 004 | loss: 0.67916 - acc: 0.5643 -- iter: 288/421
[A[ATraining Step: 52  | total loss: [1m[32m0.67122[0m[0m | time: 6.161s
[2K
| Adam | epoch: 004 | loss: 0.67122 - acc: 0.5781 -- iter: 320/421
[A[ATraining Step: 53  | total loss: [1m[32m0.66620[0m[0m | time: 6.786s
[2K
| Adam | epoch: 004 | loss: 0.66620 - acc: 0.5850 -- iter: 352/421
[A[ATraining Step: 54  | total loss: [1m[32m0.68661[0m[0m | time: 7.439s
[2K
| Adam | epoch: 004 | loss: 0.68661 - acc: 0.5546 -- iter: 384/421
[A[ATraining Step: 55  | total loss: [1m[32m0.70079[0m[0m | time: 8.044s
[2K
| Adam | epoch: 004 | loss: 0.70079 - acc: 0.5200 -- iter: 416/421
[A[ATraining Step: 56  | total loss: [1m[32m0.70088[0m[0m | time: 9.660s
[2K
| Adam | epoch: 004 | loss: 0.70088 - acc: 0.5040 | val_loss: 0.67856 - val_acc: 0.5909 -- iter: 421/421
--
Training Step: 57  | total loss: [1m[32m0.69695[0m[0m | time: 0.679s
[2K
| Adam | epoch: 005 | loss: 0.69695 - acc: 0.5121 -- iter: 032/421
[A[ATraining Step: 58  | total loss: [1m[32m0.69439[0m[0m | time: 1.292s
[2K
| Adam | epoch: 005 | loss: 0.69439 - acc: 0.5190 -- iter: 064/421
[A[ATraining Step: 59  | total loss: [1m[32m0.69297[0m[0m | time: 1.426s
[2K
| Adam | epoch: 005 | loss: 0.69297 - acc: 0.5206 -- iter: 096/421
[A[ATraining Step: 60  | total loss: [1m[32m0.69161[0m[0m | time: 1.569s
[2K
| Adam | epoch: 005 | loss: 0.69161 - acc: 0.5311 -- iter: 128/421
[A[ATraining Step: 61  | total loss: [1m[32m0.69024[0m[0m | time: 2.170s
[2K
| Adam | epoch: 005 | loss: 0.69024 - acc: 0.5401 -- iter: 160/421
[A[ATraining Step: 62  | total loss: [1m[32m0.69047[0m[0m | time: 2.786s
[2K
| Adam | epoch: 005 | loss: 0.69047 - acc: 0.5108 -- iter: 192/421
[A[ATraining Step: 63  | total loss: [1m[32m0.68980[0m[0m | time: 3.402s
[2K
| Adam | epoch: 005 | loss: 0.68980 - acc: 0.5055 -- iter: 224/421
[A[ATraining Step: 64  | total loss: [1m[32m0.68853[0m[0m | time: 4.026s
[2K
| Adam | epoch: 005 | loss: 0.68853 - acc: 0.5243 -- iter: 256/421
[A[ATraining Step: 65  | total loss: [1m[32m0.68754[0m[0m | time: 4.629s
[2K
| Adam | epoch: 005 | loss: 0.68754 - acc: 0.5522 -- iter: 288/421
[A[ATraining Step: 66  | total loss: [1m[32m0.68632[0m[0m | time: 5.243s
[2K
| Adam | epoch: 005 | loss: 0.68632 - acc: 0.5724 -- iter: 320/421
[A[ATraining Step: 67  | total loss: [1m[32m0.68606[0m[0m | time: 5.879s
[2K
| Adam | epoch: 005 | loss: 0.68606 - acc: 0.5862 -- iter: 352/421
[A[ATraining Step: 68  | total loss: [1m[32m0.68437[0m[0m | time: 6.485s
[2K
| Adam | epoch: 005 | loss: 0.68437 - acc: 0.5871 -- iter: 384/421
[A[ATraining Step: 69  | total loss: [1m[32m0.68219[0m[0m | time: 7.096s
[2K
| Adam | epoch: 005 | loss: 0.68219 - acc: 0.5989 -- iter: 416/421
[A[ATraining Step: 70  | total loss: [1m[32m0.68078[0m[0m | time: 8.746s
[2K
| Adam | epoch: 005 | loss: 0.68078 - acc: 0.6055 | val_loss: 0.65624 - val_acc: 0.6818 -- iter: 421/421
--
Training Step: 71  | total loss: [1m[32m0.67725[0m[0m | time: 0.624s
[2K
| Adam | epoch: 006 | loss: 0.67725 - acc: 0.6219 -- iter: 032/421
[A[ATraining Step: 72  | total loss: [1m[32m0.67713[0m[0m | time: 1.263s
[2K
| Adam | epoch: 006 | loss: 0.67713 - acc: 0.6047 -- iter: 064/421
[A[ATraining Step: 73  | total loss: [1m[32m0.67664[0m[0m | time: 1.923s
[2K
| Adam | epoch: 006 | loss: 0.67664 - acc: 0.6139 -- iter: 096/421
[A[ATraining Step: 74  | total loss: [1m[32m0.66829[0m[0m | time: 2.050s
[2K
| Adam | epoch: 006 | loss: 0.66829 - acc: 0.6494 -- iter: 128/421
[A[ATraining Step: 75  | total loss: [1m[32m0.66417[0m[0m | time: 2.194s
[2K
| Adam | epoch: 006 | loss: 0.66417 - acc: 0.6441 -- iter: 160/421
[A[ATraining Step: 76  | total loss: [1m[32m0.65627[0m[0m | time: 2.810s
[2K
| Adam | epoch: 006 | loss: 0.65627 - acc: 0.6608 -- iter: 192/421
[A[ATraining Step: 77  | total loss: [1m[32m0.64589[0m[0m | time: 3.423s
[2K
| Adam | epoch: 006 | loss: 0.64589 - acc: 0.6669 -- iter: 224/421
[A[ATraining Step: 78  | total loss: [1m[32m0.64061[0m[0m | time: 4.054s
[2K
| Adam | epoch: 006 | loss: 0.64061 - acc: 0.6658 -- iter: 256/421
[A[ATraining Step: 79  | total loss: [1m[32m0.63988[0m[0m | time: 4.667s
[2K
| Adam | epoch: 006 | loss: 0.63988 - acc: 0.6616 -- iter: 288/421
[A[ATraining Step: 80  | total loss: [1m[32m0.63433[0m[0m | time: 5.311s
[2K
| Adam | epoch: 006 | loss: 0.63433 - acc: 0.6610 -- iter: 320/421
[A[ATraining Step: 81  | total loss: [1m[32m0.63346[0m[0m | time: 6.326s
[2K
| Adam | epoch: 006 | loss: 0.63346 - acc: 0.6669 -- iter: 352/421
[A[ATraining Step: 82  | total loss: [1m[32m0.62214[0m[0m | time: 7.635s
[2K
| Adam | epoch: 006 | loss: 0.62214 - acc: 0.6783 -- iter: 384/421
[A[ATraining Step: 83  | total loss: [1m[32m0.62049[0m[0m | time: 8.961s
[2K
| Adam | epoch: 006 | loss: 0.62049 - acc: 0.6699 -- iter: 416/421
[A[ATraining Step: 84  | total loss: [1m[32m0.61530[0m[0m | time: 13.393s
[2K
| Adam | epoch: 006 | loss: 0.61530 - acc: 0.6685 | val_loss: 0.62889 - val_acc: 0.6288 -- iter: 421/421
--
Training Step: 85  | total loss: [1m[32m0.59735[0m[0m | time: 1.140s
[2K
| Adam | epoch: 007 | loss: 0.59735 - acc: 0.6860 -- iter: 032/421
[A[ATraining Step: 86  | total loss: [1m[32m0.59296[0m[0m | time: 2.112s
[2K
| Adam | epoch: 007 | loss: 0.59296 - acc: 0.6893 -- iter: 064/421
[A[ATraining Step: 87  | total loss: [1m[32m0.59492[0m[0m | time: 3.428s
[2K
| Adam | epoch: 007 | loss: 0.59492 - acc: 0.6860 -- iter: 096/421
[A[ATraining Step: 88  | total loss: [1m[32m0.58442[0m[0m | time: 4.712s
[2K
| Adam | epoch: 007 | loss: 0.58442 - acc: 0.6893 -- iter: 128/421
[A[ATraining Step: 89  | total loss: [1m[32m0.57456[0m[0m | time: 5.031s
[2K
| Adam | epoch: 007 | loss: 0.57456 - acc: 0.6922 -- iter: 160/421
[A[ATraining Step: 90  | total loss: [1m[32m0.53323[0m[0m | time: 5.258s
[2K
| Adam | epoch: 007 | loss: 0.53323 - acc: 0.7230 -- iter: 192/421
[A[ATraining Step: 91  | total loss: [1m[32m0.49187[0m[0m | time: 16.329s
[2K
| Adam | epoch: 007 | loss: 0.49187 - acc: 0.7507 -- iter: 224/421
[A[ATraining Step: 92  | total loss: [1m[32m0.48221[0m[0m | time: 17.185s
[2K
| Adam | epoch: 007 | loss: 0.48221 - acc: 0.7506 -- iter: 256/421
[A[ATraining Step: 93  | total loss: [1m[32m0.48261[0m[0m | time: 18.145s
[2K
| Adam | epoch: 007 | loss: 0.48261 - acc: 0.7568 -- iter: 288/421
[A[ATraining Step: 94  | total loss: [1m[32m0.47555[0m[0m | time: 19.091s
[2K
| Adam | epoch: 007 | loss: 0.47555 - acc: 0.7593 -- iter: 320/421
[A[ATraining Step: 95  | total loss: [1m[32m0.48203[0m[0m | time: 20.149s
[2K
| Adam | epoch: 007 | loss: 0.48203 - acc: 0.7521 -- iter: 352/421
[A[ATraining Step: 96  | total loss: [1m[32m0.47554[0m[0m | time: 21.171s
[2K
| Adam | epoch: 007 | loss: 0.47554 - acc: 0.7519 -- iter: 384/421
[A[ATraining Step: 97  | total loss: [1m[32m0.44796[0m[0m | time: 22.088s
[2K
| Adam | epoch: 007 | loss: 0.44796 - acc: 0.7673 -- iter: 416/421
[A[ATraining Step: 98  | total loss: [1m[32m0.45184[0m[0m | time: 24.191s
[2K
| Adam | epoch: 007 | loss: 0.45184 - acc: 0.7687 | val_loss: 0.44623 - val_acc: 0.8182 -- iter: 421/421
--
Training Step: 99  | total loss: [1m[32m0.44154[0m[0m | time: 11.832s
[2K
| Adam | epoch: 008 | loss: 0.44154 - acc: 0.7793 -- iter: 032/421
[A[ATraining Step: 100  | total loss: [1m[32m0.43556[0m[0m | time: 12.840s
[2K
| Adam | epoch: 008 | loss: 0.43556 - acc: 0.7795 -- iter: 064/421
[A[ATraining Step: 101  | total loss: [1m[32m0.43503[0m[0m | time: 13.759s
[2K
| Adam | epoch: 008 | loss: 0.43503 - acc: 0.7828 -- iter: 096/421
[A[ATraining Step: 102  | total loss: [1m[32m0.43314[0m[0m | time: 14.712s
[2K
| Adam | epoch: 008 | loss: 0.43314 - acc: 0.7889 -- iter: 128/421
[A[ATraining Step: 103  | total loss: [1m[32m0.42925[0m[0m | time: 15.729s
[2K
| Adam | epoch: 008 | loss: 0.42925 - acc: 0.7913 -- iter: 160/421
[A[ATraining Step: 104  | total loss: [1m[32m0.41895[0m[0m | time: 15.967s
[2K
| Adam | epoch: 008 | loss: 0.41895 - acc: 0.7996 -- iter: 192/421
[A[ATraining Step: 105  | total loss: [1m[32m0.42050[0m[0m | time: 16.202s
[2K
| Adam | epoch: 008 | loss: 0.42050 - acc: 0.7997 -- iter: 224/421
[A[ATraining Step: 106  | total loss: [1m[32m0.42079[0m[0m | time: 17.240s
[2K
| Adam | epoch: 008 | loss: 0.42079 - acc: 0.7997 -- iter: 256/421
[A[ATraining Step: 107  | total loss: [1m[32m0.40621[0m[0m | time: 18.096s
[2K
| Adam | epoch: 008 | loss: 0.40621 - acc: 0.8072 -- iter: 288/421
[A[ATraining Step: 108  | total loss: [1m[32m0.40234[0m[0m | time: 19.311s
[2K
| Adam | epoch: 008 | loss: 0.40234 - acc: 0.8078 -- iter: 320/421
[A[ATraining Step: 109  | total loss: [1m[32m0.39684[0m[0m | time: 20.724s
[2K
| Adam | epoch: 008 | loss: 0.39684 - acc: 0.8114 -- iter: 352/421
[A[ATraining Step: 110  | total loss: [1m[32m0.39943[0m[0m | time: 21.833s
[2K
| Adam | epoch: 008 | loss: 0.39943 - acc: 0.8052 -- iter: 384/421
[A[ATraining Step: 111  | total loss: [1m[32m0.40912[0m[0m | time: 23.861s
[2K
| Adam | epoch: 008 | loss: 0.40912 - acc: 0.7935 -- iter: 416/421
[A[ATraining Step: 112  | total loss: [1m[32m0.39897[0m[0m | time: 25.717s
[2K
| Adam | epoch: 008 | loss: 0.39897 - acc: 0.8079 | val_loss: 0.46034 - val_acc: 0.7879 -- iter: 421/421
--
Training Step: 113  | total loss: [1m[32m0.39381[0m[0m | time: 1.272s
[2K
| Adam | epoch: 009 | loss: 0.39381 - acc: 0.8114 -- iter: 032/421
[A[ATraining Step: 114  | total loss: [1m[32m0.37938[0m[0m | time: 2.583s
[2K
| Adam | epoch: 009 | loss: 0.37938 - acc: 0.8209 -- iter: 064/421
[A[ATraining Step: 115  | total loss: [1m[32m0.36269[0m[0m | time: 3.479s
[2K
| Adam | epoch: 009 | loss: 0.36269 - acc: 0.8326 -- iter: 096/421
[A[ATraining Step: 116  | total loss: [1m[32m0.35618[0m[0m | time: 4.483s
[2K
| Adam | epoch: 009 | loss: 0.35618 - acc: 0.8337 -- iter: 128/421
[A[ATraining Step: 117  | total loss: [1m[32m0.35556[0m[0m | time: 5.401s
[2K
| Adam | epoch: 009 | loss: 0.35556 - acc: 0.8316 -- iter: 160/421
[A[ATraining Step: 118  | total loss: [1m[32m0.33314[0m[0m | time: 6.472s
[2K
| Adam | epoch: 009 | loss: 0.33314 - acc: 0.8484 -- iter: 192/421
[A[ATraining Step: 119  | total loss: [1m[32m0.32728[0m[0m | time: 6.705s
[2K
| Adam | epoch: 009 | loss: 0.32728 - acc: 0.8573 -- iter: 224/421
[A[ATraining Step: 120  | total loss: [1m[32m0.32891[0m[0m | time: 6.916s
[2K
| Adam | epoch: 009 | loss: 0.32891 - acc: 0.8516 -- iter: 256/421
[A[ATraining Step: 121  | total loss: [1m[32m0.31875[0m[0m | time: 7.771s
[2K
| Adam | epoch: 009 | loss: 0.31875 - acc: 0.8664 -- iter: 288/421
[A[ATraining Step: 122  | total loss: [1m[32m0.30211[0m[0m | time: 8.999s
[2K
| Adam | epoch: 009 | loss: 0.30211 - acc: 0.8735 -- iter: 320/421
[A[ATraining Step: 123  | total loss: [1m[32m0.29858[0m[0m | time: 10.282s
[2K
| Adam | epoch: 009 | loss: 0.29858 - acc: 0.8737 -- iter: 352/421
[A[ATraining Step: 124  | total loss: [1m[32m0.28965[0m[0m | time: 11.121s
[2K
| Adam | epoch: 009 | loss: 0.28965 - acc: 0.8769 -- iter: 384/421
[A[ATraining Step: 125  | total loss: [1m[32m0.28008[0m[0m | time: 12.031s
[2K
| Adam | epoch: 009 | loss: 0.28008 - acc: 0.8799 -- iter: 416/421
[A[ATraining Step: 126  | total loss: [1m[32m0.25814[0m[0m | time: 13.997s
[2K
| Adam | epoch: 009 | loss: 0.25814 - acc: 0.8919 | val_loss: 0.44772 - val_acc: 0.7879 -- iter: 421/421
--
Training Step: 127  | total loss: [1m[32m0.24365[0m[0m | time: 3.163s
[2K
| Adam | epoch: 010 | loss: 0.24365 - acc: 0.8996 -- iter: 032/421
[A[ATraining Step: 128  | total loss: [1m[32m0.24237[0m[0m | time: 21.232s
[2K
| Adam | epoch: 010 | loss: 0.24237 - acc: 0.8971 -- iter: 064/421
[A[ATraining Step: 129  | total loss: [1m[32m0.23220[0m[0m | time: 23.258s
[2K
| Adam | epoch: 010 | loss: 0.23220 - acc: 0.9012 -- iter: 096/421
[A[ATraining Step: 130  | total loss: [1m[32m0.23363[0m[0m | time: 24.186s
[2K
| Adam | epoch: 010 | loss: 0.23363 - acc: 0.9048 -- iter: 128/421
[A[ATraining Step: 131  | total loss: [1m[32m0.24841[0m[0m | time: 25.194s
[2K
| Adam | epoch: 010 | loss: 0.24841 - acc: 0.8924 -- iter: 160/421
[A[ATraining Step: 132  | total loss: [1m[32m0.27401[0m[0m | time: 26.166s
[2K
| Adam | epoch: 010 | loss: 0.27401 - acc: 0.8782 -- iter: 192/421
[A[ATraining Step: 133  | total loss: [1m[32m0.27495[0m[0m | time: 27.278s
[2K
| Adam | epoch: 010 | loss: 0.27495 - acc: 0.8716 -- iter: 224/421
[A[ATraining Step: 134  | total loss: [1m[32m0.26341[0m[0m | time: 27.521s
[2K
| Adam | epoch: 010 | loss: 0.26341 - acc: 0.8782 -- iter: 256/421
[A[ATraining Step: 135  | total loss: [1m[32m0.24182[0m[0m | time: 27.749s
[2K
| Adam | epoch: 010 | loss: 0.24182 - acc: 0.8904 -- iter: 288/421
[A[ATraining Step: 136  | total loss: [1m[32m0.23536[0m[0m | time: 28.829s
[2K
| Adam | epoch: 010 | loss: 0.23536 - acc: 0.9014 -- iter: 320/421
[A[ATraining Step: 137  | total loss: [1m[32m0.24061[0m[0m | time: 29.818s
[2K
| Adam | epoch: 010 | loss: 0.24061 - acc: 0.8987 -- iter: 352/421
[A[ATraining Step: 138  | total loss: [1m[32m0.27380[0m[0m | time: 31.047s
[2K
| Adam | epoch: 010 | loss: 0.27380 - acc: 0.8932 -- iter: 384/421
[A[ATraining Step: 139  | total loss: [1m[32m0.25283[0m[0m | time: 32.189s
[2K
| Adam | epoch: 010 | loss: 0.25283 - acc: 0.9008 -- iter: 416/421
[A[ATraining Step: 140  | total loss: [1m[32m0.24352[0m[0m | time: 34.072s
[2K
| Adam | epoch: 010 | loss: 0.24352 - acc: 0.9044 | val_loss: 0.38199 - val_acc: 0.8712 -- iter: 421/421
--
Training Step: 141  | total loss: [1m[32m0.27436[0m[0m | time: 0.652s
[2K
| Adam | epoch: 011 | loss: 0.27436 - acc: 0.8921 -- iter: 032/421
[A[ATraining Step: 142  | total loss: [1m[32m0.25246[0m[0m | time: 1.291s
[2K
| Adam | epoch: 011 | loss: 0.25246 - acc: 0.9029 -- iter: 064/421
[A[ATraining Step: 143  | total loss: [1m[32m0.24381[0m[0m | time: 1.959s
[2K
| Adam | epoch: 011 | loss: 0.24381 - acc: 0.9032 -- iter: 096/421
[A[ATraining Step: 144  | total loss: [1m[32m0.22627[0m[0m | time: 2.590s
[2K
| Adam | epoch: 011 | loss: 0.22627 - acc: 0.9098 -- iter: 128/421
[A[ATraining Step: 145  | total loss: [1m[32m0.25080[0m[0m | time: 3.241s
[2K
| Adam | epoch: 011 | loss: 0.25080 - acc: 0.9032 -- iter: 160/421
[A[ATraining Step: 146  | total loss: [1m[32m0.23960[0m[0m | time: 3.869s
[2K
| Adam | epoch: 011 | loss: 0.23960 - acc: 0.9097 -- iter: 192/421
[A[ATraining Step: 147  | total loss: [1m[32m0.22518[0m[0m | time: 4.519s
[2K
| Adam | epoch: 011 | loss: 0.22518 - acc: 0.9156 -- iter: 224/421
[A[ATraining Step: 148  | total loss: [1m[32m0.20941[0m[0m | time: 5.223s
[2K
| Adam | epoch: 011 | loss: 0.20941 - acc: 0.9210 -- iter: 256/421
[A[ATraining Step: 149  | total loss: [1m[32m0.21497[0m[0m | time: 5.367s
[2K
| Adam | epoch: 011 | loss: 0.21497 - acc: 0.9164 -- iter: 288/421
[A[ATraining Step: 150  | total loss: [1m[32m0.19476[0m[0m | time: 5.501s
[2K
| Adam | epoch: 011 | loss: 0.19476 - acc: 0.9247 -- iter: 320/421
[A[ATraining Step: 151  | total loss: [1m[32m0.17674[0m[0m | time: 6.101s
[2K
| Adam | epoch: 011 | loss: 0.17674 - acc: 0.9323 -- iter: 352/421
[A[ATraining Step: 152  | total loss: [1m[32m0.17295[0m[0m | time: 6.735s
[2K
| Adam | epoch: 011 | loss: 0.17295 - acc: 0.9328 -- iter: 384/421
[A[ATraining Step: 153  | total loss: [1m[32m0.18312[0m[0m | time: 7.392s
[2K
| Adam | epoch: 011 | loss: 0.18312 - acc: 0.9239 -- iter: 416/421
[A[ATraining Step: 154  | total loss: [1m[32m0.17335[0m[0m | time: 9.005s
[2K
| Adam | epoch: 011 | loss: 0.17335 - acc: 0.9284 | val_loss: 0.46529 - val_acc: 0.8333 -- iter: 421/421
--
Training Step: 155  | total loss: [1m[32m0.16830[0m[0m | time: 0.630s
[2K
| Adam | epoch: 012 | loss: 0.16830 - acc: 0.9324 -- iter: 032/421
[A[ATraining Step: 156  | total loss: [1m[32m0.16730[0m[0m | time: 1.655s
[2K
| Adam | epoch: 012 | loss: 0.16730 - acc: 0.9360 -- iter: 064/421
[A[ATraining Step: 157  | total loss: [1m[32m0.16856[0m[0m | time: 2.983s
[2K
| Adam | epoch: 012 | loss: 0.16856 - acc: 0.9393 -- iter: 096/421
[A[ATraining Step: 158  | total loss: [1m[32m0.15445[0m[0m | time: 4.338s
[2K
| Adam | epoch: 012 | loss: 0.15445 - acc: 0.9454 -- iter: 128/421
[A[ATraining Step: 159  | total loss: [1m[32m0.14225[0m[0m | time: 7.072s
[2K
| Adam | epoch: 012 | loss: 0.14225 - acc: 0.9508 -- iter: 160/421
[A[ATraining Step: 160  | total loss: [1m[32m0.15156[0m[0m | time: 19.868s
[2K
| Adam | epoch: 012 | loss: 0.15156 - acc: 0.9433 -- iter: 192/421
[A[ATraining Step: 161  | total loss: [1m[32m0.14142[0m[0m | time: 20.807s
[2K
| Adam | epoch: 012 | loss: 0.14142 - acc: 0.9489 -- iter: 224/421
[A[ATraining Step: 162  | total loss: [1m[32m0.13934[0m[0m | time: 21.771s
[2K
| Adam | epoch: 012 | loss: 0.13934 - acc: 0.9509 -- iter: 256/421
[A[ATraining Step: 163  | total loss: [1m[32m0.13458[0m[0m | time: 22.749s
[2K
| Adam | epoch: 012 | loss: 0.13458 - acc: 0.9527 -- iter: 288/421
[A[ATraining Step: 164  | total loss: [1m[32m0.12634[0m[0m | time: 22.987s
[2K
| Adam | epoch: 012 | loss: 0.12634 - acc: 0.9574 -- iter: 320/421
[A[ATraining Step: 165  | total loss: [1m[32m0.11450[0m[0m | time: 23.206s
[2K
| Adam | epoch: 012 | loss: 0.11450 - acc: 0.9617 -- iter: 352/421
[A[ATraining Step: 166  | total loss: [1m[32m0.10417[0m[0m | time: 24.393s
[2K
| Adam | epoch: 012 | loss: 0.10417 - acc: 0.9655 -- iter: 384/421
[A[ATraining Step: 167  | total loss: [1m[32m0.10698[0m[0m | time: 25.355s
[2K
| Adam | epoch: 012 | loss: 0.10698 - acc: 0.9658 -- iter: 416/421
[A[ATraining Step: 168  | total loss: [1m[32m0.10251[0m[0m | time: 27.224s
[2K
| Adam | epoch: 012 | loss: 0.10251 - acc: 0.9661 | val_loss: 0.37391 - val_acc: 0.8636 -- iter: 421/421
--
Training Step: 169  | total loss: [1m[32m0.10049[0m[0m | time: 1.012s
[2K
| Adam | epoch: 013 | loss: 0.10049 - acc: 0.9633 -- iter: 032/421
[A[ATraining Step: 170  | total loss: [1m[32m0.09491[0m[0m | time: 1.987s
[2K
| Adam | epoch: 013 | loss: 0.09491 - acc: 0.9669 -- iter: 064/421
[A[ATraining Step: 171  | total loss: [1m[32m0.09772[0m[0m | time: 3.201s
[2K
| Adam | epoch: 013 | loss: 0.09772 - acc: 0.9640 -- iter: 096/421
[A[ATraining Step: 172  | total loss: [1m[32m0.09113[0m[0m | time: 4.166s
[2K
| Adam | epoch: 013 | loss: 0.09113 - acc: 0.9676 -- iter: 128/421
[A[ATraining Step: 173  | total loss: [1m[32m0.08268[0m[0m | time: 5.112s
[2K
| Adam | epoch: 013 | loss: 0.08268 - acc: 0.9708 -- iter: 160/421
[A[ATraining Step: 174  | total loss: [1m[32m0.08716[0m[0m | time: 6.467s
[2K
| Adam | epoch: 013 | loss: 0.08716 - acc: 0.9675 -- iter: 192/421
[A[ATraining Step: 175  | total loss: [1m[32m0.08553[0m[0m | time: 7.740s
[2K
| Adam | epoch: 013 | loss: 0.08553 - acc: 0.9676 -- iter: 224/421
[A[ATraining Step: 176  | total loss: [1m[32m0.08621[0m[0m | time: 9.619s
[2K
| Adam | epoch: 013 | loss: 0.08621 - acc: 0.9677 -- iter: 256/421
[A[ATraining Step: 177  | total loss: [1m[32m0.08442[0m[0m | time: 11.036s
[2K
| Adam | epoch: 013 | loss: 0.08442 - acc: 0.9647 -- iter: 288/421
[A[ATraining Step: 178  | total loss: [1m[32m0.07705[0m[0m | time: 12.036s
[2K
| Adam | epoch: 013 | loss: 0.07705 - acc: 0.9682 -- iter: 320/421
[A[ATraining Step: 179  | total loss: [1m[32m0.07457[0m[0m | time: 12.248s
[2K
| Adam | epoch: 013 | loss: 0.07457 - acc: 0.9714 -- iter: 352/421
[A[ATraining Step: 180  | total loss: [1m[32m0.06824[0m[0m | time: 12.480s
[2K
| Adam | epoch: 013 | loss: 0.06824 - acc: 0.9743 -- iter: 384/421
[A[ATraining Step: 181  | total loss: [1m[32m0.06324[0m[0m | time: 13.422s
[2K
| Adam | epoch: 013 | loss: 0.06324 - acc: 0.9769 -- iter: 416/421
[A[ATraining Step: 182  | total loss: [1m[32m0.05890[0m[0m | time: 15.440s
[2K
| Adam | epoch: 013 | loss: 0.05890 - acc: 0.9792 | val_loss: 0.39274 - val_acc: 0.8864 -- iter: 421/421
--
Training Step: 183  | total loss: [1m[32m0.06105[0m[0m | time: 1.088s
[2K
| Adam | epoch: 014 | loss: 0.06105 - acc: 0.9781 -- iter: 032/421
[A[ATraining Step: 184  | total loss: [1m[32m0.05708[0m[0m | time: 2.097s
[2K
| Adam | epoch: 014 | loss: 0.05708 - acc: 0.9803 -- iter: 064/421
[A[ATraining Step: 185  | total loss: [1m[32m0.06439[0m[0m | time: 3.118s
[2K
| Adam | epoch: 014 | loss: 0.06439 - acc: 0.9729 -- iter: 096/421
[A[ATraining Step: 186  | total loss: [1m[32m0.06040[0m[0m | time: 4.213s
[2K
| Adam | epoch: 014 | loss: 0.06040 - acc: 0.9756 -- iter: 128/421
[A[ATraining Step: 187  | total loss: [1m[32m0.06569[0m[0m | time: 5.123s
[2K
| Adam | epoch: 014 | loss: 0.06569 - acc: 0.9687 -- iter: 160/421
[A[ATraining Step: 188  | total loss: [1m[32m0.06066[0m[0m | time: 6.179s
[2K
| Adam | epoch: 014 | loss: 0.06066 - acc: 0.9718 -- iter: 192/421
[A[ATraining Step: 189  | total loss: [1m[32m0.06073[0m[0m | time: 7.688s
[2K
| Adam | epoch: 014 | loss: 0.06073 - acc: 0.9715 -- iter: 224/421
[A[ATraining Step: 190  | total loss: [1m[32m0.06830[0m[0m | time: 9.030s
[2K
| Adam | epoch: 014 | loss: 0.06830 - acc: 0.9712 -- iter: 256/421
[A[ATraining Step: 191  | total loss: [1m[32m0.06232[0m[0m | time: 16.442s
[2K
| Adam | epoch: 014 | loss: 0.06232 - acc: 0.9741 -- iter: 288/421
[A[ATraining Step: 192  | total loss: [1m[32m0.05673[0m[0m | time: 17.284s
[2K
| Adam | epoch: 014 | loss: 0.05673 - acc: 0.9767 -- iter: 320/421
[A[ATraining Step: 193  | total loss: [1m[32m0.10023[0m[0m | time: 18.293s
[2K
| Adam | epoch: 014 | loss: 0.10023 - acc: 0.9728 -- iter: 352/421
[A[ATraining Step: 194  | total loss: [1m[32m0.09384[0m[0m | time: 18.525s
[2K
| Adam | epoch: 014 | loss: 0.09384 - acc: 0.9755 -- iter: 384/421
[A[ATraining Step: 195  | total loss: [1m[32m0.08638[0m[0m | time: 18.735s
[2K
| Adam | epoch: 014 | loss: 0.08638 - acc: 0.9779 -- iter: 416/421
[A[ATraining Step: 196  | total loss: [1m[32m0.07839[0m[0m | time: 20.864s
[2K
| Adam | epoch: 014 | loss: 0.07839 - acc: 0.9802 | val_loss: 0.36609 - val_acc: 0.8788 -- iter: 421/421
--
Training Step: 197  | total loss: [1m[32m0.07333[0m[0m | time: 1.041s
[2K
| Adam | epoch: 015 | loss: 0.07333 - acc: 0.9821 -- iter: 032/421
[A[ATraining Step: 198  | total loss: [1m[32m0.06782[0m[0m | time: 2.482s
[2K
| Adam | epoch: 015 | loss: 0.06782 - acc: 0.9839 -- iter: 064/421
[A[ATraining Step: 199  | total loss: [1m[32m0.06230[0m[0m | time: 4.065s
[2K
| Adam | epoch: 015 | loss: 0.06230 - acc: 0.9855 -- iter: 096/421
[A[ATraining Step: 200  | total loss: [1m[32m0.06088[0m[0m | time: 6.234s
[2K
| Adam | epoch: 015 | loss: 0.06088 - acc: 0.9839 | val_loss: 0.33080 - val_acc: 0.8864 -- iter: 128/421
--
Training Step: 201  | total loss: [1m[32m0.05810[0m[0m | time: 7.531s
[2K
| Adam | epoch: 015 | loss: 0.05810 - acc: 0.9855 -- iter: 160/421
[A[ATraining Step: 202  | total loss: [1m[32m0.05464[0m[0m | time: 8.696s
[2K
| Adam | epoch: 015 | loss: 0.05464 - acc: 0.9869 -- iter: 192/421
[A[ATraining Step: 203  | total loss: [1m[32m0.05020[0m[0m | time: 10.173s
[2K
| Adam | epoch: 015 | loss: 0.05020 - acc: 0.9882 -- iter: 224/421
[A[ATraining Step: 204  | total loss: [1m[32m0.04591[0m[0m | time: 11.601s
[2K
| Adam | epoch: 015 | loss: 0.04591 - acc: 0.9894 -- iter: 256/421
[A[ATraining Step: 205  | total loss: [1m[32m0.04321[0m[0m | time: 12.709s
[2K
| Adam | epoch: 015 | loss: 0.04321 - acc: 0.9905 -- iter: 288/421
[A[ATraining Step: 206  | total loss: [1m[32m0.04040[0m[0m | time: 13.912s
[2K
| Adam | epoch: 015 | loss: 0.04040 - acc: 0.9914 -- iter: 320/421
[A[ATraining Step: 207  | total loss: [1m[32m0.03807[0m[0m | time: 15.149s
[2K
| Adam | epoch: 015 | loss: 0.03807 - acc: 0.9923 -- iter: 352/421
[A[ATraining Step: 208  | total loss: [1m[32m0.03489[0m[0m | time: 16.486s
[2K
| Adam | epoch: 015 | loss: 0.03489 - acc: 0.9930 -- iter: 384/421
[A[ATraining Step: 209  | total loss: [1m[32m0.03222[0m[0m | time: 16.822s
[2K
| Adam | epoch: 015 | loss: 0.03222 - acc: 0.9937 -- iter: 416/421
[A[ATraining Step: 210  | total loss: [1m[32m0.02938[0m[0m | time: 18.130s
[2K
| Adam | epoch: 015 | loss: 0.02938 - acc: 0.9944 | val_loss: 0.41688 - val_acc: 0.8939 -- iter: 421/421
--
Validation AUC:0.9629629629629629
Validation AUPRC:0.975020883563098
Test AUC:0.9797235023041474
Test AUPRC:0.9863990369510516
BestTestF1Score	0.95	0.9	0.95	0.98	0.91	64	1	61	6	0.94
BestTestMCCScore	0.95	0.9	0.95	0.98	0.91	64	1	61	6	0.94
BestTestAccuracyScore	0.95	0.9	0.95	0.98	0.91	64	1	61	6	0.94
BestValidationF1Score	0.92	0.81	0.91	0.93	0.91	71	5	49	7	0.94
BestValidationMCC	0.92	0.81	0.91	0.93	0.91	71	5	49	7	0.94
BestValidationAccuracy	0.92	0.81	0.91	0.93	0.91	71	5	49	7	0.94
TestPredictions (Threshold:0.94)
CHEMBL3663547,TP,ACT,1.0	CHEMBL3655677,FN,ACT,0.009999999776482582	CHEMBL330674,TN,INACT,0.05000000074505806	CHEMBL3704948,TP,ACT,1.0	CHEMBL3691838,TP,ACT,1.0	CHEMBL3663477,TP,ACT,1.0	CHEMBL3691825,TP,ACT,1.0	CHEMBL169675,TN,INACT,0.0	CHEMBL135988,TN,INACT,0.0	CHEMBL3663504,TP,ACT,0.9800000190734863	CHEMBL3669043,TP,ACT,1.0	CHEMBL319036,TN,INACT,0.5	CHEMBL3691831,TP,ACT,1.0	CHEMBL107574,TN,INACT,0.0	CHEMBL3663515,TP,ACT,1.0	CHEMBL45875,TN,INACT,0.0	CHEMBL3691846,TP,ACT,1.0	CHEMBL357983,TN,INACT,0.6600000262260437	CHEMBL329861,TN,INACT,0.03999999910593033	CHEMBL460470,TN,INACT,0.0	CHEMBL424214,TN,INACT,0.0	CHEMBL3663574,TP,ACT,1.0	CHEMBL3663388,FN,ACT,0.5199999809265137	CHEMBL112877,TN,INACT,0.0	CHEMBL3663560,TP,ACT,1.0	CHEMBL417719,TN,INACT,0.7099999785423279	CHEMBL3691836,TP,ACT,1.0	CHEMBL3663518,TP,ACT,1.0	CHEMBL19808,TN,INACT,0.25999999046325684	CHEMBL1765668,FP,INACT,0.9800000190734863	CHEMBL3663506,TP,ACT,1.0	CHEMBL453,TN,INACT,0.0	CHEMBL3680360,FN,ACT,0.009999999776482582	CHEMBL3680361,TP,ACT,1.0	CHEMBL3663487,TP,ACT,1.0	CHEMBL594802,TN,INACT,0.009999999776482582	CHEMBL602474,TN,INACT,0.15000000596046448	CHEMBL79030,TN,INACT,0.009999999776482582	CHEMBL89203,TN,INACT,0.0	CHEMBL3704939,TP,ACT,1.0	CHEMBL3669051,TP,ACT,1.0	CHEMBL3669048,TP,ACT,1.0	CHEMBL150260,TN,INACT,0.0	CHEMBL3663409,TP,ACT,1.0	CHEMBL3669019,TP,ACT,0.9900000095367432	CHEMBL281232,TN,INACT,0.3499999940395355	CHEMBL59,TN,INACT,0.0	CHEMBL104172,TN,INACT,0.0	CHEMBL3659202,TP,ACT,1.0	CHEMBL2370511,TN,INACT,0.009999999776482582	CHEMBL140365,TN,INACT,0.05000000074505806	CHEMBL3669028,TP,ACT,1.0	CHEMBL3663426,TP,ACT,1.0	CHEMBL3780633,TN,INACT,0.0	CHEMBL140495,TN,INACT,0.019999999552965164	CHEMBL3691816,TP,ACT,1.0	CHEMBL324652,TN,INACT,0.0	CHEMBL320569,TN,INACT,0.0	CHEMBL3704945,TP,ACT,1.0	CHEMBL3663484,TP,ACT,1.0	CHEMBL303386,TN,INACT,0.009999999776482582	CHEMBL3691828,TP,ACT,0.9900000095367432	CHEMBL3663570,TP,ACT,1.0	CHEMBL78601,TN,INACT,0.009999999776482582	CHEMBL3691823,TP,ACT,1.0	CHEMBL171108,TN,INACT,0.30000001192092896	CHEMBL3691819,TP,ACT,1.0	CHEMBL3691844,TP,ACT,0.9900000095367432	CHEMBL324685,TN,INACT,0.0	CHEMBL3663419,TP,ACT,1.0	CHEMBL3663567,TP,ACT,1.0	CHEMBL3659228,TP,ACT,1.0	CHEMBL421523,TN,INACT,0.009999999776482582	CHEMBL594376,TN,INACT,0.009999999776482582	CHEMBL320124,TN,INACT,0.0	CHEMBL3655666,TP,ACT,1.0	CHEMBL595022,TN,INACT,0.03999999910593033	CHEMBL3663513,TP,ACT,1.0	CHEMBL3704942,TP,ACT,1.0	CHEMBL3663528,TP,ACT,1.0	CHEMBL324586,TN,INACT,0.0	CHEMBL3655664,TP,ACT,1.0	CHEMBL3663402,TP,ACT,1.0	CHEMBL3669021,FN,ACT,0.8299999833106995	CHEMBL3659217,TP,ACT,1.0	CHEMBL3663502,FN,ACT,0.9300000071525574	CHEMBL307034,TN,INACT,0.05999999865889549	CHEMBL3663458,TP,ACT,1.0	CHEMBL3663550,TP,ACT,1.0	CHEMBL336033,TN,INACT,0.11999999731779099	CHEMBL3669010,TP,ACT,1.0	CHEMBL3691830,TP,ACT,1.0	CHEMBL450463,TN,INACT,0.0	CHEMBL3669017,TP,ACT,1.0	CHEMBL423260,TN,INACT,0.019999999552965164	CHEMBL111023,TN,INACT,0.0	CHEMBL3663551,TP,ACT,1.0	CHEMBL80180,TN,INACT,0.009999999776482582	CHEMBL3659204,TP,ACT,1.0	CHEMBL368629,TN,INACT,0.0	CHEMBL3655683,TP,ACT,1.0	CHEMBL3655678,FN,ACT,0.009999999776482582	CHEMBL446693,TN,INACT,0.009999999776482582	CHEMBL3663529,TP,ACT,1.0	CHEMBL252231,TN,INACT,0.0	CHEMBL283320,TN,INACT,0.0	CHEMBL76860,TN,INACT,0.0	CHEMBL113472,TN,INACT,0.0	CHEMBL3659215,TP,ACT,1.0	CHEMBL2370509,TN,INACT,0.019999999552965164	CHEMBL88506,TN,INACT,0.019999999552965164	CHEMBL3663527,TP,ACT,1.0	CHEMBL3642148,TP,ACT,1.0	CHEMBL3394842,TP,ACT,1.0	CHEMBL2391356,TN,INACT,0.019999999552965164	CHEMBL295651,TN,INACT,0.019999999552965164	CHEMBL110064,TN,INACT,0.0	CHEMBL3669046,TP,ACT,1.0	CHEMBL21508,TN,INACT,0.0	CHEMBL91073,TN,INACT,0.9300000071525574	CHEMBL319924,TN,INACT,0.0	CHEMBL3704946,TP,ACT,1.0	CHEMBL10808,TN,INACT,0.029999999329447746	CHEMBL228144,TN,INACT,0.009999999776482582	CHEMBL110053,TN,INACT,0.0	CHEMBL3691822,TP,ACT,1.0	CHEMBL3597970,TP,ACT,1.0	CHEMBL3659222,TP,ACT,1.0	CHEMBL164968,TN,INACT,0.0	CHEMBL3691806,TP,ACT,1.0	CHEMBL3655671,TP,ACT,1.0	CHEMBL3663481,TP,ACT,1.0	

