CNNModel CHEMBL4040 adam 0.0005 15 32 0 0.6 False True
Number of active compounds :	1128
Number of inactive compounds :	1128
---------------------------------
Run id: CNNModel_CHEMBL4040_adam_0.0005_15_32_0_0.6_False_True_id
Log directory: ../tflearnLogs/CNNModel_CHEMBL4040_adam_0.0005_15_32_0.6_True/
---------------------------------
Training samples: 1403
Validation samples: 439
--
Training Step: 1  | time: 1.511s
[2K
| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 0032/1403
[A[ATraining Step: 2  | total loss: [1m[32m0.62428[0m[0m | time: 2.719s
[2K
| Adam | epoch: 001 | loss: 0.62428 - acc: 0.3937 -- iter: 0064/1403
[A[ATraining Step: 3  | total loss: [1m[32m0.68152[0m[0m | time: 3.835s
[2K
| Adam | epoch: 001 | loss: 0.68152 - acc: 0.4551 -- iter: 0096/1403
[A[ATraining Step: 4  | total loss: [1m[32m0.69162[0m[0m | time: 5.030s
[2K
| Adam | epoch: 001 | loss: 0.69162 - acc: 0.4185 -- iter: 0128/1403
[A[ATraining Step: 5  | total loss: [1m[32m0.69297[0m[0m | time: 6.275s
[2K
| Adam | epoch: 001 | loss: 0.69297 - acc: 0.4533 -- iter: 0160/1403
[A[ATraining Step: 6  | total loss: [1m[32m0.69310[0m[0m | time: 7.412s
[2K
| Adam | epoch: 001 | loss: 0.69310 - acc: 0.4632 -- iter: 0192/1403
[A[ATraining Step: 7  | total loss: [1m[32m0.69331[0m[0m | time: 8.658s
[2K
| Adam | epoch: 001 | loss: 0.69331 - acc: 0.4478 -- iter: 0224/1403
[A[ATraining Step: 8  | total loss: [1m[32m0.69344[0m[0m | time: 9.998s
[2K
| Adam | epoch: 001 | loss: 0.69344 - acc: 0.4596 -- iter: 0256/1403
[A[ATraining Step: 9  | total loss: [1m[32m0.69423[0m[0m | time: 13.582s
[2K
| Adam | epoch: 001 | loss: 0.69423 - acc: 0.3817 -- iter: 0288/1403
[A[ATraining Step: 10  | total loss: [1m[32m0.69386[0m[0m | time: 19.563s
[2K
| Adam | epoch: 001 | loss: 0.69386 - acc: 0.4252 -- iter: 0320/1403
[A[ATraining Step: 11  | total loss: [1m[32m0.69340[0m[0m | time: 26.113s
[2K
| Adam | epoch: 001 | loss: 0.69340 - acc: 0.4755 -- iter: 0352/1403
[A[ATraining Step: 12  | total loss: [1m[32m0.69317[0m[0m | time: 28.771s
[2K
| Adam | epoch: 001 | loss: 0.69317 - acc: 0.5568 -- iter: 0384/1403
[A[ATraining Step: 13  | total loss: [1m[32m0.69333[0m[0m | time: 29.865s
[2K
| Adam | epoch: 001 | loss: 0.69333 - acc: 0.4789 -- iter: 0416/1403
[A[ATraining Step: 14  | total loss: [1m[32m0.69339[0m[0m | time: 30.901s
[2K
| Adam | epoch: 001 | loss: 0.69339 - acc: 0.4492 -- iter: 0448/1403
[A[ATraining Step: 15  | total loss: [1m[32m0.69304[0m[0m | time: 31.983s
[2K
| Adam | epoch: 001 | loss: 0.69304 - acc: 0.5424 -- iter: 0480/1403
[A[ATraining Step: 16  | total loss: [1m[32m0.69319[0m[0m | time: 33.012s
[2K
| Adam | epoch: 001 | loss: 0.69319 - acc: 0.5148 -- iter: 0512/1403
[A[ATraining Step: 17  | total loss: [1m[32m0.69278[0m[0m | time: 34.159s
[2K
| Adam | epoch: 001 | loss: 0.69278 - acc: 0.5432 -- iter: 0544/1403
[A[ATraining Step: 18  | total loss: [1m[32m0.69305[0m[0m | time: 35.487s
[2K
| Adam | epoch: 001 | loss: 0.69305 - acc: 0.5283 -- iter: 0576/1403
[A[ATraining Step: 19  | total loss: [1m[32m0.69338[0m[0m | time: 36.756s
[2K
| Adam | epoch: 001 | loss: 0.69338 - acc: 0.5084 -- iter: 0608/1403
[A[ATraining Step: 20  | total loss: [1m[32m0.69236[0m[0m | time: 37.806s
[2K
| Adam | epoch: 001 | loss: 0.69236 - acc: 0.5359 -- iter: 0640/1403
[A[ATraining Step: 21  | total loss: [1m[32m0.69471[0m[0m | time: 39.083s
[2K
| Adam | epoch: 001 | loss: 0.69471 - acc: 0.4762 -- iter: 0672/1403
[A[ATraining Step: 22  | total loss: [1m[32m0.69256[0m[0m | time: 40.285s
[2K
| Adam | epoch: 001 | loss: 0.69256 - acc: 0.5302 -- iter: 0704/1403
[A[ATraining Step: 23  | total loss: [1m[32m0.69279[0m[0m | time: 45.500s
[2K
| Adam | epoch: 001 | loss: 0.69279 - acc: 0.5215 -- iter: 0736/1403
[A[ATraining Step: 24  | total loss: [1m[32m0.69415[0m[0m | time: 52.426s
[2K
| Adam | epoch: 001 | loss: 0.69415 - acc: 0.4891 -- iter: 0768/1403
[A[ATraining Step: 25  | total loss: [1m[32m0.69358[0m[0m | time: 58.284s
[2K
| Adam | epoch: 001 | loss: 0.69358 - acc: 0.5006 -- iter: 0800/1403
[A[ATraining Step: 26  | total loss: [1m[32m0.69182[0m[0m | time: 63.225s
[2K
| Adam | epoch: 001 | loss: 0.69182 - acc: 0.5418 -- iter: 0832/1403
[A[ATraining Step: 27  | total loss: [1m[32m0.69324[0m[0m | time: 64.296s
[2K
| Adam | epoch: 001 | loss: 0.69324 - acc: 0.5069 -- iter: 0864/1403
[A[ATraining Step: 28  | total loss: [1m[32m0.69255[0m[0m | time: 65.593s
[2K
| Adam | epoch: 001 | loss: 0.69255 - acc: 0.5208 -- iter: 0896/1403
[A[ATraining Step: 29  | total loss: [1m[32m0.69323[0m[0m | time: 66.780s
[2K
| Adam | epoch: 001 | loss: 0.69323 - acc: 0.5082 -- iter: 0928/1403
[A[ATraining Step: 30  | total loss: [1m[32m0.69233[0m[0m | time: 68.082s
[2K
| Adam | epoch: 001 | loss: 0.69233 - acc: 0.5284 -- iter: 0960/1403
[A[ATraining Step: 31  | total loss: [1m[32m0.69365[0m[0m | time: 69.009s
[2K
| Adam | epoch: 001 | loss: 0.69365 - acc: 0.5002 -- iter: 0992/1403
[A[ATraining Step: 32  | total loss: [1m[32m0.69362[0m[0m | time: 70.200s
[2K
| Adam | epoch: 001 | loss: 0.69362 - acc: 0.5002 -- iter: 1024/1403
[A[ATraining Step: 33  | total loss: [1m[32m0.69325[0m[0m | time: 71.426s
[2K
| Adam | epoch: 001 | loss: 0.69325 - acc: 0.5070 -- iter: 1056/1403
[A[ATraining Step: 34  | total loss: [1m[32m0.69355[0m[0m | time: 72.518s
[2K
| Adam | epoch: 001 | loss: 0.69355 - acc: 0.4988 -- iter: 1088/1403
[A[ATraining Step: 35  | total loss: [1m[32m0.69488[0m[0m | time: 73.742s
[2K
| Adam | epoch: 001 | loss: 0.69488 - acc: 0.4664 -- iter: 1120/1403
[A[ATraining Step: 36  | total loss: [1m[32m0.69431[0m[0m | time: 75.131s
[2K
| Adam | epoch: 001 | loss: 0.69431 - acc: 0.4796 -- iter: 1152/1403
[A[ATraining Step: 37  | total loss: [1m[32m0.69464[0m[0m | time: 76.550s
[2K
| Adam | epoch: 001 | loss: 0.69464 - acc: 0.4650 -- iter: 1184/1403
[A[ATraining Step: 38  | total loss: [1m[32m0.69421[0m[0m | time: 82.990s
[2K
| Adam | epoch: 001 | loss: 0.69421 - acc: 0.4779 -- iter: 1216/1403
[A[ATraining Step: 39  | total loss: [1m[32m0.69414[0m[0m | time: 84.373s
[2K
| Adam | epoch: 001 | loss: 0.69414 - acc: 0.4762 -- iter: 1248/1403
[A[ATraining Step: 40  | total loss: [1m[32m0.69418[0m[0m | time: 85.472s
[2K
| Adam | epoch: 001 | loss: 0.69418 - acc: 0.4689 -- iter: 1280/1403
[A[ATraining Step: 41  | total loss: [1m[32m0.69422[0m[0m | time: 86.589s
[2K
| Adam | epoch: 001 | loss: 0.69422 - acc: 0.4574 -- iter: 1312/1403
[A[ATraining Step: 42  | total loss: [1m[32m0.69399[0m[0m | time: 87.732s
[2K
| Adam | epoch: 001 | loss: 0.69399 - acc: 0.4707 -- iter: 1344/1403
[A[ATraining Step: 43  | total loss: [1m[32m0.69378[0m[0m | time: 88.880s
[2K
| Adam | epoch: 001 | loss: 0.69378 - acc: 0.4814 -- iter: 1376/1403
[A[ATraining Step: 44  | total loss: [1m[32m0.69371[0m[0m | time: 93.093s
[2K
| Adam | epoch: 001 | loss: 0.69371 - acc: 0.4792 | val_loss: 0.69314 - val_acc: 0.4943 -- iter: 1403/1403
--
Training Step: 45  | total loss: [1m[32m0.69362[0m[0m | time: 1.109s
[2K
| Adam | epoch: 002 | loss: 0.69362 - acc: 0.4796 -- iter: 0032/1403
[A[ATraining Step: 46  | total loss: [1m[32m0.69352[0m[0m | time: 2.246s
[2K
| Adam | epoch: 002 | loss: 0.69352 - acc: 0.4984 -- iter: 0064/1403
[A[ATraining Step: 47  | total loss: [1m[32m0.69343[0m[0m | time: 3.433s
[2K
| Adam | epoch: 002 | loss: 0.69343 - acc: 0.4987 -- iter: 0096/1403
[A[ATraining Step: 48  | total loss: [1m[32m0.69336[0m[0m | time: 4.507s
[2K
| Adam | epoch: 002 | loss: 0.69336 - acc: 0.5039 -- iter: 0128/1403
[A[ATraining Step: 49  | total loss: [1m[32m0.69342[0m[0m | time: 5.643s
[2K
| Adam | epoch: 002 | loss: 0.69342 - acc: 0.4786 -- iter: 0160/1403
[A[ATraining Step: 50  | total loss: [1m[32m0.69339[0m[0m | time: 6.785s
[2K
| Adam | epoch: 002 | loss: 0.69339 - acc: 0.4722 -- iter: 0192/1403
[A[ATraining Step: 51  | total loss: [1m[32m0.69333[0m[0m | time: 7.990s
[2K
| Adam | epoch: 002 | loss: 0.69333 - acc: 0.4908 -- iter: 0224/1403
[A[ATraining Step: 52  | total loss: [1m[32m0.69329[0m[0m | time: 9.109s
[2K
| Adam | epoch: 002 | loss: 0.69329 - acc: 0.4922 -- iter: 0256/1403
[A[ATraining Step: 53  | total loss: [1m[32m0.69326[0m[0m | time: 9.915s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.5071 -- iter: 0288/1403
[A[ATraining Step: 54  | total loss: [1m[32m0.69326[0m[0m | time: 10.736s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4970 -- iter: 0320/1403
[A[ATraining Step: 55  | total loss: [1m[32m0.69331[0m[0m | time: 11.560s
[2K
| Adam | epoch: 002 | loss: 0.69331 - acc: 0.4796 -- iter: 0352/1403
[A[ATraining Step: 56  | total loss: [1m[32m0.69327[0m[0m | time: 12.462s
[2K
| Adam | epoch: 002 | loss: 0.69327 - acc: 0.4957 -- iter: 0384/1403
[A[ATraining Step: 57  | total loss: [1m[32m0.69326[0m[0m | time: 13.261s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4919 -- iter: 0416/1403
[A[ATraining Step: 58  | total loss: [1m[32m0.69322[0m[0m | time: 14.066s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.5058 -- iter: 0448/1403
[A[ATraining Step: 59  | total loss: [1m[32m0.69322[0m[0m | time: 14.826s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.5008 -- iter: 0480/1403
[A[ATraining Step: 60  | total loss: [1m[32m0.69326[0m[0m | time: 15.641s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4759 -- iter: 0512/1403
[A[ATraining Step: 61  | total loss: [1m[32m0.69322[0m[0m | time: 16.411s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4913 -- iter: 0544/1403
[A[ATraining Step: 62  | total loss: [1m[32m0.69323[0m[0m | time: 17.163s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.4884 -- iter: 0576/1403
[A[ATraining Step: 63  | total loss: [1m[32m0.69325[0m[0m | time: 18.090s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4661 -- iter: 0608/1403
[A[ATraining Step: 64  | total loss: [1m[32m0.69325[0m[0m | time: 18.903s
[2K
| Adam | epoch: 002 | loss: 0.69325 - acc: 0.4586 -- iter: 0640/1403
[A[ATraining Step: 65  | total loss: [1m[32m0.69324[0m[0m | time: 19.669s
[2K
| Adam | epoch: 002 | loss: 0.69324 - acc: 0.4522 -- iter: 0672/1403
[A[ATraining Step: 66  | total loss: [1m[32m0.69323[0m[0m | time: 20.508s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.4466 -- iter: 0704/1403
[A[ATraining Step: 67  | total loss: [1m[32m0.69323[0m[0m | time: 21.282s
[2K
| Adam | epoch: 002 | loss: 0.69323 - acc: 0.4417 -- iter: 0736/1403
[A[ATraining Step: 68  | total loss: [1m[32m0.69322[0m[0m | time: 22.057s
[2K
| Adam | epoch: 002 | loss: 0.69322 - acc: 0.4560 -- iter: 0768/1403
[A[ATraining Step: 69  | total loss: [1m[32m0.69321[0m[0m | time: 22.916s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4685 -- iter: 0800/1403
[A[ATraining Step: 70  | total loss: [1m[32m0.69321[0m[0m | time: 23.709s
[2K
| Adam | epoch: 002 | loss: 0.69321 - acc: 0.4649 -- iter: 0832/1403
[A[ATraining Step: 71  | total loss: [1m[32m0.69319[0m[0m | time: 24.554s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.4796 -- iter: 0864/1403
[A[ATraining Step: 72  | total loss: [1m[32m0.69317[0m[0m | time: 25.364s
[2K
| Adam | epoch: 002 | loss: 0.69317 - acc: 0.4995 -- iter: 0896/1403
[A[ATraining Step: 73  | total loss: [1m[32m0.69314[0m[0m | time: 26.232s
[2K
| Adam | epoch: 002 | loss: 0.69314 - acc: 0.5030 -- iter: 0928/1403
[A[ATraining Step: 74  | total loss: [1m[32m0.69312[0m[0m | time: 27.077s
[2K
| Adam | epoch: 002 | loss: 0.69312 - acc: 0.5267 -- iter: 0960/1403
[A[ATraining Step: 75  | total loss: [1m[32m0.69306[0m[0m | time: 27.910s
[2K
| Adam | epoch: 002 | loss: 0.69306 - acc: 0.5407 -- iter: 0992/1403
[A[ATraining Step: 76  | total loss: [1m[32m0.69307[0m[0m | time: 28.687s
[2K
| Adam | epoch: 002 | loss: 0.69307 - acc: 0.5330 -- iter: 1024/1403
[A[ATraining Step: 77  | total loss: [1m[32m0.69315[0m[0m | time: 29.488s
[2K
| Adam | epoch: 002 | loss: 0.69315 - acc: 0.5196 -- iter: 1056/1403
[A[ATraining Step: 78  | total loss: [1m[32m0.69318[0m[0m | time: 30.502s
[2K
| Adam | epoch: 002 | loss: 0.69318 - acc: 0.5110 -- iter: 1088/1403
[A[ATraining Step: 79  | total loss: [1m[32m0.69328[0m[0m | time: 31.758s
[2K
| Adam | epoch: 002 | loss: 0.69328 - acc: 0.4937 -- iter: 1120/1403
[A[ATraining Step: 80  | total loss: [1m[32m0.69326[0m[0m | time: 36.319s
[2K
| Adam | epoch: 002 | loss: 0.69326 - acc: 0.4879 -- iter: 1152/1403
[A[ATraining Step: 81  | total loss: [1m[32m0.69319[0m[0m | time: 40.174s
[2K
| Adam | epoch: 002 | loss: 0.69319 - acc: 0.5144 -- iter: 1184/1403
[A[ATraining Step: 82  | total loss: [1m[32m0.69317[0m[0m | time: 47.172s
[2K
| Adam | epoch: 002 | loss: 0.69317 - acc: 0.5068 -- iter: 1216/1403
[A[ATraining Step: 83  | total loss: [1m[32m0.69312[0m[0m | time: 48.786s
[2K
| Adam | epoch: 002 | loss: 0.69312 - acc: 0.5186 -- iter: 1248/1403
[A[ATraining Step: 84  | total loss: [1m[32m0.69313[0m[0m | time: 49.900s
[2K
| Adam | epoch: 002 | loss: 0.69313 - acc: 0.5105 -- iter: 1280/1403
[A[ATraining Step: 85  | total loss: [1m[32m0.69311[0m[0m | time: 50.979s
[2K
| Adam | epoch: 002 | loss: 0.69311 - acc: 0.5094 -- iter: 1312/1403
[A[ATraining Step: 86  | total loss: [1m[32m0.69308[0m[0m | time: 51.987s
[2K
| Adam | epoch: 002 | loss: 0.69308 - acc: 0.5147 -- iter: 1344/1403
[A[ATraining Step: 87  | total loss: [1m[32m0.69302[0m[0m | time: 53.076s
[2K
| Adam | epoch: 002 | loss: 0.69302 - acc: 0.5289 -- iter: 1376/1403
[A[ATraining Step: 88  | total loss: [1m[32m0.69297[0m[0m | time: 57.407s
[2K
| Adam | epoch: 002 | loss: 0.69297 - acc: 0.5479 | val_loss: 0.69234 - val_acc: 0.5877 -- iter: 1403/1403
--
Training Step: 89  | total loss: [1m[32m0.69301[0m[0m | time: 6.227s
[2K
| Adam | epoch: 003 | loss: 0.69301 - acc: 0.5368 -- iter: 0032/1403
[A[ATraining Step: 90  | total loss: [1m[32m0.69299[0m[0m | time: 13.062s
[2K
| Adam | epoch: 003 | loss: 0.69299 - acc: 0.5387 -- iter: 0064/1403
[A[ATraining Step: 91  | total loss: [1m[32m0.69290[0m[0m | time: 18.204s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5478 -- iter: 0096/1403
[A[ATraining Step: 92  | total loss: [1m[32m0.69290[0m[0m | time: 21.602s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5461 -- iter: 0128/1403
[A[ATraining Step: 93  | total loss: [1m[32m0.69277[0m[0m | time: 22.746s
[2K
| Adam | epoch: 003 | loss: 0.69277 - acc: 0.5478 -- iter: 0160/1403
[A[ATraining Step: 94  | total loss: [1m[32m0.69279[0m[0m | time: 23.772s
[2K
| Adam | epoch: 003 | loss: 0.69279 - acc: 0.5430 -- iter: 0192/1403
[A[ATraining Step: 95  | total loss: [1m[32m0.69290[0m[0m | time: 24.803s
[2K
| Adam | epoch: 003 | loss: 0.69290 - acc: 0.5325 -- iter: 0224/1403
[A[ATraining Step: 96  | total loss: [1m[32m0.69295[0m[0m | time: 25.782s
[2K
| Adam | epoch: 003 | loss: 0.69295 - acc: 0.5230 -- iter: 0256/1403
[A[ATraining Step: 97  | total loss: [1m[32m0.69263[0m[0m | time: 26.951s
[2K
| Adam | epoch: 003 | loss: 0.69263 - acc: 0.5300 -- iter: 0288/1403
[A[ATraining Step: 98  | total loss: [1m[32m0.69251[0m[0m | time: 28.262s
[2K
| Adam | epoch: 003 | loss: 0.69251 - acc: 0.5239 -- iter: 0320/1403
[A[ATraining Step: 99  | total loss: [1m[32m0.69250[0m[0m | time: 29.447s
[2K
| Adam | epoch: 003 | loss: 0.69250 - acc: 0.5309 -- iter: 0352/1403
[A[ATraining Step: 100  | total loss: [1m[32m0.69215[0m[0m | time: 30.573s
[2K
| Adam | epoch: 003 | loss: 0.69215 - acc: 0.5528 -- iter: 0384/1403
[A[ATraining Step: 101  | total loss: [1m[32m0.69207[0m[0m | time: 31.952s
[2K
| Adam | epoch: 003 | loss: 0.69207 - acc: 0.5538 -- iter: 0416/1403
[A[ATraining Step: 102  | total loss: [1m[32m0.69179[0m[0m | time: 35.596s
[2K
| Adam | epoch: 003 | loss: 0.69179 - acc: 0.5609 -- iter: 0448/1403
[A[ATraining Step: 103  | total loss: [1m[32m0.69149[0m[0m | time: 42.628s
[2K
| Adam | epoch: 003 | loss: 0.69149 - acc: 0.5704 -- iter: 0480/1403
[A[ATraining Step: 104  | total loss: [1m[32m0.69093[0m[0m | time: 48.409s
[2K
| Adam | epoch: 003 | loss: 0.69093 - acc: 0.5790 -- iter: 0512/1403
[A[ATraining Step: 105  | total loss: [1m[32m0.69007[0m[0m | time: 49.997s
[2K
| Adam | epoch: 003 | loss: 0.69007 - acc: 0.5992 -- iter: 0544/1403
[A[ATraining Step: 106  | total loss: [1m[32m0.68962[0m[0m | time: 51.136s
[2K
| Adam | epoch: 003 | loss: 0.68962 - acc: 0.5831 -- iter: 0576/1403
[A[ATraining Step: 107  | total loss: [1m[32m0.68965[0m[0m | time: 52.355s
[2K
| Adam | epoch: 003 | loss: 0.68965 - acc: 0.5779 -- iter: 0608/1403
[A[ATraining Step: 108  | total loss: [1m[32m0.68834[0m[0m | time: 53.476s
[2K
| Adam | epoch: 003 | loss: 0.68834 - acc: 0.5795 -- iter: 0640/1403
[A[ATraining Step: 109  | total loss: [1m[32m0.68553[0m[0m | time: 54.600s
[2K
| Adam | epoch: 003 | loss: 0.68553 - acc: 0.5965 -- iter: 0672/1403
[A[ATraining Step: 110  | total loss: [1m[32m0.68455[0m[0m | time: 55.839s
[2K
| Adam | epoch: 003 | loss: 0.68455 - acc: 0.5962 -- iter: 0704/1403
[A[ATraining Step: 111  | total loss: [1m[32m0.68367[0m[0m | time: 57.165s
[2K
| Adam | epoch: 003 | loss: 0.68367 - acc: 0.5866 -- iter: 0736/1403
[A[ATraining Step: 112  | total loss: [1m[32m0.68106[0m[0m | time: 58.241s
[2K
| Adam | epoch: 003 | loss: 0.68106 - acc: 0.5905 -- iter: 0768/1403
[A[ATraining Step: 113  | total loss: [1m[32m0.67576[0m[0m | time: 59.351s
[2K
| Adam | epoch: 003 | loss: 0.67576 - acc: 0.6033 -- iter: 0800/1403
[A[ATraining Step: 114  | total loss: [1m[32m0.66982[0m[0m | time: 60.713s
[2K
| Adam | epoch: 003 | loss: 0.66982 - acc: 0.6117 -- iter: 0832/1403
[A[ATraining Step: 115  | total loss: [1m[32m0.66706[0m[0m | time: 62.166s
[2K
| Adam | epoch: 003 | loss: 0.66706 - acc: 0.6162 -- iter: 0864/1403
[A[ATraining Step: 116  | total loss: [1m[32m0.66210[0m[0m | time: 65.302s
[2K
| Adam | epoch: 003 | loss: 0.66210 - acc: 0.6358 -- iter: 0896/1403
[A[ATraining Step: 117  | total loss: [1m[32m0.65154[0m[0m | time: 67.250s
[2K
| Adam | epoch: 003 | loss: 0.65154 - acc: 0.6503 -- iter: 0928/1403
[A[ATraining Step: 118  | total loss: [1m[32m0.64338[0m[0m | time: 74.037s
[2K
| Adam | epoch: 003 | loss: 0.64338 - acc: 0.6603 -- iter: 0960/1403
[A[ATraining Step: 119  | total loss: [1m[32m0.64880[0m[0m | time: 75.757s
[2K
| Adam | epoch: 003 | loss: 0.64880 - acc: 0.6662 -- iter: 0992/1403
[A[ATraining Step: 120  | total loss: [1m[32m0.64039[0m[0m | time: 76.805s
[2K
| Adam | epoch: 003 | loss: 0.64039 - acc: 0.6714 -- iter: 1024/1403
[A[ATraining Step: 121  | total loss: [1m[32m0.63929[0m[0m | time: 77.935s
[2K
| Adam | epoch: 003 | loss: 0.63929 - acc: 0.6730 -- iter: 1056/1403
[A[ATraining Step: 122  | total loss: [1m[32m0.63682[0m[0m | time: 79.158s
[2K
| Adam | epoch: 003 | loss: 0.63682 - acc: 0.6776 -- iter: 1088/1403
[A[ATraining Step: 123  | total loss: [1m[32m0.62288[0m[0m | time: 80.309s
[2K
| Adam | epoch: 003 | loss: 0.62288 - acc: 0.6911 -- iter: 1120/1403
[A[ATraining Step: 124  | total loss: [1m[32m0.61198[0m[0m | time: 81.706s
[2K
| Adam | epoch: 003 | loss: 0.61198 - acc: 0.7001 -- iter: 1152/1403
[A[ATraining Step: 125  | total loss: [1m[32m0.60553[0m[0m | time: 82.912s
[2K
| Adam | epoch: 003 | loss: 0.60553 - acc: 0.7020 -- iter: 1184/1403
[A[ATraining Step: 126  | total loss: [1m[32m0.60611[0m[0m | time: 84.017s
[2K
| Adam | epoch: 003 | loss: 0.60611 - acc: 0.7036 -- iter: 1216/1403
[A[ATraining Step: 127  | total loss: [1m[32m0.62614[0m[0m | time: 85.077s
[2K
| Adam | epoch: 003 | loss: 0.62614 - acc: 0.7020 -- iter: 1248/1403
[A[ATraining Step: 128  | total loss: [1m[32m0.62031[0m[0m | time: 86.465s
[2K
| Adam | epoch: 003 | loss: 0.62031 - acc: 0.7006 -- iter: 1280/1403
[A[ATraining Step: 129  | total loss: [1m[32m0.60325[0m[0m | time: 89.050s
[2K
| Adam | epoch: 003 | loss: 0.60325 - acc: 0.7149 -- iter: 1312/1403
[A[ATraining Step: 130  | total loss: [1m[32m0.62827[0m[0m | time: 92.337s
[2K
| Adam | epoch: 003 | loss: 0.62827 - acc: 0.6872 -- iter: 1344/1403
[A[ATraining Step: 131  | total loss: [1m[32m0.62995[0m[0m | time: 97.476s
[2K
| Adam | epoch: 003 | loss: 0.62995 - acc: 0.6747 -- iter: 1376/1403
[A[ATraining Step: 132  | total loss: [1m[32m0.63110[0m[0m | time: 112.139s
[2K
| Adam | epoch: 003 | loss: 0.63110 - acc: 0.6697 | val_loss: 0.59160 - val_acc: 0.7062 -- iter: 1403/1403
--
Training Step: 133  | total loss: [1m[32m0.62679[0m[0m | time: 1.214s
[2K
| Adam | epoch: 004 | loss: 0.62679 - acc: 0.6840 -- iter: 0032/1403
[A[ATraining Step: 134  | total loss: [1m[32m0.62176[0m[0m | time: 2.191s
[2K
| Adam | epoch: 004 | loss: 0.62176 - acc: 0.6843 -- iter: 0064/1403
[A[ATraining Step: 135  | total loss: [1m[32m0.61046[0m[0m | time: 3.354s
[2K
| Adam | epoch: 004 | loss: 0.61046 - acc: 0.6863 -- iter: 0096/1403
[A[ATraining Step: 136  | total loss: [1m[32m0.60305[0m[0m | time: 4.621s
[2K
| Adam | epoch: 004 | loss: 0.60305 - acc: 0.6917 -- iter: 0128/1403
[A[ATraining Step: 137  | total loss: [1m[32m0.60962[0m[0m | time: 5.786s
[2K
| Adam | epoch: 004 | loss: 0.60962 - acc: 0.6726 -- iter: 0160/1403
[A[ATraining Step: 138  | total loss: [1m[32m0.60452[0m[0m | time: 7.034s
[2K
| Adam | epoch: 004 | loss: 0.60452 - acc: 0.6834 -- iter: 0192/1403
[A[ATraining Step: 139  | total loss: [1m[32m0.60683[0m[0m | time: 8.345s
[2K
| Adam | epoch: 004 | loss: 0.60683 - acc: 0.6776 -- iter: 0224/1403
[A[ATraining Step: 140  | total loss: [1m[32m0.59870[0m[0m | time: 15.642s
[2K
| Adam | epoch: 004 | loss: 0.59870 - acc: 0.6848 -- iter: 0256/1403
[A[ATraining Step: 141  | total loss: [1m[32m0.59675[0m[0m | time: 19.517s
[2K
| Adam | epoch: 004 | loss: 0.59675 - acc: 0.6851 -- iter: 0288/1403
[A[ATraining Step: 142  | total loss: [1m[32m0.58840[0m[0m | time: 26.718s
[2K
| Adam | epoch: 004 | loss: 0.58840 - acc: 0.7072 -- iter: 0320/1403
[A[ATraining Step: 143  | total loss: [1m[32m0.58795[0m[0m | time: 31.319s
[2K
| Adam | epoch: 004 | loss: 0.58795 - acc: 0.7084 -- iter: 0352/1403
[A[ATraining Step: 144  | total loss: [1m[32m0.59034[0m[0m | time: 35.707s
[2K
| Adam | epoch: 004 | loss: 0.59034 - acc: 0.7000 -- iter: 0384/1403
[A[ATraining Step: 145  | total loss: [1m[32m0.58717[0m[0m | time: 39.003s
[2K
| Adam | epoch: 004 | loss: 0.58717 - acc: 0.7019 -- iter: 0416/1403
[A[ATraining Step: 146  | total loss: [1m[32m0.58717[0m[0m | time: 40.400s
[2K
| Adam | epoch: 004 | loss: 0.58717 - acc: 0.7067 -- iter: 0448/1403
[A[ATraining Step: 147  | total loss: [1m[32m0.57543[0m[0m | time: 45.510s
[2K
| Adam | epoch: 004 | loss: 0.57543 - acc: 0.7142 -- iter: 0480/1403
[A[ATraining Step: 148  | total loss: [1m[32m0.59245[0m[0m | time: 46.880s
[2K
| Adam | epoch: 004 | loss: 0.59245 - acc: 0.7021 -- iter: 0512/1403
[A[ATraining Step: 149  | total loss: [1m[32m0.59023[0m[0m | time: 48.021s
[2K
| Adam | epoch: 004 | loss: 0.59023 - acc: 0.7100 -- iter: 0544/1403
[A[ATraining Step: 150  | total loss: [1m[32m0.57275[0m[0m | time: 49.111s
[2K
| Adam | epoch: 004 | loss: 0.57275 - acc: 0.7265 -- iter: 0576/1403
[A[ATraining Step: 151  | total loss: [1m[32m0.57487[0m[0m | time: 50.372s
[2K
| Adam | epoch: 004 | loss: 0.57487 - acc: 0.7258 -- iter: 0608/1403
[A[ATraining Step: 152  | total loss: [1m[32m0.58338[0m[0m | time: 51.792s
[2K
| Adam | epoch: 004 | loss: 0.58338 - acc: 0.7219 -- iter: 0640/1403
[A[ATraining Step: 153  | total loss: [1m[32m0.58295[0m[0m | time: 52.954s
[2K
| Adam | epoch: 004 | loss: 0.58295 - acc: 0.7185 -- iter: 0672/1403
[A[ATraining Step: 154  | total loss: [1m[32m0.57200[0m[0m | time: 54.230s
[2K
| Adam | epoch: 004 | loss: 0.57200 - acc: 0.7279 -- iter: 0704/1403
[A[ATraining Step: 155  | total loss: [1m[32m0.55954[0m[0m | time: 55.493s
[2K
| Adam | epoch: 004 | loss: 0.55954 - acc: 0.7332 -- iter: 0736/1403
[A[ATraining Step: 156  | total loss: [1m[32m0.54592[0m[0m | time: 59.152s
[2K
| Adam | epoch: 004 | loss: 0.54592 - acc: 0.7443 -- iter: 0768/1403
[A[ATraining Step: 157  | total loss: [1m[32m0.54658[0m[0m | time: 63.606s
[2K
| Adam | epoch: 004 | loss: 0.54658 - acc: 0.7386 -- iter: 0800/1403
[A[ATraining Step: 158  | total loss: [1m[32m0.53715[0m[0m | time: 67.439s
[2K
| Adam | epoch: 004 | loss: 0.53715 - acc: 0.7460 -- iter: 0832/1403
[A[ATraining Step: 159  | total loss: [1m[32m0.51518[0m[0m | time: 74.013s
[2K
| Adam | epoch: 004 | loss: 0.51518 - acc: 0.7589 -- iter: 0864/1403
[A[ATraining Step: 160  | total loss: [1m[32m0.51681[0m[0m | time: 76.923s
[2K
| Adam | epoch: 004 | loss: 0.51681 - acc: 0.7580 -- iter: 0896/1403
[A[ATraining Step: 161  | total loss: [1m[32m0.52518[0m[0m | time: 83.056s
[2K
| Adam | epoch: 004 | loss: 0.52518 - acc: 0.7541 -- iter: 0928/1403
[A[ATraining Step: 162  | total loss: [1m[32m0.52791[0m[0m | time: 85.448s
[2K
| Adam | epoch: 004 | loss: 0.52791 - acc: 0.7568 -- iter: 0960/1403
[A[ATraining Step: 163  | total loss: [1m[32m0.53909[0m[0m | time: 86.390s
[2K
| Adam | epoch: 004 | loss: 0.53909 - acc: 0.7467 -- iter: 0992/1403
[A[ATraining Step: 164  | total loss: [1m[32m0.53128[0m[0m | time: 87.539s
[2K
| Adam | epoch: 004 | loss: 0.53128 - acc: 0.7533 -- iter: 1024/1403
[A[ATraining Step: 165  | total loss: [1m[32m0.53833[0m[0m | time: 88.595s
[2K
| Adam | epoch: 004 | loss: 0.53833 - acc: 0.7467 -- iter: 1056/1403
[A[ATraining Step: 166  | total loss: [1m[32m0.52979[0m[0m | time: 89.843s
[2K
| Adam | epoch: 004 | loss: 0.52979 - acc: 0.7564 -- iter: 1088/1403
[A[ATraining Step: 167  | total loss: [1m[32m0.53435[0m[0m | time: 91.083s
[2K
| Adam | epoch: 004 | loss: 0.53435 - acc: 0.7558 -- iter: 1120/1403
[A[ATraining Step: 168  | total loss: [1m[32m0.55423[0m[0m | time: 92.306s
[2K
| Adam | epoch: 004 | loss: 0.55423 - acc: 0.7396 -- iter: 1152/1403
[A[ATraining Step: 169  | total loss: [1m[32m0.53966[0m[0m | time: 93.572s
[2K
| Adam | epoch: 004 | loss: 0.53966 - acc: 0.7469 -- iter: 1184/1403
[A[ATraining Step: 170  | total loss: [1m[32m0.53624[0m[0m | time: 94.620s
[2K
| Adam | epoch: 004 | loss: 0.53624 - acc: 0.7441 -- iter: 1216/1403
[A[ATraining Step: 171  | total loss: [1m[32m0.54486[0m[0m | time: 95.871s
[2K
| Adam | epoch: 004 | loss: 0.54486 - acc: 0.7353 -- iter: 1248/1403
[A[ATraining Step: 172  | total loss: [1m[32m0.54079[0m[0m | time: 97.349s
[2K
| Adam | epoch: 004 | loss: 0.54079 - acc: 0.7368 -- iter: 1280/1403
[A[ATraining Step: 173  | total loss: [1m[32m0.52975[0m[0m | time: 99.119s
[2K
| Adam | epoch: 004 | loss: 0.52975 - acc: 0.7443 -- iter: 1312/1403
[A[ATraining Step: 174  | total loss: [1m[32m0.52281[0m[0m | time: 103.940s
[2K
| Adam | epoch: 004 | loss: 0.52281 - acc: 0.7543 -- iter: 1344/1403
[A[ATraining Step: 175  | total loss: [1m[32m0.51177[0m[0m | time: 109.717s
[2K
| Adam | epoch: 004 | loss: 0.51177 - acc: 0.7632 -- iter: 1376/1403
[A[ATraining Step: 176  | total loss: [1m[32m0.52118[0m[0m | time: 124.994s
[2K
| Adam | epoch: 004 | loss: 0.52118 - acc: 0.7681 | val_loss: 0.51951 - val_acc: 0.7563 -- iter: 1403/1403
--
Training Step: 177  | total loss: [1m[32m0.51058[0m[0m | time: 1.138s
[2K
| Adam | epoch: 005 | loss: 0.51058 - acc: 0.7757 -- iter: 0032/1403
[A[ATraining Step: 178  | total loss: [1m[32m0.50062[0m[0m | time: 2.204s
[2K
| Adam | epoch: 005 | loss: 0.50062 - acc: 0.7825 -- iter: 0064/1403
[A[ATraining Step: 179  | total loss: [1m[32m0.50179[0m[0m | time: 3.383s
[2K
| Adam | epoch: 005 | loss: 0.50179 - acc: 0.7824 -- iter: 0096/1403
[A[ATraining Step: 180  | total loss: [1m[32m0.51111[0m[0m | time: 4.772s
[2K
| Adam | epoch: 005 | loss: 0.51111 - acc: 0.7671 -- iter: 0128/1403
[A[ATraining Step: 181  | total loss: [1m[32m0.51538[0m[0m | time: 11.452s
[2K
| Adam | epoch: 005 | loss: 0.51538 - acc: 0.7534 -- iter: 0160/1403
[A[ATraining Step: 182  | total loss: [1m[32m0.50753[0m[0m | time: 19.579s
[2K
| Adam | epoch: 005 | loss: 0.50753 - acc: 0.7624 -- iter: 0192/1403
[A[ATraining Step: 183  | total loss: [1m[32m0.52708[0m[0m | time: 25.013s
[2K
| Adam | epoch: 005 | loss: 0.52708 - acc: 0.7549 -- iter: 0224/1403
[A[ATraining Step: 184  | total loss: [1m[32m0.53367[0m[0m | time: 29.910s
[2K
| Adam | epoch: 005 | loss: 0.53367 - acc: 0.7513 -- iter: 0256/1403
[A[ATraining Step: 185  | total loss: [1m[32m0.51947[0m[0m | time: 40.891s
[2K
| Adam | epoch: 005 | loss: 0.51947 - acc: 0.7637 -- iter: 0288/1403
[A[ATraining Step: 186  | total loss: [1m[32m0.52219[0m[0m | time: 44.742s
[2K
| Adam | epoch: 005 | loss: 0.52219 - acc: 0.7498 -- iter: 0320/1403
[A[ATraining Step: 187  | total loss: [1m[32m0.51554[0m[0m | time: 50.009s
[2K
| Adam | epoch: 005 | loss: 0.51554 - acc: 0.7561 -- iter: 0352/1403
[A[ATraining Step: 188  | total loss: [1m[32m0.51641[0m[0m | time: 55.357s
[2K
| Adam | epoch: 005 | loss: 0.51641 - acc: 0.7523 -- iter: 0384/1403
[A[ATraining Step: 189  | total loss: [1m[32m0.50534[0m[0m | time: 59.349s
[2K
| Adam | epoch: 005 | loss: 0.50534 - acc: 0.7615 -- iter: 0416/1403
[A[ATraining Step: 190  | total loss: [1m[32m0.50861[0m[0m | time: 67.205s
[2K
| Adam | epoch: 005 | loss: 0.50861 - acc: 0.7603 -- iter: 0448/1403
[A[ATraining Step: 191  | total loss: [1m[32m0.51140[0m[0m | time: 72.338s
[2K
| Adam | epoch: 005 | loss: 0.51140 - acc: 0.7499 -- iter: 0480/1403
[A[ATraining Step: 192  | total loss: [1m[32m0.50536[0m[0m | time: 76.614s
[2K
| Adam | epoch: 005 | loss: 0.50536 - acc: 0.7531 -- iter: 0512/1403
[A[ATraining Step: 193  | total loss: [1m[32m0.50168[0m[0m | time: 82.447s
[2K
| Adam | epoch: 005 | loss: 0.50168 - acc: 0.7590 -- iter: 0544/1403
[A[ATraining Step: 194  | total loss: [1m[32m0.51665[0m[0m | time: 86.135s
[2K
| Adam | epoch: 005 | loss: 0.51665 - acc: 0.7550 -- iter: 0576/1403
[A[ATraining Step: 195  | total loss: [1m[32m0.52930[0m[0m | time: 92.450s
[2K
| Adam | epoch: 005 | loss: 0.52930 - acc: 0.7420 -- iter: 0608/1403
[A[ATraining Step: 196  | total loss: [1m[32m0.51622[0m[0m | time: 96.499s
[2K
| Adam | epoch: 005 | loss: 0.51622 - acc: 0.7490 -- iter: 0640/1403
[A[ATraining Step: 197  | total loss: [1m[32m0.50778[0m[0m | time: 100.677s
[2K
| Adam | epoch: 005 | loss: 0.50778 - acc: 0.7523 -- iter: 0672/1403
[A[ATraining Step: 198  | total loss: [1m[32m0.49911[0m[0m | time: 104.776s
[2K
| Adam | epoch: 005 | loss: 0.49911 - acc: 0.7583 -- iter: 0704/1403
[A[ATraining Step: 199  | total loss: [1m[32m0.48445[0m[0m | time: 108.324s
[2K
| Adam | epoch: 005 | loss: 0.48445 - acc: 0.7699 -- iter: 0736/1403
[A[ATraining Step: 200  | total loss: [1m[32m0.49071[0m[0m | time: 137.171s
[2K
| Adam | epoch: 005 | loss: 0.49071 - acc: 0.7617 | val_loss: 0.51112 - val_acc: 0.7472 -- iter: 0768/1403
--
Training Step: 201  | total loss: [1m[32m0.48277[0m[0m | time: 138.709s
[2K
| Adam | epoch: 005 | loss: 0.48277 - acc: 0.7730 -- iter: 0800/1403
[A[ATraining Step: 202  | total loss: [1m[32m0.48935[0m[0m | time: 140.253s
[2K
| Adam | epoch: 005 | loss: 0.48935 - acc: 0.7645 -- iter: 0832/1403
[A[ATraining Step: 203  | total loss: [1m[32m0.47668[0m[0m | time: 141.901s
[2K
| Adam | epoch: 005 | loss: 0.47668 - acc: 0.7787 -- iter: 0864/1403
[A[ATraining Step: 204  | total loss: [1m[32m0.47411[0m[0m | time: 143.413s
[2K
| Adam | epoch: 005 | loss: 0.47411 - acc: 0.7727 -- iter: 0896/1403
[A[ATraining Step: 205  | total loss: [1m[32m0.48822[0m[0m | time: 144.664s
[2K
| Adam | epoch: 005 | loss: 0.48822 - acc: 0.7641 -- iter: 0928/1403
[A[ATraining Step: 206  | total loss: [1m[32m0.49009[0m[0m | time: 146.214s
[2K
| Adam | epoch: 005 | loss: 0.49009 - acc: 0.7690 -- iter: 0960/1403
[A[ATraining Step: 207  | total loss: [1m[32m0.49145[0m[0m | time: 152.896s
[2K
| Adam | epoch: 005 | loss: 0.49145 - acc: 0.7640 -- iter: 0992/1403
[A[ATraining Step: 208  | total loss: [1m[32m0.49618[0m[0m | time: 156.498s
[2K
| Adam | epoch: 005 | loss: 0.49618 - acc: 0.7657 -- iter: 1024/1403
[A[ATraining Step: 209  | total loss: [1m[32m0.48425[0m[0m | time: 161.353s
[2K
| Adam | epoch: 005 | loss: 0.48425 - acc: 0.7766 -- iter: 1056/1403
[A[ATraining Step: 210  | total loss: [1m[32m0.47939[0m[0m | time: 164.158s
[2K
| Adam | epoch: 005 | loss: 0.47939 - acc: 0.7740 -- iter: 1088/1403
[A[ATraining Step: 211  | total loss: [1m[32m0.48969[0m[0m | time: 169.594s
[2K
| Adam | epoch: 005 | loss: 0.48969 - acc: 0.7653 -- iter: 1120/1403
[A[ATraining Step: 212  | total loss: [1m[32m0.48503[0m[0m | time: 172.414s
[2K
| Adam | epoch: 005 | loss: 0.48503 - acc: 0.7732 -- iter: 1152/1403
[A[ATraining Step: 213  | total loss: [1m[32m0.48934[0m[0m | time: 176.530s
[2K
| Adam | epoch: 005 | loss: 0.48934 - acc: 0.7708 -- iter: 1184/1403
[A[ATraining Step: 214  | total loss: [1m[32m0.48029[0m[0m | time: 180.519s
[2K
| Adam | epoch: 005 | loss: 0.48029 - acc: 0.7813 -- iter: 1216/1403
[A[ATraining Step: 215  | total loss: [1m[32m0.48039[0m[0m | time: 184.175s
[2K
| Adam | epoch: 005 | loss: 0.48039 - acc: 0.7750 -- iter: 1248/1403
[A[ATraining Step: 216  | total loss: [1m[32m0.47026[0m[0m | time: 187.013s
[2K
| Adam | epoch: 005 | loss: 0.47026 - acc: 0.7850 -- iter: 1280/1403
[A[ATraining Step: 217  | total loss: [1m[32m0.46494[0m[0m | time: 190.372s
[2K
| Adam | epoch: 005 | loss: 0.46494 - acc: 0.7909 -- iter: 1312/1403
[A[ATraining Step: 218  | total loss: [1m[32m0.45435[0m[0m | time: 193.442s
[2K
| Adam | epoch: 005 | loss: 0.45435 - acc: 0.8024 -- iter: 1344/1403
[A[ATraining Step: 219  | total loss: [1m[32m0.46199[0m[0m | time: 195.830s
[2K
| Adam | epoch: 005 | loss: 0.46199 - acc: 0.7972 -- iter: 1376/1403
[A[ATraining Step: 220  | total loss: [1m[32m0.46361[0m[0m | time: 230.396s
[2K
| Adam | epoch: 005 | loss: 0.46361 - acc: 0.7925 | val_loss: 0.45197 - val_acc: 0.7973 -- iter: 1403/1403
--
Training Step: 221  | total loss: [1m[32m0.45239[0m[0m | time: 1.390s
[2K
| Adam | epoch: 006 | loss: 0.45239 - acc: 0.8038 -- iter: 0032/1403
[A[ATraining Step: 222  | total loss: [1m[32m0.45551[0m[0m | time: 4.095s
[2K
| Adam | epoch: 006 | loss: 0.45551 - acc: 0.7953 -- iter: 0064/1403
[A[ATraining Step: 223  | total loss: [1m[32m0.46570[0m[0m | time: 8.882s
[2K
| Adam | epoch: 006 | loss: 0.46570 - acc: 0.7877 -- iter: 0096/1403
[A[ATraining Step: 224  | total loss: [1m[32m0.46419[0m[0m | time: 11.102s
[2K
| Adam | epoch: 006 | loss: 0.46419 - acc: 0.7870 -- iter: 0128/1403
[A[ATraining Step: 225  | total loss: [1m[32m0.46276[0m[0m | time: 12.252s
[2K
| Adam | epoch: 006 | loss: 0.46276 - acc: 0.7898 -- iter: 0160/1403
[A[ATraining Step: 226  | total loss: [1m[32m0.46029[0m[0m | time: 13.674s
[2K
| Adam | epoch: 006 | loss: 0.46029 - acc: 0.7923 -- iter: 0192/1403
[A[ATraining Step: 227  | total loss: [1m[32m0.45606[0m[0m | time: 15.057s
[2K
| Adam | epoch: 006 | loss: 0.45606 - acc: 0.7975 -- iter: 0224/1403
[A[ATraining Step: 228  | total loss: [1m[32m0.50307[0m[0m | time: 16.461s
[2K
| Adam | epoch: 006 | loss: 0.50307 - acc: 0.7771 -- iter: 0256/1403
[A[ATraining Step: 229  | total loss: [1m[32m0.49886[0m[0m | time: 18.034s
[2K
| Adam | epoch: 006 | loss: 0.49886 - acc: 0.7712 -- iter: 0288/1403
[A[ATraining Step: 230  | total loss: [1m[32m0.51775[0m[0m | time: 19.599s
[2K
| Adam | epoch: 006 | loss: 0.51775 - acc: 0.7566 -- iter: 0320/1403
[A[ATraining Step: 231  | total loss: [1m[32m0.51189[0m[0m | time: 21.194s
[2K
| Adam | epoch: 006 | loss: 0.51189 - acc: 0.7622 -- iter: 0352/1403
[A[ATraining Step: 232  | total loss: [1m[32m0.50738[0m[0m | time: 22.743s
[2K
| Adam | epoch: 006 | loss: 0.50738 - acc: 0.7672 -- iter: 0384/1403
[A[ATraining Step: 233  | total loss: [1m[32m0.50703[0m[0m | time: 30.375s
[2K
| Adam | epoch: 006 | loss: 0.50703 - acc: 0.7655 -- iter: 0416/1403
[A[ATraining Step: 234  | total loss: [1m[32m0.48881[0m[0m | time: 34.510s
[2K
| Adam | epoch: 006 | loss: 0.48881 - acc: 0.7827 -- iter: 0448/1403
[A[ATraining Step: 235  | total loss: [1m[32m0.47668[0m[0m | time: 38.161s
[2K
| Adam | epoch: 006 | loss: 0.47668 - acc: 0.7919 -- iter: 0480/1403
[A[ATraining Step: 236  | total loss: [1m[32m0.47906[0m[0m | time: 44.762s
[2K
| Adam | epoch: 006 | loss: 0.47906 - acc: 0.7877 -- iter: 0512/1403
[A[ATraining Step: 237  | total loss: [1m[32m0.47174[0m[0m | time: 47.323s
[2K
| Adam | epoch: 006 | loss: 0.47174 - acc: 0.7933 -- iter: 0544/1403
[A[ATraining Step: 238  | total loss: [1m[32m0.47829[0m[0m | time: 54.215s
[2K
| Adam | epoch: 006 | loss: 0.47829 - acc: 0.7796 -- iter: 0576/1403
[A[ATraining Step: 239  | total loss: [1m[32m0.47045[0m[0m | time: 57.992s
[2K
| Adam | epoch: 006 | loss: 0.47045 - acc: 0.7892 -- iter: 0608/1403
[A[ATraining Step: 240  | total loss: [1m[32m0.46501[0m[0m | time: 64.183s
[2K
| Adam | epoch: 006 | loss: 0.46501 - acc: 0.7915 -- iter: 0640/1403
[A[ATraining Step: 241  | total loss: [1m[32m0.45529[0m[0m | time: 66.868s
[2K
| Adam | epoch: 006 | loss: 0.45529 - acc: 0.7967 -- iter: 0672/1403
[A[ATraining Step: 242  | total loss: [1m[32m0.45859[0m[0m | time: 70.051s
[2K
| Adam | epoch: 006 | loss: 0.45859 - acc: 0.7921 -- iter: 0704/1403
[A[ATraining Step: 243  | total loss: [1m[32m0.46038[0m[0m | time: 73.729s
[2K
| Adam | epoch: 006 | loss: 0.46038 - acc: 0.7910 -- iter: 0736/1403
[A[ATraining Step: 244  | total loss: [1m[32m0.44891[0m[0m | time: 78.032s
[2K
| Adam | epoch: 006 | loss: 0.44891 - acc: 0.7838 -- iter: 0768/1403
[A[ATraining Step: 245  | total loss: [1m[32m0.44840[0m[0m | time: 80.801s
[2K
| Adam | epoch: 006 | loss: 0.44840 - acc: 0.7866 -- iter: 0800/1403
[A[ATraining Step: 246  | total loss: [1m[32m0.43969[0m[0m | time: 84.078s
[2K
| Adam | epoch: 006 | loss: 0.43969 - acc: 0.7923 -- iter: 0832/1403
[A[ATraining Step: 247  | total loss: [1m[32m0.42312[0m[0m | time: 90.342s
[2K
| Adam | epoch: 006 | loss: 0.42312 - acc: 0.8069 -- iter: 0864/1403
[A[ATraining Step: 248  | total loss: [1m[32m0.41568[0m[0m | time: 93.901s
[2K
| Adam | epoch: 006 | loss: 0.41568 - acc: 0.8105 -- iter: 0896/1403
[A[ATraining Step: 249  | total loss: [1m[32m0.41200[0m[0m | time: 96.624s
[2K
| Adam | epoch: 006 | loss: 0.41200 - acc: 0.8170 -- iter: 0928/1403
[A[ATraining Step: 250  | total loss: [1m[32m0.41341[0m[0m | time: 98.024s
[2K
| Adam | epoch: 006 | loss: 0.41341 - acc: 0.8165 -- iter: 0960/1403
[A[ATraining Step: 251  | total loss: [1m[32m0.44758[0m[0m | time: 99.600s
[2K
| Adam | epoch: 006 | loss: 0.44758 - acc: 0.8099 -- iter: 0992/1403
[A[ATraining Step: 252  | total loss: [1m[32m0.43838[0m[0m | time: 101.183s
[2K
| Adam | epoch: 006 | loss: 0.43838 - acc: 0.8101 -- iter: 1024/1403
[A[ATraining Step: 253  | total loss: [1m[32m0.42906[0m[0m | time: 102.803s
[2K
| Adam | epoch: 006 | loss: 0.42906 - acc: 0.8166 -- iter: 1056/1403
[A[ATraining Step: 254  | total loss: [1m[32m0.42786[0m[0m | time: 104.406s
[2K
| Adam | epoch: 006 | loss: 0.42786 - acc: 0.8193 -- iter: 1088/1403
[A[ATraining Step: 255  | total loss: [1m[32m0.41543[0m[0m | time: 105.928s
[2K
| Adam | epoch: 006 | loss: 0.41543 - acc: 0.8249 -- iter: 1120/1403
[A[ATraining Step: 256  | total loss: [1m[32m0.39766[0m[0m | time: 107.544s
[2K
| Adam | epoch: 006 | loss: 0.39766 - acc: 0.8393 -- iter: 1152/1403
[A[ATraining Step: 257  | total loss: [1m[32m0.39887[0m[0m | time: 109.235s
[2K
| Adam | epoch: 006 | loss: 0.39887 - acc: 0.8304 -- iter: 1184/1403
[A[ATraining Step: 258  | total loss: [1m[32m0.39994[0m[0m | time: 110.734s
[2K
| Adam | epoch: 006 | loss: 0.39994 - acc: 0.8317 -- iter: 1216/1403
[A[ATraining Step: 259  | total loss: [1m[32m0.40423[0m[0m | time: 112.230s
[2K
| Adam | epoch: 006 | loss: 0.40423 - acc: 0.8298 -- iter: 1248/1403
[A[ATraining Step: 260  | total loss: [1m[32m0.40227[0m[0m | time: 116.121s
[2K
| Adam | epoch: 006 | loss: 0.40227 - acc: 0.8312 -- iter: 1280/1403
[A[ATraining Step: 261  | total loss: [1m[32m0.40385[0m[0m | time: 117.584s
[2K
| Adam | epoch: 006 | loss: 0.40385 - acc: 0.8293 -- iter: 1312/1403
[A[ATraining Step: 262  | total loss: [1m[32m0.40524[0m[0m | time: 122.799s
[2K
| Adam | epoch: 006 | loss: 0.40524 - acc: 0.8308 -- iter: 1344/1403
[A[ATraining Step: 263  | total loss: [1m[32m0.40048[0m[0m | time: 126.544s
[2K
| Adam | epoch: 006 | loss: 0.40048 - acc: 0.8321 -- iter: 1376/1403
[A[ATraining Step: 264  | total loss: [1m[32m0.40370[0m[0m | time: 194.170s
[2K
| Adam | epoch: 006 | loss: 0.40370 - acc: 0.8301 | val_loss: 0.40125 - val_acc: 0.8314 -- iter: 1403/1403
--
Training Step: 265  | total loss: [1m[32m0.41207[0m[0m | time: 8.994s
[2K
| Adam | epoch: 007 | loss: 0.41207 - acc: 0.8190 -- iter: 0032/1403
[A[ATraining Step: 266  | total loss: [1m[32m0.41323[0m[0m | time: 16.338s
[2K
| Adam | epoch: 007 | loss: 0.41323 - acc: 0.8183 -- iter: 0064/1403
[A[ATraining Step: 267  | total loss: [1m[32m0.42543[0m[0m | time: 21.828s
[2K
| Adam | epoch: 007 | loss: 0.42543 - acc: 0.8146 -- iter: 0096/1403
[A[ATraining Step: 268  | total loss: [1m[32m0.41160[0m[0m | time: 28.075s
[2K
| Adam | epoch: 007 | loss: 0.41160 - acc: 0.8269 -- iter: 0128/1403
[A[ATraining Step: 269  | total loss: [1m[32m0.40244[0m[0m | time: 34.993s
[2K
| Adam | epoch: 007 | loss: 0.40244 - acc: 0.8255 -- iter: 0160/1403
[A[ATraining Step: 270  | total loss: [1m[32m0.40725[0m[0m | time: 41.602s
[2K
| Adam | epoch: 007 | loss: 0.40725 - acc: 0.8244 -- iter: 0192/1403
[A[ATraining Step: 271  | total loss: [1m[32m0.40978[0m[0m | time: 46.863s
[2K
| Adam | epoch: 007 | loss: 0.40978 - acc: 0.8308 -- iter: 0224/1403
[A[ATraining Step: 272  | total loss: [1m[32m0.41539[0m[0m | time: 52.404s
[2K
| Adam | epoch: 007 | loss: 0.41539 - acc: 0.8290 -- iter: 0256/1403
[A[ATraining Step: 273  | total loss: [1m[32m0.41093[0m[0m | time: 58.597s
[2K
| Adam | epoch: 007 | loss: 0.41093 - acc: 0.8305 -- iter: 0288/1403
[A[ATraining Step: 274  | total loss: [1m[32m0.41305[0m[0m | time: 61.761s
[2K
| Adam | epoch: 007 | loss: 0.41305 - acc: 0.8256 -- iter: 0320/1403
[A[ATraining Step: 275  | total loss: [1m[32m0.41230[0m[0m | time: 65.281s
[2K
| Adam | epoch: 007 | loss: 0.41230 - acc: 0.8243 -- iter: 0352/1403
[A[ATraining Step: 276  | total loss: [1m[32m0.40613[0m[0m | time: 76.455s
[2K
| Adam | epoch: 007 | loss: 0.40613 - acc: 0.8325 -- iter: 0384/1403
[A[ATraining Step: 277  | total loss: [1m[32m0.41334[0m[0m | time: 87.317s
[2K
| Adam | epoch: 007 | loss: 0.41334 - acc: 0.8211 -- iter: 0416/1403
[A[ATraining Step: 278  | total loss: [1m[32m0.42056[0m[0m | time: 93.381s
[2K
| Adam | epoch: 007 | loss: 0.42056 - acc: 0.8140 -- iter: 0448/1403
[A[ATraining Step: 279  | total loss: [1m[32m0.42340[0m[0m | time: 103.081s
[2K
| Adam | epoch: 007 | loss: 0.42340 - acc: 0.8107 -- iter: 0480/1403
[A[ATraining Step: 280  | total loss: [1m[32m0.42335[0m[0m | time: 110.790s
[2K
| Adam | epoch: 007 | loss: 0.42335 - acc: 0.8078 -- iter: 0512/1403
[A[ATraining Step: 281  | total loss: [1m[32m0.42745[0m[0m | time: 113.859s
[2K
| Adam | epoch: 007 | loss: 0.42745 - acc: 0.8051 -- iter: 0544/1403
[A[ATraining Step: 282  | total loss: [1m[32m0.41995[0m[0m | time: 131.881s
[2K
| Adam | epoch: 007 | loss: 0.41995 - acc: 0.8121 -- iter: 0576/1403
[A[ATraining Step: 283  | total loss: [1m[32m0.40103[0m[0m | time: 138.503s
[2K
| Adam | epoch: 007 | loss: 0.40103 - acc: 0.8278 -- iter: 0608/1403
[A[ATraining Step: 284  | total loss: [1m[32m0.39194[0m[0m | time: 148.195s
[2K
| Adam | epoch: 007 | loss: 0.39194 - acc: 0.8325 -- iter: 0640/1403
[A[ATraining Step: 285  | total loss: [1m[32m0.40483[0m[0m | time: 155.878s
[2K
| Adam | epoch: 007 | loss: 0.40483 - acc: 0.8211 -- iter: 0672/1403
[A[ATraining Step: 286  | total loss: [1m[32m0.38233[0m[0m | time: 162.627s
[2K
| Adam | epoch: 007 | loss: 0.38233 - acc: 0.8328 -- iter: 0704/1403
[A[ATraining Step: 287  | total loss: [1m[32m0.37935[0m[0m | time: 173.268s
[2K
| Adam | epoch: 007 | loss: 0.37935 - acc: 0.8339 -- iter: 0736/1403
[A[ATraining Step: 288  | total loss: [1m[32m0.37558[0m[0m | time: 174.592s
[2K
| Adam | epoch: 007 | loss: 0.37558 - acc: 0.8348 -- iter: 0768/1403
[A[ATraining Step: 289  | total loss: [1m[32m0.37760[0m[0m | time: 175.821s
[2K
| Adam | epoch: 007 | loss: 0.37760 - acc: 0.8389 -- iter: 0800/1403
[A[ATraining Step: 290  | total loss: [1m[32m0.39202[0m[0m | time: 179.283s
[2K
| Adam | epoch: 007 | loss: 0.39202 - acc: 0.8331 -- iter: 0832/1403
[A[ATraining Step: 291  | total loss: [1m[32m0.38718[0m[0m | time: 185.773s
[2K
| Adam | epoch: 007 | loss: 0.38718 - acc: 0.8373 -- iter: 0864/1403
[A[ATraining Step: 292  | total loss: [1m[32m0.38331[0m[0m | time: 192.173s
[2K
| Adam | epoch: 007 | loss: 0.38331 - acc: 0.8442 -- iter: 0896/1403
[A[ATraining Step: 293  | total loss: [1m[32m0.38205[0m[0m | time: 194.150s
[2K
| Adam | epoch: 007 | loss: 0.38205 - acc: 0.8410 -- iter: 0928/1403
[A[ATraining Step: 294  | total loss: [1m[32m0.36520[0m[0m | time: 202.248s
[2K
| Adam | epoch: 007 | loss: 0.36520 - acc: 0.8475 -- iter: 0960/1403
[A[ATraining Step: 295  | total loss: [1m[32m0.36217[0m[0m | time: 216.559s
[2K
| Adam | epoch: 007 | loss: 0.36217 - acc: 0.8503 -- iter: 0992/1403
[A[ATraining Step: 296  | total loss: [1m[32m0.34531[0m[0m | time: 223.017s
[2K
| Adam | epoch: 007 | loss: 0.34531 - acc: 0.8590 -- iter: 1024/1403
[A[ATraining Step: 297  | total loss: [1m[32m0.35653[0m[0m | time: 234.511s
[2K
| Adam | epoch: 007 | loss: 0.35653 - acc: 0.8575 -- iter: 1056/1403
[A[ATraining Step: 298  | total loss: [1m[32m0.35089[0m[0m | time: 241.799s
[2K
| Adam | epoch: 007 | loss: 0.35089 - acc: 0.8624 -- iter: 1088/1403
[A[ATraining Step: 299  | total loss: [1m[32m0.34135[0m[0m | time: 252.970s
[2K
| Adam | epoch: 007 | loss: 0.34135 - acc: 0.8636 -- iter: 1120/1403
[A[ATraining Step: 300  | total loss: [1m[32m0.36198[0m[0m | time: 258.617s
[2K
| Adam | epoch: 007 | loss: 0.36198 - acc: 0.8523 -- iter: 1152/1403
[A[ATraining Step: 301  | total loss: [1m[32m0.37449[0m[0m | time: 262.805s
[2K
| Adam | epoch: 007 | loss: 0.37449 - acc: 0.8264 -- iter: 1184/1403
[A[ATraining Step: 302  | total loss: [1m[32m0.36680[0m[0m | time: 268.665s
[2K
| Adam | epoch: 007 | loss: 0.36680 - acc: 0.8313 -- iter: 1216/1403
[A[ATraining Step: 303  | total loss: [1m[32m0.36945[0m[0m | time: 275.202s
[2K
| Adam | epoch: 007 | loss: 0.36945 - acc: 0.8325 -- iter: 1248/1403
[A[ATraining Step: 304  | total loss: [1m[32m0.37119[0m[0m | time: 276.978s
[2K
| Adam | epoch: 007 | loss: 0.37119 - acc: 0.8305 -- iter: 1280/1403
[A[ATraining Step: 305  | total loss: [1m[32m0.36080[0m[0m | time: 279.410s
[2K
| Adam | epoch: 007 | loss: 0.36080 - acc: 0.8350 -- iter: 1312/1403
[A[ATraining Step: 306  | total loss: [1m[32m0.35750[0m[0m | time: 283.067s
[2K
| Adam | epoch: 007 | loss: 0.35750 - acc: 0.8358 -- iter: 1344/1403
[A[ATraining Step: 307  | total loss: [1m[32m0.34072[0m[0m | time: 291.548s
[2K
| Adam | epoch: 007 | loss: 0.34072 - acc: 0.8460 -- iter: 1376/1403
[A[ATraining Step: 308  | total loss: [1m[32m0.33669[0m[0m | time: 343.345s
[2K
| Adam | epoch: 007 | loss: 0.33669 - acc: 0.8489 | val_loss: 0.36959 - val_acc: 0.8565 -- iter: 1403/1403
--
Training Step: 309  | total loss: [1m[32m0.34239[0m[0m | time: 1.184s
[2K
| Adam | epoch: 008 | loss: 0.34239 - acc: 0.8453 -- iter: 0032/1403
[A[ATraining Step: 310  | total loss: [1m[32m0.33355[0m[0m | time: 2.512s
[2K
| Adam | epoch: 008 | loss: 0.33355 - acc: 0.8482 -- iter: 0064/1403
[A[ATraining Step: 311  | total loss: [1m[32m0.32794[0m[0m | time: 3.783s
[2K
| Adam | epoch: 008 | loss: 0.32794 - acc: 0.8509 -- iter: 0096/1403
[A[ATraining Step: 312  | total loss: [1m[32m0.32515[0m[0m | time: 5.120s
[2K
| Adam | epoch: 008 | loss: 0.32515 - acc: 0.8564 -- iter: 0128/1403
[A[ATraining Step: 313  | total loss: [1m[32m0.35653[0m[0m | time: 6.444s
[2K
| Adam | epoch: 008 | loss: 0.35653 - acc: 0.8396 -- iter: 0160/1403
[A[ATraining Step: 314  | total loss: [1m[32m0.37991[0m[0m | time: 7.525s
[2K
| Adam | epoch: 008 | loss: 0.37991 - acc: 0.8306 -- iter: 0192/1403
[A[ATraining Step: 315  | total loss: [1m[32m0.37742[0m[0m | time: 8.842s
[2K
| Adam | epoch: 008 | loss: 0.37742 - acc: 0.8364 -- iter: 0224/1403
[A[ATraining Step: 316  | total loss: [1m[32m0.37256[0m[0m | time: 10.289s
[2K
| Adam | epoch: 008 | loss: 0.37256 - acc: 0.8380 -- iter: 0256/1403
[A[ATraining Step: 317  | total loss: [1m[32m0.37826[0m[0m | time: 11.714s
[2K
| Adam | epoch: 008 | loss: 0.37826 - acc: 0.8260 -- iter: 0288/1403
[A[ATraining Step: 318  | total loss: [1m[32m0.42284[0m[0m | time: 15.573s
[2K
| Adam | epoch: 008 | loss: 0.42284 - acc: 0.8028 -- iter: 0320/1403
[A[ATraining Step: 319  | total loss: [1m[32m0.42938[0m[0m | time: 18.117s
[2K
| Adam | epoch: 008 | loss: 0.42938 - acc: 0.7975 -- iter: 0352/1403
[A[ATraining Step: 320  | total loss: [1m[32m0.42269[0m[0m | time: 23.831s
[2K
| Adam | epoch: 008 | loss: 0.42269 - acc: 0.7990 -- iter: 0384/1403
[A[ATraining Step: 321  | total loss: [1m[32m0.41123[0m[0m | time: 28.607s
[2K
| Adam | epoch: 008 | loss: 0.41123 - acc: 0.8066 -- iter: 0416/1403
[A[ATraining Step: 322  | total loss: [1m[32m0.44230[0m[0m | time: 31.997s
[2K
| Adam | epoch: 008 | loss: 0.44230 - acc: 0.7885 -- iter: 0448/1403
[A[ATraining Step: 323  | total loss: [1m[32m0.43391[0m[0m | time: 36.584s
[2K
| Adam | epoch: 008 | loss: 0.43391 - acc: 0.8002 -- iter: 0480/1403
[A[ATraining Step: 324  | total loss: [1m[32m0.42771[0m[0m | time: 43.043s
[2K
| Adam | epoch: 008 | loss: 0.42771 - acc: 0.8046 -- iter: 0512/1403
[A[ATraining Step: 325  | total loss: [1m[32m0.42877[0m[0m | time: 49.637s
[2K
| Adam | epoch: 008 | loss: 0.42877 - acc: 0.8085 -- iter: 0544/1403
[A[ATraining Step: 326  | total loss: [1m[32m0.42943[0m[0m | time: 51.808s
[2K
| Adam | epoch: 008 | loss: 0.42943 - acc: 0.8027 -- iter: 0576/1403
[A[ATraining Step: 327  | total loss: [1m[32m0.42487[0m[0m | time: 53.023s
[2K
| Adam | epoch: 008 | loss: 0.42487 - acc: 0.8068 -- iter: 0608/1403
[A[ATraining Step: 328  | total loss: [1m[32m0.41126[0m[0m | time: 54.029s
[2K
| Adam | epoch: 008 | loss: 0.41126 - acc: 0.8136 -- iter: 0640/1403
[A[ATraining Step: 329  | total loss: [1m[32m0.41466[0m[0m | time: 55.188s
[2K
| Adam | epoch: 008 | loss: 0.41466 - acc: 0.8072 -- iter: 0672/1403
[A[ATraining Step: 330  | total loss: [1m[32m0.41729[0m[0m | time: 56.456s
[2K
| Adam | epoch: 008 | loss: 0.41729 - acc: 0.8078 -- iter: 0704/1403
[A[ATraining Step: 331  | total loss: [1m[32m0.40211[0m[0m | time: 57.791s
[2K
| Adam | epoch: 008 | loss: 0.40211 - acc: 0.8176 -- iter: 0736/1403
[A[ATraining Step: 332  | total loss: [1m[32m0.39286[0m[0m | time: 59.047s
[2K
| Adam | epoch: 008 | loss: 0.39286 - acc: 0.8233 -- iter: 0768/1403
[A[ATraining Step: 333  | total loss: [1m[32m0.37958[0m[0m | time: 60.355s
[2K
| Adam | epoch: 008 | loss: 0.37958 - acc: 0.8316 -- iter: 0800/1403
[A[ATraining Step: 334  | total loss: [1m[32m0.38087[0m[0m | time: 61.586s
[2K
| Adam | epoch: 008 | loss: 0.38087 - acc: 0.8266 -- iter: 0832/1403
[A[ATraining Step: 335  | total loss: [1m[32m0.39172[0m[0m | time: 62.923s
[2K
| Adam | epoch: 008 | loss: 0.39172 - acc: 0.8189 -- iter: 0864/1403
[A[ATraining Step: 336  | total loss: [1m[32m0.38639[0m[0m | time: 64.341s
[2K
| Adam | epoch: 008 | loss: 0.38639 - acc: 0.8214 -- iter: 0896/1403
[A[ATraining Step: 337  | total loss: [1m[32m0.37799[0m[0m | time: 65.709s
[2K
| Adam | epoch: 008 | loss: 0.37799 - acc: 0.8299 -- iter: 0928/1403
[A[ATraining Step: 338  | total loss: [1m[32m0.36770[0m[0m | time: 68.405s
[2K
| Adam | epoch: 008 | loss: 0.36770 - acc: 0.8344 -- iter: 0960/1403
[A[ATraining Step: 339  | total loss: [1m[32m0.37242[0m[0m | time: 72.432s
[2K
| Adam | epoch: 008 | loss: 0.37242 - acc: 0.8385 -- iter: 0992/1403
[A[ATraining Step: 340  | total loss: [1m[32m0.35927[0m[0m | time: 76.688s
[2K
| Adam | epoch: 008 | loss: 0.35927 - acc: 0.8484 -- iter: 1024/1403
[A[ATraining Step: 341  | total loss: [1m[32m0.34402[0m[0m | time: 83.327s
[2K
| Adam | epoch: 008 | loss: 0.34402 - acc: 0.8542 -- iter: 1056/1403
[A[ATraining Step: 342  | total loss: [1m[32m0.34790[0m[0m | time: 87.318s
[2K
| Adam | epoch: 008 | loss: 0.34790 - acc: 0.8531 -- iter: 1088/1403
[A[ATraining Step: 343  | total loss: [1m[32m0.34963[0m[0m | time: 92.248s
[2K
| Adam | epoch: 008 | loss: 0.34963 - acc: 0.8491 -- iter: 1120/1403
[A[ATraining Step: 344  | total loss: [1m[32m0.34796[0m[0m | time: 97.394s
[2K
| Adam | epoch: 008 | loss: 0.34796 - acc: 0.8548 -- iter: 1152/1403
[A[ATraining Step: 345  | total loss: [1m[32m0.33273[0m[0m | time: 98.510s
[2K
| Adam | epoch: 008 | loss: 0.33273 - acc: 0.8568 -- iter: 1184/1403
[A[ATraining Step: 346  | total loss: [1m[32m0.32394[0m[0m | time: 99.609s
[2K
| Adam | epoch: 008 | loss: 0.32394 - acc: 0.8586 -- iter: 1216/1403
[A[ATraining Step: 347  | total loss: [1m[32m0.32219[0m[0m | time: 100.856s
[2K
| Adam | epoch: 008 | loss: 0.32219 - acc: 0.8571 -- iter: 1248/1403
[A[ATraining Step: 348  | total loss: [1m[32m0.33078[0m[0m | time: 102.132s
[2K
| Adam | epoch: 008 | loss: 0.33078 - acc: 0.8527 -- iter: 1280/1403
[A[ATraining Step: 349  | total loss: [1m[32m0.31154[0m[0m | time: 103.424s
[2K
| Adam | epoch: 008 | loss: 0.31154 - acc: 0.8643 -- iter: 1312/1403
[A[ATraining Step: 350  | total loss: [1m[32m0.30369[0m[0m | time: 104.647s
[2K
| Adam | epoch: 008 | loss: 0.30369 - acc: 0.8685 -- iter: 1344/1403
[A[ATraining Step: 351  | total loss: [1m[32m0.31441[0m[0m | time: 105.954s
[2K
| Adam | epoch: 008 | loss: 0.31441 - acc: 0.8660 -- iter: 1376/1403
[A[ATraining Step: 352  | total loss: [1m[32m0.32477[0m[0m | time: 110.812s
[2K
| Adam | epoch: 008 | loss: 0.32477 - acc: 0.8607 | val_loss: 0.34637 - val_acc: 0.8793 -- iter: 1403/1403
--
Training Step: 353  | total loss: [1m[32m0.31997[0m[0m | time: 9.993s
[2K
| Adam | epoch: 009 | loss: 0.31997 - acc: 0.8683 -- iter: 0032/1403
[A[ATraining Step: 354  | total loss: [1m[32m0.32431[0m[0m | time: 14.191s
[2K
| Adam | epoch: 009 | loss: 0.32431 - acc: 0.8659 -- iter: 0064/1403
[A[ATraining Step: 355  | total loss: [1m[32m0.31735[0m[0m | time: 18.495s
[2K
| Adam | epoch: 009 | loss: 0.31735 - acc: 0.8668 -- iter: 0096/1403
[A[ATraining Step: 356  | total loss: [1m[32m0.32691[0m[0m | time: 26.020s
[2K
| Adam | epoch: 009 | loss: 0.32691 - acc: 0.8676 -- iter: 0128/1403
[A[ATraining Step: 357  | total loss: [1m[32m0.32835[0m[0m | time: 31.096s
[2K
| Adam | epoch: 009 | loss: 0.32835 - acc: 0.8621 -- iter: 0160/1403
[A[ATraining Step: 358  | total loss: [1m[32m0.32867[0m[0m | time: 37.251s
[2K
| Adam | epoch: 009 | loss: 0.32867 - acc: 0.8634 -- iter: 0192/1403
[A[ATraining Step: 359  | total loss: [1m[32m0.33763[0m[0m | time: 40.262s
[2K
| Adam | epoch: 009 | loss: 0.33763 - acc: 0.8583 -- iter: 0224/1403
[A[ATraining Step: 360  | total loss: [1m[32m0.31840[0m[0m | time: 46.103s
[2K
| Adam | epoch: 009 | loss: 0.31840 - acc: 0.8688 -- iter: 0256/1403
[A[ATraining Step: 361  | total loss: [1m[32m0.29916[0m[0m | time: 47.054s
[2K
| Adam | epoch: 009 | loss: 0.29916 - acc: 0.8782 -- iter: 0288/1403
[A[ATraining Step: 362  | total loss: [1m[32m0.30939[0m[0m | time: 48.185s
[2K
| Adam | epoch: 009 | loss: 0.30939 - acc: 0.8779 -- iter: 0320/1403
[A[ATraining Step: 363  | total loss: [1m[32m0.31375[0m[0m | time: 49.463s
[2K
| Adam | epoch: 009 | loss: 0.31375 - acc: 0.8745 -- iter: 0352/1403
[A[ATraining Step: 364  | total loss: [1m[32m0.30839[0m[0m | time: 50.802s
[2K
| Adam | epoch: 009 | loss: 0.30839 - acc: 0.8808 -- iter: 0384/1403
[A[ATraining Step: 365  | total loss: [1m[32m0.31283[0m[0m | time: 52.133s
[2K
| Adam | epoch: 009 | loss: 0.31283 - acc: 0.8802 -- iter: 0416/1403
[A[ATraining Step: 366  | total loss: [1m[32m0.30683[0m[0m | time: 53.447s
[2K
| Adam | epoch: 009 | loss: 0.30683 - acc: 0.8828 -- iter: 0448/1403
[A[ATraining Step: 367  | total loss: [1m[32m0.32257[0m[0m | time: 54.772s
[2K
| Adam | epoch: 009 | loss: 0.32257 - acc: 0.8664 -- iter: 0480/1403
[A[ATraining Step: 368  | total loss: [1m[32m0.32005[0m[0m | time: 56.081s
[2K
| Adam | epoch: 009 | loss: 0.32005 - acc: 0.8641 -- iter: 0512/1403
[A[ATraining Step: 369  | total loss: [1m[32m0.31991[0m[0m | time: 57.561s
[2K
| Adam | epoch: 009 | loss: 0.31991 - acc: 0.8683 -- iter: 0544/1403
[A[ATraining Step: 370  | total loss: [1m[32m0.32511[0m[0m | time: 59.025s
[2K
| Adam | epoch: 009 | loss: 0.32511 - acc: 0.8628 -- iter: 0576/1403
[A[ATraining Step: 371  | total loss: [1m[32m0.32182[0m[0m | time: 63.333s
[2K
| Adam | epoch: 009 | loss: 0.32182 - acc: 0.8671 -- iter: 0608/1403
[A[ATraining Step: 372  | total loss: [1m[32m0.32824[0m[0m | time: 69.387s
[2K
| Adam | epoch: 009 | loss: 0.32824 - acc: 0.8585 -- iter: 0640/1403
[A[ATraining Step: 373  | total loss: [1m[32m0.33381[0m[0m | time: 76.830s
[2K
| Adam | epoch: 009 | loss: 0.33381 - acc: 0.8633 -- iter: 0672/1403
[A[ATraining Step: 374  | total loss: [1m[32m0.32955[0m[0m | time: 82.560s
[2K
| Adam | epoch: 009 | loss: 0.32955 - acc: 0.8676 -- iter: 0704/1403
[A[ATraining Step: 375  | total loss: [1m[32m0.32401[0m[0m | time: 88.522s
[2K
| Adam | epoch: 009 | loss: 0.32401 - acc: 0.8683 -- iter: 0736/1403
[A[ATraining Step: 376  | total loss: [1m[32m0.33089[0m[0m | time: 90.983s
[2K
| Adam | epoch: 009 | loss: 0.33089 - acc: 0.8596 -- iter: 0768/1403
[A[ATraining Step: 377  | total loss: [1m[32m0.32082[0m[0m | time: 95.213s
[2K
| Adam | epoch: 009 | loss: 0.32082 - acc: 0.8674 -- iter: 0800/1403
[A[ATraining Step: 378  | total loss: [1m[32m0.30739[0m[0m | time: 99.796s
[2K
| Adam | epoch: 009 | loss: 0.30739 - acc: 0.8775 -- iter: 0832/1403
[A[ATraining Step: 379  | total loss: [1m[32m0.30534[0m[0m | time: 103.135s
[2K
| Adam | epoch: 009 | loss: 0.30534 - acc: 0.8804 -- iter: 0864/1403
[A[ATraining Step: 380  | total loss: [1m[32m0.29851[0m[0m | time: 109.150s
[2K
| Adam | epoch: 009 | loss: 0.29851 - acc: 0.8830 -- iter: 0896/1403
[A[ATraining Step: 381  | total loss: [1m[32m0.30661[0m[0m | time: 116.817s
[2K
| Adam | epoch: 009 | loss: 0.30661 - acc: 0.8759 -- iter: 0928/1403
[A[ATraining Step: 382  | total loss: [1m[32m0.29328[0m[0m | time: 118.589s
[2K
| Adam | epoch: 009 | loss: 0.29328 - acc: 0.8852 -- iter: 0960/1403
[A[ATraining Step: 383  | total loss: [1m[32m0.28530[0m[0m | time: 122.977s
[2K
| Adam | epoch: 009 | loss: 0.28530 - acc: 0.8873 -- iter: 0992/1403
[A[ATraining Step: 384  | total loss: [1m[32m0.28002[0m[0m | time: 125.584s
[2K
| Adam | epoch: 009 | loss: 0.28002 - acc: 0.8861 -- iter: 1024/1403
[A[ATraining Step: 385  | total loss: [1m[32m0.26383[0m[0m | time: 134.832s
[2K
| Adam | epoch: 009 | loss: 0.26383 - acc: 0.8975 -- iter: 1056/1403
[A[ATraining Step: 386  | total loss: [1m[32m0.27048[0m[0m | time: 138.551s
[2K
| Adam | epoch: 009 | loss: 0.27048 - acc: 0.8890 -- iter: 1088/1403
[A[ATraining Step: 387  | total loss: [1m[32m0.28936[0m[0m | time: 148.201s
[2K
| Adam | epoch: 009 | loss: 0.28936 - acc: 0.8813 -- iter: 1120/1403
[A[ATraining Step: 388  | total loss: [1m[32m0.28201[0m[0m | time: 149.427s
[2K
| Adam | epoch: 009 | loss: 0.28201 - acc: 0.8870 -- iter: 1152/1403
[A[ATraining Step: 389  | total loss: [1m[32m0.30465[0m[0m | time: 150.652s
[2K
| Adam | epoch: 009 | loss: 0.30465 - acc: 0.8764 -- iter: 1184/1403
[A[ATraining Step: 390  | total loss: [1m[32m0.30026[0m[0m | time: 151.894s
[2K
| Adam | epoch: 009 | loss: 0.30026 - acc: 0.8762 -- iter: 1216/1403
[A[ATraining Step: 391  | total loss: [1m[32m0.30168[0m[0m | time: 153.187s
[2K
| Adam | epoch: 009 | loss: 0.30168 - acc: 0.8761 -- iter: 1248/1403
[A[ATraining Step: 392  | total loss: [1m[32m0.30609[0m[0m | time: 154.515s
[2K
| Adam | epoch: 009 | loss: 0.30609 - acc: 0.8729 -- iter: 1280/1403
[A[ATraining Step: 393  | total loss: [1m[32m0.30039[0m[0m | time: 155.881s
[2K
| Adam | epoch: 009 | loss: 0.30039 - acc: 0.8731 -- iter: 1312/1403
[A[ATraining Step: 394  | total loss: [1m[32m0.28551[0m[0m | time: 157.112s
[2K
| Adam | epoch: 009 | loss: 0.28551 - acc: 0.8795 -- iter: 1344/1403
[A[ATraining Step: 395  | total loss: [1m[32m0.29393[0m[0m | time: 158.528s
[2K
| Adam | epoch: 009 | loss: 0.29393 - acc: 0.8822 -- iter: 1376/1403
[A[ATraining Step: 396  | total loss: [1m[32m0.28617[0m[0m | time: 168.101s
[2K
| Adam | epoch: 009 | loss: 0.28617 - acc: 0.8846 | val_loss: 0.36722 - val_acc: 0.8474 -- iter: 1403/1403
--
Training Step: 397  | total loss: [1m[32m0.27691[0m[0m | time: 1.987s
[2K
| Adam | epoch: 010 | loss: 0.27691 - acc: 0.8899 -- iter: 0032/1403
[A[ATraining Step: 398  | total loss: [1m[32m0.29216[0m[0m | time: 6.584s
[2K
| Adam | epoch: 010 | loss: 0.29216 - acc: 0.8822 -- iter: 0064/1403
[A[ATraining Step: 399  | total loss: [1m[32m0.29143[0m[0m | time: 7.804s
[2K
| Adam | epoch: 010 | loss: 0.29143 - acc: 0.8846 -- iter: 0096/1403
[A[ATraining Step: 400  | total loss: [1m[32m0.28395[0m[0m | time: 12.829s
[2K
| Adam | epoch: 010 | loss: 0.28395 - acc: 0.8867 | val_loss: 0.33398 - val_acc: 0.8610 -- iter: 0128/1403
--
Training Step: 401  | total loss: [1m[32m0.27030[0m[0m | time: 14.153s
[2K
| Adam | epoch: 010 | loss: 0.27030 - acc: 0.8949 -- iter: 0160/1403
[A[ATraining Step: 402  | total loss: [1m[32m0.28189[0m[0m | time: 15.706s
[2K
| Adam | epoch: 010 | loss: 0.28189 - acc: 0.8898 -- iter: 0192/1403
[A[ATraining Step: 403  | total loss: [1m[32m0.26890[0m[0m | time: 16.947s
[2K
| Adam | epoch: 010 | loss: 0.26890 - acc: 0.8977 -- iter: 0224/1403
[A[ATraining Step: 404  | total loss: [1m[32m0.27403[0m[0m | time: 18.092s
[2K
| Adam | epoch: 010 | loss: 0.27403 - acc: 0.8954 -- iter: 0256/1403
[A[ATraining Step: 405  | total loss: [1m[32m0.26322[0m[0m | time: 19.306s
[2K
| Adam | epoch: 010 | loss: 0.26322 - acc: 0.9059 -- iter: 0288/1403
[A[ATraining Step: 406  | total loss: [1m[32m0.25147[0m[0m | time: 20.578s
[2K
| Adam | epoch: 010 | loss: 0.25147 - acc: 0.9116 -- iter: 0320/1403
[A[ATraining Step: 407  | total loss: [1m[32m0.24990[0m[0m | time: 21.704s
[2K
| Adam | epoch: 010 | loss: 0.24990 - acc: 0.9142 -- iter: 0352/1403
[A[ATraining Step: 408  | total loss: [1m[32m0.26290[0m[0m | time: 25.450s
[2K
| Adam | epoch: 010 | loss: 0.26290 - acc: 0.9071 -- iter: 0384/1403
[A[ATraining Step: 409  | total loss: [1m[32m0.25905[0m[0m | time: 31.845s
[2K
| Adam | epoch: 010 | loss: 0.25905 - acc: 0.9102 -- iter: 0416/1403
[A[ATraining Step: 410  | total loss: [1m[32m0.27282[0m[0m | time: 35.878s
[2K
| Adam | epoch: 010 | loss: 0.27282 - acc: 0.9035 -- iter: 0448/1403
[A[ATraining Step: 411  | total loss: [1m[32m0.25800[0m[0m | time: 41.296s
[2K
| Adam | epoch: 010 | loss: 0.25800 - acc: 0.9101 -- iter: 0480/1403
[A[ATraining Step: 412  | total loss: [1m[32m0.24701[0m[0m | time: 43.911s
[2K
| Adam | epoch: 010 | loss: 0.24701 - acc: 0.9159 -- iter: 0512/1403
[A[ATraining Step: 413  | total loss: [1m[32m0.25196[0m[0m | time: 45.085s
[2K
| Adam | epoch: 010 | loss: 0.25196 - acc: 0.9150 -- iter: 0544/1403
[A[ATraining Step: 414  | total loss: [1m[32m0.24928[0m[0m | time: 46.307s
[2K
| Adam | epoch: 010 | loss: 0.24928 - acc: 0.9172 -- iter: 0576/1403
[A[ATraining Step: 415  | total loss: [1m[32m0.25796[0m[0m | time: 47.420s
[2K
| Adam | epoch: 010 | loss: 0.25796 - acc: 0.9067 -- iter: 0608/1403
[A[ATraining Step: 416  | total loss: [1m[32m0.25801[0m[0m | time: 48.679s
[2K
| Adam | epoch: 010 | loss: 0.25801 - acc: 0.9036 -- iter: 0640/1403
[A[ATraining Step: 417  | total loss: [1m[32m0.26372[0m[0m | time: 49.961s
[2K
| Adam | epoch: 010 | loss: 0.26372 - acc: 0.8976 -- iter: 0672/1403
[A[ATraining Step: 418  | total loss: [1m[32m0.26977[0m[0m | time: 51.245s
[2K
| Adam | epoch: 010 | loss: 0.26977 - acc: 0.9016 -- iter: 0704/1403
[A[ATraining Step: 419  | total loss: [1m[32m0.25902[0m[0m | time: 52.582s
[2K
| Adam | epoch: 010 | loss: 0.25902 - acc: 0.9020 -- iter: 0736/1403
[A[ATraining Step: 420  | total loss: [1m[32m0.25994[0m[0m | time: 53.935s
[2K
| Adam | epoch: 010 | loss: 0.25994 - acc: 0.9025 -- iter: 0768/1403
[A[ATraining Step: 421  | total loss: [1m[32m0.24860[0m[0m | time: 55.323s
[2K
| Adam | epoch: 010 | loss: 0.24860 - acc: 0.9028 -- iter: 0800/1403
[A[ATraining Step: 422  | total loss: [1m[32m0.23255[0m[0m | time: 56.756s
[2K
| Adam | epoch: 010 | loss: 0.23255 - acc: 0.9126 -- iter: 0832/1403
[A[ATraining Step: 423  | total loss: [1m[32m0.21827[0m[0m | time: 58.094s
[2K
| Adam | epoch: 010 | loss: 0.21827 - acc: 0.9213 -- iter: 0864/1403
[A[ATraining Step: 424  | total loss: [1m[32m0.20257[0m[0m | time: 59.447s
[2K
| Adam | epoch: 010 | loss: 0.20257 - acc: 0.9292 -- iter: 0896/1403
[A[ATraining Step: 425  | total loss: [1m[32m0.19408[0m[0m | time: 64.577s
[2K
| Adam | epoch: 010 | loss: 0.19408 - acc: 0.9331 -- iter: 0928/1403
[A[ATraining Step: 426  | total loss: [1m[32m0.19281[0m[0m | time: 68.054s
[2K
| Adam | epoch: 010 | loss: 0.19281 - acc: 0.9336 -- iter: 0960/1403
[A[ATraining Step: 427  | total loss: [1m[32m0.18391[0m[0m | time: 72.890s
[2K
| Adam | epoch: 010 | loss: 0.18391 - acc: 0.9371 -- iter: 0992/1403
[A[ATraining Step: 428  | total loss: [1m[32m0.18728[0m[0m | time: 76.978s
[2K
| Adam | epoch: 010 | loss: 0.18728 - acc: 0.9309 -- iter: 1024/1403
[A[ATraining Step: 429  | total loss: [1m[32m0.18391[0m[0m | time: 81.236s
[2K
| Adam | epoch: 010 | loss: 0.18391 - acc: 0.9378 -- iter: 1056/1403
[A[ATraining Step: 430  | total loss: [1m[32m0.20230[0m[0m | time: 85.086s
[2K
| Adam | epoch: 010 | loss: 0.20230 - acc: 0.9284 -- iter: 1088/1403
[A[ATraining Step: 431  | total loss: [1m[32m0.19503[0m[0m | time: 86.328s
[2K
| Adam | epoch: 010 | loss: 0.19503 - acc: 0.9324 -- iter: 1120/1403
[A[ATraining Step: 432  | total loss: [1m[32m0.19228[0m[0m | time: 87.512s
[2K
| Adam | epoch: 010 | loss: 0.19228 - acc: 0.9361 -- iter: 1152/1403
[A[ATraining Step: 433  | total loss: [1m[32m0.19360[0m[0m | time: 88.634s
[2K
| Adam | epoch: 010 | loss: 0.19360 - acc: 0.9331 -- iter: 1184/1403
[A[ATraining Step: 434  | total loss: [1m[32m0.19334[0m[0m | time: 89.852s
[2K
| Adam | epoch: 010 | loss: 0.19334 - acc: 0.9304 -- iter: 1216/1403
[A[ATraining Step: 435  | total loss: [1m[32m0.19611[0m[0m | time: 91.115s
[2K
| Adam | epoch: 010 | loss: 0.19611 - acc: 0.9311 -- iter: 1248/1403
[A[ATraining Step: 436  | total loss: [1m[32m0.19064[0m[0m | time: 92.367s
[2K
| Adam | epoch: 010 | loss: 0.19064 - acc: 0.9349 -- iter: 1280/1403
[A[ATraining Step: 437  | total loss: [1m[32m0.20057[0m[0m | time: 93.597s
[2K
| Adam | epoch: 010 | loss: 0.20057 - acc: 0.9320 -- iter: 1312/1403
[A[ATraining Step: 438  | total loss: [1m[32m0.19906[0m[0m | time: 95.106s
[2K
| Adam | epoch: 010 | loss: 0.19906 - acc: 0.9294 -- iter: 1344/1403
[A[ATraining Step: 439  | total loss: [1m[32m0.19507[0m[0m | time: 96.328s
[2K
| Adam | epoch: 010 | loss: 0.19507 - acc: 0.9302 -- iter: 1376/1403
[A[ATraining Step: 440  | total loss: [1m[32m0.19165[0m[0m | time: 115.685s
[2K
| Adam | epoch: 010 | loss: 0.19165 - acc: 0.9247 | val_loss: 0.34592 - val_acc: 0.8679 -- iter: 1403/1403
--
Training Step: 441  | total loss: [1m[32m0.20556[0m[0m | time: 1.238s
[2K
| Adam | epoch: 011 | loss: 0.20556 - acc: 0.9229 -- iter: 0032/1403
[A[ATraining Step: 442  | total loss: [1m[32m0.19605[0m[0m | time: 2.554s
[2K
| Adam | epoch: 011 | loss: 0.19605 - acc: 0.9306 -- iter: 0064/1403
[A[ATraining Step: 443  | total loss: [1m[32m0.20479[0m[0m | time: 3.951s
[2K
| Adam | epoch: 011 | loss: 0.20479 - acc: 0.9250 -- iter: 0096/1403
[A[ATraining Step: 444  | total loss: [1m[32m0.19676[0m[0m | time: 5.273s
[2K
| Adam | epoch: 011 | loss: 0.19676 - acc: 0.9294 -- iter: 0128/1403
[A[ATraining Step: 445  | total loss: [1m[32m0.20779[0m[0m | time: 6.622s
[2K
| Adam | epoch: 011 | loss: 0.20779 - acc: 0.9240 -- iter: 0160/1403
[A[ATraining Step: 446  | total loss: [1m[32m0.22504[0m[0m | time: 8.004s
[2K
| Adam | epoch: 011 | loss: 0.22504 - acc: 0.9159 -- iter: 0192/1403
[A[ATraining Step: 447  | total loss: [1m[32m0.25428[0m[0m | time: 9.299s
[2K
| Adam | epoch: 011 | loss: 0.25428 - acc: 0.9056 -- iter: 0224/1403
[A[ATraining Step: 448  | total loss: [1m[32m0.28370[0m[0m | time: 10.354s
[2K
| Adam | epoch: 011 | loss: 0.28370 - acc: 0.8932 -- iter: 0256/1403
[A[ATraining Step: 449  | total loss: [1m[32m0.28476[0m[0m | time: 11.210s
[2K
| Adam | epoch: 011 | loss: 0.28476 - acc: 0.8913 -- iter: 0288/1403
[A[ATraining Step: 450  | total loss: [1m[32m0.27174[0m[0m | time: 12.458s
[2K
| Adam | epoch: 011 | loss: 0.27174 - acc: 0.8985 -- iter: 0320/1403
[A[ATraining Step: 451  | total loss: [1m[32m0.25950[0m[0m | time: 13.820s
[2K
| Adam | epoch: 011 | loss: 0.25950 - acc: 0.9049 -- iter: 0352/1403
[A[ATraining Step: 452  | total loss: [1m[32m0.24651[0m[0m | time: 16.578s
[2K
| Adam | epoch: 011 | loss: 0.24651 - acc: 0.9082 -- iter: 0384/1403
[A[ATraining Step: 453  | total loss: [1m[32m0.25469[0m[0m | time: 17.983s
[2K
| Adam | epoch: 011 | loss: 0.25469 - acc: 0.9080 -- iter: 0416/1403
[A[ATraining Step: 454  | total loss: [1m[32m0.24643[0m[0m | time: 23.320s
[2K
| Adam | epoch: 011 | loss: 0.24643 - acc: 0.9110 -- iter: 0448/1403
[A[ATraining Step: 455  | total loss: [1m[32m0.23412[0m[0m | time: 27.425s
[2K
| Adam | epoch: 011 | loss: 0.23412 - acc: 0.9167 -- iter: 0480/1403
[A[ATraining Step: 456  | total loss: [1m[32m0.23816[0m[0m | time: 30.490s
[2K
| Adam | epoch: 011 | loss: 0.23816 - acc: 0.9188 -- iter: 0512/1403
[A[ATraining Step: 457  | total loss: [1m[32m0.23756[0m[0m | time: 35.133s
[2K
| Adam | epoch: 011 | loss: 0.23756 - acc: 0.9176 -- iter: 0544/1403
[A[ATraining Step: 458  | total loss: [1m[32m0.24643[0m[0m | time: 39.973s
[2K
| Adam | epoch: 011 | loss: 0.24643 - acc: 0.9133 -- iter: 0576/1403
[A[ATraining Step: 459  | total loss: [1m[32m0.23868[0m[0m | time: 47.604s
[2K
| Adam | epoch: 011 | loss: 0.23868 - acc: 0.9188 -- iter: 0608/1403
[A[ATraining Step: 460  | total loss: [1m[32m0.23334[0m[0m | time: 52.218s
[2K
| Adam | epoch: 011 | loss: 0.23334 - acc: 0.9176 -- iter: 0640/1403
[A[ATraining Step: 461  | total loss: [1m[32m0.23215[0m[0m | time: 53.645s
[2K
| Adam | epoch: 011 | loss: 0.23215 - acc: 0.9165 -- iter: 0672/1403
[A[ATraining Step: 462  | total loss: [1m[32m0.24466[0m[0m | time: 55.161s
[2K
| Adam | epoch: 011 | loss: 0.24466 - acc: 0.9154 -- iter: 0704/1403
[A[ATraining Step: 463  | total loss: [1m[32m0.32843[0m[0m | time: 56.627s
[2K
| Adam | epoch: 011 | loss: 0.32843 - acc: 0.8895 -- iter: 0736/1403
[A[ATraining Step: 464  | total loss: [1m[32m0.30512[0m[0m | time: 58.000s
[2K
| Adam | epoch: 011 | loss: 0.30512 - acc: 0.8974 -- iter: 0768/1403
[A[ATraining Step: 465  | total loss: [1m[32m0.30181[0m[0m | time: 59.428s
[2K
| Adam | epoch: 011 | loss: 0.30181 - acc: 0.8983 -- iter: 0800/1403
[A[ATraining Step: 466  | total loss: [1m[32m0.28480[0m[0m | time: 60.798s
[2K
| Adam | epoch: 011 | loss: 0.28480 - acc: 0.9054 -- iter: 0832/1403
[A[ATraining Step: 467  | total loss: [1m[32m0.28030[0m[0m | time: 62.356s
[2K
| Adam | epoch: 011 | loss: 0.28030 - acc: 0.9055 -- iter: 0864/1403
[A[ATraining Step: 468  | total loss: [1m[32m0.27336[0m[0m | time: 63.858s
[2K
| Adam | epoch: 011 | loss: 0.27336 - acc: 0.9118 -- iter: 0896/1403
[A[ATraining Step: 469  | total loss: [1m[32m0.26343[0m[0m | time: 65.374s
[2K
| Adam | epoch: 011 | loss: 0.26343 - acc: 0.9175 -- iter: 0928/1403
[A[ATraining Step: 470  | total loss: [1m[32m0.27050[0m[0m | time: 66.804s
[2K
| Adam | epoch: 011 | loss: 0.27050 - acc: 0.9132 -- iter: 0960/1403
[A[ATraining Step: 471  | total loss: [1m[32m0.25760[0m[0m | time: 68.312s
[2K
| Adam | epoch: 011 | loss: 0.25760 - acc: 0.9188 -- iter: 0992/1403
[A[ATraining Step: 472  | total loss: [1m[32m0.25356[0m[0m | time: 69.733s
[2K
| Adam | epoch: 011 | loss: 0.25356 - acc: 0.9175 -- iter: 1024/1403
[A[ATraining Step: 473  | total loss: [1m[32m0.24912[0m[0m | time: 73.113s
[2K
| Adam | epoch: 011 | loss: 0.24912 - acc: 0.9227 -- iter: 1056/1403
[A[ATraining Step: 474  | total loss: [1m[32m0.23736[0m[0m | time: 77.517s
[2K
| Adam | epoch: 011 | loss: 0.23736 - acc: 0.9304 -- iter: 1088/1403
[A[ATraining Step: 475  | total loss: [1m[32m0.24661[0m[0m | time: 78.565s
[2K
| Adam | epoch: 011 | loss: 0.24661 - acc: 0.9248 -- iter: 1120/1403
[A[ATraining Step: 476  | total loss: [1m[32m0.25043[0m[0m | time: 79.574s
[2K
| Adam | epoch: 011 | loss: 0.25043 - acc: 0.9261 -- iter: 1152/1403
[A[ATraining Step: 477  | total loss: [1m[32m0.23600[0m[0m | time: 80.644s
[2K
| Adam | epoch: 011 | loss: 0.23600 - acc: 0.9304 -- iter: 1184/1403
[A[ATraining Step: 478  | total loss: [1m[32m0.23088[0m[0m | time: 81.697s
[2K
| Adam | epoch: 011 | loss: 0.23088 - acc: 0.9311 -- iter: 1216/1403
[A[ATraining Step: 479  | total loss: [1m[32m0.21488[0m[0m | time: 82.769s
[2K
| Adam | epoch: 011 | loss: 0.21488 - acc: 0.9349 -- iter: 1248/1403
[A[ATraining Step: 480  | total loss: [1m[32m0.21185[0m[0m | time: 83.825s
[2K
| Adam | epoch: 011 | loss: 0.21185 - acc: 0.9382 -- iter: 1280/1403
[A[ATraining Step: 481  | total loss: [1m[32m0.19955[0m[0m | time: 84.766s
[2K
| Adam | epoch: 011 | loss: 0.19955 - acc: 0.9444 -- iter: 1312/1403
[A[ATraining Step: 482  | total loss: [1m[32m0.18918[0m[0m | time: 85.756s
[2K
| Adam | epoch: 011 | loss: 0.18918 - acc: 0.9469 -- iter: 1344/1403
[A[ATraining Step: 483  | total loss: [1m[32m0.19936[0m[0m | time: 87.189s
[2K
| Adam | epoch: 011 | loss: 0.19936 - acc: 0.9397 -- iter: 1376/1403
[A[ATraining Step: 484  | total loss: [1m[32m0.19999[0m[0m | time: 91.633s
[2K
| Adam | epoch: 011 | loss: 0.19999 - acc: 0.9395 | val_loss: 0.38406 - val_acc: 0.8542 -- iter: 1403/1403
--
Training Step: 485  | total loss: [1m[32m0.19510[0m[0m | time: 1.036s
[2K
| Adam | epoch: 012 | loss: 0.19510 - acc: 0.9424 -- iter: 0032/1403
[A[ATraining Step: 486  | total loss: [1m[32m0.19000[0m[0m | time: 1.995s
[2K
| Adam | epoch: 012 | loss: 0.19000 - acc: 0.9388 -- iter: 0064/1403
[A[ATraining Step: 487  | total loss: [1m[32m0.20541[0m[0m | time: 3.128s
[2K
| Adam | epoch: 012 | loss: 0.20541 - acc: 0.9293 -- iter: 0096/1403
[A[ATraining Step: 488  | total loss: [1m[32m0.19641[0m[0m | time: 4.004s
[2K
| Adam | epoch: 012 | loss: 0.19641 - acc: 0.9332 -- iter: 0128/1403
[A[ATraining Step: 489  | total loss: [1m[32m0.19026[0m[0m | time: 5.020s
[2K
| Adam | epoch: 012 | loss: 0.19026 - acc: 0.9336 -- iter: 0160/1403
[A[ATraining Step: 490  | total loss: [1m[32m0.18803[0m[0m | time: 6.412s
[2K
| Adam | epoch: 012 | loss: 0.18803 - acc: 0.9340 -- iter: 0192/1403
[A[ATraining Step: 491  | total loss: [1m[32m0.18236[0m[0m | time: 7.844s
[2K
| Adam | epoch: 012 | loss: 0.18236 - acc: 0.9313 -- iter: 0224/1403
[A[ATraining Step: 492  | total loss: [1m[32m0.18250[0m[0m | time: 10.836s
[2K
| Adam | epoch: 012 | loss: 0.18250 - acc: 0.9288 -- iter: 0256/1403
[A[ATraining Step: 493  | total loss: [1m[32m0.18326[0m[0m | time: 18.368s
[2K
| Adam | epoch: 012 | loss: 0.18326 - acc: 0.9328 -- iter: 0288/1403
[A[ATraining Step: 494  | total loss: [1m[32m0.17740[0m[0m | time: 19.117s
[2K
| Adam | epoch: 012 | loss: 0.17740 - acc: 0.9364 -- iter: 0320/1403
[A[ATraining Step: 495  | total loss: [1m[32m0.17631[0m[0m | time: 19.994s
[2K
| Adam | epoch: 012 | loss: 0.17631 - acc: 0.9353 -- iter: 0352/1403
[A[ATraining Step: 496  | total loss: [1m[32m0.17015[0m[0m | time: 21.002s
[2K
| Adam | epoch: 012 | loss: 0.17015 - acc: 0.9381 -- iter: 0384/1403
[A[ATraining Step: 497  | total loss: [1m[32m0.16415[0m[0m | time: 22.012s
[2K
| Adam | epoch: 012 | loss: 0.16415 - acc: 0.9380 -- iter: 0416/1403
[A[ATraining Step: 498  | total loss: [1m[32m0.15784[0m[0m | time: 23.039s
[2K
| Adam | epoch: 012 | loss: 0.15784 - acc: 0.9411 -- iter: 0448/1403
[A[ATraining Step: 499  | total loss: [1m[32m0.16378[0m[0m | time: 24.097s
[2K
| Adam | epoch: 012 | loss: 0.16378 - acc: 0.9376 -- iter: 0480/1403
[A[ATraining Step: 500  | total loss: [1m[32m0.17348[0m[0m | time: 25.132s
[2K
| Adam | epoch: 012 | loss: 0.17348 - acc: 0.9345 -- iter: 0512/1403
[A[ATraining Step: 501  | total loss: [1m[32m0.16223[0m[0m | time: 26.078s
[2K
| Adam | epoch: 012 | loss: 0.16223 - acc: 0.9410 -- iter: 0544/1403
[A[ATraining Step: 502  | total loss: [1m[32m0.15277[0m[0m | time: 27.335s
[2K
| Adam | epoch: 012 | loss: 0.15277 - acc: 0.9438 -- iter: 0576/1403
[A[ATraining Step: 503  | total loss: [1m[32m0.16766[0m[0m | time: 28.588s
[2K
| Adam | epoch: 012 | loss: 0.16766 - acc: 0.9400 -- iter: 0608/1403
[A[ATraining Step: 504  | total loss: [1m[32m0.17242[0m[0m | time: 29.438s
[2K
| Adam | epoch: 012 | loss: 0.17242 - acc: 0.9398 -- iter: 0640/1403
[A[ATraining Step: 505  | total loss: [1m[32m0.16675[0m[0m | time: 30.397s
[2K
| Adam | epoch: 012 | loss: 0.16675 - acc: 0.9427 -- iter: 0672/1403
[A[ATraining Step: 506  | total loss: [1m[32m0.15609[0m[0m | time: 31.438s
[2K
| Adam | epoch: 012 | loss: 0.15609 - acc: 0.9484 -- iter: 0704/1403
[A[ATraining Step: 507  | total loss: [1m[32m0.15998[0m[0m | time: 32.430s
[2K
| Adam | epoch: 012 | loss: 0.15998 - acc: 0.9473 -- iter: 0736/1403
[A[ATraining Step: 508  | total loss: [1m[32m0.20044[0m[0m | time: 33.430s
[2K
| Adam | epoch: 012 | loss: 0.20044 - acc: 0.9370 -- iter: 0768/1403
[A[ATraining Step: 509  | total loss: [1m[32m0.19333[0m[0m | time: 34.490s
[2K
| Adam | epoch: 012 | loss: 0.19333 - acc: 0.9401 -- iter: 0800/1403
[A[ATraining Step: 510  | total loss: [1m[32m0.17997[0m[0m | time: 35.550s
[2K
| Adam | epoch: 012 | loss: 0.17997 - acc: 0.9461 -- iter: 0832/1403
[A[ATraining Step: 511  | total loss: [1m[32m0.17202[0m[0m | time: 36.507s
[2K
| Adam | epoch: 012 | loss: 0.17202 - acc: 0.9484 -- iter: 0864/1403
[A[ATraining Step: 512  | total loss: [1m[32m0.15948[0m[0m | time: 37.778s
[2K
| Adam | epoch: 012 | loss: 0.15948 - acc: 0.9536 -- iter: 0896/1403
[A[ATraining Step: 513  | total loss: [1m[32m0.15222[0m[0m | time: 39.143s
[2K
| Adam | epoch: 012 | loss: 0.15222 - acc: 0.9551 -- iter: 0928/1403
[A[ATraining Step: 514  | total loss: [1m[32m0.14670[0m[0m | time: 40.164s
[2K
| Adam | epoch: 012 | loss: 0.14670 - acc: 0.9564 -- iter: 0960/1403
[A[ATraining Step: 515  | total loss: [1m[32m0.13798[0m[0m | time: 41.135s
[2K
| Adam | epoch: 012 | loss: 0.13798 - acc: 0.9608 -- iter: 0992/1403
[A[ATraining Step: 516  | total loss: [1m[32m0.14075[0m[0m | time: 42.254s
[2K
| Adam | epoch: 012 | loss: 0.14075 - acc: 0.9585 -- iter: 1024/1403
[A[ATraining Step: 517  | total loss: [1m[32m0.13243[0m[0m | time: 43.248s
[2K
| Adam | epoch: 012 | loss: 0.13243 - acc: 0.9626 -- iter: 1056/1403
[A[ATraining Step: 518  | total loss: [1m[32m0.12703[0m[0m | time: 44.342s
[2K
| Adam | epoch: 012 | loss: 0.12703 - acc: 0.9632 -- iter: 1088/1403
[A[ATraining Step: 519  | total loss: [1m[32m0.11772[0m[0m | time: 45.409s
[2K
| Adam | epoch: 012 | loss: 0.11772 - acc: 0.9669 -- iter: 1120/1403
[A[ATraining Step: 520  | total loss: [1m[32m0.11342[0m[0m | time: 46.362s
[2K
| Adam | epoch: 012 | loss: 0.11342 - acc: 0.9671 -- iter: 1152/1403
[A[ATraining Step: 521  | total loss: [1m[32m0.11188[0m[0m | time: 47.387s
[2K
| Adam | epoch: 012 | loss: 0.11188 - acc: 0.9704 -- iter: 1184/1403
[A[ATraining Step: 522  | total loss: [1m[32m0.12009[0m[0m | time: 48.595s
[2K
| Adam | epoch: 012 | loss: 0.12009 - acc: 0.9671 -- iter: 1216/1403
[A[ATraining Step: 523  | total loss: [1m[32m0.11292[0m[0m | time: 49.874s
[2K
| Adam | epoch: 012 | loss: 0.11292 - acc: 0.9704 -- iter: 1248/1403
[A[ATraining Step: 524  | total loss: [1m[32m0.10515[0m[0m | time: 50.655s
[2K
| Adam | epoch: 012 | loss: 0.10515 - acc: 0.9733 -- iter: 1280/1403
[A[ATraining Step: 525  | total loss: [1m[32m0.10175[0m[0m | time: 51.632s
[2K
| Adam | epoch: 012 | loss: 0.10175 - acc: 0.9729 -- iter: 1312/1403
[A[ATraining Step: 526  | total loss: [1m[32m0.11913[0m[0m | time: 52.703s
[2K
| Adam | epoch: 012 | loss: 0.11913 - acc: 0.9693 -- iter: 1344/1403
[A[ATraining Step: 527  | total loss: [1m[32m0.12801[0m[0m | time: 53.755s
[2K
| Adam | epoch: 012 | loss: 0.12801 - acc: 0.9630 -- iter: 1376/1403
[A[ATraining Step: 528  | total loss: [1m[32m0.12012[0m[0m | time: 57.477s
[2K
| Adam | epoch: 012 | loss: 0.12012 - acc: 0.9667 | val_loss: 0.31131 - val_acc: 0.9043 -- iter: 1403/1403
--
Training Step: 529  | total loss: [1m[32m0.11107[0m[0m | time: 1.403s
[2K
| Adam | epoch: 013 | loss: 0.11107 - acc: 0.9701 -- iter: 0032/1403
[A[ATraining Step: 530  | total loss: [1m[32m0.10905[0m[0m | time: 2.413s
[2K
| Adam | epoch: 013 | loss: 0.10905 - acc: 0.9699 -- iter: 0064/1403
[A[ATraining Step: 531  | total loss: [1m[32m0.12656[0m[0m | time: 3.308s
[2K
| Adam | epoch: 013 | loss: 0.12656 - acc: 0.9667 -- iter: 0096/1403
[A[ATraining Step: 532  | total loss: [1m[32m0.12957[0m[0m | time: 4.260s
[2K
| Adam | epoch: 013 | loss: 0.12957 - acc: 0.9638 -- iter: 0128/1403
[A[ATraining Step: 533  | total loss: [1m[32m0.11942[0m[0m | time: 5.247s
[2K
| Adam | epoch: 013 | loss: 0.11942 - acc: 0.9674 -- iter: 0160/1403
[A[ATraining Step: 534  | total loss: [1m[32m0.13320[0m[0m | time: 6.202s
[2K
| Adam | epoch: 013 | loss: 0.13320 - acc: 0.9582 -- iter: 0192/1403
[A[ATraining Step: 535  | total loss: [1m[32m0.13479[0m[0m | time: 7.296s
[2K
| Adam | epoch: 013 | loss: 0.13479 - acc: 0.9592 -- iter: 0224/1403
[A[ATraining Step: 536  | total loss: [1m[32m0.14302[0m[0m | time: 8.427s
[2K
| Adam | epoch: 013 | loss: 0.14302 - acc: 0.9570 -- iter: 0256/1403
[A[ATraining Step: 537  | total loss: [1m[32m0.13673[0m[0m | time: 9.426s
[2K
| Adam | epoch: 013 | loss: 0.13673 - acc: 0.9582 -- iter: 0288/1403
[A[ATraining Step: 538  | total loss: [1m[32m0.13279[0m[0m | time: 10.552s
[2K
| Adam | epoch: 013 | loss: 0.13279 - acc: 0.9593 -- iter: 0320/1403
[A[ATraining Step: 539  | total loss: [1m[32m0.15409[0m[0m | time: 11.630s
[2K
| Adam | epoch: 013 | loss: 0.15409 - acc: 0.9540 -- iter: 0352/1403
[A[ATraining Step: 540  | total loss: [1m[32m0.14633[0m[0m | time: 12.786s
[2K
| Adam | epoch: 013 | loss: 0.14633 - acc: 0.9549 -- iter: 0384/1403
[A[ATraining Step: 541  | total loss: [1m[32m0.13424[0m[0m | time: 13.683s
[2K
| Adam | epoch: 013 | loss: 0.13424 - acc: 0.9594 -- iter: 0416/1403
[A[ATraining Step: 542  | total loss: [1m[32m0.17161[0m[0m | time: 14.661s
[2K
| Adam | epoch: 013 | loss: 0.17161 - acc: 0.9478 -- iter: 0448/1403
[A[ATraining Step: 543  | total loss: [1m[32m0.16460[0m[0m | time: 15.710s
[2K
| Adam | epoch: 013 | loss: 0.16460 - acc: 0.9468 -- iter: 0480/1403
[A[ATraining Step: 544  | total loss: [1m[32m0.16696[0m[0m | time: 16.727s
[2K
| Adam | epoch: 013 | loss: 0.16696 - acc: 0.9427 -- iter: 0512/1403
[A[ATraining Step: 545  | total loss: [1m[32m0.16713[0m[0m | time: 17.752s
[2K
| Adam | epoch: 013 | loss: 0.16713 - acc: 0.9391 -- iter: 0544/1403
[A[ATraining Step: 546  | total loss: [1m[32m0.17537[0m[0m | time: 18.781s
[2K
| Adam | epoch: 013 | loss: 0.17537 - acc: 0.9358 -- iter: 0576/1403
[A[ATraining Step: 547  | total loss: [1m[32m0.16882[0m[0m | time: 19.754s
[2K
| Adam | epoch: 013 | loss: 0.16882 - acc: 0.9391 -- iter: 0608/1403
[A[ATraining Step: 548  | total loss: [1m[32m0.18534[0m[0m | time: 20.790s
[2K
| Adam | epoch: 013 | loss: 0.18534 - acc: 0.9327 -- iter: 0640/1403
[A[ATraining Step: 549  | total loss: [1m[32m0.19878[0m[0m | time: 22.101s
[2K
| Adam | epoch: 013 | loss: 0.19878 - acc: 0.9238 -- iter: 0672/1403
[A[ATraining Step: 550  | total loss: [1m[32m0.19013[0m[0m | time: 23.284s
[2K
| Adam | epoch: 013 | loss: 0.19013 - acc: 0.9283 -- iter: 0704/1403
[A[ATraining Step: 551  | total loss: [1m[32m0.17740[0m[0m | time: 24.112s
[2K
| Adam | epoch: 013 | loss: 0.17740 - acc: 0.9355 -- iter: 0736/1403
[A[ATraining Step: 552  | total loss: [1m[32m0.17216[0m[0m | time: 25.051s
[2K
| Adam | epoch: 013 | loss: 0.17216 - acc: 0.9388 -- iter: 0768/1403
[A[ATraining Step: 553  | total loss: [1m[32m0.19291[0m[0m | time: 26.018s
[2K
| Adam | epoch: 013 | loss: 0.19291 - acc: 0.9293 -- iter: 0800/1403
[A[ATraining Step: 554  | total loss: [1m[32m0.19480[0m[0m | time: 27.048s
[2K
| Adam | epoch: 013 | loss: 0.19480 - acc: 0.9270 -- iter: 0832/1403
[A[ATraining Step: 555  | total loss: [1m[32m0.18156[0m[0m | time: 28.091s
[2K
| Adam | epoch: 013 | loss: 0.18156 - acc: 0.9343 -- iter: 0864/1403
[A[ATraining Step: 556  | total loss: [1m[32m0.17121[0m[0m | time: 29.147s
[2K
| Adam | epoch: 013 | loss: 0.17121 - acc: 0.9377 -- iter: 0896/1403
[A[ATraining Step: 557  | total loss: [1m[32m0.16540[0m[0m | time: 30.219s
[2K
| Adam | epoch: 013 | loss: 0.16540 - acc: 0.9377 -- iter: 0928/1403
[A[ATraining Step: 558  | total loss: [1m[32m0.16079[0m[0m | time: 31.153s
[2K
| Adam | epoch: 013 | loss: 0.16079 - acc: 0.9408 -- iter: 0960/1403
[A[ATraining Step: 559  | total loss: [1m[32m0.17350[0m[0m | time: 32.427s
[2K
| Adam | epoch: 013 | loss: 0.17350 - acc: 0.9374 -- iter: 0992/1403
[A[ATraining Step: 560  | total loss: [1m[32m0.16367[0m[0m | time: 33.718s
[2K
| Adam | epoch: 013 | loss: 0.16367 - acc: 0.9436 -- iter: 1024/1403
[A[ATraining Step: 561  | total loss: [1m[32m0.17505[0m[0m | time: 34.663s
[2K
| Adam | epoch: 013 | loss: 0.17505 - acc: 0.9399 -- iter: 1056/1403
[A[ATraining Step: 562  | total loss: [1m[32m0.17176[0m[0m | time: 35.645s
[2K
| Adam | epoch: 013 | loss: 0.17176 - acc: 0.9396 -- iter: 1088/1403
[A[ATraining Step: 563  | total loss: [1m[32m0.15972[0m[0m | time: 36.642s
[2K
| Adam | epoch: 013 | loss: 0.15972 - acc: 0.9457 -- iter: 1120/1403
[A[ATraining Step: 564  | total loss: [1m[32m0.14780[0m[0m | time: 37.641s
[2K
| Adam | epoch: 013 | loss: 0.14780 - acc: 0.9511 -- iter: 1152/1403
[A[ATraining Step: 565  | total loss: [1m[32m0.14410[0m[0m | time: 38.690s
[2K
| Adam | epoch: 013 | loss: 0.14410 - acc: 0.9529 -- iter: 1184/1403
[A[ATraining Step: 566  | total loss: [1m[32m0.13549[0m[0m | time: 39.725s
[2K
| Adam | epoch: 013 | loss: 0.13549 - acc: 0.9545 -- iter: 1216/1403
[A[ATraining Step: 567  | total loss: [1m[32m0.12555[0m[0m | time: 40.746s
[2K
| Adam | epoch: 013 | loss: 0.12555 - acc: 0.9590 -- iter: 1248/1403
[A[ATraining Step: 568  | total loss: [1m[32m0.12550[0m[0m | time: 41.754s
[2K
| Adam | epoch: 013 | loss: 0.12550 - acc: 0.9569 -- iter: 1280/1403
[A[ATraining Step: 569  | total loss: [1m[32m0.11561[0m[0m | time: 42.901s
[2K
| Adam | epoch: 013 | loss: 0.11561 - acc: 0.9612 -- iter: 1312/1403
[A[ATraining Step: 570  | total loss: [1m[32m0.11962[0m[0m | time: 44.159s
[2K
| Adam | epoch: 013 | loss: 0.11962 - acc: 0.9557 -- iter: 1344/1403
[A[ATraining Step: 571  | total loss: [1m[32m0.12025[0m[0m | time: 45.019s
[2K
| Adam | epoch: 013 | loss: 0.12025 - acc: 0.9570 -- iter: 1376/1403
[A[ATraining Step: 572  | total loss: [1m[32m0.11879[0m[0m | time: 48.695s
[2K
| Adam | epoch: 013 | loss: 0.11879 - acc: 0.9582 | val_loss: 0.34845 - val_acc: 0.8838 -- iter: 1403/1403
--
Training Step: 573  | total loss: [1m[32m0.11044[0m[0m | time: 1.085s
[2K
| Adam | epoch: 014 | loss: 0.11044 - acc: 0.9624 -- iter: 0032/1403
[A[ATraining Step: 574  | total loss: [1m[32m0.10113[0m[0m | time: 2.113s
[2K
| Adam | epoch: 014 | loss: 0.10113 - acc: 0.9661 -- iter: 0064/1403
[A[ATraining Step: 575  | total loss: [1m[32m0.10339[0m[0m | time: 3.015s
[2K
| Adam | epoch: 014 | loss: 0.10339 - acc: 0.9664 -- iter: 0096/1403
[A[ATraining Step: 576  | total loss: [1m[32m0.10787[0m[0m | time: 4.098s
[2K
| Adam | epoch: 014 | loss: 0.10787 - acc: 0.9666 -- iter: 0128/1403
[A[ATraining Step: 577  | total loss: [1m[32m0.11107[0m[0m | time: 5.366s
[2K
| Adam | epoch: 014 | loss: 0.11107 - acc: 0.9668 -- iter: 0160/1403
[A[ATraining Step: 578  | total loss: [1m[32m0.10368[0m[0m | time: 6.374s
[2K
| Adam | epoch: 014 | loss: 0.10368 - acc: 0.9701 -- iter: 0192/1403
[A[ATraining Step: 579  | total loss: [1m[32m0.09644[0m[0m | time: 7.287s
[2K
| Adam | epoch: 014 | loss: 0.09644 - acc: 0.9731 -- iter: 0224/1403
[A[ATraining Step: 580  | total loss: [1m[32m0.10069[0m[0m | time: 8.287s
[2K
| Adam | epoch: 014 | loss: 0.10069 - acc: 0.9727 -- iter: 0256/1403
[A[ATraining Step: 581  | total loss: [1m[32m0.10198[0m[0m | time: 9.262s
[2K
| Adam | epoch: 014 | loss: 0.10198 - acc: 0.9723 -- iter: 0288/1403
[A[ATraining Step: 582  | total loss: [1m[32m0.09480[0m[0m | time: 10.226s
[2K
| Adam | epoch: 014 | loss: 0.09480 - acc: 0.9751 -- iter: 0320/1403
[A[ATraining Step: 583  | total loss: [1m[32m0.10684[0m[0m | time: 11.233s
[2K
| Adam | epoch: 014 | loss: 0.10684 - acc: 0.9744 -- iter: 0352/1403
[A[ATraining Step: 584  | total loss: [1m[32m0.10255[0m[0m | time: 12.101s
[2K
| Adam | epoch: 014 | loss: 0.10255 - acc: 0.9739 -- iter: 0384/1403
[A[ATraining Step: 585  | total loss: [1m[32m0.11595[0m[0m | time: 12.951s
[2K
| Adam | epoch: 014 | loss: 0.11595 - acc: 0.9728 -- iter: 0416/1403
[A[ATraining Step: 586  | total loss: [1m[32m0.12425[0m[0m | time: 13.908s
[2K
| Adam | epoch: 014 | loss: 0.12425 - acc: 0.9718 -- iter: 0448/1403
[A[ATraining Step: 587  | total loss: [1m[32m0.11353[0m[0m | time: 15.301s
[2K
| Adam | epoch: 014 | loss: 0.11353 - acc: 0.9746 -- iter: 0480/1403
[A[ATraining Step: 588  | total loss: [1m[32m0.11194[0m[0m | time: 16.760s
[2K
| Adam | epoch: 014 | loss: 0.11194 - acc: 0.9709 -- iter: 0512/1403
[A[ATraining Step: 589  | total loss: [1m[32m0.13128[0m[0m | time: 17.748s
[2K
| Adam | epoch: 014 | loss: 0.13128 - acc: 0.9613 -- iter: 0544/1403
[A[ATraining Step: 590  | total loss: [1m[32m0.13033[0m[0m | time: 19.764s
[2K
| Adam | epoch: 014 | loss: 0.13033 - acc: 0.9621 -- iter: 0576/1403
[A[ATraining Step: 591  | total loss: [1m[32m0.12245[0m[0m | time: 20.794s
[2K
| Adam | epoch: 014 | loss: 0.12245 - acc: 0.9627 -- iter: 0608/1403
[A[ATraining Step: 592  | total loss: [1m[32m0.11470[0m[0m | time: 21.876s
[2K
| Adam | epoch: 014 | loss: 0.11470 - acc: 0.9665 -- iter: 0640/1403
[A[ATraining Step: 593  | total loss: [1m[32m0.10924[0m[0m | time: 22.921s
[2K
| Adam | epoch: 014 | loss: 0.10924 - acc: 0.9698 -- iter: 0672/1403
[A[ATraining Step: 594  | total loss: [1m[32m0.10266[0m[0m | time: 24.000s
[2K
| Adam | epoch: 014 | loss: 0.10266 - acc: 0.9728 -- iter: 0704/1403
[A[ATraining Step: 595  | total loss: [1m[32m0.10611[0m[0m | time: 25.033s
[2K
| Adam | epoch: 014 | loss: 0.10611 - acc: 0.9693 -- iter: 0736/1403
[A[ATraining Step: 596  | total loss: [1m[32m0.12498[0m[0m | time: 25.955s
[2K
| Adam | epoch: 014 | loss: 0.12498 - acc: 0.9630 -- iter: 0768/1403
[A[ATraining Step: 597  | total loss: [1m[32m0.11897[0m[0m | time: 27.049s
[2K
| Adam | epoch: 014 | loss: 0.11897 - acc: 0.9636 -- iter: 0800/1403
[A[ATraining Step: 598  | total loss: [1m[32m0.12577[0m[0m | time: 28.267s
[2K
| Adam | epoch: 014 | loss: 0.12577 - acc: 0.9610 -- iter: 0832/1403
[A[ATraining Step: 599  | total loss: [1m[32m0.11556[0m[0m | time: 29.114s
[2K
| Adam | epoch: 014 | loss: 0.11556 - acc: 0.9649 -- iter: 0864/1403
[A[ATraining Step: 600  | total loss: [1m[32m0.10647[0m[0m | time: 32.723s
[2K
| Adam | epoch: 014 | loss: 0.10647 - acc: 0.9684 | val_loss: 0.34489 - val_acc: 0.8861 -- iter: 0896/1403
--
Training Step: 601  | total loss: [1m[32m0.10214[0m[0m | time: 33.787s
[2K
| Adam | epoch: 014 | loss: 0.10214 - acc: 0.9715 -- iter: 0928/1403
[A[ATraining Step: 602  | total loss: [1m[32m0.09959[0m[0m | time: 34.892s
[2K
| Adam | epoch: 014 | loss: 0.09959 - acc: 0.9713 -- iter: 0960/1403
[A[ATraining Step: 603  | total loss: [1m[32m0.10261[0m[0m | time: 35.870s
[2K
| Adam | epoch: 014 | loss: 0.10261 - acc: 0.9679 -- iter: 0992/1403
[A[ATraining Step: 604  | total loss: [1m[32m0.11000[0m[0m | time: 36.786s
[2K
| Adam | epoch: 014 | loss: 0.11000 - acc: 0.9617 -- iter: 1024/1403
[A[ATraining Step: 605  | total loss: [1m[32m0.10230[0m[0m | time: 37.955s
[2K
| Adam | epoch: 014 | loss: 0.10230 - acc: 0.9655 -- iter: 1056/1403
[A[ATraining Step: 606  | total loss: [1m[32m0.10337[0m[0m | time: 39.185s
[2K
| Adam | epoch: 014 | loss: 0.10337 - acc: 0.9659 -- iter: 1088/1403
[A[ATraining Step: 607  | total loss: [1m[32m0.10411[0m[0m | time: 39.977s
[2K
| Adam | epoch: 014 | loss: 0.10411 - acc: 0.9662 -- iter: 1120/1403
[A[ATraining Step: 608  | total loss: [1m[32m0.09700[0m[0m | time: 40.935s
[2K
| Adam | epoch: 014 | loss: 0.09700 - acc: 0.9695 -- iter: 1152/1403
[A[ATraining Step: 609  | total loss: [1m[32m0.08882[0m[0m | time: 41.980s
[2K
| Adam | epoch: 014 | loss: 0.08882 - acc: 0.9726 -- iter: 1184/1403
[A[ATraining Step: 610  | total loss: [1m[32m0.08812[0m[0m | time: 42.902s
[2K
| Adam | epoch: 014 | loss: 0.08812 - acc: 0.9722 -- iter: 1216/1403
[A[ATraining Step: 611  | total loss: [1m[32m0.09858[0m[0m | time: 43.904s
[2K
| Adam | epoch: 014 | loss: 0.09858 - acc: 0.9687 -- iter: 1248/1403
[A[ATraining Step: 612  | total loss: [1m[32m0.10723[0m[0m | time: 44.884s
[2K
| Adam | epoch: 014 | loss: 0.10723 - acc: 0.9687 -- iter: 1280/1403
[A[ATraining Step: 613  | total loss: [1m[32m0.11166[0m[0m | time: 45.878s
[2K
| Adam | epoch: 014 | loss: 0.11166 - acc: 0.9656 -- iter: 1312/1403
[A[ATraining Step: 614  | total loss: [1m[32m0.10451[0m[0m | time: 46.794s
[2K
| Adam | epoch: 014 | loss: 0.10451 - acc: 0.9691 -- iter: 1344/1403
[A[ATraining Step: 615  | total loss: [1m[32m0.09753[0m[0m | time: 47.763s
[2K
| Adam | epoch: 014 | loss: 0.09753 - acc: 0.9721 -- iter: 1376/1403
[A[ATraining Step: 616  | total loss: [1m[32m0.11762[0m[0m | time: 51.493s
[2K
| Adam | epoch: 014 | loss: 0.11762 - acc: 0.9687 | val_loss: 0.51023 - val_acc: 0.8428 -- iter: 1403/1403
--
Training Step: 617  | total loss: [1m[32m0.13022[0m[0m | time: 0.971s
[2K
| Adam | epoch: 015 | loss: 0.13022 - acc: 0.9656 -- iter: 0032/1403
[A[ATraining Step: 618  | total loss: [1m[32m0.13887[0m[0m | time: 1.977s
[2K
| Adam | epoch: 015 | loss: 0.13887 - acc: 0.9628 -- iter: 0064/1403
[A[ATraining Step: 619  | total loss: [1m[32m0.13113[0m[0m | time: 2.913s
[2K
| Adam | epoch: 015 | loss: 0.13113 - acc: 0.9634 -- iter: 0096/1403
[A[ATraining Step: 620  | total loss: [1m[32m0.15238[0m[0m | time: 3.931s
[2K
| Adam | epoch: 015 | loss: 0.15238 - acc: 0.9545 -- iter: 0128/1403
[A[ATraining Step: 621  | total loss: [1m[32m0.14114[0m[0m | time: 4.964s
[2K
| Adam | epoch: 015 | loss: 0.14114 - acc: 0.9591 -- iter: 0160/1403
[A[ATraining Step: 622  | total loss: [1m[32m0.13005[0m[0m | time: 5.942s
[2K
| Adam | epoch: 015 | loss: 0.13005 - acc: 0.9632 -- iter: 0192/1403
[A[ATraining Step: 623  | total loss: [1m[32m0.11997[0m[0m | time: 7.035s
[2K
| Adam | epoch: 015 | loss: 0.11997 - acc: 0.9668 -- iter: 0224/1403
[A[ATraining Step: 624  | total loss: [1m[32m0.13737[0m[0m | time: 8.294s
[2K
| Adam | epoch: 015 | loss: 0.13737 - acc: 0.9608 -- iter: 0256/1403
[A[ATraining Step: 625  | total loss: [1m[32m0.13254[0m[0m | time: 9.380s
[2K
| Adam | epoch: 015 | loss: 0.13254 - acc: 0.9647 -- iter: 0288/1403
[A[ATraining Step: 626  | total loss: [1m[32m0.13611[0m[0m | time: 10.286s
[2K
| Adam | epoch: 015 | loss: 0.13611 - acc: 0.9620 -- iter: 0320/1403
[A[ATraining Step: 627  | total loss: [1m[32m0.13139[0m[0m | time: 11.325s
[2K
| Adam | epoch: 015 | loss: 0.13139 - acc: 0.9627 -- iter: 0352/1403
[A[ATraining Step: 628  | total loss: [1m[32m0.12821[0m[0m | time: 12.291s
[2K
| Adam | epoch: 015 | loss: 0.12821 - acc: 0.9601 -- iter: 0384/1403
[A[ATraining Step: 629  | total loss: [1m[32m0.13160[0m[0m | time: 13.138s
[2K
| Adam | epoch: 015 | loss: 0.13160 - acc: 0.9610 -- iter: 0416/1403
[A[ATraining Step: 630  | total loss: [1m[32m0.13011[0m[0m | time: 14.041s
[2K
| Adam | epoch: 015 | loss: 0.13011 - acc: 0.9612 -- iter: 0448/1403
[A[ATraining Step: 631  | total loss: [1m[32m0.12640[0m[0m | time: 15.126s
[2K
| Adam | epoch: 015 | loss: 0.12640 - acc: 0.9614 -- iter: 0480/1403
[A[ATraining Step: 632  | total loss: [1m[32m0.12801[0m[0m | time: 16.190s
[2K
| Adam | epoch: 015 | loss: 0.12801 - acc: 0.9621 -- iter: 0512/1403
[A[ATraining Step: 633  | total loss: [1m[32m0.11667[0m[0m | time: 17.262s
[2K
| Adam | epoch: 015 | loss: 0.11667 - acc: 0.9659 -- iter: 0544/1403
[A[ATraining Step: 634  | total loss: [1m[32m0.11411[0m[0m | time: 18.604s
[2K
| Adam | epoch: 015 | loss: 0.11411 - acc: 0.9662 -- iter: 0576/1403
[A[ATraining Step: 635  | total loss: [1m[32m0.11269[0m[0m | time: 19.806s
[2K
| Adam | epoch: 015 | loss: 0.11269 - acc: 0.9664 -- iter: 0608/1403
[A[ATraining Step: 636  | total loss: [1m[32m0.10588[0m[0m | time: 20.701s
[2K
| Adam | epoch: 015 | loss: 0.10588 - acc: 0.9698 -- iter: 0640/1403
[A[ATraining Step: 637  | total loss: [1m[32m0.10156[0m[0m | time: 21.739s
[2K
| Adam | epoch: 015 | loss: 0.10156 - acc: 0.9697 -- iter: 0672/1403
[A[ATraining Step: 638  | total loss: [1m[32m0.09483[0m[0m | time: 22.779s
[2K
| Adam | epoch: 015 | loss: 0.09483 - acc: 0.9727 -- iter: 0704/1403
[A[ATraining Step: 639  | total loss: [1m[32m0.11049[0m[0m | time: 23.774s
[2K
| Adam | epoch: 015 | loss: 0.11049 - acc: 0.9661 -- iter: 0736/1403
[A[ATraining Step: 640  | total loss: [1m[32m0.10291[0m[0m | time: 24.862s
[2K
| Adam | epoch: 015 | loss: 0.10291 - acc: 0.9695 -- iter: 0768/1403
[A[ATraining Step: 641  | total loss: [1m[32m0.09597[0m[0m | time: 25.916s
[2K
| Adam | epoch: 015 | loss: 0.09597 - acc: 0.9725 -- iter: 0800/1403
[A[ATraining Step: 642  | total loss: [1m[32m0.08858[0m[0m | time: 26.910s
[2K
| Adam | epoch: 015 | loss: 0.08858 - acc: 0.9753 -- iter: 0832/1403
[A[ATraining Step: 643  | total loss: [1m[32m0.12109[0m[0m | time: 28.060s
[2K
| Adam | epoch: 015 | loss: 0.12109 - acc: 0.9684 -- iter: 0864/1403
[A[ATraining Step: 644  | total loss: [1m[32m0.11769[0m[0m | time: 29.351s
[2K
| Adam | epoch: 015 | loss: 0.11769 - acc: 0.9653 -- iter: 0896/1403
[A[ATraining Step: 645  | total loss: [1m[32m0.12054[0m[0m | time: 30.452s
[2K
| Adam | epoch: 015 | loss: 0.12054 - acc: 0.9625 -- iter: 0928/1403
[A[ATraining Step: 646  | total loss: [1m[32m0.11618[0m[0m | time: 31.353s
[2K
| Adam | epoch: 015 | loss: 0.11618 - acc: 0.9631 -- iter: 0960/1403
[A[ATraining Step: 647  | total loss: [1m[32m0.10572[0m[0m | time: 32.346s
[2K
| Adam | epoch: 015 | loss: 0.10572 - acc: 0.9668 -- iter: 0992/1403
[A[ATraining Step: 648  | total loss: [1m[32m0.09850[0m[0m | time: 33.354s
[2K
| Adam | epoch: 015 | loss: 0.09850 - acc: 0.9701 -- iter: 1024/1403
[A[ATraining Step: 649  | total loss: [1m[32m0.10111[0m[0m | time: 34.331s
[2K
| Adam | epoch: 015 | loss: 0.10111 - acc: 0.9700 -- iter: 1056/1403
[A[ATraining Step: 650  | total loss: [1m[32m0.12353[0m[0m | time: 35.338s
[2K
| Adam | epoch: 015 | loss: 0.12353 - acc: 0.9636 -- iter: 1088/1403
[A[ATraining Step: 651  | total loss: [1m[32m0.13125[0m[0m | time: 36.345s
[2K
| Adam | epoch: 015 | loss: 0.13125 - acc: 0.9579 -- iter: 1120/1403
[A[ATraining Step: 652  | total loss: [1m[32m0.12388[0m[0m | time: 37.317s
[2K
| Adam | epoch: 015 | loss: 0.12388 - acc: 0.9590 -- iter: 1152/1403
[A[ATraining Step: 653  | total loss: [1m[32m0.11671[0m[0m | time: 38.391s
[2K
| Adam | epoch: 015 | loss: 0.11671 - acc: 0.9631 -- iter: 1184/1403
[A[ATraining Step: 654  | total loss: [1m[32m0.10957[0m[0m | time: 39.555s
[2K
| Adam | epoch: 015 | loss: 0.10957 - acc: 0.9636 -- iter: 1216/1403
[A[ATraining Step: 655  | total loss: [1m[32m0.10660[0m[0m | time: 40.690s
[2K
| Adam | epoch: 015 | loss: 0.10660 - acc: 0.9673 -- iter: 1248/1403
[A[ATraining Step: 656  | total loss: [1m[32m0.12105[0m[0m | time: 41.514s
[2K
| Adam | epoch: 015 | loss: 0.12105 - acc: 0.9643 -- iter: 1280/1403
[A[ATraining Step: 657  | total loss: [1m[32m0.11332[0m[0m | time: 42.483s
[2K
| Adam | epoch: 015 | loss: 0.11332 - acc: 0.9647 -- iter: 1312/1403
[A[ATraining Step: 658  | total loss: [1m[32m0.10470[0m[0m | time: 43.482s
[2K
| Adam | epoch: 015 | loss: 0.10470 - acc: 0.9683 -- iter: 1344/1403
[A[ATraining Step: 659  | total loss: [1m[32m0.09644[0m[0m | time: 44.451s
[2K
| Adam | epoch: 015 | loss: 0.09644 - acc: 0.9714 -- iter: 1376/1403
[A[ATraining Step: 660  | total loss: [1m[32m0.09819[0m[0m | time: 48.233s
[2K
| Adam | epoch: 015 | loss: 0.09819 - acc: 0.9712 | val_loss: 0.43824 - val_acc: 0.8702 -- iter: 1403/1403
--
2018-08-02 04:39:06.874055: W tensorflow/core/framework/allocator.cc:101] Allocation of 3975921152 exceeds 10% of system memory.
2018-08-02 04:39:08.691802: W tensorflow/core/framework/allocator.cc:101] Allocation of 3975921152 exceeds 10% of system memory.
Validation AUC:0.94148295761199
Validation AUPRC:0.9529294500480864
Test AUC:0.9479049405878673
Test AUPRC:0.9602589546435831
BestTestF1Score	0.88	0.78	0.89	0.86	0.9	185	29	205	20	0.81
BestTestMCCScore	0.9	0.83	0.91	0.96	0.84	173	7	227	32	0.98
BestTestAccuracyScore	0.9	0.83	0.91	0.96	0.84	173	7	227	32	0.98
BestValidationF1Score	0.89	0.78	0.89	0.88	0.9	195	27	195	22	0.81
BestValidationMCC	0.89	0.8	0.9	0.95	0.83	181	10	212	36	0.98
BestValidationAccuracy	0.89	0.8	0.9	0.95	0.83	181	10	212	36	0.98
TestPredictions (Threshold:0.98)
CHEMBL3298310,TP,ACT,1.0	CHEMBL246088,TP,ACT,0.9900000095367432	CHEMBL589503,TN,INACT,0.699999988079071	CHEMBL3297853,TP,ACT,1.0	CHEMBL3654862,TP,ACT,1.0	CHEMBL86795,TN,INACT,0.10000000149011612	CHEMBL1910762,TN,INACT,0.009999999776482582	CHEMBL309625,TN,INACT,0.2199999988079071	CHEMBL328627,TN,INACT,0.019999999552965164	CHEMBL1688212,TN,INACT,0.27000001072883606	CHEMBL513336,TN,INACT,0.029999999329447746	CHEMBL541445,TN,INACT,0.05000000074505806	CHEMBL7699,TN,INACT,0.029999999329447746	CHEMBL3421968,TN,INACT,0.029999999329447746	CHEMBL3658641,TP,ACT,1.0	CHEMBL214949,TN,INACT,0.5699999928474426	CHEMBL322640,TN,INACT,0.009999999776482582	CHEMBL3658769,TP,ACT,1.0	CHEMBL3298308,FN,ACT,0.9700000286102295	CHEMBL3098312,TN,INACT,0.029999999329447746	CHEMBL3654791,TP,ACT,1.0	CHEMBL3658758,TP,ACT,1.0	CHEMBL3654756,TP,ACT,1.0	CHEMBL2372113,TN,INACT,0.029999999329447746	CHEMBL3658827,TP,ACT,1.0	CHEMBL3658644,TP,ACT,1.0	CHEMBL3409572,FN,ACT,0.9700000286102295	CHEMBL3658714,TP,ACT,1.0	CHEMBL454617,FN,ACT,0.009999999776482582	CHEMBL3797559,TN,INACT,0.09000000357627869	CHEMBL3662983,TP,ACT,1.0	CHEMBL228114,TN,INACT,0.05000000074505806	CHEMBL246166,TN,INACT,0.9599999785423279	CHEMBL1956893,TN,INACT,0.009999999776482582	CHEMBL93464,TN,INACT,0.6499999761581421	CHEMBL2392232,TN,INACT,0.019999999552965164	CHEMBL603198,TN,INACT,0.009999999776482582	CHEMBL529663,TN,INACT,0.029999999329447746	CHEMBL3654806,TP,ACT,1.0	CHEMBL3654697,TP,ACT,1.0	CHEMBL3356120,TP,ACT,0.9900000095367432	CHEMBL3654691,TP,ACT,1.0	CHEMBL228862,TN,INACT,0.8700000047683716	CHEMBL1087054,TN,INACT,0.009999999776482582	CHEMBL3798109,TP,ACT,1.0	CHEMBL3658650,TP,ACT,1.0	CHEMBL3662959,TP,ACT,1.0	CHEMBL3658826,TP,ACT,1.0	CHEMBL2392379,TN,INACT,0.019999999552965164	CHEMBL3654709,TP,ACT,1.0	CHEMBL3342105,TN,INACT,0.009999999776482582	CHEMBL3608458,TP,ACT,0.9800000190734863	CHEMBL3798015,TP,ACT,1.0	CHEMBL100312,TN,INACT,0.009999999776482582	CHEMBL67655,TN,INACT,0.05000000074505806	CHEMBL3654839,TP,ACT,1.0	CHEMBL259551,FN,ACT,0.009999999776482582	CHEMBL1738705,TN,INACT,0.009999999776482582	CHEMBL435831,TN,INACT,0.0	CHEMBL557456,TN,INACT,0.009999999776482582	CHEMBL3671125,TP,ACT,1.0	CHEMBL1796187,FP,INACT,1.0	CHEMBL3671113,TP,ACT,1.0	CHEMBL3799614,TP,ACT,1.0	CHEMBL1081198,FP,INACT,0.9800000190734863	CHEMBL3604854,TP,ACT,1.0	CHEMBL2316152,TN,INACT,0.05000000074505806	CHEMBL1171125,TN,INACT,0.05000000074505806	CHEMBL3662970,TP,ACT,1.0	CHEMBL3654706,TP,ACT,0.9800000190734863	CHEMBL1973716,TN,INACT,0.009999999776482582	CHEMBL3658723,TP,ACT,1.0	CHEMBL3356115,TP,ACT,0.9800000190734863	CHEMBL3663082,TP,ACT,1.0	CHEMBL472566,TN,INACT,0.019999999552965164	CHEMBL3628376,FN,ACT,0.949999988079071	CHEMBL3658669,TP,ACT,1.0	CHEMBL3671127,FN,ACT,0.1899999976158142	CHEMBL219683,TP,ACT,1.0	CHEMBL2164716,TN,INACT,0.009999999776482582	CHEMBL3671109,TP,ACT,1.0	CHEMBL91,TN,INACT,0.009999999776482582	CHEMBL69358,TN,INACT,0.9399999976158142	CHEMBL3663087,TP,ACT,1.0	CHEMBL3628247,TN,INACT,0.03999999910593033	CHEMBL2029519,TN,INACT,0.029999999329447746	CHEMBL3353406,TN,INACT,0.25999999046325684	CHEMBL3298311,FN,ACT,0.7099999785423279	CHEMBL373628,TP,ACT,1.0	CHEMBL3409591,TP,ACT,1.0	CHEMBL3658766,TP,ACT,1.0	CHEMBL3654717,TP,ACT,1.0	CHEMBL3298416,TP,ACT,1.0	CHEMBL1242663,TN,INACT,0.009999999776482582	CHEMBL15887,TN,INACT,0.07000000029802322	CHEMBL3590114,FN,ACT,0.029999999329447746	CHEMBL74645,TN,INACT,0.029999999329447746	CHEMBL1956892,TN,INACT,0.07999999821186066	CHEMBL3663127,TP,ACT,1.0	CHEMBL2205426,FN,ACT,0.9700000286102295	CHEMBL3658825,TP,ACT,1.0	CHEMBL591437,TN,INACT,0.019999999552965164	CHEMBL335966,TN,INACT,0.6800000071525574	CHEMBL3662967,TP,ACT,1.0	CHEMBL3654730,TP,ACT,1.0	CHEMBL131382,TN,INACT,0.2800000011920929	CHEMBL3662969,TP,ACT,1.0	CHEMBL1944931,FP,INACT,0.9900000095367432	CHEMBL3672511,TN,INACT,0.0	CHEMBL1922120,TN,INACT,0.019999999552965164	CHEMBL3577565,TP,ACT,1.0	CHEMBL3654797,TP,ACT,1.0	CHEMBL290106,FN,ACT,0.019999999552965164	CHEMBL2062563,TN,INACT,0.009999999776482582	CHEMBL318485,TN,INACT,0.009999999776482582	CHEMBL3639713,TN,INACT,0.009999999776482582	CHEMBL1094808,TN,INACT,0.03999999910593033	CHEMBL3654735,TP,ACT,1.0	CHEMBL497114,TN,INACT,0.03999999910593033	CHEMBL3590112,TP,ACT,1.0	CHEMBL3654855,TP,ACT,1.0	CHEMBL3421980,TN,INACT,0.05000000074505806	CHEMBL1288005,TN,INACT,0.9599999785423279	CHEMBL1173023,TN,INACT,0.009999999776482582	CHEMBL3799956,FP,INACT,1.0	CHEMBL492828,TN,INACT,0.019999999552965164	CHEMBL329367,TN,INACT,0.4699999988079071	CHEMBL3133827,TN,INACT,0.05999999865889549	CHEMBL1734241,TN,INACT,0.18000000715255737	CHEMBL3263998,FP,INACT,1.0	CHEMBL3623846,TN,INACT,0.03999999910593033	CHEMBL3800262,TN,INACT,0.20000000298023224	CHEMBL3662980,FN,ACT,0.23999999463558197	CHEMBL1082152,TN,INACT,0.019999999552965164	CHEMBL2312645,TN,INACT,0.029999999329447746	CHEMBL3680461,TN,INACT,0.019999999552965164	CHEMBL1641998,TN,INACT,0.009999999776482582	CHEMBL1828883,TN,INACT,0.3400000035762787	CHEMBL128000,TN,INACT,0.03999999910593033	CHEMBL453336,TN,INACT,0.029999999329447746	CHEMBL2348167,TN,INACT,0.009999999776482582	CHEMBL137653,TN,INACT,0.2199999988079071	CHEMBL560278,TN,INACT,0.009999999776482582	CHEMBL3409592,TP,ACT,1.0	CHEMBL1809197,TN,INACT,0.20999999344348907	CHEMBL3627726,TN,INACT,0.05999999865889549	CHEMBL3663078,TP,ACT,1.0	CHEMBL509499,TN,INACT,0.019999999552965164	CHEMBL238617,TN,INACT,0.09000000357627869	CHEMBL3654885,TP,ACT,1.0	CHEMBL3659983,TN,INACT,0.2199999988079071	CHEMBL2425628,FN,ACT,0.44999998807907104	CHEMBL3661089,TN,INACT,0.009999999776482582	CHEMBL3654818,TP,ACT,1.0	CHEMBL431996,TN,INACT,0.019999999552965164	CHEMBL2392392,TN,INACT,0.23000000417232513	CHEMBL3658772,TP,ACT,1.0	CHEMBL3662961,TP,ACT,1.0	CHEMBL435054,TN,INACT,0.05000000074505806	CHEMBL291979,TN,INACT,0.0	CHEMBL208433,TN,INACT,0.03999999910593033	CHEMBL3654880,TP,ACT,1.0	CHEMBL1161234,TN,INACT,0.03999999910593033	CHEMBL3798624,TP,ACT,1.0	CHEMBL3781538,TN,INACT,0.44999998807907104	CHEMBL35482,FN,ACT,0.009999999776482582	CHEMBL209511,TN,INACT,0.019999999552965164	CHEMBL3663056,TP,ACT,1.0	CHEMBL3658787,TP,ACT,1.0	CHEMBL3663086,TP,ACT,1.0	CHEMBL550855,TN,INACT,0.7099999785423279	CHEMBL334026,TN,INACT,0.05999999865889549	CHEMBL247797,FN,ACT,0.23999999463558197	CHEMBL2031893,TN,INACT,0.8600000143051147	CHEMBL3663116,TP,ACT,1.0	CHEMBL565084,TN,INACT,0.009999999776482582	CHEMBL3628379,FN,ACT,0.9399999976158142	CHEMBL151,TN,INACT,0.8999999761581421	CHEMBL559683,TN,INACT,0.03999999910593033	CHEMBL62701,TN,INACT,0.05999999865889549	CHEMBL3409606,TP,ACT,1.0	CHEMBL455389,TN,INACT,0.019999999552965164	CHEMBL3663048,TP,ACT,1.0	CHEMBL3409596,TP,ACT,1.0	CHEMBL3662996,TP,ACT,1.0	CHEMBL1161235,TN,INACT,0.03999999910593033	CHEMBL1171955,TN,INACT,0.20999999344348907	CHEMBL509435,TN,INACT,0.029999999329447746	CHEMBL504547,TN,INACT,0.2199999988079071	CHEMBL3658740,TP,ACT,1.0	CHEMBL1922218,TN,INACT,0.019999999552965164	CHEMBL3658835,TP,ACT,1.0	CHEMBL3658736,TP,ACT,1.0	CHEMBL3356117,TP,ACT,0.9800000190734863	CHEMBL271138,TN,INACT,0.019999999552965164	CHEMBL1093100,TN,INACT,0.009999999776482582	CHEMBL1094784,TN,INACT,0.7699999809265137	CHEMBL77155,TN,INACT,0.029999999329447746	CHEMBL1466,FN,ACT,0.07000000029802322	CHEMBL311119,TN,INACT,0.09000000357627869	CHEMBL520882,FN,ACT,0.3400000035762787	CHEMBL3662973,TP,ACT,1.0	CHEMBL3675710,TP,ACT,1.0	CHEMBL1922219,TN,INACT,0.009999999776482582	CHEMBL3654686,TP,ACT,1.0	CHEMBL3654847,TP,ACT,1.0	CHEMBL3409571,TP,ACT,0.9900000095367432	CHEMBL3654769,TP,ACT,1.0	CHEMBL1910753,TN,INACT,0.0	CHEMBL380946,FN,ACT,0.4699999988079071	CHEMBL3663135,TP,ACT,1.0	CHEMBL1241943,TN,INACT,0.029999999329447746	CHEMBL563948,TN,INACT,0.019999999552965164	CHEMBL3662947,TP,ACT,1.0	CHEMBL3663016,TP,ACT,1.0	CHEMBL483081,TN,INACT,0.05000000074505806	CHEMBL568483,TP,ACT,1.0	CHEMBL589120,TN,INACT,0.05000000074505806	CHEMBL154080,TN,INACT,0.009999999776482582	CHEMBL3335362,TN,INACT,0.019999999552965164	CHEMBL220169,TN,INACT,0.05999999865889549	CHEMBL3663119,TP,ACT,1.0	CHEMBL3661090,TN,INACT,0.019999999552965164	CHEMBL603494,TN,INACT,0.019999999552965164	CHEMBL3654723,TP,ACT,1.0	CHEMBL3577634,TP,ACT,1.0	CHEMBL3663007,TP,ACT,1.0	CHEMBL3658732,TP,ACT,1.0	CHEMBL1235213,TN,INACT,0.009999999776482582	CHEMBL83228,TN,INACT,0.03999999910593033	CHEMBL2337363,TN,INACT,0.019999999552965164	CHEMBL3663072,TP,ACT,1.0	CHEMBL2337366,TN,INACT,0.009999999776482582	CHEMBL1094475,TN,INACT,0.029999999329447746	CHEMBL285527,TN,INACT,0.03999999910593033	CHEMBL1828880,TN,INACT,0.9200000166893005	CHEMBL3662984,TP,ACT,1.0	CHEMBL3604850,TP,ACT,1.0	CHEMBL522011,TN,INACT,0.07999999821186066	CHEMBL522760,TN,INACT,0.019999999552965164	CHEMBL550623,TN,INACT,0.949999988079071	CHEMBL3663095,TP,ACT,1.0	CHEMBL3658730,TP,ACT,1.0	CHEMBL3358976,TN,INACT,0.029999999329447746	CHEMBL564575,TN,INACT,0.019999999552965164	CHEMBL3577638,TP,ACT,1.0	CHEMBL502803,TN,INACT,0.0	CHEMBL1922215,TN,INACT,0.009999999776482582	CHEMBL3654774,TP,ACT,1.0	CHEMBL3421974,TN,INACT,0.7900000214576721	CHEMBL3577645,TP,ACT,1.0	CHEMBL3662957,TP,ACT,1.0	CHEMBL3297857,FN,ACT,0.8999999761581421	CHEMBL3663081,TP,ACT,1.0	CHEMBL3658823,TP,ACT,1.0	CHEMBL3654858,TP,ACT,1.0	CHEMBL3237851,TN,INACT,0.11999999731779099	CHEMBL184231,TN,INACT,0.949999988079071	CHEMBL2163612,TN,INACT,0.7699999809265137	CHEMBL3628360,TN,INACT,0.019999999552965164	CHEMBL482489,TN,INACT,0.009999999776482582	CHEMBL131098,TN,INACT,0.009999999776482582	CHEMBL3663010,TP,ACT,1.0	CHEMBL3298677,TP,ACT,0.9900000095367432	CHEMBL3628377,FN,ACT,0.9700000286102295	CHEMBL220320,TP,ACT,1.0	CHEMBL375621,FN,ACT,0.9100000262260437	CHEMBL264667,TN,INACT,0.019999999552965164	CHEMBL1952210,FN,ACT,0.009999999776482582	CHEMBL2337367,TN,INACT,0.009999999776482582	CHEMBL3297858,TP,ACT,1.0	CHEMBL3663005,TP,ACT,1.0	CHEMBL422540,TN,INACT,0.009999999776482582	CHEMBL1242468,TN,INACT,0.019999999552965164	CHEMBL362455,TN,INACT,0.029999999329447746	CHEMBL474208,TN,INACT,0.9200000166893005	CHEMBL399914,TN,INACT,0.8600000143051147	CHEMBL3658691,TP,ACT,1.0	CHEMBL3654677,TP,ACT,1.0	CHEMBL3409588,TP,ACT,1.0	CHEMBL450383,TN,INACT,0.14000000059604645	CHEMBL3663015,TP,ACT,1.0	CHEMBL2367589,TN,INACT,0.7900000214576721	CHEMBL3577631,FN,ACT,0.9300000071525574	CHEMBL3654875,TP,ACT,1.0	CHEMBL1683951,TN,INACT,0.019999999552965164	CHEMBL3680484,TN,INACT,0.019999999552965164	CHEMBL2163623,TN,INACT,0.0	CHEMBL73625,TN,INACT,0.03999999910593033	CHEMBL3658796,TP,ACT,1.0	CHEMBL3409589,TP,ACT,1.0	CHEMBL1288067,FP,INACT,1.0	CHEMBL280074,FN,ACT,0.6499999761581421	CHEMBL3654830,TP,ACT,1.0	CHEMBL3654779,TP,ACT,1.0	CHEMBL3358991,TN,INACT,0.550000011920929	CHEMBL524708,TN,INACT,0.15000000596046448	CHEMBL3590122,TP,ACT,1.0	CHEMBL100079,TN,INACT,0.03999999910593033	CHEMBL77732,TN,INACT,0.009999999776482582	CHEMBL3654759,TP,ACT,1.0	CHEMBL3654789,TP,ACT,1.0	CHEMBL90277,TN,INACT,0.44999998807907104	CHEMBL245884,TP,ACT,0.9900000095367432	CHEMBL3628372,TP,ACT,1.0	CHEMBL1910278,TN,INACT,0.07999999821186066	CHEMBL2372109,TN,INACT,0.009999999776482582	CHEMBL490251,TN,INACT,0.949999988079071	CHEMBL3654883,TP,ACT,1.0	CHEMBL2420909,TN,INACT,0.11999999731779099	CHEMBL3658773,TP,ACT,1.0	CHEMBL3663001,TP,ACT,1.0	CHEMBL334032,TN,INACT,0.05999999865889549	CHEMBL282575,TN,INACT,0.9200000166893005	CHEMBL3658645,TP,ACT,1.0	CHEMBL3654755,TP,ACT,1.0	CHEMBL3654833,TP,ACT,1.0	CHEMBL556669,TN,INACT,0.029999999329447746	CHEMBL3815097,TN,INACT,0.5699999928474426	CHEMBL3662999,TP,ACT,1.0	CHEMBL456797,TN,INACT,0.009999999776482582	CHEMBL1241300,TN,INACT,0.029999999329447746	CHEMBL3658731,TP,ACT,1.0	CHEMBL3658692,TP,ACT,1.0	CHEMBL157304,TN,INACT,0.03999999910593033	CHEMBL1910755,TN,INACT,0.029999999329447746	CHEMBL3353409,TN,INACT,0.07999999821186066	CHEMBL233349,TN,INACT,0.4300000071525574	CHEMBL266540,TN,INACT,0.10999999940395355	CHEMBL1684366,TN,INACT,0.9599999785423279	CHEMBL498130,FP,INACT,0.9800000190734863	CHEMBL131695,TN,INACT,0.07999999821186066	CHEMBL1559959,TN,INACT,0.05999999865889549	CHEMBL1242753,TN,INACT,0.05000000074505806	CHEMBL469346,TN,INACT,0.41999998688697815	CHEMBL3663126,TP,ACT,1.0	CHEMBL501709,TN,INACT,0.3199999928474426	CHEMBL3658814,TP,ACT,1.0	CHEMBL3628365,TN,INACT,0.12999999523162842	CHEMBL483535,TN,INACT,0.18000000715255737	CHEMBL3409605,FN,ACT,0.8799999952316284	CHEMBL3654840,TP,ACT,1.0	CHEMBL3658695,TP,ACT,1.0	CHEMBL3628252,TN,INACT,0.11999999731779099	CHEMBL3703715,TP,ACT,1.0	CHEMBL3102933,TN,INACT,0.550000011920929	CHEMBL3654699,TP,ACT,1.0	CHEMBL3398609,TP,ACT,0.9900000095367432	CHEMBL3662955,TP,ACT,1.0	CHEMBL497290,TN,INACT,0.019999999552965164	CHEMBL3654873,TP,ACT,1.0	CHEMBL3663028,TP,ACT,1.0	CHEMBL1945646,TN,INACT,0.09000000357627869	CHEMBL313433,TN,INACT,0.019999999552965164	CHEMBL3409584,TP,ACT,1.0	CHEMBL3799983,TP,ACT,1.0	CHEMBL1668411,TP,ACT,0.9900000095367432	CHEMBL3662994,TP,ACT,1.0	CHEMBL3798257,TP,ACT,1.0	CHEMBL3658718,TP,ACT,1.0	CHEMBL295316,TN,INACT,0.019999999552965164	CHEMBL1287975,TN,INACT,0.8600000143051147	CHEMBL3654824,TP,ACT,1.0	CHEMBL523780,TN,INACT,0.9700000286102295	CHEMBL2163616,TN,INACT,0.05999999865889549	CHEMBL326044,TN,INACT,0.019999999552965164	CHEMBL506247,FN,ACT,0.019999999552965164	CHEMBL3800189,TP,ACT,1.0	CHEMBL1172147,TN,INACT,0.07999999821186066	CHEMBL3133912,TN,INACT,0.9599999785423279	CHEMBL1080271,TN,INACT,0.9100000262260437	CHEMBL233958,TN,INACT,0.9700000286102295	CHEMBL89723,TN,INACT,0.03999999910593033	CHEMBL3671095,TP,ACT,1.0	CHEMBL296586,FN,ACT,0.009999999776482582	CHEMBL3671111,TP,ACT,1.0	CHEMBL3671105,TP,ACT,1.0	CHEMBL3654766,TP,ACT,1.0	CHEMBL3658727,TP,ACT,1.0	CHEMBL1688210,TN,INACT,0.0	CHEMBL332342,TN,INACT,0.03999999910593033	CHEMBL291986,TN,INACT,0.03999999910593033	CHEMBL3298312,FN,ACT,0.9399999976158142	CHEMBL3654716,TP,ACT,1.0	CHEMBL520515,TN,INACT,0.03999999910593033	CHEMBL3654841,TP,ACT,1.0	CHEMBL242237,TN,INACT,0.009999999776482582	CHEMBL1828884,TN,INACT,0.3100000023841858	CHEMBL3654838,TP,ACT,1.0	CHEMBL3662985,TP,ACT,1.0	CHEMBL726,TN,INACT,0.029999999329447746	CHEMBL3658637,TP,ACT,1.0	CHEMBL3654750,TP,ACT,1.0	CHEMBL564726,TN,INACT,0.019999999552965164	CHEMBL1172419,TN,INACT,0.009999999776482582	CHEMBL1241679,TN,INACT,0.009999999776482582	CHEMBL3658704,TP,ACT,1.0	CHEMBL1956888,TN,INACT,0.009999999776482582	CHEMBL3662975,TP,ACT,1.0	CHEMBL3680499,TN,INACT,0.019999999552965164	CHEMBL2064628,FN,ACT,0.75	CHEMBL602472,TN,INACT,0.029999999329447746	CHEMBL509,FN,ACT,0.019999999552965164	CHEMBL1242661,TN,INACT,0.03999999910593033	CHEMBL324439,TN,INACT,0.009999999776482582	CHEMBL3658646,TP,ACT,1.0	CHEMBL3604851,TP,ACT,1.0	CHEMBL1922119,TN,INACT,0.019999999552965164	CHEMBL373598,FN,ACT,0.3199999928474426	CHEMBL3663063,TP,ACT,1.0	CHEMBL373797,TP,ACT,0.9800000190734863	CHEMBL3639599,TN,INACT,0.019999999552965164	CHEMBL604748,TN,INACT,0.009999999776482582	CHEMBL3298894,TP,ACT,1.0	CHEMBL1762181,TN,INACT,0.30000001192092896	CHEMBL3654860,TP,ACT,1.0	CHEMBL3298982,TP,ACT,1.0	CHEMBL3675714,TP,ACT,0.9900000095367432	CHEMBL40583,TN,INACT,0.009999999776482582	CHEMBL3297854,TP,ACT,0.9900000095367432	CHEMBL3604845,TP,ACT,1.0	CHEMBL2392241,TN,INACT,0.03999999910593033	CHEMBL230761,TN,INACT,0.8700000047683716	CHEMBL3675703,TP,ACT,1.0	CHEMBL3675715,TP,ACT,1.0	CHEMBL57553,TN,INACT,0.9300000071525574	CHEMBL570313,TN,INACT,0.07000000029802322	CHEMBL3628253,TN,INACT,0.05999999865889549	CHEMBL3663099,TP,ACT,1.0	CHEMBL3798556,TN,INACT,0.8199999928474426	CHEMBL591051,TN,INACT,0.3499999940395355	CHEMBL3675719,TP,ACT,1.0	CHEMBL234944,TN,INACT,0.4000000059604645	CHEMBL1796184,TN,INACT,0.18000000715255737	CHEMBL591706,TN,INACT,0.029999999329447746	CHEMBL3628381,FN,ACT,0.9300000071525574	CHEMBL456143,TN,INACT,0.07000000029802322	CHEMBL2348165,TN,INACT,0.009999999776482582	CHEMBL1944928,TN,INACT,0.019999999552965164	

